Title: D&D AI and Power
Publication date: 2021-03-08
Playlist: Mozilla Festival 2021
Description: 
	The AI in our daily lives reinforces historical power imbalances â€” across gender, across race, and across class. Is it possible to make more just AI systems mainstream? A panel featuring:

Cierra Robson, Associate Director of the Ida B. Wells JUST Data Lab at Princeton University

Dr. Sarah Roberts, Co-Director, UCLA Center for Critical Internet Inquiry

Nighat Dad, Executive Director, Digital Rights Foundation

Julie Owono, Executive Director, Internet Sans FrontiÃ¨res

And moderator J. Bob Alotta, Mozilla's VP of Global Programs
Captions: 
	00:00:00,960 --> 00:00:04,880
hi everyone um thank you for joining us

00:00:03,280 --> 00:00:06,640
today i'm jay babalota

00:00:04,880 --> 00:00:08,400
i'm the vice president of global

00:00:06,640 --> 00:00:10,320
programs at mozilla and i'm going to be

00:00:08,400 --> 00:00:13,440
your host for today's panel

00:00:10,320 --> 00:00:14,400
um we have a vital discussion planned

00:00:13,440 --> 00:00:16,640
for today

00:00:14,400 --> 00:00:17,520
as part of mozfest's dialogues and

00:00:16,640 --> 00:00:19,039
debates

00:00:17,520 --> 00:00:20,720
we're going to unpack an issue that's

00:00:19,039 --> 00:00:21,439
underpinning so many of the problems

00:00:20,720 --> 00:00:23,199
online

00:00:21,439 --> 00:00:24,640
and offline today the relationship

00:00:23,199 --> 00:00:27,840
between ai

00:00:24,640 --> 00:00:30,080
and power the ai in our lives

00:00:27,840 --> 00:00:33,120
reinforces historical power imbalances

00:00:30,080 --> 00:00:35,680
across gender across race across class

00:00:33,120 --> 00:00:37,040
there are so many examples to list but

00:00:35,680 --> 00:00:39,520
here are a few

00:00:37,040 --> 00:00:40,239
hiring algorithms prior prioritize men

00:00:39,520 --> 00:00:42,320
over women

00:00:40,239 --> 00:00:44,480
and non-binary candidates facial

00:00:42,320 --> 00:00:46,559
recognition systems misidentified black

00:00:44,480 --> 00:00:49,760
faces and i would argue also that

00:00:46,559 --> 00:00:51,120
zoom backgrounds don't uh allow for

00:00:49,760 --> 00:00:52,879
black folks to use

00:00:51,120 --> 00:00:54,399
a zoom background without becoming part

00:00:52,879 --> 00:00:57,600
of the background as we

00:00:54,399 --> 00:00:58,879
just discovered 30 seconds ago and a

00:00:57,600 --> 00:01:00,079
year into the pandemic we could have

00:00:58,879 --> 00:01:03,280
gotten that right by now

00:01:00,079 --> 00:01:05,519
facial recognition systems uh um and

00:01:03,280 --> 00:01:07,760
voice assistants like alex and siri

00:01:05,519 --> 00:01:09,600
struggle to understand the voices of so

00:01:07,760 --> 00:01:11,920
many diasporas

00:01:09,600 --> 00:01:12,720
ai-powered digital ads can prey on or

00:01:11,920 --> 00:01:15,520
exclude

00:01:12,720 --> 00:01:17,280
those who have the least we're going to

00:01:15,520 --> 00:01:18,880
unpack all of this today but we're also

00:01:17,280 --> 00:01:20,799
going to ask is it possible to

00:01:18,880 --> 00:01:24,479
mainstream ai systems

00:01:20,799 --> 00:01:25,360
which are actually just today i am

00:01:24,479 --> 00:01:27,280
joined by

00:01:25,360 --> 00:01:28,799
a number of fantastic colleagues i'm

00:01:27,280 --> 00:01:32,000
really uh honored

00:01:28,799 --> 00:01:34,400
to be on screen with y'all dr

00:01:32,000 --> 00:01:36,000
sarah roberts is an associate professor

00:01:34,400 --> 00:01:37,840
at the university of california

00:01:36,000 --> 00:01:39,600
los angeles in the department of

00:01:37,840 --> 00:01:40,720
information studies where she serves as

00:01:39,600 --> 00:01:43,119
the co-director

00:01:40,720 --> 00:01:44,159
of the ucla center for critical uh

00:01:43,119 --> 00:01:47,280
internet inquiry

00:01:44,159 --> 00:01:47,840
welcome sierra robson uh the associate

00:01:47,280 --> 00:01:50,240
director

00:01:47,840 --> 00:01:52,159
of the idb wells just data lab at

00:01:50,240 --> 00:01:54,000
princeton university where she guides

00:01:52,159 --> 00:01:56,719
research teams in partnership

00:01:54,000 --> 00:01:58,799
with community organizations to explore

00:01:56,719 --> 00:02:00,880
how data can be retooled for racial

00:01:58,799 --> 00:02:03,040
justice welcome sierra

00:02:00,880 --> 00:02:04,880
julia omono is a lawyer and executive

00:02:03,040 --> 00:02:05,520
director of paris based digital rights

00:02:04,880 --> 00:02:08,640
organization

00:02:05,520 --> 00:02:12,400
international frontiers um

00:02:08,640 --> 00:02:13,920
i made it spanish i'm sorry um julie

00:02:12,400 --> 00:02:16,239
i could have practiced that i actually

00:02:13,920 --> 00:02:18,000
let's go practice your french in the

00:02:16,239 --> 00:02:19,920
bathroom julie's work focuses

00:02:18,000 --> 00:02:21,360
on building bridges and creating

00:02:19,920 --> 00:02:22,640
channels of collaboration between

00:02:21,360 --> 00:02:24,640
various actors

00:02:22,640 --> 00:02:26,560
of the digital space to foster the

00:02:24,640 --> 00:02:28,160
development of an internet that benefits

00:02:26,560 --> 00:02:29,520
everyone all over the world welcome

00:02:28,160 --> 00:02:31,920
julie

00:02:29,520 --> 00:02:33,920
and nigatad is the executive director of

00:02:31,920 --> 00:02:35,840
the digital rights foundation night

00:02:33,920 --> 00:02:37,360
is one of the pioneer women's rights

00:02:35,840 --> 00:02:39,280
activists in pakistan

00:02:37,360 --> 00:02:41,599
and has played a pivotal role in

00:02:39,280 --> 00:02:42,480
defining the cyberspace narrative in the

00:02:41,599 --> 00:02:45,920
country

00:02:42,480 --> 00:02:47,920
welcome and one last thing we're taking

00:02:45,920 --> 00:02:49,120
questions for this panel in real time so

00:02:47,920 --> 00:02:51,760
you can tweet them

00:02:49,120 --> 00:02:52,239
at mozilla with the hashtag dialogues

00:02:51,760 --> 00:02:55,280
and

00:02:52,239 --> 00:02:56,480
debates spelled out so this is a

00:02:55,280 --> 00:02:59,040
conversation

00:02:56,480 --> 00:03:00,720
i'm going to feel the question to to

00:02:59,040 --> 00:03:01,440
each one of our panelists but to the

00:03:00,720 --> 00:03:04,560
other

00:03:01,440 --> 00:03:07,200
panelists after our initial uh

00:03:04,560 --> 00:03:08,319
uh panelist takes a stab at an answer

00:03:07,200 --> 00:03:11,599
please feel free

00:03:08,319 --> 00:03:12,319
to chime in um and i'll move us along by

00:03:11,599 --> 00:03:14,879
taking

00:03:12,319 --> 00:03:15,840
facilitated privilege but um i don't

00:03:14,879 --> 00:03:18,159
want to squash any

00:03:15,840 --> 00:03:20,640
any conversation so please do feel free

00:03:18,159 --> 00:03:24,959
to engage one another

00:03:20,640 --> 00:03:28,640
um so let's start with some context

00:03:24,959 --> 00:03:31,519
this panel is entitled ai and power

00:03:28,640 --> 00:03:32,159
right now who wields power in the realm

00:03:31,519 --> 00:03:34,720
of ai

00:03:32,159 --> 00:03:37,200
and who doesn't negot do you want to

00:03:34,720 --> 00:03:39,519
kick us off

00:03:37,200 --> 00:03:40,400
sure um first of all thank you so much

00:03:39,519 --> 00:03:43,519
for having me

00:03:40,400 --> 00:03:45,360
and having a voice from a place where we

00:03:43,519 --> 00:03:46,560
usually don't have these conversations

00:03:45,360 --> 00:03:49,680
so

00:03:46,560 --> 00:03:52,959
i'm glad that someone from pakistan

00:03:49,680 --> 00:03:55,200
is actually talking about ai and power

00:03:52,959 --> 00:03:56,319
and you asked a question who actually

00:03:55,200 --> 00:03:58,239
has the power

00:03:56,319 --> 00:04:00,879
the one group that doesn't yield any

00:03:58,239 --> 00:04:04,159
power in ai is the

00:04:00,879 --> 00:04:05,200
end user and consumer the average

00:04:04,159 --> 00:04:09,280
internet user

00:04:05,200 --> 00:04:11,840
and netizen um it's the users data that

00:04:09,280 --> 00:04:12,560
that is collected and sold and except

00:04:11,840 --> 00:04:15,120
for the

00:04:12,560 --> 00:04:16,079
global north and a few developing

00:04:15,120 --> 00:04:19,120
countries

00:04:16,079 --> 00:04:20,239
most users do not know what their

00:04:19,120 --> 00:04:22,079
digital rights are

00:04:20,239 --> 00:04:24,639
and you know i'm i'm speaking from the

00:04:22,079 --> 00:04:27,840
perspective and the context of pakistan

00:04:24,639 --> 00:04:30,880
and really are they enshrined and

00:04:27,840 --> 00:04:34,000
protected in our laws or constitution

00:04:30,880 --> 00:04:35,280
so this collected data is fed into that

00:04:34,000 --> 00:04:38,000
databases

00:04:35,280 --> 00:04:39,280
that then targets the users through ai

00:04:38,000 --> 00:04:41,520
internet giants

00:04:39,280 --> 00:04:43,040
governments and social media companies

00:04:41,520 --> 00:04:45,600
become more and more powerful

00:04:43,040 --> 00:04:47,440
and the average user is left with fewer

00:04:45,600 --> 00:04:50,800
and fewer avenues and way to

00:04:47,440 --> 00:04:53,840
exert their power minus the end user

00:04:50,800 --> 00:04:55,199
everyone in the digital ecosystem gains

00:04:53,840 --> 00:04:57,759
power through ai

00:04:55,199 --> 00:04:58,800
um the only difference is that each

00:04:57,759 --> 00:05:00,720
stakeholder

00:04:58,800 --> 00:05:02,400
yields different amounts of power and

00:05:00,720 --> 00:05:04,560
control uh

00:05:02,400 --> 00:05:05,600
social media companies and tech giants

00:05:04,560 --> 00:05:07,919
have spun

00:05:05,600 --> 00:05:09,199
a deeply internet connected in

00:05:07,919 --> 00:05:11,280
interconnected web of

00:05:09,199 --> 00:05:12,960
data sharing that gives them immense

00:05:11,280 --> 00:05:15,199
power over the internet

00:05:12,960 --> 00:05:16,880
and internet users and now with

00:05:15,199 --> 00:05:20,000
governments entering

00:05:16,880 --> 00:05:21,360
uh this equation this power and data is

00:05:20,000 --> 00:05:23,600
also being shared with them

00:05:21,360 --> 00:05:26,800
so in usual circumstances governments

00:05:23,600 --> 00:05:29,840
are already powerful entities however

00:05:26,800 --> 00:05:33,360
when we add this ai into this equation

00:05:29,840 --> 00:05:35,840
their power increases exponentially

00:05:33,360 --> 00:05:38,479
data and online behavior gives the

00:05:35,840 --> 00:05:40,400
government the ability to identify

00:05:38,479 --> 00:05:42,320
how to target individuals and how to

00:05:40,400 --> 00:05:44,320
control narratives online

00:05:42,320 --> 00:05:46,240
and if we go a little further in this

00:05:44,320 --> 00:05:49,360
debate of power i think it's very

00:05:46,240 --> 00:05:52,639
important for us to examine the bias

00:05:49,360 --> 00:05:54,160
in ai and how these biases mainly stem

00:05:52,639 --> 00:05:57,199
from human

00:05:54,160 --> 00:05:58,560
humans inherent biases the models and

00:05:57,199 --> 00:06:01,199
systems we create

00:05:58,560 --> 00:06:03,600
and train are a reflection of ourselves

00:06:01,199 --> 00:06:05,600
and extremely important for us to see

00:06:03,600 --> 00:06:07,120
who is designing and training ai and

00:06:05,600 --> 00:06:09,600
which part of the world

00:06:07,120 --> 00:06:11,919
you know they are designing ai be it a

00:06:09,600 --> 00:06:15,520
tech giant social media company

00:06:11,919 --> 00:06:15,520
or uh within a government

00:06:17,680 --> 00:06:21,039
thank you yeah that anybody else

00:06:19,840 --> 00:06:23,360
want to respond

00:06:21,039 --> 00:06:23,360
um

00:06:24,639 --> 00:06:28,000
i think uh one thing that i want to

00:06:26,319 --> 00:06:30,319
offer up in in

00:06:28,000 --> 00:06:32,080
into the when we're talking about power

00:06:30,319 --> 00:06:34,000
and we're talking about bias and then

00:06:32,080 --> 00:06:37,600
also what it means for just this group

00:06:34,000 --> 00:06:40,400
of folks to be um uh having

00:06:37,600 --> 00:06:41,280
uh the opportunity for us all to speak

00:06:40,400 --> 00:06:44,400
together

00:06:41,280 --> 00:06:47,039
is um um

00:06:44,400 --> 00:06:48,960
oftentimes if if we're the voices who

00:06:47,039 --> 00:06:49,840
have to combat the bias what is it

00:06:48,960 --> 00:06:52,240
actually where are

00:06:49,840 --> 00:06:53,919
where's the original thought and where

00:06:52,240 --> 00:06:54,880
that we'd actually don't have the room

00:06:53,919 --> 00:06:57,680
or the space

00:06:54,880 --> 00:06:58,240
to bring forward in that right so if the

00:06:57,680 --> 00:07:00,880
onus

00:06:58,240 --> 00:07:02,720
is on the folks who are actually bearing

00:07:00,880 --> 00:07:05,840
the brunt of that bias

00:07:02,720 --> 00:07:08,560
to showcase that bias where's the

00:07:05,840 --> 00:07:10,240
invention and the incentive um for that

00:07:08,560 --> 00:07:11,680
to actually come forward and so we're

00:07:10,240 --> 00:07:14,880
losing out twice

00:07:11,680 --> 00:07:18,160
um and and that that that's the impact

00:07:14,880 --> 00:07:18,160
of that bias on everyone

00:07:19,039 --> 00:07:23,919
um and we know that the power imbalance

00:07:22,080 --> 00:07:26,240
can't be fixed simply by

00:07:23,919 --> 00:07:27,759
tweaking code or enacting a single new

00:07:26,240 --> 00:07:29,919
law right power and

00:07:27,759 --> 00:07:32,319
inequalities are baked into the systems

00:07:29,919 --> 00:07:34,240
and the data that powers them

00:07:32,319 --> 00:07:35,440
but i'm curious about how deep the

00:07:34,240 --> 00:07:38,560
problem goes

00:07:35,440 --> 00:07:40,479
um sierra do you think you can um

00:07:38,560 --> 00:07:41,759
shine some light on it the subject for

00:07:40,479 --> 00:07:43,520
us yeah

00:07:41,759 --> 00:07:45,120
absolutely first of all thank you so

00:07:43,520 --> 00:07:46,960
much for including me in this

00:07:45,120 --> 00:07:48,560
conversation i'm so excited to be here

00:07:46,960 --> 00:07:50,879
with you all um

00:07:48,560 --> 00:07:52,319
to get to the question one of the things

00:07:50,879 --> 00:07:55,039
that we have to think about

00:07:52,319 --> 00:07:55,440
is how even those technologies that are

00:07:55,039 --> 00:07:57,280
not

00:07:55,440 --> 00:07:59,759
meant to reinforce power inequalities

00:07:57,280 --> 00:08:01,520
can still end up doing so

00:07:59,759 --> 00:08:04,160
so the tools that are fundamentally

00:08:01,520 --> 00:08:04,400
built to reduce harm can often reinforce

00:08:04,160 --> 00:08:06,560
it

00:08:04,400 --> 00:08:08,400
and one good example of this is

00:08:06,560 --> 00:08:11,599
pre-trial risk assessment tools

00:08:08,400 --> 00:08:14,319
so algorithms judges use

00:08:11,599 --> 00:08:15,039
to determine a defender's uh of a

00:08:14,319 --> 00:08:17,280
defendant's

00:08:15,039 --> 00:08:18,160
risk of reoffense before a sentencing

00:08:17,280 --> 00:08:20,560
hearing

00:08:18,160 --> 00:08:21,440
in many states this was heralded as a

00:08:20,560 --> 00:08:24,479
solution

00:08:21,440 --> 00:08:26,879
to cash bail which many people know has

00:08:24,479 --> 00:08:28,400
lots of issues and often reinforces

00:08:26,879 --> 00:08:30,319
like income inequality wealth and

00:08:28,400 --> 00:08:32,000
equality um

00:08:30,319 --> 00:08:34,399
but they don't understand the ways in

00:08:32,000 --> 00:08:35,519
which these algorithms can also

00:08:34,399 --> 00:08:37,599
reinforce

00:08:35,519 --> 00:08:39,440
all sorts of different things so

00:08:37,599 --> 00:08:41,599
pre-trial risk assessments were proposed

00:08:39,440 --> 00:08:43,839
as this technological solution

00:08:41,599 --> 00:08:45,200
but those who were deemed most risky

00:08:43,839 --> 00:08:47,040
would be put in prison

00:08:45,200 --> 00:08:48,959
until their hearing and everyone else

00:08:47,040 --> 00:08:51,040
would be allowed to to

00:08:48,959 --> 00:08:52,880
await their child but in the first

00:08:51,040 --> 00:08:54,720
iteration many of these tools included

00:08:52,880 --> 00:08:56,800
race races predictive variables many of

00:08:54,720 --> 00:08:58,640
them included zip codes many of them

00:08:56,800 --> 00:08:59,200
included things like do you own a cell

00:08:58,640 --> 00:09:02,560
phone

00:08:59,200 --> 00:09:04,240
or do you pay rent in their variables

00:09:02,560 --> 00:09:04,880
that they use to predict whether or not

00:09:04,240 --> 00:09:08,000
someone would

00:09:04,880 --> 00:09:09,760
be deemed risky and they people

00:09:08,000 --> 00:09:12,000
quickly realized that this produced

00:09:09,760 --> 00:09:14,320
discriminatory results

00:09:12,000 --> 00:09:16,399
so these categories were then excluded

00:09:14,320 --> 00:09:18,480
but then new categories came up as

00:09:16,399 --> 00:09:20,800
proxies for things like race

00:09:18,480 --> 00:09:22,240
and so what does all of this mean in

00:09:20,800 --> 00:09:23,120
short it means that tweaking code

00:09:22,240 --> 00:09:26,240
doesn't

00:09:23,120 --> 00:09:27,839
rid systems of bias or power instead we

00:09:26,240 --> 00:09:30,080
have to really think about what the

00:09:27,839 --> 00:09:31,680
tools are meant to do at their inception

00:09:30,080 --> 00:09:33,040
and technological tools

00:09:31,680 --> 00:09:34,959
will not be able to solve social

00:09:33,040 --> 00:09:36,560
problems on their own and we really

00:09:34,959 --> 00:09:38,640
should stop asking them to do so and

00:09:36,560 --> 00:09:40,959
instead build tools from the ground up

00:09:38,640 --> 00:09:50,880
that are supposed to help the world in

00:09:40,959 --> 00:09:54,000
the ways that we want them to

00:09:50,880 --> 00:09:57,040
i want all of the um participates

00:09:54,000 --> 00:10:01,360
in the conversation i um to

00:09:57,040 --> 00:10:04,640
to um lean into uh

00:10:01,360 --> 00:10:07,200
being being in conversation with one yes

00:10:04,640 --> 00:10:09,040
i just wanted i just wanted to uh double

00:10:07,200 --> 00:10:12,800
down on what sierra

00:10:09,040 --> 00:10:15,440
just said um we we tend to focus a lot

00:10:12,800 --> 00:10:18,399
of the conversation recently around

00:10:15,440 --> 00:10:19,040
ai and its biases on technical solutions

00:10:18,399 --> 00:10:22,000
but we

00:10:19,040 --> 00:10:22,320
actually forget what sierra and what we

00:10:22,000 --> 00:10:25,120
got

00:10:22,320 --> 00:10:26,399
also said previously is that the digital

00:10:25,120 --> 00:10:30,240
world is just a mirror

00:10:26,399 --> 00:10:34,079
of whatever already exists uh offline

00:10:30,240 --> 00:10:36,720
so it's um we shouldn't you know

00:10:34,079 --> 00:10:39,279
stop ourselves from having those very

00:10:36,720 --> 00:10:39,839
serious conversations too on how racist

00:10:39,279 --> 00:10:43,279
our

00:10:39,839 --> 00:10:46,000
societies are on our sexes they are hi

00:10:43,279 --> 00:10:46,480
happy international women's day on how

00:10:46,000 --> 00:10:48,640
um

00:10:46,480 --> 00:10:50,000
you know transphobic they are and all

00:10:48,640 --> 00:10:51,760
the the the

00:10:50,000 --> 00:10:53,120
very negative things that we see

00:10:51,760 --> 00:10:55,680
reproduced online

00:10:53,120 --> 00:10:56,160
so i just wanted to to chime in and say

00:10:55,680 --> 00:10:59,200
that

00:10:56,160 --> 00:11:01,200
in this machine in in this era in which

00:10:59,200 --> 00:11:02,160
a machine is going to basically make

00:11:01,200 --> 00:11:04,480
decisions

00:11:02,160 --> 00:11:06,480
and is making decisions on human

00:11:04,480 --> 00:11:09,200
interaction and human-produced content

00:11:06,480 --> 00:11:10,000
it's really time for us to go beyond the

00:11:09,200 --> 00:11:12,240
machine

00:11:10,000 --> 00:11:14,000
and bring back the human within this

00:11:12,240 --> 00:11:17,680
this conversation it's absolutely

00:11:14,000 --> 00:11:19,839
important sarah i saw your henry's

00:11:17,680 --> 00:11:21,040
yeah i mean i think that's an excellent

00:11:19,839 --> 00:11:22,720
segue and

00:11:21,040 --> 00:11:24,160
i'd love to just pick that one up

00:11:22,720 --> 00:11:25,920
because um

00:11:24,160 --> 00:11:28,880
you know essentially i think it's what

00:11:25,920 --> 00:11:30,240
i'm uh charged with speaking a bit about

00:11:28,880 --> 00:11:34,240
on today's panel

00:11:30,240 --> 00:11:37,120
and that is to actually uh

00:11:34,240 --> 00:11:39,680
on some levels fundamentally ask the

00:11:37,120 --> 00:11:40,720
question what do we mean when we say ai

00:11:39,680 --> 00:11:42,720
anyway right

00:11:40,720 --> 00:11:44,399
so there are all these received notions

00:11:42,720 --> 00:11:46,160
right now within

00:11:44,399 --> 00:11:48,160
um not only within just like the

00:11:46,160 --> 00:11:49,200
zeitgeist you know within our media

00:11:48,160 --> 00:11:51,279
sphere

00:11:49,200 --> 00:11:53,200
in conversation with each other as

00:11:51,279 --> 00:11:56,720
advocates um

00:11:53,200 --> 00:11:58,720
and and off times critics but that

00:11:56,720 --> 00:11:59,839
that question of what is ai what

00:11:58,720 --> 00:12:02,880
constitutes ai

00:11:59,839 --> 00:12:06,480
is in fact um a a

00:12:02,880 --> 00:12:10,160
standing problem space uh

00:12:06,480 --> 00:12:11,760
within computer science okay both in

00:12:10,160 --> 00:12:14,639
you know in the theater in the

00:12:11,760 --> 00:12:17,760
theoretical side of of computer science

00:12:14,639 --> 00:12:21,279
and in its application and so um

00:12:17,760 --> 00:12:23,120
this kind of this dilemma about what

00:12:21,279 --> 00:12:25,760
constitutes

00:12:23,120 --> 00:12:27,760
artificial intelligence was present at

00:12:25,760 --> 00:12:30,959
the birth of the field and it was

00:12:27,760 --> 00:12:34,399
you know in some fundamental papers by

00:12:30,959 --> 00:12:37,760
uh by the key kinds of

00:12:34,399 --> 00:12:40,079
uh computer scientists

00:12:37,760 --> 00:12:41,120
of the day you know they they actually

00:12:40,079 --> 00:12:43,839
stated that

00:12:41,120 --> 00:12:45,760
part of the problem with artificial

00:12:43,839 --> 00:12:47,760
intelligence

00:12:45,760 --> 00:12:48,800
precedes artificial intelligence it's

00:12:47,760 --> 00:12:51,600
the question of

00:12:48,800 --> 00:12:53,600
what constitutes intelligence full stop

00:12:51,600 --> 00:12:55,120
what constitutes intelligence within the

00:12:53,600 --> 00:12:57,440
realm of the human

00:12:55,120 --> 00:12:59,360
and then you know if that problem or if

00:12:57,440 --> 00:13:00,320
that if that definition is somewhat

00:12:59,360 --> 00:13:03,360
fuzzy

00:13:00,320 --> 00:13:05,440
unclear contested uh

00:13:03,360 --> 00:13:07,200
then what does it mean therefore that

00:13:05,440 --> 00:13:11,200
this kind of nebulous

00:13:07,200 --> 00:13:14,720
notion is picked up and um

00:13:11,200 --> 00:13:16,560
by by a definition

00:13:14,720 --> 00:13:18,560
abstracted and then put into

00:13:16,560 --> 00:13:21,920
implementation this was

00:13:18,560 --> 00:13:24,639
this was a an issue for foreseen uh

00:13:21,920 --> 00:13:26,399
by the uh by some of the uh the the

00:13:24,639 --> 00:13:29,040
founders of this field

00:13:26,399 --> 00:13:29,440
and all the way up till till today we

00:13:29,040 --> 00:13:32,880
have

00:13:29,440 --> 00:13:36,160
um uh you know very important

00:13:32,880 --> 00:13:39,920
uh kind of industry facing

00:13:36,160 --> 00:13:42,480
uh bodies and and uh

00:13:39,920 --> 00:13:44,079
uh thinkers in the form of you know just

00:13:42,480 --> 00:13:45,199
the one that's on my mind is the

00:13:44,079 --> 00:13:48,480
o'reilly group

00:13:45,199 --> 00:13:50,560
um kind of still adequately acknowledge

00:13:48,480 --> 00:13:52,240
you know acknowledging still adequately

00:13:50,560 --> 00:13:56,399
trying to define

00:13:52,240 --> 00:14:00,000
uh what what this is and you know again

00:13:56,399 --> 00:14:00,639
drawing down on this issue of what ai is

00:14:00,000 --> 00:14:03,120
they say

00:14:00,639 --> 00:14:05,120
not only is it difficult to define it's

00:14:03,120 --> 00:14:06,480
actually impossible to do especially

00:14:05,120 --> 00:14:08,880
without falling into

00:14:06,480 --> 00:14:10,560
you know tautologies and in a kind of

00:14:08,880 --> 00:14:13,760
like these self-referential

00:14:10,560 --> 00:14:17,760
um uh intractable uh

00:14:13,760 --> 00:14:20,000
circles so i i think it's important as

00:14:17,760 --> 00:14:22,160
some of my my colleagues have already

00:14:20,000 --> 00:14:23,279
said that we step you know sierra was

00:14:22,160 --> 00:14:26,399
just saying we can't

00:14:23,279 --> 00:14:28,800
um critique the ai piece if we don't

00:14:26,399 --> 00:14:30,560
really understand what the systems are

00:14:28,800 --> 00:14:33,120
that are in play and what the

00:14:30,560 --> 00:14:34,399
fundamental social issues are that are

00:14:33,120 --> 00:14:37,920
feeding into that

00:14:34,399 --> 00:14:41,680
whether it's overtly sometimes

00:14:37,920 --> 00:14:43,839
but more importantly and more worrisome

00:14:41,680 --> 00:14:45,519
in an insidious fashion because we don't

00:14:43,839 --> 00:14:47,120
we don't even know how to adequately

00:14:45,519 --> 00:14:49,519
address these issues

00:14:47,120 --> 00:14:51,040
uh and attend to them as a as a social

00:14:49,519 --> 00:14:52,160
collective there are many of us who do

00:14:51,040 --> 00:14:54,959
work on them right

00:14:52,160 --> 00:14:57,199
but we we're in a in a fight around that

00:14:54,959 --> 00:14:59,839
in a fight to constantly prove

00:14:57,199 --> 00:15:00,880
um that some of these uh social forces

00:14:59,839 --> 00:15:02,959
are at play

00:15:00,880 --> 00:15:05,120
and are causing harm now that gets

00:15:02,959 --> 00:15:07,279
picked up and packaged up into ai

00:15:05,120 --> 00:15:08,160
and pushed out and i guess one of the

00:15:07,279 --> 00:15:10,720
greatest

00:15:08,160 --> 00:15:11,440
concerns there is we take these already

00:15:10,720 --> 00:15:14,959
um

00:15:11,440 --> 00:15:18,959
very hard to demonstrate

00:15:14,959 --> 00:15:20,320
systems of power and we create a huge

00:15:18,959 --> 00:15:24,079
layer of opacity

00:15:20,320 --> 00:15:26,240
around them and then we further

00:15:24,079 --> 00:15:28,320
automate them and give them incredible

00:15:26,240 --> 00:15:30,639
power to be reproduced

00:15:28,320 --> 00:15:32,079
and so that's where we sit with ai and

00:15:30,639 --> 00:15:33,839
the last comment i'll make

00:15:32,079 --> 00:15:36,240
about my own work and my own

00:15:33,839 --> 00:15:39,199
intervention in thinking in the space

00:15:36,240 --> 00:15:40,959
is simply um within the realm of

00:15:39,199 --> 00:15:42,399
commercial content moderation where we

00:15:40,959 --> 00:15:44,560
have heard for years

00:15:42,399 --> 00:15:46,000
uh from the firms and from others that

00:15:44,560 --> 00:15:49,600
kind of the way out

00:15:46,000 --> 00:15:51,600
of the horror of doing this work and its

00:15:49,600 --> 00:15:53,120
psychological consequence will be

00:15:51,600 --> 00:15:55,759
deliverance via

00:15:53,120 --> 00:15:57,040
ai and other kinds of automated content

00:15:55,759 --> 00:15:59,040
moderation tools

00:15:57,040 --> 00:16:00,480
but again i've just you know i hopefully

00:15:59,040 --> 00:16:02,160
convinced everyone that what we're

00:16:00,480 --> 00:16:03,199
dealing with is a very blunt kind of

00:16:02,160 --> 00:16:06,720
instrument

00:16:03,199 --> 00:16:07,680
that is in fact incredibly unintelligent

00:16:06,720 --> 00:16:10,240
in many cases

00:16:07,680 --> 00:16:12,079
it will do exactly what it's programmed

00:16:10,240 --> 00:16:14,800
to do which is often

00:16:12,079 --> 00:16:16,399
going to create more and more and new

00:16:14,800 --> 00:16:17,440
and different kind of errors they might

00:16:16,399 --> 00:16:19,279
be different

00:16:17,440 --> 00:16:21,519
um they might be errors that humans

00:16:19,279 --> 00:16:23,920
wouldn't themselves make in fact

00:16:21,519 --> 00:16:26,560
and so um you know we have a lot of

00:16:23,920 --> 00:16:28,880
false positives coming into play here

00:16:26,560 --> 00:16:30,320
and going back to the claim that humans

00:16:28,880 --> 00:16:32,160
would then be delivered from content

00:16:30,320 --> 00:16:34,160
moderation what i've actually been

00:16:32,160 --> 00:16:35,199
tracking for some time is the ways in

00:16:34,160 --> 00:16:37,199
which um

00:16:35,199 --> 00:16:38,320
ai and other kinds of automated content

00:16:37,199 --> 00:16:40,560
moderation tools

00:16:38,320 --> 00:16:42,639
actually expand the need for human

00:16:40,560 --> 00:16:44,720
intervention because now we need

00:16:42,639 --> 00:16:46,240
not only we need the creation of the

00:16:44,720 --> 00:16:48,639
tools of course

00:16:46,240 --> 00:16:49,519
on the input side but on the output side

00:16:48,639 --> 00:16:53,199
we now need

00:16:49,519 --> 00:16:57,440
more and more humans to vet or even undo

00:16:53,199 --> 00:16:59,519
errors caused by uh by ai moderation

00:16:57,440 --> 00:17:01,360
that's in a best case scenario in in the

00:16:59,519 --> 00:17:04,160
worst case scenario the errors aren't

00:17:01,360 --> 00:17:05,280
undone and all kinds of false positives

00:17:04,160 --> 00:17:07,360
go forward or

00:17:05,280 --> 00:17:09,199
decisions are just simply made that we

00:17:07,360 --> 00:17:12,640
can't understand or even know

00:17:09,199 --> 00:17:15,679
uh are being taken thanks

00:17:12,640 --> 00:17:17,679
i just wanna let me oh sarah go ahead

00:17:15,679 --> 00:17:19,280
oh i just wanted to echo what sarah was

00:17:17,679 --> 00:17:21,520
saying i really appreciate your

00:17:19,280 --> 00:17:22,880
your emphasis on the definition of what

00:17:21,520 --> 00:17:24,160
ai actually is and

00:17:22,880 --> 00:17:25,919
it just brought to mind that the

00:17:24,160 --> 00:17:28,640
definition of what is fair

00:17:25,919 --> 00:17:29,840
is also a contested issue and something

00:17:28,640 --> 00:17:32,160
that we should think

00:17:29,840 --> 00:17:33,440
really critically about i mean computer

00:17:32,160 --> 00:17:35,360
scientists have been thinking about the

00:17:33,440 --> 00:17:37,280
definition of fair for algorithms for

00:17:35,360 --> 00:17:39,200
quite some time and the short answer is

00:17:37,280 --> 00:17:41,200
that there is no answer yet

00:17:39,200 --> 00:17:43,120
but also to remember that what is fair

00:17:41,200 --> 00:17:46,160
is not necessarily just

00:17:43,120 --> 00:17:47,280
so it's not totally clear that making

00:17:46,160 --> 00:17:49,919
facial recognition

00:17:47,280 --> 00:17:50,720
better at identifying black faces is a

00:17:49,919 --> 00:17:53,360
good thing

00:17:50,720 --> 00:17:54,240
for the world it's not totally clear

00:17:53,360 --> 00:17:56,880
that you want

00:17:54,240 --> 00:17:58,559
police to be able to better identify

00:17:56,880 --> 00:18:00,559
people in black neighborhoods

00:17:58,559 --> 00:18:03,200
it's not totally clear that you want ice

00:18:00,559 --> 00:18:05,840
to be able to better identify

00:18:03,200 --> 00:18:06,400
undocumented immigrants all of these

00:18:05,840 --> 00:18:07,760
things

00:18:06,400 --> 00:18:09,600
kind of come up in the definition of

00:18:07,760 --> 00:18:11,120
fairness and and so i think it's really

00:18:09,600 --> 00:18:12,960
important that we hone in on what we

00:18:11,120 --> 00:18:13,679
actually need when we are talking about

00:18:12,960 --> 00:18:15,360
fairness

00:18:13,679 --> 00:18:17,360
what we actually want to prioritize in

00:18:15,360 --> 00:18:18,630
our conversations about ai

00:18:17,360 --> 00:18:21,200
and power

00:18:18,630 --> 00:18:23,440
[Music]

00:18:21,200 --> 00:18:25,120
thank you i yeah i really appreciate

00:18:23,440 --> 00:18:27,360
that and that and also the other

00:18:25,120 --> 00:18:28,160
this idea that it's not static right

00:18:27,360 --> 00:18:30,080
that it's

00:18:28,160 --> 00:18:31,200
um in the in kind of enough in the same

00:18:30,080 --> 00:18:34,559
way that that

00:18:31,200 --> 00:18:37,200
um uh the shifting of power is

00:18:34,559 --> 00:18:38,080
an ever-evolving possibility the idea

00:18:37,200 --> 00:18:40,559
that even that

00:18:38,080 --> 00:18:43,039
the idea of the notion of intelligence

00:18:40,559 --> 00:18:45,440
is not fixed um and that it's

00:18:43,039 --> 00:18:46,160
that there's a cultural context uh or

00:18:45,440 --> 00:18:49,120
multiple

00:18:46,160 --> 00:18:49,840
cultural contexts around what what's

00:18:49,120 --> 00:18:52,880
getting deemed

00:18:49,840 --> 00:18:56,720
intelligent and and um

00:18:52,880 --> 00:18:59,360
the outputs and the outcomes are as uh

00:18:56,720 --> 00:19:00,000
are leaning into all of those systemic

00:18:59,360 --> 00:19:02,320
notions

00:19:00,000 --> 00:19:03,840
as as anything else i i really

00:19:02,320 --> 00:19:06,400
appreciate that a lot

00:19:03,840 --> 00:19:06,960
um i mean the other the other piece of

00:19:06,400 --> 00:19:09,039
it

00:19:06,960 --> 00:19:10,640
that certainly in in in the context of

00:19:09,039 --> 00:19:13,200
this conversation right is that much of

00:19:10,640 --> 00:19:16,640
the ai technology is actually tested

00:19:13,200 --> 00:19:18,000
and made uh or made in the western world

00:19:16,640 --> 00:19:20,960
and beta tested elsewhere

00:19:18,000 --> 00:19:23,280
and um there are invasive ai systems

00:19:20,960 --> 00:19:25,520
deployed at refugee camps

00:19:23,280 --> 00:19:26,480
uh cambridge analytica meddled in

00:19:25,520 --> 00:19:29,200
african elections

00:19:26,480 --> 00:19:29,760
long before the u.s election right and

00:19:29,200 --> 00:19:32,160
so

00:19:29,760 --> 00:19:33,440
um so what can be done are there

00:19:32,160 --> 00:19:38,559
movements pushing back

00:19:33,440 --> 00:19:41,600
against this behavior

00:19:38,559 --> 00:19:44,720
i i'm happy i'm happy to jump in uh

00:19:41,600 --> 00:19:45,440
on this one and uh for that if you allow

00:19:44,720 --> 00:19:47,919
me

00:19:45,440 --> 00:19:49,520
i'm just gonna share uh instead of

00:19:47,919 --> 00:19:51,760
having a beautiful background today

00:19:49,520 --> 00:19:54,320
because zoom doesn't recognize

00:19:51,760 --> 00:19:54,799
the features of my face i'm just gonna

00:19:54,320 --> 00:19:58,480
share

00:19:54,799 --> 00:20:00,160
i hope you can see this um this answer

00:19:58,480 --> 00:20:03,280
that i drafted

00:20:00,160 --> 00:20:06,400
um regarding your your your your

00:20:03,280 --> 00:20:09,600
question which is what is being done to

00:20:06,400 --> 00:20:12,640
uh basically prevent

00:20:09,600 --> 00:20:15,679
uh all the bad actors from

00:20:12,640 --> 00:20:18,480
testing all this and also the

00:20:15,679 --> 00:20:19,200
good faith ones are honest on testing to

00:20:18,480 --> 00:20:21,520
test from

00:20:19,200 --> 00:20:22,400
to test all these horrible things on

00:20:21,520 --> 00:20:25,200
users

00:20:22,400 --> 00:20:26,799
and end users and consumers like niga

00:20:25,200 --> 00:20:29,440
said earlier who have

00:20:26,799 --> 00:20:30,480
no absolutely no say into this

00:20:29,440 --> 00:20:33,039
conversation

00:20:30,480 --> 00:20:34,320
and for that i'd like to borrow a term

00:20:33,039 --> 00:20:36,960
that i read

00:20:34,320 --> 00:20:39,520
in a a recent publication called

00:20:36,960 --> 00:20:42,799
philanthropy and digital civil society

00:20:39,520 --> 00:20:43,760
blueprint 2021 it was it's uh it was

00:20:42,799 --> 00:20:46,799
written by

00:20:43,760 --> 00:20:49,280
dr lucy benholtz from the digital civil

00:20:46,799 --> 00:20:52,559
society lab at stanford university

00:20:49,280 --> 00:20:54,640
and it's basically uh i call it a bible

00:20:52,559 --> 00:20:56,640
for all that's related if you want to

00:20:54,640 --> 00:20:58,400
know everything about philanthropy and

00:20:56,640 --> 00:21:00,400
digital civil society

00:20:58,400 --> 00:21:02,880
at this year this is definitely one

00:21:00,400 --> 00:21:07,120
place you should you should go to

00:21:02,880 --> 00:21:09,520
and in that in that bible um

00:21:07,120 --> 00:21:10,320
there was this word that was used global

00:21:09,520 --> 00:21:13,039
majority

00:21:10,320 --> 00:21:14,840
i hate the term honestly global south

00:21:13,039 --> 00:21:18,320
global north they absolutely mean

00:21:14,840 --> 00:21:19,360
nothing um but when we talk about global

00:21:18,320 --> 00:21:22,480
majority

00:21:19,360 --> 00:21:25,200
we we clearly understand

00:21:22,480 --> 00:21:26,640
that a majority of those illegals who

00:21:25,200 --> 00:21:30,240
live on this earth

00:21:26,640 --> 00:21:33,760
are actually um you know

00:21:30,240 --> 00:21:37,360
the well guinea pigs the uh

00:21:33,760 --> 00:21:37,919
they they're just honestly victims of

00:21:37,360 --> 00:21:40,799
whatever

00:21:37,919 --> 00:21:43,200
is being decided elsewhere without ever

00:21:40,799 --> 00:21:45,919
being consulted and ever being

00:21:43,200 --> 00:21:46,880
uh part of the the conversation but at

00:21:45,919 --> 00:21:50,320
the same time

00:21:46,880 --> 00:21:52,559
this global majority is also our future

00:21:50,320 --> 00:21:54,640
they tell us what's going to happen to

00:21:52,559 --> 00:21:56,000
us here in the global minority i say

00:21:54,640 --> 00:21:58,159
here because i live in

00:21:56,000 --> 00:21:59,360
the so-called global north uh but i'm

00:21:58,159 --> 00:22:02,720
i'm cameroonian

00:21:59,360 --> 00:22:04,640
um and i i've seen in my work

00:22:02,720 --> 00:22:06,559
at antoinette some frontier internet

00:22:04,640 --> 00:22:09,679
without words also in english

00:22:06,559 --> 00:22:12,799
we have seen how how uh

00:22:09,679 --> 00:22:13,840
you know how quick you can understand

00:22:12,799 --> 00:22:15,679
what's going to happen

00:22:13,840 --> 00:22:17,919
when you look at what's happening in

00:22:15,679 --> 00:22:20,000
places where actually nobody usually

00:22:17,919 --> 00:22:21,919
cares and specifically the media

00:22:20,000 --> 00:22:23,039
i'll give you one example when we

00:22:21,919 --> 00:22:25,919
started to talk about

00:22:23,039 --> 00:22:27,039
trolls in following in the aftermath of

00:22:25,919 --> 00:22:29,840
the 2016

00:22:27,039 --> 00:22:30,240
u.s presidential election we actually

00:22:29,840 --> 00:22:31,840
knew

00:22:30,240 --> 00:22:33,600
that this was i mean we didn't know

00:22:31,840 --> 00:22:37,520
these were trolls but we

00:22:33,600 --> 00:22:40,960
we knew that we had seen those automated

00:22:37,520 --> 00:22:44,640
automatically um you know generated

00:22:40,960 --> 00:22:46,640
publication tweets uh back in 2010

00:22:44,640 --> 00:22:47,679
when we're looking at what was happening

00:22:46,640 --> 00:22:50,880
in a western

00:22:47,679 --> 00:22:54,320
african country called gabon in which

00:22:50,880 --> 00:22:58,159
there were you know there were

00:22:54,320 --> 00:23:00,400
repression following um uprising of the

00:22:58,159 --> 00:23:01,039
population in the aftermath of the arab

00:23:00,400 --> 00:23:04,000
spring

00:23:01,039 --> 00:23:04,880
and to counter the narrative around what

00:23:04,000 --> 00:23:06,400
was happening

00:23:04,880 --> 00:23:08,240
and to counter the fact that civil

00:23:06,400 --> 00:23:10,880
society organization citizens have

00:23:08,240 --> 00:23:12,320
found a space on twitter and on facebook

00:23:10,880 --> 00:23:15,520
twitter particularly

00:23:12,320 --> 00:23:17,440
to tell what was really happening in a

00:23:15,520 --> 00:23:18,880
media environment that was completely

00:23:17,440 --> 00:23:22,240
locked for them

00:23:18,880 --> 00:23:25,440
um well the government chose

00:23:22,240 --> 00:23:26,320
to buy people well not people bots

00:23:25,440 --> 00:23:28,000
obviously

00:23:26,320 --> 00:23:29,440
i mean we started seeing people from

00:23:28,000 --> 00:23:31,039
india or from turkey

00:23:29,440 --> 00:23:33,360
tweeting about what was happening in

00:23:31,039 --> 00:23:35,440
gabon while not being there

00:23:33,360 --> 00:23:36,720
this was weird but at the time honestly

00:23:35,440 --> 00:23:39,520
we didn't know

00:23:36,720 --> 00:23:40,320
that this was this was a this was a

00:23:39,520 --> 00:23:43,919
troll or

00:23:40,320 --> 00:23:46,960
you know automated uh propaganda

00:23:43,919 --> 00:23:48,559
so why am i saying that global majority

00:23:46,960 --> 00:23:50,480
and global minority

00:23:48,559 --> 00:23:52,640
more than ever need to collaborate it's

00:23:50,480 --> 00:23:55,919
because we have the knowledge

00:23:52,640 --> 00:23:58,000
in western big academic institutions

00:23:55,919 --> 00:23:58,960
in western big human rights

00:23:58,000 --> 00:24:01,520
organizations

00:23:58,960 --> 00:24:03,279
but in the global majority they have the

00:24:01,520 --> 00:24:05,440
experience in their flesh

00:24:03,279 --> 00:24:06,720
but they cannot name that experience

00:24:05,440 --> 00:24:07,440
they cannot name that what they're

00:24:06,720 --> 00:24:10,240
seeing and what

00:24:07,440 --> 00:24:12,400
they're uh being victims of is wrong

00:24:10,240 --> 00:24:15,840
we're talking about facial recognition

00:24:12,400 --> 00:24:18,480
recently reports surveys that in in

00:24:15,840 --> 00:24:20,640
in countries like uganda facial

00:24:18,480 --> 00:24:24,559
recognition is being used to arrest

00:24:20,640 --> 00:24:27,039
um you know uh democrat democratic

00:24:24,559 --> 00:24:27,679
demonstrators that that's absolutely

00:24:27,039 --> 00:24:29,840
worrying

00:24:27,679 --> 00:24:31,200
we're also we're also you talked about

00:24:29,840 --> 00:24:33,679
refugees of course

00:24:31,200 --> 00:24:35,600
refugees this is a big problem in my

00:24:33,679 --> 00:24:38,480
country cameron there's a huge

00:24:35,600 --> 00:24:39,679
refugee well several huge refugee crisis

00:24:38,480 --> 00:24:42,080
at the same time

00:24:39,679 --> 00:24:43,840
and we recently learned that the

00:24:42,080 --> 00:24:47,039
government accepted to sign

00:24:43,840 --> 00:24:50,720
with them i think it was the unhcr

00:24:47,039 --> 00:24:53,760
at least a big u.n refugee institution

00:24:50,720 --> 00:24:55,440
they accepted to sign a basically a

00:24:53,760 --> 00:24:56,960
program that would allow them to

00:24:55,440 --> 00:24:59,520
digitally

00:24:56,960 --> 00:25:00,240
trace all the refugees that come into

00:24:59,520 --> 00:25:02,400
cameroon

00:25:00,240 --> 00:25:04,080
it might sound appealing especially for

00:25:02,400 --> 00:25:05,360
a cameroon a country like cameroon

00:25:04,080 --> 00:25:07,679
that's already struggling

00:25:05,360 --> 00:25:09,200
with many other issues and you know

00:25:07,679 --> 00:25:11,520
basically doesn't have the money

00:25:09,200 --> 00:25:12,640
to handle all these new refugees and all

00:25:11,520 --> 00:25:15,679
these new peoples

00:25:12,640 --> 00:25:18,080
but what are the problems that will come

00:25:15,679 --> 00:25:18,799
after that when you start tracing the

00:25:18,080 --> 00:25:20,960
weakest

00:25:18,799 --> 00:25:22,640
what are you going to do later on to

00:25:20,960 --> 00:25:24,000
those once you have tested when you want

00:25:22,640 --> 00:25:26,480
to have perfected

00:25:24,000 --> 00:25:27,279
your ability to trace every single

00:25:26,480 --> 00:25:29,120
moment of

00:25:27,279 --> 00:25:30,640
the life of an individual what are you

00:25:29,120 --> 00:25:32,960
gonna do uh with

00:25:30,640 --> 00:25:33,760
those were for now living in a more

00:25:32,960 --> 00:25:35,360
liberal

00:25:33,760 --> 00:25:37,120
in a more liberal world and in a

00:25:35,360 --> 00:25:39,919
peaceful world so

00:25:37,120 --> 00:25:40,480
um this is this has been the core of my

00:25:39,919 --> 00:25:44,480
work

00:25:40,480 --> 00:25:46,720
uh since you know working in this space

00:25:44,480 --> 00:25:48,559
making sure that we collaborate as much

00:25:46,720 --> 00:25:49,760
as possible because a lot of things that

00:25:48,559 --> 00:25:52,880
we can tell you

00:25:49,760 --> 00:25:54,000
and i'm not not just africans asians

00:25:52,880 --> 00:25:56,400
latin americans

00:25:54,000 --> 00:25:58,000
but also trans communities lgbt

00:25:56,400 --> 00:26:00,320
communities in general

00:25:58,000 --> 00:26:01,679
they they we can tell you things but we

00:26:00,320 --> 00:26:03,520
need to collaborate

00:26:01,679 --> 00:26:05,039
uh with academics and with big

00:26:03,520 --> 00:26:07,200
institutions not in

00:26:05,039 --> 00:26:08,480
an extractive way and i'm insisting on

00:26:07,200 --> 00:26:10,720
that but really

00:26:08,480 --> 00:26:12,559
collaborate respecting you know the

00:26:10,720 --> 00:26:14,000
expertise of each other it's not because

00:26:12,559 --> 00:26:16,080
it's an experience that it's worth

00:26:14,000 --> 00:26:17,520
less that's a false assumption that is

00:26:16,080 --> 00:26:20,400
plaguing the industry

00:26:17,520 --> 00:26:22,880
um but collaborate on an equal level

00:26:20,400 --> 00:26:25,440
because what i'm bringing to the table

00:26:22,880 --> 00:26:27,120
is absolutely necessary for you to make

00:26:25,440 --> 00:26:30,480
the point with your theoretical

00:26:27,120 --> 00:26:32,640
uh you know frame so yeah that's what i

00:26:30,480 --> 00:26:35,360
i wanted to share with you today and i'm

00:26:32,640 --> 00:26:38,400
going to stop sharing

00:26:35,360 --> 00:26:40,480
thank you um sarah i heard

00:26:38,400 --> 00:26:42,080
i saw your um hand raised and i want to

00:26:40,480 --> 00:26:44,320
also um prompt

00:26:42,080 --> 00:26:45,440
um the other folks in the in the

00:26:44,320 --> 00:26:49,679
conversation

00:26:45,440 --> 00:26:52,000
um i i think the

00:26:49,679 --> 00:26:53,679
that presumption of of who has what to

00:26:52,000 --> 00:26:56,400
say and even the terminology

00:26:53,679 --> 00:26:58,240
around majority and minority sierra that

00:26:56,400 --> 00:26:59,039
reminds me too about the distinction

00:26:58,240 --> 00:27:02,400
between

00:26:59,039 --> 00:27:05,200
fair and just and then they got

00:27:02,400 --> 00:27:06,400
the point you uh were making originally

00:27:05,200 --> 00:27:09,679
in terms of

00:27:06,400 --> 00:27:12,240
who's who's articulating um uh

00:27:09,679 --> 00:27:14,080
their power and who has agency under the

00:27:12,240 --> 00:27:14,640
current paradigms i mean i think that we

00:27:14,080 --> 00:27:16,640
could

00:27:14,640 --> 00:27:18,480
kind of flip the script here and and

00:27:16,640 --> 00:27:20,799
break the conversation

00:27:18,480 --> 00:27:21,679
open a little bit about around around

00:27:20,799 --> 00:27:24,320
all of that so

00:27:21,679 --> 00:27:26,480
so sarah you had your hand open but but

00:27:24,320 --> 00:27:28,720
no i'm gonna call on the rest of you uh

00:27:26,480 --> 00:27:29,520
yeah right afterwards yeah i'm gonna

00:27:28,720 --> 00:27:32,080
toss the mic

00:27:29,520 --> 00:27:33,600
to my my peers in just one second i just

00:27:32,080 --> 00:27:34,080
have such like a short-term memory

00:27:33,600 --> 00:27:38,080
problem

00:27:34,080 --> 00:27:40,240
that i wanna um i wanna just uh raise up

00:27:38,080 --> 00:27:42,000
uh plus one you know i get on these

00:27:40,240 --> 00:27:42,640
panels and i freak out with excitement

00:27:42,000 --> 00:27:45,279
because

00:27:42,640 --> 00:27:46,559
what people are saying is so on point

00:27:45,279 --> 00:27:48,960
and powerful

00:27:46,559 --> 00:27:51,039
and so julie i think what you just said

00:27:48,960 --> 00:27:54,000
about terminology number one

00:27:51,039 --> 00:27:56,320
and about you know this rel the

00:27:54,000 --> 00:27:58,080
problematic relationship historically

00:27:56,320 --> 00:27:59,440
and in this contemporary moment with

00:27:58,080 --> 00:28:02,159
academia

00:27:59,440 --> 00:28:04,080
and its relationship to industry and its

00:28:02,159 --> 00:28:07,120
extractive relationship

00:28:04,080 --> 00:28:10,240
on communities is also key here

00:28:07,120 --> 00:28:13,840
to kind of where we might break in

00:28:10,240 --> 00:28:14,240
and and do repair work and do new kinds

00:28:13,840 --> 00:28:17,440
of

00:28:14,240 --> 00:28:18,960
paradigm shifting um to change exactly

00:28:17,440 --> 00:28:20,640
what you were talking about so

00:28:18,960 --> 00:28:22,159
first of all i just wanted to share out

00:28:20,640 --> 00:28:25,360
on the terminology piece

00:28:22,159 --> 00:28:28,159
that i once read a a um

00:28:25,360 --> 00:28:30,159
just within another piece by a civil

00:28:28,159 --> 00:28:33,200
society advocate from uh

00:28:30,159 --> 00:28:35,200
from india who was speaking about

00:28:33,200 --> 00:28:36,559
you know he refused to use those uh

00:28:35,200 --> 00:28:38,799
kinds of um

00:28:36,559 --> 00:28:39,840
received terms as well and he so he was

00:28:38,799 --> 00:28:42,080
talking about the over

00:28:39,840 --> 00:28:42,960
developed world and i've always loved

00:28:42,080 --> 00:28:45,919
that and so

00:28:42,960 --> 00:28:47,840
um i kind of try to use that when i can

00:28:45,919 --> 00:28:49,520
and i also think about uh

00:28:47,840 --> 00:28:51,360
what we're actually talking about is

00:28:49,520 --> 00:28:54,240
resources and and

00:28:51,360 --> 00:28:56,080
economic resources primarily and so i

00:28:54,240 --> 00:28:59,360
think about it in terms of

00:28:56,080 --> 00:28:59,840
um the the economic overly resourced

00:28:59,360 --> 00:29:02,240
world

00:28:59,840 --> 00:29:03,200
you know like like jumping off on that

00:29:02,240 --> 00:29:05,919
point

00:29:03,200 --> 00:29:07,760
versus um the inappropriately

00:29:05,919 --> 00:29:10,159
economically under-resourced

00:29:07,760 --> 00:29:11,360
part parts of the world so i i just

00:29:10,159 --> 00:29:13,120
throwing that out there as a

00:29:11,360 --> 00:29:14,480
as a possibility and is something that

00:29:13,120 --> 00:29:16,480
that i think about

00:29:14,480 --> 00:29:17,600
um in terms of your you know the

00:29:16,480 --> 00:29:20,880
comments about

00:29:17,600 --> 00:29:23,279
um who get who gets to create

00:29:20,880 --> 00:29:24,159
laboratories on other people and treat

00:29:23,279 --> 00:29:27,360
other

00:29:24,159 --> 00:29:27,919
places and and and uh peoples as guinea

00:29:27,360 --> 00:29:30,799
pigs

00:29:27,919 --> 00:29:31,200
you know we this predates all of this

00:29:30,799 --> 00:29:33,600
this

00:29:31,200 --> 00:29:35,760
uh computational business i always think

00:29:33,600 --> 00:29:37,600
about from my american contacts

00:29:35,760 --> 00:29:38,880
the interference of the american

00:29:37,600 --> 00:29:42,480
government uh

00:29:38,880 --> 00:29:46,080
in in south america and in places like

00:29:42,480 --> 00:29:48,000
chile and um you know argentina

00:29:46,080 --> 00:29:49,200
and brazil and all of these countries

00:29:48,000 --> 00:29:52,640
that were meddled with

00:29:49,200 --> 00:29:55,679
to um to murderous ends and

00:29:52,640 --> 00:29:59,200
this is a tradition in place uh

00:29:55,679 --> 00:30:02,960
predating ai but certainly in place

00:29:59,200 --> 00:30:05,200
around uh uh picking places in the world

00:30:02,960 --> 00:30:07,360
and then going and doing stuff

00:30:05,200 --> 00:30:09,679
uh upon them that will then come home to

00:30:07,360 --> 00:30:12,640
roost uh in the american context

00:30:09,679 --> 00:30:13,440
uh and then um the last thing i wanted

00:30:12,640 --> 00:30:16,320
to say

00:30:13,440 --> 00:30:16,720
uh before i before i silence myself is

00:30:16,320 --> 00:30:19,760
uh

00:30:16,720 --> 00:30:22,880
the the piece about uh

00:30:19,760 --> 00:30:25,600
what you said so accurately

00:30:22,880 --> 00:30:27,200
about who actually has special insight

00:30:25,600 --> 00:30:30,720
into these problems

00:30:27,200 --> 00:30:32,559
who is um most harmed

00:30:30,720 --> 00:30:34,240
are the people who have the the

00:30:32,559 --> 00:30:36,000
solutions or at least the

00:30:34,240 --> 00:30:38,480
the knowledge to put it into the

00:30:36,000 --> 00:30:40,640
pipeline to talk about interventions

00:30:38,480 --> 00:30:42,320
and it was with that in mind that my

00:30:40,640 --> 00:30:45,600
colleague and collaborator

00:30:42,320 --> 00:30:47,760
and dear friend dr sofia noble and i

00:30:45,600 --> 00:30:49,600
came up with the ucla center for

00:30:47,760 --> 00:30:53,279
critical internet inquiry where we

00:30:49,600 --> 00:30:56,159
put forth and put forward and put first

00:30:53,279 --> 00:30:57,919
uh these kinds of uh voices with all of

00:30:56,159 --> 00:31:01,200
the expertise they have

00:30:57,919 --> 00:31:01,679
because we ourselves sofia as a black

00:31:01,200 --> 00:31:05,200
woman

00:31:01,679 --> 00:31:07,919
myself as a gay woman we understand

00:31:05,200 --> 00:31:09,679
what it's like to have the knowledge and

00:31:07,919 --> 00:31:11,200
to frankly be the canaries in the coal

00:31:09,679 --> 00:31:13,360
mine we're always trying to

00:31:11,200 --> 00:31:14,880
bang on the window and and tell everyone

00:31:13,360 --> 00:31:15,840
and so that's what we're trying to

00:31:14,880 --> 00:31:18,159
actually

00:31:15,840 --> 00:31:19,919
uh create a beacon for and to create a

00:31:18,159 --> 00:31:22,399
large enough

00:31:19,919 --> 00:31:23,919
critical mass of people to do some of

00:31:22,399 --> 00:31:25,200
that within academia

00:31:23,919 --> 00:31:27,120
specifically

00:31:25,200 --> 00:31:29,200
[Music]

00:31:27,120 --> 00:31:30,399
i just want to acknowledge that um some

00:31:29,200 --> 00:31:33,840
of our internet is

00:31:30,399 --> 00:31:34,320
is um uh uh more robust than others so

00:31:33,840 --> 00:31:36,320


00:31:34,320 --> 00:31:37,360
is going to go on audio um are you

00:31:36,320 --> 00:31:40,320
able to hear us

00:31:37,360 --> 00:31:40,320
uh pretty well now

00:31:40,799 --> 00:31:46,640
yes i can um i just wanted to add um

00:31:44,320 --> 00:31:48,480
a little into into this conversation i

00:31:46,640 --> 00:31:49,919
mean i know we are talking about ai

00:31:48,480 --> 00:31:52,399
and power and i think we're very

00:31:49,919 --> 00:31:55,600
important for us to focus on power

00:31:52,399 --> 00:31:59,039
then who gets to uh design

00:31:55,600 --> 00:32:00,480
or train ai uh and i think i have said a

00:31:59,039 --> 00:32:03,200
little bit about this but

00:32:00,480 --> 00:32:03,919
i building on what building on what

00:32:03,200 --> 00:32:07,039
julie

00:32:03,919 --> 00:32:09,360
said um it's

00:32:07,039 --> 00:32:10,960
whose knowledge is it anyway right i

00:32:09,360 --> 00:32:14,240
mean uh the people

00:32:10,960 --> 00:32:16,080
who uh who are in our context have

00:32:14,240 --> 00:32:18,880
so much knowledge but there is an

00:32:16,080 --> 00:32:20,240
immense inequality of distribution of

00:32:18,880 --> 00:32:24,399
that knowledge

00:32:20,240 --> 00:32:26,480
we are mostly used as you know

00:32:24,399 --> 00:32:27,440
although we have all the knowledge and

00:32:26,480 --> 00:32:30,880
then that

00:32:27,440 --> 00:32:32,000
knowledge sort of transfers or travels

00:32:30,880 --> 00:32:34,000
to the western world

00:32:32,000 --> 00:32:35,679
and then you know that's where we see

00:32:34,000 --> 00:32:38,000
the bias that's where the design

00:32:35,679 --> 00:32:39,279
you know uh the the design of product

00:32:38,000 --> 00:32:42,320
takes place

00:32:39,279 --> 00:32:44,480
uh and instead of distribution or equal

00:32:42,320 --> 00:32:47,120
distribution of resources

00:32:44,480 --> 00:32:47,919
we see that you know the inequalities of

00:32:47,120 --> 00:32:50,320
risk

00:32:47,919 --> 00:32:51,440
inequalities between the global north

00:32:50,320 --> 00:32:53,760
and global south

00:32:51,440 --> 00:32:55,760
organizations working on digital rights

00:32:53,760 --> 00:32:58,480
or working on tech and human rights

00:32:55,760 --> 00:32:59,519
those inequalities become wider and

00:32:58,480 --> 00:33:02,640
wider every

00:32:59,519 --> 00:33:03,519
you know every day so so and it's it's a

00:33:02,640 --> 00:33:06,640
lot of labor

00:33:03,519 --> 00:33:07,039
it's a free labor like sitting on panels

00:33:06,640 --> 00:33:09,279
and

00:33:07,039 --> 00:33:10,559
sharing your knowledge it's a free labor

00:33:09,279 --> 00:33:12,880
uh and i think

00:33:10,559 --> 00:33:14,399
it's it's it's now time when we are

00:33:12,880 --> 00:33:15,919
seeing this these conversations

00:33:14,399 --> 00:33:17,440
happening in the western world around

00:33:15,919 --> 00:33:20,559
content moderation

00:33:17,440 --> 00:33:20,559
how we actually

00:33:22,399 --> 00:33:27,679
absolutely have no idea what's uh

00:33:25,679 --> 00:33:28,880
what are the decisions being taken

00:33:27,679 --> 00:33:30,480
around them

00:33:28,880 --> 00:33:32,720
while people who are sitting in these

00:33:30,480 --> 00:33:33,200
big tech giants social media companies

00:33:32,720 --> 00:33:34,880
or

00:33:33,200 --> 00:33:36,720
you know like running governments so i

00:33:34,880 --> 00:33:38,480
just wanted to acknowledge that there is

00:33:36,720 --> 00:33:42,960
a lot of labor happening

00:33:38,480 --> 00:33:42,960
in global south but there is a very

00:33:44,960 --> 00:33:48,399
that labor and distribution of

00:33:51,600 --> 00:33:58,720
you got you your audio cut out um right

00:33:55,440 --> 00:34:00,480
right at the end there but um but

00:33:58,720 --> 00:34:03,200
i'm gonna i'm gonna try to recap and

00:34:00,480 --> 00:34:05,679
then uh let us know if

00:34:03,200 --> 00:34:06,320
that i've come close but just in terms

00:34:05,679 --> 00:34:09,440
of

00:34:06,320 --> 00:34:10,560
the the wealth of information that is

00:34:09,440 --> 00:34:12,240
extracted

00:34:10,560 --> 00:34:14,720
and i'm paraphrasing obviously that is

00:34:12,240 --> 00:34:18,320
extracted like a resource

00:34:14,720 --> 00:34:21,760
um as resources have long been extracted

00:34:18,320 --> 00:34:24,320
from the location of of that knowledge

00:34:21,760 --> 00:34:25,520
and then there's a huge gap between then

00:34:24,320 --> 00:34:28,720
and and

00:34:25,520 --> 00:34:32,399
and a dearth of information of how that

00:34:28,720 --> 00:34:34,639
information even parlays into

00:34:32,399 --> 00:34:35,679
uh uh invention if you will and i'm

00:34:34,639 --> 00:34:38,240
making air

00:34:35,679 --> 00:34:38,960
air quotes um and how it's being used

00:34:38,240 --> 00:34:42,399
and so

00:34:38,960 --> 00:34:43,359
so it's it's hap so the it's happening

00:34:42,399 --> 00:34:45,280
on two levels

00:34:43,359 --> 00:34:47,040
there's the original extraction of

00:34:45,280 --> 00:34:49,359
knowledge and then there's the ways that

00:34:47,040 --> 00:34:49,919
the knowledge is being put to use that's

00:34:49,359 --> 00:34:54,000
not even

00:34:49,919 --> 00:34:55,200
being made clear is that is that correct

00:34:54,000 --> 00:34:58,560
on the point that you were trying to

00:34:55,200 --> 00:34:58,560
make right there at the end

00:35:01,040 --> 00:35:04,079
absolutely great thank you okay

00:35:03,040 --> 00:35:06,880
beautiful

00:35:04,079 --> 00:35:08,640
sierra do you want to hop in there sure

00:35:06,880 --> 00:35:10,720
i was just adding on to

00:35:08,640 --> 00:35:12,480
sarah i mean at the justice data lab we

00:35:10,720 --> 00:35:15,280
do exactly the same thing and

00:35:12,480 --> 00:35:16,720
the way that we are trying to do that is

00:35:15,280 --> 00:35:18,960
literally to put in the hands of

00:35:16,720 --> 00:35:21,680
community organizations

00:35:18,960 --> 00:35:22,560
research resources and so we assign

00:35:21,680 --> 00:35:25,119
teams

00:35:22,560 --> 00:35:26,640
of undergrad researchers with the

00:35:25,119 --> 00:35:29,280
princeton pedigree

00:35:26,640 --> 00:35:30,640
to these community organizations who say

00:35:29,280 --> 00:35:31,040
you know we really would love to know

00:35:30,640 --> 00:35:33,440
this

00:35:31,040 --> 00:35:34,880
or we really want to advocate for this

00:35:33,440 --> 00:35:36,560
and the students work

00:35:34,880 --> 00:35:38,480
on behalf of the organization in

00:35:36,560 --> 00:35:41,680
partnership with the organizations

00:35:38,480 --> 00:35:43,599
the organizations drive all of the

00:35:41,680 --> 00:35:44,800
theorizing drive the data collection

00:35:43,599 --> 00:35:46,720
drive everything

00:35:44,800 --> 00:35:47,920
and i think it's just a really powerful

00:35:46,720 --> 00:35:49,680
way um

00:35:47,920 --> 00:35:51,839
to make sure that the voices who need to

00:35:49,680 --> 00:35:53,200
be included are not only at the table

00:35:51,839 --> 00:35:59,839
but are at the head of the table they're

00:35:53,200 --> 00:35:59,839
controlling the conversation

00:35:59,920 --> 00:36:03,200
let's talk about that the kind of

00:36:01,599 --> 00:36:06,560
opportunities that you're each

00:36:03,200 --> 00:36:09,280
actually um uh creating

00:36:06,560 --> 00:36:09,680
and um what you're excited about and

00:36:09,280 --> 00:36:12,480
what

00:36:09,680 --> 00:36:14,560
like i i really don't want it to be that

00:36:12,480 --> 00:36:18,079
when we're having conversations of power

00:36:14,560 --> 00:36:21,040
and we have a panel of uh

00:36:18,079 --> 00:36:21,680
women queer women queer people of color

00:36:21,040 --> 00:36:24,480
that we're

00:36:21,680 --> 00:36:25,520
only talking about the power that we're

00:36:24,480 --> 00:36:28,960
disallowed

00:36:25,520 --> 00:36:31,359
or um and like i know everybody here

00:36:28,960 --> 00:36:33,040
is doing incredible work and putting

00:36:31,359 --> 00:36:33,760
forward sierra you just gave us a little

00:36:33,040 --> 00:36:36,320
window in

00:36:33,760 --> 00:36:37,280
into that as well um what are you

00:36:36,320 --> 00:36:39,200
excited about

00:36:37,280 --> 00:36:40,480
how do you see that shifting you know

00:36:39,200 --> 00:36:43,839
when we're talking about

00:36:40,480 --> 00:36:46,960
um uh the analog disparities of

00:36:43,839 --> 00:36:48,960
of power are often upended when we

00:36:46,960 --> 00:36:50,960
come to collective purpose so i'm

00:36:48,960 --> 00:36:52,000
curious about examples of that kind of

00:36:50,960 --> 00:36:53,760
collectivity

00:36:52,000 --> 00:36:55,599
or anything that's thrilling you in this

00:36:53,760 --> 00:36:59,040
moment um if we could

00:36:55,599 --> 00:37:01,280
if we could go around um and and

00:36:59,040 --> 00:37:02,800
i know i'm i'm uh i didn't give you a

00:37:01,280 --> 00:37:04,720
warning i was going to ask you that but

00:37:02,800 --> 00:37:06,720
but if we can be thoughtful about that

00:37:04,720 --> 00:37:09,839
of something that you're excited about

00:37:06,720 --> 00:37:10,400
um and what you see as potentially power

00:37:09,839 --> 00:37:13,440
shifting

00:37:10,400 --> 00:37:15,520
in the most micro or macro way um

00:37:13,440 --> 00:37:17,839
i'd love i'd love for that to be in the

00:37:15,520 --> 00:37:20,160
room and it as part of the conversation

00:37:17,839 --> 00:37:21,359
i'm gonna go around so sarah you're the

00:37:20,160 --> 00:37:24,640
first

00:37:21,359 --> 00:37:25,760
square in my family feud yeah i feel

00:37:24,640 --> 00:37:28,160
like brady bunch

00:37:25,760 --> 00:37:28,800
a lot of times too with this okay um and

00:37:28,160 --> 00:37:31,839
we're all

00:37:28,800 --> 00:37:34,320
like arranged differently but anyway um

00:37:31,839 --> 00:37:35,200
okay so yeah great question i appreciate

00:37:34,320 --> 00:37:37,440
the

00:37:35,200 --> 00:37:38,720
the context too right because this isn't

00:37:37,440 --> 00:37:42,240
all about

00:37:38,720 --> 00:37:45,440
um those of us on the panel

00:37:42,240 --> 00:37:48,640
and those who who we represent

00:37:45,440 --> 00:37:49,200
um just seating power we're not doing

00:37:48,640 --> 00:37:50,960
that

00:37:49,200 --> 00:37:52,400
you know if we ever did it we're not

00:37:50,960 --> 00:37:55,520
doing it anymore

00:37:52,400 --> 00:37:58,720
and we're actually thinking through

00:37:55,520 --> 00:38:01,599
um new ways of of doing and new ways

00:37:58,720 --> 00:38:03,520
of of creating as sierra was just you

00:38:01,599 --> 00:38:06,560
know articulating and so

00:38:03,520 --> 00:38:10,079
um from my own perspective and from

00:38:06,560 --> 00:38:12,880
speaking for uh our

00:38:10,079 --> 00:38:15,200
our center at ucla one of the things

00:38:12,880 --> 00:38:16,480
that uh safiya noble and i are working

00:38:15,200 --> 00:38:19,680
on right now

00:38:16,480 --> 00:38:21,359
actively is thinking about

00:38:19,680 --> 00:38:22,800
uh you know some of the projects we've

00:38:21,359 --> 00:38:27,119
had in mind for

00:38:22,800 --> 00:38:30,400
for a decade which is um

00:38:27,119 --> 00:38:32,640
pushing back pushing open that public

00:38:30,400 --> 00:38:35,440
space and the public sphere

00:38:32,640 --> 00:38:36,079
that has been inappropriately colonized

00:38:35,440 --> 00:38:38,550
and i do

00:38:36,079 --> 00:38:39,599
use that word very uh

00:38:38,550 --> 00:38:42,880
[Music]

00:38:39,599 --> 00:38:46,240
very um intentionally

00:38:42,880 --> 00:38:49,839
by tech uh

00:38:46,240 --> 00:38:52,400
tech having kind of um

00:38:49,839 --> 00:38:53,200
taken up these notions that we have

00:38:52,400 --> 00:38:54,800
about

00:38:53,200 --> 00:38:57,119
so many of these information

00:38:54,800 --> 00:39:00,800
institutions that have sat in

00:38:57,119 --> 00:39:04,400
uh squarely in uh kind of the public

00:39:00,800 --> 00:39:06,640
good space and then colonized

00:39:04,400 --> 00:39:08,480
their words their identities we have

00:39:06,640 --> 00:39:10,240
susan wojcicki from youtube

00:39:08,480 --> 00:39:12,160
going around the world telling the whole

00:39:10,240 --> 00:39:14,000
world youtube is a library if you want

00:39:12,160 --> 00:39:16,160
to see me go apoplectic

00:39:14,000 --> 00:39:17,760
let me hear her say that one more time i

00:39:16,160 --> 00:39:20,720
lose it every time

00:39:17,760 --> 00:39:21,839
it's not um it's not without harm that

00:39:20,720 --> 00:39:24,240
she does that

00:39:21,839 --> 00:39:26,400
libraries don't collect data and and

00:39:24,240 --> 00:39:27,280
monetize it on their users libraries

00:39:26,400 --> 00:39:29,359
don't

00:39:27,280 --> 00:39:31,040
promote and disseminate uh

00:39:29,359 --> 00:39:32,880
disinformation and misinformation

00:39:31,040 --> 00:39:34,960
material with without any

00:39:32,880 --> 00:39:36,160
sense of responsibility they don't use

00:39:34,960 --> 00:39:39,040
algorithms

00:39:36,160 --> 00:39:40,720
to serve up uh garbage to just keep

00:39:39,040 --> 00:39:42,000
people engaged none of that is not a

00:39:40,720 --> 00:39:44,480
library so youtube is not

00:39:42,000 --> 00:39:45,839
a library but libraries actually have so

00:39:44,480 --> 00:39:48,480
much to offer

00:39:45,839 --> 00:39:50,480
uh and our ways of knowing libraries a

00:39:48,480 --> 00:39:52,720
flawed institution as well with uh

00:39:50,480 --> 00:39:54,240
you know with a difficult history but

00:39:52,720 --> 00:39:55,920
how could we reimagine

00:39:54,240 --> 00:39:57,920
some of the principles and values that

00:39:55,920 --> 00:39:59,680
come from libraries and librarianship

00:39:57,920 --> 00:40:01,440
to actually say not only is youtube not

00:39:59,680 --> 00:40:02,320
a library but this is what a library

00:40:01,440 --> 00:40:05,280
looks like

00:40:02,320 --> 00:40:05,760
um when it is in the internet space and

00:40:05,280 --> 00:40:07,760
in

00:40:05,760 --> 00:40:09,440
in practice for the for the public good

00:40:07,760 --> 00:40:11,599
and for the benefit of the public so

00:40:09,440 --> 00:40:12,560
that's just like the slightest preview

00:40:11,599 --> 00:40:14,640
of um

00:40:12,560 --> 00:40:15,839
and a very half-baked explanation of

00:40:14,640 --> 00:40:17,599
what we're coming up with

00:40:15,839 --> 00:40:18,880
but what i'm saying is we're actually

00:40:17,599 --> 00:40:21,520
going to stop

00:40:18,880 --> 00:40:22,480
seeding those spaces and those

00:40:21,520 --> 00:40:25,040
imaginaries

00:40:22,480 --> 00:40:26,079
actually to tech and we're going to

00:40:25,040 --> 00:40:29,839
reintroduce

00:40:26,079 --> 00:40:30,880
very um very directly and with great

00:40:29,839 --> 00:40:34,160
purpose

00:40:30,880 --> 00:40:37,280
uh some of these identifiable

00:40:34,160 --> 00:40:39,119
information curatorial roles to help

00:40:37,280 --> 00:40:41,599
users make sense

00:40:39,119 --> 00:40:43,440
when the the sense making has been

00:40:41,599 --> 00:40:46,720
deliberately removed from them

00:40:43,440 --> 00:40:49,920
uh for the purposes of profit

00:40:46,720 --> 00:40:50,640
so that's kind of where we are um in in

00:40:49,920 --> 00:40:53,440
essence

00:40:50,640 --> 00:40:55,200
um bringing the human back and and and

00:40:53,440 --> 00:40:58,160
foregrounding the human

00:40:55,200 --> 00:40:59,920
in this notion of um artificial

00:40:58,160 --> 00:41:01,200
intelligence like whoever said that was

00:40:59,920 --> 00:41:04,240
better

00:41:01,200 --> 00:41:05,920
you know um we used to think uh uh sweet

00:41:04,240 --> 00:41:06,240
and low was better too you know what i

00:41:05,920 --> 00:41:08,960
mean

00:41:06,240 --> 00:41:09,359
it's not it caused cancer it's not good

00:41:08,960 --> 00:41:11,359
so

00:41:09,359 --> 00:41:13,040
um you know just we're just thinking

00:41:11,359 --> 00:41:15,599
that way right now thanks

00:41:13,040 --> 00:41:16,960
cool thank you julie what about you what

00:41:15,599 --> 00:41:19,680
are you excited about

00:41:16,960 --> 00:41:20,240
where do you see uh some potential and

00:41:19,680 --> 00:41:21,920
um

00:41:20,240 --> 00:41:25,280
uh what would make you really happy to

00:41:21,920 --> 00:41:25,280
see some momentum behind

00:41:25,680 --> 00:41:30,319
um i'm honestly very excited about a lot

00:41:28,640 --> 00:41:31,680
of things right now when it comes to

00:41:30,319 --> 00:41:34,720
this conversation

00:41:31,680 --> 00:41:36,880
the first thing of course is that my

00:41:34,720 --> 00:41:39,839
very dear colleague nigat

00:41:36,880 --> 00:41:41,040
i shall speak for herself and myself are

00:41:39,839 --> 00:41:44,400
both

00:41:41,040 --> 00:41:46,560
part of a new organization

00:41:44,400 --> 00:41:48,000
powerful organization which is making

00:41:46,560 --> 00:41:50,319
decisions on

00:41:48,000 --> 00:41:51,119
uh facebook and instagram content

00:41:50,319 --> 00:41:53,520
moderation

00:41:51,119 --> 00:41:54,880
including the automated ones and i'm

00:41:53,520 --> 00:41:56,880
talking here about the

00:41:54,880 --> 00:41:59,599
the oversight board which was which was

00:41:56,880 --> 00:42:03,680
created almost a year ago now

00:41:59,599 --> 00:42:06,720
and for me this is exciting because

00:42:03,680 --> 00:42:10,400
it's honestly the first time

00:42:06,720 --> 00:42:13,680
in this industry that we are recognizing

00:42:10,400 --> 00:42:16,800
that the the expertise and knowledge

00:42:13,680 --> 00:42:20,560
from people who we thought before

00:42:16,800 --> 00:42:22,640
uh you know did not matter let's

00:42:20,560 --> 00:42:24,079
talk very frankly i mean i wouldn't i'm

00:42:22,640 --> 00:42:25,839
a black woman so

00:42:24,079 --> 00:42:28,000
how many chances i would have been here

00:42:25,839 --> 00:42:28,560
having this conversation 10 or 15 years

00:42:28,000 --> 00:42:30,560
ago

00:42:28,560 --> 00:42:32,800
but that would have been very difficult

00:42:30,560 --> 00:42:36,160
so uh i measure

00:42:32,800 --> 00:42:39,680
and i we we talked about that with night

00:42:36,160 --> 00:42:42,000
um often we measured uh you know

00:42:39,680 --> 00:42:43,599
what what we've been able to to do but

00:42:42,000 --> 00:42:44,480
that's not you know that's not the end

00:42:43,599 --> 00:42:47,520
of it all

00:42:44,480 --> 00:42:50,400
we are here and i'm here particularly uh

00:42:47,520 --> 00:42:53,440
with the purpose of making sure that

00:42:50,400 --> 00:42:53,920
whenever we will have our conversations

00:42:53,440 --> 00:42:56,720
about

00:42:53,920 --> 00:42:58,000
content moderation but others in general

00:42:56,720 --> 00:43:01,280
we will not look

00:42:58,000 --> 00:43:03,760
at people like me or uh you know

00:43:01,280 --> 00:43:06,079
people elsewhere outside of the us and

00:43:03,760 --> 00:43:09,760
outside of europe outside of canada

00:43:06,079 --> 00:43:12,400
as you know just consumers or users who

00:43:09,760 --> 00:43:13,119
we think about in the thought it's the

00:43:12,400 --> 00:43:15,760
priority

00:43:13,119 --> 00:43:17,680
it should be the principle and the other

00:43:15,760 --> 00:43:20,480
thing i'm excited about which is

00:43:17,680 --> 00:43:21,920
closely linked to uh to the one i just

00:43:20,480 --> 00:43:24,880
mentioned is that we're

00:43:21,920 --> 00:43:26,800
i'm doing a research right now at the

00:43:24,880 --> 00:43:27,760
digital civil society lab at stanford

00:43:26,800 --> 00:43:30,000
university

00:43:27,760 --> 00:43:31,839
and also as an affiliate at the berkeley

00:43:30,000 --> 00:43:34,560
client center at harvard

00:43:31,839 --> 00:43:35,280
uh when i'm working i mean i'm not even

00:43:34,560 --> 00:43:37,200
studying

00:43:35,280 --> 00:43:38,319
we've developed at anthony san francis

00:43:37,200 --> 00:43:40,880
methodology

00:43:38,319 --> 00:43:43,119
to make sure that in the automated

00:43:40,880 --> 00:43:45,280
moderation systems that

00:43:43,119 --> 00:43:46,319
platforms are rolling out as the

00:43:45,280 --> 00:43:49,280
solution to

00:43:46,319 --> 00:43:49,920
the content problems well we want to

00:43:49,280 --> 00:43:53,280
make sure

00:43:49,920 --> 00:43:54,160
to get you know the human back into the

00:43:53,280 --> 00:43:57,040
loop and

00:43:54,160 --> 00:43:58,240
by human i talk here about the very

00:43:57,040 --> 00:44:01,200
specific

00:43:58,240 --> 00:44:03,760
context that is missing from most of the

00:44:01,200 --> 00:44:06,000
automated content moderation systems

00:44:03,760 --> 00:44:08,400
and by doing that to bring those

00:44:06,000 --> 00:44:09,200
contacts to bring this very local

00:44:08,400 --> 00:44:12,960
knowledge

00:44:09,200 --> 00:44:15,599
we rely and we work with and we

00:44:12,960 --> 00:44:17,119
also you know collaborate as i was

00:44:15,599 --> 00:44:19,440
saying we collaborate

00:44:17,119 --> 00:44:20,319
with organizations in the countries

00:44:19,440 --> 00:44:22,800
where we work in

00:44:20,319 --> 00:44:23,920
and once we work with them we have a

00:44:22,800 --> 00:44:26,480
better understanding

00:44:23,920 --> 00:44:28,319
of what hate actually looks like in this

00:44:26,480 --> 00:44:29,119
country what disinformation actually

00:44:28,319 --> 00:44:33,280
looks like

00:44:29,119 --> 00:44:35,440
when you work only with people located

00:44:33,280 --> 00:44:37,520
in global north you're going to feed

00:44:35,440 --> 00:44:38,640
databases that are filled with errors

00:44:37,520 --> 00:44:40,400
and honestly

00:44:38,640 --> 00:44:42,319
 most of the times and that are

00:44:40,400 --> 00:44:45,359
even going to silence

00:44:42,319 --> 00:44:47,359
those who are actually using

00:44:45,359 --> 00:44:49,119
those platforms to bring a critical

00:44:47,359 --> 00:44:51,520
debate a critical

00:44:49,119 --> 00:44:52,800
voice that we don't like necessarily but

00:44:51,520 --> 00:44:55,119
that is necessary

00:44:52,800 --> 00:44:56,079
for for many democracies in the world to

00:44:55,119 --> 00:44:58,400
flourish

00:44:56,079 --> 00:44:59,200
and so that's the other part i'm excited

00:44:58,400 --> 00:45:02,079
about

00:44:59,200 --> 00:45:03,200
making sure that whenever we talk about

00:45:02,079 --> 00:45:06,079
those products

00:45:03,200 --> 00:45:08,160
uh we will adopt basically the same

00:45:06,079 --> 00:45:11,200
strategy as the bad actors

00:45:08,160 --> 00:45:14,319
why not test the good things you know

00:45:11,200 --> 00:45:15,119
by collaborating with civil society

00:45:14,319 --> 00:45:18,160
organizations

00:45:15,119 --> 00:45:20,640
in those countries and global majority

00:45:18,160 --> 00:45:21,680
i'm trying to educate myself too it's

00:45:20,640 --> 00:45:24,720
very difficult

00:45:21,680 --> 00:45:25,200
and uh yes that that's yeah that's the

00:45:24,720 --> 00:45:28,160
future

00:45:25,200 --> 00:45:29,119
i'm borrowing you know a word here from

00:45:28,160 --> 00:45:32,160
catherine mather

00:45:29,119 --> 00:45:35,040
who said that to make her work uh

00:45:32,160 --> 00:45:36,800
so positive heading the wikimedia

00:45:35,040 --> 00:45:38,960
foundation she looked at the future

00:45:36,800 --> 00:45:39,920
and the future was africa asia latin

00:45:38,960 --> 00:45:43,599
america

00:45:39,920 --> 00:45:45,040
thanks so i i think that's so important

00:45:43,599 --> 00:45:47,839
because so

00:45:45,040 --> 00:45:49,520
so many times the conversation is how do

00:45:47,839 --> 00:45:51,280
we have a seat at the table and not how

00:45:49,520 --> 00:45:53,200
do we make a new table or whoever said

00:45:51,280 --> 00:45:55,200
we wanted a table in the first place

00:45:53,200 --> 00:45:56,560
right like that's it's really really

00:45:55,200 --> 00:45:59,440
really important to think about

00:45:56,560 --> 00:46:00,079
what what uh how we build the future

00:45:59,440 --> 00:46:03,119
that we're

00:46:00,079 --> 00:46:04,560
intent upon uh living in sierra what

00:46:03,119 --> 00:46:07,599
about you what are you excited about

00:46:04,560 --> 00:46:09,680
what feels positive to you i'm also so

00:46:07,599 --> 00:46:11,599
excited about so many things and i

00:46:09,680 --> 00:46:13,119
i told you all about the just data lab

00:46:11,599 --> 00:46:14,960
and i'm so excited about the work that's

00:46:13,119 --> 00:46:17,680
going on there

00:46:14,960 --> 00:46:19,200
but in my own research i'm also i'm

00:46:17,680 --> 00:46:20,960
working on a project that

00:46:19,200 --> 00:46:22,240
that explores how minority political

00:46:20,960 --> 00:46:25,359
candidates in the u.s

00:46:22,240 --> 00:46:25,920
experience misindis information online

00:46:25,359 --> 00:46:27,839
and

00:46:25,920 --> 00:46:29,920
unsurprisingly it often borders on

00:46:27,839 --> 00:46:33,040
harassment one easy example

00:46:29,920 --> 00:46:34,560
is obama's anti-birther rumor that that

00:46:33,040 --> 00:46:36,079
accused him of not being born in the

00:46:34,560 --> 00:46:37,040
united states but that specifically

00:46:36,079 --> 00:46:39,920
hinged on his

00:46:37,040 --> 00:46:41,119
racial and ethnic identity but anyway

00:46:39,920 --> 00:46:43,680
all of that is to say

00:46:41,119 --> 00:46:45,920
that i'm really excited about a lot of

00:46:43,680 --> 00:46:48,079
the new tools that are springing up

00:46:45,920 --> 00:46:49,440
created by women created by people of

00:46:48,079 --> 00:46:52,720
color created by other

00:46:49,440 --> 00:46:54,400
other marginalized folks um to

00:46:52,720 --> 00:46:56,319
kind of solve these problems and i

00:46:54,400 --> 00:46:57,680
really appreciate what julie and sarah

00:46:56,319 --> 00:46:58,720
were talking about about bringing the

00:46:57,680 --> 00:47:00,640
human back in and

00:46:58,720 --> 00:47:02,160
one instrumental part of being human is

00:47:00,640 --> 00:47:05,359
the communities um

00:47:02,160 --> 00:47:07,680
that that we're a part of so one of my

00:47:05,359 --> 00:47:08,640
favorite examples is amy zhang's squad

00:47:07,680 --> 00:47:11,359
box which

00:47:08,640 --> 00:47:13,359
is a kind of crowd-sourced way for your

00:47:11,359 --> 00:47:15,839
friends and family to filter out

00:47:13,359 --> 00:47:17,520
negative negativity and harassment

00:47:15,839 --> 00:47:20,559
online and it really

00:47:17,520 --> 00:47:22,720
centers community involvement care

00:47:20,559 --> 00:47:24,960
and i love that these things are being

00:47:22,720 --> 00:47:25,920
infused into what we often deemed really

00:47:24,960 --> 00:47:28,240
impersonal

00:47:25,920 --> 00:47:29,200
kind of objective whatever that means

00:47:28,240 --> 00:47:31,599
systems

00:47:29,200 --> 00:47:32,960
and tools so i love that that's kind of

00:47:31,599 --> 00:47:36,559
being infused and

00:47:32,960 --> 00:47:36,559
i think that's the best way to move

00:47:36,839 --> 00:47:42,400
forward

00:47:38,240 --> 00:47:42,400
thank you what about you

00:47:42,880 --> 00:47:47,440
yeah i mean um as julie already said

00:47:46,960 --> 00:47:50,160
that

00:47:47,440 --> 00:47:50,640
um the experience that we both are

00:47:50,160 --> 00:47:53,359
having

00:47:50,640 --> 00:47:54,559
i think it's uh i'm it's i'm very

00:47:53,359 --> 00:47:58,160
excited and

00:47:54,559 --> 00:48:01,359
also you know like it's a it's unusual

00:47:58,160 --> 00:48:05,280
space for women like me a woman of color

00:48:01,359 --> 00:48:07,520
where you have like a a powerful

00:48:05,280 --> 00:48:08,880
space where you have all the power to

00:48:07,520 --> 00:48:10,800
take decisions

00:48:08,880 --> 00:48:12,800
and it's unusual for us because usually

00:48:10,800 --> 00:48:15,119
we don't have that kind of space

00:48:12,800 --> 00:48:17,280
and i i feel that it's so important to

00:48:15,119 --> 00:48:18,160
normalize these spaces for women of

00:48:17,280 --> 00:48:21,200
color

00:48:18,160 --> 00:48:23,520
who have um

00:48:21,200 --> 00:48:24,880
immense knowledge around human rights

00:48:23,520 --> 00:48:27,040
and technology

00:48:24,880 --> 00:48:28,720
uh and digital rights and we have so

00:48:27,040 --> 00:48:30,800
many women women of color

00:48:28,720 --> 00:48:32,720
and even if they are part of different

00:48:30,800 --> 00:48:35,280
boards or advisory councils

00:48:32,720 --> 00:48:36,400
how much voice they have and i think we

00:48:35,280 --> 00:48:38,480
really need to see that

00:48:36,400 --> 00:48:39,920
you know like how we can give them that

00:48:38,480 --> 00:48:42,319
voice um

00:48:39,920 --> 00:48:44,160
and at the micro level i'm very excited

00:48:42,319 --> 00:48:45,280
uh around the work that we are doing in

00:48:44,160 --> 00:48:48,079
pakistan

00:48:45,280 --> 00:48:48,720
uh i'm very excited to see a lot of

00:48:48,079 --> 00:48:51,599
women

00:48:48,720 --> 00:48:53,359
feminists taking lead around the

00:48:51,599 --> 00:48:55,680
discourse of digital rights

00:48:53,359 --> 00:48:56,880
and the kind of feminist internet we are

00:48:55,680 --> 00:49:01,280
making here

00:48:56,880 --> 00:49:04,240
um also you know uh looking into the

00:49:01,280 --> 00:49:05,440
issues that no one has ever looked into

00:49:04,240 --> 00:49:07,520
and then holding

00:49:05,440 --> 00:49:09,680
you know tech giants accountable or

00:49:07,520 --> 00:49:11,520
powerful actors accountable within the

00:49:09,680 --> 00:49:14,720
country while living in a country

00:49:11,520 --> 00:49:15,200
where in the patriarchal society talking

00:49:14,720 --> 00:49:17,599
to

00:49:15,200 --> 00:49:19,760
a powerful state is very difficult i'm

00:49:17,599 --> 00:49:20,400
very excited for that future especially

00:49:19,760 --> 00:49:23,280
on this

00:49:20,400 --> 00:49:25,440
international women's day i'm excited to

00:49:23,280 --> 00:49:26,960
see the feminist internet you know

00:49:25,440 --> 00:49:27,610
not just in pakistan but across the

00:49:26,960 --> 00:49:29,200
world

00:49:27,610 --> 00:49:31,520
[Music]

00:49:29,200 --> 00:49:32,319
and and and the other thing i think is

00:49:31,520 --> 00:49:34,000
really important

00:49:32,319 --> 00:49:36,000
and i'm going to tie it to one of the

00:49:34,000 --> 00:49:39,040
questions we got asked on twitter

00:49:36,000 --> 00:49:40,960
is that we're not talking about um uh

00:49:39,040 --> 00:49:42,400
only engaging something theoretically

00:49:40,960 --> 00:49:45,200
right like that these

00:49:42,400 --> 00:49:46,160
ideas of a feminist internet of a

00:49:45,200 --> 00:49:49,920
community

00:49:46,160 --> 00:49:52,960
led internet of of uh majority

00:49:49,920 --> 00:49:55,920
uh the global majority right that

00:49:52,960 --> 00:49:56,880
are actually about um being able to

00:49:55,920 --> 00:49:59,200
build

00:49:56,880 --> 00:50:00,319
and having the capacity to build

00:49:59,200 --> 00:50:03,760
autonomy

00:50:00,319 --> 00:50:06,640
and autonomous spaces that are that are

00:50:03,760 --> 00:50:07,520
um untethered from some from these

00:50:06,640 --> 00:50:10,640
systems

00:50:07,520 --> 00:50:13,040
uh of of inequality and

00:50:10,640 --> 00:50:14,000
and that and that they were designed to

00:50:13,040 --> 00:50:15,680
be

00:50:14,000 --> 00:50:17,520
unjust i mean i think that that's the

00:50:15,680 --> 00:50:19,599
piece is that it's not that

00:50:17,520 --> 00:50:21,839
it's just broken it's actually working

00:50:19,599 --> 00:50:23,920
in the ways that things were intended

00:50:21,839 --> 00:50:26,000
and insofar as we hold different

00:50:23,920 --> 00:50:27,760
intentions then we have to build

00:50:26,000 --> 00:50:30,079
for the for those intentions and i think

00:50:27,760 --> 00:50:32,720
that that's also a way that

00:50:30,079 --> 00:50:33,920
um uh it that's an opportunity i'm

00:50:32,720 --> 00:50:37,599
actually excited about

00:50:33,920 --> 00:50:39,760
so um is that um while

00:50:37,599 --> 00:50:40,800
certainly we see when we build

00:50:39,760 --> 00:50:44,240
unintentionally

00:50:40,800 --> 00:50:46,000
or on purpose unjustly what we

00:50:44,240 --> 00:50:48,240
what we get but that we actually do have

00:50:46,000 --> 00:50:51,440
the opportunity to build

00:50:48,240 --> 00:50:51,920
uh really specifically um in new ways

00:50:51,440 --> 00:50:55,520
and that

00:50:51,920 --> 00:50:58,800
and i have and i'm excited about that um

00:50:55,520 --> 00:51:00,240
um i think there are a lot of incredible

00:50:58,800 --> 00:51:02,160
conversations and things being built

00:51:00,240 --> 00:51:06,160
around data around data sovereignty

00:51:02,160 --> 00:51:09,680
around uh um around community access

00:51:06,160 --> 00:51:11,520
around looking at um uh um

00:51:09,680 --> 00:51:13,680
also who's holding who's holding what

00:51:11,520 --> 00:51:15,599
data and and for whom

00:51:13,680 --> 00:51:17,200
there's a lot there that that i feel

00:51:15,599 --> 00:51:21,359
really excited to unpack

00:51:17,200 --> 00:51:22,000
um and uh i told i told us that i'd

00:51:21,359 --> 00:51:24,000
point us to

00:51:22,000 --> 00:51:25,839
also to the rest of moss fest so i'm

00:51:24,000 --> 00:51:27,040
also excited the fact that a lot of what

00:51:25,839 --> 00:51:30,800
was discussed here

00:51:27,040 --> 00:51:33,200
is getting um uh teased out much more

00:51:30,800 --> 00:51:35,200
uh across so many different panels and

00:51:33,200 --> 00:51:38,079
conversations and workshops

00:51:35,200 --> 00:51:39,440
and in uh in spatial chat around moss

00:51:38,079 --> 00:51:42,240
fest so i really

00:51:39,440 --> 00:51:43,359
urge folks to um to participate in those

00:51:42,240 --> 00:51:45,760
conversations

00:51:43,359 --> 00:51:48,000
if anything that got uplifted here feels

00:51:45,760 --> 00:51:49,440
particularly germane

00:51:48,000 --> 00:51:52,079
one of the questions we got asked on

00:51:49,440 --> 00:51:55,680
twitter um and i think that this is

00:51:52,079 --> 00:51:57,599
um uh i'm gonna bring

00:51:55,680 --> 00:51:58,880
i'm gonna bring them together um i'm

00:51:57,599 --> 00:52:00,240
gonna tell you two questions and then

00:51:58,880 --> 00:52:02,480
anybody who wants to take it

00:52:00,240 --> 00:52:04,400
because i think we've touched on this in

00:52:02,480 --> 00:52:05,599
what ways can we bring an intersectional

00:52:04,400 --> 00:52:08,160
anti-oppression

00:52:05,599 --> 00:52:09,040
anti-cast lens into discussions and

00:52:08,160 --> 00:52:11,599
decisions

00:52:09,040 --> 00:52:12,960
about power inequalities in tech another

00:52:11,599 --> 00:52:15,680
question that came up

00:52:12,960 --> 00:52:17,599
is around um indigenous wisdom so

00:52:15,680 --> 00:52:18,240
community and indigenous wisdom how do

00:52:17,599 --> 00:52:20,319
we

00:52:18,240 --> 00:52:22,319
bring that into tech particularly in

00:52:20,319 --> 00:52:25,599
response to gendered harassment

00:52:22,319 --> 00:52:28,880
racial profiling or misinformation

00:52:25,599 --> 00:52:31,119
um and so i'll just and then

00:52:28,880 --> 00:52:32,400
and then the third question on twitter

00:52:31,119 --> 00:52:36,400
was how do we snap

00:52:32,400 --> 00:52:39,200
out of uh the pre the predetermined

00:52:36,400 --> 00:52:41,119
um identities some of us have been given

00:52:39,200 --> 00:52:44,319
so how do we actually

00:52:41,119 --> 00:52:47,280
um up end or or um

00:52:44,319 --> 00:52:49,599
avoid the algorithm uh versions of

00:52:47,280 --> 00:52:52,640
ourselves that we've been ascribed

00:52:49,599 --> 00:52:55,119
so those are the they're small easy

00:52:52,640 --> 00:52:58,319
questions

00:52:55,119 --> 00:53:00,240
but um if any of them speaks to you um

00:52:58,319 --> 00:53:01,839
um i'd love to hear what you have to say

00:53:00,240 --> 00:53:05,119
julia is that

00:53:01,839 --> 00:53:08,319
yeah yes thank you um i

00:53:05,119 --> 00:53:09,280
i will you know take the most difficult

00:53:08,319 --> 00:53:12,480
one

00:53:09,280 --> 00:53:12,960
which is related to how to make sure

00:53:12,480 --> 00:53:16,000
we're

00:53:12,960 --> 00:53:19,280
uh you know bringing in entire paternity

00:53:16,000 --> 00:53:21,760
uh and entire oppression views

00:53:19,280 --> 00:53:23,680
and knowledge and also indigenous

00:53:21,760 --> 00:53:26,880
knowledge i would like to flag

00:53:23,680 --> 00:53:29,920
one a very important uh

00:53:26,880 --> 00:53:32,480
procedure that exists out there so

00:53:29,920 --> 00:53:34,400
the oversight quote which i mentioned is

00:53:32,480 --> 00:53:37,599
a new organization which

00:53:34,400 --> 00:53:39,200
makes decision on content decision made

00:53:37,599 --> 00:53:42,240
by facebook and instagram

00:53:39,200 --> 00:53:45,920
on their platforms and one of the ways

00:53:42,240 --> 00:53:48,880
i mean we really want to foster

00:53:45,920 --> 00:53:49,680
interaction with the public i know the

00:53:48,880 --> 00:53:51,440
public is

00:53:49,680 --> 00:53:52,720
potentially two billion people so it's

00:53:51,440 --> 00:53:56,240
not you know

00:53:52,720 --> 00:53:59,760
possible virtually but we do have

00:53:56,240 --> 00:54:02,880
a uh a channel of communication which is

00:53:59,760 --> 00:54:04,960
through the public comment that we open

00:54:02,880 --> 00:54:07,200
uh for each case that we receive for

00:54:04,960 --> 00:54:08,880
instance we had a public comment period

00:54:07,200 --> 00:54:12,880
that was 10 days i think

00:54:08,880 --> 00:54:15,920
uh for the trump suspension account case

00:54:12,880 --> 00:54:17,839
we received a lot a lot of comments and

00:54:15,920 --> 00:54:19,680
many of them from northern

00:54:17,839 --> 00:54:22,079
institutions and particularly in the

00:54:19,680 --> 00:54:25,280
united states we had another case

00:54:22,079 --> 00:54:28,400
that's related to back blackface on

00:54:25,280 --> 00:54:30,800
on on facebook uh are we allowed to

00:54:28,400 --> 00:54:31,440
uh and particularly on svartipit who is

00:54:30,800 --> 00:54:35,359
a

00:54:31,440 --> 00:54:38,319
traditional uh christmas character

00:54:35,359 --> 00:54:40,640
in the in the in the netherlands and who

00:54:38,319 --> 00:54:42,960
who has been criticized for

00:54:40,640 --> 00:54:44,640
alleged racism and black facing and

00:54:42,960 --> 00:54:46,559
blackface has been

00:54:44,640 --> 00:54:48,240
you know recently facebook rolled out a

00:54:46,559 --> 00:54:50,079
new policy saying blackface is not

00:54:48,240 --> 00:54:52,640
allowed anymore on its platforms

00:54:50,079 --> 00:54:53,359
so uh we invited public comments on that

00:54:52,640 --> 00:54:55,280
as well

00:54:53,359 --> 00:54:57,520
i mean in general in all the cases that

00:54:55,280 --> 00:55:00,799
we have public comments are really

00:54:57,520 --> 00:55:03,440
a great opportunity for us to have

00:55:00,799 --> 00:55:05,119
you know access to another point of view

00:55:03,440 --> 00:55:07,440
that's not from the user

00:55:05,119 --> 00:55:08,559
that's not from facebook or instagram

00:55:07,440 --> 00:55:11,040
but that's you know for

00:55:08,559 --> 00:55:12,000
from organization working on this on the

00:55:11,040 --> 00:55:14,480
on this issue

00:55:12,000 --> 00:55:15,280
and it's it's very it's very helpful

00:55:14,480 --> 00:55:18,839
i'll give you

00:55:15,280 --> 00:55:22,799
one example in a case related to

00:55:18,839 --> 00:55:24,880
um azerbaijan and and armenia there were

00:55:22,799 --> 00:55:27,640
there was a publication published during

00:55:24,880 --> 00:55:30,480
a a conflict that happened in the

00:55:27,640 --> 00:55:31,200
nagorno-karabakh region earlier last

00:55:30,480 --> 00:55:34,000
year

00:55:31,200 --> 00:55:34,960
and uh we received a comment saying

00:55:34,000 --> 00:55:36,799
telling us that

00:55:34,960 --> 00:55:38,240
well you know in a case of conflict

00:55:36,799 --> 00:55:41,119
international human rights

00:55:38,240 --> 00:55:42,000
usually allows or is more permissible

00:55:41,119 --> 00:55:45,440
with regards

00:55:42,000 --> 00:55:48,480
to using you know very inflammatory

00:55:45,440 --> 00:55:50,400
words insults and all this we did i

00:55:48,480 --> 00:55:52,079
didn't know that personally and i found

00:55:50,400 --> 00:55:55,119
it very compelling and helpful

00:55:52,079 --> 00:55:56,960
so just to give an example of how we can

00:55:55,119 --> 00:55:58,160
you know deconstruct our preconceived

00:55:56,960 --> 00:56:00,480
ideas too as

00:55:58,160 --> 00:56:03,119
uh oversight board members and look at

00:56:00,480 --> 00:56:03,359
cases differently based on contributions

00:56:03,119 --> 00:56:05,200
and

00:56:03,359 --> 00:56:06,720
comments that we received from

00:56:05,200 --> 00:56:09,440
individuals or for

00:56:06,720 --> 00:56:09,440
institutions

00:56:10,880 --> 00:56:14,559
thank you um we have three minutes left

00:56:13,680 --> 00:56:18,240
sarah

00:56:14,559 --> 00:56:19,599
please take us give us your response to

00:56:18,240 --> 00:56:21,119
any of those questions tell us which

00:56:19,599 --> 00:56:24,880
ones you're answering

00:56:21,119 --> 00:56:27,359
um sure just on the blackface uh issue

00:56:24,880 --> 00:56:30,000
uh in in this book in the english or

00:56:27,359 --> 00:56:32,640
french edition whatever is your pleasure

00:56:30,000 --> 00:56:33,760
there is a content moderator working at

00:56:32,640 --> 00:56:37,280
mega tech

00:56:33,760 --> 00:56:38,319
who raises this issue uh starting in

00:56:37,280 --> 00:56:40,400
00:56:38,319 --> 00:56:41,760
and so there's these other points of

00:56:40,400 --> 00:56:43,760
input that we can

00:56:41,760 --> 00:56:45,280
bring to the table about who sees

00:56:43,760 --> 00:56:48,400
problems and who

00:56:45,280 --> 00:56:49,839
who who has foresight and commercial

00:56:48,400 --> 00:56:52,000
content moderators at

00:56:49,839 --> 00:56:53,760
firms whether they are are located at

00:56:52,000 --> 00:56:55,599
the firms or whether they are

00:56:53,760 --> 00:56:56,880
at geographical and organizational

00:56:55,599 --> 00:56:59,520
remove as uh

00:56:56,880 --> 00:57:00,079
contractors have incredible insight and

00:56:59,520 --> 00:57:01,760
knowledge

00:57:00,079 --> 00:57:03,520
about these things and yet that

00:57:01,760 --> 00:57:04,640
knowledge has gone directly to the

00:57:03,520 --> 00:57:08,000
garbage can

00:57:04,640 --> 00:57:09,359
in most cases so i i want to acknowledge

00:57:08,000 --> 00:57:11,599
the work that they do

00:57:09,359 --> 00:57:13,760
and the kinds of information they also

00:57:11,599 --> 00:57:16,960
have that has been

00:57:13,760 --> 00:57:18,480
pretty much uh not taken up and who does

00:57:16,960 --> 00:57:20,480
commercial content moderation well it's

00:57:18,480 --> 00:57:23,119
some of the very people that we are

00:57:20,480 --> 00:57:24,160
concerned with uh in this conversation

00:57:23,119 --> 00:57:27,440
that we've had

00:57:24,160 --> 00:57:30,319
um with apologies to audre lorde

00:57:27,440 --> 00:57:31,839
uh the master's tools will not dismantle

00:57:30,319 --> 00:57:34,240
the master's house

00:57:31,839 --> 00:57:35,359
we are in a paradigm where tech defines

00:57:34,240 --> 00:57:38,640
not only

00:57:35,359 --> 00:57:40,240
the answers but the problems and so what

00:57:38,640 --> 00:57:43,440
i would urge everyone to do

00:57:40,240 --> 00:57:46,000
is to um push back on that framing and

00:57:43,440 --> 00:57:48,000
we we will take the power to ask our own

00:57:46,000 --> 00:57:50,720
questions and answer them

00:57:48,000 --> 00:57:51,920
appropriately using the expertise and

00:57:50,720 --> 00:57:54,559
knowledge we have from our lived

00:57:51,920 --> 00:57:57,040
experience from our communities

00:57:54,559 --> 00:57:57,760
from indigenous ways of knowing all the

00:57:57,040 --> 00:57:59,680
places

00:57:57,760 --> 00:58:01,440
that have historically and continue to

00:57:59,680 --> 00:58:05,119
be ignored and denied

00:58:01,440 --> 00:58:07,680
so i i refute um being in a space where

00:58:05,119 --> 00:58:11,040
i respond to the problems that tech

00:58:07,680 --> 00:58:13,119
creates and then asks us to fix

00:58:11,040 --> 00:58:14,559
and then also doesn't take up what we

00:58:13,119 --> 00:58:16,240
have to say by the way

00:58:14,559 --> 00:58:17,839
so i will say we bring we're going to

00:58:16,240 --> 00:58:21,280
bring new

00:58:17,839 --> 00:58:22,640
questions and answers not maybe even not

00:58:21,280 --> 00:58:26,160
to the table as you said

00:58:22,640 --> 00:58:28,319
earlier thank you to another place

00:58:26,160 --> 00:58:30,079
right on we're at time so i want to give

00:58:28,319 --> 00:58:32,240
sierra and you got

00:58:30,079 --> 00:58:36,640
a word if you'd like to bring anything

00:58:32,240 --> 00:58:38,480
into the room

00:58:36,640 --> 00:58:39,760
i just want to plus one everything that

00:58:38,480 --> 00:58:42,880
was already

00:58:39,760 --> 00:58:44,559
right on my god yeah same here

00:58:42,880 --> 00:58:46,640
again to everything whatever has has

00:58:44,559 --> 00:58:49,440
been said beautiful

00:58:46,640 --> 00:58:50,640
thank you so much sierra julie negot

00:58:49,440 --> 00:58:53,280
sarah for joining us

00:58:50,640 --> 00:58:53,920
thank you all out there for joining us

00:58:53,280 --> 00:58:57,119
remember

00:58:53,920 --> 00:59:00,400
that um power is already ours and

00:58:57,119 --> 00:59:03,680
this is about actually um um stepping up

00:59:00,400 --> 00:59:04,559
uh in in community in collaboration and

00:59:03,680 --> 00:59:06,400
in purpose

00:59:04,559 --> 00:59:07,760
to exercise that power so thanks

00:59:06,400 --> 00:59:19,839
everyone and

00:59:07,760 --> 00:59:19,839
see you at the rest of mazfest

01:00:03,760 --> 01:00:05,839

YouTube URL: https://www.youtube.com/watch?v=x1NYw0Q7BCs


