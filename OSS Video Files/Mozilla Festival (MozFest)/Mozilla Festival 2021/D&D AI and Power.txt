Title: D&D AI and Power
Publication date: 2021-03-08
Playlist: Mozilla Festival 2021
Description: 
	The AI in our daily lives reinforces historical power imbalances — across gender, across race, and across class. Is it possible to make more just AI systems mainstream? A panel featuring:

Cierra Robson, Associate Director of the Ida B. Wells JUST Data Lab at Princeton University

Dr. Sarah Roberts, Co-Director, UCLA Center for Critical Internet Inquiry

Nighat Dad, Executive Director, Digital Rights Foundation

Julie Owono, Executive Director, Internet Sans Frontières

And moderator J. Bob Alotta, Mozilla's VP of Global Programs
Captions: 
	00:00:00,960 --> 00:00:04,880
hi everyone um thank you for joining us

00:00:03,280 --> 00:00:06,640
today i'm jay babalota

00:00:04,880 --> 00:00:08,400
i'm the vice president of global

00:00:06,640 --> 00:00:10,320
programs at mozilla and i'm going to be

00:00:08,400 --> 00:00:13,440
your host for today's panel

00:00:10,320 --> 00:00:14,400
um we have a vital discussion planned

00:00:13,440 --> 00:00:16,640
for today

00:00:14,400 --> 00:00:17,520
as part of mozfest's dialogues and

00:00:16,640 --> 00:00:19,039
debates

00:00:17,520 --> 00:00:20,720
we're going to unpack an issue that's

00:00:19,039 --> 00:00:21,439
underpinning so many of the problems

00:00:20,720 --> 00:00:23,199
online

00:00:21,439 --> 00:00:24,640
and offline today the relationship

00:00:23,199 --> 00:00:27,840
between ai

00:00:24,640 --> 00:00:30,080
and power the ai in our lives

00:00:27,840 --> 00:00:33,120
reinforces historical power imbalances

00:00:30,080 --> 00:00:35,680
across gender across race across class

00:00:33,120 --> 00:00:37,040
there are so many examples to list but

00:00:35,680 --> 00:00:39,520
here are a few

00:00:37,040 --> 00:00:40,239
hiring algorithms prior prioritize men

00:00:39,520 --> 00:00:42,320
over women

00:00:40,239 --> 00:00:44,480
and non-binary candidates facial

00:00:42,320 --> 00:00:46,559
recognition systems misidentified black

00:00:44,480 --> 00:00:49,760
faces and i would argue also that

00:00:46,559 --> 00:00:51,120
zoom backgrounds don't uh allow for

00:00:49,760 --> 00:00:52,879
black folks to use

00:00:51,120 --> 00:00:54,399
a zoom background without becoming part

00:00:52,879 --> 00:00:57,600
of the background as we

00:00:54,399 --> 00:00:58,879
just discovered 30 seconds ago and a

00:00:57,600 --> 00:01:00,079
year into the pandemic we could have

00:00:58,879 --> 00:01:03,280
gotten that right by now

00:01:00,079 --> 00:01:05,519
facial recognition systems uh um and

00:01:03,280 --> 00:01:07,760
voice assistants like alex and siri

00:01:05,519 --> 00:01:09,600
struggle to understand the voices of so

00:01:07,760 --> 00:01:11,920
many diasporas

00:01:09,600 --> 00:01:12,720
ai-powered digital ads can prey on or

00:01:11,920 --> 00:01:15,520
exclude

00:01:12,720 --> 00:01:17,280
those who have the least we're going to

00:01:15,520 --> 00:01:18,880
unpack all of this today but we're also

00:01:17,280 --> 00:01:20,799
going to ask is it possible to

00:01:18,880 --> 00:01:24,479
mainstream ai systems

00:01:20,799 --> 00:01:25,360
which are actually just today i am

00:01:24,479 --> 00:01:27,280
joined by

00:01:25,360 --> 00:01:28,799
a number of fantastic colleagues i'm

00:01:27,280 --> 00:01:32,000
really uh honored

00:01:28,799 --> 00:01:34,400
to be on screen with y'all dr

00:01:32,000 --> 00:01:36,000
sarah roberts is an associate professor

00:01:34,400 --> 00:01:37,840
at the university of california

00:01:36,000 --> 00:01:39,600
los angeles in the department of

00:01:37,840 --> 00:01:40,720
information studies where she serves as

00:01:39,600 --> 00:01:43,119
the co-director

00:01:40,720 --> 00:01:44,159
of the ucla center for critical uh

00:01:43,119 --> 00:01:47,280
internet inquiry

00:01:44,159 --> 00:01:47,840
welcome sierra robson uh the associate

00:01:47,280 --> 00:01:50,240
director

00:01:47,840 --> 00:01:52,159
of the idb wells just data lab at

00:01:50,240 --> 00:01:54,000
princeton university where she guides

00:01:52,159 --> 00:01:56,719
research teams in partnership

00:01:54,000 --> 00:01:58,799
with community organizations to explore

00:01:56,719 --> 00:02:00,880
how data can be retooled for racial

00:01:58,799 --> 00:02:03,040
justice welcome sierra

00:02:00,880 --> 00:02:04,880
julia omono is a lawyer and executive

00:02:03,040 --> 00:02:05,520
director of paris based digital rights

00:02:04,880 --> 00:02:08,640
organization

00:02:05,520 --> 00:02:12,400
international frontiers um

00:02:08,640 --> 00:02:13,920
i made it spanish i'm sorry um julie

00:02:12,400 --> 00:02:16,239
i could have practiced that i actually

00:02:13,920 --> 00:02:18,000
let's go practice your french in the

00:02:16,239 --> 00:02:19,920
bathroom julie's work focuses

00:02:18,000 --> 00:02:21,360
on building bridges and creating

00:02:19,920 --> 00:02:22,640
channels of collaboration between

00:02:21,360 --> 00:02:24,640
various actors

00:02:22,640 --> 00:02:26,560
of the digital space to foster the

00:02:24,640 --> 00:02:28,160
development of an internet that benefits

00:02:26,560 --> 00:02:29,520
everyone all over the world welcome

00:02:28,160 --> 00:02:31,920
julie

00:02:29,520 --> 00:02:33,920
and nigatad is the executive director of

00:02:31,920 --> 00:02:35,840
the digital rights foundation night

00:02:33,920 --> 00:02:37,360
is one of the pioneer women's rights

00:02:35,840 --> 00:02:39,280
activists in pakistan

00:02:37,360 --> 00:02:41,599
and has played a pivotal role in

00:02:39,280 --> 00:02:42,480
defining the cyberspace narrative in the

00:02:41,599 --> 00:02:45,920
country

00:02:42,480 --> 00:02:47,920
welcome and one last thing we're taking

00:02:45,920 --> 00:02:49,120
questions for this panel in real time so

00:02:47,920 --> 00:02:51,760
you can tweet them

00:02:49,120 --> 00:02:52,239
at mozilla with the hashtag dialogues

00:02:51,760 --> 00:02:55,280
and

00:02:52,239 --> 00:02:56,480
debates spelled out so this is a

00:02:55,280 --> 00:02:59,040
conversation

00:02:56,480 --> 00:03:00,720
i'm going to feel the question to to

00:02:59,040 --> 00:03:01,440
each one of our panelists but to the

00:03:00,720 --> 00:03:04,560
other

00:03:01,440 --> 00:03:07,200
panelists after our initial uh

00:03:04,560 --> 00:03:08,319
uh panelist takes a stab at an answer

00:03:07,200 --> 00:03:11,599
please feel free

00:03:08,319 --> 00:03:12,319
to chime in um and i'll move us along by

00:03:11,599 --> 00:03:14,879
taking

00:03:12,319 --> 00:03:15,840
facilitated privilege but um i don't

00:03:14,879 --> 00:03:18,159
want to squash any

00:03:15,840 --> 00:03:20,640
any conversation so please do feel free

00:03:18,159 --> 00:03:24,959
to engage one another

00:03:20,640 --> 00:03:28,640
um so let's start with some context

00:03:24,959 --> 00:03:31,519
this panel is entitled ai and power

00:03:28,640 --> 00:03:32,159
right now who wields power in the realm

00:03:31,519 --> 00:03:34,720
of ai

00:03:32,159 --> 00:03:37,200
and who doesn't negot do you want to

00:03:34,720 --> 00:03:39,519
kick us off

00:03:37,200 --> 00:03:40,400
sure um first of all thank you so much

00:03:39,519 --> 00:03:43,519
for having me

00:03:40,400 --> 00:03:45,360
and having a voice from a place where we

00:03:43,519 --> 00:03:46,560
usually don't have these conversations

00:03:45,360 --> 00:03:49,680
so

00:03:46,560 --> 00:03:52,959
i'm glad that someone from pakistan

00:03:49,680 --> 00:03:55,200
is actually talking about ai and power

00:03:52,959 --> 00:03:56,319
and you asked a question who actually

00:03:55,200 --> 00:03:58,239
has the power

00:03:56,319 --> 00:04:00,879
the one group that doesn't yield any

00:03:58,239 --> 00:04:04,159
power in ai is the

00:04:00,879 --> 00:04:05,200
end user and consumer the average

00:04:04,159 --> 00:04:09,280
internet user

00:04:05,200 --> 00:04:11,840
and netizen um it's the users data that

00:04:09,280 --> 00:04:12,560
that is collected and sold and except

00:04:11,840 --> 00:04:15,120
for the

00:04:12,560 --> 00:04:16,079
global north and a few developing

00:04:15,120 --> 00:04:19,120
countries

00:04:16,079 --> 00:04:20,239
most users do not know what their

00:04:19,120 --> 00:04:22,079
digital rights are

00:04:20,239 --> 00:04:24,639
and you know i'm i'm speaking from the

00:04:22,079 --> 00:04:27,840
perspective and the context of pakistan

00:04:24,639 --> 00:04:30,880
and really are they enshrined and

00:04:27,840 --> 00:04:34,000
protected in our laws or constitution

00:04:30,880 --> 00:04:35,280
so this collected data is fed into that

00:04:34,000 --> 00:04:38,000
databases

00:04:35,280 --> 00:04:39,280
that then targets the users through ai

00:04:38,000 --> 00:04:41,520
internet giants

00:04:39,280 --> 00:04:43,040
governments and social media companies

00:04:41,520 --> 00:04:45,600
become more and more powerful

00:04:43,040 --> 00:04:47,440
and the average user is left with fewer

00:04:45,600 --> 00:04:50,800
and fewer avenues and way to

00:04:47,440 --> 00:04:53,840
exert their power minus the end user

00:04:50,800 --> 00:04:55,199
everyone in the digital ecosystem gains

00:04:53,840 --> 00:04:57,759
power through ai

00:04:55,199 --> 00:04:58,800
um the only difference is that each

00:04:57,759 --> 00:05:00,720
stakeholder

00:04:58,800 --> 00:05:02,400
yields different amounts of power and

00:05:00,720 --> 00:05:04,560
control uh

00:05:02,400 --> 00:05:05,600
social media companies and tech giants

00:05:04,560 --> 00:05:07,919
have spun

00:05:05,600 --> 00:05:09,199
a deeply internet connected in

00:05:07,919 --> 00:05:11,280
interconnected web of

00:05:09,199 --> 00:05:12,960
data sharing that gives them immense

00:05:11,280 --> 00:05:15,199
power over the internet

00:05:12,960 --> 00:05:16,880
and internet users and now with

00:05:15,199 --> 00:05:20,000
governments entering

00:05:16,880 --> 00:05:21,360
uh this equation this power and data is

00:05:20,000 --> 00:05:23,600
also being shared with them

00:05:21,360 --> 00:05:26,800
so in usual circumstances governments

00:05:23,600 --> 00:05:29,840
are already powerful entities however

00:05:26,800 --> 00:05:33,360
when we add this ai into this equation

00:05:29,840 --> 00:05:35,840
their power increases exponentially

00:05:33,360 --> 00:05:38,479
data and online behavior gives the

00:05:35,840 --> 00:05:40,400
government the ability to identify

00:05:38,479 --> 00:05:42,320
how to target individuals and how to

00:05:40,400 --> 00:05:44,320
control narratives online

00:05:42,320 --> 00:05:46,240
and if we go a little further in this

00:05:44,320 --> 00:05:49,360
debate of power i think it's very

00:05:46,240 --> 00:05:52,639
important for us to examine the bias

00:05:49,360 --> 00:05:54,160
in ai and how these biases mainly stem

00:05:52,639 --> 00:05:57,199
from human

00:05:54,160 --> 00:05:58,560
humans inherent biases the models and

00:05:57,199 --> 00:06:01,199
systems we create

00:05:58,560 --> 00:06:03,600
and train are a reflection of ourselves

00:06:01,199 --> 00:06:05,600
and extremely important for us to see

00:06:03,600 --> 00:06:07,120
who is designing and training ai and

00:06:05,600 --> 00:06:09,600
which part of the world

00:06:07,120 --> 00:06:11,919
you know they are designing ai be it a

00:06:09,600 --> 00:06:15,520
tech giant social media company

00:06:11,919 --> 00:06:15,520
or uh within a government

00:06:17,680 --> 00:06:21,039
thank you yeah that anybody else

00:06:19,840 --> 00:06:23,360
want to respond

00:06:21,039 --> 00:06:23,360
um

00:06:24,639 --> 00:06:28,000
i think uh one thing that i want to

00:06:26,319 --> 00:06:30,319
offer up in in

00:06:28,000 --> 00:06:32,080
into the when we're talking about power

00:06:30,319 --> 00:06:34,000
and we're talking about bias and then

00:06:32,080 --> 00:06:37,600
also what it means for just this group

00:06:34,000 --> 00:06:40,400
of folks to be um uh having

00:06:37,600 --> 00:06:41,280
uh the opportunity for us all to speak

00:06:40,400 --> 00:06:44,400
together

00:06:41,280 --> 00:06:47,039
is um um

00:06:44,400 --> 00:06:48,960
oftentimes if if we're the voices who

00:06:47,039 --> 00:06:49,840
have to combat the bias what is it

00:06:48,960 --> 00:06:52,240
actually where are

00:06:49,840 --> 00:06:53,919
where's the original thought and where

00:06:52,240 --> 00:06:54,880
that we'd actually don't have the room

00:06:53,919 --> 00:06:57,680
or the space

00:06:54,880 --> 00:06:58,240
to bring forward in that right so if the

00:06:57,680 --> 00:07:00,880
onus

00:06:58,240 --> 00:07:02,720
is on the folks who are actually bearing

00:07:00,880 --> 00:07:05,840
the brunt of that bias

00:07:02,720 --> 00:07:08,560
to showcase that bias where's the

00:07:05,840 --> 00:07:10,240
invention and the incentive um for that

00:07:08,560 --> 00:07:11,680
to actually come forward and so we're

00:07:10,240 --> 00:07:14,880
losing out twice

00:07:11,680 --> 00:07:18,160
um and and that that that's the impact

00:07:14,880 --> 00:07:18,160
of that bias on everyone

00:07:19,039 --> 00:07:23,919
um and we know that the power imbalance

00:07:22,080 --> 00:07:26,240
can't be fixed simply by

00:07:23,919 --> 00:07:27,759
tweaking code or enacting a single new

00:07:26,240 --> 00:07:29,919
law right power and

00:07:27,759 --> 00:07:32,319
inequalities are baked into the systems

00:07:29,919 --> 00:07:34,240
and the data that powers them

00:07:32,319 --> 00:07:35,440
but i'm curious about how deep the

00:07:34,240 --> 00:07:38,560
problem goes

00:07:35,440 --> 00:07:40,479
um sierra do you think you can um

00:07:38,560 --> 00:07:41,759
shine some light on it the subject for

00:07:40,479 --> 00:07:43,520
us yeah

00:07:41,759 --> 00:07:45,120
absolutely first of all thank you so

00:07:43,520 --> 00:07:46,960
much for including me in this

00:07:45,120 --> 00:07:48,560
conversation i'm so excited to be here

00:07:46,960 --> 00:07:50,879
with you all um

00:07:48,560 --> 00:07:52,319
to get to the question one of the things

00:07:50,879 --> 00:07:55,039
that we have to think about

00:07:52,319 --> 00:07:55,440
is how even those technologies that are

00:07:55,039 --> 00:07:57,280
not

00:07:55,440 --> 00:07:59,759
meant to reinforce power inequalities

00:07:57,280 --> 00:08:01,520
can still end up doing so

00:07:59,759 --> 00:08:04,160
so the tools that are fundamentally

00:08:01,520 --> 00:08:04,400
built to reduce harm can often reinforce

00:08:04,160 --> 00:08:06,560
it

00:08:04,400 --> 00:08:08,400
and one good example of this is

00:08:06,560 --> 00:08:11,599
pre-trial risk assessment tools

00:08:08,400 --> 00:08:14,319
so algorithms judges use

00:08:11,599 --> 00:08:15,039
to determine a defender's uh of a

00:08:14,319 --> 00:08:17,280
defendant's

00:08:15,039 --> 00:08:18,160
risk of reoffense before a sentencing

00:08:17,280 --> 00:08:20,560
hearing

00:08:18,160 --> 00:08:21,440
in many states this was heralded as a

00:08:20,560 --> 00:08:24,479
solution

00:08:21,440 --> 00:08:26,879
to cash bail which many people know has

00:08:24,479 --> 00:08:28,400
lots of issues and often reinforces

00:08:26,879 --> 00:08:30,319
like income inequality wealth and

00:08:28,400 --> 00:08:32,000
equality um

00:08:30,319 --> 00:08:34,399
but they don't understand the ways in

00:08:32,000 --> 00:08:35,519
which these algorithms can also

00:08:34,399 --> 00:08:37,599
reinforce

00:08:35,519 --> 00:08:39,440
all sorts of different things so

00:08:37,599 --> 00:08:41,599
pre-trial risk assessments were proposed

00:08:39,440 --> 00:08:43,839
as this technological solution

00:08:41,599 --> 00:08:45,200
but those who were deemed most risky

00:08:43,839 --> 00:08:47,040
would be put in prison

00:08:45,200 --> 00:08:48,959
until their hearing and everyone else

00:08:47,040 --> 00:08:51,040
would be allowed to to

00:08:48,959 --> 00:08:52,880
await their child but in the first

00:08:51,040 --> 00:08:54,720
iteration many of these tools included

00:08:52,880 --> 00:08:56,800
race races predictive variables many of

00:08:54,720 --> 00:08:58,640
them included zip codes many of them

00:08:56,800 --> 00:08:59,200
included things like do you own a cell

00:08:58,640 --> 00:09:02,560
phone

00:08:59,200 --> 00:09:04,240
or do you pay rent in their variables

00:09:02,560 --> 00:09:04,880
that they use to predict whether or not

00:09:04,240 --> 00:09:08,000
someone would

00:09:04,880 --> 00:09:09,760
be deemed risky and they people

00:09:08,000 --> 00:09:12,000
quickly realized that this produced

00:09:09,760 --> 00:09:14,320
discriminatory results

00:09:12,000 --> 00:09:16,399
so these categories were then excluded

00:09:14,320 --> 00:09:18,480
but then new categories came up as

00:09:16,399 --> 00:09:20,800
proxies for things like race

00:09:18,480 --> 00:09:22,240
and so what does all of this mean in

00:09:20,800 --> 00:09:23,120
short it means that tweaking code

00:09:22,240 --> 00:09:26,240
doesn't

00:09:23,120 --> 00:09:27,839
rid systems of bias or power instead we

00:09:26,240 --> 00:09:30,080
have to really think about what the

00:09:27,839 --> 00:09:31,680
tools are meant to do at their inception

00:09:30,080 --> 00:09:33,040
and technological tools

00:09:31,680 --> 00:09:34,959
will not be able to solve social

00:09:33,040 --> 00:09:36,560
problems on their own and we really

00:09:34,959 --> 00:09:38,640
should stop asking them to do so and

00:09:36,560 --> 00:09:40,959
instead build tools from the ground up

00:09:38,640 --> 00:09:50,880
that are supposed to help the world in

00:09:40,959 --> 00:09:54,000
the ways that we want them to

00:09:50,880 --> 00:09:57,040
i want all of the um participates

00:09:54,000 --> 00:10:01,360
in the conversation i um to

00:09:57,040 --> 00:10:04,640
to um lean into uh

00:10:01,360 --> 00:10:07,200
being being in conversation with one yes

00:10:04,640 --> 00:10:09,040
i just wanted i just wanted to uh double

00:10:07,200 --> 00:10:12,800
down on what sierra

00:10:09,040 --> 00:10:15,440
just said um we we tend to focus a lot

00:10:12,800 --> 00:10:18,399
of the conversation recently around

00:10:15,440 --> 00:10:19,040
ai and its biases on technical solutions

00:10:18,399 --> 00:10:22,000
but we

00:10:19,040 --> 00:10:22,320
actually forget what sierra and what we

00:10:22,000 --> 00:10:25,120
got

00:10:22,320 --> 00:10:26,399
also said previously is that the digital

00:10:25,120 --> 00:10:30,240
world is just a mirror

00:10:26,399 --> 00:10:34,079
of whatever already exists uh offline

00:10:30,240 --> 00:10:36,720
so it's um we shouldn't you know

00:10:34,079 --> 00:10:39,279
stop ourselves from having those very

00:10:36,720 --> 00:10:39,839
serious conversations too on how racist

00:10:39,279 --> 00:10:43,279
our

00:10:39,839 --> 00:10:46,000
societies are on our sexes they are hi

00:10:43,279 --> 00:10:46,480
happy international women's day on how

00:10:46,000 --> 00:10:48,640
um

00:10:46,480 --> 00:10:50,000
you know transphobic they are and all

00:10:48,640 --> 00:10:51,760
the the the

00:10:50,000 --> 00:10:53,120
very negative things that we see

00:10:51,760 --> 00:10:55,680
reproduced online

00:10:53,120 --> 00:10:56,160
so i just wanted to to chime in and say

00:10:55,680 --> 00:10:59,200
that

00:10:56,160 --> 00:11:01,200
in this machine in in this era in which

00:10:59,200 --> 00:11:02,160
a machine is going to basically make

00:11:01,200 --> 00:11:04,480
decisions

00:11:02,160 --> 00:11:06,480
and is making decisions on human

00:11:04,480 --> 00:11:09,200
interaction and human-produced content

00:11:06,480 --> 00:11:10,000
it's really time for us to go beyond the

00:11:09,200 --> 00:11:12,240
machine

00:11:10,000 --> 00:11:14,000
and bring back the human within this

00:11:12,240 --> 00:11:17,680
this conversation it's absolutely

00:11:14,000 --> 00:11:19,839
important sarah i saw your henry's

00:11:17,680 --> 00:11:21,040
yeah i mean i think that's an excellent

00:11:19,839 --> 00:11:22,720
segue and

00:11:21,040 --> 00:11:24,160
i'd love to just pick that one up

00:11:22,720 --> 00:11:25,920
because um

00:11:24,160 --> 00:11:28,880
you know essentially i think it's what

00:11:25,920 --> 00:11:30,240
i'm uh charged with speaking a bit about

00:11:28,880 --> 00:11:34,240
on today's panel

00:11:30,240 --> 00:11:37,120
and that is to actually uh

00:11:34,240 --> 00:11:39,680
on some levels fundamentally ask the

00:11:37,120 --> 00:11:40,720
question what do we mean when we say ai

00:11:39,680 --> 00:11:42,720
anyway right

00:11:40,720 --> 00:11:44,399
so there are all these received notions

00:11:42,720 --> 00:11:46,160
right now within

00:11:44,399 --> 00:11:48,160
um not only within just like the

00:11:46,160 --> 00:11:49,200
zeitgeist you know within our media

00:11:48,160 --> 00:11:51,279
sphere

00:11:49,200 --> 00:11:53,200
in conversation with each other as

00:11:51,279 --> 00:11:56,720
advocates um

00:11:53,200 --> 00:11:58,720
and and off times critics but that

00:11:56,720 --> 00:11:59,839
that question of what is ai what

00:11:58,720 --> 00:12:02,880
constitutes ai

00:11:59,839 --> 00:12:06,480
is in fact um a a

00:12:02,880 --> 00:12:10,160
standing problem space uh

00:12:06,480 --> 00:12:11,760
within computer science okay both in

00:12:10,160 --> 00:12:14,639
you know in the theater in the

00:12:11,760 --> 00:12:17,760
theoretical side of of computer science

00:12:14,639 --> 00:12:21,279
and in its application and so um

00:12:17,760 --> 00:12:23,120
this kind of this dilemma about what

00:12:21,279 --> 00:12:25,760
constitutes

00:12:23,120 --> 00:12:27,760
artificial intelligence was present at

00:12:25,760 --> 00:12:30,959
the birth of the field and it was

00:12:27,760 --> 00:12:34,399
you know in some fundamental papers by

00:12:30,959 --> 00:12:37,760
uh by the key kinds of

00:12:34,399 --> 00:12:40,079
uh computer scientists

00:12:37,760 --> 00:12:41,120
of the day you know they they actually

00:12:40,079 --> 00:12:43,839
stated that

00:12:41,120 --> 00:12:45,760
part of the problem with artificial

00:12:43,839 --> 00:12:47,760
intelligence

00:12:45,760 --> 00:12:48,800
precedes artificial intelligence it's

00:12:47,760 --> 00:12:51,600
the question of

00:12:48,800 --> 00:12:53,600
what constitutes intelligence full stop

00:12:51,600 --> 00:12:55,120
what constitutes intelligence within the

00:12:53,600 --> 00:12:57,440
realm of the human

00:12:55,120 --> 00:12:59,360
and then you know if that problem or if

00:12:57,440 --> 00:13:00,320
that if that definition is somewhat

00:12:59,360 --> 00:13:03,360
fuzzy

00:13:00,320 --> 00:13:05,440
unclear contested uh

00:13:03,360 --> 00:13:07,200
then what does it mean therefore that

00:13:05,440 --> 00:13:11,200
this kind of nebulous

00:13:07,200 --> 00:13:14,720
notion is picked up and um

00:13:11,200 --> 00:13:16,560
by by a definition

00:13:14,720 --> 00:13:18,560
abstracted and then put into

00:13:16,560 --> 00:13:21,920
implementation this was

00:13:18,560 --> 00:13:24,639
this was a an issue for foreseen uh

00:13:21,920 --> 00:13:26,399
by the uh by some of the uh the the

00:13:24,639 --> 00:13:29,040
founders of this field

00:13:26,399 --> 00:13:29,440
and all the way up till till today we

00:13:29,040 --> 00:13:32,880
have

00:13:29,440 --> 00:13:36,160
um uh you know very important

00:13:32,880 --> 00:13:39,920
uh kind of industry facing

00:13:36,160 --> 00:13:42,480
uh bodies and and uh

00:13:39,920 --> 00:13:44,079
uh thinkers in the form of you know just

00:13:42,480 --> 00:13:45,199
the one that's on my mind is the

00:13:44,079 --> 00:13:48,480
o'reilly group

00:13:45,199 --> 00:13:50,560
um kind of still adequately acknowledge

00:13:48,480 --> 00:13:52,240
you know acknowledging still adequately

00:13:50,560 --> 00:13:56,399
trying to define

00:13:52,240 --> 00:14:00,000
uh what what this is and you know again

00:13:56,399 --> 00:14:00,639
drawing down on this issue of what ai is

00:14:00,000 --> 00:14:03,120
they say

00:14:00,639 --> 00:14:05,120
not only is it difficult to define it's

00:14:03,120 --> 00:14:06,480
actually impossible to do especially

00:14:05,120 --> 00:14:08,880
without falling into

00:14:06,480 --> 00:14:10,560
you know tautologies and in a kind of

00:14:08,880 --> 00:14:13,760
like these self-referential

00:14:10,560 --> 00:14:17,760
um uh intractable uh

00:14:13,760 --> 00:14:20,000
circles so i i think it's important as

00:14:17,760 --> 00:14:22,160
some of my my colleagues have already

00:14:20,000 --> 00:14:23,279
said that we step you know sierra was

00:14:22,160 --> 00:14:26,399
just saying we can't

00:14:23,279 --> 00:14:28,800
um critique the ai piece if we don't

00:14:26,399 --> 00:14:30,560
really understand what the systems are

00:14:28,800 --> 00:14:33,120
that are in play and what the

00:14:30,560 --> 00:14:34,399
fundamental social issues are that are

00:14:33,120 --> 00:14:37,920
feeding into that

00:14:34,399 --> 00:14:41,680
whether it's overtly sometimes

00:14:37,920 --> 00:14:43,839
but more importantly and more worrisome

00:14:41,680 --> 00:14:45,519
in an insidious fashion because we don't

00:14:43,839 --> 00:14:47,120
we don't even know how to adequately

00:14:45,519 --> 00:14:49,519
address these issues

00:14:47,120 --> 00:14:51,040
uh and attend to them as a as a social

00:14:49,519 --> 00:14:52,160
collective there are many of us who do

00:14:51,040 --> 00:14:54,959
work on them right

00:14:52,160 --> 00:14:57,199
but we we're in a in a fight around that

00:14:54,959 --> 00:14:59,839
in a fight to constantly prove

00:14:57,199 --> 00:15:00,880
um that some of these uh social forces

00:14:59,839 --> 00:15:02,959
are at play

00:15:00,880 --> 00:15:05,120
and are causing harm now that gets

00:15:02,959 --> 00:15:07,279
picked up and packaged up into ai

00:15:05,120 --> 00:15:08,160
and pushed out and i guess one of the

00:15:07,279 --> 00:15:10,720
greatest

00:15:08,160 --> 00:15:11,440
concerns there is we take these already

00:15:10,720 --> 00:15:14,959
um

00:15:11,440 --> 00:15:18,959
very hard to demonstrate

00:15:14,959 --> 00:15:20,320
systems of power and we create a huge

00:15:18,959 --> 00:15:24,079
layer of opacity

00:15:20,320 --> 00:15:26,240
around them and then we further

00:15:24,079 --> 00:15:28,320
automate them and give them incredible

00:15:26,240 --> 00:15:30,639
power to be reproduced

00:15:28,320 --> 00:15:32,079
and so that's where we sit with ai and

00:15:30,639 --> 00:15:33,839
the last comment i'll make

00:15:32,079 --> 00:15:36,240
about my own work and my own

00:15:33,839 --> 00:15:39,199
intervention in thinking in the space

00:15:36,240 --> 00:15:40,959
is simply um within the realm of

00:15:39,199 --> 00:15:42,399
commercial content moderation where we

00:15:40,959 --> 00:15:44,560
have heard for years

00:15:42,399 --> 00:15:46,000
uh from the firms and from others that

00:15:44,560 --> 00:15:49,600
kind of the way out

00:15:46,000 --> 00:15:51,600
of the horror of doing this work and its

00:15:49,600 --> 00:15:53,120
psychological consequence will be

00:15:51,600 --> 00:15:55,759
deliverance via

00:15:53,120 --> 00:15:57,040
ai and other kinds of automated content

00:15:55,759 --> 00:15:59,040
moderation tools

00:15:57,040 --> 00:16:00,480
but again i've just you know i hopefully

00:15:59,040 --> 00:16:02,160
convinced everyone that what we're

00:16:00,480 --> 00:16:03,199
dealing with is a very blunt kind of

00:16:02,160 --> 00:16:06,720
instrument

00:16:03,199 --> 00:16:07,680
that is in fact incredibly unintelligent

00:16:06,720 --> 00:16:10,240
in many cases

00:16:07,680 --> 00:16:12,079
it will do exactly what it's programmed

00:16:10,240 --> 00:16:14,800
to do which is often

00:16:12,079 --> 00:16:16,399
going to create more and more and new

00:16:14,800 --> 00:16:17,440
and different kind of errors they might

00:16:16,399 --> 00:16:19,279
be different

00:16:17,440 --> 00:16:21,519
um they might be errors that humans

00:16:19,279 --> 00:16:23,920
wouldn't themselves make in fact

00:16:21,519 --> 00:16:26,560
and so um you know we have a lot of

00:16:23,920 --> 00:16:28,880
false positives coming into play here

00:16:26,560 --> 00:16:30,320
and going back to the claim that humans

00:16:28,880 --> 00:16:32,160
would then be delivered from content

00:16:30,320 --> 00:16:34,160
moderation what i've actually been

00:16:32,160 --> 00:16:35,199
tracking for some time is the ways in

00:16:34,160 --> 00:16:37,199
which um

00:16:35,199 --> 00:16:38,320
ai and other kinds of automated content

00:16:37,199 --> 00:16:40,560
moderation tools

00:16:38,320 --> 00:16:42,639
actually expand the need for human

00:16:40,560 --> 00:16:44,720
intervention because now we need

00:16:42,639 --> 00:16:46,240
not only we need the creation of the

00:16:44,720 --> 00:16:48,639
tools of course

00:16:46,240 --> 00:16:49,519
on the input side but on the output side

00:16:48,639 --> 00:16:53,199
we now need

00:16:49,519 --> 00:16:57,440
more and more humans to vet or even undo

00:16:53,199 --> 00:16:59,519
errors caused by uh by ai moderation

00:16:57,440 --> 00:17:01,360
that's in a best case scenario in in the

00:16:59,519 --> 00:17:04,160
worst case scenario the errors aren't

00:17:01,360 --> 00:17:05,280
undone and all kinds of false positives

00:17:04,160 --> 00:17:07,360
go forward or

00:17:05,280 --> 00:17:09,199
decisions are just simply made that we

00:17:07,360 --> 00:17:12,640
can't understand or even know

00:17:09,199 --> 00:17:15,679
uh are being taken thanks

00:17:12,640 --> 00:17:17,679
i just wanna let me oh sarah go ahead

00:17:15,679 --> 00:17:19,280
oh i just wanted to echo what sarah was

00:17:17,679 --> 00:17:21,520
saying i really appreciate your

00:17:19,280 --> 00:17:22,880
your emphasis on the definition of what

00:17:21,520 --> 00:17:24,160
ai actually is and

00:17:22,880 --> 00:17:25,919
it just brought to mind that the

00:17:24,160 --> 00:17:28,640
definition of what is fair

00:17:25,919 --> 00:17:29,840
is also a contested issue and something

00:17:28,640 --> 00:17:32,160
that we should think

00:17:29,840 --> 00:17:33,440
really critically about i mean computer

00:17:32,160 --> 00:17:35,360
scientists have been thinking about the

00:17:33,440 --> 00:17:37,280
definition of fair for algorithms for

00:17:35,360 --> 00:17:39,200
quite some time and the short answer is

00:17:37,280 --> 00:17:41,200
that there is no answer yet

00:17:39,200 --> 00:17:43,120
but also to remember that what is fair

00:17:41,200 --> 00:17:46,160
is not necessarily just

00:17:43,120 --> 00:17:47,280
so it's not totally clear that making

00:17:46,160 --> 00:17:49,919
facial recognition

00:17:47,280 --> 00:17:50,720
better at identifying black faces is a

00:17:49,919 --> 00:17:53,360
good thing

00:17:50,720 --> 00:17:54,240
for the world it's not totally clear

00:17:53,360 --> 00:17:56,880
that you want

00:17:54,240 --> 00:17:58,559
police to be able to better identify

00:17:56,880 --> 00:18:00,559
people in black neighborhoods

00:17:58,559 --> 00:18:03,200
it's not totally clear that you want ice

00:18:00,559 --> 00:18:05,840
to be able to better identify

00:18:03,200 --> 00:18:06,400
undocumented immigrants all of these

00:18:05,840 --> 00:18:07,760
things

00:18:06,400 --> 00:18:09,600
kind of come up in the definition of

00:18:07,760 --> 00:18:11,120
fairness and and so i think it's really

00:18:09,600 --> 00:18:12,960
important that we hone in on what we

00:18:11,120 --> 00:18:13,679
actually need when we are talking about

00:18:12,960 --> 00:18:15,360
fairness

00:18:13,679 --> 00:18:17,360
what we actually want to prioritize in

00:18:15,360 --> 00:18:18,630
our conversations about ai

00:18:17,360 --> 00:18:21,200
and power

00:18:18,630 --> 00:18:23,440
[Music]

00:18:21,200 --> 00:18:25,120
thank you i yeah i really appreciate

00:18:23,440 --> 00:18:27,360
that and that and also the other

00:18:25,120 --> 00:18:28,160
this idea that it's not static right

00:18:27,360 --> 00:18:30,080
that it's

00:18:28,160 --> 00:18:31,200
um in the in kind of enough in the same

00:18:30,080 --> 00:18:34,559
way that that

00:18:31,200 --> 00:18:37,200
um uh the shifting of power is

00:18:34,559 --> 00:18:38,080
an ever-evolving possibility the idea

00:18:37,200 --> 00:18:40,559
that even that

00:18:38,080 --> 00:18:43,039
the idea of the notion of intelligence

00:18:40,559 --> 00:18:45,440
is not fixed um and that it's

00:18:43,039 --> 00:18:46,160
that there's a cultural context uh or

00:18:45,440 --> 00:18:49,120
multiple

00:18:46,160 --> 00:18:49,840
cultural contexts around what what's

00:18:49,120 --> 00:18:52,880
getting deemed

00:18:49,840 --> 00:18:56,720
intelligent and and um

00:18:52,880 --> 00:18:59,360
the outputs and the outcomes are as uh

00:18:56,720 --> 00:19:00,000
are leaning into all of those systemic

00:18:59,360 --> 00:19:02,320
notions

00:19:00,000 --> 00:19:03,840
as as anything else i i really

00:19:02,320 --> 00:19:06,400
appreciate that a lot

00:19:03,840 --> 00:19:06,960
um i mean the other the other piece of

00:19:06,400 --> 00:19:09,039
it

00:19:06,960 --> 00:19:10,640
that certainly in in in the context of

00:19:09,039 --> 00:19:13,200
this conversation right is that much of

00:19:10,640 --> 00:19:16,640
the ai technology is actually tested

00:19:13,200 --> 00:19:18,000
and made uh or made in the western world

00:19:16,640 --> 00:19:20,960
and beta tested elsewhere

00:19:18,000 --> 00:19:23,280
and um there are invasive ai systems

00:19:20,960 --> 00:19:25,520
deployed at refugee camps

00:19:23,280 --> 00:19:26,480
uh cambridge analytica meddled in

00:19:25,520 --> 00:19:29,200
african elections

00:19:26,480 --> 00:19:29,760
long before the u.s election right and

00:19:29,200 --> 00:19:32,160
so

00:19:29,760 --> 00:19:33,440
um so what can be done are there

00:19:32,160 --> 00:19:38,559
movements pushing back

00:19:33,440 --> 00:19:41,600
against this behavior

00:19:38,559 --> 00:19:44,720
i i'm happy i'm happy to jump in uh

00:19:41,600 --> 00:19:45,440
on this one and uh for that if you allow

00:19:44,720 --> 00:19:47,919
me

00:19:45,440 --> 00:19:49,520
i'm just gonna share uh instead of

00:19:47,919 --> 00:19:51,760
having a beautiful background today

00:19:49,520 --> 00:19:54,320
because zoom doesn't recognize

00:19:51,760 --> 00:19:54,799
the features of my face i'm just gonna

00:19:54,320 --> 00:19:58,480
share

00:19:54,799 --> 00:20:00,160
i hope you can see this um this answer

00:19:58,480 --> 00:20:03,280
that i drafted

00:20:00,160 --> 00:20:06,400
um regarding your your your your

00:20:03,280 --> 00:20:09,600
question which is what is being done to

00:20:06,400 --> 00:20:12,640
uh basically prevent

00:20:09,600 --> 00:20:15,679
uh all the bad actors from

00:20:12,640 --> 00:20:18,480
testing all this and also the

00:20:15,679 --> 00:20:19,200
good faith ones are honest on testing to

00:20:18,480 --> 00:20:21,520
test from

00:20:19,200 --> 00:20:22,400
to test all these horrible things on

00:20:21,520 --> 00:20:25,200
users

00:20:22,400 --> 00:20:26,799
and end users and consumers like niga

00:20:25,200 --> 00:20:29,440
said earlier who have

00:20:26,799 --> 00:20:30,480
no absolutely no say into this

00:20:29,440 --> 00:20:33,039
conversation

00:20:30,480 --> 00:20:34,320
and for that i'd like to borrow a term

00:20:33,039 --> 00:20:36,960
that i read

00:20:34,320 --> 00:20:39,520
in a a recent publication called

00:20:36,960 --> 00:20:42,799
philanthropy and digital civil society

00:20:39,520 --> 00:20:43,760
blueprint 2021 it was it's uh it was

00:20:42,799 --> 00:20:46,799
written by

00:20:43,760 --> 00:20:49,280
dr lucy benholtz from the digital civil

00:20:46,799 --> 00:20:52,559
society lab at stanford university

00:20:49,280 --> 00:20:54,640
and it's basically uh i call it a bible

00:20:52,559 --> 00:20:56,640
for all that's related if you want to

00:20:54,640 --> 00:20:58,400
know everything about philanthropy and

00:20:56,640 --> 00:21:00,400
digital civil society

00:20:58,400 --> 00:21:02,880
at this year this is definitely one

00:21:00,400 --> 00:21:07,120
place you should you should go to

00:21:02,880 --> 00:21:09,520
and in that in that bible um

00:21:07,120 --> 00:21:10,320
there was this word that was used global

00:21:09,520 --> 00:21:13,039
majority

00:21:10,320 --> 00:21:14,840
i hate the term honestly global south

00:21:13,039 --> 00:21:18,320
global north they absolutely mean

00:21:14,840 --> 00:21:19,360
nothing um but when we talk about global

00:21:18,320 --> 00:21:22,480
majority

00:21:19,360 --> 00:21:25,200
we we clearly understand

00:21:22,480 --> 00:21:26,640
that a majority of those illegals who

00:21:25,200 --> 00:21:30,240
live on this earth

00:21:26,640 --> 00:21:33,760
are actually um you know

00:21:30,240 --> 00:21:37,360
the well guinea pigs the uh

00:21:33,760 --> 00:21:37,919
they they're just honestly victims of

00:21:37,360 --> 00:21:40,799
whatever

00:21:37,919 --> 00:21:43,200
is being decided elsewhere without ever

00:21:40,799 --> 00:21:45,919
being consulted and ever being

00:21:43,200 --> 00:21:46,880
uh part of the the conversation but at

00:21:45,919 --> 00:21:50,320
the same time

00:21:46,880 --> 00:21:52,559
this global majority is also our future

00:21:50,320 --> 00:21:54,640
they tell us what's going to happen to

00:21:52,559 --> 00:21:56,000
us here in the global minority i say

00:21:54,640 --> 00:21:58,159
here because i live in

00:21:56,000 --> 00:21:59,360
the so-called global north uh but i'm

00:21:58,159 --> 00:22:02,720
i'm cameroonian

00:21:59,360 --> 00:22:04,640
um and i i've seen in my work

00:22:02,720 --> 00:22:06,559
at antoinette some frontier internet

00:22:04,640 --> 00:22:09,679
without words also in english

00:22:06,559 --> 00:22:12,799
we have seen how how uh

00:22:09,679 --> 00:22:13,840
you know how quick you can understand

00:22:12,799 --> 00:22:15,679
what's going to happen

00:22:13,840 --> 00:22:17,919
when you look at what's happening in

00:22:15,679 --> 00:22:20,000
places where actually nobody usually

00:22:17,919 --> 00:22:21,919
cares and specifically the media

00:22:20,000 --> 00:22:23,039
i'll give you one example when we

00:22:21,919 --> 00:22:25,919
started to talk about

00:22:23,039 --> 00:22:27,039
trolls in following in the aftermath of

00:22:25,919 --> 00:22:29,840
the 2016

00:22:27,039 --> 00:22:30,240
u.s presidential election we actually

00:22:29,840 --> 00:22:31,840
knew

00:22:30,240 --> 00:22:33,600
that this was i mean we didn't know

00:22:31,840 --> 00:22:37,520
these were trolls but we

00:22:33,600 --> 00:22:40,960
we knew that we had seen those automated

00:22:37,520 --> 00:22:44,640
automatically um you know generated

00:22:40,960 --> 00:22:46,640
publication tweets uh back in 2010

00:22:44,640 --> 00:22:47,679
when we're looking at what was happening

00:22:46,640 --> 00:22:50,880
in a western

00:22:47,679 --> 00:22:54,320
african country called gabon in which

00:22:50,880 --> 00:22:58,159
there were you know there were

00:22:54,320 --> 00:23:00,400
repression following um uprising of the

00:22:58,159 --> 00:23:01,039
population in the aftermath of the arab

00:23:00,400 --> 00:23:04,000
spring

00:23:01,039 --> 00:23:04,880
and to counter the narrative around what

00:23:04,000 --> 00:23:06,400
was happening

00:23:04,880 --> 00:23:08,240
and to counter the fact that civil

00:23:06,400 --> 00:23:10,880
society organization citizens have

00:23:08,240 --> 00:23:12,320
found a space on twitter and on facebook

00:23:10,880 --> 00:23:15,520
twitter particularly

00:23:12,320 --> 00:23:17,440
to tell what was really happening in a

00:23:15,520 --> 00:23:18,880
media environment that was completely

00:23:17,440 --> 00:23:22,240
locked for them

00:23:18,880 --> 00:23:25,440
um well the government chose

00:23:22,240 --> 00:23:26,320
to buy people well not people bots

00:23:25,440 --> 00:23:28,000
obviously

00:23:26,320 --> 00:23:29,440
i mean we started seeing people from

00:23:28,000 --> 00:23:31,039
india or from turkey

00:23:29,440 --> 00:23:33,360
tweeting about what was happening in

00:23:31,039 --> 00:23:35,440
gabon while not being there

00:23:33,360 --> 00:23:36,720
this was weird but at the time honestly

00:23:35,440 --> 00:23:39,520
we didn't know

00:23:36,720 --> 00:23:40,320
that this was this was a this was a

00:23:39,520 --> 00:23:43,919
troll or

00:23:40,320 --> 00:23:46,960
you know automated uh propaganda

00:23:43,919 --> 00:23:48,559
so why am i saying that global majority

00:23:46,960 --> 00:23:50,480
and global minority

00:23:48,559 --> 00:23:52,640
more than ever need to collaborate it's

00:23:50,480 --> 00:23:55,919
because we have the knowledge

00:23:52,640 --> 00:23:58,000
in western big academic institutions

00:23:55,919 --> 00:23:58,960
in western big human rights

00:23:58,000 --> 00:24:01,520
organizations

00:23:58,960 --> 00:24:03,279
but in the global majority they have the

00:24:01,520 --> 00:24:05,440
experience in their flesh

00:24:03,279 --> 00:24:06,720
but they cannot name that experience

00:24:05,440 --> 00:24:07,440
they cannot name that what they're

00:24:06,720 --> 00:24:10,240
seeing and what

00:24:07,440 --> 00:24:12,400
they're uh being victims of is wrong

00:24:10,240 --> 00:24:15,840
we're talking about facial recognition

00:24:12,400 --> 00:24:18,480
recently reports surveys that in in

00:24:15,840 --> 00:24:20,640
in countries like uganda facial

00:24:18,480 --> 00:24:24,559
recognition is being used to arrest

00:24:20,640 --> 00:24:27,039
um you know uh democrat democratic

00:24:24,559 --> 00:24:27,679
demonstrators that that's absolutely

00:24:27,039 --> 00:24:29,840
worrying

00:24:27,679 --> 00:24:31,200
we're also we're also you talked about

00:24:29,840 --> 00:24:33,679
refugees of course

00:24:31,200 --> 00:24:35,600
refugees this is a big problem in my

00:24:33,679 --> 00:24:38,480
country cameron there's a huge

00:24:35,600 --> 00:24:39,679
refugee well several huge refugee crisis

00:24:38,480 --> 00:24:42,080
at the same time

00:24:39,679 --> 00:24:43,840
and we recently learned that the

00:24:42,080 --> 00:24:47,039
government accepted to sign

00:24:43,840 --> 00:24:50,720
with them i think it was the unhcr

00:24:47,039 --> 00:24:53,760
at least a big u.n refugee institution

00:24:50,720 --> 00:24:55,440
they accepted to sign a basically a

00:24:53,760 --> 00:24:56,960
program that would allow them to

00:24:55,440 --> 00:24:59,520
digitally

00:24:56,960 --> 00:25:00,240
trace all the refugees that come into

00:24:59,520 --> 00:25:02,400
cameroon

00:25:00,240 --> 00:25:04,080
it might sound appealing especially for

00:25:02,400 --> 00:25:05,360
a cameroon a country like cameroon

00:25:04,080 --> 00:25:07,679
that's already struggling

00:25:05,360 --> 00:25:09,200
with many other issues and you know

00:25:07,679 --> 00:25:11,520
basically doesn't have the money

00:25:09,200 --> 00:25:12,640
to handle all these new refugees and all

00:25:11,520 --> 00:25:15,679
these new peoples

00:25:12,640 --> 00:25:18,080
but what are the problems that will come

00:25:15,679 --> 00:25:18,799
after that when you start tracing the

00:25:18,080 --> 00:25:20,960
weakest

00:25:18,799 --> 00:25:22,640
what are you going to do later on to

00:25:20,960 --> 00:25:24,000
those once you have tested when you want

00:25:22,640 --> 00:25:26,480
to have perfected

00:25:24,000 --> 00:25:27,279
your ability to trace every single

00:25:26,480 --> 00:25:29,120
moment of

00:25:27,279 --> 00:25:30,640
the life of an individual what are you

00:25:29,120 --> 00:25:32,960
gonna do uh with

00:25:30,640 --> 00:25:33,760
those were for now living in a more

00:25:32,960 --> 00:25:35,360
liberal

00:25:33,760 --> 00:25:37,120
in a more liberal world and in a

00:25:35,360 --> 00:25:39,919
peaceful world so

00:25:37,120 --> 00:25:40,480
um this is this has been the core of my

00:25:39,919 --> 00:25:44,480
work

00:25:40,480 --> 00:25:46,720
uh since you know working in this space

00:25:44,480 --> 00:25:48,559
making sure that we collaborate as much

00:25:46,720 --> 00:25:49,760
as possible because a lot of things that

00:25:48,559 --> 00:25:52,880
we can tell you

00:25:49,760 --> 00:25:54,000
and i'm not not just africans asians

00:25:52,880 --> 00:25:56,400
latin americans

00:25:54,000 --> 00:25:58,000
but also trans communities lgbt

00:25:56,400 --> 00:26:00,320
communities in general

00:25:58,000 --> 00:26:01,679
they they we can tell you things but we

00:26:00,320 --> 00:26:03,520
need to collaborate

00:26:01,679 --> 00:26:05,039
uh with academics and with big

00:26:03,520 --> 00:26:07,200
institutions not in

00:26:05,039 --> 00:26:08,480
an extractive way and i'm insisting on

00:26:07,200 --> 00:26:10,720
that but really

00:26:08,480 --> 00:26:12,559
collaborate respecting you know the

00:26:10,720 --> 00:26:14,000
expertise of each other it's not because

00:26:12,559 --> 00:26:16,080
it's an experience that it's worth

00:26:14,000 --> 00:26:17,520
less that's a false assumption that is

00:26:16,080 --> 00:26:20,400
plaguing the industry

00:26:17,520 --> 00:26:22,880
um but collaborate on an equal level

00:26:20,400 --> 00:26:25,440
because what i'm bringing to the table

00:26:22,880 --> 00:26:27,120
is absolutely necessary for you to make

00:26:25,440 --> 00:26:30,480
the point with your theoretical

00:26:27,120 --> 00:26:32,640
uh you know frame so yeah that's what i

00:26:30,480 --> 00:26:35,360
i wanted to share with you today and i'm

00:26:32,640 --> 00:26:38,400
going to stop sharing

00:26:35,360 --> 00:26:40,480
thank you um sarah i heard

00:26:38,400 --> 00:26:42,080
i saw your um hand raised and i want to

00:26:40,480 --> 00:26:44,320
also um prompt

00:26:42,080 --> 00:26:45,440
um the other folks in the in the

00:26:44,320 --> 00:26:49,679
conversation

00:26:45,440 --> 00:26:52,000
um i i think the

00:26:49,679 --> 00:26:53,679
that presumption of of who has what to

00:26:52,000 --> 00:26:56,400
say and even the terminology

00:26:53,679 --> 00:26:58,240
around majority and minority sierra that

00:26:56,400 --> 00:26:59,039
reminds me too about the distinction

00:26:58,240 --> 00:27:02,400
between

00:26:59,039 --> 00:27:05,200
fair and just and then they got

00:27:02,400 --> 00:27:06,400
the point you uh were making originally

00:27:05,200 --> 00:27:09,679
in terms of

00:27:06,400 --> 00:27:12,240
who's who's articulating um uh

00:27:09,679 --> 00:27:14,080
their power and who has agency under the

00:27:12,240 --> 00:27:14,640
current paradigms i mean i think that we

00:27:14,080 --> 00:27:16,640
could

00:27:14,640 --> 00:27:18,480
kind of flip the script here and and

00:27:16,640 --> 00:27:20,799
break the conversation

00:27:18,480 --> 00:27:21,679
open a little bit about around around

00:27:20,799 --> 00:27:24,320
all of that so

00:27:21,679 --> 00:27:26,480
so sarah you had your hand open but but

00:27:24,320 --> 00:27:28,720
no i'm gonna call on the rest of you uh

00:27:26,480 --> 00:27:29,520
yeah right afterwards yeah i'm gonna

00:27:28,720 --> 00:27:32,080
toss the mic

00:27:29,520 --> 00:27:33,600
to my my peers in just one second i just

00:27:32,080 --> 00:27:34,080
have such like a short-term memory

00:27:33,600 --> 00:27:38,080
problem

00:27:34,080 --> 00:27:40,240
that i wanna um i wanna just uh raise up

00:27:38,080 --> 00:27:42,000
uh plus one you know i get on these

00:27:40,240 --> 00:27:42,640
panels and i freak out with excitement

00:27:42,000 --> 00:27:45,279
because

00:27:42,640 --> 00:27:46,559
what people are saying is so on point

00:27:45,279 --> 00:27:48,960
and powerful

00:27:46,559 --> 00:27:51,039
and so julie i think what you just said

00:27:48,960 --> 00:27:54,000
about terminology number one

00:27:51,039 --> 00:27:56,320
and about you know this rel the

00:27:54,000 --> 00:27:58,080
problematic relationship historically

00:27:56,320 --> 00:27:59,440
and in this contemporary moment with

00:27:58,080 --> 00:28:02,159
academia

00:27:59,440 --> 00:28:04,080
and its relationship to industry and its

00:28:02,159 --> 00:28:07,120
extractive relationship

00:28:04,080 --> 00:28:10,240
on communities is also key here

00:28:07,120 --> 00:28:13,840
to kind of where we might break in

00:28:10,240 --> 00:28:14,240
and and do repair work and do new kinds

00:28:13,840 --> 00:28:17,440
of

00:28:14,240 --> 00:28:18,960
paradigm shifting um to change exactly

00:28:17,440 --> 00:28:20,640
what you were talking about so

00:28:18,960 --> 00:28:22,159
first of all i just wanted to share out

00:28:20,640 --> 00:28:25,360
on the terminology piece

00:28:22,159 --> 00:28:28,159
that i once read a a um

00:28:25,360 --> 00:28:30,159
just within another piece by a civil

00:28:28,159 --> 00:28:33,200
society advocate from uh

00:28:30,159 --> 00:28:35,200
from india who was speaking about

00:28:33,200 --> 00:28:36,559
you know he refused to use those uh

00:28:35,200 --> 00:28:38,799
kinds of um

00:28:36,559 --> 00:28:39,840
received terms as well and he so he was

00:28:38,799 --> 00:28:42,080
talking about the over

00:28:39,840 --> 00:28:42,960
developed world and i've always loved

00:28:42,080 --> 00:28:45,919
that and so

00:28:42,960 --> 00:28:47,840
um i kind of try to use that when i can

00:28:45,919 --> 00:28:49,520
and i also think about uh

00:28:47,840 --> 00:28:51,360
what we're actually talking about is

00:28:49,520 --> 00:28:54,240
resources and and

00:28:51,360 --> 00:28:56,080
economic resources primarily and so i

00:28:54,240 --> 00:28:59,360
think about it in terms of

00:28:56,080 --> 00:28:59,840
um the the economic overly resourced

00:28:59,360 --> 00:29:02,240
world

00:28:59,840 --> 00:29:03,200
you know like like jumping off on that

00:29:02,240 --> 00:29:05,919
point

00:29:03,200 --> 00:29:07,760
versus um the inappropriately

00:29:05,919 --> 00:29:10,159
economically under-resourced

00:29:07,760 --> 00:29:11,360
part parts of the world so i i just

00:29:10,159 --> 00:29:13,120
throwing that out there as a

00:29:11,360 --> 00:29:14,480
as a possibility and is something that

00:29:13,120 --> 00:29:16,480
that i think about

00:29:14,480 --> 00:29:17,600
um in terms of your you know the

00:29:16,480 --> 00:29:20,880
comments about

00:29:17,600 --> 00:29:23,279
um who get who gets to create

00:29:20,880 --> 00:29:24,159
laboratories on other people and treat

00:29:23,279 --> 00:29:27,360
other

00:29:24,159 --> 00:29:27,919
places and and and uh peoples as guinea

00:29:27,360 --> 00:29:30,799
pigs

00:29:27,919 --> 00:29:31,200
you know we this predates all of this

00:29:30,799 --> 00:29:33,600
this

00:29:31,200 --> 00:29:35,760
uh computational business i always think

00:29:33,600 --> 00:29:37,600
about from my american contacts

00:29:35,760 --> 00:29:38,880
the interference of the american

00:29:37,600 --> 00:29:42,480
government uh

00:29:38,880 --> 00:29:46,080
in in south america and in places like

00:29:42,480 --> 00:29:48,000
chile and um you know argentina

00:29:46,080 --> 00:29:49,200
and brazil and all of these countries

00:29:48,000 --> 00:29:52,640
that were meddled with

00:29:49,200 --> 00:29:55,679
to um to murderous ends and

00:29:52,640 --> 00:29:59,200
this is a tradition in place uh

00:29:55,679 --> 00:30:02,960
predating ai but certainly in place

00:29:59,200 --> 00:30:05,200
around uh uh picking places in the world

00:30:02,960 --> 00:30:07,360
and then going and doing stuff

00:30:05,200 --> 00:30:09,679
uh upon them that will then come home to

00:30:07,360 --> 00:30:12,640
roost uh in the american context

00:30:09,679 --> 00:30:13,440
uh and then um the last thing i wanted

00:30:12,640 --> 00:30:16,320
to say

00:30:13,440 --> 00:30:16,720
uh before i before i silence myself is

00:30:16,320 --> 00:30:19,760
uh

00:30:16,720 --> 00:30:22,880
the the piece about uh

00:30:19,760 --> 00:30:25,600
what you said so accurately

00:30:22,880 --> 00:30:27,200
about who actually has special insight

00:30:25,600 --> 00:30:30,720
into these problems

00:30:27,200 --> 00:30:32,559
who is um most harmed

00:30:30,720 --> 00:30:34,240
are the people who have the the

00:30:32,559 --> 00:30:36,000
solutions or at least the

00:30:34,240 --> 00:30:38,480
the knowledge to put it into the

00:30:36,000 --> 00:30:40,640
pipeline to talk about interventions

00:30:38,480 --> 00:30:42,320
and it was with that in mind that my

00:30:40,640 --> 00:30:45,600
colleague and collaborator

00:30:42,320 --> 00:30:47,760
and dear friend dr sofia noble and i

00:30:45,600 --> 00:30:49,600
came up with the ucla center for

00:30:47,760 --> 00:30:53,279
critical internet inquiry where we

00:30:49,600 --> 00:30:56,159
put forth and put forward and put first

00:30:53,279 --> 00:30:57,919
uh these kinds of uh voices with all of

00:30:56,159 --> 00:31:01,200
the expertise they have

00:30:57,919 --> 00:31:01,679
because we ourselves sofia as a black

00:31:01,200 --> 00:31:05,200
woman

00:31:01,679 --> 00:31:07,919
myself as a gay woman we understand

00:31:05,200 --> 00:31:09,679
what it's like to have the knowledge and

00:31:07,919 --> 00:31:11,200
to frankly be the canaries in the coal

00:31:09,679 --> 00:31:13,360
mine we're always trying to

00:31:11,200 --> 00:31:14,880
bang on the window and and tell everyone

00:31:13,360 --> 00:31:15,840
and so that's what we're trying to

00:31:14,880 --> 00:31:18,159
actually

00:31:15,840 --> 00:31:19,919
uh create a beacon for and to create a

00:31:18,159 --> 00:31:22,399
large enough

00:31:19,919 --> 00:31:23,919
critical mass of people to do some of

00:31:22,399 --> 00:31:25,200
that within academia

00:31:23,919 --> 00:31:27,120
specifically

00:31:25,200 --> 00:31:29,200
[Music]

00:31:27,120 --> 00:31:30,399
i just want to acknowledge that um some

00:31:29,200 --> 00:31:33,840
of our internet is

00:31:30,399 --> 00:31:34,320
is um uh uh more robust than others so

00:31:33,840 --> 00:31:36,320


00:31:34,320 --> 00:31:37,360
is going to go on audio um are you

00:31:36,320 --> 00:31:40,320
able to hear us

00:31:37,360 --> 00:31:40,320
uh pretty well now

00:31:40,799 --> 00:31:46,640
yes i can um i just wanted to add um

00:31:44,320 --> 00:31:48,480
a little into into this conversation i

00:31:46,640 --> 00:31:49,919
mean i know we are talking about ai

00:31:48,480 --> 00:31:52,399
and power and i think we're very

00:31:49,919 --> 00:31:55,600
important for us to focus on power

00:31:52,399 --> 00:31:59,039
then who gets to uh design

00:31:55,600 --> 00:32:00,480
or train ai uh and i think i have said a

00:31:59,039 --> 00:32:03,200
little bit about this but

00:32:00,480 --> 00:32:03,919
i building on what building on what

00:32:03,200 --> 00:32:07,039
julie

00:32:03,919 --> 00:32:09,360
said um it's

00:32:07,039 --> 00:32:10,960
whose knowledge is it anyway right i

00:32:09,360 --> 00:32:14,240
mean uh the people

00:32:10,960 --> 00:32:16,080
who uh who are in our context have

00:32:14,240 --> 00:32:18,880
so much knowledge but there is an

00:32:16,080 --> 00:32:20,240
immense inequality of distribution of

00:32:18,880 --> 00:32:24,399
that knowledge

00:32:20,240 --> 00:32:26,480
we are mostly used as you know

00:32:24,399 --> 00:32:27,440
although we have all the knowledge and

00:32:26,480 --> 00:32:30,880
then that

00:32:27,440 --> 00:32:32,000
knowledge sort of transfers or travels

00:32:30,880 --> 00:32:34,000
to the western world

00:32:32,000 --> 00:32:35,679
and then you know that's where we see

00:32:34,000 --> 00:32:38,000
the bias that's where the design

00:32:35,679 --> 00:32:39,279
you know uh the the design of product

00:32:38,000 --> 00:32:42,320
takes place

00:32:39,279 --> 00:32:44,480
uh and instead of distribution or equal

00:32:42,320 --> 00:32:47,120
distribution of resources

00:32:44,480 --> 00:32:47,919
we see that you know the inequalities of

00:32:47,120 --> 00:32:50,320
risk

00:32:47,919 --> 00:32:51,440
inequalities between the global north

00:32:50,320 --> 00:32:53,760
and global south

00:32:51,440 --> 00:32:55,760
organizations working on digital rights

00:32:53,760 --> 00:32:58,480
or working on tech and human rights

00:32:55,760 --> 00:32:59,519
those inequalities become wider and

00:32:58,480 --> 00:33:02,640
wider every

00:32:59,519 --> 00:33:03,519
you know every day so so and it's it's a

00:33:02,640 --> 00:33:06,640
lot of labor

00:33:03,519 --> 00:33:07,039
it's a free labor like sitting on panels

00:33:06,640 --> 00:33:09,279
and

00:33:07,039 --> 00:33:10,559
sharing your knowledge it's a free labor

00:33:09,279 --> 00:33:12,880
uh and i think

00:33:10,559 --> 00:33:14,399
it's it's it's now time when we are

00:33:12,880 --> 00:33:15,919
seeing this these conversations

00:33:14,399 --> 00:33:17,440
happening in the western world around

00:33:15,919 --> 00:33:20,559
content moderation

00:33:17,440 --> 00:33:20,559
how we actually

00:33:22,399 --> 00:33:27,679
absolutely have no idea what's uh

00:33:25,679 --> 00:33:28,880
what are the decisions being taken

00:33:27,679 --> 00:33:30,480
around them

00:33:28,880 --> 00:33:32,720
while people who are sitting in these

00:33:30,480 --> 00:33:33,200
big tech giants social media companies

00:33:32,720 --> 00:33:34,880
or

00:33:33,200 --> 00:33:36,720
you know like running governments so i

00:33:34,880 --> 00:33:38,480
just wanted to acknowledge that there is

00:33:36,720 --> 00:33:42,960
a lot of labor happening

00:33:38,480 --> 00:33:42,960
in global south but there is a very

00:33:44,960 --> 00:33:48,399
that labor and distribution of

00:33:51,600 --> 00:33:58,720
you got you your audio cut out um right

00:33:55,440 --> 00:34:00,480
right at the end there but um but

00:33:58,720 --> 00:34:03,200
i'm gonna i'm gonna try to recap and

00:34:00,480 --> 00:34:05,679
then uh let us know if

00:34:03,200 --> 00:34:06,320
that i've come close but just in terms

00:34:05,679 --> 00:34:09,440
of

00:34:06,320 --> 00:34:10,560
the the wealth of information that is

00:34:09,440 --> 00:34:12,240
extracted

00:34:10,560 --> 00:34:14,720
and i'm paraphrasing obviously that is

00:34:12,240 --> 00:34:18,320
extracted like a resource

00:34:14,720 --> 00:34:21,760
um as resources have long been extracted

00:34:18,320 --> 00:34:24,320
from the location of of that knowledge

00:34:21,760 --> 00:34:25,520
and then there's a huge gap between then

00:34:24,320 --> 00:34:28,720
and and

00:34:25,520 --> 00:34:32,399
and a dearth of information of how that

00:34:28,720 --> 00:34:34,639
information even parlays into

00:34:32,399 --> 00:34:35,679
uh uh invention if you will and i'm

00:34:34,639 --> 00:34:38,240
making air

00:34:35,679 --> 00:34:38,960
air quotes um and how it's being used

00:34:38,240 --> 00:34:42,399
and so

00:34:38,960 --> 00:34:43,359
so it's it's hap so the it's happening

00:34:42,399 --> 00:34:45,280
on two levels

00:34:43,359 --> 00:34:47,040
there's the original extraction of

00:34:45,280 --> 00:34:49,359
knowledge and then there's the ways that

00:34:47,040 --> 00:34:49,919
the knowledge is being put to use that's

00:34:49,359 --> 00:34:54,000
not even

00:34:49,919 --> 00:34:55,200
being made clear is that is that correct

00:34:54,000 --> 00:34:58,560
on the point that you were trying to

00:34:55,200 --> 00:34:58,560
make right there at the end

00:35:01,040 --> 00:35:04,079
absolutely great thank you okay

00:35:03,040 --> 00:35:06,880
beautiful

00:35:04,079 --> 00:35:08,640
sierra do you want to hop in there sure

00:35:06,880 --> 00:35:10,720
i was just adding on to

00:35:08,640 --> 00:35:12,480
sarah i mean at the justice data lab we

00:35:10,720 --> 00:35:15,280
do exactly the same thing and

00:35:12,480 --> 00:35:16,720
the way that we are trying to do that is

00:35:15,280 --> 00:35:18,960
literally to put in the hands of

00:35:16,720 --> 00:35:21,680
community organizations

00:35:18,960 --> 00:35:22,560
research resources and so we assign

00:35:21,680 --> 00:35:25,119
teams

00:35:22,560 --> 00:35:26,640
of undergrad researchers with the

00:35:25,119 --> 00:35:29,280
princeton pedigree

00:35:26,640 --> 00:35:30,640
to these community organizations who say

00:35:29,280 --> 00:35:31,040
you know we really would love to know

00:35:30,640 --> 00:35:33,440
this

00:35:31,040 --> 00:35:34,880
or we really want to advocate for this

00:35:33,440 --> 00:35:36,560
and the students work

00:35:34,880 --> 00:35:38,480
on behalf of the organization in

00:35:36,560 --> 00:35:41,680
partnership with the organizations

00:35:38,480 --> 00:35:43,599
the organizations drive all of the

00:35:41,680 --> 00:35:44,800
theorizing drive the data collection

00:35:43,599 --> 00:35:46,720
drive everything

00:35:44,800 --> 00:35:47,920
and i think it's just a really powerful

00:35:46,720 --> 00:35:49,680
way um

00:35:47,920 --> 00:35:51,839
to make sure that the voices who need to

00:35:49,680 --> 00:35:53,200
be included are not only at the table

00:35:51,839 --> 00:35:59,839
but are at the head of the table they're

00:35:53,200 --> 00:35:59,839
controlling the conversation

00:35:59,920 --> 00:36:03,200
let's talk about that the kind of

00:36:01,599 --> 00:36:06,560
opportunities that you're each

00:36:03,200 --> 00:36:09,280
actually um uh creating

00:36:06,560 --> 00:36:09,680
and um what you're excited about and

00:36:09,280 --> 00:36:12,480
what

00:36:09,680 --> 00:36:14,560
like i i really don't want it to be that

00:36:12,480 --> 00:36:18,079
when we're having conversations of power

00:36:14,560 --> 00:36:21,040
and we have a panel of uh

00:36:18,079 --> 00:36:21,680
women queer women queer people of color

00:36:21,040 --> 00:36:24,480
that we're

00:36:21,680 --> 00:36:25,520
only talking about the power that we're

00:36:24,480 --> 00:36:28,960
disallowed

00:36:25,520 --> 00:36:31,359
or um and like i know everybody here

00:36:28,960 --> 00:36:33,040
is doing incredible work and putting

00:36:31,359 --> 00:36:33,760
forward sierra you just gave us a little

00:36:33,040 --> 00:36:36,320
window in

00:36:33,760 --> 00:36:37,280
into that as well um what are you

00:36:36,320 --> 00:36:39,200
excited about

00:36:37,280 --> 00:36:40,480
how do you see that shifting you know

00:36:39,200 --> 00:36:43,839
when we're talking about

00:36:40,480 --> 00:36:46,960
um uh the analog disparities of

00:36:43,839 --> 00:36:48,960
of power are often upended when we

00:36:46,960 --> 00:36:50,960
come to collective purpose so i'm

00:36:48,960 --> 00:36:52,000
curious about examples of that kind of

00:36:50,960 --> 00:36:53,760
collectivity

00:36:52,000 --> 00:36:55,599
or anything that's thrilling you in this

00:36:53,760 --> 00:36:59,040
moment um if we could

00:36:55,599 --> 00:37:01,280
if we could go around um and and

00:36:59,040 --> 00:37:02,800
i know i'm i'm uh i didn't give you a

00:37:01,280 --> 00:37:04,720
warning i was going to ask you that but

00:37:02,800 --> 00:37:06,720
but if we can be thoughtful about that

00:37:04,720 --> 00:37:09,839
of something that you're excited about

00:37:06,720 --> 00:37:10,400
um and what you see as potentially power

00:37:09,839 --> 00:37:13,440
shifting

00:37:10,400 --> 00:37:15,520
in the most micro or macro way um

00:37:13,440 --> 00:37:17,839
i'd love i'd love for that to be in the

00:37:15,520 --> 00:37:20,160
room and it as part of the conversation

00:37:17,839 --> 00:37:21,359
i'm gonna go around so sarah you're the

00:37:20,160 --> 00:37:24,640
first

00:37:21,359 --> 00:37:25,760
square in my family feud yeah i feel

00:37:24,640 --> 00:37:28,160
like brady bunch

00:37:25,760 --> 00:37:28,800
a lot of times too with this okay um and

00:37:28,160 --> 00:37:31,839
we're all

00:37:28,800 --> 00:37:34,320
like arranged differently but anyway um

00:37:31,839 --> 00:37:35,200
okay so yeah great question i appreciate

00:37:34,320 --> 00:37:37,440
the

00:37:35,200 --> 00:37:38,720
the context too right because this isn't

00:37:37,440 --> 00:37:42,240
all about

00:37:38,720 --> 00:37:45,440
um those of us on the panel

00:37:42,240 --> 00:37:48,640
and those who who we represent

00:37:45,440 --> 00:37:49,200
um just seating power we're not doing

00:37:48,640 --> 00:37:50,960
that

00:37:49,200 --> 00:37:52,400
you know if we ever did it we're not

00:37:50,960 --> 00:37:55,520
doing it anymore

00:37:52,400 --> 00:37:58,720
and we're actually thinking through

00:37:55,520 --> 00:38:01,599
um new ways of of doing and new ways

00:37:58,720 --> 00:38:03,520
of of creating as sierra was just you

00:38:01,599 --> 00:38:06,560
know articulating and so

00:38:03,520 --> 00:38:10,079
um from my own perspective and from

00:38:06,560 --> 00:38:12,880
speaking for uh our

00:38:10,079 --> 00:38:15,200
our center at ucla one of the things

00:38:12,880 --> 00:38:16,480
that uh safiya noble and i are working

00:38:15,200 --> 00:38:19,680
on right now

00:38:16,480 --> 00:38:21,359
actively is thinking about

00:38:19,680 --> 00:38:22,800
uh you know some of the projects we've

00:38:21,359 --> 00:38:27,119
had in mind for

00:38:22,800 --> 00:38:30,400
for a decade which is um

00:38:27,119 --> 00:38:32,640
pushing back pushing open that public

00:38:30,400 --> 00:38:35,440
space and the public sphere

00:38:32,640 --> 00:38:36,079
that has been inappropriately colonized

00:38:35,440 --> 00:38:38,550
and i do

00:38:36,079 --> 00:38:39,599
use that word very uh

00:38:38,550 --> 00:38:42,880
[Music]

00:38:39,599 --> 00:38:46,240
very um intentionally

00:38:42,880 --> 00:38:49,839
by tech uh

00:38:46,240 --> 00:38:52,400
tech having kind of um

00:38:49,839 --> 00:38:53,200
taken up these notions that we have

00:38:52,400 --> 00:38:54,800
about

00:38:53,200 --> 00:38:57,119
so many of these information

00:38:54,800 --> 00:39:00,800
institutions that have sat in

00:38:57,119 --> 00:39:04,400
uh squarely in uh kind of the public

00:39:00,800 --> 00:39:06,640
good space and then colonized

00:39:04,400 --> 00:39:08,480
their words their identities we have

00:39:06,640 --> 00:39:10,240
susan wojcicki from youtube

00:39:08,480 --> 00:39:12,160
going around the world telling the whole

00:39:10,240 --> 00:39:14,000
world youtube is a library if you want

00:39:12,160 --> 00:39:16,160
to see me go apoplectic

00:39:14,000 --> 00:39:17,760
let me hear her say that one more time i

00:39:16,160 --> 00:39:20,720
lose it every time

00:39:17,760 --> 00:39:21,839
it's not um it's not without harm that

00:39:20,720 --> 00:39:24,240
she does that

00:39:21,839 --> 00:39:26,400
libraries don't collect data and and

00:39:24,240 --> 00:39:27,280
monetize it on their users libraries

00:39:26,400 --> 00:39:29,359
don't

00:39:27,280 --> 00:39:31,040
promote and disseminate uh

00:39:29,359 --> 00:39:32,880
disinformation and misinformation

00:39:31,040 --> 00:39:34,960
material with without any

00:39:32,880 --> 00:39:36,160
sense of responsibility they don't use

00:39:34,960 --> 00:39:39,040
algorithms

00:39:36,160 --> 00:39:40,720
to serve up uh garbage to just keep

00:39:39,040 --> 00:39:42,000
people engaged none of that is not a

00:39:40,720 --> 00:39:44,480
library so youtube is not

00:39:42,000 --> 00:39:45,839
a library but libraries actually have so

00:39:44,480 --> 00:39:48,480
much to offer

00:39:45,839 --> 00:39:50,480
uh and our ways of knowing libraries a

00:39:48,480 --> 00:39:52,720
flawed institution as well with uh

00:39:50,480 --> 00:39:54,240
you know with a difficult history but

00:39:52,720 --> 00:39:55,920
how could we reimagine

00:39:54,240 --> 00:39:57,920
some of the principles and values that

00:39:55,920 --> 00:39:59,680
come from libraries and librarianship

00:39:57,920 --> 00:40:01,440
to actually say not only is youtube not

00:39:59,680 --> 00:40:02,320
a library but this is what a library

00:40:01,440 --> 00:40:05,280
looks like

00:40:02,320 --> 00:40:05,760
um when it is in the internet space and

00:40:05,280 --> 00:40:07,760
in

00:40:05,760 --> 00:40:09,440
in practice for the for the public good

00:40:07,760 --> 00:40:11,599
and for the benefit of the public so

00:40:09,440 --> 00:40:12,560
that's just like the slightest preview

00:40:11,599 --> 00:40:14,640
of um

00:40:12,560 --> 00:40:15,839
and a very half-baked explanation of

00:40:14,640 --> 00:40:17,599
what we're coming up with

00:40:15,839 --> 00:40:18,880
but what i'm saying is we're actually

00:40:17,599 --> 00:40:21,520
going to stop

00:40:18,880 --> 00:40:22,480
seeding those spaces and those

00:40:21,520 --> 00:40:25,040
imaginaries

00:40:22,480 --> 00:40:26,079
actually to tech and we're going to

00:40:25,040 --> 00:40:29,839
reintroduce

00:40:26,079 --> 00:40:30,880
very um very directly and with great

00:40:29,839 --> 00:40:34,160
purpose

00:40:30,880 --> 00:40:37,280
uh some of these identifiable

00:40:34,160 --> 00:40:39,119
information curatorial roles to help

00:40:37,280 --> 00:40:41,599
users make sense

00:40:39,119 --> 00:40:43,440
when the the sense making has been

00:40:41,599 --> 00:40:46,720
deliberately removed from them

00:40:43,440 --> 00:40:49,920
uh for the purposes of profit

00:40:46,720 --> 00:40:50,640
so that's kind of where we are um in in

00:40:49,920 --> 00:40:53,440
essence

00:40:50,640 --> 00:40:55,200
um bringing the human back and and and

00:40:53,440 --> 00:40:58,160
foregrounding the human

00:40:55,200 --> 00:40:59,920
in this notion of um artificial

00:40:58,160 --> 00:41:01,200
intelligence like whoever said that was

00:40:59,920 --> 00:41:04,240
better

00:41:01,200 --> 00:41:05,920
you know um we used to think uh uh sweet

00:41:04,240 --> 00:41:06,240
and low was better too you know what i

00:41:05,920 --> 00:41:08,960
mean

00:41:06,240 --> 00:41:09,359
it's not it caused cancer it's not good

00:41:08,960 --> 00:41:11,359
so

00:41:09,359 --> 00:41:13,040
um you know just we're just thinking

00:41:11,359 --> 00:41:15,599
that way right now thanks

00:41:13,040 --> 00:41:16,960
cool thank you julie what about you what

00:41:15,599 --> 00:41:19,680
are you excited about

00:41:16,960 --> 00:41:20,240
where do you see uh some potential and

00:41:19,680 --> 00:41:21,920
um

00:41:20,240 --> 00:41:25,280
uh what would make you really happy to

00:41:21,920 --> 00:41:25,280
see some momentum behind

00:41:25,680 --> 00:41:30,319
um i'm honestly very excited about a lot

00:41:28,640 --> 00:41:31,680
of things right now when it comes to

00:41:30,319 --> 00:41:34,720
this conversation

00:41:31,680 --> 00:41:36,880
the first thing of course is that my

00:41:34,720 --> 00:41:39,839
very dear colleague nigat

00:41:36,880 --> 00:41:41,040
i shall speak for herself and myself are

00:41:39,839 --> 00:41:44,400
both

00:41:41,040 --> 00:41:46,560
part of a new organization

00:41:44,400 --> 00:41:48,000
powerful organization which is making

00:41:46,560 --> 00:41:50,319
decisions on

00:41:48,000 --> 00:41:51,119
uh facebook and instagram content

00:41:50,319 --> 00:41:53,520
moderation

00:41:51,119 --> 00:41:54,880
including the automated ones and i'm

00:41:53,520 --> 00:41:56,880
talking here about the

00:41:54,880 --> 00:41:59,599
the oversight board which was which was

00:41:56,880 --> 00:42:03,680
created almost a year ago now

00:41:59,599 --> 00:42:06,720
and for me this is exciting because

00:42:03,680 --> 00:42:10,400
it's honestly the first time

00:42:06,720 --> 00:42:13,680
in this industry that we are recognizing

00:42:10,400 --> 00:42:16,800
that the the expertise and knowledge

00:42:13,680 --> 00:42:20,560
from people who we thought before

00:42:16,800 --> 00:42:22,640
uh you know did not matter let's

00:42:20,560 --> 00:42:24,079
talk very frankly i mean i wouldn't i'm

00:42:22,640 --> 00:42:25,839
a black woman so

00:42:24,079 --> 00:42:28,000
how many chances i would have been here

00:42:25,839 --> 00:42:28,560
having this conversation 10 or 15 years

00:42:28,000 --> 00:42:30,560
ago

00:42:28,560 --> 00:42:32,800
but that would have been very difficult

00:42:30,560 --> 00:42:36,160
so uh i measure

00:42:32,800 --> 00:42:39,680
and i we we talked about that with night

00:42:36,160 --> 00:42:42,000
um often we measured uh you know

00:42:39,680 --> 00:42:43,599
what what we've been able to to do but

00:42:42,000 --> 00:42:44,480
that's not you know that's not the end

00:42:43,599 --> 00:42:47,520
of it all

00:42:44,480 --> 00:42:50,400
we are here and i'm here particularly uh

00:42:47,520 --> 00:42:53,440
with the purpose of making sure that

00:42:50,400 --> 00:42:53,920
whenever we will have our conversations

00:42:53,440 --> 00:42:56,720
about

00:42:53,920 --> 00:42:58,000
content moderation but others in general

00:42:56,720 --> 00:43:01,280
we will not look

00:42:58,000 --> 00:43:03,760
at people like me or uh you know

00:43:01,280 --> 00:43:06,079
people elsewhere outside of the us and

00:43:03,760 --> 00:43:09,760
outside of europe outside of canada

00:43:06,079 --> 00:43:12,400
as you know just consumers or users who

00:43:09,760 --> 00:43:13,119
we think about in the thought it's the

00:43:12,400 --> 00:43:15,760
priority

00:43:13,119 --> 00:43:17,680
it should be the principle and the other

00:43:15,760 --> 00:43:20,480
thing i'm excited about which is

00:43:17,680 --> 00:43:21,920
closely linked to uh to the one i just

00:43:20,480 --> 00:43:24,880
mentioned is that we're

00:43:21,920 --> 00:43:26,800
i'm doing a research right now at the

00:43:24,880 --> 00:43:27,760
digital civil society lab at stanford

00:43:26,800 --> 00:43:30,000
university

00:43:27,760 --> 00:43:31,839
and also as an affiliate at the berkeley

00:43:30,000 --> 00:43:34,560
client center at harvard

00:43:31,839 --> 00:43:35,280
uh when i'm working i mean i'm not even

00:43:34,560 --> 00:43:37,200
studying

00:43:35,280 --> 00:43:38,319
we've developed at anthony san francis

00:43:37,200 --> 00:43:40,880
methodology

00:43:38,319 --> 00:43:43,119
to make sure that in the automated

00:43:40,880 --> 00:43:45,280
moderation systems that

00:43:43,119 --> 00:43:46,319
platforms are rolling out as the

00:43:45,280 --> 00:43:49,280
solution to

00:43:46,319 --> 00:43:49,920
the content problems well we want to

00:43:49,280 --> 00:43:53,280
make sure

00:43:49,920 --> 00:43:54,160
to get you know the human back into the

00:43:53,280 --> 00:43:57,040
loop and

00:43:54,160 --> 00:43:58,240
by human i talk here about the very

00:43:57,040 --> 00:44:01,200
specific

00:43:58,240 --> 00:44:03,760
context that is missing from most of the

00:44:01,200 --> 00:44:06,000
automated content moderation systems

00:44:03,760 --> 00:44:08,400
and by doing that to bring those

00:44:06,000 --> 00:44:09,200
contacts to bring this very local

00:44:08,400 --> 00:44:12,960
knowledge

00:44:09,200 --> 00:44:15,599
we rely and we work with and we

00:44:12,960 --> 00:44:17,119
also you know collaborate as i was

00:44:15,599 --> 00:44:19,440
saying we collaborate

00:44:17,119 --> 00:44:20,319
with organizations in the countries

00:44:19,440 --> 00:44:22,800
where we work in

00:44:20,319 --> 00:44:23,920
and once we work with them we have a

00:44:22,800 --> 00:44:26,480
better understanding

00:44:23,920 --> 00:44:28,319
of what hate actually looks like in this

00:44:26,480 --> 00:44:29,119
country what disinformation actually

00:44:28,319 --> 00:44:33,280
looks like

00:44:29,119 --> 00:44:35,440
when you work only with people located

00:44:33,280 --> 00:44:37,520
in global north you're going to feed

00:44:35,440 --> 00:44:38,640
databases that are filled with errors

00:44:37,520 --> 00:44:40,400
and honestly

00:44:38,640 --> 00:44:42,319
 most of the times and that are

00:44:40,400 --> 00:44:45,359
even going to silence

00:44:42,319 --> 00:44:47,359
those who are actually using

00:44:45,359 --> 00:44:49,119
those platforms to bring a critical

00:44:47,359 --> 00:44:51,520
debate a critical

00:44:49,119 --> 00:44:52,800
voice that we don't like necessarily but

00:44:51,520 --> 00:44:55,119
that is necessary

00:44:52,800 --> 00:44:56,079
for for many democracies in the world to

00:44:55,119 --> 00:44:58,400
flourish

00:44:56,079 --> 00:44:59,200
and so that's the other part i'm excited

00:44:58,400 --> 00:45:02,079
about

00:44:59,200 --> 00:45:03,200
making sure that whenever we talk about

00:45:02,079 --> 00:45:06,079
those products

00:45:03,200 --> 00:45:08,160
uh we will adopt basically the same

00:45:06,079 --> 00:45:11,200
strategy as the bad actors

00:45:08,160 --> 00:45:14,319
why not test the good things you know

00:45:11,200 --> 00:45:15,119
by collaborating with civil society

00:45:14,319 --> 00:45:18,160
organizations

00:45:15,119 --> 00:45:20,640
in those countries and global majority

00:45:18,160 --> 00:45:21,680
i'm trying to educate myself too it's

00:45:20,640 --> 00:45:24,720
very difficult

00:45:21,680 --> 00:45:25,200
and uh yes that that's yeah that's the

00:45:24,720 --> 00:45:28,160
future

00:45:25,200 --> 00:45:29,119
i'm borrowing you know a word here from

00:45:28,160 --> 00:45:32,160
catherine mather

00:45:29,119 --> 00:45:35,040
who said that to make her work uh

00:45:32,160 --> 00:45:36,800
so positive heading the wikimedia

00:45:35,040 --> 00:45:38,960
foundation she looked at the future

00:45:36,800 --> 00:45:39,920
and the future was africa asia latin

00:45:38,960 --> 00:45:43,599
america

00:45:39,920 --> 00:45:45,040
thanks so i i think that's so important

00:45:43,599 --> 00:45:47,839
because so

00:45:45,040 --> 00:45:49,520
so many times the conversation is how do

00:45:47,839 --> 00:45:51,280
we have a seat at the table and not how

00:45:49,520 --> 00:45:53,200
do we make a new table or whoever said

00:45:51,280 --> 00:45:55,200
we wanted a table in the first place

00:45:53,200 --> 00:45:56,560
right like that's it's really really

00:45:55,200 --> 00:45:59,440
really important to think about

00:45:56,560 --> 00:46:00,079
what what uh how we build the future

00:45:59,440 --> 00:46:03,119
that we're

00:46:00,079 --> 00:46:04,560
intent upon uh living in sierra what

00:46:03,119 --> 00:46:07,599
about you what are you excited about

00:46:04,560 --> 00:46:09,680
what feels positive to you i'm also so

00:46:07,599 --> 00:46:11,599
excited about so many things and i

00:46:09,680 --> 00:46:13,119
i told you all about the just data lab

00:46:11,599 --> 00:46:14,960
and i'm so excited about the work that's

00:46:13,119 --> 00:46:17,680
going on there

00:46:14,960 --> 00:46:19,200
but in my own research i'm also i'm

00:46:17,680 --> 00:46:20,960
working on a project that

00:46:19,200 --> 00:46:22,240
that explores how minority political

00:46:20,960 --> 00:46:25,359
candidates in the u.s

00:46:22,240 --> 00:46:25,920
experience misindis information online

00:46:25,359 --> 00:46:27,839
and

00:46:25,920 --> 00:46:29,920
unsurprisingly it often borders on

00:46:27,839 --> 00:46:33,040
harassment one easy example

00:46:29,920 --> 00:46:34,560
is obama's anti-birther rumor that that

00:46:33,040 --> 00:46:36,079
accused him of not being born in the

00:46:34,560 --> 00:46:37,040
united states but that specifically

00:46:36,079 --> 00:46:39,920
hinged on his

00:46:37,040 --> 00:46:41,119
racial and ethnic identity but anyway

00:46:39,920 --> 00:46:43,680
all of that is to say

00:46:41,119 --> 00:46:45,920
that i'm really excited about a lot of

00:46:43,680 --> 00:46:48,079
the new tools that are springing up

00:46:45,920 --> 00:46:49,440
created by women created by people of

00:46:48,079 --> 00:46:52,720
color created by other

00:46:49,440 --> 00:46:54,400
other marginalized folks um to

00:46:52,720 --> 00:46:56,319
kind of solve these problems and i

00:46:54,400 --> 00:46:57,680
really appreciate what julie and sarah

00:46:56,319 --> 00:46:58,720
were talking about about bringing the

00:46:57,680 --> 00:47:00,640
human back in and

00:46:58,720 --> 00:47:02,160
one instrumental part of being human is

00:47:00,640 --> 00:47:05,359
the communities um

00:47:02,160 --> 00:47:07,680
that that we're a part of so one of my

00:47:05,359 --> 00:47:08,640
favorite examples is amy zhang's squad

00:47:07,680 --> 00:47:11,359
box which

00:47:08,640 --> 00:47:13,359
is a kind of crowd-sourced way for your

00:47:11,359 --> 00:47:15,839
friends and family to filter out

00:47:13,359 --> 00:47:17,520
negative negativity and harassment

00:47:15,839 --> 00:47:20,559
online and it really

00:47:17,520 --> 00:47:22,720
centers community involvement care

00:47:20,559 --> 00:47:24,960
and i love that these things are being

00:47:22,720 --> 00:47:25,920
infused into what we often deemed really

00:47:24,960 --> 00:47:28,240
impersonal

00:47:25,920 --> 00:47:29,200
kind of objective whatever that means

00:47:28,240 --> 00:47:31,599
systems

00:47:29,200 --> 00:47:32,960
and tools so i love that that's kind of

00:47:31,599 --> 00:47:36,559
being infused and

00:47:32,960 --> 00:47:36,559
i think that's the best way to move

00:47:36,839 --> 00:47:42,400
forward

00:47:38,240 --> 00:47:42,400
thank you what about you

00:47:42,880 --> 00:47:47,440
yeah i mean um as julie already said

00:47:46,960 --> 00:47:50,160
that

00:47:47,440 --> 00:47:50,640
um the experience that we both are

00:47:50,160 --> 00:47:53,359
having

00:47:50,640 --> 00:47:54,559
i think it's uh i'm it's i'm very

00:47:53,359 --> 00:47:58,160
excited and

00:47:54,559 --> 00:48:01,359
also you know like it's a it's unusual

00:47:58,160 --> 00:48:05,280
space for women like me a woman of color

00:48:01,359 --> 00:48:07,520
where you have like a a powerful

00:48:05,280 --> 00:48:08,880
space where you have all the power to

00:48:07,520 --> 00:48:10,800
take decisions

00:48:08,880 --> 00:48:12,800
and it's unusual for us because usually

00:48:10,800 --> 00:48:15,119
we don't have that kind of space

00:48:12,800 --> 00:48:17,280
and i i feel that it's so important to

00:48:15,119 --> 00:48:18,160
normalize these spaces for women of

00:48:17,280 --> 00:48:21,200
color

00:48:18,160 --> 00:48:23,520
who have um

00:48:21,200 --> 00:48:24,880
immense knowledge around human rights

00:48:23,520 --> 00:48:27,040
and technology

00:48:24,880 --> 00:48:28,720
uh and digital rights and we have so

00:48:27,040 --> 00:48:30,800
many women women of color

00:48:28,720 --> 00:48:32,720
and even if they are part of different

00:48:30,800 --> 00:48:35,280
boards or advisory councils

00:48:32,720 --> 00:48:36,400
how much voice they have and i think we

00:48:35,280 --> 00:48:38,480
really need to see that

00:48:36,400 --> 00:48:39,920
you know like how we can give them that

00:48:38,480 --> 00:48:42,319
voice um

00:48:39,920 --> 00:48:44,160
and at the micro level i'm very excited

00:48:42,319 --> 00:48:45,280
uh around the work that we are doing in

00:48:44,160 --> 00:48:48,079
pakistan

00:48:45,280 --> 00:48:48,720
uh i'm very excited to see a lot of

00:48:48,079 --> 00:48:51,599
women

00:48:48,720 --> 00:48:53,359
feminists taking lead around the

00:48:51,599 --> 00:48:55,680
discourse of digital rights

00:48:53,359 --> 00:48:56,880
and the kind of feminist internet we are

00:48:55,680 --> 00:49:01,280
making here

00:48:56,880 --> 00:49:04,240
um also you know uh looking into the

00:49:01,280 --> 00:49:05,440
issues that no one has ever looked into

00:49:04,240 --> 00:49:07,520
and then holding

00:49:05,440 --> 00:49:09,680
you know tech giants accountable or

00:49:07,520 --> 00:49:11,520
powerful actors accountable within the

00:49:09,680 --> 00:49:14,720
country while living in a country

00:49:11,520 --> 00:49:15,200
where in the patriarchal society talking

00:49:14,720 --> 00:49:17,599
to

00:49:15,200 --> 00:49:19,760
a powerful state is very difficult i'm

00:49:17,599 --> 00:49:20,400
very excited for that future especially

00:49:19,760 --> 00:49:23,280
on this

00:49:20,400 --> 00:49:25,440
international women's day i'm excited to

00:49:23,280 --> 00:49:26,960
see the feminist internet you know

00:49:25,440 --> 00:49:27,610
not just in pakistan but across the

00:49:26,960 --> 00:49:29,200
world

00:49:27,610 --> 00:49:31,520
[Music]

00:49:29,200 --> 00:49:32,319
and and and the other thing i think is

00:49:31,520 --> 00:49:34,000
really important

00:49:32,319 --> 00:49:36,000
and i'm going to tie it to one of the

00:49:34,000 --> 00:49:39,040
questions we got asked on twitter

00:49:36,000 --> 00:49:40,960
is that we're not talking about um uh

00:49:39,040 --> 00:49:42,400
only engaging something theoretically

00:49:40,960 --> 00:49:45,200
right like that these

00:49:42,400 --> 00:49:46,160
ideas of a feminist internet of a

00:49:45,200 --> 00:49:49,920
community

00:49:46,160 --> 00:49:52,960
led internet of of uh majority

00:49:49,920 --> 00:49:55,920
uh the global majority right that

00:49:52,960 --> 00:49:56,880
are actually about um being able to

00:49:55,920 --> 00:49:59,200
build

00:49:56,880 --> 00:50:00,319
and having the capacity to build

00:49:59,200 --> 00:50:03,760
autonomy

00:50:00,319 --> 00:50:06,640
and autonomous spaces that are that are

00:50:03,760 --> 00:50:07,520
um untethered from some from these

00:50:06,640 --> 00:50:10,640
systems

00:50:07,520 --> 00:50:13,040
uh of of inequality and

00:50:10,640 --> 00:50:14,000
and that and that they were designed to

00:50:13,040 --> 00:50:15,680
be

00:50:14,000 --> 00:50:17,520
unjust i mean i think that that's the

00:50:15,680 --> 00:50:19,599
piece is that it's not that

00:50:17,520 --> 00:50:21,839
it's just broken it's actually working

00:50:19,599 --> 00:50:23,920
in the ways that things were intended

00:50:21,839 --> 00:50:26,000
and insofar as we hold different

00:50:23,920 --> 00:50:27,760
intentions then we have to build

00:50:26,000 --> 00:50:30,079
for the for those intentions and i think

00:50:27,760 --> 00:50:32,720
that that's also a way that

00:50:30,079 --> 00:50:33,920
um uh it that's an opportunity i'm

00:50:32,720 --> 00:50:37,599
actually excited about

00:50:33,920 --> 00:50:39,760
so um is that um while

00:50:37,599 --> 00:50:40,800
certainly we see when we build

00:50:39,760 --> 00:50:44,240
unintentionally

00:50:40,800 --> 00:50:46,000
or on purpose unjustly what we

00:50:44,240 --> 00:50:48,240
what we get but that we actually do have

00:50:46,000 --> 00:50:51,440
the opportunity to build

00:50:48,240 --> 00:50:51,920
uh really specifically um in new ways

00:50:51,440 --> 00:50:55,520
and that

00:50:51,920 --> 00:50:58,800
and i have and i'm excited about that um

00:50:55,520 --> 00:51:00,240
um i think there are a lot of incredible

00:50:58,800 --> 00:51:02,160
conversations and things being built

00:51:00,240 --> 00:51:06,160
around data around data sovereignty

00:51:02,160 --> 00:51:09,680
around uh um around community access

00:51:06,160 --> 00:51:11,520
around looking at um uh um

00:51:09,680 --> 00:51:13,680
also who's holding who's holding what

00:51:11,520 --> 00:51:15,599
data and and for whom

00:51:13,680 --> 00:51:17,200
there's a lot there that that i feel

00:51:15,599 --> 00:51:21,359
really excited to unpack

00:51:17,200 --> 00:51:22,000
um and uh i told i told us that i'd

00:51:21,359 --> 00:51:24,000
point us to

00:51:22,000 --> 00:51:25,839
also to the rest of moss fest so i'm

00:51:24,000 --> 00:51:27,040
also excited the fact that a lot of what

00:51:25,839 --> 00:51:30,800
was discussed here

00:51:27,040 --> 00:51:33,200
is getting um uh teased out much more

00:51:30,800 --> 00:51:35,200
uh across so many different panels and

00:51:33,200 --> 00:51:38,079
conversations and workshops

00:51:35,200 --> 00:51:39,440
and in uh in spatial chat around moss

00:51:38,079 --> 00:51:42,240
fest so i really

00:51:39,440 --> 00:51:43,359
urge folks to um to participate in those

00:51:42,240 --> 00:51:45,760
conversations

00:51:43,359 --> 00:51:48,000
if anything that got uplifted here feels

00:51:45,760 --> 00:51:49,440
particularly germane

00:51:48,000 --> 00:51:52,079
one of the questions we got asked on

00:51:49,440 --> 00:51:55,680
twitter um and i think that this is

00:51:52,079 --> 00:51:57,599
um uh i'm gonna bring

00:51:55,680 --> 00:51:58,880
i'm gonna bring them together um i'm

00:51:57,599 --> 00:52:00,240
gonna tell you two questions and then

00:51:58,880 --> 00:52:02,480
anybody who wants to take it

00:52:00,240 --> 00:52:04,400
because i think we've touched on this in

00:52:02,480 --> 00:52:05,599
what ways can we bring an intersectional

00:52:04,400 --> 00:52:08,160
anti-oppression

00:52:05,599 --> 00:52:09,040
anti-cast lens into discussions and

00:52:08,160 --> 00:52:11,599
decisions

00:52:09,040 --> 00:52:12,960
about power inequalities in tech another

00:52:11,599 --> 00:52:15,680
question that came up

00:52:12,960 --> 00:52:17,599
is around um indigenous wisdom so

00:52:15,680 --> 00:52:18,240
community and indigenous wisdom how do

00:52:17,599 --> 00:52:20,319
we

00:52:18,240 --> 00:52:22,319
bring that into tech particularly in

00:52:20,319 --> 00:52:25,599
response to gendered harassment

00:52:22,319 --> 00:52:28,880
racial profiling or misinformation

00:52:25,599 --> 00:52:31,119
um and so i'll just and then

00:52:28,880 --> 00:52:32,400
and then the third question on twitter

00:52:31,119 --> 00:52:36,400
was how do we snap

00:52:32,400 --> 00:52:39,200
out of uh the pre the predetermined

00:52:36,400 --> 00:52:41,119
um identities some of us have been given

00:52:39,200 --> 00:52:44,319
so how do we actually

00:52:41,119 --> 00:52:47,280
um up end or or um

00:52:44,319 --> 00:52:49,599
avoid the algorithm uh versions of

00:52:47,280 --> 00:52:52,640
ourselves that we've been ascribed

00:52:49,599 --> 00:52:55,119
so those are the they're small easy

00:52:52,640 --> 00:52:58,319
questions

00:52:55,119 --> 00:53:00,240
but um if any of them speaks to you um

00:52:58,319 --> 00:53:01,839
um i'd love to hear what you have to say

00:53:00,240 --> 00:53:05,119
julia is that

00:53:01,839 --> 00:53:08,319
yeah yes thank you um i

00:53:05,119 --> 00:53:09,280
i will you know take the most difficult

00:53:08,319 --> 00:53:12,480
one

00:53:09,280 --> 00:53:12,960
which is related to how to make sure

00:53:12,480 --> 00:53:16,000
we're

00:53:12,960 --> 00:53:19,280
uh you know bringing in entire paternity

00:53:16,000 --> 00:53:21,760
uh and entire oppression views

00:53:19,280 --> 00:53:23,680
and knowledge and also indigenous

00:53:21,760 --> 00:53:26,880
knowledge i would like to flag

00:53:23,680 --> 00:53:29,920
one a very important uh

00:53:26,880 --> 00:53:32,480
procedure that exists out there so

00:53:29,920 --> 00:53:34,400
the oversight quote which i mentioned is

00:53:32,480 --> 00:53:37,599
a new organization which

00:53:34,400 --> 00:53:39,200
makes decision on content decision made

00:53:37,599 --> 00:53:42,240
by facebook and instagram

00:53:39,200 --> 00:53:45,920
on their platforms and one of the ways

00:53:42,240 --> 00:53:48,880
i mean we really want to foster

00:53:45,920 --> 00:53:49,680
interaction with the public i know the

00:53:48,880 --> 00:53:51,440
public is

00:53:49,680 --> 00:53:52,720
potentially two billion people so it's

00:53:51,440 --> 00:53:56,240
not you know

00:53:52,720 --> 00:53:59,760
possible virtually but we do have

00:53:56,240 --> 00:54:02,880
a uh a channel of communication which is

00:53:59,760 --> 00:54:04,960
through the public comment that we open

00:54:02,880 --> 00:54:07,200
uh for each case that we receive for

00:54:04,960 --> 00:54:08,880
instance we had a public comment period

00:54:07,200 --> 00:54:12,880
that was 10 days i think

00:54:08,880 --> 00:54:15,920
uh for the trump suspension account case

00:54:12,880 --> 00:54:17,839
we received a lot a lot of comments and

00:54:15,920 --> 00:54:19,680
many of them from northern

00:54:17,839 --> 00:54:22,079
institutions and particularly in the

00:54:19,680 --> 00:54:25,280
united states we had another case

00:54:22,079 --> 00:54:28,400
that's related to back blackface on

00:54:25,280 --> 00:54:30,800
on on facebook uh are we allowed to

00:54:28,400 --> 00:54:31,440
uh and particularly on svartipit who is

00:54:30,800 --> 00:54:35,359
a

00:54:31,440 --> 00:54:38,319
traditional uh christmas character

00:54:35,359 --> 00:54:40,640
in the in the in the netherlands and who

00:54:38,319 --> 00:54:42,960
who has been criticized for

00:54:40,640 --> 00:54:44,640
alleged racism and black facing and

00:54:42,960 --> 00:54:46,559
blackface has been

00:54:44,640 --> 00:54:48,240
you know recently facebook rolled out a

00:54:46,559 --> 00:54:50,079
new policy saying blackface is not

00:54:48,240 --> 00:54:52,640
allowed anymore on its platforms

00:54:50,079 --> 00:54:53,359
so uh we invited public comments on that

00:54:52,640 --> 00:54:55,280
as well

00:54:53,359 --> 00:54:57,520
i mean in general in all the cases that

00:54:55,280 --> 00:55:00,799
we have public comments are really

00:54:57,520 --> 00:55:03,440
a great opportunity for us to have

00:55:00,799 --> 00:55:05,119
you know access to another point of view

00:55:03,440 --> 00:55:07,440
that's not from the user

00:55:05,119 --> 00:55:08,559
that's not from facebook or instagram

00:55:07,440 --> 00:55:11,040
but that's you know for

00:55:08,559 --> 00:55:12,000
from organization working on this on the

00:55:11,040 --> 00:55:14,480
on this issue

00:55:12,000 --> 00:55:15,280
and it's it's very it's very helpful

00:55:14,480 --> 00:55:18,839
i'll give you

00:55:15,280 --> 00:55:22,799
one example in a case related to

00:55:18,839 --> 00:55:24,880
um azerbaijan and and armenia there were

00:55:22,799 --> 00:55:27,640
there was a publication published during

00:55:24,880 --> 00:55:30,480
a a conflict that happened in the

00:55:27,640 --> 00:55:31,200
nagorno-karabakh region earlier last

00:55:30,480 --> 00:55:34,000
year

00:55:31,200 --> 00:55:34,960
and uh we received a comment saying

00:55:34,000 --> 00:55:36,799
telling us that

00:55:34,960 --> 00:55:38,240
well you know in a case of conflict

00:55:36,799 --> 00:55:41,119
international human rights

00:55:38,240 --> 00:55:42,000
usually allows or is more permissible

00:55:41,119 --> 00:55:45,440
with regards

00:55:42,000 --> 00:55:48,480
to using you know very inflammatory

00:55:45,440 --> 00:55:50,400
words insults and all this we did i

00:55:48,480 --> 00:55:52,079
didn't know that personally and i found

00:55:50,400 --> 00:55:55,119
it very compelling and helpful

00:55:52,079 --> 00:55:56,960
so just to give an example of how we can

00:55:55,119 --> 00:55:58,160
you know deconstruct our preconceived

00:55:56,960 --> 00:56:00,480
ideas too as

00:55:58,160 --> 00:56:03,119
uh oversight board members and look at

00:56:00,480 --> 00:56:03,359
cases differently based on contributions

00:56:03,119 --> 00:56:05,200
and

00:56:03,359 --> 00:56:06,720
comments that we received from

00:56:05,200 --> 00:56:09,440
individuals or for

00:56:06,720 --> 00:56:09,440
institutions

00:56:10,880 --> 00:56:14,559
thank you um we have three minutes left

00:56:13,680 --> 00:56:18,240
sarah

00:56:14,559 --> 00:56:19,599
please take us give us your response to

00:56:18,240 --> 00:56:21,119
any of those questions tell us which

00:56:19,599 --> 00:56:24,880
ones you're answering

00:56:21,119 --> 00:56:27,359
um sure just on the blackface uh issue

00:56:24,880 --> 00:56:30,000
uh in in this book in the english or

00:56:27,359 --> 00:56:32,640
french edition whatever is your pleasure

00:56:30,000 --> 00:56:33,760
there is a content moderator working at

00:56:32,640 --> 00:56:37,280
mega tech

00:56:33,760 --> 00:56:38,319
who raises this issue uh starting in

00:56:37,280 --> 00:56:40,400
00:56:38,319 --> 00:56:41,760
and so there's these other points of

00:56:40,400 --> 00:56:43,760
input that we can

00:56:41,760 --> 00:56:45,280
bring to the table about who sees

00:56:43,760 --> 00:56:48,400
problems and who

00:56:45,280 --> 00:56:49,839
who who has foresight and commercial

00:56:48,400 --> 00:56:52,000
content moderators at

00:56:49,839 --> 00:56:53,760
firms whether they are are located at

00:56:52,000 --> 00:56:55,599
the firms or whether they are

00:56:53,760 --> 00:56:56,880
at geographical and organizational

00:56:55,599 --> 00:56:59,520
remove as uh

00:56:56,880 --> 00:57:00,079
contractors have incredible insight and

00:56:59,520 --> 00:57:01,760
knowledge

00:57:00,079 --> 00:57:03,520
about these things and yet that

00:57:01,760 --> 00:57:04,640
knowledge has gone directly to the

00:57:03,520 --> 00:57:08,000
garbage can

00:57:04,640 --> 00:57:09,359
in most cases so i i want to acknowledge

00:57:08,000 --> 00:57:11,599
the work that they do

00:57:09,359 --> 00:57:13,760
and the kinds of information they also

00:57:11,599 --> 00:57:16,960
have that has been

00:57:13,760 --> 00:57:18,480
pretty much uh not taken up and who does

00:57:16,960 --> 00:57:20,480
commercial content moderation well it's

00:57:18,480 --> 00:57:23,119
some of the very people that we are

00:57:20,480 --> 00:57:24,160
concerned with uh in this conversation

00:57:23,119 --> 00:57:27,440
that we've had

00:57:24,160 --> 00:57:30,319
um with apologies to audre lorde

00:57:27,440 --> 00:57:31,839
uh the master's tools will not dismantle

00:57:30,319 --> 00:57:34,240
the master's house

00:57:31,839 --> 00:57:35,359
we are in a paradigm where tech defines

00:57:34,240 --> 00:57:38,640
not only

00:57:35,359 --> 00:57:40,240
the answers but the problems and so what

00:57:38,640 --> 00:57:43,440
i would urge everyone to do

00:57:40,240 --> 00:57:46,000
is to um push back on that framing and

00:57:43,440 --> 00:57:48,000
we we will take the power to ask our own

00:57:46,000 --> 00:57:50,720
questions and answer them

00:57:48,000 --> 00:57:51,920
appropriately using the expertise and

00:57:50,720 --> 00:57:54,559
knowledge we have from our lived

00:57:51,920 --> 00:57:57,040
experience from our communities

00:57:54,559 --> 00:57:57,760
from indigenous ways of knowing all the

00:57:57,040 --> 00:57:59,680
places

00:57:57,760 --> 00:58:01,440
that have historically and continue to

00:57:59,680 --> 00:58:05,119
be ignored and denied

00:58:01,440 --> 00:58:07,680
so i i refute um being in a space where

00:58:05,119 --> 00:58:11,040
i respond to the problems that tech

00:58:07,680 --> 00:58:13,119
creates and then asks us to fix

00:58:11,040 --> 00:58:14,559
and then also doesn't take up what we

00:58:13,119 --> 00:58:16,240
have to say by the way

00:58:14,559 --> 00:58:17,839
so i will say we bring we're going to

00:58:16,240 --> 00:58:21,280
bring new

00:58:17,839 --> 00:58:22,640
questions and answers not maybe even not

00:58:21,280 --> 00:58:26,160
to the table as you said

00:58:22,640 --> 00:58:28,319
earlier thank you to another place

00:58:26,160 --> 00:58:30,079
right on we're at time so i want to give

00:58:28,319 --> 00:58:32,240
sierra and you got

00:58:30,079 --> 00:58:36,640
a word if you'd like to bring anything

00:58:32,240 --> 00:58:38,480
into the room

00:58:36,640 --> 00:58:39,760
i just want to plus one everything that

00:58:38,480 --> 00:58:42,880
was already

00:58:39,760 --> 00:58:44,559
right on my god yeah same here

00:58:42,880 --> 00:58:46,640
again to everything whatever has has

00:58:44,559 --> 00:58:49,440
been said beautiful

00:58:46,640 --> 00:58:50,640
thank you so much sierra julie negot

00:58:49,440 --> 00:58:53,280
sarah for joining us

00:58:50,640 --> 00:58:53,920
thank you all out there for joining us

00:58:53,280 --> 00:58:57,119
remember

00:58:53,920 --> 00:59:00,400
that um power is already ours and

00:58:57,119 --> 00:59:03,680
this is about actually um um stepping up

00:59:00,400 --> 00:59:04,559
uh in in community in collaboration and

00:59:03,680 --> 00:59:06,400
in purpose

00:59:04,559 --> 00:59:07,760
to exercise that power so thanks

00:59:06,400 --> 00:59:19,839
everyone and

00:59:07,760 --> 00:59:19,839
see you at the rest of mazfest

01:00:03,760 --> 01:00:05,839

YouTube URL: https://www.youtube.com/watch?v=x1NYw0Q7BCs


