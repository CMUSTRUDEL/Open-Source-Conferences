Title: MozFest 2019 - Content Moderation’s Toll - Panel
Publication date: 2019-11-04
Playlist: Mozilla Festival 2019
Description: 
	A hidden workforce tries to keep platforms free from violence and pornography. How do they cope?

Hans Block - Director of “The Cleaners”
Gabi Ivens - Independent open source researcher and Mozilla Fellow
Chris Gray - Former content moderator for Facebook, and lead plaintiff in a class action representing moderators who have been harmed by the work
Moritz Riesewieck - Director of “The Cleaners”
Clara Tsao - Content moderation researcher and Mozilla Fellow
Captions: 
	00:00:00,570 --> 00:00:04,020
welcome to day two of the panel

00:00:02,820 --> 00:00:05,549
discussion at Moss fest

00:00:04,020 --> 00:00:06,930
my name is Xavier Harding round of

00:00:05,549 --> 00:00:11,929
applause for all the folks here at

00:00:06,930 --> 00:00:14,820
Mozilla who put the show on today

00:00:11,929 --> 00:00:16,529
so unfortunately Desmond Patton who

00:00:14,820 --> 00:00:19,260
you'll see in your program is not here

00:00:16,529 --> 00:00:21,000
today he had to cancel out but we have a

00:00:19,260 --> 00:00:23,100
great first panel discussion about

00:00:21,000 --> 00:00:24,960
content moderation stole so I'd like to

00:00:23,100 --> 00:00:26,099
invite our panelists on stage right now

00:00:24,960 --> 00:00:32,460
so panelists if you guys would like to

00:00:26,099 --> 00:00:34,110
come on stage there's a lot of

00:00:32,460 --> 00:00:37,320
discussion about who six where so we'll

00:00:34,110 --> 00:00:42,090
see how they sort it out which sees all

00:00:37,320 --> 00:00:44,040
right nice so I want to start off by

00:00:42,090 --> 00:00:45,719
introducing everyone here on stage this

00:00:44,040 --> 00:00:47,160
is actually our biggest panel discussion

00:00:45,719 --> 00:00:51,180
this weekend but I think it's gonna be a

00:00:47,160 --> 00:00:55,170
good one so first off we have Gabi

00:00:51,180 --> 00:00:57,449
Ivan's Gabi was the creator of the data

00:00:55,170 --> 00:01:00,270
leaks project back when she's at Mozilla

00:00:57,449 --> 00:01:01,680
basically she looked at hacked emails

00:01:00,270 --> 00:01:03,500
and found the recipes within those

00:01:01,680 --> 00:01:05,700
hacked emails and kind of made a little

00:01:03,500 --> 00:01:08,400
pseudo cookbook nothing an actual

00:01:05,700 --> 00:01:09,869
cookbook is coming out soon yeah and

00:01:08,400 --> 00:01:12,270
what she's not cooking up hacked

00:01:09,869 --> 00:01:13,439
information Gabi works in the field of

00:01:12,270 --> 00:01:15,479
Human Rights working to preserve

00:01:13,439 --> 00:01:19,530
publicly available information about

00:01:15,479 --> 00:01:22,890
human rights violations next to her we

00:01:19,530 --> 00:01:25,680
have Chris gray Chris grades based in

00:01:22,890 --> 00:01:28,229
Dublin Chris was a former Content

00:01:25,680 --> 00:01:30,299
moderator at Facebook and he broke his

00:01:28,229 --> 00:01:32,610
NDA at Facebook to talk about everything

00:01:30,299 --> 00:01:34,829
that goes on inside there he's also

00:01:32,610 --> 00:01:36,900
currently the lead lead plaintiff in a

00:01:34,829 --> 00:01:40,020
class-action lawsuit against the company

00:01:36,900 --> 00:01:41,820
representing moderators who are harmed

00:01:40,020 --> 00:01:43,560
by this content or who constant

00:01:41,820 --> 00:01:46,290
moderation so we're really glad to have

00:01:43,560 --> 00:01:48,540
you here today now we have Moritz and

00:01:46,290 --> 00:01:50,850
hunts these are the directors of the

00:01:48,540 --> 00:01:53,399
cleaners cleaners is a documentary about

00:01:50,850 --> 00:01:55,710
content moderation on social media

00:01:53,399 --> 00:01:59,250
platforms and then last but not least we

00:01:55,710 --> 00:02:01,229
have Clara Clara is a former CTO in the

00:01:59,250 --> 00:02:03,360
US Department of Homeland Security

00:02:01,229 --> 00:02:05,640
former strategic partnerships lead at

00:02:03,360 --> 00:02:08,340
Microsoft former Google fellow current

00:02:05,640 --> 00:02:11,009
Mozilla fellow and you also fellow at

00:02:08,340 --> 00:02:13,390
the German Marshall Fund of the US is

00:02:11,009 --> 00:02:15,130
that true good great

00:02:13,390 --> 00:02:18,730
so yeah we're here to talk today about

00:02:15,130 --> 00:02:19,600
the toll of content moderation so I just

00:02:18,730 --> 00:02:22,840
kind of wanna start off with some

00:02:19,600 --> 00:02:24,460
background you know for anyone wants to

00:02:22,840 --> 00:02:27,100
answer you know what is content

00:02:24,460 --> 00:02:33,720
moderation what qualifies as a Content

00:02:27,100 --> 00:02:37,780
moderator online I mean one of the

00:02:33,720 --> 00:02:39,460
corporate Facebook's mottos was giving

00:02:37,780 --> 00:02:42,000
everyone the power to share anything

00:02:39,460 --> 00:02:44,800
with anyone and the question is is

00:02:42,000 --> 00:02:46,480
anything true and the answer is no

00:02:44,800 --> 00:02:49,270
because all of these social media

00:02:46,480 --> 00:02:51,040
platforms have some specific guidelines

00:02:49,270 --> 00:02:53,650
some community standards what is allowed

00:02:51,040 --> 00:02:56,080
to post on Facebook or Google or YouTube

00:02:53,650 --> 00:02:59,110
or Twitter and what is not and the ones

00:02:56,080 --> 00:03:02,110
deciding about what to post and what not

00:02:59,110 --> 00:03:04,810
these people are called content

00:03:02,110 --> 00:03:06,280
moderators and most of them don't get

00:03:04,810 --> 00:03:07,510
their paychecks from Facebook Google

00:03:06,280 --> 00:03:09,610
Twitter themselves they get their

00:03:07,510 --> 00:03:11,260
pictures by outsourcing companies and

00:03:09,610 --> 00:03:13,750
what they do they are sitting in front

00:03:11,260 --> 00:03:16,300
of his desk eight to ten hours every day

00:03:13,750 --> 00:03:21,760
and they review all of the content which

00:03:16,300 --> 00:03:23,620
is suspicious flagged by an algorithm or

00:03:21,760 --> 00:03:26,830
by users and they have to decide if

00:03:23,620 --> 00:03:29,680
these posts are supposed to be online or

00:03:26,830 --> 00:03:31,630
not so this is what we researched about

00:03:29,680 --> 00:03:33,850
and the guys are called content

00:03:31,630 --> 00:03:35,800
moderators and I and I did want to give

00:03:33,850 --> 00:03:37,350
a little bit of history to help set the

00:03:35,800 --> 00:03:40,510
context of what was just said

00:03:37,350 --> 00:03:41,950
historically content moderation actually

00:03:40,510 --> 00:03:43,480
came from all of you guys here at the

00:03:41,950 --> 00:03:45,910
audience if you remember the early days

00:03:43,480 --> 00:03:48,220
of AOL chat rooms there were people that

00:03:45,910 --> 00:03:50,350
were volunteers that would go and help

00:03:48,220 --> 00:03:52,630
companies determine what is acceptable

00:03:50,350 --> 00:03:55,390
and what's not and really but the

00:03:52,630 --> 00:03:58,180
definition I have is individuals that

00:03:55,390 --> 00:04:00,220
help develop and enforce policies that

00:03:58,180 --> 00:04:02,650
deem what is acceptable content and what

00:04:00,220 --> 00:04:04,209
is not and there is actually a grading

00:04:02,650 --> 00:04:05,740
of different professionals that work in

00:04:04,209 --> 00:04:08,770
this field so what I just described

00:04:05,740 --> 00:04:10,720
historically has been content moderation

00:04:08,770 --> 00:04:12,550
as a volunteer industry in the early

00:04:10,720 --> 00:04:14,730
days of the internet where this

00:04:12,550 --> 00:04:18,030
professional field did not even exist

00:04:14,730 --> 00:04:21,750
and overtime company started hire

00:04:18,030 --> 00:04:24,190
individuals that came from rules from IP

00:04:21,750 --> 00:04:26,200
IP lawyers that were used to weighing

00:04:24,190 --> 00:04:27,190
content on the gray to set content

00:04:26,200 --> 00:04:29,800
policies

00:04:27,190 --> 00:04:32,730
all the way to individuals that started

00:04:29,800 --> 00:04:36,190
to do spam and deal with bullying online

00:04:32,730 --> 00:04:38,950
in customer support roles that move

00:04:36,190 --> 00:04:41,470
their way up to the top rungs of certain

00:04:38,950 --> 00:04:43,300
companies but user-generated content has

00:04:41,470 --> 00:04:45,070
been increasing you know every single

00:04:43,300 --> 00:04:47,980
year with more and more individuals

00:04:45,070 --> 00:04:49,630
online and so a lot of major companies

00:04:47,980 --> 00:04:52,120
they start to develop what's known today

00:04:49,630 --> 00:04:54,640
as trust and safety teams and a lot of

00:04:52,120 --> 00:04:56,950
this work cannot be done by individuals

00:04:54,640 --> 00:04:59,020
and Impa knees alone and so a lot of

00:04:56,950 --> 00:05:01,060
companies what they've done recently is

00:04:59,020 --> 00:05:04,000
they've started to outsource this work

00:05:01,060 --> 00:05:06,930
to vendors from cognizance to Accenture

00:05:04,000 --> 00:05:09,810
and the odd number of third parties that

00:05:06,930 --> 00:05:11,680
estimates say they're around 100,000

00:05:09,810 --> 00:05:14,430
professionals that work in this field

00:05:11,680 --> 00:05:17,350
alone some in the US and some in

00:05:14,430 --> 00:05:18,850
emerging markets in which they really

00:05:17,350 --> 00:05:20,890
deal with the worst of the worst of the

00:05:18,850 --> 00:05:23,170
Internet's trash that comes from the

00:05:20,890 --> 00:05:25,960
Western world and so that's been a lot

00:05:23,170 --> 00:05:27,880
of discussion and framing of what is

00:05:25,960 --> 00:05:30,070
that professional ladder that people go

00:05:27,880 --> 00:05:32,050
through in this field how do we ensure

00:05:30,070 --> 00:05:34,540
that people in this field are respected

00:05:32,050 --> 00:05:37,450
and one of the discussions that Xavier

00:05:34,540 --> 00:05:41,140
and I had earlier is around a platform

00:05:37,450 --> 00:05:42,460
called 4chan on 4chan people who do this

00:05:41,140 --> 00:05:44,350
rule of moderation they're all

00:05:42,460 --> 00:05:47,500
volunteers they're literally called

00:05:44,350 --> 00:05:49,150
janitors they determine what's accepted

00:05:47,500 --> 00:05:51,400
on a floor Chanin it's all volunteer

00:05:49,150 --> 00:05:53,200
base but you know how can we actually

00:05:51,400 --> 00:05:55,780
uplift and ensure that there are fair

00:05:53,200 --> 00:05:57,790
working conditions in this community if

00:05:55,780 --> 00:05:59,560
that is the term that we're calling them

00:05:57,790 --> 00:06:01,720
right that's that's really good insight

00:05:59,560 --> 00:06:03,040
I definitely get Chris's opinion in here

00:06:01,720 --> 00:06:04,660
because you know because you tell us

00:06:03,040 --> 00:06:09,400
like what the day-to-day is like for a

00:06:04,660 --> 00:06:13,180
Content moderator for a censor yeah yeah

00:06:09,400 --> 00:06:15,669
I mean criticism of Facebook is

00:06:13,180 --> 00:06:17,410
permitted on the platform so and then

00:06:15,669 --> 00:06:19,810
people complain about the criticism and

00:06:17,410 --> 00:06:23,560
I will see messages telling me that I'm

00:06:19,810 --> 00:06:25,419
a Nazi or you know the killing I'm

00:06:23,560 --> 00:06:28,680
killing free speech I'm censoring people

00:06:25,419 --> 00:06:30,790
so we're quite happy about that because

00:06:28,680 --> 00:06:32,560
fine you know you can say what you like

00:06:30,790 --> 00:06:34,630
my job is actually to allow you to say

00:06:32,560 --> 00:06:36,550
that and I can send it back and say no

00:06:34,630 --> 00:06:38,890
not violating and then I click the

00:06:36,550 --> 00:06:40,870
button and I get another one and it's

00:06:38,890 --> 00:06:44,710
just to be honest most of the work

00:06:40,870 --> 00:06:45,850
is tedious it's just people reporting

00:06:44,710 --> 00:06:48,040
each other because they're having an

00:06:45,850 --> 00:06:49,900
argument and they want to use some

00:06:48,040 --> 00:06:52,870
process to get back at the other person

00:06:49,900 --> 00:06:55,540
it's people taking umbrage about small

00:06:52,870 --> 00:06:57,130
things or complaining about things that

00:06:55,540 --> 00:06:59,500
don't fit with their own personal

00:06:57,130 --> 00:07:01,240
morality and a lot of the time you're

00:06:59,500 --> 00:07:04,780
just sitting there saying oh for God's

00:07:01,240 --> 00:07:07,090
sake get a life this is fine not a

00:07:04,780 --> 00:07:08,680
problem you've seen in the news right

00:07:07,090 --> 00:07:10,900
you've seen all this oh it's all

00:07:08,680 --> 00:07:13,120
terrible content and it's eight hours a

00:07:10,900 --> 00:07:16,900
day of people butchering each other it's

00:07:13,120 --> 00:07:18,700
not it most of it is just Jesus what's

00:07:16,900 --> 00:07:20,440
wrong with these people and then and

00:07:18,700 --> 00:07:22,450
then you get something horrifying and

00:07:20,440 --> 00:07:25,960
and then you carry on and then you get

00:07:22,450 --> 00:07:29,560
something funny and it's the job is not

00:07:25,960 --> 00:07:32,320
as bad as they make it seem I think the

00:07:29,560 --> 00:07:34,479
worst part is being audited

00:07:32,320 --> 00:07:36,490
there's people checking to see if you've

00:07:34,479 --> 00:07:37,840
done your job properly they're reviewing

00:07:36,490 --> 00:07:41,889
the same tickets and making their own

00:07:37,840 --> 00:07:44,830
decisions applying the same rules 20 odd

00:07:41,889 --> 00:07:46,660
thousand words of instructions that I

00:07:44,830 --> 00:07:49,030
have to keep in my head all the time

00:07:46,660 --> 00:07:50,800
when I'm looking at this content and if

00:07:49,030 --> 00:07:52,690
their decision is very slightly

00:07:50,800 --> 00:07:55,090
different from mine there's about a

00:07:52,690 --> 00:07:56,979
hundred options to choose from then I've

00:07:55,090 --> 00:07:59,349
made a mistake and I'm facing getting

00:07:56,979 --> 00:08:00,880
fired if I get too many mistakes so I

00:07:59,349 --> 00:08:07,270
think Gaby wanted to talk a little bit

00:08:00,880 --> 00:08:09,490
about that right yes I think earlier we

00:08:07,270 --> 00:08:11,139
talked about content moderators deciding

00:08:09,490 --> 00:08:12,520
what content stays on and actually

00:08:11,139 --> 00:08:14,349
they're not deciding they're just

00:08:12,520 --> 00:08:16,419
implementing a policy that's been

00:08:14,349 --> 00:08:19,539
decided for them and trying to make

00:08:16,419 --> 00:08:21,130
those decisions about which content

00:08:19,539 --> 00:08:23,680
should say online is very stressful

00:08:21,130 --> 00:08:25,030
especially if you have a very high

00:08:23,680 --> 00:08:28,419
accuracy rate that you're having to

00:08:25,030 --> 00:08:30,639
reach so I think the reason I'm on this

00:08:28,419 --> 00:08:32,680
panel is because the cookbook actually

00:08:30,639 --> 00:08:35,860
was a hobby because most of the time I

00:08:32,680 --> 00:08:37,900
spend on viewing graphic content for

00:08:35,860 --> 00:08:39,820
human rights violations so I spent a lot

00:08:37,900 --> 00:08:42,789
of my time looking at graphic videos and

00:08:39,820 --> 00:08:45,070
images and because of that I started to

00:08:42,789 --> 00:08:47,050
research vicarious trauma the idea of

00:08:45,070 --> 00:08:48,940
trauma through seeing something this

00:08:47,050 --> 00:08:51,190
traumatic so not experiencing yourself

00:08:48,940 --> 00:08:53,589
but experiencing it through someone

00:08:51,190 --> 00:08:54,710
else's trauma and I started to interview

00:08:53,589 --> 00:08:57,230
people

00:08:54,710 --> 00:08:58,850
you were also viewing graphic content as

00:08:57,230 --> 00:09:01,580
part of their work so people working in

00:08:58,850 --> 00:09:04,580
Child Exploitation lawyers journalists

00:09:01,580 --> 00:09:05,870
and of course content moderators and I

00:09:04,580 --> 00:09:09,920
started to see what are the strategies

00:09:05,870 --> 00:09:11,600
what are the best practices and none of

00:09:09,920 --> 00:09:14,240
the strategies that I identified through

00:09:11,600 --> 00:09:16,700
talking to 60 people seemed to work for

00:09:14,240 --> 00:09:19,280
content moderators they're the industry

00:09:16,700 --> 00:09:20,990
of commercial content moderators in my

00:09:19,280 --> 00:09:23,420
opinion none of them will work and one

00:09:20,990 --> 00:09:25,820
of the aspects of this is around feeling

00:09:23,420 --> 00:09:29,210
like you have no control so you have

00:09:25,820 --> 00:09:30,260
these policies you have these decisions

00:09:29,210 --> 00:09:31,820
that you're having to do and sometimes

00:09:30,260 --> 00:09:34,250
you won't be out you won't agree with

00:09:31,820 --> 00:09:35,660
them so you might be keeping something

00:09:34,250 --> 00:09:36,740
online that you actually don't agree

00:09:35,660 --> 00:09:39,320
there it should stay there but the

00:09:36,740 --> 00:09:40,460
policies say it should remain and all

00:09:39,320 --> 00:09:42,710
your taking something down that you

00:09:40,460 --> 00:09:45,230
think should say up so this level of

00:09:42,710 --> 00:09:46,940
lack of control it's actually very

00:09:45,230 --> 00:09:49,220
harmful to you in the job that you're

00:09:46,940 --> 00:09:50,860
doing and other other professionals

00:09:49,220 --> 00:09:53,060
don't have this same the same issue

00:09:50,860 --> 00:09:55,220
you're implementing other people's

00:09:53,060 --> 00:09:57,440
standards there was a campaign a few

00:09:55,220 --> 00:09:59,630
years ago called free the nipple did

00:09:57,440 --> 00:10:02,780
anybody remember that one yeah hands up

00:09:59,630 --> 00:10:05,420
who doesn't like nipples no but you have

00:10:02,780 --> 00:10:07,580
to take them down every time and then

00:10:05,420 --> 00:10:09,260
and then people start protesting and I'm

00:10:07,580 --> 00:10:12,710
in the middle saying oh I just have to

00:10:09,260 --> 00:10:15,200
follow the policy I'm sorry one of my

00:10:12,710 --> 00:10:18,440
trainers did say to me one day we're not

00:10:15,200 --> 00:10:20,870
actually here to take things down we are

00:10:18,440 --> 00:10:22,820
here to look at something objectively

00:10:20,870 --> 00:10:25,700
and see if we can leave it up we're not

00:10:22,820 --> 00:10:27,670
actually here to clean up we're here to

00:10:25,700 --> 00:10:31,490
just keep things moving along and and

00:10:27,670 --> 00:10:33,260
give people the maximum freedom but at

00:10:31,490 --> 00:10:35,390
the same time we do have to implement

00:10:33,260 --> 00:10:38,750
these standards and yeah do what you're

00:10:35,390 --> 00:10:40,280
told and anything one really interesting

00:10:38,750 --> 00:10:42,350
question that you just brought up is

00:10:40,280 --> 00:10:44,510
what is acceptable content online and

00:10:42,350 --> 00:10:46,940
how does that actually bridge into

00:10:44,510 --> 00:10:49,190
cultural context is right what is

00:10:46,940 --> 00:10:50,750
considered acceptable for nipples in the

00:10:49,190 --> 00:10:53,030
Middle East might be very different from

00:10:50,750 --> 00:10:54,890
what it is in France or in certain parts

00:10:53,030 --> 00:10:56,780
of the Western world and that is

00:10:54,890 --> 00:10:59,150
something that is really difficult in

00:10:56,780 --> 00:11:01,070
this job is determining with local

00:10:59,150 --> 00:11:04,310
context what is considered acceptable

00:11:01,070 --> 00:11:06,350
and the question of how companies shirts

00:11:04,310 --> 00:11:07,780
at these policies and who writes these

00:11:06,350 --> 00:11:09,610
policies to make

00:11:07,780 --> 00:11:11,170
that it is actually representative what

00:11:09,610 --> 00:11:15,040
we deemed to be socially acceptable

00:11:11,170 --> 00:11:18,610
online and if I may just add that from

00:11:15,040 --> 00:11:21,750
our experience there actually two main

00:11:18,610 --> 00:11:25,900
challenges I would sum up one is the

00:11:21,750 --> 00:11:28,480
psychological one and I totally got from

00:11:25,900 --> 00:11:31,270
your explanation that you not have to

00:11:28,480 --> 00:11:32,890
scream horrible content for eight hours

00:11:31,270 --> 00:11:36,730
a day but we know a lot of people who

00:11:32,890 --> 00:11:38,340
did and we cover them in our film and

00:11:36,730 --> 00:11:42,400
they are mainly in the Philippines and

00:11:38,340 --> 00:11:44,800
what they had to screen is I don't want

00:11:42,400 --> 00:11:47,920
to explain what but it was just so

00:11:44,800 --> 00:11:51,160
traumatizing to a lot of them that it

00:11:47,920 --> 00:11:54,820
would almost seem cynical for me to let

00:11:51,160 --> 00:11:59,500
it stand here as a claim that this job

00:11:54,820 --> 00:12:02,980
is not psychologically horrifying it is

00:11:59,500 --> 00:12:05,320
no it is and you know I say that 90% of

00:12:02,980 --> 00:12:07,930
what you see is benign or boring but

00:12:05,320 --> 00:12:11,320
that 10% I was working

00:12:07,930 --> 00:12:14,070
typically 600 tickets a day so I

00:12:11,320 --> 00:12:17,170
imagined 10% of that is you know 60

00:12:14,070 --> 00:12:18,370
really awful yeah why don't you talk

00:12:17,170 --> 00:12:19,750
more about that because you said you

00:12:18,370 --> 00:12:22,360
know you told me you know backstage that

00:12:19,750 --> 00:12:24,250
90% of this stuff is not that graphic

00:12:22,360 --> 00:12:25,540
but then there's 10% that is I think

00:12:24,250 --> 00:12:27,400
there's a there's generally like a

00:12:25,540 --> 00:12:29,080
cachet or maybe there used to be when it

00:12:27,400 --> 00:12:30,550
comes to like I work at Facebook like

00:12:29,080 --> 00:12:32,440
you know six-figure salary living in

00:12:30,550 --> 00:12:33,970
Silicon Valley but you know this is not

00:12:32,440 --> 00:12:37,600
that it seems like could you talk about

00:12:33,970 --> 00:12:40,660
that duality of you know why don't they

00:12:37,600 --> 00:12:41,560
pay content moderators like the same way

00:12:40,660 --> 00:12:44,730
like why don't they get the same

00:12:41,560 --> 00:12:48,970
benefits 12 euros in 98 cents per hour

00:12:44,730 --> 00:12:51,510
yeah fantastic yeah and you and I pay

00:12:48,970 --> 00:12:53,920
taxes on that yeah and Dublin rent yes

00:12:51,510 --> 00:12:55,839
between one and three dollars that

00:12:53,920 --> 00:12:59,230
that's at the time we researched in the

00:12:55,839 --> 00:13:02,940
Philippines for an hour Wow

00:12:59,230 --> 00:13:06,300
and that was also the reason why we

00:13:02,940 --> 00:13:08,860
focused on on these people there because

00:13:06,300 --> 00:13:11,589
actually for them it's even harder a lot

00:13:08,860 --> 00:13:15,280
of times to get the lobby or to at least

00:13:11,589 --> 00:13:19,360
get their thoughts on this work being

00:13:15,280 --> 00:13:22,570
heard and in our film we we cover people

00:13:19,360 --> 00:13:24,339
who just had to stay in the job because

00:13:22,570 --> 00:13:28,000
they were the breadwinners for their

00:13:24,339 --> 00:13:31,180
families sometimes six seven people and

00:13:28,000 --> 00:13:33,400
their lives they financed and they

00:13:31,180 --> 00:13:36,970
didn't get any psychological support I

00:13:33,400 --> 00:13:38,980
mean there was a psychologists come in

00:13:36,970 --> 00:13:40,839
every three months and then the whole

00:13:38,980 --> 00:13:43,420
staff was gathered in a room like here

00:13:40,839 --> 00:13:46,209
now and then the psychologist asked them

00:13:43,420 --> 00:13:49,660
how do you guys feel and they were like

00:13:46,209 --> 00:13:51,370
now I should I should share my by my

00:13:49,660 --> 00:13:55,600
thoughts on the job I should share my

00:13:51,370 --> 00:13:56,770
psychic finger-painting and yoga every

00:13:55,600 --> 00:13:58,540
couple of weeks I would get an email

00:13:56,770 --> 00:14:01,480
saying huh hey guys finger painting

00:13:58,540 --> 00:14:04,510
tonight come home great wellness team

00:14:01,480 --> 00:14:07,839
thank you guys nice I mean it's highly

00:14:04,510 --> 00:14:10,209
cynical the whole thing and so and

00:14:07,839 --> 00:14:12,550
a lot of people just stay in the job for

00:14:10,209 --> 00:14:14,350
let's say 3-4 months and then they have

00:14:12,550 --> 00:14:16,380
to leave because otherwise they they

00:14:14,350 --> 00:14:18,250
just can't cope anymore with the

00:14:16,380 --> 00:14:20,890
psychological damage they are suffering

00:14:18,250 --> 00:14:23,080
from and then they they are just left

00:14:20,890 --> 00:14:25,030
alone around any psychologists like

00:14:23,080 --> 00:14:26,860
following up with them they're just left

00:14:25,030 --> 00:14:30,730
alone and you never know when the trauma

00:14:26,860 --> 00:14:33,580
will will join you and like yeah it took

00:14:30,730 --> 00:14:34,510
me a year before I realized that this

00:14:33,580 --> 00:14:37,420
job knocked me on my ass

00:14:34,510 --> 00:14:40,450
it really did get the better of me and a

00:14:37,420 --> 00:14:42,730
year later I'm phoning my health

00:14:40,450 --> 00:14:44,890
insurance company to say hey you know

00:14:42,730 --> 00:14:46,750
I've discovered I have this problem and

00:14:44,890 --> 00:14:48,370
they said well your cover was canceled

00:14:46,750 --> 00:14:51,190
today you left and it doesn't cover

00:14:48,370 --> 00:14:53,260
mental health issues anyway and I have a

00:14:51,190 --> 00:14:55,780
friend who is paying for counseling and

00:14:53,260 --> 00:14:58,540
medication out of her savings she's not

00:14:55,780 --> 00:15:00,339
working she can't go back to work at

00:14:58,540 --> 00:15:03,089
this time

00:15:00,339 --> 00:15:07,870
nobody cares we're disposable we are

00:15:03,089 --> 00:15:09,579
back to your question I think that what

00:15:07,870 --> 00:15:12,790
Clara was saying about how this thing is

00:15:09,579 --> 00:15:15,310
just kind of grown out of organically

00:15:12,790 --> 00:15:17,649
this situation has evolved without any

00:15:15,310 --> 00:15:21,550
clear top-level design in the early days

00:15:17,649 --> 00:15:24,459
and certainly in Ireland the people that

00:15:21,550 --> 00:15:26,680
were tasked with helping you change your

00:15:24,459 --> 00:15:28,720
password or you've locked yourself out

00:15:26,680 --> 00:15:31,350
and they need to verify your ID they

00:15:28,720 --> 00:15:33,579
were one day asked to deal with spam

00:15:31,350 --> 00:15:35,920
which is pretty clear as spam just

00:15:33,579 --> 00:15:37,180
delete it and then there was something

00:15:35,920 --> 00:15:39,069
else that's a problem and whenever

00:15:37,180 --> 00:15:41,769
something happens there's a whole new

00:15:39,069 --> 00:15:43,540
set of rules that Facebook creates to

00:15:41,769 --> 00:15:46,720
say well you can't do this on Facebook

00:15:43,540 --> 00:15:50,319
either anymore and now it's this massive

00:15:46,720 --> 00:15:53,499
massive set of documentation that you

00:15:50,319 --> 00:15:56,620
have to master to a 98% level of

00:15:53,499 --> 00:15:58,839
accuracy but you're still treated like a

00:15:56,620 --> 00:16:00,910
guy whose job is to say yeah this

00:15:58,839 --> 00:16:03,639
passport matches this profile picture

00:16:00,910 --> 00:16:05,980
and you're expected to reach the same

00:16:03,639 --> 00:16:08,139
level of accuracy all the time and you

00:16:05,980 --> 00:16:11,860
can't because there you will never make

00:16:08,139 --> 00:16:14,199
enough detailed rules to cover every

00:16:11,860 --> 00:16:15,550
eventuality and expect somebody to hold

00:16:14,199 --> 00:16:17,649
them in their head hmm

00:16:15,550 --> 00:16:19,509
and that is the problem about the the

00:16:17,649 --> 00:16:22,660
media that the debate we have in the

00:16:19,509 --> 00:16:24,600
media a lot of times about the problems

00:16:22,660 --> 00:16:26,620
of content moderation and whenever

00:16:24,600 --> 00:16:28,389
Facebook YouTube Twitter they're

00:16:26,620 --> 00:16:30,519
confronted with critique it's it's

00:16:28,389 --> 00:16:32,199
always about their policymaking and I

00:16:30,519 --> 00:16:35,290
guess that's mainly wrong and we should

00:16:32,199 --> 00:16:38,379
mainly focus on how it's executed and I

00:16:35,290 --> 00:16:40,360
guess already the word executing these

00:16:38,379 --> 00:16:42,970
rules is wrong because in a lot of cases

00:16:40,360 --> 00:16:46,300
you really freely have to interpret them

00:16:42,970 --> 00:16:48,220
you have to take decisions based on

00:16:46,300 --> 00:16:50,860
these guidelines but you you have to

00:16:48,220 --> 00:16:54,629
take them and it's still you you have to

00:16:50,860 --> 00:16:57,160
receive what is in the image is this

00:16:54,629 --> 00:16:59,230
like promoting violence or is this

00:16:57,160 --> 00:17:03,160
documenting violence is this a

00:16:59,230 --> 00:17:05,770
caricature is this like covered by the

00:17:03,160 --> 00:17:08,980
First Amendment this kind of things or

00:17:05,770 --> 00:17:12,909
is this already out of the out of the

00:17:08,980 --> 00:17:13,720
borders like of free speech and this has

00:17:12,909 --> 00:17:16,000
to be

00:17:13,720 --> 00:17:19,270
done in such a speed that as you say

00:17:16,000 --> 00:17:22,539
it's the mistakes which at which are

00:17:19,270 --> 00:17:25,209
made are systemically made that it's not

00:17:22,539 --> 00:17:27,159
a question of how the guidelines are

00:17:25,209 --> 00:17:29,919
designed but a question of how much time

00:17:27,159 --> 00:17:33,070
is given and in the end how much support

00:17:29,919 --> 00:17:34,600
how much money how much resources are

00:17:33,070 --> 00:17:37,419
given to these people and they get a

00:17:34,600 --> 00:17:40,450
three to six day training in our case in

00:17:37,419 --> 00:17:42,970
the Philippines like they get they got a

00:17:40,450 --> 00:17:47,590
crash course on identifying Nazi symbols

00:17:42,970 --> 00:17:50,740
like on a on a one two day training base

00:17:47,590 --> 00:17:53,140
like they were told okay be careful with

00:17:50,740 --> 00:17:55,630
ovens be careful with rats these might

00:17:53,140 --> 00:18:01,179
be anti-semitic but they didn't have any

00:17:55,630 --> 00:18:05,470
clue about the context of the the hate

00:18:01,179 --> 00:18:07,450
speech of neo-nazis in East Germany so

00:18:05,470 --> 00:18:10,890
um there are a lot of so many

00:18:07,450 --> 00:18:13,690
implications which are just made for

00:18:10,890 --> 00:18:15,580
some so much made for money for profit

00:18:13,690 --> 00:18:18,010
reasons so we really need to question

00:18:15,580 --> 00:18:20,860
this we need need to question if it's a

00:18:18,010 --> 00:18:23,580
good idea to give our digital public to

00:18:20,860 --> 00:18:27,190
a private company or let's say three

00:18:23,580 --> 00:18:29,440
private companies deciding about free

00:18:27,190 --> 00:18:32,590
speech in the online world that is not

00:18:29,440 --> 00:18:33,789
the way it should be handled yeah I want

00:18:32,590 --> 00:18:35,230
to talk I want to actually pass the ball

00:18:33,789 --> 00:18:37,809
to Gabby for a little bit cuz we were

00:18:35,230 --> 00:18:39,280
talking a little bit about you know not

00:18:37,809 --> 00:18:41,830
just Facebook with a lot of big tech

00:18:39,280 --> 00:18:42,880
companies nowadays they for a while they

00:18:41,830 --> 00:18:44,409
would frame themselves as kind of like

00:18:42,880 --> 00:18:46,120
you know saving the world like you know

00:18:44,409 --> 00:18:48,610
we're doing this because we're doing for

00:18:46,120 --> 00:18:50,530
the better of humanity but everything

00:18:48,610 --> 00:18:51,970
you hear about content moderation feels

00:18:50,530 --> 00:18:53,710
so opposite of that I was hoping you

00:18:51,970 --> 00:18:56,169
could talk about that duality a little

00:18:53,710 --> 00:18:58,780
bit yeah so and a lot of these companies

00:18:56,169 --> 00:18:59,470
they're marketing to get new and I don't

00:18:58,780 --> 00:19:01,210
know how it is

00:18:59,470 --> 00:19:02,770
cuz I just look to live in Germany and

00:19:01,210 --> 00:19:05,559
there's a thousand content moderators in

00:19:02,770 --> 00:19:06,940
Berlin so I just looked at mainly at

00:19:05,559 --> 00:19:11,860
Europe in the way that they're marketing

00:19:06,940 --> 00:19:13,090
here they use superheroes as costumes

00:19:11,860 --> 00:19:15,429
that can be a superhero

00:19:13,090 --> 00:19:18,190
clean up the Internet have a healthier

00:19:15,429 --> 00:19:20,140
internet one advert in Germany for a

00:19:18,190 --> 00:19:22,870
German content moderator ask questions

00:19:20,140 --> 00:19:24,280
like do you love social media and want

00:19:22,870 --> 00:19:27,160
to be up-to-date with what's happening

00:19:24,280 --> 00:19:29,470
in the world and if you know about what

00:19:27,160 --> 00:19:32,440
actually the job entails it doesn't

00:19:29,470 --> 00:19:33,880
include becoming a social media guru so

00:19:32,440 --> 00:19:35,200
I think that their positioning and then

00:19:33,880 --> 00:19:37,600
people apply and they think that they're

00:19:35,200 --> 00:19:40,690
getting these jobs and the actual

00:19:37,600 --> 00:19:42,190
reality is horrendous and that

00:19:40,690 --> 00:19:44,230
disconnect with what you think you're

00:19:42,190 --> 00:19:45,610
doing and actually keeping content

00:19:44,230 --> 00:19:50,560
online that you don't think should be

00:19:45,610 --> 00:19:52,390
online is extremely damaging even before

00:19:50,560 --> 00:19:55,050
you think about what people are seeing

00:19:52,390 --> 00:19:57,880
and for the work that I'm doing with

00:19:55,050 --> 00:20:00,880
human rights investigators the kind of

00:19:57,880 --> 00:20:04,780
six buckets of strategies that the most

00:20:00,880 --> 00:20:07,000
useful is to be able to control and know

00:20:04,780 --> 00:20:08,860
why you're doing what you're doing to be

00:20:07,000 --> 00:20:10,990
able to be selective to be able to

00:20:08,860 --> 00:20:12,760
identify what your triggers are to

00:20:10,990 --> 00:20:15,130
control your physical environment that

00:20:12,760 --> 00:20:16,510
you're viewing the content in to talk to

00:20:15,130 --> 00:20:19,030
other people they have peer-to-peer

00:20:16,510 --> 00:20:21,460
support and then be able to tell your

00:20:19,030 --> 00:20:23,890
managers that you're struggling all of

00:20:21,460 --> 00:20:25,930
those six things I just said that are

00:20:23,890 --> 00:20:28,630
the most helpful things are completely

00:20:25,930 --> 00:20:30,370
like the opposite of what you can do in

00:20:28,630 --> 00:20:31,450
these companies you can't tell anyone

00:20:30,370 --> 00:20:33,400
you're struggling because you're on a

00:20:31,450 --> 00:20:35,530
short term contract you can't be

00:20:33,400 --> 00:20:37,660
selective you cannot have any control

00:20:35,530 --> 00:20:39,640
over your environment so they go against

00:20:37,660 --> 00:20:42,760
it it needs the system needs a complete

00:20:39,640 --> 00:20:44,680
overhaul and and I did want to add you

00:20:42,760 --> 00:20:46,900
know one of the reasons why this came

00:20:44,680 --> 00:20:49,150
about is most companies they don't

00:20:46,900 --> 00:20:51,640
really deal with the problem of terrible

00:20:49,150 --> 00:20:53,950
things happening on their platform until

00:20:51,640 --> 00:20:56,380
it's a crisis management situation where

00:20:53,950 --> 00:20:58,810
they're suddenly having to scurry find

00:20:56,380 --> 00:21:01,120
contractors at scale to suddenly feel

00:20:58,810 --> 00:21:03,100
with all the PR backlash that they are

00:21:01,120 --> 00:21:05,410
getting and that's a huge struggle not

00:21:03,100 --> 00:21:07,180
just for contractors that work for

00:21:05,410 --> 00:21:09,010
companies but also for employees that

00:21:07,180 --> 00:21:11,350
have been at companies for 10 15 years

00:21:09,010 --> 00:21:13,270
now that set the original content

00:21:11,350 --> 00:21:15,490
moderation policies they are dealing

00:21:13,270 --> 00:21:17,410
with the bureaucracy of fighting for the

00:21:15,490 --> 00:21:20,080
rights of users and some of the hardest

00:21:17,410 --> 00:21:21,910
things that they see day to day setting

00:21:20,080 --> 00:21:24,790
the right policies and pushing against

00:21:21,910 --> 00:21:27,160
the ROI of the business pushing against

00:21:24,790 --> 00:21:29,980
advertising policy teams who are looking

00:21:27,160 --> 00:21:32,140
to help the company make money and there

00:21:29,980 --> 00:21:34,450
are a lot of professionals today that

00:21:32,140 --> 00:21:36,780
work not only from the bottom of the

00:21:34,450 --> 00:21:39,610
ladder all the way up if you look at

00:21:36,780 --> 00:21:40,470
2016 there's a woman that I have talked

00:21:39,610 --> 00:21:42,630
to

00:21:40,470 --> 00:21:45,000
that currently heads up content policy

00:21:42,630 --> 00:21:46,890
at a major platform and she has been

00:21:45,000 --> 00:21:48,960
through the rungs of this professional

00:21:46,890 --> 00:21:50,460
ladder from the ground up but she

00:21:48,960 --> 00:21:53,070
struggles you know day to day and her

00:21:50,460 --> 00:21:54,810
job pushing against the PR team to be

00:21:53,070 --> 00:21:57,180
able to put out the right voice to be

00:21:54,810 --> 00:21:59,730
able to ensure that things that she sees

00:21:57,180 --> 00:22:02,490
online like the anti-vaccine

00:21:59,730 --> 00:22:04,740
can have policies at that platform that

00:22:02,490 --> 00:22:06,720
can be enforced against and that's the

00:22:04,740 --> 00:22:08,940
other side of the spectrum is we needed

00:22:06,720 --> 00:22:10,830
to stop having platforms deal with bad

00:22:08,940 --> 00:22:12,570
issues online in a crisis management

00:22:10,830 --> 00:22:14,640
mode and really think about the

00:22:12,570 --> 00:22:16,680
thoughtful practices on how you build a

00:22:14,640 --> 00:22:18,840
team right this is a new professional

00:22:16,680 --> 00:22:20,670
sector that has evolved come about in

00:22:18,840 --> 00:22:23,400
which you have as sophisticated

00:22:20,670 --> 00:22:25,320
processes as diplomats online in the

00:22:23,400 --> 00:22:28,140
offline world making policies that

00:22:25,320 --> 00:22:31,380
impact society I mean we saw back in

00:22:28,140 --> 00:22:33,900
2013 2014 what happened in Myanmar where

00:22:31,380 --> 00:22:37,110
companies go to new countries they're

00:22:33,900 --> 00:22:39,120
trying to expand into a market and do

00:22:37,110 --> 00:22:41,220
nothing in terms of moderation there and

00:22:39,120 --> 00:22:43,440
a lot of the offline violence and whole

00:22:41,220 --> 00:22:45,720
ethnic genocide that took place years

00:22:43,440 --> 00:22:47,400
later because there was no thoughtful

00:22:45,720 --> 00:22:49,200
planning in the types of

00:22:47,400 --> 00:22:51,420
professionalization and professionals

00:22:49,200 --> 00:22:53,190
that are needed on the ground to support

00:22:51,420 --> 00:22:55,560
how content is spread and could be

00:22:53,190 --> 00:22:57,300
maliciously spread there and this whole

00:22:55,560 --> 00:22:59,340
entire professional sector needs to be

00:22:57,300 --> 00:23:00,990
uplifted needs to be recognized they

00:22:59,340 --> 00:23:02,910
should not be considered contractors

00:23:00,990 --> 00:23:05,820
they should not be considered janitors

00:23:02,910 --> 00:23:07,560
there are personally I think my my sense

00:23:05,820 --> 00:23:12,180
when when I was there was that there was

00:23:07,560 --> 00:23:13,680
no vision at the top it was all just

00:23:12,180 --> 00:23:15,510
there was you know some guy wants this

00:23:13,680 --> 00:23:18,240
and somebody else want that and at the

00:23:15,510 --> 00:23:21,630
bottom there's this set of rules for me

00:23:18,240 --> 00:23:23,220
but there's no leadership and I started

00:23:21,630 --> 00:23:25,110
asking the question so what is the

00:23:23,220 --> 00:23:27,180
business case for monta content

00:23:25,110 --> 00:23:29,070
moderation you know if I'm the boss of

00:23:27,180 --> 00:23:31,080
Facebook I have a legal obligation to

00:23:29,070 --> 00:23:34,350
make money for my shareholders how do

00:23:31,080 --> 00:23:35,880
how does content moderation support that

00:23:34,350 --> 00:23:38,010
goal and I've never heard any

00:23:35,880 --> 00:23:40,110
conversation around it there obviously

00:23:38,010 --> 00:23:42,420
there must have been a study you know do

00:23:40,110 --> 00:23:45,030
people spend more time online if we

00:23:42,420 --> 00:23:47,400
reduce and make it nice a kind of place

00:23:45,030 --> 00:23:48,870
or do they do they like it if it's nasty

00:23:47,400 --> 00:23:50,460
you know what what is good for the

00:23:48,870 --> 00:23:53,130
business they never talk about it so I

00:23:50,460 --> 00:23:54,450
assume that all this content moderation

00:23:53,130 --> 00:23:56,910
effort is because

00:23:54,450 --> 00:23:58,050
they have to they're reluctant to do it

00:23:56,910 --> 00:24:02,070
they're doing it at arm's length

00:23:58,050 --> 00:24:05,990
grudgingly because of the PR and the the

00:24:02,070 --> 00:24:08,760
legislative pressure threats of awful

00:24:05,990 --> 00:24:10,440
regulation not because it's front and

00:24:08,760 --> 00:24:13,200
center to the business so it's always

00:24:10,440 --> 00:24:15,930
going to be the lowest possible budget

00:24:13,200 --> 00:24:17,280
and the tightest controls and you know

00:24:15,930 --> 00:24:19,050
these people are disposable they're not

00:24:17,280 --> 00:24:21,000
part of the company they're not front

00:24:19,050 --> 00:24:24,300
and center to what we do yeah Gabby

00:24:21,000 --> 00:24:25,800
wants away yeah I don't think when Mark

00:24:24,300 --> 00:24:27,170
Zuckerberg started the company ever

00:24:25,800 --> 00:24:29,280
wanted to think about how to deal with

00:24:27,170 --> 00:24:31,620
the things that are being posted that

00:24:29,280 --> 00:24:34,110
you're having to look at and in 2009 I

00:24:31,620 --> 00:24:36,570
think Facebook had 12 moderators and now

00:24:34,110 --> 00:24:38,010
they're I think from last year to the

00:24:36,570 --> 00:24:40,080
year before they double their moderators

00:24:38,010 --> 00:24:42,210
so they're really throwing people at

00:24:40,080 --> 00:24:45,060
this problem which is just going to have

00:24:42,210 --> 00:24:46,890
hundreds of thousands each year of more

00:24:45,060 --> 00:24:50,670
traumatized people so yeah I think their

00:24:46,890 --> 00:24:54,690
lack of any kind of strategy or like

00:24:50,670 --> 00:24:57,420
bringing people into this in a yeah I

00:24:54,690 --> 00:24:59,370
did yeah and then the idea of AI if

00:24:57,420 --> 00:25:01,080
maybe this is a good segue oh for sure

00:24:59,370 --> 00:25:02,430
yeah because I was asking my question I

00:25:01,080 --> 00:25:04,590
had personally is like why can't a I

00:25:02,430 --> 00:25:07,500
just do handle this like why do we have

00:25:04,590 --> 00:25:08,820
to submit people to looking at these

00:25:07,500 --> 00:25:10,800
images and things like that but yeah

00:25:08,820 --> 00:25:17,640
maybe you can talk about why it's not

00:25:10,800 --> 00:25:19,920
really doable it was so the focus of

00:25:17,640 --> 00:25:21,660
Mozilla right now is AI healthy AI and

00:25:19,920 --> 00:25:25,170
obviously there's lots of issues with AI

00:25:21,660 --> 00:25:27,570
and those issues will just be replicated

00:25:25,170 --> 00:25:30,060
in this system the fact is AI can't

00:25:27,570 --> 00:25:32,730
handle the level of complexity the

00:25:30,060 --> 00:25:37,020
moderation requires it can't handle the

00:25:32,730 --> 00:25:39,570
scale I think last year Facebook said

00:25:37,020 --> 00:25:41,640
that 96% of nude and adult images they

00:25:39,570 --> 00:25:44,190
could detect automatically but that

00:25:41,640 --> 00:25:45,570
still leaves I think 1.3 million images

00:25:44,190 --> 00:25:48,780
for moderators to look through and

00:25:45,570 --> 00:25:50,280
that's just adult nude images so I think

00:25:48,780 --> 00:25:53,370
that the scale is a very simple problem

00:25:50,280 --> 00:25:56,450
relative to compared with you know if I

00:25:53,370 --> 00:26:00,120
get 500 words stream of consciousness

00:25:56,450 --> 00:26:03,120
because Doreen's boyfriend has got a new

00:26:00,120 --> 00:26:04,080
girlfriend and she's a junkie and ya da

00:26:03,120 --> 00:26:06,030
da da da da

00:26:04,080 --> 00:26:09,270
and I have to go through not line

00:26:06,030 --> 00:26:12,120
but phrase by phrase saying okay that's

00:26:09,270 --> 00:26:14,790
a violation under Section four point two

00:26:12,120 --> 00:26:17,010
point six and that's a violation under

00:26:14,790 --> 00:26:19,530
Section da-da-da-da-da and after listing

00:26:17,010 --> 00:26:21,420
all of them this is the one that I take

00:26:19,530 --> 00:26:23,550
action on because it's the the highest

00:26:21,420 --> 00:26:26,280
on the we have a hierarchy of actions

00:26:23,550 --> 00:26:27,900
this is more important than this spam is

00:26:26,280 --> 00:26:30,360
more ensure important than child abuse

00:26:27,900 --> 00:26:33,360
for example you know and I have to make

00:26:30,360 --> 00:26:36,480
the right decision based on that and I

00:26:33,360 --> 00:26:38,190
don't see how any AI is gonna do that in

00:26:36,480 --> 00:26:39,870
the near future because you still also

00:26:38,190 --> 00:26:42,180
just won and you just you still need

00:26:39,870 --> 00:26:45,170
humans to create the training data sets

00:26:42,180 --> 00:26:47,280
a new new images still need to be

00:26:45,170 --> 00:26:49,860
categorized all the time so you're still

00:26:47,280 --> 00:26:51,990
gonna have people to categorize the

00:26:49,860 --> 00:26:55,050
training data sets anyway even if AI is

00:26:51,990 --> 00:26:56,130
more utilized yeah I had a question for

00:26:55,050 --> 00:26:58,170
Chris I mean this was his personal

00:26:56,130 --> 00:26:59,940
curiosity you know you not a lot of

00:26:58,170 --> 00:27:01,980
people have broken NDA to come out

00:26:59,940 --> 00:27:05,310
against Facebook what did you think it

00:27:01,980 --> 00:27:07,170
would be like pre NDA broken what do you

00:27:05,310 --> 00:27:09,450
think it would be like and then what has

00:27:07,170 --> 00:27:14,010
it been like after you've come out I

00:27:09,450 --> 00:27:16,380
didn't think about it I was annoyed I

00:27:14,010 --> 00:27:18,360
doubt I'd had a contact from journalists

00:27:16,380 --> 00:27:19,770
general kornél at the Irish Times and

00:27:18,360 --> 00:27:22,590
she just wanted to talk off the record

00:27:19,770 --> 00:27:25,410
get some background get some ideas and I

00:27:22,590 --> 00:27:27,510
found myself getting really upset in the

00:27:25,410 --> 00:27:28,710
interview talking about the content and

00:27:27,510 --> 00:27:31,350
this was the first time that I've

00:27:28,710 --> 00:27:34,350
actually talked about that and I kind of

00:27:31,350 --> 00:27:36,240
went away and I saw a doctor and I broke

00:27:34,350 --> 00:27:39,060
down and she told me I had PTSD and I

00:27:36,240 --> 00:27:41,670
came out like the of these people

00:27:39,060 --> 00:27:43,710
done to me and and then she called me up

00:27:41,670 --> 00:27:45,360
and said you know how's it going we'd

00:27:43,710 --> 00:27:48,330
really like to put your name on this

00:27:45,360 --> 00:27:51,780
piece and I said yeah you know

00:27:48,330 --> 00:27:55,350
let's bring it on you know a big big

00:27:51,780 --> 00:27:57,480
because what I'd realized when I for the

00:27:55,350 --> 00:27:59,340
first time had had this open

00:27:57,480 --> 00:28:03,180
conversation with somebody on the

00:27:59,340 --> 00:28:05,550
outside was that we are we are silenced

00:28:03,180 --> 00:28:07,320
by these NDA's because they don't want

00:28:05,550 --> 00:28:11,820
anybody looking at what's going on

00:28:07,320 --> 00:28:15,090
they're avoiding any external oversight

00:28:11,820 --> 00:28:16,990
or criticism by using the law as a

00:28:15,090 --> 00:28:19,240
weapon we're being threatened

00:28:16,990 --> 00:28:21,790
and I had a call a couple of weeks ago

00:28:19,240 --> 00:28:24,040
from a former colleague still at Cpl the

00:28:21,790 --> 00:28:25,450
company I was working for for Facebook

00:28:24,040 --> 00:28:30,100
and they said hey I hear you're being

00:28:25,450 --> 00:28:33,850
sued by Facebook no I have not heard a

00:28:30,100 --> 00:28:35,590
word from Facebook not not one contact

00:28:33,850 --> 00:28:38,020
they didn't even give a statement to the

00:28:35,590 --> 00:28:40,750
journalist who asked them to respond to

00:28:38,020 --> 00:28:42,010
what I'd said they're keeping you know

00:28:40,750 --> 00:28:44,950
they're just hoping this problem will go

00:28:42,010 --> 00:28:47,740
away who told you I'm being sued well my

00:28:44,950 --> 00:28:50,080
team leader and your team leader is

00:28:47,740 --> 00:28:53,200
trying to manipulate you and threaten

00:28:50,080 --> 00:28:57,610
you and silence you your team leader is

00:28:53,200 --> 00:28:59,740
lied to you to obtain compliance and

00:28:57,610 --> 00:29:03,190
what kind of way is that to treat your

00:28:59,740 --> 00:29:05,710
staff in a modern democracy in a company

00:29:03,190 --> 00:29:08,050
that is dedicated to transparency and

00:29:05,710 --> 00:29:11,140
openness and sharing information privacy

00:29:08,050 --> 00:29:13,090
is dead mark yeah this this is supposed

00:29:11,140 --> 00:29:15,880
to be the world where everybody is

00:29:13,090 --> 00:29:19,090
accountable for everything except for

00:29:15,880 --> 00:29:20,380
the companies with the power I think

00:29:19,090 --> 00:29:22,210
this is really important because we

00:29:20,380 --> 00:29:24,190
experienced exactly the same in the

00:29:22,210 --> 00:29:27,220
Philippines that this is a very very

00:29:24,190 --> 00:29:29,080
secretive industry and everybody is is

00:29:27,220 --> 00:29:30,700
not allowed to talk about what they are

00:29:29,080 --> 00:29:32,679
doing and because everybody signs

00:29:30,700 --> 00:29:35,080
non-disclosure agreements and especially

00:29:32,679 --> 00:29:37,510
if you are traumatized this is the worst

00:29:35,080 --> 00:29:39,429
which can happen that you're not allowed

00:29:37,510 --> 00:29:41,350
to talk about your emotions not allowed

00:29:39,429 --> 00:29:44,260
to talk about what's happening don't

00:29:41,350 --> 00:29:47,679
talk to anybody and that's also in life

00:29:44,260 --> 00:29:50,230
about this work and exactly yes and this

00:29:47,679 --> 00:29:51,940
is what it makes so so so difficult to

00:29:50,230 --> 00:29:54,370
research about that work and also for

00:29:51,940 --> 00:29:57,040
the employees to deal with that kind of

00:29:54,370 --> 00:29:58,660
work and whenever you have facebook or

00:29:57,040 --> 00:30:00,250
any of these companies talk about this

00:29:58,660 --> 00:30:03,429
they always pretend they are transparent

00:30:00,250 --> 00:30:07,570
because they share the guidelines come

00:30:03,429 --> 00:30:09,790
on a company which asks it's outsourcing

00:30:07,570 --> 00:30:12,820
company in the Philippines to let their

00:30:09,790 --> 00:30:16,030
employees use a code word and that is

00:30:12,820 --> 00:30:17,710
true they use the code word we are the

00:30:16,030 --> 00:30:19,630
first challenge we had in our research

00:30:17,710 --> 00:30:21,580
was to find out about this code word

00:30:19,630 --> 00:30:23,410
because only by finding out the code

00:30:21,580 --> 00:30:25,720
word we could then identify the people

00:30:23,410 --> 00:30:27,490
who work for the companies because they

00:30:25,720 --> 00:30:29,740
were never allowed to share with anybody

00:30:27,490 --> 00:30:33,190
not even internally inside

00:30:29,740 --> 00:30:34,809
the company who they worked for and they

00:30:33,190 --> 00:30:38,559
always had to use this code word honey

00:30:34,809 --> 00:30:39,820
badger project this was exactly it in

00:30:38,559 --> 00:30:41,950
the Philippines at the time we were

00:30:39,820 --> 00:30:44,350
researching honey badger project was

00:30:41,950 --> 00:30:47,110
Facebook and everybody inside the

00:30:44,350 --> 00:30:48,820
company inside this account knew that

00:30:47,110 --> 00:30:50,470
whenever they talked about with anybody

00:30:48,820 --> 00:30:54,670
else in the company they had to use it

00:30:50,470 --> 00:30:57,010
in in order to hide as as bad as

00:30:54,670 --> 00:30:59,740
perfectly as possible who what they do

00:30:57,010 --> 00:31:02,559
there and that that is I guess the

00:30:59,740 --> 00:31:06,190
opposite of being transparent they do a

00:31:02,559 --> 00:31:10,170
lot they hire a security company just

00:31:06,190 --> 00:31:12,880
patrolling around the office rooms they

00:31:10,170 --> 00:31:16,120
threatened us and threatened the people

00:31:12,880 --> 00:31:18,940
talking to us that in case they share

00:31:16,120 --> 00:31:22,350
anything about the company they can be

00:31:18,940 --> 00:31:28,240
sued they can not only lose the job but

00:31:22,350 --> 00:31:30,910
face fees it was really horrifying when

00:31:28,240 --> 00:31:33,190
we were there and we really had to find

00:31:30,910 --> 00:31:37,270
a way how to make this film and it took

00:31:33,190 --> 00:31:40,150
us so long to find a slight legal way

00:31:37,270 --> 00:31:43,150
how to on one hand protect the workers

00:31:40,150 --> 00:31:46,360
the employees and on the other hand to

00:31:43,150 --> 00:31:48,340
make this film and to make it in a in a

00:31:46,360 --> 00:31:49,179
way as clear as possible yeah Clara Dino

00:31:48,340 --> 00:31:51,010
jumped over you a couple questions

00:31:49,179 --> 00:31:53,590
before did you want to jump in yeah I

00:31:51,010 --> 00:31:55,540
did well I didn't want to go back to

00:31:53,590 --> 00:31:57,370
what Gaby I pointed out about AI right

00:31:55,540 --> 00:32:00,540
and automation and one of the biggest

00:31:57,370 --> 00:32:03,250
fears for AI is will a workforce that

00:32:00,540 --> 00:32:05,500
usually does a lot of the manual work be

00:32:03,250 --> 00:32:08,470
automated away one day and when do we

00:32:05,500 --> 00:32:10,090
decide to bring in contractors into the

00:32:08,470 --> 00:32:12,580
fold versus using other types of

00:32:10,090 --> 00:32:14,380
technologies and processes and that's a

00:32:12,580 --> 00:32:16,510
lot of my research is really looking at

00:32:14,380 --> 00:32:19,540
the tools that most professionals use

00:32:16,510 --> 00:32:21,490
today to determine acceptable content

00:32:19,540 --> 00:32:23,650
online how do you do tection how do you

00:32:21,490 --> 00:32:25,660
do enforcement and how do we build it in

00:32:23,650 --> 00:32:27,460
a way that can map to the complexities

00:32:25,660 --> 00:32:29,320
of the decision making of what is

00:32:27,460 --> 00:32:31,570
allowable speech online and what isn't

00:32:29,320 --> 00:32:34,630
and at enormous volumes and so for

00:32:31,570 --> 00:32:36,040
example for most people that have seen

00:32:34,630 --> 00:32:38,410
in the news what happened during the

00:32:36,040 --> 00:32:40,180
Christchurch shooting live stream video

00:32:38,410 --> 00:32:43,180
content there's a lot that we can

00:32:40,180 --> 00:32:44,890
from child online streaming for

00:32:43,180 --> 00:32:47,410
pornography back in the early days that

00:32:44,890 --> 00:32:49,180
were operational practices but there are

00:32:47,410 --> 00:32:52,510
things that are really hard to do with

00:32:49,180 --> 00:32:54,610
AI alone and so an example with

00:32:52,510 --> 00:32:56,800
Christchurch was because the volume of

00:32:54,610 --> 00:32:58,900
content was spread it's such such strong

00:32:56,800 --> 00:33:01,390
speeds it was really hard to have human

00:32:58,900 --> 00:33:03,940
moderators come in and quickly take down

00:33:01,390 --> 00:33:07,120
one by one and so one of the operational

00:33:03,940 --> 00:33:08,980
practices Facebook did was use AI to be

00:33:07,120 --> 00:33:11,740
able to quickly take down that 17

00:33:08,980 --> 00:33:14,170
minutes of graphic content and to be

00:33:11,740 --> 00:33:16,030
able to do it quickly at scale but very

00:33:14,170 --> 00:33:19,090
there are very different processes for

00:33:16,030 --> 00:33:20,860
how a company for example responds in

00:33:19,090 --> 00:33:23,020
the instance of a foreign influence

00:33:20,860 --> 00:33:25,840
operation when there are foreign actors

00:33:23,020 --> 00:33:28,300
that come in and try to manipulate

00:33:25,840 --> 00:33:29,710
content on a platform and users seeing

00:33:28,300 --> 00:33:31,630
from the other side their accounts being

00:33:29,710 --> 00:33:33,220
taken down for no reason there are very

00:33:31,630 --> 00:33:35,110
complicated decision making in which

00:33:33,220 --> 00:33:37,030
more and more technologists are

00:33:35,110 --> 00:33:39,840
developing different tools from

00:33:37,030 --> 00:33:43,420
detecting deep fakes to other types of

00:33:39,840 --> 00:33:44,980
approaches for how we can respond to

00:33:43,420 --> 00:33:46,900
different types of content and how we

00:33:44,980 --> 00:33:49,930
can also minimize trauma when it comes

00:33:46,900 --> 00:33:52,990
to what is at the end of this and the

00:33:49,930 --> 00:33:55,930
end of the totem pole Facebook I think a

00:33:52,990 --> 00:33:58,480
few months ago with all the reporting

00:33:55,930 --> 00:34:02,740
from films and from Casey Newton's piece

00:33:58,480 --> 00:34:04,270
back in March really talking about they

00:34:02,740 --> 00:34:06,460
started to push out some tools that can

00:34:04,270 --> 00:34:08,649
actually blur out some images that

00:34:06,460 --> 00:34:10,300
content moderators see so there's

00:34:08,649 --> 00:34:12,429
different experiments that have been

00:34:10,300 --> 00:34:15,550
happening but again it's really really

00:34:12,429 --> 00:34:18,220
hard to completely use machines as the

00:34:15,550 --> 00:34:19,899
dependent way of assessing content

00:34:18,220 --> 00:34:21,700
because it does push against privacy it

00:34:19,899 --> 00:34:25,149
pushes against freedom of expression

00:34:21,700 --> 00:34:26,470
online yeah I wanna I want to ask a

00:34:25,149 --> 00:34:27,909
couple more questions before we get to

00:34:26,470 --> 00:34:29,800
the audience because wearing a long time

00:34:27,909 --> 00:34:32,020
I know when you say the honey badger

00:34:29,800 --> 00:34:34,240
project that's just wild to me I know

00:34:32,020 --> 00:34:37,570
Gabby you studied a lot about how other

00:34:34,240 --> 00:34:39,940
companies kind of work on moderation why

00:34:37,570 --> 00:34:41,890
can't the companies who may be good

00:34:39,940 --> 00:34:48,010
right why can't they apply some of the

00:34:41,890 --> 00:34:49,899
same things they do there I haven't

00:34:48,010 --> 00:34:52,350
found any companies that can because

00:34:49,899 --> 00:34:52,350
companies a

00:34:52,530 --> 00:34:58,750
motivated by like making money so the

00:34:56,920 --> 00:35:00,910
people I interviewed were people who

00:34:58,750 --> 00:35:02,920
worked on creating these data sets for

00:35:00,910 --> 00:35:04,720
AI so Child Exploitation people that

00:35:02,920 --> 00:35:06,160
work on Child Exploitation people that

00:35:04,720 --> 00:35:09,070
work on human rights violations

00:35:06,160 --> 00:35:11,080
journalists lawyers film editors and the

00:35:09,070 --> 00:35:13,530
reason they can get get it right even

00:35:11,080 --> 00:35:17,310
though no one's really getting it right

00:35:13,530 --> 00:35:19,240
and that's why I was working on this is

00:35:17,310 --> 00:35:21,640
because they're able to take the time

00:35:19,240 --> 00:35:25,720
and they prioritize people and they're

00:35:21,640 --> 00:35:28,150
able to think about really important

00:35:25,720 --> 00:35:29,710
questions that all of this work brings

00:35:28,150 --> 00:35:32,230
and I think that the reason that these

00:35:29,710 --> 00:35:33,610
companies are struggling is because it

00:35:32,230 --> 00:35:36,130
does none of the strategies will work

00:35:33,610 --> 00:35:40,360
because none of them support quick

00:35:36,130 --> 00:35:43,360
speedy decisions yeah I also agree that

00:35:40,360 --> 00:35:45,730
the core problem is not technology the

00:35:43,360 --> 00:35:47,850
core problem is that we as different

00:35:45,730 --> 00:35:53,410
societies involved in this massive

00:35:47,850 --> 00:35:56,230
humanity project called social media we

00:35:53,410 --> 00:35:58,660
are not yet clear about how we what want

00:35:56,230 --> 00:36:01,210
to define freedom of speech for example

00:35:58,660 --> 00:36:02,970
like if you only compare the definition

00:36:01,210 --> 00:36:05,230
of freedom of speech in the US with the

00:36:02,970 --> 00:36:07,600
definition in Germany where we come from

00:36:05,230 --> 00:36:10,300
for example that's completely different

00:36:07,600 --> 00:36:12,730
like what do you consider to be

00:36:10,300 --> 00:36:15,550
acceptable what not and that should be

00:36:12,730 --> 00:36:19,170
something we as the not only users but

00:36:15,550 --> 00:36:22,510
the members of these social media

00:36:19,170 --> 00:36:24,700
projects should discuss about publicly

00:36:22,510 --> 00:36:26,890
and we don't claim that it's all about

00:36:24,700 --> 00:36:30,040
that all the fault is on the side of the

00:36:26,890 --> 00:36:33,820
companies that's not true the fault we

00:36:30,040 --> 00:36:36,670
consider at least is that they don't

00:36:33,820 --> 00:36:38,680
make it transparent that they don't open

00:36:36,670 --> 00:36:40,960
the discussion that they don't accept

00:36:38,680 --> 00:36:43,360
that they alone can't decide about all

00:36:40,960 --> 00:36:44,830
that and whenever you hear is like a

00:36:43,360 --> 00:36:47,290
book talking it's like yeah we will

00:36:44,830 --> 00:36:49,570
follow up on that with our team we can

00:36:47,290 --> 00:36:51,910
fix it and that's not the way it shows

00:36:49,570 --> 00:36:54,100
one thing all the time that the Facebook

00:36:51,910 --> 00:36:57,310
can do no wrong oh maybe maybe it's not

00:36:54,100 --> 00:36:59,980
perfect but we can fix it yes the people

00:36:57,310 --> 00:37:01,600
who are doing the work have no chain of

00:36:59,980 --> 00:37:02,570
command to turn around and say look this

00:37:01,600 --> 00:37:05,870
is not working

00:37:02,570 --> 00:37:08,540
that there's if you think in terms of

00:37:05,870 --> 00:37:10,610
startup ecosystems there's all these

00:37:08,540 --> 00:37:14,090
disruptive people challenging the status

00:37:10,610 --> 00:37:17,390
quo figuring out a way to change bank

00:37:14,090 --> 00:37:18,980
banking for example FinTech we're all

00:37:17,390 --> 00:37:20,060
familiar with that model now we're

00:37:18,980 --> 00:37:22,490
seeing what's happened you've got

00:37:20,060 --> 00:37:24,860
challengers facebooking within Facebook

00:37:22,490 --> 00:37:26,870
there is a monopoly there is one person

00:37:24,860 --> 00:37:29,990
one department and all this all the

00:37:26,870 --> 00:37:31,760
people doing what they're told and as an

00:37:29,990 --> 00:37:33,560
empire at the top that needs to be

00:37:31,760 --> 00:37:35,930
disruptive needs to be challenged with

00:37:33,560 --> 00:37:38,270
too many vested interests within the

00:37:35,930 --> 00:37:40,250
organization or preventing that from

00:37:38,270 --> 00:37:41,990
happening because nobody knows the

00:37:40,250 --> 00:37:43,640
solution nobody knows what's going to

00:37:41,990 --> 00:37:45,470
work you have to try this and this and

00:37:43,640 --> 00:37:48,260
this and this and a hundred different

00:37:45,470 --> 00:37:51,320
things a gather data and figure out what

00:37:48,260 --> 00:37:52,460
works instead of just insisting you know

00:37:51,320 --> 00:37:54,230
what we're doing and we're just gonna

00:37:52,460 --> 00:37:57,020
tweak it and we'll get it right journey

00:37:54,230 --> 00:37:59,300
yeah we're running on time but my last

00:37:57,020 --> 00:38:01,490
question is about awareness for this

00:37:59,300 --> 00:38:02,690
issue like how can we bring more aware

00:38:01,490 --> 00:38:04,700
and also want to direct is that Chris

00:38:02,690 --> 00:38:07,130
like what do you need from us on this

00:38:04,700 --> 00:38:08,710
stage and the audience like what can we

00:38:07,130 --> 00:38:11,990
do to bring more awareness to this issue

00:38:08,710 --> 00:38:14,090
so my lawyer tells me that he has a rich

00:38:11,990 --> 00:38:16,030
prepared for the high quality in Ireland

00:38:14,090 --> 00:38:19,370
which will go in the next few days

00:38:16,030 --> 00:38:22,700
claiming damages for stress disorders

00:38:19,370 --> 00:38:25,220
caused by the work the things we have to

00:38:22,700 --> 00:38:27,980
see and deal with there are half a dozen

00:38:25,220 --> 00:38:29,480
offers in the case of the moment there's

00:38:27,980 --> 00:38:33,080
a whole bunch more waiting in the wings

00:38:29,480 --> 00:38:35,360
people that are afraid to even put their

00:38:33,080 --> 00:38:40,670
name on a list that they're terrified

00:38:35,360 --> 00:38:42,530
and also traumatized beaten down they

00:38:40,670 --> 00:38:43,040
just don't want to talk about this

00:38:42,530 --> 00:38:45,500
anymore

00:38:43,040 --> 00:38:49,490
and I'm here you know to speak publicly

00:38:45,500 --> 00:38:51,170
and and just say look it's okay to talk

00:38:49,490 --> 00:38:54,170
about it it's okay to just put your name

00:38:51,170 --> 00:38:57,430
on the list it's okay to call Dave

00:38:54,170 --> 00:38:59,720
Coleman and say how do I get justice

00:38:57,430 --> 00:39:02,330
whoever you are wherever you are in the

00:38:59,720 --> 00:39:04,940
world so I mean we've been talking about

00:39:02,330 --> 00:39:09,050
it looks like people in the Philippines

00:39:04,940 --> 00:39:11,480
can bring a case in Ireland people in

00:39:09,050 --> 00:39:14,000
Germany and Barcelona there's a center

00:39:11,480 --> 00:39:16,460
there they almost certainly can

00:39:14,000 --> 00:39:21,430
we want more people to come and get

00:39:16,460 --> 00:39:23,869
behind this and get justice and take

00:39:21,430 --> 00:39:25,730
agency take responsibility for their own

00:39:23,869 --> 00:39:28,070
lives instead of just being told what to

00:39:25,730 --> 00:39:31,520
do and told to keep their mouth shut so

00:39:28,070 --> 00:39:34,160
if you know anybody who does this work

00:39:31,520 --> 00:39:37,670
has done this work is connected with

00:39:34,160 --> 00:39:40,099
people or who has a budget to enable us

00:39:37,670 --> 00:39:42,890
to reach out and chase these people to

00:39:40,099 --> 00:39:44,390
find them and help them you know I'll be

00:39:42,890 --> 00:39:46,869
the lightning rod I'll be the one that

00:39:44,390 --> 00:39:49,810
gets shot up by Facebook if necessary

00:39:46,869 --> 00:39:52,210
but though we need more support from

00:39:49,810 --> 00:39:55,220
wider Internet Society

00:39:52,210 --> 00:39:57,950
all right well with that user account

00:39:55,220 --> 00:39:59,869
user Q&A uh audience Q&A I think we have

00:39:57,950 --> 00:40:05,420
some mics going around you so I'll let

00:39:59,869 --> 00:40:10,000
Kevin take the lead on that here we go

00:40:05,420 --> 00:40:12,200
they're here can you hear me yep yeah

00:40:10,000 --> 00:40:14,270
actually one of my questions I have a

00:40:12,200 --> 00:40:16,640
few friends in Moore in the Silicon

00:40:14,270 --> 00:40:18,230
Valley side we're also hired through

00:40:16,640 --> 00:40:19,730
these contracting companies to do this

00:40:18,230 --> 00:40:22,099
work and a few of them did try to get

00:40:19,730 --> 00:40:23,690
some legal help but they were told that

00:40:22,099 --> 00:40:25,700
because of the way this is done through

00:40:23,690 --> 00:40:27,619
these contracting setups that you can't

00:40:25,700 --> 00:40:29,960
really get at the company which is

00:40:27,619 --> 00:40:32,300
hiring these contracting services so I

00:40:29,960 --> 00:40:34,130
was wondering what the legal side looks

00:40:32,300 --> 00:40:36,380
like there and how this is set up with

00:40:34,130 --> 00:40:38,690
these shell companies and if you have

00:40:36,380 --> 00:40:41,359
any sort of input on how that can be

00:40:38,690 --> 00:40:43,700
addressed yeah I'm not a lawyer but

00:40:41,359 --> 00:40:45,740
we're under European law not not

00:40:43,700 --> 00:40:48,140
American law I can give this when I go

00:40:45,740 --> 00:40:50,330
there's a class-action lawsuit happening

00:40:48,140 --> 00:40:53,030
in the state of California that Salinas

00:40:50,330 --> 00:40:56,210
Cole have started in September 2018 and

00:40:53,030 --> 00:41:00,560
initially she did for a third-party

00:40:56,210 --> 00:41:02,180
company and Facebookers in the claim and

00:41:00,560 --> 00:41:04,160
now that's just been changed to Facebook

00:41:02,180 --> 00:41:06,109
and she's added other people to the

00:41:04,160 --> 00:41:08,690
class-action and I think the issue is

00:41:06,109 --> 00:41:10,730
that in some of the contracts there's

00:41:08,690 --> 00:41:12,470
possible arbitration agreements that are

00:41:10,730 --> 00:41:16,070
being mentioned which is basically you

00:41:12,470 --> 00:41:18,290
can't sue us but I think that this case

00:41:16,070 --> 00:41:22,220
is ongoing and they're looking for more

00:41:18,290 --> 00:41:24,230
class-action claimants to join them and

00:41:22,220 --> 00:41:26,780
also I think there is a tide happening

00:41:24,230 --> 00:41:27,530
legally around this in Australia a media

00:41:26,780 --> 00:41:30,590
outlet called the

00:41:27,530 --> 00:41:33,410
age has just been successfully

00:41:30,590 --> 00:41:36,890
prosecuted for negligence and duty of

00:41:33,410 --> 00:41:39,860
care around PTSD and the claimant was

00:41:36,890 --> 00:41:41,360
awarded 180,000 Australian dollars so I

00:41:39,860 --> 00:41:42,800
think that there is a tight we are

00:41:41,360 --> 00:41:46,100
definitely the contracts that people are

00:41:42,800 --> 00:41:48,320
signing and not helping but there is I

00:41:46,100 --> 00:41:51,950
would look up Salinas scholars case it's

00:41:48,320 --> 00:41:53,660
worth mentioning that I came here at the

00:41:51,950 --> 00:41:57,950
invitation of Amnesty International and

00:41:53,660 --> 00:41:59,770
a new nonprofit called foxglove who are

00:41:57,950 --> 00:42:02,840
all about holding tech companies

00:41:59,770 --> 00:42:04,550
accountable and their view both of these

00:42:02,840 --> 00:42:06,170
organizations is that this is a human

00:42:04,550 --> 00:42:10,040
rights issue and human rights law

00:42:06,170 --> 00:42:13,730
Trump's employment law or insurance law

00:42:10,040 --> 00:42:15,590
for example so if you think you're on a

00:42:13,730 --> 00:42:17,870
building site and you're an electrician

00:42:15,590 --> 00:42:19,760
and you fall down a hole do you sue the

00:42:17,870 --> 00:42:22,940
electrical wiring company that you're

00:42:19,760 --> 00:42:24,980
working for do you sue the major

00:42:22,940 --> 00:42:28,190
contractor do you sue the guy who left

00:42:24,980 --> 00:42:29,780
though the demand hole open at the end

00:42:28,190 --> 00:42:31,400
of the day it's the people that are

00:42:29,780 --> 00:42:34,460
operating the building site that are

00:42:31,400 --> 00:42:37,040
responsible I think that principle holds

00:42:34,460 --> 00:42:38,750
true with these cases as well and that's

00:42:37,040 --> 00:42:40,700
why we think that people in the

00:42:38,750 --> 00:42:48,280
Philippines for example are able to join

00:42:40,700 --> 00:42:50,390
our action in Ireland next question yeah

00:42:48,280 --> 00:42:52,250
thank you for this panel I have a

00:42:50,390 --> 00:42:54,650
question I sometimes feel like there's a

00:42:52,250 --> 00:42:56,150
disconnect between debates around ethics

00:42:54,650 --> 00:42:58,520
AI automation

00:42:56,150 --> 00:43:00,560
we're often time human intervention is

00:42:58,520 --> 00:43:02,270
seen as not may be the only solution but

00:43:00,560 --> 00:43:05,570
it's something that's very important and

00:43:02,270 --> 00:43:07,280
anybody who works on we all agree that

00:43:05,570 --> 00:43:09,050
there's certain content that has to be

00:43:07,280 --> 00:43:10,520
you unless you're completely libertarian

00:43:09,050 --> 00:43:12,770
we know that there's certain content

00:43:10,520 --> 00:43:15,080
then has to be removed but we also know

00:43:12,770 --> 00:43:17,150
that automating it isn't really working

00:43:15,080 --> 00:43:18,740
that well and that risks taking doubt

00:43:17,150 --> 00:43:20,870
things that really shouldn't be taking

00:43:18,740 --> 00:43:24,070
down and the only two solution to this

00:43:20,870 --> 00:43:26,510
seems to be having human moderators

00:43:24,070 --> 00:43:29,870
based on all your experience on this

00:43:26,510 --> 00:43:33,140
where would you draw the line in there

00:43:29,870 --> 00:43:34,960
seems to be a pay or like a cost to both

00:43:33,140 --> 00:43:37,490
either automation and the human

00:43:34,960 --> 00:43:39,140
involvement and I find this sort of like

00:43:37,490 --> 00:43:41,140
almost a dilemma that's very very

00:43:39,140 --> 00:43:43,880
difficult to resolve

00:43:41,140 --> 00:43:45,650
yeah and I think this is the really

00:43:43,880 --> 00:43:47,000
important point that I've been trying to

00:43:45,650 --> 00:43:49,640
drive home is we need to uplift

00:43:47,000 --> 00:43:52,670
operational practices in this space to

00:43:49,640 --> 00:43:54,770
the complexity that it reflects freedom

00:43:52,670 --> 00:43:56,600
of speech while protecting people from

00:43:54,770 --> 00:43:58,460
seeing the worst that is possible right

00:43:56,600 --> 00:44:00,470
now companies don't have shared

00:43:58,460 --> 00:44:03,200
operational practices on how to deal

00:44:00,470 --> 00:44:04,970
with all types of crisis moments when it

00:44:03,200 --> 00:44:06,950
comes to terrible content landing on

00:44:04,970 --> 00:44:08,720
their platforms which for the first time

00:44:06,950 --> 00:44:10,580
never had to think about someone doing a

00:44:08,720 --> 00:44:12,320
live shooting you know a few weeks ago

00:44:10,580 --> 00:44:13,880
and they suddenly had to figure out an

00:44:12,320 --> 00:44:16,670
operational response should we take that

00:44:13,880 --> 00:44:18,380
down we leave it up how do we ensure

00:44:16,670 --> 00:44:20,600
that it's not spreading to third parties

00:44:18,380 --> 00:44:22,550
unencrypted messaging platforms right

00:44:20,600 --> 00:44:24,890
and how do we ensure that other

00:44:22,550 --> 00:44:26,840
platforms that are looser with their

00:44:24,890 --> 00:44:28,670
Terms of Service are not hosting that

00:44:26,840 --> 00:44:30,560
kind of content if illegal and it's

00:44:28,670 --> 00:44:32,240
really really hard a lot of countries

00:44:30,560 --> 00:44:34,280
all around the world are thinking about

00:44:32,240 --> 00:44:36,410
regulation of content because they have

00:44:34,280 --> 00:44:38,960
no idea what to do and they don't have

00:44:36,410 --> 00:44:42,380
any idea what they can do to ask

00:44:38,960 --> 00:44:44,450
companies to better deal with all types

00:44:42,380 --> 00:44:46,850
of threats from foreign influence to

00:44:44,450 --> 00:44:49,130
terrorist content to disinformation and

00:44:46,850 --> 00:44:50,840
this is a huge struggle in which if we

00:44:49,130 --> 00:44:53,090
don't start having a more transparent

00:44:50,840 --> 00:44:55,940
and sure dialogue between industry

00:44:53,090 --> 00:44:58,280
members and also the general public it's

00:44:55,940 --> 00:45:00,530
gonna be really hard and Facebook you

00:44:58,280 --> 00:45:02,060
know set up observation boards I try to

00:45:00,530 --> 00:45:04,550
bring civil society and a number of

00:45:02,060 --> 00:45:06,080
actors into the mix to show in more

00:45:04,550 --> 00:45:09,560
transparency their own decision-making

00:45:06,080 --> 00:45:11,300
but it is not very clear how transparent

00:45:09,560 --> 00:45:13,790
that is to the public how transparent

00:45:11,300 --> 00:45:15,950
that is to governments and so really

00:45:13,790 --> 00:45:18,410
what needs to happen at least from the

00:45:15,950 --> 00:45:21,020
industry side is much more information

00:45:18,410 --> 00:45:23,300
sharing around operational practices for

00:45:21,020 --> 00:45:25,250
us to be able to have the right tools to

00:45:23,300 --> 00:45:26,300
be able to deal with all types of

00:45:25,250 --> 00:45:29,840
content at scale

00:45:26,300 --> 00:45:31,520
maybe if I may add one example which is

00:45:29,840 --> 00:45:33,020
actually based here in London it's

00:45:31,520 --> 00:45:36,080
called air wars

00:45:33,020 --> 00:45:38,240
some of you might may actually know it

00:45:36,080 --> 00:45:44,990
even it's an organization which focuses

00:45:38,240 --> 00:45:48,410
on proving guilt in the in the war in

00:45:44,990 --> 00:45:51,320
Syria or in Iraq and what they do is

00:45:48,410 --> 00:45:54,260
they try to archive videos which are

00:45:51,320 --> 00:45:58,040
uploaded to Facebook YouTube

00:45:54,260 --> 00:46:02,570
Twitter by citizen journalists in Syria

00:45:58,040 --> 00:46:04,880
in Iraq proving airstrikes or the

00:46:02,570 --> 00:46:07,670
results of airstrikes on civilian

00:46:04,880 --> 00:46:10,450
entities in in Syria or in Iraq on

00:46:07,670 --> 00:46:14,000
schools and hospitals and so on and

00:46:10,450 --> 00:46:15,530
whenever these videos are uploaded most

00:46:14,000 --> 00:46:17,840
of the time it doesn't take much time

00:46:15,530 --> 00:46:19,910
until they are taken down for good

00:46:17,840 --> 00:46:21,590
reasons on one hand because in a lot of

00:46:19,910 --> 00:46:24,080
cases they're really cruel they're

00:46:21,590 --> 00:46:26,690
really they're covering their people

00:46:24,080 --> 00:46:29,840
they're the full of horrifying content

00:46:26,690 --> 00:46:31,970
so it's really hard to actually claim

00:46:29,840 --> 00:46:34,250
that these videos should be should

00:46:31,970 --> 00:46:38,090
remain on social media but on the other

00:46:34,250 --> 00:46:40,510
side if we think back on what dreams we

00:46:38,090 --> 00:46:43,550
had about social media about the

00:46:40,510 --> 00:46:46,400
emancipating effect of social media this

00:46:43,550 --> 00:46:48,920
is maybe one of the last things

00:46:46,400 --> 00:46:51,020
remaining as a potential on social media

00:46:48,920 --> 00:46:53,210
which we should defend that this is also

00:46:51,020 --> 00:46:55,190
a way that when the Western media

00:46:53,210 --> 00:46:58,850
conventional media is not interested

00:46:55,190 --> 00:47:01,040
anymore in covering everything from the

00:46:58,850 --> 00:47:04,250
Syrian or the Iraq war

00:47:01,040 --> 00:47:08,090
that's at least civilian citizen

00:47:04,250 --> 00:47:11,780
journalists have a forum there to still

00:47:08,090 --> 00:47:15,530
reach a worldwide audience and to make

00:47:11,780 --> 00:47:18,500
their points so why not defend the fact

00:47:15,530 --> 00:47:20,420
that these videos should remain visible

00:47:18,500 --> 00:47:23,750
though they are completely cruel on

00:47:20,420 --> 00:47:26,840
social media this is just to to make

00:47:23,750 --> 00:47:29,690
clear how difficult it is how to decide

00:47:26,840 --> 00:47:32,330
about these cases and that we actually

00:47:29,690 --> 00:47:35,780
all of us people from all over the world

00:47:32,330 --> 00:47:38,660
should debate it much more and not only

00:47:35,780 --> 00:47:41,810
like representatives at whatever board

00:47:38,660 --> 00:47:44,150
they're but all of us should debate it

00:47:41,810 --> 00:47:46,369
and what we want to use it for what

00:47:44,150 --> 00:47:50,630
social media should be like should it be

00:47:46,369 --> 00:47:54,830
like first of all a healthy environment

00:47:50,630 --> 00:47:57,830
what Facebook always claims where all

00:47:54,830 --> 00:47:58,400
the family can spend a lot of time and

00:47:57,830 --> 00:48:00,460
money

00:47:58,400 --> 00:48:04,480
pork later

00:48:00,460 --> 00:48:07,420
or should it be an emancipating platform

00:48:04,480 --> 00:48:10,359
platform like which can help giving

00:48:07,420 --> 00:48:12,490
people a voice who normally don't have

00:48:10,359 --> 00:48:14,950
one and when she graphic content

00:48:12,490 --> 00:48:16,720
actually stay up right when it's proving

00:48:14,950 --> 00:48:18,460
out war crimes that are happening in

00:48:16,720 --> 00:48:20,170
other countries and these are really

00:48:18,460 --> 00:48:22,150
hard to beit's that early content

00:48:20,170 --> 00:48:23,920
moderators had to really deal with they

00:48:22,150 --> 00:48:26,470
might say hey this is really graphic

00:48:23,920 --> 00:48:28,630
violent violent content that should

00:48:26,470 --> 00:48:30,730
violate all our policies but they've

00:48:28,630 --> 00:48:32,259
started cultural movements and really

00:48:30,730 --> 00:48:34,059
helping you know push against

00:48:32,259 --> 00:48:35,440
governments that were you know doing

00:48:34,059 --> 00:48:37,779
very terrible things in their hands

00:48:35,440 --> 00:48:39,190
we're getting into moderating policy

00:48:37,779 --> 00:48:41,470
here you're missing the point

00:48:39,190 --> 00:48:45,039
whatever the policy is people are going

00:48:41,470 --> 00:48:48,009
to report this stuff yeah you share

00:48:45,039 --> 00:48:51,160
images III would see pictures of what

00:48:48,009 --> 00:48:53,619
was happening in Burma people are

00:48:51,160 --> 00:48:55,809
posting that to raise awareness not not

00:48:53,619 --> 00:48:59,880
to celebrate it and people are

00:48:55,809 --> 00:48:59,880
protesting and it's appearing on my desk

00:48:59,970 --> 00:49:07,420
and I've got to make a call is that baby

00:49:03,039 --> 00:49:08,999
dead and then I've got a press the right

00:49:07,420 --> 00:49:12,279
button and if I press the wrong button

00:49:08,999 --> 00:49:14,980
because my auditor thinks the baby's not

00:49:12,279 --> 00:49:17,319
dead then I've made a mistake and that

00:49:14,980 --> 00:49:19,180
counts towards my quality scores and I

00:49:17,319 --> 00:49:24,599
could get fired so I'm lying awake in

00:49:19,180 --> 00:49:24,599
bed at night seeing that image again and

00:49:25,710 --> 00:49:32,739
I'm trying to formulate an argument to

00:49:28,869 --> 00:49:35,140
keep my job and it doesn't matter what

00:49:32,739 --> 00:49:37,119
the policy is the point is

00:49:35,140 --> 00:49:39,579
people are gonna post this stuff and

00:49:37,119 --> 00:49:47,680
people are gonna complain about it and

00:49:39,579 --> 00:49:49,210
somebody's got to look at it I mean it

00:49:47,680 --> 00:49:51,819
just really shows the complexity of

00:49:49,210 --> 00:49:53,410
policymaking in this space right no and

00:49:51,819 --> 00:49:55,960
that's not that's not what it shows I

00:49:53,410 --> 00:49:57,640
think it shows like how difficult this

00:49:55,960 --> 00:49:59,079
job is and how you have like eight

00:49:57,640 --> 00:50:02,410
seconds sometimes to make this decision

00:49:59,079 --> 00:50:04,599
and I think that in order to understand

00:50:02,410 --> 00:50:06,880
how this all works we have to understand

00:50:04,599 --> 00:50:09,009
how these companies operate there should

00:50:06,880 --> 00:50:12,300
be the NDA's are there in place so that

00:50:09,009 --> 00:50:13,740
people don't gain the system in order to

00:50:12,300 --> 00:50:15,570
except like so that they don't get

00:50:13,740 --> 00:50:17,400
content past the moderators which is

00:50:15,570 --> 00:50:18,960
what the Facebook said but it's not it's

00:50:17,400 --> 00:50:22,080
the silence people in that we can't see

00:50:18,960 --> 00:50:24,510
what's happening for like Clara saying

00:50:22,080 --> 00:50:28,170
100,000 people who have had this exact

00:50:24,510 --> 00:50:30,480
same experience and worse yeah should we

00:50:28,170 --> 00:50:31,140
do one more question I think I think

00:50:30,480 --> 00:50:37,770
that's it then

00:50:31,140 --> 00:50:39,900
so yeah I want the air walls it was air

00:50:37,770 --> 00:50:40,290
worse okay yeah be a contact later if

00:50:39,900 --> 00:50:42,300
you like

00:50:40,290 --> 00:50:44,250
thank you nice yeah I think with that

00:50:42,300 --> 00:50:47,340
we'll wrap up the panel thank you so

00:50:44,250 --> 00:50:52,950
much for our panelists today a big round

00:50:47,340 --> 00:50:56,250
of applause for everyone okay we're

00:50:52,950 --> 00:50:58,620
gonna take a way home okay maybe just

00:50:56,250 --> 00:51:01,380
one follow-up we definitely want to

00:50:58,620 --> 00:51:04,410
highlight this book by Sarah - Roberts

00:51:01,380 --> 00:51:06,450
she was one of the persons inspiring us

00:51:04,410 --> 00:51:09,330
a lot for making the film the cleaners

00:51:06,450 --> 00:51:11,610
and we also cover in the film it's

00:51:09,330 --> 00:51:14,610
wonderful book it has a lot of in-depth

00:51:11,610 --> 00:51:16,770
information about the topic you might

00:51:14,610 --> 00:51:19,020
want to follow up on all the academic

00:51:16,770 --> 00:51:21,480
work of the people on the board here you

00:51:19,020 --> 00:51:23,270
might even want to see our film if you

00:51:21,480 --> 00:51:27,540
want to contact us there is a way online

00:51:23,270 --> 00:51:29,970
we hang around later on also if you want

00:51:27,540 --> 00:51:32,070
to engage more in supporting the people

00:51:29,970 --> 00:51:37,770
in the Philippines and there is a an

00:51:32,070 --> 00:51:40,350
organization called bien it stands for a

00:51:37,770 --> 00:51:42,420
union or a very small Union and the

00:51:40,350 --> 00:51:44,700
Philippines trying to defend workers

00:51:42,420 --> 00:51:47,940
rights in the Philippines especially in

00:51:44,700 --> 00:51:49,410
the clique working industries yen it's

00:51:47,940 --> 00:51:53,550
called like the Spanish word for good

00:51:49,410 --> 00:51:56,400
and yeah I think all these or online

00:51:53,550 --> 00:51:59,700
censorship org it's also a side some of

00:51:56,400 --> 00:52:02,430
you might know a way you can claim

00:51:59,700 --> 00:52:05,760
whenever you find it doubtful why

00:52:02,430 --> 00:52:07,680
something is taken down nice okay cool

00:52:05,760 --> 00:52:10,530
well thank you again we'll be back here

00:52:07,680 --> 00:52:12,670
in 45 minutes 12:45 for the next set of

00:52:10,530 --> 00:52:14,730
panels thank you

00:52:12,670 --> 00:52:14,730

YouTube URL: https://www.youtube.com/watch?v=qtH216R2Hls


