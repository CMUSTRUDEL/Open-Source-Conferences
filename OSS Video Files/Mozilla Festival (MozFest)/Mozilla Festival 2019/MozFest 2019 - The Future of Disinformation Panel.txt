Title: MozFest 2019 - The Future of Disinformation Panel
Publication date: 2019-11-04
Playlist: Mozilla Festival 2019
Description: 
	What will fake content look like in five years? In 10?

Camille FranÃ§ois - @camillefrancois

Chief Innovation Officer at Graphika and Mozilla Fellow

Claire Wardle - @cward1e

Co-Founder of First Draft and TED Fellow
Captions: 
	00:00:00,000 --> 00:00:03,959
so Claire Wardle she is the former

00:00:02,669 --> 00:00:06,660
researcher fellow at the Harvard

00:00:03,959 --> 00:00:08,550
Shorenstein Center but currently she's

00:00:06,660 --> 00:00:10,650
the executive director of first draft

00:00:08,550 --> 00:00:12,179
first draft is a nonprofit dedicated to

00:00:10,650 --> 00:00:16,139
addressing misinformation and

00:00:12,179 --> 00:00:18,180
disinformation and then Camille formerly

00:00:16,139 --> 00:00:20,550
a principal researcher at Google is now

00:00:18,180 --> 00:00:23,310
the chief innovation officer at grafica

00:00:20,550 --> 00:00:25,949
grafica is a company based in New York

00:00:23,310 --> 00:00:28,349
City that kind of Maps and investigates

00:00:25,949 --> 00:00:31,619
what's happening online and you're also

00:00:28,349 --> 00:00:33,570
currently a Mozilla fellow yes yeah so I

00:00:31,619 --> 00:00:36,680
think just to start just a kind of level

00:00:33,570 --> 00:00:38,820
set I was hoping you guys could explain

00:00:36,680 --> 00:00:40,649
the difference between misinformation

00:00:38,820 --> 00:00:43,200
and disinformation and you guys can take

00:00:40,649 --> 00:00:45,180
that one so I'll take this one because

00:00:43,200 --> 00:00:47,399
about two years ago I got so frustrated

00:00:45,180 --> 00:00:49,620
at the use of the term f Asterix Asterix

00:00:47,399 --> 00:00:51,149
Asterix news that I was like we need

00:00:49,620 --> 00:00:52,260
better terminology and missing

00:00:51,149 --> 00:00:52,710
disinformation been around for a long

00:00:52,260 --> 00:00:54,960
time

00:00:52,710 --> 00:00:57,059
disinformation is false information that

00:00:54,960 --> 00:00:59,879
is deliberately created and spread to

00:00:57,059 --> 00:01:01,350
cause harm misinformation is false

00:00:59,879 --> 00:01:03,420
information but the people spreading it

00:01:01,350 --> 00:01:04,650
don't realize that it's harmful so I

00:01:03,420 --> 00:01:06,450
always look about my mom a little bit

00:01:04,650 --> 00:01:08,460
like the previous panel if she sees a

00:01:06,450 --> 00:01:09,720
shark photo during a hurricane she

00:01:08,460 --> 00:01:11,460
forwards it being like oh my god the

00:01:09,720 --> 00:01:13,760
shark but she doesn't know that she's

00:01:11,460 --> 00:01:15,600
causing harm but I also talk about a

00:01:13,760 --> 00:01:17,850
creator set of turns with her same

00:01:15,600 --> 00:01:19,080
direction about mal information which

00:01:17,850 --> 00:01:21,450
actually we're seeing a lot more of

00:01:19,080 --> 00:01:23,130
which is genuine information that is

00:01:21,450 --> 00:01:24,960
shared to cause harm so that might be

00:01:23,130 --> 00:01:26,939
the deliberately leaking of information

00:01:24,960 --> 00:01:29,430
that's harmful it might be revenge porn

00:01:26,939 --> 00:01:31,079
it might be a genuine photo that's

00:01:29,430 --> 00:01:33,390
Reshard and people think that it's

00:01:31,079 --> 00:01:35,850
current so there's we just need

00:01:33,390 --> 00:01:38,729
complexity in this space because it

00:01:35,850 --> 00:01:40,140
we're three years into this moment where

00:01:38,729 --> 00:01:42,299
all of a sudden everybody worried about

00:01:40,140 --> 00:01:43,890
when I say everybody I mean the US and

00:01:42,299 --> 00:01:46,740
the UK rest of the world right yeah

00:01:43,890 --> 00:01:48,270
welcome to the party but in that time

00:01:46,740 --> 00:01:50,460
we're still talking about as these big

00:01:48,270 --> 00:01:51,570
buckets and actually we're not getting

00:01:50,460 --> 00:01:53,549
to the heart of the problem because

00:01:51,570 --> 00:01:54,780
we're using these terms in the false way

00:01:53,549 --> 00:01:57,240
that's a great way to sum it up is

00:01:54,780 --> 00:01:59,219
anything else on top of that no I I

00:01:57,240 --> 00:02:00,659
agree I kind of wonder where you put

00:01:59,219 --> 00:02:01,829
Donald Trump in your in your

00:02:00,659 --> 00:02:05,640
classification but that might be a

00:02:01,829 --> 00:02:07,409
question for later I tend to break down

00:02:05,640 --> 00:02:10,170
the hairy problem of disinformation

00:02:07,409 --> 00:02:11,750
according to three vectors right like it

00:02:10,170 --> 00:02:13,610
could be about the actors

00:02:11,750 --> 00:02:15,740
behind it if you're an account that's

00:02:13,610 --> 00:02:18,020
pretending to be an American activist

00:02:15,740 --> 00:02:19,820
but really you're run by Russian

00:02:18,020 --> 00:02:22,310
military intelligence or disinformation

00:02:19,820 --> 00:02:24,650
because of the actor that's behind the

00:02:22,310 --> 00:02:26,840
account behavior is another dimension

00:02:24,650 --> 00:02:29,120
right I'm going ABC just so that you can

00:02:26,840 --> 00:02:30,740
follow along so actor behavior for

00:02:29,120 --> 00:02:32,780
instance if there's an information that

00:02:30,740 --> 00:02:34,910
that's actually disseminated by an actor

00:02:32,780 --> 00:02:36,860
who say who they are and the content is

00:02:34,910 --> 00:02:39,320
right but they're disseminated by BOTS

00:02:36,860 --> 00:02:41,750
or by any strategy that makes it look

00:02:39,320 --> 00:02:43,520
like the content is much more popular

00:02:41,750 --> 00:02:45,260
than what it actually is it's not about

00:02:43,520 --> 00:02:47,090
the actor it's not about the contents

00:02:45,260 --> 00:02:48,890
about the behavior of how it's being

00:02:47,090 --> 00:02:51,020
disseminated and finally you have

00:02:48,890 --> 00:02:52,940
content problems right so sometimes you

00:02:51,020 --> 00:02:55,340
have content that's really designed to

00:02:52,940 --> 00:02:57,020
be dis informative so deep fakes would

00:02:55,340 --> 00:03:01,730
go into this along with all the other

00:02:57,020 --> 00:03:04,310
less deep types of fakery that's great

00:03:01,730 --> 00:03:07,130
okay so now is the game show part okay

00:03:04,310 --> 00:03:10,190
now I'm realizing that flipchart marker

00:03:07,130 --> 00:03:14,630
is not a whiteboard marker oh you'll

00:03:10,190 --> 00:03:17,989
think oh do we have just space on it

00:03:14,630 --> 00:03:19,820
okay sounds good I'll do it so the first

00:03:17,989 --> 00:03:21,260
question which platform do you think is

00:03:19,820 --> 00:03:22,940
a little worse when it comes to

00:03:21,260 --> 00:03:26,390
disinformation and write your answers on

00:03:22,940 --> 00:03:29,750
the white version and you have 30

00:03:26,390 --> 00:03:30,860
seconds on the clock I talked about this

00:03:29,750 --> 00:03:35,450
earlier when it's like it's a game of

00:03:30,860 --> 00:03:37,190
mrs. and mrs. that's a lot of people

00:03:35,450 --> 00:03:38,510
working it's real well I mean it's

00:03:37,190 --> 00:03:40,640
working ish okay

00:03:38,510 --> 00:03:41,900
okay I'll just to fight I hope you guys

00:03:40,640 --> 00:03:45,470
reveal your answers at the same time

00:03:41,900 --> 00:03:47,680
yeah okay one two three okay okay I was

00:03:45,470 --> 00:03:52,910
thinking three two one okay three two

00:03:47,680 --> 00:03:56,540
one go V contact oh we should talk about

00:03:52,910 --> 00:03:58,730
YouTube IV contacts I am I'm not rushing

00:03:56,540 --> 00:04:00,320
but but you said a lot of time in there

00:03:58,730 --> 00:04:02,989
true no but I actually don't mean that

00:04:00,320 --> 00:04:05,540
so V contact is a Russian Facebook and

00:04:02,989 --> 00:04:08,450
it's top of mind for me because when

00:04:05,540 --> 00:04:11,209
major American or European platforms

00:04:08,450 --> 00:04:13,340
focus on specific groups that they want

00:04:11,209 --> 00:04:15,290
to remove from their platforms those

00:04:13,340 --> 00:04:17,780
groups don't go off the internet and so

00:04:15,290 --> 00:04:20,150
for instance when we work on violent

00:04:17,780 --> 00:04:21,979
extremist groups or when we work on the

00:04:20,150 --> 00:04:24,140
groups in Myanmar for instance who were

00:04:21,979 --> 00:04:24,860
responsible for most of the dangerous

00:04:24,140 --> 00:04:27,169
con

00:04:24,860 --> 00:04:30,080
and once they're off Facebook and off

00:04:27,169 --> 00:04:32,360
Twitter enough Google we see them a lot

00:04:30,080 --> 00:04:34,280
on the contact and so it's you know I'm

00:04:32,360 --> 00:04:36,199
not trying to avoid pointing fingers I

00:04:34,280 --> 00:04:37,580
had any big platforms I'm not trying to

00:04:36,199 --> 00:04:40,280
be cheeky I'm just saying we have to

00:04:37,580 --> 00:04:42,199
think about smaller platforms where our

00:04:40,280 --> 00:04:44,990
moderation or frankly like our

00:04:42,199 --> 00:04:47,719
accountability don't reach because those

00:04:44,990 --> 00:04:49,610
bad actors don't seek like don't stop to

00:04:47,719 --> 00:04:52,219
do harm once we don't see them on

00:04:49,610 --> 00:04:53,810
Facebook which is a good point win I

00:04:52,219 --> 00:04:55,939
mean we're seeing more evidence now that

00:04:53,810 --> 00:04:58,069
deep platforming does work right but

00:04:55,939 --> 00:04:59,360
it's not as if it disappears yeah in the

00:04:58,069 --> 00:05:00,949
same way it's obviously there's a lot of

00:04:59,360 --> 00:05:02,930
emphasis on what's up and that also is a

00:05:00,949 --> 00:05:04,099
cesspool but increasingly we're seeing

00:05:02,930 --> 00:05:06,650
these sort of movements moving onto

00:05:04,099 --> 00:05:08,719
telegram now that a China's come down so

00:05:06,650 --> 00:05:10,009
right want a telegram like if we don't

00:05:08,719 --> 00:05:11,870
have a real understanding of the whole

00:05:10,009 --> 00:05:13,069
ecosystem right it's not that we don't

00:05:11,870 --> 00:05:14,180
have problems with the big platforms but

00:05:13,069 --> 00:05:15,379
we have to understand that another way

00:05:14,180 --> 00:05:16,699
to do this is yeah another way to put

00:05:15,379 --> 00:05:18,529
this is that it's not because it's no

00:05:16,699 --> 00:05:20,330
longer a problem for Facebook that it's

00:05:18,529 --> 00:05:21,560
no longer a problem for democracy

00:05:20,330 --> 00:05:23,479
sometimes they're things that are no

00:05:21,560 --> 00:05:24,979
longer a problem for Facebook at Google

00:05:23,479 --> 00:05:26,509
whatnot that are still really really

00:05:24,979 --> 00:05:29,060
problematic when you care about the

00:05:26,509 --> 00:05:32,000
health of the Internet so that's the V

00:05:29,060 --> 00:05:34,729
contacts back to me about YouTube no I

00:05:32,000 --> 00:05:37,129
just I mean it's it's because we work

00:05:34,729 --> 00:05:38,360
globally and so my frustration for

00:05:37,129 --> 00:05:40,610
example we did a lot of work in Brazil

00:05:38,360 --> 00:05:42,289
is that you know what's up is the place

00:05:40,610 --> 00:05:43,550
lots of people talk about but there's so

00:05:42,289 --> 00:05:44,719
much stuff on YouTube that's really

00:05:43,550 --> 00:05:46,580
really problematic and there's kind of

00:05:44,719 --> 00:05:48,229
there's different YouTube so there's the

00:05:46,580 --> 00:05:50,060
big YouTube that lots of people go in

00:05:48,229 --> 00:05:51,620
access every day and it's great but

00:05:50,060 --> 00:05:53,060
there are lots of youtubes that we don't

00:05:51,620 --> 00:05:55,189
spend time in and because it's so

00:05:53,060 --> 00:05:56,479
difficult to monitor video we're getting

00:05:55,189 --> 00:05:58,370
better now with closed captioning but

00:05:56,479 --> 00:05:59,960
it's still really really difficult then

00:05:58,370 --> 00:06:01,789
we don't necessarily understand what's

00:05:59,960 --> 00:06:03,889
happening there but those radicalization

00:06:01,789 --> 00:06:05,389
routes that we all know about it just

00:06:03,889 --> 00:06:07,879
frustrates me because it is mainstream

00:06:05,389 --> 00:06:09,409
it is owned by alphabet and they're

00:06:07,879 --> 00:06:10,849
getting away with murder because we're

00:06:09,409 --> 00:06:12,919
not giving it the scrutiny that we

00:06:10,849 --> 00:06:14,419
should be partly because it's so

00:06:12,919 --> 00:06:15,860
difficult to monitor and nobody wants to

00:06:14,419 --> 00:06:17,539
watch hours and hours of this really

00:06:15,860 --> 00:06:26,180
horrific stuff yeah I mean it's a good

00:06:17,539 --> 00:06:29,060
answer those be contact those a pair of

00:06:26,180 --> 00:06:30,289
people yeah I want to talk about video a

00:06:29,060 --> 00:06:33,110
little bit because you made a video on

00:06:30,289 --> 00:06:35,209
the New York Times that where you became

00:06:33,110 --> 00:06:37,399
Adele you were Adele and you were saying

00:06:35,209 --> 00:06:38,479
whatever you wanted to say do you want

00:06:37,399 --> 00:06:43,669
to talk about a little

00:06:38,479 --> 00:06:45,259
yeah so eyeing it so it was partly cuz I

00:06:43,669 --> 00:06:46,490
was ranting constantly about the way

00:06:45,259 --> 00:06:48,050
that journalists were talking about deep

00:06:46,490 --> 00:06:49,580
fakes and it's not as if we don't have

00:06:48,050 --> 00:06:51,409
to worry about deep fakes but the bigger

00:06:49,580 --> 00:06:52,819
concern is if we talk about it in the

00:06:51,409 --> 00:06:54,409
way that we currently are we're doing

00:06:52,819 --> 00:06:56,509
the work of the agents of disinformation

00:06:54,409 --> 00:06:58,520
which is to make everybody terrified

00:06:56,509 --> 00:07:00,349
about what they're seeing with their own

00:06:58,520 --> 00:07:01,879
eyes and I think we've honestly about

00:07:00,349 --> 00:07:03,800
two years away from a point where the

00:07:01,879 --> 00:07:06,529
majority of the population doesn't see

00:07:03,800 --> 00:07:08,689
video as evidence and that is much

00:07:06,529 --> 00:07:09,740
scarier than deep fakes and deep breaks

00:07:08,689 --> 00:07:11,330
particularly the moment around

00:07:09,740 --> 00:07:13,550
pornography is the bit that which we're

00:07:11,330 --> 00:07:15,469
talking about 96% of deep Frakes are

00:07:13,550 --> 00:07:17,150
actually women's faces put into

00:07:15,469 --> 00:07:19,189
pornography so it's not that it's not a

00:07:17,150 --> 00:07:20,599
problem but I was busy ranting so the

00:07:19,189 --> 00:07:22,430
New York Times said do you wanna do a

00:07:20,599 --> 00:07:24,319
video and ran in a video and I said yes

00:07:22,430 --> 00:07:25,550
please and then they said when we were

00:07:24,319 --> 00:07:26,990
when I was waiting for like are we gonna

00:07:25,550 --> 00:07:28,909
turn you into Adele which is a little

00:07:26,990 --> 00:07:32,210
bit like a bucket list moment but I felt

00:07:28,909 --> 00:07:33,439
bad like who has to tell maybe so I'm

00:07:32,210 --> 00:07:35,479
quite like I was like what the ethics of

00:07:33,439 --> 00:07:38,300
this and I was like sonic and so what it

00:07:35,479 --> 00:07:39,319
meant was that lots of people watch the

00:07:38,300 --> 00:07:41,389
video and I think all that was the

00:07:39,319 --> 00:07:43,249
purpose and I it's not like I'm missing

00:07:41,389 --> 00:07:44,960
an Lea changing newspaper coverage on it

00:07:43,249 --> 00:07:46,999
but the the way the media talked about

00:07:44,960 --> 00:07:48,620
defects is much much worse than I would

00:07:46,999 --> 00:07:49,999
argue the technology yeah where are some

00:07:48,620 --> 00:07:52,399
things that we should like talk about

00:07:49,999 --> 00:07:53,719
more would you say like you know I'm in

00:07:52,399 --> 00:07:56,240
the media so I could use this for my own

00:07:53,719 --> 00:07:57,740
job yeah personally asking no so for

00:07:56,240 --> 00:07:59,990
example this is being live-streamed

00:07:57,740 --> 00:08:01,370
bright isn't it yeah okay so there was a

00:07:59,990 --> 00:08:03,020
major news organization that brought me

00:08:01,370 --> 00:08:05,029
in about three weeks ago to talk about

00:08:03,020 --> 00:08:07,399
the fear of deep fakes in 2020 and I

00:08:05,029 --> 00:08:08,839
said I promise you hand on heart that's

00:08:07,399 --> 00:08:10,520
not gonna be the problem the problem is

00:08:08,839 --> 00:08:12,110
you guys running with a piece of

00:08:10,520 --> 00:08:13,699
original content that's three years old

00:08:12,110 --> 00:08:15,560
and they were like oh I don't think so I

00:08:13,699 --> 00:08:16,759
don't think so and let's just say it was

00:08:15,560 --> 00:08:19,310
potentially an American news

00:08:16,759 --> 00:08:21,139
organization ABC which a week later ran

00:08:19,310 --> 00:08:23,330
footage that they said was from Syria

00:08:21,139 --> 00:08:25,969
but actually it was a Kentucky gun show

00:08:23,330 --> 00:08:28,219
from three years ago and so the bigger

00:08:25,969 --> 00:08:31,399
problem we have is just that low level

00:08:28,219 --> 00:08:33,349
often genuine content or I always talk

00:08:31,399 --> 00:08:35,569
about like the drip drip drip drip drip

00:08:33,349 --> 00:08:37,849
of high partisan content we're not doing

00:08:35,569 --> 00:08:39,709
longitudinal studies about individual

00:08:37,849 --> 00:08:41,419
means might seem harmless and a bit of

00:08:39,709 --> 00:08:44,120
fun but what does it look like if

00:08:41,419 --> 00:08:46,130
continuously you see that stuff and so I

00:08:44,120 --> 00:08:48,529
think we focus on the sensational and

00:08:46,130 --> 00:08:50,029
the obviously fabricated and actually

00:08:48,529 --> 00:08:52,370
the bigger problem is the low level

00:08:50,029 --> 00:08:55,370
hyper partisan polarized

00:08:52,370 --> 00:08:56,330
misogynistic low-level racist yeah I

00:08:55,370 --> 00:08:57,680
want to talk about that a little bit

00:08:56,330 --> 00:09:00,080
this is gonna be another gameshow

00:08:57,680 --> 00:09:04,160
question you know there's so many

00:09:00,080 --> 00:09:05,779
flavors of deep fakes what do you think

00:09:04,160 --> 00:09:08,540
most of them are trying to accomplish

00:09:05,779 --> 00:09:11,089
like what are they mostly like political

00:09:08,540 --> 00:09:11,900
intrigue is it mostly like memes is it

00:09:11,089 --> 00:09:14,990
mostly porn

00:09:11,900 --> 00:09:19,400
what is it mostly deep fakes or any type

00:09:14,990 --> 00:09:22,730
of thanks oh yeah we can do another

00:09:19,400 --> 00:09:26,930
reveal did you rape you Kagan no okay

00:09:22,730 --> 00:09:29,990
all right three two one reveal poor okay

00:09:26,930 --> 00:09:31,940
boring okay gotcha yeah thanks it's four

00:09:29,990 --> 00:09:33,529
point that's unfortunate I mean I think

00:09:31,940 --> 00:09:35,930
about you know we live in a world where

00:09:33,529 --> 00:09:38,240
there's you know revenge porn and that

00:09:35,930 --> 00:09:40,460
could be like kind of harmful to not

00:09:38,240 --> 00:09:42,560
just kind of like really yeah I mean we

00:09:40,460 --> 00:09:44,960
know this is like most innovation comes

00:09:42,560 --> 00:09:46,370
out of pornography always has this is

00:09:44,960 --> 00:09:47,570
another one but we're not talking about

00:09:46,370 --> 00:09:49,880
it because surprise surprise the people

00:09:47,570 --> 00:09:51,230
were victims are women and so it's just

00:09:49,880 --> 00:09:53,360
not discussed in the way that it should

00:09:51,230 --> 00:09:55,970
and I mean even women in fact of like

00:09:53,360 --> 00:09:58,580
what how many of our faces are out there

00:09:55,970 --> 00:10:00,230
in these databases and how easy it is to

00:09:58,580 --> 00:10:01,430
put any of our faces out there in a

00:10:00,230 --> 00:10:02,839
pornographic place and not even know

00:10:01,430 --> 00:10:03,080
that it's happening that's the other

00:10:02,839 --> 00:10:05,420
thing

00:10:03,080 --> 00:10:07,220
it's terrible . but it's also terrible

00:10:05,420 --> 00:10:09,800
god knows where my face is right now

00:10:07,220 --> 00:10:12,140
don't i hope only on the stage i don't

00:10:09,800 --> 00:10:13,580
know what's out there but i think

00:10:12,140 --> 00:10:16,400
there's something to what Claire was

00:10:13,580 --> 00:10:17,420
saying on if you look at so so in my

00:10:16,400 --> 00:10:19,490
work I look at a lot of very

00:10:17,420 --> 00:10:21,710
sophisticated disinformation campaign

00:10:19,490 --> 00:10:23,510
that are run by actors such as

00:10:21,710 --> 00:10:25,100
government that have a lot of funding

00:10:23,510 --> 00:10:27,080
and a lot of people to do this harm

00:10:25,100 --> 00:10:29,120
right and so it's interesting that they

00:10:27,080 --> 00:10:30,800
don't use deep things the reason why

00:10:29,120 --> 00:10:32,300
they don't use deep faith is not because

00:10:30,800 --> 00:10:33,860
they're lacking the budget for it or

00:10:32,300 --> 00:10:36,020
lacking the people to do it or lacking

00:10:33,860 --> 00:10:37,580
the source material right the reason why

00:10:36,020 --> 00:10:39,500
for instance in Syria and the

00:10:37,580 --> 00:10:42,320
disinformation campaign that you see are

00:10:39,500 --> 00:10:44,089
using footage from one place and

00:10:42,320 --> 00:10:45,500
claiming that it's another place which

00:10:44,089 --> 00:10:47,150
is something you would want to do for

00:10:45,500 --> 00:10:49,580
instance if you're covering up a war

00:10:47,150 --> 00:10:52,850
crime it's because it's actually really

00:10:49,580 --> 00:10:55,790
hard to run the forensics on an image

00:10:52,850 --> 00:10:57,320
and to say oh here I actually think that

00:10:55,790 --> 00:11:00,230
the image you're presenting to me has

00:10:57,320 --> 00:11:02,930
been decontextualized and it's doable

00:11:00,230 --> 00:11:05,220
right open source in investigative

00:11:02,930 --> 00:11:07,079
techniques or growing they're fantastic

00:11:05,220 --> 00:11:09,120
like Belen can't but I think it's not

00:11:07,079 --> 00:11:11,730
considered to be a sexy tech problem

00:11:09,120 --> 00:11:14,069
there's so much funding and attention

00:11:11,730 --> 00:11:16,170
that goes into LA yeah let's detect the

00:11:14,069 --> 00:11:18,629
deep fakes when actually the lot of the

00:11:16,170 --> 00:11:20,939
hard work of the forensics that people

00:11:18,629 --> 00:11:23,550
need you know in newsrooms just in

00:11:20,939 --> 00:11:24,569
general to be supported to do is let's

00:11:23,550 --> 00:11:26,730
make sure that the image you're

00:11:24,569 --> 00:11:28,889
presenting me is what you say it is and

00:11:26,730 --> 00:11:30,959
it's not decontextualize or just taken

00:11:28,889 --> 00:11:33,060
from somewhere else again it's less sexy

00:11:30,959 --> 00:11:34,680
but it's really important yeah I think a

00:11:33,060 --> 00:11:36,329
case study that's interesting is during

00:11:34,680 --> 00:11:38,730
the Brazilian election somebody

00:11:36,329 --> 00:11:40,139
impersonated bowls Naro which one when

00:11:38,730 --> 00:11:42,480
he was stabbed and he was in hospital

00:11:40,139 --> 00:11:44,189
somebody pretended to be Boston ro and

00:11:42,480 --> 00:11:46,439
they recorded him from his hospital bed

00:11:44,189 --> 00:11:48,180
and he went viral on whatsapp has audio

00:11:46,439 --> 00:11:50,279
messages so again unless you're doing a

00:11:48,180 --> 00:11:51,959
lot of work in places like you know

00:11:50,279 --> 00:11:53,759
Nigeria or India or Brazil where audio

00:11:51,959 --> 00:11:55,560
messages are a real problem it took two

00:11:53,759 --> 00:11:56,819
days to do the forensic analysis to work

00:11:55,560 --> 00:11:58,620
out that that audio recording wasn't

00:11:56,819 --> 00:12:00,509
Bowl scenario because his pitch was

00:11:58,620 --> 00:12:02,550
slightly wrong when he used the letter R

00:12:00,509 --> 00:12:03,839
but two days by that time it was

00:12:02,550 --> 00:12:06,870
everywhere on what's that so when people

00:12:03,839 --> 00:12:08,220
deep fakes like you get a impersonator

00:12:06,870 --> 00:12:10,470
at Donald Trump you could do as much

00:12:08,220 --> 00:12:12,660
damage as doing a Donald Trump deep fake

00:12:10,470 --> 00:12:15,629
video it's audio that we are in no way

00:12:12,660 --> 00:12:19,559
ready for Wow not to mention text I mean

00:12:15,629 --> 00:12:21,240
the the machine generated blocks of text

00:12:19,559 --> 00:12:24,240
that look like they've been written by

00:12:21,240 --> 00:12:26,279
human for me are terrifying prospect in

00:12:24,240 --> 00:12:28,439
the future of disinformation when we

00:12:26,279 --> 00:12:30,870
look at troll farms the people they

00:12:28,439 --> 00:12:32,430
recruit usually in like online adverts

00:12:30,870 --> 00:12:34,110
it's actually quite fun to read them are

00:12:32,430 --> 00:12:36,779
people that they recruit to write

00:12:34,110 --> 00:12:38,220
believable content on blogs so

00:12:36,779 --> 00:12:40,800
that eventually they can weaponize the

00:12:38,220 --> 00:12:43,500
blog and then put political content in

00:12:40,800 --> 00:12:45,990
it if it becomes so much easier to just

00:12:43,500 --> 00:12:47,819
do machine generated text that creates

00:12:45,990 --> 00:12:49,800
all these blogs without having to pay

00:12:47,819 --> 00:12:52,259
someone to curate them then that's

00:12:49,800 --> 00:12:54,569
that's bad news for fake news yeah

00:12:52,259 --> 00:12:56,730
that's a that's a good line yeah I think

00:12:54,569 --> 00:12:59,069
that's a good point I was going to ask

00:12:56,730 --> 00:13:00,559
me next was what we recently saw when

00:12:59,069 --> 00:13:02,579
Elizabeth Warren who's running for

00:13:00,559 --> 00:13:03,149
Democratic nominee for president in

00:13:02,579 --> 00:13:06,629
United States

00:13:03,149 --> 00:13:08,699
she put a fake ad on Facebook about fake

00:13:06,629 --> 00:13:10,319
ads on Facebook and it said first line

00:13:08,699 --> 00:13:12,389
you know Zuckerberg comes out for Donald

00:13:10,319 --> 00:13:14,160
comes out in support for Donald Trump

00:13:12,389 --> 00:13:16,559
and then the second line said did you

00:13:14,160 --> 00:13:18,190
believe that this is a fake ad you know

00:13:16,559 --> 00:13:19,660
it's four years later since

00:13:18,190 --> 00:13:22,660
most forwards later since the 2016

00:13:19,660 --> 00:13:23,410
elections why is Facebook still having

00:13:22,660 --> 00:13:25,540
trouble with this

00:13:23,410 --> 00:13:27,100
well actually this monitor if you've

00:13:25,540 --> 00:13:29,200
seen it but if you saw the AOC

00:13:27,100 --> 00:13:30,970
questioning of Mark Zuckerberg this week

00:13:29,200 --> 00:13:32,380
and she said what happened if Sony

00:13:30,970 --> 00:13:34,120
pretends that Republican supports a

00:13:32,380 --> 00:13:35,740
green new deal and so an activist group

00:13:34,120 --> 00:13:37,030
has done exactly that they've put out an

00:13:35,740 --> 00:13:38,500
ad on Facebook saying that Lindsey

00:13:37,030 --> 00:13:41,770
Graham supports a green new deal which

00:13:38,500 --> 00:13:42,790
is like but it's and they've done

00:13:41,770 --> 00:13:44,140
research it's like a lot of people

00:13:42,790 --> 00:13:45,490
believe this I mean it I mean it's a

00:13:44,140 --> 00:13:47,050
bigger conversation about this

00:13:45,490 --> 00:13:49,150
ridiculous position that Facebook has

00:13:47,050 --> 00:13:50,770
taken on advertising there is no way

00:13:49,150 --> 00:13:52,270
that I think they can stand behind it

00:13:50,770 --> 00:13:54,730
and I think actually the Elizabeth

00:13:52,270 --> 00:13:57,130
Warren and this AOC one is is an example

00:13:54,730 --> 00:13:58,660
of you cannot pretend that you can't

00:13:57,130 --> 00:13:59,860
fact check and the reason that a lot of

00:13:58,660 --> 00:14:01,540
fact-checking organizations emerged in

00:13:59,860 --> 00:14:03,820
the late 1990s was because there was a

00:14:01,540 --> 00:14:04,510
growth of problematic claims on TV

00:14:03,820 --> 00:14:05,890
advertising

00:14:04,510 --> 00:14:07,960
so all these fact checking groups

00:14:05,890 --> 00:14:10,570
emerged and simply by being the watchdog

00:14:07,960 --> 00:14:12,040
false claims in TV advertising dropped

00:14:10,570 --> 00:14:13,720
so people go well it's the same on

00:14:12,040 --> 00:14:15,520
Facebook we just have to monitor but

00:14:13,720 --> 00:14:16,660
their Facebook ads API as we know from

00:14:15,520 --> 00:14:19,000
the amazing work from Mozilla is

00:14:16,660 --> 00:14:20,980
dreadful so if we can't actually monitor

00:14:19,000 --> 00:14:22,870
these ads then that argument completely

00:14:20,980 --> 00:14:25,600
falls on its face because we can't hold

00:14:22,870 --> 00:14:26,710
them to account so I really really hope

00:14:25,600 --> 00:14:28,360
that they change their mind on this

00:14:26,710 --> 00:14:30,460
before 2020 if they don't we're

00:14:28,360 --> 00:14:32,500
absolutely screwed Camille I remember uh

00:14:30,460 --> 00:14:34,300
like recently after Zuckerberg went to

00:14:32,500 --> 00:14:36,430
Georgetown where he said that it's not

00:14:34,300 --> 00:14:38,050
my job to police what politicians say is

00:14:36,430 --> 00:14:41,640
a good enough answer is that not good

00:14:38,050 --> 00:14:41,640
enough what do you think about that I

00:14:41,730 --> 00:14:48,850
mean I don't know there's the truth yeah

00:14:45,190 --> 00:14:51,130
politicians lie that that's a true story

00:14:48,850 --> 00:14:53,440
um in the 21st century politicians lie

00:14:51,130 --> 00:14:56,200
on Facebook that sucks

00:14:53,440 --> 00:14:58,660
I think this is one bucket of issues and

00:14:56,200 --> 00:15:00,160
frankly like I think my own personal

00:14:58,660 --> 00:15:02,650
feelings on this don't really matter I

00:15:00,160 --> 00:15:05,770
tend to focus on again like if you go to

00:15:02,650 --> 00:15:08,410
ABC actors and behave in content content

00:15:05,770 --> 00:15:09,970
is easy to obsess on because we can look

00:15:08,410 --> 00:15:11,320
at it and we can say oh I think it's

00:15:09,970 --> 00:15:12,580
story I think it's not true I think it's

00:15:11,320 --> 00:15:13,990
a lie I don't think it's a lie I think

00:15:12,580 --> 00:15:16,300
you manipulated the video and like you

00:15:13,990 --> 00:15:18,610
can argue on this I tend to worry a

00:15:16,300 --> 00:15:20,980
little bit more about behaviors like

00:15:18,610 --> 00:15:24,190
what are the politicians who are running

00:15:20,980 --> 00:15:26,440
campaigns with amplified bots and trolls

00:15:24,190 --> 00:15:28,810
right like you don't see that it's

00:15:26,440 --> 00:15:31,450
more problematic because it's less easy

00:15:28,810 --> 00:15:31,900
for consumers and for individuals to

00:15:31,450 --> 00:15:32,980
just be

00:15:31,900 --> 00:15:34,960
line and be like oh I'm being

00:15:32,980 --> 00:15:37,930
manipulated right like the information

00:15:34,960 --> 00:15:39,970
is the information asymmetry between the

00:15:37,930 --> 00:15:42,220
Internet user and the platform on

00:15:39,970 --> 00:15:44,610
everything that touches upon behavior is

00:15:42,220 --> 00:15:47,470
gigantic so I'm more worried about like

00:15:44,610 --> 00:15:49,390
politicians using BOTS and trolls and

00:15:47,470 --> 00:15:51,070
like a lot of weird behavioral

00:15:49,390 --> 00:15:52,420
manipulation technique on social media

00:15:51,070 --> 00:15:54,310
for their campaigns which we never

00:15:52,420 --> 00:15:56,050
talked about and I'm more worried about

00:15:54,310 --> 00:15:58,510
actors who are creating like fake

00:15:56,050 --> 00:16:00,880
personas same thing it's very hard for

00:15:58,510 --> 00:16:01,900
the users to see I'm a little bit less

00:16:00,880 --> 00:16:04,390
worried about lying

00:16:01,900 --> 00:16:06,370
who says what type of and ads I

00:16:04,390 --> 00:16:09,220
think that's like an American politics

00:16:06,370 --> 00:16:10,990
problem yeah yeah I think going back to

00:16:09,220 --> 00:16:12,190
like but but I'm I'm you know I'm not

00:16:10,990 --> 00:16:15,760
trying to be cheeky I'm serious like

00:16:12,190 --> 00:16:17,650
yeah as we head towards 2020 there's

00:16:15,760 --> 00:16:20,710
still zero serious debate in America

00:16:17,650 --> 00:16:23,110
about how campaigns and candidate are

00:16:20,710 --> 00:16:27,160
going to use or not to use social media

00:16:23,110 --> 00:16:29,500
right will they use fake profiles will

00:16:27,160 --> 00:16:31,180
they use BOTS you know what's the limit

00:16:29,500 --> 00:16:33,070
of what they're gonna do no one has gone

00:16:31,180 --> 00:16:35,590
and said hey by the way I'm not gonna do

00:16:33,070 --> 00:16:37,600
this this is my own code of conduct for

00:16:35,590 --> 00:16:39,850
my campaign and I'll give you a small

00:16:37,600 --> 00:16:41,590
example of like why that matters and how

00:16:39,850 --> 00:16:46,000
this can like really break down and to

00:16:41,590 --> 00:16:46,980
collect at a Syria in 2018 during the

00:16:46,000 --> 00:16:51,430
midterms

00:16:46,980 --> 00:16:54,820
one day I wake up and there's all these

00:16:51,430 --> 00:16:57,250
Ted Cruz supporter messages and they're

00:16:54,820 --> 00:17:00,070
all saying the exact same thing at the

00:16:57,250 --> 00:17:01,840
exact same time and so my phone explodes

00:17:00,070 --> 00:17:03,430
and my computer explodes and everyone's

00:17:01,840 --> 00:17:07,720
running around being like the Russian

00:17:03,430 --> 00:17:09,310
trolls are here protect Cruz is like you

00:17:07,720 --> 00:17:10,540
know so we start running the forensics

00:17:09,310 --> 00:17:11,980
and we're like I don't know guys it

00:17:10,540 --> 00:17:13,450
doesn't look like Russian trolls are

00:17:11,980 --> 00:17:15,820
like next thing it was like well the

00:17:13,450 --> 00:17:18,550
bots are here above all right in reality

00:17:15,820 --> 00:17:21,430
what had happened is the senator had

00:17:18,550 --> 00:17:23,110
created a campaign app right and his

00:17:21,430 --> 00:17:25,810
supporters how downloaded the campaign

00:17:23,110 --> 00:17:28,060
app and they had willingly agreed for

00:17:25,810 --> 00:17:30,850
the campaign app to share messages on

00:17:28,060 --> 00:17:33,010
social media by giving an auth token

00:17:30,850 --> 00:17:35,050
right so it was not fake

00:17:33,010 --> 00:17:37,690
nor was it done without the content of

00:17:35,050 --> 00:17:40,030
the users it did look like kind of weird

00:17:37,690 --> 00:17:41,880
but this is still something that

00:17:40,030 --> 00:17:44,400
technically is supposed to

00:17:41,880 --> 00:17:48,150
Hey and it was deaf technically okay to

00:17:44,400 --> 00:17:49,650
buy Twitter's own senders is that okay

00:17:48,150 --> 00:17:51,090
is that the type of use that we want

00:17:49,650 --> 00:17:52,380
again if we don't have a serious

00:17:51,090 --> 00:17:54,090
conversation about the types of

00:17:52,380 --> 00:17:56,430
behaviors that we want to see in

00:17:54,090 --> 00:17:58,050
campaigns we're bound to freak out every

00:17:56,430 --> 00:17:59,850
time someone does something innovative

00:17:58,050 --> 00:18:02,270
on social media and we're bound to call

00:17:59,850 --> 00:18:04,620
a troll and a bot everything that's like

00:18:02,270 --> 00:18:05,940
looking kind of weird you make a really

00:18:04,620 --> 00:18:07,980
good point I think what I want to ask

00:18:05,940 --> 00:18:09,870
both of you guys right now is like what

00:18:07,980 --> 00:18:11,640
is your wish list of what's in bounds

00:18:09,870 --> 00:18:13,410
like if a politician says I'm gonna do

00:18:11,640 --> 00:18:14,820
this and this and not this in this what

00:18:13,410 --> 00:18:16,380
does that wish let's look like of what's

00:18:14,820 --> 00:18:19,710
fair game and what's not very good

00:18:16,380 --> 00:18:21,510
question I mean I I do think this

00:18:19,710 --> 00:18:22,770
question of stance I mean I think Joe

00:18:21,510 --> 00:18:24,920
Biden came out and said we should all

00:18:22,770 --> 00:18:27,000
support it and then nobody else has and

00:18:24,920 --> 00:18:28,980
Facebook uses a term influence

00:18:27,000 --> 00:18:30,600
operations but what you just described

00:18:28,980 --> 00:18:32,700
is an influence operation and where

00:18:30,600 --> 00:18:35,010
activism tics into politics is a real

00:18:32,700 --> 00:18:36,420
issue I mean I think micro-targeting I

00:18:35,010 --> 00:18:37,440
mean I just really wish all the

00:18:36,420 --> 00:18:39,390
platforms would say we're not going to

00:18:37,440 --> 00:18:41,670
take political advertising because the

00:18:39,390 --> 00:18:43,470
truth is I mean I don't know how we we

00:18:41,670 --> 00:18:45,330
you know how do we actually police lies

00:18:43,470 --> 00:18:47,220
and if if it's about falsehoods they

00:18:45,330 --> 00:18:49,170
will just skirt the line of what's

00:18:47,220 --> 00:18:51,390
misleading but I think things like

00:18:49,170 --> 00:18:54,180
refusing to I mean the other question is

00:18:51,390 --> 00:18:56,190
leaked documents if a you know every

00:18:54,180 --> 00:18:57,570
politician uses oppositional research if

00:18:56,190 --> 00:18:58,770
somebody comes along with that kind of

00:18:57,570 --> 00:18:59,940
stuff are they really gonna use it when

00:18:58,770 --> 00:19:01,530
they don't know where it's come from

00:18:59,940 --> 00:19:03,510
but I think that things like leaked

00:19:01,530 --> 00:19:04,770
documents things like micro-targeting

00:19:03,510 --> 00:19:07,800
which I don't know how we do so I'd like

00:19:04,770 --> 00:19:09,000
to get it all all gone are the main

00:19:07,800 --> 00:19:10,140
things I just I don't think we've

00:19:09,000 --> 00:19:11,580
wrapped ahead run and we're not gonna do

00:19:10,140 --> 00:19:13,530
it before 2020 something dread for what

00:19:11,580 --> 00:19:15,770
happened and then they'll be like oh we

00:19:13,530 --> 00:19:18,960
shoulda seen this coming

00:19:15,770 --> 00:19:21,150
I think more transparency in general

00:19:18,960 --> 00:19:23,070
enables people to sort of see what's

00:19:21,150 --> 00:19:25,440
what right so like in the Ted Cruz thing

00:19:23,070 --> 00:19:27,930
if all these messages said sent with

00:19:25,440 --> 00:19:29,220
this app then people start you know stop

00:19:27,930 --> 00:19:31,140
freaking out at me like oh I see what's

00:19:29,220 --> 00:19:34,050
going on right similarly if you have

00:19:31,140 --> 00:19:36,240
like a profile that says you know

00:19:34,050 --> 00:19:37,920
operated in Ukraine you can start asking

00:19:36,240 --> 00:19:39,480
questions I think like which which

00:19:37,920 --> 00:19:41,820
happened recently right there was a big

00:19:39,480 --> 00:19:43,620
I love Trump page was like operated from

00:19:41,820 --> 00:19:45,150
Ukraine and people like but Facebook

00:19:43,620 --> 00:19:46,620
didn't find it journalists found it was

00:19:45,150 --> 00:19:48,420
why I'm saying like if you have more

00:19:46,620 --> 00:19:49,140
transparency than you have smarter

00:19:48,420 --> 00:19:50,700
people

00:19:49,140 --> 00:19:52,470
investigative journalism that is

00:19:50,700 --> 00:19:54,420
investigative groups you know consumer

00:19:52,470 --> 00:19:55,260
advocacy groups who are able to do this

00:19:54,420 --> 00:19:57,360
type of work and

00:19:55,260 --> 00:19:59,700
hey what the is going on here right

00:19:57,360 --> 00:20:01,860
so I think in general more labeling of

00:19:59,700 --> 00:20:04,169
the complexity of these information

00:20:01,860 --> 00:20:06,540
environment helps people look for those

00:20:04,169 --> 00:20:09,090
signals and see when something's odd

00:20:06,540 --> 00:20:11,010
yeah yeah I relive that point you

00:20:09,090 --> 00:20:13,049
mentioned of like why isn't a politician

00:20:11,010 --> 00:20:15,600
said this is what we're not doing that's

00:20:13,049 --> 00:20:17,070
definitely a thing that's missing I want

00:20:15,600 --> 00:20:17,790
you know you guys have done a lot of

00:20:17,070 --> 00:20:19,049
panels together

00:20:17,790 --> 00:20:22,320
I think the audience can tell that even

00:20:19,049 --> 00:20:26,760
with the report first time we're getting

00:20:22,320 --> 00:20:30,059
petals weights from now on yeah I'm

00:20:26,760 --> 00:20:38,280
gonna travel yeah can't get the porn off

00:20:30,059 --> 00:20:40,350
your paddles gonna ask you guys you know

00:20:38,280 --> 00:20:42,000
you guys probably have a good sense of

00:20:40,350 --> 00:20:43,559
you know what things always get talked

00:20:42,000 --> 00:20:45,360
about when you talk about this

00:20:43,559 --> 00:20:46,320
information and what things never get

00:20:45,360 --> 00:20:47,580
talked like you guys can make the

00:20:46,320 --> 00:20:50,130
drinking game of like this information

00:20:47,580 --> 00:20:51,510
panel in cooking game got the bingo

00:20:50,130 --> 00:20:53,309
sheet out here and we don't know you

00:20:51,510 --> 00:20:54,570
guys who make it but I want to ask like

00:20:53,309 --> 00:20:56,100
what are some things that never gets

00:20:54,570 --> 00:20:57,299
talked about when it comes to this

00:20:56,100 --> 00:21:03,179
information that needs to get talked

00:20:57,299 --> 00:21:05,220
about so okay so we're we all have our

00:21:03,179 --> 00:21:07,049
little rabbit holes right like one that

00:21:05,220 --> 00:21:09,720
Clara and I were just talking about is

00:21:07,049 --> 00:21:12,299
um I think about the big Russian

00:21:09,720 --> 00:21:15,840
campaign that targeted the u.s. in 2016

00:21:12,299 --> 00:21:17,460
right we talked about it so much right

00:21:15,840 --> 00:21:19,500
it was a headlines on headlines on

00:21:17,460 --> 00:21:21,510
headlines and data was shared and

00:21:19,500 --> 00:21:23,460
congressional reports were written I

00:21:21,510 --> 00:21:26,280
record some of them and it's just like

00:21:23,460 --> 00:21:27,870
you know this this this constant

00:21:26,280 --> 00:21:29,720
overload of information about what

00:21:27,870 --> 00:21:33,390
happened in 2016

00:21:29,720 --> 00:21:35,520
yet there are a few things that did

00:21:33,390 --> 00:21:37,799
happen in 2016 that we never talked

00:21:35,520 --> 00:21:39,929
about and that as a result create little

00:21:37,799 --> 00:21:42,570
taboos that prevent us from actually

00:21:39,929 --> 00:21:45,870
being ready for more campaigns of the

00:21:42,570 --> 00:21:49,380
story one of them is a lot of these big

00:21:45,870 --> 00:21:53,460
troll campaigns use private messaging

00:21:49,380 --> 00:21:56,460
emails DMS to target journalists and

00:21:53,460 --> 00:21:58,470
activists and citizens directly we're in

00:21:56,460 --> 00:22:00,150
the impression that like Russian trolls

00:21:58,470 --> 00:22:02,010
basically liked us put out a bunch of

00:22:00,150 --> 00:22:03,659
tweets and the tweets were fun and some

00:22:02,010 --> 00:22:04,350
people retweeted it and really was the

00:22:03,659 --> 00:22:06,570
harm in it

00:22:04,350 --> 00:22:08,460
right but in reality you had a much more

00:22:06,570 --> 00:22:09,000
insidious profound and complicated

00:22:08,460 --> 00:22:10,799
campaign

00:22:09,000 --> 00:22:12,870
we're journalists were being fed

00:22:10,799 --> 00:22:14,760
material we're activists were being

00:22:12,870 --> 00:22:16,650
funded and manipulated and because we

00:22:14,760 --> 00:22:18,539
haven't gone through the bottom of this

00:22:16,650 --> 00:22:20,340
because we have an impact exactly what

00:22:18,539 --> 00:22:21,990
happened because we had never heard

00:22:20,340 --> 00:22:24,090
those stories and because we never put

00:22:21,990 --> 00:22:25,799
those data on the table we're not really

00:22:24,090 --> 00:22:27,929
acknowledging how insidious and

00:22:25,799 --> 00:22:30,240
complicated those more complicated

00:22:27,929 --> 00:22:32,220
campaigns can be and again I think for

00:22:30,240 --> 00:22:34,350
the groups who were targeted and for the

00:22:32,220 --> 00:22:35,130
media in particular that's a hell of a

00:22:34,350 --> 00:22:36,929
blind spot

00:22:35,130 --> 00:22:38,730
yeah but also nobody wants to be the

00:22:36,929 --> 00:22:40,500
person like all walks I got four words

00:22:38,730 --> 00:22:42,240
yeah like that's part of the problem is

00:22:40,500 --> 00:22:44,039
and that's why we're not hearing about

00:22:42,240 --> 00:22:46,860
it but the real vulnerability for 2020

00:22:44,039 --> 00:22:48,870
is local news in the US which has had

00:22:46,860 --> 00:22:50,700
its heart ripped out anyway so you've

00:22:48,870 --> 00:22:51,900
got under-resourced newsrooms with many

00:22:50,700 --> 00:22:53,429
journalists that would love to get out

00:22:51,900 --> 00:22:55,710
of local and potentially move to

00:22:53,429 --> 00:22:56,850
national you get there in a place where

00:22:55,710 --> 00:22:59,010
they haven't been trained they haven't

00:22:56,850 --> 00:23:00,360
got the editorial oversight and you've

00:22:59,010 --> 00:23:01,740
got a number of problems there so if you

00:23:00,360 --> 00:23:03,390
try and go to some of the New York Times

00:23:01,740 --> 00:23:05,520
and hand them some problematic content

00:23:03,390 --> 00:23:06,600
thinking like no but if you go to five

00:23:05,520 --> 00:23:07,830
different local newsrooms and they

00:23:06,600 --> 00:23:09,419
publish it and then you go to the New

00:23:07,830 --> 00:23:11,220
York Times I'm like oh your colleagues

00:23:09,419 --> 00:23:13,110
have done that I mean the PlayBook is

00:23:11,220 --> 00:23:14,570
already out there but we're not having

00:23:13,110 --> 00:23:17,130
that conversation because it's all about

00:23:14,570 --> 00:23:18,750
people being manipulated because the

00:23:17,130 --> 00:23:20,429
mainstream media and to be fair they

00:23:18,750 --> 00:23:21,659
also used activist groups and

00:23:20,429 --> 00:23:23,460
communities of color and other

00:23:21,659 --> 00:23:25,440
communities who are more vulnerable to

00:23:23,460 --> 00:23:26,280
these messages and we're not protecting

00:23:25,440 --> 00:23:27,659
them we're not training them we're not

00:23:26,280 --> 00:23:29,940
seeing that as part of the information

00:23:27,659 --> 00:23:31,890
ecosystem we're not even doing the basic

00:23:29,940 --> 00:23:34,679
due diligence of investigating what

00:23:31,890 --> 00:23:35,880
targeted them a few years ago frankly so

00:23:34,679 --> 00:23:38,159
that's one the other thing that I would

00:23:35,880 --> 00:23:39,929
love is that we stop lumping all these

00:23:38,159 --> 00:23:42,090
issues together right like what we call

00:23:39,929 --> 00:23:43,830
disinformation now is so complex and

00:23:42,090 --> 00:23:45,690
touches upon so many different topics

00:23:43,830 --> 00:23:47,400
that I don't think is going to be

00:23:45,690 --> 00:23:51,000
helpful going forward to just like keep

00:23:47,400 --> 00:23:53,850
on you know stacking everything recently

00:23:51,000 --> 00:23:57,000
we published a report on a campaign that

00:23:53,850 --> 00:23:59,100
was run by and Chinese Network to do

00:23:57,000 --> 00:24:01,140
into Human Rights messaging on multiple

00:23:59,100 --> 00:24:02,909
platforms and people were like oh yeah

00:24:01,140 --> 00:24:04,650
that's great also my grandmother on

00:24:02,909 --> 00:24:06,539
Facebook she's like completely off her

00:24:04,650 --> 00:24:09,000
rocker I'm like those are not the same

00:24:06,539 --> 00:24:11,490
issues like I'm sorry that you know like

00:24:09,000 --> 00:24:13,380
news feeds are probably set up and you

00:24:11,490 --> 00:24:15,809
think outrage is winning on social media

00:24:13,380 --> 00:24:17,429
but like we have to start and separate

00:24:15,809 --> 00:24:19,440
what's you know what are the different

00:24:17,429 --> 00:24:21,000
lanes of disinformation problems how do

00:24:19,440 --> 00:24:22,510
we talk about them they all have

00:24:21,000 --> 00:24:24,880
different solutions so

00:24:22,510 --> 00:24:27,070
belong to cybersecurity some belong to

00:24:24,880 --> 00:24:29,260
consumer protection some belong to media

00:24:27,070 --> 00:24:30,970
training like it's so important I think

00:24:29,260 --> 00:24:33,370
we should no longer have disinformation

00:24:30,970 --> 00:24:36,990
panels which it's like yes yeah maybe

00:24:33,370 --> 00:24:36,990
that's the last disinformation panel

00:24:38,040 --> 00:24:43,240
that's like you know I know that can I

00:24:41,020 --> 00:24:43,840
add firing from that's because for the

00:24:43,240 --> 00:24:44,799
last three years

00:24:43,840 --> 00:24:46,780
everybody has been like oh my god

00:24:44,799 --> 00:24:48,250
disinformation the normal ethical

00:24:46,780 --> 00:24:49,929
boundaries that would exist have kind of

00:24:48,250 --> 00:24:51,490
been thrown out of the window so you

00:24:49,929 --> 00:24:52,929
have different disinformation confidence

00:24:51,490 --> 00:24:54,940
when you've got like a sweet librarian

00:24:52,929 --> 00:24:56,860
called Barbara from there at west next

00:24:54,940 --> 00:24:58,210
to somebody from the NSA because bob was

00:24:56,860 --> 00:25:00,490
there to talk about media literacy and

00:24:58,210 --> 00:25:02,290
NSA dude is there about how do we do

00:25:00,490 --> 00:25:03,580
surveillance of state actors yeah and

00:25:02,290 --> 00:25:04,809
the truth is they're very different

00:25:03,580 --> 00:25:06,460
communities and they normally would not

00:25:04,809 --> 00:25:08,500
be in the same room and so questions

00:25:06,460 --> 00:25:09,160
about who funds who whose technology is

00:25:08,500 --> 00:25:10,720
okay to use

00:25:09,160 --> 00:25:12,960
where does monitoring tip into

00:25:10,720 --> 00:25:15,429
surveillance really big questions that

00:25:12,960 --> 00:25:17,049
here would just be like normal we just

00:25:15,429 --> 00:25:18,880
kind of work those things out when it

00:25:17,049 --> 00:25:20,140
comes to disinformation those questions

00:25:18,880 --> 00:25:22,179
are not being asked those guidelines are

00:25:20,140 --> 00:25:25,270
not being created because like here for

00:25:22,179 --> 00:25:27,100
the Russians moral panic put Barbara the

00:25:25,270 --> 00:25:28,690
NSA give them data we're freaking out

00:25:27,100 --> 00:25:30,610
you know like this is not helpful or

00:25:28,690 --> 00:25:31,470
Barbara like she's for jobs what I'm

00:25:30,610 --> 00:25:34,960
saying

00:25:31,470 --> 00:25:36,760
for example the ethics of like scraping

00:25:34,960 --> 00:25:38,350
open whatsapp groups like everyone like

00:25:36,760 --> 00:25:39,940
oh we can't get into whatsapp groups and

00:25:38,350 --> 00:25:41,620
so what you hear is academics say

00:25:39,940 --> 00:25:43,299
exactly the same as platforms would say

00:25:41,620 --> 00:25:44,770
which is like well we need to have this

00:25:43,299 --> 00:25:45,790
data because we need to understand

00:25:44,770 --> 00:25:46,929
what's going on I mean the platform's

00:25:45,790 --> 00:25:48,640
always trying to use it for advertising

00:25:46,929 --> 00:25:50,020
but you know we don't have standards

00:25:48,640 --> 00:25:51,370
around whether or not we should be

00:25:50,020 --> 00:25:52,450
scraping open what's that groups and if

00:25:51,370 --> 00:25:55,510
we're gonna do it how do we secure the

00:25:52,450 --> 00:25:56,650
data etc etc etc and so from UNICEF for

00:25:55,510 --> 00:25:58,210
scraping open whatsapp groups in

00:25:56,650 --> 00:25:59,830
Pakistan to find about polio rumors

00:25:58,210 --> 00:26:01,179
academics in Brazil is trying to do

00:25:59,830 --> 00:26:02,110
where researchers trying to do it

00:26:01,179 --> 00:26:03,429
because they actually just want to you

00:26:02,110 --> 00:26:05,020
know get up on the CV ladder I mean

00:26:03,429 --> 00:26:06,130
we're just not thinking through these

00:26:05,020 --> 00:26:08,080
things we don't have a set of ethical

00:26:06,130 --> 00:26:10,360
guidelines around scraping closed

00:26:08,080 --> 00:26:11,260
messaging like that's just a basic we

00:26:10,360 --> 00:26:12,850
should be happy though you know it's

00:26:11,260 --> 00:26:14,290
what the thing that's fun though is like

00:26:12,850 --> 00:26:16,450
because we're stuck on our like

00:26:14,290 --> 00:26:18,340
disinformation industrial complex I know

00:26:16,450 --> 00:26:20,200
you like the sentence like we're sucking

00:26:18,340 --> 00:26:22,240
this thing or like all our issues are

00:26:20,200 --> 00:26:24,580
really new and we do new rules for our

00:26:22,240 --> 00:26:26,410
own new issues like there are a lot of

00:26:24,580 --> 00:26:28,900
like really smart scholars that have

00:26:26,410 --> 00:26:30,909
been using Internet data to do serious

00:26:28,900 --> 00:26:32,470
scholarship and they have a lot of like

00:26:30,909 --> 00:26:34,419
very clear ethical guidelines and

00:26:32,470 --> 00:26:35,630
thoughts about when you can break terms

00:26:34,419 --> 00:26:36,950
of services and when it's a

00:26:35,630 --> 00:26:38,300
terrible idea what do you do for

00:26:36,950 --> 00:26:40,220
security and what do you do for privacy

00:26:38,300 --> 00:26:42,260
and they're kind of like who the

00:26:40,220 --> 00:26:44,360
are those super agitated miss and so

00:26:42,260 --> 00:26:47,270
people who are like oh my god scraping

00:26:44,360 --> 00:26:49,580
is new like think we're nuts like you

00:26:47,270 --> 00:26:52,430
also have to like land back and learn

00:26:49,580 --> 00:26:54,170
from old guidelines and ethical

00:26:52,430 --> 00:26:56,120
principles that are generally in place

00:26:54,170 --> 00:26:57,680
from other fields that we should be

00:26:56,120 --> 00:27:00,140
learning from I enjoyed the South is

00:26:57,680 --> 00:27:01,130
like 120 ethics guidelines for AI but

00:27:00,140 --> 00:27:04,310
there'll be stalking to one another I

00:27:01,130 --> 00:27:05,450
was like yeah field yeah exactly I love

00:27:04,310 --> 00:27:07,610
to hear this is gonna be the last

00:27:05,450 --> 00:27:09,590
disinformation panel of all time sounds

00:27:07,610 --> 00:27:11,420
like we have a lot of other stuff to

00:27:09,590 --> 00:27:13,430
cover now we should do audience Q&A is

00:27:11,420 --> 00:27:15,890
they might have any questions it's one

00:27:13,430 --> 00:27:22,490
in the back one over here one over here

00:27:15,890 --> 00:27:23,960
I defer to Kevin I mean I guess the the

00:27:22,490 --> 00:27:25,910
obvious question here is sort of a who

00:27:23,960 --> 00:27:27,350
watches the Watchmen type thing where

00:27:25,910 --> 00:27:29,480
why should we trust you

00:27:27,350 --> 00:27:32,300
yeah accurately tell us what is this

00:27:29,480 --> 00:27:34,010
information or not yeah but this came

00:27:32,300 --> 00:27:37,130
through very clearly we're not to be

00:27:34,010 --> 00:27:38,690
trusted but in general overseas yeah

00:27:37,130 --> 00:27:39,830
it's still that one but I think this is

00:27:38,690 --> 00:27:41,630
the question that we're trying to say

00:27:39,830 --> 00:27:43,160
right link you can't just show up and be

00:27:41,630 --> 00:27:44,690
like oh wow and his information is so

00:27:43,160 --> 00:27:46,490
new it's so important let us do our

00:27:44,690 --> 00:27:48,260
thing right like it's a terrible idea we

00:27:46,490 --> 00:27:50,060
need ethical guidelines we need

00:27:48,260 --> 00:27:52,190
watchdogs for the watchdogs we need a

00:27:50,060 --> 00:27:54,470
serious feel with like clear ethical

00:27:52,190 --> 00:27:56,480
standards and standards of rigor and we

00:27:54,470 --> 00:27:59,180
need some processes for peer reviewing

00:27:56,480 --> 00:28:01,370
even for non scholarly work right so

00:27:59,180 --> 00:28:03,110
like in a normal field you can't just

00:28:01,370 --> 00:28:04,880
show up and like make something up out

00:28:03,110 --> 00:28:06,890
of ethical guidelines that you thought

00:28:04,880 --> 00:28:08,600
about last night based on some

00:28:06,890 --> 00:28:10,280
principles of rigor that you just made

00:28:08,600 --> 00:28:12,050
up you know over drinks with friends

00:28:10,280 --> 00:28:14,060
right like we need to sort of evolve

00:28:12,050 --> 00:28:17,090
this new misinformation field into

00:28:14,060 --> 00:28:18,740
something that's more structured and and

00:28:17,090 --> 00:28:20,810
frankly more accountable for the people

00:28:18,740 --> 00:28:23,120
who operate within them so definitely

00:28:20,810 --> 00:28:25,010
agree do not trust us and partly because

00:28:23,120 --> 00:28:26,360
not grafica but there are other

00:28:25,010 --> 00:28:27,950
organizations that are part of the

00:28:26,360 --> 00:28:29,480
disinformation industrial complex who

00:28:27,950 --> 00:28:30,710
are basically right they do some

00:28:29,480 --> 00:28:32,510
analysis they write a press release they

00:28:30,710 --> 00:28:34,130
sent a journalist to say here's evidence

00:28:32,510 --> 00:28:36,080
of a coordinated campaign that was

00:28:34,130 --> 00:28:37,610
organized by Russia you're like okay can

00:28:36,080 --> 00:28:38,990
you give me access to the data Lake can

00:28:37,610 --> 00:28:40,670
you tell me how you did that no we

00:28:38,990 --> 00:28:42,260
couldn't possibly and what you have is a

00:28:40,670 --> 00:28:43,550
lot of really problematic journalism

00:28:42,260 --> 00:28:45,170
where they're they have no understanding

00:28:43,550 --> 00:28:46,760
of how to do the attribution correctly

00:28:45,170 --> 00:28:47,690
and they don't understand how this

00:28:46,760 --> 00:28:49,490
research has been done in the first

00:28:47,690 --> 00:28:50,929
place and so a Turk

00:28:49,490 --> 00:28:51,950
Al's point the only way that we can

00:28:50,929 --> 00:28:54,140
watch The Watchmen is by having

00:28:51,950 --> 00:28:56,240
transparent principles about how we

00:28:54,140 --> 00:28:58,250
understand and attribute these campaigns

00:28:56,240 --> 00:29:00,020
to certain state actors and certainly

00:28:58,250 --> 00:29:02,030
you know we are both European but live

00:29:00,020 --> 00:29:03,860
in the u.s. you can spend time in the

00:29:02,030 --> 00:29:05,030
u.s. meetings as if the u.s. is never

00:29:03,860 --> 00:29:06,590
itself been involved in any of these

00:29:05,030 --> 00:29:08,179
types of campaigns yeah so like this is

00:29:06,590 --> 00:29:09,410
a really challenging complex problem

00:29:08,179 --> 00:29:11,210
that requires a level of transparency

00:29:09,410 --> 00:29:13,710
from everybody to understand what's

00:29:11,210 --> 00:29:15,010
really happening all right next question

00:29:13,710 --> 00:29:19,100
[Music]

00:29:15,010 --> 00:29:26,600
once again defer to Kevin let's go

00:29:19,100 --> 00:29:28,250
question coming up hi thank you so much

00:29:26,600 --> 00:29:30,200
for the panel I have two questions the

00:29:28,250 --> 00:29:31,490
first you alluded to it now we talk a

00:29:30,200 --> 00:29:34,070
lot about Russian misinformation

00:29:31,490 --> 00:29:35,540
disinformation campaigns and a lot less

00:29:34,070 --> 00:29:37,850
about the role that Western governments

00:29:35,540 --> 00:29:39,320
and States play in this and I'd love to

00:29:37,850 --> 00:29:42,429
hear more about what's the research on

00:29:39,320 --> 00:29:44,929
this how do we tackle this problem

00:29:42,429 --> 00:29:47,000
because it must exist as well would be

00:29:44,929 --> 00:29:49,070
naive to assume it isn't and the second

00:29:47,000 --> 00:29:50,570
one coming from a data privacy security

00:29:49,070 --> 00:29:52,730
background we're very concerned about

00:29:50,570 --> 00:29:54,890
the use of data in targeting of

00:29:52,730 --> 00:29:57,290
political advertisement the use of data

00:29:54,890 --> 00:29:59,050
broker data how do you see the

00:29:57,290 --> 00:30:02,630
relationship between this and

00:29:59,050 --> 00:30:05,720
misinformation disinformation don't

00:30:02,630 --> 00:30:08,150
tackle the state act as one yeah that's

00:30:05,720 --> 00:30:11,540
a great question so there's an official

00:30:08,150 --> 00:30:12,080
answer and there's a complex thing that

00:30:11,540 --> 00:30:14,150
goes with it

00:30:12,080 --> 00:30:16,190
the official answer is the field of

00:30:14,150 --> 00:30:18,470
disinformation has agreed that state

00:30:16,190 --> 00:30:22,780
actors in general shouldn't be using

00:30:18,470 --> 00:30:25,790
deceptive methods in order to you know

00:30:22,780 --> 00:30:28,670
interfere with democratic processes and

00:30:25,790 --> 00:30:30,380
do election interference and in general

00:30:28,670 --> 00:30:31,910
if you listen to the industry so if you

00:30:30,380 --> 00:30:34,070
listen to the tech platforms they would

00:30:31,910 --> 00:30:35,510
tell you that what really matters isn't

00:30:34,070 --> 00:30:37,760
really who's behind it it's just the

00:30:35,510 --> 00:30:41,809
fact that governments are using these

00:30:37,760 --> 00:30:43,220
techniques that's sort of like on the

00:30:41,809 --> 00:30:44,809
record everyone agrees that no

00:30:43,220 --> 00:30:48,170
governments should do that now in

00:30:44,809 --> 00:30:50,540
reality no Western government ever gets

00:30:48,170 --> 00:30:51,860
caught doing this type of activity which

00:30:50,540 --> 00:30:53,900
is interesting because of course it goes

00:30:51,860 --> 00:30:55,250
to like well perhaps those are not being

00:30:53,900 --> 00:30:59,330
investigated those are not being

00:30:55,250 --> 00:31:01,070
prioritized with that creates for me two

00:30:59,330 --> 00:31:03,080
questions the first one is a policy

00:31:01,070 --> 00:31:05,059
question the second one is an in

00:31:03,080 --> 00:31:07,070
to get if question on the investigative

00:31:05,059 --> 00:31:09,590
side I don't know if there are people

00:31:07,070 --> 00:31:11,809
enough people looking at the types of

00:31:09,590 --> 00:31:15,110
campaign that the US and France and the

00:31:11,809 --> 00:31:17,149
UK could be running that are using the

00:31:15,110 --> 00:31:19,279
same techniques we know that some of

00:31:17,149 --> 00:31:21,919
these campaigns have been discussed so

00:31:19,279 --> 00:31:24,860
for instance known examples where

00:31:21,919 --> 00:31:27,080
government used fake profiles to target

00:31:24,860 --> 00:31:29,179
specific communities we have some of

00:31:27,080 --> 00:31:30,500
those in counterterrorism for instance

00:31:29,179 --> 00:31:32,480
so it's not a taboo that people have

00:31:30,500 --> 00:31:34,460
been thinking about that the other

00:31:32,480 --> 00:31:36,080
answer besides the who's doing the

00:31:34,460 --> 00:31:38,059
forensics been taking this problem

00:31:36,080 --> 00:31:39,919
seriously is a diplomatic answer right

00:31:38,059 --> 00:31:41,210
similarly to we don't really have

00:31:39,919 --> 00:31:42,889
candidates saying here's what we don't

00:31:41,210 --> 00:31:44,990
do we don't really have governments

00:31:42,889 --> 00:31:46,309
saying here's what we don't do in

00:31:44,990 --> 00:31:48,500
cyberspace

00:31:46,309 --> 00:31:49,940
there is something as norms right so you

00:31:48,500 --> 00:31:52,100
could totally see a government saying

00:31:49,940 --> 00:31:55,010
like hey by the way we will not use

00:31:52,100 --> 00:31:57,169
covert social media campaign in order to

00:31:55,010 --> 00:31:59,240
interfere in the democratic processes of

00:31:57,169 --> 00:32:01,190
other geopolitical allies or enemies

00:31:59,240 --> 00:32:02,690
that's not really a conversation we're

00:32:01,190 --> 00:32:05,269
hearing so I'm kind of like you know

00:32:02,690 --> 00:32:07,159
interested in in seeing who are the

00:32:05,269 --> 00:32:09,380
first connect nations who are going to

00:32:07,159 --> 00:32:10,940
be I'm saying this if you haven't

00:32:09,380 --> 00:32:13,360
watched Alex Gibney's documentary zero

00:32:10,940 --> 00:32:16,220
days which is about us and Israel's

00:32:13,360 --> 00:32:18,320
hacking of Iran to basically take over a

00:32:16,220 --> 00:32:20,360
power station what's so powerful about

00:32:18,320 --> 00:32:22,460
the documentary is that you see a kind

00:32:20,360 --> 00:32:24,289
of a computer-generated image of all of

00:32:22,460 --> 00:32:26,720
the NSA whistleblowers who basically

00:32:24,289 --> 00:32:28,190
said I know that my country has to think

00:32:26,720 --> 00:32:30,320
about these sorts of things but what

00:32:28,190 --> 00:32:32,450
concerns me is we have no playbook for

00:32:30,320 --> 00:32:33,710
this we have and if we're doing it what

00:32:32,450 --> 00:32:35,149
the hell is everybody else doing back to

00:32:33,710 --> 00:32:36,350
us and so the reason I think the

00:32:35,149 --> 00:32:38,539
documentary is interesting is it's

00:32:36,350 --> 00:32:40,399
simply saying what we can do with

00:32:38,539 --> 00:32:41,690
technology is so powerful and yet we

00:32:40,399 --> 00:32:42,919
haven't thought it through and so we

00:32:41,690 --> 00:32:45,710
have these conversations at these kind

00:32:42,919 --> 00:32:47,899
of calms about AI but in this space I

00:32:45,710 --> 00:32:49,429
just you know it's yeah and it's not I

00:32:47,899 --> 00:32:51,590
mean we're not be naive its how the

00:32:49,429 --> 00:32:52,789
world works but I just we're just not

00:32:51,590 --> 00:32:54,139
having those conversations and making a

00:32:52,789 --> 00:32:56,000
face cuz it's a two-hour long

00:32:54,139 --> 00:32:58,070
documentary about cyber warfare without

00:32:56,000 --> 00:33:02,480
a single woman in it yeah yeah

00:32:58,070 --> 00:33:03,740
true story like Belling cat joke um what

00:33:02,480 --> 00:33:05,809
was and the other question about Mike's

00:33:03,740 --> 00:33:07,580
talking so I also want to say this

00:33:05,809 --> 00:33:09,740
because what I think is fascinating is

00:33:07,580 --> 00:33:12,320
okay the movie the great hack or Netflix

00:33:09,740 --> 00:33:15,440
many of us have seen it it's not

00:33:12,320 --> 00:33:16,999
necessarily great all-time but you know

00:33:15,440 --> 00:33:19,939
what it did it got released on the same

00:33:16,999 --> 00:33:22,309
in 93 countries and it did more to get

00:33:19,939 --> 00:33:23,449
more people aware of the challenges of

00:33:22,309 --> 00:33:25,399
data and what that meant around

00:33:23,449 --> 00:33:27,019
marketing then anything else

00:33:25,399 --> 00:33:29,029
and apparently kind of like broke the

00:33:27,019 --> 00:33:30,739
Netflix algorithm and Netflix like how

00:33:29,029 --> 00:33:32,149
do we get people to like what should

00:33:30,739 --> 00:33:34,399
they do now because they were all hungry

00:33:32,149 --> 00:33:36,739
to do something and despite three years

00:33:34,399 --> 00:33:38,569
of convenings on this issue we have

00:33:36,739 --> 00:33:40,249
nothing to give the public we have

00:33:38,569 --> 00:33:43,069
nothing to say this is what you should

00:33:40,249 --> 00:33:44,419
do and so for me to your question if

00:33:43,069 --> 00:33:46,789
we're trying to get the mums of the

00:33:44,419 --> 00:33:48,919
world engaged is around data is around

00:33:46,789 --> 00:33:51,049
how that intersects with hate and

00:33:48,919 --> 00:33:52,579
disinformation and misinformation but I

00:33:51,049 --> 00:33:54,259
just I don't think that we've got beyond

00:33:52,579 --> 00:33:56,119
talking on panels which is why we should

00:33:54,259 --> 00:33:58,419
stop having these panels and actually

00:33:56,119 --> 00:34:01,549
come up with a tool set to actually give

00:33:58,419 --> 00:34:02,959
like contour tools to people to say this

00:34:01,549 --> 00:34:05,179
is what I should do when I suddenly

00:34:02,959 --> 00:34:07,249
learn about it and get angry so I think

00:34:05,179 --> 00:34:08,960
data and disinformation are really

00:34:07,249 --> 00:34:10,940
closely connected as ever in this space

00:34:08,960 --> 00:34:12,559
they tend to be different panels on

00:34:10,940 --> 00:34:14,210
different converses funded by different

00:34:12,559 --> 00:34:16,190
organizations and we don't talk to each

00:34:14,210 --> 00:34:17,839
other but really for me that's the sweet

00:34:16,190 --> 00:34:20,480
spot of how these two things should be

00:34:17,839 --> 00:34:22,129
working together nice well I think that

00:34:20,480 --> 00:34:24,409
will do one more question actually yeah

00:34:22,129 --> 00:34:27,289
I mean it is the last panel onto synth

00:34:24,409 --> 00:34:34,099
oh yeah last question of any

00:34:27,289 --> 00:34:36,409
disinformation panel thank you so I am

00:34:34,099 --> 00:34:41,210
running a workshop tomorrow designing a

00:34:36,409 --> 00:34:44,629
policy lab on deep fakes and it's two

00:34:41,210 --> 00:34:46,789
o'clock and I'm wondering if you can get

00:34:44,629 --> 00:34:48,649
us started by putting some ideas out

00:34:46,789 --> 00:34:53,629
there like how do you how do you tackle

00:34:48,649 --> 00:34:56,299
a problem like deep lakes teach everyone

00:34:53,629 --> 00:34:58,910
how to deep fake just that was seriously

00:34:56,299 --> 00:35:01,009
like you'll see it's it's easy it's

00:34:58,910 --> 00:35:03,410
quite fun as not as bad as people think

00:35:01,009 --> 00:35:07,220
it's kind of clunky and and just

00:35:03,410 --> 00:35:11,990
demystify it that's my I feel like I've

00:35:07,220 --> 00:35:13,519
just said out loud a terrible idea the

00:35:11,990 --> 00:35:14,240
best way to teach this information is to

00:35:13,519 --> 00:35:15,380
get people to come up with a

00:35:14,240 --> 00:35:16,789
disinformation campaign so I do you

00:35:15,380 --> 00:35:19,220
think you're on something good Vasiliy

00:35:16,789 --> 00:35:21,019
just don't put it on the Internet mercy

00:35:19,220 --> 00:35:21,799
read all the stuff that witness has done

00:35:21,019 --> 00:35:23,660
on this because they've done an

00:35:21,799 --> 00:35:25,970
incredible job of and they're working

00:35:23,660 --> 00:35:27,739
with activists globally around the deep

00:35:25,970 --> 00:35:29,690
fake conversation again is very us

00:35:27,739 --> 00:35:30,740
focused and so it must be a lot of white

00:35:29,690 --> 00:35:31,970
men in Silicon Valley

00:35:30,740 --> 00:35:33,530
talking about defects when actually if

00:35:31,970 --> 00:35:34,940
you you know they've done great work in

00:35:33,530 --> 00:35:37,430
places like Brazil you're like this is

00:35:34,940 --> 00:35:38,630
what we're terrified about might you

00:35:37,430 --> 00:35:40,310
know is already seeing some pretty

00:35:38,630 --> 00:35:41,630
problematic legislation around deep

00:35:40,310 --> 00:35:43,790
fakes because it's focused on the

00:35:41,630 --> 00:35:45,140
content and if we focus on content we're

00:35:43,790 --> 00:35:47,750
gonna end up taking out stuff like

00:35:45,140 --> 00:35:49,160
satire and other spaces that I think we

00:35:47,750 --> 00:35:51,560
are not necessarily thinking about now

00:35:49,160 --> 00:35:53,330
and so that that worries me and so it

00:35:51,560 --> 00:35:54,710
should really be about behaviors so

00:35:53,330 --> 00:35:56,900
whenever we're thinking about regulation

00:35:54,710 --> 00:35:58,490
in this space we've really got to how do

00:35:56,900 --> 00:35:59,990
we understand behaviors and the thing is

00:35:58,490 --> 00:36:01,700
that's hard because to Camille's point

00:35:59,990 --> 00:36:03,470
we focus on content because we can get

00:36:01,700 --> 00:36:04,790
access to that it's very difficult to

00:36:03,470 --> 00:36:05,840
understand behaviors because we can't

00:36:04,790 --> 00:36:07,460
get access to the data that the

00:36:05,840 --> 00:36:09,800
platforms have which would help us

00:36:07,460 --> 00:36:11,540
understand behaviors but I would say

00:36:09,800 --> 00:36:13,460
around deep fakes we need to be really

00:36:11,540 --> 00:36:14,570
careful it's a very sexy topic

00:36:13,460 --> 00:36:15,680
everything's wading in and saying oh

00:36:14,570 --> 00:36:18,080
that's something that we can easily

00:36:15,680 --> 00:36:20,480
regulate but I don't think it's as easy

00:36:18,080 --> 00:36:21,740
as we think it is and it's still very

00:36:20,480 --> 00:36:23,780
very early days in terms of the

00:36:21,740 --> 00:36:25,250
technology so my worry is that we

00:36:23,780 --> 00:36:26,660
regulate too early but at the same time

00:36:25,250 --> 00:36:28,430
we do have to recognize the fears but

00:36:26,660 --> 00:36:30,580
just all about the pool and anything can

00:36:28,430 --> 00:36:33,770
do about there that'd be great thanks

00:36:30,580 --> 00:36:36,020
all right I think that's it for us thank

00:36:33,770 --> 00:36:36,450
you guys Camille and Claire for joining

00:36:36,020 --> 00:36:39,850
me today

00:36:36,450 --> 00:36:39,850

YouTube URL: https://www.youtube.com/watch?v=K3I5fLHoB2w


