Title: MozFest 2019 - Great Code Great Responsibility
Publication date: 2019-11-04
Playlist: Mozilla Festival 2019
Description: 
	How do we fix the internet? Teach the next generation of coders ethics right alongside computer science

Kathy Pham
@kathytpham

Computer scientist and Mozilla Fellow co-leading the Responsible Computer Science Challenge. Kathy teaches Product Management and Society at the Harvard Kennedy School, co-leads the Ethical Tech Working Group at the Harvard Berkman Klein Center, and founded the Ethical Tech Collective.

Bitange Ndemo
@bantigito

ICT Specialist and Associate Professor at the University of Nairobi
Captions: 
	00:00:00,410 --> 00:00:06,299
hey guys welcome back to MOSFETs 2019

00:00:03,659 --> 00:00:08,069
the 10th anniversary also this month is

00:00:06,299 --> 00:00:08,940
London's Black History Month which is

00:00:08,069 --> 00:00:12,210
awesome

00:00:08,940 --> 00:00:14,340
so unfortunately Francesca Bria was

00:00:12,210 --> 00:00:15,929
going to have give a talk but she'll no

00:00:14,340 --> 00:00:18,830
longer can make it but you should still

00:00:15,929 --> 00:00:21,029
check out her project decode online

00:00:18,830 --> 00:00:23,269
instead we have a panel for you today

00:00:21,029 --> 00:00:27,660
called great code great responsibility

00:00:23,269 --> 00:00:28,740
including Kathy Pham and baton game demo

00:00:27,660 --> 00:00:32,390
so if you guys want to come on stage

00:00:28,740 --> 00:00:32,390
right now you got some game applause

00:00:32,420 --> 00:00:38,760
thanks for thanks for joining me thank

00:00:35,640 --> 00:00:39,210
you for joining me I'm just laying

00:00:38,760 --> 00:00:43,969
around

00:00:39,210 --> 00:00:46,020
okay so just introduce these guys Kathy

00:00:43,969 --> 00:00:48,930
previously worked at Google on the

00:00:46,020 --> 00:00:50,820
Google health team she also worked at

00:00:48,930 --> 00:00:53,430
the White House United States digital

00:00:50,820 --> 00:00:55,559
service currently though she's at

00:00:53,430 --> 00:00:57,270
Harvard's Kennedy School where she

00:00:55,559 --> 00:00:59,730
teaches a course on product management

00:00:57,270 --> 00:01:01,829
and society she's definitely qualified

00:00:59,730 --> 00:01:05,549
to talk about great responsibility she's

00:01:01,829 --> 00:01:07,080
also a mozilla fellow and in demo is a

00:01:05,549 --> 00:01:09,450
professor of entrepreneurship at

00:01:07,080 --> 00:01:12,510
University of Nairobi he's also chairman

00:01:09,450 --> 00:01:14,939
of distributed ledgers and AI he's also

00:01:12,510 --> 00:01:16,470
senior adviser to the UN and hears a lot

00:01:14,939 --> 00:01:17,820
other credentials what he told me don't

00:01:16,470 --> 00:01:21,150
even list them all because it's too many

00:01:17,820 --> 00:01:22,650
to name so I'll stop it right there but

00:01:21,150 --> 00:01:25,409
yeah I want to talk to you guys about

00:01:22,650 --> 00:01:27,659
the infamous you know spider-man quote

00:01:25,409 --> 00:01:30,450
great code great responsibility and I

00:01:27,659 --> 00:01:31,890
think just to kick it off you know when

00:01:30,450 --> 00:01:33,000
we talk about what's wrong on the

00:01:31,890 --> 00:01:36,590
internet today whether it be

00:01:33,000 --> 00:01:39,560
misinformation tracking bias algorithms

00:01:36,590 --> 00:01:43,110
some people suggest like policy fixes

00:01:39,560 --> 00:01:45,420
and like you know laws what do you guys

00:01:43,110 --> 00:01:49,560
advocate for how do we go about kind of

00:01:45,420 --> 00:01:52,740
fixing some of these things anyone can

00:01:49,560 --> 00:01:55,700
start by the way yes it is actually very

00:01:52,740 --> 00:01:58,530
difficult to say that policymakers alone

00:01:55,700 --> 00:02:03,810
can just sit down and do that I used to

00:01:58,530 --> 00:02:06,869
be in in policymaking and the way we did

00:02:03,810 --> 00:02:10,140
it was to enable innovation to take

00:02:06,869 --> 00:02:11,760
place and then we can look at which

00:02:10,140 --> 00:02:16,440
areas we can

00:02:11,760 --> 00:02:19,170
put some regulations even now as we work

00:02:16,440 --> 00:02:22,200
through AI and these are emerging

00:02:19,170 --> 00:02:25,760
technologies we're looking at how can we

00:02:22,200 --> 00:02:30,000
have legal sandboxes and build something

00:02:25,760 --> 00:02:33,390
because what what has happened when gdpr

00:02:30,000 --> 00:02:35,459
went through in Europe African

00:02:33,390 --> 00:02:42,330
governments began to shut down internet

00:02:35,459 --> 00:02:45,180
by raising putting laws like taxes or in

00:02:42,330 --> 00:02:48,780
social media and completely stifling

00:02:45,180 --> 00:02:53,250
innovation so there is a huge balance

00:02:48,780 --> 00:02:55,890
that we need to do to balance between

00:02:53,250 --> 00:03:00,500
innovation and the policy-making

00:02:55,890 --> 00:03:03,030
in this space I've always said that

00:03:00,500 --> 00:03:07,230
religion will be so boring if there was

00:03:03,030 --> 00:03:09,989
in Satan so a little bad is good a

00:03:07,230 --> 00:03:12,810
little bad as you're on the panel called

00:03:09,989 --> 00:03:16,049
great codes right yeah so Kathy do you

00:03:12,810 --> 00:03:18,090
want to talk about I I think we need

00:03:16,049 --> 00:03:21,120
it's an ecosystem right we need the

00:03:18,090 --> 00:03:22,650
policymakers we need the developers we

00:03:21,120 --> 00:03:24,959
need leadership we need the individual

00:03:22,650 --> 00:03:28,470
contributors I'm gonna circle back to

00:03:24,959 --> 00:03:32,180
the policy piece at the end I think of

00:03:28,470 --> 00:03:34,980
one the code we right now effect

00:03:32,180 --> 00:03:37,170
products that are deeply rooted in all

00:03:34,980 --> 00:03:38,880
of our lives we can't just say we build

00:03:37,170 --> 00:03:41,190
technology and maybe an impact society

00:03:38,880 --> 00:03:43,560
it's all like all the technology with a

00:03:41,190 --> 00:03:45,239
code we write impact all parts of

00:03:43,560 --> 00:03:46,620
society whether whether it goes in the

00:03:45,239 --> 00:03:49,709
airplanes that took you here to this

00:03:46,620 --> 00:03:51,750
event or the platforms that give you the

00:03:49,709 --> 00:03:53,730
information that we read a number of

00:03:51,750 --> 00:03:56,880
places and I think that's where as a

00:03:53,730 --> 00:03:58,079
computer scientist when we write code

00:03:56,880 --> 00:04:00,889
there's a lot of responsibility I

00:03:58,079 --> 00:04:03,359
recognizing how it's used but also I

00:04:00,889 --> 00:04:05,010
always go back to there's this book that

00:04:03,359 --> 00:04:06,510
a lot of people who study computer

00:04:05,010 --> 00:04:08,609
science or software engineers read I

00:04:06,510 --> 00:04:12,030
hate the title that it's called the

00:04:08,609 --> 00:04:13,590
mythical man-month and part of that

00:04:12,030 --> 00:04:15,389
there's a whole section there on why

00:04:13,590 --> 00:04:20,130
people get into software wiki because we

00:04:15,389 --> 00:04:22,650
like having a very a very malleable

00:04:20,130 --> 00:04:24,090
medium so like a not malleable medium is

00:04:22,650 --> 00:04:25,400
like a foundation for a house when you

00:04:24,090 --> 00:04:27,080
set the foundation it's really

00:04:25,400 --> 00:04:30,259
hard to change the foundation but with

00:04:27,080 --> 00:04:33,500
code you can change a variable you can

00:04:30,259 --> 00:04:35,570
change something in your code to say if

00:04:33,500 --> 00:04:37,190
number of prison sentences is greater

00:04:35,570 --> 00:04:38,539
than five do this pretty quickly and

00:04:37,190 --> 00:04:40,430
deploy the code out and it can change

00:04:38,539 --> 00:04:42,530
especially in the world with like cloud

00:04:40,430 --> 00:04:43,940
computing etc and so there's a lot of

00:04:42,530 --> 00:04:45,530
responsibility there because we work in

00:04:43,940 --> 00:04:47,509
a medium that's really easy to change

00:04:45,530 --> 00:04:48,949
and really quickly to change it when you

00:04:47,509 --> 00:04:51,500
can you can write code and have in front

00:04:48,949 --> 00:04:52,850
of people and in front of groups pretty

00:04:51,500 --> 00:04:55,490
readily and so there's so much

00:04:52,850 --> 00:04:59,840
responsibility there of what to think

00:04:55,490 --> 00:05:01,639
about how that happens and I think on

00:04:59,840 --> 00:05:03,380
the regulation piece we need people

00:05:01,639 --> 00:05:06,050
there also to help us think about when

00:05:03,380 --> 00:05:07,430
when we don't write our code well or

00:05:06,050 --> 00:05:09,350
impact societies in a ways that we don't

00:05:07,430 --> 00:05:10,850
understand there are other safeguards

00:05:09,350 --> 00:05:12,979
they are ever at least in the United

00:05:10,850 --> 00:05:15,229
States we don't have people in those

00:05:12,979 --> 00:05:17,750
positions who can make those write that

00:05:15,229 --> 00:05:20,300
in those policies very well yeah I mean

00:05:17,750 --> 00:05:22,370
I think about you know computer science

00:05:20,300 --> 00:05:23,930
education and the classroom level and

00:05:22,370 --> 00:05:27,320
you guys have both have worked in the

00:05:23,930 --> 00:05:29,750
classroom extensively what are some

00:05:27,320 --> 00:05:33,280
things that computer science education

00:05:29,750 --> 00:05:37,520
is getting right and also getting wrong

00:05:33,280 --> 00:05:41,050
well you can't say that we have a

00:05:37,520 --> 00:05:44,000
responsibility to inculcate culture in

00:05:41,050 --> 00:05:47,930
students at university level I always

00:05:44,000 --> 00:05:50,150
say that culture I mean ethics are is

00:05:47,930 --> 00:05:53,630
actually culture I mean where you grew

00:05:50,150 --> 00:05:56,300
up and how you are brought up so we all

00:05:53,630 --> 00:05:58,789
have responsibility as parents before

00:05:56,300 --> 00:06:00,889
you even talk at universe level of

00:05:58,789 --> 00:06:03,650
course the universities and corporates

00:06:00,889 --> 00:06:06,979
have a responsibility also in the sense

00:06:03,650 --> 00:06:10,750
that they can build an ESCO culture

00:06:06,979 --> 00:06:16,729
within that space and people begin to

00:06:10,750 --> 00:06:18,919
understand the role of ethics so part of

00:06:16,729 --> 00:06:20,389
mozilla we fund something called the

00:06:18,919 --> 00:06:22,070
responsible computer science challenge

00:06:20,389 --> 00:06:24,320
can you raise your hand in the room if

00:06:22,070 --> 00:06:25,909
you are part of that and then raise your

00:06:24,320 --> 00:06:28,430
hand if you're not hardly but you also

00:06:25,909 --> 00:06:30,740
teach ethics or responsibility and

00:06:28,430 --> 00:06:34,610
computing in some form or fashion we

00:06:30,740 --> 00:06:36,520
have some folks as well yeah it's and

00:06:34,610 --> 00:06:39,330
you mean York you're talking about

00:06:36,520 --> 00:06:44,790
education specifically

00:06:39,330 --> 00:06:46,950
I think a hundred percent culture I that

00:06:44,790 --> 00:06:48,540
we have this is culture I think we're at

00:06:46,950 --> 00:06:50,370
least in university we kind of separate

00:06:48,540 --> 00:06:52,280
out you can come to University you pick

00:06:50,370 --> 00:06:54,330
a field you study computer science or

00:06:52,280 --> 00:06:57,000
social science or anthropology or

00:06:54,330 --> 00:06:58,650
philosophy or something else and you go

00:06:57,000 --> 00:07:01,920
in your lane and you go do that really

00:06:58,650 --> 00:07:04,860
really well and I think how I've seen

00:07:01,920 --> 00:07:06,630
that manifest is now you have people who

00:07:04,860 --> 00:07:08,400
perhaps can scale a system and write

00:07:06,630 --> 00:07:10,170
really efficient code without much

00:07:08,400 --> 00:07:14,640
consideration for the societal impacts

00:07:10,170 --> 00:07:19,200
or how it impacts like the long history

00:07:14,640 --> 00:07:20,370
of race in the world etc and I think

00:07:19,200 --> 00:07:22,970
that's where we do have a shortcoming

00:07:20,370 --> 00:07:26,520
because you put people into lanes and

00:07:22,970 --> 00:07:27,840
not all universities do that but many do

00:07:26,520 --> 00:07:29,640
you put people on the lanes and we dealt

00:07:27,840 --> 00:07:31,920
with culture and then within those lanes

00:07:29,640 --> 00:07:34,140
we have hierarchies there are majors

00:07:31,920 --> 00:07:35,370
that are viewed as quote smarter or

00:07:34,140 --> 00:07:36,600
better than other majors sometimes

00:07:35,370 --> 00:07:38,850
that's because when you graduate you're

00:07:36,600 --> 00:07:40,410
paid significantly more and now you have

00:07:38,850 --> 00:07:42,510
a hierarchy of majors with people who've

00:07:40,410 --> 00:07:44,010
now been put into your lanes and that

00:07:42,510 --> 00:07:45,810
translates into the culture in the tech

00:07:44,010 --> 00:07:47,490
industry where you have engineering

00:07:45,810 --> 00:07:49,020
versus non engineering which is how some

00:07:47,490 --> 00:07:50,760
people are labeled in companies which is

00:07:49,020 --> 00:07:52,920
so problematic where software

00:07:50,760 --> 00:07:54,600
engineering versus support at other big

00:07:52,920 --> 00:07:57,510
tech companies I think the culture piece

00:07:54,600 --> 00:07:59,880
is a really big part of it and where I

00:07:57,510 --> 00:08:01,530
do think maybe there's a sliver hope

00:07:59,880 --> 00:08:03,120
there are a good number of people who go

00:08:01,530 --> 00:08:05,550
into technology field because they do

00:08:03,120 --> 00:08:07,020
want to change the world and perhaps the

00:08:05,550 --> 00:08:10,830
definition of what change the world

00:08:07,020 --> 00:08:12,660
means we can think about how to how to

00:08:10,830 --> 00:08:14,610
shift that yeah I want to hit on a few

00:08:12,660 --> 00:08:19,080
things you just mentioned because you

00:08:14,610 --> 00:08:21,510
mentioned how malleable code can be

00:08:19,080 --> 00:08:24,270
you're basically playing God when you're

00:08:21,510 --> 00:08:25,890
making certain products and then you

00:08:24,270 --> 00:08:28,320
also have people on the outside telling

00:08:25,890 --> 00:08:29,880
you you know you're you're the chosen

00:08:28,320 --> 00:08:31,260
one you're the smartest person here take

00:08:29,880 --> 00:08:33,960
the six-figure salary like you're the

00:08:31,260 --> 00:08:37,350
you're the person and you also mention

00:08:33,960 --> 00:08:39,210
the ways that race kind of can play into

00:08:37,350 --> 00:08:41,010
it I know only my own experience and

00:08:39,210 --> 00:08:43,830
journals and there's not a lot of like

00:08:41,010 --> 00:08:46,920
black people in general in newsrooms

00:08:43,830 --> 00:08:48,840
that I've been in so in a sense you know

00:08:46,920 --> 00:08:50,850
I feel a little humbled by like my own

00:08:48,840 --> 00:08:52,450
background and I'd imagine that's

00:08:50,850 --> 00:08:55,100
possibly true and

00:08:52,450 --> 00:08:56,900
could you speak to you know the effect

00:08:55,100 --> 00:08:58,100
of you know on the one side people

00:08:56,900 --> 00:08:59,630
telling you your chosen one you're the

00:08:58,100 --> 00:09:01,880
most partner person here but on the

00:08:59,630 --> 00:09:04,160
other side knowing that's who you are

00:09:01,880 --> 00:09:06,650
and your makeup kind of makes you never

00:09:04,160 --> 00:09:08,630
feel like you're as important as you

00:09:06,650 --> 00:09:11,480
should feel does I ever have like an

00:09:08,630 --> 00:09:15,160
effect on the things you make what kind

00:09:11,480 --> 00:09:18,980
of effect does that have at all like a

00:09:15,160 --> 00:09:21,710
reflection on like my life in 60 seconds

00:09:18,980 --> 00:09:23,660
you have to answer all of that yeah you

00:09:21,710 --> 00:09:25,610
me specifically or like the field of CS

00:09:23,660 --> 00:09:27,860
being told that it's the chosen one a

00:09:25,610 --> 00:09:30,080
little bit of both I mean yeah yeah so I

00:09:27,860 --> 00:09:31,520
think if it's just personal reflection

00:09:30,080 --> 00:09:32,750
it's yeah when you study at least in my

00:09:31,520 --> 00:09:35,210
universe and when you study computer

00:09:32,750 --> 00:09:36,500
science you know we had a prep meeting

00:09:35,210 --> 00:09:38,060
we were talking about how it's like oh

00:09:36,500 --> 00:09:39,230
you study computer science or

00:09:38,060 --> 00:09:41,900
engineering you must be really really

00:09:39,230 --> 00:09:43,820
smart or if like that person studied

00:09:41,900 --> 00:09:44,780
business no wonder they have time to go

00:09:43,820 --> 00:09:47,000
out on the weekends to the football

00:09:44,780 --> 00:09:49,310
games and it's such a reduced ridiculous

00:09:47,000 --> 00:09:51,380
framing of things that's not even true

00:09:49,310 --> 00:09:52,640
and that's not how the world works but

00:09:51,380 --> 00:09:55,910
you kind of told this over and over and

00:09:52,640 --> 00:09:58,670
over again and then you go into company

00:09:55,910 --> 00:10:00,950
and it carries on and your second part

00:09:58,670 --> 00:10:02,270
of your question was how well it's the

00:10:00,950 --> 00:10:04,910
second part of that well I'm asking you

00:10:02,270 --> 00:10:07,250
know how this idea that you know you you

00:10:04,910 --> 00:10:08,810
have this inflated ego but then you're a

00:10:07,250 --> 00:10:13,220
little humbled by the fact that you know

00:10:08,810 --> 00:10:15,770
you're not like hot-shit you know just

00:10:13,220 --> 00:10:17,090
like the duality of that versus like if

00:10:15,770 --> 00:10:18,530
someone doesn't have that what kinds of

00:10:17,090 --> 00:10:21,200
products as they create as how does it

00:10:18,530 --> 00:10:23,210
affect you know what they make I think I

00:10:21,200 --> 00:10:25,610
I posited I felt like I don't know if I

00:10:23,210 --> 00:10:27,410
ever had the inflated egos like you were

00:10:25,610 --> 00:10:30,350
told that and ural and I think because I

00:10:27,410 --> 00:10:31,790
came from a family of refugees to the

00:10:30,350 --> 00:10:34,280
country it was always for me like oh

00:10:31,790 --> 00:10:37,850
this might mean I can just now get a job

00:10:34,280 --> 00:10:40,190
that is like a normal American jobs that

00:10:37,850 --> 00:10:41,930
can support my family and I don't know

00:10:40,190 --> 00:10:44,750
if that sense of inflated ego was there

00:10:41,930 --> 00:10:47,450
it was more a we're told this field is

00:10:44,750 --> 00:10:50,840
really really great and now I can use

00:10:47,450 --> 00:10:52,550
these skill sets to since it seems like

00:10:50,840 --> 00:10:53,990
it's a really valuable skill set in the

00:10:52,550 --> 00:10:55,880
tech industry yeah and then demo

00:10:53,990 --> 00:10:57,890
anything you want how cocky are your

00:10:55,880 --> 00:10:59,540
students are they like telling you the

00:10:57,890 --> 00:11:02,180
answers like no you're wrong like have

00:10:59,540 --> 00:11:05,180
you seen any of that in students at your

00:11:02,180 --> 00:11:06,230
school have you seen that at all in your

00:11:05,180 --> 00:11:08,930
area

00:11:06,230 --> 00:11:11,120
always the wire the Hamill's you no

00:11:08,930 --> 00:11:13,850
matter what you you've studied I mean

00:11:11,120 --> 00:11:16,670
where you come from but when you come to

00:11:13,850 --> 00:11:19,460
the real world you find that things are

00:11:16,670 --> 00:11:23,030
completely different from what you

00:11:19,460 --> 00:11:26,720
thought they would be and that's what I

00:11:23,030 --> 00:11:28,790
can say with my students yeah I just

00:11:26,720 --> 00:11:30,350
thought of something right do you think

00:11:28,790 --> 00:11:33,140
the sense of humility does come in when

00:11:30,350 --> 00:11:34,760
you're like oh you're told that these

00:11:33,140 --> 00:11:36,140
skill sets are the most important skills

00:11:34,760 --> 00:11:38,360
that you need everyone to know how to

00:11:36,140 --> 00:11:40,220
code not me everyone to learn how to

00:11:38,360 --> 00:11:41,930
code these are the skill sets that are

00:11:40,220 --> 00:11:46,340
the highest paying the most important

00:11:41,930 --> 00:11:48,050
and then getting to collaborate with the

00:11:46,340 --> 00:11:49,550
social science scientists and the race

00:11:48,050 --> 00:11:51,920
and gender scholars and the people

00:11:49,550 --> 00:11:55,690
who've studied genocide in the world for

00:11:51,920 --> 00:11:57,920
decades and having them really surface

00:11:55,690 --> 00:11:59,270
what your technology could do in a

00:11:57,920 --> 00:12:01,430
region when you never thought about

00:11:59,270 --> 00:12:04,610
those consequences before become really

00:12:01,430 --> 00:12:06,320
incredibly powerful and really gets one

00:12:04,610 --> 00:12:07,640
thinking about oh my gosh how do we

00:12:06,320 --> 00:12:08,870
change the culture of our companies such

00:12:07,640 --> 00:12:10,550
that these kinds of conversations are

00:12:08,870 --> 00:12:12,890
really normal and make it to all the

00:12:10,550 --> 00:12:15,170
product development and design but if

00:12:12,890 --> 00:12:17,630
you see the in the code schools that we

00:12:15,170 --> 00:12:20,600
are having now which are non-traditional

00:12:17,630 --> 00:12:23,630
I mean the students who didn't go to

00:12:20,600 --> 00:12:26,960
college to do quote some of them are

00:12:23,630 --> 00:12:28,280
become so good that they humble those

00:12:26,960 --> 00:12:34,010
who have gone through the normal

00:12:28,280 --> 00:12:35,720
processes meaning that code is isn't

00:12:34,010 --> 00:12:39,050
what people used to think that you have

00:12:35,720 --> 00:12:42,260
to go to Howard somehow the crazy

00:12:39,050 --> 00:12:44,290
MIT to get it I know some of the best

00:12:42,260 --> 00:12:49,040
coders who never went to college

00:12:44,290 --> 00:12:50,930
they do the same I want to talk about

00:12:49,040 --> 00:12:52,580
something you mentioned earlier and it's

00:12:50,930 --> 00:12:54,920
it's something we talked about and I saw

00:12:52,580 --> 00:12:56,390
yesterday you mentioned at the top that

00:12:54,920 --> 00:12:57,530
you know ever there's always like a

00:12:56,390 --> 00:12:59,390
little bit of evil out there and the

00:12:57,530 --> 00:13:01,310
people who kind of make these things but

00:12:59,390 --> 00:13:04,430
then in contrast to that you've talked

00:13:01,310 --> 00:13:06,170
about before you know if you're working

00:13:04,430 --> 00:13:08,420
a tech company you may not always know

00:13:06,170 --> 00:13:09,770
the giant products you're working on you

00:13:08,420 --> 00:13:11,690
may just kind of be following orders I

00:13:09,770 --> 00:13:13,760
want to talk about the duality of good

00:13:11,690 --> 00:13:17,660
versus evil not in a superhero sense in

00:13:13,760 --> 00:13:20,120
a sense of people who want to do good

00:13:17,660 --> 00:13:23,120
people who want to do evil I don't

00:13:20,120 --> 00:13:24,199
exist and then also the idea that if

00:13:23,120 --> 00:13:26,050
you're working a tech company you may

00:13:24,199 --> 00:13:28,639
not even know what you're producing

00:13:26,050 --> 00:13:30,079
until the whole puzzle is formed in

00:13:28,639 --> 00:13:36,189
front of you he doesn't talk about that

00:13:30,079 --> 00:13:36,189
a little bit well I said yesterday that

00:13:37,809 --> 00:13:45,639
and I said it in the introduction that

00:13:40,100 --> 00:13:49,279
some evil is good in the sense that they

00:13:45,639 --> 00:13:52,879
the people who hack and then show you

00:13:49,279 --> 00:13:57,980
that you did nothing help you to build a

00:13:52,879 --> 00:14:01,249
better product and in code I think it's

00:13:57,980 --> 00:14:04,490
good that we continue to have problems

00:14:01,249 --> 00:14:06,970
because in entrepreneurship we say the

00:14:04,490 --> 00:14:10,730
best opportunity is the greatest problem

00:14:06,970 --> 00:14:13,370
get the problem solve it and move

00:14:10,730 --> 00:14:16,309
forward without having those problems

00:14:13,370 --> 00:14:20,839
you wouldn't have the whole industry of

00:14:16,309 --> 00:14:22,850
security and that's why I say that you

00:14:20,839 --> 00:14:25,399
have created that whole cyber security

00:14:22,850 --> 00:14:28,670
industry because of fear that someone

00:14:25,399 --> 00:14:32,629
would would break through and be able to

00:14:28,670 --> 00:14:35,779
do evil so sometimes it plays a big role

00:14:32,629 --> 00:14:37,689
in terms of improving our product yeah

00:14:35,779 --> 00:14:41,209
there's there's so many layers to this

00:14:37,689 --> 00:14:43,040
to me and I think it's important to have

00:14:41,209 --> 00:14:45,399
the developers or the people just in

00:14:43,040 --> 00:14:47,689
companies that the change was to think

00:14:45,399 --> 00:14:49,009
critically to ask questions I'm because

00:14:47,689 --> 00:14:51,470
there's so many layers so there's for me

00:14:49,009 --> 00:14:52,610
the the good and evil but in order if

00:14:51,470 --> 00:14:55,069
there's a group of people who generally

00:14:52,610 --> 00:14:56,809
believe we're doing good but our

00:14:55,069 --> 00:14:58,429
training has just been in such a way

00:14:56,809 --> 00:15:00,139
where we don't recognize when we're

00:14:58,429 --> 00:15:01,370
doing evil and so you're like that's

00:15:00,139 --> 00:15:02,240
like different kind of derry-o change

00:15:01,370 --> 00:15:03,800
we're like these people are already

00:15:02,240 --> 00:15:06,679
thinking they're doing good and they

00:15:03,800 --> 00:15:08,629
want to but they're just not versus the

00:15:06,679 --> 00:15:10,309
people that are like I only care about

00:15:08,629 --> 00:15:11,870
making money I only care about the

00:15:10,309 --> 00:15:13,459
technical aspects I don't care about

00:15:11,870 --> 00:15:15,499
anything else I only want to scale the

00:15:13,459 --> 00:15:16,610
system to be the fastest system that I

00:15:15,499 --> 00:15:18,980
can possibly build and that's like a

00:15:16,610 --> 00:15:20,360
different kind of group as well and they

00:15:18,980 --> 00:15:22,490
may be doing evil too but like it's

00:15:20,360 --> 00:15:24,800
because they don't care about society

00:15:22,490 --> 00:15:27,259
issues and you need to and they're like

00:15:24,800 --> 00:15:28,759
the you know code is neutral base and

00:15:27,259 --> 00:15:30,079
then you also have people you mentioned

00:15:28,759 --> 00:15:31,160
you know sometimes you're building

00:15:30,079 --> 00:15:33,260
something but you don't know the big

00:15:31,160 --> 00:15:35,270
picture until later and that

00:15:33,260 --> 00:15:36,860
that's also complicating you have

00:15:35,270 --> 00:15:38,180
different size companies like small tech

00:15:36,860 --> 00:15:39,230
companies where you actually know what's

00:15:38,180 --> 00:15:41,210
going on and you have the much bigger

00:15:39,230 --> 00:15:43,970
companies where for example no single

00:15:41,210 --> 00:15:45,530
person most single people don't know how

00:15:43,970 --> 00:15:48,080
all of Google search works for example

00:15:45,530 --> 00:15:50,930
it's like like the Coca Cola recipe you

00:15:48,080 --> 00:15:53,210
just don't really really know so there's

00:15:50,930 --> 00:15:55,850
different layers of that too

00:15:53,210 --> 00:15:57,380
but and one last thing is there's a Book

00:15:55,850 --> 00:16:00,260
now called IBM in the Holocaust that

00:15:57,380 --> 00:16:03,230
many people now know and there's like a

00:16:00,260 --> 00:16:05,180
different lens there where if you we

00:16:03,230 --> 00:16:07,010
often talk about consumer type companies

00:16:05,180 --> 00:16:08,150
or ones that create products that go

00:16:07,010 --> 00:16:09,890
directly to you and also these

00:16:08,150 --> 00:16:13,160
business-to-business companies where

00:16:09,890 --> 00:16:15,650
they develop products and it's sold to a

00:16:13,160 --> 00:16:17,120
certain entity we're seeing that now

00:16:15,650 --> 00:16:18,590
right with the US government not just

00:16:17,120 --> 00:16:19,490
you guys but companies build

00:16:18,590 --> 00:16:20,900
technologies that get sold to

00:16:19,490 --> 00:16:23,890
governments and we have to figure out

00:16:20,900 --> 00:16:27,620
what that means for us for all of us and

00:16:23,890 --> 00:16:28,730
and so you and that's a different kind

00:16:27,620 --> 00:16:30,440
of control because like you built

00:16:28,730 --> 00:16:31,970
something and now it's sold and

00:16:30,440 --> 00:16:33,980
depending on who it's sold to it's used

00:16:31,970 --> 00:16:37,430
in different ways so there's just lots

00:16:33,980 --> 00:16:38,630
of layers yeah I mean yeah one thing you

00:16:37,430 --> 00:16:40,160
were mentioning for our code is neutral

00:16:38,630 --> 00:16:42,920
and Dan well yesterday you were telling

00:16:40,160 --> 00:16:44,870
me about this this hand dryer which only

00:16:42,920 --> 00:16:46,760
recognized white hands which seems like

00:16:44,870 --> 00:16:47,390
a huge oversight when it's put out into

00:16:46,760 --> 00:16:49,730
the world

00:16:47,390 --> 00:16:51,380
I guess people making it didn't do it on

00:16:49,730 --> 00:16:53,270
purpose just kind of never came up is

00:16:51,380 --> 00:16:56,900
that an area where code is neutral is

00:16:53,270 --> 00:17:00,020
that an area where it's just everywhere

00:16:56,900 --> 00:17:03,350
there's bias even in this room there is

00:17:00,020 --> 00:17:05,770
bias and we should when we create code

00:17:03,350 --> 00:17:10,160
we should know that there is bias

00:17:05,770 --> 00:17:12,140
perhaps the person who trained who did

00:17:10,160 --> 00:17:16,450
the machine learning for the code for

00:17:12,140 --> 00:17:20,060
the dryer did it inadvertently or

00:17:16,450 --> 00:17:24,140
deliberately that it was only going to

00:17:20,060 --> 00:17:26,600
drive white hand or the person had white

00:17:24,140 --> 00:17:30,770
hands and that's what they used to train

00:17:26,600 --> 00:17:35,120
it so I would say biases all over the

00:17:30,770 --> 00:17:38,480
place and the best thing on this subject

00:17:35,120 --> 00:17:40,670
is actually we create more awareness so

00:17:38,480 --> 00:17:43,460
that you actually know that there is

00:17:40,670 --> 00:17:44,870
bias and correct the bias I think that's

00:17:43,460 --> 00:17:46,820
actually a great point to creating a

00:17:44,870 --> 00:17:49,640
culture I don't think we have this yet

00:17:46,820 --> 00:17:51,230
where this exists in the technical side

00:17:49,640 --> 00:17:54,020
of the house where the moment you

00:17:51,230 --> 00:17:56,390
recognize a problem there's on the tire

00:17:54,020 --> 00:17:58,370
like DevOps or SRE team of tech

00:17:56,390 --> 00:18:00,290
companies to recognize a problem and

00:17:58,370 --> 00:18:01,790
like they swarm on it and you reverse

00:18:00,290 --> 00:18:03,380
the problem like true for the most part

00:18:01,790 --> 00:18:04,940
most of the platforms you're on w oligo

00:18:03,380 --> 00:18:05,330
down but people are hacking it all the

00:18:04,940 --> 00:18:06,920
time

00:18:05,330 --> 00:18:08,360
but it's because there's a whole team

00:18:06,920 --> 00:18:09,740
that will swarm on it to turn rather

00:18:08,360 --> 00:18:11,780
than write a whole post-mortem on it and

00:18:09,740 --> 00:18:13,490
they fix it and we don't even have to

00:18:11,780 --> 00:18:17,390
have that we don't really have that yet

00:18:13,490 --> 00:18:18,950
for a more societal kind of issues and

00:18:17,390 --> 00:18:20,360
then on like the Vice he's bringing it

00:18:18,950 --> 00:18:22,550
down to the code level I was having a

00:18:20,360 --> 00:18:24,230
conversation a few weeks ago with folks

00:18:22,550 --> 00:18:26,270
of when you're writing : let's say you

00:18:24,230 --> 00:18:28,340
make decisions like I'm gonna make

00:18:26,270 --> 00:18:31,310
gender just like a boolean field which

00:18:28,340 --> 00:18:32,660
is like a binary on or off field because

00:18:31,310 --> 00:18:33,860
that's what I view it as and like later

00:18:32,660 --> 00:18:35,390
on is much harder to change because

00:18:33,860 --> 00:18:37,520
you're like what you Andrew only two

00:18:35,390 --> 00:18:40,400
things or like what if your feels like

00:18:37,520 --> 00:18:42,350
your array for for like skin tones is

00:18:40,400 --> 00:18:43,970
like for you just like make it look the

00:18:42,350 --> 00:18:44,630
length of four or something cuz like

00:18:43,970 --> 00:18:46,040
that's what you think

00:18:44,630 --> 00:18:47,420
and then like later on you don't really

00:18:46,040 --> 00:18:48,620
need to change it now yeah your ability

00:18:47,420 --> 00:18:50,390
to recognize like four levels of skin

00:18:48,620 --> 00:18:51,860
tones or something and so like there are

00:18:50,390 --> 00:18:54,140
all these decisions I think that's where

00:18:51,860 --> 00:18:55,340
for me a great code great responsibility

00:18:54,140 --> 00:18:56,570
where you're making all these small

00:18:55,340 --> 00:18:58,970
decisions when you're writing the code

00:18:56,570 --> 00:19:02,060
the ultimately effect a really really

00:18:58,970 --> 00:19:03,800
big picture yeah yeah yeah I mean that

00:19:02,060 --> 00:19:05,450
boolean true/false example is a great

00:19:03,800 --> 00:19:08,000
one and well you mentioned before you

00:19:05,450 --> 00:19:10,640
mentioned before Cathy about the swarms

00:19:08,000 --> 00:19:12,560
of team who will like parachute in to

00:19:10,640 --> 00:19:14,480
fix the problem like I think about the

00:19:12,560 --> 00:19:16,610
time where Google had that search

00:19:14,480 --> 00:19:18,950
they've had a few search mistakes but

00:19:16,610 --> 00:19:20,450
one was like my car was stolen by white

00:19:18,950 --> 00:19:21,800
people and then the suggestion was did

00:19:20,450 --> 00:19:23,570
you mean your car was stolen by black

00:19:21,800 --> 00:19:25,280
people and it's just definitely the

00:19:23,570 --> 00:19:26,780
oversight no one did it on purpose but

00:19:25,280 --> 00:19:30,500
they quickly change that because it's

00:19:26,780 --> 00:19:32,420
super racist but have you can you think

00:19:30,500 --> 00:19:34,550
of any times where something was blatant

00:19:32,420 --> 00:19:38,900
but they no one swooped in quickly to

00:19:34,550 --> 00:19:41,170
solve it I mean sorry for johnson is

00:19:38,900 --> 00:19:45,770
sitting on the spot but in general i

00:19:41,170 --> 00:19:47,090
feel like that all the time yes and on

00:19:45,770 --> 00:19:48,560
the platform companies are just in

00:19:47,090 --> 00:19:49,880
general high tech products or platform

00:19:48,560 --> 00:19:51,500
companies i think like the hand-dryer

00:19:49,880 --> 00:19:54,320
example is just like okay that's clearly

00:19:51,500 --> 00:19:56,930
like I almost have trouble seeing

00:19:54,320 --> 00:19:58,670
someone's like racing to fix it just

00:19:56,930 --> 00:19:59,920
feels like sometimes AI problems like

00:19:58,670 --> 00:20:00,820
that

00:19:59,920 --> 00:20:03,490
some people don't want to admit that

00:20:00,820 --> 00:20:04,630
they had biases there I wanted to spend

00:20:03,490 --> 00:20:06,610
on your question which is I think there

00:20:04,630 --> 00:20:08,290
are some things let's just take platform

00:20:06,610 --> 00:20:11,230
companies for example that have been

00:20:08,290 --> 00:20:12,850
really blatant for certain communities

00:20:11,230 --> 00:20:15,760
let's see bullying on Twitter for

00:20:12,850 --> 00:20:17,980
example and it's blatant to some

00:20:15,760 --> 00:20:19,960
communities and it took it effecting a

00:20:17,980 --> 00:20:21,550
much bigger community or maybe the more

00:20:19,960 --> 00:20:24,250
privileged community for the company to

00:20:21,550 --> 00:20:25,360
pay attention so I think the blatant

00:20:24,250 --> 00:20:27,490
question is sometimes yeah there are

00:20:25,360 --> 00:20:28,990
people who have been affected by it for

00:20:27,490 --> 00:20:31,120
a long time but it took some kind of

00:20:28,990 --> 00:20:33,280
uproar took people really pointed out or

00:20:31,120 --> 00:20:35,020
even like someone's off dead to really

00:20:33,280 --> 00:20:37,390
get the company to pay attention and

00:20:35,020 --> 00:20:38,980
sometimes it also takes affecting the

00:20:37,390 --> 00:20:40,390
privileged population before their

00:20:38,980 --> 00:20:41,860
whereas you're like people we've been

00:20:40,390 --> 00:20:44,770
affected by this for years and now

00:20:41,860 --> 00:20:46,540
you're paying attention yeah and then

00:20:44,770 --> 00:20:48,670
another thing I want to get back to with

00:20:46,540 --> 00:20:50,680
the hand dryer is just so crazy to me

00:20:48,670 --> 00:20:52,750
one thing IV talked about in the last

00:20:50,680 --> 00:20:55,450
panel and something I think about a lot

00:20:52,750 --> 00:20:57,310
is this idea that we're just doomed to

00:20:55,450 --> 00:21:01,030
repeat the same problems over and over

00:20:57,310 --> 00:21:03,730
again with new toys so you know in the

00:21:01,030 --> 00:21:05,410
50s United States Jim Crow laws met you

00:21:03,730 --> 00:21:07,240
know black people couldn't use this

00:21:05,410 --> 00:21:09,070
certain bathroom to certain water

00:21:07,240 --> 00:21:10,480
fountains certain hand dryer and then

00:21:09,070 --> 00:21:11,770
now it seems like that problem has

00:21:10,480 --> 00:21:14,170
resurfaced not because there's a law

00:21:11,770 --> 00:21:15,730
says it because the text says no are we

00:21:14,170 --> 00:21:19,150
just doomed to repeat our problems

00:21:15,730 --> 00:21:20,470
forever with like in regardless of my

00:21:19,150 --> 00:21:22,750
regards but regardless of you know what

00:21:20,470 --> 00:21:24,370
technology what laws everything are we

00:21:22,750 --> 00:21:27,280
just doing to repeat these problems

00:21:24,370 --> 00:21:32,050
forever it's a pretty heavy question I

00:21:27,280 --> 00:21:34,000
think this is a challenge that we we

00:21:32,050 --> 00:21:37,020
must constantly build a capacity to

00:21:34,000 --> 00:21:40,030
notice such things and correct them

00:21:37,020 --> 00:21:43,510
whereas in the past it was more obvious

00:21:40,030 --> 00:21:46,150
that you could see code has changed it

00:21:43,510 --> 00:21:49,150
and that's why I keep on saying that we

00:21:46,150 --> 00:21:51,700
must build substantial capacity to be

00:21:49,150 --> 00:21:55,660
able to know that there is bias here and

00:21:51,700 --> 00:21:57,670
we can correct it since you mentioned

00:21:55,660 --> 00:22:02,950
Jim Crow I'm going to call out dr. ruja

00:21:57,670 --> 00:22:06,880
Benjamin and her new her she has framed

00:22:02,950 --> 00:22:08,620
the term the new Jim Code so for us as

00:22:06,880 --> 00:22:13,180
we think about race and technology and

00:22:08,620 --> 00:22:16,030
how technology and code affect race

00:22:13,180 --> 00:22:20,010
I don't have a good answers beyond and

00:22:16,030 --> 00:22:22,240
some in many ways code can just amplify

00:22:20,010 --> 00:22:25,390
society and we just have to recognize

00:22:22,240 --> 00:22:26,710
that as we write code versus a I'll just

00:22:25,390 --> 00:22:30,160
put my blinders on and write code and

00:22:26,710 --> 00:22:32,770
like however society uses it so be it

00:22:30,160 --> 00:22:34,450
I don't think that code can't change

00:22:32,770 --> 00:22:36,730
society either I think it can as well

00:22:34,450 --> 00:22:39,460
but it also amplifies it and just this

00:22:36,730 --> 00:22:42,160
recognition when we write code to know

00:22:39,460 --> 00:22:45,130
that we should take all of that into

00:22:42,160 --> 00:22:47,820
consideration yeah you're actually a lot

00:22:45,130 --> 00:22:52,180
of quote especially in the recruitment

00:22:47,820 --> 00:22:54,690
where the recruitment completely ignores

00:22:52,180 --> 00:23:01,600
women or gives them different whatever

00:22:54,690 --> 00:23:04,360
or in several ways the sense of problems

00:23:01,600 --> 00:23:07,840
we have in society have been transferred

00:23:04,360 --> 00:23:12,160
into code and the most important thing

00:23:07,840 --> 00:23:13,920
is that before company uses the code for

00:23:12,160 --> 00:23:18,190
recruitment

00:23:13,920 --> 00:23:21,820
it must be vetted to to ensure that all

00:23:18,190 --> 00:23:25,150
the issues gender whatnot is taken care

00:23:21,820 --> 00:23:26,590
of yeah this is the last question this

00:23:25,150 --> 00:23:28,720
is actually kind of looking to a future

00:23:26,590 --> 00:23:30,700
panel that we'll have tomorrow but

00:23:28,720 --> 00:23:31,810
should it be on the government to do the

00:23:30,700 --> 00:23:33,280
vetting or should it be on the company

00:23:31,810 --> 00:23:36,880
to do the vetting or both or like a

00:23:33,280 --> 00:23:39,850
third party separately worked for

00:23:36,880 --> 00:23:41,340
government and I wouldn't give it to

00:23:39,850 --> 00:23:43,049
government

00:23:41,340 --> 00:23:46,650
[Music]

00:23:43,049 --> 00:23:48,789
there is what we call multi-stakeholder

00:23:46,650 --> 00:23:51,120
arrangements where you bring multiple

00:23:48,789 --> 00:23:53,620
people to come and look at something

00:23:51,120 --> 00:23:56,890
government would smile and use it for

00:23:53,620 --> 00:24:01,600
other purposes which which are more

00:23:56,890 --> 00:24:03,789
complex than when I can say yeah now all

00:24:01,600 --> 00:24:05,830
of us say it's it's I think it's all

00:24:03,789 --> 00:24:07,630
it's government and as tech companies

00:24:05,830 --> 00:24:11,799
and it's different levels in the tech

00:24:07,630 --> 00:24:13,659
company on the government side we go

00:24:11,799 --> 00:24:17,169
back to we don't have the people in

00:24:13,659 --> 00:24:19,240
government the same people who are you

00:24:17,169 --> 00:24:20,470
know building the technologies there's

00:24:19,240 --> 00:24:21,549
not the same level of skill set of

00:24:20,470 --> 00:24:24,460
understanding in the technology and

00:24:21,549 --> 00:24:25,990
government to to regulate what the type

00:24:24,460 --> 00:24:28,059
of nuance I think that's needed and then

00:24:25,990 --> 00:24:30,130
in addition to regulation how the laws

00:24:28,059 --> 00:24:32,620
and policies are enforced I think is

00:24:30,130 --> 00:24:34,720
actually a much more important part

00:24:32,620 --> 00:24:36,490
where you might have a policy out there

00:24:34,720 --> 00:24:39,100
but how it's actually enforced we need

00:24:36,490 --> 00:24:42,580
the people around who can do that and

00:24:39,100 --> 00:24:43,929
people who make meaningful policies and

00:24:42,580 --> 00:24:48,340
haven't make sense

00:24:43,929 --> 00:24:50,470
not just like some new line in in a law

00:24:48,340 --> 00:24:53,350
firm that's like AI cannot be biased

00:24:50,470 --> 00:24:55,570
like what does that even mean and and

00:24:53,350 --> 00:24:59,890
understand the nuance of what that is so

00:24:55,570 --> 00:25:02,169
you can really enforce that plus we also

00:24:59,890 --> 00:25:04,510
can't just wait for you and even if they

00:25:02,169 --> 00:25:06,309
let's say they regulate us where's the

00:25:04,510 --> 00:25:09,970
skill set to understand like how you fix

00:25:06,309 --> 00:25:11,730
your product right so so we also need

00:25:09,970 --> 00:25:14,260
the people in the companies to

00:25:11,730 --> 00:25:16,659
understand how to build more responsible

00:25:14,260 --> 00:25:19,090
better better products through some

00:25:16,659 --> 00:25:22,120
version of internal regulation top up

00:25:19,090 --> 00:25:23,409
bottom down users everyone in the

00:25:22,120 --> 00:25:24,909
ecosystem they used to work in

00:25:23,409 --> 00:25:27,130
government - so you're both are saying I

00:25:24,909 --> 00:25:27,940
worked in government not government just

00:25:27,130 --> 00:25:29,530
give it to the people

00:25:27,940 --> 00:25:32,110
no no nothing I didn't say not

00:25:29,530 --> 00:25:33,490
government I think government has a role

00:25:32,110 --> 00:25:34,960
in this I think regulation has a goal in

00:25:33,490 --> 00:25:36,490
this whether or not people are pro or

00:25:34,960 --> 00:25:39,070
against GDP are and how effective it is

00:25:36,490 --> 00:25:40,210
it's there and it sends us up at the

00:25:39,070 --> 00:25:43,059
very least it sends a signal that

00:25:40,210 --> 00:25:44,500
there's a thing that requires you to be

00:25:43,059 --> 00:25:45,760
a little bit more responsible or at

00:25:44,500 --> 00:25:47,380
least like let me know that cookies are

00:25:45,760 --> 00:25:49,030
on my site like I think there's at least

00:25:47,380 --> 00:25:51,360
like it's a starting point I think

00:25:49,030 --> 00:25:55,000
government a hundred percent has a role

00:25:51,360 --> 00:25:55,690
and can be very powerful I think this is

00:25:55,000 --> 00:25:57,129
one the short

00:25:55,690 --> 00:25:58,559
we just don't always have the tech

00:25:57,129 --> 00:26:00,700
skillsets and that's something

00:25:58,559 --> 00:26:02,620
governments across the world are

00:26:00,700 --> 00:26:04,750
grappling with my capacity and

00:26:02,620 --> 00:26:06,519
government was more just in the United

00:26:04,750 --> 00:26:08,740
States we build the United States

00:26:06,519 --> 00:26:09,820
digital service people had been thinking

00:26:08,740 --> 00:26:12,490
about bringing tech skills into

00:26:09,820 --> 00:26:14,559
government for years and then one year

00:26:12,490 --> 00:26:16,690
healthcare.gov failed and that was kind

00:26:14,559 --> 00:26:18,129
of an impetus to bring more

00:26:16,690 --> 00:26:20,169
technologists in government and it was

00:26:18,129 --> 00:26:21,789
folks came in to specifically work on

00:26:20,169 --> 00:26:23,740
social service issues but because you

00:26:21,789 --> 00:26:25,870
were in the room they were asked to

00:26:23,740 --> 00:26:28,000
advise on things with policy and like

00:26:25,870 --> 00:26:31,450
executive orders and you know different

00:26:28,000 --> 00:26:33,149
things like that so I hundred percent

00:26:31,450 --> 00:26:36,669
think government has a role in this I

00:26:33,149 --> 00:26:41,139
say in the fullness of time technology

00:26:36,669 --> 00:26:44,500
finds solutions to problems if you see

00:26:41,139 --> 00:26:47,259
fake media they are imagining software's

00:26:44,500 --> 00:26:51,220
which would actually tell you that this

00:26:47,259 --> 00:26:54,759
is fake media when we go for policy to

00:26:51,220 --> 00:26:57,370
correct problems in technology it

00:26:54,759 --> 00:26:59,799
usually happened too early before the

00:26:57,370 --> 00:27:03,090
whole development is done and out of

00:26:59,799 --> 00:27:07,139
frustration that all this is happening

00:27:03,090 --> 00:27:11,649
even in places where we are the problem

00:27:07,139 --> 00:27:13,600
if you look at the what is available

00:27:11,649 --> 00:27:17,200
online it's something that we have put

00:27:13,600 --> 00:27:21,759
there voluntarily and not what has been

00:27:17,200 --> 00:27:24,129
collected by the government or some of

00:27:21,759 --> 00:27:27,299
the companies so we are our worst

00:27:24,129 --> 00:27:29,169
enemies when it comes to online but

00:27:27,299 --> 00:27:32,350
whenever there is something that

00:27:29,169 --> 00:27:34,149
requires correction I think it gives a

00:27:32,350 --> 00:27:37,179
challenge that another company would

00:27:34,149 --> 00:27:40,570
come and create a solution out of it and

00:27:37,179 --> 00:27:45,429
it usually happens but when we go for

00:27:40,570 --> 00:27:47,620
policy we kill the whole thing all right

00:27:45,429 --> 00:27:50,259
well that's all questions for me if the

00:27:47,620 --> 00:27:50,830
audience has any Q&A questions oh so

00:27:50,259 --> 00:27:52,299
right there

00:27:50,830 --> 00:27:57,429
I think we have a microphone just come

00:27:52,299 --> 00:28:00,639
to you right now hi I love the idea of

00:27:57,429 --> 00:28:02,980
having infusing ethics into code but I'm

00:28:00,639 --> 00:28:04,929
wondering also if there should be some

00:28:02,980 --> 00:28:06,519
kind of partnership between the people

00:28:04,929 --> 00:28:07,940
who set the user requirements in the

00:28:06,519 --> 00:28:10,129
strategic direction of either the

00:28:07,940 --> 00:28:12,049
function or the enterprise which then

00:28:10,129 --> 00:28:13,850
means to me you have to have infused

00:28:12,049 --> 00:28:16,519
ethics across all disciplines that

00:28:13,850 --> 00:28:18,200
ultimately affect code how do you guys

00:28:16,519 --> 00:28:22,549
feel about doing something like that

00:28:18,200 --> 00:28:24,070
infusing it across all disciplines we

00:28:22,549 --> 00:28:27,889
are actually seeing a lot more

00:28:24,070 --> 00:28:32,389
collaborations a lot more people talking

00:28:27,889 --> 00:28:35,120
about multi stakeholder approach to

00:28:32,389 --> 00:28:37,100
developing some solutions and I think

00:28:35,120 --> 00:28:40,009
that is what would be more effective

00:28:37,100 --> 00:28:43,039
than the current processes that we are

00:28:40,009 --> 00:28:46,730
doing I think that there's work in that

00:28:43,039 --> 00:28:47,899
space now where it's yes to infuse

00:28:46,730 --> 00:28:51,049
Ithaca response to across our

00:28:47,899 --> 00:28:52,639
disciplines and yes to giving other

00:28:51,049 --> 00:28:54,320
disciplines that are not computer

00:28:52,639 --> 00:28:55,669
science dispersed and some on some level

00:28:54,320 --> 00:28:56,960
understanding of computer science our

00:28:55,669 --> 00:29:01,100
code such that when they're thinking

00:28:56,960 --> 00:29:02,480
about law issues or human rights issues

00:29:01,100 --> 00:29:04,789
there's also an understanding how code

00:29:02,480 --> 00:29:07,220
fits into that I think is also really

00:29:04,789 --> 00:29:10,639
important and I think also back to like

00:29:07,220 --> 00:29:14,330
how we're all in our own lanes some of

00:29:10,639 --> 00:29:17,210
the ethics conversations I think for me

00:29:14,330 --> 00:29:19,700
are also just social and race and

00:29:17,210 --> 00:29:20,629
justice conversations and not ethics of

00:29:19,700 --> 00:29:22,460
them maybe the traditional like

00:29:20,629 --> 00:29:23,960
philosophy sense so even just bringing

00:29:22,460 --> 00:29:26,960
the people who study those things

00:29:23,960 --> 00:29:28,429
together with the tech people that kind

00:29:26,960 --> 00:29:30,309
of is like thinking about tech in like

00:29:28,429 --> 00:29:33,259
an ethical way even without those words

00:29:30,309 --> 00:29:35,860
and so yes an agreement to you

00:29:33,259 --> 00:29:35,860
everything you said

00:29:39,460 --> 00:29:45,340
hello I've been thinking a lot about

00:29:42,399 --> 00:29:48,820
unions lately do you think that some

00:29:45,340 --> 00:29:50,470
sort of unions labor unions Tech labor

00:29:48,820 --> 00:29:52,659
unions do you think that something like

00:29:50,470 --> 00:29:59,679
that could play a role in providing a

00:29:52,659 --> 00:30:05,350
check and balance on ethics actually yes

00:29:59,679 --> 00:30:08,230
it's important I was watching the u.s.

00:30:05,350 --> 00:30:11,169
debate and I think is Elizabeth Warren

00:30:08,230 --> 00:30:13,169
who brought the issue and says she's

00:30:11,169 --> 00:30:17,380
going to have responsible capitalism

00:30:13,169 --> 00:30:21,039
where the unions would be part of the

00:30:17,380 --> 00:30:24,520
board that would be very key in the

00:30:21,039 --> 00:30:27,549
sense that when they introduced like a

00:30:24,520 --> 00:30:31,809
recruitment software the unions would

00:30:27,549 --> 00:30:35,200
vet and see what biases does it have and

00:30:31,809 --> 00:30:39,070
then corrected before it is used I think

00:30:35,200 --> 00:30:41,440
it's important that we take that from

00:30:39,070 --> 00:30:44,830
responsible capitalism to responsible

00:30:41,440 --> 00:30:49,179
code and provide some solutions that add

00:30:44,830 --> 00:30:51,399
that feet yeah I think unions are very

00:30:49,179 --> 00:30:53,890
power we're seeing now employees

00:30:51,399 --> 00:30:58,510
speaking up attack workers coalition etc

00:30:53,890 --> 00:31:01,840
I also think it's important that the

00:30:58,510 --> 00:31:03,220
unions are not just like the software

00:31:01,840 --> 00:31:04,750
engineers are working the companies that

00:31:03,220 --> 00:31:06,549
they're all the people who are part of

00:31:04,750 --> 00:31:08,200
the entire tech ecosystem that make tech

00:31:06,549 --> 00:31:09,429
happen so if you're only looking at

00:31:08,200 --> 00:31:11,140
let's say the ride-sharing companies

00:31:09,429 --> 00:31:13,090
that's all the people who make tech

00:31:11,140 --> 00:31:14,500
happen whether it's content and content

00:31:13,090 --> 00:31:16,840
more like all those people that make

00:31:14,500 --> 00:31:18,130
tech happen and that it's not just maybe

00:31:16,840 --> 00:31:20,409
perhaps the privileged folks in the

00:31:18,130 --> 00:31:23,140
unions and the dynamics that can come

00:31:20,409 --> 00:31:24,549
out of that there's so much more that we

00:31:23,140 --> 00:31:26,320
could probably talk more about after

00:31:24,549 --> 00:31:28,390
this but there's a lot I think I think

00:31:26,320 --> 00:31:30,789
about there too I think the term is

00:31:28,390 --> 00:31:32,559
interdisciplinary where everybody a

00:31:30,789 --> 00:31:35,429
social scientist would ask a

00:31:32,559 --> 00:31:39,899
psychologist would ask a tech person

00:31:35,429 --> 00:31:43,299
that approach would solve the problems

00:31:39,899 --> 00:31:45,470
any other questions out there so be our

00:31:43,299 --> 00:31:49,309
last one

00:31:45,470 --> 00:31:53,870
I wanted to ask maybe a bit of a weird

00:31:49,309 --> 00:31:56,389
spin in where bias in technology or our

00:31:53,870 --> 00:31:59,389
trained algorithms could you not also

00:31:56,389 --> 00:32:02,629
look at them as great mechanisms to

00:31:59,389 --> 00:32:05,870
surface formerly invisible types of

00:32:02,629 --> 00:32:08,870
discrimination I've seen examples where

00:32:05,870 --> 00:32:10,610
for instance in recruitment all of a

00:32:08,870 --> 00:32:14,029
sudden because this became visible

00:32:10,610 --> 00:32:17,899
through technology society more broadly

00:32:14,029 --> 00:32:20,120
became aware wow this is actually an

00:32:17,899 --> 00:32:23,600
evidence base for the discrimination

00:32:20,120 --> 00:32:26,139
happening it wouldn't you also could you

00:32:23,600 --> 00:32:31,639
also not see that as a positive kind of

00:32:26,139 --> 00:32:34,039
signaling pattern recognition you mean

00:32:31,639 --> 00:32:35,809
like by design it was biased so

00:32:34,039 --> 00:32:37,070
therefore now the company is like oh wow

00:32:35,809 --> 00:32:38,600
look at this algorithm that was probably

00:32:37,070 --> 00:32:42,370
designed by the surface and issue or

00:32:38,600 --> 00:32:46,009
that we should use it to surface issues

00:32:42,370 --> 00:32:50,240
yeah I guess you know if out of training

00:32:46,009 --> 00:32:52,669
data discriminatory patterns emerge that

00:32:50,240 --> 00:32:55,549
can that's kind of a signaling rule so

00:32:52,669 --> 00:32:57,799
maybe you should think about what kind

00:32:55,549 --> 00:33:00,409
of correcting mechanism should we have

00:32:57,799 --> 00:33:02,059
once you identify that because else you

00:33:00,409 --> 00:33:05,570
may not have seen that ingrained

00:33:02,059 --> 00:33:11,750
discrimination that that was there but

00:33:05,570 --> 00:33:15,769
it was never signal it's good I would

00:33:11,750 --> 00:33:18,230
say in my country they used to be

00:33:15,769 --> 00:33:21,049
statistics that we have taken care of

00:33:18,230 --> 00:33:23,240
gender but if you look at the gender

00:33:21,049 --> 00:33:25,370
that has been taken care of the t girls

00:33:23,240 --> 00:33:28,730
and other things so that the percentage

00:33:25,370 --> 00:33:31,009
doesn't so what they are talking in

00:33:28,730 --> 00:33:34,429
doesn't involve you don't see it at the

00:33:31,009 --> 00:33:37,009
top is only recently that people began

00:33:34,429 --> 00:33:39,429
to question what do you mean by gender

00:33:37,009 --> 00:33:42,559
so some definitions ought to be

00:33:39,429 --> 00:33:44,779
expounded so that you understand that

00:33:42,559 --> 00:33:48,409
when you're talking addenda balance it

00:33:44,779 --> 00:33:51,919
must balance all the way and not at the

00:33:48,409 --> 00:33:55,009
bottom then you apply it lying with

00:33:51,919 --> 00:33:56,410
statistics and I think yes it is

00:33:55,009 --> 00:33:59,820
important but

00:33:56,410 --> 00:34:02,380
we are able to disable some of the

00:33:59,820 --> 00:34:05,799
practices that happen without us knowing

00:34:02,380 --> 00:34:07,330
that they used to happen before I think

00:34:05,799 --> 00:34:12,389
this is such an interesting so I spent

00:34:07,330 --> 00:34:14,290
for fun I spent a year and a half on

00:34:12,389 --> 00:34:16,690
Google's hiring team because I really

00:34:14,290 --> 00:34:19,330
wanted to know how hiring worked and I

00:34:16,690 --> 00:34:20,830
think to some extent yes you even AI

00:34:19,330 --> 00:34:22,690
aside you can use really simple data

00:34:20,830 --> 00:34:24,460
analysis and you're like wow we pulled

00:34:22,690 --> 00:34:27,340
some data from a database and last year

00:34:24,460 --> 00:34:31,419
we hired three women and 800 men or

00:34:27,340 --> 00:34:35,230
something and that's not a real number

00:34:31,419 --> 00:34:36,790
and it takes to something that the

00:34:35,230 --> 00:34:40,389
surface data points right and I think

00:34:36,790 --> 00:34:42,690
the added layer of if you're using that

00:34:40,389 --> 00:34:44,919
as a data point great but then if now

00:34:42,690 --> 00:34:48,280
you're having automated decision-making

00:34:44,919 --> 00:34:50,800
around it without care for that actual

00:34:48,280 --> 00:34:53,490
bias where so I think in one hand if it

00:34:50,800 --> 00:34:56,470
surfaces it and you use it for something

00:34:53,490 --> 00:34:58,390
let's talk about how you're using it but

00:34:56,470 --> 00:35:01,300
then if your system services some kind

00:34:58,390 --> 00:35:03,609
of bias and all it does is feed it into

00:35:01,300 --> 00:35:07,720
some system that determines if someone

00:35:03,609 --> 00:35:09,670
gets social benefits or someone gets

00:35:07,720 --> 00:35:11,920
released in prison for example without

00:35:09,670 --> 00:35:14,140
that level of understanding that there

00:35:11,920 --> 00:35:17,590
is even bias it gets really really

00:35:14,140 --> 00:35:18,760
dangerous so I think maybe for a few to

00:35:17,590 --> 00:35:20,680
answer your question adding the layer of

00:35:18,760 --> 00:35:22,570
automated decision-making to it is where

00:35:20,680 --> 00:35:23,619
I can get really gnarly versus just

00:35:22,570 --> 00:35:25,990
here's some data

00:35:23,619 --> 00:35:28,180
I've suffered some data for you go and

00:35:25,990 --> 00:35:30,390
analyze it and figure out your system

00:35:28,180 --> 00:35:33,810
I think the automated decision part is

00:35:30,390 --> 00:35:36,520
is where it can get really dangerous

00:35:33,810 --> 00:35:38,470
nice ok I think that's all from this

00:35:36,520 --> 00:35:43,869
panel thank you Cathy and then demo for

00:35:38,470 --> 00:35:48,330
joining me today come back at 3:15 for

00:35:43,869 --> 00:35:48,330

YouTube URL: https://www.youtube.com/watch?v=GoQwp9igcSo


