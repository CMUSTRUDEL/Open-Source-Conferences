Title: EuRuKo 2019: Surrounded by Microservices by Damir Svrtan
Publication date: 2021-01-11
Playlist: EuRuKo 2019
Description: 
	Surrounded by Microservices

How to architect an app that consumes endless data sources via various different protocols? How to support easy swapping of those data sources and how to test it with confidence? Let's checkout how these and many other requirements are fulfilled within the Netflix Studio space.

Damir Svrtan - https://twitter.com/DamirSvrtan
EuRuKo 2019
Captions: 
	00:00:05,680 --> 00:00:09,679
so let's bring out

00:00:06,640 --> 00:00:12,719
our next swashbuckler uh

00:00:09,679 --> 00:00:14,080
dumber here is coming to us from san

00:00:12,719 --> 00:00:16,160
francisco is that right

00:00:14,080 --> 00:00:17,520
working at netflix as a senior software

00:00:16,160 --> 00:00:20,800
developer

00:00:17,520 --> 00:00:30,640
and he is uh into punk

00:00:20,800 --> 00:00:33,840
so i'm hoping he'll rock the boat today

00:00:30,640 --> 00:00:35,360
and um we weren't sure uh but we saw in

00:00:33,840 --> 00:00:37,520
a tweet of yours dumber that that you

00:00:35,360 --> 00:00:39,600
either found or gave away a box of

00:00:37,520 --> 00:00:40,800
programming books

00:00:39,600 --> 00:00:42,800
i found it on the street in san

00:00:40,800 --> 00:00:44,079
francisco yeah so

00:00:42,800 --> 00:00:45,920
that's something that happens in san

00:00:44,079 --> 00:00:48,239
francisco apparently

00:00:45,920 --> 00:00:58,640
so well without further ado take it away

00:00:48,239 --> 00:01:02,320
demmer thank you

00:00:58,640 --> 00:01:03,760
okay great hi aruco glad to see all of

00:01:02,320 --> 00:01:04,720
you here and hope you're having a good

00:01:03,760 --> 00:01:06,960
time

00:01:04,720 --> 00:01:08,640
uh as said my name is damir swerten and

00:01:06,960 --> 00:01:10,960
i work in the studio engineering

00:01:08,640 --> 00:01:13,119
organization inside of netflix

00:01:10,960 --> 00:01:15,200
now netflix is often referred to as the

00:01:13,119 --> 00:01:16,720
pioneer of the microservice movement

00:01:15,200 --> 00:01:18,320
and i want to talk to you about my

00:01:16,720 --> 00:01:20,799
practical experience

00:01:18,320 --> 00:01:22,720
after being surrounded by microservices

00:01:20,799 --> 00:01:26,799
and some of the patterns that

00:01:22,720 --> 00:01:28,720
our team uses to tackle distributed data

00:01:26,799 --> 00:01:29,920
most of us from europe so i'm actually

00:01:28,720 --> 00:01:32,320
from croatia

00:01:29,920 --> 00:01:34,240
know netflix as a streaming service but

00:01:32,320 --> 00:01:36,000
netflix actually existed for 10 years

00:01:34,240 --> 00:01:38,079
before getting into streaming

00:01:36,000 --> 00:01:40,560
as a business that shipped dvds to a

00:01:38,079 --> 00:01:42,640
home in red envelopes you would open up

00:01:40,560 --> 00:01:44,640
the envelope take the dvd and

00:01:42,640 --> 00:01:46,320
watch the movies however many times you

00:01:44,640 --> 00:01:49,360
want return it whenever

00:01:46,320 --> 00:01:51,360
and there were no late fees a fun fact

00:01:49,360 --> 00:01:53,280
i thought that this business stopped

00:01:51,360 --> 00:01:54,000
working but it's actually used by more

00:01:53,280 --> 00:01:57,040
than two and a half

00:01:54,000 --> 00:02:00,000
million people in the united states

00:01:57,040 --> 00:02:01,439
uh so the dvd rental business was the

00:02:00,000 --> 00:02:03,439
first phase of netflix

00:02:01,439 --> 00:02:04,880
the second one as i mentioned was the

00:02:03,439 --> 00:02:06,320
streaming service which changed how

00:02:04,880 --> 00:02:08,640
people watch content

00:02:06,320 --> 00:02:11,200
it was a risky move back then streaming

00:02:08,640 --> 00:02:13,040
technologies were not good in 2007 but

00:02:11,200 --> 00:02:14,640
eventually netflix provided a way

00:02:13,040 --> 00:02:16,879
for people to watch great content

00:02:14,640 --> 00:02:18,000
without being just disrupted by endless

00:02:16,879 --> 00:02:19,280
commercials

00:02:18,000 --> 00:02:21,440
i'm not sure if you've ever watched

00:02:19,280 --> 00:02:23,040
cable tv in the us

00:02:21,440 --> 00:02:24,640
but the amount of commercials is

00:02:23,040 --> 00:02:27,040
actually ridiculous

00:02:24,640 --> 00:02:28,239
some of some channels actually feature

00:02:27,040 --> 00:02:30,800
more than 15 min

00:02:28,239 --> 00:02:32,000
15 minutes of commercials within one

00:02:30,800 --> 00:02:35,840
hour of programming

00:02:32,000 --> 00:02:38,480
it's it's basically unbearable to watch

00:02:35,840 --> 00:02:39,120
in 2013 another big shift happened at

00:02:38,480 --> 00:02:41,840
netflix

00:02:39,120 --> 00:02:43,760
and that was producing original content

00:02:41,840 --> 00:02:45,840
what started in the early days with

00:02:43,760 --> 00:02:48,000
house of cards and continued with orange

00:02:45,840 --> 00:02:49,840
is the new black and stranger things

00:02:48,000 --> 00:02:51,760
now netflix produces hundreds and

00:02:49,840 --> 00:02:52,720
hundreds of original shows and movies

00:02:51,760 --> 00:02:54,720
each year

00:02:52,720 --> 00:02:56,480
which is way more than most major film

00:02:54,720 --> 00:02:59,440
studios combined

00:02:56,480 --> 00:03:01,760
now was that a big shift it surely was

00:02:59,440 --> 00:03:03,760
all of a sudden netflix came from being

00:03:01,760 --> 00:03:05,440
just purely a technology company where

00:03:03,760 --> 00:03:07,599
everything is fully automated

00:03:05,440 --> 00:03:09,200
and performs efficiently into the

00:03:07,599 --> 00:03:11,680
entertainment business

00:03:09,200 --> 00:03:13,599
now the movie making business is a

00:03:11,680 --> 00:03:15,680
hundred year old industry

00:03:13,599 --> 00:03:17,440
and in many ways unfortunately it hasn't

00:03:15,680 --> 00:03:19,680
changed a lot since it started

00:03:17,440 --> 00:03:23,040
most of the work is still done on paper

00:03:19,680 --> 00:03:27,360
and it requires a lot of manual labor

00:03:23,040 --> 00:03:29,360
so do you remember these fax machines

00:03:27,360 --> 00:03:30,560
i personally don't have an idea how to

00:03:29,360 --> 00:03:32,480
use one of these

00:03:30,560 --> 00:03:34,720
but basically every single movie

00:03:32,480 --> 00:03:36,640
production uses fax machines

00:03:34,720 --> 00:03:38,879
they're used constantly on sets to

00:03:36,640 --> 00:03:41,440
distribute massive amounts of paperwork

00:03:38,879 --> 00:03:42,080
just to give you a sense how what

00:03:41,440 --> 00:03:43,920
massive

00:03:42,080 --> 00:03:45,680
is there are instances of movie

00:03:43,920 --> 00:03:47,120
productions that manage to print out

00:03:45,680 --> 00:03:50,319
more than 50 000

00:03:47,120 --> 00:03:52,640
pages within the first week of shooting

00:03:50,319 --> 00:03:54,720
at basically at the scale the netflix is

00:03:52,640 --> 00:03:56,720
producing content these traditional

00:03:54,720 --> 00:03:59,760
means do not work well

00:03:56,720 --> 00:04:01,680
so the problem space and the number of

00:03:59,760 --> 00:04:03,040
domains for movie productions and film

00:04:01,680 --> 00:04:05,040
studios is huge

00:04:03,040 --> 00:04:07,439
from deciding which scripts are going to

00:04:05,040 --> 00:04:09,040
be produced to deciding what content

00:04:07,439 --> 00:04:10,560
will be acquired searching and

00:04:09,040 --> 00:04:13,040
discovering talent

00:04:10,560 --> 00:04:15,439
managing contracts and paying actors

00:04:13,040 --> 00:04:17,759
fighting shooting locations

00:04:15,439 --> 00:04:19,120
local title localization subtitles

00:04:17,759 --> 00:04:21,919
dubbing marketing

00:04:19,120 --> 00:04:24,160
it's basically absolutely endless so how

00:04:21,919 --> 00:04:26,960
does netflix tackle these problems

00:04:24,160 --> 00:04:28,800
netflix tackles this by using technology

00:04:26,960 --> 00:04:29,759
and creating apps that cover key part of

00:04:28,800 --> 00:04:31,360
every production

00:04:29,759 --> 00:04:33,199
netflix is creating a first fully

00:04:31,360 --> 00:04:34,880
digital studio to help automate the

00:04:33,199 --> 00:04:37,199
boilerplate and boring parts

00:04:34,880 --> 00:04:38,880
that usually creatives do not want to do

00:04:37,199 --> 00:04:40,960
we're talking about a suit of more than

00:04:38,880 --> 00:04:42,000
50 applications that help with covering

00:04:40,960 --> 00:04:45,360
the previously mentioned

00:04:42,000 --> 00:04:46,960
areas now netflix actually started

00:04:45,360 --> 00:04:49,280
tackling the studio space with a

00:04:46,960 --> 00:04:51,040
monolith with a rails application

00:04:49,280 --> 00:04:52,560
it allowed for rapid development and

00:04:51,040 --> 00:04:54,400
quick changes while the knowledge of the

00:04:52,560 --> 00:04:55,919
space was non-existent

00:04:54,400 --> 00:04:57,759
there are many other apps currently at

00:04:55,919 --> 00:04:59,360
netflix and netflix studios

00:04:57,759 --> 00:05:01,120
but this is still the biggest and the

00:04:59,360 --> 00:05:03,199
most used app there is

00:05:01,120 --> 00:05:05,120
it is pretty big and at one point it had

00:05:03,199 --> 00:05:07,840
more than 30 developers working on it

00:05:05,120 --> 00:05:10,160
and well over 300 database tables

00:05:07,840 --> 00:05:11,440
now a lot of these areas started getting

00:05:10,160 --> 00:05:13,759
specialized apps

00:05:11,440 --> 00:05:15,680
and as we started and we basically

00:05:13,759 --> 00:05:17,600
started decomposing the rails monolith

00:05:15,680 --> 00:05:20,080
and migrating data into various

00:05:17,600 --> 00:05:22,000
specialized apps or microservices the

00:05:20,080 --> 00:05:23,600
decision was not geared by any kind of

00:05:22,000 --> 00:05:24,560
performance issue but with setting

00:05:23,600 --> 00:05:27,199
boundaries around

00:05:24,560 --> 00:05:27,600
all of these different areas and domains

00:05:27,199 --> 00:05:29,600
now

00:05:27,600 --> 00:05:31,440
i've joined netflix about a year ago and

00:05:29,600 --> 00:05:33,120
as i've joined our team started working

00:05:31,440 --> 00:05:34,800
on a new app that crosses multiple

00:05:33,120 --> 00:05:36,479
domains of the business

00:05:34,800 --> 00:05:38,479
we decided to build this app with ruby

00:05:36,479 --> 00:05:39,199
and rails we had the expertise with ruby

00:05:38,479 --> 00:05:41,600
and rails

00:05:39,199 --> 00:05:42,880
it supports agile development it brings

00:05:41,600 --> 00:05:44,880
up team velocity

00:05:42,880 --> 00:05:46,880
time to market is minimal and the amount

00:05:44,880 --> 00:05:49,039
of gems is unbelievable we don't have to

00:05:46,880 --> 00:05:50,400
build already built stuff

00:05:49,039 --> 00:05:52,639
now one of the key elements that

00:05:50,400 --> 00:05:54,080
describes rails is its pragmatic use of

00:05:52,639 --> 00:05:55,840
the active record pattern

00:05:54,080 --> 00:05:58,080
the active record pattern mixes a lot of

00:05:55,840 --> 00:05:59,759
things into one class the main objects

00:05:58,080 --> 00:06:01,919
business rules validations

00:05:59,759 --> 00:06:03,919
persistence and that is great for rapid

00:06:01,919 --> 00:06:05,759
development however that's how we end up

00:06:03,919 --> 00:06:06,800
with models that are tightly coupled to

00:06:05,759 --> 00:06:09,520
the database and

00:06:06,800 --> 00:06:10,960
decoupling those is a pain now why am i

00:06:09,520 --> 00:06:13,600
talking about decoupling

00:06:10,960 --> 00:06:14,160
well what makes working in this network

00:06:13,600 --> 00:06:16,160
studio

00:06:14,160 --> 00:06:17,919
world special is that you start dealing

00:06:16,160 --> 00:06:19,520
with a lot of distributed data

00:06:17,919 --> 00:06:21,120
if you need to work on a project that

00:06:19,520 --> 00:06:22,720
cuts through multiple domains

00:06:21,120 --> 00:06:25,199
you start dealing with various different

00:06:22,720 --> 00:06:26,960
data sources it's a polyglot environment

00:06:25,199 --> 00:06:28,800
and these are some of the examples

00:06:26,960 --> 00:06:30,240
of technologies from where we can get

00:06:28,800 --> 00:06:31,840
data our users

00:06:30,240 --> 00:06:34,000
and their permissions might be behind a

00:06:31,840 --> 00:06:36,560
rest api while our movie information

00:06:34,000 --> 00:06:38,960
might be behind a grpc endpoint and so

00:06:36,560 --> 00:06:41,840
on and a lot of applications actually

00:06:38,960 --> 00:06:43,520
consume data from these services so one

00:06:41,840 --> 00:06:45,199
thing we need to tweak in regards to

00:06:43,520 --> 00:06:47,280
rails is the persistence layer

00:06:45,199 --> 00:06:48,560
we have a key thing to keep in mind also

00:06:47,280 --> 00:06:50,400
when building a new app

00:06:48,560 --> 00:06:52,240
and that is the data that lives in our

00:06:50,400 --> 00:06:52,960
database today might live in a service

00:06:52,240 --> 00:06:54,720
tomorrow

00:06:52,960 --> 00:06:56,240
and its whole behavior might live in a

00:06:54,720 --> 00:06:57,840
specialized app so

00:06:56,240 --> 00:07:00,080
some of the data we have in our local

00:06:57,840 --> 00:07:00,880
database today might have a way broader

00:07:00,080 --> 00:07:03,039
use case

00:07:00,880 --> 00:07:04,639
just the domain might explode and so the

00:07:03,039 --> 00:07:05,680
source of truth of that data might

00:07:04,639 --> 00:07:07,599
actually transfer

00:07:05,680 --> 00:07:09,840
and we have to deal with it differently

00:07:07,599 --> 00:07:11,520
it might be behind some grpc or a rest

00:07:09,840 --> 00:07:12,720
api or something like that

00:07:11,520 --> 00:07:15,360
and we don't want to rely on the

00:07:12,720 --> 00:07:17,360
protocol so basically what we need

00:07:15,360 --> 00:07:18,400
is architecture that clearly separates

00:07:17,360 --> 00:07:20,240
the business logic

00:07:18,400 --> 00:07:21,680
from any kind of implementation details

00:07:20,240 --> 00:07:23,840
and protocols

00:07:21,680 --> 00:07:25,759
and with all of that in mind we realize

00:07:23,840 --> 00:07:27,360
that the perfect architecture for

00:07:25,759 --> 00:07:29,199
the problems we are solving is the

00:07:27,360 --> 00:07:31,759
hexagonal architecture

00:07:29,199 --> 00:07:32,319
the idea behind it is to put inputs and

00:07:31,759 --> 00:07:34,479
outputs

00:07:32,319 --> 00:07:36,720
at the edges of our design inputs would

00:07:34,479 --> 00:07:38,319
be requests hitting the app server or

00:07:36,720 --> 00:07:39,599
any kind of invocation you have from the

00:07:38,319 --> 00:07:42,160
rails console

00:07:39,599 --> 00:07:44,000
what and that would be the green part

00:07:42,160 --> 00:07:46,479
while the outputs would be

00:07:44,000 --> 00:07:48,479
the yellow part and that's data flowing

00:07:46,479 --> 00:07:50,560
into the persistence layer it might be a

00:07:48,479 --> 00:07:51,759
sql database a nosql database some kind

00:07:50,560 --> 00:07:54,879
of elastic search

00:07:51,759 --> 00:07:57,280
a notification system or whatever

00:07:54,879 --> 00:07:59,440
basically in doing so we isolated the

00:07:57,280 --> 00:08:02,240
core logic the central logic

00:07:59,440 --> 00:08:03,599
that we have here from any kind of

00:08:02,240 --> 00:08:05,440
outside concerns

00:08:03,599 --> 00:08:07,759
having inputs and outputs at the edges

00:08:05,440 --> 00:08:11,039
mean we means we can swap their adapters

00:08:07,759 --> 00:08:12,720
without changing the core code at all

00:08:11,039 --> 00:08:14,240
now let's go through a couple of core

00:08:12,720 --> 00:08:16,080
concepts that we have here

00:08:14,240 --> 00:08:17,919
and these are by no means any kind of

00:08:16,080 --> 00:08:19,680
new and revolutionary concepts

00:08:17,919 --> 00:08:22,000
as most of them you might have heard

00:08:19,680 --> 00:08:25,120
obviously from hexagonal architecture

00:08:22,000 --> 00:08:27,199
or uncle bob's clean architecture now

00:08:25,120 --> 00:08:28,160
at the heart of our domain we have our

00:08:27,199 --> 00:08:30,960
entities

00:08:28,160 --> 00:08:32,880
an entity in the case and in our case at

00:08:30,960 --> 00:08:34,880
netflix studios is a movie

00:08:32,880 --> 00:08:36,560
a production a shooting location an

00:08:34,880 --> 00:08:38,800
employee and so on

00:08:36,560 --> 00:08:39,760
and entities by themselves do not know

00:08:38,800 --> 00:08:42,479
where they're stored

00:08:39,760 --> 00:08:44,399
this is unlike what activerecord does

00:08:42,479 --> 00:08:46,080
another core concepts that we have are

00:08:44,399 --> 00:08:48,160
the repositories they are

00:08:46,080 --> 00:08:50,000
our interfaces to getting entities as

00:08:48,160 --> 00:08:52,160
well as creating and changing them

00:08:50,000 --> 00:08:53,200
methods defined on them usually return a

00:08:52,160 --> 00:08:54,959
single entity

00:08:53,200 --> 00:08:56,560
or a list of entities and they keep a

00:08:54,959 --> 00:08:58,640
list of methods that we use to

00:08:56,560 --> 00:09:00,800
communicate with data sources

00:08:58,640 --> 00:09:02,320
now what would be our data sources

00:09:00,800 --> 00:09:04,000
they're basically our adapters to

00:09:02,320 --> 00:09:05,839
different storage implementations

00:09:04,000 --> 00:09:08,240
a data source might be an adapter to a

00:09:05,839 --> 00:09:10,640
sql database to elasticsearch

00:09:08,240 --> 00:09:12,959
to a rest api or even something more

00:09:10,640 --> 00:09:16,240
simpler just a json file or a csv

00:09:12,959 --> 00:09:18,480
file or a ruby hash and

00:09:16,240 --> 00:09:20,240
that's usually where any kind of saucy

00:09:18,480 --> 00:09:20,880
implementation of fetching and pushing

00:09:20,240 --> 00:09:23,760
data

00:09:20,880 --> 00:09:24,640
is kept and then at last we have our

00:09:23,760 --> 00:09:26,399
interactors

00:09:24,640 --> 00:09:28,160
there are classes that orchestrate how

00:09:26,399 --> 00:09:30,000
certain domain action is performed

00:09:28,160 --> 00:09:32,080
they're very similar to what developers

00:09:30,000 --> 00:09:33,200
usually call use case objects or service

00:09:32,080 --> 00:09:34,640
objects

00:09:33,200 --> 00:09:36,480
basically they're classes that are very

00:09:34,640 --> 00:09:38,320
explicit about what they're doing

00:09:36,480 --> 00:09:40,399
and they implement complex business

00:09:38,320 --> 00:09:42,240
rules and validation logic specific to

00:09:40,399 --> 00:09:45,519
that domain action

00:09:42,240 --> 00:09:48,080
so talk is cheap let's see how

00:09:45,519 --> 00:09:48,959
we implement these concepts in our app

00:09:48,080 --> 00:09:51,279
and how

00:09:48,959 --> 00:09:53,120
we generally design our domain with them

00:09:51,279 --> 00:09:54,959
let's start with entities

00:09:53,120 --> 00:09:57,519
an example of an entity in the netflix

00:09:54,959 --> 00:09:59,839
studio domain would be a production

00:09:57,519 --> 00:10:01,600
such as black mirror season 2 or a

00:09:59,839 --> 00:10:03,519
season of stranger things or a movie

00:10:01,600 --> 00:10:06,160
production such as the bird box

00:10:03,519 --> 00:10:07,279
now each of them have an id a title and

00:10:06,160 --> 00:10:09,200
a log line

00:10:07,279 --> 00:10:11,600
to represent them we use the dry struct

00:10:09,200 --> 00:10:14,640
gem from the dry rb family of gems

00:10:11,600 --> 00:10:16,560
drystruck enables us to describe

00:10:14,640 --> 00:10:18,560
entities by listing their attributes

00:10:16,560 --> 00:10:19,839
along with their types and which of them

00:10:18,560 --> 00:10:20,640
are required and which of them are

00:10:19,839 --> 00:10:22,720
optional

00:10:20,640 --> 00:10:24,320
as said they don't have any kind of

00:10:22,720 --> 00:10:26,320
knowledge of

00:10:24,320 --> 00:10:27,600
of the persistence layer those are

00:10:26,320 --> 00:10:29,680
outside concerns

00:10:27,600 --> 00:10:31,519
we need to be able to model our domain

00:10:29,680 --> 00:10:33,200
without the data source implementation

00:10:31,519 --> 00:10:35,920
details

00:10:33,200 --> 00:10:38,160
now for repositories we use a custom

00:10:35,920 --> 00:10:40,079
thin dsl layer to describe them

00:10:38,160 --> 00:10:42,000
we describe which entity they work with

00:10:40,079 --> 00:10:43,519
and what is their default data source

00:10:42,000 --> 00:10:45,200
so in this example a production

00:10:43,519 --> 00:10:48,399
repository will work with

00:10:45,200 --> 00:10:51,200
the production entity class and

00:10:48,399 --> 00:10:52,720
will by default work with a movie

00:10:51,200 --> 00:10:55,040
production

00:10:52,720 --> 00:10:56,079
class which is usually just an active

00:10:55,040 --> 00:10:59,440
record

00:10:56,079 --> 00:11:01,279
model and i said they keep a list of

00:10:59,440 --> 00:11:02,640
methods that we use to communicate with

00:11:01,279 --> 00:11:04,160
data sources so you can see it's

00:11:02,640 --> 00:11:06,000
basically delegating

00:11:04,160 --> 00:11:07,440
a lot of a lot of those to the data

00:11:06,000 --> 00:11:10,079
source and we

00:11:07,440 --> 00:11:12,000
wrap those data source results into the

00:11:10,079 --> 00:11:13,279
entity classes or instances of the

00:11:12,000 --> 00:11:15,360
entity class

00:11:13,279 --> 00:11:17,440
you can see that we inject the data the

00:11:15,360 --> 00:11:20,320
data sources into them

00:11:17,440 --> 00:11:21,920
we want to be able to swap those data

00:11:20,320 --> 00:11:23,680
sources whenever we need

00:11:21,920 --> 00:11:26,800
the only thing those data sources need

00:11:23,680 --> 00:11:28,480
to is conform to the same interface

00:11:26,800 --> 00:11:30,480
now what would be our implementation of

00:11:28,480 --> 00:11:31,920
a data source if we're talking directly

00:11:30,480 --> 00:11:33,680
to our sql database

00:11:31,920 --> 00:11:35,760
our data source will be just an active

00:11:33,680 --> 00:11:37,839
record model that's where any kind of

00:11:35,760 --> 00:11:39,519
sql lodging such as celex groupings or

00:11:37,839 --> 00:11:42,079
aggregate functions will be

00:11:39,519 --> 00:11:43,200
and those implementation details are

00:11:42,079 --> 00:11:45,440
kept directly

00:11:43,200 --> 00:11:47,120
in the data sources as they should they

00:11:45,440 --> 00:11:49,600
should not leave their implementation

00:11:47,120 --> 00:11:51,920
details further into the business logic

00:11:49,600 --> 00:11:52,720
if we were talking to some rest api risk

00:11:51,920 --> 00:11:54,560
endpoint

00:11:52,720 --> 00:11:56,639
like if we got if we were getting our

00:11:54,560 --> 00:11:58,240
movie productions from an api

00:11:56,639 --> 00:12:00,160
we'll need to create a class that will

00:11:58,240 --> 00:12:00,880
fetch data using some kind of a rest

00:12:00,160 --> 00:12:02,399
client

00:12:00,880 --> 00:12:04,560
and you can see that both of these

00:12:02,399 --> 00:12:06,800
classes have the same interface

00:12:04,560 --> 00:12:08,320
this makes our repositories independent

00:12:06,800 --> 00:12:10,720
of our data storage

00:12:08,320 --> 00:12:12,160
system as we can have a default one and

00:12:10,720 --> 00:12:14,320
easily use a different one

00:12:12,160 --> 00:12:15,519
if we need to swap a data source at a

00:12:14,320 --> 00:12:17,920
given moment

00:12:15,519 --> 00:12:18,959
changing a data source in this way does

00:12:17,920 --> 00:12:22,399
not

00:12:18,959 --> 00:12:23,360
whatsoever impact uh our business logic

00:12:22,399 --> 00:12:25,760
which is great

00:12:23,360 --> 00:12:27,519
and another thing we can do with this is

00:12:25,760 --> 00:12:29,920
we can perform it with one line

00:12:27,519 --> 00:12:30,639
changes so it's also very easy to roll

00:12:29,920 --> 00:12:33,839
back

00:12:30,639 --> 00:12:35,680
in situations if we got something wrong

00:12:33,839 --> 00:12:37,360
and finally let's talk about how we

00:12:35,680 --> 00:12:38,959
implement interactors

00:12:37,360 --> 00:12:40,959
for building interactors we use the

00:12:38,959 --> 00:12:43,839
interactor gem the interactor gem

00:12:40,959 --> 00:12:45,279
is great as it provides a uniform way to

00:12:43,839 --> 00:12:48,399
state whether an action

00:12:45,279 --> 00:12:50,639
is a success or a failure now we built a

00:12:48,399 --> 00:12:52,639
small dsl on top of it that enables us

00:12:50,639 --> 00:12:54,800
to define what the dependencies are

00:12:52,639 --> 00:12:55,920
so for the main action of onboarding a

00:12:54,800 --> 00:12:58,480
production

00:12:55,920 --> 00:13:00,480
we will pass in what the production id

00:12:58,480 --> 00:13:03,600
and what the content vertical id

00:13:00,480 --> 00:13:05,440
whether it's a movie or a show and then

00:13:03,600 --> 00:13:06,320
we will instantiate and call the call

00:13:05,440 --> 00:13:09,200
method on it

00:13:06,320 --> 00:13:10,560
which will validate the inputs check if

00:13:09,200 --> 00:13:12,560
it's okay to

00:13:10,560 --> 00:13:14,399
onboard a production and then cover

00:13:12,560 --> 00:13:16,320
various other edge cases

00:13:14,399 --> 00:13:18,000
and then notify others that a production

00:13:16,320 --> 00:13:19,760
has been onboarded

00:13:18,000 --> 00:13:21,680
design like this makes our business

00:13:19,760 --> 00:13:23,920
logic totally decoupled from the

00:13:21,680 --> 00:13:25,600
persistence layer and follow the single

00:13:23,920 --> 00:13:27,440
responsibility principle

00:13:25,600 --> 00:13:29,600
if you look closely you can see that

00:13:27,440 --> 00:13:30,959
actually we passed the repository as the

00:13:29,600 --> 00:13:33,519
default parameter

00:13:30,959 --> 00:13:34,000
why well we actually leverage dependency

00:13:33,519 --> 00:13:36,240
injection

00:13:34,000 --> 00:13:38,880
to properly unit test our interactors

00:13:36,240 --> 00:13:41,680
which i will talk about later on

00:13:38,880 --> 00:13:43,279
now one thing i want to mention rails

00:13:41,680 --> 00:13:45,839
this is not the rails way of doing

00:13:43,279 --> 00:13:47,519
things definitely

00:13:45,839 --> 00:13:49,120
although rails does not aim at

00:13:47,519 --> 00:13:50,560
separating business logic and

00:13:49,120 --> 00:13:54,000
persistence like this

00:13:50,560 --> 00:13:57,440
there are frameworks that build

00:13:54,000 --> 00:14:00,880
that which we which you can build apps

00:13:57,440 --> 00:14:02,399
using a clean architecture fashion so

00:14:00,880 --> 00:14:03,920
if you're interested in that check out

00:14:02,399 --> 00:14:05,600
the konami framework

00:14:03,920 --> 00:14:07,440
uh hanami is a great framework that

00:14:05,600 --> 00:14:08,000
follows these principles and basically

00:14:07,440 --> 00:14:10,320
all the

00:14:08,000 --> 00:14:12,399
the terminology that i've just mentioned

00:14:10,320 --> 00:14:14,560
is implemented in the hanami framework

00:14:12,399 --> 00:14:16,480
the reason why we didn't use it back

00:14:14,560 --> 00:14:17,920
then is because we wanted to leverage

00:14:16,480 --> 00:14:21,199
the large ecosystem

00:14:17,920 --> 00:14:23,360
around active record gems just as like

00:14:21,199 --> 00:14:24,320
counter culture or access list and a

00:14:23,360 --> 00:14:26,560
bunch of others

00:14:24,320 --> 00:14:28,800
that enabled us to move fast and ship

00:14:26,560 --> 00:14:31,199
features on a regular basis

00:14:28,800 --> 00:14:32,240
so that's it about the business logic

00:14:31,199 --> 00:14:34,320
and the core of it

00:14:32,240 --> 00:14:36,720
let's talk about implementing data

00:14:34,320 --> 00:14:38,560
sources we have touched the data sources

00:14:36,720 --> 00:14:38,959
part a little bit but let's talk more

00:14:38,560 --> 00:14:40,800
about

00:14:38,959 --> 00:14:43,040
implementing data sources that actually

00:14:40,800 --> 00:14:45,279
depend on external services

00:14:43,040 --> 00:14:46,800
so as we consume data from different

00:14:45,279 --> 00:14:49,360
apis we need to have

00:14:46,800 --> 00:14:50,160
a lot of api clients there are two main

00:14:49,360 --> 00:14:52,079
approaches

00:14:50,160 --> 00:14:53,519
we could write clients by hand and

00:14:52,079 --> 00:14:55,440
package them in gems

00:14:53,519 --> 00:14:56,720
and in a lot of scenarios that make

00:14:55,440 --> 00:14:59,440
sense just for us

00:14:56,720 --> 00:15:00,079
it doesn't it takes a lot of time to

00:14:59,440 --> 00:15:02,399
write them

00:15:00,079 --> 00:15:03,199
they are error prone they easily get out

00:15:02,399 --> 00:15:05,120
of date

00:15:03,199 --> 00:15:06,240
and you have to always add new features

00:15:05,120 --> 00:15:07,839
by hand

00:15:06,240 --> 00:15:09,680
generally the maintenance burden is too

00:15:07,839 --> 00:15:10,160
heavy and it simply does not scale for

00:15:09,680 --> 00:15:12,560
us

00:15:10,160 --> 00:15:13,600
what we opt in is for other generated

00:15:12,560 --> 00:15:16,240
api clients

00:15:13,600 --> 00:15:17,680
it's basically any api that we work with

00:15:16,240 --> 00:15:20,160
has to be able to provide

00:15:17,680 --> 00:15:21,760
a way to easily interact with either by

00:15:20,160 --> 00:15:23,600
following a specification

00:15:21,760 --> 00:15:27,120
or having documentation from which we

00:15:23,600 --> 00:15:28,880
can generate a client so

00:15:27,120 --> 00:15:30,560
rest apis usually have swagger

00:15:28,880 --> 00:15:31,920
documentation on netflix

00:15:30,560 --> 00:15:33,680
from that we can actually use the

00:15:31,920 --> 00:15:36,320
swagger code generator

00:15:33,680 --> 00:15:37,519
to generate a client in ruby and we

00:15:36,320 --> 00:15:39,360
usually package those

00:15:37,519 --> 00:15:40,800
clients in gems and publish them to a

00:15:39,360 --> 00:15:43,279
local repository

00:15:40,800 --> 00:15:43,839
with grpc we can also generate clients

00:15:43,279 --> 00:15:46,720
easy

00:15:43,839 --> 00:15:48,240
and then with apis that follow the json

00:15:46,720 --> 00:15:50,480
api specification

00:15:48,240 --> 00:15:52,560
which prescribes a uniform way to expose

00:15:50,480 --> 00:15:55,600
resources and receive requests

00:15:52,560 --> 00:15:57,600
there are gems that enable you to easily

00:15:55,600 --> 00:16:00,480
communicate with them without spending

00:15:57,600 --> 00:16:02,800
days and days of actually writing any

00:16:00,480 --> 00:16:04,880
kind of api clients

00:16:02,800 --> 00:16:07,120
now if you go down this path of

00:16:04,880 --> 00:16:09,040
communicating with microservices

00:16:07,120 --> 00:16:11,839
one thing you'll have to deal with is

00:16:09,040 --> 00:16:14,000
errors and that is a big shift

00:16:11,839 --> 00:16:14,959
uh when your only data source is the

00:16:14,000 --> 00:16:17,839
database

00:16:14,959 --> 00:16:18,560
rarely anyone adds extra code for cases

00:16:17,839 --> 00:16:21,680
where the

00:16:18,560 --> 00:16:23,440
when there's a database outage or as or

00:16:21,680 --> 00:16:24,560
something like that as those generally

00:16:23,440 --> 00:16:27,040
rarely happen

00:16:24,560 --> 00:16:27,680
but if one thing is sure it's that the

00:16:27,040 --> 00:16:30,959
network

00:16:27,680 --> 00:16:31,920
is unreliable this kind of happy path

00:16:30,959 --> 00:16:34,079
thinking that

00:16:31,920 --> 00:16:35,839
we usually take with databases does not

00:16:34,079 --> 00:16:37,920
work well in a microservices

00:16:35,839 --> 00:16:39,040
environment microservices will

00:16:37,920 --> 00:16:41,040
definitely fail

00:16:39,040 --> 00:16:42,320
and there will be outages even at

00:16:41,040 --> 00:16:45,440
netflix

00:16:42,320 --> 00:16:47,279
now one thing we need to be prepared for

00:16:45,440 --> 00:16:49,199
is graceful failure what is the

00:16:47,279 --> 00:16:51,920
experience if a downstream service

00:16:49,199 --> 00:16:52,880
fails or has a total outage we need to

00:16:51,920 --> 00:16:55,199
be sure that a

00:16:52,880 --> 00:16:56,560
single outage does not take the whole

00:16:55,199 --> 00:16:58,399
application down

00:16:56,560 --> 00:17:00,959
and we need to be sure that we at least

00:16:58,399 --> 00:17:04,160
are able to serve some partial data and

00:17:00,959 --> 00:17:06,559
give clear error messages to our users

00:17:04,160 --> 00:17:07,520
an essential part of this is being

00:17:06,559 --> 00:17:09,360
properly

00:17:07,520 --> 00:17:11,760
able to troubleshoot errors when

00:17:09,360 --> 00:17:15,039
communicating with downstream services

00:17:11,760 --> 00:17:16,079
if some kind of a 400 or 500 occurs on a

00:17:15,039 --> 00:17:17,839
downstream service

00:17:16,079 --> 00:17:19,679
and you're not sure why that happened

00:17:17,839 --> 00:17:21,839
without proper logging troubleshooting

00:17:19,679 --> 00:17:23,760
is basically a nightmare

00:17:21,839 --> 00:17:24,880
now another extremely extremely

00:17:23,760 --> 00:17:28,240
important uh

00:17:24,880 --> 00:17:30,160
important aspect is measuring as without

00:17:28,240 --> 00:17:31,360
that you won't be able to discover what

00:17:30,160 --> 00:17:33,280
your pain points are

00:17:31,360 --> 00:17:35,760
a good way to solve a lot of these

00:17:33,280 --> 00:17:38,640
problems is having metrics in place

00:17:35,760 --> 00:17:40,640
even just simple ones as what is the

00:17:38,640 --> 00:17:42,480
failure to success ratio

00:17:40,640 --> 00:17:43,840
on this service or what are the

00:17:42,480 --> 00:17:47,520
downstream service

00:17:43,840 --> 00:17:50,080
response times of course we need to also

00:17:47,520 --> 00:17:52,799
have some kind of error reporting system

00:17:50,080 --> 00:17:55,919
just as most vanilla rails apps do such

00:17:52,799 --> 00:17:59,039
as sentry bug snag or something similar

00:17:55,919 --> 00:18:00,720
one thing that we need to be cautious is

00:17:59,039 --> 00:18:03,919
that we don't overload

00:18:00,720 --> 00:18:05,760
ourselves with unactionable errors so we

00:18:03,919 --> 00:18:07,520
should only report errors that are

00:18:05,760 --> 00:18:08,240
actually actionable if a downstream

00:18:07,520 --> 00:18:11,039
service

00:18:08,240 --> 00:18:12,799
let's say responds with a 400 some or

00:18:11,039 --> 00:18:14,799
some kind of validation error

00:18:12,799 --> 00:18:16,880
we don't want to be alerted by that but

00:18:14,799 --> 00:18:17,919
there's not that much that we can do

00:18:16,880 --> 00:18:20,799
actually there

00:18:17,919 --> 00:18:21,840
and the reason why they must be

00:18:20,799 --> 00:18:24,720
actionable

00:18:21,840 --> 00:18:26,240
is because errors otherwise just bring

00:18:24,720 --> 00:18:28,240
alarm fatigue

00:18:26,240 --> 00:18:30,000
how many of you have heard of the phrase

00:18:28,240 --> 00:18:32,960
alarm fatigue

00:18:30,000 --> 00:18:33,200
okay so if you enter an emergency room

00:18:32,960 --> 00:18:35,200
or

00:18:33,200 --> 00:18:37,120
hospital or something like that probably

00:18:35,200 --> 00:18:38,799
the first thing you'll hear is a bunch

00:18:37,120 --> 00:18:40,880
of alarms going off

00:18:38,799 --> 00:18:42,400
constantly from various different

00:18:40,880 --> 00:18:44,720
monitoring systems

00:18:42,400 --> 00:18:46,640
that monitor vital signs on patients

00:18:44,720 --> 00:18:47,440
such as the heart rate the pulse the

00:18:46,640 --> 00:18:50,320
oxygen

00:18:47,440 --> 00:18:50,799
and so on as a lot of these alarms are

00:18:50,320 --> 00:18:53,440
actually

00:18:50,799 --> 00:18:54,400
unnecessary medical staff just starts to

00:18:53,440 --> 00:18:56,240
ignore them

00:18:54,400 --> 00:19:00,400
and this was actually a huge problem in

00:18:56,240 --> 00:19:03,440
the u.s because between 2005 and 2008

00:19:00,400 --> 00:19:05,440
there were more than 550 debts that were

00:19:03,440 --> 00:19:07,840
just due to alarm fatigue

00:19:05,440 --> 00:19:08,480
now our team at the beginning used to

00:19:07,840 --> 00:19:10,640
report

00:19:08,480 --> 00:19:13,200
every single thing even if it was not

00:19:10,640 --> 00:19:14,960
actionable as time passed by we removed

00:19:13,200 --> 00:19:16,720
a lot of those error reports and we set

00:19:14,960 --> 00:19:17,440
up threshold alerts on our metric

00:19:16,720 --> 00:19:19,440
systems

00:19:17,440 --> 00:19:20,640
to notify us when a larger amount of

00:19:19,440 --> 00:19:23,520
calls start failing

00:19:20,640 --> 00:19:25,280
an example of that would be if 20 of

00:19:23,520 --> 00:19:27,440
these calls start failing

00:19:25,280 --> 00:19:29,760
alert our team at that point maybe we're

00:19:27,440 --> 00:19:30,480
not integrating well anymore or maybe

00:19:29,760 --> 00:19:32,480
there's

00:19:30,480 --> 00:19:34,559
there's probably some action that we can

00:19:32,480 --> 00:19:36,799
do to make it better

00:19:34,559 --> 00:19:38,480
now at this point a lot of you might be

00:19:36,799 --> 00:19:39,520
wondering why we'd go straight to the

00:19:38,480 --> 00:19:41,120
data source

00:19:39,520 --> 00:19:43,440
instead of like syncing data or

00:19:41,120 --> 00:19:45,120
something like that

00:19:43,440 --> 00:19:46,799
and a question you might be asking is

00:19:45,120 --> 00:19:48,880
whether this actually scales

00:19:46,799 --> 00:19:51,039
isn't it slow to make additional network

00:19:48,880 --> 00:19:53,520
calls to other services

00:19:51,039 --> 00:19:54,799
well before i answer that let's talk

00:19:53,520 --> 00:19:56,080
about what would be some of the

00:19:54,799 --> 00:19:58,320
alternatives

00:19:56,080 --> 00:20:00,240
we could of course keep copies of that

00:19:58,320 --> 00:20:01,120
data closer to us in some kind of a

00:20:00,240 --> 00:20:03,200
database

00:20:01,120 --> 00:20:05,120
we could listen to events whenever this

00:20:03,200 --> 00:20:07,760
data changes at the source of truth

00:20:05,120 --> 00:20:08,480
and refresh our copies so basically we

00:20:07,760 --> 00:20:11,760
could leverage

00:20:08,480 --> 00:20:12,720
eventual consistency as it is definitely

00:20:11,760 --> 00:20:15,360
the way to go

00:20:12,720 --> 00:20:16,480
to actually reach true scalability but

00:20:15,360 --> 00:20:18,559
at the same time

00:20:16,480 --> 00:20:19,840
it's a solid amount of work there's

00:20:18,559 --> 00:20:21,600
always the question of trading

00:20:19,840 --> 00:20:23,679
consistency for availability

00:20:21,600 --> 00:20:25,360
and in most cases availability actually

00:20:23,679 --> 00:20:27,840
wins in the case for

00:20:25,360 --> 00:20:28,480
let's say amazon's or apple's shopping

00:20:27,840 --> 00:20:30,880
cart

00:20:28,480 --> 00:20:33,200
availability is the absolute winner

00:20:30,880 --> 00:20:35,919
people must always be able to shop

00:20:33,200 --> 00:20:37,360
if if amazon or apple sell an item that

00:20:35,919 --> 00:20:38,799
is no longer in stock

00:20:37,360 --> 00:20:41,039
there's really not that much of a

00:20:38,799 --> 00:20:43,280
problem they'll just issue a refund

00:20:41,039 --> 00:20:44,720
or give some coupons and that's it

00:20:43,280 --> 00:20:46,720
everyone will be happy

00:20:44,720 --> 00:20:49,440
but we're also in a very different

00:20:46,720 --> 00:20:50,720
position amazon has huge volume of data

00:20:49,440 --> 00:20:53,520
enormous traffic

00:20:50,720 --> 00:20:54,400
while our app in the netflix studio

00:20:53,520 --> 00:20:56,960
environment

00:20:54,400 --> 00:20:58,240
at most has a couple of thousand users

00:20:56,960 --> 00:21:01,280
and at the same time

00:20:58,240 --> 00:21:04,240
those users actually make big decisions

00:21:01,280 --> 00:21:06,000
based on the data that we provide so it

00:21:04,240 --> 00:21:08,480
actually better be right

00:21:06,000 --> 00:21:10,000
we we cannot afford the data to be

00:21:08,480 --> 00:21:12,640
inconsistent

00:21:10,000 --> 00:21:13,520
now in network studio and of course the

00:21:12,640 --> 00:21:15,919
whole netflix

00:21:13,520 --> 00:21:18,320
services must be reliable highly

00:21:15,919 --> 00:21:20,640
available and respond in a timely manner

00:21:18,320 --> 00:21:22,720
if we encounter a service that is slow

00:21:20,640 --> 00:21:24,400
team that operates that service will get

00:21:22,720 --> 00:21:27,120
feedback to optimize it

00:21:24,400 --> 00:21:28,080
and we rely a lot of on our services

00:21:27,120 --> 00:21:30,640
being available

00:21:28,080 --> 00:21:32,559
and so far the ride has been great if

00:21:30,640 --> 00:21:34,400
there is a possibility for us to avoid

00:21:32,559 --> 00:21:36,720
synchronizing data in our app

00:21:34,400 --> 00:21:37,840
that is actually the preferred way to go

00:21:36,720 --> 00:21:40,480
don't get me wrong

00:21:37,840 --> 00:21:42,640
a lot of apps at the netflix studio work

00:21:40,480 --> 00:21:44,240
on the eventual consistency model

00:21:42,640 --> 00:21:45,679
but they also have a much more

00:21:44,240 --> 00:21:47,840
specialized use case

00:21:45,679 --> 00:21:48,720
so they don't have such a huge variety

00:21:47,840 --> 00:21:52,320
of data

00:21:48,720 --> 00:21:54,559
as we have in our app but what if this

00:21:52,320 --> 00:21:57,039
actually becomes slow in the future if

00:21:54,559 --> 00:21:59,520
in the future we start to deal with

00:21:57,039 --> 00:22:00,880
huge amounts of data or we need to

00:21:59,520 --> 00:22:03,120
additionally decorate

00:22:00,880 --> 00:22:05,039
some of the data sources that we or some

00:22:03,120 --> 00:22:06,320
of the entities that we rely on from

00:22:05,039 --> 00:22:08,400
external data sources

00:22:06,320 --> 00:22:10,559
will probably decide to keep decorated

00:22:08,400 --> 00:22:12,960
copies of that data closer to us

00:22:10,559 --> 00:22:14,880
but that's another great reason why this

00:22:12,960 --> 00:22:16,799
architecture is awesome

00:22:14,880 --> 00:22:18,720
it enables us to actually delay

00:22:16,799 --> 00:22:20,000
decisions we're not only in a great

00:22:18,720 --> 00:22:21,600
positions when

00:22:20,000 --> 00:22:23,440
in a great position when it comes to

00:22:21,600 --> 00:22:26,000
swapping data sources from

00:22:23,440 --> 00:22:28,400
let's say we consume data from a rest

00:22:26,000 --> 00:22:29,520
api today but let's transfer to graphql

00:22:28,400 --> 00:22:31,840
or something similar

00:22:29,520 --> 00:22:34,159
but also to delay some of the decisions

00:22:31,840 --> 00:22:36,960
whether we want to actually store data

00:22:34,159 --> 00:22:37,600
internally or not and how we want to do

00:22:36,960 --> 00:22:39,600
it

00:22:37,600 --> 00:22:42,000
there's a thing that's called a project

00:22:39,600 --> 00:22:43,440
paradox and that is that we actually

00:22:42,000 --> 00:22:46,080
make the biggest decisions

00:22:43,440 --> 00:22:47,440
on a project when knowledge is at its

00:22:46,080 --> 00:22:49,360
absolute lowest

00:22:47,440 --> 00:22:51,120
just think about it when we start off a

00:22:49,360 --> 00:22:52,720
project we decide what language we're

00:22:51,120 --> 00:22:54,080
going to use what framework we're going

00:22:52,720 --> 00:22:56,240
to use what's the database

00:22:54,080 --> 00:22:58,080
going to be what kind of a database what

00:22:56,240 --> 00:22:59,200
are we going to use for search for pub

00:22:58,080 --> 00:23:02,320
sub mechanism

00:22:59,200 --> 00:23:03,360
and so on and at the same time we really

00:23:02,320 --> 00:23:06,480
don't know much

00:23:03,360 --> 00:23:08,159
but as time goes by the knowledge of the

00:23:06,480 --> 00:23:10,080
domain gets bigger and bigger

00:23:08,159 --> 00:23:12,640
and we know where the project is going

00:23:10,080 --> 00:23:14,080
towards but the scope of the decisions

00:23:12,640 --> 00:23:15,919
that we can actually make

00:23:14,080 --> 00:23:18,799
is lower and lower because we have

00:23:15,919 --> 00:23:20,720
constraints from the previously

00:23:18,799 --> 00:23:22,240
pre previous decisions that we made at

00:23:20,720 --> 00:23:24,960
the beginning of the project

00:23:22,240 --> 00:23:27,280
so uncle bob once said the purpose of

00:23:24,960 --> 00:23:30,080
good architecture is to delay decisions

00:23:27,280 --> 00:23:32,240
why because when we delay a decision we

00:23:30,080 --> 00:23:33,520
have more information when it comes time

00:23:32,240 --> 00:23:35,360
to make it

00:23:33,520 --> 00:23:37,760
so we currently store some of the data

00:23:35,360 --> 00:23:39,600
in postgres but if tomorrow for whatever

00:23:37,760 --> 00:23:41,679
reason we need to switch to some of the

00:23:39,600 --> 00:23:42,960
alternatives because we have set up the

00:23:41,679 --> 00:23:45,120
architecture this way

00:23:42,960 --> 00:23:47,679
it is very easy to delay all of those

00:23:45,120 --> 00:23:50,799
decisions and we can easily opt up

00:23:47,679 --> 00:23:53,919
opta optin for a polyglot approach

00:23:50,799 --> 00:23:57,200
where we take multiple of these

00:23:53,919 --> 00:23:58,400
uh of these various kinds of databases

00:23:57,200 --> 00:24:01,360
or approaches

00:23:58,400 --> 00:24:02,880
and just use them when when it fits our

00:24:01,360 --> 00:24:06,240
needs

00:24:02,880 --> 00:24:08,559
so i want to talk shortly about our

00:24:06,240 --> 00:24:10,559
testing strategy

00:24:08,559 --> 00:24:12,559
we firmly believe that the test suite

00:24:10,559 --> 00:24:15,600
must be reliable and fast

00:24:12,559 --> 00:24:17,200
it's not a nice to have it's a must no

00:24:15,600 --> 00:24:19,760
one wants to run their specs

00:24:17,200 --> 00:24:20,480
only on the ci server stories of

00:24:19,760 --> 00:24:23,279
developers

00:24:20,480 --> 00:24:24,159
running their 30 minute spec suit in

00:24:23,279 --> 00:24:26,960
parallel on

00:24:24,159 --> 00:24:28,960
8 cores just doesn't sound efficient we

00:24:26,960 --> 00:24:32,240
want to have super fast tests

00:24:28,960 --> 00:24:35,120
so we have good development velocity so

00:24:32,240 --> 00:24:35,440
how does usually rails testing look like

00:24:35,120 --> 00:24:38,640
well

00:24:35,440 --> 00:24:39,120
usually a pattern to test rails apps is

00:24:38,640 --> 00:24:41,039
hit

00:24:39,120 --> 00:24:42,640
is basically just hitting the database a

00:24:41,039 --> 00:24:44,880
lot not of course

00:24:42,640 --> 00:24:46,799
every codebase does it like that but

00:24:44,880 --> 00:24:49,919
most apps that i've seen

00:24:46,799 --> 00:24:52,640
actually constantly hit the database now

00:24:49,919 --> 00:24:54,320
when testing business logic you really

00:24:52,640 --> 00:24:56,880
want your

00:24:54,320 --> 00:24:59,039
business logic to be dependent on what

00:24:56,880 --> 00:25:01,200
the data source implementation is

00:24:59,039 --> 00:25:03,600
because we surely don't want to so we

00:25:01,200 --> 00:25:05,440
test our business logic independently

00:25:03,600 --> 00:25:07,120
we leverage dependency injection to

00:25:05,440 --> 00:25:09,600
easily test our interactors

00:25:07,120 --> 00:25:11,200
where most of our business logic resides

00:25:09,600 --> 00:25:11,840
with dependency injection we can

00:25:11,200 --> 00:25:14,159
leverage

00:25:11,840 --> 00:25:15,039
verify doubles and mocks to decouple our

00:25:14,159 --> 00:25:18,240
core code

00:25:15,039 --> 00:25:19,039
from the persistence layer so as an

00:25:18,240 --> 00:25:21,360
example

00:25:19,039 --> 00:25:22,480
of testing that previous interactor that

00:25:21,360 --> 00:25:25,279
i showed you

00:25:22,480 --> 00:25:26,799
we can easily test it for a production

00:25:25,279 --> 00:25:28,480
id and the vertical id that we're

00:25:26,799 --> 00:25:29,360
passing in we can just generate

00:25:28,480 --> 00:25:31,360
something random

00:25:29,360 --> 00:25:33,279
it's not actually stored anywhere and

00:25:31,360 --> 00:25:36,960
then when calling the interactor

00:25:33,279 --> 00:25:38,960
we can actually inject a mock repository

00:25:36,960 --> 00:25:42,159
to properly unit test our logic

00:25:38,960 --> 00:25:44,320
in a failing scenario we can inject a

00:25:42,159 --> 00:25:45,200
mog that returns an existing production

00:25:44,320 --> 00:25:48,559
which should

00:25:45,200 --> 00:25:50,320
respond in a failure in our test case

00:25:48,559 --> 00:25:52,400
and with that we can continue on

00:25:50,320 --> 00:25:53,840
iterating on more difficult edge cases

00:25:52,400 --> 00:25:56,720
and other success

00:25:53,840 --> 00:25:58,240
scenarios so most of our business logic

00:25:56,720 --> 00:26:00,400
is tested through unit tests

00:25:58,240 --> 00:26:02,400
but we of course have integration specs

00:26:00,400 --> 00:26:03,360
our integration specs are written at two

00:26:02,400 --> 00:26:05,120
different layers

00:26:03,360 --> 00:26:06,960
the first layer of integration specs

00:26:05,120 --> 00:26:07,440
works on the data source layer where we

00:26:06,960 --> 00:26:09,360
check

00:26:07,440 --> 00:26:10,559
whether we're integrating properly with

00:26:09,360 --> 00:26:13,120
other services

00:26:10,559 --> 00:26:14,159
the second layer we test are basically

00:26:13,120 --> 00:26:17,600
end-to-end specs

00:26:14,159 --> 00:26:19,200
where we basically go through the input

00:26:17,600 --> 00:26:22,080
go through the core logic

00:26:19,200 --> 00:26:23,840
go to the persistence layer and and get

00:26:22,080 --> 00:26:27,440
back and of course those

00:26:23,840 --> 00:26:30,000
integration tests are cached with vcr

00:26:27,440 --> 00:26:32,159
and we usually build them in most cases

00:26:30,000 --> 00:26:33,279
in a way that they cover one happy pad

00:26:32,159 --> 00:26:36,159
one satpat

00:26:33,279 --> 00:26:37,360
while unit tests cover the rest what

00:26:36,159 --> 00:26:40,240
this produces

00:26:37,360 --> 00:26:41,760
is a fast and reliable spec suit these

00:26:40,240 --> 00:26:42,480
are some of the numbers that we have

00:26:41,760 --> 00:26:44,720
currently

00:26:42,480 --> 00:26:45,919
however we think we can do better it is

00:26:44,720 --> 00:26:48,480
generally lovely

00:26:45,919 --> 00:26:49,360
to work with a test suit that can easily

00:26:48,480 --> 00:26:51,200
be run on

00:26:49,360 --> 00:26:53,120
any development machine and our

00:26:51,200 --> 00:26:55,760
development team can work without

00:26:53,120 --> 00:26:57,919
disrupt disrupting their work on their

00:26:55,760 --> 00:27:01,039
daily features

00:26:57,919 --> 00:27:03,360
so in conclusion uh

00:27:01,039 --> 00:27:05,360
hexagonal architecture really proved to

00:27:03,360 --> 00:27:06,159
be a great way of approaching problems

00:27:05,360 --> 00:27:08,240
for us

00:27:06,159 --> 00:27:09,600
it generally forces us to think in terms

00:27:08,240 --> 00:27:12,080
of the coupling layers

00:27:09,600 --> 00:27:14,559
which is just what we needed and if you

00:27:12,080 --> 00:27:16,880
take one thing from this presentation

00:27:14,559 --> 00:27:18,399
please let it be delaying decisions

00:27:16,880 --> 00:27:20,320
making most of the decisions at the

00:27:18,399 --> 00:27:21,200
beginning of a project does not make a

00:27:20,320 --> 00:27:23,919
lot of sense

00:27:21,200 --> 00:27:25,039
the decisions we made so far have been

00:27:23,919 --> 00:27:27,039
great for us and

00:27:25,039 --> 00:27:28,880
have enabled us to move fast but the

00:27:27,039 --> 00:27:30,720
best part of this architecture is that

00:27:28,880 --> 00:27:32,720
it keeps us flexible for future

00:27:30,720 --> 00:27:34,720
requirements to come

00:27:32,720 --> 00:27:36,960
thank you all for listening hope you all

00:27:34,720 --> 00:27:38,880
got a general idea of this topic

00:27:36,960 --> 00:27:40,720
this only scratches the surface so if

00:27:38,880 --> 00:27:42,080
you want to talk more about it feel free

00:27:40,720 --> 00:27:46,240
to stop me in the hallway

00:27:42,080 --> 00:27:46,240
or at the github booth at any time thank

00:27:46,840 --> 00:27:49,840
you

00:27:54,640 --> 00:27:59,120
well thank you thank you thank you we

00:27:58,000 --> 00:28:02,159
have a present for you as well thank you

00:27:59,120 --> 00:28:02,159

YouTube URL: https://www.youtube.com/watch?v=L7Q2e0i2osc


