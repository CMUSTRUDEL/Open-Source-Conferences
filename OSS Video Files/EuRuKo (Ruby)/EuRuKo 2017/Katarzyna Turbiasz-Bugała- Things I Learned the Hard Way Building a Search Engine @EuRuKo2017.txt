Title: Katarzyna Turbiasz-BugaÅ‚a- Things I Learned the Hard Way Building a Search Engine @EuRuKo2017
Publication date: 2017-12-20
Playlist: EuRuKo 2017
Description: 
	Slides: https://euruko2017.org/downloads/slides/search_engine.pdf
Captions: 
	00:00:06,439 --> 00:00:17,750
okay so my name is Katerina and I am

00:00:12,480 --> 00:00:20,430
well okay

00:00:17,750 --> 00:00:25,529
without the sound rack it won't be the

00:00:20,430 --> 00:00:28,740
same okay so I'm going to tell you some

00:00:25,529 --> 00:00:32,400
things about search like search to be

00:00:28,740 --> 00:00:33,390
more specific but before I do few words

00:00:32,400 --> 00:00:37,110
about me

00:00:33,390 --> 00:00:41,190
I graduated from Polish biology then I

00:00:37,110 --> 00:00:44,789
spent like seven years being general

00:00:41,190 --> 00:00:49,129
logical researcher and about four years

00:00:44,789 --> 00:00:55,579
ago I converted to programming and I'm

00:00:49,129 --> 00:00:59,629
still in it at the beginning of my

00:00:55,579 --> 00:01:04,350
programming path I stumbled upon this

00:00:59,629 --> 00:01:09,600
wonderful company and I'm staying there

00:01:04,350 --> 00:01:13,829
thank you revised and the current

00:01:09,600 --> 00:01:19,259
project I mean is an e-commerce app and

00:01:13,829 --> 00:01:23,149
my main task is the search mechanism the

00:01:19,259 --> 00:01:27,840
first part was to replace existing

00:01:23,149 --> 00:01:31,799
search mechanism which is which was

00:01:27,840 --> 00:01:38,180
based on PostgreSQL with the one based

00:01:31,799 --> 00:01:42,170
on elastic search so as I have no formal

00:01:38,180 --> 00:01:45,090
programming educational background I

00:01:42,170 --> 00:01:51,450
first when I've heard the world the

00:01:45,090 --> 00:01:54,420
world elastic search well I my impostor

00:01:51,450 --> 00:01:58,259
syndrome got like through the roof and

00:01:54,420 --> 00:02:03,000
then I went into Chuck Norris mode and I

00:01:58,259 --> 00:02:08,430
read the whole internet and I learned

00:02:03,000 --> 00:02:11,120
plenty of things that is what elastic

00:02:08,430 --> 00:02:13,700
search is this guy

00:02:11,120 --> 00:02:16,830
elasticsearch is like you know

00:02:13,700 --> 00:02:19,560
self-sufficient having all option you

00:02:16,830 --> 00:02:23,819
can imagine each option you can imagine

00:02:19,560 --> 00:02:28,110
right and it make it it's a huge and

00:02:23,819 --> 00:02:32,160
powerful tool basically for allowing you

00:02:28,110 --> 00:02:34,650
to build your search and it takes like I

00:02:32,160 --> 00:02:38,480
don't know million years to master it

00:02:34,650 --> 00:02:42,690
and that's why I will not tell you about

00:02:38,480 --> 00:02:45,330
elasticsearch today anything but instead

00:02:42,690 --> 00:02:48,780
I will tell you something about

00:02:45,330 --> 00:02:51,739
information retrieval solutions that are

00:02:48,780 --> 00:02:56,239
underlying elasticsearch and probably

00:02:51,739 --> 00:02:59,519
every other search tool you can find

00:02:56,239 --> 00:03:03,420
before though I will tell you exactly

00:02:59,519 --> 00:03:05,400
what information retrieval is let's

00:03:03,420 --> 00:03:07,970
think about search for just a moment

00:03:05,400 --> 00:03:11,160
well I think about searches about

00:03:07,970 --> 00:03:14,730
communication act and in communication

00:03:11,160 --> 00:03:18,810
act you've got this user and the user

00:03:14,730 --> 00:03:22,500
has a computer and user asks computer

00:03:18,810 --> 00:03:27,900
about things he or she is interested in

00:03:22,500 --> 00:03:31,380
right so the first and most important

00:03:27,900 --> 00:03:35,190
condition for it to be successful and

00:03:31,380 --> 00:03:38,280
our search to be effective is common

00:03:35,190 --> 00:03:41,959
language because without common language

00:03:38,280 --> 00:03:46,850
there is no communication at all so

00:03:41,959 --> 00:03:50,370
that's the condition that's the solution

00:03:46,850 --> 00:03:52,670
not gonna happen unfortunately so we

00:03:50,370 --> 00:03:55,980
need to think about some alternatives

00:03:52,670 --> 00:03:59,609
there we go we need to first user to

00:03:55,980 --> 00:04:02,120
formulate their query in a way that is

00:03:59,609 --> 00:04:05,579
easily translated to computer language

00:04:02,120 --> 00:04:09,810
so we can go with the easy option we can

00:04:05,579 --> 00:04:11,730
go with filters type of interface when

00:04:09,810 --> 00:04:13,960
user has all those checkboxes radio

00:04:11,730 --> 00:04:17,850
buttons selects

00:04:13,960 --> 00:04:22,000
and simply you know clicks their way to

00:04:17,850 --> 00:04:27,010
the query with the text search though it

00:04:22,000 --> 00:04:29,110
won't it won't pass an exam because text

00:04:27,010 --> 00:04:33,370
search is basically rooted in the

00:04:29,110 --> 00:04:36,370
natural language and that's as such we

00:04:33,370 --> 00:04:39,940
get ambiguous and not exhaustive queries

00:04:36,370 --> 00:04:42,730
from a user we have a collection of well

00:04:39,940 --> 00:04:46,840
texts which are basically not well

00:04:42,730 --> 00:04:48,190
structured and finally and this is the

00:04:46,840 --> 00:04:51,160
main problem

00:04:48,190 --> 00:04:54,130
I think the relevance in the text search

00:04:51,160 --> 00:04:57,660
is not a boolean value it's more like a

00:04:54,130 --> 00:05:01,360
spectrum because with the traditional

00:04:57,660 --> 00:05:05,010
database queries you have like either

00:05:01,360 --> 00:05:10,680
element is meeting given criteria or

00:05:05,010 --> 00:05:14,350
it's not and if it's if the criteria G

00:05:10,680 --> 00:05:16,510
with the criteria are met then we have a

00:05:14,350 --> 00:05:19,330
relevant result right with the text

00:05:16,510 --> 00:05:22,500
search is more like well this text

00:05:19,330 --> 00:05:25,750
matches fully this text matches well

00:05:22,500 --> 00:05:29,260
more or less and this one is totally not

00:05:25,750 --> 00:05:32,620
relevant so a spectrum right so do we

00:05:29,260 --> 00:05:35,500
have a problem yes we have but we have

00:05:32,620 --> 00:05:38,170
also information retrieval and it will

00:05:35,500 --> 00:05:42,160
be like Superman coming to the rescue

00:05:38,170 --> 00:05:46,210
so what is it so information retrieval

00:05:42,160 --> 00:05:48,790
tells works I will say only that the

00:05:46,210 --> 00:05:51,010
definition is somewhat descriptive so

00:05:48,790 --> 00:05:53,470
the information retrieval deals with the

00:05:51,010 --> 00:05:56,460
representation storage organization of

00:05:53,470 --> 00:05:58,990
and access to information items such as

00:05:56,460 --> 00:06:01,050
document web pages online catalogs

00:05:58,990 --> 00:06:04,540
structured and semi-structured record

00:06:01,050 --> 00:06:07,450
multimedia objects so full spectrum of

00:06:04,540 --> 00:06:11,110
elements right and the primary goal of

00:06:07,450 --> 00:06:13,330
an IRS system is to retrieve all the

00:06:11,110 --> 00:06:16,120
documents that are relevant to a user

00:06:13,330 --> 00:06:20,500
query while retrieving as few non

00:06:16,120 --> 00:06:26,410
relevant documents as possible so

00:06:20,500 --> 00:06:31,600
how does it really work imagine we have

00:06:26,410 --> 00:06:33,400
items it can be collection of our I

00:06:31,600 --> 00:06:37,810
don't know products in our online shop

00:06:33,400 --> 00:06:39,820
or it it can be collection of text or it

00:06:37,810 --> 00:06:45,760
can be collection of music pieces

00:06:39,820 --> 00:06:48,640
whatever we prepare text representation

00:06:45,760 --> 00:06:51,550
which we will call document and the

00:06:48,640 --> 00:06:55,900
document in form of the Texas nothing

00:06:51,550 --> 00:06:59,200
but a bag of world and and on the other

00:06:55,900 --> 00:07:01,530
end we've got user with their

00:06:59,200 --> 00:07:06,580
information need that is somehow

00:07:01,530 --> 00:07:08,620
represented with the users query we can

00:07:06,580 --> 00:07:13,750
suspect that somewhere in the universe

00:07:08,620 --> 00:07:17,320
there is this ideal item that our user

00:07:13,750 --> 00:07:20,740
wants and this ideal item or actually

00:07:17,320 --> 00:07:26,890
collection of items fills the fits user

00:07:20,740 --> 00:07:30,220
needs in 100% if we if we know this item

00:07:26,890 --> 00:07:33,370
we can compare it to our collection and

00:07:30,220 --> 00:07:36,729
pick the most similar one or more likely

00:07:33,370 --> 00:07:40,000
we can prepare this ideal item

00:07:36,729 --> 00:07:44,590
representation and compare it with other

00:07:40,000 --> 00:07:48,070
with our collection unfortunately we

00:07:44,590 --> 00:07:52,510
have no idea if such item exists and if

00:07:48,070 --> 00:07:55,330
so we have no access to that right so

00:07:52,510 --> 00:07:59,200
what we do we have to make a bold

00:07:55,330 --> 00:08:03,340
assumption that's the query user enters

00:07:59,200 --> 00:08:06,790
in our text field is some form of this

00:08:03,340 --> 00:08:09,640
ideal item representation and now we can

00:08:06,790 --> 00:08:12,850
compare and calculate similarity between

00:08:09,640 --> 00:08:16,390
each document in our collection and the

00:08:12,850 --> 00:08:19,180
query with some kind of ranking function

00:08:16,390 --> 00:08:25,020
and we should get somehow relevant

00:08:19,180 --> 00:08:28,039
results so the relevance because it's

00:08:25,020 --> 00:08:30,499
important in its secured here

00:08:28,039 --> 00:08:33,680
the relevance tells us how well a

00:08:30,499 --> 00:08:39,469
document satisfies users information

00:08:33,680 --> 00:08:43,899
need so how this how our documents are

00:08:39,469 --> 00:08:48,260
similar to users query and that's the

00:08:43,899 --> 00:08:52,820
base and basting for information

00:08:48,260 --> 00:08:57,740
retrieval so we have to have a

00:08:52,820 --> 00:09:03,769
collection to have something to work on

00:08:57,740 --> 00:09:06,170
and our collection will be will consist

00:09:03,769 --> 00:09:09,319
from quotes let's say from a tech

00:09:06,170 --> 00:09:12,920
subculture which were translated or

00:09:09,319 --> 00:09:16,610
encrypted by me but in a quasi language

00:09:12,920 --> 00:09:18,709
of my invention so don't read it I mean

00:09:16,610 --> 00:09:20,720
when the text appears you you are not to

00:09:18,709 --> 00:09:23,449
read it you just take a look at it all

00:09:20,720 --> 00:09:28,430
important things will be highlighted

00:09:23,449 --> 00:09:30,709
somehow it will help us to prevent from

00:09:28,430 --> 00:09:33,940
making assumptions because when your

00:09:30,709 --> 00:09:37,100
brain sees the text you automatically

00:09:33,940 --> 00:09:39,800
take some meaning out of it and then you

00:09:37,100 --> 00:09:43,930
have this your own ideas how the ranking

00:09:39,800 --> 00:09:46,639
should look like and how this text

00:09:43,930 --> 00:09:48,800
relates to the query we don't want that

00:09:46,639 --> 00:09:52,639
we want to focus on the mechanism itself

00:09:48,800 --> 00:09:54,829
so no assumptions and last but not least

00:09:52,639 --> 00:09:57,410
you will have this unique opportunity to

00:09:54,829 --> 00:10:00,589
feel like your computer when you ask a

00:09:57,410 --> 00:10:04,339
question right like a search engine so

00:10:00,589 --> 00:10:08,899
let's start those are those are our text

00:10:04,339 --> 00:10:12,880
as you can see no no point in reading

00:10:08,899 --> 00:10:17,569
that this is all about sweets cupcakes

00:10:12,880 --> 00:10:20,899
camels and this kind of stuff I got very

00:10:17,569 --> 00:10:25,040
hungry each time I was sitting down to

00:10:20,899 --> 00:10:27,360
the presentation so this is what our

00:10:25,040 --> 00:10:30,089
user wants to find

00:10:27,360 --> 00:10:32,549
it's a it's an actual query also

00:10:30,089 --> 00:10:35,699
encrypted right so we get marshmallow

00:10:32,549 --> 00:10:41,100
donut caramel and let's start we don't

00:10:35,699 --> 00:10:43,379
want to read each text each time we

00:10:41,100 --> 00:10:46,230
change our mind about the way our

00:10:43,379 --> 00:10:48,959
function ranking function should look

00:10:46,230 --> 00:10:51,739
like so we are clever we will be built

00:10:48,959 --> 00:10:55,589
inverted index in a simplified version

00:10:51,739 --> 00:10:58,529
now it's Harry Potter magic and we have

00:10:55,589 --> 00:11:00,899
our index or rather part of the index as

00:10:58,529 --> 00:11:05,189
you can see the most important are those

00:11:00,899 --> 00:11:08,579
three terms from the user's query and

00:11:05,189 --> 00:11:10,889
this index consists basically of two

00:11:08,579 --> 00:11:14,279
parts there is the dictionary and the

00:11:10,889 --> 00:11:19,040
dictionary are simply all terms from our

00:11:14,279 --> 00:11:23,670
documents collection of unique terms and

00:11:19,040 --> 00:11:27,959
well listed and each term has its own

00:11:23,670 --> 00:11:31,980
postings assigned and postings it's hash

00:11:27,959 --> 00:11:33,989
like structure which contains reference

00:11:31,980 --> 00:11:37,709
to the document and the number of

00:11:33,989 --> 00:11:41,790
occurrences of a given term simple

00:11:37,709 --> 00:11:44,339
structure easy to read and very fast so

00:11:41,790 --> 00:11:49,199
now let's get to measuring similarity

00:11:44,339 --> 00:11:52,559
and okay I admit measuring similarity

00:11:49,199 --> 00:11:55,799
between two texts seems a bit abstract

00:11:52,559 --> 00:11:58,549
right because there is no easy way we

00:11:55,799 --> 00:11:58,549
can think of

00:11:58,890 --> 00:12:08,020
of how to do it and the wise people of

00:12:04,920 --> 00:12:12,850
information retrieval field came with

00:12:08,020 --> 00:12:15,220
the solution let's represent text as bit

00:12:12,850 --> 00:12:18,040
vector in the multi-dimensional space

00:12:15,220 --> 00:12:20,860
each dimension corresponding with one

00:12:18,040 --> 00:12:23,140
term we are interested in and the

00:12:20,860 --> 00:12:25,720
relevance will be simply similarity

00:12:23,140 --> 00:12:27,820
between those two vectors in practice

00:12:25,720 --> 00:12:30,940
it's something like that we've got three

00:12:27,820 --> 00:12:34,810
important terms we look at information

00:12:30,940 --> 00:12:37,450
retrieval and fun and here is our table

00:12:34,810 --> 00:12:40,810
so we've got two texts the first

00:12:37,450 --> 00:12:43,000
information retrieval is fun haha and

00:12:40,810 --> 00:12:44,920
the second we are having fun with

00:12:43,000 --> 00:12:48,310
retrieval whatever that means I just

00:12:44,920 --> 00:12:51,010
needed an example so on the first

00:12:48,310 --> 00:12:55,510
dimension the first text will will have

00:12:51,010 --> 00:12:58,960
a coordinate valued as one because the

00:12:55,510 --> 00:13:01,240
information term is present in it in the

00:12:58,960 --> 00:13:04,120
text in the second text it will be zero

00:13:01,240 --> 00:13:07,180
because there is no such term and we do

00:13:04,120 --> 00:13:11,440
that with every term you are interested

00:13:07,180 --> 00:13:16,600
in and then is text text vectorized

00:13:11,440 --> 00:13:20,350
somehow now we get to similarity cosine

00:13:16,600 --> 00:13:23,560
similarity to be specific here is wise

00:13:20,350 --> 00:13:27,670
formula how to do it so we simply use

00:13:23,560 --> 00:13:29,860
dot product for vectors so we take first

00:13:27,670 --> 00:13:32,470
coordinate of first vector we made

00:13:29,860 --> 00:13:34,510
multiply it by first coordinate of the

00:13:32,470 --> 00:13:37,240
second vector then we do the same with

00:13:34,510 --> 00:13:39,880
the second coordinate and third

00:13:37,240 --> 00:13:42,670
coordinate and until our coordinates are

00:13:39,880 --> 00:13:46,770
finished and then we added up together

00:13:42,670 --> 00:13:50,230
and param we've got similarity

00:13:46,770 --> 00:13:53,640
so first let's prepare some kind of

00:13:50,230 --> 00:13:56,700
matrix and we have our three

00:13:53,640 --> 00:14:01,050
terms from user query and the query

00:13:56,700 --> 00:14:03,690
obviously will have all ones in the

00:14:01,050 --> 00:14:06,120
table because each term appears in a

00:14:03,690 --> 00:14:09,600
query and then the humans will vary

00:14:06,120 --> 00:14:13,350
depending on the term is or is not

00:14:09,600 --> 00:14:18,630
within the document and then we do our

00:14:13,350 --> 00:14:21,720
math and thus Emily the similarity gets

00:14:18,630 --> 00:14:25,560
revealed so we have like five best

00:14:21,720 --> 00:14:29,790
matches right let's take a look at it

00:14:25,560 --> 00:14:33,270
and we can see that each of those best

00:14:29,790 --> 00:14:37,430
matches actually contains each term we

00:14:33,270 --> 00:14:40,950
are interested in and some of them are

00:14:37,430 --> 00:14:45,300
appearing even twice or more times right

00:14:40,950 --> 00:14:49,820
so perhaps time-frequency is something

00:14:45,300 --> 00:14:54,060
we should include in our calculation

00:14:49,820 --> 00:14:57,360
maybe the more term at times the more

00:14:54,060 --> 00:15:01,440
times term appears the better it's true

00:14:57,360 --> 00:15:03,180
but not all the world words were created

00:15:01,440 --> 00:15:06,770
equal because we are dealing with the

00:15:03,180 --> 00:15:10,470
natural language and it's full of those

00:15:06,770 --> 00:15:14,310
pronouns articles prepositions and this

00:15:10,470 --> 00:15:17,400
kind of words that actually burn oh no

00:15:14,310 --> 00:15:21,030
no meaning or a very little meaning so

00:15:17,400 --> 00:15:23,190
we don't want to you know compare to

00:15:21,030 --> 00:15:26,760
text and say that they are they are

00:15:23,190 --> 00:15:31,170
similar simply because of appears in

00:15:26,760 --> 00:15:36,270
both of them so we need to get what they

00:15:31,170 --> 00:15:40,050
are called stop words so we are getting

00:15:36,270 --> 00:15:41,940
rid of the stop word from our users

00:15:40,050 --> 00:15:43,490
query and

00:15:41,940 --> 00:15:46,910
[Music]

00:15:43,490 --> 00:15:49,700
now our matrix looks like that and the

00:15:46,910 --> 00:15:53,210
similarity changes as you can see two

00:15:49,700 --> 00:15:56,180
documents just drastically dropped down

00:15:53,210 --> 00:16:00,410
in a ranking so let's take a look at

00:15:56,180 --> 00:16:03,500
them actually no matches but if we will

00:16:00,410 --> 00:16:06,440
take closer look we will see that one of

00:16:03,500 --> 00:16:11,570
them maybe doesn't contain caramel per

00:16:06,440 --> 00:16:14,510
se but has something very similar and if

00:16:11,570 --> 00:16:17,839
we see through our inventor inverted

00:16:14,510 --> 00:16:20,870
index we will see that there is also

00:16:17,839 --> 00:16:25,010
word caramelize and world world

00:16:20,870 --> 00:16:28,850
marshmallows and we can suspect that our

00:16:25,010 --> 00:16:31,370
user may be interested in documents

00:16:28,850 --> 00:16:34,279
containing also this words right because

00:16:31,370 --> 00:16:38,540
it obviously there is some fun some kind

00:16:34,279 --> 00:16:41,089
of semantic connection so we have to get

00:16:38,540 --> 00:16:44,450
into the family business and we have to

00:16:41,089 --> 00:16:47,450
find those related words because in the

00:16:44,450 --> 00:16:50,089
language as you know there are there are

00:16:47,450 --> 00:16:53,600
those words families and we have a base

00:16:50,089 --> 00:16:57,050
words like ideal and then we have its

00:16:53,600 --> 00:16:59,450
family which contains idealistic ideally

00:16:57,050 --> 00:17:02,330
or we have a base word program and there

00:16:59,450 --> 00:17:06,260
is this word programming programmer and

00:17:02,330 --> 00:17:09,890
so on right so we want to simplify our

00:17:06,260 --> 00:17:12,410
index and our query and work only on

00:17:09,890 --> 00:17:15,740
those base words because they are very

00:17:12,410 --> 00:17:18,380
similar to each other and there are two

00:17:15,740 --> 00:17:20,329
tools to achieve that goal we have

00:17:18,380 --> 00:17:24,260
something that is called limit ization

00:17:20,329 --> 00:17:25,699
and it requires sample previous semantic

00:17:24,260 --> 00:17:28,480
knowledge and knowledge and about

00:17:25,699 --> 00:17:31,280
morphological analysis and basically

00:17:28,480 --> 00:17:33,410
yeah we extracting the base word because

00:17:31,280 --> 00:17:35,780
we know about the processes that were in

00:17:33,410 --> 00:17:41,830
the language and there is other tool

00:17:35,780 --> 00:17:46,040
called stemming which is more like

00:17:41,830 --> 00:17:48,590
tactical and brute force we simply

00:17:46,040 --> 00:17:50,590
remove words ending and we hope that we

00:17:48,590 --> 00:17:54,700
got the base word

00:17:50,590 --> 00:17:56,440
of course those languid oohs tools will

00:17:54,700 --> 00:17:59,320
be different for different different

00:17:56,440 --> 00:18:04,540
language but we have we can find them

00:17:59,320 --> 00:18:09,130
online and it's okay to use them so when

00:18:04,540 --> 00:18:11,590
we adjust our metrics and we will focus

00:18:09,130 --> 00:18:13,510
not on the marshmallow and caramel world

00:18:11,590 --> 00:18:16,530
itself but the whole family of

00:18:13,510 --> 00:18:20,140
marshmallow and caramel we will get

00:18:16,530 --> 00:18:24,390
slightly different outcome and now we

00:18:20,140 --> 00:18:30,040
can seven best matches which is not cool

00:18:24,390 --> 00:18:33,280
so let's get back to the frequency let's

00:18:30,040 --> 00:18:36,060
think about query if we have this query

00:18:33,280 --> 00:18:39,490
Ruby programming and we have text and

00:18:36,060 --> 00:18:42,970
each of those texts contain the world

00:18:39,490 --> 00:18:46,000
programming and in some of those texts

00:18:42,970 --> 00:18:48,670
there is like Ruby mentioned I don't

00:18:46,000 --> 00:18:51,970
know three or four times and some of

00:18:48,670 --> 00:18:55,750
them mentioned will be 300 or 400 times

00:18:51,970 --> 00:19:00,070
we obviously can say that the last group

00:18:55,750 --> 00:19:04,420
is probably about Ruby and therefore is

00:19:00,070 --> 00:19:07,900
relevant for our for our query on the

00:19:04,420 --> 00:19:12,100
other hand if we take this last group in

00:19:07,900 --> 00:19:15,750
this group it doesn't matter if the word

00:19:12,100 --> 00:19:18,640
Ruby appeared 200 times or 300 times the

00:19:15,750 --> 00:19:22,750
most important fact is that it is about

00:19:18,640 --> 00:19:27,310
Ruby hence it's relevant so we would

00:19:22,750 --> 00:19:30,970
expect that the scores of with scores by

00:19:27,310 --> 00:19:35,410
similarity in the last group will not

00:19:30,970 --> 00:19:38,170
differ very much and

00:19:35,410 --> 00:19:41,140
yeah so we can say that the more

00:19:38,170 --> 00:19:44,140
frequent term within one document the

00:19:41,140 --> 00:19:47,140
more relevant it gets but up to a point

00:19:44,140 --> 00:19:50,250
because above some point each occurrence

00:19:47,140 --> 00:19:53,980
is not really meaningful and important

00:19:50,250 --> 00:19:56,920
so wise people of information retrieval

00:19:53,980 --> 00:19:59,500
came up with this nice formula don't

00:19:56,920 --> 00:20:01,780
focus on it too much because it's one of

00:19:59,500 --> 00:20:05,350
many possible possibilities I'm just

00:20:01,780 --> 00:20:09,550
putting it here so that you can be sure

00:20:05,350 --> 00:20:13,210
that I somehow calculated all the stuff

00:20:09,550 --> 00:20:16,330
in the tables and there is another

00:20:13,210 --> 00:20:20,380
aspect of the term frequency which is

00:20:16,330 --> 00:20:22,120
called document frequency again Ruby

00:20:20,380 --> 00:20:25,060
programming again texts about

00:20:22,120 --> 00:20:28,450
programming programming in each of the

00:20:25,060 --> 00:20:30,730
text and programming in C so no Ruby

00:20:28,450 --> 00:20:35,320
they're programming in various languages

00:20:30,730 --> 00:20:37,060
so mentions about Ruby R and the rate

00:20:35,320 --> 00:20:38,710
the last group programming in Ruby

00:20:37,060 --> 00:20:42,070
plenty of Ruby

00:20:38,710 --> 00:20:44,560
so because programming is appearing in

00:20:42,070 --> 00:20:47,290
each text we can say that it has a high

00:20:44,560 --> 00:20:50,500
document frequency because it appears in

00:20:47,290 --> 00:20:53,350
many documents on the other hand Ruby

00:20:50,500 --> 00:20:56,380
appears in a very few texts so we have a

00:20:53,350 --> 00:21:04,900
low document frequency of the term right

00:20:56,380 --> 00:21:06,760
and it's a bit strange yeah but the last

00:21:04,900 --> 00:21:10,020
document contained that the last

00:21:06,760 --> 00:21:12,640
documents contain the term the more

00:21:10,020 --> 00:21:17,380
discriminative power it has right so we

00:21:12,640 --> 00:21:19,510
if only one text contain one term this

00:21:17,380 --> 00:21:24,070
term is very specific for a given

00:21:19,510 --> 00:21:27,070
document so we want to reward somehow

00:21:24,070 --> 00:21:28,340
the terms and the documents that are not

00:21:27,070 --> 00:21:32,270
very

00:21:28,340 --> 00:21:34,210
not very common and this is done by

00:21:32,270 --> 00:21:36,020
invert by inverse document frequency

00:21:34,210 --> 00:21:39,350
idea for short

00:21:36,020 --> 00:21:42,230
and again wise people of information

00:21:39,350 --> 00:21:44,990
retrieval came with this nice formula

00:21:42,230 --> 00:21:46,610
and we take into account total number of

00:21:44,990 --> 00:21:48,260
documents in the collection and the

00:21:46,610 --> 00:21:52,910
total number of documents containing

00:21:48,260 --> 00:21:56,420
given query term and we need to combine

00:21:52,910 --> 00:22:00,920
those formulas to get as you can see

00:21:56,420 --> 00:22:05,090
tf-idf tf-idf is a weight or measure

00:22:00,920 --> 00:22:09,280
that can be applied to number of of two

00:22:05,090 --> 00:22:12,770
to count of terms in the document and

00:22:09,280 --> 00:22:16,070
let's do it let's do it because we want

00:22:12,770 --> 00:22:19,160
turn frequency to be somehow involved in

00:22:16,070 --> 00:22:23,480
our calculation of similarity as you can

00:22:19,160 --> 00:22:26,990
see the results first got a bit lower

00:22:23,480 --> 00:22:29,720
and second we now see that it's actually

00:22:26,990 --> 00:22:33,130
is a spectrum and some documents are

00:22:29,720 --> 00:22:36,260
more fitting to the query than the other

00:22:33,130 --> 00:22:43,700
so let's take a look at the winning four

00:22:36,260 --> 00:22:47,300
and yes still we have matches by query

00:22:43,700 --> 00:22:50,180
terms we can also see that the first

00:22:47,300 --> 00:22:55,400
document which got the highest score is

00:22:50,180 --> 00:22:58,850
the longest one so perhaps it's because

00:22:55,400 --> 00:23:01,700
size matters perhaps the longer

00:22:58,850 --> 00:23:04,130
documents the more probable that any

00:23:01,700 --> 00:23:06,890
term appears that would statistics

00:23:04,130 --> 00:23:09,110
suggest right so we need to somehow

00:23:06,890 --> 00:23:11,210
compensate it because we can have in our

00:23:09,110 --> 00:23:13,490
collection short documents long

00:23:11,210 --> 00:23:17,740
documents and we cannot just you know

00:23:13,490 --> 00:23:23,540
cut number of words to some arbitrary

00:23:17,740 --> 00:23:26,120
chosen one so longer documents should be

00:23:23,540 --> 00:23:29,000
somehow penalized because they have more

00:23:26,120 --> 00:23:31,970
words so the bigger chance of hitting

00:23:29,000 --> 00:23:34,160
the term from the query and the shorter

00:23:31,970 --> 00:23:35,850
documents should be boosted up because

00:23:34,160 --> 00:23:40,169
they

00:23:35,850 --> 00:23:44,130
less words and lesser chances matching

00:23:40,169 --> 00:23:47,160
the query and so again thank you wise

00:23:44,130 --> 00:23:49,140
people of information retrieval we've

00:23:47,160 --> 00:23:51,960
got something which is called private

00:23:49,140 --> 00:23:54,090
length normalization factor and it's

00:23:51,960 --> 00:23:58,250
taken to the counts average document

00:23:54,090 --> 00:24:02,520
slide the length which is our pivot we

00:23:58,250 --> 00:24:04,980
that is the value above which length of

00:24:02,520 --> 00:24:10,620
documents should be a bit penalized and

00:24:04,980 --> 00:24:14,820
below which documents should be boosted

00:24:10,620 --> 00:24:17,450
up and we have a slope slope can be

00:24:14,820 --> 00:24:21,480
adjusted it depends on collection

00:24:17,450 --> 00:24:23,159
elasticsearch uses loosing underneath

00:24:21,480 --> 00:24:27,030
never mind that

00:24:23,159 --> 00:24:30,559
inelastic search is opened sixteen and

00:24:27,030 --> 00:24:30,559
we will stick to that number and

00:24:30,690 --> 00:24:37,050
it's a normalizer so we divide our

00:24:33,780 --> 00:24:43,740
tf-idf similar similarity by this factor

00:24:37,050 --> 00:24:45,960
and we should get the final score so

00:24:43,740 --> 00:24:48,630
before we get to the table with the

00:24:45,960 --> 00:24:51,870
results I want to tell you that we just

00:24:48,630 --> 00:24:54,450
worked out ranking function of what is

00:24:51,870 --> 00:24:58,110
called vector retrieval model or one of

00:24:54,450 --> 00:25:01,910
its variation and our final formula

00:24:58,110 --> 00:25:03,090
looks like that say hello to the monster

00:25:01,910 --> 00:25:06,510
yeah

00:25:03,090 --> 00:25:08,910
don't focus on it too much because as I

00:25:06,510 --> 00:25:12,090
said there is there are some other

00:25:08,910 --> 00:25:14,550
options because each of element can be

00:25:12,090 --> 00:25:19,650
counted a bit definitely but what we

00:25:14,550 --> 00:25:23,490
have here we have numerator with TF

00:25:19,650 --> 00:25:25,080
measure we have denominator with our

00:25:23,490 --> 00:25:28,800
lanthanum normalizer

00:25:25,080 --> 00:25:34,500
and then at the end we have our IDF

00:25:28,800 --> 00:25:37,860
measure yeah so let's apply it as you

00:25:34,500 --> 00:25:41,750
can see in the top row there is length

00:25:37,860 --> 00:25:44,100
given and if you compare tf-idf

00:25:41,750 --> 00:25:47,940
similarity with our new normalized

00:25:44,100 --> 00:25:51,150
similarity it actually becomes quite

00:25:47,940 --> 00:25:54,060
obvious that that shorter documents got

00:25:51,150 --> 00:26:00,679
a bit of a boost and longer documents

00:25:54,060 --> 00:26:05,269
got a bit of boost down

00:26:00,679 --> 00:26:09,259
anyway we can ask is that all we can do

00:26:05,269 --> 00:26:12,259
can we do anything better yes we can we

00:26:09,259 --> 00:26:15,129
can use for example synonyms and as it

00:26:12,259 --> 00:26:18,499
happens in our language in my language

00:26:15,129 --> 00:26:22,459
marshmallow it has two synonym words

00:26:18,499 --> 00:26:25,519
chupa-chupa offer and if we check with

00:26:22,459 --> 00:26:29,690
our inverted index we have two documents

00:26:25,519 --> 00:26:32,929
containing those synonyms and now we

00:26:29,690 --> 00:26:36,709
have to do something which is called

00:26:32,929 --> 00:26:39,289
query expansion because our user asked

00:26:36,709 --> 00:26:42,349
us about marshmallow caramel

00:26:39,289 --> 00:26:45,289
we know that marshmallow has synonym

00:26:42,349 --> 00:26:48,259
chupa chup and the synonym offer so we

00:26:45,289 --> 00:26:50,749
just assume that our user might have

00:26:48,259 --> 00:26:55,309
asked us about marshmallow chupa chup

00:26:50,749 --> 00:26:59,959
whopper caramel and we count similarity

00:26:55,309 --> 00:27:02,539
for those words as you can see document

00:26:59,959 --> 00:27:08,149
9 and document 11 which contains

00:27:02,539 --> 00:27:12,499
synonyms actually were quite quite

00:27:08,149 --> 00:27:17,329
boosted and they are right now at the

00:27:12,499 --> 00:27:21,259
top of our ranking because our ranking

00:27:17,329 --> 00:27:26,379
right now looks like that and we have we

00:27:21,259 --> 00:27:30,709
have 11 documents neatly sorted ranges

00:27:26,379 --> 00:27:33,919
that goes with the color I are somewhat

00:27:30,709 --> 00:27:36,950
arbitrary picked I just looked at it and

00:27:33,919 --> 00:27:40,599
it's well looked nice to divide it this

00:27:36,950 --> 00:27:44,690
way because they are clustering together

00:27:40,599 --> 00:27:47,719
so we have and the important thing is

00:27:44,690 --> 00:27:50,869
that those ranges you need to adjust

00:27:47,719 --> 00:27:53,059
because it depends on the collection so

00:27:50,869 --> 00:27:55,450
you have to do it through the experience

00:27:53,059 --> 00:27:58,070
actually and you have to learn your

00:27:55,450 --> 00:28:03,440
documents and Larian then

00:27:58,070 --> 00:28:08,210
your learn your data okay so we have two

00:28:03,440 --> 00:28:10,160
top documents we have six more or less

00:28:08,210 --> 00:28:15,770
matching documents and three documents

00:28:10,160 --> 00:28:20,450
that are rather not relevant can we do

00:28:15,770 --> 00:28:24,920
better yes we can we can boost our

00:28:20,450 --> 00:28:28,370
documents if exact user query appears in

00:28:24,920 --> 00:28:31,190
it we can boost our documents when they

00:28:28,370 --> 00:28:36,070
contain all query terms because as you

00:28:31,190 --> 00:28:39,830
may suspect our ranking also in includes

00:28:36,070 --> 00:28:43,250
documents were only I don't know 50% of

00:28:39,830 --> 00:28:47,210
terms appeared we can boost documents

00:28:43,250 --> 00:28:51,710
with the similar ordering of terms as it

00:28:47,210 --> 00:28:54,680
is inquiry we can prepare wider search

00:28:51,710 --> 00:28:58,790
because user might have misspelled the

00:28:54,680 --> 00:29:01,880
world the word and users are known to

00:28:58,790 --> 00:29:04,520
misspelled words we have plenty of other

00:29:01,880 --> 00:29:07,690
options and if you go deeper into

00:29:04,520 --> 00:29:12,290
information text retrieval information

00:29:07,690 --> 00:29:16,000
retrieval yes and text search area you

00:29:12,290 --> 00:29:19,310
will discover each and every one of them

00:29:16,000 --> 00:29:23,150
but we won't do that because we have

00:29:19,310 --> 00:29:27,410
like 11 minutes left and it would take a

00:29:23,150 --> 00:29:31,250
moment to count all the staff so we want

00:29:27,410 --> 00:29:34,360
to sum up somehow thinks about text

00:29:31,250 --> 00:29:37,820
search and information retrieval as such

00:29:34,360 --> 00:29:39,750
so first and foremost relevance is a

00:29:37,820 --> 00:29:43,210
spectrum

00:29:39,750 --> 00:29:45,940
second thing is that relevance can be

00:29:43,210 --> 00:29:48,310
viewed as similarity between query user

00:29:45,940 --> 00:29:51,910
entered and the document in our

00:29:48,310 --> 00:29:55,750
collection and we can count it with

00:29:51,910 --> 00:29:59,890
vector magic and the count of terms is

00:29:55,750 --> 00:30:05,470
quite complicated area and asks for

00:29:59,890 --> 00:30:08,500
tf-idf measure and length normalization

00:30:05,470 --> 00:30:13,090
generally pays off because our documents

00:30:08,500 --> 00:30:15,580
for sure will differ in length and last

00:30:13,090 --> 00:30:18,280
but not least semantics cannot be

00:30:15,580 --> 00:30:21,160
avoided but we can control it to some

00:30:18,280 --> 00:30:25,390
extent with the use of stop words with

00:30:21,160 --> 00:30:30,010
youth use of synonyms lists and related

00:30:25,390 --> 00:30:31,440
words finding and yeah we can

00:30:30,010 --> 00:30:35,560
I don't know prepare controlled

00:30:31,440 --> 00:30:38,470
vocabularies and it's there is a plenty

00:30:35,560 --> 00:30:42,730
of possibility here

00:30:38,470 --> 00:30:46,390
important note vector model which we

00:30:42,730 --> 00:30:51,630
discussed is one of many models and it's

00:30:46,390 --> 00:30:58,480
it goes really well with long text and

00:30:51,630 --> 00:31:01,450
not that structured as for more records

00:30:58,480 --> 00:31:04,990
like database like database like

00:31:01,450 --> 00:31:09,460
structures it is better to use another

00:31:04,990 --> 00:31:16,030
model which is called BM 25f which is

00:31:09,460 --> 00:31:19,090
probability direct derived and yeah

00:31:16,030 --> 00:31:22,630
that's that's the important note and now

00:31:19,090 --> 00:31:26,340
the moments that we will learn what our

00:31:22,630 --> 00:31:31,860
user was actually searching for online

00:31:26,340 --> 00:31:35,450
well that was meaning of life and sorry

00:31:31,860 --> 00:31:39,390
I I have to tell you that I had no idea

00:31:35,450 --> 00:31:42,630
how result results will shape at the end

00:31:39,390 --> 00:31:46,200
it was just experiment while I was

00:31:42,630 --> 00:31:49,830
preparing this talk and quotes were

00:31:46,200 --> 00:31:55,080
selected a bit randomly fraud from

00:31:49,830 --> 00:31:58,880
Goodreads not all of them and the best

00:31:55,080 --> 00:32:04,790
match here we have until the D'Mello

00:31:58,880 --> 00:32:10,110
you may want to read it but I'm not sure

00:32:04,790 --> 00:32:12,870
don't blame me for the quote there is

00:32:10,110 --> 00:32:18,780
another somewhat shorter and those are

00:32:12,870 --> 00:32:22,350
our winners right and not really

00:32:18,780 --> 00:32:26,400
matching I so so regret Henry Miller

00:32:22,350 --> 00:32:32,610
didn't make to the final yet to the

00:32:26,400 --> 00:32:37,770
final another list of somehow matching

00:32:32,610 --> 00:32:41,700
and finally what was rejected so our

00:32:37,770 --> 00:32:44,670
retrieval system decided that definition

00:32:41,700 --> 00:32:48,750
of life for Diablo is not really

00:32:44,670 --> 00:32:53,160
relevant for meaning of life as well as

00:32:48,750 --> 00:32:57,690
this guy thought

00:32:53,160 --> 00:33:00,480
and Monty Python texts about fruit fight

00:32:57,690 --> 00:33:03,300
is also not relevant

00:33:00,480 --> 00:33:09,930
I disagree personally but what can you

00:33:03,300 --> 00:33:14,190
do it is what it is yeah and that's it I

00:33:09,930 --> 00:33:16,770
mean I okay one suggestion if you are

00:33:14,190 --> 00:33:19,590
looking for the meaning of life I truly

00:33:16,770 --> 00:33:22,890
encourage you to go and watch Monty

00:33:19,590 --> 00:33:26,510
Python's meaning of life movie really

00:33:22,890 --> 00:33:30,660
and at the end there is a scene where

00:33:26,510 --> 00:33:36,420
the meaning of life is revealed yes I

00:33:30,660 --> 00:33:40,790
recommend that and that's one thing and

00:33:36,420 --> 00:33:45,060
the second thing is that I digest it

00:33:40,790 --> 00:33:48,660
think about it and if you happen to have

00:33:45,060 --> 00:33:55,170
any question regarding my presentation I

00:33:48,660 --> 00:33:57,540
will be really glad to try and answer it

00:33:55,170 --> 00:34:01,380
because I cannot make any promise

00:33:57,540 --> 00:34:04,710
because it's a really huge area and yeah

00:34:01,380 --> 00:34:08,060
so find me later and ask me this

00:34:04,710 --> 00:34:14,300
question and I will go like thinking and

00:34:08,060 --> 00:34:14,300
and now but for now it's all

00:34:15,219 --> 00:34:18,630
[Applause]

00:34:17,639 --> 00:34:23,570
thank you

00:34:18,630 --> 00:34:23,570

YouTube URL: https://www.youtube.com/watch?v=4zanERox264


