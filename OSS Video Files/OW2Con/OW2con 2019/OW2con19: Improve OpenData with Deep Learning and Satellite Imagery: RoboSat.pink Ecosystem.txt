Title: OW2con19: Improve OpenData with Deep Learning and Satellite Imagery: RoboSat.pink Ecosystem
Publication date: 2019-06-20
Playlist: OW2con 2019
Description: 
	Quality of OpenData is for sure an issue, and among them all location based data.

On the other hand, we gather nowadays more and more data from remote sensing, and we are talking here in PetaBytes.

So, how can we use efficiently several kind of data, by fusion, to extract and spot meaningful insights ?

Deep Learning is for sure a good candidate, and RoboSat.pink is a dedicated ecosystem providing Semantic Segmentation for geospatial imagery.

www.RoboSat.pink
Captions: 
	00:00:05,600 --> 00:00:12,809
so this topic is about hung out to check

00:00:09,929 --> 00:00:14,790
the quality of open data and we are

00:00:12,809 --> 00:00:17,340
taking the case of from juice machine

00:00:14,790 --> 00:00:18,900
open data so you can have a

00:00:17,340 --> 00:00:22,230
example something like open switch one

00:00:18,900 --> 00:00:25,680
in mind or any kind of data provided by

00:00:22,230 --> 00:00:28,170
big city especially in Europe so one

00:00:25,680 --> 00:00:31,140
point about dependent eyes to be sure

00:00:28,170 --> 00:00:35,820
that they are really bill and right now

00:00:31,140 --> 00:00:39,600
we are we've got a lot of imagery from

00:00:35,820 --> 00:00:41,640
from space or from aerial imagery and so

00:00:39,600 --> 00:00:44,850
with deep learning we'll see

00:00:41,640 --> 00:00:47,340
or we can use this kind of imagery to

00:00:44,850 --> 00:00:50,670
check if our open data are yes or no

00:00:47,340 --> 00:00:52,829
enough array label so the point is to

00:00:50,670 --> 00:00:55,379
check if from between two kind of data

00:00:52,829 --> 00:00:57,780
set there is a enough difference is yes

00:00:55,379 --> 00:01:00,210
or no so that will be the man the main

00:00:57,780 --> 00:01:02,760
goal and the third kind of that assesses

00:01:00,210 --> 00:01:07,110
imagery and the other one will be our

00:01:02,760 --> 00:01:10,260
open data so as I said we will use a

00:01:07,110 --> 00:01:14,100
deep learning stuff so we'll use a

00:01:10,260 --> 00:01:17,250
computer vision algorithm to help to

00:01:14,100 --> 00:01:22,680
recognize from imagery patterns so it's

00:01:17,250 --> 00:01:25,140
a supervisor in kind of deep learning so

00:01:22,680 --> 00:01:29,180
we will need to provide a tool our

00:01:25,140 --> 00:01:32,460
neural network to kind of data as input

00:01:29,180 --> 00:01:36,840
imagery of course and also labelled to

00:01:32,460 --> 00:01:39,840
Alper EEMA to true to to trainer and to

00:01:36,840 --> 00:01:42,810
be able to recognize what is supposed to

00:01:39,840 --> 00:01:45,869
extract once we train the model we are

00:01:42,810 --> 00:01:48,689
then able only from the imagery to

00:01:45,869 --> 00:01:50,579
predict what we what we want what we

00:01:48,689 --> 00:01:53,790
have been trained as a mother for and

00:01:50,579 --> 00:01:56,460
then to compare with our alternate data

00:01:53,790 --> 00:01:59,729
set to be sure that is it really evolved

00:01:56,460 --> 00:02:02,159
yes or no so that the main the main

00:01:59,729 --> 00:02:06,270
concept what is the technical solution

00:02:02,159 --> 00:02:10,050
to do that is to provide a framework on

00:02:06,270 --> 00:02:11,550
the pencils one called that robust at

00:02:10,050 --> 00:02:15,120
pink

00:02:11,550 --> 00:02:18,750
and this framework is dedicated to help

00:02:15,120 --> 00:02:23,490
you to to perform computer vision stuff

00:02:18,750 --> 00:02:27,390
on imagery and and so to film three use

00:02:23,490 --> 00:02:30,390
cases first one is the tested quality

00:02:27,390 --> 00:02:33,930
analysis the other one is and to spot

00:02:30,390 --> 00:02:36,570
any kind of change detection between two

00:02:33,930 --> 00:02:38,790
time step from from your data and the so

00:02:36,570 --> 00:02:44,250
one is to train a model on a small area

00:02:38,790 --> 00:02:46,380
and to predict on the broader one so

00:02:44,250 --> 00:02:48,180
it's open source as I said so if you

00:02:46,380 --> 00:02:50,760
want to play with the code it's

00:02:48,180 --> 00:02:53,340
announced on github as a receive all the

00:02:50,760 --> 00:02:57,240
contributors and it's MIT so it's really

00:02:53,340 --> 00:02:59,880
permissive license it's easy to deploy

00:02:57,240 --> 00:03:05,070
so if you want to play with

00:02:59,880 --> 00:03:07,020
it's a one-liner and we we improve a lot

00:03:05,070 --> 00:03:11,970
of existing computer vision stuff so

00:03:07,020 --> 00:03:15,860
it's not only as as simple that using

00:03:11,970 --> 00:03:20,130
already computer vision algorithm so we

00:03:15,860 --> 00:03:23,720
enhanced classical same semantics

00:03:20,130 --> 00:03:26,450
semantics version model to recognize

00:03:23,720 --> 00:03:29,400
pixel from your input imagery and we

00:03:26,450 --> 00:03:32,670
also improve the way that the model

00:03:29,400 --> 00:03:38,360
learn itself so if you see in this

00:03:32,670 --> 00:03:42,000
example a classical way to recognize

00:03:38,360 --> 00:03:44,370
from the imagery and the label the

00:03:42,000 --> 00:03:48,000
pattern is to use a classical croissant

00:03:44,370 --> 00:03:51,840
repeat a loss function and so by keeping

00:03:48,000 --> 00:03:54,810
the semantic topology we can improve the

00:03:51,840 --> 00:03:57,780
accuracy of the prediction and so help

00:03:54,810 --> 00:04:02,580
to improve the pattern and the quality

00:03:57,780 --> 00:04:04,980
of the pattern in the in the output it's

00:04:02,580 --> 00:04:07,830
some cell it's a common line interface

00:04:04,980 --> 00:04:10,620
based so you don't need to to develop

00:04:07,830 --> 00:04:13,740
yourself or you don't need to be so to

00:04:10,620 --> 00:04:17,169
do it to play with it's only

00:04:13,740 --> 00:04:20,380
it could be lunch only or we service

00:04:17,169 --> 00:04:22,900
command line and it will help you to

00:04:20,380 --> 00:04:25,810
save time with the data preparation so

00:04:22,900 --> 00:04:28,380
when you play with deep learning or any

00:04:25,810 --> 00:04:31,180
kind of machine learning stuff you will

00:04:28,380 --> 00:04:34,120
take a lot of time with your data

00:04:31,180 --> 00:04:37,030
progression so this um framework will

00:04:34,120 --> 00:04:41,260
help you to save time by providing you

00:04:37,030 --> 00:04:45,130
several small tool the pink ones each

00:04:41,260 --> 00:04:49,750
tools are able to help you to prepare

00:04:45,130 --> 00:04:53,070
your input data and at the end to get

00:04:49,750 --> 00:04:55,900
training data set you could play with so

00:04:53,070 --> 00:04:59,710
it will help you to save time and to

00:04:55,900 --> 00:05:04,350
directly able to train the model it's

00:04:59,710 --> 00:05:10,090
also a point with with data you will

00:05:04,350 --> 00:05:12,700
quite some quite in fact there is a

00:05:10,090 --> 00:05:15,700
initial Bell Jolla bells so most of the

00:05:12,700 --> 00:05:18,220
time you will lacking of enough quality

00:05:15,700 --> 00:05:20,530
level and so with that augmentation will

00:05:18,220 --> 00:05:24,130
help you even if you don't have a lot of

00:05:20,530 --> 00:05:30,130
levels to train enough the model with a

00:05:24,130 --> 00:05:32,770
small data set and and so if we put all

00:05:30,130 --> 00:05:38,919
this kind of improvement and enhancement

00:05:32,770 --> 00:05:41,800
and tuning in inside that this framework

00:05:38,919 --> 00:05:44,800
were able to play with a plane open data

00:05:41,800 --> 00:05:47,380
to train a model and to check the

00:05:44,800 --> 00:05:52,210
quality so yeah there is a tutorial

00:05:47,380 --> 00:05:55,539
online if you go on this URL you will

00:05:52,210 --> 00:06:00,220
will be able to see a check a step by

00:05:55,539 --> 00:06:03,850
step story a tutorial to use the plane

00:06:00,220 --> 00:06:07,780
open data with this on this framework

00:06:03,850 --> 00:06:09,910
and to check the quality of your just

00:06:07,780 --> 00:06:12,490
basically the set so what we do with a

00:06:09,910 --> 00:06:16,360
ring Retriever and unload and plane

00:06:12,490 --> 00:06:20,050
imagery from a city you know it's from

00:06:16,360 --> 00:06:24,640
volume in France and so we retrieve from

00:06:20,050 --> 00:06:26,590
the open that server imagery we retrieve

00:06:24,640 --> 00:06:30,220
also the official labels

00:06:26,590 --> 00:06:34,419
related to building footprints so here

00:06:30,220 --> 00:06:39,190
in green it's related to what the

00:06:34,419 --> 00:06:41,680
official data are about the food Frank

00:06:39,190 --> 00:06:44,440
and so we launched a training on the

00:06:41,680 --> 00:06:47,169
model so in pink it will be able to

00:06:44,440 --> 00:06:50,530
predict from this imagery and say it's

00:06:47,169 --> 00:06:53,910
been trained well on the imagery where

00:06:50,530 --> 00:06:59,020
from the imagery of the buildings our

00:06:53,910 --> 00:07:03,700
own place and so once we done that the

00:06:59,020 --> 00:07:07,050
next step is to is to clean the training

00:07:03,700 --> 00:07:10,990
data set to be sure that there will no

00:07:07,050 --> 00:07:13,290
part of the imagery and indelible well

00:07:10,990 --> 00:07:17,380
there is still a some inconsistency

00:07:13,290 --> 00:07:20,740
between the region's boss and so yeah if

00:07:17,380 --> 00:07:23,110
you remind in pink its what is frayed by

00:07:20,740 --> 00:07:25,360
the model in green it was it's supposed

00:07:23,110 --> 00:07:27,790
to be in the official data and when

00:07:25,360 --> 00:07:30,190
buzzer agree a green and pink it becomes

00:07:27,790 --> 00:07:33,039
gray so every time it's gray so it means

00:07:30,190 --> 00:07:35,470
that both the prediction and official

00:07:33,039 --> 00:07:38,289
labeller agree so yeah for instance

00:07:35,470 --> 00:07:40,930
there is a place where it's supposed to

00:07:38,289 --> 00:07:44,500
be buildings but you can see here that's

00:07:40,930 --> 00:07:46,810
it under construction so you will you

00:07:44,500 --> 00:07:51,039
will want to remove this kind of input

00:07:46,810 --> 00:07:54,130
data to be sure that your model don't be

00:07:51,039 --> 00:07:59,229
trained on inaccurate data and with this

00:07:54,130 --> 00:08:02,880
tool we help to really quickly can't can

00:07:59,229 --> 00:08:06,729
clean the data set so with only a few

00:08:02,880 --> 00:08:09,250
few action few human action you wanna be

00:08:06,729 --> 00:08:12,550
you wanna be able to clean your data set

00:08:09,250 --> 00:08:15,970
and uncertain that you can train again

00:08:12,550 --> 00:08:19,979
the model with a clean data set and get

00:08:15,970 --> 00:08:24,130
this kind of result so yeah there is a

00:08:19,979 --> 00:08:27,039
an improved consistency wium between the

00:08:24,130 --> 00:08:29,200
official data and the prediction and it

00:08:27,039 --> 00:08:31,630
could help to monitor something like

00:08:29,200 --> 00:08:34,839
change detection so you can see here in

00:08:31,630 --> 00:08:37,750
this example that the main part of the

00:08:34,839 --> 00:08:40,300
building was am obviously dedicated but

00:08:37,750 --> 00:08:44,470
some parts of the building were not

00:08:40,300 --> 00:08:49,510
in the official data and also to zoom

00:08:44,470 --> 00:08:53,590
out you can have a focus on aria

00:08:49,510 --> 00:08:56,380
yeah it's with zero mean the pink

00:08:53,590 --> 00:08:58,960
squares where there is a significant

00:08:56,380 --> 00:09:01,300
inconsistency between your data set and

00:08:58,960 --> 00:09:05,950
the prediction so it can help you to

00:09:01,300 --> 00:09:08,800
directly see that for example here there

00:09:05,950 --> 00:09:10,720
is obviously some some area where there

00:09:08,800 --> 00:09:13,840
is a lot of inconsistencies between

00:09:10,720 --> 00:09:16,980
which in bursts and so to focus and two

00:09:13,840 --> 00:09:21,910
if you zoom in you can get this kind of

00:09:16,980 --> 00:09:24,280
information in yeah there is a lot of

00:09:21,910 --> 00:09:26,350
buildings will not present in the

00:09:24,280 --> 00:09:29,530
official data but obviously from the

00:09:26,350 --> 00:09:32,320
imagery the model is a is able to detect

00:09:29,530 --> 00:09:35,170
them so it can help you to save time to

00:09:32,320 --> 00:09:39,460
quickly check if your open data is yes

00:09:35,170 --> 00:09:42,010
or no reliable and on each yes if it's

00:09:39,460 --> 00:09:49,000
the case in all your broader area or

00:09:42,010 --> 00:09:51,310
only on small parts if you play with

00:09:49,000 --> 00:09:55,120
other kind of data set once you've

00:09:51,310 --> 00:09:58,330
trained once a model so for example here

00:09:55,120 --> 00:10:02,580
we switch with OpenStreetMap and so we

00:09:58,330 --> 00:10:11,080
can perform the same kind of of checking

00:10:02,580 --> 00:10:13,090
with with the point to be true that your

00:10:11,080 --> 00:10:16,830
true data set gets us some kind of

00:10:13,090 --> 00:10:21,340
classification so ER if individual data

00:10:16,830 --> 00:10:24,559
parking for example is considerated as a

00:10:21,340 --> 00:10:27,689
buildings it could be

00:10:24,559 --> 00:10:29,790
something will be an issue if you check

00:10:27,689 --> 00:10:32,579
with another kind of data set so what

00:10:29,790 --> 00:10:35,369
about this tax as a result Rick kind of

00:10:32,579 --> 00:10:38,579
open-source tax related to these tools

00:10:35,369 --> 00:10:41,519
the first one is a GIS one the other one

00:10:38,579 --> 00:10:43,769
is related to a computer vision and the

00:10:41,519 --> 00:10:45,689
third one is related to deep learning so

00:10:43,769 --> 00:10:49,709
there is three kind of stacks involved

00:10:45,689 --> 00:10:55,019
in this solution the point is to to keep

00:10:49,709 --> 00:10:56,220
the cabeza as as tiny as we can and even

00:10:55,019 --> 00:10:58,350
if I said that

00:10:56,220 --> 00:11:03,869
it's a common line interface you've got

00:10:58,350 --> 00:11:05,879
to a Python API so you can extend it if

00:11:03,869 --> 00:11:07,980
you want to change something so if you

00:11:05,879 --> 00:11:10,439
want to another kind of model it's

00:11:07,980 --> 00:11:13,110
possible if you want another user tool

00:11:10,439 --> 00:11:15,569
but you just have to add a new one and

00:11:13,110 --> 00:11:17,970
so on and so on so it's really easy it's

00:11:15,569 --> 00:11:20,850
really designed for to extend it to your

00:11:17,970 --> 00:11:23,069
own need as since you've got something

00:11:20,850 --> 00:11:26,119
quite related so computer vision and

00:11:23,069 --> 00:11:29,939
just assume that you can play with it

00:11:26,119 --> 00:11:32,970
what next there is two kind of next

00:11:29,939 --> 00:11:38,040
point the first one will to be able to

00:11:32,970 --> 00:11:40,290
get some quite decent result even if

00:11:38,040 --> 00:11:43,980
we've got a low resolution imagery in

00:11:40,290 --> 00:11:46,739
input and because we've got a lot of low

00:11:43,980 --> 00:11:48,629
resolution imagery for free crust so it

00:11:46,739 --> 00:11:50,999
will change a lot of thing if we are

00:11:48,629 --> 00:11:53,339
able to deal with this kind of data set

00:11:50,999 --> 00:11:56,579
and the other one is to be able to

00:11:53,339 --> 00:11:59,069
predict at low cost so on a wider area

00:11:56,579 --> 00:12:01,470
because yeah it's just a small area like

00:11:59,069 --> 00:12:04,290
a city if you want to play with

00:12:01,470 --> 00:12:06,929
something a bit bigger it will be fine

00:12:04,290 --> 00:12:10,889
too but if you want to play with

00:12:06,929 --> 00:12:15,869
something like Europe or even a world it

00:12:10,889 --> 00:12:21,149
doesn't right now really work without a

00:12:15,869 --> 00:12:25,379
huge infrastructure to to make it work

00:12:21,149 --> 00:12:29,160
so as a takeaway right now you already

00:12:25,379 --> 00:12:31,980
got an open source solution dedicated to

00:12:29,160 --> 00:12:35,639
do special imagery pattern recognition

00:12:31,980 --> 00:12:37,620
and quality analysis and so yeah just

00:12:35,639 --> 00:12:40,110
play with it you can

00:12:37,620 --> 00:12:41,220
a plane open that to train model and

00:12:40,110 --> 00:12:46,230
it's brand new

00:12:41,220 --> 00:12:49,800
because I'm till because before we are

00:12:46,230 --> 00:12:55,860
obliged all to use an already existing

00:12:49,800 --> 00:12:58,770
data set or to make it to to create a

00:12:55,860 --> 00:13:01,290
levels and by anthem and the third one

00:12:58,770 --> 00:13:04,100
is a we still need to improve the speed

00:13:01,290 --> 00:13:06,830
of the project to make it scale at large

00:13:04,100 --> 00:13:12,690
sense

00:13:06,830 --> 00:13:12,690

YouTube URL: https://www.youtube.com/watch?v=1JM9yU1wkW8


