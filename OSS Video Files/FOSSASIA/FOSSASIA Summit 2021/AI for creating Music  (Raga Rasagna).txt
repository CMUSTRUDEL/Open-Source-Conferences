Title: AI for creating Music  (Raga Rasagna)
Publication date: 2021-03-15
Playlist: FOSSASIA Summit 2021
Description: 
	
Captions: 
	00:00:00,480 --> 00:00:04,720
hello everyone i'm raghav sagna a final

00:00:03,439 --> 00:00:07,040
year computer science

00:00:04,720 --> 00:00:08,320
student of bivariati hyderabad college

00:00:07,040 --> 00:00:10,960
of engineering

00:00:08,320 --> 00:00:12,559
for women today i'm thrilled to share

00:00:10,960 --> 00:00:15,200
about the role

00:00:12,559 --> 00:00:16,640
of creating ai to create music on this

00:00:15,200 --> 00:00:18,560
esteem platform

00:00:16,640 --> 00:00:20,320
i'd like to take this opportunity to

00:00:18,560 --> 00:00:21,920
talk about creating music with

00:00:20,320 --> 00:00:23,519
artificial intelligence

00:00:21,920 --> 00:00:25,439
if i were not an engineer i would

00:00:23,519 --> 00:00:28,240
probably be a musician

00:00:25,439 --> 00:00:30,000
as it signifies the meaning of my name i

00:00:28,240 --> 00:00:31,920
often think in music and live my day

00:00:30,000 --> 00:00:33,200
dreams in music i can't remember a

00:00:31,920 --> 00:00:35,840
single day when

00:00:33,200 --> 00:00:37,200
i did not open up my music player so

00:00:35,840 --> 00:00:39,440
let's quickly listen

00:00:37,200 --> 00:00:41,360
to a short musical composition done by

00:00:39,440 --> 00:00:45,840
using magenta's ai

00:00:41,360 --> 00:00:45,840
before diving deeper

00:00:50,940 --> 00:00:54,150
[Applause]

00:01:24,840 --> 00:01:27,840
foreign

00:01:50,320 --> 00:01:55,840
amazing right does it feel like

00:02:04,560 --> 00:02:10,000
in an easy process not only the

00:02:07,360 --> 00:02:10,000
musicians

00:02:10,800 --> 00:02:15,840
so coming to the history let's know when

00:02:14,160 --> 00:02:17,920
and how it all started

00:02:15,840 --> 00:02:18,879
the earliest use of the computers to

00:02:17,920 --> 00:02:22,239
compose music

00:02:18,879 --> 00:02:23,440
dates back to the mid 1950s as the

00:02:22,239 --> 00:02:25,760
research continues

00:02:23,440 --> 00:02:26,959
initiatives such as google magenta sony

00:02:25,760 --> 00:02:30,160
flow machines

00:02:26,959 --> 00:02:34,080
ibm watson beat want to find out if ai

00:02:30,160 --> 00:02:37,840
can compose compelling music

00:02:34,080 --> 00:02:39,920
so these are the existing services

00:02:37,840 --> 00:02:41,840
traditionally composing music has

00:02:39,920 --> 00:02:44,239
involved a series of activities

00:02:41,840 --> 00:02:45,040
such as definition of the melody and

00:02:44,239 --> 00:02:48,840
rhythm

00:02:45,040 --> 00:02:51,599
harmonization arrangement or

00:02:48,840 --> 00:02:54,400
orchestralization

00:02:51,599 --> 00:02:56,640
however now we are significantly being

00:02:54,400 --> 00:02:57,360
able to generate music instead of a huge

00:02:56,640 --> 00:02:59,840
orchestra

00:02:57,360 --> 00:03:00,560
with deep learning models obviously it's

00:02:59,840 --> 00:03:02,480
not

00:03:00,560 --> 00:03:04,000
readily applicable to every form of

00:03:02,480 --> 00:03:06,159
music but it's a reasonable

00:03:04,000 --> 00:03:07,040
starting point especially for classical

00:03:06,159 --> 00:03:09,040
music

00:03:07,040 --> 00:03:10,800
when a piece of music is performed

00:03:09,040 --> 00:03:13,680
musicians add patterns of small

00:03:10,800 --> 00:03:16,800
deviations and nonsense in pitch

00:03:13,680 --> 00:03:18,879
timing and other musical parameters

00:03:16,800 --> 00:03:19,840
these patterns accord for the musical

00:03:18,879 --> 00:03:22,239
concept of

00:03:19,840 --> 00:03:26,400
expressiveness or gesture and they are

00:03:22,239 --> 00:03:28,879
necessary for the music to sound natural

00:03:26,400 --> 00:03:30,000
so this trend towards the ai systems

00:03:28,879 --> 00:03:32,159
building their

00:03:30,000 --> 00:03:33,519
own self-sufficient understanding of

00:03:32,159 --> 00:03:35,519
musical elements

00:03:33,519 --> 00:03:38,159
was the basis of the higher level

00:03:35,519 --> 00:03:41,599
musical intelligence we see today

00:03:38,159 --> 00:03:44,000
in the 1980s david cope a composer and

00:03:41,599 --> 00:03:44,799
professor of music with his experiments

00:03:44,000 --> 00:03:47,360
in

00:03:44,799 --> 00:03:49,599
music intelligence build a foundation

00:03:47,360 --> 00:03:50,720
for many current ai models on the market

00:03:49,599 --> 00:03:53,519
right now

00:03:50,720 --> 00:03:54,879
first music ns attributes are encoded

00:03:53,519 --> 00:03:56,799
into databases

00:03:54,879 --> 00:03:58,400
then the collection of the recombinant

00:03:56,799 --> 00:04:00,720
segments are extracted

00:03:58,400 --> 00:04:02,400
using certain identifiers and pattern

00:04:00,720 --> 00:04:04,799
matching systems

00:04:02,400 --> 00:04:06,879
from there musical segments are

00:04:04,799 --> 00:04:08,799
categorized and reconstructed in a

00:04:06,879 --> 00:04:12,560
logical musical order

00:04:08,799 --> 00:04:15,040
until new music output is produced

00:04:12,560 --> 00:04:16,880
now we'll see how magenta can be used

00:04:15,040 --> 00:04:19,359
for creating ai music

00:04:16,880 --> 00:04:21,919
why only magenta and not any other

00:04:19,359 --> 00:04:24,080
existing services has mentioned before

00:04:21,919 --> 00:04:25,840
magenta is an open source library

00:04:24,080 --> 00:04:29,040
powered by tensorflow

00:04:25,840 --> 00:04:30,960
mainly for manipulating music and images

00:04:29,040 --> 00:04:32,400
and to use these data to train the deep

00:04:30,960 --> 00:04:34,960
learning models

00:04:32,400 --> 00:04:36,880
the magenta has three phases deep

00:04:34,960 --> 00:04:37,759
learning algorithm auto encoders and

00:04:36,880 --> 00:04:41,680
music vie

00:04:37,759 --> 00:04:43,520
data set and training initially the deep

00:04:41,680 --> 00:04:46,479
learning model has to be built

00:04:43,520 --> 00:04:46,960
for the magenta library the music vi

00:04:46,479 --> 00:04:50,400
function

00:04:46,960 --> 00:04:51,919
allows the encoders to create music by

00:04:50,400 --> 00:04:54,880
interpolating musical

00:04:51,919 --> 00:04:56,880
data a sequence of music notes is

00:04:54,880 --> 00:05:00,000
encoded into a latent factor

00:04:56,880 --> 00:05:02,639
and then decoded into a sequence again

00:05:00,000 --> 00:05:05,280
the latent factor is a type of a model

00:05:02,639 --> 00:05:07,120
which allows high dimensional input data

00:05:05,280 --> 00:05:08,400
this allows for more realistic and

00:05:07,120 --> 00:05:10,960
smooth interpretation

00:05:08,400 --> 00:05:12,800
of the music sequence and eventually

00:05:10,960 --> 00:05:15,440
smooth and realistic output can be

00:05:12,800 --> 00:05:15,440
generated

00:05:21,199 --> 00:05:25,280
interesting right i had a lot of fun and

00:05:23,759 --> 00:05:26,560
learning while learning about such

00:05:25,280 --> 00:05:29,600
emerging trends

00:05:26,560 --> 00:05:33,440
music is such an

00:05:29,600 --> 00:05:35,759
amazing topic to work on and combining

00:05:33,440 --> 00:05:36,880
artificial intelligence with it it just

00:05:35,759 --> 00:05:40,000
makes it

00:05:36,880 --> 00:05:41,360
superb so thank you all for being

00:05:40,000 --> 00:05:48,560
wonderful audience

00:05:41,360 --> 00:05:48,560

YouTube URL: https://www.youtube.com/watch?v=bdxvGjYWIoM


