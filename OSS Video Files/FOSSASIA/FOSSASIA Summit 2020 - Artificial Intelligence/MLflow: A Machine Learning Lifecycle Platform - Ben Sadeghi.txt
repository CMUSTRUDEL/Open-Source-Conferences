Title: MLflow: A Machine Learning Lifecycle Platform - Ben Sadeghi
Publication date: 2020-04-02
Playlist: FOSSASIA Summit 2020 - Artificial Intelligence
Description: 
	MLflow is an open-source platform to streamline machine learning development, including tracking experiments, packaging code into reproducible runs, and sharing and deploying models. MLflow offers a set of lightweight APIs that can be used with any existing machine learning application or library (TensorFlow, PyTorch, XGBoost, etc), wherever you currently run ML code (e.g. in notebooks, standalone applications or the cloud). In this talk, we'll discuss MLflow's components and run through a quick demo.

FOSSASIA Summit 2020 - Artificial Intelligence

Speaker: Ben Sadeghi, Partner Solutions Architect Databricks
Captions: 
	00:00:04,850 --> 00:00:13,530
all right hi guys so next speaker is is

00:00:08,130 --> 00:00:16,770
Ben sacoby and he obviously worked at

00:00:13,530 --> 00:00:19,050
Microsoft as a Solutions Architect so

00:00:16,770 --> 00:00:21,660
connect and then and now he's working at

00:00:19,050 --> 00:00:25,400
data breaks just in town here and then

00:00:21,660 --> 00:00:30,529
he'll talk about an ml flow on this the

00:00:25,400 --> 00:00:32,700
life cycle of ml and AI over to Pam

00:00:30,529 --> 00:00:37,590
thank you Dan

00:00:32,700 --> 00:00:41,550
hello everyone great to be here so I'll

00:00:37,590 --> 00:00:44,000
get straight to it yeah this is ml flow

00:00:41,550 --> 00:00:48,329
it's basically a machine learning

00:00:44,000 --> 00:00:51,510
lifecycle management platform let's talk

00:00:48,329 --> 00:00:53,340
about why it's it exists why people are

00:00:51,510 --> 00:00:57,390
actually investing so much time building

00:00:53,340 --> 00:00:59,399
it primarily because ml work special

00:00:57,390 --> 00:01:03,210
development pipeline development is

00:00:59,399 --> 00:01:05,189
complex right for those all of you

00:01:03,210 --> 00:01:09,060
practitioners you would know that it's a

00:01:05,189 --> 00:01:11,820
an iterative process it really is a

00:01:09,060 --> 00:01:14,930
cycle right you have a data preparation

00:01:11,820 --> 00:01:21,000
phase followed by more training more

00:01:14,930 --> 00:01:22,729
evaluation then on to deployment and and

00:01:21,000 --> 00:01:24,960
basically you're constantly catching

00:01:22,729 --> 00:01:27,420
these metrics and seeing whether your

00:01:24,960 --> 00:01:30,150
mouth drifting or not hence you have new

00:01:27,420 --> 00:01:32,909
raw data coming in and potentially going

00:01:30,150 --> 00:01:37,110
back and doing running through your

00:01:32,909 --> 00:01:41,070
whole training and deployment cycle over

00:01:37,110 --> 00:01:43,350
again there are dozens of tools open

00:01:41,070 --> 00:01:48,990
source tools out there for each of these

00:01:43,350 --> 00:01:52,759
various phrases phases right I know

00:01:48,990 --> 00:01:57,540
primarily we talk about R and the Python

00:01:52,759 --> 00:02:02,909
ecosystem I'll talk about spark a bit

00:01:57,540 --> 00:02:07,220
more in a second but as a whole each of

00:02:02,909 --> 00:02:09,539
these steps themselves are iterative

00:02:07,220 --> 00:02:12,000
right so you'll go through for the data

00:02:09,539 --> 00:02:13,540
preparation you'll loop in there with

00:02:12,000 --> 00:02:16,090
new features right

00:02:13,540 --> 00:02:18,400
same goes with of course a mall training

00:02:16,090 --> 00:02:23,129
you're gonna iterate on that piece as

00:02:18,400 --> 00:02:26,109
well so yeah a lot of parameters to be

00:02:23,129 --> 00:02:27,180
tracked and that's that in itself is can

00:02:26,109 --> 00:02:30,310
be can be challenged

00:02:27,180 --> 00:02:36,010
then you need to sort of make all this

00:02:30,310 --> 00:02:38,560
scale to not just you know many servers

00:02:36,010 --> 00:02:45,159
but large groups right we're talking

00:02:38,560 --> 00:02:48,069
about bringing in siloed teams onto one

00:02:45,159 --> 00:02:49,540
onto one flow right so for data

00:02:48,069 --> 00:02:52,540
preparation you might have so data

00:02:49,540 --> 00:02:54,519
engineers involved for the model

00:02:52,540 --> 00:02:57,220
training it would be a data scientists

00:02:54,519 --> 00:03:00,040
for the deployment and the collection of

00:02:57,220 --> 00:03:06,430
the new raw data that might be the

00:03:00,040 --> 00:03:08,709
DevOps folks right so this lifecycle

00:03:06,430 --> 00:03:12,609
needs to scale out to all these various

00:03:08,709 --> 00:03:16,019
teams okay and on top of that you want

00:03:12,609 --> 00:03:23,530
to impose some sort of governance

00:03:16,019 --> 00:03:26,739
ideally right this is rarely done but ml

00:03:23,530 --> 00:03:29,620
flow will will is assisting in changing

00:03:26,739 --> 00:03:33,370
all this and there's also a model

00:03:29,620 --> 00:03:36,099
exchange so ability to say train a model

00:03:33,370 --> 00:03:39,790
with one open-source framework yet

00:03:36,099 --> 00:03:42,340
deploy it using another one right train

00:03:39,790 --> 00:03:45,340
intends to Flo deploy and PI torch as an

00:03:42,340 --> 00:03:48,180
example okay so that's that's the

00:03:45,340 --> 00:03:51,040
complexity we're trying to address and

00:03:48,180 --> 00:03:55,359
Emma flow is here to the rescue

00:03:51,040 --> 00:03:59,489
yeah so what is it it's an open source

00:03:55,359 --> 00:04:04,599
project it was started by data bricks

00:03:59,489 --> 00:04:08,229
open source in June of 2018 it's a set

00:04:04,599 --> 00:04:11,729
of conventions specifications tools CLI

00:04:08,229 --> 00:04:14,430
libraries and a community of course

00:04:11,729 --> 00:04:20,549
currently all development is on github

00:04:14,430 --> 00:04:22,750
right and yeah a lot of lot of different

00:04:20,549 --> 00:04:25,770
folks involved it's already been

00:04:22,750 --> 00:04:25,770
integrated in

00:04:25,940 --> 00:04:36,380
three or four commercial software yeah

00:04:30,880 --> 00:04:38,960
yes so quick quick design philosophy API

00:04:36,380 --> 00:04:46,250
first yeah so everything as an API it's

00:04:38,960 --> 00:04:48,970
it's meant to be really easy to just set

00:04:46,250 --> 00:04:51,140
up programmatically right it is about

00:04:48,970 --> 00:04:53,900
automating this or life cycle right so

00:04:51,140 --> 00:04:56,810
everything needs to be done

00:04:53,900 --> 00:04:59,060
programmatically if needed it's modular

00:04:56,810 --> 00:04:59,930
we'll talk about its its various pieces

00:04:59,060 --> 00:05:05,020
in a second

00:04:59,930 --> 00:05:10,460
but again you can take what you need

00:05:05,020 --> 00:05:16,070
discard the rest no easy to use I'll

00:05:10,460 --> 00:05:18,080
demo that in a second and yeah so right

00:05:16,070 --> 00:05:22,910
now it's actually available from within

00:05:18,080 --> 00:05:29,780
pip within Conda on Conda it's on the on

00:05:22,910 --> 00:05:33,560
the source forge side good good good oh

00:05:29,780 --> 00:05:39,700
by the way API is for Java Python and

00:05:33,560 --> 00:05:43,010
are didn't get to mention that yeah and

00:05:39,700 --> 00:05:45,740
yeah this is open source in that yeah

00:05:43,010 --> 00:05:49,730
it's it's a big problem so we're trying

00:05:45,740 --> 00:05:52,460
to really get as many contributors to

00:05:49,730 --> 00:05:54,560
assist given their problems right we

00:05:52,460 --> 00:05:57,200
want to have this this to sort of

00:05:54,560 --> 00:05:59,150
address everyone's needs and hence we

00:05:57,200 --> 00:06:02,060
need more input and more contributions

00:05:59,150 --> 00:06:04,940
from others okay so let's get into the

00:06:02,060 --> 00:06:06,830
actual components there are four one is

00:06:04,940 --> 00:06:09,800
brand new I'm not gonna talk about too

00:06:06,830 --> 00:06:11,540
much that's the registry but the major

00:06:09,800 --> 00:06:14,060
ones are the tracking projects and

00:06:11,540 --> 00:06:17,210
models so tracking is the QI tracking of

00:06:14,060 --> 00:06:20,120
everything the code used for the data

00:06:17,210 --> 00:06:23,750
preparation code use for the modeling

00:06:20,120 --> 00:06:26,650
all the parameters used within the

00:06:23,750 --> 00:06:30,800
machine learning algorithms the

00:06:26,650 --> 00:06:34,810
corresponding model performance results

00:06:30,800 --> 00:06:37,550
are tracked any sort of environment

00:06:34,810 --> 00:06:38,210
configurations what not all that's

00:06:37,550 --> 00:06:41,389
tracked

00:06:38,210 --> 00:06:44,810
then you have the the projects component

00:06:41,389 --> 00:06:49,180
which basically bundles all that all

00:06:44,810 --> 00:06:53,660
those articles into two into increments

00:06:49,180 --> 00:06:57,919
a container into a package which can be

00:06:53,660 --> 00:06:59,720
then redeployed and anywhere such that

00:06:57,919 --> 00:07:04,150
you can go ahead and reproduce the exact

00:06:59,720 --> 00:07:06,979
same results right so projects aims for

00:07:04,150 --> 00:07:12,289
reprieve stability and then on the

00:07:06,979 --> 00:07:15,410
models piece you basically have two open

00:07:12,289 --> 00:07:19,639
source components integrated with ml

00:07:15,410 --> 00:07:23,419
flow namely M leap and onks Oh N and X

00:07:19,639 --> 00:07:26,449
which are both basically converters from

00:07:23,419 --> 00:07:28,880
one machine learning framework to

00:07:26,449 --> 00:07:31,909
another so again using M leap and ONC's

00:07:28,880 --> 00:07:34,520
you can go train in say tends to flow

00:07:31,909 --> 00:07:36,319
but then deploy that model and convert

00:07:34,520 --> 00:07:38,060
the model to PI torch and also might

00:07:36,319 --> 00:07:43,120
deploy it as a pipe towards model you

00:07:38,060 --> 00:07:46,630
know so bit more on the tracking side

00:07:43,120 --> 00:07:49,460
tracking your again you you have a few

00:07:46,630 --> 00:07:50,930
concepts here your tracking parameters

00:07:49,460 --> 00:07:53,199
these are actually generic key value

00:07:50,930 --> 00:07:55,789
pairs so it could be anything you like

00:07:53,199 --> 00:07:58,699
actual metrics these are performance

00:07:55,789 --> 00:08:01,479
metrics for the models artifacts these

00:07:58,699 --> 00:08:04,639
are actually these could be just any

00:08:01,479 --> 00:08:07,699
generic files you've generated some

00:08:04,639 --> 00:08:09,620
image for the results of your model you

00:08:07,699 --> 00:08:14,139
can bundle that in and of course the

00:08:09,620 --> 00:08:16,940
source code yeah and projects themselves

00:08:14,139 --> 00:08:20,270
again this is that bundling of the octa

00:08:16,940 --> 00:08:25,729
code the configuration and the data sets

00:08:20,270 --> 00:08:28,449
such that you can readily re rerun re

00:08:25,729 --> 00:08:31,370
execute the entire environment and

00:08:28,449 --> 00:08:35,419
reproduce the same results whether it's

00:08:31,370 --> 00:08:38,360
done remotely or on your local set up

00:08:35,419 --> 00:08:41,690
yeah so here's an example of what a

00:08:38,360 --> 00:08:43,610
project would would contain basically

00:08:41,690 --> 00:08:49,339
you always have some sort of say yeah

00:08:43,610 --> 00:08:50,640
mol config file and your main your your

00:08:49,339 --> 00:08:53,190
modeling

00:08:50,640 --> 00:08:56,640
ripped and all that you can actually

00:08:53,190 --> 00:08:59,490
just do an ml for run they'll find main

00:08:56,640 --> 00:09:02,850
and it'll kind of go get what it needs

00:08:59,490 --> 00:09:05,040
from the ammo and set up your

00:09:02,850 --> 00:09:08,010
environment for you and yeah you up and

00:09:05,040 --> 00:09:11,850
running with that entire workflow

00:09:08,010 --> 00:09:15,060
reproduced as I mentioned yep so with

00:09:11,850 --> 00:09:21,180
with models that are just you have these

00:09:15,060 --> 00:09:23,940
M bleep and and unk's the ability to

00:09:21,180 --> 00:09:27,420
actually convert furthermore you can

00:09:23,940 --> 00:09:30,740
have it set up such that you have the

00:09:27,420 --> 00:09:34,350
native model see in this example

00:09:30,740 --> 00:09:37,650
tensorflow right that's saved as is and

00:09:34,350 --> 00:09:39,690
then you can have a converted one as a

00:09:37,650 --> 00:09:42,870
generic Python function which can then

00:09:39,690 --> 00:09:47,100
be run by with by any Python environment

00:09:42,870 --> 00:09:48,300
yeah say in a darker or on spark which

00:09:47,100 --> 00:09:52,160
I'll demonstrate in a second

00:09:48,300 --> 00:09:55,040
you know deployment environments

00:09:52,160 --> 00:09:57,360
basically anything you can imagine so

00:09:55,040 --> 00:10:00,060
Java should be included there my

00:09:57,360 --> 00:10:03,050
apologies but we often have actually

00:10:00,060 --> 00:10:05,610
deployments done on on docker containers

00:10:03,050 --> 00:10:08,310
I'll go demonstrate this one in a second

00:10:05,610 --> 00:10:11,040
we'll do some batch deployment using

00:10:08,310 --> 00:10:13,890
spark and there are even some other

00:10:11,040 --> 00:10:16,050
cloud services out there namely Mac's

00:10:13,890 --> 00:10:20,660
officers machine learning service and

00:10:16,050 --> 00:10:28,070
AWS is sage maker okay

00:10:20,660 --> 00:10:30,570
so yeah it's lightweight open platform

00:10:28,070 --> 00:10:36,050
integrates well with existing frameworks

00:10:30,570 --> 00:10:38,220
and it has its own server by the way

00:10:36,050 --> 00:10:40,080
yeah running in the background keeping

00:10:38,220 --> 00:10:44,610
track of all these of this logging

00:10:40,080 --> 00:10:48,330
activity and within data breaks you have

00:10:44,610 --> 00:10:54,390
a managed version of ml flow available

00:10:48,330 --> 00:10:57,970
okay so if I may jump into demo time

00:10:54,390 --> 00:11:02,499
right it was demo time okay

00:10:57,970 --> 00:11:04,509
so here we are in so this is a Jordana

00:11:02,499 --> 00:11:07,479
bricks so data bricks is a managed

00:11:04,509 --> 00:11:11,679
apache spark environment available on

00:11:07,479 --> 00:11:14,470
Microsoft's cloud is your and AWS I'm on

00:11:11,679 --> 00:11:16,449
the user side right now I have a little

00:11:14,470 --> 00:11:20,649
spark cluster going button by little I

00:11:16,449 --> 00:11:23,169
mean minimal as one worker yay let's

00:11:20,649 --> 00:11:26,499
take a look at libraries I do have two

00:11:23,169 --> 00:11:30,159
libraries installed ml flow which we I

00:11:26,499 --> 00:11:32,019
fetched from pi PI and koalas which I'll

00:11:30,159 --> 00:11:35,849
talk about tomorrow if you guys are

00:11:32,019 --> 00:11:39,759
around that's basically a pandas API for

00:11:35,849 --> 00:11:42,509
Apache spark yeah so this library I'm a

00:11:39,759 --> 00:11:48,269
flow is installed on this spark cluster

00:11:42,509 --> 00:11:50,709
and I'm gonna jump into a notebook so

00:11:48,269 --> 00:11:53,349
this is data books notebook if you're

00:11:50,709 --> 00:11:57,279
familiar with Jupiter or Zeppelin this

00:11:53,349 --> 00:11:59,289
should be yeah it should be very very

00:11:57,279 --> 00:12:05,199
easy for you same thing it's an HTML

00:11:59,289 --> 00:12:07,899
based IDE and for you those

00:12:05,199 --> 00:12:10,059
practitioners or those who use we've

00:12:07,899 --> 00:12:11,559
studied the machine learning a bit

00:12:10,059 --> 00:12:14,289
you're probably familiar with this data

00:12:11,559 --> 00:12:16,709
set the iris data set some called

00:12:14,289 --> 00:12:20,439
vintage data because it's from the 30s

00:12:16,709 --> 00:12:22,569
yeah I really like it because it's

00:12:20,439 --> 00:12:23,709
pretty straightforward so let's go

00:12:22,569 --> 00:12:26,609
so I've actually connected to that

00:12:23,709 --> 00:12:28,779
cluster which I've named Faust Asia and

00:12:26,609 --> 00:12:30,809
let's do some machine learning and keep

00:12:28,779 --> 00:12:35,079
track of all these experiments right

00:12:30,809 --> 00:12:38,139
okay so my go ahead I'm going and load

00:12:35,079 --> 00:12:40,149
this iris data yeah it's a CSV file I'm

00:12:38,139 --> 00:12:42,299
gonna read it in in to spark cluster I'm

00:12:40,149 --> 00:12:46,149
gonna do a little bit renaming and

00:12:42,299 --> 00:12:49,329
ultimately just display the first first

00:12:46,149 --> 00:12:51,639
ten results no so this is the first

00:12:49,329 --> 00:12:54,399
execution on the cluster takes a give it

00:12:51,639 --> 00:12:57,939
a give it a second assumes it that the

00:12:54,399 --> 00:12:59,889
data sets up will we can get started

00:12:57,939 --> 00:13:03,519
with putting together our pipelines

00:12:59,889 --> 00:13:07,769
basically getting getting the our data

00:13:03,519 --> 00:13:07,769
prepped for machine learning work

00:13:08,110 --> 00:13:14,080
I hope it's not internet here okay so as

00:13:12,280 --> 00:13:17,080
soon as God that goes in the meantime

00:13:14,080 --> 00:13:20,110
we'll continue on so next stage once we

00:13:17,080 --> 00:13:22,180
have the data set in memory we're gonna

00:13:20,110 --> 00:13:25,180
do a couple things first off you'll see

00:13:22,180 --> 00:13:28,360
that the one of the fields their label

00:13:25,180 --> 00:13:32,770
excuse me species actually is a string

00:13:28,360 --> 00:13:34,810
and we have to address that because what

00:13:32,770 --> 00:13:37,960
we'll be using later on for machine

00:13:34,810 --> 00:13:40,450
learning work the spark machine learning

00:13:37,960 --> 00:13:43,870
learning library demands that all that

00:13:40,450 --> 00:13:49,470
be in numerical format so we'll go ahead

00:13:43,870 --> 00:13:56,790
and convert that is map those strings to

00:13:49,470 --> 00:13:59,380
jane teachers okay whoops it's going

00:13:56,790 --> 00:14:00,880
that's using this string indexer and

00:13:59,380 --> 00:14:02,950
there's one other step that needs to be

00:14:00,880 --> 00:14:05,890
done vector assembler basically taking

00:14:02,950 --> 00:14:07,840
all the features that we see and

00:14:05,890 --> 00:14:10,990
basically crunching them up into one

00:14:07,840 --> 00:14:14,440
vector and that's what basically will

00:14:10,990 --> 00:14:19,570
have as our prepped

00:14:14,440 --> 00:14:22,360
data set okay so here we go again those

00:14:19,570 --> 00:14:26,170
of you familiar with the iris data set

00:14:22,360 --> 00:14:29,260
yeah this should be should be very very

00:14:26,170 --> 00:14:33,760
old site but basically you have four

00:14:29,260 --> 00:14:36,550
fields and four for length fields these

00:14:33,760 --> 00:14:40,840
are sepals and petals so if I'm not

00:14:36,550 --> 00:14:44,320
mistaken the big ones are petals the

00:14:40,840 --> 00:14:44,890
small ones are sepals yeah which was the

00:14:44,320 --> 00:14:48,010
big ones

00:14:44,890 --> 00:14:51,310
these excuse me know SEP was along with

00:14:48,010 --> 00:14:54,060
these guys you know and what Fisher did

00:14:51,310 --> 00:14:57,640
back in the 30s was go ahead and

00:14:54,060 --> 00:14:59,950
basically make these length and width

00:14:57,640 --> 00:15:02,860
measurements on these petals and sepals

00:14:59,950 --> 00:15:05,470
and he himself was a botanist slash

00:15:02,860 --> 00:15:08,080
statistician so he could identify the

00:15:05,470 --> 00:15:10,180
species of these flowers and he went

00:15:08,080 --> 00:15:13,510
ahead and constructed this this data set

00:15:10,180 --> 00:15:17,890
so I actually has three species so Tosa

00:15:13,510 --> 00:15:21,980
virginica and versicolor okay so we're

00:15:17,890 --> 00:15:26,209
gonna build a model that's basically

00:15:21,980 --> 00:15:29,869
an expert system which is fed these

00:15:26,209 --> 00:15:32,540
lengths and widths and with that it will

00:15:29,869 --> 00:15:33,910
just predict that the species of the the

00:15:32,540 --> 00:15:38,329
flower here okay

00:15:33,910 --> 00:15:42,709
that's we're doing as I mentioned we're

00:15:38,329 --> 00:15:46,100
gonna do this the mapping of our species

00:15:42,709 --> 00:15:48,169
to an integer that's label so these

00:15:46,100 --> 00:15:51,290
species have now been mapped to label

00:15:48,169 --> 00:15:54,589
and our and our original features have

00:15:51,290 --> 00:15:57,079
been vectorized into that vector there

00:15:54,589 --> 00:15:58,989
okay and it's this label and features

00:15:57,079 --> 00:16:02,899
columns that we're gonna feed into our

00:15:58,989 --> 00:16:04,639
machine learning algorithm so a very

00:16:02,899 --> 00:16:07,249
quick run through the data science

00:16:04,639 --> 00:16:10,730
process I just want to talk about the

00:16:07,249 --> 00:16:14,499
act of splitting your data set into

00:16:10,730 --> 00:16:18,009
training test sets it is basically to to

00:16:14,499 --> 00:16:21,019
make sure you have a sensible way of

00:16:18,009 --> 00:16:23,540
evaluating model performance so

00:16:21,019 --> 00:16:26,179
typically you term you hand over the

00:16:23,540 --> 00:16:29,629
majority of your data set for training

00:16:26,179 --> 00:16:32,509
purposes and what remains what's held

00:16:29,629 --> 00:16:33,769
out is used for testing okay inspark

00:16:32,509 --> 00:16:36,169
there's a very simple function for

00:16:33,769 --> 00:16:39,319
that's called random split in this case

00:16:36,169 --> 00:16:41,869
I'm gonna give passed 2/3 of the data

00:16:39,319 --> 00:16:45,199
set over for training yeah that's the

00:16:41,869 --> 00:16:49,699
side and remaining third will keep for

00:16:45,199 --> 00:16:51,230
testing okay good good good here comes

00:16:49,699 --> 00:16:53,509
Devon flow Peas okay I'm just gonna

00:16:51,230 --> 00:16:56,089
import that in I'm also gonna important

00:16:53,509 --> 00:16:59,360
other extension from it that the SPARC

00:16:56,089 --> 00:17:04,069
pieces while we're there we'll go to

00:16:59,360 --> 00:17:06,110
will pull in a couple things from sparks

00:17:04,069 --> 00:17:11,149
machine learning library namely a

00:17:06,110 --> 00:17:16,010
decision tree classifier and and and

00:17:11,149 --> 00:17:18,409
also a multi class evaluator okay I'm

00:17:16,010 --> 00:17:22,579
building this little helper function

00:17:18,409 --> 00:17:25,490
here called train and evaluate and it's

00:17:22,579 --> 00:17:28,929
gonna take in two model parameters for

00:17:25,490 --> 00:17:32,929
this decision tree max bins max depth

00:17:28,929 --> 00:17:34,870
okay so here we go I'll start off with

00:17:32,929 --> 00:17:38,440
an ml flow start

00:17:34,870 --> 00:17:40,750
yeah everything following this within

00:17:38,440 --> 00:17:44,320
within that indentation is going to be

00:17:40,750 --> 00:17:47,679
logged by Emma flow okay so I'm gonna

00:17:44,320 --> 00:17:51,039
construct this the constructor for the

00:17:47,679 --> 00:17:54,070
century classifier and pass it these max

00:17:51,039 --> 00:17:57,429
bins max depth parameters which were fed

00:17:54,070 --> 00:18:05,200
into my helper function correct I'm

00:17:57,429 --> 00:18:07,179
going to then train my model fit it that

00:18:05,200 --> 00:18:11,919
is to the training data set data frame

00:18:07,179 --> 00:18:14,590
and out will pop this decision tree

00:18:11,919 --> 00:18:18,460
classifier model do a little print okay

00:18:14,590 --> 00:18:20,230
just for the sanity check and straight

00:18:18,460 --> 00:18:23,230
afterwards we're going to use the same

00:18:20,230 --> 00:18:25,990
model to make predictions on the test

00:18:23,230 --> 00:18:28,990
set okay that's this transform function

00:18:25,990 --> 00:18:32,380
here you can think it was predict as you

00:18:28,990 --> 00:18:35,500
wouldn't say scikit-learn okay so we've

00:18:32,380 --> 00:18:38,559
now made predictions that is or what are

00:18:35,500 --> 00:18:40,659
predicting again the species of the

00:18:38,559 --> 00:18:44,200
flower given the lengths and widths of

00:18:40,659 --> 00:18:47,110
the sepals and petals correct so built a

00:18:44,200 --> 00:18:52,450
model we've made predictions but we need

00:18:47,110 --> 00:18:55,029
a way to basically gauge its performance

00:18:52,450 --> 00:18:57,490
right I'm gonna use two separate metrics

00:18:55,029 --> 00:19:01,240
one being accuracy the other one being

00:18:57,490 --> 00:19:02,980
f1 score you know so yeah we'll have

00:19:01,240 --> 00:19:06,309
those generated that's basically

00:19:02,980 --> 00:19:08,440
comparing the actual species versus the

00:19:06,309 --> 00:19:11,679
predicted ones no different different

00:19:08,440 --> 00:19:14,020
techniques for measuring how well am I

00:19:11,679 --> 00:19:17,260
was performing and then comes all the

00:19:14,020 --> 00:19:19,600
logging okay I'm a flow I'm gonna log

00:19:17,260 --> 00:19:24,120
parameters namely as I said it's just a

00:19:19,600 --> 00:19:27,070
key value pair yeah I'm gonna log those

00:19:24,120 --> 00:19:31,600
those model parameters max bins and max

00:19:27,070 --> 00:19:34,500
depth I'm also going to log to metrics

00:19:31,600 --> 00:19:37,120
that I'm generating accuracy in f1 score

00:19:34,500 --> 00:19:39,340
you know at this point I could even

00:19:37,120 --> 00:19:43,240
logged any sort of other artifact that I

00:19:39,340 --> 00:19:45,370
would like code any images I've

00:19:43,240 --> 00:19:48,700
generated whatnot doesn't matter yeah

00:19:45,370 --> 00:19:51,940
you can log all that I'm also logging

00:19:48,700 --> 00:19:53,770
your model itself in this case it's this

00:19:51,940 --> 00:19:57,910
pipeline model and I'm just giving it a

00:19:53,770 --> 00:19:59,110
name okay so that's my little helper

00:19:57,910 --> 00:20:03,000
function and by the way this thing

00:19:59,110 --> 00:20:05,140
returns the model at the very end okay

00:20:03,000 --> 00:20:08,260
now let's go ahead and put this guy

00:20:05,140 --> 00:20:09,840
let's use it so here we go I'm actually

00:20:08,260 --> 00:20:14,830
going to use this train in value eight

00:20:09,840 --> 00:20:18,370
I'll pass it a max Bin's value of 15 and

00:20:14,830 --> 00:20:22,590
max depth of two and have it build a

00:20:18,370 --> 00:20:22,590
model for me okay

00:20:22,770 --> 00:20:28,510
good good good

00:20:24,370 --> 00:20:30,310
there we go accuracies point nine of1

00:20:28,510 --> 00:20:32,740
scores nine one that's a pretty good

00:20:30,310 --> 00:20:37,360
model can we do better I'm just gonna

00:20:32,740 --> 00:20:40,000
say and go ahead with max depth of three

00:20:37,360 --> 00:20:42,850
just just alter that one value there

00:20:40,000 --> 00:20:43,860
parameter it's a model parameter yeah

00:20:42,850 --> 00:20:51,250
much better

00:20:43,860 --> 00:20:53,800
98% okay I can continue this m4 I

00:20:51,250 --> 00:20:55,090
haven't altered by max bins it looks

00:20:53,800 --> 00:20:58,180
like that didn't make too much of a

00:20:55,090 --> 00:21:00,750
difference there but you know what I've

00:20:58,180 --> 00:21:03,430
already forgotten the first few scores

00:21:00,750 --> 00:21:04,840
but hey that's okay because that's what

00:21:03,430 --> 00:21:07,390
mo flow is doing in the background

00:21:04,840 --> 00:21:09,580
tracking all that activity so here are

00:21:07,390 --> 00:21:12,010
two things within data bricks you

00:21:09,580 --> 00:21:13,600
actually have a little sidebar for ML

00:21:12,010 --> 00:21:17,530
flow will actually keep track of the

00:21:13,600 --> 00:21:19,810
three runs I just ran yeah so actually

00:21:17,530 --> 00:21:22,450
this one point yeah these two are pretty

00:21:19,810 --> 00:21:26,760
similar but better yet there's a whole

00:21:22,450 --> 00:21:31,450
UI so this is part of the ml flow server

00:21:26,760 --> 00:21:35,530
okay give it a second again this is this

00:21:31,450 --> 00:21:38,560
will you would run in your as on your

00:21:35,530 --> 00:21:40,390
CLI it would be Emma flow space UI and

00:21:38,560 --> 00:21:42,250
you get this this environment up and

00:21:40,390 --> 00:21:45,100
running and here you can actually come

00:21:42,250 --> 00:21:47,830
in and compare results right so if I

00:21:45,100 --> 00:21:55,930
want to say let's say sort these guys by

00:21:47,830 --> 00:21:57,700
accuracy I could do that no okay good so

00:21:55,930 --> 00:21:59,830
far but I want to go a little bit

00:21:57,700 --> 00:22:02,210
crazier so so far yeah I've just done

00:21:59,830 --> 00:22:04,869
very simple

00:22:02,210 --> 00:22:07,879
changes of one parameter typically in

00:22:04,869 --> 00:22:09,889
real machine learning work you might

00:22:07,879 --> 00:22:13,909
have dozens of parameters that you want

00:22:09,889 --> 00:22:17,330
to search through to find the the best

00:22:13,909 --> 00:22:20,389
model available right so you wind up

00:22:17,330 --> 00:22:23,389
having a multi dimensional parameter

00:22:20,389 --> 00:22:26,029
space that that you'd like to explore

00:22:23,389 --> 00:22:28,730
through in this case I'm just gonna go

00:22:26,029 --> 00:22:32,840
the two-dimensional one so let me close

00:22:28,730 --> 00:22:34,129
that guy let's do something silly so

00:22:32,840 --> 00:22:35,690
there's a right way of doing this in a

00:22:34,129 --> 00:22:39,409
wrong way I'm gonna do the wrong way

00:22:35,690 --> 00:22:43,940
for the sake of simplicity I'm gonna do

00:22:39,409 --> 00:22:45,769
a brute force search so we'll do a I'm

00:22:43,940 --> 00:22:48,679
gonna actually basically just do a

00:22:45,769 --> 00:22:57,409
couple of four loops per microsecond

00:22:48,679 --> 00:23:08,149
type okay let's do four max bins in the

00:22:57,409 --> 00:23:10,480
range of say 5 to 16 every two for max

00:23:08,149 --> 00:23:10,480
depth

00:23:16,970 --> 00:23:31,650
in the range of two to five let's go

00:23:24,720 --> 00:23:34,470
ahead and run our run our helper

00:23:31,650 --> 00:23:37,500
function okay so I'm actually running

00:23:34,470 --> 00:23:41,760
through how many is that that's gonna be

00:23:37,500 --> 00:23:43,610
five by five by five twenty five runs

00:23:41,760 --> 00:23:47,940
here roughly yeah

00:23:43,610 --> 00:23:49,500
so it's chucking away I don't have to

00:23:47,940 --> 00:23:51,480
pay too much attention here because

00:23:49,500 --> 00:23:53,340
again this is all being tracked I have a

00:23:51,480 --> 00:23:58,230
whole user interface for exploring the

00:23:53,340 --> 00:24:01,500
results in just a second yeah so give it

00:23:58,230 --> 00:24:05,220
a second Bob yeah we're doing a full you

00:24:01,500 --> 00:24:06,630
know a pretty aggressive sweep the right

00:24:05,220 --> 00:24:09,480
way of doing this is to do

00:24:06,630 --> 00:24:11,610
cross-validation while doing your

00:24:09,480 --> 00:24:14,490
parameter tuning and if you're using

00:24:11,610 --> 00:24:16,560
spark ml ml flow will capture all that

00:24:14,490 --> 00:24:21,510
activity as well within your

00:24:16,560 --> 00:24:30,150
cross-validation runs okay and you know

00:24:21,510 --> 00:24:36,240
still going ooh look at that BAM might

00:24:30,150 --> 00:24:38,040
have a champion right there okay okay

00:24:36,240 --> 00:24:41,550
that's done good good good let me jump

00:24:38,040 --> 00:24:45,800
back into my UI now let's do a little

00:24:41,550 --> 00:24:45,800
refresh real quick

00:24:52,750 --> 00:24:59,710
I did know it was arranged it was

00:24:56,170 --> 00:25:02,310
arranged yeah I give it a yeah 5 to 16

00:24:59,710 --> 00:25:06,490
in every two steps intervals in

00:25:02,310 --> 00:25:09,010
increments of 2 via so now we have a

00:25:06,490 --> 00:25:13,630
bunch of runs all right right look at

00:25:09,010 --> 00:25:18,270
that nice I want to compare all these

00:25:13,630 --> 00:25:18,270
guys together now okay

00:25:19,330 --> 00:25:26,530
let's compare so you can actually go in

00:25:21,880 --> 00:25:30,370
and say look at one parameters dimension

00:25:26,530 --> 00:25:32,980
at a time say max depth versus accuracy

00:25:30,370 --> 00:25:35,920
that's fine we see that max depth of 4

00:25:32,980 --> 00:25:37,000
is faring better but what we were but we

00:25:35,920 --> 00:25:39,880
actually were searching a

00:25:37,000 --> 00:25:41,260
two-dimensional space so it makes more

00:25:39,880 --> 00:25:49,950
sense to actually go ahead with a

00:25:41,260 --> 00:25:53,170
contour yeah okay so this is max bins

00:25:49,950 --> 00:25:57,270
actually let me do the round let me do

00:25:53,170 --> 00:25:57,270
that max bins versus max depth

00:25:59,310 --> 00:26:07,960
okay cool yeah okay so where we getting

00:26:05,380 --> 00:26:11,140
high so for we doing we know we're doing

00:26:07,960 --> 00:26:13,330
pretty well says max bins on the on the

00:26:11,140 --> 00:26:15,610
x axis so it looks like there's a few

00:26:13,330 --> 00:26:17,020
scenarios where so we're trying to get

00:26:15,610 --> 00:26:21,010
to the lighter shade right the lighter

00:26:17,020 --> 00:26:23,350
shade meaning accuracy of one so lighter

00:26:21,010 --> 00:26:26,320
is better so it looks like these pockets

00:26:23,350 --> 00:26:29,500
are actually doing pretty well for some

00:26:26,320 --> 00:26:32,170
reason here this whole bit around max

00:26:29,500 --> 00:26:33,850
bins of 13 for some reason isn't faring

00:26:32,170 --> 00:26:36,160
well okay good to know

00:26:33,850 --> 00:26:38,620
we'll avoid that for I mean we should do

00:26:36,160 --> 00:26:43,900
a final model run but yeah we've

00:26:38,620 --> 00:26:46,750
identified sort of corners within our

00:26:43,900 --> 00:26:49,770
multi dimensional parameter space that

00:26:46,750 --> 00:26:56,740
that are good for this specific task

00:26:49,770 --> 00:27:01,000
okay so yeah max depth of 4 and then max

00:26:56,740 --> 00:27:04,570
bins anything above say 13 good okay

00:27:01,000 --> 00:27:06,050
that's that's a little demo um so with

00:27:04,570 --> 00:27:08,810
with with it without

00:27:06,050 --> 00:27:12,290
managed version within data bricks you

00:27:08,810 --> 00:27:13,820
still get all this demo flow UI you just

00:27:12,290 --> 00:27:15,380
don't have a you just have a you know

00:27:13,820 --> 00:27:20,090
you just doing a localhost

00:27:15,380 --> 00:27:23,720
I think that's fine 5000 M and yeah

00:27:20,090 --> 00:27:26,840
that's it thank you very much and by the

00:27:23,720 --> 00:27:31,160
way I'm so you can find me on LinkedIn

00:27:26,840 --> 00:27:36,080
github and Twitter I have posted all the

00:27:31,160 --> 00:27:39,920
slides and the demo code on github so if

00:27:36,080 --> 00:27:40,490
you go to this to my github repo my get

00:27:39,920 --> 00:27:43,970
my account

00:27:40,490 --> 00:27:46,430
there's a false Asia 2020 demos repo the

00:27:43,970 --> 00:27:49,600
slides and the the code are all there

00:27:46,430 --> 00:27:49,600

YouTube URL: https://www.youtube.com/watch?v=KWsMq__QItA


