Title: AI, Cloud, Blockchain and the Conversational Web: Where is it all going? - FOSSASIA 2018
Publication date: 2018-03-31
Playlist: FOSSASIA Summit 2018 - Blockchain
Description: 
	Panelists:

- Frank Karlitschek, Founder Nextcloud
- Liang Moung, Head of Digital Technology Singapore Press Holdings
- Ramji Venkateswaran, Global Head of Cloud Ecosystem Development & Head of Cloud Services Asia J.P. Morgan
- Dr Graham Williams, Data Science Director, APAC - Microsoft

Moderator: Mario Behling, Co-Founder FOSSASIA

At the leadership opening panel of the FOSSASIA Summit we bring technologists, developers and digital journalists together who will help us to understand what where we are heading with this rapid change. Where are opportunities, where are challenges? Panelists will provide insights from their personal perspective and their daily work. What will distinguish us from machines in future? What do we need to learn to stay ahead of the competition? What tools and technologies are most promising? Does everyone need to be a coder in future? And how can Open Technologies help us?

Room: Lecture Theatre
Track: Artificial Intelligence
Date: Thursday, 22nd March, 2018
Info: https://2018.fossasia.org/event/tracks.html#4597

Event Page: https://2018.fossasia.org
Follow FOSSASIA on Twitter: https://twitter.com/fossasia/
Like FOSSASIA on Facebook: https://www.facebook.com/fossasia/ 

Produced by Engineers.SG
Captions: 
	00:00:00,800 --> 00:00:05,790
okay thank you thank you Harris

00:00:03,210 --> 00:00:07,470
Tim yeah well it's been very interesting

00:00:05,790 --> 00:00:09,210
so far I would see a lot of people

00:00:07,470 --> 00:00:12,509
coming in and then like it's a lot of

00:00:09,210 --> 00:00:14,940
back and forth and so awesome here to

00:00:12,509 --> 00:00:16,859
see all this activity and the

00:00:14,940 --> 00:00:19,800
interesting talk so far and I'm very

00:00:16,859 --> 00:00:23,600
pleased to go into more depth now and

00:00:19,800 --> 00:00:26,689
with our next topic which is next slide

00:00:23,600 --> 00:00:29,010
artificial intelligence cloud blockchain

00:00:26,689 --> 00:00:31,349
please take out the s and the

00:00:29,010 --> 00:00:35,250
conversational weapon where is it all

00:00:31,349 --> 00:00:39,180
going so that's the big question here

00:00:35,250 --> 00:00:42,360
where are we heading Harris just had a

00:00:39,180 --> 00:00:44,730
few ideas of his own so we will get back

00:00:42,360 --> 00:00:48,059
to this later and but I would like to

00:00:44,730 --> 00:00:50,430
and ask to invite some of our panelists

00:00:48,059 --> 00:00:53,190
or all of our panelists of course here

00:00:50,430 --> 00:00:54,840
on the stage and introduce them to you

00:00:53,190 --> 00:00:57,210
they're coming from all over the world

00:00:54,840 --> 00:00:59,309
so please give them a big round of

00:00:57,210 --> 00:01:01,859
applause when they are coming and I

00:00:59,309 --> 00:01:03,480
would like the first one to ask to join

00:01:01,859 --> 00:01:07,439
us here Ramji

00:01:03,480 --> 00:01:10,729
Venkatesh Veron we practice a bit first

00:01:07,439 --> 00:01:13,380
Ramji please join us you're on stage so

00:01:10,729 --> 00:01:18,930
yes it's your plans come on given a bit

00:01:13,380 --> 00:01:23,970
more please like sure yes okay thank you

00:01:18,930 --> 00:01:26,610
rob ji so um Ramji has benefitted from

00:01:23,970 --> 00:01:28,460
having worked alongside and to have been

00:01:26,610 --> 00:01:33,180
mentored by some incredibly talented

00:01:28,460 --> 00:01:35,640
talented and nurturing folks without one

00:01:33,180 --> 00:01:37,860
what professional good fortune he had

00:01:35,640 --> 00:01:40,079
wouldn't have been squandered unwisely

00:01:37,860 --> 00:01:42,810
and this is what you write on your

00:01:40,079 --> 00:01:45,689
LinkedIn profile and yeah I couldn't

00:01:42,810 --> 00:01:47,700
agree more and yeah you have a very

00:01:45,689 --> 00:01:49,470
interesting career you're currently the

00:01:47,700 --> 00:01:50,939
global head of cloud ecosystem

00:01:49,470 --> 00:01:55,200
development and head of cloud services

00:01:50,939 --> 00:01:58,500
Asia at JPMorgan so yeah we will also

00:01:55,200 --> 00:02:00,660
get to the security aspect here when we

00:01:58,500 --> 00:02:03,330
we'll have the conversation in a moment

00:02:00,660 --> 00:02:07,800
and you have worked for Goldman and

00:02:03,330 --> 00:02:10,080
Sachs but your background is mainly like

00:02:07,800 --> 00:02:13,560
technical you have been involved in

00:02:10,080 --> 00:02:16,470
architect in architectural aspects of IT

00:02:13,560 --> 00:02:20,550
and but not just technical you have also

00:02:16,470 --> 00:02:22,500
been involved in a photography studio in

00:02:20,550 --> 00:02:27,780
Manhattan you've been linked in stalking

00:02:22,500 --> 00:02:30,270
me yeah I yeah and so I love that so

00:02:27,780 --> 00:02:32,190
that's actually a very good example for

00:02:30,270 --> 00:02:34,260
the community that we have here like

00:02:32,190 --> 00:02:36,060
people like who engaged in lots of

00:02:34,260 --> 00:02:38,459
different projects different aspects and

00:02:36,060 --> 00:02:41,010
so on so it's great to connect you and

00:02:38,459 --> 00:02:42,209
connect you with you on this panel thank

00:02:41,010 --> 00:02:50,700
you very much for joining us thank you

00:02:42,209 --> 00:02:53,730
for the welcome the next one I would

00:02:50,700 --> 00:03:00,150
like to invite is Miss young mone

00:02:53,730 --> 00:03:02,430
yes hello thank you very much young man

00:03:00,150 --> 00:03:04,080
it was one of the pioneers who

00:03:02,430 --> 00:03:06,480
spearheaded the digital media and

00:03:04,080 --> 00:03:08,640
business at a singapore press holding

00:03:06,480 --> 00:03:11,160
she is currently the head of digital

00:03:08,640 --> 00:03:12,989
technology and leads a high performing

00:03:11,160 --> 00:03:15,060
engineering team to develop and support

00:03:12,989 --> 00:03:18,989
the various web sites and mobile

00:03:15,060 --> 00:03:21,299
applications for SPH flagship new brands

00:03:18,989 --> 00:03:23,880
including this straight times young

00:03:21,299 --> 00:03:25,739
heads are power and so on her team is

00:03:23,880 --> 00:03:28,500
also responsible for technology

00:03:25,739 --> 00:03:36,769
exploration and innovations thank you

00:03:28,500 --> 00:03:40,380
very much for joining us the next one is

00:03:36,769 --> 00:03:47,250
doctor grayham williams please come on

00:03:40,380 --> 00:03:49,530
stage and some of you might remember mr.

00:03:47,250 --> 00:03:51,870
Williams from last year and they have

00:03:49,530 --> 00:03:55,440
also been a lot of meetups here so

00:03:51,870 --> 00:03:57,360
actually the the conversation that we

00:03:55,440 --> 00:04:01,170
have here is a kind of a continuation of

00:03:57,360 --> 00:04:02,940
what we've started last year and dr.

00:04:01,170 --> 00:04:06,269
Williams is director of data science

00:04:02,940 --> 00:04:09,790
cloudy eye and research and at Microsoft

00:04:06,269 --> 00:04:12,040
asia-pacific and his background is the

00:04:09,790 --> 00:04:14,890
like he's been to the australian

00:04:12,040 --> 00:04:17,290
national university and he leads a team

00:04:14,890 --> 00:04:20,019
delivering innovative cutting-edge AI

00:04:17,290 --> 00:04:24,070
and machine learning to the enterprise

00:04:20,019 --> 00:04:26,770
and developing tomorrow's advances in AI

00:04:24,070 --> 00:04:30,190
so very interesting to talk to you about

00:04:26,770 --> 00:04:33,550
the future of AI and your background is

00:04:30,190 --> 00:04:37,360
open source software since the 80s I

00:04:33,550 --> 00:04:39,820
can't read out everything here but you

00:04:37,360 --> 00:04:42,340
have been involved already in the 80s as

00:04:39,820 --> 00:04:45,419
a data scientist I think a lot of people

00:04:42,340 --> 00:04:49,840
didn't know the word back then yeah and

00:04:45,419 --> 00:04:54,280
yeah so you've been you're originally

00:04:49,840 --> 00:04:58,960
from Australia and from the University

00:04:54,280 --> 00:05:01,380
of Canberra and in 1984 you've been

00:04:58,960 --> 00:05:04,990
involved in the project for he makes a

00:05:01,380 --> 00:05:09,220
package managing packaging as a package

00:05:04,990 --> 00:05:16,419
manager sorry so okay so welcome mister

00:05:09,220 --> 00:05:18,699
doctor grayham williams and the last one

00:05:16,419 --> 00:05:21,820
we have here but not the least of course

00:05:18,699 --> 00:05:25,070
is Frank Frank Carly chick from next

00:05:21,820 --> 00:05:28,149
cloud in Germany welcome

00:05:25,070 --> 00:05:28,149
[Music]

00:05:28,919 --> 00:05:33,940
so Frank has been a keynote speaker at

00:05:32,139 --> 00:05:36,550
for Asia last year but he has also

00:05:33,940 --> 00:05:39,130
spoken at the open source summit in the

00:05:36,550 --> 00:05:41,979
US and many other events he is the face

00:05:39,130 --> 00:05:44,470
of next cloud as the founder of course

00:05:41,979 --> 00:05:47,530
as well and some might also know him as

00:05:44,470 --> 00:05:50,860
the founder of own cloud years agone so

00:05:47,530 --> 00:05:53,169
next cloud is the successor and but

00:05:50,860 --> 00:05:56,409
Frank is not only like his German by the

00:05:53,169 --> 00:05:58,120
way and has not only lived in Germany

00:05:56,409 --> 00:06:00,039
though you have also lived several years

00:05:58,120 --> 00:06:07,510
in the u.s. in the Greater Boston area

00:06:00,039 --> 00:06:10,479
and worked for him 5:01 yes so pay some

00:06:07,510 --> 00:06:12,340
stuttgart by the way so good opportunity

00:06:10,479 --> 00:06:13,840
to connect with Daimler then as well and

00:06:12,340 --> 00:06:17,110
stood guard as there also based on

00:06:13,840 --> 00:06:19,870
shortcut so yeah let's start the

00:06:17,110 --> 00:06:21,180
conversation next cloud is an open

00:06:19,870 --> 00:06:24,070
source

00:06:21,180 --> 00:06:26,410
solution yeah or maybe you explained it

00:06:24,070 --> 00:06:30,490
yourself what what is next cloud and how

00:06:26,410 --> 00:06:33,790
they do use AI in next cloud what is AI

00:06:30,490 --> 00:06:36,010
and next cloud thanks a lot

00:06:33,790 --> 00:06:37,570
try to be here by the way that's one of

00:06:36,010 --> 00:06:40,260
my favorite conferences here it's really

00:06:37,570 --> 00:06:44,500
an honor to be here back this year so

00:06:40,260 --> 00:06:47,830
next cloud is an alternative to Dropbox

00:06:44,500 --> 00:06:49,360
and office 365 and Google suite with the

00:06:47,830 --> 00:06:51,670
main difference that is hundred percent

00:06:49,360 --> 00:06:53,140
free software open source of course so

00:06:51,670 --> 00:06:55,420
that's one free software conference here

00:06:53,140 --> 00:06:57,070
so it should be obvious so you can

00:06:55,420 --> 00:07:00,040
actually run it wherever you want which

00:06:57,070 --> 00:07:02,050
is nowadays really important if you want

00:07:00,040 --> 00:07:04,540
to protect your data you want to run it

00:07:02,050 --> 00:07:06,220
in every in a trusted hosting Center it

00:07:04,540 --> 00:07:08,230
really runs from a small device like a

00:07:06,220 --> 00:07:10,720
Raspberry Pi at home if you want

00:07:08,230 --> 00:07:12,910
most companies or universities run it

00:07:10,720 --> 00:07:14,590
off obviously in a bigger instance and

00:07:12,910 --> 00:07:16,240
the biggest instance at the moment is

00:07:14,590 --> 00:07:17,980
for a service provider for 20 million

00:07:16,240 --> 00:07:20,980
users so everything from very small to

00:07:17,980 --> 00:07:23,890
very big I'm actually very very proud

00:07:20,980 --> 00:07:25,930
that that next cloud is Hana peasant

00:07:23,890 --> 00:07:28,210
open source it's done by an really

00:07:25,930 --> 00:07:30,730
active community so the last release we

00:07:28,210 --> 00:07:32,500
had according to our statistics over 500

00:07:30,730 --> 00:07:35,170
people from all our work contributed to

00:07:32,500 --> 00:07:37,660
it so it's one of the very most active

00:07:35,170 --> 00:07:40,510
and vibrant open source communities and

00:07:37,660 --> 00:07:42,460
we also have a company very often

00:07:40,510 --> 00:07:44,440
services and support around it but you

00:07:42,460 --> 00:07:46,720
have like 40 people based and stupid at

00:07:44,440 --> 00:07:49,390
the moment again with 100% open source

00:07:46,720 --> 00:07:51,480
business model so similar to companies

00:07:49,390 --> 00:07:54,070
like red head for example which are

00:07:51,480 --> 00:07:55,510
supposed to charge here obviously so

00:07:54,070 --> 00:08:01,000
hundred percent open source business

00:07:55,510 --> 00:08:02,830
model okay thank you very much for these

00:08:01,000 --> 00:08:05,860
insights I would like to make it first

00:08:02,830 --> 00:08:11,620
round because before we go into the

00:08:05,860 --> 00:08:14,530
conversation in deeper and gray we know

00:08:11,620 --> 00:08:16,630
a lot of products from Microsoft and

00:08:14,530 --> 00:08:19,510
it's been fantastic last year to hear

00:08:16,630 --> 00:08:21,130
how Microsoft is engaging more and more

00:08:19,510 --> 00:08:24,340
in in the open source and free software

00:08:21,130 --> 00:08:27,940
community and what's happening in this

00:08:24,340 --> 00:08:29,320
area of AI of cloud services and so on

00:08:27,940 --> 00:08:34,880
with

00:08:29,320 --> 00:08:36,110
in Microsoft so thank you so what's

00:08:34,880 --> 00:08:38,930
happening I mean that there's an

00:08:36,110 --> 00:08:41,360
enormous amount of activity and

00:08:38,930 --> 00:08:45,080
excitement across across Microsoft

00:08:41,360 --> 00:08:48,380
across many of the the larger vendors

00:08:45,080 --> 00:08:52,040
worldwide all around the the development

00:08:48,380 --> 00:08:54,320
of AI and machine learning so I've been

00:08:52,040 --> 00:08:57,260
in in the AI space machine learning

00:08:54,320 --> 00:08:59,780
since since the 1980s and and this is

00:08:57,260 --> 00:09:03,190
really the third so I'd say it's the

00:08:59,780 --> 00:09:06,530
fourth surge of interest in AI and

00:09:03,190 --> 00:09:08,450
actually each surge we get a lot of the

00:09:06,530 --> 00:09:10,370
same questions some is this the end of

00:09:08,450 --> 00:09:14,770
the world will they I take over and so

00:09:10,370 --> 00:09:17,900
on and I'm with our previous commentator

00:09:14,770 --> 00:09:22,280
from read out saying you know AI is

00:09:17,900 --> 00:09:24,170
going to augment what we do now it's not

00:09:22,280 --> 00:09:26,990
going to take over it's going to be

00:09:24,170 --> 00:09:31,460
augmented intelligence and the work that

00:09:26,990 --> 00:09:34,340
we're doing in Microsoft is and actually

00:09:31,460 --> 00:09:36,170
before I joined Microsoft most of the

00:09:34,340 --> 00:09:40,010
work that I was doing was based on

00:09:36,170 --> 00:09:41,750
trying to share what we learn so I come

00:09:40,010 --> 00:09:44,120
from both the AI machine learning

00:09:41,750 --> 00:09:45,950
research community but also a very

00:09:44,120 --> 00:09:49,220
strong contributor to open source

00:09:45,950 --> 00:09:51,680
software over my career as as Maria

00:09:49,220 --> 00:09:54,260
mentioned starting in the 1980s with

00:09:51,680 --> 00:09:57,740
before open source was even thought of

00:09:54,260 --> 00:10:00,730
as I guess a concept we just set up FTP

00:09:57,740 --> 00:10:03,380
servers and put our software on there a

00:10:00,730 --> 00:10:05,030
package manager for Emacs was something

00:10:03,380 --> 00:10:07,760
that we worked on at the ANU in

00:10:05,030 --> 00:10:10,130
Australia packages for the tech

00:10:07,760 --> 00:10:12,320
typesetting system that we made and

00:10:10,130 --> 00:10:15,470
shared freely available through FTP

00:10:12,320 --> 00:10:19,690
servers so open source has really been

00:10:15,470 --> 00:10:23,870
part of my makeup for all of my career

00:10:19,690 --> 00:10:26,470
my most widely used package is something

00:10:23,870 --> 00:10:29,180
called rattle for the our software

00:10:26,470 --> 00:10:30,980
statistical software all open source for

00:10:29,180 --> 00:10:33,260
doing data science and data mining and

00:10:30,980 --> 00:10:36,250
the focus has always been how do we

00:10:33,260 --> 00:10:39,950
share what we learn what we discover and

00:10:36,250 --> 00:10:40,780
allow others to build on what has come

00:10:39,950 --> 00:10:43,150
before

00:10:40,780 --> 00:10:44,920
an open source just provides such a

00:10:43,150 --> 00:10:46,990
great model for doing that and some of

00:10:44,920 --> 00:10:48,580
our earlier speakers have highlighted

00:10:46,990 --> 00:10:50,560
that as well building on the shoulders

00:10:48,580 --> 00:10:53,920
of those who come before us and that

00:10:50,560 --> 00:10:58,480
it's so important to the future of all

00:10:53,920 --> 00:11:01,270
of us and and of society um it is such a

00:10:58,480 --> 00:11:05,020
shame I think over the history of our

00:11:01,270 --> 00:11:07,210
computer all vendors of many products

00:11:05,020 --> 00:11:09,760
coming to the market and then

00:11:07,210 --> 00:11:11,680
disappearing and being reinvented and

00:11:09,760 --> 00:11:15,040
rediscovered over and over again there's

00:11:11,680 --> 00:11:17,350
so much intellectual capital that goes

00:11:15,040 --> 00:11:20,440
into that so what we're trying to do in

00:11:17,350 --> 00:11:25,180
Microsoft is how do we enable and

00:11:20,440 --> 00:11:27,490
empower everyone to do to achieve so

00:11:25,180 --> 00:11:29,980
much more with the technology that we

00:11:27,490 --> 00:11:32,500
have available everyone on the planet is

00:11:29,980 --> 00:11:34,840
as Satya likes to say how do we empower

00:11:32,500 --> 00:11:39,310
every person and every organization to

00:11:34,840 --> 00:11:42,580
do more and we have a real focus in our

00:11:39,310 --> 00:11:44,560
data science team on capturing what we

00:11:42,580 --> 00:11:46,030
learn is practicing data scientists

00:11:44,560 --> 00:11:49,390
developing new machine learning

00:11:46,030 --> 00:11:52,660
algorithms and exposing that openly

00:11:49,390 --> 00:11:55,330
through github repositories through

00:11:52,660 --> 00:11:56,890
documentation repositories our code is

00:11:55,330 --> 00:12:00,460
available in the open-source community

00:11:56,890 --> 00:12:03,940
to replicate the work that we do but

00:12:00,460 --> 00:12:05,860
we're making available algorithms to

00:12:03,940 --> 00:12:09,030
build your models your machine learning

00:12:05,860 --> 00:12:11,890
models we're making available the

00:12:09,030 --> 00:12:14,020
platform to execute those models and

00:12:11,890 --> 00:12:18,250
recent announcements from Microsoft and

00:12:14,020 --> 00:12:20,440
other vendors around particularly around

00:12:18,250 --> 00:12:23,230
Windows and incorporating a machine

00:12:20,440 --> 00:12:26,770
learning execution capability in the

00:12:23,230 --> 00:12:29,200
operating system itself so that the

00:12:26,770 --> 00:12:32,770
models that we build can be shared

00:12:29,200 --> 00:12:34,150
openly and execute on those platforms so

00:12:32,770 --> 00:12:37,270
we've got a real focus not only on

00:12:34,150 --> 00:12:39,080
developing new algorithms and technology

00:12:37,270 --> 00:12:42,170
but making that available

00:12:39,080 --> 00:12:44,450
empowering everyone empowering everyone

00:12:42,170 --> 00:12:47,390
is part of them but there's also what is

00:12:44,450 --> 00:12:50,960
going to be next in AI and it's real

00:12:47,390 --> 00:12:53,270
focus around what's beyond deep learning

00:12:50,960 --> 00:12:55,970
deep learning ai surge at the moment

00:12:53,270 --> 00:12:58,250
massive compute with massive data what's

00:12:55,970 --> 00:13:00,700
beyond that neural networks as our

00:12:58,250 --> 00:13:02,870
previous speaker noted is old technology

00:13:00,700 --> 00:13:06,800
there's a lot of new developments but

00:13:02,870 --> 00:13:09,140
it's old technology what else from the

00:13:06,800 --> 00:13:11,080
history of AI is going to come to the

00:13:09,140 --> 00:13:14,090
fore and one of those things I think is

00:13:11,080 --> 00:13:15,800
more knowledge and discovery we don't

00:13:14,090 --> 00:13:17,590
know what a neural network is really

00:13:15,800 --> 00:13:20,630
doing it's an incredibly complex

00:13:17,590 --> 00:13:24,260
mathematical formula where do we get the

00:13:20,630 --> 00:13:26,960
knowledge from that what discoveries do

00:13:24,260 --> 00:13:28,730
we make by building your network models

00:13:26,960 --> 00:13:32,870
they work incredibly well they appear to

00:13:28,730 --> 00:13:34,970
be intelligent but we need to go beyond

00:13:32,870 --> 00:13:37,880
that to discover knowledge and then use

00:13:34,970 --> 00:13:40,250
reasoning to work with what we've

00:13:37,880 --> 00:13:42,410
discovered to reason about the world

00:13:40,250 --> 00:13:44,200
that we're interacting in so we're good

00:13:42,410 --> 00:13:47,480
starting to see the emergence of new

00:13:44,200 --> 00:13:50,030
other areas of AI that benefit from

00:13:47,480 --> 00:13:53,750
massive data and massive compute in this

00:13:50,030 --> 00:13:57,620
area thank you so thank you very much

00:13:53,750 --> 00:14:02,960
you gave a very good keyword for this

00:13:57,620 --> 00:14:06,410
young because data and of course you are

00:14:02,960 --> 00:14:08,390
connected with a lot of customers a lot

00:14:06,410 --> 00:14:10,910
of readers for example on your websites

00:14:08,390 --> 00:14:14,270
and also journals so you have a lot of

00:14:10,910 --> 00:14:17,330
data and how do you analyze this data

00:14:14,270 --> 00:14:20,200
how do you use it already and are there

00:14:17,330 --> 00:14:24,740
already applications like we say ok we

00:14:20,200 --> 00:14:27,230
analyze it in and use AI to to improve

00:14:24,740 --> 00:14:29,780
what we provide to customers or how do

00:14:27,230 --> 00:14:33,080
you how do you use it what insights can

00:14:29,780 --> 00:14:36,230
you give us to your work well as much as

00:14:33,080 --> 00:14:37,940
a business organization so we ran our we

00:14:36,230 --> 00:14:39,680
were very careful about bottom line and

00:14:37,940 --> 00:14:41,939
profitability so the way we view

00:14:39,680 --> 00:14:44,069
technologies is how it can

00:14:41,939 --> 00:14:45,689
increase revenue or increase user

00:14:44,069 --> 00:14:47,999
engagement so you're right we have lots

00:14:45,689 --> 00:14:51,839
of data in our organization like content

00:14:47,999 --> 00:14:54,299
so when my team embarked on this no AI

00:14:51,839 --> 00:14:55,679
and all this emerging technology we

00:14:54,299 --> 00:14:57,569
really look at how it can apply across

00:14:55,679 --> 00:14:59,549
the media value chain so broadly

00:14:57,569 --> 00:15:01,169
speaking we look at media value chain as

00:14:59,549 --> 00:15:03,359
the news gathering the content

00:15:01,169 --> 00:15:04,739
production stage now in this stage where

00:15:03,359 --> 00:15:06,749
our reporters write stories

00:15:04,739 --> 00:15:09,419
we are looking at tools where they can

00:15:06,749 --> 00:15:12,899
scan all the social media to see what

00:15:09,419 --> 00:15:15,149
are the most buzz what are the stories

00:15:12,899 --> 00:15:17,579
that disagree we also looking into robot

00:15:15,149 --> 00:15:19,289
journalism right now in the content

00:15:17,579 --> 00:15:20,549
distribution station not after content

00:15:19,289 --> 00:15:22,379
is being produced we need to distribute

00:15:20,549 --> 00:15:24,209
now that's where a lot of challenges we

00:15:22,379 --> 00:15:26,389
used to be just a print company now we

00:15:24,209 --> 00:15:30,359
have websites and mobile apps but

00:15:26,389 --> 00:15:32,039
readers like you don't expect this kind

00:15:30,359 --> 00:15:33,269
of a usual channel to receive the news

00:15:32,039 --> 00:15:36,149
so they are now looking at voice

00:15:33,269 --> 00:15:37,229
assisted devices or various other ways

00:15:36,149 --> 00:15:39,149
that they can get their news and they

00:15:37,229 --> 00:15:42,479
want news to be personalized they want

00:15:39,149 --> 00:15:44,339
news that you know they want so this is

00:15:42,479 --> 00:15:46,859
where content recommendation using AI a

00:15:44,339 --> 00:15:50,099
machine learning come into play so when

00:15:46,859 --> 00:15:52,199
we tried machine learning data based on

00:15:50,099 --> 00:15:54,019
news content to be able to do topic

00:15:52,199 --> 00:15:56,819
modeling or something that we were very

00:15:54,019 --> 00:16:00,209
excited about we have the content use

00:15:56,819 --> 00:16:02,099
the data to be able to do a Content

00:16:00,209 --> 00:16:05,069
recommender that can you know recommend

00:16:02,099 --> 00:16:08,129
based on user behavior was something

00:16:05,069 --> 00:16:10,799
that really you know talked to us a step

00:16:08,129 --> 00:16:12,119
back we suddenly realized that yes we

00:16:10,799 --> 00:16:14,699
have user data but we have not been

00:16:12,119 --> 00:16:16,409
keeping it in a very usable manner so

00:16:14,699 --> 00:16:19,799
this is the the stage that we are right

00:16:16,409 --> 00:16:21,569
now that we suddenly also realized that

00:16:19,799 --> 00:16:23,789
the newspaper business is not longer

00:16:21,569 --> 00:16:25,679
just going to be a Content business you

00:16:23,789 --> 00:16:28,859
know our real ambition is to become a

00:16:25,679 --> 00:16:30,329
data company where we know our users

00:16:28,859 --> 00:16:32,759
very well from the various touch points

00:16:30,329 --> 00:16:34,859
and then use those data to bring more

00:16:32,759 --> 00:16:36,629
revenue to the company so it still

00:16:34,859 --> 00:16:40,229
touching it and then the last stages of

00:16:36,629 --> 00:16:43,139
cost content and all analysis how do you

00:16:40,229 --> 00:16:45,050
get insights from all this content so we

00:16:43,139 --> 00:16:49,470
also applying something

00:16:45,050 --> 00:16:52,230
yeah yeah okay well thank you very much

00:16:49,470 --> 00:16:54,240
and and yes I mean like we want to hear

00:16:52,230 --> 00:16:56,700
more of course also about the products

00:16:54,240 --> 00:17:03,930
you are using in a moment but like let's

00:16:56,700 --> 00:17:06,150
move on first to the banks right so I'm

00:17:03,930 --> 00:17:09,180
hearing about data but I'm also hearing

00:17:06,150 --> 00:17:13,470
like concerns about security and so on

00:17:09,180 --> 00:17:15,390
and what is your company doing you know

00:17:13,470 --> 00:17:17,459
what is JP Morgan doing what what what

00:17:15,390 --> 00:17:17,910
is your work what is involved in your

00:17:17,459 --> 00:17:19,500
work

00:17:17,910 --> 00:17:21,449
thanks very much first of all thanks

00:17:19,500 --> 00:17:24,270
very much for having us here

00:17:21,449 --> 00:17:26,220
it's an incredible event and I think a

00:17:24,270 --> 00:17:28,350
whole bunch of my my team will be around

00:17:26,220 --> 00:17:29,490
in the next few days I've seen them

00:17:28,350 --> 00:17:32,310
walking around the smiles in their faces

00:17:29,490 --> 00:17:33,630
just to be involved as 12 tracks but

00:17:32,310 --> 00:17:34,140
here which is more than I've seen for a

00:17:33,630 --> 00:17:36,000
long time

00:17:34,140 --> 00:17:37,740
highly nerdy content and you mentioned

00:17:36,000 --> 00:17:39,180
architecture embrace other words I stood

00:17:37,740 --> 00:17:41,370
off my career being a network nerd an

00:17:39,180 --> 00:17:43,590
ISP I mean it's not through industries

00:17:41,370 --> 00:17:45,420
when it comes down to being around the

00:17:43,590 --> 00:17:47,400
kind of subject matter that I really get

00:17:45,420 --> 00:17:49,860
exposed to conferences I'm really glad

00:17:47,400 --> 00:17:52,200
to get this one so um coming onto that

00:17:49,860 --> 00:17:55,470
as a personal note aside JPMorgan is a

00:17:52,200 --> 00:17:57,660
as a company and I I'm lucky enough to

00:17:55,470 --> 00:18:00,030
represent it in I guess with two hats

00:17:57,660 --> 00:18:02,070
one of which is to be responsible for a

00:18:00,030 --> 00:18:03,120
chunk of work we call cloud ecosystem

00:18:02,070 --> 00:18:05,970
development which is about how do you

00:18:03,120 --> 00:18:07,980
actually make the use of cloud as a

00:18:05,970 --> 00:18:09,360
substrate meaningful to the people

00:18:07,980 --> 00:18:11,790
within the bank who actually have to do

00:18:09,360 --> 00:18:13,740
bank related work and it's really about

00:18:11,790 --> 00:18:16,500
the concept of undifferentiated heavy

00:18:13,740 --> 00:18:18,720
lifting you and why does everybody have

00:18:16,500 --> 00:18:20,100
to know how to build a VM if what you

00:18:18,720 --> 00:18:22,830
really want to do is price a bond that

00:18:20,100 --> 00:18:25,950
sort of question and then I'm

00:18:22,830 --> 00:18:28,020
responsible for strategy and delivery of

00:18:25,950 --> 00:18:30,300
the hybrid strategy in Asia so that's

00:18:28,020 --> 00:18:33,630
really how do we how we using cloud are

00:18:30,300 --> 00:18:34,470
our customers data being thought about

00:18:33,630 --> 00:18:36,679
how we make

00:18:34,470 --> 00:18:39,270
that we're exactly to your point

00:18:36,679 --> 00:18:40,650
protecting the firm at all opportunities

00:18:39,270 --> 00:18:42,270
and therefore implicitly protecting our

00:18:40,650 --> 00:18:44,730
customers and I think there's an

00:18:42,270 --> 00:18:45,870
interesting implicit point in a lot of

00:18:44,730 --> 00:18:49,289
what people have been talking about

00:18:45,870 --> 00:18:51,539
which is I read the other week someone

00:18:49,289 --> 00:18:54,059
said it far better than me that so data

00:18:51,539 --> 00:18:55,860
is a new currency in essence I mean yes

00:18:54,059 --> 00:18:57,179
there's bitcoins and blockchains and all

00:18:55,860 --> 00:18:58,530
these other kind of bits night I'm

00:18:57,179 --> 00:19:00,150
always amused by the fact that if we had

00:18:58,530 --> 00:19:02,280
design thinking and something else onto

00:19:00,150 --> 00:19:04,409
the other thing we have here we've

00:19:02,280 --> 00:19:07,130
become fully buzzword compliant but from

00:19:04,409 --> 00:19:09,720
a pragmatic perspective data is now

00:19:07,130 --> 00:19:12,990
something that we need to protect but

00:19:09,720 --> 00:19:14,250
the value of it goes to very minimal

00:19:12,990 --> 00:19:16,080
once it's been breached

00:19:14,250 --> 00:19:17,850
so unlike gold so if you steal a bar of

00:19:16,080 --> 00:19:20,100
gold it's very hard to duplicate er you

00:19:17,850 --> 00:19:22,110
gotta go mined more gold our data is

00:19:20,100 --> 00:19:25,799
incredibly easy to duplicate so a

00:19:22,110 --> 00:19:28,080
customer data especially but any data is

00:19:25,799 --> 00:19:29,309
very important to protect and we put

00:19:28,080 --> 00:19:31,289
that at the heart of a lot of our

00:19:29,309 --> 00:19:33,000
strategies and we'll talk about that

00:19:31,289 --> 00:19:35,280
more I suspect but it's going to be very

00:19:33,000 --> 00:19:38,220
important as we think about moving into

00:19:35,280 --> 00:19:42,150
a more and more autonomous future where

00:19:38,220 --> 00:19:45,080
we're expecting processes to

00:19:42,150 --> 00:19:47,490
independently think about analyzing data

00:19:45,080 --> 00:19:48,960
based on triggers and signals which

00:19:47,490 --> 00:19:51,480
we're again not gonna be human

00:19:48,960 --> 00:19:54,500
initiative how we think about access to

00:19:51,480 --> 00:19:58,770
data and information for these processes

00:19:54,500 --> 00:20:02,159
okay thank you and yes but I would like

00:19:58,770 --> 00:20:05,309
to get more into this point like what is

00:20:02,159 --> 00:20:06,929
JP Morgan doing in this area what what

00:20:05,309 --> 00:20:08,880
are your next steps like so so we are

00:20:06,929 --> 00:20:11,940
talking about the future is like this

00:20:08,880 --> 00:20:14,370
big thing that will happen at one point

00:20:11,940 --> 00:20:18,179
to all of us and but like you are

00:20:14,370 --> 00:20:19,919
sitting in the office yeah and note I

00:20:18,179 --> 00:20:21,480
think it's interesting so so JP Morgan

00:20:19,919 --> 00:20:25,559
for folks that aren't familiar and I

00:20:21,480 --> 00:20:28,260
know that we're a very much a North

00:20:25,559 --> 00:20:29,900
America retail brand so that's it's well

00:20:28,260 --> 00:20:33,059
known but also I guess in asia-pacific

00:20:29,900 --> 00:20:34,770
folks will have heard of us I hope but

00:20:33,059 --> 00:20:35,490
we are a hundred billion dollar

00:20:34,770 --> 00:20:37,230
financial

00:20:35,490 --> 00:20:39,360
as company and we spend about 10 billion

00:20:37,230 --> 00:20:41,370
dollars a year on technology and I think

00:20:39,360 --> 00:20:42,600
this is one of these interesting I hate

00:20:41,370 --> 00:20:44,460
throwing numbers out like this but I

00:20:42,600 --> 00:20:46,290
wouldn't looked it up on the chart and

00:20:44,460 --> 00:20:49,050
it makes us slightly smaller than

00:20:46,290 --> 00:20:50,610
Ecuador as a country goes the amount of

00:20:49,050 --> 00:20:54,210
money we spend on tech and it's kind of

00:20:50,610 --> 00:20:55,620
mind-boggling so what are we doing is

00:20:54,210 --> 00:20:58,260
not an easy question to answer I'm

00:20:55,620 --> 00:21:00,300
afraid but let me give you a few

00:20:58,260 --> 00:21:03,390
examples of the kind of problems we have

00:21:00,300 --> 00:21:05,280
to solve in our retail brand we still

00:21:03,390 --> 00:21:06,929
have a lot of check-writing businesses

00:21:05,280 --> 00:21:07,980
so we have to be thoughtful about the

00:21:06,929 --> 00:21:11,130
fact that the people that are signing

00:21:07,980 --> 00:21:12,780
cheques are having to validate those

00:21:11,130 --> 00:21:14,820
signatures so there's a reasonable

00:21:12,780 --> 00:21:16,559
amount of how do we know that the checks

00:21:14,820 --> 00:21:20,429
that are being written are actually

00:21:16,559 --> 00:21:22,950
being correctly cashed the same is true

00:21:20,429 --> 00:21:25,530
for contracts that we sign with third

00:21:22,950 --> 00:21:27,510
parties or a client sign or we sign on

00:21:25,530 --> 00:21:28,980
behalf of clients again there's a lot of

00:21:27,510 --> 00:21:31,890
physical paper still in the world

00:21:28,980 --> 00:21:33,570
floating around but we in an ideal world

00:21:31,890 --> 00:21:35,670
obviously were to digitize and get rid

00:21:33,570 --> 00:21:37,200
of and no magical but still it's a huge

00:21:35,670 --> 00:21:39,059
amount of custody flow that we need to

00:21:37,200 --> 00:21:40,230
think about there then you look at the

00:21:39,059 --> 00:21:43,050
other end of the business which is

00:21:40,230 --> 00:21:45,630
perhaps not measured in in bits of paper

00:21:43,050 --> 00:21:47,280
traveling across the world in hours but

00:21:45,630 --> 00:21:49,940
instead is measured in the time it takes

00:21:47,280 --> 00:21:52,770
for us to take a signal or market data

00:21:49,940 --> 00:21:54,090
pass that through an algorithm in order

00:21:52,770 --> 00:21:55,710
to make determine whether or not a

00:21:54,090 --> 00:21:57,240
customer trade should be executed or not

00:21:55,710 --> 00:22:00,750
and those things are measured

00:21:57,240 --> 00:22:03,890
potentially in hundreds of microseconds

00:22:00,750 --> 00:22:05,970
maybe milliseconds and the gamut of

00:22:03,890 --> 00:22:08,250
possibilities between the two plus the

00:22:05,970 --> 00:22:11,400
surveillance and regulation all of which

00:22:08,250 --> 00:22:14,700
fall into what we do as a technology

00:22:11,400 --> 00:22:16,530
company so it's a I would say it's a

00:22:14,700 --> 00:22:18,690
challenge that's probably on par with

00:22:16,530 --> 00:22:19,890
the the automotive industry certainly a

00:22:18,690 --> 00:22:21,559
level of complexity that I'd never

00:22:19,890 --> 00:22:25,720
considered before is a wonderful talk

00:22:21,559 --> 00:22:27,370
yes it's a huge opportunity for us so

00:22:25,720 --> 00:22:29,740
and I think there would be an obvious

00:22:27,370 --> 00:22:31,990
question now that people say what do you

00:22:29,740 --> 00:22:35,139
do about blockchain interestingly you

00:22:31,990 --> 00:22:37,870
didn't even say that blockchain the word

00:22:35,139 --> 00:22:39,129
yeah and but like I would like to state

00:22:37,870 --> 00:22:42,250
in another direction I would like to

00:22:39,129 --> 00:22:45,639
know we are here at an open tech event

00:22:42,250 --> 00:22:47,500
right and you are engaging at this event

00:22:45,639 --> 00:22:51,759
you said you you're not really at many

00:22:47,500 --> 00:22:54,519
events so so the question is like yeah

00:22:51,759 --> 00:22:57,000
you see an potentially seen opportunity

00:22:54,519 --> 00:23:00,070
with open source you use a lot yourself

00:22:57,000 --> 00:23:02,830
yeah I think so a bit of background

00:23:00,070 --> 00:23:04,149
about myself I suspect is that it was

00:23:02,830 --> 00:23:05,710
quite a pleasure because the booth

00:23:04,149 --> 00:23:07,299
that's opposite us downstairs is the

00:23:05,710 --> 00:23:08,830
freebsd booths and I got quite excited

00:23:07,299 --> 00:23:10,419
so whenever I had a chat with the chap

00:23:08,830 --> 00:23:14,169
that was sat there because I think I've

00:23:10,419 --> 00:23:15,789
been using and open source of 20 years

00:23:14,169 --> 00:23:17,559
old but it's often it's obviously a lot

00:23:15,789 --> 00:23:19,929
older than that rather than the GPO was

00:23:17,559 --> 00:23:21,610
like 1989 when GPL version 1 came out

00:23:19,929 --> 00:23:23,830
and the barky license has been around

00:23:21,610 --> 00:23:25,840
forever right so from a pragmatic

00:23:23,830 --> 00:23:28,539
perspective the sharing of ideas and

00:23:25,840 --> 00:23:30,279
thoughts is so part of my DNA and a

00:23:28,539 --> 00:23:32,409
certain I've gained a lot from it not

00:23:30,279 --> 00:23:35,080
standing unsolved of giants kind of

00:23:32,409 --> 00:23:37,179
point internally within the company I

00:23:35,080 --> 00:23:38,830
think we've probably like many large

00:23:37,179 --> 00:23:41,620
companies we've gone through a bit of a

00:23:38,830 --> 00:23:45,700
deep introspection right there isn't

00:23:41,620 --> 00:23:47,950
really a banking business without a

00:23:45,700 --> 00:23:51,879
knowledge anymor a trading business is

00:23:47,950 --> 00:23:53,620
really predicated on it and a business

00:23:51,879 --> 00:23:56,230
as a store of trust and an actor on

00:23:53,620 --> 00:23:58,000
somebody else's behalf trusts now

00:23:56,230 --> 00:23:59,649
involves that data component as we were

00:23:58,000 --> 00:24:01,960
saying earlier so technologies now

00:23:59,649 --> 00:24:03,700
become the heart of what we do so we've

00:24:01,960 --> 00:24:05,710
had to learn and change and grow and

00:24:03,700 --> 00:24:09,190
part of that is moving away from a

00:24:05,710 --> 00:24:10,929
vendor ecosystem where we don't actually

00:24:09,190 --> 00:24:12,370
get the opportunity to understand what

00:24:10,929 --> 00:24:12,840
we're doing we just trusted somebody

00:24:12,370 --> 00:24:15,029
else

00:24:12,840 --> 00:24:16,740
it's an outsourcing discussion it really

00:24:15,029 --> 00:24:18,510
is a I don't want to do this I don't

00:24:16,740 --> 00:24:19,890
need to be good at this I need to let

00:24:18,510 --> 00:24:21,990
someone else do it for me because I've

00:24:19,890 --> 00:24:25,289
got banking to do well these days

00:24:21,990 --> 00:24:28,679
banking is tech and so we don't get to

00:24:25,289 --> 00:24:30,240
even if we chose to and I think the fact

00:24:28,679 --> 00:24:33,179
that I'm sat in the seat Patrick Morgan

00:24:30,240 --> 00:24:34,890
is a sign that we haven't chosen to we

00:24:33,179 --> 00:24:37,200
don't get to make that choice we have to

00:24:34,890 --> 00:24:39,059
be involved in what we do open-source is

00:24:37,200 --> 00:24:41,880
by far and away the most obvious way to

00:24:39,059 --> 00:24:44,059
do all right so we use a lot of open

00:24:41,880 --> 00:24:47,130
source internally and we use a lot of

00:24:44,059 --> 00:24:48,929
not just the obvious sort of Linux eff

00:24:47,130 --> 00:24:51,720
various other things like that it's in

00:24:48,929 --> 00:24:53,279
it's in areas where previously we

00:24:51,720 --> 00:24:55,169
wouldn't have be able to been able to

00:24:53,279 --> 00:24:58,049
push but people have started to do

00:24:55,169 --> 00:25:02,370
things I was fascinated by the the open

00:24:58,049 --> 00:25:03,990
source conversational web took down a

00:25:02,370 --> 00:25:05,190
note are we taking that away because

00:25:03,990 --> 00:25:06,390
everyone wants to go to chat board

00:25:05,190 --> 00:25:08,279
because everyone's got customers

00:25:06,390 --> 00:25:10,110
internal or external well if there's an

00:25:08,279 --> 00:25:12,140
opportunity to be in be part of that

00:25:10,110 --> 00:25:15,600
loop and then contribute back there's a

00:25:12,140 --> 00:25:17,700
great uplift in not everybody solving a

00:25:15,600 --> 00:25:19,230
problem that isn't competitive advantage

00:25:17,700 --> 00:25:24,000
but still direct delivers value to

00:25:19,230 --> 00:25:28,080
everybody so and Frank I would come back

00:25:24,000 --> 00:25:30,090
to you because you are representing like

00:25:28,080 --> 00:25:32,070
the open source community made many many

00:25:30,090 --> 00:25:34,980
people as I said like more than 500

00:25:32,070 --> 00:25:37,289
contributors and so we are talking about

00:25:34,980 --> 00:25:40,740
the future and like everyone sees an

00:25:37,289 --> 00:25:42,779
opportunity with open source and so what

00:25:40,740 --> 00:25:46,399
do we need to learn to stay ahead of the

00:25:42,779 --> 00:25:49,380
competition as an open source community

00:25:46,399 --> 00:25:51,090
that's a good question thanks for asking

00:25:49,380 --> 00:25:53,730
me that tricky because I think this is

00:25:51,090 --> 00:25:57,029
one of my my mains point I want to make

00:25:53,730 --> 00:25:59,730
here is that I mean this event is called

00:25:57,029 --> 00:26:02,700
Foss Asia force for open source and free

00:25:59,730 --> 00:26:04,830
software so I think we all have to

00:26:02,700 --> 00:26:08,250
remember what it actually means I mean

00:26:04,830 --> 00:26:09,570
the society was basically is this term

00:26:08,250 --> 00:26:11,370
free software invented by Richard

00:26:09,570 --> 00:26:14,669
Stallman which basically defined this

00:26:11,370 --> 00:26:16,500
based on four principles like the first

00:26:14,669 --> 00:26:19,080
is that everybody should be able to run

00:26:16,500 --> 00:26:21,240
the software to run the program it has

00:26:19,080 --> 00:26:23,940
to be able you have to be able to run it

00:26:21,240 --> 00:26:25,010
to be open source second is you have to

00:26:23,940 --> 00:26:27,380
be able to start

00:26:25,010 --> 00:26:28,610
the sauce cotton to change it and the

00:26:27,380 --> 00:26:30,920
third and fourth talked about

00:26:28,610 --> 00:26:32,870
distributing it to others but is it like

00:26:30,920 --> 00:26:34,400
the fundamental of open source and free

00:26:32,870 --> 00:26:36,830
software that we are talking about that

00:26:34,400 --> 00:26:39,260
as a fundamental of communities like us

00:26:36,830 --> 00:26:41,540
here if we define us as the people who

00:26:39,260 --> 00:26:43,280
contribute and build technology not only

00:26:41,540 --> 00:26:45,200
use technology rather than using

00:26:43,280 --> 00:26:47,930
technology using some nice depth

00:26:45,200 --> 00:26:49,910
services run by some nice big American

00:26:47,930 --> 00:26:51,500
companies this is easy but this is the

00:26:49,910 --> 00:26:53,960
open source and free software community

00:26:51,500 --> 00:26:56,780
building it and for that we need these

00:26:53,960 --> 00:26:58,580
freedoms and we all agree that machine

00:26:56,780 --> 00:27:01,430
learning and artificial tensions of the

00:26:58,580 --> 00:27:02,840
future and this changes to gain this is

00:27:01,430 --> 00:27:06,110
I find it's quite as interesting it

00:27:02,840 --> 00:27:08,720
changes the game because how does this

00:27:06,110 --> 00:27:10,100
work in the future how does how does the

00:27:08,720 --> 00:27:12,740
open source and free software community

00:27:10,100 --> 00:27:15,380
can still participate in this world of

00:27:12,740 --> 00:27:19,280
machine learning because it becomes more

00:27:15,380 --> 00:27:21,680
complicated let's say some big company I

00:27:19,280 --> 00:27:23,780
don't want to say names has like this

00:27:21,680 --> 00:27:25,700
nice algorithm where it studies like the

00:27:23,780 --> 00:27:27,950
behavior of lots of people of lots of

00:27:25,700 --> 00:27:30,530
data big data right and analyzes

00:27:27,950 --> 00:27:31,880
something right then of course the

00:27:30,530 --> 00:27:32,570
question is first question okay where's

00:27:31,880 --> 00:27:34,130
the source code

00:27:32,570 --> 00:27:35,690
first of all lots of the stuff is not

00:27:34,130 --> 00:27:37,460
really open source rather say we are

00:27:35,690 --> 00:27:39,140
open because we can use our API is

00:27:37,460 --> 00:27:40,880
that's not open source as I've just

00:27:39,140 --> 00:27:43,160
described you need more you need a

00:27:40,880 --> 00:27:46,190
source code okay maybe this company's

00:27:43,160 --> 00:27:49,580
done very nice let's call it just for

00:27:46,190 --> 00:27:51,470
fun Facebook could be anyone else but

00:27:49,580 --> 00:27:52,970
there in the press lately so there's

00:27:51,470 --> 00:27:55,780
some interest interviews with Mark

00:27:52,970 --> 00:27:59,030
Zuckerberg two billion on CNN let's say

00:27:55,780 --> 00:28:01,310
let's say open Facebook open source is

00:27:59,030 --> 00:28:02,630
the full source code of Facebook right

00:28:01,310 --> 00:28:05,210
then we have one right

00:28:02,630 --> 00:28:07,160
GPL that we upon while not really

00:28:05,210 --> 00:28:10,370
because what can you do is use software

00:28:07,160 --> 00:28:12,440
if you don't have the data this is all

00:28:10,370 --> 00:28:15,020
about the data of the people this is you

00:28:12,440 --> 00:28:16,460
need a machine learning like an a neural

00:28:15,020 --> 00:28:17,300
network is dumped right is completely

00:28:16,460 --> 00:28:19,400
useless

00:28:17,300 --> 00:28:21,740
you can't you can run it and it says

00:28:19,400 --> 00:28:23,300
nothing without data and you need the

00:28:21,740 --> 00:28:25,790
data and the data is not really

00:28:23,300 --> 00:28:27,940
available let's say like Facebook is

00:28:25,790 --> 00:28:30,590
even nice and also open sourced data Oh

00:28:27,940 --> 00:28:32,450
what will you do with it you can't do

00:28:30,590 --> 00:28:33,210
anything because it doesn't run at home

00:28:32,450 --> 00:28:34,800
and you're left

00:28:33,210 --> 00:28:37,080
right you need a bigger server cluster

00:28:34,800 --> 00:28:40,050
for that and this is also like not

00:28:37,080 --> 00:28:41,670
available for us here right so the

00:28:40,050 --> 00:28:44,580
danger for the free software and open

00:28:41,670 --> 00:28:47,040
source community for us fear is that we

00:28:44,580 --> 00:28:49,590
become uses of the community and no

00:28:47,040 --> 00:28:51,330
longer builders of the community it's a

00:28:49,590 --> 00:28:53,670
quite quite a danger for our movement

00:28:51,330 --> 00:28:56,220
here and also it has implications for

00:28:53,670 --> 00:28:58,530
privacy and security and for innovation

00:28:56,220 --> 00:29:00,510
overall so there's a danger that

00:28:58,530 --> 00:29:03,240
artificial intelligence machine learning

00:29:00,510 --> 00:29:05,100
leads into a future that basically like

00:29:03,240 --> 00:29:10,500
five big companies can innovate and the

00:29:05,100 --> 00:29:14,880
rest of us becomes users can i yes yeah

00:29:10,500 --> 00:29:17,880
I see you dotting so yes Frank raises

00:29:14,880 --> 00:29:20,100
really interesting points and and some

00:29:17,880 --> 00:29:22,230
really important points that we as a

00:29:20,100 --> 00:29:26,370
community really need to get on top of

00:29:22,230 --> 00:29:28,020
and understand and I guess I'm probably

00:29:26,370 --> 00:29:31,080
a bit more optimistic by the sounds of

00:29:28,020 --> 00:29:34,830
it than Frank about where we are where

00:29:31,080 --> 00:29:37,620
we are going and I think the optimism

00:29:34,830 --> 00:29:40,890
comes from seeing the enthusiasm and the

00:29:37,620 --> 00:29:43,440
talent in the open-source community and

00:29:40,890 --> 00:29:46,080
also now and I've only been in Microsoft

00:29:43,440 --> 00:29:48,030
for two years and I'm understanding and

00:29:46,080 --> 00:29:50,460
learning the the change and culture

00:29:48,030 --> 00:29:53,640
that's happening in such a large

00:29:50,460 --> 00:29:58,650
organization that was so anti open

00:29:53,640 --> 00:30:01,650
source for very many years realizing the

00:29:58,650 --> 00:30:04,170
importance and the significance of water

00:30:01,650 --> 00:30:09,750
open-source has actually contributed to

00:30:04,170 --> 00:30:12,930
society into development and so on one

00:30:09,750 --> 00:30:14,550
of our or one of the exciting things I

00:30:12,930 --> 00:30:19,230
see from my point of view isn't data

00:30:14,550 --> 00:30:22,470
scientist and AI Xin learner is that I

00:30:19,230 --> 00:30:24,770
do now have access to massive amounts of

00:30:22,470 --> 00:30:30,030
compute very efficiently on the cloud

00:30:24,770 --> 00:30:32,610
fairly cheaply at my fingertips you know

00:30:30,030 --> 00:30:35,270
it took me three years in the Australian

00:30:32,610 --> 00:30:38,830
government to set up one of our first

00:30:35,270 --> 00:30:40,780
completely open source stack base

00:30:38,830 --> 00:30:42,610
sir the network in the Australian

00:30:40,780 --> 00:30:46,540
Taxation Office three years of working

00:30:42,610 --> 00:30:48,430
with our IT departments to get that open

00:30:46,540 --> 00:30:51,190
source stack for our data scientists

00:30:48,430 --> 00:30:53,080
into the organization I mean now it

00:30:51,190 --> 00:30:57,130
takes me five minutes to push a button

00:30:53,080 --> 00:31:00,490
and on the cloud have a server available

00:30:57,130 --> 00:31:03,340
to me that runs the full open source

00:31:00,490 --> 00:31:07,900
stack of everything that I use as a data

00:31:03,340 --> 00:31:10,960
scientist Python our tensorflow c NT k

00:31:07,900 --> 00:31:13,690
you name it but a data scientist uses it

00:31:10,960 --> 00:31:15,820
it's on that stack and that is now

00:31:13,690 --> 00:31:17,470
accessible to me I fire that machine up

00:31:15,820 --> 00:31:20,050
I do my date of mind if I've got the

00:31:17,470 --> 00:31:23,560
data and that that's another issue

00:31:20,050 --> 00:31:25,210
we've got time to come back to but I can

00:31:23,560 --> 00:31:28,240
do my data science and then shut that

00:31:25,210 --> 00:31:29,590
machine down or or or Park it and fire

00:31:28,240 --> 00:31:32,530
it up when I need it again and

00:31:29,590 --> 00:31:34,390
dynamically rescale it and I know it's a

00:31:32,530 --> 00:31:36,930
bit of a buzz phase but we like to say

00:31:34,390 --> 00:31:39,400
you know the the access to an AI

00:31:36,930 --> 00:31:42,490
supercomputer is there on the cloud now

00:31:39,400 --> 00:31:44,650
at the push of the button pushing the

00:31:42,490 --> 00:31:47,230
buzzwords a bit too much but there's a

00:31:44,650 --> 00:31:49,390
lot of compute that is accessible to us

00:31:47,230 --> 00:31:52,990
and becoming even more accessible and

00:31:49,390 --> 00:31:56,770
cheaper in the cloud now that's giving

00:31:52,990 --> 00:31:58,420
me as an independent developer access to

00:31:56,770 --> 00:32:00,070
compute power that otherwise would have

00:31:58,420 --> 00:32:04,720
been in the you know in the big vendor

00:32:00,070 --> 00:32:07,150
space so it's a very good point the

00:32:04,720 --> 00:32:08,710
cloud which obviously I'm a huge

00:32:07,150 --> 00:32:10,510
advocate of anyway but the cloud

00:32:08,710 --> 00:32:12,030
certainly is the ability to get access

00:32:10,510 --> 00:32:16,060
to huge amounts of compute resources

00:32:12,030 --> 00:32:17,080
previously unknown there's another side

00:32:16,060 --> 00:32:19,000
to it and I think you've probably been

00:32:17,080 --> 00:32:21,070
more directly involved in that and

00:32:19,000 --> 00:32:22,480
certainly I have which is the ability to

00:32:21,070 --> 00:32:23,860
actually do that sort of machine

00:32:22,480 --> 00:32:27,340
learning to have techniques and tools

00:32:23,860 --> 00:32:31,030
available to you has become democratized

00:32:27,340 --> 00:32:32,800
or on our Amazon word probably even in

00:32:31,030 --> 00:32:34,060
the last five years in a way that it

00:32:32,800 --> 00:32:37,570
hadn't been in the previous 20 years

00:32:34,060 --> 00:32:39,730
learning for trainers hard and the third

00:32:37,570 --> 00:32:41,140
piece and I think this is where we're

00:32:39,730 --> 00:32:43,620
seeing the other side of it is that data

00:32:41,140 --> 00:32:45,150
and having data available in

00:32:43,620 --> 00:32:47,490
data containers that you can apply

00:32:45,150 --> 00:32:50,520
metadata to is something that's also

00:32:47,490 --> 00:32:53,250
become far far more available and I

00:32:50,520 --> 00:32:54,360
think there's useless stats like 90% of

00:32:53,250 --> 00:32:56,370
all the date when the world's been

00:32:54,360 --> 00:32:58,050
recreated in the last two years or this

00:32:56,370 --> 00:33:00,090
five standard bytes of beta-alanine

00:32:58,050 --> 00:33:01,830
it'll completely functionally useless

00:33:00,090 --> 00:33:04,050
but it sounds good on stage right but

00:33:01,830 --> 00:33:05,370
the the the other side of that means

00:33:04,050 --> 00:33:06,960
that the combination of these three

00:33:05,370 --> 00:33:09,660
things have now made it possible for

00:33:06,960 --> 00:33:12,060
almost anybody to garner insights from

00:33:09,660 --> 00:33:14,550
if you have a large data set if you have

00:33:12,060 --> 00:33:17,580
a credit card and if you have a couple

00:33:14,550 --> 00:33:19,740
of university graduates and and that

00:33:17,580 --> 00:33:23,670
democratization I think is so important

00:33:19,740 --> 00:33:25,680
we are making an effort to ensure the

00:33:23,670 --> 00:33:29,060
new algorithms that we're developing are

00:33:25,680 --> 00:33:32,970
becoming available between open source

00:33:29,060 --> 00:33:35,310
know most if not all of my work and the

00:33:32,970 --> 00:33:38,730
team of my data science my data science

00:33:35,310 --> 00:33:41,940
teams is published now on github we work

00:33:38,730 --> 00:33:43,740
with enterprises we capture what we do

00:33:41,940 --> 00:33:45,270
with those enterprises and then share

00:33:43,740 --> 00:33:49,470
them as templates basically you know

00:33:45,270 --> 00:33:52,320
templates of code on on github and we're

00:33:49,470 --> 00:33:57,140
also focusing on going up a layer you

00:33:52,320 --> 00:34:01,320
you saw some code of tensorflow earlier

00:33:57,140 --> 00:34:04,830
it's really hard to know how to analyze

00:34:01,320 --> 00:34:08,010
images using tensorflow and yet we also

00:34:04,830 --> 00:34:09,990
saw the API approach which in one sense

00:34:08,010 --> 00:34:11,700
dumbed down the whole process it makes

00:34:09,990 --> 00:34:14,310
it really simple just to load in some

00:34:11,700 --> 00:34:15,650
images and do some machine learning but

00:34:14,310 --> 00:34:18,060
it's very limiting on what it can do

00:34:15,650 --> 00:34:21,450
there's a middle layer there that it's

00:34:18,060 --> 00:34:24,270
so important that captures the expertise

00:34:21,450 --> 00:34:25,679
of knowing that you've got a manipulate

00:34:24,270 --> 00:34:27,540
some of these images and this way

00:34:25,679 --> 00:34:29,760
typically before you build your models

00:34:27,540 --> 00:34:32,340
so we're focusing on that middle layer

00:34:29,760 --> 00:34:34,679
to see how we can democratize and make

00:34:32,340 --> 00:34:38,880
more of this III machine learning

00:34:34,679 --> 00:34:41,280
technology available free I'm not so

00:34:38,880 --> 00:34:42,990
sure about the democratizing I mean if

00:34:41,280 --> 00:34:44,580
you look at the old world for a second

00:34:42,990 --> 00:34:47,820
but if you look for example how Linux

00:34:44,580 --> 00:34:51,290
was built and our Linux this was done by

00:34:47,820 --> 00:34:54,450
by Lin was in his basement by a

00:34:51,290 --> 00:34:54,870
commodity PC and he paid he sat down and

00:34:54,450 --> 00:34:57,360
wrote

00:34:54,870 --> 00:34:59,280
thing in the same way like lots of other

00:34:57,360 --> 00:35:01,920
open source free software projects were

00:34:59,280 --> 00:35:04,230
founded we need like no resources you

00:35:01,920 --> 00:35:06,870
need no no you don't need to pay any

00:35:04,230 --> 00:35:08,400
money to Amazon or to whatever to run in

00:35:06,870 --> 00:35:10,650
virtual machines or something which are

00:35:08,400 --> 00:35:13,050
by the way not cheap if you want to do

00:35:10,650 --> 00:35:15,030
big data like this is me I'm sure you

00:35:13,050 --> 00:35:16,800
can do after budget I'm not sure like

00:35:15,030 --> 00:35:22,140
every student yes the budget to do that

00:35:16,800 --> 00:35:23,820
big data analysis on AWS and not even

00:35:22,140 --> 00:35:25,590
talking about the data itself as I said

00:35:23,820 --> 00:35:29,400
before so I'm not really sure this is

00:35:25,590 --> 00:35:30,990
really so erotic so question is a

00:35:29,400 --> 00:35:32,400
democratic so just it's an interesting

00:35:30,990 --> 00:35:33,720
point you're right it's not democratic

00:35:32,400 --> 00:35:36,930
in that it's not fair write it down to

00:35:33,720 --> 00:35:39,120
the individual it is democratic in but

00:35:36,930 --> 00:35:41,370
it's no longer simply in the hands of a

00:35:39,120 --> 00:35:43,500
few large vendors who hold on to that

00:35:41,370 --> 00:35:44,760
secret and then it's extort license tax

00:35:43,500 --> 00:35:48,900
from you I think is that's that's

00:35:44,760 --> 00:35:51,240
probably to be more specific around I

00:35:48,900 --> 00:35:54,030
mean the example of this is there's a

00:35:51,240 --> 00:35:57,150
there's a category of analysis that used

00:35:54,030 --> 00:36:00,240
to be only available to but here's the

00:35:57,150 --> 00:36:04,700
story there the Wal Mart CEO used to fly

00:36:00,240 --> 00:36:06,900
over or send planes I fly over other

00:36:04,700 --> 00:36:08,820
competitors car parks in order to take

00:36:06,900 --> 00:36:11,220
photos of it and only he would do this

00:36:08,820 --> 00:36:14,640
is in the 1950s like 60 years ago

00:36:11,220 --> 00:36:16,020
whatever more than that I guess and he

00:36:14,640 --> 00:36:17,310
would have that data abroad to him

00:36:16,020 --> 00:36:18,930
they'd look at it over a weekend they'd

00:36:17,310 --> 00:36:22,020
make a few predictive and intensive

00:36:18,930 --> 00:36:23,670
analytical guesses and would get the

00:36:22,020 --> 00:36:24,750
jump on what was gonna be happening what

00:36:23,670 --> 00:36:26,970
they should be putting in their stores

00:36:24,750 --> 00:36:28,650
now we know that's old hat right that

00:36:26,970 --> 00:36:31,020
sort of stuff that's there really is 50

00:36:28,650 --> 00:36:32,730
years old we have micro satellites that

00:36:31,020 --> 00:36:34,710
are able to effectively look at pretty

00:36:32,730 --> 00:36:36,510
much every part of the earth and

00:36:34,710 --> 00:36:38,070
previously I'd say 10 15 years ago there

00:36:36,510 --> 00:36:40,560
were a handful of groups that would have

00:36:38,070 --> 00:36:41,820
access to that data now it's much more

00:36:40,560 --> 00:36:43,560
substantially available you're right

00:36:41,820 --> 00:36:44,880
it's not available to anyone it's

00:36:43,560 --> 00:36:46,710
certainly not available in a small

00:36:44,880 --> 00:36:48,510
budget but it's not available you don't

00:36:46,710 --> 00:36:49,740
require to have to spend millions of

00:36:48,510 --> 00:36:51,270
dollars to get off the ground at there

00:36:49,740 --> 00:36:54,330
and I think that's the key point

00:36:51,270 --> 00:36:56,290
okay I think like I would like to get

00:36:54,330 --> 00:36:59,350
the perspective of

00:36:56,290 --> 00:37:01,359
young as well and but like I think we're

00:36:59,350 --> 00:37:04,330
touching several questions we won't be

00:37:01,359 --> 00:37:07,119
able to solve this year one question is

00:37:04,330 --> 00:37:09,880
the the source code of the applications

00:37:07,119 --> 00:37:10,660
the other question is where does the

00:37:09,880 --> 00:37:12,369
data come from

00:37:10,660 --> 00:37:14,109
of course companies who have acquired

00:37:12,369 --> 00:37:16,450
the state and put in a lot of resources

00:37:14,109 --> 00:37:19,600
to get this data they want to keep this

00:37:16,450 --> 00:37:22,000
data then there are other entities like

00:37:19,600 --> 00:37:26,710
let's say even states Europe with the

00:37:22,000 --> 00:37:28,869
data protective lost right so they say

00:37:26,710 --> 00:37:31,210
you're only allowed to keep a certain

00:37:28,869 --> 00:37:33,220
kind of data so number of data and so on

00:37:31,210 --> 00:37:36,070
so there are roots that come in place

00:37:33,220 --> 00:37:38,440
here and so yeah the question is really

00:37:36,070 --> 00:37:40,570
who owns the data and what is our end

00:37:38,440 --> 00:37:41,920
goal is our end goal that everyone has

00:37:40,570 --> 00:37:43,480
the source code or is our end goal that

00:37:41,920 --> 00:37:45,550
everyone's controlling the data and so

00:37:43,480 --> 00:37:47,290
on so I think this is a very long

00:37:45,550 --> 00:37:48,869
discussion that will take over years and

00:37:47,290 --> 00:37:52,420
I see like different approaches in Asia

00:37:48,869 --> 00:37:56,200
China let's say right I mean in the US

00:37:52,420 --> 00:37:58,030
and in Europe and very curious to see in

00:37:56,200 --> 00:37:59,650
which direction we're heading and I

00:37:58,030 --> 00:38:02,710
would like to come back a little bit

00:37:59,650 --> 00:38:06,490
also to the question here in open source

00:38:02,710 --> 00:38:08,800
also SBH like on the ground

00:38:06,490 --> 00:38:12,130
how much open source are you using

00:38:08,800 --> 00:38:13,869
already and are you already engaging in

00:38:12,130 --> 00:38:16,600
projects like do you work together with

00:38:13,869 --> 00:38:18,820
in any open source projects do you have

00:38:16,600 --> 00:38:21,160
already like a code online order your

00:38:18,820 --> 00:38:23,590
plan to release it of some applications

00:38:21,160 --> 00:38:25,390
that you use in the company and where

00:38:23,590 --> 00:38:27,100
you want to connect with the community

00:38:25,390 --> 00:38:29,140
it was interesting to hear them in or

00:38:27,100 --> 00:38:31,240
debating over as a person contributing

00:38:29,140 --> 00:38:31,690
to the open source for a speech as a

00:38:31,240 --> 00:38:34,510
user

00:38:31,690 --> 00:38:36,130
we are the benefactor so we have not you

00:38:34,510 --> 00:38:37,630
know so-called contribute proactively

00:38:36,130 --> 00:38:39,790
into the open source but we definitely

00:38:37,630 --> 00:38:41,890
benefitted a lot when we started our

00:38:39,790 --> 00:38:44,170
machine learning and AI I don't have

00:38:41,890 --> 00:38:46,840
data scientists or math you know experts

00:38:44,170 --> 00:38:49,930
in my team and my bosses were super

00:38:46,840 --> 00:38:51,880
skeptical how are you gonna stop AI a

00:38:49,930 --> 00:38:54,070
machine learning but thanks to all these

00:38:51,880 --> 00:38:57,100
open source no ready to use machine

00:38:54,070 --> 00:38:57,740
learning framework tools we were able to

00:38:57,100 --> 00:38:59,960
you know

00:38:57,740 --> 00:39:03,890
exploring so thanks to the open source

00:38:59,960 --> 00:39:05,750
community I also very curious how as an

00:39:03,890 --> 00:39:08,570
enterprise like yourself we can

00:39:05,750 --> 00:39:11,330
contribute back not directly in terms of

00:39:08,570 --> 00:39:14,210
no giving back the code but it is anyway

00:39:11,330 --> 00:39:16,940
that you know we can you know bring

00:39:14,210 --> 00:39:21,050
forth value back into this open source

00:39:16,940 --> 00:39:22,820
sure so I'm I'm involved in the KDE

00:39:21,050 --> 00:39:25,580
project for a long time I started like

00:39:22,820 --> 00:39:28,160
20 years ago at the beginning everybody

00:39:25,580 --> 00:39:30,460
in the community we call developers but

00:39:28,160 --> 00:39:33,140
later we change the term to contributors

00:39:30,460 --> 00:39:35,150
because that's way better fit because

00:39:33,140 --> 00:39:37,240
there are a lot of more ways to

00:39:35,150 --> 00:39:40,880
contribute than just writing code like

00:39:37,240 --> 00:39:43,160
you can help with testing writing back

00:39:40,880 --> 00:39:46,580
records help with translations help with

00:39:43,160 --> 00:39:48,860
marketing packaging all kinds of things

00:39:46,580 --> 00:39:51,290
most of the better open-source project

00:39:48,860 --> 00:39:53,390
to actually have like pages where it's

00:39:51,290 --> 00:39:54,710
described how you can get involved so

00:39:53,390 --> 00:39:57,440
there are lots of ways you don't have to

00:39:54,710 --> 00:39:59,000
really do like development and you don't

00:39:57,440 --> 00:40:00,380
have to be a data scientist which I'm

00:39:59,000 --> 00:40:02,510
sure they're not a lot of them on the

00:40:00,380 --> 00:40:05,359
planet so but there a lot of other ways

00:40:02,510 --> 00:40:08,450
to contribute depends on the project I

00:40:05,359 --> 00:40:09,890
think the challenge is often like the

00:40:08,450 --> 00:40:12,380
the organizational structure the

00:40:09,890 --> 00:40:14,480
open-source community were works in very

00:40:12,380 --> 00:40:16,040
different ways and a lot of the IT

00:40:14,480 --> 00:40:19,280
community works in different ways we see

00:40:16,040 --> 00:40:21,410
in step by step like that like other

00:40:19,280 --> 00:40:23,090
departments they're becoming more agile

00:40:21,410 --> 00:40:25,850
and they're looking for different ways

00:40:23,090 --> 00:40:28,100
to organize their teams like the teams

00:40:25,850 --> 00:40:29,960
are taking up tasks we saw like tools

00:40:28,100 --> 00:40:31,910
where like Trello or something like that

00:40:29,960 --> 00:40:35,150
where you can actually like say ok I'm

00:40:31,910 --> 00:40:38,000
gonna do this or that so it is not just

00:40:35,150 --> 00:40:39,680
like a way like ok like let's go online

00:40:38,000 --> 00:40:42,470
and start contribute is actually a

00:40:39,680 --> 00:40:44,750
cultural change that is necessary in

00:40:42,470 --> 00:40:47,300
order to work together and benefit from

00:40:44,750 --> 00:40:49,990
the community and and like companies

00:40:47,300 --> 00:40:52,580
that like plug in very well with this

00:40:49,990 --> 00:40:54,109
open-source way of working together they

00:40:52,580 --> 00:40:56,180
can also benefit because you can hire

00:40:54,109 --> 00:40:57,050
directly you don't need to teach them

00:40:56,180 --> 00:40:59,660
anymore

00:40:57,050 --> 00:41:01,520
ok you have to like now do this process

00:40:59,660 --> 00:41:03,560
or that right so if you already have

00:41:01,520 --> 00:41:05,910
similar processes you can hire the

00:41:03,560 --> 00:41:08,490
people very quickly so

00:41:05,910 --> 00:41:10,680
there are many benefits to it but Ramji

00:41:08,490 --> 00:41:13,640
maybe you have more insights here

00:41:10,680 --> 00:41:17,100
because if you work in a corporation and

00:41:13,640 --> 00:41:19,020
SPH is looking like how do I work

00:41:17,100 --> 00:41:21,030
together with the open-source community

00:41:19,020 --> 00:41:22,530
if I want to get started ok data in the

00:41:21,030 --> 00:41:25,410
future what you're mentioning is still a

00:41:22,530 --> 00:41:27,000
big topic but like I'm I want to like no

00:41:25,410 --> 00:41:28,770
actually we're using open-source but we

00:41:27,000 --> 00:41:31,230
don't know how to actually engage with

00:41:28,770 --> 00:41:32,640
them support them you're now started

00:41:31,230 --> 00:41:34,740
you're supporting for Asia you're

00:41:32,640 --> 00:41:36,510
present here you have a lot of media

00:41:34,740 --> 00:41:38,370
announcements so that that's great but

00:41:36,510 --> 00:41:41,040
what insights can you give from your

00:41:38,370 --> 00:41:43,410
perspective we the procurement process

00:41:41,040 --> 00:41:44,910
within large enterprises is probably one

00:41:43,410 --> 00:41:46,860
of the biggest barriers here because you

00:41:44,910 --> 00:41:48,900
start a conversation and you say well I

00:41:46,860 --> 00:41:50,700
have this third party worked with for 30

00:41:48,900 --> 00:41:52,260
years we understand supply chain well we

00:41:50,700 --> 00:41:54,690
have contracts in place everything else

00:41:52,260 --> 00:41:56,700
is good oh there's this three person

00:41:54,690 --> 00:41:57,810
company that's actually well I don't

00:41:56,700 --> 00:41:59,460
know where they're based because they're

00:41:57,810 --> 00:42:01,560
one of their developers in Toronto one

00:41:59,460 --> 00:42:02,970
is in Singapore and one is in Russia and

00:42:01,560 --> 00:42:04,890
I think they're incorporated in

00:42:02,970 --> 00:42:06,150
Luxembourg Oh what we'd like to have a

00:42:04,890 --> 00:42:07,980
contractual agreement with them and

00:42:06,150 --> 00:42:10,350
that's that immediately runs into

00:42:07,980 --> 00:42:12,240
certain level of minecraft so being an

00:42:10,350 --> 00:42:14,430
advocate and being a champion for the

00:42:12,240 --> 00:42:16,890
fact that that is actually how you get

00:42:14,430 --> 00:42:19,050
smart ideas in you don't have to even

00:42:16,890 --> 00:42:20,250
necessarily contribute back and there

00:42:19,050 --> 00:42:21,480
was a discussion I think earlier about

00:42:20,250 --> 00:42:23,460
the difficulties of getting through

00:42:21,480 --> 00:42:24,480
legal teams in order to be able to

00:42:23,460 --> 00:42:26,610
contract back I mean we're very

00:42:24,480 --> 00:42:29,130
fortunate JPM partly because of our size

00:42:26,610 --> 00:42:31,560
and partly because of the the seismic

00:42:29,130 --> 00:42:33,240
shift internally that's an area where

00:42:31,560 --> 00:42:35,070
we're starting to see much much more

00:42:33,240 --> 00:42:37,260
we have 45,000 also technologists

00:42:35,070 --> 00:42:39,300
working a lot of whom do con feedback

00:42:37,260 --> 00:42:41,100
but it's much more I would say about

00:42:39,300 --> 00:42:43,050
being a champion internally being a

00:42:41,100 --> 00:42:44,880
champion of things that are correlated

00:42:43,050 --> 00:42:47,580
with the open-source movement but not

00:42:44,880 --> 00:42:49,380
necessarily the same so agile lean

00:42:47,580 --> 00:42:52,950
thinking being able to actually have

00:42:49,380 --> 00:42:55,440
people be creating an open and trusting

00:42:52,950 --> 00:42:57,150
workplace so that if somewhere people do

00:42:55,440 --> 00:42:58,740
want to work and then invest in

00:42:57,150 --> 00:42:59,750
companies and buy software from

00:42:58,740 --> 00:43:01,430
companies

00:42:59,750 --> 00:43:03,080
that are open source and free software

00:43:01,430 --> 00:43:05,510
companies meaning you are not buying the

00:43:03,080 --> 00:43:07,070
software you're investing in them so

00:43:05,510 --> 00:43:10,700
they can pay developers we're going to

00:43:07,070 --> 00:43:12,440
write open source software because even

00:43:10,700 --> 00:43:14,720
in SPS for the traditional side of the

00:43:12,440 --> 00:43:16,880
business there's not very much into the

00:43:14,720 --> 00:43:17,480
open source but for the digital side of

00:43:16,880 --> 00:43:19,430
the business

00:43:17,480 --> 00:43:21,740
we really see open source as the engine

00:43:19,430 --> 00:43:24,110
of digital transformation we are using

00:43:21,740 --> 00:43:28,310
open source CMS open source in the tools

00:43:24,110 --> 00:43:30,200
and SDK so heaven quite income I mean so

00:43:28,310 --> 00:43:31,760
we have to get there and be brave in

00:43:30,200 --> 00:43:34,970
confronting some of this kind of put

00:43:31,760 --> 00:43:37,070
government issues and so on okay so

00:43:34,970 --> 00:43:39,410
that's where Microsoft types in recently

00:43:37,070 --> 00:43:42,050
more and more like I remember like a

00:43:39,410 --> 00:43:45,200
little over ten years ago it was like oh

00:43:42,050 --> 00:43:48,950
no yeah but like Microsoft has changed a

00:43:45,200 --> 00:43:51,140
lot of these it certainly has it and as

00:43:48,950 --> 00:43:53,030
I saying it it's on a journey it's not

00:43:51,140 --> 00:43:57,290
at the end of that journey yet in terms

00:43:53,030 --> 00:44:00,320
of open source but it's certainly

00:43:57,290 --> 00:44:04,460
heading in the right direction from from

00:44:00,320 --> 00:44:07,790
where I can see internally as well along

00:44:04,460 --> 00:44:10,010
that theme if I can just can't tie

00:44:07,790 --> 00:44:11,390
together a comment I was going to make

00:44:10,010 --> 00:44:15,560
to frank him something about

00:44:11,390 --> 00:44:17,300
contributing back the the it's not just

00:44:15,560 --> 00:44:19,880
the algorithms that we're open sourcing

00:44:17,300 --> 00:44:23,320
though it's the models that we build and

00:44:19,880 --> 00:44:27,200
so for example these models that are

00:44:23,320 --> 00:44:31,690
classifying images to identify objects

00:44:27,200 --> 00:44:35,830
in the images those models can take

00:44:31,690 --> 00:44:38,540
three four five weeks of multiple GPUs

00:44:35,830 --> 00:44:41,450
massive neural networks to build and to

00:44:38,540 --> 00:44:43,520
get the accuracy that we're saying

00:44:41,450 --> 00:44:45,710
that's a massive amount of compute

00:44:43,520 --> 00:44:48,020
that's required but what we're doing is

00:44:45,710 --> 00:44:49,970
making those models themselves openly

00:44:48,020 --> 00:44:54,320
available and indeed there's a whole

00:44:49,970 --> 00:44:56,600
movement around trying to and what I was

00:44:54,320 --> 00:44:58,289
going to say was that a contribution

00:44:56,600 --> 00:45:01,199
back to the

00:44:58,289 --> 00:45:03,209
community is sometimes hard for

00:45:01,199 --> 00:45:05,279
commercial organizations to do so but

00:45:03,209 --> 00:45:07,559
where it's possible models that you

00:45:05,279 --> 00:45:09,929
build share them back into the community

00:45:07,559 --> 00:45:12,719
to demonstrate how you are building the

00:45:09,929 --> 00:45:16,109
models the algorithms that were went

00:45:12,719 --> 00:45:17,819
into it processing and illustrating that

00:45:16,109 --> 00:45:20,819
to the rest of the community so we can

00:45:17,819 --> 00:45:24,989
share what we're doing with others that

00:45:20,819 --> 00:45:26,789
also then leads into the transparency

00:45:24,989 --> 00:45:28,979
around the models that we're building

00:45:26,789 --> 00:45:30,749
for policy development for example in

00:45:28,979 --> 00:45:33,299
government all models that we develop

00:45:30,749 --> 00:45:35,749
there should be open models that we can

00:45:33,299 --> 00:45:38,160
test and validate the assumptions there

00:45:35,749 --> 00:45:41,369
I'd love to also talk about some of the

00:45:38,160 --> 00:45:44,099
data issues too I would love to answer

00:45:41,369 --> 00:45:46,169
you but I don't think so we're getting

00:45:44,099 --> 00:45:47,849
to the end it's a shame because I feel

00:45:46,169 --> 00:45:49,589
now it's really like we're getting to a

00:45:47,849 --> 00:45:50,699
very interesting point that it just

00:45:49,589 --> 00:45:53,549
means we have to continue the

00:45:50,699 --> 00:45:57,119
conversation and so but I would like to

00:45:53,549 --> 00:45:59,429
ask closing questions to you and to

00:45:57,119 --> 00:46:02,160
answer this like from your company and

00:45:59,429 --> 00:46:05,909
personal perspective and so like years

00:46:02,160 --> 00:46:07,949
ago it was very like much easier to put

00:46:05,909 --> 00:46:10,319
on a conference like let's say was a

00:46:07,949 --> 00:46:13,019
single theme yeah you could say okay

00:46:10,319 --> 00:46:15,390
mobile technologies now everything is

00:46:13,019 --> 00:46:17,009
about the smartphone right so you make

00:46:15,390 --> 00:46:18,749
conference mobile technologies and how

00:46:17,009 --> 00:46:21,509
we can do it open source and so on and

00:46:18,749 --> 00:46:24,569
it was very difficult for us to actually

00:46:21,509 --> 00:46:26,880
grasp all these changes that are

00:46:24,569 --> 00:46:28,890
happening at the moment okay we always

00:46:26,880 --> 00:46:31,109
talk about rapid changes and revolutions

00:46:28,890 --> 00:46:33,119
on but right now really and so many

00:46:31,109 --> 00:46:34,999
topics yeah I mean you can see AI

00:46:33,119 --> 00:46:37,319
machine learning cloud blockchain

00:46:34,999 --> 00:46:39,839
conversational web how can we touch all

00:46:37,319 --> 00:46:41,729
of this just becoming more and more but

00:46:39,839 --> 00:46:43,890
I would like to get a statement from

00:46:41,729 --> 00:46:45,900
each of you from your personal

00:46:43,890 --> 00:46:48,479
perspective so what tools and

00:46:45,900 --> 00:46:53,189
technologies are most promising for you

00:46:48,479 --> 00:46:56,429
right now I mean it's interesting the

00:46:53,189 --> 00:46:57,999
point you make because I think IT kinda

00:46:56,429 --> 00:47:00,639
goes through cycles and wheels

00:46:57,999 --> 00:47:02,079
until you know maybe something will just

00:47:00,639 --> 00:47:04,809
drop the cycle in the next 10-15 years

00:47:02,079 --> 00:47:06,879
but I haven't seen it yet and so we're

00:47:04,809 --> 00:47:08,169
going through a cycle of pull the data

00:47:06,879 --> 00:47:10,089
back to the center and that's all

00:47:08,169 --> 00:47:11,679
computer in it I think the next set of

00:47:10,089 --> 00:47:14,859
things and it's pretty common knowledge

00:47:11,679 --> 00:47:17,649
is well the laws of physics still kick

00:47:14,859 --> 00:47:18,879
in there's only so much the speed of

00:47:17,649 --> 00:47:20,379
Lights willing to propagate through a

00:47:18,879 --> 00:47:22,149
fiber or even through all oak or

00:47:20,379 --> 00:47:23,649
whatever it is so I need to do more work

00:47:22,149 --> 00:47:25,869
at the edge in order to be able to only

00:47:23,649 --> 00:47:29,799
send back signals so you end up with

00:47:25,869 --> 00:47:31,329
this sort of I have model at the edge I

00:47:29,799 --> 00:47:33,009
have an incomplete model at the center

00:47:31,329 --> 00:47:34,839
because I've got a thousand other models

00:47:33,009 --> 00:47:36,489
and I'm looking at problem I think

00:47:34,839 --> 00:47:37,929
that's really what the next few years

00:47:36,489 --> 00:47:40,089
are gonna be I think it's gonna be about

00:47:37,929 --> 00:47:41,859
how do we do more at the edge I think

00:47:40,089 --> 00:47:43,389
it's gonna be ahead of you it really is

00:47:41,859 --> 00:47:44,919
about the connected homes but that's

00:47:43,389 --> 00:47:46,089
that's sort of from a consumer

00:47:44,919 --> 00:47:47,499
perspective and I don't really know that

00:47:46,089 --> 00:47:48,789
much about it but from a business

00:47:47,499 --> 00:47:51,099
perspective it's gonna be around how do

00:47:48,789 --> 00:47:52,899
I make smart decisions about something

00:47:51,099 --> 00:47:54,309
that's localized that's a high volume of

00:47:52,899 --> 00:47:56,559
data that I need to process within the

00:47:54,309 --> 00:47:58,959
local scope but that will be affected

00:47:56,559 --> 00:48:02,049
and will affect lots of other scopes and

00:47:58,959 --> 00:48:03,369
so there's gonna be some feedback cycle

00:48:02,049 --> 00:48:06,519
that we need to work our way through

00:48:03,369 --> 00:48:07,959
it's all right now just beginning I

00:48:06,519 --> 00:48:09,969
think we can see that this sort of if

00:48:07,959 --> 00:48:12,879
it's an urban flow is it we're in 80

00:48:09,969 --> 00:48:14,499
cycles we're in the beginning of that

00:48:12,879 --> 00:48:17,979
flow we're kind of moving back but I'm

00:48:14,499 --> 00:48:20,709
it's gonna be a little fun okay I think

00:48:17,979 --> 00:48:22,689
that your question is asking whether you

00:48:20,709 --> 00:48:25,449
know how all this emerging technologies

00:48:22,689 --> 00:48:27,579
how do we view it and how you affected

00:48:25,449 --> 00:48:29,829
our business definitely all these

00:48:27,579 --> 00:48:31,839
emerging technology we see it as no more

00:48:29,829 --> 00:48:34,749
just hi me usually they go through the

00:48:31,839 --> 00:48:38,169
hype cycle so as a user organization we

00:48:34,749 --> 00:48:40,419
usually have to be very careful and come

00:48:38,169 --> 00:48:42,309
assess whether it is still just a type

00:48:40,419 --> 00:48:44,709
stitch or at the mass adoption stage or

00:48:42,309 --> 00:48:46,659
you know is it ready for us to get into

00:48:44,709 --> 00:48:47,909
it so certain of these technologies like

00:48:46,659 --> 00:48:50,409
let's take a cloud computing

00:48:47,909 --> 00:48:52,299
surprisingly AI we take it that now is

00:48:50,409 --> 00:48:54,579
definitely mentioned is going to be

00:48:52,299 --> 00:48:56,949
ingrained into our business but things

00:48:54,579 --> 00:48:59,169
like blockchain I see it more like long

00:48:56,949 --> 00:49:01,689
cannot be revenue reform in the industry

00:48:59,169 --> 00:49:04,469
but it's not so soon so we were just

00:49:01,689 --> 00:49:04,469
taking a monitor

00:49:06,230 --> 00:49:15,500
so around tools and technologies I think

00:49:11,220 --> 00:49:17,790
I think what we're seeing emerging and

00:49:15,500 --> 00:49:20,839
something that we're developing as well

00:49:17,790 --> 00:49:26,760
is how do we provide that environment

00:49:20,839 --> 00:49:29,070
the the platform for doing data sights

00:49:26,760 --> 00:49:32,190
I guess machine learning AI or this data

00:49:29,070 --> 00:49:33,990
oriented stuff and it is a science so we

00:49:32,190 --> 00:49:38,280
call it data science it is a science it

00:49:33,990 --> 00:49:39,680
is about experimentation and a key thing

00:49:38,280 --> 00:49:42,359
of that is how do we support

00:49:39,680 --> 00:49:44,369
experimentation things called parameter

00:49:42,359 --> 00:49:46,849
sweeps where we are building models and

00:49:44,369 --> 00:49:49,230
we're looking at hundreds of different

00:49:46,849 --> 00:49:50,700
possible parameters and then choose the

00:49:49,230 --> 00:49:52,890
business model out of that it's almost

00:49:50,700 --> 00:49:55,560
random search to find something that

00:49:52,890 --> 00:49:57,900
actually works how do we support all of

00:49:55,560 --> 00:50:00,050
this experimentation and so we're seeing

00:49:57,900 --> 00:50:04,160
a whole platform being developed around

00:50:00,050 --> 00:50:07,319
model experimentation model deployment

00:50:04,160 --> 00:50:08,460
and model management becomes important

00:50:07,319 --> 00:50:10,829
when you've got so many different

00:50:08,460 --> 00:50:13,230
techniques new technique new algorithms

00:50:10,829 --> 00:50:15,420
emerging daily into the open-source

00:50:13,230 --> 00:50:17,310
community we want to adopt those

00:50:15,420 --> 00:50:19,500
techniques experiment with them really

00:50:17,310 --> 00:50:22,380
really quickly and see whether they can

00:50:19,500 --> 00:50:24,900
be useful to us so want to shorten that

00:50:22,380 --> 00:50:26,400
cycle and get excited quickly with

00:50:24,900 --> 00:50:28,710
things that are really working for us

00:50:26,400 --> 00:50:33,210
something adapt them for our own

00:50:28,710 --> 00:50:35,210
environments so I think if you if you

00:50:33,210 --> 00:50:38,099
look back a little bit at 10 20 years

00:50:35,210 --> 00:50:40,349
then and you think about the successful

00:50:38,099 --> 00:50:42,210
technologies like email for example

00:50:40,349 --> 00:50:44,190
email was successful because everybody

00:50:42,210 --> 00:50:45,420
can run a mail server and we can roll

00:50:44,190 --> 00:50:46,650
communicate with each other

00:50:45,420 --> 00:50:48,450
there wasn't there's no central mail

00:50:46,650 --> 00:50:50,609
server on the planet everybody can hit

00:50:48,450 --> 00:50:52,589
one the same with the World Wide Web but

00:50:50,609 --> 00:50:55,410
what worked one against like this old

00:50:52,589 --> 00:50:56,640
like AOL and other proprietary services

00:50:55,410 --> 00:50:59,040
because everybody can run a website

00:50:56,640 --> 00:51:01,770
there's no central instance no one has a

00:50:59,040 --> 00:51:03,660
destiny the central half of all the

00:51:01,770 --> 00:51:05,940
pages doesn't exist completely

00:51:03,660 --> 00:51:08,190
distributed but nowadays with a lot of

00:51:05,940 --> 00:51:10,470
modern more modern technologies like we

00:51:08,190 --> 00:51:12,170
have to have social networking for

00:51:10,470 --> 00:51:14,960
example or we have

00:51:12,170 --> 00:51:17,720
with Google and some others we have the

00:51:14,960 --> 00:51:20,390
trend of centralization but suddenly you

00:51:17,720 --> 00:51:22,520
can't really run it yourself it only

00:51:20,390 --> 00:51:24,650
exists like once on the planet and

00:51:22,520 --> 00:51:26,780
Facebook gets its own you wantem Google

00:51:24,650 --> 00:51:28,640
exists only ones and lots of this other

00:51:26,780 --> 00:51:31,400
technology Google system only exists

00:51:28,640 --> 00:51:32,780
once and so on so I think if you to come

00:51:31,400 --> 00:51:34,250
back to your question what are the most

00:51:32,780 --> 00:51:36,290
promising and more interesting

00:51:34,250 --> 00:51:38,630
technologies I think for me everything

00:51:36,290 --> 00:51:40,130
that's decentralized it's like really

00:51:38,630 --> 00:51:43,130
interesting and something we should

00:51:40,130 --> 00:51:45,380
explore so I don't I'm not a fan of

00:51:43,130 --> 00:51:47,110
centralization I think with the help of

00:51:45,380 --> 00:51:48,950
free software and open source and

00:51:47,110 --> 00:51:51,380
decentralized technologies like a

00:51:48,950 --> 00:51:53,240
decentralized search engine I just think

00:51:51,380 --> 00:51:55,220
someone for example I'm still working it

00:51:53,240 --> 00:51:57,500
our decentralized social networking

00:51:55,220 --> 00:52:00,920
decentralized artificial intelligence

00:51:57,500 --> 00:52:07,250
decentralized and machine learning this

00:52:00,920 --> 00:52:10,700
is like the future very much so yeah and

00:52:07,250 --> 00:52:13,100
like I also want to take the Virginia we

00:52:10,700 --> 00:52:16,130
need you also a few words what we are

00:52:13,100 --> 00:52:17,360
doing here and and so actually for the

00:52:16,130 --> 00:52:20,210
first area it's not just the conference

00:52:17,360 --> 00:52:22,790
actually we are a community is one of

00:52:20,210 --> 00:52:25,090
the largest tech communities in the

00:52:22,790 --> 00:52:28,190
world like of the top 50 on github and

00:52:25,090 --> 00:52:30,170
and so we develop a lot of stuff all

00:52:28,190 --> 00:52:33,410
services often often like small projects

00:52:30,170 --> 00:52:36,680
and but like so what's our motivation

00:52:33,410 --> 00:52:38,990
behind this right we are very interested

00:52:36,680 --> 00:52:40,340
in the future it's the topic we started

00:52:38,990 --> 00:52:43,160
off with they're like we are we're

00:52:40,340 --> 00:52:45,290
excited like let's say like ideas I have

00:52:43,160 --> 00:52:47,420
some friends you they say ok we fly to

00:52:45,290 --> 00:52:50,000
Mars so we can't connect with the

00:52:47,420 --> 00:52:52,040
central server on the internet here

00:52:50,000 --> 00:52:55,670
right like so people have all kinds of

00:52:52,040 --> 00:52:58,130
amazing ideas and all these questions

00:52:55,670 --> 00:53:00,080
come up like data science questions you

00:52:58,130 --> 00:53:02,840
know I mean like if you have algorithms

00:53:00,080 --> 00:53:04,550
like actually real life decisions and

00:53:02,840 --> 00:53:06,740
science are so close to each other like

00:53:04,550 --> 00:53:08,600
it's not like in the old times you have

00:53:06,740 --> 00:53:10,220
like some scientists you find something

00:53:08,600 --> 00:53:11,780
and then years later we'll use it as

00:53:10,220 --> 00:53:15,710
actually data science it's like part of

00:53:11,780 --> 00:53:18,740
every company so how do we replicate it

00:53:15,710 --> 00:53:21,000
sciences that must be replicable right

00:53:18,740 --> 00:53:23,280
you don't have the data we can traffic

00:53:21,000 --> 00:53:25,680
yeah is it true what they are telling us

00:53:23,280 --> 00:53:28,760
or not so a lot of these questions will

00:53:25,680 --> 00:53:31,380
be discussed over the next few days and

00:53:28,760 --> 00:53:33,780
so their questions in into the future

00:53:31,380 --> 00:53:37,050
and there are questions very close like

00:53:33,780 --> 00:53:38,970
the conversational in web so this is

00:53:37,050 --> 00:53:41,970
something that's happening now and this

00:53:38,970 --> 00:53:44,300
is a topic over the next few days and

00:53:41,970 --> 00:53:46,950
the question how can we run it ourselves

00:53:44,300 --> 00:53:51,690
without having to connect to next and so

00:53:46,950 --> 00:53:54,119
so I hope you got inspired well I did

00:53:51,690 --> 00:53:55,800
like I have a lot of new questions that

00:53:54,119 --> 00:53:58,080
are coming up to my mind and I hope to

00:53:55,800 --> 00:53:59,820
continue these conversations here and

00:53:58,080 --> 00:54:02,490
also the conversations how we can

00:53:59,820 --> 00:54:04,560
collaborate in future and between

00:54:02,490 --> 00:54:07,260
different communities I hope you will

00:54:04,560 --> 00:54:09,840
stay maybe visit us on some other days

00:54:07,260 --> 00:54:12,090
and be part of the tracks and I would

00:54:09,840 --> 00:54:16,410
like to thank everyone here on the panel

00:54:12,090 --> 00:54:18,180
and Ramji liang gray and Frank thank you

00:54:16,410 --> 00:54:20,420
very much for joining us and thank you

00:54:18,180 --> 00:54:27,870
very much for giving us the opportunity

00:54:20,420 --> 00:54:30,620
[Applause]

00:54:27,870 --> 00:54:30,620

YouTube URL: https://www.youtube.com/watch?v=JvEH-eOSRHI


