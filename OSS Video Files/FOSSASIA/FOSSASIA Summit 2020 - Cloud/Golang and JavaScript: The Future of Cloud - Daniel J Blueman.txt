Title: Golang and JavaScript: The Future of Cloud - Daniel J Blueman
Publication date: 2020-03-26
Playlist: FOSSASIA Summit 2020 - Cloud
Description: 
	The talk addresses strategies to develop cloud applications using Golang and JavaScript and includes a quick look at some code sections.

FOSSASIA Summit 2020 - Cloud

Speaker: Daniel J Blueman, FOSSASIA
Captions: 
	00:00:00,000 --> 00:00:06,240
oh it's clouds systems today I'm using

00:00:03,170 --> 00:00:09,840
alkaline and JavaScript so quite an

00:00:06,240 --> 00:00:12,090
interesting combination my my PDF is

00:00:09,840 --> 00:00:12,750
online here at this URL so later you

00:00:12,090 --> 00:00:15,870
could download it

00:00:12,750 --> 00:00:21,480
it'll be also shown at the ends at link

00:00:15,870 --> 00:00:23,430
in my email and such so I was like

00:00:21,480 --> 00:00:26,460
system developer doing kernel

00:00:23,430 --> 00:00:28,800
development drivers platforms for like

00:00:26,460 --> 00:00:31,529
quite a while now and then more recently

00:00:28,800 --> 00:00:36,000
been doing simply can design silicon

00:00:31,529 --> 00:00:38,420
verification and now only the last a

00:00:36,000 --> 00:00:42,540
couple of years doing some front-end web

00:00:38,420 --> 00:00:46,160
work and what I'd say is it's

00:00:42,540 --> 00:00:49,020
interesting almost kind of almost quite

00:00:46,160 --> 00:00:51,809
enlightening going from being more like

00:00:49,020 --> 00:00:54,600
low-level then getting in the ends

00:00:51,809 --> 00:00:57,420
lighter more kind of like high-level

00:00:54,600 --> 00:01:00,649
JavaScript front-end systems kind of

00:00:57,420 --> 00:01:02,670
interesting often perhaps it could be

00:01:00,649 --> 00:01:08,310
people are working only at a single

00:01:02,670 --> 00:01:11,340
layer so gonna talk about one of the

00:01:08,310 --> 00:01:15,750
projects I worked on recently I last two

00:01:11,340 --> 00:01:19,590
years and it's going to go through the

00:01:15,750 --> 00:01:22,049
problem statements different ways I

00:01:19,590 --> 00:01:25,619
could have solved it and then looking at

00:01:22,049 --> 00:01:31,890
how I looked at the project design going

00:01:25,619 --> 00:01:33,540
to give a a demonstration also even have

00:01:31,890 --> 00:01:35,400
a look at the code as well unlike see

00:01:33,540 --> 00:01:38,340
how it actually looks some of the we

00:01:35,400 --> 00:01:42,869
kind of core parts of the code then also

00:01:38,340 --> 00:01:46,790
talked about some of the limitations so

00:01:42,869 --> 00:01:51,030
um in our company I was working on some

00:01:46,790 --> 00:01:54,060
project to to expose the silicon chip

00:01:51,030 --> 00:01:57,810
counters so typically silicon chips burn

00:01:54,060 --> 00:02:00,210
at high frequency they then have like

00:01:57,810 --> 00:02:03,270
other counters the increment and many

00:02:00,210 --> 00:02:05,750
megahertz so how do you how do you count

00:02:03,270 --> 00:02:08,459
events how do you then show that live

00:02:05,750 --> 00:02:11,069
like unlike it like a like a kind of

00:02:08,459 --> 00:02:13,450
graphing or like dashboard so the people

00:02:11,069 --> 00:02:14,860
can like Behnken engineers can then

00:02:13,450 --> 00:02:18,340
you start or customers can then use that

00:02:14,860 --> 00:02:22,090
how is my my system working is it

00:02:18,340 --> 00:02:24,190
working efficiently and so obviously

00:02:22,090 --> 00:02:25,540
having a lot of data like that how do

00:02:24,190 --> 00:02:27,370
you

00:02:25,540 --> 00:02:30,099
I don't know how do you capture it

00:02:27,370 --> 00:02:33,459
efficiently and then how do you graph it

00:02:30,099 --> 00:02:39,310
in real time so that's really that was

00:02:33,459 --> 00:02:41,769
the the goal here and then of course

00:02:39,310 --> 00:02:44,049
having am like a high rates of data

00:02:41,769 --> 00:02:46,540
being streamed in real time with

00:02:44,049 --> 00:02:49,690
recently a little latency actually

00:02:46,540 --> 00:02:54,069
presents quite a conflicting problem

00:02:49,690 --> 00:02:57,040
there because it's like latency and and

00:02:54,069 --> 00:03:00,610
volume of data is is you know hundreds

00:02:57,040 --> 00:03:03,160
of megabytes and of course you want to

00:03:00,610 --> 00:03:07,660
stream only like a matter of kilobytes

00:03:03,160 --> 00:03:08,079
on to your front end so um how do we

00:03:07,660 --> 00:03:10,360
solve that

00:03:08,079 --> 00:03:16,480
well obviously cloud services are like

00:03:10,360 --> 00:03:18,639
the the future and like now Trust Bank

00:03:16,480 --> 00:03:23,040
restore established and security is

00:03:18,639 --> 00:03:27,489
there so there's no issues with with

00:03:23,040 --> 00:03:31,450
pushing this data through onto your your

00:03:27,489 --> 00:03:35,680
front end via like a like service

00:03:31,450 --> 00:03:40,780
running in the cloud so it's it's

00:03:35,680 --> 00:03:42,819
obviously the solution you want now in

00:03:40,780 --> 00:03:46,239
terms of choosing different languages

00:03:42,819 --> 00:03:46,810
there's of course and you a few newer

00:03:46,239 --> 00:03:49,180
languages

00:03:46,810 --> 00:03:52,209
more recently these days but in the past

00:03:49,180 --> 00:03:54,280
you had things like C which were way

00:03:52,209 --> 00:03:56,620
more mechanical you had libraries you

00:03:54,280 --> 00:03:59,260
had a lot of integration work to do to

00:03:56,620 --> 00:04:04,239
use these libraries and like C++ you had

00:03:59,260 --> 00:04:06,609
more layering of course perhaps Java

00:04:04,239 --> 00:04:09,010
also like many libraries you can

00:04:06,609 --> 00:04:12,280
integrate and and of course so on but

00:04:09,010 --> 00:04:14,739
then as you get to the higher level

00:04:12,280 --> 00:04:17,139
languages like Python then you end up

00:04:14,739 --> 00:04:19,359
with with like slower performance less

00:04:17,139 --> 00:04:23,349
scalable to see more more like memory

00:04:19,359 --> 00:04:25,630
overhead and so here of course obviously

00:04:23,349 --> 00:04:26,980
something is missing here and of course

00:04:25,630 --> 00:04:28,900
our JavaScript

00:04:26,980 --> 00:04:30,700
and so that's that's one of the key

00:04:28,900 --> 00:04:32,170
things here so you can if you offload a

00:04:30,700 --> 00:04:35,650
lot of the processing onto the front

00:04:32,170 --> 00:04:38,020
ends like data production or that kind

00:04:35,650 --> 00:04:41,010
of thing then of course you can you can

00:04:38,020 --> 00:04:45,580
have quite a responsive efficient

00:04:41,010 --> 00:04:48,610
dashboard or interface so here we like

00:04:45,580 --> 00:04:50,830
like rust under course go there

00:04:48,610 --> 00:04:53,280
obviously quite quite recent and like

00:04:50,830 --> 00:04:56,290
the last ten years and they've been

00:04:53,280 --> 00:04:58,720
really quite instrumental in changing

00:04:56,290 --> 00:05:01,270
how you implement or giving you the

00:04:58,720 --> 00:05:04,660
tools and then implement unlike cloud

00:05:01,270 --> 00:05:07,270
services web servers and of course have

00:05:04,660 --> 00:05:09,520
integration across that's about stark

00:05:07,270 --> 00:05:12,460
whereas previously you'd have the HP

00:05:09,520 --> 00:05:15,840
running under Apache and then you'd have

00:05:12,460 --> 00:05:19,030
other like separate middleware running

00:05:15,840 --> 00:05:21,670
so on so here of course with like go

00:05:19,030 --> 00:05:24,100
arrest you can integrate things which

00:05:21,670 --> 00:05:29,290
which like makes it much more efficient

00:05:24,100 --> 00:05:35,500
and easier managing it so here I chose

00:05:29,290 --> 00:05:37,780
go and then let's see I'd say that this

00:05:35,500 --> 00:05:40,240
now a like a huge amount of information

00:05:37,780 --> 00:05:43,180
out there so it's pretty good choice

00:05:40,240 --> 00:05:44,230
pretty well supported and also you can

00:05:43,180 --> 00:05:47,860
cross compile two different

00:05:44,230 --> 00:05:52,240
architectures how many people have heard

00:05:47,860 --> 00:05:53,710
about arm in the cloud exactly yeah a

00:05:52,240 --> 00:05:55,240
few of us could actually half the

00:05:53,710 --> 00:05:57,010
audience that's really good that's the

00:05:55,240 --> 00:06:01,900
future and it's happening now so now you

00:05:57,010 --> 00:06:06,340
have many hosting many companies making

00:06:01,900 --> 00:06:09,910
making chips with 80 64 cause 128 calls

00:06:06,340 --> 00:06:15,520
in one single chip it's going to take

00:06:09,910 --> 00:06:17,140
off in the next few years anyway so of

00:06:15,520 --> 00:06:18,940
course one of the key things there is is

00:06:17,140 --> 00:06:23,680
with go you can very easily cross

00:06:18,940 --> 00:06:29,050
compile onto arm so and therefore you

00:06:23,680 --> 00:06:30,850
can deploy your services efficiently now

00:06:29,050 --> 00:06:34,780
in terms of the architecture that I used

00:06:30,850 --> 00:06:37,000
for my application pretty simply and we

00:06:34,780 --> 00:06:38,440
need some communication between the

00:06:37,000 --> 00:06:40,479
client and the server two-way

00:06:38,440 --> 00:06:43,270
communication so that the server can

00:06:40,479 --> 00:06:46,449
send data asynchronously back to the

00:06:43,270 --> 00:06:50,259
clients so because HTTP will only

00:06:46,449 --> 00:06:53,080
request when the client wants then you

00:06:50,259 --> 00:06:56,879
need a of cross-channel back from the

00:06:53,080 --> 00:07:00,689
server so we're going to use like

00:06:56,879 --> 00:07:03,999
WebSockets for that's so key thing about

00:07:00,689 --> 00:07:06,900
of course like golang is it's compiled

00:07:03,999 --> 00:07:10,240
unlike Python so it's actually quite

00:07:06,900 --> 00:07:14,349
efficient with CPU usage easy to

00:07:10,240 --> 00:07:17,080
integrate with different libraries

00:07:14,349 --> 00:07:20,830
either from get low so I get hurt but

00:07:17,080 --> 00:07:25,900
all like built-in libraries and you have

00:07:20,830 --> 00:07:28,810
pretty rapid build times and time mr.

00:07:25,900 --> 00:07:31,479
Burnett unlike for example if you if

00:07:28,810 --> 00:07:35,289
anyone has used a boost build times can

00:07:31,479 --> 00:07:38,379
be like many minutes you have built-in

00:07:35,289 --> 00:07:40,389
language concurrency which is really

00:07:38,379 --> 00:07:42,969
really nice and then channels for

00:07:40,389 --> 00:07:46,810
communicating states and data and then

00:07:42,969 --> 00:07:48,399
also it has lower like everything is

00:07:46,810 --> 00:07:49,810
built into the binary so you don't have

00:07:48,399 --> 00:07:54,490
all all these libraries you got a check

00:07:49,810 --> 00:07:57,099
and actually I'm in fact mentioning that

00:07:54,490 --> 00:08:01,330
you can you can have the equivalent of a

00:07:57,099 --> 00:08:03,520
kind of a docker ice container if you

00:08:01,330 --> 00:08:08,409
just if you run this if you run your

00:08:03,520 --> 00:08:12,749
binary and you edit the the the systemd

00:08:08,409 --> 00:08:16,300
file then you can isolate all of the the

00:08:12,749 --> 00:08:18,789
namespace the pit Bank space and so on

00:08:16,300 --> 00:08:22,300
so actually you can actually secure and

00:08:18,789 --> 00:08:25,300
isolate your binary as it's a like

00:08:22,300 --> 00:08:27,490
single binary okay so here of course

00:08:25,300 --> 00:08:30,339
JavaScript obviously it's really mature

00:08:27,490 --> 00:08:33,159
very very well known so easy pool of

00:08:30,339 --> 00:08:38,889
talent available so very good choice for

00:08:33,159 --> 00:08:41,969
this this approach and then here the key

00:08:38,889 --> 00:08:44,769
thing perhaps when you're you're you're

00:08:41,969 --> 00:08:47,560
developing such an application is you

00:08:44,769 --> 00:08:49,120
then you like map out your protocol so

00:08:47,560 --> 00:08:51,290
your messages

00:08:49,120 --> 00:08:53,209
probably encoded in JSON

00:08:51,290 --> 00:08:56,899
that happened between the client and the

00:08:53,209 --> 00:08:59,209
server once you've worked out okay the

00:08:56,899 --> 00:09:01,490
the message flow and all the kind of

00:08:59,209 --> 00:09:06,490
behavior surrounding Mars then you can

00:09:01,490 --> 00:09:12,139
begin to implement here what I did is is

00:09:06,490 --> 00:09:14,660
I actually have like a very simple kind

00:09:12,139 --> 00:09:19,639
of like a handshake for signing on like

00:09:14,660 --> 00:09:23,029
from the clients then I send States for

00:09:19,639 --> 00:09:25,250
example and any any information needed

00:09:23,029 --> 00:09:29,630
for drawing the UI I'm on the clients

00:09:25,250 --> 00:09:32,329
and then also the client will then ask

00:09:29,630 --> 00:09:34,940
okay I want these events to be shown and

00:09:32,329 --> 00:09:37,130
so then will will then like transmit

00:09:34,940 --> 00:09:42,100
these events like regular intervals and

00:09:37,130 --> 00:09:42,100
then rendering will occur on the clients

00:09:42,639 --> 00:09:51,019
so in terms of the the actual structure

00:09:46,220 --> 00:09:52,850
of the the code I am it's broken up into

00:09:51,019 --> 00:09:57,490
different modules in the different files

00:09:52,850 --> 00:10:01,339
and we have various threads here

00:09:57,490 --> 00:10:03,800
so the kinda main thing is is events

00:10:01,339 --> 00:10:07,029
being read from different sources in

00:10:03,800 --> 00:10:10,370
this case we have our silicon chip and

00:10:07,029 --> 00:10:13,269
also kernel VM counters and also

00:10:10,370 --> 00:10:15,800
processor counters as well so we can

00:10:13,269 --> 00:10:17,750
when we're running like a workload with

00:10:15,800 --> 00:10:20,510
our our silicon chip then you can see

00:10:17,750 --> 00:10:22,220
okay what is the kernel doing at the

00:10:20,510 --> 00:10:27,279
page faults how is the processor core

00:10:22,220 --> 00:10:34,010
load that data is then ingested and

00:10:27,279 --> 00:10:36,260
since sent to a like a file that is

00:10:34,010 --> 00:10:39,380
mapped in memory so that you have data

00:10:36,260 --> 00:10:42,620
like history information and encoded

00:10:39,380 --> 00:10:45,500
into a like a fixed binary format so

00:10:42,620 --> 00:10:51,699
it's efficient and then that's that's

00:10:45,500 --> 00:10:57,889
then sense also via Jason to the HTML

00:10:51,699 --> 00:11:01,760
clients there likewise we have let's see

00:10:57,889 --> 00:11:03,400
we have I'm sorry it sent via the web

00:11:01,760 --> 00:11:07,029
service threads here rather

00:11:03,400 --> 00:11:10,029
yeah that's also for static contents so

00:11:07,029 --> 00:11:14,410
everything is self hosting and then we

00:11:10,029 --> 00:11:17,290
also have a like like SSH client so that

00:11:14,410 --> 00:11:18,880
you can you can easily in your session

00:11:17,290 --> 00:11:20,460
logged into a server you can monitor

00:11:18,880 --> 00:11:23,500
these like stats

00:11:20,460 --> 00:11:26,070
I'm so like you can very easily see

00:11:23,500 --> 00:11:30,750
what's happening on a like system here

00:11:26,070 --> 00:11:30,750
okay so I'll show a live demonstration

00:11:38,460 --> 00:11:47,100
all right so here I'm logged into system

00:11:41,770 --> 00:11:47,100
here which has all of these processes

00:11:56,680 --> 00:12:04,970
okay so here I'm running a H stop here H

00:12:00,770 --> 00:12:06,860
top shows 144 cause here so that's one

00:12:04,970 --> 00:12:09,260
of our like our largest service with our

00:12:06,860 --> 00:12:11,960
silicon chips inside going to run my

00:12:09,260 --> 00:12:17,360
Numa scope project which is there for

00:12:11,960 --> 00:12:19,850
monitoring the the cache coherent events

00:12:17,360 --> 00:12:22,370
in our ships so other than that it's now

00:12:19,850 --> 00:12:34,820
listening here not sure if you guys can

00:12:22,370 --> 00:12:36,950
see that okay is likely yeah okay so

00:12:34,820 --> 00:12:40,250
better now right so it's listening on

00:12:36,950 --> 00:12:43,700
port 80 I'm forwarding report over SSH

00:12:40,250 --> 00:12:46,880
so I can connect from my browser to this

00:12:43,700 --> 00:12:50,200
this process moaning here what's

00:12:46,880 --> 00:12:54,590
happening is it's now it's now showing

00:12:50,200 --> 00:12:58,460
live updates from our silicon there and

00:12:54,590 --> 00:13:01,190
we can see um since since this is

00:12:58,460 --> 00:13:03,200
showing a cache coherent events

00:13:01,190 --> 00:13:03,860
occurring on on the actual CPU

00:13:03,200 --> 00:13:06,410
interconnects

00:13:03,860 --> 00:13:08,480
it's quite hard to explain the meaning

00:13:06,410 --> 00:13:10,760
of each of the events but right now we

00:13:08,480 --> 00:13:14,690
can see this something like fifty

00:13:10,760 --> 00:13:16,430
thousand occurring like that and right

00:13:14,690 --> 00:13:19,040
now there isn't any workload as we can

00:13:16,430 --> 00:13:25,130
see on H top so we're gonna run a

00:13:19,040 --> 00:13:26,680
benchmark this is the NASA NES power of

00:13:25,130 --> 00:13:30,290
the benchmarks which doing some

00:13:26,680 --> 00:13:35,420
mathematical operations and we should

00:13:30,290 --> 00:13:41,170
see the load here climbs nificantly so

00:13:35,420 --> 00:13:47,000
we have like real-time graphing here via

00:13:41,170 --> 00:13:48,620
d3.js and yeah so we can see now

00:13:47,000 --> 00:13:52,520
actually different different things

00:13:48,620 --> 00:13:56,600
happening we can pause this thing and we

00:13:52,520 --> 00:13:59,900
can zoom in and yeah there's some 17

00:13:56,600 --> 00:14:02,090
million events happening right now in

00:13:59,900 --> 00:14:05,750
the meanwhile this is now updating down

00:14:02,090 --> 00:14:10,370
here as well and we can

00:14:05,750 --> 00:14:11,270
zoom scrolling here now I just want to

00:14:10,370 --> 00:14:15,410
show you guys

00:14:11,270 --> 00:14:17,960
there's Colonel VM starts here that I'm

00:14:15,410 --> 00:14:20,390
capturing this is all done in in

00:14:17,960 --> 00:14:25,640
bootstrap actually and actually pretty

00:14:20,390 --> 00:14:28,700
simple and here I'm showing some

00:14:25,640 --> 00:14:30,770
interesting events for example how many

00:14:28,700 --> 00:14:34,310
page faults are happening which tells

00:14:30,770 --> 00:14:38,210
you when when there's memory allocated

00:14:34,310 --> 00:14:39,920
and consumes also I can select the

00:14:38,210 --> 00:14:42,710
always different event counters on my

00:14:39,920 --> 00:14:46,190
silicon chips so we can get a lot of

00:14:42,710 --> 00:14:48,650
interesting stats from this about our

00:14:46,190 --> 00:14:53,270
our silicon chip unlike if if for

00:14:48,650 --> 00:14:58,850
example it's working as we expect just

00:14:53,270 --> 00:15:00,980
finally we can also right now it's it's

00:14:58,850 --> 00:15:03,880
a bridging these over all of these six

00:15:00,980 --> 00:15:08,900
servers that we have because our chip

00:15:03,880 --> 00:15:11,990
lets you boot six like many service is

00:15:08,900 --> 00:15:14,300
one big server so we have six service

00:15:11,990 --> 00:15:19,120
there I'm gonna show you how it looks

00:15:14,300 --> 00:15:25,910
when I disable that's averaging and then

00:15:19,120 --> 00:15:30,280
it's broken down per server so particles

00:15:25,910 --> 00:15:33,020
explains why like like white 144 calls

00:15:30,280 --> 00:15:35,740
and then we can see there's there's

00:15:33,020 --> 00:15:39,740
actually some work load imbalance here I

00:15:35,740 --> 00:15:43,030
thought that we can see the the work

00:15:39,740 --> 00:15:47,300
load from from this across benchmark

00:15:43,030 --> 00:15:49,190
occurs differently on different servers

00:15:47,300 --> 00:15:51,980
so on on two servers it's like two

00:15:49,190 --> 00:15:54,080
million reads of cache lines second and

00:15:51,980 --> 00:15:56,660
then in for service it's only like 30

00:15:54,080 --> 00:15:59,120
thousands so you can see that this is

00:15:56,660 --> 00:16:01,190
not utilizing the benchmark here is not

00:15:59,120 --> 00:16:07,089
utilizing all all the service resources

00:16:01,190 --> 00:16:11,210
efficiently yeah good and in fact I can

00:16:07,089 --> 00:16:13,430
I'll go on to show you a little bit of

00:16:11,210 --> 00:16:16,400
the structure of how I serve this these

00:16:13,430 --> 00:16:19,020
files and the JavaScript the HTML and

00:16:16,400 --> 00:16:24,800
also the the

00:16:19,020 --> 00:16:24,800
the actually occurred line as well so

00:16:25,280 --> 00:16:28,610
back to the presentation

00:16:40,730 --> 00:16:45,600
okay so we've actually look at estimate

00:16:43,410 --> 00:16:48,630
the code here we have these different

00:16:45,600 --> 00:16:50,010
files generally it's nice breaking

00:16:48,630 --> 00:16:53,070
things down into files cuz then you can

00:16:50,010 --> 00:16:55,830
manage it then we like get history you

00:16:53,070 --> 00:16:58,710
can like get logged on a certain file

00:16:55,830 --> 00:17:01,080
and then it's easier tracking changes so

00:16:58,710 --> 00:17:03,630
I have these two files here interact

00:17:01,080 --> 00:17:08,520
areas and index.html which is served by

00:17:03,630 --> 00:17:11,820
B the built-in golang webserver and so

00:17:08,520 --> 00:17:14,400
those are the only only content that is

00:17:11,820 --> 00:17:18,270
that is served and that means you can

00:17:14,400 --> 00:17:20,310
actually you can run this application on

00:17:18,270 --> 00:17:21,150
an internal network which isn't exposed

00:17:20,310 --> 00:17:23,310
on the Internet

00:17:21,150 --> 00:17:26,430
there were no external and external kind

00:17:23,310 --> 00:17:30,590
of like files and resources needed then

00:17:26,430 --> 00:17:34,200
the actual events and the the

00:17:30,590 --> 00:17:36,630
measurement of the the kind of samples

00:17:34,200 --> 00:17:39,840
is done via these like these three

00:17:36,630 --> 00:17:43,260
different files here so this the events

00:17:39,840 --> 00:17:45,150
test file here that then lets me run go

00:17:43,260 --> 00:17:50,490
tests and then it will run some

00:17:45,150 --> 00:17:53,460
automatic verification of the different

00:17:50,490 --> 00:17:57,180
functions so then it's easier than to to

00:17:53,460 --> 00:18:01,560
then like address bugs and everything

00:17:57,180 --> 00:18:04,950
and then here I have an a like awesome I

00:18:01,560 --> 00:18:08,130
live a web web version and then also

00:18:04,950 --> 00:18:10,830
like a sampling version which I I can

00:18:08,130 --> 00:18:15,360
run offline so I can then later save a

00:18:10,830 --> 00:18:18,660
choice and that I can load later I also

00:18:15,360 --> 00:18:21,420
make sure that as well and then the

00:18:18,660 --> 00:18:25,560
top-level files here for the argument

00:18:21,420 --> 00:18:28,760
handling so I'm going to show you some

00:18:25,560 --> 00:18:32,299
of the very cool things here with go

00:18:28,760 --> 00:18:34,309
so here in Maine taco we have the

00:18:32,299 --> 00:18:39,080
argument handling very simple just with

00:18:34,309 --> 00:18:41,090
with passing any flags that you pass

00:18:39,080 --> 00:18:44,390
when you when you run any of the

00:18:41,090 --> 00:18:49,520
different modes of the binary so here

00:18:44,390 --> 00:18:52,340
live is is the one well what I was

00:18:49,520 --> 00:18:56,059
showing there like for the web interface

00:18:52,340 --> 00:18:58,880
start is is like like I can kinda like a

00:18:56,059 --> 00:19:01,700
like a Clive version which shows you on

00:18:58,880 --> 00:19:04,309
the terminal information and then of

00:19:01,700 --> 00:19:09,470
course record record then it gives you

00:19:04,309 --> 00:19:13,030
the like captures like all those starts

00:19:09,470 --> 00:19:13,030
on the disc so later you can load them

00:19:14,650 --> 00:19:22,490
here we have the function which then

00:19:17,690 --> 00:19:24,500
starts the HTTP server in effect all

00:19:22,490 --> 00:19:26,570
it's doing is calling HTTP the file

00:19:24,500 --> 00:19:30,320
server and then on a certain directory

00:19:26,570 --> 00:19:33,669
and saying if if the client access is a

00:19:30,320 --> 00:19:38,290
slash monitor then call function monitor

00:19:33,669 --> 00:19:41,390
monitor then we'll handle WebSockets and

00:19:38,290 --> 00:19:44,419
then and then it go here this like

00:19:41,390 --> 00:19:45,919
prefix go then makes this function HTTP

00:19:44,419 --> 00:19:50,090
listen and serve makes that one

00:19:45,919 --> 00:19:53,179
asynchronous so it's now serving HTTP

00:19:50,090 --> 00:19:57,080
requests so here monitor is used for

00:19:53,179 --> 00:20:03,040
hunting incoming connections for the

00:19:57,080 --> 00:20:05,840
JSON web socket and then it reads the

00:20:03,040 --> 00:20:08,330
like any kind of message that was

00:20:05,840 --> 00:20:11,210
written down it and then compares the e

00:20:08,330 --> 00:20:14,000
string if it matches the V secret key

00:20:11,210 --> 00:20:16,850
then it will F kind of fall through and

00:20:14,000 --> 00:20:20,360
if not then it'll just terminate like

00:20:16,850 --> 00:20:22,520
terminate the connection after that then

00:20:20,360 --> 00:20:27,590
it'll send down a bit of state here in

00:20:22,520 --> 00:20:31,790
like a map that's produced of events so

00:20:27,590 --> 00:20:40,580
then the UI can then build those lists

00:20:31,790 --> 00:20:42,590
of events so on to the the connect the

00:20:40,580 --> 00:20:45,440
sampling of the

00:20:42,590 --> 00:20:49,279
the events here so how do we actually

00:20:45,440 --> 00:20:51,950
how do you access the the registers on

00:20:49,279 --> 00:20:55,190
silicon chips well what we do is we call

00:20:51,950 --> 00:20:59,150
we open death man and then we M map

00:20:55,190 --> 00:21:01,669
death man a map will will let you access

00:20:59,150 --> 00:21:05,960
from your application like from an array

00:21:01,669 --> 00:21:09,080
your any of any silicone registers so

00:21:05,960 --> 00:21:13,360
any registers in your in your silicon it

00:21:09,080 --> 00:21:18,159
could be in any part of the system and

00:21:13,360 --> 00:21:21,980
so you then cast this an array and go

00:21:18,159 --> 00:21:24,140
which is can be considered unsafe

00:21:21,980 --> 00:21:27,080
because then you can you can access

00:21:24,140 --> 00:21:29,299
registers you're not meant to and then

00:21:27,080 --> 00:21:31,429
it like checks is this a really our Chet

00:21:29,299 --> 00:21:34,490
this the offender and like to buy

00:21:31,429 --> 00:21:38,240
slightly much and then after that it

00:21:34,490 --> 00:21:42,799
simply will like access some of the

00:21:38,240 --> 00:21:47,179
registers here and then and then later

00:21:42,799 --> 00:21:51,590
on it's enabled then then to to actually

00:21:47,179 --> 00:21:53,720
sample the the events by accessing this

00:21:51,590 --> 00:21:56,990
array later in like start control and

00:21:53,720 --> 00:21:59,510
then looking at the elapsed the the

00:21:56,990 --> 00:22:01,789
number of cycles elapsed since it like

00:21:59,510 --> 00:22:04,309
last sampled and then reaching out each

00:22:01,789 --> 00:22:08,630
of the each of the events of interest

00:22:04,309 --> 00:22:14,809
and then normalizing that like by the

00:22:08,630 --> 00:22:17,840
clock speed like those samples of course

00:22:14,809 --> 00:22:22,220
then it passed back and marshaled back

00:22:17,840 --> 00:22:24,559
to the clients and so so then what are

00:22:22,220 --> 00:22:26,929
the issues that actually but I found

00:22:24,559 --> 00:22:30,230
well if you're if you're like sending

00:22:26,929 --> 00:22:33,230
data at like say a thousand Hertz via a

00:22:30,230 --> 00:22:35,720
socket bucket the clients then it's a

00:22:33,230 --> 00:22:38,419
lot of congestion I mean it isn't

00:22:35,720 --> 00:22:41,330
efficiently parked and Jason also when

00:22:38,419 --> 00:22:44,270
the JavaScript then is passing it it's

00:22:41,330 --> 00:22:47,120
it's like I didn't only like like very

00:22:44,270 --> 00:22:50,090
very small loops so it's like doing a

00:22:47,120 --> 00:22:51,909
lot of work for a little data so

00:22:50,090 --> 00:22:55,449
batching

00:22:51,909 --> 00:22:59,440
so batching the the actual these events

00:22:55,449 --> 00:23:04,419
into like blocks really helps obviously

00:22:59,440 --> 00:23:08,279
like their time stamps and and then when

00:23:04,419 --> 00:23:12,159
actually when the graph is drawn then

00:23:08,279 --> 00:23:15,190
you like scroll it I don't like a like a

00:23:12,159 --> 00:23:16,599
lower frequency and then it's it's it's

00:23:15,190 --> 00:23:18,639
definitely smoothen earth but also it

00:23:16,599 --> 00:23:22,259
isn't being like drawing a thousand

00:23:18,639 --> 00:23:25,149
times like like a thousand Hertz also

00:23:22,259 --> 00:23:27,729
clearly like choosing I like to sing

00:23:25,149 --> 00:23:30,579
like a library that will be efficient

00:23:27,729 --> 00:23:34,209
for graphing so I think UJS is quite

00:23:30,579 --> 00:23:36,969
mature some of the other ones aren't

00:23:34,209 --> 00:23:40,719
ours like mature and therefore cannot

00:23:36,969 --> 00:23:44,109
handle millions of points and then also

00:23:40,719 --> 00:23:47,739
in the future and one thing I have to to

00:23:44,109 --> 00:23:50,859
also implement is is a loading loading

00:23:47,739 --> 00:23:53,139
in like blocks because if I like load

00:23:50,859 --> 00:23:56,079
like a like a really large trace file

00:23:53,139 --> 00:23:58,599
it'll it'll like jam the the kind of

00:23:56,079 --> 00:24:02,139
main loop for like for many many seconds

00:23:58,599 --> 00:24:05,229
and then it will block the the rendering

00:24:02,139 --> 00:24:10,809
thread in fact I'll just show you the

00:24:05,229 --> 00:24:15,969
loading traces here so here we can we

00:24:10,809 --> 00:24:22,179
can simply just access here I have some

00:24:15,969 --> 00:24:25,029
places here actually this one is okay

00:24:22,179 --> 00:24:28,839
anyway this one has an issue but then

00:24:25,029 --> 00:24:30,519
also we summarized various stats as well

00:24:28,839 --> 00:24:35,519
so we can see how many events occurred

00:24:30,519 --> 00:24:38,259
and also like the rate of events and

00:24:35,519 --> 00:24:42,579
then normally you'd be able to zoom

00:24:38,259 --> 00:24:46,449
around here and activate and deactivate

00:24:42,579 --> 00:24:49,629
different different races here and here

00:24:46,449 --> 00:24:51,369
all of the events are captured so on the

00:24:49,629 --> 00:24:54,299
chip so then you can really figure out

00:24:51,369 --> 00:24:57,549
what you want to see yep

00:24:54,299 --> 00:25:02,949
plus when I'm in life mode you can vary

00:24:57,549 --> 00:25:05,139
the the sample rate on the slider here

00:25:02,949 --> 00:25:05,680
and that's why that's why when you're

00:25:05,139 --> 00:25:08,770
sampling

00:25:05,680 --> 00:25:10,780
I like high-frequency like every say

00:25:08,770 --> 00:25:14,590
like few milliseconds then you really

00:25:10,780 --> 00:25:17,920
really must batch the updates finally

00:25:14,590 --> 00:25:21,730
I'll demonstrate the the actual will

00:25:17,920 --> 00:25:27,700
climb a stock put because it but that's

00:25:21,730 --> 00:25:31,150
of course quite useful as well so here

00:25:27,700 --> 00:25:34,690
and it's now running like a default set

00:25:31,150 --> 00:25:38,080
of events here so page falls at the end

00:25:34,690 --> 00:25:42,160
here shows you how many like pages being

00:25:38,080 --> 00:25:45,070
being used by the colonel across all all

00:25:42,160 --> 00:25:48,040
applications running and then here these

00:25:45,070 --> 00:25:51,430
these events here these end to victim

00:25:48,040 --> 00:25:55,020
blocks sent and and so on these are all

00:25:51,430 --> 00:26:00,580
cache coherent events so if I run my

00:25:55,020 --> 00:26:02,770
workload then we'll see definitely those

00:26:00,580 --> 00:26:09,130
we're going to spike but it's just

00:26:02,770 --> 00:26:12,370
resize this there we go yeah so we can

00:26:09,130 --> 00:26:15,700
see that we went from like say 50,000

00:26:12,370 --> 00:26:20,950
now to like 1.3 million two million that

00:26:15,700 --> 00:26:24,550
kind of thing so yeah and finally I can

00:26:20,950 --> 00:26:29,800
actually record this for later collect

00:26:24,550 --> 00:26:32,530
like like the later analysis so I'll

00:26:29,800 --> 00:26:36,030
just do a quick capture and then I'll

00:26:32,530 --> 00:26:36,030
load that into the UI and you can see

00:26:59,400 --> 00:27:07,170
okay I've copied it across and now I'm

00:27:01,960 --> 00:27:07,170
just loading as I see what's going on

00:27:10,110 --> 00:27:17,680
okay so here now we can analyze the

00:27:13,050 --> 00:27:20,080
events that the difficult here and here

00:27:17,680 --> 00:27:25,090
I can average across all surfers and if

00:27:20,080 --> 00:27:27,430
I let that again will ya make it easier

00:27:25,090 --> 00:27:30,250
okay good so here we can see is that

00:27:27,430 --> 00:27:32,620
like something interesting here so the

00:27:30,250 --> 00:27:38,230
number of weight cycles if I see a

00:27:32,620 --> 00:27:41,560
minute in yes so you can see that

00:27:38,230 --> 00:27:43,740
actually and on average there was

00:27:41,560 --> 00:27:49,090
probably about 80 percent per server

00:27:43,740 --> 00:27:51,880
waiting for our interconnect for

00:27:49,090 --> 00:27:55,690
resources so in this case we can see

00:27:51,880 --> 00:27:58,860
during this like time period during this

00:27:55,690 --> 00:28:01,480
benchmark our interconnected slow

00:27:58,860 --> 00:28:06,640
unblocking like reducing the throughput

00:28:01,480 --> 00:28:09,700
of the the execution good so that wraps

00:28:06,640 --> 00:28:15,280
up this is all published on github with

00:28:09,700 --> 00:28:25,780
along with the history here so I show

00:28:15,280 --> 00:28:27,970
you births yeah and this has also all

00:28:25,780 --> 00:28:33,130
the documentation here as well and then

00:28:27,970 --> 00:28:34,710
you can you can go cosplay on it and

00:28:33,130 --> 00:28:37,930
then build it something like that and

00:28:34,710 --> 00:28:40,600
then you have to run it as route because

00:28:37,930 --> 00:28:43,300
it accesses and maps the chip counters

00:28:40,600 --> 00:28:45,650
and then we also it tells you how to run

00:28:43,300 --> 00:28:52,090
it so

00:28:45,650 --> 00:28:52,090

YouTube URL: https://www.youtube.com/watch?v=YaEBLMa74HI


