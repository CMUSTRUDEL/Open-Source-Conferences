Title: Machine Learning Landscape Today by Aiko Klostermann
Publication date: 2019-03-27
Playlist: FOSSASIA Summit 2019 - Artificial Intelligence
Description: 
	15 March 2019 14:30, Event Hall 2-1

When you have a data-centric problem to solve and you look for a technology to support you with this: The machine intelligence landscape can be overwhelming.

I analysed the landscape using a data-driven approach and condensed the outcome into a consumable form.

Additionally, I came to the conclusion that there is a set of questions you have to ask yourself to make the best possible choice for your situation.

This talk will cover these questions and present the analysis results on the basis of these.

TL;DR: With this simple talk you will know which framework / toolkit / library is best suited for your problem. Machine Learning Consultants hate him!
Captions: 
	00:00:00,149 --> 00:00:04,920
hello everyone I how are you doing okay

00:00:03,899 --> 00:00:06,870
great

00:00:04,920 --> 00:00:10,860
awesome I hope you had a great pi day

00:00:06,870 --> 00:00:14,700
yesterday and today we have a quite

00:00:10,860 --> 00:00:18,090
interesting they still ahead of us

00:00:14,700 --> 00:00:19,439
promising I track and I would just like

00:00:18,090 --> 00:00:21,630
to do my part and talk a little bit

00:00:19,439 --> 00:00:24,720
about the machine learning landscape

00:00:21,630 --> 00:00:25,619
that we have today so as announced my

00:00:24,720 --> 00:00:27,630
name is Aiko

00:00:25,619 --> 00:00:31,830
I work for a company called thought

00:00:27,630 --> 00:00:34,380
works and we are consultancy which means

00:00:31,830 --> 00:00:36,420
we build individual software for

00:00:34,380 --> 00:00:40,379
different clients and in in different

00:00:36,420 --> 00:00:43,079
domains using different technologies and

00:00:40,379 --> 00:00:45,690
we try to follow what we would consider

00:00:43,079 --> 00:00:53,610
the best practices so we try to be agile

00:00:45,690 --> 00:00:55,250
like actually as I try to follow

00:00:53,610 --> 00:00:56,730
it's like test-driven development

00:00:55,250 --> 00:01:00,930
continuous integration continuous

00:00:56,730 --> 00:01:02,699
delivery and pair programming and we are

00:01:00,930 --> 00:01:06,390
also a huge fan of open source software

00:01:02,699 --> 00:01:08,610
and so there's this one statistic that I

00:01:06,390 --> 00:01:14,700
found so this is where the arrow this is

00:01:08,610 --> 00:01:16,470
the company and apparently we are number

00:01:14,700 --> 00:01:18,570
eight on that list so whatever I mean

00:01:16,470 --> 00:01:20,009
the statistic being used here is the

00:01:18,570 --> 00:01:21,630
employees the number of employees

00:01:20,009 --> 00:01:25,490
contributing to open source software on

00:01:21,630 --> 00:01:28,290
get I'm sure there are other statistics

00:01:25,490 --> 00:01:30,479
but I think it gives a gives a nice idea

00:01:28,290 --> 00:01:33,840
that there is that we do have some

00:01:30,479 --> 00:01:36,240
interest and for a company with around

00:01:33,840 --> 00:01:38,040
5,000 people I think that's quite

00:01:36,240 --> 00:01:40,520
impressive especially compared to some

00:01:38,040 --> 00:01:46,350
other lower on the list who are

00:01:40,520 --> 00:01:48,869
significant work power all right we also

00:01:46,350 --> 00:01:51,659
have an office in Singapore so check it

00:01:48,869 --> 00:01:54,329
out as we do some meetups I think Martin

00:01:51,659 --> 00:02:00,030
Fowler's coming next month and obviously

00:01:54,329 --> 00:02:02,189
as everyone in tech we hire as well yeah

00:02:00,030 --> 00:02:04,380
so working for consultancy kinda makes

00:02:02,189 --> 00:02:09,090
me a consultant but I would consider

00:02:04,380 --> 00:02:11,940
myself a developer and my my passion is

00:02:09,090 --> 00:02:13,560
machine learning and that started when I

00:02:11,940 --> 00:02:16,739
was at university I

00:02:13,560 --> 00:02:19,980
wrote my thesis about convolutional

00:02:16,739 --> 00:02:23,280
neural networks on on mobile devices and

00:02:19,980 --> 00:02:26,250
then later continued when I was working

00:02:23,280 --> 00:02:28,440
at clients at top works and one there's

00:02:26,250 --> 00:02:31,560
one particular client that I would like

00:02:28,440 --> 00:02:33,989
to tell you about that is that was

00:02:31,560 --> 00:02:37,410
online retailer in Germany the the

00:02:33,989 --> 00:02:39,959
second largest behind Amazon and what we

00:02:37,410 --> 00:02:45,239
did there was we use neural networks to

00:02:39,959 --> 00:02:47,340
predict orders based on browser session

00:02:45,239 --> 00:02:49,560
data so we looked at the browser session

00:02:47,340 --> 00:02:51,470
data of users that were coming in and

00:02:49,560 --> 00:02:54,930
then predicted how likely it is that

00:02:51,470 --> 00:02:56,760
that user will buy something within that

00:02:54,930 --> 00:02:59,730
session and if it would be unlikely we

00:02:56,760 --> 00:03:02,489
would give offer some discounts or

00:02:59,730 --> 00:03:04,440
something like like that but enough

00:03:02,489 --> 00:03:08,640
about me we hate to talk about machine

00:03:04,440 --> 00:03:11,730
learning and so as I heard before

00:03:08,640 --> 00:03:15,980
multiple times and as we all know AI

00:03:11,730 --> 00:03:18,510
machine learning all these terms are

00:03:15,980 --> 00:03:22,290
let's let's not say overhyped let's say

00:03:18,510 --> 00:03:24,870
popular nowadays and I think it would be

00:03:22,290 --> 00:03:27,870
good to get a common understanding of of

00:03:24,870 --> 00:03:31,290
what these term mean at least in my

00:03:27,870 --> 00:03:33,359
understanding and artificial

00:03:31,290 --> 00:03:37,160
intelligence and I mean we hear AI

00:03:33,359 --> 00:03:40,140
everywhere especially in the AI track

00:03:37,160 --> 00:03:42,030
artificial intelligence I I would

00:03:40,140 --> 00:03:44,519
consider artificial intelligence I like

00:03:42,030 --> 00:03:47,160
this definition that box for

00:03:44,519 --> 00:03:49,470
dictionaries takoma offers a lot and

00:03:47,160 --> 00:03:51,989
this is by the way also the definition

00:03:49,470 --> 00:03:54,209
you find when you ask Google to define

00:03:51,989 --> 00:03:57,090
artificial intelligence and it basically

00:03:54,209 --> 00:03:59,220
is the theory and development of

00:03:57,090 --> 00:04:04,109
computer systems able to perform tasks

00:03:59,220 --> 00:04:06,450
normally requiring human intelligence so

00:04:04,109 --> 00:04:08,880
that doesn't sound too crazy does it and

00:04:06,450 --> 00:04:13,109
and one example that I that I like is is

00:04:08,880 --> 00:04:15,389
a chess program where if you think of a

00:04:13,109 --> 00:04:17,220
person playing chess you would you would

00:04:15,389 --> 00:04:19,440
assume that person has like some level

00:04:17,220 --> 00:04:22,940
of intelligent to be able to play chess

00:04:19,440 --> 00:04:27,950
now if you make a computer play chess

00:04:22,940 --> 00:04:30,780
then that is the artificial

00:04:27,950 --> 00:04:32,490
but if you know how how chess works

00:04:30,780 --> 00:04:33,930
there are certain moves you can make and

00:04:32,490 --> 00:04:36,960
then in the next one you can make

00:04:33,930 --> 00:04:38,430
certain certain other moves you could

00:04:36,960 --> 00:04:39,720
basically brute force that right you

00:04:38,430 --> 00:04:42,360
could write like write a couple of

00:04:39,720 --> 00:04:44,520
if-else branches and then you can

00:04:42,360 --> 00:04:47,700
brute-force all the possible solutions

00:04:44,520 --> 00:04:52,290
and then find the one that gifts that

00:04:47,700 --> 00:04:53,700
makes you win that there chess game but

00:04:52,290 --> 00:04:57,600
then again brute forcing and reverse

00:04:53,700 --> 00:05:01,050
isn't isn't that crazy right so for me

00:04:57,600 --> 00:05:04,310
and for also dictionaries the definition

00:05:01,050 --> 00:05:07,320
of AI is less a technical more like a

00:05:04,310 --> 00:05:12,350
physiologic fists or love you know what

00:05:07,320 --> 00:05:15,180
I mean a rather technical but but more

00:05:12,350 --> 00:05:19,910
 right

00:05:15,180 --> 00:05:22,950
oh yes who was it thank you very much

00:05:19,910 --> 00:05:25,440
yeah but then so nothing nothing fancy

00:05:22,950 --> 00:05:28,770
so far but where the fan path starts

00:05:25,440 --> 00:05:31,140
from is machine learning where this

00:05:28,770 --> 00:05:32,720
defining your algorithm and that then

00:05:31,140 --> 00:05:35,340
follow step by step to achieve something

00:05:32,720 --> 00:05:39,120
it's really the case anymore like in

00:05:35,340 --> 00:05:40,800
machine learning where the way of

00:05:39,120 --> 00:05:43,890
solving a problem the way the algorithm

00:05:40,800 --> 00:05:47,160
works is actually defined by the data we

00:05:43,890 --> 00:05:48,800
put in to a machine and if we put in

00:05:47,160 --> 00:05:53,430
different data or we put in more data

00:05:48,800 --> 00:05:56,730
the way of how the algorithm solves the

00:05:53,430 --> 00:05:58,740
problem changes that's where I work

00:05:56,730 --> 00:06:00,390
that's where I think that the fancy part

00:05:58,740 --> 00:06:02,130
starts and then there are neural

00:06:00,390 --> 00:06:05,100
networks which is the subset of machine

00:06:02,130 --> 00:06:07,290
learning modeled after the human brain

00:06:05,100 --> 00:06:09,410
where you have like neurons and they are

00:06:07,290 --> 00:06:12,360
connected to each other and send signals

00:06:09,410 --> 00:06:16,500
and then deep learning which is probably

00:06:12,360 --> 00:06:20,430
the most hyped one it's basically just

00:06:16,500 --> 00:06:23,910
in your network with lots of layers like

00:06:20,430 --> 00:06:26,850
a deep structure and then there's data

00:06:23,910 --> 00:06:30,150
science and we've heard that term before

00:06:26,850 --> 00:06:34,620
as well and data science is basically

00:06:30,150 --> 00:06:37,500
extracting valuable information out of

00:06:34,620 --> 00:06:38,460
or insights out of data and it can use

00:06:37,500 --> 00:06:40,920
the

00:06:38,460 --> 00:06:46,100
methods but it doesn't particularly have

00:06:40,920 --> 00:06:50,430
to so the question is why do we need

00:06:46,100 --> 00:06:53,280
machine learning so there are there are

00:06:50,430 --> 00:06:56,160
a couple of use cases where machine

00:06:53,280 --> 00:06:58,410
learning just simply outperforms other

00:06:56,160 --> 00:07:00,980
approaches and one thing that machine

00:06:58,410 --> 00:07:04,290
learning can do is it can find

00:07:00,980 --> 00:07:07,080
non-obvious correlations in a set of

00:07:04,290 --> 00:07:10,740
data going back to the to the online

00:07:07,080 --> 00:07:13,020
retailer there was was working with we

00:07:10,740 --> 00:07:15,150
had like 700 data points of browser

00:07:13,020 --> 00:07:17,640
session data like finding manually

00:07:15,150 --> 00:07:20,250
finding correlations between 700 points

00:07:17,640 --> 00:07:22,620
and someone buys something would be

00:07:20,250 --> 00:07:26,550
infeasible we're throwing the whole data

00:07:22,620 --> 00:07:30,930
at a at a neural network was rather

00:07:26,550 --> 00:07:34,050
successful right so as I said my

00:07:30,930 --> 00:07:35,460
patience machine learning and last year

00:07:34,050 --> 00:07:39,420
early last year I want to do something

00:07:35,460 --> 00:07:41,940
cool and machine learning and I remember

00:07:39,420 --> 00:07:46,310
this this product by by Larry Ellison

00:07:41,940 --> 00:07:46,310
who ously the founder and CEO of Oracle

00:07:46,370 --> 00:07:53,220
apart from it being slightly sexist I

00:07:49,470 --> 00:07:55,370
think it still holds true and let me

00:07:53,220 --> 00:07:59,790
maybe prove that by asking a question

00:07:55,370 --> 00:08:08,700
raise your hand if you use Apache Apache

00:07:59,790 --> 00:08:10,920
Kafka at work actually so I did this at

00:08:08,700 --> 00:08:13,500
a different conference and like 40 40

00:08:10,920 --> 00:08:16,380
percent race in their arms and the thing

00:08:13,500 --> 00:08:19,620
is the follow-up question is how many

00:08:16,380 --> 00:08:20,970
people of you think Apache Kafka is the

00:08:19,620 --> 00:08:23,490
perfect solution to the problem you are

00:08:20,970 --> 00:08:25,980
solving and then half the arms went down

00:08:23,490 --> 00:08:28,590
I'm not sure whatever yeah I see not

00:08:25,980 --> 00:08:33,000
nodding so I guess I guess it still

00:08:28,590 --> 00:08:34,260
holds true even nowadays that in the

00:08:33,000 --> 00:08:37,590
computer industry we just go for the

00:08:34,260 --> 00:08:40,650
cool new kid on the block so I realized

00:08:37,590 --> 00:08:43,710
that and then I realized looking at the

00:08:40,650 --> 00:08:45,600
landscape of of machine learning that's

00:08:43,710 --> 00:08:47,570
out there there are so many things and

00:08:45,600 --> 00:08:51,130
it's so overwhelming that I need to do

00:08:47,570 --> 00:08:53,110
my own analysis of

00:08:51,130 --> 00:08:56,440
what tools out there and what they're

00:08:53,110 --> 00:08:57,880
good for and this is basically the what

00:08:56,440 --> 00:08:59,050
I try to do with his targets lift the

00:08:57,880 --> 00:09:03,670
fork around the machine learning

00:08:59,050 --> 00:09:09,490
landscape a little bit I'll be focusing

00:09:03,670 --> 00:09:13,720
on machine learning and then later on

00:09:09,490 --> 00:09:16,780
it's subset of deep learning so right

00:09:13,720 --> 00:09:19,930
when you try to analyze the landscape of

00:09:16,780 --> 00:09:23,620
something that can be used to analyze

00:09:19,930 --> 00:09:26,890
data I mean what what possible approach

00:09:23,620 --> 00:09:31,870
could you do obviously you do that data

00:09:26,890 --> 00:09:34,860
driven so what I did was I compared a

00:09:31,870 --> 00:09:37,270
lot of tools based on certain features

00:09:34,860 --> 00:09:39,760
look at the the popularity of these

00:09:37,270 --> 00:09:42,190
tools where I went to get up I mean I

00:09:39,760 --> 00:09:44,860
rode a Python script to get star the

00:09:42,190 --> 00:09:47,800
star count of github for each of these

00:09:44,860 --> 00:09:50,560
tools and the same thing with the

00:09:47,800 --> 00:09:53,230
questions that were asked with this

00:09:50,560 --> 00:09:54,220
specific tag of one of those tools on

00:09:53,230 --> 00:09:57,460
Stack Overflow

00:09:54,220 --> 00:09:59,470
I looked at some API dogs I played

00:09:57,460 --> 00:10:02,320
around for some tutorials and when

00:09:59,470 --> 00:10:04,120
possible included expert opinion and all

00:10:02,320 --> 00:10:06,070
that to get a better understanding of of

00:10:04,120 --> 00:10:11,110
what kind of tools are out there and

00:10:06,070 --> 00:10:13,060
what are they capable of that means if

00:10:11,110 --> 00:10:15,070
one of you have worked with I don't know

00:10:13,060 --> 00:10:18,100
pi thoughts for the last two and a half

00:10:15,070 --> 00:10:21,340
years you are probably more an expert in

00:10:18,100 --> 00:10:22,660
PI tortes than I am I have used some of

00:10:21,340 --> 00:10:27,460
these tools but definitely not all of

00:10:22,660 --> 00:10:30,250
them and right but the thing is there

00:10:27,460 --> 00:10:32,470
are lots of them I write new rather new

00:10:30,250 --> 00:10:34,720
like two three maybe three-and-a-half

00:10:32,470 --> 00:10:36,250
years old I don't think anyone in this

00:10:34,720 --> 00:10:39,610
on this planet can be an expert in all

00:10:36,250 --> 00:10:43,660
of them so that saves me a little bit in

00:10:39,610 --> 00:10:46,270
that regard so the question now was I

00:10:43,660 --> 00:10:49,060
could spend all the time analyzing the

00:10:46,270 --> 00:10:50,920
landscape so what is the best tool and I

00:10:49,060 --> 00:10:52,900
have to disappoint you a little bit

00:10:50,920 --> 00:10:57,640
because I have to give you the classical

00:10:52,900 --> 00:10:59,520
consultant answer it depends it depends

00:10:57,640 --> 00:11:02,920
on a couple of things that depends on

00:10:59,520 --> 00:11:04,780
the use case your you're doing whether

00:11:02,920 --> 00:11:06,880
you do image classification

00:11:04,780 --> 00:11:09,250
be it for signature checking or for

00:11:06,880 --> 00:11:10,900
optical character recognition or you

00:11:09,250 --> 00:11:13,480
want to do order prediction like we did

00:11:10,900 --> 00:11:16,300
that declined and Germany that I

00:11:13,480 --> 00:11:21,160
mentioned before and I think in general

00:11:16,300 --> 00:11:22,510
a great advice would be if the tool you

00:11:21,160 --> 00:11:26,620
are picking doesn't solve the problem

00:11:22,510 --> 00:11:29,770
you are having don't pick that tool that

00:11:26,620 --> 00:11:33,190
might sound obvious I've seen cases

00:11:29,770 --> 00:11:34,720
where that advice wasn't followed it

00:11:33,190 --> 00:11:36,520
also depends on your experience or your

00:11:34,720 --> 00:11:37,720
team's experience regarding the

00:11:36,520 --> 00:11:41,230
programming language that issue is

00:11:37,720 --> 00:11:43,120
regarding the to of themselves also

00:11:41,230 --> 00:11:45,400
regarding the the general general

00:11:43,120 --> 00:11:47,370
understanding of machine learning it

00:11:45,400 --> 00:11:49,690
depends on the infrastructure whether

00:11:47,370 --> 00:11:53,890
your model will be running on a powerful

00:11:49,690 --> 00:11:56,110
server or on a mobile device or whether

00:11:53,890 --> 00:11:58,360
the training of that model will happen

00:11:56,110 --> 00:12:01,900
with unlimited resources in the cloud or

00:11:58,360 --> 00:12:04,930
whether it's on your laptop without

00:12:01,900 --> 00:12:06,940
without a GPU and depends on the

00:12:04,930 --> 00:12:08,440
structure needs of your data so what

00:12:06,940 --> 00:12:10,330
kind of database is your data stored on

00:12:08,440 --> 00:12:13,720
is it in a graph database or is it in a

00:12:10,330 --> 00:12:15,730
only Hadoop cluster depends on the

00:12:13,720 --> 00:12:19,089
feasibility and what I what I mean by

00:12:15,730 --> 00:12:23,410
that is are you currently trying to

00:12:19,089 --> 00:12:25,330
figure out a general a general solution

00:12:23,410 --> 00:12:27,040
to the to the problem or are you like

00:12:25,330 --> 00:12:30,430
are you in like some prototyping States

00:12:27,040 --> 00:12:32,200
or are you in production and you want to

00:12:30,430 --> 00:12:35,370
fine-tune and get the trick the level

00:12:32,200 --> 00:12:40,480
the last little bit out of your model

00:12:35,370 --> 00:12:43,200
right and obviously it depends on how

00:12:40,480 --> 00:12:45,580
much data you have like if you are

00:12:43,200 --> 00:12:48,520
training a model with Amazon's

00:12:45,580 --> 00:12:50,410
clickstream over the last two years or

00:12:48,520 --> 00:12:53,560
you train a model with your

00:12:50,410 --> 00:12:57,130
grandmother's cookie recipe collection

00:12:53,560 --> 00:13:00,150
the amount of data might might be

00:12:57,130 --> 00:13:03,220
different depending on your grandmother

00:13:00,150 --> 00:13:04,540
and depends a lot of other things like

00:13:03,220 --> 00:13:06,820
how much time you have how much money

00:13:04,540 --> 00:13:11,350
you have basically how big the team is

00:13:06,820 --> 00:13:13,120
etc all right to give you like a some

00:13:11,350 --> 00:13:18,310
insight on how I approach this whole

00:13:13,120 --> 00:13:20,380
thing let's talk about tens of flow

00:13:18,310 --> 00:13:21,310
little bit everyone anyone has not heard

00:13:20,380 --> 00:13:26,650
about tensorflow

00:13:21,310 --> 00:13:28,090
by now everyone it's by far the most

00:13:26,650 --> 00:13:31,870
popular deep learning framework with

00:13:28,090 --> 00:13:37,420
more than 100,000 stars on github and

00:13:31,870 --> 00:13:38,950
what I did is I had those four features

00:13:37,420 --> 00:13:41,200
if you will or four categories where I

00:13:38,950 --> 00:13:45,040
ranked where I gave basically marks for

00:13:41,200 --> 00:13:47,320
for these technologies where one's being

00:13:45,040 --> 00:13:49,660
the lowest and fires the highest and I

00:13:47,320 --> 00:13:52,330
think the I mean the most obvious one is

00:13:49,660 --> 00:13:57,430
probably the ease of setup here with the

00:13:52,330 --> 00:14:01,140
two and now the question is why is that

00:13:57,430 --> 00:14:03,220
and what I did was I went to the

00:14:01,140 --> 00:14:04,870
installation page of tens the flow how

00:14:03,220 --> 00:14:10,540
you install the tender flow on Ubuntu

00:14:04,870 --> 00:14:12,310
and that's all I got in order to take

00:14:10,540 --> 00:14:14,470
this screenshot I had to install a

00:14:12,310 --> 00:14:16,270
browser plug-in that takes the

00:14:14,470 --> 00:14:17,860
screenshot Scrolls down and like

00:14:16,270 --> 00:14:22,540
stitches all these these pictures

00:14:17,860 --> 00:14:25,390
together and now you're asking if if one

00:14:22,540 --> 00:14:27,820
is the lowest mark that that framework

00:14:25,390 --> 00:14:30,430
can get why is it still - I did the same

00:14:27,820 --> 00:14:38,200
thing with with the Microsoft cognitive

00:14:30,430 --> 00:14:39,460
ticket and this is what I got then in in

00:14:38,200 --> 00:14:42,180
Microsoft's defense

00:14:39,460 --> 00:14:44,650
this is installing it on Ubuntu

00:14:42,180 --> 00:14:47,650
apparently installing the Microsoft

00:14:44,650 --> 00:14:51,430
cognitive toolkit on Windows is rather

00:14:47,650 --> 00:14:55,110
easy but maybe one quick question is

00:14:51,430 --> 00:14:55,110
anyone doing machine learning on Windows

00:14:55,770 --> 00:15:02,290
good to know

00:14:58,440 --> 00:15:07,530
so to be true to tell you the truth this

00:15:02,290 --> 00:15:10,030
slide was made about a year ago and

00:15:07,530 --> 00:15:12,990
especially in in machine learning

00:15:10,030 --> 00:15:17,160
everything is changing so fast

00:15:12,990 --> 00:15:19,420
tensorflow has drastically reduced the

00:15:17,160 --> 00:15:21,520
steps you need to take to install it in

00:15:19,420 --> 00:15:25,770
fact right now it's pip install

00:15:21,520 --> 00:15:28,990
tensorflow then you have the CPU version

00:15:25,770 --> 00:15:31,500
so that is but this slide was too funny

00:15:28,990 --> 00:15:31,500
to skip it

00:15:32,910 --> 00:15:42,580
there a couple of other things so even

00:15:39,460 --> 00:15:44,020
even last year when when this was the

00:15:42,580 --> 00:15:45,880
case and you had to go through all this

00:15:44,020 --> 00:15:48,480
pain to install it why was popular

00:15:45,880 --> 00:15:51,160
why was tensorflow so popular back then

00:15:48,480 --> 00:15:53,140
and up so does a couple of things right

00:15:51,160 --> 00:15:55,660
it has this thing called tensor board

00:15:53,140 --> 00:15:57,480
which is basically a real-time

00:15:55,660 --> 00:15:59,950
visualization of your training process

00:15:57,480 --> 00:16:02,440
other frameworks have picked that up as

00:15:59,950 --> 00:16:05,800
well but tends overhead that from I

00:16:02,440 --> 00:16:07,600
think the first version 0.6 on which is

00:16:05,800 --> 00:16:09,610
kind of cool because we can in real time

00:16:07,600 --> 00:16:14,620
see how your your model behaves or your

00:16:09,610 --> 00:16:17,320
accuracy is or your cost function and it

00:16:14,620 --> 00:16:20,100
also it's able to visualize the

00:16:17,320 --> 00:16:27,010
computational graph that you bought

00:16:20,100 --> 00:16:30,190
there there is however there are a

00:16:27,010 --> 00:16:32,230
couple of things so two other features

00:16:30,190 --> 00:16:34,110
that I had look at this the degrees of

00:16:32,230 --> 00:16:37,570
freedom of the parameters exposed

00:16:34,110 --> 00:16:39,790
basically how many hyper parameters can

00:16:37,570 --> 00:16:42,010
you play with how many how much in

00:16:39,790 --> 00:16:45,250
detail can you go to fine-tune your

00:16:42,010 --> 00:16:49,840
model and tens of low has a ton of

00:16:45,250 --> 00:16:52,900
options there but that also means so

00:16:49,840 --> 00:16:55,060
that's great for for this however it

00:16:52,900 --> 00:16:56,860
also has like pure tens of who has a

00:16:55,060 --> 00:16:58,290
pretty steep learning curve which then

00:16:56,860 --> 00:17:03,090
affects the ease of use a little bit

00:16:58,290 --> 00:17:07,210
right and I've already mentioned the the

00:17:03,090 --> 00:17:09,610
adoption in the community which which

00:17:07,210 --> 00:17:11,320
itself I mean maybe in high adoption

00:17:09,610 --> 00:17:13,450
rate doesn't practically say something

00:17:11,320 --> 00:17:16,900
as good but what if what it can indicate

00:17:13,450 --> 00:17:18,700
is that if you run into problems and the

00:17:16,900 --> 00:17:20,830
community using that technology is

00:17:18,700 --> 00:17:23,470
rather rather last then you have a high

00:17:20,830 --> 00:17:26,200
chance of getting actually some help

00:17:23,470 --> 00:17:31,030
from the community that's that's using

00:17:26,200 --> 00:17:33,340
it right same thing I did for Karis were

00:17:31,030 --> 00:17:37,270
careless we've heard about it who does

00:17:33,340 --> 00:17:39,550
not know about carers all right so I

00:17:37,270 --> 00:17:41,410
quickly thought about carrots is not

00:17:39,550 --> 00:17:42,850
actually deep learning framework it's

00:17:41,410 --> 00:17:46,410
something like a higher-level interface

00:17:42,850 --> 00:17:46,410
that you can put on top of

00:17:46,540 --> 00:17:53,620
deep learning frameworks and it offers a

00:17:49,510 --> 00:17:55,330
more intuitive set of instructions so

00:17:53,620 --> 00:17:58,300
you can easily build their neural

00:17:55,330 --> 00:17:59,950
networks and so for example you can

00:17:58,300 --> 00:18:02,560
build a long short-term memory Network

00:17:59,950 --> 00:18:05,860
in like ten lines of code which is which

00:18:02,560 --> 00:18:08,340
is pretty crazy and it offers use you

00:18:05,860 --> 00:18:12,280
there that offers the fast prototyping

00:18:08,340 --> 00:18:16,990
and you can explore solutions and big P

00:18:12,280 --> 00:18:18,520
or C's and careth currently supports MX

00:18:16,990 --> 00:18:21,070
native learning project tens of flow

00:18:18,520 --> 00:18:23,800
Microsoft cognitive toolkit and piano

00:18:21,070 --> 00:18:25,840
and in fact if you install tensorflow

00:18:23,800 --> 00:18:28,320
it's already built-in and you can use

00:18:25,840 --> 00:18:30,640
care us even that was separately

00:18:28,320 --> 00:18:32,890
installing it

00:18:30,640 --> 00:18:37,090
the installation is basically if you

00:18:32,890 --> 00:18:40,000
don't use ten the flow becomes default

00:18:37,090 --> 00:18:42,520
comes by default you can do the pip

00:18:40,000 --> 00:18:45,490
install tensorflow and then you get that

00:18:42,520 --> 00:18:47,890
however for the other cases you need to

00:18:45,490 --> 00:18:50,350
have a separate what they call back-end

00:18:47,890 --> 00:18:55,660
the deep learning framework where this

00:18:50,350 --> 00:18:57,490
carolyn works on top of right that was

00:18:55,660 --> 00:19:01,950
about the methodology one thing I did is

00:18:57,490 --> 00:19:05,200
I separated classical machine learning

00:19:01,950 --> 00:19:07,870
libraries or tool kits from deep

00:19:05,200 --> 00:19:10,480
learning mainly I mean for several

00:19:07,870 --> 00:19:14,020
several reasons the resources the

00:19:10,480 --> 00:19:16,210
resource requirements are different all

00:19:14,020 --> 00:19:19,360
the deep learning frameworks support

00:19:16,210 --> 00:19:22,030
GPUs and after all if you can find a

00:19:19,360 --> 00:19:23,740
linear model to find your to solve your

00:19:22,030 --> 00:19:27,850
machine learning problem

00:19:23,740 --> 00:19:30,580
I would advise picking a straightforward

00:19:27,850 --> 00:19:33,970
model rather than going for deep

00:19:30,580 --> 00:19:37,030
learning approach because this is a more

00:19:33,970 --> 00:19:38,320
complex system and in general if you can

00:19:37,030 --> 00:19:43,120
solve it the easy way

00:19:38,320 --> 00:19:45,940
easy way why why not right this is where

00:19:43,120 --> 00:19:47,890
I plotted the this machine learning I

00:19:45,940 --> 00:19:50,260
reached against each other where the

00:19:47,890 --> 00:19:52,870
adoption rate is on the x axis and the

00:19:50,260 --> 00:19:54,790
degrees of freedom on the y axis and the

00:19:52,870 --> 00:19:58,420
ease of use is displayed by the size and

00:19:54,790 --> 00:19:59,330
you on the on the on the very right of

00:19:58,420 --> 00:20:01,309
the char

00:19:59,330 --> 00:20:03,249
you can see we cup hi brain and Shogun

00:20:01,309 --> 00:20:07,100
these haven't been particularly popular

00:20:03,249 --> 00:20:09,830
in the in the last time

00:20:07,100 --> 00:20:11,629
in fact PI brain I don't I think the

00:20:09,830 --> 00:20:13,149
last change on the github repository was

00:20:11,629 --> 00:20:15,289
like two and a half years ago oh maybe

00:20:13,149 --> 00:20:16,789
there were five change in the last two

00:20:15,289 --> 00:20:18,409
and half years something like this so I

00:20:16,789 --> 00:20:21,620
would consider that being being

00:20:18,409 --> 00:20:22,999
discontinued weaker offers a graphical

00:20:21,620 --> 00:20:24,980
user interface which also doesn't seem

00:20:22,999 --> 00:20:26,899
to be that popular

00:20:24,980 --> 00:20:30,889
it is however popular when it comes to

00:20:26,899 --> 00:20:33,259
data mining but I think the what I would

00:20:30,889 --> 00:20:35,570
call community Kings on the on the left

00:20:33,259 --> 00:20:38,299
side of the chart there scikit-learn

00:20:35,570 --> 00:20:40,789
which is again I would assume most of

00:20:38,299 --> 00:20:43,220
you have heard of highly adopted in the

00:20:40,789 --> 00:20:45,860
community offers a powerful interface

00:20:43,220 --> 00:20:47,539
who to play with and you can treat your

00:20:45,860 --> 00:20:51,999
metal model with many different

00:20:47,539 --> 00:20:56,629
parameters and then if you're if you're

00:20:51,999 --> 00:20:58,159
working with spark there is there are

00:20:56,629 --> 00:20:59,749
these other three that that are

00:20:58,159 --> 00:21:04,039
interested than what you might be

00:20:59,749 --> 00:21:06,200
interested in ml lib which comes with

00:21:04,039 --> 00:21:11,149
spark by default and even has a higher

00:21:06,200 --> 00:21:14,840
level wrapper spark ml and h2o which in

00:21:11,149 --> 00:21:18,980
some cases offers better results then

00:21:14,840 --> 00:21:20,450
spark a mellow ml lip but then even if

00:21:18,980 --> 00:21:24,789
you start with a malleable spoken male

00:21:20,450 --> 00:21:24,789
you can just add h2o later on anyway

00:21:25,690 --> 00:21:32,029
another perspective when choosing a

00:21:29,470 --> 00:21:36,200
machine learning technology you might

00:21:32,029 --> 00:21:37,669
have is scalability and we have as I

00:21:36,200 --> 00:21:41,179
mentioned before so I could learn sila

00:21:37,669 --> 00:21:44,299
dab didn't officer have asked options

00:21:41,179 --> 00:21:47,659
for improving your model it is however

00:21:44,299 --> 00:21:49,639
limited to run on a single machine that

00:21:47,659 --> 00:21:52,399
doesn't particularly mean it's one

00:21:49,639 --> 00:21:54,769
thread or one process because some

00:21:52,399 --> 00:21:57,409
algorithms can be implemented into run

00:21:54,769 --> 00:22:03,169
parallel and as far as I know circular

00:21:57,409 --> 00:22:05,450
has done that however if you are if you

00:22:03,169 --> 00:22:07,700
can't like best process your your

00:22:05,450 --> 00:22:09,590
training then you might have a problem

00:22:07,700 --> 00:22:11,320
because you are limited to the machines

00:22:09,590 --> 00:22:14,090
memory

00:22:11,320 --> 00:22:15,560
but if you don't need that's the amount

00:22:14,090 --> 00:22:17,060
of scalability and you don't need to get

00:22:15,560 --> 00:22:20,510
no need to go distribute it and you

00:22:17,060 --> 00:22:22,730
don't have more memory then it fits more

00:22:20,510 --> 00:22:24,980
data than it fits in memory and you're

00:22:22,730 --> 00:22:29,000
comfortable with Python then psychic

00:22:24,980 --> 00:22:32,030
learn this is a pretty safe bet they are

00:22:29,000 --> 00:22:35,420
however h2o Emily party mahute and

00:22:32,030 --> 00:22:39,410
children if you are more comfortable

00:22:35,420 --> 00:22:41,990
with Java they would they would work

00:22:39,410 --> 00:22:45,440
quite well and in fact Fatima who'd

00:22:41,990 --> 00:22:48,440
Emily been h2o can all run on top of an

00:22:45,440 --> 00:22:50,630
HDFS so I guess the the question you

00:22:48,440 --> 00:22:51,740
have to ask yourself is one of the

00:22:50,630 --> 00:22:52,250
questions that you want to ask your

00:22:51,740 --> 00:22:54,110
service

00:22:52,250 --> 00:22:57,980
whether you need distributed computing

00:22:54,110 --> 00:23:00,590
power and whether the structure needs of

00:22:57,980 --> 00:23:04,880
your data being whether it is running on

00:23:00,590 --> 00:23:07,070
HDFS or not in in fact we talked about

00:23:04,880 --> 00:23:08,780
scalability here when we talk about deep

00:23:07,070 --> 00:23:13,250
learning frameworks that I will come to

00:23:08,780 --> 00:23:18,200
later they are all highly scalable and

00:23:13,250 --> 00:23:21,160
by later I mean now and there are a lot

00:23:18,200 --> 00:23:26,330
of a lot of deep learning frameworks and

00:23:21,160 --> 00:23:29,420
as I as I said if you know I didn't say

00:23:26,330 --> 00:23:33,770
that actually but all of these are

00:23:29,420 --> 00:23:36,440
capable of mostly capable of running the

00:23:33,770 --> 00:23:41,470
same things that you have seen that you

00:23:36,440 --> 00:23:45,020
could do with the non deep learning

00:23:41,470 --> 00:23:47,090
libraries that I've shown before it's

00:23:45,020 --> 00:23:49,370
just the case that in some areas deep

00:23:47,090 --> 00:23:53,630
learning is significantly more

00:23:49,370 --> 00:23:56,330
successful and some examples would be I

00:23:53,630 --> 00:23:59,090
think computer vision is the prime

00:23:56,330 --> 00:24:02,170
example of where deep learning shines a

00:23:59,090 --> 00:24:04,520
lot and outperforms every other approach

00:24:02,170 --> 00:24:08,180
speech recognition is another example

00:24:04,520 --> 00:24:10,910
audio recognition and machine

00:24:08,180 --> 00:24:13,190
translation as well but they are they

00:24:10,910 --> 00:24:19,100
are disadvantages through to deep

00:24:13,190 --> 00:24:21,290
learning it's more complex the setup

00:24:19,100 --> 00:24:24,470
might be a little bit more difficult

00:24:21,290 --> 00:24:27,080
than for these for these frameworks

00:24:24,470 --> 00:24:31,159
in general you need a little bit more

00:24:27,080 --> 00:24:32,960
data so there are there's something

00:24:31,159 --> 00:25:02,750
called transfer learning where you can

00:24:32,960 --> 00:25:06,830
your model okay I've only seen transfer

00:25:02,750 --> 00:25:09,860
learning being applied to image so if

00:25:06,830 --> 00:25:12,200
you have structured data I am not aware

00:25:09,860 --> 00:25:13,880
that there is any I don't know three

00:25:12,200 --> 00:25:21,260
trains to actual data model that fits

00:25:13,880 --> 00:25:24,080
your financial analysis another another

00:25:21,260 --> 00:25:28,279
drawback of deep learning is it's

00:25:24,080 --> 00:25:31,240
difficult to comprehend so what I mean

00:25:28,279 --> 00:25:36,760
by that is that the per feature

00:25:31,240 --> 00:25:39,620
importance it's difficult to figure out

00:25:36,760 --> 00:25:43,130
given right it's difficult to figure out

00:25:39,620 --> 00:25:45,039
so that means you put in some amount of

00:25:43,130 --> 00:25:47,990
data and then you get some output

00:25:45,039 --> 00:25:50,419
figuring out which of these particular

00:25:47,990 --> 00:25:57,649
data points you know responsible for

00:25:50,419 --> 00:25:59,690
creating the route and I can't think of

00:25:57,649 --> 00:26:10,460
an example where that would that would

00:25:59,690 --> 00:26:13,370
make me personally I go to a doctor and

00:26:10,460 --> 00:26:14,779
I said the symptoms and the doctor is

00:26:13,370 --> 00:26:16,309
typing the symptoms of machine and

00:26:14,779 --> 00:26:19,880
intuitive learning model and the deep

00:26:16,309 --> 00:26:23,029
learning we have this condition I would

00:26:19,880 --> 00:26:25,820
like the doctor to be able to verify why

00:26:23,029 --> 00:26:30,490
the deep learning model would suggest I

00:26:25,820 --> 00:26:33,320
have this condition now and yeah the

00:26:30,490 --> 00:26:36,830
basically the simple of the model is

00:26:33,320 --> 00:26:43,820
to get a direct relationship between

00:26:36,830 --> 00:26:45,350
apparel and all right so what do deep

00:26:43,820 --> 00:26:55,100
learning frameworks probably all of you

00:26:45,350 --> 00:26:56,480
have seen some input nodes in this case

00:26:55,100 --> 00:27:00,169
they're all connected to the next layer

00:26:56,480 --> 00:27:01,399
to the nose the next layer there's

00:27:00,169 --> 00:27:08,000
another hidden layer and output layer

00:27:01,399 --> 00:27:09,889
which gives you the as mention before

00:27:08,000 --> 00:27:16,309
deep learning would just have more of

00:27:09,889 --> 00:27:18,350
these hidden layers this network is

00:27:16,309 --> 00:27:21,500
rather small I'm not sure what it could

00:27:18,350 --> 00:27:23,210
do so if you have an actual model could

00:27:21,500 --> 00:27:26,000
also have more nodes not only more

00:27:23,210 --> 00:27:29,389
layers but then the question is why do

00:27:26,000 --> 00:27:30,789
we need deep learning frameworks and all

00:27:29,389 --> 00:27:36,950
of these people earning frameworks offer

00:27:30,789 --> 00:27:41,120
the basic building blocks of deep neural

00:27:36,950 --> 00:27:43,250
networks you can just say give me a

00:27:41,120 --> 00:27:44,690
convolutional layer and then you get a

00:27:43,250 --> 00:27:48,620
convolutional layer and you can

00:27:44,690 --> 00:27:50,179
basically create all these layers you so

00:27:48,620 --> 00:27:53,059
there are I mean all these nodes to some

00:27:50,179 --> 00:27:56,629
kind of computation and all you can get

00:27:53,059 --> 00:27:58,460
all these these algorithms you can use

00:27:56,629 --> 00:28:05,289
different functions that the deep

00:27:58,460 --> 00:28:05,289
learning model provides and all of them

00:28:09,700 --> 00:28:17,960
I've said before the all of these

00:28:12,440 --> 00:28:20,720
support GPUs which is I mean the fact

00:28:17,960 --> 00:28:22,429
that we started putting all these the

00:28:20,720 --> 00:28:24,019
all these computations are similar at

00:28:22,429 --> 00:28:26,690
the fact that we started putting them on

00:28:24,019 --> 00:28:28,100
on single shaders on GPUs it's one of

00:28:26,690 --> 00:28:30,110
the reasons why deep learning has been

00:28:28,100 --> 00:28:31,909
so successful over the years over the

00:28:30,110 --> 00:28:34,580
last couple of years and can effect

00:28:31,909 --> 00:28:38,230
reduce training time from days we exert

00:28:34,580 --> 00:28:42,220
out to hours

00:28:38,230 --> 00:28:51,640
right so these are the framers we've

00:28:42,220 --> 00:28:56,950
just seen again and degrees of freedom

00:28:51,640 --> 00:29:00,100
on the y-axis and the ease of setup the

00:28:56,950 --> 00:29:03,610
color according accordingly to this

00:29:00,100 --> 00:29:06,490
thing here and the size represents the

00:29:03,610 --> 00:29:09,610
ease of use and we've already talked

00:29:06,490 --> 00:29:14,770
about tens of flow and chaos they have

00:29:09,610 --> 00:29:17,230
the most adopted currently followed by

00:29:14,770 --> 00:29:19,630
pi thoughts and especially in

00:29:17,230 --> 00:29:21,700
combination where you have tens of flow

00:29:19,630 --> 00:29:26,830
back-end and have Karos on top of that

00:29:21,700 --> 00:29:28,810
they've been highly popular Karis s

00:29:26,830 --> 00:29:31,960
mentioned is good for this prototyping

00:29:28,810 --> 00:29:36,250
and you can like quickly define your

00:29:31,960 --> 00:29:37,960
your model where tens of flow absolute

00:29:36,250 --> 00:29:40,180
outshines every other framework when it

00:29:37,960 --> 00:29:41,950
comes to deployment whether you deploy

00:29:40,180 --> 00:29:45,040
it on a distributed system or on mobile

00:29:41,950 --> 00:29:47,850
devices and if you use both of them you

00:29:45,040 --> 00:29:49,930
get the both best of both worlds

00:29:47,850 --> 00:29:54,700
however there are a couple of things

00:29:49,930 --> 00:29:56,770
should as a debugging and all these

00:29:54,700 --> 00:30:07,600
fine-tuning and whether you want to run

00:29:56,770 --> 00:30:11,290
you can define in the middle there's

00:30:07,600 --> 00:30:12,790
this this blob of frameworks which I

00:30:11,290 --> 00:30:16,830
would consider they're all fighting for

00:30:12,790 --> 00:30:19,960
attention and and the reason for that is

00:30:16,830 --> 00:30:22,930
so there are quite a few big companies

00:30:19,960 --> 00:30:26,140
who have vast amount of data behind some

00:30:22,930 --> 00:30:30,310
of those frameworks the data itself

00:30:26,140 --> 00:30:32,560
isn't particularly valuable if you don't

00:30:30,310 --> 00:30:35,020
if you can't get insights out of that

00:30:32,560 --> 00:30:38,320
data and you can't analyze it correctly

00:30:35,020 --> 00:30:42,460
and therefore all these companies like

00:30:38,320 --> 00:30:47,530
Facebook Microsoft Google open sourcing

00:30:42,460 --> 00:30:50,710
these these frameworks basically make it

00:30:47,530 --> 00:30:55,530
open for the community to improve upon

00:30:50,710 --> 00:31:00,790
it brings value to at least to them

00:30:55,530 --> 00:31:02,860
right there is I think the so I I call

00:31:00,790 --> 00:31:04,480
carers and tender float the the

00:31:02,860 --> 00:31:06,880
community Kings right now but the the

00:31:04,480 --> 00:31:08,980
strongest contender currently ASP I

00:31:06,880 --> 00:31:16,150
thought I taught is a reimplementation

00:31:08,980 --> 00:31:20,190
of torch and PI thoughts is being has

00:31:16,150 --> 00:31:23,980
been or is being developed at Facebook

00:31:20,190 --> 00:31:27,990
paid watch is especially popular amongst

00:31:23,980 --> 00:31:31,320
researchers pirates seems to pick up

00:31:27,990 --> 00:31:33,700
recent academic research relies

00:31:31,320 --> 00:31:39,520
significantly faster than all the other

00:31:33,700 --> 00:31:42,850
ones and and that seems to be quite

00:31:39,520 --> 00:31:45,910
important also has I don't I don't want

00:31:42,850 --> 00:31:55,030
to go into detail there but it has the

00:31:45,910 --> 00:31:58,180
dynamic also has I mean I mentioned

00:31:55,030 --> 00:31:59,830
earlier that when I made the first

00:31:58,180 --> 00:32:03,790
tensorflow slide and that is a little

00:31:59,830 --> 00:32:07,090
bit outdated because the changed a

00:32:03,790 --> 00:32:09,490
little bit last week tens of load 2.0

00:32:07,090 --> 00:32:13,240
was announced where there have quite a

00:32:09,490 --> 00:32:17,520
couple of changes and quite a couple of

00:32:13,240 --> 00:32:21,490
implementations that actually take away

00:32:17,520 --> 00:32:24,490
advantage from from Python and then we

00:32:21,490 --> 00:32:26,200
have a couple of other ones Theano and I

00:32:24,490 --> 00:32:28,000
indicated that by this arrow Gianna was

00:32:26,200 --> 00:32:31,450
one of the first deep learning

00:32:28,000 --> 00:32:33,160
frameworks was developed by the

00:32:31,450 --> 00:32:35,740
University of Montreal but last year

00:32:33,160 --> 00:32:38,770
they actually stopped that project

00:32:35,740 --> 00:32:40,810
because they thought that the the

00:32:38,770 --> 00:32:43,900
environment the landscape has already

00:32:40,810 --> 00:32:49,270
matured enough and piano isn't necessary

00:32:43,900 --> 00:32:52,660
in the case anymore then there is Kaffee

00:32:49,270 --> 00:32:58,570
which has also been around for quite a

00:32:52,660 --> 00:33:00,510
while the it is there is Kathy - which

00:32:58,570 --> 00:33:02,800
has also been developed by Facebook

00:33:00,510 --> 00:33:04,160
Kathy is still around because it seems

00:33:02,800 --> 00:33:07,250
to be quite popular for

00:33:04,160 --> 00:33:08,540
in this recognition however you for

00:33:07,250 --> 00:33:11,420
careful you define your model in llamo

00:33:08,540 --> 00:33:12,470
and that doesn't seem to be up-to-date

00:33:11,420 --> 00:33:15,530
anymore

00:33:12,470 --> 00:33:19,910
I mentioned pay towards towards the

00:33:15,530 --> 00:33:23,360
original has a very as a fairly small

00:33:19,910 --> 00:33:26,500
community maybe because it's written in

00:33:23,360 --> 00:33:28,730
Lua and you have to write Lua to use it

00:33:26,500 --> 00:33:39,380
they are steep learning for J as the

00:33:28,730 --> 00:33:42,080
name suggested I think so that was that

00:33:39,380 --> 00:33:44,240
one over there is a there is a different

00:33:42,080 --> 00:33:46,790
again a different point of view soon you

00:33:44,240 --> 00:33:51,110
might want to ask yourself when choosing

00:33:46,790 --> 00:33:53,150
a tool and that is which project

00:33:51,110 --> 00:33:57,320
life-cycle are which part of the project

00:33:53,150 --> 00:34:02,360
lifecycle you are in there some of them

00:33:57,320 --> 00:34:06,590
offer easy fast prototyping can build

00:34:02,360 --> 00:34:11,870
your video POCs fast where others of a

00:34:06,590 --> 00:34:13,670
very fine gain fine-grained control to

00:34:11,870 --> 00:34:18,320
basically treat your model and get the

00:34:13,670 --> 00:34:19,670
most all of that and machine learning or

00:34:18,320 --> 00:34:21,800
if you try to solve a problem with

00:34:19,670 --> 00:34:24,020
machine learning the path to success is

00:34:21,800 --> 00:34:27,380
not always that obvious like if you just

00:34:24,020 --> 00:34:29,270
I mean if you developed the software and

00:34:27,380 --> 00:34:30,770
you get your user story you kind of know

00:34:29,270 --> 00:34:32,780
okay I have to do this this is go to

00:34:30,770 --> 00:34:34,730
that class do this and then you do that

00:34:32,780 --> 00:34:37,670
and then your story is done with machine

00:34:34,730 --> 00:34:39,440
learning you have to experiment a lot

00:34:37,670 --> 00:34:41,330
you have to figure out which is the

00:34:39,440 --> 00:34:44,750
right model I mean there are some there

00:34:41,330 --> 00:34:46,040
are some ideas if you if you do image

00:34:44,750 --> 00:34:48,350
recognition you probably want some

00:34:46,040 --> 00:34:52,030
convolutional layers in there but in

00:34:48,350 --> 00:34:57,620
general there's a lot of exploration and

00:34:52,030 --> 00:35:00,080
and try an error basically before you

00:34:57,620 --> 00:35:02,780
know which general model works good for

00:35:00,080 --> 00:35:05,570
your use case so in the beginning you

00:35:02,780 --> 00:35:09,560
need you need technology that supports

00:35:05,570 --> 00:35:12,080
this kind of first order where in later

00:35:09,560 --> 00:35:13,880
stages of the product life cycle you

00:35:12,080 --> 00:35:17,360
want something where you can get the

00:35:13,880 --> 00:35:23,990
last bit the last 0.01 percent accurate

00:35:17,360 --> 00:35:26,000
see up out of your model and now I mean

00:35:23,990 --> 00:35:28,700
I'm I'm basically telling you you have

00:35:26,000 --> 00:35:30,470
to start writing everything like with

00:35:28,700 --> 00:35:32,690
the framework on this side and then six

00:35:30,470 --> 00:35:35,780
weeks later show the way and start

00:35:32,690 --> 00:35:37,300
writing the same thing with the

00:35:35,780 --> 00:35:40,850
different framework more on the

00:35:37,300 --> 00:35:42,530
fine-tuning or control side luckily

00:35:40,850 --> 00:35:47,900
that's not that will be horrible luckily

00:35:42,530 --> 00:35:52,370
that's not the case there is something

00:35:47,900 --> 00:35:54,200
there our framework interoperability

00:35:52,370 --> 00:35:57,710
solutions being developed right now and

00:35:54,200 --> 00:36:00,950
one of them is onyx stands for open your

00:35:57,710 --> 00:36:03,980
network exchange which is basically a

00:36:00,950 --> 00:36:07,460
common format of machine learning models

00:36:03,980 --> 00:36:09,020
that multiple of these frameworks use so

00:36:07,460 --> 00:36:11,060
currently there's Caffey to microsoft

00:36:09,020 --> 00:36:13,910
contractor toolkit and Max net and and

00:36:11,060 --> 00:36:17,330
Python who store their model in this

00:36:13,910 --> 00:36:20,240
specific format so what you can do is

00:36:17,330 --> 00:36:22,790
then I mentioned Facebook before because

00:36:20,240 --> 00:36:25,100
Facebook is developing pie charts and

00:36:22,790 --> 00:36:28,340
Kathy - and that's exactly what they're

00:36:25,100 --> 00:36:30,800
doing they use PI thoughts - to design

00:36:28,340 --> 00:36:33,380
their model because it's easy you can

00:36:30,800 --> 00:36:36,860
fast prototype and then take that model

00:36:33,380 --> 00:36:39,760
the exact same model throw it on - Kathy

00:36:36,860 --> 00:36:44,990
- and then let that run in production

00:36:39,760 --> 00:36:46,910
and there's right and not only are these

00:36:44,990 --> 00:36:50,690
these four that I've mentioned supported

00:36:46,910 --> 00:36:53,300
but also like Kenza flow for example was

00:36:50,690 --> 00:36:55,460
not part of them it's not storing the

00:36:53,300 --> 00:36:58,910
model in this specific format however

00:36:55,460 --> 00:37:03,500
there are converters that are able to

00:36:58,910 --> 00:37:05,600
convert tender flow models to onyx and I

00:37:03,500 --> 00:37:13,610
think it's bi-directional I would guess

00:37:05,600 --> 00:37:16,700
so right another perspective I'd want to

00:37:13,610 --> 00:37:20,900
have when choosing deep learning

00:37:16,700 --> 00:37:23,210
framework to solve a problem is maybe a

00:37:20,900 --> 00:37:26,900
question you need to ask yourself are

00:37:23,210 --> 00:37:29,270
you solving core problem or are you

00:37:26,900 --> 00:37:30,410
solving a peripheral problem of your

00:37:29,270 --> 00:37:37,520
domain

00:37:30,410 --> 00:37:41,000
and let's say let's say the you are on

00:37:37,520 --> 00:37:42,710
and retailer and product recommendation

00:37:41,000 --> 00:37:44,750
is probably one of the most important

00:37:42,710 --> 00:37:46,010
things of your business and if you can

00:37:44,750 --> 00:37:49,789
if you can make your product

00:37:46,010 --> 00:37:51,079
recommendation 0.1% better that's I mean

00:37:49,789 --> 00:37:52,670
that's cash right that's probably

00:37:51,079 --> 00:37:55,420
depending on your I mean depending on

00:37:52,670 --> 00:37:59,900
the size that can be millions of dollars

00:37:55,420 --> 00:38:01,760
in that case you do want the the most

00:37:59,900 --> 00:38:06,440
fine gain control you can get for for

00:38:01,760 --> 00:38:08,059
this particular model because its its

00:38:06,440 --> 00:38:10,160
cash

00:38:08,059 --> 00:38:13,250
however if you and let me give you a

00:38:10,160 --> 00:38:16,339
different example imagine you not on and

00:38:13,250 --> 00:38:18,109
we tell about your a dating site and in

00:38:16,339 --> 00:38:20,359
order for users to sign up for the

00:38:18,109 --> 00:38:24,770
stating side you need to they need to

00:38:20,359 --> 00:38:26,839
upload an ID known for well for multiple

00:38:24,770 --> 00:38:29,720
reasons people don't like uploading

00:38:26,839 --> 00:38:31,549
their IDs to some website and we have

00:38:29,720 --> 00:38:33,440
like 50 percent of the pictures being

00:38:31,549 --> 00:38:35,329
uploaded it's just not ID at all it's

00:38:33,440 --> 00:38:39,140
like pictures of I don't know flowers of

00:38:35,329 --> 00:38:41,210
the wall of something and the very very

00:38:39,140 --> 00:38:42,529
complication process for these IDs is

00:38:41,210 --> 00:38:45,289
currently being done manually so we have

00:38:42,529 --> 00:38:47,470
like five people verifying these IDs and

00:38:45,289 --> 00:38:53,420
half of these pictures they look at

00:38:47,470 --> 00:38:55,700
rubbish now having a machine model that

00:38:53,420 --> 00:38:58,849
can filter out eighty percent of these

00:38:55,700 --> 00:39:00,980
non ID pictures that would be great

00:38:58,849 --> 00:39:05,869
right that would would reduce your labor

00:39:00,980 --> 00:39:08,119
and cost a lot but really gain a lot

00:39:05,869 --> 00:39:09,710
from like if you spend like if you

00:39:08,119 --> 00:39:14,690
create a fifty people team trying to

00:39:09,710 --> 00:39:15,950
optimize this use case probably not so a

00:39:14,690 --> 00:39:18,559
question you have to ask yourself is are

00:39:15,950 --> 00:39:23,059
you solving your peripheral domain or a

00:39:18,559 --> 00:39:24,260
quarter main problem and so a couple of

00:39:23,059 --> 00:39:26,630
things I haven't talked about are these

00:39:24,260 --> 00:39:30,020
I mean I'm not actually I'm not actually

00:39:26,630 --> 00:39:34,490
talking about GCP and Ezer and AWS but

00:39:30,020 --> 00:39:37,430
all of these cloud providers have some

00:39:34,490 --> 00:39:39,680
machine learning as a service solutions

00:39:37,430 --> 00:39:41,360
available but they are very specific so

00:39:39,680 --> 00:39:42,800
you can

00:39:41,360 --> 00:39:45,260
it usually is like an API where you

00:39:42,800 --> 00:39:48,200
upload something and then you get a JSON

00:39:45,260 --> 00:39:50,810
bag or like XML whatever with the

00:39:48,200 --> 00:39:53,210
analysis of whatever you've uploaded you

00:39:50,810 --> 00:39:56,990
can upload pictures and then you can do

00:39:53,210 --> 00:39:59,540
something like a landmark detection or

00:39:56,990 --> 00:40:01,640
you can do face detection or speaker

00:39:59,540 --> 00:40:05,470
recognition and all these all these kind

00:40:01,640 --> 00:40:08,630
of things what you usually can't train

00:40:05,470 --> 00:40:10,810
the model yourself so you have to you

00:40:08,630 --> 00:40:12,830
can do some things but you have

00:40:10,810 --> 00:40:15,440
significantly less freedom as if you

00:40:12,830 --> 00:40:18,710
develop your machine learning or a deep

00:40:15,440 --> 00:40:22,490
learning solution yourself but then

00:40:18,710 --> 00:40:24,590
again if I can just upload all my

00:40:22,490 --> 00:40:27,850
pictures and Google helps me this is an

00:40:24,590 --> 00:40:31,100
ID or not my problem is solved right so

00:40:27,850 --> 00:40:33,110
I mean as long as I'm fine with

00:40:31,100 --> 00:40:38,380
uploading IDs to one of those services

00:40:33,110 --> 00:40:43,250
and paying money for that all right

00:40:38,380 --> 00:40:45,770
let's skip that actually right I hope I

00:40:43,250 --> 00:40:47,510
could give you like some idea of what

00:40:45,770 --> 00:40:50,630
the machine learning landscape currently

00:40:47,510 --> 00:40:52,460
looks like and I hope I could make the

00:40:50,630 --> 00:40:54,050
point that you need to ask yourself a

00:40:52,460 --> 00:40:56,660
certain set of questions to make a

00:40:54,050 --> 00:41:00,140
reasonable decision on how to pick a

00:40:56,660 --> 00:41:02,260
machine learning tool thank you very

00:41:00,140 --> 00:41:02,260
much

00:41:05,309 --> 00:41:17,500
thank you very much Aiko we have time

00:41:09,040 --> 00:41:19,690
for a couple of questions hyukoh I'm

00:41:17,500 --> 00:41:21,220
Ahmad and first of all really thanks for

00:41:19,690 --> 00:41:22,660
a very nice presentation I really liked

00:41:21,220 --> 00:41:25,720
your slides and a way of presenting is

00:41:22,660 --> 00:41:26,770
really awesome regarding 1 1 of a

00:41:25,720 --> 00:41:28,690
question that since being a machine

00:41:26,770 --> 00:41:30,819
learning developer I have a question

00:41:28,690 --> 00:41:33,160
that basically when we are kind of

00:41:30,819 --> 00:41:34,809
working on GPUs especially which library

00:41:33,160 --> 00:41:36,730
or which kind of API issue which we

00:41:34,809 --> 00:41:38,740
should prefer because basically it

00:41:36,730 --> 00:41:41,710
should be like Python and kind of

00:41:38,740 --> 00:41:43,150
tensorflow or Python or OpenCV or is any

00:41:41,710 --> 00:41:45,160
other GPU which we should kind of

00:41:43,150 --> 00:41:47,970
basically use which is freely available

00:41:45,160 --> 00:41:52,450
on the cloud what's your thought on that

00:41:47,970 --> 00:41:57,130
well III think again it depends on on

00:41:52,450 --> 00:42:01,800
what situation you're in whether like I

00:41:57,130 --> 00:42:04,359
would even argue that not for all cases

00:42:01,800 --> 00:42:09,210
especially in terms of prototyping you

00:42:04,359 --> 00:42:12,010
need a GPU but then as far as I know

00:42:09,210 --> 00:42:14,290
when when the let's talk about deep

00:42:12,010 --> 00:42:17,349
learning because then that's where GPUs

00:42:14,290 --> 00:42:21,970
become interesting as far as I know they

00:42:17,349 --> 00:42:24,220
all work on CUDA and therefore i don't

00:42:21,970 --> 00:42:27,490
see particularly performance difference

00:42:24,220 --> 00:42:30,970
in most of them if you I mean if you

00:42:27,490 --> 00:42:33,730
need the highest possible performance I

00:42:30,970 --> 00:42:36,030
think AWS has a couple of of images

00:42:33,730 --> 00:42:38,740
where you can just like get some ml

00:42:36,030 --> 00:42:41,349
instance and then that probably you can

00:42:38,740 --> 00:42:44,650
scale it up to whatever your bank

00:42:41,349 --> 00:42:47,280
account you can pay for further

00:42:44,650 --> 00:42:47,280
questions

00:42:52,470 --> 00:42:57,260
that is not the case let's thank again

00:42:54,690 --> 00:43:01,039
Aiko very nice presentation

00:42:57,260 --> 00:43:01,039

YouTube URL: https://www.youtube.com/watch?v=PfWgoCNx4fA


