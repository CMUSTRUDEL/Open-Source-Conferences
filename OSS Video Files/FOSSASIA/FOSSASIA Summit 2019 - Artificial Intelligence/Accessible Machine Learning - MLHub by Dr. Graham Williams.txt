Title: Accessible Machine Learning - MLHub by Dr. Graham Williams
Publication date: 2019-03-27
Playlist: FOSSASIA Summit 2019 - Artificial Intelligence
Description: 
	16 March 2019 17:10, Event Hall 2-1

An impressive array of tools and technologies for building artificial intelligence and machine learning models in R/Python is now available, and growing daily. Breaking into this technology is daunting. This talk will introduce and demonstrate an experimental concept of an AI and machine learning repository for openly sharing pre-built models and technology demonstrators. The repository (https://mlhub.ai/) is based around a command line pip installable tool, mlhub, which locally installs AI/ML packages directly from github (and other git repositories). Packages are downloaded, configured and demoed within minutes.
Captions: 
	00:00:00,000 --> 00:00:06,359
next panelist is dr. Graham Williams you

00:00:03,389 --> 00:00:10,139
may have seen it on the panelist on the

00:00:06,359 --> 00:00:16,759
first day he will talk about him at hope

00:00:10,139 --> 00:00:16,759
an accessible machine learning thank you

00:00:19,699 --> 00:00:26,369
okay thank you for joining me joining us

00:00:22,619 --> 00:00:28,859
at the end of at the end of this fairly

00:00:26,369 --> 00:00:30,570
long day I must say pretty exciting day

00:00:28,859 --> 00:00:32,239
it's it's always fun in these

00:00:30,570 --> 00:00:34,920
conferences there's lots of

00:00:32,239 --> 00:00:37,559
idiosyncratic projects that we hear

00:00:34,920 --> 00:00:40,649
about in the open source community as

00:00:37,559 --> 00:00:43,559
well as well as getting updates on some

00:00:40,649 --> 00:00:44,510
of our favorite tools previous speaker

00:00:43,559 --> 00:00:49,860
on tensorflow

00:00:44,510 --> 00:00:59,730
I want to talk about accessible machine

00:00:49,860 --> 00:01:04,949
learning it's kind of continuing a theme

00:00:59,730 --> 00:01:08,100
of over a very long career in open

00:01:04,949 --> 00:01:10,920
source you know most of us in open

00:01:08,100 --> 00:01:14,790
source were very keen to share what we

00:01:10,920 --> 00:01:18,630
learn what we what we build to share

00:01:14,790 --> 00:01:21,540
that with the community and my daytime

00:01:18,630 --> 00:01:25,409
job is a machine learning artificial

00:01:21,540 --> 00:01:28,670
intelligence researcher I did my PhD in

00:01:25,409 --> 00:01:31,350
the 1980s in in AI and machine learning

00:01:28,670 --> 00:01:32,939
developing new algorithms something

00:01:31,350 --> 00:01:35,220
called decision trees and actually

00:01:32,939 --> 00:01:38,340
developed the concept of ensembles of

00:01:35,220 --> 00:01:39,960
decision trees and I've kind of being

00:01:38,340 --> 00:01:41,820
what's called an ensemble person ever

00:01:39,960 --> 00:01:48,810
since you know building multiple models

00:01:41,820 --> 00:01:51,540
and combined and ever since then I've

00:01:48,810 --> 00:01:53,670
been looking at how we can and I've also

00:01:51,540 --> 00:01:55,649
been an educator so I've been working in

00:01:53,670 --> 00:01:57,509
universities teaching for many years I

00:01:55,649 --> 00:01:58,920
still teach I'm still an adjunct

00:01:57,509 --> 00:02:01,890
professor at the Australian National

00:01:58,920 --> 00:02:04,439
University and the University of

00:02:01,890 --> 00:02:10,050
Canberra I do some teaching here in

00:02:04,439 --> 00:02:12,540
Singapore as well so I really keen on

00:02:10,050 --> 00:02:13,569
this concept of making sure and

00:02:12,540 --> 00:02:15,730
demystifying

00:02:13,569 --> 00:02:18,489
if you like many of the complexities

00:02:15,730 --> 00:02:23,409
that we often fear and often see in

00:02:18,489 --> 00:02:25,780
machine learning and AI so as I say this

00:02:23,409 --> 00:02:27,790
is kind of like what I'm what I want to

00:02:25,780 --> 00:02:31,900
talk about today is a continuation of

00:02:27,790 --> 00:02:35,769
that theme of how do we make AI machine

00:02:31,900 --> 00:02:37,810
learning more accessible to to everyone

00:02:35,769 --> 00:02:40,989
how do we empower everyone with with

00:02:37,810 --> 00:02:43,030
this kind of technology some of you may

00:02:40,989 --> 00:02:46,090
know of and I was talking to some in the

00:02:43,030 --> 00:02:50,699
audience earlier of some of my earlier

00:02:46,090 --> 00:02:54,310
work around some toolkits that I awesome

00:02:50,699 --> 00:02:57,250
products that I developed called rattle

00:02:54,310 --> 00:03:00,159
in the our community to very easily it's

00:02:57,250 --> 00:03:03,129
a graphical user interface to build your

00:03:00,159 --> 00:03:05,439
very first machine learning model in

00:03:03,129 --> 00:03:09,340
less than four clicks or in four clicks

00:03:05,439 --> 00:03:11,469
or there abouts loading in some data

00:03:09,340 --> 00:03:14,290
building your very first model a

00:03:11,469 --> 00:03:17,139
decision tree and exploring and

00:03:14,290 --> 00:03:19,150
understanding what decision trees are in

00:03:17,139 --> 00:03:23,169
the machine learning type of context

00:03:19,150 --> 00:03:25,930
more recently I've developed the ideas

00:03:23,169 --> 00:03:30,159
further and particularly in the context

00:03:25,930 --> 00:03:33,099
of teaching and my most recent book the

00:03:30,159 --> 00:03:36,419
essentials of data science introduces a

00:03:33,099 --> 00:03:38,889
kind of a template approach that

00:03:36,419 --> 00:03:42,810
practicing data scientists like myself

00:03:38,889 --> 00:03:45,579
and my team use in a day to day basis

00:03:42,810 --> 00:03:49,239
for the projects that we get involved in

00:03:45,579 --> 00:03:52,209
and we publish openly in github a

00:03:49,239 --> 00:03:54,699
collection of templates essentially

00:03:52,209 --> 00:03:56,769
scripts in our own Python that we use as

00:03:54,699 --> 00:04:00,790
the starting point for any project that

00:03:56,769 --> 00:04:02,889
we do in data science and this leads to

00:04:00,790 --> 00:04:06,060
what I want to talk about today and

00:04:02,889 --> 00:04:09,549
introduce today which is ml hub dot I

00:04:06,060 --> 00:04:11,949
which is a repository of pre-built

00:04:09,549 --> 00:04:14,799
machine learning models today

00:04:11,949 --> 00:04:17,829
particularly in the you know I today

00:04:14,799 --> 00:04:19,150
wearing probably the fourth surge of

00:04:17,829 --> 00:04:23,469
artificial intelligence

00:04:19,150 --> 00:04:27,449
maybe it's the fifth I wasn't alive for

00:04:23,469 --> 00:04:30,900
the first the 1956 56

00:04:27,449 --> 00:04:32,689
mouths meeting the kind of created the

00:04:30,900 --> 00:04:36,689
whole field of artificial intelligence

00:04:32,689 --> 00:04:40,139
but over my career I've seen three three

00:04:36,689 --> 00:04:43,560
or four surges of interest in AI this is

00:04:40,139 --> 00:04:45,779
another surge that we're in at the

00:04:43,560 --> 00:04:48,479
moment are characterized by massive

00:04:45,779 --> 00:04:51,779
amounts of data being able to be

00:04:48,479 --> 00:04:54,689
computed across with massive amounts of

00:04:51,779 --> 00:04:56,699
compute that kind of is available to

00:04:54,689 --> 00:05:01,979
everyone today the supercomputers that

00:04:56,699 --> 00:05:05,569
we are using in the 90s are now readily

00:05:01,979 --> 00:05:08,099
available to all of us in the cloud and

00:05:05,569 --> 00:05:12,120
relatively cheaply yes you're getting

00:05:08,099 --> 00:05:15,060
two massive CPI GPUs some of the compute

00:05:12,120 --> 00:05:17,939
that we need runs for run weeks on end

00:05:15,060 --> 00:05:21,930
that does get very expensive but for

00:05:17,939 --> 00:05:24,539
smaller projects firing up massive

00:05:21,930 --> 00:05:26,819
compute on the cloud for short periods

00:05:24,539 --> 00:05:30,029
of time to do some analysis is becoming

00:05:26,819 --> 00:05:33,449
much more accessible to everyone

00:05:30,029 --> 00:05:36,659
however we are building in this current

00:05:33,449 --> 00:05:40,229
surge of AI some fairly complex and

00:05:36,659 --> 00:05:45,439
incredibly useful models in computer

00:05:40,229 --> 00:05:49,770
vision and in language audio type of

00:05:45,439 --> 00:05:53,270
areas areas characterized by massive

00:05:49,770 --> 00:05:56,909
amounts of essentially numeric data a

00:05:53,270 --> 00:05:59,370
images is numeric data audio is numeric

00:05:56,909 --> 00:06:02,430
data and so on and that's where neural

00:05:59,370 --> 00:06:05,279
networks are really doing some fantastic

00:06:02,430 --> 00:06:06,930
stuff we don't actually understand what

00:06:05,279 --> 00:06:11,490
the fuel networks are doing underneath

00:06:06,930 --> 00:06:14,250
and my purist AI kind of background says

00:06:11,490 --> 00:06:17,279
hey we're not really discovering new

00:06:14,250 --> 00:06:19,349
knowledge here but what we are doing is

00:06:17,279 --> 00:06:23,580
something incredible it looks like magic

00:06:19,349 --> 00:06:25,770
it is producing really good models and

00:06:23,580 --> 00:06:29,659
some of these models take weeks of GPU

00:06:25,770 --> 00:06:32,490
time to build in Microsoft some of the

00:06:29,659 --> 00:06:34,680
language translation model some of the

00:06:32,490 --> 00:06:36,930
text processing speech-to-text some of

00:06:34,680 --> 00:06:40,260
the image processing models that we've

00:06:36,930 --> 00:06:46,540
built where we are seeing

00:06:40,260 --> 00:06:49,810
above human results to some of these

00:06:46,540 --> 00:06:55,240
tasks these models are taking multiple

00:06:49,810 --> 00:06:57,460
weeks of multiple many GPUs to compute

00:06:55,240 --> 00:07:01,900
these models underneath using tensorflow

00:06:57,460 --> 00:07:05,080
C and D K type technologies so the

00:07:01,900 --> 00:07:07,000
question is how how can we should we be

00:07:05,080 --> 00:07:09,700
sharing these models and how can we

00:07:07,000 --> 00:07:11,230
share these these pre-built models or

00:07:09,700 --> 00:07:14,290
these models that we've built more

00:07:11,230 --> 00:07:16,870
freely amongst the community and there's

00:07:14,290 --> 00:07:19,000
a number of efforts underway to kind of

00:07:16,870 --> 00:07:22,330
figure that out

00:07:19,000 --> 00:07:24,760
given my also my background the open

00:07:22,330 --> 00:07:27,370
source community around back in the

00:07:24,760 --> 00:07:28,810
early well back in the 80s throughout

00:07:27,370 --> 00:07:32,680
the panel we would have heard I talked

00:07:28,810 --> 00:07:36,070
about I explored ideas for packaging

00:07:32,680 --> 00:07:38,680
Emacs packages and making them freely

00:07:36,070 --> 00:07:41,500
available as tar files on the internet

00:07:38,680 --> 00:07:43,900
and developing a repository then with

00:07:41,500 --> 00:07:47,530
lar tech and tech and the cetane

00:07:43,900 --> 00:07:49,479
repository I got involved in in that in

00:07:47,530 --> 00:07:53,669
the early days as well and then of

00:07:49,479 --> 00:07:56,620
course Debian developed its concept of

00:07:53,669 --> 00:08:01,030
packaging systems at the time it was

00:07:56,620 --> 00:08:04,690
really wow this is a fantastic stuff the

00:08:01,030 --> 00:08:08,100
Debian guy zine really got on top of how

00:08:04,690 --> 00:08:10,870
we should be packaging and sharing

00:08:08,100 --> 00:08:14,169
open-source products in a easy way in a

00:08:10,870 --> 00:08:18,220
repository and of course we've seen that

00:08:14,169 --> 00:08:20,820
repeated over and over again so now I

00:08:18,220 --> 00:08:24,669
come to how can we do something similar

00:08:20,820 --> 00:08:27,640
for pre-built machine learning models

00:08:24,669 --> 00:08:31,150
how can we get them out there for people

00:08:27,640 --> 00:08:32,860
to access and share the models that we

00:08:31,150 --> 00:08:35,169
build as data scientists machine

00:08:32,860 --> 00:08:37,900
learning researchers and share those

00:08:35,169 --> 00:08:43,450
models really easily amongst the

00:08:37,900 --> 00:08:46,030
community make it accessible and freely

00:08:43,450 --> 00:08:48,910
available so that others can then take

00:08:46,030 --> 00:08:50,890
those models and build upon what we have

00:08:48,910 --> 00:08:53,070
there and we have technology now that

00:08:50,890 --> 00:08:55,260
allows us to take models

00:08:53,070 --> 00:08:58,440
and extend and build on those models

00:08:55,260 --> 00:09:00,600
that we've published and provided so

00:08:58,440 --> 00:09:04,410
that's part of the motivation of in our

00:09:00,600 --> 00:09:08,880
hub another part is the case that as an

00:09:04,410 --> 00:09:11,910
educator I'm often wanting to share or

00:09:08,880 --> 00:09:14,730
to for the students to very quickly come

00:09:11,910 --> 00:09:18,560
up to speed with technologies you know

00:09:14,730 --> 00:09:22,470
the whole world is not neural networks a

00:09:18,560 --> 00:09:24,210
lot of work that we do as data

00:09:22,470 --> 00:09:26,010
scientists is still a lot of the

00:09:24,210 --> 00:09:30,960
traditional machine learning algorithms

00:09:26,010 --> 00:09:33,750
decision trees are still widely used in

00:09:30,960 --> 00:09:36,900
a lot of enterprises today that it's a

00:09:33,750 --> 00:09:40,770
good technology they're there as random

00:09:36,900 --> 00:09:44,400
forests or boosted gradient boosting

00:09:40,770 --> 00:09:46,740
type algorithms but the technology which

00:09:44,400 --> 00:09:48,390
has been around since the 1970s our

00:09:46,740 --> 00:09:53,400
neural networks been around since the

00:09:48,390 --> 00:09:57,120
1950s the technology is solid and widely

00:09:53,400 --> 00:09:58,830
used we wanted to communicate that kind

00:09:57,120 --> 00:10:01,920
of technology very very quickly as well

00:09:58,830 --> 00:10:04,110
and to show that's not really you know

00:10:01,920 --> 00:10:07,050
the mathematics behind there may be some

00:10:04,110 --> 00:10:08,790
complexities around that but it's it's

00:10:07,050 --> 00:10:10,890
there's a level of understanding we can

00:10:08,790 --> 00:10:13,020
gain fairly quickly about how machine

00:10:10,890 --> 00:10:18,060
learning actually works through a

00:10:13,020 --> 00:10:20,280
hands-on experience and we wanted that

00:10:18,060 --> 00:10:23,220
experience to be a five-minute

00:10:20,280 --> 00:10:28,320
experience and and I guess this is also

00:10:23,220 --> 00:10:31,380
you know my lack of staying ability I

00:10:28,320 --> 00:10:34,740
guess I often see new projects somebody

00:10:31,380 --> 00:10:36,360
shows me their github repository often

00:10:34,740 --> 00:10:38,280
at a conference like this I'm sitting in

00:10:36,360 --> 00:10:40,710
the audience and they're presenting a

00:10:38,280 --> 00:10:42,750
new algorithm and they say hey we've got

00:10:40,710 --> 00:10:44,250
this on a github repository and during

00:10:42,750 --> 00:10:49,170
the presentation I go to the github

00:10:44,250 --> 00:10:51,420
repository I downloaded I try to compile

00:10:49,170 --> 00:10:55,020
it all I need this and that and get the

00:10:51,420 --> 00:10:57,270
dependencies there and it

00:10:55,020 --> 00:10:59,370
I give up if it takes more than five

00:10:57,270 --> 00:11:02,550
minutes maybe it says something more

00:10:59,370 --> 00:11:04,590
about me than the software but gee I

00:11:02,550 --> 00:11:06,279
really like that experience of being

00:11:04,590 --> 00:11:10,120
able to take something and

00:11:06,279 --> 00:11:12,879
this is true in the linux world with my

00:11:10,120 --> 00:11:16,899
with package managers i can take a

00:11:12,879 --> 00:11:19,660
package while apt-get install package

00:11:16,899 --> 00:11:23,259
try it in five minutes if I like it

00:11:19,660 --> 00:11:24,759
I'll keep it if I don't I move on so

00:11:23,259 --> 00:11:32,160
it's that kind of concept I want to try

00:11:24,759 --> 00:11:34,300
and capture in the the ml hub as well so

00:11:32,160 --> 00:11:36,910
there are a number of efforts around

00:11:34,300 --> 00:11:40,990
already to kind of see if we can create

00:11:36,910 --> 00:11:42,610
repositories of pre-built models there's

00:11:40,990 --> 00:11:45,220
a couple I've got on the screen there

00:11:42,610 --> 00:11:48,790
model Depot IO is a really nice open

00:11:45,220 --> 00:11:51,670
source a program attempt to do this nice

00:11:48,790 --> 00:11:53,980
graphical user interface Microsoft has

00:11:51,670 --> 00:11:57,699
we have our own gallery Dodger dot a I

00:11:53,980 --> 00:12:01,120
for a whole bunch of pre-built AI type

00:11:57,699 --> 00:12:05,800
models some of which you can access via

00:12:01,120 --> 00:12:09,069
api's to to the cloud first one model

00:12:05,800 --> 00:12:12,189
Depot dot IO gives you some API

00:12:09,069 --> 00:12:14,230
interfaces pretty much aimed at some

00:12:12,189 --> 00:12:16,870
developers the extra thing we wanted to

00:12:14,230 --> 00:12:21,189
do with the ml hub was to make it

00:12:16,870 --> 00:12:25,209
accessible at a command line to anyone

00:12:21,189 --> 00:12:29,290
not just not just developers and maybe

00:12:25,209 --> 00:12:31,779
it's another sign of my heritage it is a

00:12:29,290 --> 00:12:34,839
command line tool as a basis at the

00:12:31,779 --> 00:12:38,649
moment so everything I'm doing here is

00:12:34,839 --> 00:12:40,870
controlled through the command line now

00:12:38,649 --> 00:12:43,769
I would like to encourage anyone who's

00:12:40,870 --> 00:12:46,389
got a computer in front of them

00:12:43,769 --> 00:12:49,079
encourage you to go through this as

00:12:46,389 --> 00:12:53,679
we're going as I'm going through it here

00:12:49,079 --> 00:12:56,559
and it's it'd be a nice experiment to

00:12:53,679 --> 00:13:00,429
see how much difficulty you get and the

00:12:56,559 --> 00:13:03,699
first difficulty is going to be the tool

00:13:00,429 --> 00:13:06,999
is currently fairly focused on running

00:13:03,699 --> 00:13:14,519
out of the box on ml on Ubuntu and

00:13:06,999 --> 00:13:14,519
particularly Ubuntu 18.04 LTS however

00:13:15,770 --> 00:13:24,260
you can install virtual machines etc

00:13:19,100 --> 00:13:27,530
running Ubuntu we we kind of suggest we

00:13:24,260 --> 00:13:31,910
test this regularly on Mac OS with

00:13:27,530 --> 00:13:33,440
parallels with running Ubuntu 1804 there

00:13:31,910 --> 00:13:40,550
how many in the audience actually

00:13:33,440 --> 00:13:47,660
running Ubuntu him okay good number and

00:13:40,550 --> 00:13:55,030
how many are running 1804 okay

00:13:47,660 --> 00:13:58,310
what are you running 1810 1904 not quite

00:13:55,030 --> 00:14:01,460
okay it probably runs out of the box on

00:13:58,310 --> 00:14:04,070
1810 as well so I would encourage you

00:14:01,460 --> 00:14:06,170
particularly if you've got Ubuntu it's

00:14:04,070 --> 00:14:09,680
not going to run out of the box on Mac

00:14:06,170 --> 00:14:14,150
OS unfortunately sorry but if you've got

00:14:09,680 --> 00:14:18,620
parallels or VirtualBox and or even a

00:14:14,150 --> 00:14:26,620
container for Ubuntu 1804 it works on

00:14:18,620 --> 00:14:29,480
all of them so to run to install ml hub

00:14:26,620 --> 00:14:32,210
it's a pip 3 install so people sorry

00:14:29,480 --> 00:14:35,510
install ml hub and that will just

00:14:32,210 --> 00:14:38,870
download ml hard latest version and

00:14:35,510 --> 00:14:41,690
you'll have it on your on your local

00:14:38,870 --> 00:14:45,140
machine Oh another way we often run this

00:14:41,690 --> 00:14:47,960
which I probably should mention is is

00:14:45,140 --> 00:14:51,520
through the cloud so Ubuntu servers on

00:14:47,960 --> 00:14:55,880
the cloud you can fire up in as your

00:14:51,520 --> 00:14:57,530
Ubuntu 1804 origin and there's your data

00:14:55,880 --> 00:15:00,590
science virtual machine particularly a

00:14:57,530 --> 00:15:04,400
data science virtual machine which is a

00:15:00,590 --> 00:15:07,730
Ubuntu server that we have published on

00:15:04,400 --> 00:15:10,900
Azure which contains all the open-source

00:15:07,730 --> 00:15:13,640
software by default that is a a I

00:15:10,900 --> 00:15:15,890
machine learning research to you so five

00:15:13,640 --> 00:15:17,810
minutes push a button and you have a

00:15:15,890 --> 00:15:20,870
data science fertile machine that has

00:15:17,810 --> 00:15:23,540
Python are tensorflow c NT k every

00:15:20,870 --> 00:15:25,640
package that you can imagine that a data

00:15:23,540 --> 00:15:29,000
scientist uses that is open source plus

00:15:25,640 --> 00:15:35,060
a few add-ins from

00:15:29,000 --> 00:15:36,890
Microsoft so very easy to install

00:15:35,060 --> 00:15:38,630
out-of-the-box the nice thing about the

00:15:36,890 --> 00:15:40,130
data science virtual machine is all of

00:15:38,630 --> 00:15:42,140
the dependencies are already there for

00:15:40,130 --> 00:15:45,350
most of the models that we publish be

00:15:42,140 --> 00:15:49,010
there mail have people three install ml

00:15:45,350 --> 00:15:54,310
hub depending on how familiar you are

00:15:49,010 --> 00:15:57,260
with PIP and the Python ecosystem pip

00:15:54,310 --> 00:15:59,270
pip install will install that into dot

00:15:57,260 --> 00:16:02,300
local been ml so you need to make sure

00:15:59,270 --> 00:16:04,760
that's in your part after you've

00:16:02,300 --> 00:16:10,100
installed that you should be able to do

00:16:04,760 --> 00:16:12,620
just ml or ml available and that will go

00:16:10,100 --> 00:16:16,580
to our ml hub repository and tell you

00:16:12,620 --> 00:16:18,100
the the models that are available at the

00:16:16,580 --> 00:16:21,200
moment

00:16:18,100 --> 00:16:24,110
ml installed will show you the list of

00:16:21,200 --> 00:16:26,710
models that are that you've currently

00:16:24,110 --> 00:16:30,260
installed now the installation process

00:16:26,710 --> 00:16:33,290
it's fairly simple

00:16:30,260 --> 00:16:35,360
it takes a collection it takes the files

00:16:33,290 --> 00:16:39,740
of the package so you can think of this

00:16:35,360 --> 00:16:43,220
like installing Linux package it takes

00:16:39,740 --> 00:16:46,430
the contents of that package it unpacks

00:16:43,220 --> 00:16:48,740
packs it it puts it into a dot ml hub

00:16:46,430 --> 00:16:51,700
folder with the name as the with the

00:16:48,740 --> 00:16:55,420
package name very very simple mechanism

00:16:51,700 --> 00:17:00,110
wanted to keep it really simple to avoid

00:16:55,420 --> 00:17:03,950
too much complexity and then the ml or

00:17:00,110 --> 00:17:08,420
command will work with what's been

00:17:03,950 --> 00:17:11,600
extracted into that package folder so

00:17:08,420 --> 00:17:14,569
when you type ml available did anyone

00:17:11,600 --> 00:17:17,060
actually have success just then great oK

00:17:14,569 --> 00:17:19,839
we've got a few hands coming up so do

00:17:17,060 --> 00:17:24,650
feel free to give it a go

00:17:19,839 --> 00:17:26,089
ml available will list a collection of

00:17:24,650 --> 00:17:28,550
the packages available on this

00:17:26,089 --> 00:17:30,800
particular repository you can point ml

00:17:28,550 --> 00:17:33,260
hub 20 repository and it will list the

00:17:30,800 --> 00:17:37,380
packages available on that repository

00:17:33,260 --> 00:17:41,860
and there's a collection of

00:17:37,380 --> 00:17:46,420
sample models there if you like that we

00:17:41,860 --> 00:17:49,870
use to illustrate ml hum now the kind of

00:17:46,420 --> 00:17:55,090
hello world example is the rain package

00:17:49,870 --> 00:17:58,530
so if we go through that ml install rain

00:17:55,090 --> 00:18:03,910
so that will go to the repository and

00:17:58,530 --> 00:18:08,260
install the rain package now the first

00:18:03,910 --> 00:18:12,300
trick here to explain is that we

00:18:08,260 --> 00:18:15,040
actually decided not to create packages

00:18:12,300 --> 00:18:18,550
I'm installing a package but we don't

00:18:15,040 --> 00:18:21,280
actually go out and create a package the

00:18:18,550 --> 00:18:24,370
packages are created dynamically from

00:18:21,280 --> 00:18:30,130
github or gate lab or bitbucket whatever

00:18:24,370 --> 00:18:32,560
your favorite git repository is and it's

00:18:30,130 --> 00:18:36,160
all based on yama files which is a

00:18:32,560 --> 00:18:39,400
configuration file to specify what has

00:18:36,160 --> 00:18:42,670
to happen for ml hub so we were at first

00:18:39,400 --> 00:18:45,790
packaging stuff from github into a zip

00:18:42,670 --> 00:18:48,730
file or our file and having that stored

00:18:45,790 --> 00:18:53,440
in a repository that turned out to be

00:18:48,730 --> 00:18:56,740
quite a loop game why take stuff out of

00:18:53,440 --> 00:19:00,250
github and put it somewhere else and why

00:18:56,740 --> 00:19:02,500
not rather take it directly from github

00:19:00,250 --> 00:19:06,220
and build the packages effectively

00:19:02,500 --> 00:19:08,230
dynamically and so you can see here it's

00:19:06,220 --> 00:19:11,550
actually getting the code from my git

00:19:08,230 --> 00:19:15,190
repository a package called grain and

00:19:11,550 --> 00:19:19,150
it's downloading that github repository

00:19:15,190 --> 00:19:23,350
and unzipping it into ml hub slash rain

00:19:19,150 --> 00:19:26,860
that's the default behavior of ml store

00:19:23,350 --> 00:19:28,780
that's all it does and another thing

00:19:26,860 --> 00:19:32,200
we've been careful to do is to always

00:19:28,780 --> 00:19:34,360
give you a guide what to do next I never

00:19:32,200 --> 00:19:36,520
like the tools that okay we've done

00:19:34,360 --> 00:19:37,990
something what do I do next I okay look

00:19:36,520 --> 00:19:41,250
up in the manual and see what I do next

00:19:37,990 --> 00:19:43,600
and so we've tried to make this as as

00:19:41,250 --> 00:19:47,890
user-friendly as possible in the sense

00:19:43,600 --> 00:19:49,240
of you know where do I go you know what

00:19:47,890 --> 00:19:50,500
one of the nice things about Ubuntu

00:19:49,240 --> 00:19:52,480
these days is

00:19:50,500 --> 00:19:55,090
if you mistype the command it will do

00:19:52,480 --> 00:19:57,550
that for you know maybe you meant this

00:19:55,090 --> 00:20:01,120
command or this command is not available

00:19:57,550 --> 00:20:05,320
install it with this apt-get command and

00:20:01,120 --> 00:20:07,780
so on so it's that kind of so it

00:20:05,320 --> 00:20:09,370
suggests ml readme so if you say ml

00:20:07,780 --> 00:20:10,780
readme in the name of the package it

00:20:09,370 --> 00:20:12,970
will show you a little bit of an

00:20:10,780 --> 00:20:15,610
introduction to that package in

00:20:12,970 --> 00:20:18,010
particular it will should give you a

00:20:15,610 --> 00:20:20,920
link to the actual github repository as

00:20:18,010 --> 00:20:22,570
well and for those who are online have a

00:20:20,920 --> 00:20:24,940
look at that github repository and you

00:20:22,570 --> 00:20:27,250
you'll get a bit of a sense of what it's

00:20:24,940 --> 00:20:29,380
doing to turn a github repository into

00:20:27,250 --> 00:20:31,860
an ml hub package and we will talk a

00:20:29,380 --> 00:20:34,540
little bit about that as time permits

00:20:31,860 --> 00:20:38,980
and then it suggests the next command is

00:20:34,540 --> 00:20:43,870
an ml configure yeah dependency is a

00:20:38,980 --> 00:20:45,160
real issue and a real struggle for it's

00:20:43,870 --> 00:20:46,990
the real problem trying to solve

00:20:45,160 --> 00:20:49,030
effectively how do we make sure we've

00:20:46,990 --> 00:20:51,550
got the proper dependency so that we can

00:20:49,030 --> 00:20:53,530
run this and so we have a system of

00:20:51,550 --> 00:20:56,230
specifying those dependencies whether

00:20:53,530 --> 00:20:58,570
there are dependencies Python operating

00:20:56,230 --> 00:21:01,150
system dependencies and so on whether

00:20:58,570 --> 00:21:05,290
you're using pip install or you have got

00:21:01,150 --> 00:21:07,420
a condor environment in python or you've

00:21:05,290 --> 00:21:10,140
got an our environment and you've got a

00:21:07,420 --> 00:21:13,990
local library of our packages and so

00:21:10,140 --> 00:21:15,400
we're looking at simplifying or handling

00:21:13,990 --> 00:21:18,970
all of that so the next command you

00:21:15,400 --> 00:21:21,460
would run is ml configure after the

00:21:18,970 --> 00:21:23,500
configure well it's gone through this

00:21:21,460 --> 00:21:28,540
package actually uses a tree or one of

00:21:23,500 --> 00:21:30,850
the it's just a PDF viewer a collection

00:21:28,540 --> 00:21:34,510
of packages that it needs from our so

00:21:30,850 --> 00:21:36,040
it's an AR model in this example and it

00:21:34,510 --> 00:21:37,750
ensures that they're all all the

00:21:36,040 --> 00:21:40,390
dependencies are actually they're

00:21:37,750 --> 00:21:45,010
available in install next command it

00:21:40,390 --> 00:21:47,620
suggests is ml commands rain it tells

00:21:45,010 --> 00:21:50,770
you what are the commands that are

00:21:47,620 --> 00:21:53,460
provided by this package so we've got

00:21:50,770 --> 00:21:56,350
one two three four commands here demo

00:21:53,460 --> 00:22:00,040
every package should have a demo command

00:21:56,350 --> 00:22:02,920
and okay to be honest it's a demo dot pi

00:22:00,040 --> 00:22:04,050
or a demo dot our script that it finds

00:22:02,920 --> 00:22:06,210
in

00:22:04,050 --> 00:22:08,190
that github repository that's all the

00:22:06,210 --> 00:22:10,680
command is sum so we've got a print dot

00:22:08,190 --> 00:22:14,580
Potter our display dot our and scored

00:22:10,680 --> 00:22:18,120
are from that repository so the next

00:22:14,580 --> 00:22:21,990
thing I want to do is to run rain to run

00:22:18,120 --> 00:22:25,170
the demo for rain emerald demo rain so I

00:22:21,990 --> 00:22:29,790
might just swap over to actually showing

00:22:25,170 --> 00:22:33,690
this if that's visible hopefully you can

00:22:29,790 --> 00:22:35,100
see that as well so oops I'm going I've

00:22:33,690 --> 00:22:39,720
already installed it so I won't install

00:22:35,100 --> 00:22:42,570
it again ml let's jump right to that ml

00:22:39,720 --> 00:22:45,710
demo rain now a little bit of a

00:22:42,570 --> 00:22:48,060
description so I would use this to

00:22:45,710 --> 00:22:50,010
explain to people what a decision tree

00:22:48,060 --> 00:22:52,770
model is very simple machine learning

00:22:50,010 --> 00:22:55,920
model it's predicting whether it's going

00:22:52,770 --> 00:22:59,240
to rain tomorrow based on historic data

00:22:55,920 --> 00:23:01,920
very simple data set very simple example

00:22:59,240 --> 00:23:04,260
but this is a pre-built model the

00:23:01,920 --> 00:23:05,550
concept is we have a pre-built model

00:23:04,260 --> 00:23:08,820
here that predicts whether it's going to

00:23:05,550 --> 00:23:11,070
rain tomorrow and we apply that model

00:23:08,820 --> 00:23:14,330
that pre-built decision tree to some

00:23:11,070 --> 00:23:16,770
actual data get the actual results and

00:23:14,330 --> 00:23:19,230
predicted results and you can see it's

00:23:16,770 --> 00:23:23,220
mostly getting getting the right answer

00:23:19,230 --> 00:23:25,020
so the model is it is doing ok and then

00:23:23,220 --> 00:23:27,420
I introduced the concept of a confusion

00:23:25,020 --> 00:23:30,090
matrix you know this is a measure of how

00:23:27,420 --> 00:23:32,010
the performance of the model and we can

00:23:30,090 --> 00:23:38,550
see it's getting an overall error rate

00:23:32,010 --> 00:23:40,380
of 25% every class error 25% it's kind

00:23:38,550 --> 00:23:43,460
of ok it's not too bad seventy-five

00:23:40,380 --> 00:23:48,720
percent accuracy type of model here's a

00:23:43,460 --> 00:23:51,680
a performance evaluation chart and we we

00:23:48,720 --> 00:23:55,350
might explain that a little bit and

00:23:51,680 --> 00:23:56,610
that's the end of the demo however there

00:23:55,350 --> 00:23:59,670
were some other commands and it says

00:23:56,610 --> 00:24:02,370
next we might want to print so ml print

00:23:59,670 --> 00:24:05,490
and maybe the choice of names can be

00:24:02,370 --> 00:24:07,350
better print is a textual explanation of

00:24:05,490 --> 00:24:10,650
the model I won't go into any detail

00:24:07,350 --> 00:24:13,410
except to say that textual structure

00:24:10,650 --> 00:24:16,410
that you see there is a just a text

00:24:13,410 --> 00:24:17,669
representation of a decision tree model

00:24:16,410 --> 00:24:21,119
it's discovered

00:24:17,669 --> 00:24:24,690
model that's the model we're using some

00:24:21,119 --> 00:24:30,239
people prefer their a more visual

00:24:24,690 --> 00:24:33,209
version of it so that will pop up a a

00:24:30,239 --> 00:24:35,489
graphical version of that textual model

00:24:33,209 --> 00:24:38,459
so here's the model that we've pre-built

00:24:35,489 --> 00:24:41,820
on some historic data it says if the

00:24:38,459 --> 00:24:44,969
humidity at 3:00 p.m. today is let's say

00:24:41,820 --> 00:24:48,690
greater than equal to 67 then the chance

00:24:44,969 --> 00:24:50,639
of it raining tomorrow is 73%

00:24:48,690 --> 00:24:52,709
similarly we go down the other path if

00:24:50,639 --> 00:24:54,959
the humidity is lower but we've got a

00:24:52,709 --> 00:24:57,779
lot of sunshine today chance of it

00:24:54,959 --> 00:25:00,200
raining tomorrow is only 16 percent so

00:24:57,779 --> 00:25:03,119
we predicted that it won't rain tomorrow

00:25:00,200 --> 00:25:05,249
with 84 percent accuracy and so on

00:25:03,119 --> 00:25:07,859
that's a decision tree model that's it's

00:25:05,249 --> 00:25:14,629
built that model on some historic data

00:25:07,859 --> 00:25:19,709
and made those decisions and often we

00:25:14,629 --> 00:25:23,039
explain the the knowledge discovery or

00:25:19,709 --> 00:25:25,559
which variable what is most impactful

00:25:23,039 --> 00:25:27,869
long the decision here whether it rains

00:25:25,559 --> 00:25:29,940
tomorrow we have these plots and it says

00:25:27,869 --> 00:25:32,549
humidity at 3 p.m. is the most important

00:25:29,940 --> 00:25:34,200
variable not so interesting from a

00:25:32,549 --> 00:25:36,239
single decision tree but very useful

00:25:34,200 --> 00:25:41,509
when we have something called a random

00:25:36,239 --> 00:25:45,809
forest or a other ensemble approaches

00:25:41,509 --> 00:25:48,029
and then we have this particular package

00:25:45,809 --> 00:25:52,339
also has a score command so we say in

00:25:48,029 --> 00:25:54,539
the score rain and that just analyze

00:25:52,339 --> 00:25:57,509
extracts the variables from the decision

00:25:54,539 --> 00:25:58,919
tree asks me what are the values of some

00:25:57,509 --> 00:26:02,099
of these variables let's just put some

00:25:58,919 --> 00:26:05,070
random numbers in I've got no idea what

00:26:02,099 --> 00:26:07,649
I'm doing here that's probably a bit too

00:26:05,070 --> 00:26:11,219
big and it says I predict the chance of

00:26:07,649 --> 00:26:13,249
rain tomorrow to be 43% if I run that

00:26:11,219 --> 00:26:17,820
again and put in some different numbers

00:26:13,249 --> 00:26:24,529
let's just put in is the same ok put in

00:26:17,820 --> 00:26:24,529
some different numbers always 43%

00:26:25,509 --> 00:26:33,709
let's try something dramatically

00:26:27,499 --> 00:26:35,690
different okay it's not really there are

00:26:33,709 --> 00:26:43,249
other pathways through that tree to get

00:26:35,690 --> 00:26:44,989
down to sixteen percent okay so so

00:26:43,249 --> 00:26:46,759
different numbers will take you down

00:26:44,989 --> 00:26:49,669
different pathways in that tree

00:26:46,759 --> 00:26:50,119
this one predicts 42% rain tomorrow this

00:26:49,669 --> 00:26:54,799
one

00:26:50,119 --> 00:26:56,089
16% rain tomorrow fuel and then a nice

00:26:54,799 --> 00:26:57,919
message at the end thank you for

00:26:56,089 --> 00:27:01,969
exploring the rain model there are no

00:26:57,919 --> 00:27:04,399
other commands to to explore here so if

00:27:01,969 --> 00:27:07,969
we go quickly go back to here we've just

00:27:04,399 --> 00:27:09,709
gone through all of that so that's a

00:27:07,969 --> 00:27:13,419
fairly simple model that's kind of like

00:27:09,709 --> 00:27:16,609
the hello world model the next one is a

00:27:13,419 --> 00:27:19,069
colorize it's it's a tensorflow built

00:27:16,609 --> 00:27:23,989
model it's one of the traditional

00:27:19,069 --> 00:27:26,359
examples of using deep learning it's it

00:27:23,989 --> 00:27:28,159
takes black-and-white photos and the

00:27:26,359 --> 00:27:30,949
color I system turns them into color

00:27:28,159 --> 00:27:35,839
photos so this is a pre-built model the

00:27:30,949 --> 00:27:39,559
the model itself took in thousands I the

00:27:35,839 --> 00:27:46,009
readme will probably tell us so in this

00:27:39,559 --> 00:27:49,159
case we would go to demo ml demo ml

00:27:46,009 --> 00:27:51,019
install colorized but then readme

00:27:49,159 --> 00:27:53,389
colorize should give a little bit of an

00:27:51,019 --> 00:27:57,099
explanation there so this is a model

00:27:53,389 --> 00:27:59,809
built by one of my colleagues in China

00:27:57,099 --> 00:28:01,459
not a lot of extra detail there if you

00:27:59,809 --> 00:28:03,349
go to the website he's probably got more

00:28:01,459 --> 00:28:05,779
more of the details there

00:28:03,349 --> 00:28:08,989
it's a tensor flow deep learning model

00:28:05,779 --> 00:28:11,989
thousands of photos black-and-white and

00:28:08,989 --> 00:28:14,329
color examples and builds a neural

00:28:11,989 --> 00:28:17,599
network model to take any black and

00:28:14,329 --> 00:28:20,359
white photo and colorize that photo so

00:28:17,599 --> 00:28:21,949
if I look at so I've do an ml install

00:28:20,359 --> 00:28:24,409
colorize you should be able to do that

00:28:21,949 --> 00:28:27,799
you should then do an ml configure

00:28:24,409 --> 00:28:29,809
colorize now I say within five minutes

00:28:27,799 --> 00:28:31,669
you should be able to get the demo up

00:28:29,809 --> 00:28:34,309
and running if you don't have all the

00:28:31,669 --> 00:28:36,229
dependencies there sometimes that time

00:28:34,309 --> 00:28:37,320
may take more than just the 5 minutes

00:28:36,229 --> 00:28:40,769
but

00:28:37,320 --> 00:28:42,720
M L once you've got the configuration it

00:28:40,769 --> 00:28:44,669
if you don't have tensorflow installed

00:28:42,720 --> 00:28:48,659
it will install tensorflow and that's

00:28:44,669 --> 00:28:52,710
not a trivial process so it will install

00:28:48,659 --> 00:28:57,929
it the dependency so ml then we go ml or

00:28:52,710 --> 00:29:00,539
demo colorize and so the point that the

00:28:57,929 --> 00:29:03,509
aim here is what could wow you within

00:29:00,539 --> 00:29:06,659
five minutes so this goes through a

00:29:03,509 --> 00:29:08,789
collection of photos black-and-white

00:29:06,659 --> 00:29:13,379
photos that it provides in the package

00:29:08,789 --> 00:29:16,200
and it color eise's them immediately for

00:29:13,379 --> 00:29:17,549
us this is not canned this is taking

00:29:16,200 --> 00:29:20,340
those black-and-white photos and

00:29:17,549 --> 00:29:21,779
colorizing them as we're running it here

00:29:20,340 --> 00:29:24,029
so I'll close that why not bring up the

00:29:21,779 --> 00:29:26,879
next one so you can see it's doing a

00:29:24,029 --> 00:29:30,330
reasonable job of colorizing a bunch of

00:29:26,879 --> 00:29:32,669
black-and-white photos I think this

00:29:30,330 --> 00:29:35,509
particular model has a bias towards

00:29:32,669 --> 00:29:39,600
water and green scenery unmastered min

00:29:35,509 --> 00:29:40,970
but it does a reasonable job on on most

00:29:39,600 --> 00:29:43,740
of these so I'm just going through

00:29:40,970 --> 00:29:46,370
control duct closing the graphic window

00:29:43,740 --> 00:29:50,600
and it goes on to the next one and

00:29:46,370 --> 00:29:54,950
that's hence colorized a whole bunch of

00:29:50,600 --> 00:29:59,519
images for me using that pre-built model

00:29:54,950 --> 00:30:03,330
so an ml installed this actually

00:29:59,519 --> 00:30:06,830
downloads from his github repository his

00:30:03,330 --> 00:30:10,919
code his demo dot PI script basically

00:30:06,830 --> 00:30:15,149
which and also the configure also

00:30:10,919 --> 00:30:16,289
downloads his binary model that he's

00:30:15,149 --> 00:30:19,320
built in tensorflow

00:30:16,289 --> 00:30:21,480
already and it downloads that to the

00:30:19,320 --> 00:30:27,389
local machine and he's running it on on

00:30:21,480 --> 00:30:28,769
this local machine here that that model

00:30:27,389 --> 00:30:30,269
could actually come from anywhere and

00:30:28,769 --> 00:30:32,730
there are many there are tensor flow

00:30:30,269 --> 00:30:35,419
based model repositories it could come

00:30:32,730 --> 00:30:38,700
from the tensor flow repository

00:30:35,419 --> 00:30:41,909
similarly we've got the res net if you

00:30:38,700 --> 00:30:43,620
know the ResNet models we've got those

00:30:41,909 --> 00:30:46,139
models we can download we've got some

00:30:43,620 --> 00:30:48,360
examples of that as well we'll probably

00:30:46,139 --> 00:30:49,350
run out of time to see that but we'll

00:30:48,360 --> 00:30:53,360
see

00:30:49,350 --> 00:30:56,539
we go now I won't do the print colorize

00:30:53,360 --> 00:31:01,919
it doesn't really give us much

00:30:56,539 --> 00:31:08,429
information but if I do in there this ml

00:31:01,919 --> 00:31:11,730
read me colorize and let's just open

00:31:08,429 --> 00:31:15,840
this link in the browser so this is

00:31:11,730 --> 00:31:19,410
going to the github repository and going

00:31:15,840 --> 00:31:21,870
to that github repository you can see

00:31:19,410 --> 00:31:23,909
it's got a bunch of the usual stuff but

00:31:21,870 --> 00:31:26,669
there's this ml hub dot llamo file and

00:31:23,909 --> 00:31:33,090
that's the key for turning any

00:31:26,669 --> 00:31:38,640
repository into a ml hub package so the

00:31:33,090 --> 00:31:43,110
aim is is to e non burdensome to be

00:31:38,640 --> 00:31:46,110
simple in anyone having a package anyone

00:31:43,110 --> 00:31:48,450
having a github repository installing a

00:31:46,110 --> 00:31:52,250
or putting creating an ml hub dot llamo

00:31:48,450 --> 00:31:55,980
file to specify what is needed and

00:31:52,250 --> 00:32:00,900
possibly creating this demo dot PI and

00:31:55,980 --> 00:32:03,929
particularly score PI for a and that

00:32:00,900 --> 00:32:06,380
turns it into an ml hub package ml hub

00:32:03,929 --> 00:32:09,720
we'll look at that github repository and

00:32:06,380 --> 00:32:12,870
in fact on the ml hub command-line ml

00:32:09,720 --> 00:32:16,260
install you can give it the path to the

00:32:12,870 --> 00:32:18,179
Emma to the github repository and it

00:32:16,260 --> 00:32:21,120
will look for the ml hub dot yeah Mel

00:32:18,179 --> 00:32:22,770
file download that file and follow the

00:32:21,120 --> 00:32:23,940
instructions in there if we have if

00:32:22,770 --> 00:32:25,289
you're online you can have a look at

00:32:23,940 --> 00:32:30,710
this yourself but if you have a quick

00:32:25,289 --> 00:32:32,880
look at this here it's a specification

00:32:30,710 --> 00:32:34,890
configuration so you can see there's the

00:32:32,880 --> 00:32:37,380
dependencies if that's big enough to see

00:32:34,890 --> 00:32:41,610
there's the dependencies for this

00:32:37,380 --> 00:32:43,860
particular package um yeah so he is

00:32:41,610 --> 00:32:45,690
using tensorflow there so we have to

00:32:43,860 --> 00:32:48,570
make sure we've got tensorflow installed

00:32:45,690 --> 00:32:51,360
a whole bunch of other the system

00:32:48,570 --> 00:32:53,370
dependencies plus the files from the

00:32:51,360 --> 00:32:54,960
repository that we also need to download

00:32:53,370 --> 00:32:58,770
so we don't have to get the whole

00:32:54,960 --> 00:33:02,210
repository just what's required to be

00:32:58,770 --> 00:33:03,769
able to demo this particular pack

00:33:02,210 --> 00:33:06,080
and so you can see a list of the files

00:33:03,769 --> 00:33:08,330
there and folders plus you can specify

00:33:06,080 --> 00:33:12,639
so here's the model that we're

00:33:08,330 --> 00:33:15,649
downloading so he's got this in a in a

00:33:12,639 --> 00:33:18,950
store somewhere that's the model that

00:33:15,649 --> 00:33:21,679
he's built on hdf5 model and we just

00:33:18,950 --> 00:33:23,809
store it locally on this machine once we

00:33:21,679 --> 00:33:25,370
download it email hub will try and be

00:33:23,809 --> 00:33:27,350
able to be clever encasing these

00:33:25,370 --> 00:33:30,830
downloads when you up when you get the

00:33:27,350 --> 00:33:33,860
new version from his repository it won't

00:33:30,830 --> 00:33:37,490
necessarily download the the actual

00:33:33,860 --> 00:33:40,250
binary model file unless it needed to so

00:33:37,490 --> 00:33:45,139
that's what's required to create an ml

00:33:40,250 --> 00:33:49,070
hub package have an ml hub dot Yama file

00:33:45,139 --> 00:33:52,279
on your repository now notice another

00:33:49,070 --> 00:33:56,539
command he's got there is score actually

00:33:52,279 --> 00:33:58,820
let's let's um just make sure I'm not

00:33:56,539 --> 00:34:02,169
skipping over too much so that's the

00:33:58,820 --> 00:34:07,190
colorized package and we've seen that

00:34:02,169 --> 00:34:09,859
and we saw the demo and we've talked

00:34:07,190 --> 00:34:15,379
about building the actual package so

00:34:09,859 --> 00:34:17,629
github and having a look at the ML Hamel

00:34:15,379 --> 00:34:20,419
file now some github repositories have

00:34:17,629 --> 00:34:22,550
multiple functionality or multiple

00:34:20,419 --> 00:34:26,770
commands if you like um before I say

00:34:22,550 --> 00:34:32,440
that let's just think about that ml hub

00:34:26,770 --> 00:34:34,849
score sorry if I just go back to here

00:34:32,440 --> 00:34:40,190
what I wanted to say was there's an ml

00:34:34,849 --> 00:34:43,310
score and this was colorize you can

00:34:40,190 --> 00:34:44,899
provide here an image any

00:34:43,310 --> 00:34:47,540
black-and-white photo that you might

00:34:44,899 --> 00:34:48,200
have or anything that you might find on

00:34:47,540 --> 00:34:51,909
the Internet

00:34:48,200 --> 00:34:57,650
whoops I think we've got an example here

00:34:51,909 --> 00:35:01,640
of a file to colorize yeah so you can do

00:34:57,650 --> 00:35:05,599
this so I'll just grab some picture from

00:35:01,640 --> 00:35:07,670
the internet and do that so that

00:35:05,599 --> 00:35:11,390
downloads that picture it colorized is

00:35:07,670 --> 00:35:12,560
the picture and it will pop up the

00:35:11,390 --> 00:35:16,520
result of that color

00:35:12,560 --> 00:35:20,390
so you know it's not dramatic then it

00:35:16,520 --> 00:35:22,010
does do the task so in effect you can

00:35:20,390 --> 00:35:23,990
think of it as a command now it's

00:35:22,010 --> 00:35:26,270
actually a small tool if I've got a

00:35:23,990 --> 00:35:28,010
folder of black and white photos that I

00:35:26,270 --> 00:35:31,610
want to colorize I just point it to the

00:35:28,010 --> 00:35:32,270
folder and it will colorize those those

00:35:31,610 --> 00:35:36,350
for me

00:35:32,270 --> 00:35:42,440
the aim again is a common infrastructure

00:35:36,350 --> 00:35:45,560
that we can use to have this working as

00:35:42,440 --> 00:35:50,240
quickly as possible so another example

00:35:45,560 --> 00:35:53,690
is that I might just illustrate with

00:35:50,240 --> 00:35:57,980
these objects ml few ml install a

00:35:53,690 --> 00:36:00,380
package called objects it's it's an

00:35:57,980 --> 00:36:02,480
again another demonstration of using

00:36:00,380 --> 00:36:07,280
neural networks on images to identify

00:36:02,480 --> 00:36:11,630
objects in photos UML install and

00:36:07,280 --> 00:36:14,210
they'll read me ml configure objects and

00:36:11,630 --> 00:36:16,820
then you'll get two ml demo objects so

00:36:14,210 --> 00:36:21,380
let's just jump straight to demo objects

00:36:16,820 --> 00:36:23,060
this is using the ResNet 150 to model I

00:36:21,380 --> 00:36:25,070
won't go into details of what that is

00:36:23,060 --> 00:36:29,030
you can go to the github repository and

00:36:25,070 --> 00:36:32,410
see what resonate and 152 is but it's a

00:36:29,030 --> 00:36:35,180
model that will take a photo and

00:36:32,410 --> 00:36:37,730
identify the primary object in that

00:36:35,180 --> 00:36:40,970
photo and it's you know there's been

00:36:37,730 --> 00:36:44,270
competition over the over the over the

00:36:40,970 --> 00:36:47,660
years maybe you have months or between

00:36:44,270 --> 00:36:50,060
Google Microsoft and others and we can

00:36:47,660 --> 00:36:54,350
leap frogging each other on how accurate

00:36:50,060 --> 00:36:57,500
these type of computer vision models can

00:36:54,350 --> 00:37:00,050
become so in this example here's a

00:36:57,500 --> 00:37:01,910
computer vision model it's it's a

00:37:00,050 --> 00:37:05,330
pre-built model so I haven't built the

00:37:01,910 --> 00:37:08,930
model here it's already built if I

00:37:05,330 --> 00:37:14,390
remember right I think this is a C NT k

00:37:08,930 --> 00:37:18,230
model and it which is another deep

00:37:14,390 --> 00:37:20,180
learning framework and it's recognizing

00:37:18,230 --> 00:37:23,150
in that image that that's an African

00:37:20,180 --> 00:37:25,630
crocodile the green there is just the

00:37:23,150 --> 00:37:27,070
strength of that recognition

00:37:25,630 --> 00:37:30,400
it could have been an American alligator

00:37:27,070 --> 00:37:34,950
or a komodo dragon but they if you see

00:37:30,400 --> 00:37:37,270
the text here 99.9% African crocodile

00:37:34,950 --> 00:37:39,310
0.07% that it's an American alligator

00:37:37,270 --> 00:37:41,380
and zero point oh two percent that it's

00:37:39,310 --> 00:37:44,170
the Komodo dragon

00:37:41,380 --> 00:37:46,060
so that's accurately identified that and

00:37:44,170 --> 00:37:47,650
so we've got a collection of examples

00:37:46,060 --> 00:37:51,340
here that's a Lynx apparently rather

00:37:47,650 --> 00:37:53,170
than a leopard or Snow Leopard this next

00:37:51,340 --> 00:37:56,020
ones are Brambling rather than a

00:37:53,170 --> 00:37:57,730
partridge and you can see there it it

00:37:56,020 --> 00:37:59,380
has slightly higher probabilities that

00:37:57,730 --> 00:38:01,710
it might have been a partridge or or

00:37:59,380 --> 00:38:01,710
water

00:38:03,640 --> 00:38:09,150
that's a liner it could have been a doc

00:38:06,070 --> 00:38:12,790
but a planetarium but pretty unlikely

00:38:09,150 --> 00:38:16,180
this one's a sports car or a racer with

00:38:12,790 --> 00:38:19,360
some degree of probability or a

00:38:16,180 --> 00:38:23,320
convertible and so on we've got a that's

00:38:19,360 --> 00:38:26,800
so called injury could be a Madagascar

00:38:23,320 --> 00:38:29,590
carrot or a koala fairly unlikely and

00:38:26,800 --> 00:38:33,160
there's a summary of them all so there's

00:38:29,590 --> 00:38:34,720
that five minute Wow or hmm looks

00:38:33,160 --> 00:38:36,190
interesting but I'm not interested

00:38:34,720 --> 00:38:40,450
particularly so I'll move on I've only

00:38:36,190 --> 00:38:46,690
waited five minutes of my time so that's

00:38:40,450 --> 00:38:48,790
the kind of intent of the of building

00:38:46,690 --> 00:38:52,180
the model and of course this has a you

00:38:48,790 --> 00:39:01,180
know score function again if I do the

00:38:52,180 --> 00:39:05,080
readme objects and go open up the github

00:39:01,180 --> 00:39:09,130
repository I think we've got further

00:39:05,080 --> 00:39:11,140
examples there yeah so I can score some

00:39:09,130 --> 00:39:13,660
random images your own images if you

00:39:11,140 --> 00:39:15,700
like or images from the internet copy

00:39:13,660 --> 00:39:18,760
that paste that into there whoops lost

00:39:15,700 --> 00:39:21,760
the M so that's downloading that image

00:39:18,760 --> 00:39:24,610
whatever it is from the internet and it

00:39:21,760 --> 00:39:28,930
will run that model the resident net

00:39:24,610 --> 00:39:31,380
model over that and it comes up and

00:39:28,930 --> 00:39:33,130
tells us that's a damselfly

00:39:31,380 --> 00:39:34,670
dragonfly a little bit higher

00:39:33,130 --> 00:39:38,630
probability

00:39:34,670 --> 00:39:44,020
in that instance but in this case it's

00:39:38,630 --> 00:39:53,240
clearly a dragonfly yeah a damselfly

00:39:44,020 --> 00:39:57,020
okay one last example we we are are

00:39:53,240 --> 00:40:00,380
saying that we look for the ml homophile

00:39:57,020 --> 00:40:04,850
in github and that defines a ml hub

00:40:00,380 --> 00:40:08,780
package we can have multiple packages

00:40:04,850 --> 00:40:11,270
within the one repository so Microsoft

00:40:08,780 --> 00:40:14,470
where we're developing what's called a

00:40:11,270 --> 00:40:18,350
collection of recommendation tools

00:40:14,470 --> 00:40:20,810
recommendation packages to support the

00:40:18,350 --> 00:40:23,000
Netflix type recommenders food

00:40:20,810 --> 00:40:23,750
recommenders and so on we're collecting

00:40:23,000 --> 00:40:26,860
together

00:40:23,750 --> 00:40:28,790
a framework for dealing with

00:40:26,860 --> 00:40:30,620
recommendations that's all all open

00:40:28,790 --> 00:40:32,870
source and it's built on our experience

00:40:30,620 --> 00:40:34,730
working with a large number of customers

00:40:32,870 --> 00:40:37,370
some of the big customers that you know

00:40:34,730 --> 00:40:40,160
of who are developing these type of

00:40:37,370 --> 00:40:42,140
technology we take the algorithmic side

00:40:40,160 --> 00:40:46,310
of that and the process side of that and

00:40:42,140 --> 00:40:48,230
turn it into github repositories that we

00:40:46,310 --> 00:40:53,800
call best practice that we're sharing

00:40:48,230 --> 00:40:56,360
openly in in github one of them is the

00:40:53,800 --> 00:40:58,370
you will find in my repository called

00:40:56,360 --> 00:41:01,730
recommenders but the original one I've

00:40:58,370 --> 00:41:03,890
got got a fork of it but Microsoft slash

00:41:01,730 --> 00:41:05,870
recommenders for example now there are

00:41:03,890 --> 00:41:08,630
multiple recommender algorithms and

00:41:05,870 --> 00:41:10,940
there's something called SAR this which

00:41:08,630 --> 00:41:17,090
is smart adaptive recommender there's

00:41:10,940 --> 00:41:20,860
RBM there are BM which is the restricted

00:41:17,090 --> 00:41:23,330
Boltzmann machine there's ALS for

00:41:20,860 --> 00:41:27,110
alternating least squares and so on and

00:41:23,330 --> 00:41:29,780
so there are multiple packages if you

00:41:27,110 --> 00:41:32,440
like in this single repository and so

00:41:29,780 --> 00:41:35,000
all that I've done to the Microsoft

00:41:32,440 --> 00:41:37,240
repository for recommenders is added

00:41:35,000 --> 00:41:42,350
I've added a folder here in this case

00:41:37,240 --> 00:41:46,490
with two Yama files RBM Jamal

00:41:42,350 --> 00:41:51,050
and sorry Emma so I can now install

00:41:46,490 --> 00:41:56,290
either RBM model or a Sam model from

00:41:51,050 --> 00:41:59,960
this one repository and indeed we can do

00:41:56,290 --> 00:42:02,450
ml install SAR that will download the

00:41:59,960 --> 00:42:06,080
appropriate files if we look at one of

00:42:02,450 --> 00:42:08,270
them yeah more RB m dot yeah more for

00:42:06,080 --> 00:42:10,760
example you can see that it specifies

00:42:08,270 --> 00:42:13,460
here the the actual files that it

00:42:10,760 --> 00:42:15,770
downloads so RB m dot pi becomes demo

00:42:13,460 --> 00:42:20,390
dot pi in the package hopefully you can

00:42:15,770 --> 00:42:22,780
see that RB MMD becomes readme MD in the

00:42:20,390 --> 00:42:29,270
package things that ml hub knows about

00:42:22,780 --> 00:42:31,880
in fact and then there's the actual some

00:42:29,270 --> 00:42:33,980
data that had also downloads so if we

00:42:31,880 --> 00:42:37,270
run this demo so this is a movie

00:42:33,980 --> 00:42:39,380
recommender it's using open subtitles

00:42:37,270 --> 00:42:43,730
data said if you're in the recommended

00:42:39,380 --> 00:42:48,050
space that's the data that is often you

00:42:43,730 --> 00:42:50,450
so we're loading the data now it takes a

00:42:48,050 --> 00:42:52,610
little while to load that data it's a

00:42:50,450 --> 00:42:54,650
fairly large data set a hundred thousand

00:42:52,610 --> 00:42:58,550
users in this data set it's loaded and

00:42:54,650 --> 00:43:00,380
it showed showing us the first few data

00:42:58,550 --> 00:43:02,210
items from there so you can see a user a

00:43:00,380 --> 00:43:03,980
movie they watched the rating they gave

00:43:02,210 --> 00:43:09,320
the movie in the name of the titles of

00:43:03,980 --> 00:43:11,750
the movie I'm now building in this case

00:43:09,320 --> 00:43:14,510
I'm actually constructing that the model

00:43:11,750 --> 00:43:19,850
and I'm applying the model to this data

00:43:14,510 --> 00:43:22,370
set and then I just as an example I use

00:43:19,850 --> 00:43:26,570
it for one particular user

00:43:22,370 --> 00:43:28,760
I've these are the movies that that user

00:43:26,570 --> 00:43:31,670
has watched or the top five movies that

00:43:28,760 --> 00:43:33,620
they've rated that they've watched the

00:43:31,670 --> 00:43:38,780
images are just downloaded dynamically

00:43:33,620 --> 00:43:41,480
from Amazon IMDB and these are movies

00:43:38,780 --> 00:43:43,280
that are being recommended by the

00:43:41,480 --> 00:43:46,520
recommendation system the model that

00:43:43,280 --> 00:43:52,640
we've just demonstrated here again the

00:43:46,520 --> 00:43:55,730
images are downloaded from Amazon so

00:43:52,640 --> 00:43:57,170
again wow that's that's great for

00:43:55,730 --> 00:43:59,780
not very interesting and move on to

00:43:57,170 --> 00:44:01,880
something else we also do model

00:43:59,780 --> 00:44:04,180
performance in the framework so if

00:44:01,880 --> 00:44:08,330
you're familiar with recommenders the

00:44:04,180 --> 00:44:10,400
map is the usual discriminative but

00:44:08,330 --> 00:44:19,750
we've got precision recall and so on

00:44:10,400 --> 00:44:19,750
there so that's basically what we see

00:44:21,100 --> 00:44:27,980
we've got face detect models there again

00:44:25,640 --> 00:44:29,720
a lot of the traditional examples of

00:44:27,980 --> 00:44:34,070
some of the more complex neural network

00:44:29,720 --> 00:44:36,760
deep learning models are included you

00:44:34,070 --> 00:44:40,550
can use it live so ml live face detect

00:44:36,760 --> 00:44:43,070
so you can have your your camera on your

00:44:40,550 --> 00:44:48,260
computer start up and it will follow

00:44:43,070 --> 00:44:50,180
your face around live as we do that and

00:44:48,260 --> 00:44:53,510
there's a variety of other packages

00:44:50,180 --> 00:44:56,119
available so just to finish ml hub dot

00:44:53,510 --> 00:44:57,710
ai is where you should be able to find

00:44:56,119 --> 00:44:59,660
all the information it's a little

00:44:57,710 --> 00:45:02,240
experimental still at the moment I'm

00:44:59,660 --> 00:45:05,060
really keen to get feedback comments

00:45:02,240 --> 00:45:07,010
some you know this is a crazy idea or um

00:45:05,060 --> 00:45:09,320
stop it now and move on to something

00:45:07,010 --> 00:45:10,790
more interesting or hey this this looks

00:45:09,320 --> 00:45:13,280
interesting we'd like to contribute

00:45:10,790 --> 00:45:14,560
model to it how can we do that love to

00:45:13,280 --> 00:45:19,820
work with anyone who's interested

00:45:14,560 --> 00:45:23,000
interested to do so and contributions

00:45:19,820 --> 00:45:24,630
are very much welcome thank you very

00:45:23,000 --> 00:45:30,490
much

00:45:24,630 --> 00:45:44,109
[Applause]

00:45:30,490 --> 00:45:47,840
so some question I have two questions

00:45:44,109 --> 00:45:52,010
the first is so other than doing just

00:45:47,840 --> 00:45:53,810
demos of various models is used to have

00:45:52,010 --> 00:45:55,970
the use case of doing ensembles on

00:45:53,810 --> 00:45:59,800
models somehow to basically leverage all

00:45:55,970 --> 00:45:59,800
of the all of the underlying models I

00:46:01,240 --> 00:46:10,760
mean in terms of the tool itself it

00:46:06,890 --> 00:46:12,890
can't you can be used as a so ml score

00:46:10,760 --> 00:46:15,440
and then a model name and then you can

00:46:12,890 --> 00:46:17,960
provide it some data file to apply the

00:46:15,440 --> 00:46:20,180
model to that data file you could

00:46:17,960 --> 00:46:22,220
orchestrate it to have multiples of

00:46:20,180 --> 00:46:24,710
these to save the output in ensembl in

00:46:22,220 --> 00:46:28,010
that way or you can package it up to

00:46:24,710 --> 00:46:30,020
demonstrate the concept of an ensemble

00:46:28,010 --> 00:46:32,630
of different types of models or an

00:46:30,020 --> 00:46:34,250
ensemble in the decision tree and the

00:46:32,630 --> 00:46:38,440
ensemble of the same type of modeling

00:46:34,250 --> 00:46:43,790
approach so it's not not excluded that

00:46:38,440 --> 00:46:45,500
do that but it's not directly and sorry

00:46:43,790 --> 00:46:48,790
just quick second question those are

00:46:45,500 --> 00:46:48,790
your slides on online somewhere

00:47:01,589 --> 00:47:04,839
thank you for your presentation just a

00:47:03,940 --> 00:47:06,730
quick question

00:47:04,839 --> 00:47:08,410
so you said their contributions of path

00:47:06,730 --> 00:47:12,579
models are welcome but what's your

00:47:08,410 --> 00:47:18,930
criteria for curating the models so

00:47:12,579 --> 00:47:22,000
currently and it is being developed and

00:47:18,930 --> 00:47:27,670
we moved away from the concept of

00:47:22,000 --> 00:47:30,520
curation when we moved from taking the

00:47:27,670 --> 00:47:33,400
data are the the code from github and

00:47:30,520 --> 00:47:36,819
putting it into our zip file and moving

00:47:33,400 --> 00:47:39,640
that to github itself now in terms of

00:47:36,819 --> 00:47:41,980
our package repository so in ml hub when

00:47:39,640 --> 00:47:44,140
you say ml available it gives you a list

00:47:41,980 --> 00:47:46,619
of the packages that is curated there

00:47:44,140 --> 00:47:50,530
that's where our curation takes place

00:47:46,619 --> 00:47:53,589
however you can install models from

00:47:50,530 --> 00:47:55,420
anywhere you like so ml install and then

00:47:53,589 --> 00:47:59,619
you give it the github location of the

00:47:55,420 --> 00:48:03,040
yam or file anyone can install a model

00:47:59,619 --> 00:48:05,710
in that way the ones that we put into

00:48:03,040 --> 00:48:08,079
our repository where curating where X

00:48:05,710 --> 00:48:11,980
we're ensuring that they look okay they

00:48:08,079 --> 00:48:15,880
work ok hopefully there's no issues in

00:48:11,980 --> 00:48:18,970
the security of those models we will

00:48:15,880 --> 00:48:21,280
review the code and so we are confident

00:48:18,970 --> 00:48:25,900
the ones that we're curating in that

00:48:21,280 --> 00:48:28,720
list underneath when you do ml available

00:48:25,900 --> 00:48:34,599
you've seen a list of that on the next

00:48:28,720 --> 00:48:36,400
slide you'll see a list of models chip

00:48:34,599 --> 00:48:39,280
them is just a map to a github

00:48:36,400 --> 00:48:41,230
repository with model actually Lintz so

00:48:39,280 --> 00:48:43,240
it's just a shorthand for that command

00:48:41,230 --> 00:48:46,000
line that says ml and then the whole

00:48:43,240 --> 00:48:48,730
github path but that's what we're

00:48:46,000 --> 00:48:51,280
curating but there's nothing to stop

00:48:48,730 --> 00:48:52,990
anyone creating their own ml hub model

00:48:51,280 --> 00:48:57,299
and you'll be able to point anyone else

00:48:52,990 --> 00:48:57,299
to that model through the ml hub c'mon

00:49:02,300 --> 00:49:08,090
my my thing says yet thank you very much

00:49:05,460 --> 00:49:08,090

YouTube URL: https://www.youtube.com/watch?v=dVWc6fYMJKA


