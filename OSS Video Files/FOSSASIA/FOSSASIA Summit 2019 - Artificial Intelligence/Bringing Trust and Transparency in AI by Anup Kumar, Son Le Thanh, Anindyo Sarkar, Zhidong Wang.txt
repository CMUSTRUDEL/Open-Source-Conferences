Title: Bringing Trust and Transparency in AI by Anup Kumar, Son Le Thanh, Anindyo Sarkar, Zhidong Wang
Publication date: 2019-03-27
Playlist: FOSSASIA Summit 2019 - Artificial Intelligence
Description: 
	15 March 2019 11:05, Event Hall 2-1

In this workshop participants will learn how they can understand the data they have, apply this information to build and run optimal machine learning models, and then operationalizing AI to continuously understand, improve, and explain outcomes. In the hands on lab we will be using data science workbench to explore, model and deploy a machine learning model and then monitor the model for performance, accuracy, and fairness.

* Audience: Data Scientists, Application Developers, Domain Experts

* Keywords: Python, Jupyter Notebooks, Python, Rest API, Machine Learning, Trust and Transparency, Object Storage, Watson, Studio, Watson Openscale, AI

Requirements

* Bring a laptop wit full access. The installation of software is required for this workshop.
* Sign up for IBM Cloud before the workshop: http://ibm.biz/FOSSASIAIBM
Captions: 
	00:00:00,030 --> 00:00:06,720
okay Oh in terms of AI adoption and why

00:00:04,740 --> 00:00:09,599
we are talking about bias oil you know

00:00:06,720 --> 00:00:12,150
now one of the reason is you know in the

00:00:09,599 --> 00:00:15,120
early stages of adoption right you know

00:00:12,150 --> 00:00:17,250
in terms of machine learning and AI bias

00:00:15,120 --> 00:00:19,980
was not even thought about because

00:00:17,250 --> 00:00:22,140
everybody was just in a hurry to get the

00:00:19,980 --> 00:00:23,850
result right the outcome was more

00:00:22,140 --> 00:00:28,769
important than you know the quality of

00:00:23,850 --> 00:00:30,390
the outcome itself right but today if

00:00:28,769 --> 00:00:33,690
you look at you know you can create a

00:00:30,390 --> 00:00:36,559
model maybe in ten minutes right you may

00:00:33,690 --> 00:00:38,850
take a whole year to do the same stuff

00:00:36,559 --> 00:00:40,500
right because what matters is the

00:00:38,850 --> 00:00:43,140
quality of the output you are getting

00:00:40,500 --> 00:00:45,809
and one of the quality parameter is how

00:00:43,140 --> 00:00:48,420
good is your algorithms in terms of bias

00:00:45,809 --> 00:00:51,480
detection right in terms of making sure

00:00:48,420 --> 00:00:54,149
that you know if you give the a new set

00:00:51,480 --> 00:00:57,180
of data how it responds to the new set

00:00:54,149 --> 00:00:58,350
of data and that's why we are here and

00:00:57,180 --> 00:01:01,170
if you look at you know what we are

00:00:58,350 --> 00:01:03,059
trying to say is when the AI adoption is

00:01:01,170 --> 00:01:05,580
increasing one of the biggest issue in

00:01:03,059 --> 00:01:08,360
terms of the success of the AI itself is

00:01:05,580 --> 00:01:10,950
because people don't trust the outcome

00:01:08,360 --> 00:01:14,700
okay there was a pretty good joke about

00:01:10,950 --> 00:01:17,640
IBM you know a couple of years back IBM

00:01:14,700 --> 00:01:20,070
created a very simple application when

00:01:17,640 --> 00:01:21,420
you go to the airport it tells you you

00:01:20,070 --> 00:01:25,049
know remember they do the screening

00:01:21,420 --> 00:01:26,250
right and at the moment you know

00:01:25,049 --> 00:01:28,799
basically the security guy will just

00:01:26,250 --> 00:01:31,079
stop you and say that okay I want to

00:01:28,799 --> 00:01:32,549
scream and people thought oh this was

00:01:31,079 --> 00:01:34,409
biased because you know he looked at the

00:01:32,549 --> 00:01:36,509
person and based on that you know he

00:01:34,409 --> 00:01:38,310
will randomly pick it was supposed to be

00:01:36,509 --> 00:01:39,630
random but a lot of time everybody you

00:01:38,310 --> 00:01:42,180
know who went through that his cleaning

00:01:39,630 --> 00:01:43,649
process thought he was biased right so

00:01:42,180 --> 00:01:46,350
what they did is they asked IBM what you

00:01:43,649 --> 00:01:49,079
can do and we created a small app right

00:01:46,350 --> 00:01:51,990
it's like iPad app and you know you just

00:01:49,079 --> 00:01:53,850
go through tap in you go straight or you

00:01:51,990 --> 00:01:56,100
go through the screening process now

00:01:53,850 --> 00:01:58,049
that app was like in a few million

00:01:56,100 --> 00:01:59,909
dollar okay

00:01:58,049 --> 00:02:01,469
and someone put on internet that you

00:01:59,909 --> 00:02:04,140
know it was written by maybe some

00:02:01,469 --> 00:02:07,020
interns or something maybe in an hour

00:02:04,140 --> 00:02:10,020
okay so a million dollar for just you

00:02:07,020 --> 00:02:11,730
know few line of code but that was not

00:02:10,020 --> 00:02:13,830
true right you know in inside you know

00:02:11,730 --> 00:02:16,740
we did a lot of stuff to make sure that

00:02:13,830 --> 00:02:19,530
we mitigate those biases and the very

00:02:16,740 --> 00:02:22,020
reason the application was created okay

00:02:19,530 --> 00:02:23,850
so what I wanted to see you is when

00:02:22,020 --> 00:02:26,520
you're embarking on the journey of you

00:02:23,850 --> 00:02:28,470
know creating a model trust is very

00:02:26,520 --> 00:02:30,330
important right the correctness of the

00:02:28,470 --> 00:02:32,970
model is very important it's not just

00:02:30,330 --> 00:02:36,120
about model itself okay and that's what

00:02:32,970 --> 00:02:38,280
I'm going to focus today now for some of

00:02:36,120 --> 00:02:41,130
you who are new to machine learning I

00:02:38,280 --> 00:02:42,870
heard a lot of you you know some of you

00:02:41,130 --> 00:02:45,990
said you are here for the first time

00:02:42,870 --> 00:02:49,230
you're hearing something okay we don't

00:02:45,990 --> 00:02:50,400
have like you know I'll say time to go

00:02:49,230 --> 00:02:52,290
through the whole machine learning

00:02:50,400 --> 00:02:54,870
exercise but I just put up like what I

00:02:52,290 --> 00:02:56,580
call a cheat sheet for machine learning

00:02:54,870 --> 00:02:58,560
and I'll take one minutes to walk you

00:02:56,580 --> 00:03:01,650
through right basically related to like

00:02:58,560 --> 00:03:04,740
for example oh I want to predict about

00:03:01,650 --> 00:03:07,380
someone going to a college degree after

00:03:04,740 --> 00:03:09,930
10 plus 2 right after your a-level

00:03:07,380 --> 00:03:11,360
whatever you see now for that purpose

00:03:09,930 --> 00:03:14,310
you know because your data is already

00:03:11,360 --> 00:03:16,050
kind of categorical right you'll be

00:03:14,310 --> 00:03:18,900
using logistic regression instead of

00:03:16,050 --> 00:03:21,120
using basic regulation right the same

00:03:18,900 --> 00:03:23,340
way you know if I want to do any kind of

00:03:21,120 --> 00:03:25,200
prediction right and basically the

00:03:23,340 --> 00:03:27,030
recommendation engine you see where

00:03:25,200 --> 00:03:29,250
someone is trying to figure out whether

00:03:27,030 --> 00:03:31,019
you'll get a loan or not for that

00:03:29,250 --> 00:03:33,390
purpose we are using a stuff like you

00:03:31,019 --> 00:03:38,010
know decision tree or the random forest

00:03:33,390 --> 00:03:40,080
kind of algorithms okay the idea behind

00:03:38,010 --> 00:03:42,150
no matter what you are using the step

00:03:40,080 --> 00:03:45,890
what you go through is the same okay

00:03:42,150 --> 00:03:48,570
this algorithms are much more ulting

00:03:45,890 --> 00:03:50,970
trusted the reason is when I am doing

00:03:48,570 --> 00:03:53,459
our decision tree or a random forest it

00:03:50,970 --> 00:03:56,120
gives me a pretty good like a diagram

00:03:53,459 --> 00:03:58,890
like on what basis the decision came

00:03:56,120 --> 00:04:01,709
okay so that's why if you look at you

00:03:58,890 --> 00:04:04,019
know I the success of this algorithms

00:04:01,709 --> 00:04:06,090
are much higher as compared to deep

00:04:04,019 --> 00:04:07,620
learning algorithms because deep

00:04:06,090 --> 00:04:09,959
learning algorithms you know I'll talk

00:04:07,620 --> 00:04:12,180
about that where they use the concept of

00:04:09,959 --> 00:04:14,130
neural networks and other things to you

00:04:12,180 --> 00:04:15,989
know come to a conclusion and because

00:04:14,130 --> 00:04:20,370
lot of things are black box over there

00:04:15,989 --> 00:04:21,989
right the trust is not that high so you

00:04:20,370 --> 00:04:23,940
know if someone is starting and it's

00:04:21,989 --> 00:04:25,620
good to learn deep learning and all but

00:04:23,940 --> 00:04:27,240
if you really want to be successful and

00:04:25,620 --> 00:04:28,710
if you really want to do

00:04:27,240 --> 00:04:30,990
plop something right which you can put

00:04:28,710 --> 00:04:35,120
in production which people can trust I

00:04:30,990 --> 00:04:37,349
will say start from here alright so uh

00:04:35,120 --> 00:04:39,240
yeah so whatever saying is you know you

00:04:37,349 --> 00:04:40,949
got much better off trust and other

00:04:39,240 --> 00:04:44,009
things with this them because these

00:04:40,949 --> 00:04:46,319
algorithms itself give you on what basis

00:04:44,009 --> 00:04:48,090
you came to a conclusion but it

00:04:46,319 --> 00:04:50,610
specifically the deep learning algorithm

00:04:48,090 --> 00:04:53,160
doesn't tell you right so here we are

00:04:50,610 --> 00:04:56,539
going to talk about how do we when we

00:04:53,160 --> 00:04:57,919
build a model how do we develop trust

00:04:56,539 --> 00:05:01,409
okay

00:04:57,919 --> 00:05:03,870
now the beauty dot AI application which

00:05:01,409 --> 00:05:05,610
I showed you you know you can say okay

00:05:03,870 --> 00:05:08,759
even if it goes wrong it was made for

00:05:05,610 --> 00:05:11,180
fun purpose right so you know doesn't

00:05:08,759 --> 00:05:13,949
we'll have a like a life-changing impact

00:05:11,180 --> 00:05:15,449
but trust me the algorithm which you

00:05:13,949 --> 00:05:18,690
build can have a life-changing impact

00:05:15,449 --> 00:05:22,130
okay just to give you an idea okay so

00:05:18,690 --> 00:05:25,949
this was one of the you know use keys

00:05:22,130 --> 00:05:29,310
regarding you know machine bias okay and

00:05:25,949 --> 00:05:31,110
this was really research a lot and what

00:05:29,310 --> 00:05:33,060
they figured out is just to I'm giving

00:05:31,110 --> 00:05:34,949
you a summary of the result so what

00:05:33,060 --> 00:05:37,349
happened is there was this algorithm put

00:05:34,949 --> 00:05:40,199
into like the you know criminal system

00:05:37,349 --> 00:05:42,210
where they basically help you to

00:05:40,199 --> 00:05:45,780
identify like how many years of

00:05:42,210 --> 00:05:48,150
imprisonment you have to go through okay

00:05:45,780 --> 00:05:51,930
so in this case what happened is they

00:05:48,150 --> 00:05:53,699
were to tapped okay and this algorithm

00:05:51,930 --> 00:05:56,669
which was being used by the police

00:05:53,699 --> 00:05:58,770
department you know looked at the

00:05:56,669 --> 00:06:01,110
picture and looked at the profile of the

00:05:58,770 --> 00:06:03,599
person as well and based on that it

00:06:01,110 --> 00:06:06,509
basically says that this guy is a low

00:06:03,599 --> 00:06:09,030
risk and the other person or Britisher

00:06:06,509 --> 00:06:11,520
Borden high risk and if you look at the

00:06:09,030 --> 00:06:13,979
risk category it's pretty high so this

00:06:11,520 --> 00:06:15,419
is like on a score of one to ten the

00:06:13,979 --> 00:06:18,300
risk basically tells you the algorithm

00:06:15,419 --> 00:06:20,840
was about what is a good chance that

00:06:18,300 --> 00:06:25,380
this person is going to do another crime

00:06:20,840 --> 00:06:27,840
okay so they waited you know high okay

00:06:25,380 --> 00:06:30,180
but what really happened right after

00:06:27,840 --> 00:06:32,159
like you know you can't look at in the

00:06:30,180 --> 00:06:33,569
future but you know after sometime you

00:06:32,159 --> 00:06:36,889
can look in the past and see what

00:06:33,569 --> 00:06:38,750
happens so this is really what happened

00:06:36,889 --> 00:06:42,030
okay

00:06:38,750 --> 00:06:42,660
this guy whom they risk like just a

00:06:42,030 --> 00:06:45,540
lower-risk

00:06:42,660 --> 00:06:48,540
already has some past experience okay

00:06:45,540 --> 00:06:51,600
two armed robbery and he did some

00:06:48,540 --> 00:06:55,500
subsequent offense as well okay in this

00:06:51,600 --> 00:06:59,010
case there was no offense right either

00:06:55,500 --> 00:07:02,340
before or after so what if sources your

00:06:59,010 --> 00:07:08,130
algorithm was totally wrong and it

00:07:02,340 --> 00:07:09,750
happened because the bias right so what

00:07:08,130 --> 00:07:13,140
happened is the algorithm was trained

00:07:09,750 --> 00:07:15,210
based on historical data set and one of

00:07:13,140 --> 00:07:16,770
the thing which happens is you know even

00:07:15,210 --> 00:07:20,310
the beauty dot a I mean what happened is

00:07:16,770 --> 00:07:23,310
the trained the model based on a certain

00:07:20,310 --> 00:07:25,680
set of data and this data was mostly

00:07:23,310 --> 00:07:28,290
from let's say you know European

00:07:25,680 --> 00:07:31,920
countries or America right and that's

00:07:28,290 --> 00:07:33,720
why this bias happens okay so what I'm

00:07:31,920 --> 00:07:35,580
trying to say is it's not just fun right

00:07:33,720 --> 00:07:38,280
the trust and the bias it's a very

00:07:35,580 --> 00:07:40,260
serious it's a life-changing impact on

00:07:38,280 --> 00:07:42,030
someone so when you're developing your

00:07:40,260 --> 00:07:44,430
code you need to be responsible person

00:07:42,030 --> 00:07:48,690
and make sure that you imbibe this on

00:07:44,430 --> 00:07:51,780
day one now here I got a life cycle of

00:07:48,690 --> 00:07:54,480
how you make sure that this o bias your

00:07:51,780 --> 00:07:57,120
code okay pretty complex stuff but I'm

00:07:54,480 --> 00:07:59,340
trying to simplify not oversimplify but

00:07:57,120 --> 00:08:02,520
you know trying to simplify so that we

00:07:59,340 --> 00:08:04,290
can cover in this session so we talked

00:08:02,520 --> 00:08:06,060
about you know building a model let's

00:08:04,290 --> 00:08:08,010
say we are building this model for the

00:08:06,060 --> 00:08:09,630
same stuff right trying to find out

00:08:08,010 --> 00:08:13,230
whether this person will do a crime

00:08:09,630 --> 00:08:14,610
again or not the first thing is of

00:08:13,230 --> 00:08:16,800
course you have to do some this is a

00:08:14,610 --> 00:08:18,750
life cycle of your machine learning

00:08:16,800 --> 00:08:22,560
model development as well I've just

00:08:18,750 --> 00:08:24,930
added the bias you know it steps as well

00:08:22,560 --> 00:08:26,580
over here so first you do the

00:08:24,930 --> 00:08:28,320
pre-processing what I mean by

00:08:26,580 --> 00:08:29,880
pre-processing is you know you may get

00:08:28,320 --> 00:08:32,850
data right for example if I am looking

00:08:29,880 --> 00:08:35,490
at you know some references I may be

00:08:32,850 --> 00:08:37,800
getting the data in you know some HTML

00:08:35,490 --> 00:08:40,229
format some JSON format you know

00:08:37,800 --> 00:08:41,940
something else right what do you need to

00:08:40,229 --> 00:08:44,640
do is you need to make sure that the

00:08:41,940 --> 00:08:46,560
data can be utilized for your algorithm

00:08:44,640 --> 00:08:48,480
that basically means either you are

00:08:46,560 --> 00:08:49,650
doing the categorizations right

00:08:48,480 --> 00:08:51,690
sometimes you are doing a

00:08:49,650 --> 00:08:52,380
standardization and sometimes just

00:08:51,690 --> 00:08:55,280
grouping

00:08:52,380 --> 00:08:58,110
self you know you're converting your

00:08:55,280 --> 00:09:01,290
categorical into a numerical value right

00:08:58,110 --> 00:09:04,440
just to give an example for example you

00:09:01,290 --> 00:09:06,480
know if I have each of every individual

00:09:04,440 --> 00:09:08,880
if you give machine learning or age

00:09:06,480 --> 00:09:10,530
itself it doesn't mean anything so what

00:09:08,880 --> 00:09:13,320
you have to do is you have to categorize

00:09:10,530 --> 00:09:16,950
this age into age group right and that's

00:09:13,320 --> 00:09:18,210
part of the pre-processing right so you

00:09:16,950 --> 00:09:20,070
have to go through the pre-processing

00:09:18,210 --> 00:09:22,350
and then what you do is you have some

00:09:20,070 --> 00:09:25,560
training data so you get a samples of

00:09:22,350 --> 00:09:27,330
data and this tour this sample right you

00:09:25,560 --> 00:09:31,440
split the data into what we call other

00:09:27,330 --> 00:09:33,960
data test data right and doing the

00:09:31,440 --> 00:09:36,330
training part you train your model using

00:09:33,960 --> 00:09:38,850
those algorithms okay and after that you

00:09:36,330 --> 00:09:42,030
are testing it okay and then usually you

00:09:38,850 --> 00:09:43,850
go ahead and deploy it now there are a

00:09:42,030 --> 00:09:47,100
couple of ways where you can do the

00:09:43,850 --> 00:09:48,930
mitigation one is of course you know

00:09:47,100 --> 00:09:51,300
when you deploy you learn from the

00:09:48,930 --> 00:09:52,860
experience so in this case it's very

00:09:51,300 --> 00:09:55,320
straightforward I didn't need anything

00:09:52,860 --> 00:09:57,930
in the past I deployed the model but I

00:09:55,320 --> 00:10:01,140
have a mechanism by which I can monitor

00:09:57,930 --> 00:10:03,960
the model okay figure out if the model

00:10:01,140 --> 00:10:07,230
is bias if it is bias I take that

00:10:03,960 --> 00:10:10,170
feedback do some cleanup right and we

00:10:07,230 --> 00:10:11,640
deploy the model so if you're going with

00:10:10,170 --> 00:10:13,590
this approach that basically means

00:10:11,640 --> 00:10:17,640
you're look monitoring the outcome each

00:10:13,590 --> 00:10:20,580
and every outcome okay over a period of

00:10:17,640 --> 00:10:22,830
time but this is more like I will say

00:10:20,580 --> 00:10:24,570
reactive approach right because what is

00:10:22,830 --> 00:10:26,540
happening is already someone life has

00:10:24,570 --> 00:10:30,150
been impacted and now you're trying to

00:10:26,540 --> 00:10:32,760
mitigate it the proactive approach will

00:10:30,150 --> 00:10:36,740
be before even if you go to data step

00:10:32,760 --> 00:10:40,290
right you have the training data okay do

00:10:36,740 --> 00:10:42,420
what I call is you know pre-processing

00:10:40,290 --> 00:10:45,680
on that training data and try to go

00:10:42,420 --> 00:10:48,950
through you know data what I call is

00:10:45,680 --> 00:10:54,810
going through algorithm that mitigate

00:10:48,950 --> 00:10:56,370
biases from the data itself okay what it

00:10:54,810 --> 00:10:59,160
mean is let's see if I give you a data

00:10:56,370 --> 00:11:00,390
right and I'm just trying to simplify in

00:10:59,160 --> 00:11:02,370
the sense that let's say I give you a

00:11:00,390 --> 00:11:04,890
data and we are trying to say that okay

00:11:02,370 --> 00:11:06,030
the other earlier example I took how

00:11:04,890 --> 00:11:09,900
many people will go

00:11:06,030 --> 00:11:13,920
from you know 10+2 to college right and

00:11:09,900 --> 00:11:16,200
if I'm picking a particular city okay

00:11:13,920 --> 00:11:18,540
like let's say Singapore and I'm going

00:11:16,200 --> 00:11:20,330
to use this model you know somewhere

00:11:18,540 --> 00:11:23,790
else some other part of the world

00:11:20,330 --> 00:11:26,430
already I am biased because over here

00:11:23,790 --> 00:11:28,680
right you know the living style of the

00:11:26,430 --> 00:11:31,110
economic is very different than the rest

00:11:28,680 --> 00:11:32,790
of the country so when you are doing

00:11:31,110 --> 00:11:35,040
mitigating this kind of bias what you

00:11:32,790 --> 00:11:36,180
need to do you need to generalize your

00:11:35,040 --> 00:11:37,920
dataset

00:11:36,180 --> 00:11:41,040
okay you need to make sure that your

00:11:37,920 --> 00:11:44,130
data set is general enough to represent

00:11:41,040 --> 00:11:46,920
a larger population okay so that's what

00:11:44,130 --> 00:11:48,870
you do into the this if it is very

00:11:46,920 --> 00:11:50,400
simple right you can do that but certain

00:11:48,870 --> 00:11:52,080
point of time you'll find that it's very

00:11:50,400 --> 00:11:54,210
complicated okay

00:11:52,080 --> 00:11:56,070
I will start from here right the

00:11:54,210 --> 00:11:58,770
proactive effort and then we'll go to

00:11:56,070 --> 00:12:01,050
the reactive effort so for the proactive

00:11:58,770 --> 00:12:04,470
effort we put something called AI

00:12:01,050 --> 00:12:07,290
fairness 360 and this is a open source

00:12:04,470 --> 00:12:10,770
toolkit okay so all of you have access

00:12:07,290 --> 00:12:13,980
to this okay what the AI fairness 360

00:12:10,770 --> 00:12:15,770
open source toolkit does basically it

00:12:13,980 --> 00:12:19,200
gives you more than 70 different

00:12:15,770 --> 00:12:22,770
algorithm which can help you find a risk

00:12:19,200 --> 00:12:25,140
in your data set itself okay also it

00:12:22,770 --> 00:12:27,930
provides more than 20 different matrices

00:12:25,140 --> 00:12:30,870
which will basically tell you right you

00:12:27,930 --> 00:12:32,970
know whether if you develop an algorithm

00:12:30,870 --> 00:12:35,820
based on this data set will have a

00:12:32,970 --> 00:12:39,360
problem or not okay I'll show you

00:12:35,820 --> 00:12:43,070
quickly you know how you can use this so

00:12:39,360 --> 00:12:43,070
let me go to this

00:12:53,639 --> 00:13:02,290
yeah so this is the URL is now a call AI

00:12:58,600 --> 00:13:04,089
Fairness 360 I'll put it on my in a

00:13:02,290 --> 00:13:07,259
PowerPoint if it is not visible

00:13:04,089 --> 00:13:08,379
it's called AI F 360 . my bluemix.net

00:13:07,259 --> 00:13:10,899
okay

00:13:08,379 --> 00:13:13,720
and this asset was developed by IBM

00:13:10,899 --> 00:13:15,370
Research okay and do you know it has

00:13:13,720 --> 00:13:17,829
been there for last like we published it

00:13:15,370 --> 00:13:19,029
we open-source it six months back we

00:13:17,829 --> 00:13:21,160
have getting pretty good you know

00:13:19,029 --> 00:13:22,839
interaction and what I would suggest if

00:13:21,160 --> 00:13:25,180
you are into open-source please

00:13:22,839 --> 00:13:28,029
contribute back use this and contribute

00:13:25,180 --> 00:13:30,490
back to this as well okay now let's look

00:13:28,029 --> 00:13:33,759
at you know how this helps you to

00:13:30,490 --> 00:13:35,800
mitigate a risk okay so what we provide

00:13:33,759 --> 00:13:37,930
you the API we provide you the algorithm

00:13:35,800 --> 00:13:40,029
but for this sake you know just to make

00:13:37,930 --> 00:13:42,250
it easier for you to understand or we

00:13:40,029 --> 00:13:44,379
also created a small demo I'll just walk

00:13:42,250 --> 00:13:47,259
you through this demo is available okay

00:13:44,379 --> 00:13:50,139
I'm going to use this you know this data

00:13:47,259 --> 00:13:52,660
called German credit scoring and this is

00:13:50,139 --> 00:13:55,209
a the same data set we are going to use

00:13:52,660 --> 00:13:56,769
in our lab okay so I'm just trying to

00:13:55,209 --> 00:13:59,589
make sure that you get to understand

00:13:56,769 --> 00:14:00,689
this data set better in this case I have

00:13:59,589 --> 00:14:03,970
like you know basically we provide

00:14:00,689 --> 00:14:05,500
predicting individual credit risk very

00:14:03,970 --> 00:14:08,139
common thing right we all go through

00:14:05,500 --> 00:14:10,569
that the banks are doing on us so we are

00:14:08,139 --> 00:14:15,730
going to do a credit risk prediction

00:14:10,569 --> 00:14:17,620
oh now in this case the first step is

00:14:15,730 --> 00:14:20,019
checking the bias whether the data is

00:14:17,620 --> 00:14:26,860
good or the data is having some bias

00:14:20,019 --> 00:14:28,809
okay now how to find out bias right and

00:14:26,860 --> 00:14:31,720
this is not like rocket science but

00:14:28,809 --> 00:14:34,750
again it's a lot of mathematical you

00:14:31,720 --> 00:14:36,610
know equations as well I will take the

00:14:34,750 --> 00:14:38,500
simplest one okay I'm not going to

00:14:36,610 --> 00:14:40,449
explain the complex one the simplest one

00:14:38,500 --> 00:14:42,730
so let's say for example there is

00:14:40,449 --> 00:14:46,420
something called statistical parity

00:14:42,730 --> 00:14:47,980
difference okay this basically tells

00:14:46,420 --> 00:14:49,870
like okay there is this concept of

00:14:47,980 --> 00:14:51,579
privileged group and unprivileged group

00:14:49,870 --> 00:14:54,490
right so what are you saying is let's

00:14:51,579 --> 00:14:56,709
say you know in our Beauty dot AI we

00:14:54,490 --> 00:14:59,290
said you know the guys with the white

00:14:56,709 --> 00:15:01,720
scheme is a privileged group other is

00:14:59,290 --> 00:15:04,490
unprivileged group right or we can say

00:15:01,720 --> 00:15:06,870
each right

00:15:04,490 --> 00:15:09,690
algorithm the statistical parity

00:15:06,870 --> 00:15:12,990
difference basically tells you right in

00:15:09,690 --> 00:15:15,360
terms of the outcome where you are bias

00:15:12,990 --> 00:15:17,400
okay so basically if you're getting a

00:15:15,360 --> 00:15:19,320
value of zero that means you're neutral

00:15:17,400 --> 00:15:22,140
if you're getting anywhere then you

00:15:19,320 --> 00:15:24,210
basically it means bias so what we did

00:15:22,140 --> 00:15:27,090
is we created more than you know seventy

00:15:24,210 --> 00:15:29,610
different you know such matrixes right

00:15:27,090 --> 00:15:32,430
and over here like on this data sets

00:15:29,610 --> 00:15:34,590
when I apply this algorithm what we do

00:15:32,430 --> 00:15:37,110
is we apply not just one algorithm but

00:15:34,590 --> 00:15:40,080
multiple set of algorithm in behind and

00:15:37,110 --> 00:15:42,840
this is giving me a few matrices right

00:15:40,080 --> 00:15:46,050
with me you know this data set is of

00:15:42,840 --> 00:15:49,020
limit it a set or it is good to use okay

00:15:46,050 --> 00:15:50,730
so in this case it says that okay

00:15:49,020 --> 00:15:54,750
statical private a difference you know

00:15:50,730 --> 00:15:58,410
the difference is 0.01 means almost it

00:15:54,750 --> 00:15:59,790
is fair right but in certain cases you

00:15:58,410 --> 00:16:03,330
know you'll find that you know or

00:15:59,790 --> 00:16:06,120
disparate impact or in case of you know

00:16:03,330 --> 00:16:08,460
thrill index right i see you know a much

00:16:06,120 --> 00:16:11,070
higher or something so if you find in

00:16:08,460 --> 00:16:13,110
this case you know the data set is like

00:16:11,070 --> 00:16:17,280
if you look at you know for we are

00:16:13,110 --> 00:16:19,110
looking for two different entity okay

00:16:17,280 --> 00:16:20,880
one is the sex right whether it's a male

00:16:19,110 --> 00:16:23,250
or female so if you look at over here

00:16:20,880 --> 00:16:25,740
it's basically saying that if I am

00:16:23,250 --> 00:16:27,810
looking at protected attribute sex right

00:16:25,740 --> 00:16:30,390
you know everything is PT okay in the

00:16:27,810 --> 00:16:34,020
data set is fear right but if I'm

00:16:30,390 --> 00:16:38,090
looking at age right in this case what

00:16:34,020 --> 00:16:41,160
you find is the data set is highly bias

00:16:38,090 --> 00:16:42,870
okay and this is not a rocket science

00:16:41,160 --> 00:16:45,720
you know means say you know people

00:16:42,870 --> 00:16:50,940
figured out very easily why can anyone

00:16:45,720 --> 00:16:52,710
tell me why why the data so this was

00:16:50,940 --> 00:16:55,920
actually based on real data set right in

00:16:52,710 --> 00:16:57,900
the 22 score of lot of people in Germany

00:16:55,920 --> 00:17:01,400
over a period of time and they found

00:16:57,900 --> 00:17:07,079
that the data set was bias against age

00:17:01,400 --> 00:17:09,150
why exactly right because lot of you

00:17:07,079 --> 00:17:11,520
know young people were applying for the

00:17:09,150 --> 00:17:14,100
credit card and this is the data you

00:17:11,520 --> 00:17:16,470
know they had in sorry other way not a

00:17:14,100 --> 00:17:18,030
lot of young people were applying right

00:17:16,470 --> 00:17:20,040
because most

00:17:18,030 --> 00:17:22,140
time by the time you make money you know

00:17:20,040 --> 00:17:24,720
10 years back you already into a certain

00:17:22,140 --> 00:17:29,480
age group so this is why it soars bias

00:17:24,720 --> 00:17:32,700
against you know younger population okay

00:17:29,480 --> 00:17:34,920
so now we know that okay there's some

00:17:32,700 --> 00:17:37,110
bias over here how do we mitigate the

00:17:34,920 --> 00:17:40,020
bias so this is where you know you go to

00:17:37,110 --> 00:17:44,040
this next process okay you can check

00:17:40,020 --> 00:17:46,110
some of those okay now I have a

00:17:44,040 --> 00:17:48,330
different bias mitigation algorithms

00:17:46,110 --> 00:17:50,790
over here I can look at you know which a

00:17:48,330 --> 00:17:53,880
bias mitigation algorithm I'll be using

00:17:50,790 --> 00:17:55,170
it right one of the simple thing is V

00:17:53,880 --> 00:17:57,980
weighting right

00:17:55,170 --> 00:18:02,370
that basically means okay earlier if

00:17:57,980 --> 00:18:05,370
your age was you know 30 to 35 I was

00:18:02,370 --> 00:18:08,730
giving you this graph let's say five now

00:18:05,370 --> 00:18:10,560
I'm making it maybe a bit lower right a

00:18:08,730 --> 00:18:12,780
bit higher depends on the use case right

00:18:10,560 --> 00:18:16,110
so but that basically means I have those

00:18:12,780 --> 00:18:19,320
ten attributes which identify our result

00:18:16,110 --> 00:18:22,680
and I'm rewriting them okay so that my

00:18:19,320 --> 00:18:25,290
data becomes much generalized and it

00:18:22,680 --> 00:18:27,480
supports every age group okay so that's

00:18:25,290 --> 00:18:29,160
what you know you can do as well now if

00:18:27,480 --> 00:18:31,710
you do manually you have to prepare the

00:18:29,160 --> 00:18:33,510
data sets in this case what happens is I

00:18:31,710 --> 00:18:38,100
take the data sets I pick up the

00:18:33,510 --> 00:18:41,610
algorithm and the AI F 360 helps you to

00:18:38,100 --> 00:18:43,260
generate the new data sets for you okay

00:18:41,610 --> 00:18:43,500
it will take some time you know to do

00:18:43,260 --> 00:18:46,140
that

00:18:43,500 --> 00:18:47,930
and this is basically saying that you

00:18:46,140 --> 00:18:51,090
know you give have a certain set of data

00:18:47,930 --> 00:18:53,490
you check if there is a bias on certain

00:18:51,090 --> 00:18:55,230
protected group and if you find the bias

00:18:53,490 --> 00:18:57,690
you run through the next set of

00:18:55,230 --> 00:19:00,900
algorithms which mitigates and give you

00:18:57,690 --> 00:19:03,420
a new set of data and this data this new

00:19:00,900 --> 00:19:07,800
set of data is good for building your

00:19:03,420 --> 00:19:10,050
algorithm okay so very you know strong

00:19:07,800 --> 00:19:12,000
and very powerful you know set of

00:19:10,050 --> 00:19:14,850
algorithms over here it makes your job

00:19:12,000 --> 00:19:16,590
much easier instead of you trying to you

00:19:14,850 --> 00:19:18,570
know change manually the data and a lot

00:19:16,590 --> 00:19:21,120
of time it happens right if you look at

00:19:18,570 --> 00:19:23,610
you know even when people are machine

00:19:21,120 --> 00:19:25,860
learning was not popular people say say

00:19:23,610 --> 00:19:27,900
statistical analysis there the sampling

00:19:25,860 --> 00:19:29,880
was very important okay and they were

00:19:27,900 --> 00:19:31,950
trying to take the right set of data for

00:19:29,880 --> 00:19:34,559
the sampling right here

00:19:31,950 --> 00:19:36,270
you're doing the same but what are you

00:19:34,559 --> 00:19:38,250
doing is you know if you need to make

00:19:36,270 --> 00:19:40,080
some modification in the data sets for

00:19:38,250 --> 00:19:43,770
making sure that your algorithm is not

00:19:40,080 --> 00:19:46,110
biased we are doing that as well okay so

00:19:43,770 --> 00:19:48,360
now once I have a new set of data you

00:19:46,110 --> 00:19:52,080
can see that you know you can compare

00:19:48,360 --> 00:19:53,820
right I'm not going to the this part I

00:19:52,080 --> 00:19:56,850
look at the each part because this was

00:19:53,820 --> 00:19:59,070
where the bias was and you know if you

00:19:56,850 --> 00:20:02,790
look at even after certain changes I'm

00:19:59,070 --> 00:20:04,950
still seeing some biases okay so what I

00:20:02,790 --> 00:20:07,320
can do is I can go back at a different

00:20:04,950 --> 00:20:09,450
algorithm so rebating is not helping me

00:20:07,320 --> 00:20:12,210
okay so I'll go back and pick the other

00:20:09,450 --> 00:20:15,809
algorithm and go through that when I see

00:20:12,210 --> 00:20:18,179
that this bias is removed or very close

00:20:15,809 --> 00:20:20,370
because it's not possible to have a

00:20:18,179 --> 00:20:22,260
perfect world okay you're never going to

00:20:20,370 --> 00:20:24,720
have an algorithm will be just perfect

00:20:22,260 --> 00:20:26,010
right you'll always have some issues but

00:20:24,720 --> 00:20:30,960
we are trying to make sure you close

00:20:26,010 --> 00:20:32,790
come as close as possible okay I'll pass

00:20:30,960 --> 00:20:35,000
over here for a moment any question on

00:20:32,790 --> 00:20:35,000
this

00:20:48,370 --> 00:20:53,659
so we're creating a new copy of the data

00:20:50,899 --> 00:20:57,590
set right and we are really changing the

00:20:53,659 --> 00:20:59,059
weight okay so different algorithm does

00:20:57,590 --> 00:21:11,510
this in case of rewriting we are

00:20:59,059 --> 00:21:13,070
changing the weight yeah so that

00:21:11,510 --> 00:21:15,860
basically also means let's say you know

00:21:13,070 --> 00:21:18,070
I if I had like type records right I'll

00:21:15,860 --> 00:21:19,309
introduce you know ten dummy records

00:21:18,070 --> 00:21:21,289
right

00:21:19,309 --> 00:21:22,580
so that will automatically you know when

00:21:21,289 --> 00:21:24,740
you are doing your analysis right

00:21:22,580 --> 00:21:26,750
because you have more record of such

00:21:24,740 --> 00:21:34,309
type your weight will change that's what

00:21:26,750 --> 00:21:36,500
it means you can say that you know some

00:21:34,309 --> 00:21:37,940
means it's similar approach right but

00:21:36,500 --> 00:21:41,149
what are you doing is we are looking

00:21:37,940 --> 00:21:42,980
more from a data bias perspective like

00:21:41,149 --> 00:21:44,390
the other you know objective is

00:21:42,980 --> 00:21:48,010
different right here we are trying to

00:21:44,390 --> 00:21:48,010
look more from the biased perspective

00:21:54,920 --> 00:22:03,540
right from the existing record set yeah

00:22:02,160 --> 00:22:05,010
you can look at you know so that's why

00:22:03,540 --> 00:22:06,870
you know I said this is open source the

00:22:05,010 --> 00:22:09,330
data set is open source the algorithms

00:22:06,870 --> 00:22:12,300
are all open source you can try yourself

00:22:09,330 --> 00:22:20,580
right and just bookmark this AI F 360

00:22:12,300 --> 00:22:22,470
dot my bluemix.net okay let's go back to

00:22:20,580 --> 00:22:24,300
the other part of the agenda so this was

00:22:22,470 --> 00:22:26,550
like proactively trying to clean up your

00:22:24,300 --> 00:22:28,590
data now let's say you know I build the

00:22:26,550 --> 00:22:31,860
algorithms now I put up in a production

00:22:28,590 --> 00:22:33,870
what else I can do okay so I went

00:22:31,860 --> 00:22:36,090
through this now for the second part

00:22:33,870 --> 00:22:38,250
right where we talked about you build a

00:22:36,090 --> 00:22:39,870
model right you put it in the production

00:22:38,250 --> 00:22:42,720
you deployed the model you want to check

00:22:39,870 --> 00:22:44,430
for the biases for that purpose I bi

00:22:42,720 --> 00:22:47,430
like to introduce you know our

00:22:44,430 --> 00:22:51,420
technology what we call as open is scale

00:22:47,430 --> 00:22:53,610
AI okay and this is a technology B which

00:22:51,420 --> 00:22:55,020
we in you know is a product actually

00:22:53,610 --> 00:22:57,150
which is available on the cloud and

00:22:55,020 --> 00:22:59,040
on-premise well okay that basically

00:22:57,150 --> 00:23:02,430
means you can do with your secure set of

00:22:59,040 --> 00:23:05,310
data as well and the concept over here

00:23:02,430 --> 00:23:08,130
is you build your model you deploy and

00:23:05,310 --> 00:23:10,560
your model and after deploying the model

00:23:08,130 --> 00:23:12,720
you decide what are the protected

00:23:10,560 --> 00:23:15,480
attributes what are the unprotected

00:23:12,720 --> 00:23:17,520
attributes and based on the result based

00:23:15,480 --> 00:23:20,520
on the outcome it will continuously

00:23:17,520 --> 00:23:24,600
monitor your model and tell you about

00:23:20,520 --> 00:23:27,030
any kind of biases now it doesn't just

00:23:24,600 --> 00:23:31,200
you know do the monitoring but also it

00:23:27,030 --> 00:23:32,940
gives you a kind of I will say insight

00:23:31,200 --> 00:23:35,030
which is helpful in a production

00:23:32,940 --> 00:23:37,770
environment so you can set a threshold

00:23:35,030 --> 00:23:40,740
right so for example I can say that okay

00:23:37,770 --> 00:23:44,580
if the bias on this let's say each group

00:23:40,740 --> 00:23:46,470
becomes you know goes beyond 80% right

00:23:44,580 --> 00:23:49,680
then send me an alert or I stop this

00:23:46,470 --> 00:23:52,020
model for running further right that is

00:23:49,680 --> 00:23:55,370
very important so you you can put those

00:23:52,020 --> 00:23:58,320
threshold over here as well okay so

00:23:55,370 --> 00:24:00,870
apart from the model you know the bias

00:23:58,320 --> 00:24:03,020
part it also is giving you another

00:24:00,870 --> 00:24:05,940
important of trust which is a lineage

00:24:03,020 --> 00:24:08,350
okay so what we mean by lineage is like

00:24:05,940 --> 00:24:10,750
when you do a prediction

00:24:08,350 --> 00:24:12,370
there may be you know 20 different data

00:24:10,750 --> 00:24:14,770
elements which you pass to do the

00:24:12,370 --> 00:24:17,440
prediction but what was those two data

00:24:14,770 --> 00:24:19,540
element which was most important for the

00:24:17,440 --> 00:24:21,910
algorithm to make decision it will show

00:24:19,540 --> 00:24:23,470
you that as well okay so normally if

00:24:21,910 --> 00:24:26,260
you're doing you know algorithms like

00:24:23,470 --> 00:24:28,660
this entry another it automatically

00:24:26,260 --> 00:24:29,170
shows you right but those I meant you

00:24:28,660 --> 00:24:32,260
know further

00:24:29,170 --> 00:24:35,740
guy who is building the model itself

00:24:32,260 --> 00:24:38,920
this is something we are targeting also

00:24:35,740 --> 00:24:41,620
for the guys were consuming it okay so

00:24:38,920 --> 00:24:44,620
what I mean is you see a credit risk and

00:24:41,620 --> 00:24:48,850
you want to know how this credit risk

00:24:44,620 --> 00:24:50,350
was applied right and this is where you

00:24:48,850 --> 00:24:52,570
know today it's not happening but you

00:24:50,350 --> 00:24:55,390
know going forward we see this future

00:24:52,570 --> 00:24:57,730
where you can very much ask right the

00:24:55,390 --> 00:25:00,430
bank okay you came up like you I will I

00:24:57,730 --> 00:25:04,000
requested for a loan of this amount you

00:25:00,430 --> 00:25:05,920
give me only this why okay because the

00:25:04,000 --> 00:25:07,450
decision will be made by machine they

00:25:05,920 --> 00:25:09,370
need to justify through the machine

00:25:07,450 --> 00:25:11,440
right and this is where the openness

00:25:09,370 --> 00:25:13,900
skill will actually give you a pretty

00:25:11,440 --> 00:25:16,900
good idea like you had these three

00:25:13,900 --> 00:25:18,580
things maybe your last loan was rejected

00:25:16,900 --> 00:25:20,950
and that's why your credit score goes

00:25:18,580 --> 00:25:23,560
down and this is why this is your scope

00:25:20,950 --> 00:25:25,500
okay so that's what you know it does so

00:25:23,560 --> 00:25:29,650
two things one is the lineage one is

00:25:25,500 --> 00:25:32,980
giving you the you know the bias reports

00:25:29,650 --> 00:25:34,660
and mitigating the bias report now how

00:25:32,980 --> 00:25:36,640
do you do that like let's say you want

00:25:34,660 --> 00:25:39,580
to build such a things yourself how do

00:25:36,640 --> 00:25:42,490
we do that so there are two part three

00:25:39,580 --> 00:25:44,290
parts to this one is developing it so

00:25:42,490 --> 00:25:47,200
this is where we are going to probably

00:25:44,290 --> 00:25:50,410
have a tool called Watson studio okay

00:25:47,200 --> 00:25:51,970
and it specifically if you look at we're

00:25:50,410 --> 00:25:54,640
doing the DevOps process for a data

00:25:51,970 --> 00:25:57,610
science and AI it's all about you know

00:25:54,640 --> 00:26:01,120
open source okay so here we built our

00:25:57,610 --> 00:26:03,550
platform using open source right and

00:26:01,120 --> 00:26:05,140
this is like in a hole like if you're

00:26:03,550 --> 00:26:06,910
looking for Python you know you're

00:26:05,140 --> 00:26:09,340
looking at anaconda packages whether

00:26:06,910 --> 00:26:13,540
you're looking at tensor flow you know

00:26:09,340 --> 00:26:15,700
more than 75 different you know AI

00:26:13,540 --> 00:26:17,860
framework the machine learning framework

00:26:15,700 --> 00:26:19,570
we embedded into this and we build a

00:26:17,860 --> 00:26:22,029
development process where you can

00:26:19,570 --> 00:26:24,519
actually build the code using your fair

00:26:22,029 --> 00:26:26,559
- so whether you are using our whether

00:26:24,519 --> 00:26:28,499
you're using a Jupiter notebook or

00:26:26,559 --> 00:26:33,249
whether you're using our studio right

00:26:28,499 --> 00:26:35,229
Chaplin okay you know you can use this

00:26:33,249 --> 00:26:37,119
to build the code so once you build the

00:26:35,229 --> 00:26:39,609
code the next part is how do I do the

00:26:37,119 --> 00:26:41,259
deployment into the production and this

00:26:39,609 --> 00:26:43,719
is where we have something called Watson

00:26:41,259 --> 00:26:47,919
machine learning this is a platform for

00:26:43,719 --> 00:26:49,539
you to deploy your model okay building

00:26:47,919 --> 00:26:52,119
the model you can build through the

00:26:49,539 --> 00:26:54,099
watson studio or even some other tools

00:26:52,119 --> 00:26:56,859
like for example if you're using SAS or

00:26:54,099 --> 00:26:59,139
if you're using you know maybe you know

00:26:56,859 --> 00:27:02,289
just your notebook on your laptop right

00:26:59,139 --> 00:27:04,389
to build the model that's perfectly fine

00:27:02,289 --> 00:27:06,460
when you have to deploy the model you

00:27:04,389 --> 00:27:08,889
want to deploy in a way it is scaleable

00:27:06,460 --> 00:27:11,080
it is easy to consume by the application

00:27:08,889 --> 00:27:13,359
so when you deploy the model in Watson

00:27:11,080 --> 00:27:16,899
machine learning two things is happening

00:27:13,359 --> 00:27:19,239
one a very secure way of assessing your

00:27:16,899 --> 00:27:21,219
model so what we do is we provide you

00:27:19,239 --> 00:27:23,950
the REST API for anything which is

00:27:21,219 --> 00:27:25,570
deployed over here that means as soon as

00:27:23,950 --> 00:27:26,649
you deploy the model over here it's

00:27:25,570 --> 00:27:28,509
ready for consumption

00:27:26,649 --> 00:27:31,299
okay so anybody you know from your

00:27:28,509 --> 00:27:34,089
mobile apps from your IOT applications

00:27:31,299 --> 00:27:35,799
right you can consume those model in a

00:27:34,089 --> 00:27:37,659
very secure way so we have this

00:27:35,799 --> 00:27:41,320
authentication mechanism another thing

00:27:37,659 --> 00:27:43,749
all built in what it means it's this is

00:27:41,320 --> 00:27:46,450
very important what it mean is from your

00:27:43,749 --> 00:27:50,589
built to deploy it's just a matter of

00:27:46,450 --> 00:27:53,830
few hours okay till now the built to

00:27:50,589 --> 00:27:59,830
deploy was a matter of at least a couple

00:27:53,830 --> 00:28:08,900
of weeks why anyone over here why the

00:27:59,830 --> 00:28:16,110
bill to deploy is a big challenge okay

00:28:08,900 --> 00:28:18,419
using something okay so you got a spot

00:28:16,110 --> 00:28:19,919
on right so basically if you look at you

00:28:18,419 --> 00:28:24,059
know when I am building this models

00:28:19,919 --> 00:28:25,770
right you know I will be using different

00:28:24,059 --> 00:28:28,140
kind of library when I am building on my

00:28:25,770 --> 00:28:30,900
laptop right I have like you know Python

00:28:28,140 --> 00:28:33,990
2.7 is still on my Mac and I build using

00:28:30,900 --> 00:28:36,179
that right when I'm doing it into the

00:28:33,990 --> 00:28:37,909
production what happened is that machine

00:28:36,179 --> 00:28:41,039
may not have the same sort of library

00:28:37,909 --> 00:28:43,530
right then what do you do you try to

00:28:41,039 --> 00:28:44,970
figure out the library right and a lot

00:28:43,530 --> 00:28:47,010
of times it's happens that the code

00:28:44,970 --> 00:28:49,559
which you wrote for one package is not

00:28:47,010 --> 00:28:51,419
available into other package and in open

00:28:49,559 --> 00:28:53,820
source it's happening every day right

00:28:51,419 --> 00:28:57,299
you know I all my code in Python 2.7

00:28:53,820 --> 00:29:00,240
doesn't work in Python 3.7 writes a big

00:28:57,299 --> 00:29:02,280
change so what we do is we use this

00:29:00,240 --> 00:29:04,320
concept of you know we had this creative

00:29:02,280 --> 00:29:06,539
session right and most of you were here

00:29:04,320 --> 00:29:09,690
you understand the concept of docker

00:29:06,539 --> 00:29:12,090
right so we are using the same concept

00:29:09,690 --> 00:29:15,330
over here so when you're building this

00:29:12,090 --> 00:29:17,159
library over here instead of you know

00:29:15,330 --> 00:29:19,110
giving you the code on your host machine

00:29:17,159 --> 00:29:21,419
itself we provide that as a

00:29:19,110 --> 00:29:23,039
containerized image that means you know

00:29:21,419 --> 00:29:25,230
it gives you flexibility to build a

00:29:23,039 --> 00:29:27,750
model using different version right and

00:29:25,230 --> 00:29:29,510
in one tool you have different

00:29:27,750 --> 00:29:33,090
environments so I can have you know

00:29:29,510 --> 00:29:36,570
spark you know to spark 1.6 if you had

00:29:33,090 --> 00:29:38,159
some old codes as well right all in a

00:29:36,570 --> 00:29:40,260
single environment and when you're

00:29:38,159 --> 00:29:40,559
building going to the deployment part of

00:29:40,260 --> 00:29:43,380
it

00:29:40,559 --> 00:29:45,840
I can use the same container to deploy

00:29:43,380 --> 00:29:47,520
it over here ok and you don't have to do

00:29:45,840 --> 00:29:49,500
anything manually automatically as soon

00:29:47,520 --> 00:29:51,299
as you do the deployment the containers

00:29:49,500 --> 00:29:53,730
are pushed to the production machine and

00:29:51,299 --> 00:29:56,820
you are all set to go and that's what I

00:29:53,730 --> 00:29:58,380
am saying you know from few weeks three

00:29:56,820 --> 00:30:00,450
to four weeks depends on the maturity

00:29:58,380 --> 00:30:03,720
some people may take three month as well

00:30:00,450 --> 00:30:06,150
right here we are doing the development

00:30:03,720 --> 00:30:10,130
to production in just a matter of few

00:30:06,150 --> 00:30:10,130
hours yeah

00:30:18,020 --> 00:30:22,470
yes it does allow you because you know

00:30:20,970 --> 00:30:24,840
even though we provide you like

00:30:22,470 --> 00:30:26,790
pre-built containers five six containers

00:30:24,840 --> 00:30:28,170
but that's not good enough right you

00:30:26,790 --> 00:30:30,660
know someone may come up with some new

00:30:28,170 --> 00:30:32,940
set of algorithms right today only I saw

00:30:30,660 --> 00:30:36,180
a one of our research team built an

00:30:32,940 --> 00:30:37,740
algorithm which basically fast you know

00:30:36,180 --> 00:30:40,170
track like the performance of your

00:30:37,740 --> 00:30:42,240
normal logistic regression increases by

00:30:40,170 --> 00:30:44,370
forty five times and that's their

00:30:42,240 --> 00:30:46,590
proprietary algorithms but they want to

00:30:44,370 --> 00:30:48,270
develop on this platform so they can

00:30:46,590 --> 00:30:50,910
containerize it so what we do is we

00:30:48,270 --> 00:30:53,010
provide our toolkit okay so you can

00:30:50,910 --> 00:30:55,770
download the existing environment we

00:30:53,010 --> 00:30:58,560
have right and you can modify it push it

00:30:55,770 --> 00:31:01,830
back over here okay so you can very much

00:30:58,560 --> 00:31:03,840
bring your own environment okay so that

00:31:01,830 --> 00:31:05,460
helps you to do the production part once

00:31:03,840 --> 00:31:07,650
the production is done right you know

00:31:05,460 --> 00:31:09,360
the next part is the monitoring thing

00:31:07,650 --> 00:31:10,410
and this is where the openness skills

00:31:09,360 --> 00:31:13,320
comes into the picture

00:31:10,410 --> 00:31:15,240
right and this as I mentioned earlier we

00:31:13,320 --> 00:31:16,740
are talking about bias right which is

00:31:15,240 --> 00:31:18,180
the fairness part of it then we are

00:31:16,740 --> 00:31:20,790
talking about lineage which is the

00:31:18,180 --> 00:31:22,830
explained ability part of it apart from

00:31:20,790 --> 00:31:25,710
that it also looked at the model health

00:31:22,830 --> 00:31:27,210
the model accuracy right and also the

00:31:25,710 --> 00:31:29,250
performance as well let's say for

00:31:27,210 --> 00:31:31,830
example or ten thousand people said

00:31:29,250 --> 00:31:33,240
earlier start hitting your API right of

00:31:31,830 --> 00:31:35,040
course the response time will get is

00:31:33,240 --> 00:31:36,840
slow it will tell you you know whether

00:31:35,040 --> 00:31:39,450
the response response time is a slowing

00:31:36,840 --> 00:31:41,070
or missing the best thing is based on

00:31:39,450 --> 00:31:43,530
the feedback so today you have ten

00:31:41,070 --> 00:31:44,910
thousand you know concurrent users

00:31:43,530 --> 00:31:47,460
suddenly it become a million concurrent

00:31:44,910 --> 00:31:49,050
user because we're using the container

00:31:47,460 --> 00:31:51,240
technology to deploy over here

00:31:49,050 --> 00:31:53,640
automatically it will scale more

00:31:51,240 --> 00:31:58,020
containers and it will take care of your

00:31:53,640 --> 00:32:01,320
workload as well okay so that's why you

00:31:58,020 --> 00:32:04,440
know the build deploy and monitor right

00:32:01,320 --> 00:32:05,850
so we are providing this with a set of

00:32:04,440 --> 00:32:10,170
tools to you and these are the tools

00:32:05,850 --> 00:32:12,750
we'll be using in the lab as well okay a

00:32:10,170 --> 00:32:14,910
bit more amount of you know this

00:32:12,750 --> 00:32:18,660
openness scale and then I'll move to the

00:32:14,910 --> 00:32:21,690
lab part of it so as I mentioned over

00:32:18,660 --> 00:32:23,850
here it you know it's doing your model

00:32:21,690 --> 00:32:26,130
explain ability right

00:32:23,850 --> 00:32:27,480
one important thing is to use the

00:32:26,130 --> 00:32:30,690
openness scale it doesn't mean you have

00:32:27,480 --> 00:32:32,909
to deploy it on IBM Watson machine

00:32:30,690 --> 00:32:35,039
learning itself you may have deployed on

00:32:32,909 --> 00:32:37,350
like let's say what about the existing

00:32:35,039 --> 00:32:40,049
deployment so if you have some existing

00:32:37,350 --> 00:32:42,570
deployment open a skill can connect even

00:32:40,049 --> 00:32:44,909
to that okay and we do two-way I don't

00:32:42,570 --> 00:32:47,610
you give us the locks or either you give

00:32:44,909 --> 00:32:49,530
us the URL okay so if you have deployed

00:32:47,610 --> 00:32:51,780
it there will be an endpoint URL if you

00:32:49,530 --> 00:32:54,299
give us the endpoint URL we can connect

00:32:51,780 --> 00:32:55,230
and start monitoring those algorithms of

00:32:54,299 --> 00:32:57,990
course there are certain limitations

00:32:55,230 --> 00:32:59,549
right because normally you know those

00:32:57,990 --> 00:33:01,620
kind of bias and other things work

00:32:59,549 --> 00:33:04,289
pretty much well with logistic

00:33:01,620 --> 00:33:05,909
regressions kind of algorithms and some

00:33:04,289 --> 00:33:08,940
of the things I talked about like this

00:33:05,909 --> 00:33:11,370
isn't we we are building up to match

00:33:08,940 --> 00:33:13,679
this means basically generalize it to

00:33:11,370 --> 00:33:15,330
more common algorithms as well but right

00:33:13,679 --> 00:33:18,090
now you know when you're using it it

00:33:15,330 --> 00:33:27,600
supports the 70% of the algorithms which

00:33:18,090 --> 00:33:29,460
I talked about yeah yes so kidman you

00:33:27,600 --> 00:33:35,850
know just put his laptop aside so I let

00:33:29,460 --> 00:33:37,919
him answer okay so we have this you know

00:33:35,850 --> 00:33:40,110
whatever you have over here we have a

00:33:37,919 --> 00:33:42,659
solution which we call as IBM cloud

00:33:40,110 --> 00:33:45,360
private for data okay which is like a

00:33:42,659 --> 00:33:47,429
our container technology we along with

00:33:45,360 --> 00:33:49,350
the applications the data and AI

00:33:47,429 --> 00:33:51,480
applications all bundled together and

00:33:49,350 --> 00:33:54,750
that you can deploy anywhere you can

00:33:51,480 --> 00:33:57,150
deploy on your you know data center you

00:33:54,750 --> 00:34:02,150
can deploy on Google Cloud Microsoft you

00:33:57,150 --> 00:34:02,150
know anywhere right so the answer is yes

00:34:03,980 --> 00:34:09,690
okay so apart from you know the open

00:34:07,860 --> 00:34:11,909
scale the other technology right and

00:34:09,690 --> 00:34:13,320
this is where I in I talked about you

00:34:11,909 --> 00:34:15,929
know deep learning in the beginning I

00:34:13,320 --> 00:34:17,609
just wanted to close on to that so deep

00:34:15,929 --> 00:34:19,679
learning if you look at the most common

00:34:17,609 --> 00:34:21,960
you use kiss for that is around two

00:34:19,679 --> 00:34:24,060
things one is among basically picture

00:34:21,960 --> 00:34:27,139
classifications and the other is around

00:34:24,060 --> 00:34:28,320
natural language right understanding so

00:34:27,139 --> 00:34:30,720
tensorflow

00:34:28,320 --> 00:34:34,139
you know how many of you heard about

00:34:30,720 --> 00:34:35,700
tensor flow most of your heart right so

00:34:34,139 --> 00:34:37,110
has been a common way and if you are

00:34:35,700 --> 00:34:39,090
doing the stuff right you know

00:34:37,110 --> 00:34:40,140
it takes a bit of effort to do some

00:34:39,090 --> 00:34:42,570
coding over here

00:34:40,140 --> 00:34:44,520
there right and then you can build a

00:34:42,570 --> 00:34:46,500
model the first thing very easily but if

00:34:44,520 --> 00:34:48,780
you have to really get to a label where

00:34:46,500 --> 00:34:52,320
the algorithm is very accurate it takes

00:34:48,780 --> 00:34:55,100
a lot more effort so to simplify that we

00:34:52,320 --> 00:34:58,140
came with something we call AI for AI

00:34:55,100 --> 00:35:00,600
okay and kidman is giving a talk later

00:34:58,140 --> 00:35:05,010
today at 2 o'clock I think which is

00:35:00,600 --> 00:35:08,070
about will AI take over developers right

00:35:05,010 --> 00:35:10,290
this is like you know just a preliminary

00:35:08,070 --> 00:35:12,480
stuff around that you know what here we

00:35:10,290 --> 00:35:15,150
are talking about is here we have a tool

00:35:12,480 --> 00:35:17,550
where you give an image right and it

00:35:15,150 --> 00:35:20,400
automatically built the whole new let

00:35:17,550 --> 00:35:22,800
work for you okay of course you know

00:35:20,400 --> 00:35:25,770
when machine is doing and also this is

00:35:22,800 --> 00:35:29,250
just we just got it started right so

00:35:25,770 --> 00:35:31,050
don't expect magic right but you know

00:35:29,250 --> 00:35:32,580
this is doing pretty good job like if

00:35:31,050 --> 00:35:35,880
you give I tried with some natural

00:35:32,580 --> 00:35:38,460
language classifier and if you give like

00:35:35,880 --> 00:35:40,560
a set of text and say you know classify

00:35:38,460 --> 00:35:42,960
as a positive negative or classify based

00:35:40,560 --> 00:35:45,150
on the sentiment right you know you can

00:35:42,960 --> 00:35:46,940
get to outcome in you know like maybe an

00:35:45,150 --> 00:35:49,050
hour or something you will be all set

00:35:46,940 --> 00:35:50,570
whereas you you'll have to build the

00:35:49,050 --> 00:35:54,330
code you know it may take some more time

00:35:50,570 --> 00:35:57,000
so that's an unit and in the lab you're

00:35:54,330 --> 00:35:58,830
going to talk about that as well so that

00:35:57,000 --> 00:36:00,450
was my chart let's go to the hands-on

00:35:58,830 --> 00:36:04,080
workshop what we are going to do on the

00:36:00,450 --> 00:36:06,510
hands-on workshop so this is our

00:36:04,080 --> 00:36:08,940
scenario right so let's assume that we

00:36:06,510 --> 00:36:11,400
are a credit card we are going to do the

00:36:08,940 --> 00:36:13,800
same thing like a credit risk analysis

00:36:11,400 --> 00:36:15,810
for that I'm using the same data set

00:36:13,800 --> 00:36:18,060
which I showed you earlier so we have

00:36:15,810 --> 00:36:20,190
certain population data from the past

00:36:18,060 --> 00:36:22,170
where it automatically classified

00:36:20,190 --> 00:36:24,450
whether this guys are what is the credit

00:36:22,170 --> 00:36:27,270
risk for them okay so we are going to

00:36:24,450 --> 00:36:31,620
use that data and based on that we are

00:36:27,270 --> 00:36:34,500
going to create a risk model okay and on

00:36:31,620 --> 00:36:37,170
this risk model we will deploy our open

00:36:34,500 --> 00:36:41,100
scale to figure out right if there is

00:36:37,170 --> 00:36:43,260
any kind of bias okay we are not going

00:36:41,100 --> 00:36:45,330
through the AI F 360 where we were

00:36:43,260 --> 00:36:47,850
mitigating the bias okay here we'll

00:36:45,330 --> 00:36:51,420
build it just deploy it and then look

00:36:47,850 --> 00:36:53,670
for if there is any bias okay so will be

00:36:51,420 --> 00:36:59,970
doing mostly on to the monitoring part

00:36:53,670 --> 00:37:02,309
of the bias so how does this work so we

00:36:59,970 --> 00:37:04,380
are going to use you know okay let me go

00:37:02,309 --> 00:37:07,369
back over here first so we are going to

00:37:04,380 --> 00:37:10,230
use this for tools one is you know

00:37:07,369 --> 00:37:12,210
Watson machine learning which will be

00:37:10,230 --> 00:37:14,490
basically used for the deployment of the

00:37:12,210 --> 00:37:16,710
model open is skill for the monitoring

00:37:14,490 --> 00:37:19,200
part and in the back end you know our

00:37:16,710 --> 00:37:20,819
data set is in a db2 warehouse and for

00:37:19,200 --> 00:37:24,809
processing purpose we are going to use

00:37:20,819 --> 00:37:26,369
apache spark okay if you you know most

00:37:24,809 --> 00:37:28,170
of the codes are like already there so

00:37:26,369 --> 00:37:30,119
if you are new just you know try to

00:37:28,170 --> 00:37:31,920
spend some time going through this stuff

00:37:30,119 --> 00:37:35,460
and you'll get it know how we are doing

00:37:31,920 --> 00:37:37,410
it we are using the this is openly

00:37:35,460 --> 00:37:39,960
available data set so why I'm bringing

00:37:37,410 --> 00:37:41,760
this you know just to give you an idea

00:37:39,960 --> 00:37:43,920
like we are not using anybody personal

00:37:41,760 --> 00:37:45,809
data this is open datasets what we have

00:37:43,920 --> 00:37:49,140
and we are using this open data sets for

00:37:45,809 --> 00:37:51,569
the algorithms okay and these are

00:37:49,140 --> 00:37:53,730
certain like data elements which are

00:37:51,569 --> 00:37:56,069
available over here which we'll be using

00:37:53,730 --> 00:37:58,950
to predict and in this case our

00:37:56,069 --> 00:38:01,770
protected group is going to be personal

00:37:58,950 --> 00:38:03,780
status and age on which we are going to

00:38:01,770 --> 00:38:08,640
do the prediction for which are going to

00:38:03,780 --> 00:38:10,920
monitor for the biases okay how things

00:38:08,640 --> 00:38:11,780
will work in production once the model

00:38:10,920 --> 00:38:15,089
is deployed

00:38:11,780 --> 00:38:16,559
there'll be requests right and this

00:38:15,089 --> 00:38:18,480
request goes to the Watson mercy

00:38:16,559 --> 00:38:20,640
learning where it is deployed and the

00:38:18,480 --> 00:38:22,859
eye-opener skill is going to look for

00:38:20,640 --> 00:38:25,440
you know that winning look for the

00:38:22,859 --> 00:38:27,809
biases and as I mentioned if it finds

00:38:25,440 --> 00:38:29,700
there is a bias or something which is

00:38:27,809 --> 00:38:31,950
happening over a period of time we can

00:38:29,700 --> 00:38:35,190
look at a new training data sets and try

00:38:31,950 --> 00:38:38,790
to re-evaluate our model so that the

00:38:35,190 --> 00:38:41,940
problem can be fixed okay with that I

00:38:38,790 --> 00:38:44,640
think we are all good to get a started

00:38:41,940 --> 00:38:47,010
okay so I need couple of things from you

00:38:44,640 --> 00:38:52,190
everybody connect to the internet using

00:38:47,010 --> 00:38:55,260
this Wi-Fi if you haven't done yet so

00:38:52,190 --> 00:39:00,950
this you want to join and do you want to

00:38:55,260 --> 00:39:00,950
walk them through the content okay

00:39:02,700 --> 00:39:10,810
okay so let them note this first and

00:39:08,320 --> 00:39:12,570
then I'll show you just note this guy's

00:39:10,810 --> 00:39:14,740
because I am going to show you another

00:39:12,570 --> 00:39:20,490
URL where you need to download some

00:39:14,740 --> 00:39:20,490
content let me know once you are done

00:39:29,170 --> 00:39:33,200
okay you guys are smart so 30 seconds

00:39:31,790 --> 00:39:37,120
should be good enough to note this down

00:39:33,200 --> 00:39:37,120
let me go to the other URL

00:39:51,849 --> 00:40:07,380
this was the one right

00:39:54,740 --> 00:40:18,380
you give me that shortcut okay ready to

00:40:07,380 --> 00:40:18,380
give me on what's a very copied or not

00:40:23,090 --> 00:40:29,060
okay I'm just noting it down over here

00:40:25,740 --> 00:40:29,060
so you can note it down yours

00:40:54,770 --> 00:41:09,490
but correct okay don't note it down let

00:40:59,240 --> 00:41:09,490
me just make sure that it works first oh

00:41:09,790 --> 00:41:33,740
it was as TT PS been taught ly all right

00:41:24,680 --> 00:41:35,570
this is correct all right so you know

00:41:33,740 --> 00:41:38,630
sorry I have to ask you to do a bit of

00:41:35,570 --> 00:41:41,570
work so I want you to put this on your

00:41:38,630 --> 00:41:44,180
browser okay and this will take you to a

00:41:41,570 --> 00:41:49,430
folder where you can download the

00:41:44,180 --> 00:41:52,520
content okay so so once you get to this

00:41:49,430 --> 00:41:56,380
URL on the top you'll find that you got

00:41:52,520 --> 00:41:59,210
certain datasets over here then we have

00:41:56,380 --> 00:42:00,830
two laps okay

00:41:59,210 --> 00:42:03,280
we will request you to start from the

00:42:00,830 --> 00:42:06,020
lab one look at the lab one basically

00:42:03,280 --> 00:42:08,020
you know goes through the building the

00:42:06,020 --> 00:42:10,460
model deploying to open a scale

00:42:08,020 --> 00:42:12,950
monitoring the model once you are done

00:42:10,460 --> 00:42:15,050
then you can go to the lab 2 which is

00:42:12,950 --> 00:42:21,830
about building a deep machine learning

00:42:15,050 --> 00:42:25,520
using the new nets okay the account

00:42:21,830 --> 00:42:28,070
information all there and though ok you

00:42:25,520 --> 00:42:30,859
want to go okay I'll ask you know while

00:42:28,070 --> 00:42:32,270
you do this right here I'll ask so

00:42:30,859 --> 00:42:34,460
there's two just to walk you through the

00:42:32,270 --> 00:42:41,390
steps how to get it started

00:42:34,460 --> 00:42:43,580
on to this yeah actually so so once you

00:42:41,390 --> 00:42:46,760
open the lab one right so you'll see

00:42:43,580 --> 00:42:50,210
there is a scenario that is given but in

00:42:46,760 --> 00:42:51,980
terms of practically doing it from the

00:42:50,210 --> 00:42:55,400
previous session you already have a

00:42:51,980 --> 00:42:58,670
registered IBM cloud account right so

00:42:55,400 --> 00:43:02,200
you go into that account right and you

00:42:58,670 --> 00:43:02,200
will see there is a catalog

00:43:14,170 --> 00:43:19,500
are you logged in to cloud are you

00:43:16,720 --> 00:43:19,500
logged in to the cloud

00:43:27,270 --> 00:43:34,330
so in the previous lab you didn't

00:43:30,550 --> 00:43:37,830
actually really create any any services

00:43:34,330 --> 00:43:39,730
right so whatever was given you just

00:43:37,830 --> 00:43:41,830
continue with the exercise because the

00:43:39,730 --> 00:43:43,570
clusters were already given in this lab

00:43:41,830 --> 00:43:47,020
you will be creating creating these

00:43:43,570 --> 00:43:49,270
services so you know once you go into

00:43:47,020 --> 00:43:51,880
the main catalog here you will see you

00:43:49,270 --> 00:43:54,460
have you know you have this whole IBM

00:43:51,880 --> 00:43:56,830
catalog right so what we are doing is

00:43:54,460 --> 00:43:59,890
for this exercise we are using some of

00:43:56,830 --> 00:44:02,560
the api's right so if you click on the

00:43:59,890 --> 00:44:04,870
AI tab right so you will see there's all

00:44:02,560 --> 00:44:06,340
these different api's so for example one

00:44:04,870 --> 00:44:08,020
of the one of the services that we are

00:44:06,340 --> 00:44:09,790
using in this lab is let's say the

00:44:08,020 --> 00:44:13,780
machine learning so you click on the

00:44:09,790 --> 00:44:16,060
machine learning this thing and then it

00:44:13,780 --> 00:44:18,790
will come up with some some name and you

00:44:16,060 --> 00:44:20,500
know some details about it so what you

00:44:18,790 --> 00:44:22,810
do is you choose you know the light

00:44:20,500 --> 00:44:26,080
version which is a free version for your

00:44:22,810 --> 00:44:28,420
account and then you just click a create

00:44:26,080 --> 00:44:30,760
button right so that will actually

00:44:28,420 --> 00:44:34,830
instantiate a machine learning service

00:44:30,760 --> 00:44:34,830
for you which is needed for the lab so

00:44:45,780 --> 00:44:55,890
okay so so one more thing so in your

00:44:51,480 --> 00:44:58,200
last in your last exercise some of you

00:44:55,890 --> 00:45:00,480
would have changed this account to IBM

00:44:58,200 --> 00:45:04,080
right you change it back to your name

00:45:00,480 --> 00:45:06,390
suppose you have logged in as ABC at you

00:45:04,080 --> 00:45:08,760
know yahoo.com you change that back to

00:45:06,390 --> 00:45:11,970
your account right because you may not

00:45:08,760 --> 00:45:13,650
have permissions in in the previous

00:45:11,970 --> 00:45:19,370
account to create services right so you

00:45:13,650 --> 00:45:19,370
change it back to your account sorry

00:46:03,180 --> 00:46:12,550
okay first thing everybody is able to

00:46:08,170 --> 00:46:15,820
download the PDF everybody is able to

00:46:12,550 --> 00:46:19,090
download the PDF right so once you have

00:46:15,820 --> 00:46:21,400
downloaded the PDF right so you make

00:46:19,090 --> 00:46:24,070
sure you the first step is you are able

00:46:21,400 --> 00:46:26,770
to login to the to the IBM cloud right

00:46:24,070 --> 00:46:28,780
so that's the next step so once you are

00:46:26,770 --> 00:46:31,180
there you'll see you need to you know

00:46:28,780 --> 00:46:32,680
create some of the services right so

00:46:31,180 --> 00:46:36,760
make sure you are in the right

00:46:32,680 --> 00:46:38,770
organization you know in your case it

00:46:36,760 --> 00:46:41,380
will just display your name here right

00:46:38,770 --> 00:46:43,660
or the email address once you are there

00:46:41,380 --> 00:46:47,560
you click on let's say the first thing

00:46:43,660 --> 00:46:49,210
is instantiate Watson Studio service so

00:46:47,560 --> 00:46:53,020
you see here there's a Watson Studio

00:46:49,210 --> 00:46:57,210
service you click here right it will

00:46:53,020 --> 00:47:00,310
come up with some name here and then

00:46:57,210 --> 00:47:01,630
make sure you're always in you know for

00:47:00,310 --> 00:47:07,840
this exercise make sure you're in

00:47:01,630 --> 00:47:09,960
Della's and then do you know and then

00:47:07,840 --> 00:47:15,160
once you have done you just say create

00:47:09,960 --> 00:47:18,400
right the same thing you do you create

00:47:15,160 --> 00:47:21,010
multiple instance you create multiple

00:47:18,400 --> 00:47:23,710
services Watson studio Watson machine

00:47:21,010 --> 00:47:25,330
learning Watson open scale just follow

00:47:23,710 --> 00:47:28,660
through the follow through the lab you

00:47:25,330 --> 00:47:31,120
should be able to get it through because

00:47:28,660 --> 00:47:33,040
there's no there's no code that is

00:47:31,120 --> 00:47:35,110
needed to be written here you just

00:47:33,040 --> 00:47:40,570
follow the scenario and then just

00:47:35,110 --> 00:47:42,610
progress okay a couple of you know

00:47:40,570 --> 00:47:43,960
common things what I'm saying most of

00:47:42,610 --> 00:47:45,870
you are going through so I'll just

00:47:43,960 --> 00:47:48,370
explain you know why it is happening

00:47:45,870 --> 00:47:51,100
some of the things you have to take care

00:47:48,370 --> 00:47:54,070
right while doing the lab the number one

00:47:51,100 --> 00:47:58,300
is you know I can't get the projector

00:47:54,070 --> 00:48:00,670
back but I'll talk through make sure

00:47:58,300 --> 00:48:01,330
that all your services are in the same

00:48:00,670 --> 00:48:03,520
zone

00:48:01,330 --> 00:48:05,920
okay so a lot of couple of guys I have

00:48:03,520 --> 00:48:08,140
seen when you're creating the services

00:48:05,920 --> 00:48:10,750
the three services make sure that they

00:48:08,140 --> 00:48:13,480
are in the same June yeah so that's one

00:48:10,750 --> 00:48:15,040
of the things so over here like if you

00:48:13,480 --> 00:48:18,280
look at I have the words on the stage

00:48:15,040 --> 00:48:22,210
you the other one which you need is the

00:48:18,280 --> 00:48:24,130
openness scale and the much you know the

00:48:22,210 --> 00:48:27,810
machine learning all the three services

00:48:24,130 --> 00:48:30,490
create in the same place okay right now

00:48:27,810 --> 00:48:32,410
you know we have this limitations where

00:48:30,490 --> 00:48:34,510
if you are running this open skill in a

00:48:32,410 --> 00:48:35,920
different zone you know we have some

00:48:34,510 --> 00:48:38,470
network issues and other things so

00:48:35,920 --> 00:48:41,080
you'll get some you know authorization

00:48:38,470 --> 00:48:42,850
or authentication kind of ever okay so

00:48:41,080 --> 00:48:46,990
to avoid that you know make sure that

00:48:42,850 --> 00:48:48,520
you it in the same zone so if you have

00:48:46,990 --> 00:48:50,770
done this by mistake like you know if

00:48:48,520 --> 00:48:53,620
you have gone to some other zone delete

00:48:50,770 --> 00:48:56,350
the services because you cannot get more

00:48:53,620 --> 00:48:57,790
than one services on the free account so

00:48:56,350 --> 00:49:01,330
it will not allow you to create you know

00:48:57,790 --> 00:49:03,460
multiple open scaler services so delete

00:49:01,330 --> 00:49:06,610
the old services create or new services

00:49:03,460 --> 00:49:09,130
and then you should be fine once you

00:49:06,610 --> 00:49:12,250
have done that the next step is you know

00:49:09,130 --> 00:49:15,270
the best way to can move quickly is go

00:49:12,250 --> 00:49:15,270
to your Watson studio

00:49:33,410 --> 00:49:41,850
okay and in Watson studio when you are

00:49:36,270 --> 00:49:43,410
creating the project first you need to

00:49:41,850 --> 00:49:45,450
make sure that you know you have linked

00:49:43,410 --> 00:49:47,700
Watson studio to the Watson

00:49:45,450 --> 00:49:50,580
machine-learning right and that you do

00:49:47,700 --> 00:49:52,830
by add it as a services so what you need

00:49:50,580 --> 00:49:54,960
to make sure that you you would be you

00:49:52,830 --> 00:49:56,490
know able to connect to your objective

00:49:54,960 --> 00:50:00,690
stories and the Watson machine learning

00:49:56,490 --> 00:50:02,160
services there the steps you know what

00:50:00,690 --> 00:50:04,320
we have given to you is like you know

00:50:02,160 --> 00:50:06,000
going through the different X experience

00:50:04,320 --> 00:50:08,720
but typically what you are doing is

00:50:06,000 --> 00:50:11,760
either you can build your own model or

00:50:08,720 --> 00:50:18,030
you can go over here and say new Watson

00:50:11,760 --> 00:50:20,010
machine learning model and when you do

00:50:18,030 --> 00:50:22,170
that you have the option to select from

00:50:20,010 --> 00:50:24,270
the sample so either you have your own

00:50:22,170 --> 00:50:26,340
model or you do it from the sample in

00:50:24,270 --> 00:50:28,260
this case the credit risk model is

00:50:26,340 --> 00:50:31,020
already there so all you have to do is

00:50:28,260 --> 00:50:32,760
pick where it risk as the model to be

00:50:31,020 --> 00:50:35,430
deployed okay

00:50:32,760 --> 00:50:38,190
give a name and that's all once the

00:50:35,430 --> 00:50:41,460
model is deployed you do the testing

00:50:38,190 --> 00:50:44,280
okay you got a REST API the JSON

00:50:41,460 --> 00:50:46,260
interface to test it typically that is

00:50:44,280 --> 00:50:48,650
given just for the testing purpose in

00:50:46,260 --> 00:50:51,110
real case you will be using that API and

00:50:48,650 --> 00:50:52,260
including your front-end application

00:50:51,110 --> 00:50:55,830
okay

00:50:52,260 --> 00:50:57,990
now once you do that when you are going

00:50:55,830 --> 00:51:00,600
back to your open scale configuration

00:50:57,990 --> 00:51:02,910
window there will be bit of latency and

00:51:00,600 --> 00:51:05,040
at this is very practical right because

00:51:02,910 --> 00:51:06,780
what is happening is these are two

00:51:05,040 --> 00:51:08,160
different services and you are trying to

00:51:06,780 --> 00:51:10,560
connect okay

00:51:08,160 --> 00:51:12,870
and the idea about monitoring is not

00:51:10,560 --> 00:51:15,690
like instantaneous right we are looking

00:51:12,870 --> 00:51:17,820
at the history of his bias based on the

00:51:15,690 --> 00:51:20,010
history of prediction so it doesn't need

00:51:17,820 --> 00:51:22,620
to be real-time that's a reason there is

00:51:20,010 --> 00:51:24,990
a latency over there the typical latency

00:51:22,620 --> 00:51:26,870
can be like an hour so if you go to the

00:51:24,990 --> 00:51:29,310
open scale it says that you know

00:51:26,870 --> 00:51:32,670
whatever prediction is available for

00:51:29,310 --> 00:51:35,250
only lasts one hour and the latency may

00:51:32,670 --> 00:51:36,930
be like you know five minutes okay so if

00:51:35,250 --> 00:51:38,490
you have done like a single prediction

00:51:36,930 --> 00:51:40,680
by the time it is available in open

00:51:38,490 --> 00:51:43,500
skill to monitor maybe about five

00:51:40,680 --> 00:51:46,520
minutes okay so there is no harm

00:51:43,500 --> 00:51:48,080
predicting it couple of times

00:51:46,520 --> 00:51:50,690
you can predict couple of times so that

00:51:48,080 --> 00:51:53,780
it has got more transaction in the open

00:51:50,690 --> 00:51:56,180
scale and once it is done then when you

00:51:53,780 --> 00:51:57,650
will come to the open scale right I am

00:51:56,180 --> 00:51:59,720
going to walk you through this interface

00:51:57,650 --> 00:52:03,080
because some of you were not able to go

00:51:59,720 --> 00:52:06,380
to this step and also considering that

00:52:03,080 --> 00:52:09,140
you know we are serving lunch at 120

00:52:06,380 --> 00:52:11,210
okay so I want you to quickly finish

00:52:09,140 --> 00:52:13,280
don't miss your lunch and then be ready

00:52:11,210 --> 00:52:16,400
for the next session this lapse you can

00:52:13,280 --> 00:52:18,170
also do later as well so let's go

00:52:16,400 --> 00:52:21,770
through this interface what this

00:52:18,170 --> 00:52:23,510
interface does so in this case the first

00:52:21,770 --> 00:52:25,610
step is you know if you look at you know

00:52:23,510 --> 00:52:28,550
here there are couple of a step one is

00:52:25,610 --> 00:52:30,950
like configuring the model itself okay

00:52:28,550 --> 00:52:33,560
in this case you know when you do the

00:52:30,950 --> 00:52:35,570
edit you'll pick up your existing Watson

00:52:33,560 --> 00:52:39,440
machine learning model whatever you have

00:52:35,570 --> 00:52:42,440
deployed and then you know you'll pick

00:52:39,440 --> 00:52:45,350
up right what is those bias columns you

00:52:42,440 --> 00:52:48,980
want to detect the bias okay once you

00:52:45,350 --> 00:52:51,530
have done this configuration one of the

00:52:48,980 --> 00:52:53,980
things you can also do over here or not

00:52:51,530 --> 00:52:53,980
the chat

00:53:05,290 --> 00:53:12,130
you click on that model once it is

00:53:07,240 --> 00:53:14,320
deployed and one of the things I

00:53:12,130 --> 00:53:16,630
typically do is because I want to see

00:53:14,320 --> 00:53:20,610
some more transactions right you have

00:53:16,630 --> 00:53:24,510
the option of you know add feedback data

00:53:20,610 --> 00:53:27,010
okay so you can give some feedback data

00:53:24,510 --> 00:53:29,140
over here so what it will do is it will

00:53:27,010 --> 00:53:30,640
do actually the testing on each one of

00:53:29,140 --> 00:53:33,010
them so it's like a batch of scoring

00:53:30,640 --> 00:53:34,570
okay and that gives you a lot more

00:53:33,010 --> 00:53:36,700
transactions so that you know when

00:53:34,570 --> 00:53:39,430
you're looking at the output in open

00:53:36,700 --> 00:53:40,900
skill it make more sense at least when

00:53:39,430 --> 00:53:43,330
you are doing the testing part of it so

00:53:40,900 --> 00:53:47,920
normally I'll put some feedback data

00:53:43,330 --> 00:53:50,560
over here let's go to the you know the

00:53:47,920 --> 00:53:52,150
interface itself so in this case my

00:53:50,560 --> 00:53:54,850
model is bit different than what you are

00:53:52,150 --> 00:53:56,050
trying to do your model was around risk

00:53:54,850 --> 00:53:58,780
right

00:53:56,050 --> 00:54:01,780
credit risk here I've got a model about

00:53:58,780 --> 00:54:04,390
drug test so basically in the scenario

00:54:01,780 --> 00:54:08,410
over here is I got a set of drugs called

00:54:04,390 --> 00:54:11,230
ABC right and the set of like disease

00:54:08,410 --> 00:54:14,170
and we are trying to figure out if my

00:54:11,230 --> 00:54:17,380
model is bias against a certain

00:54:14,170 --> 00:54:20,410
population right based on you know age

00:54:17,380 --> 00:54:25,030
or based on actually over here based on

00:54:20,410 --> 00:54:27,910
blood pressure okay so in this case you

00:54:25,030 --> 00:54:29,710
know if you look at I don't have any new

00:54:27,910 --> 00:54:31,780
set of data because I haven't done any

00:54:29,710 --> 00:54:33,910
training so you look at the time line

00:54:31,780 --> 00:54:37,450
the way to look at over here is this is

00:54:33,910 --> 00:54:42,310
swing historical right so over here it

00:54:37,450 --> 00:54:44,530
shows the accuracy fairness right and on

00:54:42,310 --> 00:54:46,750
over here it shows over a period of time

00:54:44,530 --> 00:54:48,100
so if you have transaction lot of

00:54:46,750 --> 00:54:50,170
transaction you know when I will move

00:54:48,100 --> 00:54:52,000
around I'll get a lot of transactions

00:54:50,170 --> 00:54:55,020
over here but I haven't done anything

00:54:52,000 --> 00:54:58,560
over here so I am saying for some last

00:54:55,020 --> 00:55:03,310
transaction which was done on March 8th

00:54:58,560 --> 00:55:06,820
okay now here basically it shows me that

00:55:03,310 --> 00:55:12,730
okay let's look at this I will go to the

00:55:06,820 --> 00:55:14,000
details okay now in this case if you

00:55:12,730 --> 00:55:19,730
look at

00:55:14,000 --> 00:55:22,190
I had though you know some some money

00:55:19,730 --> 00:55:24,650
over here it says 1% of the group is

00:55:22,190 --> 00:55:27,770
normal right and there is certain bias

00:55:24,650 --> 00:55:29,599
as well and if you look you know look

00:55:27,770 --> 00:55:31,849
for the data element it will tell you

00:55:29,599 --> 00:55:33,830
you know what happens over here so in

00:55:31,849 --> 00:55:36,050
this case what it is saying is if the

00:55:33,830 --> 00:55:39,470
blood pressure was low right

00:55:36,050 --> 00:55:42,080
you know 26% wartime a particular drug

00:55:39,470 --> 00:55:44,450
was given and what are you trying to say

00:55:42,080 --> 00:55:46,040
is the problem is the same right the you

00:55:44,450 --> 00:55:47,660
know the symptoms and everything is the

00:55:46,040 --> 00:55:51,740
same why we are giving different

00:55:47,660 --> 00:55:53,540
medicine right so in in your case you

00:55:51,740 --> 00:55:55,670
know we were looking at agent sex right

00:55:53,540 --> 00:55:57,740
in this case we are looking at a blood

00:55:55,670 --> 00:55:59,180
pressure as one of the element and

00:55:57,740 --> 00:56:05,060
whether we are saying that blood

00:55:59,180 --> 00:56:06,290
pressure influenced the decision or you

00:56:05,060 --> 00:56:08,210
will also be able to see the

00:56:06,290 --> 00:56:10,490
transactions where it will do the

00:56:08,210 --> 00:56:13,130
transaction explained ability as well in

00:56:10,490 --> 00:56:16,580
my case you know if you look at you know

00:56:13,130 --> 00:56:19,010
you know I have some the model and it

00:56:16,580 --> 00:56:22,640
shows me like you know the performance

00:56:19,010 --> 00:56:23,960
of that okay if I had more transactions

00:56:22,640 --> 00:56:25,640
you know I can actually look at the

00:56:23,960 --> 00:56:27,230
transactions over here so I don't have

00:56:25,640 --> 00:56:30,410
the transactions history over here

00:56:27,230 --> 00:56:32,930
because typically just one or or

00:56:30,410 --> 00:56:34,940
something okay if you means that's by

00:56:32,930 --> 00:56:36,770
default I can change the parameter to

00:56:34,940 --> 00:56:38,630
keep it for a month or whatever I want

00:56:36,770 --> 00:56:41,119
and when you click on a particular

00:56:38,630 --> 00:56:44,359
transaction transaction is over here is

00:56:41,119 --> 00:56:46,900
the scoring okay it will tell you how

00:56:44,359 --> 00:56:49,250
the prediction happened okay

00:56:46,900 --> 00:56:53,900
so that's something you'll be able to

00:56:49,250 --> 00:56:56,060
look at in your stuff okay

00:56:53,900 --> 00:56:58,970
also I told you about you know the more

00:56:56,060 --> 00:57:01,640
this is your production model but if it

00:56:58,970 --> 00:57:02,210
finds though there's a bias this is the

00:57:01,640 --> 00:57:04,220
good part

00:57:02,210 --> 00:57:07,670
you know it also gives you a D biased

00:57:04,220 --> 00:57:10,190
model okay so basically it is you know

00:57:07,670 --> 00:57:12,740
modifying some of your I will say

00:57:10,190 --> 00:57:14,599
optimization parameter right and based

00:57:12,740 --> 00:57:18,230
on that you know it is creating

00:57:14,599 --> 00:57:20,060
suggesting a D bias model as well if you

00:57:18,230 --> 00:57:25,490
want to take this model to production

00:57:20,060 --> 00:57:27,869
you can take that as well okay so this

00:57:25,490 --> 00:57:30,960
was about your Oh

00:57:27,869 --> 00:57:32,490
skill and I apologize I think some of

00:57:30,960 --> 00:57:34,349
you are having some issue with the

00:57:32,490 --> 00:57:37,499
services okay

00:57:34,349 --> 00:57:38,999
I think the latency from the machine

00:57:37,499 --> 00:57:40,170
learning to here shouldn't be more than

00:57:38,999 --> 00:57:42,480
five minutes when you are doing the

00:57:40,170 --> 00:57:44,339
configuration but right now make sure

00:57:42,480 --> 00:57:45,900
that you are putting up in the same zone

00:57:44,339 --> 00:57:49,289
if you are putting up in different data

00:57:45,900 --> 00:57:49,680
center we we know that's a non-issue all

00:57:49,289 --> 00:57:52,319
right

00:57:49,680 --> 00:57:55,170
also one other thing I wanted to show

00:57:52,319 --> 00:57:58,140
you like in this case the model is

00:57:55,170 --> 00:58:00,990
deployed on our machine learning you

00:57:58,140 --> 00:58:03,119
know in our environment itself but this

00:58:00,990 --> 00:58:05,759
is important right you can do it for

00:58:03,119 --> 00:58:08,609
your model can be anywhere okay your

00:58:05,759 --> 00:58:10,880
bottle can be deployed on Amazon okay

00:58:08,609 --> 00:58:13,859
your model can be on as your ml cloud

00:58:10,880 --> 00:58:15,900
right the reason we are trying to do is

00:58:13,859 --> 00:58:18,809
because we understand that you're not

00:58:15,900 --> 00:58:20,999
going to drink you know whole thing just

00:58:18,809 --> 00:58:23,940
for the sake of using the open skill

00:58:20,999 --> 00:58:26,369
right so if you're already using AWS or

00:58:23,940 --> 00:58:29,249
Microsoft you know services you can

00:58:26,369 --> 00:58:31,109
still use this environment the custom

00:58:29,249 --> 00:58:33,089
environment is nice in this case you

00:58:31,109 --> 00:58:35,640
know even if it is somewhere else right

00:58:33,089 --> 00:58:38,190
it's what you can do is you can give the

00:58:35,640 --> 00:58:40,380
individual scoring endpoint and this way

00:58:38,190 --> 00:58:43,739
it will be able to connect to the custom

00:58:40,380 --> 00:58:45,119
services okay so that basically means

00:58:43,739 --> 00:58:47,460
you know I don't have to deploy

00:58:45,119 --> 00:58:49,140
everything in Watson machine learning

00:58:47,460 --> 00:58:52,970
you know you can deploy it anywhere and

00:58:49,140 --> 00:58:52,970
you can bring this stuff over here

00:59:06,590 --> 00:59:10,670
and the new net thing right because none

00:59:08,900 --> 00:59:13,460
of you did it right you know what you'll

00:59:10,670 --> 00:59:15,770
do is there's a service in openness

00:59:13,460 --> 00:59:18,650
skill at the last it will say in units

00:59:15,770 --> 00:59:20,450
and when you go to this you can you know

00:59:18,650 --> 00:59:25,100
if you have provision the unit it will

00:59:20,450 --> 00:59:27,800
say synthesize a model right and over

00:59:25,100 --> 00:59:29,930
here basically two steps right one is

00:59:27,800 --> 00:59:32,690
you upload your data so you give some

00:59:29,930 --> 00:59:36,400
certain data over here and then it will

00:59:32,690 --> 00:59:40,520
do the rest of the things for you okay

00:59:36,400 --> 00:59:43,190
so yeah I'll really like you know thanks

00:59:40,520 --> 00:59:46,280
for your time I hope you know it helps

00:59:43,190 --> 00:59:47,930
you to learn something new right and you

00:59:46,280 --> 00:59:50,120
know basically you can play with it

00:59:47,930 --> 00:59:52,850
even this account will be there for a

00:59:50,120 --> 00:59:54,590
month this service is if you get wrong

00:59:52,850 --> 00:59:57,830
anyway I just delete those services

00:59:54,590 --> 01:00:01,100
create a new services okay and you know

00:59:57,830 --> 01:00:04,640
that's all so we have another 15 minutes

01:00:01,100 --> 01:00:07,190
right at 1:15 will break right of there

01:00:04,640 --> 01:00:12,250
serving or one lunch down at 1:30 so

01:00:07,190 --> 01:00:12,250
we'll break around 1:15 okay thank you

01:00:38,430 --> 01:00:41,790

YouTube URL: https://www.youtube.com/watch?v=BkYPKrVRC6M


