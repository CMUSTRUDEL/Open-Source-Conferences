Title: Using Machine Learning to Interpret Hand Sign Language by Vivek Khurana
Publication date: 2019-03-27
Playlist: FOSSASIA Summit 2019 - Artificial Intelligence
Description: 
	17 March 2019 15:55, Event Hall 2-1

There is a large number of deaf and dumb people across globe and communicating with them is difficult as not everyone can understand the sign language. There is also a lack of official sign language interpreters. In India the official number of certified sign language interpreters stood at merely 250 in the year 2017. This makes communication with mute people really difficult. Most of the teaching methods for deaf and dumb involve accommodating them to people without disabilities - while discouraging the sign language.  To make it easier for people to communicate with deaf and dumb people, I had attempted to use TensorFlow to interpret sign language. As of now the system can recognize only alphabets and work is in progress to interpret complete words. The talk will be divide in two parts. First is how TensorFlow object recognition was used to achieve the desired results. The second part will focus on how to contribute to the project and add localization (language specific signs) to make it more robust and more usable.
YouTube URL: https://www.youtube.com/watch?v=hfUsL6bUPss


