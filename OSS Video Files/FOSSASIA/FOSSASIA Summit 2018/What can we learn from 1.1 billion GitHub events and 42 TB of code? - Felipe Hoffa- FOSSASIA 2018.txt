Title: What can we learn from 1.1 billion GitHub events and 42 TB of code? - Felipe Hoffa- FOSSASIA 2018
Publication date: 2018-03-23
Playlist: FOSSASIA Summit 2018
Description: 
	Speaker: Felipe Hoffa, Developer Advocate Google
Info: https://2018.fossasia.org/event/speakers.html#felipe-hoffa3110

Anyone can easily analyze the more than five years of GitHub metadata and 42+ terabytes of open source code. Weâ€™ll leverage this data to understand the community and code related to any language or project. Relevant for open source creators, users, and choosers.

Room: Lecture Theatre
Track: Open Data, Internet Society, Community
Date: Friday, 23rd March, 14:40 - 15:20

Event Page: http://2018.fossasia.org
Follow FOSSASIA on Twitter: https://twitter.com/fossasia/
Like FOSSASIA on Facebook: https://www.facebook.com/fossasia/

Produced by Engineers.SG
Captions: 
	00:00:00,170 --> 00:00:05,640
all right hi everyone good afternoon I

00:00:03,030 --> 00:00:07,200
hope you've settled in philippi is gonna

00:00:05,640 --> 00:00:09,570
talk about all the stuff that you guys

00:00:07,200 --> 00:00:11,429
have done on github I hope everyone here

00:00:09,570 --> 00:00:13,410
is done at least something on github so

00:00:11,429 --> 00:00:14,730
now he's gonna tell you what you've done

00:00:13,410 --> 00:00:16,350
and why you've done it and why it was

00:00:14,730 --> 00:00:18,109
wrong because he has the data so

00:00:16,350 --> 00:00:20,880
everyone say hi to Felipe

00:00:18,109 --> 00:00:23,760
hello everyone yes thank you very much

00:00:20,880 --> 00:00:25,470
thank you for being here I'm Felipe

00:00:23,760 --> 00:00:29,010
Hoffa I live in San Francisco

00:00:25,470 --> 00:00:31,679
I have deadlock but I'm pretty happy to

00:00:29,010 --> 00:00:34,320
be here we are going to analyze data

00:00:31,679 --> 00:00:39,090
we're going to analyze a lot of data on

00:00:34,320 --> 00:00:41,399
github who has a github account good

00:00:39,090 --> 00:00:43,860
good good good so I'm going to measure

00:00:41,399 --> 00:00:45,809
you now what do you have been doing what

00:00:43,860 --> 00:00:50,340
are your favorite projects and why you

00:00:45,809 --> 00:00:52,260
should be doing this if you have any

00:00:50,340 --> 00:00:54,420
questions you might want to interrupt me

00:00:52,260 --> 00:00:57,539
don't interrupt me too much but a bit

00:00:54,420 --> 00:01:01,050
very happy to run interactive queries

00:00:57,539 --> 00:01:08,659
and go wherever you want to go what do

00:01:01,050 --> 00:01:14,760
you see here what is this mmm a license

00:01:08,659 --> 00:01:16,259
code yes it's code but if you go deeper

00:01:14,760 --> 00:01:18,000
you can start seeing other things like

00:01:16,259 --> 00:01:20,340
yeah it has a license

00:01:18,000 --> 00:01:22,979
and it's doing some imports there are

00:01:20,340 --> 00:01:26,130
some modules there from the future if

00:01:22,979 --> 00:01:28,110
you it's Python code if you go back you

00:01:26,130 --> 00:01:31,049
can see you look at the big picture you

00:01:28,110 --> 00:01:33,780
can see number of lines you can see the

00:01:31,049 --> 00:01:36,360
number of stars number of Forks how many

00:01:33,780 --> 00:01:39,780
people have contributed and so what I

00:01:36,360 --> 00:01:44,040
want to say here is we're looking at

00:01:39,780 --> 00:01:47,070
here is data and with a big font because

00:01:44,040 --> 00:01:49,950
it's big data we have a lot of data here

00:01:47,070 --> 00:01:53,610
that we can analyze so who wants to Anna

00:01:49,950 --> 00:01:55,560
who wants to analyze github for example

00:01:53,610 --> 00:01:58,259
project maintainer who here has a

00:01:55,560 --> 00:01:59,850
popular project everyone happening you'd

00:01:58,259 --> 00:02:04,500
have account but who has a popular

00:01:59,850 --> 00:02:06,299
project I know some people yes so yes we

00:02:04,500 --> 00:02:09,390
are surprised maintainer you might want

00:02:06,299 --> 00:02:13,069
to know how popular is your project who

00:02:09,390 --> 00:02:15,590
is starring in it how to manage change

00:02:13,069 --> 00:02:18,260
how many people would you be breaking if

00:02:15,590 --> 00:02:20,780
you change your API or if your project

00:02:18,260 --> 00:02:24,230
healthy are you closing issues fast

00:02:20,780 --> 00:02:26,420
enough if you are a project user you

00:02:24,230 --> 00:02:28,730
might want to know the same things but

00:02:26,420 --> 00:02:31,939
also how to request features how to be

00:02:28,730 --> 00:02:34,519
more effective when asking about - how

00:02:31,939 --> 00:02:36,879
to get new features or what are the

00:02:34,519 --> 00:02:38,900
projects you should be following other

00:02:36,879 --> 00:02:41,959
more popular projects and especially

00:02:38,900 --> 00:02:44,930
before you become a new sir your project

00:02:41,959 --> 00:02:48,349
juicer you want to choose a more the

00:02:44,930 --> 00:02:50,780
most healthy project you want to see if

00:02:48,349 --> 00:02:52,310
there are more popular projects if

00:02:50,780 --> 00:02:54,889
you're looking for a JavaScript library

00:02:52,310 --> 00:02:57,680
there are like a thousand of them but

00:02:54,889 --> 00:03:01,159
you can use data to choose the one

00:02:57,680 --> 00:03:04,189
that's closest to your needs and if you

00:03:01,159 --> 00:03:07,040
just love data yep we have a lot of

00:03:04,189 --> 00:03:08,750
interesting data here that's why we keep

00:03:07,040 --> 00:03:10,609
doing this that's why Allen is doing

00:03:08,750 --> 00:03:12,949
beacon this is why I love doing get help

00:03:10,609 --> 00:03:16,340
because we have a lot lot lot of

00:03:12,949 --> 00:03:17,930
interesting data that we can analyze we

00:03:16,340 --> 00:03:20,750
are going to look at three main data

00:03:17,930 --> 00:03:22,090
sets all of these data sets are stored

00:03:20,750 --> 00:03:24,949
in bigquery

00:03:22,090 --> 00:03:27,590
the first one is give have archive these

00:03:24,949 --> 00:03:30,769
have a log of all the events that are

00:03:27,590 --> 00:03:33,859
happening on github hour-by-hour you can

00:03:30,769 --> 00:03:37,250
see every row every event and stuck

00:03:33,859 --> 00:03:40,430
wearing it it's updated hourly there's

00:03:37,250 --> 00:03:42,889
this other data set that it's gh tauren

00:03:40,430 --> 00:03:46,280
that look within the graph it goes

00:03:42,889 --> 00:03:49,459
beyond events and loser also adds more

00:03:46,280 --> 00:03:52,519
data of metadata that people have used

00:03:49,459 --> 00:03:58,129
an annotated github with and then we

00:03:52,519 --> 00:04:00,379
also have a github called play we copied

00:03:58,129 --> 00:04:02,780
most of the open-source projects into

00:04:00,379 --> 00:04:06,889
bigquery so you can analyze it and look

00:04:02,780 --> 00:04:08,209
at it as called as data and things I've

00:04:06,889 --> 00:04:09,979
been doing with this I've been doing a

00:04:08,209 --> 00:04:13,250
lot of interesting blog posts my

00:04:09,979 --> 00:04:15,650
favorite Landon or when a lot of people

00:04:13,250 --> 00:04:17,780
love is what are the top companies

00:04:15,650 --> 00:04:20,329
contributing to open source on github

00:04:17,780 --> 00:04:24,830
you know what the top companies

00:04:20,329 --> 00:04:26,090
contributed to open source are you read

00:04:24,830 --> 00:04:28,610
that blog post

00:04:26,090 --> 00:04:30,590
yeah there was a blog post two years ago

00:04:28,610 --> 00:04:33,230
that said that Microsoft was a top

00:04:30,590 --> 00:04:34,910
company contributing to github but the

00:04:33,230 --> 00:04:36,889
thing is when you're analyzing data

00:04:34,910 --> 00:04:40,100
there are so many ways to measure things

00:04:36,889 --> 00:04:43,880
and no way is absolutely correct you

00:04:40,100 --> 00:04:48,169
have to make a lot of assumptions and I

00:04:43,880 --> 00:04:50,630
mention assumptions in that case that

00:04:48,169 --> 00:04:53,480
blog post said that Microsoft was the

00:04:50,630 --> 00:04:56,410
one that was contributing the most users

00:04:53,480 --> 00:04:59,270
to get her but then you can count

00:04:56,410 --> 00:05:01,790
different ways so for example here I

00:04:59,270 --> 00:05:05,720
have it in two dimensions one is the

00:05:01,790 --> 00:05:08,210
number of users I identified from each

00:05:05,720 --> 00:05:11,570
company on github and you can see that

00:05:08,210 --> 00:05:14,090
yes Microsoft that's the one of the most

00:05:11,570 --> 00:05:16,070
of the right that has the most users but

00:05:14,090 --> 00:05:18,520
if you look at the dimension of how many

00:05:16,070 --> 00:05:22,060
repositories people are contributing to

00:05:18,520 --> 00:05:27,020
Google is on top but most companies are

00:05:22,060 --> 00:05:28,760
very top and have way more users and way

00:05:27,020 --> 00:05:30,710
more projects and these are the

00:05:28,760 --> 00:05:34,750
companies that is honestly pretty cool

00:05:30,710 --> 00:05:37,640
but also the size of each circle here is

00:05:34,750 --> 00:05:39,830
counting the number of stars these

00:05:37,640 --> 00:05:42,620
projects are getting so basically we're

00:05:39,830 --> 00:05:45,410
looking at how much impact how much

00:05:42,620 --> 00:05:47,600
people love all of these projects so

00:05:45,410 --> 00:05:50,210
even though Microsoft is doing really

00:05:47,600 --> 00:05:52,610
well I love how much they've changed in

00:05:50,210 --> 00:05:54,860
the last few years I still can say that

00:05:52,610 --> 00:05:58,039
Google has more projects and more stars

00:05:54,860 --> 00:05:59,660
I love it that it's that things are that

00:05:58,039 --> 00:06:02,120
way then you have a lot of other

00:05:59,660 --> 00:06:07,220
companies there they're pretty cool some

00:06:02,120 --> 00:06:08,780
I expect more from some doing huge

00:06:07,220 --> 00:06:12,169
contributions while being small

00:06:08,780 --> 00:06:14,539
companies so yeah these are pretty

00:06:12,169 --> 00:06:18,729
interesting ways to measure still I had

00:06:14,539 --> 00:06:21,770
to make assumptions and one of the main

00:06:18,729 --> 00:06:24,410
messages of this talk is that I want you

00:06:21,770 --> 00:06:27,139
to challenge my assumptions if you think

00:06:24,410 --> 00:06:29,180
I'm wrong please tell me you have access

00:06:27,139 --> 00:06:30,760
to all of this data you can go deeper

00:06:29,180 --> 00:06:34,099
you can count things in different ways

00:06:30,760 --> 00:06:36,440
we can refine the results I got here to

00:06:34,099 --> 00:06:38,950
get to these results this is the query

00:06:36,440 --> 00:06:40,540
that I ran it's

00:06:38,950 --> 00:06:45,310
really complicated it has a lot of

00:06:40,540 --> 00:06:48,430
assumptions so for this top wish it's

00:06:45,310 --> 00:06:52,660
better if we start at a more simple

00:06:48,430 --> 00:06:55,840
place let's go back to 2012 when my

00:06:52,660 --> 00:06:59,230
teammate will bear Alegre garlic started

00:06:55,840 --> 00:07:01,330
collecting all of these events and you'd

00:06:59,230 --> 00:07:03,700
have Castle API he connected to the API

00:07:01,330 --> 00:07:09,370
he started downloading all of the events

00:07:03,700 --> 00:07:11,740
and he left these files that you could

00:07:09,370 --> 00:07:14,770
download if you want to get one hour of

00:07:11,740 --> 00:07:17,380
github archive each have events you do a

00:07:14,770 --> 00:07:19,240
double you'll get you'll get a file in

00:07:17,380 --> 00:07:21,820
less than a second by megabytes of

00:07:19,240 --> 00:07:26,700
compress later if you decompress it just

00:07:21,820 --> 00:07:29,260
like 40 megabytes of data that's nothing

00:07:26,700 --> 00:07:31,990
anyone can download any of these files

00:07:29,260 --> 00:07:35,260
and start analyzing you eat them on your

00:07:31,990 --> 00:07:37,750
computer at any time but that's only one

00:07:35,260 --> 00:07:40,660
hour of state if you want to analyze

00:07:37,750 --> 00:07:44,290
seven years of data at this rate we are

00:07:40,660 --> 00:07:47,020
talking about two terabytes of data more

00:07:44,290 --> 00:07:50,500
than a billion rows and that's way more

00:07:47,020 --> 00:07:53,200
than we normally handle if you have to

00:07:50,500 --> 00:07:55,750
handle the 1 billion events a two

00:07:53,200 --> 00:07:56,320
terabyte of data how do you where do you

00:07:55,750 --> 00:08:06,760
do this

00:07:56,320 --> 00:08:13,900
what's your tool of choice and what

00:08:06,760 --> 00:08:17,710
would you use okay that's one answer yes

00:08:13,900 --> 00:08:19,900
so there are options but my option the

00:08:17,710 --> 00:08:23,920
one that I am using is called bigquery

00:08:19,900 --> 00:08:27,520
that when you start collecting these

00:08:23,920 --> 00:08:30,010
events in 2012 was one of our new

00:08:27,520 --> 00:08:33,490
projects at that time and he put all of

00:08:30,010 --> 00:08:34,240
the these files here why do we want to

00:08:33,490 --> 00:08:38,200
use bigquery

00:08:34,240 --> 00:08:40,240
we have some nice advantages one it's

00:08:38,200 --> 00:08:42,550
fast we will be able to analyze

00:08:40,240 --> 00:08:45,040
terabytes in seconds it's simple you

00:08:42,550 --> 00:08:47,650
only need to know sequel it's scalable

00:08:45,040 --> 00:08:50,050
you can go from bytes doesn't matter how

00:08:47,650 --> 00:08:50,690
much data you have it will store all of

00:08:50,050 --> 00:08:53,330
it

00:08:50,690 --> 00:08:56,660
and it's always on compared to other

00:08:53,330 --> 00:08:59,180
solutions here you have nothing to turn

00:08:56,660 --> 00:09:00,980
on it's just always there you have to

00:08:59,180 --> 00:09:03,860
load your data as much data you have and

00:09:00,980 --> 00:09:05,750
it will be running always because you

00:09:03,860 --> 00:09:08,150
don't pay for hours you don't pay for

00:09:05,750 --> 00:09:10,580
Ramu you just pay for how much data

00:09:08,150 --> 00:09:14,930
you're storing and how much data your

00:09:10,580 --> 00:09:17,180
query and everyone gets a free terabyte

00:09:14,930 --> 00:09:18,920
every month so if you want to run any of

00:09:17,180 --> 00:09:22,160
the queries I won't I'm going to run now

00:09:18,920 --> 00:09:23,830
you can just open your computer create

00:09:22,160 --> 00:09:26,540
an account with Google you will get

00:09:23,830 --> 00:09:29,960
three terabyte and you will be able to

00:09:26,540 --> 00:09:33,620
repeat all of this even better the query

00:09:29,960 --> 00:09:36,050
has you can share data and you can when

00:09:33,620 --> 00:09:37,910
you load a data query to your data it's

00:09:36,050 --> 00:09:41,390
for your eyes only you can have data

00:09:37,910 --> 00:09:43,940
health data private data it will be

00:09:41,390 --> 00:09:46,700
stored securely but if you want to share

00:09:43,940 --> 00:09:49,370
it with third parties with any other

00:09:46,700 --> 00:09:52,310
companies within your company or with

00:09:49,370 --> 00:09:54,470
the whole world you can do it and so

00:09:52,310 --> 00:09:57,050
easily I was able to share all of these

00:09:54,470 --> 00:09:59,260
events with all of you and you get this

00:09:57,050 --> 00:10:04,400
free terabyte every month to run queries

00:09:59,260 --> 00:10:06,470
so that's bigquery will demo it will run

00:10:04,400 --> 00:10:10,190
some live queries but let's start

00:10:06,470 --> 00:10:15,530
looking at the start which starts and

00:10:10,190 --> 00:10:18,230
talking about github stars of course so

00:10:15,530 --> 00:10:22,250
what were the projects that got the most

00:10:18,230 --> 00:10:26,270
number of stars last year tensorflow

00:10:22,250 --> 00:10:29,800
that's a good guess any other guess what

00:10:26,270 --> 00:10:29,800
other projects what a lot of stars

00:10:31,930 --> 00:10:39,050
okay let's count it let's let's run this

00:10:35,120 --> 00:10:42,190
query before we run out of gases so I

00:10:39,050 --> 00:10:45,080
have here bigquery I have a simple query

00:10:42,190 --> 00:10:47,540
you can connect python r whatever your

00:10:45,080 --> 00:10:50,839
favorite tool to analyze data is to be

00:10:47,540 --> 00:10:53,959
query but it also has this web UI so i

00:10:50,839 --> 00:10:55,610
have this table from 2017 all of the

00:10:53,959 --> 00:10:58,399
events from this year

00:10:55,610 --> 00:11:02,540
this table is has one terabyte of data

00:10:58,399 --> 00:11:04,880
it has 400 million rows and if i want to

00:11:02,540 --> 00:11:07,430
count the number of stars I can run a

00:11:04,880 --> 00:11:10,279
count stars of all the watch events

00:11:07,430 --> 00:11:15,910
every time someone starts something it

00:11:10,279 --> 00:11:19,370
produces a watch event last year we saw

00:11:15,910 --> 00:11:24,860
30 million stars you want to know what

00:11:19,370 --> 00:11:27,320
are the project's repo name group it's

00:11:24,860 --> 00:11:32,060
the first column order by the second one

00:11:27,320 --> 00:11:37,940
and in descending order and give me the

00:11:32,060 --> 00:11:41,120
top 20 what were the top 20 projects

00:11:37,940 --> 00:11:43,390
last year and it's 25 to go start

00:11:41,120 --> 00:11:45,950
writing queries and getting results and

00:11:43,390 --> 00:11:47,060
the second project with the most stars

00:11:45,950 --> 00:11:50,750
was tensorflow

00:11:47,060 --> 00:11:52,910
good good good good guess the first

00:11:50,750 --> 00:11:56,690
project was free code camp anyone here

00:11:52,910 --> 00:11:58,640
knows free code camp yeah so they are a

00:11:56,690 --> 00:12:02,089
great resource for people that want to

00:11:58,640 --> 00:12:05,450
learn how to code and the first step in

00:12:02,089 --> 00:12:08,660
this in their program is create a github

00:12:05,450 --> 00:12:11,660
account the second step is star our

00:12:08,660 --> 00:12:16,459
project and that's how you get to the

00:12:11,660 --> 00:12:19,940
number one spot smart oh yeah they

00:12:16,459 --> 00:12:22,820
deleted that step so these 90,000 stars

00:12:19,940 --> 00:12:26,300
are only from the first half of 2017 and

00:12:22,820 --> 00:12:28,820
you have bougie-ass Facebook we add what

00:12:26,300 --> 00:12:32,209
every programmer should know and develop

00:12:28,820 --> 00:12:35,870
a road map it's attractive so that's how

00:12:32,209 --> 00:12:38,089
we start analyzing it hub now whenever

00:12:35,870 --> 00:12:41,240
you run a query whenever you're looking

00:12:38,089 --> 00:12:43,490
at data you have to ask you have to be a

00:12:41,240 --> 00:12:44,389
little suspicious and this the real

00:12:43,490 --> 00:12:47,509
results

00:12:44,389 --> 00:12:49,689
can we trust any rank in that tell fast

00:12:47,509 --> 00:12:55,639
these were the top projects last year

00:12:49,689 --> 00:12:58,429
come with turns out I mean this is false

00:12:55,639 --> 00:13:02,059
Asia you may know anyone here is a fan

00:12:58,429 --> 00:13:04,040
of Faust Asia and a fan of aphasia so

00:13:02,059 --> 00:13:05,600
this is a project that has almost a

00:13:04,040 --> 00:13:08,540
thousand stars and I will give it

00:13:05,600 --> 00:13:11,839
another star and then if I remove this

00:13:08,540 --> 00:13:13,910
star I can give them one star again and

00:13:11,839 --> 00:13:17,029
I can remove it and I can give them one

00:13:13,910 --> 00:13:20,269
star again and in this way I can just

00:13:17,029 --> 00:13:22,819
create a series of events of that just

00:13:20,269 --> 00:13:25,399
give them a lot of stars when I'm just

00:13:22,819 --> 00:13:28,040
counting them like this so instead of

00:13:25,399 --> 00:13:30,049
doing an eight count I can just look

00:13:28,040 --> 00:13:33,379
instead at how many different people

00:13:30,049 --> 00:13:36,559
have stopped these projects so the

00:13:33,379 --> 00:13:41,139
extinct art or logging and now we are

00:13:36,559 --> 00:13:43,819
going to order by that column instead

00:13:41,139 --> 00:13:46,999
and let's look at the real number of

00:13:43,819 --> 00:13:49,009
stars that this project lot you will

00:13:46,999 --> 00:13:52,759
notice that some projects are more

00:13:49,009 --> 00:13:56,540
inflated than others and again requiring

00:13:52,759 --> 00:14:01,429
one whole year of data it's taking 15

00:13:56,540 --> 00:14:03,709
seconds and yes you can find out see the

00:14:01,429 --> 00:14:06,470
free code camp you didn't get 90

00:14:03,709 --> 00:14:08,439
thousand stars it was 85 thousand there

00:14:06,470 --> 00:14:10,850
are like five thousand obligated stars

00:14:08,439 --> 00:14:12,799
sometimes have more duplicate starts

00:14:10,850 --> 00:14:15,350
than others we can call them fake stars

00:14:12,799 --> 00:14:18,559
if you want but that is happening and

00:14:15,350 --> 00:14:20,989
when you're running rankings take care

00:14:18,559 --> 00:14:27,589
of projects that might be faking their

00:14:20,989 --> 00:14:31,129
number of stars for any reason let me go

00:14:27,589 --> 00:14:34,069
back to slides because yes so these were

00:14:31,129 --> 00:14:36,019
the top prizes on 2016 2015 free code

00:14:34,069 --> 00:14:39,589
camp got double the number of stars

00:14:36,019 --> 00:14:45,980
because they have these variable stars

00:14:39,589 --> 00:14:48,759
now we can do the so this is called the

00:14:45,980 --> 00:14:51,919
rank is changed from 2016 to 17

00:14:48,759 --> 00:14:55,450
tensorflow went from the number five

00:14:51,919 --> 00:14:58,630
position to the number two

00:14:55,450 --> 00:15:02,320
as I was telling you not all stars are

00:14:58,630 --> 00:15:05,020
equal a star that I give a project is

00:15:02,320 --> 00:15:06,700
different and I start that you give to a

00:15:05,020 --> 00:15:08,560
project that you give to a project

00:15:06,700 --> 00:15:11,650
because everyone has a different

00:15:08,560 --> 00:15:13,300
background every star comes from a

00:15:11,650 --> 00:15:15,310
different individual with a different

00:15:13,300 --> 00:15:16,510
experience with different interests and

00:15:15,310 --> 00:15:18,340
people are interested in machine

00:15:16,510 --> 00:15:20,590
learning some people are interested in

00:15:18,340 --> 00:15:22,930
PHP some people are thirsty

00:15:20,590 --> 00:15:25,450
I live in Singapore and each star has

00:15:22,930 --> 00:15:28,680
all of that background and we can start

00:15:25,450 --> 00:15:28,680
wearing that kind of data

00:15:29,040 --> 00:15:35,610
well we have a cool query yeah so for

00:15:33,040 --> 00:15:40,150
example let's compare

00:15:35,610 --> 00:15:43,060
let's compare tensorflow with free code

00:15:40,150 --> 00:15:47,500
camp they both got a lot of stars in

00:15:43,060 --> 00:15:51,250
this case and comparing the number of

00:15:47,500 --> 00:15:53,890
stars they got it in 2007 16 and I'm

00:15:51,250 --> 00:15:56,890
looking at different dimensions here for

00:15:53,890 --> 00:15:59,350
example the age of the users tagging is

00:15:56,890 --> 00:16:02,470
prior I don't know the age of people

00:15:59,350 --> 00:16:04,480
long it huh but I know how long they

00:16:02,470 --> 00:16:06,840
been around github did equate their

00:16:04,480 --> 00:16:11,410
accounts five years ago or one year ago

00:16:06,840 --> 00:16:14,290
it turns out the age of people that

00:16:11,410 --> 00:16:16,720
start free code camp is one year while

00:16:14,290 --> 00:16:19,600
tensorflow is two years people start in

00:16:16,720 --> 00:16:22,090
terms of law have more experience they

00:16:19,600 --> 00:16:24,100
have watch star more repositories like 8

00:16:22,090 --> 00:16:27,520
times more repositories they have

00:16:24,100 --> 00:16:30,520
written more issues more comments

00:16:27,520 --> 00:16:33,520
they've done more pull requests and this

00:16:30,520 --> 00:16:35,560
way you can find the project a

00:16:33,520 --> 00:16:39,640
constitute of different kind of people

00:16:35,560 --> 00:16:41,680
if you are creating a project for people

00:16:39,640 --> 00:16:45,970
that are learning how to code you

00:16:41,680 --> 00:16:48,520
probably want to get newbies if you have

00:16:45,970 --> 00:16:50,290
an advanced project you have your run

00:16:48,520 --> 00:16:52,270
you will count things in a different way

00:16:50,290 --> 00:16:55,120
it all depends on what you're counting

00:16:52,270 --> 00:16:58,090
you can define your own blankets you can

00:16:55,120 --> 00:17:02,680
be the number one in any project in any

00:16:58,090 --> 00:17:07,000
mix that you define in this case if we

00:17:02,680 --> 00:17:09,050
count only the number of News stars from

00:17:07,000 --> 00:17:12,080
people that have written

00:17:09,050 --> 00:17:14,450
than 20 comments free code camp doesn't

00:17:12,080 --> 00:17:17,810
have a hundred forty thousand four two

00:17:14,450 --> 00:17:20,110
thousand forty thousand stars but almost

00:17:17,810 --> 00:17:23,150
the same number as tensorflow

00:17:20,110 --> 00:17:24,830
because in this case in this ranking we

00:17:23,150 --> 00:17:28,040
care only about experience of people

00:17:24,830 --> 00:17:29,090
maybe that's why what I care about if

00:17:28,040 --> 00:17:33,070
you care about something different

00:17:29,090 --> 00:17:38,270
that's up to you to refine your ranking

00:17:33,070 --> 00:17:41,510
so again looking at 2015 if we look at

00:17:38,270 --> 00:17:44,270
users with a lot of comments that have

00:17:41,510 --> 00:17:46,580
been active on github the ranking

00:17:44,270 --> 00:17:53,000
changes free code camp is not longer the

00:17:46,580 --> 00:17:55,610
number one project yarn if Facebook

00:17:53,000 --> 00:17:58,610
react is not on the top ten but Facebook

00:17:55,610 --> 00:18:01,880
indicator create react app is on top and

00:17:58,610 --> 00:18:05,420
so it all depends on who were our users

00:18:01,880 --> 00:18:08,690
I was looking up for the experts for for

00:18:05,420 --> 00:18:11,750
profession for say she has 100 some 200

00:18:08,690 --> 00:18:13,610
projects 211 repositories I wanted to

00:18:11,750 --> 00:18:16,370
know what are the top projects for

00:18:13,610 --> 00:18:19,790
rosacea you can run a query like this

00:18:16,370 --> 00:18:23,210
and interestingly enough you get results

00:18:19,790 --> 00:18:28,720
the loop like this so many for social

00:18:23,210 --> 00:18:31,760
projects curve around 280 stars

00:18:28,720 --> 00:18:35,540
what's company here that we have a lot

00:18:31,760 --> 00:18:38,690
of post Asia fans that star every fourth

00:18:35,540 --> 00:18:40,610
Asia project which is nice but it makes

00:18:38,690 --> 00:18:43,160
us harder to know what are the top prize

00:18:40,610 --> 00:18:47,060
a that people are interested in

00:18:43,160 --> 00:18:49,400
so it's cool if everyone starts was HR

00:18:47,060 --> 00:18:50,870
projects but we may need to look at

00:18:49,400 --> 00:18:54,230
things in a different way and we have

00:18:50,870 --> 00:18:57,230
the raw data to do so so for example if

00:18:54,230 --> 00:19:02,000
I look at fans that have starred more

00:18:57,230 --> 00:19:05,240
than that star mostly only for fascia

00:19:02,000 --> 00:19:07,070
projects and I remove them I get a

00:19:05,240 --> 00:19:08,270
completely different branch in a

00:19:07,070 --> 00:19:11,480
different and a different distribution

00:19:08,270 --> 00:19:13,190
this looks more normal now here not

00:19:11,480 --> 00:19:16,970
looking at fans and looking at general

00:19:13,190 --> 00:19:19,430
interest on each project and when you

00:19:16,970 --> 00:19:21,830
get stars you can also ask so what else

00:19:19,430 --> 00:19:22,670
can do these people start role in this

00:19:21,830 --> 00:19:25,460
case for exam

00:19:22,670 --> 00:19:30,770
and looking at stars to telsa flow what

00:19:25,460 --> 00:19:32,660
else did they start they start as with a

00:19:30,770 --> 00:19:35,150
correlative difficulty they start

00:19:32,660 --> 00:19:39,310
finding and other machine learning

00:19:35,150 --> 00:19:42,590
projects and it works pretty well now

00:19:39,310 --> 00:19:43,820
this is a name ranking just by Counting

00:19:42,590 --> 00:19:46,340
but then if I were to do it by

00:19:43,820 --> 00:19:48,620
probability I get a different ranking

00:19:46,340 --> 00:19:52,130
and again that yes people that start

00:19:48,620 --> 00:19:56,030
pencil flow also start there are no

00:19:52,130 --> 00:19:59,060
thougts cafes I could learn Karis MX net

00:19:56,030 --> 00:20:01,460
and you can start navigating creating a

00:19:59,060 --> 00:20:04,130
graph for any project wherever your

00:20:01,460 --> 00:20:06,200
project is you can navigate what they

00:20:04,130 --> 00:20:09,770
say people that are starting to appraise

00:20:06,200 --> 00:20:12,230
I'll start to you can do titles of stars

00:20:09,770 --> 00:20:15,830
because I'm probably it like stars in a

00:20:12,230 --> 00:20:17,750
very they get the same number of stars

00:20:15,830 --> 00:20:20,450
every week and some other price just

00:20:17,750 --> 00:20:23,300
have these huge spikes these are the top

00:20:20,450 --> 00:20:26,000
Apache projects I created this we

00:20:23,300 --> 00:20:28,460
pattice to do our free this validation

00:20:26,000 --> 00:20:30,410
tool I have a whole interactive

00:20:28,460 --> 00:20:33,320
repository we have time later we can

00:20:30,410 --> 00:20:35,810
come back here but for example here I

00:20:33,320 --> 00:20:38,840
chose two different party projects a are

00:20:35,810 --> 00:20:41,450
all versus plink plink has gets a stable

00:20:38,840 --> 00:20:44,330
number of stars each week being well

00:20:41,450 --> 00:20:46,550
arrow gets a lot of stars every time

00:20:44,330 --> 00:20:48,740
with Mikey D writes a blog post about it

00:20:46,550 --> 00:20:51,260
boom everyone starts to this project

00:20:48,740 --> 00:20:52,700
this was in February one year ago then

00:20:51,260 --> 00:20:56,660
in September he wrote another blog post

00:20:52,700 --> 00:20:58,400
have another kids jump so if you want to

00:20:56,660 --> 00:21:00,920
get stars if you want to get attention

00:20:58,400 --> 00:21:04,280
to your projects they are things that

00:21:00,920 --> 00:21:08,180
you can do like for example putting your

00:21:04,280 --> 00:21:10,010
project on happiness because let's look

00:21:08,180 --> 00:21:15,680
at this project all the spikes they got

00:21:10,010 --> 00:21:17,450
in the number of stars if you see those

00:21:15,680 --> 00:21:19,880
annotations or sanitation's

00:21:17,450 --> 00:21:22,370
show when these projects were shown on

00:21:19,880 --> 00:21:24,170
the hacker news front page and there's a

00:21:22,370 --> 00:21:25,880
huge correlation if you show up on how

00:21:24,170 --> 00:21:28,760
can you people will give you a lot of

00:21:25,880 --> 00:21:31,130
stars and what's super interesting here

00:21:28,760 --> 00:21:35,120
is that I didn't run these annotations

00:21:31,130 --> 00:21:36,110
manually but because on the query I not

00:21:35,120 --> 00:21:38,720
only have

00:21:36,110 --> 00:21:42,170
they also have for example all of the

00:21:38,720 --> 00:21:44,720
hacker news story so you every day we

00:21:42,170 --> 00:21:46,910
update the data said and you can run

00:21:44,720 --> 00:21:49,040
adjoin between both datasets and they

00:21:46,910 --> 00:21:50,840
are still looking for things that show

00:21:49,040 --> 00:21:55,160
up on Hacker News and cut the number of

00:21:50,840 --> 00:21:57,920
stars it produces now the number starts

00:21:55,160 --> 00:22:00,650
is not the only important metric we can

00:21:57,920 --> 00:22:04,720
gain stars we can but for example we may

00:22:00,650 --> 00:22:07,100
want to see a price the Herto project

00:22:04,720 --> 00:22:11,470
what are the products that had the most

00:22:07,100 --> 00:22:14,710
comment on issues in this month do 2016

00:22:11,470 --> 00:22:17,740
veneris has a huge amount of comments

00:22:14,710 --> 00:22:20,840
17,000 Sparkle a lot of comments a

00:22:17,740 --> 00:22:26,500
OpenShift - and a project called

00:22:20,840 --> 00:22:28,570
thousand demo anyone knows that project

00:22:26,500 --> 00:22:32,390
No

00:22:28,570 --> 00:22:35,840
so again whenever we run a query

00:22:32,390 --> 00:22:38,210
whenever we we get results we have to be

00:22:35,840 --> 00:22:42,830
a little suspicious of these results and

00:22:38,210 --> 00:22:45,470
it turns out sound mo-mo these almost

00:22:42,830 --> 00:22:51,470
5,000 comments were written by one

00:22:45,470 --> 00:22:54,530
account you can have robots writing

00:22:51,470 --> 00:22:58,100
comments so you might want to take away

00:22:54,530 --> 00:23:00,830
that kind of stuff in this case this

00:22:58,100 --> 00:23:02,270
ranking is counting not only the number

00:23:00,830 --> 00:23:05,900
of people writing comments there are

00:23:02,270 --> 00:23:07,550
source so we have the number of comments

00:23:05,900 --> 00:23:10,910
we have the number of people who write

00:23:07,550 --> 00:23:13,490
in comments and then I'm calculating how

00:23:10,910 --> 00:23:16,490
many comments each author world and you

00:23:13,490 --> 00:23:20,480
can see that for kubernetes each author

00:23:16,490 --> 00:23:23,270
wrote about 18 comments 500 people write

00:23:20,480 --> 00:23:25,820
in 18 comments each that shows you that

00:23:23,270 --> 00:23:27,320
you have a super healthy community well

00:23:25,820 --> 00:23:28,910
the project font awesome

00:23:27,320 --> 00:23:32,180
yeah have more people writing comments

00:23:28,910 --> 00:23:37,100
but each one left less than 2 comments

00:23:32,180 --> 00:23:40,070
each so in average so ya be suspicious

00:23:37,100 --> 00:23:42,710
of the results you get and you can see

00:23:40,070 --> 00:23:44,660
here that even those probably can get

00:23:42,710 --> 00:23:47,899
the same number of comments there is the

00:23:44,660 --> 00:23:52,119
different measure of happiness

00:23:47,899 --> 00:23:55,460
potential project I did the same query

00:23:52,119 --> 00:23:59,659
removing the comments that look too

00:23:55,460 --> 00:24:01,999
similar and these are the top pros for

00:23:59,659 --> 00:24:04,279
force Asia open event Android Susy

00:24:01,999 --> 00:24:06,589
servers who see Android and you see that

00:24:04,279 --> 00:24:08,899
there's a healthy number of people

00:24:06,589 --> 00:24:11,659
commenting and there is a different rate

00:24:08,899 --> 00:24:13,549
of cognitive project and as a prize

00:24:11,659 --> 00:24:16,539
maintainer that's super interesting data

00:24:13,549 --> 00:24:20,690
as a producer it's interesting data -

00:24:16,539 --> 00:24:23,269
you can do text analysis - so for

00:24:20,690 --> 00:24:25,729
example how do people start issues on

00:24:23,269 --> 00:24:27,379
github what's the most common way to

00:24:25,729 --> 00:24:30,320
start an issue if you want to request

00:24:27,379 --> 00:24:33,769
something are people nice and not are

00:24:30,320 --> 00:24:35,749
they no time these are the results I got

00:24:33,769 --> 00:24:38,330
for the first four words when someone

00:24:35,749 --> 00:24:42,259
starts an issue they start in a nice way

00:24:38,330 --> 00:24:46,659
like it would be nice if it possible -

00:24:42,259 --> 00:24:49,309
and trying to people are really nice

00:24:46,659 --> 00:24:52,369
there's a lot of people that start

00:24:49,309 --> 00:24:54,469
issues in this way but what's most

00:24:52,369 --> 00:24:57,169
interesting here is the third column

00:24:54,469 --> 00:25:01,129
that asked how many of these issues get

00:24:57,169 --> 00:25:04,369
closure and it turns out if you start an

00:25:01,129 --> 00:25:07,190
issue it would be nice you get a 56%

00:25:04,369 --> 00:25:11,059
closure well is it possible to which is

00:25:07,190 --> 00:25:13,609
more concrete get 73% of closure now the

00:25:11,059 --> 00:25:16,519
best one I got here is when you start an

00:25:13,609 --> 00:25:18,349
issue saying I get the following like

00:25:16,519 --> 00:25:19,909
being concrete showing what you're

00:25:18,349 --> 00:25:22,609
probably and will show you what you want

00:25:19,909 --> 00:25:27,769
gets you much better results than

00:25:22,609 --> 00:25:32,839
there's been more tyria you can look at

00:25:27,769 --> 00:25:34,309
countries where people can from any if

00:25:32,839 --> 00:25:36,589
you have a guess of the top countries

00:25:34,309 --> 00:25:38,479
these are the top countries the first

00:25:36,589 --> 00:25:42,619
one is moved because most people don't

00:25:38,479 --> 00:25:44,809
put their location on the profile but

00:25:42,619 --> 00:25:49,179
then you have the United States India

00:25:44,809 --> 00:25:53,059
China Great Britain the Deutschland

00:25:49,179 --> 00:25:55,309
which might be interesting this is the

00:25:53,059 --> 00:25:58,489
same by number of posts around the world

00:25:55,309 --> 00:25:59,380
and of course the most concentration is

00:25:58,489 --> 00:26:01,480
in you

00:25:59,380 --> 00:26:04,690
China but it's more interesting if we

00:26:01,480 --> 00:26:07,570
look at results per capita and now we

00:26:04,690 --> 00:26:09,690
see a huge concentration on North Europe

00:26:07,570 --> 00:26:11,890
we see a huge concentration Australia

00:26:09,690 --> 00:26:14,770
these are the numbers ago the top

00:26:11,890 --> 00:26:17,140
countries we buy concentration of

00:26:14,770 --> 00:26:21,550
programmers are Iceland Sweden Norway

00:26:17,140 --> 00:26:28,180
New Zealand Denmark basically cold

00:26:21,550 --> 00:26:31,120
countries all that's world I think when

00:26:28,180 --> 00:26:32,770
I see you those names now I instead of

00:26:31,120 --> 00:26:35,200
stopping here and thinking about cold

00:26:32,770 --> 00:26:37,750
countries I can go and run an analysis

00:26:35,200 --> 00:26:41,560
over it I can find out where do coders

00:26:37,750 --> 00:26:43,570
prefer to live and in before they also

00:26:41,560 --> 00:26:46,180
have the worldwide weather they buy they

00:26:43,570 --> 00:26:50,320
station by station you can get this data

00:26:46,180 --> 00:26:53,200
and this is my the average temperature

00:26:50,320 --> 00:26:56,140
for each station around the world group

00:26:53,200 --> 00:27:00,720
by country and Singapore is one of the

00:26:56,140 --> 00:27:03,460
hottest countries I can confirm that

00:27:00,720 --> 00:27:06,220
here the coldest countries on this side

00:27:03,460 --> 00:27:08,470
we can join both data sets and we can

00:27:06,220 --> 00:27:11,380
get a chart like this this chart we can

00:27:08,470 --> 00:27:14,640
see that yes the coldest countries have

00:27:11,380 --> 00:27:19,270
the highest concentration of programmers

00:27:14,640 --> 00:27:27,600
there is a correlation how within the

00:27:19,270 --> 00:27:27,600
heart of country that's Singapore yes

00:27:27,810 --> 00:27:32,640
exactly people don't want to go outside

00:27:33,180 --> 00:27:38,110
there's a huge concentration of

00:27:35,620 --> 00:27:40,120
programmers here and somehow in Asia you

00:27:38,110 --> 00:27:42,610
have the opposite correlation where the

00:27:40,120 --> 00:27:45,490
hottest countries have the biggest

00:27:42,610 --> 00:27:47,200
concentration of coders County

00:27:45,490 --> 00:27:50,470
developers there are many ways to count

00:27:47,200 --> 00:27:52,360
them again looking at the Emperor

00:27:50,470 --> 00:27:55,120
country in Asia you can see that of

00:27:52,360 --> 00:27:57,310
course the country with the most users

00:27:55,120 --> 00:28:01,030
is China followed by India Japan

00:27:57,310 --> 00:28:03,610
Indonesia this is by github now each

00:28:01,030 --> 00:28:05,890
country behaves in a different way China

00:28:03,610 --> 00:28:09,510
gives a lot more stars per user than

00:28:05,890 --> 00:28:11,340
India 34 starter users who spend and

00:28:09,510 --> 00:28:13,680
Singapore there

00:28:11,340 --> 00:28:17,190
nine you give another rat 17 starts to

00:28:13,680 --> 00:28:18,930
project you could do more and then I

00:28:17,190 --> 00:28:21,480
have other datasets in bigquery have a

00:28:18,930 --> 00:28:23,100
stack overflow so what are the top

00:28:21,480 --> 00:28:27,540
countries in stack overflow is it the

00:28:23,100 --> 00:28:29,370
same ranking or different well in the

00:28:27,540 --> 00:28:31,500
exit table one followed by Pakistan

00:28:29,370 --> 00:28:34,100
somehow Pakistan uses a lot of stock

00:28:31,500 --> 00:28:38,220
overflows produces answers producing

00:28:34,100 --> 00:28:43,980
questions China and then here Singapore

00:28:38,220 --> 00:28:45,330
goes down to to number 11 you could use

00:28:43,980 --> 00:28:46,530
smaller stack overflow you could produce

00:28:45,330 --> 00:28:49,500
more content you could ask questions

00:28:46,530 --> 00:28:52,980
answer them and these numbers could go

00:28:49,500 --> 00:28:54,630
up you can look at the growth in this

00:28:52,980 --> 00:28:59,220
case for Stack Overflow have many more

00:28:54,630 --> 00:29:00,780
users you're getting per per year Brin

00:28:59,220 --> 00:29:03,630
surprise here about Philippines

00:29:00,780 --> 00:29:05,640
Indonesia and Malaysia they had a huge

00:29:03,630 --> 00:29:07,530
growth on the number of people

00:29:05,640 --> 00:29:10,040
participated in Stack Overflow Singapore

00:29:07,530 --> 00:29:18,450
had a 45 percent since birth

00:29:10,040 --> 00:29:20,820
yes replication distribution oh I would

00:29:18,450 --> 00:29:22,860
love to do that okay that's my homework

00:29:20,820 --> 00:29:24,660
or you can help me anyone can run

00:29:22,860 --> 00:29:26,790
queries here will be really interesting

00:29:24,660 --> 00:29:34,590
to see which countries produces the most

00:29:26,790 --> 00:29:37,680
useful answers stay tuned yes so we also

00:29:34,590 --> 00:29:40,230
have all of the stock over the github

00:29:37,680 --> 00:29:42,840
code the open source projects we have a

00:29:40,230 --> 00:29:47,400
copy required so you can analyze code

00:29:42,840 --> 00:29:49,260
when release this two years ago when

00:29:47,400 --> 00:29:52,050
they took the screenshot the table was

00:29:49,260 --> 00:29:53,970
almost two terabytes now it's over two

00:29:52,050 --> 00:29:57,120
terabyte more than two hundred million

00:29:53,970 --> 00:30:00,570
unique files it's a table that has to

00:29:57,120 --> 00:30:03,780
the content of each file the size it's

00:30:00,570 --> 00:30:07,290
five unique files only shown here once

00:30:03,780 --> 00:30:09,660
and so we are disciplic 18 it you want

00:30:07,290 --> 00:30:12,510
to get the total number of bytes you can

00:30:09,660 --> 00:30:14,280
multiply the size by the number of

00:30:12,510 --> 00:30:17,340
copies and you get that we have more

00:30:14,280 --> 00:30:19,800
than 46 terabytes of code in this table

00:30:17,340 --> 00:30:22,170
and then remember

00:30:19,800 --> 00:30:25,380
some rules before quietly stable it's

00:30:22,170 --> 00:30:27,780
really important that just don't go and

00:30:25,380 --> 00:30:30,030
where is this table extract the data

00:30:27,780 --> 00:30:32,580
that you want to extract first because

00:30:30,030 --> 00:30:35,400
everyone has a free terabyte of analysis

00:30:32,580 --> 00:30:38,190
every month and querying a two terabyte

00:30:35,400 --> 00:30:41,880
table will take away your free terabyte

00:30:38,190 --> 00:30:44,250
pretty fast but I have left for you a

00:30:41,880 --> 00:30:45,930
table with all of the Java code all of

00:30:44,250 --> 00:30:47,640
the Python code and if you want to

00:30:45,930 --> 00:30:49,740
extract anything special you can all

00:30:47,640 --> 00:30:53,160
sort my help and I will leave that table

00:30:49,740 --> 00:30:55,860
publicly for you I also left a sample

00:30:53,160 --> 00:30:58,290
table that's way smaller and remember we

00:30:55,860 --> 00:31:00,810
only get open-source projects according

00:30:58,290 --> 00:31:03,030
to the license they have if we cannot

00:31:00,810 --> 00:31:07,140
determine that the licenses open source

00:31:03,030 --> 00:31:09,570
we don't copy it and now you can start

00:31:07,140 --> 00:31:11,730
looking at the real code you can brand

00:31:09,570 --> 00:31:14,190
regular expressions you can see for

00:31:11,730 --> 00:31:16,740
example this world the top imports the

00:31:14,190 --> 00:31:19,200
top growth in import in Java lab between

00:31:16,740 --> 00:31:22,140
these years people are doing way more

00:31:19,200 --> 00:31:24,750
injects now people are using mojito etc

00:31:22,140 --> 00:31:26,910
and then you can start looking at things

00:31:24,750 --> 00:31:27,450
right or are people linking to Stack

00:31:26,910 --> 00:31:30,540
Overflow

00:31:27,450 --> 00:31:32,340
within the code without words like this

00:31:30,540 --> 00:31:34,080
I'm looking for regular expression

00:31:32,340 --> 00:31:35,790
anything that looks like a link to stack

00:31:34,080 --> 00:31:37,950
overflow I can join it with my Stack

00:31:35,790 --> 00:31:39,870
Overflow data fit for example in

00:31:37,950 --> 00:31:42,690
JavaScript code these are the top linked

00:31:39,870 --> 00:31:44,480
questions right if there are reggae

00:31:42,690 --> 00:31:46,980
function in JavaScript

00:31:44,480 --> 00:31:50,130
I'm also have the number of views that

00:31:46,980 --> 00:31:51,720
these questions are getting one of the

00:31:50,130 --> 00:31:55,310
questions within our top number of views

00:31:51,720 --> 00:31:58,560
is how to create a new ad industry have

00:31:55,310 --> 00:32:01,590
it's linked from 600 files on github has

00:31:58,560 --> 00:32:05,610
tech 600,000 views on a stack overflow

00:32:01,590 --> 00:32:07,290
same with Python and this is how I

00:32:05,610 --> 00:32:09,480
extracted all of the Python code

00:32:07,290 --> 00:32:12,390
anything that ends with the PI or

00:32:09,480 --> 00:32:15,570
ipython notebook a big advice of Python

00:32:12,390 --> 00:32:18,870
code a gigabytes of ipython notebooks

00:32:15,570 --> 00:32:21,300
and this how is to search for the top

00:32:18,870 --> 00:32:23,460
imports within Python just look at the

00:32:21,300 --> 00:32:26,610
lines that start this way and extract

00:32:23,460 --> 00:32:28,350
what's there and top style references

00:32:26,610 --> 00:32:32,130
stack overflow questions from Python

00:32:28,350 --> 00:32:35,880
code and then you can look at the

00:32:32,130 --> 00:32:38,430
the question Sebastiaan did here how

00:32:35,880 --> 00:32:43,410
many people are copying code from Stack

00:32:38,430 --> 00:32:46,980
Overflow into github anyone here anyone

00:32:43,410 --> 00:32:50,040
wants to admit it so Sarah ten was

00:32:46,980 --> 00:32:52,830
asking that question and he found one of

00:32:50,040 --> 00:32:55,560
the most popular answers how to compare

00:32:52,830 --> 00:32:58,500
by size into human readable code the

00:32:55,560 --> 00:33:00,840
format in Java that's the top answer and

00:32:58,500 --> 00:33:02,430
then if you want to look for these it's

00:33:00,840 --> 00:33:05,010
not that easy because people change the

00:33:02,430 --> 00:33:07,590
name of the variable segmentation so he

00:33:05,010 --> 00:33:12,480
transformed this answer into a regular

00:33:07,590 --> 00:33:16,410
expression and with record even fetch

00:33:12,480 --> 00:33:19,530
well expression you can do it in a 3d

00:33:16,410 --> 00:33:22,190
time and he found I believe four hundred

00:33:19,530 --> 00:33:26,370
files that match this answer and only

00:33:22,190 --> 00:33:29,460
27% gave credits and they all look like

00:33:26,370 --> 00:33:31,470
a copy of the Stack Overflow answer so

00:33:29,460 --> 00:33:34,890
please when you copy code from Stack

00:33:31,470 --> 00:33:39,540
Overflow credited or serviced Ian will

00:33:34,890 --> 00:33:43,140
find me and how do you request teachers

00:33:39,540 --> 00:33:46,020
using data someone wanted in goal

00:33:43,140 --> 00:33:48,930
whatever I think have it right after

00:33:46,020 --> 00:33:52,260
expiration time sub time now they wanted

00:33:48,930 --> 00:33:56,040
to write after time until it's nicer but

00:33:52,260 --> 00:33:59,280
they didn't add any data so my teammate

00:33:56,040 --> 00:34:02,670
at that time Sal says that still working

00:33:59,280 --> 00:34:05,370
and go but not with me but with you he

00:34:02,670 --> 00:34:07,770
moved to a different company but he

00:34:05,370 --> 00:34:11,159
still does the kind of analysis he

00:34:07,770 --> 00:34:13,590
looked for all the projects would

00:34:11,159 --> 00:34:16,200
benefit from this and he found at least

00:34:13,590 --> 00:34:19,310
2,000 repositories that would benefit

00:34:16,200 --> 00:34:22,409
from this change and they've all Anton

00:34:19,310 --> 00:34:26,940
implemented this feature and someone

00:34:22,409 --> 00:34:29,760
else was asking also to to rename a city

00:34:26,940 --> 00:34:33,379
TLS config to make it standardizes

00:34:29,760 --> 00:34:36,210
between two different modules and

00:34:33,379 --> 00:34:38,879
process found that 700 repositories

00:34:36,210 --> 00:34:41,820
would break if they normalized this so

00:34:38,879 --> 00:34:44,070
they didn't and the important message

00:34:41,820 --> 00:34:45,149
here for you is that if you put your

00:34:44,070 --> 00:34:48,899
code on github

00:34:45,149 --> 00:34:52,649
if you open for real code you can your

00:34:48,899 --> 00:34:54,899
vodka your code comes as vaults because

00:34:52,649 --> 00:34:56,940
people can you don't need to do anything

00:34:54,899 --> 00:34:59,190
just put your code there and people that

00:34:56,940 --> 00:35:01,710
are interested in analyzing it will find

00:34:59,190 --> 00:35:04,109
it and will implement features that are

00:35:01,710 --> 00:35:06,029
more the most useful for you just and

00:35:04,109 --> 00:35:08,730
you don't need to do anything else other

00:35:06,029 --> 00:35:10,309
than open-source you can go beyond

00:35:08,730 --> 00:35:12,839
regular expressions you can do

00:35:10,309 --> 00:35:15,329
user-defined functions in JavaScript so

00:35:12,839 --> 00:35:18,599
for example to do static code analysis I

00:35:15,329 --> 00:35:22,799
download the JavaScript library from

00:35:18,599 --> 00:35:25,349
github called Jes killed and now I can

00:35:22,799 --> 00:35:27,749
run it inside the query and I just

00:35:25,349 --> 00:35:31,019
imported a script library of things man

00:35:27,749 --> 00:35:36,119
some people are also running arbitrary

00:35:31,019 --> 00:35:40,529
feel cold inside the query because you

00:35:36,119 --> 00:35:42,569
can compile the code to webassembly I

00:35:40,529 --> 00:35:46,380
have some people here that are doing

00:35:42,569 --> 00:35:48,509
exactly that yes you can run the kind of

00:35:46,380 --> 00:35:50,190
thing and this is a static code analysis

00:35:48,509 --> 00:35:52,170
of Jericho speed code what are the top

00:35:50,190 --> 00:35:56,099
warnings I have two minutes left so I

00:35:52,170 --> 00:35:59,549
will hurry up specialist versus TAS

00:35:56,099 --> 00:36:01,349
spaces tabs these were the rules how I

00:35:59,549 --> 00:36:05,190
analyzed this everyone wanted to know

00:36:01,349 --> 00:36:09,930
what's more popular spaces are way more

00:36:05,190 --> 00:36:11,999
popular except in law if you like if you

00:36:09,930 --> 00:36:17,160
like tops you can go to go and like

00:36:11,999 --> 00:36:20,720
where people just put - people have used

00:36:17,160 --> 00:36:23,670
this repository to fix vulnerabilities

00:36:20,720 --> 00:36:26,549
there was a team of 50 Googlers that

00:36:23,670 --> 00:36:29,180
went all around get have fix in the map

00:36:26,549 --> 00:36:32,819
catcher vulnerability it was pretty cool

00:36:29,180 --> 00:36:35,009
I love putting when you write also when

00:36:32,819 --> 00:36:36,660
you put your comments in sequel would

00:36:35,009 --> 00:36:39,930
you rather put them at the end of the

00:36:36,660 --> 00:36:42,559
line or at the start of the line anyone

00:36:39,930 --> 00:36:44,880
likes them at the start of the line I

00:36:42,559 --> 00:36:47,279
like it at the start of the line I know

00:36:44,880 --> 00:36:48,809
it's early but I wanted to demonstrate

00:36:47,279 --> 00:36:50,609
to everyone but it was better but it

00:36:48,809 --> 00:36:53,099
turns out yes way more people put them

00:36:50,609 --> 00:36:56,339
at the end but then the question is

00:36:53,099 --> 00:36:58,270
which breaks are more successful and how

00:36:56,339 --> 00:37:00,730
do you measure success stars stars

00:36:58,270 --> 00:37:02,590
year number of contributors activity and

00:37:00,730 --> 00:37:03,640
turns out that projects with like

00:37:02,590 --> 00:37:06,100
weather like this you can look at

00:37:03,640 --> 00:37:08,560
projects that allow you to put a comma

00:37:06,100 --> 00:37:11,050
at the start if I like them those

00:37:08,560 --> 00:37:15,610
projects are double a successful of the

00:37:11,050 --> 00:37:18,040
other projects so I get a win and till

00:37:15,610 --> 00:37:20,710
someone else proves that I ran the wrong

00:37:18,040 --> 00:37:24,310
query you can go and find me because all

00:37:20,710 --> 00:37:27,970
the raw data is enables here so please

00:37:24,310 --> 00:37:29,440
challenge these results just go be find

00:37:27,970 --> 00:37:31,810
the things you want to find tell me

00:37:29,440 --> 00:37:34,300
where I'm wrong and show up change these

00:37:31,810 --> 00:37:35,640
results you can be more active on github

00:37:34,300 --> 00:37:37,840
you can be more active on Stack Overflow

00:37:35,640 --> 00:37:40,690
tweet about what you're doing blood of

00:37:37,840 --> 00:37:42,280
blog people are measuring and looking at

00:37:40,690 --> 00:37:45,130
what you are doing so who wants to

00:37:42,280 --> 00:37:47,260
analyze github even github does it with

00:37:45,130 --> 00:37:50,110
bigquery I have a video with a list on

00:37:47,260 --> 00:37:52,240
one of the data scientists at github and

00:37:50,110 --> 00:37:54,730
I hope you get pretty interested in

00:37:52,240 --> 00:37:56,170
doing this there's way more I don't have

00:37:54,730 --> 00:37:59,860
time to talk about all of these blog

00:37:56,170 --> 00:38:01,660
posts in the last 40 seconds but you can

00:37:59,860 --> 00:38:04,450
go deeper you can publish I'll be very

00:38:01,660 --> 00:38:06,850
happy to eat we have also other than our

00:38:04,450 --> 00:38:08,170
$300 we have the startup program for

00:38:06,850 --> 00:38:12,040
with more than three thousand dollar

00:38:08,170 --> 00:38:13,690
credit talked to us about it and yes you

00:38:12,040 --> 00:38:15,850
can find me on github you can find me on

00:38:13,690 --> 00:38:18,130
reddit AMA Stack Overflow and you can

00:38:15,850 --> 00:38:20,740
give me feedback because I love feedback

00:38:18,130 --> 00:38:25,990
so please leave it there thank you very

00:38:20,740 --> 00:38:28,380
much anyone has a question in ten

00:38:25,990 --> 00:38:28,380
seconds

00:38:29,340 --> 00:38:32,609

YouTube URL: https://www.youtube.com/watch?v=UD3zEvPUfiM


