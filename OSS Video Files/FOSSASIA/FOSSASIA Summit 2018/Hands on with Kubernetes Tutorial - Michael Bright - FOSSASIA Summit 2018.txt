Title: Hands on with Kubernetes Tutorial - Michael Bright - FOSSASIA Summit 2018
Publication date: 2018-03-23
Playlist: FOSSASIA Summit 2018
Description: 
	Speaker: Michael Bright
Info: https://2018.fossasia.org/event/speakers.html#michael-bright3285

Kubernetes is taking a clear lead in container orchestration being adopted by all the major cloud/virtualization platforms (Google, Azure, probably AWS, VMWare).

This tutorial session will cover
    kubernetes concepts and architecture
    basic container orchestration using cli tools, apis (Python, Go)
    Exposing services
    scaling, rolling updates, rollbacks, healthchecks
    Kubernetes tools
          cli such as kubectl, kubeadm, helper tools such as kubectx
          higher-level tools such as Helm, Brigade
          use of Traefik as an Ingress controller

Based on previous labs, all tutorial materials will be freely available during and after the session allowing students to just watch, or follow along on their own laptop or to run the tutorial themselves after the conference.

Online resources will be provided to run the labs either on the students own laptop or using their cloud account.

Room: Event Hall 2-2
Track: Cloud, Container, DevOps
Date: Friday, 23rd March, 2018

Event Page: https://2018.fossasia.org/
Follow FOSSASIA on Twitter: https://twitter.com/fossasia/
Like FOSSASIA on Facebook: https://www.facebook.com/fossasia/ 

Produced by Engineers.SG
Captions: 
	00:00:22,870 --> 00:00:25,410
okay

00:00:33,670 --> 00:00:37,410
there are maybe it's the other one

00:00:40,320 --> 00:00:43,910
so I tried it up yes

00:00:48,520 --> 00:00:51,030
No

00:00:55,070 --> 00:00:58,210
[Music]

00:01:14,360 --> 00:01:17,410
fifteen minutes

00:01:20,100 --> 00:01:27,800
so what I have to 610 oh yeah okay

00:01:24,090 --> 00:01:27,800
right thank you

00:01:31,380 --> 00:01:40,210
okay good afternoon can you hear me okay

00:01:35,040 --> 00:01:45,630
yeah okay so I promised you a kubernetes

00:01:40,210 --> 00:01:47,320
tutorial so first a Mia culpa I

00:01:45,630 --> 00:01:49,810
suggested I would give you hands-on

00:01:47,320 --> 00:01:52,720
access and so on and I just realized

00:01:49,810 --> 00:01:54,940
when practicing with people in a two

00:01:52,720 --> 00:01:56,920
hour situation that this wouldn't

00:01:54,940 --> 00:01:59,650
translate to a one-hour session so I

00:01:56,920 --> 00:02:01,860
really do it in mode tutorial of doing

00:01:59,650 --> 00:02:04,060
things and showing you what I'm doing

00:02:01,860 --> 00:02:05,800
that if you want to follow along

00:02:04,060 --> 00:02:08,679
yourself either you've got your own

00:02:05,800 --> 00:02:11,020
Cuban every semester already or you do

00:02:08,679 --> 00:02:13,989
it after the event okay I hope that's

00:02:11,020 --> 00:02:16,239
okay river rock okay so I'm Michael

00:02:13,989 --> 00:02:19,209
bright I'm a developer advocate at

00:02:16,239 --> 00:02:21,790
containers containers are the creators

00:02:19,209 --> 00:02:25,060
of traffic some of you may know it it's

00:02:21,790 --> 00:02:27,310
reverse proxy load balancer and can be

00:02:25,060 --> 00:02:29,530
used as a kubernetes ingress controller

00:02:27,310 --> 00:02:31,890
so that's something I'll be showing as a

00:02:29,530 --> 00:02:31,890
demo

00:02:34,120 --> 00:02:38,890
just out of interest what people's

00:02:36,970 --> 00:02:41,680
experience here with kubernetes are you

00:02:38,890 --> 00:02:46,000
all fairly new to cuban entities or some

00:02:41,680 --> 00:02:47,290
people so who is totally new or pretty

00:02:46,000 --> 00:02:51,250
well to give a netizen

00:02:47,290 --> 00:02:54,129
yeah okay good you're the people I'm I'm

00:02:51,250 --> 00:02:58,120
aiming at one side and just out of

00:02:54,129 --> 00:03:01,150
interest is anyone here using traffic to

00:02:58,120 --> 00:03:06,579
use traffic already know do people know

00:03:01,150 --> 00:03:12,180
about traffic good thank you

00:03:06,579 --> 00:03:15,069
I just say this tutorial is open-source

00:03:12,180 --> 00:03:17,680
the initial version which is warm

00:03:15,069 --> 00:03:20,470
kinetise and lasers we've run about 3-4

00:03:17,680 --> 00:03:24,010
times and now this is the third or

00:03:20,470 --> 00:03:27,910
fourth time after I've run the purely

00:03:24,010 --> 00:03:31,720
kubernetes version and it's all on

00:03:27,910 --> 00:03:33,519
top and you're welcome to open any

00:03:31,720 --> 00:03:38,970
issues on it or just send me feedback

00:03:33,519 --> 00:03:38,970
directly I'm keen to have this evolve

00:03:39,030 --> 00:03:47,300
okay so this is what we will be covering

00:03:41,570 --> 00:03:51,660
basic concepts of kubernetes the basics

00:03:47,300 --> 00:03:55,440
command line client the dashboard then

00:03:51,660 --> 00:03:58,440
we look at running pops so if you know

00:03:55,440 --> 00:04:01,320
about containers and you know that body

00:03:58,440 --> 00:04:04,020
roll numbers the basic unit of execution

00:04:01,320 --> 00:04:06,150
within kubernetes is a pod which is one

00:04:04,020 --> 00:04:09,360
or more containers so look at that

00:04:06,150 --> 00:04:12,690
concept and running pods and what we

00:04:09,360 --> 00:04:14,700
call deployments we look at how to

00:04:12,690 --> 00:04:18,269
perform an rolling upgrade across our

00:04:14,700 --> 00:04:20,310
cluster and then how to expose our

00:04:18,269 --> 00:04:22,049
applications as services there are

00:04:20,310 --> 00:04:24,510
several ways of doing that and I will

00:04:22,049 --> 00:04:28,620
show just one way which is the ingress

00:04:24,510 --> 00:04:31,740
controller and this time which will very

00:04:28,620 --> 00:04:33,360
quickly just talk about Hell which is

00:04:31,740 --> 00:04:35,510
quite an interesting tool for keeping it

00:04:33,360 --> 00:04:35,510
is

00:04:36,729 --> 00:04:40,479
if you have to do this afterwards then

00:04:38,800 --> 00:04:43,180
there is a page that talks about a set

00:04:40,479 --> 00:04:45,789
of options for just simply running your

00:04:43,180 --> 00:04:52,530
own cluster the simplest way of course

00:04:45,789 --> 00:04:52,530
is to run mini-cooper a mini cube being

00:04:53,909 --> 00:04:58,499
we used to be just a VM for running

00:04:56,520 --> 00:05:03,599
kubernetes as a single node cluster

00:04:58,499 --> 00:05:06,089
within a VM there's also a non VM option

00:05:03,599 --> 00:05:08,520
as well as you can just run it with the

00:05:06,089 --> 00:05:12,029
docker to simulate a human it is cluster

00:05:08,520 --> 00:05:14,069
just one thing so you'll hear me talk

00:05:12,029 --> 00:05:16,229
about traffic and so on I mentioned in

00:05:14,069 --> 00:05:19,499
the dive work for containers with the

00:05:16,229 --> 00:05:23,789
craters of traffic and we're hiring by

00:05:19,499 --> 00:05:26,120
the way for remote workers do okay let's

00:05:23,789 --> 00:05:26,120
get started

00:05:30,750 --> 00:05:37,200
okay don't be put off by the fact that

00:05:35,220 --> 00:05:40,620
what are we showing you when I execute

00:05:37,200 --> 00:05:43,710
stuff mainly I'll be doing it within the

00:05:40,620 --> 00:05:45,210
cubit and the Jupiter environment you

00:05:43,710 --> 00:05:47,280
don't have to worry about what that is

00:05:45,210 --> 00:05:51,210
it's basically a notebook where you can

00:05:47,280 --> 00:05:53,810
mix markdown and executable code and so

00:05:51,210 --> 00:05:57,380
it's quite a nice way of documenting

00:05:53,810 --> 00:05:57,380
things as you go along

00:05:58,070 --> 00:06:04,860
so I'll start with some some slides and

00:06:01,440 --> 00:06:07,260
then go back into the notebook so Cuba

00:06:04,860 --> 00:06:10,170
net is in Kosovo what is it I mean it's

00:06:07,260 --> 00:06:13,500
a it's basically a cluster manager

00:06:10,170 --> 00:06:15,660
managing cluster of containers could be

00:06:13,500 --> 00:06:18,060
a whole data center that you're going to

00:06:15,660 --> 00:06:20,930
manage with it the the principle of

00:06:18,060 --> 00:06:23,220
course is that as we move towards

00:06:20,930 --> 00:06:25,230
micro-services we've got more and more

00:06:23,220 --> 00:06:27,980
containers running in our data center

00:06:25,230 --> 00:06:31,260
and it's becoming impossible for

00:06:27,980 --> 00:06:33,360
operators to you know take care of all

00:06:31,260 --> 00:06:35,640
of the details of deployment and you

00:06:33,360 --> 00:06:37,560
really need some sort of deployment

00:06:35,640 --> 00:06:41,730
platform which is going to allow you to

00:06:37,560 --> 00:06:45,480
say declaratively okay I want these

00:06:41,730 --> 00:06:48,390
services running kubernetes go away and

00:06:45,480 --> 00:06:49,440
take care of where they actually run

00:06:48,390 --> 00:06:51,419
okay

00:06:49,440 --> 00:06:54,990
and you want that platform as well tell

00:06:51,419 --> 00:06:57,060
you okay there's a well no don't even

00:06:54,990 --> 00:07:00,900
want it to tell you when there is a

00:06:57,060 --> 00:07:03,660
problem imagine maybe an ogre cluster

00:07:00,900 --> 00:07:07,250
goes down that'd be a physical node or

00:07:03,660 --> 00:07:09,900
the N or a pod or container it goes down

00:07:07,250 --> 00:07:12,470
you don't even want to be informed you

00:07:09,900 --> 00:07:15,300
just want to kubernetes just relaunch

00:07:12,470 --> 00:07:18,960
Europe resources and

00:07:15,300 --> 00:07:21,480
in place so if you know about cloud

00:07:18,960 --> 00:07:24,450
native and the discussion about pets and

00:07:21,480 --> 00:07:29,190
cattle you know from the old world all

00:07:24,450 --> 00:07:31,860
software and the MS tended to be pets if

00:07:29,190 --> 00:07:35,640
there was a problem with with a VM and

00:07:31,860 --> 00:07:37,200
would go in and try and fix it and do

00:07:35,640 --> 00:07:38,360
your best to care for it like you would

00:07:37,200 --> 00:07:40,620
for a pet

00:07:38,360 --> 00:07:44,160
whereas here with much more in a

00:07:40,620 --> 00:07:46,650
scenario of cattle where container dies

00:07:44,160 --> 00:07:47,310
then you just launched another one in

00:07:46,650 --> 00:07:50,510
its place

00:07:47,310 --> 00:07:54,360
okay very different philosophy where we

00:07:50,510 --> 00:07:57,890
tend to Claire what we want to be

00:07:54,360 --> 00:08:00,330
running on a cluster so historically

00:07:57,890 --> 00:08:03,630
kubernetes it's an open source project

00:08:00,330 --> 00:08:06,530
that was created by Google it was based

00:08:03,630 --> 00:08:08,670
on their experience with deploying

00:08:06,530 --> 00:08:12,600
containers within their infrastructure

00:08:08,670 --> 00:08:15,240
so notably in the internal projects of

00:08:12,600 --> 00:08:17,790
Fork and them again and they really

00:08:15,240 --> 00:08:20,730
wanted to bring the same principles into

00:08:17,790 --> 00:08:23,940
an open source project they donated list

00:08:20,730 --> 00:08:27,990
the CN CF cognitive computing foundation

00:08:23,940 --> 00:08:30,540
in 2015 and a lot of companies bought

00:08:27,990 --> 00:08:33,560
into that there's a container

00:08:30,540 --> 00:08:36,600
orchestration platform and it's

00:08:33,560 --> 00:08:39,890
currently at the 1.9 release shirley

00:08:36,600 --> 00:08:39,890
coq10 obviously

00:08:45,269 --> 00:08:47,959
we just talked

00:08:50,110 --> 00:08:56,410
okay this is just a Google Trends just

00:08:52,450 --> 00:08:57,910
showing the the tendency I have the

00:08:56,410 --> 00:08:59,380
different container orchestration

00:08:57,910 --> 00:09:00,670
engines there are more but I just

00:08:59,380 --> 00:09:03,640
compared docker swarm

00:09:00,670 --> 00:09:07,030
Apache ms-dos and kubernetes I we can

00:09:03,640 --> 00:09:09,730
see quite easily the blue line which is

00:09:07,030 --> 00:09:15,220
kubernetes has just taken off completely

00:09:09,730 --> 00:09:19,290
and in 2017 we've really seen the effect

00:09:15,220 --> 00:09:23,440
of that with some surprising or not

00:09:19,290 --> 00:09:25,300
announcements from Amazon everyone was

00:09:23,440 --> 00:09:27,880
expecting them to entre people in Italy

00:09:25,300 --> 00:09:32,770
services and they did that with their

00:09:27,880 --> 00:09:34,600
ApS but also Fargate services to me more

00:09:32,770 --> 00:09:36,870
of a surprise was docker and announced

00:09:34,600 --> 00:09:40,420
topic on that they would support

00:09:36,870 --> 00:09:44,650
kubernetes as an alternative container

00:09:40,420 --> 00:09:47,920
orchestration to dr. swarm we've seen

00:09:44,650 --> 00:09:51,450
new managed humanity services so this is

00:09:47,920 --> 00:09:53,640
where you will pay to user base via

00:09:51,450 --> 00:09:58,180
kubernetes control playing a dashboard

00:09:53,640 --> 00:10:01,690
to deploy a cluster in some other

00:09:58,180 --> 00:10:04,450
infrastructure could be out on Amazon

00:10:01,690 --> 00:10:09,530
ec2 for example could be on-premises

00:10:04,450 --> 00:10:11,540
actual physical nodes on your site

00:10:09,530 --> 00:10:16,000
so it's some new services launched from

00:10:11,540 --> 00:10:21,050
Microsoft and HP e and many others

00:10:16,000 --> 00:10:23,930
managed manageability space there are

00:10:21,050 --> 00:10:27,110
many other distributions one of the

00:10:23,930 --> 00:10:31,000
early adopters of kubernetes was read

00:10:27,110 --> 00:10:35,840
out their openshift pass is based

00:10:31,000 --> 00:10:38,300
implicitly on kubernetes others have

00:10:35,840 --> 00:10:42,200
been core OS with tecktonik who

00:10:38,300 --> 00:10:45,410
purchased in both pirate hat can i also

00:10:42,200 --> 00:10:48,790
have their distribution and we see new

00:10:45,410 --> 00:10:51,500
tools there are many many tools

00:10:48,790 --> 00:10:52,550
appearing around kubernetes there's one

00:10:51,500 --> 00:10:55,940
which is looking particularly

00:10:52,550 --> 00:10:59,810
interesting today which is hell which

00:10:55,940 --> 00:11:02,480
essentially is a sort of allows you to

00:10:59,810 --> 00:11:05,240
do create whole stacks of applications a

00:11:02,480 --> 00:11:09,790
bit like a stack with the docker swarm

00:11:05,240 --> 00:11:11,750
today but also with a catalogue

00:11:09,790 --> 00:11:15,790
gratifications that you can pull them

00:11:11,750 --> 00:11:15,790
off full stacks you can pull down

00:11:16,420 --> 00:11:21,110
okay so if we look at the Cuban SS

00:11:19,100 --> 00:11:24,500
architecture this is a bit small this

00:11:21,110 --> 00:11:28,790
diagram was really just to show three

00:11:24,500 --> 00:11:32,030
things basically we have master and

00:11:28,790 --> 00:11:34,520
worker notes normally in production at

00:11:32,030 --> 00:11:37,160
least it's on the worker nodes that you

00:11:34,520 --> 00:11:41,810
actually run pods with containers in

00:11:37,160 --> 00:11:45,560
them and the master node is the V master

00:11:41,810 --> 00:11:49,100
nodes are the control plane nodes that

00:11:45,560 --> 00:11:54,440
will monitor the workers and distribute

00:11:49,100 --> 00:11:57,940
tasks to the workers there's also some

00:11:54,440 --> 00:12:01,070
sort of distributed key-value store so

00:11:57,940 --> 00:12:03,380
etcd which is used to manage the

00:12:01,070 --> 00:12:06,110
configurator and in particular to say

00:12:03,380 --> 00:12:08,780
which of those masters we have there's

00:12:06,110 --> 00:12:12,710
only one here in this diagram which of

00:12:08,780 --> 00:12:15,260
them will be the leader and so this is

00:12:12,710 --> 00:12:19,600
something that I don't know what size

00:12:15,260 --> 00:12:22,430
kubernetes cluster scale today that

00:12:19,600 --> 00:12:24,230
essentially yes we're talking about you

00:12:22,430 --> 00:12:26,420
might have a whole data center or you

00:12:24,230 --> 00:12:28,840
might have several clusters in a date

00:12:26,420 --> 00:12:28,840
center

00:12:30,229 --> 00:12:35,179
so if we look just a bit closer at the

00:12:33,389 --> 00:12:39,329
masternodes

00:12:35,179 --> 00:12:42,359
there are three main components within

00:12:39,329 --> 00:12:45,899
the masternode apart from the etc the

00:12:42,359 --> 00:12:47,789
demon itself at the API server so most

00:12:45,899 --> 00:12:50,970
things you do Cuba Nettie's will be

00:12:47,789 --> 00:12:55,619
either using command-line tool like Cuba

00:12:50,970 --> 00:12:58,649
CTL or the the dashboard or some other

00:12:55,619 --> 00:13:01,019
application built from the API that is

00:12:58,649 --> 00:13:04,049
the way the that an operator will

00:13:01,019 --> 00:13:06,389
interact with the cluster there is a

00:13:04,049 --> 00:13:10,049
scheduler and a controller so as I said

00:13:06,389 --> 00:13:14,429
Cuba net is a very much base on the idea

00:13:10,049 --> 00:13:16,319
of declaring what you want to be running

00:13:14,429 --> 00:13:18,599
on your cluster it's very much a

00:13:16,319 --> 00:13:21,899
declarative approach and in the same way

00:13:18,599 --> 00:13:25,669
the controller is actually think about

00:13:21,899 --> 00:13:29,339
50 software control loops each of which

00:13:25,669 --> 00:13:33,629
checking some particular aspect and they

00:13:29,339 --> 00:13:35,699
notice a discrepancy let's say you've

00:13:33,629 --> 00:13:39,119
declared that you want ten replicas of

00:13:35,699 --> 00:13:41,789
the Apache web service for some reason

00:13:39,119 --> 00:13:44,549
there are only nine a pod has died or a

00:13:41,789 --> 00:13:46,679
node has gone down so on the controller

00:13:44,549 --> 00:13:50,939
will detect that and it will tell the

00:13:46,679 --> 00:13:55,159
scheduler okay we need one more Apache

00:13:50,939 --> 00:13:57,539
web service the scheduler then based on

00:13:55,159 --> 00:14:00,299
constraints if there are any will then

00:13:57,539 --> 00:14:05,119
decide where that new evacuate server

00:14:00,299 --> 00:14:05,119
should be deployed on which worker node

00:14:05,260 --> 00:14:09,430
are there any questions about

00:14:13,100 --> 00:14:21,560
okay mmm so if we look at the worker

00:14:16,520 --> 00:14:25,100
nodes few more elements in that so the

00:14:21,560 --> 00:14:28,160
main contact point is the cubelet so

00:14:25,100 --> 00:14:30,020
this manages the API that the master

00:14:28,160 --> 00:14:32,600
node will use to talk to the worker

00:14:30,020 --> 00:14:38,300
nodes obviously there's a container

00:14:32,600 --> 00:14:41,180
engine so typically today at docker but

00:14:38,300 --> 00:14:43,310
rocket is already supported who is

00:14:41,180 --> 00:14:46,660
seeing the creation of new container

00:14:43,310 --> 00:14:50,510
engines so there is a specification CRI

00:14:46,660 --> 00:14:52,790
containing a runtime interface which has

00:14:50,510 --> 00:14:55,460
also been used by by docker already and

00:14:52,790 --> 00:14:59,780
Red Hat have created one who stands

00:14:55,460 --> 00:15:03,290
iation of that view which then provides

00:14:59,780 --> 00:15:09,220
a new container and time so we will see

00:15:03,290 --> 00:15:12,140
choice in that area cue proxy so and

00:15:09,220 --> 00:15:15,500
into white pods first the pods they are

00:15:12,140 --> 00:15:17,780
one or more containers in each pod they

00:15:15,500 --> 00:15:21,380
are on a separate network so to get

00:15:17,780 --> 00:15:24,410
access to the actual application sorting

00:15:21,380 --> 00:15:27,290
those pods the cube proxy is the one

00:15:24,410 --> 00:15:27,779
that will provide the routing on to

00:15:27,290 --> 00:15:31,889
those in

00:15:27,779 --> 00:15:35,819
networks there are various at almost

00:15:31,889 --> 00:15:38,730
like cubed DNS to to do service allowing

00:15:35,819 --> 00:15:42,899
service discovery and so on and there's

00:15:38,730 --> 00:15:47,160
the dashboard which itself is is an

00:15:42,899 --> 00:15:50,040
add-on and in fact all of those elements

00:15:47,160 --> 00:15:53,749
themselves can can run on the containers

00:15:50,040 --> 00:15:53,749
on a cube system as we will see

00:15:54,890 --> 00:16:01,310
so the pods I said the warm on more

00:15:59,000 --> 00:16:03,380
containers so the philosophy just as

00:16:01,310 --> 00:16:06,830
likely the containers it philosophy is

00:16:03,380 --> 00:16:12,770
really to have one or more containers in

00:16:06,830 --> 00:16:16,160
a pod in a pod that's right I mean one

00:16:12,770 --> 00:16:18,200
or more process in the container in the

00:16:16,160 --> 00:16:21,620
same way a part will have one or more

00:16:18,200 --> 00:16:24,170
containers in it but the idea is that

00:16:21,620 --> 00:16:26,830
you should have you know one principle

00:16:24,170 --> 00:16:29,450
functionality provided by this pod and

00:16:26,830 --> 00:16:31,280
if there are other containers and they

00:16:29,450 --> 00:16:34,820
should be providing sort of supporting

00:16:31,280 --> 00:16:38,780
function to that main container so for

00:16:34,820 --> 00:16:41,360
example I don't know could be Apache web

00:16:38,780 --> 00:16:45,110
server again maybe another container

00:16:41,360 --> 00:16:47,950
which is maybe flu and D maybe doing

00:16:45,110 --> 00:16:51,940
some distributed loving to to elsewhere

00:16:47,950 --> 00:16:54,200
or another good example for a web server

00:16:51,940 --> 00:16:58,490
you might have a container which is

00:16:54,200 --> 00:17:01,250
doing I get wrap or sink it would be

00:16:58,490 --> 00:17:04,040
pulling from a gate right for any

00:17:01,250 --> 00:17:06,080
updates which are actually the static

00:17:04,040 --> 00:17:07,529
content of the website that you're

00:17:06,080 --> 00:17:09,929
serving up

00:17:07,529 --> 00:17:13,720
those are the two quite distinct

00:17:09,929 --> 00:17:15,639
functionalities but the red bow is

00:17:13,720 --> 00:17:18,879
supporting for the main web server

00:17:15,639 --> 00:17:24,999
functionality and those containers a

00:17:18,879 --> 00:17:29,769
share namespaces so these will have

00:17:24,999 --> 00:17:34,600
different process IDs within them they

00:17:29,769 --> 00:17:36,279
will have the same IP address the

00:17:34,600 --> 00:17:38,350
Sheridan same IP address and they

00:17:36,279 --> 00:17:40,090
mustn't use the same ports and so on so

00:17:38,350 --> 00:17:45,039
it's an abstraction which is a little

00:17:40,090 --> 00:17:49,419
bit like a machine in fact it's actually

00:17:45,039 --> 00:17:50,950
Oh an important point is as I say you

00:17:49,419 --> 00:17:53,139
know a pod will be one main

00:17:50,950 --> 00:17:56,320
functionality and then some supporting

00:17:53,139 --> 00:17:59,139
functionality that really tightly linked

00:17:56,320 --> 00:18:02,289
and the idea is that as you scale this

00:17:59,139 --> 00:18:05,919
is the minimum functionality that you

00:18:02,289 --> 00:18:09,429
want to scale I want to scale from 10 to

00:18:05,919 --> 00:18:11,739
20 web servers what I need let's say the

00:18:09,429 --> 00:18:14,039
the get rep of associated with each of

00:18:11,739 --> 00:18:14,039
those

00:18:17,290 --> 00:18:19,920
okay

00:18:31,260 --> 00:18:35,050
so we've seen a moment the command-line

00:18:34,360 --> 00:18:37,510
client

00:18:35,050 --> 00:18:40,630
I heard bad habit of working from the

00:18:37,510 --> 00:18:42,640
command line all the time but I should

00:18:40,630 --> 00:18:44,620
try and come back to the dashboard as

00:18:42,640 --> 00:18:47,820
much resourceful because it's a pretty

00:18:44,620 --> 00:18:47,820
nice dashboard

00:18:51,110 --> 00:18:58,550
so let me rather than show you slides

00:18:53,940 --> 00:18:58,550
here we actually launched that dashboard

00:19:11,140 --> 00:19:20,410
okay so okay Cuban SS dashboard first

00:19:15,310 --> 00:19:25,450
thing to notice is within our cluster we

00:19:20,410 --> 00:19:27,670
have three namespaces when we run we can

00:19:25,450 --> 00:19:30,700
create new namespaces of course when we

00:19:27,670 --> 00:19:32,370
run new bobs by default they will

00:19:30,700 --> 00:19:35,770
obviously go into the default namespace

00:19:32,370 --> 00:19:40,150
so which is empty at the moment I'm not

00:19:35,770 --> 00:19:43,210
creating anything other namespaces are

00:19:40,150 --> 00:19:47,040
too public and cube system but if we we

00:19:43,210 --> 00:19:47,040
can change into cube system

00:19:51,040 --> 00:19:55,610
and there we see already that there are

00:19:53,630 --> 00:20:00,230
some things deployed

00:19:55,610 --> 00:20:03,950
Jib dns to dashboard so the dashboard is

00:20:00,230 --> 00:20:05,570
showing itself in the system then we can

00:20:03,950 --> 00:20:09,020
interrogate obviously the number of

00:20:05,570 --> 00:20:13,400
there but the replica sets of Javan

00:20:09,020 --> 00:20:16,810
presenters as a concept and pods so in

00:20:13,400 --> 00:20:16,810
fact all that

00:20:19,340 --> 00:20:27,200
a set of bugs that represent our

00:20:23,170 --> 00:20:30,320
kubernetes cluster itself and in this

00:20:27,200 --> 00:20:36,430
example I'm running an a three node

00:20:30,320 --> 00:20:36,430
system one master and two worker nodes

00:20:40,730 --> 00:20:43,390
default

00:20:47,640 --> 00:20:54,470
I'll go back that spike that into Tina

00:21:15,510 --> 00:21:21,970
okay so as I mentioned for this part of

00:21:18,610 --> 00:21:25,440
the lab are we working with this three

00:21:21,970 --> 00:21:28,360
node cluster it's actually a complete

00:21:25,440 --> 00:21:30,400
complicated environment so later when

00:21:28,360 --> 00:21:32,820
doing ingress control I will switch to

00:21:30,400 --> 00:21:36,160
another Mini Cooper based environment

00:21:32,820 --> 00:21:39,390
but I wanted to show that working in

00:21:36,160 --> 00:21:39,390
Multi multi Nolan

00:21:40,350 --> 00:21:45,600
okay

00:21:42,600 --> 00:21:45,600
so

00:21:50,540 --> 00:21:54,010
let me just do some cleanup

00:21:57,140 --> 00:22:01,720
I see I did still have some things wrong

00:22:03,560 --> 00:22:06,010
oops

00:22:11,300 --> 00:22:16,050
advantage of the notebook hissed as it

00:22:13,440 --> 00:22:18,480
keeps historical everything I've done so

00:22:16,050 --> 00:22:22,080
allows me to archive with the whole

00:22:18,480 --> 00:22:25,590
tutorial but to run it the better I like

00:22:22,080 --> 00:22:29,190
that stuff so so I mentioned the command

00:22:25,590 --> 00:22:31,590
cube CDL normally I extend or cube

00:22:29,190 --> 00:22:33,810
controls and the way I spend time just

00:22:31,590 --> 00:22:35,700
showing a bit the option so that but I

00:22:33,810 --> 00:22:42,770
really want to try and keep them two to

00:22:35,700 --> 00:22:46,340
one hour so I do a cube CTL get all so

00:22:42,770 --> 00:22:49,020
basically with get we can interrogate

00:22:46,340 --> 00:22:52,440
services deployments replica sets and so

00:22:49,020 --> 00:22:56,100
on you'll be seeing in a moment if we do

00:22:52,440 --> 00:23:00,380
all it will give us those types of

00:22:56,100 --> 00:23:00,380
resources from the from the start

00:23:03,800 --> 00:23:10,520
so if we look at the most basic way of

00:23:07,920 --> 00:23:14,940
starting pods and recoupment is cluster

00:23:10,520 --> 00:23:17,940
the quick and dirty is cube CTL run and

00:23:14,940 --> 00:23:19,790
what this does behind the scenes is it

00:23:17,940 --> 00:23:22,980
creates something called the employment

00:23:19,790 --> 00:23:26,310
which is self crater a replica set and

00:23:22,980 --> 00:23:29,880
then we'll create pods that will

00:23:26,310 --> 00:23:32,900
actually implement our application so

00:23:29,880 --> 00:23:37,620
what are these concepts the deployment

00:23:32,900 --> 00:23:39,570
represents essentially a deployment so

00:23:37,620 --> 00:23:42,210
the deployment of radicular version of

00:23:39,570 --> 00:23:44,910
an application I will see that when we

00:23:42,210 --> 00:23:47,100
do a rolling upgrade this is the

00:23:44,910 --> 00:23:48,690
resource that will take care of of

00:23:47,100 --> 00:23:52,770
grading from one version real

00:23:48,690 --> 00:23:56,580
application to another it creates a a

00:23:52,770 --> 00:23:58,530
replica set which is responsible for

00:23:56,580 --> 00:24:01,660
obviously creating the number of

00:23:58,530 --> 00:24:03,670
replicas that we asked for

00:24:01,660 --> 00:24:06,760
and in this case I specified replicas

00:24:03,670 --> 00:24:09,280
equal to so we have two parts of course

00:24:06,760 --> 00:24:13,320
a lower level then each part will have

00:24:09,280 --> 00:24:13,320
one or more containers

00:24:16,210 --> 00:24:20,169
okay so I'm going to do

00:24:20,950 --> 00:24:27,450
in lifecycle hope

00:24:23,190 --> 00:24:36,300
I'm going to do a cube run of this image

00:24:27,450 --> 00:24:39,750
of this image key we test k8s demo : 1

00:24:36,300 --> 00:24:43,170
so the : 1 is standard docker image

00:24:39,750 --> 00:24:47,760
notation same version 1 of this this

00:24:43,170 --> 00:24:53,100
image this is basically a deployment

00:24:47,760 --> 00:24:55,260
called the same thing k8s demo I'm going

00:24:53,100 --> 00:24:56,940
to apply a label I haven't talked about

00:24:55,260 --> 00:25:00,390
the concept of labels if something is

00:24:56,940 --> 00:25:03,180
very important in kubernetes essentially

00:25:00,390 --> 00:25:05,400
you can kubernetes already applies

00:25:03,180 --> 00:25:08,340
labels to various resources and you can

00:25:05,400 --> 00:25:14,220
explicitly apply labels and it's a way

00:25:08,340 --> 00:25:16,800
of marking things so for example if

00:25:14,220 --> 00:25:21,470
you're running on the same cluster you

00:25:16,800 --> 00:25:24,540
are only development of test pods

00:25:21,470 --> 00:25:26,640
staging pods and production pods I don't

00:25:24,540 --> 00:25:28,410
recommend it but if it that's what

00:25:26,640 --> 00:25:30,600
you're doing then you could label

00:25:28,410 --> 00:25:33,549
ok I'm launching this just a test and I

00:25:30,600 --> 00:25:36,190
would say you know

00:25:33,549 --> 00:25:39,519
status equals test or something and it

00:25:36,190 --> 00:25:42,220
would be a way of late if I'd want to

00:25:39,519 --> 00:25:45,190
just clean up I could did he just the

00:25:42,220 --> 00:25:49,149
test bots for example not touching my

00:25:45,190 --> 00:25:51,580
production environment generally labels

00:25:49,149 --> 00:25:57,009
are really useful I mean another thing

00:25:51,580 --> 00:25:59,200
is imagine the nodes in your cluster you

00:25:57,009 --> 00:26:02,019
might have noted ich Euler physical

00:25:59,200 --> 00:26:06,129
properties you might have nodes that

00:26:02,019 --> 00:26:08,529
have a GPU graphics card particularly

00:26:06,129 --> 00:26:11,200
good for the high intensive compute

00:26:08,529 --> 00:26:14,710
operations you might have nodes that

00:26:11,200 --> 00:26:17,950
have SSDs others that have disk drives

00:26:14,710 --> 00:26:21,039
and they it would be useful for

00:26:17,950 --> 00:26:23,470
different types of applications okay so

00:26:21,039 --> 00:26:26,529
you could use labeling to then select

00:26:23,470 --> 00:26:29,799
and say when you run apart to say okay I

00:26:26,529 --> 00:26:33,370
want to run this only on nodes that have

00:26:29,799 --> 00:26:37,240
a GPU

00:26:33,370 --> 00:26:40,990
and I just explained tables and as

00:26:37,240 --> 00:26:45,940
before I will say we want to replicas I

00:26:40,990 --> 00:26:47,730
went the pod to expose port 8080 I'm

00:26:45,940 --> 00:26:50,890
going to do a cube CT I'll get all

00:26:47,730 --> 00:26:54,360
immediately behind that just to grab it

00:26:50,890 --> 00:26:54,360
in the intermediate state

00:26:54,370 --> 00:27:03,429
okay so that first line deployment

00:27:00,700 --> 00:27:06,490
captain kts demo created that's the

00:27:03,429 --> 00:27:10,659
output of the run the command and then

00:27:06,490 --> 00:27:13,360
the get all curiously list the

00:27:10,659 --> 00:27:17,020
deployment is twice in the replica sets

00:27:13,360 --> 00:27:20,610
twice so I'll start looking from here so

00:27:17,020 --> 00:27:26,380
it's launched deployment it says here

00:27:20,610 --> 00:27:28,840
desired to saying that basically we want

00:27:26,380 --> 00:27:32,590
I think that's Hobbs rather than

00:27:28,840 --> 00:27:34,840
containers at this level we've declared

00:27:32,590 --> 00:27:37,929
that we want to wreck replicas or this

00:27:34,840 --> 00:27:42,520
pod there are currently two is already

00:27:37,929 --> 00:27:44,549
bombs them they're up to date but zero

00:27:42,520 --> 00:27:48,240
are available

00:27:44,549 --> 00:27:51,309
similarly the level of the replica set

00:27:48,240 --> 00:27:55,630
there are two of them desired and

00:27:51,309 --> 00:27:58,779
present they don't already I feel look

00:27:55,630 --> 00:28:00,730
at the pod we can see why it's in the

00:27:58,779 --> 00:28:02,679
status container creating so typically

00:28:00,730 --> 00:28:05,289
it's actually pulling the docker image

00:28:02,679 --> 00:28:08,059
off the docker hub

00:28:05,289 --> 00:28:10,700
probably not the case in this this

00:28:08,059 --> 00:28:12,529
example cuz I had already done that but

00:28:10,700 --> 00:28:16,490
still there's a little time if we can

00:28:12,529 --> 00:28:19,429
contain the creation and here they're

00:28:16,490 --> 00:28:23,210
ready we have zero of one it's actually

00:28:19,429 --> 00:28:26,750
telling us that's zero containers out of

00:28:23,210 --> 00:28:29,649
one desire a particular pod specifies

00:28:26,750 --> 00:28:29,649
only one container

00:28:40,120 --> 00:28:43,110
okay oops

00:28:47,020 --> 00:28:56,350
okay I'm gonna run that command again

00:28:49,220 --> 00:28:56,350
it'll be basically the same promise

00:28:56,549 --> 00:29:07,379
except this now we see two available to

00:29:04,109 --> 00:29:09,539
ready and of course both pubs are

00:29:07,379 --> 00:29:11,989
running with one container out of one

00:29:09,539 --> 00:29:11,989
okay

00:29:12,140 --> 00:29:19,190
just to show an example of the sort of

00:29:14,400 --> 00:29:19,190
output we get to it they're cubes ETL

00:29:22,120 --> 00:29:29,019
we can also explicitly interrogate the

00:29:25,960 --> 00:29:32,649
pods deployments and so on and with get

00:29:29,019 --> 00:29:35,110
pots taking the option wide we get just

00:29:32,649 --> 00:29:39,549
a little more information we had here

00:29:35,110 --> 00:29:42,730
before this is the IP address of pot

00:29:39,549 --> 00:29:44,860
that's created and this is obviously the

00:29:42,730 --> 00:29:49,450
node on which the pot was assigned

00:29:44,860 --> 00:29:52,450
so normally you run pots only on the

00:29:49,450 --> 00:29:56,289
worker nodes though if this was a single

00:29:52,450 --> 00:29:58,779
node cluster we only have a master so

00:29:56,289 --> 00:30:01,929
for development purposes you can take a

00:29:58,779 --> 00:30:06,070
node allowing that to render pods as

00:30:01,929 --> 00:30:07,840
well but if you were to scale to 10 pods

00:30:06,070 --> 00:30:10,840
here we would see that it would all be

00:30:07,840 --> 00:30:16,590
distributed across the worker nodes I'd

00:30:10,840 --> 00:30:16,590
want to know - interesting as well

00:30:21,110 --> 00:30:26,050
by - okay

00:30:29,480 --> 00:30:34,900
I can see the note we have here what I'm

00:30:32,480 --> 00:30:34,900
going to do

00:30:39,960 --> 00:30:46,090
so as a command called describe which

00:30:43,960 --> 00:30:49,210
gives much much more detailed

00:30:46,090 --> 00:30:51,940
information a lot of information if I

00:30:49,210 --> 00:30:54,789
look at those nodes we can see the

00:30:51,940 --> 00:30:57,580
actual IP address of the nodes

00:30:54,789 --> 00:31:01,809
themselves and we can see that but I

00:30:57,580 --> 00:31:03,489
know that these are / 16 subnets knowing

00:31:01,809 --> 00:31:07,029
that we can see that these are a

00:31:03,489 --> 00:31:10,059
different subnet and the pops and in

00:31:07,029 --> 00:31:13,269
fact I think that every deployment we

00:31:10,059 --> 00:31:20,200
create and creates a new subnet

00:31:13,269 --> 00:31:24,700
specifically to those BOTS okay so how

00:31:20,200 --> 00:31:27,429
can we access our applications I'm going

00:31:24,700 --> 00:31:30,009
to use that information about the IP

00:31:27,429 --> 00:31:31,929
address of the pods again this is not

00:31:30,009 --> 00:31:33,789
how you do it that I'm working through

00:31:31,929 --> 00:31:36,549
to the different ways of accessing your

00:31:33,789 --> 00:31:39,879
application given that we have the IP

00:31:36,549 --> 00:31:45,029
address of the pods with a bit of bash

00:31:39,879 --> 00:31:47,569
magic we can pull out those IP addresses

00:31:45,029 --> 00:31:47,569
okay

00:31:49,520 --> 00:31:55,760
and then we can do a occur on the port

00:31:52,100 --> 00:32:00,490
8080 that we were exposing okay this is

00:31:55,760 --> 00:32:00,490
what we get and the other one

00:32:03,030 --> 00:32:07,710
can't can't see both but basically

00:32:05,700 --> 00:32:14,100
that's that's a different container name

00:32:07,710 --> 00:32:17,190
from the other one okay what happens if

00:32:14,100 --> 00:32:19,890
I pop die so I say well yeah we will

00:32:17,190 --> 00:32:23,070
automatically not launch another one so

00:32:19,890 --> 00:32:26,240
I'm just meant to get the ID of the

00:32:23,070 --> 00:32:26,240
first one of those pods

00:32:29,060 --> 00:32:32,680
and I'm going to delete that pod

00:32:34,800 --> 00:32:40,410
I don't quit Lee get pods behind it just

00:32:38,010 --> 00:32:46,050
to show okay we're in this intermediate

00:32:40,410 --> 00:32:48,030
state so that first one and then s5 is

00:32:46,050 --> 00:32:50,610
already in the terminating state it's

00:32:48,030 --> 00:32:53,070
not quite finished yet we could see that

00:32:50,610 --> 00:32:56,809
obviously the the controller has

00:32:53,070 --> 00:32:59,400
detected that that I'll just go down

00:32:56,809 --> 00:33:03,540
well actually would even know in this

00:32:59,400 --> 00:33:05,370
video it's creating another container in

00:33:03,540 --> 00:33:07,830
place and a lot of the operations that

00:33:05,370 --> 00:33:10,020
would happen within kubernetes will be

00:33:07,830 --> 00:33:12,390
on this basis of you want to make a

00:33:10,020 --> 00:33:15,900
change or you actually just kill the

00:33:12,390 --> 00:33:17,280
existing pods and launch others in the

00:33:15,900 --> 00:33:22,580
place and we'll see that bit there

00:33:17,280 --> 00:33:22,580
rolling upgrades yeah

00:33:22,670 --> 00:33:30,290
that's okay so now we just have two

00:33:26,870 --> 00:33:34,600
nodes again of one of them that you want

00:33:30,290 --> 00:33:34,600
who have you been running for 49 seconds

00:33:56,270 --> 00:34:06,440
okay so we've seen how to launch pods by

00:34:01,360 --> 00:34:08,450
deployment and replica set actually

00:34:06,440 --> 00:34:09,919
cutting them the tutorial - one hour

00:34:08,450 --> 00:34:12,830
just one point that I didn't mention is

00:34:09,919 --> 00:34:15,649
so I've been creating those from just a

00:34:12,830 --> 00:34:19,190
cube CTL run command that that is the

00:34:15,649 --> 00:34:21,679
quick and dirty method the way you were

00:34:19,190 --> 00:34:24,500
to create resources and we'll see it a

00:34:21,679 --> 00:34:30,050
bit later is we tend to put those in a

00:34:24,500 --> 00:34:32,000
llamo file to actually again declare the

00:34:30,050 --> 00:34:34,040
overall set of resources that you want

00:34:32,000 --> 00:34:38,090
with your system and we would actually

00:34:34,040 --> 00:34:40,330
do a cube CTL create or apply of that

00:34:38,090 --> 00:34:42,750
yellow file

00:34:40,330 --> 00:34:45,010
which is quite nice because you can also

00:34:42,750 --> 00:34:47,800
on the other hand when you want to stop

00:34:45,010 --> 00:34:49,750
things you can do a QC TL and delete or

00:34:47,800 --> 00:34:53,040
if you want to modify parameters you do

00:34:49,750 --> 00:34:53,040
a cube CTL apply

00:34:53,159 --> 00:35:02,099
okay so when we start doing stuffy I'm

00:34:58,440 --> 00:35:04,049
going to use a different cluster it's no

00:35:02,099 --> 00:35:09,180
longer this mostly no cursor it's just a

00:35:04,049 --> 00:35:11,369
mini cube of single node in the cube I'm

00:35:09,180 --> 00:35:13,859
going to show other ways of accessing

00:35:11,369 --> 00:35:15,809
our application Asli what I just showed

00:35:13,859 --> 00:35:21,119
I was accessing the pod directly that

00:35:15,809 --> 00:35:23,730
that's no good I had to know the IP

00:35:21,119 --> 00:35:26,250
address of a particular pod type said it

00:35:23,730 --> 00:35:29,099
access it and also I was accessing

00:35:26,250 --> 00:35:31,259
directly an internal network so as an

00:35:29,099 --> 00:35:35,900
owner so let's look at how we can use

00:35:31,259 --> 00:35:35,900
services to expose those pods

00:35:36,060 --> 00:35:43,480
so basic principle is you will have a

00:35:39,970 --> 00:35:46,450
service which are going to expose one or

00:35:43,480 --> 00:35:49,810
more IP addresses one or more ports so

00:35:46,450 --> 00:35:51,610
some external user can get to those

00:35:49,810 --> 00:35:54,640
parts okay and there are different ways

00:35:51,610 --> 00:35:58,150
of doing that and it's important as well

00:35:54,640 --> 00:36:01,180
not just because users shouldn't have

00:35:58,150 --> 00:36:03,340
access to a part which is internal but

00:36:01,180 --> 00:36:05,440
as well because of this whole nature are

00:36:03,340 --> 00:36:08,560
when we change things pots will come and

00:36:05,440 --> 00:36:10,890
go we can't keep track of those part of

00:36:08,560 --> 00:36:10,890
IP addresses

00:36:13,530 --> 00:36:20,230
okay so there are there are many ways

00:36:15,970 --> 00:36:22,750
actually but at least a purple I haven't

00:36:20,230 --> 00:36:25,660
listed here these are maybe three most

00:36:22,750 --> 00:36:28,740
disparate interesting ways of creating a

00:36:25,660 --> 00:36:28,740
service to access

00:36:29,590 --> 00:36:36,730
our our application first one is note

00:36:33,010 --> 00:36:40,500
port but I'll skip to them Forex

00:36:36,730 --> 00:36:45,610
lightness so the idea of Note port is

00:36:40,500 --> 00:36:49,240
that you will expose the IP address of

00:36:45,610 --> 00:36:51,880
each worker node and a particular port

00:36:49,240 --> 00:36:56,530
that will be used to access one

00:36:51,880 --> 00:36:58,810
application okay so well yeah but that

00:36:56,530 --> 00:37:00,550
means you don't have to know the

00:36:58,810 --> 00:37:02,860
addresses of the pods anymore you don't

00:37:00,550 --> 00:37:04,870
have to assess that's internal network

00:37:02,860 --> 00:37:07,030
but you still have to know the address

00:37:04,870 --> 00:37:10,540
of the worker node which might go away

00:37:07,030 --> 00:37:13,170
be replaced by another one and it's also

00:37:10,540 --> 00:37:16,210
no doubt an internal networking as well

00:37:13,170 --> 00:37:18,280
so that's really something that can be

00:37:16,210 --> 00:37:21,790
useful maybe for internal testing

00:37:18,280 --> 00:37:25,230
something that's probably not something

00:37:21,790 --> 00:37:25,230
you'd want to use in production

00:37:25,960 --> 00:37:32,560
and it says here then yeah you'd also be

00:37:28,880 --> 00:37:35,599
using one port for each servant to

00:37:32,560 --> 00:37:40,460
expose it's also in this time that's

00:37:35,599 --> 00:37:42,740
thirty thousand or puts range some

00:37:40,460 --> 00:37:45,190
disadvantages but it's it can be useful

00:37:42,740 --> 00:37:45,190
for testing

00:37:45,589 --> 00:37:52,210
another way is load balancer so

00:37:48,310 --> 00:37:56,650
typically if you create a cluster arm

00:37:52,210 --> 00:38:01,489
Jiki we will give an S engine

00:37:56,650 --> 00:38:03,769
you could use this method and an

00:38:01,489 --> 00:38:05,660
external load balancer will be created

00:38:03,769 --> 00:38:09,669
for you automatically and you can use

00:38:05,660 --> 00:38:09,669
them that's

00:38:10,059 --> 00:38:13,790
that's sort of like the advantage

00:38:12,079 --> 00:38:15,619
disadvantage of this it is great when

00:38:13,790 --> 00:38:17,359
you're running in some cloud provider

00:38:15,619 --> 00:38:20,690
and they will provide this external load

00:38:17,359 --> 00:38:24,349
balancer for you and this will provide

00:38:20,690 --> 00:38:26,589
you an IP address an own IP address and

00:38:24,349 --> 00:38:30,530
this will no doubt be on some safe

00:38:26,589 --> 00:38:33,770
subnet that you you do accept to expose

00:38:30,530 --> 00:38:36,140
and then it will load balance between

00:38:33,770 --> 00:38:39,829
the worker node while between the pots I

00:38:36,140 --> 00:38:42,589
should say so this is good for for

00:38:39,829 --> 00:38:44,630
deployment well there's a third way

00:38:42,589 --> 00:38:47,270
that's the one I want to present to you

00:38:44,630 --> 00:38:52,839
which is have a Cuba Nexus ingress

00:38:47,270 --> 00:38:56,230
controller and this one provides more

00:38:52,839 --> 00:38:59,569
functionalities so it will provide

00:38:56,230 --> 00:39:03,500
public addresses you can use to get in

00:38:59,569 --> 00:39:06,530
to the services running in the pods the

00:39:03,500 --> 00:39:09,049
thing is that you will no doubt be

00:39:06,530 --> 00:39:11,059
having a large number of services in

00:39:09,049 --> 00:39:14,690
your cluster and it becomes complicated

00:39:11,059 --> 00:39:16,309
to a rule between them the concept of

00:39:14,690 --> 00:39:18,559
ingress controller allows to do

00:39:16,309 --> 00:39:21,380
different types of routing to get to

00:39:18,559 --> 00:39:25,609
those services like basement routing so

00:39:21,380 --> 00:39:27,740
it's an example where based on the host

00:39:25,609 --> 00:39:30,170
name that we attack will be directed to

00:39:27,740 --> 00:39:31,940
a different service and it's the ingress

00:39:30,170 --> 00:39:34,480
controller that will provide us that

00:39:31,940 --> 00:39:34,480
functionality

00:39:41,510 --> 00:39:50,220
okay so traffic of traffic is an example

00:39:47,670 --> 00:39:53,760
of a reverse proxy look on answer that

00:39:50,220 --> 00:39:58,020
can be used as an ingress controller as

00:39:53,760 --> 00:40:00,890
I would use that in a demo traffic

00:39:58,020 --> 00:40:08,250
allows quite extensive combinations of

00:40:00,890 --> 00:40:10,200
hostname path B fix a URL and port based

00:40:08,250 --> 00:40:12,859
routing to be able to direct to

00:40:10,200 --> 00:40:17,100
different services within your cluster

00:40:12,859 --> 00:40:19,320
it also allows to do hop reloads of the

00:40:17,100 --> 00:40:22,020
configuration you don't have to restart

00:40:19,320 --> 00:40:24,090
traffic if you have reconfigure it to

00:40:22,020 --> 00:40:28,230
add another service or to change an

00:40:24,090 --> 00:40:32,030
existing service and it also has less

00:40:28,230 --> 00:40:37,520
encrypted support so it can actually do

00:40:32,030 --> 00:40:37,520
or automated approach in there

00:40:39,820 --> 00:40:42,450
okay

00:40:48,930 --> 00:40:56,940
I'm going to go away from this previous

00:40:54,250 --> 00:40:56,940
dashboard

00:41:00,410 --> 00:41:06,170
like a toast at recess

00:41:02,980 --> 00:41:06,170
[Music]

00:41:07,400 --> 00:41:15,319
okay so this is Cuban SS dashboard of

00:41:12,759 --> 00:41:17,329
another kubernetes cluster as I said

00:41:15,319 --> 00:41:20,269
this one is based on mini cube so we

00:41:17,329 --> 00:41:23,680
should see here it has just a symbol and

00:41:20,269 --> 00:41:23,680
a single node

00:41:24,530 --> 00:41:30,670
I think I have nothing running let me

00:41:27,590 --> 00:41:30,670
check that

00:41:32,380 --> 00:41:35,009
okay

00:41:39,340 --> 00:41:42,530
[Music]

00:41:46,289 --> 00:41:54,759
okay so I'm going to show how to deploy

00:41:50,829 --> 00:41:57,339
traffic itself as an ingress controller

00:41:54,759 --> 00:42:00,249
so the moment I didn't show you

00:41:57,339 --> 00:42:02,579
explicitly again if I cleaned up

00:42:00,249 --> 00:42:02,579
properly

00:42:05,669 --> 00:42:10,079
no I didn't clean it properly economy

00:42:10,510 --> 00:42:14,950
okay

00:42:11,740 --> 00:42:14,950
[Music]

00:42:20,910 --> 00:42:26,619
okay so I just got a scripted demo and

00:42:25,479 --> 00:42:30,099
I'll talk you through the different

00:42:26,619 --> 00:42:33,279
steps so I'm going to install traffic

00:42:30,099 --> 00:42:37,839
itself we'll see that's quite simple to

00:42:33,279 --> 00:42:41,049
do with the appropriate llamÃ³ file I'm

00:42:37,839 --> 00:42:43,839
going to deploy some parts of an

00:42:41,049 --> 00:42:47,160
application that shows Jesus as you'll

00:42:43,839 --> 00:42:53,019
have seen traffic is really introduces

00:42:47,160 --> 00:42:54,749
and I will deploy a service those

00:42:53,019 --> 00:43:00,249
different applications

00:42:54,749 --> 00:43:04,769
yeah and then I will set up different

00:43:00,249 --> 00:43:04,769
paths to those services

00:43:08,530 --> 00:43:16,870
okay so the first step I won't show the

00:43:12,040 --> 00:43:19,360
actual llamo final Sara I've actually

00:43:16,870 --> 00:43:22,050
applied the configuration to install

00:43:19,360 --> 00:43:22,050
traffic

00:43:26,620 --> 00:43:33,490
and I'm going to create my my

00:43:30,650 --> 00:43:41,270
applications or my services

00:43:33,490 --> 00:43:45,380
okay so we have the image we have an

00:43:41,270 --> 00:43:48,550
application called cheese and we're

00:43:45,380 --> 00:43:48,550
going to deploy that

00:43:52,650 --> 00:43:58,900
okay so I've deployed three services

00:43:57,130 --> 00:44:02,080
actually all based on their the same

00:43:58,900 --> 00:44:05,890
image called Stilton cheddar on

00:44:02,080 --> 00:44:08,910
Wensleydale we can see that those three

00:44:05,890 --> 00:44:08,910
services are running now

00:44:11,650 --> 00:44:17,890
okay actually still have okay something

00:44:15,310 --> 00:44:19,300
wasn't cleaned up properly so I have an

00:44:17,890 --> 00:44:21,130
ingress running for guys I'm gonna

00:44:19,300 --> 00:44:23,410
craters problem so I'll get an arrow

00:44:21,130 --> 00:44:26,220
here I think because the ingress is

00:44:23,410 --> 00:44:26,220
already created

00:44:28,180 --> 00:44:31,180
okay

00:44:32,140 --> 00:44:36,120
it's actually might work better than

00:44:33,970 --> 00:44:36,120
before

00:44:44,150 --> 00:44:50,730
so let me complain I have a working

00:44:46,470 --> 00:44:53,070
version of this demo and it was the

00:44:50,730 --> 00:44:54,660
first time I was told it myself so this

00:44:53,070 --> 00:44:56,850
may or may not work if it doesn't work

00:44:54,660 --> 00:44:59,760
I'll switch to the working version that

00:44:56,850 --> 00:45:03,770
I already had but it would be really

00:44:59,760 --> 00:45:06,420
cool if

00:45:03,770 --> 00:45:09,049
this works

00:45:06,420 --> 00:45:11,400
let me change if you do that's not

00:45:09,049 --> 00:45:14,569
that's the working version and this is

00:45:11,400 --> 00:45:14,569
the maybe working mission

00:45:15,920 --> 00:45:23,600
okay so just to say the address of their

00:45:20,160 --> 00:45:30,930
which is totally in read or is traffic

00:45:23,600 --> 00:45:32,910
UI mini cube of 3 and I have a HTC host

00:45:30,930 --> 00:45:36,420
sentry with the IP address of that

00:45:32,910 --> 00:45:41,130
particular node okay so this is the

00:45:36,420 --> 00:45:43,020
traffic dashboard I didn't mention that

00:45:41,130 --> 00:45:44,160
traffic actually can work with many

00:45:43,020 --> 00:45:47,430
different backends

00:45:44,160 --> 00:45:54,780
so obviously kubernetes docker swarm

00:45:47,430 --> 00:45:57,210
Apache missus Nomad Rancher and also

00:45:54,780 --> 00:46:02,280
some of the back-end services like

00:45:57,210 --> 00:46:03,990
console zookeeper Eureka there are a lot

00:46:02,280 --> 00:46:08,580
of back-end services what we're seeing

00:46:03,990 --> 00:46:11,130
here is okay terms of providers we have

00:46:08,580 --> 00:46:13,110
one configured which is kubernetes so

00:46:11,130 --> 00:46:15,560
when we configured it as an ingress

00:46:13,110 --> 00:46:15,560
controller

00:46:16,160 --> 00:46:21,510
basically enable this this tab what

00:46:19,740 --> 00:46:25,080
we're seeing is a number of front ends

00:46:21,510 --> 00:46:27,930
so these are actually the ingresses for

00:46:25,080 --> 00:46:30,030
the services I created now this first

00:46:27,930 --> 00:46:32,070
one actually is an error this was me

00:46:30,030 --> 00:46:35,340
trying to set up the system earlier and

00:46:32,070 --> 00:46:37,610
then the these following ones should be

00:46:35,340 --> 00:46:37,610
good

00:46:37,880 --> 00:46:43,030
okay I found it surprised by the dress

00:46:41,240 --> 00:46:46,180
but okay

00:46:43,030 --> 00:46:48,910
and the these front ends are going to

00:46:46,180 --> 00:46:50,640
basically root through to the back-end

00:46:48,910 --> 00:46:53,739
services

00:46:50,640 --> 00:46:53,739
[Music]

00:46:59,630 --> 00:47:04,269
okay yeah HTTP it always helps

00:47:07,200 --> 00:47:10,440
quickly fire

00:47:17,990 --> 00:47:20,560
mom

00:47:27,670 --> 00:47:33,859
okay that's that's fine

00:47:30,270 --> 00:47:33,859
don't normally use that address

00:47:36,530 --> 00:47:43,270
service invivo okay nevermind so I'll go

00:47:39,620 --> 00:47:43,270
to my work English and then

00:47:44,970 --> 00:47:48,650
I'm cheating oops

00:47:53,570 --> 00:47:59,990
I start with the dashboard of the other

00:47:56,740 --> 00:48:02,030
system that I have again here this is

00:47:59,990 --> 00:48:06,320
more analysis and more we're expecting

00:48:02,030 --> 00:48:09,500
of cheddar mini cube still some domini

00:48:06,320 --> 00:48:13,630
cube and the last one Wensley Dale

00:48:09,500 --> 00:48:16,400
Dominic uber so these are the host names

00:48:13,630 --> 00:48:18,380
again it's the same ip address

00:48:16,400 --> 00:48:22,990
they have entries for these in my etc

00:48:18,380 --> 00:48:22,990
hosts so now

00:48:23,900 --> 00:48:28,750
I try to access cheddar mini Pew

00:48:31,950 --> 00:48:37,460
I will be directed to the cheddar

00:48:34,460 --> 00:48:37,460
service

00:48:41,980 --> 00:48:47,740
once the day out okay and I think you

00:48:45,010 --> 00:48:50,609
get the idea but I fantasy bit of

00:48:47,740 --> 00:48:50,609
Stilton anyway

00:48:53,740 --> 00:49:04,140
okay so that I just want to show you the

00:49:00,250 --> 00:49:06,970
the idea behind an ingress controller

00:49:04,140 --> 00:49:11,410
where basically you can configure

00:49:06,970 --> 00:49:13,599
different routes in this case basically

00:49:11,410 --> 00:49:15,609
if the host is tethered on mini cube

00:49:13,599 --> 00:49:18,910
then we're going to route through to the

00:49:15,609 --> 00:49:20,470
backend tether and thought mini cube and

00:49:18,910 --> 00:49:23,380
this is going to direct through to the

00:49:20,470 --> 00:49:25,060
pots what traffic is doing here is there

00:49:23,380 --> 00:49:26,830
are different ways it can be configured

00:49:25,060 --> 00:49:31,170
but is actually interrogating the

00:49:26,830 --> 00:49:34,180
kubernetes api so we don't have to

00:49:31,170 --> 00:49:35,950
configure traffic to say okay these are

00:49:34,180 --> 00:49:38,890
the services now

00:49:35,950 --> 00:49:43,300
it's traffic which is detected that

00:49:38,890 --> 00:49:45,369
those services are running if I normally

00:49:43,300 --> 00:49:48,070
fight fine delete stuff

00:49:45,369 --> 00:49:51,520
delete the pubs then those backends will

00:49:48,070 --> 00:49:53,530
do this at the end that's one of the

00:49:51,520 --> 00:49:56,260
advantages at least a traffic and it has

00:49:53,530 --> 00:50:00,310
this dynamic configuration reloading

00:49:56,260 --> 00:50:03,250
okay and generally this is sort of

00:50:00,310 --> 00:50:05,410
functionality that reverse proxies in

00:50:03,250 --> 00:50:09,430
risk controls will provide but maybe not

00:50:05,410 --> 00:50:11,310
with such dynamic read-only so in this

00:50:09,430 --> 00:50:16,540
case it's very simple filtering

00:50:11,310 --> 00:50:20,470
basically saying it comes in on cheddar

00:50:16,540 --> 00:50:23,230
dot mini cube hostname with path slash

00:50:20,470 --> 00:50:26,080
then go to this service we could do

00:50:23,230 --> 00:50:28,330
things more extravagant we'd have array

00:50:26,080 --> 00:50:33,250
X in there and this sort of thing

00:50:28,330 --> 00:50:37,380
there's a lot of possibility for quite

00:50:33,250 --> 00:50:37,380
flexible routing different services

00:50:37,860 --> 00:50:43,050
or any questions on that before I go on

00:50:46,890 --> 00:50:50,340
behind another

00:51:02,610 --> 00:51:09,200
I guess you could sure to understand the

00:51:06,660 --> 00:51:12,049
use case but

00:51:09,200 --> 00:51:14,240
yes a lot I'm in love the use cases we

00:51:12,049 --> 00:51:15,980
have are treating we're headers already

00:51:14,240 --> 00:51:20,380
modified because they passed through

00:51:15,980 --> 00:51:23,790
different systems I guess you could have

00:51:20,380 --> 00:51:27,170
chaining over this boxes

00:51:23,790 --> 00:51:27,170
it's not gonna see your question

00:51:40,480 --> 00:51:43,480
so

00:51:45,349 --> 00:51:53,150
yeah I think that would be possible and

00:51:49,809 --> 00:51:56,019
try to remember it as an idea for a demo

00:51:53,150 --> 00:51:56,019
would be pretty good

00:51:56,560 --> 00:52:07,830
okay fine go back let's say this is

00:52:03,640 --> 00:52:07,830
really the shortened version

00:52:10,250 --> 00:52:14,320
this is the cheap one our version

00:52:14,519 --> 00:52:19,029
speaking of which I mean this is the

00:52:16,359 --> 00:52:22,059
first time I present traffic the second

00:52:19,029 --> 00:52:25,269
time would be this evening made me think

00:52:22,059 --> 00:52:27,849
earlier of say never happened to I got

00:52:25,269 --> 00:52:30,009
in the plane once the pilot proudly

00:52:27,849 --> 00:52:32,589
announces you know wonderful people of

00:52:30,009 --> 00:52:36,009
these don't worry this is this planes

00:52:32,589 --> 00:52:39,450
first right so everyone's happy except

00:52:36,009 --> 00:52:43,269
the engineers I think engineering

00:52:39,450 --> 00:52:45,519
reliability curves it's the same my

00:52:43,269 --> 00:52:48,069
first time presenting traffic so for you

00:52:45,519 --> 00:52:51,700
few hits hope you go be better for the

00:52:48,069 --> 00:52:57,009
second time see if a panty bug from the

00:52:51,700 --> 00:53:00,250
MRT later okay as I mentioned I mean

00:52:57,009 --> 00:53:03,750
there are tons and tons of tools coming

00:53:00,250 --> 00:53:05,930
out kubernetes I even bumped into

00:53:03,750 --> 00:53:08,280
a guy this morning with speaker rule

00:53:05,930 --> 00:53:11,310
presented three new tools so many but

00:53:08,280 --> 00:53:13,920
he's working on pretty cool but there's

00:53:11,310 --> 00:53:15,810
there's one in particular helm which is

00:53:13,920 --> 00:53:18,390
really interesting so it was company

00:53:15,810 --> 00:53:20,400
called dice who started working on this

00:53:18,390 --> 00:53:23,670
and some of the tools and dice got

00:53:20,400 --> 00:53:25,920
bought by Microsoft last year and that

00:53:23,670 --> 00:53:31,230
continues to operate as an open-source

00:53:25,920 --> 00:53:34,650
project but there's real momentum I mean

00:53:31,230 --> 00:53:40,590
I guess dice was to create the project

00:53:34,650 --> 00:53:43,910
to two or three years ago and already in

00:53:40,590 --> 00:53:48,830
January I think there was a hell summit

00:53:43,910 --> 00:53:52,410
Wow okay so what is helm it basically

00:53:48,830 --> 00:53:57,990
allows you to specify in the llamÃ³ file

00:53:52,410 --> 00:54:01,110
or application stack and then those

00:53:57,990 --> 00:54:04,410
yellow files themselves are available on

00:54:01,110 --> 00:54:07,220
a hub that's pretty nice that means you

00:54:04,410 --> 00:54:07,220
can actually browse

00:54:10,240 --> 00:54:14,490
do I have it okay because of that

00:54:15,099 --> 00:54:23,779
this is the word the helm website down

00:54:20,210 --> 00:54:31,029
here it's option to get chat go over

00:54:23,779 --> 00:54:31,029
there cubot cube apps and explore apps

00:54:31,700 --> 00:54:38,000
so if I want don't bore you with this

00:54:34,970 --> 00:54:41,470
but you know I could even I could even

00:54:38,000 --> 00:54:41,470
install traffic using hell

00:54:43,150 --> 00:54:47,070
but you know

00:54:53,119 --> 00:55:00,279
okay but okay you can see a whole load

00:54:56,210 --> 00:55:00,279
of application stacks

00:55:00,590 --> 00:55:05,430
there's a command-line tool as well

00:55:03,590 --> 00:55:09,510
allows you to do

00:55:05,430 --> 00:55:13,500
I simply helm search hell fetch I think

00:55:09,510 --> 00:55:16,650
it is then he'll install that's not

00:55:13,500 --> 00:55:18,770
quite the pants but it's really nice way

00:55:16,650 --> 00:55:21,240
of being able to install complete

00:55:18,770 --> 00:55:23,390
applications across your kubernetes

00:55:21,240 --> 00:55:23,390
cluster

00:55:28,230 --> 00:55:30,859
okay

00:55:32,579 --> 00:55:39,640
so I'm going to stop there so in the end

00:55:35,920 --> 00:55:41,720
that was 55 minute version lot that hour

00:55:39,640 --> 00:55:46,430
version

00:55:41,720 --> 00:55:46,430
so any questions from people

00:55:49,909 --> 00:55:55,249
yeah

00:55:51,559 --> 00:55:55,249
so let me see

00:56:21,140 --> 00:56:27,420
okay

00:56:23,630 --> 00:56:31,520
Soji top.com continued orchestration

00:56:27,420 --> 00:56:31,520
laps actually then it's

00:56:32,099 --> 00:56:38,039
Cuban and our Bacchus trade and

00:56:34,829 --> 00:56:41,089
kubernetes and it's actually on a branch

00:56:38,039 --> 00:56:41,089
across Asia

00:56:41,730 --> 00:56:47,549
and yeah I'm interested for any any

00:56:45,569 --> 00:56:51,960
feedback and the issues you know open

00:56:47,549 --> 00:56:52,650
against the the tutorial this is the one

00:56:51,960 --> 00:56:55,890
hour version

00:56:52,650 --> 00:57:02,430
I mean could actually run for work team

00:56:55,890 --> 00:57:05,839
one three before hours next time okay

00:57:02,430 --> 00:57:05,839

YouTube URL: https://www.youtube.com/watch?v=MzlprLLs8bU


