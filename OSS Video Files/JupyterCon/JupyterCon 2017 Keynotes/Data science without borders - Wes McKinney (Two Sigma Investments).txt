Title: Data science without borders - Wes McKinney (Two Sigma Investments)
Publication date: 2020-08-24
Playlist: JupyterCon 2017 Keynotes
Description: 
	Wes McKinney makes the case for a shared infrastructure for data science, discusses the open source community's efforts on Apache Arrow, and offers a vision for seamless computation and data sharing across languages.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Google: http://plus.google.com/+oreillymedia
Captions: 
	00:00:00,320 --> 00:00:08,480
so my topic today is is very important

00:00:03,979 --> 00:00:10,280
to me many of you know me from my from

00:00:08,480 --> 00:00:13,519
my open source work and my a my writing

00:00:10,280 --> 00:00:16,190
in the last couple of years I've been

00:00:13,519 --> 00:00:18,980
been very excited to to get involved in

00:00:16,190 --> 00:00:20,900
a couple of projects in the Apache

00:00:18,980 --> 00:00:23,390
Software Foundation and we don't have a

00:00:20,900 --> 00:00:26,210
lot of Python programmers working in the

00:00:23,390 --> 00:00:28,580
ASF and I will say about that that as

00:00:26,210 --> 00:00:31,330
open source grows bigger and more

00:00:28,580 --> 00:00:33,860
popular and even more commingled with

00:00:31,330 --> 00:00:35,900
commercial interests that it's very

00:00:33,860 --> 00:00:38,990
important to have organizations like the

00:00:35,900 --> 00:00:40,730
ASF to put the community first and to

00:00:38,990 --> 00:00:42,170
protect protect the intellectual

00:00:40,730 --> 00:00:48,260
property rights of open-source

00:00:42,170 --> 00:00:50,240
developers so I'd like to reflect for a

00:00:48,260 --> 00:00:53,690
moment on on everything that's happened

00:00:50,240 --> 00:00:56,030
over the last ten years and certainly it

00:00:53,690 --> 00:00:57,290
goes way way beyond that you know

00:00:56,030 --> 00:00:58,730
there's work that we are we were

00:00:57,290 --> 00:01:01,790
depending on in the Python world which

00:00:58,730 --> 00:01:03,680
happened a long time before 2007 but it

00:01:01,790 --> 00:01:05,440
was this month ten years ago when I

00:01:03,680 --> 00:01:08,000
personally started thinking about

00:01:05,440 --> 00:01:10,850
thinking about data analysis and it's

00:01:08,000 --> 00:01:13,850
been really amazing to see all of the

00:01:10,850 --> 00:01:16,750
all of the progress that we've made and

00:01:13,850 --> 00:01:19,790
I spend a lot of this a lot of this time

00:01:16,750 --> 00:01:22,280
personally working on the chicken and

00:01:19,790 --> 00:01:25,729
egg problem of statistical computing and

00:01:22,280 --> 00:01:27,860
data analysis and in Python we didn't

00:01:25,729 --> 00:01:29,750
call it data science back then I guess

00:01:27,860 --> 00:01:31,820
now we can out we can call it now we can

00:01:29,750 --> 00:01:33,170
call it data science but I was really

00:01:31,820 --> 00:01:34,880
concerned about we had this great

00:01:33,170 --> 00:01:37,130
programming language with a scientific

00:01:34,880 --> 00:01:38,869
computing ecosystem that was a really

00:01:37,130 --> 00:01:41,690
great platform to build on but it was

00:01:38,869 --> 00:01:45,650
still hard to do what we now call what

00:01:41,690 --> 00:01:48,409
we now call data science one of the

00:01:45,650 --> 00:01:50,210
biggest trends over over this time

00:01:48,409 --> 00:01:53,390
period is the trend from close source

00:01:50,210 --> 00:01:56,390
software to open source software and so

00:01:53,390 --> 00:01:58,369
many of you may be painting have painful

00:01:56,390 --> 00:02:01,189
memories of what things used to be like

00:01:58,369 --> 00:02:04,250
when if you wanted to do statistics or

00:02:01,189 --> 00:02:06,950
data analysis usually it meant writing a

00:02:04,250 --> 00:02:09,679
check because no one ever got fired for

00:02:06,950 --> 00:02:12,230
buying MATLAB and you could understand

00:02:09,679 --> 00:02:14,120
the skepticism and using open source

00:02:12,230 --> 00:02:16,370
software for these problems

00:02:14,120 --> 00:02:18,680
I remember talking with my bosses at the

00:02:16,370 --> 00:02:21,200
time about Python and they would ask

00:02:18,680 --> 00:02:24,980
well who built this software can we

00:02:21,200 --> 00:02:29,480
trust it and I would say well a lot of

00:02:24,980 --> 00:02:30,950
them were grad students and they say

00:02:29,480 --> 00:02:33,110
what are they computer science grad

00:02:30,950 --> 00:02:34,879
students and so you know a lot of them

00:02:33,110 --> 00:02:37,010
are physicists and scientists who are

00:02:34,879 --> 00:02:40,700
just trying to were procrastinating on

00:02:37,010 --> 00:02:43,190
their PhDs and just trying to you know I

00:02:40,700 --> 00:02:45,019
think John you know John you know John

00:02:43,190 --> 00:02:47,599
Hunter who passed away this August five

00:02:45,019 --> 00:02:50,060
years ago you know started matplotlib

00:02:47,599 --> 00:02:51,739
because he got frustrated with matlab's

00:02:50,060 --> 00:02:53,269
licensing policy when he was you know

00:02:51,739 --> 00:02:55,819
generating plots on different servers

00:02:53,269 --> 00:02:58,370
and there have been many factors that

00:02:55,819 --> 00:03:01,310
have driven the the growth and adoption

00:02:58,370 --> 00:03:03,200
of open-source you know certainly the

00:03:01,310 --> 00:03:05,870
maturity of the libraries has been a big

00:03:03,200 --> 00:03:07,489
factor the cloud has been a huge deal

00:03:05,870 --> 00:03:09,650
because there are some days where you

00:03:07,489 --> 00:03:11,959
want to run a job on one machine

00:03:09,650 --> 00:03:14,780
sometimes a hundred or a thousand so if

00:03:11,959 --> 00:03:16,370
you needed to you know the licensing

00:03:14,780 --> 00:03:18,440
model for clothes for software is not

00:03:16,370 --> 00:03:21,139
very very compatible with that and

00:03:18,440 --> 00:03:23,750
certainly open-source has driven the

00:03:21,139 --> 00:03:25,819
democratization of data science and over

00:03:23,750 --> 00:03:28,959
over the years I've been really humbled

00:03:25,819 --> 00:03:32,510
to hear from people all over the world

00:03:28,959 --> 00:03:34,280
especially in very poor places who you

00:03:32,510 --> 00:03:36,019
know have a copy of my book or are

00:03:34,280 --> 00:03:37,790
learning from the internet and are

00:03:36,019 --> 00:03:40,310
working really hard to learn these tools

00:03:37,790 --> 00:03:45,319
so that they can analyze data and use

00:03:40,310 --> 00:03:46,849
that to improve their lives the Jupiter

00:03:45,319 --> 00:03:49,519
the growth of the Juber community has

00:03:46,849 --> 00:03:51,410
also been a really amazing thing I saw

00:03:49,519 --> 00:03:55,489
the first incarnation of the ipython

00:03:51,410 --> 00:03:57,650
notebook in summer of 2011 and I was

00:03:55,489 --> 00:03:59,870
just I was just blown away now I used

00:03:57,650 --> 00:04:02,030
Mathematica and so it was familiar with

00:03:59,870 --> 00:04:04,669
with with the notebook concept but to

00:04:02,030 --> 00:04:06,620
see that vision realized in such a

00:04:04,669 --> 00:04:09,109
natural way that fit in with the rest of

00:04:06,620 --> 00:04:10,190
the Python ecosystem was really you know

00:04:09,109 --> 00:04:12,799
it was really something I started

00:04:10,190 --> 00:04:16,370
showing it to everyone everyone around

00:04:12,799 --> 00:04:18,139
me and I think that viral quality to do

00:04:16,370 --> 00:04:20,959
that to the notebook has been a big

00:04:18,139 --> 00:04:22,880
factor in its success but I think I

00:04:20,959 --> 00:04:25,490
think you know the the ipython

00:04:22,880 --> 00:04:26,960
developers as they collaborated with the

00:04:25,490 --> 00:04:27,980
Giulia community and others realized

00:04:26,960 --> 00:04:30,350
that the

00:04:27,980 --> 00:04:33,650
booter problem is much bigger than

00:04:30,350 --> 00:04:35,120
python that concerns the general problem

00:04:33,650 --> 00:04:37,850
of interactive computing and

00:04:35,120 --> 00:04:39,530
reproducible research and so it's been

00:04:37,850 --> 00:04:41,780
you know just amazing to see this

00:04:39,530 --> 00:04:44,120
community grow and and to see so much

00:04:41,780 --> 00:04:48,320
collaboration across these different

00:04:44,120 --> 00:04:50,360
programming language ecosystems but I'd

00:04:48,320 --> 00:04:52,670
like to think a little bit about the

00:04:50,360 --> 00:04:55,130
future and I spent a lot of time

00:04:52,670 --> 00:04:57,410
thinking and worrying about the future

00:04:55,130 --> 00:05:00,050
mostly because I wanted to get here

00:04:57,410 --> 00:05:02,240
faster because we would all we would all

00:05:00,050 --> 00:05:05,000
like that and I don't know that we would

00:05:02,240 --> 00:05:07,430
have been able to predict accurately the

00:05:05,000 --> 00:05:10,340
last 10 years so who knows where we'll

00:05:07,430 --> 00:05:11,930
be in 2027 maybe we'll all be

00:05:10,340 --> 00:05:18,140
programming in JavaScript I mean it's

00:05:11,930 --> 00:05:19,670
it's it it's entirely likely but I think

00:05:18,140 --> 00:05:21,800
there's there you know there's some

00:05:19,670 --> 00:05:23,720
things that we can be doing you know we

00:05:21,800 --> 00:05:27,050
can be doing now to lay the foundation

00:05:23,720 --> 00:05:31,160
for for a better future I'd like to talk

00:05:27,050 --> 00:05:33,710
about some of those things so one of the

00:05:31,160 --> 00:05:35,780
major themes right now and I expect this

00:05:33,710 --> 00:05:38,330
to continue for for many years is what I

00:05:35,780 --> 00:05:40,430
call the AI arms race faster more

00:05:38,330 --> 00:05:43,250
scalable more cost-effective machine

00:05:40,430 --> 00:05:45,710
learning so I was in a talk by Michael I

00:05:43,250 --> 00:05:48,110
Jordan machine learning researcher and

00:05:45,710 --> 00:05:49,730
he quipped that AI is really machine

00:05:48,110 --> 00:05:52,820
learning which is pattern recognition

00:05:49,730 --> 00:05:55,130
and that's definitely true and you have

00:05:52,820 --> 00:05:56,740
all of these cutting-edge new machine

00:05:55,130 --> 00:05:59,630
learning technologies being developed

00:05:56,740 --> 00:06:01,670
but to use machine learning models you

00:05:59,630 --> 00:06:04,490
still need to load and access data and

00:06:01,670 --> 00:06:07,010
clean and manipulated it explore it find

00:06:04,490 --> 00:06:08,870
features and then do all of that in a

00:06:07,010 --> 00:06:10,550
reproducible way so that whenever you

00:06:08,870 --> 00:06:13,550
when new data comes in you can update

00:06:10,550 --> 00:06:15,530
you can update your model so no matter

00:06:13,550 --> 00:06:17,420
how sophisticated the the AI algorithms

00:06:15,530 --> 00:06:19,640
get we're still going to need all the

00:06:17,420 --> 00:06:21,770
tools that we've developed for all the

00:06:19,640 --> 00:06:26,510
work that happens before your fitting

00:06:21,770 --> 00:06:29,330
your models the hardware landscape has

00:06:26,510 --> 00:06:35,210
also changed a great deal and continues

00:06:29,330 --> 00:06:37,130
to change so you know a decade ago seven

00:06:35,210 --> 00:06:39,200
years ago you know when I was starting

00:06:37,130 --> 00:06:41,480
out building pandas most computers

00:06:39,200 --> 00:06:43,640
didn't have that much RAM we were

00:06:41,480 --> 00:06:45,680
dealing with maybe two gigabytes or four

00:06:43,640 --> 00:06:49,280
gigabytes or eight gigabytes processors

00:06:45,680 --> 00:06:50,660
generally had one or two cores disks

00:06:49,280 --> 00:06:52,760
were pretty slow

00:06:50,660 --> 00:06:55,790
you know spinning rust as some people

00:06:52,760 --> 00:06:57,740
call them and so we've seen disks get

00:06:55,790 --> 00:07:00,500
ten times or more faster you can buy a

00:06:57,740 --> 00:07:02,960
desktop processor from AMD with 16 cores

00:07:00,500 --> 00:07:07,160
you can get a machine with a terabyte or

00:07:02,960 --> 00:07:08,690
two terabytes of RAM and so and the data

00:07:07,160 --> 00:07:11,060
sizes that we're working with have also

00:07:08,690 --> 00:07:13,040
increased as we were collecting more and

00:07:11,060 --> 00:07:15,800
more data but if you look at the tools

00:07:13,040 --> 00:07:18,200
that the tools that we are using they

00:07:15,800 --> 00:07:19,610
have not scaled so gracefully to be able

00:07:18,200 --> 00:07:21,680
to take advantage of modern hardware

00:07:19,610 --> 00:07:24,860
hardware and to be able to use this

00:07:21,680 --> 00:07:26,780
hardware to its maximum capacity is

00:07:24,860 --> 00:07:28,700
going to be a lot harder and require a

00:07:26,780 --> 00:07:33,740
lot more engineering than it took to

00:07:28,700 --> 00:07:35,090
build the software that we use today and

00:07:33,740 --> 00:07:37,460
so one problem that I think a lot about

00:07:35,090 --> 00:07:39,680
is the fact that when you go beyond the

00:07:37,460 --> 00:07:41,450
front-end tools like tools like Jupiter

00:07:39,680 --> 00:07:43,250
and you go down into the Python

00:07:41,450 --> 00:07:44,900
ecosystem the our ecosystem and the

00:07:43,250 --> 00:07:46,640
other areas where people do data science

00:07:44,900 --> 00:07:49,280
there isn't a great deal of

00:07:46,640 --> 00:07:52,100
collaboration I would even go so far as

00:07:49,280 --> 00:07:53,900
to call these communities tribal you

00:07:52,100 --> 00:07:56,000
know I'm a Python person you know I'm an

00:07:53,900 --> 00:07:57,920
hour person and that becomes it becomes

00:07:56,000 --> 00:08:00,680
a part of your identity and it's very

00:07:57,920 --> 00:08:03,650
rare that you see software being

00:08:00,680 --> 00:08:06,470
developed that can be used across silos

00:08:03,650 --> 00:08:08,750
there's there's tools for calling Python

00:08:06,470 --> 00:08:11,390
code from Julia you can call R from

00:08:08,750 --> 00:08:13,940
Python but as a way to build software in

00:08:11,390 --> 00:08:17,570
general that's not the the predominant

00:08:13,940 --> 00:08:19,190
the predominant method there's many

00:08:17,570 --> 00:08:22,280
different things that that are in the

00:08:19,190 --> 00:08:23,540
silos so you need to access data when

00:08:22,280 --> 00:08:24,860
you access data you need to put it

00:08:23,540 --> 00:08:26,300
someplace so those are your data

00:08:24,860 --> 00:08:28,880
structures and what I call memory

00:08:26,300 --> 00:08:31,430
formats things like data frames you need

00:08:28,880 --> 00:08:34,220
compute engines to manipulate those data

00:08:31,430 --> 00:08:37,220
structures to run to do exploratory

00:08:34,220 --> 00:08:38,960
analytics to engineer features and then

00:08:37,220 --> 00:08:40,940
you need analytics toolkits to fit

00:08:38,960 --> 00:08:43,810
statistical models and machine learning

00:08:40,940 --> 00:08:47,060
models and if you look from from left

00:08:43,810 --> 00:08:50,930
let's see from from left to from left to

00:08:47,060 --> 00:08:53,330
right it's it's a funnel so if you have

00:08:50,930 --> 00:08:55,100
a problem earlier on in the process if

00:08:53,330 --> 00:08:56,660
you can't read a file

00:08:55,100 --> 00:08:58,820
if you can't find the right data

00:08:56,660 --> 00:09:00,350
manipulation if you can't compute the

00:08:58,820 --> 00:09:01,820
right thing you are going to get to the

00:09:00,350 --> 00:09:07,130
model development stage you're going to

00:09:01,820 --> 00:09:08,540
fall off and have a bad time and so if

00:09:07,130 --> 00:09:10,850
you just look in the in the Python

00:09:08,540 --> 00:09:12,620
ecosystem and the - and some of the

00:09:10,850 --> 00:09:15,440
tools this is not a comprehensive list

00:09:12,620 --> 00:09:17,960
by any means there's a consistent theme

00:09:15,440 --> 00:09:19,690
here in that just looking at the pandas

00:09:17,960 --> 00:09:22,640
project that we've had to develop

00:09:19,690 --> 00:09:24,080
software and many different many

00:09:22,640 --> 00:09:27,020
different domains we've written our own

00:09:24,080 --> 00:09:29,320
CSV readers and many other data access

00:09:27,020 --> 00:09:31,460
layers we have a half-baked

00:09:29,320 --> 00:09:34,220
implementation of an in-memory sequel

00:09:31,460 --> 00:09:38,300
database we have developed our own data

00:09:34,220 --> 00:09:39,530
frame data structures so that's you know

00:09:38,300 --> 00:09:41,360
that's something I think about the fact

00:09:39,530 --> 00:09:42,980
that we own all the software we built it

00:09:41,360 --> 00:09:44,540
all and it's not accessible if you're

00:09:42,980 --> 00:09:47,570
not a Python programmer and you don't

00:09:44,540 --> 00:09:49,190
use and you don't use pandas and so I

00:09:47,570 --> 00:09:52,280
started thinking more critically about

00:09:49,190 --> 00:09:54,650
this at the end of 2015 and I think my

00:09:52,280 --> 00:09:57,740
thoughts had gone back a pretty long

00:09:54,650 --> 00:10:00,410
time at the end of 2013 I gave a talk

00:09:57,740 --> 00:10:03,410
whose subtitle was ten things I hate

00:10:00,410 --> 00:10:05,030
about pandas and people thought that was

00:10:03,410 --> 00:10:08,720
funny we're like you build it you know

00:10:05,030 --> 00:10:10,760
shouldn't you really love it but I I

00:10:08,720 --> 00:10:13,130
knew about all of its flaws and at the

00:10:10,760 --> 00:10:15,110
end of at the end of 20 2015 we started

00:10:13,130 --> 00:10:17,060
talking about ways that we can make the

00:10:15,110 --> 00:10:18,740
project better and one of the things

00:10:17,060 --> 00:10:21,170
that's come out of that discussion is

00:10:18,740 --> 00:10:23,240
the fact that we would like to own less

00:10:21,170 --> 00:10:26,060
of the infrastructure that enables

00:10:23,240 --> 00:10:28,370
projects like pandas to exist so that's

00:10:26,060 --> 00:10:30,740
you know valid you know to think about

00:10:28,370 --> 00:10:32,510
how much time we've spent writing CSV

00:10:30,740 --> 00:10:36,050
readers but we've spent all that time

00:10:32,510 --> 00:10:37,850
because it is so important and so my

00:10:36,050 --> 00:10:40,970
hypothesis is what if we could make the

00:10:37,850 --> 00:10:43,750
the silos quote smaller and have some

00:10:40,970 --> 00:10:45,980
kind of software that we share across

00:10:43,750 --> 00:10:48,170
ecosystems and it would make it easier

00:10:45,980 --> 00:10:50,180
in the future to build projects like

00:10:48,170 --> 00:10:54,530
pandas to build projects like deep wire

00:10:50,180 --> 00:10:56,330
for our when you think about what are

00:10:54,530 --> 00:10:58,790
programming languages programming

00:10:56,330 --> 00:11:02,690
languages are user interfaces for

00:10:58,790 --> 00:11:04,460
describing computation and we choose our

00:11:02,690 --> 00:11:06,140
programming languages for many reasons

00:11:04,460 --> 00:11:08,120
some of them it's because the people

00:11:06,140 --> 00:11:10,430
that we work with use that language

00:11:08,120 --> 00:11:12,680
but one of the reasons that Python and

00:11:10,430 --> 00:11:15,290
our and and other data science languages

00:11:12,680 --> 00:11:17,360
have become so successful is because the

00:11:15,290 --> 00:11:19,550
programming languages are maximized for

00:11:17,360 --> 00:11:21,830
your productivity so that you can get a

00:11:19,550 --> 00:11:25,070
lot of work done in a short amount of

00:11:21,830 --> 00:11:27,290
time and I use the the iceberg metaphor

00:11:25,070 --> 00:11:29,600
and talking about programming languages

00:11:27,290 --> 00:11:31,520
and data science systems because the the

00:11:29,600 --> 00:11:35,390
amount of the portion of the software

00:11:31,520 --> 00:11:39,020
that you see is a fairly small part of

00:11:35,390 --> 00:11:40,670
the codebase you see the user API that

00:11:39,020 --> 00:11:41,870
the engineers have created like this is

00:11:40,670 --> 00:11:44,210
how you interact with this piece of

00:11:41,870 --> 00:11:46,310
software but there's a huge body of code

00:11:44,210 --> 00:11:48,260
that you don't see and that frankly you

00:11:46,310 --> 00:11:49,850
don't want to see there's parts of

00:11:48,260 --> 00:11:52,310
pandas that you know if we showed you'd

00:11:49,850 --> 00:11:55,010
be like oh my goodness like I never want

00:11:52,310 --> 00:11:56,990
to see this again but this is great

00:11:55,010 --> 00:11:59,270
because as engineers this allows us to

00:11:56,990 --> 00:12:01,490
hide all this complexity from you and

00:11:59,270 --> 00:12:04,640
show you only the parts of the library

00:12:01,490 --> 00:12:07,250
that you need to get your work done so

00:12:04,640 --> 00:12:08,990
you know if we look at some r and python

00:12:07,250 --> 00:12:11,510
examples even the code looks very

00:12:08,990 --> 00:12:13,970
similar so here we have an r example

00:12:11,510 --> 00:12:16,250
using d plier reading a csv file and the

00:12:13,970 --> 00:12:17,870
python code for that looks almost the

00:12:16,250 --> 00:12:22,550
same but it uses a different

00:12:17,870 --> 00:12:25,400
implementation under the hood so my

00:12:22,550 --> 00:12:27,770
hypothesis is what if and here's the big

00:12:25,400 --> 00:12:30,350
what if we could create what I call a

00:12:27,770 --> 00:12:32,839
shared data science runtime that could

00:12:30,350 --> 00:12:34,459
be responsible for some of these tasks

00:12:32,839 --> 00:12:36,920
which are common to all of the all of

00:12:34,459 --> 00:12:40,370
the frameworks now this might sound like

00:12:36,920 --> 00:12:43,850
total total vaporware so I'm going to

00:12:40,370 --> 00:12:46,279
give you an idea of what I think needs

00:12:43,850 --> 00:12:48,350
to go in that shared runtime and how we

00:12:46,279 --> 00:12:54,740
might go about building it together as a

00:12:48,350 --> 00:12:57,740
community so the first part and here's

00:12:54,740 --> 00:13:00,980
where we have to take a leap of faith we

00:12:57,740 --> 00:13:03,529
have data frames in most languages

00:13:00,980 --> 00:13:05,720
python has a panda's data frame R as a

00:13:03,529 --> 00:13:07,250
data frame we call them data frames but

00:13:05,720 --> 00:13:10,490
in reality our data frames are very

00:13:07,250 --> 00:13:12,470
different when you look inside so that's

00:13:10,490 --> 00:13:14,450
a problem because when I write an

00:13:12,470 --> 00:13:15,020
algorithm that manipulates a panda's

00:13:14,450 --> 00:13:16,940
data frame

00:13:15,020 --> 00:13:19,730
that's not something code that you can

00:13:16,940 --> 00:13:21,440
take and use to process the data that is

00:13:19,730 --> 00:13:23,720
inside an R data frame

00:13:21,440 --> 00:13:25,400
and vice-versa so if we want to build

00:13:23,720 --> 00:13:27,710
algorithms that can be shared between

00:13:25,400 --> 00:13:30,890
environments we have to have a data

00:13:27,710 --> 00:13:35,060
frame in memory format which is portable

00:13:30,890 --> 00:13:36,980
across environments a second part of the

00:13:35,060 --> 00:13:39,980
problem is that we need to be able to

00:13:36,980 --> 00:13:42,290
share data between environments without

00:13:39,980 --> 00:13:44,780
incurring any overhead so if you have a

00:13:42,290 --> 00:13:46,820
data frame in Python and then you want

00:13:44,780 --> 00:13:49,210
to run some R code on it if you have to

00:13:46,820 --> 00:13:52,790
pay this huge cost to move that data

00:13:49,210 --> 00:13:54,320
from python r you might be incentivized

00:13:52,790 --> 00:13:56,150
not to do it at all and just figure out

00:13:54,320 --> 00:13:57,470
a way to do it in python so if we could

00:13:56,150 --> 00:14:00,320
make these transitions between

00:13:57,470 --> 00:14:02,630
ecosystems including including things

00:14:00,320 --> 00:14:04,280
happening in the java world that would

00:14:02,630 --> 00:14:09,890
be really powerful and would help make

00:14:04,280 --> 00:14:11,660
our tools a lot more composable third

00:14:09,890 --> 00:14:13,940
part of the problem is it's not enough

00:14:11,660 --> 00:14:16,880
to have a portable data frame we need to

00:14:13,940 --> 00:14:19,580
be able to get data into it so we need

00:14:16,880 --> 00:14:21,410
to create optimized data connectors to

00:14:19,580 --> 00:14:24,680
all of the formats that we use in

00:14:21,410 --> 00:14:27,350
practice so this would be really great

00:14:24,680 --> 00:14:29,900
because me as a panda's user this means

00:14:27,350 --> 00:14:32,720
that I could stop maintaining a lot of

00:14:29,900 --> 00:14:35,330
pandas don't read CSV if you're an R

00:14:32,720 --> 00:14:38,450
user the code that implements R read CSV

00:14:35,330 --> 00:14:39,950
could also be the burden of developing

00:14:38,450 --> 00:14:44,810
that could be shifted to a much larger

00:14:39,950 --> 00:14:47,720
group of developers the last part of

00:14:44,810 --> 00:14:50,120
this and maybe the hardest hardest part

00:14:47,720 --> 00:14:53,000
is building a computation engine that is

00:14:50,120 --> 00:14:55,700
able to compute things to perform

00:14:53,000 --> 00:14:58,190
computations natively on portable data

00:14:55,700 --> 00:14:59,960
frames and this is a big topic and I

00:14:58,190 --> 00:15:02,440
could give a whole hour long or 3-hour

00:14:59,960 --> 00:15:05,150
long discourse on all of my ideas about

00:15:02,440 --> 00:15:07,730
what we could build in this type of

00:15:05,150 --> 00:15:10,310
engine but the key things are that you

00:15:07,730 --> 00:15:12,230
need to be able to embed it in existing

00:15:10,310 --> 00:15:14,300
systems so it needs to be embeddable in

00:15:12,230 --> 00:15:17,150
an our application embeddable in a julia

00:15:14,300 --> 00:15:19,250
application or python application you

00:15:17,150 --> 00:15:21,530
need to be able to extend it with

00:15:19,250 --> 00:15:24,440
functions which are written in the host

00:15:21,530 --> 00:15:27,140
language so if you write a new function

00:15:24,440 --> 00:15:28,970
to extend the computation engine in

00:15:27,140 --> 00:15:31,040
python that it can exist as a

00:15:28,970 --> 00:15:32,839
first-class citizen and you don't pay a

00:15:31,040 --> 00:15:35,120
performance penalty when you evaluate

00:15:32,839 --> 00:15:37,370
that code and if you look at system

00:15:35,120 --> 00:15:39,110
like Apache spark which have Python and

00:15:37,370 --> 00:15:40,610
are api's this has been one of the

00:15:39,110 --> 00:15:42,740
largest pain points that when you want

00:15:40,610 --> 00:15:45,490
to extend spark with user-defined

00:15:42,740 --> 00:15:48,170
functions you pay pay a heavy penalty

00:15:45,490 --> 00:15:50,960
you also another a slightly esoteric

00:15:48,170 --> 00:15:53,720
point is that if you describe a sequence

00:15:50,960 --> 00:15:55,010
of operations using this library you

00:15:53,720 --> 00:15:58,310
would like to create a represent

00:15:55,010 --> 00:15:59,470
representation of that computation that

00:15:58,310 --> 00:16:02,150
could be carried over to another

00:15:59,470 --> 00:16:07,250
environment and evaluated in a portable

00:16:02,150 --> 00:16:10,100
way so a couple of years ago I started

00:16:07,250 --> 00:16:13,100
thinking you know I can't do this alone

00:16:10,100 --> 00:16:14,960
and I tried to find a group of people

00:16:13,100 --> 00:16:16,160
who were like-minded and wanted to work

00:16:14,960 --> 00:16:18,380
on this problem together

00:16:16,160 --> 00:16:20,810
we decided to create a project in the

00:16:18,380 --> 00:16:23,930
Apache Software Foundation which we are

00:16:20,810 --> 00:16:25,490
calling arrow and it doesn't solve all

00:16:23,930 --> 00:16:27,230
four of these problems but we've been

00:16:25,490 --> 00:16:30,650
most focused on building portable data

00:16:27,230 --> 00:16:32,540
frames and zero copy interchange between

00:16:30,650 --> 00:16:35,150
environments and so this is what I've

00:16:32,540 --> 00:16:36,830
been spending a lot of the last two

00:16:35,150 --> 00:16:39,200
years working on so if you see me being

00:16:36,830 --> 00:16:41,300
very busy on github a lot of it is

00:16:39,200 --> 00:16:43,339
building as building the arrow format

00:16:41,300 --> 00:16:45,589
because that means I can build

00:16:43,339 --> 00:16:48,920
algorithms against a data frame that is

00:16:45,589 --> 00:16:51,440
the same across across languages and so

00:16:48,920 --> 00:16:54,230
in thinking about how we are approaching

00:16:51,440 --> 00:16:56,060
the the arrow problem we need our data

00:16:54,230 --> 00:16:59,480
frame to be a superset of the things

00:16:56,060 --> 00:17:01,040
that you can do in our in pandas but

00:16:59,480 --> 00:17:03,500
also sequel engines in particular

00:17:01,040 --> 00:17:07,280
columnar sequel engines it needs to be

00:17:03,500 --> 00:17:09,319
optimized for processing processing

00:17:07,280 --> 00:17:11,780
performance so that it's efficient on

00:17:09,319 --> 00:17:14,300
CPUs we're also seeing arrow used on

00:17:11,780 --> 00:17:16,490
GPUs and other hardware as well and

00:17:14,300 --> 00:17:19,010
another part of the problem is that it

00:17:16,490 --> 00:17:20,780
needs to be done in a way where the

00:17:19,010 --> 00:17:22,429
project is owned by the community and

00:17:20,780 --> 00:17:24,650
not by an individual or a corporation

00:17:22,429 --> 00:17:26,720
and so we've done it as an Apache

00:17:24,650 --> 00:17:29,809
project so that our development process

00:17:26,720 --> 00:17:33,860
is open transparent and that the aro

00:17:29,809 --> 00:17:35,179
project is owned by you the community so

00:17:33,860 --> 00:17:37,130
many of you might have seen that that

00:17:35,179 --> 00:17:39,650
had Lee Wickham and I got together at

00:17:37,130 --> 00:17:41,179
the beginning of last year I told him

00:17:39,650 --> 00:17:43,460
about arrow and one of the first things

00:17:41,179 --> 00:17:45,350
that we did is we said let's pare down

00:17:43,460 --> 00:17:47,240
arrow to just the bare essentials for

00:17:45,350 --> 00:17:48,280
Python and R and make a file format

00:17:47,240 --> 00:17:50,320
that's interoperable

00:17:48,280 --> 00:17:52,000
between our and Python and so we're

00:17:50,320 --> 00:17:53,920
really excited to you know to ship that

00:17:52,000 --> 00:17:55,840
and to socialize the idea of

00:17:53,920 --> 00:17:57,070
interoperable data and being able to

00:17:55,840 --> 00:18:00,160
transition efficiently between

00:17:57,070 --> 00:18:02,230
environments so I'm happy to report that

00:18:00,160 --> 00:18:04,030
there been there's been quite a bit of

00:18:02,230 --> 00:18:05,860
adoption of arrow amongst a variety of

00:18:04,030 --> 00:18:08,920
open-source projects which I'll allow

00:18:05,860 --> 00:18:12,160
you to explore on your own as I'm

00:18:08,920 --> 00:18:13,780
running out of time but this is a big

00:18:12,160 --> 00:18:15,940
problem but seeing what we've

00:18:13,780 --> 00:18:17,500
accomplished in the last ten years I

00:18:15,940 --> 00:18:19,420
believe this is something that we can

00:18:17,500 --> 00:18:21,160
all build together and the more we

00:18:19,420 --> 00:18:22,090
collaborate the faster we can bring

00:18:21,160 --> 00:18:24,190
about this future

00:18:22,090 --> 00:18:26,200
and as I like to say when you have a

00:18:24,190 --> 00:18:28,780
chicken-and-egg problem sometimes the

00:18:26,200 --> 00:18:33,450
best thing you can do is be the chicken

00:18:28,780 --> 00:18:40,849
so please be be the chicken thank you

00:18:33,450 --> 00:18:40,849

YouTube URL: https://www.youtube.com/watch?v=wdmf1msbtVs


