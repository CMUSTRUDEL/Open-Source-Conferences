Title: AI and AR a match made in heaven
Publication date: 2020-01-09
Playlist: linux.conf.au 2019
Description: 
	J Rosenbaum

https://2019.linux.conf.au/schedule/presentation/109/

I will discuss my journey to bridge the digital world and the physical world with my Augmented Reality and Artificial Intelligence based artworks and demonstrate artworks made by other artists working in AR and AI while discussing the technologies involved and the impact they will have on development, art and the way we view the world. 

From computer vision to style transfers, Generative Adversarial Networks and Image Classifiers and Augmented Reality platforms, I will explore the highs, the lows, the creepy and the exciting moments that come from working as an artist collaborating with a computer. 

⚠️ Content warning: This talk contains images of artistic nudity

linux.conf.au is a conference about the Linux operating system, and all aspects of the thriving ecosystem of Free and Open Source Software that has grown up around it. Run since 1999, in a different Australian or New Zealand city each year, by a team of local volunteers, LCA invites more than 500 people to learn from the people who shape the future of Open Source. For more information on the conference see https://linux.conf.au/

#linux.conf.au #linux #foss #opensource
Captions: 
	00:00:00,000 --> 00:00:14,759
welcome Jackie Rosenbaum hi everyone I

00:00:11,540 --> 00:00:17,609
often get asked how did you get here

00:00:14,759 --> 00:00:20,760
and isn't machine learning really hard

00:00:17,609 --> 00:00:23,340
and I understand that I'm an artist not

00:00:20,760 --> 00:00:24,869
a traditional developer but I do have a

00:00:23,340 --> 00:00:27,539
small background in carding

00:00:24,869 --> 00:00:30,630
back in the long long ago and I know

00:00:27,539 --> 00:00:32,009
enough what is that they say a little

00:00:30,630 --> 00:00:35,969
knowledge is a dangerous thing

00:00:32,009 --> 00:00:37,829
yeah that's me I didn't know machine

00:00:35,969 --> 00:00:39,210
learning was hard when I started I think

00:00:37,829 --> 00:00:42,059
that's the thing you all need to know I

00:00:39,210 --> 00:00:43,649
saw something cool and I found a repro

00:00:42,059 --> 00:00:46,140
with instructions I had to learn

00:00:43,649 --> 00:00:48,600
everything but I was excited about the

00:00:46,140 --> 00:00:51,239
project and the possibilities and I dove

00:00:48,600 --> 00:00:53,820
into the deep end headfirst it wasn't

00:00:51,239 --> 00:00:56,399
until I was in neck deep that I realized

00:00:53,820 --> 00:00:58,739
how difficult it all was and by then the

00:00:56,399 --> 00:01:00,719
only way out was through and then

00:00:58,739 --> 00:01:03,120
another project came along and another

00:01:00,719 --> 00:01:05,430
and another and a different way of doing

00:01:03,120 --> 00:01:09,330
things than another and I just got swept

00:01:05,430 --> 00:01:11,280
up in it all because when you're

00:01:09,330 --> 00:01:13,590
passionate about something when you're

00:01:11,280 --> 00:01:16,890
excited to get going there aren't that

00:01:13,590 --> 00:01:19,140
many barriers to entry as long as you

00:01:16,890 --> 00:01:21,060
remain stubborn and enthralled by the

00:01:19,140 --> 00:01:22,650
thing you're pursuing and the resources

00:01:21,060 --> 00:01:27,000
are there you can work your way through

00:01:22,650 --> 00:01:29,159
anything that is why machine learning

00:01:27,000 --> 00:01:32,100
and mixed reality and IRT are so

00:01:29,159 --> 00:01:34,770
exciting because not only can you make

00:01:32,100 --> 00:01:36,750
amazing things but the resources are

00:01:34,770 --> 00:01:39,240
there to help you with almost every

00:01:36,750 --> 00:01:43,590
problem you come across and I should

00:01:39,240 --> 00:01:46,560
know because I've come across a lot but

00:01:43,590 --> 00:01:48,630
I'm getting ahead of myself a developer

00:01:46,560 --> 00:01:50,430
and an artist how does that even work

00:01:48,630 --> 00:01:52,590
don't they use different parts of the

00:01:50,430 --> 00:01:54,960
brain or different and totally unrelated

00:01:52,590 --> 00:01:57,329
abilities absolutely not

00:01:54,960 --> 00:01:59,700
you'd be amazed at the mathematics that

00:01:57,329 --> 00:02:01,229
are present in painting in planning and

00:01:59,700 --> 00:02:03,810
artwork and arranging the composition

00:02:01,229 --> 00:02:06,630
and mixing the colors the physics and

00:02:03,810 --> 00:02:09,060
chemistry in producing a painting or a

00:02:06,630 --> 00:02:12,150
sculpture creative endeavors have seen

00:02:09,060 --> 00:02:12,970
as easy because the hard science beneath

00:02:12,150 --> 00:02:15,190
is cleverly

00:02:12,970 --> 00:02:17,320
but painting and art making are just

00:02:15,190 --> 00:02:19,300
another facet of creation just like

00:02:17,320 --> 00:02:22,510
producing an app or a web page or a

00:02:19,300 --> 00:02:25,540
robot and all creating uses a wealth of

00:02:22,510 --> 00:02:30,550
skills programming is a language like

00:02:25,540 --> 00:02:32,710
art and programming is an art form but

00:02:30,550 --> 00:02:34,900
when people ask isn't machine learning

00:02:32,710 --> 00:02:39,010
really hard my response is so is

00:02:34,900 --> 00:02:41,770
everything worth doing because it is

00:02:39,010 --> 00:02:44,350
everything is hard at first painting is

00:02:41,770 --> 00:02:46,330
hard programming his heart everything

00:02:44,350 --> 00:02:48,370
involves knowledge of your framework or

00:02:46,330 --> 00:02:50,110
your substrate your materials or

00:02:48,370 --> 00:02:51,940
language and the basic principles

00:02:50,110 --> 00:02:54,820
underneath that help govern your

00:02:51,940 --> 00:02:56,950
creation you don't need to be Picasso to

00:02:54,820 --> 00:02:59,590
start either anyone can pick up a

00:02:56,950 --> 00:03:02,020
paintbrush or a camera but you have to

00:02:59,590 --> 00:03:04,900
dedicate yourself to it and decide to

00:03:02,020 --> 00:03:05,800
make something amazing that decision is

00:03:04,900 --> 00:03:07,660
what matters

00:03:05,800 --> 00:03:10,420
not the skill you bring into it at the

00:03:07,660 --> 00:03:12,670
start but the decision to start the

00:03:10,420 --> 00:03:16,050
skill you evolve as you progress and

00:03:12,670 --> 00:03:19,600
what you have to say with what you make

00:03:16,050 --> 00:03:22,120
what do you want to say and how do you

00:03:19,600 --> 00:03:24,550
want to say it anything worth doing

00:03:22,120 --> 00:03:26,230
should involve asking yourself those

00:03:24,550 --> 00:03:28,720
questions and then working through the

00:03:26,230 --> 00:03:31,750
answers it's as simple and as difficult

00:03:28,720 --> 00:03:34,450
as that whether you're making art or

00:03:31,750 --> 00:03:38,650
making code or both those questions

00:03:34,450 --> 00:03:40,390
should be your first stop when I started

00:03:38,650 --> 00:03:42,880
in my master's degree I was a painter

00:03:40,390 --> 00:03:45,640
and having painted for over 10 years I

00:03:42,880 --> 00:03:47,440
was not bad that made it 3d models

00:03:45,640 --> 00:03:49,540
tracked his life models for my paintings

00:03:47,440 --> 00:03:51,220
and that was working well for me so I

00:03:49,540 --> 00:03:52,870
went into my masters selling pretty

00:03:51,220 --> 00:03:55,930
confident I actually got in without a

00:03:52,870 --> 00:03:57,700
bachelor's degree so I had a

00:03:55,930 --> 00:04:00,610
conversation with the head of department

00:03:57,700 --> 00:04:04,180
during a review went along the lines of

00:04:00,610 --> 00:04:08,980
look your paintings are good but and I'm

00:04:04,180 --> 00:04:11,890
thinking oh and he went on to say these

00:04:08,980 --> 00:04:13,690
renders these are where it's at and it

00:04:11,890 --> 00:04:16,359
caused me to take a good hard look at

00:04:13,690 --> 00:04:18,250
where I wanted to go because over the

00:04:16,359 --> 00:04:21,549
years I'd started enjoying the process

00:04:18,250 --> 00:04:23,979
of painting less and less and the 3d

00:04:21,549 --> 00:04:26,650
modeling more and more and I was

00:04:23,979 --> 00:04:29,050
enjoying learning about different things

00:04:26,650 --> 00:04:31,090
and I could do with it and say with it I

00:04:29,050 --> 00:04:33,699
wasn't saying anything truly new or

00:04:31,090 --> 00:04:36,100
unique with my paintings so in a way

00:04:33,699 --> 00:04:38,710
this was my opportunity to say goodbye

00:04:36,100 --> 00:04:41,229
to painting and go after the area I was

00:04:38,710 --> 00:04:46,570
most interested in making art with my

00:04:41,229 --> 00:04:48,970
computer and it was amazing then I saw a

00:04:46,570 --> 00:04:50,320
simple augmented reality app that a

00:04:48,970 --> 00:04:52,540
friend of fellow artists took

00:04:50,320 --> 00:04:55,870
commissioned to bring one of his

00:04:52,540 --> 00:04:57,250
paintings to life he commissioned a Jim

00:04:55,870 --> 00:05:00,160
phallus Otis commissioned er from a

00:04:57,250 --> 00:05:01,810
positive comdataís you and being a very

00:05:00,160 --> 00:05:04,750
wealthy artist he could afford to pay

00:05:01,810 --> 00:05:07,780
somebody to do it but it inspired me

00:05:04,750 --> 00:05:10,240
I found a simple app or ESMA that would

00:05:07,780 --> 00:05:12,190
allow me to create it online and I put

00:05:10,240 --> 00:05:13,780
together a short animation and shyly

00:05:12,190 --> 00:05:16,410
showed one of my professors and he

00:05:13,780 --> 00:05:20,370
literally took a step back in shock and

00:05:16,410 --> 00:05:23,770
now is it I was hooked on that reaction

00:05:20,370 --> 00:05:26,020
on that moment and I was hooked on the

00:05:23,770 --> 00:05:28,630
idea of revealing a truth behind the

00:05:26,020 --> 00:05:31,330
work to be able to show more than the

00:05:28,630 --> 00:05:34,060
printed piece would allow I'm a gamer

00:05:31,330 --> 00:05:38,080
and I loved the idea of hiding Easter

00:05:34,060 --> 00:05:40,180
eggs in my work but I still had

00:05:38,080 --> 00:05:42,460
something - I had to find something to

00:05:40,180 --> 00:05:44,169
say with all of this technology because

00:05:42,460 --> 00:05:46,330
it's all very well and good having

00:05:44,169 --> 00:05:48,400
awesome technology but as my supervisor

00:05:46,330 --> 00:05:50,530
said to me where is the art and I took

00:05:48,400 --> 00:05:52,630
that to heart and I asked myself that

00:05:50,530 --> 00:05:55,240
every time because the art is the

00:05:52,630 --> 00:05:58,990
important part the message the meaning

00:05:55,240 --> 00:06:00,940
the reason for its existence while I was

00:05:58,990 --> 00:06:02,889
muddling through this dilemma of what to

00:06:00,940 --> 00:06:05,169
say with my work a friend shared an

00:06:02,889 --> 00:06:07,060
inter post on style transfer and I

00:06:05,169 --> 00:06:09,870
started to delve into the possibilities

00:06:07,060 --> 00:06:12,729
I was already intrigued by deep dream

00:06:09,870 --> 00:06:15,780
but I couldn't say any use for it in my

00:06:12,729 --> 00:06:18,039
work but this this just clicked for me

00:06:15,780 --> 00:06:20,440
my work uses a lot of archaeological

00:06:18,039 --> 00:06:21,970
influences and I thought it would be

00:06:20,440 --> 00:06:23,979
interesting to see the computer

00:06:21,970 --> 00:06:26,530
reinterpret my work in the style of its

00:06:23,979 --> 00:06:28,990
original inspiration but the easy-to-use

00:06:26,530 --> 00:06:30,570
website hasta gram da ru was down

00:06:28,990 --> 00:06:33,610
because the post went viral

00:06:30,570 --> 00:06:35,560
so I furiously scanned the comments

00:06:33,610 --> 00:06:37,300
looking for another option something

00:06:35,560 --> 00:06:39,289
that would allow me to harness this

00:06:37,300 --> 00:06:42,649
amazing technology I was already so

00:06:39,289 --> 00:06:45,259
obsessed and there it was a link to the

00:06:42,649 --> 00:06:47,539
repo I barely had any idea what I was

00:06:45,259 --> 00:06:49,729
doing but I remembered how to use

00:06:47,539 --> 00:06:54,919
command line functions it couldn't be

00:06:49,729 --> 00:06:57,080
that hard right that first repo used

00:06:54,919 --> 00:06:58,729
torch as the framework and Lua as the

00:06:57,080 --> 00:07:00,589
language and I remember going from repo

00:06:58,729 --> 00:07:02,029
to repo and learning how to download all

00:07:00,589 --> 00:07:05,089
of the dependencies because it didn't

00:07:02,029 --> 00:07:07,879
have a requirements text and I learned

00:07:05,089 --> 00:07:10,550
how to use Pip and harbor and it took me

00:07:07,879 --> 00:07:12,649
a few days but I got it working and I

00:07:10,550 --> 00:07:16,430
produced my very first style transfer it

00:07:12,649 --> 00:07:19,909
was hideous but it was mine well mine

00:07:16,430 --> 00:07:22,339
and my computers I didn't know where I

00:07:19,909 --> 00:07:24,409
was going when I started I didn't know

00:07:22,339 --> 00:07:26,629
what the art would be I was still hooked

00:07:24,409 --> 00:07:29,240
on the technology at this point but I

00:07:26,629 --> 00:07:30,800
could see something there some potential

00:07:29,240 --> 00:07:32,509
for augmented reality and machine

00:07:30,800 --> 00:07:35,659
learning together to make something new

00:07:32,509 --> 00:07:37,759
and it started to resolve it started to

00:07:35,659 --> 00:07:40,249
come through I started working with the

00:07:37,759 --> 00:07:42,050
base code but my favorite part was the

00:07:40,249 --> 00:07:44,899
way the works would slowly transform

00:07:42,050 --> 00:07:49,069
across the iterations and slowly the

00:07:44,899 --> 00:07:52,219
final work started to take shape but I

00:07:49,069 --> 00:07:54,050
hit a snag it turns out Aurasma was very

00:07:52,219 --> 00:07:57,050
expensive and if I wanted my own

00:07:54,050 --> 00:07:58,909
branding and interface I had to pay them

00:07:57,050 --> 00:08:01,039
I think was five thousand dollars for a

00:07:58,909 --> 00:08:03,259
white labelled app so I started to

00:08:01,039 --> 00:08:06,349
research more options and realized that

00:08:03,259 --> 00:08:08,449
the cheapest way would be to make an app

00:08:06,349 --> 00:08:10,849
for myself using a library like before

00:08:08,449 --> 00:08:13,759
wicket ood after all how hard is it to

00:08:10,849 --> 00:08:17,089
get an app approved on the App Store it

00:08:13,759 --> 00:08:20,269
couldn't be that hard right yeah I asked

00:08:17,089 --> 00:08:21,889
myself that question a lot but thanks to

00:08:20,269 --> 00:08:24,349
the power of Google and a lot of hard

00:08:21,889 --> 00:08:26,269
work I made my own augmented reality app

00:08:24,349 --> 00:08:28,189
and 14 machine learning animations that

00:08:26,269 --> 00:08:30,469
shift back and forth that were presented

00:08:28,189 --> 00:08:33,079
with seven realistic renders and seven

00:08:30,469 --> 00:08:35,990
laser-cut abstractions based on the

00:08:33,079 --> 00:08:38,719
machine learning outputs and the art was

00:08:35,990 --> 00:08:41,810
the art in all of this I titled the app

00:08:38,719 --> 00:08:43,729
recursion recursion is where a function

00:08:41,810 --> 00:08:45,170
being defined is applied in its own

00:08:43,729 --> 00:08:47,750
definition as you all know in

00:08:45,170 --> 00:08:50,540
linguistics it's about repetition each

00:08:47,750 --> 00:08:52,160
artwork in this series is repeated and

00:08:50,540 --> 00:08:52,640
resolves to each other

00:08:52,160 --> 00:08:57,710
the

00:08:52,640 --> 00:08:59,420
a pattern inside h1 engender the act of

00:08:57,710 --> 00:09:01,550
defining your own gender also helps

00:08:59,420 --> 00:09:04,730
clarify it for you and contribute to the

00:09:01,550 --> 00:09:06,890
known definitions of gender we define

00:09:04,730 --> 00:09:08,810
our gender for ourselves and then apply

00:09:06,890 --> 00:09:11,420
that definition and that helps others

00:09:08,810 --> 00:09:13,250
with their own gender journey these

00:09:11,420 --> 00:09:15,140
works are about transness and about

00:09:13,250 --> 00:09:17,360
non-binary and non passing transness in

00:09:15,140 --> 00:09:19,670
particular they're about the internal

00:09:17,360 --> 00:09:21,710
journey of being a trans person and how

00:09:19,670 --> 00:09:24,800
we're so much more than our bodies or

00:09:21,710 --> 00:09:27,290
our outward presentation in this case

00:09:24,800 --> 00:09:29,990
the art is more than what's on the wall

00:09:27,290 --> 00:09:32,810
but a deeply personal internal visual

00:09:29,990 --> 00:09:34,730
monologue for each person this was my

00:09:32,810 --> 00:09:45,860
first exploration into machine learning

00:09:34,730 --> 00:09:48,440
and I was hooked my research for my PhD

00:09:45,860 --> 00:09:50,510
is on computer perceptions of gender and

00:09:48,440 --> 00:09:53,570
the way that machines learn and create

00:09:50,510 --> 00:09:56,000
and there is no better way to a medium

00:09:53,570 --> 00:09:58,130
to explore that then through the lens of

00:09:56,000 --> 00:10:01,340
augmented reality and Missha artificial

00:09:58,130 --> 00:10:03,020
intelligence my first works of my most

00:10:01,340 --> 00:10:06,440
recent work six ploor gender with a

00:10:03,020 --> 00:10:08,570
mixed data set of marble statuary the

00:10:06,440 --> 00:10:10,160
results blend gender together in a

00:10:08,570 --> 00:10:12,830
fascinating way that I'm excited to

00:10:10,160 --> 00:10:14,360
continue exploring I then examined the

00:10:12,830 --> 00:10:16,640
abstract results and created my own

00:10:14,360 --> 00:10:19,160
responses to the generated works these

00:10:16,640 --> 00:10:21,350
all unite seamlessly together inside an

00:10:19,160 --> 00:10:23,420
app that explores interactive 3d models

00:10:21,350 --> 00:10:25,040
based on the generated art with a neural

00:10:23,420 --> 00:10:27,020
network generated narrative based on

00:10:25,040 --> 00:10:29,750
image classifications and captions that

00:10:27,020 --> 00:10:31,640
shift in gender and tone by mixing

00:10:29,750 --> 00:10:33,860
different media displays on the wall

00:10:31,640 --> 00:10:36,470
music speech and 3d modeling I'm

00:10:33,860 --> 00:10:38,270
leveraging mixed reality technologies to

00:10:36,470 --> 00:10:41,420
keep it all in place and create an

00:10:38,270 --> 00:10:43,580
installation experience while the

00:10:41,420 --> 00:10:46,550
technology is cool here the meaning is

00:10:43,580 --> 00:10:48,980
clear it examines the social construct

00:10:46,550 --> 00:10:52,520
of gender and assumptions based on fresh

00:10:48,980 --> 00:10:54,050
glances the soundtrack elements for this

00:10:52,520 --> 00:10:56,210
series were inspired by the works of

00:10:54,050 --> 00:10:58,520
Troy innocent who uses augmented reality

00:10:56,210 --> 00:11:00,290
and creates work around the nature of

00:10:58,520 --> 00:11:02,570
card and concepts of pattern recognition

00:11:00,290 --> 00:11:05,630
and how they affect the world at large

00:11:02,570 --> 00:11:06,500
his highly geometric works both in

00:11:05,630 --> 00:11:08,480
gallery and

00:11:06,500 --> 00:11:10,070
in Melbourne cyclonic laneways are

00:11:08,480 --> 00:11:12,130
centered around code as a visual

00:11:10,070 --> 00:11:14,420
language and the augmented reality

00:11:12,130 --> 00:11:16,880
component firing off sound elements

00:11:14,420 --> 00:11:19,490
overlaying digital map keys and weather

00:11:16,880 --> 00:11:21,770
visualization shows machines responses

00:11:19,490 --> 00:11:24,440
to pattern recognition as well as our

00:11:21,770 --> 00:11:26,930
own while there is no machine learning

00:11:24,440 --> 00:11:28,700
directly in these works they explore the

00:11:26,930 --> 00:11:32,630
concept of the daily machine learning

00:11:28,700 --> 00:11:34,430
that surrounds us extended reality is

00:11:32,630 --> 00:11:36,650
the term for layering a new interactive

00:11:34,430 --> 00:11:39,200
digital reality on top of our existing

00:11:36,650 --> 00:11:41,480
mundane one it encompasses interactive

00:11:39,200 --> 00:11:43,610
mixed reality augmented reality via

00:11:41,480 --> 00:11:46,400
traditional means and via wearables and

00:11:43,610 --> 00:11:48,500
virtual reality a world layered on our

00:11:46,400 --> 00:11:50,000
own screens width away a world of

00:11:48,500 --> 00:11:52,520
digital creations and digital

00:11:50,000 --> 00:11:54,770
intelligence we grant access to other

00:11:52,520 --> 00:11:56,900
worlds through augmented reality why not

00:11:54,770 --> 00:12:00,410
also explore the spaces where machines

00:11:56,900 --> 00:12:01,880
learn there are a number of platforms

00:12:00,410 --> 00:12:03,890
for developing augmented reality

00:12:01,880 --> 00:12:06,350
depending on your budget and objectives

00:12:03,890 --> 00:12:07,940
you can get a white label app for more

00:12:06,350 --> 00:12:09,920
asthma and do everything via their web

00:12:07,940 --> 00:12:12,110
interface or if you're like me and have

00:12:09,920 --> 00:12:13,700
no money you and you're happy to

00:12:12,110 --> 00:12:16,730
experiment with the possibilities you

00:12:13,700 --> 00:12:21,140
may find v4 eeeh wicket ood eith wall or

00:12:16,730 --> 00:12:23,030
a rjs the best solution the first three

00:12:21,140 --> 00:12:25,970
all have packages the work in unity

00:12:23,030 --> 00:12:27,380
they're all free to test out wicket ood

00:12:25,970 --> 00:12:29,180
is free for your first app an eighth

00:12:27,380 --> 00:12:32,480
wallet at this stage is free to use and

00:12:29,180 --> 00:12:34,940
deploy they're all excellent development

00:12:32,480 --> 00:12:37,220
options for pretty much all you need to

00:12:34,940 --> 00:12:39,830
get started building your first AR app

00:12:37,220 --> 00:12:42,680
in this case you can build it in unity

00:12:39,830 --> 00:12:44,240
Xcode or Android studio add your

00:12:42,680 --> 00:12:46,540
interactions deploy it to the App

00:12:44,240 --> 00:12:49,700
Store's to allow people to download it

00:12:46,540 --> 00:12:52,100
this is so cool it's awesome to see your

00:12:49,700 --> 00:12:53,960
name in the App Store but it turns out

00:12:52,100 --> 00:12:55,640
that not everyone wants to download an

00:12:53,960 --> 00:12:58,580
app to their devices just for one event

00:12:55,640 --> 00:13:00,350
even if it is called in unity is

00:12:58,580 --> 00:13:04,640
wonderful for cross-platform development

00:13:00,350 --> 00:13:07,720
but it's slow and it's bulky the unity

00:13:04,640 --> 00:13:10,670
to App Store pipeline is a lot of work

00:13:07,720 --> 00:13:13,130
your other option is to sideload it to

00:13:10,670 --> 00:13:14,870
devices that are available at the venue

00:13:13,130 --> 00:13:19,130
to for people to use which then becomes

00:13:14,870 --> 00:13:20,510
a security concern enter a rjs it's the

00:13:19,130 --> 00:13:23,120
first live web er

00:13:20,510 --> 00:13:24,830
system all your user needs to do is

00:13:23,120 --> 00:13:27,650
point their phone browser at a webpage

00:13:24,830 --> 00:13:32,420
and then look at markers or use the live

00:13:27,650 --> 00:13:36,980
demo options it's much cleaner and

00:13:32,420 --> 00:13:38,450
faster fact if you take out your phones

00:13:36,980 --> 00:13:41,120
I hope this works

00:13:38,450 --> 00:13:43,640
and go to mink strike and github don't I

00:13:41,120 --> 00:13:45,920
or it works best in landscape I will say

00:13:43,640 --> 00:14:01,550
that you should see a quick and dirty

00:13:45,920 --> 00:14:03,590
live web a our demo working I haven't

00:14:01,550 --> 00:14:05,900
had time to test this with the screen so

00:14:03,590 --> 00:14:07,880
I read the projection it should work

00:14:05,900 --> 00:14:20,120
what you should be seeing is a little

00:14:07,880 --> 00:14:22,100
style transferred tux animating yeah at

00:14:20,120 --> 00:14:24,080
the moment it's somewhat rudimentary the

00:14:22,100 --> 00:14:26,540
marker recognition is mainly for classic

00:14:24,080 --> 00:14:29,120
AR style markers but the resolution and

00:14:26,540 --> 00:14:31,100
speed are excellent and the future is

00:14:29,120 --> 00:14:33,740
looking right for web based AR

00:14:31,100 --> 00:14:34,570
development this is just a few lines of

00:14:33,740 --> 00:14:37,400
code

00:14:34,570 --> 00:14:39,290
étoile have just released their own web

00:14:37,400 --> 00:14:41,480
based AR system which has very powerful

00:14:39,290 --> 00:14:43,580
simultaneous location and mapping

00:14:41,480 --> 00:14:45,020
technology which allows things to appear

00:14:43,580 --> 00:14:48,590
on the ground like they're really in the

00:14:45,020 --> 00:14:50,570
world Google and Apple are both working

00:14:48,590 --> 00:14:53,630
on web AR that leverages a our kit and

00:14:50,570 --> 00:14:55,820
AR core these all use javascript and a

00:14:53,630 --> 00:14:58,610
frame via web VR allowing us to use

00:14:55,820 --> 00:15:01,040
WebGL which is live 3d rendering for the

00:14:58,610 --> 00:15:02,660
web WebGL couldn't be created in

00:15:01,040 --> 00:15:04,940
platform online platforms such as

00:15:02,660 --> 00:15:06,680
sketchfab or in more sophisticated

00:15:04,940 --> 00:15:08,720
programs like unity and blender and

00:15:06,680 --> 00:15:12,500
suddenly you can leverage your 3d

00:15:08,720 --> 00:15:15,050
content online now why does augmented

00:15:12,500 --> 00:15:16,430
reality online excite me so much because

00:15:15,050 --> 00:15:19,460
of emerging machine learning

00:15:16,430 --> 00:15:20,870
technologies for the web ml 5 Jas is a

00:15:19,460 --> 00:15:22,580
group of JavaScript libraries

00:15:20,870 --> 00:15:24,350
specifically for machine learning and

00:15:22,580 --> 00:15:28,130
are making machine learning technology

00:15:24,350 --> 00:15:30,290
accessible to many developers like a Ras

00:15:28,130 --> 00:15:34,290
they use just a few lines of code to

00:15:30,290 --> 00:15:36,540
access a new world of development

00:15:34,290 --> 00:15:38,610
emoji scavenger hunt uses tensorflow

00:15:36,540 --> 00:15:41,339
light a lightweight framework for mobile

00:15:38,610 --> 00:15:43,380
use and it's a great example of machine

00:15:41,339 --> 00:15:45,420
learning game that pulls together webcam

00:15:43,380 --> 00:15:47,959
footage with a classifier to find

00:15:45,420 --> 00:15:50,370
real-world emoji using tensorflow j/s

00:15:47,959 --> 00:15:52,889
there's a demo on their website and the

00:15:50,370 --> 00:15:54,810
card to implement it yourself many

00:15:52,889 --> 00:15:56,630
formats of machine learning already rely

00:15:54,810 --> 00:15:59,819
on image camera image classification

00:15:56,630 --> 00:16:01,529
pose net and Yolo which stands for you

00:15:59,819 --> 00:16:04,050
only look once rather than the more

00:16:01,529 --> 00:16:07,230
traditional you only live once and they

00:16:04,050 --> 00:16:10,529
all use live webcam data and superimpose

00:16:07,230 --> 00:16:13,050
their results over the top this is in a

00:16:10,529 --> 00:16:14,639
way a form of augmented reality and in

00:16:13,050 --> 00:16:19,829
the future can be used to supplement

00:16:14,639 --> 00:16:21,990
live augmented reality apps apps like

00:16:19,829 --> 00:16:24,480
snapchat and any app that has a similar

00:16:21,990 --> 00:16:26,310
facial detection and overlay system also

00:16:24,480 --> 00:16:29,639
uses machine learning and augments

00:16:26,310 --> 00:16:31,170
reality to display the results snapchat

00:16:29,639 --> 00:16:33,300
filters and the like have become so

00:16:31,170 --> 00:16:35,190
eponymous with everyday selfies it's

00:16:33,300 --> 00:16:36,920
easy to forget that they use machine

00:16:35,190 --> 00:16:40,560
learning and augmented reality

00:16:36,920 --> 00:16:42,569
seamlessly together it seems strange to

00:16:40,560 --> 00:16:44,880
think of snapchat as a leader in these

00:16:42,569 --> 00:16:46,800
extremely cool technologies merging

00:16:44,880 --> 00:16:49,709
together but in a way it's very fitting

00:16:46,800 --> 00:16:52,860
its augmenting our own very personal

00:16:49,709 --> 00:16:54,480
realities our faces crafting a new

00:16:52,860 --> 00:16:57,690
appearance and sending it out to the

00:16:54,480 --> 00:17:00,540
world as a human CGI hybrid constructed

00:16:57,690 --> 00:17:02,160
using AI facial detection a webcam and

00:17:00,540 --> 00:17:05,010
augmented reality editions and

00:17:02,160 --> 00:17:09,510
components it is posthuman in the best

00:17:05,010 --> 00:17:11,250
sense in fact I'm so obsessed with

00:17:09,510 --> 00:17:14,189
snapchat it's become an area of

00:17:11,250 --> 00:17:15,720
exploration for me using a DC game to

00:17:14,189 --> 00:17:18,569
generate images based on snapchat

00:17:15,720 --> 00:17:21,120
selfies I love the way it in twines the

00:17:18,569 --> 00:17:23,640
hybrid computer human mashups and brings

00:17:21,120 --> 00:17:25,020
them together Computers only understand

00:17:23,640 --> 00:17:26,990
what they've been taught and so it's

00:17:25,020 --> 00:17:29,340
interpretations of fresh and interesting

00:17:26,990 --> 00:17:33,600
working machine with machine learning is

00:17:29,340 --> 00:17:35,460
never boring my favorite part is that at

00:17:33,600 --> 00:17:37,890
different points it focuses on different

00:17:35,460 --> 00:17:39,750
qualities it may choose to render just

00:17:37,890 --> 00:17:42,179
faces for a while as it detects the

00:17:39,750 --> 00:17:43,919
commonality in all of the images then it

00:17:42,179 --> 00:17:46,290
may focus just on the little animal

00:17:43,919 --> 00:17:48,270
noses or the glasses additions creating

00:17:46,290 --> 00:17:50,590
swirling wires around

00:17:48,270 --> 00:17:52,480
sometimes it may even focus on people

00:17:50,590 --> 00:17:54,340
sharing their snapchats gang code

00:17:52,480 --> 00:18:02,350
because I didn't clean my data set

00:17:54,340 --> 00:18:04,630
properly snapchat Instagram Facebook and

00:18:02,350 --> 00:18:07,630
similar filters all work on facial data

00:18:04,630 --> 00:18:09,640
recognition and detection the most

00:18:07,630 --> 00:18:12,400
robust one seems to be snapchats which

00:18:09,640 --> 00:18:13,960
is also the oldest they use machine

00:18:12,400 --> 00:18:16,420
learning to recognize the features of a

00:18:13,960 --> 00:18:18,430
face and see and how it moves

00:18:16,420 --> 00:18:20,620
they then resize and fit 3d

00:18:18,430 --> 00:18:23,050
augmentations to that facial template

00:18:20,620 --> 00:18:24,910
further complexity is added in

00:18:23,050 --> 00:18:26,710
augmentations like the puppy one where

00:18:24,910 --> 00:18:29,320
it detects your mouth opening and adds

00:18:26,710 --> 00:18:31,270
an animated tongue into the mix these

00:18:29,320 --> 00:18:33,370
are quite good at detection and while

00:18:31,270 --> 00:18:36,070
you can use adversarial methods to avoid

00:18:33,370 --> 00:18:39,070
the facial recognition it's a surprising

00:18:36,070 --> 00:18:40,950
amount of work to foil I'm amazed that

00:18:39,070 --> 00:18:44,230
it picked up the Francis Bacon

00:18:40,950 --> 00:18:45,910
self-portrait that's just that looks

00:18:44,230 --> 00:18:47,650
like an incredibly adversarial image to

00:18:45,910 --> 00:18:50,140
me but it didn't have much problem

00:18:47,650 --> 00:18:52,060
finding it snapchat in particular can

00:18:50,140 --> 00:18:53,560
alter the shape of her face and add

00:18:52,060 --> 00:18:55,720
instant photoshopping the glitter

00:18:53,560 --> 00:18:58,360
elements respond to movement and light

00:18:55,720 --> 00:19:01,600
sources and it's great for amusing board

00:18:58,360 --> 00:19:03,550
kids as depth sensing and light

00:19:01,600 --> 00:19:05,380
detection technologies become standard

00:19:03,550 --> 00:19:07,600
we can expect to see more of this

00:19:05,380 --> 00:19:10,090
we'll see more semantic style

00:19:07,600 --> 00:19:14,080
transferring on the fly as foreign

00:19:10,090 --> 00:19:16,270
processing improves such as Prisma and

00:19:14,080 --> 00:19:17,980
oilless already used feed-forward style

00:19:16,270 --> 00:19:20,110
transfer in their apps and are well on

00:19:17,980 --> 00:19:22,990
their way to style transferring our

00:19:20,110 --> 00:19:24,940
realities every if we return to Van Gogh

00:19:22,990 --> 00:19:27,340
here with his little snapchat ears we

00:19:24,940 --> 00:19:30,100
have Prisma on the left and oil list on

00:19:27,340 --> 00:19:33,280
the right boy list even allows you to

00:19:30,100 --> 00:19:36,130
change it as it's painting being the

00:19:33,280 --> 00:19:38,940
closest we have right now to creating a

00:19:36,130 --> 00:19:41,800
painted digital reality on the fly

00:19:38,940 --> 00:19:43,780
Facebook is working with a Prisma to

00:19:41,800 --> 00:19:45,460
create livestyle transferred videos and

00:19:43,780 --> 00:19:49,350
I wouldn't be surprised if oil List and

00:19:45,460 --> 00:19:52,180
snapchat are also working on it I

00:19:49,350 --> 00:19:53,980
mentioned a day Siegen earlier which is

00:19:52,180 --> 00:19:56,290
the main area of my research at the

00:19:53,980 --> 00:19:58,179
moment DC Ganz stands for deep

00:19:56,290 --> 00:20:01,330
convolutional generative adversarial

00:19:58,179 --> 00:20:03,820
network again is actually Turner on that

00:20:01,330 --> 00:20:06,489
a generator and a discriminator they

00:20:03,820 --> 00:20:07,809
both work off the same data set the

00:20:06,489 --> 00:20:09,789
generator creates while the

00:20:07,809 --> 00:20:11,610
discriminator critiques and rejects the

00:20:09,789 --> 00:20:14,019
creations that don't fit the data set

00:20:11,610 --> 00:20:16,360
through seeing which works pass and

00:20:14,019 --> 00:20:18,149
which failed the generator learns to

00:20:16,360 --> 00:20:20,590
make works that fulfill the criteria

00:20:18,149 --> 00:20:22,659
there are a range of different gains for

00:20:20,590 --> 00:20:24,369
different frameworks and outcomes pics

00:20:22,659 --> 00:20:26,649
depicts which is an image and video

00:20:24,369 --> 00:20:28,720
translation again is probably the most

00:20:26,649 --> 00:20:31,210
widely used in the AR art community

00:20:28,720 --> 00:20:33,609
there's even a JavaScript pics to pics

00:20:31,210 --> 00:20:36,820
for live browser work but it's a little

00:20:33,609 --> 00:20:38,350
slow for phones at the moment I use a DC

00:20:36,820 --> 00:20:42,279
gain intensive flow because of its

00:20:38,350 --> 00:20:44,289
stability and ease of use machine

00:20:42,279 --> 00:20:46,090
learning ranges from everyday uses such

00:20:44,289 --> 00:20:48,190
as shop recommendations and maps to

00:20:46,090 --> 00:20:50,950
generating art and music and medical

00:20:48,190 --> 00:20:54,100
diagnostics it's a huge area of

00:20:50,950 --> 00:20:55,960
exploration and the hottest one to the

00:20:54,100 --> 00:20:58,029
other hot technology is augmented

00:20:55,960 --> 00:21:00,609
reality and it won't be long before we

00:20:58,029 --> 00:21:02,950
see these together more and more whether

00:21:00,609 --> 00:21:05,200
in simple methods or complex ones such

00:21:02,950 --> 00:21:07,570
as creating art and creating art can be

00:21:05,200 --> 00:21:10,330
done in so many different ways whether

00:21:07,570 --> 00:21:12,399
using deep dream style transfer digital

00:21:10,330 --> 00:21:19,269
coloring picks depicts or wholesale

00:21:12,399 --> 00:21:21,489
generation we can generate music and

00:21:19,269 --> 00:21:23,950
videos and email even comic pages from

00:21:21,489 --> 00:21:26,049
videos and the options are limitless for

00:21:23,950 --> 00:21:28,539
those unafraid to attempt it and jump in

00:21:26,049 --> 00:21:30,369
headfirst and one thing leads to another

00:21:28,539 --> 00:21:32,259
and then another and before you know it

00:21:30,369 --> 00:21:35,460
you're on a stage talking about the

00:21:32,259 --> 00:21:37,869
possibilities of machine learning in art

00:21:35,460 --> 00:21:39,789
machine learning options are becoming

00:21:37,869 --> 00:21:43,330
more accessible to everyone with the

00:21:39,789 --> 00:21:46,179
right tools and interests runway ml is a

00:21:43,330 --> 00:21:48,820
beta machine learning GUI with hooks for

00:21:46,179 --> 00:21:51,609
unity via skirt blender Photoshop and

00:21:48,820 --> 00:21:54,309
more this allows creatives to get

00:21:51,609 --> 00:21:56,080
directly involved with the making of art

00:21:54,309 --> 00:21:58,359
without all of the command line work and

00:21:56,080 --> 00:22:01,779
framework installation and inevitable

00:21:58,359 --> 00:22:03,999
CUDA issues it creates a seamless GUI

00:22:01,779 --> 00:22:06,129
for the most commonly used machine

00:22:03,999 --> 00:22:07,809
learning models and maybe one of the

00:22:06,129 --> 00:22:10,529
most exciting things to happen to

00:22:07,809 --> 00:22:13,509
machine learning and art since the game

00:22:10,529 --> 00:22:15,070
because it works natively with unity it

00:22:13,509 --> 00:22:17,350
will be able to work

00:22:15,070 --> 00:22:19,210
mobile devices and virtual reality to

00:22:17,350 --> 00:22:22,659
create mixed reality machine learning

00:22:19,210 --> 00:22:25,600
art experiences unity and Unreal Engine

00:22:22,659 --> 00:22:28,120
our crime engines for VR development

00:22:25,600 --> 00:22:30,190
putting runway 2ml at the forefront of

00:22:28,120 --> 00:22:31,919
adding machine learning capabilities to

00:22:30,190 --> 00:22:36,279
virtual reality and augmented reality

00:22:31,919 --> 00:22:38,500
applications art in augmented reality

00:22:36,279 --> 00:22:41,799
has a wonderful history and future

00:22:38,500 --> 00:22:43,779
Moammar our activists with their own app

00:22:41,799 --> 00:22:45,850
taking over space in the Museum of

00:22:43,779 --> 00:22:48,070
Modern Art democratizing art and

00:22:45,850 --> 00:22:51,039
creating a message about elitism in the

00:22:48,070 --> 00:22:53,620
art world their app and installation is

00:22:51,039 --> 00:22:55,929
open source and situated in the Jackson

00:22:53,620 --> 00:22:57,370
Pollock Room of where it is unofficially

00:22:55,929 --> 00:22:59,889
taken up residence as part of the

00:22:57,370 --> 00:23:02,620
permanent exhibition well this seems

00:22:59,889 --> 00:23:04,690
parasitical in nature leeching off of

00:23:02,620 --> 00:23:11,529
the reputation and marketing of the

00:23:04,690 --> 00:23:13,779
gallery it's excuse me sorry they they

00:23:11,529 --> 00:23:16,149
leverage their own exhibition with a

00:23:13,779 --> 00:23:18,399
symbiotic relationship that's driven

00:23:16,149 --> 00:23:21,100
more visitors to MoMA that might not

00:23:18,399 --> 00:23:23,139
have otherwise attended many people love

00:23:21,100 --> 00:23:25,690
to unlock secrets and find hidden things

00:23:23,139 --> 00:23:28,870
to reveal it's a way to gain new

00:23:25,690 --> 00:23:30,940
audiences that engage with the art in

00:23:28,870 --> 00:23:32,980
new and interesting ways while

00:23:30,940 --> 00:23:35,139
detractors see a desecration of

00:23:32,980 --> 00:23:37,450
institutions defenders see

00:23:35,139 --> 00:23:39,850
democratization and an exploration of

00:23:37,450 --> 00:23:41,590
art beyond the confines of what has been

00:23:39,850 --> 00:23:44,409
established in the analysis of hit art

00:23:41,590 --> 00:23:47,830
history from sculpture installations to

00:23:44,409 --> 00:23:50,500
graffiti to location-aware art we are

00:23:47,830 --> 00:23:53,470
seeing artists explore the possibilities

00:23:50,500 --> 00:23:55,809
of adding layers onto our world there

00:23:53,470 --> 00:23:58,720
are collaborative augmented reality art

00:23:55,809 --> 00:24:00,159
projects and ephemeral works permanent

00:23:58,720 --> 00:24:01,809
works and thanks to public art

00:24:00,159 --> 00:24:04,330
collectives and Mavericks like Moammar

00:24:01,809 --> 00:24:06,789
augmented reality can be seen as a form

00:24:04,330 --> 00:24:10,210
of open source for art and art displays

00:24:06,789 --> 00:24:13,450
a revolutionary concept in democratizing

00:24:10,210 --> 00:24:15,850
art suddenly we can hike museums to show

00:24:13,450 --> 00:24:19,210
our work or alter the work of famous

00:24:15,850 --> 00:24:21,250
artists and respond to it we can install

00:24:19,210 --> 00:24:23,889
work in public spaces without permits

00:24:21,250 --> 00:24:26,740
and react to each other's art this puts

00:24:23,889 --> 00:24:28,330
art back into the hands of the artists

00:24:26,740 --> 00:24:28,870
rather than in the hands of elite

00:24:28,330 --> 00:24:31,420
instant

00:24:28,870 --> 00:24:33,160
Solutions and galleries it allows us to

00:24:31,420 --> 00:24:37,470
subvert the mainstream and create our

00:24:33,160 --> 00:24:40,150
own realities to hack the art world and

00:24:37,470 --> 00:24:42,580
with emerging browser-based AR

00:24:40,150 --> 00:24:44,770
technologies we can enable it for anyone

00:24:42,580 --> 00:24:49,210
with a browser in an instant rather than

00:24:44,770 --> 00:24:51,030
relying on an app download so why bring

00:24:49,210 --> 00:24:54,430
machine learning and augmented reality

00:24:51,030 --> 00:24:56,680
technologies together apart from the

00:24:54,430 --> 00:24:59,800
fact that they're very cool what purpose

00:24:56,680 --> 00:25:01,929
does it serve we're already seeing that

00:24:59,800 --> 00:25:04,540
your unite in snapchat and Instagram

00:25:01,929 --> 00:25:06,910
filters but does it have any real-world

00:25:04,540 --> 00:25:08,860
applications beyond the frivolous do the

00:25:06,910 --> 00:25:15,100
two together provide any meaningful ways

00:25:08,860 --> 00:25:17,770
to engage with the world some of the

00:25:15,100 --> 00:25:19,929
simplest and best use of AR and AI

00:25:17,770 --> 00:25:23,110
together are in the form of translation

00:25:19,929 --> 00:25:25,600
algorithms and language education using

00:25:23,110 --> 00:25:29,110
your device's camera to read a sign and

00:25:25,600 --> 00:25:31,780
translate it for you in real-time having

00:25:29,110 --> 00:25:35,550
those work results superimposed over the

00:25:31,780 --> 00:25:38,170
sign it's clean practical and simple

00:25:35,550 --> 00:25:40,450
Google Translate is the most famous of

00:25:38,170 --> 00:25:42,429
these but there are a range of live

00:25:40,450 --> 00:25:45,640
augmented reality translation apps

00:25:42,429 --> 00:25:48,040
available apps such as memorize also

00:25:45,640 --> 00:25:50,500
teach language by using image detection

00:25:48,040 --> 00:25:52,480
so as you point your phone at your cache

00:25:50,500 --> 00:25:56,770
in the app it will tell you it's an echo

00:25:52,480 --> 00:25:59,140
or a gato or a shot there are augmented

00:25:56,770 --> 00:26:01,240
reality travel guides and maps that will

00:25:59,140 --> 00:26:03,040
hover information about the location in

00:26:01,240 --> 00:26:05,290
your device and tell you how to get

00:26:03,040 --> 00:26:07,390
around or allow you to explore a

00:26:05,290 --> 00:26:10,030
location or a museum just by moving

00:26:07,390 --> 00:26:13,450
around your home imagine how helpful

00:26:10,030 --> 00:26:15,400
that is for people who cannot travel for

00:26:13,450 --> 00:26:18,400
affordability reasons or for

00:26:15,400 --> 00:26:20,440
accessibility imagine being able to tour

00:26:18,400 --> 00:26:22,780
museums anywhere in the world without

00:26:20,440 --> 00:26:26,110
travelling there or hovering over a city

00:26:22,780 --> 00:26:28,059
and moving around it view Ranger is an

00:26:26,110 --> 00:26:30,700
app that recognizes geological features

00:26:28,059 --> 00:26:32,770
in skyline and defines them for hikers

00:26:30,700 --> 00:26:35,380
to show the best results and the best

00:26:32,770 --> 00:26:38,230
trails it's also being used by search

00:26:35,380 --> 00:26:42,870
and rescue teams to be able to find lost

00:26:38,230 --> 00:26:42,870
hikers making it an invaluable resource

00:26:45,230 --> 00:26:51,840
wicked world browser is a practically

00:26:48,750 --> 00:26:53,669
ancient of technology from 2008 that

00:26:51,840 --> 00:26:55,799
leverages Wikipedia to identify things

00:26:53,669 --> 00:26:58,919
near you and give you information about

00:26:55,799 --> 00:27:00,980
it it uses your foreign compass location

00:26:58,919 --> 00:27:04,200
data and image recognition to provide

00:27:00,980 --> 00:27:06,570
content on worlds of items and locations

00:27:04,200 --> 00:27:08,220
if you're like me and you have a bad

00:27:06,570 --> 00:27:10,440
habit of taking photos and forgetting

00:27:08,220 --> 00:27:12,269
why you took them or taking a picture to

00:27:10,440 --> 00:27:14,580
look up later google lense is

00:27:12,269 --> 00:27:16,620
particularly useful it uses image

00:27:14,580 --> 00:27:18,389
recognition to return information on

00:27:16,620 --> 00:27:19,950
photos you have in google photos and

00:27:18,389 --> 00:27:22,799
while it isn't technically

00:27:19,950 --> 00:27:24,870
augmented-reality yet it is being worked

00:27:22,799 --> 00:27:27,720
on to give you live feedback in

00:27:24,870 --> 00:27:29,009
augmented reality it can be used to save

00:27:27,720 --> 00:27:31,860
data from business cards to your

00:27:29,009 --> 00:27:34,710
contacts at a date to your calendar read

00:27:31,860 --> 00:27:37,440
reviews about books and more imagine how

00:27:34,710 --> 00:27:39,899
powerful it will be in augmented reality

00:27:37,440 --> 00:27:45,659
to have the power of Google behind your

00:27:39,899 --> 00:27:47,669
camera working in real time we will see

00:27:45,659 --> 00:27:53,820
suggestion algorithms and advertising

00:27:47,669 --> 00:27:55,620
start to become more prevalent makeup

00:27:53,820 --> 00:27:57,330
storage Charlotte Tilbury installed

00:27:55,620 --> 00:27:59,340
magic mirrors in their Westfield stores

00:27:57,330 --> 00:28:01,860
in London the scan a user's face and

00:27:59,340 --> 00:28:03,029
augmented and automatically augment

00:28:01,860 --> 00:28:05,519
their face to add some of their

00:28:03,029 --> 00:28:07,799
signature looks in real time retail a

00:28:05,519 --> 00:28:09,720
are from dent reality has been working

00:28:07,799 --> 00:28:11,580
on a grocery shopping app that will

00:28:09,720 --> 00:28:13,500
navigate you to the aisle you need and

00:28:11,580 --> 00:28:15,779
suggest meal options for different

00:28:13,500 --> 00:28:18,210
ingredients it uses machine learning to

00:28:15,779 --> 00:28:20,460
locate you within the store and to help

00:28:18,210 --> 00:28:22,049
you find what you need and suggestion

00:28:20,460 --> 00:28:24,590
algorithms to help you decide what to

00:28:22,049 --> 00:28:24,590
make for dinner

00:28:24,980 --> 00:28:29,460
IKEA already use as they are for

00:28:27,600 --> 00:28:31,320
furnishing your room I doubt it will be

00:28:29,460 --> 00:28:33,480
long before they leverage recommendation

00:28:31,320 --> 00:28:35,820
technologies to recognize your style in

00:28:33,480 --> 00:28:37,980
the pieces you already own and suggest

00:28:35,820 --> 00:28:40,230
options based on those and display them

00:28:37,980 --> 00:28:42,090
to you in real time there's already

00:28:40,230 --> 00:28:44,700
something like that for art called

00:28:42,090 --> 00:28:47,159
artifact where you can answer questions

00:28:44,700 --> 00:28:48,750
about your taste and preview art on your

00:28:47,159 --> 00:28:53,580
walls that suits the color palette of

00:28:48,750 --> 00:28:55,529
your room research into accessibility in

00:28:53,580 --> 00:28:55,950
a combining augmented reality and

00:28:55,529 --> 00:28:58,409
artifice

00:28:55,950 --> 00:29:00,299
intelligence is also underway with a

00:28:58,409 --> 00:29:02,639
recent experiment using augmented

00:29:00,299 --> 00:29:05,220
reality headsets to help teach children

00:29:02,639 --> 00:29:08,220
with autism how to identify emotions by

00:29:05,220 --> 00:29:10,230
turning it into a game the children and

00:29:08,220 --> 00:29:12,269
their parents both Inc reported an

00:29:10,230 --> 00:29:15,090
increase in their understanding and

00:29:12,269 --> 00:29:19,350
responsiveness with one child saying

00:29:15,090 --> 00:29:21,059
that they're a mind reader highway has

00:29:19,350 --> 00:29:23,039
created an app for deaf children that

00:29:21,059 --> 00:29:25,230
uses the foreign camera to analyze the

00:29:23,039 --> 00:29:28,139
words in children's books and read the

00:29:25,230 --> 00:29:29,850
story to them using sign language many

00:29:28,139 --> 00:29:32,399
deaf children struggle to learn to read

00:29:29,850 --> 00:29:34,980
and applications such as this could help

00:29:32,399 --> 00:29:37,409
bridge that gap there are wearables

00:29:34,980 --> 00:29:39,809
enabling subtitles to be augmented onto

00:29:37,409 --> 00:29:41,880
movies and one in development for live

00:29:39,809 --> 00:29:44,850
captioning of speech in conversation

00:29:41,880 --> 00:29:46,440
will be wonderful to see the world made

00:29:44,850 --> 00:29:51,029
more accessible with wearables and

00:29:46,440 --> 00:29:52,649
augmented reality technologies effort is

00:29:51,029 --> 00:29:54,899
already underway to restore

00:29:52,649 --> 00:29:56,880
archaeological artifacts digitally and

00:29:54,899 --> 00:29:59,220
display information about them Institute

00:29:56,880 --> 00:30:01,590
for tourists via augmented reality

00:29:59,220 --> 00:30:03,769
lalana is at the forefront of this

00:30:01,590 --> 00:30:06,330
research creating an augmented reality

00:30:03,769 --> 00:30:08,220
presentation for visitors that it allows

00:30:06,330 --> 00:30:09,929
them to explore the architectural

00:30:08,220 --> 00:30:13,409
qualities of the heritage protected

00:30:09,929 --> 00:30:15,269
building and the construction low-light

00:30:13,409 --> 00:30:18,899
conditions necessary to preserving

00:30:15,269 --> 00:30:20,730
historical sites as is necessary but

00:30:18,899 --> 00:30:22,950
augmented reality provides greater

00:30:20,730 --> 00:30:25,019
accessibility and access to the details

00:30:22,950 --> 00:30:29,130
of the architecture without compromising

00:30:25,019 --> 00:30:32,070
it AR is ideal for archaeological sites

00:30:29,130 --> 00:30:33,960
preserving them as they are harnessing

00:30:32,070 --> 00:30:36,120
the technology of the future to allow us

00:30:33,960 --> 00:30:38,519
to learn from the past while maintaining

00:30:36,120 --> 00:30:41,279
the integrity of the artifacts and the

00:30:38,519 --> 00:30:43,649
site but in the future we will also

00:30:41,279 --> 00:30:46,289
harness new neural networks to restore

00:30:43,649 --> 00:30:48,240
and translate text and display it

00:30:46,289 --> 00:30:51,269
locally for you in your language on your

00:30:48,240 --> 00:30:53,429
phone neural networks will access

00:30:51,269 --> 00:30:56,130
historical data to restore the original

00:30:53,429 --> 00:30:57,630
colors of statues and frescoes and

00:30:56,130 --> 00:30:58,799
experience preserved for future

00:30:57,630 --> 00:31:01,380
generations

00:30:58,799 --> 00:31:03,269
and then because we are the way we are

00:31:01,380 --> 00:31:05,370
there will probably be in a photo

00:31:03,269 --> 00:31:07,980
opportunity to insert yourself inside

00:31:05,370 --> 00:31:09,960
the fresco being semantically seamlessly

00:31:07,980 --> 00:31:12,929
still matched

00:31:09,960 --> 00:31:14,429
we will have personal tour guides in new

00:31:12,929 --> 00:31:16,409
cities tailored to our personal

00:31:14,429 --> 00:31:18,570
interests and past experiences

00:31:16,409 --> 00:31:20,610
restaurants that are recommended based

00:31:18,570 --> 00:31:23,940
on their handling of our own dietary

00:31:20,610 --> 00:31:25,950
requirements will see medical

00:31:23,940 --> 00:31:28,590
diagnostics with a human doctor

00:31:25,950 --> 00:31:31,679
supplemented by an AR headset and

00:31:28,590 --> 00:31:35,100
leveraging a diagnostic AI to diagnose

00:31:31,679 --> 00:31:37,379
faster and more accurately than without

00:31:35,100 --> 00:31:39,809
augmentations will see engineering

00:31:37,379 --> 00:31:41,909
Diagnostics helping to solve problems in

00:31:39,809 --> 00:31:44,369
the field with a handy heads-up display

00:31:41,909 --> 00:31:46,499
and remote desktop support enabling

00:31:44,369 --> 00:31:49,230
people to fix their devices with

00:31:46,499 --> 00:31:51,419
diagrammatic support supplied live to

00:31:49,230 --> 00:31:53,509
their phones or wearables showing the

00:31:51,419 --> 00:31:56,159
exact program I'm a problem I'm

00:31:53,509 --> 00:31:58,980
personally hanging out for a heads-up

00:31:56,159 --> 00:32:00,629
display that shows me people tells me

00:31:58,980 --> 00:32:04,559
people's names and where I know them

00:32:00,629 --> 00:32:07,110
from it honestly I could also use

00:32:04,559 --> 00:32:10,590
something that helps me detect emotions

00:32:07,110 --> 00:32:13,200
and sarcasm better these are all

00:32:10,590 --> 00:32:15,840
functions of machine learning and all

00:32:13,200 --> 00:32:20,340
are in active development even sarcasm

00:32:15,840 --> 00:32:22,440
detection but beyond that I'd love to

00:32:20,340 --> 00:32:24,269
see augmented reality used with Spotify

00:32:22,440 --> 00:32:26,369
to recognize your surroundings or

00:32:24,269 --> 00:32:30,119
activities and tailor your music to

00:32:26,369 --> 00:32:33,119
match a machine learning by soundtrack

00:32:30,119 --> 00:32:35,399
to your life and your daily activities

00:32:33,119 --> 00:32:37,289
I'd love to be able to change my world

00:32:35,399 --> 00:32:40,470
to be more artistic at that push of a

00:32:37,289 --> 00:32:42,629
button to semantically style transfer

00:32:40,470 --> 00:32:44,940
people and backgrounds on-the-fly I'd

00:32:42,629 --> 00:32:47,820
love for my works to work in real time

00:32:44,940 --> 00:32:50,759
rather than being pre-programmed I'd

00:32:47,820 --> 00:32:52,799
love to play an AR or VR game and select

00:32:50,759 --> 00:32:55,259
the style that's rendered in to be able

00:32:52,799 --> 00:32:57,360
to hack my reality and create the

00:32:55,259 --> 00:33:00,740
visuals and the soundtrack for it as I

00:32:57,360 --> 00:33:04,649
exist in it as I move about the world

00:33:00,740 --> 00:33:06,509
what purpose does all of this serve of

00:33:04,649 --> 00:33:09,869
course art doesn't need a purpose it

00:33:06,509 --> 00:33:11,490
just is but the purpose behind the more

00:33:09,869 --> 00:33:14,249
commercial realizations of this

00:33:11,490 --> 00:33:15,929
technology are clear from making the

00:33:14,249 --> 00:33:18,119
world smaller and more accessible

00:33:15,929 --> 00:33:19,859
through linguistic assistance and

00:33:18,119 --> 00:33:22,109
mapping to selling products people

00:33:19,859 --> 00:33:22,830
actually need tailored for them in their

00:33:22,109 --> 00:33:25,110
homes

00:33:22,830 --> 00:33:27,150
mixed reality can bring the world to you

00:33:25,110 --> 00:33:29,100
and machine learning can learn what you

00:33:27,150 --> 00:33:33,270
need learn your interests and your

00:33:29,100 --> 00:33:35,220
tastes and learn to tailor it for you as

00:33:33,270 --> 00:33:37,350
more companies are working on AR

00:33:35,220 --> 00:33:40,320
wearables we can expect to see these

00:33:37,350 --> 00:33:42,810
technologies cross over more and more we

00:33:40,320 --> 00:33:45,150
can see it permeate and while the focus

00:33:42,810 --> 00:33:47,820
will be on advertising and selling I

00:33:45,150 --> 00:33:50,430
hope that we will also see ways to make

00:33:47,820 --> 00:33:53,460
our world more beautiful more filled

00:33:50,430 --> 00:33:56,310
with the wisdom of the world and as the

00:33:53,460 --> 00:33:57,630
power of our phones increase the more

00:33:56,310 --> 00:34:01,560
powerful the machine learning

00:33:57,630 --> 00:34:04,290
interactions will be augmented reality

00:34:01,560 --> 00:34:09,330
is the bridge between the physical and

00:34:04,290 --> 00:34:11,250
digital worlds as those worlds get

00:34:09,330 --> 00:34:13,560
blurred together by the accessibility

00:34:11,250 --> 00:34:16,770
and pervasiveness of Technology we will

00:34:13,560 --> 00:34:19,140
need that bridge more and more companies

00:34:16,770 --> 00:34:21,179
are predicting wearable glasses will be

00:34:19,140 --> 00:34:22,860
used in technical jobs medical ones

00:34:21,179 --> 00:34:25,530
enabling part one solving and

00:34:22,860 --> 00:34:27,960
diagnostics in a seamless way we have

00:34:25,530 --> 00:34:30,419
ways of making the world smaller whether

00:34:27,960 --> 00:34:32,850
it's talking to a hologram of a friend

00:34:30,419 --> 00:34:35,190
in front of you or translating science

00:34:32,850 --> 00:34:38,190
and things we need to say on the fly I

00:34:35,190 --> 00:34:41,310
hope that it will lead to a world of

00:34:38,190 --> 00:34:43,470
flowing graffiti of artwork waiting to

00:34:41,310 --> 00:34:45,600
be discovered and interacted with or

00:34:43,470 --> 00:34:47,760
walked through a chance to alter our

00:34:45,600 --> 00:34:51,450
worlds and make them more fantastical

00:34:47,760 --> 00:34:54,270
more inspiring more beautiful by working

00:34:51,450 --> 00:34:56,610
together by connecting that with machine

00:34:54,270 --> 00:34:59,910
learning we are allowing machines into

00:34:56,610 --> 00:35:01,830
our own worlds blurring that line even

00:34:59,910 --> 00:35:04,410
further we're able to collaborate with

00:35:01,830 --> 00:35:06,450
machines to teach them and create art

00:35:04,410 --> 00:35:08,220
work together and that can be seen in

00:35:06,450 --> 00:35:13,010
the real world through the medium of the

00:35:08,220 --> 00:35:13,010
screen thank you so much

00:35:14,970 --> 00:35:19,300
[Applause]

00:35:19,660 --> 00:35:25,940
thank you joy we've got time for some

00:35:22,820 --> 00:35:39,800
questions if anyone has any anything

00:35:25,940 --> 00:35:43,010
they want to ask you sound very excited

00:35:39,800 --> 00:35:44,869
about their possibilities that you know

00:35:43,010 --> 00:35:46,790
the world will get smaller and I know

00:35:44,869 --> 00:35:48,950
that you mean that and they're positive

00:35:46,790 --> 00:35:51,080
kind of forming connections between

00:35:48,950 --> 00:35:53,480
people and that kind of thing do you

00:35:51,080 --> 00:35:55,910
also have concerns that this sort of

00:35:53,480 --> 00:35:57,770
thing can end up the the way that

00:35:55,910 --> 00:36:00,230
technology is used is supposed to the

00:35:57,770 --> 00:36:02,810
technology itself can end up making the

00:36:00,230 --> 00:36:06,619
world a smaller place in an unhelpful

00:36:02,810 --> 00:36:07,820
way yes I do I worry about what it's

00:36:06,619 --> 00:36:10,490
going to do in the hands of the

00:36:07,820 --> 00:36:14,720
governments especially some of the more

00:36:10,490 --> 00:36:16,609
toxic governments I definitely worry

00:36:14,720 --> 00:36:18,109
that you know like online bullying and

00:36:16,609 --> 00:36:22,430
stuff like that that could become more

00:36:18,109 --> 00:36:25,280
of a pervasive issue but I I guess I

00:36:22,430 --> 00:36:26,869
tries to focus on the positive outcomes

00:36:25,280 --> 00:36:28,490
and hope that that's the future we're

00:36:26,869 --> 00:36:30,890
going to create because I do feel like

00:36:28,490 --> 00:36:33,650
we're trending towards our positive

00:36:30,890 --> 00:36:37,550
future so sure can I have another

00:36:33,650 --> 00:36:40,940
question with nobody else so talking

00:36:37,550 --> 00:36:43,940
about gender and you know just the way

00:36:40,940 --> 00:36:47,720
that technology affects our idea of

00:36:43,940 --> 00:36:51,339
gender um I'm thinking off this is a

00:36:47,720 --> 00:36:51,339
really simple example something like

00:36:51,369 --> 00:36:55,220
places where machine learning doesn't

00:36:53,660 --> 00:36:56,480
work the way that we explore it doesn't

00:36:55,220 --> 00:36:58,790
work the way that it was intended to

00:36:56,480 --> 00:37:02,540
because of stereotypes getting in the

00:36:58,790 --> 00:37:05,390
way of training material is your work or

00:37:02,540 --> 00:37:08,859
in your work do you explore those like

00:37:05,390 --> 00:37:11,720
how I guess how political is your work

00:37:08,859 --> 00:37:15,740
it's very very political especially my

00:37:11,720 --> 00:37:17,839
um my PhD research is I'm going to be

00:37:15,740 --> 00:37:19,820
creating a very biased Network and then

00:37:17,839 --> 00:37:21,680
seeing what I can do to unbias it and

00:37:19,820 --> 00:37:25,490
watching the artwork that it produces as

00:37:21,680 --> 00:37:27,030
it has it on biases so my my main area

00:37:25,490 --> 00:37:30,240
of research is actually in

00:37:27,030 --> 00:37:32,220
how when we train most people when they

00:37:30,240 --> 00:37:36,690
they train a data set it's very very

00:37:32,220 --> 00:37:38,880
biased it's largely white men and so I

00:37:36,690 --> 00:37:43,770
want to see what what happens you know

00:37:38,880 --> 00:37:45,120
when you slowly unbias that and how what

00:37:43,770 --> 00:37:46,620
what kind of worlds we can create I

00:37:45,120 --> 00:37:48,210
guess I mean I don't know what's going

00:37:46,620 --> 00:37:51,120
to happen because I've only I'm not I

00:37:48,210 --> 00:37:53,400
haven't quite started my PhD yet but I'm

00:37:51,120 --> 00:37:57,680
hoping that it will be quite

00:37:53,400 --> 00:38:00,980
enlightening some thank you thank you

00:37:57,680 --> 00:38:00,980
any other questions

00:38:10,640 --> 00:38:20,490
as I takes over how do we counter

00:38:14,700 --> 00:38:25,230
deterioration of physical skills as an

00:38:20,490 --> 00:38:26,400
example of red in medicine in the UK one

00:38:25,230 --> 00:38:28,860
of the problems they're having training

00:38:26,400 --> 00:38:30,870
new doctors is because as we're growing

00:38:28,860 --> 00:38:33,720
up we fiddle with things with our hands

00:38:30,870 --> 00:38:38,370
less so their manual skills deteriorate

00:38:33,720 --> 00:38:42,060
the more we rely on IR the less we're

00:38:38,370 --> 00:38:43,730
doing with our hands again so is this an

00:38:42,060 --> 00:38:49,640
issue people are thinking about is this

00:38:43,730 --> 00:38:52,920
but you know myself I would suspect that

00:38:49,640 --> 00:38:55,620
the main deterioration might be in the

00:38:52,920 --> 00:38:57,780
eyes if you're constantly used to having

00:38:55,620 --> 00:39:01,440
everything zoomed in for you you might

00:38:57,780 --> 00:39:04,590
have difficulty readjusting and so that

00:39:01,440 --> 00:39:07,290
could be an issue later on but I think

00:39:04,590 --> 00:39:09,360
that you know like if we're gamifying

00:39:07,290 --> 00:39:10,680
more and I think that there should be I

00:39:09,360 --> 00:39:12,600
love games so I think there should be

00:39:10,680 --> 00:39:15,540
more games in the world that actually

00:39:12,600 --> 00:39:18,420
increases dexterity there's been a lot

00:39:15,540 --> 00:39:20,250
of studies to show that gaming increases

00:39:18,420 --> 00:39:21,990
your hand-eye coordination it increases

00:39:20,250 --> 00:39:25,110
your manual dexterity and things like

00:39:21,990 --> 00:39:28,440
that but there's also a lot of people

00:39:25,110 --> 00:39:31,170
are encouraging fidgeting or at least

00:39:28,440 --> 00:39:34,320
not like demonizing fidgeting as much

00:39:31,170 --> 00:39:37,640
for kids like when I was growing up so

00:39:34,320 --> 00:39:40,620
we're allowed to have a little toys and

00:39:37,640 --> 00:39:42,180
kids are growing up being

00:39:40,620 --> 00:39:43,290
to do things like that and I think that

00:39:42,180 --> 00:39:44,850
that's going to help put that sort of

00:39:43,290 --> 00:39:49,050
thing as well rather than this sit on

00:39:44,850 --> 00:39:50,190
your hands stop fidgeting focus sorry I

00:39:49,050 --> 00:40:03,000
don't know if that answered your

00:39:50,190 --> 00:40:04,590
question well it's not much of a

00:40:03,000 --> 00:40:09,270
question but have you seen the video

00:40:04,590 --> 00:40:11,220
called hyper-reality on Vimeo the lady

00:40:09,270 --> 00:40:17,390
on the bus and getting a job and going

00:40:11,220 --> 00:40:17,390
shopping and stuff hyper-reality

00:40:22,730 --> 00:40:29,490
do you think that one day we'll end up

00:40:26,490 --> 00:40:31,410
in a world where you don't know whether

00:40:29,490 --> 00:40:33,120
or not when you reach out you're

00:40:31,410 --> 00:40:36,180
actually touching something or just a

00:40:33,120 --> 00:40:41,820
projection I'm sorry that sounds like a

00:40:36,180 --> 00:40:43,230
complaint it sounds like a bit of a I'm

00:40:41,820 --> 00:40:49,140
trying to think of a word without

00:40:43,230 --> 00:40:51,780
swearing so it sounds like a trip but I

00:40:49,140 --> 00:40:54,530
think it'd be fun you know it's sort of

00:40:51,780 --> 00:40:58,230
not knowing what's real and what's not

00:40:54,530 --> 00:41:01,620
could be possibly very difficult for

00:40:58,230 --> 00:41:05,280
people with dissociative issues but very

00:41:01,620 --> 00:41:06,930
interesting it depends on our resolution

00:41:05,280 --> 00:41:08,160
and I think you know if it's involving

00:41:06,930 --> 00:41:09,870
wearables and stuff like that rather

00:41:08,160 --> 00:41:12,270
than contacts you can always just take

00:41:09,870 --> 00:41:14,730
them off and go oh oh wow you're all

00:41:12,270 --> 00:41:17,070
blurs um you know you can take them off

00:41:14,730 --> 00:41:24,170
and say that you know the world really

00:41:17,070 --> 00:41:24,170
is what it is right any other questions

00:41:26,630 --> 00:41:32,880
when I was young they said all VR is

00:41:30,780 --> 00:41:35,820
gonna make it so that you play a video

00:41:32,880 --> 00:41:37,140
game where you murder your teacher and

00:41:35,820 --> 00:41:38,370
then you're gonna play it so much and

00:41:37,140 --> 00:41:40,250
you're gonna come to class and not

00:41:38,370 --> 00:41:42,510
remember if you're in real life or not

00:41:40,250 --> 00:41:46,020
what do you think like what you just

00:41:42,510 --> 00:41:49,380
said before I yeah I remember those

00:41:46,020 --> 00:41:52,920
those sorts of things they you know lawn

00:41:49,380 --> 00:41:54,180
mower man was yeah and that sort of era

00:41:52,920 --> 00:41:56,310
of oh my goodness

00:41:54,180 --> 00:41:58,320
that's that's gonna read the next and

00:41:56,310 --> 00:41:59,730
they're still trying to make it the next

00:41:58,320 --> 00:42:03,530
big thing and the technology is

00:41:59,730 --> 00:42:06,720
improving but III are no headset and

00:42:03,530 --> 00:42:11,100
I've never had difficulty distinguishing

00:42:06,720 --> 00:42:12,690
real from fake they're you know apart

00:42:11,100 --> 00:42:14,160
from the fact that it becomes quite a

00:42:12,690 --> 00:42:18,480
lot of pressure on your head after a

00:42:14,160 --> 00:42:21,000
while it you the resolution isn't there

00:42:18,480 --> 00:42:23,700
and things like that so I I don't know

00:42:21,000 --> 00:42:25,350
it hasn't changed the way I think but I

00:42:23,700 --> 00:42:28,650
have met a lot of technologists who are

00:42:25,350 --> 00:42:30,720
really afraid that they're going to be

00:42:28,650 --> 00:42:33,000
that their minds are going to be out and

00:42:30,720 --> 00:42:36,120
still like I was talking to some I think

00:42:33,000 --> 00:42:37,500
last year about VR and how they're

00:42:36,120 --> 00:42:38,820
terrified to try it because they're

00:42:37,500 --> 00:42:40,100
afraid it's going to it's going to

00:42:38,820 --> 00:42:42,780
change the way they think it's going to

00:42:40,100 --> 00:42:45,050
make them somehow violent will make them

00:42:42,780 --> 00:42:45,050
somehow

00:42:45,240 --> 00:42:49,350
difficult I play soft games in VR I

00:42:47,610 --> 00:42:53,100
don't like jump scares and things like

00:42:49,350 --> 00:42:57,750
that so maybe I'm not necessarily the

00:42:53,100 --> 00:43:02,820
right target market but I am I think

00:42:57,750 --> 00:43:05,160
that you know if it's in you to do then

00:43:02,820 --> 00:43:06,480
maybe but if it's not then it's not

00:43:05,160 --> 00:43:22,350
going to turn you into something you're

00:43:06,480 --> 00:43:27,030
not so it's going back to an earlier

00:43:22,350 --> 00:43:29,010
question about bias nai you know some of

00:43:27,030 --> 00:43:31,200
the data sets and unfortunately are

00:43:29,010 --> 00:43:33,270
already biased purely based on the fact

00:43:31,200 --> 00:43:35,880
that we live in our society today what

00:43:33,270 --> 00:43:38,130
are some of the ways that you have or

00:43:35,880 --> 00:43:41,040
you're thinking of to combat some of

00:43:38,130 --> 00:43:43,530
those biases I'm thinking sort of you

00:43:41,040 --> 00:43:45,600
know earlier when Amazon child you know

00:43:43,530 --> 00:43:48,000
AI for screening CDs and they found that

00:43:45,600 --> 00:43:49,200
they got a very glass results and they

00:43:48,000 --> 00:43:53,310
sort of scrapped the program and things

00:43:49,200 --> 00:43:55,350
like that I remember that that was uh I

00:43:53,310 --> 00:43:58,410
mean there are so many awful articles

00:43:55,350 --> 00:43:59,910
coming out about the bias in AI and

00:43:58,410 --> 00:44:02,100
that's part of why I want to tell you

00:43:59,910 --> 00:44:03,690
the work I want to do the way I'm going

00:44:02,100 --> 00:44:05,660
to be doing it is I'm going to be

00:44:03,690 --> 00:44:08,550
creating my own data set from scratch

00:44:05,660 --> 00:44:11,900
using 3d rendering

00:44:08,550 --> 00:44:14,880
so all of my models are going to be

00:44:11,900 --> 00:44:17,420
created using a animated camera and

00:44:14,880 --> 00:44:21,990
stuff like that so that I can capture

00:44:17,420 --> 00:44:23,370
hundreds with one render but with one

00:44:21,990 --> 00:44:26,670
pose and everything and then so I'm

00:44:23,370 --> 00:44:28,410
going to start with largely white men

00:44:26,670 --> 00:44:31,500
and then I'm going to actually shift

00:44:28,410 --> 00:44:36,330
shift the data set and see how it goes

00:44:31,500 --> 00:44:38,010
but I think that it's it's so important

00:44:36,330 --> 00:44:39,420
to be able to explore that I wanted the

00:44:38,010 --> 00:44:41,250
reason I'm going with my own data set

00:44:39,420 --> 00:44:45,840
rather than you know leeching off of

00:44:41,250 --> 00:44:49,590
something else like grabbing images from

00:44:45,840 --> 00:44:52,800
Google or Flickr or Instagram I've got

00:44:49,590 --> 00:44:55,440
an instagram scraper I think that it's

00:44:52,800 --> 00:44:58,380
important to go right this is the

00:44:55,440 --> 00:45:00,180
cleanest data set I can make and that's

00:44:58,380 --> 00:45:03,090
the the best way to I guess

00:45:00,180 --> 00:45:05,250
scientifically approach it it means I

00:45:03,090 --> 00:45:08,310
can control other variables which is it

00:45:05,250 --> 00:45:10,890
can be a problem as well so I might also

00:45:08,310 --> 00:45:18,860
do a scraped photographic data set

00:45:10,890 --> 00:45:18,860

YouTube URL: https://www.youtube.com/watch?v=50lK9dZ4vas


