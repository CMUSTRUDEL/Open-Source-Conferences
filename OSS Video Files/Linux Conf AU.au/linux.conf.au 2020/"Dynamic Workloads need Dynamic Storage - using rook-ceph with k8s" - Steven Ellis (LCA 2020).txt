Title: "Dynamic Workloads need Dynamic Storage - using rook-ceph with k8s" - Steven Ellis (LCA 2020)
Publication date: 2020-01-15
Playlist: linux.conf.au 2020
Description: 
	Steven Ellis

https://lca2020.linux.org.au/schedule/presentation/124/

Container technology is a great enabler for developer agility, and these environments require an agile and dynamic storage platform. Gone are the days where you had to wait on your storage administrator to provision a new LUN or NFS mount for your project. Thanks to the Rook Project, and its ceph storage provider, you can now have a rapid, dynamic and elastic storage footprint for all your development needs.

This session will cover - rook basics, dynamic vs static persistent storage needs of workloads, and a demo of using rook-ceph.

linux.conf.au is a conference about the Linux operating system, and all aspects of the thriving ecosystem of Free and Open Source Software that has grown up around it. Run since 1999, in a different Australian or New Zealand city each year, by a team of local volunteers, LCA invites more than 500 people to learn from the people who shape the future of Open Source. For more information on the conference see https://linux.conf.au/

Produced by NDV: https://youtube.com/channel/UCQ7dFBzZGlBvtU2hCecsBBg?sub_confirmation=1

#linux.conf.au #linux #foss #opensource

Tue Jan 14 12:00:00 2020 at Room 7
Captions: 
	00:00:04,430 --> 00:00:10,320
all right we're good to go so welcome

00:00:07,560 --> 00:00:12,210
everyone this will be the first talk so

00:00:10,320 --> 00:00:14,610
the immunity conf its Stephen Ellis

00:00:12,210 --> 00:00:16,139
speaking about from Red Hat speaking

00:00:14,610 --> 00:00:17,730
about rook and Sethe which is a project

00:00:16,139 --> 00:00:19,590
I'm a huge fan of when running at home

00:00:17,730 --> 00:00:21,689
for two years now and my little

00:00:19,590 --> 00:00:24,500
kubernetes cluster and it's a really

00:00:21,689 --> 00:00:27,630
nice I'm looking forward to this

00:00:24,500 --> 00:00:29,880
okay thank you everyone for coming

00:00:27,630 --> 00:00:31,679
it's a little tight on time I'm

00:00:29,880 --> 00:00:34,079
affecting we've got two sets of content

00:00:31,679 --> 00:00:35,760
and a couple of demos so we may not get

00:00:34,079 --> 00:00:39,960
through everything but you know over

00:00:35,760 --> 00:00:41,969
delivery why not based on the audience

00:00:39,960 --> 00:00:44,309
I'm going to do a little bit of an intro

00:00:41,969 --> 00:00:47,760
first on Rock and what it's all about

00:00:44,309 --> 00:00:49,320
and then I'm going to swap content and

00:00:47,760 --> 00:00:51,180
talk about a few concepts and a few

00:00:49,320 --> 00:00:54,270
things in the container storage

00:00:51,180 --> 00:00:56,039
ecosystem that hopefully will create a

00:00:54,270 --> 00:00:59,129
few light bulb moments in the room and

00:00:56,039 --> 00:01:01,710
along the way I'll show off hopefully a

00:00:59,129 --> 00:01:03,840
little bit of rock safe in action now

00:01:01,710 --> 00:01:05,700
some of the content I've got here is the

00:01:03,840 --> 00:01:09,689
latest roadmap content a Gulf Travis

00:01:05,700 --> 00:01:11,159
who's the main rock maintainer so this

00:01:09,689 --> 00:01:12,750
content has been used at some other

00:01:11,159 --> 00:01:15,380
events but I'm going to weave a few

00:01:12,750 --> 00:01:18,869
different themes and stories around it

00:01:15,380 --> 00:01:21,330
so what where is it about rock and

00:01:18,869 --> 00:01:24,360
kubernetes so what is rock rock is a

00:01:21,330 --> 00:01:26,070
storage operator for kubernetes and rock

00:01:24,360 --> 00:01:27,810
isn't Ceph specific what's really nice

00:01:26,070 --> 00:01:30,659
about rockers is a framework for

00:01:27,810 --> 00:01:32,070
managing storage providers rocks F is

00:01:30,659 --> 00:01:33,479
one but there's a number of other

00:01:32,070 --> 00:01:36,150
providers out there and in fact

00:01:33,479 --> 00:01:39,090
something Travis shared recently was a

00:01:36,150 --> 00:01:40,920
cube con number of big storage vendors

00:01:39,090 --> 00:01:43,320
came up and said how can we work better

00:01:40,920 --> 00:01:45,000
with rock and use it to enable the

00:01:43,320 --> 00:01:48,210
delivery of our storage platforms in

00:01:45,000 --> 00:01:52,610
this kubernetes ecosystem but it's not

00:01:48,210 --> 00:01:56,219
just about what one lessee is it's

00:01:52,610 --> 00:01:58,320
multifaceted Rock allows you to install

00:01:56,219 --> 00:02:01,259
the storage technology as a container

00:01:58,320 --> 00:02:03,240
native storage environment as in your

00:02:01,259 --> 00:02:05,610
storage platform runs within kubernetes

00:02:03,240 --> 00:02:08,759
and is managed by kubernetes it allows

00:02:05,610 --> 00:02:11,069
you to configure it natively within a

00:02:08,759 --> 00:02:13,050
kubernetes ecosystem but really

00:02:11,069 --> 00:02:13,810
importantly the operation allows you to

00:02:13,050 --> 00:02:16,450
upgrade it

00:02:13,810 --> 00:02:19,630
elegantly and often that's a big day to

00:02:16,450 --> 00:02:22,209
overhead how to elegantly upgrade a

00:02:19,630 --> 00:02:23,739
software-defined storage stack it's

00:02:22,209 --> 00:02:28,569
still something that many organizations

00:02:23,739 --> 00:02:30,940
are wary of kubernetes a lot of you have

00:02:28,569 --> 00:02:33,030
dealt with already so it's a you know

00:02:30,940 --> 00:02:35,410
platform for distributed applications

00:02:33,030 --> 00:02:37,989
prominently focused around containers

00:02:35,410 --> 00:02:40,510
but it's been broadened now into virtual

00:02:37,989 --> 00:02:42,310
machine management service and a broad

00:02:40,510 --> 00:02:44,590
range of other areas and it has a very

00:02:42,310 --> 00:02:46,810
declarative model who tell it what you

00:02:44,590 --> 00:02:49,260
wanted to achieve and it goes ahead and

00:02:46,810 --> 00:02:52,810
does it for you

00:02:49,260 --> 00:02:56,019
so with storage for kubernetes you have

00:02:52,810 --> 00:02:58,690
these volume plugins to provide various

00:02:56,019 --> 00:03:00,760
storage backends and these could be you

00:02:58,690 --> 00:03:07,959
know proprietary storage technologies

00:03:00,760 --> 00:03:10,750
from EMC from HP from V Sam as part of a

00:03:07,959 --> 00:03:13,690
VMware deployment or they could be open

00:03:10,750 --> 00:03:17,140
source platforms such as safe open EBS

00:03:13,690 --> 00:03:20,500
etc and the storage typically is

00:03:17,140 --> 00:03:22,060
external to the kubernetes cluster but

00:03:20,500 --> 00:03:24,130
one thing we're starting to see is these

00:03:22,060 --> 00:03:25,450
what we call container native storage

00:03:24,130 --> 00:03:28,390
platforms where the storage actually

00:03:25,450 --> 00:03:30,040
runs as a containerized service and can

00:03:28,390 --> 00:03:32,650
be managed by those kind of container

00:03:30,040 --> 00:03:34,660
centric paradigms now when you're

00:03:32,650 --> 00:03:36,760
running your container platform up on a

00:03:34,660 --> 00:03:40,959
public cloud you may be just consuming

00:03:36,760 --> 00:03:42,940
cloud-based storage Amazon s3 EBS and

00:03:40,959 --> 00:03:47,200
equivalent technologies from the Google

00:03:42,940 --> 00:03:48,160
and a Microsoft cloud platforms now I'm

00:03:47,200 --> 00:03:50,739
not going to go through this in detail

00:03:48,160 --> 00:03:52,930
it's in here for kind of reference but

00:03:50,739 --> 00:03:55,030
some of these terms may come up custom

00:03:52,930 --> 00:03:58,350
resource definitions are really critical

00:03:55,030 --> 00:04:02,859
to our ability to extend kubernetes and

00:03:58,350 --> 00:04:06,239
provide you know capabilities above and

00:04:02,859 --> 00:04:09,340
beyond anything the original kubernetes

00:04:06,239 --> 00:04:11,829
developers would have thought possible

00:04:09,340 --> 00:04:14,650
operators are a relatively new addition

00:04:11,829 --> 00:04:19,049
they came out of the core OS team as a

00:04:14,650 --> 00:04:22,419
way to encapsulate a lot of operational

00:04:19,049 --> 00:04:24,550
tasks and automate them in a way that

00:04:22,419 --> 00:04:27,229
makes the or container environment even

00:04:24,550 --> 00:04:29,870
more hands-off

00:04:27,229 --> 00:04:32,120
a PVC a persistent volume claim is

00:04:29,870 --> 00:04:33,710
fairly critical that's the the stories

00:04:32,120 --> 00:04:38,360
that were attaching to a pod or a

00:04:33,710 --> 00:04:39,889
containerized workload and CSI is the

00:04:38,360 --> 00:04:43,340
container storage interface this is

00:04:39,889 --> 00:04:44,870
really key going forward as the main way

00:04:43,340 --> 00:04:47,000
we're going to be plugging third-party

00:04:44,870 --> 00:04:51,139
storage platforms into a kubernetes

00:04:47,000 --> 00:04:53,090
ecosystem and these three terms are very

00:04:51,139 --> 00:04:54,770
critical when we're talking about how

00:04:53,090 --> 00:04:56,270
storage is consumed by kubernetes

00:04:54,770 --> 00:04:59,690
applications or containerized

00:04:56,270 --> 00:05:02,810
applications so readwrite once it's

00:04:59,690 --> 00:05:06,010
being attached to and read write mode to

00:05:02,810 --> 00:05:11,240
a single node or a single container our

00:05:06,010 --> 00:05:12,830
X we'd only mem many think of it like

00:05:11,240 --> 00:05:15,620
you know just mounting a read-only file

00:05:12,830 --> 00:05:17,240
system because it's in read-only mode we

00:05:15,620 --> 00:05:20,900
can elegantly attach that to many

00:05:17,240 --> 00:05:23,270
containers readwrite many is often the

00:05:20,900 --> 00:05:24,949
hard nut to crack it's a hard one to

00:05:23,270 --> 00:05:27,650
deal with in a lot of people default to

00:05:24,949 --> 00:05:32,570
NFS for that which has some interesting

00:05:27,650 --> 00:05:34,220
pain points and idiosyncrasies I can't

00:05:32,570 --> 00:05:35,599
quite say it but these issues right

00:05:34,220 --> 00:05:38,930
there's pain points and I'll cover that

00:05:35,599 --> 00:05:41,750
Y in a moment so I'm going to just swap

00:05:38,930 --> 00:05:45,139
content here because this is something

00:05:41,750 --> 00:05:47,750
I've been using to Ella explain why in a

00:05:45,139 --> 00:05:50,120
containerized ecosystem we need dynamic

00:05:47,750 --> 00:05:53,570
storage because many of us were dealing

00:05:50,120 --> 00:05:55,580
with workloads traditionally container

00:05:53,570 --> 00:05:56,479
in a virtual environment or in a

00:05:55,580 --> 00:05:59,840
physical environment

00:05:56,479 --> 00:06:01,280
I used to storage being a large overhead

00:05:59,840 --> 00:06:03,020
you've gotta go and tap the storage

00:06:01,280 --> 00:06:04,400
admin and have them do something for you

00:06:03,020 --> 00:06:06,949
it's not something that can happen

00:06:04,400 --> 00:06:08,870
dynamically and rapidly as we're moving

00:06:06,949 --> 00:06:11,360
into cloud ecosystems used to having

00:06:08,870 --> 00:06:14,510
cloud api's to do this for us but how

00:06:11,360 --> 00:06:17,510
elegant and how rapid are they and how

00:06:14,510 --> 00:06:18,949
efficient are they so in the past and in

00:06:17,510 --> 00:06:20,599
this case I've shown Red Hat

00:06:18,949 --> 00:06:21,800
virtualization and read out OpenStack

00:06:20,599 --> 00:06:23,900
because that's where I work

00:06:21,800 --> 00:06:25,940
this could just as easily be you know

00:06:23,900 --> 00:06:29,300
any other hypervisor platform any other

00:06:25,940 --> 00:06:31,099
implementation of OpenStack you've got a

00:06:29,300 --> 00:06:32,479
kubernetes cluster some masters some

00:06:31,099 --> 00:06:34,909
nodes and under the hood they're

00:06:32,479 --> 00:06:37,400
consuming a broad range of storage from

00:06:34,909 --> 00:06:39,289
a variety of providers well I don't show

00:06:37,400 --> 00:06:40,800
here actually kind of your traditional

00:06:39,289 --> 00:06:43,740
providers it could be I scuzzy

00:06:40,800 --> 00:06:45,569
fiber channel NFS as well and the key

00:06:43,740 --> 00:06:47,550
person is operations is kind of a

00:06:45,569 --> 00:06:49,610
safeguard to this and I've got to let

00:06:47,550 --> 00:06:52,590
them know in advance that I want some

00:06:49,610 --> 00:06:54,180
some ice cozy endpoints defined I want

00:06:52,590 --> 00:06:56,610
some fibre channel Long's I want some

00:06:54,180 --> 00:06:58,110
NFS export setup but if I'm using the

00:06:56,610 --> 00:07:01,460
cloud api's I can do some of this

00:06:58,110 --> 00:07:04,590
dynamically but there's a degree of

00:07:01,460 --> 00:07:07,470
overhead of busy work of trying to

00:07:04,590 --> 00:07:09,389
manage this so what happens then is your

00:07:07,470 --> 00:07:11,250
operations team says I'm going to pre

00:07:09,389 --> 00:07:12,569
allocate your whole bunch of storage and

00:07:11,250 --> 00:07:13,889
I'm going to allocate that to your

00:07:12,569 --> 00:07:16,520
container farm so I've got a bunch of

00:07:13,889 --> 00:07:20,190
one gig endpoints five gig 10 gig

00:07:16,520 --> 00:07:21,479
allocated off my scuzzy sand and the

00:07:20,190 --> 00:07:23,639
developer comes in and builds an

00:07:21,479 --> 00:07:25,770
application it requests 10 gig it gets

00:07:23,639 --> 00:07:27,900
allocated my application comes up a more

00:07:25,770 --> 00:07:29,789
good to go and you developer builds an

00:07:27,900 --> 00:07:31,650
application they also want an gig that's

00:07:29,789 --> 00:07:33,870
awesome we're all good we're running two

00:07:31,650 --> 00:07:35,580
workloads and then we have a problem

00:07:33,870 --> 00:07:37,680
because the third developer wants a 10

00:07:35,580 --> 00:07:40,639
gig endpoint and we've run out of those

00:07:37,680 --> 00:07:42,960
and the storage back-end has no way of

00:07:40,639 --> 00:07:43,830
dynamically resizing those two fives

00:07:42,960 --> 00:07:46,560
into a 10

00:07:43,830 --> 00:07:49,440
everything's been pre allocated now

00:07:46,560 --> 00:07:52,139
often in early application development

00:07:49,440 --> 00:07:53,639
and in pilots and pocs this is how I'm

00:07:52,139 --> 00:07:55,830
seeing an awful lot of containerized

00:07:53,639 --> 00:07:58,289
environments being built because they

00:07:55,830 --> 00:08:00,990
tend to size them enough to do the pilot

00:07:58,289 --> 00:08:05,039
the POC but then they don't size them

00:08:00,990 --> 00:08:08,039
for real-world workloads now one thing

00:08:05,039 --> 00:08:10,259
is that your workload finishes the

00:08:08,039 --> 00:08:14,940
storage gets the allocated but it

00:08:10,259 --> 00:08:17,849
doesn't get recycled because the backend

00:08:14,940 --> 00:08:20,400
has no way of telling the the storage

00:08:17,849 --> 00:08:21,719
infrastructure to delete the data and to

00:08:20,400 --> 00:08:23,310
reclaim that storage and make it

00:08:21,719 --> 00:08:25,139
available same thing happens if you're

00:08:23,310 --> 00:08:27,120
using things like NFS you may have

00:08:25,139 --> 00:08:29,279
allocated an FSM point you've allocated

00:08:27,120 --> 00:08:31,680
it to your container and when it gets

00:08:29,279 --> 00:08:34,740
disposed of that data still lives on the

00:08:31,680 --> 00:08:37,110
NFS end point unless you've got a script

00:08:34,740 --> 00:08:39,269
some busywork or a third-party tool that

00:08:37,110 --> 00:08:41,099
can go in and and deallocate that

00:08:39,269 --> 00:08:43,050
storage and then tell the environments

00:08:41,099 --> 00:08:45,420
available for reuse if you're dealing

00:08:43,050 --> 00:08:47,820
with this in a static context and it's

00:08:45,420 --> 00:08:50,100
surprising how many places still work

00:08:47,820 --> 00:08:52,560
this way because it's easy it's very

00:08:50,100 --> 00:08:54,690
easy to do if I'm doing a quick hack I

00:08:52,560 --> 00:08:56,070
just go and allocate some storage use it

00:08:54,690 --> 00:08:59,130
I'm good to go and throw the environment

00:08:56,070 --> 00:09:00,990
away so in this case we still have a

00:08:59,130 --> 00:09:02,610
problem because Ops has got to go in and

00:09:00,990 --> 00:09:05,550
do some busy work again and clear things

00:09:02,610 --> 00:09:07,230
up if we have a dynamic storage platform

00:09:05,550 --> 00:09:09,240
doesn't matter what the dynamic provider

00:09:07,230 --> 00:09:11,520
is but if it's truly dynamic things

00:09:09,240 --> 00:09:13,440
change and then the day here is a

00:09:11,520 --> 00:09:15,780
container native storage environments

00:09:13,440 --> 00:09:17,760
agnostic to the infrastructure you talk

00:09:15,780 --> 00:09:20,190
to it it deals with all the lift heavy

00:09:17,760 --> 00:09:21,780
lifting all the busy work so in this

00:09:20,190 --> 00:09:25,110
case I've got the same amount of storage

00:09:21,780 --> 00:09:26,850
I've got my 34 gig but it's not pre

00:09:25,110 --> 00:09:28,890
zoned it's not pre-allocated I've just

00:09:26,850 --> 00:09:31,620
said give me some storage and then

00:09:28,890 --> 00:09:35,400
operations is hands-off didn't do

00:09:31,620 --> 00:09:37,650
anything the developer the storage

00:09:35,400 --> 00:09:39,720
provider everything is automatic

00:09:37,650 --> 00:09:41,220
everything happens dynamically I want 10

00:09:39,720 --> 00:09:43,350
I want another 10

00:09:41,220 --> 00:09:46,170
I want another 10 and application

00:09:43,350 --> 00:09:49,080
finishes the workload dies the storage

00:09:46,170 --> 00:09:51,090
gets reclaimed we're living in a proper

00:09:49,080 --> 00:09:53,730
true dynamic ecosystem and their new

00:09:51,090 --> 00:09:56,610
applications can be deployed watermark

00:09:53,730 --> 00:09:59,490
goes up and down now if we're dealing

00:09:56,610 --> 00:10:01,410
with this in a proper environment where

00:09:59,490 --> 00:10:04,640
we've got build pipelines and we've got

00:10:01,410 --> 00:10:07,590
triggers running off our git repository

00:10:04,640 --> 00:10:10,380
try animating this in Google it's

00:10:07,590 --> 00:10:13,050
interesting right but here we go we've

00:10:10,380 --> 00:10:15,240
got an application pard it runs gets

00:10:13,050 --> 00:10:17,640
mounted we get a new application

00:10:15,240 --> 00:10:19,470
workload because we're running off

00:10:17,640 --> 00:10:21,480
triggers and completely hands-off here

00:10:19,470 --> 00:10:24,330
all of this is happening thanks to get

00:10:21,480 --> 00:10:27,840
commits isn't this awesome ray and then

00:10:24,330 --> 00:10:31,200
things happen then a workload comes to

00:10:27,840 --> 00:10:33,840
its natural end we get the D

00:10:31,200 --> 00:10:36,240
provisioning we get the release and so

00:10:33,840 --> 00:10:38,850
forth things are hands-off things are

00:10:36,240 --> 00:10:41,820
nice and clean this is the way we should

00:10:38,850 --> 00:10:44,700
work in a true container ecosystem all

00:10:41,820 --> 00:10:47,730
the heavy lifting is being done through

00:10:44,700 --> 00:10:49,110
automation through operators and that's

00:10:47,730 --> 00:10:51,330
one of the goals of things like rook

00:10:49,110 --> 00:10:53,430
once it's installed not only will it

00:10:51,330 --> 00:10:58,080
install the storage for you it will do

00:10:53,430 --> 00:10:59,520
all the data operations so hopefully

00:10:58,080 --> 00:11:03,750
that makes sense that sets kind of the

00:10:59,520 --> 00:11:05,940
context now where I'm going to do here

00:11:03,750 --> 00:11:08,280
is I actually have because I work at Red

00:11:05,940 --> 00:11:10,510
Hat open shift is our primary

00:11:08,280 --> 00:11:12,430
kubernetes platform you can go and play

00:11:10,510 --> 00:11:14,620
with okd which is our upstream tour

00:11:12,430 --> 00:11:16,360
version that's our upstream that sits

00:11:14,620 --> 00:11:20,230
between kubernetes think of is i-car

00:11:16,360 --> 00:11:22,540
fedora for kubernetes ok d and I've got

00:11:20,230 --> 00:11:25,450
two different open shift environments

00:11:22,540 --> 00:11:27,490
here so this one has currently no

00:11:25,450 --> 00:11:30,280
persistent storage defined it's a whole

00:11:27,490 --> 00:11:33,400
new environment but I have installed the

00:11:30,280 --> 00:11:35,350
operators for managing this so I can now

00:11:33,400 --> 00:11:37,210
go and create a storage cluster while I

00:11:35,350 --> 00:11:38,380
tell you about rook because this will

00:11:37,210 --> 00:11:39,520
take a few minutes because what it's

00:11:38,380 --> 00:11:41,500
going to do because this is running on

00:11:39,520 --> 00:11:43,330
Amazon is it's actually going to go and

00:11:41,500 --> 00:11:45,970
gray correct tell Amazon to give me a

00:11:43,330 --> 00:11:49,870
bunch of EBS disk they say well why

00:11:45,970 --> 00:11:51,760
don't I just use EBS natively EBS if you

00:11:49,870 --> 00:11:55,270
make a request may take three to five

00:11:51,760 --> 00:11:57,640
minutes ish sometimes to provision if

00:11:55,270 --> 00:11:59,650
I'm doing it with OCS with OpenShift

00:11:57,640 --> 00:12:03,210
container storage based on rock and Ceph

00:11:59,650 --> 00:12:05,890
or I'm just using rocks F not natively

00:12:03,210 --> 00:12:07,780
the turnaround time is maybe a second or

00:12:05,890 --> 00:12:09,460
two when you've got a large number of

00:12:07,780 --> 00:12:11,140
build pipelines that's really critical

00:12:09,460 --> 00:12:12,730
if you're doing an awful lot of work

00:12:11,140 --> 00:12:14,050
through your containerized platform

00:12:12,730 --> 00:12:16,890
you've got an awful lot of triggers

00:12:14,050 --> 00:12:22,000
those latencies really matter

00:12:16,890 --> 00:12:24,670
also EBS isn't multi a-z we can actually

00:12:22,000 --> 00:12:26,350
go and pull three pools of storage of

00:12:24,670 --> 00:12:28,060
across different AZ's and combine them

00:12:26,350 --> 00:12:29,230
into a single set cluster which is

00:12:28,060 --> 00:12:33,660
what's going to happen here

00:12:29,230 --> 00:12:33,660
so I'm going to go into operators

00:12:35,280 --> 00:12:49,360
installed operators and just shift and

00:12:44,920 --> 00:12:55,720
find the storage operator now I'm going

00:12:49,360 --> 00:13:00,990
to go and create a storage cluster now

00:12:55,720 --> 00:13:03,940
I've got a bunch of nodes were

00:13:00,990 --> 00:13:05,800
kubernetes workers and masters deployed

00:13:03,940 --> 00:13:06,760
here I just need to make sure I pick up

00:13:05,800 --> 00:13:12,150
the right ones

00:13:06,760 --> 00:13:12,150
so I ran this earlier so on

00:13:12,430 --> 00:13:19,830
[Music]

00:13:15,140 --> 00:13:28,470
thirty because these are all labeled so

00:13:19,830 --> 00:13:31,050
I can find the right ones 204 so they're

00:13:28,470 --> 00:13:34,800
all in as you can see I've got one in

00:13:31,050 --> 00:13:39,930
one c 1a 1b so I'm going to do this

00:13:34,800 --> 00:13:41,700
multi AZ I hit create that's it

00:13:39,930 --> 00:13:43,440
I'm now hands-off behind-the-scenes

00:13:41,700 --> 00:13:47,190
rocks gone away it's going to do a whole

00:13:43,440 --> 00:13:49,970
load of busy work so if I actually now

00:13:47,190 --> 00:13:49,970
go and do

00:14:11,360 --> 00:14:16,220
so right now it's already starting to

00:14:13,670 --> 00:14:18,860
kick off the generation of all the

00:14:16,220 --> 00:14:20,899
containers associated with this and as

00:14:18,860 --> 00:14:24,049
it runs you'll see these Canary mom's

00:14:20,899 --> 00:14:25,939
appear it'll actually tell AWS under the

00:14:24,049 --> 00:14:28,579
hood to give me the EBS storage' bullet

00:14:25,939 --> 00:14:30,170
acts that dynamically to the the pods

00:14:28,579 --> 00:14:32,809
providing the storage it will build the

00:14:30,170 --> 00:14:34,519
actual SEF cluster under the hood and

00:14:32,809 --> 00:14:36,199
then that will now be available as

00:14:34,519 --> 00:14:39,619
storage classes from applications to

00:14:36,199 --> 00:14:43,639
consume that's going to take about five

00:14:39,619 --> 00:14:45,079
minutes and if you want to resize it you

00:14:43,639 --> 00:14:46,730
just tell it to go and create some more

00:14:45,079 --> 00:14:48,860
storage pools and off it will go and in

00:14:46,730 --> 00:14:50,959
five minutes I've got yet more storage I

00:14:48,860 --> 00:14:53,119
can consume natively by my applications

00:14:50,959 --> 00:14:54,980
and my developers don't care

00:14:53,119 --> 00:14:58,429
my pipelines don't care as long as they

00:14:54,980 --> 00:15:00,589
know what the storage classes are so

00:14:58,429 --> 00:15:03,290
while that's running we'll talk a bit

00:15:00,589 --> 00:15:04,179
more about rock so I've kind of covers

00:15:03,290 --> 00:15:07,100
some of this already

00:15:04,179 --> 00:15:09,410
operators codify the way to deploy and

00:15:07,100 --> 00:15:11,929
manage an application and and achieve a

00:15:09,410 --> 00:15:13,489
certain desired state and then the Rock

00:15:11,929 --> 00:15:18,079
architecture will Rock owns the

00:15:13,489 --> 00:15:20,059
management of Ceph Ceph CSI is the CSI

00:15:18,079 --> 00:15:22,489
driver that actually you know does the

00:15:20,059 --> 00:15:25,009
provisioning connections and then SEF

00:15:22,489 --> 00:15:26,269
offers you these the capabilities for

00:15:25,009 --> 00:15:28,879
block file and object which then

00:15:26,269 --> 00:15:31,879
translate into those RW x RW o

00:15:28,879 --> 00:15:34,040
primitives that we mentioned earlier and

00:15:31,879 --> 00:15:35,449
under the hood as you can see we end up

00:15:34,040 --> 00:15:37,249
with quite a bunch of different

00:15:35,449 --> 00:15:41,329
containers the way it works is that for

00:15:37,249 --> 00:15:48,399
every block device we attach into the

00:15:41,329 --> 00:15:52,549
pod we get a so we connect into a given

00:15:48,399 --> 00:15:55,819
worker node in kubernetes context we get

00:15:52,549 --> 00:15:59,029
a set OSD container started so each

00:15:55,819 --> 00:16:01,220
block of storage has its own set

00:15:59,029 --> 00:16:04,220
instance fo SD attached and then we have

00:16:01,220 --> 00:16:06,499
some SEF mons and other services running

00:16:04,220 --> 00:16:08,689
and fully distributed and highly

00:16:06,499 --> 00:16:10,399
available and it means that with with

00:16:08,689 --> 00:16:13,759
rook we can actually manage the upgrades

00:16:10,399 --> 00:16:16,309
elegantly as well and then when the

00:16:13,759 --> 00:16:19,129
applications are running they will make

00:16:16,309 --> 00:16:20,899
a claim they will go down to the storage

00:16:19,129 --> 00:16:23,119
class and then it will all be handled

00:16:20,899 --> 00:16:25,190
automatically for you and it's all being

00:16:23,119 --> 00:16:27,260
allocated for Nunda lying

00:16:25,190 --> 00:16:30,260
tributed SEF cluster that you can then

00:16:27,260 --> 00:16:35,000
scale out as your environment grows and

00:16:30,260 --> 00:16:37,460
your needs change some recent features

00:16:35,000 --> 00:16:39,650
so upgrading the demons one at a time

00:16:37,460 --> 00:16:41,300
waiting for the environment to reconcile

00:16:39,650 --> 00:16:43,010
this is really critical whether you're

00:16:41,300 --> 00:16:45,080
dealing with software-defined storage on

00:16:43,010 --> 00:16:47,090
physical or virtual or containerized

00:16:45,080 --> 00:16:49,250
environments make sure your data is

00:16:47,090 --> 00:16:52,130
consistent before you upgrade the next

00:16:49,250 --> 00:16:53,420
node if you don't get consistency you've

00:16:52,130 --> 00:16:55,430
got a problem well they're one of the

00:16:53,420 --> 00:16:56,630
nice things with rockers and operators

00:16:55,430 --> 00:16:58,610
we can make sure the environments

00:16:56,630 --> 00:17:03,890
consistent before we upgrade the next

00:16:58,610 --> 00:17:05,660
member of the farm so the CSI driver is

00:17:03,890 --> 00:17:07,339
now the default way we do Rock there was

00:17:05,660 --> 00:17:12,130
a flex driver that we used historically

00:17:07,339 --> 00:17:14,750
so that's the default going forward the

00:17:12,130 --> 00:17:16,280
we now have object bucket provisioning

00:17:14,750 --> 00:17:18,470
I'm not going to go into that a lot of

00:17:16,280 --> 00:17:19,939
details we did with it short on time one

00:17:18,470 --> 00:17:22,280
nice thing that's coming forward is the

00:17:19,939 --> 00:17:24,829
ability to use external safe clusters as

00:17:22,280 --> 00:17:29,510
well as SEF native to the containerized

00:17:24,829 --> 00:17:42,530
environment now let's see so that looks

00:17:29,510 --> 00:17:44,420
like it's all running and then yet

00:17:42,530 --> 00:17:47,600
topology awareness is doing things like

00:17:44,420 --> 00:17:49,310
you know spreading your monitors out you

00:17:47,600 --> 00:17:52,250
know think about it in terms of making

00:17:49,310 --> 00:17:53,660
sure I can suffer a full a-z failure and

00:17:52,250 --> 00:17:55,580
making sure that all the services are

00:17:53,660 --> 00:17:58,220
truly distributed when you're working

00:17:55,580 --> 00:18:01,220
within a cloud context but we're working

00:17:58,220 --> 00:18:03,140
on making this topology awareness feed

00:18:01,220 --> 00:18:05,750
down into other platforms

00:18:03,140 --> 00:18:08,600
so within OpenStack or whether we're

00:18:05,750 --> 00:18:10,970
running on VMware we can make sure that

00:18:08,600 --> 00:18:13,460
you can set in a topology awareness so

00:18:10,970 --> 00:18:14,780
you can lose a hypervisor or lose a rack

00:18:13,460 --> 00:18:20,240
and the environment will still maintain

00:18:14,780 --> 00:18:22,880
availability where else will now new

00:18:20,240 --> 00:18:24,710
features there's a new crash dump

00:18:22,880 --> 00:18:26,300
collector come in and there's a whole

00:18:24,710 --> 00:18:28,940
bunch of other features coming in in the

00:18:26,300 --> 00:18:30,170
roadmap so we're yeah we're running low

00:18:28,940 --> 00:18:34,520
on time it's a few other things we'll

00:18:30,170 --> 00:18:37,130
cover off um I'll kind of skip that what

00:18:34,520 --> 00:18:38,429
will actually do is jump to more of the

00:18:37,130 --> 00:18:42,700
demo

00:18:38,429 --> 00:18:47,950
so if I come back up here to the

00:18:42,700 --> 00:18:49,809
dashboards I've now got a storage

00:18:47,950 --> 00:18:52,570
cluster with some visibility here

00:18:49,809 --> 00:18:58,440
through this particular dashboard or

00:18:52,570 --> 00:18:58,440
I've also donks I've got some scripting

00:18:59,700 --> 00:19:07,960
you know that's it's not quite up no so

00:19:06,640 --> 00:19:10,830
I've got a problem with that one so

00:19:07,960 --> 00:19:10,830
here's one I prepared earlier

00:19:18,440 --> 00:19:23,570
it's a different I've got two clusters

00:19:20,540 --> 00:19:27,860
running here so this I can actually run

00:19:23,570 --> 00:19:31,520
a chef's toolbox container and run a

00:19:27,860 --> 00:19:33,770
shell into it I can actually do standard

00:19:31,520 --> 00:19:35,390
self-management tasks in here but one

00:19:33,770 --> 00:19:37,910
thing to understand that's really

00:19:35,390 --> 00:19:41,360
critical to this is through the the

00:19:37,910 --> 00:19:43,160
Brooke interfacing to Seth we're not

00:19:41,360 --> 00:19:44,570
making all of the knobs available all

00:19:43,160 --> 00:19:46,610
the bits you want to twiddle if you're a

00:19:44,570 --> 00:19:49,430
regular set administrator because

00:19:46,610 --> 00:19:53,120
there's a lot of them Andrew is there a

00:19:49,430 --> 00:19:54,920
loss yeah so what we want to do is make

00:19:53,120 --> 00:19:58,760
it as simple as possible for you to

00:19:54,920 --> 00:20:00,830
quickly set up and consume a container

00:19:58,760 --> 00:20:02,570
native storage footprint and you can

00:20:00,830 --> 00:20:04,520
just do this straight out the back with

00:20:02,570 --> 00:20:06,380
fully upstream rock and go to rock dot

00:20:04,520 --> 00:20:07,610
IO there's a quick walk through and like

00:20:06,380 --> 00:20:08,840
in five minutes and your kubernetes

00:20:07,610 --> 00:20:12,260
cluster you can have a highly available

00:20:08,840 --> 00:20:15,130
storage cluster running now the other

00:20:12,260 --> 00:20:20,240
thing here is why is this important

00:20:15,130 --> 00:20:23,720
so quite often yeah I'm out of time so

00:20:20,240 --> 00:20:25,910
I'm gonna just over run a moment this is

00:20:23,720 --> 00:20:30,860
a simple file application deployed this

00:20:25,910 --> 00:20:37,240
is currently running in a log out of

00:20:30,860 --> 00:20:39,350
this this currently running in a three

00:20:37,240 --> 00:20:41,780
container configuration for high

00:20:39,350 --> 00:20:45,920
availability so if I upload a file

00:20:41,780 --> 00:20:49,640
random file into this with a standard

00:20:45,920 --> 00:20:51,530
container configuration and I go and

00:20:49,640 --> 00:20:54,320
list uploaded files there it is if I

00:20:51,530 --> 00:20:56,480
just go and run this this will actually

00:20:54,320 --> 00:20:58,790
go and do an LS inside all three parts

00:20:56,480 --> 00:21:01,040
and you'll see that the actual file only

00:20:58,790 --> 00:21:03,530
exists in one pod because I don't have

00:21:01,040 --> 00:21:06,170
shared storage between them and because

00:21:03,530 --> 00:21:09,170
this is a you know file based back-end I

00:21:06,170 --> 00:21:10,340
really need an rwx tie storage footprint

00:21:09,170 --> 00:21:13,820
now often this will be something like

00:21:10,340 --> 00:21:15,380
NFS but with container native storage I

00:21:13,820 --> 00:21:21,710
can just tell it to go and change its

00:21:15,380 --> 00:21:24,990
storage class over to our new storage so

00:21:21,710 --> 00:21:32,170
I'm going to just make this change

00:21:24,990 --> 00:21:34,870
yes by simply changing the storage class

00:21:32,170 --> 00:21:37,270
those containers will redeploy I will

00:21:34,870 --> 00:21:39,670
now have a common rwx back in between

00:21:37,270 --> 00:21:42,220
the three containers and if I upload a

00:21:39,670 --> 00:21:43,630
file now and I do the same LS I'll see

00:21:42,220 --> 00:21:45,550
the same file in all three it's

00:21:43,630 --> 00:21:47,170
effectively using the same back-end if I

00:21:45,550 --> 00:21:50,640
then go look inside SEF I'll see that

00:21:47,170 --> 00:21:52,840
there's been a PV created with and a PVC

00:21:50,640 --> 00:21:55,270
allocated and the storage is being

00:21:52,840 --> 00:21:57,160
consumed actually offset off s because

00:21:55,270 --> 00:21:59,920
when we do our W X it goes back ends

00:21:57,160 --> 00:22:01,950
onto CFS whereas when we're doing block

00:21:59,920 --> 00:22:06,750
we're just backing onto straight

00:22:01,950 --> 00:22:09,160
liberate us hope that makes sense so

00:22:06,750 --> 00:22:10,660
I'll show that off in a minute but are

00:22:09,160 --> 00:22:25,360
there any questions because we need to

00:22:10,660 --> 00:22:28,750
wrap up shortly I'm just creating the

00:22:25,360 --> 00:22:30,190
last so because of the change of the

00:22:28,750 --> 00:22:33,100
definition of the pods the pods are

00:22:30,190 --> 00:22:34,960
being recreated so this will be back up

00:22:33,100 --> 00:22:37,330
and running in a moment have you used a

00:22:34,960 --> 00:22:42,430
rock in production and for how long and

00:22:37,330 --> 00:22:45,070
do you have any issues so for some of

00:22:42,430 --> 00:22:46,990
the big events we've been running in the

00:22:45,070 --> 00:22:49,870
region recently we actually ran it all

00:22:46,990 --> 00:22:51,760
on top of SEF Rock I know those

00:22:49,870 --> 00:22:53,620
environments were running for you know

00:22:51,760 --> 00:22:55,030
several months you know this is stuff

00:22:53,620 --> 00:22:58,270
that's relatively new we've got a bunch

00:22:55,030 --> 00:22:59,860
of customers regionally and globally on

00:22:58,270 --> 00:23:02,680
the early adopter program for this

00:22:59,860 --> 00:23:04,780
because we are commercial GF it's about

00:23:02,680 --> 00:23:06,520
to go live but no Travis knows people

00:23:04,780 --> 00:23:09,460
using this in active production today

00:23:06,520 --> 00:23:10,660
off the community branches and at least

00:23:09,460 --> 00:23:12,490
with the community branches well there

00:23:10,660 --> 00:23:14,800
are stable releases that you can tag

00:23:12,490 --> 00:23:21,070
against so you're running against the 1

00:23:14,800 --> 00:23:22,960
1 or 1 2 release where it gets really

00:23:21,070 --> 00:23:27,010
interesting is when things randomly go

00:23:22,960 --> 00:23:31,690
down or you don't fully clean up after

00:23:27,010 --> 00:23:33,340
certain workloads have gone away if any

00:23:31,690 --> 00:23:35,770
of you work with kubernetes at scale

00:23:33,340 --> 00:23:37,309
it's great if you want to scale your

00:23:35,770 --> 00:23:38,899
workers up

00:23:37,309 --> 00:23:40,879
but dynamically scaling your workers

00:23:38,899 --> 00:23:42,710
down and cause some interesting havoc if

00:23:40,879 --> 00:23:44,240
you don't actually evacuate them

00:23:42,710 --> 00:23:47,659
properly and that can cause some issues

00:23:44,240 --> 00:23:49,279
if you think there's like a pod running

00:23:47,659 --> 00:23:52,159
on a worker that we've now

00:23:49,279 --> 00:23:53,749
decommissioned that may still think it's

00:23:52,159 --> 00:23:54,740
got some storage attached so sometimes

00:23:53,749 --> 00:23:56,529
you've got to go and do a bit of magic

00:23:54,740 --> 00:23:58,940
to tidy things up under the hood

00:23:56,529 --> 00:24:01,100
otherwise things can get a little funky

00:23:58,940 --> 00:24:05,570
but by and large it's pretty solid and

00:24:01,100 --> 00:24:09,710
stable at the moment okay so that's up

00:24:05,570 --> 00:24:14,029
and running the file has gone because

00:24:09,710 --> 00:24:18,769
this is a whole new environment upload

00:24:14,029 --> 00:24:21,049
the same file any more questions yeah

00:24:18,769 --> 00:24:25,340
it's we're at a time pretty much so I'm

00:24:21,049 --> 00:24:26,509
afraid okay oh yeah so catch me on the

00:24:25,340 --> 00:24:29,269
hallway because we're going to be doing

00:24:26,509 --> 00:24:37,850
the jobs boffin here any minute now

00:24:29,269 --> 00:24:40,389
thank you for your time so see you back

00:24:37,850 --> 00:24:40,389

YouTube URL: https://www.youtube.com/watch?v=B-uUjGuoPxk


