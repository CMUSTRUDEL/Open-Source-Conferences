Title: "Open Journal Matcher: open journal discovery for everyone" - Mark Eaton (LCA 2021 Online)
Publication date: 2021-01-31
Playlist: linux.conf.au 2021
Description: 
	Mark Eaton

https://lca2021.linux.org.au/schedule/presentation/89/

I recently built a web application called the Open Journal Matcher (https://ojm.ocert.at), which is a recommender tool for academics looking to find a suitable scholarly journal for their work. The Open Journal Matcher allows users to paste in a draft abstract, which it then compares with the abstracts of over 5600 journals from the Directory of Open Access Journals. The application then returns the top five suggested matches, which are meant to be both relevant and serendipitous. This can be very useful to anyone trying to find an appropriate journal for their work.

While there are other journal matching services available, to my knowledge this is the only one that is both fully interdisciplinary and fully open source. The code for the matcher application, the code for the matching algorithm, and the content of the journals, is all openly licensed. 

Upon its release in June 2020, the OJM received a very favorable reception from the open scholarship and scholarly communications communities. It has been shared widely by on many platforms. For me, this has reaffirmed the need for such a tool, and has led me to focus on its further development.

This presentation will describe insights gleaned while building this tool. I’ll describe the challenges of gathering journal data from the Directory of Open Access Journals’ API at scale; the numerous lessons learned while using natural language processing tools to calculate the similarity of texts; and the difficulties processing large amounts of data very quickly for the web using Google Cloud Platform and asynchronous Python programming.

This project also raises important questions about the ethics of algorithmic decision making. As technologists, how do we critically evaluate the algorithms that we use when we solve practical programming problems? How do we communicate the trade-offs and choices we make to stakeholders in our communities who rely upon the tools we build? And how do we ensure that feedback from our communities always comes first in shaping those tools, so that they most help the people we are serving?

This presentation will be of interest to authors who are looking for a journal to publish their scholarly work. It will also be relevant to technologists who are interested in building open source tools for their communities. It will be helpful to librarians who promote scholarly communications, and who may find this tool to be a useful addition to their toolkit. Lastly, it will serve as an interesting example of the novel services we can provide to our communities when we apply open digital technologies in support of our scholarship.

linux.conf.au is a conference about the Linux operating system, and all aspects of the thriving ecosystem of Free and Open Source Software that has grown up around it. Run since 1999, in a different Australian or New Zealand city each year, by a team of local volunteers, LCA invites more than 500 people to learn from the people who shape the future of Open Source. For more information on the conference see https://linux.conf.au/

Produced by Next Day Video Australia: https://nextdayvideo.com.au

#linux.conf.au #linux #foss #opensource

Sat Jan 23 11:40:00 2021 at Pia Andrews Conservatory
Captions: 
	00:00:10,820 --> 00:00:14,060
[Music]

00:00:15,120 --> 00:00:17,680
everyone

00:00:15,679 --> 00:00:19,439
um i've just been checking out our q a

00:00:17,680 --> 00:00:21,439
stream and oh my goodness there's just

00:00:19,439 --> 00:00:23,680
so much great stuff going on there

00:00:21,439 --> 00:00:25,119
i can't wait to get back in and really

00:00:23,680 --> 00:00:27,439
dive round in there

00:00:25,119 --> 00:00:28,320
um we're up for our next presentation

00:00:27,439 --> 00:00:30,560
we've got mark

00:00:28,320 --> 00:00:32,320
eden eaton who is a reader services

00:00:30,560 --> 00:00:34,000
librarian and associate professor at

00:00:32,320 --> 00:00:36,239
kingsborough community college

00:00:34,000 --> 00:00:38,640
at the city university of new york mark

00:00:36,239 --> 00:00:39,680
is committed advocate for code education

00:00:38,640 --> 00:00:41,600
for everyone

00:00:39,680 --> 00:00:44,000
he believes that when librarians build

00:00:41,600 --> 00:00:46,000
open appropriate and privacy respecting

00:00:44,000 --> 00:00:47,440
technologies for their communities it

00:00:46,000 --> 00:00:50,160
can be empowering for both

00:00:47,440 --> 00:00:52,559
librarians and their libraries mark's

00:00:50,160 --> 00:00:54,800
presenting on his open journal matcher

00:00:52,559 --> 00:00:57,199
a recommended tool for academics looking

00:00:54,800 --> 00:00:59,039
to find a suitable scholarly journal

00:00:57,199 --> 00:01:01,440
for their work he's going to share

00:00:59,039 --> 00:01:03,280
insights gleaned while building the tool

00:01:01,440 --> 00:01:05,119
and discuss important questions around

00:01:03,280 --> 00:01:07,360
the ethics of algorithmic

00:01:05,119 --> 00:01:08,880
decision making thanks mark over to

00:01:07,360 --> 00:01:12,799
youth

00:01:08,880 --> 00:01:15,439
thank you um it's nice to be here um

00:01:12,799 --> 00:01:16,880
my name is mark eaton as bonnie said uh

00:01:15,439 --> 00:01:18,320
i'm i'm at kingsborough community

00:01:16,880 --> 00:01:19,200
college at the city university of new

00:01:18,320 --> 00:01:21,360
york

00:01:19,200 --> 00:01:22,720
um i do things that's at kingsborough

00:01:21,360 --> 00:01:23,759
like work on our institutional

00:01:22,720 --> 00:01:26,799
repository and

00:01:23,759 --> 00:01:28,159
manage electronic resources i've just

00:01:26,799 --> 00:01:29,439
started sharing our library's website

00:01:28,159 --> 00:01:31,520
committee which is a big job because

00:01:29,439 --> 00:01:33,040
there's a lot of work to do there

00:01:31,520 --> 00:01:35,759
but that's not what i want to talk about

00:01:33,040 --> 00:01:37,520
today today i want to talk about

00:01:35,759 --> 00:01:39,040
a project i built which is a journal

00:01:37,520 --> 00:01:41,439
recommender tool

00:01:39,040 --> 00:01:43,200
so what it does is you can enter an

00:01:41,439 --> 00:01:43,920
abstract and it will pick the journals

00:01:43,200 --> 00:01:46,720
that

00:01:43,920 --> 00:01:48,320
best the open access journals that best

00:01:46,720 --> 00:01:50,159
match that text

00:01:48,320 --> 00:01:51,600
so the goal is really to give people

00:01:50,159 --> 00:01:53,360
writing academic papers

00:01:51,600 --> 00:01:55,600
suggestions about where they can publish

00:01:53,360 --> 00:01:57,200
their work and i'm totally not going to

00:01:55,600 --> 00:01:58,719
do a live demo because live demos are

00:01:57,200 --> 00:02:01,360
terrifying

00:01:58,719 --> 00:02:02,560
but but here's a screenshot and a url if

00:02:01,360 --> 00:02:05,520
you want to try it

00:02:02,560 --> 00:02:07,119
so you would pop your abstract in the

00:02:05,520 --> 00:02:09,759
text box

00:02:07,119 --> 00:02:10,879
and click search and it will spin for a

00:02:09,759 --> 00:02:12,239
minute or two

00:02:10,879 --> 00:02:14,720
and then it's going to give you some

00:02:12,239 --> 00:02:15,680
results for the top matching open access

00:02:14,720 --> 00:02:17,920
journals

00:02:15,680 --> 00:02:19,680
and that's that's what it does so i'm

00:02:17,920 --> 00:02:21,200
going to talk about how this works

00:02:19,680 --> 00:02:22,800
i'm going to talk about some of the

00:02:21,200 --> 00:02:24,160
things i learned along the way

00:02:22,800 --> 00:02:25,760
these are technical things these are

00:02:24,160 --> 00:02:27,120
organizational things these are ethical

00:02:25,760 --> 00:02:29,680
things

00:02:27,120 --> 00:02:30,319
but i'm going to cover all of those so

00:02:29,680 --> 00:02:32,480
you might

00:02:30,319 --> 00:02:33,519
you might want a tool like this if

00:02:32,480 --> 00:02:35,120
you're an academic

00:02:33,519 --> 00:02:38,239
writing an article and you want to find

00:02:35,120 --> 00:02:39,920
an appropriate journal for your work

00:02:38,239 --> 00:02:41,599
in the past when i did this it was very

00:02:39,920 --> 00:02:43,599
time consuming because i would do it by

00:02:41,599 --> 00:02:45,120
hand i would gather

00:02:43,599 --> 00:02:47,440
abstracts from a whole bunch of

00:02:45,120 --> 00:02:49,200
different journals over several years

00:02:47,440 --> 00:02:51,440
and read them all and it would take me a

00:02:49,200 --> 00:02:53,519
couple days to go through this process

00:02:51,440 --> 00:02:55,599
which is a lot of reading just a glean

00:02:53,519 --> 00:02:57,440
fit at a really high level

00:02:55,599 --> 00:02:59,280
so i don't think this is necessarily the

00:02:57,440 --> 00:03:01,519
best use of my time and i think that

00:02:59,280 --> 00:03:02,480
while reading for fit may be useful in

00:03:01,519 --> 00:03:04,400
some contexts

00:03:02,480 --> 00:03:07,040
some contexts there's probably a better

00:03:04,400 --> 00:03:07,040
way to do this

00:03:07,200 --> 00:03:10,720
there are other journal recommenders out

00:03:09,599 --> 00:03:12,560
there

00:03:10,720 --> 00:03:14,080
this is not the only one here are some

00:03:12,560 --> 00:03:16,239
other organizations that have

00:03:14,080 --> 00:03:17,519
journal recommenders these are probably

00:03:16,239 --> 00:03:19,760
all

00:03:17,519 --> 00:03:20,879
better resourced than my project but

00:03:19,760 --> 00:03:22,800
mine fills a niche

00:03:20,879 --> 00:03:25,680
that i believe is not addressed by these

00:03:22,800 --> 00:03:28,239
other ones it's fully interdisciplinary

00:03:25,680 --> 00:03:30,959
and it's fully openly licensed so the

00:03:28,239 --> 00:03:32,799
code is openly licensed it's mit license

00:03:30,959 --> 00:03:35,040
and the journals themselves are openly

00:03:32,799 --> 00:03:39,040
licensed

00:03:35,040 --> 00:03:41,200
uh so it's on github you're welcome to

00:03:39,040 --> 00:03:43,120
fork it and run it yourself if you want

00:03:41,200 --> 00:03:43,920
or send me pull requests that would be

00:03:43,120 --> 00:03:46,319
amazing too

00:03:43,920 --> 00:03:48,720
i would i would welcome contributions of

00:03:46,319 --> 00:03:51,440
course that would be phenomenal

00:03:48,720 --> 00:03:53,439
um this project is really inspired by

00:03:51,440 --> 00:03:56,159
the directory of open access journals

00:03:53,439 --> 00:03:58,159
api the directory of open access

00:03:56,159 --> 00:04:01,519
journals api provides access to

00:03:58,159 --> 00:04:03,599
a lot of abstracts and this was really

00:04:01,519 --> 00:04:05,680
exciting to me when i found out about it

00:04:03,599 --> 00:04:08,159
the first thing i did was build a silly

00:04:05,680 --> 00:04:10,319
bot that kind of pretends it's a scholar

00:04:08,159 --> 00:04:11,840
and mashes up bits of abstracts anyway

00:04:10,319 --> 00:04:13,760
it's not a good use of my time

00:04:11,840 --> 00:04:16,000
but it did lead me to the journal

00:04:13,760 --> 00:04:18,079
matcher project

00:04:16,000 --> 00:04:19,759
so you might be asking like well what is

00:04:18,079 --> 00:04:21,120
in this directory of open access

00:04:19,759 --> 00:04:22,720
journals

00:04:21,120 --> 00:04:24,800
that's a good question there's lots of

00:04:22,720 --> 00:04:27,840
openly licensed scholarship there

00:04:24,800 --> 00:04:29,600
in many languages with metadata of

00:04:27,840 --> 00:04:31,199
varying quality

00:04:29,600 --> 00:04:32,639
you could ask if the journals themselves

00:04:31,199 --> 00:04:34,240
are of high quality and

00:04:32,639 --> 00:04:36,000
the directory of open access journals

00:04:34,240 --> 00:04:37,680
calls their content

00:04:36,000 --> 00:04:39,520
community curated which doesn't sound

00:04:37,680 --> 00:04:41,040
super reliable to me

00:04:39,520 --> 00:04:43,120
but they have put effort into cleaning

00:04:41,040 --> 00:04:46,479
up their journalist over time so

00:04:43,120 --> 00:04:47,919
back in 2017 uh something like 5000

00:04:46,479 --> 00:04:49,280
journals were removed for not meeting

00:04:47,919 --> 00:04:51,120
standards

00:04:49,280 --> 00:04:52,960
so i think as an author you have to do

00:04:51,120 --> 00:04:55,680
your due diligence you can't

00:04:52,960 --> 00:04:56,880
just assume that a journal is the best

00:04:55,680 --> 00:04:58,479
home for your work

00:04:56,880 --> 00:05:00,880
you have to be careful about that and do

00:04:58,479 --> 00:05:03,600
your your homework

00:05:00,880 --> 00:05:05,759
so i started poking around the directory

00:05:03,600 --> 00:05:08,960
of open access journals

00:05:05,759 --> 00:05:11,840
website and api documentation and

00:05:08,960 --> 00:05:12,240
um i found a downloadable list of issns

00:05:11,840 --> 00:05:13,840
for

00:05:12,240 --> 00:05:16,320
journals in the directory this was a

00:05:13,840 --> 00:05:18,160
spreadsheet um

00:05:16,320 --> 00:05:19,840
for those who don't know issns are

00:05:18,160 --> 00:05:21,440
unique identifiers for journals they're

00:05:19,840 --> 00:05:23,360
sort of like

00:05:21,440 --> 00:05:24,960
isbns which you might be more familiar

00:05:23,360 --> 00:05:25,919
with which are unique identifiers for

00:05:24,960 --> 00:05:28,160
books

00:05:25,919 --> 00:05:29,360
issn stands for international standard

00:05:28,160 --> 00:05:31,039
serial number

00:05:29,360 --> 00:05:32,960
and i could query the directory of open

00:05:31,039 --> 00:05:35,199
access journal api

00:05:32,960 --> 00:05:36,800
with issns and get back lots of

00:05:35,199 --> 00:05:38,000
abstracts so i could download these

00:05:36,800 --> 00:05:40,479
abstracts on mass from the

00:05:38,000 --> 00:05:41,520
api and this allowed me to get like

00:05:40,479 --> 00:05:43,199
quite a collection of them

00:05:41,520 --> 00:05:44,720
uh you have to be kind of courteous

00:05:43,199 --> 00:05:46,400
about this and not

00:05:44,720 --> 00:05:48,560
hammer the api with thousands of

00:05:46,400 --> 00:05:50,160
requests at once but if you space it out

00:05:48,560 --> 00:05:52,240
a bit you can get a good collection of

00:05:50,160 --> 00:05:54,000
abstracts to work with so

00:05:52,240 --> 00:05:55,360
obviously this isn't the entire universe

00:05:54,000 --> 00:05:57,840
of scholarly journals right

00:05:55,360 --> 00:05:59,919
i ended up with maybe 6 000 english

00:05:57,840 --> 00:06:01,520
language journals

00:05:59,919 --> 00:06:03,120
which limits the utility of the tool

00:06:01,520 --> 00:06:04,840
somewhat but i think it's

00:06:03,120 --> 00:06:06,639
it's still enough data to make good

00:06:04,840 --> 00:06:07,759
recommendations

00:06:06,639 --> 00:06:10,080
one of the problems i was actually

00:06:07,759 --> 00:06:12,240
facing was that i had too much data

00:06:10,080 --> 00:06:14,000
so doing natural language processing on

00:06:12,240 --> 00:06:15,360
a data set like this requires a fair bit

00:06:14,000 --> 00:06:17,520
of computing power

00:06:15,360 --> 00:06:21,280
and i can't realistically process every

00:06:17,520 --> 00:06:23,759
single abstract in the directory uh

00:06:21,280 --> 00:06:25,520
in any feasible way so i limited myself

00:06:23,759 --> 00:06:27,199
to the hundred most recent abstracts per

00:06:25,520 --> 00:06:27,680
journal which is still a lot of data but

00:06:27,199 --> 00:06:29,440
was

00:06:27,680 --> 00:06:31,600
which was a trade-off for the sake of

00:06:29,440 --> 00:06:33,199
expediency and it gave me a good corpus

00:06:31,600 --> 00:06:35,440
to work with

00:06:33,199 --> 00:06:36,880
so these uh abstracts are in google

00:06:35,440 --> 00:06:39,759
cloud storage and i'm going to come back

00:06:36,880 --> 00:06:39,759
to them in a minute

00:06:42,240 --> 00:06:45,919
to build the application i use flask

00:06:44,400 --> 00:06:47,600
which is a python web

00:06:45,919 --> 00:06:49,280
micro framework which is especially

00:06:47,600 --> 00:06:52,319
useful for building

00:06:49,280 --> 00:06:53,680
minimal python web applications it has

00:06:52,319 --> 00:06:55,199
more advanced features that you can plug

00:06:53,680 --> 00:06:57,199
in if you need them but on its own it's

00:06:55,199 --> 00:06:58,720
very basic and very flexible

00:06:57,199 --> 00:07:00,800
and i run this flask application on

00:06:58,720 --> 00:07:01,199
python anywhere which is a service for

00:07:00,800 --> 00:07:03,759
running

00:07:01,199 --> 00:07:04,960
python applications in the cloud um i

00:07:03,759 --> 00:07:06,400
don't think it's really meant for large

00:07:04,960 --> 00:07:09,120
scale applications but it was

00:07:06,400 --> 00:07:10,720
sufficient for my purposes what i liked

00:07:09,120 --> 00:07:12,479
about it was that i could do most of my

00:07:10,720 --> 00:07:14,000
work in python or in bash

00:07:12,479 --> 00:07:15,440
and i didn't need to worry about the web

00:07:14,000 --> 00:07:16,160
interface very much and i didn't need to

00:07:15,440 --> 00:07:19,199
worry about

00:07:16,160 --> 00:07:20,160
an sdk or annoying interface like that

00:07:19,199 --> 00:07:21,599
to deal with

00:07:20,160 --> 00:07:23,680
i could do my work in python which i was

00:07:21,599 --> 00:07:28,000
happy about

00:07:23,680 --> 00:07:30,160
and the flask application in this

00:07:28,000 --> 00:07:31,520
context does not do the data processing

00:07:30,160 --> 00:07:32,160
it would be too computationally

00:07:31,520 --> 00:07:34,479
intensive

00:07:32,160 --> 00:07:35,840
to do all the data processing in the

00:07:34,479 --> 00:07:39,039
flask application

00:07:35,840 --> 00:07:41,039
so instead of that the flask application

00:07:39,039 --> 00:07:43,280
sends out

00:07:41,039 --> 00:07:44,479
sends it out to a google cloud function

00:07:43,280 --> 00:07:46,560
and a cloud function

00:07:44,479 --> 00:07:48,000
is also some python code that i wrote

00:07:46,560 --> 00:07:50,879
but it lives in the google cloud and it

00:07:48,000 --> 00:07:53,120
can be invoked with an http request

00:07:50,879 --> 00:07:54,160
so i i invoke this cloud function once

00:07:53,120 --> 00:07:56,639
for each journal that's

00:07:54,160 --> 00:07:58,720
being compared so the flask application

00:07:56,639 --> 00:08:00,960
is making like 6 000 simultaneous

00:07:58,720 --> 00:08:01,840
calls to the google cloud function which

00:08:00,960 --> 00:08:03,759
is possible

00:08:01,840 --> 00:08:05,199
um thanks to asynchronous python which

00:08:03,759 --> 00:08:07,440
i'm totally not going into

00:08:05,199 --> 00:08:08,560
but which was a key piece to making this

00:08:07,440 --> 00:08:10,720
work

00:08:08,560 --> 00:08:12,000
so part of the story is that google

00:08:10,720 --> 00:08:14,720
cloud functions

00:08:12,000 --> 00:08:15,919
uh can handle brief intense spikes of

00:08:14,720 --> 00:08:18,080
usage like this

00:08:15,919 --> 00:08:19,280
which was my use case right i needed a

00:08:18,080 --> 00:08:20,720
function that could be called many

00:08:19,280 --> 00:08:24,319
thousands of times at once

00:08:20,720 --> 00:08:25,680
and maybe not again for hours after that

00:08:24,319 --> 00:08:27,680
and this is one of the reasons why i use

00:08:25,680 --> 00:08:30,400
this this approach

00:08:27,680 --> 00:08:31,840
so here it is visually i know diagrams

00:08:30,400 --> 00:08:33,919
like this can make your eyes bleed

00:08:31,840 --> 00:08:34,880
uh i tried to make it as straightforward

00:08:33,919 --> 00:08:36,640
as possible

00:08:34,880 --> 00:08:38,560
i'm gonna i'm gonna explain this really

00:08:36,640 --> 00:08:40,560
really quickly um

00:08:38,560 --> 00:08:41,760
the user at the top left inputs their

00:08:40,560 --> 00:08:44,720
draft abstract

00:08:41,760 --> 00:08:46,160
it gets validated for um being an

00:08:44,720 --> 00:08:47,760
appropriate number of characters like

00:08:46,160 --> 00:08:49,279
not too long or anything

00:08:47,760 --> 00:08:50,880
uh it checks to make sure it's in

00:08:49,279 --> 00:08:52,320
english it calls this cloud function

00:08:50,880 --> 00:08:55,519
about six thousand times

00:08:52,320 --> 00:08:58,320
i've shown about seven of them there

00:08:55,519 --> 00:08:59,920
the cloud function draws upon the

00:08:58,320 --> 00:09:00,720
abstracts which are in google cloud

00:08:59,920 --> 00:09:02,560
storage

00:09:00,720 --> 00:09:04,720
close at hand and it does the

00:09:02,560 --> 00:09:06,480
comparisons and it returns a calculated

00:09:04,720 --> 00:09:08,160
similarity score

00:09:06,480 --> 00:09:09,519
back to the flask application so the

00:09:08,160 --> 00:09:10,800
flask application gathers all these

00:09:09,519 --> 00:09:13,200
scores

00:09:10,800 --> 00:09:14,640
sorts them and does a couple more api

00:09:13,200 --> 00:09:16,399
calls to get the titles of the top

00:09:14,640 --> 00:09:16,800
matching journals and then returns those

00:09:16,399 --> 00:09:20,640
to the

00:09:16,800 --> 00:09:22,080
user so um

00:09:20,640 --> 00:09:24,080
let's talk about how this work works

00:09:22,080 --> 00:09:25,200
under the hood um

00:09:24,080 --> 00:09:26,880
i don't have a computer science

00:09:25,200 --> 00:09:28,800
background so when i talk about

00:09:26,880 --> 00:09:30,320
algorithms there are points when i

00:09:28,800 --> 00:09:32,000
run up against the limits of my

00:09:30,320 --> 00:09:33,200
understanding and

00:09:32,000 --> 00:09:35,680
for those of you who know more about

00:09:33,200 --> 00:09:37,120
these things than i do please forgive my

00:09:35,680 --> 00:09:38,880
attempts to inadequately deal with

00:09:37,120 --> 00:09:40,320
complex topics

00:09:38,880 --> 00:09:41,839
i'm going to do those best i'm going to

00:09:40,320 --> 00:09:43,279
do my best at those moments where i'm at

00:09:41,839 --> 00:09:44,880
the limits of my understanding to point

00:09:43,279 --> 00:09:46,000
to others work that's more knowledgeable

00:09:44,880 --> 00:09:47,360
than mine

00:09:46,000 --> 00:09:51,279
but with that being said let's talk

00:09:47,360 --> 00:09:52,560
about how it works under the hood

00:09:51,279 --> 00:09:54,320
i'm not going to bore you with my

00:09:52,560 --> 00:09:56,959
initial sort of naive attempts

00:09:54,320 --> 00:09:58,480
at solving this problem it turns out

00:09:56,959 --> 00:10:00,320
that processing many many

00:09:58,480 --> 00:10:02,560
thousands of abstracts in a very short

00:10:00,320 --> 00:10:04,560
time is not a trivial challenge

00:10:02,560 --> 00:10:05,920
and i learned some lessons while doing

00:10:04,560 --> 00:10:07,440
this

00:10:05,920 --> 00:10:09,360
after some false starts i settled on

00:10:07,440 --> 00:10:10,160
spacey which is a natural language

00:10:09,360 --> 00:10:12,320
processing

00:10:10,160 --> 00:10:13,200
library in python that has a lot of

00:10:12,320 --> 00:10:15,200
useful models

00:10:13,200 --> 00:10:18,079
and abstractions built in it is also

00:10:15,200 --> 00:10:21,600
helpfully mit licensed which is great

00:10:18,079 --> 00:10:22,720
um my early pre-space attempts

00:10:21,600 --> 00:10:24,480
attempts would not even run to

00:10:22,720 --> 00:10:25,839
completion so when i found spacey and i

00:10:24,480 --> 00:10:27,040
could actually make it through six

00:10:25,839 --> 00:10:28,399
thousand journals with

00:10:27,040 --> 00:10:30,320
of abstracts without crashing my

00:10:28,399 --> 00:10:32,079
computer i was very happy that was a

00:10:30,320 --> 00:10:34,880
good early victory

00:10:32,079 --> 00:10:35,680
um and as a bonus it produces decent

00:10:34,880 --> 00:10:37,279
recommendations

00:10:35,680 --> 00:10:39,519
i was happy with the journals that were

00:10:37,279 --> 00:10:44,000
being surfaced for the most part

00:10:39,519 --> 00:10:47,760
um uh we can talk about that in a second

00:10:44,000 --> 00:10:48,399
so spacey uh has built-in tools that can

00:10:47,760 --> 00:10:50,320
extract

00:10:48,399 --> 00:10:52,079
meaning from a text blob which is kind

00:10:50,320 --> 00:10:53,920
of what i wanted to do here

00:10:52,079 --> 00:10:55,519
um it does a bunch of other things too

00:10:53,920 --> 00:10:57,040
that i'm not going to touch upon

00:10:55,519 --> 00:10:59,279
but one of the things it does is it can

00:10:57,040 --> 00:11:00,560
evaluate text using word vectors

00:10:59,279 --> 00:11:02,480
and you might be like well what are word

00:11:00,560 --> 00:11:03,440
vectors this is one of those points

00:11:02,480 --> 00:11:05,839
where i'm at the limits of my

00:11:03,440 --> 00:11:07,600
understanding so please bear with me

00:11:05,839 --> 00:11:10,480
this tutorial that's linked here by

00:11:07,600 --> 00:11:12,320
alison parrish is super useful

00:11:10,480 --> 00:11:14,480
she does an excellent job explaining

00:11:12,320 --> 00:11:16,079
word vectors and the examples that

00:11:14,480 --> 00:11:18,320
are in the following slides are drawn

00:11:16,079 --> 00:11:19,920
directly from her tutorial

00:11:18,320 --> 00:11:21,360
so i'm going to follow her lead and

00:11:19,920 --> 00:11:23,360
explain word vectors using

00:11:21,360 --> 00:11:25,040
animal vectors as an analogy and you'll

00:11:23,360 --> 00:11:26,880
see what i mean in a second

00:11:25,040 --> 00:11:29,120
i'm going to consider the features of

00:11:26,880 --> 00:11:30,160
animals much in the same way that spacey

00:11:29,120 --> 00:11:32,320
considers the features

00:11:30,160 --> 00:11:34,480
of words so so bear with me while i go

00:11:32,320 --> 00:11:37,279
down this this rabbit hole

00:11:34,480 --> 00:11:38,000
um here are some animals ranked by

00:11:37,279 --> 00:11:39,680
cuteness

00:11:38,000 --> 00:11:41,040
this may seem kind of arbitrary it is

00:11:39,680 --> 00:11:43,600
kind of arbitrary

00:11:41,040 --> 00:11:45,440
these are rankings by alison parrish she

00:11:43,600 --> 00:11:47,040
came up with the scale of one to 100 for

00:11:45,440 --> 00:11:48,880
ranking the cuteness of animals

00:11:47,040 --> 00:11:50,720
and that's like a way you could describe

00:11:48,880 --> 00:11:52,079
animals right like it's a

00:11:50,720 --> 00:11:53,200
thing you could do you could describe

00:11:52,079 --> 00:11:54,480
them in that way and you've captured

00:11:53,200 --> 00:11:57,519
something about them

00:11:54,480 --> 00:11:58,959
with that score you've given them um for

00:11:57,519 --> 00:12:02,399
context there's my dog

00:11:58,959 --> 00:12:03,440
um she is a cuteness reference point

00:12:02,399 --> 00:12:06,160
she's in the other room

00:12:03,440 --> 00:12:06,560
where she's not bothering me right now

00:12:06,160 --> 00:12:08,399
um

00:12:06,560 --> 00:12:09,839
but you could also you could also rank

00:12:08,399 --> 00:12:11,120
animals by size right like this is

00:12:09,839 --> 00:12:12,399
another way you could rank animals

00:12:11,120 --> 00:12:14,480
they're not all the same size

00:12:12,399 --> 00:12:16,000
some are bigger some are smaller you've

00:12:14,480 --> 00:12:17,920
now described these animals

00:12:16,000 --> 00:12:19,600
in two different ways two different

00:12:17,920 --> 00:12:21,360
dimensions and you could

00:12:19,600 --> 00:12:22,800
you could plot that on a two-dimensional

00:12:21,360 --> 00:12:25,279
chart right where

00:12:22,800 --> 00:12:26,480
size is one axis and cuteness is the

00:12:25,279 --> 00:12:28,079
other axis

00:12:26,480 --> 00:12:29,360
and you can see where these animals are

00:12:28,079 --> 00:12:30,800
in that two-dimensional space and you

00:12:29,360 --> 00:12:31,440
can kind of see which ones are near each

00:12:30,800 --> 00:12:32,880
other

00:12:31,440 --> 00:12:35,040
in a way that you really couldn't with

00:12:32,880 --> 00:12:36,880
the table on the previous slide

00:12:35,040 --> 00:12:38,240
so that's kind of interesting right and

00:12:36,880 --> 00:12:38,880
you could imagine a third dimension to

00:12:38,240 --> 00:12:41,279
this chart

00:12:38,880 --> 00:12:43,279
like fluffiness too you could chart it

00:12:41,279 --> 00:12:44,639
with sl size and cuteness and fluffiness

00:12:43,279 --> 00:12:46,240
as the three axes

00:12:44,639 --> 00:12:48,800
and that's kind of easy to imagine in

00:12:46,240 --> 00:12:50,639
your head but harder to show on a slide

00:12:48,800 --> 00:12:52,240
in a slide deck

00:12:50,639 --> 00:12:53,839
you could also do this with like four

00:12:52,240 --> 00:12:55,760
dimensions or five dimensions or

00:12:53,839 --> 00:12:58,079
hundreds of dimensions

00:12:55,760 --> 00:12:59,279
and that's probably impossible for us to

00:12:58,079 --> 00:13:02,000
imagine as humans

00:12:59,279 --> 00:13:03,839
spatially but a computer can do that

00:13:02,000 --> 00:13:04,639
really well and can capture data across

00:13:03,839 --> 00:13:06,959
these animals

00:13:04,639 --> 00:13:08,720
about these animals across many many

00:13:06,959 --> 00:13:10,639
different criteria

00:13:08,720 --> 00:13:12,240
and my point about this is that spacey

00:13:10,639 --> 00:13:14,880
has done this with words

00:13:12,240 --> 00:13:17,440
so it's created models where words are

00:13:14,880 --> 00:13:19,760
vectorized using up to 300 dimensions

00:13:17,440 --> 00:13:20,720
so you're capturing meaning about these

00:13:19,760 --> 00:13:23,200
words across

00:13:20,720 --> 00:13:24,079
300 dimensions which is kind of

00:13:23,200 --> 00:13:26,880
mind-blowing but

00:13:24,079 --> 00:13:28,079
it's it's neat that these models exist

00:13:26,880 --> 00:13:30,320
and you can apply these word

00:13:28,079 --> 00:13:33,279
vectorization

00:13:30,320 --> 00:13:34,399
models to text and save it as a variable

00:13:33,279 --> 00:13:36,000
for example

00:13:34,399 --> 00:13:38,000
then you can compare these vectorized

00:13:36,000 --> 00:13:40,720
objects really easily because

00:13:38,000 --> 00:13:42,399
spacey vectorized objects have a

00:13:40,720 --> 00:13:45,920
built-in similarity method

00:13:42,399 --> 00:13:47,760
that allows you to compare two objects

00:13:45,920 --> 00:13:49,360
so it'll spit out a score on a scale of

00:13:47,760 --> 00:13:51,440
zero to one where zero is like

00:13:49,360 --> 00:13:53,519
these texts are not at all the same and

00:13:51,440 --> 00:13:55,680
one is these texts are identical

00:13:53,519 --> 00:13:57,360
or anywhere in between and it makes it

00:13:55,680 --> 00:13:59,120
easy to compare the similarity of one

00:13:57,360 --> 00:14:01,680
blob of text to another

00:13:59,120 --> 00:14:03,279
so you can loop through a list of

00:14:01,680 --> 00:14:05,600
journals like this and compare them to

00:14:03,279 --> 00:14:08,720
the draft abstract one at a time

00:14:05,600 --> 00:14:10,079
to get similarity scores it's

00:14:08,720 --> 00:14:11,920
time consuming but it's actually

00:14:10,079 --> 00:14:14,839
plausible

00:14:11,920 --> 00:14:16,560
so the positives and negatives of this

00:14:14,839 --> 00:14:18,399
approach

00:14:16,560 --> 00:14:19,760
one positive is that it works that was

00:14:18,399 --> 00:14:22,959
that was a big

00:14:19,760 --> 00:14:24,399
uh win in this project it might surface

00:14:22,959 --> 00:14:26,000
journals that you hadn't considered

00:14:24,399 --> 00:14:27,440
which is really the goal the goal is not

00:14:26,000 --> 00:14:30,959
only to be

00:14:27,440 --> 00:14:32,800
relevant but also to be serendipitous so

00:14:30,959 --> 00:14:34,160
it covers all disciplines because it's

00:14:32,800 --> 00:14:35,440
drawing on the director of open access

00:14:34,160 --> 00:14:37,920
journals and it's fully

00:14:35,440 --> 00:14:39,519
openly licensed the downside of this is

00:14:37,920 --> 00:14:41,920
that like i said before it's not really

00:14:39,519 --> 00:14:44,480
guaranteeing journal quality

00:14:41,920 --> 00:14:45,680
the data set isn't complete there are

00:14:44,480 --> 00:14:47,440
journals that aren't in here because

00:14:45,680 --> 00:14:47,920
they aren't openly licensed there are

00:14:47,440 --> 00:14:49,279
others

00:14:47,920 --> 00:14:51,839
that aren't in here because they don't

00:14:49,279 --> 00:14:53,120
have uh complete metadata

00:14:51,839 --> 00:14:54,639
there are others that aren't in here

00:14:53,120 --> 00:14:56,079
because there aren't in english and my

00:14:54,639 --> 00:14:58,560
recommender only knows how to score

00:14:56,079 --> 00:15:00,399
english language abstracts

00:14:58,560 --> 00:15:02,079
lastly it's a bit slow but i think i

00:15:00,399 --> 00:15:04,000
think

00:15:02,079 --> 00:15:05,440
it's in an okay place right now i'm not

00:15:04,000 --> 00:15:06,000
going to worry about the speed too much

00:15:05,440 --> 00:15:08,399
because

00:15:06,000 --> 00:15:09,600
speeding it up requires compromises and

00:15:08,399 --> 00:15:11,279
i think that

00:15:09,600 --> 00:15:13,600
it's not necessarily a win to speed it

00:15:11,279 --> 00:15:15,040
up

00:15:13,600 --> 00:15:17,360
so the next couple slides i think are

00:15:15,040 --> 00:15:19,199
the most important of the deck

00:15:17,360 --> 00:15:21,839
we need to be thinking critically about

00:15:19,199 --> 00:15:23,199
algorithms and how they work

00:15:21,839 --> 00:15:25,040
i'm leaning on spacey's word

00:15:23,199 --> 00:15:27,680
vectorization and matching algorithm

00:15:25,040 --> 00:15:29,120
so in a sense i'm trusting it and partly

00:15:27,680 --> 00:15:30,720
i'm willing to do this because it gives

00:15:29,120 --> 00:15:33,279
what appear to be

00:15:30,720 --> 00:15:33,759
intuitively good results and this may be

00:15:33,279 --> 00:15:36,079
good

00:15:33,759 --> 00:15:38,560
enough for a work in progress but in

00:15:36,079 --> 00:15:40,160
another sense this is not good enough

00:15:38,560 --> 00:15:42,880
there are ethical blind spots in this

00:15:40,160 --> 00:15:44,959
approach these are the result of my

00:15:42,880 --> 00:15:46,880
relative position of privilege these are

00:15:44,959 --> 00:15:48,959
the result of my limited understanding

00:15:46,880 --> 00:15:50,399
of the spacey internals

00:15:48,959 --> 00:15:52,000
these are the results of me working on

00:15:50,399 --> 00:15:54,480
this project by myself

00:15:52,000 --> 00:15:56,560
so none of us are ethically perfect we

00:15:54,480 --> 00:15:58,320
all make ethical mistakes

00:15:56,560 --> 00:16:00,240
i'm no exception and ethical decision

00:15:58,320 --> 00:16:02,800
making works better with multiple voices

00:16:00,240 --> 00:16:04,399
and diverse voices

00:16:02,800 --> 00:16:06,720
so here's a bibliography to think about

00:16:04,399 --> 00:16:07,920
these questions

00:16:06,720 --> 00:16:09,519
i recommend all of these they're

00:16:07,920 --> 00:16:10,399
excellent if you have more to add to

00:16:09,519 --> 00:16:13,519
this list i would

00:16:10,399 --> 00:16:15,120
certainly be very glad to hear from you

00:16:13,519 --> 00:16:16,800
so i would i would argue that the

00:16:15,120 --> 00:16:19,360
journal recommender is

00:16:16,800 --> 00:16:20,240
ethically incomplete at this point and i

00:16:19,360 --> 00:16:21,600
think that's okay

00:16:20,240 --> 00:16:23,759
and the reason i say that is because i

00:16:21,600 --> 00:16:26,320
don't think we can really aspire to an

00:16:23,759 --> 00:16:27,920
ethic that does not require revision

00:16:26,320 --> 00:16:29,680
and really crucially i think that

00:16:27,920 --> 00:16:31,839
ethical incompleteness is an argument

00:16:29,680 --> 00:16:34,320
for building open systems

00:16:31,839 --> 00:16:35,600
open systems are revisable by anyone so

00:16:34,320 --> 00:16:37,440
they can be improved not only

00:16:35,600 --> 00:16:39,279
technically but ethically

00:16:37,440 --> 00:16:41,120
and when we equip more people with the

00:16:39,279 --> 00:16:42,079
capacity to reach in and work with the

00:16:41,120 --> 00:16:43,680
tools

00:16:42,079 --> 00:16:45,120
we broaden the ethical foundations of

00:16:43,680 --> 00:16:47,040
the project

00:16:45,120 --> 00:16:48,880
so this is worth thinking about in the

00:16:47,040 --> 00:16:51,360
context of our gleim organizations

00:16:48,880 --> 00:16:53,440
because in our glam workplaces we often

00:16:51,360 --> 00:16:55,120
see technical decision making to a small

00:16:53,440 --> 00:16:57,440
number of technologists these are people

00:16:55,120 --> 00:16:59,839
who usually work directly with the tools

00:16:57,440 --> 00:17:01,279
or we trans we allow them to translate

00:16:59,839 --> 00:17:02,079
their technical decisions for the rest

00:17:01,279 --> 00:17:03,839
of us

00:17:02,079 --> 00:17:05,439
but i would argue that this is not the

00:17:03,839 --> 00:17:08,160
best model

00:17:05,439 --> 00:17:09,839
concentrating uh tech the ethics of

00:17:08,160 --> 00:17:11,280
technical decision making in the hands

00:17:09,839 --> 00:17:12,160
of a few people is really not a good

00:17:11,280 --> 00:17:13,839
idea

00:17:12,160 --> 00:17:15,919
and with open systems it doesn't have to

00:17:13,839 --> 00:17:17,679
be this way we

00:17:15,919 --> 00:17:19,919
can encourage everyone in our

00:17:17,679 --> 00:17:21,520
organizations to engage with open tools

00:17:19,919 --> 00:17:23,120
as much as they want as much as their

00:17:21,520 --> 00:17:25,360
comfort level and their interest level

00:17:23,120 --> 00:17:28,000
and their available time allow

00:17:25,360 --> 00:17:29,760
so instead of having translation by only

00:17:28,000 --> 00:17:32,080
a few technologists we can have more

00:17:29,760 --> 00:17:33,760
people reaching in as much as they want

00:17:32,080 --> 00:17:35,600
and when we reach into our technologies

00:17:33,760 --> 00:17:36,880
we can bring back knowledge to share

00:17:35,600 --> 00:17:38,400
there's no danger of running out of

00:17:36,880 --> 00:17:40,400
technical problems to solve there will

00:17:38,400 --> 00:17:43,120
always be more

00:17:40,400 --> 00:17:44,240
that's kind of a given so where this

00:17:43,120 --> 00:17:45,679
project goes from here

00:17:44,240 --> 00:17:47,919
there's a few things i'd like to add to

00:17:45,679 --> 00:17:49,440
it um

00:17:47,919 --> 00:17:51,919
i think multilingual support would be

00:17:49,440 --> 00:17:53,679
really uh clutch

00:17:51,919 --> 00:17:55,440
there's clearly demand for this because

00:17:53,679 --> 00:17:57,760
the journal matcher gets a lot of

00:17:55,440 --> 00:17:59,440
non-english language requests

00:17:57,760 --> 00:18:01,360
uh the problem i'm facing here is that

00:17:59,440 --> 00:18:02,720
the directory of open access journals

00:18:01,360 --> 00:18:04,720
skews heavily towards

00:18:02,720 --> 00:18:06,080
english language publications by like an

00:18:04,720 --> 00:18:07,280
order of magnitude

00:18:06,080 --> 00:18:09,120
so i'm going to try to implement

00:18:07,280 --> 00:18:10,559
multilingual support and we'll see how

00:18:09,120 --> 00:18:12,160
it goes

00:18:10,559 --> 00:18:14,080
i need to make some automated

00:18:12,160 --> 00:18:16,240
maintenance of a lot of the background

00:18:14,080 --> 00:18:18,559
work that goes into this tool because

00:18:16,240 --> 00:18:20,480
it's boring and it could be automated

00:18:18,559 --> 00:18:22,400
but i'm not going to talk about that

00:18:20,480 --> 00:18:24,160
lastly i'm waiting to hear about funding

00:18:22,400 --> 00:18:26,720
for this project from my university's

00:18:24,160 --> 00:18:28,480
research foundation

00:18:26,720 --> 00:18:30,000
i'm hoping that this can spur further

00:18:28,480 --> 00:18:33,039
work on this project because

00:18:30,000 --> 00:18:35,520
development is not free and um

00:18:33,039 --> 00:18:37,440
hopefully hopefully i can get something

00:18:35,520 --> 00:18:40,160
going there

00:18:37,440 --> 00:18:41,360
so i learned a lot about automated

00:18:40,160 --> 00:18:42,880
matching

00:18:41,360 --> 00:18:44,960
i think you need to take a tool like

00:18:42,880 --> 00:18:47,840
this with a grain of salt is my

00:18:44,960 --> 00:18:49,679
conclusion tools like this can make good

00:18:47,840 --> 00:18:50,000
recommendations that may be both good

00:18:49,679 --> 00:18:51,919
and

00:18:50,000 --> 00:18:53,600
unexpected which is really the goal but

00:18:51,919 --> 00:18:54,880
there are trade-offs in building a tool

00:18:53,600 --> 00:18:56,480
like this so you can't

00:18:54,880 --> 00:18:58,559
really have everything you want in a

00:18:56,480 --> 00:18:59,360
matcher tool those other tools that i

00:18:58,559 --> 00:19:00,799
showed earlier

00:18:59,360 --> 00:19:02,240
i guarantee that they also have

00:19:00,799 --> 00:19:03,280
compromises and trade-offs that they

00:19:02,240 --> 00:19:04,640
made while they were

00:19:03,280 --> 00:19:06,960
the the builders made while they were

00:19:04,640 --> 00:19:10,720
making them i've done my best

00:19:06,960 --> 00:19:13,440
to make what i think is a useful tool

00:19:10,720 --> 00:19:14,080
so lastly i want to say thank you i

00:19:13,440 --> 00:19:15,840
think there's

00:19:14,080 --> 00:19:17,360
value in librarians and glam

00:19:15,840 --> 00:19:19,200
professionals writing code

00:19:17,360 --> 00:19:20,799
we're positioned at the confluence of a

00:19:19,200 --> 00:19:22,400
lot of information tools

00:19:20,799 --> 00:19:24,080
and there are valuable opportunities for

00:19:22,400 --> 00:19:25,919
us to contribute here so

00:19:24,080 --> 00:19:27,520
we can really build the open source

00:19:25,919 --> 00:19:28,960
information landscape we want to see

00:19:27,520 --> 00:19:31,440
and we can broaden the perceptions of

00:19:28,960 --> 00:19:34,720
what a glam organization can do

00:19:31,440 --> 00:19:34,720
and that's it thank you

00:19:36,400 --> 00:19:40,160
well mark thank you so much i can

00:19:38,720 --> 00:19:42,640
already hear the excited

00:19:40,160 --> 00:19:44,240
uh liaison librarians just you know

00:19:42,640 --> 00:19:44,799
minds exploding with what you've brought

00:19:44,240 --> 00:19:46,720
here

00:19:44,799 --> 00:19:48,000
um but i think too those issues around

00:19:46,720 --> 00:19:49,760
the ethics and and

00:19:48,000 --> 00:19:51,919
um you know positioning our own

00:19:49,760 --> 00:19:53,360
privilege um are incredibly important

00:19:51,919 --> 00:19:54,880
and i can see in the chat

00:19:53,360 --> 00:19:56,720
that people have been really discussing

00:19:54,880 --> 00:19:57,919
that so what i'm going to do is let you

00:19:56,720 --> 00:20:00,960
jump off

00:19:57,919 --> 00:20:04,000
so mark is going to jump into our

00:20:00,960 --> 00:20:04,880
q a stream um so we'll have 10 minutes

00:20:04,000 --> 00:20:07,200
there and then

00:20:04,880 --> 00:20:08,880
we'll bring you all back in for our next

00:20:07,200 --> 00:20:11,760
speaker hugh rundle

00:20:08,880 --> 00:20:21,840
who will be presenting at 12 10. thanks

00:20:11,760 --> 00:20:21,840

YouTube URL: https://www.youtube.com/watch?v=FoxKnnzgLiQ


