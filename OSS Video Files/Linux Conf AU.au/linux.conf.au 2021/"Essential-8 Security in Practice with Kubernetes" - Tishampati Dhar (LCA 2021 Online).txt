Title: "Essential-8 Security in Practice with Kubernetes" - Tishampati Dhar (LCA 2021 Online)
Publication date: 2021-01-31
Playlist: linux.conf.au 2021
Description: 
	Tishampati Dhar

https://lca2021.linux.org.au/schedule/presentation/38/

The Digital Earth Australia and Digital Earth Africa programs host and process very large volumes of open data on cloud infrastructure using primarily Kubernetes as an orchestration mechanism. The project is run out of an Australian government agency, Geoscience Australia, and as such, this infrastructure needs to meet the [Essential-8](https://www.cyber.gov.au/acsc/view-all-content/essential-eight/essential-eight-explained) security mitigation requirements.

This talk presents the difficult balancing act of meeting the security needs of an openaccess, open data and open source platform. The principal workloads on this infrastructure include web applications, petabyte scale data processing and cross-continent data movement. Part of this platform enables scientific experimentation, which essentially allows arbitrary code execution too. Recent statistical operations on year-long continental Satellite imagery time-series for Africa consumed 4,000 CPUs and 50 TiB of RAM across 200 nodes.

The infrastructure is mostly codified and open sourced [here](https://github.com/opendatacube/datacube-k8s-eks) as terraform modules. Applications are deployed via [Helm Charts](https://github.com/opendatacube/datacube-charts) and scanned using [Trivy](https://github.com/aquasecurity/trivy). The network within the cluster and to the outside is filtered using [Cilium](https://cilium.io/). Deployments are automated and audit-logged via GitOps and [Flux](https://github.com/fluxcd/flux).
The ability for users to self-signup and run arbitrary code occasionally leads to some cycles being lost to Monero. This talk will cover general security principles as well as specific security incidents and mitigation actions taken in response.

In conclusion, our stack meets Australian Government security practice, while enabling very large workloads to be executed in a flexible, on-demand computation environment that empowers scientific users. This talk will tell you how we do it.

linux.conf.au is a conference about the Linux operating system, and all aspects of the thriving ecosystem of Free and Open Source Software that has grown up around it. Run since 1999, in a different Australian or New Zealand city each year, by a team of local volunteers, LCA invites more than 500 people to learn from the people who shape the future of Open Source. For more information on the conference see https://linux.conf.au/

Produced by Next Day Video Australia: https://nextdayvideo.com.au

#linux.conf.au #linux #foss #opensource

Sun Jan 24 10:45:00 2021 at Pia Andrews Conservatory
Captions: 
	00:00:10,820 --> 00:00:14,060
[Music]

00:00:15,280 --> 00:00:19,520
speaker is

00:00:16,320 --> 00:00:21,279
tish tisch works at geoscience australia

00:00:19,520 --> 00:00:22,320
with the digital earth australia and

00:00:21,279 --> 00:00:24,880
digital earth

00:00:22,320 --> 00:00:27,119
africa projects cheshire's got a great

00:00:24,880 --> 00:00:30,240
talk today he's going to tell us about

00:00:27,119 --> 00:00:33,200
how they balance open access to data and

00:00:30,240 --> 00:00:34,480
the security of that data while the

00:00:33,200 --> 00:00:37,600
amount of data

00:00:34,480 --> 00:00:39,600
is absolutely enormous please

00:00:37,600 --> 00:00:40,879
make tish welcome with all of your

00:00:39,600 --> 00:00:42,960
digital clicks

00:00:40,879 --> 00:00:45,520
now teachers told me that at the end of

00:00:42,960 --> 00:00:46,160
the talk he is open to taking some

00:00:45,520 --> 00:00:48,480
questions

00:00:46,160 --> 00:00:50,079
on the live stream so if you've got

00:00:48,480 --> 00:00:52,320
questions during the talk

00:00:50,079 --> 00:00:54,160
then just type them into the chat and

00:00:52,320 --> 00:00:54,719
one of our other volunteers will pass

00:00:54,160 --> 00:00:57,760
them

00:00:54,719 --> 00:00:59,520
up to us i'm going to hand over to tisch

00:00:57,760 --> 00:01:02,559
now

00:00:59,520 --> 00:01:04,799
thanks um hi uh the

00:01:02,559 --> 00:01:06,799
virtual conference experience has this

00:01:04,799 --> 00:01:07,040
curtain raising thing and i just jump in

00:01:06,799 --> 00:01:09,600
and

00:01:07,040 --> 00:01:10,479
talk it's great to get audience energy

00:01:09,600 --> 00:01:14,720
which in

00:01:10,479 --> 00:01:18,000
life conference but will be i'll make do

00:01:14,720 --> 00:01:18,720
so uh so i work at uh at geoscience

00:01:18,000 --> 00:01:20,960
australia

00:01:18,720 --> 00:01:23,280
i've been work using kubernetes since

00:01:20,960 --> 00:01:26,720
around 2018-19

00:01:23,280 --> 00:01:28,159
particularly using the aks platform

00:01:26,720 --> 00:01:31,360
managed

00:01:28,159 --> 00:01:32,479
i have started using it doing logistics

00:01:31,360 --> 00:01:35,520
in africa

00:01:32,479 --> 00:01:37,759
we used to have jokes about shipping

00:01:35,520 --> 00:01:39,759
containers using containers running

00:01:37,759 --> 00:01:40,960
in data centers and containers but

00:01:39,759 --> 00:01:42,799
anyway uh

00:01:40,960 --> 00:01:44,159
i continued the practice in geoscopes in

00:01:42,799 --> 00:01:47,759
australia when i joined

00:01:44,159 --> 00:01:49,360
late 2019 still using class i started as

00:01:47,759 --> 00:01:51,840
a cloud engineer

00:01:49,360 --> 00:01:53,119
and currently i lead a small team of

00:01:51,840 --> 00:01:56,640
cloud engineers

00:01:53,119 --> 00:01:59,520
sres devops as an assistant director

00:01:56,640 --> 00:02:01,600
uh sort of a freshly minted engineering

00:01:59,520 --> 00:02:04,719
manager sort of function

00:02:01,600 --> 00:02:08,080
um yeah so the

00:02:04,719 --> 00:02:12,560
the team does our extraordinary work

00:02:08,080 --> 00:02:12,560
shipping new things and as well as

00:02:13,040 --> 00:02:19,680
maintaining security of the platform so

00:02:16,560 --> 00:02:21,920
we sort of practice

00:02:19,680 --> 00:02:24,959
the reverse of security as obscurity

00:02:21,920 --> 00:02:27,120
security with excessive transparency so

00:02:24,959 --> 00:02:28,720
the brief introduction to digital earth

00:02:27,120 --> 00:02:30,879
australia and africa

00:02:28,720 --> 00:02:32,720
uh the australia part mostly in this

00:02:30,879 --> 00:02:33,440
slide i got this slide from my colleague

00:02:32,720 --> 00:02:35,040
alex

00:02:33,440 --> 00:02:37,120
who has done this present similar

00:02:35,040 --> 00:02:40,400
presentations before

00:02:37,120 --> 00:02:42,480
australia used to download landsat and

00:02:40,400 --> 00:02:45,440
data was stored in tapes

00:02:42,480 --> 00:02:47,040
uh satellite data satellites actually

00:02:45,440 --> 00:02:47,920
have tape recorders on them they

00:02:47,040 --> 00:02:50,080
actually

00:02:47,920 --> 00:02:50,959
linearly have headers and trailers and

00:02:50,080 --> 00:02:53,360
so on

00:02:50,959 --> 00:02:54,080
eventually the data was digitized and

00:02:53,360 --> 00:02:56,400
making a

00:02:54,080 --> 00:02:58,319
30 years of landsat archive available

00:02:56,400 --> 00:03:00,560
for 40 years

00:02:58,319 --> 00:03:01,920
it was usually called digestants

00:03:00,560 --> 00:03:04,319
australia data cube

00:03:01,920 --> 00:03:06,000
httc but now it's called the open data

00:03:04,319 --> 00:03:08,400
cube new improved

00:03:06,000 --> 00:03:10,640
it's like a suit of open source projects

00:03:08,400 --> 00:03:12,720
we call the open data cube

00:03:10,640 --> 00:03:14,000
its function is to support government

00:03:12,720 --> 00:03:16,319
and industry

00:03:14,000 --> 00:03:17,519
making earth observation eo data

00:03:16,319 --> 00:03:21,040
available

00:03:17,519 --> 00:03:22,319
accessible usable in python and other

00:03:21,040 --> 00:03:26,159
languages

00:03:22,319 --> 00:03:29,760
hosted in a nice format in the cloud

00:03:26,159 --> 00:03:32,400
the similar program is being

00:03:29,760 --> 00:03:35,599
established in africa hence the digital

00:03:32,400 --> 00:03:37,519
earth slash digital earth africa

00:03:35,599 --> 00:03:40,319
responsibilities that i carry and my

00:03:37,519 --> 00:03:43,360
team carries

00:03:40,319 --> 00:03:46,080
so how do we use kubernetes so

00:03:43,360 --> 00:03:48,879
kubernetes is a new fangled and everyone

00:03:46,080 --> 00:03:51,040
even a startup with one one user is

00:03:48,879 --> 00:03:54,640
trying to use kubernetes we don't

00:03:51,040 --> 00:03:58,879
um so you run multiple web applications

00:03:54,640 --> 00:04:02,560
we for people who do gis image serving

00:03:58,879 --> 00:04:04,080
ows which has wms wmts protocol serving

00:04:02,560 --> 00:04:07,280
jpegs and pngs

00:04:04,080 --> 00:04:09,040
from the satellite imagery uh we have

00:04:07,280 --> 00:04:10,480
explorer which is sort of used to be

00:04:09,040 --> 00:04:13,599
called dashboard it's

00:04:10,480 --> 00:04:15,840
like a bi business intelligence tool to

00:04:13,599 --> 00:04:18,720
show what data we have

00:04:15,840 --> 00:04:19,919
uh where which days data is missing or

00:04:18,720 --> 00:04:23,680
something is happening

00:04:19,919 --> 00:04:26,880
it sort of does a geospatial temporal

00:04:23,680 --> 00:04:28,800
catalog viewer sort of thing of what the

00:04:26,880 --> 00:04:31,280
data holdings are

00:04:28,800 --> 00:04:33,120
uh i have like hyperlinks in this slides

00:04:31,280 --> 00:04:35,440
and i will share these slides after on

00:04:33,120 --> 00:04:38,880
twitter most likely uh

00:04:35,440 --> 00:04:41,199
to have the links to all these projects

00:04:38,880 --> 00:04:42,639
we have some sort of batch processing

00:04:41,199 --> 00:04:45,199
workloads some of them

00:04:42,639 --> 00:04:45,840
uh give them funny names coming up with

00:04:45,199 --> 00:04:48,320
names is

00:04:45,840 --> 00:04:49,520
fun uh alchemist which sort of

00:04:48,320 --> 00:04:51,680
transmutes data

00:04:49,520 --> 00:04:53,680
singing to scene statistician which

00:04:51,680 --> 00:04:55,840
squashes over time

00:04:53,680 --> 00:04:57,280
uh does product summaries then

00:04:55,840 --> 00:04:59,360
classification which are essentially

00:04:57,280 --> 00:05:01,120
machine learning classifiers

00:04:59,360 --> 00:05:03,360
various different classifiers a new one

00:05:01,120 --> 00:05:05,919
is being developed for crop masking in

00:05:03,360 --> 00:05:06,720
africa and we have another sort of

00:05:05,919 --> 00:05:09,280
workload

00:05:06,720 --> 00:05:10,479
where we have ephemeral user port

00:05:09,280 --> 00:05:12,960
containers

00:05:10,479 --> 00:05:15,039
with python environment management is a

00:05:12,960 --> 00:05:17,440
mess it's difficult

00:05:15,039 --> 00:05:19,759
lots of compile libraries in our case as

00:05:17,440 --> 00:05:22,240
well for geospatial processing

00:05:19,759 --> 00:05:24,080
and creating a stable set of libraries

00:05:22,240 --> 00:05:26,000
is hard so we make a container

00:05:24,080 --> 00:05:27,280
available with the libraries that are

00:05:26,000 --> 00:05:30,080
typically used

00:05:27,280 --> 00:05:30,800
attached to the data and then you you

00:05:30,080 --> 00:05:33,120
ship your

00:05:30,800 --> 00:05:35,280
code or experimental code to the data

00:05:33,120 --> 00:05:36,960
instead of downloading the

00:05:35,280 --> 00:05:40,240
petabytes of data to learn your

00:05:36,960 --> 00:05:40,240
satellite dimensional analysis

00:05:40,720 --> 00:05:44,960
how we deploy kubernetes we deploy

00:05:43,600 --> 00:05:48,240
kubernetes using

00:05:44,960 --> 00:05:51,600
a multi-layered terraform stack

00:05:48,240 --> 00:05:54,800
basically all the parts our

00:05:51,600 --> 00:05:56,880
implementation needs to get brought up

00:05:54,800 --> 00:05:58,560
the choice of terraform is interesting

00:05:56,880 --> 00:06:01,440
as opposed to a vendor

00:05:58,560 --> 00:06:03,759
cloud vendor tool because we aim to be

00:06:01,440 --> 00:06:06,240
sort of agnostic to the cloud provider

00:06:03,759 --> 00:06:07,120
all you need is sort of kubernetes and a

00:06:06,240 --> 00:06:10,560
stateful

00:06:07,120 --> 00:06:14,400
database and sort of a blob store

00:06:10,560 --> 00:06:15,520
to run the stack the modules have been

00:06:14,400 --> 00:06:17,520
open sourced

00:06:15,520 --> 00:06:19,120
using apache2 license you can if you

00:06:17,520 --> 00:06:21,039
follow that hyperlink there you'll get

00:06:19,120 --> 00:06:24,080
to the stack

00:06:21,039 --> 00:06:27,199
and then we have a few

00:06:24,080 --> 00:06:28,000
modules in our terraform which we sort

00:06:27,199 --> 00:06:31,360
of

00:06:28,000 --> 00:06:32,479
overlay and run specific patterns we

00:06:31,360 --> 00:06:35,520
have maybe we'll

00:06:32,479 --> 00:06:39,199
open them up as this pattern gets better

00:06:35,520 --> 00:06:42,560
documented and used by others as well

00:06:39,199 --> 00:06:44,639
so it's everything is about graphs and

00:06:42,560 --> 00:06:46,800
when i'm in electronics engineering

00:06:44,639 --> 00:06:49,199
training so i used to draw schematics

00:06:46,800 --> 00:06:52,000
and stuff i sort of drifted into

00:06:49,199 --> 00:06:52,880
satellite imagery processing late in my

00:06:52,000 --> 00:06:55,759
uh

00:06:52,880 --> 00:06:57,520
undergraduate degree i used to work for

00:06:55,759 --> 00:06:59,680
a small company in adelaide which did

00:06:57,520 --> 00:07:02,000
satellite imagery and then did my thesis

00:06:59,680 --> 00:07:04,080
on similar stuff but uh

00:07:02,000 --> 00:07:06,400
anyway i'm gonna choose engineer how to

00:07:04,080 --> 00:07:09,680
interpret diagrams and schematics and

00:07:06,400 --> 00:07:12,720
pcbs but i said i tried to adopt a

00:07:09,680 --> 00:07:15,199
diagramming tool for our terraform

00:07:12,720 --> 00:07:17,199
uh called blast radius and this is sort

00:07:15,199 --> 00:07:19,919
of the diagram it produces

00:07:17,199 --> 00:07:22,479
for a and not our stack but a cloud per

00:07:19,919 --> 00:07:25,599
se awsc

00:07:22,479 --> 00:07:27,520
sort of terraform stack and you can see

00:07:25,599 --> 00:07:29,199
so many components

00:07:27,520 --> 00:07:31,919
in that in the thing it's a huge

00:07:29,199 --> 00:07:35,520
sprawling spider web everywhere

00:07:31,919 --> 00:07:37,520
uh so it's difficult to communicate

00:07:35,520 --> 00:07:39,680
all the parts and secure all the parts

00:07:37,520 --> 00:07:42,479
ensure that

00:07:39,680 --> 00:07:44,240
everything has less privilege and

00:07:42,479 --> 00:07:45,840
terraform itself needs to be given

00:07:44,240 --> 00:07:48,319
high level access we'll talk about that

00:07:45,840 --> 00:07:48,319
a little bit

00:07:48,479 --> 00:07:53,039
so how we manage workloads on kubernetes

00:07:51,280 --> 00:07:55,039
which apps get deployed and which is

00:07:53,039 --> 00:07:57,360
sort of part of the requirements here

00:07:55,039 --> 00:07:58,319
is uh we use githubs with a tool called

00:07:57,360 --> 00:08:01,440
flux

00:07:58,319 --> 00:08:02,639
which keeps a particular folder in a

00:08:01,440 --> 00:08:05,680
particular branch

00:08:02,639 --> 00:08:07,599
of git in sync with the cluster

00:08:05,680 --> 00:08:09,520
so we apply home chart values and

00:08:07,599 --> 00:08:13,039
kubernetes manifests in a

00:08:09,520 --> 00:08:14,960
private git the devops team can push

00:08:13,039 --> 00:08:17,680
directly to the development cluster by

00:08:14,960 --> 00:08:19,919
pushing to the gate rather than

00:08:17,680 --> 00:08:23,360
performing kukkoto apply

00:08:19,919 --> 00:08:26,400
uh and then they we can sort of

00:08:23,360 --> 00:08:27,840
go to a production cluster by doing a pr

00:08:26,400 --> 00:08:30,479
to a master

00:08:27,840 --> 00:08:32,159
and we typically ship from development

00:08:30,479 --> 00:08:33,120
something we have tested in development

00:08:32,159 --> 00:08:36,240
to master by

00:08:33,120 --> 00:08:38,479
cherry picking the changes we want

00:08:36,240 --> 00:08:39,599
so if they're unhappy or open to

00:08:38,479 --> 00:08:42,479
suggestions

00:08:39,599 --> 00:08:43,919
after this hit me up if you have any

00:08:42,479 --> 00:08:47,040
ideas about a better

00:08:43,919 --> 00:08:48,080
kit like workflow for managing multiple

00:08:47,040 --> 00:08:51,279
clusters and

00:08:48,080 --> 00:08:52,800
separating dev staging prod i currently

00:08:51,279 --> 00:08:54,560
they just keep multiplying these

00:08:52,800 --> 00:08:58,320
clusters so we currently

00:08:54,560 --> 00:09:02,000
manage around six or seven clusters in

00:08:58,320 --> 00:09:04,320
sydney cape town oregon

00:09:02,000 --> 00:09:08,480
yeah due to the different workloads and

00:09:04,320 --> 00:09:10,880
data locality in the different regions

00:09:08,480 --> 00:09:11,839
uh this is sort of our doodle i drew one

00:09:10,880 --> 00:09:14,720
friday

00:09:11,839 --> 00:09:16,480
afternoon to sort of communicate how the

00:09:14,720 --> 00:09:18,640
github stuff looks like

00:09:16,480 --> 00:09:19,920
the little slashes you seen there for

00:09:18,640 --> 00:09:22,560
the different

00:09:19,920 --> 00:09:24,240
solution provider for the same function

00:09:22,560 --> 00:09:25,200
so we have a bunch of good hub reports

00:09:24,240 --> 00:09:27,360
where all our

00:09:25,200 --> 00:09:29,200
open source staff sets we have a bunch

00:09:27,360 --> 00:09:30,880
of big bucket repositories where our

00:09:29,200 --> 00:09:32,560
private stuff sets

00:09:30,880 --> 00:09:34,800
we have a bunch of docker hub

00:09:32,560 --> 00:09:36,080
repositories and then recently we have

00:09:34,800 --> 00:09:38,959
just started using

00:09:36,080 --> 00:09:40,399
ecr a lot more since the docker hub red

00:09:38,959 --> 00:09:44,000
limits came in

00:09:40,399 --> 00:09:44,720
to have our container images and then we

00:09:44,000 --> 00:09:46,640
have the

00:09:44,720 --> 00:09:48,640
flux agent in the kubernetes cluster

00:09:46,640 --> 00:09:51,120
keeping everything in sync

00:09:48,640 --> 00:09:53,040
and we just push push out all of the

00:09:51,120 --> 00:09:54,560
different kubernetes constructs to their

00:09:53,040 --> 00:09:57,519
clusters

00:09:54,560 --> 00:10:00,880
pcs jobs whatever it needs to be for

00:09:57,519 --> 00:10:03,519
getting knowledge of work done

00:10:00,880 --> 00:10:04,320
so coming down to what this talk is

00:10:03,519 --> 00:10:08,560
about

00:10:04,320 --> 00:10:11,680
the essential 8 maturity model is like a

00:10:08,560 --> 00:10:12,959
if the talk is sort of a square peg

00:10:11,680 --> 00:10:16,640
round whole talk or

00:10:12,959 --> 00:10:18,320
i was saying uh octagonal peg heptagonal

00:10:16,640 --> 00:10:21,600
whole talk

00:10:18,320 --> 00:10:24,160
of trying to fit this list of maturity

00:10:21,600 --> 00:10:26,000
model security framework the australian

00:10:24,160 --> 00:10:29,279
government has

00:10:26,000 --> 00:10:31,519
to uh how we actually do it so this

00:10:29,279 --> 00:10:33,600
needs a bit of maintenance so that the

00:10:31,519 --> 00:10:34,160
version that uh this stock is built on

00:10:33,600 --> 00:10:37,040
is the

00:10:34,160 --> 00:10:37,760
linux version of the essential eight so

00:10:37,040 --> 00:10:40,720
you will see

00:10:37,760 --> 00:10:42,079
bits and pieces of that in along in my

00:10:40,720 --> 00:10:44,079
top

00:10:42,079 --> 00:10:45,839
this stock could have been eight slides

00:10:44,079 --> 00:10:46,160
because it's above eight things but i've

00:10:45,839 --> 00:10:48,880
like

00:10:46,160 --> 00:10:51,839
padded it out a bit so it's more than

00:10:48,880 --> 00:10:55,440
eight minutes which is where we are now

00:10:51,839 --> 00:10:57,040
uh so uh i've tried to create this sort

00:10:55,440 --> 00:11:00,160
of uh

00:10:57,040 --> 00:11:01,040
satellite imagery specific slides where

00:11:00,160 --> 00:11:04,160
i could to

00:11:01,040 --> 00:11:06,480
conceptualize i think so this is an isa

00:11:04,160 --> 00:11:08,079
control center for running lots and lots

00:11:06,480 --> 00:11:10,240
of satellites you can see reception

00:11:08,079 --> 00:11:12,480
stations where the satellite is

00:11:10,240 --> 00:11:13,680
and satellite footprints and telemetry

00:11:12,480 --> 00:11:15,600
and this

00:11:13,680 --> 00:11:17,120
so this sort of one of the first

00:11:15,600 --> 00:11:20,640
requirements of

00:11:17,120 --> 00:11:22,720
this checklist is application control

00:11:20,640 --> 00:11:23,920
so you know which applications have been

00:11:22,720 --> 00:11:25,839
deployed

00:11:23,920 --> 00:11:27,440
there's a finite sort of white list of

00:11:25,839 --> 00:11:30,640
them

00:11:27,440 --> 00:11:32,240
and then you will basically keep them in

00:11:30,640 --> 00:11:34,320
check

00:11:32,240 --> 00:11:35,279
look at their behavior at runtime and

00:11:34,320 --> 00:11:37,120
also

00:11:35,279 --> 00:11:39,360
make sure they are secure when you put

00:11:37,120 --> 00:11:41,600
them in

00:11:39,360 --> 00:11:43,839
so all of our applications as we are

00:11:41,600 --> 00:11:47,120
infinities are containerized

00:11:43,839 --> 00:11:50,880
uh we maintain them as i said mostly

00:11:47,120 --> 00:11:54,480
in guitars in production so we do

00:11:50,880 --> 00:11:55,279
do apply for experimental things in the

00:11:54,480 --> 00:11:57,680
staging

00:11:55,279 --> 00:11:58,639
environment even and i've started sort

00:11:57,680 --> 00:12:01,680
of a practice

00:11:58,639 --> 00:12:05,200
in development to use mini cube

00:12:01,680 --> 00:12:07,279
and local stack for sort of

00:12:05,200 --> 00:12:08,800
emulating a cloud environment and

00:12:07,279 --> 00:12:11,680
developing in there

00:12:08,800 --> 00:12:14,320
it's not fully shippable or documented

00:12:11,680 --> 00:12:17,040
yet how that will work

00:12:14,320 --> 00:12:19,600
yeah so yes everything is configured is

00:12:17,040 --> 00:12:20,240
version controlled and we have that duty

00:12:19,600 --> 00:12:23,040
which is sort of

00:12:20,240 --> 00:12:24,959
looks after the nodes the traffic at the

00:12:23,040 --> 00:12:27,200
nodes for malicious usage so

00:12:24,959 --> 00:12:28,320
it has got a few things for us

00:12:27,200 --> 00:12:30,959
occasionally

00:12:28,320 --> 00:12:32,000
because we don't have 100 control over

00:12:30,959 --> 00:12:33,920
the applications

00:12:32,000 --> 00:12:34,760
actual code that runs i'll talk about

00:12:33,920 --> 00:12:36,079
that

00:12:34,760 --> 00:12:39,440
[Music]

00:12:36,079 --> 00:12:41,600
so this is a sample application using uh

00:12:39,440 --> 00:12:43,760
katus lens one of my colleagues did a

00:12:41,600 --> 00:12:46,959
screenshot for me for this presentation

00:12:43,760 --> 00:12:50,320
uh the thanks damian uh so

00:12:46,959 --> 00:12:52,560
the airflow is a

00:12:50,320 --> 00:12:53,680
chronon steroid sort of thing we use in

00:12:52,560 --> 00:12:55,920
our

00:12:53,680 --> 00:12:57,920
processing as our processing management

00:12:55,920 --> 00:12:59,680
to workflow management tool

00:12:57,920 --> 00:13:01,040
it has lots of different moving parts it

00:12:59,680 --> 00:13:02,639
has a web ui

00:13:01,040 --> 00:13:04,880
where you can see your processes

00:13:02,639 --> 00:13:08,800
graphically it has got

00:13:04,880 --> 00:13:12,720
workers it has got reddish it has got

00:13:08,800 --> 00:13:14,399
a sort of a scheduler it has got lots of

00:13:12,720 --> 00:13:16,079
different moving parts and

00:13:14,399 --> 00:13:18,000
that's sort of what an application

00:13:16,079 --> 00:13:18,800
typically with lots of services in it in

00:13:18,000 --> 00:13:21,600
kubernetes

00:13:18,800 --> 00:13:23,279
ends up looking like and then in this

00:13:21,600 --> 00:13:25,040
particular name space so this is the

00:13:23,279 --> 00:13:27,120
contents of a particular namespace we

00:13:25,040 --> 00:13:30,240
call processing

00:13:27,120 --> 00:13:31,600
we don't have separate clusters per type

00:13:30,240 --> 00:13:33,440
of workload yet maybe

00:13:31,600 --> 00:13:35,680
we'll do that then instead of having six

00:13:33,440 --> 00:13:36,880
clusters we'll have 18 clusters but not

00:13:35,680 --> 00:13:39,440
there yet

00:13:36,880 --> 00:13:41,760
uh but yeah so that's sort of typically

00:13:39,440 --> 00:13:45,519
what an application with its sub

00:13:41,760 --> 00:13:48,560
services looks like to us

00:13:45,519 --> 00:13:51,120
so this one is a

00:13:48,560 --> 00:13:52,959
patchwork of fields using a particular

00:13:51,120 --> 00:13:54,079
landsat 8 product we call that your

00:13:52,959 --> 00:13:55,920
median we'll talk more about the

00:13:54,079 --> 00:13:59,120
geometry and it has been

00:13:55,920 --> 00:14:01,040
the topical thing for the recent few

00:13:59,120 --> 00:14:02,639
few months or six months now it's

00:14:01,040 --> 00:14:04,240
difficult to do this

00:14:02,639 --> 00:14:06,079
complex methods okay we'll talk about

00:14:04,240 --> 00:14:08,720
that uh so this is uh

00:14:06,079 --> 00:14:10,959
it's obviously considered patching so we

00:14:08,720 --> 00:14:12,320
try to have to patch everything as much

00:14:10,959 --> 00:14:15,040
often as possible

00:14:12,320 --> 00:14:16,320
it's a never-ending battle to patch the

00:14:15,040 --> 00:14:18,240
container libraries

00:14:16,320 --> 00:14:19,839
system libraries python libraries which

00:14:18,240 --> 00:14:23,360
is mostly what we use

00:14:19,839 --> 00:14:24,320
for our development all of the open data

00:14:23,360 --> 00:14:27,360
cube project

00:14:24,320 --> 00:14:29,839
is mostly python

00:14:27,360 --> 00:14:31,600
as like a lot of the modern data science

00:14:29,839 --> 00:14:35,040
stuff is there's a lot of cec

00:14:31,600 --> 00:14:36,800
plus plus fortran underneath the iceberg

00:14:35,040 --> 00:14:38,560
that there were the top layers where

00:14:36,800 --> 00:14:40,240
people are most productive is usually

00:14:38,560 --> 00:14:42,160
python that's like a recurring thing

00:14:40,240 --> 00:14:44,320
with python

00:14:42,160 --> 00:14:46,399
i myself started using python during my

00:14:44,320 --> 00:14:47,360
phd when i couldn't manage my math lab

00:14:46,399 --> 00:14:50,000
licenses

00:14:47,360 --> 00:14:51,920
anymore and took much annoyance of my

00:14:50,000 --> 00:14:54,800
supervisor i was like yeah i'm just

00:14:51,920 --> 00:14:56,800
going to do all of my stuff in python

00:14:54,800 --> 00:14:59,680
so anyway so a lot of the satellite

00:14:56,800 --> 00:15:01,680
imagery processing is done in python

00:14:59,680 --> 00:15:03,199
and then we also have javascript

00:15:01,680 --> 00:15:06,560
libraries in our containers

00:15:03,199 --> 00:15:09,040
mostly for jupyter uh hub

00:15:06,560 --> 00:15:10,880
sort of stuff where you have the ide in

00:15:09,040 --> 00:15:11,440
jupiter hub running in the foreground

00:15:10,880 --> 00:15:14,160
and

00:15:11,440 --> 00:15:16,800
lowdash and vega and all these libraries

00:15:14,160 --> 00:15:18,720
keep on bringing things

00:15:16,800 --> 00:15:20,880
we try to patch them as soon as possible

00:15:18,720 --> 00:15:22,720
so you can i think we have a two

00:15:20,880 --> 00:15:25,440
week time window we try to patch within

00:15:22,720 --> 00:15:26,800
so this is one of the container images

00:15:25,440 --> 00:15:28,800
so as i was saying

00:15:26,800 --> 00:15:30,000
we had excessive transparency all of our

00:15:28,800 --> 00:15:31,759
containers

00:15:30,000 --> 00:15:34,000
are built on github and public

00:15:31,759 --> 00:15:36,000
repositories and then

00:15:34,000 --> 00:15:38,320
github actions pushed them into docker

00:15:36,000 --> 00:15:39,680
hub and then we synchronized from docker

00:15:38,320 --> 00:15:43,759
hub

00:15:39,680 --> 00:15:46,959
uh lambda into our ecr

00:15:43,759 --> 00:15:49,519
so my colleague mike wrought

00:15:46,959 --> 00:15:51,680
a sort of a github action to scan all

00:15:49,519 --> 00:15:54,320
the containers using trivi

00:15:51,680 --> 00:15:55,920
he sort of looks after the security side

00:15:54,320 --> 00:15:59,279
specifically

00:15:55,920 --> 00:16:01,040
and it can you can log now in github

00:15:59,279 --> 00:16:03,680
it's a new security tab where you can

00:16:01,040 --> 00:16:05,279
see any cvs that have popped up in your

00:16:03,680 --> 00:16:08,320
container scan results

00:16:05,279 --> 00:16:08,880
it's pretty cool you can see libsy

00:16:08,320 --> 00:16:11,279
things

00:16:08,880 --> 00:16:13,279
you can see stuff around any and guys

00:16:11,279 --> 00:16:16,320
the javascript one so

00:16:13,279 --> 00:16:19,040
all sorts of fun there

00:16:16,320 --> 00:16:19,680
this particular image is not a satellite

00:16:19,040 --> 00:16:22,720
image

00:16:19,680 --> 00:16:25,519
and that sort of stands to

00:16:22,720 --> 00:16:26,160
like demonstrate this part of essential

00:16:25,519 --> 00:16:29,440
aid being

00:16:26,160 --> 00:16:31,040
difficult to map to uh what we do in

00:16:29,440 --> 00:16:33,360
practice

00:16:31,040 --> 00:16:34,560
so there's a macro image you know people

00:16:33,360 --> 00:16:37,839
who do photography it's like

00:16:34,560 --> 00:16:40,720
zoomed in high high detail of a small

00:16:37,839 --> 00:16:43,279
object and obviously it's about macros

00:16:40,720 --> 00:16:46,720
so one of the points in the essential 8

00:16:43,279 --> 00:16:49,040
list checklist is you thou shall not

00:16:46,720 --> 00:16:52,800
have macros

00:16:49,040 --> 00:16:54,320
so that we don't really have anything in

00:16:52,800 --> 00:16:57,519
our particular deployment

00:16:54,320 --> 00:17:00,240
uh the linux uh essential eight

00:16:57,519 --> 00:17:01,839
sort of version that acknowledges this

00:17:00,240 --> 00:17:05,360
and has this general

00:17:01,839 --> 00:17:08,799
hardening of linux part or

00:17:05,360 --> 00:17:13,039
where the macros point dot point sits

00:17:08,799 --> 00:17:16,079
and it talks about upper mirrors linux

00:17:13,039 --> 00:17:16,079
less privilege

00:17:16,400 --> 00:17:20,640
shipping the logs out so those are the

00:17:19,839 --> 00:17:22,799
things we do

00:17:20,640 --> 00:17:24,319
practice uh in our design so i probably

00:17:22,799 --> 00:17:28,400
should have included a thing about

00:17:24,319 --> 00:17:31,280
log so we use um uh fluent bit

00:17:28,400 --> 00:17:33,600
for our logging in kubernetes these days

00:17:31,280 --> 00:17:37,039
and then we ship the logs out

00:17:33,600 --> 00:17:38,799
to s3 uh currently in the same account

00:17:37,039 --> 00:17:40,400
perhaps in the future in a separate

00:17:38,799 --> 00:17:42,720
account

00:17:40,400 --> 00:17:43,679
i think the government has a seven year

00:17:42,720 --> 00:17:45,840
retention

00:17:43,679 --> 00:17:47,360
for things but i'm not sure the

00:17:45,840 --> 00:17:50,960
kubernetes logs are

00:17:47,360 --> 00:17:52,320
covered by that uh we yeah so

00:17:50,960 --> 00:17:54,480
so that that's sort of something that

00:17:52,320 --> 00:17:57,919
needs to be adapted more relevant

00:17:54,480 --> 00:17:59,280
is the recently published uh kubernetes

00:17:57,919 --> 00:18:02,960
seek security

00:17:59,280 --> 00:18:03,600
white paper so we read we have read this

00:18:02,960 --> 00:18:06,400
as a team

00:18:03,600 --> 00:18:08,080
a couple of times and it's like a

00:18:06,400 --> 00:18:11,679
massive list of to-do's

00:18:08,080 --> 00:18:15,280
for us or just mapping out our things

00:18:11,679 --> 00:18:17,360
in detail for us as a result of reading

00:18:15,280 --> 00:18:20,720
this white paper a few times both

00:18:17,360 --> 00:18:22,559
as deployed and also as uh supply chain

00:18:20,720 --> 00:18:23,919
sort of stuff for how our containers are

00:18:22,559 --> 00:18:25,600
getting built

00:18:23,919 --> 00:18:27,520
where all the dependencies are being

00:18:25,600 --> 00:18:30,400
sourced

00:18:27,520 --> 00:18:33,520
and yeah so it's a like i remember

00:18:30,400 --> 00:18:36,320
lemurs talk today they have

00:18:33,520 --> 00:18:36,720
15 000 repositories so one time when i

00:18:36,320 --> 00:18:38,799
was

00:18:36,720 --> 00:18:40,000
previous work we were looking at a

00:18:38,799 --> 00:18:42,559
front-end application

00:18:40,000 --> 00:18:45,120
in react and there was a requirement to

00:18:42,559 --> 00:18:46,640
scan dependencies and we did so and we

00:18:45,120 --> 00:18:49,919
ended up with around

00:18:46,640 --> 00:18:52,640
2 000 npm packages in this massive tree

00:18:49,919 --> 00:18:54,880
of things but anyway sourcing it has

00:18:52,640 --> 00:18:56,720
been topical recently the supply chain

00:18:54,880 --> 00:18:57,039
and sourcing and dependency management

00:18:56,720 --> 00:19:00,240
but

00:18:57,039 --> 00:19:02,480
uh yeah and also the sort of relevant

00:19:00,240 --> 00:19:02,480
thing

00:19:03,520 --> 00:19:07,120
the the diagrams

00:19:08,559 --> 00:19:12,080
here the diagrams were generated using

00:19:11,200 --> 00:19:15,440
uh

00:19:12,080 --> 00:19:17,360
blast radius for terraform specifically

00:19:15,440 --> 00:19:19,679
i can take questions at the end of this

00:19:17,360 --> 00:19:23,120
um so the

00:19:19,679 --> 00:19:26,960
the next point is about hardening so

00:19:23,120 --> 00:19:28,799
the this one i picked alice springs a

00:19:26,960 --> 00:19:30,559
hard part of australia to live in

00:19:28,799 --> 00:19:31,919
i don't know if that metaphor translates

00:19:30,559 --> 00:19:35,440
but

00:19:31,919 --> 00:19:39,120
um australia is has pretty

00:19:35,440 --> 00:19:43,440
good deserty landscapes to pick from

00:19:39,120 --> 00:19:46,559
for hard places to live so we try to do

00:19:43,440 --> 00:19:49,120
static container analysis uh i

00:19:46,559 --> 00:19:49,919
showed that review one before in the

00:19:49,120 --> 00:19:52,960
past or

00:19:49,919 --> 00:19:54,720
concurrently we have used other

00:19:52,960 --> 00:19:57,280
container scanning tools like player

00:19:54,720 --> 00:19:59,520
scanner ecr has a built-in

00:19:57,280 --> 00:20:01,679
scanning tool we just recently got a

00:19:59,520 --> 00:20:02,720
docker hub paid subscription which gives

00:20:01,679 --> 00:20:04,320
us nick

00:20:02,720 --> 00:20:07,760
as a scanning tool i'm not sure i'm

00:20:04,320 --> 00:20:11,280
saying that right snake sneak

00:20:07,760 --> 00:20:11,919
and then we also are sort of looking to

00:20:11,280 --> 00:20:15,200
implement

00:20:11,919 --> 00:20:16,400
falco and other runtime scanning

00:20:15,200 --> 00:20:18,880
solutions

00:20:16,400 --> 00:20:20,880
so that you can look at the behavior and

00:20:18,880 --> 00:20:24,480
the privileges and syscalls being met

00:20:20,880 --> 00:20:26,159
with containers and for the python code

00:20:24,480 --> 00:20:29,919
analysis one of our projects

00:20:26,159 --> 00:20:33,039
is looking at using bandit uh for python

00:20:29,919 --> 00:20:33,760
uh it's part of the pi cqa suite of

00:20:33,039 --> 00:20:36,240
things that

00:20:33,760 --> 00:20:38,240
comes with violin and other other things

00:20:36,240 --> 00:20:40,159
you love

00:20:38,240 --> 00:20:41,760
and super opinionated about how you're

00:20:40,159 --> 00:20:44,880
at your python um

00:20:41,760 --> 00:20:48,000
and then the like the black

00:20:44,880 --> 00:20:51,039
sheep in our cluster is jupiter hub

00:20:48,000 --> 00:20:53,520
specifically the jupiter hub user pods

00:20:51,039 --> 00:20:55,600
uh if anyone has used jupiter hub it's

00:20:53,520 --> 00:20:59,679
like this

00:20:55,600 --> 00:21:04,159
multi-user shared jupiter workspace

00:20:59,679 --> 00:21:04,159
for developing interactive notebooks

00:21:12,640 --> 00:21:19,440
you use that to create

00:21:16,720 --> 00:21:20,400
the notebooks and maintain them but it

00:21:19,440 --> 00:21:23,600
lets you

00:21:20,400 --> 00:21:24,559
add any anything you want in the python

00:21:23,600 --> 00:21:26,799
application

00:21:24,559 --> 00:21:28,559
and that has caused issues for us in the

00:21:26,799 --> 00:21:32,559
past

00:21:28,559 --> 00:21:34,080
so yeah so we can't really harden that

00:21:32,559 --> 00:21:36,559
as such but you can watch from the

00:21:34,080 --> 00:21:40,159
periphery um i have an application

00:21:36,559 --> 00:21:42,799
uh in the uh have to

00:21:40,159 --> 00:21:43,520
reduce the aws resources you can access

00:21:42,799 --> 00:21:46,960
or not

00:21:43,520 --> 00:21:50,080
give you access up to the aws resources

00:21:46,960 --> 00:21:52,400
and also port security policies uh which

00:21:50,080 --> 00:21:53,360
which we and we currently have at node

00:21:52,400 --> 00:21:56,799
level

00:21:53,360 --> 00:22:00,540
it's sort of a future to do thing

00:21:56,799 --> 00:22:01,919
so the next uh uh

00:22:00,540 --> 00:22:04,480
[Music]

00:22:01,919 --> 00:22:06,559
slide i have is another sort of graph uh

00:22:04,480 --> 00:22:10,320
we use cilium for our network

00:22:06,559 --> 00:22:11,600
uh firewalling uh sort of approach in

00:22:10,320 --> 00:22:14,080
the cluster

00:22:11,600 --> 00:22:14,640
we haven't adopted a full-blown service

00:22:14,080 --> 00:22:16,799
mesh

00:22:14,640 --> 00:22:18,880
yet which bring which i used to use uh

00:22:16,799 --> 00:22:20,640
which brings nice to also visitor tools

00:22:18,880 --> 00:22:24,840
like this like yali

00:22:20,640 --> 00:22:27,440
uh so our user pods have to uh be

00:22:24,840 --> 00:22:29,280
uh looked at it from the outside and

00:22:27,440 --> 00:22:31,919
what connections they are making

00:22:29,280 --> 00:22:34,720
and this is a view from hubble uh which

00:22:31,919 --> 00:22:37,520
is the observability tool that selim has

00:22:34,720 --> 00:22:38,080
for what the or what the jupiter hub

00:22:37,520 --> 00:22:40,159
their

00:22:38,080 --> 00:22:42,559
things are doing and talking out to the

00:22:40,159 --> 00:22:42,559
internet

00:22:43,600 --> 00:22:47,520
uh so the next one is obviously where i

00:22:45,760 --> 00:22:50,080
am currently in canberra

00:22:47,520 --> 00:22:51,919
and sort of is about administration

00:22:50,080 --> 00:22:54,240
administrative access reducing

00:22:51,919 --> 00:22:57,280
administrative access

00:22:54,240 --> 00:23:00,960
uh so this is also a product that

00:22:57,280 --> 00:23:04,240
our digital earth australia produces

00:23:00,960 --> 00:23:04,720
called water observations this is sort

00:23:04,240 --> 00:23:07,679
of the

00:23:04,720 --> 00:23:08,480
lake burley griffin and which how much

00:23:07,679 --> 00:23:10,159
of it is

00:23:08,480 --> 00:23:12,159
filled with water at different times of

00:23:10,159 --> 00:23:16,240
the year during

00:23:12,159 --> 00:23:16,240
different times using in a season

00:23:17,520 --> 00:23:20,880
so restricting administrative privileges

00:23:20,320 --> 00:23:24,480
so

00:23:20,880 --> 00:23:28,960
our aws account level

00:23:24,480 --> 00:23:32,320
uh access is uh managed through sso

00:23:28,960 --> 00:23:34,799
we are moving towards aws sso

00:23:32,320 --> 00:23:36,320
uh im credentials are least privileged

00:23:34,799 --> 00:23:37,039
database credentials are least

00:23:36,320 --> 00:23:40,000
privileged

00:23:37,039 --> 00:23:41,120
when it is credentials and namespace and

00:23:40,000 --> 00:23:44,240
flux has

00:23:41,120 --> 00:23:46,159
higher privilege access or is

00:23:44,240 --> 00:23:48,080
and developers do not have high

00:23:46,159 --> 00:23:49,520
privilege access try to use non-root

00:23:48,080 --> 00:23:51,679
containers

00:23:49,520 --> 00:23:52,640
and just try to do least privilege

00:23:51,679 --> 00:23:55,919
everywhere

00:23:52,640 --> 00:23:58,720
as possible uh

00:23:55,919 --> 00:23:59,200
we're looking at one of the things that

00:23:58,720 --> 00:24:01,520
too

00:23:59,200 --> 00:24:03,279
like there's like a bootstrapping issues

00:24:01,520 --> 00:24:04,640
here with terraform to start up the

00:24:03,279 --> 00:24:06,159
clusters and so on

00:24:04,640 --> 00:24:07,679
so looking at least privilege for

00:24:06,159 --> 00:24:10,080
terraformers well currently we have a

00:24:07,679 --> 00:24:12,159
hunt crafted this privilege

00:24:10,080 --> 00:24:13,919
but we're looking at and analyzing the

00:24:12,159 --> 00:24:17,520
cloud trail logs

00:24:13,919 --> 00:24:18,400
and then looking at programmatically

00:24:17,520 --> 00:24:20,320
defining

00:24:18,400 --> 00:24:23,200
the im credentials using things like

00:24:20,320 --> 00:24:23,200
policy sentry

00:24:23,840 --> 00:24:29,360
uh the satellite data is not always

00:24:27,360 --> 00:24:30,720
let's say at 0.6 so satellite data is

00:24:29,360 --> 00:24:32,400
not always

00:24:30,720 --> 00:24:34,080
like the way we see the world there are

00:24:32,400 --> 00:24:36,320
extra bands

00:24:34,080 --> 00:24:37,279
uh uh it's like so having sort of a

00:24:36,320 --> 00:24:38,720
super power

00:24:37,279 --> 00:24:40,320
i don't know if people watch ghost in

00:24:38,720 --> 00:24:42,000
the shell like being like macho where

00:24:40,320 --> 00:24:43,600
you can see in ultraviolet and

00:24:42,000 --> 00:24:46,640
microwaves and

00:24:43,600 --> 00:24:48,159
so on so um this one is a synthetic

00:24:46,640 --> 00:24:50,320
aperture radar which is sort of

00:24:48,159 --> 00:24:52,080
close to my heart i did my phd and spent

00:24:50,320 --> 00:24:53,440
five years of my life looking at this

00:24:52,080 --> 00:24:56,400
stuff but anyway

00:24:53,440 --> 00:24:58,880
uh this is vegetation index derived from

00:24:56,400 --> 00:24:59,279
a japanese satellite called alos pulsar

00:24:58,880 --> 00:25:03,120
over

00:24:59,279 --> 00:25:06,320
farms in the nile delta in egypt

00:25:03,120 --> 00:25:09,679
so this is another sort of patchwork

00:25:06,320 --> 00:25:11,760
story uh sorry skipped a head one so we

00:25:09,679 --> 00:25:14,400
have to patch the operating system so

00:25:11,760 --> 00:25:16,000
patch the nodes underneath that's what

00:25:14,400 --> 00:25:17,360
it means for us for kubernetes or means

00:25:16,000 --> 00:25:20,559
to me

00:25:17,360 --> 00:25:24,240
so we keep our eye using the ssm for

00:25:20,559 --> 00:25:26,880
the latest patches being applied

00:25:24,240 --> 00:25:28,640
and rebuild and regularly roll our

00:25:26,880 --> 00:25:31,440
instances use manage

00:25:28,640 --> 00:25:32,880
instances is future to do and maybe

00:25:31,440 --> 00:25:36,720
we'll start adopting

00:25:32,880 --> 00:25:38,559
cut down currently use ubuntu best nodes

00:25:36,720 --> 00:25:39,760
will probably start adopting bottle

00:25:38,559 --> 00:25:42,799
rocket or other

00:25:39,760 --> 00:25:45,919
container specific run

00:25:42,799 --> 00:25:49,360
downsized smis and

00:25:45,919 --> 00:25:52,159
distributions so to say

00:25:49,360 --> 00:25:52,799
um so some of the fun stuff we have had

00:25:52,159 --> 00:25:56,480
during

00:25:52,799 --> 00:25:59,039
doing patching is with like uh

00:25:56,480 --> 00:25:59,520
so you also have space taken up in your

00:25:59,039 --> 00:26:01,679
node

00:25:59,520 --> 00:26:03,440
and some of the applications may be

00:26:01,679 --> 00:26:06,720
using empty dir

00:26:03,440 --> 00:26:09,600
for their uh processing and stuff

00:26:06,720 --> 00:26:11,279
so we had uh one of the patches just

00:26:09,600 --> 00:26:14,159
take up slightly more

00:26:11,279 --> 00:26:14,799
space and the application was using

00:26:14,159 --> 00:26:18,799
empty there

00:26:14,799 --> 00:26:21,919
to uh put some temporary data

00:26:18,799 --> 00:26:24,159
started failing more it ran for for a

00:26:21,919 --> 00:26:26,720
few test cases during the smoke test

00:26:24,159 --> 00:26:28,240
but when it started running 400

00:26:26,720 --> 00:26:30,080
satellite scenes per day

00:26:28,240 --> 00:26:31,840
some of the scenes had more content than

00:26:30,080 --> 00:26:34,400
others and it started failing

00:26:31,840 --> 00:26:36,480
due to running out of node local storage

00:26:34,400 --> 00:26:38,480
uh and i had to like spend one weekend

00:26:36,480 --> 00:26:40,640
fighting that

00:26:38,480 --> 00:26:42,240
and then uh some of that we have had

00:26:40,640 --> 00:26:44,880
networking issues we have

00:26:42,240 --> 00:26:45,279
sort of uh lodged issues with awsvpcc

00:26:44,880 --> 00:26:48,799
and i

00:26:45,279 --> 00:26:51,200
for making psilium work nicely uh

00:26:48,799 --> 00:26:53,679
and then we also have interdependency

00:26:51,200 --> 00:26:56,720
between services as they roll out

00:26:53,679 --> 00:27:00,480
so i had to have a different

00:26:56,720 --> 00:27:01,520
uh q2im and which manages our dns

00:27:00,480 --> 00:27:04,559
entries

00:27:01,520 --> 00:27:06,000
has to come before and so on and we have

00:27:04,559 --> 00:27:09,120
to manage those dependencies

00:27:06,000 --> 00:27:11,600
when rolling the nodes uh if a core node

00:27:09,120 --> 00:27:13,520
with a service like that goes off

00:27:11,600 --> 00:27:14,640
then other services may fail so we need

00:27:13,520 --> 00:27:17,520
to make sure we

00:27:14,640 --> 00:27:18,399
sort of manage our dependency graph of

00:27:17,520 --> 00:27:21,840
the services

00:27:18,399 --> 00:27:21,840
uh properly

00:27:22,159 --> 00:27:26,799
so this one is uh the confluence of

00:27:25,600 --> 00:27:30,159
nigeria and benue

00:27:26,799 --> 00:27:31,840
rivers in nigeria from landsat 8 again

00:27:30,159 --> 00:27:35,600
the germanian products

00:27:31,840 --> 00:27:38,880
there are bits of overblown sand

00:27:35,600 --> 00:27:41,200
in this sort of image and then

00:27:38,880 --> 00:27:43,120
this one is about multi-factor things

00:27:41,200 --> 00:27:47,039
joining together it's about mfa

00:27:43,120 --> 00:27:50,080
essentially so we

00:27:47,039 --> 00:27:50,640
use mfa wherever we can in our supply

00:27:50,080 --> 00:27:53,679
chain

00:27:50,640 --> 00:27:54,320
and in the management tools uh aws

00:27:53,679 --> 00:27:57,440
console

00:27:54,320 --> 00:28:00,799
github bitbucket docker hub

00:27:57,440 --> 00:28:03,600
the the cli tool we use for managing the

00:28:00,799 --> 00:28:06,640
kubernetes cluster or administering one

00:28:03,600 --> 00:28:09,039
uh ie cube cattle we sort of

00:28:06,640 --> 00:28:10,559
use aws vaults to manage our credentials

00:28:09,039 --> 00:28:13,840
and aws vault has

00:28:10,559 --> 00:28:17,039
support for mfa as well in the cli

00:28:13,840 --> 00:28:19,039
tool um so that that's sort of we apply

00:28:17,039 --> 00:28:22,640
it as much as we can

00:28:19,039 --> 00:28:24,799
you know in our accessing the

00:28:22,640 --> 00:28:27,279
cluster and the supply chain process as

00:28:24,799 --> 00:28:30,640
much as possible

00:28:27,279 --> 00:28:33,279
i'm trying to sort of leave

00:28:30,640 --> 00:28:36,720
time for questions so ask a lot of

00:28:33,279 --> 00:28:36,720
questions near the end i hope

00:28:38,080 --> 00:28:44,320
the next one we have here is a

00:28:41,279 --> 00:28:47,120
swath of scenes in a day uh

00:28:44,320 --> 00:28:48,960
captured over africa using ours a couple

00:28:47,120 --> 00:28:50,640
of satellites from the european space

00:28:48,960 --> 00:28:51,520
agency the control center we had in the

00:28:50,640 --> 00:28:55,440
beginning

00:28:51,520 --> 00:28:57,840
called sentinel 2 a and b and this

00:28:55,440 --> 00:28:59,600
this particular point which is the last

00:28:57,840 --> 00:29:01,200
one and so we'll have plenty of time for

00:28:59,600 --> 00:29:05,039
questions i guess

00:29:01,200 --> 00:29:08,480
is about daily backups

00:29:05,039 --> 00:29:11,200
so we do not run

00:29:08,480 --> 00:29:13,360
stateful things in kubernetes so try not

00:29:11,200 --> 00:29:16,240
to currently

00:29:13,360 --> 00:29:17,679
we run them in manage services so there

00:29:16,240 --> 00:29:20,799
are hourly backups for

00:29:17,679 --> 00:29:23,039
the database services s3 is where

00:29:20,799 --> 00:29:24,559
most of our investment i guess is is the

00:29:23,039 --> 00:29:28,559
most cost

00:29:24,559 --> 00:29:32,000
center uh s3 and now azure blob store

00:29:28,559 --> 00:29:34,399
uh is so we have like a multi-factor

00:29:32,000 --> 00:29:36,799
delete for the buckets we have uh

00:29:34,399 --> 00:29:39,279
versioning with seven-day retention

00:29:36,799 --> 00:29:40,559
so we have a lot of lot of data in s3 so

00:29:39,279 --> 00:29:42,640
that sort of is

00:29:40,559 --> 00:29:45,919
hopefully redundant we also have the

00:29:42,640 --> 00:29:49,679
copy of the data at the nci in canberra

00:29:45,919 --> 00:29:52,080
as well and in various uh space agencies

00:29:49,679 --> 00:29:55,840
for the africa deployment

00:29:52,080 --> 00:29:56,960
so the ebs volumes that are there

00:29:55,840 --> 00:29:58,640
attached are not

00:29:56,960 --> 00:30:01,120
backed up because we don't have any

00:29:58,640 --> 00:30:04,480
stateful services as i said uh

00:30:01,120 --> 00:30:05,600
and so the developer machines or the

00:30:04,480 --> 00:30:08,320
jupiter hub

00:30:05,600 --> 00:30:09,840
which has got some notebooks and

00:30:08,320 --> 00:30:12,320
attached storage

00:30:09,840 --> 00:30:14,640
attached to user pods don't have backups

00:30:12,320 --> 00:30:18,159
that are considered ephemeral and

00:30:14,640 --> 00:30:20,159
still working on the uh

00:30:18,159 --> 00:30:22,159
still working on the service level or

00:30:20,159 --> 00:30:23,120
the user agreement terms and conditions

00:30:22,159 --> 00:30:25,600
to say that

00:30:23,120 --> 00:30:28,240
we do not provide any backup for any

00:30:25,600 --> 00:30:30,399
code in development in the notebooks

00:30:28,240 --> 00:30:31,600
kubernetes is sort of still maturing in

00:30:30,399 --> 00:30:34,840
the stateful way

00:30:31,600 --> 00:30:36,320
i when we were looking at scaling our

00:30:34,840 --> 00:30:40,080
database we

00:30:36,320 --> 00:30:41,360
sort of could move from standard postgre

00:30:40,080 --> 00:30:43,840
which we were on to

00:30:41,360 --> 00:30:45,840
aurora or to uh something like a poster

00:30:43,840 --> 00:30:49,120
operator from crunchy data

00:30:45,840 --> 00:30:53,440
and run postgre in kubernetes we

00:30:49,120 --> 00:30:55,520
chose not to go to for our main database

00:30:53,440 --> 00:30:56,720
using the running database and

00:30:55,520 --> 00:30:59,120
kubernetes approach

00:30:56,720 --> 00:31:01,440
because we are unsure of the stateful

00:30:59,120 --> 00:31:04,399
how well stateful applications will run

00:31:01,440 --> 00:31:05,760
in kubernetes we may still explore post

00:31:04,399 --> 00:31:09,519
gray in kubernetes

00:31:05,760 --> 00:31:12,000
uh for a developer database which can be

00:31:09,519 --> 00:31:14,000
attached to jupiter hub and thrown away

00:31:12,000 --> 00:31:17,919
sort of thing because

00:31:14,000 --> 00:31:20,399
our design has a lot of the data in s3

00:31:17,919 --> 00:31:22,559
but the indexes all sit in post gray

00:31:20,399 --> 00:31:26,720
so it's difficult to develop without

00:31:22,559 --> 00:31:26,720
access to an easy postgre database

00:31:27,039 --> 00:31:30,960
yeah so i'm not sure if i'm right or

00:31:29,120 --> 00:31:33,200
wrong someone may correct me regarding

00:31:30,960 --> 00:31:35,600
the latest thing with kubernetes so

00:31:33,200 --> 00:31:37,679
kubernetes is not ready for stateful

00:31:35,600 --> 00:31:40,960
yeah there are things being done

00:31:37,679 --> 00:31:43,039
but there are no official big patterns

00:31:40,960 --> 00:31:44,080
for doing stateful things especially

00:31:43,039 --> 00:31:47,840
databases

00:31:44,080 --> 00:31:47,840
in in kubernetes

00:31:48,799 --> 00:31:53,919
and obviously nothing is perfect so we

00:31:51,679 --> 00:31:56,240
have got a few deficiencies and to-do's

00:31:53,919 --> 00:31:59,120
and things to maintain in the future

00:31:56,240 --> 00:32:00,880
in our infrastructure uh create and

00:31:59,120 --> 00:32:02,559
maintain security policies constant

00:32:00,880 --> 00:32:06,320
battle to apply patches

00:32:02,559 --> 00:32:09,360
uh fix up things uh uh look for

00:32:06,320 --> 00:32:11,120
ci tooling to scan uh

00:32:09,360 --> 00:32:12,799
python javascript whatever we have in

00:32:11,120 --> 00:32:15,360
our code base

00:32:12,799 --> 00:32:17,279
uh it's difficult to manage lots of ion

00:32:15,360 --> 00:32:20,559
credentials and lots of groups

00:32:17,279 --> 00:32:24,000
uh so just make sure uh

00:32:20,559 --> 00:32:27,120
yeah and then uh

00:32:24,000 --> 00:32:29,519
the uh this one is sort of a long

00:32:27,120 --> 00:32:31,600
dirty laundry list i guess so we have

00:32:29,519 --> 00:32:35,279
had uh

00:32:31,600 --> 00:32:36,880
the security incidents in the past one

00:32:35,279 --> 00:32:37,600
of the ones that has happened while i

00:32:36,880 --> 00:32:40,240
was there

00:32:37,600 --> 00:32:41,519
was someone logged into our jupiter hub

00:32:40,240 --> 00:32:44,399
environment

00:32:41,519 --> 00:32:46,960
and was mining monero and that was

00:32:44,399 --> 00:32:49,679
picked up by god duty as network traffic

00:32:46,960 --> 00:32:52,559
unexpected network traffic and we sort

00:32:49,679 --> 00:32:53,279
of adopted celium to act as a firewall

00:32:52,559 --> 00:32:55,200
to sort of

00:32:53,279 --> 00:32:57,760
whitelist all of the other things that

00:32:55,200 --> 00:33:00,880
are standard for scientific movement

00:32:57,760 --> 00:33:02,159
uh that people could go out to uh we had

00:33:00,880 --> 00:33:05,200
developer machines

00:33:02,159 --> 00:33:07,279
uh acting as our exit nodes uh

00:33:05,200 --> 00:33:08,720
which we sort of threw away the dev

00:33:07,279 --> 00:33:12,080
machine

00:33:08,720 --> 00:33:15,039
we have had uh insecure passwords and

00:33:12,080 --> 00:33:16,799
uh machines being compromised sort of a

00:33:15,039 --> 00:33:17,279
lot of this stuff is developer box but

00:33:16,799 --> 00:33:19,519
we

00:33:17,279 --> 00:33:20,720
do need to secure access to the cluster

00:33:19,519 --> 00:33:22,480
so we need to have security in the

00:33:20,720 --> 00:33:24,880
developer boxes as well

00:33:22,480 --> 00:33:25,840
so that cluster access cannot be

00:33:24,880 --> 00:33:29,200
escalated

00:33:25,840 --> 00:33:30,159
to um we are we are constantly under

00:33:29,200 --> 00:33:32,480
attack

00:33:30,159 --> 00:33:33,519
using for the web services especially

00:33:32,480 --> 00:33:35,360
and jupiter hub

00:33:33,519 --> 00:33:36,880
uh for people scanning for

00:33:35,360 --> 00:33:39,200
vulnerabilities

00:33:36,880 --> 00:33:40,799
uh i don't have a log for our web

00:33:39,200 --> 00:33:43,360
application firewall laugh

00:33:40,799 --> 00:33:44,880
uh but we sort of hide things behind

00:33:43,360 --> 00:33:48,000
load balancers and wi-f

00:33:44,880 --> 00:33:50,480
to sort of mitigate that a little bit

00:33:48,000 --> 00:33:51,120
uh this was a classic example of a list

00:33:50,480 --> 00:33:53,120
so there is

00:33:51,120 --> 00:33:54,720
this sort of write-up called defenders

00:33:53,120 --> 00:33:55,840
thinking lists and attackers thinking

00:33:54,720 --> 00:33:58,000
graphs

00:33:55,840 --> 00:33:59,360
and this was a classic list so if you

00:33:58,000 --> 00:34:00,960
check off things and you feel you're

00:33:59,360 --> 00:34:01,519
safe but you're not safe you need to see

00:34:00,960 --> 00:34:03,360
the

00:34:01,519 --> 00:34:04,880
relationships between the different

00:34:03,360 --> 00:34:08,720
things and

00:34:04,880 --> 00:34:12,000
how privilege can be escalated as we go

00:34:08,720 --> 00:34:15,280
um so yeah so we need some constant work

00:34:12,000 --> 00:34:18,320
to make sure we retain uh

00:34:15,280 --> 00:34:20,399
retain security uh uh sort of the

00:34:18,320 --> 00:34:22,159
balance between convenience and control

00:34:20,399 --> 00:34:23,760
of something perfectly secure is

00:34:22,159 --> 00:34:26,000
perfectly unusable

00:34:23,760 --> 00:34:27,760
especially for science users who want to

00:34:26,000 --> 00:34:31,280
iterate and experiment

00:34:27,760 --> 00:34:31,760
constantly uh this is like a success

00:34:31,280 --> 00:34:34,399
story

00:34:31,760 --> 00:34:36,320
i guess the reverse so feeling finishing

00:34:34,399 --> 00:34:38,000
off on a good note

00:34:36,320 --> 00:34:39,359
we have this algorithm called your

00:34:38,000 --> 00:34:40,320
median which you have seen sort of

00:34:39,359 --> 00:34:42,000
referred to

00:34:40,320 --> 00:34:45,280
there's a paper for it there's a

00:34:42,000 --> 00:34:48,399
hyperlink there for the paper for it

00:34:45,280 --> 00:34:49,520
and then we ran this for all of africa

00:34:48,399 --> 00:34:53,119
for one year

00:34:49,520 --> 00:34:56,079
and it took maybe four or five hours

00:34:53,119 --> 00:34:57,520
and it was consuming on the spot

00:34:56,079 --> 00:35:00,560
instances in oregon

00:34:57,520 --> 00:35:04,079
4 000 cpus and around uh

00:35:00,560 --> 00:35:05,280
50 60 terabytes of ram and that worked

00:35:04,079 --> 00:35:07,520
smoothly

00:35:05,280 --> 00:35:09,520
uh we will probably run it at an even

00:35:07,520 --> 00:35:10,880
bigger scale because we had made some

00:35:09,520 --> 00:35:13,920
errors in our code

00:35:10,880 --> 00:35:14,720
and we only ran it out like 20 meters

00:35:13,920 --> 00:35:17,520
instead of 10

00:35:14,720 --> 00:35:19,520
for so it's but it will be probably four

00:35:17,520 --> 00:35:22,640
times bigger when we run it next

00:35:19,520 --> 00:35:24,480
soon uh so we'll see how that goes

00:35:22,640 --> 00:35:26,960
uh we have made some code improvements

00:35:24,480 --> 00:35:30,880
maybe it will be more efficient

00:35:26,960 --> 00:35:31,680
and then uh i'm sort of at the end and

00:35:30,880 --> 00:35:34,079
i'm happy to take

00:35:31,680 --> 00:35:35,440
questions so i'll leave this here uh

00:35:34,079 --> 00:35:38,160
around sort of

00:35:35,440 --> 00:35:38,800
security and how humans are the weakest

00:35:38,160 --> 00:35:40,800
point

00:35:38,800 --> 00:35:42,800
in you can secure the systems

00:35:40,800 --> 00:35:44,720
automatically as much as you want

00:35:42,800 --> 00:35:45,839
but humans still remain the weakest

00:35:44,720 --> 00:35:49,280
point in

00:35:45,839 --> 00:35:50,480
in getting managing access and ultimate

00:35:49,280 --> 00:35:53,680
security

00:35:50,480 --> 00:35:56,960
yeah i'll take happy to take questions

00:35:53,680 --> 00:35:57,760
thank you tish oh that talk was great i

00:35:56,960 --> 00:35:59,839
have to say

00:35:57,760 --> 00:36:01,359
i love the idea of excessive

00:35:59,839 --> 00:36:03,440
transparency

00:36:01,359 --> 00:36:04,960
and those numbers of those massive

00:36:03,440 --> 00:36:07,440
numbers of nodes of ram

00:36:04,960 --> 00:36:09,520
just made me green it must be such an

00:36:07,440 --> 00:36:13,119
exciting place to work

00:36:09,520 --> 00:36:15,359
yep it we've got about

00:36:13,119 --> 00:36:16,240
eight minutes for questions oh that's

00:36:15,359 --> 00:36:19,359
good

00:36:16,240 --> 00:36:22,560
and uh we've got one question from the

00:36:19,359 --> 00:36:24,079
audience and i've um as i tend to do

00:36:22,560 --> 00:36:25,760
i've got it

00:36:24,079 --> 00:36:27,200
all right we'll start with a question

00:36:25,760 --> 00:36:29,760
from the audience and that was just

00:36:27,200 --> 00:36:30,640
what do you use to generate the diagrams

00:36:29,760 --> 00:36:32,400
that you showed

00:36:30,640 --> 00:36:33,760
this question came up pretty early they

00:36:32,400 --> 00:36:36,160
might have been referring to that big

00:36:33,760 --> 00:36:38,839
node diagram of all the components

00:36:36,160 --> 00:36:40,079
yeah i'm sort of rolling back to it um

00:36:38,839 --> 00:36:42,079
yep

00:36:40,079 --> 00:36:43,119
uh so a couple of diagrams in these

00:36:42,079 --> 00:36:46,160
slides uh

00:36:43,119 --> 00:36:49,040
the first one i had was

00:36:46,160 --> 00:36:50,320
this one uh so this one was generated

00:36:49,040 --> 00:36:52,160
using a tool

00:36:50,320 --> 00:36:54,400
called blast radius it's written in

00:36:52,160 --> 00:36:58,079
python it basically

00:36:54,400 --> 00:37:01,839
uh is a mix of graphics

00:36:58,079 --> 00:37:04,000
and d3.js for the front-end

00:37:01,839 --> 00:37:06,320
it takes a terraform graph and then

00:37:04,000 --> 00:37:08,880
renders it to a graphis file

00:37:06,320 --> 00:37:10,960
and then has a little ui which lets you

00:37:08,880 --> 00:37:13,599
filter and navigate and highlight

00:37:10,960 --> 00:37:18,160
sections and cut the graph a little bit

00:37:13,599 --> 00:37:21,440
uh it's great for exploring big stacks

00:37:18,160 --> 00:37:23,839
excellent um i was wondering

00:37:21,440 --> 00:37:24,960
so you talked about patching and lots of

00:37:23,839 --> 00:37:27,920
upgrades

00:37:24,960 --> 00:37:29,200
with so many components that we can see

00:37:27,920 --> 00:37:31,200
in that diagram

00:37:29,200 --> 00:37:33,040
how do you check that any one component

00:37:31,200 --> 00:37:35,200
that hasn't for whatever reason

00:37:33,040 --> 00:37:36,560
needed a change recently from like a

00:37:35,200 --> 00:37:38,240
business perspective

00:37:36,560 --> 00:37:40,160
how do you check that it doesn't have

00:37:38,240 --> 00:37:43,040
any unpatched issues that are just kind

00:37:40,160 --> 00:37:46,320
of lurking there because it's been

00:37:43,040 --> 00:37:46,800
yeah so we do have some support so our

00:37:46,320 --> 00:37:50,960
team

00:37:46,800 --> 00:37:54,000
our organization has around

00:37:50,960 --> 00:37:54,880
100 plus aws accounts under the

00:37:54,000 --> 00:37:57,599
organization

00:37:54,880 --> 00:37:58,800
and our team manages maybe seven or

00:37:57,599 --> 00:38:02,720
eight of them

00:37:58,800 --> 00:38:03,839
and there is a sort of enterprise cloud

00:38:02,720 --> 00:38:05,920
enablement team

00:38:03,839 --> 00:38:07,040
which has tooling applied to the

00:38:05,920 --> 00:38:09,920
accounts

00:38:07,040 --> 00:38:11,680
which sort of looks after the other

00:38:09,920 --> 00:38:12,960
parts that are not under our direct

00:38:11,680 --> 00:38:14,640
responsibility

00:38:12,960 --> 00:38:16,720
and one of the things they provide are

00:38:14,640 --> 00:38:17,680
these dashboards using the system

00:38:16,720 --> 00:38:21,040
manager

00:38:17,680 --> 00:38:22,240
where you can see what is uh what has

00:38:21,040 --> 00:38:23,920
been not been patched what are the

00:38:22,240 --> 00:38:24,800
vulnerabilities in other parts of the

00:38:23,920 --> 00:38:27,359
system

00:38:24,800 --> 00:38:27,920
so that i don't specifically implement

00:38:27,359 --> 00:38:29,599
those uh

00:38:27,920 --> 00:38:31,520
i do have a team member who works

00:38:29,599 --> 00:38:32,160
closely with them and is sending things

00:38:31,520 --> 00:38:33,599
that we

00:38:32,160 --> 00:38:35,680
that are in our stack and they haven't

00:38:33,599 --> 00:38:37,520
covered back to them

00:38:35,680 --> 00:38:38,880
to apply across the accounts because we

00:38:37,520 --> 00:38:40,880
don't actually have

00:38:38,880 --> 00:38:42,640
root access to the organization account

00:38:40,880 --> 00:38:46,160
to manage all of them

00:38:42,640 --> 00:38:49,119
yeah nice that that answer

00:38:46,160 --> 00:38:49,680
leads really well into my next question

00:38:49,119 --> 00:38:51,599
um

00:38:49,680 --> 00:38:53,440
which is this is a really large

00:38:51,599 --> 00:38:56,000
environment can you tell us

00:38:53,440 --> 00:38:57,119
roughly what the size of the team is and

00:38:56,000 --> 00:38:58,960
also

00:38:57,119 --> 00:39:00,160
i'm interested in the temporal nature

00:38:58,960 --> 00:39:02,640
how long has it taken

00:39:00,160 --> 00:39:04,640
to get this environment you know from an

00:39:02,640 --> 00:39:08,560
initial idea up to what we're seeing

00:39:04,640 --> 00:39:10,400
today sure um

00:39:08,560 --> 00:39:11,760
i it's my first year working in

00:39:10,400 --> 00:39:12,400
government i've worked in private

00:39:11,760 --> 00:39:15,760
industry

00:39:12,400 --> 00:39:16,640
before it's my a year and a bit the team

00:39:15,760 --> 00:39:18,240
has been

00:39:16,640 --> 00:39:19,920
fairly stable for a while i've been

00:39:18,240 --> 00:39:22,560
there that it's five

00:39:19,920 --> 00:39:24,960
people in this team the team i i work

00:39:22,560 --> 00:39:27,200
with and lead

00:39:24,960 --> 00:39:28,160
i would say it has taken many years to

00:39:27,200 --> 00:39:31,359
get to this stage

00:39:28,160 --> 00:39:33,200
the agtc has been running maybe for 10

00:39:31,359 --> 00:39:33,920
years the devops team has been around

00:39:33,200 --> 00:39:36,960
for three

00:39:33,920 --> 00:39:37,760
years or so there have had been previous

00:39:36,960 --> 00:39:39,920
iterations

00:39:37,760 --> 00:39:42,720
if you look in the github histories of

00:39:39,920 --> 00:39:45,520
the stack on ecs

00:39:42,720 --> 00:39:47,520
and then using your our own nodes using

00:39:45,520 --> 00:39:50,720
our own kubernetes one and then

00:39:47,520 --> 00:39:53,440
when key case was available on eks

00:39:50,720 --> 00:39:54,839
uh so yeah so it has taken maybe three

00:39:53,440 --> 00:39:58,560
years to get to this

00:39:54,839 --> 00:40:01,359
stage cool we've got a question from

00:39:58,560 --> 00:40:03,359
peter nunn peter wants to know if it's

00:40:01,359 --> 00:40:05,760
possible to find this stack

00:40:03,359 --> 00:40:08,640
somewhere so that they can try and apply

00:40:05,760 --> 00:40:13,520
it to their infrastructure

00:40:08,640 --> 00:40:13,520
yep uh so i'll go back uh

00:40:14,880 --> 00:40:18,560
sorry i'm just jumping around i have

00:40:16,960 --> 00:40:21,359
links and i will probably

00:40:18,560 --> 00:40:21,839
share the slides so this hyperlink here

00:40:21,359 --> 00:40:24,079
uh

00:40:21,839 --> 00:40:25,440
leads to the stack so maybe it's showing

00:40:24,079 --> 00:40:27,119
up in tiny font in the

00:40:25,440 --> 00:40:29,520
bottom yes yes i was just looking

00:40:27,119 --> 00:40:30,400
forward for that yeah yeah yeah yeah i

00:40:29,520 --> 00:40:32,400
will ask

00:40:30,400 --> 00:40:34,160
i'll probably just drop out of this

00:40:32,400 --> 00:40:36,480
presentation the screen is still shared

00:40:34,160 --> 00:40:40,400
so nothing else in this tab

00:40:36,480 --> 00:40:40,400
so i'll just follow that link through

00:40:41,280 --> 00:40:45,839
yeah so this is the terraform that we

00:40:44,160 --> 00:40:48,800
run nikita is the

00:40:45,839 --> 00:40:50,480
lead when i joined i worked with her to

00:40:48,800 --> 00:40:52,000
sort of report i can see

00:40:50,480 --> 00:40:54,480
there have been lots of contributors on

00:40:52,000 --> 00:40:58,079
this over the years

00:40:54,480 --> 00:40:59,839
the stack is shared with csro as well

00:40:58,079 --> 00:41:01,440
they run several instances of it all

00:40:59,839 --> 00:41:03,920
over the world

00:41:01,440 --> 00:41:05,200
um yeah yeah so it's a binary shared

00:41:03,920 --> 00:41:06,079
projects if you want to look at the

00:41:05,200 --> 00:41:08,160
insights of

00:41:06,079 --> 00:41:09,200
how this has come together you can see

00:41:08,160 --> 00:41:12,560
how long it has been

00:41:09,200 --> 00:41:14,480
running against uh contributors

00:41:12,560 --> 00:41:16,079
and there would be a major contributor

00:41:14,480 --> 00:41:17,839
on this but it has been tom was my

00:41:16,079 --> 00:41:19,680
predecessor in this team

00:41:17,839 --> 00:41:22,319
like you said excessive transparency

00:41:19,680 --> 00:41:22,319
this is wonderful

00:41:22,880 --> 00:41:26,160
yeah yeah yeah so you can see who has

00:41:25,599 --> 00:41:27,839
done what

00:41:26,160 --> 00:41:30,960
god yeah we've only got a few minutes

00:41:27,839 --> 00:41:32,800
i've got a comment from martin vizier

00:41:30,960 --> 00:41:34,000
who says that it's wonderful that you're

00:41:32,800 --> 00:41:36,560
being so candid about

00:41:34,000 --> 00:41:38,800
open security incidents which makes me

00:41:36,560 --> 00:41:41,359
think about one of my other questions

00:41:38,800 --> 00:41:42,400
um i was wondering do you have a robust

00:41:41,359 --> 00:41:46,079
cyber incident

00:41:42,400 --> 00:41:48,480
process or has that kind of come up

00:41:46,079 --> 00:41:49,119
as you've been experiencing these small

00:41:48,480 --> 00:41:52,560
cyber

00:41:49,119 --> 00:41:54,960
incidences um we do

00:41:52,560 --> 00:41:55,839
have what we call like uh what would i

00:41:54,960 --> 00:41:59,440
say

00:41:55,839 --> 00:42:02,400
uh an incident uh retro

00:41:59,440 --> 00:42:04,160
or postmodern process like a blameless

00:42:02,400 --> 00:42:07,200
postmortem process

00:42:04,160 --> 00:42:08,319
uh the we follow a tight sort of agile

00:42:07,200 --> 00:42:10,960
methodology where we

00:42:08,319 --> 00:42:11,520
keep on improving our processes as well

00:42:10,960 --> 00:42:15,040
as

00:42:11,520 --> 00:42:16,000
like the system itself and then whenever

00:42:15,040 --> 00:42:19,040
one of these incidents

00:42:16,000 --> 00:42:21,280
happen and we uh pick it up or our cloud

00:42:19,040 --> 00:42:24,560
enablement team picks it up

00:42:21,280 --> 00:42:24,560
uh we sort of do a

00:42:25,119 --> 00:42:29,359
teardown redeploy of the cluster so we

00:42:27,680 --> 00:42:30,240
can actually redeploy the cluster using

00:42:29,359 --> 00:42:32,880
the stack in

00:42:30,240 --> 00:42:34,200
half an hour to an hour so being

00:42:32,880 --> 00:42:36,560
stateless the good thing

00:42:34,200 --> 00:42:39,440
[Laughter]

00:42:36,560 --> 00:42:40,160
so we have done that recently uh it was

00:42:39,440 --> 00:42:42,960
actually

00:42:40,160 --> 00:42:45,280
someone who knew who started and was

00:42:42,960 --> 00:42:46,720
exploring this cluster destroyed the

00:42:45,280 --> 00:42:50,319
control plane

00:42:46,720 --> 00:42:53,200
and yeah yeah in the development cluster

00:42:50,319 --> 00:42:54,560
and uh we have yeah yeah we give

00:42:53,200 --> 00:42:55,200
high-level access to the development

00:42:54,560 --> 00:42:57,440
cluster

00:42:55,200 --> 00:42:58,800
just so that people can learn yeah and

00:42:57,440 --> 00:43:00,720
then we

00:42:58,800 --> 00:43:01,839
brought everything back in half an hour

00:43:00,720 --> 00:43:03,920
an hour uh

00:43:01,839 --> 00:43:05,440
it was weird we probably need to improve

00:43:03,920 --> 00:43:06,560
our monitoring because the control plane

00:43:05,440 --> 00:43:08,640
disappeared

00:43:06,560 --> 00:43:11,359
and um that all the applications were

00:43:08,640 --> 00:43:15,040
still up it was just we couldn't

00:43:11,359 --> 00:43:18,240
manage them monitor them yeah so

00:43:15,040 --> 00:43:20,240
cool well that is bringing us up pretty

00:43:18,240 --> 00:43:21,680
much to time we've got less than one

00:43:20,240 --> 00:43:23,520
minute

00:43:21,680 --> 00:43:26,000
thank you so much for that talk that was

00:43:23,520 --> 00:43:28,480
really great um

00:43:26,000 --> 00:43:29,200
uh coming up next in this channel we

00:43:28,480 --> 00:43:31,760
have

00:43:29,200 --> 00:43:32,720
more talks there's so much more content

00:43:31,760 --> 00:43:36,160
to come

00:43:32,720 --> 00:43:37,040
our next talk starts at 11 40 in my time

00:43:36,160 --> 00:43:39,280
zone australia

00:43:37,040 --> 00:43:40,560
melbourne time zone that's only 10

00:43:39,280 --> 00:43:42,640
minutes away

00:43:40,560 --> 00:43:43,680
it's going to be about supporting the

00:43:42,640 --> 00:43:46,160
bpf

00:43:43,680 --> 00:43:47,040
supporting bpf with the gnu compiler

00:43:46,160 --> 00:43:50,000
toolchain

00:43:47,040 --> 00:43:51,359
it's being brought to us from jose e

00:43:50,000 --> 00:43:53,599
machesi

00:43:51,359 --> 00:43:54,560
so to wrap up this section please give

00:43:53,599 --> 00:43:57,680
us all of your

00:43:54,560 --> 00:44:01,920
digital clicks and claps on vinulus

00:43:57,680 --> 00:44:01,920
and we'll see you again in about 10

00:44:02,839 --> 00:44:05,839

YouTube URL: https://www.youtube.com/watch?v=jsceIHoTNJU


