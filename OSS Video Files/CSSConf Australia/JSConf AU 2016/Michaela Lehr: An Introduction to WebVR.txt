Title: Michaela Lehr: An Introduction to WebVR
Publication date: 2017-05-19
Playlist: JSConf AU 2016
Description: 
	Thank you, Mozilla for making the video recording possible.

It's 2016 and virtual reality devices are finally ready to delight a large audience. Besides some proprietary tools there is also a new API to create VR experiences in the browser. This talk will give you an overview of the WebVR ecosystem, beginning with a short introduction to WebGL, VR devices, and basic VR concepts, like head tracking sensors, the field of view and stereoscopic 3d images. 

You will also see the current status of the WebVR API in action with some code samples of a 360 degree video for VR and – of course – fallback devices. Which leads to another important point of this talk: the struggles of creating VR applications today. There are a lot of unanswered questions, e.g. UX design challenges, input devices, motion sickness or browser support. This is why the talk ends with resources like frameworks, markup languages and polyfills.
Captions: 
	00:00:05,530 --> 00:00:15,530
hi hi yeah as you all didn't know I

00:00:13,639 --> 00:00:20,210
Mischa Ella and I'm here to talk about

00:00:15,530 --> 00:00:23,840
vet VR reading the topic of my talk you

00:00:20,210 --> 00:00:27,440
might have thought 11 3 d isn't that mon

00:00:23,840 --> 00:00:29,840
sense isn't thinking and talking about

00:00:27,440 --> 00:00:33,890
virtual reality but nothing more than

00:00:29,840 --> 00:00:38,929
ridiculous and most of all should I even

00:00:33,890 --> 00:00:41,210
care about what we are well you might

00:00:38,929 --> 00:00:43,129
have guessed already I'm here to tell

00:00:41,210 --> 00:00:47,570
you that you should care about where we

00:00:43,129 --> 00:00:50,269
are even if you're not a gamer even if

00:00:47,570 --> 00:00:53,649
you're just not into virtual reality or

00:00:50,269 --> 00:00:58,640
even if virtual reality makes you sick

00:00:53,649 --> 00:01:01,159
why you ask because if this technology

00:00:58,640 --> 00:01:03,530
is permanent and at the moment it looks

00:01:01,159 --> 00:01:05,600
like it is because what your reality

00:01:03,530 --> 00:01:08,690
will have a great impact on how our

00:01:05,600 --> 00:01:13,909
users and we all agree that we should

00:01:08,690 --> 00:01:17,719
care about our users hopefully um this

00:01:13,909 --> 00:01:19,700
is why I will tell you today the most

00:01:17,719 --> 00:01:23,740
important facts you have to know as

00:01:19,700 --> 00:01:26,810
developers about VR and we are to create

00:01:23,740 --> 00:01:30,920
responsible virtual reality experiences

00:01:26,810 --> 00:01:34,250
I will begin with some brief information

00:01:30,920 --> 00:01:37,340
about the hardware and we are concept

00:01:34,250 --> 00:01:42,109
and then we'll have a look into the web

00:01:37,340 --> 00:01:44,119
via our API and afterwards I'll come to

00:01:42,109 --> 00:01:46,789
the topic I'm most passionate about a

00:01:44,119 --> 00:01:51,799
good user experience in web via our

00:01:46,789 --> 00:01:54,679
applications before I forget you can all

00:01:51,799 --> 00:01:57,259
download the slides um with all the code

00:01:54,679 --> 00:02:02,450
and links I will give you the URL at the

00:01:57,259 --> 00:02:05,060
end of the talk so since we only have 30

00:02:02,450 --> 00:02:09,920
minutes I won't talk about what virtual

00:02:05,060 --> 00:02:13,510
reality is and I also won't talk about

00:02:09,920 --> 00:02:16,550
why I think virtual reality matters

00:02:13,510 --> 00:02:18,620
instead I want to concentrate on the

00:02:16,550 --> 00:02:21,019
things we as developers

00:02:18,620 --> 00:02:23,659
have to know when we want to create a

00:02:21,019 --> 00:02:26,860
virtual reality application so let's

00:02:23,659 --> 00:02:30,319
begin we'll look at the hardware

00:02:26,860 --> 00:02:32,950
first there are mobile real devices

00:02:30,319 --> 00:02:35,060
which basically smartphones and

00:02:32,950 --> 00:02:38,569
relatively cheap headsets with

00:02:35,060 --> 00:02:41,090
magnifying lenses the input methods on

00:02:38,569 --> 00:02:43,430
these devices veyron we have for example

00:02:41,090 --> 00:02:47,150
on the Left Google cardboard which has

00:02:43,430 --> 00:02:48,829
only one button on the side and there's

00:02:47,150 --> 00:02:52,220
the Samsung gear VR which has a button

00:02:48,829 --> 00:02:54,319
and a touchpad on the side and on the

00:02:52,220 --> 00:02:56,359
right you see the newest one the Google

00:02:54,319 --> 00:02:59,090
daydream view which comes with a special

00:02:56,359 --> 00:03:02,650
we our controller with three buttons and

00:02:59,090 --> 00:03:06,829
a touchpad and volume controls

00:03:02,650 --> 00:03:08,659
there are also desktop VR devices they

00:03:06,829 --> 00:03:12,049
are significantly more expensive because

00:03:08,659 --> 00:03:16,340
they also contain the sensors and the

00:03:12,049 --> 00:03:18,799
screens the computing power comes from

00:03:16,340 --> 00:03:21,700
the desktop computer or the gaming

00:03:18,799 --> 00:03:25,669
console which the VR device is blocked

00:03:21,700 --> 00:03:28,639
the in the input method of these devices

00:03:25,669 --> 00:03:31,010
also wearing the oculus rift users can

00:03:28,639 --> 00:03:33,950
use oculus touch motion track

00:03:31,010 --> 00:03:36,950
controllers and also the HTC vive ships

00:03:33,950 --> 00:03:38,989
with steamvr motion track controllers on

00:03:36,950 --> 00:03:42,319
the right you see the PlayStation VR you

00:03:38,989 --> 00:03:47,150
can remove use with the PlayStation Move

00:03:42,319 --> 00:03:50,239
controllers there are also standalone we

00:03:47,150 --> 00:03:52,940
our devices in theory which contain not

00:03:50,239 --> 00:03:56,329
only the sensors lenses and screens but

00:03:52,940 --> 00:03:58,970
also the computing power at the moment

00:03:56,329 --> 00:04:00,949
this is only theory because there are no

00:03:58,970 --> 00:04:03,799
really important devices on the market

00:04:00,949 --> 00:04:06,319
right now but of course there will be

00:04:03,799 --> 00:04:09,769
because this may be the most convenient

00:04:06,319 --> 00:04:13,069
form to use virtual reality applications

00:04:09,769 --> 00:04:17,319
without any plugs and cables but a

00:04:13,069 --> 00:04:17,319
higher computing power than a smartphone

00:04:18,609 --> 00:04:24,289
so now as developers we need to know

00:04:22,010 --> 00:04:27,530
about the different hardware and we our

00:04:24,289 --> 00:04:30,289
concepts when we want to not Inc exclude

00:04:27,530 --> 00:04:32,310
users so let's talk about the most

00:04:30,289 --> 00:04:35,780
important concepts of virtual

00:04:32,310 --> 00:04:42,720
reality stereoscopic images and tracking

00:04:35,780 --> 00:04:44,760
will begin with stereoscopic images when

00:04:42,720 --> 00:04:46,590
we talk about stereoscopic images in the

00:04:44,760 --> 00:04:49,290
context of the VR we are talking about

00:04:46,590 --> 00:04:51,690
two images next to each other showing

00:04:49,290 --> 00:04:57,240
the same content but from a slightly

00:04:51,690 --> 00:05:01,320
different point of view the offset

00:04:57,240 --> 00:05:05,220
between the both images is called IPD

00:05:01,320 --> 00:05:08,520
which means interpupillary distance by

00:05:05,220 --> 00:05:10,560
showing these images to our eyes we are

00:05:08,520 --> 00:05:13,140
exactly recreating how we see the world

00:05:10,560 --> 00:05:15,180
naturally and our brain combines these

00:05:13,140 --> 00:05:19,110
images like it always does and gives us

00:05:15,180 --> 00:05:21,540
the perception of freedy death when we

00:05:19,110 --> 00:05:23,630
are looking at what VR images we often

00:05:21,540 --> 00:05:26,550
see not full-screen images like these

00:05:23,630 --> 00:05:31,080
but some kind of distorted images like

00:05:26,550 --> 00:05:33,990
this we need this effect to compensate

00:05:31,080 --> 00:05:37,290
the distortion the thick lenses are

00:05:33,990 --> 00:05:40,050
making to the images if we wouldn't have

00:05:37,290 --> 00:05:44,010
this distortion the images would be

00:05:40,050 --> 00:05:46,440
distorted like this on the right but if

00:05:44,010 --> 00:05:48,930
we apply a contrasting distortion to the

00:05:46,440 --> 00:05:51,060
original image the images behind the

00:05:48,930 --> 00:05:56,610
lenses will be without any distortion

00:05:51,060 --> 00:05:59,310
again so by showing these slightly

00:05:56,610 --> 00:06:01,220
different images to our eyes we are

00:05:59,310 --> 00:06:03,870
already getting the perception of depth

00:06:01,220 --> 00:06:06,660
now to make our brain believe we are

00:06:03,870 --> 00:06:10,830
actually in this virtual world we have

00:06:06,660 --> 00:06:12,750
to include tracking all we are devices

00:06:10,830 --> 00:06:15,180
I've shown include free degree of

00:06:12,750 --> 00:06:19,080
freedom tracking sensors for the

00:06:15,180 --> 00:06:21,810
rotation around the free axis more

00:06:19,080 --> 00:06:26,370
advanced we are devices for example like

00:06:21,810 --> 00:06:28,020
the HTC vive also include tracking for

00:06:26,370 --> 00:06:31,250
the position of the user in the room

00:06:28,020 --> 00:06:34,050
which is called own room scale we are

00:06:31,250 --> 00:06:37,620
you can surely imagine that the more

00:06:34,050 --> 00:06:39,990
tracking sensors we have more intensive

00:06:37,620 --> 00:06:43,890
is the feeling of actually being in a

00:06:39,990 --> 00:06:45,840
virtual world this immersive feeling

00:06:43,890 --> 00:06:49,260
gets even stronger if we include

00:06:45,840 --> 00:06:53,130
input controllers with with rotation or

00:06:49,260 --> 00:06:55,669
position tracking sensors now how do we

00:06:53,130 --> 00:06:58,229
create such applications in JavaScript

00:06:55,669 --> 00:07:01,620
let me show you the stack will be

00:06:58,229 --> 00:07:06,000
working this first of all this of course

00:07:01,620 --> 00:07:09,030
the browser then with app GL we have an

00:07:06,000 --> 00:07:12,180
API for rendering GPU accelerated 3d

00:07:09,030 --> 00:07:14,160
graphics in the browser um we heard

00:07:12,180 --> 00:07:19,500
about this this morning in Jess's

00:07:14,160 --> 00:07:21,840
awesome talk now we need to get access

00:07:19,500 --> 00:07:23,760
to the head mounted display and the

00:07:21,840 --> 00:07:27,990
sensors and therefore we have the

00:07:23,760 --> 00:07:29,340
experimental API web VR on top of this

00:07:27,990 --> 00:07:32,310
there may be further JavaScript

00:07:29,340 --> 00:07:37,400
libraries one common library to reduce

00:07:32,310 --> 00:07:37,400
the effort of writing WebGL is free Jas

00:07:38,120 --> 00:07:45,000
now let me show you this techniques in a

00:07:41,550 --> 00:07:48,449
simple example here we have an obviously

00:07:45,000 --> 00:07:50,940
distorted freedom of spiracle video

00:07:48,449 --> 00:07:54,050
which are recorded with my 360-degree

00:07:50,940 --> 00:07:56,880
camera what we want to do is play the

00:07:54,050 --> 00:08:01,380
spherical video undistorted and in a

00:07:56,880 --> 00:08:04,830
stereoscopic way also we want to use the

00:08:01,380 --> 00:08:06,810
rotation sensors of the devices to let

00:08:04,830 --> 00:08:10,470
the user look around while the video is

00:08:06,810 --> 00:08:12,990
playing so our setup could look like

00:08:10,470 --> 00:08:15,419
this we have a three dimensional

00:08:12,990 --> 00:08:19,919
coordinate system where the camera is

00:08:15,419 --> 00:08:22,289
the user around the user we will create

00:08:19,919 --> 00:08:26,669
a large sphere which will be our video

00:08:22,289 --> 00:08:31,349
canvas so a simplified version of this

00:08:26,669 --> 00:08:34,349
code could look like this everybody who

00:08:31,349 --> 00:08:37,650
is familiar with WebGL off us see

00:08:34,349 --> 00:08:41,520
nothing new here first we create a scene

00:08:37,650 --> 00:08:45,089
and the camera then we create the sphere

00:08:41,520 --> 00:08:47,490
with video texture and then we render it

00:08:45,089 --> 00:08:51,390
all to the canvas within the render loop

00:08:47,490 --> 00:08:54,680
um this is only WebGL or free jeaious

00:08:51,390 --> 00:08:58,350
there's no web VR here at the moment so

00:08:54,680 --> 00:08:59,759
how do we render this scene not on the

00:08:58,350 --> 00:09:02,069
default screen

00:08:59,759 --> 00:09:06,449
on the canvas but on the head-mounted

00:09:02,069 --> 00:09:10,470
display this is where the web be our API

00:09:06,449 --> 00:09:13,859
comes into play first we need to get

00:09:10,470 --> 00:09:17,129
access to the VR device therefore we use

00:09:13,859 --> 00:09:21,829
the navigator interface extension get VR

00:09:17,129 --> 00:09:24,449
displays it returns a promise that

00:09:21,829 --> 00:09:27,629
results in an array of we are display

00:09:24,449 --> 00:09:31,109
objects and one we are display object

00:09:27,629 --> 00:09:34,350
represents one VR device which holds

00:09:31,109 --> 00:09:36,540
then information about the VR device for

00:09:34,350 --> 00:09:39,299
example if the device is currently

00:09:36,540 --> 00:09:41,850
connected if it is presenting and it

00:09:39,299 --> 00:09:45,119
also has methods like get AI parameters

00:09:41,850 --> 00:09:49,980
get pose requests present submit frame

00:09:45,119 --> 00:09:52,439
and request animation frame we can then

00:09:49,980 --> 00:09:54,869
use the we are display object to render

00:09:52,439 --> 00:09:58,139
content to the head-mounted display by

00:09:54,869 --> 00:10:01,079
using the request present method request

00:09:58,139 --> 00:10:03,839
present takes an array of we are layer

00:10:01,079 --> 00:10:06,839
objects which have a property source

00:10:03,839 --> 00:10:09,989
containing the html5 canvas we have will

00:10:06,839 --> 00:10:12,779
you be used to draw on the the cool

00:10:09,989 --> 00:10:15,449
thing is about requests present is that

00:10:12,779 --> 00:10:17,279
these handles device specific rendering

00:10:15,449 --> 00:10:19,829
issues like for example the barrel

00:10:17,279 --> 00:10:21,209
distortion I have talked about so you

00:10:19,829 --> 00:10:25,160
don't have to implement the stuff

00:10:21,209 --> 00:10:27,389
manually and another cool thing is that

00:10:25,160 --> 00:10:28,739
another thing you have to know us which

00:10:27,389 --> 00:10:31,769
is it's not so cool

00:10:28,739 --> 00:10:34,679
obviously for security reasons this

00:10:31,769 --> 00:10:38,339
request present method only may be

00:10:34,679 --> 00:10:40,649
triggered by a user action you may

00:10:38,339 --> 00:10:43,049
compare request resent and to request

00:10:40,649 --> 00:10:45,689
full screen it also requires a user

00:10:43,049 --> 00:10:49,399
action and request present first

00:10:45,689 --> 00:10:52,259
requests that VR device goes full screen

00:10:49,399 --> 00:10:56,459
so you would probably write something

00:10:52,259 --> 00:10:58,829
like this request present also returns a

00:10:56,459 --> 00:11:01,980
promise that is fulfilled when the

00:10:58,829 --> 00:11:04,379
presentation has begun and this is then

00:11:01,980 --> 00:11:06,389
the time we can use we can start a

00:11:04,379 --> 00:11:09,659
render loop by using VR displays

00:11:06,389 --> 00:11:12,339
requestanimationframe effort we are

00:11:09,659 --> 00:11:15,029
displays requestanimationframe is a

00:11:12,339 --> 00:11:19,149
Rivlin two windows requestanimationframe

00:11:15,029 --> 00:11:21,269
but it has device-specific and features

00:11:19,149 --> 00:11:25,120
for rendering on a head-mounted display

00:11:21,269 --> 00:11:28,120
it also draws continuously on the canvas

00:11:25,120 --> 00:11:30,730
but it does this in a higher frame rate

00:11:28,120 --> 00:11:33,660
depending on the VR device not with 60

00:11:30,730 --> 00:11:37,470
frames per second but with 90 or even

00:11:33,660 --> 00:11:39,430
120 frames per second

00:11:37,470 --> 00:11:42,730
within the render loop we are first

00:11:39,430 --> 00:11:45,610
shattering our next frames callback and

00:11:42,730 --> 00:11:48,370
then we can update our scene and camera

00:11:45,610 --> 00:11:50,550
position and rotation depending on the

00:11:48,370 --> 00:11:54,089
we are displaced tracking sensors

00:11:50,550 --> 00:11:57,550
therefore we have different interfaces

00:11:54,089 --> 00:11:59,769
there is for example the get post method

00:11:57,550 --> 00:12:03,209
which returns a VR pose with lots of

00:11:59,769 --> 00:12:06,790
information of the sensors at the moment

00:12:03,209 --> 00:12:09,129
for example there's the user's

00:12:06,790 --> 00:12:12,639
orientation which returns a quaternion

00:12:09,129 --> 00:12:17,319
or the users position which returns a 3d

00:12:12,639 --> 00:12:19,959
vector the mobile yard with VR devices

00:12:17,319 --> 00:12:23,529
will return for a position now because

00:12:19,959 --> 00:12:28,870
like I said before it has no sensors to

00:12:23,529 --> 00:12:30,790
know where user is in the room now we

00:12:28,870 --> 00:12:34,360
have to render our scene twice and a

00:12:30,790 --> 00:12:37,839
stereoscopic way and this is where we

00:12:34,360 --> 00:12:39,819
can use the get aya parameters method it

00:12:37,839 --> 00:12:42,249
gives us all the information we need if

00:12:39,819 --> 00:12:45,759
we pass one string for each eye as an

00:12:42,249 --> 00:12:47,999
document so there's the offset which is

00:12:45,759 --> 00:12:53,019
one half of the interpupillary distance

00:12:47,999 --> 00:12:55,779
or the render hate and which width which

00:12:53,019 --> 00:13:00,429
returns the recommended fits and head of

00:12:55,779 --> 00:13:02,889
a canvas for each eye with this

00:13:00,429 --> 00:13:05,829
information we can update our cameras

00:13:02,889 --> 00:13:08,170
and scene and render it all through the

00:13:05,829 --> 00:13:12,009
canvas by using the submit frame method

00:13:08,170 --> 00:13:16,029
and this is basically all you have to

00:13:12,009 --> 00:13:18,459
know and to do to get our video playing

00:13:16,029 --> 00:13:23,019
and updating by the user changes for

00:13:18,459 --> 00:13:25,540
pose so now let's get back to the stack

00:13:23,019 --> 00:13:26,360
because I want to give you also some

00:13:25,540 --> 00:13:29,690
practical

00:13:26,360 --> 00:13:33,470
tips about the libraries we used to

00:13:29,690 --> 00:13:40,910
create this prototype we didn't use a

00:13:33,470 --> 00:13:43,430
frame but we used three J's so you might

00:13:40,910 --> 00:13:46,040
have already guessed it um you are right

00:13:43,430 --> 00:13:49,519
but we are the API isn't ready today

00:13:46,040 --> 00:13:51,380
there's a good website called is web we

00:13:49,519 --> 00:13:54,790
already talked where you can see the

00:13:51,380 --> 00:13:58,640
current implementation status of the API

00:13:54,790 --> 00:14:00,920
so fortunately as long as the API isn't

00:13:58,640 --> 00:14:05,450
shipped with our modern browsers we can

00:14:00,920 --> 00:14:07,160
use the web via our polyfill and there

00:14:05,450 --> 00:14:10,209
are some small but really useful

00:14:07,160 --> 00:14:13,250
libraries that add support for the via

00:14:10,209 --> 00:14:22,250
controls and the stereoscopic rendering

00:14:13,250 --> 00:14:24,680
to free jayna's last but not least um we

00:14:22,250 --> 00:14:26,839
used that via our manager from the web

00:14:24,680 --> 00:14:29,839
via boilerplate by Boris mousse from

00:14:26,839 --> 00:14:33,649
Google which adds some basic cross

00:14:29,839 --> 00:14:36,649
browser support okay talking about cross

00:14:33,649 --> 00:14:38,959
browser support in a perfect world our

00:14:36,649 --> 00:14:41,420
prototype would work within every

00:14:38,959 --> 00:14:45,230
browser but of course with less features

00:14:41,420 --> 00:14:48,470
in older browsers so for example a

00:14:45,230 --> 00:14:51,079
browser not capable of WebGL would get a

00:14:48,470 --> 00:14:53,779
static image and the browser capable of

00:14:51,079 --> 00:14:55,730
WebGL would get a 3d WebGL application

00:14:53,779 --> 00:15:00,769
that works with the mouse or the

00:14:55,730 --> 00:15:03,079
keyboard then on mobile devices we want

00:15:00,769 --> 00:15:05,480
to make use of the touch input and more

00:15:03,079 --> 00:15:09,649
importantly the gyroscope to create a

00:15:05,480 --> 00:15:12,260
more engaging application and of course

00:15:09,649 --> 00:15:14,839
browser capable of fgf8 VR

00:15:12,260 --> 00:15:19,610
gets the full of a via application with

00:15:14,839 --> 00:15:22,579
all the web VR features one issue of

00:15:19,610 --> 00:15:26,420
WebGL and that VR apps is definitely the

00:15:22,579 --> 00:15:29,930
long loading time we have large textures

00:15:26,420 --> 00:15:32,029
images videos 3d models so you want to

00:15:29,930 --> 00:15:36,079
include mechanisms like progressive

00:15:32,029 --> 00:15:38,690
loading in your application now as

00:15:36,079 --> 00:15:39,779
you've seen here we not only use the web

00:15:38,690 --> 00:15:42,360
via our API

00:15:39,779 --> 00:15:45,300
but also the WebGL API to create this

00:15:42,360 --> 00:15:48,300
prototype and let me tell you you'll be

00:15:45,300 --> 00:15:51,389
using more api's to create a full web

00:15:48,300 --> 00:15:55,170
via our application first of all there's

00:15:51,389 --> 00:15:58,290
the gamepad API this has already shipped

00:15:55,170 --> 00:16:01,499
in modern browsers but it will get more

00:15:58,290 --> 00:16:04,680
features for handling we are specific

00:16:01,499 --> 00:16:08,550
inputs like for example the gamepad hand

00:16:04,680 --> 00:16:10,680
method to discover in which hand the

00:16:08,550 --> 00:16:12,749
gamepad lies or the gamepad pose

00:16:10,680 --> 00:16:15,389
interface to get the orientation

00:16:12,749 --> 00:16:19,860
velocity position and acceleration of

00:16:15,389 --> 00:16:23,129
the gamepad then there's also the Web

00:16:19,860 --> 00:16:26,670
Audio API we can use to create and add

00:16:23,129 --> 00:16:28,529
spatial sound to our application and the

00:16:26,670 --> 00:16:32,850
last API I want to mention is the web

00:16:28,529 --> 00:16:34,980
speech API you can use to avoid the very

00:16:32,850 --> 00:16:38,970
uncomfortable way of typing into a

00:16:34,980 --> 00:16:41,730
keyboard and we are well because I think

00:16:38,970 --> 00:16:43,620
you can all we can all agree to typing

00:16:41,730 --> 00:16:46,680
into a keyboard with the headset on or

00:16:43,620 --> 00:16:48,569
even worse I find it even worse clicking

00:16:46,680 --> 00:16:51,149
single Keys with a pointer on a digital

00:16:48,569 --> 00:16:55,649
keyboard is not the best way to make

00:16:51,149 --> 00:16:58,170
text input in VR these are only two

00:16:55,649 --> 00:17:00,209
examples um but I think overall we

00:16:58,170 --> 00:17:04,020
should talk about user experience design

00:17:00,209 --> 00:17:06,360
in VR application because the way users

00:17:04,020 --> 00:17:12,539
interact with a digital world changes

00:17:06,360 --> 00:17:15,600
dramatically in VR Bo Cronin I hope I

00:17:12,539 --> 00:17:17,939
spell his name right um Bo Cronin has

00:17:15,600 --> 00:17:21,990
created this hierarchy of needs in

00:17:17,939 --> 00:17:23,760
virtual reality which I find very

00:17:21,990 --> 00:17:26,010
compelling and a good guideline to

00:17:23,760 --> 00:17:29,940
prioritize our focus when we are

00:17:26,010 --> 00:17:33,570
creating VR apps so the hierarchy shows

00:17:29,940 --> 00:17:36,960
that the most important needs in VR our

00:17:33,570 --> 00:17:39,570
first comfort and interpretability and

00:17:36,960 --> 00:17:43,260
only afterwards comes usefulness and de

00:17:39,570 --> 00:17:45,149
lightness of an application so comfort

00:17:43,260 --> 00:17:48,140
means that a user can use your

00:17:45,149 --> 00:17:51,090
application without feeling unwell and

00:17:48,140 --> 00:17:53,310
interbred ability means that the virtual

00:17:51,090 --> 00:17:56,730
world feels convincing to the user

00:17:53,310 --> 00:17:59,010
if these both needs are satisfied the

00:17:56,730 --> 00:18:01,340
user will get the feeling of actually

00:17:59,010 --> 00:18:05,970
being present in this virtual world and

00:18:01,340 --> 00:18:08,580
this is what we want to achieve so we

00:18:05,970 --> 00:18:11,310
cannot talk about all needs um this is

00:18:08,580 --> 00:18:14,690
why I will focus on comfort and begin

00:18:11,310 --> 00:18:17,760
with some basic facts about ergonomics

00:18:14,690 --> 00:18:21,150
our we our application does not have a

00:18:17,760 --> 00:18:23,880
limited viewport on the contrary we have

00:18:21,150 --> 00:18:28,110
an infinite canvas and the user has only

00:18:23,880 --> 00:18:30,720
a limited field of view this field of

00:18:28,110 --> 00:18:33,920
view may change because the user can

00:18:30,720 --> 00:18:37,200
hide rotate her head and look around

00:18:33,920 --> 00:18:40,770
so some smart people found out how big

00:18:37,200 --> 00:18:43,710
this field of view actually is um if a

00:18:40,770 --> 00:18:46,800
user sitting she can see a 70 degree

00:18:43,710 --> 00:18:48,270
circle in front of her and then with

00:18:46,800 --> 00:18:51,720
turning the head to each side

00:18:48,270 --> 00:18:55,350
comfortably around 30 degree or with

00:18:51,720 --> 00:18:59,730
stretching max 80 degree the range

00:18:55,350 --> 00:19:02,670
increases to 230 degrees of course we

00:18:59,730 --> 00:19:04,890
could turn around and Bend much more but

00:19:02,670 --> 00:19:08,070
this means your main content should be

00:19:04,890 --> 00:19:11,490
within this range if you want to you

00:19:08,070 --> 00:19:15,660
have your user engaging with it without

00:19:11,490 --> 00:19:17,550
effort one other thing you have to

00:19:15,660 --> 00:19:20,040
remember is that we have the best depth

00:19:17,550 --> 00:19:23,010
experience if the content is not more

00:19:20,040 --> 00:19:25,950
than 20 meters away and not closer than

00:19:23,010 --> 00:19:27,660
half a meter though everything closer

00:19:25,950 --> 00:19:33,180
than 50 centimeters will make us

00:19:27,660 --> 00:19:34,770
cross-eyed and you don't want this since

00:19:33,180 --> 00:19:36,900
the device is at the moment have a

00:19:34,770 --> 00:19:39,480
relatively low amount of pixels per

00:19:36,900 --> 00:19:42,660
degree we also have to use large font

00:19:39,480 --> 00:19:46,440
sizes most designers agree that it

00:19:42,660 --> 00:19:49,530
should be you know over 20 pixels one

00:19:46,440 --> 00:19:51,960
word about PPD which means pixel fairly

00:19:49,530 --> 00:19:55,590
green the devices at the moment have

00:19:51,960 --> 00:19:57,300
around 10 PPD and a good resolution to

00:19:55,590 --> 00:20:00,420
not see any pixels anymore what with

00:19:57,300 --> 00:20:02,460
sixty pixels per degree so this is then

00:20:00,420 --> 00:20:06,800
the time you can stop worrying about

00:20:02,460 --> 00:20:06,800
anti lysing and use smaller font sizes

00:20:06,930 --> 00:20:11,370
now we know where to put our content to

00:20:09,480 --> 00:20:14,400
make it comfortably visible for the user

00:20:11,370 --> 00:20:18,300
what can we do more to make our users

00:20:14,400 --> 00:20:21,600
comfortable we can avoid eye strain by

00:20:18,300 --> 00:20:25,200
using darker colors and we can avoid

00:20:21,600 --> 00:20:27,870
focusing on different deaths we can also

00:20:25,200 --> 00:20:30,450
avoid creating environments that may

00:20:27,870 --> 00:20:32,940
trigger phobias like large empty rooms

00:20:30,450 --> 00:20:39,660
or rooms where you're standing on a

00:20:32,940 --> 00:20:42,590
stage or small rooms messy spaces hates

00:20:39,660 --> 00:20:47,430
and underwater environments for example

00:20:42,590 --> 00:20:49,470
also we should use correct scales and we

00:20:47,430 --> 00:20:51,870
do not want to move things fast towards

00:20:49,470 --> 00:20:55,890
the camera especially sharp or dangerous

00:20:51,870 --> 00:20:58,170
or pointy things also we do not want to

00:20:55,890 --> 00:21:01,400
attach things to any other camera so

00:20:58,170 --> 00:21:04,710
head-up displays are not a good idea

00:21:01,400 --> 00:21:06,480
then now what about the elephant in the

00:21:04,710 --> 00:21:08,880
room when we talk about virtual reality

00:21:06,480 --> 00:21:14,610
and comfort

00:21:08,880 --> 00:21:17,670
what about simulation sickness making a

00:21:14,610 --> 00:21:21,270
user sick causing him or her physical

00:21:17,670 --> 00:21:24,000
pain or making him or her even throw up

00:21:21,270 --> 00:21:28,620
is hopefully the last thing you want to

00:21:24,000 --> 00:21:32,030
do as would be well over now what can we

00:21:28,620 --> 00:21:34,800
do to avoid simulation sickness um

00:21:32,030 --> 00:21:37,560
simulation sickness or cures oh it's

00:21:34,800 --> 00:21:39,240
really dark single ation sickness occurs

00:21:37,560 --> 00:21:42,300
when our sensory inputs are not

00:21:39,240 --> 00:21:44,880
consistent which means for example when

00:21:42,300 --> 00:21:46,620
the simulation tells us we are in a car

00:21:44,880 --> 00:21:51,240
race and we are actually just sitting

00:21:46,620 --> 00:21:53,160
still in a room the best there are some

00:21:51,240 --> 00:21:55,380
best practices to avoid simulation

00:21:53,160 --> 00:21:59,250
sickness first of all don't use

00:21:55,380 --> 00:22:01,830
acceleration then don't move the horizon

00:21:59,250 --> 00:22:04,250
and do not force movement on the user

00:22:01,830 --> 00:22:08,240
which means do not move the camera if

00:22:04,250 --> 00:22:10,800
you want to create animated feel scenes

00:22:08,240 --> 00:22:14,010
you should allow additional head

00:22:10,800 --> 00:22:17,480
movement so for example put the camera

00:22:14,010 --> 00:22:20,380
on a dolly and then animate the dolly

00:22:17,480 --> 00:22:22,510
also keep always

00:22:20,380 --> 00:22:27,130
trekking and watch out for a low latency

00:22:22,510 --> 00:22:29,980
and a higher framerate avoid flicker and

00:22:27,130 --> 00:22:32,980
blur because they indicate movement and

00:22:29,980 --> 00:22:37,810
you may consider adding a stable focus

00:22:32,980 --> 00:22:41,320
point um your application should support

00:22:37,810 --> 00:22:47,980
short usage so savestates or make it

00:22:41,320 --> 00:22:49,900
offline capable and consider using more

00:22:47,980 --> 00:22:54,130
abstract patterns than realistic ones

00:22:49,900 --> 00:22:56,620
for example flying cartoon hints will

00:22:54,130 --> 00:22:59,350
work better than realistic arms and

00:22:56,620 --> 00:23:01,840
hands or another example is that a

00:22:59,350 --> 00:23:04,980
walking simulator will make more people

00:23:01,840 --> 00:23:08,140
sick than a flying spaceship simulator

00:23:04,980 --> 00:23:10,090
this is because we know really good how

00:23:08,140 --> 00:23:12,370
work you're walking should feel like and

00:23:10,090 --> 00:23:18,970
slight difference can make our brain

00:23:12,370 --> 00:23:21,250
confuse and the user feel unwell yeah we

00:23:18,970 --> 00:23:24,280
could talk about this all day but times

00:23:21,250 --> 00:23:28,000
flying by and we want to get back to the

00:23:24,280 --> 00:23:31,270
web and VR we are in a kind of similar

00:23:28,000 --> 00:23:33,520
situation like in 2007 or eight when the

00:23:31,270 --> 00:23:36,850
iPhone and with it the first mobile

00:23:33,520 --> 00:23:39,310
sites appeared back then we had to

00:23:36,850 --> 00:23:41,980
reconsider how we present our content on

00:23:39,310 --> 00:23:45,700
a small screen or on screens with

00:23:41,980 --> 00:23:47,230
various sizes and ratios and now we have

00:23:45,700 --> 00:23:50,080
to think about how we present our

00:23:47,230 --> 00:23:53,110
content when there's no more separation

00:23:50,080 --> 00:23:58,420
between the user and the application our

00:23:53,110 --> 00:24:01,240
users are finally in our applications so

00:23:58,420 --> 00:24:04,180
and my our company we try to get

00:24:01,240 --> 00:24:07,750
insights about this by using the example

00:24:04,180 --> 00:24:10,090
of a simple image gallery how would an

00:24:07,750 --> 00:24:14,830
image gallery look like if the user was

00:24:10,090 --> 00:24:17,650
in the application I think that the VR

00:24:14,830 --> 00:24:20,950
Web comes hand-in-hand with losing our

00:24:17,650 --> 00:24:23,200
UX design metaphors because we all agree

00:24:20,950 --> 00:24:27,640
that an image gallery of course would be

00:24:23,200 --> 00:24:30,130
a gallery with images in it so this is

00:24:27,640 --> 00:24:31,320
our application a user can look around

00:24:30,130 --> 00:24:35,940
and

00:24:31,320 --> 00:24:38,280
and see all the images from try it it's

00:24:35,940 --> 00:24:40,470
a prototype but you can try it I will

00:24:38,280 --> 00:24:44,550
give you the URL also at the end of the

00:24:40,470 --> 00:24:45,440
talk okay let me ask you one last

00:24:44,550 --> 00:24:49,770
question

00:24:45,440 --> 00:24:51,840
what about the future at the moment

00:24:49,770 --> 00:24:53,610
there are some smart people developing

00:24:51,840 --> 00:24:57,420
the API and they are also thinking about

00:24:53,610 --> 00:24:59,940
making the VR web usable without WebGL

00:24:57,420 --> 00:25:02,910
and JavaScript but only with HTML and

00:24:59,940 --> 00:25:05,550
CSS for example we could think about

00:25:02,910 --> 00:25:08,460
making our websites visible in a 3d

00:25:05,550 --> 00:25:11,310
space and let the developer decide with

00:25:08,460 --> 00:25:15,240
CSS how the spherical image around the

00:25:11,310 --> 00:25:18,390
user should look like or like a frame

00:25:15,240 --> 00:25:21,210
desert we could think about um text for

00:25:18,390 --> 00:25:24,630
3d graphics that contain also the

00:25:21,210 --> 00:25:28,520
textures and the animations or what

00:25:24,630 --> 00:25:31,110
about media queries for VR user agents

00:25:28,520 --> 00:25:33,780
there are no actual proposals at the

00:25:31,110 --> 00:25:36,090
moment for these mechanisms but I think

00:25:33,780 --> 00:25:38,760
we should keep in mind that the VR web

00:25:36,090 --> 00:25:44,760
is not uniquely defined it yet and you

00:25:38,760 --> 00:25:47,430
all can be part of shaping it so if you

00:25:44,760 --> 00:25:49,230
like it or not as a developer or a

00:25:47,430 --> 00:25:51,450
designer you are at least partly

00:25:49,230 --> 00:25:55,790
responsible for the well-being of your

00:25:51,450 --> 00:25:58,500
users and with a VR web you might not be

00:25:55,790 --> 00:26:02,250
responsible only for a low-battery or

00:25:58,500 --> 00:26:05,130
higher telephony costs anymore with a VR

00:26:02,250 --> 00:26:07,470
web sorry with a via web you could cause

00:26:05,130 --> 00:26:11,490
like a set actual physical and

00:26:07,470 --> 00:26:14,780
psychological pain to the user we talked

00:26:11,490 --> 00:26:20,640
about throwing up we could also imagine

00:26:14,780 --> 00:26:24,270
like running into walls or falling which

00:26:20,640 --> 00:26:27,120
is also what I was afraid to come here

00:26:24,270 --> 00:26:28,350
on stage when I think about it but let's

00:26:27,120 --> 00:26:30,990
be serious

00:26:28,350 --> 00:26:33,600
um even worse we could trigger

00:26:30,990 --> 00:26:36,210
paranoia's and not prevent that scary or

00:26:33,600 --> 00:26:39,960
abusive material appears directly in

00:26:36,210 --> 00:26:43,170
front of users eye um this is all way

00:26:39,960 --> 00:26:44,730
more serious in 3d where we try to make

00:26:43,170 --> 00:26:46,559
our users think that they are in

00:26:44,730 --> 00:26:50,520
another world and then this world is

00:26:46,559 --> 00:26:53,309
violent and hurts them so there is a

00:26:50,520 --> 00:26:55,950
study I read about and that lets people

00:26:53,309 --> 00:26:58,740
in VR appear superhero and then put

00:26:55,950 --> 00:27:00,990
these people and other people in a

00:26:58,740 --> 00:27:05,070
situation where someone needed to help

00:27:00,990 --> 00:27:07,530
picking up drop pencils and the people

00:27:05,070 --> 00:27:09,840
who were a superhero in via actually

00:27:07,530 --> 00:27:13,320
helped more often and faster than the

00:27:09,840 --> 00:27:15,960
others so you see that your content and

00:27:13,320 --> 00:27:19,200
how it is presented matters and this is

00:27:15,960 --> 00:27:23,640
why you all matter so be responsible and

00:27:19,200 --> 00:27:26,040
be aware of this yeah I have many

00:27:23,640 --> 00:27:28,380
resources for you and the slides and

00:27:26,040 --> 00:27:30,450
also a list with interesting people you

00:27:28,380 --> 00:27:34,650
could follow if you're interested in web

00:27:30,450 --> 00:27:36,540
PR and this is the URL to the slides and

00:27:34,650 --> 00:27:38,610
the prototype and there's also a

00:27:36,540 --> 00:27:42,330
newsletter about where we are if you

00:27:38,610 --> 00:27:42,580
like subscribe to it that's all thank

00:27:42,330 --> 00:27:47,589
you

00:27:42,580 --> 00:27:47,589

YouTube URL: https://www.youtube.com/watch?v=3D0xhZwo1vM


