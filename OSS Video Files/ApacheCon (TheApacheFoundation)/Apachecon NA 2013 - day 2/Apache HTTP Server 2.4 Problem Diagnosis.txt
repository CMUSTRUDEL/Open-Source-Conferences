Title: Apache HTTP Server 2.4 Problem Diagnosis
Publication date: 2013-10-17
Playlist: Apachecon NA 2013 - day 2
Description: 
	Jeff Trawick
ApacheCon NA 2013
A Patchy Web
Captions: 
	00:00:00,110 --> 00:00:05,970
welcome everyone please take a seat we

00:00:03,570 --> 00:00:14,719
have drift Jeff trake with Apache HTTP

00:00:05,970 --> 00:00:14,719
server 2.4 problem diagnosis hello there

00:00:15,199 --> 00:00:19,380
hi first thing we want to tell you is uh

00:00:17,550 --> 00:00:21,180
you might want to well you probably

00:00:19,380 --> 00:00:23,820
wanna get a copy of these slides because

00:00:21,180 --> 00:00:25,439
I have a lot of slides to go through I'm

00:00:23,820 --> 00:00:29,640
gonna gloss over some of them some of

00:00:25,439 --> 00:00:31,140
them are very simple recipes right so

00:00:29,640 --> 00:00:32,910
the site won't be on the screen long

00:00:31,140 --> 00:00:35,250
enough to copy down all the little

00:00:32,910 --> 00:00:36,300
configuration directives so I'm gonna

00:00:35,250 --> 00:00:37,739
try to spend more time on the

00:00:36,300 --> 00:00:38,100
interesting things but we'll see how

00:00:37,739 --> 00:00:41,309
that goes

00:00:38,100 --> 00:00:43,440
and you know if you have a question like

00:00:41,309 --> 00:00:44,579
a short question that pertains to what

00:00:43,440 --> 00:00:46,680
we're talking about you know walk

00:00:44,579 --> 00:00:49,739
towards a mic and eventually I'll see

00:00:46,680 --> 00:00:52,739
you otherwise I hope we have more time

00:00:49,739 --> 00:00:55,530
at the end for more interesting things

00:00:52,739 --> 00:00:59,250
ok so here the slides my name is Jeff

00:00:55,530 --> 00:01:01,829
Trawick I've worked on httpd for about

00:00:59,250 --> 00:01:05,369
13 years now most of that time I work

00:01:01,829 --> 00:01:07,640
for large corporations that had you know

00:01:05,369 --> 00:01:10,850
long term support for this software and

00:01:07,640 --> 00:01:13,799
you know customers that expected help

00:01:10,850 --> 00:01:16,290
spend a lot of time on just countless

00:01:13,799 --> 00:01:18,570
customer problems so obviously I'm very

00:01:16,290 --> 00:01:22,080
interested in in what are the tools and

00:01:18,570 --> 00:01:25,890
techniques for diagnosing problems and

00:01:22,080 --> 00:01:27,840
I've had some efforts to kind of extend

00:01:25,890 --> 00:01:29,369
you know kind of stretch out what the

00:01:27,840 --> 00:01:32,159
diagnostic the inbuilt

00:01:29,369 --> 00:01:33,810
diagnostic capabilities are so we'll

00:01:32,159 --> 00:01:38,009
look at some of these projects or

00:01:33,810 --> 00:01:39,479
experiments later in the talk and a lot

00:01:38,009 --> 00:01:42,600
of things we're going to talk about are

00:01:39,479 --> 00:01:48,180
just basic 2.4 capabilities out of the

00:01:42,600 --> 00:01:49,920
box and I real not go spend a lot of

00:01:48,180 --> 00:01:51,780
time on some of these boring slides but

00:01:49,920 --> 00:01:54,990
right we're you know problem symptoms

00:01:51,780 --> 00:01:58,500
right crashes or server hangs or certain

00:01:54,990 --> 00:02:01,290
requests hang things terminate abruptly

00:01:58,500 --> 00:02:05,640
bad response time high resource

00:02:01,290 --> 00:02:07,920
consumption bad output you know these

00:02:05,640 --> 00:02:10,229
are all the kind of things that make you

00:02:07,920 --> 00:02:12,590
want to look at look at logs look inside

00:02:10,229 --> 00:02:15,470
the server etc

00:02:12,590 --> 00:02:17,630
also non problems right you have a new

00:02:15,470 --> 00:02:20,569
application or new web server setup

00:02:17,630 --> 00:02:23,870
you've deployed you know run through

00:02:20,569 --> 00:02:25,760
your normal user regression test and see

00:02:23,870 --> 00:02:27,530
at different log levels see what the

00:02:25,760 --> 00:02:30,020
logs look like when everything is

00:02:27,530 --> 00:02:32,390
supposedly working properly then when

00:02:30,020 --> 00:02:33,050
you do have a one of those unfortunate

00:02:32,390 --> 00:02:35,600
weekend

00:02:33,050 --> 00:02:38,480
things and you see something in the log

00:02:35,600 --> 00:02:40,550
go back to your you know logs you've

00:02:38,480 --> 00:02:43,400
saved from a good run and see if they

00:02:40,550 --> 00:02:46,070
are there in the same frequency or order

00:02:43,400 --> 00:02:47,989
or whatever right so looking inside the

00:02:46,070 --> 00:02:49,100
server or looking at logs it creates is

00:02:47,989 --> 00:02:51,440
a good thing

00:02:49,100 --> 00:02:57,250
even in a good situation to understand

00:02:51,440 --> 00:03:00,530
what it is you've deployed let's see

00:02:57,250 --> 00:03:03,500
something to be really aware with

00:03:00,530 --> 00:03:05,300
logging is what kind of information gets

00:03:03,500 --> 00:03:08,569
logged as you turn up the trace level as

00:03:05,300 --> 00:03:12,230
you use additional you know non-standard

00:03:08,569 --> 00:03:15,050
log files in particular we have

00:03:12,230 --> 00:03:16,640
passwords and session keys and a lot of

00:03:15,050 --> 00:03:19,640
other confidential information that

00:03:16,640 --> 00:03:22,910
could be stored in the log files right

00:03:19,640 --> 00:03:25,880
so you know depending on your access to

00:03:22,910 --> 00:03:28,340
the logs your retention policies for the

00:03:25,880 --> 00:03:30,620
logs and you know part of retention is

00:03:28,340 --> 00:03:32,510
is who gets access to it somewhere else

00:03:30,620 --> 00:03:35,510
once it's offline from the web server

00:03:32,510 --> 00:03:37,340
right this could cause huge problems and

00:03:35,510 --> 00:03:39,019
you may get into a situation where you

00:03:37,340 --> 00:03:42,200
have to tell all your users to change

00:03:39,019 --> 00:03:44,120
their passwords because a period of time

00:03:42,200 --> 00:03:47,780
elapsed after which you realize that

00:03:44,120 --> 00:03:49,790
these critical information or private

00:03:47,780 --> 00:03:51,890
information had been available to a

00:03:49,790 --> 00:03:57,650
number of people that you can't really

00:03:51,890 --> 00:04:00,220
count or name so mod dump IO I mean just

00:03:57,650 --> 00:04:04,010
about always it's gonna potentially log

00:04:00,220 --> 00:04:06,790
private data my log config can be

00:04:04,010 --> 00:04:10,790
configured to do that my log forensic

00:04:06,790 --> 00:04:13,250
you know basic HTTP D when you turn up

00:04:10,790 --> 00:04:16,519
the log levels and we'll look at some of

00:04:13,250 --> 00:04:19,519
the cases where that can appear okay

00:04:16,519 --> 00:04:22,760
maybe you've got to see Rich's talk

00:04:19,519 --> 00:04:24,409
yesterday about new 2.4 features one of

00:04:22,760 --> 00:04:26,020
the great things is that air log is

00:04:24,409 --> 00:04:30,140
configurable

00:04:26,020 --> 00:04:33,710
modules can implement their own fields

00:04:30,140 --> 00:04:35,750
in the air log and you know when

00:04:33,710 --> 00:04:38,120
information is not available for a

00:04:35,750 --> 00:04:40,970
certain field that field can be dropped

00:04:38,120 --> 00:04:43,790
altogether you know see here is a

00:04:40,970 --> 00:04:46,610
typical message we have a timestamp with

00:04:43,790 --> 00:04:49,100
sub-second accuracy or precision I

00:04:46,610 --> 00:04:52,060
should say we're supposed to have the

00:04:49,100 --> 00:04:58,190
module ID where you see that - : error

00:04:52,060 --> 00:05:01,820
that's actually my WSGI and you know kid

00:04:58,190 --> 00:05:04,070
thread ID etc and some of this if you

00:05:01,820 --> 00:05:06,140
look at the model usgi portion of the

00:05:04,070 --> 00:05:08,810
message that stuff that it had explicit

00:05:06,140 --> 00:05:10,610
code to add you know basically for

00:05:08,810 --> 00:05:12,980
working with older versions of Apache

00:05:10,610 --> 00:05:15,670
right it has its module name even though

00:05:12,980 --> 00:05:18,020
that should appear in a trace field it

00:05:15,670 --> 00:05:20,390
puts the pit in there even though that

00:05:18,020 --> 00:05:22,460
appears automatically right so over time

00:05:20,390 --> 00:05:24,170
we'll see that just like the core bundle

00:05:22,460 --> 00:05:26,270
the bundled modules right these

00:05:24,170 --> 00:05:28,970
third-party modules will be updated to

00:05:26,270 --> 00:05:31,220
better utilize the new heir log

00:05:28,970 --> 00:05:33,280
capabilities not duplicate information

00:05:31,220 --> 00:05:37,310
and so forth

00:05:33,280 --> 00:05:38,900
now here's a little trick we probably

00:05:37,310 --> 00:05:40,820
saw something similar to this yesterday

00:05:38,900 --> 00:05:43,090
at Rich's talk you know what if you want

00:05:40,820 --> 00:05:45,710
to log only for the specified client IP

00:05:43,090 --> 00:05:49,100
right so globally we have a log level

00:05:45,710 --> 00:05:52,130
info and we say if the remote address

00:05:49,100 --> 00:05:54,620
came from some loopback ipv4 loopback

00:05:52,130 --> 00:05:58,160
device then we're going to crank the log

00:05:54,620 --> 00:05:59,510
level up to trace eight and you know

00:05:58,160 --> 00:06:01,790
there's a little blurb at the bottom of

00:05:59,510 --> 00:06:02,510
about why it has to appear in a location

00:06:01,790 --> 00:06:05,710
container

00:06:02,510 --> 00:06:08,900
I believe Stefon fridge fixed that and

00:06:05,710 --> 00:06:11,150
I'm not sure if it's in 244 or not right

00:06:08,900 --> 00:06:13,820
this is this will work in all the to

00:06:11,150 --> 00:06:17,470
four levels it just you know maybe a

00:06:13,820 --> 00:06:17,470
little bit simpler with two four four

00:06:18,470 --> 00:06:24,200
maybe there's a certain URI sorting

00:06:21,530 --> 00:06:26,270
portion of the web space that you want

00:06:24,200 --> 00:06:28,370
to have more detailed logging on some

00:06:26,270 --> 00:06:30,770
application that you've just deployed

00:06:28,370 --> 00:06:33,020
it's not quite working right right we

00:06:30,770 --> 00:06:36,260
can crank up the trace level to the max

00:06:33,020 --> 00:06:38,770
just for that you know just for those

00:06:36,260 --> 00:06:38,770
requests

00:06:40,459 --> 00:06:47,059
also just the core HDTV D has logging of

00:06:43,969 --> 00:06:49,879
HTTP data at different layers you can

00:06:47,059 --> 00:06:52,729
see you know basic summary of the

00:06:49,879 --> 00:06:57,769
requests or headers received from the

00:06:52,729 --> 00:06:59,329
client the response headers sent to the

00:06:57,769 --> 00:07:01,699
client right and they have slightly

00:06:59,329 --> 00:07:03,559
different trace levels but you know log

00:07:01,699 --> 00:07:04,939
level debug is not going to show any of

00:07:03,559 --> 00:07:09,619
these right you have to have at least

00:07:04,939 --> 00:07:12,799
log level trace 3 for the HTTP module in

00:07:09,619 --> 00:07:17,329
order to see that and you need four or

00:07:12,799 --> 00:07:19,519
five for the other data so this this is

00:07:17,329 --> 00:07:22,819
kind of stuff that you might have needed

00:07:19,519 --> 00:07:25,369
to run a packet trace on with previous

00:07:22,819 --> 00:07:29,269
levels right because there wasn't a

00:07:25,369 --> 00:07:33,349
capability to trace all of this data you

00:07:29,269 --> 00:07:34,849
know with a basic server feature mod log

00:07:33,349 --> 00:07:37,399
debug is a new module it's kind of

00:07:34,849 --> 00:07:39,199
interesting you know normally when we

00:07:37,399 --> 00:07:40,759
see messages in the air log right

00:07:39,199 --> 00:07:43,099
those messages are baked into the

00:07:40,759 --> 00:07:47,059
binaries right somebody had to write

00:07:43,099 --> 00:07:50,839
code to say at this point in my module

00:07:47,059 --> 00:07:53,479
processing I want to log some summary of

00:07:50,839 --> 00:07:55,669
what happened right but mod log debug

00:07:53,479 --> 00:07:59,569
gives you some flexibility as an

00:07:55,669 --> 00:08:01,999
administrator to enable messages right

00:07:59,569 --> 00:08:05,629
so we'll look at a couple of examples of

00:08:01,999 --> 00:08:08,419
the log message directive right so let's

00:08:05,629 --> 00:08:11,089
say that there's some module and it uses

00:08:08,419 --> 00:08:15,139
request notes internally to track state

00:08:11,089 --> 00:08:16,939
or some kind of correlator right so the

00:08:15,139 --> 00:08:20,269
administrator can say I want to log a

00:08:16,939 --> 00:08:22,369
message that shows that request note and

00:08:20,269 --> 00:08:24,769
when do I want to log it I'm going to

00:08:22,369 --> 00:08:26,689
log it basically at every phase of

00:08:24,769 --> 00:08:30,589
process request processing and that's

00:08:26,689 --> 00:08:32,779
what's hook equal all means and

00:08:30,589 --> 00:08:34,849
furthermore I can say I want to log it

00:08:32,779 --> 00:08:37,579
only if that expression is true and that

00:08:34,849 --> 00:08:40,399
expression checks that you know that

00:08:37,579 --> 00:08:41,990
note is actually sent so if the module

00:08:40,399 --> 00:08:44,839
doesn't handle that request the note

00:08:41,990 --> 00:08:47,050
wouldn't be set if the module only sets

00:08:44,839 --> 00:08:49,519
that at a later phase then you won't see

00:08:47,050 --> 00:08:51,140
you know the uninteresting lines in the

00:08:49,519 --> 00:08:54,360
log before then

00:08:51,140 --> 00:08:57,660
you know here's another example where

00:08:54,360 --> 00:09:00,120
you know may have you issue with mod

00:08:57,660 --> 00:09:01,800
include and included resources might

00:09:00,120 --> 00:09:05,040
include uses something called sub

00:09:01,800 --> 00:09:09,420
request issue those the requests to pull

00:09:05,040 --> 00:09:12,470
in the embedded documents right so you

00:09:09,420 --> 00:09:15,480
could have a log message directive that

00:09:12,470 --> 00:09:17,400
that prints information about you know

00:09:15,480 --> 00:09:21,510
request a certain resources was

00:09:17,400 --> 00:09:24,990
problematic for whatever reason or we

00:09:21,510 --> 00:09:26,760
can do you know here's a case I'm not

00:09:24,990 --> 00:09:29,070
sure exactly why we would want this but

00:09:26,760 --> 00:09:31,740
we catch a certain request error code

00:09:29,070 --> 00:09:34,740
and we're logging some arbitrary

00:09:31,740 --> 00:09:36,780
information about the request you know

00:09:34,740 --> 00:09:39,000
and remote editor might not be a good

00:09:36,780 --> 00:09:40,650
example because that's in the access log

00:09:39,000 --> 00:09:43,560
anyway but you know we could pull out

00:09:40,650 --> 00:09:49,080
some other aspect of the request that's

00:09:43,560 --> 00:09:51,630
not logged by default and you know that

00:09:49,080 --> 00:09:54,600
that uses the new expression capability

00:09:51,630 --> 00:09:57,390
in - for so the same variables same

00:09:54,600 --> 00:10:00,470
syntax that you could use with certain

00:09:57,390 --> 00:10:03,330
SSL directives and a lot of other stuff

00:10:00,470 --> 00:10:06,270
ok mod dump IO this has been a while

00:10:03,330 --> 00:10:09,270
been around for a while has a very

00:10:06,270 --> 00:10:11,400
simple configuration put a few

00:10:09,270 --> 00:10:15,740
directives in there in to four you'd say

00:10:11,400 --> 00:10:18,330
I want dump iota trace at level trace 7

00:10:15,740 --> 00:10:21,720
and I wouldn't have to turn up the noise

00:10:18,330 --> 00:10:25,020
for everything else and you know this is

00:10:21,720 --> 00:10:27,330
just an example of what you can see and

00:10:25,020 --> 00:10:29,310
you see the request you can see the data

00:10:27,330 --> 00:10:31,340
sent and received right that's that's

00:10:29,310 --> 00:10:35,490
one thing like the connection keep alive

00:10:31,340 --> 00:10:38,850
the request line the get slash Durer it

00:10:35,490 --> 00:10:41,670
also for studying the internal flows

00:10:38,850 --> 00:10:43,410
within httpd right you can tell a little

00:10:41,670 --> 00:10:45,990
bit more about the processing such as

00:10:43,410 --> 00:10:48,290
what kind of memory structure that was

00:10:45,990 --> 00:10:51,480
stored in and how many bytes long it is

00:10:48,290 --> 00:10:55,350
but this is often used to to get the

00:10:51,480 --> 00:10:59,160
line flow above the SSL layer without

00:10:55,350 --> 00:11:00,720
using a packet trace and you know packet

00:10:59,160 --> 00:11:02,860
trace with SSL is a pain right because

00:11:00,720 --> 00:11:09,100
you have to have the certificates and

00:11:02,860 --> 00:11:10,990
all that stuff to unencrypt it caching

00:11:09,100 --> 00:11:14,830
requests which do not finish mod log

00:11:10,990 --> 00:11:18,850
forensic right so a crash is really the

00:11:14,830 --> 00:11:22,360
typical case here web server child

00:11:18,850 --> 00:11:24,280
process crashed presumably some request

00:11:22,360 --> 00:11:28,660
was being processed at the time that

00:11:24,280 --> 00:11:31,540
triggered a bug right so in order to

00:11:28,660 --> 00:11:35,110
track what was going on there one way

00:11:31,540 --> 00:11:39,460
with log forensic is you know turn it on

00:11:35,110 --> 00:11:40,990
it records a special line in its log at

00:11:39,460 --> 00:11:42,640
the beginning of the request and another

00:11:40,990 --> 00:11:45,490
line at the end of the request that says

00:11:42,640 --> 00:11:48,040
hey that other thing is done right so

00:11:45,490 --> 00:11:50,860
after a crash if you run this log

00:11:48,040 --> 00:11:53,380
scanner check forensic right it will

00:11:50,860 --> 00:11:57,130
find the beginning of the request things

00:11:53,380 --> 00:11:59,260
that we're never ended and and you'll

00:11:57,130 --> 00:12:01,570
see some you know maybe it's just one

00:11:59,260 --> 00:12:03,190
and that's the bad guy or maybe you'll

00:12:01,570 --> 00:12:05,200
see some candidate it's a small set of

00:12:03,190 --> 00:12:09,040
candidates for what request triggered

00:12:05,200 --> 00:12:12,760
the crash if you had a like a threaded

00:12:09,040 --> 00:12:16,810
child processed like event or worker you

00:12:12,760 --> 00:12:19,480
know when one request triggers the crash

00:12:16,810 --> 00:12:21,180
right gets processed by bad code and the

00:12:19,480 --> 00:12:24,700
child process crashes you might have

00:12:21,180 --> 00:12:26,080
four or forty other requests being

00:12:24,700 --> 00:12:27,700
processed at the same time by that

00:12:26,080 --> 00:12:31,110
process so you might get a lot of

00:12:27,700 --> 00:12:35,440
candidates here for which one actually

00:12:31,110 --> 00:12:37,840
caused the crash I'm tracking where the

00:12:35,440 --> 00:12:40,570
error message came from this has been

00:12:37,840 --> 00:12:42,760
you know a mystery for a long time that

00:12:40,570 --> 00:12:46,900
I think the bundled modules with httpd

00:12:42,760 --> 00:12:48,580
were were pretty pretty good about well

00:12:46,900 --> 00:12:50,800
the thing is you have the source code

00:12:48,580 --> 00:12:52,870
for all of those always right so you can

00:12:50,800 --> 00:12:55,630
go search through the cert search

00:12:52,870 --> 00:12:58,720
through the source for the text of the

00:12:55,630 --> 00:13:01,870
message sometimes you have third party

00:12:58,720 --> 00:13:04,120
code and you wonder where the message

00:13:01,870 --> 00:13:06,670
came from sometimes you can find the

00:13:04,120 --> 00:13:07,930
strings in the binaries other times you

00:13:06,670 --> 00:13:09,670
know they've glued together so many

00:13:07,930 --> 00:13:13,370
different pieces it's not trivial to

00:13:09,670 --> 00:13:17,840
find that way but we should have the

00:13:13,370 --> 00:13:20,330
July D for that with 2.4 Anna you know

00:13:17,840 --> 00:13:23,270
there was more WSGI messages some that

00:13:20,330 --> 00:13:25,580
you know in the mod WSGI you've included

00:13:23,270 --> 00:13:27,560
the module ID others were its logging

00:13:25,580 --> 00:13:29,150
output from standard error output from

00:13:27,560 --> 00:13:31,430
the script right it just logged the

00:13:29,150 --> 00:13:34,100
output and didn't put the ID but

00:13:31,430 --> 00:13:39,260
hopefully that'll be that fix will be

00:13:34,100 --> 00:13:41,660
included soon what else ok this is kind

00:13:39,260 --> 00:13:45,860
of this is kind of hacky it's just a

00:13:41,660 --> 00:13:47,690
maybe just in the experimental set but

00:13:45,860 --> 00:13:49,490
you know sometimes you get an error

00:13:47,690 --> 00:13:52,460
message that's written by utility

00:13:49,490 --> 00:13:54,890
retained right that says a caller

00:13:52,460 --> 00:13:57,590
utility and some kind of error happened

00:13:54,890 --> 00:13:59,090
and here's the message but you really

00:13:57,590 --> 00:14:02,570
want to know what the color of the

00:13:59,090 --> 00:14:05,630
utility was so mod back-trace which is

00:14:02,570 --> 00:14:08,180
an unbundled module third-party module

00:14:05,630 --> 00:14:10,310
has a capability of putting the back

00:14:08,180 --> 00:14:13,250
trace information in an error log field

00:14:10,310 --> 00:14:16,220
and in this case you know we have our

00:14:13,250 --> 00:14:18,500
regular you know 2.4 error log format

00:14:16,220 --> 00:14:21,970
directive and somewhere in that

00:14:18,500 --> 00:14:25,280
directive it uses the percent capital B

00:14:21,970 --> 00:14:28,160
format field and that's for mod

00:14:25,280 --> 00:14:30,590
back-trace and in this case we pass mod

00:14:28,160 --> 00:14:32,510
back-trace this parameter you know aah

00:14:30,590 --> 00:14:36,280
zero zero one two eight and that tells

00:14:32,510 --> 00:14:39,350
it hey if if that string is which is a

00:14:36,280 --> 00:14:43,730
httpd message ID is in the message then

00:14:39,350 --> 00:14:46,070
replace this field with a representation

00:14:43,730 --> 00:14:47,750
of the back trace and of course if it

00:14:46,070 --> 00:14:51,080
doesn't appear there then that field

00:14:47,750 --> 00:14:53,300
won't even show up in the air' log and

00:14:51,080 --> 00:14:55,130
unfortunately this example I didn't have

00:14:53,300 --> 00:14:57,310
any symbols available so you don't see

00:14:55,130 --> 00:15:00,560
any function names for the back trace

00:14:57,310 --> 00:15:02,960
but that could you know that could show

00:15:00,560 --> 00:15:05,660
up better or of course on the other hand

00:15:02,960 --> 00:15:08,000
it would show up much longer with actual

00:15:05,660 --> 00:15:09,680
function names but that would be a way

00:15:08,000 --> 00:15:13,910
to track down what module did it right

00:15:09,680 --> 00:15:16,040
take a map of memory to show which you

00:15:13,910 --> 00:15:18,230
know DSOs were loaded which address and

00:15:16,040 --> 00:15:20,740
there you go you can find out what

00:15:18,230 --> 00:15:24,130
offset from a particular module

00:15:20,740 --> 00:15:24,130
generated the call

00:15:25,090 --> 00:15:30,470
okay let's see resource use we're not

00:15:28,580 --> 00:15:34,400
going to talk about this much just you

00:15:30,470 --> 00:15:36,380
know IO stat vmstat even PS can be told

00:15:34,400 --> 00:15:38,420
to display a bunch of interesting fields

00:15:36,380 --> 00:15:41,590
you know windows you have the process

00:15:38,420 --> 00:15:47,450
Explorer that can show IO activity and

00:15:41,590 --> 00:15:50,180
CPU usage and stuff like that system

00:15:47,450 --> 00:15:51,920
called traces s trace trusts anywhere

00:15:50,180 --> 00:15:56,900
you have D trace you have the deep trust

00:15:51,920 --> 00:16:01,520
command Matt Goss Mac OS 10 FreeBSD

00:15:56,900 --> 00:16:03,080
Solaris ok some more interesting things

00:16:01,520 --> 00:16:05,030
we'll spend a lot more time on this

00:16:03,080 --> 00:16:08,270
looking inside of the process with a

00:16:05,030 --> 00:16:12,620
debugger like gdb or something like P

00:16:08,270 --> 00:16:14,930
stack on Solaris right so for certain

00:16:12,620 --> 00:16:16,820
types of problem symptoms you know you

00:16:14,930 --> 00:16:18,980
report that in the Apache bug database

00:16:16,820 --> 00:16:21,860
we're gonna say well hey go you know use

00:16:18,980 --> 00:16:24,410
gdb or P stack and get get some basic

00:16:21,860 --> 00:16:30,050
information which is the back-trace to

00:16:24,410 --> 00:16:31,460
the to the crashing code also dbx if

00:16:30,050 --> 00:16:34,370
you're on AIX right you're probably

00:16:31,460 --> 00:16:37,610
gonna use DB x for this same same basic

00:16:34,370 --> 00:16:40,580
idea and the kind of information that's

00:16:37,610 --> 00:16:43,610
good you know I think both of these are

00:16:40,580 --> 00:16:45,740
kind of equivalent for using gdb on most

00:16:43,610 --> 00:16:47,990
platforms versus using the proc tools on

00:16:45,740 --> 00:16:50,990
Solaris you get the back-trace of all

00:16:47,990 --> 00:16:56,080
the threads you get kind of a listing of

00:16:50,990 --> 00:16:59,120
all the threads you see we're all of the

00:16:56,080 --> 00:17:03,230
modules are loaded you know in the

00:16:59,120 --> 00:17:06,170
address space and I think on think only

00:17:03,230 --> 00:17:08,360
for the gdb example will also have a

00:17:06,170 --> 00:17:11,510
little bit of code around the program

00:17:08,360 --> 00:17:13,730
counter so sometimes you can tell a bit

00:17:11,510 --> 00:17:16,670
about the base looking at the

00:17:13,730 --> 00:17:18,860
instruction where the where a crash

00:17:16,670 --> 00:17:20,630
occurred or otherwise we're the

00:17:18,860 --> 00:17:24,970
instruction where you've called in to

00:17:20,630 --> 00:17:24,970
some system call that's blocking

00:17:25,880 --> 00:17:30,740
okay so let's see you know if we do

00:17:28,459 --> 00:17:38,900
these commands what kind of Gorp do we

00:17:30,740 --> 00:17:41,419
get I'm gonna switch to an editor let's

00:17:38,900 --> 00:17:45,289
see so this is this is a Solaris example

00:17:41,419 --> 00:17:47,900
with a pea stack right and says hey we

00:17:45,289 --> 00:17:51,350
got a thread here's thread 1 and that's

00:17:47,900 --> 00:17:52,880
its back trace and assuming it has a

00:17:51,350 --> 00:17:54,890
certain number of parameters right we've

00:17:52,880 --> 00:17:58,610
got the hex for those parameters and the

00:17:54,890 --> 00:18:03,010
offset from the function entry point you

00:17:58,610 --> 00:18:06,049
know like the +26 dog or plus 3 abel and

00:18:03,010 --> 00:18:07,490
oh here's another thread and i mean if

00:18:06,049 --> 00:18:08,780
you look at these a million times right

00:18:07,490 --> 00:18:10,700
you know that that's a thread that

00:18:08,780 --> 00:18:14,230
starts up at initialization and then

00:18:10,700 --> 00:18:16,700
exits so P stack shows it as a zombie

00:18:14,230 --> 00:18:19,730
now I've got all this boatload of other

00:18:16,700 --> 00:18:21,380
things and you know if you stare at it

00:18:19,730 --> 00:18:24,620
long enough and you know the code you

00:18:21,380 --> 00:18:27,909
say well we got I don't know 20 for idle

00:18:24,620 --> 00:18:32,179
worker threads doing nothing and we have

00:18:27,909 --> 00:18:33,830
one thread I think it's thread 9 look

00:18:32,179 --> 00:18:35,929
here's a here's a thread that's actually

00:18:33,830 --> 00:18:37,820
running you know supposed to supposedly

00:18:35,929 --> 00:18:41,710
generating the response for the request

00:18:37,820 --> 00:18:44,090
and it called some code crash handler

00:18:41,710 --> 00:18:46,970
which called another function with crash

00:18:44,090 --> 00:18:49,429
in the name you know wouldn't it be nice

00:18:46,970 --> 00:18:51,679
if all the code out there would call the

00:18:49,429 --> 00:18:55,400
function crash underscore something when

00:18:51,679 --> 00:18:59,179
it but that's a kind of artificial

00:18:55,400 --> 00:19:04,750
situation obviously okay let's see gdb

00:18:59,179 --> 00:19:08,929
equivalent okay in this case I'm run gdb

00:19:04,750 --> 00:19:11,000
against a core file I've got this is

00:19:08,929 --> 00:19:13,820
from the info shared library message

00:19:11,000 --> 00:19:16,220
right so I see definitively all the all

00:19:13,820 --> 00:19:18,200
the system libraries all the bundled

00:19:16,220 --> 00:19:21,980
modules all the third-party modules that

00:19:18,200 --> 00:19:24,830
got loaded into httpd and what address

00:19:21,980 --> 00:19:26,630
range you know where they live right so

00:19:24,830 --> 00:19:29,210
that's cool if you if you have a just a

00:19:26,630 --> 00:19:31,059
plain a code address or something you go

00:19:29,210 --> 00:19:35,570
to that table and you can figure out

00:19:31,059 --> 00:19:36,590
what you know who did something what

00:19:35,570 --> 00:19:39,679
else

00:19:36,590 --> 00:19:43,070
a lot of ugly a lot of ugly back traces

00:19:39,679 --> 00:19:44,630
in here I built this H DVD with um you

00:19:43,070 --> 00:19:46,730
know all the symbols right so it can

00:19:44,630 --> 00:19:52,159
display the names of parameters and the

00:19:46,730 --> 00:19:54,020
values and also the local variables but

00:19:52,159 --> 00:19:56,779
again I don't know how much output is

00:19:54,020 --> 00:19:58,669
here let's see 1700 lines output right

00:19:56,779 --> 00:20:00,799
and if you stare at it long enough and

00:19:58,669 --> 00:20:04,520
you know the code you can figure out

00:20:00,799 --> 00:20:07,159
that maybe there's 15 completely idle

00:20:04,520 --> 00:20:09,440
threads doing nothing and I think there

00:20:07,159 --> 00:20:11,960
were a smaller set that we're waiting

00:20:09,440 --> 00:20:15,110
for to read the requests from clients

00:20:11,960 --> 00:20:17,899
and there was one I think we probably

00:20:15,110 --> 00:20:25,940
searched for crash underscore yeah there

00:20:17,899 --> 00:20:28,210
was one thread in in crash request let's

00:20:25,940 --> 00:20:28,210
see

00:20:33,099 --> 00:20:37,969
so again in order to understand that

00:20:36,379 --> 00:20:41,089
right you've got to be able to filter

00:20:37,969 --> 00:20:43,729
out the kind of normal behavior right a

00:20:41,089 --> 00:20:45,649
thread that's just reading something

00:20:43,729 --> 00:20:47,089
from a client just like it does for

00:20:45,649 --> 00:20:49,519
every kind of request a thread that's

00:20:47,089 --> 00:20:53,269
completely idle and doing nothing right

00:20:49,519 --> 00:20:55,989
not part of your problem symptom and

00:20:53,269 --> 00:20:58,219
also at you know if at all possible

00:20:55,989 --> 00:21:00,049
determine definitively where a crash

00:20:58,219 --> 00:21:04,159
occurred if you know if that's what

00:21:00,049 --> 00:21:08,089
happened and you know this is kind of a

00:21:04,159 --> 00:21:09,649
I don't know social problem but you know

00:21:08,089 --> 00:21:11,839
there's a problem with debugging right

00:21:09,649 --> 00:21:14,239
is that you you show it to the right

00:21:11,839 --> 00:21:16,190
person or the right set of people right

00:21:14,239 --> 00:21:20,299
they know very quickly what all that

00:21:16,190 --> 00:21:22,849
means right but if if you're a user of

00:21:20,299 --> 00:21:24,199
httpd right that's collecting this kind

00:21:22,849 --> 00:21:26,419
of information you don't even know

00:21:24,199 --> 00:21:30,199
enough to evaluate whether you've got

00:21:26,419 --> 00:21:31,909
the right data right so like I mentioned

00:21:30,199 --> 00:21:34,059
here users typically seen in this

00:21:31,909 --> 00:21:36,799
back-trace that shows the main thread

00:21:34,059 --> 00:21:38,479
blocked on a pipe which is gonna be for

00:21:36,799 --> 00:21:40,129
the next three years if you don't shut

00:21:38,479 --> 00:21:44,209
down your server right that's just not

00:21:40,129 --> 00:21:47,839
not useful right so it'd be cool to have

00:21:44,209 --> 00:21:50,659
like a you know code that can convert

00:21:47,839 --> 00:21:53,389
the back-trace to a common format a very

00:21:50,659 --> 00:21:55,849
simple format and then have a database

00:21:53,389 --> 00:21:58,429
of annotations to say what these back

00:21:55,849 --> 00:22:00,440
traces mean right it could be looking at

00:21:58,429 --> 00:22:02,299
the entire back trace it could look at

00:22:00,440 --> 00:22:05,809
just a few elements in the back trace

00:22:02,299 --> 00:22:09,369
and you know to identify what the threat

00:22:05,809 --> 00:22:14,749
is and what it means that it has that

00:22:09,369 --> 00:22:18,440
execution context so let's see we I

00:22:14,749 --> 00:22:22,579
gotta go to go somewhere else now so

00:22:18,440 --> 00:22:24,440
here's our Solaris 10 dot core dot fee

00:22:22,579 --> 00:22:27,349
stack out that we just looked at in a

00:22:24,440 --> 00:22:29,859
minute you know go in Emacs right but

00:22:27,349 --> 00:22:32,539
this is a bit of a different view of it

00:22:29,859 --> 00:22:36,469
probably the first the top level thing

00:22:32,539 --> 00:22:38,299
that has done is that it it's simplified

00:22:36,469 --> 00:22:40,369
the back-trace here right so we say

00:22:38,299 --> 00:22:42,559
function name and then a symbol and the

00:22:40,369 --> 00:22:44,269
function name they called it and so

00:22:42,559 --> 00:22:46,279
forth right so this

00:22:44,269 --> 00:22:48,649
this is a much more simple

00:22:46,279 --> 00:22:51,619
representation of what's happening in

00:22:48,649 --> 00:22:53,029
that thread now once we did that we can

00:22:51,619 --> 00:22:54,859
do something else that's very important

00:22:53,029 --> 00:22:57,799
when you say gosh will you have 24

00:22:54,859 --> 00:23:03,259
threads that look the same when you look

00:22:57,799 --> 00:23:04,459
at them at that level and then we have

00:23:03,259 --> 00:23:06,619
an annotation here

00:23:04,459 --> 00:23:09,019
hey we've recognized this back-trace as

00:23:06,619 --> 00:23:12,349
being the event MPM child main thread

00:23:09,019 --> 00:23:15,739
and we can also say what's it doing it's

00:23:12,349 --> 00:23:18,320
waiting on the termination event or

00:23:15,739 --> 00:23:20,959
here's another one an NPM child several

00:23:18,320 --> 00:23:23,779
of these say MPM child worker thread

00:23:20,959 --> 00:23:25,940
right same here for that thread but in

00:23:23,779 --> 00:23:27,979
this case it's waiting for a connection

00:23:25,940 --> 00:23:31,969
to handle and in this case it's running

00:23:27,979 --> 00:23:33,889
the request handler right so just have a

00:23:31,969 --> 00:23:35,869
little database that looks for certain

00:23:33,889 --> 00:23:38,209
patterns in the back traces we can tell

00:23:35,869 --> 00:23:40,279
we can identify what that thread is for

00:23:38,209 --> 00:23:42,979
and hopefully tell something about the

00:23:40,279 --> 00:23:45,109
state it's in and then if we really want

00:23:42,979 --> 00:23:50,269
to you know look at it at a higher level

00:23:45,109 --> 00:23:52,789
I'm sorry at a lower level we can look

00:23:50,269 --> 00:23:55,279
at more of the stuff from gdb or piece

00:23:52,789 --> 00:23:57,799
deck or whatever not that blue doesn't

00:23:55,279 --> 00:24:00,200
come out very well but like this case we

00:23:57,799 --> 00:24:02,690
have a piece tech output and all we have

00:24:00,200 --> 00:24:05,450
is one line for the function in the raw

00:24:02,690 --> 00:24:09,549
data that tells us the you know the

00:24:05,450 --> 00:24:12,229
function arguments I think if we look at

00:24:09,549 --> 00:24:17,929
you know try to do the same thing for

00:24:12,229 --> 00:24:21,349
this gdb example right let's say where's

00:24:17,929 --> 00:24:22,429
the guy that did something bad I mean I

00:24:21,349 --> 00:24:25,070
know it did something bad because I

00:24:22,429 --> 00:24:26,839
recognize crash request but you know I'm

00:24:25,070 --> 00:24:28,879
gonna look at all these descriptions of

00:24:26,839 --> 00:24:30,349
the thread and the state and kind of

00:24:28,879 --> 00:24:31,369
filter these guys out because they're

00:24:30,349 --> 00:24:33,409
doing something normal

00:24:31,369 --> 00:24:35,299
and here we hey hey we're running the

00:24:33,409 --> 00:24:36,940
request handler right we're busy doing

00:24:35,299 --> 00:24:39,320
something when something bad happened

00:24:36,940 --> 00:24:42,739
let me look at that further and see

00:24:39,320 --> 00:24:46,849
what's going on and and with the with

00:24:42,739 --> 00:24:48,799
the gdb example you know we had local

00:24:46,849 --> 00:24:50,479
variables available we have the names of

00:24:48,799 --> 00:24:52,869
the symbols and they get formatted

00:24:50,479 --> 00:24:56,469
properly whether they're a pointer or

00:24:52,869 --> 00:24:56,469
integer or something

00:24:56,760 --> 00:25:02,980
so I think I think this is you know

00:24:59,920 --> 00:25:05,679
doing something in this direction is a

00:25:02,980 --> 00:25:08,440
way to have help help users help

00:25:05,679 --> 00:25:10,660
themselves with this kind of data they

00:25:08,440 --> 00:25:12,460
can get a lot of meaning out of it

00:25:10,660 --> 00:25:16,330
without getting the attention of a

00:25:12,460 --> 00:25:18,190
developer and you know by by switching

00:25:16,330 --> 00:25:20,350
out the database of annotations right

00:25:18,190 --> 00:25:22,470
this could be for traffic server or this

00:25:20,350 --> 00:25:25,179
could be for some commercial product

00:25:22,470 --> 00:25:27,850
right the same basic analysis takes

00:25:25,179 --> 00:25:31,960
place under the covers that have just

00:25:27,850 --> 00:25:37,780
need different descriptions okay

00:25:31,960 --> 00:25:41,490
document okay there are other things

00:25:37,780 --> 00:25:45,130
that are not really exploring right now

00:25:41,490 --> 00:25:47,860
like playing with the debug ability of

00:25:45,130 --> 00:25:50,200
the generated code right what kind of

00:25:47,860 --> 00:25:55,210
optimization is there symbols and so

00:25:50,200 --> 00:25:56,740
forth now let's see what happens let's

00:25:55,210 --> 00:26:00,720
talk about some things we can build into

00:25:56,740 --> 00:26:04,900
httpd that's not built there by default

00:26:00,720 --> 00:26:07,390
so hook tracing is something I think

00:26:04,900 --> 00:26:11,140
this idea was first added to the

00:26:07,390 --> 00:26:13,480
open-source httpd by theo schloss Nagel

00:26:11,140 --> 00:26:18,040
who had some DTrace enhancements for

00:26:13,480 --> 00:26:19,780
httpd and if you know what the hooks are

00:26:18,040 --> 00:26:22,270
right that's a pretty critical point of

00:26:19,780 --> 00:26:25,630
processing right so use some meta

00:26:22,270 --> 00:26:30,460
programming to convert these hook

00:26:25,630 --> 00:26:33,760
invitations into traceable probes now

00:26:30,460 --> 00:26:37,900
that code is kind of died one thing we

00:26:33,760 --> 00:26:41,610
do have in 2.4 I'm going to let me just

00:26:37,900 --> 00:26:44,980
skip over some of these details is is

00:26:41,610 --> 00:26:46,720
another mechanism to you know write your

00:26:44,980 --> 00:26:50,140
own code that does something with these

00:26:46,720 --> 00:26:51,910
hooks macros right mod hook AR where AR

00:26:50,140 --> 00:26:54,670
stands for active request is just an

00:26:51,910 --> 00:26:56,530
example that uses that right and that's

00:26:54,670 --> 00:26:59,530
not I mean that's for my web site it's

00:26:56,530 --> 00:27:03,370
not in the it's not an example module in

00:26:59,530 --> 00:27:05,140
the HTTP d source tree but you know it

00:27:03,370 --> 00:27:08,710
shows how you how you would build such a

00:27:05,140 --> 00:27:09,840
mess how you build such a module and you

00:27:08,710 --> 00:27:14,309
can do things with it

00:27:09,840 --> 00:27:16,950
like like here this this access log

00:27:14,309 --> 00:27:19,440
message I've extended the access log to

00:27:16,950 --> 00:27:23,789
include the request failure note in the

00:27:19,440 --> 00:27:26,039
exes log format right and mod hook AR

00:27:23,789 --> 00:27:28,049
you know by watching what happened at

00:27:26,039 --> 00:27:32,600
every hook invocation he said okay

00:27:28,049 --> 00:27:35,070
whoops I got a bad error code 404 and

00:27:32,600 --> 00:27:37,500
the name of the hook is the handler and

00:27:35,070 --> 00:27:41,820
the module I just called into was mod CG

00:27:37,500 --> 00:27:44,580
ID right so mod hook AR can do that mod

00:27:41,820 --> 00:27:47,640
hook AR also implements an exception

00:27:44,580 --> 00:27:50,580
hook so that if the process crashes it

00:27:47,640 --> 00:27:52,919
gets its code run and it can use that

00:27:50,580 --> 00:27:55,770
same information that's been maintaining

00:27:52,919 --> 00:27:57,720
during the request to say hey at the

00:27:55,770 --> 00:28:01,770
time of the crash we were inside the

00:27:57,720 --> 00:28:03,779
handler hook and the module you know it

00:28:01,770 --> 00:28:06,750
was mod crashes handler hook that we

00:28:03,779 --> 00:28:08,220
were in so if you interested in playing

00:28:06,750 --> 00:28:12,149
with it something like that right you

00:28:08,220 --> 00:28:13,500
could download the source code and and

00:28:12,149 --> 00:28:17,610
you know there be instructions for how

00:28:13,500 --> 00:28:19,620
to build it into httpd and so forth and

00:28:17,610 --> 00:28:21,899
I think to me this is a very interesting

00:28:19,620 --> 00:28:25,380
thing but there are a lot of experiments

00:28:21,899 --> 00:28:28,080
that need to be done and for example

00:28:25,380 --> 00:28:31,110
making the API easier to use where you

00:28:28,080 --> 00:28:32,610
can load in a module dynamically and

00:28:31,110 --> 00:28:34,549
maybe load that in there only when

00:28:32,610 --> 00:28:37,020
you're trying to diagnose a problem or

00:28:34,549 --> 00:28:39,419
switch between different diagnostic

00:28:37,020 --> 00:28:43,740
modules at different times based on what

00:28:39,419 --> 00:28:45,809
you're trying to diagnose okay the

00:28:43,740 --> 00:28:48,000
dtrace probes if you're interested in

00:28:45,809 --> 00:28:51,330
this you probably should post to dev at

00:28:48,000 --> 00:28:54,740
httpd Apache or because the code is

00:28:51,330 --> 00:28:57,409
really not hasn't been kept current and

00:28:54,740 --> 00:29:00,299
hopefully some of us would have time to

00:28:57,409 --> 00:29:05,279
help you figure out what needs to be

00:29:00,299 --> 00:29:07,049
done next to get that ready exception

00:29:05,279 --> 00:29:11,880
hooks these have been around for a while

00:29:07,049 --> 00:29:14,100
on the UNIX side basically if a steep if

00:29:11,880 --> 00:29:18,870
an AC be teached I'll process crashes it

00:29:14,100 --> 00:29:20,880
can call into into loaded modules and a

00:29:18,870 --> 00:29:22,940
couple that I've written or mod what

00:29:20,880 --> 00:29:27,680
killed us and mod back-trace

00:29:22,940 --> 00:29:29,510
you know mod back-trace if it knows how

00:29:27,680 --> 00:29:33,080
to deal with the system libraries right

00:29:29,510 --> 00:29:35,540
on that on your platform it can put a

00:29:33,080 --> 00:29:37,250
back-trace in the air log or in another

00:29:35,540 --> 00:29:39,860
file depending on which version of the

00:29:37,250 --> 00:29:42,080
module you have and mod wot kill this

00:29:39,860 --> 00:29:44,600
will track what you know what was the

00:29:42,080 --> 00:29:47,330
original request line and the HTTP

00:29:44,600 --> 00:29:53,900
headers for that request that triggered

00:29:47,330 --> 00:29:55,370
the crash let's see so might what killed

00:29:53,900 --> 00:29:56,630
us I mean this looks funny that there's

00:29:55,370 --> 00:29:58,820
a back-trace there but the latest

00:29:56,630 --> 00:30:02,090
versions of model achilles and mod

00:29:58,820 --> 00:30:05,990
back-trace rely on mod what killed us to

00:30:02,090 --> 00:30:07,730
actually write the report and if back

00:30:05,990 --> 00:30:11,000
trace is available then that will be

00:30:07,730 --> 00:30:14,510
included with the rest of it and here's

00:30:11,000 --> 00:30:19,340
the part where you see the original

00:30:14,510 --> 00:30:21,410
request data that triggered it and in

00:30:19,340 --> 00:30:24,950
the latest version of mod what killed us

00:30:21,410 --> 00:30:26,660
it can filter out any kind of you know

00:30:24,950 --> 00:30:28,820
request header that you don't want to

00:30:26,660 --> 00:30:31,370
see or a query argument or anything like

00:30:28,820 --> 00:30:34,700
that to try to give the administrator a

00:30:31,370 --> 00:30:41,480
tool not to log the passwords or session

00:30:34,700 --> 00:30:44,990
data in this okay what else we're about

00:30:41,480 --> 00:30:47,030
to get veteran at a time but one thing

00:30:44,990 --> 00:30:48,770
about these is they work pretty well on

00:30:47,030 --> 00:30:51,920
Windows the latest versions of it as

00:30:48,770 --> 00:30:55,040
long as you have the the PDB files for

00:30:51,920 --> 00:30:58,370
the system libraries and the PDB files

00:30:55,040 --> 00:31:01,220
for the server right so at least in the

00:30:58,370 --> 00:31:03,110
past when Windows builds of httpd were

00:31:01,220 --> 00:31:05,270
available from Apache org there was

00:31:03,110 --> 00:31:08,300
always a separate zip file with the

00:31:05,270 --> 00:31:10,220
debug symbols right so you download the

00:31:08,300 --> 00:31:12,470
zip file that matches your binaries you

00:31:10,220 --> 00:31:15,440
unpack it from you know the install

00:31:12,470 --> 00:31:17,840
directory and that allows you know I

00:31:15,440 --> 00:31:20,750
mean traditionally it was dr. Watson or

00:31:17,840 --> 00:31:24,140
when debug something like that but also

00:31:20,750 --> 00:31:31,250
it allowed mod back-trace to get really

00:31:24,140 --> 00:31:33,040
good information for you 2.2 stuff what

00:31:31,250 --> 00:31:36,130
the difference is

00:31:33,040 --> 00:31:38,290
I mean everybody's using to for anyway

00:31:36,130 --> 00:31:39,550
so it doesn't really matter so so sort

00:31:38,290 --> 00:31:43,030
about to run out of time I'm gonna skip

00:31:39,550 --> 00:31:46,620
over that too - not available

00:31:43,030 --> 00:31:48,790
I did play with some some with engine X

00:31:46,620 --> 00:31:51,760
you know I don't have extensive

00:31:48,790 --> 00:31:53,590
extensive experience there right so you

00:31:51,760 --> 00:31:55,480
know if I if I find somebody that says

00:31:53,590 --> 00:31:58,060
something about it well as far as I know

00:31:55,480 --> 00:32:00,190
that's right and unless I can refute it

00:31:58,060 --> 00:32:02,140
with my own experiences that's that's

00:32:00,190 --> 00:32:04,960
what I believe but you know I've used

00:32:02,140 --> 00:32:06,850
httpd for a very long time and engine X

00:32:04,960 --> 00:32:08,380
I just play with from time to time but I

00:32:06,850 --> 00:32:11,320
think one of the issues with them

00:32:08,380 --> 00:32:14,260
comparing how we would do bug one server

00:32:11,320 --> 00:32:15,940
versus another is you just have to kind

00:32:14,260 --> 00:32:18,700
of take a different approach to engine X

00:32:15,940 --> 00:32:20,560
on some things right if you turn on you

00:32:18,700 --> 00:32:23,800
know you you don't have such wide

00:32:20,560 --> 00:32:27,400
control over what gets logged and even

00:32:23,800 --> 00:32:29,400
what gets logged for each line there and

00:32:27,400 --> 00:32:32,200
you have to build its it differently

00:32:29,400 --> 00:32:35,400
with this debug option to even be able

00:32:32,200 --> 00:32:38,230
to get this level of information so

00:32:35,400 --> 00:32:39,640
unless you build engine X with a debug

00:32:38,230 --> 00:32:43,090
you probably don't want to really

00:32:39,640 --> 00:32:45,280
compare it with httpd right because the

00:32:43,090 --> 00:32:46,590
debug is what is going to be required to

00:32:45,280 --> 00:32:53,290
figure out when things aren't going

00:32:46,590 --> 00:32:55,360
exactly as you expected and you know it

00:32:53,290 --> 00:32:58,660
does have capabilities to log things

00:32:55,360 --> 00:33:02,710
like mod dump io does or or the higher

00:32:58,660 --> 00:33:04,600
levels of trace in the httpd module but

00:33:02,710 --> 00:33:06,910
you know you may have to use different

00:33:04,600 --> 00:33:10,900
techniques to filter those out or get

00:33:06,910 --> 00:33:13,750
timestamps stuff like that it has a nice

00:33:10,900 --> 00:33:16,720
feature for specifying that you only

00:33:13,750 --> 00:33:18,150
want to do it for certain clients you

00:33:16,720 --> 00:33:21,460
know in 2.4 we use the expression

00:33:18,150 --> 00:33:23,320
capability and the in the if to set up a

00:33:21,460 --> 00:33:26,910
different log level this is I mean this

00:33:23,320 --> 00:33:26,910
is a more direct way to get there

00:33:27,640 --> 00:33:33,280
and as with H DVD you know someone also

00:33:31,060 --> 00:33:37,060
played with D tracing D traced probes

00:33:33,280 --> 00:33:40,570
inside engine X now I mean there is a

00:33:37,060 --> 00:33:42,310
benefit with engine X just with the

00:33:40,570 --> 00:33:44,470
generic d'Ãªtre stuff right because the

00:33:42,310 --> 00:33:45,610
pit provider of dtrace is what provides

00:33:44,470 --> 00:33:47,890
a lot of kind of

00:33:45,610 --> 00:33:49,840
if you want to find out and the pit

00:33:47,890 --> 00:33:52,420
provider you know you have to tell the

00:33:49,840 --> 00:33:54,400
pit and with engine X you don't have a

00:33:52,420 --> 00:33:55,870
boatload of httpd you don't have a

00:33:54,400 --> 00:33:57,730
boatload of processes that you have to

00:33:55,870 --> 00:34:01,210
choose from or that you have to follow

00:33:57,730 --> 00:34:03,670
in you know the entire set of right so

00:34:01,210 --> 00:34:06,010
so DTrace those will be easier with

00:34:03,670 --> 00:34:10,119
engine X even if you don't have the

00:34:06,010 --> 00:34:13,600
engine X probes well let's see another

00:34:10,119 --> 00:34:16,330
thing you know if engine X thread

00:34:13,600 --> 00:34:18,280
crashes or httpd thread crashes it's

00:34:16,330 --> 00:34:22,270
probably about the same as far as trying

00:34:18,280 --> 00:34:24,129
to understand what the back-trace is now

00:34:22,270 --> 00:34:26,399
if you're looking at idle threads in the

00:34:24,129 --> 00:34:28,990
server to see what they're doing well

00:34:26,399 --> 00:34:31,210
you know like the worker npm in apache

00:34:28,990 --> 00:34:33,010
or pre fork right you're gonna see the

00:34:31,210 --> 00:34:34,899
whole call stack even for idle threads

00:34:33,010 --> 00:34:37,330
whereas in engine x and to a very

00:34:34,899 --> 00:34:38,260
limited extent the event npm right

00:34:37,330 --> 00:34:41,020
you're gonna have to pore through

00:34:38,260 --> 00:34:43,720
function I'm sorry connection tables to

00:34:41,020 --> 00:34:45,700
know what they're doing right which in

00:34:43,720 --> 00:34:47,859
turn means you have to have a different

00:34:45,700 --> 00:34:52,149
kind of build for engine X in order to

00:34:47,859 --> 00:34:56,050
do that so here are some things that

00:34:52,149 --> 00:34:59,350
talk about during the talk but we have

00:34:56,050 --> 00:35:01,480
any questions any particular topics

00:34:59,350 --> 00:35:05,740
you're more interested in walk up to the

00:35:01,480 --> 00:35:09,040
mic and let's see what you got any

00:35:05,740 --> 00:35:10,420
questions okay Daniel thank you sir I do

00:35:09,040 --> 00:35:13,480
have a question I don't I don't often

00:35:10,420 --> 00:35:16,210
have 2d bug at this level but what's

00:35:13,480 --> 00:35:20,350
your opinion on combine compiling with

00:35:16,210 --> 00:35:23,170
full symbols in a production build well

00:35:20,350 --> 00:35:31,890
because when the crashes do happen sighs

00:35:23,170 --> 00:35:34,359
because I got no information I mean just

00:35:31,890 --> 00:35:39,490
where I work they tend to be you know

00:35:34,359 --> 00:35:41,740
moderately optimized and we could debug

00:35:39,490 --> 00:35:45,050
problems

00:35:41,740 --> 00:35:47,000
okay but you know you didn't have every

00:35:45,050 --> 00:35:49,700
tool at your disposal

00:35:47,000 --> 00:35:51,710
sure and of course you know reproduce

00:35:49,700 --> 00:35:54,770
whether whether it's than to want the

00:35:51,710 --> 00:35:55,940
desire for symbols or not right if a lot

00:35:54,770 --> 00:35:57,410
of times you spend a lot of time trying

00:35:55,940 --> 00:35:59,480
to figure out how to reproduce the

00:35:57,410 --> 00:36:01,609
problem once you know sort of what codes

00:35:59,480 --> 00:36:04,250
it's in and if you can reproduce it then

00:36:01,609 --> 00:36:09,170
you own it and you can run it on your

00:36:04,250 --> 00:36:15,920
own bill have you ever had the mr. de

00:36:09,170 --> 00:36:21,920
bugging OpenSSL problems in apache no it

00:36:15,920 --> 00:36:23,150
turns out that um well you know it's

00:36:21,920 --> 00:36:24,950
been a lot of time working on their

00:36:23,150 --> 00:36:31,690
products each of those at a proprietary

00:36:24,950 --> 00:36:34,160
as well right so you know open SSL no

00:36:31,690 --> 00:36:40,369
did I know a little bit about their

00:36:34,160 --> 00:36:47,960
their library sure you know never

00:36:40,369 --> 00:36:50,650
something I had sources open SSL Thanks

00:36:47,960 --> 00:36:50,650
sure

00:36:52,150 --> 00:36:59,200
okay well if you want to get the slides

00:36:56,890 --> 00:37:01,930
go there and if you take off all that

00:36:59,200 --> 00:37:03,550
stuff after the first flash you can

00:37:01,930 --> 00:37:06,850
probably figure out how to contact me if

00:37:03,550 --> 00:37:09,430
you want to ask other questions or you

00:37:06,850 --> 00:37:12,100
know see if there's any joint interest

00:37:09,430 --> 00:37:16,920
in say expanding those annotations or

00:37:12,100 --> 00:37:16,920

YouTube URL: https://www.youtube.com/watch?v=DcIRz0yH_eA


