Title: Hadoop Storage Reloaded: the 5 lessons Ozone learned from HDFS
Publication date: 2020-10-21
Playlist: ApacheCon @Home 2020: Big Data (Track 1)
Description: 
	Hadoop Storage Reloaded: the 5 lessons Ozone learned from HDFS
MÃ¡rton Elek

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Apache (Hadoop) Ozone is a brand-new storage system for the Hadoop ecosystem. It provides Object Store semantics (like S3) and can handle billions of objects. Ozone doesn't depend on HDFS but it's the "spiritual successor" of it. The lessons learned during the 10+ years of HDFS helped to design a more scalable object store. This presentation explains the key challenges of a storage system and shows how the specific problems can be answered.

Marton Elek is PMC in Apache Hadoop and Apache Ratis projects and working on the Apache Hadoop Ozone at Cloudera. Ozone is a new Hadoop sub-project which provides an S3 compatible Object Store for Hadoop on top of a new generalized binary storage layer. He is also working on the containerization of Hadoop and creating different solutions to run Apache Big Data projects in Kubernetes and other could native environments.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:25,920 --> 00:00:30,640
so let's start

00:00:27,199 --> 00:00:32,880
welcome everybody and this talk

00:00:30,640 --> 00:00:35,200
so the previous talk was about hadoop

00:00:32,880 --> 00:00:39,040
and and scheduling and execution

00:00:35,200 --> 00:00:42,160
so this talk is about storage

00:00:39,040 --> 00:00:44,399
and mainly about apache hadoop ozone

00:00:42,160 --> 00:00:48,000
which is a new subproject and

00:00:44,399 --> 00:00:50,399
object store but you know it's

00:00:48,000 --> 00:00:52,559
it's harder to understand what is ozone

00:00:50,399 --> 00:00:56,640
without the context

00:00:52,559 --> 00:00:59,840
how is it different from from hdfs

00:00:56,640 --> 00:01:02,559
for example so this is what we will

00:00:59,840 --> 00:01:04,720
talk about that what is ozone how is it

00:01:02,559 --> 00:01:05,519
different from the hdfs and what does it

00:01:04,720 --> 00:01:08,799
mean

00:01:05,519 --> 00:01:11,200
for for the hadoop ecosystem because the

00:01:08,799 --> 00:01:14,400
context is is very important to

00:01:11,200 --> 00:01:15,920
to compare ozone with hdfs this is my

00:01:14,400 --> 00:01:19,520
context actually so

00:01:15,920 --> 00:01:21,600
i'm ahead of pmc and the red is pmc and

00:01:19,520 --> 00:01:23,040
i'm working for cloudera is a principal

00:01:21,600 --> 00:01:26,240
software engineer

00:01:23,040 --> 00:01:27,439
and mainly i'm working on the hadoop

00:01:26,240 --> 00:01:31,520
ozone

00:01:27,439 --> 00:01:34,560
but i'm also also working

00:01:31,520 --> 00:01:36,720
on a project in my free time just to

00:01:34,560 --> 00:01:38,640
containerize apache big data project in

00:01:36,720 --> 00:01:39,680
kubernetes so if you're interested you

00:01:38,640 --> 00:01:41,280
can check

00:01:39,680 --> 00:01:43,439
this flexible which is a kubernetes

00:01:41,280 --> 00:01:46,399
resource generator or the flocker

00:01:43,439 --> 00:01:47,759
but back to the important part hadoop

00:01:46,399 --> 00:01:52,159
storage

00:01:47,759 --> 00:01:55,680
so let's start from the beginning so

00:01:52,159 --> 00:01:59,040
hadoop is roughly 15 years

00:01:55,680 --> 00:02:02,479
old and i think i don't need to

00:01:59,040 --> 00:02:06,640
explain that today this is a totally

00:02:02,479 --> 00:02:09,440
different time right this is 2020

00:02:06,640 --> 00:02:11,360
and we are just sitting at home and and

00:02:09,440 --> 00:02:12,400
participating in that conference which

00:02:11,360 --> 00:02:15,280
is awesome

00:02:12,400 --> 00:02:15,920
but this is not the same time what we

00:02:15,280 --> 00:02:19,440
had

00:02:15,920 --> 00:02:21,840
when hadoop was designed and

00:02:19,440 --> 00:02:22,879
the technical environment is also

00:02:21,840 --> 00:02:25,120
changed

00:02:22,879 --> 00:02:25,920
the change fortunately it's not so

00:02:25,120 --> 00:02:29,760
dramatic

00:02:25,920 --> 00:02:30,959
as the change in our environment but

00:02:29,760 --> 00:02:33,040
but you know this is a different

00:02:30,959 --> 00:02:33,840
different word for example we have

00:02:33,040 --> 00:02:36,879
streaming

00:02:33,840 --> 00:02:40,720
hdfs was designed to

00:02:36,879 --> 00:02:43,680
support very huge files and

00:02:40,720 --> 00:02:45,440
today it's it's pretty important to

00:02:43,680 --> 00:02:47,840
support streaming for example which can

00:02:45,440 --> 00:02:50,720
generate a lot of small files

00:02:47,840 --> 00:02:52,560
and we have a lot of ecosystem or

00:02:50,720 --> 00:02:53,680
separated ecosystem machine learning

00:02:52,560 --> 00:02:56,720
data science

00:02:53,680 --> 00:02:58,640
and it's not enough just to support

00:02:56,720 --> 00:03:00,159
the hadoop compatible file system which

00:02:58,640 --> 00:03:03,440
can be used from flink

00:03:00,159 --> 00:03:04,159
spark hive age base but we need

00:03:03,440 --> 00:03:08,239
something

00:03:04,159 --> 00:03:11,280
to to talk with different ecosystem

00:03:08,239 --> 00:03:12,159
so that's what we have today so if i

00:03:11,280 --> 00:03:14,400
asked

00:03:12,159 --> 00:03:16,840
what is the hadoop storage today i think

00:03:14,400 --> 00:03:19,840
the obvious answer is that

00:03:16,840 --> 00:03:22,959
hdfs actually this is just one

00:03:19,840 --> 00:03:26,000
part of the of the

00:03:22,959 --> 00:03:29,040
story uh

00:03:26,000 --> 00:03:30,799
because we have another one the hadoop

00:03:29,040 --> 00:03:33,040
compatible file system usually

00:03:30,799 --> 00:03:35,440
it's it's not mentioned but it's also

00:03:33,040 --> 00:03:38,640
important because this is the part

00:03:35,440 --> 00:03:39,360
which can be used to access any cloud

00:03:38,640 --> 00:03:41,599
provider

00:03:39,360 --> 00:03:43,920
right this is the s3a connector and all

00:03:41,599 --> 00:03:46,000
of the other cloud connectors

00:03:43,920 --> 00:03:47,200
and we have different type of problems

00:03:46,000 --> 00:03:50,480
on on the

00:03:47,200 --> 00:03:51,040
on the two sides so the hdfs is well

00:03:50,480 --> 00:03:53,439
known

00:03:51,040 --> 00:03:55,680
about a problem the small files problems

00:03:53,439 --> 00:03:58,480
we will we will check it later

00:03:55,680 --> 00:03:59,200
and it's there is also a limitation that

00:03:58,480 --> 00:04:01,840
the

00:03:59,200 --> 00:04:03,920
easiest way to use hdfs is just using

00:04:01,840 --> 00:04:06,319
the hadoop compatible file system

00:04:03,920 --> 00:04:08,640
and it's harder to use from python-based

00:04:06,319 --> 00:04:11,840
machine learning tool for example

00:04:08,640 --> 00:04:14,640
on the other hand if we use a

00:04:11,840 --> 00:04:16,479
cloud provider we also have some also

00:04:14,640 --> 00:04:19,519
can have some problems

00:04:16,479 --> 00:04:23,440
so for example sometimes some pro

00:04:19,519 --> 00:04:26,560
some providers some cloud providers

00:04:23,440 --> 00:04:29,680
has only eventually consistent

00:04:26,560 --> 00:04:30,240
object store or and yeah there are some

00:04:29,680 --> 00:04:32,639
limited

00:04:30,240 --> 00:04:33,520
there could be some limitations with the

00:04:32,639 --> 00:04:37,759
object store

00:04:33,520 --> 00:04:41,919
they couldn't be started on-prem so

00:04:37,759 --> 00:04:44,400
roughly five years ago a few

00:04:41,919 --> 00:04:45,120
hdfs and hadoop developers started to

00:04:44,400 --> 00:04:48,479
sync

00:04:45,120 --> 00:04:50,639
to provide something which can

00:04:48,479 --> 00:04:52,400
fix all of the problems and which is

00:04:50,639 --> 00:04:53,840
very sim something which is very similar

00:04:52,400 --> 00:04:56,880
to the hdfs

00:04:53,840 --> 00:04:58,479
but provides object store semantics like

00:04:56,880 --> 00:05:01,520
the s3 so object store

00:04:58,479 --> 00:05:03,440
for the hadoop ecosystem and the work is

00:05:01,520 --> 00:05:06,800
started

00:05:03,440 --> 00:05:07,919
at first it started as a feature branch

00:05:06,800 --> 00:05:11,680
in hadoop

00:05:07,919 --> 00:05:15,199
this was the hdfs 7240

00:05:11,680 --> 00:05:18,000
uh and after a long discussion

00:05:15,199 --> 00:05:19,520
it's merged to the hadoop code based uh

00:05:18,000 --> 00:05:22,639
the

00:05:19,520 --> 00:05:25,039
hadoop trunk and

00:05:22,639 --> 00:05:26,560
the agreement was that because this is a

00:05:25,039 --> 00:05:29,680
a new and experimental

00:05:26,560 --> 00:05:32,639
object store then it had

00:05:29,680 --> 00:05:33,919
a separated release lifecycle and it was

00:05:32,639 --> 00:05:37,199
separated from the

00:05:33,919 --> 00:05:40,800
from the core hdfs and the art code

00:05:37,199 --> 00:05:42,479
so after a while it was so independent

00:05:40,800 --> 00:05:45,440
that the code itself is moved to a

00:05:42,479 --> 00:05:48,720
separated but hadoop repository

00:05:45,440 --> 00:05:50,960
and ozone had a lot of releases so the

00:05:48,720 --> 00:05:54,160
release cadence is usually three to

00:05:50,960 --> 00:05:56,240
four monthses and it had alpha releases

00:05:54,160 --> 00:06:00,160
beta releases and finally

00:05:56,240 --> 00:06:03,600
in the september ozone had the first

00:06:00,160 --> 00:06:06,319
stable release the latest news is

00:06:03,600 --> 00:06:08,319
right now we have an open vote in the

00:06:06,319 --> 00:06:12,160
hadoop developer list

00:06:08,319 --> 00:06:15,280
to move out from the hadoop project

00:06:12,160 --> 00:06:17,840
and manage ozone as

00:06:15,280 --> 00:06:19,360
a separated project separated top level

00:06:17,840 --> 00:06:22,000
project if it's voted

00:06:19,360 --> 00:06:22,479
it will be proposed to the apache board

00:06:22,000 --> 00:06:25,360
and

00:06:22,479 --> 00:06:27,120
that could be the next step if you are

00:06:25,360 --> 00:06:29,680
interested about the

00:06:27,120 --> 00:06:30,240
history in more details i i really like

00:06:29,680 --> 00:06:32,880
it that this

00:06:30,240 --> 00:06:34,000
this history mark down this is a link so

00:06:32,880 --> 00:06:36,400
you can just check the

00:06:34,000 --> 00:06:38,240
apache slash hadoop ozone repository and

00:06:36,400 --> 00:06:41,360
you will see not just the readme

00:06:38,240 --> 00:06:45,360
but a detailed history that that about

00:06:41,360 --> 00:06:46,840
also so this is exactly the same picture

00:06:45,360 --> 00:06:50,000
what you

00:06:46,840 --> 00:06:53,520
uh which was shared with

00:06:50,000 --> 00:06:55,039
during the yarn talk so these are the

00:06:53,520 --> 00:06:57,919
comets inside

00:06:55,039 --> 00:06:59,840
the hadoop project the ozone uses the

00:06:57,919 --> 00:07:02,000
hdds

00:06:59,840 --> 00:07:03,919
gyro project and the orange is the ozone

00:07:02,000 --> 00:07:07,680
so you can see the orange

00:07:03,919 --> 00:07:09,199
this is all of the the ozone comets so

00:07:07,680 --> 00:07:12,240
actually today

00:07:09,199 --> 00:07:15,759
the majority of the hadoop comets are

00:07:12,240 --> 00:07:18,960
are awesome comets

00:07:15,759 --> 00:07:20,080
so what can ozone provide so the two

00:07:18,960 --> 00:07:22,000
biggest problem

00:07:20,080 --> 00:07:25,360
what we saw is that one is the

00:07:22,000 --> 00:07:28,800
scalability that hdfs is not very good

00:07:25,360 --> 00:07:31,360
with handling a lot of small files

00:07:28,800 --> 00:07:33,039
just because when it was designed it was

00:07:31,360 --> 00:07:35,759
not a goal

00:07:33,039 --> 00:07:37,759
at that time we had a lot of huge files

00:07:35,759 --> 00:07:41,039
today we have a lot of small files

00:07:37,759 --> 00:07:43,440
so ozone is designed to support easily

00:07:41,039 --> 00:07:44,800
billion of keys actually we test it with

00:07:43,440 --> 00:07:47,919
billion of case

00:07:44,800 --> 00:07:48,720
the other one is this my favorite slide

00:07:47,919 --> 00:07:51,360
or picture

00:07:48,720 --> 00:07:52,800
that the usability that the ozone can be

00:07:51,360 --> 00:07:55,280
used not only from

00:07:52,800 --> 00:07:58,319
link or hbase or the hadoop ecosystem

00:07:55,280 --> 00:08:01,039
but it provides an aws s3 compatible

00:07:58,319 --> 00:08:02,240
interface so can you you can use it from

00:08:01,039 --> 00:08:05,599
any tool which

00:08:02,240 --> 00:08:06,000
which can be used with aws s3 it also

00:08:05,599 --> 00:08:08,800
has

00:08:06,000 --> 00:08:10,879
a container storage interface so the

00:08:08,800 --> 00:08:14,160
storage itself can be mounted

00:08:10,879 --> 00:08:18,000
to to any container with the help of

00:08:14,160 --> 00:08:20,400
of container storage interface so

00:08:18,000 --> 00:08:22,000
this is the quick overview actually this

00:08:20,400 --> 00:08:25,520
is the

00:08:22,000 --> 00:08:28,319
ozone web page so you can just check

00:08:25,520 --> 00:08:29,280
that what are the main points there but

00:08:28,319 --> 00:08:30,479
i think we

00:08:29,280 --> 00:08:33,200
already mentioned that this is

00:08:30,479 --> 00:08:34,240
consistent and actually this is very

00:08:33,200 --> 00:08:36,560
similar to the

00:08:34,240 --> 00:08:38,000
hdfs it's not something which is which

00:08:36,560 --> 00:08:40,240
is brand new

00:08:38,000 --> 00:08:42,560
but i like this quote i don't know who

00:08:40,240 --> 00:08:44,959
is the original author i think it

00:08:42,560 --> 00:08:45,680
either on engineer or or arbit or

00:08:44,959 --> 00:08:48,320
jinandra

00:08:45,680 --> 00:08:50,080
that ozone is a spiritual successor to

00:08:48,320 --> 00:08:53,120
to hdfs

00:08:50,080 --> 00:08:56,320
so ozone reuses

00:08:53,120 --> 00:09:00,320
all of the knowledge which is learned

00:08:56,320 --> 00:09:03,920
from the 15 years of of hdfs

00:09:00,320 --> 00:09:06,480
but some of the points are are

00:09:03,920 --> 00:09:07,680
changed some of the design decisions are

00:09:06,480 --> 00:09:10,959
revisited

00:09:07,680 --> 00:09:13,120
after the 15 years and this presentation

00:09:10,959 --> 00:09:15,680
i would like to share that this one that

00:09:13,120 --> 00:09:17,360
what are the differences you know that

00:09:15,680 --> 00:09:18,240
it's it's always a big problem for me

00:09:17,360 --> 00:09:21,120
because it's very

00:09:18,240 --> 00:09:22,000
hard to demo a storage how can i demo a

00:09:21,120 --> 00:09:25,519
storage you can

00:09:22,000 --> 00:09:28,880
i can i can share a comment but

00:09:25,519 --> 00:09:32,800
you know that it's it's not like a ui

00:09:28,880 --> 00:09:35,120
and and i was thinking a lot that

00:09:32,800 --> 00:09:35,839
how can i explain the stories because

00:09:35,120 --> 00:09:39,680
the real

00:09:35,839 --> 00:09:41,360
important decisions are under the hood

00:09:39,680 --> 00:09:43,040
and with this approach we will compare

00:09:41,360 --> 00:09:46,320
the hdfs and

00:09:43,040 --> 00:09:46,640
ozone just to to check that what's going

00:09:46,320 --> 00:09:49,519
on

00:09:46,640 --> 00:09:50,000
what what are the main design decisions

00:09:49,519 --> 00:09:53,519
why

00:09:50,000 --> 00:09:55,519
ozone can be more scalable

00:09:53,519 --> 00:09:56,800
so we will have five important

00:09:55,519 --> 00:09:59,920
differences

00:09:56,800 --> 00:10:03,360
first the key and block space

00:09:59,920 --> 00:10:05,279
separation so if you are talking about

00:10:03,360 --> 00:10:07,440
the storage of hdfs

00:10:05,279 --> 00:10:09,120
which is exactly the same scheme what we

00:10:07,440 --> 00:10:12,000
have in amazon

00:10:09,120 --> 00:10:12,800
that this is a very well known pattern

00:10:12,000 --> 00:10:15,760
that

00:10:12,800 --> 00:10:17,279
a file which should be stored or a key

00:10:15,760 --> 00:10:20,959
in case of ozone

00:10:17,279 --> 00:10:24,640
is uh split two smaller blocks and the

00:10:20,959 --> 00:10:27,760
smaller blocks are stored in data nodes

00:10:24,640 --> 00:10:30,000
so these are two independent okay not

00:10:27,760 --> 00:10:32,320
independent these are two problems

00:10:30,000 --> 00:10:33,760
one is that we need to split the file

00:10:32,320 --> 00:10:36,399
and create the blocks

00:10:33,760 --> 00:10:38,240
and if you have a file i need to have a

00:10:36,399 --> 00:10:40,399
list of the blocks the other one is that

00:10:38,240 --> 00:10:42,560
the blocks the binary part

00:10:40,399 --> 00:10:43,760
should be replicated between the data

00:10:42,560 --> 00:10:47,200
nodes

00:10:43,760 --> 00:10:49,839
so actually these are two

00:10:47,200 --> 00:10:51,440
maps right one is that the file should

00:10:49,839 --> 00:10:54,480
be mapped to the blocks that

00:10:51,440 --> 00:10:56,240
what kind of block ids there for this

00:10:54,480 --> 00:11:00,720
specific file and the blocks

00:10:56,240 --> 00:11:04,480
should be mapped to locations

00:11:00,720 --> 00:11:07,920
in hdfs both of these maps are

00:11:04,480 --> 00:11:11,839
handled in name node but in ozone

00:11:07,920 --> 00:11:14,000
we we follow a different approach so

00:11:11,839 --> 00:11:16,320
what we did is just

00:11:14,000 --> 00:11:17,760
cut the responsibilities of the name

00:11:16,320 --> 00:11:20,079
node and we have

00:11:17,760 --> 00:11:21,360
two leader nodes so we have a storage

00:11:20,079 --> 00:11:23,680
container merger

00:11:21,360 --> 00:11:24,959
this is the bottom from the from the

00:11:23,680 --> 00:11:27,600
green boxes

00:11:24,959 --> 00:11:28,800
which is nothing more just a component

00:11:27,600 --> 00:11:32,160
to

00:11:28,800 --> 00:11:36,160
replicate huge binary blocks

00:11:32,160 --> 00:11:38,560
that's the block to location mapping

00:11:36,160 --> 00:11:40,640
on top of that we have the ozo manager

00:11:38,560 --> 00:11:42,160
which is responsible for the key space

00:11:40,640 --> 00:11:45,200
management this is the file

00:11:42,160 --> 00:11:48,320
or key to block

00:11:45,200 --> 00:11:50,959
mapping and obviously we have a few

00:11:48,320 --> 00:11:53,440
other optional services like the recon

00:11:50,959 --> 00:11:55,760
which is a web ui and prediction service

00:11:53,440 --> 00:11:58,320
or series interface which can provide

00:11:55,760 --> 00:12:00,079
the aws s3 compatible interface

00:11:58,320 --> 00:12:02,480
or the container storage interface

00:12:00,079 --> 00:12:03,120
services but that's the main difference

00:12:02,480 --> 00:12:06,480
that we

00:12:03,120 --> 00:12:08,639
have two leader service

00:12:06,480 --> 00:12:10,399
for for key space management and block

00:12:08,639 --> 00:12:14,079
space management

00:12:10,399 --> 00:12:16,320
why is it good well

00:12:14,079 --> 00:12:18,240
when the ozone has been started the

00:12:16,320 --> 00:12:20,160
original vision was that

00:12:18,240 --> 00:12:22,480
if we separate the block space

00:12:20,160 --> 00:12:26,160
management this very low level layer

00:12:22,480 --> 00:12:29,440
which can just replicate huge binary

00:12:26,160 --> 00:12:31,920
blobs it can be reused there is a

00:12:29,440 --> 00:12:34,079
feature branch in hadoop where

00:12:31,920 --> 00:12:36,320
which is more like a proof of concept

00:12:34,079 --> 00:12:38,959
which was a block storage

00:12:36,320 --> 00:12:39,920
so a storage which can provide any

00:12:38,959 --> 00:12:43,760
storage

00:12:39,920 --> 00:12:46,639
uh to mount to containers to nodes

00:12:43,760 --> 00:12:48,720
and this was the c block and it was also

00:12:46,639 --> 00:12:52,000
designed lower level layer is designed

00:12:48,720 --> 00:12:54,959
to make it reusable even for

00:12:52,000 --> 00:12:56,320
hdfs or maybe for hbase or any other big

00:12:54,959 --> 00:12:59,519
data

00:12:56,320 --> 00:13:01,279
but the today picture is that the lower

00:12:59,519 --> 00:13:02,399
level layer the storage container

00:13:01,279 --> 00:13:04,639
manager which

00:13:02,399 --> 00:13:05,680
and the data nodes are used the ozo

00:13:04,639 --> 00:13:09,839
manager so

00:13:05,680 --> 00:13:11,279
both are ozone and on top of that we

00:13:09,839 --> 00:13:14,320
have an ozone client

00:13:11,279 --> 00:13:16,000
and and

00:13:14,320 --> 00:13:18,000
on top of the ozone client we have

00:13:16,000 --> 00:13:20,000
additional services like s3 gateway

00:13:18,000 --> 00:13:21,360
hadoop compatible file system container

00:13:20,000 --> 00:13:24,880
storage interface

00:13:21,360 --> 00:13:28,000
and there are some ongoing uh

00:13:24,880 --> 00:13:31,360
thinking that how can we reuse the leave

00:13:28,000 --> 00:13:34,800
hdfs or fusefi system or hdfs to

00:13:31,360 --> 00:13:38,160
to provide a fuse layer for

00:13:34,800 --> 00:13:42,000
ozone okay so

00:13:38,160 --> 00:13:45,680
that's the first main differences and

00:13:42,000 --> 00:13:48,880
i mentioned that it's hard to demo

00:13:45,680 --> 00:13:49,760
the storage but i would like to try it

00:13:48,880 --> 00:13:53,199
out

00:13:49,760 --> 00:13:53,760
so i would like to show just very small

00:13:53,199 --> 00:13:56,800
chunks

00:13:53,760 --> 00:13:58,720
of ozone to demonstrate the

00:13:56,800 --> 00:14:00,320
differences so this difference was the

00:13:58,720 --> 00:14:04,000
default

00:14:00,320 --> 00:14:06,639
the separation of key space and

00:14:04,000 --> 00:14:07,440
and block space and what we can see here

00:14:06,639 --> 00:14:09,760
is an

00:14:07,440 --> 00:14:10,639
ozone install so you can download the

00:14:09,760 --> 00:14:12,800
ozone

00:14:10,639 --> 00:14:14,240
and these are the sub directories and if

00:14:12,800 --> 00:14:17,279
you go to the compose

00:14:14,240 --> 00:14:20,880
ozone folder you will have an

00:14:17,279 --> 00:14:21,920
example uh definition here an example

00:14:20,880 --> 00:14:24,160
ozone cluster

00:14:21,920 --> 00:14:24,959
so the only thing what you need to do is

00:14:24,160 --> 00:14:30,160
just start

00:14:24,959 --> 00:14:34,079
ozone you can scale

00:14:30,160 --> 00:14:37,920
and say that you need three data nodes

00:14:34,079 --> 00:14:41,279
so three data nodes started and it was

00:14:37,920 --> 00:14:44,000
10 seconds and i have a fully

00:14:41,279 --> 00:14:44,800
running ozone cluster you can see three

00:14:44,000 --> 00:14:46,880
data nodes

00:14:44,800 --> 00:14:48,480
and here it's clearly visible that i

00:14:46,880 --> 00:14:50,480
have multiple leader nodes so this is

00:14:48,480 --> 00:14:51,600
one one of the ozone manager the storage

00:14:50,480 --> 00:14:53,600
container manager

00:14:51,600 --> 00:14:54,800
and i have a few optional nodes because

00:14:53,600 --> 00:14:58,800
just by default they

00:14:54,800 --> 00:15:01,839
are started so we will use this cluster

00:14:58,800 --> 00:15:03,040
next but let's go back to the second big

00:15:01,839 --> 00:15:06,560
difference

00:15:03,040 --> 00:15:09,760
so unit of replication it's very

00:15:06,560 --> 00:15:13,040
hdfs is well known about this uh

00:15:09,760 --> 00:15:16,000
scalability problem that it can handle

00:15:13,040 --> 00:15:17,120
roughly two to three hundred million of

00:15:16,000 --> 00:15:21,040
files

00:15:17,120 --> 00:15:22,959
and it's usually

00:15:21,040 --> 00:15:24,959
i i have heard it in an other

00:15:22,959 --> 00:15:27,519
presentation that if you have

00:15:24,959 --> 00:15:29,920
a dedicated hadoop developer then maybe

00:15:27,519 --> 00:15:32,959
you can scale it up to three to

00:15:29,920 --> 00:15:36,480
six hundred million files but it's just

00:15:32,959 --> 00:15:40,720
harder and harder why is this limit

00:15:36,480 --> 00:15:44,240
well we already discussed that with the

00:15:40,720 --> 00:15:45,199
in this story scheme we are creating

00:15:44,240 --> 00:15:47,199
blocks

00:15:45,199 --> 00:15:50,000
for each of the files for each of the

00:15:47,199 --> 00:15:53,519
file we need at least one block

00:15:50,000 --> 00:15:57,040
so 100 millions of file

00:15:53,519 --> 00:15:59,759
means at least 100 million blocks

00:15:57,040 --> 00:16:01,600
and the problem is that the unit of the

00:15:59,759 --> 00:16:04,399
replication in hdfs

00:16:01,600 --> 00:16:06,720
is the block so all of the blocks are

00:16:04,399 --> 00:16:08,639
reported one by one

00:16:06,720 --> 00:16:10,560
by the data nodes to the leader node

00:16:08,639 --> 00:16:12,720
says okay this block is fine

00:16:10,560 --> 00:16:14,000
this block is fine this block is fine

00:16:12,720 --> 00:16:17,279
and all of the blocks

00:16:14,000 --> 00:16:19,279
are are stored

00:16:17,279 --> 00:16:20,639
in the or the metadata of the blocks are

00:16:19,279 --> 00:16:23,680
stored in the

00:16:20,639 --> 00:16:27,120
leader node of the hdfs so this

00:16:23,680 --> 00:16:29,120
is changed with ozone in ozone the

00:16:27,120 --> 00:16:30,320
the unit of the replication is not the

00:16:29,120 --> 00:16:32,320
block anymore

00:16:30,320 --> 00:16:34,399
which helps a lot the unit of the

00:16:32,320 --> 00:16:37,120
replication is the container

00:16:34,399 --> 00:16:37,759
and unfortunately the container it's not

00:16:37,120 --> 00:16:39,920
the

00:16:37,759 --> 00:16:41,519
maybe it's not the best name because you

00:16:39,920 --> 00:16:43,519
know that we have a lot of other meaning

00:16:41,519 --> 00:16:45,680
of the container so this container is

00:16:43,519 --> 00:16:49,040
the good old container which can be

00:16:45,680 --> 00:16:50,240
found in the in the cargo ship so the

00:16:49,040 --> 00:16:53,920
container

00:16:50,240 --> 00:16:56,079
can contain one container can contain

00:16:53,920 --> 00:16:57,759
multiple blocks this is what you can see

00:16:56,079 --> 00:16:58,639
in this this picture that we have

00:16:57,759 --> 00:17:01,839
container

00:16:58,639 --> 00:17:02,560
container contains multiple blocks and

00:17:01,839 --> 00:17:07,760
the blocks

00:17:02,560 --> 00:17:11,199
can can be uploaded in in smaller chunks

00:17:07,760 --> 00:17:12,319
why is it good well the big advantage of

00:17:11,199 --> 00:17:15,360
this approach

00:17:12,319 --> 00:17:16,959
that we don't need to report all of the

00:17:15,360 --> 00:17:20,160
blocks one by one

00:17:16,959 --> 00:17:23,039
so the data node can report that oh

00:17:20,160 --> 00:17:23,520
i have these hundred of the blocks or i

00:17:23,039 --> 00:17:25,919
can

00:17:23,520 --> 00:17:27,280
i have all of the blocks which starts

00:17:25,919 --> 00:17:29,200
with zero

00:17:27,280 --> 00:17:30,559
where the identifier is started with

00:17:29,200 --> 00:17:31,600
zero this is something like the

00:17:30,559 --> 00:17:33,600
container

00:17:31,600 --> 00:17:35,840
in the bottom of this uh slide you can

00:17:33,600 --> 00:17:38,240
see that the block id

00:17:35,840 --> 00:17:39,919
it's based on a container id and a local

00:17:38,240 --> 00:17:42,640
id which is very similar to

00:17:39,919 --> 00:17:43,600
let's say the content id is the city in

00:17:42,640 --> 00:17:47,440
an address

00:17:43,600 --> 00:17:51,520
and the local id is the is the

00:17:47,440 --> 00:17:53,120
is the street so first of all we need to

00:17:51,520 --> 00:17:55,679
find the container

00:17:53,120 --> 00:17:57,120
and after that inside the container we

00:17:55,679 --> 00:18:00,000
will have a block id

00:17:57,120 --> 00:18:01,200
but the containers are replicated which

00:18:00,000 --> 00:18:04,559
makes everything

00:18:01,200 --> 00:18:06,559
very scalable so

00:18:04,559 --> 00:18:08,480
this is the previous picture we already

00:18:06,559 --> 00:18:10,480
discussed that

00:18:08,480 --> 00:18:12,799
some of the responsibilities of the name

00:18:10,480 --> 00:18:15,840
node are split in ozone

00:18:12,799 --> 00:18:17,840
but in fact in the remaining storage

00:18:15,840 --> 00:18:18,480
container merger which is responsible

00:18:17,840 --> 00:18:21,919
for

00:18:18,480 --> 00:18:25,039
replicating huge binary blobs

00:18:21,919 --> 00:18:25,919
in fact this responsible for replicating

00:18:25,039 --> 00:18:28,240
containers

00:18:25,919 --> 00:18:30,240
this is this is why we call it storage

00:18:28,240 --> 00:18:32,400
container manager

00:18:30,240 --> 00:18:34,320
and the metadata of the blocks are

00:18:32,400 --> 00:18:36,880
handled by the data nodes

00:18:34,320 --> 00:18:38,000
this is another big advantage because in

00:18:36,880 --> 00:18:40,400
the data node

00:18:38,000 --> 00:18:42,000
reports only containers so it doesn't

00:18:40,400 --> 00:18:45,039
matter how many files do

00:18:42,000 --> 00:18:48,160
you have you can just scale it

00:18:45,039 --> 00:18:49,679
up without any little bit so let's go

00:18:48,160 --> 00:18:53,280
back to my

00:18:49,679 --> 00:18:55,600
ozone cluster so it's just running here

00:18:53,280 --> 00:18:56,640
and let's try to find something which is

00:18:55,600 --> 00:19:00,400
related to the

00:18:56,640 --> 00:19:03,760
containers so i'm going to check the

00:19:00,400 --> 00:19:06,400
uh going to the leader node

00:19:03,760 --> 00:19:06,400
so i just

00:19:06,799 --> 00:19:12,480
attached my shell to the leader node and

00:19:09,600 --> 00:19:15,440
first of all i need a few objects

00:19:12,480 --> 00:19:17,760
ozone has an internal load generator

00:19:15,440 --> 00:19:20,080
this is prion because you know that

00:19:17,760 --> 00:19:21,360
freon is the enemy of the ozone right

00:19:20,080 --> 00:19:23,360
the ozone layer

00:19:21,360 --> 00:19:24,720
so and the load generator is the biggest

00:19:23,360 --> 00:19:26,799
enemy of a storage

00:19:24,720 --> 00:19:28,400
so we have a load generator which can be

00:19:26,799 --> 00:19:31,120
used to generate

00:19:28,400 --> 00:19:31,919
a lot of keys in different uh different

00:19:31,120 --> 00:19:34,559
way

00:19:31,919 --> 00:19:36,720
so let's start with this ozone client

00:19:34,559 --> 00:19:39,120
generator

00:19:36,720 --> 00:19:41,120
also freon just to have some data

00:19:39,120 --> 00:19:41,919
because it's a brand new cluster so i

00:19:41,120 --> 00:19:46,480
need

00:19:41,919 --> 00:19:48,960
100 keys

00:19:46,480 --> 00:19:49,840
and okay this is just generated so i

00:19:48,960 --> 00:19:53,360
have a few

00:19:49,840 --> 00:19:55,840
keys generated

00:19:53,360 --> 00:19:58,080
and now i can use an other ozone

00:19:55,840 --> 00:20:00,559
subcommand the ozone inside

00:19:58,080 --> 00:20:01,600
so there are multiple inside points and

00:20:00,559 --> 00:20:05,280
one

00:20:01,600 --> 00:20:08,159
is the heartbeat so i can just check

00:20:05,280 --> 00:20:09,520
what's going on heartbeat level so with

00:20:08,159 --> 00:20:13,200
with the variables mode

00:20:09,520 --> 00:20:14,320
minus v i can see the rpc protocol

00:20:13,200 --> 00:20:18,000
content

00:20:14,320 --> 00:20:18,880
so the heartbeat here so this is the

00:20:18,000 --> 00:20:21,280
heartbeat

00:20:18,880 --> 00:20:23,280
from the data node to the leader node

00:20:21,280 --> 00:20:24,400
and you don't need to understand all of

00:20:23,280 --> 00:20:27,280
the details

00:20:24,400 --> 00:20:28,080
but something which is interesting is

00:20:27,280 --> 00:20:31,200
that

00:20:28,080 --> 00:20:34,480
okay this these are pipeline reports

00:20:31,200 --> 00:20:37,919
i think the containers are already

00:20:34,480 --> 00:20:39,760
already reported back to the

00:20:37,919 --> 00:20:41,760
yeah we have an incremental container

00:20:39,760 --> 00:20:44,880
report

00:20:41,760 --> 00:20:44,880
so let's go to

00:20:45,440 --> 00:20:49,840
here and just generate a few other

00:20:52,000 --> 00:20:57,200
keys and we can see that what's going on

00:20:56,400 --> 00:20:59,679
here

00:20:57,200 --> 00:21:00,880
so this is the heartbeat from the i'm

00:20:59,679 --> 00:21:02,480
looking for something which is the

00:21:00,880 --> 00:21:04,720
container

00:21:02,480 --> 00:21:04,720
but

00:21:05,919 --> 00:21:09,360
i need to wait that so the problem is

00:21:08,240 --> 00:21:12,400
that i'm not

00:21:09,360 --> 00:21:16,080
lucky enough because the the

00:21:12,400 --> 00:21:19,120
heartbeat heartbeat

00:21:16,080 --> 00:21:21,919
uh period is 30 minutes

00:21:19,120 --> 00:21:23,440
okay so let's check if we have a new oh

00:21:21,919 --> 00:21:26,240
we have the container report

00:21:23,440 --> 00:21:27,919
you see that we don't need to understand

00:21:26,240 --> 00:21:30,240
all of the details but here what we can

00:21:27,919 --> 00:21:33,679
see is that the

00:21:30,240 --> 00:21:35,600
replication unit is container

00:21:33,679 --> 00:21:37,520
so we are not talking about some kind of

00:21:35,600 --> 00:21:40,400
blocks but we are talking about oh

00:21:37,520 --> 00:21:42,880
i have the container id it's open it's

00:21:40,400 --> 00:21:45,520
we have some space which is used

00:21:42,880 --> 00:21:47,360
and it doesn't matter what kind of

00:21:45,520 --> 00:21:50,159
blocks are stored here

00:21:47,360 --> 00:21:52,799
okay let's go back to the the

00:21:50,159 --> 00:21:55,840
presentation

00:21:52,799 --> 00:21:57,440
third difference and actually it's not

00:21:55,840 --> 00:22:00,400
just a difference but it's a very

00:21:57,440 --> 00:22:02,320
important rule of ozone or the ozone

00:22:00,400 --> 00:22:05,120
development that we wouldn't like to

00:22:02,320 --> 00:22:06,400
reinvent the wheel that's very very

00:22:05,120 --> 00:22:09,440
important when the

00:22:06,400 --> 00:22:11,200
ozone is designed just because the

00:22:09,440 --> 00:22:13,840
storage itself

00:22:11,200 --> 00:22:16,320
or or writing a new storage it's it's

00:22:13,840 --> 00:22:20,240
very comp it's already very complex

00:22:16,320 --> 00:22:24,880
so to make it stable enough

00:22:20,240 --> 00:22:29,039
it's uh the better to reuse

00:22:24,880 --> 00:22:33,039
existing technologies or well-known

00:22:29,039 --> 00:22:35,919
solutions okay when we replicate

00:22:33,039 --> 00:22:38,240
the data we need to replicate two parts

00:22:35,919 --> 00:22:40,400
the real data the byte array

00:22:38,240 --> 00:22:41,840
and some kind of metanator right block

00:22:40,400 --> 00:22:45,280
information

00:22:41,840 --> 00:22:47,919
for the metadata replication we use raft

00:22:45,280 --> 00:22:50,080
roughly is a very well known algorithm

00:22:47,919 --> 00:22:51,520
and it's a consensus algorithm for

00:22:50,080 --> 00:22:55,600
managing replicated

00:22:51,520 --> 00:22:58,159
log and it's an understandable consensus

00:22:55,600 --> 00:22:58,159
algorithm

00:22:58,400 --> 00:23:02,880
let's talk about this two part

00:22:59,840 --> 00:23:06,480
replicated log and understandable

00:23:02,880 --> 00:23:08,960
so it seems to be a little bit complex

00:23:06,480 --> 00:23:10,960
this page and

00:23:08,960 --> 00:23:13,280
it's not required to understand all of

00:23:10,960 --> 00:23:16,000
the details but this is the main

00:23:13,280 --> 00:23:16,960
structure of the raft that the raft

00:23:16,000 --> 00:23:20,400
itself

00:23:16,960 --> 00:23:23,600
replicates commands or actions so in

00:23:20,400 --> 00:23:25,840
we can see here three data nodes

00:23:23,600 --> 00:23:27,679
and there is one leader which is elected

00:23:25,840 --> 00:23:30,799
by the three data nodes

00:23:27,679 --> 00:23:32,640
and the new commands in case of ozone

00:23:30,799 --> 00:23:37,120
it's some kind of fright

00:23:32,640 --> 00:23:41,279
are replicated in in the form of a log

00:23:37,120 --> 00:23:43,520
and if a new command or action

00:23:41,279 --> 00:23:44,320
is added to the majority of the data

00:23:43,520 --> 00:23:47,520
nodes

00:23:44,320 --> 00:23:48,640
it will be applied to to the state

00:23:47,520 --> 00:23:51,039
machine which is

00:23:48,640 --> 00:23:51,760
some shared state or or well-defined

00:23:51,039 --> 00:23:55,440
state like

00:23:51,760 --> 00:23:59,279
a data internal database or or memory

00:23:55,440 --> 00:24:02,559
that's the main structure of uh

00:23:59,279 --> 00:24:05,440
of raft so it's it's uh

00:24:02,559 --> 00:24:06,159
it's defined as a replicated log but it

00:24:05,440 --> 00:24:08,080
in fact

00:24:06,159 --> 00:24:09,279
we are just replicating the data or the

00:24:08,080 --> 00:24:11,440
state

00:24:09,279 --> 00:24:12,799
the understandable it's coming from the

00:24:11,440 --> 00:24:14,799
original paper

00:24:12,799 --> 00:24:16,000
so there is a short version of the paper

00:24:14,799 --> 00:24:19,360
which is just uh

00:24:16,000 --> 00:24:20,159
20 pages and and long version which is a

00:24:19,360 --> 00:24:23,039
phd

00:24:20,159 --> 00:24:25,520
and i think it's 200 pages so

00:24:23,039 --> 00:24:29,039
understandable doesn't mean simple

00:24:25,520 --> 00:24:30,320
but it's supposed to be easier to

00:24:29,039 --> 00:24:32,880
implement or

00:24:30,320 --> 00:24:35,360
or easier to maintain because this uh

00:24:32,880 --> 00:24:38,559
understandable property

00:24:35,360 --> 00:24:41,039
so also news is apacheratis which is an

00:24:38,559 --> 00:24:43,360
incubator project and it's embeddable

00:24:41,039 --> 00:24:45,039
that's very very important so if you

00:24:43,360 --> 00:24:47,200
have ever used zookeeper

00:24:45,039 --> 00:24:48,559
you can sync it like a zookeeper which

00:24:47,200 --> 00:24:51,279
can be started

00:24:48,559 --> 00:24:52,240
inside the process it's also very

00:24:51,279 --> 00:24:54,640
flexible

00:24:52,240 --> 00:24:57,279
so you can plug in different type of

00:24:54,640 --> 00:24:58,640
transport hadoop or pc grpc you can

00:24:57,279 --> 00:25:01,520
replace the state machine

00:24:58,640 --> 00:25:02,000
you can replace the persistence layer

00:25:01,520 --> 00:25:05,679
and it's

00:25:02,000 --> 00:25:08,480
also very fast so it tested

00:25:05,679 --> 00:25:09,039
with ozone and it has a lot of advanced

00:25:08,480 --> 00:25:12,240
feature

00:25:09,039 --> 00:25:15,120
to to batch multiple requests and and

00:25:12,240 --> 00:25:17,840
send out ad hoc heartbeats and so on

00:25:15,120 --> 00:25:19,120
this raft implementation is used in two

00:25:17,840 --> 00:25:23,200
places in ozone

00:25:19,120 --> 00:25:24,799
one for aj so for high availability

00:25:23,200 --> 00:25:26,240
for the leader nodes we need to

00:25:24,799 --> 00:25:29,440
replicate the state

00:25:26,240 --> 00:25:30,400
the other one if the data node itself so

00:25:29,440 --> 00:25:33,760
this is the

00:25:30,400 --> 00:25:35,840
the high level picture

00:25:33,760 --> 00:25:38,400
so let's say i have hundred of data

00:25:35,840 --> 00:25:41,200
nodes the hundred of data nodes

00:25:38,400 --> 00:25:42,000
are split to three data node groups

00:25:41,200 --> 00:25:45,200
which are

00:25:42,000 --> 00:25:47,279
forming this quorum they are electing

00:25:45,200 --> 00:25:48,320
one leader and the client will connect

00:25:47,279 --> 00:25:50,320
to the leader

00:25:48,320 --> 00:25:52,159
and the data replication between the

00:25:50,320 --> 00:25:56,000
leader and the follower is just

00:25:52,159 --> 00:25:59,440
good old raft which is a standard

00:25:56,000 --> 00:26:01,840
standard algorithm and widely used for

00:25:59,440 --> 00:26:04,159
example the etcd which is the back end

00:26:01,840 --> 00:26:05,760
of the back-end store of kubernetes uses

00:26:04,159 --> 00:26:09,279
exactly the same algorithm

00:26:05,760 --> 00:26:12,559
raft so

00:26:09,279 --> 00:26:14,320
let's go back to here it's very yeah

00:26:12,559 --> 00:26:15,840
it's it's harder to see that we have

00:26:14,320 --> 00:26:18,880
raft but

00:26:15,840 --> 00:26:22,320
i can try to prove it with some okay

00:26:18,880 --> 00:26:22,799
so we can check the log of the data node

00:26:22,320 --> 00:26:25,039
and

00:26:22,799 --> 00:26:26,240
unfortunately it's printed out to the

00:26:25,039 --> 00:26:28,320
standalone

00:26:26,240 --> 00:26:30,080
standard error so i'm just redirecting

00:26:28,320 --> 00:26:34,320
to the standard output

00:26:30,080 --> 00:26:36,240
and candidate what we can see here is

00:26:34,320 --> 00:26:38,640
some kind of leader election

00:26:36,240 --> 00:26:40,159
inside the data node so i have just

00:26:38,640 --> 00:26:43,520
three data nodes which means

00:26:40,159 --> 00:26:46,480
that uh it's one single uh

00:26:43,520 --> 00:26:48,400
group or quorum but we can say that

00:26:46,480 --> 00:26:51,279
there's some kind of leader action as

00:26:48,400 --> 00:26:52,080
here which will do all of the data

00:26:51,279 --> 00:26:56,320
replication

00:26:52,080 --> 00:27:01,600
between the data nodes

00:26:56,320 --> 00:27:01,600
okay well third third

00:27:02,000 --> 00:27:08,480
big difference the persistence

00:27:05,279 --> 00:27:12,000
actually so what we need to do

00:27:08,480 --> 00:27:13,679
is uh we already discussed that the

00:27:12,000 --> 00:27:16,400
storage is that uh

00:27:13,679 --> 00:27:18,320
storing data and some kind of metadata

00:27:16,400 --> 00:27:20,799
how can where can we store metadata

00:27:18,320 --> 00:27:22,880
there are multiple options so one option

00:27:20,799 --> 00:27:25,919
is just store everything in the memory

00:27:22,880 --> 00:27:27,760
actually this is what hdfs

00:27:25,919 --> 00:27:29,360
follow other one is just storing

00:27:27,760 --> 00:27:30,640
everything in an external database in

00:27:29,360 --> 00:27:32,480
that case the

00:27:30,640 --> 00:27:34,240
high availability is not our problem

00:27:32,480 --> 00:27:34,640
anymore because we can just store in a

00:27:34,240 --> 00:27:37,919
high

00:27:34,640 --> 00:27:38,880
available key value store this is for

00:27:37,919 --> 00:27:41,600
example

00:27:38,880 --> 00:27:43,200
uh followed by the hope surface and

00:27:41,600 --> 00:27:45,360
there is an other option

00:27:43,200 --> 00:27:46,799
to keep something in the memory which

00:27:45,360 --> 00:27:50,320
fits in the memory

00:27:46,799 --> 00:27:53,679
but also use very fast local store

00:27:50,320 --> 00:27:55,919
and this is what we do with ozone

00:27:53,679 --> 00:27:58,720
you remember that this is our number one

00:27:55,919 --> 00:28:02,000
rule that do not reinvent the wheel

00:27:58,720 --> 00:28:05,200
so what we are doing is uh again just

00:28:02,000 --> 00:28:08,399
ozone uses a a very well known

00:28:05,200 --> 00:28:11,760
uh solution roxdb which is

00:28:08,399 --> 00:28:12,240
a fork of leveldb and it's a local

00:28:11,760 --> 00:28:15,600
keyway

00:28:12,240 --> 00:28:18,880
store so it's something like the sqlite

00:28:15,600 --> 00:28:21,360
locally you can use it as a keyway store

00:28:18,880 --> 00:28:22,960
there is no server just you can use it

00:28:21,360 --> 00:28:25,679
from your

00:28:22,960 --> 00:28:27,120
your process and it's based on the

00:28:25,679 --> 00:28:30,080
structured merge trees

00:28:27,120 --> 00:28:32,640
and it's widely used so there is a

00:28:30,080 --> 00:28:33,919
storage backend for mysql so it's

00:28:32,640 --> 00:28:36,799
very very well tested

00:28:33,919 --> 00:28:39,120
and very very very fast so we don't

00:28:36,799 --> 00:28:40,159
ozone doesn't need to keep everything in

00:28:39,120 --> 00:28:44,159
the memory

00:28:40,159 --> 00:28:44,960
because it's uh it's fast enough to to

00:28:44,159 --> 00:28:47,360
persist

00:28:44,960 --> 00:28:49,360
something on the disk and just uh

00:28:47,360 --> 00:28:52,159
reading it when it's required

00:28:49,360 --> 00:28:52,960
with very very good caching so this is

00:28:52,159 --> 00:28:57,200
again as

00:28:52,960 --> 00:29:01,520
uh it's a very very big help

00:28:57,200 --> 00:29:04,240
for for getting better scalability

00:29:01,520 --> 00:29:04,640
okay let's just go back to the cluster

00:29:04,240 --> 00:29:08,559
and

00:29:04,640 --> 00:29:13,919
try to find something which is roxdb

00:29:08,559 --> 00:29:16,000
related so this is my cluster

00:29:13,919 --> 00:29:17,760
i have this uh so this is one of the

00:29:16,000 --> 00:29:20,480
leader nodes

00:29:17,760 --> 00:29:22,559
and here i have just some kind of

00:29:20,480 --> 00:29:26,159
database so this seems to be

00:29:22,559 --> 00:29:27,919
a roxdb

00:29:26,159 --> 00:29:29,360
but we don't know what is inside right

00:29:27,919 --> 00:29:32,799
this is a local

00:29:29,360 --> 00:29:36,000
local fish but rock cb provides an

00:29:32,799 --> 00:29:39,279
um a tool

00:29:36,000 --> 00:29:42,720
which can just i think it's list

00:29:39,279 --> 00:29:45,200
column families

00:29:42,720 --> 00:29:46,720
you can print out all of the internal

00:29:45,200 --> 00:29:50,799
column families

00:29:46,720 --> 00:29:54,000
so i think it's

00:29:50,799 --> 00:29:57,200
column family

00:29:54,000 --> 00:29:58,480
equals containers we we discussed that

00:29:57,200 --> 00:30:01,279
containers are

00:29:58,480 --> 00:30:02,960
are the unit of their applications so

00:30:01,279 --> 00:30:05,919
let's try to scan

00:30:02,960 --> 00:30:08,000
them okay i have one containers

00:30:05,919 --> 00:30:10,399
unfortunately i couldn't see

00:30:08,000 --> 00:30:11,760
the real content because again and in

00:30:10,399 --> 00:30:15,760
this industry standard

00:30:11,760 --> 00:30:18,880
protobuf is used here fortunately

00:30:15,760 --> 00:30:22,159
i have an ozone helper method

00:30:18,880 --> 00:30:26,880
which can do exactly the same and

00:30:22,159 --> 00:30:26,880
parse all of the data so

00:30:27,360 --> 00:30:31,440
yes so this is the parsed version of the

00:30:29,919 --> 00:30:35,200
the same data

00:30:31,440 --> 00:30:37,840
this is actually the available

00:30:35,200 --> 00:30:38,559
data node group but oh no this is the

00:30:37,840 --> 00:30:41,279
available

00:30:38,559 --> 00:30:43,440
container so this is just one container

00:30:41,279 --> 00:30:45,600
it's replicated with retis

00:30:43,440 --> 00:30:47,679
and this is the usage statistics which

00:30:45,600 --> 00:30:49,120
can be used so there is no information

00:30:47,679 --> 00:30:52,080
about the blocks here

00:30:49,120 --> 00:30:54,399
but i also can check the data node

00:30:52,080 --> 00:30:59,120
groups i think it was pipeline and not

00:30:54,399 --> 00:30:59,120
pipelines emit pipelines

00:30:59,519 --> 00:31:03,360
oh so this is the content of the local

00:31:01,440 --> 00:31:06,080
db just with all of the

00:31:03,360 --> 00:31:07,120
data know that all of the node

00:31:06,080 --> 00:31:10,640
information

00:31:07,120 --> 00:31:13,760
which is uh maintained on the leader

00:31:10,640 --> 00:31:16,159
side so let's go back

00:31:13,760 --> 00:31:17,039
to the presentation and last one is the

00:31:16,159 --> 00:31:20,320
usability

00:31:17,039 --> 00:31:22,799
so this is my favorite one and there

00:31:20,320 --> 00:31:24,000
are multiple dimension dimension of the

00:31:22,799 --> 00:31:27,120
usability

00:31:24,000 --> 00:31:28,720
first of all we already we have already

00:31:27,120 --> 00:31:32,799
seen that how easy

00:31:28,720 --> 00:31:34,320
is to start uh ozone just cd compose

00:31:32,799 --> 00:31:36,000
ozone docker compose app

00:31:34,320 --> 00:31:38,640
you can do exactly the same with the

00:31:36,000 --> 00:31:41,840
secure cluster so it's very very easy

00:31:38,640 --> 00:31:44,240
to it's let's say 30 seconds

00:31:41,840 --> 00:31:45,039
to start a secure cluster locally just

00:31:44,240 --> 00:31:47,440
try it out

00:31:45,039 --> 00:31:49,200
with with real notes in in with the help

00:31:47,440 --> 00:31:51,200
of containerization

00:31:49,200 --> 00:31:53,360
for me it's very important i think we

00:31:51,200 --> 00:31:56,640
need to invest a lot just to

00:31:53,360 --> 00:31:59,600
to provide better developer and and

00:31:56,640 --> 00:32:00,240
operation usability the other one with

00:31:59,600 --> 00:32:02,960
what we

00:32:00,240 --> 00:32:04,159
already we already discussed that it

00:32:02,960 --> 00:32:07,120
should be available

00:32:04,159 --> 00:32:09,679
not only from for the hadoop

00:32:07,120 --> 00:32:13,039
compatibilify system but for example

00:32:09,679 --> 00:32:13,440
aws s3 just to make it easier to use

00:32:13,039 --> 00:32:17,679
from

00:32:13,440 --> 00:32:18,720
a python command so for example if i go

00:32:17,679 --> 00:32:21,919
to here

00:32:18,720 --> 00:32:26,559
and i use this aws command line

00:32:21,919 --> 00:32:26,559
it's pure aws you can

00:32:27,200 --> 00:32:32,880
you can use it for real aws or

00:32:30,799 --> 00:32:35,279
you can use ozone the only thing what

00:32:32,880 --> 00:32:40,399
you need just change the end point

00:32:35,279 --> 00:32:40,399
and let's say i'm creating a bucket and

00:32:40,559 --> 00:32:46,399
bucket equals bucket one just let's try

00:32:43,519 --> 00:32:46,399
to create one bucket

00:32:46,640 --> 00:32:50,240
it's created so it works exactly as the

00:32:49,360 --> 00:32:53,360
aws

00:32:50,240 --> 00:32:54,559
s3 so that's the other important part of

00:32:53,360 --> 00:32:57,600
the usability

00:32:54,559 --> 00:33:00,080
and i believe that we comparing with the

00:32:57,600 --> 00:33:02,480
hdfs we need to work a lot to make the

00:33:00,080 --> 00:33:05,039
developer and administration

00:33:02,480 --> 00:33:06,320
experience better for example we

00:33:05,039 --> 00:33:09,440
introduced

00:33:06,320 --> 00:33:10,080
and some tagging process to make it

00:33:09,440 --> 00:33:12,159
easier to

00:33:10,080 --> 00:33:14,559
understand many many configuration

00:33:12,159 --> 00:33:17,760
options which is usually available for

00:33:14,559 --> 00:33:19,440
for hadoop components and

00:33:17,760 --> 00:33:21,679
you have already seen that we have

00:33:19,440 --> 00:33:25,279
different type of

00:33:21,679 --> 00:33:28,640
of tools like the freon or inside

00:33:25,279 --> 00:33:31,200
what i just demonstrated earlier

00:33:28,640 --> 00:33:33,120
so this is the web ui this is also for

00:33:31,200 --> 00:33:34,480
the usability just uh this is a

00:33:33,120 --> 00:33:37,519
separated component

00:33:34,480 --> 00:33:38,000
which can download all of the data from

00:33:37,519 --> 00:33:40,640
the

00:33:38,000 --> 00:33:41,440
other services it can store it

00:33:40,640 --> 00:33:45,200
historically

00:33:41,440 --> 00:33:48,320
it can predict what will happen

00:33:45,200 --> 00:33:51,600
for example if out of space

00:33:48,320 --> 00:33:53,039
error can be expected and it can help to

00:33:51,600 --> 00:33:55,039
understand that the

00:33:53,039 --> 00:33:56,720
status of the containers looks and

00:33:55,039 --> 00:34:01,279
everything

00:33:56,720 --> 00:34:04,840
so this is the quick overview of

00:34:01,279 --> 00:34:06,000
of ozone and with the help of

00:34:04,840 --> 00:34:09,359
differentiate

00:34:06,000 --> 00:34:11,359
between ozone and hdfs

00:34:09,359 --> 00:34:13,679
if you are more interested i can also

00:34:11,359 --> 00:34:14,800
recommend a youtube channel so ozone has

00:34:13,679 --> 00:34:16,639
a youtube

00:34:14,800 --> 00:34:18,079
channel and there are two playlists one

00:34:16,639 --> 00:34:21,520
is the ozone explained

00:34:18,079 --> 00:34:23,760
which is very similar to this talk just

00:34:21,520 --> 00:34:25,520
discussing about different type of

00:34:23,760 --> 00:34:27,839
architectural questions

00:34:25,520 --> 00:34:29,280
and ozone development can be useful for

00:34:27,839 --> 00:34:32,000
the contributors so

00:34:29,280 --> 00:34:34,399
for example how to debug ozone in your

00:34:32,000 --> 00:34:37,440
ide or how to build it or

00:34:34,399 --> 00:34:38,320
how to run it in in kubernetes so i can

00:34:37,440 --> 00:34:41,280
recommend

00:34:38,320 --> 00:34:42,960
these uh just search for apache hadoop

00:34:41,280 --> 00:34:46,399
ozone

00:34:42,960 --> 00:34:47,040
uh in the youtube and and you can follow

00:34:46,399 --> 00:34:50,240
it

00:34:47,040 --> 00:34:53,520
or you can just ping me or

00:34:50,240 --> 00:34:56,879
join to the check the ozone

00:34:53,520 --> 00:35:02,800
channel on the asf slack

00:34:56,879 --> 00:35:05,920
and questions

00:35:02,800 --> 00:35:05,920
any question

00:35:08,960 --> 00:35:13,359
how are you doing scale testing for like

00:35:10,720 --> 00:35:14,400
billion files how are we generating test

00:35:13,359 --> 00:35:15,680
data

00:35:14,400 --> 00:35:18,240
very good questions so there are

00:35:15,680 --> 00:35:21,599
multiple ways one way is just to

00:35:18,240 --> 00:35:25,040
make ozone fast enough to generate a

00:35:21,599 --> 00:35:26,000
a lot of data so we did a 1 billion key

00:35:25,040 --> 00:35:29,599
test

00:35:26,000 --> 00:35:33,200
to with real

00:35:29,599 --> 00:35:34,079
and and it worked well this is what we

00:35:33,200 --> 00:35:37,839
did

00:35:34,079 --> 00:35:41,280
and there is a new development

00:35:37,839 --> 00:35:41,520
uh new issue or new proposal to develop

00:35:41,280 --> 00:35:44,720
an

00:35:41,520 --> 00:35:48,240
offline data generator tool which can

00:35:44,720 --> 00:35:50,720
generate a lot of data even faster so

00:35:48,240 --> 00:35:51,599
generating one billion key was a few

00:35:50,720 --> 00:35:54,720
days

00:35:51,599 --> 00:35:57,680
but we will have a

00:35:54,720 --> 00:35:58,640
an offline generator very soon which can

00:35:57,680 --> 00:36:02,400
prove

00:35:58,640 --> 00:36:06,160
that we we have uh

00:36:02,400 --> 00:36:07,920
we can handle 10 billions of keys

00:36:06,160 --> 00:36:10,400
also supports authentication and

00:36:07,920 --> 00:36:12,960
encryption like hdfs kerberos

00:36:10,400 --> 00:36:14,160
yes so awesome based on hydropower pc so

00:36:12,960 --> 00:36:16,720
the encryption part

00:36:14,160 --> 00:36:18,480
is uh or the security is very very

00:36:16,720 --> 00:36:20,560
similar to the hdfs this is the

00:36:18,480 --> 00:36:22,720
spiritual successor part

00:36:20,560 --> 00:36:23,839
and there are a little difference that

00:36:22,720 --> 00:36:27,359
the block tokens

00:36:23,839 --> 00:36:28,720
are a little bit smarter but the basic

00:36:27,359 --> 00:36:30,800
kerberos info is very

00:36:28,720 --> 00:36:32,079
the basic kerberos architecture is very

00:36:30,800 --> 00:36:33,760
very similar

00:36:32,079 --> 00:36:36,640
and yes we have transparent data

00:36:33,760 --> 00:36:39,040
encryption exactly the same as uh

00:36:36,640 --> 00:36:42,079
as the hdfs so you need the key ms and

00:36:39,040 --> 00:36:42,079
you can just use it

00:36:44,320 --> 00:36:48,240
why do you think when do you think ozone

00:36:46,560 --> 00:36:51,280
will be stable enough to migrate

00:36:48,240 --> 00:36:54,480
existing production hdfs cluster yes

00:36:51,280 --> 00:36:55,680
that's a very good question so the the

00:36:54,480 --> 00:36:59,040
last release

00:36:55,680 --> 00:37:02,240
it's it's the first 1.00 release

00:36:59,040 --> 00:37:05,440
and actually we are testing a lot to

00:37:02,240 --> 00:37:09,440
to make it as stable as possible i know

00:37:05,440 --> 00:37:11,760
about one one company one chinese

00:37:09,440 --> 00:37:15,280
company who uses it in production

00:37:11,760 --> 00:37:15,920
even today but this is a totally new

00:37:15,280 --> 00:37:18,380
product

00:37:15,920 --> 00:37:19,599
that that's a good question i

00:37:18,380 --> 00:37:21,680
[Music]

00:37:19,599 --> 00:37:23,359
i think it would the best approach is

00:37:21,680 --> 00:37:26,480
just try it out and

00:37:23,359 --> 00:37:30,240
start with a small dataset

00:37:26,480 --> 00:37:32,480
so so

00:37:30,240 --> 00:37:34,320
if you would like to use you can just

00:37:32,480 --> 00:37:37,520
try it out and test it

00:37:34,320 --> 00:37:39,359
and and migrate incrementally the data

00:37:37,520 --> 00:37:42,079
you can start with none

00:37:39,359 --> 00:37:43,920
with not so critical data i think so

00:37:42,079 --> 00:37:47,200
there will be a separated talk from

00:37:43,920 --> 00:37:49,440
umar tomorrow about ufs which can be

00:37:47,200 --> 00:37:52,160
a an interesting approach where you can

00:37:49,440 --> 00:37:53,839
just change one directory from hdfs to

00:37:52,160 --> 00:37:55,599
ozone

00:37:53,839 --> 00:37:56,960
and it's also an awesome impact on age

00:37:55,599 --> 00:38:00,240
based use cases

00:37:56,960 --> 00:38:00,720
yes so that's uh we already had some age

00:38:00,240 --> 00:38:04,000
based

00:38:00,720 --> 00:38:07,520
testis tests but we

00:38:04,000 --> 00:38:10,640
need some more work for full hb support

00:38:07,520 --> 00:38:14,079
because the different approach how

00:38:10,640 --> 00:38:16,960
hdfs and ozone handles the

00:38:14,079 --> 00:38:18,000
hsync and and sync which are required

00:38:16,960 --> 00:38:21,200
for hbase so this

00:38:18,000 --> 00:38:23,760
is still in progress

00:38:21,200 --> 00:38:26,000
how do you compare ozone to objects

00:38:23,760 --> 00:38:28,240
ozone do object stores so ozone itself

00:38:26,000 --> 00:38:30,960
is an object store under the hood

00:38:28,240 --> 00:38:33,680
but so it's a first plus object store so

00:38:30,960 --> 00:38:35,920
we have keys and values that's all

00:38:33,680 --> 00:38:37,520
but because we would like to support the

00:38:35,920 --> 00:38:40,800
use cases of hdfs

00:38:37,520 --> 00:38:43,760
there are some tricky secondary indexes

00:38:40,800 --> 00:38:44,720
to provide very good experience for all

00:38:43,760 --> 00:38:48,400
of the

00:38:44,720 --> 00:38:50,880
hadoop compatible file system so

00:38:48,400 --> 00:38:51,760
comparing with other it depends so it's

00:38:50,880 --> 00:38:54,160
a new project

00:38:51,760 --> 00:38:55,920
and i think one of the main selling

00:38:54,160 --> 00:38:58,000
point is that

00:38:55,920 --> 00:38:59,440
it is a first-class citizen of all of

00:38:58,000 --> 00:39:01,599
the hadoop environments

00:38:59,440 --> 00:39:02,800
and it has the same or actually better

00:39:01,599 --> 00:39:05,839
scalability

00:39:02,800 --> 00:39:08,000
to the than hdfs so there are other

00:39:05,839 --> 00:39:10,800
object store but

00:39:08,000 --> 00:39:12,400
but it uses the same architecture what

00:39:10,800 --> 00:39:15,359
hdfs is used

00:39:12,400 --> 00:39:15,920
or almost the subsidy revisited the hdfs

00:39:15,359 --> 00:39:18,960
so

00:39:15,920 --> 00:39:21,359
it can provide the same stability and

00:39:18,960 --> 00:39:24,320
and scalability or better scalability

00:39:21,359 --> 00:39:28,000
than hdfs

00:39:24,320 --> 00:39:29,760
oh ozone mini i o so yeah that's the big

00:39:28,000 --> 00:39:31,280
that's a that's a good question i mean i

00:39:29,760 --> 00:39:34,720
o is older

00:39:31,280 --> 00:39:37,839
but so actually when

00:39:34,720 --> 00:39:41,040
i shared one picture about the three

00:39:37,839 --> 00:39:43,839
data nodes which are creating

00:39:41,040 --> 00:39:45,599
air of group so by default min io is

00:39:43,839 --> 00:39:48,480
nothing more just that one group

00:39:45,599 --> 00:39:49,680
and you need a separated federation as

00:39:48,480 --> 00:39:53,359
far as i know

00:39:49,680 --> 00:39:56,800
minao to achieve to to have multiple

00:39:53,359 --> 00:40:00,079
pipelines so

00:39:56,800 --> 00:40:02,880
it can be compared but

00:40:00,079 --> 00:40:03,520
actually ozone is is more like the hdfs

00:40:02,880 --> 00:40:05,599
when

00:40:03,520 --> 00:40:06,880
we are from the beginning we are

00:40:05,599 --> 00:40:11,280
thinking about

00:40:06,880 --> 00:40:14,800
uh using thousands of nodes

00:40:11,280 --> 00:40:14,800
what do you think is recording with

00:40:15,119 --> 00:40:18,400
yes it definitely will be supported so

00:40:17,680 --> 00:40:21,440
there is a

00:40:18,400 --> 00:40:22,960
that is the next big big uh thing

00:40:21,440 --> 00:40:24,640
the eraser the question is the is

00:40:22,960 --> 00:40:28,240
recording support in ozone

00:40:24,640 --> 00:40:31,280
and this is the the next item in uh

00:40:28,240 --> 00:40:32,720
on the list to do it

00:40:31,280 --> 00:40:34,400
because we have different type of

00:40:32,720 --> 00:40:36,319
architecture with these containers it

00:40:34,400 --> 00:40:38,480
can be different from the hdfs and there

00:40:36,319 --> 00:40:40,480
is an active

00:40:38,480 --> 00:40:42,319
design process in the community so there

00:40:40,480 --> 00:40:44,480
is a dedicated selection

00:40:42,319 --> 00:40:46,800
if somebody is interested there is also

00:40:44,480 --> 00:40:48,800
a design dock in the

00:40:46,800 --> 00:40:49,920
dryer but it's still not finished there

00:40:48,800 --> 00:40:52,960
are multiple options

00:40:49,920 --> 00:40:55,280
and will be considered is it better to

00:40:52,960 --> 00:40:57,280
migrate from hdfs to ozone or to close

00:40:55,280 --> 00:40:59,200
bit solution like

00:40:57,280 --> 00:41:00,960
so that's another question it's on-prem

00:40:59,200 --> 00:41:03,440
or not on-prem so

00:41:00,960 --> 00:41:04,160
the the goal with the ozone that any

00:41:03,440 --> 00:41:06,960
time when

00:41:04,160 --> 00:41:08,240
you would like to move from cloud to

00:41:06,960 --> 00:41:11,359
on-prem or on-prem

00:41:08,240 --> 00:41:14,560
to cloud on-prem you can just use ozone

00:41:11,359 --> 00:41:15,440
so ozone supposed to be compatible with

00:41:14,560 --> 00:41:19,280
s3

00:41:15,440 --> 00:41:21,680
so you can decide in any way at any time

00:41:19,280 --> 00:41:22,560
that that's the goal if you need cloud

00:41:21,680 --> 00:41:24,720
or on-prem

00:41:22,560 --> 00:41:25,760
this this is your it depends from the

00:41:24,720 --> 00:41:27,839
use case

00:41:25,760 --> 00:41:29,839
i think it's it's very good to use an

00:41:27,839 --> 00:41:32,079
object store in an operand

00:41:29,839 --> 00:41:34,560
but there are a lot of factors but the

00:41:32,079 --> 00:41:36,480
main goal is provide something

00:41:34,560 --> 00:41:38,319
which which is like the object store

00:41:36,480 --> 00:41:41,760
like the s3 and that keys

00:41:38,319 --> 00:41:45,839
you can free to free to

00:41:41,760 --> 00:41:47,839
move any data between cloud and on-prem

00:41:45,839 --> 00:41:50,560
because you can use exactly the same

00:41:47,839 --> 00:41:53,599
applications or

00:41:50,560 --> 00:41:53,599
in both environments

00:41:55,599 --> 00:41:59,440
okay hope i answered all of the

00:41:57,839 --> 00:42:00,720
questions

00:41:59,440 --> 00:42:02,720
thank you very much if you are

00:42:00,720 --> 00:42:05,200
interested ozone also has a weekly

00:42:02,720 --> 00:42:08,960
community meeting you can find it on the

00:42:05,200 --> 00:42:11,200
hadoop wiki and

00:42:08,960 --> 00:42:13,440
you can just join and ask on the asf's

00:42:11,200 --> 00:42:17,280
like asf slack order

00:42:13,440 --> 00:42:22,000
or the or the

00:42:17,280 --> 00:42:25,200
community meeting so thank you very much

00:42:22,000 --> 00:42:28,839
all of the questions or you can ping me

00:42:25,200 --> 00:42:31,839
at any time in the in this hop-in

00:42:28,839 --> 00:42:31,839
platform

00:43:36,160 --> 00:43:38,240

YouTube URL: https://www.youtube.com/watch?v=IXTRPp5l5mk


