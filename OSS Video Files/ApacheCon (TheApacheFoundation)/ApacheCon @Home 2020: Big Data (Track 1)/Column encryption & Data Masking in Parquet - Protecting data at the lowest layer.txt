Title: Column encryption & Data Masking in Parquet - Protecting data at the lowest layer
Publication date: 2020-10-21
Playlist: ApacheCon @Home 2020: Big Data (Track 1)
Description: 
	Column encryption & Data Masking in Parquet - Protecting data at the lowest layer
Pavi Subenderan, Xinli Shang

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

In a typical big dataset, only a minority of columns are actually sensitive and need to be protected. Columnar file formats like Apache Parquet allow for column level access control through encryption. This means the small number of sensitive columns in a dataset can be protected through encryption, while the non-sensitive columns can be open for access. Data masking features for encrypted columns bring further convenience and allows users to leverage encrypted columns even without access to them. The combination of column encryption and data masking maximizes accessibility to your data without compromising the security of sensitive data. In the first half, we will go over column encryption design and features in Parquet. We will cover considerations when operating parquet column encryption in production like Key Management Service, performance tradeoffs, encryption algorithm choice, etc. In the second half, we will cover the new Data Masking features in Parquet. There will be discussion about motivation behind data masking, the security implications of masking and implementation. Finally we will look at the tradeoffs between the different types of masks and the limitations of each type in terms of compression ratio, table joins, usability and administration overhead.

Pavi Subenderan:
Pavi is a Software Engineer on Uber's Data Infra team. His focus is on data security, privacy and open source big data technologies. He has been working on Parquet column encryption for 1.5 years and more recently on data masking.
Xinli Shang:
Xinli Shang is a tech lead on the Uber Data Infra team, Apache Parquet Committer. He is passionate about big data file format for efficiency, performance and security, tuning large scale services for performance, throughput, and reliability. He is an active contributor to Apache Parquet. He also has many years of experience developing large scale distributed systems like S3 Index, and operating system Windows.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:25,439 --> 00:00:33,280
okay i think we can get started okay

00:00:30,960 --> 00:00:35,280
all right hello everyone welcome to the

00:00:33,280 --> 00:00:36,800
session on parquet column encryption and

00:00:35,280 --> 00:00:38,399
data masking

00:00:36,800 --> 00:00:40,320
today we're going to talk about how you

00:00:38,399 --> 00:00:43,440
can use column encryption

00:00:40,320 --> 00:00:45,760
to secure your data at the lowest layer

00:00:43,440 --> 00:00:46,480
we'll also touch on the new data masking

00:00:45,760 --> 00:00:49,920
feature

00:00:46,480 --> 00:00:49,920
that we are actively working on

00:00:51,360 --> 00:00:55,920
my name is pavvy and i'm a software

00:00:53,039 --> 00:00:58,320
engineer in uber's data infrawork

00:00:55,920 --> 00:01:00,079
i'm a member of the big data security

00:00:58,320 --> 00:01:01,840
team and i have been working on parquet

00:01:00,079 --> 00:01:03,680
calling level access control for the

00:01:01,840 --> 00:01:06,080
past two years

00:01:03,680 --> 00:01:08,240
i'm also joined today by shin li who is

00:01:06,080 --> 00:01:09,280
a technical lead manager in uber data

00:01:08,240 --> 00:01:12,880
infra

00:01:09,280 --> 00:01:14,479
he is also a parquet committer and he's

00:01:12,880 --> 00:01:17,759
been working on column encryption at

00:01:14,479 --> 00:01:17,759
uber since the very start

00:01:18,720 --> 00:01:22,080
let's go over the agenda on what we're

00:01:20,159 --> 00:01:23,360
going to be covering today

00:01:22,080 --> 00:01:25,600
first of all we're going to go over the

00:01:23,360 --> 00:01:28,799
motivation of clac

00:01:25,600 --> 00:01:31,360
so like why exactly do uh do we

00:01:28,799 --> 00:01:32,640
want column encryption and what is it

00:01:31,360 --> 00:01:35,759
next we're going to go over

00:01:32,640 --> 00:01:37,840
how clec fits into a typical stack

00:01:35,759 --> 00:01:39,680
so we look at a typical data stack and

00:01:37,840 --> 00:01:41,920
talk about how we can integrate column

00:01:39,680 --> 00:01:43,439
encryption into it

00:01:41,920 --> 00:01:45,119
after that we're going to take a closer

00:01:43,439 --> 00:01:45,840
look on how exactly column encryption

00:01:45,119 --> 00:01:47,759
works

00:01:45,840 --> 00:01:49,600
we'll dive into the apache parquet

00:01:47,759 --> 00:01:51,520
implementation as well as look

00:01:49,600 --> 00:01:53,280
into the details of the other systems

00:01:51,520 --> 00:01:56,560
involved to bring

00:01:53,280 --> 00:01:58,159
calm level access control to production

00:01:56,560 --> 00:01:59,520
and lastly we'll talk about the new

00:01:58,159 --> 00:02:01,040
feature we are currently working on

00:01:59,520 --> 00:02:02,960
called data masking

00:02:01,040 --> 00:02:05,280
we'll talk about the initial design and

00:02:02,960 --> 00:02:06,799
the features which we are planning

00:02:05,280 --> 00:02:08,560
i want to highlight that this feature is

00:02:06,799 --> 00:02:09,679
currently in poc phase and a lot is

00:02:08,560 --> 00:02:11,599
subject to change

00:02:09,679 --> 00:02:13,040
but we definitely see data masking as an

00:02:11,599 --> 00:02:14,400
important feature for the smooth

00:02:13,040 --> 00:02:16,080
productionizing

00:02:14,400 --> 00:02:18,800
of column level access control in an

00:02:16,080 --> 00:02:18,800
organization

00:02:20,959 --> 00:02:26,080
okay so what is going to be covered and

00:02:23,840 --> 00:02:28,000
what are we not going to cover

00:02:26,080 --> 00:02:29,840
we will talk about how to achieve

00:02:28,000 --> 00:02:31,760
fine-grained access control within your

00:02:29,840 --> 00:02:33,680
hadoop data lake

00:02:31,760 --> 00:02:35,760
we will emphasize how parquet column

00:02:33,680 --> 00:02:37,760
encryption fits within a typical stack

00:02:35,760 --> 00:02:39,280
and we'll try to focus on technologies

00:02:37,760 --> 00:02:40,959
both the open source ones and the

00:02:39,280 --> 00:02:43,840
internal tools that we built

00:02:40,959 --> 00:02:45,680
to support this technology however

00:02:43,840 --> 00:02:47,360
please note that we are not covering all

00:02:45,680 --> 00:02:49,599
aspects of data security

00:02:47,360 --> 00:02:51,840
this isn't legal advice or legal

00:02:49,599 --> 00:02:51,840
guidance

00:02:54,160 --> 00:02:58,879
okay let's jump in on why we need column

00:02:55,840 --> 00:03:00,640
encryption so there's several reasons

00:02:58,879 --> 00:03:03,040
first of all column encryption allows us

00:03:00,640 --> 00:03:06,239
to protect data at the lowest level

00:03:03,040 --> 00:03:08,159
by going through the parquet file format

00:03:06,239 --> 00:03:10,159
this means we are protecting data at the

00:03:08,159 --> 00:03:10,959
file level and it ultimately protects

00:03:10,159 --> 00:03:14,400
the data

00:03:10,959 --> 00:03:16,000
from all possible access paths secondly

00:03:14,400 --> 00:03:17,200
an important observation that can be

00:03:16,000 --> 00:03:19,519
made

00:03:17,200 --> 00:03:21,040
is that in a typical wide data set

00:03:19,519 --> 00:03:23,599
there's only a small percentage of

00:03:21,040 --> 00:03:25,599
columns that are actually confidential

00:03:23,599 --> 00:03:27,920
by enabling fine grain control over your

00:03:25,599 --> 00:03:30,560
data you're able to protect exactly what

00:03:27,920 --> 00:03:32,319
needs to be protected

00:03:30,560 --> 00:03:34,799
the consequence of column level access

00:03:32,319 --> 00:03:36,319
control is that we can open up data sets

00:03:34,799 --> 00:03:39,440
while still protecting the

00:03:36,319 --> 00:03:41,840
critical data appropriately in practice

00:03:39,440 --> 00:03:43,360
it is not uncommon uh in the data

00:03:41,840 --> 00:03:45,680
analytics world for a table to have

00:03:43,360 --> 00:03:47,440
hundreds of columns but only a few

00:03:45,680 --> 00:03:50,080
handful of columns need to be

00:03:47,440 --> 00:03:50,080
protected

00:03:51,519 --> 00:03:55,360
all right let's go over a query

00:03:52,720 --> 00:03:57,680
comparison so you can kind of see the

00:03:55,360 --> 00:04:00,239
what the difference between clec and no

00:03:57,680 --> 00:04:03,120
clc is in practice

00:04:00,239 --> 00:04:04,319
so on top here we have a few no clec

00:04:03,120 --> 00:04:06,640
examples

00:04:04,319 --> 00:04:08,000
where we only have table level control

00:04:06,640 --> 00:04:09,920
enabled

00:04:08,000 --> 00:04:11,439
so we have two examples here example one

00:04:09,920 --> 00:04:14,319
and example two

00:04:11,439 --> 00:04:15,120
and the results of these queries and

00:04:14,319 --> 00:04:17,919
there's either

00:04:15,120 --> 00:04:19,359
a access denied sign or a check mark

00:04:17,919 --> 00:04:23,759
based on if the

00:04:19,359 --> 00:04:26,720
query is passed so in example one

00:04:23,759 --> 00:04:28,320
uh we have a select on four columns and

00:04:26,720 --> 00:04:31,759
the columns are a

00:04:28,320 --> 00:04:34,320
id email and b

00:04:31,759 --> 00:04:35,680
email and id are highlighted in red

00:04:34,320 --> 00:04:39,440
because they're considered

00:04:35,680 --> 00:04:41,360
sensitive data and the result of this

00:04:39,440 --> 00:04:42,960
is that the user's access is not because

00:04:41,360 --> 00:04:45,360
they don't have permissions to read a

00:04:42,960 --> 00:04:46,960
table with sensitive data

00:04:45,360 --> 00:04:49,600
now in example two we have a similar

00:04:46,960 --> 00:04:51,120
select but this time the user is not

00:04:49,600 --> 00:04:52,400
actually trying to read any sensitive

00:04:51,120 --> 00:04:54,080
information

00:04:52,400 --> 00:04:55,680
they're only trying to read a and b

00:04:54,080 --> 00:04:57,440
which are not sensitive

00:04:55,680 --> 00:04:59,840
however under table level control the

00:04:57,440 --> 00:05:01,440
user's access is still denied

00:04:59,840 --> 00:05:04,800
because permissions can only be

00:05:01,440 --> 00:05:07,520
controlled at table level granularity

00:05:04,800 --> 00:05:09,440
without clac we have to block all access

00:05:07,520 --> 00:05:13,919
to that table both pii access

00:05:09,440 --> 00:05:17,360
and non-pii access for that user

00:05:13,919 --> 00:05:19,280
okay now in the bottom part we have uh

00:05:17,360 --> 00:05:20,639
we can look at some queries in the clc

00:05:19,280 --> 00:05:22,560
enabled world

00:05:20,639 --> 00:05:24,000
so example three here we have a similar

00:05:22,560 --> 00:05:25,360
query to example one where we're

00:05:24,000 --> 00:05:26,960
trying to read all these all these

00:05:25,360 --> 00:05:28,639
columns including id and email which are

00:05:26,960 --> 00:05:30,880
sensitive

00:05:28,639 --> 00:05:32,400
uh and this time we still have to reject

00:05:30,880 --> 00:05:34,240
this query because the user doesn't have

00:05:32,400 --> 00:05:36,320
access

00:05:34,240 --> 00:05:38,000
however now it's example four when the

00:05:36,320 --> 00:05:39,759
user only

00:05:38,000 --> 00:05:43,360
does not query any sensitive columns the

00:05:39,759 --> 00:05:45,680
user's query is permitted

00:05:43,360 --> 00:05:46,639
basically we only block actual pi

00:05:45,680 --> 00:05:50,880
queries but we

00:05:46,639 --> 00:05:52,320
now allow non-pii queries to pass

00:05:50,880 --> 00:05:54,639
okay so now i'm going to pass it to shin

00:05:52,320 --> 00:05:56,400
lee who'll go more in depth on how clac

00:05:54,639 --> 00:05:58,080
fits into the typical stack

00:05:56,400 --> 00:05:59,919
and he'll dive more into the parking

00:05:58,080 --> 00:06:02,639
internals

00:05:59,919 --> 00:06:04,319
thanks pb uh let's talk about it from

00:06:02,639 --> 00:06:07,039
the use case perspective

00:06:04,319 --> 00:06:08,880
what does the data lake stack aesthetic

00:06:07,039 --> 00:06:10,960
looks like

00:06:08,880 --> 00:06:11,919
why the big data fail format is

00:06:10,960 --> 00:06:14,160
important

00:06:11,919 --> 00:06:14,960
and why we have the access control at

00:06:14,160 --> 00:06:18,160
the ferrule format

00:06:14,960 --> 00:06:20,560
level so in the typical

00:06:18,160 --> 00:06:21,280
big data stack the user considers a

00:06:20,560 --> 00:06:23,280
query

00:06:21,280 --> 00:06:24,800
to call the data for many different

00:06:23,280 --> 00:06:26,479
reasons for

00:06:24,800 --> 00:06:28,880
business intelligence for machine

00:06:26,479 --> 00:06:30,960
learning etc the query

00:06:28,880 --> 00:06:32,639
sends through the query engines have

00:06:30,960 --> 00:06:36,000
spark priced etc

00:06:32,639 --> 00:06:39,759
eventually arrive their data storage

00:06:36,000 --> 00:06:43,600
maybe hdfs it could be other system

00:06:39,759 --> 00:06:44,400
file system so the data returned to the

00:06:43,600 --> 00:06:46,720
current genes

00:06:44,400 --> 00:06:48,720
the current into the joints the filters

00:06:46,720 --> 00:06:52,560
etc and give back to

00:06:48,720 --> 00:06:52,560
the user next slides please

00:06:54,560 --> 00:07:00,720
now the challenge here is the exercise

00:06:58,319 --> 00:07:03,120
to the storage could be from any angle

00:07:00,720 --> 00:07:05,039
with any access it could be sql could be

00:07:03,120 --> 00:07:07,599
non-sql it could be direct success

00:07:05,039 --> 00:07:08,800
the user can download the file directly

00:07:07,599 --> 00:07:11,120
and

00:07:08,800 --> 00:07:12,000
the hdfs for example is just a file

00:07:11,120 --> 00:07:15,199
system

00:07:12,000 --> 00:07:17,919
it doesn't have the concept of color

00:07:15,199 --> 00:07:17,919
next slide please

00:07:19,280 --> 00:07:24,400
now the file format came to the picture

00:07:22,240 --> 00:07:24,400
the

00:07:28,840 --> 00:07:31,840
leg

00:07:36,720 --> 00:07:40,639
the big data file format is between the

00:07:39,840 --> 00:07:44,000
layer of

00:07:40,639 --> 00:07:47,199
compute and storage the poke library

00:07:44,000 --> 00:07:49,039
for example is linked with the car

00:07:47,199 --> 00:07:52,319
engines like compressed to

00:07:49,039 --> 00:07:54,400
spark tab etc but the data that a

00:07:52,319 --> 00:07:56,080
structure is is installed in the file

00:07:54,400 --> 00:07:59,759
system like

00:07:56,080 --> 00:08:02,080
their hdfs so you can imagine

00:07:59,759 --> 00:08:03,280
it is a rather place in the in the big

00:08:02,080 --> 00:08:07,120
data file format

00:08:03,280 --> 00:08:13,440
to have their column encryption in place

00:08:07,120 --> 00:08:16,000
next slide please

00:08:13,440 --> 00:08:17,840
so the high-level approach here is let's

00:08:16,000 --> 00:08:21,120
do the access control as

00:08:17,840 --> 00:08:24,639
the file format and we only encrypted

00:08:21,120 --> 00:08:28,319
the sensitive columns in hdfs

00:08:24,639 --> 00:08:31,120
let's talk about it by public

00:08:28,319 --> 00:08:33,039
and also the size control to the column

00:08:31,120 --> 00:08:33,599
is done by the access control on the

00:08:33,039 --> 00:08:36,320
keys

00:08:33,599 --> 00:08:36,959
in the kms you have the permission to

00:08:36,320 --> 00:08:39,039
the

00:08:36,959 --> 00:08:40,959
key and then you have the permission you

00:08:39,039 --> 00:08:44,399
have ability to decrypt the

00:08:40,959 --> 00:08:46,880
column otherwise because access denied

00:08:44,399 --> 00:08:46,880
next slide

00:08:48,640 --> 00:08:53,440
let's room either proclaim for a little

00:08:51,360 --> 00:08:54,160
bit more detail and build up the context

00:08:53,440 --> 00:08:56,880
here

00:08:54,160 --> 00:08:58,560
so procreate is a column storage the

00:08:56,880 --> 00:09:01,200
data from the same column

00:08:58,560 --> 00:09:01,839
will be put together that will make

00:09:01,200 --> 00:09:05,760
their

00:09:01,839 --> 00:09:08,640
data smaller make the query faster

00:09:05,760 --> 00:09:09,279
now for given cookie file there's a

00:09:08,640 --> 00:09:12,160
footer

00:09:09,279 --> 00:09:13,839
it has a schema have the metadata etc

00:09:12,160 --> 00:09:16,959
all the needed information

00:09:13,839 --> 00:09:18,640
for you to access the file now the the

00:09:16,959 --> 00:09:20,839
data of the file

00:09:18,640 --> 00:09:23,680
is divided into the different rule

00:09:20,839 --> 00:09:25,839
groups for a given row group

00:09:23,680 --> 00:09:28,160
is divided into the different column

00:09:25,839 --> 00:09:30,480
chunks so each column chunk is

00:09:28,160 --> 00:09:33,279
corresponding to a color

00:09:30,480 --> 00:09:35,200
now for a given column chunk is further

00:09:33,279 --> 00:09:38,240
divided into pages

00:09:35,200 --> 00:09:39,200
so page is that you need that we do the

00:09:38,240 --> 00:09:42,320
encoding

00:09:39,200 --> 00:09:47,680
compression and

00:09:42,320 --> 00:09:47,680
encryption next slides please

00:09:49,760 --> 00:09:53,040
let's look into the column encryption

00:09:51,760 --> 00:09:56,080
conceptually

00:09:53,040 --> 00:09:57,200
from a high level so in this example you

00:09:56,080 --> 00:10:00,000
have a table

00:09:57,200 --> 00:10:01,519
which only have two columns c1 column

00:10:00,000 --> 00:10:04,000
one c2 column two

00:10:01,519 --> 00:10:04,800
so column one is a plain text not

00:10:04,000 --> 00:10:08,079
sensitive

00:10:04,800 --> 00:10:10,079
column 2 is sensitive in the red path

00:10:08,079 --> 00:10:12,959
which is also encryption pass

00:10:10,079 --> 00:10:15,040
the poke application for example spark

00:10:12,959 --> 00:10:18,640
presto etc

00:10:15,040 --> 00:10:19,760
so it invokes the poker agi and tells

00:10:18,640 --> 00:10:22,880
for crazy

00:10:19,760 --> 00:10:23,760
hey column 2 is sensitive and please

00:10:22,880 --> 00:10:26,079
encrypt it

00:10:23,760 --> 00:10:27,040
with this key so pass the key to the

00:10:26,079 --> 00:10:28,959
focal library

00:10:27,040 --> 00:10:31,839
pogo library will just eat to the

00:10:28,959 --> 00:10:33,519
encryption now you can encrypt the data

00:10:31,839 --> 00:10:36,240
now poke will also

00:10:33,519 --> 00:10:37,839
snow the key metadata along with

00:10:36,240 --> 00:10:40,399
encrypted data

00:10:37,839 --> 00:10:41,440
and send to the air for the storage to

00:10:40,399 --> 00:10:43,600
store it

00:10:41,440 --> 00:10:47,360
the storage could be any it doesn't have

00:10:43,600 --> 00:10:50,959
to be hdfx it could be s3 etc

00:10:47,360 --> 00:10:53,600
now on the reading path when the reader

00:10:50,959 --> 00:10:54,240
gets a poker file reads the metadata i

00:10:53,600 --> 00:10:57,519
know

00:10:54,240 --> 00:10:59,360
that column two is encrypted also you

00:10:57,519 --> 00:11:01,839
can get the key metadata

00:10:59,360 --> 00:11:03,360
so with this key metadata the reader

00:11:01,839 --> 00:11:06,160
should be able to

00:11:03,360 --> 00:11:07,360
get the key from the kms and do the

00:11:06,160 --> 00:11:09,600
decryption by the

00:11:07,360 --> 00:11:10,480
library if they have the permission to

00:11:09,600 --> 00:11:12,480
do so

00:11:10,480 --> 00:11:14,079
if they do not have permission they will

00:11:12,480 --> 00:11:16,720
get access deny

00:11:14,079 --> 00:11:17,360
or mask the value here we will talk

00:11:16,720 --> 00:11:20,880
about the

00:11:17,360 --> 00:11:20,880
data masking in the next slide

00:11:22,399 --> 00:11:25,120
next let's please

00:11:26,839 --> 00:11:33,200
uh at percent yeah

00:11:30,560 --> 00:11:35,040
conceptually the encryption and

00:11:33,200 --> 00:11:37,200
decryption is clear

00:11:35,040 --> 00:11:39,920
but when you rule out the query engines

00:11:37,200 --> 00:11:40,560
remember poke library is just a library

00:11:39,920 --> 00:11:43,120
that built

00:11:40,560 --> 00:11:45,519
is linked by their currencies when you

00:11:43,120 --> 00:11:47,680
roll out to spark to replace those etc

00:11:45,519 --> 00:11:48,720
there are several problems now the

00:11:47,680 --> 00:11:50,800
problem is

00:11:48,720 --> 00:11:51,760
how do you define that which column

00:11:50,800 --> 00:11:54,399
insensitive

00:11:51,760 --> 00:11:56,079
and what kind of key or which key that

00:11:54,399 --> 00:11:58,959
you want to use

00:11:56,079 --> 00:11:59,440
to do the encryption what we find out

00:11:58,959 --> 00:12:01,440
that

00:11:59,440 --> 00:12:03,839
it is convenient to define these

00:12:01,440 --> 00:12:06,399
settings along with the schema

00:12:03,839 --> 00:12:07,680
for example for column you have us even

00:12:06,399 --> 00:12:10,959
have a column name

00:12:07,680 --> 00:12:11,519
you have type nullable node or you can

00:12:10,959 --> 00:12:14,399
define

00:12:11,519 --> 00:12:15,360
this column is sensitive or not if it is

00:12:14,399 --> 00:12:17,519
what kind of key

00:12:15,360 --> 00:12:18,800
id you are going to use to get the key

00:12:17,519 --> 00:12:22,160
for the encryption

00:12:18,800 --> 00:12:25,040
so that will be along with the schema

00:12:22,160 --> 00:12:27,120
so we can turn the existing schema to

00:12:25,040 --> 00:12:28,800
have these settings we called out as

00:12:27,120 --> 00:12:32,880
crypto settings

00:12:28,800 --> 00:12:38,959
now we extend the proper writer support

00:12:32,880 --> 00:12:41,680
to convey these crypto settings schema

00:12:38,959 --> 00:12:42,639
now we also develop a craft receiver as

00:12:41,680 --> 00:12:45,440
a plugin

00:12:42,639 --> 00:12:47,440
which will consume those settings and

00:12:45,440 --> 00:12:48,320
the plugin will build up the encryption

00:12:47,440 --> 00:12:50,560
properties

00:12:48,320 --> 00:12:52,800
based on the settings now this is

00:12:50,560 --> 00:12:56,639
example of the spark

00:12:52,800 --> 00:12:59,839
in their diagram so you can define

00:12:56,639 --> 00:13:00,320
their crypto settings in the schema of

00:12:59,839 --> 00:13:03,360
spark

00:13:00,320 --> 00:13:04,800
construct field let's say the column one

00:13:03,360 --> 00:13:07,120
is defined as

00:13:04,800 --> 00:13:08,720
encryption as sensitive encrypted with

00:13:07,120 --> 00:13:11,440
some key id

00:13:08,720 --> 00:13:12,160
and then the for quick write support we

00:13:11,440 --> 00:13:15,120
intended

00:13:12,160 --> 00:13:17,040
just convert that to their pocket schema

00:13:15,120 --> 00:13:19,200
now the correct settings will do the

00:13:17,040 --> 00:13:21,760
craft retriever will do the magic work

00:13:19,200 --> 00:13:24,399
and build up the encryption

00:13:21,760 --> 00:13:25,040
properties based on the settings and

00:13:24,399 --> 00:13:27,920
invoke

00:13:25,040 --> 00:13:30,720
the proper api to do the encryption work

00:13:27,920 --> 00:13:30,720
next slides please

00:13:33,360 --> 00:13:39,760
so poke encryption has several options

00:13:36,720 --> 00:13:41,279
one is whether or not to encrypt the

00:13:39,760 --> 00:13:43,360
footer

00:13:41,279 --> 00:13:44,959
so fooder has all the schema metadata

00:13:43,360 --> 00:13:48,240
etc which is needed

00:13:44,959 --> 00:13:49,760
to access the file so if you want to

00:13:48,240 --> 00:13:52,560
encrypt the footer

00:13:49,760 --> 00:13:53,360
so any column that encrypted you want

00:13:52,560 --> 00:13:55,199
access

00:13:53,360 --> 00:13:57,040
the user need to have the permission to

00:13:55,199 --> 00:13:59,120
access the folder

00:13:57,040 --> 00:14:00,720
so increase the footer definitely will

00:13:59,120 --> 00:14:04,079
give you more security

00:14:00,720 --> 00:14:07,360
but it will add more complexity

00:14:04,079 --> 00:14:10,480
to your encryption second

00:14:07,360 --> 00:14:11,120
for the encryption algorithm okay green

00:14:10,480 --> 00:14:14,880
support

00:14:11,120 --> 00:14:18,639
aes tcm and aes ctr

00:14:14,880 --> 00:14:22,399
so gcm is on top of ctr it provided

00:14:18,639 --> 00:14:25,839
the provided integrity

00:14:22,399 --> 00:14:29,360
checks actually so

00:14:25,839 --> 00:14:32,000
so um it not only prevent

00:14:29,360 --> 00:14:33,199
their privileged unprivileged reading

00:14:32,000 --> 00:14:36,320
but also

00:14:33,199 --> 00:14:38,800
prevent the malicious mutation to the

00:14:36,320 --> 00:14:41,360
original data

00:14:38,800 --> 00:14:42,959
and third option is encryption with

00:14:41,360 --> 00:14:45,920
authentication

00:14:42,959 --> 00:14:49,440
so if you use a gcm you can provide the

00:14:45,920 --> 00:14:49,440
additional authentication data

00:14:49,839 --> 00:14:57,040
we call the aad now on the decryption

00:14:54,480 --> 00:14:59,360
if you provide the correct id you can

00:14:57,040 --> 00:15:03,120
decrypt the data otherwise in the field

00:14:59,360 --> 00:15:06,000
so it provides more security

00:15:03,120 --> 00:15:07,120
but it has a complexity so you can see

00:15:06,000 --> 00:15:11,600
all the options

00:15:07,120 --> 00:15:15,360
is a trade-off within complexity and

00:15:11,600 --> 00:15:15,360
as security and the overhead

00:15:15,680 --> 00:15:18,160
next slides

00:15:19,199 --> 00:15:24,720
okay so now let's talk about how

00:15:22,720 --> 00:15:26,000
we can manage the encryption keys which

00:15:24,720 --> 00:15:29,040
are necessary to do the

00:15:26,000 --> 00:15:30,079
actual encryption and decryption first

00:15:29,040 --> 00:15:31,759
of all the parquet

00:15:30,079 --> 00:15:33,920
encryption implementation is not

00:15:31,759 --> 00:15:34,880
restricted to any particular key

00:15:33,920 --> 00:15:38,240
management

00:15:34,880 --> 00:15:39,920
service solution is designed so any kms

00:15:38,240 --> 00:15:40,880
could be plugged in to do the job of key

00:15:39,920 --> 00:15:43,199
management

00:15:40,880 --> 00:15:44,079
the key metadata that is relevant to

00:15:43,199 --> 00:15:46,399
parquet

00:15:44,079 --> 00:15:49,199
is just a generic byte array which maps

00:15:46,399 --> 00:15:50,639
to a key in any kms

00:15:49,199 --> 00:15:52,959
basically you are free to choose from

00:15:50,639 --> 00:15:56,079
the vast array of kms offerings

00:15:52,959 --> 00:15:57,199
some examples include the open source

00:15:56,079 --> 00:15:59,920
family including

00:15:57,199 --> 00:16:02,399
hadoop kms ranger kms and there's

00:15:59,920 --> 00:16:08,079
several cloud kms providers like aws

00:16:02,399 --> 00:16:09,680
kms and many others

00:16:08,079 --> 00:16:11,199
now let's take a closer look at the

00:16:09,680 --> 00:16:14,800
integration and interface

00:16:11,199 --> 00:16:16,480
between the kms and parquet

00:16:14,800 --> 00:16:18,560
the integration is controlled through a

00:16:16,480 --> 00:16:20,240
plugin which is added to any query

00:16:18,560 --> 00:16:23,199
engine which needs to support column

00:16:20,240 --> 00:16:26,240
encrypted tables essentially this plugin

00:16:23,199 --> 00:16:28,079
is just a wrapper of a kms client with a

00:16:26,240 --> 00:16:29,839
few extra features

00:16:28,079 --> 00:16:31,519
it is responsible for taking the key

00:16:29,839 --> 00:16:33,440
metadata from parquet

00:16:31,519 --> 00:16:35,120
and retrieving encryption and decryption

00:16:33,440 --> 00:16:37,199
keys from the kms

00:16:35,120 --> 00:16:39,199
but it also has the job of serializing

00:16:37,199 --> 00:16:40,240
and deserializing the key metadata into

00:16:39,199 --> 00:16:43,120
a byte array

00:16:40,240 --> 00:16:45,120
which can be then be stored by parquet

00:16:43,120 --> 00:16:45,920
and lastly the plugin also controls

00:16:45,120 --> 00:16:47,920
additional

00:16:45,920 --> 00:16:49,279
uh encryption properties like the ones

00:16:47,920 --> 00:16:50,959
that shouldn't be mentioned

00:16:49,279 --> 00:16:53,199
like setting the encryption algorithm

00:16:50,959 --> 00:16:54,800
and footer modes

00:16:53,199 --> 00:16:56,480
i want to highlight that all key

00:16:54,800 --> 00:16:59,600
metadata required

00:16:56,480 --> 00:17:02,160
to read an encrypted parquet file

00:16:59,600 --> 00:17:04,319
is stored alongside the encrypted data

00:17:02,160 --> 00:17:06,400
in the parque metadata

00:17:04,319 --> 00:17:08,000
this is important because it ensures

00:17:06,400 --> 00:17:10,480
that the encrypted data is never

00:17:08,000 --> 00:17:12,160
separated from the keys that were used

00:17:10,480 --> 00:17:15,439
to encrypt them

00:17:12,160 --> 00:17:17,439
this prevents any situation uh you may

00:17:15,439 --> 00:17:18,720
you might get into where you have

00:17:17,439 --> 00:17:20,400
encrypted data

00:17:18,720 --> 00:17:23,199
and you don't know which keys should be

00:17:20,400 --> 00:17:25,280
used to decrypt it

00:17:23,199 --> 00:17:27,839
and lastly uh shinny touched on this but

00:17:25,280 --> 00:17:28,799
the kms is important for how we actually

00:17:27,839 --> 00:17:31,679
control

00:17:28,799 --> 00:17:32,080
who gets access to what data this is

00:17:31,679 --> 00:17:34,640
because

00:17:32,080 --> 00:17:36,799
we control access to a column by

00:17:34,640 --> 00:17:38,720
actually controlling the axles on the

00:17:36,799 --> 00:17:41,600
key in the kms

00:17:38,720 --> 00:17:43,360
for example if you want a certain user

00:17:41,600 --> 00:17:44,799
or a certain ldap group to be able to

00:17:43,360 --> 00:17:47,120
read

00:17:44,799 --> 00:17:48,880
a column encrypted with a certain key

00:17:47,120 --> 00:17:50,400
called key one

00:17:48,880 --> 00:17:52,880
we would grant the user or group

00:17:50,400 --> 00:17:55,840
permissions to to key one

00:17:52,880 --> 00:17:55,840
through the kms

00:17:58,320 --> 00:18:02,000
all right so what kind of performance

00:18:00,320 --> 00:18:02,880
overhead costs are we paying to get

00:18:02,000 --> 00:18:04,799
these

00:18:02,880 --> 00:18:06,880
cool column encryption encryption

00:18:04,799 --> 00:18:08,720
features

00:18:06,880 --> 00:18:10,559
our performance testing indicated

00:18:08,720 --> 00:18:13,039
roughly a 5.7

00:18:10,559 --> 00:18:15,440
right overhead and a 3.7 percent read

00:18:13,039 --> 00:18:17,520
overhead for column encryption

00:18:15,440 --> 00:18:19,039
if we break down this overhead it comes

00:18:17,520 --> 00:18:21,679
down to two parts

00:18:19,039 --> 00:18:23,840
one the first part is the round trip to

00:18:21,679 --> 00:18:25,200
the kms to retrieve the encryption and

00:18:23,840 --> 00:18:27,360
decryption keys

00:18:25,200 --> 00:18:30,559
and the second part is the actual

00:18:27,360 --> 00:18:32,480
encrypting and decrypting time

00:18:30,559 --> 00:18:34,720
we found that the network round trip to

00:18:32,480 --> 00:18:36,960
kms was minimal in our case

00:18:34,720 --> 00:18:38,080
uh both because of good kms client

00:18:36,960 --> 00:18:41,120
caching

00:18:38,080 --> 00:18:43,120
as well as low latency uh intranet

00:18:41,120 --> 00:18:45,360
deployment

00:18:43,120 --> 00:18:46,960
the majority of this overhead is

00:18:45,360 --> 00:18:50,320
actually spent in the actual

00:18:46,960 --> 00:18:51,840
encrypting and decrypting of the data

00:18:50,320 --> 00:18:53,600
please note that these tests however

00:18:51,840 --> 00:18:56,240
were run with 60

00:18:53,600 --> 00:18:56,799
of columns encrypted and most likely in

00:18:56,240 --> 00:18:58,240
practice

00:18:56,799 --> 00:19:00,720
you'll probably find that a lot of

00:18:58,240 --> 00:19:01,600
tables require even less columns to be

00:19:00,720 --> 00:19:03,360
encrypted

00:19:01,600 --> 00:19:04,960
sometimes maybe down even to the 10 to

00:19:03,360 --> 00:19:07,679
20 range

00:19:04,960 --> 00:19:09,120
the performance overhead will benefit as

00:19:07,679 --> 00:19:10,400
you reduce the percentage of columns

00:19:09,120 --> 00:19:12,160
that you need to encrypt

00:19:10,400 --> 00:19:14,400
so the numbers might be even better than

00:19:12,160 --> 00:19:14,400
this

00:19:15,919 --> 00:19:19,520
okay let's move on to the active work we

00:19:17,600 --> 00:19:22,640
are doing with data masking

00:19:19,520 --> 00:19:23,679
so what is data masking data masking is

00:19:22,640 --> 00:19:27,600
just the process

00:19:23,679 --> 00:19:30,160
of opposite data to users who do not

00:19:27,600 --> 00:19:31,760
have privileges to access a column

00:19:30,160 --> 00:19:33,919
if this isn't completely clear what this

00:19:31,760 --> 00:19:35,760
means don't worry we have some example

00:19:33,919 --> 00:19:38,559
data mask queries in the next few slides

00:19:35,760 --> 00:19:40,559
which will make it more clear

00:19:38,559 --> 00:19:42,960
so why do we want this data masking

00:19:40,559 --> 00:19:44,640
feature

00:19:42,960 --> 00:19:46,480
there's a few reasons so first of all

00:19:44,640 --> 00:19:47,840
data masking potentially enables users

00:19:46,480 --> 00:19:49,840
to do useful things

00:19:47,840 --> 00:19:51,120
without compromising the actual contents

00:19:49,840 --> 00:19:52,720
of the data

00:19:51,120 --> 00:19:54,160
additionally it can improve the overall

00:19:52,720 --> 00:19:55,360
user experience of using column

00:19:54,160 --> 00:19:57,120
encrypted tables

00:19:55,360 --> 00:19:58,880
this is because if a user tries to read

00:19:57,120 --> 00:19:59,840
an encrypted column which they don't

00:19:58,880 --> 00:20:01,360
have access to

00:19:59,840 --> 00:20:04,640
we can just give them mass values

00:20:01,360 --> 00:20:04,640
instead of rejecting their query

00:20:04,840 --> 00:20:08,720
outright

00:20:06,720 --> 00:20:10,400
okay uh now let's talk about the

00:20:08,720 --> 00:20:11,520
different types of masks that we're

00:20:10,400 --> 00:20:14,000
working on

00:20:11,520 --> 00:20:14,640
so first of all we have the null mask

00:20:14,000 --> 00:20:16,799
and

00:20:14,640 --> 00:20:18,480
basically what this mask does is it

00:20:16,799 --> 00:20:20,320
replaces the

00:20:18,480 --> 00:20:23,919
the values in a column that you don't

00:20:20,320 --> 00:20:25,520
have access to with null values

00:20:23,919 --> 00:20:27,120
also we have something called the hash

00:20:25,520 --> 00:20:30,960
mask

00:20:27,120 --> 00:20:32,720
this replaces uh values with precomputed

00:20:30,960 --> 00:20:34,799
hash values of the original data if the

00:20:32,720 --> 00:20:36,080
user doesn't have access

00:20:34,799 --> 00:20:38,720
and also we have something called the

00:20:36,080 --> 00:20:39,760
redact mask it displays predefined

00:20:38,720 --> 00:20:41,760
redacted data

00:20:39,760 --> 00:20:43,840
when the user doesn't have access and

00:20:41,760 --> 00:20:46,080
lastly we have the general user defined

00:20:43,840 --> 00:20:49,840
mask which is basically a mask that you

00:20:46,080 --> 00:20:49,840
can define yourself

00:20:50,000 --> 00:20:53,360
okay let's look let's look at the null

00:20:51,760 --> 00:20:55,520
mask and let's look at an example query

00:20:53,360 --> 00:20:57,440
here so on the right here we see

00:20:55,520 --> 00:20:59,760
we have an example query select star

00:20:57,440 --> 00:21:02,960
from the sum table db.table

00:20:59,760 --> 00:21:05,360
and this table has three columns uh id

00:21:02,960 --> 00:21:06,080
address and language and let's say id

00:21:05,360 --> 00:21:08,320
and language

00:21:06,080 --> 00:21:10,000
here are not sensitive columns so we get

00:21:08,320 --> 00:21:12,000
back values for this

00:21:10,000 --> 00:21:13,600
from the select like one two three or

00:21:12,000 --> 00:21:15,200
english french english

00:21:13,600 --> 00:21:16,880
however address is considered a

00:21:15,200 --> 00:21:18,559
sensitive column and this user happens

00:21:16,880 --> 00:21:21,840
to not have access to the column

00:21:18,559 --> 00:21:24,480
under the null mask they would get back

00:21:21,840 --> 00:21:25,679
nulls instead of the actual values so

00:21:24,480 --> 00:21:27,440
the advantage with this

00:21:25,679 --> 00:21:29,679
type of mask is that it's very simple

00:21:27,440 --> 00:21:31,679
and it's basically the bare minimum data

00:21:29,679 --> 00:21:33,520
masking feature

00:21:31,679 --> 00:21:35,440
however there are some limitations like

00:21:33,520 --> 00:21:37,280
there's no join ability that's possible

00:21:35,440 --> 00:21:39,200
with this kind of mask

00:21:37,280 --> 00:21:40,480
uh you can't really join on the on the

00:21:39,200 --> 00:21:41,760
mass data

00:21:40,480 --> 00:21:44,000
there and there's possibility of

00:21:41,760 --> 00:21:45,039
confusion between real null values and

00:21:44,000 --> 00:21:46,480
mass null values

00:21:45,039 --> 00:21:48,640
this is something the table owner needs

00:21:46,480 --> 00:21:50,080
to take into account when they

00:21:48,640 --> 00:21:52,480
are administrating this table and

00:21:50,080 --> 00:21:53,919
deciding whether or not

00:21:52,480 --> 00:21:56,240
or what type of mass they want to add to

00:21:53,919 --> 00:21:58,400
a column and lastly we're not

00:21:56,240 --> 00:21:59,840
really able to support required or not

00:21:58,400 --> 00:22:03,360
nullable columns as well

00:21:59,840 --> 00:22:06,240
with this type of mask okay

00:22:03,360 --> 00:22:07,520
next we have the hash mask so again we

00:22:06,240 --> 00:22:09,280
have an example query here where we're

00:22:07,520 --> 00:22:10,960
selecting the same columns

00:22:09,280 --> 00:22:12,400
uh this time the address column instead

00:22:10,960 --> 00:22:15,600
of being nulled

00:22:12,400 --> 00:22:16,880
uh is replaced with hash values of the

00:22:15,600 --> 00:22:20,000
original data

00:22:16,880 --> 00:22:20,320
so here the original addresses were were

00:22:20,000 --> 00:22:21,760
pre

00:22:20,320 --> 00:22:24,080
the hashes of the original address were

00:22:21,760 --> 00:22:26,720
precomputed and

00:22:24,080 --> 00:22:28,880
we get back the hashes of the addresses

00:22:26,720 --> 00:22:31,039
so the big advantage with this hash mask

00:22:28,880 --> 00:22:33,200
is that now table joins are suddenly

00:22:31,039 --> 00:22:35,039
possible even if the user doesn't have

00:22:33,200 --> 00:22:37,120
access to the original

00:22:35,039 --> 00:22:39,039
data like to the encrypt to decrypt the

00:22:37,120 --> 00:22:41,280
data

00:22:39,039 --> 00:22:42,799
however there's still some limitations

00:22:41,280 --> 00:22:45,360
uh for example

00:22:42,799 --> 00:22:47,039
uh it's an inefficient use of storage uh

00:22:45,360 --> 00:22:48,640
due to compression ratios

00:22:47,039 --> 00:22:50,640
since we're since we're storing like

00:22:48,640 --> 00:22:52,159
hash values this cut is not very good

00:22:50,640 --> 00:22:56,559
for compression ratios

00:22:52,159 --> 00:22:59,360
and in terms of implementation um

00:22:56,559 --> 00:23:00,559
this hash mask requires that hashes need

00:22:59,360 --> 00:23:02,880
to be pre-computed

00:23:00,559 --> 00:23:05,520
and stored alongside the encrypted data

00:23:02,880 --> 00:23:05,520
in the file

00:23:06,640 --> 00:23:10,080
okay and now we have the redact mask so

00:23:09,039 --> 00:23:11,840
again we have uh

00:23:10,080 --> 00:23:13,520
example query and this time we have a

00:23:11,840 --> 00:23:15,919
last name column

00:23:13,520 --> 00:23:16,720
uh and then what the redact mask

00:23:15,919 --> 00:23:19,760
basically does

00:23:16,720 --> 00:23:22,960
is it you see a portion of the of the

00:23:19,760 --> 00:23:24,880
data but most of it it is redacted

00:23:22,960 --> 00:23:26,960
and this is i want to know this is up to

00:23:24,880 --> 00:23:27,840
the control of the table owner the table

00:23:26,960 --> 00:23:30,159
owner

00:23:27,840 --> 00:23:32,000
basically decides the level of redaction

00:23:30,159 --> 00:23:34,480
that they believe is necessary and which

00:23:32,000 --> 00:23:36,159
columns they think they should redact

00:23:34,480 --> 00:23:37,919
uh and the advantage here with the

00:23:36,159 --> 00:23:39,840
redact mask is that it's probably the

00:23:37,919 --> 00:23:42,480
most human-friendly mask

00:23:39,840 --> 00:23:42,880
compared to like the hash mask which is

00:23:42,480 --> 00:23:45,279
uh

00:23:42,880 --> 00:23:47,200
these hash values the redact mask is

00:23:45,279 --> 00:23:50,480
much more sensible for a human

00:23:47,200 --> 00:23:51,919
or user and the limitations here is

00:23:50,480 --> 00:23:53,200
again this is not really usable for

00:23:51,919 --> 00:23:56,480
joins

00:23:53,200 --> 00:23:58,559
uh we can't support all data types so

00:23:56,480 --> 00:24:00,240
for example string data types might make

00:23:58,559 --> 00:24:03,120
a lot of sense to redact

00:24:00,240 --> 00:24:04,320
but if you have some integer column that

00:24:03,120 --> 00:24:07,360
might not make sense

00:24:04,320 --> 00:24:09,200
uh to have a redact mask on it so it's

00:24:07,360 --> 00:24:11,039
really up to the table owner to decide

00:24:09,200 --> 00:24:12,720
which types of which columns

00:24:11,039 --> 00:24:15,039
uh are appropriate for which type of

00:24:12,720 --> 00:24:17,520
mask and lastly again this is

00:24:15,039 --> 00:24:18,720
uh inefficient use of storage because

00:24:17,520 --> 00:24:21,600
the redacted data needs to be

00:24:18,720 --> 00:24:25,039
pre-computed and stored in the file

00:24:21,600 --> 00:24:25,039
which is yeah bad for storage

00:24:26,799 --> 00:24:32,000
okay so here's some usability and design

00:24:30,080 --> 00:24:33,679
considerations that we

00:24:32,000 --> 00:24:35,919
are taking into account as we build out

00:24:33,679 --> 00:24:38,000
this poc feature

00:24:35,919 --> 00:24:39,840
first of all one key observation that we

00:24:38,000 --> 00:24:42,799
made is that in a typical data

00:24:39,840 --> 00:24:44,000
ecosystem queries are run both by humans

00:24:42,799 --> 00:24:45,279
and machines

00:24:44,000 --> 00:24:46,960
so it's important to take into

00:24:45,279 --> 00:24:49,039
consideration when it comes to design

00:24:46,960 --> 00:24:50,720
rollout and implementation

00:24:49,039 --> 00:24:52,080
basically data masking might be

00:24:50,720 --> 00:24:53,840
intuitive to a human

00:24:52,080 --> 00:24:55,919
but may cause issues with automated

00:24:53,840 --> 00:24:57,679
systems and we want

00:24:55,919 --> 00:25:01,440
any solution we come up with to be

00:24:57,679 --> 00:25:03,520
flexible for both types of use cases

00:25:01,440 --> 00:25:04,799
the second point is about clear

00:25:03,520 --> 00:25:07,120
communication between

00:25:04,799 --> 00:25:09,120
mass values and real values the

00:25:07,120 --> 00:25:10,960
usability of data masking relies on

00:25:09,120 --> 00:25:13,360
users knowing and expecting mass

00:25:10,960 --> 00:25:14,880
values basically we don't want to

00:25:13,360 --> 00:25:18,080
surprise users with mass

00:25:14,880 --> 00:25:19,919
values when they expect real values

00:25:18,080 --> 00:25:22,320
and lastly in terms of rollout we need

00:25:19,919 --> 00:25:24,000
to aim to minimize disruption

00:25:22,320 --> 00:25:25,919
and this goes back to the previous point

00:25:24,000 --> 00:25:27,360
of minimizing surprises

00:25:25,919 --> 00:25:28,720
rolling out without a well-thought-out

00:25:27,360 --> 00:25:32,159
strategy could break things since we're

00:25:28,720 --> 00:25:32,159
modifying query results

00:25:33,520 --> 00:25:36,960
okay so let's do a quick recap on what

00:25:35,600 --> 00:25:38,559
we touched on today

00:25:36,960 --> 00:25:40,559
so first of all we talked about how

00:25:38,559 --> 00:25:43,600
column encryption enables fine grain

00:25:40,559 --> 00:25:46,320
control over your data sets

00:25:43,600 --> 00:25:47,840
we talked about how how we decide to

00:25:46,320 --> 00:25:49,120
implement column encryption at the

00:25:47,840 --> 00:25:52,159
lowest level

00:25:49,120 --> 00:25:54,480
the parquet file format level so that

00:25:52,159 --> 00:25:56,799
so that to ensure protection from any

00:25:54,480 --> 00:25:58,799
access path

00:25:56,799 --> 00:26:01,039
permissions and apples are controlled at

00:25:58,799 --> 00:26:03,520
the key level by a plugable

00:26:01,039 --> 00:26:04,559
key management service and lastly we're

00:26:03,520 --> 00:26:06,640
working on

00:26:04,559 --> 00:26:10,240
poc for data masking for better user

00:26:06,640 --> 00:26:12,640
experience and convenience

00:26:10,240 --> 00:26:14,480
i want to uh highlight that at uber

00:26:12,640 --> 00:26:16,400
we're currently hiring for our team

00:26:14,480 --> 00:26:18,400
and to apply online at this link if

00:26:16,400 --> 00:26:19,360
you're interested or forward your resume

00:26:18,400 --> 00:26:21,360
to shin li

00:26:19,360 --> 00:26:24,400
at this email address and now we can

00:26:21,360 --> 00:26:25,679
take any questions now there is a

00:26:24,400 --> 00:26:28,400
question about

00:26:25,679 --> 00:26:30,640
separate keys for the different columns

00:26:28,400 --> 00:26:33,440
so the design of the

00:26:30,640 --> 00:26:34,480
encryption uh support that so every

00:26:33,440 --> 00:26:38,000
different columns

00:26:34,480 --> 00:26:40,640
you can have its own key uh

00:26:38,000 --> 00:26:42,320
but in the real use case if you want to

00:26:40,640 --> 00:26:43,440
use the same key that's okay for the

00:26:42,320 --> 00:26:46,000
different column

00:26:43,440 --> 00:26:47,120
it's it's essentially it depends on your

00:26:46,000 --> 00:26:49,200
requirement

00:26:47,120 --> 00:26:50,480
for example you have the two columns

00:26:49,200 --> 00:26:53,520
that have the

00:26:50,480 --> 00:26:55,200
have the same groups people to access

00:26:53,520 --> 00:26:57,679
the same card you can use the same key

00:26:55,200 --> 00:26:58,559
because the key is the place that where

00:26:57,679 --> 00:27:01,200
you manage

00:26:58,559 --> 00:27:03,039
the access so doing that you have the

00:27:01,200 --> 00:27:05,120
less number of the keys

00:27:03,039 --> 00:27:06,400
of course if you want a different

00:27:05,120 --> 00:27:09,360
columns have different key

00:27:06,400 --> 00:27:09,360
focus upon that

00:27:13,919 --> 00:27:20,559
for the redact all user defined mask

00:27:17,919 --> 00:27:21,440
can mask the value be completely user

00:27:20,559 --> 00:27:24,320
defined

00:27:21,440 --> 00:27:24,960
replace a last name with another random

00:27:24,320 --> 00:27:28,799
one

00:27:24,960 --> 00:27:31,440
a date with randomly shifted one

00:27:28,799 --> 00:27:32,399
maybe you want take this question yeah

00:27:31,440 --> 00:27:35,600
sure so

00:27:32,399 --> 00:27:37,760
yeah in terms of user defined mask uh

00:27:35,600 --> 00:27:41,279
yes it can be completely user

00:27:37,760 --> 00:27:43,679
defined uh and you should be able to

00:27:41,279 --> 00:27:46,480
replace it with any random one with your

00:27:43,679 --> 00:27:46,480
own custom code

00:27:46,559 --> 00:27:50,240
i'm not really sure what randomly

00:27:48,080 --> 00:27:54,000
shifter one is um

00:27:50,240 --> 00:27:56,640
but i hope i answered your question yeah

00:27:54,000 --> 00:27:58,399
and another question is how ready are

00:27:56,640 --> 00:28:00,799
column level encryption

00:27:58,399 --> 00:28:02,320
and the plugin are they going to be part

00:28:00,799 --> 00:28:05,360
of progression

00:28:02,320 --> 00:28:08,399
are you supporting nested columns

00:28:05,360 --> 00:28:08,960
uh this is two questions here one is how

00:28:08,399 --> 00:28:11,520
red is

00:28:08,960 --> 00:28:13,200
called so column level encryption is

00:28:11,520 --> 00:28:16,720
already merged to master

00:28:13,200 --> 00:28:20,000
it will release two poke12 further

00:28:16,720 --> 00:28:22,960
plug in so we are in the process

00:28:20,000 --> 00:28:24,640
converging to the upstream uh last

00:28:22,960 --> 00:28:26,720
question is

00:28:24,640 --> 00:28:31,840
are you supporting nasty column the

00:28:26,720 --> 00:28:31,840
answer is yes

00:28:41,200 --> 00:28:47,200
we still have couple of moments welcome

00:28:44,480 --> 00:28:49,200
questions so we have a question here uh

00:28:47,200 --> 00:28:52,000
can old parque libraries

00:28:49,200 --> 00:28:52,399
read the new data so i will i will take

00:28:52,000 --> 00:28:56,399
this

00:28:52,399 --> 00:28:59,919
question so that depends

00:28:56,399 --> 00:29:02,880
first of all if um

00:28:59,919 --> 00:29:03,840
if a column is encrypted so all the

00:29:02,880 --> 00:29:06,000
version of prop

00:29:03,840 --> 00:29:07,919
library cannot read it because it

00:29:06,000 --> 00:29:10,960
doesn't have the decryption

00:29:07,919 --> 00:29:14,159
capability now if a

00:29:10,960 --> 00:29:17,440
column is not encrypted

00:29:14,159 --> 00:29:19,520
can all the library access it it depends

00:29:17,440 --> 00:29:20,799
so in the slides i talk about

00:29:19,520 --> 00:29:24,080
incorporated footer

00:29:20,799 --> 00:29:24,799
if you decided not to disa encrypt the

00:29:24,080 --> 00:29:27,600
footer

00:29:24,799 --> 00:29:28,640
the answer is yes if you decide to

00:29:27,600 --> 00:29:30,799
encrypt the footer

00:29:28,640 --> 00:29:34,080
you cannot do it because auto library

00:29:30,799 --> 00:29:34,080
cannot decrypt the footer

00:29:36,159 --> 00:29:40,000
okay another question when storing the

00:29:38,559 --> 00:29:42,960
extra data

00:29:40,000 --> 00:29:44,960
will we have to account for it when it

00:29:42,960 --> 00:29:46,640
when accounting for row group size

00:29:44,960 --> 00:29:47,840
calculations

00:29:46,640 --> 00:29:49,840
uh shouldn't you want to take that and

00:29:47,840 --> 00:29:51,039
there's a second part to that how is it

00:29:49,840 --> 00:29:54,480
stored

00:29:51,039 --> 00:29:55,279
so it is stalled either so we so there

00:29:54,480 --> 00:29:58,799
will be

00:29:55,279 --> 00:30:01,919
some uh specification change

00:29:58,799 --> 00:30:04,880
in their pokey uh format

00:30:01,919 --> 00:30:05,440
uh the specification is essentially

00:30:04,880 --> 00:30:08,640
adding

00:30:05,440 --> 00:30:12,240
the crypto metadata so it doesn't affect

00:30:08,640 --> 00:30:14,799
the data itself it just

00:30:12,240 --> 00:30:16,159
stop more field for the craft metadata

00:30:14,799 --> 00:30:20,000
so it doesn't affect

00:30:16,159 --> 00:30:20,000
the real group says calculation

00:30:21,120 --> 00:30:24,399
next is how is what you are doing

00:30:23,440 --> 00:30:27,520
different from

00:30:24,399 --> 00:30:30,640
dynamic color masking in hive

00:30:27,520 --> 00:30:34,840
with ranger policies as a solution

00:30:30,640 --> 00:30:37,760
that is specific to that spec to that

00:30:34,840 --> 00:30:40,880
stack

00:30:37,760 --> 00:30:41,600
i'm not sure the dynamic color masking

00:30:40,880 --> 00:30:45,919
you have

00:30:41,600 --> 00:30:48,960
means if you are referring to the orc

00:30:45,919 --> 00:30:52,559
encryption with ranger policies

00:30:48,960 --> 00:30:57,120
on we are under similar

00:30:52,559 --> 00:31:00,799
the rc called encryption and

00:30:57,120 --> 00:31:05,840
economy encryption has similar idea um

00:31:00,799 --> 00:31:09,039
so for the prog b their policies

00:31:05,840 --> 00:31:11,840
can be stored in uh at many

00:31:09,039 --> 00:31:12,880
other places ranger policy star can also

00:31:11,840 --> 00:31:16,159
be used

00:31:12,880 --> 00:31:17,519
for the property encryption i i think

00:31:16,159 --> 00:31:18,720
for that question they might be

00:31:17,519 --> 00:31:20,080
referring to some

00:31:18,720 --> 00:31:22,159
masking that's happening at a higher

00:31:20,080 --> 00:31:24,240
level maybe at the hive level

00:31:22,159 --> 00:31:25,440
so i guess we're a bit different than

00:31:24,240 --> 00:31:27,840
that because we're doing at the lowest

00:31:25,440 --> 00:31:29,919
layer at the parquet layer so the

00:31:27,840 --> 00:31:32,399
so we're yeah basically protecting from

00:31:29,919 --> 00:31:34,159
all pads like this masking is more

00:31:32,399 --> 00:31:36,880
general

00:31:34,159 --> 00:31:38,399
yeah if you revert to the have udf

00:31:36,880 --> 00:31:41,200
column encryption

00:31:38,399 --> 00:31:42,000
um yeah maybe answer questions like we

00:31:41,200 --> 00:31:45,760
are doing the

00:31:42,000 --> 00:31:48,799
lower level uh also means is transparent

00:31:45,760 --> 00:31:49,840
to your application like price to etc if

00:31:48,799 --> 00:31:51,840
you do the udf

00:31:49,840 --> 00:31:53,519
you probably need to provide your own

00:31:51,840 --> 00:31:57,600
library udf

00:31:53,519 --> 00:31:57,600
to do the decryption you read the data

00:31:59,279 --> 00:32:03,519
okay i would say yeah the question i

00:32:01,840 --> 00:32:06,960
will see the main difference

00:32:03,519 --> 00:32:07,760
is that you can protect hdfs or s3

00:32:06,960 --> 00:32:14,640
access

00:32:07,760 --> 00:32:19,039
using just ranger policy correct

00:32:14,640 --> 00:32:22,720
uh i'm not sure uh i fully understand

00:32:19,039 --> 00:32:26,399
question um

00:32:22,720 --> 00:32:29,279
so so basically

00:32:26,399 --> 00:32:30,559
column encryption and poke is a

00:32:29,279 --> 00:32:33,840
client-side

00:32:30,559 --> 00:32:36,880
encryption so the client side means

00:32:33,840 --> 00:32:40,320
there are color engines like presto

00:32:36,880 --> 00:32:41,279
spark all the application that lead to

00:32:40,320 --> 00:32:43,919
the encryption

00:32:41,279 --> 00:32:46,159
decryption as a compute and sends the

00:32:43,919 --> 00:32:47,039
data across the error which is already

00:32:46,159 --> 00:32:49,519
encrypted

00:32:47,039 --> 00:32:51,279
and studied the storage layer is

00:32:49,519 --> 00:32:52,240
transparent to the encryption and

00:32:51,279 --> 00:32:54,240
decryption

00:32:52,240 --> 00:32:56,559
now come back to the key mediums

00:32:54,240 --> 00:32:59,840
essentially is where you store your key

00:32:56,559 --> 00:33:01,120
so you establish your own kms as a

00:32:59,840 --> 00:33:04,720
standalone service

00:33:01,120 --> 00:33:07,279
all the secret is in their kms

00:33:04,720 --> 00:33:07,760
yeah nikola had a follow-up where they

00:33:07,279 --> 00:33:09,919
said

00:33:07,760 --> 00:33:11,120
meaning that parquet encryption works

00:33:09,919 --> 00:33:13,279
even if you just

00:33:11,120 --> 00:33:16,880
read the files from the file system

00:33:13,279 --> 00:33:16,880
directly and yeah that's true

00:33:17,760 --> 00:33:21,600
yeah so things are filed directly from

00:33:20,880 --> 00:33:24,960
the file

00:33:21,600 --> 00:33:24,960
from the file system

00:33:25,039 --> 00:33:29,760
now if you last you use the hdfs command

00:33:28,240 --> 00:33:32,720
to download the file

00:33:29,760 --> 00:33:34,640
so the file is encrypted partially

00:33:32,720 --> 00:33:37,919
encrypted for some colors

00:33:34,640 --> 00:33:38,799
if you want to read those encrypted

00:33:37,919 --> 00:33:41,760
columns

00:33:38,799 --> 00:33:42,880
you need some way to decrypt the data

00:33:41,760 --> 00:33:46,159
for example

00:33:42,880 --> 00:33:46,480
um we have the plugin that you can hook

00:33:46,159 --> 00:33:49,679
in

00:33:46,480 --> 00:33:51,279
that will uh that will well that's a

00:33:49,679 --> 00:33:53,440
wrapper of the kms client

00:33:51,279 --> 00:33:54,399
right so you have the configuration on

00:33:53,440 --> 00:33:57,360
your

00:33:54,399 --> 00:33:58,480
reader and then that will automatically

00:33:57,360 --> 00:34:00,960
get the key

00:33:58,480 --> 00:34:01,679
and pass it to the library to the

00:34:00,960 --> 00:34:04,799
decryption

00:34:01,679 --> 00:34:05,840
which is transparent to you but you all

00:34:04,799 --> 00:34:07,600
you need to do is

00:34:05,840 --> 00:34:21,760
encrypt the library provide several

00:34:07,600 --> 00:34:35,839
settings as a kms url etc

00:34:21,760 --> 00:34:35,839
more questions

00:34:40,800 --> 00:34:45,679
let's wait for 30 seconds uh if no more

00:34:44,159 --> 00:34:49,839
questions

00:34:45,679 --> 00:34:49,839
i think that's all for today's session

00:35:10,320 --> 00:35:14,400
thanks everybody uh as pva mentioned we

00:35:13,440 --> 00:35:16,720
are hearing

00:35:14,400 --> 00:35:17,599
feel free to send me a resume or apply

00:35:16,720 --> 00:35:22,560
online

00:35:17,599 --> 00:35:22,560
directly have a good day thanks

00:35:28,839 --> 00:35:31,839
everybody

00:35:54,400 --> 00:35:56,480

YouTube URL: https://www.youtube.com/watch?v=hNMiuAvg9TQ


