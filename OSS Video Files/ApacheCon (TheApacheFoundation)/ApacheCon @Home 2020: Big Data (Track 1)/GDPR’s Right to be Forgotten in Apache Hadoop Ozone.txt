Title: GDPR’s Right to be Forgotten in Apache Hadoop Ozone
Publication date: 2020-10-21
Playlist: ApacheCon @Home 2020: Big Data (Track 1)
Description: 
	GDPR’s Right to be Forgotten in Apache Hadoop Ozone
Dinesh Chitlangia

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Apache Hadoop Ozone is a robust, distributed key-value object store for Hadoop with layered architecture and strong consistency. It isolates the namespace management from the block and node management layer, which allows users to independently scale on both axes. Ozone is interoperable with the Hadoop ecosystem as it provides OzoneFS (Hadoop compatible file system API), data locality and plug-n-play deployment with HDFS as it can be installed in an existing Hadoop cluster and can share storage disks with HDFS. Ozone solves the scalability challenges with HDFS by being size agnostic. Consequently, it allows users to store trillions of files in Ozone and access them as if they are on HDFS. Ozone plugs into existing Hadoop deployments seamlessly, and programs like Yarn, MapReduce, Spark, Hive and work without any modifications. In the era of increasing need for data privacy and regulations, Ozone also provides built-in support for GDPR compliance with strong focus on Right to be Forgotten i.e., Data Erasure. At the end of this presentation the audience will be able to understand: 1. HDFS scalability challenges 2. Ozone’s Architecture as a solution 3. Overview of GDPR 4. GDPR implementation in Ozone

Dinesh is a Software Engineer with strong expertise in Java, Distributed Systems for ~10 years. He has been involved with Hadoop ecosystem for the last 4 years and is an Apache Hadoop Committer. Dinesh is currently working at Cloudera, performing the role of a proactive support consultant for Premier customers and enjoys contributing to Open Source community. Outside of technology, Dinesh has a serious hobby in Landscape/Cityscape photography.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:24,640 --> 00:00:31,840
all right

00:00:25,439 --> 00:00:31,840
i guess we can get started

00:00:37,120 --> 00:00:40,239
so uh good morning good evening good

00:00:39,520 --> 00:00:42,800
afternoon

00:00:40,239 --> 00:00:44,000
wherever on this globe you are uh thank

00:00:42,800 --> 00:00:47,200
you for joining my talk

00:00:44,000 --> 00:00:51,039
on gdpr's right to be forgotten in

00:00:47,200 --> 00:00:53,280
apache hadoop zone so a little bit about

00:00:51,039 --> 00:00:55,680
me i'm dinesh it landed

00:00:53,280 --> 00:00:57,680
been a software engineer since 2010 um

00:00:55,680 --> 00:00:59,199
in the distributed system hadoop world

00:00:57,680 --> 00:01:01,280
since 2016

00:00:59,199 --> 00:01:02,239
uh apache hadoop committer and currently

00:01:01,280 --> 00:01:03,680
working as

00:01:02,239 --> 00:01:06,400
a premier support tech leader at

00:01:03,680 --> 00:01:07,280
cloudera and uh here are the other

00:01:06,400 --> 00:01:11,520
details of

00:01:07,280 --> 00:01:14,240
and ways of reaching out to me

00:01:11,520 --> 00:01:15,600
so uh in in this talk right i know we

00:01:14,240 --> 00:01:16,720
are going to talk about ozone and we're

00:01:15,600 --> 00:01:19,920
going to talk about

00:01:16,720 --> 00:01:22,400
gdpr but a little bit of

00:01:19,920 --> 00:01:23,680
context around why ozone was needed to

00:01:22,400 --> 00:01:25,360
begin with

00:01:23,680 --> 00:01:27,360
so some of you may have attended

00:01:25,360 --> 00:01:29,439
yesterday's talk by martin

00:01:27,360 --> 00:01:31,520
uh in case you did that this will all

00:01:29,439 --> 00:01:33,439
sound familiar grounds to you but

00:01:31,520 --> 00:01:35,520
otherwise i'll just do a quick overview

00:01:33,439 --> 00:01:36,720
of ozone and why ozone was needed in the

00:01:35,520 --> 00:01:40,240
first place

00:01:36,720 --> 00:01:43,360
so as we know right hdfs offers

00:01:40,240 --> 00:01:45,280
way beyond a scale and performance like

00:01:43,360 --> 00:01:46,720
it's pointless to talk about the kind of

00:01:45,280 --> 00:01:48,960
scale and uh

00:01:46,720 --> 00:01:50,640
performance hdfs gives because it's been

00:01:48,960 --> 00:01:53,520
used across the globe

00:01:50,640 --> 00:01:54,479
in massive data systems at scale right

00:01:53,520 --> 00:01:56,960
so

00:01:54,479 --> 00:01:58,960
that's a known fact so other features

00:01:56,960 --> 00:02:00,960
that hdfs really brings in is

00:01:58,960 --> 00:02:03,360
strongly consistent right so it makes

00:02:00,960 --> 00:02:04,960
life easy for our application developers

00:02:03,360 --> 00:02:06,880
so for example you know when you have

00:02:04,960 --> 00:02:08,479
name node ha enabled

00:02:06,880 --> 00:02:10,479
you don't need to know which name node

00:02:08,479 --> 00:02:12,800
should your app go and submit the job

00:02:10,479 --> 00:02:13,599
right you will just take the ha url and

00:02:12,800 --> 00:02:15,120
then

00:02:13,599 --> 00:02:16,800
internally the name node will figure out

00:02:15,120 --> 00:02:18,959
which one is the active one

00:02:16,800 --> 00:02:20,239
and then uh it will read out dab

00:02:18,959 --> 00:02:22,400
accordingly

00:02:20,239 --> 00:02:24,239
it's reliable right so say for example

00:02:22,400 --> 00:02:24,959
all your nodes got shut down or you know

00:02:24,239 --> 00:02:26,640
you had a

00:02:24,959 --> 00:02:28,239
power outage or something in your data

00:02:26,640 --> 00:02:30,800
center uh you

00:02:28,239 --> 00:02:32,239
are pretty much assured that when you

00:02:30,800 --> 00:02:34,879
plug in the systems back

00:02:32,239 --> 00:02:36,560
and restart uh your name nodes and your

00:02:34,879 --> 00:02:39,519
hdfs cluster will return

00:02:36,560 --> 00:02:40,560
in a very consistent state even from

00:02:39,519 --> 00:02:43,360
such catastrophic

00:02:40,560 --> 00:02:45,040
failures right now the third very

00:02:43,360 --> 00:02:47,519
important and probably one of the most

00:02:45,040 --> 00:02:50,080
underrated features of hdfs is

00:02:47,519 --> 00:02:51,519
the file system api right the hadoop

00:02:50,080 --> 00:02:54,080
file system api

00:02:51,519 --> 00:02:55,200
because of which various other apache

00:02:54,080 --> 00:02:58,560
projects like

00:02:55,200 --> 00:02:59,680
hive spark edge base you know are able

00:02:58,560 --> 00:03:03,120
to connect to the

00:02:59,680 --> 00:03:03,760
hdfs systems and not only these projects

00:03:03,120 --> 00:03:05,519
but

00:03:03,760 --> 00:03:07,680
you can eventually connect with the

00:03:05,519 --> 00:03:09,280
cloud like the azure storage or the s3

00:03:07,680 --> 00:03:11,519
storage using that file system

00:03:09,280 --> 00:03:14,640
compatible api

00:03:11,519 --> 00:03:18,000
aside from this security is obviously

00:03:14,640 --> 00:03:20,640
a very very robust area in hdfs we have

00:03:18,000 --> 00:03:22,480
kerberos we have encryption at rest

00:03:20,640 --> 00:03:23,920
encryption in motion we have four six

00:03:22,480 --> 00:03:26,879
cycles as well

00:03:23,920 --> 00:03:28,400
right uh but that said right every uh

00:03:26,879 --> 00:03:31,519
there is no system which is

00:03:28,400 --> 00:03:33,599
ideal in the world uh so of course you

00:03:31,519 --> 00:03:34,799
know for hdfs we have the one famous

00:03:33,599 --> 00:03:37,680
limitation

00:03:34,799 --> 00:03:38,239
of uh scaling to up to say 350 million

00:03:37,680 --> 00:03:40,959
files

00:03:38,239 --> 00:03:43,040
and thereafter we run into problems with

00:03:40,959 --> 00:03:43,920
heap size and the file count and all

00:03:43,040 --> 00:03:45,519
that

00:03:43,920 --> 00:03:46,959
of course this is not a problem when

00:03:45,519 --> 00:03:49,840
you're storing large files

00:03:46,959 --> 00:03:51,440
um it's primarily related to these small

00:03:49,840 --> 00:03:53,840
files in the system

00:03:51,440 --> 00:03:55,120
and what ends up happening is we run out

00:03:53,840 --> 00:03:57,680
of name node heap

00:03:55,120 --> 00:03:58,840
long before we run out of any cluster

00:03:57,680 --> 00:04:01,840
disk space

00:03:58,840 --> 00:04:04,720
right so in the community uh

00:04:01,840 --> 00:04:06,239
over the last decade and a half several

00:04:04,720 --> 00:04:09,120
solutions have been proposed

00:04:06,239 --> 00:04:09,439
right for example we can grow the heap

00:04:09,120 --> 00:04:13,120
so

00:04:09,439 --> 00:04:16,160
zgc claims support for 16 terabyte heaps

00:04:13,120 --> 00:04:18,639
but at that kind of heap the 10x 200x

00:04:16,160 --> 00:04:21,359
scale from the current 350 million

00:04:18,639 --> 00:04:22,880
is still going to be impractical the

00:04:21,359 --> 00:04:23,199
other option is yeah you know you can

00:04:22,880 --> 00:04:24,720
use

00:04:23,199 --> 00:04:26,960
less heap if you can't manage with

00:04:24,720 --> 00:04:28,639
higher heat but then

00:04:26,960 --> 00:04:31,120
what are the ideas for that right so the

00:04:28,639 --> 00:04:33,120
ideas were you scale the name space

00:04:31,120 --> 00:04:35,360
accordingly right so what you do is

00:04:33,120 --> 00:04:36,400
instead of loading the entire namespace

00:04:35,360 --> 00:04:38,639
in your memory

00:04:36,400 --> 00:04:39,440
uh like what tavnot does today we can

00:04:38,639 --> 00:04:42,160
just load a

00:04:39,440 --> 00:04:44,479
working set in the memory or you can

00:04:42,160 --> 00:04:47,840
segregate the block manager as a service

00:04:44,479 --> 00:04:48,800
right so all these uh ideas were pitched

00:04:47,840 --> 00:04:51,919
in various

00:04:48,800 --> 00:04:54,000
hdfs datas by the community and

00:04:51,919 --> 00:04:55,680
one other area was like the block

00:04:54,000 --> 00:04:56,880
reports are very heavy so as your

00:04:55,680 --> 00:04:59,440
cluster grows

00:04:56,880 --> 00:05:00,400
in terms of number of nodes and number

00:04:59,440 --> 00:05:02,639
of blocks

00:05:00,400 --> 00:05:04,479
uh those block reports also make the

00:05:02,639 --> 00:05:07,680
name node a bit choked

00:05:04,479 --> 00:05:10,800
so achieving that 10x200 scale

00:05:07,680 --> 00:05:14,080
then becomes fairly impossible with

00:05:10,800 --> 00:05:15,440
the current setup so

00:05:14,080 --> 00:05:18,639
these are the lessons we learned from

00:05:15,440 --> 00:05:20,560
hdfs right so one key lesson is

00:05:18,639 --> 00:05:23,680
keep only the working set in ram we do

00:05:20,560 --> 00:05:26,400
not need to load the entire namespace

00:05:23,680 --> 00:05:28,240
in memory and then the other idea is to

00:05:26,400 --> 00:05:29,680
decouple the namespace and the block

00:05:28,240 --> 00:05:32,400
space right so it was

00:05:29,680 --> 00:05:35,120
originally proposed by yahoo via the

00:05:32,400 --> 00:05:37,520
hdfs 5477 jira

00:05:35,120 --> 00:05:38,960
so what this will do is if your

00:05:37,520 --> 00:05:39,840
namespace and your blog space are

00:05:38,960 --> 00:05:42,639
decoupled

00:05:39,840 --> 00:05:43,039
uh basically it will allow you to scale

00:05:42,639 --> 00:05:46,639
or

00:05:43,039 --> 00:05:48,960
shard independently of each other so

00:05:46,639 --> 00:05:50,160
if you are in a scenario where you know

00:05:48,960 --> 00:05:51,919
you're going to have a lot of small

00:05:50,160 --> 00:05:53,360
files

00:05:51,919 --> 00:05:55,039
you would just want to scale the name

00:05:53,360 --> 00:05:56,960
space not the block space

00:05:55,039 --> 00:05:58,960
and if you're in a scenario where say

00:05:56,960 --> 00:05:59,840
you only dump large files into the

00:05:58,960 --> 00:06:02,080
system

00:05:59,840 --> 00:06:03,759
uh say for example you you belong to the

00:06:02,080 --> 00:06:06,479
self-driving car world or the

00:06:03,759 --> 00:06:06,960
robotic surgery kind of word right where

00:06:06,479 --> 00:06:09,199
you'll

00:06:06,960 --> 00:06:11,039
generally not get many files but what

00:06:09,199 --> 00:06:13,440
you'll get is very large files

00:06:11,039 --> 00:06:14,960
so that case you don't really have a lot

00:06:13,440 --> 00:06:17,199
of pressure on your name space

00:06:14,960 --> 00:06:18,639
but you would just like to increase the

00:06:17,199 --> 00:06:21,280
scale the block space

00:06:18,639 --> 00:06:22,240
so by decoupling it allows us to scale

00:06:21,280 --> 00:06:25,039
or shard

00:06:22,240 --> 00:06:26,800
in them independently as needed the

00:06:25,039 --> 00:06:27,440
other lesson is obviously we need to get

00:06:26,800 --> 00:06:29,600
rid of

00:06:27,440 --> 00:06:30,639
block reports because as the cluster

00:06:29,600 --> 00:06:32,639
grows

00:06:30,639 --> 00:06:34,160
uh the number of files number of blocks

00:06:32,639 --> 00:06:35,919
increases and

00:06:34,160 --> 00:06:37,360
since we are tracking each and every

00:06:35,919 --> 00:06:39,360
block in a block report

00:06:37,360 --> 00:06:40,400
it just becomes a little bit too much

00:06:39,360 --> 00:06:43,199
for the name note

00:06:40,400 --> 00:06:44,960
after a certain point in time uh there

00:06:43,199 --> 00:06:47,440
was a notion of volumes

00:06:44,960 --> 00:06:48,080
that was introduced in hdfs but never

00:06:47,440 --> 00:06:50,240
really

00:06:48,080 --> 00:06:51,840
implemented so that is something we also

00:06:50,240 --> 00:06:55,440
picked up

00:06:51,840 --> 00:06:57,280
from hdfs so that said

00:06:55,440 --> 00:06:58,720
what are the building blocks of ozone

00:06:57,280 --> 00:07:01,759
right so ozone

00:06:58,720 --> 00:07:03,280
we had primarily three tenets of you

00:07:01,759 --> 00:07:04,880
know we want to incorporate when

00:07:03,280 --> 00:07:07,919
building ozone so one is

00:07:04,880 --> 00:07:10,319
we wanted to have strong consistency

00:07:07,919 --> 00:07:12,080
otherwise the system is just not

00:07:10,319 --> 00:07:13,919
reliable as a file storage

00:07:12,080 --> 00:07:15,199
and then we wanted to have a simple

00:07:13,919 --> 00:07:18,400
architecture

00:07:15,199 --> 00:07:21,280
because that would then make it easy

00:07:18,400 --> 00:07:22,720
to manage from an operations standpoint

00:07:21,280 --> 00:07:24,720
so the building blocks of ozone are

00:07:22,720 --> 00:07:25,680
pretty straightforward we have a rafter

00:07:24,720 --> 00:07:28,000
application

00:07:25,680 --> 00:07:29,840
protocol which is an open source java

00:07:28,000 --> 00:07:32,479
implementation

00:07:29,840 --> 00:07:34,319
in the apache rattus project so this

00:07:32,479 --> 00:07:36,240
takes care of the consensus and the

00:07:34,319 --> 00:07:36,960
replica management and pipeline and all

00:07:36,240 --> 00:07:39,199
that

00:07:36,960 --> 00:07:40,800
and then we have the storage containers

00:07:39,199 --> 00:07:43,360
which

00:07:40,800 --> 00:07:45,039
i know is a very heavy used heavily used

00:07:43,360 --> 00:07:47,280
term container

00:07:45,039 --> 00:07:49,199
so these are not your standard linux

00:07:47,280 --> 00:07:50,240
container or your docker containers and

00:07:49,199 --> 00:07:53,520
stuff like that

00:07:50,240 --> 00:07:56,720
this is a logical abstraction

00:07:53,520 --> 00:07:59,280
within the data node so the storage

00:07:56,720 --> 00:08:01,440
containers in ozone use the

00:07:59,280 --> 00:08:02,800
keystone key value store called rocksdb

00:08:01,440 --> 00:08:05,120
and roxtv

00:08:02,800 --> 00:08:06,240
i'm sure you guys are aware is a very

00:08:05,120 --> 00:08:08,720
very

00:08:06,240 --> 00:08:10,840
battle tested solution for the key value

00:08:08,720 --> 00:08:12,000
stores which was a fork of level db of

00:08:10,840 --> 00:08:14,639
course

00:08:12,000 --> 00:08:16,400
then we have the hdds layer which is

00:08:14,639 --> 00:08:17,520
essentially the container management

00:08:16,400 --> 00:08:19,039
layer or you could

00:08:17,520 --> 00:08:20,639
equivalently say it's the block

00:08:19,039 --> 00:08:22,000
management layer

00:08:20,639 --> 00:08:23,680
of course here we don't manage

00:08:22,000 --> 00:08:25,520
individual blocks because they are

00:08:23,680 --> 00:08:28,240
grouped as storage containers

00:08:25,520 --> 00:08:29,599
and hence we say storage uh distributed

00:08:28,240 --> 00:08:31,840
container management layer

00:08:29,599 --> 00:08:33,120
so that's hdds hadoop distributed

00:08:31,840 --> 00:08:35,519
datastore

00:08:33,120 --> 00:08:37,440
and finally we have our ozone manager

00:08:35,519 --> 00:08:40,240
which is the namespace manager

00:08:37,440 --> 00:08:42,159
equivalent of the name node in the hdfs

00:08:40,240 --> 00:08:44,800
world

00:08:42,159 --> 00:08:46,399
now so what are storage containers as i

00:08:44,800 --> 00:08:48,480
was saying right storage container is

00:08:46,399 --> 00:08:51,920
basically a collection of blocks

00:08:48,480 --> 00:08:53,839
and the default size is five gigabyte so

00:08:51,920 --> 00:08:56,000
we will you know aggregate the report

00:08:53,839 --> 00:08:57,839
for a container

00:08:56,000 --> 00:09:00,399
uh and for all these blocks and then

00:08:57,839 --> 00:09:01,040
send it to the namespace manager instead

00:09:00,399 --> 00:09:02,720
of

00:09:01,040 --> 00:09:05,360
just sending reports for each and every

00:09:02,720 --> 00:09:06,880
block so storage mountain is basically a

00:09:05,360 --> 00:09:09,279
storage container is basically a

00:09:06,880 --> 00:09:11,200
unit of replication right it solves the

00:09:09,279 --> 00:09:13,440
block report scale problem

00:09:11,200 --> 00:09:15,600
uh as i was saying and we have the raft

00:09:13,440 --> 00:09:16,160
protocol implemented so that takes care

00:09:15,600 --> 00:09:18,480
of

00:09:16,160 --> 00:09:19,920
syncing the replicas and the consensus

00:09:18,480 --> 00:09:20,959
between who's the leader and who's the

00:09:19,920 --> 00:09:24,000
follower and all those

00:09:20,959 --> 00:09:25,920
stuff these containers are stored on

00:09:24,000 --> 00:09:26,560
data nodes and thus they are managed by

00:09:25,920 --> 00:09:28,959
the

00:09:26,560 --> 00:09:30,880
storage container manager and i will as

00:09:28,959 --> 00:09:32,160
i was saying these are equivalent to the

00:09:30,880 --> 00:09:36,399
hdfs

00:09:32,160 --> 00:09:38,800
block manager so what are uh

00:09:36,399 --> 00:09:40,000
the ozone architecture right the overall

00:09:38,800 --> 00:09:42,080
uh view

00:09:40,000 --> 00:09:44,160
so as i was saying earlier we have three

00:09:42,080 --> 00:09:45,200
key components right we have the ozone

00:09:44,160 --> 00:09:46,880
manager

00:09:45,200 --> 00:09:48,320
and we have the storage container

00:09:46,880 --> 00:09:50,320
manager the namespace

00:09:48,320 --> 00:09:52,560
and the block manager respectively and

00:09:50,320 --> 00:09:55,040
then we have a set of data nodes

00:09:52,560 --> 00:09:55,839
now on your left what you're seeing is

00:09:55,040 --> 00:09:58,800
basically

00:09:55,839 --> 00:10:00,720
the various ways in which a user could

00:09:58,800 --> 00:10:02,959
connect to the ozone system

00:10:00,720 --> 00:10:05,040
so when you have the file system

00:10:02,959 --> 00:10:06,240
connector and then you have the command

00:10:05,040 --> 00:10:08,560
line shell

00:10:06,240 --> 00:10:10,079
and then we would also like to you know

00:10:08,560 --> 00:10:12,079
introduce this idea that

00:10:10,079 --> 00:10:13,839
ozone is not just a standard file system

00:10:12,079 --> 00:10:14,560
it's basically an object store for big

00:10:13,839 --> 00:10:17,279
data

00:10:14,560 --> 00:10:18,959
so we have a similar feature like the s3

00:10:17,279 --> 00:10:20,880
gateway servers which obviously you

00:10:18,959 --> 00:10:22,640
would want to have it load balanced in a

00:10:20,880 --> 00:10:24,800
production scenario

00:10:22,640 --> 00:10:27,519
now on the right what you see is the

00:10:24,800 --> 00:10:29,519
recon server and the ozone console

00:10:27,519 --> 00:10:30,720
so operationally it has been very

00:10:29,519 --> 00:10:33,200
challenging for

00:10:30,720 --> 00:10:35,120
hdfs admins right if they run into a

00:10:33,200 --> 00:10:37,279
problem with a certain file or

00:10:35,120 --> 00:10:38,800
the state of the file system they are

00:10:37,279 --> 00:10:42,480
forced to run something like

00:10:38,800 --> 00:10:44,640
the hdfs dfs fsck command right

00:10:42,480 --> 00:10:46,000
uh the challenge with that is if it's a

00:10:44,640 --> 00:10:48,959
large cluster it can take

00:10:46,000 --> 00:10:50,480
a pretty long time and it is not very

00:10:48,959 --> 00:10:52,399
optimal to run that so

00:10:50,480 --> 00:10:54,000
with recon server what will end up

00:10:52,399 --> 00:10:56,240
happening is you will get a

00:10:54,000 --> 00:10:57,600
live view of the state of the file

00:10:56,240 --> 00:10:59,680
system thereby

00:10:57,600 --> 00:11:01,279
you never really have to run something

00:10:59,680 --> 00:11:03,040
like an fsck command

00:11:01,279 --> 00:11:04,800
and ozone console is again you know

00:11:03,040 --> 00:11:07,120
provides much more insights about the

00:11:04,800 --> 00:11:09,519
file system and the metrics and all that

00:11:07,120 --> 00:11:10,240
so operationally uh these are tools that

00:11:09,519 --> 00:11:12,800
will help the

00:11:10,240 --> 00:11:14,399
administrators to monitor the system and

00:11:12,800 --> 00:11:16,800
then learn more about the health of the

00:11:14,399 --> 00:11:16,800
system

00:11:16,959 --> 00:11:20,560
so uh before we dive further you know

00:11:19,200 --> 00:11:22,399
ozone jargons uh

00:11:20,560 --> 00:11:24,800
so of course in ozone what we have is an

00:11:22,399 --> 00:11:26,320
ozone path which is like you know volume

00:11:24,800 --> 00:11:28,480
followed by the bucket name followed by

00:11:26,320 --> 00:11:30,240
the key name right so on and so forth

00:11:28,480 --> 00:11:31,839
and volume is a basic unit of

00:11:30,240 --> 00:11:34,079
administration

00:11:31,839 --> 00:11:36,000
so what we would essentially do is uh

00:11:34,079 --> 00:11:38,320
say an admin would create a volume

00:11:36,000 --> 00:11:39,600
which could relate to maybe one business

00:11:38,320 --> 00:11:42,240
group right

00:11:39,600 --> 00:11:43,839
and then the users could also go ahead

00:11:42,240 --> 00:11:46,079
and create buckets

00:11:43,839 --> 00:11:47,040
within that volume so bucket is nothing

00:11:46,079 --> 00:11:50,560
an equivalent of

00:11:47,040 --> 00:11:53,200
directory so volumes could have you know

00:11:50,560 --> 00:11:55,279
zero or more buckets and eventually

00:11:53,200 --> 00:11:56,800
buckets will contain the keys basically

00:11:55,279 --> 00:11:59,760
the files that you want to

00:11:56,800 --> 00:12:00,720
upload in the system so key names are

00:11:59,760 --> 00:12:03,519
unique within a

00:12:00,720 --> 00:12:06,160
given bucket and there is no hard-coded

00:12:03,519 --> 00:12:07,920
limit on the size of the keys

00:12:06,160 --> 00:12:10,000
and the values can range obviously from

00:12:07,920 --> 00:12:13,360
you know empty files to anything uh

00:12:10,000 --> 00:12:15,360
above so

00:12:13,360 --> 00:12:16,800
with that architecture and with that

00:12:15,360 --> 00:12:19,760
introduction of uh

00:12:16,800 --> 00:12:21,600
ozone uh it obviously gives us an ease

00:12:19,760 --> 00:12:22,880
of operation right because we are using

00:12:21,600 --> 00:12:25,360
off-heap memory so

00:12:22,880 --> 00:12:26,240
there is no problem of large java heaps

00:12:25,360 --> 00:12:28,240
or

00:12:26,240 --> 00:12:30,480
doing the case work around what gc

00:12:28,240 --> 00:12:33,519
parameters to put in place

00:12:30,480 --> 00:12:35,680
it's a simplified ha model because ozone

00:12:33,519 --> 00:12:38,480
by default is ha enabled

00:12:35,680 --> 00:12:40,079
and the replicas communicate via the

00:12:38,480 --> 00:12:43,200
raft protocol

00:12:40,079 --> 00:12:46,399
and there is no more complexity

00:12:43,200 --> 00:12:48,079
of implementing journal nodes

00:12:46,399 --> 00:12:50,639
uh you know like three general nodes at

00:12:48,079 --> 00:12:53,040
least and then two zkfc processes

00:12:50,639 --> 00:12:54,639
at least three zookeepers right so i

00:12:53,040 --> 00:12:56,560
mean if you've

00:12:54,639 --> 00:12:57,920
managed or implemented a hadoop cluster

00:12:56,560 --> 00:13:00,320
you know this

00:12:57,920 --> 00:13:02,079
part really becomes painful especially

00:13:00,320 --> 00:13:03,040
when there is some instability in the

00:13:02,079 --> 00:13:04,959
system and

00:13:03,040 --> 00:13:06,399
this is so much more you need to spend

00:13:04,959 --> 00:13:08,399
basically to have these kind of

00:13:06,399 --> 00:13:10,240
components running

00:13:08,399 --> 00:13:11,760
of course the scm ships with its own

00:13:10,240 --> 00:13:14,079
certificate server

00:13:11,760 --> 00:13:14,959
so what ends up happening is it will

00:13:14,079 --> 00:13:17,120
automatically

00:13:14,959 --> 00:13:18,240
when you add a data node into the system

00:13:17,120 --> 00:13:19,680
it will basically

00:13:18,240 --> 00:13:21,360
authenticate itself using that

00:13:19,680 --> 00:13:24,240
certificate so

00:13:21,360 --> 00:13:25,600
you no longer have a scenario where say

00:13:24,240 --> 00:13:29,120
if you have a 3000 node

00:13:25,600 --> 00:13:31,200
cluster for each data node you do not

00:13:29,120 --> 00:13:33,200
have to create a kerberos principles

00:13:31,200 --> 00:13:35,519
uh and i've seen that in the past you

00:13:33,200 --> 00:13:37,120
know some customers or some users will

00:13:35,519 --> 00:13:39,519
end up bypassing that

00:13:37,120 --> 00:13:41,040
and will simply use a generic principle

00:13:39,519 --> 00:13:43,199
by using the wildcard

00:13:41,040 --> 00:13:45,199
uh of asterisk which is obviously

00:13:43,199 --> 00:13:47,760
defeats the purpose of having that

00:13:45,199 --> 00:13:49,519
security so it's come you know it sips

00:13:47,760 --> 00:13:52,240
with its own certificate server

00:13:49,519 --> 00:13:54,079
that makes it easy to manage uh uh the

00:13:52,240 --> 00:13:56,079
principal creation and all for

00:13:54,079 --> 00:13:57,680
each and every data node because there's

00:13:56,079 --> 00:13:58,720
no longer a need to create those

00:13:57,680 --> 00:14:00,639
principles

00:13:58,720 --> 00:14:02,320
and as i was saying earlier recon server

00:14:00,639 --> 00:14:04,320
it provides a live view

00:14:02,320 --> 00:14:07,040
of the file system state so you never

00:14:04,320 --> 00:14:09,839
have to run something like ifs cpa again

00:14:07,040 --> 00:14:11,680
and you know over the last decade and a

00:14:09,839 --> 00:14:14,240
half people have seen that

00:14:11,680 --> 00:14:16,320
managing the client configurations

00:14:14,240 --> 00:14:18,720
sometimes becomes difficult because you

00:14:16,320 --> 00:14:21,680
need to ship those same site files

00:14:18,720 --> 00:14:23,279
in every node and sometimes uh in

00:14:21,680 --> 00:14:24,240
multi-tenant systems what we have

00:14:23,279 --> 00:14:25,920
observed is

00:14:24,240 --> 00:14:27,519
although you may have a hadoop cluster

00:14:25,920 --> 00:14:30,399
being managed by

00:14:27,519 --> 00:14:32,959
a centralized administration tool like a

00:14:30,399 --> 00:14:35,199
cloudera manager or an ambari

00:14:32,959 --> 00:14:37,440
but there will always be some edge nodes

00:14:35,199 --> 00:14:40,320
which are not managed by these

00:14:37,440 --> 00:14:42,160
management consoles so keeping the

00:14:40,320 --> 00:14:43,040
configuration in sync is obviously a

00:14:42,160 --> 00:14:45,440
challenge and

00:14:43,040 --> 00:14:47,120
you run into situations where people use

00:14:45,440 --> 00:14:49,600
incorrect client configs and

00:14:47,120 --> 00:14:51,120
jobs failed and could not get submitted

00:14:49,600 --> 00:14:53,040
so in ozone what will happen is

00:14:51,120 --> 00:14:54,639
uh you know we the client will basically

00:14:53,040 --> 00:14:57,360
directly contact

00:14:54,639 --> 00:14:58,320
the ozone manager server and get the

00:14:57,360 --> 00:15:03,040
configs

00:14:58,320 --> 00:15:03,040
so that will simplify this process

00:15:03,440 --> 00:15:09,760
now a write key in ozone is basically

00:15:06,720 --> 00:15:12,320
same as what we have in

00:15:09,760 --> 00:15:13,920
the hdfs world right so a client calls a

00:15:12,320 --> 00:15:16,320
put key on ozone manager

00:15:13,920 --> 00:15:17,760
ozone manager will always have some

00:15:16,320 --> 00:15:19,519
pre-allocated blocks

00:15:17,760 --> 00:15:22,079
uh you know and container pipeline

00:15:19,519 --> 00:15:24,560
combinations from scn

00:15:22,079 --> 00:15:25,600
so once the ozone manager will share

00:15:24,560 --> 00:15:27,519
these

00:15:25,600 --> 00:15:29,680
blocks to the client client will

00:15:27,519 --> 00:15:31,600
directly talk to that particular data

00:15:29,680 --> 00:15:33,360
node wherever those blocks are

00:15:31,600 --> 00:15:35,759
write the data as chunks and update the

00:15:33,360 --> 00:15:37,920
metadata and once the client is done

00:15:35,759 --> 00:15:40,480
writing it will

00:15:37,920 --> 00:15:42,079
on ozone manager which is nothing but a

00:15:40,480 --> 00:15:44,800
you know close the file i'm done with it

00:15:42,079 --> 00:15:46,720
kind of situation

00:15:44,800 --> 00:15:48,880
read again is pretty much very similar

00:15:46,720 --> 00:15:51,040
to the hdfs path client says

00:15:48,880 --> 00:15:52,639
to zone manager uh get me this key and

00:15:51,040 --> 00:15:55,120
then also manager brings the

00:15:52,639 --> 00:15:56,880
key location infos once the info is

00:15:55,120 --> 00:15:58,079
available to client it goes directly to

00:15:56,880 --> 00:16:02,160
that data nodes and then

00:15:58,079 --> 00:16:02,160
reads the data blocks as chunks

00:16:03,120 --> 00:16:07,440
now let me just break out of this slide

00:16:06,000 --> 00:16:12,399
for a moment and then

00:16:07,440 --> 00:16:12,399
let's go see what's happening here

00:16:18,639 --> 00:16:23,839
so let's put this website in um

00:16:27,519 --> 00:16:31,440
and i have observed that this website

00:16:29,040 --> 00:16:33,759
does run a bit slow so

00:16:31,440 --> 00:16:35,839
so basically this is the gdpr

00:16:33,759 --> 00:16:39,120
enforcement tracker website

00:16:35,839 --> 00:16:42,639
and you will always get a live view of

00:16:39,120 --> 00:16:44,320
every gdpr violation that happens and

00:16:42,639 --> 00:16:47,199
the fines that are imposed on

00:16:44,320 --> 00:16:47,759
whichever entity for whatever reason so

00:16:47,199 --> 00:16:49,600
you know

00:16:47,759 --> 00:16:52,160
we can see on top right some new fine

00:16:49,600 --> 00:16:55,759
amount of 35 million euros for

00:16:52,160 --> 00:16:57,920
you know which company like that and

00:16:55,759 --> 00:17:00,399
if you scroll down further you'll see

00:16:57,920 --> 00:17:02,639
massive amount of fines being imposed on

00:17:00,399 --> 00:17:05,199
very very popular names as well as the

00:17:02,639 --> 00:17:08,160
not so popular business names

00:17:05,199 --> 00:17:08,959
so this site is basically our window

00:17:08,160 --> 00:17:12,400
which tells us

00:17:08,959 --> 00:17:14,799
okay where all the gdpr violations

00:17:12,400 --> 00:17:16,079
are serious and it's not to be taken

00:17:14,799 --> 00:17:19,199
very lightly

00:17:16,079 --> 00:17:20,799
now the talk that we have today is for

00:17:19,199 --> 00:17:23,360
the right to be forgotten which comes

00:17:20,799 --> 00:17:26,559
under article 17 of gdpr

00:17:23,360 --> 00:17:27,199
so if i search for article 17 uh again

00:17:26,559 --> 00:17:30,480
i'll find

00:17:27,199 --> 00:17:31,520
lot of you know situations where people

00:17:30,480 --> 00:17:35,120
have been

00:17:31,520 --> 00:17:35,919
given massive fines so this is just to

00:17:35,120 --> 00:17:40,160
demonstrate

00:17:35,919 --> 00:17:42,559
that right to be forgotten is a

00:17:40,160 --> 00:17:46,080
topic especially when it comes to gdpr

00:17:42,559 --> 00:17:48,880
compliance right

00:17:46,080 --> 00:17:48,880
my slide deck

00:17:49,760 --> 00:17:53,520
so these are some of the you know big

00:17:51,200 --> 00:17:56,480
names that got fined uh earlier

00:17:53,520 --> 00:17:58,160
um this year and the year before that

00:17:56,480 --> 00:18:02,160
once the gdpr violations

00:17:58,160 --> 00:18:04,960
took a serious turn so what is the gdpr

00:18:02,160 --> 00:18:05,520
concept right so it's it's a european

00:18:04,960 --> 00:18:07,360
union

00:18:05,520 --> 00:18:09,520
uh concept right it's called the general

00:18:07,360 --> 00:18:11,280
data protection regulation

00:18:09,520 --> 00:18:12,960
so of course i've written a lot of bunch

00:18:11,280 --> 00:18:15,120
of things on the slide but in a sense

00:18:12,960 --> 00:18:16,240
what it is is it's a set of guidelines

00:18:15,120 --> 00:18:20,000
and rules

00:18:16,240 --> 00:18:22,960
uh for data controllers right because

00:18:20,000 --> 00:18:25,039
you are taking someone else's data and

00:18:22,960 --> 00:18:26,000
managing as part of your business or as

00:18:25,039 --> 00:18:28,320
part of your

00:18:26,000 --> 00:18:29,440
commercial enterprise or whatever may be

00:18:28,320 --> 00:18:32,000
the case right

00:18:29,440 --> 00:18:34,320
so in that scenario uh somebody has to

00:18:32,000 --> 00:18:35,760
be held accountable somebody has to take

00:18:34,320 --> 00:18:39,200
the ownership

00:18:35,760 --> 00:18:41,919
uh and manage the data processes right

00:18:39,200 --> 00:18:42,720
so gdpr basically defines certain

00:18:41,919 --> 00:18:45,760
framework

00:18:42,720 --> 00:18:46,720
a set of rules on what the data complies

00:18:45,760 --> 00:18:48,960
need to be

00:18:46,720 --> 00:18:50,160
do you know to be compliant with their

00:18:48,960 --> 00:18:53,039
guidelines

00:18:50,160 --> 00:18:54,640
and then what happens if you end up say

00:18:53,039 --> 00:18:56,480
violating a particular

00:18:54,640 --> 00:18:58,960
rule or a particular article in this

00:18:56,480 --> 00:18:59,679
framework although it's saying european

00:18:58,960 --> 00:19:01,760
law

00:18:59,679 --> 00:19:04,160
but what happens is sometimes you might

00:19:01,760 --> 00:19:08,160
have a say an american company

00:19:04,160 --> 00:19:11,440
who has the data of you know eu citizens

00:19:08,160 --> 00:19:14,480
so in that kind of a scenario although

00:19:11,440 --> 00:19:16,799
the company is not in europe um

00:19:14,480 --> 00:19:18,000
but it still will have to comply with

00:19:16,799 --> 00:19:22,000
the gdpr

00:19:18,000 --> 00:19:25,120
laws right so with storage systems

00:19:22,000 --> 00:19:27,120
and gdpr what is our challenge right the

00:19:25,120 --> 00:19:27,919
first one is the territorial scope right

00:19:27,120 --> 00:19:29,679
so

00:19:27,919 --> 00:19:32,320
in in the olden days yeah you would have

00:19:29,679 --> 00:19:34,400
a scenario where the data

00:19:32,320 --> 00:19:36,240
stays in that geography and your storage

00:19:34,400 --> 00:19:38,320
system is in that geography

00:19:36,240 --> 00:19:39,760
but now with the advent of cloud and you

00:19:38,320 --> 00:19:41,679
know all the other

00:19:39,760 --> 00:19:43,679
failover mechanisms people want to have

00:19:41,679 --> 00:19:46,320
multiple replicas of data

00:19:43,679 --> 00:19:47,919
and oftentimes they will also have

00:19:46,320 --> 00:19:50,000
offshore replicas

00:19:47,919 --> 00:19:51,120
so that brings the complexity of the

00:19:50,000 --> 00:19:53,200
toriel scope

00:19:51,120 --> 00:19:56,400
then the challenge is about the personal

00:19:53,200 --> 00:19:58,960
data that anybody stores in the system

00:19:56,400 --> 00:20:00,000
and there comes the right to erasure it

00:19:58,960 --> 00:20:03,200
is one of

00:20:00,000 --> 00:20:04,799
the principles in gdpr it is also known

00:20:03,200 --> 00:20:08,240
as right to be forgotten

00:20:04,799 --> 00:20:10,240
so what it means is say for example i'm

00:20:08,240 --> 00:20:12,320
an eu citizen and i'm on facebook and i

00:20:10,240 --> 00:20:15,039
have uploaded some photos or

00:20:12,320 --> 00:20:17,039
you know some stuff there on facebook as

00:20:15,039 --> 00:20:20,000
an eu citizen it gives me a right

00:20:17,039 --> 00:20:20,720
to just go on to facebook and ask them

00:20:20,000 --> 00:20:22,799
to

00:20:20,720 --> 00:20:23,760
delete all my data from all their

00:20:22,799 --> 00:20:26,720
systems

00:20:23,760 --> 00:20:29,120
all their backups and everything and

00:20:26,720 --> 00:20:31,600
facebook because is the data controller

00:20:29,120 --> 00:20:33,600
in this scenario it has a notification

00:20:31,600 --> 00:20:35,280
obligation so what that means

00:20:33,600 --> 00:20:36,799
is that facebook has to give me in

00:20:35,280 --> 00:20:40,480
writing that yes

00:20:36,799 --> 00:20:43,200
i have deleted all your data and

00:20:40,480 --> 00:20:43,760
whatever reason we find that it's not

00:20:43,200 --> 00:20:45,280
true

00:20:43,760 --> 00:20:48,080
some amount of data is still left

00:20:45,280 --> 00:20:50,799
somewhere right so that counts as a gdpr

00:20:48,080 --> 00:20:51,360
compliance uh violation and thereby you

00:20:50,799 --> 00:20:53,679
know

00:20:51,360 --> 00:20:54,799
the organization might be fined so this

00:20:53,679 --> 00:20:56,480
is the kind of

00:20:54,799 --> 00:20:58,880
problem statement that we are trying to

00:20:56,480 --> 00:21:01,039
solve now historically

00:20:58,880 --> 00:21:02,000
in large in the distributed systems what

00:21:01,039 --> 00:21:04,720
we have seen is the

00:21:02,000 --> 00:21:05,200
actual data blocks will get deleted you

00:21:04,720 --> 00:21:09,120
know much

00:21:05,200 --> 00:21:11,919
later so how do you as a controller

00:21:09,120 --> 00:21:13,679
uh you know can certify that yes i have

00:21:11,919 --> 00:21:15,280
deleted this data

00:21:13,679 --> 00:21:16,880
and you know we have complied with the

00:21:15,280 --> 00:21:18,720
gdpr regulations

00:21:16,880 --> 00:21:20,000
right so that is the problem that we'll

00:21:18,720 --> 00:21:23,280
talk about so

00:21:20,000 --> 00:21:25,280
this is the delete path um of ozone

00:21:23,280 --> 00:21:26,320
a client calls a delete key on ozone

00:21:25,280 --> 00:21:29,360
manager

00:21:26,320 --> 00:21:32,240
uh then the ozone manager calls the same

00:21:29,360 --> 00:21:34,080
method on scm scm goes to the data nodes

00:21:32,240 --> 00:21:36,320
which has those containers

00:21:34,080 --> 00:21:38,559
and it will call the delete blocks but

00:21:36,320 --> 00:21:40,880
even before all this happens

00:21:38,559 --> 00:21:42,559
the moment ozone manager gets the delete

00:21:40,880 --> 00:21:44,480
key request

00:21:42,559 --> 00:21:45,600
it acknowledges that the key has been

00:21:44,480 --> 00:21:48,159
deleted right

00:21:45,600 --> 00:21:49,919
right after it communicates to scm but

00:21:48,159 --> 00:21:53,520
the actual data blocks are still there

00:21:49,919 --> 00:21:54,080
in the system now under the hood what

00:21:53,520 --> 00:21:56,320
happens

00:21:54,080 --> 00:21:57,520
once the ozone manager gets the delete

00:21:56,320 --> 00:21:59,440
request

00:21:57,520 --> 00:22:01,120
in the memory it has a table called you

00:21:59,440 --> 00:22:03,760
know deleted keys table

00:22:01,120 --> 00:22:05,840
where it moves the information about

00:22:03,760 --> 00:22:08,480
that particular key which the client

00:22:05,840 --> 00:22:11,280
wants to delete

00:22:08,480 --> 00:22:12,080
so in the ozone manager there is also a

00:22:11,280 --> 00:22:14,960
key deleting

00:22:12,080 --> 00:22:16,240
service which runs periodically right so

00:22:14,960 --> 00:22:18,640
it just checks

00:22:16,240 --> 00:22:20,480
after every certain period of time it

00:22:18,640 --> 00:22:21,840
will tell the storage container hey

00:22:20,480 --> 00:22:24,000
these are the new set of keys i would

00:22:21,840 --> 00:22:25,360
like you to delete storage manager

00:22:24,000 --> 00:22:27,360
acknowledges that

00:22:25,360 --> 00:22:28,559
and after that the key deleting service

00:22:27,360 --> 00:22:32,640
will empty the table

00:22:28,559 --> 00:22:32,640
because the message has been passed

00:22:32,799 --> 00:22:38,159
and as i was saying right the

00:22:35,919 --> 00:22:40,080
storage container manager will then you

00:22:38,159 --> 00:22:43,280
know create a deleted block manifest

00:22:40,080 --> 00:22:45,440
it will sort it by data nodes because

00:22:43,280 --> 00:22:46,960
uh you know containers will be residing

00:22:45,440 --> 00:22:48,799
on the data nodes and then it will send

00:22:46,960 --> 00:22:51,039
those manifests to data node

00:22:48,799 --> 00:22:52,720
and then you know uh there is an

00:22:51,039 --> 00:22:55,039
internal process by which the data node

00:22:52,720 --> 00:22:58,640
will eventually pick up that manifest

00:22:55,039 --> 00:23:00,960
and clear all the block so

00:22:58,640 --> 00:23:01,679
with this the problem is that we don't

00:23:00,960 --> 00:23:04,400
know when

00:23:01,679 --> 00:23:05,760
exactly it will be deleted and since we

00:23:04,400 --> 00:23:06,720
don't know when exactly it will be

00:23:05,760 --> 00:23:09,840
deleted

00:23:06,720 --> 00:23:12,640
there is almost no way

00:23:09,840 --> 00:23:14,960
you know by which you can certify that i

00:23:12,640 --> 00:23:17,919
have complied with the gdpr

00:23:14,960 --> 00:23:20,720
situation and and i can assure in

00:23:17,919 --> 00:23:22,960
writing that the data has been deleted

00:23:20,720 --> 00:23:24,159
so how do we address this problem in

00:23:22,960 --> 00:23:27,679
ozone

00:23:24,159 --> 00:23:29,919
so in ozone we thought okay um

00:23:27,679 --> 00:23:31,520
why don't we lose the encryption key

00:23:29,919 --> 00:23:34,400
right so

00:23:31,520 --> 00:23:35,600
if you don't know the key with which the

00:23:34,400 --> 00:23:37,840
data was encoded

00:23:35,600 --> 00:23:39,360
there is no way for you to decode so the

00:23:37,840 --> 00:23:42,640
data is virtually

00:23:39,360 --> 00:23:43,840
considered lost right so what we do in

00:23:42,640 --> 00:23:46,159
ozone is

00:23:43,840 --> 00:23:47,440
we introduced a flag in the bucket

00:23:46,159 --> 00:23:49,520
creation commands

00:23:47,440 --> 00:23:51,840
where you can specify whether it's a

00:23:49,520 --> 00:23:54,400
gdpr enabled bucket or not

00:23:51,840 --> 00:23:56,720
once such a bucket is created and if a

00:23:54,400 --> 00:23:59,360
client now wants to write a key

00:23:56,720 --> 00:24:01,520
in that particular bucket it will first

00:23:59,360 --> 00:24:05,039
generate a simple encryption key

00:24:01,520 --> 00:24:07,679
and the client will use this key to

00:24:05,039 --> 00:24:08,400
encode and write that data to blocks so

00:24:07,679 --> 00:24:09,679
the blocks

00:24:08,400 --> 00:24:12,000
you know obviously are written in the

00:24:09,679 --> 00:24:12,559
encoded format now when the client wants

00:24:12,000 --> 00:24:15,600
to read

00:24:12,559 --> 00:24:17,440
the same blocks again uh it will pick up

00:24:15,600 --> 00:24:20,400
the encryption key from the memory

00:24:17,440 --> 00:24:22,640
right from the key info for each key and

00:24:20,400 --> 00:24:24,960
we'll use that key to decode it

00:24:22,640 --> 00:24:26,640
and then go ahead and you know reveal

00:24:24,960 --> 00:24:29,440
the data

00:24:26,640 --> 00:24:29,840
so what we did is uh during the delete

00:24:29,440 --> 00:24:33,120
phase

00:24:29,840 --> 00:24:36,640
right i was saying that the

00:24:33,120 --> 00:24:39,840
uh let me go back to the previous slide

00:24:36,640 --> 00:24:41,840
yeah so right here so every time we

00:24:39,840 --> 00:24:44,080
issue a delete key command the ozone

00:24:41,840 --> 00:24:47,039
manager will move the key info

00:24:44,080 --> 00:24:48,240
to the deleted keys section so when it

00:24:47,039 --> 00:24:50,400
does that

00:24:48,240 --> 00:24:51,679
uh what we are doing is we are getting

00:24:50,400 --> 00:24:55,440
rid of the

00:24:51,679 --> 00:24:58,799
encryption key from the key info object

00:24:55,440 --> 00:25:02,320
so now what happens is once

00:24:58,799 --> 00:25:02,320
deleted keys table right

00:25:02,799 --> 00:25:06,720
key info is here the associated

00:25:05,360 --> 00:25:08,240
encryption key

00:25:06,720 --> 00:25:11,279
doesn't exist because it has been

00:25:08,240 --> 00:25:15,679
deleted from this object

00:25:11,279 --> 00:25:16,640
now since your option key is irrevocably

00:25:15,679 --> 00:25:19,360
lost

00:25:16,640 --> 00:25:20,400
there is no way that the data can be

00:25:19,360 --> 00:25:22,880
decoded

00:25:20,400 --> 00:25:25,360
even if you know the actual blocks are

00:25:22,880 --> 00:25:27,279
deleted much later or even if you

00:25:25,360 --> 00:25:29,520
are somehow able to get into the data

00:25:27,279 --> 00:25:32,960
node where the actual blocks are

00:25:29,520 --> 00:25:34,640
residing with this the notification of

00:25:32,960 --> 00:25:37,760
obligation is achieved

00:25:34,640 --> 00:25:40,880
because there is no way that anybody

00:25:37,760 --> 00:25:43,120
could get those data

00:25:40,880 --> 00:25:44,400
or files or the blocks uh even after

00:25:43,120 --> 00:25:46,000
being deleted right

00:25:44,400 --> 00:25:48,400
because even if they get it they can't

00:25:46,000 --> 00:25:51,279
read it so i've left a link here

00:25:48,400 --> 00:25:52,320
uh where it will talk in much detail

00:25:51,279 --> 00:25:54,640
about the design

00:25:52,320 --> 00:25:56,240
uh of this feature and how you can

00:25:54,640 --> 00:26:00,559
enable this

00:25:56,240 --> 00:26:02,640
bucket and this gdpr concept on ozo

00:26:00,559 --> 00:26:04,320
so of course uh you know there are some

00:26:02,640 --> 00:26:06,960
known limitations of this system

00:26:04,320 --> 00:26:09,039
um so first one is backups and restore

00:26:06,960 --> 00:26:12,240
as i was saying right ozone uses

00:26:09,039 --> 00:26:15,039
a rock's tb layer for the metadata

00:26:12,240 --> 00:26:16,240
so if you were backing up the metadata

00:26:15,039 --> 00:26:18,799
and

00:26:16,240 --> 00:26:19,440
you would end up restoring the metadata

00:26:18,799 --> 00:26:22,640
after

00:26:19,440 --> 00:26:24,480
say deleting some files yeah the keys

00:26:22,640 --> 00:26:25,760
will come up in the name space again so

00:26:24,480 --> 00:26:28,080
that is a limitation

00:26:25,760 --> 00:26:29,200
that is something that we are we have a

00:26:28,080 --> 00:26:32,000
proposal to

00:26:29,200 --> 00:26:32,720
uh address this restore scenario in

00:26:32,000 --> 00:26:34,880
future

00:26:32,720 --> 00:26:36,320
that when you restore we can also

00:26:34,880 --> 00:26:39,039
provide the

00:26:36,320 --> 00:26:40,799
audit logs up until that point and then

00:26:39,039 --> 00:26:43,840
the restore functionality would

00:26:40,799 --> 00:26:46,480
basically take care and delete such keys

00:26:43,840 --> 00:26:47,600
before it makes the system available for

00:26:46,480 --> 00:26:50,000
users

00:26:47,600 --> 00:26:50,640
but it's a proposal it's not yet

00:26:50,000 --> 00:26:53,120
committed

00:26:50,640 --> 00:26:54,559
uh you know when this will be done the

00:26:53,120 --> 00:26:58,080
other scenario is

00:26:54,559 --> 00:27:00,480
when you create and delete keys

00:26:58,080 --> 00:27:01,440
quickly right with the same key name and

00:27:00,480 --> 00:27:04,720
the same

00:27:01,440 --> 00:27:07,679
volume bucket path sometimes it can end

00:27:04,720 --> 00:27:09,520
up generating false positives because

00:27:07,679 --> 00:27:11,279
uh let's say you created a key called

00:27:09,520 --> 00:27:14,000
key one and then you

00:27:11,279 --> 00:27:15,039
deleted it and now i ask you to certify

00:27:14,000 --> 00:27:17,679
and you said okay

00:27:15,039 --> 00:27:18,159
your key is deleted but right after that

00:27:17,679 --> 00:27:19,520
if you are

00:27:18,159 --> 00:27:21,760
you know continuously creating and

00:27:19,520 --> 00:27:23,120
deleting with the same name

00:27:21,760 --> 00:27:25,360
it will obviously lead to false

00:27:23,120 --> 00:27:27,919
positives and

00:27:25,360 --> 00:27:29,679
the last limitation is that if you have

00:27:27,919 --> 00:27:33,200
existing buckets

00:27:29,679 --> 00:27:35,919
that are not gdpr enabled then

00:27:33,200 --> 00:27:38,159
you cannot just turn on the flag and uh

00:27:35,919 --> 00:27:40,480
you know make the entire bucket as gdpr

00:27:38,159 --> 00:27:43,600
compliant you basically would need to

00:27:40,480 --> 00:27:44,559
copy the blocks or the data from those

00:27:43,600 --> 00:27:47,200
buckets

00:27:44,559 --> 00:27:49,279
into a new gdpr enabled bucket so this

00:27:47,200 --> 00:27:52,880
is just like uh

00:27:49,279 --> 00:27:55,360
encryption zones in hdfs right the

00:27:52,880 --> 00:27:58,640
files need to be copied out and then

00:27:55,360 --> 00:28:01,200
back in again that kind of a scenario

00:27:58,640 --> 00:28:03,360
so these are the limitations um and then

00:28:01,200 --> 00:28:06,720
talking about the ozone road map so

00:28:03,360 --> 00:28:10,240
ozone recently went uh ga

00:28:06,720 --> 00:28:11,600
with version 1.0.0 uh of course before

00:28:10,240 --> 00:28:14,720
it went ga there were

00:28:11,600 --> 00:28:16,640
several alpha and a beta release over

00:28:14,720 --> 00:28:20,480
the last couple of years

00:28:16,640 --> 00:28:24,240
and the ga feature release basically has

00:28:20,480 --> 00:28:24,720
end-to-end security tde uh ozone manager

00:28:24,240 --> 00:28:27,039
ha

00:28:24,720 --> 00:28:28,240
s3 api support network topology

00:28:27,039 --> 00:28:30,559
awareness

00:28:28,240 --> 00:28:32,320
it's been tested with certain apache

00:28:30,559 --> 00:28:35,039
projects like high avion

00:28:32,320 --> 00:28:35,760
mapreduce impala and spark and there is

00:28:35,039 --> 00:28:38,480
some

00:28:35,760 --> 00:28:40,559
um you know ongoing tests with some of

00:28:38,480 --> 00:28:41,360
the other apache projects like hbase

00:28:40,559 --> 00:28:45,120
nifi

00:28:41,360 --> 00:28:46,080
kudu and so on uh so there is an ongoing

00:28:45,120 --> 00:28:49,520
proposal

00:28:46,080 --> 00:28:50,640
for uh apache hadoop ozone to be carved

00:28:49,520 --> 00:28:52,320
out as a separate

00:28:50,640 --> 00:28:55,440
apache top level project in the

00:28:52,320 --> 00:28:57,840
community uh we'll see how that goes

00:28:55,440 --> 00:28:58,880
and then there is a future work to

00:28:57,840 --> 00:29:02,240
include

00:28:58,880 --> 00:29:04,799
features like erasure coding uh scmha

00:29:02,240 --> 00:29:05,679
hdfs two ozone upgrade ozone to ozone

00:29:04,799 --> 00:29:07,760
upgrade

00:29:05,679 --> 00:29:10,000
and then uh hardened support for some of

00:29:07,760 --> 00:29:13,200
the other apache projects like edge base

00:29:10,000 --> 00:29:15,520
nifi based on the community and the user

00:29:13,200 --> 00:29:18,640
demand

00:29:15,520 --> 00:29:20,799
so with that here is the reference slide

00:29:18,640 --> 00:29:23,440
you can follow us on twitter we have a

00:29:20,799 --> 00:29:26,159
video series where we talk about some of

00:29:23,440 --> 00:29:28,320
the internal concepts of ozone and if

00:29:26,159 --> 00:29:30,000
you are a developer then we talk about

00:29:28,320 --> 00:29:31,440
okay how do you set up the environment

00:29:30,000 --> 00:29:33,760
how do you debug

00:29:31,440 --> 00:29:35,039
ozone in an ide and how can you play

00:29:33,760 --> 00:29:36,399
around with it from a developer

00:29:35,039 --> 00:29:37,760
standpoint

00:29:36,399 --> 00:29:39,279
if you'd like to learn more or get

00:29:37,760 --> 00:29:40,240
started with ozone you can check out our

00:29:39,279 --> 00:29:43,600
website

00:29:40,240 --> 00:29:44,720
um we also have an official roadmap wiki

00:29:43,600 --> 00:29:47,760
and a community

00:29:44,720 --> 00:29:48,720
weekly meeting which happens for two

00:29:47,760 --> 00:29:51,760
time zones

00:29:48,720 --> 00:29:52,320
one is that caters for more uh you know

00:29:51,760 --> 00:29:55,039
the

00:29:52,320 --> 00:29:56,559
asia pacific region uh and it happens in

00:29:55,039 --> 00:29:59,600
a more friendly time for them

00:29:56,559 --> 00:30:01,600
and then one happens in the north

00:29:59,600 --> 00:30:04,240
american edt timeline

00:30:01,600 --> 00:30:06,240
so those meetings are obviously open to

00:30:04,240 --> 00:30:08,640
the community so anybody can join in and

00:30:06,240 --> 00:30:11,200
if you have more questions we would be

00:30:08,640 --> 00:30:12,159
uh happy to hear from you uh there as

00:30:11,200 --> 00:30:14,240
well

00:30:12,159 --> 00:30:15,840
uh so with that said uh you know it's an

00:30:14,240 --> 00:30:20,559
end of this presentation

00:30:15,840 --> 00:30:20,559
but at this point i will just check if

00:30:20,840 --> 00:30:26,559
questions

00:30:23,520 --> 00:30:29,360
oh that's quite a lot so let's see so

00:30:26,559 --> 00:30:32,480
first question is is it possible to use

00:30:29,360 --> 00:30:36,320
ozone as a drop in replacement for

00:30:32,480 --> 00:30:39,360
hdfs from client api perspective uh

00:30:36,320 --> 00:30:40,240
yes it would be possible because what we

00:30:39,360 --> 00:30:43,039
would do is

00:30:40,240 --> 00:30:45,279
as i said right the clients will pick up

00:30:43,039 --> 00:30:47,679
the configuration from ozone manager

00:30:45,279 --> 00:30:48,399
so there is a design proposal out there

00:30:47,679 --> 00:30:50,720
on

00:30:48,399 --> 00:30:52,159
if you have a hdfs cluster and you want

00:30:50,720 --> 00:30:54,399
to upgrade it to ozone

00:30:52,159 --> 00:30:55,279
right so that the new clients will just

00:30:54,399 --> 00:30:57,200
point to the

00:30:55,279 --> 00:30:58,880
new api and then that's it it would work

00:30:57,200 --> 00:31:01,840
as is you don't have to make

00:30:58,880 --> 00:31:04,880
any more app changes about or get 20

00:31:01,840 --> 00:31:06,960
other files and things like that

00:31:04,880 --> 00:31:08,159
so the next question is how strong is

00:31:06,960 --> 00:31:11,679
the encryption for

00:31:08,159 --> 00:31:15,200
keys when gdpr is enabled i guess

00:31:11,679 --> 00:31:15,760
it is symmetric probably aes yes that is

00:31:15,200 --> 00:31:20,399
correct

00:31:15,760 --> 00:31:24,399
so right now we are using a 128 bit

00:31:20,399 --> 00:31:26,240
but there is also a proposal to

00:31:24,399 --> 00:31:28,720
allow and make it configurable instead

00:31:26,240 --> 00:31:29,679
of 128 you might want to use 256 or

00:31:28,720 --> 00:31:31,760
whatever right

00:31:29,679 --> 00:31:33,120
so there is a proposal to make it

00:31:31,760 --> 00:31:34,080
configurable right now it's not

00:31:33,120 --> 00:31:37,519
configurable it's

00:31:34,080 --> 00:31:38,960
using a default of 128. now in terms of

00:31:37,519 --> 00:31:42,159
how strong it is

00:31:38,960 --> 00:31:45,760
um so i'm not going to go there because

00:31:42,159 --> 00:31:48,000
that stat is out there an aes 128 bit is

00:31:45,760 --> 00:31:49,760
fairly difficult to crack so i'll leave

00:31:48,000 --> 00:31:53,440
it at that and

00:31:49,760 --> 00:31:56,480
if it adds any confidence nsa

00:31:53,440 --> 00:32:00,960
also uses 128 bit aes

00:31:56,480 --> 00:32:03,519
for a lot of their top secret stuff

00:32:00,960 --> 00:32:04,640
next question is and can we use the lib

00:32:03,519 --> 00:32:08,399
hdfs

00:32:04,640 --> 00:32:10,880
api to access data stored in ozone

00:32:08,399 --> 00:32:12,880
i am not very familiar with live hdfs

00:32:10,880 --> 00:32:15,440
api but

00:32:12,880 --> 00:32:16,720
if you would uh like to join in any of

00:32:15,440 --> 00:32:17,600
our community meetings i would

00:32:16,720 --> 00:32:19,840
definitely

00:32:17,600 --> 00:32:21,440
help you to get the answer for that or

00:32:19,840 --> 00:32:23,679
otherwise you could just

00:32:21,440 --> 00:32:25,440
buzz me on twitter and so that i have

00:32:23,679 --> 00:32:26,880
your contact i can get back to you on

00:32:25,440 --> 00:32:28,880
that right

00:32:26,880 --> 00:32:30,399
uh next question is so is this possible

00:32:28,880 --> 00:32:32,799
only at bucket level

00:32:30,399 --> 00:32:34,640
yes so gdpr what we want to do is we do

00:32:32,799 --> 00:32:37,919
not want to enable at file level

00:32:34,640 --> 00:32:39,919
right um because if you're a certain

00:32:37,919 --> 00:32:42,080
organization right you have a set of

00:32:39,919 --> 00:32:43,840
files that you would

00:32:42,080 --> 00:32:46,000
enable it's just like the encryption

00:32:43,840 --> 00:32:48,960
zone concept in hdfs

00:32:46,000 --> 00:32:49,919
so it will only happen at bucket level

00:32:48,960 --> 00:32:51,679
now there is some

00:32:49,919 --> 00:32:54,000
uh discussion in the community that's

00:32:51,679 --> 00:32:57,200
going on on whether we want to make

00:32:54,000 --> 00:32:58,880
a volume also as gdpr enabled so what

00:32:57,200 --> 00:33:01,039
would end up happening is

00:32:58,880 --> 00:33:02,320
all buckets under that volume will be

00:33:01,039 --> 00:33:05,679
gdpr enabled

00:33:02,320 --> 00:33:07,919
so this is more of a feasibility check

00:33:05,679 --> 00:33:10,080
on whether we want to do that or not but

00:33:07,919 --> 00:33:11,440
it's a fairly small change it's like a

00:33:10,080 --> 00:33:14,159
maybe a 10-line patch

00:33:11,440 --> 00:33:16,240
to make that change happen but today it

00:33:14,159 --> 00:33:19,519
only happens at bucket lab

00:33:16,240 --> 00:33:22,000
if non-gdpr data is deleted at

00:33:19,519 --> 00:33:24,240
what point is it actually deleted does

00:33:22,000 --> 00:33:26,399
it wait for a certain number of deletes

00:33:24,240 --> 00:33:28,480
in a container or a time threshold

00:33:26,399 --> 00:33:29,679
so actually it's a time threshold so

00:33:28,480 --> 00:33:32,000
what happens is uh

00:33:29,679 --> 00:33:33,840
as i was explaining the delete path once

00:33:32,000 --> 00:33:36,880
the delete instruction is passed from

00:33:33,840 --> 00:33:39,039
ozone manager to scm scm waits for a

00:33:36,880 --> 00:33:40,480
certain time it prepares the deleted

00:33:39,039 --> 00:33:43,440
block manifest

00:33:40,480 --> 00:33:44,240
uh and sorts them by data node right and

00:33:43,440 --> 00:33:46,880
then it sends

00:33:44,240 --> 00:33:48,320
those manifest to the data nodes and

00:33:46,880 --> 00:33:49,840
then data nodes take their time to

00:33:48,320 --> 00:33:52,399
delete the blocks

00:33:49,840 --> 00:33:54,799
but i do not recall right off the top of

00:33:52,399 --> 00:33:58,240
my head on what that timeline is and

00:33:54,799 --> 00:33:59,919
uh what is the periodic check interval

00:33:58,240 --> 00:34:01,840
but yeah right now it happens based on

00:33:59,919 --> 00:34:04,480
time

00:34:01,840 --> 00:34:06,000
so next question thanks for the

00:34:04,480 --> 00:34:09,040
presentation what's planned for

00:34:06,000 --> 00:34:11,839
existing hdfs users to migrate

00:34:09,040 --> 00:34:13,200
ozone and how the security works as it

00:34:11,839 --> 00:34:16,639
works for

00:34:13,200 --> 00:34:17,520
both object and file so the first

00:34:16,639 --> 00:34:20,399
question

00:34:17,520 --> 00:34:21,280
hdfs uses to migrate ozone yes there is

00:34:20,399 --> 00:34:24,320
an ongoing

00:34:21,280 --> 00:34:27,599
uh design work that's happening

00:34:24,320 --> 00:34:30,639
which is about if you take an hdfs

00:34:27,599 --> 00:34:32,320
cluster can i do an in-place upgrade and

00:34:30,639 --> 00:34:35,599
you know convert it to another cluster

00:34:32,320 --> 00:34:38,560
so that is going

00:34:35,599 --> 00:34:39,200
so hopefully it will be you know

00:34:38,560 --> 00:34:41,760
available

00:34:39,200 --> 00:34:44,320
soon once we finalize and harden the

00:34:41,760 --> 00:34:46,000
design and go ahead and implement it

00:34:44,320 --> 00:34:47,359
and then your second question was how

00:34:46,000 --> 00:34:50,000
the security works

00:34:47,359 --> 00:34:52,079
as it works for both object and file yes

00:34:50,000 --> 00:34:53,520
so security is uh you know obviously

00:34:52,079 --> 00:34:55,040
works at both levels so

00:34:53,520 --> 00:34:56,639
depending on how strong you want the

00:34:55,040 --> 00:34:58,720
security you want tde

00:34:56,639 --> 00:35:00,320
uh so even your blocks will be encoded

00:34:58,720 --> 00:35:02,079
at the end of the day you can't really

00:35:00,320 --> 00:35:04,240
read anything uh if you don't have the

00:35:02,079 --> 00:35:05,839
right set of keys to decode

00:35:04,240 --> 00:35:07,920
and security is pretty much you know you

00:35:05,839 --> 00:35:10,000
have kerberos you have td

00:35:07,920 --> 00:35:10,960
um and you know you have certificates

00:35:10,000 --> 00:35:14,160
and all that so

00:35:10,960 --> 00:35:16,400
it's end-to-end okay

00:35:14,160 --> 00:35:19,359
and then we have another question which

00:35:16,400 --> 00:35:23,359
says all the existing hdfs still be

00:35:19,359 --> 00:35:26,480
features will be available um

00:35:23,359 --> 00:35:28,480
that's a good question so i would say

00:35:26,480 --> 00:35:30,320
as a file system whatever features it

00:35:28,480 --> 00:35:32,240
needs it would have

00:35:30,320 --> 00:35:34,079
additional is it would behave as an

00:35:32,240 --> 00:35:35,680
object store as well so

00:35:34,079 --> 00:35:37,520
you would get a little bit more over

00:35:35,680 --> 00:35:40,560
there uh

00:35:37,520 --> 00:35:42,000
like storage types trash so trash is an

00:35:40,560 --> 00:35:43,280
ongoing feature that's a very good

00:35:42,000 --> 00:35:45,920
question uh trash in

00:35:43,280 --> 00:35:46,320
ozone is an ongoing feature and there is

00:35:45,920 --> 00:35:49,359
a

00:35:46,320 --> 00:35:51,200
ongoing work going on for truncate and

00:35:49,359 --> 00:35:54,320
append as well

00:35:51,200 --> 00:35:57,200
right so i guess yeah

00:35:54,320 --> 00:35:59,040
that's all the question i have but i'll

00:35:57,200 --> 00:36:01,280
still hang around for a few more minutes

00:35:59,040 --> 00:36:04,160
if some more questions come up

00:36:01,280 --> 00:36:04,560
and i see appreciations from a few folks

00:36:04,160 --> 00:36:07,440
so

00:36:04,560 --> 00:36:10,079
thank you so much for listening in i was

00:36:07,440 --> 00:36:10,079
glad it was

00:36:10,839 --> 00:36:13,839
worthless

00:36:58,480 --> 00:37:02,160
all right i guess i can terminate the

00:37:00,720 --> 00:37:03,920
session now um

00:37:02,160 --> 00:37:06,640
and we'll move on to the other talks at

00:37:03,920 --> 00:37:09,839
apachecon and have a happy apache

00:37:06,640 --> 00:37:09,839

YouTube URL: https://www.youtube.com/watch?v=mISCTU-cqt8


