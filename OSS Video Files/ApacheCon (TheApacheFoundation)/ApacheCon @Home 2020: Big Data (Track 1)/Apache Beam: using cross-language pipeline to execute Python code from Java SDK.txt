Title: Apache Beam: using cross-language pipeline to execute Python code from Java SDK
Publication date: 2020-10-21
Playlist: ApacheCon @Home 2020: Big Data (Track 1)
Description: 
	Apache Beam: using cross-language pipeline to execute Python code from Java SDK
Alexey Romanenko

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

There are many reasons why we would need to execute Python code in Java data processing pipelines (and vice versa) - e.g. Machine Learning libraries, IO connectors, user’s Python code - and several different ways to do that. With the End of Life of Python 2 started this year, it’s getting more challenging since not all old solutions still work well for Python 3. One of the potential options for this could be using a cross-language pipeline and Portable Runner in Apache Beam. In this talk I’m going to talk about what the cross-language pipeline in Beam is, how to create a mixed Java/Python pipeline, how to set up and run it, what kind of requirements and pitfalls we can expect in this case. Also, I’ll show a demo of a use case where we need to execute a custom user’s Python 3 code in the middle of Java SDK pipeline and run it with Portable Spark Runner.

Alexey Romanenko is Principal Software Engineer at Talend France, with more than 18 years of experience in software development. During his career, he has been working on very different projects, like high-load web services, web search engine and cloud storages. He is Apache Beam PMC member and committer, he contributed to different Beam IO components and Spark Runner.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:24,640 --> 00:00:34,160
let's start

00:00:31,840 --> 00:00:34,160
okay

00:00:40,000 --> 00:00:50,000
hello everybody

00:00:45,200 --> 00:00:53,120
my name is alexis and today i'm going to

00:00:50,000 --> 00:00:55,360
talk about uh about sheben

00:00:53,120 --> 00:00:57,520
and how to use first language pipeline

00:00:55,360 --> 00:01:02,000
to execute a

00:00:57,520 --> 00:01:06,159
item code from java

00:01:02,000 --> 00:01:09,760
usb so let's get started

00:01:06,159 --> 00:01:12,880
a few words about me

00:01:09,760 --> 00:01:15,600
so i'm approaching my pmc

00:01:12,880 --> 00:01:17,920
commuter and also i'm a principal

00:01:15,600 --> 00:01:21,280
software engineer at thailand

00:01:17,920 --> 00:01:21,280
feel free to follow me on here

00:01:22,159 --> 00:01:27,280
quick agenda for today because we'll

00:01:25,439 --> 00:01:30,479
start

00:01:27,280 --> 00:01:30,880
with the uh just in reduction to beam

00:01:30,479 --> 00:01:32,960
for

00:01:30,880 --> 00:01:34,000
those who are not aware of what actually

00:01:32,960 --> 00:01:37,759
is

00:01:34,000 --> 00:01:40,000
then i will talk her about

00:01:37,759 --> 00:01:41,520
uh what actually crossed which pipeline

00:01:40,000 --> 00:01:44,720
is

00:01:41,520 --> 00:01:45,920
and uh a quick again and then just a few

00:01:44,720 --> 00:01:47,680
words about

00:01:45,920 --> 00:01:49,119
beam portability architecture which

00:01:47,680 --> 00:01:50,159
allows us to use the cross-language

00:01:49,119 --> 00:01:52,240
pipeline

00:01:50,159 --> 00:01:53,759
then i will show how to create and run

00:01:52,240 --> 00:01:58,240
across which pipeline

00:01:53,759 --> 00:02:01,040
this beam finally will jump into some

00:01:58,240 --> 00:02:01,680
demo i hope it will work and then i will

00:02:01,040 --> 00:02:04,880
show you

00:02:01,680 --> 00:02:10,239
use cases and uh just

00:02:04,880 --> 00:02:10,239
to give some um some

00:02:10,720 --> 00:02:16,000
sorry some numbers of benchmarks

00:02:18,160 --> 00:02:26,879
uh okay so

00:02:23,200 --> 00:02:27,280
sorry okay introduction to what should

00:02:26,879 --> 00:02:30,480
be

00:02:27,280 --> 00:02:34,000
actually being uh rewards

00:02:30,480 --> 00:02:36,080
uh as we all know that uh back to the

00:02:34,000 --> 00:02:40,000
beginning of 2000

00:02:36,080 --> 00:02:43,760
google published mapreduce paper which

00:02:40,000 --> 00:02:47,680
actually allows users to develop

00:02:43,760 --> 00:02:50,319
and process data in a

00:02:47,680 --> 00:02:51,840
distributed way so finally google

00:02:50,319 --> 00:02:54,959
started to

00:02:51,840 --> 00:02:55,599
work on different projects to processing

00:02:54,959 --> 00:02:58,319
data

00:02:55,599 --> 00:02:58,800
internally but all of this project

00:02:58,319 --> 00:03:01,680
actually

00:02:58,800 --> 00:03:03,840
unfortunately wasn't available for users

00:03:01,680 --> 00:03:06,400
directly

00:03:03,840 --> 00:03:08,319
and at the same time different other

00:03:06,400 --> 00:03:11,519
projects started to be developed

00:03:08,319 --> 00:03:14,720
under patch foundation like of course

00:03:11,519 --> 00:03:18,560
hadoop and the spark fling

00:03:14,720 --> 00:03:23,920
and many others uh

00:03:18,560 --> 00:03:28,480
in the middle of two i think

00:03:23,920 --> 00:03:30,799
two chance uh 2000 tests google

00:03:28,480 --> 00:03:31,680
started projecting google cloud data

00:03:30,799 --> 00:03:34,720
flow

00:03:31,680 --> 00:03:35,840
which actually was based on different

00:03:34,720 --> 00:03:38,720
internal

00:03:35,840 --> 00:03:38,720
google concepts

00:03:39,040 --> 00:03:44,640
taken from film and mirror wheel and

00:03:42,159 --> 00:03:44,640
finally

00:03:44,720 --> 00:03:48,319
it was decided to create open source

00:03:46,879 --> 00:03:50,319
project called

00:03:48,319 --> 00:03:52,159
and then finally it was a donated to

00:03:50,319 --> 00:03:56,239
apache foundation

00:03:52,159 --> 00:04:00,480
uh in the beginning of 2016

00:03:56,239 --> 00:04:03,840
and uh it's in the end of 2016

00:04:00,480 --> 00:04:05,920
it became just a top-level apache

00:04:03,840 --> 00:04:09,280
project

00:04:05,920 --> 00:04:12,000
so what actually beam is uh

00:04:09,280 --> 00:04:14,959
there are three main things in beam so

00:04:12,000 --> 00:04:14,959
the first one is

00:04:15,280 --> 00:04:21,600
which allows us to create a

00:04:18,880 --> 00:04:22,000
data process pipeline and the same way

00:04:21,600 --> 00:04:23,360
for

00:04:22,000 --> 00:04:25,600
patch processing and streaming

00:04:23,360 --> 00:04:28,479
processing

00:04:25,600 --> 00:04:29,199
the second one is the sdk which allows

00:04:28,479 --> 00:04:30,720
us to write

00:04:29,199 --> 00:04:32,639
our product lines with different

00:04:30,720 --> 00:04:36,080
programming languages

00:04:32,639 --> 00:04:37,840
like uh currently supported java python

00:04:36,080 --> 00:04:40,840
and gold

00:04:37,840 --> 00:04:42,479
and this is runners this is runners

00:04:40,840 --> 00:04:45,120
actually

00:04:42,479 --> 00:04:46,800
which allows us to run our pipeline

00:04:45,120 --> 00:04:49,440
which is written in the same way

00:04:46,800 --> 00:04:50,639
on a different data processing engine

00:04:49,440 --> 00:04:54,840
like uh spar

00:04:50,639 --> 00:04:56,880
fling thunder google data flow and many

00:04:54,840 --> 00:04:59,680
others

00:04:56,880 --> 00:05:00,320
uh being program programming model it's

00:04:59,680 --> 00:05:03,199
a

00:05:00,320 --> 00:05:04,320
quite complicated thing so i will not go

00:05:03,199 --> 00:05:05,919
into details

00:05:04,320 --> 00:05:07,440
so it's not the goal of this call

00:05:05,919 --> 00:05:08,000
because we don't have too much time for

00:05:07,440 --> 00:05:11,600
that

00:05:08,000 --> 00:05:15,600
so just if in a few words uh

00:05:11,600 --> 00:05:19,199
for to be aware that it allows us to

00:05:15,600 --> 00:05:20,960
uh create like four main types of uh

00:05:19,199 --> 00:05:24,000
data processing pipelines

00:05:20,960 --> 00:05:27,120
it's classical batch when we to to

00:05:24,000 --> 00:05:30,639
have all data in the processes

00:05:27,120 --> 00:05:33,840
in the end we can also

00:05:30,639 --> 00:05:35,919
split our batch into windows and

00:05:33,840 --> 00:05:38,720
then to do some irrigation or some other

00:05:35,919 --> 00:05:41,039
operations per window

00:05:38,720 --> 00:05:42,960
also of course streaming case so in this

00:05:41,039 --> 00:05:44,880
case we still needed to

00:05:42,960 --> 00:05:46,320
have windows but we do not need to wait

00:05:44,880 --> 00:05:50,400
for complete

00:05:46,320 --> 00:05:54,160
data to arrive so in this case we we

00:05:50,400 --> 00:05:57,440
can process and might realize those

00:05:54,160 --> 00:05:59,759
results as soon as they arrive but uh

00:05:57,440 --> 00:06:00,560
we can have an issue with the late data

00:05:59,759 --> 00:06:03,520
for example

00:06:00,560 --> 00:06:04,160
install poly data we can uh lose some

00:06:03,520 --> 00:06:06,319
data

00:06:04,160 --> 00:06:08,560
so that is why i needed probably to

00:06:06,319 --> 00:06:11,440
apply a motivated

00:06:08,560 --> 00:06:14,240
uh pipeline with the streaming

00:06:11,440 --> 00:06:16,550
accumulation so in this case we

00:06:14,240 --> 00:06:18,880
process lay data then

00:06:16,550 --> 00:06:22,160
[Music]

00:06:18,880 --> 00:06:24,319
apply it to our final result so b

00:06:22,160 --> 00:06:26,560
allows us to create different type of

00:06:24,319 --> 00:06:30,160
pipelines with a minimal

00:06:26,560 --> 00:06:33,199
minimum magnification of your pipeline

00:06:30,160 --> 00:06:35,199
and finally envision is a can consider

00:06:33,199 --> 00:06:37,680
three types of users so of course the

00:06:35,199 --> 00:06:40,560
first one is end users actually who

00:06:37,680 --> 00:06:41,280
write their pipelines in different

00:06:40,560 --> 00:06:44,000
languages

00:06:41,280 --> 00:06:45,840
and you run it and sdk writer just in

00:06:44,000 --> 00:06:49,120
case if you want to add your

00:06:45,840 --> 00:06:51,599
language to them so it's uh

00:06:49,120 --> 00:06:52,960
quite easy to do you just needed to

00:06:51,599 --> 00:06:55,919
write a

00:06:52,960 --> 00:06:56,800
different sdk and uh runner or writers

00:06:55,919 --> 00:06:58,560
as well so

00:06:56,800 --> 00:07:00,319
in this case if you want to run

00:06:58,560 --> 00:07:03,759
pipelines on your

00:07:00,319 --> 00:07:06,000
supported the processing environment

00:07:03,759 --> 00:07:06,960
you just needed to write a runner and

00:07:06,000 --> 00:07:09,919
all other

00:07:06,960 --> 00:07:12,800
and that's and it will allow to run the

00:07:09,919 --> 00:07:12,800
pipeline on this

00:07:13,199 --> 00:07:17,280
uh so three main things why to to choose

00:07:16,400 --> 00:07:20,639
b

00:07:17,280 --> 00:07:21,759
the first one is it's unified so it's

00:07:20,639 --> 00:07:24,960
only one model

00:07:21,759 --> 00:07:27,840
uh model to handle batch and streaming

00:07:24,960 --> 00:07:30,080
processes and then it's portable so

00:07:27,840 --> 00:07:33,360
pipelines can be created

00:07:30,080 --> 00:07:36,560
in multiple execution environments so

00:07:33,360 --> 00:07:40,000
just uh can run your pipeline once and

00:07:36,560 --> 00:07:43,199
run it on a different processing engines

00:07:40,000 --> 00:07:44,319
and extensible so again so you can have

00:07:43,199 --> 00:07:46,560
your sdk

00:07:44,319 --> 00:07:47,599
you can add your your runner some

00:07:46,560 --> 00:07:50,319
libraries and

00:07:47,599 --> 00:07:51,840
uh your connectors as well to be kind of

00:07:50,319 --> 00:07:55,440
really possible to run

00:07:51,840 --> 00:07:59,039
on different backends

00:07:55,440 --> 00:08:00,479
uh example about how what is actually

00:07:59,039 --> 00:08:03,120
being pipeline is

00:08:00,479 --> 00:08:03,599
this is a word current example article

00:08:03,120 --> 00:08:06,160
one

00:08:03,599 --> 00:08:08,080
with java sdk and here you can see in

00:08:06,160 --> 00:08:08,800
the beginning we create our pipeline and

00:08:08,080 --> 00:08:12,720
then we have

00:08:08,800 --> 00:08:16,160
a call method call apply so it apply

00:08:12,720 --> 00:08:17,039
vb transforms uh over the collections

00:08:16,160 --> 00:08:19,199
which we have

00:08:17,039 --> 00:08:20,400
as an input and output for this method

00:08:19,199 --> 00:08:22,639
so

00:08:20,400 --> 00:08:24,960
in this case we use the text layout to

00:08:22,639 --> 00:08:28,639
read the data from a file system

00:08:24,960 --> 00:08:31,759
this is a our connector but actually

00:08:28,639 --> 00:08:33,360
then we call our written transform

00:08:31,759 --> 00:08:35,839
called count force where we actually

00:08:33,360 --> 00:08:37,279
count our words and we process this

00:08:35,839 --> 00:08:42,159
output to make it

00:08:37,279 --> 00:08:42,159
more user friendly for

00:08:43,760 --> 00:08:49,920
write this uh data issue file

00:08:46,880 --> 00:08:54,480
with the text leo into file system

00:08:49,920 --> 00:08:58,240
as well so pretty easy

00:08:54,480 --> 00:09:02,720
so it's actually cross language pipeline

00:08:58,240 --> 00:09:06,000
okay as i show

00:09:02,720 --> 00:09:06,640
it was a classical pipeline so why is it

00:09:06,000 --> 00:09:09,360
classical

00:09:06,640 --> 00:09:11,040
because it actually uses only one sdk

00:09:09,360 --> 00:09:14,560
for pipeline and runners so

00:09:11,040 --> 00:09:16,000
you are you need to run right write your

00:09:14,560 --> 00:09:18,720
pipeline

00:09:16,000 --> 00:09:19,120
with the same language as you want to

00:09:18,720 --> 00:09:22,000
use

00:09:19,120 --> 00:09:23,440
for run so for example if you write your

00:09:22,000 --> 00:09:28,800
pipeline java

00:09:23,440 --> 00:09:28,800
you should use a runner written in java

00:09:29,120 --> 00:09:34,320
and for other languages uh the same

00:09:32,160 --> 00:09:38,160
principle

00:09:34,320 --> 00:09:40,320
but supports portable pipeline uh

00:09:38,160 --> 00:09:42,880
it's quite a big feature of beam uh it

00:09:40,320 --> 00:09:45,680
has been starting to develop several

00:09:42,880 --> 00:09:47,040
years ago still under kind of

00:09:45,680 --> 00:09:50,399
development but

00:09:47,040 --> 00:09:53,760
now it's pretty stable so it's possible

00:09:50,399 --> 00:09:54,880
and uh recommended to use but what is it

00:09:53,760 --> 00:09:57,200
it allows actually

00:09:54,880 --> 00:09:59,120
to use a different sdk for pipeline and

00:09:57,200 --> 00:10:01,360
for runners so our pipeline can do it

00:09:59,120 --> 00:10:04,480
and this one sdk and our runner can

00:10:01,360 --> 00:10:06,640
we can use a different sdk

00:10:04,480 --> 00:10:08,480
very classical example is for example if

00:10:06,640 --> 00:10:11,680
you if you want to

00:10:08,480 --> 00:10:12,720
have our um written in java in this case

00:10:11,680 --> 00:10:15,600
we can

00:10:12,720 --> 00:10:18,160
it's possible to implement the pipeline

00:10:15,600 --> 00:10:18,160
in python

00:10:21,040 --> 00:10:25,279
uh and the next step uh kind of logical

00:10:24,480 --> 00:10:28,160
step from that

00:10:25,279 --> 00:10:29,519
is a portable cross language pipeline so

00:10:28,160 --> 00:10:31,680
in this case we again

00:10:29,519 --> 00:10:32,560
we can use different sdk for pipeline

00:10:31,680 --> 00:10:36,720
for runner

00:10:32,560 --> 00:10:39,279
but inside the pipeline we can

00:10:36,720 --> 00:10:40,959
write our transform in different

00:10:39,279 --> 00:10:44,160
languages

00:10:40,959 --> 00:10:45,279
so uh for example i call it like a

00:10:44,160 --> 00:10:49,120
pipeline sdk

00:10:45,279 --> 00:10:52,000
it's a main case which we used to write

00:10:49,120 --> 00:10:54,480
our pipeline and then external sdk it

00:10:52,000 --> 00:10:57,600
could be in a different language

00:10:54,480 --> 00:10:58,800
in this case it allows us to execute our

00:10:57,600 --> 00:11:00,280
code

00:10:58,800 --> 00:11:02,160
in different languages

00:11:00,280 --> 00:11:04,959
[Music]

00:11:02,160 --> 00:11:06,880
uh and for example this is a java python

00:11:04,959 --> 00:11:11,519
pipeline on spark runner

00:11:06,880 --> 00:11:14,560
uh which actually is written in java

00:11:11,519 --> 00:11:16,640
so we run our pipeline in java

00:11:14,560 --> 00:11:19,279
but we can add some transformation

00:11:16,640 --> 00:11:20,640
python then run it on a portable runner

00:11:19,279 --> 00:11:22,720
with the java api

00:11:20,640 --> 00:11:24,310
and then it will be finally we'll create

00:11:22,720 --> 00:11:25,519
a

00:11:24,310 --> 00:11:28,640
[Music]

00:11:25,519 --> 00:11:30,399
portable representation of our pipelines

00:11:28,640 --> 00:11:31,200
and it will run on a portable spark

00:11:30,399 --> 00:11:34,959
runner

00:11:31,200 --> 00:11:34,959
and finally to the runway of course

00:11:35,920 --> 00:11:44,800
so how it works the importability

00:11:40,800 --> 00:11:49,279
a few words uh that's an example for

00:11:44,800 --> 00:11:51,360
spark uh our sdk

00:11:49,279 --> 00:11:53,040
will translate our pipeline into a

00:11:51,360 --> 00:11:56,160
prototype representation via

00:11:53,040 --> 00:11:59,440
runner api so also it will upload

00:11:56,160 --> 00:12:02,800
all our dependency to just runner

00:11:59,440 --> 00:12:04,959
new artifact api and finally i

00:12:02,800 --> 00:12:05,920
will be submitted to the job server this

00:12:04,959 --> 00:12:07,839
is just a

00:12:05,920 --> 00:12:09,440
separate instance which you need to run

00:12:07,839 --> 00:12:12,639
via job api

00:12:09,440 --> 00:12:16,000
and on the job server we have a runner

00:12:12,639 --> 00:12:18,079
which will take a portable

00:12:16,000 --> 00:12:19,120
representation of our pipeline and it

00:12:18,079 --> 00:12:22,320
will be translate

00:12:19,120 --> 00:12:24,959
and run this pipeline and spark so

00:12:22,320 --> 00:12:25,360
as you can see job server is uh consists

00:12:24,959 --> 00:12:27,120
from

00:12:25,360 --> 00:12:28,880
three additional services it's called

00:12:27,120 --> 00:12:30,639
artifact staging service expansion

00:12:28,880 --> 00:12:34,000
service and job service

00:12:30,639 --> 00:12:38,000
uh i will show in the demo how to

00:12:34,000 --> 00:12:40,639
run it

00:12:38,000 --> 00:12:42,399
bits more details about how we actually

00:12:40,639 --> 00:12:46,240
run it on the job server

00:12:42,399 --> 00:12:49,760
uh so for example if you have a back end

00:12:46,240 --> 00:12:53,040
uh and of course we have a deck but for

00:12:49,760 --> 00:12:55,839
for example it will this work and

00:12:53,040 --> 00:12:57,519
when we run our pipeline there are many

00:12:55,839 --> 00:13:01,120
different stages

00:12:57,519 --> 00:13:03,839
so every transform okay just will be

00:13:01,120 --> 00:13:06,720
translated into the stage which will run

00:13:03,839 --> 00:13:09,920
as far everybody

00:13:06,720 --> 00:13:12,399
transform and uh then code

00:13:09,920 --> 00:13:14,079
this transform it will run on a it's

00:13:12,399 --> 00:13:18,320
called the sdk harness

00:13:14,079 --> 00:13:21,839
via fn apm sdk harness will be

00:13:18,320 --> 00:13:26,240
responsible to execute uh transform code

00:13:21,839 --> 00:13:26,720
so uh how to run an sdk hardness

00:13:26,240 --> 00:13:29,200
actually

00:13:26,720 --> 00:13:30,160
it could be usd implemented here in bank

00:13:29,200 --> 00:13:33,760
via docker

00:13:30,160 --> 00:13:34,560
or rear process so actually we have two

00:13:33,760 --> 00:13:37,839
main

00:13:34,560 --> 00:13:38,079
types of sdk cameras docker sdk hardness

00:13:37,839 --> 00:13:41,440
and

00:13:38,079 --> 00:13:41,440
process sdk cameras

00:13:42,639 --> 00:13:50,880
this is example with a

00:13:45,839 --> 00:13:52,959
the java python cross language pipeline

00:13:50,880 --> 00:13:55,920
additionally to run the cross language

00:13:52,959 --> 00:13:59,279
pipeline we needed to

00:13:55,920 --> 00:14:00,079
run expansion servers for external

00:13:59,279 --> 00:14:02,399
transforms

00:14:00,079 --> 00:14:03,600
in this case it will be python transform

00:14:02,399 --> 00:14:06,560
so in this case uh

00:14:03,600 --> 00:14:07,279
this service will uh actually contains

00:14:06,560 --> 00:14:11,120
all

00:14:07,279 --> 00:14:15,440
uh code of our external transforms

00:14:11,120 --> 00:14:17,279
for python and sdk

00:14:15,440 --> 00:14:18,720
get all this information from expansion

00:14:17,279 --> 00:14:21,199
service

00:14:18,720 --> 00:14:22,639
code to execute some information about

00:14:21,199 --> 00:14:25,199
coders and so on

00:14:22,639 --> 00:14:27,120
uh to edit into our portable

00:14:25,199 --> 00:14:29,519
representation of our pipeline and then

00:14:27,120 --> 00:14:31,199
send it to job server

00:14:29,519 --> 00:14:33,839
and finally as you can see on the back

00:14:31,199 --> 00:14:37,199
end when we will execute our stages

00:14:33,839 --> 00:14:39,839
uh for every sdk it will run

00:14:37,199 --> 00:14:40,320
different sdk hardwares for java sdk it

00:14:39,839 --> 00:14:41,760
will be

00:14:40,320 --> 00:14:45,839
of course javascript corners for

00:14:41,760 --> 00:14:45,839
pyramind will be private

00:14:46,880 --> 00:14:53,120
so some advantages of portable runner

00:14:50,880 --> 00:14:54,880
of course it's io connectors that could

00:14:53,120 --> 00:14:55,839
be shared across different sdts for

00:14:54,880 --> 00:14:58,079
example

00:14:55,839 --> 00:14:58,959
we have a glass connectors written in

00:14:58,079 --> 00:15:01,440
java

00:14:58,959 --> 00:15:02,639
so when with the portable runner they

00:15:01,440 --> 00:15:06,320
will be accessible

00:15:02,639 --> 00:15:09,600
uh for python sdk as well

00:15:06,320 --> 00:15:12,399
same time java sdk can utilize transform

00:15:09,600 --> 00:15:14,720
libraries available only for python goal

00:15:12,399 --> 00:15:18,480
like uh

00:15:14,720 --> 00:15:22,959
pubs and so on uh and the

00:15:18,480 --> 00:15:26,000
java python goes dk you can use uh

00:15:22,959 --> 00:15:28,240
z transforms uh and so in this

00:15:26,000 --> 00:15:29,199
case we we have a cross language

00:15:28,240 --> 00:15:31,199
pipeline

00:15:29,199 --> 00:15:32,240
view sql currently is available only for

00:15:31,199 --> 00:15:34,399
java sdk but

00:15:32,240 --> 00:15:35,519
uh it is a portable runner it can be

00:15:34,399 --> 00:15:38,639
available uh

00:15:35,519 --> 00:15:38,639
by on python

00:15:38,880 --> 00:15:42,079
the beam uh tensorflow transforms that

00:15:41,440 --> 00:15:45,120
currently

00:15:42,079 --> 00:15:45,440
on the python sdk then we can utilize

00:15:45,120 --> 00:15:49,040
them

00:15:45,440 --> 00:15:52,560
in java sdk so in this case

00:15:49,040 --> 00:15:53,040
actually it makes beam really portable

00:15:52,560 --> 00:15:56,160
and

00:15:53,040 --> 00:16:00,399
possible to use to mix different

00:15:56,160 --> 00:16:00,399
libraries in the same pipeline

00:16:01,040 --> 00:16:06,320
some potential difficulties which we we

00:16:03,839 --> 00:16:08,720
can fix as a portable runner so

00:16:06,320 --> 00:16:10,160
first of all as i said that's uh

00:16:08,720 --> 00:16:13,759
portability is still

00:16:10,160 --> 00:16:16,000
kind of working progress uh

00:16:13,759 --> 00:16:18,160
it's but it's under active development

00:16:16,000 --> 00:16:19,199
so some kind of epa changes can be

00:16:18,160 --> 00:16:22,240
expected from

00:16:19,199 --> 00:16:25,040
released release uh

00:16:22,240 --> 00:16:25,040
it supports

00:16:26,079 --> 00:16:28,399
sorry

00:16:35,279 --> 00:16:37,839
uh

00:16:38,560 --> 00:16:43,600
uh we kind of it depends on your

00:16:41,440 --> 00:16:46,639
deployment modes

00:16:43,600 --> 00:16:47,360
not sometimes everything works depending

00:16:46,639 --> 00:16:51,600
on your

00:16:47,360 --> 00:16:54,160
mod like locally on cloud or kubernetes

00:16:51,600 --> 00:16:56,480
so potentially it will uh require

00:16:54,160 --> 00:16:58,560
additional configuration for that

00:16:56,480 --> 00:16:59,759
of course it will also require

00:16:58,560 --> 00:17:02,320
application

00:16:59,759 --> 00:17:02,800
changes in your application architecture

00:17:02,320 --> 00:17:05,839
and

00:17:02,800 --> 00:17:06,880
it will impact your the performance of

00:17:05,839 --> 00:17:09,039
your pipeline

00:17:06,880 --> 00:17:10,000
i i will talk about that in the end of

00:17:09,039 --> 00:17:13,280
the presentation

00:17:10,000 --> 00:17:17,039
and we will talk about uh benchmarks

00:17:13,280 --> 00:17:20,559
so how there to run percentage my plan

00:17:17,039 --> 00:17:23,280
okay just to show that uh

00:17:20,559 --> 00:17:24,559
i created an example like how to

00:17:23,280 --> 00:17:26,559
integrate python suite

00:17:24,559 --> 00:17:27,760
transform into your apache beam java

00:17:26,559 --> 00:17:30,720
pipeline

00:17:27,760 --> 00:17:32,000
so this pipeline is pretty simple it

00:17:30,720 --> 00:17:35,600
uses kind of machine learning

00:17:32,000 --> 00:17:38,480
training model to classify genres of

00:17:35,600 --> 00:17:40,320
different movies and of course it will

00:17:38,480 --> 00:17:43,200
since this first language backline

00:17:40,320 --> 00:17:47,360
it will use the expansion service to

00:17:43,200 --> 00:17:49,919
make it possible okay first of all

00:17:47,360 --> 00:17:50,960
uh since our kind of main sdk for

00:17:49,919 --> 00:17:54,160
planner java

00:17:50,960 --> 00:17:54,559
we we create a java outline and that

00:17:54,160 --> 00:17:57,520
will

00:17:54,559 --> 00:17:58,000
integrate the java transform to read it

00:17:57,520 --> 00:18:01,360
to

00:17:58,000 --> 00:18:02,000
write data but it also will uh transform

00:18:01,360 --> 00:18:04,960
it's called the

00:18:02,000 --> 00:18:07,600
genre classifier which will be

00:18:04,960 --> 00:18:09,440
irresponsible actually to

00:18:07,600 --> 00:18:12,000
collaborate classifier which is written

00:18:09,440 --> 00:18:15,120
in pipeline

00:18:12,000 --> 00:18:18,559
so this is this transform

00:18:15,120 --> 00:18:21,120
uh as you can see uh it will apply

00:18:18,559 --> 00:18:22,559
our external external it's called

00:18:21,120 --> 00:18:25,760
external transform

00:18:22,559 --> 00:18:28,799
which actually will we needed to pass

00:18:25,760 --> 00:18:32,160
three different arguments like ram

00:18:28,799 --> 00:18:32,799
uh some payload which actually now it's

00:18:32,160 --> 00:18:36,160
a

00:18:32,799 --> 00:18:39,360
just a byte array and the url

00:18:36,160 --> 00:18:42,400
uh hosting port to our expansion service

00:18:39,360 --> 00:18:44,480
for this term

00:18:42,400 --> 00:18:46,240
urine is very important because uh it

00:18:44,480 --> 00:18:49,600
should be the same as

00:18:46,240 --> 00:18:52,880
the and for

00:18:49,600 --> 00:18:55,039
our external transfer for our extension

00:18:52,880 --> 00:18:58,240
servers

00:18:55,039 --> 00:18:58,960
as now we needed to create our python

00:18:58,240 --> 00:19:02,960
transform

00:18:58,960 --> 00:19:06,400
that actually will implement expand

00:19:02,960 --> 00:19:08,720
uh where we will call a classical

00:19:06,400 --> 00:19:10,000
event which actually will uh contains

00:19:08,720 --> 00:19:12,960
all our business logic

00:19:10,000 --> 00:19:14,160
but importance here and i think here

00:19:12,960 --> 00:19:18,320
sees that

00:19:14,160 --> 00:19:21,039
this transform should get it with a

00:19:18,320 --> 00:19:25,360
with their same url as we used on the

00:19:21,039 --> 00:19:27,280
previous step

00:19:25,360 --> 00:19:29,520
and finally as we did implement in

00:19:27,280 --> 00:19:32,160
python i would do them

00:19:29,520 --> 00:19:33,840
actually we'll be very responsible to do

00:19:32,160 --> 00:19:36,840
all this classification via

00:19:33,840 --> 00:19:39,840
libraries or we have our own code and so

00:19:36,840 --> 00:19:39,840
on

00:19:40,559 --> 00:19:46,799
uh finally finally to

00:19:44,480 --> 00:19:48,480
we need to to add this transform to

00:19:46,799 --> 00:19:51,919
python extension service

00:19:48,480 --> 00:19:52,480
uh which actually just the server jpc

00:19:51,919 --> 00:19:55,520
server

00:19:52,480 --> 00:19:59,039
which we run and it provided some

00:19:55,520 --> 00:20:00,160
additional arguments to like specify

00:19:59,039 --> 00:20:04,080
which type of

00:20:00,160 --> 00:20:07,840
sdk is the key hardware you want to use

00:20:04,080 --> 00:20:07,840
and so on

00:20:08,159 --> 00:20:13,919
how to run it uh first of all we needed

00:20:10,640 --> 00:20:13,919
to run a job service

00:20:15,280 --> 00:20:19,440
for spark runner we can do it in two

00:20:18,480 --> 00:20:22,799
different ways

00:20:19,440 --> 00:20:26,480
first of all we can run just a docker

00:20:22,799 --> 00:20:30,720
container it's already in a docker

00:20:26,480 --> 00:20:35,440
repository so just just uh

00:20:30,720 --> 00:20:37,200
run as usual in this docker ram or

00:20:35,440 --> 00:20:39,120
we can run it in from a beam source code

00:20:37,200 --> 00:20:43,360
so you needed to

00:20:39,120 --> 00:20:47,039
download the source code and run this

00:20:43,360 --> 00:20:51,440
with this gradle command for

00:20:47,039 --> 00:20:51,440
the example for spark job server

00:20:51,679 --> 00:20:56,960
uh i will show it in there uh next step

00:20:55,360 --> 00:20:59,039
i need to run an additional expression

00:20:56,960 --> 00:21:01,039
service for our license transformers

00:20:59,039 --> 00:21:02,080
so first of all we needed to set up our

00:21:01,039 --> 00:21:04,799
python

00:21:02,080 --> 00:21:05,520
environment and following just this

00:21:04,799 --> 00:21:08,240
guide

00:21:05,520 --> 00:21:09,360
on again apache oxide and finally we

00:21:08,240 --> 00:21:12,480
just run it

00:21:09,360 --> 00:21:14,159
this uh as usual and provide some

00:21:12,480 --> 00:21:17,280
arguments in this case it will be just

00:21:14,159 --> 00:21:21,520
expansion of export and

00:21:17,280 --> 00:21:25,039
the first step here we run our pipeline

00:21:21,520 --> 00:21:27,280
now case in my case just a magnum

00:21:25,039 --> 00:21:29,520
with mine so we use the marvin exact you

00:21:27,280 --> 00:21:31,840
run our pipeline

00:21:29,520 --> 00:21:34,400
where did you provide some arguments as

00:21:31,840 --> 00:21:36,159
you can see we used the portable runner

00:21:34,400 --> 00:21:38,640
and we needed to provide arguments for

00:21:36,159 --> 00:21:40,640
our service endpoint

00:21:38,640 --> 00:21:42,880
first import and for our expansion

00:21:40,640 --> 00:21:46,240
service

00:21:42,880 --> 00:21:46,240
so quick demo

00:21:47,679 --> 00:21:49,919
okay

00:21:54,240 --> 00:21:57,919
okay so uh

00:22:07,600 --> 00:22:16,240
yes i hope it's better to swatch uh

00:22:13,039 --> 00:22:17,280
this is a quote of our pipeline as i

00:22:16,240 --> 00:22:22,000
showed you before

00:22:17,280 --> 00:22:25,280
just uh more details on this

00:22:22,000 --> 00:22:28,400
also down to creating a pipeline

00:22:25,280 --> 00:22:30,720
so here we create a white line

00:22:28,400 --> 00:22:32,159
then we as an input we create just a

00:22:30,720 --> 00:22:35,120
very test

00:22:32,159 --> 00:22:36,480
data set of course it could be data from

00:22:35,120 --> 00:22:39,600
any other

00:22:36,480 --> 00:22:42,559
sources but i created just

00:22:39,600 --> 00:22:42,559
very small data set

00:22:43,520 --> 00:22:50,320
with different movies then

00:22:47,440 --> 00:22:51,120
on this collection of these movies i

00:22:50,320 --> 00:22:54,880
will apply

00:22:51,120 --> 00:22:57,919
our transforms for the genre classifier

00:22:54,880 --> 00:22:58,720
and finally i will output results with

00:22:57,919 --> 00:23:01,919
the

00:22:58,720 --> 00:23:07,039
printfn transformers

00:23:01,919 --> 00:23:07,039
will just output the system output

00:23:07,360 --> 00:23:09,840
data

00:23:10,960 --> 00:23:18,240
okay so what does it actually actually

00:23:15,039 --> 00:23:21,280
require uh transport

00:23:18,240 --> 00:23:24,880
as you can see we use a uam

00:23:21,280 --> 00:23:27,840
what's that uh the inside

00:23:24,880 --> 00:23:29,360
expand methods where we spend our

00:23:27,840 --> 00:23:32,240
transform

00:23:29,360 --> 00:23:32,960
in case of using the external uh

00:23:32,240 --> 00:23:37,520
transfer

00:23:32,960 --> 00:23:40,640
in our case we call external transform

00:23:37,520 --> 00:23:43,679
it has the crm payload

00:23:40,640 --> 00:23:46,960
which currently is empty by tray and the

00:23:43,679 --> 00:23:50,799
url from which to take from options

00:23:46,960 --> 00:23:54,559
to expansion service

00:23:50,799 --> 00:23:57,840
and finally our expansion service

00:23:54,559 --> 00:23:59,840
file written in python contains this

00:23:57,840 --> 00:24:01,840
transform

00:23:59,840 --> 00:24:04,960
with the same url which we provided in

00:24:01,840 --> 00:24:07,679
our previous step and

00:24:04,960 --> 00:24:08,240
this implementation of our family is

00:24:07,679 --> 00:24:10,240
like

00:24:08,240 --> 00:24:11,679
it should be classified but of course

00:24:10,240 --> 00:24:16,159
it's a very simple one

00:24:11,679 --> 00:24:16,159
just for sake of tests

00:24:16,559 --> 00:24:23,760
which we kind of specify our enemies

00:24:20,480 --> 00:24:27,760
so and in the main

00:24:23,760 --> 00:24:31,039
methods we run our server

00:24:27,760 --> 00:24:33,279
for different type of sdt cameras

00:24:31,039 --> 00:24:34,320
in my case i used rocket ready for car

00:24:33,279 --> 00:24:36,240
harness

00:24:34,320 --> 00:24:38,159
but in case of using processes etk

00:24:36,240 --> 00:24:39,600
finals it's kind of the same but we need

00:24:38,159 --> 00:24:42,880
just to provide a different

00:24:39,600 --> 00:24:44,559
pipeline for that

00:24:42,880 --> 00:24:46,080
environment type and we're in conflict

00:24:44,559 --> 00:24:49,679
which actually want to

00:24:46,080 --> 00:24:52,080
i will go with the others and some other

00:24:49,679 --> 00:24:52,080
options

00:24:52,640 --> 00:25:01,840
okay so now

00:24:55,760 --> 00:25:01,840
i will try to

00:25:03,360 --> 00:25:15,840
okay first of all we needed to run a

00:25:06,720 --> 00:25:15,840
job service i do it from ibm

00:25:18,640 --> 00:25:22,880
okay it's running as you can see

00:25:20,400 --> 00:25:26,480
actually it launched three different

00:25:22,880 --> 00:25:29,520
services activate staging service

00:25:26,480 --> 00:25:32,640
java expansion service and job service

00:25:29,520 --> 00:25:36,159
for three different ports

00:25:32,640 --> 00:25:37,919
uh we need to run expansion service for

00:25:36,159 --> 00:25:43,840
our python

00:25:37,919 --> 00:25:43,840
transform we do it in the separate tab

00:25:44,080 --> 00:25:51,440
so it runs to different ports

00:25:47,760 --> 00:25:55,039
and finally i'm going to

00:25:51,440 --> 00:25:58,320
run my classification pipeline

00:25:55,039 --> 00:26:02,159
the arguments and i

00:25:58,320 --> 00:26:04,960
which actually specify the job endpoint

00:26:02,159 --> 00:26:07,679
and extension service for python

00:26:04,960 --> 00:26:07,679
transforms

00:26:08,480 --> 00:26:11,840
so i run it

00:26:11,919 --> 00:26:26,960
and we will see if it works

00:26:24,080 --> 00:26:27,520
actually it used gives a rain point and

00:26:26,960 --> 00:26:31,279
finally

00:26:27,520 --> 00:26:34,400
it sends our job to job service

00:26:31,279 --> 00:26:37,840
there are some messages and

00:26:34,400 --> 00:26:41,600
finally if you want a job i'm usually

00:26:37,840 --> 00:26:44,480
not going to stop start running

00:26:41,600 --> 00:26:44,480
and also of course

00:26:47,120 --> 00:26:50,720
so then i will uh run the sdp corners

00:26:50,240 --> 00:26:53,360
for

00:26:50,720 --> 00:26:53,360
javika

00:27:04,960 --> 00:27:09,360
a vitamin d programs

00:27:19,520 --> 00:27:26,399
and actually that's it as you can see

00:27:22,799 --> 00:27:29,919
the output we have our

00:27:26,399 --> 00:27:32,799
data which actually was a generated

00:27:29,919 --> 00:27:34,559
in python but finally we outputted it

00:27:32,799 --> 00:27:38,320
from java

00:27:34,559 --> 00:27:43,679
so first time which pipeline works

00:27:38,320 --> 00:27:43,679
cool okay back to

00:27:46,840 --> 00:27:49,840
presentation

00:27:51,360 --> 00:27:58,159
uh our use case and some benchmark

00:27:55,200 --> 00:27:58,799
so in thailand actually we have a

00:27:58,159 --> 00:28:01,039
product

00:27:58,799 --> 00:28:03,360
called the pipeline designer which

00:28:01,039 --> 00:28:07,279
allows the user to design a

00:28:03,360 --> 00:28:10,399
data processing pipeline in a

00:28:07,279 --> 00:28:13,679
graphical mode so

00:28:10,399 --> 00:28:16,790
and one of the actually source

00:28:13,679 --> 00:28:19,440
sync different components to

00:28:16,790 --> 00:28:22,399
[Music]

00:28:19,440 --> 00:28:23,440
do to process your your data and one is

00:28:22,399 --> 00:28:25,600
this component

00:28:23,440 --> 00:28:25,600
uh

00:28:26,480 --> 00:28:30,399
allows user to write its own pattern

00:28:28,880 --> 00:28:34,320
code

00:28:30,399 --> 00:28:39,520
you do that under the hood this product

00:28:34,320 --> 00:28:41,840
uses apache beam and so

00:28:39,520 --> 00:28:43,520
initially what's the problem with it why

00:28:41,840 --> 00:28:46,960
are python sweep

00:28:43,520 --> 00:28:50,960
because python 2.7 was a

00:28:46,960 --> 00:28:54,480
reached support in the end of last year

00:28:50,960 --> 00:28:58,520
but at that time

00:28:54,480 --> 00:29:01,679
our product is supported on the python

00:28:58,520 --> 00:29:03,919
2.7 with a j 10.

00:29:01,679 --> 00:29:05,600
so our component actually was written

00:29:03,919 --> 00:29:09,200
with data

00:29:05,600 --> 00:29:12,559
but unfortunately pi items v is not

00:29:09,200 --> 00:29:14,320
supported by jaden for the moment so

00:29:12,559 --> 00:29:16,799
there are several options actually how

00:29:14,320 --> 00:29:20,640
to run a python 3 from

00:29:16,799 --> 00:29:22,880
java pipeline uh and one of the approach

00:29:20,640 --> 00:29:23,679
was like uh to do it with the beam cross

00:29:22,880 --> 00:29:26,320
language

00:29:23,679 --> 00:29:27,919
transform i showed you before on an

00:29:26,320 --> 00:29:32,000
importable run

00:29:27,919 --> 00:29:32,720
so we did the pvc for that and run some

00:29:32,000 --> 00:29:36,240
benchmark

00:29:32,720 --> 00:29:36,240
to see the different numbers

00:29:36,320 --> 00:29:41,840
and uh

00:29:43,279 --> 00:29:48,799
so uh what actually do you see what

00:29:46,559 --> 00:29:50,080
well it's like a very simple pipeline

00:29:48,799 --> 00:29:55,760
with the sourcing and

00:29:50,080 --> 00:29:58,880
processor uh sourcing uh based company

00:29:55,760 --> 00:30:01,279
uh i did the

00:29:58,880 --> 00:30:02,159
benchmark for different types of uh

00:30:01,279 --> 00:30:04,799
source

00:30:02,159 --> 00:30:05,600
as uh as it was in memory based or file

00:30:04,799 --> 00:30:08,000
based

00:30:05,600 --> 00:30:09,600
for something just for small data sets

00:30:08,000 --> 00:30:13,039
and the file based for

00:30:09,600 --> 00:30:13,440
large datasets processes and processors

00:30:13,039 --> 00:30:15,600
sorry

00:30:13,440 --> 00:30:17,919
it was either java or python based

00:30:15,600 --> 00:30:20,000
component so just to see

00:30:17,919 --> 00:30:22,640
the difference between pure java white

00:30:20,000 --> 00:30:25,120
line and cross language pipeline

00:30:22,640 --> 00:30:26,799
uh so this component was pretty easy one

00:30:25,120 --> 00:30:28,880
like it takes into record from

00:30:26,799 --> 00:30:30,960
source i do some symbols through my

00:30:28,880 --> 00:30:34,880
identification like to uppercase and

00:30:30,960 --> 00:30:34,880
then send this vapor to output

00:30:35,760 --> 00:30:42,240
two modes of this benchmark that's uh

00:30:39,120 --> 00:30:43,279
with the very small input data sets and

00:30:42,240 --> 00:30:46,399
the

00:30:43,279 --> 00:30:48,880
live input data sets for a small one

00:30:46,399 --> 00:30:50,080
the goal was to compare beam portability

00:30:48,880 --> 00:30:52,559
overhead

00:30:50,080 --> 00:30:54,320
for spark runner because we tested for

00:30:52,559 --> 00:30:57,679
spark running

00:30:54,320 --> 00:30:59,360
and for real life input data sets the

00:30:57,679 --> 00:31:01,919
goal was likely to compare

00:30:59,360 --> 00:31:05,679
real pipelines different runners

00:31:01,919 --> 00:31:08,960
portable runner and spark runner

00:31:05,679 --> 00:31:10,399
and i did this benchmark on my local

00:31:08,960 --> 00:31:13,919
machine

00:31:10,399 --> 00:31:18,720
so with the spark master

00:31:13,919 --> 00:31:21,039
equal vocal four

00:31:18,720 --> 00:31:21,840
and the two types actually of uh

00:31:21,039 --> 00:31:24,880
pipelines

00:31:21,840 --> 00:31:28,480
is that i did first uh it's the

00:31:24,880 --> 00:31:30,320
pure java pipeline and then uh

00:31:28,480 --> 00:31:32,000
cross language pipeline again just to

00:31:30,320 --> 00:31:35,760
compare with the difference

00:31:32,000 --> 00:31:38,240
how external transformer will affect the

00:31:35,760 --> 00:31:38,240
performance

00:31:40,399 --> 00:31:46,640
so some numbers for

00:31:43,519 --> 00:31:48,000
a tv input data set it's like a tens of

00:31:46,640 --> 00:31:51,440
records

00:31:48,000 --> 00:31:52,320
uh i did it for portable from the user

00:31:51,440 --> 00:31:54,240
docker

00:31:52,320 --> 00:31:56,240
harness for portable runner with the

00:31:54,240 --> 00:32:00,880
process sdk harness

00:31:56,240 --> 00:32:04,880
for your classical spark planner

00:32:00,880 --> 00:32:04,880
as you can see on shows

00:32:05,039 --> 00:32:11,200
left and right we see that quite

00:32:08,320 --> 00:32:12,159
a big difference actually several times

00:32:11,200 --> 00:32:14,720
for

00:32:12,159 --> 00:32:15,440
between portable runner and spark run so

00:32:14,720 --> 00:32:19,200
it shows

00:32:15,440 --> 00:32:22,320
the overhead of the portability for

00:32:19,200 --> 00:32:23,200
if we don't take into account the time

00:32:22,320 --> 00:32:27,120
which we

00:32:23,200 --> 00:32:27,120
spent for data processing

00:32:27,519 --> 00:32:36,159
this is what i call portability overhead

00:32:31,120 --> 00:32:38,159
uh at the same time uh benchmark results

00:32:36,159 --> 00:32:39,600
for real input dataset was a bit

00:32:38,159 --> 00:32:42,799
different

00:32:39,600 --> 00:32:44,880
for only java sdk pipeline uh

00:32:42,799 --> 00:32:46,480
what i did again i ran it with a

00:32:44,880 --> 00:32:48,399
portable roundabout but only

00:32:46,480 --> 00:32:50,320
the process is the key here because it

00:32:48,399 --> 00:32:53,919
was fast faster than

00:32:50,320 --> 00:32:54,399
the quality harness and uh against spark

00:32:53,919 --> 00:32:56,720
runner

00:32:54,399 --> 00:32:58,559
i increased number of records like uh

00:32:56,720 --> 00:33:01,440
starting from 10 records and then

00:32:58,559 --> 00:33:02,880
i ended up with a 500 thousand of

00:33:01,440 --> 00:33:06,480
records

00:33:02,880 --> 00:33:10,000
and as you can see on the

00:33:06,480 --> 00:33:12,159
right chart the difference is getting

00:33:10,000 --> 00:33:13,760
lower and lower noticeable once we

00:33:12,159 --> 00:33:16,000
increase number of

00:33:13,760 --> 00:33:16,000
input

00:33:17,679 --> 00:33:21,679
and the same test benchmark id for first

00:33:20,799 --> 00:33:25,039
language pipeline

00:33:21,679 --> 00:33:29,279
is java python so

00:33:25,039 --> 00:33:32,320
again the same number of input records

00:33:29,279 --> 00:33:32,720
and here you can see the same picture

00:33:32,320 --> 00:33:36,240
but

00:33:32,720 --> 00:33:37,519
in the end we even see that portable

00:33:36,240 --> 00:33:40,320
runner was faster with

00:33:37,519 --> 00:33:41,120
just pushpark runner well it's kind of

00:33:40,320 --> 00:33:43,919
unexpected

00:33:41,120 --> 00:33:45,600
but the main reason is main kind of

00:33:43,919 --> 00:33:48,000
conclusion for that

00:33:45,600 --> 00:33:50,720
this is difference kind of getting less

00:33:48,000 --> 00:33:54,880
and less noticeable and finally

00:33:50,720 --> 00:33:57,360
for data sets the performance

00:33:54,880 --> 00:33:59,679
between portable runner and portable

00:33:57,360 --> 00:34:04,559
spark runner and classical spark runner

00:33:59,679 --> 00:34:06,399
is kind of safe so some conclusions

00:34:04,559 --> 00:34:08,000
well as i mentioned before of course

00:34:06,399 --> 00:34:11,040
portable runner will add

00:34:08,000 --> 00:34:13,520
some overhead to the right in time

00:34:11,040 --> 00:34:14,159
uh mainly because we need we spend some

00:34:13,520 --> 00:34:16,720
time to run

00:34:14,159 --> 00:34:17,599
sdt hardware stock your process for ios

00:34:16,720 --> 00:34:20,720
log stage

00:34:17,599 --> 00:34:23,679
so if you have a small data it will

00:34:20,720 --> 00:34:23,679
be quite noticeable

00:34:23,760 --> 00:34:28,720
uh processor key hardness is faster than

00:34:26,760 --> 00:34:29,520
documents but of course it's still

00:34:28,720 --> 00:34:33,679
slower than

00:34:29,520 --> 00:34:37,280
just a pure spark runner in most cases

00:34:33,679 --> 00:34:39,919
uh when we with increasing of input data

00:34:37,280 --> 00:34:41,119
this difference is getting less and less

00:34:39,919 --> 00:34:44,159
noticeable

00:34:41,119 --> 00:34:46,879
so uh for

00:34:44,159 --> 00:34:49,839
kind of real-life input of data uh it

00:34:46,879 --> 00:34:49,839
should not be a problem

00:34:50,399 --> 00:34:56,720
uh so some helpful links uh

00:34:54,320 --> 00:34:58,320
which you probably just linked to apache

00:34:56,720 --> 00:35:00,880
team and

00:34:58,320 --> 00:35:01,760
all the examples which i showed you

00:35:00,880 --> 00:35:06,240
today

00:35:01,760 --> 00:35:06,240
i put on youtube repository

00:35:06,560 --> 00:35:08,800
and

00:35:09,599 --> 00:35:16,160
if you interested in this

00:35:12,720 --> 00:35:18,960
portable spark runner

00:35:16,160 --> 00:35:22,560
you to watch this talk from last apache

00:35:18,960 --> 00:35:22,560
con from ismail and kyle

00:35:22,640 --> 00:35:26,640
they will give you more details about

00:35:24,320 --> 00:35:29,680
actually how portable spark runner

00:35:26,640 --> 00:35:32,880
works uh

00:35:29,680 --> 00:35:36,240
thank you very much feel free to ping me

00:35:32,880 --> 00:35:45,839
on email on twitter

00:35:36,240 --> 00:35:45,839
thank you

00:35:47,119 --> 00:35:50,720
feel free to ask me questions if you

00:35:56,839 --> 00:35:59,839
want

00:36:07,760 --> 00:36:15,119
okay so here for no questions

00:36:11,680 --> 00:36:18,079
again don't hesitate to reach me

00:36:15,119 --> 00:36:18,960
here on the mail and we'll call this

00:36:18,079 --> 00:36:27,839
session

00:36:18,960 --> 00:36:27,839
finished thank you everybody bye

00:36:47,200 --> 00:36:49,280

YouTube URL: https://www.youtube.com/watch?v=uGE2i_MNL3c


