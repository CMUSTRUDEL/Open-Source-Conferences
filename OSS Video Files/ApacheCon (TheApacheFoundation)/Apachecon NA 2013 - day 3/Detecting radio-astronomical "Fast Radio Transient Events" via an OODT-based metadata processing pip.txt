Title: Detecting radio-astronomical "Fast Radio Transient Events" via an OODT-based metadata processing pip
Publication date: 2013-10-18
Playlist: Apachecon NA 2013 - day 3
Description: 
	Luca Cinquini
ApacheCon NA 2013
Apache in Science
Captions: 
	00:00:00,000 --> 00:00:04,799
um okay so this talk really I'm just

00:00:03,000 --> 00:00:07,109
going to give some the background on

00:00:04,799 --> 00:00:09,960
this talk this this is about detecting

00:00:07,109 --> 00:00:11,940
just verbiage purposes rayo sort of fast

00:00:09,960 --> 00:00:15,030
transient events like pulsars and and

00:00:11,940 --> 00:00:16,890
other interesting detections using ODT

00:00:15,030 --> 00:00:19,770
as sort of a metadata based pipeline

00:00:16,890 --> 00:00:21,270
processing pipeline and so myself in her

00:00:19,770 --> 00:00:23,490
heart blue kitchen Queenie David

00:00:21,270 --> 00:00:26,550
Thompson Kerry wagstaff and shiki could

00:00:23,490 --> 00:00:30,000
you can is the people who did this so

00:00:26,550 --> 00:00:32,340
the impetus for this was initiative that

00:00:30,000 --> 00:00:34,440
we had at JPL for cuz well three years

00:00:32,340 --> 00:00:37,829
really an internal strategic aren't ed

00:00:34,440 --> 00:00:39,350
initiative basically making JPL sort of

00:00:37,829 --> 00:00:42,059
pay attention and be more competitive

00:00:39,350 --> 00:00:43,800
with the next generation radio erase why

00:00:42,059 --> 00:00:46,620
does anyone care about radio astronomy

00:00:43,800 --> 00:00:48,450
or astronomy in general most if you look

00:00:46,620 --> 00:00:49,320
at what the types of challenges that

00:00:48,450 --> 00:00:51,030
they're going to have to face with

00:00:49,320 --> 00:00:53,370
respect to Big Data over the next decade

00:00:51,030 --> 00:00:56,309
they're really pushing the boundaries in

00:00:53,370 --> 00:00:58,829
many ways for what we're going to have

00:00:56,309 --> 00:01:00,359
to deal with i mean the sk is a classic

00:00:58,829 --> 00:01:02,370
example you know with numbers

00:01:00,359 --> 00:01:04,409
potentially at the level of 700

00:01:02,370 --> 00:01:06,150
terabytes of data per second you know

00:01:04,409 --> 00:01:07,799
and having to come up with ways to do

00:01:06,150 --> 00:01:09,210
things like intelligent triage and stuff

00:01:07,799 --> 00:01:10,890
like that but even today with

00:01:09,210 --> 00:01:12,390
instruments in europe like low far the

00:01:10,890 --> 00:01:14,939
low frequency array which is generating

00:01:12,390 --> 00:01:15,930
138 terabytes of data per day that

00:01:14,939 --> 00:01:17,790
they're keeping a lot of it around

00:01:15,930 --> 00:01:19,920
because astronomers have realized as

00:01:17,790 --> 00:01:21,750
opposed to their philosophy before that

00:01:19,920 --> 00:01:23,759
this guy was the archive and if you

00:01:21,750 --> 00:01:25,409
missed it you could kind of always go

00:01:23,759 --> 00:01:26,729
reimage it you know the next time you

00:01:25,409 --> 00:01:28,680
were there because with these fast

00:01:26,729 --> 00:01:30,479
transient events and with time domain

00:01:28,680 --> 00:01:32,369
astronomy people are realizing the time

00:01:30,479 --> 00:01:34,170
does matter within that domain and you

00:01:32,369 --> 00:01:36,479
have to pay attention to that so the

00:01:34,170 --> 00:01:38,880
goal the leaders of the radio array

00:01:36,479 --> 00:01:41,100
initiative were a Bob Preston who's our

00:01:38,880 --> 00:01:42,720
chief technologist for interplanetary

00:01:41,100 --> 00:01:44,399
Network Directorate I'm sorry chief

00:01:42,720 --> 00:01:45,600
scientist and then Dayton Jones was the

00:01:44,399 --> 00:01:48,270
initiative lead for that and it was to

00:01:45,600 --> 00:01:49,920
basically make JPL and our projects more

00:01:48,270 --> 00:01:51,960
competitive for these next generation

00:01:49,920 --> 00:01:53,970
radio astronomical instruments because

00:01:51,960 --> 00:01:56,369
we felt that they were going to be very

00:01:53,970 --> 00:01:59,579
important to us and so it was like three

00:01:56,369 --> 00:02:01,229
thrusts defined in the three thrusts to

00:01:59,579 --> 00:02:03,899
find as part of the initiative one of

00:02:01,229 --> 00:02:06,090
them initially was data mining and

00:02:03,899 --> 00:02:08,310
intelligent triage algorithms another

00:02:06,090 --> 00:02:09,369
one was on low power hardware because as

00:02:08,310 --> 00:02:11,379
it turned out

00:02:09,369 --> 00:02:13,569
in certain situations if we can improve

00:02:11,379 --> 00:02:14,890
on the power of the hardware we can save

00:02:13,569 --> 00:02:16,739
on the order of tens of millions of

00:02:14,890 --> 00:02:19,420
dollars per month because many of these

00:02:16,739 --> 00:02:20,920
these next generation radio astronomy

00:02:19,420 --> 00:02:23,019
instruments or astronomy instruments

00:02:20,920 --> 00:02:24,549
have power drawers that are that high

00:02:23,019 --> 00:02:26,110
because they're generating that much

00:02:24,549 --> 00:02:27,909
data and someone's got to pay for the

00:02:26,110 --> 00:02:29,379
power and a lot of these are in

00:02:27,909 --> 00:02:30,549
developing countries and things like

00:02:29,379 --> 00:02:31,690
them they don't have the money to do

00:02:30,549 --> 00:02:33,430
that and so if you can design

00:02:31,690 --> 00:02:35,230
intelligent hardware and instruments

00:02:33,430 --> 00:02:37,030
that are low voltage and for certain

00:02:35,230 --> 00:02:38,409
scenarios and certain operations you can

00:02:37,030 --> 00:02:40,450
save 10 million dollars a month and

00:02:38,409 --> 00:02:41,950
that's important to people so it started

00:02:40,450 --> 00:02:44,049
out as those and then we were kind of

00:02:41,950 --> 00:02:45,879
hired on later on to do data archiving

00:02:44,049 --> 00:02:47,920
realizing that archiving was an

00:02:45,879 --> 00:02:49,989
important part of understanding you know

00:02:47,920 --> 00:02:52,120
these these these next-generation

00:02:49,989 --> 00:02:53,680
instruments so these were the different

00:02:52,120 --> 00:02:55,569
areas I kind of talked about some of

00:02:53,680 --> 00:02:58,450
them that the radio array initiative was

00:02:55,569 --> 00:03:01,420
kind of important for we have a new

00:02:58,450 --> 00:03:04,299
initiative at JPL and big data some of

00:03:01,420 --> 00:03:06,370
the elements of that have drawn from the

00:03:04,299 --> 00:03:07,989
radio array initiative especially on the

00:03:06,370 --> 00:03:10,510
astronomy side but also looking at Earth

00:03:07,989 --> 00:03:12,609
and other challenges you know that half

00:03:10,510 --> 00:03:13,810
that you know we have to deal with and

00:03:12,609 --> 00:03:15,489
then so this work is part of that

00:03:13,810 --> 00:03:17,530
initiative and these are the types of

00:03:15,489 --> 00:03:19,480
challenges like the SKA but also like

00:03:17,530 --> 00:03:21,160
rapid science algorithm integration some

00:03:19,480 --> 00:03:22,720
of the stuff that we heard about for the

00:03:21,160 --> 00:03:24,549
snow project that we were talking about

00:03:22,720 --> 00:03:25,840
sort of earlier also the types of stuff

00:03:24,549 --> 00:03:27,780
that Luca was talking about when he was

00:03:25,840 --> 00:03:30,069
talking about her system grid you know

00:03:27,780 --> 00:03:31,780
tech stuff that Andrew was talking about

00:03:30,069 --> 00:03:36,220
when he talked about solar and all those

00:03:31,780 --> 00:03:37,599
types of things so um I I think i'm

00:03:36,220 --> 00:03:40,180
going to hand it over to luca nail and

00:03:37,599 --> 00:03:42,669
luca is gonna talk about the V faster

00:03:40,180 --> 00:03:44,530
project okay so yeah so I'm yet to start

00:03:42,669 --> 00:03:46,480
talking about be faster and then Andrew

00:03:44,530 --> 00:03:49,660
we follow me and you know who put the

00:03:46,480 --> 00:03:51,040
talk about be faster and come talk about

00:03:49,660 --> 00:03:53,739
conclusions they publish it say on the

00:03:51,040 --> 00:03:57,220
side okay so I so what is be faster so

00:03:53,739 --> 00:03:59,349
we faster stands for avlb vrda fast

00:03:57,220 --> 00:04:01,449
radio transients so it's this project

00:03:59,349 --> 00:04:03,340
going on and are a GPL and in other

00:04:01,449 --> 00:04:05,560
institutions that's dedicated to

00:04:03,340 --> 00:04:07,209
detecting these very fast or radio

00:04:05,560 --> 00:04:09,940
pulses coming hopefully from

00:04:07,209 --> 00:04:13,030
extraterrestrial sources and they did

00:04:09,940 --> 00:04:13,860
and I yes well no we know that the

00:04:13,030 --> 00:04:17,910
chemical

00:04:13,860 --> 00:04:20,230
lovely not I've never let me go to that

00:04:17,910 --> 00:04:24,160
source could be edited all right but

00:04:20,230 --> 00:04:27,220
maybe so okay so um so the idea is

00:04:24,160 --> 00:04:29,410
actually to mine the data that's taken

00:04:27,220 --> 00:04:31,450
by the vlba for other purposes and to

00:04:29,410 --> 00:04:33,870
try to detect this but this burst on

00:04:31,450 --> 00:04:36,700
this data that's not on our own on disk

00:04:33,870 --> 00:04:38,380
so as far as sources well could be is so

00:04:36,700 --> 00:04:41,020
these are very very short passes about

00:04:38,380 --> 00:04:42,580
you know a few milliseconds and a bit

00:04:41,020 --> 00:04:44,980
could come from known and unknown

00:04:42,580 --> 00:04:46,570
sources we know that there are object in

00:04:44,980 --> 00:04:48,610
the sky that produce disperse these are

00:04:46,570 --> 00:04:50,979
in our pastors intermittent passers

00:04:48,610 --> 00:04:53,290
x-ray binaries and supernovae no we

00:04:50,979 --> 00:04:54,760
expect burst from these sources but you

00:04:53,290 --> 00:04:56,080
know they hope is to detect these things

00:04:54,760 --> 00:04:57,430
that Chris was just mentioning you know

00:04:56,080 --> 00:04:58,900
things that the people have just

00:04:57,430 --> 00:05:01,090
speculating about things like you know

00:04:58,900 --> 00:05:03,010
merging neutron stars neutron stars I'm

00:05:01,090 --> 00:05:05,050
collecting black horse I don't even know

00:05:03,010 --> 00:05:06,940
what that means but you know if I'm is

00:05:05,050 --> 00:05:09,010
great and you know maybe signals from

00:05:06,940 --> 00:05:11,020
other civilizations no it's not

00:05:09,010 --> 00:05:13,840
impossible i guess and the ID i know

00:05:11,020 --> 00:05:15,610
even in other possibilities to define to

00:05:13,840 --> 00:05:17,229
totally new categories of deep space

00:05:15,610 --> 00:05:19,930
object and things that people have not

00:05:17,229 --> 00:05:21,310
observed before so the faster is really

00:05:19,930 --> 00:05:23,370
one of these new categories of

00:05:21,310 --> 00:05:26,800
experiments that are you know aimed at

00:05:23,370 --> 00:05:28,630
mapping the dynamic radio sky so this is

00:05:26,800 --> 00:05:30,430
your tip in in the past and

00:05:28,630 --> 00:05:32,979
traditionally radio from experience are

00:05:30,430 --> 00:05:34,780
about no mapping static sources that we

00:05:32,979 --> 00:05:36,640
know about we are now actually looking

00:05:34,780 --> 00:05:38,650
at doing a know trying to identify

00:05:36,640 --> 00:05:42,010
things that are very very transient in

00:05:38,650 --> 00:05:44,260
nature so i mentioned a the RBA there'll

00:05:42,010 --> 00:05:46,930
be a stand for very large baseline array

00:05:44,260 --> 00:05:48,729
it's a set of ten very large

00:05:46,930 --> 00:05:51,160
radio-telescope turn on each of them is

00:05:48,729 --> 00:05:53,320
about 25 meters in diameter and these

00:05:51,160 --> 00:05:55,479
telescopes are distributed across the

00:05:53,320 --> 00:05:58,419
u.s. from hawaii on the west to the

00:05:55,479 --> 00:06:02,080
virgin islands on the east they are

00:05:58,419 --> 00:06:04,630
located such that no no antenna can see

00:06:02,080 --> 00:06:05,770
the non 10 sits on the local rider of

00:06:04,630 --> 00:06:07,960
each other antenna so they are very

00:06:05,770 --> 00:06:09,490
separate from each other and the overall

00:06:07,960 --> 00:06:10,600
baseline of the whole instrument is

00:06:09,490 --> 00:06:12,639
about eight other eight hundred

00:06:10,600 --> 00:06:13,600
kilometers and therefore the instrument

00:06:12,639 --> 00:06:17,820
can actually achieve very high

00:06:13,600 --> 00:06:21,520
resolutions of about a million second so

00:06:17,820 --> 00:06:23,530
definitely LBA v faster uses a commensal

00:06:21,520 --> 00:06:25,760
which means passive approach to

00:06:23,530 --> 00:06:27,980
detecting these are these passes

00:06:25,760 --> 00:06:30,350
so data is taken but it will be a any

00:06:27,980 --> 00:06:32,240
health nor for other scientific purposes

00:06:30,350 --> 00:06:35,420
and it's then you know it goes to a

00:06:32,240 --> 00:06:39,020
processing pipeline at the DNA RNA NRA

00:06:35,420 --> 00:06:40,850
or in a Socorro New Mexico and now as

00:06:39,020 --> 00:06:42,590
part of the processing or they would

00:06:40,850 --> 00:06:43,970
expire as possible what actually happens

00:06:42,590 --> 00:06:45,980
is that the signals from the different

00:06:43,970 --> 00:06:47,360
tennis our time correlated they are

00:06:45,980 --> 00:06:49,040
corrected for dispersion in the

00:06:47,360 --> 00:06:51,020
interstellar medium they are also

00:06:49,040 --> 00:06:52,670
separated from the noise but the net

00:06:51,020 --> 00:06:57,200
result is that after flowing through a

00:06:52,670 --> 00:06:59,690
correlator data sits on disk for the 4g

00:06:57,200 --> 00:07:01,190
faster to analyze and can only sit here

00:06:59,690 --> 00:07:03,620
for a limited number of time because

00:07:01,190 --> 00:07:06,830
amount of time because i know these are

00:07:03,620 --> 00:07:09,020
pretty big bitty big data directories

00:07:06,830 --> 00:07:11,360
and that this space here is limited so

00:07:09,020 --> 00:07:13,430
the faster people only have about 30

00:07:11,360 --> 00:07:15,380
days to actually select the interesting

00:07:13,430 --> 00:07:18,820
events from the pool of noise and

00:07:15,380 --> 00:07:21,140
archive this event for later inspection

00:07:18,820 --> 00:07:23,420
so there is a team of scientists not

00:07:21,140 --> 00:07:25,310
distribute around the world whose job is

00:07:23,420 --> 00:07:28,160
to know every night or every day they

00:07:25,310 --> 00:07:30,530
actually go to their job is to spec this

00:07:28,160 --> 00:07:32,210
a promising candidate and you know flag

00:07:30,530 --> 00:07:33,710
the ones that know could be interesting

00:07:32,210 --> 00:07:35,870
events from the ones that actually can

00:07:33,710 --> 00:07:37,310
be disregarded and this is actually

00:07:35,870 --> 00:07:39,200
really international scheme it's

00:07:37,310 --> 00:07:41,930
composed by people in the netherlands

00:07:39,200 --> 00:07:43,820
people in Australia and people at to

00:07:41,930 --> 00:07:45,710
institution in the u.s. one is JPL the

00:07:43,820 --> 00:07:50,030
other is a the National registrar me

00:07:45,710 --> 00:07:51,680
observatory in New Mexico um so what we

00:07:50,030 --> 00:07:53,810
have done here at JPL and so did the

00:07:51,680 --> 00:07:55,400
software engineering team at JPL as

00:07:53,810 --> 00:07:57,350
Chris was saying what we've done is

00:07:55,400 --> 00:07:58,970
developing an end-to-end system they

00:07:57,350 --> 00:08:01,820
would actually help the scientists

00:07:58,970 --> 00:08:04,940
identify and analyze it is interesting

00:08:01,820 --> 00:08:07,310
events so our system had two major goal

00:08:04,940 --> 00:08:08,750
one is you know these provide this web

00:08:07,310 --> 00:08:11,450
environment what people could actually

00:08:08,750 --> 00:08:14,000
do their analysis a faster and better

00:08:11,450 --> 00:08:16,210
the other goal that actually just came

00:08:14,000 --> 00:08:18,800
out later was to enable the automatic

00:08:16,210 --> 00:08:21,610
inspection of these events by machine

00:08:18,800 --> 00:08:24,110
agent by basically editor mining process

00:08:21,610 --> 00:08:25,550
so we build this pipeline that you know

00:08:24,110 --> 00:08:27,560
at a very high level has three

00:08:25,550 --> 00:08:30,500
components there is a data processing

00:08:27,560 --> 00:08:33,979
pipeline which takes care of moving

00:08:30,500 --> 00:08:36,440
the data products from nro to JPL and

00:08:33,979 --> 00:08:38,719
then extracting the metadata not having

00:08:36,440 --> 00:08:40,370
a job for inspection there is a second

00:08:38,719 --> 00:08:42,229
component that's the web portal and we

00:08:40,370 --> 00:08:44,000
will talk about that that is this web

00:08:42,229 --> 00:08:46,820
environment where scientists can log in

00:08:44,000 --> 00:08:48,410
and do their analysis and finally there

00:08:46,820 --> 00:08:49,880
is a different man in algorithm that we

00:08:48,410 --> 00:08:51,740
are not going to mention very much but

00:08:49,880 --> 00:08:53,210
these are shows a very interesting part

00:08:51,740 --> 00:08:56,330
of the system because this data mining

00:08:53,210 --> 00:08:58,700
algorithm every night it goes through

00:08:56,330 --> 00:09:01,490
all of the events in the pool and tries

00:08:58,700 --> 00:09:03,290
to automatically tag events based on

00:09:01,490 --> 00:09:05,450
similar characteristics with other

00:09:03,290 --> 00:09:07,220
events they'll be intact by humans so

00:09:05,450 --> 00:09:09,470
this is kind of a self learning machine

00:09:07,220 --> 00:09:13,550
algorithm which is you know precursor to

00:09:09,470 --> 00:09:14,900
intelligent robots basically so in order

00:09:13,550 --> 00:09:16,490
to build this pipeline we actually

00:09:14,900 --> 00:09:17,630
looked at existing frameworks and in

00:09:16,490 --> 00:09:19,310
particular because of our experience

00:09:17,630 --> 00:09:21,260
with Ricky because it's proven

00:09:19,310 --> 00:09:24,230
reliability in other science missions

00:09:21,260 --> 00:09:26,510
which also dt as the the building blocks

00:09:24,230 --> 00:09:28,370
of the pipeline so we talked about to

00:09:26,510 --> 00:09:30,380
the ps3 quite a beta so I'm not going to

00:09:28,370 --> 00:09:32,630
go into a lot of details at a very high

00:09:30,380 --> 00:09:34,130
level let me just mention that you know

00:09:32,630 --> 00:09:35,930
what oddity of the stands for up to rain

00:09:34,130 --> 00:09:37,580
today the technology let me just mention

00:09:35,930 --> 00:09:39,260
that you know in my opinion are some of

00:09:37,580 --> 00:09:41,360
the best best current ratio of the dr

00:09:39,260 --> 00:09:45,350
now it's modularity it's configurability

00:09:41,360 --> 00:09:49,700
and it's extensibility and now why is

00:09:45,350 --> 00:09:52,520
that it's written on the slide ODT is

00:09:49,700 --> 00:09:53,990
also very used knowing very different

00:09:52,520 --> 00:09:55,820
scientific domains we talked about that

00:09:53,990 --> 00:09:58,610
yesterday in particular you know it's

00:09:55,820 --> 00:10:00,950
used in earth science and if used in the

00:09:58,610 --> 00:10:03,010
health sciences involuntary science not

00:10:00,950 --> 00:10:05,060
already astronomy and so on so it it has

00:10:03,010 --> 00:10:06,710
it's really a very flexible architecture

00:10:05,060 --> 00:10:10,820
that can be applied to many scientific

00:10:06,710 --> 00:10:12,380
problems I hope I have your slides

00:10:10,820 --> 00:10:15,710
because this ship's beer in the hook

00:10:12,380 --> 00:10:17,870
version which is okay so this is a very

00:10:15,710 --> 00:10:21,140
high level picture of the pipeline that

00:10:17,870 --> 00:10:22,930
we put in place basically it's a

00:10:21,140 --> 00:10:25,040
complete picture of the whole system and

00:10:22,930 --> 00:10:27,260
what I'm going to do next I'm gonna

00:10:25,040 --> 00:10:30,200
actually go into more detail about each

00:10:27,260 --> 00:10:32,030
single component but at the very high

00:10:30,200 --> 00:10:33,760
level what the pipeline does is that it

00:10:32,030 --> 00:10:36,730
transits data from

00:10:33,760 --> 00:10:39,340
hello where it's now accumulated by day

00:10:36,730 --> 00:10:42,040
from the DMV a data stream the data

00:10:39,340 --> 00:10:43,780
structure to JPL where attention because

00:10:42,040 --> 00:10:46,390
it processing pipeline composability

00:10:43,780 --> 00:10:48,600
components and there's a chronal

00:10:46,390 --> 00:10:51,370
component if a manager component a

00:10:48,600 --> 00:10:53,710
curator component acting on a solar

00:10:51,370 --> 00:10:55,870
indexing script and the whole result of

00:10:53,710 --> 00:10:57,760
these is that the promising look at all

00:10:55,870 --> 00:10:59,410
of the events are actually made

00:10:57,760 --> 00:11:01,870
available to the web portal for

00:10:59,410 --> 00:11:03,100
scientists to inspect and the

00:11:01,870 --> 00:11:07,350
interesting events are tagged the

00:11:03,100 --> 00:11:09,940
enterprise the back at an era nrao

00:11:07,350 --> 00:11:13,090
before going to now describing in detail

00:11:09,940 --> 00:11:14,530
what the pipeline does it's important we

00:11:13,090 --> 00:11:18,310
could be my son could see consideration

00:11:14,530 --> 00:11:20,020
so um so as we design your Kotecha we

00:11:18,310 --> 00:11:21,880
are not completely free i mean we we had

00:11:20,020 --> 00:11:24,310
some constraints that we had to work

00:11:21,880 --> 00:11:26,740
with the first constraint was that we

00:11:24,310 --> 00:11:30,160
actually had to minimize impact on the

00:11:26,740 --> 00:11:31,900
NRI NRI your resources um as I mentioned

00:11:30,160 --> 00:11:33,730
be faster is a commensal project you

00:11:31,900 --> 00:11:37,150
know it works passively on data that's

00:11:33,730 --> 00:11:38,560
taken by an array or anyhow and as a

00:11:37,150 --> 00:11:40,930
conservation we are kind of a guest

00:11:38,560 --> 00:11:43,930
project in the Rio so we had to know

00:11:40,930 --> 00:11:46,420
minimize our users of this storage CPU

00:11:43,930 --> 00:11:49,510
and network bandwidth the second

00:11:46,420 --> 00:11:52,810
consideration of security arm our system

00:11:49,510 --> 00:11:55,150
could not in any way expose the inner

00:11:52,810 --> 00:11:56,980
aerial system compromised in any way or

00:11:55,150 --> 00:11:59,290
touching anyway there are the original

00:11:56,980 --> 00:12:01,030
data product so that's why we decided to

00:11:59,290 --> 00:12:03,220
instead of doing all of this proposition

00:12:01,030 --> 00:12:04,840
pipeline eight in a row directly we

00:12:03,220 --> 00:12:07,810
actually moved all the processing back

00:12:04,840 --> 00:12:09,730
to JPL and the DA neural data products

00:12:07,810 --> 00:12:11,700
were all exposing a read-only mode that

00:12:09,730 --> 00:12:14,470
they could not be now written in any way

00:12:11,700 --> 00:12:16,600
the other thing to consider is that as

00:12:14,470 --> 00:12:18,100
we know this projects been going off for

00:12:16,600 --> 00:12:20,290
maybe a year about something like that

00:12:18,100 --> 00:12:23,200
now and the requirements did evolve

00:12:20,290 --> 00:12:25,090
during this time because no because they

00:12:23,200 --> 00:12:26,800
were cleaner the scientist kiri and

00:12:25,090 --> 00:12:28,810
actually should actually acknowledge you

00:12:26,800 --> 00:12:30,610
know that the two main sizes at JPL are

00:12:28,810 --> 00:12:32,710
doing doing this work out chilliwack

00:12:30,610 --> 00:12:33,910
stuff and david thompson and you know

00:12:32,710 --> 00:12:35,770
during this time you know is they were

00:12:33,910 --> 00:12:37,960
learning more about the system they were

00:12:35,770 --> 00:12:40,060
actually tweaking the processing

00:12:37,960 --> 00:12:41,830
algorithm in front of our system is a

00:12:40,060 --> 00:12:43,690
consequence away now with the passing of

00:12:41,830 --> 00:12:45,550
time we got increased data volumes and

00:12:43,690 --> 00:12:48,220
increase high frequencies that we had

00:12:45,550 --> 00:12:50,140
deal with and no we had to respond to

00:12:48,220 --> 00:12:52,690
this and we had to modify the pipeline

00:12:50,140 --> 00:12:54,399
so for example one thing we did that we

00:12:52,690 --> 00:12:56,140
actually switch well I should pop out

00:12:54,399 --> 00:12:58,660
that later but there were some changes

00:12:56,140 --> 00:13:00,279
to the pipeline as we actually know as

00:12:58,660 --> 00:13:03,640
we had to deal with the different

00:13:00,279 --> 00:13:05,829
conditions so going to be faster with a

00:13:03,640 --> 00:13:08,470
product um it's important to understand

00:13:05,829 --> 00:13:10,360
what we fasoli the product is with us

00:13:08,470 --> 00:13:13,000
the data really is organized at three

00:13:10,360 --> 00:13:16,180
levels it's organized as jobs let scans

00:13:13,000 --> 00:13:17,890
and events so a job is a whole set of

00:13:16,180 --> 00:13:19,570
data that is stored together on this

00:13:17,890 --> 00:13:21,610
calendar one single director that's

00:13:19,570 --> 00:13:23,290
named like the job and this is all the

00:13:21,610 --> 00:13:25,329
data that's associated with a single

00:13:23,290 --> 00:13:27,160
scientific investigation so scientists

00:13:25,329 --> 00:13:29,260
now require note scientists got any

00:13:27,160 --> 00:13:32,620
rodius for no permission to an observer

00:13:29,260 --> 00:13:34,120
serta portion on the sky and no they are

00:13:32,620 --> 00:13:36,240
granted a certain amount of time and

00:13:34,120 --> 00:13:39,279
that's a whole job so all of that

00:13:36,240 --> 00:13:42,880
observation stay in one directory each

00:13:39,279 --> 00:13:45,160
job consists of 1 to 100 scans so it's

00:13:42,880 --> 00:13:47,500
candy is a period of time where all the

00:13:45,160 --> 00:13:49,480
antennas know this tenant and as part of

00:13:47,500 --> 00:13:52,120
the LBA all the antennas are pointed at

00:13:49,480 --> 00:13:55,060
the same point in the sky and typically

00:13:52,120 --> 00:13:58,120
scan the last problem in 0 1 to 100

00:13:55,060 --> 00:14:01,930
seconds each scan can contain what can

00:13:58,120 --> 00:14:03,610
contain from 0 to 100 device so most

00:14:01,930 --> 00:14:05,829
cans don't contain any so what is in

00:14:03,610 --> 00:14:07,480
rent in event is a a portion of time

00:14:05,829 --> 00:14:08,740
that the system thinks is interesting

00:14:07,480 --> 00:14:11,410
because it could contain a detection

00:14:08,740 --> 00:14:14,079
from extraterrestrial sources um each

00:14:11,410 --> 00:14:15,910
event is about one to two second and if

00:14:14,079 --> 00:14:17,980
you know most cans don't have any events

00:14:15,910 --> 00:14:20,770
but the scan can have about ten event or

00:14:17,980 --> 00:14:22,899
they can even have a hundred events and

00:14:20,770 --> 00:14:24,730
you know each event is about saying is

00:14:22,899 --> 00:14:26,500
about two seconds and i wanted to second

00:14:24,730 --> 00:14:28,120
but the really interesting part of an

00:14:26,500 --> 00:14:30,370
event is actually much shorter is about

00:14:28,120 --> 00:14:33,640
you know ten ten milliseconds it's a

00:14:30,370 --> 00:14:36,820
very very quick burst radio pulse from

00:14:33,640 --> 00:14:39,160
from the sky so this is very important a

00:14:36,820 --> 00:14:41,740
very important distinction on each data

00:14:39,160 --> 00:14:43,390
product for us is a correspond so each

00:14:41,740 --> 00:14:45,940
job correspond to one single data

00:14:43,390 --> 00:14:48,970
product and that's the whole set of five

00:14:45,940 --> 00:14:51,339
states under one directory and it's

00:14:48,970 --> 00:14:53,740
basically not only contains calibration

00:14:51,339 --> 00:14:55,100
files output files voltages the

00:14:53,740 --> 00:14:57,170
reconstructed image essence

00:14:55,100 --> 00:14:58,400
and it's approximately 1 to 100

00:14:57,170 --> 00:14:59,990
gigabytes you know depending on how many

00:14:58,400 --> 00:15:02,180
events you have in the particular job

00:14:59,990 --> 00:15:05,930
you can you can actually be very small

00:15:02,180 --> 00:15:07,520
or quite large so what are these events

00:15:05,930 --> 00:15:10,070
so these are exams so this is an example

00:15:07,520 --> 00:15:12,020
of the events we detect this is a

00:15:10,070 --> 00:15:15,440
compost imagine where you can you have

00:15:12,020 --> 00:15:17,540
each of these line is the detection from

00:15:15,440 --> 00:15:19,310
a single telescope we have nine of these

00:15:17,540 --> 00:15:22,400
and you know they are plotted in

00:15:19,310 --> 00:15:25,190
different ways on the x-axis you have

00:15:22,400 --> 00:15:26,960
time on the y-axis you have other the

00:15:25,190 --> 00:15:29,150
frequency of the relative signal and

00:15:26,960 --> 00:15:31,400
what you can see clearly here is that at

00:15:29,150 --> 00:15:35,030
this particular point in time no hear

00:15:31,400 --> 00:15:37,790
all nine nine of the ten telescopes

00:15:35,030 --> 00:15:39,890
clearly so as a radio frequency signal

00:15:37,790 --> 00:15:42,410
they clearly so it is very very rapid

00:15:39,890 --> 00:15:44,390
about burst and it turns out that this

00:15:42,410 --> 00:15:46,550
is actually a pulser so this is a real

00:15:44,390 --> 00:15:48,890
deep space object that's actually known

00:15:46,550 --> 00:15:50,330
so we didn't discover anything new but

00:15:48,890 --> 00:15:51,890
the fact that we faster could attack

00:15:50,330 --> 00:15:53,240
that it was actually proved that they

00:15:51,890 --> 00:15:54,710
know it's actually working I mean the

00:15:53,240 --> 00:15:56,720
whole the whole processing is actually

00:15:54,710 --> 00:15:58,700
working this is the composite signal

00:15:56,720 --> 00:16:01,070
from all of the nine all of the ninth

00:15:58,700 --> 00:16:02,870
telescopes nine instead of 10 because

00:16:01,070 --> 00:16:04,760
the region algorithm that actually is

00:16:02,870 --> 00:16:06,740
regards telescope see if they introduce

00:16:04,760 --> 00:16:09,860
too much noise that's what's called

00:16:06,740 --> 00:16:12,380
adaptive adaptive excision I guess so

00:16:09,860 --> 00:16:14,420
that will be a signal there's also lots

00:16:12,380 --> 00:16:16,850
of fixing us for example this is singer

00:16:14,420 --> 00:16:18,580
called a digit an example of hi-fi which

00:16:16,850 --> 00:16:20,900
stands for radio frequency interference

00:16:18,580 --> 00:16:23,900
so in this case you see that one

00:16:20,900 --> 00:16:26,150
telescope so one signal here but none of

00:16:23,900 --> 00:16:27,770
the others so the same signal so this is

00:16:26,150 --> 00:16:30,140
the signal for motors but none of the

00:16:27,770 --> 00:16:31,730
others are the same and the reason here

00:16:30,140 --> 00:16:33,860
is that this signal is actually from

00:16:31,730 --> 00:16:37,640
terraced resources it's not from aliens

00:16:33,860 --> 00:16:39,950
or anything like that there's also yeah

00:16:37,640 --> 00:16:41,630
I'm sorry there's also Cygnus that we

00:16:39,950 --> 00:16:44,000
don't understand so for example this is

00:16:41,630 --> 00:16:45,770
a famous signal called the feature the

00:16:44,000 --> 00:16:48,560
scene it's a very weak signal but it's

00:16:45,770 --> 00:16:50,570
seen in all the antennas and people are

00:16:48,560 --> 00:16:52,160
still debating what that is and they

00:16:50,570 --> 00:16:54,130
can't really figure it out but you know

00:16:52,160 --> 00:16:57,230
it clearly has a very clear statement or

00:16:54,130 --> 00:16:58,579
this has no name I call it the snake but

00:16:57,230 --> 00:16:59,899
you know it

00:16:58,579 --> 00:17:01,220
sitting on the scene by one tends to

00:16:59,899 --> 00:17:03,199
fall is the most likely just like a

00:17:01,220 --> 00:17:05,260
defect or some interference in a

00:17:03,199 --> 00:17:08,539
particular task over its kind of weird

00:17:05,260 --> 00:17:09,949
so right here we are doing here um so

00:17:08,539 --> 00:17:11,480
let's go back to the pipeline let's

00:17:09,949 --> 00:17:13,189
discuss what are the different component

00:17:11,480 --> 00:17:15,230
that we actually use that to build this

00:17:13,189 --> 00:17:17,059
pipeline the first of this component is

00:17:15,230 --> 00:17:18,829
actually not in a party product but it's

00:17:17,059 --> 00:17:20,600
a very it's an open source and very

00:17:18,829 --> 00:17:21,709
useful product called rsync that you

00:17:20,600 --> 00:17:24,260
know some of you might be familiar with

00:17:21,709 --> 00:17:26,539
our sink is this unix utility that

00:17:24,260 --> 00:17:28,069
allows you to synchronize a remote and

00:17:26,539 --> 00:17:30,440
the local data directory with very

00:17:28,069 --> 00:17:32,419
minimal user user intervention so

00:17:30,440 --> 00:17:35,330
basically what we use rsync for is to

00:17:32,419 --> 00:17:37,159
transfer data products from niÃ±o to JPL

00:17:35,330 --> 00:17:39,019
where they were transferred it's very

00:17:37,159 --> 00:17:40,940
useful very easy to set up but it has a

00:17:39,019 --> 00:17:43,760
bunch of options it's a it's quite high

00:17:40,940 --> 00:17:45,500
performance utility because it only

00:17:43,760 --> 00:17:48,919
turns their differences of files in

00:17:45,500 --> 00:17:50,779
between different in vocations so if one

00:17:48,919 --> 00:17:52,730
of the files are the source changes will

00:17:50,779 --> 00:17:54,649
not return for the whole file but just

00:17:52,730 --> 00:17:56,510
what changed and it's really can a

00:17:54,649 --> 00:17:58,909
turnkey solution I mean it would turn it

00:17:56,510 --> 00:18:02,510
on a year ago we never had to touch it

00:17:58,909 --> 00:18:05,929
again so that that's just great so the

00:18:02,510 --> 00:18:08,210
way we're using in be faster is that we

00:18:05,929 --> 00:18:11,120
had enough seed I've seen server demon

00:18:08,210 --> 00:18:13,789
running at an array or and which was

00:18:11,120 --> 00:18:16,490
configured with some tight security

00:18:13,789 --> 00:18:19,130
security restrictions it would all allow

00:18:16,490 --> 00:18:20,809
connections from JPL host and it would

00:18:19,130 --> 00:18:23,269
only allow connections II read all the

00:18:20,809 --> 00:18:25,700
mode so you couldn't write abyss demon a

00:18:23,269 --> 00:18:27,230
j.pierre Ella we had a nursing client

00:18:25,700 --> 00:18:30,740
they would actually run as a cron job

00:18:27,230 --> 00:18:32,510
every hour think and so every hour on

00:18:30,740 --> 00:18:35,350
all new products coming from the vlba

00:18:32,510 --> 00:18:37,419
were automatically transferred to JPL um

00:18:35,350 --> 00:18:40,010
the other thing that happens that

00:18:37,419 --> 00:18:42,559
because we wanted to minimize impact on

00:18:40,010 --> 00:18:43,880
NRAO resources we did not transfer the

00:18:42,559 --> 00:18:46,070
whole Prada the whole product can be

00:18:43,880 --> 00:18:48,110
from 1 to 100 gigabyte there was too

00:18:46,070 --> 00:18:50,330
much we decided to actually very

00:18:48,110 --> 00:18:52,460
slightly transfer only those files dude

00:18:50,330 --> 00:18:54,080
allow scientists to expect a particular

00:18:52,460 --> 00:18:56,240
job at the particular particular event

00:18:54,080 --> 00:18:57,500
so basically by you know by deciding

00:18:56,240 --> 00:18:59,450
which side to transfer we actually

00:18:57,500 --> 00:19:01,909
managed to reduce the product from five

00:18:59,450 --> 00:19:04,010
from 50 gigabytes on average 250

00:19:01,909 --> 00:19:06,289
megabytes so a reduction of three orders

00:19:04,010 --> 00:19:07,820
of magnitude and because of that it

00:19:06,289 --> 00:19:09,320
turns and because of that and because of

00:19:07,820 --> 00:19:11,389
the transfer fee

00:19:09,320 --> 00:19:12,649
speed between the two hosts it turns out

00:19:11,389 --> 00:19:14,690
we can actually transfer the food

00:19:12,649 --> 00:19:16,639
products for a for a whole day in just a

00:19:14,690 --> 00:19:19,850
matter of minutes so we are certainly

00:19:16,639 --> 00:19:20,960
not the data transfer bound the second

00:19:19,850 --> 00:19:22,549
component will use that is the

00:19:20,960 --> 00:19:25,100
controller that no we talked about that

00:19:22,549 --> 00:19:27,320
as some sometime yesterday the color is

00:19:25,100 --> 00:19:29,299
a component is a one of the most useful

00:19:27,320 --> 00:19:31,220
oddity component if something that you

00:19:29,299 --> 00:19:33,950
can use to monitor a day tastes a

00:19:31,220 --> 00:19:35,600
certain staging area and s files and

00:19:33,950 --> 00:19:37,100
products coming to the staging area you

00:19:35,600 --> 00:19:39,049
can actually submit them automatically

00:19:37,100 --> 00:19:42,379
to a file manager which is another key

00:19:39,049 --> 00:19:44,000
component what will come next so you

00:19:42,379 --> 00:19:47,179
know for we faster we set up this

00:19:44,000 --> 00:19:48,980
crawler to actually run every I things

00:19:47,179 --> 00:19:51,049
actually every 300 seconds every five

00:19:48,980 --> 00:19:53,269
minutes the clerk was monitoring this

00:19:51,049 --> 00:19:55,820
staging directory and every time no

00:19:53,269 --> 00:19:57,980
these full products arrived from an

00:19:55,820 --> 00:19:59,960
inner area it would actually trigger

00:19:57,980 --> 00:20:03,080
this adventures on this product to the

00:19:59,960 --> 00:20:04,639
castle manager um as many of the

00:20:03,080 --> 00:20:08,600
components the crawler has different

00:20:04,639 --> 00:20:10,490
extension points and we heavily average

00:20:08,600 --> 00:20:12,259
this configurability and one of the

00:20:10,490 --> 00:20:14,509
things we did for example we establish a

00:20:12,259 --> 00:20:16,309
precondition a java would not be

00:20:14,509 --> 00:20:18,620
ingesting to the file manager unless it

00:20:16,309 --> 00:20:20,870
was completed so we had a marker file

00:20:18,620 --> 00:20:23,539
that only word that market file was

00:20:20,870 --> 00:20:24,980
transferred to JPL the crawler would

00:20:23,539 --> 00:20:27,289
actually trigger ingesting them to the

00:20:24,980 --> 00:20:28,669
file manager the other thing that you

00:20:27,289 --> 00:20:30,350
can do with the crawler you cannot you

00:20:28,669 --> 00:20:33,710
can have precondition you can also have

00:20:30,350 --> 00:20:35,570
a post actions so after the job has been

00:20:33,710 --> 00:20:37,700
ingested then after it's been other

00:20:35,570 --> 00:20:40,399
successful or failed you can actually

00:20:37,700 --> 00:20:42,139
trigger some some piece of code and the

00:20:40,399 --> 00:20:45,379
way we use that is that you know on

00:20:42,139 --> 00:20:47,960
POSIX on post ingest success so if the

00:20:45,379 --> 00:20:50,029
injectable successful we triggered a

00:20:47,960 --> 00:20:52,940
particular script the transfer the

00:20:50,029 --> 00:20:54,740
metadata from the file manager into a

00:20:52,940 --> 00:20:57,860
solar instance and we talked about that

00:20:54,740 --> 00:21:00,259
in just a cycle so the second component

00:20:57,860 --> 00:21:02,149
we use alpha DT is the file manager so

00:21:00,259 --> 00:21:04,639
this is now one of the core components

00:21:02,149 --> 00:21:07,789
of oddity it's what you typically use to

00:21:04,639 --> 00:21:09,799
archive archive data product extract

00:21:07,789 --> 00:21:11,570
metadata and send this metadata to a

00:21:09,799 --> 00:21:14,720
catalog that you can actually then later

00:21:11,570 --> 00:21:17,419
query for a foreign in or two to get any

00:21:14,720 --> 00:21:19,549
information about the job the file

00:21:17,419 --> 00:21:21,739
manager also is very configurable

00:21:19,549 --> 00:21:24,379
extensible is it all led component and

00:21:21,739 --> 00:21:27,499
the way we use these in order in the

00:21:24,379 --> 00:21:30,440
faster is that no well so there's many

00:21:27,499 --> 00:21:32,480
ways we use this a bit faster the first

00:21:30,440 --> 00:21:35,389
thing we did we actually find policies

00:21:32,480 --> 00:21:38,509
that establish which data products were

00:21:35,389 --> 00:21:40,669
allowed in the system and another

00:21:38,509 --> 00:21:43,039
decision here was to be find one single

00:21:40,669 --> 00:21:46,909
data product to capture all the metadata

00:21:43,039 --> 00:21:48,080
for a specific job so we could have done

00:21:46,909 --> 00:21:49,850
something different we could have

00:21:48,080 --> 00:21:52,429
decided that you know because metadata

00:21:49,850 --> 00:21:54,470
is divided into job sorry because data

00:21:52,429 --> 00:21:56,119
is largely divided into jobs canceled

00:21:54,470 --> 00:21:57,710
events we could have defined three

00:21:56,119 --> 00:22:00,320
different metaproducts not one for jog

00:21:57,710 --> 00:22:02,389
one force can work for invent but we

00:22:00,320 --> 00:22:04,519
didn't do so partly because of because

00:22:02,389 --> 00:22:06,139
of historical reasons but the other the

00:22:04,519 --> 00:22:07,730
other advantage of doing that the times

00:22:06,139 --> 00:22:09,769
of having one single data product is

00:22:07,730 --> 00:22:11,450
that if you are required you can

00:22:09,769 --> 00:22:13,580
actually qualify manager for a specific

00:22:11,450 --> 00:22:15,139
identifiers and get all the metadata at

00:22:13,580 --> 00:22:18,769
once now without having to issue

00:22:15,139 --> 00:22:21,289
multiple queries a consequence of our

00:22:18,769 --> 00:22:24,200
decision was that some of the keys that

00:22:21,289 --> 00:22:25,639
so I should say that when method it

00:22:24,200 --> 00:22:27,799
isn't just inside manager you need to

00:22:25,639 --> 00:22:29,419
reduce it to key values pairs because

00:22:27,799 --> 00:22:31,879
that's the underlying model in the cast

00:22:29,419 --> 00:22:34,369
fund manager because we only had one

00:22:31,879 --> 00:22:36,440
data product because not the number of

00:22:34,369 --> 00:22:38,509
scans in a product and number of events

00:22:36,440 --> 00:22:40,700
in scan is variable so it's not known a

00:22:38,509 --> 00:22:43,369
priori we actually had to be fine with a

00:22:40,700 --> 00:22:44,960
dynamic metadata keys so we had our

00:22:43,369 --> 00:22:47,330
metadata that defines things like you

00:22:44,960 --> 00:22:50,600
know the start time for our 40404 events

00:22:47,330 --> 00:22:52,549
for scan six is you know a certain

00:22:50,600 --> 00:22:55,820
number of value so these kids were

00:22:52,549 --> 00:22:57,799
dynamically defined this also meant that

00:22:55,820 --> 00:23:00,200
we had to do something with a validation

00:22:57,799 --> 00:23:01,909
layer the validation layer is that

00:23:00,200 --> 00:23:04,429
component of the file manager that

00:23:01,909 --> 00:23:06,109
ensures that once in just a product all

00:23:04,429 --> 00:23:08,330
those metadata fields are really there

00:23:06,109 --> 00:23:10,429
so it would that typically reject the

00:23:08,330 --> 00:23:12,859
pro that it does mr. if those keys are

00:23:10,429 --> 00:23:14,840
not found but because the keys are not

00:23:12,859 --> 00:23:17,149
known a priori we had to define a linear

00:23:14,840 --> 00:23:19,159
behavior for this for dessert plugin and

00:23:17,149 --> 00:23:20,749
we basically had to tell you know ingest

00:23:19,159 --> 00:23:24,259
meta data even if they know you don't

00:23:20,749 --> 00:23:25,789
really know about these keys um we

00:23:24,259 --> 00:23:27,499
actually had we find a row meter detects

00:23:25,789 --> 00:23:29,450
tractor that's a typical thing you know

00:23:27,499 --> 00:23:30,500
in the file manager we have this

00:23:29,450 --> 00:23:32,840
pluggable config

00:23:30,500 --> 00:23:34,460
correction where you decide no whenever

00:23:32,840 --> 00:23:36,320
you ingest a proud that you decide which

00:23:34,460 --> 00:23:39,740
piece of code to run to extract metadata

00:23:36,320 --> 00:23:41,540
appropriately and no RV facility that

00:23:39,740 --> 00:23:44,300
structure looked into the data directory

00:23:41,540 --> 00:23:46,820
then you they know how to parse each

00:23:44,300 --> 00:23:50,540
node each kind of file and ingest all

00:23:46,820 --> 00:23:51,890
the metadata into the file manager the

00:23:50,540 --> 00:23:55,160
other thing that happened is that in our

00:23:51,890 --> 00:23:56,810
mediator catalog that is something

00:23:55,160 --> 00:23:58,850
that's also configurable in the file

00:23:56,810 --> 00:24:00,740
manager we started with the default

00:23:58,850 --> 00:24:02,600
losing implementation but you know as

00:24:00,740 --> 00:24:04,520
the frequency of metadata ingestion

00:24:02,600 --> 00:24:06,050
become became higher and higher and is

00:24:04,520 --> 00:24:07,850
the frequency of updates became higher

00:24:06,050 --> 00:24:09,440
we actually had to switch to a

00:24:07,850 --> 00:24:12,260
relational database because we had a

00:24:09,440 --> 00:24:14,030
problem at a time in the curator um so

00:24:12,260 --> 00:24:16,220
we switch from losing to my sequel and

00:24:14,030 --> 00:24:17,980
later on we went back in the 60 curator

00:24:16,220 --> 00:24:21,050
to also deal with these high transfer

00:24:17,980 --> 00:24:24,020
updates and it's partly the transfer you

00:24:21,050 --> 00:24:26,060
know what we decide is that typically in

00:24:24,020 --> 00:24:28,010
the file manager you move data products

00:24:26,060 --> 00:24:30,290
from a staging area to an archive area

00:24:28,010 --> 00:24:32,210
and you decide how that archive area

00:24:30,290 --> 00:24:33,680
should be structure but what we actually

00:24:32,210 --> 00:24:35,480
had to do in the faster we actually

00:24:33,680 --> 00:24:37,040
archive them in place because you know

00:24:35,480 --> 00:24:38,990
if we move them they are seeing that

00:24:37,040 --> 00:24:40,520
prod at their sink a demon would

00:24:38,990 --> 00:24:42,710
actually transfer them to the same

00:24:40,520 --> 00:24:45,830
location so that's that's how that's

00:24:42,710 --> 00:24:47,930
what we did um the third component going

00:24:45,830 --> 00:24:50,270
to talk about is curator so curatorial

00:24:47,930 --> 00:24:53,330
is this oddity component that it is a

00:24:50,270 --> 00:24:54,860
web application that sits in front of

00:24:53,330 --> 00:24:58,040
the file manager in it allows both

00:24:54,860 --> 00:25:01,250
humans oops both humans in ATM machines

00:24:58,040 --> 00:25:03,790
to submit request to the curator to

00:25:01,250 --> 00:25:06,140
modify the meta data in the file manager

00:25:03,790 --> 00:25:08,930
so it really comes with two interfaces

00:25:06,140 --> 00:25:11,150
one is a web interface that's typically

00:25:08,930 --> 00:25:12,800
used by humans and this web interface

00:25:11,150 --> 00:25:14,870
disease no representation of the

00:25:12,800 --> 00:25:16,580
interface the web interface will allow

00:25:14,870 --> 00:25:19,250
you to in your selected data product

00:25:16,580 --> 00:25:22,340
from in all your staging area drop them

00:25:19,250 --> 00:25:25,340
onto these onto this panel here on the

00:25:22,340 --> 00:25:27,170
right and no accumulators of a number of

00:25:25,340 --> 00:25:28,910
product for each product you decide on

00:25:27,170 --> 00:25:32,750
which mediatek meter detects tractor to

00:25:28,910 --> 00:25:34,550
run and then you trigger a full job that

00:25:32,750 --> 00:25:36,260
ingest all those product at once into

00:25:34,550 --> 00:25:38,750
the fund manager so that's one of the

00:25:36,260 --> 00:25:41,660
way you can use curator but the way we

00:25:38,750 --> 00:25:43,730
use it in the faster is different in the

00:25:41,660 --> 00:25:45,680
faster we use the second way the second

00:25:43,730 --> 00:25:49,490
is exposed by the curator which is a

00:25:45,680 --> 00:25:53,180
website for API so um these capabilities

00:25:49,490 --> 00:25:55,070
built on top of Apache jax-rs and what

00:25:53,180 --> 00:25:57,470
it is is that the curator web

00:25:55,070 --> 00:26:00,620
application has endpoints now you are

00:25:57,470 --> 00:26:02,270
else like these metadata / update that

00:26:00,620 --> 00:26:04,700
you can actually invoke it not from a

00:26:02,270 --> 00:26:07,400
script from a client from anything to

00:26:04,700 --> 00:26:09,740
change modify or add metadata to an

00:26:07,400 --> 00:26:11,780
existing product so if you wanted to

00:26:09,740 --> 00:26:13,550
actually add a name value pair to an

00:26:11,780 --> 00:26:16,460
existing product you will simply not

00:26:13,550 --> 00:26:18,680
invoke this URL as seen as post

00:26:16,460 --> 00:26:20,420
parameters the protein it afire and then

00:26:18,680 --> 00:26:23,390
in value and this will actually be added

00:26:20,420 --> 00:26:25,940
to the existing metadata in the faster

00:26:23,390 --> 00:26:29,690
this is actually if these capabilities

00:26:25,940 --> 00:26:32,090
invoked twice it is it involved by both

00:26:29,690 --> 00:26:35,380
both the day they'll be faster portal

00:26:32,090 --> 00:26:37,760
and the Machine determine the script so

00:26:35,380 --> 00:26:39,980
and we will actually show you know from

00:26:37,760 --> 00:26:42,830
the disaster humans can grow and they

00:26:39,980 --> 00:26:45,920
know tag metadata basically the sides of

00:26:42,830 --> 00:26:47,930
tags to admit a data to an event and the

00:26:45,920 --> 00:26:49,790
determining algorithm does that nightly

00:26:47,930 --> 00:26:51,530
the domani algorithm nightly goes

00:26:49,790 --> 00:26:53,810
through the whole pool of events in the

00:26:51,530 --> 00:26:56,840
database besides which ones are worth

00:26:53,810 --> 00:26:58,610
tagging and sends these instructions the

00:26:56,840 --> 00:27:00,980
curator which then activates the file

00:26:58,610 --> 00:27:03,230
manager and at the same time triggers

00:27:00,980 --> 00:27:08,030
Andrey in jersey on the metadata into

00:27:03,230 --> 00:27:09,170
solar finally the last component I'm

00:27:08,030 --> 00:27:11,570
going to talk about before leaving the

00:27:09,170 --> 00:27:13,370
stage is Apache Solr originally we

00:27:11,570 --> 00:27:14,600
didn't have these in the system and we

00:27:13,370 --> 00:27:16,610
were simply querying the product

00:27:14,600 --> 00:27:19,880
metadata to the cache file manager but

00:27:16,610 --> 00:27:22,070
the result that you know as we as we had

00:27:19,880 --> 00:27:24,860
increasing demand for a high-frequency

00:27:22,070 --> 00:27:26,480
query to the system or different entity

00:27:24,860 --> 00:27:29,660
was simply not able to actually support

00:27:26,480 --> 00:27:32,960
those and we had to move to a more a

00:27:29,660 --> 00:27:35,090
more high performance solution so we

00:27:32,960 --> 00:27:36,770
looked at this you know we since we were

00:27:35,090 --> 00:27:39,530
already familiar with Apache Solr which

00:27:36,770 --> 00:27:41,780
is ignoring known Apache product we

00:27:39,530 --> 00:27:43,880
decided to use it into our system so

00:27:41,780 --> 00:27:45,530
Apache Solr you know it's a very high

00:27:43,880 --> 00:27:46,840
perform a search engine below top of the

00:27:45,530 --> 00:27:49,910
scene and we talked about that yesterday

00:27:46,840 --> 00:27:53,050
it allows you know text queries faceted

00:27:49,910 --> 00:27:55,280
queries it also has no

00:27:53,050 --> 00:27:58,030
advanced features like no highlighting

00:27:55,280 --> 00:28:01,130
what completion and stuff like that and

00:27:58,030 --> 00:28:04,160
underneath the solar mother is very

00:28:01,130 --> 00:28:06,320
similar to the cast metadata model you

00:28:04,160 --> 00:28:09,920
store metadata is key multiple value

00:28:06,320 --> 00:28:11,480
pairs it's also very scalable component

00:28:09,920 --> 00:28:12,860
that you know you can scale to tens and

00:28:11,480 --> 00:28:15,980
hundreds of millions of records but I'm

00:28:12,860 --> 00:28:19,160
not going to go into that but the way we

00:28:15,980 --> 00:28:21,350
use the solar in in the faster is the

00:28:19,160 --> 00:28:23,900
following basically the reason is that

00:28:21,350 --> 00:28:26,330
we wanted to enable very fast very high

00:28:23,900 --> 00:28:28,400
frequency query by the clients and the

00:28:26,330 --> 00:28:31,310
clients are the portal and the data

00:28:28,400 --> 00:28:33,950
mining straight so what we did we

00:28:31,310 --> 00:28:35,870
actually were running a solar instance

00:28:33,950 --> 00:28:39,860
within the same town cutter defrosting

00:28:35,870 --> 00:28:42,020
the curator application and these are

00:28:39,860 --> 00:28:45,380
basically this solar instance the bitter

00:28:42,020 --> 00:28:47,720
it is ingested from the cancer from the

00:28:45,380 --> 00:28:50,000
casket alabi into solar in two

00:28:47,720 --> 00:28:52,450
conditions when the job is first

00:28:50,000 --> 00:28:54,920
ingested the castro as i was mentioning

00:28:52,450 --> 00:28:56,720
after a job in his ingest the controller

00:28:54,920 --> 00:28:58,910
will trigger these solar english in the

00:28:56,720 --> 00:29:00,710
evenings in script which reduce metadata

00:28:58,910 --> 00:29:05,000
from there and move it all the way to

00:29:00,710 --> 00:29:07,490
here also when the job when when each

00:29:05,000 --> 00:29:09,950
other is when an event is tagged to be

00:29:07,490 --> 00:29:12,080
interesting with the window with other a

00:29:09,950 --> 00:29:15,290
pastor or the nullify or anything like

00:29:12,080 --> 00:29:18,590
that the calculator the calculator

00:29:15,290 --> 00:29:20,840
itself triggers again is an indexing

00:29:18,590 --> 00:29:22,880
script which takes eliminate again from

00:29:20,840 --> 00:29:26,180
here and replace the existing metadata

00:29:22,880 --> 00:29:28,400
into solar and the way this works is

00:29:26,180 --> 00:29:30,380
this through this jax-rs filter that

00:29:28,400 --> 00:29:32,810
allows not the response to be

00:29:30,380 --> 00:29:35,480
intercepted on the outgoing undergoing

00:29:32,810 --> 00:29:38,450
channel on so this works really well for

00:29:35,480 --> 00:29:41,480
us as we move metadata from the file

00:29:38,450 --> 00:29:43,660
manager into solar if you remember said

00:29:41,480 --> 00:29:46,090
that in the file manager each job is

00:29:43,660 --> 00:29:48,530
represented one single blob of metadata

00:29:46,090 --> 00:29:50,210
in order to put any metadata better as

00:29:48,530 --> 00:29:52,850
we move the metadata from here to here

00:29:50,210 --> 00:29:55,940
we actually decided to split each single

00:29:52,850 --> 00:29:57,860
metadata blob in too many records so you

00:29:55,940 --> 00:30:00,300
in judgment arranged in solar as xml

00:29:57,860 --> 00:30:02,910
record and what we are doing

00:30:00,300 --> 00:30:04,890
with indiscreet is that the formulator

00:30:02,910 --> 00:30:08,130
for a job it is split into records that

00:30:04,890 --> 00:30:10,950
our flag this job scan in event so each

00:30:08,130 --> 00:30:13,200
single metadata record here becomes many

00:30:10,950 --> 00:30:14,700
metadata records here and this allows us

00:30:13,200 --> 00:30:17,700
to actually better query the metadata

00:30:14,700 --> 00:30:19,650
because we can issue queries for for

00:30:17,700 --> 00:30:22,290
example we can ask the system what are

00:30:19,650 --> 00:30:25,290
all the latest product ingesting a

00:30:22,290 --> 00:30:27,180
system by date what is the full metadata

00:30:25,290 --> 00:30:29,730
for a single job a single scan or a

00:30:27,180 --> 00:30:32,040
single event or also we can ask

00:30:29,730 --> 00:30:34,230
questions like what are all the events

00:30:32,040 --> 00:30:36,630
the systems are detected its path search

00:30:34,230 --> 00:30:39,150
detectives RFI or detectives anything

00:30:36,630 --> 00:30:40,800
else and you know it's more on you as

00:30:39,150 --> 00:30:42,270
more humans are going to use the system

00:30:40,800 --> 00:30:44,730
and are going to know in certain new

00:30:42,270 --> 00:30:46,170
tags that we still have not about we can

00:30:44,730 --> 00:30:47,730
actually ask things like what are all

00:30:46,170 --> 00:30:49,320
the tags that humans have assigned to

00:30:47,730 --> 00:30:52,290
this event and get the list of those

00:30:49,320 --> 00:30:53,670
tags so at this point I'm going to leave

00:30:52,290 --> 00:30:55,980
the stage for Andrea who's going to talk

00:30:53,670 --> 00:31:02,070
about then this web portal that uses all

00:30:55,980 --> 00:31:03,960
these infrastructure thanks sister okay

00:31:02,070 --> 00:31:06,300
so Luca has done a great job of sort of

00:31:03,960 --> 00:31:08,100
laying out the back end system and why

00:31:06,300 --> 00:31:09,810
we've constructed it the way that we

00:31:08,100 --> 00:31:12,780
have what I'm going to talk about a

00:31:09,810 --> 00:31:15,090
little bit is the way that users of the

00:31:12,780 --> 00:31:18,180
system more specifically the V faster

00:31:15,090 --> 00:31:20,280
science data team will take advantage of

00:31:18,180 --> 00:31:23,340
the system and basically how they will

00:31:20,280 --> 00:31:25,110
interact with it for the longest time

00:31:23,340 --> 00:31:28,800
the team had been doing things basically

00:31:25,110 --> 00:31:31,380
by remotely logging in through command

00:31:28,800 --> 00:31:33,630
line and investigating metadata and jobs

00:31:31,380 --> 00:31:35,910
that way this portal was meant as a way

00:31:33,630 --> 00:31:37,740
to make it a little bit more flexible

00:31:35,910 --> 00:31:40,920
and a little bit more standardized and

00:31:37,740 --> 00:31:44,700
to facilitate collaboration between the

00:31:40,920 --> 00:31:46,970
team so the team just to be more

00:31:44,700 --> 00:31:49,380
specific is distributed around the globe

00:31:46,970 --> 00:31:53,520
so there's obviously the issue of time

00:31:49,380 --> 00:31:55,170
zones but there's also just just

00:31:53,520 --> 00:31:57,060
collaborating is difficult in providing

00:31:55,170 --> 00:31:58,410
a single shared environment where these

00:31:57,060 --> 00:32:02,760
people could take a look at things was

00:31:58,410 --> 00:32:05,820
important so the system that Luca just

00:32:02,760 --> 00:32:07,530
laid out here at a high level follows

00:32:05,820 --> 00:32:09,990
the data follows this process that

00:32:07,530 --> 00:32:12,100
roughly goes from upstream product

00:32:09,990 --> 00:32:14,559
acquisition through to staging and

00:32:12,100 --> 00:32:16,210
archiving and cataloging and what the

00:32:14,559 --> 00:32:19,480
web portal is designed to do is to

00:32:16,210 --> 00:32:21,549
provide a largely read-only view of the

00:32:19,480 --> 00:32:23,830
information the latest information that

00:32:21,549 --> 00:32:25,299
was captured the previous evening but

00:32:23,830 --> 00:32:27,340
also an archive of all of the

00:32:25,299 --> 00:32:29,080
information that has been captured or

00:32:27,340 --> 00:32:30,700
rather the metadata that's been captured

00:32:29,080 --> 00:32:33,400
up to date and I think it's important to

00:32:30,700 --> 00:32:35,830
mention that what is like Lucas said we

00:32:33,400 --> 00:32:37,600
had to be good neighbors essentially and

00:32:35,830 --> 00:32:40,570
be very careful about how much of NRA

00:32:37,600 --> 00:32:42,610
owes resources that we were taking and

00:32:40,570 --> 00:32:45,760
so the information while we were while

00:32:42,610 --> 00:32:47,289
the raw voltage data off of the upstream

00:32:45,760 --> 00:32:49,570
antennas is on the order of gigabytes

00:32:47,289 --> 00:32:51,669
two terabytes the information that we

00:32:49,570 --> 00:32:53,049
collected on the JPL side is on the

00:32:51,669 --> 00:32:55,870
order of megabytes hundreds of megabytes

00:32:53,049 --> 00:32:59,169
per night and it consists mostly of this

00:32:55,870 --> 00:33:01,059
raw metadata and the image data that

00:32:59,169 --> 00:33:03,100
Lucas was showing you later earlier

00:33:01,059 --> 00:33:05,789
where you can see the visual

00:33:03,100 --> 00:33:09,460
representation of what the antenna see

00:33:05,789 --> 00:33:10,870
so what do we build we've built the

00:33:09,460 --> 00:33:14,260
portal off of a number of different

00:33:10,870 --> 00:33:18,070
Apache products obviously ODT forms a

00:33:14,260 --> 00:33:19,390
lot of the back end but there is a web

00:33:18,070 --> 00:33:21,760
framework called balance which is a

00:33:19,390 --> 00:33:23,260
component of ODT and shikha is going to

00:33:21,760 --> 00:33:25,740
give a talk on that later this afternoon

00:33:23,260 --> 00:33:28,539
that source sort of serves as the

00:33:25,740 --> 00:33:31,630
substrate for the portal we're using

00:33:28,539 --> 00:33:33,370
solar for search as Luca mentioned and

00:33:31,630 --> 00:33:37,929
we both take advantage of the HTTP

00:33:33,370 --> 00:33:39,309
server and tomcat so if you're taking a

00:33:37,929 --> 00:33:41,020
look at the pole and you were to come in

00:33:39,309 --> 00:33:43,270
as a science team member this would be

00:33:41,020 --> 00:33:44,919
the first screen essentially what you

00:33:43,270 --> 00:33:46,360
see is the latest detection data

00:33:44,919 --> 00:33:48,880
expressed as sort of very high-level

00:33:46,360 --> 00:33:51,700
information as well as an indication of

00:33:48,880 --> 00:33:55,929
both how many scans were run and how

00:33:51,700 --> 00:33:58,960
many total events were detected by the

00:33:55,929 --> 00:34:01,450
automated detecting machinery if you dig

00:33:58,960 --> 00:34:04,090
into a particular scan you start to see

00:34:01,450 --> 00:34:06,010
some scan level metadata what job the

00:34:04,090 --> 00:34:08,919
scan belonged to we're in the sky the

00:34:06,010 --> 00:34:11,379
scan was looking and some information

00:34:08,919 --> 00:34:13,389
that helps you anchor the scan in time

00:34:11,379 --> 00:34:18,490
as well as an indication of how many

00:34:13,389 --> 00:34:21,760
events were flagged by the system so if

00:34:18,490 --> 00:34:23,800
we dig in one more

00:34:21,760 --> 00:34:25,899
you can see what it would look like for

00:34:23,800 --> 00:34:28,360
an individual event again you have that

00:34:25,899 --> 00:34:30,850
same level context metadata but now more

00:34:28,360 --> 00:34:33,880
specific to this individual event you've

00:34:30,850 --> 00:34:35,889
got the ability to download the full

00:34:33,880 --> 00:34:38,050
resolution imagery to sort of take a

00:34:35,889 --> 00:34:41,409
really close look at it but you're

00:34:38,050 --> 00:34:42,580
starting to see again what what Luca was

00:34:41,409 --> 00:34:44,550
showing earlier about what these

00:34:42,580 --> 00:34:47,530
antennas are actually looking at and

00:34:44,550 --> 00:34:50,110
somebody who's a reviewer is going to be

00:34:47,530 --> 00:34:51,190
taking a look at this and they can by

00:34:50,110 --> 00:34:52,690
virtue of the fact that they've looked

00:34:51,190 --> 00:34:54,639
at thousands of these over the years

00:34:52,690 --> 00:34:56,670
very quickly as in within a matter of

00:34:54,639 --> 00:34:59,020
you know five to ten seconds usually

00:34:56,670 --> 00:35:01,300
classify this as either being of

00:34:59,020 --> 00:35:03,610
interest or not of interest and if it's

00:35:01,300 --> 00:35:06,460
not interesting they move on if it is

00:35:03,610 --> 00:35:09,490
interesting they are now able to do

00:35:06,460 --> 00:35:12,400
something called tagging and tagging as

00:35:09,490 --> 00:35:13,990
Luca said is a way to associate some

00:35:12,400 --> 00:35:16,450
description some descriptive metadata

00:35:13,990 --> 00:35:19,270
with a particular event that will later

00:35:16,450 --> 00:35:20,890
allow for its classification as either

00:35:19,270 --> 00:35:22,420
being something of scientific interest

00:35:20,890 --> 00:35:23,730
or something that should not have been

00:35:22,420 --> 00:35:28,330
flagged in the first place and that

00:35:23,730 --> 00:35:30,070
filtering is interesting because it

00:35:28,330 --> 00:35:34,660
helps to classify things but it also is

00:35:30,070 --> 00:35:36,010
used it to train the machine learning

00:35:34,660 --> 00:35:38,320
algorithms that were doing the initial

00:35:36,010 --> 00:35:40,630
classification so that right now the

00:35:38,320 --> 00:35:43,000
human is absolutely the bottleneck the

00:35:40,630 --> 00:35:45,520
the human in the loop doing the review

00:35:43,000 --> 00:35:46,660
is only there because they want to be

00:35:45,520 --> 00:35:49,060
sure that they're not missing anything

00:35:46,660 --> 00:35:51,160
and the confidence in the AI algorithms

00:35:49,060 --> 00:35:55,390
isn't there yet that they can just trust

00:35:51,160 --> 00:35:56,860
that the human in the loop tagging then

00:35:55,390 --> 00:35:59,200
is sort of a supervised learning

00:35:56,860 --> 00:36:02,080
technique where they can go and use this

00:35:59,200 --> 00:36:03,460
information to iteratively improve the

00:36:02,080 --> 00:36:05,170
underlying algorithms with the idea that

00:36:03,460 --> 00:36:07,600
ultimately they'll have enough

00:36:05,170 --> 00:36:12,400
confidence in there that the workload

00:36:07,600 --> 00:36:14,320
for the human reviewers goes down so

00:36:12,400 --> 00:36:15,730
this on the interface if somebody's

00:36:14,320 --> 00:36:17,710
gotten done looking at something they

00:36:15,730 --> 00:36:19,810
have the ability to associate tags for

00:36:17,710 --> 00:36:21,760
the event and Luca went over sort of the

00:36:19,810 --> 00:36:24,130
difference the machine is going and

00:36:21,760 --> 00:36:25,600
adding is what it it's best guess of

00:36:24,130 --> 00:36:27,970
what it is and those will show up as

00:36:25,600 --> 00:36:30,130
great eggs I'm sorry those will show up

00:36:27,970 --> 00:36:32,530
as boot eggs and then machine tags

00:36:30,130 --> 00:36:34,250
entered by a human science team reviewer

00:36:32,530 --> 00:36:40,580
will

00:36:34,250 --> 00:36:42,320
show up as great so what can users do in

00:36:40,580 --> 00:36:44,150
this portal enough by and large it's a

00:36:42,320 --> 00:36:46,280
read-only view it's just what data was

00:36:44,150 --> 00:36:48,110
collected let me take a look at it but

00:36:46,280 --> 00:36:50,420
what we're starting to get is this

00:36:48,110 --> 00:36:52,600
ability to start feed information back

00:36:50,420 --> 00:36:54,890
into the system and allow it to affect

00:36:52,600 --> 00:36:56,870
the future performance and sort of

00:36:54,890 --> 00:36:59,480
improve the performance of the system in

00:36:56,870 --> 00:37:01,670
the future one of the things that we

00:36:59,480 --> 00:37:05,150
they can't do quite yet but that we will

00:37:01,670 --> 00:37:07,850
do is to use the portal as a initiator

00:37:05,150 --> 00:37:09,760
for what to archive so I mentioned that

00:37:07,850 --> 00:37:11,960
the upstream data is many many many

00:37:09,760 --> 00:37:14,990
gigabytes and sometimes many terabytes

00:37:11,960 --> 00:37:16,250
of data we have a limited amount of

00:37:14,990 --> 00:37:18,740
space on that system that we've been

00:37:16,250 --> 00:37:20,390
granted to run this experiment and so I

00:37:18,740 --> 00:37:22,310
have to be sort of judicious about what

00:37:20,390 --> 00:37:27,470
int what data we keep for long term

00:37:22,310 --> 00:37:29,300
offline analysis the criteria for what

00:37:27,470 --> 00:37:31,070
is kept in what is thrown away is

00:37:29,300 --> 00:37:33,770
entirely dependent on what's interesting

00:37:31,070 --> 00:37:35,450
to the scientists and right now there's

00:37:33,770 --> 00:37:37,640
sort of a duality where the scientists

00:37:35,450 --> 00:37:39,140
will use the portal for this rapid

00:37:37,640 --> 00:37:41,000
viewing of information and even

00:37:39,140 --> 00:37:42,820
providing these taggings but then

00:37:41,000 --> 00:37:45,140
they'll still log into the system and

00:37:42,820 --> 00:37:48,290
actually physically perform the archive

00:37:45,140 --> 00:37:50,000
or flush the data from the disk and one

00:37:48,290 --> 00:37:52,730
of the things that we want to do is to

00:37:50,000 --> 00:37:54,440
make this a little bit more fluid in the

00:37:52,730 --> 00:37:56,900
sense that once they've tagged something

00:37:54,440 --> 00:37:58,640
the system will then use a set of

00:37:56,900 --> 00:37:59,960
metrics or rules to understand that if

00:37:58,640 --> 00:38:01,910
such and such has been tagged as

00:37:59,960 --> 00:38:06,530
interesting the corresponding job should

00:38:01,910 --> 00:38:08,240
be archived so what have users thought

00:38:06,530 --> 00:38:10,070
so far we've had this particular

00:38:08,240 --> 00:38:12,230
interface in production for about eight

00:38:10,070 --> 00:38:13,900
months now and we've had a chance to get

00:38:12,230 --> 00:38:16,400
a lot of feedback and to work with that

00:38:13,900 --> 00:38:18,170
by and large people seem to find that

00:38:16,400 --> 00:38:19,760
the interface is an improvement over the

00:38:18,170 --> 00:38:22,370
terminal based stuff where they'd have

00:38:19,760 --> 00:38:23,990
to pull up using an X Window some you

00:38:22,370 --> 00:38:26,390
know the image is sort of one by one

00:38:23,990 --> 00:38:27,620
having them in a web-based interface is

00:38:26,390 --> 00:38:29,210
really great they can just scroll

00:38:27,620 --> 00:38:31,220
through these things one of the

00:38:29,210 --> 00:38:33,470
feedbacks that we got the most was that

00:38:31,220 --> 00:38:35,390
they really wanted us to minimize clicks

00:38:33,470 --> 00:38:36,560
so those screens that I showed you in

00:38:35,390 --> 00:38:38,780
the beginning where you're sort of see

00:38:36,560 --> 00:38:41,840
really see really looking at an event

00:38:38,780 --> 00:38:43,340
one by one is actually not the way that

00:38:41,840 --> 00:38:45,029
they would prefer to work and so we've

00:38:43,340 --> 00:38:47,130
developed an alternative view

00:38:45,029 --> 00:38:49,679
specifically for the process of

00:38:47,130 --> 00:38:51,719
reviewing a job where in all of the

00:38:49,679 --> 00:38:53,849
imagery for all of the events just loads

00:38:51,719 --> 00:38:55,709
in a never-ending stream somewhat like

00:38:53,849 --> 00:38:57,929
you Facebook pages you keep scrolling

00:38:55,709 --> 00:38:59,699
more stuff keeps showing up although we

00:38:57,929 --> 00:39:01,169
do load it all at once because some of

00:38:59,699 --> 00:39:04,199
those people really scroll fast and that

00:39:01,169 --> 00:39:07,229
the lag of waiting avoiding is can be

00:39:04,199 --> 00:39:09,890
really painful so minimizing clicks was

00:39:07,229 --> 00:39:12,479
one of the things that we took as as

00:39:09,890 --> 00:39:14,429
criticism for this and so we've tried to

00:39:12,479 --> 00:39:16,829
improve that and we've even had

00:39:14,429 --> 00:39:18,209
experiences where reviewers have been

00:39:16,829 --> 00:39:19,289
able to see something on their mobile

00:39:18,209 --> 00:39:21,359
phone because they're traveling or

00:39:19,289 --> 00:39:22,799
whatnot they don't have access to the

00:39:21,359 --> 00:39:24,509
full environment of their of their

00:39:22,799 --> 00:39:28,650
workstations and they found that to be

00:39:24,509 --> 00:39:31,140
quite useful so what's next for for this

00:39:28,650 --> 00:39:32,459
interface in particular is to do sort of

00:39:31,140 --> 00:39:34,409
what Luca said at the very end of his

00:39:32,459 --> 00:39:37,049
portion which is to take advantage of

00:39:34,409 --> 00:39:39,199
some of the power of solar to afford

00:39:37,049 --> 00:39:41,640
these people you know flexible search

00:39:39,199 --> 00:39:43,279
faceting by different tag values so that

00:39:41,640 --> 00:39:45,390
they can pull down different collections

00:39:43,279 --> 00:39:46,739
search by different index metadata

00:39:45,390 --> 00:39:48,839
because what we're doing right now is

00:39:46,739 --> 00:39:51,059
we're utilizing the portal primarily for

00:39:48,839 --> 00:39:52,589
the information that just came in and

00:39:51,059 --> 00:39:55,619
you know what last night's data

00:39:52,589 --> 00:39:57,059
essentially but over time as this volume

00:39:55,619 --> 00:39:58,829
grows and as we get more and more

00:39:57,059 --> 00:40:00,419
information in there it's going to

00:39:58,829 --> 00:40:01,859
become increasingly important to say hey

00:40:00,419 --> 00:40:03,479
I'd like to see all the things that

00:40:01,859 --> 00:40:04,650
actually were marked as a pulsar and

00:40:03,479 --> 00:40:06,569
sort of get a sense of those

00:40:04,650 --> 00:40:08,809
independently or i'd like to see this

00:40:06,569 --> 00:40:11,189
category or that category and so

00:40:08,809 --> 00:40:13,319
providing since solar makes it so easy

00:40:11,189 --> 00:40:15,150
to do it's really just a matter of

00:40:13,319 --> 00:40:17,699
wiring it into the interface at this

00:40:15,150 --> 00:40:19,049
moment and then like I said we'll try

00:40:17,699 --> 00:40:21,359
and keep keep improving the efficiency

00:40:19,049 --> 00:40:25,709
to keep up with these the science team

00:40:21,359 --> 00:40:28,499
and implement the system to support the

00:40:25,709 --> 00:40:31,729
automatic archiving of data back into

00:40:28,499 --> 00:40:34,140
the into the permanent offline our code

00:40:31,729 --> 00:40:37,169
so i think i think that about wraps it

00:40:34,140 --> 00:40:38,489
up for for the presentation put any and

00:40:37,169 --> 00:40:40,640
all of us would be happy to take

00:40:38,489 --> 00:40:40,640
questions

00:40:51,829 --> 00:40:56,910
well right now you guys are mostly

00:40:53,970 --> 00:40:58,980
focused on grabbing data from existing

00:40:56,910 --> 00:41:02,190
archives extract it and running the you

00:40:58,980 --> 00:41:03,869
know your algorithms on that so you know

00:41:02,190 --> 00:41:05,730
it closer the SKA some of those other

00:41:03,869 --> 00:41:08,490
things we've got it and sort of sampling

00:41:05,730 --> 00:41:11,670
algorithms upstream as we're collecting

00:41:08,490 --> 00:41:12,930
data can we use ODT to do that we use

00:41:11,670 --> 00:41:15,000
the workflow infrastructure to actually

00:41:12,930 --> 00:41:16,890
eat as part of firing off these agents

00:41:15,000 --> 00:41:18,150
as a data is coming in streaming into

00:41:16,890 --> 00:41:27,420
the archive centers or where would we

00:41:18,150 --> 00:41:29,700
put that no go ahead oh okay ah yeah my

00:41:27,420 --> 00:41:31,829
thoughts my thoughts on that are that

00:41:29,700 --> 00:41:34,079
when I originally talked to carrie and

00:41:31,829 --> 00:41:36,029
dave about doing this a couple years ago

00:41:34,079 --> 00:41:39,059
one of the things that we discussed was

00:41:36,029 --> 00:41:40,710
their jobs our Python jobs right now the

00:41:39,059 --> 00:41:43,950
way there are doing the upstream like

00:41:40,710 --> 00:41:46,349
their their their code runs at the

00:41:43,950 --> 00:41:48,059
instrument correlator and so but the

00:41:46,349 --> 00:41:49,440
problem is not the problem but just the

00:41:48,059 --> 00:41:51,359
way that they did it is that they wrote

00:41:49,440 --> 00:41:53,190
that park themselves and so they did

00:41:51,359 --> 00:41:54,809
intend at some point like to figure out

00:41:53,190 --> 00:41:56,400
if they could use any of the ODT things

00:41:54,809 --> 00:41:58,230
like upstream at the instrument

00:41:56,400 --> 00:42:01,010
correlator like running in some cases on

00:41:58,230 --> 00:42:03,029
like like you know the hardware itself

00:42:01,010 --> 00:42:04,440
and I think that they would have done

00:42:03,029 --> 00:42:06,420
that because that they could run Python

00:42:04,440 --> 00:42:08,190
on there so they can run in Java or the

00:42:06,420 --> 00:42:09,329
JVM or at least portions of it and we

00:42:08,190 --> 00:42:12,089
talked to them about that we just never

00:42:09,329 --> 00:42:13,710
did it but yes that's because of the way

00:42:12,089 --> 00:42:14,789
that it's been delineated between what

00:42:13,710 --> 00:42:17,190
these guys have been talking about the

00:42:14,789 --> 00:42:18,990
way that we work with them like we've

00:42:17,190 --> 00:42:20,880
been focused yeah like on the downstream

00:42:18,990 --> 00:42:23,730
stuff with the intention yet to grow

00:42:20,880 --> 00:42:25,710
like like for sk like you said dan to

00:42:23,730 --> 00:42:29,309
the upstream stuff and also in the

00:42:25,710 --> 00:42:31,440
interim for LSST so LSST is there's

00:42:29,309 --> 00:42:32,549
another fast transient potential type of

00:42:31,440 --> 00:42:34,319
thing because they're gonna get like for

00:42:32,549 --> 00:42:35,640
20 to 40 terabytes a night and then

00:42:34,319 --> 00:42:37,289
they're going to go process it offline

00:42:35,640 --> 00:42:38,880
like the next whatever and so we talked

00:42:37,289 --> 00:42:40,740
to the LSST people about potentially

00:42:38,880 --> 00:42:41,250
using this for that too it might be

00:42:40,740 --> 00:42:43,800
interested

00:42:41,250 --> 00:42:45,930
benchmark of how how you can scale on

00:42:43,800 --> 00:42:47,610
you know the front end of this whole

00:42:45,930 --> 00:42:49,440
thing right so that you can figure out

00:42:47,610 --> 00:42:53,490
how much data you can actually capture

00:42:49,440 --> 00:42:54,900
oh you know or time in how the workload

00:42:53,490 --> 00:43:02,280
for structure could be used to actually

00:42:54,900 --> 00:43:04,110
support that yep great thanks hi I let

00:43:02,280 --> 00:43:07,080
you talk my questions going the other

00:43:04,110 --> 00:43:09,960
way what if you were looking at data and

00:43:07,080 --> 00:43:12,420
you decided that the snake is a really

00:43:09,960 --> 00:43:14,790
important artifact of a cosmic event

00:43:12,420 --> 00:43:17,280
that just got discovered how flexible is

00:43:14,790 --> 00:43:19,740
a system to kind of go back into your

00:43:17,280 --> 00:43:23,310
huge archives and try to extract all

00:43:19,740 --> 00:43:26,970
instances of snake so that's a great

00:43:23,310 --> 00:43:28,440
point and I think one of the things that

00:43:26,970 --> 00:43:31,650
we have to keep in mind is that

00:43:28,440 --> 00:43:34,740
obviously it has to do with the fact

00:43:31,650 --> 00:43:37,200
that we are not gathering the original

00:43:34,740 --> 00:43:38,790
information we are we are simply

00:43:37,200 --> 00:43:40,140
piggybacking on information that's being

00:43:38,790 --> 00:43:42,210
gathered in the context of other

00:43:40,140 --> 00:43:43,650
experiments so that's what Luca was

00:43:42,210 --> 00:43:45,840
saying when you said this is a commensal

00:43:43,650 --> 00:43:47,760
experiment is that every night these

00:43:45,840 --> 00:43:50,850
experiments are being generated by other

00:43:47,760 --> 00:43:52,620
people we as V faster does not control

00:43:50,850 --> 00:43:54,240
for example the pointing source at any

00:43:52,620 --> 00:43:56,730
point in time it doesn't control what's

00:43:54,240 --> 00:43:58,110
being looked at it simply has access to

00:43:56,730 --> 00:44:00,750
the data that's being captured by other

00:43:58,110 --> 00:44:02,970
by other researchers furthermore what we

00:44:00,750 --> 00:44:06,660
end up doing with that data is taking a

00:44:02,970 --> 00:44:08,340
look at something like what like this

00:44:06,660 --> 00:44:10,680
snake so if this snake shows up right

00:44:08,340 --> 00:44:12,450
the snake pattern shows up we have

00:44:10,680 --> 00:44:14,460
access for the next I don't know less

00:44:12,450 --> 00:44:16,080
than a month or so to that data and have

00:44:14,460 --> 00:44:19,410
that time to make a decision about

00:44:16,080 --> 00:44:22,290
whether to keep or whether to destroy

00:44:19,410 --> 00:44:24,330
that data and I think the to get to your

00:44:22,290 --> 00:44:25,650
point which is which is how do you go

00:44:24,330 --> 00:44:28,080
back and find something else that's

00:44:25,650 --> 00:44:30,180
similar I think the way to address that

00:44:28,080 --> 00:44:32,460
is to become a little bit more

00:44:30,180 --> 00:44:35,550
expressive with the tags that we've

00:44:32,460 --> 00:44:37,950
developed so for example right now if if

00:44:35,550 --> 00:44:39,480
that if that snake thing is this is

00:44:37,950 --> 00:44:41,280
determined to be interesting and it's

00:44:39,480 --> 00:44:44,310
not garbage in it but it's just unknown

00:44:41,280 --> 00:44:45,960
and we tag that as I don't know I have

00:44:44,310 --> 00:44:47,760
no idea what this is but it's

00:44:45,960 --> 00:44:49,020
potentially interesting and it's

00:44:47,760 --> 00:44:51,510
interesting enough that it's worth

00:44:49,020 --> 00:44:52,420
archiving that data and the data gets

00:44:51,510 --> 00:44:54,520
archived then

00:44:52,420 --> 00:44:55,870
we can do exactly what you're saying but

00:44:54,520 --> 00:44:58,650
I think it's going to be a text based

00:44:55,870 --> 00:45:01,450
search at the moment because the

00:44:58,650 --> 00:45:03,550
information the individual jobs are

00:45:01,450 --> 00:45:05,800
archived as sort of self-contained units

00:45:03,550 --> 00:45:09,930
and the information about what's in

00:45:05,800 --> 00:45:09,930
those little units is all this metadata

00:45:10,020 --> 00:45:14,500
I'm not really sure about this but I

00:45:12,280 --> 00:45:16,960
think that after a month that we

00:45:14,500 --> 00:45:19,090
actually lose any data that was taken

00:45:16,960 --> 00:45:21,940
right so you would be able to get the

00:45:19,090 --> 00:45:24,100
snake to run these algorithms and find

00:45:21,940 --> 00:45:27,280
the snakes only for the past previous 30

00:45:24,100 --> 00:45:28,960
days right I think I'm yeah so this is

00:45:27,280 --> 00:45:30,340
this is an area in which it would be

00:45:28,960 --> 00:45:34,000
really helpful to have the actual

00:45:30,340 --> 00:45:35,830
scientists here because no right babe

00:45:34,000 --> 00:45:37,630
well I mean primarily because what we've

00:45:35,830 --> 00:45:39,400
been building is the metadata analysis

00:45:37,630 --> 00:45:40,780
framework not so much the data analysis

00:45:39,400 --> 00:45:42,730
side of things it's okay and it's also

00:45:40,780 --> 00:45:44,410
within the context it's also within the

00:45:42,730 --> 00:45:45,580
context of this experiment that's right

00:45:44,410 --> 00:45:46,990
yeah so maybe thinking more broadly

00:45:45,580 --> 00:45:48,580
which is maybe what you're doing or

00:45:46,990 --> 00:45:50,400
whatever to like like so they're going

00:45:48,580 --> 00:45:52,600
around like the upstream scientists

00:45:50,400 --> 00:45:53,830
scientists like machine learning people

00:45:52,600 --> 00:45:55,480
so it's a combination of computer

00:45:53,830 --> 00:45:57,370
scientists as well as like radio

00:45:55,480 --> 00:45:59,350
astronomers and then experts and that to

00:45:57,370 --> 00:46:02,050
tho Xin learning people that they kind

00:45:59,350 --> 00:46:04,630
of sit in between us and like weird data

00:46:02,050 --> 00:46:06,850
like data ops or data processing

00:46:04,630 --> 00:46:08,530
whatever and then then the scientists it

00:46:06,850 --> 00:46:10,090
in between them like the nrao people are

00:46:08,530 --> 00:46:11,560
the people in Australia or yadda yadda

00:46:10,090 --> 00:46:13,840
the other people the actual radio

00:46:11,560 --> 00:46:15,160
astronomers and so what they've been

00:46:13,840 --> 00:46:16,600
doing is going around pitching this

00:46:15,160 --> 00:46:18,820
approach to like other groups like the

00:46:16,600 --> 00:46:21,700
OSS t people like the large synoptic

00:46:18,820 --> 00:46:23,860
survey telescope and then and then to

00:46:21,700 --> 00:46:25,630
others like low far in the Europe like

00:46:23,860 --> 00:46:27,580
the low frequency array which low far

00:46:25,630 --> 00:46:30,040
has an existing transient pipeline but

00:46:27,580 --> 00:46:31,930
in those types of cases just for V

00:46:30,040 --> 00:46:33,790
faster yes we don't keep the data around

00:46:31,930 --> 00:46:35,200
because like this isn't like 100 million

00:46:33,790 --> 00:46:36,640
dollar funded project it's more of a

00:46:35,200 --> 00:46:38,260
smaller science research effort and

00:46:36,640 --> 00:46:39,640
those other hundred-million-dollar

00:46:38,260 --> 00:46:41,290
funded projects or whatever the

00:46:39,640 --> 00:46:43,840
suggestion is to use something like this

00:46:41,290 --> 00:46:46,150
to do precisely what you're saying 22

00:46:43,840 --> 00:46:48,220
then suggests yes like to keep the data

00:46:46,150 --> 00:46:49,990
around period and then use this to

00:46:48,220 --> 00:46:51,430
dictate and drive initially text based

00:46:49,990 --> 00:46:53,140
search or whatever of the tags for the

00:46:51,430 --> 00:46:54,670
machine learning but eventually into the

00:46:53,140 --> 00:46:57,650
bits themselves using things like Casa

00:46:54,670 --> 00:46:59,630
rapes or things like that do some use

00:46:57,650 --> 00:47:01,640
there might be some real synergy you can

00:46:59,630 --> 00:47:03,799
gain with these guys for tracking

00:47:01,640 --> 00:47:06,589
simultaneous events against different

00:47:03,799 --> 00:47:08,869
frequency observations or write us these

00:47:06,589 --> 00:47:14,359
different groups right good luck with it

00:47:08,869 --> 00:47:16,579
thanks thanks it yeah so it's 1206 so

00:47:14,359 --> 00:47:18,260
technically we've got nine minutes then

00:47:16,579 --> 00:47:19,880
it's lunch time so you can go early to

00:47:18,260 --> 00:47:22,700
lunch if you want or if anyone has any

00:47:19,880 --> 00:47:31,599
questions anymore all right early to

00:47:22,700 --> 00:47:31,599

YouTube URL: https://www.youtube.com/watch?v=oDZUne-kj0k


