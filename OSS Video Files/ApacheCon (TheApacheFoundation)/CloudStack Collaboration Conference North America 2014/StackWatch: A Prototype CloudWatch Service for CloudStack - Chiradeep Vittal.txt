Title: StackWatch: A Prototype CloudWatch Service for CloudStack - Chiradeep Vittal
Publication date: 2014-04-29
Playlist: CloudStack Collaboration Conference North America 2014
Description: 
	CloudStack Collaboration Conference North America 2014
Captions: 
	00:00:00,000 --> 00:00:05,009
good morning everybody my name is chi

00:00:02,639 --> 00:00:08,150
redeep I work for citrix and architect

00:00:05,009 --> 00:00:10,800
with citrix and i work on CloudStack and

00:00:08,150 --> 00:00:12,900
this is something i've been if you heard

00:00:10,800 --> 00:00:14,400
of google's twenty percent time they

00:00:12,900 --> 00:00:16,980
give you twenty percent employees to

00:00:14,400 --> 00:00:18,630
work on their pet projects this is

00:00:16,980 --> 00:00:20,160
something I've worked on my minus ten

00:00:18,630 --> 00:00:22,500
percent time which means I had no time

00:00:20,160 --> 00:00:24,060
to work on it but I did learn something

00:00:22,500 --> 00:00:29,160
and I want to share those learnings with

00:00:24,060 --> 00:00:31,590
you this is a developer talk so you are

00:00:29,160 --> 00:00:34,739
if you not a developer your eyes my

00:00:31,590 --> 00:00:37,020
cloud over I thought I was going to give

00:00:34,739 --> 00:00:40,260
a demo but there's something wrong with

00:00:37,020 --> 00:00:42,600
my setup but largely the the attempt is

00:00:40,260 --> 00:00:45,180
to make you think about how you want to

00:00:42,600 --> 00:00:49,350
contribute to CloudStack and where do

00:00:45,180 --> 00:00:51,629
you want to run your service so I'll

00:00:49,350 --> 00:00:55,530
talk about what a stack watch how I

00:00:51,629 --> 00:00:57,930
designed it and some lessons learnt and

00:00:55,530 --> 00:01:04,159
then tips for building your own service

00:00:57,930 --> 00:01:07,500
in in clouds type so stack watch is a

00:01:04,159 --> 00:01:10,710
very strictly modeled around a similar

00:01:07,500 --> 00:01:12,990
sounding name from amazon called a

00:01:10,710 --> 00:01:15,210
tubeless cloud watch that essentially is

00:01:12,990 --> 00:01:18,479
a monitoring as a service so you have

00:01:15,210 --> 00:01:20,009
your app running in the cloud and you

00:01:18,479 --> 00:01:23,220
want to be able to monitor things like

00:01:20,009 --> 00:01:25,860
in a request latency or memory pressure

00:01:23,220 --> 00:01:27,720
or anything like that you can think of

00:01:25,860 --> 00:01:31,229
you want to be able to monitor at a very

00:01:27,720 --> 00:01:34,979
fine granularity and then be able to

00:01:31,229 --> 00:01:36,960
retrieve those metrics at a later time

00:01:34,979 --> 00:01:41,400
maybe 15 days later you want to see well

00:01:36,960 --> 00:01:43,049
what happened two weekends ago you want

00:01:41,400 --> 00:01:46,049
to be able to graph them get averages

00:01:43,049 --> 00:01:47,399
statistics etc and very importantly you

00:01:46,049 --> 00:01:49,290
want to be able to alarm when there's a

00:01:47,399 --> 00:01:51,899
threshold crossings either you know

00:01:49,290 --> 00:01:53,970
there's loads too high of the or you

00:01:51,899 --> 00:01:58,140
know corresponding the loads dropped to

00:01:53,970 --> 00:02:00,270
an acceptable level and because you're

00:01:58,140 --> 00:02:02,100
running in a multi-tenant cloud is an

00:02:00,270 --> 00:02:03,659
imagine that you have in a thousand or

00:02:02,100 --> 00:02:07,259
ten thousand tenants and they're each

00:02:03,659 --> 00:02:09,959
sending a hundred events or 100 metrics

00:02:07,259 --> 00:02:11,099
a minute that's a million metrics a

00:02:09,959 --> 00:02:13,440
minute you're trying to handle that

00:02:11,099 --> 00:02:16,650
right so that these are some of the

00:02:13,440 --> 00:02:19,470
requirements for stack watch and the way

00:02:16,650 --> 00:02:22,350
it came about was that cloudstack has

00:02:19,470 --> 00:02:23,970
auto scaling mechanism and there was

00:02:22,350 --> 00:02:26,340
somebody complaining about that hey you

00:02:23,970 --> 00:02:28,020
know I like the feature but I need to

00:02:26,340 --> 00:02:29,610
deploy a netscaler to take advantage of

00:02:28,020 --> 00:02:32,100
it I don't want to use the netscaler

00:02:29,610 --> 00:02:34,590
besides just my applications not even

00:02:32,100 --> 00:02:38,370
load balance so why should i buy a night

00:02:34,590 --> 00:02:40,620
scalar tuna put in something which uses

00:02:38,370 --> 00:02:45,870
h a proxy but that still requires a load

00:02:40,620 --> 00:02:49,110
balancer in the in the path so then i

00:02:45,870 --> 00:02:50,970
looked at well how does amazon do it in

00:02:49,110 --> 00:02:52,530
amazon lets you use application matrix

00:02:50,970 --> 00:02:55,380
the matrix that really matter right i

00:02:52,530 --> 00:02:58,350
mean so what if your hypervisors

00:02:55,380 --> 00:03:00,240
reporting your CPU is high what really

00:02:58,350 --> 00:03:05,490
matters is what your application things

00:03:00,240 --> 00:03:07,110
is the load right and then the current

00:03:05,490 --> 00:03:08,790
implementation uses a lot of polling

00:03:07,110 --> 00:03:11,130
which really doesn't scale if you want

00:03:08,790 --> 00:03:14,220
the million metric submitted kind of

00:03:11,130 --> 00:03:17,100
thing and then if you want fidelity to

00:03:14,220 --> 00:03:20,489
the AWS API again that was not there at

00:03:17,100 --> 00:03:23,340
CloudStack and then some people said

00:03:20,489 --> 00:03:26,220
well you know sure you can scale up by

00:03:23,340 --> 00:03:28,320
starting a new vm or are scaled down by

00:03:26,220 --> 00:03:30,660
stopping a vm but what if i want to do

00:03:28,320 --> 00:03:33,300
something else maybe i want to increase

00:03:30,660 --> 00:03:36,630
the my java memory or heap or something

00:03:33,300 --> 00:03:40,110
right they weren't more flexibility but

00:03:36,630 --> 00:03:42,420
all that indicated that the if i were to

00:03:40,110 --> 00:03:46,830
do the auto scale service again i would

00:03:42,420 --> 00:03:50,010
need a new or a service like cloud watch

00:03:46,830 --> 00:03:53,010
which is what i call stack watch and

00:03:50,010 --> 00:03:54,959
then along the way because you know i

00:03:53,010 --> 00:03:57,780
read an article that saying that a

00:03:54,959 --> 00:04:00,269
learning mind is essential to keep your

00:03:57,780 --> 00:04:01,440
brain for young and fresh i said why

00:04:00,269 --> 00:04:07,350
don't i develop this in a different

00:04:01,440 --> 00:04:09,060
language right and then because i was

00:04:07,350 --> 00:04:12,989
doing it's on a minus ten percent time

00:04:09,060 --> 00:04:16,230
you know I'd code on this like 22 23

00:04:12,989 --> 00:04:19,260
times a week and then every time you

00:04:16,230 --> 00:04:21,780
sync up with the master it's moved I had

00:04:19,260 --> 00:04:23,310
so much that you do a lot of yak shaving

00:04:21,780 --> 00:04:26,240
just trying to get up we catch up with

00:04:23,310 --> 00:04:26,240
the code right so

00:04:26,460 --> 00:04:32,550
so here's I'm going to go in a little

00:04:28,740 --> 00:04:35,160
bit of digression so if when I adopted

00:04:32,550 --> 00:04:36,479
my learning hat I thought well what is

00:04:35,160 --> 00:04:38,370
the new developer coming in the clouds

00:04:36,479 --> 00:04:40,169
that kind of thing what if we they are

00:04:38,370 --> 00:04:41,220
trying to attack the same problem are

00:04:40,169 --> 00:04:44,550
they going to put the code into

00:04:41,220 --> 00:04:46,620
CloudStack or they are they not and it

00:04:44,550 --> 00:04:48,539
in and you realize that it can be

00:04:46,620 --> 00:04:50,099
intimidating right i mean there's so

00:04:48,539 --> 00:04:51,840
many features in cloudstack you don't

00:04:50,099 --> 00:04:54,120
know where exactly to put your service

00:04:51,840 --> 00:04:57,330
and get scared that you might break

00:04:54,120 --> 00:05:02,910
something as a long review process and

00:04:57,330 --> 00:05:05,639
then what if I don't like Java right and

00:05:02,910 --> 00:05:08,130
then I read another article about about

00:05:05,639 --> 00:05:11,130
the internet and their talks about the

00:05:08,130 --> 00:05:13,729
narrow waist of the internet and if you

00:05:11,130 --> 00:05:16,080
look at it like an hourglass you got a

00:05:13,729 --> 00:05:17,699
plethora of protocols at the physical

00:05:16,080 --> 00:05:20,669
layer ethernet and copper or fiber

00:05:17,699 --> 00:05:23,400
Ethernet whatever right and at the top

00:05:20,669 --> 00:05:26,400
you have a again a profusion of

00:05:23,400 --> 00:05:28,650
protocols which solves specific unique

00:05:26,400 --> 00:05:33,750
problems but right at the middle is the

00:05:28,650 --> 00:05:35,479
IP layer and the IP layer is hard to

00:05:33,750 --> 00:05:38,070
change people have tried to change it

00:05:35,479 --> 00:05:40,440
there's been several attempts to do like

00:05:38,070 --> 00:05:41,909
a internet to or internet three but it

00:05:40,440 --> 00:05:45,539
still hasn't changed because it's so

00:05:41,909 --> 00:05:47,610
damn hard to change right so if you

00:05:45,539 --> 00:05:50,930
think about apply the same apache

00:05:47,610 --> 00:05:53,490
cloudstack you have the acs core which

00:05:50,930 --> 00:05:57,690
alex described a couple of toxic oil in

00:05:53,490 --> 00:05:59,460
great detail you have a lower end the

00:05:57,690 --> 00:06:02,820
the technology which is you know the

00:05:59,460 --> 00:06:04,289
hypervisor is SD andy and then you'll

00:06:02,820 --> 00:06:06,150
find a lot of talks about talking about

00:06:04,289 --> 00:06:09,900
how they how people are integrating

00:06:06,150 --> 00:06:11,940
their technologies in to acs and then at

00:06:09,900 --> 00:06:15,360
the top you have services built on top

00:06:11,940 --> 00:06:18,479
of acs right so is it load balancing or

00:06:15,360 --> 00:06:22,349
dbe as stack mate which is going on in

00:06:18,479 --> 00:06:29,190
the adjacent room there if you want to

00:06:22,349 --> 00:06:30,810
build a pass and and and then compared

00:06:29,190 --> 00:06:33,479
to doing stuff at the top or the bottom

00:06:30,810 --> 00:06:35,190
acs core is a little hard to change but

00:06:33,479 --> 00:06:36,990
then the question becomes i'm going to

00:06:35,190 --> 00:06:39,950
do monitoring as a service or auto scale

00:06:36,990 --> 00:06:42,080
as a service where should I put my coat

00:06:39,950 --> 00:06:43,490
you know should it be in the ACS core or

00:06:42,080 --> 00:06:50,480
should it be on the top or should be at

00:06:43,490 --> 00:06:54,080
the bottom so to to make you think even

00:06:50,480 --> 00:06:56,360
more deeply so today if you look at how

00:06:54,080 --> 00:06:58,910
card stack uses the virtual router and

00:06:56,360 --> 00:07:02,900
it's almost like magic right i create a

00:06:58,910 --> 00:07:05,450
network CloudStack has internal api's

00:07:02,900 --> 00:07:10,400
into into services internally to acs

00:07:05,450 --> 00:07:13,460
which you never see which magically

00:07:10,400 --> 00:07:15,920
creates the virtual router vm configures

00:07:13,460 --> 00:07:21,620
it and then its present it's ready for

00:07:15,920 --> 00:07:23,420
you to use right and it's as a consumer

00:07:21,620 --> 00:07:26,090
of the API I just love it I mean it just

00:07:23,420 --> 00:07:29,120
it just works on us magically about all

00:07:26,090 --> 00:07:31,730
these services running for me but as a

00:07:29,120 --> 00:07:33,650
developer it's a little bit challenging

00:07:31,730 --> 00:07:37,100
now I say ok I want to make some changes

00:07:33,650 --> 00:07:39,020
to this magic it's hard right there's

00:07:37,100 --> 00:07:40,820
fiddly scripts there there's

00:07:39,020 --> 00:07:42,320
interactions between different services

00:07:40,820 --> 00:07:47,270
you don't know what you're going to

00:07:42,320 --> 00:07:52,550
break or if you look at this model let's

00:07:47,270 --> 00:07:54,650
say I do create a network but a seus

00:07:52,550 --> 00:07:57,260
does not just creates the network object

00:07:54,650 --> 00:08:00,320
and then there's this VR service which

00:07:57,260 --> 00:08:06,290
is running outside of acs which now

00:08:00,320 --> 00:08:09,410
calls the trick vm api and then the VR

00:08:06,290 --> 00:08:11,180
interaction with that VR service now if

00:08:09,410 --> 00:08:13,580
you were a developer you say feel

00:08:11,180 --> 00:08:15,440
confident about mucking around with the

00:08:13,580 --> 00:08:16,940
VR service because you're pretty

00:08:15,440 --> 00:08:20,390
confident that you're not affecting the

00:08:16,940 --> 00:08:22,640
rest of acs but as an end user or a

00:08:20,390 --> 00:08:25,520
consumer you're like God I got to start

00:08:22,640 --> 00:08:28,610
our frustrating with two api's now I got

00:08:25,520 --> 00:08:30,110
to deploy two services I gotta do a che

00:08:28,610 --> 00:08:34,250
and state maintenance for two different

00:08:30,110 --> 00:08:38,090
services that's a pain so i'm trying to

00:08:34,250 --> 00:08:40,430
illustrate there's a design balance

00:08:38,090 --> 00:08:42,919
between usability and maintainability

00:08:40,430 --> 00:08:44,480
which you have to think about anytime

00:08:42,919 --> 00:08:51,560
you want to introduce a new service into

00:08:44,480 --> 00:08:53,660
intercloud stack and in and wait

00:08:51,560 --> 00:08:55,490
industry is talking about

00:08:53,660 --> 00:08:57,470
follow this called microservices and

00:08:55,490 --> 00:08:59,660
there's a interesting blog by martin

00:08:57,470 --> 00:09:01,970
fowler about this where you design

00:08:59,660 --> 00:09:04,480
software applications as sweet so

00:09:01,970 --> 00:09:07,279
independently de pliable services so

00:09:04,480 --> 00:09:09,939
instead of acs corey could imagine the

00:09:07,279 --> 00:09:12,470
20 different services each of them

00:09:09,939 --> 00:09:16,100
responsible one for virtual machine one

00:09:12,470 --> 00:09:19,129
for host 14 account and then all their

00:09:16,100 --> 00:09:24,319
interacting using rest api and not an

00:09:19,129 --> 00:09:25,759
in-memory model its controversial it's

00:09:24,319 --> 00:09:27,889
not exactly service-oriented

00:09:25,759 --> 00:09:31,490
architecture where it's one step further

00:09:27,889 --> 00:09:33,019
and and cardstock has rightly been

00:09:31,490 --> 00:09:36,410
described if you look at the mattress

00:09:33,019 --> 00:09:40,220
offices model cloudstack is a monolith

00:09:36,410 --> 00:09:43,420
because its runs in one jbm and and that

00:09:40,220 --> 00:09:45,680
brings some disadvantages change is hard

00:09:43,420 --> 00:09:49,220
that is what we've been working two

00:09:45,680 --> 00:09:51,139
years to make it easier to change it but

00:09:49,220 --> 00:09:52,339
if you put yourselves into cloudstack

00:09:51,139 --> 00:09:54,589
you automatically get a bunch of stuff

00:09:52,339 --> 00:09:57,220
you get horizontal scale heart laying

00:09:54,589 --> 00:10:00,889
api monitoring everything comes for free

00:09:57,220 --> 00:10:02,300
and then if you just if you introduce

00:10:00,889 --> 00:10:04,880
the service and then you're saying well

00:10:02,300 --> 00:10:06,680
maybe it's not the right design you just

00:10:04,880 --> 00:10:09,939
go to eclipse and do the refactoring and

00:10:06,680 --> 00:10:12,680
then it's done right in a micro service

00:10:09,939 --> 00:10:14,089
typically the model is I don't like the

00:10:12,680 --> 00:10:17,810
service I throw away the cord and write

00:10:14,089 --> 00:10:19,459
a new service and i can write it in any

00:10:17,810 --> 00:10:21,259
language and i can use any database i

00:10:19,459 --> 00:10:24,259
want i don't really care about what the

00:10:21,259 --> 00:10:26,089
other services are doing and there's a

00:10:24,259 --> 00:10:30,079
disadvantage is that which you can read

00:10:26,089 --> 00:10:31,310
in martin follows blog so that these are

00:10:30,079 --> 00:10:32,839
the two extremes where it's immoral

00:10:31,310 --> 00:10:35,449
earth versus microservice now so let's

00:10:32,839 --> 00:10:37,130
look at what Amazon's done their service

00:10:35,449 --> 00:10:39,259
boundaries are defined by a PR in points

00:10:37,130 --> 00:10:43,040
so they have an ec2 endpoint auto scale

00:10:39,259 --> 00:10:44,660
and point cloud watch lv but not for VPC

00:10:43,040 --> 00:10:50,209
not to elastically nothing like that

00:10:44,660 --> 00:10:52,220
right so so that gives us a useful

00:10:50,209 --> 00:10:55,850
starting point about how to structure

00:10:52,220 --> 00:10:58,730
your service so now look let's look at

00:10:55,850 --> 00:11:01,430
how I designed stack watch as I said I

00:10:58,730 --> 00:11:02,870
didn't want to use Java and I use

00:11:01,430 --> 00:11:06,170
actually use the language called closure

00:11:02,870 --> 00:11:07,629
which is a JVM language but it's not

00:11:06,170 --> 00:11:11,329
java

00:11:07,629 --> 00:11:13,759
szostak watch is a closure task or

00:11:11,329 --> 00:11:17,449
process it runs our soundcloud check and

00:11:13,759 --> 00:11:22,639
then you can apply the cloud watch api's

00:11:17,449 --> 00:11:25,149
into stack watch and it has its own my

00:11:22,639 --> 00:11:27,739
sequel database to store metadata like

00:11:25,149 --> 00:11:31,999
the alarms are interested in the metrics

00:11:27,739 --> 00:11:34,009
and in order to authenticate the user it

00:11:31,999 --> 00:11:36,739
uses the cloud credentials from

00:11:34,009 --> 00:11:39,290
cloudstack so now remember you're

00:11:36,739 --> 00:11:42,199
getting a million API calls in to stack

00:11:39,290 --> 00:11:44,269
watch a minute and we are going to

00:11:42,199 --> 00:11:45,949
authenticate each of these calls so it's

00:11:44,269 --> 00:11:50,689
better to cash those credentials once

00:11:45,949 --> 00:11:52,910
you get it from card stack and then in

00:11:50,689 --> 00:11:55,549
order to store these metrics at a very

00:11:52,910 --> 00:11:57,589
fine fidelity for a long time we used I

00:11:55,549 --> 00:12:00,649
use something called open TS DB which is

00:11:57,589 --> 00:12:04,999
a another open source project which uses

00:12:00,649 --> 00:12:06,739
HBase as a back-end and to get alarms or

00:12:04,999 --> 00:12:09,109
threshold crossing I use another high

00:12:06,739 --> 00:12:12,019
performance training process process

00:12:09,109 --> 00:12:14,209
called Riemann so now you can see that

00:12:12,019 --> 00:12:20,079
there's a at least three different

00:12:14,209 --> 00:12:23,749
processes running here open T is DB is a

00:12:20,079 --> 00:12:26,749
transfer open time series data base it's

00:12:23,749 --> 00:12:28,459
a front-end Apache HBase and it's

00:12:26,749 --> 00:12:31,549
capable of storing billions of data

00:12:28,459 --> 00:12:34,059
points so if you want to store metrics

00:12:31,549 --> 00:12:37,730
for a whole year you could do that with

00:12:34,059 --> 00:12:41,059
with with open th DB you could use

00:12:37,730 --> 00:12:43,369
something like AR AR DS but arteries are

00:12:41,059 --> 00:12:45,769
going to start summarizing your

00:12:43,369 --> 00:12:49,850
information as soon as there's no space

00:12:45,769 --> 00:12:51,829
left to story already right but with

00:12:49,850 --> 00:12:53,360
something like open th DV you could

00:12:51,829 --> 00:12:56,360
store it indefinitely at any for any

00:12:53,360 --> 00:12:59,829
fidelity that you want and it's scalable

00:12:56,360 --> 00:13:02,569
and it's reliable because it's HBase

00:12:59,829 --> 00:13:04,549
Riemann is another open source project

00:13:02,569 --> 00:13:06,379
with the Eclipse license and it's

00:13:04,549 --> 00:13:07,730
designed as a stream process and there's

00:13:06,379 --> 00:13:12,109
a bunch of other stream processors that

00:13:07,730 --> 00:13:15,439
I could have used theirs Esper as Apache

00:13:12,109 --> 00:13:16,970
storm but this was appealed to me

00:13:15,439 --> 00:13:18,350
because it was designed it as a single

00:13:16,970 --> 00:13:19,640
process and it's designed as

00:13:18,350 --> 00:13:23,000
infrastructure money

00:13:19,640 --> 00:13:26,300
and I use this to generate the alarms

00:13:23,000 --> 00:13:28,400
back into stack watch so that stack

00:13:26,300 --> 00:13:31,370
watch can then pass those alarms on to

00:13:28,400 --> 00:13:33,260
the art scale engine this is what it

00:13:31,370 --> 00:13:36,440
looks like from the left hand side

00:13:33,260 --> 00:13:38,630
you're getting events from you know

00:13:36,440 --> 00:13:41,330
metrics about your CPU memory disk or

00:13:38,630 --> 00:13:43,400
whatever your app metrics are comes in

00:13:41,330 --> 00:13:46,100
to remain he tell you apply some

00:13:43,400 --> 00:13:47,930
algorithms decides what's interesting

00:13:46,100 --> 00:13:51,050
what events interesting and then it

00:13:47,930 --> 00:13:52,940
sends out alerts or a pluggable engine

00:13:51,050 --> 00:13:57,740
at the right hand side to do whatever

00:13:52,940 --> 00:14:00,680
you wanted to do here's an example of

00:13:57,740 --> 00:14:04,520
the it's got a domain-specific language

00:14:00,680 --> 00:14:07,160
where you can configure it to generate

00:14:04,520 --> 00:14:11,360
the alarm here's an example this is

00:14:07,160 --> 00:14:13,310
actually close your code this will send

00:14:11,360 --> 00:14:20,480
out a email if there's a threshold

00:14:13,310 --> 00:14:23,090
crossing on your request latency so

00:14:20,480 --> 00:14:25,010
szostak watch site is just a front end

00:14:23,090 --> 00:14:28,610
it's an API front end it knows how to do

00:14:25,010 --> 00:14:32,300
the Amazon API it stores metric metadata

00:14:28,610 --> 00:14:34,670
in my sequel and then it does the AP

00:14:32,300 --> 00:14:38,180
authentication using signatures using

00:14:34,670 --> 00:14:39,920
data it fetches from cloudstack and I

00:14:38,180 --> 00:14:44,060
wrote it in clojure because I thought I

00:14:39,920 --> 00:14:46,190
wanted to run it in the same jvm as the

00:14:44,060 --> 00:14:48,680
as Riemann but that turned out to be a

00:14:46,190 --> 00:14:52,510
wrong assumption but anyway I learned

00:14:48,680 --> 00:14:56,750
something here so what happens is that

00:14:52,510 --> 00:14:59,090
the the Amazon API comes in this is what

00:14:56,750 --> 00:15:01,280
the the CLI looks in if you want to

00:14:59,090 --> 00:15:05,630
insert a particular metric intercloud

00:15:01,280 --> 00:15:07,760
watch it this is a the request latency

00:15:05,630 --> 00:15:10,580
for a web front-end you give it the

00:15:07,760 --> 00:15:15,530
timestamp you give it some tags and end

00:15:10,580 --> 00:15:18,320
the value this gets sent into open TSD

00:15:15,530 --> 00:15:21,100
be and the PSDB has to AP as you can use

00:15:18,320 --> 00:15:24,190
it can use a telnet like api or rest api

00:15:21,100 --> 00:15:27,140
we send it and it stores it in there and

00:15:24,190 --> 00:15:29,570
then Riemann has an API as well which is

00:15:27,140 --> 00:15:30,920
based on portal buff and then we can

00:15:29,570 --> 00:15:32,100
send it in agreement and the Riemann

00:15:30,920 --> 00:15:38,790
concerned alarms

00:15:32,100 --> 00:15:40,769
back to stack watch so the so the only

00:15:38,790 --> 00:15:43,769
point of integration of stack watch and

00:15:40,769 --> 00:15:48,860
CloudStack is the user credentials and

00:15:43,769 --> 00:15:51,209
and views this API called get user and

00:15:48,860 --> 00:15:52,949
then once we get the user we have the

00:15:51,209 --> 00:15:56,579
account uuid and then we can start

00:15:52,949 --> 00:15:58,920
storing data in stack watch tagged with

00:15:56,579 --> 00:16:03,630
that account to you ID and so there is

00:15:58,920 --> 00:16:06,600
no foreign key relationship with cloud

00:16:03,630 --> 00:16:09,540
stacks databases but there's an implicit

00:16:06,600 --> 00:16:12,269
foreign key based on the uuid right and

00:16:09,540 --> 00:16:15,240
so if I now wanted to say well what are

00:16:12,269 --> 00:16:16,980
the alarms that belong to me I could use

00:16:15,240 --> 00:16:19,829
my account you your ID and find it

00:16:16,980 --> 00:16:27,569
instead of instead of doing a sequel

00:16:19,829 --> 00:16:31,649
join inside Clark stacks database so the

00:16:27,569 --> 00:16:35,639
current status for stack watch it's

00:16:31,649 --> 00:16:38,430
written as a cloture web app the

00:16:35,639 --> 00:16:40,259
intention is to scale to a million event

00:16:38,430 --> 00:16:42,060
per minute I have not tested it I don't

00:16:40,259 --> 00:16:45,899
have the infrastructure to test that

00:16:42,060 --> 00:16:48,480
kind of stuff I got a handful of ApS at

00:16:45,899 --> 00:16:50,399
work you can put the metric data it goes

00:16:48,480 --> 00:16:53,189
into Riemann and open T is DV you can

00:16:50,399 --> 00:16:56,939
list your metrics and it you can fetch

00:16:53,189 --> 00:16:59,759
some graphs from opened estb there's no

00:16:56,939 --> 00:17:05,429
web UI was not that was not my intention

00:16:59,759 --> 00:17:07,260
of this project and so but if you

00:17:05,429 --> 00:17:10,319
remember my motivation was to start with

00:17:07,260 --> 00:17:13,829
auto scale and I never actually got

00:17:10,319 --> 00:17:16,919
around to doing it but if I were to do

00:17:13,829 --> 00:17:19,740
it since I got this idea of doing stuff

00:17:16,919 --> 00:17:22,350
outside of cloudstack here's one way I

00:17:19,740 --> 00:17:24,480
might have done it I would have written

00:17:22,350 --> 00:17:31,799
it as a ruby on rails app remember this

00:17:24,480 --> 00:17:34,890
is not a high-performance API I would

00:17:31,799 --> 00:17:40,250
implement all the auto scale api's that

00:17:34,890 --> 00:17:41,950
are needed stored in a separate database

00:17:40,250 --> 00:17:43,870
again

00:17:41,950 --> 00:17:47,020
use the get user iker I from cloudstack

00:17:43,870 --> 00:17:51,010
authenticate the API store the

00:17:47,020 --> 00:17:52,780
credentials as before in a cash send the

00:17:51,010 --> 00:17:54,880
alarm configuration to stack watch and

00:17:52,780 --> 00:17:58,900
the stack watch would send me back

00:17:54,880 --> 00:18:02,650
threshold alarms and then i would call

00:17:58,900 --> 00:18:04,900
cloud stacks and use API deploy vm list

00:18:02,650 --> 00:18:08,650
vm exit strategy to actually deploy the

00:18:04,900 --> 00:18:11,170
VMS and the all the interactions here

00:18:08,650 --> 00:18:14,380
would be using the public API right it's

00:18:11,170 --> 00:18:16,500
all authenticated it's all that it can

00:18:14,380 --> 00:18:20,140
be over the network or inside the same

00:18:16,500 --> 00:18:28,950
host what your the api's are coming all

00:18:20,140 --> 00:18:33,520
the network instead of in process so I

00:18:28,950 --> 00:18:35,080
learned some lessons and here's the huge

00:18:33,520 --> 00:18:37,090
here they are so if you're using a

00:18:35,080 --> 00:18:40,780
service oriented architecture like I

00:18:37,090 --> 00:18:44,380
showed it's easy to do rapid prototyping

00:18:40,780 --> 00:18:46,480
and evolution I did not have to you know

00:18:44,380 --> 00:18:51,100
synchronize it Apache master more than

00:18:46,480 --> 00:18:52,540
you know a couple of times a month you

00:18:51,100 --> 00:18:55,510
can use your favorite language if you

00:18:52,540 --> 00:18:58,080
needed to and use the appropriate

00:18:55,510 --> 00:19:00,600
framework right i mean HBase is a

00:18:58,080 --> 00:19:03,880
database which club track does not use

00:19:00,600 --> 00:19:09,700
now you want to use it and so this is a

00:19:03,880 --> 00:19:11,440
useful way of doing it and and then

00:19:09,700 --> 00:19:13,780
maybe you want to use some open source

00:19:11,440 --> 00:19:15,280
project which is not compatible with

00:19:13,780 --> 00:19:19,770
license wise you at Apache CloudStack

00:19:15,280 --> 00:19:19,770
and so that's one other way way to do it

00:19:19,830 --> 00:19:23,980
but then what I found was that I just

00:19:22,570 --> 00:19:26,440
had to do a lot of the Act shaving I had

00:19:23,980 --> 00:19:28,300
to reinvent API validation parsing and

00:19:26,440 --> 00:19:30,550
authentication and that took a lot of

00:19:28,300 --> 00:19:33,960
time I mean it was already done in club

00:19:30,550 --> 00:19:37,120
stat but then I had to do it again and

00:19:33,960 --> 00:19:40,510
then you know how do i deployed how do i

00:19:37,120 --> 00:19:42,760
exchange keys with cloudstack how do I

00:19:40,510 --> 00:19:45,850
just suddenly have six different

00:19:42,760 --> 00:19:49,060
services how do i deploy it so that it's

00:19:45,850 --> 00:19:51,970
easy to deploy maintain our grade and

00:19:49,060 --> 00:19:54,490
then if you wanted a unified you I well

00:19:51,970 --> 00:19:54,990
how would you do it across two different

00:19:54,490 --> 00:19:58,080
endpoint

00:19:54,990 --> 00:20:02,460
so it threw up more questions but these

00:19:58,080 --> 00:20:07,020
are questions to be solved as a as a

00:20:02,460 --> 00:20:08,429
design point but I felt that at least

00:20:07,020 --> 00:20:12,170
from the performance perspective it was

00:20:08,429 --> 00:20:12,170
useful to run this as a separate service

00:20:13,670 --> 00:20:18,240
some of the things I might do in the

00:20:15,960 --> 00:20:22,340
future in my minus ten percent time I

00:20:18,240 --> 00:20:24,540
might test metric insertion at scale

00:20:22,340 --> 00:20:28,290
finish the support for the complete

00:20:24,540 --> 00:20:36,150
cloud watch EP I and then maybe even

00:20:28,290 --> 00:20:41,210
work on the auto scale cells so the the

00:20:36,150 --> 00:20:43,410
lessons learnt where when do you want or

00:20:41,210 --> 00:20:45,510
the questions I want you to think about

00:20:43,410 --> 00:20:48,740
our when do you want to run it as a

00:20:45,510 --> 00:20:51,320
separate service opponent Apache Corp

00:20:48,740 --> 00:20:55,350
one is you don't want to code in Java

00:20:51,320 --> 00:20:58,679
that that question is obvious you can't

00:20:55,350 --> 00:21:01,559
put a CS so it run it as a separate

00:20:58,679 --> 00:21:02,850
service second point is that your

00:21:01,559 --> 00:21:05,040
requirements are not clear you don't

00:21:02,850 --> 00:21:08,100
know what you want to do are your

00:21:05,040 --> 00:21:10,350
requirements fuzzy it's really going to

00:21:08,100 --> 00:21:13,980
be really hard to start prototyping that

00:21:10,350 --> 00:21:15,390
in Apache master right so maybe you want

00:21:13,980 --> 00:21:19,110
to start writing it as a separate

00:21:15,390 --> 00:21:21,210
service when your firm on the the design

00:21:19,110 --> 00:21:24,210
details and then you can move it back

00:21:21,210 --> 00:21:25,770
into Apache CloudStack maybe your

00:21:24,210 --> 00:21:27,270
audience is different your cloud

00:21:25,770 --> 00:21:31,040
operator is different from your database

00:21:27,270 --> 00:21:31,040
operator right so it's a different

00:21:32,390 --> 00:21:40,170
community that you're selling to and

00:21:37,700 --> 00:21:42,750
then if you can do stuff with the

00:21:40,170 --> 00:21:44,750
existing API like you saw that you know

00:21:42,750 --> 00:21:48,720
auto scale could use the existing API

00:21:44,750 --> 00:21:51,080
why not do it as a separate service or

00:21:48,720 --> 00:21:53,670
your service as a niche need which

00:21:51,080 --> 00:21:56,520
nobody else needs I mean there was a

00:21:53,670 --> 00:21:59,700
request the other day that hey I want to

00:21:56,520 --> 00:22:01,650
monitor all the hosts in my data center

00:21:59,700 --> 00:22:05,130
and then patch them when they given the

00:22:01,650 --> 00:22:07,950
god of patch validation is that Apache

00:22:05,130 --> 00:22:08,790
core a CS core I don't think so so you

00:22:07,950 --> 00:22:12,030
would run

00:22:08,790 --> 00:22:13,980
purses or you have some favorite package

00:22:12,030 --> 00:22:16,530
that you want to use that is

00:22:13,980 --> 00:22:20,610
incompatible with apache license so

00:22:16,530 --> 00:22:22,650
you've run it as a separate service case

00:22:20,610 --> 00:22:26,160
we're in process service is as strong as

00:22:22,650 --> 00:22:27,540
well you get a Puritan community there's

00:22:26,160 --> 00:22:31,320
lots of people using it all the time

00:22:27,540 --> 00:22:33,150
testing it all the time and then

00:22:31,320 --> 00:22:35,750
especially if the operation run envelope

00:22:33,150 --> 00:22:39,240
whether it's how you back it up how you

00:22:35,750 --> 00:22:41,660
upgrade it etc is the same as a patchy

00:22:39,240 --> 00:22:46,110
cloud stack then it's a good fit for

00:22:41,660 --> 00:22:48,510
coding inside Apache CloudStack or you

00:22:46,110 --> 00:22:49,830
know the public API is insufficient you

00:22:48,510 --> 00:22:53,220
need access to the internal ap has

00:22:49,830 --> 00:22:55,110
internal tables then you know but you I

00:22:53,220 --> 00:22:58,920
would consider enhancing the public API

00:22:55,110 --> 00:23:00,780
first for that and some reasons why you

00:22:58,920 --> 00:23:03,660
might want to do it but they're not good

00:23:00,780 --> 00:23:05,130
enough reasons you want to reuse some of

00:23:03,660 --> 00:23:10,050
the stuff that clutch that gives you

00:23:05,130 --> 00:23:12,870
like clustering or UI plugins or you

00:23:10,050 --> 00:23:16,230
want you you feel that you want a join

00:23:12,870 --> 00:23:18,030
with the existing table these are not

00:23:16,230 --> 00:23:20,850
strong enough reasons to put it in an

00:23:18,030 --> 00:23:27,540
Apache core you should consider doing it

00:23:20,850 --> 00:23:31,830
as a separate service and some of the

00:23:27,540 --> 00:23:34,620
niche examples of seen are as I said the

00:23:31,830 --> 00:23:36,540
hypervisor patching service one way to

00:23:34,620 --> 00:23:39,390
do it is that you just use the admin API

00:23:36,540 --> 00:23:42,330
to retrieve the host details run a

00:23:39,390 --> 00:23:45,020
service which poles each hypervisor once

00:23:42,330 --> 00:23:47,010
a day and then apply a patching serviced

00:23:45,020 --> 00:23:50,250
you want to integrate with the data

00:23:47,010 --> 00:23:53,580
center monitoring or CMD be again use

00:23:50,250 --> 00:23:57,720
the admin api's to do that you can use

00:23:53,580 --> 00:23:59,160
the events API to do that you want to do

00:23:57,720 --> 00:24:03,830
some kind of real time reporting

00:23:59,160 --> 00:24:07,500
correlation again it's probably not

00:24:03,830 --> 00:24:09,300
Gortat stack so do it outside somebody

00:24:07,500 --> 00:24:11,340
does we wanted to do spot pricing and

00:24:09,300 --> 00:24:13,650
that's totally you know something you

00:24:11,340 --> 00:24:17,330
can easily run outside clouds like just

00:24:13,650 --> 00:24:17,330
using the clouds like api's

00:24:19,480 --> 00:24:27,950
here are some references for you guys

00:24:22,820 --> 00:24:31,520
and I would recommend Martin Fowler's

00:24:27,950 --> 00:24:33,550
blog and also before you caught up with

00:24:31,520 --> 00:24:37,040
separate service read the fallacies of

00:24:33,550 --> 00:24:38,870
distributed computing you know when

00:24:37,040 --> 00:24:41,060
you're a programmer you assume that the

00:24:38,870 --> 00:24:42,440
network is always reliable like your

00:24:41,060 --> 00:24:47,140
package they're going to get across in

00:24:42,440 --> 00:24:50,210
in in in in a finite amount of time that

00:24:47,140 --> 00:24:51,890
never happens or it happens maybe ninety

00:24:50,210 --> 00:24:53,150
nine percent of the time would you had

00:24:51,890 --> 00:24:57,350
write code with the one percent whole

00:24:53,150 --> 00:25:03,710
time and don't search for narrow waist

00:24:57,350 --> 00:25:20,870
model on Google at least not at work any

00:25:03,710 --> 00:25:22,790
questions so the question is who is

00:25:20,870 --> 00:25:27,770
actually doing the application metric

00:25:22,790 --> 00:25:32,270
perform so if you go back to the way you

00:25:27,770 --> 00:25:34,840
insert the metric is this man put data

00:25:32,270 --> 00:25:38,450
so let's say your application as a

00:25:34,840 --> 00:25:41,750
typically your application has

00:25:38,450 --> 00:25:44,480
well-defined metric collection point at

00:25:41,750 --> 00:25:46,550
your if you're running a java service

00:25:44,480 --> 00:25:48,830
for instance then you could have a

00:25:46,550 --> 00:25:52,040
filter in your servlet which measures

00:25:48,830 --> 00:25:55,400
request latency right and so that

00:25:52,040 --> 00:26:00,460
service would then use the card watch

00:25:55,400 --> 00:26:00,460
API to send that data to cloud watch

00:26:25,770 --> 00:26:29,300

YouTube URL: https://www.youtube.com/watch?v=j2KMko8_Dao


