Title: Monitoring of CloudStack
Publication date: 2019-09-20
Playlist: ApacheCon 2019, Cloudstack Collaboration Conference
Description: 
	Our approach of monitoring the CloudStack management server, parts of CloudStacks ecosystem and its underlying components. We give an introduction of how to monitor virtual routers, customer systems and customer resources in CloudStack.
Captions: 
	00:00:04,570 --> 00:00:12,389
hi and welcome to my talk about

00:00:07,620 --> 00:00:15,340
monitoring of cloud tech and components

00:00:12,389 --> 00:00:17,920
maybe at first some facts about me my

00:00:15,340 --> 00:00:20,020
name is Alexander stock I'm working as a

00:00:17,920 --> 00:00:22,930
cloud infrastructure architect at

00:00:20,020 --> 00:00:26,800
engines and over the years I have

00:00:22,930 --> 00:00:30,250
collected some experience with VMware

00:00:26,800 --> 00:00:32,920
KVM Nagios and of course with cloud

00:00:30,250 --> 00:00:36,250
stack so I'm working with Cloud State

00:00:32,920 --> 00:00:39,660
since roundabout 2015 I think this was

00:00:36,250 --> 00:00:43,270
version 4.6

00:00:39,660 --> 00:00:45,240
some sigh facts about our company we're

00:00:43,270 --> 00:00:49,150
hosting also some events in the area of

00:00:45,240 --> 00:00:52,270
Dre's and Berlin for clouds deck and the

00:00:49,150 --> 00:00:54,460
bull and SEF and if you want to contact

00:00:52,270 --> 00:00:56,530
me after the presentation there's my

00:00:54,460 --> 00:01:00,720
business mail address so if we have

00:00:56,530 --> 00:01:00,720
questions afterwards you can contact me

00:01:02,430 --> 00:01:09,430
some facts about our company so we were

00:01:05,229 --> 00:01:11,320
founded in 1989 in Germany we have now

00:01:09,430 --> 00:01:14,530
about seven thousand nine hundred

00:01:11,320 --> 00:01:16,900
employees around the globe so we have 25

00:01:14,530 --> 00:01:20,350
offices in 25 countries around the world

00:01:16,900 --> 00:01:22,420
for example in the u.s. in Canada of

00:01:20,350 --> 00:01:27,130
course in Germany and also in many

00:01:22,420 --> 00:01:31,870
countries in Asia we our main business

00:01:27,130 --> 00:01:34,030
is the development in consulting and yet

00:01:31,870 --> 00:01:36,580
the support for SAV solutions for our

00:01:34,030 --> 00:01:40,240
customers and we currently have around

00:01:36,580 --> 00:01:45,700
about 6,000 customers which we deliver

00:01:40,240 --> 00:01:47,560
services to ok what do I want to show

00:01:45,700 --> 00:01:49,270
you today I want to give you an

00:01:47,560 --> 00:01:51,790
introduction of what we use for

00:01:49,270 --> 00:01:55,150
monitoring of our landscape and

00:01:51,790 --> 00:01:57,970
especially cloud stack and of course I

00:01:55,150 --> 00:02:00,280
will show you some insights how do we

00:01:57,970 --> 00:02:03,850
manage how do we monitor our management

00:02:00,280 --> 00:02:08,019
server components like MySQL tomcat and

00:02:03,850 --> 00:02:09,399
also the cloud stack API itself the next

00:02:08,019 --> 00:02:11,680
part will be about distributed

00:02:09,399 --> 00:02:13,950
monitoring so we have a distributed

00:02:11,680 --> 00:02:16,870
monitoring setup for our customers and

00:02:13,950 --> 00:02:18,360
the last part will be about monitoring

00:02:16,870 --> 00:02:21,090
virtual routers are owned by

00:02:18,360 --> 00:02:28,620
which is also based on distributed

00:02:21,090 --> 00:02:29,940
monitoring setup okay um at first I want

00:02:28,620 --> 00:02:32,850
to give you a short introduction of what

00:02:29,940 --> 00:02:35,610
is our cloud about so of course we use

00:02:32,850 --> 00:02:38,760
cloud stack as the heart an Orchestrator

00:02:35,610 --> 00:02:41,940
of our cloud system so we have an

00:02:38,760 --> 00:02:44,580
advanced networking setup with set as

00:02:41,940 --> 00:02:47,820
our storage back-end KVM as the

00:02:44,580 --> 00:02:50,310
hypervisor and the main purpose of our

00:02:47,820 --> 00:02:52,980
cloud is to deliver automated

00:02:50,310 --> 00:02:56,490
application setups especially for SMP

00:02:52,980 --> 00:02:59,870
systems like Hana s4 and also all three

00:02:56,490 --> 00:03:01,050
systems so this automation we use

00:02:59,870 --> 00:03:03,450
ansible

00:03:01,050 --> 00:03:05,130
so all our tasks for infrastructure

00:03:03,450 --> 00:03:08,340
setup and also for the application

00:03:05,130 --> 00:03:11,130
setups and we have a self written portal

00:03:08,340 --> 00:03:14,160
which abstracts away all the api's and

00:03:11,130 --> 00:03:17,880
tools we use in our landscape to give

00:03:14,160 --> 00:03:19,740
the user unique experience of one portal

00:03:17,880 --> 00:03:23,130
where you can trigger actions and

00:03:19,740 --> 00:03:25,170
install the systems so that means the

00:03:23,130 --> 00:03:30,600
customers don't have direct clastic

00:03:25,170 --> 00:03:32,970
access in our landscape so why do we

00:03:30,600 --> 00:03:35,880
monitor our cloud stack we wanted to

00:03:32,970 --> 00:03:38,730
identify and detect performance issues

00:03:35,880 --> 00:03:41,220
we want to detect misconfigurations

00:03:38,730 --> 00:03:44,459
also resource bottlenecks for the

00:03:41,220 --> 00:03:45,750
customer for for example and we get

00:03:44,459 --> 00:03:48,630
along we want to get a long time

00:03:45,750 --> 00:03:50,190
overview of our installations and all

00:03:48,630 --> 00:03:53,100
the surrounding components of cloud

00:03:50,190 --> 00:03:55,680
stack and also the status in detail of

00:03:53,100 --> 00:04:02,489
our virtual routers and of the system

00:03:55,680 --> 00:04:06,150
VMs what do we use for monitoring we use

00:04:02,489 --> 00:04:09,570
check MK check and K is the Nagios based

00:04:06,150 --> 00:04:11,820
monitoring solution which ships with a

00:04:09,570 --> 00:04:13,980
nice UI you can also see on the right

00:04:11,820 --> 00:04:16,320
side where you can have a complete

00:04:13,980 --> 00:04:17,760
overview of what's going on inside your

00:04:16,320 --> 00:04:20,100
landscape and also in the customer

00:04:17,760 --> 00:04:23,130
landscapes with this UI you can also

00:04:20,100 --> 00:04:25,590
manage your hosts and services and also

00:04:23,130 --> 00:04:28,050
create rules for thresholds and yeah

00:04:25,590 --> 00:04:30,930
settings for your monitoring system it

00:04:28,050 --> 00:04:31,510
combines the advantages of passive and

00:04:30,930 --> 00:04:35,020
active

00:04:31,510 --> 00:04:37,630
in the Nagios world and it has also some

00:04:35,020 --> 00:04:40,390
altar inventory functions for example

00:04:37,630 --> 00:04:42,040
when you add new storage to a VM or a

00:04:40,390 --> 00:04:44,290
new network interface it will be

00:04:42,040 --> 00:04:48,040
automatically detected and added to your

00:04:44,290 --> 00:04:51,130
monitoring system it has also scale out

00:04:48,040 --> 00:04:53,710
features so we have a master slave setup

00:04:51,130 --> 00:04:56,920
here and this is based on so called life

00:04:53,710 --> 00:04:58,780
status it's an alias core module which

00:04:56,920 --> 00:05:01,660
enables you to read data directly from

00:04:58,780 --> 00:05:03,250
the Nagios core without any file system

00:05:01,660 --> 00:05:07,650
in between so it's very resource

00:05:03,250 --> 00:05:10,960
friendly and fast it also ships with a

00:05:07,650 --> 00:05:13,750
high amount of predefined plugins which

00:05:10,960 --> 00:05:16,540
you can use for example for windows for

00:05:13,750 --> 00:05:19,750
linux and also for storage boxes like

00:05:16,540 --> 00:05:22,270
emc NetApp and you can also monitor

00:05:19,750 --> 00:05:26,310
Network Devices out of the ports Cisco

00:05:22,270 --> 00:05:34,600
f5 devices via SNMP or by a predefined

00:05:26,310 --> 00:05:37,930
api's the next thing is a big picture of

00:05:34,600 --> 00:05:41,680
the architecture of check MK so in the

00:05:37,930 --> 00:05:45,130
middle you can see the Nagios core which

00:05:41,680 --> 00:05:48,790
has below and on top the life status

00:05:45,130 --> 00:05:50,980
interface which acts as the unique data

00:05:48,790 --> 00:05:53,370
source for the surrounding tools in the

00:05:50,980 --> 00:05:56,170
check MK echo system that means the

00:05:53,370 --> 00:05:58,690
multi-site web platform uses live status

00:05:56,170 --> 00:06:02,380
as a data source and also nacreous for

00:05:58,690 --> 00:06:05,170
example and the underlying checks for

00:06:02,380 --> 00:06:08,830
check MK also using check the life

00:06:05,170 --> 00:06:10,750
status interface with the plug-in code

00:06:08,830 --> 00:06:14,080
also checking K which is shipped to of

00:06:10,750 --> 00:06:17,890
the system you can monitor your hosts by

00:06:14,080 --> 00:06:19,810
a few TCP connection by our SSH and also

00:06:17,890 --> 00:06:23,740
SNMP for some special devices like

00:06:19,810 --> 00:06:27,070
routers firewalls and storage boxes for

00:06:23,740 --> 00:06:29,140
example you can also use your legacy

00:06:27,070 --> 00:06:31,780
Nagios checks which you have used maybe

00:06:29,140 --> 00:06:39,820
before with your old set up and ya can

00:06:31,780 --> 00:06:41,950
continue using your own code here how

00:06:39,820 --> 00:06:45,070
chicken cake collected data from the

00:06:41,950 --> 00:06:47,500
hosts so at first you have geneco score

00:06:45,070 --> 00:06:50,230
of course which triggers an active check

00:06:47,500 --> 00:06:52,270
which calls the chicken Cade plugin this

00:06:50,230 --> 00:06:55,210
plugin will then connect to the target

00:06:52,270 --> 00:06:58,060
host we have configured and we'll start

00:06:55,210 --> 00:07:00,400
the ancient on that host so it's in most

00:06:58,060 --> 00:07:02,920
cases just the powershell script or -

00:07:00,400 --> 00:07:05,470
script on linux and the script will then

00:07:02,920 --> 00:07:07,870
collect the raw data of the host that

00:07:05,470 --> 00:07:12,580
means we just collect the metrics like

00:07:07,870 --> 00:07:15,280
the fill grade of a file system or the

00:07:12,580 --> 00:07:19,030
statistics of a network device and we'll

00:07:15,280 --> 00:07:21,910
send back this data to check and K

00:07:19,030 --> 00:07:25,570
hosts at lead to the plug-in which then

00:07:21,910 --> 00:07:28,020
will start to compute the results for

00:07:25,570 --> 00:07:31,720
the checks for each of the metrics and

00:07:28,020 --> 00:07:33,340
we send these passive or we'll send the

00:07:31,720 --> 00:07:37,030
results back as passive checks

00:07:33,340 --> 00:07:38,710
Juden Agra score also the RO DFAS will

00:07:37,030 --> 00:07:40,720
be written this is the format or the

00:07:38,710 --> 00:07:43,150
standard Nagios format for long term

00:07:40,720 --> 00:07:47,080
data you can get a long-term overview of

00:07:43,150 --> 00:07:49,780
your installations and this setup is

00:07:47,080 --> 00:07:51,880
very resource friendly so you just need

00:07:49,780 --> 00:07:54,960
one TCP connection to gather all the

00:07:51,880 --> 00:07:57,090
data of a host at once so it's very

00:07:54,960 --> 00:08:01,180
resource friendly also from the

00:07:57,090 --> 00:08:03,640
perspective and yeah this is the way

00:08:01,180 --> 00:08:09,100
check MK collects data from all the

00:08:03,640 --> 00:08:11,920
hosts so let's take a look at the core

00:08:09,100 --> 00:08:14,170
components of the management server so

00:08:11,920 --> 00:08:18,010
the first one here is the MySQL server

00:08:14,170 --> 00:08:20,650
which clastic relies on and also check

00:08:18,010 --> 00:08:23,050
in K has a predefined plugin for this

00:08:20,650 --> 00:08:25,540
year so you don't have to download from

00:08:23,050 --> 00:08:27,610
search party tools or something

00:08:25,540 --> 00:08:29,560
the installation is quite simple you

00:08:27,610 --> 00:08:33,669
just have to download the plugin to a

00:08:29,560 --> 00:08:37,360
specific folder you have to create a

00:08:33,669 --> 00:08:39,550
user which just says select writes on

00:08:37,360 --> 00:08:42,010
the database and you have to specify a

00:08:39,550 --> 00:08:45,640
contact file well give in the user and

00:08:42,010 --> 00:08:47,470
password of that specific user then the

00:08:45,640 --> 00:08:50,740
outer inventory fraction of check MK

00:08:47,470 --> 00:08:53,050
kicks in and with the next inventory run

00:08:50,740 --> 00:08:53,649
you will see checks for every database

00:08:53,050 --> 00:08:55,720
you have

00:08:53,649 --> 00:08:57,879
figured on your database host for

00:08:55,720 --> 00:09:00,879
example the cloud and the cloud usage

00:08:57,879 --> 00:09:04,420
database and you will also get checks

00:09:00,879 --> 00:09:06,279
for connection states for slave status

00:09:04,420 --> 00:09:10,389
when you have a replicated setup of your

00:09:06,279 --> 00:09:13,480
MySQL database you have annuity b io

00:09:10,389 --> 00:09:16,360
checks which detects the i/o throughput

00:09:13,480 --> 00:09:19,329
of your database engine yeah and this is

00:09:16,360 --> 00:09:22,569
all automatically detected via you check

00:09:19,329 --> 00:09:25,720
in k originality so i have a quite good

00:09:22,569 --> 00:09:30,519
overview on also for long term theta you

00:09:25,720 --> 00:09:36,309
can see on the right so you can monitor

00:09:30,519 --> 00:09:38,709
your database quite well the next core

00:09:36,309 --> 00:09:42,189
component of cloud stack is of course

00:09:38,709 --> 00:09:45,069
the tomcat server here checking k also

00:09:42,189 --> 00:09:48,730
provides a predefined plugin which is

00:09:45,069 --> 00:09:51,790
based on Jolokia so what is Jolokia it's

00:09:48,730 --> 00:09:53,709
some kind of tomcat extension this is

00:09:51,790 --> 00:09:56,110
some kind of war file if you have to add

00:09:53,709 --> 00:09:59,910
to your Tomcat installation which builds

00:09:56,110 --> 00:10:02,889
up an HTTP rich within which you can

00:09:59,910 --> 00:10:05,559
query data from the internals of tomcat

00:10:02,889 --> 00:10:07,389
it means you can get some statistics of

00:10:05,559 --> 00:10:09,579
the Tomcat server how many connections

00:10:07,389 --> 00:10:12,550
it has it has to handle at the moment

00:10:09,579 --> 00:10:24,309
and yeah also dd current sessions for

00:10:12,550 --> 00:10:26,410
specific URL question it's the standard

00:10:24,309 --> 00:10:29,800
way checking cake does it so it's it's

00:10:26,410 --> 00:10:32,860
the predefined yeah way to go for for

00:10:29,800 --> 00:10:34,839
that system but if you want you to go

00:10:32,860 --> 00:10:37,329
with J mix or something you also can

00:10:34,839 --> 00:10:41,110
define your own plugins and do it that

00:10:37,329 --> 00:10:43,329
way that should be no problem and yeah

00:10:41,110 --> 00:10:45,670
so the installation is quite similar to

00:10:43,329 --> 00:10:48,490
the MySQL check you just have to

00:10:45,670 --> 00:10:50,949
download the Chola Kiawah file the

00:10:48,490 --> 00:10:55,480
plugin and then use the auto inventory

00:10:50,949 --> 00:10:57,160
function on the management host to yeah

00:10:55,480 --> 00:10:59,649
get the checks into your into your

00:10:57,160 --> 00:11:01,990
monitoring system that means you will

00:10:59,649 --> 00:11:04,899
get the request and session checks for

00:11:01,990 --> 00:11:08,730
every URL which is hosted on the Tomcat

00:11:04,899 --> 00:11:08,730
service you will get checks for

00:11:09,180 --> 00:11:13,870
scavenged mark-sweep so for for garbage

00:11:11,500 --> 00:11:16,000
collection you would get a memory usage

00:11:13,870 --> 00:11:19,480
of the jvm processes and also you have

00:11:16,000 --> 00:11:22,629
some threat to checks automatically

00:11:19,480 --> 00:11:25,629
detected of course you have again the

00:11:22,629 --> 00:11:29,079
wrong term data so you can get an

00:11:25,629 --> 00:11:36,100
overview of me also the last month for

00:11:29,079 --> 00:11:39,100
the last weeks this was about the two

00:11:36,100 --> 00:11:42,759
core components cloud stack uses from a

00:11:39,100 --> 00:11:45,160
server perspective and we decided after

00:11:42,759 --> 00:11:47,410
this was finished that we need also some

00:11:45,160 --> 00:11:50,639
overview of what's going on inside cloud

00:11:47,410 --> 00:11:54,250
stack so we decided to develop a plugin

00:11:50,639 --> 00:11:56,230
to monitor specific parts of the cloud

00:11:54,250 --> 00:11:58,689
stack API to get an overview of what's

00:11:56,230 --> 00:12:01,509
going on inside cloud stack for example

00:11:58,689 --> 00:12:04,060
the connection status of a hypervisor

00:12:01,509 --> 00:12:07,209
the current status of virtual routers

00:12:04,060 --> 00:12:08,709
and also some capacity checks for

00:12:07,209 --> 00:12:12,360
example to get an overview of what is

00:12:08,709 --> 00:12:15,220
globally consumed in our installation

00:12:12,360 --> 00:12:17,259
it's a python-based plugin you can

00:12:15,220 --> 00:12:19,990
download also on github so when you want

00:12:17,259 --> 00:12:22,540
to give it a try you can download it

00:12:19,990 --> 00:12:24,939
there and it's also usable for plain

00:12:22,540 --> 00:12:31,689
agus installations as a simple active

00:12:24,939 --> 00:12:33,930
check if you want that ok let's take a

00:12:31,689 --> 00:12:37,300
look at the checks we have defined now

00:12:33,930 --> 00:12:39,699
so the first three checks or more of a

00:12:37,300 --> 00:12:41,949
status checks of objects defined in

00:12:39,699 --> 00:12:44,290
cloud stack it means for example the

00:12:41,949 --> 00:12:46,870
first one is the host status check which

00:12:44,290 --> 00:12:48,459
gathers the list of configured

00:12:46,870 --> 00:12:50,829
hypervisors from the cloud stack

00:12:48,459 --> 00:12:53,740
installation checks if the host is

00:12:50,829 --> 00:12:56,319
enabled if it's have an alert state or

00:12:53,740 --> 00:12:59,769
if it's maybe down and more reachable

00:12:56,319 --> 00:13:01,779
from the cloud stack management host the

00:12:59,769 --> 00:13:05,040
same for the system VM here we also

00:13:01,779 --> 00:13:09,220
check for allowed States and yeah for

00:13:05,040 --> 00:13:11,769
maybe system VM which is down and needs

00:13:09,220 --> 00:13:15,759
you have to be rebooted or to be

00:13:11,769 --> 00:13:18,279
replaced by a new one the last one is

00:13:15,759 --> 00:13:20,300
the virtual router check which gathers

00:13:18,279 --> 00:13:22,190
the list of virtual routers or

00:13:20,300 --> 00:13:24,170
you clouds the installation and checks

00:13:22,190 --> 00:13:26,300
also if your relatives are up and

00:13:24,170 --> 00:13:28,760
running and also if they need an upgrade

00:13:26,300 --> 00:13:34,520
after your cloud stack update maybe form

00:13:28,760 --> 00:13:36,800
for 11 to 412 and if you use red and NV

00:13:34,520 --> 00:13:39,470
PC setups it also checks if there is an

00:13:36,800 --> 00:13:42,440
active and the backup note for your V PC

00:13:39,470 --> 00:13:44,090
setup it informs you of course when one

00:13:42,440 --> 00:13:46,340
of the notes fails and gets a name

00:13:44,090 --> 00:13:52,700
square in a critical state he sends your

00:13:46,340 --> 00:14:00,760
mail the next three checks are capacity

00:13:52,700 --> 00:14:00,760
based checks sorry

00:14:01,190 --> 00:14:05,590
it's all by de classic a klutz the API

00:14:06,100 --> 00:14:13,040
sorry yeah sure every check is a good

00:14:11,060 --> 00:14:17,570
API paste so we don't access the cloud

00:14:13,040 --> 00:14:20,990
SEC database directly the next three

00:14:17,570 --> 00:14:22,940
checks or capacity checks - the first

00:14:20,990 --> 00:14:27,440
one is the standard capacity check which

00:14:22,940 --> 00:14:30,260
get those global resources you have or

00:14:27,440 --> 00:14:32,750
you you can use in your cloud so it's

00:14:30,260 --> 00:14:34,640
the same data you see when you log into

00:14:32,750 --> 00:14:37,100
cloud stack and see the landing page

00:14:34,640 --> 00:14:40,250
with the overview of the resources this

00:14:37,100 --> 00:14:42,080
is the data we collect here you also can

00:14:40,250 --> 00:14:45,500
define thresholds for that so you can be

00:14:42,080 --> 00:14:50,210
informed maybe when you have used 80% of

00:14:45,500 --> 00:14:52,880
your VLANs in your zone we can do the

00:14:50,210 --> 00:14:56,540
same thing for domain and projects so we

00:14:52,880 --> 00:14:58,910
can also check the resources consumed

00:14:56,540 --> 00:15:03,200
already by a specific domain or by a

00:14:58,910 --> 00:15:04,970
specific project and we also can define

00:15:03,200 --> 00:15:07,100
specials here so that we can be informed

00:15:04,970 --> 00:15:11,870
when a customer reached a specific level

00:15:07,100 --> 00:15:13,880
of resource consumption the last one is

00:15:11,870 --> 00:15:16,940
the offering check which

00:15:13,880 --> 00:15:19,730
reads all the define offerings from

00:15:16,940 --> 00:15:22,390
cloud stack and simulates the deployment

00:15:19,730 --> 00:15:25,940
on all the configured hypervisors and

00:15:22,390 --> 00:15:29,060
counts the possible deployment of a

00:15:25,940 --> 00:15:31,520
specific offering also here we can

00:15:29,060 --> 00:15:34,610
define thresholds to be informed maybe

00:15:31,520 --> 00:15:36,709
when we just have one XXL offering left

00:15:34,610 --> 00:15:39,559
for the customer so that we can order

00:15:36,709 --> 00:15:46,519
new hop there or yeah maybe delete some

00:15:39,559 --> 00:15:50,809
some test VMs or something so and also

00:15:46,519 --> 00:15:52,519
the capacity checks will made use of the

00:15:50,809 --> 00:15:54,499
auto inventory function of cloud stack

00:15:52,519 --> 00:15:56,540
so that means when you add a new

00:15:54,499 --> 00:15:58,670
offering and you domain of a new project

00:15:56,540 --> 00:16:01,100
it will be automatically added to the

00:15:58,670 --> 00:16:03,920
monitoring configuration so I don't have

00:16:01,100 --> 00:16:10,339
to specify it with each customer yet to

00:16:03,920 --> 00:16:12,799
a classic system how do we define these

00:16:10,339 --> 00:16:16,040
thresholds for these checks so it's all

00:16:12,799 --> 00:16:19,489
included in the UI and the API of the

00:16:16,040 --> 00:16:21,799
check-in camera system so at the first

00:16:19,489 --> 00:16:26,420
picture you can see these thresholds for

00:16:21,799 --> 00:16:28,040
cloud stack global resources so that

00:16:26,420 --> 00:16:30,709
means you can set warning and critical

00:16:28,040 --> 00:16:33,319
levels for that specific metrics like

00:16:30,709 --> 00:16:35,089
for example here the VLAN resource usage

00:16:33,319 --> 00:16:38,169
we set to a one level of sixty percent

00:16:35,089 --> 00:16:41,259
and a critical level of ninety percent

00:16:38,169 --> 00:16:44,869
in the middle you can see the usage for

00:16:41,259 --> 00:16:47,149
domains yeah four domains here's the

00:16:44,869 --> 00:16:49,489
specialty you can set also some default

00:16:47,149 --> 00:16:52,009
values for new domains which will be

00:16:49,489 --> 00:16:55,360
added to cloud stack so you can define

00:16:52,009 --> 00:16:58,579
default results and you can also define

00:16:55,360 --> 00:17:00,919
custom specials for specific domains or

00:16:58,579 --> 00:17:03,169
projects when you want to be informed

00:17:00,919 --> 00:17:08,630
for special customers when they have

00:17:03,169 --> 00:17:11,240
reached some limit the last picture is

00:17:08,630 --> 00:17:14,059
for the offerings so we can also define

00:17:11,240 --> 00:17:16,819
for specific thresholds for specific

00:17:14,059 --> 00:17:20,299
offerings for example here we want to be

00:17:16,819 --> 00:17:23,209
informed when we want to receive a

00:17:20,299 --> 00:17:25,339
warning message we have reached five

00:17:23,209 --> 00:17:27,970
deployments of Oryx Excel offering and

00:17:25,339 --> 00:17:31,909
we want to receive critical mail if we

00:17:27,970 --> 00:17:34,690
reached the special of one deployable X

00:17:31,909 --> 00:17:34,690
Excel offering

00:17:38,679 --> 00:17:46,309
it was about the monitoring of the

00:17:42,169 --> 00:17:48,289
clouds the components itself and we have

00:17:46,309 --> 00:17:51,350
also some we have also some managed

00:17:48,289 --> 00:17:53,840
service where we offer monitoring for

00:17:51,350 --> 00:17:56,149
the customer systems and for this we

00:17:53,840 --> 00:17:58,909
also need some distributed monitoring to

00:17:56,149 --> 00:18:02,869
spread the load over several monitoring

00:17:58,909 --> 00:18:06,429
service and yeah so as I said at the

00:18:02,869 --> 00:18:09,499
beginning checking k offers the

00:18:06,429 --> 00:18:12,440
possibility to build up a master/slave

00:18:09,499 --> 00:18:14,269
construct with several slave servers you

00:18:12,440 --> 00:18:18,379
can distribute the load of your

00:18:14,269 --> 00:18:20,509
monitoring instances too so we have one

00:18:18,379 --> 00:18:23,179
master node which holds all the

00:18:20,509 --> 00:18:25,730
configuration for the hosts and for the

00:18:23,179 --> 00:18:29,419
services of the customers and it

00:18:25,730 --> 00:18:32,720
distributes all the changes you made to

00:18:29,419 --> 00:18:35,710
that hosts via API to a slave host to

00:18:32,720 --> 00:18:39,379
configure for the customer for example

00:18:35,710 --> 00:18:42,139
so the slave host or also Hugh check and

00:18:39,379 --> 00:18:44,509
K hosts with an own Nagios core which

00:18:42,139 --> 00:18:47,600
hold their data locally so there's no

00:18:44,509 --> 00:18:50,019
data transport back to the master so for

00:18:47,600 --> 00:18:54,129
example when a new state of the host

00:18:50,019 --> 00:18:56,570
occurs like maybe you know from zabbix

00:18:54,129 --> 00:18:58,249
so that makes it really resource

00:18:56,570 --> 00:19:00,769
efficient because there's no transport

00:18:58,249 --> 00:19:03,529
back to the master and the that I will

00:19:00,769 --> 00:19:05,450
just be queried on demand when you as an

00:19:03,529 --> 00:19:10,159
administrator start a query for a

00:19:05,450 --> 00:19:14,090
specific customer also the slave service

00:19:10,159 --> 00:19:15,799
can be used as an API and as a UI for

00:19:14,090 --> 00:19:18,980
the customer so when he locks into a

00:19:15,799 --> 00:19:27,139
slave host and it just sees his hosts

00:19:18,980 --> 00:19:29,749
not from customer be seen how does it

00:19:27,139 --> 00:19:32,119
look in our environment so as I said at

00:19:29,749 --> 00:19:34,429
the beginning we have an advanced set up

00:19:32,119 --> 00:19:37,460
in our cloud psych environment so that

00:19:34,429 --> 00:19:39,320
means we have fully fenced networks for

00:19:37,460 --> 00:19:42,289
our customers with a roto-rooter in

00:19:39,320 --> 00:19:44,690
front and yeah several VMS in the

00:19:42,289 --> 00:19:48,049
customer network and then every network

00:19:44,690 --> 00:19:51,110
redeploys so called castration virtual

00:19:48,049 --> 00:19:52,610
machine which offers some services

00:19:51,110 --> 00:19:54,470
for the customer in this specific

00:19:52,610 --> 00:19:57,830
Network for example for Central

00:19:54,470 --> 00:20:01,429
identification for backup from the

00:19:57,830 --> 00:20:05,809
automation of course and for checking K

00:20:01,429 --> 00:20:08,780
slave host the orchestration VM also has

00:20:05,809 --> 00:20:13,850
a second interface in a service network

00:20:08,780 --> 00:20:17,090
where also the master node is resided in

00:20:13,850 --> 00:20:20,210
and also our of T cloud portal which is

00:20:17,090 --> 00:20:23,960
the single point of administration for

00:20:20,210 --> 00:20:26,179
our customer and the same way the master

00:20:23,960 --> 00:20:30,230
VM receives the data via live status

00:20:26,179 --> 00:20:32,929
from the slave host we do it with the

00:20:30,230 --> 00:20:35,330
portal so we just query the specific

00:20:32,929 --> 00:20:38,240
Orion of the customer and receive the

00:20:35,330 --> 00:20:40,910
status of specific host or a specific

00:20:38,240 --> 00:20:43,520
service of that host and we can display

00:20:40,910 --> 00:20:45,140
it later in the portal to give the

00:20:43,520 --> 00:20:52,100
customer a complete overview of what's

00:20:45,140 --> 00:20:54,710
going on inside this VM how does it look

00:20:52,100 --> 00:20:58,460
like so this is a screenshot of our

00:20:54,710 --> 00:21:01,490
portal and the virtual machine main view

00:20:58,460 --> 00:21:04,190
where we can find many informations

00:21:01,490 --> 00:21:06,830
about the virtual machine so for example

00:21:04,190 --> 00:21:09,320
IP configuration some some cost

00:21:06,830 --> 00:21:11,750
information and also the attached

00:21:09,320 --> 00:21:15,169
volumes and firewall rules and we have

00:21:11,750 --> 00:21:19,460
also a tab for monitoring which reflects

00:21:15,169 --> 00:21:21,980
the monitoring status on dit or vm or on

00:21:19,460 --> 00:21:24,260
the orchestration vm and so that the

00:21:21,980 --> 00:21:27,230
customer can see directly what's wrong

00:21:24,260 --> 00:21:31,179
with this virtual machine and very me if

00:21:27,230 --> 00:21:34,210
you take action we also offer some

00:21:31,179 --> 00:21:37,280
combined overview at the landscape level

00:21:34,210 --> 00:21:39,440
that means the customer can also see all

00:21:37,280 --> 00:21:42,290
the warning and critical information and

00:21:39,440 --> 00:21:44,480
all the VMS resided in that specific

00:21:42,290 --> 00:21:47,630
customer network so we have everything

00:21:44,480 --> 00:21:49,960
on one view what's currently wrong in

00:21:47,630 --> 00:21:49,960
that landscape

00:21:55,610 --> 00:22:02,720
okay now we come to the last point which

00:21:59,490 --> 00:22:07,800
is the topic virtual router monitoring

00:22:02,720 --> 00:22:10,140
so at some point we decided to monitor

00:22:07,800 --> 00:22:13,470
also our virtual routers or included in

00:22:10,140 --> 00:22:16,080
our monitoring system and we needed to

00:22:13,470 --> 00:22:17,970
find a way how to install our monitoring

00:22:16,080 --> 00:22:20,880
agent on the virtual routers of the

00:22:17,970 --> 00:22:24,240
customer and yeah how to get the data

00:22:20,880 --> 00:22:26,460
from the virtual router so it just may

00:22:24,240 --> 00:22:29,550
be a little bit complicated so I try to

00:22:26,460 --> 00:22:32,040
explain it so on the right side you can

00:22:29,550 --> 00:22:36,030
see your clouds take instance and also

00:22:32,040 --> 00:22:37,800
your our check-in kay server and under

00:22:36,030 --> 00:22:40,770
check in case server periodically

00:22:37,800 --> 00:22:43,920
there's a synchronization script running

00:22:40,770 --> 00:22:46,830
which gets all the data or the virtual

00:22:43,920 --> 00:22:48,780
routers from cloud stack and compares it

00:22:46,830 --> 00:22:50,990
with the virtual routers already

00:22:48,780 --> 00:22:53,610
configured in a monitoring system and

00:22:50,990 --> 00:22:57,240
identifies which are recruiters on you

00:22:53,610 --> 00:22:59,910
and with this information we identify on

00:22:57,240 --> 00:23:02,130
which hypervisor the virtual router is

00:22:59,910 --> 00:23:05,790
running and use the hypervisor

00:23:02,130 --> 00:23:08,430
management interface as an SSH proxy

00:23:05,790 --> 00:23:11,420
interface to configure the virtual

00:23:08,430 --> 00:23:13,920
router so we use link local interface

00:23:11,420 --> 00:23:15,390
because we use KVM we have no direct

00:23:13,920 --> 00:23:20,520
connection to the management interface

00:23:15,390 --> 00:23:23,280
with kvn we use this as a proxy for the

00:23:20,520 --> 00:23:26,640
link local interface and we install on

00:23:23,280 --> 00:23:29,460
that way our management or sorry our

00:23:26,640 --> 00:23:33,540
monitoring agent and also of the plugins

00:23:29,460 --> 00:23:36,740
we need for the virtual router after

00:23:33,540 --> 00:23:40,110
this has happened we add the host to

00:23:36,740 --> 00:23:42,360
checking page configuration and check MK

00:23:40,110 --> 00:23:47,730
configuration will be replicated through

00:23:42,360 --> 00:23:50,310
the specific customer slave server so it

00:23:47,730 --> 00:23:51,810
slave server you see down here the

00:23:50,310 --> 00:23:55,160
virtual appliances will be the odd

00:23:51,810 --> 00:23:57,720
virtual machine can then monitor the

00:23:55,160 --> 00:24:02,100
virtual router over the guest network

00:23:57,720 --> 00:24:04,830
and collect data like on any other Linux

00:24:02,100 --> 00:24:07,200
or Windows host so we have it just added

00:24:04,830 --> 00:24:09,470
to that specific monitoring

00:24:07,200 --> 00:24:09,470
configuration

00:24:10,490 --> 00:24:21,420
Christian's didn't know what was the

00:24:17,220 --> 00:24:23,850
result of this yeah project so currently

00:24:21,420 --> 00:24:26,010
we have all virtual routers inside a

00:24:23,850 --> 00:24:28,620
monitoring configuration spread it all

00:24:26,010 --> 00:24:31,140
over the slave servers of the customers

00:24:28,620 --> 00:24:34,350
so we have no load problems with central

00:24:31,140 --> 00:24:36,870
components here we also automatically

00:24:34,350 --> 00:24:39,720
delete virtual routers when yeah the

00:24:36,870 --> 00:24:43,290
customer project gets deleted from cloud

00:24:39,720 --> 00:24:45,240
stack and yeah we already identified

00:24:43,290 --> 00:24:48,120
some problems here so we have some

00:24:45,240 --> 00:24:51,000
packet loss on several interfaces which

00:24:48,120 --> 00:24:53,400
we currently investigate what's the

00:24:51,000 --> 00:24:56,460
problem here and we wouldn't have seen

00:24:53,400 --> 00:25:05,780
that without integrating the virtual

00:24:56,460 --> 00:25:09,150
routers in our own central monitoring ok

00:25:05,780 --> 00:25:11,730
now a short how to maybe what to come in

00:25:09,150 --> 00:25:13,380
the future so in the future we also want

00:25:11,730 --> 00:25:16,680
to do with some better integration of

00:25:13,380 --> 00:25:18,630
the monitoring system of in a portal so

00:25:16,680 --> 00:25:20,310
that means we want to also give the

00:25:18,630 --> 00:25:23,070
customer the opportunity to have some

00:25:20,310 --> 00:25:26,190
long-term overview of the data of his

00:25:23,070 --> 00:25:28,200
systems or services we want to add some

00:25:26,190 --> 00:25:31,950
more application checks specifically for

00:25:28,200 --> 00:25:34,950
Hana databases as for instances and some

00:25:31,950 --> 00:25:38,100
old or three systems and also we want to

00:25:34,950 --> 00:25:40,230
extend the virtual routine monitoring

00:25:38,100 --> 00:25:43,020
that means we want to do it more

00:25:40,230 --> 00:25:46,020
dynamically that we can also roll out

00:25:43,020 --> 00:25:48,810
new plugins and new checks to the

00:25:46,020 --> 00:25:55,590
existing virtual routers so this is the

00:25:48,810 --> 00:26:04,680
plan for the future and that's all from

00:25:55,590 --> 00:26:16,549
my side any questions left sorry to the

00:26:04,680 --> 00:26:18,529
VTR this one the green here

00:26:16,549 --> 00:26:21,409
this is the dista gas network of the

00:26:18,529 --> 00:26:28,070
specific customer so that one which is

00:26:21,409 --> 00:26:28,549
fenced through the virtual router yeah

00:26:28,070 --> 00:26:32,830
correct

00:26:28,549 --> 00:26:34,580
so it takes some some time before the

00:26:32,830 --> 00:26:36,440
synchronization script detects that

00:26:34,580 --> 00:26:39,409
there's a new router so we have like

00:26:36,440 --> 00:26:41,719
maybe about five minutes depends on how

00:26:39,409 --> 00:26:44,059
fast the EDT froze custom movie and gets

00:26:41,719 --> 00:26:46,820
deployed and after this Kiki Boosh

00:26:44,059 --> 00:27:18,349
router will be added to the moisture

00:26:46,820 --> 00:27:20,509
configuration started then yeah there is

00:27:18,349 --> 00:27:22,519
always a process we am deployed which is

00:27:20,509 --> 00:27:24,769
our orchestration VM which resides in

00:27:22,519 --> 00:27:29,239
the same network so the virtual router

00:27:24,769 --> 00:27:45,289
is started when our orchestration vm

00:27:29,239 --> 00:27:47,749
gets deployed that's a problem currently

00:27:45,289 --> 00:27:49,219
so it can happen that we receive an

00:27:47,749 --> 00:27:51,619
error message yes

00:27:49,219 --> 00:27:53,929
so we maybe switch also later or to a

00:27:51,619 --> 00:27:55,849
event based system and not all based

00:27:53,929 --> 00:27:59,719
system every five minutes but it is not

00:27:55,849 --> 00:28:02,479
implemented yet but we have know that

00:27:59,719 --> 00:28:04,940
that big amount of networks which will

00:28:02,479 --> 00:28:11,690
get destroyed and build up again so it's

00:28:04,940 --> 00:28:14,109
more static in all landscape yeah all

00:28:11,690 --> 00:28:14,109
the questions

00:28:25,250 --> 00:28:28,950
correct yeah

00:28:26,670 --> 00:28:31,309
not just the VR also the other custom

00:28:28,950 --> 00:28:31,309
systems

00:29:39,470 --> 00:29:45,809
you mean some some self-healing

00:29:43,250 --> 00:29:46,410
be an idea but but maybe this is very

00:29:45,809 --> 00:29:49,230
risky

00:29:46,410 --> 00:29:51,299
for some cases so currently we just

00:29:49,230 --> 00:29:53,940
receive alarms and then we have to

00:29:51,299 --> 00:29:56,669
manually interact with with their

00:29:53,940 --> 00:29:58,410
components which is affected yeah yeah

00:29:56,669 --> 00:30:01,320
but but the idea was also there from

00:29:58,410 --> 00:30:03,480
from from our side but I think you need

00:30:01,320 --> 00:30:08,809
a lot of testing to get this working

00:30:03,480 --> 00:30:08,809
very really pretty properly yeah but

00:30:34,260 --> 00:30:42,450

YouTube URL: https://www.youtube.com/watch?v=DNmEmKIepzo


