Title: #ACEU19: Paul Brebner – Kongo: Building a Scalable Streaming IoT Application using Apache Kafka
Publication date: 2019-10-31
Playlist: ApacheCon Europe 2019 – Berlin
Description: 
	More: https://aceu19.apachecon.com/session/kongo-building-scalable-streaming-iot-application-using-apache-kafka

Join with me in a journey of exploration upriver with "Kongo", a scalable streaming IoT logistics demonstration application using Apache Kafka, the popular open source distributed streaming platform. Along the way you'll discover: an example logistics IoT problem domain (involving the rapid movement of thousands of goods by trucks between warehouses, with real-time checking of complex business and safety rules from sensor data); an overview of the Apache Kafka architecture and components; lessons learned from making critical Kaka application design decisions; an example of Kafka Streams for checking truck load limits; and finish the journey by overcoming final performance challenges and shooting the rapids to scale Kongo on a production Kafka cluster.
Captions: 
	00:00:04,530 --> 00:00:10,559
very much this is a very exclusive

00:00:07,100 --> 00:00:13,080
location and audience thank you very

00:00:10,559 --> 00:00:14,280
much for coming along after lunch I feel

00:00:13,080 --> 00:00:19,020
like we should all have a drink in our

00:00:14,280 --> 00:00:21,600
hands or or something in the saloon so

00:00:19,020 --> 00:00:23,789
I'm a technology evangelist that sort of

00:00:21,600 --> 00:00:25,949
it's a bit of an odd title that means I

00:00:23,789 --> 00:00:29,310
I get to learn about interesting new

00:00:25,949 --> 00:00:31,619
open-source technologies try them out

00:00:29,310 --> 00:00:33,030
myself build things blog about them and

00:00:31,619 --> 00:00:34,470
occasionally get to give a talk on them

00:00:33,030 --> 00:00:36,600
so I'm really quite pleased if I can

00:00:34,470 --> 00:00:38,730
give a talk on this topic this is one of

00:00:36,600 --> 00:00:40,980
the first ones I did when I started with

00:00:38,730 --> 00:00:42,809
inter-cluster about that was last year

00:00:40,980 --> 00:00:44,879
when I did this project so it's a bit

00:00:42,809 --> 00:00:47,070
out of date which I apologize for in

00:00:44,879 --> 00:00:48,840
advance so there's a few gaps and there

00:00:47,070 --> 00:00:51,270
could be a few improvements as well so

00:00:48,840 --> 00:00:52,950
there's some future work possible for it

00:00:51,270 --> 00:00:57,719
but basically is talking about what I

00:00:52,950 --> 00:01:00,390
did last year it's not sort of on the

00:00:57,719 --> 00:01:03,870
edge in terms of IOT technology it's

00:01:00,390 --> 00:01:05,640
more to do with core infrastructure so

00:01:03,870 --> 00:01:06,539
hopefully that's okay for people a

00:01:05,640 --> 00:01:09,270
little more interested in edge

00:01:06,539 --> 00:01:11,580
technologies it's not a real project

00:01:09,270 --> 00:01:13,979
it's just demo projects so it's

00:01:11,580 --> 00:01:15,540
realistic but not correct or complete

00:01:13,979 --> 00:01:17,549
all those other good things that you'd

00:01:15,540 --> 00:01:19,979
need to do in production but hopefully

00:01:17,549 --> 00:01:22,350
it gives people some ideas and it's the

00:01:19,979 --> 00:01:24,720
way I actually learnt Kefka so in a

00:01:22,350 --> 00:01:27,330
sense you're going to hear about some of

00:01:24,720 --> 00:01:30,080
my mistakes and some sort of conclusions

00:01:27,330 --> 00:01:33,450
about how to actually get things working

00:01:30,080 --> 00:01:35,939
so let's go so what we'll see on our

00:01:33,450 --> 00:01:37,799
journey upriver is a bit of an intro

00:01:35,939 --> 00:01:41,009
Kefka I just said can I get a show of

00:01:37,799 --> 00:01:44,790
hands to see who knows about Kefka who's

00:01:41,009 --> 00:01:47,549
used Kafka okay so it's gonna be a very

00:01:44,790 --> 00:01:49,200
basic intro and then I'm gonna look at

00:01:47,549 --> 00:01:50,909
the Congo problem which is the problem

00:01:49,200 --> 00:01:52,890
of my own invention

00:01:50,909 --> 00:01:54,329
next I have a bit of look at the

00:01:52,890 --> 00:01:57,810
application the architecture and the

00:01:54,329 --> 00:01:59,700
possible designs for the system then

00:01:57,810 --> 00:02:01,439
I'll look at a streams extension that I

00:01:59,700 --> 00:02:03,329
did and then have a look at the problem

00:02:01,439 --> 00:02:05,399
of scalability for the whole the whole

00:02:03,329 --> 00:02:07,259
system so that's what I'm going to talk

00:02:05,399 --> 00:02:11,009
about hopefully that's interesting most

00:02:07,259 --> 00:02:13,349
people so first of all the Kefka

00:02:11,009 --> 00:02:17,040
introduction so I worked in stew cluster

00:02:13,349 --> 00:02:18,480
we have a managed platform for a variety

00:02:17,040 --> 00:02:20,700
of technologies we do

00:02:18,480 --> 00:02:23,190
multi-cloud a scale performance

00:02:20,700 --> 00:02:25,019
availability integration and security so

00:02:23,190 --> 00:02:27,170
essentially we provide some of the

00:02:25,019 --> 00:02:29,670
missing pieces for some of the Apache

00:02:27,170 --> 00:02:31,650
Big Data projects in terms of the

00:02:29,670 --> 00:02:34,140
operations space and also we we look

00:02:31,650 --> 00:02:35,849
after the clusters of people so that

00:02:34,140 --> 00:02:41,580
customers don't have to worry about

00:02:35,849 --> 00:02:43,080
doing that themselves so we've got an

00:02:41,580 --> 00:02:46,739
open-source technologies for storage

00:02:43,080 --> 00:02:49,110
it's Cassandra analysis that spark

00:02:46,739 --> 00:02:52,920
search coming up this year is

00:02:49,110 --> 00:02:55,140
elasticsearch exploration cabana and

00:02:52,920 --> 00:02:57,930
last year we added some streams

00:02:55,140 --> 00:03:00,359
technology ie Kefka so that was why it

00:02:57,930 --> 00:03:01,829
was an appropriate technology for me to

00:03:00,359 --> 00:03:06,750
start learning and start blogging about

00:03:01,829 --> 00:03:09,060
as well so kefka's distributed streams

00:03:06,750 --> 00:03:10,950
processing system which enables

00:03:09,060 --> 00:03:13,890
distributed producers to send messages

00:03:10,950 --> 00:03:16,230
to distributed consumers VAR AK Africa

00:03:13,890 --> 00:03:17,970
cluster so that level it's pretty simple

00:03:16,230 --> 00:03:20,099
isn't it I think you do anything itself

00:03:17,970 --> 00:03:23,069
it's just a way of delivering messages

00:03:20,099 --> 00:03:25,620
to where you want them to go some of the

00:03:23,069 --> 00:03:27,930
benefits are that it's fast it's got

00:03:25,620 --> 00:03:29,910
high throughput and latency it's

00:03:27,930 --> 00:03:32,190
scalable horizontally scalable you can

00:03:29,910 --> 00:03:33,989
just add nodes and petitions to increase

00:03:32,190 --> 00:03:35,430
the concurrency in the throughput it's

00:03:33,989 --> 00:03:37,109
reliable which is important for

00:03:35,430 --> 00:03:39,630
production environments it's distributed

00:03:37,109 --> 00:03:42,329
and fault tolerant it enables you'd have

00:03:39,630 --> 00:03:45,599
zero data loss it's open source it's an

00:03:42,329 --> 00:03:47,489
Apache you project quite a critical

00:03:45,599 --> 00:03:49,590
aspect as it enables should have

00:03:47,489 --> 00:03:51,599
heterogeneous data sources and syncs

00:03:49,590 --> 00:03:52,889
that actually came from LinkedIn

00:03:51,599 --> 00:03:56,519
originally and their problem was

00:03:52,889 --> 00:03:59,639
actually how they could re re architect

00:03:56,519 --> 00:04:01,430
all of their weird applications about

00:03:59,639 --> 00:04:04,590
talking to each other point point and

00:04:01,430 --> 00:04:06,810
remove the burden on integration of new

00:04:04,590 --> 00:04:08,750
applications so they decided to use it

00:04:06,810 --> 00:04:11,099
as a hub spoke sort of an architecture

00:04:08,750 --> 00:04:12,359
and that's sort of where it came from

00:04:11,099 --> 00:04:13,620
that's still actually quite useful for

00:04:12,359 --> 00:04:16,979
that purpose as well particularly the

00:04:13,620 --> 00:04:20,039
IOT space I you're highly likely to have

00:04:16,979 --> 00:04:21,329
heterogeneous sources of data so that's

00:04:20,039 --> 00:04:24,240
a great way of combining them all

00:04:21,329 --> 00:04:25,770
together in one system and and it's

00:04:24,240 --> 00:04:27,570
available resonance to cluster managed

00:04:25,770 --> 00:04:30,120
service that's the way you'd like to run

00:04:27,570 --> 00:04:32,670
it how does kept achill work well I've

00:04:30,120 --> 00:04:34,920
actually a few months guide

00:04:32,670 --> 00:04:36,930
a visual introduction to Kafka this is

00:04:34,920 --> 00:04:38,610
not that but you can look at it on our

00:04:36,930 --> 00:04:40,620
website and download it later this is

00:04:38,610 --> 00:04:44,850
the first sort of few slides that are

00:04:40,620 --> 00:04:47,190
relevant from that look so kefka is

00:04:44,850 --> 00:04:48,900
pub/sub it's publish/subscribe it's

00:04:47,190 --> 00:04:54,960
loosely coupled producers and consumers

00:04:48,900 --> 00:04:57,210
don't know about each other filtering or

00:04:54,960 --> 00:04:59,700
which consumers get which messages is

00:04:57,210 --> 00:05:02,790
topic-based producers send messages to

00:04:59,700 --> 00:05:04,290
topics consumers subscribe to topics of

00:05:02,790 --> 00:05:06,600
interest for example in this case

00:05:04,290 --> 00:05:09,450
there's a bit of a story around parties

00:05:06,600 --> 00:05:11,400
versus work when they poll they only

00:05:09,450 --> 00:05:13,200
receive messages sent for those topics

00:05:11,400 --> 00:05:15,240
none of the consumers in this example

00:05:13,200 --> 00:05:17,640
will receive messages sent for the work

00:05:15,240 --> 00:05:20,700
topic only messages sent to the parties

00:05:17,640 --> 00:05:22,560
topic so there's two aspects about

00:05:20,700 --> 00:05:24,090
caf-co that I just want to focus on

00:05:22,560 --> 00:05:26,880
first of all it works a bit like an

00:05:24,090 --> 00:05:30,570
Amish barn raising so this is how you

00:05:26,880 --> 00:05:32,640
get the the shared concurrency aspect

00:05:30,570 --> 00:05:35,070
partitions and a consumer group share

00:05:32,640 --> 00:05:36,540
work across multiple consumers the more

00:05:35,070 --> 00:05:38,430
petitions or topic hairs the more

00:05:36,540 --> 00:05:41,370
consumers it supports and therefore the

00:05:38,430 --> 00:05:43,290
more more work and get done on the other

00:05:41,370 --> 00:05:45,960
hand kefka also works a bit like the

00:05:43,290 --> 00:05:48,390
clone army it supports delivery of the

00:05:45,960 --> 00:05:51,120
same message to multiple consumers with

00:05:48,390 --> 00:05:52,770
consumer groups so because kefka doesn't

00:05:51,120 --> 00:05:55,440
throw messages away like traditional

00:05:52,770 --> 00:05:57,690
messaging systems immediately they are

00:05:55,440 --> 00:05:59,730
delivered the same message can be easily

00:05:57,690 --> 00:06:00,900
delivered to multiple consumer groups so

00:05:59,730 --> 00:06:05,880
this gives you the broadcasting

00:06:00,900 --> 00:06:07,500
capability so just let's see how that

00:06:05,880 --> 00:06:09,690
works in fact the practice consumers

00:06:07,500 --> 00:06:12,960
subscribe to the parties topic our

00:06:09,690 --> 00:06:14,460
elephant partitions when they poll they

00:06:12,960 --> 00:06:17,220
will only get messages from their

00:06:14,460 --> 00:06:22,250
allocated partitions so this divide is

00:06:17,220 --> 00:06:24,750
the problem down into a smaller scale

00:06:22,250 --> 00:06:26,940
this enables consumers in the same group

00:06:24,750 --> 00:06:29,310
to share the work around each consumer

00:06:26,940 --> 00:06:33,870
via Gibson gets only a subset of the

00:06:29,310 --> 00:06:35,340
available messages on the other hand

00:06:33,870 --> 00:06:37,590
multiple groups enable the message

00:06:35,340 --> 00:06:39,390
broadcasting messages are duplicated

00:06:37,590 --> 00:06:42,660
across groups as each consumer group

00:06:39,390 --> 00:06:44,250
receives a copy of each message and in

00:06:42,660 --> 00:06:45,669
theory can have as many consumer groups

00:06:44,250 --> 00:06:47,439
as you like

00:06:45,669 --> 00:06:49,180
in order to satisfy the particular

00:06:47,439 --> 00:06:51,099
business case you've got however we'll

00:06:49,180 --> 00:06:54,639
see maybe there are some complications

00:06:51,099 --> 00:06:57,610
doing that later on so the the

00:06:54,639 --> 00:07:00,159
particular application problem that I

00:06:57,610 --> 00:07:03,729
came up with I've called the Congo

00:07:00,159 --> 00:07:08,199
problem the reason for the name is the

00:07:03,729 --> 00:07:10,479
Amazon was taken obviously as an AWS and

00:07:08,199 --> 00:07:12,819
Congo is the second biggest river at

00:07:10,479 --> 00:07:15,279
5,000 kilometers long and it turns out

00:07:12,819 --> 00:07:16,689
to be the deepest river so it is

00:07:15,279 --> 00:07:19,330
actually up there in a sense of being

00:07:16,689 --> 00:07:21,279
one of the most important river systems

00:07:19,330 --> 00:07:23,110
in the world and while the odd naming

00:07:21,279 --> 00:07:25,719
well it turns out that it used to be

00:07:23,110 --> 00:07:28,689
called the Congo were the k named after

00:07:25,719 --> 00:07:32,819
the kingdom of Kongo that was a feed on

00:07:28,689 --> 00:07:34,599
the coast of the river so hence the name

00:07:32,819 --> 00:07:36,699
in terms of the actual application

00:07:34,599 --> 00:07:38,830
domain it was very important and still

00:07:36,699 --> 00:07:42,009
is for trade it's the main source of odd

00:07:38,830 --> 00:07:43,689
movement into central Africa and I was

00:07:42,009 --> 00:07:44,919
interested in developing an example that

00:07:43,689 --> 00:07:49,719
just sticks a problem and so it seemed

00:07:44,919 --> 00:07:51,759
like a good name so bit more about the

00:07:49,719 --> 00:07:55,150
particular logistics problem that I had

00:07:51,759 --> 00:07:57,250
in mind I had in mind the idea that

00:07:55,150 --> 00:07:58,870
there'd be lots of goods for a start and

00:07:57,250 --> 00:08:01,000
the goods are going to be stored in

00:07:58,870 --> 00:08:03,099
warehouses and the goods are going to be

00:08:01,000 --> 00:08:05,740
moved around between warehouses in

00:08:03,099 --> 00:08:08,830
trucks or some other way of moving them

00:08:05,740 --> 00:08:10,569
around if you prefer and I wanted to be

00:08:08,830 --> 00:08:13,149
able to also check lots of interesting

00:08:10,569 --> 00:08:18,430
rules in real time so that's sort of a

00:08:13,149 --> 00:08:20,080
context in in a real case that we would

00:08:18,430 --> 00:08:20,919
actually be all these things happening

00:08:20,080 --> 00:08:23,979
in the real world

00:08:20,919 --> 00:08:26,409
they'd be an interface through sensors

00:08:23,979 --> 00:08:29,080
and RFID devices into the virtual world

00:08:26,409 --> 00:08:31,000
where all the software is running for

00:08:29,080 --> 00:08:32,469
this particular demo system the whole

00:08:31,000 --> 00:08:34,659
system actually is running in the

00:08:32,469 --> 00:08:36,339
virtual world so there's no actual real

00:08:34,659 --> 00:08:39,849
component but that's that's what the

00:08:36,339 --> 00:08:41,979
story would look like so let's have a

00:08:39,849 --> 00:08:44,709
look at some goods here's some examples

00:08:41,979 --> 00:08:47,490
of goods chickens they're perishable

00:08:44,709 --> 00:08:50,050
fragile and maybe even hittable

00:08:47,490 --> 00:08:53,230
we've got toxic waste well that's

00:08:50,050 --> 00:08:54,699
hazardous and potentially bulky now

00:08:53,230 --> 00:08:57,760
we've got vegetables they're perishable

00:08:54,699 --> 00:08:58,980
and edible and then Mabel you've got

00:08:57,760 --> 00:09:01,800
something like art we

00:08:58,980 --> 00:09:05,760
as fragile and I guess potentially

00:09:01,800 --> 00:09:08,010
valuable as well warehouses well okay

00:09:05,760 --> 00:09:12,420
you can just imagine warehouses there's

00:09:08,010 --> 00:09:14,399
places where the goods are stored before

00:09:12,420 --> 00:09:17,430
and after they're being moved around by

00:09:14,399 --> 00:09:18,600
trucks trucks well okay there are the

00:09:17,430 --> 00:09:22,920
things that move the goods around

00:09:18,600 --> 00:09:24,480
between the warehouses all right and as

00:09:22,920 --> 00:09:26,130
I mentioned this sort of is an assumed

00:09:24,480 --> 00:09:27,750
interface between the virtual world in

00:09:26,130 --> 00:09:32,610
the real world so we're assuming that

00:09:27,750 --> 00:09:35,699
all the goods have RFID tags on them so

00:09:32,610 --> 00:09:39,360
you can identify what the goods are from

00:09:35,699 --> 00:09:40,860
their RFID tag and when they go in and

00:09:39,360 --> 00:09:43,440
out of warehouses and trucks you can

00:09:40,860 --> 00:09:45,779
detect when they're coming in and out so

00:09:43,440 --> 00:09:48,630
we're also assuming RFID readers

00:09:45,779 --> 00:09:50,579
essentially at the boundaries between

00:09:48,630 --> 00:09:51,600
the warehouse system and the truck

00:09:50,579 --> 00:09:54,540
system if you like

00:09:51,600 --> 00:09:57,810
so the RFID readers produce load and

00:09:54,540 --> 00:09:59,550
unload events basically so every time a

00:09:57,810 --> 00:10:02,339
good is removed from a warehouse and

00:09:59,550 --> 00:10:05,940
loaded into a truck we'll get a load the

00:10:02,339 --> 00:10:07,079
goods ID and then the truck ID and every

00:10:05,940 --> 00:10:09,300
time they're unloaded we'll get an

00:10:07,079 --> 00:10:13,980
unalloyed event saying more or less the

00:10:09,300 --> 00:10:16,440
same in reverse order okay this isn't a

00:10:13,980 --> 00:10:17,730
slightly different part of the story is

00:10:16,440 --> 00:10:20,880
that we're assuming there's a whole

00:10:17,730 --> 00:10:23,790
bunch of sensors in both the warehouses

00:10:20,880 --> 00:10:25,800
and the trucks as well so these are

00:10:23,790 --> 00:10:28,319
assumed to produce a whole variety of

00:10:25,800 --> 00:10:30,000
relevant metrics for example on the

00:10:28,319 --> 00:10:31,769
trucks will have submit and some sensors

00:10:30,000 --> 00:10:34,470
producing shock and vibration

00:10:31,769 --> 00:10:36,870
information in the warehouses maybe

00:10:34,470 --> 00:10:38,069
we'll have some rebar Ament all sensors

00:10:36,870 --> 00:10:41,010
including things like temperature and

00:10:38,069 --> 00:10:43,290
guess our levels and things like that so

00:10:41,010 --> 00:10:46,350
the the system assumes that there's

00:10:43,290 --> 00:10:48,180
about 20 metrics in total some are

00:10:46,350 --> 00:10:50,100
common across trucks in warehouses some

00:10:48,180 --> 00:10:54,949
a unique trucks and some are unique for

00:10:50,100 --> 00:10:57,389
warehouses so that the story essentially

00:10:54,949 --> 00:10:59,399
works like this so we've got well in

00:10:57,389 --> 00:11:03,420
this case we've got two warehouses that

00:10:59,399 --> 00:11:05,430
the simplest possible case I guess so

00:11:03,420 --> 00:11:07,319
there are some goods initially stored in

00:11:05,430 --> 00:11:11,910
one warehouse there are no goods in the

00:11:07,319 --> 00:11:12,510
other one to start with each warehouse

00:11:11,910 --> 00:11:14,700
produce

00:11:12,510 --> 00:11:16,350
some sensor events telling us what's

00:11:14,700 --> 00:11:18,990
going on in that warehouse over a

00:11:16,350 --> 00:11:21,360
particular period of time and what we

00:11:18,990 --> 00:11:22,950
want to do is check the rules for the

00:11:21,360 --> 00:11:26,220
goods see if there's been any

00:11:22,950 --> 00:11:28,020
environmental violations for those Goods

00:11:26,220 --> 00:11:31,530
in the particular warehouse that they

00:11:28,020 --> 00:11:33,120
they are in so in this case you get all

00:11:31,530 --> 00:11:35,160
the sensor events from a warehouse for a

00:11:33,120 --> 00:11:36,390
particular unit of time for every goods

00:11:35,160 --> 00:11:38,940
in that warehouse you want to see if

00:11:36,390 --> 00:11:41,340
there's been any violations there are no

00:11:38,940 --> 00:11:44,820
goods in the bottom warehouse so there's

00:11:41,340 --> 00:11:48,840
no checking required along comes a truck

00:11:44,820 --> 00:11:50,190
it arrives at the top warehouse I mean

00:11:48,840 --> 00:11:54,900
get a load something on let's load some

00:11:50,190 --> 00:11:57,990
art on the truck and this produces a

00:11:54,900 --> 00:12:00,090
load event and the system now knows that

00:11:57,990 --> 00:12:02,640
the art is in the truck not in the

00:12:00,090 --> 00:12:05,280
warehouse let's load something else on

00:12:02,640 --> 00:12:08,160
the truck let's load some toxic waste

00:12:05,280 --> 00:12:11,190
onto the truck as well may not be a good

00:12:08,160 --> 00:12:14,010
idea but it happened so we get another

00:12:11,190 --> 00:12:16,500
load event we know that the drums are

00:12:14,010 --> 00:12:18,870
now on the truck not the warehouse and

00:12:16,500 --> 00:12:21,900
at this point because there are two

00:12:18,870 --> 00:12:23,220
goods in the truck we can run some kicks

00:12:21,900 --> 00:12:26,310
on whether those two goods are actually

00:12:23,220 --> 00:12:27,540
happy to be together in the same small

00:12:26,310 --> 00:12:29,430
location ie

00:12:27,540 --> 00:12:31,080
in a truck we don't run these these

00:12:29,430 --> 00:12:32,340
checks in the warehouses we assume the

00:12:31,080 --> 00:12:34,860
warehouses are big enough that the

00:12:32,340 --> 00:12:36,900
people would types can be segregated

00:12:34,860 --> 00:12:38,300
safely but every time there's more than

00:12:36,900 --> 00:12:42,570
one goods in the truck we want to check

00:12:38,300 --> 00:12:46,260
if there's any any potential collocation

00:12:42,570 --> 00:12:51,930
issues the truck then drives to another

00:12:46,260 --> 00:12:55,040
warehouse while it's doing that we

00:12:51,930 --> 00:12:57,210
assume that the truck sensor events

00:12:55,040 --> 00:12:59,310
occur and we want to check to see

00:12:57,210 --> 00:13:00,810
whether all the goods in the truck are

00:12:59,310 --> 00:13:03,750
still happy with the environment that

00:13:00,810 --> 00:13:05,190
they're in in terms of vibrations and

00:13:03,750 --> 00:13:07,560
acceleration and temperature and

00:13:05,190 --> 00:13:12,660
anything else that they they may care

00:13:07,560 --> 00:13:14,490
about once the the truck arrives at the

00:13:12,660 --> 00:13:17,130
second warehouse the goods are unloaded

00:13:14,490 --> 00:13:19,920
so we unload the drums and the art all

00:13:17,130 --> 00:13:22,920
all the goods are always unloaded when

00:13:19,920 --> 00:13:25,620
the truck arrives at each warehouse this

00:13:22,920 --> 00:13:27,089
produces the RFI the unload events and

00:13:25,620 --> 00:13:29,250
system then knows that the goods are in

00:13:27,089 --> 00:13:31,589
the warehouse and basically we just

00:13:29,250 --> 00:13:33,990
repeat in a loop doing exactly the same

00:13:31,589 --> 00:13:36,690
thing forever and ever until we decide

00:13:33,990 --> 00:13:38,190
to stop it except the main differences

00:13:36,690 --> 00:13:42,120
there's lots more warehouses Goods and

00:13:38,190 --> 00:13:43,080
trucks potentially so I've already

00:13:42,120 --> 00:13:45,630
mentioned that there's a couple of

00:13:43,080 --> 00:13:49,410
different sorts of rules so we've got

00:13:45,630 --> 00:13:52,110
rules for the categories for the goods

00:13:49,410 --> 00:13:53,520
each Goods has zero or more general

00:13:52,110 --> 00:13:55,320
categories for things like whether

00:13:53,520 --> 00:13:59,850
they're perishable hazardous fragile

00:13:55,320 --> 00:14:00,960
edible but distant all bulky and dry in

00:13:59,850 --> 00:14:03,150
the real world it's a lot more

00:14:00,960 --> 00:14:05,820
complicated of course I I got the idea

00:14:03,150 --> 00:14:08,130
for this from the Australian Transport

00:14:05,820 --> 00:14:10,350
regulations fer for goods and everything

00:14:08,130 --> 00:14:12,180
there's 97 categories with a very very

00:14:10,350 --> 00:14:14,100
complicated matrix explaining which

00:14:12,180 --> 00:14:19,950
things are allowed to be pens brought up

00:14:14,100 --> 00:14:21,839
together so there's also zero or one

00:14:19,950 --> 00:14:25,200
temperature category for each Goods so

00:14:21,839 --> 00:14:26,940
going right from so frozen through to

00:14:25,200 --> 00:14:28,200
anything little cope with just being at

00:14:26,940 --> 00:14:30,870
the ambient temperature which in

00:14:28,200 --> 00:14:33,900
Australia can get pretty hot so 40 50

00:14:30,870 --> 00:14:35,400
degrees potentially in some warehouses

00:14:33,900 --> 00:14:37,230
and trucks are temperature controlled so

00:14:35,400 --> 00:14:39,990
they actually ensure that the

00:14:37,230 --> 00:14:41,630
temperature is in one of these category

00:14:39,990 --> 00:14:44,970
one or more of these categories actually

00:14:41,630 --> 00:14:48,060
others others aren't and can randomly go

00:14:44,970 --> 00:14:49,830
to any temperature as ahead of the rules

00:14:48,060 --> 00:14:52,529
get checked off so first of all this is

00:14:49,830 --> 00:14:54,959
an example the collocation rules so each

00:14:52,529 --> 00:14:57,720
good has rules to check if they are safe

00:14:54,959 --> 00:15:00,000
in the same truck as another goods

00:14:57,720 --> 00:15:02,010
category so for example you don't want

00:15:00,000 --> 00:15:04,500
explosive Goods to be in the presence of

00:15:02,010 --> 00:15:07,620
spontaneously combustible goods because

00:15:04,500 --> 00:15:10,160
something really bad might happen now

00:15:07,620 --> 00:15:12,839
the sensor rules on the other hand

00:15:10,160 --> 00:15:14,279
worked like this the goods have rules to

00:15:12,839 --> 00:15:17,190
check if they're safe in the environment

00:15:14,279 --> 00:15:18,720
of a particular location either the

00:15:17,190 --> 00:15:20,190
warehouse or the truck and as I've

00:15:18,720 --> 00:15:22,290
mentioned there's about 20 metric some

00:15:20,190 --> 00:15:23,790
in common so you want to keep your

00:15:22,290 --> 00:15:25,709
chickens cool while they're being

00:15:23,790 --> 00:15:28,140
transported and if they're being stored

00:15:25,709 --> 00:15:30,660
in a warehouse as well this does an

00:15:28,140 --> 00:15:32,580
example and so what does the application

00:15:30,660 --> 00:15:35,370
actually look like well it's it's a

00:15:32,580 --> 00:15:38,400
simulation the first step is that we

00:15:35,370 --> 00:15:39,360
create a whole system out with a certain

00:15:38,400 --> 00:15:41,070
number of good

00:15:39,360 --> 00:15:42,240
where houses and trucks and there's a

00:15:41,070 --> 00:15:43,580
whole bunch of parameters that you can

00:15:42,240 --> 00:15:46,170
fiddle with at that point to create

00:15:43,580 --> 00:15:49,380
different numbers of categories of each

00:15:46,170 --> 00:15:51,030
thing and and such like and then that

00:15:49,380 --> 00:15:54,420
there's basically a loop which gets

00:15:51,030 --> 00:15:56,070
repeated the time unit is an hour in the

00:15:54,420 --> 00:15:59,130
simulations everything happens on our

00:15:56,070 --> 00:16:00,480
boundaries first of all we simulate the

00:15:59,130 --> 00:16:02,820
sensor values for the trucks and

00:16:00,480 --> 00:16:05,820
warehouses then we check their goods and

00:16:02,820 --> 00:16:07,290
collocation violation rules to check

00:16:05,820 --> 00:16:09,780
that the goods are allowed together on

00:16:07,290 --> 00:16:11,880
the trucks now we unload the goods and

00:16:09,780 --> 00:16:15,780
the warehouses we check the goods and

00:16:11,880 --> 00:16:17,580
cents violation rules for the goods in

00:16:15,780 --> 00:16:19,200
the trucks and warehouses and then we

00:16:17,580 --> 00:16:22,950
load the trucks with goods move trucks

00:16:19,200 --> 00:16:24,260
to a random warehouse and repeat so

00:16:22,950 --> 00:16:27,090
they're the logical steps are not

00:16:24,260 --> 00:16:30,720
necessarily exactly the ones we do an

00:16:27,090 --> 00:16:32,220
order as it turns out so initially I

00:16:30,720 --> 00:16:35,070
built the application as a monolithic

00:16:32,220 --> 00:16:39,900
architecture you'll see the same steps

00:16:35,070 --> 00:16:42,810
they're basically the steps on the left

00:16:39,900 --> 00:16:46,440
hand side they're the system which is

00:16:42,810 --> 00:16:51,780
perfect knowledge producing some events

00:16:46,440 --> 00:16:53,970
and the the events are purely passed

00:16:51,780 --> 00:16:56,910
internally in the initial monolithic

00:16:53,970 --> 00:16:58,560
application to the checking rules in the

00:16:56,910 --> 00:17:00,690
two orange boxes there which then

00:16:58,560 --> 00:17:02,400
produced some violations well that's

00:17:00,690 --> 00:17:03,750
great I mean it works fine it's just

00:17:02,400 --> 00:17:05,550
it's not scalable it doesn't really

00:17:03,750 --> 00:17:08,430
demonstrate anything terribly

00:17:05,550 --> 00:17:11,310
interesting so what we had to do is the

00:17:08,430 --> 00:17:15,540
couple the simulation side from the

00:17:11,310 --> 00:17:17,130
checking side using event streams so as

00:17:15,540 --> 00:17:19,620
you see there's a whole bunch of sensor

00:17:17,130 --> 00:17:22,560
events and then the RFID events for

00:17:19,620 --> 00:17:25,670
unload and load being passed from the

00:17:22,560 --> 00:17:31,800
the simulation stack into the checking

00:17:25,670 --> 00:17:33,780
system on the right hand side there okay

00:17:31,800 --> 00:17:36,090
so the next step is to move to a real

00:17:33,780 --> 00:17:37,710
distributed architecture so this is

00:17:36,090 --> 00:17:39,810
where we actually introduce separate

00:17:37,710 --> 00:17:43,950
caprica producers and consumers the

00:17:39,810 --> 00:17:45,360
producers basically the application

00:17:43,950 --> 00:17:48,570
running the simulation on the left-hand

00:17:45,360 --> 00:17:51,210
side the consumers are essentially the

00:17:48,570 --> 00:17:55,350
the rule checking

00:17:51,210 --> 00:17:57,630
for the goods themselves the simulation

00:17:55,350 --> 00:18:00,150
has perfect knowledge but I did assume

00:17:57,630 --> 00:18:02,760
that the the rule checking system relies

00:18:00,150 --> 00:18:05,370
on the event stream data for its context

00:18:02,760 --> 00:18:06,540
in order to to make decisions about

00:18:05,370 --> 00:18:12,900
whether some of the rules are being

00:18:06,540 --> 00:18:17,580
violated or not so I had some design

00:18:12,900 --> 00:18:19,170
goals the primary one was one of the

00:18:17,580 --> 00:18:22,740
deliver events produced from each

00:18:19,170 --> 00:18:26,670
location to goods in the same location

00:18:22,740 --> 00:18:29,310
so if we have some warehouses and trucks

00:18:26,670 --> 00:18:31,020
on the left-hand side here and the goods

00:18:29,310 --> 00:18:33,660
on the right-hand side are actually in

00:18:31,020 --> 00:18:35,850
those locations and we want the the

00:18:33,660 --> 00:18:37,650
sensor events and the RFID events and

00:18:35,850 --> 00:18:40,140
those locations to only be delivered for

00:18:37,650 --> 00:18:42,170
those Goods and always delivered to

00:18:40,140 --> 00:18:45,630
those goods if you if you like so

00:18:42,170 --> 00:18:47,130
there's at least two aspects to that you

00:18:45,630 --> 00:18:53,340
want guaranteed delivery and you don't

00:18:47,130 --> 00:18:54,960
want the event sent the wrong good now

00:18:53,340 --> 00:18:57,090
in terms of how you would implement this

00:18:54,960 --> 00:18:58,410
in Kefka well because I was learning in

00:18:57,090 --> 00:18:59,820
Category at the time it seemed to me

00:18:58,410 --> 00:19:03,090
that there were a number of different

00:18:59,820 --> 00:19:04,770
variables and therefore that the impact

00:19:03,090 --> 00:19:07,830
of the design decisions that I could

00:19:04,770 --> 00:19:10,230
make the first thing in in caf-co that's

00:19:07,830 --> 00:19:11,820
important is the topics so the topics of

00:19:10,230 --> 00:19:14,850
the mechanism that Kefka uses for

00:19:11,820 --> 00:19:18,000
delivering events to to a destination so

00:19:14,850 --> 00:19:19,320
it seemed relevant in this case so

00:19:18,000 --> 00:19:21,570
there's there's two extreme

00:19:19,320 --> 00:19:24,540
possibilities if you like one is any

00:19:21,570 --> 00:19:26,340
having one topic so in my case I could

00:19:24,540 --> 00:19:28,680
put all the locations together in one

00:19:26,340 --> 00:19:30,120
topic or the other approach which at the

00:19:28,680 --> 00:19:32,030
time seemed sensible was to have many

00:19:30,120 --> 00:19:34,260
topics and you could have one topic per

00:19:32,030 --> 00:19:37,230
location in other words one topic per

00:19:34,260 --> 00:19:39,360
warehouse and her truck so that seemed

00:19:37,230 --> 00:19:43,050
like a clever idea in terms of the

00:19:39,360 --> 00:19:46,130
consumers as well some of the design

00:19:43,050 --> 00:19:48,480
choices I thought of at the time where

00:19:46,130 --> 00:19:51,150
you could decouple the goods from the

00:19:48,480 --> 00:19:54,480
actual consumers and that seemed a bit

00:19:51,150 --> 00:19:56,490
complicated and unnecessary so I ended

00:19:54,480 --> 00:19:58,680
up trying the one on the right bottom

00:19:56,490 --> 00:20:01,440
there which is every good is actually a

00:19:58,680 --> 00:20:03,880
consumer or a consumer group in fact so

00:20:01,440 --> 00:20:05,890
this meant that the number of kaftan

00:20:03,880 --> 00:20:07,809
a number of CAF consumer groups was

00:20:05,890 --> 00:20:11,049
actually equal to the number of goods my

00:20:07,809 --> 00:20:14,350
simulation is that kind of work mmm

00:20:11,049 --> 00:20:18,160
we'll see so some of the problems with

00:20:14,350 --> 00:20:20,679
those two choices in particular first of

00:20:18,160 --> 00:20:22,090
all looking at the topic one or hundreds

00:20:20,679 --> 00:20:25,000
of locations or even potentially

00:20:22,090 --> 00:20:27,640
thousands means you have hundreds or

00:20:25,000 --> 00:20:28,809
thousands of cafe topics which is I mean

00:20:27,640 --> 00:20:31,299
you can sort of get away with a few

00:20:28,809 --> 00:20:33,309
hundred thousands ten thousands hundreds

00:20:31,299 --> 00:20:37,120
of thousands probably not so good for

00:20:33,309 --> 00:20:39,309
scalability to Kefka and the other

00:20:37,120 --> 00:20:40,720
problem is if you have a very large

00:20:39,309 --> 00:20:42,760
number of consumer groups

00:20:40,720 --> 00:20:44,980
you also have scalability problems

00:20:42,760 --> 00:20:46,780
unfortunately at that point so that the

00:20:44,980 --> 00:20:49,210
sort of the obvious way of doing this in

00:20:46,780 --> 00:20:52,750
terms of the design that fitted the the

00:20:49,210 --> 00:20:55,809
data model that I had actually didn't

00:20:52,750 --> 00:20:57,789
turn out so well so yeah I'm gonna have

00:20:55,809 --> 00:20:59,830
a look at the two extreme cases now and

00:20:57,789 --> 00:21:03,880
see how well they work so the possible

00:20:59,830 --> 00:21:06,330
design number one this is that when we

00:21:03,880 --> 00:21:09,220
have multiple topics and as many

00:21:06,330 --> 00:21:12,700
consumers as there are goods so lots of

00:21:09,220 --> 00:21:16,150
consumer groups so it looks like an

00:21:12,700 --> 00:21:19,840
elegant solution it sort of fits the the

00:21:16,150 --> 00:21:22,990
data model reasonably well design number

00:21:19,840 --> 00:21:25,000
two seems a bit unnecessarily simplistic

00:21:22,990 --> 00:21:26,850
at one level this is where you only have

00:21:25,000 --> 00:21:31,330
a single topic for all allocation data

00:21:26,850 --> 00:21:33,010
and a single consumer group and the

00:21:31,330 --> 00:21:34,900
goods objects and the system are

00:21:33,010 --> 00:21:37,690
essentially then decoupled from the the

00:21:34,900 --> 00:21:40,780
consumers by another magic component

00:21:37,690 --> 00:21:42,370
that I will gloss over at this this talk

00:21:40,780 --> 00:21:45,010
but there is another component that I

00:21:42,370 --> 00:21:46,600
had to insert at that point which made a

00:21:45,010 --> 00:21:50,460
decision about which events were going

00:21:46,600 --> 00:21:50,460
to which Goods based on location data

00:21:51,299 --> 00:21:57,010
yep okay so I decided to check the

00:21:55,030 --> 00:21:58,720
design before I tried the scaling the

00:21:57,010 --> 00:22:01,720
system out list to see which of those

00:21:58,720 --> 00:22:03,700
two extremes actually worked well so in

00:22:01,720 --> 00:22:07,990
a sense the problem is related to the

00:22:03,700 --> 00:22:09,580
the fan-out problem in Kefka so how well

00:22:07,990 --> 00:22:12,159
does catechol work for broadcast

00:22:09,580 --> 00:22:14,169
delivery of the same event to a very

00:22:12,159 --> 00:22:16,400
large number of consumers which is

00:22:14,169 --> 00:22:19,190
actually a perfectly valid use case

00:22:16,400 --> 00:22:20,990
Katka so don't be scared of that just

00:22:19,190 --> 00:22:23,030
don't do nothing quite as extremes what

00:22:20,990 --> 00:22:25,040
I was doing without thinking about it so

00:22:23,030 --> 00:22:28,400
my initial benchmarking just on a small

00:22:25,040 --> 00:22:30,800
katka cluster with a hundred locations a

00:22:28,400 --> 00:22:33,320
hundred thousand Goods so I found out of

00:22:30,800 --> 00:22:38,150
100 thousand so each event had to be

00:22:33,320 --> 00:22:39,620
delivered to a thousand consumers and

00:22:38,150 --> 00:22:44,630
you'll see the result here in terms of

00:22:39,620 --> 00:22:47,630
relative throughput the first design was

00:22:44,630 --> 00:22:49,250
very very poor tens of throughput and I

00:22:47,630 --> 00:22:52,490
was getting the maximum throughput for

00:22:49,250 --> 00:22:54,860
the system with the second design which

00:22:52,490 --> 00:22:56,960
has the single topic and the single

00:22:54,860 --> 00:22:58,850
consumer group so there's a massive

00:22:56,960 --> 00:23:01,250
difference in through port between the

00:22:58,850 --> 00:23:03,020
two designs which took me some time to

00:23:01,250 --> 00:23:05,810
work out what was going going wrong and

00:23:03,020 --> 00:23:08,170
why I'd made those choices and how to

00:23:05,810 --> 00:23:08,170
fix them

00:23:09,520 --> 00:23:16,190
so just a slightly different aspect of

00:23:12,650 --> 00:23:18,110
Kefka now I've talked about that was a

00:23:16,190 --> 00:23:19,670
bit about really in a sense the Kefka

00:23:18,110 --> 00:23:22,100
consumers and topics well there's

00:23:19,670 --> 00:23:24,680
another API and Kefka called the streams

00:23:22,100 --> 00:23:26,870
API this is actually really powerful and

00:23:24,680 --> 00:23:28,970
quite a clever part of the Kefka

00:23:26,870 --> 00:23:31,400
technology stack there's another API as

00:23:28,970 --> 00:23:33,380
well which enables you to connect kapha

00:23:31,400 --> 00:23:34,490
code up to other other things as well

00:23:33,380 --> 00:23:36,920
but I'm not going to talk about that

00:23:34,490 --> 00:23:39,170
today and turns out the Congo River

00:23:36,920 --> 00:23:40,730
actually has this crazy way of fishing

00:23:39,170 --> 00:23:42,500
they're basically to stick the nets and

00:23:40,730 --> 00:23:44,690
the rapids and wait for the fish to come

00:23:42,500 --> 00:23:49,790
along so in a sense catechist reams is a

00:23:44,690 --> 00:23:52,730
bit like that it is highly scalable the

00:23:49,790 --> 00:23:54,410
Kefka streams mechanism and again the

00:23:52,730 --> 00:23:59,200
the fishing does appear to be scalable

00:23:54,410 --> 00:24:02,540
than the Congo River there so you can

00:23:59,200 --> 00:24:05,420
scale out your streams application with

00:24:02,540 --> 00:24:08,870
things called tasks again it's

00:24:05,420 --> 00:24:12,560
complicated but possible so I just does

00:24:08,870 --> 00:24:14,720
a bit of an overview says the streams

00:24:12,560 --> 00:24:17,780
API allows an application to act as a

00:24:14,720 --> 00:24:19,840
streams processor so it can consume an

00:24:17,780 --> 00:24:22,520
input stream from one or more topics and

00:24:19,840 --> 00:24:25,100
produces an output stream again to one

00:24:22,520 --> 00:24:26,660
or more topics and it transforms input

00:24:25,100 --> 00:24:28,750
streams to the output stream so it's all

00:24:26,660 --> 00:24:31,210
about transformation

00:24:28,750 --> 00:24:33,460
the stream is an unbound and ordered

00:24:31,210 --> 00:24:35,820
replayable continuously updating data

00:24:33,460 --> 00:24:39,780
set consisting of strongly typed key

00:24:35,820 --> 00:24:39,780
value records yep

00:24:40,900 --> 00:24:46,840
so streams habit apology so a stream

00:24:44,530 --> 00:24:49,090
application is essentially a directed

00:24:46,840 --> 00:24:51,820
acyclic graph of stream process tools

00:24:49,090 --> 00:24:54,760
called nodes that are connected by

00:24:51,820 --> 00:24:56,440
streams or edges and they transform the

00:24:54,760 --> 00:24:57,790
data by receiving one input record

00:24:56,440 --> 00:25:03,610
applying an operation to it and then

00:24:57,790 --> 00:25:05,620
producing output records there's a DSL

00:25:03,610 --> 00:25:07,420
for it there is another mechanism which

00:25:05,620 --> 00:25:09,400
is a bit lower level again but I only

00:25:07,420 --> 00:25:11,680
had a look at the DSL so that the

00:25:09,400 --> 00:25:15,670
streams DSL has built-in abstractions

00:25:11,680 --> 00:25:17,770
for streams and tables so there's a

00:25:15,670 --> 00:25:20,440
whole bunch of sort of weirdly named

00:25:17,770 --> 00:25:22,330
things to do a streams and tables there

00:25:20,440 --> 00:25:24,160
and it supports a declarative functional

00:25:22,330 --> 00:25:26,740
programming style which is if you're

00:25:24,160 --> 00:25:28,240
familiar with that style it makes it

00:25:26,740 --> 00:25:29,770
relatively easy to write the streams

00:25:28,240 --> 00:25:30,940
application if you're not then it's a

00:25:29,770 --> 00:25:33,370
bit harder to get your head around that

00:25:30,940 --> 00:25:36,040
there's two sorts of transformations is

00:25:33,370 --> 00:25:38,440
stateless for example a map and the

00:25:36,040 --> 00:25:41,130
filter operation as well as stateful

00:25:38,440 --> 00:25:43,750
transformations such as aggregations

00:25:41,130 --> 00:25:45,550
including count reduced joins and

00:25:43,750 --> 00:25:49,870
windowing so it's got some quite complex

00:25:45,550 --> 00:25:52,360
stateful operations one of the problems

00:25:49,870 --> 00:25:55,120
that I as a beginner for the streams API

00:25:52,360 --> 00:25:56,830
I had was knowing how to compose these

00:25:55,120 --> 00:25:58,570
operations together to actually produce

00:25:56,830 --> 00:26:00,970
something that worked and that did

00:25:58,570 --> 00:26:04,480
something useful and it turned out this

00:26:00,970 --> 00:26:06,040
this diagram is the absolute key to that

00:26:04,480 --> 00:26:07,360
so this tells you it's essentially a

00:26:06,040 --> 00:26:10,330
state machine which tells you which

00:26:07,360 --> 00:26:12,640
operations work together what what

00:26:10,330 --> 00:26:14,410
output is produced by each operation

00:26:12,640 --> 00:26:17,980
type and what you can then do with the

00:26:14,410 --> 00:26:21,970
thing that's produced on that so this

00:26:17,980 --> 00:26:23,920
yeah this is a pretty useful diagram so

00:26:21,970 --> 00:26:26,170
the particular application extension

00:26:23,920 --> 00:26:27,730
that I decided to try out was checking

00:26:26,170 --> 00:26:28,990
of tracks but I overloaded it seemed

00:26:27,730 --> 00:26:31,780
like a natural fit to the logistics

00:26:28,990 --> 00:26:33,520
problem I had in mind my simulation

00:26:31,780 --> 00:26:36,040
initially had no concept about how many

00:26:33,520 --> 00:26:39,340
things could fit on a truck so I decided

00:26:36,040 --> 00:26:43,150
to impose some maximum load limits

00:26:39,340 --> 00:26:46,000
and produce some produce the goods with

00:26:43,150 --> 00:26:47,530
known weights as well and then I built a

00:26:46,000 --> 00:26:52,450
streams application which could check

00:26:47,530 --> 00:26:53,890
for overloading for the trucks so I

00:26:52,450 --> 00:26:56,050
won't show you the application it's sort

00:26:53,890 --> 00:26:57,550
of complicated and nasty it's on github

00:26:56,050 --> 00:26:59,200
if you wanna have a look but some of the

00:26:57,550 --> 00:27:01,840
things that I discovered building the

00:26:59,200 --> 00:27:04,750
streams application included getting

00:27:01,840 --> 00:27:08,650
lots of topology exceptions and floating

00:27:04,750 --> 00:27:10,410
trucks what are they well so it turns

00:27:08,650 --> 00:27:12,970
out that also this this actually is my

00:27:10,410 --> 00:27:16,980
streams application as you see the

00:27:12,970 --> 00:27:16,980
topology is sort of a bit complicated

00:27:17,310 --> 00:27:22,380
one thing I discovered that was really

00:27:19,540 --> 00:27:24,610
helpful for debugging it and also for

00:27:22,380 --> 00:27:26,290
finding out what was wrong with some of

00:27:24,610 --> 00:27:28,600
the topology errors I was getting is

00:27:26,290 --> 00:27:30,730
this thing which is a third-party tool

00:27:28,600 --> 00:27:36,130
which gives you a visualization of the

00:27:30,730 --> 00:27:37,990
of the stream so the first problem that

00:27:36,130 --> 00:27:41,170
solved was invalid pathologies I was

00:27:37,990 --> 00:27:42,970
getting topology errors and I had no

00:27:41,170 --> 00:27:46,840
idea what they meant but yeah being able

00:27:42,970 --> 00:27:48,250
to actually visualize using this tool

00:27:46,840 --> 00:27:49,840
was quite handy to work out that I'd

00:27:48,250 --> 00:27:53,740
actually made a mistake in this case and

00:27:49,840 --> 00:27:58,290
I was using the same node as a source

00:27:53,740 --> 00:28:01,750
for two operations which is not allowed

00:27:58,290 --> 00:28:05,260
and my- truck weight problem well had I

00:28:01,750 --> 00:28:06,460
invented anti-gravity or not now it

00:28:05,260 --> 00:28:08,260
turns out that there's quite a lot of

00:28:06,460 --> 00:28:10,690
Kefka settings that you you have to

00:28:08,260 --> 00:28:12,400
think about not thusly but the default

00:28:10,690 --> 00:28:14,620
setting and that was what was catching

00:28:12,400 --> 00:28:17,440
me out so I had to turn on the exactly

00:28:14,620 --> 00:28:20,770
once transactional setting so this

00:28:17,440 --> 00:28:22,480
allows a transactional producer allows

00:28:20,770 --> 00:28:25,540
an application to send messages to

00:28:22,480 --> 00:28:28,000
multiple petitions atomically so this

00:28:25,540 --> 00:28:32,140
actually solved my problem my weights no

00:28:28,000 --> 00:28:34,720
longer went negative so the final part

00:28:32,140 --> 00:28:36,610
of the story is about the scalability of

00:28:34,720 --> 00:28:38,260
the whole application so it turns out

00:28:36,610 --> 00:28:39,640
that Congo River actually has the

00:28:38,260 --> 00:28:42,040
biggest rapids in the world so it's a

00:28:39,640 --> 00:28:43,990
good choice of river I think as sort of

00:28:42,040 --> 00:28:47,590
an example for this type of problem so

00:28:43,990 --> 00:28:51,940
the Inga Rapids astonishingly be given

00:28:47,590 --> 00:28:53,500
me so let's go scaling is scrolling easy

00:28:51,940 --> 00:28:56,050
well

00:28:53,500 --> 00:28:58,540
I tried initially well in fact this is

00:28:56,050 --> 00:29:00,880
the well I finally ended up with 100

00:28:58,540 --> 00:29:06,060
warehouses 200 trucks which gave me 300

00:29:00,880 --> 00:29:08,470
locations and 10,000 Goods in the system

00:29:06,060 --> 00:29:11,470
so in terms of the scalability of the

00:29:08,470 --> 00:29:13,900
Kefka cluster itself

00:29:11,470 --> 00:29:17,700
I tried scaling out up and multiple

00:29:13,900 --> 00:29:21,430
clusters to see which ones would help

00:29:17,700 --> 00:29:24,330
so you'll see initially so 3 3 nodes of

00:29:21,430 --> 00:29:27,430
2 cores each 6 nodes the 2 cores each

00:29:24,330 --> 00:29:29,290
this third option which was 6 by 2 and a

00:29:27,430 --> 00:29:34,990
3 by 2 configuration and the finally the

00:29:29,290 --> 00:29:36,850
3 nodes by 4 cores each so yep so it

00:29:34,990 --> 00:29:39,550
does the scale and in different ways

00:29:36,850 --> 00:29:41,110
these are any relatively small clusters

00:29:39,550 --> 00:29:43,330
as well this was just for a demo

00:29:41,110 --> 00:29:46,030
application in production the sky's the

00:29:43,330 --> 00:29:49,630
limit in terms of how big you can scale

00:29:46,030 --> 00:29:52,420
it up the ability to split the

00:29:49,630 --> 00:29:54,130
application and put different topics on

00:29:52,420 --> 00:29:55,960
different characters there's actually

00:29:54,130 --> 00:29:58,120
quite a useful trick so you can actually

00:29:55,960 --> 00:29:59,680
scale the clusters independently and a

00:29:58,120 --> 00:30:02,380
lot of big users of Kafka do this

00:29:59,680 --> 00:30:04,800
including Netflix so you don't have to

00:30:02,380 --> 00:30:07,360
stick with just the one Kefka cluster

00:30:04,800 --> 00:30:11,050
bigger instance sizes actually have a

00:30:07,360 --> 00:30:14,020
huge impact on performance probably due

00:30:11,050 --> 00:30:19,750
to the the different network speeds that

00:30:14,020 --> 00:30:22,030
AWS allocated instance sizes is so the

00:30:19,750 --> 00:30:26,890
bigger the instance is the lower the

00:30:22,030 --> 00:30:28,630
latency by a long a long way probably

00:30:26,890 --> 00:30:30,670
the first thing that work contributes to

00:30:28,630 --> 00:30:33,280
that so we actually run some of our

00:30:30,670 --> 00:30:35,440
bigger instances our 8 core instances

00:30:33,280 --> 00:30:40,210
backed by SSDs so they're quite powerful

00:30:35,440 --> 00:30:42,040
instances running category and terms of

00:30:40,210 --> 00:30:43,720
the total resource usage so I've just

00:30:42,040 --> 00:30:45,670
been talking about the Kefka clusters so

00:30:43,720 --> 00:30:50,040
far the application itself was a

00:30:45,670 --> 00:30:52,210
significant consumer of AWS instances

00:30:50,040 --> 00:30:54,730
that turned out that the application

00:30:52,210 --> 00:30:56,140
itself used about twice as many cores as

00:30:54,730 --> 00:30:58,150
the caf-co cluster so it's not an

00:30:56,140 --> 00:30:59,860
insignificant part of the system in fact

00:30:58,150 --> 00:31:03,430
it's the biggest single part of the

00:30:59,860 --> 00:31:05,620
system that's running the application so

00:31:03,430 --> 00:31:06,850
in my most recent projects i've been

00:31:05,620 --> 00:31:08,610
using kubernetes for the

00:31:06,850 --> 00:31:10,600
doing the automation of the application

00:31:08,610 --> 00:31:12,820
provisioning and scalability in that

00:31:10,600 --> 00:31:14,440
that would be equally applicable for

00:31:12,820 --> 00:31:16,690
this project even though I didn't didn't

00:31:14,440 --> 00:31:18,490
use it but that that turns out to be

00:31:16,690 --> 00:31:20,440
quite a useful technology for managing

00:31:18,490 --> 00:31:25,480
the application scalability for systems

00:31:20,440 --> 00:31:28,480
like this so did I have any other

00:31:25,480 --> 00:31:33,070
problems have a game time few minutes

00:31:28,480 --> 00:31:35,680
the icon so so we we did manage this

00:31:33,070 --> 00:31:37,300
girl assistant successfully but as usual

00:31:35,680 --> 00:31:39,970
there were a few things we learnt along

00:31:37,300 --> 00:31:42,310
the way so it was actually quite hard to

00:31:39,970 --> 00:31:44,260
achieve linear scalability which is a

00:31:42,310 --> 00:31:46,720
bit odd because in Category scalable but

00:31:44,260 --> 00:31:48,490
you've got to actually take into account

00:31:46,720 --> 00:31:51,940
a few other other things that can happen

00:31:48,490 --> 00:31:53,440
the first problem I noticed as a result

00:31:51,940 --> 00:31:55,960
of hash collisions so what actually

00:31:53,440 --> 00:31:58,030
happened was I was getting an exception

00:31:55,960 --> 00:31:59,650
saying I had too many open files which

00:31:58,030 --> 00:32:01,930
seemed like an odd sort of an exception

00:31:59,650 --> 00:32:03,640
and this turned out to be due to him and

00:32:01,930 --> 00:32:07,300
increasing and eventually to many

00:32:03,640 --> 00:32:08,470
consumers and looking further at the

00:32:07,300 --> 00:32:11,260
problem that turned out that some

00:32:08,470 --> 00:32:12,850
consumers for timing out well why didn't

00:32:11,260 --> 00:32:15,040
Sheila's time out well it turns out that

00:32:12,850 --> 00:32:16,330
if a consumer doesn't receive any events

00:32:15,040 --> 00:32:18,700
in a particular time period they

00:32:16,330 --> 00:32:20,260
actually time out and say well I'm going

00:32:18,700 --> 00:32:24,520
away and my system automatically then

00:32:20,260 --> 00:32:28,000
spun up another consumer so I had 300

00:32:24,520 --> 00:32:31,180
locations but stupidly only had 300

00:32:28,000 --> 00:32:34,300
petitions and only its it turned out

00:32:31,180 --> 00:32:35,950
eventually 200 unique values so only 200

00:32:34,300 --> 00:32:37,660
consumers out of the 300 we were

00:32:35,950 --> 00:32:39,040
actually receiving in the events which

00:32:37,660 --> 00:32:41,650
meant that the rest turned out and gave

00:32:39,040 --> 00:32:43,870
me this this problem so essentially this

00:32:41,650 --> 00:32:46,390
is druid hashing collisions if some

00:32:43,870 --> 00:32:48,730
petitions get greater than one of their

00:32:46,390 --> 00:32:51,700
location values then others are going to

00:32:48,730 --> 00:32:53,260
get 0 which is not a good thing so this

00:32:51,700 --> 00:32:55,270
is actually well known problem so and

00:32:53,260 --> 00:32:56,560
it's been around since 1962 so I should

00:32:55,270 --> 00:32:58,480
have known about it and I just wasn't

00:32:56,560 --> 00:33:00,940
thinking it's the the key parking

00:32:58,480 --> 00:33:04,840
problem that noose first actually wrote

00:33:00,940 --> 00:33:06,550
about in his career so in the Kefka

00:33:04,840 --> 00:33:09,370
context you have to ensure that the

00:33:06,550 --> 00:33:11,110
number of keys is a lot greater than the

00:33:09,370 --> 00:33:14,110
number of partitions at least 20 times

00:33:11,110 --> 00:33:15,670
bigger is my rule of thumb and the

00:33:14,110 --> 00:33:17,290
number of petitions of course have to be

00:33:15,670 --> 00:33:19,390
greater than equal to the number of

00:33:17,290 --> 00:33:22,050
consumers in a group otherwise some of

00:33:19,390 --> 00:33:22,050
the consumers might

00:33:22,700 --> 00:33:27,590
again the second aspect of scalability

00:33:25,160 --> 00:33:29,570
is it's probably not one you'll come

00:33:27,590 --> 00:33:32,030
across because I was doing this sort of

00:33:29,570 --> 00:33:34,790
as an experimental system I was ramping

00:33:32,030 --> 00:33:36,350
up the load really quickly running it

00:33:34,790 --> 00:33:40,550
for a while and killing the whole system

00:33:36,350 --> 00:33:43,790
well this caused a problem called

00:33:40,550 --> 00:33:47,600
rebalancing so I was actually getting

00:33:43,790 --> 00:33:49,880
rebalancing storms rebalancing storms

00:33:47,600 --> 00:33:51,950
and Khafre result in some consumers not

00:33:49,880 --> 00:33:53,840
receiving events so you get a big drop

00:33:51,950 --> 00:33:56,120
in throughput for the system often first

00:33:53,840 --> 00:33:57,920
significant periods of time so and it

00:33:56,120 --> 00:34:00,110
was also producing a very slow startup

00:33:57,920 --> 00:34:03,200
time for new consumers up back to and

00:34:00,110 --> 00:34:04,850
more in some cases than 20 seconds so

00:34:03,200 --> 00:34:07,460
you need to ensure that your consumers

00:34:04,850 --> 00:34:09,620
are started and are polling the the calf

00:34:07,460 --> 00:34:11,480
current system before trying to add lots

00:34:09,620 --> 00:34:13,100
more consumers so I was essentially can

00:34:11,480 --> 00:34:15,770
I create all my consumers at once and

00:34:13,100 --> 00:34:17,390
that's not a great idea and you also

00:34:15,770 --> 00:34:20,660
want to try and keep the total number of

00:34:17,390 --> 00:34:22,760
consumers as low as practical as it

00:34:20,660 --> 00:34:25,310
turns out and this is the third point so

00:34:22,760 --> 00:34:27,740
if you've got too many consumers

00:34:25,310 --> 00:34:32,300
scalability suffers and you might get

00:34:27,740 --> 00:34:34,610
sucked into a whirlpool so in general

00:34:32,300 --> 00:34:37,430
for calf care less is more in terms of

00:34:34,610 --> 00:34:39,410
consumers so even though we used the

00:34:37,430 --> 00:34:43,100
design with the least consumers in

00:34:39,410 --> 00:34:45,950
theory if caf-co consumers take too long

00:34:43,100 --> 00:34:47,690
to read events and process them then you

00:34:45,950 --> 00:34:50,390
need more consumer threads and therefore

00:34:47,690 --> 00:34:53,150
more petitions which impacts the calf

00:34:50,390 --> 00:34:55,040
care cluster scalability so the solution

00:34:53,150 --> 00:34:57,230
is to minimize the consumer response

00:34:55,040 --> 00:34:59,240
time so you really only only want to use

00:34:57,230 --> 00:35:01,280
capita consumers for reading events from

00:34:59,240 --> 00:35:03,020
the calf code cluster and if you have to

00:35:01,280 --> 00:35:05,030
do any processing including writing to a

00:35:03,020 --> 00:35:06,680
database or something or running

00:35:05,030 --> 00:35:08,840
complicated algorithms or anything

00:35:06,680 --> 00:35:10,610
running complicated checks and there's a

00:35:08,840 --> 00:35:12,650
particular case you should do that

00:35:10,610 --> 00:35:14,620
processing asynchronously in a separate

00:35:12,650 --> 00:35:17,660
thread pool at least or some other

00:35:14,620 --> 00:35:20,480
scalable mechanism so my number one

00:35:17,660 --> 00:35:22,490
Kefka rule really is cathica is easy to

00:35:20,480 --> 00:35:27,980
scale as long as you have the smallest

00:35:22,490 --> 00:35:29,990
number of consumers possible so that's

00:35:27,980 --> 00:35:32,300
about it in terms of the formal part of

00:35:29,990 --> 00:35:34,160
the talk the code for both the congo

00:35:32,300 --> 00:35:36,589
application and the extension

00:35:34,160 --> 00:35:40,579
the streams extension is on a github

00:35:36,589 --> 00:35:42,739
page I've got a whole bunch of blogs on

00:35:40,579 --> 00:35:45,920
other sort of related topics the latest

00:35:42,739 --> 00:35:48,680
one was on anomaly detection using Kefka

00:35:45,920 --> 00:35:50,779
Cassandra and kubernetes that also

00:35:48,680 --> 00:35:52,220
includes some Prometheus and I've been

00:35:50,779 --> 00:35:53,420
tracing from the monitoring side which

00:35:52,220 --> 00:35:55,309
people might find interesting

00:35:53,420 --> 00:35:58,640
there's an extension to that work and

00:35:55,309 --> 00:36:00,559
doing geospatial anomaly detection with

00:35:58,640 --> 00:36:03,049
things like the leucine cassandra plugin

00:36:00,559 --> 00:36:04,430
and geohashes and stuff like that

00:36:03,049 --> 00:36:06,140
there's my visual introduction to

00:36:04,430 --> 00:36:07,309
category to sort of a fun either view or

00:36:06,140 --> 00:36:09,289
Kefka if you don't have a look at that

00:36:07,309 --> 00:36:11,749
and you can find out more about our

00:36:09,289 --> 00:36:13,880
manage platform and sign up for a free

00:36:11,749 --> 00:36:16,789
trial and test out anything you like as

00:36:13,880 --> 00:36:26,680
well so that's all from me thank you

00:36:16,789 --> 00:36:26,680
very much questions anybody

00:36:32,019 --> 00:36:40,519
Hey great talk so you mentioned that the

00:36:38,150 --> 00:36:42,049
like if we are doing any processing with

00:36:40,519 --> 00:36:44,690
consumers it should get either

00:36:42,049 --> 00:36:46,969
asynchronous or like put it inside on a

00:36:44,690 --> 00:36:49,160
thread yeah but wasn't that the whole

00:36:46,969 --> 00:36:50,569
point of using Kafka in the first place

00:36:49,160 --> 00:36:54,019
so that's what I thought because we

00:36:50,569 --> 00:36:56,210
we're using a log so that we can do this

00:36:54,019 --> 00:36:58,369
like we could push the this all this

00:36:56,210 --> 00:37:00,410
stuff into a log and then easily do it

00:36:58,369 --> 00:37:02,539
afterwards but now if we do the same

00:37:00,410 --> 00:37:05,089
thing like we're just using another log

00:37:02,539 --> 00:37:07,279
for the same purpose yeah I tend to

00:37:05,089 --> 00:37:10,160
agree this it's a bit of a tension

00:37:07,279 --> 00:37:12,859
I mean Kefka will scales I sure don't

00:37:10,160 --> 00:37:15,769
get me wrong you can put everything in

00:37:12,859 --> 00:37:17,210
New York York Africa consumers and but

00:37:15,769 --> 00:37:20,150
then you will have to increase the

00:37:17,210 --> 00:37:21,380
number of consumers inevitably and your

00:37:20,150 --> 00:37:22,729
throughput will suffer in which case

00:37:21,380 --> 00:37:24,559
you'll have to then get a bigger Kafka

00:37:22,729 --> 00:37:26,450
cluster so the mean there is a solution

00:37:24,559 --> 00:37:28,190
which is just to make the cluster bigger

00:37:26,450 --> 00:37:30,289
basically and there are some tuning

00:37:28,190 --> 00:37:31,940
settings that I haven't played around

00:37:30,289 --> 00:37:33,319
off yet but I'm in part of the issue I

00:37:31,940 --> 00:37:35,989
think is some of the default settings

00:37:33,319 --> 00:37:38,119
are not quite optimal for larger bhai

00:37:35,989 --> 00:37:39,410
throughputs it's it there is a bit of a

00:37:38,119 --> 00:37:41,509
trade-off though I think because there's

00:37:39,410 --> 00:37:44,499
sort of the application design which

00:37:41,509 --> 00:37:47,400
which may mean you want lots of

00:37:44,499 --> 00:37:49,319
consumers either accidentally or on

00:37:47,400 --> 00:37:50,220
on purpose but then yet at that point

00:37:49,319 --> 00:37:52,319
you really do need to think about

00:37:50,220 --> 00:38:03,380
whether your your Casa cluster is going

00:37:52,319 --> 00:38:03,380
to be able to deliver mm-hmm questions

00:38:04,819 --> 00:38:12,020
no well thank you again I've saw

00:38:06,960 --> 00:38:17,610
everyone's problem thank you

00:38:12,020 --> 00:38:17,610

YouTube URL: https://www.youtube.com/watch?v=tseAyqK8JEA


