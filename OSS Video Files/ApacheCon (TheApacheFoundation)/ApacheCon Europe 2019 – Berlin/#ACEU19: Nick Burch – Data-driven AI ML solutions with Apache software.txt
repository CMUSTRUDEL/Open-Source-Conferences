Title: #ACEU19: Nick Burch – Data-driven AI ML solutions with Apache software
Publication date: 2019-10-26
Playlist: ApacheCon Europe 2019 – Berlin
Description: 
	More: https://aceu19.apachecon.com/session/data-driven-aiml-solutions-apache-software

Classifying images into Cats or Hotdogs may make for great AI demos, but for many of us, it has limited $DAYJOB uses. What if you have loads of documents, or a bunch of legacy data? Fear not, Apache software can help!

We'll begin by building a few AI / ML systems to solve some common business problems, without a cat picture in sight (sorry...). We'll also cover some key concepts around building AI / ML systems, and some of the pitfalls that beginners risk encountering.

With the base AI bits covered, next we need to feed in some data! We'll review both common and lesser-known Apache projects, and see how we can combine them all to get our real-world data into something AI-friendly. Finally, we'll look at some real business problems we can solve by using all this Apache software together.

When we're done, you'll have seen some real business problems solved with AI (with the code!), know what to watch out for, and have discovered some of the Apache projects out there you'll need to build your own AI / ML business
solution.
Captions: 
	00:00:04,560 --> 00:00:12,600
Thanks okay so my name is Nick birch I'm

00:00:10,050 --> 00:00:15,270
director of engineering a small start-up

00:00:12,600 --> 00:00:18,120
called flick I'm also involved in a few

00:00:15,270 --> 00:00:19,770
of the Apache content projects and I'm

00:00:18,120 --> 00:00:21,980
involved in things like community

00:00:19,770 --> 00:00:25,890
development and incubator and so on

00:00:21,980 --> 00:00:28,680
so before I begin and you'll be able to

00:00:25,890 --> 00:00:31,710
find or you can find all of the code and

00:00:28,680 --> 00:00:34,800
all of the test data up at that URL as

00:00:31,710 --> 00:00:39,120
well as the slides so if you want to

00:00:34,800 --> 00:00:42,659
take a photo this is your chance what

00:00:39,120 --> 00:00:44,550
I've got is too much content for the

00:00:42,659 --> 00:00:47,070
time we have available because I'm not

00:00:44,550 --> 00:00:49,050
sure quite what level everyone's at so

00:00:47,070 --> 00:00:50,760
and do a show of hands in a second to

00:00:49,050 --> 00:00:53,460
gauge that so I know which slice to skip

00:00:50,760 --> 00:00:54,780
over and if you're unfortunately one of

00:00:53,460 --> 00:00:56,819
the sort of two people that put their

00:00:54,780 --> 00:00:58,769
hand up for a section I skip over then

00:00:56,819 --> 00:01:01,109
you can get the four slide deck and you

00:00:58,769 --> 00:01:04,470
can then see the bits that I went

00:01:01,109 --> 00:01:08,969
through quite quickly so who here has

00:01:04,470 --> 00:01:12,299
done some stuff with an AI ml framework

00:01:08,969 --> 00:01:16,020
like Apache MX net or scikit-learn any

00:01:12,299 --> 00:01:18,710
hands got a few okay and who's done

00:01:16,020 --> 00:01:24,869
stuff with natural language processing

00:01:18,710 --> 00:01:30,659
got a few here as well okay I'll do my

00:01:24,869 --> 00:01:33,869
best to cover off those things so the

00:01:30,659 --> 00:01:36,180
other thing is I've got the code

00:01:33,869 --> 00:01:39,210
available on a Microsoft Azure notebook

00:01:36,180 --> 00:01:44,119
so if you want to you can go here and

00:01:39,210 --> 00:01:47,340
get the Apache MX net code for this and

00:01:44,119 --> 00:01:50,820
then as well I gave a version of this

00:01:47,340 --> 00:01:52,890
talk at Berlin buzzwords here so you can

00:01:50,820 --> 00:01:54,149
watch the video of that later this one

00:01:52,890 --> 00:01:57,210
is also being videoed so you better

00:01:54,149 --> 00:02:01,320
catch up on that and then finally here's

00:01:57,210 --> 00:02:03,329
the simpler scikit-learn version if you

00:02:01,320 --> 00:02:05,520
want to have a play with that code and

00:02:03,329 --> 00:02:07,829
work along with that as well nice thing

00:02:05,520 --> 00:02:10,530
about is your notebooks is there free

00:02:07,829 --> 00:02:12,720
Microsoft have pre-installed most of the

00:02:10,530 --> 00:02:14,879
things you need though sadly not apache

00:02:12,720 --> 00:02:16,379
MX net so you have to install that but

00:02:14,879 --> 00:02:17,430
it means that you can have a play with a

00:02:16,379 --> 00:02:20,099
lot of this stuff

00:02:17,430 --> 00:02:21,840
without needing to install anything on

00:02:20,099 --> 00:02:23,129
your laptop so if you're on a corporate

00:02:21,840 --> 00:02:25,170
laptop you don't have to worry you can

00:02:23,129 --> 00:02:26,879
try it on the cloud if you're on a Mac

00:02:25,170 --> 00:02:28,620
and installing Python stuff as a pain

00:02:26,879 --> 00:02:29,930
again you don't have to worry it's it's

00:02:28,620 --> 00:02:33,810
all up there for you

00:02:29,930 --> 00:02:35,730
so this is not your typical a I talk

00:02:33,810 --> 00:02:39,480
we're going to be focused a lot more

00:02:35,730 --> 00:02:42,390
around and textual content going to look

00:02:39,480 --> 00:02:44,129
at how we can do some very simple AI

00:02:42,390 --> 00:02:46,739
stuff for text and then we'll take it

00:02:44,129 --> 00:02:47,849
through to a more complex bit and then

00:02:46,739 --> 00:02:49,620
I'm also going to tell you at the end

00:02:47,849 --> 00:02:51,569
about some of the things to be aware of

00:02:49,620 --> 00:02:54,590
and some of the other Apache projects

00:02:51,569 --> 00:02:58,680
you might want to go and investigate

00:02:54,590 --> 00:03:02,640
okay so what's a I and M L and why is it

00:02:58,680 --> 00:03:05,670
one of the the hot topics here today so

00:03:02,640 --> 00:03:08,640
AI artificial intelligence ml machine

00:03:05,670 --> 00:03:11,459
learning Larry Tesla's theorem is AI is

00:03:08,640 --> 00:03:13,769
whatever hasn't been done yet so maybe

00:03:11,459 --> 00:03:18,510
ml is everything that we we can go off

00:03:13,769 --> 00:03:20,159
and do today first big AI bubble maybe a

00:03:18,510 --> 00:03:23,280
few people in the audience were around

00:03:20,159 --> 00:03:26,160
for that and in the mid-1980s over a

00:03:23,280 --> 00:03:28,019
billion was spent on AI startups which

00:03:26,160 --> 00:03:31,169
were often at the time called expert

00:03:28,019 --> 00:03:34,019
systems they had two big drawbacks that

00:03:31,169 --> 00:03:36,389
caused the bubble to pop one is that

00:03:34,019 --> 00:03:38,730
they didn't have enough training data to

00:03:36,389 --> 00:03:40,620
build their systems and the other one is

00:03:38,730 --> 00:03:42,810
that the computers were a hell of a lot

00:03:40,620 --> 00:03:44,790
more expensive than the experts that the

00:03:42,810 --> 00:03:46,680
expert systems were trying to replace so

00:03:44,790 --> 00:03:51,389
no training data more expensive than the

00:03:46,680 --> 00:03:53,609
old thing pop okay what about today so

00:03:51,389 --> 00:03:56,430
Moore's law hopefully everyone knows

00:03:53,609 --> 00:03:59,040
Moore's law so 1 million dollars worth

00:03:56,430 --> 00:04:01,530
of computing power in 1985 from the

00:03:59,040 --> 00:04:04,440
heart of that original boom that's under

00:04:01,530 --> 00:04:06,150
$1 today if you go on Amazon with your

00:04:04,440 --> 00:04:08,849
credit card you can rent the machine

00:04:06,150 --> 00:04:12,660
with one terabyte of memory for about

00:04:08,849 --> 00:04:16,199
the cost of a latte per hour okay full

00:04:12,660 --> 00:04:18,389
terabyte machine 25 bucks an hour there

00:04:16,199 --> 00:04:21,690
are an awful lot of problems out there

00:04:18,389 --> 00:04:24,090
that can be solved for about 12 dollars

00:04:21,690 --> 00:04:26,130
by renting a machine from Amazon loading

00:04:24,090 --> 00:04:28,500
it all up into memory processing it

00:04:26,130 --> 00:04:31,169
dumping it out and then also we've got a

00:04:28,500 --> 00:04:32,729
lot more data to train our models on

00:04:31,169 --> 00:04:34,560
and we've got a lot of these awesome

00:04:32,729 --> 00:04:36,689
open-source libraries that make it

00:04:34,560 --> 00:04:38,909
really easy you don't have to sit there

00:04:36,689 --> 00:04:40,770
with all your maths textbooks and

00:04:38,909 --> 00:04:42,719
everything figuring out how to do the a

00:04:40,770 --> 00:04:44,249
I am writing the code for it in Fortran

00:04:42,719 --> 00:04:47,219
or something like that you can just go

00:04:44,249 --> 00:04:48,779
pip install MX net wait while it sucks

00:04:47,219 --> 00:04:56,639
down a third the internet and then off

00:04:48,779 --> 00:04:59,069
you go okay who's seen this xkcd there

00:04:56,639 --> 00:05:02,159
is a little we're actually quite a lot

00:04:59,069 --> 00:05:03,960
of truth in this but um people can just

00:05:02,159 --> 00:05:06,089
play with the AI tweak the parameters

00:05:03,960 --> 00:05:07,770
and maybe they'll get the right answer

00:05:06,089 --> 00:05:12,150
for their one testing and then they'll

00:05:07,770 --> 00:05:14,669
call it done um hopefully a lot of you

00:05:12,150 --> 00:05:16,229
in the audience are aware of this issue

00:05:14,669 --> 00:05:18,060
and will be trying to make sure that

00:05:16,229 --> 00:05:20,039
your systems have a reproducible

00:05:18,060 --> 00:05:21,960
pipeline that you actually store your

00:05:20,039 --> 00:05:25,080
high parameters that sort of thing but

00:05:21,960 --> 00:05:26,999
but do please before you try and make

00:05:25,080 --> 00:05:29,249
any important judgments based on your AI

00:05:26,999 --> 00:05:31,860
be aware of what's gone into it and how

00:05:29,249 --> 00:05:36,270
to reproduce it okay

00:05:31,860 --> 00:05:39,120
so typical AI demo is image

00:05:36,270 --> 00:05:42,000
classification so it's fun it's easy

00:05:39,120 --> 00:05:45,830
makes for a great demo okay who can who

00:05:42,000 --> 00:05:45,830
can be an AI what's this dogs or cats

00:05:46,399 --> 00:05:55,080
okay this one dogs or cats yeah so

00:05:53,339 --> 00:05:57,270
you've just trained a binary classifier

00:05:55,080 --> 00:06:00,689
to say dogs or cats and you feed it a

00:05:57,270 --> 00:06:02,759
koala not going to work so first a Oh a

00:06:00,689 --> 00:06:04,740
lesson it's only going to be as good as

00:06:02,759 --> 00:06:07,649
the training data and the problem you

00:06:04,740 --> 00:06:11,339
taught it on binary classifier a or B

00:06:07,649 --> 00:06:12,659
you feed it C it all goes wrong so okay

00:06:11,339 --> 00:06:17,819
train an image classifier what Anna

00:06:12,659 --> 00:06:24,710
wants this one kangaroo okay what about

00:06:17,819 --> 00:06:24,710
this one what map and this one

00:06:26,510 --> 00:06:33,230
this one's an echidna so again we built

00:06:31,310 --> 00:06:35,210
this great training system with images

00:06:33,230 --> 00:06:36,890
and we've just discovered that experts

00:06:35,210 --> 00:06:38,390
in the room don't know what it is so

00:06:36,890 --> 00:06:40,330
they can't classify it so we can't get

00:06:38,390 --> 00:06:47,420
the training data and it all falls apart

00:06:40,330 --> 00:06:50,900
now my data though doesn't look like

00:06:47,420 --> 00:06:54,470
that my data looks like this a lot of

00:06:50,900 --> 00:06:58,160
you probably have this kind of data so

00:06:54,470 --> 00:07:00,230
it's no good trying to get a bunch of

00:06:58,160 --> 00:07:04,150
humans on the internet to give you

00:07:00,230 --> 00:07:08,000
answers for this sort of thing because

00:07:04,150 --> 00:07:10,220
you might not be able to share these

00:07:08,000 --> 00:07:12,200
kind of things with random Mechanical

00:07:10,220 --> 00:07:14,830
Turks on the internet and even if you do

00:07:12,200 --> 00:07:16,640
they might not know what the answer is

00:07:14,830 --> 00:07:18,500
you probably have people in your

00:07:16,640 --> 00:07:21,620
organization that do but there tend to

00:07:18,500 --> 00:07:23,600
be really busy so what I want to talk to

00:07:21,620 --> 00:07:25,910
a little bit today is about what to do

00:07:23,600 --> 00:07:28,580
if we don't have the great training data

00:07:25,910 --> 00:07:30,110
we don't have the ground truth okay if

00:07:28,580 --> 00:07:31,880
you were interested in an image

00:07:30,110 --> 00:07:34,070
classification talk this was a brilliant

00:07:31,880 --> 00:07:35,900
one given in this very room about 18

00:07:34,070 --> 00:07:37,460
months ago so you can go look that one

00:07:35,900 --> 00:07:40,370
up and they've also got the video foul

00:07:37,460 --> 00:07:42,320
online but we're not going to be doing

00:07:40,370 --> 00:07:45,620
image classification we're going to be

00:07:42,320 --> 00:07:47,240
doing text so I've got lots of policies

00:07:45,620 --> 00:07:49,030
I've got procedures I've got training

00:07:47,240 --> 00:07:51,980
guides I've got help information and

00:07:49,030 --> 00:07:54,950
it's all in Word documents it's in

00:07:51,980 --> 00:07:59,930
spreadsheets it's in slideshows it's on

00:07:54,950 --> 00:08:02,930
wiki's all that kind of thing and I need

00:07:59,930 --> 00:08:04,730
to do in exact searches over them so

00:08:02,930 --> 00:08:06,700
I've got some project training material

00:08:04,730 --> 00:08:09,470
and I've got someone new to the project

00:08:06,700 --> 00:08:11,540
now you could just say well we're going

00:08:09,470 --> 00:08:12,440
to spin up an elastic search instance

00:08:11,540 --> 00:08:14,540
and away we go

00:08:12,440 --> 00:08:15,800
the problem is someone new to the

00:08:14,540 --> 00:08:18,500
project doesn't know the right

00:08:15,800 --> 00:08:20,030
terminology so it's no good saying all

00:08:18,500 --> 00:08:21,650
there's the elastic search we've fed all

00:08:20,030 --> 00:08:23,360
the data in because they don't know what

00:08:21,650 --> 00:08:25,550
to type into the search engine to find

00:08:23,360 --> 00:08:26,900
the answer that they need so at the

00:08:25,550 --> 00:08:28,460
moment they just keep messaging the

00:08:26,900 --> 00:08:30,950
really busy team lead and asking them

00:08:28,460 --> 00:08:33,670
and it doesn't really scale it really

00:08:30,950 --> 00:08:36,500
limits how quickly we can ramp people up

00:08:33,670 --> 00:08:38,450
got RFP questionnaires lots of customers

00:08:36,500 --> 00:08:39,740
saying hey we might want to work with

00:08:38,450 --> 00:08:41,539
you but here's our

00:08:39,740 --> 00:08:44,300
wonderful list of questions go and fill

00:08:41,539 --> 00:08:46,580
them in and they're always asking us the

00:08:44,300 --> 00:08:49,220
same things but they never used the same

00:08:46,580 --> 00:08:51,110
words and they always insist on using

00:08:49,220 --> 00:08:53,029
their own templates and unfortunately

00:08:51,110 --> 00:08:55,790
because we want their cash we can't say

00:08:53,029 --> 00:08:57,980
no you must use our format we just have

00:08:55,790 --> 00:08:59,300
to use theirs and the workaround is that

00:08:57,980 --> 00:09:01,279
lots of really busy people keep

00:08:59,300 --> 00:09:02,600
rewriting the same text because the

00:09:01,279 --> 00:09:04,790
question is slightly different and the

00:09:02,600 --> 00:09:07,640
contracts team can't find it and it's

00:09:04,790 --> 00:09:10,070
terrible and then job titles and job

00:09:07,640 --> 00:09:12,170
postings people say or you know I need a

00:09:10,070 --> 00:09:13,580
developer I need a senior developer II

00:09:12,170 --> 00:09:15,260
need a Java developer in the Java

00:09:13,580 --> 00:09:17,240
engineer all these kind of things it's

00:09:15,260 --> 00:09:19,100
all the same thing but these in the

00:09:17,240 --> 00:09:21,380
wrong terms and so we can work around

00:09:19,100 --> 00:09:22,790
this by giving a little translation

00:09:21,380 --> 00:09:24,410
guide to the people but then they get

00:09:22,790 --> 00:09:26,540
grumpy because doesn't match what the

00:09:24,410 --> 00:09:29,600
client wanted and again it's it's a pain

00:09:26,540 --> 00:09:32,120
because we haven't got one ground truth

00:09:29,600 --> 00:09:37,490
we haven't got one answer we've got the

00:09:32,120 --> 00:09:39,080
complex world of human language so my

00:09:37,490 --> 00:09:41,029
other problem is I can't show you most

00:09:39,080 --> 00:09:43,640
of the documents that I use internally

00:09:41,029 --> 00:09:46,339
to train on this but I do have all of

00:09:43,640 --> 00:09:48,529
the Berlin buzzwords talks available and

00:09:46,339 --> 00:09:51,589
I picked Berlin buzzwords because the

00:09:48,529 --> 00:09:54,529
approach econ website changes who's

00:09:51,589 --> 00:09:55,670
producing it an exact URL format a lot -

00:09:54,529 --> 00:09:57,320
whereas the Berlin buzzwords one is

00:09:55,670 --> 00:10:00,290
quite stable fairly similar set the

00:09:57,320 --> 00:10:02,089
talks so I'm going to use the titles and

00:10:00,290 --> 00:10:05,570
the abstracts for a few of the examples

00:10:02,089 --> 00:10:07,760
because we might want to find talks

00:10:05,570 --> 00:10:09,589
about AI and ml and all the different

00:10:07,760 --> 00:10:12,110
things and it's better example than

00:10:09,589 --> 00:10:15,079
documents I can't show you so they look

00:10:12,110 --> 00:10:18,940
kind of like this yeah a title but the

00:10:15,079 --> 00:10:23,329
text whole load of keywords and things

00:10:18,940 --> 00:10:25,070
so what do we want to do well one of the

00:10:23,329 --> 00:10:28,279
things we might want to do is sort of a

00:10:25,070 --> 00:10:31,190
bit like clustering if you're interested

00:10:28,279 --> 00:10:33,740
in this talk what other talks might you

00:10:31,190 --> 00:10:35,480
want to go and find out about partly

00:10:33,740 --> 00:10:37,370
it's a recommendation thing people who

00:10:35,480 --> 00:10:39,589
are searching and found this talk what

00:10:37,370 --> 00:10:43,160
are the searches were they interested in

00:10:39,589 --> 00:10:45,230
doing but it's not exact matching and we

00:10:43,160 --> 00:10:47,329
don't have wonderful classification

00:10:45,230 --> 00:10:49,010
labels and I haven't been able to get

00:10:47,329 --> 00:10:51,440
anyone no matter how much beer I

00:10:49,010 --> 00:10:52,899
promised them to go through and label

00:10:51,440 --> 00:10:55,119
every single talk in the

00:10:52,899 --> 00:10:56,709
conference with particular specific

00:10:55,119 --> 00:11:00,189
labels so that we can do exact matching

00:10:56,709 --> 00:11:02,709
and unfortunately I can't really a be

00:11:00,189 --> 00:11:04,480
test it I can't at the end of the

00:11:02,709 --> 00:11:06,069
conference on Thursday say okay everyone

00:11:04,480 --> 00:11:07,629
jump back in the time machine try

00:11:06,069 --> 00:11:09,399
different set of talks and then tell me

00:11:07,629 --> 00:11:12,100
if my system was better or worse the

00:11:09,399 --> 00:11:13,480
second time than the first time and it

00:11:12,100 --> 00:11:15,999
also struggles with people that give

00:11:13,480 --> 00:11:20,499
really wacky fun titles so we've got

00:11:15,999 --> 00:11:24,249
this in exactness again affecting us um

00:11:20,499 --> 00:11:27,399
another issue is that AI nml frameworks

00:11:24,249 --> 00:11:30,999
don't like Word documents they don't

00:11:27,399 --> 00:11:33,730
like PDFs so Apache tika jumps into the

00:11:30,999 --> 00:11:36,389
rescue others talking here are also ago

00:11:33,730 --> 00:11:40,689
about tika as well and so it lets us

00:11:36,389 --> 00:11:42,160
hand over this messy word document or

00:11:40,689 --> 00:11:44,110
maybe even think that we don't know what

00:11:42,160 --> 00:11:46,179
it is and get back some nice

00:11:44,110 --> 00:11:48,759
semantically meaningful HTML or some

00:11:46,179 --> 00:11:51,429
metadata or some plain text so that we

00:11:48,759 --> 00:11:55,029
can then get something that's text that

00:11:51,429 --> 00:11:56,170
we can feed into the AI in ml so first

00:11:55,029 --> 00:11:58,029
thing is you've probably got all these

00:11:56,170 --> 00:12:01,029
Word documents and whatnot make use of a

00:11:58,029 --> 00:12:04,870
patchy Tico get the text all right text

00:12:01,029 --> 00:12:06,670
awesome here we are if you were to go to

00:12:04,870 --> 00:12:08,709
the URL look in the sample data you'll

00:12:06,670 --> 00:12:13,059
see JSON that looks like this without

00:12:08,709 --> 00:12:16,389
tracks and titles and so on okay text

00:12:13,059 --> 00:12:21,429
JSON clean no Word documents no funny

00:12:16,389 --> 00:12:24,279
accents we're all set and no none of the

00:12:21,429 --> 00:12:27,279
AI n ml frameworks talk JSON either and

00:12:24,279 --> 00:12:30,990
they don't talk JSON of text what they

00:12:27,279 --> 00:12:34,300
want is ones and zeros or things between

00:12:30,990 --> 00:12:36,370
anyone remember matrix multiplication

00:12:34,300 --> 00:12:39,059
that sort of thing from maths classes or

00:12:36,370 --> 00:12:42,839
university and so on and unfortunately

00:12:39,059 --> 00:12:45,730
most of the AI ml stuff ends up with

00:12:42,839 --> 00:12:48,129
complicated vector space diagrams you

00:12:45,730 --> 00:12:50,439
don't need to know all of it but you do

00:12:48,129 --> 00:12:53,170
have to translate your stuff into that

00:12:50,439 --> 00:12:56,199
kind of thing so it can work now you can

00:12:53,170 --> 00:12:57,970
have sparse matrices where only the old

00:12:56,199 --> 00:12:59,799
thing is filled in or you can have

00:12:57,970 --> 00:13:04,209
really dense ones we're almost every

00:12:59,799 --> 00:13:05,430
position in the matrix has a value if

00:13:04,209 --> 00:13:07,710
you have

00:13:05,430 --> 00:13:09,360
quite quite a large number of features

00:13:07,710 --> 00:13:11,760
in your data then you're gonna need more

00:13:09,360 --> 00:13:13,620
memory and more CPU if you can shrink it

00:13:11,760 --> 00:13:15,030
down to a smaller set then it's gonna be

00:13:13,620 --> 00:13:18,290
a bit cheaper it may be a bit less

00:13:15,030 --> 00:13:20,940
precise so here's your next challenge

00:13:18,290 --> 00:13:23,460
how big is your laptop how big is your

00:13:20,940 --> 00:13:24,960
data center how much credit limit is

00:13:23,460 --> 00:13:26,780
there on your corporate credit card that

00:13:24,960 --> 00:13:28,890
you can get away with burning on Amazon

00:13:26,780 --> 00:13:29,970
that's a trade-off that you're going to

00:13:28,890 --> 00:13:34,890
have to make and that's going to affect

00:13:29,970 --> 00:13:36,330
what goes on okay we had a few people in

00:13:34,890 --> 00:13:38,220
the audience that didn't put their hands

00:13:36,330 --> 00:13:41,850
up for some of the Aoi nml stuff so a

00:13:38,220 --> 00:13:44,880
few key bits of terminology so a feature

00:13:41,850 --> 00:13:47,400
is some kind of input variable that

00:13:44,880 --> 00:13:49,830
you're going to use for prediction so it

00:13:47,400 --> 00:13:51,930
might be the height and width of an

00:13:49,830 --> 00:13:55,830
image it might be the different RGB

00:13:51,930 --> 00:13:59,040
channels of your your image data or it

00:13:55,830 --> 00:14:02,700
might be whether a particular document

00:13:59,040 --> 00:14:05,850
is talking about AI or whether it's

00:14:02,700 --> 00:14:08,520
talking about Java okay if we're working

00:14:05,850 --> 00:14:10,800
with labeled data for classification

00:14:08,520 --> 00:14:15,000
that's the value that this thing should

00:14:10,800 --> 00:14:18,000
map to this image should be a dog this

00:14:15,000 --> 00:14:20,000
image should be on that so that's when

00:14:18,000 --> 00:14:23,100
we know what it is

00:14:20,000 --> 00:14:28,200
training is the process of taking this

00:14:23,100 --> 00:14:30,000
bucket of data and a list of labels or

00:14:28,200 --> 00:14:32,640
some sort of scoring parameter and

00:14:30,000 --> 00:14:34,650
getting out a model and then inference

00:14:32,640 --> 00:14:36,450
is when we take that model we hand it to

00:14:34,650 --> 00:14:39,780
something it's never seen before and it

00:14:36,450 --> 00:14:41,250
says on that if all of this is new to

00:14:39,780 --> 00:14:43,290
you Google have got a pretty good crash

00:14:41,250 --> 00:14:47,610
course on a lot of this terminology that

00:14:43,290 --> 00:14:50,220
you can go look later a few more things

00:14:47,610 --> 00:14:53,820
so regression is for continuous

00:14:50,220 --> 00:14:56,430
variables if a house is in this bit of

00:14:53,820 --> 00:14:58,400
California with this many bedrooms what

00:14:56,430 --> 00:15:01,050
do we think the likely price is

00:14:58,400 --> 00:15:04,230
classification is the discrete values so

00:15:01,050 --> 00:15:06,900
is this a dog or a cat and then

00:15:04,230 --> 00:15:08,430
clustering is where you're saying these

00:15:06,900 --> 00:15:11,070
things are like each other these things

00:15:08,430 --> 00:15:12,570
are like each other so if you know what

00:15:11,070 --> 00:15:15,090
those things that should be grouping

00:15:12,570 --> 00:15:16,260
into that's the classification and if

00:15:15,090 --> 00:15:18,420
you don't know what it is and you've

00:15:16,260 --> 00:15:20,850
just got some sort of sense or scoring

00:15:18,420 --> 00:15:24,959
that's that's the unsupervised machine

00:15:20,850 --> 00:15:27,000
learning clustering okay so we've got

00:15:24,959 --> 00:15:29,940
our Word document we've turned it into

00:15:27,000 --> 00:15:32,279
some text we've got that text available

00:15:29,940 --> 00:15:34,200
and the next thing we have to do is

00:15:32,279 --> 00:15:36,930
break it down into smaller units into

00:15:34,200 --> 00:15:38,339
tokens typically what you do is just

00:15:36,930 --> 00:15:41,579
split it on white space or something

00:15:38,339 --> 00:15:43,680
like that if this is all new to you go

00:15:41,579 --> 00:15:45,480
look up any blue scene talk it's the

00:15:43,680 --> 00:15:47,100
same kind of thing for searching an

00:15:45,480 --> 00:15:49,380
information retrieval but we've got to

00:15:47,100 --> 00:15:53,100
get our work our text into chunks

00:15:49,380 --> 00:15:55,829
for example words okay now we need

00:15:53,100 --> 00:15:58,440
numbers so the simplest thing to do is

00:15:55,829 --> 00:16:00,120
build up a term dictionary so for every

00:15:58,440 --> 00:16:02,910
individual word that we find in our

00:16:00,120 --> 00:16:06,089
input text assign a unique index and

00:16:02,910 --> 00:16:07,350
then we can take our text and say the

00:16:06,089 --> 00:16:09,720
mouse ran up the clock it's these

00:16:07,350 --> 00:16:12,480
particular word indexes so we're getting

00:16:09,720 --> 00:16:14,970
into nearly numbers we still want things

00:16:12,480 --> 00:16:20,130
between minus 1 and 1 but we've at least

00:16:14,970 --> 00:16:22,589
gone from text into numbers the next

00:16:20,130 --> 00:16:26,610
thing we can do is count how often that

00:16:22,589 --> 00:16:28,769
particular word or token occurs and if

00:16:26,610 --> 00:16:30,899
we're just saying present or not present

00:16:28,769 --> 00:16:33,690
that's called one hot encoding so it's

00:16:30,899 --> 00:16:35,370
just seeing ones and zeros and another

00:16:33,690 --> 00:16:37,500
thing that's commonly is continuous bag

00:16:35,370 --> 00:16:39,720
of word account just literally how many

00:16:37,500 --> 00:16:46,199
times have you seen this word in the

00:16:39,720 --> 00:16:50,399
text the final trick for simple text in

00:16:46,199 --> 00:16:53,160
AI is called tf-idf term frequency

00:16:50,399 --> 00:16:56,279
inverse document frequency if a word

00:16:53,160 --> 00:16:58,649
occurs a lot in most of your files you

00:16:56,279 --> 00:17:01,740
probably don't care about it whether or

00:16:58,649 --> 00:17:04,319
not a word contains V or a not going to

00:17:01,740 --> 00:17:07,890
have a huge impact on the outcome of

00:17:04,319 --> 00:17:10,079
your AI and if a word occurs a lot in

00:17:07,890 --> 00:17:11,490
one document but not the others it's

00:17:10,079 --> 00:17:14,699
probably really important for that one

00:17:11,490 --> 00:17:16,829
document but if your document is really

00:17:14,699 --> 00:17:18,360
really really long it's going to managed

00:17:16,829 --> 00:17:19,470
to cram loads of different words in and

00:17:18,360 --> 00:17:21,540
that's maybe going to be less relevant

00:17:19,470 --> 00:17:23,760
than if we've got a single short title

00:17:21,540 --> 00:17:26,010
that contains the word so you want to

00:17:23,760 --> 00:17:28,350
rate rarer terms higher common words

00:17:26,010 --> 00:17:31,080
lower that sort of thing there are

00:17:28,350 --> 00:17:32,370
better algorithms out there and the

00:17:31,080 --> 00:17:33,630
lutein folks can tell you

00:17:32,370 --> 00:17:35,430
about them but this is one of the

00:17:33,630 --> 00:17:39,240
simplest ones and one that most of the

00:17:35,430 --> 00:17:40,890
AI frameworks implement so based on the

00:17:39,240 --> 00:17:46,020
continues bag of words and then the

00:17:40,890 --> 00:17:48,720
tf-idf we can get something into zero

00:17:46,020 --> 00:17:50,400
zero nor point one zero zero not point

00:17:48,720 --> 00:17:54,540
five that kind of thing which is ready

00:17:50,400 --> 00:17:58,309
to feed it okay so our next challenge

00:17:54,540 --> 00:18:01,440
with at AI is we've got our vector of

00:17:58,309 --> 00:18:05,160
numbers for the different words but we

00:18:01,440 --> 00:18:06,690
don't know which is the right talk we

00:18:05,160 --> 00:18:11,610
don't know which is the right help

00:18:06,690 --> 00:18:15,090
document ideally what you do is go off

00:18:11,610 --> 00:18:16,890
and do a load of analysis with real

00:18:15,090 --> 00:18:19,110
humans and get them to go and rate your

00:18:16,890 --> 00:18:22,500
talks or get them to go through the help

00:18:19,110 --> 00:18:23,880
documents the trouble is that those

00:18:22,500 --> 00:18:25,290
people are normally really busy or

00:18:23,880 --> 00:18:28,200
expensive or something like that

00:18:25,290 --> 00:18:32,059
so one thing that you can potentially do

00:18:28,200 --> 00:18:35,220
is just use text similarity at the start

00:18:32,059 --> 00:18:38,460
then ask your users of your real system

00:18:35,220 --> 00:18:40,920
to explicitly or implicitly rate your

00:18:38,460 --> 00:18:43,590
answers use that to build up the

00:18:40,920 --> 00:18:45,210
training data and then finally do

00:18:43,590 --> 00:18:47,309
something really cool six months down

00:18:45,210 --> 00:18:49,260
the line where you've got real answers

00:18:47,309 --> 00:18:50,880
from real humans who maybe didn't

00:18:49,260 --> 00:18:52,260
realize that every time they were

00:18:50,880 --> 00:18:54,090
clicking through and you were measuring

00:18:52,260 --> 00:18:56,160
how long they were on the page you

00:18:54,090 --> 00:18:57,990
figured that if they went to a page and

00:18:56,160 --> 00:18:59,730
then clicked off a link than they

00:18:57,990 --> 00:19:01,410
probably liked it if they went to a page

00:18:59,730 --> 00:19:03,450
and stayed there for two minutes maybe

00:19:01,410 --> 00:19:05,100
they made a cup of tea or maybe they

00:19:03,450 --> 00:19:06,780
actually found that one relevant and if

00:19:05,100 --> 00:19:08,520
they click onto a page and then click

00:19:06,780 --> 00:19:11,309
back again quickly that was probably the

00:19:08,520 --> 00:19:14,400
wrong answer so you can maybe by doing

00:19:11,309 --> 00:19:17,040
some weblog scraping or analytics find

00:19:14,400 --> 00:19:19,260
out which answers mattered to people and

00:19:17,040 --> 00:19:22,760
then later on use that but for now we'll

00:19:19,260 --> 00:19:28,020
cheat and just do some text similarity

00:19:22,760 --> 00:19:30,000
so first bit of AI then is we're going

00:19:28,020 --> 00:19:32,790
to build a classification model for our

00:19:30,000 --> 00:19:35,100
talks train it from the title and the

00:19:32,790 --> 00:19:37,980
abstract with the tf-idf get the nice

00:19:35,100 --> 00:19:40,080
vector and then we'll ask a model to

00:19:37,980 --> 00:19:43,140
classify a query and we'll say which

00:19:40,080 --> 00:19:45,120
talk is this query like and then find

00:19:43,140 --> 00:19:49,639
other similar talks

00:19:45,120 --> 00:19:53,070
and in the end to do it with

00:19:49,639 --> 00:19:54,779
scikit-learn the answer is this bit of

00:19:53,070 --> 00:19:57,330
code here it's actually pretty good

00:19:54,779 --> 00:20:02,730
it fits on one slide mostly

00:19:57,330 --> 00:20:04,769
understandable so you can do this enough

00:20:02,730 --> 00:20:07,139
relatively easily and if you want to

00:20:04,769 --> 00:20:08,850
play with it then we can have it you can

00:20:07,139 --> 00:20:10,679
have a look on the is your notebook

00:20:08,850 --> 00:20:12,450
the codes there including all the setup

00:20:10,679 --> 00:20:15,149
and the loading and so on but all we

00:20:12,450 --> 00:20:18,379
need to do then is build a build the

00:20:15,149 --> 00:20:20,519
vectorizer feed in all the data build

00:20:18,379 --> 00:20:22,590
some sort of classifier so this is a

00:20:20,519 --> 00:20:24,869
multinomial naive bayes which is quite

00:20:22,590 --> 00:20:26,809
as input one check the text in and away

00:20:24,869 --> 00:20:32,039
we go

00:20:26,809 --> 00:20:35,610
and then this is the prediction so we

00:20:32,039 --> 00:20:37,980
take a bit of text we turn it into a

00:20:35,610 --> 00:20:40,919
vector space again we ask the classifier

00:20:37,980 --> 00:20:42,059
which talk is like that and this is then

00:20:40,919 --> 00:20:43,860
going to give us back the idea of the

00:20:42,059 --> 00:20:48,629
talk we turn that back into a title and

00:20:43,860 --> 00:20:53,009
we're were away so shall we MC if the

00:20:48,629 --> 00:20:56,869
demo gods are smiling on us people want

00:20:53,009 --> 00:21:15,830
to see that I haven't just made it up

00:20:56,869 --> 00:21:15,830
let's go over here so the order tf-idf

00:21:17,299 --> 00:21:22,100
build a model hopefully

00:21:29,570 --> 00:21:35,869
I had run all these in advance and then

00:21:34,429 --> 00:21:38,139
as you're kicked me off I made from the

00:21:35,869 --> 00:21:49,879
other room say sorry

00:21:38,139 --> 00:21:54,470
come on demigods like me no okay here's

00:21:49,879 --> 00:22:04,099
one I prepared earlier so we did a query

00:21:54,470 --> 00:22:07,759
here for machine learning and it came

00:22:04,099 --> 00:22:09,619
back with some some talks that were

00:22:07,759 --> 00:22:11,929
vaguely relevant to machine learning but

00:22:09,619 --> 00:22:13,999
not perfect so this is the disadvantage

00:22:11,929 --> 00:22:16,519
this is that we don't have any proper

00:22:13,999 --> 00:22:19,220
training data so just taking some of the

00:22:16,519 --> 00:22:23,119
individual words ignoring their place in

00:22:19,220 --> 00:22:24,139
text ignoring the semantic meaning of

00:22:23,119 --> 00:22:25,700
them and just treating them as

00:22:24,139 --> 00:22:27,710
individual tokens and trying to do

00:22:25,700 --> 00:22:36,909
similar things we might get an OK

00:22:27,710 --> 00:22:39,470
response or we might not know okay so

00:22:36,909 --> 00:22:42,979
next approach we can take is the cluster

00:22:39,470 --> 00:22:44,599
the talks and so we want to try and

00:22:42,979 --> 00:22:46,879
figure out which talks are similar to

00:22:44,599 --> 00:22:50,599
other talks based on the text contained

00:22:46,879 --> 00:22:54,799
within them so the simplest way to do

00:22:50,599 --> 00:22:56,599
that is with something called k-means so

00:22:54,799 --> 00:22:57,950
we're going to say build an AI model

00:22:56,599 --> 00:22:59,629
that's going to figure out which things

00:22:57,950 --> 00:23:01,159
are near which other things group them

00:22:59,629 --> 00:23:02,899
together and then we can say if you're

00:23:01,159 --> 00:23:04,279
interested in this one talk you're going

00:23:02,899 --> 00:23:07,190
to probably be interested in the other

00:23:04,279 --> 00:23:09,440
talks similar to it likewise if you're

00:23:07,190 --> 00:23:12,349
interested in one particular help

00:23:09,440 --> 00:23:13,759
document or RFP response then other ones

00:23:12,349 --> 00:23:17,659
that are very similar might be of

00:23:13,759 --> 00:23:19,639
interest to you too now the challenge

00:23:17,659 --> 00:23:23,629
with clustering is how many clusters

00:23:19,639 --> 00:23:26,509
should you make so if we've got K terms

00:23:23,629 --> 00:23:28,159
in our tf-idf let's say we've got a

00:23:26,509 --> 00:23:30,499
thousand different words in all of our

00:23:28,159 --> 00:23:33,049
talks if we have a thousand clusters

00:23:30,499 --> 00:23:36,799
then each talk is going to fit perfectly

00:23:33,049 --> 00:23:39,529
into each cluster zero error but it's

00:23:36,799 --> 00:23:41,090
not a lot of help if every talk is on

00:23:39,529 --> 00:23:42,679
its own because then it's got nothing

00:23:41,090 --> 00:23:43,510
else with it and we can't figure out

00:23:42,679 --> 00:23:45,800
what similar

00:23:43,510 --> 00:23:47,900
likewise if we put everything into one

00:23:45,800 --> 00:23:50,090
group then everything has the maximum

00:23:47,900 --> 00:23:51,830
number of neighbors and our error is

00:23:50,090 --> 00:23:53,660
absolutely maxima and all we can say is

00:23:51,830 --> 00:23:56,210
people who went to this conference liked

00:23:53,660 --> 00:23:59,120
other talks from this conference people

00:23:56,210 --> 00:24:00,500
interested in help also wanted help so

00:23:59,120 --> 00:24:06,020
we need something somewhere between

00:24:00,500 --> 00:24:07,810
those two the other challenge that we're

00:24:06,020 --> 00:24:10,100
going to face is if we randomly

00:24:07,810 --> 00:24:13,850
initializing our clusters each time and

00:24:10,100 --> 00:24:15,050
we run and build a model from a random

00:24:13,850 --> 00:24:18,760
seed each time we're going to get

00:24:15,050 --> 00:24:21,860
different answers at the same size so

00:24:18,760 --> 00:24:24,200
random could potentially help us find

00:24:21,860 --> 00:24:26,090
the best thing but we're gonna need to

00:24:24,200 --> 00:24:27,740
run it a few times and potentially if we

00:24:26,090 --> 00:24:33,230
find one seed that works we'll save that

00:24:27,740 --> 00:24:37,010
and use that again so if we if we

00:24:33,230 --> 00:24:39,740
calculate the score based on the amount

00:24:37,010 --> 00:24:43,520
of error and we increase the size of the

00:24:39,740 --> 00:24:45,920
clusters we see that the bigger the

00:24:43,520 --> 00:24:47,750
cluster size the more accurate is the

00:24:45,920 --> 00:24:50,390
more we get to every talk being on its

00:24:47,750 --> 00:24:52,340
own but it's not it's not uniform

00:24:50,390 --> 00:24:54,140
there's certain sciences that work

00:24:52,340 --> 00:24:57,500
better certain sizes that work work

00:24:54,140 --> 00:24:59,240
worse so this is the next kind of lesson

00:24:57,500 --> 00:25:02,000
for your AI is that you're going to have

00:24:59,240 --> 00:25:04,340
to go and measure how different

00:25:02,000 --> 00:25:06,080
parameters affect your data and then

00:25:04,340 --> 00:25:07,880
make decisions for yourself so you might

00:25:06,080 --> 00:25:09,800
look at this and say well I've got about

00:25:07,880 --> 00:25:12,220
a thousand talks something around 50s

00:25:09,800 --> 00:25:15,620
about right let me find the value that's

00:25:12,220 --> 00:25:17,240
the the best match around that point and

00:25:15,620 --> 00:25:19,130
go for that or you might look at that

00:25:17,240 --> 00:25:21,620
and say oh actually I think maybe we

00:25:19,130 --> 00:25:24,170
want something about 70 so depending on

00:25:21,620 --> 00:25:26,480
your needs depending on how long you can

00:25:24,170 --> 00:25:28,100
wait for this to run the bigger the

00:25:26,480 --> 00:25:29,810
number of clusters the the longer it's

00:25:28,100 --> 00:25:31,730
going to take to get the answer you can

00:25:29,810 --> 00:25:34,460
make a decision that's right for you and

00:25:31,730 --> 00:25:36,440
for your business on how we should do

00:25:34,460 --> 00:25:39,890
the clustering or how we should gene a

00:25:36,440 --> 00:25:42,650
hyper parameter there are not simple

00:25:39,890 --> 00:25:44,150
answers it's not just like saying all my

00:25:42,650 --> 00:25:46,670
unit tests has grown green we're good

00:25:44,150 --> 00:25:48,560
you have to start thinking about what's

00:25:46,670 --> 00:25:51,500
going on what this data means what the

00:25:48,560 --> 00:25:55,100
outputs of this mean and then make best

00:25:51,500 --> 00:25:56,840
guess judgments on the parameters on the

00:25:55,100 --> 00:25:59,299
error measures that you get

00:25:56,840 --> 00:26:01,580
unfortunately this is a sort of slightly

00:25:59,299 --> 00:26:07,580
hand-wavy world that your your moving

00:26:01,580 --> 00:26:09,520
into now okay so that was that was the

00:26:07,580 --> 00:26:14,240
graph just for the cluster size to error

00:26:09,520 --> 00:26:15,860
but when we've got all the text so I've

00:26:14,240 --> 00:26:17,360
just got the text from five years of

00:26:15,860 --> 00:26:19,549
Berlin buzzword talks and I ended up

00:26:17,360 --> 00:26:24,049
with about twenty thousand entries in my

00:26:19,549 --> 00:26:26,809
tf-idf how many dimensions can we think

00:26:24,049 --> 00:26:29,149
about maybe if you're all specialist

00:26:26,809 --> 00:26:32,120
astrophysicists you can get up to six or

00:26:29,149 --> 00:26:34,130
seven most of us top out at three or

00:26:32,120 --> 00:26:36,740
four dimensions so we've got a problem

00:26:34,130 --> 00:26:39,919
that we want to visualize how our model

00:26:36,740 --> 00:26:41,210
is doing and it has all these thousands

00:26:39,919 --> 00:26:42,470
of dimensions even hundreds of

00:26:41,210 --> 00:26:44,600
dimensions which is more than we can

00:26:42,470 --> 00:26:46,250
cope with so one of the things that we

00:26:44,600 --> 00:26:50,210
can do is we can use a technique like

00:26:46,250 --> 00:26:51,799
t-sne or PCA to throw away a lot of

00:26:50,210 --> 00:26:53,360
those dimensions and then give us

00:26:51,799 --> 00:26:55,159
something that our brain can cope with

00:26:53,360 --> 00:26:57,080
so that we can then look at it and say

00:26:55,159 --> 00:27:00,230
hmmm that one's pretty better than that

00:26:57,080 --> 00:27:03,440
one now we are throwing away information

00:27:00,230 --> 00:27:05,360
so it's not going to be perfect but it's

00:27:03,440 --> 00:27:07,010
probably the best thing we can do to

00:27:05,360 --> 00:27:10,039
have a sort of finger in the air check

00:27:07,010 --> 00:27:15,080
if is our model working so you end up

00:27:10,039 --> 00:27:16,279
with things that look like this all

00:27:15,080 --> 00:27:18,679
things that look like this

00:27:16,279 --> 00:27:20,419
so the PS anyone we're including color

00:27:18,679 --> 00:27:22,309
as well so that we've got three

00:27:20,419 --> 00:27:25,520
dimensions and we've got the X the Y and

00:27:22,309 --> 00:27:27,350
the color it's a bit washed out on this

00:27:25,520 --> 00:27:29,960
have a look at the slides later it's

00:27:27,350 --> 00:27:30,950
still not perfect because we're still

00:27:29,960 --> 00:27:32,270
trying to map all these different

00:27:30,950 --> 00:27:34,130
dimensions down but you can look at that

00:27:32,270 --> 00:27:35,750
and say well on the whole things are

00:27:34,130 --> 00:27:38,020
fairly spread out it's not too much

00:27:35,750 --> 00:27:43,130
really close to other things probably

00:27:38,020 --> 00:27:44,840
the the groupings looking okay but it's

00:27:43,130 --> 00:27:47,990
not you're not just going to get a big

00:27:44,840 --> 00:27:49,580
tick or cross you're going to get fuzzy

00:27:47,990 --> 00:27:53,179
information that you've got to make

00:27:49,580 --> 00:27:56,149
sense of and I'll skip over a bit more

00:27:53,179 --> 00:27:58,669
on clustering and I won't do the demo

00:27:56,149 --> 00:28:00,230
because I sure doesn't like me in this

00:27:58,669 --> 00:28:02,330
room for some reason okay

00:28:00,230 --> 00:28:04,820
so the next thing we might want to do

00:28:02,330 --> 00:28:06,919
with our talk data or you might want to

00:28:04,820 --> 00:28:08,860
do with RFP responses or something like

00:28:06,919 --> 00:28:11,380
that you start adding a time

00:28:08,860 --> 00:28:12,640
mentioned to the scoring so for example

00:28:11,380 --> 00:28:14,770
we might say we're going to recommend

00:28:12,640 --> 00:28:16,960
videos at past conference talks to you

00:28:14,770 --> 00:28:21,429
that might help you find the answer to

00:28:16,960 --> 00:28:23,530
your question so could we prefer newer

00:28:21,429 --> 00:28:25,480
talks to older ones were in the tech

00:28:23,530 --> 00:28:27,460
industry things move relatively fast

00:28:25,480 --> 00:28:31,600
maybe a newer talk is better than an

00:28:27,460 --> 00:28:35,140
older talk so we can't necessarily

00:28:31,600 --> 00:28:37,600
easily add it as a feature because a

00:28:35,140 --> 00:28:39,040
query time you're not saying you know

00:28:37,600 --> 00:28:42,280
probably not going to say give me talks

00:28:39,040 --> 00:28:43,660
from 2018 you're going to say help my

00:28:42,280 --> 00:28:48,400
bosses just told me I've got to

00:28:43,660 --> 00:28:52,570
introduce Kafka by yesterday we can

00:28:48,400 --> 00:28:55,090
order in at scoring time but we need to

00:28:52,570 --> 00:28:56,799
take care that we don't push things into

00:28:55,090 --> 00:28:59,230
it for example into a different cluster

00:28:56,799 --> 00:29:04,960
or mess up the similarity on the vector

00:28:59,230 --> 00:29:06,340
space if we take the tf-idf weights and

00:29:04,960 --> 00:29:07,929
we say oh well we're going to shrink the

00:29:06,340 --> 00:29:10,540
tf-idf weights for everything that's a

00:29:07,929 --> 00:29:12,190
really old talk we can end up moving it

00:29:10,540 --> 00:29:13,929
so instead of being over here with all

00:29:12,190 --> 00:29:16,570
of its friends it's been shrunk down

00:29:13,929 --> 00:29:18,660
near the axis and it's now surrounded by

00:29:16,570 --> 00:29:22,809
other talks that are not relevant so

00:29:18,660 --> 00:29:25,630
adding these kind of things in is is is

00:29:22,809 --> 00:29:27,400
trickier and then our data isn't

00:29:25,630 --> 00:29:28,510
long-term static so next year there's

00:29:27,400 --> 00:29:30,640
going to be another Berlin buzzwords

00:29:28,510 --> 00:29:32,230
sometime in July that means there's

00:29:30,640 --> 00:29:34,390
gonna be another 100 all talks to go

00:29:32,230 --> 00:29:37,090
into our data set you've built your

00:29:34,390 --> 00:29:39,010
model of RFP responses now the query

00:29:37,090 --> 00:29:40,559
comes in from a new customer you need to

00:29:39,010 --> 00:29:44,309
add that extra question into the data

00:29:40,559 --> 00:29:46,750
you've got the training data for your

00:29:44,309 --> 00:29:50,350
for your system at work people already

00:29:46,750 --> 00:29:53,500
new features to it so you can't just

00:29:50,350 --> 00:29:55,660
trust the human provided answers that

00:29:53,500 --> 00:29:57,549
you've got because if someone adds

00:29:55,660 --> 00:29:59,890
something new in that's novel

00:29:57,549 --> 00:30:02,350
there's no rating for it there's no

00:29:59,890 --> 00:30:05,740
classification for it but it's new then

00:30:02,350 --> 00:30:07,510
maybe it's going to be more important so

00:30:05,740 --> 00:30:09,130
you're gonna have to deal with that

00:30:07,510 --> 00:30:11,799
challenge yourself say who or how much

00:30:09,130 --> 00:30:14,650
do I value novelty how much weight do I

00:30:11,799 --> 00:30:17,590
give to new things how do i boost things

00:30:14,650 --> 00:30:19,210
that have no other other ratings how

00:30:17,590 --> 00:30:21,880
much should i D weight the old things

00:30:19,210 --> 00:30:22,690
and that answer you're gonna have to try

00:30:21,880 --> 00:30:24,670
a few things out

00:30:22,690 --> 00:30:26,710
look at the answers maybe sit down with

00:30:24,670 --> 00:30:28,120
someone from the business and say which

00:30:26,710 --> 00:30:29,800
one of these three would you have really

00:30:28,120 --> 00:30:33,210
wanted and then we'll tweak the

00:30:29,800 --> 00:30:33,210
parameters and see which one comes out

00:30:34,470 --> 00:30:40,930
skip over that embedding some feature

00:30:37,210 --> 00:30:42,610
extraction so without text if we took

00:30:40,930 --> 00:30:44,590
all the text of all the Berlin bells

00:30:42,610 --> 00:30:49,570
where talks and put it through a tf-idf

00:30:44,590 --> 00:30:52,720
we got 30,000 different tokens out most

00:30:49,570 --> 00:30:55,840
of those are 0 if we're using something

00:30:52,720 --> 00:30:58,960
like Bayesian or k-means it's ok to have

00:30:55,840 --> 00:31:02,680
lots of zeros takes up more memory but

00:30:58,960 --> 00:31:05,050
as we saw 4 terabytes 25 bucks now we

00:31:02,680 --> 00:31:07,750
can just kind of be lazy

00:31:05,050 --> 00:31:10,750
but if we are trying to work with some

00:31:07,750 --> 00:31:12,520
of the neural network techniques then we

00:31:10,750 --> 00:31:15,010
really want something where most of the

00:31:12,520 --> 00:31:16,420
different dimensions have a value in so

00:31:15,010 --> 00:31:19,560
we're aiming for something with maybe 50

00:31:16,420 --> 00:31:22,930
or 100 features that have value not

00:31:19,560 --> 00:31:25,300
30,000 most of which are 0 otherwise it

00:31:22,930 --> 00:31:26,950
won't fit on the memory of your GPU and

00:31:25,300 --> 00:31:28,990
if it won't fit on the GPU and it has to

00:31:26,950 --> 00:31:31,330
go into main memory it's just got 100

00:31:28,990 --> 00:31:33,190
times slower so it's not if we want to

00:31:31,330 --> 00:31:34,780
do neural networks if we want to do GPU

00:31:33,190 --> 00:31:37,060
accelerated we've got to think about

00:31:34,780 --> 00:31:40,270
shrinking our data down so that it will

00:31:37,060 --> 00:31:42,640
fit onto the core of the GPU or

00:31:40,270 --> 00:31:45,760
something like that so they can be fast

00:31:42,640 --> 00:31:47,620
and so a text what that means that

00:31:45,760 --> 00:31:49,510
instead of just doing a tf-idf we've got

00:31:47,620 --> 00:31:52,630
to come up with an alternate way of

00:31:49,510 --> 00:31:56,950
getting the text into features and

00:31:52,630 --> 00:31:58,510
that's around the embeddings another

00:31:56,950 --> 00:32:00,550
problem we tf-idf is that you've got no

00:31:58,510 --> 00:32:03,340
semantic information and word order

00:32:00,550 --> 00:32:04,390
matters my Kindle is easy to use I do

00:32:03,340 --> 00:32:07,060
not need help

00:32:04,390 --> 00:32:10,720
great I do need help my Kindle is not

00:32:07,060 --> 00:32:13,320
easy to use bad now those two things

00:32:10,720 --> 00:32:15,730
will have exactly the same tf-idf

00:32:13,320 --> 00:32:17,620
representation because we're throwing

00:32:15,730 --> 00:32:20,020
away the word order all we count caring

00:32:17,620 --> 00:32:23,470
about is which words happened in the

00:32:20,020 --> 00:32:24,970
document somewhere so we're going to

00:32:23,470 --> 00:32:27,160
need to give someone very different

00:32:24,970 --> 00:32:28,960
answers very different help depending on

00:32:27,160 --> 00:32:32,940
which of those two it is but if we're

00:32:28,960 --> 00:32:32,940
just using tf-idf we've lost that

00:32:33,680 --> 00:32:39,000
so there are a bunch of different

00:32:36,600 --> 00:32:41,370
embeddings and proaches for those of you

00:32:39,000 --> 00:32:43,650
who want to go off and do reading later

00:32:41,370 --> 00:32:45,900
these are some of the the main ones to

00:32:43,650 --> 00:32:48,600
go and read up on I'm not sure why

00:32:45,900 --> 00:32:50,310
there's Elmo and birds and I think

00:32:48,600 --> 00:32:52,410
someone was having fun whose fan of

00:32:50,310 --> 00:32:54,600
Sesame Street they don't all have silly

00:32:52,410 --> 00:32:57,960
names but a lot of them seem to I think

00:32:54,600 --> 00:33:01,350
a lot of geeks seem to like funny names

00:32:57,960 --> 00:33:03,600
for things probably the easiest one to

00:33:01,350 --> 00:33:05,280
understand and one of the ones with the

00:33:03,600 --> 00:33:07,230
best talks out there so it's been around

00:33:05,280 --> 00:33:09,960
the longest is word to Veck

00:33:07,230 --> 00:33:14,760
so it's originally developed by Google

00:33:09,960 --> 00:33:18,030
and it's trying to put things with other

00:33:14,760 --> 00:33:19,560
words with a similar meaning and also so

00:33:18,030 --> 00:33:21,900
that as you move through the vector

00:33:19,560 --> 00:33:25,230
space you get a similar semantic meaning

00:33:21,900 --> 00:33:28,770
as you move through it so that hopefully

00:33:25,230 --> 00:33:31,350
you can say man is the boy what woman is

00:33:28,770 --> 00:33:32,880
to go so we've taken these concepts and

00:33:31,350 --> 00:33:35,340
then when we move through the vector

00:33:32,880 --> 00:33:38,850
space we'll end up with a word with the

00:33:35,340 --> 00:33:44,550
same relative meaning to them in a

00:33:38,850 --> 00:33:50,070
graphical form like this and that way

00:33:44,550 --> 00:33:53,880
when we're trying to produce an AI based

00:33:50,070 --> 00:33:57,060
on that if you give it a word that it

00:33:53,880 --> 00:33:58,920
hasn't seen that it has seen before but

00:33:57,060 --> 00:34:00,060
in a different context it can then try

00:33:58,920 --> 00:34:07,460
and make an inference and make a

00:34:00,060 --> 00:34:10,980
prediction that will be similar ok um

00:34:07,460 --> 00:34:14,790
next thing to be aware of testing

00:34:10,980 --> 00:34:18,419
cross-validation so if I have a hundred

00:34:14,790 --> 00:34:22,860
pieces of data and I feed all of them in

00:34:18,419 --> 00:34:25,290
the training step I've got nothing left

00:34:22,860 --> 00:34:27,300
to test how well it worked so if I fed a

00:34:25,290 --> 00:34:29,159
model 100 pieces of information and then

00:34:27,300 --> 00:34:31,350
I feed it the same hundred again it's

00:34:29,159 --> 00:34:32,370
probably going to do pretty well I mean

00:34:31,350 --> 00:34:34,530
if it doesn't then there's something

00:34:32,370 --> 00:34:36,300
wrong with your your AI but on the whole

00:34:34,530 --> 00:34:38,280
if you give it a piece of data to train

00:34:36,300 --> 00:34:39,629
on and then you ask it to predict it

00:34:38,280 --> 00:34:41,159
already knows what the right answer is

00:34:39,629 --> 00:34:43,350
so it can cheat and give you the answer

00:34:41,159 --> 00:34:46,159
back so when you're doing your training

00:34:43,350 --> 00:34:48,980
you need to keep some of that data back

00:34:46,159 --> 00:34:52,190
so that you can check how well the model

00:34:48,980 --> 00:34:54,190
works on all your data because it can do

00:34:52,190 --> 00:34:56,149
too well and it can end up overfitting

00:34:54,190 --> 00:34:59,539
so generally you don't want to have a

00:34:56,149 --> 00:35:01,940
split some of your data for doing the

00:34:59,539 --> 00:35:04,549
training some of your stuff for doing

00:35:01,940 --> 00:35:06,140
the testing and if you don't have a lot

00:35:04,549 --> 00:35:08,180
of data which is often going to be the

00:35:06,140 --> 00:35:10,549
case with this tech stuff where you

00:35:08,180 --> 00:35:13,640
maybe got two hours of an expert's time

00:35:10,549 --> 00:35:16,490
and they classified 50 documents you

00:35:13,640 --> 00:35:18,200
might need to try slicing the data up in

00:35:16,490 --> 00:35:20,960
multiple different ways training the

00:35:18,200 --> 00:35:23,059
model on multiple or current multiple

00:35:20,960 --> 00:35:24,920
different slices and then make sure that

00:35:23,059 --> 00:35:26,480
you get roughly the right answer out and

00:35:24,920 --> 00:35:32,359
they'll tell you that your model is not

00:35:26,480 --> 00:35:35,809
overfitting or under fitting hyper

00:35:32,359 --> 00:35:39,309
parameters really sort of sci-fi

00:35:35,809 --> 00:35:43,400
sounding thing and it's basically any

00:35:39,309 --> 00:35:46,549
knob that you twiddle on your AI that's

00:35:43,400 --> 00:35:48,049
not part of the input data so that might

00:35:46,549 --> 00:35:50,869
just mean what is the size of my cluster

00:35:48,049 --> 00:35:53,599
what's the initial seed that we're going

00:35:50,869 --> 00:35:56,420
to use and if you pick the wrong

00:35:53,599 --> 00:35:59,510
parameter then your AI might spend a

00:35:56,420 --> 00:36:01,609
huge amount of CPU cycles or GPU cycles

00:35:59,510 --> 00:36:03,890
trying to get out of a local minima to

00:36:01,609 --> 00:36:05,569
to find the best solution or it might

00:36:03,890 --> 00:36:09,589
even just give up early and then you

00:36:05,569 --> 00:36:12,799
haven't got the right model being good

00:36:09,589 --> 00:36:14,930
at picking - parameters is why some data

00:36:12,799 --> 00:36:20,839
scientists are able to attract huge

00:36:14,930 --> 00:36:22,190
amounts of salary it's is is though

00:36:20,839 --> 00:36:23,510
finger in the air they are looking at

00:36:22,190 --> 00:36:24,799
some of these graphs they are trying to

00:36:23,510 --> 00:36:27,440
figure out what's going to be the right

00:36:24,799 --> 00:36:29,319
kind of place to start the AI off when

00:36:27,440 --> 00:36:35,230
it goes off and and lends its models

00:36:29,319 --> 00:36:38,200
okay and errors errors are important and

00:36:35,230 --> 00:36:41,119
different kinds of errors so we can have

00:36:38,200 --> 00:36:43,250
true positive false positive true

00:36:41,119 --> 00:36:46,329
negative false negative so if you want

00:36:43,250 --> 00:36:51,230
to know what those mean and so on

00:36:46,329 --> 00:36:52,609
depending on what you're doing the thing

00:36:51,230 --> 00:36:55,160
that you want to optimize for is

00:36:52,609 --> 00:36:57,710
different if you're trying to detect

00:36:55,160 --> 00:36:59,790
cancer is it better to say to someone

00:36:57,710 --> 00:37:01,740
it's okay you haven't got cancer

00:36:59,790 --> 00:37:03,270
you're off you're free to go when it

00:37:01,740 --> 00:37:05,280
turns out they have and now they go off

00:37:03,270 --> 00:37:07,170
and die or is it better to go to someone

00:37:05,280 --> 00:37:09,990
and be like I think we're gonna have to

00:37:07,170 --> 00:37:11,550
we'll take your arm off turns out it was

00:37:09,990 --> 00:37:16,950
fine later but you know it's better to

00:37:11,550 --> 00:37:18,690
be safe than sorry you know hopefully

00:37:16,950 --> 00:37:20,460
your data is not going to be quite as

00:37:18,690 --> 00:37:21,360
critical as that but again you're going

00:37:20,460 --> 00:37:23,850
to need to sit down with the business

00:37:21,360 --> 00:37:26,640
and figure out what is the right answer

00:37:23,850 --> 00:37:33,120
how do we need to tune the AI so that we

00:37:26,640 --> 00:37:34,710
get the get the the best answers that we

00:37:33,120 --> 00:37:38,040
can with minimizing the errors that

00:37:34,710 --> 00:37:40,110
matter to us and another thing you need

00:37:38,040 --> 00:37:42,690
to be aware of is biases so if your

00:37:40,110 --> 00:37:43,980
input data is biased your model is going

00:37:42,690 --> 00:37:45,660
to be biased which means that your

00:37:43,980 --> 00:37:48,450
predictions are going to be biased

00:37:45,660 --> 00:37:51,150
you can try and hide biases from your

00:37:48,450 --> 00:37:53,610
model but if you do it badly they'll

00:37:51,150 --> 00:37:56,040
still come through so you might say okay

00:37:53,610 --> 00:37:57,390
I'm going to train a model on people and

00:37:56,040 --> 00:38:00,180
I'm not going to tell it the gender I

00:37:57,390 --> 00:38:02,000
want it to be gender blind but I'm gonna

00:38:00,180 --> 00:38:04,440
leave in everyone's name and

00:38:02,000 --> 00:38:06,960
unfortunately you're AI might then learn

00:38:04,440 --> 00:38:09,030
which names tend to be female which

00:38:06,960 --> 00:38:11,790
names tend to be male and then it's

00:38:09,030 --> 00:38:13,290
still figured out if you're male or

00:38:11,790 --> 00:38:16,740
female and then it's got the original

00:38:13,290 --> 00:38:18,420
biasing you might say oh well I'm

00:38:16,740 --> 00:38:20,910
worried about racial discrimination so

00:38:18,420 --> 00:38:23,700
I'm not going to teach my AI about race

00:38:20,910 --> 00:38:26,460
but if I've just left in your postcode

00:38:23,700 --> 00:38:29,430
your zip code or which school you went

00:38:26,460 --> 00:38:31,950
to when you were age five and you're in

00:38:29,430 --> 00:38:33,270
a country where people tend to live with

00:38:31,950 --> 00:38:35,610
other people from their race group

00:38:33,270 --> 00:38:37,440
because of historic discrimination then

00:38:35,610 --> 00:38:39,840
you've still kind of taught it about the

00:38:37,440 --> 00:38:43,080
race and you might say oh it's okay my a

00:38:39,840 --> 00:38:45,270
is gender blind or race blind but if you

00:38:43,080 --> 00:38:50,240
didn't properly D by us your input data

00:38:45,270 --> 00:38:53,910
you're just kidding yourself okay um

00:38:50,240 --> 00:38:56,460
patchy NX net had some hands up earlier

00:38:53,910 --> 00:38:59,190
for people using it any developers of M

00:38:56,460 --> 00:39:01,560
X net in the room before I put my foot

00:38:59,190 --> 00:39:05,070
in it okay

00:39:01,560 --> 00:39:07,200
and it's it's it's a really good project

00:39:05,070 --> 00:39:08,940
it's still in the incubator I think it's

00:39:07,200 --> 00:39:11,550
going to be coming out fairly soon based

00:39:08,940 --> 00:39:13,300
on the board reports works for a whole

00:39:11,550 --> 00:39:15,730
bunch of different languages

00:39:13,300 --> 00:39:18,460
it's got all sorts of pre-trained models

00:39:15,730 --> 00:39:21,940
available and you can run it on your CPU

00:39:18,460 --> 00:39:24,850
or your GPU you can use the same code so

00:39:21,940 --> 00:39:28,330
it's great if you want to play with

00:39:24,850 --> 00:39:30,750
Apache MX net and text and there's a few

00:39:28,330 --> 00:39:34,420
different things to look at there's the

00:39:30,750 --> 00:39:36,310
text contra package which has a lot of

00:39:34,420 --> 00:39:38,890
things for working with the word

00:39:36,310 --> 00:39:42,460
embedding models so they have things for

00:39:38,890 --> 00:39:44,620
for globe for Bert those those kind of

00:39:42,460 --> 00:39:47,290
things and they also have pre trained

00:39:44,620 --> 00:39:49,420
models so that you don't have to go and

00:39:47,290 --> 00:39:51,640
teach your model about English or

00:39:49,420 --> 00:39:53,500
something like that you can say someone

00:39:51,640 --> 00:39:57,010
else has already spent some time and

00:39:53,500 --> 00:39:58,840
load of CPU credits teaching it about

00:39:57,010 --> 00:40:01,030
the English language from Wikipedia just

00:39:58,840 --> 00:40:02,560
give me the result model and it has the

00:40:01,030 --> 00:40:05,980
code in there to download that and cache

00:40:02,560 --> 00:40:08,050
that and work with it if you're

00:40:05,980 --> 00:40:12,100
interested in diving into more I'd

00:40:08,050 --> 00:40:16,660
suggest the d2l a I domain

00:40:12,100 --> 00:40:18,790
I think it's deep dive into AI learning

00:40:16,660 --> 00:40:22,690
is what it's called so that's an online

00:40:18,790 --> 00:40:25,870
course about AI machine learning deep

00:40:22,690 --> 00:40:28,420
learning using Apache MX net as the

00:40:25,870 --> 00:40:29,650
reference library that's available it's

00:40:28,420 --> 00:40:36,820
being taught at a couple of universities

00:40:29,650 --> 00:40:41,440
and I found it really helpful ok if we

00:40:36,820 --> 00:40:44,230
want to use Apache MX net to figure out

00:40:41,440 --> 00:40:47,440
which words are like which other words

00:40:44,230 --> 00:40:50,080
based on the globe word embedding and a

00:40:47,440 --> 00:40:53,380
bunch of Wikipedia text this is all we

00:40:50,080 --> 00:40:54,880
need to do this code will run on a GPU

00:40:53,380 --> 00:40:58,780
if you have one and you've got the right

00:40:54,880 --> 00:41:01,960
bindings available the very first time

00:40:58,780 --> 00:41:03,850
you run it it's gonna take between a

00:41:01,960 --> 00:41:05,770
minute and an hour depending on your

00:41:03,850 --> 00:41:08,200
internet connection because it downloads

00:41:05,770 --> 00:41:11,290
about 800 megabytes of pre compiled data

00:41:08,200 --> 00:41:13,870
I ran it earlier on my laptop it was

00:41:11,290 --> 00:41:15,550
pretty good I run it on Azure it was

00:41:13,870 --> 00:41:19,660
slightly less good and then it kicked me

00:41:15,550 --> 00:41:22,090
off and just set expectations and but

00:41:19,660 --> 00:41:26,410
you can connect to download the data and

00:41:22,090 --> 00:41:28,270
run it so in this case if you run it

00:41:26,410 --> 00:41:32,980
ask it for things about Linux it will

00:41:28,270 --> 00:41:34,390
tell you colonel GNU and Unix

00:41:32,980 --> 00:41:38,609
and it will say these are similar words

00:41:34,390 --> 00:41:42,160
based on what is in Wikipedia to Linux

00:41:38,609 --> 00:41:44,980
so rather than having just that simple

00:41:42,160 --> 00:41:48,280
tf-idf we can have the complex vector

00:41:44,980 --> 00:41:51,609
space model from this for free just with

00:41:48,280 --> 00:41:53,500
a few lines of code and a few hundred

00:41:51,609 --> 00:41:56,710
megabytes of temporary dissipates on

00:41:53,500 --> 00:42:01,059
your machine and it's a bit less

00:41:56,710 --> 00:42:03,130
readable than the scikit-learn code it's

00:42:01,059 --> 00:42:06,369
a lot more readable than the version of

00:42:03,130 --> 00:42:07,780
this I saw for Google's tensor flow so

00:42:06,369 --> 00:42:10,359
it's sort of somewhere in between in

00:42:07,780 --> 00:42:13,450
terms of understandability and

00:42:10,359 --> 00:42:16,750
readability and if you if this code is

00:42:13,450 --> 00:42:22,329
looking like gibberish then have a look

00:42:16,750 --> 00:42:24,309
in the d2l AI course these code samples

00:42:22,329 --> 00:42:25,329
are inspired by the stuff in that and

00:42:24,309 --> 00:42:27,849
they go into a lot more detail about

00:42:25,329 --> 00:42:31,270
what's actually going on for this kind

00:42:27,849 --> 00:42:33,430
of code and but if you if you clone the

00:42:31,270 --> 00:42:35,970
workbook I've got on Azure notebooks or

00:42:33,430 --> 00:42:38,710
if you grab the code from my apache

00:42:35,970 --> 00:42:40,210
homepage and run it locally you can run

00:42:38,710 --> 00:42:45,180
through this you can try different words

00:42:40,210 --> 00:42:49,180
have a play see see how you get on and

00:42:45,180 --> 00:42:51,010
so built a model we've run some

00:42:49,180 --> 00:42:52,900
predictions it's told us what words are

00:42:51,010 --> 00:42:56,700
like what other words we can then go off

00:42:52,900 --> 00:42:59,770
and and train an AI based on that and

00:42:56,700 --> 00:43:01,869
then we need to put it into production

00:42:59,770 --> 00:43:05,829
so you're making some changes how's my

00:43:01,869 --> 00:43:08,440
model improved is it better than the old

00:43:05,829 --> 00:43:10,359
one you're gonna need to have some sort

00:43:08,440 --> 00:43:12,549
of heuristics in there so that you can

00:43:10,359 --> 00:43:14,289
check when you tweak to hyper from it so

00:43:12,549 --> 00:43:17,770
have you improved it have you made it

00:43:14,289 --> 00:43:20,049
worse and you're also ideally going to

00:43:17,770 --> 00:43:22,329
want to store checkpoints over time so

00:43:20,049 --> 00:43:25,140
you can compare how are we doing six

00:43:22,329 --> 00:43:29,109
months ago to now and what changed and

00:43:25,140 --> 00:43:32,319
compare the differences if you're not

00:43:29,109 --> 00:43:35,410
sure how to do that the best example I

00:43:32,319 --> 00:43:37,960
know of is Apache ticket eval patchy

00:43:35,410 --> 00:43:40,480
Tico I already mentioned the start

00:43:37,960 --> 00:43:42,930
texture metadata extraction library for

00:43:40,480 --> 00:43:45,609
pretty much any file format out there

00:43:42,930 --> 00:43:48,579
with Apache tikka there's a regression

00:43:45,609 --> 00:43:50,260
library of about 4 terabytes stored on a

00:43:48,579 --> 00:43:53,410
machine at Rackspace Thank You Rackspace

00:43:50,260 --> 00:43:56,079
for the free hosting and every release

00:43:53,410 --> 00:43:59,319
as a project we have to figure out half

00:43:56,079 --> 00:44:04,329
the changes we've made improved or

00:43:59,319 --> 00:44:08,470
worsened our overall performance no

00:44:04,329 --> 00:44:12,309
amount of Amazon Turk credits is going

00:44:08,470 --> 00:44:14,349
to let us get that kind of answer by

00:44:12,309 --> 00:44:16,180
giving every single document and every

00:44:14,349 --> 00:44:17,380
single piece of output to real humans

00:44:16,180 --> 00:44:18,010
and getting on so it's just it's just

00:44:17,380 --> 00:44:19,690
not possible

00:44:18,010 --> 00:44:21,460
so we have to have some sort of finger

00:44:19,690 --> 00:44:23,650
in the air heuristics so we look at

00:44:21,460 --> 00:44:26,170
things like how many exceptions did we

00:44:23,650 --> 00:44:28,390
hear how many timeouts did we get how

00:44:26,170 --> 00:44:30,220
many out of memory problems did we get

00:44:28,390 --> 00:44:32,170
now some of those are just the Machine

00:44:30,220 --> 00:44:33,910
falling over me it's a free machine we

00:44:32,170 --> 00:44:35,349
can't complain but some of them because

00:44:33,910 --> 00:44:37,059
we've made a change to a library or

00:44:35,349 --> 00:44:39,910
upgraded a library and it's affected it

00:44:37,059 --> 00:44:40,900
we also need to look at things like how

00:44:39,910 --> 00:44:43,900
long did it take

00:44:40,900 --> 00:44:46,359
if extraction from a PDF used to take an

00:44:43,900 --> 00:44:49,660
average of 500 milliseconds and now it's

00:44:46,359 --> 00:44:53,020
up to 500 seconds probably we've stuff

00:44:49,660 --> 00:44:56,890
something up you can look at the common

00:44:53,020 --> 00:45:01,569
engrams if extracting from PDF typically

00:44:56,890 --> 00:45:03,849
produce words like the a that kind of

00:45:01,569 --> 00:45:07,569
thing in English and now we're getting

00:45:03,849 --> 00:45:09,010
Zed Zed Zed Zed Zed probably something's

00:45:07,569 --> 00:45:11,530
gone wrong there and it's gone wrong on

00:45:09,010 --> 00:45:14,230
the PDF and if you look at it by

00:45:11,530 --> 00:45:17,079
language split by language you can end

00:45:14,230 --> 00:45:19,599
up and having a more useful set of

00:45:17,079 --> 00:45:22,450
information so even if you've only got

00:45:19,599 --> 00:45:23,619
50 German documents in your corpus if

00:45:22,450 --> 00:45:25,420
you compare the German documents

00:45:23,619 --> 00:45:27,190
separate from the English documents

00:45:25,420 --> 00:45:28,599
you'll get a different top answer and

00:45:27,190 --> 00:45:30,520
you can look at it and go are those

00:45:28,599 --> 00:45:32,380
actually German words you might look at

00:45:30,520 --> 00:45:33,910
it and go well what we thought was going

00:45:32,380 --> 00:45:35,349
to be German words all seem to be French

00:45:33,910 --> 00:45:38,380
maybe we've stuffed up the language

00:45:35,349 --> 00:45:40,390
identification but these are all just

00:45:38,380 --> 00:45:43,859
something where someone is going to look

00:45:40,390 --> 00:45:46,510
at a dashboard once per release and say

00:45:43,859 --> 00:45:48,339
how have we done and it's going to be a

00:45:46,510 --> 00:45:50,559
similar thing for for you with your Aoi

00:45:48,339 --> 00:45:51,520
models you build a new model you'll feed

00:45:50,559 --> 00:45:53,620
in some test query

00:45:51,520 --> 00:45:57,420
is you might split it different ways

00:45:53,620 --> 00:45:57,420
look at it and go should we put it live

00:45:57,810 --> 00:46:05,710
um as I've said before make sure you

00:46:01,570 --> 00:46:08,080
know how to recreate your model there

00:46:05,710 --> 00:46:11,170
used to be a thing a while ago

00:46:08,080 --> 00:46:16,030
maybe 10-15 years ago it worked on my

00:46:11,170 --> 00:46:20,230
computer but before that it compiled on

00:46:16,030 --> 00:46:22,210
my computer with some other data science

00:46:20,230 --> 00:46:25,420
data engineering at the moment it can be

00:46:22,210 --> 00:46:28,870
like well it gives the right answer on

00:46:25,420 --> 00:46:31,690
my laptop or at least it did last

00:46:28,870 --> 00:46:33,280
Tuesday if this is something that's

00:46:31,690 --> 00:46:35,890
gonna be important to your business and

00:46:33,280 --> 00:46:38,500
sometimes the data scientist laptop

00:46:35,890 --> 00:46:39,760
works and sometimes it doesn't and it

00:46:38,500 --> 00:46:42,700
never works in production

00:46:39,760 --> 00:46:44,500
that's mmm yeah that's gonna be a

00:46:42,700 --> 00:46:47,320
problem for your the people paying the

00:46:44,500 --> 00:46:49,150
bills so do you make sure that you have

00:46:47,320 --> 00:46:51,910
all of your training data stored

00:46:49,150 --> 00:46:53,740
somewhere ID versioned make sure you

00:46:51,910 --> 00:46:56,470
have a record of how your pre-processing

00:46:53,740 --> 00:46:58,390
your data so in my case I might say oh

00:46:56,470 --> 00:47:00,220
I'm training it on a globe word

00:46:58,390 --> 00:47:02,260
embedding and I'm using this specific

00:47:00,220 --> 00:47:05,860
globe word embedding with these many

00:47:02,260 --> 00:47:08,260
words from this date so that I know how

00:47:05,860 --> 00:47:09,670
to recreate it if possible when you're

00:47:08,260 --> 00:47:10,660
storing the model so you built your

00:47:09,670 --> 00:47:13,840
model and you're going to put it

00:47:10,660 --> 00:47:15,340
somewhere to just to serve try and put

00:47:13,840 --> 00:47:17,260
that information with it just that

00:47:15,340 --> 00:47:18,970
metadata so that when you're looking at

00:47:17,260 --> 00:47:21,550
a model in production and everyone's

00:47:18,970 --> 00:47:23,530
going why is it that we keep asking for

00:47:21,550 --> 00:47:25,810
talks on AI in ml and it keeps

00:47:23,530 --> 00:47:27,490
suggesting stuff on leucine you can be

00:47:25,810 --> 00:47:28,990
like well these are the parameters that

00:47:27,490 --> 00:47:31,030
we put in let's go off and do some

00:47:28,990 --> 00:47:33,040
testing let's see what's going on and if

00:47:31,030 --> 00:47:35,410
you've stored the parameters with your

00:47:33,040 --> 00:47:38,500
resulting model you've got a way to work

00:47:35,410 --> 00:47:40,690
backwards if you just say well there's

00:47:38,500 --> 00:47:44,410
500 megabytes of stuff on the server

00:47:40,690 --> 00:47:48,340
with this sha we think that's what we

00:47:44,410 --> 00:47:49,690
deployed last week you've got now you've

00:47:48,340 --> 00:47:52,060
got really no hope of being able to

00:47:49,690 --> 00:47:53,530
support this and yet you're building

00:47:52,060 --> 00:47:54,850
this for a reason someone's paying your

00:47:53,530 --> 00:47:56,530
salary someone's paying your server

00:47:54,850 --> 00:47:58,960
costs they probably want some useful

00:47:56,530 --> 00:48:00,610
answers and if you can think about this

00:47:58,960 --> 00:48:01,840
upfront then when it goes wrong in

00:48:00,610 --> 00:48:03,400
production you've got a hope of fixing

00:48:01,840 --> 00:48:04,720
it rather than so

00:48:03,400 --> 00:48:09,339
on saying what the hell are we paying

00:48:04,720 --> 00:48:12,339
you for some Apache projects to know

00:48:09,339 --> 00:48:14,230
about Apache MX net obviously if you're

00:48:12,339 --> 00:48:17,349
interested in the NLP then have a look

00:48:14,230 --> 00:48:19,690
at the gluon NLP sub project it's got a

00:48:17,349 --> 00:48:21,339
lot of stuff already available for you a

00:48:19,690 --> 00:48:23,980
lot of the embeddings a lot of the

00:48:21,339 --> 00:48:25,869
techniques that you'll need Apache tikka

00:48:23,980 --> 00:48:28,690
to get your word documents or whatever

00:48:25,869 --> 00:48:30,130
into some useful text there's also a

00:48:28,690 --> 00:48:32,230
bunch of other projects in the incubator

00:48:30,130 --> 00:48:34,990
to be aware of so there's a Patchi D lab

00:48:32,230 --> 00:48:36,700
which is trying to create self-service

00:48:34,990 --> 00:48:41,470
data science environments in the cloud

00:48:36,700 --> 00:48:43,329
and there is Marvin AI which is a

00:48:41,470 --> 00:48:45,549
platform trying to help the data

00:48:43,329 --> 00:48:49,599
scientists again experiment and

00:48:45,549 --> 00:48:51,849
prototype in the cloud pachi singer who

00:48:49,599 --> 00:48:55,000
are trying to do really scale out

00:48:51,849 --> 00:48:57,670
versions of all of this and then Apache

00:48:55,000 --> 00:48:59,529
TVM which is also trying to help you

00:48:57,670 --> 00:49:02,349
compile your code down into something

00:48:59,529 --> 00:49:04,839
that run on a CPU or GPU so there's some

00:49:02,349 --> 00:49:06,279
other new projects at Apache from the

00:49:04,839 --> 00:49:08,470
last year or so that you might not have

00:49:06,279 --> 00:49:13,480
heard of yet that may be worth checking

00:49:08,470 --> 00:49:16,270
out another thing if you've actually got

00:49:13,480 --> 00:49:19,000
questions and answers in your text

00:49:16,270 --> 00:49:20,710
rather than trying to retrofit questions

00:49:19,000 --> 00:49:23,710
and answers onto the text that you found

00:49:20,710 --> 00:49:25,539
on your server or you know from your

00:49:23,710 --> 00:49:27,670
users or whatever then Facebook have

00:49:25,539 --> 00:49:29,260
developed something called dr. QA there

00:49:27,670 --> 00:49:30,940
was a talk on it at Berlin buzzwords

00:49:29,260 --> 00:49:33,309
this year that's worth checking out if

00:49:30,940 --> 00:49:34,569
if you happen to have meaningful

00:49:33,309 --> 00:49:36,640
questions and answers in your text

00:49:34,569 --> 00:49:40,569
rather than just a later text them exam

00:49:36,640 --> 00:49:42,910
itself um there were two relevant talks

00:49:40,569 --> 00:49:45,250
Apache con North America and Vegas from

00:49:42,910 --> 00:49:46,420
two months ago there was the recent

00:49:45,250 --> 00:49:48,990
advances in natural language processing

00:49:46,420 --> 00:49:51,339
from the Apache an accident folks

00:49:48,990 --> 00:49:53,650
sadly the audio recording of that

00:49:51,339 --> 00:49:54,940
doesn't seem to work so there's no audio

00:49:53,650 --> 00:49:57,130
recording but there are the slides

00:49:54,940 --> 00:49:59,710
available on the website the other one

00:49:57,130 --> 00:50:01,900
is the evaluating content and text

00:49:59,710 --> 00:50:03,849
extraction at scale talked by Tim

00:50:01,900 --> 00:50:06,400
Allison you can get the slides and the

00:50:03,849 --> 00:50:09,099
audio for that online so that's all

00:50:06,400 --> 00:50:10,660
about how Apache tika tries to finger in

00:50:09,099 --> 00:50:12,730
the air figure out if things have got

00:50:10,660 --> 00:50:15,339
better or worse and you can use a lot of

00:50:12,730 --> 00:50:17,170
those same techniques for understanding

00:50:15,339 --> 00:50:20,109
if you're a IML pipeline

00:50:17,170 --> 00:50:23,170
has got better or worse if you want to

00:50:20,109 --> 00:50:25,569
try it out yourself you can have a play

00:50:23,170 --> 00:50:28,809
with Jupiter notebooks there's also

00:50:25,569 --> 00:50:31,329
Apache Zeppelin notebooks both Microsoft

00:50:28,809 --> 00:50:33,460
and Google will give you free hosted

00:50:31,329 --> 00:50:35,109
Jupiter notebooks to play around with so

00:50:33,460 --> 00:50:37,089
you don't have to worry about installing

00:50:35,109 --> 00:50:38,619
anything you have to worry about any

00:50:37,089 --> 00:50:42,790
dependencies you can just point your

00:50:38,619 --> 00:50:44,319
browser at it start coding hit run with

00:50:42,790 --> 00:50:46,690
both of them try and have a stable

00:50:44,319 --> 00:50:49,630
internet connection if you're hopping

00:50:46,690 --> 00:50:51,520
from IP to IP and putting your laptop to

00:50:49,630 --> 00:50:53,109
sleep then with the free ones they have

00:50:51,520 --> 00:50:54,790
a tendency to shutdown the container

00:50:53,109 --> 00:50:56,589
that you're running on and then when you

00:50:54,790 --> 00:50:59,530
wake it up again on stage your demo

00:50:56,589 --> 00:51:00,849
doesn't work if you're paying for this

00:50:59,530 --> 00:51:03,190
stuff if you've got your own hosted

00:51:00,849 --> 00:51:05,859
version of Zeppelin or your own hosted

00:51:03,190 --> 00:51:07,119
version of Jupiter you can tune the

00:51:05,859 --> 00:51:09,579
security settings and keep those

00:51:07,119 --> 00:51:11,020
persistent while you move around your

00:51:09,579 --> 00:51:13,150
company or go for a cup of coffee or

00:51:11,020 --> 00:51:15,280
something on the free stuff is a bit

00:51:13,150 --> 00:51:16,990
more flaky but you haven't paid for it

00:51:15,280 --> 00:51:20,230
you haven't installed it so trade off

00:51:16,990 --> 00:51:21,970
there and if all of this is new to you

00:51:20,230 --> 00:51:25,569
there's a bunch of really good learning

00:51:21,970 --> 00:51:27,430
courses online and I won't dwell on them

00:51:25,569 --> 00:51:28,720
but you hopefully all got the slides at

00:51:27,430 --> 00:51:32,680
the start so you can go look those up

00:51:28,720 --> 00:51:34,150
later it's a couple of books available

00:51:32,680 --> 00:51:37,900
as well

00:51:34,150 --> 00:51:42,760
we have zero minutes left so I'm gonna

00:51:37,900 --> 00:51:44,859
leave you with the slides and the code

00:51:42,760 --> 00:51:46,450
again I'm gonna be around so any

00:51:44,859 --> 00:51:48,250
questions just come up and talk to me

00:51:46,450 --> 00:51:49,510
afterwards I will happily answer your

00:51:48,250 --> 00:51:51,670
questions or point you to other people

00:51:49,510 --> 00:51:53,530
but I am now out of time and I know a

00:51:51,670 --> 00:51:55,030
lot of you will need to get some fresh

00:51:53,530 --> 00:51:58,980
air or something so I will stop there

00:51:55,030 --> 00:51:58,980
thank you for your time thank you

00:51:59,690 --> 00:52:01,750

YouTube URL: https://www.youtube.com/watch?v=jTHQn1yK75E


