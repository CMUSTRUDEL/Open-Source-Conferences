Title: Lessons Learned: Building Cassandra DBaaS on Alibaba Cloud
Publication date: 2020-10-21
Playlist: ApacheCon @Home 2020: Cassandra
Description: 
	Lessons Learned: Building Cassandra DBaaS on Alibaba Cloud
Maxwell Guo

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

During this session, we will share the lessons we learned when we built Apache Cassandra as a Service on Alibaba Cloud. Specific topics include: - how we boosted Cassandra performance through soft raid on cloud disk, - why we do a continuous full incremental backup - how to apply automatic data repairs Additionally, we will share the experience of doing non-stop data migration between different Cassandra clusters and between Cassandra and other databases as well as how we optimize a Cassandra service for different use case.

Maxwell is a cloud software architect at Alibaba, working on offering Apache Cassandra as a cloud based service.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:24,720 --> 00:00:30,000
hello everyone

00:00:26,160 --> 00:00:32,320
okay and i came from china and

00:00:30,000 --> 00:00:34,640
i came from alibaba cloud database

00:00:32,320 --> 00:00:37,920
department

00:00:34,640 --> 00:00:41,440
my name is max maxwell and

00:00:37,920 --> 00:00:44,559
my nickname in alibaba is journey

00:00:41,440 --> 00:00:47,840
for this is my first time first

00:00:44,559 --> 00:00:51,440
time to use english to make a speech so

00:00:47,840 --> 00:00:54,800
please forgive me if i will make

00:00:51,440 --> 00:00:58,879
some language problem okay

00:00:54,800 --> 00:00:59,920
today my topic is building cassandra

00:00:58,879 --> 00:01:04,400
debuss

00:00:59,920 --> 00:01:06,640
on alibaba cloud this is my tropic

00:01:04,400 --> 00:01:06,640
okay

00:01:08,960 --> 00:01:15,040
if i can say okay

00:01:12,230 --> 00:01:18,320
[Music]

00:01:15,040 --> 00:01:22,560
today my talk uh

00:01:18,320 --> 00:01:24,960
well introduce consists of four parts

00:01:22,560 --> 00:01:26,479
uh first is the introduction to absolute

00:01:24,960 --> 00:01:29,520
db db4 cassandra

00:01:26,479 --> 00:01:32,640
the second is the data immigration of of

00:01:29,520 --> 00:01:35,600
absolute db for cassandra and third is

00:01:32,640 --> 00:01:37,280
optimization and the features for uh of

00:01:35,600 --> 00:01:39,920
cep for cassandra

00:01:37,280 --> 00:01:42,159
the last part is q and a um

00:01:39,920 --> 00:01:44,960
[Music]

00:01:42,159 --> 00:01:48,320
okay uh the part one introduction to

00:01:44,960 --> 00:01:51,119
absolute db for cassandra

00:01:48,320 --> 00:01:52,560
absolutely before cassandra is apache a

00:01:51,119 --> 00:01:55,280
cassandra spoke

00:01:52,560 --> 00:01:58,000
with some kernel customs development and

00:01:55,280 --> 00:01:58,000
optimization

00:01:59,119 --> 00:02:05,520
let's uh come in to see

00:02:02,240 --> 00:02:09,119
uh the overall architecture of

00:02:05,520 --> 00:02:12,400
our sub db for cassandra part one

00:02:09,119 --> 00:02:15,920
um so we can see that uh

00:02:12,400 --> 00:02:19,280
the architecture is uh for

00:02:15,920 --> 00:02:22,800
uh if a user uh the uh

00:02:19,280 --> 00:02:26,400
so sorry um our cassandra

00:02:22,800 --> 00:02:30,400
is not serverless so if a user wants to

00:02:26,400 --> 00:02:33,920
buy a buyer service

00:02:30,400 --> 00:02:37,840
it is he will buy a cluster

00:02:33,920 --> 00:02:37,840
for cassandra and

00:02:38,080 --> 00:02:45,840
different users are of different weapons

00:02:41,760 --> 00:02:49,599
vbcs were under aluminum alibaba cloud

00:02:45,840 --> 00:02:53,040
means virtual private cloud

00:02:49,599 --> 00:02:56,640
and different users we all got different

00:02:53,040 --> 00:03:01,360
vpc and they are

00:02:56,640 --> 00:03:04,720
isolated from each other for example

00:03:01,360 --> 00:03:07,840
if users see in our picture

00:03:04,720 --> 00:03:11,120
user c uh can contact to

00:03:07,840 --> 00:03:14,800
uh the user sees the environment

00:03:11,120 --> 00:03:18,800
of which he buys but uh

00:03:14,800 --> 00:03:22,879
user system will not connect to user ace

00:03:18,800 --> 00:03:26,959
cassandra's environment and

00:03:22,879 --> 00:03:30,720
besides we support

00:03:26,959 --> 00:03:34,080
dc design disaster tolerance and

00:03:30,720 --> 00:03:36,879
different clusters were

00:03:34,080 --> 00:03:37,120
got a backup service and they will back

00:03:36,879 --> 00:03:40,640
up

00:03:37,120 --> 00:03:44,159
their data to our early

00:03:40,640 --> 00:03:48,319
alibaba cloud oss service

00:03:44,159 --> 00:03:51,040
so uh the absurd db4 cassandra

00:03:48,319 --> 00:03:52,080
uh supports security that means

00:03:51,040 --> 00:03:55,439
isolation

00:03:52,080 --> 00:03:58,480
between vpcs and only

00:03:55,439 --> 00:04:01,680
the uh host or the eyepiece

00:03:58,480 --> 00:04:02,799
added to the white list can contact to

00:04:01,680 --> 00:04:06,159
the

00:04:02,799 --> 00:04:10,239
specific vpc environment

00:04:06,159 --> 00:04:13,439
and we support higher availability

00:04:10,239 --> 00:04:13,760
that is water cassandra support replica

00:04:13,439 --> 00:04:16,880
and

00:04:13,760 --> 00:04:20,320
dc level disaster tolerance

00:04:16,880 --> 00:04:22,960
besides we also support rich functions

00:04:20,320 --> 00:04:24,160
that means data migration and backup and

00:04:22,960 --> 00:04:28,479
responsories

00:04:24,160 --> 00:04:31,759
and other services okay

00:04:28,479 --> 00:04:35,040
uh seven second

00:04:31,759 --> 00:04:37,120
the uh that's the uh the two

00:04:35,040 --> 00:04:38,960
uh the second part of the overall

00:04:37,120 --> 00:04:42,400
architecture of our absurd db

00:04:38,960 --> 00:04:44,000
for cassandra um we know that absolutely

00:04:42,400 --> 00:04:47,120
before cassandra is a folk of

00:04:44,000 --> 00:04:48,160
apache cassandra and we have uh done

00:04:47,120 --> 00:04:51,360
some

00:04:48,160 --> 00:04:54,400
uh optimization and we have made

00:04:51,360 --> 00:04:57,759
some features for uh for

00:04:54,400 --> 00:05:01,039
our cassandra but the architecture

00:04:57,759 --> 00:05:05,199
is the same with uh

00:05:01,039 --> 00:05:07,919
apache central uh we got we got

00:05:05,199 --> 00:05:08,720
cassandra cassandra's consistent hashi

00:05:07,919 --> 00:05:13,840
ring

00:05:08,720 --> 00:05:13,840
and we also got a com read and write

00:05:14,000 --> 00:05:18,960
but we support um

00:05:19,199 --> 00:05:26,479
support uh agent service that's called

00:05:22,639 --> 00:05:29,280
cassandro meat which will do some

00:05:26,479 --> 00:05:32,080
automated operation and maintenance

00:05:29,280 --> 00:05:35,000
besides we also

00:05:32,080 --> 00:05:36,320
do some kernel custom constant

00:05:35,000 --> 00:05:39,759
customization

00:05:36,320 --> 00:05:43,919
to make a higher performance um

00:05:39,759 --> 00:05:47,840
okay that's what uh that that is a

00:05:43,919 --> 00:05:51,039
a class single clusters architecture

00:05:47,840 --> 00:05:54,560
okay um

00:05:51,039 --> 00:05:57,919
the um this is a list of character

00:05:54,560 --> 00:06:00,960
characteristics of absolute v4 cassandra

00:05:57,919 --> 00:06:04,080
uh part one we support out of the box

00:06:00,960 --> 00:06:06,479
uh service uh which will animate the

00:06:04,080 --> 00:06:10,240
operation and maintains trouble

00:06:06,479 --> 00:06:13,520
elastic scaling and

00:06:10,240 --> 00:06:16,720
nearly expansion besides a

00:06:13,520 --> 00:06:19,360
high availability is supported

00:06:16,720 --> 00:06:21,120
and the backup and response service is

00:06:19,360 --> 00:06:23,680
supported at which

00:06:21,120 --> 00:06:24,240
we got full and incremental backup and

00:06:23,680 --> 00:06:27,440
the

00:06:24,240 --> 00:06:29,919
restore okay

00:06:27,440 --> 00:06:31,039
i will see if your anyone got some

00:06:29,919 --> 00:06:35,360
question

00:06:31,039 --> 00:06:40,400
okay continue

00:06:35,360 --> 00:06:43,440
um besides security is also

00:06:40,400 --> 00:06:47,520
coming soon that we will support

00:06:43,440 --> 00:06:51,120
ssl and the td following entry

00:06:47,520 --> 00:06:52,080
in encryption uh ordinark and the cloud

00:06:51,120 --> 00:06:56,000
dba

00:06:52,080 --> 00:06:59,039
that is uh supported by earlier database

00:06:56,000 --> 00:07:02,160
we're coming soon okay uh

00:06:59,039 --> 00:07:04,720
let's come to part two that is the

00:07:02,160 --> 00:07:05,680
the data migration of of sar db for

00:07:04,720 --> 00:07:08,960
cassandra

00:07:05,680 --> 00:07:12,960
um we have got

00:07:08,960 --> 00:07:15,520
two versions uh the uh evolution

00:07:12,960 --> 00:07:16,240
we evolution from version one to version

00:07:15,520 --> 00:07:20,319
two at first

00:07:16,240 --> 00:07:24,479
we support version one um

00:07:20,319 --> 00:07:27,759
we got a service called the lts which uh

00:07:24,479 --> 00:07:31,759
former name is pds

00:07:27,759 --> 00:07:35,199
this series will help us to do

00:07:31,759 --> 00:07:38,639
data migration in version one

00:07:35,199 --> 00:07:42,560
actually our first version

00:07:38,639 --> 00:07:45,599
lts will support

00:07:42,560 --> 00:07:49,919
the same

00:07:45,599 --> 00:07:53,599
topology topology node topology um

00:07:49,919 --> 00:07:57,520
that is uh if the source cluster

00:07:53,599 --> 00:08:00,479
is four nodes uh in our picture

00:07:57,520 --> 00:08:01,280
on the left side it is we got a four

00:08:00,479 --> 00:08:04,479
notes

00:08:01,280 --> 00:08:07,599
uh that is a w x y

00:08:04,479 --> 00:08:10,720
and z and they are of different uh

00:08:07,599 --> 00:08:13,759
ranges uh w got

00:08:10,720 --> 00:08:17,440
uh token 10 and x

00:08:13,759 --> 00:08:20,960
is uh 20 y is 30 and

00:08:17,440 --> 00:08:23,919
z is 40. um so

00:08:20,960 --> 00:08:24,639
uh we have got a limitation that is uh

00:08:23,919 --> 00:08:27,840
the

00:08:24,639 --> 00:08:31,120
um destination class

00:08:27,840 --> 00:08:34,640
should also be four nodes and

00:08:31,120 --> 00:08:37,519
their nodes corresponding nodes

00:08:34,640 --> 00:08:37,919
tokens should be the same there is on

00:08:37,519 --> 00:08:40,959
the

00:08:37,919 --> 00:08:44,000
right side the destination cluster

00:08:40,959 --> 00:08:47,040
w should also be total b

00:08:44,000 --> 00:08:50,800
sets with the token 10 and x

00:08:47,040 --> 00:08:54,880
is 20 y is 30 and z is

00:08:50,800 --> 00:08:57,519
40. so they are

00:08:54,880 --> 00:08:58,240
their data range are the same and the

00:08:57,519 --> 00:09:01,440
nodes

00:08:58,240 --> 00:09:01,920
uh topology are also same this is the

00:09:01,440 --> 00:09:06,320
first

00:09:01,920 --> 00:09:10,880
step that lts will do they will set

00:09:06,320 --> 00:09:14,720
the nodes with the same topology

00:09:10,880 --> 00:09:18,800
okay second the lts

00:09:14,720 --> 00:09:22,000
will have to do scammer set um

00:09:18,800 --> 00:09:26,080
he the lts

00:09:22,000 --> 00:09:30,080
will cut the scammer of the left side

00:09:26,080 --> 00:09:32,959
source cluster and then

00:09:30,080 --> 00:09:33,440
lts will set the scanner on the right

00:09:32,959 --> 00:09:38,000
side

00:09:33,440 --> 00:09:41,519
with the same scammer this is what lts

00:09:38,000 --> 00:09:44,640
do for the initial

00:09:41,519 --> 00:09:47,920
initial information

00:09:44,640 --> 00:09:51,519
sets the note topology and schema

00:09:47,920 --> 00:09:55,279
second we lcs will do

00:09:51,519 --> 00:09:59,760
uh do two-part

00:09:55,279 --> 00:10:04,399
uh data migration part one is uh

00:09:59,760 --> 00:10:08,079
for data for data that is of uh

00:10:04,399 --> 00:10:10,240
which well uh generated by snapshot

00:10:08,079 --> 00:10:12,000
we make a snapshot and the snapshot will

00:10:10,240 --> 00:10:15,760
got

00:10:12,000 --> 00:10:19,600
the four nodes as table on the left

00:10:15,760 --> 00:10:23,600
then data lts will do data migration

00:10:19,600 --> 00:10:27,519
he will transfer the data or the

00:10:23,600 --> 00:10:27,519
snapshot accessible on the left

00:10:27,839 --> 00:10:35,680
for example that uh sql that belongs to

00:10:31,279 --> 00:10:39,200
node w and lts will

00:10:35,680 --> 00:10:42,800
transfer the data belongs w to

00:10:39,200 --> 00:10:46,240
the right side to w

00:10:42,800 --> 00:10:49,519
to the right size w okay and

00:10:46,240 --> 00:10:52,720
the uh the that the snapshot

00:10:49,519 --> 00:10:56,240
as table belongs to z on the left

00:10:52,720 --> 00:10:56,959
to the right uh to the right side of the

00:10:56,240 --> 00:11:00,079
node

00:10:56,959 --> 00:11:04,320
z adds to left x

00:11:00,079 --> 00:11:09,040
to the right x left y to the right one

00:11:04,320 --> 00:11:12,839
that is the second step the third step

00:11:09,040 --> 00:11:16,800
we will for uh for incremental

00:11:12,839 --> 00:11:20,240
data that is we will do

00:11:16,800 --> 00:11:25,440
open the incremental backup function

00:11:20,240 --> 00:11:25,440
for the left size cluster

00:11:25,760 --> 00:11:32,000
okay if we open this feature

00:11:28,959 --> 00:11:33,200
uh every incremental insert or

00:11:32,000 --> 00:11:36,959
modification

00:11:33,200 --> 00:11:40,959
to this cluster will

00:11:36,959 --> 00:11:44,720
come into a backup directory directory

00:11:40,959 --> 00:11:47,920
and it is uh after flashing

00:11:44,720 --> 00:11:51,279
from the mem from mem table to as table

00:11:47,920 --> 00:11:54,720
okay we just transfer the data

00:11:51,279 --> 00:11:57,600
that's uh uh coming from the mem

00:11:54,720 --> 00:11:57,920
coming from the flashing mem cable then

00:11:57,600 --> 00:12:01,519
we

00:11:57,920 --> 00:12:02,880
also transfer the uh incremental

00:12:01,519 --> 00:12:06,320
estimate that's uh

00:12:02,880 --> 00:12:09,920
coming from uh mem cable flash

00:12:06,320 --> 00:12:13,519
um to the right side okay

00:12:09,920 --> 00:12:17,680
w no w's incremental symbol

00:12:13,519 --> 00:12:20,399
uh transfer to the right side w

00:12:17,680 --> 00:12:21,200
okay that's the same with uh snapshot

00:12:20,399 --> 00:12:24,639
symbols

00:12:21,200 --> 00:12:27,920
transfer um

00:12:24,639 --> 00:12:28,959
and the um and the incremental

00:12:27,920 --> 00:12:32,079
accessible

00:12:28,959 --> 00:12:36,839
uh transform um will be

00:12:32,079 --> 00:12:40,480
done continually continually uh always

00:12:36,839 --> 00:12:44,000
okay on the right side

00:12:40,480 --> 00:12:48,000
the video has just done the operation of

00:12:44,000 --> 00:12:51,279
node refresh that's a

00:12:48,000 --> 00:12:54,639
refreshes as table transformed by the

00:12:51,279 --> 00:12:58,000
babies or by lts uh

00:12:54,639 --> 00:13:01,440
and uh through node refresh the

00:12:58,000 --> 00:13:02,160
data meta will be replayed uh in the

00:13:01,440 --> 00:13:05,519
memory

00:13:02,160 --> 00:13:06,320
okay that is a version one but version

00:13:05,519 --> 00:13:10,240
one

00:13:06,320 --> 00:13:12,560
caught a limitation that is a the nodes

00:13:10,240 --> 00:13:16,079
topology should be the same and the

00:13:12,560 --> 00:13:16,079
nodes number should be the same

00:13:16,720 --> 00:13:20,000
that is we don't think this is a good

00:13:19,440 --> 00:13:22,959
idea

00:13:20,000 --> 00:13:25,120
so we have got a virtual evolution that

00:13:22,959 --> 00:13:30,320
is a version 2

00:13:25,120 --> 00:13:33,200
which supports different node topologies

00:13:30,320 --> 00:13:33,200
data migration

00:13:33,360 --> 00:13:40,800
um so uh in version two we um

00:13:37,600 --> 00:13:44,320
we bds or lts sorry

00:13:40,800 --> 00:13:46,880
lts can support uh

00:13:44,320 --> 00:13:48,639
different nodes topologies uh data

00:13:46,880 --> 00:13:52,720
migration

00:13:48,639 --> 00:13:55,920
and we don't lts don't uh

00:13:52,720 --> 00:13:59,680
well we won't do uh nose

00:13:55,920 --> 00:14:03,760
topologies uh initial that is uh um

00:13:59,680 --> 00:14:06,000
we won't assess the initial tokens

00:14:03,760 --> 00:14:07,440
of the right sides to be the same with

00:14:06,000 --> 00:14:09,120
the left side

00:14:07,440 --> 00:14:10,639
we don't want to do this but which

00:14:09,120 --> 00:14:14,079
version one will do this

00:14:10,639 --> 00:14:17,680
as a first step version 2 won't do this

00:14:14,079 --> 00:14:20,880
and um what what what

00:14:17,680 --> 00:14:24,880
lts will do is just a status scammer

00:14:20,880 --> 00:14:28,600
uh as a first step uh in version two

00:14:24,880 --> 00:14:32,959
and um so um

00:14:28,600 --> 00:14:35,920
plts will maintain a token mapping

00:14:32,959 --> 00:14:37,600
in the memory and in the disk of lts

00:14:35,920 --> 00:14:40,800
service

00:14:37,600 --> 00:14:43,680
which is just the left left side

00:14:40,800 --> 00:14:44,320
token map and the right side tongue map

00:14:43,680 --> 00:14:47,760
which

00:14:44,320 --> 00:14:50,800
means um the token map and

00:14:47,760 --> 00:14:53,120
their primary range of

00:14:50,800 --> 00:14:54,399
of the left side and of the right side

00:14:53,120 --> 00:14:57,519
um

00:14:54,399 --> 00:15:00,560
so we can do this that is uh

00:14:57,519 --> 00:15:03,839
if an unaccessible

00:15:00,560 --> 00:15:07,920
accessible that belongs belongs to the

00:15:03,839 --> 00:15:11,360
left side for example is a

00:15:07,920 --> 00:15:11,360
node a and

00:15:11,440 --> 00:15:16,399
this assetable and under the data all

00:15:14,399 --> 00:15:19,920
the estimate belongs to the a

00:15:16,399 --> 00:15:22,959
and belongs to the uh primary range of

00:15:19,920 --> 00:15:26,079
uh of a winning net

00:15:22,959 --> 00:15:26,800
cassandro i've got a primary and for

00:15:26,079 --> 00:15:30,160
every node

00:15:26,800 --> 00:15:33,440
and also they will got a replica

00:15:30,160 --> 00:15:37,600
range for every node but uh

00:15:33,440 --> 00:15:40,959
we first we only take out the

00:15:37,600 --> 00:15:44,079
primary end of every node okay if

00:15:40,959 --> 00:15:46,079
as a table belongs to node a and its

00:15:44,079 --> 00:15:49,920
belongs to the primary range of

00:15:46,079 --> 00:15:54,800
node a so we will

00:15:49,920 --> 00:15:58,000
pds or lts will where to where

00:15:54,800 --> 00:16:00,560
where well make this as cable that

00:15:58,000 --> 00:16:01,199
belongs to the primary engine to

00:16:00,560 --> 00:16:04,880
transfer

00:16:01,199 --> 00:16:08,480
the data to the to the left right side

00:16:04,880 --> 00:16:12,000
with the primary ranges

00:16:08,480 --> 00:16:12,880
that's uh for the rock signs for example

00:16:12,000 --> 00:16:17,759
if

00:16:12,880 --> 00:16:21,600
the range is the primary range is

00:16:17,759 --> 00:16:25,279
11 to 20 20 25

00:16:21,600 --> 00:16:28,880
and that means

00:16:25,279 --> 00:16:32,560
what lts were done is to split

00:16:28,880 --> 00:16:36,399
the the symbol

00:16:32,560 --> 00:16:39,440
into two parts part one is 11 to 20

00:16:36,399 --> 00:16:42,720
and part 2 is 20 to

00:16:39,440 --> 00:16:44,959
25 and this table coming from the

00:16:42,720 --> 00:16:48,720
primary end node of

00:16:44,959 --> 00:16:50,079
the left side then after sleeping this s

00:16:48,720 --> 00:16:53,600
table

00:16:50,079 --> 00:16:56,560
the s table will be put to the

00:16:53,600 --> 00:16:57,759
right size primary engine node for

00:16:56,560 --> 00:17:01,600
example is w

00:16:57,759 --> 00:17:04,640
and z this is a data that comes

00:17:01,600 --> 00:17:07,760
belongs to prime range and also if

00:17:04,640 --> 00:17:10,880
accessible that's a belongs to some

00:17:07,760 --> 00:17:14,880
replica nodes or replica

00:17:10,880 --> 00:17:18,799
no syringe they will also

00:17:14,880 --> 00:17:21,679
lts will also do doing sleeping and

00:17:18,799 --> 00:17:24,400
transfer them to the replica notes okay

00:17:21,679 --> 00:17:28,799
after doing this

00:17:24,400 --> 00:17:33,840
lts will also do not refresh and

00:17:28,799 --> 00:17:33,840
in this way data will be

00:17:33,919 --> 00:17:39,039
transferred very quickly and will be

00:17:36,640 --> 00:17:42,320
immigration very quickly okay

00:17:39,039 --> 00:17:45,440
for incremental data we also open

00:17:42,320 --> 00:17:47,360
uh incremental backups for the left side

00:17:45,440 --> 00:17:50,880
and uh

00:17:47,360 --> 00:17:54,080
lts we are done talking about whipping

00:17:50,880 --> 00:17:57,760
tool map mapping for um for

00:17:54,080 --> 00:18:01,440
incremental datas and we are doing

00:17:57,760 --> 00:18:04,799
a stable sleeping sleeping okay

00:18:01,440 --> 00:18:08,480
and on the right side uh lcs were all

00:18:04,799 --> 00:18:11,840
were also done another refresh

00:18:08,480 --> 00:18:13,440
that is the evolution from we we went to

00:18:11,840 --> 00:18:16,480
version two

00:18:13,440 --> 00:18:19,120
and the version 2 is can be

00:18:16,480 --> 00:18:20,880
migration in both directions from the

00:18:19,120 --> 00:18:22,640
left side to right side and to right

00:18:20,880 --> 00:18:25,679
side to the left side

00:18:22,640 --> 00:18:28,880
that means if the nodes are different

00:18:25,679 --> 00:18:31,360
no matter which side the nose is bigger

00:18:28,880 --> 00:18:34,160
it is okay it can be migrated from both

00:18:31,360 --> 00:18:37,280
sides in both direction

00:18:34,160 --> 00:18:39,679
okay part three part three means

00:18:37,280 --> 00:18:41,520
the optimum optimization and the

00:18:39,679 --> 00:18:41,840
features of absorptive focus cassandra

00:18:41,520 --> 00:18:44,960
which

00:18:41,840 --> 00:18:48,000
we have done for cassandra

00:18:44,960 --> 00:18:49,760
okay if let's see if anyone got some

00:18:48,000 --> 00:18:53,520
problem

00:18:49,760 --> 00:18:53,520
okay okay

00:18:54,160 --> 00:18:57,840
uh okay

00:19:00,160 --> 00:19:06,160
um for our environment

00:19:03,200 --> 00:19:06,799
for our uh alibaba cloud environment we

00:19:06,160 --> 00:19:09,120
know that we

00:19:06,799 --> 00:19:11,200
and we have introduction at the first

00:19:09,120 --> 00:19:13,840
part that

00:19:11,200 --> 00:19:14,799
every customer's cluster is not

00:19:13,840 --> 00:19:18,640
serverless

00:19:14,799 --> 00:19:22,080
it is if a user buy a service it is a

00:19:18,640 --> 00:19:25,520
he will buy a cluster service

00:19:22,080 --> 00:19:28,080
and uh if we got thousands of

00:19:25,520 --> 00:19:29,360
clusters that's where that means that we

00:19:28,080 --> 00:19:32,480
will maintain

00:19:29,360 --> 00:19:33,039
thousands of clusters on the cloud that

00:19:32,480 --> 00:19:36,320
is the

00:19:33,039 --> 00:19:39,600
um that is a big task and it's um

00:19:36,320 --> 00:19:42,080
it may um and we will caught some

00:19:39,600 --> 00:19:42,080
problems

00:19:42,320 --> 00:19:49,280
for so many classes okay

00:19:46,080 --> 00:19:51,760
we know that repel for

00:19:49,280 --> 00:19:52,480
cassandra is needed and must be done

00:19:51,760 --> 00:19:55,760
purely

00:19:52,480 --> 00:19:59,679
periodically first

00:19:55,760 --> 00:20:02,720
second repel if we don't repeal

00:19:59,679 --> 00:20:06,400
once this this is a

00:20:02,720 --> 00:20:11,120
resource costing repair will cost the

00:20:06,400 --> 00:20:14,240
cpu memory and the disk okay

00:20:11,120 --> 00:20:17,760
um third doing repair

00:20:14,240 --> 00:20:21,039
for our environment for our environment

00:20:17,760 --> 00:20:25,600
purely periodically is troublesome

00:20:21,039 --> 00:20:29,120
because we may got thousands of clusters

00:20:25,600 --> 00:20:32,320
so we think that to do

00:20:29,120 --> 00:20:35,520
repair automation

00:20:32,320 --> 00:20:39,840
automation automated is needed

00:20:35,520 --> 00:20:39,840
and we won't also want that

00:20:40,159 --> 00:20:46,880
repair for the repair process

00:20:43,360 --> 00:20:50,000
for us is not resource costing

00:20:46,880 --> 00:20:55,520
and and will make

00:20:50,000 --> 00:20:55,520
little effects for our customers

00:20:55,600 --> 00:20:57,919
also

00:20:59,600 --> 00:21:07,520
we don't want to our

00:21:04,080 --> 00:21:10,880
repair automation our auto

00:21:07,520 --> 00:21:11,360
automate automates repair will cost the

00:21:10,880 --> 00:21:15,039
mass

00:21:11,360 --> 00:21:19,120
time so we want the time is controllable

00:21:15,039 --> 00:21:20,880
so we have abated the apache cassandra's

00:21:19,120 --> 00:21:24,240
repair method and we will

00:21:20,880 --> 00:21:28,080
implement and we have implement our own

00:21:24,240 --> 00:21:32,000
repairmate service which will then

00:21:28,080 --> 00:21:35,919
repair or repeal

00:21:32,000 --> 00:21:39,440
how done the data repel

00:21:35,919 --> 00:21:40,320
automated uh let's in introduction to

00:21:39,440 --> 00:21:43,360
our method

00:21:40,320 --> 00:21:47,280
we have uh make a process

00:21:43,360 --> 00:21:50,000
in our cassandra daemon and

00:21:47,280 --> 00:21:51,600
every cassandra demon node of our casino

00:21:50,000 --> 00:21:55,679
nodes will

00:21:51,600 --> 00:21:59,120
just do the repair process for

00:21:55,679 --> 00:22:03,120
automatic that is uh we know that

00:21:59,120 --> 00:22:05,600
erica sanjo eric sanjo knows well got

00:22:03,120 --> 00:22:06,320
a primary range for the uh for their

00:22:05,600 --> 00:22:09,200
nose

00:22:06,320 --> 00:22:10,799
and they are also got a republican range

00:22:09,200 --> 00:22:13,919
for themselves also

00:22:10,799 --> 00:22:17,280
but we just divide or cut

00:22:13,919 --> 00:22:20,880
the uh prime range which nodes

00:22:17,280 --> 00:22:24,000
responsible catch them cuts the

00:22:20,880 --> 00:22:26,559
range into some smaller

00:22:24,000 --> 00:22:27,280
sub ranges uh in our picture we can see

00:22:26,559 --> 00:22:30,960
that b

00:22:27,280 --> 00:22:31,919
uh node b uh well got subreddit one two

00:22:30,960 --> 00:22:35,520
three

00:22:31,919 --> 00:22:38,640
four for simply okay um

00:22:35,520 --> 00:22:42,159
that is what we first done just cut

00:22:38,640 --> 00:22:45,280
the primal range into

00:22:42,159 --> 00:22:49,840
permanence of the nodes into some

00:22:45,280 --> 00:22:53,520
smaller sub range okay and

00:22:49,840 --> 00:22:56,320
every range and our pale demon

00:22:53,520 --> 00:22:58,080
we are done we've got some for every

00:22:56,320 --> 00:23:01,200
note we'll call some tasks

00:22:58,080 --> 00:23:04,240
and every text every task

00:23:01,200 --> 00:23:08,640
will reticule

00:23:04,240 --> 00:23:08,640
take off some some sub ranges and

00:23:10,400 --> 00:23:14,000
pixels some sub ranges uh that is the

00:23:13,280 --> 00:23:17,520
first step

00:23:14,000 --> 00:23:20,720
then every task

00:23:17,520 --> 00:23:24,640
will doing

00:23:20,720 --> 00:23:24,640
doing the data data repair

00:23:24,799 --> 00:23:32,159
they will just scan

00:23:28,240 --> 00:23:36,159
the sub range from the

00:23:32,159 --> 00:23:39,520
start to the end round and round

00:23:36,159 --> 00:23:42,559
every round they will just scan some

00:23:39,520 --> 00:23:45,600
such as a turn uh keys

00:23:42,559 --> 00:23:49,120
uh for example and the

00:23:45,600 --> 00:23:52,880
z just scans this data as against this

00:23:49,120 --> 00:23:56,240
token keys and

00:23:52,880 --> 00:23:59,760
just read

00:23:56,240 --> 00:24:03,039
all the data of this key

00:23:59,760 --> 00:24:03,440
from a replica with the consistent level

00:24:03,039 --> 00:24:06,960
of

00:24:03,440 --> 00:24:11,200
all just read them and as

00:24:06,960 --> 00:24:14,320
node b we will compare compare the data

00:24:11,200 --> 00:24:18,960
from different replica and

00:24:14,320 --> 00:24:18,960
then step two we will doing

00:24:19,200 --> 00:24:23,520
the data fix and then we will we know

00:24:21,919 --> 00:24:28,480
that we can

00:24:23,520 --> 00:24:31,760
get the detailed data of different

00:24:28,480 --> 00:24:34,559
replicas for the same key

00:24:31,760 --> 00:24:36,640
then we will fix them with the detailed

00:24:34,559 --> 00:24:41,440
data

00:24:36,640 --> 00:24:44,960
of uh for different replica

00:24:41,440 --> 00:24:49,360
for us the data repair path

00:24:44,960 --> 00:24:53,679
for reads okay uh sorry i i forgot that

00:24:49,360 --> 00:24:56,720
the fixed path we will also

00:24:53,679 --> 00:25:00,400
with the consistent level of all so

00:24:56,720 --> 00:25:04,880
that means we the node b with

00:25:00,400 --> 00:25:08,080
uh the the repair demon on node abc

00:25:04,880 --> 00:25:10,880
uh just a wheel doing uh

00:25:08,080 --> 00:25:12,240
data rates from all replicas with the

00:25:10,880 --> 00:25:15,600
consistent level of all

00:25:12,240 --> 00:25:19,360
and gets the detailed data

00:25:15,600 --> 00:25:22,480
for all replica and then we will fix

00:25:19,360 --> 00:25:25,360
the data for all

00:25:22,480 --> 00:25:26,320
replica with the consumer level of all

00:25:25,360 --> 00:25:29,600
that is what

00:25:26,320 --> 00:25:33,360
we we have done and second

00:25:29,600 --> 00:25:34,640
the read and the fixed pass for re for

00:25:33,360 --> 00:25:38,559
our repair demon

00:25:34,640 --> 00:25:41,200
is individual is independent independent

00:25:38,559 --> 00:25:41,840
um with the normal rights and the read

00:25:41,200 --> 00:25:45,200
pass

00:25:41,840 --> 00:25:48,240
so that means this demon

00:25:45,200 --> 00:25:52,320
this demon will not affect the

00:25:48,240 --> 00:25:55,600
um the normal read and rights

00:25:52,320 --> 00:26:00,000
pass okay so um

00:25:55,600 --> 00:26:02,640
besides if one task filled

00:26:00,000 --> 00:26:03,039
uh for example if one node is dead and

00:26:02,640 --> 00:26:06,080
the

00:26:03,039 --> 00:26:09,200
all consistent level uh read

00:26:06,080 --> 00:26:12,799
and write will fill so

00:26:09,200 --> 00:26:16,400
after sometimes retry if the the finger

00:26:12,799 --> 00:26:19,760
also occurs so we just keep this

00:26:16,400 --> 00:26:23,039
uh submarines uh record in

00:26:19,760 --> 00:26:26,480
in some uh what we call the

00:26:23,039 --> 00:26:29,520
system system table

00:26:26,480 --> 00:26:31,760
we have we have made a system table and

00:26:29,520 --> 00:26:31,760
uh

00:26:32,720 --> 00:26:39,919
and as after another run

00:26:35,840 --> 00:26:42,880
runs the the record we're coming to a

00:26:39,919 --> 00:26:43,919
cube the queen is uh you know we can

00:26:42,880 --> 00:26:47,200
take this

00:26:43,919 --> 00:26:50,960
uh finial recorder uh

00:26:47,200 --> 00:26:53,600
with a higher priority okay that's

00:26:50,960 --> 00:26:54,080
what we have done and we know that in

00:26:53,600 --> 00:26:57,120
this

00:26:54,080 --> 00:26:58,720
in this way every node will do their

00:26:57,120 --> 00:27:02,640
repel

00:26:58,720 --> 00:27:05,760
automated we won't uh do it manually

00:27:02,640 --> 00:27:09,200
okay and we have got that

00:27:05,760 --> 00:27:11,760
this repair will uh doing uh

00:27:09,200 --> 00:27:12,480
well got less uh resource costing and

00:27:11,760 --> 00:27:16,000
the

00:27:12,480 --> 00:27:16,000
for the repairs

00:27:16,159 --> 00:27:19,600
uh path is the independent and won't

00:27:19,039 --> 00:27:23,200
wear

00:27:19,600 --> 00:27:27,440
a factor read and write um okay

00:27:23,200 --> 00:27:31,600
uh every note we have to do to their own

00:27:27,440 --> 00:27:35,760
primary read and read so it is okay for

00:27:31,600 --> 00:27:39,360
for our cluster there won't be any

00:27:35,760 --> 00:27:43,679
any uh submarines on only range that

00:27:39,360 --> 00:27:44,399
won't be done every every range will be

00:27:43,679 --> 00:27:48,000
done

00:27:44,399 --> 00:27:51,279
our repair the repair will be done

00:27:48,000 --> 00:27:55,200
for our uh all ranges

00:27:51,279 --> 00:27:57,760
so now nonrest will be missing okay

00:27:55,200 --> 00:27:58,720
that is what we have done for our repair

00:27:57,760 --> 00:28:02,399
automation

00:27:58,720 --> 00:28:05,440
and our cluster under our uh

00:28:02,399 --> 00:28:08,559
alibaba class uh have got this

00:28:05,440 --> 00:28:11,440
service uh it is um

00:28:08,559 --> 00:28:13,679
it is uh i think it is a very good job

00:28:11,440 --> 00:28:13,679
okay

00:28:14,720 --> 00:28:18,080
the another another way we have done for

00:28:17,600 --> 00:28:20,399
our

00:28:18,080 --> 00:28:22,320
is a is our performance enhancer

00:28:20,399 --> 00:28:27,200
enhanced

00:28:22,320 --> 00:28:27,200
no sorry

00:28:29,279 --> 00:28:35,520
besides we at first when uh

00:28:32,320 --> 00:28:38,559
our deployment on environment may be

00:28:35,520 --> 00:28:42,640
like maybe like this

00:28:38,559 --> 00:28:42,640
like the picture on the left side

00:28:42,720 --> 00:28:49,360
on top is aerosm3 engine and uh

00:28:46,480 --> 00:28:50,720
there is a file system level and there

00:28:49,360 --> 00:28:54,880
is cloud disk

00:28:50,720 --> 00:28:59,039
we use our alibaba cloud disk

00:28:54,880 --> 00:29:01,360
alibaba cloud disk okay for example

00:28:59,039 --> 00:29:02,960
we know that the deployment configure

00:29:01,360 --> 00:29:06,880
configuration for

00:29:02,960 --> 00:29:11,440
uh for for cassandra should be

00:29:06,880 --> 00:29:15,600
like that comics log maybe

00:29:11,440 --> 00:29:19,520
separated disc and all symbols should be

00:29:15,600 --> 00:29:19,520
with other left discs

00:29:19,679 --> 00:29:26,480
but on this performance

00:29:22,799 --> 00:29:29,200
it it will make a higher price for users

00:29:26,480 --> 00:29:30,399
you for for that we will make an

00:29:29,200 --> 00:29:32,799
individual

00:29:30,399 --> 00:29:34,559
disk for disks for commercial boxes

00:29:32,799 --> 00:29:37,760
comic box

00:29:34,559 --> 00:29:41,440
wounds store store

00:29:37,760 --> 00:29:44,559
store store like a store data for

00:29:41,440 --> 00:29:48,480
for a very very long time and every

00:29:44,559 --> 00:29:48,480
key insert into cassandra will

00:29:48,880 --> 00:29:55,279
reflect to commit solo and then uh

00:29:52,240 --> 00:29:56,640
will be deleted periodically but as

00:29:55,279 --> 00:30:00,240
tables and across this

00:29:56,640 --> 00:30:03,679
should be should be

00:30:00,240 --> 00:30:05,600
persisted forever or for very long time

00:30:03,679 --> 00:30:07,039
if the competitor com compassion

00:30:05,600 --> 00:30:10,640
strategy is okay

00:30:07,039 --> 00:30:13,840
and but uh we know that this

00:30:10,640 --> 00:30:17,919
format for uh for the users if you

00:30:13,840 --> 00:30:21,600
buy these products like this deployment

00:30:17,919 --> 00:30:26,640
they will cost us so much money

00:30:21,600 --> 00:30:26,640
so and this is not a good um

00:30:28,080 --> 00:30:34,000
this is volume this deployment is

00:30:31,360 --> 00:30:34,399
won't got a very good right performance

00:30:34,000 --> 00:30:38,159
so

00:30:34,399 --> 00:30:41,760
we change the deployment from left to

00:30:38,159 --> 00:30:45,440
the right side that is uh we use

00:30:41,760 --> 00:30:49,120
lvm to bind all cloud disk uh

00:30:45,440 --> 00:30:49,520
cloud disks together and if one stables

00:30:49,120 --> 00:30:52,720
and

00:30:49,520 --> 00:30:56,000
all kami's logs coming from uh from the

00:30:52,720 --> 00:30:59,360
casino and they will go from to

00:30:56,000 --> 00:31:01,760
arium and ariem will help them to split

00:30:59,360 --> 00:31:03,440
them into chunks and the different

00:31:01,760 --> 00:31:06,480
chunks were

00:31:03,440 --> 00:31:10,480
coming to different club discs in prayer

00:31:06,480 --> 00:31:11,600
in parallel so in this format we have

00:31:10,480 --> 00:31:14,640
got some balance

00:31:11,600 --> 00:31:18,000
benefits and

00:31:14,640 --> 00:31:21,519
why we can do this is because of

00:31:18,000 --> 00:31:24,880
the our cloud native environment why

00:31:21,519 --> 00:31:28,080
uh that is a at first

00:31:24,880 --> 00:31:29,279
we use our cloud disk that is pangu

00:31:28,080 --> 00:31:32,320
cloudy disk

00:31:29,279 --> 00:31:36,159
which can ensure 9 nine

00:31:32,320 --> 00:31:40,640
nines uh data reliability

00:31:36,159 --> 00:31:43,679
um but if you use a local disk

00:31:40,640 --> 00:31:45,360
and you use lvm i don't i don't advise

00:31:43,679 --> 00:31:49,279
you to use this format

00:31:45,360 --> 00:31:49,279
for if one disks

00:31:50,480 --> 00:31:56,640
got some error the

00:31:53,600 --> 00:31:59,840
the data on the nodes were a lot i don't

00:31:56,640 --> 00:32:00,559
advise you to be use this format but on

00:31:59,840 --> 00:32:03,519
our

00:32:00,559 --> 00:32:05,679
uh cloud environment i think this is a

00:32:03,519 --> 00:32:08,880
very is a good uh

00:32:05,679 --> 00:32:12,480
is a good uh advice for you to

00:32:08,880 --> 00:32:16,559
choose this deployment for

00:32:12,480 --> 00:32:21,120
the cloud disk will ensure line

00:32:16,559 --> 00:32:25,600
number of line data reliability

00:32:21,120 --> 00:32:28,880
okay this is first second

00:32:25,600 --> 00:32:31,279
we use this format and

00:32:28,880 --> 00:32:32,799
we can use the multi-disk parallel

00:32:31,279 --> 00:32:35,919
writing capability

00:32:32,799 --> 00:32:40,240
capacity which

00:32:35,919 --> 00:32:43,600
improve about 20 right performance

00:32:40,240 --> 00:32:45,840
and we have done a task uh the results

00:32:43,600 --> 00:32:45,840
will

00:32:46,000 --> 00:32:53,039
go to 20 on average uh okay

00:32:50,320 --> 00:32:54,320
third this is a better choice on the

00:32:53,039 --> 00:32:56,080
comprehensive

00:32:54,320 --> 00:32:57,760
consideration of performance and the

00:32:56,080 --> 00:33:01,279
prices we know that

00:32:57,760 --> 00:33:05,760
um on the left side deployment will got

00:33:01,279 --> 00:33:08,960
much money and this is the cheaper then

00:33:05,760 --> 00:33:12,000
then then the commission

00:33:08,960 --> 00:33:14,799
with one disk configuration

00:33:12,000 --> 00:33:15,679
is very is cheaper than than the left

00:33:14,799 --> 00:33:18,640
side

00:33:15,679 --> 00:33:19,600
picture or deployment okay that's the

00:33:18,640 --> 00:33:22,720
way down

00:33:19,600 --> 00:33:26,559
for performance enhancements just one

00:33:22,720 --> 00:33:29,600
one one one point we also we have got

00:33:26,559 --> 00:33:32,720
an another any other point

00:33:29,600 --> 00:33:35,519
um okay let's come in to see

00:33:32,720 --> 00:33:36,640
what have done for backhand backup and

00:33:35,519 --> 00:33:38,559
the restore

00:33:36,640 --> 00:33:40,720
we have done four and the incremental

00:33:38,559 --> 00:33:43,279
backhand restore

00:33:40,720 --> 00:33:45,360
it's it's a little like a lts text

00:33:43,279 --> 00:33:48,480
emigration

00:33:45,360 --> 00:33:49,120
we have some snapshots and increments

00:33:48,480 --> 00:33:52,399
back

00:33:49,120 --> 00:33:55,279
in snapshots as simple backup and

00:33:52,399 --> 00:33:56,640
incremental backups as table and also we

00:33:55,279 --> 00:33:59,760
have done commissilock's

00:33:56,640 --> 00:34:03,519
backup we have made

00:33:59,760 --> 00:34:07,360
y log or coming slot to doing online

00:34:03,519 --> 00:34:10,639
active we know that's if we you want to

00:34:07,360 --> 00:34:10,960
doing our commit lots uh actually we

00:34:10,639 --> 00:34:14,000
should

00:34:10,960 --> 00:34:15,599
restart this uh cluster we we we don't

00:34:14,000 --> 00:34:19,919
think that's a good idea so

00:34:15,599 --> 00:34:20,720
we doing uh online and replace online

00:34:19,919 --> 00:34:22,800
okay if you

00:34:20,720 --> 00:34:24,560
back up the snapshot as libra and the

00:34:22,800 --> 00:34:26,720
incremental backup basketball

00:34:24,560 --> 00:34:29,440
and commit log from the left to the

00:34:26,720 --> 00:34:33,200
right right

00:34:29,440 --> 00:34:37,119
and we when you doing restore

00:34:33,200 --> 00:34:39,359
we will pick uh some ass tables and

00:34:37,119 --> 00:34:40,320
commission locks we want to replace all

00:34:39,359 --> 00:34:43,280
comic clocks

00:34:40,320 --> 00:34:45,599
for that some that are also in

00:34:43,280 --> 00:34:48,240
incremental backups at school

00:34:45,599 --> 00:34:49,359
they are they are their work they will

00:34:48,240 --> 00:34:52,079
cause some data that's

00:34:49,359 --> 00:34:53,679
uh also include incremental accessible

00:34:52,079 --> 00:34:56,960
and also incremental so we

00:34:53,679 --> 00:34:57,680
won't replace them all we just we think

00:34:56,960 --> 00:35:01,119
that

00:34:57,680 --> 00:35:04,960
the more established to replace the less

00:35:01,119 --> 00:35:07,680
commission lock to replay and the better

00:35:04,960 --> 00:35:08,720
and the the less time we will cost if

00:35:07,680 --> 00:35:11,359
you use the commission

00:35:08,720 --> 00:35:12,320
is too much it will cost us so much time

00:35:11,359 --> 00:35:15,440
okay

00:35:12,320 --> 00:35:18,800
the last part is monitoring and alarm

00:35:15,440 --> 00:35:21,599
we will call this architecture

00:35:18,800 --> 00:35:22,079
magic connection that is a storage

00:35:21,599 --> 00:35:24,480
service

00:35:22,079 --> 00:35:25,680
magical storage storage proxy magic

00:35:24,480 --> 00:35:29,040
compaction mesh and

00:35:25,680 --> 00:35:31,359
so on and logs slow sql

00:35:29,040 --> 00:35:32,800
and the gc locks of warlocks will uh

00:35:31,359 --> 00:35:36,240
connected by sas

00:35:32,800 --> 00:35:39,680
service and uh the os services

00:35:36,240 --> 00:35:45,200
os um monitoring is a

00:35:39,680 --> 00:35:48,240
fs aero pack job demondance ttc

00:35:45,200 --> 00:35:52,079
all this information will be collected

00:35:48,240 --> 00:35:55,839
from our cloud service like cms

00:35:52,079 --> 00:35:56,240
and the sas and also available exception

00:35:55,839 --> 00:35:59,359
will

00:35:56,240 --> 00:36:00,560
come into our office and the rcms that

00:35:59,359 --> 00:36:04,960
are coming to

00:36:00,560 --> 00:36:08,000
a show for clients okay

00:36:04,960 --> 00:36:11,520
that's my talk and uh

00:36:08,000 --> 00:36:12,320
let's come into q a the uh this is my

00:36:11,520 --> 00:36:15,359
personal

00:36:12,320 --> 00:36:16,880
email uh you can you if you caught some

00:36:15,359 --> 00:36:20,880
question or if

00:36:16,880 --> 00:36:21,440
um uh if uh i you know this is my first

00:36:20,880 --> 00:36:24,320
time to

00:36:21,440 --> 00:36:26,160
talk in english so if you uh something

00:36:24,320 --> 00:36:29,680
is not um

00:36:26,160 --> 00:36:32,720
clear you can send me an email

00:36:29,680 --> 00:36:34,640
uh the the last link is our client

00:36:32,720 --> 00:36:38,480
absolutely

00:36:34,640 --> 00:36:39,760
you product you are left coming to see

00:36:38,480 --> 00:36:44,480
if anyone got some

00:36:39,760 --> 00:36:44,480
question any question

00:36:53,359 --> 00:36:57,440
hey maxwell thank you for your

00:36:54,960 --> 00:37:00,960
presentation

00:36:57,440 --> 00:37:04,640
uh can you can you can you

00:37:00,960 --> 00:37:08,400
just copy it

00:37:04,640 --> 00:37:08,400
maximum smoking is not so good

00:37:08,480 --> 00:37:12,560
that's okay um i'm the chair for the

00:37:10,560 --> 00:37:14,079
session so i'm just gonna ask anyone if

00:37:12,560 --> 00:37:16,720
they have any questions please put them

00:37:14,079 --> 00:37:16,720
into the chat

00:37:20,839 --> 00:37:23,839
anyone

00:37:34,320 --> 00:37:40,560
okay i think if

00:37:37,359 --> 00:37:42,240
anyone got some question he can send me

00:37:40,560 --> 00:37:51,839
an email

00:37:42,240 --> 00:37:51,839
this is my email

00:38:02,839 --> 00:38:08,400
maybe thank you thank you thank you

00:38:06,079 --> 00:38:09,359
yeah all right well if there's no

00:38:08,400 --> 00:38:12,880
questions um

00:38:09,359 --> 00:38:12,880
thanks again maxwell for presenting

00:38:14,720 --> 00:38:19,839
okay thank you thank you

00:38:44,839 --> 00:38:47,839
maiden

00:38:55,520 --> 00:38:57,599

YouTube URL: https://www.youtube.com/watch?v=PI882TVSltg


