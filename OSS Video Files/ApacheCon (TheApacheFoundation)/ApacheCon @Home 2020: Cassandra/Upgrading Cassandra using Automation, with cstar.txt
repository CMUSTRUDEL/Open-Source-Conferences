Title: Upgrading Cassandra using Automation, with cstar
Publication date: 2020-10-21
Playlist: ApacheCon @Home 2020: Cassandra
Description: 
	Upgrading Cassandra using Automation, with cstar
Valerie Parham-Thompson

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

I recently did an upgrade of 200+ nodes of Cassandra across multiple environments sitting behind multiple applications using the cstar tool. We chose the cstar tool because, out of all automation options, it has topology awareness specifically to Cassandra. I will share my experience with this upgrade, including observations and surprises, as well as a walk-through of the process using a Cassandra cluster provisioned in Docker.

With experience as an open-source DBA and developer for software-as-a-service environments, Valerie has expertise in web-scale data storage and data delivery, including MySQL, Cassandra, Postgres, and MongoDB.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:26,080 --> 00:00:30,080
all right

00:00:27,039 --> 00:00:32,960
um i am valerie kiram thompson

00:00:30,080 --> 00:00:34,000
i work for pipian and today i'm going to

00:00:32,960 --> 00:00:36,559
talk to you about

00:00:34,000 --> 00:00:37,680
my experience of creating a large

00:00:36,559 --> 00:00:40,320
cassandra

00:00:37,680 --> 00:00:41,920
cluster using automation specifically

00:00:40,320 --> 00:00:44,640
c-star

00:00:41,920 --> 00:00:45,120
i will say if you are interested in

00:00:44,640 --> 00:00:48,239
seeing

00:00:45,120 --> 00:00:50,559
the uh live demo of docker um

00:00:48,239 --> 00:00:52,559
the the demo is not going to happen

00:00:50,559 --> 00:00:53,280
today for technical reasons so i guess

00:00:52,559 --> 00:00:55,199
that beats

00:00:53,280 --> 00:00:56,640
um the live demo cutting off in the

00:00:55,199 --> 00:01:00,160
middle of the demo

00:00:56,640 --> 00:01:00,160
but just a heads up regarding that

00:01:01,760 --> 00:01:06,320
so i'm gonna assume that everybody here

00:01:04,720 --> 00:01:09,600
um

00:01:06,320 --> 00:01:11,680
knows what cassandra is um there are a

00:01:09,600 --> 00:01:13,200
couple things about cassandra design

00:01:11,680 --> 00:01:14,320
that i do want to point out because

00:01:13,200 --> 00:01:17,680
they're relevant to

00:01:14,320 --> 00:01:19,680
the upgrade maintenance

00:01:17,680 --> 00:01:21,520
so the first of course looking at this

00:01:19,680 --> 00:01:24,159
diagram that i took from the

00:01:21,520 --> 00:01:25,439
apache documentation cassandra's a

00:01:24,159 --> 00:01:28,159
distributed database

00:01:25,439 --> 00:01:28,560
so data is stored across nodes in our

00:01:28,159 --> 00:01:31,280
case

00:01:28,560 --> 00:01:32,159
a lot of nodes and it's stored in more

00:01:31,280 --> 00:01:33,680
than one place

00:01:32,159 --> 00:01:36,799
and that has some implications that

00:01:33,680 --> 00:01:39,520
we'll talk about in a second

00:01:36,799 --> 00:01:41,200
the other thing is um you know running a

00:01:39,520 --> 00:01:43,360
cassandra cluster you have a certain

00:01:41,200 --> 00:01:46,320
amount of operational knowledge

00:01:43,360 --> 00:01:47,200
um there are two things that are

00:01:46,320 --> 00:01:49,280
important

00:01:47,200 --> 00:01:50,240
uh for a relevant for this type of

00:01:49,280 --> 00:01:53,119
maintenance

00:01:50,240 --> 00:01:55,040
uh one is the discussion and the other

00:01:53,119 --> 00:01:56,719
is the general availability

00:01:55,040 --> 00:01:58,320
of course there are other operational

00:01:56,719 --> 00:02:01,759
concerns but these are the ones

00:01:58,320 --> 00:02:04,880
um to think about going into this

00:02:01,759 --> 00:02:06,560
um so for cassandra disk space of course

00:02:04,880 --> 00:02:07,920
run out of space right make sure you

00:02:06,560 --> 00:02:09,920
have the monitoring you need it for

00:02:07,920 --> 00:02:12,560
compaction you need it for snapshots

00:02:09,920 --> 00:02:14,319
you need it for ss table upgrades and

00:02:12,560 --> 00:02:16,400
you need more than you might imagine you

00:02:14,319 --> 00:02:19,520
need for this maintenance we needed

00:02:16,400 --> 00:02:22,000
on 60 overhead

00:02:19,520 --> 00:02:23,040
and thinking back to the diagram of

00:02:22,000 --> 00:02:24,800
cassandra

00:02:23,040 --> 00:02:26,879
cassandra can tolerate one node being

00:02:24,800 --> 00:02:27,520
down at a time but usually not more than

00:02:26,879 --> 00:02:30,879
that

00:02:27,520 --> 00:02:32,720
so um this will have implications for c

00:02:30,879 --> 00:02:34,080
star as we'll see in a second

00:02:32,720 --> 00:02:36,640
but this is something you definitely

00:02:34,080 --> 00:02:38,239
want to monitor just to send a side

00:02:36,640 --> 00:02:40,239
this is a key feature of distributed

00:02:38,239 --> 00:02:42,319
databases

00:02:40,239 --> 00:02:44,319
to deal with maintenance what we usually

00:02:42,319 --> 00:02:46,560
do is rolling restarts

00:02:44,319 --> 00:02:48,319
and this can be done for upgrades

00:02:46,560 --> 00:02:51,840
configuration changes

00:02:48,319 --> 00:02:51,840
or just any hardware changes

00:02:53,519 --> 00:02:56,959
okay so we can automate a variety of

00:02:56,239 --> 00:02:59,519
operations

00:02:56,959 --> 00:03:01,040
including upgrades this automation can

00:02:59,519 --> 00:03:04,080
be done with custom scripts

00:03:01,040 --> 00:03:04,720
one frequent example of a type of

00:03:04,080 --> 00:03:06,560
scripting

00:03:04,720 --> 00:03:07,760
ansible and we use well two to do

00:03:06,560 --> 00:03:10,560
maintenance this

00:03:07,760 --> 00:03:12,159
upgrades another kind of maintenance you

00:03:10,560 --> 00:03:14,400
have to code in those operational

00:03:12,159 --> 00:03:16,159
concerns that i mentioned above the idea

00:03:14,400 --> 00:03:18,000
of rolling restarts

00:03:16,159 --> 00:03:20,239
idea of making sure that not more than

00:03:18,000 --> 00:03:22,000
one node is down at a time

00:03:20,239 --> 00:03:24,800
the idea of monitoring for disk

00:03:22,000 --> 00:03:24,800
utilization

00:03:25,519 --> 00:03:29,120
as an aside if you are running sandra

00:03:28,080 --> 00:03:31,519
and containers

00:03:29,120 --> 00:03:33,280
kubernetes operators are really exciting

00:03:31,519 --> 00:03:35,200
way to

00:03:33,280 --> 00:03:36,400
make sure you're using that operational

00:03:35,200 --> 00:03:39,280
knowledge because they

00:03:36,400 --> 00:03:41,040
they tend to build a lot of that in in

00:03:39,280 --> 00:03:43,840
this case we were not using cassandra on

00:03:41,040 --> 00:03:43,840
containers though

00:03:44,480 --> 00:03:47,760
i'll talk a little bit about the c-star

00:03:46,239 --> 00:03:49,360
features

00:03:47,760 --> 00:03:51,200
um so this was a community tool it's

00:03:49,360 --> 00:03:54,159
contributed by spotify of course

00:03:51,200 --> 00:03:55,920
thank you spotify um i did see on the on

00:03:54,159 --> 00:03:57,519
a message for that someone mentioned

00:03:55,920 --> 00:03:58,480
they've never seen it work outside of

00:03:57,519 --> 00:04:00,720
spotify

00:03:58,480 --> 00:04:03,280
um clearly i have i've seen it working

00:04:00,720 --> 00:04:05,599
several times outside of spotify

00:04:03,280 --> 00:04:07,439
it's one of many community tools in use

00:04:05,599 --> 00:04:10,239
for apache

00:04:07,439 --> 00:04:11,840
of course we also have reaper and medusa

00:04:10,239 --> 00:04:13,519
thanks to the community and all those

00:04:11,840 --> 00:04:17,760
allow us to

00:04:13,519 --> 00:04:17,760
run operations against apache cassandra

00:04:17,840 --> 00:04:22,240
the dependencies for c-star are very

00:04:19,919 --> 00:04:25,440
minimal

00:04:22,240 --> 00:04:26,880
you need on the jump hose you just need

00:04:25,440 --> 00:04:28,880
python 3

00:04:26,880 --> 00:04:30,400
and of course the package manager makes

00:04:28,880 --> 00:04:32,960
that easier as well

00:04:30,400 --> 00:04:34,800
um when you're thinking about installing

00:04:32,960 --> 00:04:35,520
c-star you don't have to install it on

00:04:34,800 --> 00:04:36,720
the nodes

00:04:35,520 --> 00:04:38,160
so don't i know there are many

00:04:36,720 --> 00:04:41,520
environments you're still struggling

00:04:38,160 --> 00:04:43,040
with the python 2 python 3 overlap

00:04:41,520 --> 00:04:44,560
don't feel like you have to upgrade all

00:04:43,040 --> 00:04:45,040
your python to three you just need a

00:04:44,560 --> 00:04:47,759
simple

00:04:45,040 --> 00:04:50,639
jump post that's running c-star um you

00:04:47,759 --> 00:04:52,000
could even just spin up a vm for that

00:04:50,639 --> 00:04:54,720
most commonly you're going to use an

00:04:52,000 --> 00:04:56,880
existing operational jump pose direction

00:04:54,720 --> 00:04:58,960
the cassandra nodes themselves only need

00:04:56,880 --> 00:05:00,639
no tool since this is installed with

00:04:58,960 --> 00:05:03,919
cassandra typically

00:05:00,639 --> 00:05:03,919
that dependency is met

00:05:04,479 --> 00:05:08,320
a big thing you need is networking you

00:05:07,120 --> 00:05:10,479
require

00:05:08,320 --> 00:05:12,479
ssh connectivity um and that has to be

00:05:10,479 --> 00:05:15,680
done non-interactively so

00:05:12,479 --> 00:05:18,000
usually done ssh keys again this doesn't

00:05:15,680 --> 00:05:19,919
mean that c star has to be on a node

00:05:18,000 --> 00:05:25,280
typically your operational jump post

00:05:19,919 --> 00:05:27,600
will have that kind of networking

00:05:25,280 --> 00:05:28,800
so c-star is designed to run commands in

00:05:27,600 --> 00:05:31,199
a distributed way

00:05:28,800 --> 00:05:32,560
that's really all it well that's all it

00:05:31,199 --> 00:05:34,160
does um except for

00:05:32,560 --> 00:05:35,840
a bit of smartness i'll tell you about

00:05:34,160 --> 00:05:37,680
in a second um but

00:05:35,840 --> 00:05:39,600
it's really dumb in regards to the

00:05:37,680 --> 00:05:42,400
commands right it's only going to do

00:05:39,600 --> 00:05:44,080
what you tell it to do for example there

00:05:42,400 --> 00:05:46,800
aren't cassandra

00:05:44,080 --> 00:05:47,919
um operations built into the tool you

00:05:46,800 --> 00:05:50,080
couldn't do something like

00:05:47,919 --> 00:05:51,199
sea star cleanup and expect it to clean

00:05:50,080 --> 00:05:53,600
up your notes

00:05:51,199 --> 00:05:55,199
you have to see start run and then get a

00:05:53,600 --> 00:05:56,880
command in this instance

00:05:55,199 --> 00:05:58,560
you would do something like node tooling

00:05:56,880 --> 00:06:00,720
up and also just

00:05:58,560 --> 00:06:02,160
typical command state i don't have to

00:06:00,720 --> 00:06:07,680
because android commands

00:06:02,160 --> 00:06:10,800
so you could create files

00:06:07,680 --> 00:06:12,800
the part is not dumb about is regards to

00:06:10,800 --> 00:06:14,400
cassandra topology specifically the

00:06:12,800 --> 00:06:17,280
token distribution

00:06:14,400 --> 00:06:19,120
um it's able to run in parallel across

00:06:17,280 --> 00:06:20,160
data centers because it understands that

00:06:19,120 --> 00:06:22,560
concept

00:06:20,160 --> 00:06:24,160
and it knows um you know thinking back

00:06:22,560 --> 00:06:24,880
to the operational knowledge it knows

00:06:24,160 --> 00:06:26,720
that it

00:06:24,880 --> 00:06:28,319
waits for one node to be before it

00:06:26,720 --> 00:06:30,080
proceeds with the next

00:06:28,319 --> 00:06:32,319
it can manage data centers of different

00:06:30,080 --> 00:06:35,840
sizes so this is the part where because

00:06:32,319 --> 00:06:35,840
uh c-star really shines

00:06:36,720 --> 00:06:40,000
there's three ways you can pass code to

00:06:38,560 --> 00:06:42,880
z star

00:06:40,000 --> 00:06:44,400
you can run a distinct task you can run

00:06:42,880 --> 00:06:46,880
a custom script

00:06:44,400 --> 00:06:48,639
if you have a list of tasks or you can

00:06:46,880 --> 00:06:51,440
create a custom command

00:06:48,639 --> 00:06:53,919
so let's look at examples of those

00:06:51,440 --> 00:06:57,360
here's an example of a distinct task

00:06:53,919 --> 00:07:00,560
so with this i'm using cstar to run

00:06:57,360 --> 00:07:03,880
a command which will create files

00:07:00,560 --> 00:07:05,840
on all of my nodes in my cluster called

00:07:03,880 --> 00:07:08,160
file.txt

00:07:05,840 --> 00:07:09,919
i'm feeding it a speed host and through

00:07:08,160 --> 00:07:12,080
that seed host estar

00:07:09,919 --> 00:07:17,120
will detect the topology and know what

00:07:12,080 --> 00:07:19,199
all the nodes of my cluster are

00:07:17,120 --> 00:07:20,479
and this one i'm using c star par and

00:07:19,199 --> 00:07:22,400
i'll talk a little bit about the

00:07:20,479 --> 00:07:23,840
difference between c star and c start

00:07:22,400 --> 00:07:26,479
par in a little while

00:07:23,840 --> 00:07:27,280
but in this one i'm passing in a custom

00:07:26,479 --> 00:07:29,199
script

00:07:27,280 --> 00:07:31,440
the script in this case was named test

00:07:29,199 --> 00:07:35,199
types and config.sh

00:07:31,440 --> 00:07:36,319
and you can see the the contents of that

00:07:35,199 --> 00:07:38,960
file below

00:07:36,319 --> 00:07:40,800
it's just a bash script i'm passing in

00:07:38,960 --> 00:07:44,000
some ssh options

00:07:40,800 --> 00:07:46,479
i'm echoing something to the screen

00:07:44,000 --> 00:07:47,360
and the logs and then i'm sending an ssh

00:07:46,479 --> 00:07:50,160
command

00:07:47,360 --> 00:07:50,560
so again i've defined a list of tasks

00:07:50,160 --> 00:07:54,319
that

00:07:50,560 --> 00:07:56,000
c-star will then pass um

00:07:54,319 --> 00:07:57,759
well 6-star parts a little different but

00:07:56,000 --> 00:07:59,599
in any case that will run across all of

00:07:57,759 --> 00:08:02,400
the nodes in my cluster

00:07:59,599 --> 00:08:03,360
one more thing to notice here is that um

00:08:02,400 --> 00:08:05,759
i've

00:08:03,360 --> 00:08:06,960
i've passed in the option no done pause

00:08:05,759 --> 00:08:08,560
time 30.

00:08:06,960 --> 00:08:11,199
that just gives us a little breathing

00:08:08,560 --> 00:08:12,879
space between the

00:08:11,199 --> 00:08:15,280
the jobs as they're running across the

00:08:12,879 --> 00:08:15,280
cluster

00:08:16,879 --> 00:08:21,120
so in the examples we've seen you'll see

00:08:19,039 --> 00:08:24,080
that by default the c-star command

00:08:21,120 --> 00:08:25,520
is run other than that the only other

00:08:24,080 --> 00:08:28,319
two commands that you can run

00:08:25,520 --> 00:08:30,560
are cleanup jobs and continue and we'll

00:08:28,319 --> 00:08:31,280
see an example of cleanup ups in just a

00:08:30,560 --> 00:08:33,440
second

00:08:31,280 --> 00:08:35,440
the continue is just to continue a job

00:08:33,440 --> 00:08:37,200
that's been paused

00:08:35,440 --> 00:08:39,519
if you wanted to create a custom command

00:08:37,200 --> 00:08:42,719
though you would just create that

00:08:39,519 --> 00:08:44,560
script in something like bash or python

00:08:42,719 --> 00:08:46,080
and then add it to your commands folder

00:08:44,560 --> 00:08:48,080
under cstar

00:08:46,080 --> 00:08:50,560
for example looking back at that command

00:08:48,080 --> 00:08:51,360
that we wanted to run before the c-star

00:08:50,560 --> 00:08:55,040
cleanup

00:08:51,360 --> 00:08:57,040
we could find a bash script that would

00:08:55,040 --> 00:09:01,440
have a list of tasks to accomplish what

00:08:57,040 --> 00:09:01,440
we expect when we run c star cleanup

00:09:01,839 --> 00:09:05,839
i'm taking this example from the

00:09:03,279 --> 00:09:08,160
documentation because we didn't do this

00:09:05,839 --> 00:09:09,839
so here the custom command is called

00:09:08,160 --> 00:09:12,880
puppet hyphen upgrade

00:09:09,839 --> 00:09:16,880
hyphen cassandra and so i'm

00:09:12,880 --> 00:09:16,880
calling that command from c star

00:09:17,920 --> 00:09:22,399
this is a is again from the

00:09:19,600 --> 00:09:24,080
documentation an example of that script

00:09:22,399 --> 00:09:25,760
i'll point out a couple of things up at

00:09:24,080 --> 00:09:28,800
the top you've got a list of

00:09:25,760 --> 00:09:30,800
uh comments in those comments you can

00:09:28,800 --> 00:09:33,200
see their default options

00:09:30,800 --> 00:09:34,880
uh options that are being passed in and

00:09:33,200 --> 00:09:36,240
there's some help tests in the form of

00:09:34,880 --> 00:09:39,360
the description

00:09:36,240 --> 00:09:40,560
this command this custom command does

00:09:39,360 --> 00:09:42,959
four tasks

00:09:40,560 --> 00:09:43,920
it does a snapshot runs configuration

00:09:42,959 --> 00:09:46,160
management

00:09:43,920 --> 00:09:51,839
restarts cassandra and then upgrades to

00:09:46,160 --> 00:09:51,839
ss tables

00:09:52,240 --> 00:09:55,440
so if there's one part of c star that

00:09:54,959 --> 00:09:58,000
has

00:09:55,440 --> 00:09:59,519
um the most con that you would have the

00:09:58,000 --> 00:10:00,720
most control over it's in this

00:09:59,519 --> 00:10:03,360
parallelism

00:10:00,720 --> 00:10:04,399
so by default she starts going to run in

00:10:03,360 --> 00:10:06,720
parallel

00:10:04,399 --> 00:10:07,600
and it avoids that token overlap that

00:10:06,720 --> 00:10:10,160
it's detected

00:10:07,600 --> 00:10:11,920
when it first starts you can control

00:10:10,160 --> 00:10:15,440
this with the strategy

00:10:11,920 --> 00:10:18,320
options um the two common ones are

00:10:15,440 --> 00:10:20,079
strategy all and strategy one so we were

00:10:18,320 --> 00:10:20,480
doing verification steps we were fine

00:10:20,079 --> 00:10:22,240
using

00:10:20,480 --> 00:10:24,640
strategy all because those weren't very

00:10:22,240 --> 00:10:27,200
impactful when we wanted to do

00:10:24,640 --> 00:10:29,200
the upgrade or the sf table upgrade we

00:10:27,200 --> 00:10:31,360
reverted to strategy one

00:10:29,200 --> 00:10:32,480
to give a little less impact to the

00:10:31,360 --> 00:10:34,560
cluster

00:10:32,480 --> 00:10:36,480
you can also control it by using the

00:10:34,560 --> 00:10:38,640
options of tc parallel

00:10:36,480 --> 00:10:41,040
data center obviously or cluster

00:10:38,640 --> 00:10:41,040
parallel

00:10:42,320 --> 00:10:46,560
here's an example of what the output

00:10:44,000 --> 00:10:48,959
looks like so this command

00:10:46,560 --> 00:10:52,079
was used to look in the data directory

00:10:48,959 --> 00:10:54,959
and find files that were

00:10:52,079 --> 00:10:56,480
other than a format that we expected and

00:10:54,959 --> 00:10:57,440
so you can see first of all it gives you

00:10:56,480 --> 00:10:59,600
a job id

00:10:57,440 --> 00:11:00,480
i'll talk about that in a second it's

00:10:59,600 --> 00:11:04,160
running that

00:11:00,480 --> 00:11:06,079
default script which is run.sh

00:11:04,160 --> 00:11:07,200
if you were running a custom script you

00:11:06,079 --> 00:11:09,839
would actually see

00:11:07,200 --> 00:11:10,959
that it was running your custom script

00:11:09,839 --> 00:11:13,040
um and then it's

00:11:10,959 --> 00:11:14,720
back some of the options default options

00:11:13,040 --> 00:11:16,480
i thing to pass in

00:11:14,720 --> 00:11:18,560
and then the lower part of this is

00:11:16,480 --> 00:11:19,600
loading the cluster topology preheating

00:11:18,560 --> 00:11:22,079
the cache

00:11:19,600 --> 00:11:22,640
and doing the endpoint mapping um so

00:11:22,079 --> 00:11:24,959
here you

00:11:22,640 --> 00:11:26,959
see where c-star is telling you that

00:11:24,959 --> 00:11:28,000
it's doing that topology detection it's

00:11:26,959 --> 00:11:29,360
determining

00:11:28,000 --> 00:11:33,120
all of the nodes that are in your

00:11:29,360 --> 00:11:36,880
cluster if there's any part

00:11:33,120 --> 00:11:39,120
if you ever run seastar and this part

00:11:36,880 --> 00:11:40,560
lags and you feel like it's not

00:11:39,120 --> 00:11:42,399
completing

00:11:40,560 --> 00:11:43,360
first of all it does take quite a while

00:11:42,399 --> 00:11:44,480
because you've got to get all the

00:11:43,360 --> 00:11:46,720
information

00:11:44,480 --> 00:11:47,600
but two has one make sure that your

00:11:46,720 --> 00:11:50,240
networking

00:11:47,600 --> 00:11:51,200
is set correctly and make sure that

00:11:50,240 --> 00:11:56,079
you're using

00:11:51,200 --> 00:11:59,360
the most recent version of c store

00:11:56,079 --> 00:12:02,240
csr provides a mini dashboard of status

00:11:59,360 --> 00:12:03,200
so here you see a key up at the top with

00:12:02,240 --> 00:12:06,000
symbols

00:12:03,200 --> 00:12:07,760
um and then below you can see that this

00:12:06,000 --> 00:12:09,760
is a task cluster and there's only one

00:12:07,760 --> 00:12:12,399
data center and it has four notes

00:12:09,760 --> 00:12:12,800
all four of those nodes are executing

00:12:12,399 --> 00:12:15,360
the c

00:12:12,800 --> 00:12:15,360
star job

00:12:16,240 --> 00:12:20,079
and then this is what it looks like when

00:12:17,600 --> 00:12:21,360
it's finished so all four of them are

00:12:20,079 --> 00:12:24,639
finished so now your

00:12:21,360 --> 00:12:27,600
symbol has changed to

00:12:24,639 --> 00:12:28,880
done and they're up and then we also get

00:12:27,600 --> 00:12:31,279
that job id

00:12:28,880 --> 00:12:35,040
i've bolded that so you can see that

00:12:31,279 --> 00:12:35,040
that output is shown again

00:12:36,079 --> 00:12:39,680
so here's what it would look like um or

00:12:38,320 --> 00:12:41,040
here's what it did look like in a lot in

00:12:39,680 --> 00:12:44,800
the larger cluster

00:12:41,040 --> 00:12:46,800
um so you can see here that some of the

00:12:44,800 --> 00:12:49,680
nodes have finished so they're done

00:12:46,800 --> 00:12:51,040
and up some of them are executing so

00:12:49,680 --> 00:12:53,279
they're an asterisk

00:12:51,040 --> 00:12:54,320
and then some indicated by periods are

00:12:53,279 --> 00:12:58,000
waiting so

00:12:54,320 --> 00:12:58,000
nothing's happening on those right now

00:12:59,040 --> 00:13:03,200
also notice here that data center 4 is

00:13:01,440 --> 00:13:06,720
larger than the other data centers i'll

00:13:03,200 --> 00:13:09,440
come to that in a second

00:13:06,720 --> 00:13:12,000
so remember that job id you can use that

00:13:09,440 --> 00:13:13,519
job id to look in vstar jobs which is

00:13:12,000 --> 00:13:16,160
the log directory

00:13:13,519 --> 00:13:17,040
underneath the jobs folder you'll have a

00:13:16,160 --> 00:13:19,040
bunch of folders

00:13:17,040 --> 00:13:20,320
your job ids one for each job that you

00:13:19,040 --> 00:13:22,480
run let's see star

00:13:20,320 --> 00:13:24,560
and then under that you'll have the host

00:13:22,480 --> 00:13:28,079
names that were involved in that job

00:13:24,560 --> 00:13:28,880
the file four is named out and so here

00:13:28,079 --> 00:13:31,120
what i've

00:13:28,880 --> 00:13:32,480
done is my t star job as for disk

00:13:31,120 --> 00:13:34,959
utilization

00:13:32,480 --> 00:13:36,639
and i'm just checking to make sure we

00:13:34,959 --> 00:13:39,440
have enough overhead for the maintenance

00:13:36,639 --> 00:13:39,440
that we're about to do

00:13:40,720 --> 00:13:46,480
okay uh so why did we choose c-star

00:13:44,959 --> 00:13:48,880
there's three main reasons that you

00:13:46,480 --> 00:13:51,199
would use something like cstar

00:13:48,880 --> 00:13:52,800
which community tool over developing

00:13:51,199 --> 00:13:54,800
your own script

00:13:52,800 --> 00:13:56,480
so um a script that's been used in

00:13:54,800 --> 00:13:57,600
different systems has the advantage of

00:13:56,480 --> 00:14:00,560
being

00:13:57,600 --> 00:14:01,760
hardened against production another

00:14:00,560 --> 00:14:05,920
consideration

00:14:01,760 --> 00:14:07,600
that's really important is usually often

00:14:05,920 --> 00:14:09,040
these kinds of custom scripts are

00:14:07,600 --> 00:14:11,360
passion projects right

00:14:09,040 --> 00:14:13,120
so if the developer ever leaves usually

00:14:11,360 --> 00:14:16,720
there's nobody to pick that up

00:14:13,120 --> 00:14:17,600
and also you know they they tend to be

00:14:16,720 --> 00:14:19,839
not maintained

00:14:17,600 --> 00:14:22,240
very well so then you have to end up

00:14:19,839 --> 00:14:24,000
rewriting the custom scripts

00:14:22,240 --> 00:14:25,600
and then another concern is that it's a

00:14:24,000 --> 00:14:27,199
great way to contribute back to the

00:14:25,600 --> 00:14:27,760
community for all the tools that we're

00:14:27,199 --> 00:14:30,480
given

00:14:27,760 --> 00:14:31,680
right um even if your doc uh

00:14:30,480 --> 00:14:34,160
documentation or

00:14:31,680 --> 00:14:36,079
issues or doing pull requests this is a

00:14:34,160 --> 00:14:38,000
way to give back to the community

00:14:36,079 --> 00:14:40,639
so for these reasons we chose p star for

00:14:38,000 --> 00:14:40,639
this project

00:14:41,519 --> 00:14:48,880
okay a walk through the upgrade process

00:14:45,760 --> 00:14:50,639
um so because c-star was developed in

00:14:48,880 --> 00:14:52,320
a single company before it was open

00:14:50,639 --> 00:14:53,920
source i found that reading the

00:14:52,320 --> 00:14:56,000
documentation there were assumptions

00:14:53,920 --> 00:14:59,360
that i just didn't understand

00:14:56,000 --> 00:15:01,760
and so i did a lot of testing um

00:14:59,360 --> 00:15:03,440
just to understand the functionality um

00:15:01,760 --> 00:15:05,680
how it broke how it didn't break

00:15:03,440 --> 00:15:07,199
where the output was that kind of thing

00:15:05,680 --> 00:15:08,800
and then after that

00:15:07,199 --> 00:15:10,320
of course we tested in a staging

00:15:08,800 --> 00:15:11,600
environment which was a little bit

00:15:10,320 --> 00:15:13,360
closer to production

00:15:11,600 --> 00:15:16,480
had a little bit closer to production

00:15:13,360 --> 00:15:17,920
workload and data size

00:15:16,480 --> 00:15:19,440
so by the time we got to production of

00:15:17,920 --> 00:15:21,199
course most of those kinks were worked

00:15:19,440 --> 00:15:24,079
out we understood how the tool worked

00:15:21,199 --> 00:15:24,800
we understood not only where the output

00:15:24,079 --> 00:15:26,959
was but

00:15:24,800 --> 00:15:28,320
what it meant it still needed some

00:15:26,959 --> 00:15:30,320
babysitting so i'll talk about that in a

00:15:28,320 --> 00:15:33,040
second

00:15:30,320 --> 00:15:34,079
when you're running any kind of

00:15:33,040 --> 00:15:36,399
long-running job

00:15:34,079 --> 00:15:38,079
you obviously want to use screen but

00:15:36,399 --> 00:15:39,680
there's another reason you want to do

00:15:38,079 --> 00:15:41,759
that for key star

00:15:39,680 --> 00:15:42,880
if you think about c star is run from

00:15:41,759 --> 00:15:45,199
the jump host

00:15:42,880 --> 00:15:46,160
but the the work itself is being run on

00:15:45,199 --> 00:15:48,560
the nodes

00:15:46,160 --> 00:15:49,519
and so if for some reason you lose your

00:15:48,560 --> 00:15:51,360
status

00:15:49,519 --> 00:15:53,680
and something goes wrong you have to

00:15:51,360 --> 00:15:57,040
look at all your notes to figure out

00:15:53,680 --> 00:15:59,680
what to stop so running that

00:15:57,040 --> 00:16:02,160
screen allows you to have that status

00:15:59,680 --> 00:16:05,040
available even if you close your laptop

00:16:02,160 --> 00:16:06,000
so you can see what nodes need to be

00:16:05,040 --> 00:16:07,600
stopped

00:16:06,000 --> 00:16:10,240
i'm sorry about jobs on which notes need

00:16:07,600 --> 00:16:10,240
to be stopped

00:16:10,800 --> 00:16:15,519
okay so we put some prechecks um this is

00:16:13,600 --> 00:16:17,279
typical of a maintenance um we did this

00:16:15,519 --> 00:16:18,800
several days in advance just in case we

00:16:17,279 --> 00:16:20,959
needed to do some changes

00:16:18,800 --> 00:16:22,000
we verified we had the right hosts

00:16:20,959 --> 00:16:24,399
permissions

00:16:22,000 --> 00:16:26,959
so not only those ss permissions that i

00:16:24,399 --> 00:16:28,800
talked about but also

00:16:26,959 --> 00:16:30,160
um you know does can i get to the

00:16:28,800 --> 00:16:31,920
authentication server

00:16:30,160 --> 00:16:33,519
can i get to the nodes can i get to the

00:16:31,920 --> 00:16:35,040
configuration server those kinds of

00:16:33,519 --> 00:16:38,079
things making sure the software is in

00:16:35,040 --> 00:16:40,000
place and making sure that the scripts

00:16:38,079 --> 00:16:43,839
that we wrote were in place on the

00:16:40,000 --> 00:16:47,519
general so everything was ready for us

00:16:43,839 --> 00:16:50,480
and here we did run smc star jobs

00:16:47,519 --> 00:16:52,399
so one was to check that disk space that

00:16:50,480 --> 00:16:54,959
i talked about earlier

00:16:52,399 --> 00:16:56,320
this again these verification steps were

00:16:54,959 --> 00:16:58,079
done with strategy all because they

00:16:56,320 --> 00:17:00,480
weren't very impactful and it was okay

00:16:58,079 --> 00:17:02,480
to run them against all the nodes

00:17:00,480 --> 00:17:04,000
well we also wanted to make sure that

00:17:02,480 --> 00:17:07,199
there weren't any ss tables

00:17:04,000 --> 00:17:09,839
left behind from a previous upgrade

00:17:07,199 --> 00:17:10,799
just in case just because that causes a

00:17:09,839 --> 00:17:13,039
bit of messiness

00:17:10,799 --> 00:17:14,959
um so i just wanted to make sure all the

00:17:13,039 --> 00:17:18,079
access tables were in the current

00:17:14,959 --> 00:17:20,319
version format for the cassandra version

00:17:18,079 --> 00:17:24,959
running on the servers

00:17:20,319 --> 00:17:28,319
um then the snapshots we've run

00:17:24,959 --> 00:17:29,919
into several problems where

00:17:28,319 --> 00:17:31,679
you get in the middle of a maintenance

00:17:29,919 --> 00:17:32,000
and either you have a disk utilization

00:17:31,679 --> 00:17:34,799
problem

00:17:32,000 --> 00:17:36,240
or you have a recovery problem and there

00:17:34,799 --> 00:17:37,520
all of a sudden there are old snapshots

00:17:36,240 --> 00:17:39,039
that nobody knows about

00:17:37,520 --> 00:17:40,640
and then you have to have conversations

00:17:39,039 --> 00:17:44,080
about whether you can get rid of them

00:17:40,640 --> 00:17:46,320
um so we've just learned just

00:17:44,080 --> 00:17:47,120
go see what the snapshot exist on the

00:17:46,320 --> 00:17:50,320
servers

00:17:47,120 --> 00:17:53,760
so this is just a way to make sure um

00:17:50,320 --> 00:17:57,600
either there weren't any snapshots or

00:17:53,760 --> 00:17:58,480
that um that we at least knew what they

00:17:57,600 --> 00:18:01,200
were

00:17:58,480 --> 00:18:02,640
this is uh so we upgraded from starting

00:18:01,200 --> 00:18:06,720
from 2.0

00:18:02,640 --> 00:18:08,400
so um this is a custom command we

00:18:06,720 --> 00:18:11,280
couldn't use the notable command to

00:18:08,400 --> 00:18:11,280
use the snapshot

00:18:12,000 --> 00:18:15,440
and then the day of the maintenance um

00:18:14,000 --> 00:18:17,039
typical stuff send the maintenance

00:18:15,440 --> 00:18:18,640
notification we had the benefit of

00:18:17,039 --> 00:18:19,440
having a really nice dashboard that

00:18:18,640 --> 00:18:21,679
showed

00:18:19,440 --> 00:18:23,600
systems and application information um

00:18:21,679 --> 00:18:26,320
so we turn that on

00:18:23,600 --> 00:18:26,799
and then prepared the configuration

00:18:26,320 --> 00:18:28,559
files

00:18:26,799 --> 00:18:31,039
so that they were ready to apply via

00:18:28,559 --> 00:18:31,039
automation

00:18:31,919 --> 00:18:35,919
then we did some backups um so these

00:18:34,480 --> 00:18:38,400
first ones we're not using

00:18:35,919 --> 00:18:40,400
star but i've shown them anyways we did

00:18:38,400 --> 00:18:43,840
those on a single host

00:18:40,400 --> 00:18:45,280
and then then we did use the star to do

00:18:43,840 --> 00:18:49,280
the snapshots so

00:18:45,280 --> 00:18:51,200
i really liked using c star here

00:18:49,280 --> 00:18:57,120
because it was possible to do those

00:18:51,200 --> 00:19:00,480
snapshots across the entire cluster

00:18:57,120 --> 00:19:03,280
and then the upgrade um so

00:19:00,480 --> 00:19:05,120
using cstarpar here um so the

00:19:03,280 --> 00:19:08,160
configuration host

00:19:05,120 --> 00:19:09,520
was not accessible from the nodes so i

00:19:08,160 --> 00:19:10,160
told you i would tell you the difference

00:19:09,520 --> 00:19:14,160
between c

00:19:10,160 --> 00:19:15,840
star and c star par so c star is

00:19:14,160 --> 00:19:17,679
running the command is you're running it

00:19:15,840 --> 00:19:19,280
from the jump hose but it's running the

00:19:17,679 --> 00:19:22,559
commands on

00:19:19,280 --> 00:19:24,720
cstar par is running the command on the

00:19:22,559 --> 00:19:27,679
jump post with knowledge

00:19:24,720 --> 00:19:29,280
of the notes so in this case with since

00:19:27,679 --> 00:19:31,520
we could not reach the configuration

00:19:29,280 --> 00:19:33,520
management server from the nodes

00:19:31,520 --> 00:19:35,360
um we had to run it from the jump close

00:19:33,520 --> 00:19:36,080
but we did use c star so we would have

00:19:35,360 --> 00:19:39,600
the benefit

00:19:36,080 --> 00:19:42,880
and we could loop through all of the

00:19:39,600 --> 00:19:46,000
nodes that were detected so

00:19:42,880 --> 00:19:47,919
in this case um you know we ran a test

00:19:46,000 --> 00:19:51,120
mode configuration management

00:19:47,919 --> 00:19:52,640
statement just to be sure before this

00:19:51,120 --> 00:19:55,360
was started that

00:19:52,640 --> 00:19:56,960
it was going to send the right version

00:19:55,360 --> 00:20:00,960
and that it was the

00:19:56,960 --> 00:20:04,720
that it was working and then the um

00:20:00,960 --> 00:20:07,760
the upgrade cassandra bash

00:20:04,720 --> 00:20:08,880
script did a list of things stop

00:20:07,760 --> 00:20:10,960
cassandra applied

00:20:08,880 --> 00:20:14,240
the new binary and configuration files

00:20:10,960 --> 00:20:14,240
and then started cassandra

00:20:14,480 --> 00:20:17,919
and both of these we did with strategy

00:20:16,640 --> 00:20:19,760
one

00:20:17,919 --> 00:20:22,159
so that there would only be one per data

00:20:19,760 --> 00:20:22,159
center

00:20:24,240 --> 00:20:30,080
after that was done so the entire

00:20:28,000 --> 00:20:32,559
cluster was upgraded

00:20:30,080 --> 00:20:33,280
then of course you have to go and do the

00:20:32,559 --> 00:20:37,120
upgrade

00:20:33,280 --> 00:20:38,799
access table format so before

00:20:37,120 --> 00:20:40,640
i jumped into that really long running

00:20:38,799 --> 00:20:42,480
process i did want to make sure

00:20:40,640 --> 00:20:43,679
that we had the right version across all

00:20:42,480 --> 00:20:45,840
the notes

00:20:43,679 --> 00:20:47,360
so usually this is something i really

00:20:45,840 --> 00:20:48,559
liked about c-star if

00:20:47,360 --> 00:20:50,000
you know if you were doing this with

00:20:48,559 --> 00:20:51,679
hundreds of nodes you would either have

00:20:50,000 --> 00:20:53,280
to do a spot check

00:20:51,679 --> 00:20:55,679
or maybe you have to go do all the

00:20:53,280 --> 00:20:58,559
servers or you send some ssh statement

00:20:55,679 --> 00:21:00,720
um it was really easy to just do c-star

00:20:58,559 --> 00:21:02,960
you know send it out to all the servers

00:21:00,720 --> 00:21:05,840
ask for the no tool version and then

00:21:02,960 --> 00:21:08,720
grep through the output log

00:21:05,840 --> 00:21:09,280
so it was very fast check the disk space

00:21:08,720 --> 00:21:11,840
again

00:21:09,280 --> 00:21:13,120
just in case we had changed from the

00:21:11,840 --> 00:21:15,200
prefix

00:21:13,120 --> 00:21:16,240
and then upgrade ss table to the current

00:21:15,200 --> 00:21:18,320
version format

00:21:16,240 --> 00:21:20,000
so for this we actually did use a custom

00:21:18,320 --> 00:21:22,559
script for a variety of reasons it

00:21:20,000 --> 00:21:25,520
wasn't too much different in logic from

00:21:22,559 --> 00:21:26,640
how sp star works but if you were going

00:21:25,520 --> 00:21:28,080
to use z-star

00:21:26,640 --> 00:21:31,840
i've included this statement that you

00:21:28,080 --> 00:21:31,840
would use

00:21:32,320 --> 00:21:36,880
and then after the burn-in after

00:21:35,280 --> 00:21:38,240
everyone agreed that the application was

00:21:36,880 --> 00:21:40,720
fine then it was

00:21:38,240 --> 00:21:42,480
just a few cleanup steps close remaining

00:21:40,720 --> 00:21:45,760
screen sessions

00:21:42,480 --> 00:21:47,520
and remove the old snapshots and then

00:21:45,760 --> 00:21:49,600
i told you that c-star can do two things

00:21:47,520 --> 00:21:52,640
natively or three things natively

00:21:49,600 --> 00:21:55,840
run uh continue and clean up jobs so

00:21:52,640 --> 00:21:59,200
the cleanup jobs will remove all of the

00:21:55,840 --> 00:22:00,080
all of those log files in the cstar jobs

00:21:59,200 --> 00:22:01,600
directory

00:22:00,080 --> 00:22:03,919
by default it does everything over a

00:22:01,600 --> 00:22:05,600
week old for us the burn-in was longer

00:22:03,919 --> 00:22:07,039
than a week so which of all them anyways

00:22:05,600 --> 00:22:12,320
but you can adjust that

00:22:07,039 --> 00:22:15,679
with the option max job

00:22:12,320 --> 00:22:19,120
so changes for next time um because

00:22:15,679 --> 00:22:21,600
once we got to a certain level in

00:22:19,120 --> 00:22:23,440
environments um we didn't want to make

00:22:21,600 --> 00:22:25,360
any more changes before production there

00:22:23,440 --> 00:22:26,559
were things that i realized going along

00:22:25,360 --> 00:22:29,440
that i would

00:22:26,559 --> 00:22:31,039
do a little bit better next time so one

00:22:29,440 --> 00:22:31,919
is to combine more of those automation

00:22:31,039 --> 00:22:34,880
steps

00:22:31,919 --> 00:22:38,080
it would be nice to also have automate

00:22:34,880 --> 00:22:41,200
automation of the verification steps

00:22:38,080 --> 00:22:43,520
so combining those would be great um

00:22:41,200 --> 00:22:45,120
and i would also we didn't have time to

00:22:43,520 --> 00:22:49,360
put medusa in this environment

00:22:45,120 --> 00:22:49,360
but i would use medusa for the snapshot

00:22:50,640 --> 00:22:57,200
okay six lessons learned um

00:22:54,159 --> 00:22:58,480
so again uh if if c star isn't quite

00:22:57,200 --> 00:22:59,840
working the way you expect it to

00:22:58,480 --> 00:23:03,520
consider using c star

00:22:59,840 --> 00:23:04,720
par um and i've already explained that

00:23:03,520 --> 00:23:06,400
we didn't have access to the

00:23:04,720 --> 00:23:09,600
configuration management server from

00:23:06,400 --> 00:23:12,720
nodes and that's why it was used

00:23:09,600 --> 00:23:13,600
the cstar job folder this is especially

00:23:12,720 --> 00:23:16,640
useful

00:23:13,600 --> 00:23:17,120
if you're using screen because um your

00:23:16,640 --> 00:23:18,640
output

00:23:17,120 --> 00:23:20,320
you know will scroll off you can't copy

00:23:18,640 --> 00:23:22,000
and paste it and anyways it's nice to

00:23:20,320 --> 00:23:23,840
have a history so um

00:23:22,000 --> 00:23:26,240
you know definitely use that c star jobs

00:23:23,840 --> 00:23:30,720
you can tell that out file

00:23:26,240 --> 00:23:30,720
and see exactly what c star is doing

00:23:31,760 --> 00:23:35,039
the c star output i found it was too

00:23:33,679 --> 00:23:37,840
quiet um

00:23:35,039 --> 00:23:39,360
and so at some point early in testing

00:23:37,840 --> 00:23:41,919
the functionality

00:23:39,360 --> 00:23:42,960
um we ran into some errors and just

00:23:41,919 --> 00:23:45,600
didn't know

00:23:42,960 --> 00:23:47,760
why it wasn't working um it wasn't in

00:23:45,600 --> 00:23:50,400
the logs

00:23:47,760 --> 00:23:51,360
and because i as chef said the logs

00:23:50,400 --> 00:23:54,400
don't

00:23:51,360 --> 00:23:56,480
really give you information about um

00:23:54,400 --> 00:23:58,640
errors in c-star they give you the

00:23:56,480 --> 00:24:00,400
output of your job

00:23:58,640 --> 00:24:01,760
um so anyway turning on that verbose

00:24:00,400 --> 00:24:03,120
flag gives you a lot more error

00:24:01,760 --> 00:24:05,039
reporting

00:24:03,120 --> 00:24:06,400
and anyways it's going into your jobs

00:24:05,039 --> 00:24:08,000
logs so

00:24:06,400 --> 00:24:10,720
it's better to have that information for

00:24:08,000 --> 00:24:10,720
history anyway

00:24:11,120 --> 00:24:15,279
um this was a bit of a logic fail on my

00:24:13,120 --> 00:24:16,240
part but one of the things i asked the

00:24:15,279 --> 00:24:18,640
star to do

00:24:16,240 --> 00:24:19,520
was to go to all the nodes and make sure

00:24:18,640 --> 00:24:22,640
that a certain

00:24:19,520 --> 00:24:25,440
file didn't exist um

00:24:22,640 --> 00:24:26,880
of course if it didn't exist then c-star

00:24:25,440 --> 00:24:30,880
considered that

00:24:26,880 --> 00:24:33,679
the job had failed um so

00:24:30,880 --> 00:24:36,400
the quick fix for that is to um you know

00:24:33,679 --> 00:24:39,360
just add a line count

00:24:36,400 --> 00:24:40,960
at the end of the um the request so you

00:24:39,360 --> 00:24:43,520
at least get a zero back

00:24:40,960 --> 00:24:44,799
um one thing about c star is it it stops

00:24:43,520 --> 00:24:47,600
if it fails

00:24:44,799 --> 00:24:48,480
so you're kind of waiting wondering why

00:24:47,600 --> 00:24:52,320
the job's not

00:24:48,480 --> 00:24:52,320
completing this may help you

00:24:52,960 --> 00:24:56,960
um this is documented it's it wasn't a

00:24:55,679 --> 00:24:59,440
surprise

00:24:56,960 --> 00:25:00,720
what was a surprise was that because i

00:24:59,440 --> 00:25:02,960
had to hit the configure

00:25:00,720 --> 00:25:04,880
authentication server so many times and

00:25:02,960 --> 00:25:07,120
applying configuration management

00:25:04,880 --> 00:25:08,799
eventually the authentication server

00:25:07,120 --> 00:25:11,600
thought i was um

00:25:08,799 --> 00:25:12,720
stopping it i guess or um or trying to

00:25:11,600 --> 00:25:16,320
break into something

00:25:12,720 --> 00:25:17,360
so it locked me out the first time this

00:25:16,320 --> 00:25:20,880
happened

00:25:17,360 --> 00:25:24,960
i was about maybe 50 nodes

00:25:20,880 --> 00:25:27,200
into the process and

00:25:24,960 --> 00:25:28,480
so i went to the node and did the

00:25:27,200 --> 00:25:31,600
configuration

00:25:28,480 --> 00:25:33,200
manually and then restarted the node

00:25:31,600 --> 00:25:34,880
i was really worried that i was going to

00:25:33,200 --> 00:25:35,440
have to go back and restart the c start

00:25:34,880 --> 00:25:36,799
job

00:25:35,440 --> 00:25:39,600
but the really cool thing is that it

00:25:36,799 --> 00:25:43,840
just picked up it just kept going

00:25:39,600 --> 00:25:43,840
so i have a huge advantage of cstar

00:25:44,799 --> 00:25:48,080
and that doesn't know it really is

00:25:46,240 --> 00:25:50,159
topology aware um

00:25:48,080 --> 00:25:51,600
this is obviously documented it's kind

00:25:50,159 --> 00:25:54,240
of the point of c4

00:25:51,600 --> 00:25:56,320
um but until i saw it live i didn't

00:25:54,240 --> 00:25:57,600
realize how cool it was that it it did

00:25:56,320 --> 00:25:59,520
balance remember that

00:25:57,600 --> 00:26:00,640
uh fourth data center had a lot more

00:25:59,520 --> 00:26:02,960
nodes in it

00:26:00,640 --> 00:26:04,240
if we had just been doing kind of a

00:26:02,960 --> 00:26:06,799
round robin

00:26:04,240 --> 00:26:07,760
and um doing them one at a time on the

00:26:06,799 --> 00:26:09,360
data centers

00:26:07,760 --> 00:26:12,480
then that last data center would have

00:26:09,360 --> 00:26:14,480
had a lot of restarts at the end

00:26:12,480 --> 00:26:15,760
so it was really nice to see that it was

00:26:14,480 --> 00:26:18,480
balancing that

00:26:15,760 --> 00:26:19,440
and what appeared to me to be a

00:26:18,480 --> 00:26:22,880
balancing on

00:26:19,440 --> 00:26:26,159
percentages of nodes per data center

00:26:22,880 --> 00:26:26,640
so anyway the jobs time for each day the

00:26:26,159 --> 00:26:28,559
center

00:26:26,640 --> 00:26:30,960
and i found that to be a really good

00:26:28,559 --> 00:26:30,960
advantage

00:26:33,760 --> 00:26:41,679
okay um that is my presentation

00:26:38,320 --> 00:26:45,120
i will come back to the chat window

00:26:41,679 --> 00:26:48,960
and see if you have any questions

00:26:45,120 --> 00:26:48,960
thank you nate for the record for the

00:26:50,840 --> 00:26:55,520
announcement

00:26:53,279 --> 00:26:58,000
any questions about sea star or upgrade

00:26:55,520 --> 00:26:58,000
process

00:27:00,320 --> 00:27:08,400
about cassandra about pipian

00:27:06,080 --> 00:27:09,919
thank you thank you for coming to the

00:27:08,400 --> 00:27:12,240
presentation

00:27:09,919 --> 00:27:21,840
has anyone out there you see star or are

00:27:12,240 --> 00:27:21,840
looking at it

00:27:26,320 --> 00:27:28,559
okay

00:27:33,440 --> 00:27:35,840
okay

00:27:52,720 --> 00:27:57,200
um so your question can you compare or

00:27:55,520 --> 00:27:59,919
contrast it with ansible

00:27:57,200 --> 00:28:01,039
um so ansible is another one of these

00:27:59,919 --> 00:28:03,200
tools that

00:28:01,039 --> 00:28:04,640
is dumb it just does what you tell it to

00:28:03,200 --> 00:28:06,480
do um

00:28:04,640 --> 00:28:08,640
kind of like i described sea star as

00:28:06,480 --> 00:28:12,080
doing the thing

00:28:08,640 --> 00:28:15,679
you have to include

00:28:12,080 --> 00:28:18,399
the uh so the smart part about c-star

00:28:15,679 --> 00:28:19,760
is that it does that topology check and

00:28:18,399 --> 00:28:21,919
it makes sure that

00:28:19,760 --> 00:28:23,919
you don't have more than one node down

00:28:21,919 --> 00:28:25,760
uh you know for your

00:28:23,919 --> 00:28:27,279
token range and it makes sure that the

00:28:25,760 --> 00:28:28,559
application is not going to have

00:28:27,279 --> 00:28:30,399
downtime

00:28:28,559 --> 00:28:32,320
you can certainly do that with ansible

00:28:30,399 --> 00:28:35,039
we have done that with ansible

00:28:32,320 --> 00:28:37,200
but you have to code that part in um so

00:28:35,039 --> 00:28:39,039
it's just an additional step

00:28:37,200 --> 00:28:40,960
ansible can certainly be used to do this

00:28:39,039 --> 00:28:41,440
you just have to to give it a lot more

00:28:40,960 --> 00:28:45,840
code

00:28:41,440 --> 00:28:59,840
to do that c star is designed to deal

00:28:45,840 --> 00:28:59,840
specifically with cassandra clusters

00:29:12,399 --> 00:29:27,840
okay i don't see any more questions so

00:29:16,880 --> 00:29:27,840
thank you all for coming

00:30:56,799 --> 00:30:58,880

YouTube URL: https://www.youtube.com/watch?v=xcX_0UXjEvo


