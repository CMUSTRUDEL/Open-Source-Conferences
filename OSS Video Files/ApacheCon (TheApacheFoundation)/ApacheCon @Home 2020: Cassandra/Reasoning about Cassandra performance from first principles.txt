Title: Reasoning about Cassandra performance from first principles
Publication date: 2020-10-21
Playlist: ApacheCon @Home 2020: Cassandra
Description: 
	Reasoning about Cassandra performance from first principles
Jeff Hajewski

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

There are a plethora of articles and blog posts on Cassandra performance and performance tuning. Typically these resources contain specific pieces of advice on how to improve read or write throughput. The problem with these resources is that they focus on a specific solution to specific problem. In this talk we will start from first principles and develop a mental model that will allow us to reason about Cassandra's performance. The goal of the talk is for attendees to leave with a deeper understanding of how Cassandra works and how they can use that information to think through Cassandra's performance characteristics. We will start off by looking at how Cassandra stores data, the underlying data structures, and the implications of these design choices. The next two parts of the talk will discuss how Cassandra handles reads and writes and the associated trade-offs in the context of distributed systems. This talk is suitable both for those that regularly use Cassandra as well as those who are new to Cassandra because we focus on the ideas and principles behind Cassandra, rather than specific APIs or configurations.

Jeff is a software engineer at Salesforce, where he works on distributed systems for machine learning on streaming data. Prior to working at Salesforce he did his PhD at the University of Iowa. He works remotely from Iowa, where he lives with his wife, kid, and dog.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:25,920 --> 00:00:30,800
all right well i think we'll go ahead

00:00:27,279 --> 00:00:31,039
and get started sure this works all

00:00:30,800 --> 00:00:33,360
right

00:00:31,039 --> 00:00:34,480
well hi everyone my name is jeff ajewski

00:00:33,360 --> 00:00:36,480
i'm a sales uh

00:00:34,480 --> 00:00:38,960
software engineer at salesforce and

00:00:36,480 --> 00:00:40,960
today i'm going to be talking about

00:00:38,960 --> 00:00:42,480
some ways and some techniques in which

00:00:40,960 --> 00:00:43,760
we can reason about cassandra's

00:00:42,480 --> 00:00:46,960
performance

00:00:43,760 --> 00:00:49,280
using first principles so

00:00:46,960 --> 00:00:52,480
i'll start the talk with giving a brief

00:00:49,280 --> 00:00:52,480
overview of

00:00:52,800 --> 00:00:56,800
the talk in general the motivations

00:00:55,360 --> 00:00:58,079
behind this why

00:00:56,800 --> 00:01:00,559
i thought this would be an interesting

00:00:58,079 --> 00:01:02,239
talk to give but a bulk of the talk

00:01:00,559 --> 00:01:03,920
will be spent in three parts the first

00:01:02,239 --> 00:01:06,479
part will go over some of the core data

00:01:03,920 --> 00:01:07,840
structures used by cassandra

00:01:06,479 --> 00:01:09,840
in the second part we'll look at

00:01:07,840 --> 00:01:11,840
cassandra as a distributed system

00:01:09,840 --> 00:01:13,119
and in the third part we'll go through

00:01:11,840 --> 00:01:16,159
an example

00:01:13,119 --> 00:01:17,360
and how we can use the things we've

00:01:16,159 --> 00:01:18,960
learned the techniques we've learned in

00:01:17,360 --> 00:01:22,159
parts one and two

00:01:18,960 --> 00:01:24,960
and putting them into practice

00:01:22,159 --> 00:01:26,080
and then we'll end with a few takeaways

00:01:24,960 --> 00:01:28,159
okay so if you take

00:01:26,080 --> 00:01:29,840
one thing away from this talk one way to

00:01:28,159 --> 00:01:32,400
avoid any

00:01:29,840 --> 00:01:32,880
performance issues with cassandra and

00:01:32,400 --> 00:01:36,720
that is

00:01:32,880 --> 00:01:38,720
don't use cassandra uh as with every

00:01:36,720 --> 00:01:41,920
problem and every technology

00:01:38,720 --> 00:01:45,280
there are contexts and when

00:01:41,920 --> 00:01:47,040
where that technology uh makes sense

00:01:45,280 --> 00:01:49,759
and there are contexts in which that

00:01:47,040 --> 00:01:54,479
technology probably doesn't make sense

00:01:49,759 --> 00:01:57,360
so i i think there's kind of a

00:01:54,479 --> 00:01:58,799
an inclination uh us as engineers people

00:01:57,360 --> 00:02:00,719
interested in technology

00:01:58,799 --> 00:02:02,479
to use the most advanced or coolest

00:02:00,719 --> 00:02:05,119
technology out there

00:02:02,479 --> 00:02:06,560
uh but that can be problematic uh while

00:02:05,119 --> 00:02:09,280
cassandra is a great database

00:02:06,560 --> 00:02:11,520
very scalable it's non-trivial to

00:02:09,280 --> 00:02:14,239
administer and there can be some gotchas

00:02:11,520 --> 00:02:15,840
so if you need cassandra it's an

00:02:14,239 --> 00:02:17,680
excellent choice but if you don't need

00:02:15,840 --> 00:02:19,680
cassandra it's probably not the best

00:02:17,680 --> 00:02:22,720
choice

00:02:19,680 --> 00:02:24,239
so if if that's the case like

00:02:22,720 --> 00:02:26,239
think about your problem maybe start

00:02:24,239 --> 00:02:28,319
with a sql database until you know for

00:02:26,239 --> 00:02:30,319
sure that the sql database

00:02:28,319 --> 00:02:33,599
is not going to satisfy your needs then

00:02:30,319 --> 00:02:33,599
cassandra is probably a good option

00:02:33,920 --> 00:02:38,000
okay so what about this talk what was

00:02:36,560 --> 00:02:40,879
the motivation well

00:02:38,000 --> 00:02:42,959
i found online that there's a lot of

00:02:40,879 --> 00:02:43,280
blog posts about cassandra performance

00:02:42,959 --> 00:02:44,800
but

00:02:43,280 --> 00:02:46,319
they pretty much repeat each other they

00:02:44,800 --> 00:02:48,959
all say the same thing

00:02:46,319 --> 00:02:50,720
and that is basically that rights are

00:02:48,959 --> 00:02:52,239
fast in cassandra but don't read from

00:02:50,720 --> 00:02:54,080
cassandra because reads are slow

00:02:52,239 --> 00:02:56,000
and they'll say oh cassandra's a right

00:02:54,080 --> 00:02:59,280
optimized database

00:02:56,000 --> 00:03:02,840
uh which sure i'll grant that but

00:02:59,280 --> 00:03:05,760
the idea that reads are slow kind of

00:03:02,840 --> 00:03:08,159
uh chased me a little bit

00:03:05,760 --> 00:03:10,159
specifically because none of these posts

00:03:08,159 --> 00:03:11,519
really show any benchmarks or any real

00:03:10,159 --> 00:03:14,000
numbers

00:03:11,519 --> 00:03:15,200
uh so can cassandra reads be slow

00:03:14,000 --> 00:03:18,159
absolutely but

00:03:15,200 --> 00:03:19,760
they by just by definition of using

00:03:18,159 --> 00:03:20,879
cassandra does not mean your reads have

00:03:19,760 --> 00:03:22,159
to be slow

00:03:20,879 --> 00:03:24,720
uh so that's really the primary

00:03:22,159 --> 00:03:26,959
motivator here similarly

00:03:24,720 --> 00:03:28,400
you can come up with queries very simple

00:03:26,959 --> 00:03:30,560
looking queries in sql

00:03:28,400 --> 00:03:32,159
that are quite slow so as with

00:03:30,560 --> 00:03:34,879
everything you need to understand

00:03:32,159 --> 00:03:36,480
how your systems work and the tools you

00:03:34,879 --> 00:03:39,519
can use to interact with those systems

00:03:36,480 --> 00:03:41,200
to get the best performance

00:03:39,519 --> 00:03:43,680
okay so let's look at cassandra's core

00:03:41,200 --> 00:03:45,599
data structures

00:03:43,680 --> 00:03:47,200
i'll start with this quote from pat

00:03:45,599 --> 00:03:49,040
hellen which i really like and that's

00:03:47,200 --> 00:03:50,480
accountants don't use erasers otherwise

00:03:49,040 --> 00:03:51,920
they may go to jail

00:03:50,480 --> 00:03:53,840
and that leads into the core data

00:03:51,920 --> 00:03:55,760
structure of cassandra which is the log

00:03:53,840 --> 00:03:58,080
structured merge tree

00:03:55,760 --> 00:03:58,959
or lsm tree for short so these were

00:03:58,080 --> 00:04:02,560
proposed in

00:03:58,959 --> 00:04:06,400
96 as

00:04:02,560 --> 00:04:08,560
a new data structure where there are

00:04:06,400 --> 00:04:09,840
two mediums of storage for the structure

00:04:08,560 --> 00:04:12,799
there's a

00:04:09,840 --> 00:04:15,120
in memory structure and then there's

00:04:12,799 --> 00:04:17,440
data that's persisted to disk

00:04:15,120 --> 00:04:20,000
the in-memory data structures is

00:04:17,440 --> 00:04:23,199
typically referred to as the mem table

00:04:20,000 --> 00:04:24,960
and it's a tree-like structure

00:04:23,199 --> 00:04:26,400
it's implementation dependent so it

00:04:24,960 --> 00:04:28,800
doesn't there's not a specific data

00:04:26,400 --> 00:04:30,800
structure it has to be

00:04:28,800 --> 00:04:33,199
the pa in the paper they they propose

00:04:30,800 --> 00:04:36,720
avl trees is a good

00:04:33,199 --> 00:04:39,759
data structure to use for the mem table

00:04:36,720 --> 00:04:42,720
and then the structure on disk

00:04:39,759 --> 00:04:44,320
is what gets flushed from the mem table

00:04:42,720 --> 00:04:46,479
to disk and this again can be

00:04:44,320 --> 00:04:49,840
implementation dependent data structure

00:04:46,479 --> 00:04:51,280
so uh it could be a b plus tree if you

00:04:49,840 --> 00:04:53,440
wanted to but it doesn't have to be and

00:04:51,280 --> 00:04:56,479
in the case of cassandra

00:04:53,440 --> 00:04:58,000
the ls lsm trace we'll see is an ss

00:04:56,479 --> 00:04:59,680
table

00:04:58,000 --> 00:05:01,600
so what's the advantage of using this

00:04:59,680 --> 00:05:04,720
lsm tree

00:05:01,600 --> 00:05:06,160
well i when the mem table hits some

00:05:04,720 --> 00:05:09,360
capacity threshold

00:05:06,160 --> 00:05:11,280
it gets persisted to disk and the

00:05:09,360 --> 00:05:13,199
advantage there is

00:05:11,280 --> 00:05:14,320
it's being written to disk in a single

00:05:13,199 --> 00:05:16,960
process so

00:05:14,320 --> 00:05:17,600
the right is sequential there's no

00:05:16,960 --> 00:05:21,520
seeking

00:05:17,600 --> 00:05:21,520
involved on disk so it's very fast

00:05:21,759 --> 00:05:24,800
similarly when these men the memp tables

00:05:23,919 --> 00:05:28,320
flush to disk

00:05:24,800 --> 00:05:30,320
it's flushed as a append operation so

00:05:28,320 --> 00:05:32,479
that's typically just creating a new

00:05:30,320 --> 00:05:34,080
file uh it doesn't have to be creating a

00:05:32,479 --> 00:05:35,919
new file

00:05:34,080 --> 00:05:40,400
but the point here is we don't need any

00:05:35,919 --> 00:05:42,479
locks for this flush to disc

00:05:40,400 --> 00:05:44,320
uh now the two cons associated with this

00:05:42,479 --> 00:05:45,759
data structure are what are referred to

00:05:44,320 --> 00:05:48,320
as read amplification

00:05:45,759 --> 00:05:50,080
and right amplification so read

00:05:48,320 --> 00:05:51,600
amplification

00:05:50,080 --> 00:05:53,759
we'll learn more about in the coming

00:05:51,600 --> 00:05:57,919
slides but the basic idea here

00:05:53,759 --> 00:05:59,919
is in a zero amplification settings

00:05:57,919 --> 00:06:03,039
there's no read amplification

00:05:59,919 --> 00:06:04,479
a request a read request generates a

00:06:03,039 --> 00:06:06,960
single read

00:06:04,479 --> 00:06:09,120
but with read amplification a read

00:06:06,960 --> 00:06:11,759
request will generate multiple reads

00:06:09,120 --> 00:06:13,680
so there's some additional overhead for

00:06:11,759 --> 00:06:17,199
a given read request

00:06:13,680 --> 00:06:18,479
and similarly with right amplification

00:06:17,199 --> 00:06:20,319
in a setting where there is right

00:06:18,479 --> 00:06:25,039
amplification a single right

00:06:20,319 --> 00:06:27,039
will generate possibly more rights

00:06:25,039 --> 00:06:29,360
and we'll we'll see how this occurs in

00:06:27,039 --> 00:06:32,319
cassandra

00:06:29,360 --> 00:06:33,440
as i mentioned a slot a couple slides

00:06:32,319 --> 00:06:36,800
back

00:06:33,440 --> 00:06:38,639
cassandra persists the

00:06:36,800 --> 00:06:41,120
mem table to disk using what's called an

00:06:38,639 --> 00:06:42,400
ss table or a sorted string table

00:06:41,120 --> 00:06:44,400
this is a data structure that was

00:06:42,400 --> 00:06:47,759
introduced in the big table paper

00:06:44,400 --> 00:06:48,960
back in 2006 it is a very simple

00:06:47,759 --> 00:06:51,919
structure

00:06:48,960 --> 00:06:52,560
it's just a list of key value pairs

00:06:51,919 --> 00:06:55,759
sorted

00:06:52,560 --> 00:06:58,400
by key and the value is a an arbitrary

00:06:55,759 --> 00:06:58,400
byte string

00:06:59,120 --> 00:07:02,720
and this is important to understand so

00:07:01,680 --> 00:07:05,039
if we have a

00:07:02,720 --> 00:07:07,919
sorted list of key value pairs how long

00:07:05,039 --> 00:07:09,680
does it take to find a given key

00:07:07,919 --> 00:07:11,440
it's logarithmic time we you can use

00:07:09,680 --> 00:07:13,120
binary binary search this is a pretty

00:07:11,440 --> 00:07:15,039
standard

00:07:13,120 --> 00:07:16,800
question in a like an undergraduate

00:07:15,039 --> 00:07:20,080
algorithms course

00:07:16,800 --> 00:07:23,680
now what about lookups in sql

00:07:20,080 --> 00:07:25,120
well uh in sql we're typically using

00:07:23,680 --> 00:07:28,960
let's say some kind of variant of a b

00:07:25,120 --> 00:07:29,680
plus tree so we have some index

00:07:28,960 --> 00:07:31,840
structure

00:07:29,680 --> 00:07:34,319
and we need to traverse that structure

00:07:31,840 --> 00:07:37,759
to find maybe some file offset

00:07:34,319 --> 00:07:40,080
that's also logarithmic now of course

00:07:37,759 --> 00:07:41,280
the base of these logarithms might be

00:07:40,080 --> 00:07:43,919
different

00:07:41,280 --> 00:07:45,759
but the core point here is in both cases

00:07:43,919 --> 00:07:48,800
whether we're going through an ss table

00:07:45,759 --> 00:07:51,919
or similarly a mem table

00:07:48,800 --> 00:07:53,599
or a lookup in a sql database

00:07:51,919 --> 00:07:56,160
we in both cases we have this

00:07:53,599 --> 00:07:58,560
logarithmic complexity

00:07:56,160 --> 00:08:00,960
so the point here is that with cassandra

00:07:58,560 --> 00:08:04,479
there's nothing particular about

00:08:00,960 --> 00:08:07,520
the uh like pure lookup

00:08:04,479 --> 00:08:09,440
process that's slower than sql

00:08:07,520 --> 00:08:10,560
now it's we'll see the interaction of

00:08:09,440 --> 00:08:14,879
the system as a whole

00:08:10,560 --> 00:08:14,879
what is what can add some overhead

00:08:15,280 --> 00:08:19,680
now as i said before when the mem table

00:08:18,000 --> 00:08:22,639
reaches some capacity

00:08:19,680 --> 00:08:23,680
it's flush to disk and this flush

00:08:22,639 --> 00:08:26,560
creates a new file

00:08:23,680 --> 00:08:28,400
cassandra and this is what causes read

00:08:26,560 --> 00:08:30,800
amplification

00:08:28,400 --> 00:08:32,719
so if we think about this as our mem

00:08:30,800 --> 00:08:36,719
table keeps getting flushed to disk

00:08:32,719 --> 00:08:39,599
we have files that start to accumulate

00:08:36,719 --> 00:08:41,039
on our disk and this flushing is

00:08:39,599 --> 00:08:43,039
happening because the med table is

00:08:41,039 --> 00:08:46,080
reaching some maximum capacity

00:08:43,039 --> 00:08:48,000
so we persist it and we remove some of

00:08:46,080 --> 00:08:51,360
the data from that mem table

00:08:48,000 --> 00:08:54,720
which means that the files on

00:08:51,360 --> 00:08:56,640
disk likely contain

00:08:54,720 --> 00:08:57,920
different values there's probably some

00:08:56,640 --> 00:09:01,600
overlap but

00:08:57,920 --> 00:09:01,600
there's no guaranteed overlap

00:09:02,080 --> 00:09:05,279
and so what this means is as we're

00:09:03,760 --> 00:09:08,240
reading from these files

00:09:05,279 --> 00:09:09,440
if we don't find a key in one of the

00:09:08,240 --> 00:09:11,040
files

00:09:09,440 --> 00:09:12,399
we need to search the other files

00:09:11,040 --> 00:09:14,240
because it's possible it's just this

00:09:12,399 --> 00:09:17,440
specific file that doesn't have the key

00:09:14,240 --> 00:09:21,120
but it exists in some other file

00:09:17,440 --> 00:09:23,120
now what about write amplification

00:09:21,120 --> 00:09:24,480
well as we accumulate these files on

00:09:23,120 --> 00:09:27,360
disk we can

00:09:24,480 --> 00:09:28,480
condense them or compact them and this

00:09:27,360 --> 00:09:31,519
compaction process

00:09:28,480 --> 00:09:33,600
is what causes the right amplification

00:09:31,519 --> 00:09:36,000
so you can think of in let's say like

00:09:33,600 --> 00:09:38,720
the most trivial setting

00:09:36,000 --> 00:09:39,680
we have two files they contain a single

00:09:38,720 --> 00:09:42,720
element each

00:09:39,680 --> 00:09:45,040
and it's the same key the newer file is

00:09:42,720 --> 00:09:47,680
going to contain the more recent

00:09:45,040 --> 00:09:48,480
value written to that key than the older

00:09:47,680 --> 00:09:50,959
file

00:09:48,480 --> 00:09:52,640
so in that compaction process we merge

00:09:50,959 --> 00:09:54,800
these two files into one

00:09:52,640 --> 00:09:57,040
and we keep the updated value the most

00:09:54,800 --> 00:09:59,040
recent value for that key

00:09:57,040 --> 00:10:00,480
now remember we're not deleting data

00:09:59,040 --> 00:10:02,640
anywhere uh with

00:10:00,480 --> 00:10:03,760
with cassandra you know specifically

00:10:02,640 --> 00:10:06,079
with these lsm entries

00:10:03,760 --> 00:10:08,720
we're appending so we add a new

00:10:06,079 --> 00:10:11,920
reference to the data with a new value

00:10:08,720 --> 00:10:15,920
instead of overwriting an old value

00:10:11,920 --> 00:10:15,920
which is how sql typically works

00:10:16,640 --> 00:10:23,839
okay so let's walk through um some

00:10:20,000 --> 00:10:27,680
kind of pseudo kodish slash java

00:10:23,839 --> 00:10:31,680
uh logic of what happens

00:10:27,680 --> 00:10:33,680
when we query a key uh

00:10:31,680 --> 00:10:35,920
like what is the the process what steps

00:10:33,680 --> 00:10:37,360
happen so we look up a key

00:10:35,920 --> 00:10:39,760
and we want to get the corresponding

00:10:37,360 --> 00:10:42,480
value so step one

00:10:39,760 --> 00:10:45,120
is check the mem table does the mem

00:10:42,480 --> 00:10:47,040
table contain the value for this key

00:10:45,120 --> 00:10:49,519
and this is the best case scenario if it

00:10:47,040 --> 00:10:52,800
does then we can immediately return

00:10:49,519 --> 00:10:52,800
the value for that key

00:10:53,200 --> 00:10:58,320
and in this case this is pretty similar

00:10:55,839 --> 00:11:01,519
to just hitting a sql database

00:10:58,320 --> 00:11:02,720
now the challenge is if the mem table

00:11:01,519 --> 00:11:05,519
does not contain the key

00:11:02,720 --> 00:11:06,800
then what should we do well the logic

00:11:05,519 --> 00:11:09,760
works as follows

00:11:06,800 --> 00:11:11,600
we sort all of our log files by creation

00:11:09,760 --> 00:11:13,279
time

00:11:11,600 --> 00:11:15,440
in that we iterate through the most

00:11:13,279 --> 00:11:18,240
recent log file first

00:11:15,440 --> 00:11:19,760
and the least recent or oldest log file

00:11:18,240 --> 00:11:21,760
last

00:11:19,760 --> 00:11:23,440
and for each of those files we do the

00:11:21,760 --> 00:11:26,240
following we check

00:11:23,440 --> 00:11:27,680
is it possible that this file contains

00:11:26,240 --> 00:11:29,839
the key

00:11:27,680 --> 00:11:32,000
and if that's true then we try to

00:11:29,839 --> 00:11:34,480
retrieve the key

00:11:32,000 --> 00:11:36,320
if this is false in other words if we

00:11:34,480 --> 00:11:37,920
know for sure that the file will not

00:11:36,320 --> 00:11:41,279
contain the key

00:11:37,920 --> 00:11:43,920
then we move on to the next file

00:11:41,279 --> 00:11:45,680
uh now note that i'm saying here file

00:11:43,920 --> 00:11:47,519
might contain the key

00:11:45,680 --> 00:11:49,839
so when we attempt to retrieve the key

00:11:47,519 --> 00:11:51,279
from a given file it's possible we won't

00:11:49,839 --> 00:11:54,399
find it

00:11:51,279 --> 00:11:58,720
so here we're only returning the value

00:11:54,399 --> 00:11:58,720
for the key if it exists

00:12:00,240 --> 00:12:03,519
so this might be a little bit of a head

00:12:01,600 --> 00:12:04,320
scratcher for some of you what is going

00:12:03,519 --> 00:12:07,920
on here with this

00:12:04,320 --> 00:12:08,320
might contain key and it turns out this

00:12:07,920 --> 00:12:10,160
is

00:12:08,320 --> 00:12:13,279
a data structure called a bloom filter

00:12:10,160 --> 00:12:16,399
it's a very cool data structure

00:12:13,279 --> 00:12:17,360
and the idea with a bloom filter is it

00:12:16,399 --> 00:12:18,800
can tell us

00:12:17,360 --> 00:12:20,959
a bloom filter can tell us with

00:12:18,800 --> 00:12:24,480
certainty we have not seen

00:12:20,959 --> 00:12:26,240
a specific key or

00:12:24,480 --> 00:12:28,320
it can tell us that we might have seen a

00:12:26,240 --> 00:12:29,360
key

00:12:28,320 --> 00:12:31,040
this is what's known as it's a

00:12:29,360 --> 00:12:33,920
probabilistic data structure in that

00:12:31,040 --> 00:12:36,399
when we get a positive response

00:12:33,920 --> 00:12:38,480
it's not a guarantee that we have seen

00:12:36,399 --> 00:12:40,399
the element we're trying to look up

00:12:38,480 --> 00:12:41,519
if you find this interesting i suggest

00:12:40,399 --> 00:12:43,920
after the talk go

00:12:41,519 --> 00:12:46,079
read up on blue filters they're very

00:12:43,920 --> 00:12:48,880
extremely useful

00:12:46,079 --> 00:12:50,480
uh data structure in a number of

00:12:48,880 --> 00:12:52,480
settings but in this particular setting

00:12:50,480 --> 00:12:55,120
it's great because

00:12:52,480 --> 00:12:56,480
for a given key and a file the blue

00:12:55,120 --> 00:12:57,920
filter can tell us for sure

00:12:56,480 --> 00:13:00,160
it's not worth our time to search that

00:12:57,920 --> 00:13:06,000
file and that's very valuable

00:13:00,160 --> 00:13:08,320
especially if we have a number of files

00:13:06,000 --> 00:13:10,720
so what about cassandra as a distributed

00:13:08,320 --> 00:13:10,720
system

00:13:14,240 --> 00:13:17,360
when we talk about distributed systems

00:13:16,480 --> 00:13:20,079
consistency

00:13:17,360 --> 00:13:21,440
is one of the key concepts we need to

00:13:20,079 --> 00:13:24,160
deal with

00:13:21,440 --> 00:13:26,000
and consistency is you can kind of think

00:13:24,160 --> 00:13:26,800
about it as like the global state of

00:13:26,000 --> 00:13:29,839
your data

00:13:26,800 --> 00:13:30,480
during a read i guess i say write or

00:13:29,839 --> 00:13:31,680
read but

00:13:30,480 --> 00:13:34,320
we typically think about this in the

00:13:31,680 --> 00:13:37,519
read setting

00:13:34,320 --> 00:13:40,079
so what exactly do we mean by that well

00:13:37,519 --> 00:13:41,760
i let's think about this in terms of

00:13:40,079 --> 00:13:43,920
examples so

00:13:41,760 --> 00:13:45,360
in general we see the two kinds of

00:13:43,920 --> 00:13:46,480
consistencies that are discussed

00:13:45,360 --> 00:13:47,920
although it's important to point out

00:13:46,480 --> 00:13:48,959
that these are not the only kinds of

00:13:47,920 --> 00:13:51,680
consistency

00:13:48,959 --> 00:13:53,519
we can have in a distributed system but

00:13:51,680 --> 00:13:55,040
we have what's called read after right

00:13:53,519 --> 00:13:58,399
consistency

00:13:55,040 --> 00:13:59,680
and eventual consistency

00:13:58,399 --> 00:14:02,480
if you're familiar with distributed

00:13:59,680 --> 00:14:03,600
systems like theory and stuff read after

00:14:02,480 --> 00:14:06,639
right consistency and

00:14:03,600 --> 00:14:08,399
is also known as strict cons consistency

00:14:06,639 --> 00:14:10,639
and this is the strongest type of

00:14:08,399 --> 00:14:14,880
consistency we can have

00:14:10,639 --> 00:14:17,120
and what this means is after a write

00:14:14,880 --> 00:14:19,519
any read will return the most recently

00:14:17,120 --> 00:14:21,839
written value

00:14:19,519 --> 00:14:22,959
now naively this might seem like obvious

00:14:21,839 --> 00:14:25,040
like of course this is what we would

00:14:22,959 --> 00:14:28,399
expect but in a distributed system where

00:14:25,040 --> 00:14:28,399
we have multiple nodes

00:14:29,440 --> 00:14:34,639
there is some leeway as to when we want

00:14:32,160 --> 00:14:37,680
to call a write successful

00:14:34,639 --> 00:14:40,000
and in read after write consistency

00:14:37,680 --> 00:14:43,199
we say a write is successful whenever a

00:14:40,000 --> 00:14:46,000
node agrees on the value

00:14:43,199 --> 00:14:48,399
now with eventual consistency we're

00:14:46,000 --> 00:14:50,160
relaxing that requirement a little bit

00:14:48,399 --> 00:14:52,240
and with eventual consistency what we're

00:14:50,160 --> 00:14:56,320
asking for is

00:14:52,240 --> 00:14:58,720
uh for a given write after enough time

00:14:56,320 --> 00:15:01,440
a read from some node will return that

00:14:58,720 --> 00:15:01,440
written value

00:15:02,320 --> 00:15:05,600
so what does that mean that means for

00:15:03,760 --> 00:15:08,320
any written value it's

00:15:05,600 --> 00:15:10,240
possible we'll eventually see that value

00:15:08,320 --> 00:15:10,880
but it's not a guarantee that the value

00:15:10,240 --> 00:15:14,160
we read

00:15:10,880 --> 00:15:14,160
is the most recent value

00:15:14,560 --> 00:15:18,399
another way of thinking about this is

00:15:16,399 --> 00:15:22,240
you write some data to a couple nodes in

00:15:18,399 --> 00:15:22,240
your system but not the entire system

00:15:22,560 --> 00:15:27,040
and if you read from a node that has not

00:15:25,360 --> 00:15:30,560
seen that data yet you'll get an

00:15:27,040 --> 00:15:32,720
old value but the system will propagate

00:15:30,560 --> 00:15:34,000
that data through all the other nodes

00:15:32,720 --> 00:15:35,600
and eventually

00:15:34,000 --> 00:15:37,759
if you keep reading from the same node

00:15:35,600 --> 00:15:40,399
over and over eventually you'll see this

00:15:37,759 --> 00:15:42,480
updated value

00:15:40,399 --> 00:15:44,079
this type of consistency i think was

00:15:42,480 --> 00:15:47,120
probably popularized in the

00:15:44,079 --> 00:15:48,160
dynamodb paper from amazon dynamodb is

00:15:47,120 --> 00:15:51,440
known for

00:15:48,160 --> 00:15:54,320
eventual consistency and this is a big

00:15:51,440 --> 00:15:57,440
concept in cassandra as well

00:15:54,320 --> 00:15:59,519
okay so i say like consistency is

00:15:57,440 --> 00:16:01,040
is a big part of distributed systems so

00:15:59,519 --> 00:16:03,680
why do we really care about this

00:16:01,040 --> 00:16:04,959
well there's a correlation between

00:16:03,680 --> 00:16:07,360
transaction latency

00:16:04,959 --> 00:16:08,000
and consistency so the stronger your

00:16:07,360 --> 00:16:10,800
consistency

00:16:08,000 --> 00:16:12,880
requirements are of your system the

00:16:10,800 --> 00:16:13,600
larger your transaction latency is going

00:16:12,880 --> 00:16:16,720
to be

00:16:13,600 --> 00:16:18,639
and that's intuitive if you need to

00:16:16,720 --> 00:16:22,160
have a transaction you only care if one

00:16:18,639 --> 00:16:24,079
node acknowledges that transaction

00:16:22,160 --> 00:16:25,440
it's it's of course that is going to be

00:16:24,079 --> 00:16:26,959
much faster than if you have a

00:16:25,440 --> 00:16:30,000
transaction where every node

00:16:26,959 --> 00:16:31,759
must acknowledge that transaction

00:16:30,000 --> 00:16:33,519
not only do you have to interact with

00:16:31,759 --> 00:16:34,880
multiple nodes but it's possible some of

00:16:33,519 --> 00:16:37,279
those nodes are bogged down

00:16:34,880 --> 00:16:38,399
or might be failing so there's a lot

00:16:37,279 --> 00:16:41,279
more that can go wrong

00:16:38,399 --> 00:16:42,320
with a read after write consistency type

00:16:41,279 --> 00:16:43,680
level

00:16:42,320 --> 00:16:46,800
on the other hand read after write

00:16:43,680 --> 00:16:49,600
consistency gives you some much stricter

00:16:46,800 --> 00:16:51,839
or stronger guarantees about your data

00:16:49,600 --> 00:16:53,759
and as we'll see in this part of the

00:16:51,839 --> 00:16:56,000
talk that

00:16:53,759 --> 00:16:57,519
i guess in the third part understanding

00:16:56,000 --> 00:16:59,440
the consistency requirements of your

00:16:57,519 --> 00:17:00,320
application are very important to

00:16:59,440 --> 00:17:05,280
getting

00:17:00,320 --> 00:17:09,360
to tuning the performance of cassandra

00:17:05,280 --> 00:17:10,559
okay now with uh distributed data stores

00:17:09,360 --> 00:17:11,520
in general there's this idea of

00:17:10,559 --> 00:17:14,880
replication

00:17:11,520 --> 00:17:16,400
uh i guess in the most familiar sense

00:17:14,880 --> 00:17:16,959
even like backing up your data like

00:17:16,400 --> 00:17:18,720
typically

00:17:16,959 --> 00:17:20,400
you back your data up to maybe a couple

00:17:18,720 --> 00:17:21,760
hard drives just to be safe in case one

00:17:20,400 --> 00:17:24,160
of them fails

00:17:21,760 --> 00:17:26,480
it's the same idea with distributed data

00:17:24,160 --> 00:17:27,839
systems

00:17:26,480 --> 00:17:30,799
there's a couple additional advantage

00:17:27,839 --> 00:17:32,480
though so with replicas

00:17:30,799 --> 00:17:34,240
you have a few things certainly like if

00:17:32,480 --> 00:17:35,760
one if you lose one of the replicas

00:17:34,240 --> 00:17:37,840
you have your data persisted to the

00:17:35,760 --> 00:17:39,440
additional replicas that that's great

00:17:37,840 --> 00:17:41,600
uh but that's kind of like the obvious

00:17:39,440 --> 00:17:43,520
benefit here

00:17:41,600 --> 00:17:45,200
some other benefits of having these

00:17:43,520 --> 00:17:48,320
replicas is that you can

00:17:45,200 --> 00:17:50,160
read from one of the replicas rather

00:17:48,320 --> 00:17:52,559
than having to read from the same node

00:17:50,160 --> 00:17:55,200
all of the time and it'll turn out that

00:17:52,559 --> 00:17:57,520
this is quite important

00:17:55,200 --> 00:17:59,760
so in cassandra we use this term quorum

00:17:57,520 --> 00:18:00,240
to refer to the number of replicas that

00:17:59,760 --> 00:18:02,880
must

00:18:00,240 --> 00:18:04,320
successfully execute some transaction in

00:18:02,880 --> 00:18:07,760
order for us to

00:18:04,320 --> 00:18:09,760
deem it successful so for example

00:18:07,760 --> 00:18:11,440
if you have let's say a replication

00:18:09,760 --> 00:18:14,480
factor of three

00:18:11,440 --> 00:18:16,160
a local quorum right level means that at

00:18:14,480 --> 00:18:17,520
least two of our replicas within our

00:18:16,160 --> 00:18:20,640
same data center

00:18:17,520 --> 00:18:24,400
must successfully commit

00:18:20,640 --> 00:18:26,960
this right and respond that it's been

00:18:24,400 --> 00:18:29,760
successful

00:18:26,960 --> 00:18:30,480
uh now we can dial back this quorum to

00:18:29,760 --> 00:18:32,240
like let's say

00:18:30,480 --> 00:18:33,919
one quorum where we only need one of the

00:18:32,240 --> 00:18:35,280
replicas to successfully commit their

00:18:33,919 --> 00:18:36,720
log so that's a lower latency

00:18:35,280 --> 00:18:39,039
transaction

00:18:36,720 --> 00:18:40,000
but it's a we're not getting as strong

00:18:39,039 --> 00:18:43,840
of a guarantee

00:18:40,000 --> 00:18:43,840
on persisting our data

00:18:45,520 --> 00:18:50,240
okay so how does this rel how do these

00:18:49,280 --> 00:18:53,600
two kind of combine

00:18:50,240 --> 00:18:55,760
well as i said i if you dial back the

00:18:53,600 --> 00:18:59,840
consistency requirements

00:18:55,760 --> 00:19:02,880
of your transactions then you can reduce

00:18:59,840 --> 00:19:04,160
the latency and if you need to dial up

00:19:02,880 --> 00:19:05,360
the consistency requirements of your

00:19:04,160 --> 00:19:06,799
transactions you're going to increase

00:19:05,360 --> 00:19:10,240
your latency

00:19:06,799 --> 00:19:12,720
and with cassandra the the dial

00:19:10,240 --> 00:19:14,480
we're dealing with here for consistency

00:19:12,720 --> 00:19:16,799
is the quorum the read in the right

00:19:14,480 --> 00:19:16,799
corner

00:19:17,360 --> 00:19:24,559
now for a uh strongly consistent

00:19:21,039 --> 00:19:26,960
uh or i should say as we've been using

00:19:24,559 --> 00:19:28,960
the term read after write consistency

00:19:26,960 --> 00:19:30,080
the requirement is that the size of your

00:19:28,960 --> 00:19:32,400
read quorum

00:19:30,080 --> 00:19:35,039
and the size of your right quorum are

00:19:32,400 --> 00:19:36,720
greater than the replication factor

00:19:35,039 --> 00:19:38,880
and typically the replication factor is

00:19:36,720 --> 00:19:41,360
an odd number i think by default we set

00:19:38,880 --> 00:19:41,360
it to three

00:19:42,400 --> 00:19:49,039
but five is a common one too

00:19:45,760 --> 00:19:50,840
okay so i assume let's assume

00:19:49,039 --> 00:19:52,400
for now we have an odd replication

00:19:50,840 --> 00:19:53,760
factor so

00:19:52,400 --> 00:19:56,080
how might we think about tuning our

00:19:53,760 --> 00:19:59,039
application

00:19:56,080 --> 00:20:01,039
well for the setting where the reads and

00:19:59,039 --> 00:20:02,480
the writes are about the same

00:20:01,039 --> 00:20:04,880
then it makes sense to have our read

00:20:02,480 --> 00:20:06,559
quorum and right quorum equal

00:20:04,880 --> 00:20:08,960
and a good value for that is the

00:20:06,559 --> 00:20:09,760
replication factor plus one divided by

00:20:08,960 --> 00:20:11,840
two

00:20:09,760 --> 00:20:13,760
so for a replication of three

00:20:11,840 --> 00:20:15,520
replication factor of three

00:20:13,760 --> 00:20:17,360
that gives us a read quorum of two and a

00:20:15,520 --> 00:20:19,039
right corner of two so that means for a

00:20:17,360 --> 00:20:20,559
successful read we need two out of the

00:20:19,039 --> 00:20:22,799
three to respond

00:20:20,559 --> 00:20:25,760
for a successful write we need two out

00:20:22,799 --> 00:20:25,760
of the three to respond

00:20:26,320 --> 00:20:30,080
now setting number two here where our

00:20:29,039 --> 00:20:33,679
number of reads

00:20:30,080 --> 00:20:36,400
is greatly is dramatically larger

00:20:33,679 --> 00:20:38,000
than the number of writes we have an

00:20:36,400 --> 00:20:39,840
interesting thing here we can set the

00:20:38,000 --> 00:20:41,760
read quorum to 1

00:20:39,840 --> 00:20:44,000
if we set the right quorum to the

00:20:41,760 --> 00:20:45,440
replication factor

00:20:44,000 --> 00:20:47,760
so let's think about this what we're

00:20:45,440 --> 00:20:50,559
saying is we're making rights

00:20:47,760 --> 00:20:52,559
more expensive and we're increasing the

00:20:50,559 --> 00:20:55,600
likelihood that our rights might fail

00:20:52,559 --> 00:20:58,159
if they can't reach a full quorum

00:20:55,600 --> 00:20:58,799
however for reads we can read from any

00:20:58,159 --> 00:21:00,880
node

00:20:58,799 --> 00:21:02,480
so we can can dramatically improve the

00:21:00,880 --> 00:21:04,240
response from our reads

00:21:02,480 --> 00:21:06,000
by basically just sending out the read

00:21:04,240 --> 00:21:07,679
request and whatever

00:21:06,000 --> 00:21:09,919
the first response is we go with that

00:21:07,679 --> 00:21:09,919
one

00:21:10,159 --> 00:21:14,000
now in the setting where rights greatly

00:21:12,080 --> 00:21:16,960
exceed reads

00:21:14,000 --> 00:21:17,679
this is a tricky one and it really is

00:21:16,960 --> 00:21:20,720
context

00:21:17,679 --> 00:21:22,480
dependent but the easiest thing is to

00:21:20,720 --> 00:21:24,880
just go with num number one

00:21:22,480 --> 00:21:27,200
so just set local quorum for reads and

00:21:24,880 --> 00:21:27,200
writes

00:21:29,280 --> 00:21:34,640
okay so uh when you submit a query

00:21:32,720 --> 00:21:35,760
to cassandra let's let's what is the

00:21:34,640 --> 00:21:39,440
path

00:21:35,760 --> 00:21:41,120
of that query so let's walk through this

00:21:39,440 --> 00:21:42,799
uh so we submit the query the first

00:21:41,120 --> 00:21:45,440
thing that happens is we hash our

00:21:42,799 --> 00:21:49,200
partition key of the query

00:21:45,440 --> 00:21:50,799
and that hash determines which partition

00:21:49,200 --> 00:21:52,640
our query is sent to and we can think of

00:21:50,799 --> 00:21:55,360
these partitions kind of like as hosts

00:21:52,640 --> 00:21:55,360
in our cluster

00:21:55,600 --> 00:21:59,520
within that partition the first thing

00:21:57,280 --> 00:22:01,440
that happens is we check the mem table

00:21:59,520 --> 00:22:03,120
do we know do we have this value in

00:22:01,440 --> 00:22:06,159
memory

00:22:03,120 --> 00:22:08,880
if the answer is yes then we return the

00:22:06,159 --> 00:22:10,720
response to the user and this is the

00:22:08,880 --> 00:22:14,000
best case scenario and in this case

00:22:10,720 --> 00:22:16,000
scenario for let's say like a

00:22:14,000 --> 00:22:17,840
a single quorum so we're only waiting

00:22:16,000 --> 00:22:19,520
for response from one node

00:22:17,840 --> 00:22:22,480
the performance here really is not much

00:22:19,520 --> 00:22:22,480
different from sql

00:22:23,600 --> 00:22:30,240
and by that i mean the request

00:22:27,440 --> 00:22:32,640
path is hit a remote server and that

00:22:30,240 --> 00:22:34,880
remote server

00:22:32,640 --> 00:22:37,280
checks an in-memory data structure

00:22:34,880 --> 00:22:39,280
returns a response

00:22:37,280 --> 00:22:41,840
or similarly maybe we have to hit the

00:22:39,280 --> 00:22:43,919
file so we have to go to disk

00:22:41,840 --> 00:22:46,559
and the first file contains the the key

00:22:43,919 --> 00:22:49,840
we're looking for

00:22:46,559 --> 00:22:52,400
the problem here is if we don't

00:22:49,840 --> 00:22:53,600
find our key in the mem table or the

00:22:52,400 --> 00:22:55,679
first file we check

00:22:53,600 --> 00:22:57,280
now where there's some additional

00:22:55,679 --> 00:23:00,480
overhead compared to

00:22:57,280 --> 00:23:02,080
a typical sql database and that is we

00:23:00,480 --> 00:23:03,280
have to start scanning each of these

00:23:02,080 --> 00:23:05,280
files

00:23:03,280 --> 00:23:06,400
although remember we're checking this

00:23:05,280 --> 00:23:08,480
bloom filter

00:23:06,400 --> 00:23:09,679
to see if the file might contain the key

00:23:08,480 --> 00:23:11,360
or not

00:23:09,679 --> 00:23:13,120
so that gives us a little bit of a speed

00:23:11,360 --> 00:23:15,520
up there but largely this is a slow

00:23:13,120 --> 00:23:15,520
process

00:23:20,880 --> 00:23:26,159
okay so there's a question we don't

00:23:22,720 --> 00:23:29,600
return a proposal that we don't return

00:23:26,159 --> 00:23:29,600
the data from the mem table

00:23:30,080 --> 00:23:34,720
i'm not sure if i understand the

00:23:32,000 --> 00:23:36,640
question so

00:23:34,720 --> 00:23:39,840
the mem table keeps the more recent

00:23:36,640 --> 00:23:39,840
versions of our data

00:23:40,480 --> 00:23:44,000
but maybe we can talk about this after

00:23:42,799 --> 00:23:48,480
this session

00:23:44,000 --> 00:23:52,559
i might not understand the question uh

00:23:48,480 --> 00:23:55,679
okay so this is a path for a query that

00:23:52,559 --> 00:23:55,679
hits a single partition

00:23:56,400 --> 00:24:00,400
the thing we really want to avoid though

00:23:59,360 --> 00:24:03,440
is having to hit

00:24:00,400 --> 00:24:08,640
multiple partitions

00:24:03,440 --> 00:24:11,840
and uh this can happen if if we

00:24:08,640 --> 00:24:14,000
don't structure our data model

00:24:11,840 --> 00:24:18,000
correctly or if we are don't think

00:24:14,000 --> 00:24:19,679
carefully about our queries

00:24:18,000 --> 00:24:21,120
the reason this is so bad i mean this

00:24:19,679 --> 00:24:23,120
hopefully is kind of intuitive

00:24:21,120 --> 00:24:24,159
is if we have to scan multiple

00:24:23,120 --> 00:24:25,520
partitions

00:24:24,159 --> 00:24:27,919
uh maybe we're doing some kind of range

00:24:25,520 --> 00:24:29,840
scan or something

00:24:27,919 --> 00:24:33,840
these this is multiple hosts we're

00:24:29,840 --> 00:24:33,840
enacting with multiple network calls

00:24:34,240 --> 00:24:37,600
and as the number of hosts increases the

00:24:36,320 --> 00:24:41,200
amount of overhead

00:24:37,600 --> 00:24:41,200
is going to increase for a given query

00:24:41,279 --> 00:24:45,200
okay so let's using all of this that

00:24:43,600 --> 00:24:47,040
we've just learned let's see if we can

00:24:45,200 --> 00:24:48,880
put this together

00:24:47,040 --> 00:24:52,000
[Music]

00:24:48,880 --> 00:24:52,000
in a couple examples

00:24:53,679 --> 00:24:56,320
okay so

00:24:57,360 --> 00:25:01,840
we're using the partition key to

00:24:58,880 --> 00:25:04,400
determine the partition

00:25:01,840 --> 00:25:06,159
if we can't do that so if if when we're

00:25:04,400 --> 00:25:07,919
forming our query

00:25:06,159 --> 00:25:09,440
if we don't have enough information to

00:25:07,919 --> 00:25:11,279
go to our precise

00:25:09,440 --> 00:25:14,000
partition then we're going to have to go

00:25:11,279 --> 00:25:16,480
to multiple partitions

00:25:14,000 --> 00:25:18,080
this is slow and this is why if you look

00:25:16,480 --> 00:25:21,919
at like any documentation

00:25:18,080 --> 00:25:25,120
on data stacks or like

00:25:21,919 --> 00:25:28,159
just googling data modeling and

00:25:25,120 --> 00:25:28,960
cassandra they always say start with the

00:25:28,159 --> 00:25:31,520
query

00:25:28,960 --> 00:25:32,799
and let that drive your data model so

00:25:31,520 --> 00:25:34,559
you want to make sure

00:25:32,799 --> 00:25:36,559
at the application level when you're

00:25:34,559 --> 00:25:38,240
when you're designing your application

00:25:36,559 --> 00:25:40,000
and how you want to lay out data in

00:25:38,240 --> 00:25:41,840
cassandra

00:25:40,000 --> 00:25:43,279
you think like what data do i have

00:25:41,840 --> 00:25:45,840
access to

00:25:43,279 --> 00:25:47,919
at the application level and how can i

00:25:45,840 --> 00:25:49,520
use that data to generate my partition

00:25:47,919 --> 00:25:52,240
key and from that partition key get the

00:25:49,520 --> 00:25:52,240
data i want

00:25:53,120 --> 00:25:56,640
okay so this example is taken from the

00:25:55,760 --> 00:25:58,880
original

00:25:56,640 --> 00:26:01,360
cassandra paper published by some

00:25:58,880 --> 00:26:03,520
engineers at facebook

00:26:01,360 --> 00:26:06,320
now i've got here in red this is

00:26:03,520 --> 00:26:09,360
deprecated so the

00:26:06,320 --> 00:26:13,360
this example uses the

00:26:09,360 --> 00:26:15,760
an old uh version of cassandra

00:26:13,360 --> 00:26:16,400
and so it has some things that have

00:26:15,760 --> 00:26:19,520
changed

00:26:16,400 --> 00:26:21,360
since then so

00:26:19,520 --> 00:26:23,120
i just want to make this very clear do

00:26:21,360 --> 00:26:24,640
not take this first example as the way

00:26:23,120 --> 00:26:27,679
you should do things

00:26:24,640 --> 00:26:28,960
the reason i'm sharing this example is

00:26:27,679 --> 00:26:30,559
because

00:26:28,960 --> 00:26:32,320
this is just one of those things that i

00:26:30,559 --> 00:26:33,200
i when you you read it and it just

00:26:32,320 --> 00:26:36,159
changes your outlook

00:26:33,200 --> 00:26:36,640
on problem solving i thought this was

00:26:36,159 --> 00:26:40,799
such

00:26:36,640 --> 00:26:43,520
a clever solution to this problem

00:26:40,799 --> 00:26:44,720
it was very elegant and very much like

00:26:43,520 --> 00:26:46,000
outside of the box i

00:26:44,720 --> 00:26:48,240
i don't know that i would have thought

00:26:46,000 --> 00:26:50,000
of this approach

00:26:48,240 --> 00:26:52,640
so i think there's a lot of value in at

00:26:50,000 --> 00:26:56,799
least discussing it

00:26:52,640 --> 00:26:59,120
just to kind of illustrate like that the

00:26:56,799 --> 00:27:00,240
a way in which to design your data

00:26:59,120 --> 00:27:03,039
scheme is here

00:27:00,240 --> 00:27:03,760
uh is very different than how you might

00:27:03,039 --> 00:27:09,039
think through it

00:27:03,760 --> 00:27:11,679
in a relational manner okay so

00:27:09,039 --> 00:27:14,320
in in the cassandra paper they give one

00:27:11,679 --> 00:27:17,600
of the examples of

00:27:14,320 --> 00:27:19,360
searching your chat history

00:27:17,600 --> 00:27:20,799
now we have a requirement you only want

00:27:19,360 --> 00:27:22,080
to be able to search your own chat

00:27:20,799 --> 00:27:25,039
history

00:27:22,080 --> 00:27:28,000
that's kind of a given and we know that

00:27:25,039 --> 00:27:29,600
when the user performs a search

00:27:28,000 --> 00:27:31,520
we're going to know their id so we

00:27:29,600 --> 00:27:33,840
certainly have a user id at the

00:27:31,520 --> 00:27:36,320
application

00:27:33,840 --> 00:27:37,760
now here's where things get really cool

00:27:36,320 --> 00:27:39,279
in this example so

00:27:37,760 --> 00:27:41,200
uh if you look through like release

00:27:39,279 --> 00:27:43,120
notes of older versions of cassandra you

00:27:41,200 --> 00:27:44,720
can see there's a release

00:27:43,120 --> 00:27:46,640
i forget which one off the top my head

00:27:44,720 --> 00:27:49,039
where it says the cassandra supports

00:27:46,640 --> 00:27:53,360
around 2 billion columns

00:27:49,039 --> 00:27:56,320
now modern cassandra they don't

00:27:53,360 --> 00:27:58,320
support as many columns and the

00:27:56,320 --> 00:28:00,799
recommendation is to

00:27:58,320 --> 00:28:04,320
not use like very wide rows so don't

00:28:00,799 --> 00:28:04,320
have huge amounts of columns

00:28:04,480 --> 00:28:08,640
but initially that was not the case so

00:28:07,039 --> 00:28:10,720
we have a cassandra that supports around

00:28:08,640 --> 00:28:12,880
2 billion columns

00:28:10,720 --> 00:28:14,480
and if we look at like a typical english

00:28:12,880 --> 00:28:17,919
dictionary there's about 500

00:28:14,480 --> 00:28:18,720
000 words so we can support way more

00:28:17,919 --> 00:28:22,159
columns

00:28:18,720 --> 00:28:25,440
than we have words in the dictionary

00:28:22,159 --> 00:28:29,120
and what they

00:28:25,440 --> 00:28:32,480
did at least initially was

00:28:29,120 --> 00:28:33,039
map the words to these like super

00:28:32,480 --> 00:28:35,440
columns

00:28:33,039 --> 00:28:35,440
call them

00:28:36,159 --> 00:28:39,760
so words of the english language that is

00:28:38,159 --> 00:28:41,039
so what are

00:28:39,760 --> 00:28:42,559
typical words that people are going to

00:28:41,039 --> 00:28:43,039
be searching or we would want to index

00:28:42,559 --> 00:28:46,159
on

00:28:43,039 --> 00:28:48,320
map those to columns in our database

00:28:46,159 --> 00:28:50,159
now let's think through a query so a

00:28:48,320 --> 00:28:54,080
user types in

00:28:50,159 --> 00:28:56,799
i don't know scared cats or something

00:28:54,080 --> 00:28:58,480
in in their search bar so we we want

00:28:56,799 --> 00:29:00,399
something with the word scare

00:28:58,480 --> 00:29:01,840
and cat those are let's say the two

00:29:00,399 --> 00:29:04,880
terms we're going to search on

00:29:01,840 --> 00:29:05,760
and we have a user id so they take those

00:29:04,880 --> 00:29:07,760
two terms

00:29:05,760 --> 00:29:08,880
and they map those to column names they

00:29:07,760 --> 00:29:11,200
have a user name

00:29:08,880 --> 00:29:13,360
so that can give us a row and then for

00:29:11,200 --> 00:29:17,760
those column families we can look at

00:29:13,360 --> 00:29:21,039
message ids as the corresponding columns

00:29:17,760 --> 00:29:23,120
to me like that that just like was

00:29:21,039 --> 00:29:24,559
very clever in my opinion now maybe you

00:29:23,120 --> 00:29:25,679
are can argue like well there's better

00:29:24,559 --> 00:29:28,320
ways to do this

00:29:25,679 --> 00:29:30,399
sure but that is a very cool and clever

00:29:28,320 --> 00:29:32,799
solution to this problem

00:29:30,399 --> 00:29:34,799
and perform it it took advantage of how

00:29:32,799 --> 00:29:40,159
cassandra was designed at the time

00:29:34,799 --> 00:29:42,480
i gave him a very performant solution

00:29:40,159 --> 00:29:42,480
okay

00:29:44,480 --> 00:29:48,799
so now i said don't don't use that

00:29:47,840 --> 00:29:51,120
approach because that

00:29:48,799 --> 00:29:53,360
is based on an old version of cassandra

00:29:51,120 --> 00:29:56,240
things have changed since then

00:29:53,360 --> 00:29:58,080
so let's think through uh using what

00:29:56,240 --> 00:30:01,200
we've discussed so far

00:29:58,080 --> 00:30:02,240
how we might implement a similar search

00:30:01,200 --> 00:30:05,679
process

00:30:02,240 --> 00:30:08,399
with a more modern cassandra however i

00:30:05,679 --> 00:30:11,520
want to caveat this with

00:30:08,399 --> 00:30:13,919
maybe the best approach here is to

00:30:11,520 --> 00:30:15,520
consult some information retrieval texts

00:30:13,919 --> 00:30:18,080
and

00:30:15,520 --> 00:30:18,640
think about it from an ir perspective

00:30:18,080 --> 00:30:21,440
rather than

00:30:18,640 --> 00:30:22,559
forcing the usage of cassandra

00:30:21,440 --> 00:30:24,240
additionally

00:30:22,559 --> 00:30:26,159
the solution we come up with may not be

00:30:24,240 --> 00:30:29,120
the most optimal but the point here

00:30:26,159 --> 00:30:30,799
really is the process the journey we go

00:30:29,120 --> 00:30:34,000
to to arrive at our solution

00:30:30,799 --> 00:30:37,200
not so much the solution itself

00:30:34,000 --> 00:30:39,600
my hope is that after this talk you're

00:30:37,200 --> 00:30:41,360
better equipped to kind of think through

00:30:39,600 --> 00:30:44,799
how should we structure

00:30:41,360 --> 00:30:46,880
our data in cassandra so as to

00:30:44,799 --> 00:30:50,240
get better performance similarly how

00:30:46,880 --> 00:30:54,720
should we tune consistency requirements

00:30:50,240 --> 00:30:56,399
okay so how do we do this

00:30:54,720 --> 00:30:58,960
first things first what data do we have

00:30:56,399 --> 00:31:02,640
on the application side

00:30:58,960 --> 00:31:06,080
uh we're gonna have a user id

00:31:02,640 --> 00:31:06,080
and we're gonna have the query terms

00:31:07,279 --> 00:31:11,120
uh oh yeah so as i said in the previous

00:31:10,159 --> 00:31:12,880
slide

00:31:11,120 --> 00:31:14,159
consideration one maybe don't use

00:31:12,880 --> 00:31:16,320
cassandra for this but

00:31:14,159 --> 00:31:17,600
uh this is a talk on cassandra so we're

00:31:16,320 --> 00:31:19,919
gonna do it

00:31:17,600 --> 00:31:21,440
and as before we only want users to

00:31:19,919 --> 00:31:24,559
search their own messages that's

00:31:21,440 --> 00:31:26,960
i think kind of goes without saying

00:31:24,559 --> 00:31:28,480
now another thing here is we don't have

00:31:26,960 --> 00:31:31,120
to show the user everything

00:31:28,480 --> 00:31:33,039
right up front front um in another point

00:31:31,120 --> 00:31:36,080
we'll touch on in a slide or two

00:31:33,039 --> 00:31:40,240
is that users might have some of the

00:31:36,080 --> 00:31:40,240
messages already cached on their machine

00:31:41,360 --> 00:31:46,320
okay so naively what we might do is have

00:31:44,080 --> 00:31:47,519
a table that just stores all of our

00:31:46,320 --> 00:31:50,640
messages

00:31:47,519 --> 00:31:51,919
we look message up by message id and we

00:31:50,640 --> 00:31:57,600
have a user

00:31:51,919 --> 00:31:59,600
table so we can look up for a given user

00:31:57,600 --> 00:32:03,360
user information but if we want to query

00:31:59,600 --> 00:32:04,960
all messages from a user for search

00:32:03,360 --> 00:32:07,519
then we would say something like select

00:32:04,960 --> 00:32:09,360
all the messages from our messages table

00:32:07,519 --> 00:32:11,200
where the user id is equal to this

00:32:09,360 --> 00:32:12,960
searching user

00:32:11,200 --> 00:32:14,320
that gives us all messages and we can

00:32:12,960 --> 00:32:15,840
pipe that into spark

00:32:14,320 --> 00:32:18,240
and do some analytics on it maybe do

00:32:15,840 --> 00:32:21,039
some processing and this is

00:32:18,240 --> 00:32:22,720
very slow much too slow for what we want

00:32:21,039 --> 00:32:25,200
the problem here is

00:32:22,720 --> 00:32:28,640
with this approach when we say give us

00:32:25,200 --> 00:32:30,559
all messages for this specific user

00:32:28,640 --> 00:32:33,840
we are going to have to scan through all

00:32:30,559 --> 00:32:35,360
partitions of the messages table

00:32:33,840 --> 00:32:38,960
remember we're saying here that messages

00:32:35,360 --> 00:32:42,480
are partitioned on message id

00:32:38,960 --> 00:32:44,640
so all messages we're going to search

00:32:42,480 --> 00:32:46,000
through all partitions very slow

00:32:44,640 --> 00:32:47,919
now we might be able to structure things

00:32:46,000 --> 00:32:48,559
a little bit better to improve that

00:32:47,919 --> 00:32:51,760
scanning

00:32:48,559 --> 00:32:54,559
but largely this is not how we want to

00:32:51,760 --> 00:32:54,559
approach the problem

00:32:55,600 --> 00:33:00,080
okay so for a given query as i said we

00:32:58,240 --> 00:33:03,200
will have a list of query terms

00:33:00,080 --> 00:33:04,399
and a user id uh so

00:33:03,200 --> 00:33:06,480
if let's say we're searching for

00:33:04,399 --> 00:33:10,080
conversations that

00:33:06,480 --> 00:33:11,840
are about scared cats we might have

00:33:10,080 --> 00:33:13,600
the search terms would be scared cats

00:33:11,840 --> 00:33:17,200
and we might trim those down to

00:33:13,600 --> 00:33:17,200
scare and cat

00:33:19,360 --> 00:33:22,640
and the results we're going to return to

00:33:21,519 --> 00:33:24,720
the user

00:33:22,640 --> 00:33:26,399
should contain should should be all the

00:33:24,720 --> 00:33:28,159
messages that contain maybe one

00:33:26,399 --> 00:33:30,000
or two of these terms and i suppose we

00:33:28,159 --> 00:33:31,200
could rank the

00:33:30,000 --> 00:33:32,720
the higher the hit rate so the more

00:33:31,200 --> 00:33:35,600
terms are in a message maybe that ranks

00:33:32,720 --> 00:33:38,880
higher in the search rate

00:33:35,600 --> 00:33:41,919
so here's an idea what if we partition

00:33:38,880 --> 00:33:44,880
our data based on user id

00:33:41,919 --> 00:33:46,960
and query term and we cluster it based

00:33:44,880 --> 00:33:50,240
on query term

00:33:46,960 --> 00:33:53,600
so what does this mean this means

00:33:50,240 --> 00:33:55,039
for a given query for let's say for a

00:33:53,600 --> 00:33:58,399
given message

00:33:55,039 --> 00:34:02,399
uh the partition is determined

00:33:58,399 --> 00:34:04,880
by the user id and a query term

00:34:02,399 --> 00:34:06,000
and then we group all messages for a

00:34:04,880 --> 00:34:10,000
given user and query

00:34:06,000 --> 00:34:11,679
term together and uh

00:34:10,000 --> 00:34:13,520
that we can store there let's say like a

00:34:11,679 --> 00:34:17,280
message id

00:34:13,520 --> 00:34:17,839
now uh there's a few things here so one

00:34:17,280 --> 00:34:20,960
is

00:34:17,839 --> 00:34:22,800
we're replicating data all right

00:34:20,960 --> 00:34:24,399
and there's no sql world and it's

00:34:22,800 --> 00:34:26,879
particularly with cassandra and

00:34:24,399 --> 00:34:29,040
let's say probably most nosql databases

00:34:26,879 --> 00:34:30,960
this is not necessarily a bad thing but

00:34:29,040 --> 00:34:33,679
we do have to be careful

00:34:30,960 --> 00:34:35,760
in this specific case because we're

00:34:33,679 --> 00:34:36,879
replicating based on query terms there

00:34:35,760 --> 00:34:38,399
actually could be quite a bit of

00:34:36,879 --> 00:34:39,839
replication going on here

00:34:38,399 --> 00:34:41,919
so it's probably better to store the

00:34:39,839 --> 00:34:43,359
message id rather than the message body

00:34:41,919 --> 00:34:47,440
itself

00:34:43,359 --> 00:34:51,919
and why is that okay well remember

00:34:47,440 --> 00:34:54,879
the query here is based on the

00:34:51,919 --> 00:34:56,399
user query typed into the search bar so

00:34:54,879 --> 00:34:58,640
we don't need to do any post

00:34:56,399 --> 00:35:00,320
processing on the message body once we

00:34:58,640 --> 00:35:01,839
have that message

00:35:00,320 --> 00:35:04,000
in other words what this query is

00:35:01,839 --> 00:35:07,119
telling us is that this message id

00:35:04,000 --> 00:35:09,359
for this is associated with this user id

00:35:07,119 --> 00:35:12,480
and has this term in it so no additional

00:35:09,359 --> 00:35:12,480
processing necessary

00:35:13,599 --> 00:35:17,280
the advantage to this is that a given

00:35:15,520 --> 00:35:19,680
query gets us exactly to the right

00:35:17,280 --> 00:35:22,320
partition

00:35:19,680 --> 00:35:22,960
another advantage is we have separated

00:35:22,320 --> 00:35:26,160
our

00:35:22,960 --> 00:35:28,640
general like search query into terms so

00:35:26,160 --> 00:35:31,839
we can run those queries in parallel

00:35:28,640 --> 00:35:31,839
that'll give us a performance boost

00:35:33,200 --> 00:35:39,599
now there is a downside here

00:35:36,400 --> 00:35:42,800
and that is we are

00:35:39,599 --> 00:35:44,720
grouping based on query term and

00:35:42,800 --> 00:35:46,079
as with every language some words are

00:35:44,720 --> 00:35:48,960
more common than others

00:35:46,079 --> 00:35:49,599
so this can do if we're not careful this

00:35:48,960 --> 00:35:52,720
can

00:35:49,599 --> 00:35:55,599
create some hot spots in our database

00:35:52,720 --> 00:35:56,880
as an example the word the is extremely

00:35:55,599 --> 00:35:58,880
common that's probably going to show up

00:35:56,880 --> 00:36:01,040
in every chat message

00:35:58,880 --> 00:36:03,599
that would definitely create a hot spot

00:36:01,040 --> 00:36:05,359
in the database however

00:36:03,599 --> 00:36:07,920
the word the doesn't really contain much

00:36:05,359 --> 00:36:07,920
information

00:36:10,480 --> 00:36:14,000
oh an excellent point here that some

00:36:12,320 --> 00:36:14,560
some users like bots would have tons of

00:36:14,000 --> 00:36:17,280
messages

00:36:14,560 --> 00:36:19,440
yes and uh in that setting i would i

00:36:17,280 --> 00:36:22,880
would go so far as to say maybe

00:36:19,440 --> 00:36:24,720
we have some analysis on uh

00:36:22,880 --> 00:36:26,320
are these messages bot generated and how

00:36:24,720 --> 00:36:29,200
we want to handle that that's an

00:36:26,320 --> 00:36:29,200
excellent observation

00:36:32,960 --> 00:36:36,400
so with respect to the more frequent

00:36:35,040 --> 00:36:39,119
word usage

00:36:36,400 --> 00:36:40,000
as i was saying the word the uh is very

00:36:39,119 --> 00:36:41,680
common

00:36:40,000 --> 00:36:43,760
on the other hand remember the ultimate

00:36:41,680 --> 00:36:45,839
goal here is to

00:36:43,760 --> 00:36:48,000
take a search query from the user and

00:36:45,839 --> 00:36:50,880
convert that into messages

00:36:48,000 --> 00:36:52,240
so if we're searching on the word the

00:36:50,880 --> 00:36:54,000
it's probably going to give us every

00:36:52,240 --> 00:36:56,880
message of that user and that's not

00:36:54,000 --> 00:36:57,760
very useful in other words what we might

00:36:56,880 --> 00:37:00,400
say is

00:36:57,760 --> 00:37:01,920
the term the does not contain a lot of

00:37:00,400 --> 00:37:03,440
information it doesn't help us narrow

00:37:01,920 --> 00:37:05,440
down our search

00:37:03,440 --> 00:37:06,720
so some of these very frequent words can

00:37:05,440 --> 00:37:09,760
probably be filtered out

00:37:06,720 --> 00:37:11,599
things like the a i we probably don't

00:37:09,760 --> 00:37:14,160
need to include all that

00:37:11,599 --> 00:37:15,760
but this is certainly a downside to this

00:37:14,160 --> 00:37:18,720
approach it's something to be aware of

00:37:15,760 --> 00:37:18,720
watch for hot spots

00:37:19,119 --> 00:37:22,640
okay so i think that's like it's pretty

00:37:21,119 --> 00:37:24,240
interesting on its own just thinking

00:37:22,640 --> 00:37:25,760
through that problem i i certainly when

00:37:24,240 --> 00:37:29,040
i was preparing this talk i had a lot of

00:37:25,760 --> 00:37:30,240
fun thinking about that but uh we can

00:37:29,040 --> 00:37:33,680
dig in even more

00:37:30,240 --> 00:37:35,280
and that is thinking about consistency

00:37:33,680 --> 00:37:36,800
so how should we think about the

00:37:35,280 --> 00:37:40,560
consistency of our

00:37:36,800 --> 00:37:42,079
application here or of of the database

00:37:40,560 --> 00:37:44,800
well one thing one thing is for sure we

00:37:42,079 --> 00:37:46,320
don't want to lose messages

00:37:44,800 --> 00:37:48,160
i think users would generally be pretty

00:37:46,320 --> 00:37:49,520
upset if their chat messages were

00:37:48,160 --> 00:37:51,200
randomly getting deleted

00:37:49,520 --> 00:37:52,800
similarly like if you're a google and

00:37:51,200 --> 00:37:54,720
you're providing email and emails are

00:37:52,800 --> 00:37:58,079
starting to get randomly get deleted

00:37:54,720 --> 00:38:00,480
that's uh not good right but

00:37:58,079 --> 00:38:01,599
the read operation here so search we

00:38:00,480 --> 00:38:04,000
have two

00:38:01,599 --> 00:38:05,599
important things one is search is pretty

00:38:04,000 --> 00:38:08,720
infrequent operation

00:38:05,599 --> 00:38:11,200
right like certainly like with you know

00:38:08,720 --> 00:38:13,280
my email clients in my search clients

00:38:11,200 --> 00:38:16,160
i am rarely searching so this is a low

00:38:13,280 --> 00:38:18,400
frequency operation

00:38:16,160 --> 00:38:20,079
two i don't expect this to be

00:38:18,400 --> 00:38:21,599
instantaneous although the faster it is

00:38:20,079 --> 00:38:23,280
the greater like you know i would love

00:38:21,599 --> 00:38:25,040
for it to be instantaneous but

00:38:23,280 --> 00:38:26,560
i think users generally expect a little

00:38:25,040 --> 00:38:29,440
bit of a delay in

00:38:26,560 --> 00:38:30,560
a search query but lastly and most

00:38:29,440 --> 00:38:32,800
importantly

00:38:30,560 --> 00:38:34,880
is that the search does not need to

00:38:32,800 --> 00:38:37,280
return the most recently written

00:38:34,880 --> 00:38:37,280
data

00:38:38,160 --> 00:38:45,680
this is particularly true with chat

00:38:42,240 --> 00:38:47,280
so think of uh you're a user on facebook

00:38:45,680 --> 00:38:50,240
and you're trying to

00:38:47,280 --> 00:38:53,520
look up all messages that talk about

00:38:50,240 --> 00:38:55,920
scared cats or whatever

00:38:53,520 --> 00:38:57,440
uh you're probably not looking for the

00:38:55,920 --> 00:38:59,599
message you just sent to your friend

00:38:57,440 --> 00:39:01,440
right or your most recent messages

00:38:59,599 --> 00:39:03,680
you're probably not looking for the one

00:39:01,440 --> 00:39:05,680
you just hit enter on

00:39:03,680 --> 00:39:07,280
typically people go to a search like a

00:39:05,680 --> 00:39:10,640
chat search just search

00:39:07,280 --> 00:39:11,119
historical messages so in because of

00:39:10,640 --> 00:39:14,079
this

00:39:11,119 --> 00:39:15,040
context here this search context we can

00:39:14,079 --> 00:39:18,640
get away with

00:39:15,040 --> 00:39:22,240
not showing the most recent rights

00:39:18,640 --> 00:39:24,240
to this user's messages

00:39:22,240 --> 00:39:25,599
so how would we structure this well our

00:39:24,240 --> 00:39:28,480
rights should be

00:39:25,599 --> 00:39:30,960
like local quorum is probably good we uh

00:39:28,480 --> 00:39:33,839
local quorum is probably good enough

00:39:30,960 --> 00:39:35,760
but if we're um it may be full quorum uh

00:39:33,839 --> 00:39:39,040
if we want to be particularly

00:39:35,760 --> 00:39:40,000
cautious and that's fine there's nothing

00:39:39,040 --> 00:39:42,400
surprising there

00:39:40,000 --> 00:39:43,119
but since we're okay with stale data we

00:39:42,400 --> 00:39:45,280
can dial

00:39:43,119 --> 00:39:46,720
down our read consistency our read

00:39:45,280 --> 00:39:48,720
quorum to one

00:39:46,720 --> 00:39:49,760
and say we're okay with any response we

00:39:48,720 --> 00:39:51,280
get back

00:39:49,760 --> 00:39:54,640
that will dramatically improve the

00:39:51,280 --> 00:39:54,640
latency on our reads

00:39:55,680 --> 00:40:00,720
uh i just want to hammer this point in

00:39:58,400 --> 00:40:01,440
because in our application context we

00:40:00,720 --> 00:40:03,920
know

00:40:01,440 --> 00:40:05,920
we don't need the most recent data we

00:40:03,920 --> 00:40:07,599
can improve our performance by dialing

00:40:05,920 --> 00:40:09,200
down the consistency on our reads

00:40:07,599 --> 00:40:10,960
it's that's it's a very important

00:40:09,200 --> 00:40:14,000
takeaway

00:40:10,960 --> 00:40:15,920
i think there's probably uh

00:40:14,000 --> 00:40:17,680
this kind of like default setting for

00:40:15,920 --> 00:40:19,760
most people where we think like oh we

00:40:17,680 --> 00:40:21,920
can't have eventual consistency we need

00:40:19,760 --> 00:40:24,160
we always need to use local quorum or

00:40:21,920 --> 00:40:26,240
full quorum for our reads or rights

00:40:24,160 --> 00:40:27,680
that's not always the case you'd be

00:40:26,240 --> 00:40:30,079
surprised really if you if you give it

00:40:27,680 --> 00:40:32,400
some careful thought

00:40:30,079 --> 00:40:34,319
on when you really need that strong

00:40:32,400 --> 00:40:36,640
consistency it's it's not as often as

00:40:34,319 --> 00:40:40,160
you might think

00:40:36,640 --> 00:40:40,160
okay so what about some takeaways

00:40:40,240 --> 00:40:44,079
most importantly uh maybe i shouldn't

00:40:42,640 --> 00:40:45,680
say most importantly but

00:40:44,079 --> 00:40:47,040
certainly very important understand the

00:40:45,680 --> 00:40:49,520
consistency requirements of your

00:40:47,040 --> 00:40:51,680
application

00:40:49,520 --> 00:40:53,359
if you need strong consistency or this

00:40:51,680 --> 00:40:54,640
read after right consistency that

00:40:53,359 --> 00:40:55,440
there's nothing wrong with that that's

00:40:54,640 --> 00:40:56,880
great

00:40:55,440 --> 00:40:59,520
there are a lot of settings where that

00:40:56,880 --> 00:41:01,200
is required but if you can get away with

00:40:59,520 --> 00:41:03,280
reduced consistency

00:41:01,200 --> 00:41:04,640
at the application level uh you can

00:41:03,280 --> 00:41:06,880
really get some performance improvements

00:41:04,640 --> 00:41:08,880
from that

00:41:06,880 --> 00:41:10,160
understanding your read and write load

00:41:08,880 --> 00:41:13,119
is also very important

00:41:10,160 --> 00:41:14,560
uh for tuning your consistency i would

00:41:13,119 --> 00:41:16,640
argue kind of like in general if you're

00:41:14,560 --> 00:41:18,000
building a distributed system this is

00:41:16,640 --> 00:41:19,520
one of like the first steps you need to

00:41:18,000 --> 00:41:21,839
understand your traffic your read and

00:41:19,520 --> 00:41:21,839
write traffic

00:41:22,240 --> 00:41:26,240
but in particular with cassandra this

00:41:24,720 --> 00:41:30,319
can kind of dictate how you

00:41:26,240 --> 00:41:30,319
tune your read and write quorums

00:41:31,359 --> 00:41:35,280
i'm sure like this has been pounded into

00:41:33,280 --> 00:41:37,920
all of us at infin item

00:41:35,280 --> 00:41:39,520
but start with the query and use that to

00:41:37,920 --> 00:41:41,760
guide your data model

00:41:39,520 --> 00:41:43,040
so it in the example we just went

00:41:41,760 --> 00:41:46,560
through

00:41:43,040 --> 00:41:46,880
we started with uh what data will we

00:41:46,560 --> 00:41:49,200
have

00:41:46,880 --> 00:41:50,800
at the application and how can we use

00:41:49,200 --> 00:41:52,560
that to structure our query

00:41:50,800 --> 00:41:55,920
to give us the data we want and then

00:41:52,560 --> 00:41:55,920
from there we had our data model

00:41:57,280 --> 00:42:03,359
and as we noted one

00:42:00,960 --> 00:42:05,680
key thing when you're running a query is

00:42:03,359 --> 00:42:07,280
you want to avoid hitting

00:42:05,680 --> 00:42:09,680
multiple partitions if you can hit a

00:42:07,280 --> 00:42:11,280
single partition you're golden

00:42:09,680 --> 00:42:13,520
and maybe i shouldn't say that but i

00:42:11,280 --> 00:42:16,800
mean that's like the ideal setting right

00:42:13,520 --> 00:42:19,040
in a single partition do not scan

00:42:16,800 --> 00:42:21,119
over multiple partitions if you can help

00:42:19,040 --> 00:42:21,119
it

00:42:21,760 --> 00:42:25,119
as we noted in the example watch out for

00:42:23,760 --> 00:42:27,599
hot spots and

00:42:25,119 --> 00:42:29,119
if you can structure your data so that

00:42:27,599 --> 00:42:33,680
it's evenly spread

00:42:29,119 --> 00:42:33,680
across partitions hot spots

00:42:33,760 --> 00:42:37,920
can be problematic especially if they're

00:42:35,839 --> 00:42:41,119
generated based on like popularity

00:42:37,920 --> 00:42:42,720
so if we have for example a hotspot

00:42:41,119 --> 00:42:44,800
based on word frequency

00:42:42,720 --> 00:42:46,000
and every search is containing that

00:42:44,800 --> 00:42:47,280
popular word

00:42:46,000 --> 00:42:49,440
then we're going to cause a lot of

00:42:47,280 --> 00:42:51,839
congestion when we're doing a read

00:42:49,440 --> 00:42:54,240
operation

00:42:51,839 --> 00:42:56,079
and that's it for this talk so i think

00:42:54,240 --> 00:42:59,280
we've got a few minutes left

00:42:56,079 --> 00:43:13,839
so if anyone has any questions um now's

00:42:59,280 --> 00:43:13,839
the time to ask them

00:43:16,480 --> 00:43:23,760
uh yes okay so

00:43:19,760 --> 00:43:25,680
uh lacks because

00:43:23,760 --> 00:43:28,319
excellent observation yes you are

00:43:25,680 --> 00:43:30,880
correct the the mem table

00:43:28,319 --> 00:43:32,640
may not contain all of the information

00:43:30,880 --> 00:43:34,319
we need to return i i see what you're

00:43:32,640 --> 00:43:37,119
getting at with your initial question

00:43:34,319 --> 00:43:38,240
yes that that is an excellent

00:43:37,119 --> 00:43:41,839
observation

00:43:38,240 --> 00:43:42,240
uh yeah very good so the the question

00:43:41,839 --> 00:43:44,079
was

00:43:42,240 --> 00:43:46,000
uh initially earlier in the talk i

00:43:44,079 --> 00:43:48,079
mentioned if we hit the mem table we get

00:43:46,000 --> 00:43:51,119
the value we return it

00:43:48,079 --> 00:43:54,000
uh it's not really correct

00:43:51,119 --> 00:43:55,280
um the mem table will contain like some

00:43:54,000 --> 00:43:58,319
partial information

00:43:55,280 --> 00:44:00,960
we still will have to get any

00:43:58,319 --> 00:44:02,960
information that's missing from disk so

00:44:00,960 --> 00:44:06,160
that will

00:44:02,960 --> 00:44:09,839
require a scan from disk which

00:44:06,160 --> 00:44:09,839
is slow but uh

00:44:09,920 --> 00:44:15,839
i would argue it's not materially slower

00:44:12,800 --> 00:44:23,839
than hitting a sql database

00:44:15,839 --> 00:44:23,839
but that's a very good observation yeah

00:44:27,280 --> 00:44:31,040
all right well thank you everyone for

00:44:29,520 --> 00:44:32,240
joining in um

00:44:31,040 --> 00:44:37,839
i'll stick around a little longer if

00:44:32,240 --> 00:44:37,839
there are any other questions

00:44:38,960 --> 00:44:42,079
all right pavel yeah

00:44:42,400 --> 00:44:45,520
excellent uh point yeah it would be

00:44:44,400 --> 00:44:47,760
interesting to look at different

00:44:45,520 --> 00:44:51,839
compaction strategies and how that can

00:44:47,760 --> 00:44:51,839
impact things

00:44:54,079 --> 00:44:58,640
ah kai okay so kai asked how would you

00:44:56,240 --> 00:45:01,359
deal with hot partitions

00:44:58,640 --> 00:45:03,359
uh that's hard to say in the general

00:45:01,359 --> 00:45:05,200
sense

00:45:03,359 --> 00:45:07,200
it really i think kind of depends on the

00:45:05,200 --> 00:45:09,359
problem

00:45:07,200 --> 00:45:12,720
so for i'll just speak to the example i

00:45:09,359 --> 00:45:12,720
gave where we're doing a search

00:45:12,800 --> 00:45:21,839
on message messages or indexing messages

00:45:18,720 --> 00:45:23,280
uh yeah so

00:45:21,839 --> 00:45:25,359
i would probably spend some time

00:45:23,280 --> 00:45:27,599
analyzing like

00:45:25,359 --> 00:45:30,480
what makes an effective query and is

00:45:27,599 --> 00:45:34,720
there any way we can reduce

00:45:30,480 --> 00:45:36,720
the uh amount of noise in our queries so

00:45:34,720 --> 00:45:39,200
like for example removing the word the

00:45:36,720 --> 00:45:40,560
from queries that helps reduce noise in

00:45:39,200 --> 00:45:43,280
the query itself

00:45:40,560 --> 00:45:45,280
but would also reduce hot spots in our

00:45:43,280 --> 00:45:49,359
cluster

00:45:45,280 --> 00:45:51,119
um and for your specific case here

00:45:49,359 --> 00:45:53,280
the the simplest thing that comes to

00:45:51,119 --> 00:45:56,319
mind is

00:45:53,280 --> 00:45:59,599
um moving

00:45:56,319 --> 00:46:02,640
whatever whatever is specific about the

00:45:59,599 --> 00:46:05,839
data that's causing that hotspot

00:46:02,640 --> 00:46:09,599
moving that field around

00:46:05,839 --> 00:46:10,160
uh so that the data is now stored on

00:46:09,599 --> 00:46:12,839
different

00:46:10,160 --> 00:46:14,319
partitions so what i mean by that is for

00:46:12,839 --> 00:46:17,599
example um

00:46:14,319 --> 00:46:20,880
in the query that the met the query word

00:46:17,599 --> 00:46:25,680
case if we were to move the word to

00:46:20,880 --> 00:46:27,280
like a more part of the partition id

00:46:25,680 --> 00:46:29,520
then we're getting more spread across

00:46:27,280 --> 00:46:31,920
the cluster rather than what we were

00:46:29,520 --> 00:46:34,800
actually doing

00:46:31,920 --> 00:46:37,119
well that's that's the opposite of what

00:46:34,800 --> 00:46:37,119
we want

00:46:37,520 --> 00:46:40,880
in the search case here i think the

00:46:39,520 --> 00:46:43,839
simplest solution is just trying to

00:46:40,880 --> 00:46:45,200
eliminate that word somehow

00:46:43,839 --> 00:46:47,520
but yeah that's a very interesting

00:46:45,200 --> 00:46:47,520
question

00:46:49,359 --> 00:46:56,240
and edward says

00:46:52,400 --> 00:46:58,160
start with query oh and that's

00:46:56,240 --> 00:46:59,920
done for relational databases too yeah i

00:46:58,160 --> 00:47:02,640
think it's very powerful i'll have to

00:46:59,920 --> 00:47:02,640
read through this

00:47:05,920 --> 00:47:11,839
oh very cool link hey thanks for sharing

00:47:07,839 --> 00:47:11,839
that edward that's a very cool link

00:47:33,680 --> 00:47:37,760
okay raymond says let's see batch

00:47:35,839 --> 00:47:39,520
workloads with queries

00:47:37,760 --> 00:47:41,839
that hit multiple partitions from

00:47:39,520 --> 00:47:43,839
different tables

00:47:41,839 --> 00:47:45,920
but with the same partition key so that

00:47:43,839 --> 00:47:48,240
the partitions are still on just one

00:47:45,920 --> 00:47:48,240
node

00:47:51,440 --> 00:47:55,359
so i don't have any experience in this

00:47:52,960 --> 00:47:58,559
specific setting

00:47:55,359 --> 00:48:01,280
but my question to this would be uh

00:47:58,559 --> 00:48:03,119
why do they have the same partition key

00:48:01,280 --> 00:48:06,319
that that's kind of the red flag to me

00:48:03,119 --> 00:48:10,319
how can we rework the partition key

00:48:06,319 --> 00:48:10,319
so that we can distribute this across

00:48:16,880 --> 00:48:21,520
yeah so that that's without knowing more

00:48:20,079 --> 00:48:22,559
details it's hard to say but that's

00:48:21,520 --> 00:48:25,599
that's what i would

00:48:22,559 --> 00:48:27,839
that would be what i was i'm looking at

00:48:25,599 --> 00:48:30,079
why why are they all the same partition

00:48:27,839 --> 00:48:30,079
key

00:48:31,119 --> 00:48:34,240
if you if you note from earlier in the

00:48:32,559 --> 00:48:37,040
talk we structured

00:48:34,240 --> 00:48:40,640
our data specifically so our queries

00:48:37,040 --> 00:48:40,640
would have different partition keys

00:48:42,319 --> 00:48:45,760
and i'll also add like these are all

00:48:43,839 --> 00:48:47,359
great questions

00:48:45,760 --> 00:48:49,119
i personally don't think there's none of

00:48:47,359 --> 00:48:51,040
this stuff is ever obvious it takes some

00:48:49,119 --> 00:48:54,160
time of some careful thinking

00:48:51,040 --> 00:48:56,079
of what makes the most sense uh thinking

00:48:54,160 --> 00:48:58,800
through different solutions how would

00:48:56,079 --> 00:49:03,839
the query be routed in the system yeah

00:48:58,800 --> 00:49:03,839
these are all really good questions

00:49:04,400 --> 00:49:08,960
all right um i don't know if

00:49:07,520 --> 00:49:10,720
if there's a limit to how long i can

00:49:08,960 --> 00:49:11,839
stay in here answering questions but

00:49:10,720 --> 00:49:14,319
it looks like questions are kind of

00:49:11,839 --> 00:49:16,800
dying down if if i haven't answered any

00:49:14,319 --> 00:49:19,040
questions or you want to talk offline

00:49:16,800 --> 00:49:22,319
i think i'm pretty easy to find online

00:49:19,040 --> 00:49:24,319
i've got a pretty unique last name

00:49:22,319 --> 00:49:25,760
and yeah you should be able to easily

00:49:24,319 --> 00:49:27,040
find me on linkedin or

00:49:25,760 --> 00:49:29,200
you could probably even guess my email

00:49:27,040 --> 00:49:30,880
address

00:49:29,200 --> 00:49:32,720
but yeah thanks everyone for attending

00:49:30,880 --> 00:49:45,839
and i think we'll

00:49:32,720 --> 00:49:45,839
close the session at this

00:50:01,520 --> 00:50:03,599

YouTube URL: https://www.youtube.com/watch?v=HpZ2z8oFQu0


