Title: Building Apache Cassandra 4.0: behind the scenes
Publication date: 2020-10-26
Playlist: ApacheCon @Home 2020: Cassandra
Description: 
	Building Apache Cassandra 4.0: behind the scenes
Dinesh Joshi

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Building a database is hard. Building a distributed database is harder. Building a distributed database that the industry relies on is even harder. Our goal to build Apache Cassandra 4.0 is to make it rock solid. In this talk, we go behind the scenes to show you how the Apache Cassandra community is building and testing Apache Cassandra 4.0 so that it is the most stable release ever!

Dinesh A. Joshi has been a professional Software Engineer for over a decade building highly scalable realtime Web Services and Distributed Streaming Data Processing Architectures serving over 1 billion devices. Dinesh is an active contributor to the Apache Cassandra codebase. He has a Masters degree in Computer Science (Distributed Systems & Databases) from Georgia Tech, Atlanta, USA.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:36,559 --> 00:00:45,840
hi everybody

00:00:37,440 --> 00:00:45,840
uh can can everyone listen hear me

00:00:46,719 --> 00:00:50,480
all right thank you so much all right i

00:00:49,520 --> 00:00:53,039
was just in

00:00:50,480 --> 00:00:54,320
a different uh presentation so uh sorry

00:00:53,039 --> 00:00:57,360
about the delay

00:00:54,320 --> 00:01:00,800
uh i'm gonna share my screen uh please

00:00:57,360 --> 00:01:00,800
let me know if you can see

00:01:01,840 --> 00:01:13,840
my screen

00:01:15,040 --> 00:01:19,439
i think it's wrong screen let me try

00:01:24,840 --> 00:01:27,840
again

00:01:30,799 --> 00:01:33,840
all right um

00:01:34,240 --> 00:01:39,600
is uh is my screen visible uh with the

00:01:37,439 --> 00:01:43,280
presentation

00:01:39,600 --> 00:01:45,520
okay cool thank you um

00:01:43,280 --> 00:01:46,560
so thank you for joining my session

00:01:45,520 --> 00:01:49,759
today

00:01:46,560 --> 00:01:52,320
um so my name is danesh joshi

00:01:49,759 --> 00:01:53,840
and i will be talking about building

00:01:52,320 --> 00:01:57,759
apache cassandra

00:01:53,840 --> 00:02:00,960
behind the scenes this is cassandra 4.0

00:01:57,759 --> 00:02:04,799
and a little bit about me

00:02:00,960 --> 00:02:07,280
uh before we get started i work at apple

00:02:04,799 --> 00:02:09,119
and i work on cassandra i'm also an

00:02:07,280 --> 00:02:12,000
apache cassandra committer

00:02:09,119 --> 00:02:12,879
been in the community for a while and my

00:02:12,000 --> 00:02:15,440
major

00:02:12,879 --> 00:02:16,800
current work in cassandra is related to

00:02:15,440 --> 00:02:19,200
cassandra 4.0

00:02:16,800 --> 00:02:20,959
although we've made certain bug fixes to

00:02:19,200 --> 00:02:24,879
3.0 as well

00:02:20,959 --> 00:02:28,879
but 4.0 is where i have contributed

00:02:24,879 --> 00:02:33,200
my maximum time so with that

00:02:28,879 --> 00:02:34,560
let's get started so um

00:02:33,200 --> 00:02:36,720
i'm going to talk about some of the

00:02:34,560 --> 00:02:38,560
industry trends first

00:02:36,720 --> 00:02:40,959
um we're going to talk a little bit

00:02:38,560 --> 00:02:43,920
about the history of cassandra

00:02:40,959 --> 00:02:44,800
and also the architecture uh we're going

00:02:43,920 --> 00:02:47,440
to talk about

00:02:44,800 --> 00:02:48,160
cassandra's internals a little bit and

00:02:47,440 --> 00:02:50,560
then

00:02:48,160 --> 00:02:51,680
talk about challenges in testing and

00:02:50,560 --> 00:02:55,120
validations

00:02:51,680 --> 00:02:58,720
and finally uh testing uh cassandra

00:02:55,120 --> 00:03:01,300
and what makes it very hard um and

00:02:58,720 --> 00:03:02,720
a summary so

00:03:01,300 --> 00:03:05,040
[Music]

00:03:02,720 --> 00:03:05,920
for those of you who are not uh familiar

00:03:05,040 --> 00:03:08,879
4.0

00:03:05,920 --> 00:03:09,280
is one of the first releases that has

00:03:08,879 --> 00:03:12,560
been

00:03:09,280 --> 00:03:15,200
um in the works for over two years now

00:03:12,560 --> 00:03:15,840
um and uh i want to add a little bit of

00:03:15,200 --> 00:03:19,040
context

00:03:15,840 --> 00:03:21,440
as to how 4.0

00:03:19,040 --> 00:03:23,360
is being built uh and what are the

00:03:21,440 --> 00:03:27,680
things that we are doing to ensure

00:03:23,360 --> 00:03:29,760
that this is a good stable release

00:03:27,680 --> 00:03:32,080
and as bug-free as possible in the

00:03:29,760 --> 00:03:36,080
cassandra community

00:03:32,080 --> 00:03:39,200
so uh can anybody guess what this

00:03:36,080 --> 00:03:39,200
chart represents

00:03:39,440 --> 00:03:43,680
you can type it in the chat what your

00:03:41,519 --> 00:03:46,159
theory is about this chart

00:03:43,680 --> 00:03:48,799
and i'm sure everybody is going to

00:03:46,159 --> 00:03:52,640
relate to this particular

00:03:48,799 --> 00:03:52,640
chart once i tell you what it is

00:03:56,720 --> 00:04:04,080
any guesses

00:04:00,000 --> 00:04:07,120
okay i'll just uh put a label on it

00:04:04,080 --> 00:04:11,120
uh this is the industry uh data growth

00:04:07,120 --> 00:04:14,159
trend um and uh basically the

00:04:11,120 --> 00:04:14,879
the industry which i'm talking about is

00:04:14,159 --> 00:04:17,120
is

00:04:14,879 --> 00:04:18,720
everybody that today is attending

00:04:17,120 --> 00:04:22,000
apachecon is working in

00:04:18,720 --> 00:04:22,800
uh basically the industry has

00:04:22,000 --> 00:04:25,680
experienced

00:04:22,800 --> 00:04:28,160
a lot of data growth over time and with

00:04:25,680 --> 00:04:29,759
covert 19 it's gotten even worse

00:04:28,160 --> 00:04:32,400
because everybody's working from home

00:04:29,759 --> 00:04:35,600
there's a lot more uh emphasis on

00:04:32,400 --> 00:04:37,600
remote working and and so

00:04:35,600 --> 00:04:38,639
the data growth in the industry is

00:04:37,600 --> 00:04:41,040
phenomenal

00:04:38,639 --> 00:04:42,479
and with this data growth the systems

00:04:41,040 --> 00:04:45,759
that store the data

00:04:42,479 --> 00:04:46,400
have also uh to they need to scale as

00:04:45,759 --> 00:04:50,479
well

00:04:46,400 --> 00:04:54,160
and uh there is an added emphasis on

00:04:50,479 --> 00:04:56,800
um the the quality of the of the

00:04:54,160 --> 00:04:58,639
storage systems as well as the speed and

00:04:56,800 --> 00:05:01,759
reliability of the storage systems

00:04:58,639 --> 00:05:04,160
so that's uh that's what our industry

00:05:01,759 --> 00:05:05,600
is experiencing at the moment and so

00:05:04,160 --> 00:05:09,199
cassandra is not immune to

00:05:05,600 --> 00:05:12,080
any of these uh industry trends as well

00:05:09,199 --> 00:05:12,479
and so uh with that said uh let's see

00:05:12,080 --> 00:05:15,039
what

00:05:12,479 --> 00:05:16,720
uh cassandra is looks like in the

00:05:15,039 --> 00:05:18,560
community

00:05:16,720 --> 00:05:20,000
so currently cassandra has a various

00:05:18,560 --> 00:05:22,400
releases that people use

00:05:20,000 --> 00:05:23,039
in production we have customer 2.x

00:05:22,400 --> 00:05:26,080
series

00:05:23,039 --> 00:05:27,919
which is stable and widely adapted um

00:05:26,080 --> 00:05:29,840
and then there is the cassandra 3.0

00:05:27,919 --> 00:05:33,120
series which is also stable

00:05:29,840 --> 00:05:36,720
and uh adopted in the industry

00:05:33,120 --> 00:05:37,759
and we have cassandra 3.11 which is also

00:05:36,720 --> 00:05:40,400
stable

00:05:37,759 --> 00:05:41,360
it has some performance improvements or

00:05:40,400 --> 00:05:44,320
3.0

00:05:41,360 --> 00:05:46,000
and it's it's also quite uh widely

00:05:44,320 --> 00:05:46,800
adopted so we have various releases of

00:05:46,000 --> 00:05:50,479
cassandra

00:05:46,800 --> 00:05:53,520
with some incremental benefits in the

00:05:50,479 --> 00:05:55,199
community and 4.0

00:05:53,520 --> 00:05:56,960
is the next unreleased version of

00:05:55,199 --> 00:05:59,199
cassandra that we are working on

00:05:56,960 --> 00:06:00,160
um as in the christian community is

00:05:59,199 --> 00:06:03,199
working on

00:06:00,160 --> 00:06:04,160
and this is the next uh release of

00:06:03,199 --> 00:06:06,960
cassandra

00:06:04,160 --> 00:06:07,600
and this particular release of cassandra

00:06:06,960 --> 00:06:10,080
is uh

00:06:07,600 --> 00:06:10,880
quite important because uh it's been in

00:06:10,080 --> 00:06:12,800
the works for

00:06:10,880 --> 00:06:14,560
quite quite a long time and also it

00:06:12,800 --> 00:06:18,560
brings in a lot of features

00:06:14,560 --> 00:06:21,039
uh to the table so

00:06:18,560 --> 00:06:22,240
uh these are if you if you look at

00:06:21,039 --> 00:06:24,800
standard change log

00:06:22,240 --> 00:06:25,600
you're gonna see pages and pages of

00:06:24,800 --> 00:06:28,639
changes

00:06:25,600 --> 00:06:30,960
and if you try to uh look at uh

00:06:28,639 --> 00:06:31,840
all the changes you will find that there

00:06:30,960 --> 00:06:35,280
are over

00:06:31,840 --> 00:06:38,720
400 changes in cassandra

00:06:35,280 --> 00:06:41,919
4.0 and these changes are

00:06:38,720 --> 00:06:44,560
quite uh significant so in in

00:06:41,919 --> 00:06:45,360
in the community um whenever we make a

00:06:44,560 --> 00:06:49,199
comment

00:06:45,360 --> 00:06:51,199
uh exchange is termed as a could be a

00:06:49,199 --> 00:06:52,240
feature or it could be a bug fix or it

00:06:51,199 --> 00:06:55,360
could be a minor

00:06:52,240 --> 00:06:57,759
change but with cassandra 4.0 we have a

00:06:55,360 --> 00:07:00,880
lot of changes that are coming in

00:06:57,759 --> 00:07:02,319
and with uh with those changes comes the

00:07:00,880 --> 00:07:05,440
risk of

00:07:02,319 --> 00:07:09,360
bugs and regressions and stuff like that

00:07:05,440 --> 00:07:12,000
so uh so let's see uh what

00:07:09,360 --> 00:07:12,479
uh what cassandra's internals look like

00:07:12,000 --> 00:07:14,160
um

00:07:12,479 --> 00:07:16,400
because with all of these changes we

00:07:14,160 --> 00:07:21,599
need to test uh cassandra

00:07:16,400 --> 00:07:21,599
so that we ensure that the release is

00:07:21,919 --> 00:07:29,360
reasonably stable so

00:07:26,240 --> 00:07:31,680
here's the cassandra architecture and

00:07:29,360 --> 00:07:33,599
uh most of you should be familiar uh

00:07:31,680 --> 00:07:35,039
with this architecture but if you're not

00:07:33,599 --> 00:07:37,680
i'll just take you through it

00:07:35,039 --> 00:07:38,960
so with cassandra we have we we have

00:07:37,680 --> 00:07:42,000
individual nodes

00:07:38,960 --> 00:07:44,479
that are participating in the overall

00:07:42,000 --> 00:07:45,199
uh ring uh which is called a standard

00:07:44,479 --> 00:07:49,680
ring

00:07:45,199 --> 00:07:52,479
and uh this makes the cassandra

00:07:49,680 --> 00:07:53,440
system as a whole act like a distributed

00:07:52,479 --> 00:07:56,240
hash table

00:07:53,440 --> 00:07:56,879
because each node in the ring is going

00:07:56,240 --> 00:08:00,240
to have

00:07:56,879 --> 00:08:03,520
a certain range of data and that

00:08:00,240 --> 00:08:07,039
range of data is called the token range

00:08:03,520 --> 00:08:07,680
and this node is primarily responsible

00:08:07,039 --> 00:08:10,319
for

00:08:07,680 --> 00:08:12,080
storing that data but also we need to

00:08:10,319 --> 00:08:15,599
make sure that this data is

00:08:12,080 --> 00:08:18,240
available for consumption

00:08:15,599 --> 00:08:18,960
without any downtime in case a node goes

00:08:18,240 --> 00:08:22,319
down

00:08:18,960 --> 00:08:24,319
right so this

00:08:22,319 --> 00:08:25,680
node is going to take the data and it's

00:08:24,319 --> 00:08:28,560
going to replicate to

00:08:25,680 --> 00:08:30,160
all the replicas of that node and

00:08:28,560 --> 00:08:34,080
typically in cassandra

00:08:30,160 --> 00:08:36,959
we have a replication factor of three

00:08:34,080 --> 00:08:37,760
which means that the data is going to be

00:08:36,959 --> 00:08:40,800
stored

00:08:37,760 --> 00:08:44,240
across three different replicas

00:08:40,800 --> 00:08:48,000
for for durability and availability

00:08:44,240 --> 00:08:51,200
uh so uh with that said um

00:08:48,000 --> 00:08:53,279
whenever a node fails in cassandra the

00:08:51,200 --> 00:08:54,480
from the customer's perspective from the

00:08:53,279 --> 00:08:56,560
client's perspective

00:08:54,480 --> 00:08:57,600
the system continues to function as a

00:08:56,560 --> 00:09:00,080
whole

00:08:57,600 --> 00:09:00,720
but we have to internally repair that

00:09:00,080 --> 00:09:03,279
node

00:09:00,720 --> 00:09:05,519
and ensure that data that that node has

00:09:03,279 --> 00:09:08,800
is consistent

00:09:05,519 --> 00:09:11,760
so apart from the overall

00:09:08,800 --> 00:09:13,600
architecture of cassandra um cassandra

00:09:11,760 --> 00:09:14,480
has various components within within

00:09:13,600 --> 00:09:16,640
each node

00:09:14,480 --> 00:09:18,720
um this these components are uh

00:09:16,640 --> 00:09:20,240
non-exact and non-exhaustive

00:09:18,720 --> 00:09:22,720
uh but these are the most important

00:09:20,240 --> 00:09:25,519
components which is the storage engine

00:09:22,720 --> 00:09:27,040
the coordination layer there is there

00:09:25,519 --> 00:09:30,959
are activities that

00:09:27,040 --> 00:09:33,360
it runs like repair which is to

00:09:30,959 --> 00:09:35,279
reconcile data differences between nodes

00:09:33,360 --> 00:09:37,040
in the cluster

00:09:35,279 --> 00:09:38,560
they're streaming which does data

00:09:37,040 --> 00:09:41,600
transfer between nodes

00:09:38,560 --> 00:09:44,959
in a cluster and uh compaction

00:09:41,600 --> 00:09:47,839
that ensures that data that is

00:09:44,959 --> 00:09:48,880
deleted or is no longer reachable is

00:09:47,839 --> 00:09:52,800
dropped

00:09:48,880 --> 00:09:55,680
over time so and then there is also

00:09:52,800 --> 00:09:56,640
the internet communication in cassandra

00:09:55,680 --> 00:09:58,320
which means uh

00:09:56,640 --> 00:10:00,000
you know all the nodes they need to

00:09:58,320 --> 00:10:02,160
participate in a cluster

00:10:00,000 --> 00:10:04,800
and in order to participate uh in the

00:10:02,160 --> 00:10:06,959
cluster there is internet communication

00:10:04,800 --> 00:10:08,800
and there are other parts of cassandra

00:10:06,959 --> 00:10:11,680
that i have not really

00:10:08,800 --> 00:10:12,959
called out here but there is gossip and

00:10:11,680 --> 00:10:16,000
other parts of cassandra

00:10:12,959 --> 00:10:18,000
that participate in

00:10:16,000 --> 00:10:20,720
in making the cluster look like a single

00:10:18,000 --> 00:10:24,079
entity from a client's perspective

00:10:20,720 --> 00:10:27,360
so with this uh with this said uh

00:10:24,079 --> 00:10:30,480
there is a lot of stuff in cassandra uh

00:10:27,360 --> 00:10:31,440
that um that is participating in making

00:10:30,480 --> 00:10:34,640
this system

00:10:31,440 --> 00:10:35,600
uh the whole database work as a as a

00:10:34,640 --> 00:10:37,920
single unit

00:10:35,600 --> 00:10:38,640
and um and so whenever we change

00:10:37,920 --> 00:10:41,519
anything

00:10:38,640 --> 00:10:41,920
in cassandra that there are uh changes

00:10:41,519 --> 00:10:44,240
that

00:10:41,920 --> 00:10:45,360
may uh affect all of these layers or

00:10:44,240 --> 00:10:48,160
some of these layers

00:10:45,360 --> 00:10:48,880
within within the database um and so

00:10:48,160 --> 00:10:51,120
when we

00:10:48,880 --> 00:10:52,480
when we uh change something we need to

00:10:51,120 --> 00:10:54,800
make sure that there are no

00:10:52,480 --> 00:10:56,720
regressions that are introduced and that

00:10:54,800 --> 00:11:00,079
the system continues to function

00:10:56,720 --> 00:11:03,279
as uh previously expected and as we

00:11:00,079 --> 00:11:05,519
uh dive into the further slides uh

00:11:03,279 --> 00:11:07,040
i'll talk about the progressive

00:11:05,519 --> 00:11:11,839
difficulty of testing these

00:11:07,040 --> 00:11:13,279
different parts of cassandra so

00:11:11,839 --> 00:11:15,360
so let's let's talk about testing

00:11:13,279 --> 00:11:17,440
cassandra now um

00:11:15,360 --> 00:11:18,800
what there are various challenges in

00:11:17,440 --> 00:11:21,680
testing cassandra

00:11:18,800 --> 00:11:23,360
and those challenges uh are primarily

00:11:21,680 --> 00:11:25,440
because there are a lot of variables

00:11:23,360 --> 00:11:26,640
so anybody who has operated cassandra

00:11:25,440 --> 00:11:29,760
knows that there are a lot of

00:11:26,640 --> 00:11:30,320
components in within cassandra and there

00:11:29,760 --> 00:11:32,959
are

00:11:30,320 --> 00:11:34,480
a lot of knobs that we can tune so for

00:11:32,959 --> 00:11:37,600
example we can change

00:11:34,480 --> 00:11:40,880
a lot of settings and these settings

00:11:37,600 --> 00:11:43,839
can lead to great performance for

00:11:40,880 --> 00:11:43,839
certain types of

00:11:44,079 --> 00:11:50,240
schemas and some of these settings may

00:11:47,680 --> 00:11:51,120
introduce performance regressions for

00:11:50,240 --> 00:11:53,440
other types of

00:11:51,120 --> 00:11:55,120
schemas and so there are certain

00:11:53,440 --> 00:11:56,079
behavior characteristics that are

00:11:55,120 --> 00:12:00,240
dependent on

00:11:56,079 --> 00:12:02,959
the settings that cassandra has so um

00:12:00,240 --> 00:12:04,560
and to add to this we have a different

00:12:02,959 --> 00:12:08,959
deployment configuration

00:12:04,560 --> 00:12:10,720
so you can deploy this in

00:12:08,959 --> 00:12:12,560
in two data centers three data centers

00:12:10,720 --> 00:12:15,600
four data centers five data centers

00:12:12,560 --> 00:12:17,519
you can deploy them um in large ec2

00:12:15,600 --> 00:12:20,480
machines or you can deploy them

00:12:17,519 --> 00:12:21,760
in uh very tiny hardware so the

00:12:20,480 --> 00:12:25,519
deployment configuration

00:12:21,760 --> 00:12:28,639
also matters when when it comes to

00:12:25,519 --> 00:12:32,560
testing cassandra

00:12:28,639 --> 00:12:34,800
and the schemas or use cases that are

00:12:32,560 --> 00:12:36,800
you can model on cassandra are very

00:12:34,800 --> 00:12:38,480
varied so there's a lot of variants on

00:12:36,800 --> 00:12:40,880
the schemas that you can use

00:12:38,480 --> 00:12:41,839
and people use cassandra in very

00:12:40,880 --> 00:12:45,120
different ways

00:12:41,839 --> 00:12:46,880
so now i think uh you get the idea that

00:12:45,120 --> 00:12:49,760
there are a lot of variables

00:12:46,880 --> 00:12:50,320
that uh come into picture when it comes

00:12:49,760 --> 00:12:52,240
to

00:12:50,320 --> 00:12:53,600
um you know deploying and running

00:12:52,240 --> 00:12:56,160
cassandra and

00:12:53,600 --> 00:12:57,839
so naturally when it comes to making a

00:12:56,160 --> 00:13:00,240
change in cassandra's code base

00:12:57,839 --> 00:13:01,040
it also means that you have to you know

00:13:00,240 --> 00:13:03,519
make sure

00:13:01,040 --> 00:13:04,320
that all of these things that the system

00:13:03,519 --> 00:13:06,720
as a whole

00:13:04,320 --> 00:13:08,560
works under different settings uh

00:13:06,720 --> 00:13:08,959
different components we have exactly the

00:13:08,560 --> 00:13:11,360
way

00:13:08,959 --> 00:13:12,160
they were supposed to behave earlier and

00:13:11,360 --> 00:13:14,320
uh

00:13:12,160 --> 00:13:15,600
that we are not regressing uh we are not

00:13:14,320 --> 00:13:17,920
losing any data

00:13:15,600 --> 00:13:19,279
uh we are not uh causing any sort of

00:13:17,920 --> 00:13:23,760
bugs uh from

00:13:19,279 --> 00:13:27,600
from the usage standpoint um

00:13:23,760 --> 00:13:28,079
so what does testing in persona look

00:13:27,600 --> 00:13:30,079
like

00:13:28,079 --> 00:13:32,160
right now so in the open source

00:13:30,079 --> 00:13:34,399
community we have

00:13:32,160 --> 00:13:35,839
various unit tests uh cassandra has a

00:13:34,399 --> 00:13:39,120
lot of unit tests

00:13:35,839 --> 00:13:41,120
um it has python d-tests and upgrade

00:13:39,120 --> 00:13:44,240
tests and in jbmd tests

00:13:41,120 --> 00:13:44,639
and um d-tests are basically distributed

00:13:44,240 --> 00:13:46,800
tests

00:13:44,639 --> 00:13:48,320
what that means is we spawn various

00:13:46,800 --> 00:13:51,600
instances of cassandra

00:13:48,320 --> 00:13:52,800
and uh each instance is a physically

00:13:51,600 --> 00:13:56,240
separate process

00:13:52,800 --> 00:13:59,760
in case of python whereas in jbmd tests

00:13:56,240 --> 00:14:00,240
we have a single jvm that kind of models

00:13:59,760 --> 00:14:03,360
different

00:14:00,240 --> 00:14:04,560
instances of cassandra as threads within

00:14:03,360 --> 00:14:08,079
the same jbm

00:14:04,560 --> 00:14:10,160
um and but the general idea is that you

00:14:08,079 --> 00:14:12,480
can launch a three node cluster or five

00:14:10,160 --> 00:14:15,839
node cluster and you can run some tests

00:14:12,480 --> 00:14:16,320
uh within the scope of your test machine

00:14:15,839 --> 00:14:19,360
so

00:14:16,320 --> 00:14:20,000
you know let's say you have a laptop and

00:14:19,360 --> 00:14:21,680
you can

00:14:20,000 --> 00:14:23,680
launch the python details and it runs

00:14:21,680 --> 00:14:27,519
the d-test but these thetas

00:14:23,680 --> 00:14:30,959
also require a lot of resources so

00:14:27,519 --> 00:14:34,000
so but they they can be still run

00:14:30,959 --> 00:14:34,800
locally uh on your machine uh india vmt

00:14:34,000 --> 00:14:37,920
tests are

00:14:34,800 --> 00:14:38,800
um are used to test some of the

00:14:37,920 --> 00:14:41,760
components

00:14:38,800 --> 00:14:44,399
and these are more focused uh for uh

00:14:41,760 --> 00:14:47,600
doing whitebox testing in cassandra

00:14:44,399 --> 00:14:51,519
so what that means is you have

00:14:47,600 --> 00:14:55,440
the tests that are um

00:14:51,519 --> 00:14:58,000
running within the jvm but it is

00:14:55,440 --> 00:14:59,040
a single jvm so you you can much more

00:14:58,000 --> 00:15:01,920
easily

00:14:59,040 --> 00:15:02,800
mock out components uh especially the

00:15:01,920 --> 00:15:06,399
networking

00:15:02,800 --> 00:15:09,920
component in cassandra to test uh the

00:15:06,399 --> 00:15:12,000
test uh cassandra's uh code flow um and

00:15:09,920 --> 00:15:14,399
this also makes it easier for a

00:15:12,000 --> 00:15:18,160
developer to debug

00:15:14,399 --> 00:15:20,800
failures that are pertaining to

00:15:18,160 --> 00:15:22,079
a distributed setup of the of the

00:15:20,800 --> 00:15:24,720
cluster

00:15:22,079 --> 00:15:27,120
and upgrade tests are are also part of

00:15:24,720 --> 00:15:30,160
the test suite that cassandra has

00:15:27,120 --> 00:15:32,320
and um and the upgrade tests uh

00:15:30,160 --> 00:15:32,560
basically test that when cassandra is in

00:15:32,320 --> 00:15:34,079
a

00:15:32,560 --> 00:15:36,160
upgrade state or we are upgrading

00:15:34,079 --> 00:15:37,040
cassandra and it is running in a mixed

00:15:36,160 --> 00:15:41,600
mode state

00:15:37,040 --> 00:15:44,639
that we don't regress um

00:15:41,600 --> 00:15:46,639
we don't regress the from

00:15:44,639 --> 00:15:47,680
from the existing state so what that

00:15:46,639 --> 00:15:50,720
means is uh

00:15:47,680 --> 00:15:51,440
let's say uh there's a cluster that you

00:15:50,720 --> 00:15:54,560
have

00:15:51,440 --> 00:15:55,600
running 3.0 and uh you are upgrading it

00:15:54,560 --> 00:15:58,320
to 4.0

00:15:55,600 --> 00:15:58,720
and an upgrade test will check when that

00:15:58,320 --> 00:16:01,600
when

00:15:58,720 --> 00:16:02,560
the when the cluster is partially in 4r0

00:16:01,600 --> 00:16:05,519
and 3.0

00:16:02,560 --> 00:16:06,399
that there are no um there are no

00:16:05,519 --> 00:16:08,240
regressions

00:16:06,399 --> 00:16:10,000
uh because one of the underpinning

00:16:08,240 --> 00:16:12,160
principles with cassandra is

00:16:10,000 --> 00:16:13,040
that we never take the database offline

00:16:12,160 --> 00:16:15,680
in even

00:16:13,040 --> 00:16:16,480
even in case of upgrades we continue to

00:16:15,680 --> 00:16:20,160
function

00:16:16,480 --> 00:16:22,880
and so uh as we update individual loads

00:16:20,160 --> 00:16:23,680
the customer is doesn't experience any

00:16:22,880 --> 00:16:25,759
downtime

00:16:23,680 --> 00:16:28,720
uh which is not something that other

00:16:25,759 --> 00:16:31,759
databases can typically do

00:16:28,720 --> 00:16:35,199
so uh the with with all these tests

00:16:31,759 --> 00:16:38,480
uh the natural question is um

00:16:35,199 --> 00:16:41,680
are these enough um are these tests

00:16:38,480 --> 00:16:45,040
enough and the answer to

00:16:41,680 --> 00:16:48,079
to that question is a resounding no and

00:16:45,040 --> 00:16:50,880
uh and the reason why these are

00:16:48,079 --> 00:16:51,759
insufficient is because uh here's the

00:16:50,880 --> 00:16:55,040
graph

00:16:51,759 --> 00:16:57,040
um uh the

00:16:55,040 --> 00:16:58,399
the source of the graph is is below and

00:16:57,040 --> 00:17:01,519
we have a lot of

00:16:58,399 --> 00:17:05,520
issues that we've seen being

00:17:01,519 --> 00:17:08,240
patched in cassandra post the 3.0

00:17:05,520 --> 00:17:09,520
release and some of these are

00:17:08,240 --> 00:17:12,559
availability issues

00:17:09,520 --> 00:17:16,160
some of these are crashes

00:17:12,559 --> 00:17:17,919
that the the user experiences

00:17:16,160 --> 00:17:19,679
which is the the sree's experience and

00:17:17,919 --> 00:17:22,959
then there are correctness

00:17:19,679 --> 00:17:26,160
uh issues as well and uh these defects

00:17:22,959 --> 00:17:29,280
are uh are non-trivial uh

00:17:26,160 --> 00:17:32,000
to fix uh and you may not always uh

00:17:29,280 --> 00:17:34,160
experience these failures uh or you may

00:17:32,000 --> 00:17:37,520
not always hit these bugs

00:17:34,160 --> 00:17:39,919
and it's only when you reach

00:17:37,520 --> 00:17:41,600
maybe a certain scale or you you are

00:17:39,919 --> 00:17:43,600
using cassandra in a certain

00:17:41,600 --> 00:17:45,120
configuration that you may actually

00:17:43,600 --> 00:17:48,480
experience these issues

00:17:45,120 --> 00:17:49,440
and so obviously the uh the logic

00:17:48,480 --> 00:17:52,320
follows is that

00:17:49,440 --> 00:17:53,039
if we see these errors or or defects in

00:17:52,320 --> 00:17:56,080
cassandra

00:17:53,039 --> 00:17:58,640
then there are then the meaning to

00:17:56,080 --> 00:18:00,400
figure out a better testing strategy uh

00:17:58,640 --> 00:18:05,360
more effective testing strategy to

00:18:00,400 --> 00:18:05,360
ferret out these bugs and so

00:18:05,840 --> 00:18:09,280
going back to the challenges that we

00:18:07,840 --> 00:18:12,880
have uh

00:18:09,280 --> 00:18:15,840
if you look at why it is hard to

00:18:12,880 --> 00:18:17,520
expose these bugs is because there are a

00:18:15,840 --> 00:18:21,360
lot of moving parts

00:18:17,520 --> 00:18:23,360
uh the components that make up cassandra

00:18:21,360 --> 00:18:25,360
the the settings the deployment

00:18:23,360 --> 00:18:28,720
configuration the schemas

00:18:25,360 --> 00:18:33,200
the use cases and uh you know uh

00:18:28,720 --> 00:18:35,919
in many situations uh we have to

00:18:33,200 --> 00:18:36,960
use cassandra in a mixed mode uh that is

00:18:35,919 --> 00:18:39,280
during upgrades

00:18:36,960 --> 00:18:40,080
we are going to see a lot of these

00:18:39,280 --> 00:18:43,440
issues

00:18:40,080 --> 00:18:46,640
uh pop up um it's only when

00:18:43,440 --> 00:18:47,919
you uh set these uh components in a

00:18:46,640 --> 00:18:49,679
specific configuration

00:18:47,919 --> 00:18:51,919
that you might actually experience these

00:18:49,679 --> 00:18:54,960
issues so

00:18:51,919 --> 00:18:58,400
what makes this even worse is

00:18:54,960 --> 00:18:59,039
the uh in a distributed system time is a

00:18:58,400 --> 00:19:01,840
quantity

00:18:59,039 --> 00:19:02,960
that is kind of weird uh what i mean to

00:19:01,840 --> 00:19:05,679
say is that

00:19:02,960 --> 00:19:07,600
uh in a cluster when you have uh

00:19:05,679 --> 00:19:11,360
different nodes talking to each other

00:19:07,600 --> 00:19:13,760
each node has its own um clock

00:19:11,360 --> 00:19:15,039
and uh it's a well-known phenomena in a

00:19:13,760 --> 00:19:17,280
distributed system

00:19:15,039 --> 00:19:18,559
that uh when when you're coordinating

00:19:17,280 --> 00:19:21,120
between two nodes

00:19:18,559 --> 00:19:21,600
uh or two processes that have their own

00:19:21,120 --> 00:19:25,840
clock

00:19:21,600 --> 00:19:25,840
it is very hard to actually

00:19:26,160 --> 00:19:32,720
establish a happens before relationship

00:19:29,280 --> 00:19:35,840
which means that if the clocks drift

00:19:32,720 --> 00:19:36,320
in the systems it's going to affect the

00:19:35,840 --> 00:19:39,760
way

00:19:36,320 --> 00:19:42,799
the same query or same uh set of packets

00:19:39,760 --> 00:19:44,720
that are flowing between the two nodes

00:19:42,799 --> 00:19:46,320
to be processed in a slightly different

00:19:44,720 --> 00:19:49,200
way depending on

00:19:46,320 --> 00:19:50,000
how the timing is the other issue with

00:19:49,200 --> 00:19:52,320
timing is

00:19:50,000 --> 00:19:53,120
that it's very hard to simulate a

00:19:52,320 --> 00:19:55,280
certain

00:19:53,120 --> 00:19:56,880
race condition a lot of race conditions

00:19:55,280 --> 00:19:59,919
are due to timing issues

00:19:56,880 --> 00:20:03,120
in the system so if let's say you

00:19:59,919 --> 00:20:06,080
you hit a error condition or a bug

00:20:03,120 --> 00:20:07,440
because the there is a slight

00:20:06,080 --> 00:20:10,640
variability in the way

00:20:07,440 --> 00:20:13,360
packets are being being delivered uh

00:20:10,640 --> 00:20:14,720
in in our system then it is very hard to

00:20:13,360 --> 00:20:16,720
do

00:20:14,720 --> 00:20:19,440
to simulate that that particular

00:20:16,720 --> 00:20:21,679
situation exactly in a test scenario

00:20:19,440 --> 00:20:22,640
um and especially this gets worse

00:20:21,679 --> 00:20:24,799
because

00:20:22,640 --> 00:20:26,400
when you have let's say a 10 node

00:20:24,799 --> 00:20:28,640
cluster or 20 node cluster

00:20:26,400 --> 00:20:29,919
now there are messages being sent back

00:20:28,640 --> 00:20:33,120
and forth

00:20:29,919 --> 00:20:36,000
across a lot of nodes so eventually what

00:20:33,120 --> 00:20:37,440
happens is that if you have to simulate

00:20:36,000 --> 00:20:40,640
this entire system

00:20:37,440 --> 00:20:44,080
it it is a very complicated problem uh

00:20:40,640 --> 00:20:46,240
and timing is a issue here

00:20:44,080 --> 00:20:48,000
the other issue is uh the message

00:20:46,240 --> 00:20:51,360
delivery in cassandra

00:20:48,000 --> 00:20:53,200
4.0 is asynchronous or what that means

00:20:51,360 --> 00:20:55,600
is we have switched to async i o

00:20:53,200 --> 00:20:57,039
so uh some of the operations that were

00:20:55,600 --> 00:21:00,320
obviously synchronous

00:20:57,039 --> 00:21:00,960
uh are non are asynchronous at this

00:21:00,320 --> 00:21:05,039
point

00:21:00,960 --> 00:21:08,400
and as a result there are a lot of

00:21:05,039 --> 00:21:11,600
edge cases where uh earlier a

00:21:08,400 --> 00:21:14,880
synchronous code flow is now

00:21:11,600 --> 00:21:18,080
asynchronous and and that also

00:21:14,880 --> 00:21:21,520
introduces a difficulty in

00:21:18,080 --> 00:21:25,120
testing um node failures

00:21:21,520 --> 00:21:27,120
is another big issue that

00:21:25,120 --> 00:21:28,880
you if you if you want to simulate a

00:21:27,120 --> 00:21:30,880
node failure it's generally much easier

00:21:28,880 --> 00:21:34,720
to simulate a node failure

00:21:30,880 --> 00:21:37,760
than compared to the first two issues

00:21:34,720 --> 00:21:40,080
and also race conditions

00:21:37,760 --> 00:21:42,159
uh within the process as well as across

00:21:40,080 --> 00:21:44,240
different processes of cassandra

00:21:42,159 --> 00:21:45,440
that are running in different nodes uh

00:21:44,240 --> 00:21:48,640
these race conditions

00:21:45,440 --> 00:21:51,919
are are very uh hard

00:21:48,640 --> 00:21:55,280
to stimulate so any piece of code that

00:21:51,919 --> 00:21:58,080
is uh multi-threaded is uh is

00:21:55,280 --> 00:21:58,480
by definition it is non-deterministic

00:21:58,080 --> 00:22:01,039
and

00:21:58,480 --> 00:22:02,240
it is harder to test so if you go

00:22:01,039 --> 00:22:05,679
looking for

00:22:02,240 --> 00:22:08,640
a library in java that allows you to

00:22:05,679 --> 00:22:10,840
test a concurrent code you would be

00:22:08,640 --> 00:22:14,080
hard-pressed to find something that is

00:22:10,840 --> 00:22:17,039
reasonable and um

00:22:14,080 --> 00:22:18,080
and finally nato network flakiness so

00:22:17,039 --> 00:22:19,919
believe it or not

00:22:18,080 --> 00:22:21,280
there are a lot of edge conditions that

00:22:19,919 --> 00:22:23,440
are exposed because

00:22:21,280 --> 00:22:25,039
network drops a packet or there is

00:22:23,440 --> 00:22:27,840
flakiness

00:22:25,039 --> 00:22:29,440
in the in the networking and uh or there

00:22:27,840 --> 00:22:32,400
are system parameters

00:22:29,440 --> 00:22:33,440
uh that are uh set differently uh in

00:22:32,400 --> 00:22:36,720
cassandra

00:22:33,440 --> 00:22:38,960
uh uh what i mean to say the the

00:22:36,720 --> 00:22:40,320
the system that is running cassandra has

00:22:38,960 --> 00:22:43,200
a lot of parameters

00:22:40,320 --> 00:22:44,000
that make uh network behave in a

00:22:43,200 --> 00:22:47,919
different way

00:22:44,000 --> 00:22:50,960
so the test setup for that network uh

00:22:47,919 --> 00:22:51,440
networking is it's gonna also change the

00:22:50,960 --> 00:22:55,679
way

00:22:51,440 --> 00:22:59,039
networking works within uh cassandra

00:22:55,679 --> 00:23:02,000
and finally uh java's garbage collector

00:22:59,039 --> 00:23:03,360
um this also adds a form of a

00:23:02,000 --> 00:23:06,960
non-determinism

00:23:03,360 --> 00:23:09,440
in the cassandra process so

00:23:06,960 --> 00:23:10,320
all of these challenges are in addition

00:23:09,440 --> 00:23:13,360
to having

00:23:10,320 --> 00:23:15,520
a complicated code base as well as uh

00:23:13,360 --> 00:23:17,280
a ton of distributed components that are

00:23:15,520 --> 00:23:20,880
talking to each other

00:23:17,280 --> 00:23:24,240
so coming to

00:23:20,880 --> 00:23:28,880
testing uh cassandra 4.0 so how do we

00:23:24,240 --> 00:23:28,880
test cassandra 4.0 um

00:23:28,960 --> 00:23:32,400
there are various approaches that the

00:23:30,480 --> 00:23:35,039
community has adopted

00:23:32,400 --> 00:23:36,080
uh one of the approach is replay testing

00:23:35,039 --> 00:23:39,120
and we'll dive

00:23:36,080 --> 00:23:41,520
uh more deeper into each of these um

00:23:39,120 --> 00:23:42,320
uh test um scenario uh testing

00:23:41,520 --> 00:23:45,600
approaches

00:23:42,320 --> 00:23:47,919
uh in a in the further slides but uh

00:23:45,600 --> 00:23:50,159
the first uh one of the first approaches

00:23:47,919 --> 00:23:52,080
is replay testing

00:23:50,159 --> 00:23:53,279
the second approach is fuzz and property

00:23:52,080 --> 00:23:56,240
based testing

00:23:53,279 --> 00:23:58,799
and third approach is dispute test and

00:23:56,240 --> 00:24:01,919
fault injection testing

00:23:58,799 --> 00:24:04,720
and the last approach is upgrade testing

00:24:01,919 --> 00:24:06,880
and let me talk through uh these

00:24:04,720 --> 00:24:10,080
individual

00:24:06,880 --> 00:24:13,200
testing strategies so

00:24:10,080 --> 00:24:16,640
uh replay testing is uh basically

00:24:13,200 --> 00:24:18,240
um when where we capture traffic and we

00:24:16,640 --> 00:24:21,120
replay it and

00:24:18,240 --> 00:24:21,760
uh in 4.2 we have this feature called as

00:24:21,120 --> 00:24:24,080
fql

00:24:21,760 --> 00:24:24,960
which is full query logging and with

00:24:24,080 --> 00:24:28,000
this feature

00:24:24,960 --> 00:24:31,360
what we can do is we can capture logs

00:24:28,000 --> 00:24:35,520
um or rather capture queries

00:24:31,360 --> 00:24:38,799
and log them into binary files that are

00:24:35,520 --> 00:24:39,919
stored on disk and then i take those

00:24:38,799 --> 00:24:41,679
files and replay

00:24:39,919 --> 00:24:43,840
the contents of those files so the

00:24:41,679 --> 00:24:44,720
queries that you actually experience in

00:24:43,840 --> 00:24:46,559
production

00:24:44,720 --> 00:24:48,000
we can take those queries and we can

00:24:46,559 --> 00:24:50,880
capture them and

00:24:48,000 --> 00:24:51,760
on on individual nodes or all nodes uh

00:24:50,880 --> 00:24:54,080
in a cluster

00:24:51,760 --> 00:24:55,520
and then we can take those uh individual

00:24:54,080 --> 00:24:59,120
queries and replay them

00:24:55,520 --> 00:25:00,320
on a test cluster and uh this is a very

00:24:59,120 --> 00:25:03,919
effective way

00:25:00,320 --> 00:25:07,600
of testing um testing uh

00:25:03,919 --> 00:25:10,159
cassandra um so

00:25:07,600 --> 00:25:11,919
uh in this in this approach we can

00:25:10,159 --> 00:25:12,960
either capture all queries or we can

00:25:11,919 --> 00:25:16,880
also

00:25:12,960 --> 00:25:19,600
sample queries on in individual nodes

00:25:16,880 --> 00:25:20,080
and this is a high throughput approach

00:25:19,600 --> 00:25:22,720
uh

00:25:20,080 --> 00:25:23,360
for uh for testing cassandra uh what i

00:25:22,720 --> 00:25:27,360
mean to say

00:25:23,360 --> 00:25:29,600
is that when we capture queries in

00:25:27,360 --> 00:25:30,400
production it doesn't have to compromise

00:25:29,600 --> 00:25:33,200
on

00:25:30,400 --> 00:25:35,360
on how many queries we capture the

00:25:33,200 --> 00:25:36,320
implementation that fql has is a very

00:25:35,360 --> 00:25:39,279
low overhead in

00:25:36,320 --> 00:25:39,919
implementation so as long as you have

00:25:39,279 --> 00:25:42,559
enough

00:25:39,919 --> 00:25:43,200
disk io we can capture every single

00:25:42,559 --> 00:25:46,880
query that

00:25:43,200 --> 00:25:50,080
is making it to that node and then

00:25:46,880 --> 00:25:53,760
log it without really having to drop

00:25:50,080 --> 00:25:54,799
the the number of drop a few queries on

00:25:53,760 --> 00:25:57,760
the on the floor

00:25:54,799 --> 00:25:58,159
because uh it may degrade performance um

00:25:57,760 --> 00:26:00,720
and

00:25:58,159 --> 00:26:02,159
uh replay testing is typically uh

00:26:00,720 --> 00:26:04,960
carried out on

00:26:02,159 --> 00:26:05,840
uh a cluster that is upgraded or is in

00:26:04,960 --> 00:26:09,919
the process have been

00:26:05,840 --> 00:26:10,880
upgraded um and that uh basically uh

00:26:09,919 --> 00:26:12,480
simulates a

00:26:10,880 --> 00:26:14,240
scenario where you have upgraded

00:26:12,480 --> 00:26:16,400
cassandra with the same data set

00:26:14,240 --> 00:26:17,919
and you're throwing the same queries uh

00:26:16,400 --> 00:26:20,320
at that cluster

00:26:17,919 --> 00:26:21,360
and the expectation is that that cluster

00:26:20,320 --> 00:26:24,000
also

00:26:21,360 --> 00:26:26,000
gives you the same data and responses

00:26:24,000 --> 00:26:28,720
that your old cluster

00:26:26,000 --> 00:26:30,720
gives so from from a user standpoint

00:26:28,720 --> 00:26:31,600
when we upgrade a user from let's say

00:26:30,720 --> 00:26:33,760
3.0

00:26:31,600 --> 00:26:35,760
to folder oh functionally they should

00:26:33,760 --> 00:26:37,760
not see any difference in the

00:26:35,760 --> 00:26:40,240
response characteristics being the

00:26:37,760 --> 00:26:42,720
latency and the throughput of queries

00:26:40,240 --> 00:26:43,440
and also they should not see any changes

00:26:42,720 --> 00:26:46,000
in the read

00:26:43,440 --> 00:26:47,440
or write path of cassandra so the

00:26:46,000 --> 00:26:50,720
results of the query's

00:26:47,440 --> 00:26:51,200
pre 4.0 upgrade and post for auto

00:26:50,720 --> 00:26:55,760
upgrade

00:26:51,200 --> 00:26:55,760
should be exactly the same um so

00:26:56,480 --> 00:27:00,720
in all all dimensions

00:27:00,960 --> 00:27:04,840
coming to fuzz and property based

00:27:03,360 --> 00:27:08,240
testing

00:27:04,840 --> 00:27:10,159
um the uh cassandra recently open

00:27:08,240 --> 00:27:13,919
sourced this tool called harry

00:27:10,159 --> 00:27:17,360
um and harry allows you to uh perform

00:27:13,919 --> 00:27:20,480
uh basically uh first testing uh

00:27:17,360 --> 00:27:23,840
and uh and so so

00:27:20,480 --> 00:27:26,000
before we uh talk about

00:27:23,840 --> 00:27:27,279
this uh further uh let's talk a little

00:27:26,000 --> 00:27:30,559
bit about fast testing

00:27:27,279 --> 00:27:33,200
and property based testing so

00:27:30,559 --> 00:27:34,399
these are uh these are testing tools

00:27:33,200 --> 00:27:36,159
that are

00:27:34,399 --> 00:27:37,760
that have been around for quite a long

00:27:36,159 --> 00:27:42,159
time um

00:27:37,760 --> 00:27:44,880
the basic idea of these tools is to

00:27:42,159 --> 00:27:45,279
explore the state space of a component

00:27:44,880 --> 00:27:47,440
so

00:27:45,279 --> 00:27:49,120
let's say you have a component that

00:27:47,440 --> 00:27:52,799
takes a certain

00:27:49,120 --> 00:27:55,440
set of inputs and you can

00:27:52,799 --> 00:27:56,399
pass various valid values in those

00:27:55,440 --> 00:27:59,600
inputs

00:27:56,399 --> 00:28:00,399
and you get a valid response back but

00:27:59,600 --> 00:28:03,440
what happens

00:28:00,399 --> 00:28:05,440
uh in in the real world is that those

00:28:03,440 --> 00:28:06,880
that component may not always get a

00:28:05,440 --> 00:28:09,679
valid uh input

00:28:06,880 --> 00:28:11,520
in which case uh there are edge cases

00:28:09,679 --> 00:28:13,360
that are left unexplored

00:28:11,520 --> 00:28:15,360
and what uh fuzz and property based

00:28:13,360 --> 00:28:17,279
testing does is

00:28:15,360 --> 00:28:18,399
helps you establish an invariant for

00:28:17,279 --> 00:28:20,559
that component

00:28:18,399 --> 00:28:22,480
and explore the state space of the

00:28:20,559 --> 00:28:26,159
inputs for that component

00:28:22,480 --> 00:28:27,120
and um the the tool allows you to pass

00:28:26,159 --> 00:28:30,080
in

00:28:27,120 --> 00:28:31,520
various values and ensuring that the way

00:28:30,080 --> 00:28:34,880
invariant that you

00:28:31,520 --> 00:28:38,159
have established is always true and uh

00:28:34,880 --> 00:28:41,280
this uh this approach has allowed us to

00:28:38,159 --> 00:28:42,640
expose issues um in um

00:28:41,280 --> 00:28:45,919
[Music]

00:28:42,640 --> 00:28:49,360
in uh in areas like um

00:28:45,919 --> 00:28:52,159
uh check summing um or uh or

00:28:49,360 --> 00:28:54,320
framing uh within uh cassandra's uh

00:28:52,159 --> 00:28:58,399
internet uh networking protocol

00:28:54,320 --> 00:29:01,039
um and and so this is a very useful tool

00:28:58,399 --> 00:29:01,840
where a a developer may not be able to

00:29:01,039 --> 00:29:04,960
write a

00:29:01,840 --> 00:29:05,679
very effective test or explore the state

00:29:04,960 --> 00:29:08,880
space

00:29:05,679 --> 00:29:11,760
uh in its entirety and uh this tool

00:29:08,880 --> 00:29:13,039
uh these tools allow us to do this very

00:29:11,760 --> 00:29:15,200
easily

00:29:13,039 --> 00:29:16,399
harry is a more recent contribution into

00:29:15,200 --> 00:29:19,200
cassandra

00:29:16,399 --> 00:29:20,480
but prior to harry we use a library

00:29:19,200 --> 00:29:23,760
called quick theories

00:29:20,480 --> 00:29:27,200
uh and it is able to uh do

00:29:23,760 --> 00:29:28,159
this first testing or property based

00:29:27,200 --> 00:29:31,600
testing um

00:29:28,159 --> 00:29:34,159
in standard code base and we have a more

00:29:31,600 --> 00:29:35,360
uh in-depth article about this uh on the

00:29:34,159 --> 00:29:37,120
cassandra blog

00:29:35,360 --> 00:29:39,600
if you are interested you can go to the

00:29:37,120 --> 00:29:42,320
blog link and um

00:29:39,600 --> 00:29:43,039
and basically look at how cassandra is

00:29:42,320 --> 00:29:44,720
using

00:29:43,039 --> 00:29:47,200
uh property-based testing and first

00:29:44,720 --> 00:29:47,200
testing

00:29:47,679 --> 00:29:51,120
the other approaches are distributed

00:29:49,679 --> 00:29:54,240
testing and

00:29:51,120 --> 00:29:57,679
fault injection testing in this case uh

00:29:54,240 --> 00:30:01,120
what we do is uh basically

00:29:57,679 --> 00:30:02,559
uh spin up a cluster and run tests

00:30:01,120 --> 00:30:05,600
against that cluster

00:30:02,559 --> 00:30:06,080
um these tests uh while these tests are

00:30:05,600 --> 00:30:09,200
running

00:30:06,080 --> 00:30:12,080
uh we inject fault um

00:30:09,200 --> 00:30:13,919
which means uh we use the stuff like

00:30:12,080 --> 00:30:16,640
chaos monkey or chaos gorilla

00:30:13,919 --> 00:30:17,919
and we can introduce chaos in the

00:30:16,640 --> 00:30:21,120
overall

00:30:17,919 --> 00:30:22,559
overall system uh this allows the system

00:30:21,120 --> 00:30:25,679
to

00:30:22,559 --> 00:30:28,880
survive failures and at the same time

00:30:25,679 --> 00:30:31,039
we are able to expose bugs related to

00:30:28,880 --> 00:30:32,000
edge conditions like when hardware fails

00:30:31,039 --> 00:30:34,640
or when a

00:30:32,000 --> 00:30:36,799
node suddenly goes offline or there is a

00:30:34,640 --> 00:30:40,640
flakiness when no note comes

00:30:36,799 --> 00:30:43,039
online goes offline repeatedly

00:30:40,640 --> 00:30:44,640
and this is one of the more effective

00:30:43,039 --> 00:30:49,120
ways of ferreting issues

00:30:44,640 --> 00:30:52,240
out uh in any distributed system

00:30:49,120 --> 00:30:55,039
uh the final uh the final uh

00:30:52,240 --> 00:30:56,000
testing strategy is upgrade testing this

00:30:55,039 --> 00:30:59,919
is one of the most

00:30:56,000 --> 00:31:02,960
critical in my view to test uh

00:30:59,919 --> 00:31:05,279
the upgrade scenarios in cassandra and

00:31:02,960 --> 00:31:07,360
uh this is not really a special type of

00:31:05,279 --> 00:31:08,000
testing but this is basically forcing

00:31:07,360 --> 00:31:10,880
the cluster

00:31:08,000 --> 00:31:11,679
into a situation where it's running in

00:31:10,880 --> 00:31:13,519
mixed mode

00:31:11,679 --> 00:31:14,720
and making sure that all the components

00:31:13,519 --> 00:31:17,200
are behaving

00:31:14,720 --> 00:31:18,000
the way uh they uh they're expected to

00:31:17,200 --> 00:31:22,080
behave

00:31:18,000 --> 00:31:22,960
and um and so uh the testing strategy

00:31:22,080 --> 00:31:25,760
that we

00:31:22,960 --> 00:31:26,399
uh apply here is no different from the

00:31:25,760 --> 00:31:28,960
previous

00:31:26,399 --> 00:31:29,760
testing strategies uh but what is

00:31:28,960 --> 00:31:31,679
different here

00:31:29,760 --> 00:31:32,799
is that the cluster is actually running

00:31:31,679 --> 00:31:36,000
in a mixed board

00:31:32,799 --> 00:31:39,039
situation and so uh

00:31:36,000 --> 00:31:39,600
there are uh what this allows us to uh

00:31:39,039 --> 00:31:42,080
verify

00:31:39,600 --> 00:31:44,559
is that the cluster is gonna behave

00:31:42,080 --> 00:31:45,279
exactly the same as a 4.0 or a 3.0

00:31:44,559 --> 00:31:47,679
cluster

00:31:45,279 --> 00:31:48,880
if it is running in a mixed mod 3.0 and

00:31:47,679 --> 00:31:51,440
4.0 cluster

00:31:48,880 --> 00:31:52,480
uh obviously you won't expect all the

00:31:51,440 --> 00:31:56,159
features to work as

00:31:52,480 --> 00:31:58,399
um in in in the case of the

00:31:56,159 --> 00:31:59,200
client uh you would expect all the

00:31:58,399 --> 00:32:02,320
features to

00:31:59,200 --> 00:32:02,960
exactly work but the 4.0 specific

00:32:02,320 --> 00:32:04,730
features

00:32:02,960 --> 00:32:06,559
would not be

00:32:04,730 --> 00:32:08,799
[Music]

00:32:06,559 --> 00:32:10,240
available because the cluster is running

00:32:08,799 --> 00:32:12,720
in a mixed mode

00:32:10,240 --> 00:32:15,200
scenario and once the cluster is fully

00:32:12,720 --> 00:32:18,000
upgraded uh you know

00:32:15,200 --> 00:32:19,200
you would expect that the cluster would

00:32:18,000 --> 00:32:22,720
expose functionality

00:32:19,200 --> 00:32:25,200
that is 4.0 specific and it's available

00:32:22,720 --> 00:32:28,240
to the customers to use it

00:32:25,200 --> 00:32:31,840
so um

00:32:28,240 --> 00:32:34,880
so with that said uh i'll summarize

00:32:31,840 --> 00:32:35,360
um 4.2 should be stable that is the goal

00:32:34,880 --> 00:32:37,600
of

00:32:35,360 --> 00:32:39,360
the cassandra community and a lot has

00:32:37,600 --> 00:32:42,880
gone into ensuring

00:32:39,360 --> 00:32:46,640
4.0 is stable a lot of issues are

00:32:42,880 --> 00:32:49,360
have been already reported and fixed um

00:32:46,640 --> 00:32:50,320
there are a few issues that existing

00:32:49,360 --> 00:32:53,760
techniques uh

00:32:50,320 --> 00:32:56,480
miss they do catch some of the very

00:32:53,760 --> 00:32:58,320
obvious failures but there are certain

00:32:56,480 --> 00:33:00,159
issues that they have missed

00:32:58,320 --> 00:33:01,760
and so the community is working really

00:33:00,159 --> 00:33:05,679
hard to ensure that

00:33:01,760 --> 00:33:08,840
all of this uh all these issues are are

00:33:05,679 --> 00:33:13,039
exposed before we declare photo is

00:33:08,840 --> 00:33:15,440
stable and uh

00:33:13,039 --> 00:33:17,279
the the final takeaway uh is testing any

00:33:15,440 --> 00:33:21,200
distributed system is hard

00:33:17,279 --> 00:33:23,519
um the testing a stateful distributed

00:33:21,200 --> 00:33:26,880
system like cassandra is even harder

00:33:23,519 --> 00:33:28,480
and the emphasis that we've uh

00:33:26,880 --> 00:33:30,320
placed on testing is uh pretty

00:33:28,480 --> 00:33:33,360
phenomenal and uh

00:33:30,320 --> 00:33:37,360
we we can't do it uh by ourselves

00:33:33,360 --> 00:33:40,000
um so uh please help test cassandra 4.0

00:33:37,360 --> 00:33:40,399
uh the beta2 for cassandra is already

00:33:40,000 --> 00:33:43,679
out

00:33:40,399 --> 00:33:46,480
on uh on our website

00:33:43,679 --> 00:33:48,320
um and uh you can just download install

00:33:46,480 --> 00:33:49,760
it and try it out for your use case

00:33:48,320 --> 00:33:52,159
maybe you'll find an issue maybe you

00:33:49,760 --> 00:33:55,039
will not find an issue

00:33:52,159 --> 00:33:56,000
but at least we will get some uh great

00:33:55,039 --> 00:33:59,039
feedback from

00:33:56,000 --> 00:34:02,000
our users so uh that is uh

00:33:59,039 --> 00:34:02,640
i think that is a very uh critical uh

00:34:02,000 --> 00:34:05,760
for us

00:34:02,640 --> 00:34:06,320
uh at this point uh as we are all trying

00:34:05,760 --> 00:34:09,359
to get

00:34:06,320 --> 00:34:12,879
photoco out soon

00:34:09,359 --> 00:34:16,000
and uh finally um we are hiring

00:34:12,879 --> 00:34:17,919
at apple so if you're interested in uh

00:34:16,000 --> 00:34:19,040
working at apple we have a ton of

00:34:17,919 --> 00:34:21,839
positions open

00:34:19,040 --> 00:34:23,119
in our organization please follow the

00:34:21,839 --> 00:34:26,399
link

00:34:23,119 --> 00:34:28,800
on the on the screen and

00:34:26,399 --> 00:34:29,760
it should hopefully take you to the uh

00:34:28,800 --> 00:34:32,879
jobs page uh

00:34:29,760 --> 00:34:35,839
at apple uh where you can apply uh

00:34:32,879 --> 00:34:36,960
this is a apache con specific link so uh

00:34:35,839 --> 00:34:39,040
please do

00:34:36,960 --> 00:34:40,399
um apply if you are interested in

00:34:39,040 --> 00:34:44,240
working on apple and

00:34:40,399 --> 00:34:46,560
solving some of these problems um

00:34:44,240 --> 00:34:48,000
all right uh that's it from me uh thank

00:34:46,560 --> 00:34:51,040
you very much uh

00:34:48,000 --> 00:34:54,159
apologies for the delay uh for

00:34:51,040 --> 00:35:03,280
enjoying the session uh and i'm open

00:34:54,159 --> 00:35:07,200
for any questions if anybody has any

00:35:03,280 --> 00:35:07,200
you can type the questions in in the

00:35:14,839 --> 00:35:17,839
chat

00:35:41,119 --> 00:35:47,040
all right um sorry so i

00:35:44,480 --> 00:35:48,160
didn't see the previous questions uh in

00:35:47,040 --> 00:35:51,040
in the

00:35:48,160 --> 00:35:51,040
chat um

00:35:52,320 --> 00:35:58,640
all right um so the

00:35:55,520 --> 00:35:59,520
the graph was not a number of bugs over

00:35:58,640 --> 00:36:03,760
time

00:35:59,520 --> 00:36:06,720
it was uh distribution of bugs surges

00:36:03,760 --> 00:36:08,079
so these are overall bugs and they're

00:36:06,720 --> 00:36:11,440
classified by

00:36:08,079 --> 00:36:12,160
defect type and so the overall bugs that

00:36:11,440 --> 00:36:15,359
were

00:36:12,160 --> 00:36:18,640
caught um so far

00:36:15,359 --> 00:36:22,079
uh post 3.0 release are

00:36:18,640 --> 00:36:24,320
summarized here there's a jira link

00:36:22,079 --> 00:36:25,520
if you go to that filter you should see

00:36:24,320 --> 00:36:28,160
all the

00:36:25,520 --> 00:36:30,720
individual issues uh most of these

00:36:28,160 --> 00:36:34,320
issues won't be something that you would

00:36:30,720 --> 00:36:36,000
um be able to uh

00:36:34,320 --> 00:36:38,079
i mean most of these issues are not

00:36:36,000 --> 00:36:39,599
something that you would encounter

00:36:38,079 --> 00:36:41,680
under normal circumstances these are

00:36:39,599 --> 00:36:44,000
really really weird issues

00:36:41,680 --> 00:36:44,000
um

00:36:45,119 --> 00:36:53,040
yes uh about four dot of stability

00:36:49,119 --> 00:36:56,160
um i don't know

00:36:53,040 --> 00:36:58,560
um so we are testing

00:36:56,160 --> 00:36:59,760
uh there is a very uh interesting

00:36:58,560 --> 00:37:02,960
discussion that happened

00:36:59,760 --> 00:37:06,240
earlier on the dev list uh about

00:37:02,960 --> 00:37:08,960
the overall freeze that we had in order

00:37:06,240 --> 00:37:10,880
to focus on on stability

00:37:08,960 --> 00:37:13,200
um obviously there are different view

00:37:10,880 --> 00:37:16,480
points that people have

00:37:13,200 --> 00:37:17,520
about stability sorry i'm going back and

00:37:16,480 --> 00:37:19,599
forth

00:37:17,520 --> 00:37:21,200
so i think i think there are a lot of

00:37:19,599 --> 00:37:24,240
issues that were

00:37:21,200 --> 00:37:26,000
found and fixed in 4.0 we're still

00:37:24,240 --> 00:37:28,480
finding issues

00:37:26,000 --> 00:37:29,359
and the community is working really hard

00:37:28,480 --> 00:37:31,839
to

00:37:29,359 --> 00:37:31,839
make sure

00:37:32,800 --> 00:37:36,880
make sure that we are able to fix those

00:37:35,280 --> 00:37:40,560
issues

00:37:36,880 --> 00:37:43,650
example of issues that

00:37:40,560 --> 00:37:46,480
existing techniques miss so

00:37:43,650 --> 00:37:49,200
[Music]

00:37:46,480 --> 00:37:50,079
there are various examples i think if

00:37:49,200 --> 00:37:52,960
you if you

00:37:50,079 --> 00:37:53,359
see this uh filter you will see all of

00:37:52,960 --> 00:37:56,400
these

00:37:53,359 --> 00:37:57,119
what uh immediately comes to my mind is

00:37:56,400 --> 00:37:59,920
a couple

00:37:57,119 --> 00:38:02,079
issues uh with related to networking and

00:37:59,920 --> 00:38:05,520
networking is one of the most

00:38:02,079 --> 00:38:07,839
annoying pieces of uh you know um

00:38:05,520 --> 00:38:10,240
the overall distributed system right uh

00:38:07,839 --> 00:38:10,960
so uh netflix actually encountered this

00:38:10,240 --> 00:38:14,160
issue

00:38:10,960 --> 00:38:17,280
with uh stateful firewalls on aws

00:38:14,160 --> 00:38:20,640
uh which which uh caused us to

00:38:17,280 --> 00:38:23,440
add a um

00:38:20,640 --> 00:38:24,800
and add a feature uh slash a

00:38:23,440 --> 00:38:27,359
configuration item

00:38:24,800 --> 00:38:28,000
which allows you to tune tcp user

00:38:27,359 --> 00:38:30,160
timeout

00:38:28,000 --> 00:38:31,280
i don't know how many of you have heard

00:38:30,160 --> 00:38:36,240
of tcp user

00:38:31,280 --> 00:38:36,240
timeout as a as a

00:38:36,320 --> 00:38:43,119
kernel parameter slash

00:38:39,680 --> 00:38:46,640
tcp option uh

00:38:43,119 --> 00:38:50,480
it basically deals with unacknowledged

00:38:46,640 --> 00:38:52,880
pcp segments and and

00:38:50,480 --> 00:38:55,040
and what what happened is they

00:38:52,880 --> 00:38:58,640
encountered an issue where

00:38:55,040 --> 00:38:59,440
aws was keeping tcp connections half

00:38:58,640 --> 00:39:01,920
open

00:38:59,440 --> 00:39:02,960
and when a tcp connection is half open

00:39:01,920 --> 00:39:05,599
what that means is that

00:39:02,960 --> 00:39:07,040
uh either the sender i think on the

00:39:05,599 --> 00:39:09,040
sender or receiver side

00:39:07,040 --> 00:39:10,480
the connection remains open but there's

00:39:09,040 --> 00:39:12,720
nothing on the other side

00:39:10,480 --> 00:39:14,960
and this actually causes a lot of

00:39:12,720 --> 00:39:18,400
backlog of

00:39:14,960 --> 00:39:21,760
network packets and that is an issue for

00:39:18,400 --> 00:39:26,480
um for for folks

00:39:21,760 --> 00:39:29,599
because well the whole system

00:39:26,480 --> 00:39:30,960
depends on networking and if networking

00:39:29,599 --> 00:39:34,800
stops functioning

00:39:30,960 --> 00:39:37,680
um you run into this issue so um

00:39:34,800 --> 00:39:38,400
so i don't know the jira of the top of

00:39:37,680 --> 00:39:41,040
my head

00:39:38,400 --> 00:39:42,000
but 4.0 allows you to tune this

00:39:41,040 --> 00:39:45,920
parameter

00:39:42,000 --> 00:39:48,079
so that you don't have to deal with

00:39:45,920 --> 00:39:49,599
tcp half open issues now this is

00:39:48,079 --> 00:39:51,839
something that i don't think any of the

00:39:49,599 --> 00:39:56,320
existing techniques could catch

00:39:51,839 --> 00:39:58,960
unless you can very accurately um

00:39:56,320 --> 00:40:00,640
assimilate the network uh but even then

00:39:58,960 --> 00:40:02,720
i'm not very optimistic

00:40:00,640 --> 00:40:04,480
so uh this is only uh something that you

00:40:02,720 --> 00:40:04,800
can encounter when you actually deploy

00:40:04,480 --> 00:40:06,880
it

00:40:04,800 --> 00:40:08,800
to a real live environment and try

00:40:06,880 --> 00:40:12,079
testing cassandra

00:40:08,800 --> 00:40:13,839
so that's an example uh any other

00:40:12,079 --> 00:40:18,880
questions that i could answer

00:40:13,839 --> 00:40:18,880
uh i think we are all a little bit over

00:40:22,839 --> 00:40:26,480
time

00:40:24,880 --> 00:40:28,640
how do you test different consistency

00:40:26,480 --> 00:40:31,680
levels in cassandra um

00:40:28,640 --> 00:40:34,960
i uh um again

00:40:31,680 --> 00:40:38,240
uh there are various tests uh for

00:40:34,960 --> 00:40:41,760
for testing different consistency levels

00:40:38,240 --> 00:40:46,240
but that this is where i think uh

00:40:41,760 --> 00:40:47,920
we need more um diversity in testing

00:40:46,240 --> 00:40:50,000
uh which means uh if you're using

00:40:47,920 --> 00:40:50,400
cassandra in a very uh different way

00:40:50,000 --> 00:40:53,280
with

00:40:50,400 --> 00:40:53,760
different consistency levels then uh you

00:40:53,280 --> 00:40:56,240
would

00:40:53,760 --> 00:40:57,680
want to put this on an actual cluster

00:40:56,240 --> 00:41:00,240
and try it out

00:40:57,680 --> 00:41:02,079
and test it uh there are a lot of tests

00:41:00,240 --> 00:41:03,040
which test different consistency levels

00:41:02,079 --> 00:41:06,000
work as

00:41:03,040 --> 00:41:06,880
expected but there's no substitute for

00:41:06,000 --> 00:41:10,079
actually

00:41:06,880 --> 00:41:13,280
putting this on on a set of machines

00:41:10,079 --> 00:41:15,680
and running uh your application against

00:41:13,280 --> 00:41:16,560
uh against that cluster and ensuring

00:41:15,680 --> 00:41:20,160
that it works

00:41:16,560 --> 00:41:23,359
uh in um with the consistency levels

00:41:20,160 --> 00:41:26,480
uh that you uh that you require so

00:41:23,359 --> 00:41:29,599
um uh that's why i encourage uh

00:41:26,480 --> 00:41:30,560
try testing it by yourself uh with your

00:41:29,599 --> 00:41:33,040
application

00:41:30,560 --> 00:41:34,000
i know there are people who use very

00:41:33,040 --> 00:41:36,480
beard consistency

00:41:34,000 --> 00:41:37,440
levels and we may not actually capture

00:41:36,480 --> 00:41:39,359
this in a test

00:41:37,440 --> 00:41:40,480
but you may actually encounter this

00:41:39,359 --> 00:41:43,680
issue

00:41:40,480 --> 00:41:47,359
and edward i agree 4.0 is

00:41:43,680 --> 00:41:49,680
comprehensively tested so far

00:41:47,359 --> 00:41:50,480
all right uh so we are a few minutes

00:41:49,680 --> 00:41:52,319
over um

00:41:50,480 --> 00:41:54,400
if there is any uh question that you

00:41:52,319 --> 00:41:57,599
have you can bring me on slack

00:41:54,400 --> 00:42:00,079
apache slack um and um

00:41:57,599 --> 00:42:01,760
you know i'll be happy to answer your

00:42:00,079 --> 00:42:04,880
questions

00:42:01,760 --> 00:42:06,000
all right so thank you everybody for

00:42:04,880 --> 00:42:11,119
joining the session

00:42:06,000 --> 00:42:11,119
and hope apache con is great for all of

00:42:14,839 --> 00:42:17,839
you

00:42:25,200 --> 00:42:27,280

YouTube URL: https://www.youtube.com/watch?v=rjCVqjLRALo


