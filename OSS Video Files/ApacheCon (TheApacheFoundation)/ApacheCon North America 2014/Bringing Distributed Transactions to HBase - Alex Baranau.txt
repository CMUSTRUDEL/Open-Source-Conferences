Title: Bringing Distributed Transactions to HBase - Alex Baranau
Publication date: 2014-04-25
Playlist: ApacheCon North America 2014
Description: 
	ApacheCon North America 2014
Captions: 
	00:00:00,000 --> 00:00:06,330
so hello everyone thank you for coming

00:00:03,140 --> 00:00:11,910
how many of you have used HBase or

00:00:06,330 --> 00:00:14,610
building big data applications okay so

00:00:11,910 --> 00:00:17,850
and what do you think will you benefit

00:00:14,610 --> 00:00:23,100
from having transaction supported on top

00:00:17,850 --> 00:00:25,949
of it or or nine so what we believe is

00:00:23,100 --> 00:00:28,859
that have introduction support in many

00:00:25,949 --> 00:00:31,410
use cases will make it much simpler to

00:00:28,859 --> 00:00:32,489
go up big data application and much

00:00:31,410 --> 00:00:36,210
easier to integrate with existing

00:00:32,489 --> 00:00:37,950
systems right and the good news is you

00:00:36,210 --> 00:00:40,230
can build it on top of page base and

00:00:37,950 --> 00:00:43,559
today I'm going to share you how to do

00:00:40,230 --> 00:00:47,340
it one one way of doing that so before

00:00:43,559 --> 00:00:50,520
we get started well I work as a software

00:00:47,340 --> 00:00:53,250
engineer at continuity so I continually

00:00:50,520 --> 00:00:58,140
we build the first Hadoop application

00:00:53,250 --> 00:00:59,969
server that is man to help w offer is to

00:00:58,140 --> 00:01:04,290
build belated applications on top of the

00:00:59,969 --> 00:01:07,229
dupe and H place and then since it makes

00:01:04,290 --> 00:01:11,310
it makes easier to build applications on

00:01:07,229 --> 00:01:15,000
top of that transactions is a core part

00:01:11,310 --> 00:01:20,250
of it and it makes it easier to draw

00:01:15,000 --> 00:01:23,369
publications essentially so do what I'm

00:01:20,250 --> 00:01:26,340
going to talk about today I will briefly

00:01:23,369 --> 00:01:29,880
walk through why do we even need

00:01:26,340 --> 00:01:33,659
traductions over each page and what it

00:01:29,880 --> 00:01:35,520
is that we need from them then I will do

00:01:33,659 --> 00:01:37,409
a deep dive into the implementation how

00:01:35,520 --> 00:01:39,689
you can do it how you how you can bring

00:01:37,409 --> 00:01:42,899
it will talk about the approach will

00:01:39,689 --> 00:01:45,090
talk about the central service center

00:01:42,899 --> 00:01:49,439
management piece of lead transaction

00:01:45,090 --> 00:01:51,390
manager and also briefly cover how do

00:01:49,439 --> 00:01:56,640
you integrate transactions with one

00:01:51,390 --> 00:01:58,020
running bad shops so the application

00:01:56,640 --> 00:02:00,869
server that will build called reactive

00:01:58,020 --> 00:02:02,460
and the application is deployed to the

00:02:00,869 --> 00:02:04,650
server doing

00:02:02,460 --> 00:02:08,009
acting processing storing and serving

00:02:04,650 --> 00:02:09,750
the down right and then the real time

00:02:08,009 --> 00:02:11,790
component and that makes possible

00:02:09,750 --> 00:02:14,400
processing data in real time we call

00:02:11,790 --> 00:02:17,130
flow and consent consists of multiple

00:02:14,400 --> 00:02:20,420
folders that are connected with queues

00:02:17,130 --> 00:02:23,250
but the key thing about it is that it

00:02:20,420 --> 00:02:27,360
provides exactly one processing

00:02:23,250 --> 00:02:31,110
guarantee and then this is how it may

00:02:27,360 --> 00:02:32,640
look like so this is a flow right the

00:02:31,110 --> 00:02:34,800
green boxes are follet and they are

00:02:32,640 --> 00:02:37,200
connected with q's right so they pass

00:02:34,800 --> 00:02:39,540
data between them and then fall they can

00:02:37,200 --> 00:02:42,540
have mode one input and model outputs

00:02:39,540 --> 00:02:44,730
and at the same time what we also do is

00:02:42,540 --> 00:02:46,980
we allow users to access persistent

00:02:44,730 --> 00:02:50,160
store in every processing you need so in

00:02:46,980 --> 00:02:52,019
in this case you can access HBase right

00:02:50,160 --> 00:02:55,890
you can right attitude you can read data

00:02:52,019 --> 00:02:57,750
from it and then to make it useful you

00:02:55,890 --> 00:03:01,380
may want to have multiple phones in your

00:02:57,750 --> 00:03:03,840
system and the next thing about is about

00:03:01,380 --> 00:03:07,670
it is that they can share the data they

00:03:03,840 --> 00:03:10,079
mix it simply programming api's and

00:03:07,670 --> 00:03:13,980
makes it easier to go up applications

00:03:10,079 --> 00:03:18,930
right but then because of that the bad

00:03:13,980 --> 00:03:21,209
thing can happen right so to you follow

00:03:18,930 --> 00:03:28,620
the process indeed in real time they can

00:03:21,209 --> 00:03:31,950
conflict on the same data right so what

00:03:28,620 --> 00:03:34,320
we need from the framework is being able

00:03:31,950 --> 00:03:38,400
to detect this kind of conflict being

00:03:34,320 --> 00:03:41,489
able to handle it and in case failures

00:03:38,400 --> 00:03:43,860
happen we need to retry process in this

00:03:41,489 --> 00:03:46,170
data and still even even though the

00:03:43,860 --> 00:03:50,100
weather happens we want to have this

00:03:46,170 --> 00:03:52,920
exactly ones processing guarantee you

00:03:50,100 --> 00:03:54,630
could use everyone there is a simple way

00:03:52,920 --> 00:03:57,840
to do it you just wrap everything in one

00:03:54,630 --> 00:03:59,340
transaction right so you do continuing

00:03:57,840 --> 00:04:01,920
from the previous q you write another

00:03:59,340 --> 00:04:04,220
ques and then you access data in HBase

00:04:01,920 --> 00:04:09,540
and these old data operations are

00:04:04,220 --> 00:04:13,709
wrapped in one transaction and then of

00:04:09,540 --> 00:04:15,720
course from that you want the standard

00:04:13,709 --> 00:04:18,320
guarantees you want your data operations

00:04:15,720 --> 00:04:24,449
to be atomic consistent durable and

00:04:18,320 --> 00:04:26,970
isolated so what about HBase each piece

00:04:24,449 --> 00:04:32,060
is for those of you who don't know what

00:04:26,970 --> 00:04:37,199
is it is in non-relational distributed

00:04:32,060 --> 00:04:39,600
columnar database and it's so stated in

00:04:37,199 --> 00:04:42,150
multiple tables multiple name tables and

00:04:39,600 --> 00:04:44,000
tables consist of rows and then you can

00:04:42,150 --> 00:04:47,880
have multiple columns in a row and

00:04:44,000 --> 00:04:50,790
there's a cell that that is identified

00:04:47,880 --> 00:04:53,729
by table name row and a column right and

00:04:50,790 --> 00:04:57,330
then important thing to know about it is

00:04:53,729 --> 00:04:59,190
that you can store multiple versions of

00:04:57,330 --> 00:05:00,900
a value in the south and then you're

00:04:59,190 --> 00:05:03,270
associated with the timestamp so you can

00:05:00,900 --> 00:05:05,760
have history basically of how the value

00:05:03,270 --> 00:05:09,510
has changed right another component

00:05:05,760 --> 00:05:14,070
anybody's for for this presentation is

00:05:09,510 --> 00:05:15,960
that tables are distributed to to

00:05:14,070 --> 00:05:18,180
distributed tables well it's based as it

00:05:15,960 --> 00:05:20,940
splits and into regent and then it

00:05:18,180 --> 00:05:22,560
assigns region to region server and then

00:05:20,940 --> 00:05:26,880
there's one single region server that

00:05:22,560 --> 00:05:28,290
serves data of this region right of the

00:05:26,880 --> 00:05:29,820
table that's how the table is

00:05:28,290 --> 00:05:32,880
distributed right because it can it be a

00:05:29,820 --> 00:05:37,320
huge so that you can handle their ops

00:05:32,880 --> 00:05:43,440
button by using multiple servers in your

00:05:37,320 --> 00:05:45,990
cluster so why do we need something on

00:05:43,440 --> 00:05:48,630
top of it that that is called

00:05:45,990 --> 00:05:50,790
transactions right so each base out of

00:05:48,630 --> 00:05:53,130
the box provides very nice features and

00:05:50,790 --> 00:05:56,509
it provides some complex atomic

00:05:53,130 --> 00:05:58,580
operations like conditional check input

00:05:56,509 --> 00:06:01,169
conditional code conditional delete

00:05:58,580 --> 00:06:03,600
atomic increment and atomic append so

00:06:01,169 --> 00:06:06,870
basically you can check some value and

00:06:03,600 --> 00:06:09,540
then update another one based on result

00:06:06,870 --> 00:06:12,560
and it is atomic right on top of that

00:06:09,540 --> 00:06:15,090
you can also batch your patients and

00:06:12,560 --> 00:06:17,850
execute them atomically within single

00:06:15,090 --> 00:06:18,840
region so we can even change multiple

00:06:17,850 --> 00:06:21,960
roles of the

00:06:18,840 --> 00:06:25,770
within single region in an atomic way

00:06:21,960 --> 00:06:27,510
right but it does not provide you cross

00:06:25,770 --> 00:06:32,220
region atomic operation so when you

00:06:27,510 --> 00:06:33,600
change two rows in the table you may not

00:06:32,220 --> 00:06:35,750
necessarily know that they belong to the

00:06:33,600 --> 00:06:38,520
same region and then they could be

00:06:35,750 --> 00:06:41,400
updated independently and those

00:06:38,520 --> 00:06:43,350
suppressant won't be atomic right and of

00:06:41,400 --> 00:06:46,169
course it does not provide you cross

00:06:43,350 --> 00:06:48,690
table atomic operations and in general

00:06:46,169 --> 00:06:51,870
there is no way to do multi RPC

00:06:48,690 --> 00:06:54,479
operations atomically so for example you

00:06:51,870 --> 00:06:56,940
cannot like read one value of the row

00:06:54,479 --> 00:07:04,790
and then based on that update another

00:06:56,940 --> 00:07:07,200
one in atomic weight right so I

00:07:04,790 --> 00:07:10,500
mentioned the real-time streaming data

00:07:07,200 --> 00:07:12,479
processing use case then we need

00:07:10,500 --> 00:07:14,700
transactions for right but then there

00:07:12,479 --> 00:07:17,220
are many other cases where you also want

00:07:14,700 --> 00:07:19,380
that and just thank you complex data

00:07:17,220 --> 00:07:21,330
access pylons like for example mentioned

00:07:19,380 --> 00:07:24,300
in the previous presentation secondary

00:07:21,330 --> 00:07:26,880
indexes so in that sense in that case

00:07:24,300 --> 00:07:28,560
you usually what you do it is easy to

00:07:26,880 --> 00:07:30,000
implement in a great secondary index it

00:07:28,560 --> 00:07:33,090
is not supported out of the box but you

00:07:30,000 --> 00:07:35,400
can implement it by just touring index

00:07:33,090 --> 00:07:38,460
in the separate table right so you have

00:07:35,400 --> 00:07:39,979
two rows with original data and indexed

00:07:38,460 --> 00:07:42,690
or you can even store it in the same

00:07:39,979 --> 00:07:45,840
table but the problem with that is those

00:07:42,690 --> 00:07:50,250
operations or not atomic when you update

00:07:45,840 --> 00:07:53,700
index and original and I mean you can

00:07:50,250 --> 00:07:56,280
have inconsistent state right and then

00:07:53,700 --> 00:07:58,550
it also allows you to design for a

00:07:56,280 --> 00:08:01,610
greater performance so when you do

00:07:58,550 --> 00:08:03,930
operations what usually helps is

00:08:01,610 --> 00:08:08,520
applying them in batches so you want to

00:08:03,930 --> 00:08:11,880
update multiple rows as a single

00:08:08,520 --> 00:08:14,280
operation right so that without in a

00:08:11,880 --> 00:08:17,760
single rights of work right ahead log

00:08:14,280 --> 00:08:19,500
and it just helps you write it is faster

00:08:17,760 --> 00:08:22,349
obviously faster than doing it one by

00:08:19,500 --> 00:08:26,639
one and at the same time you want to

00:08:22,349 --> 00:08:29,310
fully use client-side buffer of H table

00:08:26,639 --> 00:08:31,230
interface and then what it does is when

00:08:29,310 --> 00:08:33,330
you do your data operations

00:08:31,230 --> 00:08:36,630
Chris your operations your rights and

00:08:33,330 --> 00:08:38,460
then when buffer is filled it is a

00:08:36,630 --> 00:08:42,479
sending these operations and with a

00:08:38,460 --> 00:08:44,370
single RPC or multiple our pcs and by

00:08:42,479 --> 00:08:46,440
that you achieve greater performance but

00:08:44,370 --> 00:08:49,350
the problem with that is it is not

00:08:46,440 --> 00:08:51,510
reliable because you mean it is in

00:08:49,350 --> 00:08:54,000
memory state so when you climb crashes

00:08:51,510 --> 00:08:58,230
use this data right and then at the same

00:08:54,000 --> 00:09:00,930
time when you flash data from them from

00:08:58,230 --> 00:09:03,420
client-side buffer it may talk to

00:09:00,930 --> 00:09:05,910
multiple regions and again you can

00:09:03,420 --> 00:09:07,800
update one region daily in one region

00:09:05,910 --> 00:09:10,830
but not another one so it is not

00:09:07,800 --> 00:09:14,910
reliable if you rub it in one

00:09:10,830 --> 00:09:17,700
transaction that makes it reliable right

00:09:14,910 --> 00:09:20,540
so how do we implement it so we use a

00:09:17,700 --> 00:09:23,040
mix of two commonly known approaches

00:09:20,540 --> 00:09:24,180
which are multi version concurrency

00:09:23,040 --> 00:09:28,170
control and optimistic concurrency

00:09:24,180 --> 00:09:30,420
control so as I mentioned before HBase

00:09:28,170 --> 00:09:35,340
allows you to store multiple versions of

00:09:30,420 --> 00:09:38,840
a cell and this is what we use so we

00:09:35,340 --> 00:09:42,030
override timestamp of a version

00:09:38,840 --> 00:09:44,040
timestamp of a cell of a value and we

00:09:42,030 --> 00:09:46,470
put transaction ID into it and this is

00:09:44,040 --> 00:09:49,620
how we do isolation so on weeds you know

00:09:46,470 --> 00:09:51,570
what are the transactions that are valid

00:09:49,620 --> 00:09:53,190
what are invalid what what you can see

00:09:51,570 --> 00:09:55,620
what you cannot see so you can basically

00:09:53,190 --> 00:09:58,440
figure the doubt right and then

00:09:55,620 --> 00:10:02,910
optimistic concurrency control it allows

00:09:58,440 --> 00:10:06,930
us to do a different league detection

00:10:02,910 --> 00:10:09,120
and we do it at commit 10 and then we

00:10:06,930 --> 00:10:13,290
roll back transaction if there's some

00:10:09,120 --> 00:10:14,430
something wrong goes right and then why

00:10:13,290 --> 00:10:17,790
do we choose optimistic concurrency

00:10:14,430 --> 00:10:19,260
control and the first one the multi

00:10:17,790 --> 00:10:20,970
version concurrency control is obvious

00:10:19,260 --> 00:10:22,530
because each page basically provides you

00:10:20,970 --> 00:10:24,900
all the teachers that you need out of

00:10:22,530 --> 00:10:27,660
the box right and then with optimistic

00:10:24,900 --> 00:10:29,520
concurrency control the reason for that

00:10:27,660 --> 00:10:33,200
is usually when you design your big data

00:10:29,520 --> 00:10:36,420
application and it is much more

00:10:33,200 --> 00:10:40,890
efficient to design it in a way that you

00:10:36,420 --> 00:10:43,630
have your daily operations have minimal

00:10:40,890 --> 00:10:45,130
conflicts by design or they even

00:10:43,630 --> 00:10:47,080
by GAD sir your partition that's a data

00:10:45,130 --> 00:10:49,930
between your processing units so that

00:10:47,080 --> 00:10:52,470
they don't conflict right so the effort

00:10:49,930 --> 00:10:58,950
put in design your application correctly

00:10:52,470 --> 00:10:58,950
it is better than guarding against bad

00:10:59,160 --> 00:11:06,640
bad data operations so locks are more

00:11:02,920 --> 00:11:07,990
expensive than that so in with

00:11:06,640 --> 00:11:10,270
optimistic concurrency control your

00:11:07,990 --> 00:11:12,040
avoid complete cost of walking right and

00:11:10,270 --> 00:11:14,790
then allows you for high-throughput and

00:11:12,040 --> 00:11:20,950
then only if you have a lot of conflicts

00:11:14,790 --> 00:11:23,920
you will be screwed so this how it all

00:11:20,950 --> 00:11:25,420
fits together so we have a central

00:11:23,920 --> 00:11:29,230
component that is transaction manager

00:11:25,420 --> 00:11:31,420
that Energy's transaction state right

00:11:29,230 --> 00:11:34,420
and you can have multiple of those so

00:11:31,420 --> 00:11:38,230
that you have higher gradually and then

00:11:34,420 --> 00:11:40,510
they are orchestrated by zookeeper and

00:11:38,230 --> 00:11:42,610
there's a client there could be multiple

00:11:40,510 --> 00:11:45,250
clients who talked to the transaction

00:11:42,610 --> 00:11:47,200
manager to get transaction state or new

00:11:45,250 --> 00:11:49,090
transactions right and then they write

00:11:47,200 --> 00:11:50,800
to hbase using the transaction

00:11:49,090 --> 00:11:55,630
information that i get from transaction

00:11:50,800 --> 00:11:58,030
manager so to get in more details let's

00:11:55,630 --> 00:12:02,530
see how Klein interacts with transaction

00:11:58,030 --> 00:12:04,960
manager so when we start transaction it

00:12:02,530 --> 00:12:07,240
talks to transaction manager and that

00:12:04,960 --> 00:12:10,590
guy starts new transaction and it puts

00:12:07,240 --> 00:12:13,360
it in in progress list internally and

00:12:10,590 --> 00:12:17,770
returns it is this information to climb

00:12:13,360 --> 00:12:20,800
right client uses this information to do

00:12:17,770 --> 00:12:23,950
the work to you update thousand a value

00:12:20,800 --> 00:12:26,230
in HBase using this transaction ID is a

00:12:23,950 --> 00:12:28,180
timestamp and then when it is done it

00:12:26,230 --> 00:12:31,480
tries to come in and for that it also

00:12:28,180 --> 00:12:33,340
talks to transaction manager and it asks

00:12:31,480 --> 00:12:37,810
to check for conflict so at that point

00:12:33,340 --> 00:12:39,760
client sends the changes our information

00:12:37,810 --> 00:12:44,010
about the changes to transaction manager

00:12:39,760 --> 00:12:47,110
now it doesn't attend all the data that

00:12:44,010 --> 00:12:49,390
like that it changes right so it's not

00:12:47,110 --> 00:12:52,900
that like all data goes to transaction

00:12:49,390 --> 00:12:55,570
manager depending on your desired level

00:12:52,900 --> 00:12:59,710
of conflict resolution you may choose

00:12:55,570 --> 00:13:01,000
you let's say send only names of the

00:12:59,710 --> 00:13:03,490
tables that you are baited and then

00:13:01,000 --> 00:13:05,860
conflict would be if two overlapping

00:13:03,490 --> 00:13:08,620
transactions updated the same table

00:13:05,860 --> 00:13:11,290
right rose in the same table then you

00:13:08,620 --> 00:13:17,020
can even like do it more fine grain and

00:13:11,290 --> 00:13:19,300
then send the row row row keys or just

00:13:17,020 --> 00:13:21,850
practices so that you can basically say

00:13:19,300 --> 00:13:23,200
I've dated this group of rows so for

00:13:21,850 --> 00:13:25,330
transaction manager it doesn't matter

00:13:23,200 --> 00:13:27,820
what are those changes so it treats them

00:13:25,330 --> 00:13:30,160
as just changes and then there's just by

00:13:27,820 --> 00:13:33,280
the race so it doesn't matter right so

00:13:30,160 --> 00:13:35,560
it gives flexibility to client to figure

00:13:33,280 --> 00:13:38,050
out what is the conflict resolution

00:13:35,560 --> 00:13:41,550
level that you want and then if

00:13:38,050 --> 00:13:45,820
everything goes well then what it does

00:13:41,550 --> 00:13:47,410
transaction manager links from in

00:13:45,820 --> 00:13:49,690
progress this this transaction into

00:13:47,410 --> 00:13:53,020
complete list and then after that it is

00:13:49,690 --> 00:13:55,540
visible to everyone after visible to all

00:13:53,020 --> 00:13:59,880
other transactions started after and

00:13:55,540 --> 00:14:02,560
then if things go bad what you do is

00:13:59,880 --> 00:14:07,180
client tries to go back all the changes

00:14:02,560 --> 00:14:09,400
that are made in a place right and so

00:14:07,180 --> 00:14:12,730
that there is no junk left behind and if

00:14:09,400 --> 00:14:15,130
that one succeeds we just move

00:14:12,730 --> 00:14:17,140
transaction incomplete list again

00:14:15,130 --> 00:14:19,660
because it is safe to do that because

00:14:17,140 --> 00:14:22,620
there's no there's no effect of this

00:14:19,660 --> 00:14:25,180
transaction in HBase left behind right

00:14:22,620 --> 00:14:28,120
but then when things go really wrong

00:14:25,180 --> 00:14:31,240
really bad when you cannot row back your

00:14:28,120 --> 00:14:32,860
changes right for example you got that

00:14:31,240 --> 00:14:36,010
you have a conflict underneath base

00:14:32,860 --> 00:14:37,660
crushes right what happens is you tell

00:14:36,010 --> 00:14:39,430
manager that ok this transaction should

00:14:37,660 --> 00:14:41,370
be invalid which is there's some junk in

00:14:39,430 --> 00:14:43,690
eight days and nobody should ever see

00:14:41,370 --> 00:14:46,750
right and then it puts in invalid least

00:14:43,690 --> 00:14:49,450
see same thing can happen when client

00:14:46,750 --> 00:14:54,070
times up so for example there is one

00:14:49,450 --> 00:14:56,020
running transaction and I need oil coin

00:14:54,070 --> 00:14:59,230
crashes right then we time out this

00:14:56,020 --> 00:15:01,630
transaction and then if it was just

00:14:59,230 --> 00:15:03,580
simply one transaction and client wakes

00:15:01,630 --> 00:15:06,130
up and tries to commit them it will go

00:15:03,580 --> 00:15:08,140
through the whole tribe or steps again

00:15:06,130 --> 00:15:10,870
and then you can also choose to row back

00:15:08,140 --> 00:15:17,620
to avoid transaction by your application

00:15:10,870 --> 00:15:22,120
logic so this is how client interact

00:15:17,620 --> 00:15:23,770
with each base so there's transaction

00:15:22,120 --> 00:15:26,350
manager right now the state is that

00:15:23,770 --> 00:15:28,089
there's a read pointer points to one

00:15:26,350 --> 00:15:32,110
thousand one and there's right pointer

00:15:28,089 --> 00:15:36,430
points to 1000 to right what it means is

00:15:32,110 --> 00:15:38,980
that all transactions up until 1001 are

00:15:36,430 --> 00:15:41,290
committed and visible and there is some

00:15:38,980 --> 00:15:44,589
data that was done by page transactions

00:15:41,290 --> 00:15:47,460
so coin first starts transaction it gets

00:15:44,589 --> 00:15:49,839
the transaction state and then

00:15:47,460 --> 00:15:52,720
transaction manager increases the right

00:15:49,839 --> 00:15:57,250
pointer and puts this transaction in

00:15:52,720 --> 00:16:00,040
progress list right crying tries to

00:15:57,250 --> 00:16:02,410
increment value in HBase and instead of

00:16:00,040 --> 00:16:06,070
changing it will append new version

00:16:02,410 --> 00:16:14,020
right and then it will use right pointer

00:16:06,070 --> 00:16:16,990
to set a time stamp for this so then one

00:16:14,020 --> 00:16:19,240
next client starts transaction you will

00:16:16,990 --> 00:16:22,000
get the same it will get the transaction

00:16:19,240 --> 00:16:24,430
state from transaction manager and then

00:16:22,000 --> 00:16:26,140
bit and then transaction manager will

00:16:24,430 --> 00:16:28,630
put in in progress give an increment

00:16:26,140 --> 00:16:32,260
right pointer based on the state that

00:16:28,630 --> 00:16:35,800
time to knows when it tries to increment

00:16:32,260 --> 00:16:39,910
the same value the same cell it will not

00:16:35,800 --> 00:16:42,550
see the one that was not simply changed

00:16:39,910 --> 00:16:45,070
made by transaction one because it was

00:16:42,550 --> 00:16:48,430
not committed yet right and then it gets

00:16:45,070 --> 00:16:51,430
it include excluded list so will

00:16:48,430 --> 00:16:53,170
increment again 10 to 11 and then we'll

00:16:51,430 --> 00:16:55,990
try to commit and that's perfectly fine

00:16:53,170 --> 00:16:59,020
right so transaction manager removes it

00:16:55,990 --> 00:17:02,200
from in progress list it is visible for

00:16:59,020 --> 00:17:05,439
everyone now one klein one tries to

00:17:02,200 --> 00:17:09,160
commit and it says 42 transaction

00:17:05,439 --> 00:17:11,199
manager than hey I did it is so music on

00:17:09,160 --> 00:17:13,870
three right there is another transaction

00:17:11,199 --> 00:17:16,350
that updated the same cell and committed

00:17:13,870 --> 00:17:16,350
before that

00:17:17,160 --> 00:17:22,140
so quite tries to roll back in this case

00:17:19,230 --> 00:17:25,650
it just removing their that it was

00:17:22,140 --> 00:17:27,570
really there is wrong way and then it

00:17:25,650 --> 00:17:29,580
was successful it talks to transaction

00:17:27,570 --> 00:17:31,800
manager and again we can remove it from

00:17:29,580 --> 00:17:34,530
in progress list and say that it is

00:17:31,800 --> 00:17:36,270
completed successfully visible to

00:17:34,530 --> 00:17:40,110
everyone because there's no jump out

00:17:36,270 --> 00:17:42,390
behind you increment read pointers so up

00:17:40,110 --> 00:17:45,570
to one thousand three all transactions

00:17:42,390 --> 00:17:48,420
are committed and then next transaction

00:17:45,570 --> 00:17:53,910
start it will see exactly the last

00:17:48,420 --> 00:17:56,040
version right so now let's get back to

00:17:53,910 --> 00:17:57,840
the situation where conflict was

00:17:56,040 --> 00:18:00,780
detected and now let's say that we're

00:17:57,840 --> 00:18:03,750
trying to roll back we failed so it

00:18:00,780 --> 00:18:07,550
weighs goes down right we talked with

00:18:03,750 --> 00:18:07,550
how transaction manager about it and

00:18:07,790 --> 00:18:18,480
transaction manager put this transaction

00:18:13,200 --> 00:18:20,460
ID into invalid list so when next

00:18:18,480 --> 00:18:22,920
transaction is started even though this

00:18:20,460 --> 00:18:31,050
gunk there but it's not visible because

00:18:22,920 --> 00:18:33,750
it is an excluded list so what is

00:18:31,050 --> 00:18:37,680
exactly that transaction manager is

00:18:33,750 --> 00:18:41,520
doing right so it creates new

00:18:37,680 --> 00:18:43,790
transactions it has to provide

00:18:41,520 --> 00:18:46,680
monotonically increasing right pointers

00:18:43,790 --> 00:18:50,070
as we saw before right so there is no

00:18:46,680 --> 00:18:52,650
overlapping it also maintains all the in

00:18:50,070 --> 00:18:55,350
progress I'll committing an invalid

00:18:52,650 --> 00:18:57,210
transactions now they can be this list

00:18:55,350 --> 00:19:01,230
can become compressed like for example

00:18:57,210 --> 00:19:03,090
for committed we don't even have to even

00:19:01,230 --> 00:19:05,070
keep this list I mean it is a logical

00:19:03,090 --> 00:19:06,690
list of committed transactions but we

00:19:05,070 --> 00:19:08,850
don't have to keep it because we say

00:19:06,690 --> 00:19:12,000
that okay up to this read pointer if

00:19:08,850 --> 00:19:15,300
transaction is not invalid then it is

00:19:12,000 --> 00:19:19,440
visible right it is committed then what

00:19:15,300 --> 00:19:23,070
it does also it detects conflict right

00:19:19,440 --> 00:19:25,650
and the transaction that is provided to

00:19:23,070 --> 00:19:27,840
decline by transaction manager consists

00:19:25,650 --> 00:19:28,809
of three key pieces it is right pointer

00:19:27,840 --> 00:19:31,809
read pointer and X cool

00:19:28,809 --> 00:19:35,470
as we saw on the example before now the

00:19:31,809 --> 00:19:37,779
state now the good thing about the

00:19:35,470 --> 00:19:41,590
transaction manager is it is simple and

00:19:37,779 --> 00:19:43,870
fast so it keeps all the data that is

00:19:41,590 --> 00:19:46,600
needed for providing new transactions in

00:19:43,870 --> 00:19:48,610
memory and the reason why it can do that

00:19:46,600 --> 00:19:52,769
is because you basically your

00:19:48,610 --> 00:19:55,149
transaction state is bounded by how many

00:19:52,769 --> 00:19:57,070
transactions you can have in progress at

00:19:55,149 --> 00:19:59,499
the same moment and then you usually

00:19:57,070 --> 00:20:01,570
don't have over a couple hundred

00:19:59,499 --> 00:20:04,559
thousands or a million transactions at

00:20:01,570 --> 00:20:08,950
the same time so you can spare some

00:20:04,559 --> 00:20:12,070
memory for that right so it is super

00:20:08,950 --> 00:20:15,850
fast because it is in memory but at the

00:20:12,070 --> 00:20:17,649
same time though even though it is it

00:20:15,850 --> 00:20:20,320
keep stayed in memory it is not a single

00:20:17,649 --> 00:20:24,549
point of failure it writes right ahead

00:20:20,320 --> 00:20:27,639
wad similar to what HBase does on the

00:20:24,549 --> 00:20:30,210
right path so so that there is a

00:20:27,639 --> 00:20:35,139
secondary transaction manager that can

00:20:30,210 --> 00:20:38,080
overtake if there is a failure in the

00:20:35,139 --> 00:20:43,840
primary one right and then fell over

00:20:38,080 --> 00:20:47,559
will happen quickly now this is this how

00:20:43,840 --> 00:20:50,379
how it looks like so transaction starts

00:20:47,559 --> 00:20:52,749
we change the internal stay of

00:20:50,379 --> 00:20:54,610
transaction manager in this case we

00:20:52,749 --> 00:20:55,929
increment right pointer and we put

00:20:54,610 --> 00:20:59,019
transaction in progress and we're ready

00:20:55,929 --> 00:21:03,190
to transaction log and transaction log

00:20:59,019 --> 00:21:05,919
is located in HDFS so we can say that is

00:21:03,190 --> 00:21:09,970
reliably story right and then any others

00:21:05,919 --> 00:21:13,809
can access it same thing happens when

00:21:09,970 --> 00:21:15,700
commit again we update current state of

00:21:13,809 --> 00:21:18,600
transaction manager which is in memory

00:21:15,700 --> 00:21:20,649
and right Eddie to HDFS right and then

00:21:18,600 --> 00:21:23,220
using the transaction log another

00:21:20,649 --> 00:21:28,440
secondary transaction manager can

00:21:23,220 --> 00:21:31,619
restore the state any point of time now

00:21:28,440 --> 00:21:36,240
transaction log provides persistence and

00:21:31,619 --> 00:21:38,100
this is how we make a reliable rain and

00:21:36,240 --> 00:21:42,300
it going to use point in time recovery

00:21:38,100 --> 00:21:44,610
but at the same time the longer you run

00:21:42,300 --> 00:21:46,230
your transaction manager the bigger log

00:21:44,610 --> 00:21:49,920
you have and in case of failure you have

00:21:46,230 --> 00:21:53,640
to process it all all at once and then

00:21:49,920 --> 00:21:56,370
recovery will be really slow so what we

00:21:53,640 --> 00:21:58,290
do is we periodically right snapshots of

00:21:56,370 --> 00:22:00,990
full transaction state and again it is

00:21:58,290 --> 00:22:04,080
pretty fast to do we can do it as

00:22:00,990 --> 00:22:09,240
synchronously I will show it on the next

00:22:04,080 --> 00:22:11,340
picture how and it is as fast because it

00:22:09,240 --> 00:22:15,840
is just a memory state so it is pretty

00:22:11,340 --> 00:22:17,850
small I mean so after that did snapshot

00:22:15,840 --> 00:22:19,650
class all the logs they are reading

00:22:17,850 --> 00:22:23,280
after snapshotting can be used to

00:22:19,650 --> 00:22:27,870
restore the state at least what happens

00:22:23,280 --> 00:22:29,970
so you rotate walks periodically let's

00:22:27,870 --> 00:22:31,800
say we wrote to transaction log a and

00:22:29,970 --> 00:22:34,650
then we're right in to transaction log B

00:22:31,800 --> 00:22:37,440
and at the same time what we are doing

00:22:34,650 --> 00:22:38,730
is we're creating snapshot this is the

00:22:37,440 --> 00:22:40,370
only synchronous operation so we're

00:22:38,730 --> 00:22:42,600
rotating staff and creating the

00:22:40,370 --> 00:22:44,730
in-memory snapshot but it is in memory

00:22:42,600 --> 00:22:47,640
so it is pretty fast right to copy data

00:22:44,730 --> 00:22:50,429
in memory and then at this point of time

00:22:47,640 --> 00:22:52,260
once we created it the transaction

00:22:50,429 --> 00:22:54,450
manager is still continues to handle

00:22:52,260 --> 00:22:57,870
requests from clients it will just write

00:22:54,450 --> 00:23:00,059
data to transaction log B so there's no

00:22:57,870 --> 00:23:02,700
delay on the client side and then we

00:23:00,059 --> 00:23:11,190
write to a transaction snapshot to HD

00:23:02,700 --> 00:23:12,630
offense right and it is fine if we fail

00:23:11,190 --> 00:23:16,559
to write if it breaks in the middle

00:23:12,630 --> 00:23:19,440
before we ready to before we write

00:23:16,559 --> 00:23:21,090
transaction snapshot in HDFS because in

00:23:19,440 --> 00:23:23,429
that case we will have just two words

00:23:21,090 --> 00:23:26,309
right to recover the state and the

00:23:23,429 --> 00:23:28,890
previous snapshot so after this when it

00:23:26,309 --> 00:23:32,570
is done then we can remove the first

00:23:28,890 --> 00:23:38,370
walk because it's not needed anymore

00:23:32,570 --> 00:23:41,190
right so let's get back to one situation

00:23:38,370 --> 00:23:43,860
where we try to row back data but we

00:23:41,190 --> 00:23:45,200
fail to do that right so we left some

00:23:43,860 --> 00:23:49,730
junk behind in HBase

00:23:45,200 --> 00:23:52,190
and living JUNK behind is not cool if

00:23:49,730 --> 00:23:54,230
you run your system for years you will

00:23:52,190 --> 00:23:56,990
accumulate a lot of junk right so you

00:23:54,230 --> 00:24:01,370
have to clean it up somehow and then

00:23:56,990 --> 00:24:04,490
what we do is we have a component that

00:24:01,370 --> 00:24:07,010
is data janitor the dust transactions on

00:24:04,490 --> 00:24:12,740
clean up and it is a region observer

00:24:07,010 --> 00:24:15,200
coprocessor right so it uses snapshot of

00:24:12,740 --> 00:24:16,880
transaction state that we're eating by

00:24:15,200 --> 00:24:18,860
transaction manager and the frequency of

00:24:16,880 --> 00:24:22,669
that is cut every like five minutes

00:24:18,860 --> 00:24:25,490
right and then it really clear basis so

00:24:22,669 --> 00:24:32,120
it keeps more or less recent one and it

00:24:25,490 --> 00:24:36,590
produced data while we do monster flash

00:24:32,120 --> 00:24:39,940
or compaction and then it is fine to be

00:24:36,590 --> 00:24:42,230
a little bit to have little bit stale

00:24:39,940 --> 00:24:45,769
snapshot of transaction stay because

00:24:42,230 --> 00:24:47,960
eventually what HBase does it performs

00:24:45,769 --> 00:24:50,120
Compassion's over and over again so you

00:24:47,960 --> 00:24:52,580
will rewrite your data multiple times so

00:24:50,120 --> 00:24:54,529
at some point of time you will get back

00:24:52,580 --> 00:24:58,669
to your data do major compaction and it

00:24:54,529 --> 00:25:00,470
will clean up the data alright so this

00:24:58,669 --> 00:25:03,980
how it happens there's a transaction

00:25:00,470 --> 00:25:06,230
snapshot on HDFS the data generator gets

00:25:03,980 --> 00:25:08,149
this information and then let's say we

00:25:06,230 --> 00:25:11,980
have in mem store we have these three

00:25:08,149 --> 00:25:11,980
records and we are going to flash them

00:25:12,639 --> 00:25:18,289
so we put this core processor in pre

00:25:16,279 --> 00:25:24,230
flash hook the same way we put it in a

00:25:18,289 --> 00:25:26,240
pre in compaction and then that one

00:25:24,230 --> 00:25:27,799
creates a custom region scanner so

00:25:26,240 --> 00:25:30,080
basically all data goes through this

00:25:27,799 --> 00:25:31,970
core processor and this guy decides what

00:25:30,080 --> 00:25:34,519
you actually proceed and what you not to

00:25:31,970 --> 00:25:37,100
participate and then in this case if we

00:25:34,519 --> 00:25:40,370
look at the first one this one is

00:25:37,100 --> 00:25:42,289
distance rod this data is reading by

00:25:40,370 --> 00:25:45,740
transaction that is still in progress so

00:25:42,289 --> 00:25:47,389
we have two ugly right the next one is

00:25:45,740 --> 00:25:50,029
reading by transaction that was

00:25:47,389 --> 00:25:54,860
committed successfully again we ready

00:25:50,029 --> 00:25:57,230
and then the third one is invalid it is

00:25:54,860 --> 00:25:58,910
a junk and this is why we do this whole

00:25:57,230 --> 00:26:04,050
cleanup so we don't don't

00:25:58,910 --> 00:26:07,380
and then after that my story goes away

00:26:04,050 --> 00:26:14,100
and then there's no John behind left

00:26:07,380 --> 00:26:16,380
behind in persistent data right but it's

00:26:14,100 --> 00:26:18,500
not only the junk of invalid

00:26:16,380 --> 00:26:21,780
transactions that we try to clean up

00:26:18,500 --> 00:26:25,190
what you also want to do an indirect you

00:26:21,780 --> 00:26:28,770
use cases where you update heavily

00:26:25,190 --> 00:26:32,160
values the same value the same cell in

00:26:28,770 --> 00:26:35,730
your application and then because the

00:26:32,160 --> 00:26:39,720
way we do right it is an append it is a

00:26:35,730 --> 00:26:41,520
new value right so in case of heavily

00:26:39,720 --> 00:26:47,880
updates like for example counters you

00:26:41,520 --> 00:26:51,060
will create a huge log of values in for

00:26:47,880 --> 00:26:53,250
this out right so what usually people do

00:26:51,060 --> 00:26:56,520
is decide the maximum number of versions

00:26:53,250 --> 00:26:59,760
to keep in HBase right in for this table

00:26:56,520 --> 00:27:01,500
for this column family and it is not

00:26:59,760 --> 00:27:03,960
possible to do that here because we

00:27:01,500 --> 00:27:06,270
don't know I mean there's no restriction

00:27:03,960 --> 00:27:07,680
on how many operations how many

00:27:06,270 --> 00:27:10,500
transactions that could be in progress

00:27:07,680 --> 00:27:13,560
so you may have 11 running transaction

00:27:10,500 --> 00:27:16,740
and it keeps others work in progress and

00:27:13,560 --> 00:27:20,340
then you can it could be fine to have

00:27:16,740 --> 00:27:22,710
more than I know dozens of versions

00:27:20,340 --> 00:27:24,480
reading by in progress transactions that

00:27:22,710 --> 00:27:27,690
are right now they're so there's just no

00:27:24,480 --> 00:27:30,650
way to bound it somehow but the same

00:27:27,690 --> 00:27:34,370
time we want to clean up right and then

00:27:30,650 --> 00:27:37,050
the way we clean it up the logic is

00:27:34,370 --> 00:27:38,340
keeping at most one version of a saw

00:27:37,050 --> 00:27:42,630
that is visible to all other

00:27:38,340 --> 00:27:44,700
transactions right and then we can plug

00:27:42,630 --> 00:27:47,130
in this logic into the same core

00:27:44,700 --> 00:27:51,240
processor did a clean up core processor

00:27:47,130 --> 00:27:53,610
so how it happens when you go in region

00:27:51,240 --> 00:27:55,560
scanner you start with most recent

00:27:53,610 --> 00:27:58,890
version and then if you decide that okay

00:27:55,560 --> 00:28:00,300
this version is visible for Ultron or

00:27:58,890 --> 00:28:02,760
all transactions that are currently

00:28:00,300 --> 00:28:06,690
running then whatever else coming after

00:28:02,760 --> 00:28:09,540
it will just remove it right it is a

00:28:06,690 --> 00:28:11,080
little bit tricky you have to keep for

00:28:09,540 --> 00:28:14,830
every transaction

00:28:11,080 --> 00:28:17,890
what is the upper visibility bond so

00:28:14,830 --> 00:28:22,000
basically what what is the transaction

00:28:17,890 --> 00:28:24,789
ID that it uses as a read pointer right

00:28:22,000 --> 00:28:27,700
because you can have right now you can

00:28:24,789 --> 00:28:31,029
say the system state is that the real

00:28:27,700 --> 00:28:33,490
point is up to they say 11 thousand five

00:28:31,029 --> 00:28:36,279
right but there is still one transaction

00:28:33,490 --> 00:28:38,380
that is in progress that is reading some

00:28:36,279 --> 00:28:41,049
older versions right so we have to keep

00:28:38,380 --> 00:28:45,130
it for all of them but is a small piece

00:28:41,049 --> 00:28:47,080
of data it is just one pointer right so

00:28:45,130 --> 00:28:49,539
you can you keep a global one and then

00:28:47,080 --> 00:28:53,580
you based on the minimum of this upper

00:28:49,539 --> 00:29:02,529
visibility bank you you can do cleanup

00:28:53,580 --> 00:29:04,510
now another important thing is with this

00:29:02,529 --> 00:29:08,139
approach what on the biggest problem

00:29:04,510 --> 00:29:10,029
when people do it is that you screw up

00:29:08,139 --> 00:29:12,580
the timestamps of each place right and

00:29:10,029 --> 00:29:16,110
then there is a native features of HBase

00:29:12,580 --> 00:29:19,600
that are very useful that rely on this

00:29:16,110 --> 00:29:23,049
timestamp to be like real time stamp

00:29:19,600 --> 00:29:25,779
right for example TTL teacher and the

00:29:23,049 --> 00:29:28,269
TTL feature allows you to say okay to

00:29:25,779 --> 00:29:31,870
say how long have you want to keep your

00:29:28,269 --> 00:29:33,460
data so let's say you say okay I care

00:29:31,870 --> 00:29:35,529
about this data for two years for two

00:29:33,460 --> 00:29:37,690
days and then after two days if it is

00:29:35,529 --> 00:29:42,490
too old and HBase will automatically

00:29:37,690 --> 00:29:44,440
clean it up right so since we hijack

00:29:42,490 --> 00:29:47,110
timestamps and this is what hbase uses

00:29:44,440 --> 00:29:49,659
for clean cleaning up it is broken right

00:29:47,110 --> 00:29:52,929
at the same time the natural the obvious

00:29:49,659 --> 00:29:54,880
way to fix it is okay let's just line

00:29:52,929 --> 00:29:56,830
transaction it is with timestamps right

00:29:54,880 --> 00:29:58,539
but you cannot do that because you want

00:29:56,830 --> 00:30:01,210
to be able to do more than 1,000

00:29:58,539 --> 00:30:04,240
transactions per second right and then

00:30:01,210 --> 00:30:06,000
each base uses milliseconds as a

00:30:04,240 --> 00:30:08,679
timestamp so you can have only one

00:30:06,000 --> 00:30:13,240
thousand different time stamps in one

00:30:08,679 --> 00:30:18,159
second so here what we do we encode

00:30:13,240 --> 00:30:21,639
timestamps in transaction ID right and

00:30:18,159 --> 00:30:22,540
then for that what we do is transaction

00:30:21,639 --> 00:30:25,660
ID is

00:30:22,540 --> 00:30:27,580
x 10 x 1,000,000 and there's in

00:30:25,660 --> 00:30:30,970
millisecond counter so that you can have

00:30:27,580 --> 00:30:33,160
multiple transactions within the same

00:30:30,970 --> 00:30:36,040
millisecond right and then it gives you

00:30:33,160 --> 00:30:37,900
ability to have more than not more than

00:30:36,040 --> 00:30:40,840
but exactly 1 billion transactions per

00:30:37,900 --> 00:30:43,150
second which is I guess enough for many

00:30:40,840 --> 00:30:45,880
systems and then you will have one value

00:30:43,150 --> 00:30:48,400
over for in 200 years which is hopefully

00:30:45,880 --> 00:30:52,510
will be there by that time but we will

00:30:48,400 --> 00:30:55,000
do with that right so at the same time

00:30:52,510 --> 00:30:59,440
we do not we turn off TTL feature of

00:30:55,000 --> 00:31:02,050
HBase because if it uses x times that we

00:30:59,440 --> 00:31:08,340
hijacked then it may produce some bad

00:31:02,050 --> 00:31:12,820
things right so we again plug in this

00:31:08,340 --> 00:31:14,950
clean up in the same coprocessor since

00:31:12,820 --> 00:31:18,970
we already have alldata commentary is

00:31:14,950 --> 00:31:21,150
easy to do it and it is applied on

00:31:18,970 --> 00:31:23,860
Compassion's and I'm store flash and

00:31:21,150 --> 00:31:26,950
what we also do what you also have to do

00:31:23,860 --> 00:31:28,900
is apply this TTL logic on Reed's right

00:31:26,950 --> 00:31:31,900
so each base will not do it for you

00:31:28,900 --> 00:31:34,560
because TDL feature is turned off right

00:31:31,900 --> 00:31:34,560
so you have to do

00:31:40,179 --> 00:31:48,090
so one last thing that I'm going to talk

00:31:45,610 --> 00:31:51,249
about is how do we do transactions and

00:31:48,090 --> 00:31:54,190
how do we integrate with bad jobs so the

00:31:51,249 --> 00:31:57,220
so far what I was talking about is a

00:31:54,190 --> 00:32:00,279
project that is very nice for short

00:31:57,220 --> 00:32:02,169
transactions and something you would

00:32:00,279 --> 00:32:04,509
probably have in real-time data

00:32:02,169 --> 00:32:05,889
processing right but then when you do

00:32:04,509 --> 00:32:07,179
with patch and you want to share the

00:32:05,889 --> 00:32:10,119
same layer between your real-time

00:32:07,179 --> 00:32:12,909
processing pipeline and batch processing

00:32:10,119 --> 00:32:14,799
right you I mean if you have if you want

00:32:12,909 --> 00:32:17,590
to share the data you have to somehow

00:32:14,799 --> 00:32:19,539
integrate that and the problems are bad

00:32:17,590 --> 00:32:22,179
jobs are one running it is completely

00:32:19,539 --> 00:32:24,789
different from what you have in real

00:32:22,179 --> 00:32:29,999
time right and another problem is that

00:32:24,789 --> 00:32:29,999
our jobs are multi stop and then

00:32:30,090 --> 00:32:36,909
individuals tab can be restarted by the

00:32:32,679 --> 00:32:38,499
framework if it fails and this is one of

00:32:36,909 --> 00:32:40,179
the biggest reasons why why do you want

00:32:38,499 --> 00:32:43,539
to have transactions when you do when

00:32:40,179 --> 00:32:46,029
you run bad jobs when you do for example

00:32:43,539 --> 00:32:49,059
MapReduce job right and you read it it

00:32:46,029 --> 00:32:53,679
to you updated in HBase it is very

00:32:49,059 --> 00:32:55,899
tricky so you either make sure that your

00:32:53,679 --> 00:32:58,269
operations are I dumped it in so that if

00:32:55,899 --> 00:33:00,399
you restart the same task in case of

00:32:58,269 --> 00:33:03,309
failure then we'll write the same data

00:33:00,399 --> 00:33:07,539
but even in that case it is tricky

00:33:03,309 --> 00:33:09,940
because when your job fails then you

00:33:07,539 --> 00:33:13,690
still have data left behind right and

00:33:09,940 --> 00:33:15,549
you have to to make your data consistent

00:33:13,690 --> 00:33:17,470
you have to make sure that you start the

00:33:15,549 --> 00:33:20,080
same job again so that it produces the

00:33:17,470 --> 00:33:22,149
same data with writing the same items

00:33:20,080 --> 00:33:24,279
and operations that will produce exactly

00:33:22,149 --> 00:33:26,889
the same data right but in many cases

00:33:24,279 --> 00:33:29,230
you want to have increments in your bad

00:33:26,889 --> 00:33:32,019
jobs right an increment oppression is

00:33:29,230 --> 00:33:33,610
not a dominant so it would be cool to be

00:33:32,019 --> 00:33:36,669
able to wrap it in silent inside

00:33:33,610 --> 00:33:39,720
transactions right at the same time

00:33:36,669 --> 00:33:43,899
every step has to be isolated so you

00:33:39,720 --> 00:33:45,580
inside your map task or reduced ask you

00:33:43,899 --> 00:33:46,960
want to see what was reading by this

00:33:45,580 --> 00:33:48,519
task right but you don't want to see

00:33:46,960 --> 00:33:51,539
what what others are reading because

00:33:48,519 --> 00:33:51,539
they can sail right

00:33:54,580 --> 00:34:01,250
so it is very very expensive to detect

00:33:59,180 --> 00:34:05,600
conflicts for bad jobs because it just

00:34:01,250 --> 00:34:07,820
affects a lot of data right so and then

00:34:05,600 --> 00:34:09,620
even if you detect conflicts right even

00:34:07,820 --> 00:34:14,090
if you have the system in place the

00:34:09,620 --> 00:34:16,370
detect conflict it is very inefficient

00:34:14,090 --> 00:34:18,830
to row back to make this transaction

00:34:16,370 --> 00:34:21,620
invalid to make this job invalid because

00:34:18,830 --> 00:34:23,960
you probably ran it for and in a couple

00:34:21,620 --> 00:34:25,760
hours or maybe days and then there is

00:34:23,960 --> 00:34:28,370
some conflict because there's someone

00:34:25,760 --> 00:34:31,040
wrote some value in one row that was

00:34:28,370 --> 00:34:33,530
also affected by this man pages job and

00:34:31,040 --> 00:34:37,360
then you probably back altogether so for

00:34:33,530 --> 00:34:37,360
that what usually people want is a

00:34:37,780 --> 00:34:45,560
policy how who wins right so we do not

00:34:40,970 --> 00:34:48,230
do conflict resolution here and whatever

00:34:45,560 --> 00:34:49,730
transaction that started later and

00:34:48,230 --> 00:34:53,750
committed successfully will just

00:34:49,730 --> 00:34:57,139
override this data right at the same

00:34:53,750 --> 00:35:01,160
time if it is very expensive to roll

00:34:57,139 --> 00:35:04,730
back wherever HBase whatever your batch

00:35:01,160 --> 00:35:06,410
job did my job did in HBase in case of

00:35:04,730 --> 00:35:10,010
failure right because you have one of

00:35:06,410 --> 00:35:11,870
maybe random reads so it is expensive in

00:35:10,010 --> 00:35:13,820
case of real-time processing you have

00:35:11,870 --> 00:35:15,950
probably couple rights and you can roll

00:35:13,820 --> 00:35:18,760
them back and it's fine but in case of

00:35:15,950 --> 00:35:20,900
bad job it is a lot right and then you

00:35:18,760 --> 00:35:24,850
don't want to keep track of what you

00:35:20,900 --> 00:35:29,780
changed right so in this case you defer

00:35:24,850 --> 00:35:33,410
rollback of failed transactions right or

00:35:29,780 --> 00:35:35,570
failed jobs and then again you market

00:35:33,410 --> 00:35:37,610
always if you have it if you want to

00:35:35,570 --> 00:35:40,360
avoid it you always put an invalid list

00:35:37,610 --> 00:35:43,130
and then transaction cleanup coprocessor

00:35:40,360 --> 00:35:47,900
will do the job for you so you don't do

00:35:43,130 --> 00:35:50,480
it right away right and so for now what

00:35:47,900 --> 00:35:55,550
we do is we wrap the whole job inside

00:35:50,480 --> 00:35:58,040
one transaction right what we want to do

00:35:55,550 --> 00:35:59,750
in future is to have support from nested

00:35:58,040 --> 00:36:03,530
transactions so these are the

00:35:59,750 --> 00:36:05,160
transactions that you that performs in

00:36:03,530 --> 00:36:09,059
isolation so you see the change

00:36:05,160 --> 00:36:10,890
is performed by each transaction each

00:36:09,059 --> 00:36:13,710
child transaction but not necessarily

00:36:10,890 --> 00:36:20,700
another one and then they are committed

00:36:13,710 --> 00:36:25,319
as a whole at the same time and this is

00:36:20,700 --> 00:36:27,000
the last piece right so important

00:36:25,319 --> 00:36:28,980
question is what is the overhead of

00:36:27,000 --> 00:36:31,559
having this transaction right on top of

00:36:28,980 --> 00:36:33,599
HBase so you do your rights and then in

00:36:31,559 --> 00:36:36,299
HBase in your applications and then you

00:36:33,599 --> 00:36:38,579
think okay it makes my application much

00:36:36,299 --> 00:36:40,650
simpler if i use transactions so they

00:36:38,579 --> 00:36:43,170
don't have to figure out how to sync how

00:36:40,650 --> 00:36:45,270
to rebuild your indexes and stuff like

00:36:43,170 --> 00:36:48,140
that so we'll just use transaction but

00:36:45,270 --> 00:36:50,309
what is the price for it and the cost is

00:36:48,140 --> 00:36:53,000
basically what it boils down to is to

00:36:50,309 --> 00:36:55,710
RPC calls right per transaction and

00:36:53,000 --> 00:36:58,260
these are just networking calls talking

00:36:55,710 --> 00:37:00,930
to transaction manager this is in good

00:36:58,260 --> 00:37:03,900
scenario so you have start transaction

00:37:00,930 --> 00:37:05,460
and commit one right and then what

00:37:03,900 --> 00:37:07,799
transaction manager does it perform

00:37:05,460 --> 00:37:09,869
stuff in memory so it is pretty fast I

00:37:07,799 --> 00:37:12,390
mean returns pretty fast and even though

00:37:09,869 --> 00:37:13,920
it right ready headlock it's seeing if

00:37:12,390 --> 00:37:16,770
you have multiple clients and this is

00:37:13,920 --> 00:37:20,430
what you usually have and then they are

00:37:16,770 --> 00:37:23,369
doing our pcs in parallel so when it

00:37:20,430 --> 00:37:26,490
updates right ahead walk it applies the

00:37:23,369 --> 00:37:28,619
batch of those changes to edit lock from

00:37:26,490 --> 00:37:31,230
multiple clients so if you have one kind

00:37:28,619 --> 00:37:34,440
talking one by one then yeah you will

00:37:31,230 --> 00:37:35,970
have like cereal rise to right ahead one

00:37:34,440 --> 00:37:38,970
but if you have multiple clients it will

00:37:35,970 --> 00:37:44,490
be committed many of those will be

00:37:38,970 --> 00:37:48,299
committed as a whole right so what you

00:37:44,490 --> 00:37:50,369
also can do is you can improve this you

00:37:48,299 --> 00:37:53,789
can reduce this overhand by using

00:37:50,369 --> 00:37:57,289
batching so you may want to do more

00:37:53,789 --> 00:37:59,880
operations per transaction right so it's

00:37:57,289 --> 00:38:02,660
perfectly fine in many cases to do 800

00:37:59,880 --> 00:38:04,950
processing hundred inputs in what your

00:38:02,660 --> 00:38:09,569
streaming data processing pipeline so

00:38:04,950 --> 00:38:13,289
that you do less transactions right at

00:38:09,569 --> 00:38:16,230
the same time you can also request or

00:38:13,289 --> 00:38:18,099
you can request multiple transactions at

00:38:16,230 --> 00:38:21,640
the same time so let's say you have

00:38:18,099 --> 00:38:24,249
one client that is working and you want

00:38:21,640 --> 00:38:25,739
you want to you know that it is

00:38:24,249 --> 00:38:28,210
processed in real time when it does

00:38:25,739 --> 00:38:30,220
hundreds operations per second then you

00:38:28,210 --> 00:38:32,440
can say okay give me hundred transaction

00:38:30,220 --> 00:38:34,930
start hundred transactions and then that

00:38:32,440 --> 00:38:38,319
will be one RPC call and it will be one

00:38:34,930 --> 00:38:40,089
heat into the redhead log and then you

00:38:38,319 --> 00:38:46,390
will commit it at the same time all of

00:38:40,089 --> 00:38:50,079
them together as well so one thing that

00:38:46,390 --> 00:38:51,999
is nice about this approach is that you

00:38:50,079 --> 00:38:55,509
can relax transactional grantees by

00:38:51,999 --> 00:38:57,940
simply not talking to transaction

00:38:55,509 --> 00:39:00,279
manager and writing your data in each

00:38:57,940 --> 00:39:03,130
place and without it changing the data

00:39:00,279 --> 00:39:04,569
format so all you need to do is when

00:39:03,130 --> 00:39:06,690
reading you just reading the way

00:39:04,569 --> 00:39:09,849
dispersion so you mean you don't care if

00:39:06,690 --> 00:39:11,499
it was not committed yard or stuff like

00:39:09,849 --> 00:39:12,999
that so I mean if you're relaxing

00:39:11,499 --> 00:39:14,920
transactional guarantees but you can

00:39:12,999 --> 00:39:17,049
read this data right and then at the

00:39:14,920 --> 00:39:18,999
same time when you write you only make

00:39:17,049 --> 00:39:23,859
sure that whatever you write the

00:39:18,999 --> 00:39:25,960
timestamp is aligned with transaction ID

00:39:23,859 --> 00:39:33,269
is that we generate so the TTL feature

00:39:25,960 --> 00:39:35,979
is applied as well so what's next to it

00:39:33,269 --> 00:39:39,249
we are considering to making this open

00:39:35,979 --> 00:39:41,499
source so at continuity we build teams

00:39:39,249 --> 00:39:43,630
for ourselves for project for our

00:39:41,499 --> 00:39:46,769
flagship product which is stated

00:39:43,630 --> 00:39:49,180
platform right and then what we do is we

00:39:46,769 --> 00:39:50,890
extract reusable pieces and make them

00:39:49,180 --> 00:39:53,349
open source one of those things for

00:39:50,890 --> 00:39:56,859
example is a patch it will project we

00:39:53,349 --> 00:40:00,640
contributed that makes it easier to run

00:39:56,859 --> 00:40:02,380
applications on top of twill right so we

00:40:00,640 --> 00:40:04,799
are considering to open sourcing this

00:40:02,380 --> 00:40:04,799
piece as well

00:40:07,580 --> 00:40:11,790
then one thing that we want to do also

00:40:10,110 --> 00:40:14,310
is we want to continue scaling

00:40:11,790 --> 00:40:16,590
transaction manager even though right

00:40:14,310 --> 00:40:17,910
now is not a bottleneck in I mean we

00:40:16,590 --> 00:40:20,100
haven't seen an application that is

00:40:17,910 --> 00:40:21,350
about bottleneck because because of

00:40:20,100 --> 00:40:24,150
these all techniques that you can apply

00:40:21,350 --> 00:40:26,910
like batching and stuff right at the

00:40:24,150 --> 00:40:29,990
same time we want to have more scalable

00:40:26,910 --> 00:40:32,850
approach right we want to probably group

00:40:29,990 --> 00:40:36,180
transactions and then assign these

00:40:32,850 --> 00:40:38,010
groups to specific nodes in your cluster

00:40:36,180 --> 00:40:41,790
to specific transaction managers so that

00:40:38,010 --> 00:40:43,890
they're handled in Scoble way and then

00:40:41,790 --> 00:40:45,330
if you think about this reproach about

00:40:43,890 --> 00:40:48,660
this transaction manager it is not

00:40:45,330 --> 00:40:50,490
actually specific for each base right so

00:40:48,660 --> 00:40:52,590
what it cares about is this changes IDs

00:40:50,490 --> 00:40:55,230
which are by the Rays and managing

00:40:52,590 --> 00:40:58,020
transactions so what we are doing is we

00:40:55,230 --> 00:41:01,350
are integrating other data stores for

00:40:58,020 --> 00:41:04,590
example like running into files on HDFS

00:41:01,350 --> 00:41:08,850
and also supporting other other data

00:41:04,590 --> 00:41:11,190
stores you know basically whatever can

00:41:08,850 --> 00:41:19,770
support two phase commit can be

00:41:11,190 --> 00:41:21,450
integrated so to to wrap up having

00:41:19,770 --> 00:41:23,430
transactions make it easier to develop

00:41:21,450 --> 00:41:25,800
big data applications on top of each

00:41:23,430 --> 00:41:32,640
page and this is just one way of doing

00:41:25,800 --> 00:41:33,990
that so you try out why and if you have

00:41:32,640 --> 00:41:36,380
any questions that will be happy to

00:41:33,990 --> 00:41:36,380
answer them

00:41:43,650 --> 00:41:49,869
so does it mean that Oh again you

00:41:48,490 --> 00:41:53,080
mentioned earlier transaction was on the

00:41:49,869 --> 00:41:55,240
bench and does it mean that you sort of

00:41:53,080 --> 00:41:59,200
trying to change the semantics of a

00:41:55,240 --> 00:42:00,820
batch because what I'm talking about is

00:41:59,200 --> 00:42:02,619
that by page consists of multiple

00:42:00,820 --> 00:42:06,010
operations right so you trying to update

00:42:02,619 --> 00:42:07,720
multiple regions right and in case of

00:42:06,010 --> 00:42:10,000
transactions if I am trying to do the

00:42:07,720 --> 00:42:11,950
transactional badge it means that if

00:42:10,000 --> 00:42:14,619
something goes wrong I would be able to

00:42:11,950 --> 00:42:16,330
roll backwards in traditional badge some

00:42:14,619 --> 00:42:19,150
of the row of these can go through and

00:42:16,330 --> 00:42:21,130
some cannot right so it sort of can can

00:42:19,150 --> 00:42:23,950
partially succeed so what you tryin to

00:42:21,130 --> 00:42:26,109
have is an atomic weight right is it is

00:42:23,950 --> 00:42:27,670
it really direct descendant right I mean

00:42:26,109 --> 00:42:29,109
you understand it correctly it's just

00:42:27,670 --> 00:42:32,080
that we don't change the semantics of

00:42:29,109 --> 00:42:35,290
bad job of my business job these medical

00:42:32,080 --> 00:42:38,320
if you think about it it was development

00:42:35,290 --> 00:42:42,250
first on files right and then there is

00:42:38,320 --> 00:42:45,339
no no way to have a partial changes made

00:42:42,250 --> 00:42:47,080
by mapping the job if it fails with the

00:42:45,339 --> 00:42:49,510
boot others so what what it does on file

00:42:47,080 --> 00:42:51,609
is on HDFS it is very simple you just

00:42:49,510 --> 00:42:53,500
write somewhere your files and then once

00:42:51,609 --> 00:42:55,900
it is completed is visible to others

00:42:53,500 --> 00:42:57,339
right so you move it somewhere so the

00:42:55,900 --> 00:42:59,349
semantics of MapReduce job is either

00:42:57,339 --> 00:43:02,890
everything complete or Nothing complete

00:42:59,349 --> 00:43:05,830
in that case if you try to use if you

00:43:02,890 --> 00:43:08,380
try to write to each base from you're my

00:43:05,830 --> 00:43:11,790
producer you kind of lose this thematic

00:43:08,380 --> 00:43:14,380
and then we are trying to bring it back

00:43:11,790 --> 00:43:16,599
but the member uses not the only client

00:43:14,380 --> 00:43:22,109
right of the HBS right there are others

00:43:16,599 --> 00:43:25,660
right right okay thinking great

00:43:22,109 --> 00:43:29,710
presentation really enjoyed that curious

00:43:25,660 --> 00:43:31,839
on the open-source front any thoughts

00:43:29,710 --> 00:43:34,150
about what your vehicle for open

00:43:31,839 --> 00:43:37,690
sourcing would be in what the license

00:43:34,150 --> 00:43:39,580
might be I mean whatever whatever we

00:43:37,690 --> 00:43:42,040
open source it is about you to license

00:43:39,580 --> 00:43:44,770
right because I mean otherwise there is

00:43:42,040 --> 00:43:45,460
just no way to build a community around

00:43:44,770 --> 00:43:49,180
it

00:43:45,460 --> 00:43:50,650
and I mean doesn't really help to open

00:43:49,180 --> 00:43:53,040
source it if it is not a virtualized

00:43:50,650 --> 00:43:55,750
right and then the question again as

00:43:53,040 --> 00:43:57,460
yeah only during the keen on mentioned

00:43:55,750 --> 00:43:59,800
whether we open source it on github or

00:43:57,460 --> 00:44:02,230
we open source it in putting in some

00:43:59,800 --> 00:44:04,330
community like a patch it right and then

00:44:02,230 --> 00:44:06,430
what we've done so far we are trying to

00:44:04,330 --> 00:44:09,760
open source it first and github and then

00:44:06,430 --> 00:44:14,260
we move it graduated to Apache right so

00:44:09,760 --> 00:44:16,900
I mean this transaction system makes

00:44:14,260 --> 00:44:20,050
sense in general so it probably a good

00:44:16,900 --> 00:44:23,380
fit for putting it into Apache Incubator

00:44:20,050 --> 00:44:26,589
in working on in there then it could be

00:44:23,380 --> 00:44:28,270
very complimentary with with Phoenix be

00:44:26,589 --> 00:44:30,700
pretty interesting combination so I can

00:44:28,270 --> 00:44:32,650
I can I can definitely see how when

00:44:30,700 --> 00:44:36,270
these two things can be integrated right

00:44:32,650 --> 00:44:36,270
so thanks

00:44:44,969 --> 00:44:54,249
what kind of use cases have you seen for

00:44:49,209 --> 00:44:55,839
transaction support in using HBase so I

00:44:54,249 --> 00:44:59,859
mean like I mentioned before there's a

00:44:55,839 --> 00:45:02,859
couple of them like like one use case is

00:44:59,859 --> 00:45:04,749
real-time human data processing ensuring

00:45:02,859 --> 00:45:07,119
data between processing units right you

00:45:04,749 --> 00:45:09,459
want to share data inconsistent weight

00:45:07,119 --> 00:45:11,890
right at the same time you may want to

00:45:09,459 --> 00:45:14,349
do multiple operations that are atomic

00:45:11,890 --> 00:45:16,689
multiple data operations that are atomic

00:45:14,349 --> 00:45:18,789
to support your complex data access

00:45:16,689 --> 00:45:21,849
paranoid for example secondary index

00:45:18,789 --> 00:45:24,939
right so to build a secondary index you

00:45:21,849 --> 00:45:26,949
for each right in edgeways you do

00:45:24,939 --> 00:45:28,839
another right into maybe even into

00:45:26,949 --> 00:45:31,209
different table right to keep them and

00:45:28,839 --> 00:45:34,689
think it is very hard to do right so

00:45:31,209 --> 00:45:36,549
this will help because because of the

00:45:34,689 --> 00:45:38,469
transactional guarantees right you

00:45:36,549 --> 00:45:42,579
either see what of them or none of them

00:45:38,469 --> 00:45:46,509
right another case is improving

00:45:42,579 --> 00:45:49,719
efficiency improving performance by

00:45:46,509 --> 00:45:52,630
allowing you to basically do multiple

00:45:49,719 --> 00:45:54,639
operations in a domick way so so that

00:45:52,630 --> 00:45:56,019
you can do it in in your application it

00:45:54,639 --> 00:45:57,849
will be more efficient than doing one by

00:45:56,019 --> 00:45:59,409
one and then you cannot do it without

00:45:57,849 --> 00:46:02,619
transaction if you care about the data

00:45:59,409 --> 00:46:06,069
consistency do you have any real life

00:46:02,619 --> 00:46:09,130
applications using your orientation

00:46:06,069 --> 00:46:11,769
basically what whatever applications are

00:46:09,130 --> 00:46:14,489
built on top of our platform they use

00:46:11,769 --> 00:46:16,899
transactions by default I mean you can

00:46:14,489 --> 00:46:18,279
relax it like there is for example one

00:46:16,899 --> 00:46:19,779
use case that they're relaxing this

00:46:18,279 --> 00:46:21,759
guarantees for example you're doing deep

00:46:19,779 --> 00:46:23,529
packet deep network packet inspection

00:46:21,759 --> 00:46:25,359
and then it's fine to lose some data

00:46:23,529 --> 00:46:26,619
then you just relax it right you you

00:46:25,359 --> 00:46:29,169
don't care about it you don't want this

00:46:26,619 --> 00:46:32,919
overhead but at the same time when you

00:46:29,169 --> 00:46:34,359
are doing consumer or user analytics on

00:46:32,919 --> 00:46:37,839
your website and you care about what

00:46:34,359 --> 00:46:40,630
user does every single action then mean

00:46:37,839 --> 00:46:42,609
and then you're updating multiple tables

00:46:40,630 --> 00:46:45,130
in HBase that one is lets a user

00:46:42,609 --> 00:46:47,380
activity another one is and where a

00:46:45,130 --> 00:46:51,309
transaction is done or another one is

00:46:47,380 --> 00:46:54,969
maybe some I know classification moil

00:46:51,309 --> 00:46:56,810
for providing some recommendation for

00:46:54,969 --> 00:46:58,570
users so what you do usually update

00:46:56,810 --> 00:47:03,350
multiple them and you want to have that

00:46:58,570 --> 00:47:05,780
also an atomic weight and yeah another

00:47:03,350 --> 00:47:08,660
another bigger use cases it mentioned

00:47:05,780 --> 00:47:11,840
during the prayers talk was when you do

00:47:08,660 --> 00:47:14,180
aggregations when you do all up when you

00:47:11,840 --> 00:47:16,250
do a lap system on top of it so you have

00:47:14,180 --> 00:47:17,780
some kind of go up cube and you want to

00:47:16,250 --> 00:47:19,100
create data out of them so basically

00:47:17,780 --> 00:47:21,080
what you have is you have on the input

00:47:19,100 --> 00:47:23,360
lots of data and then you write it in

00:47:21,080 --> 00:47:25,850
two to an output and then you have to

00:47:23,360 --> 00:47:27,920
like act that okay this whole batch is

00:47:25,850 --> 00:47:30,680
processed and then at the same time you

00:47:27,920 --> 00:47:31,880
want to update multiple indexes so that

00:47:30,680 --> 00:47:34,100
you can support multiple different

00:47:31,880 --> 00:47:36,200
Curie's let's say you're building your

00:47:34,100 --> 00:47:38,780
aggregation by user you're building your

00:47:36,200 --> 00:47:41,030
aggravation by location by something

00:47:38,780 --> 00:47:42,260
else and then these are all multiple

00:47:41,030 --> 00:47:44,590
operations and you want to have them

00:47:42,260 --> 00:47:47,330
either all of them succeed or not so

00:47:44,590 --> 00:47:50,510
there will be another use case have one

00:47:47,330 --> 00:47:54,140
more question if that's right your

00:47:50,510 --> 00:47:57,560
overhead you described it as in terms of

00:47:54,140 --> 00:48:01,760
to our pcs do you have a number in terms

00:47:57,560 --> 00:48:04,700
of percentage so you compared to hbase

00:48:01,760 --> 00:48:07,670
vanilla calls right it depends on your

00:48:04,700 --> 00:48:09,980
use case how you how you do like how

00:48:07,670 --> 00:48:11,930
many operations that you do with it so

00:48:09,980 --> 00:48:14,630
let's say you have in the case when you

00:48:11,930 --> 00:48:16,850
have let's say you do ten right for a

00:48:14,630 --> 00:48:18,850
transaction in HBase then the overhead

00:48:16,850 --> 00:48:21,950
will be like to four percent because

00:48:18,850 --> 00:48:23,900
these two are pieces are faster than

00:48:21,950 --> 00:48:25,670
even rise to eighth place because and

00:48:23,900 --> 00:48:28,880
that this is the reason why we don't use

00:48:25,670 --> 00:48:31,790
HBase for transaction manager because I

00:48:28,880 --> 00:48:35,270
mean the way that it weighs doesn't

00:48:31,790 --> 00:48:37,640
allow you to have like all the

00:48:35,270 --> 00:48:39,740
flexibility in core processors in like

00:48:37,640 --> 00:48:42,890
managing the mem story that we want so

00:48:39,740 --> 00:48:45,290
since we know that this is the data

00:48:42,890 --> 00:48:46,970
format in our memory in transaction

00:48:45,290 --> 00:48:49,520
manager we can do it more efficiently at

00:48:46,970 --> 00:48:51,320
the same time we apply the same logic

00:48:49,520 --> 00:48:55,520
when you write to write a headlock as is

00:48:51,320 --> 00:48:59,320
basis like it is basically committing

00:48:55,520 --> 00:49:01,650
edits in radiohead log based on multiple

00:48:59,320 --> 00:49:04,049
requests from users at the same

00:49:01,650 --> 00:49:05,490
so it is not like cereal so we can't

00:49:04,049 --> 00:49:09,089
even improve that so you can think about

00:49:05,490 --> 00:49:12,539
this as to rise to hbase but maybe like

00:49:09,089 --> 00:49:14,190
two times or three times faster solely

00:49:12,539 --> 00:49:17,809
select additional right in HBase just

00:49:14,190 --> 00:49:17,809
single put which is super fast

00:49:27,109 --> 00:49:32,589
and curious on the conflict resolution

00:49:31,039 --> 00:49:35,599
piece it seems like there might be

00:49:32,589 --> 00:49:39,410
overhead associated with that aside from

00:49:35,599 --> 00:49:41,239
the RPC calls ha right can you talk a

00:49:39,410 --> 00:49:43,549
little bit more about how do you do that

00:49:41,239 --> 00:49:46,309
conflict resolution what they have what

00:49:43,549 --> 00:49:48,230
happens you send big changes made by

00:49:46,309 --> 00:49:51,140
this transaction to the transaction

00:49:48,230 --> 00:49:55,819
manager usually like in case if you're

00:49:51,140 --> 00:49:57,799
doing let's say real-time processing and

00:49:55,819 --> 00:50:00,499
now for example you are liking this o

00:49:57,799 --> 00:50:02,660
app case you just updating like ten are

00:50:00,499 --> 00:50:04,220
aggregates right so what happens is like

00:50:02,660 --> 00:50:05,299
you have these ten rockies that your

00:50:04,220 --> 00:50:09,499
update and you just send it with your

00:50:05,299 --> 00:50:13,880
RPC so basically all these requests are

00:50:09,499 --> 00:50:16,220
very small and then choosing the level

00:50:13,880 --> 00:50:18,170
of resolution of conflict resolution you

00:50:16,220 --> 00:50:19,759
can even say that okay i'm not providing

00:50:18,170 --> 00:50:21,799
even the whole keys but then i will

00:50:19,759 --> 00:50:24,440
probably like small let's say subset of

00:50:21,799 --> 00:50:26,690
it and then which will tell you that in

00:50:24,440 --> 00:50:29,599
case of aggregation that lets say i

00:50:26,690 --> 00:50:32,269
updated some data in this time interval

00:50:29,599 --> 00:50:33,890
right and then transaction manager it

00:50:32,269 --> 00:50:36,289
doesn't care what is it will just try to

00:50:33,890 --> 00:50:40,579
overlap if it is there or not so even if

00:50:36,289 --> 00:50:42,529
you're like the data size that you send

00:50:40,579 --> 00:50:44,299
to the transaction manager is like

00:50:42,529 --> 00:50:46,730
really critical for you you send a lot

00:50:44,299 --> 00:50:50,150
of data right then you can minimize it

00:50:46,730 --> 00:50:52,930
by just fine I changing the level of

00:50:50,150 --> 00:50:55,940
conflict resolution which usually helps

00:50:52,930 --> 00:50:58,749
so then there is an RPC call from the

00:50:55,940 --> 00:51:02,960
region server to your zookeeper

00:50:58,749 --> 00:51:05,239
transaction manager is that is that like

00:51:02,960 --> 00:51:07,039
when is that conflict resolution he'll

00:51:05,239 --> 00:51:09,859
take place what you do is when you can

00:51:07,039 --> 00:51:11,539
need you inside your client you know

00:51:09,859 --> 00:51:13,099
what are the roles that you change let's

00:51:11,539 --> 00:51:14,150
say you conflict resolution and growth

00:51:13,099 --> 00:51:16,309
right and then you tell it to

00:51:14,150 --> 00:51:17,989
transaction manager transaction manager

00:51:16,309 --> 00:51:20,749
keeps all in progress transactions and

00:51:17,989 --> 00:51:23,869
then whatever was committed whatever

00:51:20,749 --> 00:51:25,759
transaction has started since your

00:51:23,869 --> 00:51:27,619
transaction started right so it is

00:51:25,759 --> 00:51:29,599
basically like whatever is in progress

00:51:27,619 --> 00:51:31,339
right now and then it knows what it was

00:51:29,599 --> 00:51:33,230
committed by these transactions so it

00:51:31,339 --> 00:51:35,059
for some time it keeps an in-memory all

00:51:33,230 --> 00:51:37,190
these changes right but it's only for

00:51:35,059 --> 00:51:40,000
those that are in progress right now so

00:51:37,190 --> 00:51:42,440
enable just check it just basically

00:51:40,000 --> 00:51:45,849
so does the client need to hold in

00:51:42,440 --> 00:51:49,460
memory of all of its transactions state

00:51:45,849 --> 00:51:52,010
it no it keeps in memory only the

00:51:49,460 --> 00:51:54,260
changes that it did based on the level

00:51:52,010 --> 00:51:57,529
it can be on kinetic resolution level it

00:51:54,260 --> 00:51:59,960
can be roast edit changes or it can be I

00:51:57,529 --> 00:52:02,380
know tables there factors I ca so it is

00:51:59,960 --> 00:52:05,119
only for this production right right so

00:52:02,380 --> 00:52:08,690
the drawback of that is that you do not

00:52:05,119 --> 00:52:12,049
share the same transaction by to client

00:52:08,690 --> 00:52:14,720
I mean we just usually find because it

00:52:12,049 --> 00:52:17,089
gives you I mean based in your use case

00:52:14,720 --> 00:52:18,589
right right and then at the same time

00:52:17,089 --> 00:52:20,839
when you know that you design your

00:52:18,589 --> 00:52:23,750
application in a way that there is like

00:52:20,839 --> 00:52:25,789
they could not be any conflict right for

00:52:23,750 --> 00:52:28,130
example when you will be consumed from Q

00:52:25,789 --> 00:52:30,049
we know that okay there is only one guy

00:52:28,130 --> 00:52:32,420
who can consume from this Q in that

00:52:30,049 --> 00:52:35,539
sense since the clients defines and

00:52:32,420 --> 00:52:36,950
decides what to change its report to

00:52:35,539 --> 00:52:39,019
transaction manager you can just not

00:52:36,950 --> 00:52:40,670
report them at all so if you know that

00:52:39,019 --> 00:52:42,619
you partition like you have it a

00:52:40,670 --> 00:52:44,150
real-time processing pipeline and you

00:52:42,619 --> 00:52:46,490
partition your data in a way that you

00:52:44,150 --> 00:52:48,019
know they did they do not intersect by

00:52:46,490 --> 00:52:50,059
any means right you can just tell that

00:52:48,019 --> 00:52:52,130
and then you will not provide any

00:52:50,059 --> 00:52:56,630
changes so there is a lot of flexibility

00:52:52,130 --> 00:53:00,140
to decline in this case yeah nice last

00:52:56,630 --> 00:53:01,940
question if the transaction involved

00:53:00,140 --> 00:53:04,789
multiple regions are was something there

00:53:01,940 --> 00:53:08,150
are some invalid records then you in the

00:53:04,789 --> 00:53:13,880
pre flush you are removing that right

00:53:08,150 --> 00:53:17,000
you are not writing to H file so you in

00:53:13,880 --> 00:53:19,220
some green server you want to make our

00:53:17,000 --> 00:53:21,529
physical to find the invalid records

00:53:19,220 --> 00:53:23,900
from the transaction transaction manager

00:53:21,529 --> 00:53:25,640
so if I understand the question how do

00:53:23,900 --> 00:53:28,670
we decide what are the invalid or not

00:53:25,640 --> 00:53:35,059
how do we remove them so we if you look

00:53:28,670 --> 00:53:38,269
at the picture so what what this region

00:53:35,059 --> 00:53:39,740
observer core processor does it gets the

00:53:38,269 --> 00:53:41,599
way this transaction snapshot and this

00:53:39,740 --> 00:53:43,609
is how it knows what are the valid

00:53:41,599 --> 00:53:45,730
transaction to what are invalid

00:53:43,609 --> 00:53:47,920
transactions now this can be little bit

00:53:45,730 --> 00:53:49,840
tail because we do try and we write

00:53:47,920 --> 00:53:51,820
snapshots to hdfs every like five

00:53:49,840 --> 00:53:54,400
minutes but it's fine because will

00:53:51,820 --> 00:53:56,590
anyways compacted multiple times the

00:53:54,400 --> 00:54:00,180
same data right database will do that

00:53:56,590 --> 00:54:00,180
for you and then we'll just hook it up

00:54:03,990 --> 00:54:08,250

YouTube URL: https://www.youtube.com/watch?v=AerF7flT4tk


