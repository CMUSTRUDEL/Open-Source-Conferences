Title: Data cubes in Apache Hive - Amareshwari Sriramadasu, Jaideep Dhok
Publication date: 2014-04-25
Playlist: ApacheCon North America 2014
Description: 
	ApacheCon North America 2014
Captions: 
	00:00:00,060 --> 00:00:05,549
good afternoon everyone so we will I'll

00:00:03,120 --> 00:00:08,010
introduce you to data cubes in Apache

00:00:05,549 --> 00:00:12,330
high which are introduced at tie-in

00:00:08,010 --> 00:00:17,640
movie I'm Irish very sweet Amanda soon

00:00:12,330 --> 00:00:19,740
I work as engineering in movie I work in

00:00:17,640 --> 00:00:22,650
a data platform team where it collects

00:00:19,740 --> 00:00:26,519
all the data processes sit and provides

00:00:22,650 --> 00:00:28,830
it for analytics so collects the data

00:00:26,519 --> 00:00:32,099
puts it on Hadoop and then provides

00:00:28,830 --> 00:00:34,460
analytics on top of it before in movie I

00:00:32,099 --> 00:00:40,290
was working with Yahoo and core Hadoop

00:00:34,460 --> 00:00:44,879
team I'm Apache Hadoop EMC and hive

00:00:40,290 --> 00:00:47,340
committer so we'll go ahead so I have my

00:00:44,879 --> 00:00:50,100
colleague Jay deep who's accompanying me

00:00:47,340 --> 00:00:52,739
here he's also working in Hadoop and

00:00:50,100 --> 00:00:58,829
ecosystem and he is a hide contributor

00:00:52,739 --> 00:01:01,530
as well in this talk I will cover I'll

00:00:58,829 --> 00:01:07,430
give you a background on watt in Mobius

00:01:01,530 --> 00:01:11,070
and the analytics it in movie and then

00:01:07,430 --> 00:01:14,220
I'll tell the motivation why movie wants

00:01:11,070 --> 00:01:17,220
to use Apache hype now and then I'll

00:01:14,220 --> 00:01:20,460
introduce data cubes that are that are

00:01:17,220 --> 00:01:26,640
introduced by in movie and then we'll

00:01:20,460 --> 00:01:29,759
see more examples and queries and I'll

00:01:26,640 --> 00:01:33,920
introduce another system grill which is

00:01:29,759 --> 00:01:33,920
the analytic system with built in movie

00:01:34,009 --> 00:01:45,479
so without any more delay I will go to

00:01:37,860 --> 00:01:51,060
the so yes in movie is a global mobile

00:01:45,479 --> 00:01:55,100
technology company which which gets

00:01:51,060 --> 00:02:00,030
mobile mobile space that is available on

00:01:55,100 --> 00:02:04,770
tablets and mobiles and and it uses the

00:02:00,030 --> 00:02:06,780
real-estate availability so so it buys

00:02:04,770 --> 00:02:09,840
them from app developers and publisher

00:02:06,780 --> 00:02:11,910
and then it wants to monetize for them

00:02:09,840 --> 00:02:13,100
and then it sells the real estate

00:02:11,910 --> 00:02:15,770
privatized

00:02:13,100 --> 00:02:19,610
to show their ads and all this happens

00:02:15,770 --> 00:02:23,000
at scale so in movie actually provides

00:02:19,610 --> 00:02:26,780
around like billions of facts every day

00:02:23,000 --> 00:02:29,210
so it serves billions of fires every day

00:02:26,780 --> 00:02:32,900
so more into that so that is what that

00:02:29,210 --> 00:02:35,810
is so it buys in went to different

00:02:32,900 --> 00:02:38,630
publishers and and has the marketplace

00:02:35,810 --> 00:02:40,790
where and it where publishers come

00:02:38,630 --> 00:02:43,130
register and then it sells that to the

00:02:40,790 --> 00:02:45,200
advertisers so in this process it

00:02:43,130 --> 00:02:48,170
acquires the end consumer who is the

00:02:45,200 --> 00:02:55,610
user so it wants to understand the user

00:02:48,170 --> 00:02:57,620
show him proper ads in this process sohe

00:02:55,610 --> 00:03:01,280
do it in moving with respect to

00:02:57,620 --> 00:03:04,880
analytics so we have 130 TB of hadoop

00:03:01,280 --> 00:03:08,380
warehouse and 5 TB of sequel warehouse

00:03:04,880 --> 00:03:11,540
and we'll see an example of Howard

00:03:08,380 --> 00:03:13,850
reporting page looks so this is this is

00:03:11,540 --> 00:03:16,370
what a publisher sees when he logins and

00:03:13,850 --> 00:03:18,620
goes to his dashboard this is one of the

00:03:16,370 --> 00:03:20,990
dashboard that he sees where it says

00:03:18,620 --> 00:03:23,360
like how we see performing today with

00:03:20,990 --> 00:03:26,990
respect to Esther day so how many ad

00:03:23,360 --> 00:03:30,050
requests are served on his on his page

00:03:26,990 --> 00:03:32,690
and then how is his fill rate compared

00:03:30,050 --> 00:03:34,970
to yesterday and how is Howard the ad

00:03:32,690 --> 00:03:36,980
request served across regions so

00:03:34,970 --> 00:03:43,910
obviously shown and the dashboard for

00:03:36,980 --> 00:03:45,680
the publisher and then so they're not

00:03:43,910 --> 00:03:47,930
just that raises and publishes there are

00:03:45,680 --> 00:03:50,390
many other users inside in a movie who

00:03:47,930 --> 00:03:52,640
wants to analyze what is happening to

00:03:50,390 --> 00:03:55,100
the business so their account managers

00:03:52,640 --> 00:03:57,050
who treat the counts their regional

00:03:55,100 --> 00:03:59,210
officers who wants to look at their

00:03:57,050 --> 00:04:01,400
region what is happening there and their

00:03:59,210 --> 00:04:04,670
business analyst product analysts and

00:04:01,400 --> 00:04:07,730
their data scientists who wants to infer

00:04:04,670 --> 00:04:11,210
more information around the user and

00:04:07,730 --> 00:04:14,960
things and their engineering systems

00:04:11,210 --> 00:04:18,380
themselves who wants to get a feedback

00:04:14,960 --> 00:04:22,180
from the system by querying it and then

00:04:18,380 --> 00:04:22,180
take appropriate decision on that

00:04:23,759 --> 00:04:31,810
so what they do is the share reports and

00:04:28,389 --> 00:04:35,199
data with consumer and then understand

00:04:31,810 --> 00:04:36,610
trends through data exploration that is

00:04:35,199 --> 00:04:37,900
the analysis that you want to do you

00:04:36,610 --> 00:04:41,139
want to see the trending how we are

00:04:37,900 --> 00:04:46,300
performing or a month or a or a time

00:04:41,139 --> 00:04:47,860
period and then the developers so if

00:04:46,300 --> 00:04:50,710
something is going wrong you have to go

00:04:47,860 --> 00:04:52,960
debug find where it went wrong so you

00:04:50,710 --> 00:04:56,410
need to analyze your business there

00:04:52,960 --> 00:04:59,940
again and for your sizing and estimation

00:04:56,410 --> 00:05:02,289
so how big is your business how many

00:04:59,940 --> 00:05:06,910
requests are coming and also you need to

00:05:02,289 --> 00:05:11,310
know for the sizing and estimation and

00:05:06,910 --> 00:05:15,870
they're so summary of products at

00:05:11,310 --> 00:05:21,030
geographic level and at network level

00:05:15,870 --> 00:05:23,590
and then we have the sales in revenue

00:05:21,030 --> 00:05:26,650
comparisons versus targets with versus

00:05:23,590 --> 00:05:28,750
sexuals and then your you have to track

00:05:26,650 --> 00:05:33,400
your company performance and then the

00:05:28,750 --> 00:05:36,010
metrics real time so if we categories

00:05:33,400 --> 00:05:38,410
all these use cases and put them so

00:05:36,010 --> 00:05:41,349
there those are nothing but they're

00:05:38,410 --> 00:05:44,409
batch Paris who wants to perform queries

00:05:41,349 --> 00:05:47,979
over a big period of data say month the

00:05:44,409 --> 00:05:50,260
six months or more a week are and the

00:05:47,979 --> 00:05:53,289
queries which are ready are doc which

00:05:50,260 --> 00:05:56,110
you don't know ahead so you will just go

00:05:53,289 --> 00:06:00,760
whatever you want you want to type and

00:05:56,110 --> 00:06:03,280
they're interactive queries where you

00:06:00,760 --> 00:06:06,580
want to looking at the result you want

00:06:03,280 --> 00:06:08,650
to again drill down into that and there

00:06:06,580 --> 00:06:11,440
are shady old queries where you want to

00:06:08,650 --> 00:06:14,349
say give me your queries say run every

00:06:11,440 --> 00:06:17,500
1st of the month or every Monday of the

00:06:14,349 --> 00:06:20,820
week things like that and then and you

00:06:17,500 --> 00:06:20,820
want to infer insights

00:06:23,080 --> 00:06:31,060
then so all this happens it in movie

00:06:26,949 --> 00:06:32,650
through multiple systems so there more

00:06:31,060 --> 00:06:34,870
than one system that is available at in

00:06:32,650 --> 00:06:36,580
mobile to do analytics so there is an

00:06:34,870 --> 00:06:41,199
adduct querying system which is built on

00:06:36,580 --> 00:06:45,189
top of Hadoop MapReduce and then which

00:06:41,199 --> 00:06:47,650
uses data in Hadoop so so it will it has

00:06:45,189 --> 00:06:50,319
a UA where user can go drag and drop

00:06:47,650 --> 00:06:53,050
things and then submit a query so that

00:06:50,319 --> 00:06:56,229
will in turn runs a MapReduce job get

00:06:53,050 --> 00:06:58,210
the results and then so it will and then

00:06:56,229 --> 00:07:01,259
it will convert the result into a say

00:06:58,210 --> 00:07:05,409
CSV file and then mail it to the user so

00:07:01,259 --> 00:07:08,169
this system like works on HDFS data and

00:07:05,409 --> 00:07:10,740
it provides a custom API for Java

00:07:08,169 --> 00:07:13,990
applications if they want to try it out

00:07:10,740 --> 00:07:16,389
and there is something called dashboard

00:07:13,990 --> 00:07:19,360
system where dashboards are already

00:07:16,389 --> 00:07:21,520
created you go check it how they're

00:07:19,360 --> 00:07:24,370
performing a user can go create his own

00:07:21,520 --> 00:07:26,620
dashboard and then looking at the

00:07:24,370 --> 00:07:29,259
dashboard you go click drill down see

00:07:26,620 --> 00:07:33,310
what is happening so there is one mode

00:07:29,259 --> 00:07:35,469
system called dashboard system and there

00:07:33,310 --> 00:07:36,639
is another system customer-facing system

00:07:35,469 --> 00:07:39,759
which is very similar to dashboard

00:07:36,639 --> 00:07:40,900
system but this is this is face to the

00:07:39,759 --> 00:07:45,190
outside world that is for the

00:07:40,900 --> 00:07:46,930
advertisers and publishers so this will

00:07:45,190 --> 00:07:50,379
also allow you to look at your

00:07:46,930 --> 00:07:51,849
dashboards and interactively process go

00:07:50,379 --> 00:07:55,690
inside and look at drill down the

00:07:51,849 --> 00:07:58,080
results but the only thing is it is it

00:07:55,690 --> 00:08:00,819
is secluded from the other users so only

00:07:58,080 --> 00:08:07,000
only on only Outsiders can access it

00:08:00,819 --> 00:08:08,560
with a authentication and so so all is

00:08:07,000 --> 00:08:12,669
fine till now so what are the problems

00:08:08,560 --> 00:08:14,889
in mobile facing right so individual

00:08:12,669 --> 00:08:17,699
systems we just let me just saw they

00:08:14,889 --> 00:08:21,099
work like perfectly fine they give the

00:08:17,699 --> 00:08:24,969
very good response time to users and

00:08:21,099 --> 00:08:28,240
then they're all happy but then what is

00:08:24,969 --> 00:08:31,270
the problem right so there is a

00:08:28,240 --> 00:08:33,190
disparate user experience because same

00:08:31,270 --> 00:08:35,770
users go to a dashboard system they go

00:08:33,190 --> 00:08:36,370
to ad hoc query system and things you

00:08:35,770 --> 00:08:40,240
see on two

00:08:36,370 --> 00:08:44,020
different systems is different the same

00:08:40,240 --> 00:08:46,180
name is shown is as one name here and

00:08:44,020 --> 00:08:49,240
then name one here and name two there so

00:08:46,180 --> 00:08:52,960
it is confusing for them and also they

00:08:49,240 --> 00:08:55,750
have their own Java API or custom API to

00:08:52,960 --> 00:08:59,770
talk to the systems directly so that

00:08:55,750 --> 00:09:05,770
makes the user experience bad and at the

00:08:59,770 --> 00:09:09,430
same time actually if we see here so the

00:09:05,770 --> 00:09:12,279
carrying system here accesses data in

00:09:09,430 --> 00:09:15,190
HDFS the dashboard system access data on

00:09:12,279 --> 00:09:17,320
a column our data warehouse because it

00:09:15,190 --> 00:09:21,089
wants to sell queries interactively and

00:09:17,320 --> 00:09:23,500
Hadoop can't solve interactive queries

00:09:21,089 --> 00:09:25,720
and then the customer-facing system

00:09:23,500 --> 00:09:30,430
Maxis data on relational DB which is

00:09:25,720 --> 00:09:32,740
something like Postgres so if if

00:09:30,430 --> 00:09:34,990
dashboard system has got a query which

00:09:32,740 --> 00:09:37,690
which wants to scan actually data or a

00:09:34,990 --> 00:09:40,089
six-months it can't answer it because it

00:09:37,690 --> 00:09:40,420
that will take time but even if it wants

00:09:40,089 --> 00:09:42,310
to

00:09:40,420 --> 00:09:44,230
even if user wants to wait for a while

00:09:42,310 --> 00:09:48,520
and look at the result it can't because

00:09:44,230 --> 00:09:52,860
it contact or duper so so these systems

00:09:48,520 --> 00:09:52,860
are like having disparate storage

00:09:54,180 --> 00:09:59,170
storage systems causing the inability to

00:09:56,800 --> 00:10:01,600
scale you can't the data is readily

00:09:59,170 --> 00:10:04,630
available there you can't go use it and

00:10:01,600 --> 00:10:07,690
not say your caress and schema

00:10:04,630 --> 00:10:09,970
management is a problem because the

00:10:07,690 --> 00:10:12,820
systems themselves maintain the schema

00:10:09,970 --> 00:10:14,380
of the data that is present for example

00:10:12,820 --> 00:10:16,480
the addict whirring system maintains the

00:10:14,380 --> 00:10:18,970
schema in property files and it is part

00:10:16,480 --> 00:10:22,209
of their code and the other systems have

00:10:18,970 --> 00:10:25,420
it in their DB DB schema so if a new

00:10:22,209 --> 00:10:29,740
field has to be added it has to be added

00:10:25,420 --> 00:10:32,050
in three different systems and that will

00:10:29,740 --> 00:10:33,640
take time so for it you feel to be are

00:10:32,050 --> 00:10:38,110
available for the end user it will take

00:10:33,640 --> 00:10:40,870
a week for finishing every for all the

00:10:38,110 --> 00:10:45,310
systems to be available and being good

00:10:40,870 --> 00:10:48,760
and and moreover so analytics on Hadoop

00:10:45,310 --> 00:10:49,260
is a very big community out there there

00:10:48,760 --> 00:10:51,960
is

00:10:49,260 --> 00:10:54,330
there is Impala there is drill so but

00:10:51,960 --> 00:10:58,830
you know he is not using it is building

00:10:54,330 --> 00:11:00,270
its own systems and it is not if a new

00:10:58,830 --> 00:11:03,020
feature has to come again it has to be

00:11:00,270 --> 00:11:05,880
invest development on that and and

00:11:03,020 --> 00:11:07,590
expose that so it's not leveraging the

00:11:05,880 --> 00:11:10,650
community around so these are the

00:11:07,590 --> 00:11:13,670
problems we are we are trying to solve

00:11:10,650 --> 00:11:16,260
and use the community around and then

00:11:13,670 --> 00:11:23,880
provide the same analytics that users

00:11:16,260 --> 00:11:30,930
are filling so now we will see why in

00:11:23,880 --> 00:11:35,850
maybe wants to use Apache hi right so

00:11:30,930 --> 00:11:39,660
what does hi provide it associates

00:11:35,850 --> 00:11:41,760
structure to the data so whatever is

00:11:39,660 --> 00:11:44,160
data is that is there an HDFS you

00:11:41,760 --> 00:11:45,960
associate the structure to it and that

00:11:44,160 --> 00:11:48,330
is available in the hive metal store and

00:11:45,960 --> 00:11:50,940
it provides pluggable storage interface

00:11:48,330 --> 00:11:53,700
through the storage Handler and any

00:11:50,940 --> 00:11:58,080
storage can be accessed and it accepts

00:11:53,700 --> 00:12:00,240
sequel like bash queries so sequel is is

00:11:58,080 --> 00:12:03,690
the standard that people use easily

00:12:00,240 --> 00:12:05,550
understand so you go use them so any

00:12:03,690 --> 00:12:07,380
business analyst or product analyst if

00:12:05,550 --> 00:12:09,090
they have to write sequel it is very

00:12:07,380 --> 00:12:13,140
easy for them than to write a custom API

00:12:09,090 --> 00:12:15,450
query to understand and then English

00:12:13,140 --> 00:12:18,210
Creole is widely adopted by other

00:12:15,450 --> 00:12:21,210
systems as well shark and Impala and

00:12:18,210 --> 00:12:28,500
yeah and it has the stronger patchy

00:12:21,210 --> 00:12:30,420
community so what is missing so for a

00:12:28,500 --> 00:12:33,300
business if you see it will have

00:12:30,420 --> 00:12:34,770
actually facts and dimensions in data

00:12:33,300 --> 00:12:37,710
where you will always have facts and

00:12:34,770 --> 00:12:41,430
dimensions but time doesn't give any

00:12:37,710 --> 00:12:44,790
notion of facts and dimensions so that

00:12:41,430 --> 00:12:47,910
is what something is missing and so what

00:12:44,790 --> 00:12:49,260
what we have in it in movie are and even

00:12:47,910 --> 00:12:52,650
in any other place that could be the

00:12:49,260 --> 00:12:56,100
problem that we define a table which is

00:12:52,650 --> 00:12:58,020
present in more than one location so a

00:12:56,100 --> 00:12:59,699
table is present and say in one

00:12:58,020 --> 00:13:01,709
clustered more than one cluster

00:12:59,699 --> 00:13:04,649
just the cluster it can be present in a

00:13:01,709 --> 00:13:06,389
DB but having the same schema so there

00:13:04,649 --> 00:13:09,839
is no notion of a logical table attached

00:13:06,389 --> 00:13:11,699
to multiple physical storages that is

00:13:09,839 --> 00:13:15,089
also missing and interactive charissa

00:13:11,699 --> 00:13:17,669
missing and you can't dual queries for

00:13:15,089 --> 00:13:22,230
example run query every first of the

00:13:17,669 --> 00:13:30,959
month and there is no drag-and-drop sort

00:13:22,230 --> 00:13:33,809
of UI that is available so so to to fill

00:13:30,959 --> 00:13:41,819
the missing part in Apache hi so we

00:13:33,809 --> 00:13:47,100
introduce your data cubes let us look at

00:13:41,819 --> 00:13:49,799
a data layout of the fact fact data so

00:13:47,100 --> 00:13:52,889
any raw of fact that is available out

00:13:49,799 --> 00:13:55,980
there will have measures which are

00:13:52,889 --> 00:13:59,339
measured at some dimensions so you have

00:13:55,980 --> 00:14:01,769
say you have a mod measures say here and

00:13:59,339 --> 00:14:05,369
D are dimensions so those are available

00:14:01,769 --> 00:14:07,949
as raw fact but if every query goes to

00:14:05,369 --> 00:14:10,410
raw data raw data can be say here this

00:14:07,949 --> 00:14:11,669
can be in thousands hundreds if you can

00:14:10,410 --> 00:14:14,279
have two hundred measures and two

00:14:11,669 --> 00:14:16,289
hundred dimensions in your raw fact but

00:14:14,279 --> 00:14:18,449
the fight for every simple query if you

00:14:16,289 --> 00:14:19,949
are hitting raw fat and that is going to

00:14:18,449 --> 00:14:22,709
scan all the data and that is very

00:14:19,949 --> 00:14:27,600
costly right so what you usually do is

00:14:22,709 --> 00:14:30,089
you aggregate the raw data so drop some

00:14:27,600 --> 00:14:34,639
dimensions or measures then create an

00:14:30,089 --> 00:14:38,039
aggregated fact data on top of it so

00:14:34,639 --> 00:14:41,039
that can happen in multiple levels so if

00:14:38,039 --> 00:14:44,339
we keep if we put all of that it look

00:14:41,039 --> 00:14:46,559
like a pyramid so which is going up the

00:14:44,339 --> 00:14:48,829
pyramid you are having lesser measures

00:14:46,559 --> 00:14:51,209
and dimensions but more frequently used

00:14:48,829 --> 00:14:54,029
measures and dimensions you would want

00:14:51,209 --> 00:14:55,919
to keep this so that if if the query

00:14:54,029 --> 00:15:01,859
comes you want to answer from the top of

00:14:55,919 --> 00:15:03,839
the pyramid so all this is see all this

00:15:01,859 --> 00:15:06,539
is available at an hourly granularity

00:15:03,839 --> 00:15:07,630
then you you also want to keep all this

00:15:06,539 --> 00:15:12,460
at a daily green

00:15:07,630 --> 00:15:15,580
or monthly and quarterly yearly so other

00:15:12,460 --> 00:15:18,250
side of these pyramids are aggregated at

00:15:15,580 --> 00:15:22,840
time dimensions like daily or hourly

00:15:18,250 --> 00:15:33,100
stuff so we want to view actually fact

00:15:22,840 --> 00:15:35,740
data is this pyramid so once we have the

00:15:33,100 --> 00:15:38,530
fact data this and the dimensions here I

00:15:35,740 --> 00:15:44,920
actually not not the actual full

00:15:38,530 --> 00:15:47,770
dimension Keys dimensions so those are

00:15:44,920 --> 00:15:49,240
only actually the case that contains so

00:15:47,770 --> 00:15:51,880
 data usually contains the

00:15:49,240 --> 00:15:54,430
measures and the dimension keys that you

00:15:51,880 --> 00:15:56,800
cut your measures on and the keys point

00:15:54,430 --> 00:16:01,720
to actually a dimensions a table sitting

00:15:56,800 --> 00:16:04,180
somewhere which which would have all the

00:16:01,720 --> 00:16:07,210
fields of the table for example if if

00:16:04,180 --> 00:16:10,270
your measure is measured at a CT so you

00:16:07,210 --> 00:16:12,430
maybe put a CT ID in the fact and there

00:16:10,270 --> 00:16:14,700
is a city table as one of the dimension

00:16:12,430 --> 00:16:17,670
which will have more details of the city

00:16:14,700 --> 00:16:24,580
which state it belongs to what is its

00:16:17,670 --> 00:16:29,500
lat lon and things like that so this is

00:16:24,580 --> 00:16:32,290
the typical snowflake schema yeah so the

00:16:29,500 --> 00:16:35,470
goal is to actually represent the fact

00:16:32,290 --> 00:16:41,440
and emotional dimension its data in

00:16:35,470 --> 00:16:45,310
Apache hive natively right suit to to

00:16:41,440 --> 00:16:47,680
achieve this we introduced a fork

00:16:45,310 --> 00:16:51,520
first-class constructs something called

00:16:47,680 --> 00:16:55,150
cube storage a fact table and a

00:16:51,520 --> 00:16:56,680
dimension table so I'll go into more

00:16:55,150 --> 00:16:59,500
details of what it is in the coming

00:16:56,680 --> 00:17:06,250
slides and we and fact table and

00:16:59,500 --> 00:17:09,910
dimension tables have physical tables so

00:17:06,250 --> 00:17:13,390
what is a cube cube is nothing but a set

00:17:09,910 --> 00:17:16,300
of measures and dimensions so there is

00:17:13,390 --> 00:17:18,130
no ordering defined for a cube so you

00:17:16,300 --> 00:17:20,040
are just gathering some measures and

00:17:18,130 --> 00:17:24,450
dimensions together so that user

00:17:20,040 --> 00:17:26,520
gorgeous query from a cube what is a

00:17:24,450 --> 00:17:28,080
measure right so measure is nothing

00:17:26,520 --> 00:17:32,610
nothing but anything that you want to

00:17:28,080 --> 00:17:36,390
measure so that that that will have a

00:17:32,610 --> 00:17:38,130
simple name type and and going up going

00:17:36,390 --> 00:17:39,630
up the pyramid that we just saw it will

00:17:38,130 --> 00:17:43,980
have an aggregate function that is

00:17:39,630 --> 00:17:48,900
applied and and they start date and end

00:17:43,980 --> 00:17:51,240
date if if it is there and then there

00:17:48,900 --> 00:17:53,280
can be a expression measure which is

00:17:51,240 --> 00:17:56,550
having a complicated expression for

00:17:53,280 --> 00:17:58,830
example CTR sort of thing right so you

00:17:56,550 --> 00:18:00,570
can define CTR to be a complicated

00:17:58,830 --> 00:18:02,760
measure of already existing measures

00:18:00,570 --> 00:18:05,700
that users don't have to remember it

00:18:02,760 --> 00:18:08,070
every time so you define it here and

00:18:05,700 --> 00:18:09,570
then we just query CTR and that would be

00:18:08,070 --> 00:18:16,200
replaced with the expression of what it

00:18:09,570 --> 00:18:20,460
is and what is the dimension dimension

00:18:16,200 --> 00:18:22,830
is a simple column which is having a

00:18:20,460 --> 00:18:25,110
name and type or a reference and

00:18:22,830 --> 00:18:27,660
dimension which is actually referencing

00:18:25,110 --> 00:18:31,230
another table more like foreign key in

00:18:27,660 --> 00:18:34,680
our DBMS right so it what it is

00:18:31,230 --> 00:18:39,810
referring to another table with an ax

00:18:34,680 --> 00:18:41,850
column or a hierarchical dimension which

00:18:39,810 --> 00:18:45,090
is like location location is a dimension

00:18:41,850 --> 00:18:48,050
where it can have a hierarchy for

00:18:45,090 --> 00:18:49,980
example zip code city state country

00:18:48,050 --> 00:18:52,280
region that is all the hierarchy you

00:18:49,980 --> 00:18:54,750
define for a location dimension so

00:18:52,280 --> 00:18:57,020
hierarchical dimension will have an

00:18:54,750 --> 00:19:00,540
Associated hierarchy associated with it

00:18:57,020 --> 00:19:03,210
an expression dimension will have again

00:19:00,540 --> 00:19:05,850
the expression associated with it which

00:19:03,210 --> 00:19:08,100
can be replaced at the query time and a

00:19:05,850 --> 00:19:10,620
dimension can be a time dimension on

00:19:08,100 --> 00:19:15,630
which you can give time range Paris so

00:19:10,620 --> 00:19:18,090
you'd say that from for one month I want

00:19:15,630 --> 00:19:21,230
on this time dimension I want to query

00:19:18,090 --> 00:19:21,230
on this time dimension

00:19:23,350 --> 00:19:28,920
so some of these concepts are taken from

00:19:26,050 --> 00:19:28,920
Mon right

00:19:29,460 --> 00:19:38,020
and then we go to the next construct

00:19:32,500 --> 00:19:40,540
that is storage so storage is storage is

00:19:38,020 --> 00:19:43,390
nothing but any storage that is out

00:19:40,540 --> 00:19:45,550
there you want to define it in the in

00:19:43,390 --> 00:19:47,970
the model here so you will have a name

00:19:45,550 --> 00:19:50,830
associated to it an end point and

00:19:47,970 --> 00:19:52,420
associate some properties to it for

00:19:50,830 --> 00:19:54,400
example there is a production cluster or

00:19:52,420 --> 00:19:56,680
a staging cluster and there is a post

00:19:54,400 --> 00:20:04,630
grist DB out there or there is HBase

00:19:56,680 --> 00:20:08,650
cluster HBase one two and next we have

00:20:04,630 --> 00:20:15,730
fact table fact table is nothing but a

00:20:08,650 --> 00:20:19,210
table with columns and so you it would

00:20:15,730 --> 00:20:20,590
belong to a cube so we have defined cube

00:20:19,210 --> 00:20:25,840
as mayor set of measures and dimensions

00:20:20,590 --> 00:20:28,690
right so Frank belongs to a cube in the

00:20:25,840 --> 00:20:31,090
sense that the columns here are actually

00:20:28,690 --> 00:20:37,660
subsets of measures and dimensions of

00:20:31,090 --> 00:20:41,440
the cube in fact and fact table is

00:20:37,660 --> 00:20:47,350
present on storages and multiple

00:20:41,440 --> 00:20:51,130
storages and then and it can be updated

00:20:47,350 --> 00:20:53,710
at some update period say there is fat

00:20:51,130 --> 00:20:55,420
table 1 which is present on production

00:20:53,710 --> 00:20:58,780
cluster and also it's staging cluster

00:20:55,420 --> 00:21:01,480
and it is updated hourly daily and

00:20:58,780 --> 00:21:02,890
monthly so that is what that is all you

00:21:01,480 --> 00:21:05,500
define when you are defining a fact

00:21:02,890 --> 00:21:08,320
table so the the columns of the table

00:21:05,500 --> 00:21:10,330
which cube it belongs to and then on

00:21:08,320 --> 00:21:16,840
what are all storages it is present and

00:21:10,330 --> 00:21:18,580
The Associated update periods so the

00:21:16,840 --> 00:21:22,030
relationship between fact and cube is

00:21:18,580 --> 00:21:27,430
fact belongs to the cube and cube

00:21:22,030 --> 00:21:33,600
actually contains multiple facts so if

00:21:27,430 --> 00:21:33,600
we look at the locator pyramid leg

00:21:37,080 --> 00:21:44,019
so here the whole pyramid is like your

00:21:40,539 --> 00:21:47,190
cube and then each box here is one fact

00:21:44,019 --> 00:21:47,190
fact table

00:21:56,539 --> 00:22:01,849
so then fact table is available on

00:21:58,869 --> 00:22:05,779
storages that is what you are seeing and

00:22:01,849 --> 00:22:07,669
then we move to the dimension table so

00:22:05,779 --> 00:22:10,729
dimension table is again a table having

00:22:07,669 --> 00:22:13,849
columns but it would have dimension

00:22:10,729 --> 00:22:17,029
references so dimension table itself can

00:22:13,849 --> 00:22:19,759
refer can have dimension references

00:22:17,029 --> 00:22:21,529
where each each reference here is

00:22:19,759 --> 00:22:27,199
actually referring to another dimension

00:22:21,529 --> 00:22:29,059
table on a on a column rate again

00:22:27,199 --> 00:22:32,539
dimension table can be present on

00:22:29,059 --> 00:22:35,329
multiple storages so a dimension table

00:22:32,539 --> 00:22:37,099
is sort of it is not fact data right so

00:22:35,329 --> 00:22:39,619
fact data is immutable data but

00:22:37,099 --> 00:22:44,569
dimension table is a changing table it

00:22:39,619 --> 00:22:47,089
can't be it is not immutable so what you

00:22:44,569 --> 00:22:50,539
do is either you take snapshot dumps

00:22:47,089 --> 00:22:53,419
every hour or every day or you have a

00:22:50,539 --> 00:22:55,639
corresponding associated table in a

00:22:53,419 --> 00:22:58,999
different storage altogether for example

00:22:55,639 --> 00:23:00,289
if it is in HBase all the Aldabra sure

00:22:58,999 --> 00:23:02,569
all readily available so you are

00:23:00,289 --> 00:23:04,279
pointing to the HBase table directly so

00:23:02,569 --> 00:23:06,109
that doesn't have any snapshot dump but

00:23:04,279 --> 00:23:08,329
your if you are putting the same data in

00:23:06,109 --> 00:23:10,549
HDFS you might want to take daily

00:23:08,329 --> 00:23:12,649
snapshot dumps of your dimension data so

00:23:10,549 --> 00:23:16,129
that you query with your latest data

00:23:12,649 --> 00:23:17,869
anytime you query so when you are

00:23:16,129 --> 00:23:20,509
defining your dimension table here is

00:23:17,869 --> 00:23:22,969
say what are the columns of it and the

00:23:20,509 --> 00:23:26,899
references storages on which it is

00:23:22,969 --> 00:23:32,179
present and the snapshot dumps if there

00:23:26,899 --> 00:23:34,339
are any so the relationship between the

00:23:32,179 --> 00:23:37,009
cube and dimension is Cube is referring

00:23:34,339 --> 00:23:39,379
to a dimension table with the reference

00:23:37,009 --> 00:23:45,409
dimension and dimension table itself can

00:23:39,379 --> 00:23:50,959
refer to other dimension tables and they

00:23:45,409 --> 00:23:54,139
are present on multiple storages so

00:23:50,959 --> 00:23:57,139
storage tables right so a storage table

00:23:54,139 --> 00:23:59,419
is the actual physical table so till now

00:23:57,139 --> 00:24:02,269
what we saw is all logical tables that

00:23:59,419 --> 00:24:05,869
are there which are not associated to

00:24:02,269 --> 00:24:07,339
any storage yet right so storage table

00:24:05,869 --> 00:24:07,830
is the final physical table that is

00:24:07,339 --> 00:24:11,250
actually

00:24:07,830 --> 00:24:16,080
on storage it belongs to a the factor

00:24:11,250 --> 00:24:17,940
dimension so when it belongs to a factor

00:24:16,080 --> 00:24:19,740
dimension it will have actually the same

00:24:17,940 --> 00:24:21,600
schema of the factor dimension that is

00:24:19,740 --> 00:24:23,820
already defined so you'll not again

00:24:21,600 --> 00:24:27,960
define all the columns same things here

00:24:23,820 --> 00:24:29,880
for the storage table but it can have

00:24:27,960 --> 00:24:32,280
its own associated the storage the

00:24:29,880 --> 00:24:35,280
script of example it can be stored in an

00:24:32,280 --> 00:24:40,560
RC file or it is stored by storage

00:24:35,280 --> 00:24:42,960
handler or or it is stored by a stored

00:24:40,560 --> 00:24:45,690
SRC file with the Saudi the custom Saudi

00:24:42,960 --> 00:24:50,310
so all this can be described for each

00:24:45,690 --> 00:24:52,380
storage table and each today's table can

00:24:50,310 --> 00:24:57,540
be partitioned by some columns usually

00:24:52,380 --> 00:25:00,390
these columns are dimensions so so you

00:24:57,540 --> 00:25:04,200
partition your data by some dimensions

00:25:00,390 --> 00:25:06,840
so and these dimensions can be simple

00:25:04,200 --> 00:25:08,520
dimensions our time dimensions so if it

00:25:06,840 --> 00:25:12,690
is time dimensions the range queries

00:25:08,520 --> 00:25:17,670
time range queries will directly pick up

00:25:12,690 --> 00:25:19,170
proper range for the partitions so a

00:25:17,670 --> 00:25:20,970
naming convention for these storage

00:25:19,170 --> 00:25:27,200
tables are like storage name followed by

00:25:20,970 --> 00:25:31,050
the factor dimension name and and

00:25:27,200 --> 00:25:32,490
partitions so storage table you can add

00:25:31,050 --> 00:25:35,660
partitions whenever the data is

00:25:32,490 --> 00:25:38,010
available so for example for a fact

00:25:35,660 --> 00:25:40,500
whenever an hourly partition is

00:25:38,010 --> 00:25:42,600
available you go add it to the storage

00:25:40,500 --> 00:25:44,130
table that is there and each partition

00:25:42,600 --> 00:25:46,830
can again already its own storage

00:25:44,130 --> 00:25:48,570
descriptor so the storage descriptor is

00:25:46,830 --> 00:25:54,150
readily available in hive that is what

00:25:48,570 --> 00:25:56,700
is taken here so facts have a fact

00:25:54,150 --> 00:26:01,380
storage table dimensions have dimension

00:25:56,700 --> 00:26:06,950
storage table so we'll see more queries

00:26:01,380 --> 00:26:06,950
on data cubes with some examples

00:26:08,960 --> 00:26:15,800
so queries on the data cubes that we

00:26:12,930 --> 00:26:19,200
just defined can be accessed through

00:26:15,800 --> 00:26:21,740
simple sequel so what we are doing is we

00:26:19,200 --> 00:26:24,090
are just adding a cube in front of the

00:26:21,740 --> 00:26:27,690
simple sequel expression and there is

00:26:24,090 --> 00:26:30,120
one more added the time range in from a

00:26:27,690 --> 00:26:32,490
faerie column from Mentos so that is an

00:26:30,120 --> 00:26:35,580
optional thing that is also added

00:26:32,490 --> 00:26:40,530
otherwise this is a subset of hive Fairy

00:26:35,580 --> 00:26:43,830
language and then this is the detailed

00:26:40,530 --> 00:26:45,660
description of the grammar I'm not going

00:26:43,830 --> 00:26:54,360
to the second part but the first part is

00:26:45,660 --> 00:26:56,070
simple thing so when a cube if you call

00:26:54,360 --> 00:27:01,140
it cube select query what happens right

00:26:56,070 --> 00:27:03,060
so what we do is we resolve the

00:27:01,140 --> 00:27:06,750
candidate tables so we want to pick

00:27:03,060 --> 00:27:09,480
facts which are which are towards the

00:27:06,750 --> 00:27:13,470
top of the pyramid as as as possible and

00:27:09,480 --> 00:27:15,570
then pick up the storage depending on

00:27:13,470 --> 00:27:17,640
the time range that is queried so for

00:27:15,570 --> 00:27:22,500
the given time range where the data is

00:27:17,640 --> 00:27:25,530
available and then user need not

00:27:22,500 --> 00:27:28,910
remember all the joints that are there

00:27:25,530 --> 00:27:31,950
so right now user has to in the normal

00:27:28,910 --> 00:27:33,780
hive world he has to give all the giant

00:27:31,950 --> 00:27:36,570
expression which is very complicated in

00:27:33,780 --> 00:27:38,130
many cases it will have seven way eight

00:27:36,570 --> 00:27:40,140
way join which he has to remember always

00:27:38,130 --> 00:27:42,830
so all that will be automatically

00:27:40,140 --> 00:27:49,410
resolved because we are defining the

00:27:42,830 --> 00:27:52,740
relationships and then so in a pyramid

00:27:49,410 --> 00:27:55,080
we actually aggregated aggregated some

00:27:52,740 --> 00:27:57,450
measures and kept right so those those

00:27:55,080 --> 00:28:00,390
aggregates will be we will not be known

00:27:57,450 --> 00:28:03,870
to use it or they're known at the cube

00:28:00,390 --> 00:28:05,490
level so he need not always give the

00:28:03,870 --> 00:28:08,730
aggregate again in his query those will

00:28:05,490 --> 00:28:12,000
be automatically resolved and also if a

00:28:08,730 --> 00:28:13,050
if a dimension field is projected it

00:28:12,000 --> 00:28:15,150
will be added to the group by

00:28:13,050 --> 00:28:16,980
automatically so on this is optional you

00:28:15,150 --> 00:28:21,190
can disable all this optional automatic

00:28:16,980 --> 00:28:22,809
resolution and give give proper

00:28:21,190 --> 00:28:24,879
chain by yourself and also the

00:28:22,809 --> 00:28:31,479
aggregates and group by expressions as

00:28:24,879 --> 00:28:33,220
well and then so you can reckon right

00:28:31,479 --> 00:28:36,879
the complicated sequel expression over

00:28:33,220 --> 00:28:40,840
the cube select query so it can be lying

00:28:36,879 --> 00:28:43,539
somewhere down here here nested sequel

00:28:40,840 --> 00:28:51,879
query so all the sequel features come

00:28:43,539 --> 00:28:57,700
for you then queries can spawn multiple

00:28:51,879 --> 00:29:00,279
storages and then not-not-not actually

00:28:57,700 --> 00:29:02,349
the one ring you can give like two days

00:29:00,279 --> 00:29:04,809
of this month and the next two days of

00:29:02,349 --> 00:29:07,749
the next month so it can accept multiple

00:29:04,809 --> 00:29:10,210
time range queries as well and all high

00:29:07,749 --> 00:29:15,099
PLL features come to you so I'll use all

00:29:10,210 --> 00:29:19,210
UDF's windowing functions all the nested

00:29:15,099 --> 00:29:21,399
queries UDF so all the new features that

00:29:19,210 --> 00:29:29,279
are coming in hive you can directly use

00:29:21,399 --> 00:29:32,379
them so we'll see example so this is a

00:29:29,279 --> 00:29:38,320
cube select query where we are selecting

00:29:32,379 --> 00:29:40,599
a city table on name and state ID so say

00:29:38,320 --> 00:29:45,009
CT table is available in two storages

00:29:40,599 --> 00:29:49,749
say c1 and c2 and then so the query

00:29:45,009 --> 00:29:52,509
would be rewritten like this so here and

00:29:49,749 --> 00:29:55,539
c2 city table is present as the native

00:29:52,509 --> 00:29:58,809
table c2 is like HBase where c1 is like

00:29:55,539 --> 00:30:03,070
your HD HDFS cluster where it is

00:29:58,809 --> 00:30:05,759
available with snapshot them so it will

00:30:03,070 --> 00:30:08,769
it will pick up the latest dump of that

00:30:05,759 --> 00:30:10,659
so it would be rereading the rewriting

00:30:08,769 --> 00:30:12,940
the query like this and this query can

00:30:10,659 --> 00:30:20,769
be given to anyone understand sequel

00:30:12,940 --> 00:30:23,830
however Impala shark will see one more

00:30:20,769 --> 00:30:27,639
very little complicated here so here we

00:30:23,830 --> 00:30:31,919
have cube select from a city table name

00:30:27,639 --> 00:30:35,120
for it for each city get the measure

00:30:31,919 --> 00:30:41,420
measure - MSR - from

00:30:35,120 --> 00:30:44,420
you wear time range is 10 10 March third

00:30:41,420 --> 00:30:46,490
hour to 12th much third ever right so

00:30:44,420 --> 00:30:50,020
this is what user wanted so he wanted to

00:30:46,490 --> 00:30:55,910
get value of measure to for city table

00:30:50,020 --> 00:30:59,750
city for each city for two days so so

00:30:55,910 --> 00:31:02,870
this will be rewritten as high PL query

00:30:59,750 --> 00:31:05,000
like this in which the aggregate for

00:31:02,870 --> 00:31:10,120
measure two is put that which is sum and

00:31:05,000 --> 00:31:13,010
it has picked up a fact sheet on c2 and

00:31:10,120 --> 00:31:16,040
they nerd in and it is joining with city

00:31:13,010 --> 00:31:19,330
table on on a condition that city city

00:31:16,040 --> 00:31:23,150
take city table idea is the test cube

00:31:19,330 --> 00:31:24,679
city ID and where it is resolving all

00:31:23,150 --> 00:31:27,530
the partitions that are available for

00:31:24,679 --> 00:31:29,600
the given time range so for the given

00:31:27,530 --> 00:31:32,090
time range it is making up hourly

00:31:29,600 --> 00:31:35,679
partitions for 10th and it is picking up

00:31:32,090 --> 00:31:40,309
picked up daily partition for 11th and

00:31:35,679 --> 00:31:42,290
early partition for 12th again and and

00:31:40,309 --> 00:31:44,720
you just put a group by city table name

00:31:42,290 --> 00:31:49,610
because that is selected and that is not

00:31:44,720 --> 00:31:56,360
a measured quantity so so once this is

00:31:49,610 --> 00:31:58,940
written now this can be run anywhere so

00:31:56,360 --> 00:32:03,140
this is what the data cubes is so where

00:31:58,940 --> 00:32:08,179
is it available so available in hive

00:32:03,140 --> 00:32:09,590
right now so it provides facts and

00:32:08,179 --> 00:32:15,200
dimensions and the logical table

00:32:09,590 --> 00:32:19,000
associated with physical table so now I

00:32:15,200 --> 00:32:21,800
will introduce you to grill which is

00:32:19,000 --> 00:32:24,559
which is done at in movie where we have

00:32:21,800 --> 00:32:31,700
put pluggable execution engine and query

00:32:24,559 --> 00:32:33,950
history and Shatila race and more so

00:32:31,700 --> 00:32:36,530
grill is a unified analytics platform

00:32:33,950 --> 00:32:38,630
done at in mobile which supports

00:32:36,530 --> 00:32:44,120
multiple execution engines and multiple

00:32:38,630 --> 00:32:45,830
storages so it wants to provide

00:32:44,120 --> 00:32:48,110
analytics on the on the same system

00:32:45,830 --> 00:32:50,320
because when you look in the pyramid

00:32:48,110 --> 00:32:56,120
we said actually we want to drop some

00:32:50,320 --> 00:32:59,179
measures and dimensions and and prune

00:32:56,120 --> 00:33:02,270
the pyramid to like most frequently used

00:32:59,179 --> 00:33:04,610
the emissions to go up its but who will

00:33:02,270 --> 00:33:06,650
know that these dimensions are actually

00:33:04,610 --> 00:33:08,570
mostly used only if the querying system

00:33:06,650 --> 00:33:11,000
actually gives that that these are the

00:33:08,570 --> 00:33:13,700
columns that are being paid every day or

00:33:11,000 --> 00:33:15,500
which are the ones that operate so it

00:33:13,700 --> 00:33:20,750
would provide analytics on this system

00:33:15,500 --> 00:33:23,510
itself and it provides history so this

00:33:20,750 --> 00:33:27,799
is this is how the architecture of the

00:33:23,510 --> 00:33:30,980
grille looks so there is a grille server

00:33:27,799 --> 00:33:35,299
which can talk to eligible execution

00:33:30,980 --> 00:33:38,809
engines like hi JD BC or shark car

00:33:35,299 --> 00:33:43,490
Impala and then it supports all data

00:33:38,809 --> 00:33:47,540
stores HDFS HBase calamari WH s3 or

00:33:43,490 --> 00:33:49,580
redshift and then the grille server will

00:33:47,540 --> 00:33:53,000
talk to the OLAP cube microscope that we

00:33:49,580 --> 00:33:55,370
just defined in this talk and then it

00:33:53,000 --> 00:34:01,429
provides actually REST API for querying

00:33:55,370 --> 00:34:03,760
and the schema schema occurred so on top

00:34:01,429 --> 00:34:03,760
of it

00:34:12,090 --> 00:34:19,020
so on top of it we have CL a Java client

00:34:15,669 --> 00:34:21,490
and JDBC and UA is in works and

00:34:19,020 --> 00:34:27,520
applications can directly talk REST API

00:34:21,490 --> 00:34:31,750
as well so how do you in how do you add

00:34:27,520 --> 00:34:33,369
a new plugin execution engine so it has

00:34:31,750 --> 00:34:35,919
to say we implement a simple interface

00:34:33,369 --> 00:34:39,250
which which has things like execute

00:34:35,919 --> 00:34:44,470
explain execute a synchronously and then

00:34:39,250 --> 00:34:46,270
fetch results so what what is the what

00:34:44,470 --> 00:34:48,369
is the one that is joining the execution

00:34:46,270 --> 00:34:50,590
engine with the system is what are the

00:34:48,369 --> 00:34:52,510
storages it can support switch system

00:34:50,590 --> 00:34:54,669
would say I all support these storages

00:34:52,510 --> 00:34:56,610
and those throw register would have been

00:34:54,669 --> 00:35:02,290
already defined for example I would say

00:34:56,610 --> 00:35:04,660
it would suffer it would support HDFS

00:35:02,290 --> 00:35:06,190
cluster say in our example a production

00:35:04,660 --> 00:35:09,940
cluster staging cluster and HBase

00:35:06,190 --> 00:35:12,310
cluster and say s3 and things like that

00:35:09,940 --> 00:35:19,720
and then our JDBC driver would say that

00:35:12,310 --> 00:35:24,220
I support post Chris as storage so when

00:35:19,720 --> 00:35:26,140
a cube select query comes comes here so

00:35:24,220 --> 00:35:28,960
what happens is like we will write the

00:35:26,140 --> 00:35:33,070
query for each execution engine for its

00:35:28,960 --> 00:35:34,810
supported storages and then get cost

00:35:33,070 --> 00:35:37,300
cost of the query for each execution

00:35:34,810 --> 00:35:43,630
engine and then pick up the execution

00:35:37,300 --> 00:35:45,250
engine with minimal cost and then it

00:35:43,630 --> 00:35:50,590
would be given to that execution engine

00:35:45,250 --> 00:35:55,330
to run it so this is how the grilles our

00:35:50,590 --> 00:35:59,410
looks so it has it provides jax-rs GRC a

00:35:55,330 --> 00:36:00,970
PA for the user and then it has a should

00:35:59,410 --> 00:36:03,700
euler service where you can you should

00:36:00,970 --> 00:36:07,150
you query service where you can submit

00:36:03,700 --> 00:36:11,260
your query and then fetch status of it

00:36:07,150 --> 00:36:14,080
and then fetch the results and then

00:36:11,260 --> 00:36:16,990
there is a meta stored service to browse

00:36:14,080 --> 00:36:19,210
the meta store and then session service

00:36:16,990 --> 00:36:21,910
we are which which usually gives the

00:36:19,210 --> 00:36:22,589
shell experience so you open a session

00:36:21,910 --> 00:36:25,019
set

00:36:22,589 --> 00:36:30,509
configurations secure DB what DB wants

00:36:25,019 --> 00:36:32,549
to use and things and it has hype driver

00:36:30,509 --> 00:36:34,799
JDBC driver and Impala driver for now

00:36:32,549 --> 00:36:38,849
and other drivers are not there and it

00:36:34,799 --> 00:36:43,109
has an even service to send events

00:36:38,849 --> 00:36:47,519
across these services so the code status

00:36:43,109 --> 00:36:49,859
right now is the things that are all in

00:36:47,519 --> 00:36:52,469
green are done so red they are not done

00:36:49,859 --> 00:36:54,769
metrics and statistics part of it is

00:36:52,469 --> 00:36:57,059
done statistics is not it there

00:36:54,769 --> 00:36:58,460
otherwise we have very service might

00:36:57,059 --> 00:37:03,599
restore service session service

00:36:58,460 --> 00:37:08,519
available so here are some statistics

00:37:03,599 --> 00:37:11,759
that we have at in movie so 700 to 900

00:37:08,519 --> 00:37:16,529
calories per day and 125 dimension

00:37:11,759 --> 00:37:21,059
tables and 24 fact tables 15 cubes and

00:37:16,529 --> 00:37:24,359
then total size of the data is 136 TB

00:37:21,059 --> 00:37:28,619
and the dimension data is which is domed

00:37:24,359 --> 00:37:37,039
every hour is 400 MB and raw data is 1.2

00:37:28,619 --> 00:37:39,450
terabytes and 53 aggregate effects so

00:37:37,039 --> 00:37:43,769
the attack cubes in a patch hive is

00:37:39,450 --> 00:37:46,380
proposed in high 4 1 1 5 so it is it is

00:37:43,769 --> 00:37:50,130
part of it is dead in the branch high 4

00:37:46,380 --> 00:37:53,519
1 1 5 but actual code is pushed to you

00:37:50,130 --> 00:37:56,849
know be high so will try and push it

00:37:53,519 --> 00:38:00,420
apache hype soon there is the code for

00:37:56,849 --> 00:38:03,900
grill is there in in MOBA grill so and

00:38:00,420 --> 00:38:06,210
that and it is fully documented it at

00:38:03,900 --> 00:38:09,390
the given documentation link so you can

00:38:06,210 --> 00:38:11,779
just go try it as well it is all open

00:38:09,390 --> 00:38:11,779
source

00:38:17,560 --> 00:38:23,000
we have time for some questions and if

00:38:21,620 --> 00:38:30,260
anyone has a question they can use the

00:38:23,000 --> 00:38:33,440
mic good nice presentation Thanks

00:38:30,260 --> 00:38:36,980
question about whether or not you've

00:38:33,440 --> 00:38:42,890
tried Apache Phoenix as a JDBC driver

00:38:36,980 --> 00:38:45,500
for your HP data we can we can have a

00:38:42,890 --> 00:38:47,240
Phoenix driver so that can be just

00:38:45,500 --> 00:38:50,750
plugged in as well it it shouldn't be a

00:38:47,240 --> 00:38:52,370
problem okay yeah see if we can just

00:38:50,750 --> 00:39:04,250
implement the interface it is right

00:38:52,370 --> 00:39:06,920
there any other questions so if you have

00:39:04,250 --> 00:39:08,960
multiple execution engines do you give

00:39:06,920 --> 00:39:12,680
an opportunity for the application to

00:39:08,960 --> 00:39:15,290
specify which execution in unit 1 to get

00:39:12,680 --> 00:39:17,690
the data from no you won't actually

00:39:15,290 --> 00:39:20,570
abstract that from the user because that

00:39:17,690 --> 00:39:22,400
is confusing for him to choose so not

00:39:20,570 --> 00:39:28,630
for the user but at an application level

00:39:22,400 --> 00:39:28,630
somehow it's not something it's not

00:39:32,300 --> 00:39:38,420
you mentioned that you do some you get

00:39:36,440 --> 00:39:40,460
cost information for the queries from

00:39:38,420 --> 00:39:43,250
all the are you getting that from the

00:39:40,460 --> 00:39:46,430
storage systems and I'm wondering how

00:39:43,250 --> 00:39:48,980
are you how are you calculating the cost

00:39:46,430 --> 00:39:51,350
right now where does cost is not

00:39:48,980 --> 00:39:55,370
calculated yet so what we are doing is

00:39:51,350 --> 00:39:56,990
number of grew by expressions the joints

00:39:55,370 --> 00:39:59,660
that they're calling so depending on

00:39:56,990 --> 00:40:04,310
that we're coming up with a normalized

00:39:59,660 --> 00:40:06,890
value tip but haven't done that fully

00:40:04,310 --> 00:40:09,680
okay so it's not based on data sizes

00:40:06,890 --> 00:40:11,090
yeah or anything like that it will it'll

00:40:09,680 --> 00:40:12,890
be based on data size as well you to

00:40:11,090 --> 00:40:16,070
look at how much data it is being it is

00:40:12,890 --> 00:40:18,770
accessed so if it is for a day then

00:40:16,070 --> 00:40:20,630
maybe column are did a warehouse can

00:40:18,770 --> 00:40:27,380
answer it but if it is for a month it

00:40:20,630 --> 00:40:29,120
has to go to DFS yeah all right well

00:40:27,380 --> 00:40:31,390
let's think I'm Irish sorry for a great

00:40:29,120 --> 00:40:31,390

YouTube URL: https://www.youtube.com/watch?v=AFEvwOl6u40


