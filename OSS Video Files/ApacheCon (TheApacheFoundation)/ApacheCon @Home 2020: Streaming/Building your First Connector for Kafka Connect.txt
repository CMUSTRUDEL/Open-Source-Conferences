Title: Building your First Connector for Kafka Connect
Publication date: 2020-10-22
Playlist: ApacheCon @Home 2020: Streaming
Description: 
	Building your First Connector for Kafka Connect
Ricardo Ferreira

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Apache Kafka is rapidly becoming the de-facto standard for distributed streaming architectures, and as its adoption grows the need to leverage existing data also grows. When developers need to handle certain technologies that happen to not have an connector available; they have no other choice other than write their own. But that can be quite challenging, even for experienced developers. This talk will explain in details what it takes to develop a connector, how the Kafka Connect framework works, and what are the common pitfalls that you should avoid. The code of an existing connector will be used to explain how the implementation should look like so you can develop more confidence when building your own.

Ricardo is a Developer Advocate at Confluent, the company founded by the original co-creators of Apache Kafka. He has over 20 years of experience where he specializes in streaming data architectures, big data, cloud, and serverless. Prior to Confluent, he worked for other vendors, such as Oracle, Red Hat, and IONA Technologies, as well as several consulting firms. When not working, he enjoys grilling steaks in his backyard with his family and friends, where he gets the chance to talk about anything that is not IT related. Currently, he lives in Raleigh, North Carolina, with his wife and son. Follow Ricardo on Twitter: @riferrei
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:35,440 --> 00:00:38,879
right let's get started

00:00:36,559 --> 00:00:40,399
um welcome to the everyone that is

00:00:38,879 --> 00:00:42,879
attending this session about building

00:00:40,399 --> 00:00:45,039
your first connector with kafka

00:00:42,879 --> 00:00:46,000
my name is ricardo and i'm uh i'm gonna

00:00:45,039 --> 00:00:48,879
share the

00:00:46,000 --> 00:00:50,160
my contact dictators in a moment uh but

00:00:48,879 --> 00:00:51,600
just a heads up for everybody that is

00:00:50,160 --> 00:00:51,920
attending the session this is going to

00:00:51,600 --> 00:00:54,800
be

00:00:51,920 --> 00:00:55,600
a very heavy demo session so throughout

00:00:54,800 --> 00:00:57,600
the following

00:00:55,600 --> 00:00:59,680
throughout the next 30 minutes i'm gonna

00:00:57,600 --> 00:01:01,520
be showing how to build your connector

00:00:59,680 --> 00:01:03,680
uh basically there are those lights i'm

00:01:01,520 --> 00:01:04,720
basically gonna use an ide for showing

00:01:03,680 --> 00:01:06,640
how to code

00:01:04,720 --> 00:01:08,240
and how to structure your code and how

00:01:06,640 --> 00:01:09,920
to do implementation so

00:01:08,240 --> 00:01:11,520
any questions that you might have please

00:01:09,920 --> 00:01:14,080
hold them until the end

00:01:11,520 --> 00:01:15,520
right uh let me start here on the screen

00:01:14,080 --> 00:01:19,040
so we can

00:01:15,520 --> 00:01:21,040
share my details of

00:01:19,040 --> 00:01:22,799
uh all right so hopefully you can see my

00:01:21,040 --> 00:01:24,400
screen um

00:01:22,799 --> 00:01:26,000
the title of this presentation i call

00:01:24,400 --> 00:01:27,920
building your first connection for kafka

00:01:26,000 --> 00:01:29,759
connect because the whole intention of

00:01:27,920 --> 00:01:33,600
the presentations is to show

00:01:29,759 --> 00:01:35,600
and share uh what it takes to for you to

00:01:33,600 --> 00:01:39,119
build a connector with afghan

00:01:35,600 --> 00:01:40,960
right so many of you actually

00:01:39,119 --> 00:01:42,560
might have experiences before of kafka

00:01:40,960 --> 00:01:44,000
using it as a messaging platform

00:01:42,560 --> 00:01:45,600
as a message broker or a streaming

00:01:44,000 --> 00:01:48,159
platform uh but

00:01:45,600 --> 00:01:49,119
from time to time you might have the uh

00:01:48,159 --> 00:01:51,280
the need

00:01:49,119 --> 00:01:52,880
to actually uh integrate kafka with some

00:01:51,280 --> 00:01:54,479
other technologies right and

00:01:52,880 --> 00:01:55,920
for those of you in it they will kafka

00:01:54,479 --> 00:01:57,920
very well you know that there is this

00:01:55,920 --> 00:02:00,560
framework called kafka connect

00:01:57,920 --> 00:02:01,680
which acts as the integration layer for

00:02:00,560 --> 00:02:04,880
kafka right

00:02:01,680 --> 00:02:07,280
um it works pretty well uh obviously

00:02:04,880 --> 00:02:08,800
right but the reality is that from time

00:02:07,280 --> 00:02:10,399
to time you also have to deal with

00:02:08,800 --> 00:02:12,640
technology that don't have connectors

00:02:10,399 --> 00:02:14,640
available uh you name it like for

00:02:12,640 --> 00:02:16,800
any specific technology that maybe is

00:02:14,640 --> 00:02:18,560
too new or maybe it's too old uh it

00:02:16,800 --> 00:02:21,360
might be the inverse sometimes

00:02:18,560 --> 00:02:23,440
uh and for those cases you you actually

00:02:21,360 --> 00:02:25,360
have to know how to build your own right

00:02:23,440 --> 00:02:27,520
that's the trick right and this is what

00:02:25,360 --> 00:02:29,920
what's going to be the session about

00:02:27,520 --> 00:02:31,519
um this is my twitter handle uh right

00:02:29,920 --> 00:02:32,319
here in the bottom so for those of you

00:02:31,519 --> 00:02:34,560
that care

00:02:32,319 --> 00:02:36,160
to follow me on twitter uh from time to

00:02:34,560 --> 00:02:38,480
time i actually share some content about

00:02:36,160 --> 00:02:41,760
kafka and streaming technology so

00:02:38,480 --> 00:02:43,760
keep those in mind right um

00:02:41,760 --> 00:02:45,519
for for those of you that don't know me

00:02:43,760 --> 00:02:46,800
actually my clicker probably is not in

00:02:45,519 --> 00:02:48,959
the right time yeah

00:02:46,800 --> 00:02:50,640
now it's working so for those of you

00:02:48,959 --> 00:02:52,560
that know me my name is ricardo right

00:02:50,640 --> 00:02:53,440
i'm a developer advocate in this company

00:02:52,560 --> 00:02:56,160
called elastic

00:02:53,440 --> 00:02:56,800
uh where i'm part of the community team

00:02:56,160 --> 00:02:59,840
so

00:02:56,800 --> 00:03:01,680
basically what i do 24x7 is to connect

00:02:59,840 --> 00:03:03,920
people and developers with knowledge

00:03:01,680 --> 00:03:05,840
for that that's pretty much the sense of

00:03:03,920 --> 00:03:08,560
what i do as a developer advocate

00:03:05,840 --> 00:03:09,680
um and also um i i'm part of the kafka

00:03:08,560 --> 00:03:11,120
summit pc member

00:03:09,680 --> 00:03:13,680
uh for those of you that know this

00:03:11,120 --> 00:03:15,360
conference which is pretty good um

00:03:13,680 --> 00:03:17,519
i'm part of the committee that actually

00:03:15,360 --> 00:03:19,519
this there's a selection of which tops

00:03:17,519 --> 00:03:21,599
is going to compose the final agenda

00:03:19,519 --> 00:03:23,360
so i've been doing this for since last

00:03:21,599 --> 00:03:26,560
year and

00:03:23,360 --> 00:03:28,640
i i've been like lucky to kind of share

00:03:26,560 --> 00:03:30,400
this uh position with other

00:03:28,640 --> 00:03:33,200
very smart folks from the community as

00:03:30,400 --> 00:03:35,159
well those are my main contacts so this

00:03:33,200 --> 00:03:37,519
is my email from elastic right for a

00:03:35,159 --> 00:03:39,040
thelastic.com and this is my personal

00:03:37,519 --> 00:03:40,640
email if you care to like

00:03:39,040 --> 00:03:41,840
get in touch for anything that's not

00:03:40,640 --> 00:03:42,879
necessarily has to do with this

00:03:41,840 --> 00:03:44,720
presentation or

00:03:42,879 --> 00:03:46,799
with the technology that i often talk

00:03:44,720 --> 00:03:47,440
about in conferences and meetups uh so

00:03:46,799 --> 00:03:49,680
the referee

00:03:47,440 --> 00:03:52,319
bryfree.com right and as i mentioned

00:03:49,680 --> 00:03:55,360
before this is my twitter handler so

00:03:52,319 --> 00:03:56,159
um not in this presentation but in the

00:03:55,360 --> 00:03:57,680
next one

00:03:56,159 --> 00:03:59,280
the three hand is going to be available

00:03:57,680 --> 00:04:01,680
on all the slides right

00:03:59,280 --> 00:04:03,840
um as i mentioned before this

00:04:01,680 --> 00:04:06,239
presentation is going to be heavily demo

00:04:03,840 --> 00:04:08,319
passage so there is no slide so

00:04:06,239 --> 00:04:10,319
in order to prove to you this is

00:04:08,319 --> 00:04:12,080
actually the the final next light of

00:04:10,319 --> 00:04:13,760
this presentation so i'm actually going

00:04:12,080 --> 00:04:16,320
to

00:04:13,760 --> 00:04:17,759
close this window right now because we

00:04:16,320 --> 00:04:20,000
don't need it anymore

00:04:17,759 --> 00:04:21,600
um and pretty much what we are going to

00:04:20,000 --> 00:04:24,000
do is to

00:04:21,600 --> 00:04:25,040
play with this github repository right

00:04:24,000 --> 00:04:28,400
here so

00:04:25,040 --> 00:04:30,000
just a heads up um in this session we're

00:04:28,400 --> 00:04:31,040
going to focus on building connectors

00:04:30,000 --> 00:04:33,040
for kafka

00:04:31,040 --> 00:04:34,479
there will be a neck and a second

00:04:33,040 --> 00:04:35,040
session that i'm going to literally

00:04:34,479 --> 00:04:37,199
deliver

00:04:35,040 --> 00:04:39,680
after this presentation which is going

00:04:37,199 --> 00:04:40,960
to cover all the concepts and some of

00:04:39,680 --> 00:04:43,360
the underlying uh

00:04:40,960 --> 00:04:44,800
understanding about what kafka is and

00:04:43,360 --> 00:04:46,880
what kafka does so

00:04:44,800 --> 00:04:47,919
if you're new to kafka i would highly

00:04:46,880 --> 00:04:49,680
encourage you to

00:04:47,919 --> 00:04:51,280
uh keep in the session right it's gonna

00:04:49,680 --> 00:04:53,759
be literally right

00:04:51,280 --> 00:04:54,960
next to the session so uh maybe the

00:04:53,759 --> 00:04:56,400
sessions might be until

00:04:54,960 --> 00:04:58,160
to advance it for you but for those of

00:04:56,400 --> 00:05:00,080
you that know kafka already

00:04:58,160 --> 00:05:01,280
this might be your chance to know how to

00:05:00,080 --> 00:05:04,880
build your kafka connector

00:05:01,280 --> 00:05:06,639
right so uh this is the uh

00:05:04,880 --> 00:05:08,880
this is a github repository that i've

00:05:06,639 --> 00:05:10,160
created that actually has a skeleton of

00:05:08,880 --> 00:05:12,400
a pre-built

00:05:10,160 --> 00:05:14,000
connector for kafka right i've built

00:05:12,400 --> 00:05:16,240
this because i

00:05:14,000 --> 00:05:17,680
uh about four months ago i've put myself

00:05:16,240 --> 00:05:19,520
in the seat of developers

00:05:17,680 --> 00:05:21,280
wanting to create their own connectors

00:05:19,520 --> 00:05:22,639
and what i found is that there's a lot

00:05:21,280 --> 00:05:25,039
of documentation out there

00:05:22,639 --> 00:05:26,960
uh specifically from the kafka con uh

00:05:25,039 --> 00:05:28,080
pachi kafka documentation website for an

00:05:26,960 --> 00:05:30,440
apache route

00:05:28,080 --> 00:05:32,160
that takes you the concepts the

00:05:30,440 --> 00:05:34,400
architecturally and

00:05:32,160 --> 00:05:36,240
a little bit of the uh the java api

00:05:34,400 --> 00:05:38,160
that's uh that's behind the you're

00:05:36,240 --> 00:05:39,759
building your own connector right but

00:05:38,160 --> 00:05:40,960
what is not available out there very

00:05:39,759 --> 00:05:44,080
easily is

00:05:40,960 --> 00:05:46,320
uh a skeleton of code

00:05:44,080 --> 00:05:48,160
that gives you everything you you need

00:05:46,320 --> 00:05:48,479
to actually start with the right foot

00:05:48,160 --> 00:05:50,320
right

00:05:48,479 --> 00:05:52,720
and this is exactly what this wrapper

00:05:50,320 --> 00:05:53,120
does so i'm going to share this link

00:05:52,720 --> 00:05:56,639
here

00:05:53,120 --> 00:06:00,160
on the comment section so

00:05:56,639 --> 00:06:02,160
we can all have uh i'm going to post it

00:06:00,160 --> 00:06:03,680
right here

00:06:02,160 --> 00:06:06,479
session so everybody can actually have a

00:06:03,680 --> 00:06:08,880
copy of it and then what i'm gonna do

00:06:06,479 --> 00:06:10,800
is to start with the demo right so i'm

00:06:08,880 --> 00:06:12,479
gonna clone this wrapper right here

00:06:10,800 --> 00:06:14,080
and i'm gonna spin up an environment

00:06:12,479 --> 00:06:16,400
that is basic on docker

00:06:14,080 --> 00:06:18,479
uh that is available here and this is

00:06:16,400 --> 00:06:19,440
has a pre-built connector that i'm going

00:06:18,479 --> 00:06:22,319
to deploy it

00:06:19,440 --> 00:06:23,440
and show if it's work right uh and then

00:06:22,319 --> 00:06:25,199
we can start from there like

00:06:23,440 --> 00:06:26,800
if it's working i can start walking

00:06:25,199 --> 00:06:29,440
through the how the code is

00:06:26,800 --> 00:06:31,120
structured and what are the uh

00:06:29,440 --> 00:06:31,840
implementation aspect that you have to

00:06:31,120 --> 00:06:34,240
know about it

00:06:31,840 --> 00:06:35,600
right so let's start with the first most

00:06:34,240 --> 00:06:38,080
obvious step which is

00:06:35,600 --> 00:06:39,400
cloning the raffle right so i'm gonna

00:06:38,080 --> 00:06:42,639
i'm gonna actually create

00:06:39,400 --> 00:06:46,400
a new terminal over here

00:06:42,639 --> 00:06:48,080
uh somewhere my terminal ended up in the

00:06:46,400 --> 00:06:50,960
second monitor but i can create a new

00:06:48,080 --> 00:06:52,800
window over here so i'm gonna

00:06:50,960 --> 00:06:54,880
zoom in a little bit because i know

00:06:52,800 --> 00:06:55,520
that's when we share our screens in a

00:06:54,880 --> 00:06:57,599
conference

00:06:55,520 --> 00:06:59,840
sometimes the font size is not too big

00:06:57,599 --> 00:07:01,680
hopefully this is going to be enough

00:06:59,840 --> 00:07:04,479
and so what i'm going gonna do i'm gonna

00:07:01,680 --> 00:07:07,280
create a director here called apachecon

00:07:04,479 --> 00:07:09,199
on my temp folder right so i'm gonna

00:07:07,280 --> 00:07:12,720
actually get there

00:07:09,199 --> 00:07:15,680
so i'm gonna uh execute my

00:07:12,720 --> 00:07:16,560
ide right here in this folder so i'm

00:07:15,680 --> 00:07:18,479
doing this because

00:07:16,560 --> 00:07:20,160
i want to show you how to actually start

00:07:18,479 --> 00:07:23,199
from fresh right so

00:07:20,160 --> 00:07:26,240
this is um literally

00:07:23,199 --> 00:07:28,479
a new fresh folder where actually i

00:07:26,240 --> 00:07:30,319
should not have started the id yet

00:07:28,479 --> 00:07:31,840
so what i'm going to do here is actually

00:07:30,319 --> 00:07:34,160
to git clone

00:07:31,840 --> 00:07:35,199
that rapple that i've just copied right

00:07:34,160 --> 00:07:38,880
so i'm going to

00:07:35,199 --> 00:07:40,639
clone it right here okay so now we can

00:07:38,880 --> 00:07:44,000
actually

00:07:40,639 --> 00:07:45,360
start code referencing that project

00:07:44,000 --> 00:07:47,680
and this is the project that i've

00:07:45,360 --> 00:07:51,199
mentioned before is available on github

00:07:47,680 --> 00:07:52,720
so i'm going to explain the structure of

00:07:51,199 --> 00:07:56,319
this project in a moment

00:07:52,720 --> 00:07:57,520
right but i'd like to i like to start by

00:07:56,319 --> 00:08:00,080
explaining what the code

00:07:57,520 --> 00:08:01,919
does right because as a developer if

00:08:00,080 --> 00:08:03,599
you're looking to what the code does you

00:08:01,919 --> 00:08:04,400
might be a little more comfortable in

00:08:03,599 --> 00:08:06,000
understanding

00:08:04,400 --> 00:08:08,160
what is the code behind it and what it

00:08:06,000 --> 00:08:09,280
does right so the first thing i'm going

00:08:08,160 --> 00:08:12,400
to do here

00:08:09,280 --> 00:08:15,280
is to actually let me

00:08:12,400 --> 00:08:15,759
increase the font size a little bit uh

00:08:15,280 --> 00:08:18,080
and

00:08:15,759 --> 00:08:20,000
for those of you that maybe are

00:08:18,080 --> 00:08:23,440
struggling to see the phone size

00:08:20,000 --> 00:08:26,160
if you double tap your screen on hop

00:08:23,440 --> 00:08:27,520
in you might you might actually zoom in

00:08:26,160 --> 00:08:28,639
a little bit so it might be a little

00:08:27,520 --> 00:08:31,759
bigger for you

00:08:28,639 --> 00:08:33,120
so as i mentioned before as part of this

00:08:31,759 --> 00:08:35,760
code is badges on docker

00:08:33,120 --> 00:08:37,120
right so there is a uh docker compose

00:08:35,760 --> 00:08:39,440
yaml file over here

00:08:37,120 --> 00:08:41,200
that in order to use you actually have

00:08:39,440 --> 00:08:41,680
to have docker compose installed your

00:08:41,200 --> 00:08:44,159
machine

00:08:41,680 --> 00:08:45,680
right all the code has been written in

00:08:44,159 --> 00:08:48,000
java because this is a

00:08:45,680 --> 00:08:48,880
programming language where the kafka

00:08:48,000 --> 00:08:51,360
connect framework

00:08:48,880 --> 00:08:52,080
is available right and you gotta also

00:08:51,360 --> 00:08:54,399
have to be

00:08:52,080 --> 00:08:56,240
uh stellar on your computer maven right

00:08:54,399 --> 00:08:59,040
because the coco build is

00:08:56,240 --> 00:09:00,560
based on maybe so and this is what i'm

00:08:59,040 --> 00:09:04,160
gonna do right now i'm gonna actually

00:09:00,560 --> 00:09:06,560
uh build this project so i'm gonna

00:09:04,160 --> 00:09:07,279
clean and package so it's going to

00:09:06,560 --> 00:09:10,800
generate

00:09:07,279 --> 00:09:13,360
a new deployment deployment archive

00:09:10,800 --> 00:09:15,120
right and the folder so just for you

00:09:13,360 --> 00:09:17,279
just to know

00:09:15,120 --> 00:09:19,760
the file that is going to be generated

00:09:17,279 --> 00:09:23,279
is going to be this one over here right

00:09:19,760 --> 00:09:26,320
actually generated sources

00:09:23,279 --> 00:09:29,839
components packages

00:09:26,320 --> 00:09:31,680
yeah that's right here the zip file over

00:09:29,839 --> 00:09:34,640
here that's your deployment

00:09:31,680 --> 00:09:35,040
unit for kafka connect right so this is

00:09:34,640 --> 00:09:37,519
what

00:09:35,040 --> 00:09:39,040
you are actually going to deploy on a

00:09:37,519 --> 00:09:41,680
typical kafka connects um

00:09:39,040 --> 00:09:42,800
clustering all right but we're going to

00:09:41,680 --> 00:09:44,880
talk about the project

00:09:42,800 --> 00:09:46,080
structure later now that you have built

00:09:44,880 --> 00:09:49,519
the project

00:09:46,080 --> 00:09:52,240
we can actually start up the

00:09:49,519 --> 00:09:53,920
because i'm gonna start up the

00:09:52,240 --> 00:09:56,399
environment as a dealer over here

00:09:53,920 --> 00:09:57,360
so this docker compose basically has a

00:09:56,399 --> 00:10:00,080
zookeeper

00:09:57,360 --> 00:10:01,519
uh a kafka kafka broker salad and a

00:10:00,080 --> 00:10:05,040
kafka connect as well

00:10:01,519 --> 00:10:08,320
so let's follow log

00:10:05,040 --> 00:10:11,519
logs to see if the server started up uh

00:10:08,320 --> 00:10:13,680
appropriately so

00:10:11,519 --> 00:10:15,519
so there in this docker compose there

00:10:13,680 --> 00:10:17,120
are basically three instances of docker

00:10:15,519 --> 00:10:19,040
components right so the first one is the

00:10:17,120 --> 00:10:20,320
keeper the kafka broker and kafka

00:10:19,040 --> 00:10:22,000
connect

00:10:20,320 --> 00:10:24,240
you know that kafka connect is actually

00:10:22,000 --> 00:10:26,959
uh running in its own jvm

00:10:24,240 --> 00:10:28,160
that connects to the java to the kafka

00:10:26,959 --> 00:10:31,200
broker so those are

00:10:28,160 --> 00:10:34,720
two separate deployments okay

00:10:31,200 --> 00:10:35,920
so the kafka server is up and i'm going

00:10:34,720 --> 00:10:38,399
to actually split

00:10:35,920 --> 00:10:39,360
this turn over here because i want you

00:10:38,399 --> 00:10:41,680
to see

00:10:39,360 --> 00:10:43,440
what is going to happen after start

00:10:41,680 --> 00:10:45,360
playing with the connector right

00:10:43,440 --> 00:10:47,279
right now there's no connector deploy

00:10:45,360 --> 00:10:48,959
the connector has been built but haven't

00:10:47,279 --> 00:10:51,040
been deployed right so

00:10:48,959 --> 00:10:52,160
uh the only thing is running right now

00:10:51,040 --> 00:10:54,880
is the kafka connect

00:10:52,160 --> 00:10:56,640
server so what i'm gonna do and actually

00:10:54,880 --> 00:10:58,240
when you do this by yourself you can

00:10:56,640 --> 00:10:59,279
follow the instructions here on the

00:10:58,240 --> 00:11:01,519
github

00:10:59,279 --> 00:11:03,519
repo so the first step is obviously what

00:11:01,519 --> 00:11:06,320
we just did which is building the

00:11:03,519 --> 00:11:08,320
project the second step is to start up

00:11:06,320 --> 00:11:11,040
the docker compose and the third

00:11:08,320 --> 00:11:12,079
step is to actually deploy the connector

00:11:11,040 --> 00:11:15,279
right

00:11:12,079 --> 00:11:16,640
so this is a curve command uh i'm gonna

00:11:15,279 --> 00:11:18,320
run it over here

00:11:16,640 --> 00:11:20,560
right as you can see here this cur

00:11:18,320 --> 00:11:23,360
command is going to post

00:11:20,560 --> 00:11:25,279
a to this end point over here that is

00:11:23,360 --> 00:11:28,399
exposed by the kafka connect server

00:11:25,279 --> 00:11:30,480
under the port 8083 right and

00:11:28,399 --> 00:11:32,079
basically has this json payload that

00:11:30,480 --> 00:11:33,200
comprises the connector deployment

00:11:32,079 --> 00:11:33,839
details right i'm going to show in a

00:11:33,200 --> 00:11:36,480
second but

00:11:33,839 --> 00:11:37,839
let's deploy it for a second so as you

00:11:36,480 --> 00:11:41,040
can see here

00:11:37,839 --> 00:11:43,360
when the rest end point finishes

00:11:41,040 --> 00:11:44,959
the the deployment happens right so now

00:11:43,360 --> 00:11:47,120
we have the connector actually

00:11:44,959 --> 00:11:48,959
what this custom connector does is to

00:11:47,120 --> 00:11:51,440
for every five seconds

00:11:48,959 --> 00:11:52,959
it keeps pulling data out of nowhere is

00:11:51,440 --> 00:11:55,279
a fixture to a set of data that i

00:11:52,959 --> 00:11:57,519
basically wrote hard-coded in the code

00:11:55,279 --> 00:11:59,600
just to emphasize that it can be reading

00:11:57,519 --> 00:12:02,079
for in anything right

00:11:59,600 --> 00:12:03,519
um and what it does is basically this is

00:12:02,079 --> 00:12:04,880
a source connector so

00:12:03,519 --> 00:12:06,560
basically the role of the source

00:12:04,880 --> 00:12:09,200
connector is to read the data

00:12:06,560 --> 00:12:10,560
from a source system and bring it into

00:12:09,200 --> 00:12:13,760
kafka right

00:12:10,560 --> 00:12:16,880
so considering that the data is on kafka

00:12:13,760 --> 00:12:17,839
we can actually expect this using this

00:12:16,880 --> 00:12:20,240
doctor

00:12:17,839 --> 00:12:21,120
execution for those of you that know

00:12:20,240 --> 00:12:25,040
kafka

00:12:21,120 --> 00:12:27,040
you know what is um kafka console

00:12:25,040 --> 00:12:28,320
consumer does so basically we are going

00:12:27,040 --> 00:12:30,240
to create a consumer

00:12:28,320 --> 00:12:32,800
that's going to keep pulling the data

00:12:30,240 --> 00:12:34,240
out of the specific kafka topic which in

00:12:32,800 --> 00:12:37,920
this case the kafka topic

00:12:34,240 --> 00:12:39,519
source one so what it needs to happen is

00:12:37,920 --> 00:12:42,000
that every five seconds

00:12:39,519 --> 00:12:43,839
a new entry data from source one should

00:12:42,000 --> 00:12:47,120
appears over here so

00:12:43,839 --> 00:12:47,120
yeah it's working

00:12:48,560 --> 00:12:52,560
so this is only to prove the case that

00:12:50,240 --> 00:12:55,600
um what this uh

00:12:52,560 --> 00:12:58,720
skeleton does is to give you

00:12:55,600 --> 00:13:01,440
a pre-built and pre-reading code

00:12:58,720 --> 00:13:03,200
that contains a kafka connector that is

00:13:01,440 --> 00:13:05,279
ready to go right obviously

00:13:03,200 --> 00:13:06,880
when you start building your own you

00:13:05,279 --> 00:13:08,000
what you want to do is basically clone

00:13:06,880 --> 00:13:10,399
this rapple and

00:13:08,000 --> 00:13:11,760
basically change the code to do you to

00:13:10,399 --> 00:13:13,600
satisfy the requirements that you

00:13:11,760 --> 00:13:14,800
already have such as

00:13:13,600 --> 00:13:16,880
writing the code that actually is going

00:13:14,800 --> 00:13:19,920
to connect with your search system but

00:13:16,880 --> 00:13:20,720
all the skeleton code which sometimes

00:13:19,920 --> 00:13:22,880
that's what i

00:13:20,720 --> 00:13:24,160
i have felt actually when i was studying

00:13:22,880 --> 00:13:26,000
kafka connect

00:13:24,160 --> 00:13:27,680
the cafe connect framework which is

00:13:26,000 --> 00:13:28,480
sometimes it's not very trivial to

00:13:27,680 --> 00:13:29,600
understand

00:13:28,480 --> 00:13:31,839
right there is a little bit of a

00:13:29,600 --> 00:13:34,480
complexity uh inherited complexity on

00:13:31,839 --> 00:13:36,880
the kafka connect framework

00:13:34,480 --> 00:13:38,560
it's not it's not necessarily that's uh

00:13:36,880 --> 00:13:40,880
bad documented

00:13:38,560 --> 00:13:42,560
but uh what i found is that the language

00:13:40,880 --> 00:13:43,120
that you use in the documentation kind

00:13:42,560 --> 00:13:45,120
of

00:13:43,120 --> 00:13:46,320
pre-assumes too much free knowledge

00:13:45,120 --> 00:13:47,680
right so

00:13:46,320 --> 00:13:50,160
for those of you that started from

00:13:47,680 --> 00:13:51,360
scratch that might be uh some sort of

00:13:50,160 --> 00:13:54,720
struggle sometimes

00:13:51,360 --> 00:13:55,839
right so we've seen that's working so

00:13:54,720 --> 00:13:59,920
i'm gonna stop

00:13:55,839 --> 00:14:01,920
this console over here um i'm gonna exit

00:13:59,920 --> 00:14:03,760
we don't need this anymore and then i'm

00:14:01,920 --> 00:14:05,760
going to

00:14:03,760 --> 00:14:08,560
stop the docker compose that we've just

00:14:05,760 --> 00:14:12,560
started so docker component here

00:14:08,560 --> 00:14:16,079
and i'm going to actually set the oops

00:14:12,560 --> 00:14:17,120
docker compose down

00:14:16,079 --> 00:14:19,519
because now we're going to start

00:14:17,120 --> 00:14:22,959
discussing uh the code structure

00:14:19,519 --> 00:14:27,760
right so the code structure is probably

00:14:22,959 --> 00:14:29,920
what matter the most right so um

00:14:27,760 --> 00:14:32,160
okay so basically what i'm going to do

00:14:29,920 --> 00:14:35,519
right now is to show the code

00:14:32,160 --> 00:14:36,560
so let me uh minimize this window over

00:14:35,519 --> 00:14:38,800
here

00:14:36,560 --> 00:14:40,240
and bring back the project structuring

00:14:38,800 --> 00:14:42,320
right so

00:14:40,240 --> 00:14:44,000
um if you have any questions please i'm

00:14:42,320 --> 00:14:47,199
going to reserve kind five minutes

00:14:44,000 --> 00:14:49,360
uh to the end right uh so

00:14:47,199 --> 00:14:50,240
or just keep putting your questions on

00:14:49,360 --> 00:14:51,839
the chat and

00:14:50,240 --> 00:14:53,040
by the time i finish this presentation

00:14:51,839 --> 00:14:54,240
i'm gonna go to the chat and walk

00:14:53,040 --> 00:14:55,839
through the questions that have been

00:14:54,240 --> 00:14:58,800
reading there right so

00:14:55,839 --> 00:14:59,839
don't worry uh if you you have any

00:14:58,800 --> 00:15:02,800
questions

00:14:59,839 --> 00:15:03,920
so let me explain the code structure for

00:15:02,800 --> 00:15:06,240
a bit and then

00:15:03,920 --> 00:15:08,399
after that i'm going to dig deeper into

00:15:06,240 --> 00:15:09,760
the java code itself so the code

00:15:08,399 --> 00:15:11,440
structure is forget about

00:15:09,760 --> 00:15:13,120
the docker compose this is optional

00:15:11,440 --> 00:15:14,320
obviously right you don't need to create

00:15:13,120 --> 00:15:15,920
a docker compose

00:15:14,320 --> 00:15:17,440
in order to build a kafka connect

00:15:15,920 --> 00:15:19,680
connector right

00:15:17,440 --> 00:15:21,360
the docker compose has been put here

00:15:19,680 --> 00:15:23,519
just for the sake of uh

00:15:21,360 --> 00:15:25,279
what we just did like to rapidly and

00:15:23,519 --> 00:15:27,040
quickly spin up an environment to test

00:15:25,279 --> 00:15:27,839
the connector right when you're testing

00:15:27,040 --> 00:15:31,040
i think that might

00:15:27,839 --> 00:15:33,040
come in handy sometimes so as i

00:15:31,040 --> 00:15:35,920
mentioned before the whole code

00:15:33,040 --> 00:15:37,040
is written on java and maven so this is

00:15:35,920 --> 00:15:40,399
the palm file

00:15:37,040 --> 00:15:43,600
that basically comprises everything you

00:15:40,399 --> 00:15:45,279
let me close this compress everything

00:15:43,600 --> 00:15:47,040
that your all the dependencies that you

00:15:45,279 --> 00:15:48,160
have to have in your code so basically

00:15:47,040 --> 00:15:51,600
as you can see here

00:15:48,160 --> 00:15:53,519
you need the kafka api obviously right

00:15:51,600 --> 00:15:55,360
but the scope has been provided which

00:15:53,519 --> 00:15:56,160
means that it's not going to be set on

00:15:55,360 --> 00:15:59,040
your final

00:15:56,160 --> 00:15:59,279
jar files generated and basically this

00:15:59,040 --> 00:16:01,440
is

00:15:59,279 --> 00:16:03,600
all frameworks for tasks and purposes

00:16:01,440 --> 00:16:05,519
right uh i like to use test containers

00:16:03,600 --> 00:16:07,440
for testing because using test

00:16:05,519 --> 00:16:08,079
containers you can actually spin up a

00:16:07,440 --> 00:16:11,120
bunch of

00:16:08,079 --> 00:16:13,199
uh background kafka containers

00:16:11,120 --> 00:16:14,639
that uses docker right but it's whole

00:16:13,199 --> 00:16:16,880
transparent for

00:16:14,639 --> 00:16:18,240
for for your code as the only thing

00:16:16,880 --> 00:16:19,759
obviously you have to have installed in

00:16:18,240 --> 00:16:22,720
your computer is docker but

00:16:19,759 --> 00:16:24,240
it is transparent and that's it so

00:16:22,720 --> 00:16:25,920
basically the build file is going to

00:16:24,240 --> 00:16:27,120
generate that zip file that i've made

00:16:25,920 --> 00:16:30,959
that i've shown before

00:16:27,120 --> 00:16:33,839
right so let's start business

00:16:30,959 --> 00:16:35,600
in the source folder you you're gonna

00:16:33,839 --> 00:16:36,800
have this two main folder which is main

00:16:35,600 --> 00:16:38,959
and test that

00:16:36,800 --> 00:16:41,040
this is a typical maven project

00:16:38,959 --> 00:16:43,040
structure so you know what those means

00:16:41,040 --> 00:16:44,399
right and then you're gonna have this uh

00:16:43,040 --> 00:16:46,480
under java

00:16:44,399 --> 00:16:47,519
basically the main classes that we are

00:16:46,480 --> 00:16:51,519
going to discuss

00:16:47,519 --> 00:16:54,480
here right so we have

00:16:51,519 --> 00:16:55,040
five java classes here but i'm going to

00:16:54,480 --> 00:16:57,759
start

00:16:55,040 --> 00:16:58,320
with the simple question right which is

00:16:57,759 --> 00:17:01,040
which

00:16:58,320 --> 00:17:02,079
of those java classes are actually

00:17:01,040 --> 00:17:05,120
necessary

00:17:02,079 --> 00:17:06,720
and which ones are optional

00:17:05,120 --> 00:17:08,959
right and because there are optional

00:17:06,720 --> 00:17:10,319
java classes here um not everyone you

00:17:08,959 --> 00:17:13,039
actually have to write

00:17:10,319 --> 00:17:14,079
for building your own connector so let

00:17:13,039 --> 00:17:16,160
me start

00:17:14,079 --> 00:17:18,240
uh highlighting with which ones are

00:17:16,160 --> 00:17:20,559
actually important this one

00:17:18,240 --> 00:17:21,600
all right let's call this one simply

00:17:20,559 --> 00:17:23,439
connector

00:17:21,600 --> 00:17:25,280
that's called connector class right

00:17:23,439 --> 00:17:27,760
that's what you have to remember in your

00:17:25,280 --> 00:17:28,400
in your mind and then you have the task

00:17:27,760 --> 00:17:32,559
class

00:17:28,400 --> 00:17:35,440
right so keep it open okay

00:17:32,559 --> 00:17:37,520
so those are the actually only classes

00:17:35,440 --> 00:17:38,880
required for you to build your own

00:17:37,520 --> 00:17:41,120
connector

00:17:38,880 --> 00:17:42,960
whereas i'm going to obviously explain

00:17:41,120 --> 00:17:44,880
the code stricter in a bit

00:17:42,960 --> 00:17:46,960
right what you have to know right now is

00:17:44,880 --> 00:17:48,080
that any other java class that i've

00:17:46,960 --> 00:17:50,320
created here

00:17:48,080 --> 00:17:52,080
was basically created for just

00:17:50,320 --> 00:17:54,880
organizing the code

00:17:52,080 --> 00:17:56,400
better right you know you know the

00:17:54,880 --> 00:17:58,080
technique of simplifying a code

00:17:56,400 --> 00:18:01,039
structure like breaking down the logic

00:17:58,080 --> 00:18:02,799
into multiple uh files so you you don't

00:18:01,039 --> 00:18:04,880
have that huge file that has

00:18:02,799 --> 00:18:06,559
all the logs for this is that basically

00:18:04,880 --> 00:18:09,600
the same concept right

00:18:06,559 --> 00:18:12,400
so uh let me start discussing

00:18:09,600 --> 00:18:14,320
what the connector class does and then

00:18:12,400 --> 00:18:15,360
you're gonna see that as we walk through

00:18:14,320 --> 00:18:17,120
this code

00:18:15,360 --> 00:18:18,960
we're going to reference the other files

00:18:17,120 --> 00:18:19,840
right the other java classes that i've

00:18:18,960 --> 00:18:21,520
built for

00:18:19,840 --> 00:18:22,960
simplifying the code right so let's

00:18:21,520 --> 00:18:25,679
start with the

00:18:22,960 --> 00:18:28,000
main class which is the connector right

00:18:25,679 --> 00:18:31,360
a connector is basically a class that

00:18:28,000 --> 00:18:34,240
extends uh this here

00:18:31,360 --> 00:18:34,880
this abstract class called connector

00:18:34,240 --> 00:18:36,720
right

00:18:34,880 --> 00:18:37,919
and there are two types of connector

00:18:36,720 --> 00:18:38,480
right that's the first thing you have to

00:18:37,919 --> 00:18:40,480
know

00:18:38,480 --> 00:18:42,160
the first one is called sources which is

00:18:40,480 --> 00:18:44,000
literally what we have built here

00:18:42,160 --> 00:18:46,080
the source connector is the one that

00:18:44,000 --> 00:18:47,200
reads as a source system and bring data

00:18:46,080 --> 00:18:50,160
into kafka

00:18:47,200 --> 00:18:51,440
and there's the sync connector right the

00:18:50,160 --> 00:18:53,520
sync connector

00:18:51,440 --> 00:18:55,679
responsibility is to read data that is

00:18:53,520 --> 00:18:58,480
available in kafka so

00:18:55,679 --> 00:18:59,840
now the source of the the source of the

00:18:58,480 --> 00:19:02,080
system is kafka

00:18:59,840 --> 00:19:03,200
and you want to send to somewhere else

00:19:02,080 --> 00:19:04,559
like you're

00:19:03,200 --> 00:19:06,559
you're going to send the data that's in

00:19:04,559 --> 00:19:07,520
kafka to some other system so for this

00:19:06,559 --> 00:19:09,600
to happen

00:19:07,520 --> 00:19:11,679
you have to extend for sync connector

00:19:09,600 --> 00:19:12,640
not source connector okay so keep that

00:19:11,679 --> 00:19:15,200
in mind because

00:19:12,640 --> 00:19:17,280
it makes a huge difference right

00:19:15,200 --> 00:19:20,000
specifically in terms of behavior

00:19:17,280 --> 00:19:20,640
so by the time you extend the source

00:19:20,000 --> 00:19:23,440
connector

00:19:20,640 --> 00:19:25,200
there are some methods that you're going

00:19:23,440 --> 00:19:27,600
to need to implement in your java class

00:19:25,200 --> 00:19:29,360
those are going to be abstract methods

00:19:27,600 --> 00:19:30,960
that obviously do you have to provide an

00:19:29,360 --> 00:19:31,600
implementation so i'm going to highlight

00:19:30,960 --> 00:19:34,720
them

00:19:31,600 --> 00:19:35,600
right now so the first one is going to

00:19:34,720 --> 00:19:38,799
be the method

00:19:35,600 --> 00:19:40,720
start okay this is abstract you have to

00:19:38,799 --> 00:19:43,520
provide implementation for it

00:19:40,720 --> 00:19:45,360
the other method is tasks configs this

00:19:43,520 --> 00:19:46,799
is abstract you also have to provide an

00:19:45,360 --> 00:19:50,160
implementation for it

00:19:46,799 --> 00:19:52,000
and the method stop okay

00:19:50,160 --> 00:19:53,840
those are the method that you actually

00:19:52,000 --> 00:19:55,200
have to implement and provide code for

00:19:53,840 --> 00:19:57,440
it without it

00:19:55,200 --> 00:19:58,880
the connector is not going to work right

00:19:57,440 --> 00:20:00,400
what about the other one what about the

00:19:58,880 --> 00:20:03,360
method of validate

00:20:00,400 --> 00:20:04,799
um actually i take that back there's one

00:20:03,360 --> 00:20:05,280
more method that you have to implement

00:20:04,799 --> 00:20:08,400
which is

00:20:05,280 --> 00:20:12,960
task class this is uh mandatory as well

00:20:08,400 --> 00:20:14,720
right so all these methods

00:20:12,960 --> 00:20:17,360
their responsibilities to basically

00:20:14,720 --> 00:20:21,039
create the framework

00:20:17,360 --> 00:20:24,240
that in runtime okay is going to spin

00:20:21,039 --> 00:20:26,240
up a bunch of tasks right so let's take

00:20:24,240 --> 00:20:27,919
time right now to understand what tasks

00:20:26,240 --> 00:20:30,960
are okay

00:20:27,919 --> 00:20:32,880
the best way to understand task is is to

00:20:30,960 --> 00:20:34,400
keep in mind that whatever you write

00:20:32,880 --> 00:20:36,240
here whatever code you write here in

00:20:34,400 --> 00:20:39,600
your connector is not going to do

00:20:36,240 --> 00:20:39,919
anything with data right it's basically

00:20:39,600 --> 00:20:42,960
a

00:20:39,919 --> 00:20:44,320
skeleton code that takes care of

00:20:42,960 --> 00:20:47,520
spinning up

00:20:44,320 --> 00:20:48,000
tasks all right task is is actually what

00:20:47,520 --> 00:20:49,440
the code

00:20:48,000 --> 00:20:51,200
that you were you're going to handle

00:20:49,440 --> 00:20:52,799
data okay so

00:20:51,200 --> 00:20:54,320
you're going to decide right here on

00:20:52,799 --> 00:20:54,799
this connector if you're going to spend

00:20:54,320 --> 00:20:58,080
one

00:20:54,799 --> 00:20:59,919
two five 100 tasks right uh you can

00:20:58,080 --> 00:21:02,880
think task is in terms of

00:20:59,919 --> 00:21:04,480
threads right so ricardo how do you

00:21:02,880 --> 00:21:05,600
handle concurrency in kafka connect when

00:21:04,480 --> 00:21:07,440
you're building connector

00:21:05,600 --> 00:21:08,960
uh very simple you basically have to

00:21:07,440 --> 00:21:11,679
spread all your workload

00:21:08,960 --> 00:21:14,400
into multiple tasks right so for example

00:21:11,679 --> 00:21:16,960
if your your search system is a database

00:21:14,400 --> 00:21:18,480
and maybe you were you having this

00:21:16,960 --> 00:21:20,480
database 100 tables

00:21:18,480 --> 00:21:22,720
right that's a lot i know but just

00:21:20,480 --> 00:21:25,600
imagine that you have 100 tables

00:21:22,720 --> 00:21:25,919
so it is a good best practices to spin

00:21:25,600 --> 00:21:27,919
up

00:21:25,919 --> 00:21:29,120
one task per table right so you can

00:21:27,919 --> 00:21:32,159
actually uh

00:21:29,120 --> 00:21:34,559
spread and spread the working right uh

00:21:32,159 --> 00:21:35,280
into one individual table per task and

00:21:34,559 --> 00:21:37,120
then

00:21:35,280 --> 00:21:39,679
in run time what kafka connects going to

00:21:37,120 --> 00:21:40,480
do is to spread all those tasks in the

00:21:39,679 --> 00:21:43,360
cluster

00:21:40,480 --> 00:21:44,960
how nobody knows right this is basically

00:21:43,360 --> 00:21:45,760
the kafka connect clustering protocol

00:21:44,960 --> 00:21:47,600
that does this

00:21:45,760 --> 00:21:49,360
you are supposed to not worry about this

00:21:47,600 --> 00:21:50,159
detail because that's what kafka connect

00:21:49,360 --> 00:21:52,559
is best

00:21:50,159 --> 00:21:54,880
which is abstracting away details about

00:21:52,559 --> 00:21:57,760
uh clustering fault tolerance

00:21:54,880 --> 00:21:58,880
and security so basically your job as a

00:21:57,760 --> 00:22:01,120
connector developer

00:21:58,880 --> 00:22:02,000
is to decide how many tasks i need to

00:22:01,120 --> 00:22:03,919
spin up right

00:22:02,000 --> 00:22:05,600
and this is you are going to decide

00:22:03,919 --> 00:22:07,840
there's no the framework are not to

00:22:05,600 --> 00:22:11,200
detect this automatically right

00:22:07,840 --> 00:22:14,240
so uh with that said where you actually

00:22:11,200 --> 00:22:17,120
tell for the cafe connect framework how

00:22:14,240 --> 00:22:19,520
many tasks you are going to spin up so

00:22:17,120 --> 00:22:20,559
this method here called task configs

00:22:19,520 --> 00:22:23,520
okay

00:22:20,559 --> 00:22:26,240
is going to receive as a perimeter the

00:22:23,520 --> 00:22:28,400
maximum number of tasks that

00:22:26,240 --> 00:22:30,000
your code is allowed to handle right

00:22:28,400 --> 00:22:31,520
this is going to be a configuration that

00:22:30,000 --> 00:22:34,159
the user not the developer

00:22:31,520 --> 00:22:36,080
the user is going to are going to set

00:22:34,159 --> 00:22:36,559
during the deployment of this connector

00:22:36,080 --> 00:22:39,360
right

00:22:36,559 --> 00:22:39,760
and this might be like a higher a high

00:22:39,360 --> 00:22:42,640
mark

00:22:39,760 --> 00:22:45,520
saying that right do not spin up more

00:22:42,640 --> 00:22:48,640
than 100 tasks for example because

00:22:45,520 --> 00:22:50,320
uh there won't be enough brokers or jvms

00:22:48,640 --> 00:22:51,200
available to spin up all of that right

00:22:50,320 --> 00:22:53,440
so maybe

00:22:51,200 --> 00:22:55,440
this is this is the reason for 100 but

00:22:53,440 --> 00:22:56,799
this can be virtually any number there's

00:22:55,440 --> 00:22:58,480
no actual limit for it

00:22:56,799 --> 00:23:00,080
what you have to know is that this is

00:22:58,480 --> 00:23:02,400
going to dictate

00:23:00,080 --> 00:23:05,200
what you as a developer need to consider

00:23:02,400 --> 00:23:09,440
as the maximum number of tasks right

00:23:05,200 --> 00:23:13,200
so um and here basically what i'm doing

00:23:09,440 --> 00:23:15,039
is to create like a i'm setting a list

00:23:13,200 --> 00:23:16,400
you pay attention that would you need to

00:23:15,039 --> 00:23:19,120
return a list

00:23:16,400 --> 00:23:20,559
of a map of configuration right so the

00:23:19,120 --> 00:23:23,120
size of this list

00:23:20,559 --> 00:23:24,880
is going to dictate the number of tasks

00:23:23,120 --> 00:23:26,240
if we take the example that i've shared

00:23:24,880 --> 00:23:28,799
before about the database

00:23:26,240 --> 00:23:29,520
right if you have 100 tables so the list

00:23:28,799 --> 00:23:32,480
size

00:23:29,520 --> 00:23:33,919
optionally needs to have a 100 as a size

00:23:32,480 --> 00:23:37,039
right so this is

00:23:33,919 --> 00:23:40,559
the best practices for maximum parallels

00:23:37,039 --> 00:23:41,760
right so basically what the code needs

00:23:40,559 --> 00:23:45,200
to do is for

00:23:41,760 --> 00:23:48,000
its task needs to have their own

00:23:45,200 --> 00:23:50,880
set of configurations right so the

00:23:48,000 --> 00:23:54,000
configuration here is the properties

00:23:50,880 --> 00:23:55,679
that the task needs to have in order to

00:23:54,000 --> 00:23:57,039
let's say communicate with the search

00:23:55,679 --> 00:23:59,120
system um

00:23:57,039 --> 00:24:00,559
the database for example uh you know how

00:23:59,120 --> 00:24:01,120
do you connect to a database you have to

00:24:00,559 --> 00:24:03,520
have

00:24:01,120 --> 00:24:05,279
the url for for the host you have to

00:24:03,520 --> 00:24:06,960
know the port

00:24:05,279 --> 00:24:08,320
if there's authentication in place you

00:24:06,960 --> 00:24:08,960
have to know the username and password

00:24:08,320 --> 00:24:11,200
so all

00:24:08,960 --> 00:24:12,159
all those details are going to be

00:24:11,200 --> 00:24:15,440
actually the test

00:24:12,159 --> 00:24:16,480
properties right so you basically define

00:24:15,440 --> 00:24:19,679
those here

00:24:16,480 --> 00:24:23,039
right and you can actually

00:24:19,679 --> 00:24:25,440
inherit all those settings here because

00:24:23,039 --> 00:24:28,240
one of the matches that you create here

00:24:25,440 --> 00:24:32,880
is the where is it

00:24:28,240 --> 00:24:33,600
uh start here over here so in the start

00:24:32,880 --> 00:24:35,600
method

00:24:33,600 --> 00:24:37,360
you actually receive a bunch of

00:24:35,600 --> 00:24:39,919
properties that the user set

00:24:37,360 --> 00:24:41,520
so in the example that i've made before

00:24:39,919 --> 00:24:42,960
right which is basically remember that

00:24:41,520 --> 00:24:45,279
json payload that i've

00:24:42,960 --> 00:24:46,000
used for deployment purposes basic

00:24:45,279 --> 00:24:48,799
that's what

00:24:46,000 --> 00:24:49,760
uh the json pillows over here so as you

00:24:48,799 --> 00:24:52,640
can see here

00:24:49,760 --> 00:24:54,000
i've set parameters that only make sense

00:24:52,640 --> 00:24:56,159
for my connector

00:24:54,000 --> 00:24:57,919
over here exactly so all those

00:24:56,159 --> 00:25:00,960
parameters over here

00:24:57,919 --> 00:25:02,720
are going to be end up over here right

00:25:00,960 --> 00:25:04,320
and then you can use this moment here

00:25:02,720 --> 00:25:05,520
the start method to actually perform

00:25:04,320 --> 00:25:08,000
some validation

00:25:05,520 --> 00:25:08,559
uh things like all right see if you set

00:25:08,000 --> 00:25:11,279
four

00:25:08,559 --> 00:25:12,799
to the parameter number x you can ask

00:25:11,279 --> 00:25:15,520
you cannot have like uh

00:25:12,799 --> 00:25:16,720
eight for the para the parameter y

00:25:15,520 --> 00:25:18,400
something like this uh

00:25:16,720 --> 00:25:20,480
the logic is going to be yours it

00:25:18,400 --> 00:25:21,360
doesn't have to follow any preconditions

00:25:20,480 --> 00:25:23,440
specifically

00:25:21,360 --> 00:25:24,799
but the point is all those properties

00:25:23,440 --> 00:25:27,039
you can actually save it for

00:25:24,799 --> 00:25:28,000
use it later that's what i've done here

00:25:27,039 --> 00:25:29,600
so i've

00:25:28,000 --> 00:25:31,679
created a copy of this profits

00:25:29,600 --> 00:25:33,440
originally over here and when you were

00:25:31,679 --> 00:25:35,279
actually defining the number of tasks

00:25:33,440 --> 00:25:39,039
you can actually inherit all that

00:25:35,279 --> 00:25:42,880
all of that and either provided as

00:25:39,039 --> 00:25:44,559
is for each task likely you're not going

00:25:42,880 --> 00:25:45,600
to do this because each task might have

00:25:44,559 --> 00:25:48,720
their specifics

00:25:45,600 --> 00:25:50,480
for example uh each task for database

00:25:48,720 --> 00:25:52,480
table might have the table name

00:25:50,480 --> 00:25:56,799
which is unique for that task right the

00:25:52,480 --> 00:25:58,880
table name specifically

00:25:56,799 --> 00:26:01,279
but you got a point basically what you

00:25:58,880 --> 00:26:03,440
have to do is to spin up the tasks right

00:26:01,279 --> 00:26:05,520
which task is going to be actually

00:26:03,440 --> 00:26:07,679
executed in run time

00:26:05,520 --> 00:26:09,440
you specify over here in this method

00:26:07,679 --> 00:26:11,360
called task class

00:26:09,440 --> 00:26:13,279
okay so as you can see here it's very

00:26:11,360 --> 00:26:16,240
simple you just need to return

00:26:13,279 --> 00:26:16,960
a class that represents your task class

00:26:16,240 --> 00:26:20,240
which

00:26:16,960 --> 00:26:22,320
and the code is this class over here

00:26:20,240 --> 00:26:24,080
all right so let's discuss a little bit

00:26:22,320 --> 00:26:25,919
about the task class

00:26:24,080 --> 00:26:28,799
so you can better understand as i

00:26:25,919 --> 00:26:31,840
mentioned before the connector class

00:26:28,799 --> 00:26:32,240
is it's important obviously without it

00:26:31,840 --> 00:26:34,159
you

00:26:32,240 --> 00:26:36,000
you no longer has the ability to deploy

00:26:34,159 --> 00:26:37,279
your connector but remember that the

00:26:36,000 --> 00:26:40,400
connector class doesn't do

00:26:37,279 --> 00:26:42,640
anything right it's a placeholder that

00:26:40,400 --> 00:26:45,600
basically comprises the logic to spin up

00:26:42,640 --> 00:26:47,200
tasks and the task is are going to be

00:26:45,600 --> 00:26:48,240
the implementation the code

00:26:47,200 --> 00:26:50,720
implementation

00:26:48,240 --> 00:26:52,480
that you're gonna handle data right this

00:26:50,720 --> 00:26:54,159
is probably where you're going to spend

00:26:52,480 --> 00:26:55,279
the majority of your time developing the

00:26:54,159 --> 00:26:56,720
connector because

00:26:55,279 --> 00:26:58,799
this is the class that you're going to

00:26:56,720 --> 00:27:01,360
set up code for connectivity

00:26:58,799 --> 00:27:02,480
uh to handle fault tolerance if there's

00:27:01,360 --> 00:27:04,000
transaction involved

00:27:02,480 --> 00:27:06,799
that we're going to put your transaction

00:27:04,000 --> 00:27:09,120
logic over here so this is going to be

00:27:06,799 --> 00:27:11,039
potentially right a very complicated

00:27:09,120 --> 00:27:14,640
implementation right

00:27:11,039 --> 00:27:15,360
so uh let's review the most important

00:27:14,640 --> 00:27:17,039
methods

00:27:15,360 --> 00:27:19,039
or that you can step here as you can see

00:27:17,039 --> 00:27:19,520
here it's not very complicated in terms

00:27:19,039 --> 00:27:22,559
of

00:27:19,520 --> 00:27:24,960
territory right your code your

00:27:22,559 --> 00:27:26,559
algorithm right that is going to be a

00:27:24,960 --> 00:27:27,919
little complicated because it depends of

00:27:26,559 --> 00:27:28,799
your use case you were implementing

00:27:27,919 --> 00:27:30,640
right but

00:27:28,799 --> 00:27:32,240
the code the structure here is basically

00:27:30,640 --> 00:27:34,960
you have the start method

00:27:32,240 --> 00:27:35,919
right this method is very important

00:27:34,960 --> 00:27:38,240
because

00:27:35,919 --> 00:27:39,360
um since this is a source connector

00:27:38,240 --> 00:27:42,159
right it's been

00:27:39,360 --> 00:27:44,080
probably is going to specify establish a

00:27:42,159 --> 00:27:46,320
connection with a source system right

00:27:44,080 --> 00:27:47,200
one or multiple connections if you want

00:27:46,320 --> 00:27:49,600
to have like some

00:27:47,200 --> 00:27:51,600
some sort of a parallelism and handling

00:27:49,600 --> 00:27:53,279
io or multiple connections

00:27:51,600 --> 00:27:54,880
you name it whatever you need to

00:27:53,279 --> 00:27:57,679
establish with the search system

00:27:54,880 --> 00:27:58,960
so the best moment to establish a

00:27:57,679 --> 00:28:00,840
connection is going to be here in the

00:27:58,960 --> 00:28:02,960
start method right

00:28:00,840 --> 00:28:04,399
consequentially you also have this

00:28:02,960 --> 00:28:06,559
method called stop

00:28:04,399 --> 00:28:08,320
that is the appropriate method for doing

00:28:06,559 --> 00:28:11,120
some uh resources cleanup

00:28:08,320 --> 00:28:13,039
right so if you had some socket

00:28:11,120 --> 00:28:13,840
connections established or network calls

00:28:13,039 --> 00:28:18,240
being established

00:28:13,840 --> 00:28:20,480
this is the place where uh when the user

00:28:18,240 --> 00:28:22,720
specifies that he or she is going to

00:28:20,480 --> 00:28:24,880
like undeploy the connector

00:28:22,720 --> 00:28:26,720
uh before the underplaned processes this

00:28:24,880 --> 00:28:28,399
method is going to be executed so this

00:28:26,720 --> 00:28:30,880
is the perfect place to close

00:28:28,399 --> 00:28:32,080
all the underlying resources right and

00:28:30,880 --> 00:28:35,679
then we have

00:28:32,080 --> 00:28:38,799
the main method which is the poll right

00:28:35,679 --> 00:28:39,840
the poll method is a method that is

00:28:38,799 --> 00:28:42,880
first of all

00:28:39,840 --> 00:28:46,080
is continuously executed on its own

00:28:42,880 --> 00:28:49,520
thread right so remember this

00:28:46,080 --> 00:28:50,399
each thread on kafka connect represents

00:28:49,520 --> 00:28:53,520
a thread

00:28:50,399 --> 00:28:56,480
okay so what that means is that

00:28:53,520 --> 00:28:58,799
whatever you execute here is no it's not

00:28:56,480 --> 00:29:00,159
going to communicate or have a direct

00:28:58,799 --> 00:29:02,799
path of communication

00:29:00,159 --> 00:29:05,120
with the other tasks right you have to

00:29:02,799 --> 00:29:08,159
take this in mind and write your code

00:29:05,120 --> 00:29:10,640
specify that each task or thread

00:29:08,159 --> 00:29:12,080
is going to be self-sufficient right

00:29:10,640 --> 00:29:13,760
everything they need to know

00:29:12,080 --> 00:29:15,600
everything they need to in order to work

00:29:13,760 --> 00:29:18,799
with they need to have

00:29:15,600 --> 00:29:20,799
already right so this pool method here

00:29:18,799 --> 00:29:22,720
is going to be executed continuously

00:29:20,799 --> 00:29:25,919
right in a wire true

00:29:22,720 --> 00:29:27,360
type of uh execution right so it is up

00:29:25,919 --> 00:29:28,880
to you

00:29:27,360 --> 00:29:30,960
if you want to perform some sort of a

00:29:28,880 --> 00:29:34,399
throttling or perhaps

00:29:30,960 --> 00:29:36,159
you you need to take pauses or uh

00:29:34,399 --> 00:29:37,919
shorter periods of time where there will

00:29:36,159 --> 00:29:40,240
be no execution

00:29:37,919 --> 00:29:42,480
you have to control it over here like

00:29:40,240 --> 00:29:44,799
for for the sake of the example i

00:29:42,480 --> 00:29:46,240
put here some thread sleep never do this

00:29:44,799 --> 00:29:47,679
right i've

00:29:46,240 --> 00:29:49,679
i've done this on purpose just to

00:29:47,679 --> 00:29:52,799
emphasize that i'm gonna do a pause

00:29:49,679 --> 00:29:54,799
but in a real low in a real world uh you

00:29:52,799 --> 00:29:58,080
should never do this right this is a bad

00:29:54,799 --> 00:29:59,679
bad bad practice right but the reality

00:29:58,080 --> 00:30:01,360
is that sometimes you might need some to

00:29:59,679 --> 00:30:04,240
use some sort of a scheduler

00:30:01,360 --> 00:30:05,039
to perhaps like i want to execute this

00:30:04,240 --> 00:30:07,279
poll

00:30:05,039 --> 00:30:09,440
every five minutes for example so it is

00:30:07,279 --> 00:30:11,200
up to you to put this logic here

00:30:09,440 --> 00:30:12,640
what scheduler algorithm or

00:30:11,200 --> 00:30:14,720
implementation you're going to use

00:30:12,640 --> 00:30:16,000
you decided right that's the beauty of

00:30:14,720 --> 00:30:19,840
it right

00:30:16,000 --> 00:30:22,799
the point is whatever you do here

00:30:19,840 --> 00:30:23,440
your responsibility is to return a list

00:30:22,799 --> 00:30:26,000
of

00:30:23,440 --> 00:30:27,679
source records the source records d is

00:30:26,000 --> 00:30:29,440
self-explanatory right it's going to

00:30:27,679 --> 00:30:31,840
represent a record

00:30:29,440 --> 00:30:32,480
that has been read from the source

00:30:31,840 --> 00:30:35,600
system

00:30:32,480 --> 00:30:36,159
right and for each poll you don't

00:30:35,600 --> 00:30:38,080
necessarily

00:30:36,159 --> 00:30:39,440
have to kind of return one single record

00:30:38,080 --> 00:30:42,159
you can actually accumulate

00:30:39,440 --> 00:30:44,159
perhaps you are reading the the the data

00:30:42,159 --> 00:30:46,080
from the search system in batches so

00:30:44,159 --> 00:30:48,159
this is the best way for you to all

00:30:46,080 --> 00:30:49,520
right you're gonna batch and cache all

00:30:48,159 --> 00:30:50,399
those records that are coming from the

00:30:49,520 --> 00:30:52,799
search system

00:30:50,399 --> 00:30:53,600
and then you are going to send them back

00:30:52,799 --> 00:30:56,640
to kafka

00:30:53,600 --> 00:30:59,919
in a in a once right so

00:30:56,640 --> 00:31:02,559
this is why you have this ability to um

00:30:59,919 --> 00:31:04,080
create a list and fill this list with

00:31:02,559 --> 00:31:07,840
more than one record right

00:31:04,080 --> 00:31:10,000
so it is considerably simple

00:31:07,840 --> 00:31:11,600
if you think about it right obviously

00:31:10,000 --> 00:31:12,399
the whole complexity of the search

00:31:11,600 --> 00:31:14,000
connector here

00:31:12,399 --> 00:31:15,919
is going to be about connectivity and

00:31:14,000 --> 00:31:18,640
for tolerance and things like that

00:31:15,919 --> 00:31:19,120
but the reality is that by the time you

00:31:18,640 --> 00:31:21,679
actually

00:31:19,120 --> 00:31:23,679
end up writing the code for the poll

00:31:21,679 --> 00:31:26,559
you're probably going to do

00:31:23,679 --> 00:31:27,440
what you as a developer might be already

00:31:26,559 --> 00:31:29,120
familiar with

00:31:27,440 --> 00:31:30,640
for example let's talk about the uh the

00:31:29,120 --> 00:31:33,279
example of the database

00:31:30,640 --> 00:31:34,399
uh maybe you can establish here on this

00:31:33,279 --> 00:31:36,559
start method

00:31:34,399 --> 00:31:37,840
you can establish a jdbc connection

00:31:36,559 --> 00:31:40,960
right and

00:31:37,840 --> 00:31:42,240
hold cache locally the jdbc connection

00:31:40,960 --> 00:31:44,320
over here in the task

00:31:42,240 --> 00:31:46,640
and then on the pool you're basically

00:31:44,320 --> 00:31:48,799
going to like issue some sql statements

00:31:46,640 --> 00:31:50,399
for a database to require data

00:31:48,799 --> 00:31:52,880
and then you're going to assemble this

00:31:50,399 --> 00:31:54,480
list of source connect it is that simple

00:31:52,880 --> 00:31:54,960
i mean there's no complexity other than

00:31:54,480 --> 00:31:57,200
this

00:31:54,960 --> 00:31:58,880
the complexity will come from by the

00:31:57,200 --> 00:32:01,120
characteristics that you want to bring

00:31:58,880 --> 00:32:02,559
into kafka like for example oh i want to

00:32:01,120 --> 00:32:04,080
i want to throttle this for reading

00:32:02,559 --> 00:32:05,120
every five minutes you have to put a

00:32:04,080 --> 00:32:07,519
scheduler here

00:32:05,120 --> 00:32:10,399
right or perhaps you want to read this

00:32:07,519 --> 00:32:13,200
on a descriptive global transaction so

00:32:10,399 --> 00:32:14,080
it will be your job to actually acquire

00:32:13,200 --> 00:32:17,360
a transaction

00:32:14,080 --> 00:32:18,799
monitor for a transaction coordinator

00:32:17,360 --> 00:32:20,320
that's running somewhere in an

00:32:18,799 --> 00:32:21,519
application server or somewhere

00:32:20,320 --> 00:32:23,760
and then you're going to use it right

00:32:21,519 --> 00:32:25,200
here to enlist the transaction that

00:32:23,760 --> 00:32:28,000
you're going to do here

00:32:25,200 --> 00:32:29,039
so the whole transaction the global

00:32:28,000 --> 00:32:31,840
transaction can

00:32:29,039 --> 00:32:32,720
execute it atomically right so this is

00:32:31,840 --> 00:32:34,880
the part where

00:32:32,720 --> 00:32:36,880
the complexity is going to be inherited

00:32:34,880 --> 00:32:38,480
to your use case it's not necessarily

00:32:36,880 --> 00:32:40,480
inherent to how the kafka connect

00:32:38,480 --> 00:32:41,279
framework works right that's the beauty

00:32:40,480 --> 00:32:44,159
of it

00:32:41,279 --> 00:32:47,039
right the one thing i would like to

00:32:44,159 --> 00:32:50,640
point out before we start wrapping up

00:32:47,039 --> 00:32:53,360
is that um the source records

00:32:50,640 --> 00:32:54,240
has a very specific structure as you can

00:32:53,360 --> 00:32:56,640
see here

00:32:54,240 --> 00:32:58,240
so this is the constructor of the search

00:32:56,640 --> 00:33:00,880
record actually i'm going to open

00:32:58,240 --> 00:33:02,080
real quick for you to see right because

00:33:00,880 --> 00:33:03,760
there are some very important

00:33:02,080 --> 00:33:04,799
information here in this constructor

00:33:03,760 --> 00:33:07,279
some of them

00:33:04,799 --> 00:33:08,640
you don't need to set right for example

00:33:07,279 --> 00:33:10,880
just to take it for example

00:33:08,640 --> 00:33:12,320
imagine that the record that you were

00:33:10,880 --> 00:33:12,960
reading or a document that you were

00:33:12,320 --> 00:33:15,120
reading

00:33:12,960 --> 00:33:16,080
doesn't have a key right if it doesn't

00:33:15,120 --> 00:33:17,519
have a key

00:33:16,080 --> 00:33:19,519
you don't need to provide you can

00:33:17,519 --> 00:33:21,760
provide a no for key

00:33:19,519 --> 00:33:22,640
and for the uh the key schema for

00:33:21,760 --> 00:33:24,320
example because

00:33:22,640 --> 00:33:26,000
like i mentioned before there has no key

00:33:24,320 --> 00:33:28,960
right uh

00:33:26,000 --> 00:33:30,159
same goes for example maybe you don't

00:33:28,960 --> 00:33:33,279
have the concept

00:33:30,159 --> 00:33:36,480
of a partitioning right so but

00:33:33,279 --> 00:33:38,080
partitioning just a parenthesis is

00:33:36,480 --> 00:33:40,640
just let me give you an example of

00:33:38,080 --> 00:33:44,000
partitioning so imagine a database table

00:33:40,640 --> 00:33:45,200
right so a database table is broken down

00:33:44,000 --> 00:33:48,320
in different roles

00:33:45,200 --> 00:33:48,960
okay so each role is going to have a

00:33:48,320 --> 00:33:51,679
unique

00:33:48,960 --> 00:33:53,279
row id right so this is a very good

00:33:51,679 --> 00:33:56,480
example of a partition

00:33:53,279 --> 00:33:59,679
right so uh partitions is

00:33:56,480 --> 00:34:01,919
um a way to specify how a specific

00:33:59,679 --> 00:34:03,519
data set is broken down right uh if

00:34:01,919 --> 00:34:05,279
you're dealing with a nosql database

00:34:03,519 --> 00:34:08,560
that might be for example

00:34:05,279 --> 00:34:10,480
um perhaps the

00:34:08,560 --> 00:34:11,599
the itin that you were dealing with

00:34:10,480 --> 00:34:14,720
right

00:34:11,599 --> 00:34:16,800
you name it i mean that's the the whole

00:34:14,720 --> 00:34:20,000
purpose of having a partition

00:34:16,800 --> 00:34:21,760
is for you to accommodate your code more

00:34:20,000 --> 00:34:23,440
easily right it doesn't necessarily have

00:34:21,760 --> 00:34:27,280
to mean anything

00:34:23,440 --> 00:34:30,159
generically or specifically right

00:34:27,280 --> 00:34:32,240
so another one important uh aspect here

00:34:30,159 --> 00:34:36,000
is this information about the source

00:34:32,240 --> 00:34:39,760
offset this

00:34:36,000 --> 00:34:43,119
believe me when i say this is probably

00:34:39,760 --> 00:34:44,960
the less obvious thing

00:34:43,119 --> 00:34:46,639
that you are going to see on kafka

00:34:44,960 --> 00:34:49,119
connect framework right

00:34:46,639 --> 00:34:50,240
that most developers me included when i

00:34:49,119 --> 00:34:52,399
was uh

00:34:50,240 --> 00:34:53,599
doing this for the first time is not

00:34:52,399 --> 00:34:56,240
going to be a

00:34:53,599 --> 00:34:57,599
pay a very good attention on it but is

00:34:56,240 --> 00:35:00,960
an extremely

00:34:57,599 --> 00:35:01,280
powerful feature that in a production

00:35:00,960 --> 00:35:03,200
var

00:35:01,280 --> 00:35:04,880
makes the whole difference so in order

00:35:03,200 --> 00:35:06,320
for me to understand to explain that

00:35:04,880 --> 00:35:08,480
what this offset does

00:35:06,320 --> 00:35:09,839
let me put a situation for you right now

00:35:08,480 --> 00:35:11,359
so imagine that you were reading a

00:35:09,839 --> 00:35:14,640
source system right

00:35:11,359 --> 00:35:16,800
that has for example maybe 100 records

00:35:14,640 --> 00:35:18,800
just for the sake of example right and

00:35:16,800 --> 00:35:22,000
then your connector stop reading it

00:35:18,800 --> 00:35:24,160
one two three four five the objective is

00:35:22,000 --> 00:35:26,960
to read all of the records right

00:35:24,160 --> 00:35:27,359
and then by the time the the connector

00:35:26,960 --> 00:35:30,640
is

00:35:27,359 --> 00:35:33,280
processing the record uh 37

00:35:30,640 --> 00:35:34,720
for example right something on the kafka

00:35:33,280 --> 00:35:36,800
connect cluster happens right

00:35:34,720 --> 00:35:38,160
the broker goes down right something in

00:35:36,800 --> 00:35:40,079
the network goes down

00:35:38,160 --> 00:35:41,839
uh failures can happens all the time

00:35:40,079 --> 00:35:43,520
right so what's going to happen with

00:35:41,839 --> 00:35:44,000
your connector your connector obviously

00:35:43,520 --> 00:35:46,720
is going

00:35:44,000 --> 00:35:47,359
to go down right along with the broker

00:35:46,720 --> 00:35:49,760
right

00:35:47,359 --> 00:35:50,880
okay so this is how wi-fi tolerance is

00:35:49,760 --> 00:35:53,839
all about right

00:35:50,880 --> 00:35:56,320
so maybe you can spin up a new broker

00:35:53,839 --> 00:35:58,480
node of kafka connect and the task

00:35:56,320 --> 00:36:00,160
is going to be migrated automatically to

00:35:58,480 --> 00:36:01,520
this new kafka broker note this happens

00:36:00,160 --> 00:36:02,000
automatically you don't have to code

00:36:01,520 --> 00:36:04,560
this

00:36:02,000 --> 00:36:06,000
that's the magic of kafka connect but

00:36:04,560 --> 00:36:08,160
the reality is that

00:36:06,000 --> 00:36:09,599
you have to provide a way for the kafka

00:36:08,160 --> 00:36:13,119
connect your connector

00:36:09,599 --> 00:36:15,760
to resume the processing

00:36:13,119 --> 00:36:17,520
this is where the information of the

00:36:15,760 --> 00:36:19,280
offset is important right

00:36:17,520 --> 00:36:21,280
your connector has to have the

00:36:19,280 --> 00:36:21,760
responsibility of for each record that

00:36:21,280 --> 00:36:23,839
has

00:36:21,760 --> 00:36:25,520
has been read from the source system you

00:36:23,839 --> 00:36:26,320
have to set this information of the

00:36:25,520 --> 00:36:28,560
offset

00:36:26,320 --> 00:36:30,720
so it's store it along with the record

00:36:28,560 --> 00:36:32,079
in kafka right because otherwise

00:36:30,720 --> 00:36:33,839
if you don't set this look what's going

00:36:32,079 --> 00:36:34,560
to happen remember the example it's

00:36:33,839 --> 00:36:38,320
stopping on

00:36:34,560 --> 00:36:40,560
record 37 if you don't set the offset

00:36:38,320 --> 00:36:42,880
all the all the records when the task

00:36:40,560 --> 00:36:45,040
resumed is going to be reprocessed

00:36:42,880 --> 00:36:46,000
from the beginning which is record

00:36:45,040 --> 00:36:48,400
number one two

00:36:46,000 --> 00:36:49,280
three and four or fives therefore

00:36:48,400 --> 00:36:51,440
potentially

00:36:49,280 --> 00:36:52,720
processing and generating some redundant

00:36:51,440 --> 00:36:54,960
redundancy right

00:36:52,720 --> 00:36:56,240
in your code and probably you don't you

00:36:54,960 --> 00:36:58,160
want this right

00:36:56,240 --> 00:37:00,160
uh this is probably the the the thing

00:36:58,160 --> 00:37:02,800
that nobody is gonna want

00:37:00,160 --> 00:37:03,680
but you got the idea right so what i'm

00:37:02,800 --> 00:37:07,040
gonna do right now

00:37:03,680 --> 00:37:08,720
is to um let me go back to this

00:37:07,040 --> 00:37:10,560
presentation here i'm gonna stop sharing

00:37:08,720 --> 00:37:13,920
for a moment uh

00:37:10,560 --> 00:37:16,560
and i will take a look

00:37:13,920 --> 00:37:18,079
on the questions that's on the chat and

00:37:16,560 --> 00:37:20,160
if you have one right now

00:37:18,079 --> 00:37:21,520
please this is the time i'm gonna spend

00:37:20,160 --> 00:37:24,640
the next five minutes here

00:37:21,520 --> 00:37:28,960
so we can answer the the q a right

00:37:24,640 --> 00:37:33,599
so let me look into the chat

00:37:28,960 --> 00:37:33,599
can all of this the patrick gamers and

00:37:35,200 --> 00:37:42,560
can all this be done in python patrick

00:37:39,280 --> 00:37:45,200
i wish we could but unfortunately

00:37:42,560 --> 00:37:46,480
kafka connect framework the sdk is only

00:37:45,200 --> 00:37:50,640
available on java

00:37:46,480 --> 00:37:51,440
right uh so i think in a worst case

00:37:50,640 --> 00:37:53,599
scenario

00:37:51,440 --> 00:37:55,280
i'm just wondering ella i've never done

00:37:53,599 --> 00:37:57,680
it right but you know

00:37:55,280 --> 00:37:58,880
or you might know that you can run

00:37:57,680 --> 00:38:02,240
python on top

00:37:58,880 --> 00:38:04,960
on top of a jvm right we call this gyton

00:38:02,240 --> 00:38:06,320
right so maybe what you could do is to

00:38:04,960 --> 00:38:09,359
actually write a curve in

00:38:06,320 --> 00:38:11,839
using python right and try to run

00:38:09,359 --> 00:38:12,880
this on gyto because ultimately what you

00:38:11,839 --> 00:38:14,880
have to do is to provide your

00:38:12,880 --> 00:38:15,359
implementation on the jvm compatible

00:38:14,880 --> 00:38:16,960
language

00:38:15,359 --> 00:38:18,880
right that's the the requirement

00:38:16,960 --> 00:38:19,520
unfortunately there's no native python

00:38:18,880 --> 00:38:23,839
code

00:38:19,520 --> 00:38:23,839
so jython could be your way out

00:38:26,240 --> 00:38:32,640
jen's thanks recorder great session

00:38:29,680 --> 00:38:33,359
my pleasure gents i i i hope you like it

00:38:32,640 --> 00:38:36,480
alright so

00:38:33,359 --> 00:38:38,480
patrick not sure if you're that answer

00:38:36,480 --> 00:38:41,599
your question about the python thing

00:38:38,480 --> 00:38:44,800
um but it doesn't seem to have okay

00:38:41,599 --> 00:38:47,760
so nicholas has you said max

00:38:44,800 --> 00:38:49,599
task is given by user to kafka connect

00:38:47,760 --> 00:38:50,720
in that the connector needs to take into

00:38:49,599 --> 00:38:52,720
account so

00:38:50,720 --> 00:38:54,000
what would the connector do if the mass

00:38:52,720 --> 00:38:57,440
x is smaller

00:38:54,000 --> 00:38:59,200
than needed uh okay that's a very great

00:38:57,440 --> 00:39:02,240
question nicholas so

00:38:59,200 --> 00:39:04,720
one of the things that you can do right

00:39:02,240 --> 00:39:06,160
is to remember the whole purpose of

00:39:04,720 --> 00:39:08,640
setting max task is because

00:39:06,160 --> 00:39:10,160
the user is telling you about some

00:39:08,640 --> 00:39:12,320
infrastructure limit

00:39:10,160 --> 00:39:14,160
right if you go beyond that limit you

00:39:12,320 --> 00:39:17,520
buy overload the infrastructure

00:39:14,160 --> 00:39:20,320
that some someone previous than you

00:39:17,520 --> 00:39:21,359
size it properly right so what you can

00:39:20,320 --> 00:39:23,839
try to do

00:39:21,359 --> 00:39:25,040
is to use your own concurrency strategy

00:39:23,839 --> 00:39:27,920
to break down the logic

00:39:25,040 --> 00:39:29,119
so it's task for example my might be

00:39:27,920 --> 00:39:33,599
able to spin up their

00:39:29,119 --> 00:39:35,520
its own child threads for example right

00:39:33,599 --> 00:39:37,599
you have to do this carefully right

00:39:35,520 --> 00:39:37,920
because ultimately this is still going

00:39:37,599 --> 00:39:39,839
to

00:39:37,920 --> 00:39:41,200
try to overload the environment that has

00:39:39,839 --> 00:39:42,880
been specified for you

00:39:41,200 --> 00:39:45,599
the only thing that you are bypassing

00:39:42,880 --> 00:39:47,040
here is the criteria of tasks per user

00:39:45,599 --> 00:39:48,480
so now

00:39:47,040 --> 00:39:50,960
it will be your responsibility to break

00:39:48,480 --> 00:39:54,160
down its task in its own thread and

00:39:50,960 --> 00:39:56,400
most importantly your code would have to

00:39:54,160 --> 00:39:58,640
control each one of those child threats

00:39:56,400 --> 00:39:59,520
the life cycle of them so this is one

00:39:58,640 --> 00:40:02,480
strategy

00:39:59,520 --> 00:40:04,960
right uh but yeah that's basically what

00:40:02,480 --> 00:40:04,960
you can do

00:40:06,000 --> 00:40:12,400
okay so patrick oh interesting so it's

00:40:10,400 --> 00:40:13,920
kafka connector for doing things other

00:40:12,400 --> 00:40:15,920
than publishing subscribe

00:40:13,920 --> 00:40:17,200
what are some use kits for connector

00:40:15,920 --> 00:40:19,680
good question patrick so

00:40:17,200 --> 00:40:21,599
uh a very typical and common use case

00:40:19,680 --> 00:40:23,280
for connectors cafe connect specifically

00:40:21,599 --> 00:40:26,000
is to do cdc

00:40:23,280 --> 00:40:26,960
change data capture so imagine a use

00:40:26,000 --> 00:40:29,359
case where

00:40:26,960 --> 00:40:31,359
you have a legacy database that is

00:40:29,359 --> 00:40:33,280
whether running on a mainframe or maybe

00:40:31,359 --> 00:40:35,680
uh uh on some other platform

00:40:33,280 --> 00:40:37,839
and you want that data that has been

00:40:35,680 --> 00:40:39,440
transacted for the applications right

00:40:37,839 --> 00:40:41,119
you want to make that data available to

00:40:39,440 --> 00:40:43,119
some other systems but you don't

00:40:41,119 --> 00:40:45,760
necessarily want to actually uh

00:40:43,119 --> 00:40:47,680
interrupt the transaction that's going

00:40:45,760 --> 00:40:48,240
on with the application so what you can

00:40:47,680 --> 00:40:51,359
do

00:40:48,240 --> 00:40:53,119
is to build a connector for cdc purposes

00:40:51,359 --> 00:40:55,440
where you're going to read all the

00:40:53,119 --> 00:40:58,160
transaction log for the source database

00:40:55,440 --> 00:41:00,079
and then you can stream that out into

00:40:58,160 --> 00:41:01,599
the intersect applications right

00:41:00,079 --> 00:41:03,920
actually i'm going to put here on the

00:41:01,599 --> 00:41:07,280
chat there is a

00:41:03,920 --> 00:41:09,760
very interesting project from red hat

00:41:07,280 --> 00:41:11,359
it's called the busine.io i'm gonna just

00:41:09,760 --> 00:41:14,480
put here in the chat

00:41:11,359 --> 00:41:16,960
where there is some pre-built cdc

00:41:14,480 --> 00:41:18,319
basic connectors written on top of kafka

00:41:16,960 --> 00:41:19,119
connect that you can use for this

00:41:18,319 --> 00:41:22,720
purpose

00:41:19,119 --> 00:41:24,319
okay uh

00:41:22,720 --> 00:41:26,000
so i could break down too many

00:41:24,319 --> 00:41:28,560
sequential tasks container for kafka

00:41:26,000 --> 00:41:30,240
yes nicholas exactly so though each one

00:41:28,560 --> 00:41:32,480
sequential task is

00:41:30,240 --> 00:41:33,440
could be executed either in a sequence

00:41:32,480 --> 00:41:35,359
or in parallel

00:41:33,440 --> 00:41:36,480
that's uh what i meant creating your own

00:41:35,359 --> 00:41:38,640
thread i

00:41:36,480 --> 00:41:40,560
i we're thinking about uh parallelism

00:41:38,640 --> 00:41:43,200
right but yeah you can actually

00:41:40,560 --> 00:41:45,359
break down into sequences as well for

00:41:43,200 --> 00:41:48,400
sure

00:41:45,359 --> 00:41:51,680
can i do json parsing and jdbc

00:41:48,400 --> 00:41:54,800
think dynamically uh that's a very

00:41:51,680 --> 00:41:56,240
very interesting question eldos um so

00:41:54,800 --> 00:41:59,760
you don't need to do this

00:41:56,240 --> 00:42:01,760
right so kafka connect has some built-in

00:41:59,760 --> 00:42:03,520
and some freaking awesome capabilities

00:42:01,760 --> 00:42:05,520
to do parsing for

00:42:03,520 --> 00:42:06,960
known serial agent serialization

00:42:05,520 --> 00:42:10,960
technology such as

00:42:06,960 --> 00:42:14,240
jason avro pro buff and

00:42:10,960 --> 00:42:17,040
i think csv i'm not sure

00:42:14,240 --> 00:42:17,520
point is you don't need to do this right

00:42:17,040 --> 00:42:19,839
if you

00:42:17,520 --> 00:42:21,280
want it remember that method poll that

00:42:19,839 --> 00:42:21,760
i've mentioned before that's the place

00:42:21,280 --> 00:42:23,200
where

00:42:21,760 --> 00:42:24,960
if you want to transform the method and

00:42:23,200 --> 00:42:26,240
do your own json handily

00:42:24,960 --> 00:42:28,079
that's the place where you should do it

00:42:26,240 --> 00:42:30,480
but uh

00:42:28,079 --> 00:42:31,119
you don't need it uh you there's a

00:42:30,480 --> 00:42:32,560
property

00:42:31,119 --> 00:42:35,200
for your connector that you can simply

00:42:32,560 --> 00:42:38,640
say all right i want this output

00:42:35,200 --> 00:42:38,960
to be json and then whatever format you

00:42:38,640 --> 00:42:45,440
have

00:42:38,960 --> 00:42:47,680
is going to be transformed for you

00:42:45,440 --> 00:42:48,720
yes i have my next presentation right

00:42:47,680 --> 00:42:51,920
now so

00:42:48,720 --> 00:42:54,880
unfortunately we have to wrap it up so

00:42:51,920 --> 00:42:56,079
thanks everybody for joining me in the

00:42:54,880 --> 00:42:58,480
session and for those of you

00:42:56,079 --> 00:42:59,520
are welcome to to keep up for the next

00:42:58,480 --> 00:43:01,200
session right

00:42:59,520 --> 00:43:03,200
but for this one thank you for

00:43:01,200 --> 00:43:13,040
participating and see you

00:43:03,200 --> 00:43:15,119
out there

00:43:13,040 --> 00:43:15,119

YouTube URL: https://www.youtube.com/watch?v=EXviLqXFoQI


