Title: Fast Samza SQL: Stream Processing Made Easy
Publication date: 2020-10-22
Playlist: ApacheCon @Home 2020: Streaming
Description: 
	Fast Samza SQL: Stream Processing Made Easy
Weiqing Yang, Aditya Toomula

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Weiqing Yang
Weiqing has been working in big data computation frameworks since 2015 and is an Apache Spark/HBase/Hadoop/Samza contributor. She is currently a software engineer in streaming infrastructure team at LinkedIn, working on Samza, Kafka, etc. Before that, she worked in Spark team at Hortonworks. Weiqing obtained a Master Degree in Computational Data Science from Carnegie Mellon University. Weiqing enjoys speaking at conferences. She presented in Spark Summit 2017, HBaseCon 2017, and KubeCon + CloudNativeCon North America 2019.
Aditya Toomula
Aditya has been working at Linkedin in streams infrastructure team since 2016. He has contributed to Apache Samza and Brooklin with latest contributions to Samza Sql and fully managed Samza. He is an Apache Samza committer and has over 15 years of Software Engineering experience. In his earlier life, he worked in Storage domain at NetApp, building various kinds of replication products and file systems.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:24,560 --> 00:00:28,800
yes

00:00:25,439 --> 00:00:30,960
okay cool sorry

00:00:28,800 --> 00:00:32,320
so today we are gonna walk you through

00:00:30,960 --> 00:00:35,040
by giving you a

00:00:32,320 --> 00:00:35,680
quick high-level view of what man exams

00:00:35,040 --> 00:00:38,000
are that

00:00:35,680 --> 00:00:39,600
and what we teach to our customers who

00:00:38,000 --> 00:00:42,079
want to do stream processing at the

00:00:39,600 --> 00:00:42,079
linking

00:00:42,840 --> 00:00:45,840
so

00:00:46,239 --> 00:00:50,719
so this is the kind of over agenda we

00:00:49,039 --> 00:00:53,120
have for the next half an hour

00:00:50,719 --> 00:00:55,039
to 40 minutes so i will give you an

00:00:53,120 --> 00:00:58,960
introduction and background about

00:00:55,039 --> 00:00:58,960
apache sensor and medicine

00:00:59,359 --> 00:01:02,480
i'm sorry again like i don't see your

00:01:01,039 --> 00:01:06,960
presentation

00:01:02,480 --> 00:01:09,119
oh you can still make me how about now

00:01:06,960 --> 00:01:09,119
no

00:01:10,320 --> 00:01:15,280
uh how about now i just yeah no i don't

00:01:13,040 --> 00:01:15,280
see it

00:01:15,520 --> 00:01:23,360
okay now now it's good yeah okay

00:01:19,200 --> 00:01:26,479
i don't know what's happening okay cool

00:01:23,360 --> 00:01:29,520
so this is kind of like overall agenda

00:01:26,479 --> 00:01:30,560
what we have for them for the next half

00:01:29,520 --> 00:01:33,759
an hour

00:01:30,560 --> 00:01:36,079
so um first i'll give the introduction

00:01:33,759 --> 00:01:37,119
background about match standard at the

00:01:36,079 --> 00:01:40,320
linking

00:01:37,119 --> 00:01:42,640
and what's the value of proposition

00:01:40,320 --> 00:01:44,079
that mandatory stanza has offered for

00:01:42,640 --> 00:01:46,560
our customers

00:01:44,079 --> 00:01:47,840
and then i will cover some typical use

00:01:46,560 --> 00:01:51,520
cases

00:01:47,840 --> 00:01:54,000
and a general use user experience

00:01:51,520 --> 00:01:54,799
and then aptl will talk about the

00:01:54,000 --> 00:01:57,200
internals

00:01:54,799 --> 00:01:57,920
of magic standard and share the

00:01:57,200 --> 00:02:01,280
experience

00:01:57,920 --> 00:02:01,280
and lessons we have learned

00:02:02,719 --> 00:02:09,679
so um to start why many stand down

00:02:06,640 --> 00:02:12,720
here is the background about uh

00:02:09,679 --> 00:02:15,680
so uh i think it's gone

00:02:12,720 --> 00:02:15,680
again presentation

00:02:20,160 --> 00:02:22,640
how

00:02:24,239 --> 00:02:29,760
okay so apache sensor is a scalable

00:02:28,080 --> 00:02:32,480
stream processing engine

00:02:29,760 --> 00:02:34,080
that allows people to process data in

00:02:32,480 --> 00:02:36,560
near real time

00:02:34,080 --> 00:02:38,640
samsa is linking solution so it's a

00:02:36,560 --> 00:02:40,800
pretty old open source project

00:02:38,640 --> 00:02:41,840
as a linkedin it has been used in

00:02:40,800 --> 00:02:45,599
production since

00:02:41,840 --> 00:02:46,400
like 2014 and currently there have been

00:02:45,599 --> 00:02:51,200
thousands of

00:02:46,400 --> 00:02:54,000
application production already

00:02:51,200 --> 00:02:54,640
so after linking in one of the major

00:02:54,000 --> 00:02:56,879
things

00:02:54,640 --> 00:02:58,000
we have been working on is you want to

00:02:56,879 --> 00:03:00,959
make it effortless

00:02:58,000 --> 00:03:01,920
to create and run standard apps at any

00:03:00,959 --> 00:03:04,959
scale

00:03:01,920 --> 00:03:07,840
and one make it like cost

00:03:04,959 --> 00:03:08,879
effective center comes up different

00:03:07,840 --> 00:03:11,599
flavors

00:03:08,879 --> 00:03:14,800
standard as a library center on young

00:03:11,599 --> 00:03:14,800
and managed center

00:03:15,040 --> 00:03:21,440
so users can run center as the library

00:03:18,800 --> 00:03:23,360
in standalone mode users can embed

00:03:21,440 --> 00:03:26,799
extender as a component

00:03:23,360 --> 00:03:27,920
within a larger application so they can

00:03:26,799 --> 00:03:30,239
import stanza

00:03:27,920 --> 00:03:31,440
as a library and write streaming

00:03:30,239 --> 00:03:34,400
processing logic

00:03:31,440 --> 00:03:35,440
using their existing application so in

00:03:34,400 --> 00:03:38,480
this mode

00:03:35,440 --> 00:03:38,879
everything is under user's control user

00:03:38,480 --> 00:03:42,720
has

00:03:38,879 --> 00:03:45,680
lots of flexibility but

00:03:42,720 --> 00:03:46,000
meanwhile user is responsible for pretty

00:03:45,680 --> 00:03:49,280
much

00:03:46,000 --> 00:03:52,480
everything both the app app management

00:03:49,280 --> 00:03:56,000
and resource management what

00:03:52,480 --> 00:03:58,080
users do for app management first

00:03:56,000 --> 00:04:00,640
user need to write their app in

00:03:58,080 --> 00:04:03,920
imperative language like in python

00:04:00,640 --> 00:04:05,599
in java and they need to manage standard

00:04:03,920 --> 00:04:08,480
framework dependencies

00:04:05,599 --> 00:04:11,200
test the app in experimental clusters

00:04:08,480 --> 00:04:14,080
set up configurations to the app

00:04:11,200 --> 00:04:15,680
publish and deploy the apps this kind of

00:04:14,080 --> 00:04:18,560
long journey to make an

00:04:15,680 --> 00:04:20,799
app in production and users need to

00:04:18,560 --> 00:04:23,440
repeat this journey for every

00:04:20,799 --> 00:04:26,000
framework dependency upgrade and deal

00:04:23,440 --> 00:04:29,120
with any bugs in framework

00:04:26,000 --> 00:04:31,680
user is the first poc for all the alerts

00:04:29,120 --> 00:04:32,880
when the app goes down user is the is

00:04:31,680 --> 00:04:34,960
the one who will

00:04:32,880 --> 00:04:36,000
take first look before involving

00:04:34,960 --> 00:04:37,919
standard team

00:04:36,000 --> 00:04:39,440
if there's any issue with them doesn't

00:04:37,919 --> 00:04:41,759
work itself

00:04:39,440 --> 00:04:43,520
so all the alerts and monitoring a

00:04:41,759 --> 00:04:46,639
user's responsibility

00:04:43,520 --> 00:04:50,400
it's user to keep the app

00:04:46,639 --> 00:04:53,600
up and running besides app management

00:04:50,400 --> 00:04:56,160
user needs to manage resources as well

00:04:53,600 --> 00:04:58,240
they need to manage the hardware like

00:04:56,160 --> 00:04:59,040
the hardware failure or add more

00:04:58,240 --> 00:05:02,560
hardware

00:04:59,040 --> 00:05:05,919
then applications need more resources

00:05:02,560 --> 00:05:08,320
and also they need to scale the

00:05:05,919 --> 00:05:09,199
resource education based on their app's

00:05:08,320 --> 00:05:12,639
needs

00:05:09,199 --> 00:05:13,600
for example to scale up resources like

00:05:12,639 --> 00:05:16,000
the cpu

00:05:13,600 --> 00:05:16,639
and memory when the traffic is very

00:05:16,000 --> 00:05:18,800
heavy

00:05:16,639 --> 00:05:20,320
and scale you down when the traffic is

00:05:18,800 --> 00:05:22,960
low

00:05:20,320 --> 00:05:24,160
since the resource measurement is a very

00:05:22,960 --> 00:05:26,479
big piece of work

00:05:24,160 --> 00:05:28,560
so a lot of users don't want to match

00:05:26,479 --> 00:05:32,080
the resources by themselves

00:05:28,560 --> 00:05:35,199
so samsung comes out another flavor

00:05:32,080 --> 00:05:38,479
user can run send our own

00:05:35,199 --> 00:05:39,600
young cluster the management

00:05:38,479 --> 00:05:42,639
responsibility

00:05:39,600 --> 00:05:46,000
about running samsung on young is

00:05:42,639 --> 00:05:46,560
half and half divided user manages the

00:05:46,000 --> 00:05:49,600
app

00:05:46,560 --> 00:05:52,080
while standardizing managed resources we

00:05:49,600 --> 00:05:54,560
use young as a multi-payment payment

00:05:52,080 --> 00:05:55,360
managed clustering which provides

00:05:54,560 --> 00:05:58,639
failure

00:05:55,360 --> 00:06:01,840
isolation failure handling

00:05:58,639 --> 00:06:03,759
and resource management and running

00:06:01,840 --> 00:06:06,800
center on young

00:06:03,759 --> 00:06:07,600
obviously helps to relieve user's burden

00:06:06,800 --> 00:06:10,479
a lot

00:06:07,600 --> 00:06:11,120
but still there are many observed pain

00:06:10,479 --> 00:06:15,120
points

00:06:11,120 --> 00:06:17,120
from app management first it could take

00:06:15,120 --> 00:06:19,600
a few weeks to create an

00:06:17,120 --> 00:06:21,840
app as we mentioned in previous slides

00:06:19,600 --> 00:06:23,440
it's kind of long journey to make an app

00:06:21,840 --> 00:06:25,759
into production

00:06:23,440 --> 00:06:27,280
and it could take time to upgrade the

00:06:25,759 --> 00:06:29,680
framework version

00:06:27,280 --> 00:06:31,680
to upgrade the finger version using is

00:06:29,680 --> 00:06:34,000
to recompile the app

00:06:31,680 --> 00:06:35,360
and with the new version and redeploy

00:06:34,000 --> 00:06:37,759
the app

00:06:35,360 --> 00:06:38,400
sometimes the deployment on some

00:06:37,759 --> 00:06:41,680
framework

00:06:38,400 --> 00:06:42,479
upgrades through results in facts and

00:06:41,680 --> 00:06:46,000
apps

00:06:42,479 --> 00:06:49,440
that could make users very frustrated

00:06:46,000 --> 00:06:53,599
if two ways to use recycled for issues

00:06:49,440 --> 00:06:56,880
with the framework and also not everyone

00:06:53,599 --> 00:06:59,520
not everyone is adapted you um

00:06:56,880 --> 00:07:00,319
using configs to choose apps to fully

00:06:59,520 --> 00:07:03,360
understand

00:07:00,319 --> 00:07:06,000
and set up correct configurations

00:07:03,360 --> 00:07:08,080
um there are some complexity there and

00:07:06,000 --> 00:07:12,160
also not everyone is aware

00:07:08,080 --> 00:07:15,680
imperative language like java or python

00:07:12,160 --> 00:07:18,240
and for the apps written in java

00:07:15,680 --> 00:07:19,599
or python usually to manually compile

00:07:18,240 --> 00:07:23,440
and publish it

00:07:19,599 --> 00:07:27,120
so we cannot dynamically create those

00:07:23,440 --> 00:07:28,080
standard java apps but we do have some

00:07:27,120 --> 00:07:30,360
customers

00:07:28,080 --> 00:07:33,199
they do one like dynamically and

00:07:30,360 --> 00:07:36,319
programmatically create standard apps in

00:07:33,199 --> 00:07:39,120
their services and the last

00:07:36,319 --> 00:07:40,160
but not least there are quite a few

00:07:39,120 --> 00:07:43,680
applications

00:07:40,160 --> 00:07:45,440
having similar use cases we should be

00:07:43,680 --> 00:07:47,919
able to accomplish those

00:07:45,440 --> 00:07:48,720
instead of reinventing the wheel every

00:07:47,919 --> 00:07:52,319
time

00:07:48,720 --> 00:07:53,120
for example um it's common for users to

00:07:52,319 --> 00:07:55,039
compact

00:07:53,120 --> 00:07:56,160
records based on the keys in the

00:07:55,039 --> 00:07:58,560
database

00:07:56,160 --> 00:08:00,240
it will be great if we can template

00:07:58,560 --> 00:08:02,240
these common business needs

00:08:00,240 --> 00:08:03,599
and then usually you can just send me

00:08:02,240 --> 00:08:06,960
some configurations

00:08:03,599 --> 00:08:09,759
or parameters like the record key and

00:08:06,960 --> 00:08:10,319
database table information through some

00:08:09,759 --> 00:08:13,599
portal

00:08:10,319 --> 00:08:16,720
or 12 and then the app could be

00:08:13,599 --> 00:08:19,280
automatically provisioned

00:08:16,720 --> 00:08:20,400
um so how to resolve all these pain

00:08:19,280 --> 00:08:22,800
points

00:08:20,400 --> 00:08:24,840
how to make job creation faster and

00:08:22,800 --> 00:08:27,680
imagine

00:08:24,840 --> 00:08:30,240
simpler

00:08:27,680 --> 00:08:31,199
so that's why many stanza comes to the

00:08:30,240 --> 00:08:34,399
picture

00:08:31,199 --> 00:08:35,120
to resolve those pinpoint so before we

00:08:34,399 --> 00:08:38,080
call

00:08:35,120 --> 00:08:41,200
match standard manage stream processing

00:08:38,080 --> 00:08:43,919
at the linkedin as fast standard sql

00:08:41,200 --> 00:08:45,360
that now are required with managed

00:08:43,919 --> 00:08:48,160
standard

00:08:45,360 --> 00:08:49,519
in this mode user just needs to focus on

00:08:48,160 --> 00:08:52,880
the app logic

00:08:49,519 --> 00:08:56,080
with zero configurations standard team

00:08:52,880 --> 00:08:57,920
we managed app and resources

00:08:56,080 --> 00:08:59,760
to resolve the needs of dynamically

00:08:57,920 --> 00:09:03,519
creating standby apps

00:08:59,760 --> 00:09:07,680
we introduced fast single service

00:09:03,519 --> 00:09:11,040
we will talk about civil service later

00:09:07,680 --> 00:09:13,760
for users responsibilities

00:09:11,040 --> 00:09:14,560
now user just needs to focus on the app

00:09:13,760 --> 00:09:17,839
logic

00:09:14,560 --> 00:09:20,480
and manage the app lifecycle of the app

00:09:17,839 --> 00:09:21,519
currently user can like order out your

00:09:20,480 --> 00:09:24,560
sql

00:09:21,519 --> 00:09:25,920
and but we plan to support more dsl in

00:09:24,560 --> 00:09:28,880
the future

00:09:25,920 --> 00:09:30,640
resource allocation and resource sizing

00:09:28,880 --> 00:09:32,720
is done by standard team

00:09:30,640 --> 00:09:35,040
we have dedicated young clusters for

00:09:32,720 --> 00:09:38,320
magic standard apps

00:09:35,040 --> 00:09:41,680
for operational effects like the

00:09:38,320 --> 00:09:45,120
uh library updates since we sort of do

00:09:41,680 --> 00:09:46,640
the app business logic with underlying

00:09:45,120 --> 00:09:49,040
framework libraries

00:09:46,640 --> 00:09:49,680
but never gets a new version available

00:09:49,040 --> 00:09:52,560
let's say

00:09:49,680 --> 00:09:53,839
standard version upgrades what we do is

00:09:52,560 --> 00:09:56,720
we roll out that

00:09:53,839 --> 00:09:57,200
new version without updating users apps

00:09:56,720 --> 00:10:00,240
with that

00:09:57,200 --> 00:10:02,560
new framework library

00:10:00,240 --> 00:10:04,079
so users don't need to don't have to

00:10:02,560 --> 00:10:06,880
worry about picking up

00:10:04,079 --> 00:10:07,760
a new version every time we take care of

00:10:06,880 --> 00:10:10,959
those underneath

00:10:07,760 --> 00:10:14,000
libraries so for alerts

00:10:10,959 --> 00:10:14,640
alerts goes to send a team first stamina

00:10:14,000 --> 00:10:16,800
team take

00:10:14,640 --> 00:10:18,399
care of the alerts and monitoring the

00:10:16,800 --> 00:10:21,440
alert lot

00:10:18,399 --> 00:10:21,680
and we will involve user when when there

00:10:21,440 --> 00:10:24,399
is

00:10:21,680 --> 00:10:26,160
some issues about the business logic

00:10:24,399 --> 00:10:28,240
user will be alerted

00:10:26,160 --> 00:10:30,959
only if there are issues from their own

00:10:28,240 --> 00:10:30,959
ud apps

00:10:31,680 --> 00:10:36,240
so what's the value of proposition that

00:10:34,240 --> 00:10:40,240
manages samsung offers to

00:10:36,240 --> 00:10:43,200
our customer um the vision is to

00:10:40,240 --> 00:10:45,279
our vision is to build a platform that

00:10:43,200 --> 00:10:46,079
enables users to create stream

00:10:45,279 --> 00:10:49,040
processing

00:10:46,079 --> 00:10:50,160
pipelines within minutes and match them

00:10:49,040 --> 00:10:52,560
easily

00:10:50,160 --> 00:10:53,680
i'd like to think about it in three

00:10:52,560 --> 00:10:56,800
pillars

00:10:53,680 --> 00:11:00,000
productive smart and reliable

00:10:56,800 --> 00:11:02,480
so all what all this mean

00:11:00,000 --> 00:11:04,640
when we talk about productive one of the

00:11:02,480 --> 00:11:05,760
biggest ladder proposition we bring to

00:11:04,640 --> 00:11:09,120
the table is

00:11:05,760 --> 00:11:11,519
how easy is used for customers so

00:11:09,120 --> 00:11:12,480
if the customer is knowledgeable in sql

00:11:11,519 --> 00:11:14,720
they can build an

00:11:12,480 --> 00:11:15,680
end-to-end streaming pipeline on the top

00:11:14,720 --> 00:11:18,880
of the semicircle

00:11:15,680 --> 00:11:20,640
just within a few minutes we do

00:11:18,880 --> 00:11:22,720
understand signal is not

00:11:20,640 --> 00:11:24,320
going to be good enough for most of the

00:11:22,720 --> 00:11:26,839
advanced scenarios

00:11:24,320 --> 00:11:28,560
so we have augmented to that with

00:11:26,839 --> 00:11:32,320
user-defined functions

00:11:28,560 --> 00:11:33,680
in java and no configuration required

00:11:32,320 --> 00:11:36,800
from the user

00:11:33,680 --> 00:11:39,440
we also offer a

00:11:36,800 --> 00:11:42,000
orchestrator orchestration layer to help

00:11:39,440 --> 00:11:44,720
user to validate the app logic

00:11:42,000 --> 00:11:46,800
we'll talk about this later so this

00:11:44,720 --> 00:11:50,320
enables users to find the errors

00:11:46,800 --> 00:11:52,079
before job management and smart

00:11:50,320 --> 00:11:53,839
all the scaling is offered out of the

00:11:52,079 --> 00:11:56,880
box so you don't need to

00:11:53,839 --> 00:11:59,680
cue your apps based on the traffic

00:11:56,880 --> 00:12:02,480
to make operation easier we have smart

00:11:59,680 --> 00:12:05,360
alerting system for custom udfs

00:12:02,480 --> 00:12:06,160
we have custom dashboard based on the

00:12:05,360 --> 00:12:09,360
inputs and

00:12:06,160 --> 00:12:11,920
outputs as well and also

00:12:09,360 --> 00:12:14,560
manchester united must be reliable uh

00:12:11,920 --> 00:12:17,839
regarding no data loss at least once

00:12:14,560 --> 00:12:18,240
one was processing and for tolerance and

00:12:17,839 --> 00:12:20,639
for

00:12:18,240 --> 00:12:24,720
cavalry so all these are offered by

00:12:20,639 --> 00:12:26,959
standard engine

00:12:24,720 --> 00:12:29,200
currently if user runner create a

00:12:26,959 --> 00:12:31,440
managed standard app be used

00:12:29,200 --> 00:12:32,800
they can use them.sql to develop their

00:12:31,440 --> 00:12:35,440
business logic

00:12:32,800 --> 00:12:35,920
in the future we can support more dsl

00:12:35,440 --> 00:12:39,120
than

00:12:35,920 --> 00:12:42,399
classical um but now let's let's

00:12:39,120 --> 00:12:45,519
quick uh quick look at standard sql so

00:12:42,399 --> 00:12:48,399
standard sql um use

00:12:45,519 --> 00:12:48,959
a car site as as underlying engine to

00:12:48,399 --> 00:12:52,240
convert

00:12:48,959 --> 00:12:54,959
sql to a budget plan its

00:12:52,240 --> 00:12:55,760
seminar sql supports standard sql

00:12:54,959 --> 00:12:58,320
operations

00:12:55,760 --> 00:12:59,600
and support different ios like for

00:12:58,320 --> 00:13:02,480
streams

00:12:59,600 --> 00:13:04,320
uh we support kafka and brooklyn the

00:13:02,480 --> 00:13:07,360
program is developed at linkedin

00:13:04,320 --> 00:13:10,639
and has been open sourced already it's a

00:13:07,360 --> 00:13:13,279
stream ingestion service that can

00:13:10,639 --> 00:13:14,000
inject string data from different source

00:13:13,279 --> 00:13:16,959
type and

00:13:14,000 --> 00:13:17,680
publish to different destination type

00:13:16,959 --> 00:13:20,800
like

00:13:17,680 --> 00:13:24,880
kafka azure even have an anymore

00:13:20,800 --> 00:13:27,680
so we will use it in an example later

00:13:24,880 --> 00:13:28,720
for stores for example we support

00:13:27,680 --> 00:13:31,680
espresso

00:13:28,720 --> 00:13:33,440
a document oriented data store which is

00:13:31,680 --> 00:13:36,560
developed at

00:13:33,440 --> 00:13:40,399
coach base which we often use as a

00:13:36,560 --> 00:13:41,120
cache and then is is a specialized kiwi

00:13:40,399 --> 00:13:44,000
store

00:13:41,120 --> 00:13:44,480
to inject and serve derive the data

00:13:44,000 --> 00:13:48,079
learning

00:13:44,480 --> 00:13:51,600
is also developed at linkedin

00:13:48,079 --> 00:13:54,560
and we also offer pre-defined good apps

00:13:51,600 --> 00:13:55,600
the framework good apps everyone can use

00:13:54,560 --> 00:13:57,680
it

00:13:55,600 --> 00:13:58,800
but sometimes those support are still

00:13:57,680 --> 00:14:00,880
not enough

00:13:58,800 --> 00:14:02,880
so in this case you can apply your own

00:14:00,880 --> 00:14:04,079
pdf where you can do your own

00:14:02,880 --> 00:14:08,240
transformation

00:14:04,079 --> 00:14:13,199
or mix even you can make some rest calls

00:14:08,240 --> 00:14:13,199
and now we support java for udfs

00:14:13,519 --> 00:14:17,760
um just give you an example about

00:14:16,160 --> 00:14:21,120
standard sql

00:14:17,760 --> 00:14:24,639
so here in the slides you can see um

00:14:21,120 --> 00:14:27,440
there is a case the case is to enrich

00:14:24,639 --> 00:14:28,800
pageview event messages with member

00:14:27,440 --> 00:14:34,000
profile data

00:14:28,800 --> 00:14:37,360
their data are saved in espresso table

00:14:34,000 --> 00:14:40,959
the page view event is a kafka topic

00:14:37,360 --> 00:14:42,560
which has information of page page views

00:14:40,959 --> 00:14:45,760
of each member

00:14:42,560 --> 00:14:49,120
so let's say now your app shouldn't

00:14:45,760 --> 00:14:51,440
read data directly from espresso table

00:14:49,120 --> 00:14:53,199
because maybe you run out of the

00:14:51,440 --> 00:14:56,079
espresso quota

00:14:53,199 --> 00:14:57,839
so what you can do is you can create a

00:14:56,079 --> 00:15:00,320
culture-based bucket as patch

00:14:57,839 --> 00:15:01,040
for this so you can create a grouping

00:15:00,320 --> 00:15:04,079
string

00:15:01,040 --> 00:15:07,760
let's say the broken string name is

00:15:04,079 --> 00:15:11,040
identify profile change capture so here

00:15:07,760 --> 00:15:14,399
we use opening as change capture service

00:15:11,040 --> 00:15:16,880
the source of the stream is uh espresso

00:15:14,399 --> 00:15:17,600
identity profile table and under the

00:15:16,880 --> 00:15:19,199
hood

00:15:17,600 --> 00:15:21,920
brooklyn will send those change

00:15:19,199 --> 00:15:22,560
practices events of the special table to

00:15:21,920 --> 00:15:26,240
the

00:15:22,560 --> 00:15:29,040
topic and then you can create a

00:15:26,240 --> 00:15:29,920
sql job which is reading from booking

00:15:29,040 --> 00:15:32,320
stream

00:15:29,920 --> 00:15:33,519
and insert those data into culture-based

00:15:32,320 --> 00:15:36,880
market

00:15:33,519 --> 00:15:39,120
and later on this culture-based bucket

00:15:36,880 --> 00:15:40,000
is something your other application can

00:15:39,120 --> 00:15:42,959
use for reading

00:15:40,000 --> 00:15:45,040
data that's one way we can extend that

00:15:42,959 --> 00:15:47,279
sequel

00:15:45,040 --> 00:15:48,160
and then let's say you want to enrich

00:15:47,279 --> 00:15:50,880
your data

00:15:48,160 --> 00:15:52,880
you want to add more information about

00:15:50,880 --> 00:15:54,160
the members along with the pageview

00:15:52,880 --> 00:15:56,480
event

00:15:54,160 --> 00:15:58,320
and so what you can do is you can use

00:15:56,480 --> 00:16:01,600
join you can read the

00:15:58,320 --> 00:16:04,240
topic and for each topic

00:16:01,600 --> 00:16:04,880
for each on comparing events you look up

00:16:04,240 --> 00:16:07,199
the cache

00:16:04,880 --> 00:16:08,720
culture-based cache which has created in

00:16:07,199 --> 00:16:11,279
the first example

00:16:08,720 --> 00:16:13,519
and then you can do join that data and

00:16:11,279 --> 00:16:16,720
then you output the enriched data

00:16:13,519 --> 00:16:20,320
into some other topic let's say enrich

00:16:16,720 --> 00:16:22,639
pageview event so that others can

00:16:20,320 --> 00:16:24,880
consume from that topic

00:16:22,639 --> 00:16:27,600
so this is just an example to show you

00:16:24,880 --> 00:16:30,800
what stem that sequel looks like

00:16:27,600 --> 00:16:32,560
for more details about zendasico

00:16:30,800 --> 00:16:35,519
you can check the talk about standard

00:16:32,560 --> 00:16:37,600
super engine given by my co-workers uni

00:16:35,519 --> 00:16:40,560
i have copied the video link in the

00:16:37,600 --> 00:16:40,560
bottom of the slide

00:16:42,480 --> 00:16:50,240
next i will cover some typical use cases

00:16:46,160 --> 00:16:53,759
so now we have more than 500

00:16:50,240 --> 00:16:56,639
magic standard pipelines in production

00:16:53,759 --> 00:16:58,480
so before looking at the use cases let's

00:16:56,639 --> 00:17:01,920
briefly go through the digital

00:16:58,480 --> 00:17:05,679
app after architecture um

00:17:01,920 --> 00:17:08,240
event producer so it could be a service

00:17:05,679 --> 00:17:09,919
which produced events for example

00:17:08,240 --> 00:17:12,959
pageview human events

00:17:09,919 --> 00:17:16,079
used in previous sentences for example

00:17:12,959 --> 00:17:19,280
it could be database changes it could be

00:17:16,079 --> 00:17:22,400
major metrics you have all these

00:17:19,280 --> 00:17:22,880
event producers which produce your

00:17:22,400 --> 00:17:26,079
events

00:17:22,880 --> 00:17:28,160
into matching systems like kafka

00:17:26,079 --> 00:17:30,799
you will have standard apps which

00:17:28,160 --> 00:17:33,360
process those events from the streams

00:17:30,799 --> 00:17:35,200
and write those processed data out to

00:17:33,360 --> 00:17:38,720
the output system

00:17:35,200 --> 00:17:42,080
let's say it could be a database a rest

00:17:38,720 --> 00:17:44,000
address services or it could

00:17:42,080 --> 00:17:46,080
it might write data again to another

00:17:44,000 --> 00:17:48,640
system like captain

00:17:46,080 --> 00:17:49,440
then your downstream applications can

00:17:48,640 --> 00:17:53,120
consume

00:17:49,440 --> 00:17:56,400
the results to do their own analysis

00:17:53,120 --> 00:18:00,320
so that's a typical app

00:17:56,400 --> 00:18:03,840
architecture looks like

00:18:00,320 --> 00:18:06,880
so what other use cases um

00:18:03,840 --> 00:18:08,400
so you can use magic center for all

00:18:06,880 --> 00:18:11,240
these use cases

00:18:08,400 --> 00:18:12,840
change capture data migration

00:18:11,240 --> 00:18:16,080
repartitioning

00:18:12,840 --> 00:18:19,600
cache window join and window

00:18:16,080 --> 00:18:21,440
applications um i will quickly just go

00:18:19,600 --> 00:18:24,720
through some of them

00:18:21,440 --> 00:18:27,440
so we peop we put a picture about the

00:18:24,720 --> 00:18:31,039
workflow of change capture view use case

00:18:27,440 --> 00:18:31,760
here so as we mentioned in previous

00:18:31,039 --> 00:18:34,880
slides

00:18:31,760 --> 00:18:37,679
brooklyn is a distributed service for

00:18:34,880 --> 00:18:37,679
streaming data

00:18:39,039 --> 00:18:44,559
it has been widely used at linkedin for

00:18:42,160 --> 00:18:46,160
change capture of change capture of the

00:18:44,559 --> 00:18:49,760
source of two stores

00:18:46,160 --> 00:18:52,880
like espresso article and

00:18:49,760 --> 00:18:55,360
my simple as it shows here users can

00:18:52,880 --> 00:18:57,039
create a change capture view by using a

00:18:55,360 --> 00:18:59,520
managed standard job

00:18:57,039 --> 00:19:01,200
which consumes the change capture event

00:18:59,520 --> 00:19:03,520
from booking stream

00:19:01,200 --> 00:19:05,280
and in standard job there could be a

00:19:03,520 --> 00:19:08,840
string table join

00:19:05,280 --> 00:19:13,520
join between multiple tables filtering

00:19:08,840 --> 00:19:13,520
masking pi data and so on

00:19:14,000 --> 00:19:20,720
so user can create

00:19:17,120 --> 00:19:24,160
database materialized view like espresso

00:19:20,720 --> 00:19:27,360
materials view um

00:19:24,160 --> 00:19:31,120
which you can create a derived

00:19:27,360 --> 00:19:33,919
table out of a primary table

00:19:31,120 --> 00:19:36,240
so uh to conduct the derived table for

00:19:33,919 --> 00:19:36,799
example you may want to project only a

00:19:36,240 --> 00:19:39,440
few

00:19:36,799 --> 00:19:40,400
a few fields and fill the drawers do

00:19:39,440 --> 00:19:43,520
some join

00:19:40,400 --> 00:19:44,880
or even you can upgrade your own utf to

00:19:43,520 --> 00:19:49,120
do some custom

00:19:44,880 --> 00:19:52,320
stuff on the primary data table

00:19:49,120 --> 00:19:55,360
so this is data and

00:19:52,320 --> 00:19:59,039
this is the data caching we

00:19:55,360 --> 00:20:01,840
just just uh i've mentioned we in the

00:19:59,039 --> 00:20:03,440
previous standard sql example we can use

00:20:01,840 --> 00:20:07,840
cash base as the

00:20:03,440 --> 00:20:11,039
cache okay

00:20:07,840 --> 00:20:13,760
uh let's switch the gears of it let's

00:20:11,039 --> 00:20:16,480
look at the overall like user experience

00:20:13,760 --> 00:20:16,880
and the operator experience offered by

00:20:16,480 --> 00:20:20,480
the

00:20:16,880 --> 00:20:23,760
managed standard so

00:20:20,480 --> 00:20:25,440
for job creation mandy stanza provides

00:20:23,760 --> 00:20:29,280
two different ways

00:20:25,440 --> 00:20:30,159
uh the first one uh is repository based

00:20:29,280 --> 00:20:33,039
author

00:20:30,159 --> 00:20:35,600
so this way provides an end-to-end good

00:20:33,039 --> 00:20:39,200
experience in job creation

00:20:35,600 --> 00:20:41,679
typically users can use our tools like

00:20:39,200 --> 00:20:43,440
standard sql shell to test and author

00:20:41,679 --> 00:20:46,320
their sql logic

00:20:43,440 --> 00:20:48,400
and after validating the simple logic

00:20:46,320 --> 00:20:49,760
users can commit their sequels to

00:20:48,400 --> 00:20:52,480
codepen

00:20:49,760 --> 00:20:54,080
and and then create and deploy their

00:20:52,480 --> 00:20:57,360
jobs through the shell

00:20:54,080 --> 00:21:01,600
uh we'll introduce this more in next

00:20:57,360 --> 00:21:04,880
slides and we have exposed

00:21:01,600 --> 00:21:08,400
the crude apis for managed standard apps

00:21:04,880 --> 00:21:10,960
so note not only show experience

00:21:08,400 --> 00:21:11,679
but this will also enable other services

00:21:10,960 --> 00:21:14,880
to create

00:21:11,679 --> 00:21:18,320
managed center apps programmatically

00:21:14,880 --> 00:21:21,919
on demand so the second way

00:21:18,320 --> 00:21:24,080
to create an app is programmatic

00:21:21,919 --> 00:21:26,720
so that's unblocking new capability

00:21:24,080 --> 00:21:28,720
which we didn't have before

00:21:26,720 --> 00:21:30,880
there are quite a few teams within the

00:21:28,720 --> 00:21:33,760
green that are in the process of using

00:21:30,880 --> 00:21:34,559
programmatic creation standard apps as a

00:21:33,760 --> 00:21:37,360
building block

00:21:34,559 --> 00:21:38,240
in their architecture so this also

00:21:37,360 --> 00:21:41,520
enables

00:21:38,240 --> 00:21:41,520
longer processing

00:21:42,080 --> 00:21:46,480
let's brief the repository based off and

00:21:44,720 --> 00:21:49,760
use the experience a bit

00:21:46,480 --> 00:21:50,880
uh during the authoring phase first user

00:21:49,760 --> 00:21:54,000
needs to develop their

00:21:50,880 --> 00:21:56,640
business logic with inputs and output

00:21:54,000 --> 00:21:58,480
after that they can express the app

00:21:56,640 --> 00:22:01,520
logic in one of the

00:21:58,480 --> 00:22:02,880
dsl supported by bench sensor like

00:22:01,520 --> 00:22:06,559
standard sql

00:22:02,880 --> 00:22:09,039
and then they can orchestrate their app

00:22:06,559 --> 00:22:09,679
validating the sequel in standard sequel

00:22:09,039 --> 00:22:11,679
shell

00:22:09,679 --> 00:22:13,120
where user can experiment their

00:22:11,679 --> 00:22:15,919
psychological

00:22:13,120 --> 00:22:18,240
um we'll we'll talk about sql

00:22:15,919 --> 00:22:21,360
orchestrator later

00:22:18,240 --> 00:22:23,039
but all these verification tests user

00:22:21,360 --> 00:22:26,080
can

00:22:23,039 --> 00:22:29,440
really can test their sql logic against

00:22:26,080 --> 00:22:33,840
the data in our experimental cluster

00:22:29,440 --> 00:22:37,200
and then commit and deploy the sequels

00:22:33,840 --> 00:22:38,320
so this is the end-to-end user

00:22:37,200 --> 00:22:41,520
experience

00:22:38,320 --> 00:22:44,159
using repository-based offering

00:22:41,520 --> 00:22:44,159
so for

00:22:45,360 --> 00:22:52,799
for user measurement and operators

00:22:49,360 --> 00:22:54,480
operations as we mentioned we allowed

00:22:52,799 --> 00:22:58,080
using control over

00:22:54,480 --> 00:23:00,960
the apps like cycle either from shell or

00:22:58,080 --> 00:23:01,679
or send a dashboard that means we cannot

00:23:00,960 --> 00:23:04,640
decide

00:23:01,679 --> 00:23:05,760
when users can start or stop the app and

00:23:04,640 --> 00:23:08,880
very eventually

00:23:05,760 --> 00:23:11,760
make change of their business logic so

00:23:08,880 --> 00:23:12,640
these things are user specific they are

00:23:11,760 --> 00:23:15,840
supposed to

00:23:12,640 --> 00:23:19,280
be handled by users user

00:23:15,840 --> 00:23:21,600
can create a new app and you strongly

00:23:19,280 --> 00:23:22,880
instruct it to start from a particular

00:23:21,600 --> 00:23:27,039
time

00:23:22,880 --> 00:23:27,360
and they can instruct the existing app

00:23:27,039 --> 00:23:30,240
to

00:23:27,360 --> 00:23:32,320
reprocess data from a particular time so

00:23:30,240 --> 00:23:36,159
that's used a lot

00:23:32,320 --> 00:23:38,880
by our customer they can also like be

00:23:36,159 --> 00:23:39,600
configs for their udf when they deploy

00:23:38,880 --> 00:23:41,919
their app

00:23:39,600 --> 00:23:43,360
if they want normally they don't require

00:23:41,919 --> 00:23:46,000
we don't require them

00:23:43,360 --> 00:23:46,720
we don't require any conflict from user

00:23:46,000 --> 00:23:49,679
so

00:23:46,720 --> 00:23:52,799
typically those config set up by user

00:23:49,679 --> 00:23:56,159
adjust for their udls

00:23:52,799 --> 00:23:59,760
so user can check the app status through

00:23:56,159 --> 00:24:02,400
extender dashboard

00:23:59,760 --> 00:24:03,679
we have standard dashboard for all the

00:24:02,400 --> 00:24:06,799
deployments

00:24:03,679 --> 00:24:09,760
in dashboard ui there are there

00:24:06,799 --> 00:24:10,960
there are app code here is the sql

00:24:09,760 --> 00:24:15,200
statements

00:24:10,960 --> 00:24:18,960
and there are a few options where user

00:24:15,200 --> 00:24:22,240
can add an update config if they want

00:24:18,960 --> 00:24:25,440
and user can start and stop that app so

00:24:22,240 --> 00:24:27,440
after dashboard generated users can just

00:24:25,440 --> 00:24:28,080
go to the dashboard to check their job

00:24:27,440 --> 00:24:31,840
better

00:24:28,080 --> 00:24:35,279
and control the job life cycle here

00:24:31,840 --> 00:24:37,760
they can click here to check the job

00:24:35,279 --> 00:24:37,760
matrix

00:24:37,840 --> 00:24:43,440
and we have matched like lagging

00:24:41,039 --> 00:24:44,640
the count of input event and the count

00:24:43,440 --> 00:24:48,640
of output event

00:24:44,640 --> 00:24:52,159
and so on so you can also click the job

00:24:48,640 --> 00:24:52,960
diagnostics tab here to check the top

00:24:52,159 --> 00:24:55,520
errors

00:24:52,960 --> 00:24:56,880
and the most recent errors if they have

00:24:55,520 --> 00:24:59,520
any

00:24:56,880 --> 00:25:00,159
so in the dashboard there are many

00:24:59,520 --> 00:25:02,880
useful

00:25:00,159 --> 00:25:02,880
information

00:25:04,880 --> 00:25:08,159
we have for the measurement and

00:25:07,440 --> 00:25:11,440
operation

00:25:08,159 --> 00:25:13,360
experience of operators we may have

00:25:11,440 --> 00:25:16,960
mentioned this in previous slides

00:25:13,360 --> 00:25:20,159
so sentence stamina team is the operator

00:25:16,960 --> 00:25:21,120
and it needs to match the app alert

00:25:20,159 --> 00:25:24,159
pretty much

00:25:21,120 --> 00:25:27,200
everything okay

00:25:24,159 --> 00:25:30,320
so that's about the user experience

00:25:27,200 --> 00:25:34,240
now let's um let's talk a bit about the

00:25:30,320 --> 00:25:37,120
sla model we have here so every time

00:25:34,240 --> 00:25:38,000
user deploy a new app the automatic

00:25:37,120 --> 00:25:41,120
setup

00:25:38,000 --> 00:25:43,360
alerts and the dashboard and the

00:25:41,120 --> 00:25:44,240
user and the own call doesn't need to do

00:25:43,360 --> 00:25:47,520
anything

00:25:44,240 --> 00:25:50,080
we also have like custom

00:25:47,520 --> 00:25:51,360
dashboard based on the input and output

00:25:50,080 --> 00:25:53,200
and sensor team

00:25:51,360 --> 00:25:56,000
is the first point of contact for the

00:25:53,200 --> 00:25:59,200
alerts if there are so many customer

00:25:56,000 --> 00:26:02,960
or udf ud apps um

00:25:59,200 --> 00:26:06,080
used by the job and if he issues that

00:26:02,960 --> 00:26:09,520
udf related orders will go to the user

00:26:06,080 --> 00:26:12,640
themselves and we guarantee 99

00:26:09,520 --> 00:26:14,559
job uptime exclude the job failure on uk

00:26:12,640 --> 00:26:18,080
app and downstream issues

00:26:14,559 --> 00:26:20,559
we have lag sla which based on the

00:26:18,080 --> 00:26:21,279
type of the pipeline for example if any

00:26:20,559 --> 00:26:23,760
tax bill

00:26:21,279 --> 00:26:24,799
is lagging for more than 10 minutes or

00:26:23,760 --> 00:26:27,440
20 minutes

00:26:24,799 --> 00:26:29,120
maybe there is something goes wrong we

00:26:27,440 --> 00:26:33,520
won't prevent that so in

00:26:29,120 --> 00:26:36,880
such case on call will get involved okay

00:26:33,520 --> 00:26:39,200
so next uh aditya will

00:26:36,880 --> 00:26:41,039
go into the details on manchester under

00:26:39,200 --> 00:26:45,760
under the book

00:26:41,039 --> 00:26:45,760
so let me stop sharing

00:26:49,840 --> 00:26:54,640
thanks richie i will

00:26:53,039 --> 00:26:56,640
first like breeze through the internal

00:26:54,640 --> 00:27:00,559
details of managed samsara

00:26:56,640 --> 00:27:01,840
followed by the learnings um

00:27:00,559 --> 00:27:03,520
here is the high level architecture

00:27:01,840 --> 00:27:04,080
diagram which shows different components

00:27:03,520 --> 00:27:07,120
of

00:27:04,080 --> 00:27:09,360
minus samsa and how they interact

00:27:07,120 --> 00:27:10,880
so a user first goes to the shell and

00:27:09,360 --> 00:27:14,640
other sql statement

00:27:10,880 --> 00:27:16,880
right equal by contacting the

00:27:14,640 --> 00:27:19,919
orchestrator and evaluator service

00:27:16,880 --> 00:27:22,000
and he finally deploys the sql job via

00:27:19,919 --> 00:27:25,200
shell deployment command

00:27:22,000 --> 00:27:27,440
so the shell deployment command ends up

00:27:25,200 --> 00:27:29,840
calling the stop and start apis on the

00:27:27,440 --> 00:27:32,000
fast sql service endpoint

00:27:29,840 --> 00:27:33,120
and upon receiving the start request the

00:27:32,000 --> 00:27:35,279
service

00:27:33,120 --> 00:27:37,360
the bundles the sql statement with the

00:27:35,279 --> 00:27:38,960
framework libraries and configs

00:27:37,360 --> 00:27:40,960
and pushes the resulting job to the

00:27:38,960 --> 00:27:45,360
young cluster to run

00:27:40,960 --> 00:27:48,000
now as soon as the containers come up

00:27:45,360 --> 00:27:48,880
in the yarn cluster as part of starting

00:27:48,000 --> 00:27:51,279
the java

00:27:48,880 --> 00:27:52,720
the samsung dashboard service uh it

00:27:51,279 --> 00:27:53,600
populates the job information in its

00:27:52,720 --> 00:27:55,679
database

00:27:53,600 --> 00:27:57,440
and the user should now be able to visit

00:27:55,679 --> 00:28:00,080
the app dashboard ui

00:27:57,440 --> 00:28:00,799
to check the status of the app look at

00:28:00,080 --> 00:28:03,760
the logs

00:28:00,799 --> 00:28:05,200
or metrics etc like a user can manage

00:28:03,760 --> 00:28:07,840
the job from the dashboard as matching

00:28:05,200 --> 00:28:11,600
virgin mentioned like earlier

00:28:07,840 --> 00:28:13,600
and after the job starts running

00:28:11,600 --> 00:28:15,440
auto scale controller kicks in and it

00:28:13,600 --> 00:28:17,039
sizes the job based on the load

00:28:15,440 --> 00:28:19,039
and it keeps like monitoring out of

00:28:17,039 --> 00:28:19,760
scale controller to see how the load is

00:28:19,039 --> 00:28:23,440
varying

00:28:19,760 --> 00:28:26,880
and accordingly it sizes the job

00:28:23,440 --> 00:28:30,320
so let me quickly dive into

00:28:26,880 --> 00:28:30,640
some of these components actually even

00:28:30,320 --> 00:28:32,240
the

00:28:30,640 --> 00:28:36,320
programmatic creation of apps also go

00:28:32,240 --> 00:28:36,320
through the similar sequence

00:28:36,480 --> 00:28:40,240
so shell um shell gives like a lot of

00:28:39,039 --> 00:28:42,960
capabilities

00:28:40,240 --> 00:28:43,360
for users to seamlessly write and run

00:28:42,960 --> 00:28:46,399
some

00:28:43,360 --> 00:28:47,039
applications they can use like shell to

00:28:46,399 --> 00:28:50,399
test

00:28:47,039 --> 00:28:53,120
their sql against like some data

00:28:50,399 --> 00:28:55,360
and experiment with queries uh while

00:28:53,120 --> 00:28:57,200
formulating their app logic

00:28:55,360 --> 00:28:58,559
so it provides like some of the basic

00:28:57,200 --> 00:28:59,679
capabilities like command editing

00:28:58,559 --> 00:29:02,880
history highlight

00:28:59,679 --> 00:29:03,120
um auto completion uh capabilities and

00:29:02,880 --> 00:29:04,559
it

00:29:03,120 --> 00:29:06,159
has like some commands like showing

00:29:04,559 --> 00:29:07,360
schema showing like what all data

00:29:06,159 --> 00:29:09,440
sources it has

00:29:07,360 --> 00:29:11,120
showing the udfs uh the both the

00:29:09,440 --> 00:29:13,039
framework uds and the custom udfs that

00:29:11,120 --> 00:29:16,960
the user has written

00:29:13,039 --> 00:29:20,000
and also it does it gives like a

00:29:16,960 --> 00:29:21,440
capability to run like sql query

00:29:20,000 --> 00:29:24,000
so as part of like running that

00:29:21,440 --> 00:29:26,640
executing that sql query

00:29:24,000 --> 00:29:27,600
the job validation uh and correction

00:29:26,640 --> 00:29:30,480
happens

00:29:27,600 --> 00:29:32,000
um like let's say if a resource is

00:29:30,480 --> 00:29:32,880
missing if a schema is missing if the

00:29:32,000 --> 00:29:34,640
schema

00:29:32,880 --> 00:29:36,480
the input schema and the output schema

00:29:34,640 --> 00:29:39,840
uh they do not match

00:29:36,480 --> 00:29:41,279
um and the select query like whatever

00:29:39,840 --> 00:29:43,039
fields are given in select query

00:29:41,279 --> 00:29:44,559
and the output schema like if there is

00:29:43,039 --> 00:29:47,679
uh any

00:29:44,559 --> 00:29:51,279
uh mismatch over there uh it uh

00:29:47,679 --> 00:29:52,960
looks at eccles um uh any actual

00:29:51,279 --> 00:29:55,679
validation if the user

00:29:52,960 --> 00:29:58,159
sorry if the app has access to the input

00:29:55,679 --> 00:30:01,919
resources and the output resources

00:29:58,159 --> 00:30:04,080
so um it does several such things

00:30:01,919 --> 00:30:05,520
and once this validation the static

00:30:04,080 --> 00:30:06,559
validation is done there is like logical

00:30:05,520 --> 00:30:08,960
validation

00:30:06,559 --> 00:30:09,600
where the query is run against the data

00:30:08,960 --> 00:30:12,080
and

00:30:09,600 --> 00:30:13,919
then it will display the results uh in a

00:30:12,080 --> 00:30:15,279
streaming friendly way within the shell

00:30:13,919 --> 00:30:17,840
itself

00:30:15,279 --> 00:30:19,600
so user does like a logical validation

00:30:17,840 --> 00:30:21,679
at this point

00:30:19,600 --> 00:30:22,880
now these are the ordering commands and

00:30:21,679 --> 00:30:23,279
there are like other set of commands

00:30:22,880 --> 00:30:25,279
that

00:30:23,279 --> 00:30:27,279
shell provides that's the job deployment

00:30:25,279 --> 00:30:32,320
and management commands

00:30:27,279 --> 00:30:32,320
so here is a snapshot of shell

00:30:32,559 --> 00:30:35,679
as i said like there are two sets of

00:30:34,080 --> 00:30:36,640
commands ordering and deployment as part

00:30:35,679 --> 00:30:39,760
of deployment

00:30:36,640 --> 00:30:42,480
one can see what all apps they have uh

00:30:39,760 --> 00:30:43,679
when was the app like deployed last time

00:30:42,480 --> 00:30:45,520
or like they want to

00:30:43,679 --> 00:30:46,960
redeploy the job that if they want to

00:30:45,520 --> 00:30:49,279
like uh

00:30:46,960 --> 00:30:50,960
restart the job from a particular point

00:30:49,279 --> 00:30:54,080
in the past

00:30:50,960 --> 00:30:54,720
they can do all these things so as i

00:30:54,080 --> 00:30:57,440
mentioned

00:30:54,720 --> 00:30:58,320
earlier like orchestration validation it

00:30:57,440 --> 00:31:01,679
does

00:30:58,320 --> 00:31:01,679
all the validations

00:31:02,559 --> 00:31:07,679
and fast sql service um uh

00:31:05,760 --> 00:31:09,840
it has a rest end point with support for

00:31:07,679 --> 00:31:12,640
uh start stop register jobs

00:31:09,840 --> 00:31:13,279
apis um it is the one responsible for

00:31:12,640 --> 00:31:15,600
creating the

00:31:13,279 --> 00:31:16,480
uh center sql apps dynamically and it

00:31:15,600 --> 00:31:18,320
determines the

00:31:16,480 --> 00:31:20,399
framework libraries and configs for each

00:31:18,320 --> 00:31:22,559
app

00:31:20,399 --> 00:31:24,000
it also authorizes the user operation on

00:31:22,559 --> 00:31:26,399
the apps like only

00:31:24,000 --> 00:31:27,919
people who have authorization to work on

00:31:26,399 --> 00:31:31,279
those apps they will be able to

00:31:27,919 --> 00:31:32,480
start or stop the apps and

00:31:31,279 --> 00:31:36,399
another thing that it does is like

00:31:32,480 --> 00:31:39,360
whenever a sql job is created or updated

00:31:36,399 --> 00:31:40,880
uh this fast sequel service it um

00:31:39,360 --> 00:31:42,159
figures out like what are the inputs and

00:31:40,880 --> 00:31:42,960
outputs that are there in the sql

00:31:42,159 --> 00:31:45,279
statement

00:31:42,960 --> 00:31:46,240
and it automatically uh generates the

00:31:45,279 --> 00:31:48,159
dashboards

00:31:46,240 --> 00:31:50,080
and it also automatically uh sets up the

00:31:48,159 --> 00:31:51,760
alerts

00:31:50,080 --> 00:31:54,799
so it also provides backfill capability

00:31:51,760 --> 00:31:57,760
i'll talk more about it in the learnings

00:31:54,799 --> 00:31:59,600
so autoscale controller and yarn cluster

00:31:57,760 --> 00:32:01,519
outer scale controller it does like

00:31:59,600 --> 00:32:03,760
scale up scale out and scale down based

00:32:01,519 --> 00:32:06,240
on a few heuristics

00:32:03,760 --> 00:32:07,679
um so basically on the input qps and

00:32:06,240 --> 00:32:09,600
processing lag

00:32:07,679 --> 00:32:11,279
and also it is since we support like

00:32:09,600 --> 00:32:13,919
remote store

00:32:11,279 --> 00:32:15,279
accesses so it sure it is aware of like

00:32:13,919 --> 00:32:18,880
remote store read write

00:32:15,279 --> 00:32:20,799
quotas as well um

00:32:18,880 --> 00:32:22,640
now uh which you already mentioned about

00:32:20,799 --> 00:32:24,480
young cluster it provides like a

00:32:22,640 --> 00:32:25,600
multi-tenancy and it's fully managed by

00:32:24,480 --> 00:32:28,240
sensor team

00:32:25,600 --> 00:32:30,799
uh it gives like a failure handling out

00:32:28,240 --> 00:32:30,799
of the box

00:32:31,919 --> 00:32:37,279
now let me go through the learnings

00:32:35,519 --> 00:32:39,120
so uh we've been running like sensor

00:32:37,279 --> 00:32:41,200
apps java the apps for like almost like

00:32:39,120 --> 00:32:43,840
seven years and manage samsung apps

00:32:41,200 --> 00:32:44,960
with sql direct dialect for uh over two

00:32:43,840 --> 00:32:48,559
years now

00:32:44,960 --> 00:32:51,760
um so uh we have quite a bit of like uh

00:32:48,559 --> 00:32:54,559
learnings from there um

00:32:51,760 --> 00:32:56,480
uh i will uh mention like one of the

00:32:54,559 --> 00:32:58,799
some of the salient ones

00:32:56,480 --> 00:33:00,799
um so we have like thousands of samsung

00:32:58,799 --> 00:33:03,200
apps processing millions of like uh

00:33:00,799 --> 00:33:04,720
messages per second and hundreds of gigs

00:33:03,200 --> 00:33:07,840
of data per second like 15

00:33:04,720 --> 00:33:10,640
of them are minus samsung apps uh now

00:33:07,840 --> 00:33:12,640
our target is to reach 80 to 90 percent

00:33:10,640 --> 00:33:14,960
of like the new samsa apps to be

00:33:12,640 --> 00:33:17,279
managed once uh in the next couple of

00:33:14,960 --> 00:33:17,279
years

00:33:17,360 --> 00:33:21,420
so um

00:33:18,330 --> 00:33:21,420
[Music]

00:33:21,679 --> 00:33:25,440
learnings wise uh with respect to

00:33:23,840 --> 00:33:26,000
authoring they're like a lot of them

00:33:25,440 --> 00:33:29,440
like

00:33:26,000 --> 00:33:32,159
but this is the most important one um

00:33:29,440 --> 00:33:33,840
a rich validator it goes a long way in

00:33:32,159 --> 00:33:36,080
reducing alcohol load

00:33:33,840 --> 00:33:38,320
so we want to ideally catch user errors

00:33:36,080 --> 00:33:40,320
uh during ordering phase itself

00:33:38,320 --> 00:33:41,760
where we can give like good legible

00:33:40,320 --> 00:33:43,679
feedback to the user

00:33:41,760 --> 00:33:45,200
rather than throwing an obscure

00:33:43,679 --> 00:33:48,320
exception at runtime

00:33:45,200 --> 00:33:49,039
so for example with cdc data it is very

00:33:48,320 --> 00:33:53,519
easy for

00:33:49,039 --> 00:33:55,840
users to not account for delete of types

00:33:53,519 --> 00:33:56,880
which result in issues ranging from mps

00:33:55,840 --> 00:33:59,039
to

00:33:56,880 --> 00:34:00,960
data inconsistencies in production it'll

00:33:59,039 --> 00:34:06,000
be extremely hard to debug

00:34:00,960 --> 00:34:09,760
at that time so rich validator is

00:34:06,000 --> 00:34:10,720
very important and with respect to user

00:34:09,760 --> 00:34:14,320
ordered

00:34:10,720 --> 00:34:15,839
udfs so since we have like smart

00:34:14,320 --> 00:34:18,560
alerting and everything like if users

00:34:15,839 --> 00:34:21,119
write their own udfs

00:34:18,560 --> 00:34:22,560
if there is any issue in uh their duty

00:34:21,119 --> 00:34:26,399
of like the alerts go

00:34:22,560 --> 00:34:28,480
to them so um our users like want to

00:34:26,399 --> 00:34:29,760
avoid writing custom udfs for the same

00:34:28,480 --> 00:34:33,440
reason they don't want to like

00:34:29,760 --> 00:34:36,800
manage it partially manage it so um

00:34:33,440 --> 00:34:39,200
as much as possible uh uh we should

00:34:36,800 --> 00:34:40,560
provide the framework udfs like that are

00:34:39,200 --> 00:34:43,280
generic enough

00:34:40,560 --> 00:34:44,000
um that's one learning and the second

00:34:43,280 --> 00:34:45,599
one is

00:34:44,000 --> 00:34:48,000
it's not always easy to automatically

00:34:45,599 --> 00:34:51,760
determine where to route the apps

00:34:48,000 --> 00:34:54,639
if the job runs into any issues

00:34:51,760 --> 00:34:54,639
it's a hard problem

00:34:55,760 --> 00:34:59,200
and with respect to deploying newly

00:34:58,000 --> 00:35:02,320
created i updated like

00:34:59,200 --> 00:35:04,640
manage samsung apps to production um we

00:35:02,320 --> 00:35:07,760
need to provide

00:35:04,640 --> 00:35:10,960
a staging environment

00:35:07,760 --> 00:35:12,560
for samsung apps to be wetted before

00:35:10,960 --> 00:35:15,359
promoting it to production

00:35:12,560 --> 00:35:17,520
so when it gets promoted to production

00:35:15,359 --> 00:35:18,160
it's a samsara team that is responsible

00:35:17,520 --> 00:35:20,160
for

00:35:18,160 --> 00:35:21,599
managing the job so we want to wait it

00:35:20,160 --> 00:35:24,720
like properly before it

00:35:21,599 --> 00:35:25,599
lands in the production so um so we want

00:35:24,720 --> 00:35:28,720
to have that

00:35:25,599 --> 00:35:31,040
staging layer and now uh but another

00:35:28,720 --> 00:35:34,480
problem is like waiting the app

00:35:31,040 --> 00:35:37,200
before pushing it to prod is a

00:35:34,480 --> 00:35:38,800
uh it's a challenge uh considering that

00:35:37,200 --> 00:35:40,160
it is a function of the diversity of the

00:35:38,800 --> 00:35:42,240
input data

00:35:40,160 --> 00:35:43,599
and the sql operations that are actually

00:35:42,240 --> 00:35:47,200
done

00:35:43,599 --> 00:35:48,560
in the sql statement so that this is

00:35:47,200 --> 00:35:51,839
something that we are

00:35:48,560 --> 00:35:55,200
trying to solve as much as we can

00:35:51,839 --> 00:35:56,480
and schema evolution um so minus sensor

00:35:55,200 --> 00:35:58,720
is like fire and forget

00:35:56,480 --> 00:36:00,079
people write like sql statement and

00:35:58,720 --> 00:36:02,320
unless their business logic

00:36:00,079 --> 00:36:03,760
change they don't want to like revisit

00:36:02,320 --> 00:36:07,440
that again

00:36:03,760 --> 00:36:08,800
but the input uh the resources that

00:36:07,440 --> 00:36:10,640
they're accessing

00:36:08,800 --> 00:36:13,040
the schema for that might change any

00:36:10,640 --> 00:36:16,800
time so

00:36:13,040 --> 00:36:19,839
it'll be great if the managed

00:36:16,800 --> 00:36:23,040
samsa automatically handles that

00:36:19,839 --> 00:36:24,560
schema evolution we have done it like

00:36:23,040 --> 00:36:26,240
for a few cases

00:36:24,560 --> 00:36:27,680
but we are trying to cover all the other

00:36:26,240 --> 00:36:32,000
cases as well

00:36:27,680 --> 00:36:35,599
um and with respect to operational

00:36:32,000 --> 00:36:37,200
enhancements um upgrading

00:36:35,599 --> 00:36:38,880
so samsung team is responsible for like

00:36:37,200 --> 00:36:41,920
upgrading framework libraries and

00:36:38,880 --> 00:36:44,320
conflicts but

00:36:41,920 --> 00:36:46,240
upgrading the framework uh libraries

00:36:44,320 --> 00:36:48,560
without app or user knowledge

00:36:46,240 --> 00:36:49,440
it's a very hard problem so we need to

00:36:48,560 --> 00:36:52,320
have like a

00:36:49,440 --> 00:36:54,560
very robust validations after upgrading

00:36:52,320 --> 00:36:56,160
all the apps

00:36:54,560 --> 00:36:58,400
of different varieties like they will

00:36:56,160 --> 00:37:01,040
have like different use cases

00:36:58,400 --> 00:37:02,240
and if something fails if any of these

00:37:01,040 --> 00:37:05,760
validations fail

00:37:02,240 --> 00:37:07,040
then we need to have a reliable rollback

00:37:05,760 --> 00:37:09,359
so this is something that we are

00:37:07,040 --> 00:37:12,320
actually uh

00:37:09,359 --> 00:37:13,680
working on currently with respect to

00:37:12,320 --> 00:37:16,560
backfills

00:37:13,680 --> 00:37:17,760
we use lambda so we have like uh two

00:37:16,560 --> 00:37:20,640
different apis for

00:37:17,760 --> 00:37:23,359
uh batch and stream processing uh we are

00:37:20,640 --> 00:37:26,079
in the process of unifying those apis

00:37:23,359 --> 00:37:27,280
uh but there is a problem with lambda

00:37:26,079 --> 00:37:28,320
there is like an operational and

00:37:27,280 --> 00:37:31,920
manageability

00:37:28,320 --> 00:37:33,760
challenge because um

00:37:31,920 --> 00:37:35,440
the bad jobs they run in a different

00:37:33,760 --> 00:37:39,280
execution environment than the

00:37:35,440 --> 00:37:42,400
stealing jobs so uh for stateless

00:37:39,280 --> 00:37:46,320
processing of change capture data

00:37:42,400 --> 00:37:48,160
we follow kappa architecture where

00:37:46,320 --> 00:37:50,320
uh the bad jobs also run in like

00:37:48,160 --> 00:37:52,640
streaming layer

00:37:50,320 --> 00:37:53,599
so uh we're also working towards like uh

00:37:52,640 --> 00:37:56,960
on demand

00:37:53,599 --> 00:37:59,359
uh uh backfill without any heat to

00:37:56,960 --> 00:38:00,960
data availability by having like

00:37:59,359 --> 00:38:02,800
parallel reprocessing uh in the

00:38:00,960 --> 00:38:06,079
background having different versions

00:38:02,800 --> 00:38:07,119
and all that stuff the next one is like

00:38:06,079 --> 00:38:10,160
a

00:38:07,119 --> 00:38:13,760
auto scale auto scale

00:38:10,160 --> 00:38:16,800
is a must have for

00:38:13,760 --> 00:38:19,280
a hosted sql solution

00:38:16,800 --> 00:38:21,119
otherwise the load keeps changing there

00:38:19,280 --> 00:38:23,359
like a lot of variables over there

00:38:21,119 --> 00:38:25,839
it's tough to configure the jobs so we

00:38:23,359 --> 00:38:29,520
need to have a robust like auto scale

00:38:25,839 --> 00:38:31,200
now um it has worked like with few

00:38:29,520 --> 00:38:33,119
heuristics that we have like pretty well

00:38:31,200 --> 00:38:35,200
for most of the cases

00:38:33,119 --> 00:38:37,280
but for some like really like complex

00:38:35,200 --> 00:38:38,880
cases where we have like joints

00:38:37,280 --> 00:38:40,720
we are inserting into like several

00:38:38,880 --> 00:38:44,000
different like stores

00:38:40,720 --> 00:38:46,960
uh we uh

00:38:44,000 --> 00:38:48,640
there we require like some ml models to

00:38:46,960 --> 00:38:49,599
actually make this such uh scaling

00:38:48,640 --> 00:38:51,359
decisions

00:38:49,599 --> 00:38:53,119
uh we are working on that actively right

00:38:51,359 --> 00:38:55,760
now and

00:38:53,119 --> 00:38:57,520
with respect to cost optimizations we

00:38:55,760 --> 00:38:58,880
have quite a few sql jobs

00:38:57,520 --> 00:39:01,200
working on the same set of data and

00:38:58,880 --> 00:39:01,760
publishing the same set of like derived

00:39:01,200 --> 00:39:04,640
data set

00:39:01,760 --> 00:39:05,920
which could have been like easily reused

00:39:04,640 --> 00:39:07,599
across different apps

00:39:05,920 --> 00:39:08,960
so uh we are working towards like a

00:39:07,599 --> 00:39:12,320
building

00:39:08,960 --> 00:39:14,880
a metadata layer making such data sets

00:39:12,320 --> 00:39:16,640
like easily discoverable

00:39:14,880 --> 00:39:18,800
and there is another case like typically

00:39:16,640 --> 00:39:21,520
like streaming jobs or long-running jobs

00:39:18,800 --> 00:39:21,920
but they're like jobs that like people

00:39:21,520 --> 00:39:24,880
uh

00:39:21,920 --> 00:39:27,680
stop like after like couple of years

00:39:24,880 --> 00:39:29,040
because uh they found like uh

00:39:27,680 --> 00:39:31,359
app they have created another app

00:39:29,040 --> 00:39:35,520
advanced app advanced algorithm

00:39:31,359 --> 00:39:40,160
so um we need to detect and delete such

00:39:35,520 --> 00:39:40,160
unused jobs and release such resources

00:39:40,880 --> 00:39:44,000
and insights and analytics like we are

00:39:43,280 --> 00:39:46,560
using

00:39:44,000 --> 00:39:48,160
insights and analytics to get a view of

00:39:46,560 --> 00:39:50,960
the overall status of the

00:39:48,160 --> 00:39:52,720
apps and resources and get the resource

00:39:50,960 --> 00:39:57,760
usage and everything

00:39:52,720 --> 00:40:00,720
um so this is like work in progress

00:39:57,760 --> 00:40:00,720
yep that's all i have

00:40:07,280 --> 00:40:10,720
i think we ran out of time i'm not sure

00:40:09,520 --> 00:40:14,160
like

00:40:10,720 --> 00:40:25,839
if people have any questions yeah cool

00:40:14,160 --> 00:40:25,839
thank you thank you

00:40:33,680 --> 00:40:35,760

YouTube URL: https://www.youtube.com/watch?v=VAFJ-JkobAw


