Title: Concurrent Search In Lucene
Publication date: 2020-10-17
Playlist: ApacheCon @Home 2020: Search
Description: 
	Concurrent Search In Lucene
Atri Sharma

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Concurrent search is not a new feature in Lucene but has been unexplored. This talk will talk about the basics, benefits, when to use and when not to use and recent improvements in this area. Concurrent search can provide a massive gain for analytical queries, which are becoming more and more popular as data volumes grow. Single threaded queries do not take the complete advantage of available CPU resources -- something that concurrent query fixes. This talk will take audience through a complete know-hows and integrating with existing search platforms built using Lucene.

Database and search guy. Apache Lucene and Apache Solr committer. Major contributor to PostgreSQL.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:24,480 --> 00:00:29,599
hello everyone

00:00:25,840 --> 00:00:32,079
uh welcome to apachecon at home 2020

00:00:29,599 --> 00:00:33,120
in this first session track today we

00:00:32,079 --> 00:00:35,680
have uh

00:00:33,120 --> 00:00:37,840
sharma he's an apache lucien committer

00:00:35,680 --> 00:00:40,879
and a pmc member

00:00:37,840 --> 00:00:42,879
and a major contributor to postgres

00:00:40,879 --> 00:00:44,800
today aatri will be talking about

00:00:42,879 --> 00:00:47,760
concurrent search and lucine

00:00:44,800 --> 00:00:48,640
a rather unexplored topic and sharing

00:00:47,760 --> 00:00:50,079
with you how to

00:00:48,640 --> 00:00:51,760
integrate that with existing

00:00:50,079 --> 00:00:54,160
leucine-based search engines

00:00:51,760 --> 00:00:55,520
uh hope you enjoy the session over to

00:00:54,160 --> 00:00:56,800
your three

00:00:55,520 --> 00:00:58,800
thank you anshum for the great

00:00:56,800 --> 00:01:02,160
introduction uh hey everybody

00:00:58,800 --> 00:01:03,120
uh r3 uh that's pronounced r3 not a3 for

00:01:02,160 --> 00:01:06,159
many

00:01:03,120 --> 00:01:08,000
of my colleagues and uh you know i'm

00:01:06,159 --> 00:01:11,040
talking about concrete search and lucien

00:01:08,000 --> 00:01:14,080
it's not a very long presentation but

00:01:11,040 --> 00:01:17,920
i hope you guys can see my screen and

00:01:14,080 --> 00:01:21,200
uh yeah let's get started

00:01:17,920 --> 00:01:24,479
so yeah uh okay before i start

00:01:21,200 --> 00:01:24,479
i'm hoping the screen is visible

00:01:24,560 --> 00:01:29,520
yes i just rejoined to tell you your

00:01:26,479 --> 00:01:29,520
screen's not shared

00:01:30,000 --> 00:01:33,439
uh mystery is not shared okay i'll try

00:01:31,680 --> 00:01:36,880
to do that yeah

00:01:33,439 --> 00:01:39,680
oh can you see it now uh

00:01:36,880 --> 00:01:40,560
no okay give me one second let me figure

00:01:39,680 --> 00:01:42,960
out what's

00:01:40,560 --> 00:01:42,960
wrong

00:01:45,520 --> 00:01:50,720
back in no i think i

00:01:48,880 --> 00:01:51,920
saw a button somewhere which allows you

00:01:50,720 --> 00:01:53,840
to it's

00:01:51,920 --> 00:01:54,960
it's right at the bottom next to the

00:01:53,840 --> 00:01:58,079
microphone in the

00:01:54,960 --> 00:02:01,439
video ah okay i see it

00:01:58,079 --> 00:02:04,079
yeah sure yep uh

00:02:01,439 --> 00:02:04,479
i'm okay now right get out of here now

00:02:04,079 --> 00:02:07,680
yes

00:02:04,479 --> 00:02:09,280
leave it okay all good great yeah thank

00:02:07,680 --> 00:02:12,560
you

00:02:09,280 --> 00:02:15,760
awesome so yeah i don't know what's

00:02:12,560 --> 00:02:17,520
going on but yeah uh guys so hopefully

00:02:15,760 --> 00:02:20,000
you can see in the screen and

00:02:17,520 --> 00:02:21,280
i'm at three i work at a company called

00:02:20,000 --> 00:02:24,000
synchronics where we

00:02:21,280 --> 00:02:26,560
actually do threat hunting analytics and

00:02:24,000 --> 00:02:28,800
you know we are a major user of solar

00:02:26,560 --> 00:02:29,599
i'm a listening solar pmc member as i

00:02:28,800 --> 00:02:31,760
was highlighted

00:02:29,599 --> 00:02:32,959
and i'm also a hawking partner png

00:02:31,760 --> 00:02:34,879
member with in my

00:02:32,959 --> 00:02:37,280
previous slides which were actually

00:02:34,879 --> 00:02:39,760
derived from my work on postgres

00:02:37,280 --> 00:02:40,400
and yeah i have contributed to postgres

00:02:39,760 --> 00:02:42,000
in the past

00:02:40,400 --> 00:02:43,440
and one of the things that i have

00:02:42,000 --> 00:02:45,920
carried over is basically

00:02:43,440 --> 00:02:47,680
the power of statistical processing that

00:02:45,920 --> 00:02:48,160
databases do i'm trying to bring some of

00:02:47,680 --> 00:02:51,760
that

00:02:48,160 --> 00:02:53,760
into the world of search uh today we

00:02:51,760 --> 00:02:56,720
will be basically talking about

00:02:53,760 --> 00:02:57,680
concurrent search and i'll be going at

00:02:56,720 --> 00:02:59,840
very basics

00:02:57,680 --> 00:03:01,200
uh you know as to how what exactly are

00:02:59,840 --> 00:03:03,040
we talking about

00:03:01,200 --> 00:03:04,800
when to use it when not to use it

00:03:03,040 --> 00:03:05,200
looking at some interfaces and classes

00:03:04,800 --> 00:03:07,680
that

00:03:05,200 --> 00:03:08,959
basically make this entire thing work uh

00:03:07,680 --> 00:03:10,879
one of the pros and cons

00:03:08,959 --> 00:03:12,080
and what is the future work that's

00:03:10,879 --> 00:03:14,319
planned around it or

00:03:12,080 --> 00:03:15,680
so things that we're already in progress

00:03:14,319 --> 00:03:17,760
or you know

00:03:15,680 --> 00:03:19,599
things that we really want to achieve in

00:03:17,760 --> 00:03:21,280
that area right

00:03:19,599 --> 00:03:22,959
uh so some of this stuff might be very

00:03:21,280 --> 00:03:24,159
basic please bear with me and i'm

00:03:22,959 --> 00:03:27,200
trying to make sure that we get a

00:03:24,159 --> 00:03:28,959
comprehensive treatment to the subject

00:03:27,200 --> 00:03:30,959
uh so a quick refresher as you can see

00:03:28,959 --> 00:03:32,239
on the screen i've drawn a very rough

00:03:30,959 --> 00:03:34,400
diagram of what

00:03:32,239 --> 00:03:36,319
a typical leucine index looks like uh

00:03:34,400 --> 00:03:38,000
leucine indexes are comprised of

00:03:36,319 --> 00:03:40,400
segments which are meaningless in

00:03:38,000 --> 00:03:41,680
themselves and if you look you know if

00:03:40,400 --> 00:03:43,599
you open the hood of a lucian index

00:03:41,680 --> 00:03:45,760
you'll see multiple directories there

00:03:43,599 --> 00:03:46,640
of a specific segment id and stuff which

00:03:45,760 --> 00:03:50,799
is basically

00:03:46,640 --> 00:03:53,360
a segment right uh now a typical search

00:03:50,799 --> 00:03:55,040
uh basically operates in a process where

00:03:53,360 --> 00:03:56,400
you open index searcher right i'm not

00:03:55,040 --> 00:03:58,080
talking about content search a

00:03:56,400 --> 00:04:00,080
normal single thread search on a single

00:03:58,080 --> 00:04:01,280
node we fire a query you know there's an

00:04:00,080 --> 00:04:03,040
index searcher it'll go

00:04:01,280 --> 00:04:04,879
leave context by leave context basically

00:04:03,040 --> 00:04:06,720
it's going segment by segment it will

00:04:04,879 --> 00:04:08,720
it has a global priority queue of top

00:04:06,720 --> 00:04:12,000
hits and it will go segment one

00:04:08,720 --> 00:04:12,560
then you know segment two and then it

00:04:12,000 --> 00:04:16,079
will go

00:04:12,560 --> 00:04:17,040
you know segment three and then at the

00:04:16,079 --> 00:04:18,799
end you know it

00:04:17,040 --> 00:04:20,720
it has a global priority queue so it's

00:04:18,799 --> 00:04:21,680
basically just accumulating here it's

00:04:20,720 --> 00:04:24,080
filtering them out

00:04:21,680 --> 00:04:25,600
it knows what hits i've looked at if you

00:04:24,080 --> 00:04:27,280
ask for top 10 hits you'll get the

00:04:25,600 --> 00:04:29,280
global top 10 hits right

00:04:27,280 --> 00:04:32,160
that's it i mean end of story there's

00:04:29,280 --> 00:04:34,720
nothing more or less that happens today

00:04:32,160 --> 00:04:36,960
uh the typical problem here is that

00:04:34,720 --> 00:04:37,520
another problem i know one optimization

00:04:36,960 --> 00:04:39,040
that is

00:04:37,520 --> 00:04:41,440
very obvious here is you know if we

00:04:39,040 --> 00:04:44,880
could actually spawn

00:04:41,440 --> 00:04:46,240
multiple threads um across all of

00:04:44,880 --> 00:04:48,240
these segments or at least some of these

00:04:46,240 --> 00:04:50,400
segments

00:04:48,240 --> 00:04:51,440
take their own you know best hits and

00:04:50,400 --> 00:04:53,520
then do

00:04:51,440 --> 00:04:55,040
another step on top where we only look

00:04:53,520 --> 00:04:56,639
at the best hits from all of these

00:04:55,040 --> 00:04:57,919
threads and then identify okay these are

00:04:56,639 --> 00:05:00,720
the ones which are the actual

00:04:57,919 --> 00:05:01,440
global maxima and return results back

00:05:00,720 --> 00:05:02,880
right

00:05:01,440 --> 00:05:05,360
uh that is something that would

00:05:02,880 --> 00:05:06,639
typically uh speed up the entire process

00:05:05,360 --> 00:05:08,080
especially if you have a very large

00:05:06,639 --> 00:05:08,479
number of segments and you know you have

00:05:08,080 --> 00:05:10,720
to

00:05:08,479 --> 00:05:12,240
go sequentially across all of them that

00:05:10,720 --> 00:05:13,199
your query might take a significant

00:05:12,240 --> 00:05:15,520
amount of time

00:05:13,199 --> 00:05:18,160
so that is the entire concept of

00:05:15,520 --> 00:05:20,720
leucine's confidence search right

00:05:18,160 --> 00:05:22,000
so you know yeah i've already given you

00:05:20,720 --> 00:05:23,520
this idea

00:05:22,000 --> 00:05:26,240
basically it's just this right so you

00:05:23,520 --> 00:05:28,000
basically fire for a given query

00:05:26,240 --> 00:05:29,840
you fire multiple number of threads so

00:05:28,000 --> 00:05:32,080
you schedule multiple number of threads

00:05:29,840 --> 00:05:33,680
each of those threads has a set of

00:05:32,080 --> 00:05:35,039
segments we'll get to that part in a bit

00:05:33,680 --> 00:05:36,720
but each of those threads

00:05:35,039 --> 00:05:38,720
you know in this example you can imagine

00:05:36,720 --> 00:05:40,320
that it has one segment each and

00:05:38,720 --> 00:05:42,000
you know one thread goes to that segment

00:05:40,320 --> 00:05:42,880
collects okay i want the top ten hits

00:05:42,000 --> 00:05:45,280
i'm going to

00:05:42,880 --> 00:05:46,240
perform a regular search as i would too

00:05:45,280 --> 00:05:48,080
and then thread two

00:05:46,240 --> 00:05:49,520
does the same on segment two thread

00:05:48,080 --> 00:05:51,120
through seven segment three

00:05:49,520 --> 00:05:52,960
eventually these guys bring in all of

00:05:51,120 --> 00:05:54,639
their top hits and then there's another

00:05:52,960 --> 00:05:56,479
step which you call reduced step

00:05:54,639 --> 00:05:58,800
uh that is performed and then we look at

00:05:56,479 --> 00:05:59,600
all the 30 top hits identify the best 10

00:05:58,800 --> 00:06:02,800
out of them

00:05:59,600 --> 00:06:05,840
and that becomes my final concept right

00:06:02,800 --> 00:06:06,800
uh so that is at a very high level how

00:06:05,840 --> 00:06:10,000
concurrent search

00:06:06,800 --> 00:06:10,000
works within lucy

00:06:10,080 --> 00:06:13,440
uh you know yeah again just a

00:06:12,000 --> 00:06:15,039
summarization of what i said you know

00:06:13,440 --> 00:06:16,160
you distribute search to all the slices

00:06:15,039 --> 00:06:19,120
what a slice is something that

00:06:16,160 --> 00:06:21,039
we'll come to uh so slices you know each

00:06:19,120 --> 00:06:22,800
habit has its own collector

00:06:21,039 --> 00:06:24,720
uh that collector builds own priority

00:06:22,800 --> 00:06:25,280
queue just by looking at the subset of

00:06:24,720 --> 00:06:26,639
segments

00:06:25,280 --> 00:06:28,639
in this case one segment that was a

00:06:26,639 --> 00:06:31,440
logging you know elevator two

00:06:28,639 --> 00:06:32,880
uh then eventually all the once all the

00:06:31,440 --> 00:06:34,720
characters are finished will cut back

00:06:32,880 --> 00:06:36,880
you'll merge all the priority queues

00:06:34,720 --> 00:06:39,280
using a partial merge sort and identify

00:06:36,880 --> 00:06:42,400
the test right

00:06:39,280 --> 00:06:44,319
uh again a diagonal representation of

00:06:42,400 --> 00:06:46,560
how it looks like with some specific

00:06:44,319 --> 00:06:48,960
details of classes so you'll see some

00:06:46,560 --> 00:06:50,160
new terms such as collective manager and

00:06:48,960 --> 00:06:51,919
slice right so

00:06:50,160 --> 00:06:53,280
basically a collect there's a new class

00:06:51,919 --> 00:06:54,720
or the interface called

00:06:53,280 --> 00:06:56,319
collector manager which is like a

00:06:54,720 --> 00:06:58,800
collector of collectors

00:06:56,319 --> 00:07:00,319
i just introduced specifically for this

00:06:58,800 --> 00:07:02,800
uh conference such operation

00:07:00,319 --> 00:07:04,479
the collective manager does uh typical

00:07:02,800 --> 00:07:05,759
steps such as scattergather right so if

00:07:04,479 --> 00:07:07,360
you're familiar with paradigms like

00:07:05,759 --> 00:07:08,639
mapreduce you know exactly what i'm

00:07:07,360 --> 00:07:11,280
talking about where

00:07:08,639 --> 00:07:13,039
you basically uh send out an operation

00:07:11,280 --> 00:07:15,199
to a bunch of threads each of those

00:07:13,039 --> 00:07:17,599
threads perform that operation locally

00:07:15,199 --> 00:07:19,360
and then you know build a partial result

00:07:17,599 --> 00:07:20,720
set so if you see the diagram that is

00:07:19,360 --> 00:07:22,240
projected on the screen

00:07:20,720 --> 00:07:23,759
uh you know there's a collective first

00:07:22,240 --> 00:07:24,720
slice and each of it has its own

00:07:23,759 --> 00:07:26,720
priority key

00:07:24,720 --> 00:07:28,160
and then all of those go back to the

00:07:26,720 --> 00:07:29,440
collector manager a character manager

00:07:28,160 --> 00:07:31,680
has a merge step

00:07:29,440 --> 00:07:33,759
which we technically call reduce now

00:07:31,680 --> 00:07:35,919
reduction does what we talked about

00:07:33,759 --> 00:07:37,520
filters out uh the best from all of

00:07:35,919 --> 00:07:39,680
those different priority queues

00:07:37,520 --> 00:07:41,120
gives back the final result so the user

00:07:39,680 --> 00:07:44,000
experience rate doesn't change you know

00:07:41,120 --> 00:07:45,599
what you expect back from your lucid api

00:07:44,000 --> 00:07:47,360
or you know what for example if you're

00:07:45,599 --> 00:07:48,319
looking at top docs you probably you

00:07:47,360 --> 00:07:50,879
know you'll get back

00:07:48,319 --> 00:07:52,479
the exact same results and one of the

00:07:50,879 --> 00:07:54,639
ingredients here of course is that

00:07:52,479 --> 00:07:57,039
the semantics don't change right so for

00:07:54,639 --> 00:07:58,160
the exact same data set and exact same

00:07:57,039 --> 00:07:59,840
query uh

00:07:58,160 --> 00:08:01,520
you'll get the exact the exact same

00:07:59,840 --> 00:08:03,039
results that you would do if you just

00:08:01,520 --> 00:08:04,479
run a sequential search versus the

00:08:03,039 --> 00:08:05,840
concurrence right there's no semantic

00:08:04,479 --> 00:08:07,599
difference between them

00:08:05,840 --> 00:08:09,039
except for how that query actually

00:08:07,599 --> 00:08:11,840
internally got processed

00:08:09,039 --> 00:08:13,919
so this is more of an internal detail or

00:08:11,840 --> 00:08:15,360
internal optimization as to how leucine

00:08:13,919 --> 00:08:17,520
is executing this query

00:08:15,360 --> 00:08:19,120
it is not necessarily applicable or

00:08:17,520 --> 00:08:22,240
visible to the end user

00:08:19,120 --> 00:08:24,240
uh you know from a perspective okay his

00:08:22,240 --> 00:08:24,720
cpu usage might go up and his queries

00:08:24,240 --> 00:08:26,720
will

00:08:24,720 --> 00:08:28,479
finish way faster but that's about it

00:08:26,720 --> 00:08:30,319
the interfaces the api is

00:08:28,479 --> 00:08:33,520
the way the user interacts with the

00:08:30,319 --> 00:08:33,520
system doesn't really change

00:08:35,680 --> 00:08:40,479
so now to get on to some terminologies

00:08:39,039 --> 00:08:41,519
that we have looked at till this point

00:08:40,479 --> 00:08:44,399
of time

00:08:41,519 --> 00:08:45,600
uh you know collector manager is

00:08:44,399 --> 00:08:47,839
basically a new

00:08:45,600 --> 00:08:49,680
class that we have introduced uh it's a

00:08:47,839 --> 00:08:50,399
very simple concept collector manager is

00:08:49,680 --> 00:08:52,959
just a

00:08:50,399 --> 00:08:53,680
collector of collectors right so it has

00:08:52,959 --> 00:08:56,640
uh

00:08:53,680 --> 00:08:57,360
two up it has two jobs one uh when it is

00:08:56,640 --> 00:08:59,279
asked for

00:08:57,360 --> 00:09:00,880
it will generate a new collector of a

00:08:59,279 --> 00:09:02,959
specific type so each collector matter

00:09:00,880 --> 00:09:04,720
is specialized for a specific character

00:09:02,959 --> 00:09:06,399
type that we're dealing with so when

00:09:04,720 --> 00:09:07,920
it's asked for it has a method which

00:09:06,399 --> 00:09:09,600
will create a new collector and they see

00:09:07,920 --> 00:09:10,560
registered somewhere or you know doesn't

00:09:09,600 --> 00:09:12,320
even need to register it

00:09:10,560 --> 00:09:14,160
just create a new collector of the given

00:09:12,320 --> 00:09:17,200
type and return it back

00:09:14,160 --> 00:09:19,760
uh then at the completion of

00:09:17,200 --> 00:09:21,120
all the collectors a specific method

00:09:19,760 --> 00:09:23,279
needs to be invoked on this collector

00:09:21,120 --> 00:09:24,399
manager giving it a collection of the

00:09:23,279 --> 00:09:26,080
collectors which have

00:09:24,399 --> 00:09:28,080
worked across all of the stress right so

00:09:26,080 --> 00:09:30,399
basically this is the gather step

00:09:28,080 --> 00:09:31,200
and then the collective manager has

00:09:30,399 --> 00:09:34,480
specific

00:09:31,200 --> 00:09:35,680
information as to how to reduce the uh

00:09:34,480 --> 00:09:37,760
information gathered from those

00:09:35,680 --> 00:09:39,839
characters into a set of final results

00:09:37,760 --> 00:09:40,959
so that you know so now beforehand in

00:09:39,839 --> 00:09:42,800
sequential search

00:09:40,959 --> 00:09:44,399
we typically have a collector which

00:09:42,800 --> 00:09:45,040
gives back the results and you know you

00:09:44,399 --> 00:09:46,560
can

00:09:45,040 --> 00:09:47,760
if you look at lucien's internals you

00:09:46,560 --> 00:09:49,040
basically are dealing with the collector

00:09:47,760 --> 00:09:51,040
and getting results back

00:09:49,040 --> 00:09:53,200
in this scenario collector manager is

00:09:51,040 --> 00:09:55,519
responsible for giving the results back

00:09:53,200 --> 00:09:56,320
uh this detail is still encapsulated

00:09:55,519 --> 00:09:58,080
somewhat

00:09:56,320 --> 00:09:59,519
closely with an index searcher so you

00:09:58,080 --> 00:10:02,399
know anybody outside

00:09:59,519 --> 00:10:03,600
that class isn't really concerned but uh

00:10:02,399 --> 00:10:04,480
i wanted to give you a more holistic

00:10:03,600 --> 00:10:06,399
view of how

00:10:04,480 --> 00:10:08,959
this you know this entire equation works

00:10:06,399 --> 00:10:12,560
especially uh for somebody who wants to

00:10:08,959 --> 00:10:14,320
uh you know use this entire mechanism to

00:10:12,560 --> 00:10:16,320
paralyze their own collector types right

00:10:14,320 --> 00:10:17,120
because uh the power of concurrent

00:10:16,320 --> 00:10:18,880
search is

00:10:17,120 --> 00:10:20,399
pretty much limited to the collector

00:10:18,880 --> 00:10:21,760
types that have their own creative

00:10:20,399 --> 00:10:24,399
managers right

00:10:21,760 --> 00:10:25,839
so if you have your own custom collector

00:10:24,399 --> 00:10:27,920
that you want to deal with

00:10:25,839 --> 00:10:28,880
uh or you want to just paralyze you will

00:10:27,920 --> 00:10:31,360
have to

00:10:28,880 --> 00:10:32,160
you know implement this paradigm and

00:10:31,360 --> 00:10:33,680
write specific

00:10:32,160 --> 00:10:35,519
this spectrum is basically interface

00:10:33,680 --> 00:10:37,040
right so you have to write that specific

00:10:35,519 --> 00:10:40,480
paradigm making sure that

00:10:37,040 --> 00:10:42,320
uh you know how to scatter and gather uh

00:10:40,480 --> 00:10:43,920
results between different collectors of

00:10:42,320 --> 00:10:45,440
your own type and as long as

00:10:43,920 --> 00:10:47,200
you do that you can actually plug that

00:10:45,440 --> 00:10:49,279
right into the scene and it'll take care

00:10:47,200 --> 00:10:52,000
of all the other aspects of concurrent

00:10:49,279 --> 00:10:52,000
searching for you

00:10:54,160 --> 00:10:58,079
ah so now coming to our slice right we

00:10:56,640 --> 00:11:00,320
have talked about slice for a while what

00:10:58,079 --> 00:11:02,880
exactly is a slice

00:11:00,320 --> 00:11:03,839
so in its most granular form or in this

00:11:02,880 --> 00:11:05,920
most

00:11:03,839 --> 00:11:08,320
unoptimized form a slice is just a

00:11:05,920 --> 00:11:11,440
single segment

00:11:08,320 --> 00:11:13,839
dice is the set of segments that will be

00:11:11,440 --> 00:11:14,880
processed by a single thread during a

00:11:13,839 --> 00:11:18,240
concurrent search

00:11:14,880 --> 00:11:20,399
right uh so in

00:11:18,240 --> 00:11:21,360
as i said in a very an unoptimized form

00:11:20,399 --> 00:11:23,200
you'd be defining

00:11:21,360 --> 00:11:24,800
a thread per segment that you're looking

00:11:23,200 --> 00:11:26,800
at again that would be

00:11:24,800 --> 00:11:28,000
very expensive that would not be worth

00:11:26,800 --> 00:11:30,640
it because there is a

00:11:28,000 --> 00:11:32,240
segment size q and doesn't really make

00:11:30,640 --> 00:11:33,760
sense maybe some segments may be really

00:11:32,240 --> 00:11:34,320
awesome might be really small and then

00:11:33,760 --> 00:11:36,000
you are

00:11:34,320 --> 00:11:38,160
treating them equally so you know you're

00:11:36,000 --> 00:11:40,959
not setting yourself up for success

00:11:38,160 --> 00:11:42,800
uh that's why we have something in

00:11:40,959 --> 00:11:43,760
researcher which basically looks at the

00:11:42,800 --> 00:11:46,000
slice sizes

00:11:43,760 --> 00:11:47,200
and tries to you know distribute them in

00:11:46,000 --> 00:11:50,880
a greedy algorithm

00:11:47,200 --> 00:11:52,880
to keep the median size uh of all these

00:11:50,880 --> 00:11:55,360
um you know threads or the median load

00:11:52,880 --> 00:11:57,040
on each thread more or less the same

00:11:55,360 --> 00:11:59,680
so typically what happened that if you

00:11:57,040 --> 00:12:02,000
have like one large segment and

00:11:59,680 --> 00:12:03,600
three small segments uh there are high

00:12:02,000 --> 00:12:05,200
chances that the three small segments

00:12:03,600 --> 00:12:06,800
will be allocated to one thread

00:12:05,200 --> 00:12:08,000
and one last segment will go to its own

00:12:06,800 --> 00:12:09,519
thread so you know there will be two

00:12:08,000 --> 00:12:10,880
response for a query and

00:12:09,519 --> 00:12:12,320
one will be handling only in that

00:12:10,880 --> 00:12:14,320
segment the other will be handling three

00:12:12,320 --> 00:12:15,839
small segments and we'll expect or we'll

00:12:14,320 --> 00:12:17,360
you know more or less will estimate that

00:12:15,839 --> 00:12:19,360
they'll finish in

00:12:17,360 --> 00:12:21,440
equal or comparative amount of time so

00:12:19,360 --> 00:12:22,959
that there's no single bottleneck into

00:12:21,440 --> 00:12:23,680
the entire question right because if one

00:12:22,959 --> 00:12:25,600
thread takes

00:12:23,680 --> 00:12:26,720
most you know much more time than the

00:12:25,600 --> 00:12:29,200
others then the

00:12:26,720 --> 00:12:30,800
entire point of actually parallelizing

00:12:29,200 --> 00:12:34,480
is defeated

00:12:30,800 --> 00:12:37,120
so uh the the slice allocation algorithm

00:12:34,480 --> 00:12:40,160
is there it was up recently optimized to

00:12:37,120 --> 00:12:42,399
basically look at you know sizes of

00:12:40,160 --> 00:12:43,360
the number of documents that a segment

00:12:42,399 --> 00:12:45,120
has and

00:12:43,360 --> 00:12:46,880
keep a cap on the number of segments

00:12:45,120 --> 00:12:48,399
that a single thread can handle

00:12:46,880 --> 00:12:50,320
you know there are some mathematical

00:12:48,399 --> 00:12:52,959
considerations with that

00:12:50,320 --> 00:12:54,639
uh so that's that's the entire concept

00:12:52,959 --> 00:12:55,120
of slice uh you can actually go and

00:12:54,639 --> 00:12:58,079
change

00:12:55,120 --> 00:12:59,680
the algorithm or the way sizes allocated

00:12:58,079 --> 00:13:01,279
with an index searcher

00:12:59,680 --> 00:13:02,639
uh although it's i don't think it's very

00:13:01,279 --> 00:13:03,279
pluggable but you know you can go and

00:13:02,639 --> 00:13:05,279
override the

00:13:03,279 --> 00:13:08,639
that method index searcher and make your

00:13:05,279 --> 00:13:08,639
own slice allocation algorithm

00:13:09,200 --> 00:13:12,240
ah this is something slightly

00:13:10,880 --> 00:13:12,959
interesting i'd like to take a moment

00:13:12,240 --> 00:13:16,000
about it

00:13:12,959 --> 00:13:18,480
so one of the biggest

00:13:16,000 --> 00:13:20,079
challenges when you know when that you

00:13:18,480 --> 00:13:22,480
face when you start paralyzing

00:13:20,079 --> 00:13:23,920
things is basically uh resource

00:13:22,480 --> 00:13:26,399
contention right

00:13:23,920 --> 00:13:27,920
so if you are for example if you have a

00:13:26,399 --> 00:13:29,680
bunch of queries and each of those

00:13:27,920 --> 00:13:30,560
queries starts firing in number of

00:13:29,680 --> 00:13:32,399
threads

00:13:30,560 --> 00:13:34,320
uh then it there are chances that you

00:13:32,399 --> 00:13:36,639
might actually end up just

00:13:34,320 --> 00:13:37,440
looking at too much of uh you know query

00:13:36,639 --> 00:13:39,839
contention or

00:13:37,440 --> 00:13:41,360
thread contention and you really don't

00:13:39,839 --> 00:13:42,720
leave any cpu headphone for any other

00:13:41,360 --> 00:13:43,920
process that wants to do something or

00:13:42,720 --> 00:13:46,560
maybe just for indexing

00:13:43,920 --> 00:13:48,639
right uh that contention might just grow

00:13:46,560 --> 00:13:50,560
and there might be uh noisy neighbor

00:13:48,639 --> 00:13:54,079
problems that start occurring

00:13:50,560 --> 00:13:55,600
so slice executor is a mechanism for

00:13:54,079 --> 00:13:57,680
controlling that behavior

00:13:55,600 --> 00:13:59,040
a first off it is not an implementation

00:13:57,680 --> 00:14:02,720
of java execute it just

00:13:59,040 --> 00:14:04,320
named uh you know they are monotonically

00:14:02,720 --> 00:14:05,199
named but they don't have relation with

00:14:04,320 --> 00:14:07,920
each other

00:14:05,199 --> 00:14:09,279
uh size executor is basically a way in

00:14:07,920 --> 00:14:12,720
which you can define

00:14:09,279 --> 00:14:14,240
uh how a query should be running its

00:14:12,720 --> 00:14:16,240
threads in real time so this is not a

00:14:14,240 --> 00:14:17,120
static thing it's actually done in real

00:14:16,240 --> 00:14:19,760
time right

00:14:17,120 --> 00:14:20,560
so uh for example you might actually say

00:14:19,760 --> 00:14:23,279
that hey

00:14:20,560 --> 00:14:23,760
at any you know at any point of time

00:14:23,279 --> 00:14:25,839
don't

00:14:23,760 --> 00:14:27,600
run more than n number of threads for a

00:14:25,839 --> 00:14:29,760
given query right

00:14:27,600 --> 00:14:30,880
now that is one way or maybe at any

00:14:29,760 --> 00:14:32,959
point of time

00:14:30,880 --> 00:14:34,000
uh i don't want my overall cpu users to

00:14:32,959 --> 00:14:36,399
go more than

00:14:34,000 --> 00:14:38,079
x percentage or the total number of

00:14:36,399 --> 00:14:38,880
threads that are fired across one

00:14:38,079 --> 00:14:41,360
executor

00:14:38,880 --> 00:14:42,639
should not know more be more than number

00:14:41,360 --> 00:14:45,760
of cores that i have

00:14:42,639 --> 00:14:47,279
any any real-time feedback or any

00:14:45,760 --> 00:14:49,279
real-time data that you would like to

00:14:47,279 --> 00:14:50,240
push into the actual execution of your

00:14:49,279 --> 00:14:52,079
query

00:14:50,240 --> 00:14:54,240
specifically around aligning how many

00:14:52,079 --> 00:14:56,959
threads single point of time

00:14:54,240 --> 00:14:58,560
right so the slice time would have

00:14:56,959 --> 00:14:59,360
happened earlier you know uh index

00:14:58,560 --> 00:15:02,720
watcher would have

00:14:59,360 --> 00:15:04,639
allocated slices for your segment

00:15:02,720 --> 00:15:06,399
said they're going to fight for a query

00:15:04,639 --> 00:15:09,199
but during the actual execution

00:15:06,399 --> 00:15:10,079
you can actually look at system six and

00:15:09,199 --> 00:15:12,000
feed them back

00:15:10,079 --> 00:15:13,199
into search and say okay now you know

00:15:12,000 --> 00:15:15,440
system is too

00:15:13,199 --> 00:15:16,880
loaded don't execute more than three

00:15:15,440 --> 00:15:19,760
threads at the time so then

00:15:16,880 --> 00:15:20,399
uh you know the index searcher instance

00:15:19,760 --> 00:15:23,120
will actually

00:15:20,399 --> 00:15:24,560
stagger threads or it'll you know bash

00:15:23,120 --> 00:15:26,560
threads and execute them

00:15:24,560 --> 00:15:28,800
make sure that it does not exceed the

00:15:26,560 --> 00:15:30,639
limits that are set by a slice executor

00:15:28,800 --> 00:15:31,920
so basically a slice exit is a way to

00:15:30,639 --> 00:15:33,839
set your

00:15:31,920 --> 00:15:36,000
thread execution strategy so that you

00:15:33,839 --> 00:15:37,680
can control the actual behavior of a

00:15:36,000 --> 00:15:39,199
query when it's going multi-threaded

00:15:37,680 --> 00:15:41,600
and this is basically put into place to

00:15:39,199 --> 00:15:41,839
ensure that in um you know in high load

00:15:41,600 --> 00:15:44,399
or

00:15:41,839 --> 00:15:46,000
in skewed scenarios uh one query does

00:15:44,399 --> 00:15:47,839
not overtake the entire

00:15:46,000 --> 00:15:49,199
maximum amount of cpu usage because it

00:15:47,839 --> 00:15:51,040
had too many threads or

00:15:49,199 --> 00:15:52,880
you know it was just a very heavy query

00:15:51,040 --> 00:15:56,160
so using this likes executor

00:15:52,880 --> 00:15:58,079
interface you can actually define the uh

00:15:56,160 --> 00:15:59,680
execution strategy that you you want

00:15:58,079 --> 00:16:00,320
your queries to be used and this is real

00:15:59,680 --> 00:16:02,000
time so

00:16:00,320 --> 00:16:03,360
this won't be a static operation it will

00:16:02,000 --> 00:16:05,759
actually take system statistics to

00:16:03,360 --> 00:16:05,759
account

00:16:06,959 --> 00:16:11,600
yeah so now coming to some specifics of

00:16:09,920 --> 00:16:12,959
you know how do we use whatever we have

00:16:11,600 --> 00:16:14,720
seen till now

00:16:12,959 --> 00:16:16,240
if you look at the index searcher class

00:16:14,720 --> 00:16:17,519
and again i'll be going to some code

00:16:16,240 --> 00:16:18,800
specifics here

00:16:17,519 --> 00:16:21,199
uh if you look at the index searcher

00:16:18,800 --> 00:16:23,759
class uh and you know you see how to

00:16:21,199 --> 00:16:25,759
create one you'll see two new uh

00:16:23,759 --> 00:16:28,160
constructor methods available there

00:16:25,759 --> 00:16:29,920
one is called the uh you know one has

00:16:28,160 --> 00:16:30,639
only the industry the context and the

00:16:29,920 --> 00:16:33,920
executor

00:16:30,639 --> 00:16:35,360
instance so basically the way to uh

00:16:33,920 --> 00:16:36,959
tell you seen that you want to do

00:16:35,360 --> 00:16:39,839
concurrent search is to pass

00:16:36,959 --> 00:16:41,759
in a java executor class to index search

00:16:39,839 --> 00:16:45,040
so that is an implicit

00:16:41,759 --> 00:16:46,880
agreement to uh you know to

00:16:45,040 --> 00:16:48,480
basically be using concrete so you're

00:16:46,880 --> 00:16:50,399
basically signing into lucien that hey i

00:16:48,480 --> 00:16:51,199
want to use concurrent search whenever

00:16:50,399 --> 00:16:52,639
applicable

00:16:51,199 --> 00:16:54,079
it might actually happen that you know

00:16:52,639 --> 00:16:55,120
your queries are so light they're only

00:16:54,079 --> 00:16:58,079
looking

00:16:55,120 --> 00:16:59,519
so you know so small segments or the

00:16:58,079 --> 00:17:00,399
density of segments are not that much

00:16:59,519 --> 00:17:02,320
that eventually

00:17:00,399 --> 00:17:04,160
losing will decide that it only requires

00:17:02,320 --> 00:17:06,000
one thread for most of the queries but

00:17:04,160 --> 00:17:08,000
you're basically allowing lucien to use

00:17:06,000 --> 00:17:08,240
confidence search if it's applicable if

00:17:08,000 --> 00:17:10,959
it

00:17:08,240 --> 00:17:12,079
were expected to help your the latency

00:17:10,959 --> 00:17:14,000
of your query

00:17:12,079 --> 00:17:15,520
uh in the first in your constructor if

00:17:14,000 --> 00:17:17,919
you use that you're basically telling

00:17:15,520 --> 00:17:20,319
lucien to use the default sizes tutor uh

00:17:17,919 --> 00:17:21,760
this default executor is very simple

00:17:20,319 --> 00:17:23,600
as i mentioned in the previous slide the

00:17:21,760 --> 00:17:25,360
default model says that you know

00:17:23,600 --> 00:17:27,839
the executor that you have passed in the

00:17:25,360 --> 00:17:30,000
java executor uh at any point

00:17:27,839 --> 00:17:32,400
no more than 1.5 times of the maximum

00:17:30,000 --> 00:17:33,840
size threads are scheduled and executed

00:17:32,400 --> 00:17:35,600
right so you're not going to

00:17:33,840 --> 00:17:37,200
schedule like five times the number of

00:17:35,600 --> 00:17:38,559
the size of executor threads

00:17:37,200 --> 00:17:40,400
because that doesn't make sense that's a

00:17:38,559 --> 00:17:42,160
default behavior and if you're not

00:17:40,400 --> 00:17:44,400
passing in your own customs executor

00:17:42,160 --> 00:17:48,000
that is a behavior that you get

00:17:44,400 --> 00:17:49,600
uh the other constructor is even more

00:17:48,000 --> 00:17:50,720
fine-grained so you can pass in your own

00:17:49,600 --> 00:17:52,080
java executor

00:17:50,720 --> 00:17:53,840
and you can pass in your own site's

00:17:52,080 --> 00:17:56,000
executive implementation

00:17:53,840 --> 00:17:57,760
in this scenario your own implementation

00:17:56,000 --> 00:18:00,880
of the slice executor

00:17:57,760 --> 00:18:02,480
will override the default version and uh

00:18:00,880 --> 00:18:04,240
in that's you know you are you basically

00:18:02,480 --> 00:18:07,039
master of your destiny so

00:18:04,240 --> 00:18:08,880
the way for each query execution your

00:18:07,039 --> 00:18:10,880
size executable will be invoked

00:18:08,880 --> 00:18:11,919
and then you can basically decide how

00:18:10,880 --> 00:18:14,240
you want to

00:18:11,919 --> 00:18:15,760
run those threads you can build your own

00:18:14,240 --> 00:18:16,559
priority model you can do whatever you

00:18:15,760 --> 00:18:19,280
would want

00:18:16,559 --> 00:18:21,120
and lucene will basically uh follow the

00:18:19,280 --> 00:18:22,080
execution strategy set by your slice

00:18:21,120 --> 00:18:24,160
executor

00:18:22,080 --> 00:18:25,919
uh to the last step and that is the

00:18:24,160 --> 00:18:29,280
amount of control that you can have

00:18:25,919 --> 00:18:32,480
on how your queries get executed

00:18:29,280 --> 00:18:32,880
uh so as i said so that is basically how

00:18:32,480 --> 00:18:35,280
you

00:18:32,880 --> 00:18:36,960
uh you know indicate to lucien that you

00:18:35,280 --> 00:18:39,120
want to use concurrency

00:18:36,960 --> 00:18:41,120
uh if you want to as a i mentioned this

00:18:39,120 --> 00:18:43,360
before if you actually want to use

00:18:41,120 --> 00:18:44,640
concurrency for your custom collectors

00:18:43,360 --> 00:18:45,760
then you have to implement the collector

00:18:44,640 --> 00:18:47,520
manager interface

00:18:45,760 --> 00:18:50,080
which basically has two methods so it's

00:18:47,520 --> 00:18:52,080
a new character which is used during the

00:18:50,080 --> 00:18:53,120
query spanning phase you know when we

00:18:52,080 --> 00:18:55,600
actually uh

00:18:53,120 --> 00:18:56,799
firing new threads for different phases

00:18:55,600 --> 00:18:57,600
of the query or different slices of the

00:18:56,799 --> 00:18:58,880
query

00:18:57,600 --> 00:19:00,960
and then there's a reduce operation

00:18:58,880 --> 00:19:02,640
which is basically gather step or the

00:19:00,960 --> 00:19:04,799
you know if you map it to mapreduce it

00:19:02,640 --> 00:19:06,000
is a view step where you give it all the

00:19:04,799 --> 00:19:08,240
collectors that have been done for a

00:19:06,000 --> 00:19:09,039
specific query and expect the reduce

00:19:08,240 --> 00:19:11,520
method

00:19:09,039 --> 00:19:13,520
to turn that partial set of results into

00:19:11,520 --> 00:19:14,080
a final comprehensible result that can

00:19:13,520 --> 00:19:16,640
be

00:19:14,080 --> 00:19:18,240
given back to the end user again these

00:19:16,640 --> 00:19:20,480
are very specific to

00:19:18,240 --> 00:19:21,440
uh the specific collector that you're

00:19:20,480 --> 00:19:24,320
dealing with

00:19:21,440 --> 00:19:25,840
so you know all of your logic should be

00:19:24,320 --> 00:19:27,520
encapsulated within your own custom

00:19:25,840 --> 00:19:30,480
collector manager interface

00:19:27,520 --> 00:19:30,480
implementation i'm sorry

00:19:31,600 --> 00:19:36,000
i'm not coming to you know i mean this

00:19:34,400 --> 00:19:37,280
sounds great right but does that mean

00:19:36,000 --> 00:19:38,400
that we should be using concurrent

00:19:37,280 --> 00:19:40,960
search all the time

00:19:38,400 --> 00:19:42,720
or well not necessarily because one

00:19:40,960 --> 00:19:45,600
thing we have to realize is that this

00:19:42,720 --> 00:19:48,480
does add additional computational cost

00:19:45,600 --> 00:19:49,200
uh to the overall search uh runtime

00:19:48,480 --> 00:19:51,679
because

00:19:49,200 --> 00:19:52,799
you know for example if you asked uh

00:19:51,679 --> 00:19:55,919
lucine for

00:19:52,799 --> 00:19:58,080
n hits and lucene decides and you

00:19:55,919 --> 00:19:59,679
said okay go and use concurrence search

00:19:58,080 --> 00:20:00,720
then basically lucian decide that you

00:19:59,679 --> 00:20:03,360
want

00:20:00,720 --> 00:20:04,640
maybe let's say m threads then the total

00:20:03,360 --> 00:20:05,200
number of hits that you're actually

00:20:04,640 --> 00:20:08,799
collecting

00:20:05,200 --> 00:20:11,360
is n into m right because now each uh

00:20:08,799 --> 00:20:13,120
collector each slice is actually looking

00:20:11,360 --> 00:20:14,640
at n hits right if it can if it

00:20:13,120 --> 00:20:16,320
does not even have an document then this

00:20:14,640 --> 00:20:18,400
different story but basically

00:20:16,320 --> 00:20:20,080
you know the end slice the each slice

00:20:18,400 --> 00:20:22,240
will generate n documents

00:20:20,080 --> 00:20:23,280
and they're m of those threads m of

00:20:22,240 --> 00:20:24,400
those slices so you're basically

00:20:23,280 --> 00:20:26,880
correcting n into m

00:20:24,400 --> 00:20:27,600
documents on top of it then you have an

00:20:26,880 --> 00:20:30,080
additional

00:20:27,600 --> 00:20:31,600
uh you know partial merge sort step or

00:20:30,080 --> 00:20:33,039
partial merge set

00:20:31,600 --> 00:20:34,640
where you're basically now going through

00:20:33,039 --> 00:20:36,480
all those strategies merging them and

00:20:34,640 --> 00:20:37,919
building the final result which will be

00:20:36,480 --> 00:20:39,280
given back to the user

00:20:37,919 --> 00:20:41,440
and then there's you know there's always

00:20:39,280 --> 00:20:43,280
always coordination because i said if

00:20:41,440 --> 00:20:44,640
for some reason one thread is much

00:20:43,280 --> 00:20:46,159
slower than the others then

00:20:44,640 --> 00:20:48,320
that thread basically defines your

00:20:46,159 --> 00:20:49,440
latency right so you actually are paying

00:20:48,320 --> 00:20:51,360
the cost of

00:20:49,440 --> 00:20:52,720
the additional computation without any

00:20:51,360 --> 00:20:55,360
significant gains because

00:20:52,720 --> 00:20:56,640
you know one thread really went slower

00:20:55,360 --> 00:20:57,600
you have a bad this or something like

00:20:56,640 --> 00:21:00,880
that

00:20:57,600 --> 00:21:02,320
so uh concurrent search is not perfect

00:21:00,880 --> 00:21:04,640
it doesn't have its own computation

00:21:02,320 --> 00:21:06,320
overhead and they can get amplified

00:21:04,640 --> 00:21:08,480
uh if you have too much of data right so

00:21:06,320 --> 00:21:10,080
if your queries are so expensive that

00:21:08,480 --> 00:21:11,280
they actually you know you concurrency

00:21:10,080 --> 00:21:12,159
the amount of data that you're looking

00:21:11,280 --> 00:21:14,320
at

00:21:12,159 --> 00:21:16,159
greatly explodes then you need to be a

00:21:14,320 --> 00:21:18,000
bit careful

00:21:16,159 --> 00:21:19,520
uh so when to actually be using

00:21:18,000 --> 00:21:22,559
concurrent search uh

00:21:19,520 --> 00:21:23,600
concurrent search is pretty useful uh

00:21:22,559 --> 00:21:25,919
when you know you have

00:21:23,600 --> 00:21:27,840
available cpu resources you know you're

00:21:25,919 --> 00:21:29,360
not basically hitting the red line qps

00:21:27,840 --> 00:21:32,400
of your existing system

00:21:29,360 --> 00:21:34,559
uh but your queries that are getting

00:21:32,400 --> 00:21:36,320
fired are long pole quiz right they are

00:21:34,559 --> 00:21:38,000
expensive queries they are looking at

00:21:36,320 --> 00:21:39,520
large amount of data they're

00:21:38,000 --> 00:21:41,280
spending significant amount of time just

00:21:39,520 --> 00:21:44,240
scanning data right

00:21:41,280 --> 00:21:45,280
uh that queries or there might just be

00:21:44,240 --> 00:21:47,039
some sort of

00:21:45,280 --> 00:21:48,480
uh you know some sort of reporting that

00:21:47,039 --> 00:21:52,000
you're doing

00:21:48,480 --> 00:21:54,320
depends uh so if you have the available

00:21:52,000 --> 00:21:56,000
computational power and you want to go

00:21:54,320 --> 00:21:57,600
that extra step to make sure that if

00:21:56,000 --> 00:21:59,039
your long pull down ring queries

00:21:57,600 --> 00:22:01,600
actually your long pole queries

00:21:59,039 --> 00:22:02,159
are getting faster at the trade-off of a

00:22:01,600 --> 00:22:03,760
higher

00:22:02,159 --> 00:22:05,440
uh resource usage then you should be

00:22:03,760 --> 00:22:07,440
using confidence search right and that

00:22:05,440 --> 00:22:08,320
is becoming a very common use keys these

00:22:07,440 --> 00:22:10,400
days because

00:22:08,320 --> 00:22:12,640
uh people are going beyond the typical

00:22:10,400 --> 00:22:14,880
search application when using the scene

00:22:12,640 --> 00:22:16,559
so uh in those sort of scenarios when

00:22:14,880 --> 00:22:18,159
you have heavy queries and you have

00:22:16,559 --> 00:22:20,240
uh resource compute you know resource

00:22:18,159 --> 00:22:21,600
capacity to spare you can actually use

00:22:20,240 --> 00:22:24,320
concurrent search to

00:22:21,600 --> 00:22:26,320
greatly reduce down the overall latency

00:22:24,320 --> 00:22:29,440
of your long pole queries right

00:22:26,320 --> 00:22:30,720
uh and that actually also leads to the

00:22:29,440 --> 00:22:31,840
other aspect of where not to use

00:22:30,720 --> 00:22:33,520
concurrent search

00:22:31,840 --> 00:22:35,280
uh it's basically when you are already

00:22:33,520 --> 00:22:37,760
at red line right you have a very high

00:22:35,280 --> 00:22:39,840
qps scenario where your queries per

00:22:37,760 --> 00:22:41,440
second is extremely high and you're also

00:22:39,840 --> 00:22:43,120
already bordering on

00:22:41,440 --> 00:22:45,520
the high water mark or the alert

00:22:43,120 --> 00:22:47,280
watermark for your uh resource capacity

00:22:45,520 --> 00:22:49,760
or your computational capacity

00:22:47,280 --> 00:22:51,200
so you should not be using uh you know

00:22:49,760 --> 00:22:52,799
concurrent surgery because it will only

00:22:51,200 --> 00:22:55,039
act with the pain

00:22:52,799 --> 00:22:56,240
the other aspect is if you have very

00:22:55,039 --> 00:22:58,159
light queries right

00:22:56,240 --> 00:22:59,600
um you really don't want multi-threading

00:22:58,159 --> 00:23:01,360
or you don't need multi-threading

00:22:59,600 --> 00:23:02,640
because you know you might have a large

00:23:01,360 --> 00:23:03,760
number of segments but those segments

00:23:02,640 --> 00:23:05,440
are so small that

00:23:03,760 --> 00:23:06,960
it doesn't really matter although you

00:23:05,440 --> 00:23:08,080
know leucine slice plans should take

00:23:06,960 --> 00:23:10,080
care of this but

00:23:08,080 --> 00:23:11,679
in those scenarios you might what not

00:23:10,080 --> 00:23:13,760
want to use uh

00:23:11,679 --> 00:23:14,960
containers because it might actually do

00:23:13,760 --> 00:23:16,960
more harm than good

00:23:14,960 --> 00:23:18,000
as i said losing size fine should i take

00:23:16,960 --> 00:23:19,600
care of this

00:23:18,000 --> 00:23:20,960
and same for small data set if you're a

00:23:19,600 --> 00:23:22,640
low number of segments it doesn't really

00:23:20,960 --> 00:23:23,200
make sense to be using concurrent search

00:23:22,640 --> 00:23:25,280
but for the

00:23:23,200 --> 00:23:26,960
last two options i think you've seen can

00:23:25,280 --> 00:23:28,240
take care of it the biggest takeaway

00:23:26,960 --> 00:23:29,520
here i would say is that

00:23:28,240 --> 00:23:32,080
if you're serving a very high

00:23:29,520 --> 00:23:33,760
transaction load uh

00:23:32,080 --> 00:23:35,039
then this probably won't make sense

00:23:33,760 --> 00:23:36,000
right if you have too many queries

00:23:35,039 --> 00:23:38,960
coming at the same time

00:23:36,000 --> 00:23:40,080
and most of the space are short-lived

00:23:38,960 --> 00:23:42,240
and you're already

00:23:40,080 --> 00:23:43,679
running higher resources then adding

00:23:42,240 --> 00:23:46,000
more computational

00:23:43,679 --> 00:23:47,120
expense to each query might not be a

00:23:46,000 --> 00:23:48,720
really good idea

00:23:47,120 --> 00:23:50,640
so you might want to consider which

00:23:48,720 --> 00:23:51,840
scenario you want to use concurrent

00:23:50,640 --> 00:23:54,000
search for

00:23:51,840 --> 00:23:56,159
and the converse is also true right if

00:23:54,000 --> 00:23:58,559
you have the available capacity you can

00:23:56,159 --> 00:24:00,960
actually just and you want to make your

00:23:58,559 --> 00:24:02,400
slow queries faster or your large long

00:24:00,960 --> 00:24:03,600
run queries faster you can just use

00:24:02,400 --> 00:24:05,200
concurrent search and you'll see a

00:24:03,600 --> 00:24:08,880
significant improvement

00:24:05,200 --> 00:24:08,880
in the overall latency that you see

00:24:09,200 --> 00:24:13,360
uh so that you know what till what this

00:24:12,080 --> 00:24:16,640
point what you talked about is

00:24:13,360 --> 00:24:19,440
a basic model of concurrent search that

00:24:16,640 --> 00:24:20,559
is not really optimized uh for a lot of

00:24:19,440 --> 00:24:21,919
scenarios for example you know

00:24:20,559 --> 00:24:23,120
everybody's collecting their own hits

00:24:21,919 --> 00:24:25,600
they're not coordinating between

00:24:23,120 --> 00:24:27,360
each other um there is no you know

00:24:25,600 --> 00:24:28,400
they're not really using the caller

00:24:27,360 --> 00:24:30,080
threat for anything

00:24:28,400 --> 00:24:31,600
so there have been optimizations there

00:24:30,080 --> 00:24:32,400
are different optimizations going on

00:24:31,600 --> 00:24:34,480
right now

00:24:32,400 --> 00:24:35,600
i might have actually missed a couple in

00:24:34,480 --> 00:24:38,640
the recent times but

00:24:35,600 --> 00:24:40,640
um for example if you only you know

00:24:38,640 --> 00:24:43,200
if you only want to look at n number of

00:24:40,640 --> 00:24:43,679
documents uh globally right if you can

00:24:43,200 --> 00:24:45,279
actually

00:24:43,679 --> 00:24:47,520
tell you seem to not look at more than n

00:24:45,279 --> 00:24:49,120
number of documents in that scenario

00:24:47,520 --> 00:24:50,960
earlier concurrent search actually used

00:24:49,120 --> 00:24:52,799
to look at end documents for slice

00:24:50,960 --> 00:24:54,880
but now it's a global counter where

00:24:52,799 --> 00:24:58,080
you'll only look at end documents global

00:24:54,880 --> 00:25:00,400
so it really doesn't matter if you know

00:24:58,080 --> 00:25:01,760
you're using n threads the limit that

00:25:00,400 --> 00:25:02,559
you've put for the visibility of

00:25:01,760 --> 00:25:04,480
documents will

00:25:02,559 --> 00:25:06,080
still be respected uh comprehensively

00:25:04,480 --> 00:25:07,840
and across all threads

00:25:06,080 --> 00:25:09,200
uh then the other optimization which

00:25:07,840 --> 00:25:12,240
actually was pretty

00:25:09,200 --> 00:25:14,640
uh excuse me helpful in uh the likely

00:25:12,240 --> 00:25:16,480
benchmarks that we run was basically

00:25:14,640 --> 00:25:18,000
publishing the worst of the best right

00:25:16,480 --> 00:25:20,880
so basically uh

00:25:18,000 --> 00:25:22,240
each collector in the you know each uh

00:25:20,880 --> 00:25:25,360
slice basically

00:25:22,240 --> 00:25:27,120
publishes the uh score of the first

00:25:25,360 --> 00:25:28,799
item in his priority queue so you know

00:25:27,120 --> 00:25:31,360
we as you know right when

00:25:28,799 --> 00:25:32,400
a collector is going over its uh data it

00:25:31,360 --> 00:25:34,480
basically

00:25:32,400 --> 00:25:36,480
decides at every point which you know if

00:25:34,480 --> 00:25:39,120
a document is worth adding to the

00:25:36,480 --> 00:25:40,480
priority of its collection or not or the

00:25:39,120 --> 00:25:41,039
priority queue it means maintaining

00:25:40,480 --> 00:25:42,480
whether

00:25:41,039 --> 00:25:44,480
the new document should be added to it

00:25:42,480 --> 00:25:47,279
or not replacing some other document

00:25:44,480 --> 00:25:48,159
so uh one optimization that has been

00:25:47,279 --> 00:25:50,640
done is basically

00:25:48,159 --> 00:25:52,080
every collector publishes the worst the

00:25:50,640 --> 00:25:53,840
score of the worst document that is

00:25:52,080 --> 00:25:56,480
currently in its private eq

00:25:53,840 --> 00:25:58,320
and then the other threads uh compare

00:25:56,480 --> 00:26:00,000
that with their local verse right so

00:25:58,320 --> 00:26:00,799
it's like a local minima versus global

00:26:00,000 --> 00:26:02,640
minima

00:26:00,799 --> 00:26:04,000
they take the maximum of it and actually

00:26:02,640 --> 00:26:06,000
use that to be

00:26:04,000 --> 00:26:08,080
uh you know filtering documents in their

00:26:06,000 --> 00:26:09,360
local search so what might happen is

00:26:08,080 --> 00:26:11,760
that as a thread

00:26:09,360 --> 00:26:13,520
i have you know my worst scene document

00:26:11,760 --> 00:26:15,520
has a score of x

00:26:13,520 --> 00:26:16,720
and globally the worst scene score

00:26:15,520 --> 00:26:19,039
document you know

00:26:16,720 --> 00:26:20,640
versing document has a score of let's

00:26:19,039 --> 00:26:23,120
say x plus two or something

00:26:20,640 --> 00:26:24,400
or not two but a score has an x so

00:26:23,120 --> 00:26:26,400
basically what i mean is that my

00:26:24,400 --> 00:26:29,520
document will never make it to

00:26:26,400 --> 00:26:30,159
uh this you know basically never make it

00:26:29,520 --> 00:26:31,919
to the

00:26:30,159 --> 00:26:33,360
top 10 elite or you know the final

00:26:31,919 --> 00:26:34,799
result set because there are only

00:26:33,360 --> 00:26:36,640
already 10 documents that are better

00:26:34,799 --> 00:26:38,720
than this guy right so i can start

00:26:36,640 --> 00:26:40,480
filtering those documents i can start

00:26:38,720 --> 00:26:42,080
pruning documents right from the get go

00:26:40,480 --> 00:26:43,600
so that i'm not looking at unnecessary

00:26:42,080 --> 00:26:44,400
documents i'm not taking them for final

00:26:43,600 --> 00:26:45,760
processing

00:26:44,400 --> 00:26:47,360
when i don't know that they have no

00:26:45,760 --> 00:26:48,240
chance of making it to the final result

00:26:47,360 --> 00:26:50,320
set

00:26:48,240 --> 00:26:52,640
and then another optimization that went

00:26:50,320 --> 00:26:54,000
in was basically using the collar thread

00:26:52,640 --> 00:26:56,240
for

00:26:54,000 --> 00:26:58,000
you executing one of the uh you know one

00:26:56,240 --> 00:26:59,520
of these slices as well

00:26:58,000 --> 00:27:01,440
so the optimization that i haven't

00:26:59,520 --> 00:27:02,960
really mentioned here are also around

00:27:01,440 --> 00:27:03,760
using a shared priority queue which we

00:27:02,960 --> 00:27:05,600
explored

00:27:03,760 --> 00:27:06,960
or basically uh you know making sure

00:27:05,600 --> 00:27:09,440
that if we because

00:27:06,960 --> 00:27:11,200
using a shared priority q as on uh

00:27:09,440 --> 00:27:12,400
concurrency cost so we are

00:27:11,200 --> 00:27:14,320
i think there have been optimization

00:27:12,400 --> 00:27:14,720
done recently in that area and there are

00:27:14,320 --> 00:27:16,240
more

00:27:14,720 --> 00:27:18,080
that have to be explored just to make

00:27:16,240 --> 00:27:20,799
sure that the cost of these

00:27:18,080 --> 00:27:22,159
end into m collections is reduced or if

00:27:20,799 --> 00:27:24,159
you can reduce the number of

00:27:22,159 --> 00:27:25,679
documents that we actually looking at in

00:27:24,159 --> 00:27:26,960
a concurrent search if you can reduce

00:27:25,679 --> 00:27:27,840
that footprint that will be really

00:27:26,960 --> 00:27:29,919
helpful and

00:27:27,840 --> 00:27:31,279
increase the scope of applicability of

00:27:29,919 --> 00:27:33,840
concurrent search

00:27:31,279 --> 00:27:34,399
other improvement that actually went in

00:27:33,840 --> 00:27:36,320
uh but

00:27:34,399 --> 00:27:38,399
you know what got reverted because of

00:27:36,320 --> 00:27:40,480
some corner case test failure that

00:27:38,399 --> 00:27:42,480
and yet to look at is basically using

00:27:40,480 --> 00:27:44,320
the same executor to actually

00:27:42,480 --> 00:27:46,159
uh you know cache concurrently so

00:27:44,320 --> 00:27:48,080
basically make lru caching concurrent

00:27:46,159 --> 00:27:51,039
using the same executor

00:27:48,080 --> 00:27:51,520
so i'm actually reviving that discussion

00:27:51,039 --> 00:27:54,640
and

00:27:51,520 --> 00:27:56,880
uh one very interesting item that

00:27:54,640 --> 00:27:58,000
i haven't put up here because it's not

00:27:56,880 --> 00:27:59,760
gone in yet it's

00:27:58,000 --> 00:28:01,200
under a lot of contention that you know

00:27:59,760 --> 00:28:02,240
we are doing on the community is

00:28:01,200 --> 00:28:05,279
basically

00:28:02,240 --> 00:28:07,120
a scenario where uh you know

00:28:05,279 --> 00:28:08,559
if you actually are actually let me see

00:28:07,120 --> 00:28:12,159
if i have that yeah so you know

00:28:08,559 --> 00:28:14,559
here so you know a scenario where uh

00:28:12,159 --> 00:28:16,399
imagine if you've merged all of your

00:28:14,559 --> 00:28:18,320
index into one large um all of your

00:28:16,399 --> 00:28:20,000
segments into one last segment right

00:28:18,320 --> 00:28:22,000
uh that happens people do that for query

00:28:20,000 --> 00:28:24,159
performance or for freezing or you know

00:28:22,000 --> 00:28:26,240
for long term storage stuff like that

00:28:24,159 --> 00:28:28,159
and now in that scenario even if your

00:28:26,240 --> 00:28:30,159
segment is very large

00:28:28,159 --> 00:28:31,200
uh in the current concurrent search

00:28:30,159 --> 00:28:33,039
implementation

00:28:31,200 --> 00:28:34,799
uh you cannot benefit from

00:28:33,039 --> 00:28:36,320
multi-threading because

00:28:34,799 --> 00:28:37,840
uh you know you'll still be have it's

00:28:36,320 --> 00:28:39,440
still a single segment you'll still have

00:28:37,840 --> 00:28:40,799
one thread reading through it

00:28:39,440 --> 00:28:42,640
it doesn't really matter the segment is

00:28:40,799 --> 00:28:43,440
really large we don't have the ability

00:28:42,640 --> 00:28:45,600
to

00:28:43,440 --> 00:28:47,440
split a single segment and actually

00:28:45,600 --> 00:28:48,399
divide dock id ranges among multiple

00:28:47,440 --> 00:28:50,799
threads

00:28:48,399 --> 00:28:52,159
which is one of the optimizations that

00:28:50,799 --> 00:28:54,559
you know that has been pursued

00:28:52,159 --> 00:28:55,919
that has been discussed and i think uh

00:28:54,559 --> 00:28:57,919
that will help

00:28:55,919 --> 00:28:59,760
other scenarios that are not yet being

00:28:57,919 --> 00:29:02,159
targeted by concurrent search

00:28:59,760 --> 00:29:02,960
so that is one uh potential optimization

00:29:02,159 --> 00:29:04,399
that

00:29:02,960 --> 00:29:07,440
which will hopefully make it way into

00:29:04,399 --> 00:29:09,520
lucine sometime or in some other form

00:29:07,440 --> 00:29:10,720
but uh yeah that has been pursued and

00:29:09,520 --> 00:29:12,000
then again there are

00:29:10,720 --> 00:29:13,600
you know more slice executed

00:29:12,000 --> 00:29:14,480
implementations right other model is

00:29:13,600 --> 00:29:17,120
pretty simple

00:29:14,480 --> 00:29:19,440
simplistic maybe we want to use more of

00:29:17,120 --> 00:29:21,039
uh system stats or resource stats and

00:29:19,440 --> 00:29:23,200
more of live monitoring to

00:29:21,039 --> 00:29:24,320
actually control how threads are being

00:29:23,200 --> 00:29:27,279
executed for

00:29:24,320 --> 00:29:29,440
the existing executing queries which are

00:29:27,279 --> 00:29:32,799
actually using concurrency

00:29:29,440 --> 00:29:35,039
uh so yeah i think uh that

00:29:32,799 --> 00:29:36,399
is mostly about uh blue scenes

00:29:35,039 --> 00:29:38,960
concurrent search

00:29:36,399 --> 00:29:40,159
uh right now you know neither of the

00:29:38,960 --> 00:29:42,640
popular

00:29:40,159 --> 00:29:44,159
uh search engines built on top of lucien

00:29:42,640 --> 00:29:48,000
actually exposed this feature

00:29:44,159 --> 00:29:50,480
uh solar has an open item for this

00:29:48,000 --> 00:29:51,760
uh which is being targeted for 9.0 uh

00:29:50,480 --> 00:29:53,120
there's a jira open

00:29:51,760 --> 00:29:55,840
please take a look at it there's also a

00:29:53,120 --> 00:29:58,080
pr open for every piece to be updated

00:29:55,840 --> 00:29:59,279
but hopefully nine dot or release of

00:29:58,080 --> 00:30:01,679
solar will have

00:29:59,279 --> 00:30:03,200
uh usage of collective matches and allow

00:30:01,679 --> 00:30:05,200
uh multi

00:30:03,200 --> 00:30:07,600
threaded searching for a single node as

00:30:05,200 --> 00:30:09,200
well and that should hopefully help for

00:30:07,600 --> 00:30:12,000
large analytical queries

00:30:09,200 --> 00:30:12,640
but uh that item is being pursued and uh

00:30:12,000 --> 00:30:14,080
no

00:30:12,640 --> 00:30:16,880
fingers crossed that will land pretty

00:30:14,080 --> 00:30:19,679
soon pretty soon as well

00:30:16,880 --> 00:30:22,080
so yeah i think uh that was a marathon

00:30:19,679 --> 00:30:24,399
and that was all i wanted to share today

00:30:22,080 --> 00:30:26,799
uh so thank you for being patience

00:30:24,399 --> 00:30:28,480
audience i'm not sure if you know

00:30:26,799 --> 00:30:30,559
if there any questions that i can help

00:30:28,480 --> 00:30:34,320
answer anything that

00:30:30,559 --> 00:30:34,320
it was not obvious and i can help

00:30:34,840 --> 00:30:37,840
clarify

00:30:43,919 --> 00:30:51,360
okay so i see a bunch of questions i'll

00:30:46,799 --> 00:30:54,399
start answering them

00:30:51,360 --> 00:30:56,240
yeah so as charm mentioned you know

00:30:54,399 --> 00:30:57,760
uh mike and candace actually brought me

00:30:56,240 --> 00:30:59,679
to you know

00:30:57,760 --> 00:31:01,679
the world of lucine and he actually told

00:30:59,679 --> 00:31:03,919
me i would contend search first

00:31:01,679 --> 00:31:05,840
so yeah a lot of things that i have done

00:31:03,919 --> 00:31:09,840
and have been done recently are

00:31:05,840 --> 00:31:13,039
motivated by him uh

00:31:09,840 --> 00:31:16,159
so um

00:31:13,039 --> 00:31:17,279
yeah you know so as uh brown last is

00:31:16,159 --> 00:31:19,679
facing

00:31:17,279 --> 00:31:20,799
currently multi-threaded no it is not as

00:31:19,679 --> 00:31:21,679
they would already answer thank you

00:31:20,799 --> 00:31:24,240
david but

00:31:21,679 --> 00:31:26,320
it can be made multithreaded uh if we

00:31:24,240 --> 00:31:29,840
put in the right semantics

00:31:26,320 --> 00:31:32,880
uh to answer push question um

00:31:29,840 --> 00:31:34,960
you know yes there are uh

00:31:32,880 --> 00:31:36,320
you know performance tests done and you

00:31:34,960 --> 00:31:38,000
can actually look at them if you look at

00:31:36,320 --> 00:31:39,919
the nightly benchmarks that we've run

00:31:38,000 --> 00:31:41,360
uh i think mike also published some

00:31:39,919 --> 00:31:42,640
numbers and i also have them so i can

00:31:41,360 --> 00:31:43,679
connect with you offline and share but

00:31:42,640 --> 00:31:45,360
if you look at the

00:31:43,679 --> 00:31:47,279
blog post that was referred if you look

00:31:45,360 --> 00:31:49,039
at the nightly benchmarks that

00:31:47,279 --> 00:31:52,640
we run you should be able to see what

00:31:49,039 --> 00:31:55,279
kind of performance changes we have seen

00:31:52,640 --> 00:31:56,720
yeah if i had same question i think

00:31:55,279 --> 00:31:58,159
there are public available numbers that

00:31:56,720 --> 00:32:01,840
i don't have right now but

00:31:58,159 --> 00:32:01,840
i can go offline share with you

00:32:06,399 --> 00:32:09,799
now

00:32:06,720 --> 00:32:09,799
[Music]

00:32:11,600 --> 00:32:15,760
uh parallel indexing is uh you know it

00:32:14,799 --> 00:32:17,919
is doable

00:32:15,760 --> 00:32:19,120
uh but i don't think this approach

00:32:17,919 --> 00:32:20,960
actually helps there because this is

00:32:19,120 --> 00:32:22,640
very specific to search

00:32:20,960 --> 00:32:24,640
and all the semantics that we've

00:32:22,640 --> 00:32:26,480
actually uh put in here

00:32:24,640 --> 00:32:28,159
are you know just related to the search

00:32:26,480 --> 00:32:29,120
part of the world yes of course i mean

00:32:28,159 --> 00:32:31,120
theoretically it is

00:32:29,120 --> 00:32:32,399
possible but i don't think we have

00:32:31,120 --> 00:32:34,480
explored that yet or

00:32:32,399 --> 00:32:36,240
anything or much of what has been done

00:32:34,480 --> 00:32:37,679
for concurrent search can be salvaged

00:32:36,240 --> 00:32:43,840
for that implementation so that would be

00:32:37,679 --> 00:32:43,840
a separate effort in itself

00:32:59,279 --> 00:33:03,279
oh okay i probably misunderstood the

00:33:01,360 --> 00:33:06,480
question then i'm sorry yeah

00:33:03,279 --> 00:33:08,559
if you meant only a single node indexing

00:33:06,480 --> 00:33:09,679
in leucine yes that's already there okay

00:33:08,559 --> 00:33:10,720
a probably

00:33:09,679 --> 00:33:14,000
you know was thinking about something

00:33:10,720 --> 00:33:14,000
very different sorry about that

00:33:18,399 --> 00:33:24,080
thank you eric thank you sean

00:33:21,840 --> 00:33:25,360
so we have quite some time we can

00:33:24,080 --> 00:33:27,760
actually you know

00:33:25,360 --> 00:33:28,799
hang back here or i can i'll be present

00:33:27,760 --> 00:33:30,640
around in

00:33:28,799 --> 00:33:32,480
multiple rooms if you want to chat about

00:33:30,640 --> 00:33:34,480
it uh

00:33:32,480 --> 00:33:38,159
i'm always available for any questions

00:33:34,480 --> 00:33:40,720
that i can help answer

00:33:38,159 --> 00:33:41,679
termination uh yeah so it's basically if

00:33:40,720 --> 00:33:43,679
you're talking about

00:33:41,679 --> 00:33:45,360
the number of documents that you know

00:33:43,679 --> 00:33:53,840
you can limit yes that's something that

00:33:45,360 --> 00:33:53,840
we do support

00:34:16,480 --> 00:34:20,720
uh that's a great question charm right

00:34:18,639 --> 00:34:23,280
now we don't capture those metrics

00:34:20,720 --> 00:34:24,560
per se but uh you know it would be good

00:34:23,280 --> 00:34:27,599
to publish those numbers

00:34:24,560 --> 00:34:29,040
in some aggregated form so yeah i think

00:34:27,599 --> 00:34:30,879
that's a great idea we should definitely

00:34:29,040 --> 00:34:31,839
discuss it offline but right now i don't

00:34:30,879 --> 00:34:34,480
think we have any

00:34:31,839 --> 00:34:35,760
clear way of capturing those numbers and

00:34:34,480 --> 00:34:39,359
actually making them available

00:34:35,760 --> 00:34:39,359
i'm making them available links to any

00:34:46,839 --> 00:34:49,839
api

00:34:54,720 --> 00:34:56,800

YouTube URL: https://www.youtube.com/watch?v=POb_pG4IzpQ


