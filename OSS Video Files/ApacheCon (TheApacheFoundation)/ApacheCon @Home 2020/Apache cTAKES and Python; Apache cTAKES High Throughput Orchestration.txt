Title: Apache cTAKES and Python; Apache cTAKES High Throughput Orchestration
Publication date: 2020-10-14
Playlist: ApacheCon @Home 2020
Description: 
	Apache cTAKES and Python; Apache cTAKES High Throughput Orchestration
Dmitriy Dligach, Sean Finan, Peter Abramowitsch

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

1. The rise of Natural Language Processing Machine Learning libraries in Python has created opportunities for the Apache clinical Text Analysis and Knowledge Extraction System (cTAKES). There are also challenges in utilizing the Java-based cTAKES type system across platforms.

2. We have built a high throughput orchestration mechanism to process and publish millions of redacted and unredacted notes in a PHI-safe environment and to manage refreshes where notes can continually be re-redacted, or obsoleted. We have a high-urgency stream of Covid related notes that are on a weekly refresh basis.

Dmitriy Dligach:
The overarching goal of Dr. Dligach's research is developing methods for automatic semantic analysis of texts. His work spans such areas of computer science as natural language processing, machine learning, and data mining. Most recently his research has focused on semantic analysis of clinical texts. He works both on method development and applications.

Sean Finan:
Sean Finan is a software developer in the Natural Language Processing lab at Boston Children's Hospital. He has worked with Apache cTAKES for the past 8 years, contributing code and supporting the community.
Peter Abramowitsch: Peter Abramowitsch started using cTAKES while working in the Hearst Health Innovation Lab. He is now an Architect and cTAKES Implementer in Bakar Computational Health Sciences Institute at the University of California, San Francisco.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:25,359 --> 00:00:30,560
i'm gonna go ahead and get

00:00:26,800 --> 00:00:34,000
started now this is not the right thing

00:00:30,560 --> 00:00:36,960
um just a very short presentation

00:00:34,000 --> 00:00:37,280
and it will be followed by one uh given

00:00:36,960 --> 00:00:40,320
by

00:00:37,280 --> 00:00:43,600
peter abramovic from ucsf

00:00:40,320 --> 00:00:47,360
okay so apache see takes

00:00:43,600 --> 00:00:47,360
and python uh

00:00:48,559 --> 00:00:51,760
the work for this was done by someone at

00:00:50,879 --> 00:00:53,680
loyola

00:00:51,760 --> 00:00:55,199
and unfortunately he could not be with

00:00:53,680 --> 00:00:59,520
us today so

00:00:55,199 --> 00:01:02,480
i'm going to be uh trying to fill in the

00:00:59,520 --> 00:01:03,840
gaps all right so what we want to

00:01:02,480 --> 00:01:05,519
present today

00:01:03,840 --> 00:01:07,280
uh we're going to compare and contrast

00:01:05,519 --> 00:01:09,680
all of the python frameworks for

00:01:07,280 --> 00:01:11,040
nlp uh then we're going to thoroughly

00:01:09,680 --> 00:01:15,280
examine the difference between

00:01:11,040 --> 00:01:17,439
class and type in software languages

00:01:15,280 --> 00:01:19,439
after that obviously we're going to

00:01:17,439 --> 00:01:21,280
drill down into the uema and then ctax

00:01:19,439 --> 00:01:22,400
type system to get a full understanding

00:01:21,280 --> 00:01:24,400
of those

00:01:22,400 --> 00:01:27,439
and then we're going to write some code

00:01:24,400 --> 00:01:30,960
in python using the new ctx module

00:01:27,439 --> 00:01:30,960
in python called cnix

00:01:31,040 --> 00:01:37,040
and don't believe any of that

00:01:34,400 --> 00:01:37,600
okay so python nlp frameworks in python

00:01:37,040 --> 00:01:40,240
have been

00:01:37,600 --> 00:01:41,119
uh popping up in nlp over the last

00:01:40,240 --> 00:01:44,079
couple of years

00:01:41,119 --> 00:01:44,560
uh you've got a bunch on the left uh

00:01:44,079 --> 00:01:46,960
that

00:01:44,560 --> 00:01:48,560
decided not to go with the sesame street

00:01:46,960 --> 00:01:49,439
theme and then you've got a bunch on the

00:01:48,560 --> 00:01:51,280
right that are

00:01:49,439 --> 00:01:52,799
generally called muppet ware but the

00:01:51,280 --> 00:01:54,960
point is

00:01:52,799 --> 00:01:56,240
i think people have been uh taking up

00:01:54,960 --> 00:02:00,240
the python

00:01:56,240 --> 00:02:03,439
side of things um one because it's

00:02:00,240 --> 00:02:06,479
you know new and fresh uh

00:02:03,439 --> 00:02:07,200
but also i think python has an easy

00:02:06,479 --> 00:02:09,520
entrance

00:02:07,200 --> 00:02:12,879
for people that don't necessarily want

00:02:09,520 --> 00:02:15,280
to be full-time developers

00:02:12,879 --> 00:02:16,959
and that's kind of good for it so

00:02:15,280 --> 00:02:19,280
c-takes is written primarily in

00:02:16,959 --> 00:02:22,560
java as everyone knows and there isn't

00:02:19,280 --> 00:02:26,959
really a fantastic way to combine java

00:02:22,560 --> 00:02:26,959
and python code so

00:02:27,280 --> 00:02:30,560
are we stuck is that the end of the game

00:02:29,440 --> 00:02:34,080
i don't think so

00:02:30,560 --> 00:02:37,360
so what we do have is a type system and

00:02:34,080 --> 00:02:40,720
scenic takes uses the uema type system

00:02:37,360 --> 00:02:42,400
subtyping that okay so

00:02:40,720 --> 00:02:44,160
there is a difference between type and

00:02:42,400 --> 00:02:46,879
class but you know

00:02:44,160 --> 00:02:46,879
put simply

00:02:47,680 --> 00:02:51,519
using a type there's no overriding and

00:02:50,239 --> 00:02:53,280
implementation so

00:02:51,519 --> 00:02:55,280
basically once you have something and

00:02:53,280 --> 00:02:57,920
you say okay give me

00:02:55,280 --> 00:02:59,760
the part of speech it's always going to

00:02:57,920 --> 00:03:00,800
return you a string there's never going

00:02:59,760 --> 00:03:04,000
to be some

00:03:00,800 --> 00:03:06,400
you know down the stream somewhere in

00:03:04,000 --> 00:03:08,319
sea takes where uh you have an

00:03:06,400 --> 00:03:08,640
annotation and all of a sudden you say

00:03:08,319 --> 00:03:11,200
when

00:03:08,640 --> 00:03:11,760
when i asked for the part of speech

00:03:11,200 --> 00:03:14,159
return

00:03:11,760 --> 00:03:15,360
an integer that's just never going to

00:03:14,159 --> 00:03:18,400
happen

00:03:15,360 --> 00:03:20,000
so that being given

00:03:18,400 --> 00:03:21,760
and the fact that the type system is

00:03:20,000 --> 00:03:24,640
fully defined in

00:03:21,760 --> 00:03:25,120
an xml file that can be loaded by any

00:03:24,640 --> 00:03:28,480
tool

00:03:25,120 --> 00:03:31,920
in any software language uh

00:03:28,480 --> 00:03:33,040
means that we can kind of across that

00:03:31,920 --> 00:03:35,360
where we can we can

00:03:33,040 --> 00:03:36,080
build a bridge across this gap between

00:03:35,360 --> 00:03:39,519
the uh

00:03:36,080 --> 00:03:42,080
tools built into different languages

00:03:39,519 --> 00:03:42,720
some people that have already done that

00:03:42,080 --> 00:03:45,840
are over at

00:03:42,720 --> 00:03:46,799
dk pro there's a dk pro project called

00:03:45,840 --> 00:03:48,080
cassis and

00:03:46,799 --> 00:03:50,480
this is a direct quote from their

00:03:48,080 --> 00:03:52,400
website uh this library enables the

00:03:50,480 --> 00:03:54,000
creation and manipulation of cast

00:03:52,400 --> 00:03:55,120
objects and their associated type

00:03:54,000 --> 00:03:56,720
systems

00:03:55,120 --> 00:03:58,560
as well as loading and saving cast

00:03:56,720 --> 00:04:00,959
objects into the classics my xml

00:03:58,560 --> 00:04:04,000
representation by dunk rhythms okay

00:04:00,959 --> 00:04:08,799
so what that means is

00:04:04,000 --> 00:04:08,799
we don't have to try to

00:04:08,959 --> 00:04:15,360
shoehorn python code into

00:04:12,319 --> 00:04:18,639
a java framework we don't have to try to

00:04:15,360 --> 00:04:21,040
similarly take a bunch of java code

00:04:18,639 --> 00:04:21,840
and somehow get it running in a python

00:04:21,040 --> 00:04:24,639
wrapper

00:04:21,840 --> 00:04:25,280
right instead what we can do is we can

00:04:24,639 --> 00:04:28,720
just

00:04:25,280 --> 00:04:32,240
save whatever we're doing in c takes

00:04:28,720 --> 00:04:35,280
as an xmi which is you know a rep

00:04:32,240 --> 00:04:36,320
snapshot representation of the cast that

00:04:35,280 --> 00:04:40,080
is

00:04:36,320 --> 00:04:43,600
containing all of the uh data for the

00:04:40,080 --> 00:04:48,160
ctx pipeline

00:04:43,600 --> 00:04:48,160
we save that into a file we can take a

00:04:48,400 --> 00:04:55,440
python tool and using dk procas

00:04:53,440 --> 00:04:57,199
we can read that file that was written

00:04:55,440 --> 00:05:00,320
by ctx

00:04:57,199 --> 00:05:04,960
and create the same cast this

00:05:00,320 --> 00:05:08,400
data object in python

00:05:04,960 --> 00:05:08,400
i hope that made a lot of sense

00:05:09,199 --> 00:05:13,600
so really we're bridging this gap

00:05:11,600 --> 00:05:16,080
between the two languages

00:05:13,600 --> 00:05:16,639
by not bothering to do any construction

00:05:16,080 --> 00:05:19,520
at all

00:05:16,639 --> 00:05:21,120
we're basically just getting in a boat

00:05:19,520 --> 00:05:24,400
and rowing the boat across

00:05:21,120 --> 00:05:28,320
this river between the two

00:05:24,400 --> 00:05:28,320
and we can row it in both directions

00:05:29,520 --> 00:05:33,360
okay so it's actually pretty easy to use

00:05:32,160 --> 00:05:36,560
this is some code

00:05:33,360 --> 00:05:39,360
uh that actually was written by dima

00:05:36,560 --> 00:05:40,000
it's on github i'll show you the link in

00:05:39,360 --> 00:05:42,800
a minute

00:05:40,000 --> 00:05:44,800
but it's very easy you just import

00:05:42,800 --> 00:05:47,919
everything from cases

00:05:44,800 --> 00:05:50,880
you point it to your type system file

00:05:47,919 --> 00:05:51,680
this exists in c takes in the type

00:05:50,880 --> 00:05:55,360
system

00:05:51,680 --> 00:05:57,759
module and then from there on

00:05:55,360 --> 00:05:58,479
it's really easy if you are familiar

00:05:57,759 --> 00:06:01,039
with the

00:05:58,479 --> 00:06:02,800
type system as it exists in java it's

00:06:01,039 --> 00:06:05,840
exactly the same

00:06:02,800 --> 00:06:06,800
in python all of the name spacing is

00:06:05,840 --> 00:06:08,960
identical

00:06:06,800 --> 00:06:10,319
so you can say i'm interested in this

00:06:08,960 --> 00:06:13,440
relationship type

00:06:10,319 --> 00:06:15,520
i put it in blue and everything after

00:06:13,440 --> 00:06:19,120
that is exactly as it would be

00:06:15,520 --> 00:06:23,039
package and class name or type name

00:06:19,120 --> 00:06:26,000
in java and this will uh

00:06:23,039 --> 00:06:26,000
cassis will then

00:06:26,080 --> 00:06:30,000
basically reach into the type system see

00:06:27,840 --> 00:06:33,360
what this is and it will load this type

00:06:30,000 --> 00:06:37,280
and then you can use within this type

00:06:33,360 --> 00:06:40,639
this temporal text relation everything

00:06:37,280 --> 00:06:44,160
that every field by name by uh

00:06:40,639 --> 00:06:46,960
address that you would recognize

00:06:44,160 --> 00:06:47,360
in c takes in java it's the same exact

00:06:46,960 --> 00:06:50,479
thing

00:06:47,360 --> 00:06:51,280
in python so if you've been unfortunate

00:06:50,479 --> 00:06:55,280
enough to

00:06:51,280 --> 00:06:57,680
use uh binary text relations

00:06:55,280 --> 00:06:59,199
you're familiar with the dot arg1 dot

00:06:57,680 --> 00:07:00,880
argument

00:06:59,199 --> 00:07:02,560
and you're going to use that exactly the

00:07:00,880 --> 00:07:05,759
same in python

00:07:02,560 --> 00:07:07,520
same with dot category if you've done it

00:07:05,759 --> 00:07:11,840
in java you can do it

00:07:07,520 --> 00:07:11,840
in python the naming is the same

00:07:12,080 --> 00:07:18,479
so that's it that was fast

00:07:15,199 --> 00:07:23,039
uh i'll take one question um

00:07:18,479 --> 00:07:25,759
but yes up here i've got the

00:07:23,039 --> 00:07:25,759
website for

00:07:26,400 --> 00:07:32,960
second cases and

00:07:29,520 --> 00:07:36,080
also demons code

00:07:32,960 --> 00:07:36,080
there we go okay

00:07:39,280 --> 00:07:42,800
okay peter says uh she did the same

00:07:41,280 --> 00:07:46,240
thing for ruby a few years ago

00:07:42,800 --> 00:07:49,840
i believe it it's it's a

00:07:46,240 --> 00:07:51,120
simple concept and um it's just great

00:07:49,840 --> 00:07:55,919
that someone else has

00:07:51,120 --> 00:07:57,759
gone ahead and done it for us honestly

00:07:55,919 --> 00:08:00,080
and that people have already been

00:07:57,759 --> 00:08:02,879
testing and working with it

00:08:00,080 --> 00:08:02,879
such as demon

00:08:05,039 --> 00:08:07,360
okay

00:08:08,240 --> 00:08:13,840
so peter are you ready

00:08:24,840 --> 00:08:31,440
uh

00:08:27,680 --> 00:08:31,440
great okay do you hear me

00:08:31,840 --> 00:08:36,560
yes okay cool all right uh my name is

00:08:35,440 --> 00:08:38,560
peter abramovic

00:08:36,560 --> 00:08:40,640
i'm a consultant to a team at the

00:08:38,560 --> 00:08:41,760
university of california san francisco's

00:08:40,640 --> 00:08:44,959
bakar

00:08:41,760 --> 00:08:46,800
computational health sciences institute

00:08:44,959 --> 00:08:48,399
and i've been a software designer

00:08:46,800 --> 00:08:50,560
architect in healthcare

00:08:48,399 --> 00:08:51,920
in california and internationally for

00:08:50,560 --> 00:08:54,560
many years

00:08:51,920 --> 00:08:56,160
and my role at the ucsf is to advise and

00:08:54,560 --> 00:08:57,839
implement a high volume

00:08:56,160 --> 00:08:59,440
uh clinical note processing

00:08:57,839 --> 00:09:02,800
infrastructure within

00:08:59,440 --> 00:09:05,040
a larger information pipeline and

00:09:02,800 --> 00:09:05,839
um i'm not going to dive into the

00:09:05,040 --> 00:09:07,440
details of c

00:09:05,839 --> 00:09:08,880
takes but give a kind of high level

00:09:07,440 --> 00:09:12,640
technical view

00:09:08,880 --> 00:09:14,800
of um how we uh solve the particular uh

00:09:12,640 --> 00:09:16,640
use cases that we had and i've been

00:09:14,800 --> 00:09:16,959
really impressed with what i've seen so

00:09:16,640 --> 00:09:19,360
far

00:09:16,959 --> 00:09:22,399
in the other presentations and also

00:09:19,360 --> 00:09:24,720
surprised at how different

00:09:22,399 --> 00:09:26,000
the implementations are and possibly a

00:09:24,720 --> 00:09:29,279
sign of my own age

00:09:26,000 --> 00:09:32,480
and and uh and also my

00:09:29,279 --> 00:09:36,080
uh review of some of the cluster

00:09:32,480 --> 00:09:39,120
uh orchestration software

00:09:36,080 --> 00:09:39,440
we did look at beam and spark but given

00:09:39,120 --> 00:09:42,399
the

00:09:39,440 --> 00:09:44,000
some of the constraints we had uh it

00:09:42,399 --> 00:09:44,560
seemed like doing something a little bit

00:09:44,000 --> 00:09:47,279
different

00:09:44,560 --> 00:09:48,839
uh might be the right solution for us

00:09:47,279 --> 00:09:50,880
oops

00:09:48,839 --> 00:09:53,440
wrong um

00:09:50,880 --> 00:09:55,360
so we're working in a multi-pronged

00:09:53,440 --> 00:09:57,120
initiative to make a lot of patient data

00:09:55,360 --> 00:10:00,160
available for research projects

00:09:57,120 --> 00:10:02,480
across a whole clinical spectrum rather

00:10:00,160 --> 00:10:04,320
than an individual project

00:10:02,480 --> 00:10:06,560
and one of the initiatives at the

00:10:04,320 --> 00:10:08,640
institute is called information commons

00:10:06,560 --> 00:10:10,399
and it consists of models and data and

00:10:08,640 --> 00:10:12,640
data science tools

00:10:10,399 --> 00:10:13,839
that enable researchers to discover

00:10:12,640 --> 00:10:16,320
cohorts of patients

00:10:13,839 --> 00:10:18,240
and work with their treatment data from

00:10:16,320 --> 00:10:20,079
the over 100 clinics

00:10:18,240 --> 00:10:22,640
and hospitals that we have around the

00:10:20,079 --> 00:10:22,640
bay area

00:10:27,120 --> 00:10:31,600
so if we drill down further the core

00:10:29,519 --> 00:10:33,440
asset of the information comments

00:10:31,600 --> 00:10:35,360
is the data mart which is built from

00:10:33,440 --> 00:10:36,560
structured patient data and extracted

00:10:35,360 --> 00:10:38,240
concepts

00:10:36,560 --> 00:10:40,640
from years of clinical notes that we

00:10:38,240 --> 00:10:42,480
have over thousands of patients

00:10:40,640 --> 00:10:44,320
at the moment we also have about 80

00:10:42,480 --> 00:10:46,560
million nodes that is similar to sounds

00:10:44,320 --> 00:10:48,000
like jeff's project queued up and

00:10:46,560 --> 00:10:49,680
they're being

00:10:48,000 --> 00:10:51,600
traditionally there's a stream of new

00:10:49,680 --> 00:10:54,880
notes which around

00:10:51,600 --> 00:10:57,760
amounts to about 1 million per month

00:10:54,880 --> 00:10:59,920
and as our infrastructure was getting

00:10:57,760 --> 00:11:02,720
ready and being scaled out

00:10:59,920 --> 00:11:04,640
covet came along and this quickly became

00:11:02,720 --> 00:11:05,680
a top priority amongst the researchers

00:11:04,640 --> 00:11:07,040
in our group

00:11:05,680 --> 00:11:09,760
and suddenly we were getting a

00:11:07,040 --> 00:11:11,519
completely new stream of notes

00:11:09,760 --> 00:11:13,600
and because these patients were being

00:11:11,519 --> 00:11:15,839
studied under a different irb

00:11:13,600 --> 00:11:16,959
with different regulatory standards we

00:11:15,839 --> 00:11:18,880
had basically

00:11:16,959 --> 00:11:21,519
another cue and a new set of technical

00:11:18,880 --> 00:11:21,519
requirements

00:11:26,320 --> 00:11:29,440
here's a quick snapshot of some of our

00:11:28,160 --> 00:11:32,160
design requirements

00:11:29,440 --> 00:11:33,120
um thinking about that 80 million uh

00:11:32,160 --> 00:11:35,120
note backlog

00:11:33,120 --> 00:11:37,120
plus a million of new nodes per month

00:11:35,120 --> 00:11:40,240
plus a new code stream

00:11:37,120 --> 00:11:42,160
and we had some constraints we didn't

00:11:40,240 --> 00:11:44,399
have a lot of machine power and we had

00:11:42,160 --> 00:11:46,079
extremely tight control over

00:11:44,399 --> 00:11:49,440
inner machine communications and

00:11:46,079 --> 00:11:51,839
visibility to other ucsf assets

00:11:49,440 --> 00:11:53,920
um it had to run at full throttle kind

00:11:51,839 --> 00:11:54,839
of inside of a black box and it had to

00:11:53,920 --> 00:11:57,680
run

00:11:54,839 --> 00:12:00,720
autonomously for weeks or months

00:11:57,680 --> 00:12:03,279
providing some status but we had a kind

00:12:00,720 --> 00:12:05,200
of mandatory two-factor

00:12:03,279 --> 00:12:08,560
authentication access across the

00:12:05,200 --> 00:12:10,480
machines that are within our phi zone

00:12:08,560 --> 00:12:11,839
so that made the use of orchestration

00:12:10,480 --> 00:12:14,320
managers like

00:12:11,839 --> 00:12:16,560
brook apache brooklyn which we looked at

00:12:14,320 --> 00:12:19,200
a bit problematic and we also needed to

00:12:16,560 --> 00:12:20,720
solve the umls authentication issue

00:12:19,200 --> 00:12:23,760
since the machines that were running c

00:12:20,720 --> 00:12:27,040
tapes could not access the internet

00:12:23,760 --> 00:12:28,560
and also of course the problem is

00:12:27,040 --> 00:12:30,320
we weren't sure how the data was going

00:12:28,560 --> 00:12:32,240
to be used by the researchers

00:12:30,320 --> 00:12:34,160
and so we needed to anticipate different

00:12:32,240 --> 00:12:35,760
downstream data models and query

00:12:34,160 --> 00:12:38,240
mechanisms

00:12:35,760 --> 00:12:39,680
so we just needed to improvise and knew

00:12:38,240 --> 00:12:42,720
that our researchers would be

00:12:39,680 --> 00:12:42,720
improvising as well

00:12:44,800 --> 00:12:48,720
firstly we decided to on a kind of nosql

00:12:47,519 --> 00:12:51,519
database paradigm

00:12:48,720 --> 00:12:53,120
using and it's well suited to

00:12:51,519 --> 00:12:55,360
handling a mixture of

00:12:53,120 --> 00:12:57,200
millions of text blobs and serialized

00:12:55,360 --> 00:12:59,360
row oriented data

00:12:57,200 --> 00:13:01,200
and as you know it pro it has amazing

00:12:59,360 --> 00:13:02,959
performance if it's given enough memory

00:13:01,200 --> 00:13:05,120
to do its job

00:13:02,959 --> 00:13:06,639
and if you're not familiar with nosql

00:13:05,120 --> 00:13:07,920
then you know when i use the word

00:13:06,639 --> 00:13:11,839
collection later on

00:13:07,920 --> 00:13:14,000
think a table of jason rose

00:13:11,839 --> 00:13:14,959
so uh let me describe roughly what we

00:13:14,000 --> 00:13:17,200
did

00:13:14,959 --> 00:13:18,639
upstream of the c takes element is an

00:13:17,200 --> 00:13:20,560
infrastructure that collects the

00:13:18,639 --> 00:13:23,360
clinical notes from a number of sources

00:13:20,560 --> 00:13:24,440
from around the ucsf medical centers

00:13:23,360 --> 00:13:26,560
these notes are run through a

00:13:24,440 --> 00:13:28,160
de-identification system

00:13:26,560 --> 00:13:30,079
that was developed also within the

00:13:28,160 --> 00:13:31,040
information commons and i'm sure that

00:13:30,079 --> 00:13:35,839
that would warrant

00:13:31,040 --> 00:13:35,839
a another presentation one day

00:13:38,480 --> 00:13:41,519
so batches of notes that are running in

00:13:40,480 --> 00:13:44,000
the

00:13:41,519 --> 00:13:45,920
high hundreds of thousands or low

00:13:44,000 --> 00:13:47,600
millions are fetched into the sea takes

00:13:45,920 --> 00:13:50,800
area sorry i'm in the wrong

00:13:47,600 --> 00:13:52,480
i'm in the wrong slide here by

00:13:50,800 --> 00:13:53,920
they're fetched into the sea takes area

00:13:52,480 --> 00:13:56,480
by an import process

00:13:53,920 --> 00:13:58,320
and one of the responsibilities of this

00:13:56,480 --> 00:14:00,800
importing mechanism is to prop

00:13:58,320 --> 00:14:02,000
propagate the deletion of raw and

00:14:00,800 --> 00:14:05,120
extracted information

00:14:02,000 --> 00:14:07,360
for patients that after the fact it was

00:14:05,120 --> 00:14:09,279
decided that their data that their data

00:14:07,360 --> 00:14:10,800
even if it's identified had to be

00:14:09,279 --> 00:14:13,920
withdrawn so

00:14:10,800 --> 00:14:14,480
so part of this process is kind of um is

00:14:13,920 --> 00:14:16,800
uh

00:14:14,480 --> 00:14:19,440
pruning data that has already been

00:14:16,800 --> 00:14:19,440
extracted

00:14:19,839 --> 00:14:22,079
okay

00:14:23,680 --> 00:14:27,199
so we've packaged ctax as a

00:14:25,519 --> 00:14:28,959
multi-pipeline web service

00:14:27,199 --> 00:14:30,720
running in a generously configured

00:14:28,959 --> 00:14:31,839
machine but nothing like some of the

00:14:30,720 --> 00:14:34,480
spark clusters

00:14:31,839 --> 00:14:35,680
that have been spoken of and on another

00:14:34,480 --> 00:14:37,839
machine we have a number of

00:14:35,680 --> 00:14:39,839
very lightweight client processes and

00:14:37,839 --> 00:14:41,360
each one repeatedly calls the c-takes

00:14:39,839 --> 00:14:43,600
web service with a note

00:14:41,360 --> 00:14:45,360
and retrieves back the output as a json

00:14:43,600 --> 00:14:48,240
formatted message which is written

00:14:45,360 --> 00:14:49,199
into the repository and we

00:14:48,240 --> 00:14:51,279
co-located

00:14:49,199 --> 00:14:53,120
the client processes on the same machine

00:14:51,279 --> 00:14:55,680
as the primary instance to

00:14:53,120 --> 00:14:57,440
maximize bandwidth

00:14:55,680 --> 00:14:59,839
and on the machines we have available

00:14:57,440 --> 00:15:02,000
today we run one large ctax server

00:14:59,839 --> 00:15:03,040
process that hosts multiple pipeline

00:15:02,000 --> 00:15:05,360
instances

00:15:03,040 --> 00:15:07,199
about 30 client and we have about 30

00:15:05,360 --> 00:15:09,040
clients on the other machine

00:15:07,199 --> 00:15:11,279
and our combined throughput averages at

00:15:09,040 --> 00:15:14,480
about 16 notes per second which is

00:15:11,279 --> 00:15:17,199
1.3 million notes per day and these

00:15:14,480 --> 00:15:19,120
notes can vary from a few sentences to

00:15:17,199 --> 00:15:21,760
10 or more pages of really dense

00:15:19,120 --> 00:15:24,560
clinical language

00:15:21,760 --> 00:15:25,519
i think our average is about us 7 000

00:15:24,560 --> 00:15:27,920
bytes

00:15:25,519 --> 00:15:31,040
per node but they but they come in all

00:15:27,920 --> 00:15:31,040
sizes as you well know

00:15:31,440 --> 00:15:36,639
um and you've probably noticed that i

00:15:33,759 --> 00:15:40,160
also have a umls proxy sitting there

00:15:36,639 --> 00:15:41,680
at the edge of the phi zone and that's

00:15:40,160 --> 00:15:43,440
another bit of infrastructure which we

00:15:41,680 --> 00:15:46,399
built that serves to relay

00:15:43,440 --> 00:15:49,120
umls authentication requests from inside

00:15:46,399 --> 00:15:51,839
of our phi zone to the outside world

00:15:49,120 --> 00:15:53,199
where it calls the nlm's authentication

00:15:51,839 --> 00:15:55,360
api

00:15:53,199 --> 00:15:57,440
and this is actually used by a couple of

00:15:55,360 --> 00:15:57,920
different implementations that we have

00:15:57,440 --> 00:16:02,399
that we

00:15:57,920 --> 00:16:02,399
of ctakes in our in our setup

00:16:02,880 --> 00:16:06,480
so um what we did for c takes rather

00:16:06,160 --> 00:16:08,000
than

00:16:06,480 --> 00:16:09,759
trying to run the single threaded

00:16:08,000 --> 00:16:11,759
process uh or use

00:16:09,759 --> 00:16:12,880
the synchronization that was available

00:16:11,759 --> 00:16:14,560
of the

00:16:12,880 --> 00:16:16,079
multi-threadedness that was available

00:16:14,560 --> 00:16:19,839
within the pipeline

00:16:16,079 --> 00:16:24,399
itself is i built a new

00:16:19,839 --> 00:16:26,399
rest implementation using spark java

00:16:24,399 --> 00:16:28,079
after looking at some of the other risk

00:16:26,399 --> 00:16:29,440
implementations that were available in

00:16:28,079 --> 00:16:33,040
the ctx

00:16:29,440 --> 00:16:33,759
community and we chose to do our own for

00:16:33,040 --> 00:16:35,600
stability

00:16:33,759 --> 00:16:37,600
and ease of modification and for

00:16:35,600 --> 00:16:39,360
performance

00:16:37,600 --> 00:16:42,079
we have a couple of different apis that

00:16:39,360 --> 00:16:45,440
will return either the full jcads

00:16:42,079 --> 00:16:47,920
or a concept level data which i will

00:16:45,440 --> 00:16:49,440
describe later on

00:16:47,920 --> 00:16:51,120
and a key choice in terms of the

00:16:49,440 --> 00:16:52,480
performance on the server side was how

00:16:51,120 --> 00:16:54,000
the threading would be managed for

00:16:52,480 --> 00:16:56,320
optimum throughput

00:16:54,000 --> 00:16:58,560
and um as you know that ctek's native

00:16:56,320 --> 00:17:00,320
code implements an optional

00:16:58,560 --> 00:17:02,480
and rather simple approach to threading

00:17:00,320 --> 00:17:04,880
by using java synchronization

00:17:02,480 --> 00:17:06,799
around shared resources and what i found

00:17:04,880 --> 00:17:08,079
was that having concurrency control at a

00:17:06,799 --> 00:17:10,799
really granular level

00:17:08,079 --> 00:17:12,880
of text processing processing caused a

00:17:10,799 --> 00:17:14,400
performance degradation as the server

00:17:12,880 --> 00:17:16,160
load increased

00:17:14,400 --> 00:17:17,520
and our approach was to put the thread

00:17:16,160 --> 00:17:19,600
isolation at a much

00:17:17,520 --> 00:17:21,439
less granular level right up at the node

00:17:19,600 --> 00:17:23,679
itself

00:17:21,439 --> 00:17:25,520
so in our c takes implementation we

00:17:23,679 --> 00:17:26,240
maintain a thread pool and each pool

00:17:25,520 --> 00:17:28,640
member

00:17:26,240 --> 00:17:30,880
has its own z-takes pipeline and

00:17:28,640 --> 00:17:33,280
annotation manager

00:17:30,880 --> 00:17:35,200
so it uses more memory but we've had no

00:17:33,280 --> 00:17:37,360
conflicts and no performance issues no

00:17:35,200 --> 00:17:40,400
matter how heavily the sea takes process

00:17:37,360 --> 00:17:42,960
is being hammered um

00:17:40,400 --> 00:17:45,280
our modifications also allow the ability

00:17:42,960 --> 00:17:46,799
to dynamically upsize or downsize the

00:17:45,280 --> 00:17:49,200
number of cool elements

00:17:46,799 --> 00:17:50,400
within the available memory according to

00:17:49,200 --> 00:17:52,640
the size of the document

00:17:50,400 --> 00:17:53,760
so we partition off all of our really

00:17:52,640 --> 00:17:56,400
long notes

00:17:53,760 --> 00:17:58,559
uh and run them separately when we're

00:17:56,400 --> 00:18:01,600
when we've kind of configured the

00:17:58,559 --> 00:18:03,440
server to run with fewer pipelines and

00:18:01,600 --> 00:18:05,440
more memory

00:18:03,440 --> 00:18:08,000
and we also staged another instance of

00:18:05,440 --> 00:18:10,640
this uh ctx as a web service

00:18:08,000 --> 00:18:12,160
and we distribute client applications to

00:18:10,640 --> 00:18:13,840
students or researchers

00:18:12,160 --> 00:18:15,600
that want to process their own notes

00:18:13,840 --> 00:18:17,600
that are kind of outside this big data

00:18:15,600 --> 00:18:19,840
mart

00:18:17,600 --> 00:18:19,840
queue

00:18:21,200 --> 00:18:25,120
so on the client side like i said we

00:18:23,200 --> 00:18:27,120
opted for running these multiple single

00:18:25,120 --> 00:18:27,760
threaded java client processes that are

00:18:27,120 --> 00:18:30,799
managed by

00:18:27,760 --> 00:18:32,240
new parallels a very simple very

00:18:30,799 --> 00:18:34,960
straightforward

00:18:32,240 --> 00:18:37,039
approach no kind of heavy computing

00:18:34,960 --> 00:18:38,720
infrastructure

00:18:37,039 --> 00:18:40,720
and to avoid sort of hammering the

00:18:38,720 --> 00:18:41,200
database for the available nodes left to

00:18:40,720 --> 00:18:43,520
process

00:18:41,200 --> 00:18:45,039
each client reserves a group of free

00:18:43,520 --> 00:18:46,160
nodes and it works on them without any

00:18:45,039 --> 00:18:48,160
conflicts

00:18:46,160 --> 00:18:49,919
until it's done with that batch and then

00:18:48,160 --> 00:18:52,080
it catches another batch

00:18:49,919 --> 00:18:54,320
so the potential conflict between client

00:18:52,080 --> 00:18:57,280
instances is reduced only to the moment

00:18:54,320 --> 00:18:59,600
when they're trying to fetch a new batch

00:18:57,280 --> 00:19:01,520
but because of the indeterminate time it

00:18:59,600 --> 00:19:03,280
takes to process a note and the size of

00:19:01,520 --> 00:19:05,200
our reservation queue

00:19:03,280 --> 00:19:06,480
these are rarely concurrent so there's

00:19:05,200 --> 00:19:09,520
very little competition

00:19:06,480 --> 00:19:10,080
for resources so from a high level

00:19:09,520 --> 00:19:12,559
perspective

00:19:10,080 --> 00:19:13,919
the total process flow is really fault

00:19:12,559 --> 00:19:17,679
tolerant

00:19:13,919 --> 00:19:19,600
um like i said the client process

00:19:17,679 --> 00:19:23,520
is not concerned at all with

00:19:19,600 --> 00:19:26,000
authentication that's done by the umls

00:19:23,520 --> 00:19:27,600
element in the server and it's done once

00:19:26,000 --> 00:19:29,919
per 24 hours per

00:19:27,600 --> 00:19:31,919
per user in but in this particular use

00:19:29,919 --> 00:19:32,640
case there is only one user in that

00:19:31,919 --> 00:19:35,200
other

00:19:32,640 --> 00:19:36,320
uh ctx instance which is available for

00:19:35,200 --> 00:19:39,039
researchers

00:19:36,320 --> 00:19:40,720
and students that one does do individual

00:19:39,039 --> 00:19:44,799
authentication for its

00:19:40,720 --> 00:19:44,799
client client-side users

00:19:46,400 --> 00:19:49,600
i know you've had some great

00:19:47,440 --> 00:19:51,520
presentations on dictionary and pipeline

00:19:49,600 --> 00:19:53,919
customization and z-takes but

00:19:51,520 --> 00:19:54,720
i thought i'd just say a few words too

00:19:53,919 --> 00:19:56,960
um

00:19:54,720 --> 00:19:58,160
and uh so we started with the out of the

00:19:56,960 --> 00:20:00,000
box configuration

00:19:58,160 --> 00:20:01,280
as far as dictionaries and the standard

00:20:00,000 --> 00:20:03,600
pipeline

00:20:01,280 --> 00:20:06,080
um and of course we noticed like

00:20:03,600 --> 00:20:07,840
everyone does that certain artifacts are

00:20:06,080 --> 00:20:09,919
concepts that we're under and over

00:20:07,840 --> 00:20:12,880
specified missing negations

00:20:09,919 --> 00:20:13,840
vocabulary items that have um and things

00:20:12,880 --> 00:20:16,559
that have motivated

00:20:13,840 --> 00:20:18,320
us to start making some changes these

00:20:16,559 --> 00:20:20,159
had to kind of come late in the process

00:20:18,320 --> 00:20:22,400
just due to our timelines

00:20:20,159 --> 00:20:24,240
so as of now we've built a new

00:20:22,400 --> 00:20:27,600
dictionary that includes the

00:20:24,240 --> 00:20:28,640
hgnc gene terms and we've added social

00:20:27,600 --> 00:20:31,679
and behavioral

00:20:28,640 --> 00:20:34,000
behavioral vocabulary as well um

00:20:31,679 --> 00:20:35,039
we've added a mechanism that prunes or

00:20:34,000 --> 00:20:37,840
adds synonyms

00:20:35,039 --> 00:20:38,960
uh to the main dictionary that that we

00:20:37,840 --> 00:20:41,440
created using the

00:20:38,960 --> 00:20:43,280
dictionary creator and we're also making

00:20:41,440 --> 00:20:46,080
use of some built-in but not very

00:20:43,280 --> 00:20:48,000
uh heavily publicized uh capabilities

00:20:46,080 --> 00:20:50,240
that the

00:20:48,000 --> 00:20:52,640
that the dictionary lookup mechanism has

00:20:50,240 --> 00:20:54,640
which is the ability to blacklist terms

00:20:52,640 --> 00:20:56,240
to blacklist concepts or even case

00:20:54,640 --> 00:20:59,600
sensitive manifestations

00:20:56,240 --> 00:21:03,200
certain terms we've also used the bsv

00:20:59,600 --> 00:21:04,799
mechanism and we've experimented with

00:21:03,200 --> 00:21:08,000
different negation tools

00:21:04,799 --> 00:21:10,080
and so far the negative negator

00:21:08,000 --> 00:21:11,840
seems to be the best performing one out

00:21:10,080 --> 00:21:15,679
of the box it has

00:21:11,840 --> 00:21:17,840
uh one uh it has one

00:21:15,679 --> 00:21:19,440
use case that it does not perform well

00:21:17,840 --> 00:21:22,240
on where it's kind of too eager and

00:21:19,440 --> 00:21:24,799
tries to negate everything in a sentence

00:21:22,240 --> 00:21:26,240
but i have a i have a scheme for solving

00:21:24,799 --> 00:21:27,760
that and i'm i'm going to be working on

00:21:26,240 --> 00:21:30,000
that next year

00:21:27,760 --> 00:21:30,960
um but negation is definitely an

00:21:30,000 --> 00:21:32,720
interesting topic

00:21:30,960 --> 00:21:35,120
uh and it's sort of like a gift that

00:21:32,720 --> 00:21:37,280
never stops giving

00:21:35,120 --> 00:21:37,280
so

00:21:39,360 --> 00:21:43,120
back to the workflow so after all the

00:21:41,760 --> 00:21:45,200
notes of a given batch are

00:21:43,120 --> 00:21:47,280
processed or at some other milestone

00:21:45,200 --> 00:21:48,880
that we've configured

00:21:47,280 --> 00:21:50,400
the concepts are exported into a

00:21:48,880 --> 00:21:52,480
slightly modified form

00:21:50,400 --> 00:21:54,880
that's kind of staging database and from

00:21:52,480 --> 00:21:56,799
there they're copied into a different

00:21:54,880 --> 00:21:58,080
instance of which is available to

00:21:56,799 --> 00:21:59,840
the researchers has its own

00:21:58,080 --> 00:22:02,320
authentication scheme

00:21:59,840 --> 00:22:02,320
and everything

00:22:04,240 --> 00:22:07,440
so i'll spend a few minutes on what

00:22:05,600 --> 00:22:10,320
we've done with the output of c takes

00:22:07,440 --> 00:22:12,559
so within the server i mentioned that we

00:22:10,320 --> 00:22:14,880
can fetch via one api we can fetch the

00:22:12,559 --> 00:22:18,000
whole jcats but with another one

00:22:14,880 --> 00:22:19,919
um we do some kind of re repackaging

00:22:18,000 --> 00:22:21,360
and so we start with all the classic

00:22:19,919 --> 00:22:23,120
identified annotations

00:22:21,360 --> 00:22:25,360
the medication mentioned the procedure

00:22:23,120 --> 00:22:28,480
mentioned the lab mansion and so on

00:22:25,360 --> 00:22:31,039
and we integrate data from you the umls

00:22:28,480 --> 00:22:32,240
annotations parts of speech relationship

00:22:31,039 --> 00:22:35,280
and so on

00:22:32,240 --> 00:22:37,679
and we create these concept objects um

00:22:35,280 --> 00:22:39,440
and a fully populated concept contains

00:22:37,679 --> 00:22:42,159
the range text its offsets

00:22:39,440 --> 00:22:43,600
its canonical text its history in

00:22:42,159 --> 00:22:45,520
negation statuses

00:22:43,600 --> 00:22:47,440
cooley snomed or extraordinary all that

00:22:45,520 --> 00:22:50,000
stuff um

00:22:47,440 --> 00:22:52,400
and so the api returns a collection of

00:22:50,000 --> 00:22:53,919
these concepts for each note

00:22:52,400 --> 00:22:56,159
and we're in the middle of some

00:22:53,919 --> 00:22:57,039
conversations and experiments on the

00:22:56,159 --> 00:22:59,200
ideal layout

00:22:57,039 --> 00:23:01,440
of the exported concept data to help the

00:22:59,200 --> 00:23:03,280
researchers get on with their work and

00:23:01,440 --> 00:23:04,640
here i'd like to say that i really like

00:23:03,280 --> 00:23:07,840
the idea of using

00:23:04,640 --> 00:23:09,280
solar as a kind of an exploration tool

00:23:07,840 --> 00:23:11,840
it sounds great i

00:23:09,280 --> 00:23:14,000
hope we get a chance to look at it too

00:23:11,840 --> 00:23:16,000
so in this slide i'm demonstrating kind

00:23:14,000 --> 00:23:18,159
of our flat model

00:23:16,000 --> 00:23:20,720
where the number of kind of concept

00:23:18,159 --> 00:23:24,159
records per note

00:23:20,720 --> 00:23:25,600
are in the tens uh of records per note

00:23:24,159 --> 00:23:26,880
and we also of course maintain a

00:23:25,600 --> 00:23:28,960
separate collection

00:23:26,880 --> 00:23:31,520
for the raw text and for the note level

00:23:28,960 --> 00:23:33,919
metadata

00:23:31,520 --> 00:23:35,360
and then you know some of it's it's a

00:23:33,919 --> 00:23:37,039
model that's more familiar to

00:23:35,360 --> 00:23:39,600
researchers who are used to relational

00:23:37,039 --> 00:23:42,240
databases but it has this downside

00:23:39,600 --> 00:23:44,400
of exploding the memory size of concept

00:23:42,240 --> 00:23:46,559
related indices and requiring

00:23:44,400 --> 00:23:47,840
queries to bring records of a given note

00:23:46,559 --> 00:23:49,600
back you know

00:23:47,840 --> 00:23:51,520
sort of joins to bring the records of a

00:23:49,600 --> 00:23:53,679
given note back together

00:23:51,520 --> 00:23:55,679
and and our database now has well over a

00:23:53,679 --> 00:23:58,159
billion concepts so

00:23:55,679 --> 00:24:00,400
this kind of gathering is not at all

00:23:58,159 --> 00:24:02,159
trivial

00:24:00,400 --> 00:24:04,480
and it's a billion records and we're

00:24:02,159 --> 00:24:07,760
only a third of the way through the

00:24:04,480 --> 00:24:09,520
our data um

00:24:07,760 --> 00:24:11,919
and the other model that we've looked at

00:24:09,520 --> 00:24:12,320
is a kind of a shallow hierarchy where

00:24:11,919 --> 00:24:15,840
we

00:24:12,320 --> 00:24:18,240
where each each note is represented as a

00:24:15,840 --> 00:24:20,480
collection of collections and a

00:24:18,240 --> 00:24:22,080
shallow tree and so there's a collection

00:24:20,480 --> 00:24:23,279
of concepts of each of the standard

00:24:22,080 --> 00:24:25,760
clinical domains or

00:24:23,279 --> 00:24:27,039
diagnosis signs and symptoms medications

00:24:25,760 --> 00:24:28,640
and so on

00:24:27,039 --> 00:24:30,320
and so you can see how it's really easy

00:24:28,640 --> 00:24:32,320
to pull back the

00:24:30,320 --> 00:24:35,279
per node or per patient longitudinal

00:24:32,320 --> 00:24:37,679
view if you need to do that

00:24:35,279 --> 00:24:39,360
but on the downside mongo's ability to

00:24:37,679 --> 00:24:41,120
query on features of

00:24:39,360 --> 00:24:42,799
sub collections it has a bit of a

00:24:41,120 --> 00:24:45,520
steeper learning curve

00:24:42,799 --> 00:24:46,320
and it gets less efficient in its use of

00:24:45,520 --> 00:24:49,679
indices

00:24:46,320 --> 00:24:52,640
um when you're diving into into

00:24:49,679 --> 00:24:53,679
sub collections so um it's got those

00:24:52,640 --> 00:24:55,919
disadvantages

00:24:53,679 --> 00:24:57,679
but on the other hand those tree of

00:24:55,919 --> 00:24:58,880
concepts there's one to one with the

00:24:57,679 --> 00:25:02,880
note so it's

00:24:58,880 --> 00:25:02,880
it's a it's quite nice to work with

00:25:06,240 --> 00:25:11,600
um so um

00:25:09,360 --> 00:25:13,600
we have a ways to go kind of in terms of

00:25:11,600 --> 00:25:16,000
of improving our configuration

00:25:13,600 --> 00:25:16,640
but we have the information in place to

00:25:16,000 --> 00:25:18,880
see

00:25:16,640 --> 00:25:21,039
that our processing is working and it's

00:25:18,880 --> 00:25:23,400
getting done 24 by seven with a minimum

00:25:21,039 --> 00:25:26,559
of supervision

00:25:23,400 --> 00:25:28,080
icc takes is a swiss army knife i'm sure

00:25:26,559 --> 00:25:30,880
it's an overused

00:25:28,080 --> 00:25:32,640
uh metaphor but you've tried luck you

00:25:30,880 --> 00:25:34,640
know you on a knife like that you've got

00:25:32,640 --> 00:25:36,080
lots of blades and tools and the ctix

00:25:34,640 --> 00:25:37,679
repository has

00:25:36,080 --> 00:25:39,279
lots of different tools for you to work

00:25:37,679 --> 00:25:40,799
with and um

00:25:39,279 --> 00:25:42,400
so you just have to find a way of

00:25:40,799 --> 00:25:44,559
matching the tool

00:25:42,400 --> 00:25:46,320
to what is in the what's available and

00:25:44,559 --> 00:25:48,080
what you can configure

00:25:46,320 --> 00:25:49,919
i just wanted to say that i had fun

00:25:48,080 --> 00:25:50,480
years ago i got stuck in the nevada

00:25:49,919 --> 00:25:53,200
desert

00:25:50,480 --> 00:25:54,720
with an ancient volkswagen bus but i

00:25:53,200 --> 00:25:56,480
found a way of adjusting the engine

00:25:54,720 --> 00:25:58,000
timing with the swiss army knife and the

00:25:56,480 --> 00:26:00,480
tail light bulb

00:25:58,000 --> 00:26:02,000
and i think that in the sea takes

00:26:00,480 --> 00:26:03,840
repository you'll probably find

00:26:02,000 --> 00:26:05,279
a lot of things that that you can use

00:26:03,840 --> 00:26:06,240
and we've also seen some really

00:26:05,279 --> 00:26:09,279
interesting

00:26:06,240 --> 00:26:11,840
additions from from other

00:26:09,279 --> 00:26:13,279
software packages to do that so and i

00:26:11,840 --> 00:26:16,240
want to thank this fantastic

00:26:13,279 --> 00:26:16,480
user community that we have for helping

00:26:16,240 --> 00:26:18,159
us

00:26:16,480 --> 00:26:20,799
out and i'm sure helping a lot of you

00:26:18,159 --> 00:26:20,799
out as well

00:26:21,760 --> 00:26:25,120
and to thank you for your patience

00:26:23,760 --> 00:26:27,039
because i know this is a very end of the

00:26:25,120 --> 00:26:29,279
sea takes track and to thank sean

00:26:27,039 --> 00:26:31,600
for leading the ctek's effort and for

00:26:29,279 --> 00:26:33,200
his infinite patience and handling

00:26:31,600 --> 00:26:34,799
all the questions that are coming from

00:26:33,200 --> 00:26:39,279
around the planet so

00:26:34,799 --> 00:26:42,159
i'll turn it back to you sean

00:26:39,279 --> 00:26:42,159
thank you very much

00:26:46,400 --> 00:26:49,440
i don't see any questions in the chat

00:26:49,120 --> 00:26:53,919
but

00:26:49,440 --> 00:26:56,000
uh this is the end of apache con

00:26:53,919 --> 00:26:58,080
so this is your last chance to ask

00:26:56,000 --> 00:27:01,200
questions about anything

00:26:58,080 --> 00:27:02,159
um not just for these presentations but

00:27:01,200 --> 00:27:06,080
for anything that's

00:27:02,159 --> 00:27:08,799
going on the last two days um

00:27:06,080 --> 00:27:21,840
ask for any other news about sea takes

00:27:08,799 --> 00:27:21,840
or what have you

00:27:24,640 --> 00:27:28,399
okay on the horizon for c takes in terms

00:27:27,039 --> 00:27:31,840
of new milestones

00:27:28,399 --> 00:27:35,120
um so we would

00:27:31,840 --> 00:27:38,399
like to get a version five out

00:27:35,120 --> 00:27:39,760
asap i think they're if you've been

00:27:38,399 --> 00:27:42,240
watching this week you've

00:27:39,760 --> 00:27:44,399
realized that there's a lot of new work

00:27:42,240 --> 00:27:46,399
a lot of

00:27:44,399 --> 00:27:47,600
big items that have gone into seatage

00:27:46,399 --> 00:27:49,360
recently

00:27:47,600 --> 00:27:51,679
well and by recently i mean over the

00:27:49,360 --> 00:27:56,559
last several years

00:27:51,679 --> 00:27:59,760
uh and as jeff and jared indicated

00:27:56,559 --> 00:28:01,760
people want to be able to point to a an

00:27:59,760 --> 00:28:03,360
actual point release something that can

00:28:01,760 --> 00:28:06,559
be referenced and

00:28:03,360 --> 00:28:08,399
uh getting cpa 5 out there would be

00:28:06,559 --> 00:28:10,000
extremely important to a lot of people

00:28:08,399 --> 00:28:12,640
so

00:28:10,000 --> 00:28:15,200
i for one want to make it happen but i'm

00:28:12,640 --> 00:28:17,120
not in this game alone

00:28:15,200 --> 00:28:18,399
everything in sea takes is done by a

00:28:17,120 --> 00:28:21,279
team uh

00:28:18,399 --> 00:28:23,760
and by team i don't mean just people at

00:28:21,279 --> 00:28:26,799
boston children's hospital where i work

00:28:23,760 --> 00:28:27,600
but you know around the globe and to get

00:28:26,799 --> 00:28:30,880
c takes

00:28:27,600 --> 00:28:33,919
version five out there we need

00:28:30,880 --> 00:28:37,440
to have people volunteer to

00:28:33,919 --> 00:28:40,559
do some testing uh do some documentation

00:28:37,440 --> 00:28:45,360
and you know give it stamps of approval

00:28:40,559 --> 00:28:47,919
when all is said and done

00:28:45,360 --> 00:28:49,600
so i can't say when that milestone will

00:28:47,919 --> 00:28:52,240
appear but

00:28:49,600 --> 00:28:59,840
like i said i would like to get it done

00:28:52,240 --> 00:28:59,840
very very easily

00:29:02,080 --> 00:29:08,000
okay i'm not sure where to pick up on

00:29:05,120 --> 00:29:08,000
the chat anymore

00:29:10,559 --> 00:29:13,840
yeah some of the items i can't tell

00:29:12,080 --> 00:29:15,840
whether they're for

00:29:13,840 --> 00:29:17,520
this presentation or in general it's

00:29:15,840 --> 00:29:20,559
they look like they're general questions

00:29:17,520 --> 00:29:21,840
right can you use this model to get

00:29:20,559 --> 00:29:25,200
medical text search

00:29:21,840 --> 00:29:29,039
using semantic concepts and relation

00:29:25,200 --> 00:29:29,039
extracted using an annotation

00:29:32,159 --> 00:29:35,200
that might be for you

00:29:35,679 --> 00:29:43,279
peter uh yeah well

00:29:39,600 --> 00:29:45,120
okay um probably the the relations

00:29:43,279 --> 00:29:48,480
between concepts are things

00:29:45,120 --> 00:29:51,200
that will come later i mean um

00:29:48,480 --> 00:29:51,760
my remit was to build an infrastructure

00:29:51,200 --> 00:29:53,440
to do

00:29:51,760 --> 00:29:55,200
that sort of heavy lifting and get

00:29:53,440 --> 00:29:55,440
through this very large set of notes and

00:29:55,200 --> 00:29:58,880
i

00:29:55,440 --> 00:30:00,880
i'm fully expecting that once the

00:29:58,880 --> 00:30:02,080
researchers start working with the notes

00:30:00,880 --> 00:30:04,080
and especially

00:30:02,080 --> 00:30:05,520
those researchers that need to kind of

00:30:04,080 --> 00:30:07,600
reconstruct

00:30:05,520 --> 00:30:09,679
the longitudinal view that we're going

00:30:07,600 --> 00:30:12,080
to be making changes we're going to be

00:30:09,679 --> 00:30:12,799
you know fetching more information or

00:30:12,080 --> 00:30:16,399
doing

00:30:12,799 --> 00:30:19,279
some options such as uh saving off this

00:30:16,399 --> 00:30:20,080
the jkz and then reprocessing it later

00:30:19,279 --> 00:30:23,760
on

00:30:20,080 --> 00:30:26,960
the the size i mean the the uh

00:30:23,760 --> 00:30:30,399
thinking of storing 80 million jake has

00:30:26,960 --> 00:30:30,880
is a is a very very large i mean a very

00:30:30,399 --> 00:30:34,080
large

00:30:30,880 --> 00:30:35,440
data asset and um and so

00:30:34,080 --> 00:30:37,840
that's something i think we would have

00:30:35,440 --> 00:30:40,960
to look at you know we'd have to find

00:30:37,840 --> 00:30:45,919
an active use case in order to do it and

00:30:40,960 --> 00:30:45,919
justify the from a budgetary perspective

00:30:49,120 --> 00:30:54,960
uh the question from gergana um

00:30:52,799 --> 00:30:57,120
uh not in well i don't know what the

00:30:54,960 --> 00:30:59,679
entire uc system is it's this is

00:30:57,120 --> 00:31:01,360
the i the the institute this is probably

00:30:59,679 --> 00:31:04,720
a question better answered by

00:31:01,360 --> 00:31:06,799
my manager eugenia ruttenberg um and she

00:31:04,720 --> 00:31:09,440
i don't she's on the call she can

00:31:06,799 --> 00:31:11,120
um she can put it in the chat box but

00:31:09,440 --> 00:31:12,000
this is sort of within the purview of

00:31:11,120 --> 00:31:15,200
this bakar

00:31:12,000 --> 00:31:16,640
institute which is mostly involved in

00:31:15,200 --> 00:31:21,360
research rather than

00:31:16,640 --> 00:31:24,960
uh day-to-day patient care

00:31:21,360 --> 00:31:28,000
we would love to do probably some

00:31:24,960 --> 00:31:29,840
usage of this in day-to-day care and i

00:31:28,000 --> 00:31:33,600
have worked on that in previous

00:31:29,840 --> 00:31:36,000
uh the previous jobs but but not here

00:31:33,600 --> 00:31:36,720
so this is all for retrospective

00:31:36,000 --> 00:31:39,360
research

00:31:36,720 --> 00:31:39,360
i would imagine

00:31:39,840 --> 00:31:44,159
so deb asked if there were any

00:31:42,320 --> 00:31:45,200
bottlenecks while performing dictionary

00:31:44,159 --> 00:31:47,679
lookup

00:31:45,200 --> 00:31:48,240
no um that was the interesting thing i

00:31:47,679 --> 00:31:51,519
did some

00:31:48,240 --> 00:31:54,640
i i um once i had sort of

00:31:51,519 --> 00:31:56,720
explored this model of having multiple

00:31:54,640 --> 00:31:58,799
instances of the pipeline within the

00:31:56,720 --> 00:31:59,200
same seat takes process i put it through

00:31:58,799 --> 00:32:01,679
some

00:31:59,200 --> 00:32:02,880
really heavy testing to make sure that

00:32:01,679 --> 00:32:05,840
there were no

00:32:02,880 --> 00:32:06,559
um you know thread conflicts or anything

00:32:05,840 --> 00:32:09,200
and there weren't

00:32:06,559 --> 00:32:10,480
basically i can bring the ctake server

00:32:09,200 --> 00:32:13,440
to its knees

00:32:10,480 --> 00:32:14,159
and still you know um and it'll still

00:32:13,440 --> 00:32:17,600
keep going

00:32:14,159 --> 00:32:19,679
occasionally as as was mentioned earlier

00:32:17,600 --> 00:32:20,640
an exception will be thrown out of an

00:32:19,679 --> 00:32:22,320
annotator

00:32:20,640 --> 00:32:23,679
but not through a thread conflict these

00:32:22,320 --> 00:32:26,559
are actually bugs

00:32:23,679 --> 00:32:26,880
in sea takes uh itself um but i haven't

00:32:26,559 --> 00:32:28,799
had

00:32:26,880 --> 00:32:31,360
any thread you know a little but only

00:32:28,799 --> 00:32:34,559
for very very very dense notes

00:32:31,360 --> 00:32:37,600
um that have certain problems uh

00:32:34,559 --> 00:32:40,640
so yeah it's been remarkably full i

00:32:37,600 --> 00:32:42,080
you know like i can run through millions

00:32:40,640 --> 00:32:46,960
of notes without a single

00:32:42,080 --> 00:32:51,200
problem very you know like that 24 by 7

00:32:46,960 --> 00:32:51,200
50 000 notes per hour without any

00:32:54,840 --> 00:32:57,840
problem

00:33:08,320 --> 00:33:15,039
oh i see um uh

00:33:11,519 --> 00:33:17,039
looking at gergano's notes um

00:33:15,039 --> 00:33:18,640
it might be but again um i'm a

00:33:17,039 --> 00:33:22,320
consultant so i don't really

00:33:18,640 --> 00:33:24,159
have the big picture um of of how this

00:33:22,320 --> 00:33:25,360
uh data mart is going to be used

00:33:24,159 --> 00:33:28,720
throughout ucsf

00:33:25,360 --> 00:33:31,960
so uh i suggest you contact

00:33:28,720 --> 00:33:34,080
there's an address in

00:33:31,960 --> 00:33:36,840
infocommons.ucsf.edu

00:33:34,080 --> 00:33:38,320
somebody will be able to answer that

00:33:36,840 --> 00:33:41,840
question

00:33:38,320 --> 00:33:41,840
sorry my cat is protesting

00:33:50,840 --> 00:33:53,840
uh

00:33:55,120 --> 00:33:58,960
well uh i don't know if that question is

00:33:57,200 --> 00:34:03,039
for me in terms of performance from

00:33:58,960 --> 00:34:06,080
um debito um but uh

00:34:03,039 --> 00:34:08,320
we did i i did prune the

00:34:06,080 --> 00:34:09,200
pipeline down to make sure that it

00:34:08,320 --> 00:34:12,240
wasn't

00:34:09,200 --> 00:34:14,240
doing work that was unnecessary um

00:34:12,240 --> 00:34:15,599
you know we started out with a look

00:34:14,240 --> 00:34:19,200
trying to find

00:34:15,599 --> 00:34:23,200
uh trying you know using the um

00:34:19,200 --> 00:34:25,280
some of the clear tk annotators um

00:34:23,200 --> 00:34:26,879
and uh that it turned out we weren't

00:34:25,280 --> 00:34:28,720
actually we didn't even need

00:34:26,879 --> 00:34:30,000
the data that they were generating and

00:34:28,720 --> 00:34:32,800
and

00:34:30,000 --> 00:34:34,960
i'm very unhappy with the location of

00:34:32,800 --> 00:34:36,639
like other people have been and so i i'm

00:34:34,960 --> 00:34:38,639
definitely looking for a different

00:34:36,639 --> 00:34:39,919
approach to that because we do try to

00:34:38,639 --> 00:34:42,159
find the location

00:34:39,919 --> 00:34:44,000
but so we've seen some really hilarious

00:34:42,159 --> 00:34:47,200
mistakes that it's made

00:34:44,000 --> 00:34:50,240
um so um so

00:34:47,200 --> 00:34:53,599
the the uh

00:34:50,240 --> 00:34:55,040
i haven't done a methodical

00:34:53,599 --> 00:34:57,359
look at each of the possible

00:34:55,040 --> 00:34:58,960
permutations it sort of i eyeballed a

00:34:57,359 --> 00:35:00,960
lot of it and

00:34:58,960 --> 00:35:03,839
um in terms of our experimentation with

00:35:00,960 --> 00:35:03,839
pipelines

00:35:26,240 --> 00:35:30,640
well i guess if there's no other

00:35:28,079 --> 00:35:30,640
questions

00:35:31,200 --> 00:35:37,680
i suppose not yes okay so um

00:35:34,640 --> 00:35:39,280
as i've said several times anything can

00:35:37,680 --> 00:35:42,960
be posted on the

00:35:39,280 --> 00:35:45,119
devlin for c takes and

00:35:42,960 --> 00:35:46,000
question comments that's a you know

00:35:45,119 --> 00:35:48,320
pretty good

00:35:46,000 --> 00:35:49,599
place to communicate with uh everyone

00:35:48,320 --> 00:35:52,960
that cares

00:35:49,599 --> 00:35:57,200
um over one beer excellent food right

00:35:52,960 --> 00:35:57,680
okay um i think we've had some really

00:35:57,200 --> 00:35:59,359
good

00:35:57,680 --> 00:36:00,880
presentations i'd like to thank

00:35:59,359 --> 00:36:04,240
everybody that shared their work

00:36:00,880 --> 00:36:05,520
and uh knowledge with us i would also

00:36:04,240 --> 00:36:07,359
like to thank everybody that

00:36:05,520 --> 00:36:10,720
uh took time out of your schedule to

00:36:07,359 --> 00:36:13,040
watch and listen to these presentations

00:36:10,720 --> 00:36:14,000
learn more about sea takes and all the

00:36:13,040 --> 00:36:16,640
really interesting

00:36:14,000 --> 00:36:18,880
efforts that are going on around the

00:36:16,640 --> 00:36:23,760
world

00:36:18,880 --> 00:36:28,079
so that's all i have to say

00:36:23,760 --> 00:36:28,079
thank you everyone thank you thanks

00:36:38,839 --> 00:36:41,839
bye

00:37:24,880 --> 00:37:26,960

YouTube URL: https://www.youtube.com/watch?v=F5WCCPWz7Z0


