Title: Build a reliable, efficient and easy-to-use service for Apache Spark at Uber's scale
Publication date: 2020-10-21
Playlist: ApacheCon @Home 2020: Big Data (Track 2)
Description: 
	Build a reliable, efficient and easy-to-use service for Apache Spark at Uber's scale
Nan Zhu, Wei Han

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

As the global platform supporting 14+ million daily trips, Uber leverages huge amounts of data to power decisions like pricing, routing, etc. Spark is the backbone of large-scale batch computing at Uber. Nearly 250K+ Spark applications serve in scenarios like data ingestion, data cleaning/transformation, and machine learning model training/inference, etc. on a daily basis. Running Spark as a service at Uber’s scale faces many challenges. (a) reliability is the top priority for us while there are many factors that could cause outages and negative business impact. We build an end-to-end robust solution from job service to the Spark distro as well as the thoughtfully designed integrations with other components in data infrastructure. (b) centralized management of Spark applications is also crucial at Uber’s scale. In the past 2-3 years, the Spark ecosystem in Uber has been evolving from a partially managed situation to a service with full-fledged functionalities like monitoring, version management, etc. (c) Processing the massive volume of data in Uber raises challenges against the efficiency of Spark framework itself. We have developed optimizations for nested column pruning, parallel hive table committing implementation, etc. to significantly improve the Spark application performance. In this talk, we will walk through the aforementioned journey in Uber and share the experiences and lessons learned along the way. We hope that this talk can showcase how Apache software serves industry worldwide, help others who face similar challenges, and raise more discussions around the topic.

Nan Zhu:
Nan is Tech Lead of Spark team in Uber. He works on Spark service handling 100s of 1000s of Spark application every day in Uber, and the internal features which scales Spark to handle massive volume of data in Uber. He is also PMC member of XGBoost, one of the most popular machine learning library in both industry and academia.
Wei Han:
Wei Han is an Engineering Manager, leading a few teams in Uber’s data platform org, including Spark platform, Data security and Compliance, Privacy platform, and File Format(Apache Parquet)
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:27,599 --> 00:00:31,840
yeah i think

00:00:28,240 --> 00:00:31,840
we can we can start

00:00:36,480 --> 00:00:40,640
all right uh let's start can you hear me

00:00:38,399 --> 00:00:40,640
okay

00:00:41,920 --> 00:00:47,440
now can you hear me yes okay uh hello

00:00:45,520 --> 00:00:50,800
everyone um welcome to

00:00:47,440 --> 00:00:52,000
our presentation today uh me and anand

00:00:50,800 --> 00:00:55,360
are gonna talk about

00:00:52,000 --> 00:00:59,840
um how do we build a reliable efficient

00:00:55,360 --> 00:00:59,840
and easy to use spark ecosystem and uber

00:01:00,559 --> 00:01:07,040
next slide um so here's the agenda

00:01:04,479 --> 00:01:08,240
so i'm gonna give everyone a brief

00:01:07,040 --> 00:01:11,119
overview of

00:01:08,240 --> 00:01:12,159
spark at uber the architecture the use

00:01:11,119 --> 00:01:14,479
case etc

00:01:12,159 --> 00:01:15,600
then a little bit on history how the

00:01:14,479 --> 00:01:18,320
spark ecosystem

00:01:15,600 --> 00:01:20,560
evolved at woven in the past few years

00:01:18,320 --> 00:01:22,799
and then then we'll give us

00:01:20,560 --> 00:01:25,040
you know share some stories about you

00:01:22,799 --> 00:01:25,680
know how we solve reliability problems

00:01:25,040 --> 00:01:28,320
how we

00:01:25,680 --> 00:01:29,040
make sparky more efficient and how we

00:01:28,320 --> 00:01:33,520
make spark

00:01:29,040 --> 00:01:33,520
easy to use next please

00:01:33,600 --> 00:01:38,840
so a quick intro about myself i'm an

00:01:36,640 --> 00:01:41,280
engineer manager at uber i did a few

00:01:38,840 --> 00:01:43,600
teams including our spark team

00:01:41,280 --> 00:01:45,920
which is main target today data security

00:01:43,600 --> 00:01:47,759
and privacy and file format

00:01:45,920 --> 00:01:51,040
our teams are heavily dependent on

00:01:47,759 --> 00:01:54,240
apache um so we use apache parkway for

00:01:51,040 --> 00:01:57,840
free format for security we use

00:01:54,240 --> 00:01:58,399
nox and sentry and uh we're also looking

00:01:57,840 --> 00:02:01,840
at

00:01:58,399 --> 00:02:03,680
into apache ranger um and for spark of

00:02:01,840 --> 00:02:04,560
course we use spark we also depend on

00:02:03,680 --> 00:02:09,280
apache dv

00:02:04,560 --> 00:02:12,319
for a job service next

00:02:09,280 --> 00:02:15,760
next slice now yeah okay

00:02:12,319 --> 00:02:18,959
can you see that yeah so uh about then

00:02:15,760 --> 00:02:22,400
uh he's our uh amazing tech lead of

00:02:18,959 --> 00:02:23,840
in our smart team um he's also the pmc

00:02:22,400 --> 00:02:25,920
member or actually boost

00:02:23,840 --> 00:02:28,160
um he's actually the you know the

00:02:25,920 --> 00:02:30,879
founder i actually do spark project

00:02:28,160 --> 00:02:32,480
um he's also serving at uh in our uber

00:02:30,879 --> 00:02:34,720
open source machine learning working

00:02:32,480 --> 00:02:34,720
group

00:02:35,200 --> 00:02:42,800
next next slide

00:02:39,360 --> 00:02:46,480
um so a little bit of us

00:02:42,800 --> 00:02:49,599
about our scale so um uber is um

00:02:46,480 --> 00:02:53,040
really a data-driven company

00:02:49,599 --> 00:02:56,160
so um data is everywhere

00:02:53,040 --> 00:02:57,280
um we just like any other company we

00:02:56,160 --> 00:03:00,239
store the data

00:02:57,280 --> 00:03:00,720
we analyze data we extract data from we

00:03:00,239 --> 00:03:03,360
extract

00:03:00,720 --> 00:03:04,159
insight from the data and we use this

00:03:03,360 --> 00:03:07,120
insight to

00:03:04,159 --> 00:03:07,680
um move things around in the physical

00:03:07,120 --> 00:03:10,959
world

00:03:07,680 --> 00:03:11,599
um and deadly uber is massive um you

00:03:10,959 --> 00:03:13,840
know

00:03:11,599 --> 00:03:14,640
we did restore every piece of data into

00:03:13,840 --> 00:03:17,840
the data lake

00:03:14,640 --> 00:03:19,680
for various use uh use cases and for

00:03:17,840 --> 00:03:23,280
spark is really foundational

00:03:19,680 --> 00:03:24,560
um and it's everywhere um so on a daily

00:03:23,280 --> 00:03:28,319
basis we have about

00:03:24,560 --> 00:03:31,120
2 50 000 spark applications

00:03:28,319 --> 00:03:32,239
and then on our yarn cluster which is a

00:03:31,120 --> 00:03:36,239
compute cluster

00:03:32,239 --> 00:03:39,120
98 of cpu cycles are being used by spark

00:03:36,239 --> 00:03:40,000
um and on a daily basis we have a

00:03:39,120 --> 00:03:43,120
thousand

00:03:40,000 --> 00:03:45,440
plus daily users and

00:03:43,120 --> 00:03:46,640
in terms of table size we have tens of

00:03:45,440 --> 00:03:51,840
heck bytes of you know

00:03:46,640 --> 00:03:54,080
uh table and 100 pegabytes of images

00:03:51,840 --> 00:03:54,080
next

00:03:55,360 --> 00:03:59,599
all right um so as i mentioned you know

00:03:58,000 --> 00:04:02,400
spark is used by

00:03:59,599 --> 00:04:03,680
you know all the you know organizations

00:04:02,400 --> 00:04:06,799
and teams in uber

00:04:03,680 --> 00:04:10,480
um here we list a few use cases um

00:04:06,799 --> 00:04:11,599
so for um you know instant detection so

00:04:10,480 --> 00:04:14,000
we use spark to

00:04:11,599 --> 00:04:15,840
automatically detect instance happening

00:04:14,000 --> 00:04:19,040
on the platform

00:04:15,840 --> 00:04:22,079
for ubereats we use spark to

00:04:19,040 --> 00:04:25,040
recommend food for our customers

00:04:22,079 --> 00:04:26,320
of course if we use etls you know to you

00:04:25,040 --> 00:04:29,280
know clean up the data

00:04:26,320 --> 00:04:31,440
transform data in various format um last

00:04:29,280 --> 00:04:33,440
but but not least for detection we use

00:04:31,440 --> 00:04:36,320
spark to detect flaws in the

00:04:33,440 --> 00:04:39,280
on the system um on the right side we

00:04:36,320 --> 00:04:42,479
also have a few platforms

00:04:39,280 --> 00:04:43,440
that are built on top of spark so data

00:04:42,479 --> 00:04:46,800
ingestion

00:04:43,440 --> 00:04:49,040
which is the platform that compunes

00:04:46,800 --> 00:04:50,160
transform the data from the online world

00:04:49,040 --> 00:04:53,360
including

00:04:50,160 --> 00:04:56,880
databases uh kafka mysql

00:04:53,360 --> 00:04:58,560
etc into the data lake um this pipeline

00:04:56,880 --> 00:05:01,440
is built on top hot spark

00:04:58,560 --> 00:05:03,280
um experimentation you know which is the

00:05:01,440 --> 00:05:04,240
our platform to do all sorts of

00:05:03,280 --> 00:05:06,320
experiments

00:05:04,240 --> 00:05:08,720
a b testing session is also built on top

00:05:06,320 --> 00:05:11,280
of spark michelangelo which is our

00:05:08,720 --> 00:05:12,800
uber's machine learning platform of

00:05:11,280 --> 00:05:15,919
course it's also built on

00:05:12,800 --> 00:05:17,199
on top of spark and also notebooks which

00:05:15,919 --> 00:05:19,919
is used by

00:05:17,199 --> 00:05:20,960
all these scientist scientists to either

00:05:19,919 --> 00:05:23,280
do

00:05:20,960 --> 00:05:24,160
interactive queries or sketch curves

00:05:23,280 --> 00:05:29,120
let's also

00:05:24,160 --> 00:05:29,120
build on top of spark next

00:05:29,440 --> 00:05:33,360
all right a very high level architecture

00:05:31,759 --> 00:05:36,639
so about you know

00:05:33,360 --> 00:05:37,280
spark and ecosystem so uh if you see the

00:05:36,639 --> 00:05:39,440
on the top

00:05:37,280 --> 00:05:40,400
you uh we have scheduled spark jobs we

00:05:39,440 --> 00:05:42,960
have interactive

00:05:40,400 --> 00:05:44,320
interactive spark jobs all these jobs

00:05:42,960 --> 00:05:47,520
are being

00:05:44,320 --> 00:05:50,400
submitted to us uh to a spark gateway um

00:05:47,520 --> 00:05:51,199
and uh you know underlying we use levy

00:05:50,400 --> 00:05:54,320
um

00:05:51,199 --> 00:05:56,319
for me submitting the jobs and

00:05:54,320 --> 00:05:57,520
on the left side we have a remote

00:05:56,319 --> 00:05:59,600
shuffle service um

00:05:57,520 --> 00:06:01,120
and mayank and bo are giving another

00:05:59,600 --> 00:06:03,759
talk on on that

00:06:01,120 --> 00:06:04,560
we also just open sourced our remote

00:06:03,759 --> 00:06:07,680
shuffle

00:06:04,560 --> 00:06:10,720
yesterday so do check that out um

00:06:07,680 --> 00:06:13,360
and i'm not going to skip

00:06:10,720 --> 00:06:15,039
the right side for now so um on the on

00:06:13,360 --> 00:06:18,319
the resource manager side we have

00:06:15,039 --> 00:06:20,160
yarn we also have pelton our uber's own

00:06:18,319 --> 00:06:22,800
resource manager

00:06:20,160 --> 00:06:23,680
and the underlying is storage is either

00:06:22,800 --> 00:06:27,039
on primark

00:06:23,680 --> 00:06:29,120
on or on cloud now let's

00:06:27,039 --> 00:06:30,319
zoom into the spark ecosystem the green

00:06:29,120 --> 00:06:34,639
box here so

00:06:30,319 --> 00:06:37,759
this is uh sorry that's to me that this

00:06:34,639 --> 00:06:40,240
so this is really uh you know

00:06:37,759 --> 00:06:41,840
something really helps us and the

00:06:40,240 --> 00:06:44,800
customer a lot so

00:06:41,840 --> 00:06:46,479
we build tons of services um and uh

00:06:44,800 --> 00:06:49,840
ecosystem around this

00:06:46,479 --> 00:06:52,720
including observability so and auto tune

00:06:49,840 --> 00:06:54,479
and the root cause analysis now we'll

00:06:52,720 --> 00:06:56,160
you know share more details later on but

00:06:54,479 --> 00:06:58,639
these are really really important

00:06:56,160 --> 00:07:00,720
to make spark easy to use and more

00:06:58,639 --> 00:07:03,840
efficient uber

00:07:00,720 --> 00:07:03,840
can do next

00:07:05,919 --> 00:07:11,039
um okay so um

00:07:09,039 --> 00:07:12,240
a little bit of history um you know what

00:07:11,039 --> 00:07:18,160
happens at uber

00:07:12,240 --> 00:07:21,520
especially for spark um so before 2018

00:07:18,160 --> 00:07:24,479
um the way you know we

00:07:21,520 --> 00:07:26,880
submit spark jobs at uber um is by

00:07:24,479 --> 00:07:30,000
logging into a production box

00:07:26,880 --> 00:07:32,880
um as you can see this is not very

00:07:30,000 --> 00:07:33,199
efficient you know people need to um you

00:07:32,880 --> 00:07:35,120
know

00:07:33,199 --> 00:07:37,599
uh use a very hectic way to submit the

00:07:35,120 --> 00:07:38,160
jobs uh as a result of that there's

00:07:37,599 --> 00:07:40,560
there was

00:07:38,160 --> 00:07:41,759
19 plus spark versions used by different

00:07:40,560 --> 00:07:44,080
teams

00:07:41,759 --> 00:07:45,440
there was no centralized spark team or

00:07:44,080 --> 00:07:48,960
spark database azure

00:07:45,440 --> 00:07:50,720
so around 2018 we start to build

00:07:48,960 --> 00:07:52,080
our spark database service so

00:07:50,720 --> 00:07:54,800
essentially instead of

00:07:52,080 --> 00:07:55,520
customers logging and submitting jobs by

00:07:54,800 --> 00:07:57,280
themselves

00:07:55,520 --> 00:07:59,360
they can submit a job to this

00:07:57,280 --> 00:08:02,000
centralized spark gateway

00:07:59,360 --> 00:08:03,440
which handles all you know the worship

00:08:02,000 --> 00:08:06,879
management

00:08:03,440 --> 00:08:09,759
the job submission etc um

00:08:06,879 --> 00:08:11,680
however you know there was still lots of

00:08:09,759 --> 00:08:12,000
existing or legacy use cases where

00:08:11,680 --> 00:08:14,400
people

00:08:12,000 --> 00:08:16,800
still use the old way to do that so in

00:08:14,400 --> 00:08:19,520
2019 we start to

00:08:16,800 --> 00:08:22,240
migrating all these use cases to this

00:08:19,520 --> 00:08:24,879
single uh spark database service

00:08:22,240 --> 00:08:26,000
and after that we basically achieve a

00:08:24,879 --> 00:08:28,639
very important goal which

00:08:26,000 --> 00:08:31,120
is you know all the spark applications

00:08:28,639 --> 00:08:33,760
is being submitted in a centralized way

00:08:31,120 --> 00:08:35,440
all the lot is mentioned essentially so

00:08:33,760 --> 00:08:37,519
this is actually very important you know

00:08:35,440 --> 00:08:38,240
because of this we were able to do lots

00:08:37,519 --> 00:08:42,080
of things

00:08:38,240 --> 00:08:44,399
including efficiency security

00:08:42,080 --> 00:08:46,000
and before that it was not even possible

00:08:44,399 --> 00:08:47,519
because people use their own way to

00:08:46,000 --> 00:08:49,440
submit jobs

00:08:47,519 --> 00:08:50,880
um what's hap what will happen in the

00:08:49,440 --> 00:08:52,800
future and what we are

00:08:50,880 --> 00:08:54,800
working on right now uh of course we are

00:08:52,800 --> 00:08:57,360
looking at uh sparks 3.0

00:08:54,800 --> 00:08:58,240
uh very actively um but our long-term

00:08:57,360 --> 00:09:01,200
vision um

00:08:58,240 --> 00:09:03,600
is so is incl also includes auto

00:09:01,200 --> 00:09:06,320
optimized configurations this has been a

00:09:03,600 --> 00:09:07,519
pinpoint form from our customers uh they

00:09:06,320 --> 00:09:10,720
don't want to deal with

00:09:07,519 --> 00:09:12,000
you know hundreds of configurations and

00:09:10,720 --> 00:09:14,959
to tune these jobs

00:09:12,000 --> 00:09:16,800
we want to we want our spark ecosystem

00:09:14,959 --> 00:09:20,240
to do that for the customers

00:09:16,800 --> 00:09:22,880
if i also want to achieve soa

00:09:20,240 --> 00:09:24,399
oriented goal so which means whenever

00:09:22,880 --> 00:09:27,279
you submit a super job

00:09:24,399 --> 00:09:29,279
we auto optimize the configurations in

00:09:27,279 --> 00:09:32,800
order to satisfy this as a way

00:09:29,279 --> 00:09:35,200
for the customers um

00:09:32,800 --> 00:09:36,000
with that i'm going to turn over to nan

00:09:35,200 --> 00:09:38,640
who is going to share

00:09:36,000 --> 00:09:39,279
a few stories go ahead and thank you

00:09:38,640 --> 00:09:41,760
okay

00:09:39,279 --> 00:09:42,880
uh thanks to way for uh giving

00:09:41,760 --> 00:09:45,120
introduction about

00:09:42,880 --> 00:09:46,880
spark at the uber and the next i will

00:09:45,120 --> 00:09:47,920
share several stories we have in the

00:09:46,880 --> 00:09:50,640
journey of

00:09:47,920 --> 00:09:53,839
improving reliability efficiency and

00:09:50,640 --> 00:09:57,120
usability of our spark system

00:09:53,839 --> 00:09:59,839
so first the story is about reliability

00:09:57,120 --> 00:10:01,519
reliability is a fundamental goal for us

00:09:59,839 --> 00:10:03,760
to build a spark at uber

00:10:01,519 --> 00:10:05,600
because whether we have a reliable spark

00:10:03,760 --> 00:10:07,680
service directly impacts

00:10:05,600 --> 00:10:08,959
several critical business scenarios for

00:10:07,680 --> 00:10:10,560
example

00:10:08,959 --> 00:10:12,800
whether our engineers and the data

00:10:10,560 --> 00:10:15,519
scientists can get a timely

00:10:12,800 --> 00:10:17,120
and correct data for analysis and the

00:10:15,519 --> 00:10:19,279
way that ubereats can

00:10:17,120 --> 00:10:20,480
recommend the most favorite food to the

00:10:19,279 --> 00:10:22,880
users

00:10:20,480 --> 00:10:23,920
and when we talk about the reliability

00:10:22,880 --> 00:10:26,480
of spark service

00:10:23,920 --> 00:10:27,519
we are actually faced with the upper

00:10:26,480 --> 00:10:29,920
bound

00:10:27,519 --> 00:10:32,640
of reliability set by our dependencies

00:10:29,920 --> 00:10:35,680
like a yar high metastar hdfs

00:10:32,640 --> 00:10:39,200
because we can never expect to build a

00:10:35,680 --> 00:10:42,480
spark service with a 39 reliability sla

00:10:39,200 --> 00:10:45,040
if those dependencies are lower than 3.9

00:10:42,480 --> 00:10:46,560
and at some time point we did experience

00:10:45,040 --> 00:10:48,480
several issues with this

00:10:46,560 --> 00:10:49,760
dependencies for example we have

00:10:48,480 --> 00:10:52,480
unexpected the

00:10:49,760 --> 00:10:53,040
fair overall resource manager we have

00:10:52,480 --> 00:10:56,480
frequent

00:10:53,040 --> 00:10:58,959
time out of hms requests sent from our

00:10:56,480 --> 00:11:01,600
spark applications

00:10:58,959 --> 00:11:02,800
after we tried everything to improve

00:11:01,600 --> 00:11:05,600
this assistance

00:11:02,800 --> 00:11:06,640
like your hms itself we actually

00:11:05,600 --> 00:11:08,959
received some

00:11:06,640 --> 00:11:09,920
uh surprising feedback from our partner

00:11:08,959 --> 00:11:12,720
teams

00:11:09,920 --> 00:11:14,000
uh for example young team told us that

00:11:12,720 --> 00:11:16,160
yeah our resource manager

00:11:14,000 --> 00:11:17,600
fair overrate is a bit higher than

00:11:16,160 --> 00:11:20,079
europe but

00:11:17,600 --> 00:11:22,560
since spark job service contributed a

00:11:20,079 --> 00:11:25,279
lot of rpc traffic pressure

00:11:22,560 --> 00:11:26,399
and similarly hive team told us that we

00:11:25,279 --> 00:11:29,279
assigned a u3

00:11:26,399 --> 00:11:31,360
hms instance however sim says all

00:11:29,279 --> 00:11:33,519
applications are just the use of one of

00:11:31,360 --> 00:11:34,160
them for more than 95 percent of

00:11:33,519 --> 00:11:36,480
requests

00:11:34,160 --> 00:11:37,440
which makes that particular instance to

00:11:36,480 --> 00:11:40,800
be

00:11:37,440 --> 00:11:43,440
more fragile so then we started to

00:11:40,800 --> 00:11:46,240
check back every component in our spark

00:11:43,440 --> 00:11:46,240
services stack

00:11:46,320 --> 00:11:50,079
we find out that there are several

00:11:49,040 --> 00:11:53,120
design flaws

00:11:50,079 --> 00:11:54,160
which could only surface up at uber the

00:11:53,120 --> 00:11:56,880
scale

00:11:54,160 --> 00:11:59,279
for example we build our spark job

00:11:56,880 --> 00:12:02,240
service on top of apache dvd

00:11:59,279 --> 00:12:03,519
and we found that libby assigns a

00:12:02,240 --> 00:12:06,399
application handler

00:12:03,519 --> 00:12:08,480
for every user request when the user

00:12:06,399 --> 00:12:10,720
wants to start a new spark application

00:12:08,480 --> 00:12:11,760
this application handler will get all

00:12:10,720 --> 00:12:14,320
application list

00:12:11,760 --> 00:12:17,040
from resource manager to check whether a

00:12:14,320 --> 00:12:18,560
new application id has been assigned to

00:12:17,040 --> 00:12:20,720
this user

00:12:18,560 --> 00:12:22,880
and if the user's application has been

00:12:20,720 --> 00:12:24,160
running then this application handler

00:12:22,880 --> 00:12:26,320
will periodically

00:12:24,160 --> 00:12:28,720
query resource manager to update the

00:12:26,320 --> 00:12:31,200
application studios

00:12:28,720 --> 00:12:32,160
with this architecture we can see that

00:12:31,200 --> 00:12:34,240
the number of

00:12:32,160 --> 00:12:36,240
concurrent threads acquiring resource

00:12:34,240 --> 00:12:39,360
manager equals to the number of

00:12:36,240 --> 00:12:41,839
active user request in our system and

00:12:39,360 --> 00:12:43,760
even uber's scale you can imagine that

00:12:41,839 --> 00:12:45,920
this number could be very large and

00:12:43,760 --> 00:12:48,079
bring a lot of pressure to a resource

00:12:45,920 --> 00:12:50,480
manager

00:12:48,079 --> 00:12:51,600
to resolve this problem we add a new

00:12:50,480 --> 00:12:54,880
layer called the

00:12:51,600 --> 00:12:57,600
young interaction manager in divi

00:12:54,880 --> 00:12:58,079
it this layer gets information from

00:12:57,600 --> 00:13:00,639
young

00:12:58,079 --> 00:13:01,519
within a single thread and then is a

00:13:00,639 --> 00:13:03,279
dispatch

00:13:01,519 --> 00:13:05,360
fetch the information to other

00:13:03,279 --> 00:13:08,320
application handlers

00:13:05,360 --> 00:13:09,040
in this way we can significantly reduce

00:13:08,320 --> 00:13:12,160
the traffic

00:13:09,040 --> 00:13:14,959
between levy and the er so that we make

00:13:12,160 --> 00:13:15,440
a resource manager take less traffic it

00:13:14,959 --> 00:13:18,240
becomes

00:13:15,440 --> 00:13:20,079
more reliable and in turn improve the

00:13:18,240 --> 00:13:22,639
reliability of our spark service

00:13:20,079 --> 00:13:22,639
itself

00:13:23,519 --> 00:13:27,120
similarly in hive site we found that the

00:13:26,480 --> 00:13:29,839
building

00:13:27,120 --> 00:13:33,279
hms client in spark distro actually

00:13:29,839 --> 00:13:36,480
cannot leverage multiple hms

00:13:33,279 --> 00:13:38,320
errors properly and also it initializes

00:13:36,480 --> 00:13:39,680
the intercept with the expensive

00:13:38,320 --> 00:13:43,120
operation like at least

00:13:39,680 --> 00:13:46,240
all the udf uh registering height

00:13:43,120 --> 00:13:48,480
by fixing these two issues we can get a

00:13:46,240 --> 00:13:49,600
where balance the load between all the

00:13:48,480 --> 00:13:53,519
spark applications

00:13:49,600 --> 00:13:55,519
and hmas and also we get a 20x traffic

00:13:53,519 --> 00:13:59,199
reduction between spark applications

00:13:55,519 --> 00:13:59,199
and the hmis

00:13:59,680 --> 00:14:03,519
so to complete this diagram where we

00:14:02,320 --> 00:14:05,680
said that

00:14:03,519 --> 00:14:07,040
our service dependencies like a young

00:14:05,680 --> 00:14:09,920
hms set a

00:14:07,040 --> 00:14:11,040
upper bound of reliability to spark

00:14:09,920 --> 00:14:13,839
service

00:14:11,040 --> 00:14:16,000
but since here we have we are operating

00:14:13,839 --> 00:14:18,800
spark service at a very large scale

00:14:16,000 --> 00:14:21,199
we get the capability to lifting this

00:14:18,800 --> 00:14:22,639
reliability upper bound by hardening our

00:14:21,199 --> 00:14:25,839
job service and the spark

00:14:22,639 --> 00:14:27,360
spark uh disreserve so we improve the

00:14:25,839 --> 00:14:30,079
reliability of dependency

00:14:27,360 --> 00:14:32,639
and which in turn uh beneficial to

00:14:30,079 --> 00:14:32,639
ourselves

00:14:32,959 --> 00:14:37,199
this is the first story uh the second

00:14:35,920 --> 00:14:39,920
one is about

00:14:37,199 --> 00:14:41,360
efficiency efficiency is also a very

00:14:39,920 --> 00:14:44,639
critical goal for us

00:14:41,360 --> 00:14:47,360
because efficiency decides the operating

00:14:44,639 --> 00:14:50,480
cost for our data infrastructure

00:14:47,360 --> 00:14:52,959
it also decides the velocity for us to

00:14:50,480 --> 00:14:56,560
make data-driven decisions

00:14:52,959 --> 00:14:59,199
however we faced a common challenge

00:14:56,560 --> 00:14:59,920
with many other spark teams in different

00:14:59,199 --> 00:15:02,880
companies

00:14:59,920 --> 00:15:04,800
that is um us customers workloads are

00:15:02,880 --> 00:15:07,279
kind of black box to us

00:15:04,800 --> 00:15:09,519
because the spark is so flexible uh

00:15:07,279 --> 00:15:10,000
users can build their applications on

00:15:09,519 --> 00:15:12,720
top of

00:15:10,000 --> 00:15:13,440
rdd on top of spark sql that's that

00:15:12,720 --> 00:15:15,360
frame

00:15:13,440 --> 00:15:16,639
and their programming in different

00:15:15,360 --> 00:15:18,880
language and

00:15:16,639 --> 00:15:19,839
it makes us very hard to answer for

00:15:18,880 --> 00:15:21,839
example what

00:15:19,839 --> 00:15:23,760
is the general bottleneck for all the

00:15:21,839 --> 00:15:25,920
spark applications in uber

00:15:23,760 --> 00:15:27,839
and even we build something in

00:15:25,920 --> 00:15:30,079
production how to measure the

00:15:27,839 --> 00:15:34,000
effectiveness of this feature and

00:15:30,079 --> 00:15:36,560
enable us to continuously improve that

00:15:34,000 --> 00:15:39,680
to resolve this problem we build a

00:15:36,560 --> 00:15:42,079
customer observability stack

00:15:39,680 --> 00:15:44,000
through spark gateway and job service we

00:15:42,079 --> 00:15:47,360
can inject some parameters

00:15:44,000 --> 00:15:48,160
into user request so that the spark

00:15:47,360 --> 00:15:50,480
applications

00:15:48,160 --> 00:15:51,680
running in our cluster not only runs

00:15:50,480 --> 00:15:54,959
user logic but

00:15:51,680 --> 00:15:56,959
also jvm profiler and spark listener

00:15:54,959 --> 00:15:59,759
and these two things will collect

00:15:56,959 --> 00:16:03,680
metrics like cpu memory utilization

00:15:59,759 --> 00:16:06,079
and also a sparkle specific metrics like

00:16:03,680 --> 00:16:06,800
input size shuffle size and these

00:16:06,079 --> 00:16:09,920
metrics

00:16:06,800 --> 00:16:11,199
are synchronized to kafka topic when the

00:16:09,920 --> 00:16:14,639
application is finished

00:16:11,199 --> 00:16:16,000
we leverage a yarn lock aggregation

00:16:14,639 --> 00:16:19,120
service to select

00:16:16,000 --> 00:16:21,920
to collect application logs to https

00:16:19,120 --> 00:16:24,000
and then we have log x which is a spark

00:16:21,920 --> 00:16:25,680
based log of mining pipeline to collect

00:16:24,000 --> 00:16:28,240
the logs from hdfs

00:16:25,680 --> 00:16:28,880
and apply analysis like root cause root

00:16:28,240 --> 00:16:31,839
cause

00:16:28,880 --> 00:16:32,160
analysis and the specific log parsing

00:16:31,839 --> 00:16:35,680
and

00:16:32,160 --> 00:16:38,240
the result is send to kafka as well

00:16:35,680 --> 00:16:39,279
finally we utilize the data ingestion

00:16:38,240 --> 00:16:42,160
mechanism

00:16:39,279 --> 00:16:43,360
in uber to synchronize the kafka topic

00:16:42,160 --> 00:16:45,519
and high tables

00:16:43,360 --> 00:16:47,680
and then our engineers can perform some

00:16:45,519 --> 00:16:50,800
analysis on top of these

00:16:47,680 --> 00:16:53,519
hive tables to find the issues

00:16:50,800 --> 00:16:54,560
and next i will introduce an example how

00:16:53,519 --> 00:16:56,399
we

00:16:54,560 --> 00:16:57,759
leverage this customer observability

00:16:56,399 --> 00:17:00,560
stack to get

00:16:57,759 --> 00:17:02,320
a feature bringing 2x performance boost

00:17:00,560 --> 00:17:05,199
in uber

00:17:02,320 --> 00:17:07,199
first we instrument a lot of logs in our

00:17:05,199 --> 00:17:08,079
internal spark district to dissect the

00:17:07,199 --> 00:17:10,880
performance of

00:17:08,079 --> 00:17:11,760
applications on this page i'm showing

00:17:10,880 --> 00:17:14,559
that

00:17:11,760 --> 00:17:16,720
we are instrument instrumenting a log in

00:17:14,559 --> 00:17:18,640
data source scanning operator in spark

00:17:16,720 --> 00:17:21,039
so that we can measure the latency on

00:17:18,640 --> 00:17:24,079
this part

00:17:21,039 --> 00:17:26,400
and then we develop a module in log x

00:17:24,079 --> 00:17:27,600
which i said it is a spark based the log

00:17:26,400 --> 00:17:30,240
binding pipeline

00:17:27,600 --> 00:17:31,520
to parse these logs and get information

00:17:30,240 --> 00:17:33,600
like a language number

00:17:31,520 --> 00:17:36,559
and the center the collective analyze

00:17:33,600 --> 00:17:38,480
the data to kafka

00:17:36,559 --> 00:17:39,919
after the kafka topic had been

00:17:38,480 --> 00:17:42,880
automatically ingested

00:17:39,919 --> 00:17:43,919
into hive table we can run sql queries

00:17:42,880 --> 00:17:47,600
to

00:17:43,919 --> 00:17:50,160
do some matrix analysis okay

00:17:47,600 --> 00:17:52,080
through these steps we actually detect a

00:17:50,160 --> 00:17:54,880
common customer issue

00:17:52,080 --> 00:17:55,840
we found that applications accessing

00:17:54,880 --> 00:17:58,480
tables with

00:17:55,840 --> 00:18:01,039
nextview column prunins are usually

00:17:58,480 --> 00:18:02,880
having very long table scanning time

00:18:01,039 --> 00:18:05,120
and if we compare these type of

00:18:02,880 --> 00:18:09,440
applications with others we find that

00:18:05,120 --> 00:18:12,960
they are usually the most expensive ones

00:18:09,440 --> 00:18:15,679
this makes us associate the observer

00:18:12,960 --> 00:18:17,679
observation to a missing feature in open

00:18:15,679 --> 00:18:20,000
source version of spark

00:18:17,679 --> 00:18:21,760
that is the nested column pruning

00:18:20,000 --> 00:18:22,400
essential energy column pruning says

00:18:21,760 --> 00:18:25,679
that

00:18:22,400 --> 00:18:26,640
if i want to fetch a nested column in a

00:18:25,679 --> 00:18:28,640
table

00:18:26,640 --> 00:18:30,640
how many columns i need to fetch from

00:18:28,640 --> 00:18:33,280
starter system

00:18:30,640 --> 00:18:35,200
in the example of this page uh do if i

00:18:33,280 --> 00:18:38,320
just want to private column zero

00:18:35,200 --> 00:18:38,799
do i need to fetch the column zero or i

00:18:38,320 --> 00:18:40,640
need to

00:18:38,799 --> 00:18:42,400
fetch all the columns under the same

00:18:40,640 --> 00:18:44,559
parent column

00:18:42,400 --> 00:18:46,000
so actually open source version of spark

00:18:44,559 --> 00:18:49,200
has very limited support

00:18:46,000 --> 00:18:51,679
of this feature uh before 2.4

00:18:49,200 --> 00:18:52,240
we don't have a supporter for this at

00:18:51,679 --> 00:18:55,679
all

00:18:52,240 --> 00:18:56,799
and in 2.4 it only supports select and

00:18:55,679 --> 00:18:59,679
filter

00:18:56,799 --> 00:19:00,880
and in the spark 3 which just released

00:18:59,679 --> 00:19:03,120
several months ago

00:19:00,880 --> 00:19:04,640
i just has a wider range of spots but

00:19:03,120 --> 00:19:07,520
still missing

00:19:04,640 --> 00:19:10,160
missing the missing support for cases

00:19:07,520 --> 00:19:12,480
like drawing and windowing

00:19:10,160 --> 00:19:14,960
back to two years ago we started to

00:19:12,480 --> 00:19:17,360
build a netcon pruning feature in uber

00:19:14,960 --> 00:19:19,280
internally we can support all private

00:19:17,360 --> 00:19:22,320
patterns ranging from scan

00:19:19,280 --> 00:19:25,280
filter drawing windowing

00:19:22,320 --> 00:19:27,600
and because of this feature we can bring

00:19:25,280 --> 00:19:28,880
uh more than 2x performance boost to

00:19:27,600 --> 00:19:31,120
many pipelines

00:19:28,880 --> 00:19:33,360
here i show an example from one of the

00:19:31,120 --> 00:19:36,559
most expensive and critical

00:19:33,360 --> 00:19:38,480
uh smart pipelines in uber

00:19:36,559 --> 00:19:40,160
we can actually leverage the necessary

00:19:38,480 --> 00:19:44,799
pruning feature to reduce

00:19:40,160 --> 00:19:44,799
the running time uh by 2x

00:19:45,679 --> 00:19:50,640
so for the summary of this story uh

00:19:48,640 --> 00:19:52,720
efficiency is very critical

00:19:50,640 --> 00:19:54,720
but you need to bring the efficiency

00:19:52,720 --> 00:19:56,640
with the customer in size

00:19:54,720 --> 00:19:58,320
the more you understand your customer

00:19:56,640 --> 00:19:59,360
the higher impact that you can bring

00:19:58,320 --> 00:20:02,480
with your

00:19:59,360 --> 00:20:03,840
spark service and given the uber-like

00:20:02,480 --> 00:20:06,880
scale of spark service

00:20:03,840 --> 00:20:09,679
isn't it very hard for you to talk with

00:20:06,880 --> 00:20:11,919
every customer and build every customer

00:20:09,679 --> 00:20:14,080
specific feature one by one

00:20:11,919 --> 00:20:16,640
so you need to build a systematic

00:20:14,080 --> 00:20:17,840
mechanism to capture characteristics of

00:20:16,640 --> 00:20:20,080
customer workloads

00:20:17,840 --> 00:20:22,480
and help you to build efficiency related

00:20:20,080 --> 00:20:22,480
features

00:20:22,880 --> 00:20:29,919
so next story after we have

00:20:26,000 --> 00:20:32,480
a reliable and efficiency spark service

00:20:29,919 --> 00:20:33,520
a common comment from our customers is

00:20:32,480 --> 00:20:36,000
there like a

00:20:33,520 --> 00:20:37,120
spark is very powerful but it is so hard

00:20:36,000 --> 00:20:40,000
to use

00:20:37,120 --> 00:20:41,360
seems we are still missing the last key

00:20:40,000 --> 00:20:44,720
to success

00:20:41,360 --> 00:20:46,559
so the last key is actually usability

00:20:44,720 --> 00:20:49,200
let's review what our customers have to

00:20:46,559 --> 00:20:52,320
do when they use spark

00:20:49,200 --> 00:20:54,799
so they have two coding in their laptop

00:20:52,320 --> 00:20:57,360
of course and then after they finish the

00:20:54,799 --> 00:20:59,520
first version of code they need to

00:20:57,360 --> 00:21:02,559
package their applications and upload it

00:20:59,520 --> 00:21:05,679
to a remote server and log in there

00:21:02,559 --> 00:21:06,559
and then they jump and debug you remote

00:21:05,679 --> 00:21:09,600
servers

00:21:06,559 --> 00:21:11,600
and tune their applications and

00:21:09,600 --> 00:21:13,039
then they come back to their laptop to

00:21:11,600 --> 00:21:16,480
revise the code

00:21:13,039 --> 00:21:18,960
and repeat this process

00:21:16,480 --> 00:21:19,600
we can see that there are several steps

00:21:18,960 --> 00:21:22,960
which is

00:21:19,600 --> 00:21:23,919
user so tedious and time consuming for

00:21:22,960 --> 00:21:27,440
example

00:21:23,919 --> 00:21:29,520
like upload a file to remote server log

00:21:27,440 --> 00:21:31,919
in there trigger application

00:21:29,520 --> 00:21:32,799
and also even they have run their

00:21:31,919 --> 00:21:35,679
application

00:21:32,799 --> 00:21:37,520
they are faced with four over mysterious

00:21:35,679 --> 00:21:40,400
logs and they have hundreds of

00:21:37,520 --> 00:21:40,880
spark parameters for tuning and even

00:21:40,400 --> 00:21:43,760
they have

00:21:40,880 --> 00:21:44,559
deployed their spark application to

00:21:43,760 --> 00:21:47,120
production

00:21:44,559 --> 00:21:48,000
after some time it becomes very hard for

00:21:47,120 --> 00:21:50,400
them to track

00:21:48,000 --> 00:21:52,240
what's the current version of uh

00:21:50,400 --> 00:21:53,440
applications only in production because

00:21:52,240 --> 00:21:56,320
let me forget

00:21:53,440 --> 00:21:57,440
oh whether i deploy every comment of my

00:21:56,320 --> 00:22:00,880
master branch to

00:21:57,440 --> 00:22:04,080
production so to resolve the problems

00:22:00,880 --> 00:22:06,400
in this site we build a set of drawers

00:22:04,080 --> 00:22:08,720
first story is the dragon cri this

00:22:06,400 --> 00:22:11,360
enables our customers to develop

00:22:08,720 --> 00:22:12,960
and john spark applications just from

00:22:11,360 --> 00:22:15,120
their laptop

00:22:12,960 --> 00:22:17,280
with the um sync or just on fire they

00:22:15,120 --> 00:22:18,159
can configure how to deploy their

00:22:17,280 --> 00:22:20,720
applications

00:22:18,159 --> 00:22:22,720
they can also configure how they want to

00:22:20,720 --> 00:22:24,559
launch these spark applications

00:22:22,720 --> 00:22:26,000
what they need to do is just to write

00:22:24,559 --> 00:22:28,080
adjacent fire and run

00:22:26,000 --> 00:22:29,520
two commands in their laptop uh dragon

00:22:28,080 --> 00:22:32,320
deploy and dragon

00:22:29,520 --> 00:22:34,480
launch and behind these two commands

00:22:32,320 --> 00:22:35,520
armature are interacting with remote

00:22:34,480 --> 00:22:38,240
assistance

00:22:35,520 --> 00:22:38,240
automatically

00:22:38,640 --> 00:22:41,919
and also we integrated with the ci cd

00:22:41,039 --> 00:22:44,880
system

00:22:41,919 --> 00:22:45,520
users can specify ripple name and git

00:22:44,880 --> 00:22:47,360
tag

00:22:45,520 --> 00:22:49,120
uh so that they can easily track what's

00:22:47,360 --> 00:22:51,840
the current version joining there

00:22:49,120 --> 00:22:53,840
and also they can configure whether to

00:22:51,840 --> 00:22:54,320
automatically release a new version of

00:22:53,840 --> 00:22:57,919
spark

00:22:54,320 --> 00:22:57,919
on a computer in master branch

00:22:58,000 --> 00:23:02,159
and to have our customers debug their

00:23:00,480 --> 00:23:03,679
applications we have a root cause

00:23:02,159 --> 00:23:05,840
analysis pipeline

00:23:03,679 --> 00:23:07,440
here i show the configuration file in

00:23:05,840 --> 00:23:10,880
our root cause

00:23:07,440 --> 00:23:13,039
pipeline which where we map the log

00:23:10,880 --> 00:23:16,559
entries to the possible reason of

00:23:13,039 --> 00:23:16,559
failure over spark applications

00:23:16,880 --> 00:23:20,880
and we also have a working progress

00:23:18,720 --> 00:23:22,559
project called hominix

00:23:20,880 --> 00:23:24,640
which will help our customers to

00:23:22,559 --> 00:23:26,640
automatically to automatically tune

00:23:24,640 --> 00:23:28,880
spark applications based on different

00:23:26,640 --> 00:23:30,799
goals like whether i want to make a

00:23:28,880 --> 00:23:34,840
spark application more efficient

00:23:30,799 --> 00:23:36,400
or i want to make the running time more

00:23:34,840 --> 00:23:39,679
predictable

00:23:36,400 --> 00:23:42,159
so in summary uh spark and uber

00:23:39,679 --> 00:23:43,200
runs at a very unique scale for very

00:23:42,159 --> 00:23:46,400
diverse

00:23:43,200 --> 00:23:49,840
usage uh scenarios and

00:23:46,400 --> 00:23:52,000
our spark systems have evolved from a

00:23:49,840 --> 00:23:54,480
preview register to a full-fledged

00:23:52,000 --> 00:23:57,120
service in the last two to three years

00:23:54,480 --> 00:24:00,240
uh we have a unified spark

00:23:57,120 --> 00:24:02,240
job service we centralized uh we manage

00:24:00,240 --> 00:24:04,240
the versions in a centralized way

00:24:02,240 --> 00:24:05,919
and also we bring a lot of custom

00:24:04,240 --> 00:24:09,120
customized optimizations

00:24:05,919 --> 00:24:12,720
uh in our internal spark distro and

00:24:09,120 --> 00:24:15,039
also we share stories about the uh

00:24:12,720 --> 00:24:17,120
serving spark at uber at the uber scale

00:24:15,039 --> 00:24:19,520
it's very challenging

00:24:17,120 --> 00:24:21,440
we care about reliability but since we

00:24:19,520 --> 00:24:23,840
operate in a larger scale we can lift

00:24:21,440 --> 00:24:27,039
the reliability upper bound by hardening

00:24:23,840 --> 00:24:28,880
service and destroy yourself and also we

00:24:27,039 --> 00:24:30,960
care about the efficiency

00:24:28,880 --> 00:24:33,440
to bring efficiency at a very large

00:24:30,960 --> 00:24:35,279
scale you need to

00:24:33,440 --> 00:24:37,039
build your customer insights with a

00:24:35,279 --> 00:24:40,159
systematic way

00:24:37,039 --> 00:24:41,600
and the usability is the last key to

00:24:40,159 --> 00:24:43,360
making your success in your spark

00:24:41,600 --> 00:24:44,559
service you need to understand the

00:24:43,360 --> 00:24:48,159
customer workflow

00:24:44,559 --> 00:24:51,679
and the problems one by one

00:24:48,159 --> 00:24:52,159
so one last thing uh if you enjoy our

00:24:51,679 --> 00:24:54,159
talks

00:24:52,159 --> 00:24:55,919
and you want to be part of our journey

00:24:54,159 --> 00:24:58,960
to make spark at the uber better and

00:24:55,919 --> 00:25:02,480
better we are hiring this is the

00:24:58,960 --> 00:25:03,039
uh talk and this is the talk and the

00:25:02,480 --> 00:25:05,279
hiring

00:25:03,039 --> 00:25:06,400
and hiring link and feel free to talk us

00:25:05,279 --> 00:25:09,520
uh

00:25:06,400 --> 00:25:15,840
offline and drop me your rhythm thanks

00:25:09,520 --> 00:25:15,840
uh questions i can pick up questions

00:25:20,720 --> 00:25:25,760
so the first question from rob is about

00:25:23,840 --> 00:25:27,600
where you committed the spark pruning

00:25:25,760 --> 00:25:30,559
improvements back to community

00:25:27,600 --> 00:25:31,840
also where you open source unified uh

00:25:30,559 --> 00:25:34,880
job service

00:25:31,840 --> 00:25:35,440
uh so yes you know that is the meta

00:25:34,880 --> 00:25:38,159
branch

00:25:35,440 --> 00:25:39,440
uh spark community has implemented the

00:25:38,159 --> 00:25:42,720
next account rooney

00:25:39,440 --> 00:25:46,720
in spark 3 in a very different way so

00:25:42,720 --> 00:25:48,799
we uh in the con so we cannot control

00:25:46,720 --> 00:25:50,960
contribute back at this point since we

00:25:48,799 --> 00:25:53,520
go into different technical paths

00:25:50,960 --> 00:25:54,159
uh and your sparks3 by default you can

00:25:53,520 --> 00:25:56,960
get this

00:25:54,159 --> 00:25:57,840
feature in but with some limited support

00:25:56,960 --> 00:26:01,039
for

00:25:57,840 --> 00:26:04,640
several pattern of queries in the coming

00:26:01,039 --> 00:26:05,200
sparkler 3.1 which is supposed to be

00:26:04,640 --> 00:26:07,440
released

00:26:05,200 --> 00:26:08,960
in december uh you can get a

00:26:07,440 --> 00:26:10,960
full-fledged nancy caller pruning

00:26:08,960 --> 00:26:12,799
feature

00:26:10,960 --> 00:26:15,120
where you open source the unified job

00:26:12,799 --> 00:26:18,880
service uh

00:26:15,120 --> 00:26:22,080
actually we built on top of open source

00:26:18,880 --> 00:26:24,240
apache levy we have two components

00:26:22,080 --> 00:26:25,600
in the job service one is the gateway

00:26:24,240 --> 00:26:28,880
that has a lot of

00:26:25,600 --> 00:26:31,520
uber specific logic there so we don't uh

00:26:28,880 --> 00:26:32,240
plan to open source that but uh for liby

00:26:31,520 --> 00:26:34,320
we have

00:26:32,240 --> 00:26:36,240
we are building on top of open source

00:26:34,320 --> 00:26:38,080
and in living community there has been

00:26:36,240 --> 00:26:41,200
some discussion about the

00:26:38,080 --> 00:26:42,720
uh similar issues like uh

00:26:41,200 --> 00:26:44,640
leave you started two minutes threads or

00:26:42,720 --> 00:26:46,480
whatever uh

00:26:44,640 --> 00:26:48,000
but uh there haven't been a conclusion

00:26:46,480 --> 00:26:49,919
at some time points

00:26:48,000 --> 00:26:52,159
when there is a agreement we can

00:26:49,919 --> 00:26:54,960
contribute back

00:26:52,159 --> 00:26:56,960
yarn injection manager feature in livvy

00:26:54,960 --> 00:27:01,039
is available in open source

00:26:56,960 --> 00:27:04,159
uh from for ikea about question

00:27:01,039 --> 00:27:04,799
of yarn injection manager feature no it

00:27:04,159 --> 00:27:08,240
is not

00:27:04,799 --> 00:27:10,559
in open source this is actually uh

00:27:08,240 --> 00:27:11,600
achieved by our spark database that's

00:27:10,559 --> 00:27:14,799
called dragon

00:27:11,600 --> 00:27:16,320
you can check out our uber

00:27:14,799 --> 00:27:18,640
engineering blog we have this

00:27:16,320 --> 00:27:20,320
distribution there but as i said

00:27:18,640 --> 00:27:23,919
there are a lot of uber specific

00:27:20,320 --> 00:27:23,919
features in that season so

00:27:24,080 --> 00:27:28,399
we don't have any reason plan to open

00:27:25,919 --> 00:27:28,399
source that

00:27:30,080 --> 00:27:35,200
next question from patrick have you guys

00:27:33,120 --> 00:27:37,840
applied any machine learning to help

00:27:35,200 --> 00:27:40,880
optimize your sparkle parameters

00:27:37,840 --> 00:27:43,360
uh this is a good question we explore

00:27:40,880 --> 00:27:44,960
some way some machine learning-based way

00:27:43,360 --> 00:27:48,000
to optimize the

00:27:44,960 --> 00:27:51,840
parameters but since there are since

00:27:48,000 --> 00:27:55,679
the environment over yarn of cluster is

00:27:51,840 --> 00:27:58,799
so dynamic so it's so hard to capture

00:27:55,679 --> 00:28:02,080
a good training set or feature set

00:27:58,799 --> 00:28:05,120
so now we are thinking about

00:28:02,080 --> 00:28:07,760
a start from root based to

00:28:05,120 --> 00:28:07,760
work on this

00:28:08,640 --> 00:28:13,760
next question when shown about uh are

00:28:11,440 --> 00:28:15,919
your applications node exclusive

00:28:13,760 --> 00:28:18,080
or do you have tasks from multiple

00:28:15,919 --> 00:28:20,480
applications running on the same nodes

00:28:18,080 --> 00:28:21,200
if yes how do you prevent applications

00:28:20,480 --> 00:28:24,880
from

00:28:21,200 --> 00:28:27,440
uh from interfering with each other

00:28:24,880 --> 00:28:29,200
this is also a very good question so in

00:28:27,440 --> 00:28:31,679
our yarn cluster

00:28:29,200 --> 00:28:32,799
we actually set the maximum maximum

00:28:31,679 --> 00:28:37,200
number of cars

00:28:32,799 --> 00:28:39,600
and the memory space every

00:28:37,200 --> 00:28:41,840
container can use so you should provide

00:28:39,600 --> 00:28:44,880
some kind of

00:28:41,840 --> 00:28:46,080
resource isolation but also but here we

00:28:44,880 --> 00:28:49,279
face some issues

00:28:46,080 --> 00:28:51,600
for uh if you say one of

00:28:49,279 --> 00:28:53,200
uh spark application just to dump a lot

00:28:51,600 --> 00:28:55,520
of data to local disk

00:28:53,200 --> 00:28:57,600
that will affect others these kind of

00:28:55,520 --> 00:29:01,360
things are still discussing how

00:28:57,600 --> 00:29:04,399
how can be achieved but currently we

00:29:01,360 --> 00:29:07,200
just limited

00:29:04,399 --> 00:29:12,159
uh of data can be dumped to local disk

00:29:07,200 --> 00:29:15,279
from every spark application uh

00:29:12,159 --> 00:29:17,679
next question from events how is the

00:29:15,279 --> 00:29:19,039
user code of being shipped by dronecri

00:29:17,679 --> 00:29:21,600
is the user compiled

00:29:19,039 --> 00:29:22,399
and the scp and rsync that you get away

00:29:21,600 --> 00:29:25,679
or

00:29:22,399 --> 00:29:26,480
resolution yes it is essentially a rca

00:29:25,679 --> 00:29:28,480
you package

00:29:26,480 --> 00:29:29,840
and then you are sync your database and

00:29:28,480 --> 00:29:33,840
then upload it to

00:29:29,840 --> 00:29:36,799
hdfs for downloading uh

00:29:33,840 --> 00:29:37,039
do you enable c group next question do

00:29:36,799 --> 00:29:40,240
you

00:29:37,039 --> 00:29:42,880
never see group or what uh

00:29:40,240 --> 00:29:44,960
way uh you know we will never still

00:29:42,880 --> 00:29:46,240
group in yarn

00:29:44,960 --> 00:29:47,919
yeah i think so this is probably a

00:29:46,240 --> 00:29:48,880
follow-up question from the previous

00:29:47,919 --> 00:29:55,840
question yep

00:29:48,880 --> 00:29:55,840
yes i think the answer is yes

00:29:57,679 --> 00:30:00,559
any more questions

00:30:07,360 --> 00:30:10,799
yeah i guess that's all the question uh

00:30:09,520 --> 00:30:13,919
thank you everyone for

00:30:10,799 --> 00:30:15,440
joining the session um as i mentioned we

00:30:13,919 --> 00:30:18,240
are hiring so

00:30:15,440 --> 00:30:18,880
and um you know to talk to us if you are

00:30:18,240 --> 00:30:22,159
interested

00:30:18,880 --> 00:30:26,000
uh we also have the remote shuffle

00:30:22,159 --> 00:30:37,840
talk to check that out as well

00:30:26,000 --> 00:30:37,840
thank you yes thank you

00:31:16,159 --> 00:31:18,240

YouTube URL: https://www.youtube.com/watch?v=1CmWlZvmPF8


