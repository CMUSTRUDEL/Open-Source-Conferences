Title: Zeus: Uber’s Highly Scalable and Distributed Shuffle as a Service
Publication date: 2020-10-21
Playlist: ApacheCon @Home 2020: Big Data (Track 2)
Description: 
	Zeus: Uber’s Highly Scalable and Distributed Shuffle as a Service
Mayank Bansal, Bo Yang

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Zeus is an efficient, highly scalable and distributed shuffle as a service which is powering all Data processing (Spark and Hive) at Uber. Uber runs one of the largest Spark and Hive clusters on top of YARN in industry which leads to many issues such as hardware failures (Burn out Disks), reliability and scalability challenges. Zeus is built ground up to support hundreds of thousands of jobs and millions of containers which shuffles petabytes of shuffle data. Zeus has changed the paradigm of current external shuffle which resulted in far better performance for shuffle. Although the shuffle data is getting written Remote, the performance is better or the same for most of the Jobs. In this talk we’ll take a deep dive into the Zeus architecture and describe how it’s deployed at Uber. We will then describe how it’s integrated to run shuffle for Spark, and contrast it with Spark’s built-in sort-based shuffle mechanism. We will also talk about future roadmap and plans for Zeus.

Mayank Bansal:
Mayank Bansal is currently working as a Staff engineer at Uber in data infrastructure team. He is co-author of Peloton. He is Apache Hadoop Committer and Oozie PMC and Committer. Previously he was working at ebay in hadoop platform team leading YARN and MapReduce effort. Prior to that he was working at Yahoo and worked on Oozie.
Bo Yang:
Bo is Sr. Software Engineer II in Uber and working on Spark team. In the past he worked on many streaming technologies.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:26,640 --> 00:00:31,439
uh

00:00:28,160 --> 00:00:33,120
you can see my screen right yes i can

00:00:31,439 --> 00:00:35,360
see your screen yes

00:00:33,120 --> 00:00:36,480
okay hello everyone this is mayank

00:00:35,360 --> 00:00:39,360
bansal um

00:00:36,480 --> 00:00:41,120
working in a data infra group at uber

00:00:39,360 --> 00:00:44,000
and i'm presenting with my

00:00:41,120 --> 00:00:46,160
colleague bo yan who also will work in

00:00:44,000 --> 00:00:49,920
the same group as me

00:00:46,160 --> 00:00:51,920
and we and we are here to present zias

00:00:49,920 --> 00:00:59,600
uber's highly skillable and distributed

00:00:51,920 --> 00:01:02,960
shuffle as a service

00:00:59,600 --> 00:01:05,360
let's talk about um a bit about uber

00:01:02,960 --> 00:01:06,560
these numbers are little old so i don't

00:01:05,360 --> 00:01:10,320
have a current number so

00:01:06,560 --> 00:01:12,640
um user is a globe oh no so yeah so

00:01:10,320 --> 00:01:13,439
the number could be little bit different

00:01:12,640 --> 00:01:16,320
uh

00:01:13,439 --> 00:01:17,439
currently uh anyway so uber is a global

00:01:16,320 --> 00:01:19,600
company

00:01:17,439 --> 00:01:21,040
we have completed 15 billion trips

00:01:19,600 --> 00:01:24,400
approximately complete

00:01:21,040 --> 00:01:27,439
18 million trips

00:01:24,400 --> 00:01:29,119
per day we have 16 we are we are on six

00:01:27,439 --> 00:01:32,479
continents 69 countries

00:01:29,119 --> 00:01:35,840
and 10 000 cities and we have

00:01:32,479 --> 00:01:39,360
103 million active monthly users

00:01:35,840 --> 00:01:43,119
who take rights every month

00:01:39,360 --> 00:01:43,119
and we have five million active drivers

00:01:44,479 --> 00:01:47,600
uh let's talk about data and ml use

00:01:46,320 --> 00:01:49,520
cases

00:01:47,600 --> 00:01:52,159
uber is a data driven company and pretty

00:01:49,520 --> 00:01:54,960
much everything we do is data driven

00:01:52,159 --> 00:01:57,439
data ml is the backbone of all the

00:01:54,960 --> 00:01:59,200
processing happens everywhere

00:01:57,439 --> 00:02:00,640
here are some of the use cases i listed

00:01:59,200 --> 00:02:04,079
such as ubereats

00:02:00,640 --> 00:02:06,240
epa self-driving cars etc however there

00:02:04,079 --> 00:02:06,799
are so many which i can't even list in

00:02:06,240 --> 00:02:10,800
this

00:02:06,799 --> 00:02:13,520
one slide so all these use cases

00:02:10,800 --> 00:02:16,160
are actually being supported by data and

00:02:13,520 --> 00:02:16,160
analytical

00:02:16,480 --> 00:02:20,840
let's talk about uh some of the these

00:02:18,560 --> 00:02:23,120
use cases little bit

00:02:20,840 --> 00:02:25,520
more

00:02:23,120 --> 00:02:26,160
let's first talk about our etas right so

00:02:25,520 --> 00:02:28,400
eta

00:02:26,160 --> 00:02:30,239
etas are the core to uber experience

00:02:28,400 --> 00:02:36,560
whenever any use

00:02:30,239 --> 00:02:40,400
user open their app and they see

00:02:36,560 --> 00:02:42,160
um open their app and they see the cars

00:02:40,400 --> 00:02:44,400
available in five minute distance that

00:02:42,160 --> 00:02:46,640
information is coming from ek system

00:02:44,400 --> 00:02:49,440
etas are used by many other systems in

00:02:46,640 --> 00:02:52,160
uber such as each

00:02:49,440 --> 00:02:53,200
etas are generated by route-based

00:02:52,160 --> 00:02:55,120
algorithm and

00:02:53,200 --> 00:02:56,800
ml model predicts the route at the

00:02:55,120 --> 00:02:59,440
runtime

00:02:56,800 --> 00:03:00,000
we also have a feedback loop to our

00:02:59,440 --> 00:03:03,200
models

00:03:00,000 --> 00:03:05,360
which gets improved day by day based on

00:03:03,200 --> 00:03:08,159
the et error we get

00:03:05,360 --> 00:03:10,159
to the better user experience each years

00:03:08,159 --> 00:03:13,440
are improved a lot

00:03:10,159 --> 00:03:16,000
um all thanks to data and ml use

00:03:13,440 --> 00:03:16,000
attribute

00:03:17,360 --> 00:03:20,480
let's talk about um driver and rider

00:03:19,920 --> 00:03:22,239
match

00:03:20,480 --> 00:03:24,799
right this is another big use case for

00:03:22,239 --> 00:03:27,760
uber whenever

00:03:24,799 --> 00:03:30,159
um user end user open their app and

00:03:27,760 --> 00:03:32,720
request to write based on their location

00:03:30,159 --> 00:03:34,400
uber uber app actually optimize the

00:03:32,720 --> 00:03:36,720
rider and driver

00:03:34,400 --> 00:03:37,760
all these optimizations are done by data

00:03:36,720 --> 00:03:40,480
and ml models

00:03:37,760 --> 00:03:42,400
at the runtime we also predict if user

00:03:40,480 --> 00:03:47,840
will take a trip or not

00:03:42,400 --> 00:03:47,840
using our machine learning models

00:03:48,239 --> 00:03:54,480
let's talk about each right each is a

00:03:51,519 --> 00:03:56,159
very big business for uber

00:03:54,480 --> 00:03:57,920
pretty much everything which gets

00:03:56,159 --> 00:03:59,519
rendered on the uber eats app

00:03:57,920 --> 00:04:01,920
is through the hundreds of models in the

00:03:59,519 --> 00:04:04,159
background we use machine learning

00:04:01,920 --> 00:04:07,280
models for ranking of restaurants

00:04:04,159 --> 00:04:09,840
ranking of dishes preferences

00:04:07,280 --> 00:04:11,120
predictions delivery times and even

00:04:09,840 --> 00:04:14,000
search ranking

00:04:11,120 --> 00:04:15,120
on all the restaurants as well as for

00:04:14,000 --> 00:04:17,519
the dishes you

00:04:15,120 --> 00:04:17,519
ordered

00:04:18,720 --> 00:04:23,680
let's talk about another big use cases

00:04:20,560 --> 00:04:23,680
for uber which is

00:04:24,240 --> 00:04:28,880
self-driving cars as we all know that

00:04:27,120 --> 00:04:30,479
data and ml is a crucial piece of

00:04:28,880 --> 00:04:32,639
autonomous vehicles

00:04:30,479 --> 00:04:34,320
each and every prediction run time

00:04:32,639 --> 00:04:38,479
decisions maps

00:04:34,320 --> 00:04:43,040
route all is driven by mlm data

00:04:38,479 --> 00:04:47,440
mln data is

00:04:43,040 --> 00:04:47,440
giving is doing a lot of uh uh

00:04:47,759 --> 00:04:51,280
benefit for the autonomous vehicle for

00:04:50,560 --> 00:04:53,759
each and so

00:04:51,280 --> 00:04:54,639
the the picture you see on the uh on the

00:04:53,759 --> 00:04:57,120
slide

00:04:54,639 --> 00:04:59,040
is pretty much what your car sees at the

00:04:57,120 --> 00:04:59,440
runtime and all these being rendered

00:04:59,040 --> 00:05:03,840
through

00:04:59,440 --> 00:05:03,840
mln data for the uber

00:05:05,440 --> 00:05:10,000
let's talk about the uber's data stacks

00:05:07,360 --> 00:05:12,400
how it looks like

00:05:10,000 --> 00:05:14,320
we have lot of events which gets

00:05:12,400 --> 00:05:15,759
generated through app and otherwise such

00:05:14,320 --> 00:05:19,120
as mobile app events

00:05:15,759 --> 00:05:20,720
device telemetry micro services

00:05:19,120 --> 00:05:22,720
generated lot of emails

00:05:20,720 --> 00:05:24,320
we also collect lot of database events

00:05:22,720 --> 00:05:27,360
as well as third party feeds

00:05:24,320 --> 00:05:29,440
we collect them using kafka

00:05:27,360 --> 00:05:31,280
and then we ingest them into the

00:05:29,440 --> 00:05:34,080
in-memory database such as pino

00:05:31,280 --> 00:05:37,600
at least db or the tiered offline

00:05:34,080 --> 00:05:40,639
storage such as hdfs

00:05:37,600 --> 00:05:43,520
on top of it we have

00:05:40,639 --> 00:05:44,639
compute fabric which is consists of yarn

00:05:43,520 --> 00:05:46,320
and pelleting

00:05:44,639 --> 00:05:48,400
everybody knows is a hadoop compute

00:05:46,320 --> 00:05:50,960
engine we also have something new

00:05:48,400 --> 00:05:52,880
called palatine pelleting is run on

00:05:50,960 --> 00:05:55,360
mesos and it's overs unified

00:05:52,880 --> 00:05:57,520
resource scheduler our data and ml

00:05:55,360 --> 00:06:00,800
workloads run on both the schedulers

00:05:57,520 --> 00:06:03,199
yarn as well as spectrum most uh

00:06:00,800 --> 00:06:05,520
in our in our processing yarn is the

00:06:03,199 --> 00:06:09,520
most prominent one which we use

00:06:05,520 --> 00:06:11,840
on top of it we have string processing

00:06:09,520 --> 00:06:13,759
engines such as flink as well as we have

00:06:11,840 --> 00:06:17,039
bought batch processing engines such as

00:06:13,759 --> 00:06:20,800
spark phase map produce

00:06:17,039 --> 00:06:24,479
on top of it we have query engines

00:06:20,800 --> 00:06:25,199
such as ethenex uh for our real-time

00:06:24,479 --> 00:06:27,120
education

00:06:25,199 --> 00:06:28,880
aggregation queries we have presto and

00:06:27,120 --> 00:06:29,600
vertica for a doc and interactive

00:06:28,880 --> 00:06:31,280
queries

00:06:29,600 --> 00:06:33,039
and we have high for complex in the

00:06:31,280 --> 00:06:34,639
batch processing

00:06:33,039 --> 00:06:36,400
on top of it we have all these

00:06:34,639 --> 00:06:39,520
orchestration engines such as

00:06:36,400 --> 00:06:41,280
piper which is data preparation or the

00:06:39,520 --> 00:06:41,919
orchestration workflow orchestration

00:06:41,280 --> 00:06:43,360
engine

00:06:41,919 --> 00:06:45,759
we have different dashboards we have

00:06:43,360 --> 00:06:48,080
different ad hoc query

00:06:45,759 --> 00:06:52,160
editors such as query builder and then

00:06:48,080 --> 00:06:52,160
the bi tools such as gsw and w

00:06:53,680 --> 00:06:59,919
now let's talk about

00:06:57,199 --> 00:07:01,280
uber's ml stock among staff which is

00:06:59,919 --> 00:07:03,520
michelangelo

00:07:01,280 --> 00:07:04,560
michelangelo is a very prominent tool

00:07:03,520 --> 00:07:08,240
which is being used

00:07:04,560 --> 00:07:11,680
and is very is very popular um also

00:07:08,240 --> 00:07:15,759
so what a mac michelangelo

00:07:11,680 --> 00:07:18,000
does is we have it generates

00:07:15,759 --> 00:07:19,759
it generates all the events of the kafka

00:07:18,000 --> 00:07:21,919
and then it gets prepared

00:07:19,759 --> 00:07:23,360
uh through stream processing flint and

00:07:21,919 --> 00:07:25,599
the bad processing hive

00:07:23,360 --> 00:07:26,400
the stream processing will put this

00:07:25,599 --> 00:07:29,759
information

00:07:26,400 --> 00:07:32,639
into uh out

00:07:29,759 --> 00:07:33,599
sinks like kafka again or any other uh

00:07:32,639 --> 00:07:35,360
cassandra

00:07:33,599 --> 00:07:37,199
and the batch processing high when they

00:07:35,360 --> 00:07:40,880
need to put them into the

00:07:37,199 --> 00:07:42,560
data lake like hdfs and then in ml we do

00:07:40,880 --> 00:07:45,280
like lot of prototyping we do this

00:07:42,560 --> 00:07:48,319
prototyping through jupiter notebooks

00:07:45,280 --> 00:07:48,319
or the spark magic

00:07:48,960 --> 00:07:54,000
after that we used for the trainings

00:07:51,280 --> 00:07:55,199
which we use tensorflow pytorch executes

00:07:54,000 --> 00:07:56,800
and spark ml

00:07:55,199 --> 00:07:59,360
and for the interference we for the real

00:07:56,800 --> 00:08:01,039
real-time prediction services we use

00:07:59,360 --> 00:08:02,400
for the interference as well as batch

00:08:01,039 --> 00:08:04,080
prediction jobs

00:08:02,400 --> 00:08:06,639
we have different stores such as feature

00:08:04,080 --> 00:08:08,560
stores to store all the features we have

00:08:06,639 --> 00:08:10,400
models tools for store all the models

00:08:08,560 --> 00:08:11,280
and then we have also the metric stores

00:08:10,400 --> 00:08:13,039
where we

00:08:11,280 --> 00:08:16,720
can slice and dice all the metrics

00:08:13,039 --> 00:08:16,720
together to come up with the models

00:08:20,720 --> 00:08:27,599
let's talk about little bit of apache

00:08:22,879 --> 00:08:30,240
spark at uber

00:08:27,599 --> 00:08:31,280
apache spark um is the primary analytics

00:08:30,240 --> 00:08:33,279
execution engine

00:08:31,280 --> 00:08:35,599
where pretty much 90 percent of the

00:08:33,279 --> 00:08:37,360
processing happens through spark

00:08:35,599 --> 00:08:38,800
whether that is a normal spark or a high

00:08:37,360 --> 00:08:41,200
one spark

00:08:38,800 --> 00:08:42,159
we run on spark on yarn as well as on

00:08:41,200 --> 00:08:45,440
peliton

00:08:42,159 --> 00:08:47,040
for all the spark we use to use external

00:08:45,440 --> 00:08:50,399
shuffle surveys

00:08:47,040 --> 00:08:54,399
um i i'm talking about before the zs we

00:08:50,399 --> 00:08:54,399
used to use the external triple service

00:08:55,519 --> 00:08:59,200
let's talk about um the external shuffle

00:08:58,480 --> 00:09:01,920
service

00:08:59,200 --> 00:09:03,279
for little bit the context we have

00:09:01,920 --> 00:09:05,279
mapper host and i mean

00:09:03,279 --> 00:09:07,040
as you see in this figure we have

00:09:05,279 --> 00:09:07,600
mappers and the reducers they are mapper

00:09:07,040 --> 00:09:10,560
host and

00:09:07,600 --> 00:09:12,480
the reducer host the we have mapper host

00:09:10,560 --> 00:09:13,360
mapper task generates lot of shuffle

00:09:12,480 --> 00:09:16,160
data

00:09:13,360 --> 00:09:17,040
which gets stored into data files on the

00:09:16,160 --> 00:09:19,680
local machine

00:09:17,040 --> 00:09:21,519
through local shuffle service there are

00:09:19,680 --> 00:09:23,040
different partitions being stored into

00:09:21,519 --> 00:09:24,800
those machines and then there is index

00:09:23,040 --> 00:09:25,920
file which actually goes and you know

00:09:24,800 --> 00:09:28,480
have this

00:09:25,920 --> 00:09:29,360
index for each all these partitions

00:09:28,480 --> 00:09:31,519
similarly you

00:09:29,360 --> 00:09:33,040
you can see there is a host which runs

00:09:31,519 --> 00:09:36,000
the

00:09:33,040 --> 00:09:37,519
other executors which are running uh

00:09:36,000 --> 00:09:39,200
reduced

00:09:37,519 --> 00:09:40,560
and then in the reducer does there is

00:09:39,200 --> 00:09:42,160
something called shuffle reader which

00:09:40,560 --> 00:09:47,040
will go and connect

00:09:42,160 --> 00:09:50,640
each and every mapper machines through

00:09:47,040 --> 00:09:53,680
shuffle um

00:09:50,640 --> 00:09:56,240
through shuffle service um

00:09:53,680 --> 00:09:57,440
to the reducer hole sorry the mapper

00:09:56,240 --> 00:10:00,000
host and then

00:09:57,440 --> 00:10:00,720
uh stream all the output or mapper

00:10:00,000 --> 00:10:02,560
outputs

00:10:00,720 --> 00:10:04,000
right and then combine them put them

00:10:02,560 --> 00:10:08,079
business logic on top of it

00:10:04,000 --> 00:10:10,560
and then store it into the uh

00:10:08,079 --> 00:10:11,760
store it into the local machine as well

00:10:10,560 --> 00:10:15,920
as

00:10:11,760 --> 00:10:15,920
maybe that storing part and he was still

00:10:16,000 --> 00:10:20,880
here or see i cannot see me

00:10:25,519 --> 00:10:30,000
hey boy i can't hear you i'm not sure if

00:10:28,160 --> 00:10:33,120
you can hear me okay

00:10:30,000 --> 00:10:36,240
thank you guys um

00:10:33,120 --> 00:10:38,880
so uh okay

00:10:36,240 --> 00:10:40,560
sorry um so yeah so then reducer will go

00:10:38,880 --> 00:10:41,519
and stream output and then put the data

00:10:40,560 --> 00:10:44,079
into the local

00:10:41,519 --> 00:10:45,839
into the hdfs or any other storage

00:10:44,079 --> 00:10:46,560
however that could be a multi-step

00:10:45,839 --> 00:10:49,360
process where

00:10:46,560 --> 00:10:50,720
you you may have to have different

00:10:49,360 --> 00:10:53,440
spills which you need to combine

00:10:50,720 --> 00:10:56,160
etcetera so this is how the whole spark

00:10:53,440 --> 00:10:57,170
external shuffle service work right this

00:10:56,160 --> 00:10:58,640
is just for context

00:10:57,170 --> 00:11:00,399
[Music]

00:10:58,640 --> 00:11:01,839
so there are certain limitations

00:11:00,399 --> 00:11:04,959
regarding this process

00:11:01,839 --> 00:11:07,279
right and the limitations are the first

00:11:04,959 --> 00:11:10,320
limitation is

00:11:07,279 --> 00:11:12,959
for the context we use uh compute and

00:11:10,320 --> 00:11:15,440
storage separately in our data centers

00:11:12,959 --> 00:11:16,560
so what it means is we use the base

00:11:15,440 --> 00:11:20,480
machines

00:11:16,560 --> 00:11:22,560
for our compute right and which is

00:11:20,480 --> 00:11:25,600
pretty much

00:11:22,560 --> 00:11:28,720
having one ssds so generally there is a

00:11:25,600 --> 00:11:31,839
concept called dwpd in ssds which is

00:11:28,720 --> 00:11:32,240
you write um how much data you write per

00:11:31,839 --> 00:11:35,440
day

00:11:32,240 --> 00:11:38,640
on the disk right so generally

00:11:35,440 --> 00:11:42,079
it is one so and then if you

00:11:38,640 --> 00:11:44,470
have a dwpd as one what it means is your

00:11:42,079 --> 00:11:45,760
disk you can write and

00:11:44,470 --> 00:11:48,800
[Music]

00:11:45,760 --> 00:11:51,200
delete one times a day

00:11:48,800 --> 00:11:52,480
for three years so then this disk will

00:11:51,200 --> 00:11:55,680
work for three years

00:11:52,480 --> 00:11:57,760
however at uber we've been using as i

00:11:55,680 --> 00:12:00,240
said earlier that we've been using spark

00:11:57,760 --> 00:12:01,360
for the most of the our processing we

00:12:00,240 --> 00:12:03,519
are

00:12:01,360 --> 00:12:05,920
producing so much shuffle data that each

00:12:03,519 --> 00:12:09,519
machine actually writes

00:12:05,920 --> 00:12:10,000
four to five times which caused our ssds

00:12:09,519 --> 00:12:13,200
to wear

00:12:10,000 --> 00:12:16,320
out very very fast uh hence

00:12:13,200 --> 00:12:18,240
uh there were the the machines or the

00:12:16,320 --> 00:12:19,920
hardware which needs to be replaced

00:12:18,240 --> 00:12:21,440
after three years has to be has to

00:12:19,920 --> 00:12:23,279
replace it like in six months

00:12:21,440 --> 00:12:24,639
right so that was one of the major

00:12:23,279 --> 00:12:28,000
concern which we

00:12:24,639 --> 00:12:31,200
uh wanted to avoid uh

00:12:28,000 --> 00:12:33,120
through zeus second real second issue is

00:12:31,200 --> 00:12:35,120
the reliability right um

00:12:33,120 --> 00:12:37,360
there is always because we the compute

00:12:35,120 --> 00:12:39,600
machines are base machines

00:12:37,360 --> 00:12:41,360
and the reliability and they have like

00:12:39,600 --> 00:12:43,360
limited storage so there is always a

00:12:41,360 --> 00:12:45,040
nice evolution right

00:12:43,360 --> 00:12:47,200
application or multiple application and

00:12:45,040 --> 00:12:50,800
writing lot of data which can

00:12:47,200 --> 00:12:52,480
fill up the disk and that can cause

00:12:50,800 --> 00:12:53,760
problems into other application as well

00:12:52,480 --> 00:12:55,040
as the same application which is writing

00:12:53,760 --> 00:12:56,800
so much data

00:12:55,040 --> 00:12:58,800
there are other issues like machine goes

00:12:56,800 --> 00:13:00,880
down this failures

00:12:58,800 --> 00:13:02,880
and then pretty much there are use cases

00:13:00,880 --> 00:13:03,440
which write so much shuffle data which

00:13:02,880 --> 00:13:06,079
cannot

00:13:03,440 --> 00:13:08,240
come or which cannot reside into one

00:13:06,079 --> 00:13:09,839
machine

00:13:08,240 --> 00:13:13,440
those use cases you know cannot be

00:13:09,839 --> 00:13:15,120
enabled running here

00:13:13,440 --> 00:13:17,519
there is another concerns about

00:13:15,120 --> 00:13:20,639
kubernetes um

00:13:17,519 --> 00:13:23,279
dynamic allocation

00:13:20,639 --> 00:13:24,800
so because kubernetes does not have a

00:13:23,279 --> 00:13:26,399
remote

00:13:24,800 --> 00:13:28,480
we cannot do dynamic allocation on

00:13:26,399 --> 00:13:30,000
kubernetes so we probably need to write

00:13:28,480 --> 00:13:32,959
something external

00:13:30,000 --> 00:13:34,000
to being able to go to capabilities and

00:13:32,959 --> 00:13:37,279
other

00:13:34,000 --> 00:13:40,399
main concern was the co-location so

00:13:37,279 --> 00:13:43,839
um in uber uh are very much

00:13:40,399 --> 00:13:45,440
efficiency driven uh company so what we

00:13:43,839 --> 00:13:48,240
do is we wanted to enable our

00:13:45,440 --> 00:13:48,959
batch and stateless processing together

00:13:48,240 --> 00:13:51,199
and which

00:13:48,959 --> 00:13:53,040
can actually you can run stateless

00:13:51,199 --> 00:13:54,480
services with the bad services however

00:13:53,040 --> 00:13:57,680
our bad services likes

00:13:54,480 --> 00:13:59,680
too much data the stateless services get

00:13:57,680 --> 00:14:02,240
impacted because of that on the same

00:13:59,680 --> 00:14:06,320
machine so for them to

00:14:02,240 --> 00:14:09,440
be run together we need to uh

00:14:06,320 --> 00:14:12,560
we need to move the right part

00:14:09,440 --> 00:14:12,959
from the disk to somewhere external

00:14:12,560 --> 00:14:14,480
where

00:14:12,959 --> 00:14:16,399
the both the processing can happen

00:14:14,480 --> 00:14:18,560
together so these are the main other

00:14:16,399 --> 00:14:22,880
some of the concerns which we wanted to

00:14:18,560 --> 00:14:24,880
uh highlight and because of that these

00:14:22,880 --> 00:14:28,079
challenges we actually started the

00:14:24,880 --> 00:14:28,079
project called bgs

00:14:28,320 --> 00:14:34,480
so before we actually we started we

00:14:32,399 --> 00:14:36,560
experimented with different approaches

00:14:34,480 --> 00:14:38,480
in order to solve these challenges

00:14:36,560 --> 00:14:40,399
which we mentioned earlier the main and

00:14:38,480 --> 00:14:42,480
foremost point was to reduce the local

00:14:40,399 --> 00:14:45,120
rights however that seems not possible

00:14:42,480 --> 00:14:47,440
as we wanted to increase our workloads

00:14:45,120 --> 00:14:49,360
rather removing it so the other way we

00:14:47,440 --> 00:14:50,880
wanted is remove writes from the local

00:14:49,360 --> 00:14:52,880
and write somewhere else right

00:14:50,880 --> 00:14:54,160
we did lot of experiments in order to

00:14:52,880 --> 00:14:55,120
come up with the correct design

00:14:54,160 --> 00:14:57,360
physiques

00:14:55,120 --> 00:14:59,199
first we abstracted our shuffle manager

00:14:57,360 --> 00:15:02,959
with the external storage

00:14:59,199 --> 00:15:05,279
um such as nfs or hdfs

00:15:02,959 --> 00:15:06,160
however our performance benchmarking

00:15:05,279 --> 00:15:09,279
shown

00:15:06,160 --> 00:15:12,399
that nfs was twice extra slower and the

00:15:09,279 --> 00:15:13,760
hdfs was 5x lower

00:15:12,399 --> 00:15:15,839
though we were writing synchronous

00:15:13,760 --> 00:15:18,160
rights because um hdfs

00:15:15,839 --> 00:15:20,399
is not supporting his synchronous right

00:15:18,160 --> 00:15:24,399
so that was

00:15:20,399 --> 00:15:24,399
uh other then what we did is

00:15:24,959 --> 00:15:30,720
we actually um

00:15:28,240 --> 00:15:31,440
we we really pretty much experimented

00:15:30,720 --> 00:15:34,560
with

00:15:31,440 --> 00:15:36,639
semi asynchronous right uh

00:15:34,560 --> 00:15:38,399
using multiple threads as we know hdfs

00:15:36,639 --> 00:15:40,560
does not support asynchronous ways

00:15:38,399 --> 00:15:41,600
so we have to go with a similar

00:15:40,560 --> 00:15:43,600
asynchronous approach

00:15:41,600 --> 00:15:44,720
so we had like different threads which

00:15:43,600 --> 00:15:47,920
were writing

00:15:44,720 --> 00:15:49,600
etc to different files and then even

00:15:47,920 --> 00:15:52,639
though that experiment also didn't

00:15:49,600 --> 00:15:54,880
go well it was the even doing all this

00:15:52,639 --> 00:15:58,079
we had like four extra

00:15:54,880 --> 00:16:00,560
performance right

00:15:58,079 --> 00:16:02,720
so then what the other approach we took

00:16:00,560 --> 00:16:05,120
is we wrote a very

00:16:02,720 --> 00:16:06,880
lightweight streaming server and we

00:16:05,120 --> 00:16:08,160
started streaming lights directly to

00:16:06,880 --> 00:16:10,720
hdfs

00:16:08,160 --> 00:16:11,440
uh for the first experiment and that was

00:16:10,720 --> 00:16:14,800
like

00:16:11,440 --> 00:16:17,040
1.5 times lower um

00:16:14,800 --> 00:16:18,480
and then what we tried is we directly

00:16:17,040 --> 00:16:21,839
stream those

00:16:18,480 --> 00:16:23,279
rights to the local instead of hdfs

00:16:21,839 --> 00:16:24,000
however that also had the slow

00:16:23,279 --> 00:16:25,759
performance

00:16:24,000 --> 00:16:27,199
because there's a lot of skills etc so

00:16:25,759 --> 00:16:28,720
that is not uh

00:16:27,199 --> 00:16:30,320
that was also not having the same

00:16:28,720 --> 00:16:32,959
performance as we get the external

00:16:30,320 --> 00:16:32,959
shipping service

00:16:35,199 --> 00:16:42,000
so um then what we did is

00:16:38,399 --> 00:16:43,839
we kind of went to the backboard on

00:16:42,000 --> 00:16:44,399
blackboard and then we said okay what we

00:16:43,839 --> 00:16:47,040
need to do

00:16:44,399 --> 00:16:48,480
so we actually thought okay streaming

00:16:47,040 --> 00:16:51,279
rights to the local storage

00:16:48,480 --> 00:16:52,000
is the most prominent better performance

00:16:51,279 --> 00:16:54,399
we got

00:16:52,000 --> 00:16:57,199
so we wanted to improve it further so

00:16:54,399 --> 00:16:57,199
what we did is

00:16:57,600 --> 00:17:03,759
we pretty much change

00:17:00,639 --> 00:17:05,280
the map reduce paradigm in

00:17:03,759 --> 00:17:07,199
what it means changes we actually

00:17:05,280 --> 00:17:08,880
reversed it uh

00:17:07,199 --> 00:17:10,720
as we saw in the previous slides in map

00:17:08,880 --> 00:17:11,280
release framework mappers write data to

00:17:10,720 --> 00:17:13,280
local

00:17:11,280 --> 00:17:14,640
and reducer go to each mapper and fetch

00:17:13,280 --> 00:17:17,039
the data

00:17:14,640 --> 00:17:18,079
what we did is we made all mappers for

00:17:17,039 --> 00:17:20,240
the same partition

00:17:18,079 --> 00:17:21,360
to go to the same remote server for

00:17:20,240 --> 00:17:24,319
mapper output

00:17:21,360 --> 00:17:25,600
and our rss server wrote their data

00:17:24,319 --> 00:17:28,720
sequentially onto a

00:17:25,600 --> 00:17:31,520
files and in the reducer side

00:17:28,720 --> 00:17:33,120
reducer will go the partition it is

00:17:31,520 --> 00:17:33,919
assigned to it will go to the same

00:17:33,120 --> 00:17:37,679
server

00:17:33,919 --> 00:17:38,640
and fetch that file from multiple files

00:17:37,679 --> 00:17:41,520
sequentially

00:17:38,640 --> 00:17:42,960
right what it means is mappers are

00:17:41,520 --> 00:17:44,400
multiple mappers are writing to the same

00:17:42,960 --> 00:17:45,840
machine

00:17:44,400 --> 00:17:48,080
going to the same one machine and

00:17:45,840 --> 00:17:51,120
getting all the data

00:17:48,080 --> 00:17:53,440
that helped us a lot uh

00:17:51,120 --> 00:17:54,799
because that helped us in two ways one

00:17:53,440 --> 00:17:57,520
is the latencies got

00:17:54,799 --> 00:17:58,080
improved a lot second because of your

00:17:57,520 --> 00:18:01,520
writing

00:17:58,080 --> 00:18:04,000
on ssg sequential rights it helped

00:18:01,520 --> 00:18:05,360
improving the dwpd of the disk which we

00:18:04,000 --> 00:18:08,480
are using

00:18:05,360 --> 00:18:09,760
right so that that too

00:18:08,480 --> 00:18:11,679
that these are the two things which

00:18:09,760 --> 00:18:14,080
helped us a lot

00:18:11,679 --> 00:18:15,679
our other optimizations are we are

00:18:14,080 --> 00:18:16,559
directly streaming to the shuffle server

00:18:15,679 --> 00:18:20,000
to the disk

00:18:16,559 --> 00:18:20,320
and there is no temporary spill files in

00:18:20,000 --> 00:18:22,640
this

00:18:20,320 --> 00:18:24,320
executable side we are avoiding that so

00:18:22,640 --> 00:18:27,120
these are the things which actually

00:18:24,320 --> 00:18:29,440
improved the performance a bit a lot

00:18:27,120 --> 00:18:29,440
actually

00:18:32,960 --> 00:18:37,600
we have as you see earlier slide we have

00:18:35,840 --> 00:18:38,080
multiple cores which are executors

00:18:37,600 --> 00:18:39,840
running

00:18:38,080 --> 00:18:41,440
mapper task and then the multiple host

00:18:39,840 --> 00:18:43,360
which is running reducer task

00:18:41,440 --> 00:18:44,880
the shuffle manager has been abstracted

00:18:43,360 --> 00:18:46,960
out to write

00:18:44,880 --> 00:18:48,080
shuffle output to the remote shuffle

00:18:46,960 --> 00:18:51,200
service

00:18:48,080 --> 00:18:51,200
and we have like a

00:18:51,280 --> 00:18:54,960
zookeeper which can actually let you

00:18:53,120 --> 00:18:56,559
know which which partition or which

00:18:54,960 --> 00:18:58,799
server you need to choose

00:18:56,559 --> 00:19:00,400
uh i think bo is going to talk about it

00:18:58,799 --> 00:19:03,280
in detail a little bit

00:19:00,400 --> 00:19:05,360
so what in the overall level here mapper

00:19:03,280 --> 00:19:06,480
task will use shuffle manager to choose

00:19:05,360 --> 00:19:09,360
one server

00:19:06,480 --> 00:19:10,000
and then all the same partition will

00:19:09,360 --> 00:19:13,039
return to

00:19:10,000 --> 00:19:14,320
that remote shuffle server those

00:19:13,039 --> 00:19:16,720
partition is

00:19:14,320 --> 00:19:17,440
returned to the local disk and as i said

00:19:16,720 --> 00:19:19,440
earlier

00:19:17,440 --> 00:19:20,880
the host which is running reducer will

00:19:19,440 --> 00:19:24,160
go to one machine and

00:19:20,880 --> 00:19:24,880
fetch that partition right and this

00:19:24,160 --> 00:19:27,280
actually

00:19:24,880 --> 00:19:28,160
uh helped us improving our performance

00:19:27,280 --> 00:19:31,440
similar

00:19:28,160 --> 00:19:34,000
to the external uh shuffle service

00:19:31,440 --> 00:19:34,640
uh though we are writing remote right

00:19:34,000 --> 00:19:36,640
and uh

00:19:34,640 --> 00:19:38,640
so that's where we uh overall

00:19:36,640 --> 00:19:41,919
architecture for this years

00:19:38,640 --> 00:19:45,600
um now our colleague

00:19:41,919 --> 00:19:49,840
bo we'll talk about uh in detail uh

00:19:45,600 --> 00:19:49,840
different aspects of uh sales

00:19:50,080 --> 00:19:56,480
okay cool yeah thank you for

00:19:53,360 --> 00:19:59,280
the go through the all these

00:19:56,480 --> 00:20:00,559
details and uh yeah we will do some deep

00:19:59,280 --> 00:20:02,720
dive

00:20:00,559 --> 00:20:03,600
for how we design this system by the way

00:20:02,720 --> 00:20:07,200
so my name is bo

00:20:03,600 --> 00:20:10,000
i work inspecting uber

00:20:07,200 --> 00:20:11,280
there will be a lot of details from now

00:20:10,000 --> 00:20:14,159
and

00:20:11,280 --> 00:20:16,159
you guys have questions so we can

00:20:14,159 --> 00:20:22,320
discuss questions as well

00:20:16,159 --> 00:20:22,320
so i see some quick questions

00:20:22,400 --> 00:20:26,159
okay let me go through some quick stuff

00:20:24,640 --> 00:20:29,360
then we can talk about these

00:20:26,159 --> 00:20:31,360
questions in

00:20:29,360 --> 00:20:32,799
our design we have some principles we

00:20:31,360 --> 00:20:34,880
want to follow

00:20:32,799 --> 00:20:36,000
the first is we want to scale out

00:20:34,880 --> 00:20:38,640
horizontally

00:20:36,000 --> 00:20:39,919
so there's no single server bottleneck

00:20:38,640 --> 00:20:43,039
and we can just scale out

00:20:39,919 --> 00:20:44,080
by adding more machines the application

00:20:43,039 --> 00:20:46,840
can use different

00:20:44,080 --> 00:20:48,000
sharper server this can just scale

00:20:46,840 --> 00:20:51,039
horizontally

00:20:48,000 --> 00:20:55,200
and for network because we write

00:20:51,039 --> 00:20:58,000
and read the data to remote server

00:20:55,200 --> 00:21:00,240
normally it's kind of slow than right to

00:20:58,000 --> 00:21:03,360
local disk

00:21:00,240 --> 00:21:07,840
but we do a lot of forms tuning so once

00:21:03,360 --> 00:21:10,720
we uh very specific attention is

00:21:07,840 --> 00:21:12,480
in network the bandwidth this day is

00:21:10,720 --> 00:21:14,880
pretty fast the bandwidth is kind of

00:21:12,480 --> 00:21:16,880
close to the local disk

00:21:14,880 --> 00:21:18,559
but the latency is high comparing to

00:21:16,880 --> 00:21:21,120
local disk

00:21:18,559 --> 00:21:24,080
so we try to avoid the network latency

00:21:21,120 --> 00:21:24,080
as much as possible

00:21:24,400 --> 00:21:28,840
also we do a lot of performance

00:21:27,039 --> 00:21:32,720
optimization

00:21:28,840 --> 00:21:37,280
and we we will talk about that

00:21:32,720 --> 00:21:37,280
in details so next slide

00:21:40,960 --> 00:21:45,840
uh miyak next slide

00:21:49,919 --> 00:21:53,360
miak okay cool

00:21:53,440 --> 00:21:56,880
yeah this is the overlord

00:21:57,600 --> 00:22:04,000
okay so hard

00:22:01,840 --> 00:22:04,000
so

00:22:10,840 --> 00:22:13,840
okay

00:22:17,120 --> 00:22:20,480
you want all this previous thing yeah

00:22:19,440 --> 00:22:22,799
that's just the next

00:22:20,480 --> 00:22:22,799
slide

00:22:24,960 --> 00:22:29,440
right okay oh

00:22:28,080 --> 00:22:31,520
let me know let me try to share my

00:22:29,440 --> 00:22:35,120
screen how about that

00:22:31,520 --> 00:22:35,120
sure okay

00:22:37,919 --> 00:22:41,840
okay so

00:22:52,840 --> 00:22:55,840
ah

00:23:01,600 --> 00:23:05,360
okay so thank you guys for the pension

00:23:03,919 --> 00:23:08,750
sorry for

00:23:05,360 --> 00:23:12,140
for the introduction

00:23:08,750 --> 00:23:12,140
[Music]

00:23:18,480 --> 00:23:26,720
okay you still can't see

00:23:23,679 --> 00:23:26,720
oh stop can't see me

00:23:30,000 --> 00:23:40,240
okay let me do it

00:23:36,960 --> 00:23:42,640
okay sorry uh so let's do this

00:23:40,240 --> 00:23:43,520
is it this this is this this is the site

00:23:42,640 --> 00:23:47,120
you want to go

00:23:43,520 --> 00:23:50,799
yeah yes this one next one

00:23:47,120 --> 00:23:53,120
this one yeah yes

00:23:50,799 --> 00:23:53,120
okay

00:23:55,679 --> 00:24:00,240
yeah so this uh illustrates how we

00:23:57,679 --> 00:24:04,000
distribute the shuffle data to different

00:24:00,240 --> 00:24:07,279
shuffle server here we have example

00:24:04,000 --> 00:24:09,760
we have four member tasks and

00:24:07,279 --> 00:24:11,039
we have three shuffle server and we have

00:24:09,760 --> 00:24:13,840
five partition

00:24:11,039 --> 00:24:14,240
which is five reducer so for each map a

00:24:13,840 --> 00:24:17,120
task

00:24:14,240 --> 00:24:17,840
it connects to all the shuffle servers

00:24:17,120 --> 00:24:19,760
the same

00:24:17,840 --> 00:24:21,200
record to different shuffle server based

00:24:19,760 --> 00:24:24,240
on the particular id

00:24:21,200 --> 00:24:25,919
for example if this is the first

00:24:24,240 --> 00:24:26,159
partition it will go to the first server

00:24:25,919 --> 00:24:29,039
it's

00:24:26,159 --> 00:24:29,039
the second partition

00:24:29,440 --> 00:24:33,279
it'll go to second opportunity if go to

00:24:31,520 --> 00:24:34,640
second server if the third partition you

00:24:33,279 --> 00:24:38,720
go to

00:24:34,640 --> 00:24:42,400
uh seconds server yeah

00:24:38,720 --> 00:24:44,080
and in the end for each shuffle server

00:24:42,400 --> 00:24:46,080
all the data belonging to the same

00:24:44,080 --> 00:24:49,600
partition will go to the same

00:24:46,080 --> 00:24:50,640
server so basically this server kind of

00:24:49,600 --> 00:24:54,159
divides

00:24:50,640 --> 00:24:54,640
the data by partition and for reducer

00:24:54,159 --> 00:24:57,840
side

00:24:54,640 --> 00:24:59,200
each reducer just connects to the

00:24:57,840 --> 00:25:02,240
corresponding server and

00:24:59,200 --> 00:25:03,919
download the partition file directly

00:25:02,240 --> 00:25:05,919
so the reducer is pretty simple the

00:25:03,919 --> 00:25:06,720
connection is one connection to each

00:25:05,919 --> 00:25:08,559
server

00:25:06,720 --> 00:25:11,120
the other side it has more network

00:25:08,559 --> 00:25:15,840
connections

00:25:11,120 --> 00:25:15,840
so the next line

00:25:17,360 --> 00:25:21,679
yeah so this kind of some calculation in

00:25:20,240 --> 00:25:25,120
general let's say if we have

00:25:21,679 --> 00:25:27,120
ma and marvel are reduced for servers

00:25:25,120 --> 00:25:28,320
so from other side the normal connection

00:25:27,120 --> 00:25:31,840
is m multiple s

00:25:28,320 --> 00:25:34,799
it's a lot so that part we optimize that

00:25:31,840 --> 00:25:36,480
specifically for the either side reducer

00:25:34,799 --> 00:25:42,559
is simple

00:25:36,480 --> 00:25:45,919
next line

00:25:42,559 --> 00:25:47,039
go ahead next slide yeah we mentioned

00:25:45,919 --> 00:25:49,760
just now we

00:25:47,039 --> 00:25:51,120
deal with the network latency very

00:25:49,760 --> 00:25:53,520
carefully

00:25:51,120 --> 00:25:54,559
uh overall we use net it's a very high

00:25:53,520 --> 00:25:57,679
performance

00:25:54,559 --> 00:25:59,440
and the server framework and

00:25:57,679 --> 00:26:01,840
we use different thread groups for

00:25:59,440 --> 00:26:05,360
different purpose so once the red group

00:26:01,840 --> 00:26:07,440
for the circuit connect part

00:26:05,360 --> 00:26:09,760
another is for processing and reading

00:26:07,440 --> 00:26:11,440
social data so they do not block each

00:26:09,760 --> 00:26:13,520
other

00:26:11,440 --> 00:26:16,159
and we encoding the shuffle data by

00:26:13,520 --> 00:26:18,640
ourselves using binary protocol

00:26:16,159 --> 00:26:19,360
try to make it compact as much as

00:26:18,640 --> 00:26:25,840
possible

00:26:19,360 --> 00:26:25,840
yeah the next one

00:26:28,880 --> 00:26:31,120
for

00:26:34,000 --> 00:26:37,360
when we write to disk file yeah as a

00:26:36,559 --> 00:26:40,159
mega

00:26:37,360 --> 00:26:42,400
that we write directly and for the

00:26:40,159 --> 00:26:44,960
reducer read file we use zero copy

00:26:42,400 --> 00:26:46,000
so data is transferred from the server

00:26:44,960 --> 00:26:48,240
side

00:26:46,000 --> 00:26:49,919
within the kernel and to the client side

00:26:48,240 --> 00:26:52,880
directory

00:26:49,919 --> 00:26:54,960
i think previous slides also measure uh

00:26:52,880 --> 00:26:57,440
we do compression from classic

00:26:54,960 --> 00:27:00,400
we see the compressed ratio is normally

00:26:57,440 --> 00:27:04,840
sometimes a 10x so the compression saves

00:27:00,400 --> 00:27:06,400
network bandwidth a lot yeah the next

00:27:04,840 --> 00:27:08,799
slide

00:27:06,400 --> 00:27:11,039
oh yeah we mentioned the compression so

00:27:08,799 --> 00:27:12,960
next one

00:27:11,039 --> 00:27:14,960
yeah i try to be quick i want to leave

00:27:12,960 --> 00:27:20,880
more time for the q and a

00:27:14,960 --> 00:27:24,000
so i will be quick for some slides

00:27:20,880 --> 00:27:26,240
yeah this is where technique we use

00:27:24,000 --> 00:27:27,039
we find the serialization takes a lot of

00:27:26,240 --> 00:27:30,240
time

00:27:27,039 --> 00:27:33,120
for some applications so we

00:27:30,240 --> 00:27:34,080
do serialization and the socket the

00:27:33,120 --> 00:27:36,960
network i o

00:27:34,080 --> 00:27:37,760
in two threads so they can happen in

00:27:36,960 --> 00:27:39,919
parallel

00:27:37,760 --> 00:27:41,279
this can speed up the shuffle writing

00:27:39,919 --> 00:27:48,240
part

00:27:41,279 --> 00:27:50,960
next time

00:27:48,240 --> 00:27:52,000
yeah we use connection pool to try to

00:27:50,960 --> 00:27:55,200
reduce the

00:27:52,000 --> 00:27:55,200
connect operations

00:27:55,440 --> 00:28:06,480
the connection so next time

00:28:03,200 --> 00:28:09,520
also for shuffle data commit

00:28:06,480 --> 00:28:10,000
we use asynchronous commit let's say we

00:28:09,520 --> 00:28:13,120
have

00:28:10,000 --> 00:28:13,520
turn mapper tasks so each map task can

00:28:13,120 --> 00:28:16,399
finish

00:28:13,520 --> 00:28:17,360
sending data to the server side so

00:28:16,399 --> 00:28:20,799
normally we

00:28:17,360 --> 00:28:22,720
don't wait from the server to respond

00:28:20,799 --> 00:28:24,080
says okay all the data is received and

00:28:22,720 --> 00:28:26,399
written to disk

00:28:24,080 --> 00:28:27,600
if we wait that each my task will have

00:28:26,399 --> 00:28:30,399
some delay

00:28:27,600 --> 00:28:32,480
so the optimization here is each method

00:28:30,399 --> 00:28:34,480
task that just keeps sending data there

00:28:32,480 --> 00:28:35,919
and it will send a marker tell the

00:28:34,480 --> 00:28:38,559
server okay it's finished

00:28:35,919 --> 00:28:40,080
the data then the task will be marked

00:28:38,559 --> 00:28:43,440
finished

00:28:40,080 --> 00:28:46,559
after that the next mega task could run

00:28:43,440 --> 00:28:49,039
so this improve the multitask throughput

00:28:46,559 --> 00:28:49,039
overall

00:28:51,840 --> 00:28:54,399
next one

00:28:55,039 --> 00:29:01,279
the next one

00:28:58,159 --> 00:29:05,360
the next one next one yeah okay

00:29:01,279 --> 00:29:08,320
next one in for tolerance uh

00:29:05,360 --> 00:29:10,399
we use zookeeper to register all the

00:29:08,320 --> 00:29:12,240
server if some server is done

00:29:10,399 --> 00:29:13,760
it will be gone from zookeeper so you

00:29:12,240 --> 00:29:16,559
can find out

00:29:13,760 --> 00:29:16,559
so next slide

00:29:18,159 --> 00:29:22,320
also it's about replica we can write

00:29:20,720 --> 00:29:25,200
data to two server

00:29:22,320 --> 00:29:26,159
in parallel so if one server is done it

00:29:25,200 --> 00:29:27,840
can still

00:29:26,159 --> 00:29:30,640
write to another server they're just

00:29:27,840 --> 00:29:33,360
very common techniques

00:29:30,640 --> 00:29:33,360
so next one

00:29:36,240 --> 00:29:42,320
yeah we handle the state flash

00:29:40,080 --> 00:29:43,919
in some way to improve formats so we're

00:29:42,320 --> 00:29:45,600
batching the state together and the

00:29:43,919 --> 00:29:48,799
right

00:29:45,600 --> 00:29:53,039
to the disk to avoid for

00:29:48,799 --> 00:29:55,840
writing data state data for each task

00:29:53,039 --> 00:29:55,840
the next one

00:29:57,039 --> 00:30:00,880
go ahead next one so we have been

00:29:59,440 --> 00:30:04,320
running this in production

00:30:00,880 --> 00:30:06,799
for a while so we run this

00:30:04,320 --> 00:30:07,360
it'll hook up with spark shuffle magic

00:30:06,799 --> 00:30:09,840
api

00:30:07,360 --> 00:30:11,120
so we can set the class name to our

00:30:09,840 --> 00:30:16,240
shuffle manager

00:30:11,120 --> 00:30:16,240
name also we

00:30:16,320 --> 00:30:20,320
because spark itself doesn't provide

00:30:18,640 --> 00:30:22,080
very good support for this kind of

00:30:20,320 --> 00:30:25,279
remote travel scenario

00:30:22,080 --> 00:30:28,960
so we kind of leverage some

00:30:25,279 --> 00:30:31,279
information in map status to

00:30:28,960 --> 00:30:33,039
transfer some metadata information

00:30:31,279 --> 00:30:34,000
between our travel server and smart

00:30:33,039 --> 00:30:35,840
driver

00:30:34,000 --> 00:30:38,240
we try to make it compatible with open

00:30:35,840 --> 00:30:40,159
source bug so people don't need to make

00:30:38,240 --> 00:30:42,080
any changes to their

00:30:40,159 --> 00:30:43,360
spark internal code they just need to

00:30:42,080 --> 00:30:47,039
add some config

00:30:43,360 --> 00:30:47,039
yeah next slide

00:30:47,679 --> 00:30:50,799
yeah we've been running this for eight

00:30:49,200 --> 00:30:53,279
months and we just open source

00:30:50,799 --> 00:30:54,080
yesterday we will go to github remote

00:30:53,279 --> 00:30:58,720
travel service

00:30:54,080 --> 00:30:58,720
so you can find it next one

00:30:59,679 --> 00:31:03,519
yeah we still have a lot of work to do

00:31:02,559 --> 00:31:05,440
for example

00:31:03,519 --> 00:31:06,880
better multi-tenancy support we should

00:31:05,440 --> 00:31:10,720
add quota for

00:31:06,880 --> 00:31:14,159
for big users and load balancing

00:31:10,720 --> 00:31:15,919
and integrate with the new smart shop

00:31:14,159 --> 00:31:16,880
for method api so the community is

00:31:15,919 --> 00:31:18,640
working on

00:31:16,880 --> 00:31:20,559
some new metadata api so which can

00:31:18,640 --> 00:31:25,760
support the remote shuffle scenario

00:31:20,559 --> 00:31:25,760
better we can utilize that api next one

00:31:26,240 --> 00:31:30,320
yeah i think that's all so thank you

00:31:28,240 --> 00:31:32,640
guys we're still hiring and then you can

00:31:30,320 --> 00:31:36,720
check our open source github

00:31:32,640 --> 00:31:36,720
i'm going to look at the questions

00:31:39,200 --> 00:31:44,880
okay the first question from joseph

00:31:42,240 --> 00:31:47,279
how does fetching from a single place

00:31:44,880 --> 00:31:50,960
helps in preventing spill

00:31:47,279 --> 00:31:50,960
files on reducer

00:31:51,760 --> 00:31:57,039
spill files on reducer

00:31:55,440 --> 00:31:58,880
i'm not sure what kind of profile on

00:31:57,039 --> 00:32:02,480
reducer do you mean the

00:31:58,880 --> 00:32:06,480
aggregation and the salting

00:32:02,480 --> 00:32:07,279
if you mean that yeah we still have that

00:32:06,480 --> 00:32:12,159
sbr

00:32:07,279 --> 00:32:12,159
on reduces okay yeah the salty yes

00:32:12,840 --> 00:32:16,720
if

00:32:14,240 --> 00:32:17,840
currently we still the reducer still

00:32:16,720 --> 00:32:21,360
fetch the data and

00:32:17,840 --> 00:32:25,279
do the sorting on the reducer side

00:32:21,360 --> 00:32:29,600
so the reason is so good

00:32:25,279 --> 00:32:31,120
okay so the reason is for sorting spark

00:32:29,600 --> 00:32:33,440
it's application logic

00:32:31,120 --> 00:32:34,240
if your rights back job let's say you

00:32:33,440 --> 00:32:37,360
have your own

00:32:34,240 --> 00:32:38,799
java object and the sorting is very

00:32:37,360 --> 00:32:42,080
specific to your own

00:32:38,799 --> 00:32:44,559
code that logic is not transferred

00:32:42,080 --> 00:32:46,240
to remote travel server it is only

00:32:44,559 --> 00:32:48,880
inspired application side

00:32:46,240 --> 00:32:51,200
so the shuffle server cannot do sorting

00:32:48,880 --> 00:32:54,399
that's why we do this implementation

00:32:51,200 --> 00:32:56,240
but we do have some sort

00:32:54,399 --> 00:32:58,799
to support some kind of salty in the

00:32:56,240 --> 00:33:01,760
server side for example if you use bug

00:32:58,799 --> 00:33:02,399
sequel uh it's a dead frame that's

00:33:01,760 --> 00:33:05,760
rapture

00:33:02,399 --> 00:33:08,960
that destruction is kind of uh

00:33:05,760 --> 00:33:10,799
well known and it's not

00:33:08,960 --> 00:33:12,240
in most cases it's not application

00:33:10,799 --> 00:33:15,120
related

00:33:12,240 --> 00:33:16,960
uh if we know some metadata inside it in

00:33:15,120 --> 00:33:18,159
that case we can do salt in the server

00:33:16,960 --> 00:33:21,039
side

00:33:18,159 --> 00:33:23,440
yeah that could be some future work we

00:33:21,039 --> 00:33:25,360
could do

00:33:23,440 --> 00:33:27,120
yeah but for you're right from reducer

00:33:25,360 --> 00:33:31,519
side we don't we don't have

00:33:27,120 --> 00:33:31,519
a way to remove the space

00:33:32,240 --> 00:33:37,760
okay the next question is it easy to

00:33:33,919 --> 00:33:41,200
plug as use to tensorflow

00:33:37,760 --> 00:33:44,640
i think it depends so zeus has two parts

00:33:41,200 --> 00:33:47,600
one part is only have java code which is

00:33:44,640 --> 00:33:49,200
which does not depend on spark it it is

00:33:47,600 --> 00:33:50,399
a standalone shutter server and a

00:33:49,200 --> 00:33:53,600
standalone

00:33:50,399 --> 00:33:56,799
shuffle client it has nothing to do with

00:33:53,600 --> 00:34:01,039
work if tensorflow need to shuffle data

00:33:56,799 --> 00:34:04,080
i think it's possible to reuse that part

00:34:01,039 --> 00:34:07,440
but uh i'm not sure about the

00:34:04,080 --> 00:34:08,639
api so if tensorflow allows you plug in

00:34:07,440 --> 00:34:12,240
your own

00:34:08,639 --> 00:34:15,359
kind of shuffle implementation

00:34:12,240 --> 00:34:16,879
you may need to add a adapter layer on

00:34:15,359 --> 00:34:19,760
top of our

00:34:16,879 --> 00:34:21,200
java code and you use there's another

00:34:19,760 --> 00:34:23,520
part scatter code

00:34:21,200 --> 00:34:25,839
so that implement the spark shuffle

00:34:23,520 --> 00:34:28,639
manager api so that is tied with the

00:34:25,839 --> 00:34:29,359
sprocket itself it is not reasonable by

00:34:28,639 --> 00:34:32,480
other

00:34:29,359 --> 00:34:34,240
framework so but if you run tensorflow

00:34:32,480 --> 00:34:38,000
inside the spark

00:34:34,240 --> 00:34:38,879
then uh it's easy when everything is

00:34:38,000 --> 00:34:42,159
still spark

00:34:38,879 --> 00:34:44,480
so it can use use naturally it depends

00:34:42,159 --> 00:34:46,480
on different scenarios

00:34:44,480 --> 00:34:47,599
yeah so from natively we only support

00:34:46,480 --> 00:34:50,079
right now the spark

00:34:47,599 --> 00:34:51,440
we haven't don't have integration with

00:34:50,079 --> 00:34:54,240
tensorflow yet

00:34:51,440 --> 00:34:55,359
but as a as both said right we can make

00:34:54,240 --> 00:34:56,720
it work with

00:34:55,359 --> 00:34:58,400
other frameworks if they have a

00:34:56,720 --> 00:35:01,599
requirement for shuffle

00:34:58,400 --> 00:35:05,280
yeah cool so

00:35:01,599 --> 00:35:05,280
any other question yeah

00:35:09,520 --> 00:35:13,599
okay so if no question yeah we can wait

00:35:13,040 --> 00:35:17,839
maybe

00:35:13,599 --> 00:35:17,839
a few minutes here i think

00:35:23,200 --> 00:35:29,599
so yeah feel free to ask any questions

00:35:26,400 --> 00:35:33,119
or you can reach us so email

00:35:29,599 --> 00:35:34,960
or through our website yeah this is our

00:35:33,119 --> 00:35:35,440
email addresses mentioned here and these

00:35:34,960 --> 00:35:38,720
are the

00:35:35,440 --> 00:35:41,119
github link for us for the remote

00:35:38,720 --> 00:35:43,520
shuffle service please

00:35:41,119 --> 00:35:45,359
we welcome community support as well as

00:35:43,520 --> 00:35:46,000
contributions so please go ahead look at

00:35:45,359 --> 00:35:47,920
it

00:35:46,000 --> 00:35:50,400
and let give us feedback and we can work

00:35:47,920 --> 00:35:53,599
together on this

00:35:50,400 --> 00:35:53,599
and definitely we are hiring

00:35:56,240 --> 00:36:13,839
okay all right thanks guys

00:36:00,320 --> 00:36:13,839
go thank you guys bye

00:36:31,040 --> 00:36:33,119

YouTube URL: https://www.youtube.com/watch?v=GwmV3NN-W3g


