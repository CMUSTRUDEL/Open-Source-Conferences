Title: WebAssembly as a cloud-native runtime for serverless functions - Michael Yuan, Second State
Publication date: 2021-05-04
Playlist: Cloud Native Wasm Day EU 2021
Description: 
	Donâ€™t miss out! Join us at our upcoming event: KubeCon + CloudNativeCon North America 2021 in Los Angeles, CA from October 12-15. Learn more at https://kubecon.io The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.

WebAssembly as a cloud-native runtime for serverless functions - Michael Yuan, Second State

Serverless function-as-a-service is popular among developers. Public clouds use hypervisor VMs or containers (e.g., Docker) to run serverless functions. But they are slow and resource-intensive. In this talk, Michael will discuss the Wasm VM as a lightweight cloud-native runtime. It allows serverless functions to be embedded in edge & IoT devices, as well as in SaaS platforms. It also enables developers to deploy serverless functions on legacy systems without changing any code. Topics include: * How to create a function-as-a-service with Node.js & Wasm * How public clouds like Tencent Cloud utilized Wasm in serverless environments * How to use K8s and cloud-native tools to deploy & manage Wasm VMs Developers will get hands-on experience to create & deploy high-performance serverless functions in Rust.
Captions: 
	00:00:01,280 --> 00:00:06,160
hello everyone um welcome to the

00:00:04,000 --> 00:00:07,359
cloud native awesome day in this talk we

00:00:06,160 --> 00:00:09,599
want to talk about

00:00:07,359 --> 00:00:11,360
cloud native server serverless functions

00:00:09,599 --> 00:00:13,840
and how what role

00:00:11,360 --> 00:00:15,839
if any weber somebody can play in here

00:00:13,840 --> 00:00:18,560
okay

00:00:15,839 --> 00:00:19,840
um well before we start let's look at

00:00:18,560 --> 00:00:20,800
what is the serverless function

00:00:19,840 --> 00:00:22,400
serverless function

00:00:20,800 --> 00:00:23,920
you know the first serverless function

00:00:22,400 --> 00:00:26,400
that's well known is

00:00:23,920 --> 00:00:28,320
adapts lambda right you know that's uh

00:00:26,400 --> 00:00:30,480
it's a new paradigm of developing you

00:00:28,320 --> 00:00:32,480
know that's you just upload your code

00:00:30,480 --> 00:00:34,320
and uh you don't need to know where it's

00:00:32,480 --> 00:00:34,960
running and what's operating system is

00:00:34,320 --> 00:00:37,040
running and

00:00:34,960 --> 00:00:38,160
and any detail about the server the

00:00:37,040 --> 00:00:42,000
public cloud will just

00:00:38,160 --> 00:00:43,280
run it and ap a url or something else

00:00:42,000 --> 00:00:44,000
that for you to call this function and

00:00:43,280 --> 00:00:46,239
get a result

00:00:44,000 --> 00:00:47,360
right so that's what we call no

00:00:46,239 --> 00:00:49,520
infrastructure

00:00:47,360 --> 00:00:50,879
and uh um it's because the developer

00:00:49,520 --> 00:00:53,280
don't see the server we

00:00:50,879 --> 00:00:54,719
we call it serverless although obviously

00:00:53,280 --> 00:00:56,800
there's still server on the back and

00:00:54,719 --> 00:00:58,079
just serverless just making servers

00:00:56,800 --> 00:01:01,120
great again right

00:00:58,079 --> 00:01:02,719
you know so that's uh um if you look at

00:01:01,120 --> 00:01:05,199
this survey that from datadog

00:01:02,719 --> 00:01:07,840
you know the lambda adoption of aws

00:01:05,199 --> 00:01:09,840
users has gone really sky high i'm i'm

00:01:07,840 --> 00:01:12,400
actually surprised to see this

00:01:09,840 --> 00:01:14,159
half of aws users have adopted lambda if

00:01:12,400 --> 00:01:15,119
you consider how many products aws

00:01:14,159 --> 00:01:17,119
actually have

00:01:15,119 --> 00:01:18,799
you know that's uh it's amazing that

00:01:17,119 --> 00:01:20,159
something that something like that can

00:01:18,799 --> 00:01:23,280
be adopted by half of

00:01:20,159 --> 00:01:23,280
all users on aws

00:01:23,840 --> 00:01:27,520
it's the same for the other clouds as

00:01:25,360 --> 00:01:29,520
well so let's um look at the leading

00:01:27,520 --> 00:01:32,400
cloud in china you know aws is

00:01:29,520 --> 00:01:33,439
it's leading color in america so just um

00:01:32,400 --> 00:01:35,439
i translated this

00:01:33,439 --> 00:01:37,360
um the paragraph of chinese words for

00:01:35,439 --> 00:01:39,680
you so you know tencent

00:01:37,360 --> 00:01:41,280
cloud is a leading cloud is a leading

00:01:39,680 --> 00:01:43,200
cloud provider in china

00:01:41,280 --> 00:01:44,399
has over 1 million developers provide

00:01:43,200 --> 00:01:46,880
services to 10

00:01:44,399 --> 00:01:48,240
000 businesses including 500 large

00:01:46,880 --> 00:01:50,399
enterprises

00:01:48,240 --> 00:01:51,360
how many serverless function cost seats

00:01:50,399 --> 00:01:53,680
per day

00:01:51,360 --> 00:01:54,799
10 billion costs per day you know

00:01:53,680 --> 00:01:57,920
there's

00:01:54,799 --> 00:02:00,640
people are writing a large number of

00:01:57,920 --> 00:02:01,840
you know high traffic heavily used

00:02:00,640 --> 00:02:04,560
applications

00:02:01,840 --> 00:02:05,600
using tencent cloud serverless as the

00:02:04,560 --> 00:02:08,080
back that

00:02:05,600 --> 00:02:09,920
as a back-end service right so that's it

00:02:08,080 --> 00:02:12,720
shows us that's really popular and the

00:02:09,920 --> 00:02:14,879
developers really want to use it right

00:02:12,720 --> 00:02:16,000
and uh so what are the most programming

00:02:14,879 --> 00:02:18,080
languages in those

00:02:16,000 --> 00:02:20,480
um you know what's what the developers

00:02:18,080 --> 00:02:24,000
use when they write serverless functions

00:02:20,480 --> 00:02:26,720
and they use you know python node.js

00:02:24,000 --> 00:02:28,319
no surprise here those are i wouldn't

00:02:26,720 --> 00:02:29,840
call them easy languages but those are

00:02:28,319 --> 00:02:31,360
high productivity languages right you

00:02:29,840 --> 00:02:32,640
know it's easy to write applications in

00:02:31,360 --> 00:02:34,720
those languages

00:02:32,640 --> 00:02:36,720
but they are also heavyweight languages

00:02:34,720 --> 00:02:37,599
meaning that they have a heavy runtime

00:02:36,720 --> 00:02:40,560
and

00:02:37,599 --> 00:02:42,160
has somewhat slow performance right so

00:02:40,560 --> 00:02:44,080
you know so that's

00:02:42,160 --> 00:02:45,360
developers write those applications and

00:02:44,080 --> 00:02:48,800
then you

00:02:45,360 --> 00:02:50,640
um in python node.js probably without

00:02:48,800 --> 00:02:54,560
thinking a lot about the application

00:02:50,640 --> 00:02:56,800
about the performance and that shows

00:02:54,560 --> 00:02:58,239
the duration of lambda functions you

00:02:56,800 --> 00:03:00,319
know the the

00:02:58,239 --> 00:03:02,159
this figure said it in a way that is uh

00:03:00,319 --> 00:03:04,400
glass of four right half of the lambda

00:03:02,159 --> 00:03:07,920
functions was less than

00:03:04,400 --> 00:03:10,239
800 milliseconds my reaction is oh

00:03:07,920 --> 00:03:11,360
my gosh half of the laminar functions

00:03:10,239 --> 00:03:14,640
run more than

00:03:11,360 --> 00:03:16,560
800 milliseconds meaning so if you

00:03:14,640 --> 00:03:18,000
um think about you know how high

00:03:16,560 --> 00:03:20,400
performance internet works how

00:03:18,000 --> 00:03:21,760
hyper one's website works if you

00:03:20,400 --> 00:03:23,920
consider you know the

00:03:21,760 --> 00:03:25,599
the time need for the data to travel

00:03:23,920 --> 00:03:28,239
through the network to

00:03:25,599 --> 00:03:30,080
um to reach the customer and then to go

00:03:28,239 --> 00:03:30,879
from the client to the server and then

00:03:30,080 --> 00:03:34,640
back

00:03:30,879 --> 00:03:36,799
you know to spend 800 0.8 seconds on the

00:03:34,640 --> 00:03:38,480
server it's a very very long time

00:03:36,799 --> 00:03:41,200
especially if you have a application

00:03:38,480 --> 00:03:42,799
that makes 10 20 or even hundreds of

00:03:41,200 --> 00:03:44,480
back-end services costs

00:03:42,799 --> 00:03:46,879
you know that could really add up so you

00:03:44,480 --> 00:03:48,319
know so that's actually that's

00:03:46,879 --> 00:03:50,159
actually one of the other things that

00:03:48,319 --> 00:03:51,599
someone surprised me is that

00:03:50,159 --> 00:03:53,439
you know the way that people use

00:03:51,599 --> 00:03:56,159
serverless functions are

00:03:53,439 --> 00:03:56,959
tends to be that's i think that's on the

00:03:56,159 --> 00:03:58,720
next stage

00:03:56,959 --> 00:04:00,080
so the most common serverless function

00:03:58,720 --> 00:04:02,400
use cases to run

00:04:00,080 --> 00:04:04,640
a simple function on a heavy stack so

00:04:02,400 --> 00:04:06,480
the stack you know node python node.js

00:04:04,640 --> 00:04:09,680
are slow it takes a long time

00:04:06,480 --> 00:04:11,040
and that in turn only allows people to

00:04:09,680 --> 00:04:13,200
run simple functions

00:04:11,040 --> 00:04:14,879
you know you can only run a fairly

00:04:13,200 --> 00:04:16,000
simple function and it's gonna take 800

00:04:14,879 --> 00:04:18,160
milliseconds

00:04:16,000 --> 00:04:20,320
so that translates to what you know

00:04:18,160 --> 00:04:23,120
that's translates to there's only

00:04:20,320 --> 00:04:25,280
limited number of use cases that we can

00:04:23,120 --> 00:04:27,919
actually use service functions

00:04:25,280 --> 00:04:30,000
meaning you know in aw in most public

00:04:27,919 --> 00:04:31,840
clouds it used as the glue code

00:04:30,000 --> 00:04:33,360
you know when you need to move something

00:04:31,840 --> 00:04:35,759
from aws s3

00:04:33,360 --> 00:04:37,280
to the aws message queue you know

00:04:35,759 --> 00:04:37,520
something like that the best way to do

00:04:37,280 --> 00:04:40,080
it

00:04:37,520 --> 00:04:41,120
is to use servers function because it's

00:04:40,080 --> 00:04:43,919
uh

00:04:41,120 --> 00:04:45,680
it's sitting in the message queue and uh

00:04:43,919 --> 00:04:48,000
it's not very time sensitive

00:04:45,680 --> 00:04:50,080
and it's um there's no one else that

00:04:48,000 --> 00:04:52,720
waiting for a real-time response from it

00:04:50,080 --> 00:04:53,600
so in those cases where you know you can

00:04:52,720 --> 00:04:56,320
write

00:04:53,600 --> 00:04:57,360
you know python and node.js applications

00:04:56,320 --> 00:04:58,400
and not really care about their

00:04:57,360 --> 00:05:00,560
performance

00:04:58,400 --> 00:05:01,600
and uh you know each function called

00:05:00,560 --> 00:05:04,320
takes maybe a second

00:05:01,600 --> 00:05:05,120
right you know or more so that's um

00:05:04,320 --> 00:05:06,560
that's

00:05:05,120 --> 00:05:08,400
today's most common use case of

00:05:06,560 --> 00:05:09,919
serverless however

00:05:08,400 --> 00:05:11,759
as we can imagine you know because

00:05:09,919 --> 00:05:12,240
serverless is such a powerful paradigm

00:05:11,759 --> 00:05:14,639
and

00:05:12,240 --> 00:05:15,360
a lot of developers would love to use it

00:05:14,639 --> 00:05:17,199
and uh

00:05:15,360 --> 00:05:19,440
a lot of developers actually want to

00:05:17,199 --> 00:05:21,600
write four applications in serverless

00:05:19,440 --> 00:05:23,120
you know there's a there's a new you

00:05:21,600 --> 00:05:25,039
know new way of developing web

00:05:23,120 --> 00:05:28,000
applications called the gem stack

00:05:25,039 --> 00:05:29,520
and jm stack right if you haven't heard

00:05:28,000 --> 00:05:30,720
of it you've probably already done it

00:05:29,520 --> 00:05:33,120
you know that's because i think

00:05:30,720 --> 00:05:34,560
most new web applications today i see

00:05:33,120 --> 00:05:36,000
actually what's doing what's done in

00:05:34,560 --> 00:05:38,400
that fashion you know

00:05:36,000 --> 00:05:39,360
so it's uh um so on when on the front

00:05:38,400 --> 00:05:41,840
end there is a

00:05:39,360 --> 00:05:42,800
static website generator so you have

00:05:41,840 --> 00:05:45,120
frameworks like

00:05:42,800 --> 00:05:46,240
view or next js or hugo something like

00:05:45,120 --> 00:05:48,639
that so i

00:05:46,240 --> 00:05:49,680
took the content that you wrote in some

00:05:48,639 --> 00:05:51,520
kind of markup

00:05:49,680 --> 00:05:53,039
and generate a static website with

00:05:51,520 --> 00:05:56,000
javascript in it

00:05:53,039 --> 00:05:56,720
and that static website can be deployed

00:05:56,000 --> 00:05:58,639
anywhere you want

00:05:56,720 --> 00:06:00,319
this can be deployed on the local host

00:05:58,639 --> 00:06:02,479
for instance it can be deployed on

00:06:00,319 --> 00:06:04,400
cdn or it can be deployed you on

00:06:02,479 --> 00:06:05,600
blockchain right you know that's uh

00:06:04,400 --> 00:06:07,440
you know you can deploy it anywhere you

00:06:05,600 --> 00:06:08,880
want because it was just a bunch of html

00:06:07,440 --> 00:06:10,960
files and javascript

00:06:08,880 --> 00:06:13,280
and then javascript contact the backend

00:06:10,960 --> 00:06:15,759
service to provide

00:06:13,280 --> 00:06:17,759
functions for this for this starting ui

00:06:15,759 --> 00:06:20,000
right you know so you have a

00:06:17,759 --> 00:06:21,840
webpage and then javascript goes to call

00:06:20,000 --> 00:06:24,000
some back-end function

00:06:21,840 --> 00:06:25,520
to do things like you know image

00:06:24,000 --> 00:06:26,880
recognition or you know

00:06:25,520 --> 00:06:29,120
saving data to the database you know

00:06:26,880 --> 00:06:29,680
things of that nature and that back-end

00:06:29,120 --> 00:06:32,160
function

00:06:29,680 --> 00:06:33,360
is typically a serverless function right

00:06:32,160 --> 00:06:35,520
you know so that's

00:06:33,360 --> 00:06:36,960
if we see it from that lens you know

00:06:35,520 --> 00:06:39,840
that's you want we want to use

00:06:36,960 --> 00:06:40,479
serverless as uh as a universal back-end

00:06:39,840 --> 00:06:43,520
service

00:06:40,479 --> 00:06:46,720
we would want it to be much faster

00:06:43,520 --> 00:06:48,800
and uh much lighter and uh

00:06:46,720 --> 00:06:50,880
basically it needs to have a different

00:06:48,800 --> 00:06:53,280
performance characteristics than

00:06:50,880 --> 00:06:54,319
what serverless is today right it's uh

00:06:53,280 --> 00:06:56,479
it shouldn't take

00:06:54,319 --> 00:06:58,240
800 milliseconds it shouldn't even take

00:06:56,479 --> 00:06:58,720
80 milliseconds it should be a lot more

00:06:58,240 --> 00:07:00,560
faster

00:06:58,720 --> 00:07:03,120
10 times 100 times faster than that

00:07:00,560 --> 00:07:06,160
right so you know so that's uh

00:07:03,120 --> 00:07:06,880
um where we think you know that's um the

00:07:06,160 --> 00:07:08,639
current

00:07:06,880 --> 00:07:10,240
uh model or the current paradigm of

00:07:08,639 --> 00:07:12,560
serverless can really

00:07:10,240 --> 00:07:13,919
get some help you know that's uh um you

00:07:12,560 --> 00:07:16,000
know that's where

00:07:13,919 --> 00:07:17,840
we think uh cloud native web assembly

00:07:16,000 --> 00:07:20,800
could have um will have an impact

00:07:17,840 --> 00:07:22,240
okay what could contribute to um to this

00:07:20,800 --> 00:07:25,520
whole thing

00:07:22,240 --> 00:07:26,800
so um before as we get into however

00:07:25,520 --> 00:07:28,319
somebody could help let's

00:07:26,800 --> 00:07:29,520
take some time to review what are the

00:07:28,319 --> 00:07:30,960
serverless strong texts popular

00:07:29,520 --> 00:07:32,479
serverless contacts

00:07:30,960 --> 00:07:34,720
you know the first is what we call

00:07:32,479 --> 00:07:36,880
hypervisor vm or hardware vm

00:07:34,720 --> 00:07:39,520
it's you know some people call it micro

00:07:36,880 --> 00:07:42,080
vms as well like aws file cracker right

00:07:39,520 --> 00:07:42,800
that is uh how aws lambda was wrong you

00:07:42,080 --> 00:07:45,039
know that's

00:07:42,800 --> 00:07:46,879
it provide hardware-based you know it

00:07:45,039 --> 00:07:48,800
provides a high level of

00:07:46,879 --> 00:07:51,039
isolation for each of the serverless

00:07:48,800 --> 00:07:53,199
instances and you know so the serverless

00:07:51,039 --> 00:07:55,360
is contained within the vm and

00:07:53,199 --> 00:07:57,280
that but that is very inefficient

00:07:55,360 --> 00:07:58,160
because you start a whole operating

00:07:57,280 --> 00:08:01,039
system

00:07:58,160 --> 00:08:01,919
just and then the the software stack on

00:08:01,039 --> 00:08:04,240
the operating system

00:08:01,919 --> 00:08:05,599
just run a single function and then shut

00:08:04,240 --> 00:08:07,919
it down right you know that's

00:08:05,599 --> 00:08:08,639
uh to start it up may take a second and

00:08:07,919 --> 00:08:10,840
then the

00:08:08,639 --> 00:08:12,000
the function when it takes 10

00:08:10,840 --> 00:08:15,120
milliseconds

00:08:12,000 --> 00:08:16,240
and then you know 99 of the work in this

00:08:15,120 --> 00:08:18,560
process is

00:08:16,240 --> 00:08:20,319
wasted or it's it's infrastructure busy

00:08:18,560 --> 00:08:21,440
work so although that provides safety

00:08:20,319 --> 00:08:23,680
and security that's

00:08:21,440 --> 00:08:25,599
um not very efficient so some people

00:08:23,680 --> 00:08:26,000
start to use application containers like

00:08:25,599 --> 00:08:28,800
docker

00:08:26,000 --> 00:08:29,280
to do that and docker is a lot faster

00:08:28,800 --> 00:08:31,440
than

00:08:29,280 --> 00:08:32,959
the hardware vm but it's also provide

00:08:31,440 --> 00:08:36,080
less isolation

00:08:32,959 --> 00:08:38,080
and and also although the docker runs on

00:08:36,080 --> 00:08:39,120
top of operating system it also has a

00:08:38,080 --> 00:08:41,440
guest operating system

00:08:39,120 --> 00:08:42,240
inside it so it takes it still takes

00:08:41,440 --> 00:08:43,360
time to

00:08:42,240 --> 00:08:45,200
[Music]

00:08:43,360 --> 00:08:46,640
get up the operating system and the

00:08:45,200 --> 00:08:49,279
software stack so it's

00:08:46,640 --> 00:08:49,920
so although it's faster than hardware vm

00:08:49,279 --> 00:08:51,279
it

00:08:49,920 --> 00:08:53,040
still takes time to prepare the

00:08:51,279 --> 00:08:55,200
environment then

00:08:53,040 --> 00:08:57,279
the third level the highest abstraction

00:08:55,200 --> 00:08:58,240
level is to run high-level language vms

00:08:57,279 --> 00:09:00,959
in a thread

00:08:58,240 --> 00:09:01,360
so the most classic example is the jvm

00:09:00,959 --> 00:09:02,720
and

00:09:01,360 --> 00:09:05,519
you know the java virtual machine but

00:09:02,720 --> 00:09:08,480
it's also the python runtimes the v8

00:09:05,519 --> 00:09:09,440
for node.js and of course web assembly

00:09:08,480 --> 00:09:11,519
you know the common

00:09:09,440 --> 00:09:13,600
thing about those high-level vms is that

00:09:11,519 --> 00:09:15,600
they don't have operating system in it

00:09:13,600 --> 00:09:18,080
the type of code it's that can run in

00:09:15,600 --> 00:09:18,959
this in this type of vms are called

00:09:18,080 --> 00:09:21,040
bytecode

00:09:18,959 --> 00:09:22,959
so they're already defined and formatted

00:09:21,040 --> 00:09:24,560
and there's a compiler that generates

00:09:22,959 --> 00:09:27,120
those bytecode and then

00:09:24,560 --> 00:09:28,959
those vms can be started really fast in

00:09:27,120 --> 00:09:29,680
the in and running operating system in a

00:09:28,959 --> 00:09:31,680
thread

00:09:29,680 --> 00:09:33,200
and then can be shut down really fast as

00:09:31,680 --> 00:09:36,800
well so that makes them

00:09:33,200 --> 00:09:38,800
most nimble and make some least wasteful

00:09:36,800 --> 00:09:40,640
and allows us to write high performance

00:09:38,800 --> 00:09:43,040
applications in those

00:09:40,640 --> 00:09:44,080
in those high-level language vms so as

00:09:43,040 --> 00:09:45,839
you can see here

00:09:44,080 --> 00:09:47,360
you know you probably have heard of jvm

00:09:45,839 --> 00:09:48,640
python but

00:09:47,360 --> 00:09:50,480
you know that's wherever somebody is

00:09:48,640 --> 00:09:52,399
also here and and uh

00:09:50,480 --> 00:09:55,040
what we think is what web assembly is

00:09:52,399 --> 00:09:57,600
going to be probably the best vm

00:09:55,040 --> 00:09:58,080
that's run serverless functions and it's

00:09:57,600 --> 00:10:00,640
not just

00:09:58,080 --> 00:10:01,360
us the things that you know in 2019 you

00:10:00,640 --> 00:10:03,600
know

00:10:01,360 --> 00:10:05,200
it's hard to believe two you know more

00:10:03,600 --> 00:10:08,480
than two years ago now

00:10:05,200 --> 00:10:11,040
um the founder of docker and the cto of

00:10:08,480 --> 00:10:12,079
you know the first cto of docker said if

00:10:11,040 --> 00:10:14,160
web assembly

00:10:12,079 --> 00:10:17,519
wasn't wasn't stand for web assembly if

00:10:14,160 --> 00:10:19,120
web assembly plus was existed in 2008

00:10:17,519 --> 00:10:20,880
we wouldn't have needed to create a

00:10:19,120 --> 00:10:23,120
docker you know that's how important it

00:10:20,880 --> 00:10:24,720
is uh web assembly on the server is the

00:10:23,120 --> 00:10:25,519
future of computing that's how important

00:10:24,720 --> 00:10:27,279
it is

00:10:25,519 --> 00:10:28,959
that's i thought that's very strong

00:10:27,279 --> 00:10:30,880
words right you know that's uh um

00:10:28,959 --> 00:10:32,399
a standardized system interface was a

00:10:30,880 --> 00:10:34,320
missing piece so let's hope boss is up

00:10:32,399 --> 00:10:36,800
to the task we'll talk about what was is

00:10:34,320 --> 00:10:36,800
in a minute

00:10:37,440 --> 00:10:41,920
so we have made the claim that web

00:10:39,680 --> 00:10:42,959
assembly is faster than darker docker is

00:10:41,920 --> 00:10:45,120
faster than

00:10:42,959 --> 00:10:46,560
hardware vm and micro vm where um you

00:10:45,120 --> 00:10:48,160
know there's lots of research and lots

00:10:46,560 --> 00:10:50,880
of data that shows that we

00:10:48,160 --> 00:10:51,920
we don't want going you know that's um

00:10:50,880 --> 00:10:54,160
you know that's um

00:10:51,920 --> 00:10:55,600
we'll just take that as fact but the

00:10:54,160 --> 00:10:56,079
comparison between webassembly and

00:10:55,600 --> 00:10:58,079
docker

00:10:56,079 --> 00:10:59,360
is interesting you know that's uh that's

00:10:58,079 --> 00:11:01,200
a study that we did

00:10:59,360 --> 00:11:03,120
you know uh our team did and we

00:11:01,200 --> 00:11:04,000
published the results in iowa software

00:11:03,120 --> 00:11:07,600
last year

00:11:04,000 --> 00:11:09,279
it shows the performance of of

00:11:07,600 --> 00:11:12,560
web assembly versus docker in different

00:11:09,279 --> 00:11:14,560
scenarios the blue bars are ssvm which

00:11:12,560 --> 00:11:16,399
is our implementation of webassembly our

00:11:14,560 --> 00:11:17,920
open source implementation web assembly

00:11:16,399 --> 00:11:19,839
and we're going to talk about ssvm in a

00:11:17,920 --> 00:11:22,320
minute in a minute as well

00:11:19,839 --> 00:11:23,360
and the orange bar is docker plus native

00:11:22,320 --> 00:11:25,760
meaning that's

00:11:23,360 --> 00:11:26,880
it's a dark it's a variable darker image

00:11:25,760 --> 00:11:29,360
and then we run

00:11:26,880 --> 00:11:31,279
a native application on top of that

00:11:29,360 --> 00:11:32,800
image the native applications written c

00:11:31,279 --> 00:11:34,160
and compile to

00:11:32,800 --> 00:11:36,320
to run whatever the guest operating

00:11:34,160 --> 00:11:38,560
system docker has and then

00:11:36,320 --> 00:11:39,519
the green bar is dockercut node.js it's

00:11:38,560 --> 00:11:41,360
docker

00:11:39,519 --> 00:11:43,279
runs a high level programming language

00:11:41,360 --> 00:11:45,279
and high runs a heavy stack

00:11:43,279 --> 00:11:47,440
right to perform this exact same

00:11:45,279 --> 00:11:50,000
functions so the note

00:11:47,440 --> 00:11:50,800
is the note function is to just start

00:11:50,000 --> 00:11:54,480
and shut down

00:11:50,800 --> 00:11:56,079
to measure startup time and the blue bar

00:11:54,480 --> 00:11:57,760
is actually invisible so we have to

00:11:56,079 --> 00:12:00,320
multiply it by 50.

00:11:57,760 --> 00:12:02,240
you know so in order to just for it show

00:12:00,320 --> 00:12:05,360
up on the on the on the block

00:12:02,240 --> 00:12:07,519
so from here we can see in in terms of

00:12:05,360 --> 00:12:11,040
startup time although docker improves

00:12:07,519 --> 00:12:12,959
significantly from micro vms it's

00:12:11,040 --> 00:12:14,399
a thousand times slower than web

00:12:12,959 --> 00:12:15,200
assembly you know we have assembly just

00:12:14,399 --> 00:12:18,399
can start and

00:12:15,200 --> 00:12:19,519
stop in uh very very quickly without um

00:12:18,399 --> 00:12:22,480
you know that's uh

00:12:19,519 --> 00:12:23,920
um it hardly consumes any time but with

00:12:22,480 --> 00:12:25,760
docker you know that's uh

00:12:23,920 --> 00:12:28,240
um you're still talking about tens of

00:12:25,760 --> 00:12:31,519
milliseconds just to start up

00:12:28,240 --> 00:12:33,440
the um just to start the container

00:12:31,519 --> 00:12:35,440
and then you have to run the application

00:12:33,440 --> 00:12:38,800
that's that's written in a slow language

00:12:35,440 --> 00:12:39,920
on top of it right so from there that's

00:12:38,800 --> 00:12:43,120
that's already

00:12:39,920 --> 00:12:45,200
you know i think over over 100 times you

00:12:43,120 --> 00:12:47,120
know performance scans right there

00:12:45,200 --> 00:12:49,200
and then for the application that's

00:12:47,120 --> 00:12:51,519
actually the cpu intensive application

00:12:49,200 --> 00:12:53,680
that actually runs inside the containers

00:12:51,519 --> 00:12:55,680
we could see um unsurprisingly node.js

00:12:53,680 --> 00:12:57,200
performs worse because you know this uh

00:12:55,680 --> 00:12:58,160
it's written in javascript what do you

00:12:57,200 --> 00:13:01,120
expect right

00:12:58,160 --> 00:13:03,440
docker plus native is comparable to ssvm

00:13:01,120 --> 00:13:06,240
but ssvm is still faster

00:13:03,440 --> 00:13:07,760
so even for for runtime tasks you know

00:13:06,240 --> 00:13:11,680
webassembly container plus

00:13:07,760 --> 00:13:15,360
it's you know it's um sandbox bytecode

00:13:11,680 --> 00:13:16,240
it's still about 10 20 faster than

00:13:15,360 --> 00:13:18,399
docker plus

00:13:16,240 --> 00:13:19,680
fully native code you know so that's

00:13:18,399 --> 00:13:21,200
means you know if

00:13:19,680 --> 00:13:23,760
we do a performance comparison whether

00:13:21,200 --> 00:13:26,639
somebody is you know faster than darker

00:13:23,760 --> 00:13:27,120
across board and that solves the dilemma

00:13:26,639 --> 00:13:28,800
that we

00:13:27,120 --> 00:13:30,480
um that we raised in the beginning of

00:13:28,800 --> 00:13:32,320
our talk is to say

00:13:30,480 --> 00:13:34,079
how do we make serverless functions

00:13:32,320 --> 00:13:36,560
start up faster and run faster

00:13:34,079 --> 00:13:37,519
so that it can be more versatile so that

00:13:36,560 --> 00:13:39,920
it's not just

00:13:37,519 --> 00:13:40,880
the glucose to connect different systems

00:13:39,920 --> 00:13:44,399
we make it

00:13:40,880 --> 00:13:45,519
a universal back end for um for gm stack

00:13:44,399 --> 00:13:47,600
applications right

00:13:45,519 --> 00:13:48,720
so you know that's here we show that

00:13:47,600 --> 00:13:52,079
whether somebody at least have the

00:13:48,720 --> 00:13:52,079
potential because it is fast

00:13:52,399 --> 00:13:56,079
so cloud native web are some of the use

00:13:53,839 --> 00:13:57,120
cases and so those are the partners that

00:13:56,079 --> 00:13:59,600
we work with you know

00:13:57,120 --> 00:14:00,720
um at second stage obviously there are

00:13:59,600 --> 00:14:02,480
other use cases but

00:14:00,720 --> 00:14:03,920
i can only talk about things that i

00:14:02,480 --> 00:14:04,480
actually know right you know so those

00:14:03,920 --> 00:14:06,959
are

00:14:04,480 --> 00:14:08,720
our customers and partners and the first

00:14:06,959 --> 00:14:11,199
category of course is jam stack up

00:14:08,720 --> 00:14:12,480
web applications the web assembly helps

00:14:11,199 --> 00:14:15,040
here by

00:14:12,480 --> 00:14:16,560
providing a universal runtime that we

00:14:15,040 --> 00:14:17,519
can deploy not only on the cloud but

00:14:16,560 --> 00:14:20,240
also on the edge

00:14:17,519 --> 00:14:21,360
in a cdn network as a compute node right

00:14:20,240 --> 00:14:22,800
that allows gems

00:14:21,360 --> 00:14:24,720
gem stack application the

00:14:22,800 --> 00:14:26,959
serverless-based gem stack applications

00:14:24,720 --> 00:14:29,519
to have to reach high performance

00:14:26,959 --> 00:14:30,000
you know then we have sas and pass a

00:14:29,519 --> 00:14:32,959
also

00:14:30,000 --> 00:14:34,399
interesting use case is because you know

00:14:32,959 --> 00:14:36,639
one of the common

00:14:34,399 --> 00:14:38,160
thing about sas application is the need

00:14:36,639 --> 00:14:40,560
to customize and

00:14:38,160 --> 00:14:41,279
extend it for different customers right

00:14:40,560 --> 00:14:43,920
and today

00:14:41,279 --> 00:14:45,199
people do that with the api with

00:14:43,920 --> 00:14:47,279
callback apis

00:14:45,199 --> 00:14:49,360
meaning that's the the events that

00:14:47,279 --> 00:14:53,199
happen in the sas someone did something

00:14:49,360 --> 00:14:56,240
on sas platform could be sent to a

00:14:53,199 --> 00:14:57,040
external server and then developer runs

00:14:56,240 --> 00:14:58,959
that server

00:14:57,040 --> 00:15:00,800
and then the developer provides response

00:14:58,959 --> 00:15:01,920
from that server and goes back to the

00:15:00,800 --> 00:15:05,120
source

00:15:01,920 --> 00:15:07,279
interface just imagine uh say

00:15:05,120 --> 00:15:08,160
a chat bot right you know a messaging

00:15:07,279 --> 00:15:10,079
application

00:15:08,160 --> 00:15:12,160
you know how do you how do you create a

00:15:10,079 --> 00:15:15,199
chat box for messaging sas

00:15:12,160 --> 00:15:17,120
application you know you have uh you

00:15:15,199 --> 00:15:20,000
have an api based approach where

00:15:17,120 --> 00:15:20,880
you know um when a message was sent to a

00:15:20,000 --> 00:15:23,199
user

00:15:20,880 --> 00:15:24,320
something happened in that inside that

00:15:23,199 --> 00:15:26,079
messaging system

00:15:24,320 --> 00:15:27,839
the messaging system will forward this

00:15:26,079 --> 00:15:30,320
message to the server

00:15:27,839 --> 00:15:31,839
to external server that you run and then

00:15:30,320 --> 00:15:33,920
the developer

00:15:31,839 --> 00:15:35,600
the the application runs on the server

00:15:33,920 --> 00:15:36,720
sees this message and generates some

00:15:35,600 --> 00:15:38,399
kind of response

00:15:36,720 --> 00:15:40,160
and sends it back into into the

00:15:38,399 --> 00:15:41,279
messaging application and then the

00:15:40,160 --> 00:15:42,959
messaging application

00:15:41,279 --> 00:15:45,040
translates that into a message and send

00:15:42,959 --> 00:15:47,440
it back to the to the user

00:15:45,040 --> 00:15:48,320
it responds to it right so in that

00:15:47,440 --> 00:15:50,720
scenario

00:15:48,320 --> 00:15:52,399
you know we have a chat box but we also

00:15:50,720 --> 00:15:54,160
have external

00:15:52,399 --> 00:15:55,759
server side application that runs side

00:15:54,160 --> 00:15:59,120
to side with the sas

00:15:55,759 --> 00:16:00,720
and uh um isn't it let's reimagine how

00:15:59,120 --> 00:16:01,839
this might be wrong in a serverless

00:16:00,720 --> 00:16:03,759
environment

00:16:01,839 --> 00:16:05,040
why do we need the developer to set up a

00:16:03,759 --> 00:16:06,959
server that on the side

00:16:05,040 --> 00:16:08,320
you know that's uh it's tedious works

00:16:06,959 --> 00:16:10,800
it's expensive it's tedious

00:16:08,320 --> 00:16:12,079
and it's it's also an error prone

00:16:10,800 --> 00:16:13,600
because you know the server might be

00:16:12,079 --> 00:16:15,519
done and all that

00:16:13,600 --> 00:16:17,680
why can't the developer just submit a

00:16:15,519 --> 00:16:20,240
piece of code just to submit a function

00:16:17,680 --> 00:16:23,040
into the source platform and say this

00:16:20,240 --> 00:16:24,880
function responds to an incoming message

00:16:23,040 --> 00:16:26,320
right you know so if anyone send the

00:16:24,880 --> 00:16:29,120
message to to any

00:16:26,320 --> 00:16:30,800
to my users call this call this function

00:16:29,120 --> 00:16:31,920
and this function takes a string as

00:16:30,800 --> 00:16:34,320
input and

00:16:31,920 --> 00:16:36,639
returns a string at output so something

00:16:34,320 --> 00:16:38,000
like to apply the serverless model into

00:16:36,639 --> 00:16:40,639
a source application you would be able

00:16:38,000 --> 00:16:43,040
to get rid of most of the callback apis

00:16:40,639 --> 00:16:45,279
and most of the api complexities when

00:16:43,040 --> 00:16:47,040
people extend those sas applications

00:16:45,279 --> 00:16:48,480
so that's um that's that's something

00:16:47,040 --> 00:16:50,880
we're also very excited you know that we

00:16:48,480 --> 00:16:53,839
work with some sas providers that's um

00:16:50,880 --> 00:16:54,800
for for for this very purpose right you

00:16:53,839 --> 00:16:57,120
know of course there's

00:16:54,800 --> 00:16:58,480
uh iot devices and cars you know there's

00:16:57,120 --> 00:17:00,320
uh um you know

00:16:58,480 --> 00:17:01,759
i mean automobile operating system

00:17:00,320 --> 00:17:04,959
there's lots of um

00:17:01,759 --> 00:17:07,360
places where you know the the sub module

00:17:04,959 --> 00:17:10,240
subsystem is developed by someone else

00:17:07,360 --> 00:17:11,919
it's by a supplier or by a by a part

00:17:10,240 --> 00:17:14,079
supplier or by integrator

00:17:11,919 --> 00:17:15,520
and then it needs to be integrated

00:17:14,079 --> 00:17:18,240
together in a system that's

00:17:15,520 --> 00:17:20,000
that's um that's um that can run

00:17:18,240 --> 00:17:22,000
together without interfering

00:17:20,000 --> 00:17:23,839
with each other and one of the ways to

00:17:22,000 --> 00:17:26,160
do that of course is to use docker

00:17:23,839 --> 00:17:27,760
you know that's uh um so you know say

00:17:26,160 --> 00:17:30,960
you have a you have a

00:17:27,760 --> 00:17:31,679
electric car and uh it has a it has a

00:17:30,960 --> 00:17:34,799
subsystem

00:17:31,679 --> 00:17:36,320
that come from a different manufacturer

00:17:34,799 --> 00:17:38,080
that controls the window for instance

00:17:36,320 --> 00:17:39,679
the power window that goes up and down

00:17:38,080 --> 00:17:41,120
you know the logic of how the window

00:17:39,679 --> 00:17:43,039
goes up and down could

00:17:41,120 --> 00:17:44,720
needs to be run inside a container

00:17:43,039 --> 00:17:46,000
because it cannot be allowed to

00:17:44,720 --> 00:17:47,600
interfere with

00:17:46,000 --> 00:17:49,120
the drive training system or the

00:17:47,600 --> 00:17:51,120
autonomous driving system

00:17:49,120 --> 00:17:52,559
or the braking system or whatever right

00:17:51,120 --> 00:17:54,160
you know that's uh when the

00:17:52,559 --> 00:17:55,520
window with the software that comes

00:17:54,160 --> 00:17:56,559
through the window crashes it cannot

00:17:55,520 --> 00:17:58,960
crash the car

00:17:56,559 --> 00:18:00,000
so in that scenario you need something

00:17:58,960 --> 00:18:01,280
that's like docker

00:18:00,000 --> 00:18:03,280
right you know that's a software

00:18:01,280 --> 00:18:05,520
container and web assembly

00:18:03,280 --> 00:18:07,760
being able to run a variety of different

00:18:05,520 --> 00:18:09,280
um hardware and operating systems

00:18:07,760 --> 00:18:11,360
including real-time operating system

00:18:09,280 --> 00:18:14,000
provide a very good candidate for that

00:18:11,360 --> 00:18:14,720
you know that's it allows those um those

00:18:14,000 --> 00:18:16,559
um

00:18:14,720 --> 00:18:18,000
the integrated system inside of the car

00:18:16,559 --> 00:18:19,679
to function together right

00:18:18,000 --> 00:18:21,039
you know of course there's uh um there

00:18:19,679 --> 00:18:22,720
are there are blockchains and smart

00:18:21,039 --> 00:18:24,080
contracts which is another way

00:18:22,720 --> 00:18:25,440
of you know the way we look at

00:18:24,080 --> 00:18:27,200
blockchain smart contracts are

00:18:25,440 --> 00:18:28,799
decentralized the serverless right

00:18:27,200 --> 00:18:30,799
you know it's ver it's the development

00:18:28,799 --> 00:18:33,200
paradigm exactly like serverless you

00:18:30,799 --> 00:18:34,559
submit a piece of code and you don't

00:18:33,200 --> 00:18:36,400
care where it is wrong you don't care

00:18:34,559 --> 00:18:38,400
who the machine is running out

00:18:36,400 --> 00:18:39,679
but it's give you the results right you

00:18:38,400 --> 00:18:40,400
know that's like and you pay for the

00:18:39,679 --> 00:18:42,960
result

00:18:40,400 --> 00:18:44,799
and they accept this in this case the

00:18:42,960 --> 00:18:47,360
servers are not run by

00:18:44,799 --> 00:18:48,960
a cloud provider but by a network of

00:18:47,360 --> 00:18:51,760
nodes decentralized node

00:18:48,960 --> 00:18:53,520
right you know so so all those use case

00:18:51,760 --> 00:18:53,919
scenarios as you can see you know that's

00:18:53,520 --> 00:18:56,240
uh

00:18:53,919 --> 00:18:58,000
um would web assembly replace docker in

00:18:56,240 --> 00:19:01,600
cloud computing

00:18:58,000 --> 00:19:03,679
probably not but would it replace

00:19:01,600 --> 00:19:05,440
docker where docker cannot go today for

00:19:03,679 --> 00:19:07,600
instance on the edge cloud

00:19:05,440 --> 00:19:08,480
or on constrained device or on a source

00:19:07,600 --> 00:19:10,640
environment

00:19:08,480 --> 00:19:12,400
i think absolutely you know that's uh

00:19:10,640 --> 00:19:14,640
there's lots of use cases for that as we

00:19:12,400 --> 00:19:16,480
see here

00:19:14,640 --> 00:19:18,720
so the benefits of webassembly vm you

00:19:16,480 --> 00:19:20,720
know that's uh um because here

00:19:18,720 --> 00:19:22,799
so it's a one day today so i assume

00:19:20,720 --> 00:19:24,000
everybody are fairly familiar with those

00:19:22,799 --> 00:19:25,520
you know first of course there's

00:19:24,000 --> 00:19:27,520
security especially if you put them

00:19:25,520 --> 00:19:29,039
untrusted code like we talked about

00:19:27,520 --> 00:19:30,880
you know if you if you have a system

00:19:29,039 --> 00:19:31,600
where you allow people to upload code

00:19:30,880 --> 00:19:33,440
and you run it

00:19:31,600 --> 00:19:35,120
on their behalf then you need something

00:19:33,440 --> 00:19:35,760
you need a sandbox right that's where

00:19:35,120 --> 00:19:37,919
somebody is

00:19:35,760 --> 00:19:39,360
that's what a web server is for and code

00:19:37,919 --> 00:19:40,480
that needs to access hardware you know

00:19:39,360 --> 00:19:42,799
that's uh

00:19:40,480 --> 00:19:44,320
you know the iot setting or you know

00:19:42,799 --> 00:19:46,640
artificial intelligence and you know

00:19:44,320 --> 00:19:49,200
ai inference setting where code needs to

00:19:46,640 --> 00:19:51,360
access uh specialized

00:19:49,200 --> 00:19:52,559
chips that's um you know that's that

00:19:51,360 --> 00:19:53,679
handles air work

00:19:52,559 --> 00:19:55,520
you know those things have to be

00:19:53,679 --> 00:19:56,880
sandboxed so you can't have it

00:19:55,520 --> 00:19:58,799
unrestricted access

00:19:56,880 --> 00:20:00,160
that would um you know that's what have

00:19:58,799 --> 00:20:01,520
a higher probability of crashing the

00:20:00,160 --> 00:20:02,799
system

00:20:01,520 --> 00:20:04,320
you know it's very efficient and

00:20:02,799 --> 00:20:06,240
lightweight that's what it designed for

00:20:04,320 --> 00:20:07,919
you know it's uh it has very it

00:20:06,240 --> 00:20:10,000
it actually does very little it's uh

00:20:07,919 --> 00:20:12,320
it's a it's a security sandbox

00:20:10,000 --> 00:20:14,400
and uh as we can see from our previous

00:20:12,320 --> 00:20:17,760
and you know the performance charts

00:20:14,400 --> 00:20:18,159
it's has near native performance it's

00:20:17,760 --> 00:20:20,880
just

00:20:18,159 --> 00:20:23,600
it's runs as fast as uh as compiled to

00:20:20,880 --> 00:20:26,159
the native code without the sandbox

00:20:23,600 --> 00:20:27,919
so it has neonated performance and due

00:20:26,159 --> 00:20:29,520
to its dynamic perform compiler

00:20:27,919 --> 00:20:31,120
optimizers such as aot

00:20:29,520 --> 00:20:33,280
sometimes can even exceed native

00:20:31,120 --> 00:20:35,360
performance you know that's a

00:20:33,280 --> 00:20:37,120
interesting point i wouldn't expect it

00:20:35,360 --> 00:20:39,440
here but if you read our paper

00:20:37,120 --> 00:20:42,000
on our attribute software you see a

00:20:39,440 --> 00:20:44,159
discussion of it why the aot compilation

00:20:42,000 --> 00:20:45,120
could generate code that is faster than

00:20:44,159 --> 00:20:48,000
native code

00:20:45,120 --> 00:20:48,400
you know and the runtime safety you know

00:20:48,000 --> 00:20:50,240
that's

00:20:48,400 --> 00:20:51,440
um i i think still think security and

00:20:50,240 --> 00:20:52,480
safety are different things you know

00:20:51,440 --> 00:20:54,000
security are

00:20:52,480 --> 00:20:56,640
um other people want to attack you

00:20:54,000 --> 00:20:58,000
safety is um you know the bugs you have

00:20:56,640 --> 00:20:59,120
in your own code that are going to crash

00:20:58,000 --> 00:21:00,880
the system right

00:20:59,120 --> 00:21:02,400
in the portability and platform

00:21:00,880 --> 00:21:04,080
independence those are the

00:21:02,400 --> 00:21:05,760
old benefits of java you know the

00:21:04,080 --> 00:21:07,760
benefits of it but basically any

00:21:05,760 --> 00:21:09,679
software vm right you know that's uh

00:21:07,760 --> 00:21:11,120
you know it allows you to develop you

00:21:09,679 --> 00:21:13,039
know uh to to

00:21:11,120 --> 00:21:14,720
develop one machine deploying on another

00:21:13,039 --> 00:21:17,120
machine of a different

00:21:14,720 --> 00:21:18,480
operating system in the architecture and

00:21:17,120 --> 00:21:20,400
it's especially important in edge

00:21:18,480 --> 00:21:22,880
computing where there are so many

00:21:20,400 --> 00:21:23,679
devices and cpus these days you know it

00:21:22,880 --> 00:21:26,240
used to be

00:21:23,679 --> 00:21:27,200
the x86 it's the dominant cpu on the

00:21:26,240 --> 00:21:29,039
server side right

00:21:27,200 --> 00:21:30,960
but now you have arm you have all kinds

00:21:29,039 --> 00:21:32,000
of in edge environments you have all

00:21:30,960 --> 00:21:34,159
kinds of chips

00:21:32,000 --> 00:21:35,840
so you know so it's important for a live

00:21:34,159 --> 00:21:38,000
feed vm web assembly to run

00:21:35,840 --> 00:21:38,960
all those those hardware configurations

00:21:38,000 --> 00:21:41,600
and uh you know

00:21:38,960 --> 00:21:43,200
and and and it allows code to be to be

00:21:41,600 --> 00:21:44,720
written on a developer's machine and

00:21:43,200 --> 00:21:46,559
then deploy it everywhere

00:21:44,720 --> 00:21:48,000
across the edge cloud and the

00:21:46,559 --> 00:21:50,080
manageability you know that's

00:21:48,000 --> 00:21:52,000
uh because it's a container so it should

00:21:50,080 --> 00:21:52,880
be managed and orchestrated like other

00:21:52,000 --> 00:21:55,360
containers

00:21:52,880 --> 00:21:59,360
by things like kubernetes and or cube

00:21:55,360 --> 00:21:59,360
edge on in in the edge computing work

00:21:59,520 --> 00:22:03,280
so it's automated deployment and ops you

00:22:01,440 --> 00:22:04,720
know needs to support over-the-air

00:22:03,280 --> 00:22:06,400
deployments

00:22:04,720 --> 00:22:07,679
you know hotspotting with zero downtime

00:22:06,400 --> 00:22:09,360
so you know that's if you update the

00:22:07,679 --> 00:22:09,679
software you should be able to hotspot

00:22:09,360 --> 00:22:11,280
it

00:22:09,679 --> 00:22:12,720
in and out of the software module with

00:22:11,280 --> 00:22:14,880
no downtime

00:22:12,720 --> 00:22:16,000
so the web assembly system interface is

00:22:14,880 --> 00:22:18,240
called wazi

00:22:16,000 --> 00:22:19,600
and that's what um solomon hack is

00:22:18,240 --> 00:22:21,520
talking about in his tweets

00:22:19,600 --> 00:22:23,200
and this allows webassembly not only to

00:22:21,520 --> 00:22:25,760
interface with the

00:22:23,200 --> 00:22:27,280
with the browser whereas its web browser

00:22:25,760 --> 00:22:29,120
it's originally designed but also with

00:22:27,280 --> 00:22:31,520
the operating system itself

00:22:29,120 --> 00:22:33,440
so it's um interface with the file

00:22:31,520 --> 00:22:36,400
system environment variables

00:22:33,440 --> 00:22:38,320
network and all that so it allows the

00:22:36,400 --> 00:22:39,360
web assembly runtime to have access to

00:22:38,320 --> 00:22:42,880
all the

00:22:39,360 --> 00:22:44,799
of the host features that this runs out

00:22:42,880 --> 00:22:46,240
so awesome edge is open source project

00:22:44,799 --> 00:22:47,679
that we donated to cnc

00:22:46,240 --> 00:22:50,720
it's used uh the commercial version is

00:22:47,679 --> 00:22:52,400
called ssvm second state vm and it's uh

00:22:50,720 --> 00:22:53,440
it's completely open source project we

00:22:52,400 --> 00:22:56,480
developed

00:22:53,440 --> 00:23:00,080
open source from day one and we wrote it

00:22:56,480 --> 00:23:02,640
specially optimized for server-side and

00:23:00,080 --> 00:23:03,840
you know edge computing use cases if you

00:23:02,640 --> 00:23:06,240
are interested check it out

00:23:03,840 --> 00:23:06,880
and you know like it focus and you know

00:23:06,240 --> 00:23:09,679
discuss

00:23:06,880 --> 00:23:11,120
issues with us on github this is the

00:23:09,679 --> 00:23:14,320
paper that we published on

00:23:11,120 --> 00:23:16,640
itube software that shows the ssvm is

00:23:14,320 --> 00:23:17,760
is already one of the fastest web

00:23:16,640 --> 00:23:20,880
assembly runtimes

00:23:17,760 --> 00:23:22,320
that's available in the market so we um

00:23:20,880 --> 00:23:24,640
there's one particular thing that we

00:23:22,320 --> 00:23:25,919
like to add to the ssvm in context of

00:23:24,640 --> 00:23:28,159
serverless functions

00:23:25,919 --> 00:23:30,240
is that we we want to build powerful was

00:23:28,159 --> 00:23:32,480
like extensions you know onesie provide

00:23:30,240 --> 00:23:33,440
access to the host operating system and

00:23:32,480 --> 00:23:36,000
we think

00:23:33,440 --> 00:23:36,640
you know why stop has left c and i and

00:23:36,000 --> 00:23:38,880
the

00:23:36,640 --> 00:23:40,080
the operating system level function cost

00:23:38,880 --> 00:23:41,919
why don't we make it

00:23:40,080 --> 00:23:44,080
make all the native functions available

00:23:41,919 --> 00:23:44,960
to wazi and through a very organized and

00:23:44,080 --> 00:23:47,600
very polished

00:23:44,960 --> 00:23:49,039
api that's available as a rust sdk as

00:23:47,600 --> 00:23:50,880
well so we can do

00:23:49,039 --> 00:23:52,400
tensorflow inference which i wish i

00:23:50,880 --> 00:23:54,480
talked about in another talk

00:23:52,400 --> 00:23:55,520
and we can do storage we can do um

00:23:54,480 --> 00:23:57,120
blockchain stuff

00:23:55,520 --> 00:23:58,559
that's uh you know access instead of the

00:23:57,120 --> 00:23:59,360
file system the blockchain account

00:23:58,559 --> 00:24:03,520
system

00:23:59,360 --> 00:24:05,600
through our webassembly runtime

00:24:03,520 --> 00:24:06,559
the cloud native features are the ones

00:24:05,600 --> 00:24:09,279
that i talked about

00:24:06,559 --> 00:24:10,240
you know in the previous slides which to

00:24:09,279 --> 00:24:12,320
uh is to

00:24:10,240 --> 00:24:13,360
assume oci compliance allows the whole

00:24:12,320 --> 00:24:17,039
thing to be managed

00:24:13,360 --> 00:24:18,799
and orchestrated by kubernetes

00:24:17,039 --> 00:24:20,400
well so you know a service function

00:24:18,799 --> 00:24:22,000
writing web assembly is really simple

00:24:20,400 --> 00:24:23,760
you know here is a

00:24:22,000 --> 00:24:25,120
here's a complete function you know it's

00:24:23,760 --> 00:24:25,840
to say hello you know let's take a

00:24:25,120 --> 00:24:27,600
string

00:24:25,840 --> 00:24:29,840
and then if you read a little bit of

00:24:27,600 --> 00:24:31,440
rust it's uh it's append hello

00:24:29,840 --> 00:24:33,279
in front of the string and it returns it

00:24:31,440 --> 00:24:35,120
back right the one

00:24:33,279 --> 00:24:37,440
i've just shown is a service function

00:24:35,120 --> 00:24:38,159
where you can you can access your url

00:24:37,440 --> 00:24:40,000
right you know

00:24:38,159 --> 00:24:42,080
it's a service function that's on the

00:24:40,000 --> 00:24:43,840
back end of the jam stack application

00:24:42,080 --> 00:24:45,279
and here is another here is another

00:24:43,840 --> 00:24:47,440
example that that's

00:24:45,279 --> 00:24:48,799
that we talked about it's a uh is a

00:24:47,440 --> 00:24:50,960
chatbot example in

00:24:48,799 --> 00:24:52,080
a messaging application where you have a

00:24:50,960 --> 00:24:54,880
serverless mode you

00:24:52,080 --> 00:24:55,600
upload a piece of code like this to the

00:24:54,880 --> 00:24:58,159
uh to the

00:24:55,600 --> 00:24:59,600
messaging application platform and then

00:24:58,159 --> 00:25:01,840
specify

00:24:59,600 --> 00:25:02,880
a hook to say if i received any message

00:25:01,840 --> 00:25:05,679
call this function

00:25:02,880 --> 00:25:06,799
and it will tell you what the the

00:25:05,679 --> 00:25:09,039
message is received

00:25:06,799 --> 00:25:10,640
from which user it's come from and they

00:25:09,039 --> 00:25:12,880
ask you to provide a response right you

00:25:10,640 --> 00:25:14,640
can't you provide a response and then

00:25:12,880 --> 00:25:16,480
uploading and running this function you

00:25:14,640 --> 00:25:18,320
don't have to

00:25:16,480 --> 00:25:20,240
you no longer have to run your own

00:25:18,320 --> 00:25:22,480
server and do the api calls

00:25:20,240 --> 00:25:24,240
to the api callbacks for to extend sas

00:25:22,480 --> 00:25:26,720
applications

00:25:24,240 --> 00:25:28,320
so there are lots of live demos you know

00:25:26,720 --> 00:25:30,159
especially for the jam stack application

00:25:28,320 --> 00:25:32,159
use case we have a lot of ai demos

00:25:30,159 --> 00:25:33,919
where you can write serverless functions

00:25:32,159 --> 00:25:35,440
to do tensorflow inference to do

00:25:33,919 --> 00:25:37,120
image recognition and all that all the

00:25:35,440 --> 00:25:39,120
source codes are available and

00:25:37,120 --> 00:25:40,960
you can deploy them in minutes and see

00:25:39,120 --> 00:25:43,200
see the result yourself and you can even

00:25:40,960 --> 00:25:44,720
try the live demo there's lots of them

00:25:43,200 --> 00:25:46,640
in our website

00:25:44,720 --> 00:25:48,400
and there's also a lot of tutorials

00:25:46,640 --> 00:25:49,520
about you know writing server-side web

00:25:48,400 --> 00:25:52,080
assembly applications

00:25:49,520 --> 00:25:52,559
and also how to use how to optimize them

00:25:52,080 --> 00:25:55,520
for the

00:25:52,559 --> 00:25:56,240
for for awesome image and ssb all right

00:25:55,520 --> 00:25:58,960
i think

00:25:56,240 --> 00:26:00,080
my time's up and thank you very much and

00:25:58,960 --> 00:26:02,240
check out our

00:26:00,080 --> 00:26:03,760
github repository and website and i hope

00:26:02,240 --> 00:26:06,960
to see you there have a great day thank

00:26:03,760 --> 00:26:06,960

YouTube URL: https://www.youtube.com/watch?v=YnQeoGrkJKM


