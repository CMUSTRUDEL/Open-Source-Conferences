Title: Cartography: using graphs to improve and scale security decision-ma... Alex Chantavy & Marco Lancini
Publication date: 2020-11-25
Playlist: Cloud Native Security Day North America 2020
Description: 
	Cartography: using graphs to improve and scale security decision-making - Alex Chantavy, Lyft & Marco Lancini, Thought Machine

This talk highlights using Cartography (https://github.com/lyft/cartography) to improve and scale security decision-making in cloud-native environments. Attendees of this session will be introduced to the platform and shown a broad set of compelling scenarios including understanding complex permissions relationships, tracking and alerting on infrastructure changes, and enabling teams to see and better understand their security risk regardless of the platforms they use.  Cartography is a free open-source tool that consolidates your technical assets and the relationships between them in an intuitive graph database.  The presenters hope that sharing their approaches to these problems will help you better understand, categorize, and secure all the assets deployed in your cloud-native organization. They are thrilled to grow the Cartography community in the first couple years as an open source project and look forward to hearing your feedback!
Captions: 
	00:00:00,000 --> 00:00:04,560
hello everyone i'm alex cintavi and i'm

00:00:02,879 --> 00:00:06,160
marco lancini

00:00:04,560 --> 00:00:08,400
today we're going to tell you about a

00:00:06,160 --> 00:00:08,720
free open source graph tool that we work

00:00:08,400 --> 00:00:11,440
on

00:00:08,720 --> 00:00:13,679
called cartography our talk is called

00:00:11,440 --> 00:00:16,480
using graphs to improve and scale

00:00:13,679 --> 00:00:17,359
security decision making it's an honor

00:00:16,480 --> 00:00:19,359
for us to

00:00:17,359 --> 00:00:20,560
present cartography here at cloud native

00:00:19,359 --> 00:00:22,160
security day

00:00:20,560 --> 00:00:23,760
we hope you find it and the techniques

00:00:22,160 --> 00:00:25,680
we present today useful

00:00:23,760 --> 00:00:27,599
in your own teams and we also look

00:00:25,680 --> 00:00:30,640
forward to receiving your feedback

00:00:27,599 --> 00:00:32,320
and contributions

00:00:30,640 --> 00:00:34,399
so just to tell you a little bit about

00:00:32,320 --> 00:00:35,680
who we are so i'm alex i'm a software

00:00:34,399 --> 00:00:38,160
engineer at lyft

00:00:35,680 --> 00:00:39,600
i have a background in red teaming cloud

00:00:38,160 --> 00:00:41,040
environments so i kind of look at all

00:00:39,600 --> 00:00:44,800
these security problems from

00:00:41,040 --> 00:00:46,879
a little bit of an offensive slant

00:00:44,800 --> 00:00:47,920
and i'm marco lancini i'm a cloud

00:00:46,879 --> 00:00:50,399
security engineer

00:00:47,920 --> 00:00:54,320
a thought machine in the uk and i'm also

00:00:50,399 --> 00:00:54,320
the curator of cloud cyclists.com

00:00:55,360 --> 00:00:58,879
so i'd like to start off by this

00:00:56,960 --> 00:01:01,359
presentation by telling you the story

00:00:58,879 --> 00:01:04,640
about why cartography was designed

00:01:01,359 --> 00:01:05,600
in the first place it all began with a

00:01:04,640 --> 00:01:08,159
common problem

00:01:05,600 --> 00:01:08,720
that security teams and all cloud native

00:01:08,159 --> 00:01:12,240
companies

00:01:08,720 --> 00:01:14,479
are facing things are moving too fast

00:01:12,240 --> 00:01:16,320
and when things move fast there's lots

00:01:14,479 --> 00:01:18,640
of security and tech debt

00:01:16,320 --> 00:01:19,840
that accrues and because things are

00:01:18,640 --> 00:01:22,720
moving so fast

00:01:19,840 --> 00:01:23,920
there's not time to document things and

00:01:22,720 --> 00:01:25,600
everybody

00:01:23,920 --> 00:01:28,159
develops their own sort of tribal

00:01:25,600 --> 00:01:31,600
knowledge with hyper growth comes

00:01:28,159 --> 00:01:32,880
a large attack surface and one of the

00:01:31,600 --> 00:01:35,280
problems that we aimed

00:01:32,880 --> 00:01:37,119
to that we found ourselves needing to

00:01:35,280 --> 00:01:40,640
address was how can we

00:01:37,119 --> 00:01:41,600
understand track and manage our infra as

00:01:40,640 --> 00:01:46,000
it changes

00:01:41,600 --> 00:01:49,200
over time this is compounded by the fact

00:01:46,000 --> 00:01:49,520
that modern infra is complicated there

00:01:49,200 --> 00:01:51,600
are

00:01:49,520 --> 00:01:54,159
very very complicated permissions models

00:01:51,600 --> 00:01:56,799
on all the major cloud providers

00:01:54,159 --> 00:01:58,880
uh for example you have your you have

00:01:56,799 --> 00:02:01,439
with amazon web services you'll have

00:01:58,880 --> 00:02:02,399
identity and access management gcp

00:02:01,439 --> 00:02:06,159
google has their

00:02:02,399 --> 00:02:08,640
own solution for iam and so

00:02:06,159 --> 00:02:10,800
you'll have one solution that will set

00:02:08,640 --> 00:02:12,959
up identities and accesses

00:02:10,800 --> 00:02:14,959
in one way and then you'll have this

00:02:12,959 --> 00:02:16,720
cloud system that'll do that and then

00:02:14,959 --> 00:02:18,239
there'll also need you'll also need to

00:02:16,720 --> 00:02:20,480
deal with plain old

00:02:18,239 --> 00:02:22,640
username and password pairs on a storage

00:02:20,480 --> 00:02:24,879
resource or database resource

00:02:22,640 --> 00:02:25,760
and you need to answer the question who

00:02:24,879 --> 00:02:29,280
can become

00:02:25,760 --> 00:02:31,599
whom how does this im solution allow

00:02:29,280 --> 00:02:32,879
identities to become other identities

00:02:31,599 --> 00:02:36,239
and how are you opening

00:02:32,879 --> 00:02:39,280
up your environment for transitive risk

00:02:36,239 --> 00:02:42,080
and the question of which identities

00:02:39,280 --> 00:02:42,959
may access what resources is not

00:02:42,080 --> 00:02:46,400
immediately

00:02:42,959 --> 00:02:47,120
obvious and with all of these multiple

00:02:46,400 --> 00:02:49,519
vendors

00:02:47,120 --> 00:02:50,720
lots of knobs and dials it's easy to get

00:02:49,519 --> 00:02:52,959
this wrong

00:02:50,720 --> 00:02:54,400
and there are big consequences for

00:02:52,959 --> 00:02:56,400
getting it wrong

00:02:54,400 --> 00:02:58,720
and the couple of the scenarios that we

00:02:56,400 --> 00:03:01,200
wanted to address here

00:02:58,720 --> 00:03:02,159
was we wanted something that could check

00:03:01,200 --> 00:03:05,440
and audit

00:03:02,159 --> 00:03:06,159
accesses we wanted to understand policy

00:03:05,440 --> 00:03:08,720
grants

00:03:06,159 --> 00:03:10,800
for cloud resources and we wanted to

00:03:08,720 --> 00:03:14,080
understand the effect of changes

00:03:10,800 --> 00:03:16,640
to network policy

00:03:14,080 --> 00:03:17,120
and of course we wanted it all yesterday

00:03:16,640 --> 00:03:20,159
and

00:03:17,120 --> 00:03:22,159
with me for minimal cost every

00:03:20,159 --> 00:03:23,200
company faces this problem where you

00:03:22,159 --> 00:03:26,400
have limited

00:03:23,200 --> 00:03:28,159
resources we had a small team

00:03:26,400 --> 00:03:30,080
and we needed to automate where it was

00:03:28,159 --> 00:03:32,959
practical we need to aggressively

00:03:30,080 --> 00:03:34,000
prioritize projects and you know even if

00:03:32,959 --> 00:03:35,280
you have a large team

00:03:34,000 --> 00:03:37,599
you're still going to run into this

00:03:35,280 --> 00:03:43,040
problem of balancing everything

00:03:37,599 --> 00:03:43,040
so what could we do about these problems

00:03:43,120 --> 00:03:46,480
first i have to give credit to sasha

00:03:44,959 --> 00:03:48,720
faust who originally

00:03:46,480 --> 00:03:49,599
built cartography by asking this

00:03:48,720 --> 00:03:52,080
question

00:03:49,599 --> 00:03:53,840
can we apply an offensive security

00:03:52,080 --> 00:03:55,439
approach to these keep the lights on

00:03:53,840 --> 00:03:56,640
problems these problems that have to

00:03:55,439 --> 00:03:58,239
deal with

00:03:56,640 --> 00:04:00,080
essentially running the business keeping

00:03:58,239 --> 00:04:02,159
everything alive

00:04:00,080 --> 00:04:03,439
what offensive approach was he actually

00:04:02,159 --> 00:04:06,319
talking about

00:04:03,439 --> 00:04:07,920
well there's this famous quote and if

00:04:06,319 --> 00:04:09,680
you've been in infosec the past couple

00:04:07,920 --> 00:04:10,720
years you've almost certainly seen this

00:04:09,680 --> 00:04:15,040
at some point

00:04:10,720 --> 00:04:18,079
and that's defenders think in lists

00:04:15,040 --> 00:04:20,079
attackers think in graphs as long as

00:04:18,079 --> 00:04:22,880
this is true attackers win

00:04:20,079 --> 00:04:24,880
pardon the overused drake meme i i'm

00:04:22,880 --> 00:04:26,800
honestly sorry about that but this quote

00:04:24,880 --> 00:04:29,120
has been cited so much

00:04:26,800 --> 00:04:30,000
it's almost become as ubiquitous as the

00:04:29,120 --> 00:04:31,680
drake meme

00:04:30,000 --> 00:04:33,600
but i promise that i'm bringing it up

00:04:31,680 --> 00:04:36,320
again for good reason

00:04:33,600 --> 00:04:37,280
so john lombard at microsoft who made

00:04:36,320 --> 00:04:39,840
this quote

00:04:37,280 --> 00:04:41,600
says has this influential paper where he

00:04:39,840 --> 00:04:43,680
says this and the idea is that if you

00:04:41,600 --> 00:04:46,639
only look at your high valued assets

00:04:43,680 --> 00:04:47,919
in terms of lists of people who may

00:04:46,639 --> 00:04:50,080
access them

00:04:47,919 --> 00:04:51,600
you're missing out on the opportunities

00:04:50,080 --> 00:04:54,639
that an attacker is going to have

00:04:51,600 --> 00:04:56,800
moving laterally within your environment

00:04:54,639 --> 00:04:58,800
so this particular example has to deal

00:04:56,800 --> 00:04:59,840
with a windows on-prem domain

00:04:58,800 --> 00:05:02,320
environment

00:04:59,840 --> 00:05:03,840
where an attacker could gain access to

00:05:02,320 --> 00:05:06,000
this terminal server

00:05:03,840 --> 00:05:08,080
dump creds from memory and then use

00:05:06,000 --> 00:05:10,560
those to move closer and closer to

00:05:08,080 --> 00:05:12,560
objective dumping credits along the way

00:05:10,560 --> 00:05:14,479
what are those graph paths to reach

00:05:12,560 --> 00:05:18,000
there so

00:05:14,479 --> 00:05:19,919
in the cloud doing a similar technique

00:05:18,000 --> 00:05:22,000
like this is even more effective because

00:05:19,919 --> 00:05:24,720
you can take advantage of the patchwork

00:05:22,000 --> 00:05:26,240
set of permissions models and multiple

00:05:24,720 --> 00:05:30,639
zig-zaggy ways to

00:05:26,240 --> 00:05:33,280
reach your target assets if you're

00:05:30,639 --> 00:05:34,080
a cloud-first company cloud-native

00:05:33,280 --> 00:05:35,680
company

00:05:34,080 --> 00:05:37,840
then where all of your infras

00:05:35,680 --> 00:05:40,800
cloud-based you have your security work

00:05:37,840 --> 00:05:40,800
cut out for you

00:05:41,199 --> 00:05:44,639
and it became clear to us that we need a

00:05:44,160 --> 00:05:47,840
self

00:05:44,639 --> 00:05:49,840
maintaining map we want something that

00:05:47,840 --> 00:05:50,320
could highlight structural risks and

00:05:49,840 --> 00:05:53,199
answer

00:05:50,320 --> 00:05:53,600
hard to answer questions we came up with

00:05:53,199 --> 00:05:55,759
these

00:05:53,600 --> 00:05:57,280
use cases that we wanted a central view

00:05:55,759 --> 00:05:59,120
or technical assets

00:05:57,280 --> 00:06:02,000
we wanted something that we could help

00:05:59,120 --> 00:06:04,400
us in incident response

00:06:02,000 --> 00:06:05,039
security research red blue teaming and

00:06:04,400 --> 00:06:07,360
help us

00:06:05,039 --> 00:06:08,720
quickly finish the drudgery of

00:06:07,360 --> 00:06:10,880
compliance reports

00:06:08,720 --> 00:06:11,919
and audits essentially such a graph

00:06:10,880 --> 00:06:15,680
would help us show

00:06:11,919 --> 00:06:18,840
non-obvious connections between one

00:06:15,680 --> 00:06:22,560
piece of our security posture to

00:06:18,840 --> 00:06:23,919
another existing solutions that we

00:06:22,560 --> 00:06:27,600
looked into they're either

00:06:23,919 --> 00:06:30,479
really expensive proprietary locked down

00:06:27,600 --> 00:06:30,800
or too focused and limited in scope so

00:06:30,479 --> 00:06:32,479
like

00:06:30,800 --> 00:06:34,080
the main thing that we wanted to look

00:06:32,479 --> 00:06:36,639
into was because

00:06:34,080 --> 00:06:37,759
we had many different vendors and many

00:06:36,639 --> 00:06:41,199
different data sources

00:06:37,759 --> 00:06:43,199
the ability to quickly extend on the

00:06:41,199 --> 00:06:43,840
product and build plug-ins for ourselves

00:06:43,199 --> 00:06:47,280
that was

00:06:43,840 --> 00:06:49,840
a very key scenario and so that would be

00:06:47,280 --> 00:06:51,759
a main blocker for us in considering

00:06:49,840 --> 00:06:54,000
some of the other products that we

00:06:51,759 --> 00:06:57,039
looked at

00:06:54,000 --> 00:06:57,599
enter cartography so we're very really

00:06:57,039 --> 00:07:01,599
excited

00:06:57,599 --> 00:07:05,280
having um last year in march of 2019 we

00:07:01,599 --> 00:07:06,960
open sourced this idea to github

00:07:05,280 --> 00:07:08,560
come check us out github.com lyft

00:07:06,960 --> 00:07:11,680
cartography so

00:07:08,560 --> 00:07:13,840
it is a python tool that pulls

00:07:11,680 --> 00:07:15,360
data from all of your from many

00:07:13,840 --> 00:07:18,240
different

00:07:15,360 --> 00:07:19,840
sources and it puts them together in the

00:07:18,240 --> 00:07:21,840
form of a graph database

00:07:19,840 --> 00:07:23,440
and so what you'll see is that it'll

00:07:21,840 --> 00:07:25,680
what this approach lets us do

00:07:23,440 --> 00:07:27,199
is it lets us show these non-obvious

00:07:25,680 --> 00:07:29,520
relationships between

00:07:27,199 --> 00:07:30,880
each and every one of these assets and

00:07:29,520 --> 00:07:33,280
i'm going to show you how we

00:07:30,880 --> 00:07:35,199
modeled our organization as a graph and

00:07:33,280 --> 00:07:38,319
why this approach has been so

00:07:35,199 --> 00:07:41,120
useful and effective for us

00:07:38,319 --> 00:07:41,840
first off i'll start off by showing that

00:07:41,120 --> 00:07:45,120
we can

00:07:41,840 --> 00:07:46,160
model our octa infrastructure at lyft as

00:07:45,120 --> 00:07:49,360
a graph

00:07:46,160 --> 00:07:52,639
so this is an octa organization octa is

00:07:49,360 --> 00:07:56,000
an identity provider and as a person

00:07:52,639 --> 00:07:58,319
as a human i have a user identity i can

00:07:56,000 --> 00:08:01,440
be a member of a group

00:07:58,319 --> 00:08:04,879
you can set up octa to delegate access

00:08:01,440 --> 00:08:08,000
into your aws infrastructure so

00:08:04,879 --> 00:08:11,360
if you are a member of an akhta group

00:08:08,000 --> 00:08:15,199
then you're you may assume an aws

00:08:11,360 --> 00:08:17,520
role you can become an amazon identity

00:08:15,199 --> 00:08:18,240
and those aws identities they are

00:08:17,520 --> 00:08:22,080
grouped up

00:08:18,240 --> 00:08:25,120
into accounts an account is a notion

00:08:22,080 --> 00:08:28,560
of separation between business units

00:08:25,120 --> 00:08:30,639
so you can many companies will set up

00:08:28,560 --> 00:08:31,599
different departments into aws accounts

00:08:30,639 --> 00:08:33,360
for example so

00:08:31,599 --> 00:08:34,880
it's meant as an organizational way for

00:08:33,360 --> 00:08:39,599
you to split up different

00:08:34,880 --> 00:08:42,640
concerns we can tie this

00:08:39,599 --> 00:08:46,399
personnel data to workday or any other

00:08:42,640 --> 00:08:47,680
hr system so we we're adding in this new

00:08:46,399 --> 00:08:50,640
context you see that

00:08:47,680 --> 00:08:52,399
we can add in the reporting structure of

00:08:50,640 --> 00:08:53,440
an organization we can add in who

00:08:52,399 --> 00:08:56,640
belongs to which

00:08:53,440 --> 00:08:57,839
teams we can augment this further by

00:08:56,640 --> 00:09:00,800
adding okay well

00:08:57,839 --> 00:09:01,519
let's we have octa identities now let's

00:09:00,800 --> 00:09:03,279
use

00:09:01,519 --> 00:09:05,680
g suite identities let's add that in

00:09:03,279 --> 00:09:08,000
there we can get visibility onto

00:09:05,680 --> 00:09:09,839
the chrome extensions that our

00:09:08,000 --> 00:09:11,920
organization installs using

00:09:09,839 --> 00:09:13,519
something called cr excavator as well

00:09:11,920 --> 00:09:15,920
and the thing i want to call out here is

00:09:13,519 --> 00:09:19,920
that every single one of these edges

00:09:15,920 --> 00:09:23,120
is if it was actually installed onto

00:09:19,920 --> 00:09:25,360
if we were to represent this in a

00:09:23,120 --> 00:09:26,399
relational database every one of these

00:09:25,360 --> 00:09:29,519
edges would

00:09:26,399 --> 00:09:31,200
be a um would be a join

00:09:29,519 --> 00:09:32,720
and then if you were to do this for

00:09:31,200 --> 00:09:35,120
every single one of these edges it's

00:09:32,720 --> 00:09:36,080
typing join on table name join on table

00:09:35,120 --> 00:09:38,880
name this gets

00:09:36,080 --> 00:09:40,720
really old very quickly so representing

00:09:38,880 --> 00:09:44,000
this in the graph allows us to see

00:09:40,720 --> 00:09:44,399
all of these uh connections in a lot

00:09:44,000 --> 00:09:46,399
more

00:09:44,399 --> 00:09:47,839
intuitive way and i'm going to show you

00:09:46,399 --> 00:09:49,680
this scenario

00:09:47,839 --> 00:09:51,200
i'm putting this making this a little

00:09:49,680 --> 00:09:52,800
bit more hopefully a little more

00:09:51,200 --> 00:09:54,320
compelling

00:09:52,800 --> 00:09:56,720
and so the point here is that we have

00:09:54,320 --> 00:09:59,839
this extensible pluggable

00:09:56,720 --> 00:10:01,680
platform your graph becomes most useful

00:09:59,839 --> 00:10:03,279
when you can take our existing modules

00:10:01,680 --> 00:10:05,279
and join them with your own

00:10:03,279 --> 00:10:07,040
and doing so is a straightforward

00:10:05,279 --> 00:10:09,360
process

00:10:07,040 --> 00:10:10,800
so the scenario that i was just telling

00:10:09,360 --> 00:10:13,920
you right now where

00:10:10,800 --> 00:10:16,480
i got myself and i have an octa identity

00:10:13,920 --> 00:10:18,240
and i am the member of the developers

00:10:16,480 --> 00:10:21,600
group in october

00:10:18,240 --> 00:10:24,959
this lets me assume an aws role named

00:10:21,600 --> 00:10:28,640
developers this developer's role

00:10:24,959 --> 00:10:31,839
belongs to the developers aws account

00:10:28,640 --> 00:10:32,640
and okay so far so good this is how that

00:10:31,839 --> 00:10:34,720
aws

00:10:32,640 --> 00:10:36,640
and octave you can it's it's a

00:10:34,720 --> 00:10:39,279
well-documented scenario

00:10:36,640 --> 00:10:40,560
this is the what we wanted to do now the

00:10:39,279 --> 00:10:44,000
problem here is

00:10:40,560 --> 00:10:45,600
okay um i mentioned that that it is

00:10:44,000 --> 00:10:48,480
possible in aws

00:10:45,600 --> 00:10:50,160
to for one role to assume another role

00:10:48,480 --> 00:10:53,279
for one identity to

00:10:50,160 --> 00:10:53,760
become another identity and this is used

00:10:53,279 --> 00:10:57,279
as

00:10:53,760 --> 00:11:00,320
a feature of most iam

00:10:57,279 --> 00:11:01,920
solutions so as developers we have

00:11:00,320 --> 00:11:05,360
discovered using cartography

00:11:01,920 --> 00:11:08,480
that i can assume this auditor's role

00:11:05,360 --> 00:11:09,120
so as a developer i am able to assume

00:11:08,480 --> 00:11:12,480
this

00:11:09,120 --> 00:11:13,120
additional role is this expected is this

00:11:12,480 --> 00:11:15,120
not

00:11:13,120 --> 00:11:16,560
let's find out and then so with this

00:11:15,120 --> 00:11:20,480
auditor's role this otter's role

00:11:16,560 --> 00:11:22,959
belongs to the finance account and

00:11:20,480 --> 00:11:25,120
like i mentioned earlier aws accounts

00:11:22,959 --> 00:11:28,000
are used as ways to split up

00:11:25,120 --> 00:11:29,600
different concerns and so having the dev

00:11:28,000 --> 00:11:31,360
account and the finance account the way

00:11:29,600 --> 00:11:32,959
that this organization was designed was

00:11:31,360 --> 00:11:35,040
for those things to be separate

00:11:32,959 --> 00:11:36,800
and yet here we have this opportunity

00:11:35,040 --> 00:11:39,120
for developers to become

00:11:36,800 --> 00:11:39,839
auditors and view assets in the finance

00:11:39,120 --> 00:11:41,600
account

00:11:39,839 --> 00:11:43,440
potentially violating some of our

00:11:41,600 --> 00:11:46,079
assumptions about

00:11:43,440 --> 00:11:47,279
how our organization is segmented off

00:11:46,079 --> 00:11:49,920
from each other

00:11:47,279 --> 00:11:50,800
and potentially highlighting some

00:11:49,920 --> 00:11:53,440
potential

00:11:50,800 --> 00:11:54,320
compliance issues auditing issues etc

00:11:53,440 --> 00:11:57,839
etc

00:11:54,320 --> 00:12:00,160
so you know you want to have this

00:11:57,839 --> 00:12:02,720
visibility in your organization to

00:12:00,160 --> 00:12:04,079
see opportunities to move between roles

00:12:02,720 --> 00:12:06,399
especially when

00:12:04,079 --> 00:12:08,079
they cross trust boundaries and we think

00:12:06,399 --> 00:12:09,200
that this is a compelling and powerful

00:12:08,079 --> 00:12:10,800
scenario that

00:12:09,200 --> 00:12:13,279
a graph approach that lends itself well

00:12:10,800 --> 00:12:16,240
to a graph approach

00:12:13,279 --> 00:12:17,120
i'll talk briefly about how our tool

00:12:16,240 --> 00:12:20,079
does this

00:12:17,120 --> 00:12:22,880
so the main point the main um the core

00:12:20,079 --> 00:12:26,720
part of cartography is this core sync

00:12:22,880 --> 00:12:28,399
so we take we um we run a core sync the

00:12:26,720 --> 00:12:29,680
core sync of cartography so like i said

00:12:28,399 --> 00:12:32,160
it's a python tool

00:12:29,680 --> 00:12:33,200
and every single one of this of these

00:12:32,160 --> 00:12:36,000
data modules

00:12:33,200 --> 00:12:36,320
is something we call an intel module and

00:12:36,000 --> 00:12:38,560
what

00:12:36,320 --> 00:12:39,440
what each intel module does is that it

00:12:38,560 --> 00:12:42,000
will

00:12:39,440 --> 00:12:43,040
pull from its data source and write it

00:12:42,000 --> 00:12:46,399
to a

00:12:43,040 --> 00:12:48,720
graph database powered by neo4j

00:12:46,399 --> 00:12:50,480
and it will write that and then all that

00:12:48,720 --> 00:12:53,600
data will be exposed either

00:12:50,480 --> 00:12:57,440
via a web browser interface or via

00:12:53,600 --> 00:12:59,760
a api um powered by vault

00:12:57,440 --> 00:13:02,160
and so that's the basically the basic

00:12:59,760 --> 00:13:03,440
idea so we have also clean up jobs so

00:13:02,160 --> 00:13:06,480
what happens is that

00:13:03,440 --> 00:13:07,519
on every sink we set a timestamp so that

00:13:06,480 --> 00:13:10,000
we always keep

00:13:07,519 --> 00:13:11,600
the freshest data in the graph and we

00:13:10,000 --> 00:13:14,160
run a cleanup job

00:13:11,600 --> 00:13:15,680
so that nodes that are no longer there

00:13:14,160 --> 00:13:16,320
on the graph that are no longer there in

00:13:15,680 --> 00:13:19,440
real life

00:13:16,320 --> 00:13:20,480
they get deleted and cleaned up this

00:13:19,440 --> 00:13:24,079
last box

00:13:20,480 --> 00:13:26,240
on the right for enrichment jobs

00:13:24,079 --> 00:13:27,760
we after we have all this data in the

00:13:26,240 --> 00:13:29,600
graph we can perform

00:13:27,760 --> 00:13:31,440
additional analysis and additional

00:13:29,600 --> 00:13:33,440
enhancements to that data

00:13:31,440 --> 00:13:35,519
and this is another scenario of like why

00:13:33,440 --> 00:13:37,519
it's useful to put this

00:13:35,519 --> 00:13:39,040
and represent the data in the way that

00:13:37,519 --> 00:13:42,720
we have and i'm going to show you

00:13:39,040 --> 00:13:45,519
uh what this looks like right now so

00:13:42,720 --> 00:13:46,240
we want a compelling scenario is is my

00:13:45,519 --> 00:13:48,720
compute

00:13:46,240 --> 00:13:50,000
instance open to the internet we've just

00:13:48,720 --> 00:13:51,839
run our

00:13:50,000 --> 00:13:53,040
cartography sync we've got all these

00:13:51,839 --> 00:13:55,680
nodes in the graph

00:13:53,040 --> 00:13:58,079
what can we do with all this data can we

00:13:55,680 --> 00:14:00,959
exploit it can we make use of it in a

00:13:58,079 --> 00:14:02,320
you know in a more intuitive way yeah so

00:14:00,959 --> 00:14:05,279
i want to answer this question

00:14:02,320 --> 00:14:07,199
is this ec2 instance at the bottom

00:14:05,279 --> 00:14:09,360
left-hand corner of your screen here

00:14:07,199 --> 00:14:11,440
is it open to the internet given all of

00:14:09,360 --> 00:14:12,480
the relationships that are available to

00:14:11,440 --> 00:14:15,040
it in the graph

00:14:12,480 --> 00:14:15,519
so if you look at the top we have an ip

00:14:15,040 --> 00:14:17,760
range

00:14:15,519 --> 00:14:18,560
representing the whole internet zero

00:14:17,760 --> 00:14:22,720
zero zero

00:14:18,560 --> 00:14:24,240
slash zero so we can ask ourselves by

00:14:22,720 --> 00:14:27,760
starting to form this

00:14:24,240 --> 00:14:30,480
query using cipher query language and so

00:14:27,760 --> 00:14:33,920
we say that okay is let's draw a path

00:14:30,480 --> 00:14:37,600
from an ip range with the zero subnet

00:14:33,920 --> 00:14:38,160
and connect it to aws ip permission

00:14:37,600 --> 00:14:42,160
inbound

00:14:38,160 --> 00:14:45,440
rules ip rules do any of those ip rules

00:14:42,160 --> 00:14:46,320
map back to an existing ec2 security

00:14:45,440 --> 00:14:48,959
group

00:14:46,320 --> 00:14:50,639
if so let's let's keep going let's keep

00:14:48,959 --> 00:14:51,120
drawing this path let's build on this

00:14:50,639 --> 00:14:54,560
query

00:14:51,120 --> 00:14:56,320
so from an ec2 security group can i map

00:14:54,560 --> 00:15:01,360
that back to a network interface

00:14:56,320 --> 00:15:04,560
and map it back to a amazon ec2 instance

00:15:01,360 --> 00:15:07,199
if so if this path matches

00:15:04,560 --> 00:15:08,720
let's set exposed internet on that

00:15:07,199 --> 00:15:11,600
instance to true

00:15:08,720 --> 00:15:12,639
this way what we can do later on is we

00:15:11,600 --> 00:15:15,519
can query

00:15:12,639 --> 00:15:15,839
this we can query for all ec2 instances

00:15:15,519 --> 00:15:18,399
that

00:15:15,839 --> 00:15:19,760
have this exposed internet true label

00:15:18,399 --> 00:15:22,000
without needing to do

00:15:19,760 --> 00:15:22,880
this long query that i showed you right

00:15:22,000 --> 00:15:24,800
here

00:15:22,880 --> 00:15:26,000
needing to go through this entire path

00:15:24,800 --> 00:15:28,240
traversal and

00:15:26,000 --> 00:15:29,120
so you know it's easy to so what you're

00:15:28,240 --> 00:15:32,240
able to do with

00:15:29,120 --> 00:15:34,399
our platform is come up with your own

00:15:32,240 --> 00:15:35,759
enhancements come up with your own

00:15:34,399 --> 00:15:37,839
analysis jobs

00:15:35,759 --> 00:15:41,040
to perform these sorts of shortcuts to

00:15:37,839 --> 00:15:43,600
look at and with that

00:15:41,040 --> 00:15:45,279
i'm going to hand over the mic to marco

00:15:43,600 --> 00:15:48,959
to tell you about a real-life

00:15:45,279 --> 00:15:52,240
deployment hello let me just

00:15:48,959 --> 00:15:56,000
share my screen okay so

00:15:52,240 --> 00:15:59,120
as alex uh was just saying

00:15:56,000 --> 00:16:02,320
staying on top of cloud environments

00:15:59,120 --> 00:16:03,360
is a challenge that many organizations

00:16:02,320 --> 00:16:06,079
face

00:16:03,360 --> 00:16:08,000
i work for a software company building a

00:16:06,079 --> 00:16:09,519
core banking solution in a highly

00:16:08,000 --> 00:16:12,240
regulated environment

00:16:09,519 --> 00:16:13,839
we are also by default a multi-cloud

00:16:12,240 --> 00:16:17,279
native organization

00:16:13,839 --> 00:16:19,360
hence we needed a way to detect identify

00:16:17,279 --> 00:16:21,519
categorize and visualize all the

00:16:19,360 --> 00:16:22,240
different assets we deployed in our

00:16:21,519 --> 00:16:24,720
state

00:16:22,240 --> 00:16:27,440
regardless of the cloud provider news

00:16:24,720 --> 00:16:30,320
whether aws ag or gcp

00:16:27,440 --> 00:16:31,920
here i want to describe briefly the

00:16:30,320 --> 00:16:34,720
process we went through

00:16:31,920 --> 00:16:36,240
to adopt cartography and to find a way

00:16:34,720 --> 00:16:39,519
to effectively use

00:16:36,240 --> 00:16:39,839
and also act upon the data we collected

00:16:39,519 --> 00:16:42,959
with

00:16:39,839 --> 00:16:45,759
it basically we

00:16:42,959 --> 00:16:48,480
started with a very high level overview

00:16:45,759 --> 00:16:50,240
this picture shows our multi-cloud setup

00:16:48,480 --> 00:16:50,880
at a glance this is something we run in

00:16:50,240 --> 00:16:54,800
production

00:16:50,880 --> 00:16:56,639
and is going is up 24 7. uh the bundle

00:16:54,800 --> 00:17:00,240
of cartography and neo4j

00:16:56,639 --> 00:17:02,839
runs in the kubernetes cluster of

00:17:00,240 --> 00:17:04,240
gcp project we dedicate to internal

00:17:02,839 --> 00:17:06,959
tooling and

00:17:04,240 --> 00:17:09,679
from there we instructed cartography to

00:17:06,959 --> 00:17:12,959
pull assets from every gcp project

00:17:09,679 --> 00:17:15,120
and every ws account in our estate to do

00:17:12,959 --> 00:17:16,959
so we had to grant cartography the

00:17:15,120 --> 00:17:19,280
minimum set of permissions

00:17:16,959 --> 00:17:20,400
necessary to pull data without

00:17:19,280 --> 00:17:22,880
introducing risks

00:17:20,400 --> 00:17:23,839
to the infrastructure as we said highly

00:17:22,880 --> 00:17:26,799
regulated

00:17:23,839 --> 00:17:27,679
for ws we use the hub and spock model

00:17:26,799 --> 00:17:30,720
for gcp

00:17:27,679 --> 00:17:34,799
we rely on service accounts at the

00:17:30,720 --> 00:17:37,120
organization level more in detail

00:17:34,799 --> 00:17:38,160
the overall deployment is made of two

00:17:37,120 --> 00:17:40,559
main components

00:17:38,160 --> 00:17:42,480
a stateful set for neo4j and a chrome

00:17:40,559 --> 00:17:45,760
job for cartography

00:17:42,480 --> 00:17:47,600
if we start for neo4j the state stateful

00:17:45,760 --> 00:17:50,480
set is made of two container

00:17:47,600 --> 00:17:52,880
one specific for database itself and one

00:17:50,480 --> 00:17:55,280
dedicated to both to proxy

00:17:52,880 --> 00:17:57,919
which is a reverse proxy that we use to

00:17:55,280 --> 00:18:00,240
integrate with our identity provider

00:17:57,919 --> 00:18:01,600
there are two services exposing the

00:18:00,240 --> 00:18:05,200
relevant courts

00:18:01,600 --> 00:18:07,520
one service for all http based services

00:18:05,200 --> 00:18:10,960
like the neo4j web interface

00:18:07,520 --> 00:18:13,600
and another service the bold service

00:18:10,960 --> 00:18:15,280
for interacting with neo4j

00:18:13,600 --> 00:18:18,400
programmatically for example

00:18:15,280 --> 00:18:21,039
what cartography uses in addition we

00:18:18,400 --> 00:18:23,679
have kubernetes ingress uses an entry

00:18:21,039 --> 00:18:26,720
point for connecting to a database

00:18:23,679 --> 00:18:29,679
and also persistent volumes for

00:18:26,720 --> 00:18:30,240
storing the data of the database and

00:18:29,679 --> 00:18:33,520
also

00:18:30,240 --> 00:18:36,240
we integrated actually volt

00:18:33,520 --> 00:18:38,160
with our gke cluster so to provide

00:18:36,240 --> 00:18:40,799
secrets to the running containers

00:18:38,160 --> 00:18:42,480
for example the neo4j password is stored

00:18:40,799 --> 00:18:45,679
within bold and retrieved

00:18:42,480 --> 00:18:46,720
on time the cartography setup instead is

00:18:45,679 --> 00:18:48,799
more simple

00:18:46,720 --> 00:18:50,400
cartography gets released as a python

00:18:48,799 --> 00:18:52,320
package so it is

00:18:50,400 --> 00:18:55,120
fairly straightforward to containerize

00:18:52,320 --> 00:18:58,160
it we then rely on a chrome job

00:18:55,120 --> 00:18:59,919
which is set to run daily and as before

00:18:58,160 --> 00:19:02,160
we integrated with vault so that

00:18:59,919 --> 00:19:02,559
cartography can fetch credentials for

00:19:02,160 --> 00:19:06,160
both

00:19:02,559 --> 00:19:09,280
aws and gcp at runtime

00:19:06,160 --> 00:19:10,480
so we have our setup with cartography

00:19:09,280 --> 00:19:13,280
running daily and

00:19:10,480 --> 00:19:15,440
pulling assets from all our environments

00:19:13,280 --> 00:19:16,080
and the next thing we wanted to see how

00:19:15,440 --> 00:19:18,799
we could

00:19:16,080 --> 00:19:21,039
put the data collected to work the most

00:19:18,799 --> 00:19:23,200
direct way to interact with this data is

00:19:21,039 --> 00:19:24,160
to connect to the browser built into

00:19:23,200 --> 00:19:26,640
neo4j

00:19:24,160 --> 00:19:28,559
you connect to the ingress and you can

00:19:26,640 --> 00:19:31,200
manually run queries

00:19:28,559 --> 00:19:33,440
although the neo4j browser gives you

00:19:31,200 --> 00:19:34,080
full freedom to perform exploration of

00:19:33,440 --> 00:19:36,400
the data

00:19:34,080 --> 00:19:38,240
and it's quite powerful this method is

00:19:36,400 --> 00:19:40,640
also completely manual

00:19:38,240 --> 00:19:42,559
as you will keep have to manually copy

00:19:40,640 --> 00:19:44,320
paste in queries in the web interface so

00:19:42,559 --> 00:19:47,919
this doesn't scale it's too

00:19:44,320 --> 00:19:50,000
many so we had to change our approach

00:19:47,919 --> 00:19:50,960
we wanted to be able to run queries

00:19:50,000 --> 00:19:54,000
automatically

00:19:50,960 --> 00:19:56,320
against our data set so first we had to

00:19:54,000 --> 00:19:57,440
define a structure format for storing

00:19:56,320 --> 00:20:00,080
these queries

00:19:57,440 --> 00:20:01,600
which allowed allowed us to enrich them

00:20:00,080 --> 00:20:04,240
with metadata

00:20:01,600 --> 00:20:05,360
so we store them in json as a list of

00:20:04,240 --> 00:20:08,559
dictionaries

00:20:05,360 --> 00:20:10,480
where each dictionary is a query

00:20:08,559 --> 00:20:13,360
enriched with metadata we have name

00:20:10,480 --> 00:20:16,559
description tags for easy filtering

00:20:13,360 --> 00:20:18,799
human readable list of fields and that's

00:20:16,559 --> 00:20:20,480
the role metadata enriching the main

00:20:18,799 --> 00:20:23,280
cipher query

00:20:20,480 --> 00:20:24,320
so we defined a custom query format and

00:20:23,280 --> 00:20:27,840
we define

00:20:24,320 --> 00:20:28,880
multiple queries that were important for

00:20:27,840 --> 00:20:31,520
our organization

00:20:28,880 --> 00:20:32,799
like as alex was saying which is it you

00:20:31,520 --> 00:20:35,120
are public to the word

00:20:32,799 --> 00:20:35,840
s3 bucket with anonymous access many

00:20:35,120 --> 00:20:38,320
nayam

00:20:35,840 --> 00:20:41,039
and many more the last piece of the

00:20:38,320 --> 00:20:42,240
puzzle was to find a method for

00:20:41,039 --> 00:20:44,559
empowering people

00:20:42,240 --> 00:20:45,600
and teams to perform analysis of the

00:20:44,559 --> 00:20:48,960
collected data

00:20:45,600 --> 00:20:49,679
on demand what better than jupiter

00:20:48,960 --> 00:20:52,640
notebooks

00:20:49,679 --> 00:20:54,000
they are already heavily used by the

00:20:52,640 --> 00:20:56,640
security community

00:20:54,000 --> 00:20:58,640
for investigation purposes so it felt

00:20:56,640 --> 00:21:00,159
natural to create run books for

00:20:58,640 --> 00:21:03,440
self-service consumption

00:21:00,159 --> 00:21:05,600
data to start we created

00:21:03,440 --> 00:21:06,640
dashboards specific to three main

00:21:05,600 --> 00:21:09,039
domains

00:21:06,640 --> 00:21:09,840
specif one dashboard specific for

00:21:09,039 --> 00:21:12,559
security

00:21:09,840 --> 00:21:13,679
one for generic inventory and one for

00:21:12,559 --> 00:21:16,799
networking

00:21:13,679 --> 00:21:18,799
for both aws and gcp however

00:21:16,799 --> 00:21:20,720
we quickly realized that jupiter

00:21:18,799 --> 00:21:21,600
notebooks on their own were a bit too

00:21:20,720 --> 00:21:24,559
restrictive

00:21:21,600 --> 00:21:26,000
and limited in their capabilities and we

00:21:24,559 --> 00:21:28,480
started looking for

00:21:26,000 --> 00:21:29,760
alternatives which provided better

00:21:28,480 --> 00:21:31,360
integration with the rest of the

00:21:29,760 --> 00:21:34,400
security tools that

00:21:31,360 --> 00:21:38,320
we already used in our organization

00:21:34,400 --> 00:21:41,039
that's why we turn to elasticsearch next

00:21:38,320 --> 00:21:44,080
our security monitoring team already

00:21:41,039 --> 00:21:46,000
made extensive use of the elastic stack

00:21:44,080 --> 00:21:47,919
hence integrating with elasticsearch was

00:21:46,000 --> 00:21:50,799
the most obvious option after

00:21:47,919 --> 00:21:52,159
jupiter notebooks in particular we had

00:21:50,799 --> 00:21:54,799
two main goals in mind

00:21:52,159 --> 00:21:57,360
the first was to provide security

00:21:54,799 --> 00:21:58,720
analysts with a current snapshot of the

00:21:57,360 --> 00:22:01,280
infrastructure

00:21:58,720 --> 00:22:03,200
so that cartography data could enrich

00:22:01,280 --> 00:22:06,000
security investigations

00:22:03,200 --> 00:22:07,280
and the second was to alert on any new

00:22:06,000 --> 00:22:09,440
instance of drift

00:22:07,280 --> 00:22:11,120
since cartography itself can be used to

00:22:09,440 --> 00:22:12,960
detect drift within ephemeral

00:22:11,120 --> 00:22:15,120
environments

00:22:12,960 --> 00:22:17,280
here you can see the high level setup

00:22:15,120 --> 00:22:19,600
you can note at the bottom right corner

00:22:17,280 --> 00:22:21,919
a new aws account

00:22:19,600 --> 00:22:23,679
is a completely different account used

00:22:21,919 --> 00:22:26,320
by monitoring team

00:22:23,679 --> 00:22:28,320
in there we already have elasticsearch

00:22:26,320 --> 00:22:29,280
deployed for all the other security

00:22:28,320 --> 00:22:31,600
logging

00:22:29,280 --> 00:22:33,840
already integrated with the last alert

00:22:31,600 --> 00:22:34,159
which can provide notification to jira

00:22:33,840 --> 00:22:37,440
and

00:22:34,159 --> 00:22:40,000
zlac so what we have to do

00:22:37,440 --> 00:22:41,440
is creating an integration between

00:22:40,000 --> 00:22:44,080
cartography neo4j

00:22:41,440 --> 00:22:45,120
and elasticsearch we created a custom

00:22:44,080 --> 00:22:47,440
ingester

00:22:45,120 --> 00:22:49,760
deployed as a kubernetes chrome job

00:22:47,440 --> 00:22:52,840
which periodically pulls data from the

00:22:49,760 --> 00:22:54,880
neo4j database and forwards them to

00:22:52,840 --> 00:22:56,720
elasticsearch

00:22:54,880 --> 00:22:59,039
with cartography data now getting

00:22:56,720 --> 00:23:01,440
ingested into elasticsearch we were able

00:22:59,039 --> 00:23:02,400
to start using many of the features of

00:23:01,440 --> 00:23:04,720
kibana

00:23:02,400 --> 00:23:07,200
the most direct way again is you can

00:23:04,720 --> 00:23:08,480
start by browsing the discovery section

00:23:07,200 --> 00:23:10,640
of kibana

00:23:08,480 --> 00:23:14,080
which as you can see in the screenshot

00:23:10,640 --> 00:23:16,400
will report data as it gets ingested

00:23:14,080 --> 00:23:18,720
from there we wanted to recreate the

00:23:16,400 --> 00:23:21,440
dashboards we already had in jupiter

00:23:18,720 --> 00:23:23,280
and create more advanced one within

00:23:21,440 --> 00:23:25,360
kibana itself

00:23:23,280 --> 00:23:27,360
to aggregate the wall set of the

00:23:25,360 --> 00:23:28,559
infrastructure and give a quick glance

00:23:27,360 --> 00:23:30,720
of the main

00:23:28,559 --> 00:23:32,559
issues and misconfiguration we had at

00:23:30,720 --> 00:23:35,440
the moment

00:23:32,559 --> 00:23:36,240
we ended up creating one kibana

00:23:35,440 --> 00:23:38,240
visualization

00:23:36,240 --> 00:23:39,600
for each one of the custom cartography

00:23:38,240 --> 00:23:43,120
queries we created

00:23:39,600 --> 00:23:43,679
around 125. they're all open source of

00:23:43,120 --> 00:23:47,360
course

00:23:43,679 --> 00:23:49,919
like cartography and then we went to

00:23:47,360 --> 00:23:51,840
create aggregate these queries these

00:23:49,919 --> 00:23:54,320
visualizations into dashboards

00:23:51,840 --> 00:23:56,240
again starting from one specific for

00:23:54,320 --> 00:23:57,200
security one for inventory and one for

00:23:56,240 --> 00:23:59,200
networking

00:23:57,200 --> 00:24:00,640
and then also what we can do with

00:23:59,200 --> 00:24:03,919
elastic is to

00:24:00,640 --> 00:24:06,080
show trends over time but also not even

00:24:03,919 --> 00:24:06,880
also security related we can provide

00:24:06,080 --> 00:24:09,679
data to

00:24:06,880 --> 00:24:10,559
other teams like sres to see what kind

00:24:09,679 --> 00:24:12,640
of emis

00:24:10,559 --> 00:24:15,360
we are using different accounts and

00:24:12,640 --> 00:24:18,559
provide a history of how the accounts

00:24:15,360 --> 00:24:19,360
are working these nuptials show an

00:24:18,559 --> 00:24:21,360
excerpt

00:24:19,360 --> 00:24:22,640
of some of these dashboards on some test

00:24:21,360 --> 00:24:24,640
data as you can

00:24:22,640 --> 00:24:26,000
as you can see from these screenshots

00:24:24,640 --> 00:24:28,320
kibana dashboards are

00:24:26,000 --> 00:24:30,240
perfect to provide snapshots of the

00:24:28,320 --> 00:24:33,279
current state it's easy to see

00:24:30,240 --> 00:24:35,679
how does the environment look like today

00:24:33,279 --> 00:24:36,799
and these visualizations can help to

00:24:35,679 --> 00:24:39,360
quickly identify

00:24:36,799 --> 00:24:40,720
specific misconfiguration you can create

00:24:39,360 --> 00:24:43,039
a table to show

00:24:40,720 --> 00:24:44,559
all the cto exposed to the internet

00:24:43,039 --> 00:24:47,360
which is easy to see

00:24:44,559 --> 00:24:48,320
however uh this entire interaction was

00:24:47,360 --> 00:24:51,520
still heavier

00:24:48,320 --> 00:24:53,360
on manual involvement and

00:24:51,520 --> 00:24:55,360
lacks the automation needed to be more

00:24:53,360 --> 00:24:57,679
proactive in remediating

00:24:55,360 --> 00:24:59,200
any potential of this configuration uh

00:24:57,679 --> 00:25:01,120
analyst still needs to

00:24:59,200 --> 00:25:03,200
go log into elasticsearch and look at

00:25:01,120 --> 00:25:05,440
this dashboard we wanted something even

00:25:03,200 --> 00:25:08,559
more automated

00:25:05,440 --> 00:25:10,240
that's why once in elasticsearch we had

00:25:08,559 --> 00:25:12,240
the chance to leverage

00:25:10,240 --> 00:25:14,559
further integrations with tools like

00:25:12,240 --> 00:25:17,679
last alert as we were seeing before

00:25:14,559 --> 00:25:18,080
so we defined the last alert rules so

00:25:17,679 --> 00:25:20,400
that

00:25:18,080 --> 00:25:21,679
we can get notified in slack for any

00:25:20,400 --> 00:25:25,360
misconfiguration

00:25:21,679 --> 00:25:26,720
and or drift so for every new entry in

00:25:25,360 --> 00:25:28,640
any of the dashboards

00:25:26,720 --> 00:25:30,240
especially for the most critical ones we

00:25:28,640 --> 00:25:33,600
also get an alert

00:25:30,240 --> 00:25:36,240
on slack so we can go and investigate

00:25:33,600 --> 00:25:36,640
a question that someone might ask would

00:25:36,240 --> 00:25:38,799
be

00:25:36,640 --> 00:25:40,559
many companies are shifting to

00:25:38,799 --> 00:25:41,600
infrastructure as code and they're using

00:25:40,559 --> 00:25:44,480
terraform

00:25:41,600 --> 00:25:45,440
so why using cartography data to perform

00:25:44,480 --> 00:25:48,320
drift detection

00:25:45,440 --> 00:25:49,200
rather than terraform itself well

00:25:48,320 --> 00:25:51,200
terraform

00:25:49,200 --> 00:25:52,400
provides drift detection capabilities

00:25:51,200 --> 00:25:55,120
out of the box

00:25:52,400 --> 00:25:56,000
and are excellent in detecting drift for

00:25:55,120 --> 00:25:58,720
resources

00:25:56,000 --> 00:26:00,880
managed by terraform itself what

00:25:58,720 --> 00:26:02,880
terraform lacks is support for

00:26:00,880 --> 00:26:04,640
any other resource that might have been

00:26:02,880 --> 00:26:06,960
created with other means like the

00:26:04,640 --> 00:26:08,559
console or via the command line

00:26:06,960 --> 00:26:10,000
so that's why we decided to use

00:26:08,559 --> 00:26:12,559
cartography as

00:26:10,000 --> 00:26:13,120
a complement also for terraform drift so

00:26:12,559 --> 00:26:14,960
to catch

00:26:13,120 --> 00:26:17,360
everything that could be created

00:26:14,960 --> 00:26:19,120
regardless of the source

00:26:17,360 --> 00:26:20,880
and that's our journey so far we also

00:26:19,120 --> 00:26:21,919
plan to integrate with many other

00:26:20,880 --> 00:26:24,080
providers that

00:26:21,919 --> 00:26:25,039
alex was talking about like g suite and

00:26:24,080 --> 00:26:28,480
others

00:26:25,039 --> 00:26:28,480
but back to alex now

00:26:28,960 --> 00:26:32,400
thank you very much marco and i'd like

00:26:31,279 --> 00:26:36,159
to talk about

00:26:32,400 --> 00:26:37,679
what plans we have next on cartography

00:26:36,159 --> 00:26:39,279
the first thing that we would like the

00:26:37,679 --> 00:26:40,080
first big improvement we would like to

00:26:39,279 --> 00:26:43,200
bring back to

00:26:40,080 --> 00:26:46,320
cartography is to have a dag based

00:26:43,200 --> 00:26:48,880
data sync a directed acyclic graph

00:26:46,320 --> 00:26:51,279
data sync so that our data sync is more

00:26:48,880 --> 00:26:52,000
reliable and that if one sync fails then

00:26:51,279 --> 00:26:55,039
it doesn't fail

00:26:52,000 --> 00:26:56,000
the entire rest of your data sync we

00:26:55,039 --> 00:26:58,640
would also like

00:26:56,000 --> 00:26:59,039
a nicer plug-in framework i mentioned

00:26:58,640 --> 00:27:02,000
that

00:26:59,039 --> 00:27:03,679
we have a very extensible way of adding

00:27:02,000 --> 00:27:04,799
your own context and adding new data

00:27:03,679 --> 00:27:06,720
modules

00:27:04,799 --> 00:27:08,240
that that said you know we there are

00:27:06,720 --> 00:27:09,679
improvements to be made there we would

00:27:08,240 --> 00:27:12,960
like to make this process

00:27:09,679 --> 00:27:16,159
even easier for new developers to get

00:27:12,960 --> 00:27:18,399
introduced to our platform we would also

00:27:16,159 --> 00:27:19,360
or we also are working on near real-time

00:27:18,399 --> 00:27:22,320
updates

00:27:19,360 --> 00:27:23,840
so i mentioned earlier that the main

00:27:22,320 --> 00:27:27,279
cartography sync works

00:27:23,840 --> 00:27:29,360
as a job that pulls in all assets from

00:27:27,279 --> 00:27:31,600
multiple sources and then wipes away

00:27:29,360 --> 00:27:32,480
the previous state anything that is not

00:27:31,600 --> 00:27:36,000
there

00:27:32,480 --> 00:27:36,320
this is slow and so the thing that we

00:27:36,000 --> 00:27:38,240
would

00:27:36,320 --> 00:27:39,440
uh we the an area that we see

00:27:38,240 --> 00:27:42,320
improvement on

00:27:39,440 --> 00:27:44,080
is being able to stream consume a stream

00:27:42,320 --> 00:27:47,200
of something

00:27:44,080 --> 00:27:50,320
perhaps like aws cloudtrail and others a

00:27:47,200 --> 00:27:52,960
similar providers and then put in those

00:27:50,320 --> 00:27:54,080
changes little by little instead of in

00:27:52,960 --> 00:27:56,000
batch all at once

00:27:54,080 --> 00:27:57,279
so just some couple of ideas we are

00:27:56,000 --> 00:28:00,399
exploring there

00:27:57,279 --> 00:28:02,159
and as always we are adding more data

00:28:00,399 --> 00:28:03,120
types to the graph because having more

00:28:02,159 --> 00:28:06,240
data makes

00:28:03,120 --> 00:28:08,559
things well the more the merrier right

00:28:06,240 --> 00:28:10,320
the more context you can throw at this

00:28:08,559 --> 00:28:12,799
the more powerful your graph

00:28:10,320 --> 00:28:12,799
can be

00:28:14,640 --> 00:28:19,840
so with that i would like to you know

00:28:18,320 --> 00:28:21,840
end with my call to action go get

00:28:19,840 --> 00:28:23,360
started please go play with your own

00:28:21,840 --> 00:28:26,880
graph check out our tool

00:28:23,360 --> 00:28:28,799
at github.com cartography

00:28:26,880 --> 00:28:30,960
join our community say hi on slack

00:28:28,799 --> 00:28:33,919
participate in our monthly

00:28:30,960 --> 00:28:35,679
video discussion tell us how to be

00:28:33,919 --> 00:28:38,640
useful for you your opinion

00:28:35,679 --> 00:28:39,039
matters we are absolutely thrilled to be

00:28:38,640 --> 00:28:42,559
here

00:28:39,039 --> 00:28:44,640
at cloud native security day our goal

00:28:42,559 --> 00:28:45,760
is to grow and improve the project to

00:28:44,640 --> 00:28:47,520
meet that bar

00:28:45,760 --> 00:28:49,039
for high quality open source security

00:28:47,520 --> 00:28:52,080
tools and we want to

00:28:49,039 --> 00:28:53,200
continually make this problem we want to

00:28:52,080 --> 00:28:56,320
continually improve

00:28:53,200 --> 00:28:58,159
this project so with that thank you very

00:28:56,320 --> 00:29:01,200
much for your time here today

00:28:58,159 --> 00:29:02,000
and we hope to say hi to you um directly

00:29:01,200 --> 00:29:07,760
on slack or

00:29:02,000 --> 00:29:07,760

YouTube URL: https://www.youtube.com/watch?v=ZwMSkFzgiFc


