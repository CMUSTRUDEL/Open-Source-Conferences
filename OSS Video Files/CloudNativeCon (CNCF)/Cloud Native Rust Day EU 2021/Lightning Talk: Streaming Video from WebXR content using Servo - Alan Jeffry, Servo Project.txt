Title: Lightning Talk: Streaming Video from WebXR content using Servo - Alan Jeffry, Servo Project
Publication date: 2021-05-03
Playlist: Cloud Native Rust Day EU 2021
Description: 
	Donâ€™t miss out! Join us at our upcoming event: KubeCon + CloudNativeCon North America 2021 in Los Angeles, CA from October 12-15. Learn more at https://kubecon.io The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.

Lightning Talk: Streaming Video from WebXR content using Servo - Alan Jeffry, Servo Project

Servo is an embeddable web engine written in Rust, which for a long time was The Other Big Rust Program. One of the strengths of Servo is its ability to deliver immersive content using WebXR and WebGL. This talk introduces the Servo GStreamer plugin, which allows web content to be streamed to low-end devices, including streaming 360 video from WebXR content.
Captions: 
	00:00:00,080 --> 00:00:03,360
hi there my name is alan jeffrey and i'm

00:00:02,480 --> 00:00:06,319
the

00:00:03,360 --> 00:00:08,240
technical chair of the servo project and

00:00:06,319 --> 00:00:10,320
i'm here today to talk about one of the

00:00:08,240 --> 00:00:13,360
applications of servo

00:00:10,320 --> 00:00:18,320
which is in streaming video using g

00:00:13,360 --> 00:00:21,760
streamer um from web xlr content

00:00:18,320 --> 00:00:22,400
so what is servo well servo's a browser

00:00:21,760 --> 00:00:24,800
engine

00:00:22,400 --> 00:00:26,080
and so that's the core of a web browser

00:00:24,800 --> 00:00:29,519
that's responsible for

00:00:26,080 --> 00:00:32,640
downloading content off of the internet

00:00:29,519 --> 00:00:34,559
and then displaying it to the user and

00:00:32,640 --> 00:00:37,200
traditionally this has been part of the

00:00:34,559 --> 00:00:40,719
2d web using standards such as

00:00:37,200 --> 00:00:44,000
html or css or javascript

00:00:40,719 --> 00:00:48,160
our old friends and more recently though

00:00:44,000 --> 00:00:51,600
there's been efforts to allow 3d content

00:00:48,160 --> 00:00:52,079
um to be displayed using standards such

00:00:51,600 --> 00:00:55,280
as

00:00:52,079 --> 00:00:58,719
webgl and webxr

00:00:55,280 --> 00:01:01,920
and so servo was originally developed by

00:00:58,719 --> 00:01:03,039
mozilla um and is now part of the linux

00:01:01,920 --> 00:01:06,000
foundation

00:01:03,039 --> 00:01:07,760
um and the original motivation for for a

00:01:06,000 --> 00:01:11,680
survey was could twofold

00:01:07,760 --> 00:01:14,400
so one of which was finding out whether

00:01:11,680 --> 00:01:16,560
components could be developed in rust

00:01:14,400 --> 00:01:19,520
and and then deployed in florifox

00:01:16,560 --> 00:01:23,280
and the other ways to experiment with

00:01:19,520 --> 00:01:24,960
and newer web technologies such as webxr

00:01:23,280 --> 00:01:27,920
and the experiment of developing web

00:01:24,960 --> 00:01:30,240
components using rust is very successful

00:01:27,920 --> 00:01:31,040
and so technologies got transferred out

00:01:30,240 --> 00:01:34,720
of servo

00:01:31,040 --> 00:01:37,680
and into firefox such as the stylo css

00:01:34,720 --> 00:01:38,799
engine and the web renderer graphics

00:01:37,680 --> 00:01:41,680
backend

00:01:38,799 --> 00:01:44,560
and but also my server like i said was

00:01:41,680 --> 00:01:47,200
being used as an experimental platform

00:01:44,560 --> 00:01:47,600
um for finding out what you could do

00:01:47,200 --> 00:01:50,720
with

00:01:47,600 --> 00:01:53,360
an embeddable uh web engine um

00:01:50,720 --> 00:01:54,000
and what kinds of experiences this would

00:01:53,360 --> 00:01:55,759
enable

00:01:54,000 --> 00:01:57,119
and i'm going to be talking about one of

00:01:55,759 --> 00:01:58,960
those today

00:01:57,119 --> 00:02:00,560
so the next bit of the technology stack

00:01:58,960 --> 00:02:03,280
that we need to look at today

00:02:00,560 --> 00:02:04,960
is gstreamer so g streamer is a

00:02:03,280 --> 00:02:07,840
streaming media

00:02:04,960 --> 00:02:08,399
plugin architecture and where plugins

00:02:07,840 --> 00:02:11,680
can be

00:02:08,399 --> 00:02:14,800
sources um for video or audio

00:02:11,680 --> 00:02:17,920
uh filters such as transcoders um

00:02:14,800 --> 00:02:21,280
or syncs and such as your file system or

00:02:17,920 --> 00:02:23,440
streaming over the internet um and

00:02:21,280 --> 00:02:24,879
the way that content providers use g

00:02:23,440 --> 00:02:28,800
streamer is by

00:02:24,879 --> 00:02:31,440
stringing together um these uh plugins

00:02:28,800 --> 00:02:32,560
into a pipeline where media is consumed

00:02:31,440 --> 00:02:35,040
at one end is them

00:02:32,560 --> 00:02:37,200
formed by various filters and then is

00:02:35,040 --> 00:02:38,640
produced and in a sync

00:02:37,200 --> 00:02:40,560
um and one of the things that's

00:02:38,640 --> 00:02:41,280
interesting about g streamer from our

00:02:40,560 --> 00:02:44,400
point of view

00:02:41,280 --> 00:02:45,760
is that it has quite strong connections

00:02:44,400 --> 00:02:48,239
into the rust world

00:02:45,760 --> 00:02:50,080
um so there are rough bindings um for

00:02:48,239 --> 00:02:53,840
all of the g streamer apis

00:02:50,080 --> 00:02:57,840
and and also uh it's possible to develop

00:02:53,840 --> 00:03:00,480
um g streamer plugins using rust

00:02:57,840 --> 00:03:03,760
um and that's very useful for servo and

00:03:00,480 --> 00:03:06,800
which is primarily implemented in

00:03:03,760 --> 00:03:10,239
and gstreamer is used inside servo

00:03:06,800 --> 00:03:11,920
as the media subsystem but that's not

00:03:10,239 --> 00:03:14,800
actually what we're looking at today

00:03:11,920 --> 00:03:16,080
what we're looking today is using servo

00:03:14,800 --> 00:03:18,959
to provide

00:03:16,080 --> 00:03:20,879
um a source so servo is designed to be

00:03:18,959 --> 00:03:23,440
an embeddable web engine and

00:03:20,879 --> 00:03:26,000
one of the places we've embedded um is

00:03:23,440 --> 00:03:26,879
into gstreamer so there's a servo source

00:03:26,000 --> 00:03:29,920
plug-in

00:03:26,879 --> 00:03:32,959
and that you can use to take web content

00:03:29,920 --> 00:03:36,159
and put it into a juice tumor pipeline

00:03:32,959 --> 00:03:39,760
so for example you could use this to

00:03:36,159 --> 00:03:42,720
lay out the title sequence for a video

00:03:39,760 --> 00:03:44,480
using html and css and then use the

00:03:42,720 --> 00:03:46,319
server source plugin

00:03:44,480 --> 00:03:47,680
to produce that as part of your g

00:03:46,319 --> 00:03:49,440
streamer pipeline

00:03:47,680 --> 00:03:52,239
and one of the nice features about this

00:03:49,440 --> 00:03:53,040
plugin um is that it's entirely using gl

00:03:52,239 --> 00:03:55,280
memory

00:03:53,040 --> 00:03:56,239
so if the rest of your pipeline supports

00:03:55,280 --> 00:03:58,720
gl memory

00:03:56,239 --> 00:04:00,000
this means that the video content never

00:03:58,720 --> 00:04:02,159
actually has to be

00:04:00,000 --> 00:04:05,760
in the main memory of your machine and

00:04:02,159 --> 00:04:07,680
can instead reside entirely on the gpu

00:04:05,760 --> 00:04:08,879
and if you're familiar with the webcam

00:04:07,680 --> 00:04:12,159
embedding into

00:04:08,879 --> 00:04:14,239
gstream or the wpe plugin and this is

00:04:12,159 --> 00:04:16,880
doing a very similar job for

00:04:14,239 --> 00:04:17,759
server and like i said you can use this

00:04:16,880 --> 00:04:21,120
to

00:04:17,759 --> 00:04:23,759
render traditional 2d content um

00:04:21,120 --> 00:04:24,880
into a g-stream or pipeline but you can

00:04:23,759 --> 00:04:28,320
also use it

00:04:24,880 --> 00:04:31,520
to render webex so webxr is the w3c

00:04:28,320 --> 00:04:32,880
api for developing virtual reality and

00:04:31,520 --> 00:04:36,160
augmented reality

00:04:32,880 --> 00:04:38,400
applications uh using web technologies

00:04:36,160 --> 00:04:40,240
and these can be both 2d experiences

00:04:38,400 --> 00:04:42,320
such as holding a phone up

00:04:40,240 --> 00:04:43,440
and seeing a virtual object in your

00:04:42,320 --> 00:04:46,720
living room

00:04:43,440 --> 00:04:48,960
and immersive 3d experiences for users

00:04:46,720 --> 00:04:51,759
wearing appropriate headsets

00:04:48,960 --> 00:04:54,320
and for servo we've got a web xr

00:04:51,759 --> 00:04:57,759
implementation with back ends

00:04:54,320 --> 00:05:00,560
for both the hololens um

00:04:57,759 --> 00:05:02,240
and the magic leap um augmented reality

00:05:00,560 --> 00:05:04,479
headset

00:05:02,240 --> 00:05:06,320
and as part of that uh the servo

00:05:04,479 --> 00:05:09,919
development team was quite actively

00:05:06,320 --> 00:05:10,479
involved with the w3c standards effort

00:05:09,919 --> 00:05:12,400
so

00:05:10,479 --> 00:05:13,520
plugging these three technologies

00:05:12,400 --> 00:05:16,960
together so

00:05:13,520 --> 00:05:18,000
webex are server and g-streamer and this

00:05:16,960 --> 00:05:21,039
means we can take

00:05:18,000 --> 00:05:23,840
web xlr experiences um and

00:05:21,039 --> 00:05:25,039
put them into a g-stream of pipeline and

00:05:23,840 --> 00:05:27,440
this means you can do

00:05:25,039 --> 00:05:28,560
interesting things that i don't think

00:05:27,440 --> 00:05:31,360
the um

00:05:28,560 --> 00:05:32,240
authors of the web xr experiences um

00:05:31,360 --> 00:05:35,199
intended

00:05:32,240 --> 00:05:36,479
so for example we've got a back end for

00:05:35,199 --> 00:05:40,240
servo

00:05:36,479 --> 00:05:43,280
the renders to red cyan

00:05:40,240 --> 00:05:46,800
uh 3d so if you put on your

00:05:43,280 --> 00:05:47,759
uh red blue glasses and you can actually

00:05:46,800 --> 00:05:50,960
then watch

00:05:47,759 --> 00:05:52,000
a 3d experience at home without a

00:05:50,960 --> 00:05:55,840
headset

00:05:52,000 --> 00:05:59,360
um or a we've also got

00:05:55,840 --> 00:06:00,080
a another back end and the renders

00:05:59,360 --> 00:06:02,720
rather than

00:06:00,080 --> 00:06:03,520
rendering stereoscopic views of the 3d

00:06:02,720 --> 00:06:06,000
scene

00:06:03,520 --> 00:06:06,720
which you would for a headset um we

00:06:06,000 --> 00:06:10,479
render

00:06:06,720 --> 00:06:12,400
uh six views of the scene to a cube map

00:06:10,479 --> 00:06:13,840
and then we take that cube map and we

00:06:12,400 --> 00:06:16,160
project it into

00:06:13,840 --> 00:06:18,319
360 video and so this means we have the

00:06:16,160 --> 00:06:22,400
ability to record

00:06:18,319 --> 00:06:22,960
360 video out of an arbitrary web xor

00:06:22,400 --> 00:06:24,960
scene

00:06:22,960 --> 00:06:27,600
and as long as that scene hasn't

00:06:24,960 --> 00:06:29,280
hardwired the idea that people only have

00:06:27,600 --> 00:06:32,319
two eyes

00:06:29,280 --> 00:06:35,280
um so we've been able to

00:06:32,319 --> 00:06:36,400
take webex our content and that was

00:06:35,280 --> 00:06:39,199
intended for

00:06:36,400 --> 00:06:40,479
viewing a headset um and we've now

00:06:39,199 --> 00:06:43,680
managed to actually

00:06:40,479 --> 00:06:45,680
reuse it um for in scenarios that the

00:06:43,680 --> 00:06:46,639
original authors didn't intend and this

00:06:45,680 --> 00:06:49,120
is part of

00:06:46,639 --> 00:06:50,960
the philosophy of the web is that it

00:06:49,120 --> 00:07:03,840
should support this kind of

00:06:50,960 --> 00:07:03,840
accidental reuse

00:07:05,039 --> 00:07:07,120

YouTube URL: https://www.youtube.com/watch?v=fUZyJvx82o0


