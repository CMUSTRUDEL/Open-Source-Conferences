Title: Deep Dive: Kubernetes SIG Storage - Xing Yang, VMware & Michelle Au, Google
Publication date: 2020-09-11
Playlist: Cloud Native + Open Source Virtual Summit China 2020
Description: 
	Don’t miss out! Join us at our upcoming events: EnvoyCon Virtual on October 15 and KubeCon + CloudNativeCon North America 2020 Virtual from November 17-20. Learn more at https://kubecon.io The conferences feature presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects. 

Deep Dive: Kubernetes SIG Storage - Xing Yang, VMware & Michelle Au, Google 

Kubernetes SIG Storage is responsible for ensuring that different types of file and block storage are available wherever a container is scheduled, storage capacity management (container ephemeral storage usage, volume resizing, etc.), influencing scheduling of containers based on storage (data gravity, availability, etc.), and generic operations on storage (snapshotting, etc.). In this session, we will deep dive into some projects that SIG Storage is currently working on, provide an update on the current status, and discuss what might be coming in the future. 

https://sched.co/cpBN
Captions: 
	00:00:03,040 --> 00:00:07,520
hello everyone

00:00:04,640 --> 00:00:09,360
today michelle and i will be giving a

00:00:07,520 --> 00:00:12,080
deep dive on kubernetes

00:00:09,360 --> 00:00:12,080
seek storage

00:00:14,320 --> 00:00:17,600
here are the six storage leads my name

00:00:17,359 --> 00:00:21,119
is

00:00:17,600 --> 00:00:24,080
xin yang i work for vmware in the

00:00:21,119 --> 00:00:24,880
cloud storage team i'm a co-chair of

00:00:24,080 --> 00:00:30,720
seek storage

00:00:24,880 --> 00:00:32,000
along with sadali from google and uh my

00:00:30,720 --> 00:00:35,120
name is michelle oh

00:00:32,000 --> 00:00:37,920
i am a engineer at google um

00:00:35,120 --> 00:00:39,520
working on kubernetes storage um i am

00:00:37,920 --> 00:00:45,360
one of the tech leads

00:00:39,520 --> 00:00:48,719
along with uh jan from red hat

00:00:45,360 --> 00:00:51,840
here is today's agenda first

00:00:48,719 --> 00:00:54,239
we will talk about what is six storage

00:00:51,840 --> 00:00:56,160
we will talk about what we have done in

00:00:54,239 --> 00:00:59,600
the 1.80 release

00:00:56,160 --> 00:01:02,079
and what is coming in 1.19 release

00:00:59,600 --> 00:01:03,440
and we will talk about our future plans

00:01:02,079 --> 00:01:07,040
what we will be working on

00:01:03,440 --> 00:01:12,320
after 2019 and how to get involved

00:01:07,040 --> 00:01:16,159
with the sig storage so

00:01:12,320 --> 00:01:18,799
what is six storage six storage

00:01:16,159 --> 00:01:20,799
is a special interest group that focuses

00:01:18,799 --> 00:01:23,680
on how to provide storage

00:01:20,799 --> 00:01:24,799
to parts in your kubernetes cluster

00:01:23,680 --> 00:01:28,240
seeker storage

00:01:24,799 --> 00:01:30,640
scope is in the storage control plane

00:01:28,240 --> 00:01:31,280
it provides a way for containers in the

00:01:30,640 --> 00:01:34,479
pods

00:01:31,280 --> 00:01:35,840
to consume block of file storage this

00:01:34,479 --> 00:01:38,640
can be persistent

00:01:35,840 --> 00:01:39,200
long-term storage that leaves beyond a

00:01:38,640 --> 00:01:42,640
paws

00:01:39,200 --> 00:01:45,280
life cycle or it can be effemoral

00:01:42,640 --> 00:01:46,000
temporary storage which becomes

00:01:45,280 --> 00:01:48,880
available

00:01:46,000 --> 00:01:51,280
when the pot is started and goes away

00:01:48,880 --> 00:01:53,840
when the pot goes down

00:01:51,280 --> 00:01:54,320
seek storage is responsible for the life

00:01:53,840 --> 00:01:57,200
cycle

00:01:54,320 --> 00:01:57,840
of volumes used by the pots this

00:01:57,200 --> 00:02:00,719
includes

00:01:57,840 --> 00:02:02,399
provisioning a new volume attaching a

00:02:00,719 --> 00:02:05,520
volume to the node

00:02:02,399 --> 00:02:06,399
and mounting it so that the pod can use

00:02:05,520 --> 00:02:08,640
it

00:02:06,399 --> 00:02:10,640
our mounting detaching and deleting the

00:02:08,640 --> 00:02:13,760
volume when it is no longer

00:02:10,640 --> 00:02:15,840
needed taking snapshots so that it can

00:02:13,760 --> 00:02:18,080
be used to restore the volume

00:02:15,840 --> 00:02:19,920
if the original volume is corrupted for

00:02:18,080 --> 00:02:22,800
some reason

00:02:19,920 --> 00:02:23,440
sig storage also looks at how to

00:02:22,800 --> 00:02:25,680
influence

00:02:23,440 --> 00:02:27,599
the scheduling decisions based on

00:02:25,680 --> 00:02:30,000
topology information

00:02:27,599 --> 00:02:31,360
to see whether the storage is accessible

00:02:30,000 --> 00:02:34,000
to a node

00:02:31,360 --> 00:02:34,640
and make sure volume is scheduled to a

00:02:34,000 --> 00:02:38,480
node

00:02:34,640 --> 00:02:41,440
which can have access to the storage

00:02:38,480 --> 00:02:42,239
also seek storage is responsible for

00:02:41,440 --> 00:02:45,120
managing

00:02:42,239 --> 00:02:45,920
storage capacities managing quota

00:02:45,120 --> 00:02:48,840
resources

00:02:45,920 --> 00:02:50,560
based on capacities or number of

00:02:48,840 --> 00:02:53,680
resources

00:02:50,560 --> 00:02:57,599
and provides ability to expand volume

00:02:53,680 --> 00:02:57,599
if volume runs out of space

00:03:00,959 --> 00:03:07,200
sig storage owns the persistent volume

00:03:04,319 --> 00:03:10,080
and persistent volume claim feature this

00:03:07,200 --> 00:03:13,200
allows sturdy vendor to create a volume

00:03:10,080 --> 00:03:14,239
and persist storage persistent data in

00:03:13,200 --> 00:03:17,280
this volume

00:03:14,239 --> 00:03:20,239
which can be preserved even if the pod

00:03:17,280 --> 00:03:21,360
goes away we have the study class

00:03:20,239 --> 00:03:23,680
concept

00:03:21,360 --> 00:03:25,440
a story class provides a way for

00:03:23,680 --> 00:03:28,319
administrators to

00:03:25,440 --> 00:03:29,280
describe the classes of storage they

00:03:28,319 --> 00:03:31,840
offer

00:03:29,280 --> 00:03:32,319
different study classes might map to

00:03:31,840 --> 00:03:35,440
different

00:03:32,319 --> 00:03:37,200
quality of service levels of the storage

00:03:35,440 --> 00:03:39,599
system

00:03:37,200 --> 00:03:41,120
in dynamic provisioning strategy class

00:03:39,599 --> 00:03:44,000
is used to find out

00:03:41,120 --> 00:03:46,159
which provisioner should be used and

00:03:44,000 --> 00:03:46,879
what parameters should be passed to the

00:03:46,159 --> 00:03:50,319
provisioner

00:03:46,879 --> 00:03:51,360
when creating the volume kubernetes

00:03:50,319 --> 00:03:54,640
volume plugins

00:03:51,360 --> 00:03:55,200
include in-sheet plugins auto-tree flex

00:03:54,640 --> 00:03:58,720
volume

00:03:55,200 --> 00:04:00,959
and csi drivers the kubernetes

00:03:58,720 --> 00:04:02,640
implementation of the container storage

00:04:00,959 --> 00:04:05,519
interface csi

00:04:02,640 --> 00:04:07,280
has been ga since the kubernetes 1.13

00:04:05,519 --> 00:04:08,959
release

00:04:07,280 --> 00:04:11,280
sig storage has been working on

00:04:08,959 --> 00:04:11,760
migrating from injury plugins to out of

00:04:11,280 --> 00:04:15,200
three

00:04:11,760 --> 00:04:18,400
csr drivers new features

00:04:15,200 --> 00:04:21,919
are only added to the csr drivers

00:04:18,400 --> 00:04:23,759
csi is supported by multiple container

00:04:21,919 --> 00:04:27,199
orchestration systems

00:04:23,759 --> 00:04:28,639
and storage vendors it is designed to be

00:04:27,199 --> 00:04:31,759
vendor neutral

00:04:28,639 --> 00:04:35,199
interoperable and has a focus on

00:04:31,759 --> 00:04:37,759
specification it defines a set of

00:04:35,199 --> 00:04:39,840
storage interfaces so that a storage

00:04:37,759 --> 00:04:41,919
vendor can write one plugin

00:04:39,840 --> 00:04:45,440
and have it work across a range of

00:04:41,919 --> 00:04:47,360
container orchestration systems

00:04:45,440 --> 00:04:49,600
other than persistent volumes there are

00:04:47,360 --> 00:04:53,440
also ephemeral volumes

00:04:49,600 --> 00:04:56,880
effemoral volumes are specified

00:04:53,440 --> 00:04:57,440
directly in a pod spec it's mounted on

00:04:56,880 --> 00:05:00,320
the part

00:04:57,440 --> 00:05:00,800
as a directory data can be stored in a

00:05:00,320 --> 00:05:04,240
file

00:05:00,800 --> 00:05:04,720
under that directory fmoral volumes

00:05:04,240 --> 00:05:08,000
include

00:05:04,720 --> 00:05:11,199
secrets config maps csi

00:05:08,000 --> 00:05:11,680
ethmoral volumes and so on its life

00:05:11,199 --> 00:05:15,520
cycle

00:05:11,680 --> 00:05:15,520
follows the life cycle of a pod

00:05:15,759 --> 00:05:20,160
on this slide you can also see a seek

00:05:18,240 --> 00:05:22,000
story team page

00:05:20,160 --> 00:05:25,840
visit this page you will find a lot of

00:05:22,000 --> 00:05:25,840
information about the sig

00:05:30,800 --> 00:05:34,240
all right so now we're going to move on

00:05:32,800 --> 00:05:37,440
and talk about

00:05:34,240 --> 00:05:39,600
all the new features that sig storage

00:05:37,440 --> 00:05:43,199
has been working on

00:05:39,600 --> 00:05:47,680
in 118 so

00:05:43,199 --> 00:05:51,680
we landed a lot of features

00:05:47,680 --> 00:05:54,960
and graduated them to ga status

00:05:51,680 --> 00:05:58,319
first is the raw block feature

00:05:54,960 --> 00:06:01,520
this allows containers to

00:05:58,319 --> 00:06:04,639
access a volume as a

00:06:01,520 --> 00:06:06,479
block device instead of as the formatted

00:06:04,639 --> 00:06:09,759
file system

00:06:06,479 --> 00:06:13,120
this is very useful for workloads

00:06:09,759 --> 00:06:17,840
such as high performance databases

00:06:13,120 --> 00:06:21,039
that may operate and have optimizations

00:06:17,840 --> 00:06:24,479
on with their own file system format

00:06:21,039 --> 00:06:26,080
and want to deal with a block device

00:06:24,479 --> 00:06:28,800
instead of

00:06:26,080 --> 00:06:31,520
actually having someone else format the

00:06:28,800 --> 00:06:34,560
file system on it

00:06:31,520 --> 00:06:38,400
so that feature is now ga for both

00:06:34,560 --> 00:06:38,400
in tree and csi drivers

00:06:38,800 --> 00:06:45,120
the next feature that is ga is

00:06:42,400 --> 00:06:48,000
cloning this is a feature that is only

00:06:45,120 --> 00:06:52,080
available to csi drivers

00:06:48,000 --> 00:06:55,680
and this gives the ability to

00:06:52,080 --> 00:06:59,919
create a pvc

00:06:55,680 --> 00:06:59,919
as a copy of another pvc

00:07:00,400 --> 00:07:05,520
the next two features um are also csi

00:07:03,919 --> 00:07:08,800
specific

00:07:05,520 --> 00:07:12,930
one is called the skip attach feature

00:07:08,800 --> 00:07:14,080
this allows a csi driver to

00:07:12,930 --> 00:07:16,639
[Music]

00:07:14,080 --> 00:07:18,400
indicate that they don't support the

00:07:16,639 --> 00:07:20,880
attach operation

00:07:18,400 --> 00:07:23,599
and they don't have to bundle the the

00:07:20,880 --> 00:07:27,039
csi attacher sidecar with the driver

00:07:23,599 --> 00:07:29,440
so that's what this feature enables

00:07:27,039 --> 00:07:30,720
and then the next feature csi pod info

00:07:29,440 --> 00:07:34,080
on mount

00:07:30,720 --> 00:07:37,199
this allows a cs5 driver to

00:07:34,080 --> 00:07:40,319
receive pod information

00:07:37,199 --> 00:07:43,599
such as the name and name space of the

00:07:40,319 --> 00:07:47,120
pod that is mounting this volume

00:07:43,599 --> 00:07:50,319
and this is useful if if

00:07:47,120 --> 00:07:52,960
the csi driver needs things like

00:07:50,319 --> 00:07:56,000
pod specific credentials or any other

00:07:52,960 --> 00:07:56,000
pod specific info

00:07:56,560 --> 00:08:00,240
so those are the features that graduated

00:07:58,479 --> 00:08:03,360
to ga

00:08:00,240 --> 00:08:07,599
next graduating to beta

00:08:03,360 --> 00:08:11,199
is open stack csi migration so

00:08:07,599 --> 00:08:14,879
overall the csi migration feature allows

00:08:11,199 --> 00:08:20,479
users to continue using

00:08:14,879 --> 00:08:23,919
the kubernetes in-tree volume apis

00:08:20,479 --> 00:08:27,440
but the main difference is that the

00:08:23,919 --> 00:08:30,800
back end of kubernetes will

00:08:27,440 --> 00:08:34,719
call out to the csi driver instead

00:08:30,800 --> 00:08:37,599
of calling out to the entry volume code

00:08:34,719 --> 00:08:39,039
so the the main purpose of this feature

00:08:37,599 --> 00:08:40,800
is so that we can remove

00:08:39,039 --> 00:08:42,320
third-party as many third-party

00:08:40,800 --> 00:08:46,160
dependencies

00:08:42,320 --> 00:08:49,200
from the core of kubernetes as possible

00:08:46,160 --> 00:08:52,560
this will bring a lot of security

00:08:49,200 --> 00:08:56,080
benefits and also help reduce

00:08:52,560 --> 00:08:58,480
the uh vendor size of the kubernetes

00:08:56,080 --> 00:09:02,080
components themselves

00:08:58,480 --> 00:09:05,040
so the um openstack

00:09:02,080 --> 00:09:08,000
implementation of this has gone to beta

00:09:05,040 --> 00:09:11,279
in 118.

00:09:08,000 --> 00:09:13,760
and then in 118 we also introduced a

00:09:11,279 --> 00:09:18,720
number of new features

00:09:13,760 --> 00:09:22,000
that are alpha first is csi windows

00:09:18,720 --> 00:09:26,480
this is basically the ability to

00:09:22,000 --> 00:09:29,600
support csi drivers on windows notes

00:09:26,480 --> 00:09:33,279
so this is now an alpha

00:09:29,600 --> 00:09:33,279
and currently

00:09:33,360 --> 00:09:37,440
a couple there are a couple of csi

00:09:36,399 --> 00:09:41,680
drivers

00:09:37,440 --> 00:09:44,000
from azure and gce that support this

00:09:41,680 --> 00:09:46,320
and i believe more are coming on the

00:09:44,000 --> 00:09:49,760
line

00:09:46,320 --> 00:09:50,399
for all of these csi features they all

00:09:49,760 --> 00:09:53,040
depend

00:09:50,399 --> 00:09:53,920
on the csi driver to actually support

00:09:53,040 --> 00:09:57,519
and implement it

00:09:53,920 --> 00:09:58,959
so please check with your csi driver

00:09:57,519 --> 00:10:01,360
whether or not it supports these

00:09:58,959 --> 00:10:01,360
features

00:10:02,560 --> 00:10:09,519
the next alpha feature is to

00:10:06,000 --> 00:10:12,640
be able to support uh setting

00:10:09,519 --> 00:10:16,800
uh an fs group change

00:10:12,640 --> 00:10:20,160
policy in the pod security context

00:10:16,800 --> 00:10:21,680
so this is to help solve a scaling

00:10:20,160 --> 00:10:25,279
problem with

00:10:21,680 --> 00:10:28,800
the current fs group implementation

00:10:25,279 --> 00:10:30,560
where the where kubernetes has to

00:10:28,800 --> 00:10:33,200
recursively

00:10:30,560 --> 00:10:33,839
walk through every file in a volume and

00:10:33,200 --> 00:10:37,279
change

00:10:33,839 --> 00:10:40,399
the ownership of those files to match

00:10:37,279 --> 00:10:44,399
the ownership on the pods

00:10:40,399 --> 00:10:46,560
this is very time consuming

00:10:44,399 --> 00:10:47,600
for volumes that have a lot of files in

00:10:46,560 --> 00:10:50,399
them

00:10:47,600 --> 00:10:50,959
so this alpha feature is providing an

00:10:50,399 --> 00:10:53,600
option

00:10:50,959 --> 00:10:55,600
to optimize that so that we don't have

00:10:53,600 --> 00:10:58,959
to actually recursively walk

00:10:55,600 --> 00:11:02,399
a volume on every single mount

00:10:58,959 --> 00:11:05,440
instead what this new change policy

00:11:02,399 --> 00:11:08,640
offers is the ability to only

00:11:05,440 --> 00:11:12,560
update the ownership of a volume

00:11:08,640 --> 00:11:15,120
uh on the first mount when it detects

00:11:12,560 --> 00:11:16,000
that the ownership of the volume is

00:11:15,120 --> 00:11:19,200
different from

00:11:16,000 --> 00:11:22,640
the pod so

00:11:19,200 --> 00:11:26,079
that is a great alpha feature out

00:11:22,640 --> 00:11:29,839
that will help that can potentially

00:11:26,079 --> 00:11:33,040
help reduce the mount time

00:11:29,839 --> 00:11:36,560
for any of your volumes that have

00:11:33,040 --> 00:11:36,560
a lot of files in them

00:11:36,800 --> 00:11:42,160
the last alpha feature is also a

00:11:39,279 --> 00:11:45,440
scalability feature

00:11:42,160 --> 00:11:46,399
this is the ability to mark a secret or

00:11:45,440 --> 00:11:50,320
config map

00:11:46,399 --> 00:11:53,040
volume as immutable

00:11:50,320 --> 00:11:54,839
and this will base this feature will

00:11:53,040 --> 00:11:58,079
basically help reduce

00:11:54,839 --> 00:12:01,519
load on the api server

00:11:58,079 --> 00:12:06,000
from nodes because

00:12:01,519 --> 00:12:08,560
currently cubelet needs to

00:12:06,000 --> 00:12:09,279
watch the secret and config maps for

00:12:08,560 --> 00:12:12,000
updates

00:12:09,279 --> 00:12:13,360
and then be able to update the volumes

00:12:12,000 --> 00:12:17,519
periodically

00:12:13,360 --> 00:12:20,240
so if you run a lot of pods on

00:12:17,519 --> 00:12:22,160
nodes and you have a lot and those pods

00:12:20,240 --> 00:12:23,279
are using a lot of secrets and config

00:12:22,160 --> 00:12:27,680
maps

00:12:23,279 --> 00:12:28,240
you may hit some api server bottlenecks

00:12:27,680 --> 00:12:31,279
with that

00:12:28,240 --> 00:12:34,160
so this feature is going to help for

00:12:31,279 --> 00:12:34,160
those use cases

00:12:34,240 --> 00:12:39,279
so those are all the features that we've

00:12:36,639 --> 00:12:43,279
done in 118

00:12:39,279 --> 00:12:44,240
and now i will go through all the

00:12:43,279 --> 00:12:48,639
features that

00:12:44,240 --> 00:12:50,000
are planned to come in this upcoming 119

00:12:48,639 --> 00:12:53,360
release

00:12:50,000 --> 00:12:55,200
so we are currently in the middle of um

00:12:53,360 --> 00:12:57,360
or we're close to the end of the release

00:12:55,200 --> 00:13:01,360
cycle for 119.

00:12:57,360 --> 00:13:04,720
um the 119 release is targeted to be

00:13:01,360 --> 00:13:08,399
um in a little over a month now

00:13:04,720 --> 00:13:11,200
on august 25th so

00:13:08,399 --> 00:13:12,800
i'll go through all the features that

00:13:11,200 --> 00:13:16,959
sig storage is planning

00:13:12,800 --> 00:13:20,720
um for the 119 release so graduating

00:13:16,959 --> 00:13:25,120
uh to beta are the azure disk

00:13:20,720 --> 00:13:28,320
and vc vsphere csi migration features

00:13:25,120 --> 00:13:31,519
so these are just additional um

00:13:28,320 --> 00:13:34,320
cloud provider implementations for the

00:13:31,519 --> 00:13:37,519
cs overall csi migration feature

00:13:34,320 --> 00:13:41,120
and will allow

00:13:37,519 --> 00:13:41,680
the core kubernetes apis to be supported

00:13:41,120 --> 00:13:45,199
by

00:13:41,680 --> 00:13:48,320
csi back-ends and the

00:13:45,199 --> 00:13:52,320
so this release adds the azure disk and

00:13:48,320 --> 00:13:56,079
these sphere implementations for that

00:13:52,320 --> 00:13:58,320
um and then similarly the uh csi windows

00:13:56,079 --> 00:14:01,480
feature that we introduced in alpha

00:13:58,320 --> 00:14:04,480
in 118 is graduating to beta in

00:14:01,480 --> 00:14:04,480
00:14:04,800 --> 00:14:10,800
and also the

00:14:08,160 --> 00:14:11,519
immutable secrets and config maps

00:14:10,800 --> 00:14:13,920
feature

00:14:11,519 --> 00:14:16,000
that was introduced in 118 is now

00:14:13,920 --> 00:14:19,519
graduating to beta in 118

00:14:16,000 --> 00:14:22,720
as well in addition

00:14:19,519 --> 00:14:26,720
to those graduating features we

00:14:22,720 --> 00:14:30,000
are continuing uh making improvements

00:14:26,720 --> 00:14:33,199
on existing beta features so

00:14:30,000 --> 00:14:36,399
these features have been beta in have

00:14:33,199 --> 00:14:39,680
graduated to beta in earlier releases

00:14:36,399 --> 00:14:43,279
they are remaining beta in 119

00:14:39,680 --> 00:14:44,320
but we are making continuous

00:14:43,279 --> 00:14:49,199
improvements to them

00:14:44,320 --> 00:14:52,880
so first up is a volume expansion

00:14:49,199 --> 00:14:56,399
um there are improvements being made uh

00:14:52,880 --> 00:15:00,079
with related to the way that we process

00:14:56,399 --> 00:15:04,000
um offline expansion

00:15:00,079 --> 00:15:08,320
for uh volumes that can only support

00:15:04,000 --> 00:15:10,880
doing in a volume resizing operation

00:15:08,320 --> 00:15:12,320
if the volume only if the volume is

00:15:10,880 --> 00:15:16,160
unmounted

00:15:12,320 --> 00:15:19,360
so detecting that support in the driver

00:15:16,160 --> 00:15:21,519
and then having kubernetes orchestrate

00:15:19,360 --> 00:15:25,120
the volume expansion operation

00:15:21,519 --> 00:15:27,839
to work with those kinds of drivers is

00:15:25,120 --> 00:15:30,480
a big improvement that we are making in

00:15:27,839 --> 00:15:30,480
00:15:30,720 --> 00:15:36,480
and then the volume snapshot

00:15:33,839 --> 00:15:39,680
beta feature which was introduced in

00:15:36,480 --> 00:15:43,920
kubernetes 117

00:15:39,680 --> 00:15:47,079
we are continuing to make bug fixes

00:15:43,920 --> 00:15:50,079
and other improvements to the

00:15:47,079 --> 00:15:50,079
implementation

00:15:50,800 --> 00:15:56,880
119 also comes with a number of new

00:15:54,000 --> 00:15:56,880
alpha features

00:15:57,199 --> 00:16:02,079
first up is csi storage capacity

00:16:00,639 --> 00:16:05,519
tracking

00:16:02,079 --> 00:16:09,279
so this feature

00:16:05,519 --> 00:16:13,600
gives a way for a csi driver

00:16:09,279 --> 00:16:16,880
to report how much capacity they have

00:16:13,600 --> 00:16:20,839
for a storage pool on

00:16:16,880 --> 00:16:24,320
a particular topology

00:16:20,839 --> 00:16:28,079
so if you

00:16:24,320 --> 00:16:30,240
have a local volume csi driver

00:16:28,079 --> 00:16:31,279
this feature lets you node for storage

00:16:30,240 --> 00:16:34,320
class

00:16:31,279 --> 00:16:35,920
if you have a csi driver that deals with

00:16:34,320 --> 00:16:39,120
storage

00:16:35,920 --> 00:16:40,959
on a rack basis you can report

00:16:39,120 --> 00:16:43,440
how much capacity you have for

00:16:40,959 --> 00:16:48,639
provisioning volumes on a per

00:16:43,440 --> 00:16:48,639
rack and per storage class basis

00:16:48,959 --> 00:16:55,440
so this is a really important feature

00:16:52,160 --> 00:16:57,440
that will help enable uh local volume

00:16:55,440 --> 00:16:58,639
dynamic provisioning which has been a

00:16:57,440 --> 00:17:01,920
pretty long

00:16:58,639 --> 00:17:04,160
long awaited and requested feature so

00:17:01,920 --> 00:17:05,839
this is one of the key features we need

00:17:04,160 --> 00:17:09,120
to enable that use case

00:17:05,839 --> 00:17:12,319
so if you are interested

00:17:09,120 --> 00:17:15,679
in this use case please

00:17:12,319 --> 00:17:18,799
go ahead and try this out with

00:17:15,679 --> 00:17:21,199
your csi driver and

00:17:18,799 --> 00:17:24,079
you know help us fix any bugs and make

00:17:21,199 --> 00:17:24,079
improvements to it

00:17:24,319 --> 00:17:31,120
the next new alpha feature is

00:17:27,520 --> 00:17:34,280
generic ephemeral volumes so

00:17:31,120 --> 00:17:38,080
um this is sort of a

00:17:34,280 --> 00:17:41,840
improvement it's sort of an additional

00:17:38,080 --> 00:17:45,039
um alternative method for implementing

00:17:41,840 --> 00:17:47,760
ephemeral volumes

00:17:45,039 --> 00:17:49,360
in csi although it's not it's not

00:17:47,760 --> 00:17:52,720
actually specific to csi

00:17:49,360 --> 00:17:56,799
um what this feature lets you do is

00:17:52,720 --> 00:18:00,320
it lets you take any volume plug-in

00:17:56,799 --> 00:18:03,360
today that supports

00:18:00,320 --> 00:18:06,880
persistent volumes

00:18:03,360 --> 00:18:06,880
it allows you to

00:18:07,039 --> 00:18:16,000
specify them directly in a pod spec

00:18:11,760 --> 00:18:19,440
and have the volume life cycle handled

00:18:16,000 --> 00:18:20,480
automatically so what what that

00:18:19,440 --> 00:18:24,000
basically means

00:18:20,480 --> 00:18:27,280
is when you specify in a generic

00:18:24,000 --> 00:18:30,720
ephemeral volume in your pod spec

00:18:27,280 --> 00:18:34,320
you will actually specify a volume claim

00:18:30,720 --> 00:18:35,039
template which is very similar to the

00:18:34,320 --> 00:18:38,320
pvc

00:18:35,039 --> 00:18:41,120
spec and underneath the covers um

00:18:38,320 --> 00:18:42,640
it will go and manage the life cycle of

00:18:41,120 --> 00:18:46,640
that pvc

00:18:42,640 --> 00:18:50,400
with uh the life cycle of the pod

00:18:46,640 --> 00:18:53,280
so um this feature is really powerful

00:18:50,400 --> 00:18:53,919
and will and and can enable a lot of use

00:18:53,280 --> 00:18:57,600
cases

00:18:53,919 --> 00:19:02,240
such as having

00:18:57,600 --> 00:19:06,160
a external any csi

00:19:02,240 --> 00:19:09,600
driver automatically gets supported with

00:19:06,160 --> 00:19:13,840
like a scratch space use case so

00:19:09,600 --> 00:19:14,880
if for example you want to use an eds

00:19:13,840 --> 00:19:18,080
volume

00:19:14,880 --> 00:19:20,320
as a sort of an empty dir

00:19:18,080 --> 00:19:21,760
type of volume where you you're just

00:19:20,320 --> 00:19:23,679
using it as scratch space

00:19:21,760 --> 00:19:25,360
and you want it to get deleted when you

00:19:23,679 --> 00:19:28,480
delete the pod

00:19:25,360 --> 00:19:29,440
you can use this feature to specify an

00:19:28,480 --> 00:19:33,760
ebs

00:19:29,440 --> 00:19:36,720
a pvc using a ebs storage class

00:19:33,760 --> 00:19:37,440
and the provisioning and deletion of the

00:19:36,720 --> 00:19:40,799
pvc

00:19:37,440 --> 00:19:43,919
will happen automatically by and will be

00:19:40,799 --> 00:19:47,120
managed by kubernetes

00:19:43,919 --> 00:19:50,000
another uh important

00:19:47,120 --> 00:19:50,640
use case that this can enable is

00:19:50,000 --> 00:19:55,280
something

00:19:50,640 --> 00:19:59,039
like offering a empty dirt alternative

00:19:55,280 --> 00:20:02,320
but using specialized local storage

00:19:59,039 --> 00:20:05,039
so if you have say

00:20:02,320 --> 00:20:06,159
a csi driver that can provide local

00:20:05,039 --> 00:20:10,799
storage

00:20:06,159 --> 00:20:12,880
with using local ssds on your node

00:20:10,799 --> 00:20:14,159
you can use this feature to basically

00:20:12,880 --> 00:20:16,960
provide

00:20:14,159 --> 00:20:17,919
an empty dir like behavior or empty dirt

00:20:16,960 --> 00:20:21,760
like volume

00:20:17,919 --> 00:20:23,600
but on top of a local ssd instead of

00:20:21,760 --> 00:20:25,039
instead of using the boot disk on the

00:20:23,600 --> 00:20:28,720
node

00:20:25,039 --> 00:20:31,039
so this is a very powerful feature again

00:20:28,720 --> 00:20:32,559
i would highly encourage everyone to try

00:20:31,039 --> 00:20:35,520
it out and help

00:20:32,559 --> 00:20:36,799
give us feedback and help develop the

00:20:35,520 --> 00:20:39,520
feature further

00:20:36,799 --> 00:20:42,320
so that we can graduate these two beta

00:20:39,520 --> 00:20:42,320
and nga

00:20:43,039 --> 00:20:46,559
the next alpha feature that we have

00:20:45,919 --> 00:20:50,159
added

00:20:46,559 --> 00:20:53,360
is csi volume health

00:20:50,159 --> 00:20:56,480
this basically provides a way for

00:20:53,360 --> 00:21:00,640
csi drivers to monitor

00:20:56,480 --> 00:21:02,880
the status of provision volumes

00:21:00,640 --> 00:21:05,039
and to be able to report that back to

00:21:02,880 --> 00:21:09,120
kubernetes

00:21:05,039 --> 00:21:11,679
right now this will um

00:21:09,120 --> 00:21:12,960
right now volume health status is

00:21:11,679 --> 00:21:17,280
reported as

00:21:12,960 --> 00:21:20,960
events on the pbc objects

00:21:17,280 --> 00:21:23,760
so that you can you have any monitoring

00:21:20,960 --> 00:21:24,640
um you can build some monitoring on pvc

00:21:23,760 --> 00:21:27,200
events

00:21:24,640 --> 00:21:30,480
to determine if your volume is in a

00:21:27,200 --> 00:21:34,480
healthy state or not

00:21:30,480 --> 00:21:38,400
and then the last new alpha feature

00:21:34,480 --> 00:21:41,440
that we added in 119 is to add

00:21:38,400 --> 00:21:45,600
a fs group

00:21:41,440 --> 00:21:48,360
support policy on the csi driver itself

00:21:45,600 --> 00:21:50,559
this will allow a csi driver to

00:21:48,360 --> 00:21:54,320
explicitly state

00:21:50,559 --> 00:21:57,760
whether or not they support fs group

00:21:54,320 --> 00:22:01,280
so currently in kubernetes

00:21:57,760 --> 00:22:02,799
we use some heuristics to determine if a

00:22:01,280 --> 00:22:05,840
csi driver

00:22:02,799 --> 00:22:06,960
if fs group should be applied to a

00:22:05,840 --> 00:22:09,919
volume

00:22:06,960 --> 00:22:12,480
and right now we the heuristic is that

00:22:09,919 --> 00:22:15,760
if it's a read write once volume

00:22:12,480 --> 00:22:20,000
and there is a fs type set

00:22:15,760 --> 00:22:22,960
on the on the volume specification

00:22:20,000 --> 00:22:25,440
then we will then kubernetes will go and

00:22:22,960 --> 00:22:28,720
apply the fs group

00:22:25,440 --> 00:22:30,960
changes to that volume but this

00:22:28,720 --> 00:22:32,400
what this feature does is make that

00:22:30,960 --> 00:22:36,000
choice actually more

00:22:32,400 --> 00:22:39,520
explicit by the driver and

00:22:36,000 --> 00:22:41,200
the driver will indicate whether or not

00:22:39,520 --> 00:22:44,400
it supports it

00:22:41,200 --> 00:22:47,840
and this will be useful so

00:22:44,400 --> 00:22:51,520
that drivers that fall outside those

00:22:47,840 --> 00:22:52,960
heuristics like nfs drivers or any other

00:22:51,520 --> 00:22:56,240
multi-rider drivers

00:22:52,960 --> 00:22:59,120
they can potentially opt in to

00:22:56,240 --> 00:23:01,919
having kubernetes manage the permissions

00:22:59,120 --> 00:23:01,919
on their volumes

00:23:03,200 --> 00:23:09,600
thanks michelle i will be talking about

00:23:07,039 --> 00:23:12,720
our future plans what we will be working

00:23:09,600 --> 00:23:14,799
on after the 1.19 release

00:23:12,720 --> 00:23:16,240
there are a number of features that we

00:23:14,799 --> 00:23:19,760
are targeting ga

00:23:16,240 --> 00:23:23,600
or beta in 1.20

00:23:19,760 --> 00:23:25,360
the first one is csi volume expansion

00:23:23,600 --> 00:23:28,320
we have been working on bug fixing in

00:23:25,360 --> 00:23:30,559
order to bring this feature to ga

00:23:28,320 --> 00:23:33,919
we are planning to deprecate the online

00:23:30,559 --> 00:23:37,760
offline one extension plugin capability

00:23:33,919 --> 00:23:41,039
in a future csi spec release targeting

00:23:37,760 --> 00:23:43,279
1.4 css spec release

00:23:41,039 --> 00:23:45,200
online offline one expansion will still

00:23:43,279 --> 00:23:48,799
be supported

00:23:45,200 --> 00:23:50,480
while csi driver receives a request for

00:23:48,799 --> 00:23:53,440
voter expansion

00:23:50,480 --> 00:23:53,679
it should return failed precondition if

00:23:53,440 --> 00:23:57,760
it

00:23:53,679 --> 00:23:57,760
only supports offline order expansion

00:23:58,000 --> 00:24:02,080
but the request was issued while the

00:24:00,000 --> 00:24:04,480
volume is in use

00:24:02,080 --> 00:24:05,520
kubernetes will stop calling the csr

00:24:04,480 --> 00:24:09,279
driver when it

00:24:05,520 --> 00:24:09,279
receives this return code

00:24:09,840 --> 00:24:14,240
the next feature is a csi warning

00:24:12,720 --> 00:24:16,480
snapshot

00:24:14,240 --> 00:24:18,000
we have been doing bug fixing and adding

00:24:16,480 --> 00:24:21,679
tests trying to

00:24:18,000 --> 00:24:24,240
bring the gga in 1.20 release

00:24:21,679 --> 00:24:26,320
we are going to add a validation webhook

00:24:24,240 --> 00:24:29,360
to enforce the api

00:24:26,320 --> 00:24:32,080
for example there can be only one source

00:24:29,360 --> 00:24:33,120
in the world in snapshot it can either

00:24:32,080 --> 00:24:35,600
be

00:24:33,120 --> 00:24:37,919
the persistent volume claim name for

00:24:35,600 --> 00:24:41,520
dynamically provisioned snapshots

00:24:37,919 --> 00:24:44,080
or the volume snapshot content name

00:24:41,520 --> 00:24:45,279
for pre-provisioned snapshots but not

00:24:44,080 --> 00:24:46,960
both

00:24:45,279 --> 00:24:49,520
also we want to make sure that these

00:24:46,960 --> 00:24:51,919
fields are immutable

00:24:49,520 --> 00:24:52,640
similarly in volumes natural content

00:24:51,919 --> 00:24:54,559
source

00:24:52,640 --> 00:24:56,559
it can either be volume handle for

00:24:54,559 --> 00:24:59,120
dynamically provisioned snapshots

00:24:56,559 --> 00:25:00,960
or snapshot handle for pre-provision

00:24:59,120 --> 00:25:03,520
snapshots

00:25:00,960 --> 00:25:05,440
we are also planning to add a matrix to

00:25:03,520 --> 00:25:08,320
the snapshot controller

00:25:05,440 --> 00:25:09,760
using the matrix utility functions that

00:25:08,320 --> 00:25:14,559
we added earlier

00:25:09,760 --> 00:25:17,600
in 1.19 release

00:25:14,559 --> 00:25:21,360
the next feature is non-recursive

00:25:17,600 --> 00:25:24,559
fs group this feature was introduced as

00:25:21,360 --> 00:25:26,720
an alpha feature in 1.18

00:25:24,559 --> 00:25:28,880
it allows volume ownership and

00:25:26,720 --> 00:25:31,520
permission change to be skipped

00:25:28,880 --> 00:25:32,000
during the month we are planning to

00:25:31,520 --> 00:25:35,679
bring it

00:25:32,000 --> 00:25:38,559
to beta in 1.20

00:25:35,679 --> 00:25:39,679
and also we are planning to bring the

00:25:38,559 --> 00:25:43,360
azure file

00:25:39,679 --> 00:25:45,760
csi migration feature to beta in 1.20

00:25:43,360 --> 00:25:45,760
release

00:25:49,679 --> 00:25:55,360
we also have some features that we are

00:25:53,279 --> 00:25:57,760
going to introduce an alpha feature in

00:25:55,360 --> 00:26:01,279
1.20 release

00:25:57,760 --> 00:26:03,679
the first one is passport service

00:26:01,279 --> 00:26:06,559
account token to csi

00:26:03,679 --> 00:26:08,720
this feature proposes a way to obtain

00:26:06,559 --> 00:26:10,480
service account token for parts

00:26:08,720 --> 00:26:13,120
that the csr drivers are mounting

00:26:10,480 --> 00:26:13,120
volumes for

00:26:13,200 --> 00:26:19,440
and the second feature is recovery

00:26:16,320 --> 00:26:22,080
from volume expansion failure

00:26:19,440 --> 00:26:23,200
this allows recovery from volume

00:26:22,080 --> 00:26:26,640
expansion failure

00:26:23,200 --> 00:26:29,840
caused by insufficient quota

00:26:26,640 --> 00:26:32,480
it relaxes the api validation and

00:26:29,840 --> 00:26:33,440
allows the user to request a smaller

00:26:32,480 --> 00:26:36,640
size

00:26:33,440 --> 00:26:38,080
than the previous request so that one

00:26:36,640 --> 00:26:40,880
expansion can be completed

00:26:38,080 --> 00:26:42,080
successfully within the supported quota

00:26:40,880 --> 00:26:44,080
limit

00:26:42,080 --> 00:26:45,520
however this does not really support

00:26:44,080 --> 00:26:47,840
volume shrinking

00:26:45,520 --> 00:26:51,200
the requested volume size must still be

00:26:47,840 --> 00:26:52,880
smaller than original volume size

00:26:51,200 --> 00:26:55,120
so we are also trying to bring this one

00:26:52,880 --> 00:26:56,960
to other in 1.20

00:26:55,120 --> 00:27:00,080
and the third feature we're trying to

00:26:56,960 --> 00:27:04,640
bring as an other feature in 1.20

00:27:00,080 --> 00:27:07,039
is non-recursive secure linux

00:27:04,640 --> 00:27:08,240
this proposes a way to speed up

00:27:07,039 --> 00:27:11,600
container startup

00:27:08,240 --> 00:27:13,679
by mounting volumes with the correct sql

00:27:11,600 --> 00:27:15,200
linux label instead of changing each

00:27:13,679 --> 00:27:18,960
file and volumes

00:27:15,200 --> 00:27:22,000
recursively we're also planning to

00:27:18,960 --> 00:27:26,480
add a configuration so that csr drivers

00:27:22,000 --> 00:27:29,440
can opt in to support this feature

00:27:26,480 --> 00:27:29,840
there are also a few features that have

00:27:29,440 --> 00:27:33,360
been

00:27:29,840 --> 00:27:36,240
in design or been prototyped

00:27:33,360 --> 00:27:36,960
the first one is the saf csr migration

00:27:36,240 --> 00:27:40,080
and that is

00:27:36,960 --> 00:27:43,120
being designed the second one

00:27:40,080 --> 00:27:46,320
is voting groups this feature proposes

00:27:43,120 --> 00:27:48,799
to introduce a new volume group crd

00:27:46,320 --> 00:27:51,440
that groups multiple volumes together

00:27:48,799 --> 00:27:53,520
and a new group snapshot crd that

00:27:51,440 --> 00:27:54,480
supports taking a snapshot of all

00:27:53,520 --> 00:27:57,200
volumes

00:27:54,480 --> 00:27:59,120
in the same group to ensure right order

00:27:57,200 --> 00:28:00,720
consistency

00:27:59,120 --> 00:28:02,480
we are also looking at how to use the

00:28:00,720 --> 00:28:05,360
volume group concept to support

00:28:02,480 --> 00:28:07,679
failure domain spreading for example how

00:28:05,360 --> 00:28:10,240
to place volumes in the same group

00:28:07,679 --> 00:28:12,799
across different disks in the same

00:28:10,240 --> 00:28:15,200
storage system

00:28:12,799 --> 00:28:16,240
the next feature that we're working on

00:28:15,200 --> 00:28:19,840
is the generic

00:28:16,240 --> 00:28:22,880
data populator this allows a pvc to be

00:28:19,840 --> 00:28:25,919
provisioned for an external data source

00:28:22,880 --> 00:28:27,679
not just a volume snapshot or an

00:28:25,919 --> 00:28:31,440
existing pvc

00:28:27,679 --> 00:28:34,480
but it could be an object store

00:28:31,440 --> 00:28:35,919
a github ripple or an image or something

00:28:34,480 --> 00:28:38,080
else

00:28:35,919 --> 00:28:39,200
there is already an any volume data

00:28:38,080 --> 00:28:42,240
source feature gate

00:28:39,200 --> 00:28:43,120
which was introduced as an alpha feature

00:28:42,240 --> 00:28:46,799
gate

00:28:43,120 --> 00:28:49,840
in 1.80 release we want to

00:28:46,799 --> 00:28:53,039
have a generic data population

00:28:49,840 --> 00:28:55,200
implementation completed so that we can

00:28:53,039 --> 00:28:59,840
promote this feature to beta

00:28:55,200 --> 00:28:59,840
in the 1090 in the 1.20 release

00:29:00,880 --> 00:29:04,720
the next feature is the container object

00:29:03,919 --> 00:29:07,919
storage

00:29:04,720 --> 00:29:11,200
interface cozy

00:29:07,919 --> 00:29:12,080
this feature allows an object bucket to

00:29:11,200 --> 00:29:15,120
be provisioned

00:29:12,080 --> 00:29:19,200
and used by pod there have been

00:29:15,120 --> 00:29:20,000
weekly design meetings it now becomes a

00:29:19,200 --> 00:29:22,960
sub project

00:29:20,000 --> 00:29:24,080
under six storage we have ripples

00:29:22,960 --> 00:29:27,679
created under

00:29:24,080 --> 00:29:29,919
kubernetes six for a prototyping purpose

00:29:27,679 --> 00:29:31,840
if you are interested you can join the

00:29:29,919 --> 00:29:34,559
design meetings and help with the

00:29:31,840 --> 00:29:34,559
prototyping

00:29:36,880 --> 00:29:40,320
we also have a cross seek working group

00:29:39,919 --> 00:29:42,960
called

00:29:40,320 --> 00:29:45,039
the data protection working group this

00:29:42,960 --> 00:29:45,360
is a collaboration between six storage

00:29:45,039 --> 00:29:48,480
and

00:29:45,360 --> 00:29:48,880
sick apps i co-lead this working group

00:29:48,480 --> 00:29:51,919
with

00:29:48,880 --> 00:29:52,480
shenzhen from google in this working

00:29:51,919 --> 00:29:54,640
group

00:29:52,480 --> 00:29:56,240
we have been discussing a number of

00:29:54,640 --> 00:29:59,120
features that we already

00:29:56,240 --> 00:30:00,080
talked about earlier such as volume

00:29:59,120 --> 00:30:03,840
group

00:30:00,080 --> 00:30:06,240
and the generic data populator and so on

00:30:03,840 --> 00:30:07,600
one feature the data protection working

00:30:06,240 --> 00:30:10,240
group has been working on

00:30:07,600 --> 00:30:12,000
is how do you quite ask an application

00:30:10,240 --> 00:30:15,120
before taking a snapshot

00:30:12,000 --> 00:30:15,919
and unquies afterwards we initially

00:30:15,120 --> 00:30:18,720
proposed

00:30:15,919 --> 00:30:19,919
an execution hook crd approach which

00:30:18,720 --> 00:30:22,159
requires an

00:30:19,919 --> 00:30:23,440
external controller to run command

00:30:22,159 --> 00:30:26,720
through the pod

00:30:23,440 --> 00:30:29,440
exact sub resource but

00:30:26,720 --> 00:30:31,520
during the implementation we got

00:30:29,440 --> 00:30:34,399
feedback from the api reviewers

00:30:31,520 --> 00:30:36,240
that this is not secure so now we are

00:30:34,399 --> 00:30:37,840
looking at another approach called

00:30:36,240 --> 00:30:40,399
container notifier

00:30:37,840 --> 00:30:40,960
which is to define the command or signal

00:30:40,399 --> 00:30:43,760
as an

00:30:40,960 --> 00:30:45,679
inline part definition external

00:30:43,760 --> 00:30:46,720
controller can request this container

00:30:45,679 --> 00:30:48,960
notifier

00:30:46,720 --> 00:30:50,799
but cubelet will be the one executing

00:30:48,960 --> 00:30:52,559
the command or sending the signal to the

00:30:50,799 --> 00:30:54,960
container

00:30:52,559 --> 00:30:57,039
this is currently still under design

00:30:54,960 --> 00:31:00,080
discussion

00:30:57,039 --> 00:31:04,080
we also co-own volume

00:31:00,080 --> 00:31:06,480
expansion for safer sets with sick apps

00:31:04,080 --> 00:31:08,320
currently we can only support expanding

00:31:06,480 --> 00:31:11,760
a volume used by a pod

00:31:08,320 --> 00:31:12,240
but not with a staple set so this is a

00:31:11,760 --> 00:31:15,840
design

00:31:12,240 --> 00:31:16,480
in progress another design in progress

00:31:15,840 --> 00:31:20,399
feature

00:31:16,480 --> 00:31:20,799
is how to clean up pvcs used by a safer

00:31:20,399 --> 00:31:24,399
set

00:31:20,799 --> 00:31:27,279
when stiffer set is being deleted or

00:31:24,399 --> 00:31:27,279
scaled down

00:31:30,559 --> 00:31:34,000
if you are interested in getting

00:31:32,159 --> 00:31:37,039
involved with six storage

00:31:34,000 --> 00:31:37,919
take a look of the sig storage community

00:31:37,039 --> 00:31:39,679
page

00:31:37,919 --> 00:31:41,120
it has a lot of information to get you

00:31:39,679 --> 00:31:44,559
started

00:31:41,120 --> 00:31:48,480
we have a bi-weekly meeting that happens

00:31:44,559 --> 00:31:52,240
on thursdays at 9 00 a.m pacific time

00:31:48,480 --> 00:31:55,360
it is a zoo meeting near the agenda doc

00:31:52,240 --> 00:31:56,960
on that sixth order page you can feel

00:31:55,360 --> 00:32:00,159
free to add items

00:31:56,960 --> 00:32:03,200
to the jaina doc for discussion

00:32:00,159 --> 00:32:04,080
we have a lot of bugs that we need to

00:32:03,200 --> 00:32:08,960
help with

00:32:04,080 --> 00:32:13,200
so help fix a bug and help write tests

00:32:08,960 --> 00:32:16,960
how bright features kubernetes releases

00:32:13,200 --> 00:32:17,360
usually every quarter but this year due

00:32:16,960 --> 00:32:21,120
to

00:32:17,360 --> 00:32:24,159
kobe 19 there are only three releases

00:32:21,120 --> 00:32:25,519
for every release we will be doing

00:32:24,159 --> 00:32:27,840
planning

00:32:25,519 --> 00:32:30,159
so in the beginning of the release then

00:32:27,840 --> 00:32:33,279
come and join our meeting

00:32:30,159 --> 00:32:36,799
and participate in the planning

00:32:33,279 --> 00:32:38,799
and you can see if there are any

00:32:36,799 --> 00:32:39,440
features you are interested in helping

00:32:38,799 --> 00:32:42,399
out

00:32:39,440 --> 00:32:44,480
and you can get assigned to work on that

00:32:42,399 --> 00:32:45,360
every feature must have an enhancement

00:32:44,480 --> 00:32:48,559
issue

00:32:45,360 --> 00:32:52,559
and a cap which is a design spec

00:32:48,559 --> 00:32:55,440
we definitely need more contributors

00:32:52,559 --> 00:32:57,279
so this is the end of the session we

00:32:55,440 --> 00:32:58,159
have some additional resources at the

00:32:57,279 --> 00:33:01,519
end of this

00:32:58,159 --> 00:33:02,720
slide deck you can download this to take

00:33:01,519 --> 00:33:05,120
a look

00:33:02,720 --> 00:33:06,640
we hope you find this session helpful if

00:33:05,120 --> 00:33:09,679
you have any questions

00:33:06,640 --> 00:33:12,640
please don't hesitate to reach out to us

00:33:09,679 --> 00:33:12,640

YouTube URL: https://www.youtube.com/watch?v=mJlqmZm-pVs


