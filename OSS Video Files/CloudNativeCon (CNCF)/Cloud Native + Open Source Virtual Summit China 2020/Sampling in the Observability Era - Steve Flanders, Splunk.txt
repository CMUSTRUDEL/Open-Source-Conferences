Title: Sampling in the Observability Era - Steve Flanders, Splunk
Publication date: 2020-09-11
Playlist: Cloud Native + Open Source Virtual Summit China 2020
Description: 
	Don’t miss out! Join us at our upcoming events: EnvoyCon Virtual on October 15 and KubeCon + CloudNativeCon North America 2020 Virtual from November 17-20. Learn more at https://kubecon.io The conferences feature presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects. 

Sampling in the Observability Era - Steve Flanders, Splunk 

In Cloud-Native environments, traditional monitoring techniques are not sufficient to understand system behavior and cannot effectively address availability as well as performance issues. This has led to the rise of observability and the importance of distributed tracing data which provides context and correlation missing from other data sources. Typically, distributed tracing data is sampled due to the amount of data it generates and concerns about whether all data generated is valuable. While sampling is often stated as a benign or normal thing, it can greatly impact observability. As a result, it is critical to understand what sampling is as well as how each sampling technique works and their associated tradeoffs. This talk will deep dive into what sampling is and at conventions as well as industry practices to address concerns including cost, performance, and overhead. 

https://sched.co/cp93
Captions: 
	00:00:01,360 --> 00:00:06,000
hello everyone and welcome to sampling

00:00:03,679 --> 00:00:07,759
and the observability error

00:00:06,000 --> 00:00:09,440
my name is steve flanders i'm a director

00:00:07,759 --> 00:00:11,360
of engineering at splunk

00:00:09,440 --> 00:00:13,440
i've been in the observability and

00:00:11,360 --> 00:00:14,240
monitoring space for over the last 10

00:00:13,440 --> 00:00:16,880
years

00:00:14,240 --> 00:00:19,039
working in logging distributed tracing

00:00:16,880 --> 00:00:21,359
and open source technologies including

00:00:19,039 --> 00:00:23,039
open census and open telemetry if you're

00:00:21,359 --> 00:00:26,480
interested in learning more about me

00:00:23,039 --> 00:00:28,400
go ahead and follow me on twitter

00:00:26,480 --> 00:00:30,080
so today i want to cover a few different

00:00:28,400 --> 00:00:32,000
aspects first just a very

00:00:30,080 --> 00:00:33,280
quick introduction around what is

00:00:32,000 --> 00:00:35,440
observability

00:00:33,280 --> 00:00:38,079
then we'll focus in on distributed

00:00:35,440 --> 00:00:39,760
tracing and how sampling is used with

00:00:38,079 --> 00:00:41,520
distributed tracing

00:00:39,760 --> 00:00:43,760
and then all the different trade-offs

00:00:41,520 --> 00:00:46,960
depending on the sampling decisions you

00:00:43,760 --> 00:00:50,000
decide to make for your environment

00:00:46,960 --> 00:00:52,000
so first off what is observability

00:00:50,000 --> 00:00:54,480
i like this quote from baron that talks

00:00:52,000 --> 00:00:55,760
about how monitoring is telling you how

00:00:54,480 --> 00:00:58,079
a system works

00:00:55,760 --> 00:00:59,840
usually it's some sort of known thing

00:00:58,079 --> 00:01:01,039
maybe it's even a static threshold you

00:00:59,840 --> 00:01:03,760
get alerted on

00:01:01,039 --> 00:01:05,119
where observability really lets you ask

00:01:03,760 --> 00:01:05,920
any question that you want about your

00:01:05,119 --> 00:01:08,320
environment

00:01:05,920 --> 00:01:10,080
to figure out why it's not working it's

00:01:08,320 --> 00:01:11,520
for more of the unknowns

00:01:10,080 --> 00:01:13,439
and as you start working more with

00:01:11,520 --> 00:01:14,640
distributed architectures more cloud

00:01:13,439 --> 00:01:16,320
native stacks

00:01:14,640 --> 00:01:18,240
this becomes super critical because you

00:01:16,320 --> 00:01:19,920
don't necessarily know who is calling

00:01:18,240 --> 00:01:21,119
you or what changes in behavior are

00:01:19,920 --> 00:01:22,799
going to happen

00:01:21,119 --> 00:01:25,119
throughout the different services in

00:01:22,799 --> 00:01:26,880
your environment

00:01:25,119 --> 00:01:28,320
now if you've heard of observability

00:01:26,880 --> 00:01:30,320
you've probably heard of the three

00:01:28,320 --> 00:01:33,200
pillars of observability namely

00:01:30,320 --> 00:01:34,400
logs metrics and traces these different

00:01:33,200 --> 00:01:35,920
data sources

00:01:34,400 --> 00:01:37,600
have some similarities and some

00:01:35,920 --> 00:01:39,360
differences they

00:01:37,600 --> 00:01:40,960
all usually have something to do with

00:01:39,360 --> 00:01:42,880
time but the way that they're

00:01:40,960 --> 00:01:44,799
represented are different

00:01:42,880 --> 00:01:45,920
for example logs are typically

00:01:44,799 --> 00:01:47,920
unstructured though

00:01:45,920 --> 00:01:50,240
in more cloud native environments you're

00:01:47,920 --> 00:01:52,079
seeing a lot more structured text

00:01:50,240 --> 00:01:54,000
and it usually contains some amount of

00:01:52,079 --> 00:01:56,479
metadata you usually use this for last

00:01:54,000 --> 00:01:57,360
mile analysis within your environment

00:01:56,479 --> 00:01:59,920
metrics are more

00:01:57,360 --> 00:02:00,960
data point driven again time series with

00:01:59,920 --> 00:02:03,280
metadata

00:02:00,960 --> 00:02:05,119
and traditionally metrics are used to

00:02:03,280 --> 00:02:07,280
alert about a problem

00:02:05,119 --> 00:02:08,720
though they're typically more symptoms

00:02:07,280 --> 00:02:10,080
because as you look at more distributed

00:02:08,720 --> 00:02:12,400
architectures they don't

00:02:10,080 --> 00:02:14,720
have context and correlation to get you

00:02:12,400 --> 00:02:16,720
really to root cause

00:02:14,720 --> 00:02:18,080
and that's where traces or distributed

00:02:16,720 --> 00:02:20,319
tracing comes in again

00:02:18,080 --> 00:02:21,120
time-based end-end requests in your

00:02:20,319 --> 00:02:22,319
environments

00:02:21,120 --> 00:02:24,080
and even some amount of metric

00:02:22,319 --> 00:02:25,280
information you typically get your red

00:02:24,080 --> 00:02:26,959
metric so request

00:02:25,280 --> 00:02:28,720
errors and duration again with

00:02:26,959 --> 00:02:31,120
associated metadata and this

00:02:28,720 --> 00:02:32,400
is often used for problem isolation for

00:02:31,120 --> 00:02:34,879
both availability

00:02:32,400 --> 00:02:36,000
and performance problems and we're going

00:02:34,879 --> 00:02:37,840
to focus primarily on

00:02:36,000 --> 00:02:39,200
the tracing aspect because when you hear

00:02:37,840 --> 00:02:40,800
the word sampling

00:02:39,200 --> 00:02:42,640
it's usually traces that you are

00:02:40,800 --> 00:02:44,560
sampling to be fair

00:02:42,640 --> 00:02:47,120
sampling may apply to other data sources

00:02:44,560 --> 00:02:49,360
like in logs you have verbosity which is

00:02:47,120 --> 00:02:51,519
kind of a form of sampling in the case

00:02:49,360 --> 00:02:53,519
of metrics it's the granularity of how

00:02:51,519 --> 00:02:54,640
often you are collecting them or how you

00:02:53,519 --> 00:02:57,599
actually roll them up and

00:02:54,640 --> 00:02:58,800
average them that is a form of sampling

00:02:57,599 --> 00:03:00,720
but for today we're just going to focus

00:02:58,800 --> 00:03:02,720
on the tracing aspects

00:03:00,720 --> 00:03:04,720
now i would be remiss not to mention the

00:03:02,720 --> 00:03:06,879
open telemetry project given this

00:03:04,720 --> 00:03:07,760
this is a cloud native open source

00:03:06,879 --> 00:03:09,680
summit

00:03:07,760 --> 00:03:10,879
open telemetry is actually looking to

00:03:09,680 --> 00:03:12,959
provide

00:03:10,879 --> 00:03:14,000
infrastructure around instrumentation

00:03:12,959 --> 00:03:16,800
data collection

00:03:14,000 --> 00:03:19,040
api end-to-end implementation basically

00:03:16,800 --> 00:03:20,319
all the way uh just before the back end

00:03:19,040 --> 00:03:21,040
so it doesn't provide a back-end

00:03:20,319 --> 00:03:22,879
solution

00:03:21,040 --> 00:03:24,720
but it provides a vendor agnostic way to

00:03:22,879 --> 00:03:25,920
send to the back end or back ends of

00:03:24,720 --> 00:03:27,760
your choice

00:03:25,920 --> 00:03:29,920
now i bring this up only because i'll be

00:03:27,760 --> 00:03:32,239
demoing a little bit later to show how

00:03:29,920 --> 00:03:33,440
sampling kind of plays into this world

00:03:32,239 --> 00:03:35,200
but if you're interested in learning

00:03:33,440 --> 00:03:38,400
more about this project please do

00:03:35,200 --> 00:03:39,519
take a look at it next up distributed

00:03:38,400 --> 00:03:42,239
tracing

00:03:39,519 --> 00:03:44,400
so what is distributed tracing i've gone

00:03:42,239 --> 00:03:46,080
ahead and taken this picture from the

00:03:44,400 --> 00:03:48,239
yeager tracing documentation

00:03:46,080 --> 00:03:50,239
jaeger is an open source project also

00:03:48,239 --> 00:03:51,280
part of cncf and definitely worth taking

00:03:50,239 --> 00:03:53,439
a look at

00:03:51,280 --> 00:03:55,519
on the left you basically have an

00:03:53,439 --> 00:03:56,080
example of an environment where every

00:03:55,519 --> 00:03:58,319
circle

00:03:56,080 --> 00:04:00,080
is a microservice and what you're

00:03:58,319 --> 00:04:01,439
basically seeing is a call

00:04:00,080 --> 00:04:03,200
of an end-to-end request throughout the

00:04:01,439 --> 00:04:05,040
system so what ends up happening is

00:04:03,200 --> 00:04:08,319
something hits service a

00:04:05,040 --> 00:04:10,239
this generates a piece of context that

00:04:08,319 --> 00:04:11,519
then gets passed to all subsequent

00:04:10,239 --> 00:04:14,799
downstream calls

00:04:11,519 --> 00:04:16,799
for example to b to c d and e

00:04:14,799 --> 00:04:18,160
how that ends up being represented when

00:04:16,799 --> 00:04:19,840
it's collected

00:04:18,160 --> 00:04:21,199
is more of a waterfall view that you see

00:04:19,840 --> 00:04:24,400
on the right where

00:04:21,199 --> 00:04:26,160
a is kind of the end end or root span

00:04:24,400 --> 00:04:28,160
of the entire transaction it tells you

00:04:26,160 --> 00:04:30,720
how long its duration was

00:04:28,160 --> 00:04:31,360
here you can see like b and e which look

00:04:30,720 --> 00:04:33,280
more like

00:04:31,360 --> 00:04:35,360
independent services calling one another

00:04:33,280 --> 00:04:36,960
c and d could be for example

00:04:35,360 --> 00:04:39,280
functional level calls within the same

00:04:36,960 --> 00:04:41,040
microservices based application

00:04:39,280 --> 00:04:42,720
but from this we can actually extract

00:04:41,040 --> 00:04:43,520
the red metrics requests error and

00:04:42,720 --> 00:04:46,080
duration

00:04:43,520 --> 00:04:47,919
we can also tack on additional metadata

00:04:46,080 --> 00:04:48,800
and because we have context and

00:04:47,919 --> 00:04:50,800
correlation

00:04:48,800 --> 00:04:51,919
we can actually identify like where

00:04:50,800 --> 00:04:53,919
errors are occurring

00:04:51,919 --> 00:04:55,919
and why they're occurring which really

00:04:53,919 --> 00:04:56,639
helps us get to problem isolation a lot

00:04:55,919 --> 00:04:59,199
faster

00:04:56,639 --> 00:05:01,280
which is super critical in microservices

00:04:59,199 --> 00:05:03,360
based environments that are typically

00:05:01,280 --> 00:05:05,039
polyglot where every service may be

00:05:03,360 --> 00:05:07,360
owned by a different service owner

00:05:05,039 --> 00:05:09,199
and from an on-call perspective you want

00:05:07,360 --> 00:05:09,840
to minimize things like alert storms

00:05:09,199 --> 00:05:14,160
which

00:05:09,840 --> 00:05:14,160
would be very impactful to the team

00:05:14,320 --> 00:05:17,840
now let's talk a little bit about

00:05:15,919 --> 00:05:20,000
sampling and to do that

00:05:17,840 --> 00:05:21,840
i want to talk about the basics now

00:05:20,000 --> 00:05:24,160
sampling is actually a pretty in-depth

00:05:21,840 --> 00:05:25,280
topic but there are some common things

00:05:24,160 --> 00:05:27,199
that you'll hear

00:05:25,280 --> 00:05:28,960
regarding sampling specifically of

00:05:27,199 --> 00:05:31,199
tracing information

00:05:28,960 --> 00:05:33,360
first is the what you've probably heard

00:05:31,199 --> 00:05:34,800
of head based or tail based sampling

00:05:33,360 --> 00:05:36,400
we're actually going to drill into that

00:05:34,800 --> 00:05:38,960
what the differences are and kind of the

00:05:36,400 --> 00:05:40,960
trade-offs of those decisions

00:05:38,960 --> 00:05:43,440
in addition you have the when when does

00:05:40,960 --> 00:05:44,880
the sampling decision actually happen

00:05:43,440 --> 00:05:46,160
and depending on the pipeline that

00:05:44,880 --> 00:05:47,759
you've configured there are different

00:05:46,160 --> 00:05:49,360
stages in which it could occur

00:05:47,759 --> 00:05:51,039
and i'll explain that more in depth in

00:05:49,360 --> 00:05:53,520
just a moment

00:05:51,039 --> 00:05:55,360
you have the where so within a trace you

00:05:53,520 --> 00:05:57,120
have spans within spans you have

00:05:55,360 --> 00:05:59,039
services and operations

00:05:57,120 --> 00:06:01,440
you may have attributes which is kind of

00:05:59,039 --> 00:06:03,120
that metadata or key value pairs

00:06:01,440 --> 00:06:05,280
you even have other information like the

00:06:03,120 --> 00:06:06,240
duration and you may want to make a

00:06:05,280 --> 00:06:08,479
sampling decision

00:06:06,240 --> 00:06:11,600
based on these different pieces of the

00:06:08,479 --> 00:06:14,080
telemetry data that you're collecting

00:06:11,600 --> 00:06:15,919
the how is more of the policy-based way

00:06:14,080 --> 00:06:18,080
to make a sampling decision

00:06:15,919 --> 00:06:19,280
like do i want to do it based on some

00:06:18,080 --> 00:06:21,440
rule or some rate

00:06:19,280 --> 00:06:23,120
do i want to based on the duration or a

00:06:21,440 --> 00:06:24,960
probabilistic way

00:06:23,120 --> 00:06:27,280
what are the trade-offs of those is

00:06:24,960 --> 00:06:29,759
something that we'll cover here as well

00:06:27,280 --> 00:06:30,319
and then finally the why like why would

00:06:29,759 --> 00:06:32,639
you do

00:06:30,319 --> 00:06:34,160
sampling in the first place and at the

00:06:32,639 --> 00:06:36,240
end of the day it has

00:06:34,160 --> 00:06:38,240
everything to do with data and the

00:06:36,240 --> 00:06:41,360
impact that the data has

00:06:38,240 --> 00:06:42,479
to you or the environment or the price

00:06:41,360 --> 00:06:45,759
of the solution that you're

00:06:42,479 --> 00:06:47,919
you're leveraging on the other end so

00:06:45,759 --> 00:06:48,800
let's first drill into head-based

00:06:47,919 --> 00:06:51,759
sampling

00:06:48,800 --> 00:06:53,680
you may remember the service topology

00:06:51,759 --> 00:06:56,000
breakdown from the jaeger documentation

00:06:53,680 --> 00:06:58,240
here's the same representation

00:06:56,000 --> 00:07:00,000
if you do head-based sampling what that

00:06:58,240 --> 00:07:02,080
basically means is

00:07:00,000 --> 00:07:03,599
you make a sampling decision on the

00:07:02,080 --> 00:07:05,759
initial request

00:07:03,599 --> 00:07:07,120
so if the a service here is the service

00:07:05,759 --> 00:07:08,639
that's hit first

00:07:07,120 --> 00:07:10,479
that's when you're going to decide

00:07:08,639 --> 00:07:13,199
whether or not to sample

00:07:10,479 --> 00:07:15,199
that trace now this is very interesting

00:07:13,199 --> 00:07:16,639
because the trace is not completed

00:07:15,199 --> 00:07:18,960
so you don't necessarily know what

00:07:16,639 --> 00:07:21,280
happens later

00:07:18,960 --> 00:07:23,280
now in the case of tail-based sampling

00:07:21,280 --> 00:07:25,680
you actually wait for the entire

00:07:23,280 --> 00:07:28,080
end-to-end request to be completed and

00:07:25,680 --> 00:07:29,840
then based on the entire request

00:07:28,080 --> 00:07:31,680
you then make a sampling decision on

00:07:29,840 --> 00:07:34,000
whether or not you want to process

00:07:31,680 --> 00:07:35,360
and store that information that's the

00:07:34,000 --> 00:07:37,520
primary difference between

00:07:35,360 --> 00:07:39,440
head and tail but there's a lot more

00:07:37,520 --> 00:07:40,960
nuance that we'll cover in just a little

00:07:39,440 --> 00:07:43,440
bit

00:07:40,960 --> 00:07:44,560
now where can you actually make a

00:07:43,440 --> 00:07:46,240
sampling decision

00:07:44,560 --> 00:07:48,160
well that depends a lot on the

00:07:46,240 --> 00:07:50,000
architecture that you've rolled out

00:07:48,160 --> 00:07:51,360
but it's not uncommon that you have one

00:07:50,000 --> 00:07:53,680
or more applications

00:07:51,360 --> 00:07:55,280
and those applications are instrumented

00:07:53,680 --> 00:07:56,240
so you could go ahead and make a

00:07:55,280 --> 00:07:58,879
sampling decision

00:07:56,240 --> 00:08:00,560
in the instrumentation itself you

00:07:58,879 --> 00:08:01,039
probably have rolled out some sort of

00:08:00,560 --> 00:08:02,639
agent

00:08:01,039 --> 00:08:04,960
maybe it actually exists with the

00:08:02,639 --> 00:08:06,479
application or it's more of a host based

00:08:04,960 --> 00:08:08,160
agents you have one per host with

00:08:06,479 --> 00:08:08,960
multiple applications running on a given

00:08:08,160 --> 00:08:10,639
host

00:08:08,960 --> 00:08:12,319
again you could make a sampling decision

00:08:10,639 --> 00:08:13,039
there you could have some sort of

00:08:12,319 --> 00:08:15,440
standalone

00:08:13,039 --> 00:08:16,400
service or collector or aggregator or

00:08:15,440 --> 00:08:18,479
proxy

00:08:16,400 --> 00:08:19,599
usually this is like per data center or

00:08:18,479 --> 00:08:21,199
per region

00:08:19,599 --> 00:08:23,199
and you could make a sampling decision

00:08:21,199 --> 00:08:24,800
there and then of course the back end

00:08:23,199 --> 00:08:26,080
whether you're running your own or

00:08:24,800 --> 00:08:28,800
you're sending to

00:08:26,080 --> 00:08:30,720
a third-party sas solution sampling

00:08:28,800 --> 00:08:31,199
decisions can also be made on the back

00:08:30,720 --> 00:08:33,120
end

00:08:31,199 --> 00:08:34,640
so really anywhere in the entire

00:08:33,120 --> 00:08:36,240
pipeline you can go ahead and make a

00:08:34,640 --> 00:08:39,200
sampling decision

00:08:36,240 --> 00:08:40,479
but what you can sample when well that

00:08:39,200 --> 00:08:42,320
kind of matters

00:08:40,479 --> 00:08:43,599
you can do head-based sampling pretty

00:08:42,320 --> 00:08:45,440
much anywhere

00:08:43,599 --> 00:08:47,200
but in the case of tail-based sampling

00:08:45,440 --> 00:08:49,279
because we actually have to construct

00:08:47,200 --> 00:08:50,480
the entire trace before making that

00:08:49,279 --> 00:08:52,800
sampling decision

00:08:50,480 --> 00:08:54,080
it's typically at the surface or back

00:08:52,800 --> 00:08:55,760
end level

00:08:54,080 --> 00:08:57,440
a little bit more nuanced it may be

00:08:55,760 --> 00:08:59,200
possible to do it in the agent but in

00:08:57,440 --> 00:09:00,640
general you're talking about having a

00:08:59,200 --> 00:09:02,480
service or a back end

00:09:00,640 --> 00:09:04,080
that actually collects all this

00:09:02,480 --> 00:09:04,880
information and makes a decision based

00:09:04,080 --> 00:09:08,240
on an entire

00:09:04,880 --> 00:09:10,720
trace now

00:09:08,240 --> 00:09:11,839
how does tail-based sampling work so i

00:09:10,720 --> 00:09:13,600
mentioned you probably want to do this

00:09:11,839 --> 00:09:14,560
at the service or the back end so let's

00:09:13,600 --> 00:09:17,440
say here i

00:09:14,560 --> 00:09:19,360
again have my topology and i have a

00:09:17,440 --> 00:09:22,000
service deployed so i have three

00:09:19,360 --> 00:09:22,880
collectors satellites proxies whatever

00:09:22,000 --> 00:09:24,959
you want to call them

00:09:22,880 --> 00:09:26,000
i have three of them in my data center

00:09:24,959 --> 00:09:28,240
and

00:09:26,000 --> 00:09:30,560
they are fronted by a load balancer so

00:09:28,240 --> 00:09:32,399
that they can all receive the traffic

00:09:30,560 --> 00:09:34,720
so let's assume that a request comes in

00:09:32,399 --> 00:09:35,440
to my microservices-based application a

00:09:34,720 --> 00:09:38,160
gets hit

00:09:35,440 --> 00:09:39,200
and it's span gets sent to the first

00:09:38,160 --> 00:09:41,120
collector

00:09:39,200 --> 00:09:42,800
and then b gets hit and it gets set to

00:09:41,120 --> 00:09:44,640
the first collector as well

00:09:42,800 --> 00:09:46,480
c gets hit it gets sent to the third

00:09:44,640 --> 00:09:48,399
collector d gets hit it goes to the

00:09:46,480 --> 00:09:50,000
third e goes to the second

00:09:48,399 --> 00:09:51,920
now we have some sort of maybe round

00:09:50,000 --> 00:09:53,519
robin policy base here on the load

00:09:51,920 --> 00:09:56,160
balancer so

00:09:53,519 --> 00:09:57,440
while i have a single request the spans

00:09:56,160 --> 00:09:58,640
have actually gone to different

00:09:57,440 --> 00:10:00,320
collectors

00:09:58,640 --> 00:10:01,839
now this is a problem for tail-based

00:10:00,320 --> 00:10:03,519
sampling because i need to actually

00:10:01,839 --> 00:10:06,000
construct the entire end

00:10:03,519 --> 00:10:06,560
and trace so what i basically need is

00:10:06,000 --> 00:10:09,519
trace

00:10:06,560 --> 00:10:11,200
id based routing now that's typically

00:10:09,519 --> 00:10:13,680
pretty hard to do in the load balancer

00:10:11,200 --> 00:10:14,399
so most solutions today that offer tail

00:10:13,680 --> 00:10:16,640
base

00:10:14,399 --> 00:10:18,000
sampling will actually handle it at this

00:10:16,640 --> 00:10:20,720
collector level

00:10:18,000 --> 00:10:22,800
what ends up happening is like collector

00:10:20,720 --> 00:10:24,240
two here would say hey i realize that

00:10:22,800 --> 00:10:25,839
the trace id is already being stored and

00:10:24,240 --> 00:10:26,399
number one i'm going to actually pass

00:10:25,839 --> 00:10:29,519
this span

00:10:26,399 --> 00:10:30,880
i got from e over to number one and

00:10:29,519 --> 00:10:31,519
number three would do the exact same

00:10:30,880 --> 00:10:33,920
thing

00:10:31,519 --> 00:10:34,560
so the idea is all the spans for a given

00:10:33,920 --> 00:10:36,880
trace

00:10:34,560 --> 00:10:38,560
will appear on the same node and then

00:10:36,880 --> 00:10:40,399
that node can then go ahead and make a

00:10:38,560 --> 00:10:43,839
sampling decision based on the policies

00:10:40,399 --> 00:10:43,839
and rules that have been defined

00:10:44,720 --> 00:10:48,079
now as i mentioned sampling is a rather

00:10:46,800 --> 00:10:50,000
complex topic

00:10:48,079 --> 00:10:51,440
where we covered some of the major

00:10:50,000 --> 00:10:52,959
themes that may come up

00:10:51,440 --> 00:10:55,360
the way that they kind of stitch

00:10:52,959 --> 00:10:57,440
together it depends

00:10:55,360 --> 00:10:58,720
right like probabilistic type rules

00:10:57,440 --> 00:11:00,880
you're typically going to see in more of

00:10:58,720 --> 00:11:03,279
a head-based sampling solution

00:11:00,880 --> 00:11:05,200
adapt adaptive and rule-based things are

00:11:03,279 --> 00:11:06,079
typically more seen on the tail-based

00:11:05,200 --> 00:11:08,160
side

00:11:06,079 --> 00:11:10,720
rate limiting may be able to apply to a

00:11:08,160 --> 00:11:11,920
given service but may not be applicable

00:11:10,720 --> 00:11:14,800
to a given operation

00:11:11,920 --> 00:11:16,560
so only certain aspects of the span

00:11:14,800 --> 00:11:19,360
information can be leveraged

00:11:16,560 --> 00:11:21,200
and then policies really depend on the

00:11:19,360 --> 00:11:22,720
service or the backend capabilities

00:11:21,200 --> 00:11:24,320
whether that's a vendor or an open

00:11:22,720 --> 00:11:26,800
source solution

00:11:24,320 --> 00:11:28,320
these vary greatly upon like what is

00:11:26,800 --> 00:11:29,440
possible from a configuration

00:11:28,320 --> 00:11:30,959
perspective

00:11:29,440 --> 00:11:32,880
and this is really just the tip of the

00:11:30,959 --> 00:11:33,839
iceberg there are more nuance here as

00:11:32,880 --> 00:11:35,519
well but again

00:11:33,839 --> 00:11:37,120
the goal is to focus on the primary

00:11:35,519 --> 00:11:40,480
themes around sampling to give you a

00:11:37,120 --> 00:11:42,240
better understanding of the topic

00:11:40,480 --> 00:11:43,600
with that i'd like to jump into

00:11:42,240 --> 00:11:45,440
trade-offs

00:11:43,600 --> 00:11:48,079
so let's start with head-based sampling

00:11:45,440 --> 00:11:50,800
again some of the pros of this approach

00:11:48,079 --> 00:11:52,079
are it's very easy to configure it and

00:11:50,800 --> 00:11:53,839
to manage it

00:11:52,079 --> 00:11:55,600
in addition it's great at actually

00:11:53,839 --> 00:11:57,120
reducing the amount of data that's being

00:11:55,600 --> 00:12:00,079
sent which is one of the why

00:11:57,120 --> 00:12:02,160
reasons of why you do sampling anyway

00:12:00,079 --> 00:12:02,720
that happens at the the root service

00:12:02,160 --> 00:12:04,240
based

00:12:02,720 --> 00:12:06,959
level that's where you make the sampling

00:12:04,240 --> 00:12:08,560
decision now the cons are

00:12:06,959 --> 00:12:10,800
well i didn't actually wait for the

00:12:08,560 --> 00:12:13,360
entire request to complete

00:12:10,800 --> 00:12:15,920
so i don't know if i'm making an

00:12:13,360 --> 00:12:16,399
educated or a smart sampling decision

00:12:15,920 --> 00:12:19,839
i'm just

00:12:16,399 --> 00:12:20,240
making one very early on another very

00:12:19,839 --> 00:12:22,240
big

00:12:20,240 --> 00:12:23,440
problem is that if i'm making a sampling

00:12:22,240 --> 00:12:25,839
decision at the beginning

00:12:23,440 --> 00:12:27,680
then i probably won't have accurate red

00:12:25,839 --> 00:12:29,519
metrics because i'm not looking at all

00:12:27,680 --> 00:12:30,639
of the calls i'm not actually collecting

00:12:29,519 --> 00:12:33,120
all that data

00:12:30,639 --> 00:12:34,240
and the net result is really incomplete

00:12:33,120 --> 00:12:36,320
observability

00:12:34,240 --> 00:12:38,000
not only have i reduced the data and i

00:12:36,320 --> 00:12:39,760
probably don't have representative sets

00:12:38,000 --> 00:12:41,839
for the things that i care about

00:12:39,760 --> 00:12:43,440
even my red metrics are not a hundred

00:12:41,839 --> 00:12:46,480
percent accurate because i'm not

00:12:43,440 --> 00:12:48,720
analyzing all that data so in general i

00:12:46,480 --> 00:12:50,160
mean if you can avoid this model you

00:12:48,720 --> 00:12:51,920
typically want to

00:12:50,160 --> 00:12:53,600
at a minimum you want to have full

00:12:51,920 --> 00:12:56,079
fidelity metrics you have

00:12:53,600 --> 00:12:58,160
accurate slis or red metrics with

00:12:56,079 --> 00:12:58,720
accurate alerts that you're leveraging

00:12:58,160 --> 00:13:00,079
here

00:12:58,720 --> 00:13:02,800
and typically with head-based sampling

00:13:00,079 --> 00:13:04,800
you can't do that now there can be some

00:13:02,800 --> 00:13:06,399
temporary reasons why you might want to

00:13:04,800 --> 00:13:08,959
enable head-based sampling

00:13:06,399 --> 00:13:10,720
maybe it's controlling the data or cost

00:13:08,959 --> 00:13:12,880
but you just need to know that it really

00:13:10,720 --> 00:13:14,320
can impact your observability and

00:13:12,880 --> 00:13:16,160
typically is not the solution you want

00:13:14,320 --> 00:13:18,480
to head down

00:13:16,160 --> 00:13:20,399
so let's again use a representation of

00:13:18,480 --> 00:13:23,760
head-based sampling here as i mentioned

00:13:20,399 --> 00:13:25,600
it gets made at the parent or root level

00:13:23,760 --> 00:13:28,639
span so here it would be the a

00:13:25,600 --> 00:13:30,240
service well what happens if further on

00:13:28,639 --> 00:13:31,440
i decide i'm not going to sample this

00:13:30,240 --> 00:13:34,160
given trace

00:13:31,440 --> 00:13:36,079
and then when the d service gets called

00:13:34,160 --> 00:13:38,160
it actually generates an error

00:13:36,079 --> 00:13:40,639
well because i made a sampling decision

00:13:38,160 --> 00:13:42,480
when a was originally called and i

00:13:40,639 --> 00:13:44,399
decided not to sample

00:13:42,480 --> 00:13:47,199
the fact that an error was thrown in d

00:13:44,399 --> 00:13:49,120
doesn't matter i've now lost that data

00:13:47,199 --> 00:13:50,959
that really impacts my observability i

00:13:49,120 --> 00:13:52,480
can't alert on that scenario

00:13:50,959 --> 00:13:54,240
like if someone's on call they can't

00:13:52,480 --> 00:13:57,360
actually pull up that trace

00:13:54,240 --> 00:13:59,199
that's a huge impact to my ability to

00:13:57,360 --> 00:14:01,120
ask any question of my system and to

00:13:59,199 --> 00:14:02,320
really troubleshoot perform problem

00:14:01,120 --> 00:14:04,639
isolation

00:14:02,320 --> 00:14:06,639
so this is typically not an ideal

00:14:04,639 --> 00:14:08,399
scenario

00:14:06,639 --> 00:14:11,120
tail based sampling on the other side

00:14:08,399 --> 00:14:13,360
actually provides full fidelity metrics

00:14:11,120 --> 00:14:15,040
and it allows you to reduce the data

00:14:13,360 --> 00:14:16,800
based on anything available in the

00:14:15,040 --> 00:14:20,079
telemetry data that you're collecting

00:14:16,800 --> 00:14:22,720
so that's very powerful the cons are

00:14:20,079 --> 00:14:24,639
that it's typically hard to manage and

00:14:22,720 --> 00:14:26,399
it can be quite expensive to actually

00:14:24,639 --> 00:14:28,160
run these collectors i'm talking about

00:14:26,399 --> 00:14:29,600
primarily the customer side

00:14:28,160 --> 00:14:31,760
vendors typically have ways of

00:14:29,600 --> 00:14:33,440
mitigating those cost concerns

00:14:31,760 --> 00:14:35,360
but if the expectation is that you need

00:14:33,440 --> 00:14:37,920
to deploy something on your side

00:14:35,360 --> 00:14:38,480
to do the tail-based sampling that can

00:14:37,920 --> 00:14:40,000
become

00:14:38,480 --> 00:14:41,839
complex you're now talking about a

00:14:40,000 --> 00:14:43,360
distributed systems problem

00:14:41,839 --> 00:14:44,880
you have to handle redundancy what

00:14:43,360 --> 00:14:47,120
happens if they go down

00:14:44,880 --> 00:14:48,800
and it can be expensive to run because a

00:14:47,120 --> 00:14:51,120
hundred percent of the data

00:14:48,800 --> 00:14:53,040
needs to be processed and even network

00:14:51,120 --> 00:14:54,320
traffic can be pretty extensive because

00:14:53,040 --> 00:14:56,240
we need to pass around

00:14:54,320 --> 00:14:58,480
different spans for given trace to the

00:14:56,240 --> 00:15:00,160
right endpoint node

00:14:58,480 --> 00:15:02,320
now at the end of the day another con

00:15:00,160 --> 00:15:04,560
that i wrote is that you have to analyze

00:15:02,320 --> 00:15:06,399
all the data anyway like i mentioned all

00:15:04,560 --> 00:15:08,000
the compute and potentially network

00:15:06,399 --> 00:15:10,639
traffic that's involved with that

00:15:08,000 --> 00:15:12,800
that's actually the primary cost so if

00:15:10,639 --> 00:15:15,920
you already are going to take that hit

00:15:12,800 --> 00:15:17,199
of sampling all that data then then why

00:15:15,920 --> 00:15:18,560
are you doing tail-based sampling in the

00:15:17,199 --> 00:15:19,920
first place now there can be good

00:15:18,560 --> 00:15:21,279
reasons for it

00:15:19,920 --> 00:15:22,959
but it's definitely a question you

00:15:21,279 --> 00:15:25,519
should ask yourself

00:15:22,959 --> 00:15:26,560
so when you're thinking about this if

00:15:25,519 --> 00:15:28,079
you have to sample

00:15:26,560 --> 00:15:29,680
and we'll talk more about whether you do

00:15:28,079 --> 00:15:31,360
or not in just a second

00:15:29,680 --> 00:15:33,040
tail-based sampling is going to be

00:15:31,360 --> 00:15:34,800
better than head-based sampling because

00:15:33,040 --> 00:15:36,800
you now have full fidelity

00:15:34,800 --> 00:15:37,839
accurate metrics you now have

00:15:36,800 --> 00:15:40,480
flexibility

00:15:37,839 --> 00:15:42,240
in actually being being able to choose

00:15:40,480 --> 00:15:45,279
what you sample and not

00:15:42,240 --> 00:15:47,040
there are some potential cons but the

00:15:45,279 --> 00:15:48,160
flexibility and choice here is quite

00:15:47,040 --> 00:15:50,079
powerful

00:15:48,160 --> 00:15:52,000
one thing you do need to consider though

00:15:50,079 --> 00:15:54,320
is you have to factor in both

00:15:52,000 --> 00:15:55,839
capex and opex when you're determining

00:15:54,320 --> 00:15:57,600
the cost of a solution

00:15:55,839 --> 00:15:59,839
running these satellites or collectors

00:15:57,600 --> 00:16:01,519
on your side scaling them up

00:15:59,839 --> 00:16:03,040
making sure that they're they're

00:16:01,519 --> 00:16:04,639
upgraded and handling the network

00:16:03,040 --> 00:16:06,880
traffic that's associated with them

00:16:04,639 --> 00:16:08,880
that's all part of the cost of

00:16:06,880 --> 00:16:09,759
leveraging whatever solution that you

00:16:08,880 --> 00:16:11,360
are

00:16:09,759 --> 00:16:13,360
and then one final thing i didn't write

00:16:11,360 --> 00:16:14,720
this as a con but most tail-based

00:16:13,360 --> 00:16:17,199
solutions don't really have

00:16:14,720 --> 00:16:19,120
enterprise-y features like encryption

00:16:17,199 --> 00:16:20,800
between the satellites or some sort of

00:16:19,120 --> 00:16:21,440
dispatch queue it's usually all in

00:16:20,800 --> 00:16:23,600
memory

00:16:21,440 --> 00:16:25,040
this isn't necessarily a big deal it

00:16:23,600 --> 00:16:26,079
comes down to really business

00:16:25,040 --> 00:16:28,160
requirements

00:16:26,079 --> 00:16:31,279
like a lot of people don't treat tracing

00:16:28,160 --> 00:16:32,880
data as containing much or any pii

00:16:31,279 --> 00:16:34,320
it's not necessarily the end of the

00:16:32,880 --> 00:16:36,160
world if you lose that data like it's

00:16:34,320 --> 00:16:37,199
not ideal if you're having an incident

00:16:36,160 --> 00:16:39,199
or an outage

00:16:37,199 --> 00:16:41,600
but at other times maybe it's not as

00:16:39,199 --> 00:16:42,959
critical if some of that data is lost

00:16:41,600 --> 00:16:44,320
just something to keep in mind when

00:16:42,959 --> 00:16:45,040
you're actually evaluating these

00:16:44,320 --> 00:16:48,399
solutions

00:16:45,040 --> 00:16:50,000
as well so let's again go back to the

00:16:48,399 --> 00:16:51,920
tail-based sampling example

00:16:50,000 --> 00:16:54,240
and how it works as i mentioned there

00:16:51,920 --> 00:16:55,839
are a few different considerations here

00:16:54,240 --> 00:16:58,079
so let's assume that i have my

00:16:55,839 --> 00:16:59,759
end-to-end app deployed in

00:16:58,079 --> 00:17:01,120
i don't know i'm in aws so i'm in a

00:16:59,759 --> 00:17:03,120
single region

00:17:01,120 --> 00:17:05,360
and it's going to be deployed in

00:17:03,120 --> 00:17:06,240
multiple availability zones azs because

00:17:05,360 --> 00:17:08,240
i want to have

00:17:06,240 --> 00:17:10,079
high availability in case an ac goes

00:17:08,240 --> 00:17:12,160
down so these

00:17:10,079 --> 00:17:13,199
satellites may be deployed in a single

00:17:12,160 --> 00:17:15,600
az or across

00:17:13,199 --> 00:17:16,799
multiple for redundancy reasons well the

00:17:15,600 --> 00:17:19,360
net result there

00:17:16,799 --> 00:17:21,360
is that if i'm going across az's i need

00:17:19,360 --> 00:17:23,679
to pay for that network traffic

00:17:21,360 --> 00:17:25,360
both my services contacting the right

00:17:23,679 --> 00:17:26,079
node depending on how load balancing is

00:17:25,360 --> 00:17:27,839
configured

00:17:26,079 --> 00:17:30,400
as well as the nodes talking to each

00:17:27,839 --> 00:17:33,360
other to do the trace id based routing

00:17:30,400 --> 00:17:34,160
that incurs a cost it's even more

00:17:33,360 --> 00:17:36,320
complex

00:17:34,160 --> 00:17:38,720
if i actually have an end-to-end request

00:17:36,320 --> 00:17:41,120
that spans multiple different regions

00:17:38,720 --> 00:17:43,200
and there are valid use cases for that

00:17:41,120 --> 00:17:44,960
in that case i might have my services in

00:17:43,200 --> 00:17:46,559
region one and region two

00:17:44,960 --> 00:17:48,480
well i have to have this set of

00:17:46,559 --> 00:17:50,559
satellites in a single region

00:17:48,480 --> 00:17:51,679
it doesn't matter if it's in one two or

00:17:50,559 --> 00:17:53,440
even three

00:17:51,679 --> 00:17:55,120
but all the traffic needs to go to a

00:17:53,440 --> 00:17:56,720
single region so that i can actually

00:17:55,120 --> 00:17:59,440
collect a single trace and

00:17:56,720 --> 00:18:00,799
end well that map now means i might have

00:17:59,440 --> 00:18:02,720
cross region traffic

00:18:00,799 --> 00:18:03,840
network wise that i need to pay for as

00:18:02,720 --> 00:18:05,840
well

00:18:03,840 --> 00:18:07,200
and then as i mentioned earlier at the

00:18:05,840 --> 00:18:09,120
end of the day it's really

00:18:07,200 --> 00:18:10,720
all the overhead of all the traffic

00:18:09,120 --> 00:18:11,840
needs to be able to be processed by

00:18:10,720 --> 00:18:13,600
these satellites

00:18:11,840 --> 00:18:15,760
the amount of compute power memory that

00:18:13,600 --> 00:18:16,960
this requires can be extensive

00:18:15,760 --> 00:18:18,880
depending on the solutions that are

00:18:16,960 --> 00:18:19,840
available there may even be disk related

00:18:18,880 --> 00:18:22,559
as well

00:18:19,840 --> 00:18:23,440
that is a cost of leveraging a

00:18:22,559 --> 00:18:26,799
tail-based

00:18:23,440 --> 00:18:29,120
sampling solution so

00:18:26,799 --> 00:18:31,200
now let's go back to the why why would

00:18:29,120 --> 00:18:33,360
you sample in the first place

00:18:31,200 --> 00:18:34,400
and these are some of the common reasons

00:18:33,360 --> 00:18:36,320
that come up

00:18:34,400 --> 00:18:38,000
one of the biggest is just that scaling

00:18:36,320 --> 00:18:40,000
is hard like we're not talking

00:18:38,000 --> 00:18:42,080
about a small amount of data here

00:18:40,000 --> 00:18:43,679
distributed tracing information is

00:18:42,080 --> 00:18:46,240
typically significantly more than

00:18:43,679 --> 00:18:47,679
metrics and it's usually on par with

00:18:46,240 --> 00:18:50,080
logs maybe a little less

00:18:47,679 --> 00:18:50,720
in some cases maybe a little more but

00:18:50,080 --> 00:18:53,120
it's

00:18:50,720 --> 00:18:55,280
pretty extensive and so the back end

00:18:53,120 --> 00:18:56,080
required to actually process and store

00:18:55,280 --> 00:18:58,160
this information

00:18:56,080 --> 00:18:59,280
is quite a bit and then the front end to

00:18:58,160 --> 00:19:01,679
be able to

00:18:59,280 --> 00:19:03,919
query it and display it quickly that's

00:19:01,679 --> 00:19:04,559
also a hard problem it's a big data

00:19:03,919 --> 00:19:06,160
problem

00:19:04,559 --> 00:19:07,760
now this really comes down to are you

00:19:06,160 --> 00:19:09,600
rolling your own like do you have your

00:19:07,760 --> 00:19:10,799
own back end is it open source if you

00:19:09,600 --> 00:19:12,480
built something custom

00:19:10,799 --> 00:19:13,919
and you're just trying to scale it is

00:19:12,480 --> 00:19:15,520
that actually your core ip

00:19:13,919 --> 00:19:17,600
is that where you want to be investing

00:19:15,520 --> 00:19:20,000
your efforts are you going to buy

00:19:17,600 --> 00:19:20,720
instead into a vendor solution what do

00:19:20,000 --> 00:19:22,320
they offer

00:19:20,720 --> 00:19:25,120
right that there's trade-offs to the

00:19:22,320 --> 00:19:27,760
decision the next point is just around

00:19:25,120 --> 00:19:29,280
not all data is equal like if i have a

00:19:27,760 --> 00:19:31,360
trace that contains an error

00:19:29,280 --> 00:19:33,919
that's probably much more valuable than

00:19:31,360 --> 00:19:35,760
a trace that does not contain an error

00:19:33,919 --> 00:19:37,520
same applies with things like duration

00:19:35,760 --> 00:19:40,960
like if i have an outlier if i'm like

00:19:37,520 --> 00:19:42,880
above my p90 or p95 or even p99

00:19:40,960 --> 00:19:44,559
i probably want to keep that data i want

00:19:42,880 --> 00:19:47,200
to understand why i want to have

00:19:44,559 --> 00:19:47,679
more samples of that versus if they're

00:19:47,200 --> 00:19:50,000
all the

00:19:47,679 --> 00:19:50,960
same exact average duration do i really

00:19:50,000 --> 00:19:52,400
need every one

00:19:50,960 --> 00:19:54,559
sure i need them from a metrics

00:19:52,400 --> 00:19:55,840
perspective but do i need the individual

00:19:54,559 --> 00:19:58,799
traces

00:19:55,840 --> 00:20:00,480
and then maybe like i want production to

00:19:58,799 --> 00:20:01,840
to not sample i want development to

00:20:00,480 --> 00:20:03,600
sample heavily just from a cost

00:20:01,840 --> 00:20:04,240
perspective and from an availability

00:20:03,600 --> 00:20:05,840
like if dev

00:20:04,240 --> 00:20:07,600
is down maybe it's not the end of the

00:20:05,840 --> 00:20:09,120
world in my environment again this comes

00:20:07,600 --> 00:20:11,280
down to business requirements and the

00:20:09,120 --> 00:20:13,280
problems you're trying to solve

00:20:11,280 --> 00:20:14,640
but really the biggest reason that comes

00:20:13,280 --> 00:20:16,880
up around sampling is

00:20:14,640 --> 00:20:18,400
cost and when you think of costs you

00:20:16,880 --> 00:20:20,960
need to think of many things the

00:20:18,400 --> 00:20:21,679
processing aspects the network egress

00:20:20,960 --> 00:20:24,480
costs

00:20:21,679 --> 00:20:25,919
the storage costs of containing all that

00:20:24,480 --> 00:20:27,919
data and storing it for whatever

00:20:25,919 --> 00:20:30,159
retention period you care about

00:20:27,919 --> 00:20:31,760
the whole run it versus buy it like are

00:20:30,159 --> 00:20:32,880
you rolling your own back end are you

00:20:31,760 --> 00:20:35,760
rolling your own

00:20:32,880 --> 00:20:37,280
solution to instrumentation or are you

00:20:35,760 --> 00:20:39,039
leveraging open source

00:20:37,280 --> 00:20:41,919
are you doing some open source in some

00:20:39,039 --> 00:20:44,880
vendor and then finally the cost of

00:20:41,919 --> 00:20:46,240
downtime like if i sample and i don't

00:20:44,880 --> 00:20:48,159
have the data that i need if i don't

00:20:46,240 --> 00:20:49,679
have the observability if i can't answer

00:20:48,159 --> 00:20:51,520
the questions i need to

00:20:49,679 --> 00:20:53,600
what does that cost to my business and

00:20:51,520 --> 00:20:55,039
am i willing to actually pay that

00:20:53,600 --> 00:20:56,799
so there's a lot of trade-offs and

00:20:55,039 --> 00:20:59,760
decisions but this is why

00:20:56,799 --> 00:21:01,280
sampling is a real thing in distributed

00:20:59,760 --> 00:21:03,679
tracing

00:21:01,280 --> 00:21:05,679
now i want to kind of warn about the

00:21:03,679 --> 00:21:07,840
marketing hype and now full disclosure i

00:21:05,679 --> 00:21:09,520
work for a vendor so this applies just

00:21:07,840 --> 00:21:11,760
as much the company i work for

00:21:09,520 --> 00:21:13,520
as any other vendor out there any other

00:21:11,760 --> 00:21:15,360
marketing people out there

00:21:13,520 --> 00:21:17,120
but you need to be aware of some things

00:21:15,360 --> 00:21:19,440
when it comes to sampling

00:21:17,120 --> 00:21:21,280
like you'll hear sampling is fine

00:21:19,440 --> 00:21:22,880
because like you have all the data for

00:21:21,280 --> 00:21:24,880
real-time investigation

00:21:22,880 --> 00:21:26,880
what does that mean it usually means you

00:21:24,880 --> 00:21:28,880
have it for a very small window of time

00:21:26,880 --> 00:21:30,799
we're talking minutes maybe five minutes

00:21:28,880 --> 00:21:32,320
maybe 15 max

00:21:30,799 --> 00:21:34,320
sure that's great but what do you do

00:21:32,320 --> 00:21:35,360
after the fact or

00:21:34,320 --> 00:21:37,679
we're going to get all the most

00:21:35,360 --> 00:21:39,600
interesting things for you how do i know

00:21:37,679 --> 00:21:41,280
how do i trust and verify that how do i

00:21:39,600 --> 00:21:43,360
tweak that what if i need something else

00:21:41,280 --> 00:21:45,360
that i think is interesting

00:21:43,360 --> 00:21:47,120
is that okay again it comes down to

00:21:45,360 --> 00:21:49,120
business requirements

00:21:47,120 --> 00:21:51,120
another one is for just around like you

00:21:49,120 --> 00:21:52,080
have to sample because it's just too

00:21:51,120 --> 00:21:53,280
much data

00:21:52,080 --> 00:21:55,679
a lot of this comes out of like the

00:21:53,280 --> 00:21:57,360
dapper paper that came from google

00:21:55,679 --> 00:21:59,679
but one of the things you should ask is

00:21:57,360 --> 00:22:00,240
like am am i working at a fang company

00:21:59,679 --> 00:22:02,480
where

00:22:00,240 --> 00:22:04,720
there is just so much data that i

00:22:02,480 --> 00:22:08,000
absolutely have to do something about it

00:22:04,720 --> 00:22:10,480
most of us are not in that category and

00:22:08,000 --> 00:22:12,559
even at millions of spans per second

00:22:10,480 --> 00:22:13,440
it's not as much of a problem as you

00:22:12,559 --> 00:22:14,960
might think

00:22:13,440 --> 00:22:16,240
now eventually you will hit some

00:22:14,960 --> 00:22:17,280
threshold where you need to start

00:22:16,240 --> 00:22:19,039
considering it

00:22:17,280 --> 00:22:20,400
but not every company out there is a

00:22:19,039 --> 00:22:21,840
google company so

00:22:20,400 --> 00:22:23,440
you need to take that with a grain of

00:22:21,840 --> 00:22:24,480
salt as well

00:22:23,440 --> 00:22:26,000
are you going to manage your own

00:22:24,480 --> 00:22:27,520
observability back end are you going to

00:22:26,000 --> 00:22:29,039
use open source are you going to use a

00:22:27,520 --> 00:22:31,760
vendor solution

00:22:29,039 --> 00:22:33,360
all of that kind of dictates the amount

00:22:31,760 --> 00:22:35,440
of data that you can collect and

00:22:33,360 --> 00:22:36,799
of course the cost associated with that

00:22:35,440 --> 00:22:38,320
and then finally like

00:22:36,799 --> 00:22:40,799
what have you done to instrument your

00:22:38,320 --> 00:22:42,480
applications and if it is so verbose if

00:22:40,799 --> 00:22:44,320
you do have so much traffic

00:22:42,480 --> 00:22:46,000
why what problems are you trying to

00:22:44,320 --> 00:22:48,080
solve is that necessary

00:22:46,000 --> 00:22:49,440
did you instrument too much do you have

00:22:48,080 --> 00:22:51,120
too much metadata

00:22:49,440 --> 00:22:53,200
like is the instrumentation that you

00:22:51,120 --> 00:22:54,880
provided valuable or not

00:22:53,200 --> 00:22:56,559
because that might be a better problem

00:22:54,880 --> 00:22:58,480
to go solve than whether or not you

00:22:56,559 --> 00:23:00,720
sample the data

00:22:58,480 --> 00:23:01,919
and then finally just around hey our

00:23:00,720 --> 00:23:03,919
solution's cheaper

00:23:01,919 --> 00:23:05,360
because typically of sampling again you

00:23:03,919 --> 00:23:05,760
have to look at the whole ownership

00:23:05,360 --> 00:23:07,360
thing

00:23:05,760 --> 00:23:09,440
tail-based sampling doesn't come for

00:23:07,360 --> 00:23:11,280
free that cost comes from somewhere

00:23:09,440 --> 00:23:12,960
either it's on your end or it's on the

00:23:11,280 --> 00:23:14,320
vendor end but there is a cost

00:23:12,960 --> 00:23:16,559
associated with it

00:23:14,320 --> 00:23:17,919
if you sample you're going to lose some

00:23:16,559 --> 00:23:20,240
amount of observability

00:23:17,919 --> 00:23:22,159
how much is acceptable typically head

00:23:20,240 --> 00:23:23,520
base without the full fidelity metrics

00:23:22,159 --> 00:23:24,720
that's not going to be good enough for

00:23:23,520 --> 00:23:26,320
most environments

00:23:24,720 --> 00:23:28,000
but tail-based sampling where i may not

00:23:26,320 --> 00:23:28,799
have every trace but i do have fully

00:23:28,000 --> 00:23:31,360
accurate

00:23:28,799 --> 00:23:32,799
metrics and slis usually that is

00:23:31,360 --> 00:23:35,919
sufficient

00:23:32,799 --> 00:23:38,000
and then are your specific business

00:23:35,919 --> 00:23:38,400
requirements and desired outcomes being

00:23:38,000 --> 00:23:39,760
met

00:23:38,400 --> 00:23:41,600
that at the end of the day that's really

00:23:39,760 --> 00:23:43,440
the most important thing

00:23:41,600 --> 00:23:45,039
now with that i want to give a quick

00:23:43,440 --> 00:23:47,200
demo i will actually use the open

00:23:45,039 --> 00:23:50,400
telemetry project to do this

00:23:47,200 --> 00:23:53,520
i'm actually going to fire up a

00:23:50,400 --> 00:23:54,720
docker compose here and i will walk you

00:23:53,520 --> 00:23:58,240
through what it's doing

00:23:54,720 --> 00:24:00,960
as it starts running so

00:23:58,240 --> 00:24:02,799
uh what we basically have is an open

00:24:00,960 --> 00:24:05,840
telemetry collector

00:24:02,799 --> 00:24:08,559
and in that open telemetry collector we

00:24:05,840 --> 00:24:09,679
are going to point to three different

00:24:08,559 --> 00:24:12,159
jaeger instances

00:24:09,679 --> 00:24:14,159
so jaeger's distributed tracing back end

00:24:12,159 --> 00:24:16,559
and what i've done is i've configured

00:24:14,159 --> 00:24:17,679
three different pipelines uh in the open

00:24:16,559 --> 00:24:20,480
telemetry collector

00:24:17,679 --> 00:24:21,600
so basically we're going to receive 100

00:24:20,480 --> 00:24:24,799
of the traffic

00:24:21,600 --> 00:24:25,600
and we are going to send it to a jaeger

00:24:24,799 --> 00:24:28,080
instance

00:24:25,600 --> 00:24:28,799
we are going to use a probabilistic

00:24:28,080 --> 00:24:30,960
sampler

00:24:28,799 --> 00:24:32,000
and send a subset of that traffic to a

00:24:30,960 --> 00:24:33,120
second jaeger

00:24:32,000 --> 00:24:34,720
instance and then we're going to

00:24:33,120 --> 00:24:36,480
leverage tail based sampling and we're

00:24:34,720 --> 00:24:38,240
going to send it to a third instance

00:24:36,480 --> 00:24:40,640
this also kind of show you the pros and

00:24:38,240 --> 00:24:42,720
cons of the of the different approaches

00:24:40,640 --> 00:24:44,640
now from a configuration perspective the

00:24:42,720 --> 00:24:45,360
probabilistic sampler the head-based

00:24:44,640 --> 00:24:47,520
sampling

00:24:45,360 --> 00:24:49,520
is configured to sample one percent of

00:24:47,520 --> 00:24:51,200
the traffic again this is customizable

00:24:49,520 --> 00:24:53,039
so i could say five percent i could say

00:24:51,200 --> 00:24:53,760
zero point one percent i could say fifty

00:24:53,039 --> 00:24:56,400
percent

00:24:53,760 --> 00:24:58,000
it's really configurable to your needs

00:24:56,400 --> 00:24:58,400
tail-based sampling what we're going to

00:24:58,000 --> 00:25:00,559
do

00:24:58,400 --> 00:25:02,000
is we're going to tell it that we have a

00:25:00,559 --> 00:25:04,320
couple policies

00:25:02,000 --> 00:25:05,760
one is if it contains an attribute of

00:25:04,320 --> 00:25:08,240
error equals true

00:25:05,760 --> 00:25:08,799
then we're going to sample it and the

00:25:08,240 --> 00:25:11,919
next one

00:25:08,799 --> 00:25:12,720
is if we have an http status code that

00:25:11,919 --> 00:25:16,960
is between

00:25:12,720 --> 00:25:17,600
400 and 599 again we are going to sample

00:25:16,960 --> 00:25:19,600
it

00:25:17,600 --> 00:25:21,600
so this gives me kind of choice these

00:25:19,600 --> 00:25:23,760
are just some examples you might have

00:25:21,600 --> 00:25:24,559
different rules or policies or different

00:25:23,760 --> 00:25:26,400
sampling

00:25:24,559 --> 00:25:28,240
things that you want to leverage this

00:25:26,400 --> 00:25:30,240
may configure to meet your needs

00:25:28,240 --> 00:25:31,279
but hopefully this will give you an idea

00:25:30,240 --> 00:25:34,000
of how it

00:25:31,279 --> 00:25:35,679
actually works in practice now on the

00:25:34,000 --> 00:25:36,880
flip side i mentioned this is a docker

00:25:35,679 --> 00:25:39,279
compose file

00:25:36,880 --> 00:25:40,000
so we have three jaeger instances

00:25:39,279 --> 00:25:41,600
running

00:25:40,000 --> 00:25:43,120
we have an open telemetry collector

00:25:41,600 --> 00:25:45,200
running and then we basically have a

00:25:43,120 --> 00:25:46,000
load generator that's passing traffic to

00:25:45,200 --> 00:25:48,480
the collector

00:25:46,000 --> 00:25:50,480
that's basically uh everything here this

00:25:48,480 --> 00:25:52,480
is based on the open symmetry collector

00:25:50,480 --> 00:25:53,440
demo that's in the github repository

00:25:52,480 --> 00:25:56,720
today

00:25:53,440 --> 00:25:58,320
so let's go ahead and fire up the jaeger

00:25:56,720 --> 00:25:59,360
instance that's receiving all of the

00:25:58,320 --> 00:26:01,279
traffic

00:25:59,360 --> 00:26:02,480
so i'll just pick one of the services

00:26:01,279 --> 00:26:03,679
and you'll see that there's traffic

00:26:02,480 --> 00:26:05,360
coming in here

00:26:03,679 --> 00:26:07,039
the cart service is the one that i'm

00:26:05,360 --> 00:26:08,400
looking at particularly so tons of

00:26:07,039 --> 00:26:10,960
traces are coming in

00:26:08,400 --> 00:26:12,720
that's great i will pick the second one

00:26:10,960 --> 00:26:13,600
here this is doing probabilistic

00:26:12,720 --> 00:26:16,080
sampling

00:26:13,600 --> 00:26:17,279
so again i'll pick the cart service and

00:26:16,080 --> 00:26:19,200
you'll see there's actually

00:26:17,279 --> 00:26:21,039
less traces significantly less and

00:26:19,200 --> 00:26:22,799
that's because we're only sampling one

00:26:21,039 --> 00:26:24,720
percent of them

00:26:22,799 --> 00:26:26,240
and then the final one this is the

00:26:24,720 --> 00:26:26,960
tail-based sampling that is only

00:26:26,240 --> 00:26:29,679
capturing

00:26:26,960 --> 00:26:30,880
errors so in this case you'll see again

00:26:29,679 --> 00:26:33,440
cart service

00:26:30,880 --> 00:26:34,559
only cart service traces that contain

00:26:33,440 --> 00:26:37,600
errors are showing up

00:26:34,559 --> 00:26:38,000
you won't see any spans or traces that

00:26:37,600 --> 00:26:39,919
contain

00:26:38,000 --> 00:26:42,080
non-errors because that wouldn't meet

00:26:39,919 --> 00:26:44,880
the tail based sampling rule

00:26:42,080 --> 00:26:45,760
so again three different ways of

00:26:44,880 --> 00:26:48,400
collecting

00:26:45,760 --> 00:26:49,520
no sampling error-based sampling

00:26:48,400 --> 00:26:52,400
probabilistic

00:26:49,520 --> 00:26:54,159
sampling at a one percent rate very easy

00:26:52,400 --> 00:26:55,679
to get started very easy to kind of

00:26:54,159 --> 00:26:57,440
configure in your environments

00:26:55,679 --> 00:26:59,520
and then you can solve more of the scale

00:26:57,440 --> 00:27:01,120
problems or the different policies that

00:26:59,520 --> 00:27:02,159
you care about the rules you want to

00:27:01,120 --> 00:27:05,360
write for making

00:27:02,159 --> 00:27:07,440
these sampling decisions

00:27:05,360 --> 00:27:08,640
so some key takeaways from this

00:27:07,440 --> 00:27:10,720
presentation

00:27:08,640 --> 00:27:12,640
one is definitely understand your

00:27:10,720 --> 00:27:13,279
business requirements and the desired

00:27:12,640 --> 00:27:14,559
outcomes

00:27:13,279 --> 00:27:16,400
every environment's a little bit

00:27:14,559 --> 00:27:17,760
different what are you trying to solve

00:27:16,400 --> 00:27:19,120
for what are the pain points

00:27:17,760 --> 00:27:21,679
you have what visibility and

00:27:19,120 --> 00:27:24,320
observability do you really need

00:27:21,679 --> 00:27:25,360
second understand your sampling options

00:27:24,320 --> 00:27:28,640
understand their

00:27:25,360 --> 00:27:30,159
impact to both cost and observability

00:27:28,640 --> 00:27:31,840
and compare that against your business

00:27:30,159 --> 00:27:34,080
requirements and desired outcomes and

00:27:31,840 --> 00:27:36,000
decide what is right for you

00:27:34,080 --> 00:27:37,200
and then finally beware of the marketing

00:27:36,000 --> 00:27:38,880
hype there's a lot of

00:27:37,200 --> 00:27:41,120
a lot of information out there it can be

00:27:38,880 --> 00:27:43,760
hard to kind of navigate all the noise

00:27:41,120 --> 00:27:46,320
there's also like traditional more

00:27:43,760 --> 00:27:48,080
solutions versus cloud native solutions

00:27:46,320 --> 00:27:49,360
and the thought processes are a little

00:27:48,080 --> 00:27:51,440
bit different

00:27:49,360 --> 00:27:53,120
do your own research and again the

00:27:51,440 --> 00:27:54,720
foundation should be your business

00:27:53,120 --> 00:27:56,240
requirements and desired outcomes and

00:27:54,720 --> 00:27:58,640
what you're trying to solve for

00:27:56,240 --> 00:28:00,000
what you're trying to optimize for and

00:27:58,640 --> 00:28:01,919
do you actually get the

00:28:00,000 --> 00:28:03,039
the insights that you need to ensure

00:28:01,919 --> 00:28:05,360
that your service

00:28:03,039 --> 00:28:06,960
your business is successful at the end

00:28:05,360 --> 00:28:08,640
of the day

00:28:06,960 --> 00:28:10,799
and with that thank you so much for

00:28:08,640 --> 00:28:12,000
joining me this is really just an

00:28:10,799 --> 00:28:13,520
introduction to

00:28:12,000 --> 00:28:15,039
different types of sampling things that

00:28:13,520 --> 00:28:16,640
you're going to come across specifically

00:28:15,039 --> 00:28:18,399
for distributed tracing

00:28:16,640 --> 00:28:20,559
i would love to talk to folks more about

00:28:18,399 --> 00:28:23,840
it feel free to reach out to me directly

00:28:20,559 --> 00:28:23,840
and thanks so much for joining

00:28:27,760 --> 00:28:31,760
okay thank you steve thank you for your

00:28:31,039 --> 00:28:33,919
sharing

00:28:31,760 --> 00:28:34,960
and your slides it's very nice and

00:28:33,919 --> 00:28:39,279
helpful

00:28:34,960 --> 00:28:42,559
and it it's our q and a online time

00:28:39,279 --> 00:28:45,760
let's welcome steve hi steve

00:28:42,559 --> 00:28:49,279
hope you're here uh

00:28:45,760 --> 00:28:50,640
it's our online a time and let's check

00:28:49,279 --> 00:28:55,360
out the

00:28:50,640 --> 00:28:58,080
check box we got three questions for you

00:28:55,360 --> 00:29:00,399
so please yeah go ahead so the first one

00:28:58,080 --> 00:29:02,240
is uh will cloud native observability be

00:29:00,399 --> 00:29:04,080
a topic that will have like a training

00:29:02,240 --> 00:29:06,000
course and certification

00:29:04,080 --> 00:29:08,320
i think long term that wouldn't be too

00:29:06,000 --> 00:29:10,480
surprising uh in fact right now in the

00:29:08,320 --> 00:29:12,240
cncf they actually started a

00:29:10,480 --> 00:29:14,320
sig or special interest group on

00:29:12,240 --> 00:29:15,760
observability and some of these topics

00:29:14,320 --> 00:29:17,679
are being discussed like what is the

00:29:15,760 --> 00:29:20,080
best way to start promoting and getting

00:29:17,679 --> 00:29:21,760
more educated about observability

00:29:20,080 --> 00:29:23,600
some of the initial thoughts are around

00:29:21,760 --> 00:29:25,360
more blogs and just

00:29:23,600 --> 00:29:27,360
other ways of getting material around

00:29:25,360 --> 00:29:29,600
observability but long term

00:29:27,360 --> 00:29:31,440
sure like this is an important topic a

00:29:29,600 --> 00:29:33,520
lot of the projects in cncf

00:29:31,440 --> 00:29:35,039
are observability based jaeger being a

00:29:33,520 --> 00:29:37,679
big one fluent

00:29:35,039 --> 00:29:38,960
fluent bits in there so yeah i think

00:29:37,679 --> 00:29:41,120
long term that'll happen

00:29:38,960 --> 00:29:43,200
i'm not aware of any immediate plans for

00:29:41,120 --> 00:29:45,360
that though

00:29:43,200 --> 00:29:47,360
next question uh your recommendation to

00:29:45,360 --> 00:29:49,200
end users that want to build their own

00:29:47,360 --> 00:29:51,679
solutions for observability

00:29:49,200 --> 00:29:53,039
yeah so there's start with cncf or start

00:29:51,679 --> 00:29:54,480
with open source projects

00:29:53,039 --> 00:29:56,799
there's some good stuff out there like

00:29:54,480 --> 00:29:58,960
jager is a very very scalable product

00:29:56,799 --> 00:30:00,559
very easy to get started they actually

00:29:58,960 --> 00:30:02,159
have decoupled the architecture very

00:30:00,559 --> 00:30:04,720
well so it's easy to scale up

00:30:02,159 --> 00:30:06,799
individual components as the the amount

00:30:04,720 --> 00:30:08,399
of data that you're collecting increases

00:30:06,799 --> 00:30:10,159
and they can support more streaming

00:30:08,399 --> 00:30:12,399
based systems if you need it

00:30:10,159 --> 00:30:14,399
from a logging perspective fluent bit is

00:30:12,399 --> 00:30:14,960
also very efficient at collecting this

00:30:14,399 --> 00:30:16,720
data

00:30:14,960 --> 00:30:18,480
it has rich parsing rules so actually

00:30:16,720 --> 00:30:19,200
get the data in the format that you care

00:30:18,480 --> 00:30:22,320
about

00:30:19,200 --> 00:30:24,080
prometheus again great metricking tool

00:30:22,320 --> 00:30:25,840
to to collect in more cloud native

00:30:24,080 --> 00:30:27,520
environments very common

00:30:25,840 --> 00:30:29,200
becoming kind of the standard way to

00:30:27,520 --> 00:30:31,760
collect metrics today

00:30:29,200 --> 00:30:33,120
uh compared to other other mechanisms so

00:30:31,760 --> 00:30:34,000
you can definitely start with the open

00:30:33,120 --> 00:30:35,520
source tools

00:30:34,000 --> 00:30:37,200
and then you'll probably start building

00:30:35,520 --> 00:30:39,120
on top of them like hey

00:30:37,200 --> 00:30:40,320
i have prometheus and now i want to have

00:30:39,120 --> 00:30:43,840
high availability

00:30:40,320 --> 00:30:46,320
or i want to scale this to a significant

00:30:43,840 --> 00:30:47,919
a very large scale how do i do that and

00:30:46,320 --> 00:30:50,159
again there are open source solutions

00:30:47,919 --> 00:30:52,000
out there to to get you started

00:30:50,159 --> 00:30:53,360
so from a getting started perspective

00:30:52,000 --> 00:30:55,200
it's really easy

00:30:53,360 --> 00:30:57,440
if you're looking for a single tool that

00:30:55,200 --> 00:31:00,240
provides all the different data sources

00:30:57,440 --> 00:31:02,399
and a way to kind of quarry against them

00:31:00,240 --> 00:31:04,720
that's not as common today

00:31:02,399 --> 00:31:06,320
and as you get to more like enterprise

00:31:04,720 --> 00:31:08,399
features like i care about

00:31:06,320 --> 00:31:10,240
massive scale or i care about end-to-end

00:31:08,399 --> 00:31:13,039
encryption or i care about

00:31:10,240 --> 00:31:15,279
uh very rich pii or personally

00:31:13,039 --> 00:31:17,360
identifying information being extracted

00:31:15,279 --> 00:31:19,279
that can be a little bit harder but

00:31:17,360 --> 00:31:20,399
there are solutions out there for both

00:31:19,279 --> 00:31:23,919
open source and

00:31:20,399 --> 00:31:23,919
and commercial depending on your needs

00:31:24,080 --> 00:31:27,360
and then final one is around istio and

00:31:26,480 --> 00:31:29,279
asking if

00:31:27,360 --> 00:31:31,440
is there any solution to get end-to-end

00:31:29,279 --> 00:31:32,000
request training working without span

00:31:31,440 --> 00:31:34,159
context

00:31:32,000 --> 00:31:35,279
propagation as this will make it easier

00:31:34,159 --> 00:31:37,120
and motivate more

00:31:35,279 --> 00:31:38,559
customers to kind of take advantage of

00:31:37,120 --> 00:31:40,559
this or more end users

00:31:38,559 --> 00:31:42,240
take advantage of this yes let me break

00:31:40,559 --> 00:31:42,799
this down for people that are not aware

00:31:42,240 --> 00:31:45,360
so

00:31:42,799 --> 00:31:46,640
istio is a service mesh basically how it

00:31:45,360 --> 00:31:48,640
works is you deport

00:31:46,640 --> 00:31:49,679
deploy proxies to every one of your

00:31:48,640 --> 00:31:51,679
applications

00:31:49,679 --> 00:31:53,519
and all of your traffic between

00:31:51,679 --> 00:31:54,720
applications get routed across these

00:31:53,519 --> 00:31:56,720
proxies

00:31:54,720 --> 00:31:58,960
so because there's a proxy in between

00:31:56,720 --> 00:32:01,919
you can actually inspect that traffic

00:31:58,960 --> 00:32:03,840
and as a result one common question is

00:32:01,919 --> 00:32:04,640
well hey if i'm inspecting this traffic

00:32:03,840 --> 00:32:06,320
anyway

00:32:04,640 --> 00:32:09,279
can i get my distributed tracing

00:32:06,320 --> 00:32:10,880
information from that inspected traffic

00:32:09,279 --> 00:32:13,039
and the answer is of course yes you

00:32:10,880 --> 00:32:15,200
definitely can uh now i need i need to

00:32:13,039 --> 00:32:17,679
take a step back to answer the question

00:32:15,200 --> 00:32:18,320
with distributed tracing it works via

00:32:17,679 --> 00:32:20,159
something called

00:32:18,320 --> 00:32:22,159
context propagation i talked about this

00:32:20,159 --> 00:32:24,240
a little bit in the presentation

00:32:22,159 --> 00:32:25,600
uh basically you if i'm thinking about

00:32:24,240 --> 00:32:28,080
like rpc

00:32:25,600 --> 00:32:29,840
or remote protocol like type things like

00:32:28,080 --> 00:32:31,279
let's think of restful services

00:32:29,840 --> 00:32:33,679
it basically means i need to pass

00:32:31,279 --> 00:32:35,919
headers across each one of my requests

00:32:33,679 --> 00:32:37,840
so for example the trace id i have to

00:32:35,919 --> 00:32:39,039
pass that to every single call i make

00:32:37,840 --> 00:32:41,279
over the network

00:32:39,039 --> 00:32:42,080
well what happens if my application

00:32:41,279 --> 00:32:44,960
doesn't actually

00:32:42,080 --> 00:32:46,799
accept or pass these headers well then

00:32:44,960 --> 00:32:49,279
context propagation is broken and as a

00:32:46,799 --> 00:32:52,320
result my distributed tracing is broken

00:32:49,279 --> 00:32:55,600
that's a problem so while istio or

00:32:52,320 --> 00:32:57,440
any service mesh can provide traffic

00:32:55,600 --> 00:32:58,720
about everything can provide trace

00:32:57,440 --> 00:32:59,760
information about everything that passes

00:32:58,720 --> 00:33:02,640
through the proxy

00:32:59,760 --> 00:33:04,080
it can't guarantee that the headers that

00:33:02,640 --> 00:33:05,519
are being passed through the proxy that

00:33:04,080 --> 00:33:07,840
the application actually accepts and

00:33:05,519 --> 00:33:10,559
propagates to its downstream calls

00:33:07,840 --> 00:33:12,159
so unfortunately the answer is no there

00:33:10,559 --> 00:33:14,159
is no easy way

00:33:12,159 --> 00:33:15,519
yes you can get some rich information

00:33:14,159 --> 00:33:17,200
from these proxies

00:33:15,519 --> 00:33:19,440
but if you really want to take advantage

00:33:17,200 --> 00:33:20,880
of distributed tracing you need to have

00:33:19,440 --> 00:33:22,799
context propagation

00:33:20,880 --> 00:33:24,159
in fact if anyone is getting started

00:33:22,799 --> 00:33:25,919
with observability

00:33:24,159 --> 00:33:27,919
don't start with a logging tool or a

00:33:25,919 --> 00:33:29,200
metric tool or tracing tool start with

00:33:27,919 --> 00:33:32,080
context propagation

00:33:29,200 --> 00:33:33,600
because that alone enables so much for

00:33:32,080 --> 00:33:34,480
you in your environment to be able to

00:33:33,600 --> 00:33:36,840
troubleshoot

00:33:34,480 --> 00:33:39,679
availability as well as performance

00:33:36,840 --> 00:33:42,880
problems

00:33:39,679 --> 00:33:45,360
uh next question is

00:33:42,880 --> 00:33:46,080
google's hipster is not supporting open

00:33:45,360 --> 00:33:48,080
telemetry

00:33:46,080 --> 00:33:49,679
is there any way to get the hipster demo

00:33:48,080 --> 00:33:51,360
ah okay so yeah so the

00:33:49,679 --> 00:33:53,600
so open symmetry is the joining of two

00:33:51,360 --> 00:33:54,399
different projects open tracing and open

00:33:53,600 --> 00:33:57,120
census

00:33:54,399 --> 00:33:58,799
open census has something called the

00:33:57,120 --> 00:34:01,679
hipster demo application

00:33:58,799 --> 00:34:02,640
so it's basically a poly polyglot micro

00:34:01,679 --> 00:34:04,640
services

00:34:02,640 --> 00:34:05,679
application that was instrumented with

00:34:04,640 --> 00:34:07,600
open census

00:34:05,679 --> 00:34:09,359
and it was used as a demo environment to

00:34:07,600 --> 00:34:10,159
kind of show off the power of open

00:34:09,359 --> 00:34:12,240
census

00:34:10,159 --> 00:34:13,599
we are actually using it for open

00:34:12,240 --> 00:34:16,720
symmetry as well

00:34:13,599 --> 00:34:18,639
so open symmetry merges open census and

00:34:16,720 --> 00:34:21,040
open tracing together it actually

00:34:18,639 --> 00:34:22,800
supports the open census format

00:34:21,040 --> 00:34:24,079
so the fact that the hipster demo app is

00:34:22,800 --> 00:34:26,079
sending open census is

00:34:24,079 --> 00:34:27,440
totally fine now i'm assuming the

00:34:26,079 --> 00:34:28,560
question is just around well hey it

00:34:27,440 --> 00:34:30,560
doesn't support

00:34:28,560 --> 00:34:31,599
open telemetry's format which is called

00:34:30,560 --> 00:34:33,599
otop

00:34:31,599 --> 00:34:35,839
and that's true it doesn't and the

00:34:33,599 --> 00:34:37,919
reason for that is because otop was just

00:34:35,839 --> 00:34:40,800
finalized less than a month ago

00:34:37,919 --> 00:34:42,800
so it's very new and we were waiting for

00:34:40,800 --> 00:34:45,040
the tracing spec to become

00:34:42,800 --> 00:34:47,040
finalized and waiting for the otop

00:34:45,040 --> 00:34:48,159
protocol to the first version of it to

00:34:47,040 --> 00:34:49,679
be rolled out

00:34:48,159 --> 00:34:51,919
that's now done so i think you'll

00:34:49,679 --> 00:34:53,440
actually see the hipster demo app be

00:34:51,919 --> 00:34:54,079
instrumented with open symmetry going

00:34:53,440 --> 00:34:55,919
forward

00:34:54,079 --> 00:34:58,160
but there's no reason why you can't use

00:34:55,919 --> 00:34:59,839
it with the open symmetry project today

00:34:58,160 --> 00:35:01,280
because the open symmetry project does

00:34:59,839 --> 00:35:02,960
support open census

00:35:01,280 --> 00:35:05,119
so if you have the collector for example

00:35:02,960 --> 00:35:05,839
you can receive and export open census

00:35:05,119 --> 00:35:08,240
format

00:35:05,839 --> 00:35:10,240
so the same demo application can be used

00:35:08,240 --> 00:35:12,160
i know that i still use the hipster demo

00:35:10,240 --> 00:35:15,119
app today when i'm showing off

00:35:12,160 --> 00:35:16,560
open telemetry there's also a question

00:35:15,119 --> 00:35:18,000
about how do you get this tracing

00:35:16,560 --> 00:35:19,839
hipster demo application

00:35:18,000 --> 00:35:21,359
i don't have the link readily available

00:35:19,839 --> 00:35:24,520
but i'm pretty sure if you just

00:35:21,359 --> 00:35:26,640
uh go google uh the uh google

00:35:24,520 --> 00:35:29,200
microservices demo application

00:35:26,640 --> 00:35:31,040
it's on github uh i think if you just do

00:35:29,200 --> 00:35:32,320
google hipster microservices you'll

00:35:31,040 --> 00:35:34,400
probably find it

00:35:32,320 --> 00:35:35,760
but on github there is a repository that

00:35:34,400 --> 00:35:37,599
basically lists many different

00:35:35,760 --> 00:35:39,520
microservices it shows off all the

00:35:37,599 --> 00:35:42,960
primary languages so you have like

00:35:39,520 --> 00:35:44,800
net java javascript python

00:35:42,960 --> 00:35:47,200
i don't remember all the other ones but

00:35:44,800 --> 00:35:48,880
the idea here is that you can test

00:35:47,200 --> 00:35:50,640
what the instrumentation looks like

00:35:48,880 --> 00:35:51,520
because the instrumentation is language

00:35:50,640 --> 00:35:53,359
specific

00:35:51,520 --> 00:35:54,880
and you can see an end to end request

00:35:53,359 --> 00:35:56,160
calling through these different

00:35:54,880 --> 00:35:56,880
languages and what that would actually

00:35:56,160 --> 00:35:58,880
look like

00:35:56,880 --> 00:36:01,280
in the back end or back ends of your

00:35:58,880 --> 00:36:01,280
choice

00:36:02,320 --> 00:36:07,680
so i think that addresses most of the

00:36:05,040 --> 00:36:10,839
primary questions in the live q a here

00:36:07,680 --> 00:36:12,079
okay is any other questions far about

00:36:10,839 --> 00:36:14,320
tinnies

00:36:12,079 --> 00:36:15,839
okay i think he's no more okay thank you

00:36:14,320 --> 00:36:18,960
steve thank you so much

00:36:15,839 --> 00:36:21,400
i never slide by the way thank you

00:36:18,960 --> 00:36:24,400
thanks so much for having me thank you

00:36:21,400 --> 00:36:24,400

YouTube URL: https://www.youtube.com/watch?v=31poMDrZSug


