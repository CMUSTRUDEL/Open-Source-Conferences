Title: Deep Dive: Unified Runtime Service Infrastructure for Containers and VMs - Yunwen Bai & Peng Du
Publication date: 2020-09-11
Playlist: Cloud Native + Open Source Virtual Summit China 2020
Description: 
	Don’t miss out! Join us at our upcoming events: EnvoyCon Virtual on October 15 and KubeCon + CloudNativeCon North America 2020 Virtual from November 17-20. Learn more at https://kubecon.io The conferences feature presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects. 

Deep Dive: Unified Runtime Service Infrastructure for Containers and VMs - Yunwen Bai & Peng Du, Futurewei 

Nowadays cloud providers offer services orchestrating both containers and VMs with different runtime services. Kubernetes, being a container orchestration platform, uses CRI interfaces which is specifically designed for containers. Extending Kubernetes to support both container and VM types carries sizable challenges in terms of managing multiple runtimes, handling OP differences with container and VM workloads, etc.  In this talk, Peng and Yunwen present a new runtime infrastructure which is designed to address those challenges. They will dive deep into modification in Kubelet for managing multiple runtime services, workload-runtime late binding, partial runtime readiness handling, and the unified runtime interfaces that support both containe and VM workloads and operations such as reboot, snapshot, migration, etc. They will conclude the talk with lessons learned and future works. 

https://sched.co/cp9O
Captions: 
	00:00:01,520 --> 00:00:05,359
hello everyone welcome to the virtual

00:00:04,240 --> 00:00:09,120
conference

00:00:05,359 --> 00:00:11,759
i'm in mumbai i'm hondu today

00:00:09,120 --> 00:00:12,400
paul and i will share with you on the

00:00:11,759 --> 00:00:14,799
unified

00:00:12,400 --> 00:00:17,920
runtime service infrastructure we have

00:00:14,799 --> 00:00:17,920
been working on

00:00:18,240 --> 00:00:21,920
in this talk we will start from the

00:00:20,800 --> 00:00:24,800
motivation

00:00:21,920 --> 00:00:25,760
for the unified platform for vms

00:00:24,800 --> 00:00:28,800
containers

00:00:25,760 --> 00:00:32,079
and bare metals and a high level

00:00:28,800 --> 00:00:35,520
introduction to the project actors

00:00:32,079 --> 00:00:38,160
then we will dive deeper into the design

00:00:35,520 --> 00:00:40,079
and implementation details of the

00:00:38,160 --> 00:00:43,520
unified runtime project

00:00:40,079 --> 00:00:46,079
in actors we will finish this talk

00:00:43,520 --> 00:00:47,840
with a demo and some future works in

00:00:46,079 --> 00:00:50,719
this area

00:00:47,840 --> 00:00:51,280
we hope you can walk away from this talk

00:00:50,719 --> 00:00:53,920
with

00:00:51,280 --> 00:00:55,120
understanding on this novel design and

00:00:53,920 --> 00:00:58,239
even better

00:00:55,120 --> 00:01:01,440
inspired interested and contribute

00:00:58,239 --> 00:01:03,840
to those projects okay let's start with

00:01:01,440 --> 00:01:05,600
background and motivation

00:01:03,840 --> 00:01:07,360
the motivation of this work comes from

00:01:05,600 --> 00:01:08,880
the fact that we want to be able to run

00:01:07,360 --> 00:01:10,240
virtual machine and a container at the

00:01:08,880 --> 00:01:11,920
same time

00:01:10,240 --> 00:01:13,520
traditionally if you want a virtual

00:01:11,920 --> 00:01:14,560
machine you could use openstack for

00:01:13,520 --> 00:01:16,400
container you could use

00:01:14,560 --> 00:01:18,159
kubernetes but they're run as two

00:01:16,400 --> 00:01:19,920
different clusters

00:01:18,159 --> 00:01:21,840
uh at a certain point that we have this

00:01:19,920 --> 00:01:23,600
requirement that okay we want to run

00:01:21,840 --> 00:01:26,479
both virtual machine and container

00:01:23,600 --> 00:01:27,119
in the same bare metal cluster we could

00:01:26,479 --> 00:01:30,400
still use

00:01:27,119 --> 00:01:32,400
two clusters two different stacks

00:01:30,400 --> 00:01:33,920
the problem with that is that it's very

00:01:32,400 --> 00:01:35,600
hard to coordinate the resource

00:01:33,920 --> 00:01:36,960
allocation between these two stack

00:01:35,600 --> 00:01:39,280
because they're being run

00:01:36,960 --> 00:01:41,280
independently of each other this is

00:01:39,280 --> 00:01:43,360
where the new design comes in where we

00:01:41,280 --> 00:01:45,759
just want to have one single layer of

00:01:43,360 --> 00:01:48,240
orchestration between the workloads and

00:01:45,759 --> 00:01:50,880
the bare metal cluster

00:01:48,240 --> 00:01:52,079
there are a few solutions to allow you

00:01:50,880 --> 00:01:54,960
to have vm pod

00:01:52,079 --> 00:01:55,759
in kubernetes for example you could do

00:01:54,960 --> 00:01:57,920
the crd

00:01:55,759 --> 00:02:00,000
and operator solution also you could

00:01:57,920 --> 00:02:02,560
have some external component

00:02:00,000 --> 00:02:03,040
to kubernetes to allow you to access the

00:02:02,560 --> 00:02:06,159
vm

00:02:03,040 --> 00:02:07,920
pod one issue here is that

00:02:06,159 --> 00:02:09,599
by doing this we're still going through

00:02:07,920 --> 00:02:12,400
what the kubernetes provide us

00:02:09,599 --> 00:02:13,680
in terms of the cri interface and that

00:02:12,400 --> 00:02:16,239
has some limitation

00:02:13,680 --> 00:02:16,800
as to what kind of feature you can have

00:02:16,239 --> 00:02:19,840
uh

00:02:16,800 --> 00:02:20,319
in the virtual machine uh with our

00:02:19,840 --> 00:02:22,800
project

00:02:20,319 --> 00:02:24,480
which is called actos we are taking a

00:02:22,800 --> 00:02:27,040
more more of a

00:02:24,480 --> 00:02:29,280
native approach which means we are

00:02:27,040 --> 00:02:31,840
making changes to kubernetes itself

00:02:29,280 --> 00:02:32,640
and by doing this we want to provide the

00:02:31,840 --> 00:02:35,280
virtual machine

00:02:32,640 --> 00:02:36,239
as a first-class citizen and also we

00:02:35,280 --> 00:02:38,319
want to provide

00:02:36,239 --> 00:02:41,519
the full feature for virtual machine

00:02:38,319 --> 00:02:43,280
instead of a simplified one

00:02:41,519 --> 00:02:45,280
uh here are a few challenges we're

00:02:43,280 --> 00:02:47,040
facing first of all we want to provide a

00:02:45,280 --> 00:02:48,319
better solution than just kubernetes

00:02:47,040 --> 00:02:50,319
plus openstack

00:02:48,319 --> 00:02:51,920
as we have discussed we want to provide

00:02:50,319 --> 00:02:52,959
feature like the resource allocation

00:02:51,920 --> 00:02:55,840
coordination

00:02:52,959 --> 00:02:56,080
to this second is we want to stay open

00:02:55,840 --> 00:02:59,280
and

00:02:56,080 --> 00:03:00,480
extensible for future if we have more

00:02:59,280 --> 00:03:03,040
workload types

00:03:00,480 --> 00:03:04,879
we we should be able to adapt to and

00:03:03,040 --> 00:03:08,319
accommodate them

00:03:04,879 --> 00:03:10,400
very easily the third one is uh

00:03:08,319 --> 00:03:11,840
we will have a unified type definition

00:03:10,400 --> 00:03:12,640
for both the virtual machine and the

00:03:11,840 --> 00:03:15,599
container

00:03:12,640 --> 00:03:16,959
what this means is that uh basically

00:03:15,599 --> 00:03:17,440
virtual machine is the first class

00:03:16,959 --> 00:03:20,000
season

00:03:17,440 --> 00:03:20,720
it's not a guest or it's not the add-on

00:03:20,000 --> 00:03:23,920
uh the

00:03:20,720 --> 00:03:25,760
the pilot definition for instance is for

00:03:23,920 --> 00:03:27,840
virtual machine it's very similar to the

00:03:25,760 --> 00:03:30,000
pod definition for containers

00:03:27,840 --> 00:03:31,280
and this also leads us to the the fourth

00:03:30,000 --> 00:03:33,680
challenge

00:03:31,280 --> 00:03:34,799
that we want to provide rich operations

00:03:33,680 --> 00:03:37,280
for virtual machine

00:03:34,799 --> 00:03:39,840
because we're a more native approach we

00:03:37,280 --> 00:03:42,879
are able to extend the cri interface

00:03:39,840 --> 00:03:47,840
and then that allows us the possibility

00:03:42,879 --> 00:03:50,319
of providing more features there

00:03:47,840 --> 00:03:50,879
the actos project has a lot of a lot of

00:03:50,319 --> 00:03:53,200
features

00:03:50,879 --> 00:03:55,120
the unified runtime is one of them this

00:03:53,200 --> 00:03:57,680
is the focus of this talk today

00:03:55,120 --> 00:03:59,280
but if you're interested in other part

00:03:57,680 --> 00:04:01,200
of october's project

00:03:59,280 --> 00:04:04,080
feel free to take a look at our virtual

00:04:01,200 --> 00:04:06,239
booth and also actos project is

00:04:04,080 --> 00:04:07,840
is part of a bigger project called

00:04:06,239 --> 00:04:10,720
centeris from us

00:04:07,840 --> 00:04:11,200
and uh yeah that will also be show shown

00:04:10,720 --> 00:04:14,560
at the

00:04:11,200 --> 00:04:19,040
virtual booth with this i'm gonna hand

00:04:14,560 --> 00:04:19,040
over to human for design and features

00:04:19,919 --> 00:04:23,440
okay let's go design

00:04:27,520 --> 00:04:34,080
let's first briefly give a high level

00:04:30,880 --> 00:04:34,720
review to refresh aaron's memory before

00:04:34,080 --> 00:04:38,000
we dive

00:04:34,720 --> 00:04:41,199
into the unified runtime design

00:04:38,000 --> 00:04:43,600
cubelet gets content runtime endpoint

00:04:41,199 --> 00:04:45,759
where the content runtime and the

00:04:43,600 --> 00:04:47,040
container runtime endpoint command line

00:04:45,759 --> 00:04:49,199
arguments

00:04:47,040 --> 00:04:52,240
kubernetes use this information to

00:04:49,199 --> 00:04:55,440
construct the remote runtime services

00:04:52,240 --> 00:04:58,479
and pass it into the generic

00:04:55,440 --> 00:05:00,639
random manager object when kubernetes

00:04:58,479 --> 00:05:03,120
manager gets the part

00:05:00,639 --> 00:05:03,840
it computes necessary actions for

00:05:03,120 --> 00:05:07,039
example

00:05:03,840 --> 00:05:10,400
create container for the given part

00:05:07,039 --> 00:05:13,039
with a series of api invocations

00:05:10,400 --> 00:05:14,560
the request is then handed out by the

00:05:13,039 --> 00:05:18,800
remote runtime service

00:05:14,560 --> 00:05:22,400
via the rpc call please keep in mind

00:05:18,800 --> 00:05:27,280
that the current only one runtime

00:05:22,400 --> 00:05:27,280
service supported in kubernetes

00:05:28,400 --> 00:05:31,680
now let's take a look at the current

00:05:30,639 --> 00:05:34,880
changes

00:05:31,680 --> 00:05:37,360
in actors this is a high level design

00:05:34,880 --> 00:05:39,440
diagram for the multiple runtime service

00:05:37,360 --> 00:05:42,639
management in actors

00:05:39,440 --> 00:05:46,160
the goals are simple natively support

00:05:42,639 --> 00:05:48,400
vm workload extensible for future random

00:05:46,160 --> 00:05:51,199
apis

00:05:48,400 --> 00:05:52,320
the components highlights in purple and

00:05:51,199 --> 00:05:56,639
time colors

00:05:52,320 --> 00:05:59,919
are major changes to achieve these goals

00:05:56,639 --> 00:06:01,039
the cubelets now accept multiple runtime

00:05:59,919 --> 00:06:03,680
endpoints

00:06:01,039 --> 00:06:04,319
and extra information for the workload

00:06:03,680 --> 00:06:07,759
type

00:06:04,319 --> 00:06:10,960
and the designated runtime names

00:06:07,759 --> 00:06:14,240
a new component runtime registry

00:06:10,960 --> 00:06:15,600
was added to store and maintains this

00:06:14,240 --> 00:06:17,919
information

00:06:15,600 --> 00:06:19,360
the cubelet when constructing the

00:06:17,919 --> 00:06:21,919
runtime manager

00:06:19,360 --> 00:06:23,919
instead of passing in the single remote

00:06:21,919 --> 00:06:29,199
runtime service interface

00:06:23,919 --> 00:06:29,199
now it passes in the runtime registry

00:06:29,440 --> 00:06:32,880
the runtime registry provides gather

00:06:32,000 --> 00:06:35,440
apis

00:06:32,880 --> 00:06:36,880
to runtime manager to get the desired

00:06:35,440 --> 00:06:41,440
workload

00:06:36,880 --> 00:06:44,160
based on the part workload type

00:06:41,440 --> 00:06:45,520
each runtime service for different

00:06:44,160 --> 00:06:48,319
workload will require

00:06:45,520 --> 00:06:50,000
different spec for the workload types

00:06:48,319 --> 00:06:52,560
the port converter

00:06:50,000 --> 00:06:53,759
is an adapter for type conversion

00:06:52,560 --> 00:06:57,039
between actors

00:06:53,759 --> 00:06:59,599
and runtime services in a nutshell

00:06:57,039 --> 00:07:00,560
it translates the vm part definition

00:06:59,599 --> 00:07:03,039
actors

00:07:00,560 --> 00:07:05,680
to the desired spec that the remote

00:07:03,039 --> 00:07:09,360
runtime service expects

00:07:05,680 --> 00:07:10,479
last but not least the random container

00:07:09,360 --> 00:07:13,280
interface

00:07:10,479 --> 00:07:13,840
the runtime internal interface and the

00:07:13,280 --> 00:07:16,880
cr

00:07:13,840 --> 00:07:18,560
interface are extended to support vm

00:07:16,880 --> 00:07:21,759
specific operations

00:07:18,560 --> 00:07:23,599
such as start stop reboot click snapshot

00:07:21,759 --> 00:07:27,440
etc

00:07:23,599 --> 00:07:30,560
now in actors when a new part is created

00:07:27,440 --> 00:07:31,440
and scheduled the rental manager gets

00:07:30,560 --> 00:07:34,479
the pulse

00:07:31,440 --> 00:07:38,080
it will call the runtime registry to get

00:07:34,479 --> 00:07:41,039
the desired runtime service for the part

00:07:38,080 --> 00:07:43,199
based on the workload type the desired

00:07:41,039 --> 00:07:46,080
runtime service api

00:07:43,199 --> 00:07:47,440
are called for the powered actions we

00:07:46,080 --> 00:07:51,280
call this

00:07:47,440 --> 00:07:53,840
the power runtime late binding

00:07:51,280 --> 00:07:54,960
with the real-time registry power

00:07:53,840 --> 00:07:58,319
converter

00:07:54,960 --> 00:07:58,960
the crr extension together achieve the

00:07:58,319 --> 00:08:01,680
goal

00:07:58,960 --> 00:08:03,360
to support multiple random services

00:08:01,680 --> 00:08:06,639
natively

00:08:03,360 --> 00:08:10,479
and make actors extensible

00:08:06,639 --> 00:08:13,919
for new runtime services and provide

00:08:10,479 --> 00:08:14,879
rich vm operations in the next few

00:08:13,919 --> 00:08:18,800
slides

00:08:14,879 --> 00:08:18,800
we'll share some more details of them

00:08:20,080 --> 00:08:24,400
let's take a closer look at the runtime

00:08:22,720 --> 00:08:27,919
service registry type

00:08:24,400 --> 00:08:31,440
and interfaces as we can see besides

00:08:27,919 --> 00:08:32,479
the internal run internal api runtime

00:08:31,440 --> 00:08:35,519
services

00:08:32,479 --> 00:08:36,560
which is constructed by kubelet a few

00:08:35,519 --> 00:08:39,760
more fields

00:08:36,560 --> 00:08:40,800
are maintained the workload type is to

00:08:39,760 --> 00:08:44,640
determine

00:08:40,800 --> 00:08:47,360
which workload the runtime supports

00:08:44,640 --> 00:08:48,160
the its primary field is used to

00:08:47,360 --> 00:08:50,560
determine

00:08:48,160 --> 00:08:51,360
the must-have runtime service on the

00:08:50,560 --> 00:08:55,519
node

00:08:51,360 --> 00:08:58,800
which is used for node readiness check

00:08:55,519 --> 00:09:00,240
currently only static registration is

00:08:58,800 --> 00:09:02,560
supported

00:09:00,240 --> 00:09:04,399
in the future the dynamic registration

00:09:02,560 --> 00:09:07,519
will be added

00:09:04,399 --> 00:09:08,080
so when a node is ready to support new

00:09:07,519 --> 00:09:11,839
workload

00:09:08,080 --> 00:09:14,640
types couplet won't need to be restarted

00:09:11,839 --> 00:09:14,640
to load it up

00:09:15,839 --> 00:09:19,120
optos is designed to support

00:09:18,160 --> 00:09:22,720
full-fledged

00:09:19,120 --> 00:09:25,360
vm definition and operations on vms

00:09:22,720 --> 00:09:28,399
to match the feature set currently

00:09:25,360 --> 00:09:28,399
openstacks offer

00:09:28,480 --> 00:09:35,360
in actors the cr interface has been

00:09:32,080 --> 00:09:38,399
extended with a set of new apis

00:09:35,360 --> 00:09:39,519
to support those operations need to

00:09:38,399 --> 00:09:42,880
mention that

00:09:39,519 --> 00:09:45,920
even currently there's no deep changes

00:09:42,880 --> 00:09:49,279
at the internal data structures

00:09:45,920 --> 00:09:52,720
with some effort to allow the runtime

00:09:49,279 --> 00:09:56,080
sdk as plugins

00:09:52,720 --> 00:09:56,399
in the remote package in kublet it can

00:09:56,080 --> 00:09:59,279
be

00:09:56,399 --> 00:10:02,000
extended to support customized

00:09:59,279 --> 00:10:02,000
interfaces

00:10:02,839 --> 00:10:07,120
invitation

00:10:04,079 --> 00:10:10,560
with multiple runtime service in kubelet

00:10:07,120 --> 00:10:12,959
and supporting vm types we have facing

00:10:10,560 --> 00:10:14,880
some design decisions to make

00:10:12,959 --> 00:10:16,839
due to time constraint i only share a

00:10:14,880 --> 00:10:20,160
couple here

00:10:16,839 --> 00:10:23,120
first we have to ensure

00:10:20,160 --> 00:10:25,040
the compute resources such as cpu memory

00:10:23,120 --> 00:10:27,440
etc are controlled

00:10:25,040 --> 00:10:29,279
shared among the vm and the container

00:10:27,440 --> 00:10:32,640
types on the node

00:10:29,279 --> 00:10:33,680
in actors this is this is designed such

00:10:32,640 --> 00:10:36,800
way

00:10:33,680 --> 00:10:38,000
when the vm is created the actual

00:10:36,800 --> 00:10:41,519
runtime service

00:10:38,000 --> 00:10:44,480
creates the sql path for the vm

00:10:41,519 --> 00:10:46,320
following the same layout pattern as the

00:10:44,480 --> 00:10:49,200
container workload type

00:10:46,320 --> 00:10:50,079
for example it would be under keeper

00:10:49,200 --> 00:10:54,399
pause

00:10:50,079 --> 00:10:57,680
burst ball slash port id slash vm id

00:10:54,399 --> 00:11:02,240
and the random service moves the vm

00:10:57,680 --> 00:11:05,519
process to the sql path for vms

00:11:02,240 --> 00:11:07,600
there are three set of metadata in terms

00:11:05,519 --> 00:11:10,079
of resource control

00:11:07,600 --> 00:11:13,040
the first one is the sql metadata which

00:11:10,079 --> 00:11:16,079
is sql files and each control

00:11:13,040 --> 00:11:18,640
the second one is the random metadata

00:11:16,079 --> 00:11:19,760
and the third one would be the leap word

00:11:18,640 --> 00:11:23,519
vm

00:11:19,760 --> 00:11:24,160
domain definition the actors vm runtime

00:11:23,519 --> 00:11:27,519
service

00:11:24,160 --> 00:11:30,959
keeps them synchronized by checking them

00:11:27,519 --> 00:11:33,760
each time with the win win the vm status

00:11:30,959 --> 00:11:33,760
is reported

00:11:34,240 --> 00:11:40,480
another one is to handle the node status

00:11:37,839 --> 00:11:41,600
with multiple runtime service on it

00:11:40,480 --> 00:11:44,000
recall

00:11:41,600 --> 00:11:45,519
the its primary field in the runtime

00:11:44,000 --> 00:11:48,959
registry type

00:11:45,519 --> 00:11:52,079
the actors with multiple runtime service

00:11:48,959 --> 00:11:52,480
on the node we allow the cluster admin

00:11:52,079 --> 00:11:56,240
to

00:11:52,480 --> 00:11:58,880
elect one as the primary runtime service

00:11:56,240 --> 00:12:00,720
and use it to determine the node's

00:11:58,880 --> 00:12:04,320
runtime readiness

00:12:00,720 --> 00:12:05,200
the scheduler will only schedule the

00:12:04,320 --> 00:12:08,399
workload

00:12:05,200 --> 00:12:11,760
to the node where the desired runtime

00:12:08,399 --> 00:12:15,040
service is ready this is very important

00:12:11,760 --> 00:12:15,920
in the cluster so the node will be still

00:12:15,040 --> 00:12:18,959
useful

00:12:15,920 --> 00:12:21,519
as long as the primary runtime service

00:12:18,959 --> 00:12:21,519
is ready

00:12:23,040 --> 00:12:28,000
so with those uh design decisions we are

00:12:25,920 --> 00:12:29,440
able to have this unified runtime to

00:12:28,000 --> 00:12:31,360
allow the both the

00:12:29,440 --> 00:12:33,279
vm and the container to run the same

00:12:31,360 --> 00:12:34,959
time there are a few other

00:12:33,279 --> 00:12:37,040
features that we want to mention here

00:12:34,959 --> 00:12:38,160
one of them is the the pod state

00:12:37,040 --> 00:12:40,639
management

00:12:38,160 --> 00:12:41,920
what this allows us to do is to be able

00:12:40,639 --> 00:12:44,240
to have the vm

00:12:41,920 --> 00:12:45,279
to go from a running state to a shutdown

00:12:44,240 --> 00:12:48,079
state

00:12:45,279 --> 00:12:48,720
or to a hibernate state and come back

00:12:48,079 --> 00:12:50,399
this is

00:12:48,720 --> 00:12:51,920
different from just shutting down and

00:12:50,399 --> 00:12:54,720
deleting

00:12:51,920 --> 00:12:55,519
a pod this will keep all the state of

00:12:54,720 --> 00:12:57,279
the vm

00:12:55,519 --> 00:12:58,800
so that when we are ready we can bring

00:12:57,279 --> 00:12:59,600
them back running with all the same

00:12:58,800 --> 00:13:03,200
state

00:12:59,600 --> 00:13:05,760
uh in this diagram i have a quick

00:13:03,200 --> 00:13:06,480
mechanism showing how this works so for

00:13:05,760 --> 00:13:09,839
example

00:13:06,480 --> 00:13:12,560
we have this vm pod running on a node

00:13:09,839 --> 00:13:14,240
and in the definition of this other in

00:13:12,560 --> 00:13:16,560
the products back section we have this

00:13:14,240 --> 00:13:20,880
virtual machine

00:13:16,560 --> 00:13:22,160
and one of the the key is the power spec

00:13:20,880 --> 00:13:24,800
that's showing the running state the

00:13:22,160 --> 00:13:27,360
power spec indicates what the state

00:13:24,800 --> 00:13:28,160
the vm should be running and now it's in

00:13:27,360 --> 00:13:30,079
the running

00:13:28,160 --> 00:13:32,079
state so that means that the power

00:13:30,079 --> 00:13:33,680
should be running and it is running here

00:13:32,079 --> 00:13:35,279
to change this for example at a certain

00:13:33,680 --> 00:13:38,399
point that we want to shut this down

00:13:35,279 --> 00:13:40,240
maybe to uh control resource uh or

00:13:38,399 --> 00:13:41,920
just avoid using resources when we're

00:13:40,240 --> 00:13:44,079
not using this virtual machine

00:13:41,920 --> 00:13:46,079
what we can do is we can issue a patch

00:13:44,079 --> 00:13:48,000
command to the pod

00:13:46,079 --> 00:13:49,360
uh to indicate okay we want to change

00:13:48,000 --> 00:13:51,680
this part to shut down

00:13:49,360 --> 00:13:52,480
and then what's that's going to do is

00:13:51,680 --> 00:13:54,480
it's not

00:13:52,480 --> 00:13:57,199
it's going to trigger the control plan

00:13:54,480 --> 00:14:00,480
to take this part out of resources

00:13:57,199 --> 00:14:01,279
from the node and put that in a shutdown

00:14:00,480 --> 00:14:03,120
state

00:14:01,279 --> 00:14:05,199
when the scheduler sees this for example

00:14:03,120 --> 00:14:06,800
it it will see the shutdown state they

00:14:05,199 --> 00:14:09,839
will see that it's intended

00:14:06,800 --> 00:14:10,160
so it will not uh try to reschedule this

00:14:09,839 --> 00:14:12,639
part

00:14:10,160 --> 00:14:13,440
anywhere else when we are ready to bring

00:14:12,639 --> 00:14:16,560
this back

00:14:13,440 --> 00:14:18,480
we can do something very similar to

00:14:16,560 --> 00:14:20,399
brain back we can issue another patch

00:14:18,480 --> 00:14:21,680
command to change this from shutdown to

00:14:20,399 --> 00:14:24,240
running

00:14:21,680 --> 00:14:25,040
similarly the control plan will see

00:14:24,240 --> 00:14:28,079
these

00:14:25,040 --> 00:14:29,600
changes and the controller now sees that

00:14:28,079 --> 00:14:30,000
okay we want this to be in a running

00:14:29,600 --> 00:14:32,000
state

00:14:30,000 --> 00:14:34,079
the controller will schedule this

00:14:32,000 --> 00:14:36,000
product to some note that the

00:14:34,079 --> 00:14:39,120
new node can be the same node or it

00:14:36,000 --> 00:14:39,680
cannot be the same node it all depends

00:14:39,120 --> 00:14:43,680
on the

00:14:39,680 --> 00:14:46,079
resource availability at that time

00:14:43,680 --> 00:14:46,720
and when the pod is back up running it

00:14:46,079 --> 00:14:48,800
will have

00:14:46,720 --> 00:14:51,360
have all the state from the previous

00:14:48,800 --> 00:14:51,760
life so it's as if we just pause the pod

00:14:51,360 --> 00:14:54,880
for

00:14:51,760 --> 00:14:57,360
for some time um here

00:14:54,880 --> 00:14:59,279
the next one on the agenda is we were

00:14:57,360 --> 00:15:02,480
going to do a demo

00:14:59,279 --> 00:15:03,440
so in this demo let me switch to the

00:15:02,480 --> 00:15:06,720
demo window

00:15:03,440 --> 00:15:09,519
uh in this demo i will uh basically

00:15:06,720 --> 00:15:09,839
let you see i will have two parts here

00:15:09,519 --> 00:15:11,920
one

00:15:09,839 --> 00:15:13,839
is a virtual machine pod as you can see

00:15:11,920 --> 00:15:14,880
this part is the definition for the

00:15:13,839 --> 00:15:16,880
virtual machine

00:15:14,880 --> 00:15:18,160
on the right is a traditional uh

00:15:16,880 --> 00:15:19,920
container a pod

00:15:18,160 --> 00:15:21,760
so you can see that it's uh it's very

00:15:19,920 --> 00:15:24,320
basic uh definition is

00:15:21,760 --> 00:15:26,240
a very simple definition uh one thing i

00:15:24,320 --> 00:15:27,680
want to point out here is that uh as you

00:15:26,240 --> 00:15:30,000
can see the virtual machine now is

00:15:27,680 --> 00:15:32,320
on the same level of definition to the

00:15:30,000 --> 00:15:33,680
container so it's not a guess that is a

00:15:32,320 --> 00:15:36,639
first class citizen

00:15:33,680 --> 00:15:38,240
uh to be there and the the rest of the

00:15:36,639 --> 00:15:39,279
definition for example for the resource

00:15:38,240 --> 00:15:41,199
part and the

00:15:39,279 --> 00:15:43,600
resource limited request is very similar

00:15:41,199 --> 00:15:46,720
to the what the container has

00:15:43,600 --> 00:15:47,519
okay so the first part of the demo is

00:15:46,720 --> 00:15:50,560
let's create

00:15:47,519 --> 00:15:52,560
this two parts i do that

00:15:50,560 --> 00:15:54,000
create let's create the container part

00:15:52,560 --> 00:15:57,279
and let's create the vm

00:15:54,000 --> 00:16:00,800
part and here

00:15:57,279 --> 00:16:03,279
we can see that the both parts are being

00:16:00,800 --> 00:16:04,720
created and in a second we'll see that

00:16:03,279 --> 00:16:07,920
they'll go from

00:16:04,720 --> 00:16:09,279
pending to running that's good now let's

00:16:07,920 --> 00:16:12,720
take a look at what the part

00:16:09,279 --> 00:16:15,600
is actually the vm part so uh

00:16:12,720 --> 00:16:16,160
here i'm gonna show you a few things one

00:16:15,600 --> 00:16:17,920
is uh

00:16:16,160 --> 00:16:19,920
we talked about this section right uh we

00:16:17,920 --> 00:16:20,959
have this power spec to indicate the

00:16:19,920 --> 00:16:23,600
what is that

00:16:20,959 --> 00:16:24,720
the vm should be running and in the

00:16:23,600 --> 00:16:27,120
status section

00:16:24,720 --> 00:16:27,920
we actually have the the virtual machine

00:16:27,120 --> 00:16:30,480
status

00:16:27,920 --> 00:16:31,440
and also uh we have the product

00:16:30,480 --> 00:16:35,120
scheduled

00:16:31,440 --> 00:16:37,040
status for this part okay so that's good

00:16:35,120 --> 00:16:39,199
now let's try to change this to shutdown

00:16:37,040 --> 00:16:41,839
and bring it back

00:16:39,199 --> 00:16:44,160
what i'm going to do is i will issue two

00:16:41,839 --> 00:16:47,440
patches one is to shut down the

00:16:44,160 --> 00:16:50,720
the vm that's gonna work is uh

00:16:47,440 --> 00:16:51,680
let's do i will do a patch like this so

00:16:50,720 --> 00:16:53,920
if i do that

00:16:51,680 --> 00:16:55,600
the controller the scheduler will see

00:16:53,920 --> 00:16:57,920
that and it will

00:16:55,600 --> 00:17:00,000
see that it's in a no schedule state so

00:16:57,920 --> 00:17:02,079
it will not try to schedule it

00:17:00,000 --> 00:17:04,240
uh if you're curious i can show you

00:17:02,079 --> 00:17:06,799
what's in here which is very uh

00:17:04,240 --> 00:17:08,160
straightforward we just are changing the

00:17:06,799 --> 00:17:11,679
power spec section

00:17:08,160 --> 00:17:12,799
of the pod spec okay and if we go back

00:17:11,679 --> 00:17:16,079
and take again

00:17:12,799 --> 00:17:18,079
look at uh the status we can see that

00:17:16,079 --> 00:17:19,199
the pod is in the virtual machine

00:17:18,079 --> 00:17:21,199
shutdown state

00:17:19,199 --> 00:17:23,199
and it's in the no schedule no schedule

00:17:21,199 --> 00:17:24,959
means again does the schedule will not

00:17:23,199 --> 00:17:29,039
attempt to schedule this pathway

00:17:24,959 --> 00:17:31,919
sees that okay now let's go back

00:17:29,039 --> 00:17:32,559
uh okay now let's bring this back how do

00:17:31,919 --> 00:17:35,919
we do that

00:17:32,559 --> 00:17:37,280
we use uh we just do running we'll just

00:17:35,919 --> 00:17:40,559
issue another patch

00:17:37,280 --> 00:17:43,440
to to change the power spec section

00:17:40,559 --> 00:17:44,320
and we can see that okay the the patch

00:17:43,440 --> 00:17:46,320
has gone through

00:17:44,320 --> 00:17:47,840
and let's just wait for it to go back to

00:17:46,320 --> 00:17:50,480
running and now it's running

00:17:47,840 --> 00:17:51,200
so that's very good uh this demonstrate

00:17:50,480 --> 00:17:53,919
that uh

00:17:51,200 --> 00:17:55,039
we can have both vm and the container

00:17:53,919 --> 00:17:57,679
running at the same time and

00:17:55,039 --> 00:17:59,120
we can have features like uh shutdown

00:17:57,679 --> 00:18:02,160
and the restart

00:17:59,120 --> 00:18:06,000
that concludes the demo for today

00:18:02,160 --> 00:18:09,760
i will hand this back to human

00:18:06,000 --> 00:18:12,840
great thank you for the good demo

00:18:09,760 --> 00:18:14,000
the actual project is still in its early

00:18:12,840 --> 00:18:16,480
stage

00:18:14,000 --> 00:18:17,280
for the unified runtime area there are

00:18:16,480 --> 00:18:20,240
quite few

00:18:17,280 --> 00:18:21,200
new features that have been planned for

00:18:20,240 --> 00:18:24,640
example

00:18:21,200 --> 00:18:25,919
the bare metal support the gpu or device

00:18:24,640 --> 00:18:29,760
pass through

00:18:25,919 --> 00:18:31,760
more vm action support it's very

00:18:29,760 --> 00:18:34,960
integration with the storage network

00:18:31,760 --> 00:18:34,960
provider exactly

00:18:39,360 --> 00:18:43,039
we have put some useful links here

00:18:41,760 --> 00:18:45,919
including the

00:18:43,039 --> 00:18:47,760
actors project repository and some

00:18:45,919 --> 00:18:49,760
design documentation here

00:18:47,760 --> 00:18:51,760
feel free to draw the code draw the

00:18:49,760 --> 00:18:53,919
design documentation and learn more from

00:18:51,760 --> 00:18:53,919
it

00:18:54,559 --> 00:18:58,320
the future we have a virtual booth set

00:18:57,280 --> 00:19:00,720
up

00:18:58,320 --> 00:19:01,360
please visit us there and learn more

00:19:00,720 --> 00:19:04,320
about

00:19:01,360 --> 00:19:06,400
the project actors and other interesting

00:19:04,320 --> 00:19:08,480
projects we are working on

00:19:06,400 --> 00:19:10,400
feel free to contact us if you are

00:19:08,480 --> 00:19:12,160
interested in contributing to those

00:19:10,400 --> 00:19:14,880
projects

00:19:12,160 --> 00:19:15,919
with that we'll be happy to take a few

00:19:14,880 --> 00:19:19,200
questions

00:19:15,919 --> 00:19:19,200

YouTube URL: https://www.youtube.com/watch?v=qYcAf8I7shw


