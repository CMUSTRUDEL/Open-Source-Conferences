Title: High Performance Storage Solution for Large-scale ML Systems - Hongjian Yu & Pengfei Zheng
Publication date: 2020-09-11
Playlist: Cloud Native + Open Source Virtual Summit China 2020
Description: 
	Don’t miss out! Join us at our upcoming events: EnvoyCon Virtual on October 15 and KubeCon + CloudNativeCon North America 2020 Virtual from November 17-20. Learn more at https://kubecon.io The conferences feature presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects. 

High Performance Storage Solution for Large-scale ML Systems - Hongjian Yu, Cheetah Mobile & Pengfei Zheng, Baidu 

For training models that focus on a single pass of the data and for training models where the computation can be easily and efficiently parallelized or offloaded to hardware computational units, moving the data becomes a bigger problem than the computation itself. In particular, moving data from a global filesystem for such processing can be a major bottleneck in the overall computation. Our study shows that even with a small amount of parallelism in such deep learning systems, I/O accounts for a majority of the training time, thus degrading the overall system scalability.  So, We propose a new solution to solve these problems. This solution adopts high-speed hardwares, Several software improvements, such as thread model, load balance sdk, read / write splitting, read path optimization, are also introduced to achieve lower latency and higher throughput. 

https://sched.co/cp8o
Captions: 
	
YouTube URL: https://www.youtube.com/watch?v=eU2wexh0HPU


