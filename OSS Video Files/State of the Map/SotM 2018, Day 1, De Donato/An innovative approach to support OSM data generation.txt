Title: An innovative approach to support OSM data generation
Publication date: 2018-09-21
Playlist: SotM 2018, Day 1, De Donato
Description: 
	Emanuela Mihut (Phd Student (West University of Timisoara, Romania)), State of the Map 2018
https://2018.stateofthemap.org/2018/T063-An_innovative_approach_to_support_OSM_data_generation_/

Because very often, in the literature, manually generation of OSM data is described as a complex and questioned process, it might be useful to support it by automated remote sensing approaches. While automated approaches are not expected to deliver fully accurate results, they still could save important work which may substantially reduce the digitizing efforts. The aim of this session is to present our developed building extraction algorithm that combines an object-based (OBIA) approach with a deep learning algorithm: convolutional neural network (CNN). The results (building polygons) from the OBIA algorithm are used as training samples for CNN algorithm. The buildings extraction algorithm will be further tested for usefulness in supporting the OSM initiative, particularly in areas exposed to humanitarian crisis where OSM data does not exist at all. The algorithm has been tested on RGB images. In all cases, it has provided promising results, with an overall accuracy over 85%.
Captions: 
	00:00:00,030 --> 00:00:06,810
thank you just I want to let you know if

00:00:03,720 --> 00:00:09,269
you see me nervous just know that it's

00:00:06,810 --> 00:00:12,450
my first presentation in front of a lot

00:00:09,269 --> 00:00:15,509
of people and it's also in English I

00:00:12,450 --> 00:00:17,970
want to talk about using image

00:00:15,509 --> 00:00:22,890
segmentation to support OpenStreetMap

00:00:17,970 --> 00:00:28,260
data generation I come from a background

00:00:22,890 --> 00:00:30,960
it's I'm a PhD student so as you can see

00:00:28,260 --> 00:00:31,980
I come from scientific academic

00:00:30,960 --> 00:00:37,160
background

00:00:31,980 --> 00:00:39,960
I'm also OpenStreetMap volunteer for HRT

00:00:37,160 --> 00:00:46,890
GS and remonstrance again a list and

00:00:39,960 --> 00:00:50,520
also volunteer in in Africa the

00:00:46,890 --> 00:00:54,899
background idea I want to talk about why

00:00:50,520 --> 00:00:57,120
I choose to present this to you I'm a

00:00:54,899 --> 00:01:03,350
PhD student and three years ago when I

00:00:57,120 --> 00:01:06,689
started my PhD I was between these two

00:01:03,350 --> 00:01:10,680
things automatic mapping and manual

00:01:06,689 --> 00:01:15,900
mapping and I realized there is a big

00:01:10,680 --> 00:01:21,619
big gap between between them the first

00:01:15,900 --> 00:01:26,070
year I told my teachers I want to use

00:01:21,619 --> 00:01:29,159
OpenStreetMap and free free data to map

00:01:26,070 --> 00:01:31,560
those remote and very poor area from

00:01:29,159 --> 00:01:34,200
from the world in specially in Africa

00:01:31,560 --> 00:01:36,750
and Asia and my my teachers told me a

00:01:34,200 --> 00:01:39,360
why of a street map data why do you know

00:01:36,750 --> 00:01:41,520
about oppa Street Map data just to read

00:01:39,360 --> 00:01:43,259
the religious literature and the state

00:01:41,520 --> 00:01:48,600
of the arts and you will see that the

00:01:43,259 --> 00:01:50,820
data is not good so I had very big

00:01:48,600 --> 00:01:55,710
question why did this data is not good

00:01:50,820 --> 00:01:58,290
so as I told you the background idea was

00:01:55,710 --> 00:02:01,979
to generate data buildings in those

00:01:58,290 --> 00:02:03,380
areas were always some data I look at

00:02:01,979 --> 00:02:08,899
the kind of data doesn't

00:02:03,380 --> 00:02:11,420
is that Oh refugee camps ray-ray areas

00:02:08,899 --> 00:02:19,069
exposed to natural disaster pool areas

00:02:11,420 --> 00:02:21,290
like slums or other areas so I wanted to

00:02:19,069 --> 00:02:23,599
do it manually using couple feet map

00:02:21,290 --> 00:02:28,459
data but my teacher convinced me not to

00:02:23,599 --> 00:02:31,099
do it because the data is bad so I'm

00:02:28,459 --> 00:02:34,910
supporting OpenStreetMap and I think

00:02:31,099 --> 00:02:38,269
it's the best data we can use now after

00:02:34,910 --> 00:02:41,530
three years of PhD and I just want to

00:02:38,269 --> 00:02:44,180
let you know why they say in an academic

00:02:41,530 --> 00:02:45,380
university back rounded OpenStreetMap

00:02:44,180 --> 00:02:52,299
data is not good

00:02:45,380 --> 00:02:56,200
of course I talked about HRT mixing Maps

00:02:52,299 --> 00:02:59,480
they said this about the manual mapping

00:02:56,200 --> 00:03:02,019
that remote areas located in low and

00:02:59,480 --> 00:03:05,180
middle income countries lack data

00:03:02,019 --> 00:03:08,510
generating to OpenStreetMap initiatives

00:03:05,180 --> 00:03:11,150
or they are just in a very pool a very

00:03:08,510 --> 00:03:14,989
rich country and not in the poor

00:03:11,150 --> 00:03:17,569
countries and also that OpenStreetMap

00:03:14,989 --> 00:03:20,090
are prone to various accuracy related

00:03:17,569 --> 00:03:24,910
errors so the biggest event they talk

00:03:20,090 --> 00:03:32,359
about is the earthquake from Nepal in

00:03:24,910 --> 00:03:34,910
2015 they said this that OpenStreetMap

00:03:32,359 --> 00:03:38,000
contributors are very new to

00:03:34,910 --> 00:03:40,579
OpenStreetMap they do their first edits

00:03:38,000 --> 00:03:42,850
we are making mistakes because they

00:03:40,579 --> 00:03:47,630
don't have a geographical background and

00:03:42,850 --> 00:03:52,220
its quality it's a very big med it's a

00:03:47,630 --> 00:03:56,660
major concern so reading this what you

00:03:52,220 --> 00:03:59,720
believe om is not good so for the

00:03:56,660 --> 00:04:02,989
beginning I started to believe them but

00:03:59,720 --> 00:04:07,870
now and the second year of my PhD I

00:04:02,989 --> 00:04:10,290
started to use automatic automatic

00:04:07,870 --> 00:04:13,290
methods to map

00:04:10,290 --> 00:04:18,680
from satellite images and I talked about

00:04:13,290 --> 00:04:23,449
image segmentation so as as you can know

00:04:18,680 --> 00:04:26,699
there are two kinds of automatic

00:04:23,449 --> 00:04:28,889
approaches methods we can use with using

00:04:26,699 --> 00:04:37,770
training sample and without training

00:04:28,889 --> 00:04:39,780
sample so we all know about methods that

00:04:37,770 --> 00:04:43,500
use training sample it's about machine

00:04:39,780 --> 00:04:47,750
learning deep learning and it's true

00:04:43,500 --> 00:04:52,620
they have a very huge accuracy over 95%

00:04:47,750 --> 00:04:54,930
and the problem is that they need a lot

00:04:52,620 --> 00:04:57,630
of training sample if we don't have a

00:04:54,930 --> 00:05:01,050
lot of training sample the results are

00:04:57,630 --> 00:05:03,780
not not good also they they don't have

00:05:01,050 --> 00:05:08,729
transfer ability if for example we

00:05:03,780 --> 00:05:11,430
trained algorithm in US or in Europe we

00:05:08,729 --> 00:05:14,490
cannot use the same parameters with the

00:05:11,430 --> 00:05:17,580
same training sampler to map the houses

00:05:14,490 --> 00:05:22,650
in I don't know South Sudan it's not

00:05:17,580 --> 00:05:26,159
working about the methods that were

00:05:22,650 --> 00:05:28,740
without training sample they are a few

00:05:26,159 --> 00:05:32,490
the most important is about cold abaya

00:05:28,740 --> 00:05:35,669
they no don't need trained example but

00:05:32,490 --> 00:05:40,229
also the accuracy is not so high so

00:05:35,669 --> 00:05:43,919
after I read this I realized that even

00:05:40,229 --> 00:05:47,280
automatic methods didn't meet they still

00:05:43,919 --> 00:05:50,699
need human knowledge or data so what was

00:05:47,280 --> 00:05:53,280
my idea and for the next 10 minutes I

00:05:50,699 --> 00:05:56,880
want to talk about this was to develop

00:05:53,280 --> 00:06:02,099
transferable method that can extract

00:05:56,880 --> 00:06:05,639
building for from free images RGB images

00:06:02,099 --> 00:06:10,500
with a high accuracy without using

00:06:05,639 --> 00:06:13,380
people for from the beginning so let's

00:06:10,500 --> 00:06:19,409
say we have a tool and we can extract

00:06:13,380 --> 00:06:20,610
maybe 50% of 40% or more buildings from

00:06:19,409 --> 00:06:26,090
a huge

00:06:20,610 --> 00:06:27,280
you would image if we can do that

00:06:26,090 --> 00:06:28,500
automatically

00:06:27,280 --> 00:06:31,199
[Music]

00:06:28,500 --> 00:06:34,349
it's for my point of view it's very

00:06:31,199 --> 00:06:35,879
useful for the community to come and map

00:06:34,349 --> 00:06:39,659
the remain buildings

00:06:35,879 --> 00:06:43,740
I think the process will be faster if

00:06:39,659 --> 00:06:49,319
the volunteers OpenStreetMap volunteer

00:06:43,740 --> 00:06:52,460
will not start from scratch and now we

00:06:49,319 --> 00:06:57,690
we had a question how accurate an

00:06:52,460 --> 00:07:02,180
algorithm can be and to use the results

00:06:57,690 --> 00:07:07,139
to use the building for OpenStreetMap so

00:07:02,180 --> 00:07:11,099
part of the PhD study we did some small

00:07:07,139 --> 00:07:14,580
study case we took a dataset with 100

00:07:11,099 --> 00:07:20,069
different images from us we can see in

00:07:14,580 --> 00:07:24,000
this slide they are from us with a very

00:07:20,069 --> 00:07:31,520
high resolution and there are also three

00:07:24,000 --> 00:07:34,349
images RGB images so to test how

00:07:31,520 --> 00:07:38,490
automated algorithm can work we used

00:07:34,349 --> 00:07:43,860
three different approaches Abhaya

00:07:38,490 --> 00:07:47,190
and up burn operates that it works

00:07:43,860 --> 00:07:49,589
without rent training sample deep

00:07:47,190 --> 00:07:53,639
learning approach and the last one we

00:07:49,589 --> 00:07:54,389
combined them so this is the first one

00:07:53,639 --> 00:07:59,400
we Tobiah

00:07:54,389 --> 00:08:01,529
we applied it for the whole dataset 100

00:07:59,400 --> 00:08:03,180
images without straining sample we use

00:08:01,529 --> 00:08:07,550
image segmentation

00:08:03,180 --> 00:08:12,479
a tool called estimated scale parameter

00:08:07,550 --> 00:08:16,159
to segment an image after we classify

00:08:12,479 --> 00:08:19,979
the image you see using geometry

00:08:16,159 --> 00:08:23,610
brightness and some texture rules and

00:08:19,979 --> 00:08:28,409
then we we saw the results we validated

00:08:23,610 --> 00:08:31,250
using very no precision recall accuracy

00:08:28,409 --> 00:08:31,250
and half measure

00:08:31,810 --> 00:08:42,090
the next one was a Herculean Network

00:08:36,030 --> 00:08:46,830
it's a deep learning go method we used

00:08:42,090 --> 00:08:51,700
80% of the image images to train the

00:08:46,830 --> 00:08:57,270
images and with the polygons provided in

00:08:51,700 --> 00:09:00,820
the dataset and after we predicted

00:08:57,270 --> 00:09:03,310
randomly choose 20% of all the images

00:09:00,820 --> 00:09:07,630
from the dataset and we we validated

00:09:03,310 --> 00:09:11,710
them the last approach was managed to

00:09:07,630 --> 00:09:16,780
see if we can combine abaya

00:09:11,710 --> 00:09:21,300
and CNN and do it without training

00:09:16,780 --> 00:09:25,089
samples so instead of using the provided

00:09:21,300 --> 00:09:28,839
polygons from the data set we trained

00:09:25,089 --> 00:09:34,720
90% of the images using polygons

00:09:28,839 --> 00:09:41,020
resulted from obeah and we need we did

00:09:34,720 --> 00:09:43,510
the same for the rest of the approach so

00:09:41,020 --> 00:09:47,380
doing this we don't need manual training

00:09:43,510 --> 00:09:50,410
samples we use abaya image segmentation

00:09:47,380 --> 00:09:52,170
from scratch to segment the bell rings

00:09:50,410 --> 00:09:58,660
and we can talk a bit about

00:09:52,170 --> 00:10:02,710
transferability and here the results

00:09:58,660 --> 00:10:06,130
which yeah yellow you have results and

00:10:02,710 --> 00:10:08,710
which arranged alright we have the

00:10:06,130 --> 00:10:12,690
reference data and we can see that using

00:10:08,710 --> 00:10:20,070
abaya we have an accuracy pretty high

00:10:12,690 --> 00:10:24,960
over 93% and it's important to say that

00:10:20,070 --> 00:10:29,230
we applied the same rose and roll set of

00:10:24,960 --> 00:10:31,510
on doll data set different images and

00:10:29,230 --> 00:10:36,790
within your training sample to reach

00:10:31,510 --> 00:10:39,470
this accuracy Hoka same network CNN

00:10:36,790 --> 00:10:42,279
approach

00:10:39,470 --> 00:10:51,170
we have here the highest accuracy over

00:10:42,279 --> 00:10:55,970
95% and here is the last one with our

00:10:51,170 --> 00:10:58,129
approach we have which blew the results

00:10:55,970 --> 00:11:01,160
and we thread the reference data and

00:10:58,129 --> 00:11:03,949
even from the scratch without training

00:11:01,160 --> 00:11:08,689
sample we managed to reach an accuracy

00:11:03,949 --> 00:11:14,470
over 93% it's important to mention that

00:11:08,689 --> 00:11:20,209
this is a fully automatic process and

00:11:14,470 --> 00:11:22,459
just to jump to conclusions in January

00:11:20,209 --> 00:11:25,569
or I don't I don't remember exactly one

00:11:22,459 --> 00:11:29,470
when I read when I saw the email which

00:11:25,569 --> 00:11:34,850
OpenStreetMap conference requirements I

00:11:29,470 --> 00:11:36,470
read that you are looking for

00:11:34,850 --> 00:11:39,430
presentation that talked about

00:11:36,470 --> 00:11:42,680
scientific application of OpenStreetMap

00:11:39,430 --> 00:11:45,459
new approaches that facilitate or

00:11:42,680 --> 00:11:48,680
improve the data collect collection

00:11:45,459 --> 00:11:52,300
creating better connection between the

00:11:48,680 --> 00:11:56,689
scientific community and opera community

00:11:52,300 --> 00:11:59,709
as I told I told you um the second year

00:11:56,689 --> 00:12:03,350
of my PhD and I believed that

00:11:59,709 --> 00:12:09,350
OpenStreetMap is the best the best data

00:12:03,350 --> 00:12:12,620
to use and here I came with my my idea

00:12:09,350 --> 00:12:18,490
of course I talk only about the

00:12:12,620 --> 00:12:19,970
automated process but I want us to think

00:12:18,490 --> 00:12:24,649
about it

00:12:19,970 --> 00:12:27,759
if we can use it somehow to generate

00:12:24,649 --> 00:12:30,769
data that can be useful for

00:12:27,759 --> 00:12:34,639
OpenStreetMap community and here I don't

00:12:30,769 --> 00:12:38,740
want to talk about low accuracy data if

00:12:34,639 --> 00:12:42,379
our data for example is over 95%

00:12:38,740 --> 00:12:47,720
accuracy and we consider it it's good

00:12:42,379 --> 00:12:49,530
and which our artery we can map even 20%

00:12:47,720 --> 00:12:53,110
of air

00:12:49,530 --> 00:12:56,200
automatically I think it's improvement

00:12:53,110 --> 00:12:59,200
and we it's important that the

00:12:56,200 --> 00:13:01,210
volunteers who can who come after to map

00:12:59,200 --> 00:13:05,550
the area they don't start from from

00:13:01,210 --> 00:13:05,550
scratch and they have a background I

00:13:06,390 --> 00:13:13,210
told you I'm a humanitarian mapping so I

00:13:10,240 --> 00:13:19,630
was thinking if I take a random tasks

00:13:13,210 --> 00:13:24,970
from h.o.t test manager and I will apply

00:13:19,630 --> 00:13:28,180
our algorithm how useful it will be this

00:13:24,970 --> 00:13:31,120
is our plan next two tests test these

00:13:28,180 --> 00:13:35,290
things so if you have any suggestion

00:13:31,120 --> 00:13:39,340
they are welcome so if we map the area

00:13:35,290 --> 00:13:42,820
using automatic tools even as I told you

00:13:39,340 --> 00:13:45,910
50% or less or more of the area and then

00:13:42,820 --> 00:13:50,140
the volunteers come to map the rest of

00:13:45,910 --> 00:13:52,840
them this is going to reduce time maybe

00:13:50,140 --> 00:13:55,450
will improve accuracy and also the most

00:13:52,840 --> 00:13:57,580
important for me

00:13:55,450 --> 00:13:59,950
this will create connection between the

00:13:57,580 --> 00:14:04,980
scientific community and OpenStreetMap

00:13:59,950 --> 00:14:04,980
community so thank you

00:14:18,690 --> 00:14:24,100
thank you very much very interesting

00:14:21,790 --> 00:14:27,550
presentation very promising approach I

00:14:24,100 --> 00:14:30,400
think this is one of the very popular

00:14:27,550 --> 00:14:31,870
topic which is discussed very often on

00:14:30,400 --> 00:14:34,840
different mailing lists especially on

00:14:31,870 --> 00:14:39,960
the hot mailing list are there any

00:14:34,840 --> 00:14:39,960
questions or comments

00:14:47,770 --> 00:14:52,550
when you check what it's done afterwards

00:14:50,210 --> 00:14:56,600
is there a way of feeding the errors

00:14:52,550 --> 00:14:59,660
back in to improve the training saying

00:14:56,600 --> 00:15:02,810
can you when you check the output

00:14:59,660 --> 00:15:05,180
manually is there a way of using the

00:15:02,810 --> 00:15:14,510
errors that you spot to improve the

00:15:05,180 --> 00:15:16,910
training for the neural network so using

00:15:14,510 --> 00:15:19,940
knowledge of what it's got wrong with

00:15:16,910 --> 00:15:24,130
the neural network are you then able to

00:15:19,940 --> 00:15:27,620
improve the neural network to retrain it

00:15:24,130 --> 00:15:31,070
to avoid particular things or is it to a

00:15:27,620 --> 00:15:33,890
baked for that improve the neural

00:15:31,070 --> 00:15:37,160
network yes yeah there is there is a

00:15:33,890 --> 00:15:41,450
possibility to improve it for now we

00:15:37,160 --> 00:15:45,380
just tested just for this study we

00:15:41,450 --> 00:15:51,790
tested just one particular neural

00:15:45,380 --> 00:15:57,220
network and we just want you to see the

00:15:51,790 --> 00:16:00,220
differences between other like kebaya

00:15:57,220 --> 00:16:00,220
methods

00:16:07,170 --> 00:16:13,029
yes are your metrics pixel-based

00:16:10,560 --> 00:16:15,130
meaning your Precision's and recalls

00:16:13,029 --> 00:16:18,639
you're measuring them based on the

00:16:15,130 --> 00:16:23,529
number of pixels no we did it on

00:16:18,639 --> 00:16:26,410
polygons per polygon have you maybe

00:16:23,529 --> 00:16:29,380
tried to use the existing osm data to

00:16:26,410 --> 00:16:30,910
train the neural nets why are you taking

00:16:29,380 --> 00:16:32,949
the approach of doing your buyer

00:16:30,910 --> 00:16:35,680
generation instead of using what's

00:16:32,949 --> 00:16:38,440
already in there that was and I said

00:16:35,680 --> 00:16:40,930
that was my first idea and then my

00:16:38,440 --> 00:16:43,709
teacher came and they told me don't use

00:16:40,930 --> 00:16:48,550
it because it's not reliable

00:16:43,709 --> 00:16:49,500
so I have a colleague who did that - he

00:16:48,550 --> 00:16:53,560
used

00:16:49,500 --> 00:16:56,949
OpenStreetMap data from South Sudan to

00:16:53,560 --> 00:17:02,190
train some images - to detect buildings

00:16:56,949 --> 00:17:06,819
and I don't exactly not know now that

00:17:02,190 --> 00:17:13,659
the accuracy but I think it was of over

00:17:06,819 --> 00:17:15,159
90% but yeah it's a good idea for my

00:17:13,659 --> 00:17:16,870
experience I think that's a much better

00:17:15,159 --> 00:17:20,350
approach I think there's even a paper

00:17:16,870 --> 00:17:22,750
that discusses the use of OS and data to

00:17:20,350 --> 00:17:24,370
train a neural nets which shows quite

00:17:22,750 --> 00:17:28,480
good results yeah of course there are

00:17:24,370 --> 00:17:37,450
many papers but all the time on a PhD

00:17:28,480 --> 00:17:38,380
you are told to do something new thank

00:17:37,450 --> 00:17:42,460
you for the very interesting

00:17:38,380 --> 00:17:44,620
presentation back here I'm interested in

00:17:42,460 --> 00:17:47,950
you know you're taught most about

00:17:44,620 --> 00:17:49,900
buildings did you think about any other

00:17:47,950 --> 00:17:52,960
type of subjects that you could text and

00:17:49,900 --> 00:17:55,840
would your approach work I'm mostly

00:17:52,960 --> 00:17:59,620
interested in landfills for example I

00:17:55,840 --> 00:18:01,480
like areas that have a lot of trash I'm

00:17:59,620 --> 00:18:03,760
interested in having a map that would

00:18:01,480 --> 00:18:11,169
you know have have all the trash on it

00:18:03,760 --> 00:18:15,059
on the planet basically in my university

00:18:11,169 --> 00:18:20,549
group we did it on roads too

00:18:15,059 --> 00:18:23,159
but it's the results were not good but

00:18:20,549 --> 00:18:25,710
for me I just do it on on buildings

00:18:23,159 --> 00:18:28,799
because I started to it slam Bell dings

00:18:25,710 --> 00:18:31,230
first and then early when I life I got

00:18:28,799 --> 00:18:34,820
into a slum I I decided that this is not

00:18:31,230 --> 00:18:37,740
going to work so I switched a bit but

00:18:34,820 --> 00:18:41,220
this approach we only applied it for

00:18:37,740 --> 00:18:46,289
nine buildings and it's also important

00:18:41,220 --> 00:18:49,950
to mention that it's not working on huge

00:18:46,289 --> 00:18:59,940
cities with very dense buildings only in

00:18:49,950 --> 00:19:04,860
remote and rural areas other questions

00:18:59,940 --> 00:19:07,559
okay I would like just to take the

00:19:04,860 --> 00:19:09,090
chance to remember to remind that

00:19:07,559 --> 00:19:11,519
tomorrow we will have an academic track

00:19:09,090 --> 00:19:14,659
exactly based on scientific or research

00:19:11,519 --> 00:19:18,899
applications or OpenStreetMap in room s

00:19:14,659 --> 00:19:20,250
1.3 the first floor for the whole day so

00:19:18,899 --> 00:19:22,740
if you are interesting in such

00:19:20,250 --> 00:19:23,850
applications just visit the academic

00:19:22,740 --> 00:19:26,970
track which is of course on the

00:19:23,850 --> 00:19:28,440
programme no more questions so we can

00:19:26,970 --> 00:19:31,309
close this talk

00:19:28,440 --> 00:19:31,309

YouTube URL: https://www.youtube.com/watch?v=iR2rgjUiXww


