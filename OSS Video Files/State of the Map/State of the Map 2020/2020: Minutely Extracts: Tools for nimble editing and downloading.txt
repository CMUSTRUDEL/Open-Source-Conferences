Title: 2020: Minutely Extracts: Tools for nimble editing and downloading
Publication date: 2020-07-18
Playlist: State of the Map 2020
Description: 
	https://media.ccc.de/v/sotm2020-4327-minutely-extracts-tools-for-nimble-editing-and-downloading



OSM is more fun and useful with quicker access to fresh data. New web services, tools and file formats enable mappers to download and use edited data within minutes.

Workflows for adding data to OpenStreetMap keep getting better - but once an edit is uploaded, it can take a long time to appear on hosted map tiles or regional OSM extracts. The experience of downloading and using OpenStreetMap can be improved by quick access to fresh data - a fast feedback loop makes contributing to OSM more enjoyable!

The first part of this talk covers a new web service, Minutely Extracts (protomaps.com/extracts). Mappers can download rectangular or polygon regions of the world, with changes replicated every minute from planet.openstreetmap.org. I’ll show some example workflows for using Minutely Extracts with common GIS applications such as QGIS, and new tools for conversion to formats like GeoPackage and Shapefile.

The second part of this talk describes OSM Express (osmx), a new spatially indexed file format powering Minutely Extracts, that supports in-place updates. Developers needing random access to OSM objects can consider embedding osmx as a library. Near real-time editing activity visualization is one possible use case. I’ll review the technical tradeoffs between using osmx, PBFs and other popular formats.

Financial Background: The software is developed as open source, under a BSD license, and funded by the author's commercial OSM-based SaaS services as well as OSM contract software development.

Brandon Liu

https://2020.stateofthemap.org/sessions/JDNTHK/
Captions: 
	00:00:06,799 --> 00:00:13,710
hi and welcome to our next session we

00:00:11,340 --> 00:00:18,320
have Brandon Lu who is going to talk

00:00:13,710 --> 00:00:22,619
about minimally extracts so tools for

00:00:18,320 --> 00:00:27,090
nimble editing and downloading of the

00:00:22,619 --> 00:00:32,600
edits that go into OpenStreetMap and

00:00:27,090 --> 00:00:35,360
getting fresh data quickly and

00:00:32,600 --> 00:00:40,410
specifically he's going to talk about

00:00:35,360 --> 00:00:49,980
OSM Express which is a new a spatially

00:00:40,410 --> 00:00:52,379
indexed file format hello sit on the map

00:00:49,980 --> 00:00:54,390
I'm here to talk about manila extracts

00:00:52,379 --> 00:00:58,469
and tools for nimble editing and

00:00:54,390 --> 00:01:00,870
downloading so to put this project in

00:00:58,469 --> 00:01:05,280
context I'm going to present a small

00:01:00,870 --> 00:01:07,590
poll I had made to ask map makers who

00:01:05,280 --> 00:01:09,630
use Open Street Map what scale they

00:01:07,590 --> 00:01:11,760
usually work on and about half of

00:01:09,630 --> 00:01:15,000
mappers work on the scale of a city or

00:01:11,760 --> 00:01:19,409
less so that brings us to sort of a

00:01:15,000 --> 00:01:22,080
fundamental task within using LSM which

00:01:19,409 --> 00:01:25,110
is to download a manageable slice of OS

00:01:22,080 --> 00:01:27,990
m because really OS m is the plaintiff

00:01:25,110 --> 00:01:30,840
file it's updated once a week so

00:01:27,990 --> 00:01:34,320
inevitably in order to use OS m you have

00:01:30,840 --> 00:01:36,840
to go to a download site here's one

00:01:34,320 --> 00:01:41,610
example that was running for many years

00:01:36,840 --> 00:01:43,350
metro extracts in this case it had about

00:01:41,610 --> 00:01:45,689
two or three hundred different cities

00:01:43,350 --> 00:01:49,560
that were sliced once a week in two

00:01:45,689 --> 00:01:51,409
different formats but all of these

00:01:49,560 --> 00:01:54,509
download sites have some caveats

00:01:51,409 --> 00:01:57,810
specifically they vary in how often

00:01:54,509 --> 00:02:00,450
they're updated maybe one that is my

00:01:57,810 --> 00:02:03,420
frequent might update once a day but

00:02:00,450 --> 00:02:04,469
then there's also the issue of if you're

00:02:03,420 --> 00:02:07,049
interested in one per team

00:02:04,469 --> 00:02:09,330
like in one specific area that might not

00:02:07,049 --> 00:02:10,950
exist on the download site that or you

00:02:09,330 --> 00:02:15,030
might only be interested in some subset

00:02:10,950 --> 00:02:17,260
of an area in which case it be

00:02:15,030 --> 00:02:18,760
it might be a lot of work to just

00:02:17,260 --> 00:02:21,550
extract whatever you want from that

00:02:18,760 --> 00:02:24,069
pre-processed data so I'm going to talk

00:02:21,550 --> 00:02:24,970
about a brand new web service that I've

00:02:24,069 --> 00:02:28,360
been running and called minimally

00:02:24,970 --> 00:02:29,980
extracts the URL is here it's all public

00:02:28,360 --> 00:02:32,709
already printed maps column slash

00:02:29,980 --> 00:02:34,300
extracts and it's a free web service for

00:02:32,709 --> 00:02:36,730
downloading fresh parts of the OS

00:02:34,300 --> 00:02:40,650
database on demand so here's a quick

00:02:36,730 --> 00:02:42,849
demo of how this this interface works on

00:02:40,650 --> 00:02:44,950
the main page there is sort of

00:02:42,849 --> 00:02:46,630
interactive map you can zoom in on one

00:02:44,950 --> 00:02:49,390
area or interested in let's say I only

00:02:46,630 --> 00:02:52,989
won the island of Manhattan which is

00:02:49,390 --> 00:02:54,580
just right here now what you might be

00:02:52,989 --> 00:02:57,370
inclined to do is just draw a bounding

00:02:54,580 --> 00:02:58,599
box over the entire thing and it does

00:02:57,370 --> 00:03:00,610
support this but really if you do this

00:02:58,599 --> 00:03:03,610
it's kind of wasteful because you're

00:03:00,610 --> 00:03:05,769
bringing in all these nodes in ways that

00:03:03,610 --> 00:03:08,019
are outside Manhattan on the corners

00:03:05,769 --> 00:03:10,540
here so it is a bit more efficient just

00:03:08,019 --> 00:03:14,319
to draw a polygon around only the area

00:03:10,540 --> 00:03:18,910
we're interested in and the idea here is

00:03:14,319 --> 00:03:24,310
that this should be very fast in a

00:03:18,910 --> 00:03:26,109
Manhattan that I can hit create and show

00:03:24,310 --> 00:03:28,150
you some progress bars and it's it

00:03:26,109 --> 00:03:33,790
should be done very quickly now it does

00:03:28,150 --> 00:03:37,299
support up to 100 million nodes so if

00:03:33,790 --> 00:03:40,720
you imagine grabbing like a large slice

00:03:37,299 --> 00:03:43,350
of the east coast of the US that's about

00:03:40,720 --> 00:03:46,870
a hundred million nodes they might take

00:03:43,350 --> 00:03:48,970
like 20 minutes to generate but you can

00:03:46,870 --> 00:03:50,590
do it all at once the other nice thing

00:03:48,970 --> 00:03:53,350
is that if you're if you're actively

00:03:50,590 --> 00:03:54,940
editing the map in this area you can

00:03:53,350 --> 00:03:57,519
download it once you can make your

00:03:54,940 --> 00:03:58,720
changes an idea or jaw's them and then

00:03:57,519 --> 00:04:01,299
you can just hit refresh on this

00:03:58,720 --> 00:04:03,040
existing area and it will have

00:04:01,299 --> 00:04:05,200
incorporated all the changes in those

00:04:03,040 --> 00:04:06,639
minutes that have gone by and you'll be

00:04:05,200 --> 00:04:09,220
able to done with a fresh file that has

00:04:06,639 --> 00:04:10,959
all those updates so really this is

00:04:09,220 --> 00:04:13,389
meant to really close the feedback loop

00:04:10,959 --> 00:04:14,709
between editing and downloading so that

00:04:13,389 --> 00:04:20,470
you're able to take advantage of things

00:04:14,709 --> 00:04:21,820
you make in LSM immediately so for some

00:04:20,470 --> 00:04:23,470
more background on this middle you

00:04:21,820 --> 00:04:25,990
extract service I launched it last year

00:04:23,470 --> 00:04:28,840
a super the map us in September

00:04:25,990 --> 00:04:31,599
and one feature I added last month is

00:04:28,840 --> 00:04:33,340
Alessa metadata there's now version

00:04:31,599 --> 00:04:35,500
numbers for all objects which might make

00:04:33,340 --> 00:04:38,770
it good enough for for uploads and

00:04:35,500 --> 00:04:40,090
editing and there's also timestamp

00:04:38,770 --> 00:04:42,729
change that you IDs name all the other

00:04:40,090 --> 00:04:44,410
fields stored in the database for

00:04:42,729 --> 00:04:45,910
everything except for untag nodes if

00:04:44,410 --> 00:04:49,449
you've worked with raw PDFs before you

00:04:45,910 --> 00:04:51,039
know that these untag nodes are the bulk

00:04:49,449 --> 00:04:54,580
of the storage space so this is sort of

00:04:51,039 --> 00:04:57,520
a space-saving optimization some of

00:04:54,580 --> 00:04:59,770
these fields like the user name are not

00:04:57,520 --> 00:05:00,970
exposed yet on the middle you extract

00:04:59,770 --> 00:05:03,280
site because it

00:05:00,970 --> 00:05:04,810
so because of gdpr I'm working on maybe

00:05:03,280 --> 00:05:09,009
a system to have it login in terms of

00:05:04,810 --> 00:05:11,680
use in order to make that compliant in

00:05:09,009 --> 00:05:13,569
order to integrate these PDF files into

00:05:11,680 --> 00:05:16,539
your workflow so you can use something

00:05:13,569 --> 00:05:18,759
like QGIS which can now open these PDF

00:05:16,539 --> 00:05:22,449
files directly it depends on the OS and

00:05:18,759 --> 00:05:24,780
good old driver but here's an example of

00:05:22,449 --> 00:05:27,190
that Manhattan file opened in QGIS

00:05:24,780 --> 00:05:31,419
it's just kind of your standard GIS

00:05:27,190 --> 00:05:34,900
better editor something else that's new

00:05:31,419 --> 00:05:37,360
is a tool I worked on that's called osm

00:05:34,900 --> 00:05:42,639
export tool Python it was funded by hot

00:05:37,360 --> 00:05:44,919
last year and it lets you transform a

00:05:42,639 --> 00:05:47,169
PDF file into a tabular format such as

00:05:44,919 --> 00:05:49,960
shapefile or geo package or even

00:05:47,169 --> 00:05:51,789
something like garmin IMG and it uses a

00:05:49,960 --> 00:05:55,060
UML definition file that map's

00:05:51,789 --> 00:05:56,919
certain LSM tags to columns so to

00:05:55,060 --> 00:06:00,900
compare this minimally extracts service

00:05:56,919 --> 00:06:05,319
to other services such as the USM API

00:06:00,900 --> 00:06:07,840
well minimally extracts can support up

00:06:05,319 --> 00:06:09,729
to 100 million nodes so if you've ever

00:06:07,840 --> 00:06:12,039
tried to extract something that large

00:06:09,729 --> 00:06:16,180
from the OSM API or even overpass you

00:06:12,039 --> 00:06:19,990
might hit some timeouts so there is sort

00:06:16,180 --> 00:06:22,210
of a goal of being able to export very

00:06:19,990 --> 00:06:24,699
large areas from this and it does

00:06:22,210 --> 00:06:26,979
support I think for people using the

00:06:24,699 --> 00:06:28,000
extract service at a time so you might

00:06:26,979 --> 00:06:32,770
have to wait on line if it gets really

00:06:28,000 --> 00:06:34,300
popular in terms of the completeness of

00:06:32,770 --> 00:06:36,550
the extracts there are multiple agon

00:06:34,300 --> 00:06:38,650
complete which means that ways our

00:06:36,550 --> 00:06:39,670
reference complete and any relation that

00:06:38,650 --> 00:06:42,070
has titan multiple

00:06:39,670 --> 00:06:44,320
gun is gonna be reference complete but

00:06:42,070 --> 00:06:46,810
for example like a boundary relation

00:06:44,320 --> 00:06:49,360
it's not going to be complete because if

00:06:46,810 --> 00:06:51,760
you wanted a small area that touches an

00:06:49,360 --> 00:06:55,180
admin boundary you could potentially

00:06:51,760 --> 00:06:56,980
pull in you know like a lot more data so

00:06:55,180 --> 00:07:00,910
this is sort of it works the same way

00:06:56,980 --> 00:07:03,520
the ostium does like another caveat is

00:07:00,910 --> 00:07:06,640
that areas are not precise in Manilla

00:07:03,520 --> 00:07:08,050
extracts I'll go work that in second

00:07:06,640 --> 00:07:12,010
part of this talk about why that is but

00:07:08,050 --> 00:07:13,450
essentially for any area the actual

00:07:12,010 --> 00:07:15,940
things that are returned are going to be

00:07:13,450 --> 00:07:18,850
some covering or like a small expansion

00:07:15,940 --> 00:07:20,830
of the area that you give it so here's

00:07:18,850 --> 00:07:22,510
the second part of the talk and that's

00:07:20,830 --> 00:07:25,300
about this storage back-end that powers

00:07:22,510 --> 00:07:27,520
in italy extracts it's a new format

00:07:25,300 --> 00:07:29,500
called osm Express it's totally open

00:07:27,520 --> 00:07:31,180
source and I'm a github I'm also working

00:07:29,500 --> 00:07:34,120
on documentation page which you can find

00:07:31,180 --> 00:07:35,940
here and there's a talk I made about it

00:07:34,120 --> 00:07:38,380
the first end of the map us last year

00:07:35,940 --> 00:07:46,390
I'm going to give a quick demo in the

00:07:38,380 --> 00:07:49,120
terminal about how it works so I have a

00:07:46,390 --> 00:07:51,970
couple of files here so this one at the

00:07:49,120 --> 00:07:54,910
top is an extract of Washington DC that

00:07:51,970 --> 00:08:00,790
I downloaded from geo fabric so with the

00:07:54,910 --> 00:08:08,470
expand command I able to convert that to

00:08:00,790 --> 00:08:10,140
an MX file so that takes for a small

00:08:08,470 --> 00:08:14,830
sized city this can take anywhere from

00:08:10,140 --> 00:08:18,190
20 to 30 seconds and what it's doing now

00:08:14,830 --> 00:08:21,310
is it's turning all of the nodes ways

00:08:18,190 --> 00:08:25,660
relations into disk format and also

00:08:21,310 --> 00:08:33,220
creating all these indexes now I can do

00:08:25,660 --> 00:08:34,030
things like query this database file it

00:08:33,220 --> 00:08:37,450
shows me how

00:08:34,030 --> 00:08:40,570
kind of thing there are as well as query

00:08:37,450 --> 00:08:42,850
by a node ID that gives me the location

00:08:40,570 --> 00:08:44,470
and the tags for that node I can also

00:08:42,850 --> 00:08:48,210
create another extract from this

00:08:44,470 --> 00:08:48,210
database file with the extract command

00:08:49,260 --> 00:08:53,500
so in this case I need to give it an

00:08:51,880 --> 00:08:57,600
output file name and also a region I'm

00:08:53,500 --> 00:09:01,090
interested in so I have a Geo JSON of

00:08:57,600 --> 00:09:06,580
the National Mall in DC that is just a

00:09:01,090 --> 00:09:10,930
polygon so I can use some ex extract do

00:09:06,580 --> 00:09:13,000
you see output no send up PDF and give

00:09:10,930 --> 00:09:15,100
it a region which is the National Mall

00:09:13,000 --> 00:09:17,230
so that takes a very short amount of

00:09:15,100 --> 00:09:19,990
time and all the middlee extract server

00:09:17,230 --> 00:09:22,900
is doing is calling that command finally

00:09:19,990 --> 00:09:27,790
so I'm able to apply a diff to the

00:09:22,900 --> 00:09:31,660
database with the update command so in

00:09:27,790 --> 00:09:35,440
this case I have a couple of OSE files I

00:09:31,660 --> 00:09:38,320
can do an LS MX query and it will show

00:09:35,440 --> 00:09:40,720
me the sequence number so because it's

00:09:38,320 --> 00:09:42,010
on to 647 I want to update it to two six

00:09:40,720 --> 00:09:47,260
four eight so I can do something like

00:09:42,010 --> 00:09:51,100
those max update you see two six four

00:09:47,260 --> 00:09:53,160
eight two six four eight and I need to

00:09:51,100 --> 00:10:00,640
give it a timestamp which is like 20

00:09:53,160 --> 00:10:01,810
2006 that's just a number I made up if

00:10:00,640 --> 00:10:03,310
you're using this thing for real in

00:10:01,810 --> 00:10:06,670
production you would get these from the

00:10:03,310 --> 00:10:09,040
state txt file and I didn't commit that

00:10:06,670 --> 00:10:11,740
but you can see that it applied that

00:10:09,040 --> 00:10:13,270
diff to the database quite quickly so if

00:10:11,740 --> 00:10:16,660
you're curious about how the indexing

00:10:13,270 --> 00:10:18,910
works it's all done by s2 cells if you

00:10:16,660 --> 00:10:20,680
see here for a small array like a park

00:10:18,910 --> 00:10:23,920
in a city it covers it what they get the

00:10:20,680 --> 00:10:28,360
number of cells the smallest cell to

00:10:23,920 --> 00:10:29,860
zoom is at that cell level 16 if it's a

00:10:28,360 --> 00:10:34,390
really large area it will approximate

00:10:29,860 --> 00:10:37,030
that with much larger cells so this is

00:10:34,390 --> 00:10:40,900
how it's able to do spatial indexing

00:10:37,030 --> 00:10:44,200
without a lot of expensive point in

00:10:40,900 --> 00:10:47,440
polygon tests really brief one-page

00:10:44,200 --> 00:10:48,820
overview of other details I didn't see

00:10:47,440 --> 00:10:51,280
plus plus uses bunch of popular

00:10:48,820 --> 00:10:52,900
libraries the entire database is one

00:10:51,280 --> 00:10:54,430
file there's no background processes

00:10:52,900 --> 00:10:55,060
like in Postgres it's a lot more like

00:10:54,430 --> 00:10:57,670
sequel night

00:10:55,060 --> 00:11:00,090
you can have one writer and multiple

00:10:57,670 --> 00:11:04,270
reader processes accessing it at its set

00:11:00,090 --> 00:11:05,920
up at the same time it's a PFC to clause

00:11:04,270 --> 00:11:07,540
license so if you want to essentially

00:11:05,920 --> 00:11:10,920
link this into your commercial projects

00:11:07,540 --> 00:11:13,950
that are not open source that's fine and

00:11:10,920 --> 00:11:17,980
from the planet file converting planet

00:11:13,950 --> 00:11:21,400
osm the PDF to Planet X takes about

00:11:17,980 --> 00:11:24,430
seven hours and it's about a 10 X

00:11:21,400 --> 00:11:26,680
expansion in storage size and generally

00:11:24,430 --> 00:11:29,530
needs somewhere between 16 and 30

00:11:26,680 --> 00:11:33,640
gigabytes of RAM so in addition to

00:11:29,530 --> 00:11:36,430
adding object metadata I've also added a

00:11:33,640 --> 00:11:38,230
more full-featured Python library to be

00:11:36,430 --> 00:11:41,020
able to access an OS MX database from

00:11:38,230 --> 00:11:42,880
Python I'm gonna open the browser here

00:11:41,020 --> 00:11:45,550
and take a look at three example

00:11:42,880 --> 00:11:47,680
programs using the Python bindings there

00:11:45,550 --> 00:11:56,440
in this Python and then examples

00:11:47,680 --> 00:11:58,600
directory for the first program it's

00:11:56,440 --> 00:12:00,430
just called read way it's probably the

00:11:58,600 --> 00:12:02,200
simplest not it's probably the simplest

00:12:00,430 --> 00:12:05,680
non-trivial example of a program you can

00:12:02,200 --> 00:12:08,880
write with the Python bindings so I'm

00:12:05,680 --> 00:12:12,580
going to open up the terminal here and I

00:12:08,880 --> 00:12:15,730
have the DCO some X I created previously

00:12:12,580 --> 00:12:19,900
and I can take a look at this program

00:12:15,730 --> 00:12:25,200
which is in the samples directory it's

00:12:19,900 --> 00:12:28,270
very short it's very short it just opens

00:12:25,200 --> 00:12:30,940
the database here and then run some

00:12:28,270 --> 00:12:35,520
queries over it so for example how to

00:12:30,940 --> 00:12:48,400
use that I would just call Python expose

00:12:35,520 --> 00:12:49,370
we'd wait up high and give it an ID yep

00:12:48,400 --> 00:12:52,490
so you can see

00:12:49,370 --> 00:12:56,150
here for this way idea has these node

00:12:52,490 --> 00:12:58,310
locations these tags it's like the

00:12:56,150 --> 00:13:00,800
Lincoln Memorial as well as the metadata

00:12:58,310 --> 00:13:07,550
and also all the relations of that way

00:13:00,800 --> 00:13:12,020
belongs to so the second more advanced

00:13:07,550 --> 00:13:16,520
program I'm going to show is called web

00:13:12,020 --> 00:13:18,890
server it's just a web server that

00:13:16,520 --> 00:13:23,450
returns the Geo JSON for a given osm

00:13:18,890 --> 00:13:27,980
object ID so this is something that you

00:13:23,450 --> 00:13:34,100
would run as process I see if I can open

00:13:27,980 --> 00:13:36,770
this up so just like before I'm going to

00:13:34,100 --> 00:13:37,339
run web server dot pi with the awesome X

00:13:36,770 --> 00:13:40,040
file

00:13:37,339 --> 00:13:43,930
double this long it's an import and if I

00:13:40,040 --> 00:13:50,800
go back to my browser and I go to

00:13:43,930 --> 00:13:50,800
localhost / away and give it away ID I

00:13:51,190 --> 00:13:57,800
can see the geo JSON there so I can even

00:13:53,959 --> 00:14:01,459
take this geo JSON and visualize it on a

00:13:57,800 --> 00:14:03,020
site like geo JSON i/o so that's almost

00:14:01,459 --> 00:14:05,690
like you could recreate the

00:14:03,020 --> 00:14:09,370
OpenStreetMap API like a auto-awesome

00:14:05,690 --> 00:14:12,230
don't work / way / ID you can create a

00:14:09,370 --> 00:14:14,270
an ICU I like that just using this web

00:14:12,230 --> 00:14:16,550
server it only uses the Python standard

00:14:14,270 --> 00:14:18,260
library probably not production-ready

00:14:16,550 --> 00:14:20,450
they might have some performance or

00:14:18,260 --> 00:14:21,380
security issues but it's a good starting

00:14:20,450 --> 00:14:25,010
point if you wanted to build something

00:14:21,380 --> 00:14:26,959
more advanced finally the third program

00:14:25,010 --> 00:14:30,230
is much more complicated

00:14:26,959 --> 00:14:34,580
it's called augmented diff so an

00:14:30,230 --> 00:14:37,850
augmented diff is kind of like an OSC

00:14:34,580 --> 00:14:40,339
change file but it is referenced

00:14:37,850 --> 00:14:42,400
complete so if there's ways in the

00:14:40,339 --> 00:14:45,820
change file that also includes all the

00:14:42,400 --> 00:14:50,089
node location information and it also

00:14:45,820 --> 00:14:52,550
shows you if a node location change it

00:14:50,089 --> 00:14:56,089
affects the ways that that NIT belongs

00:14:52,550 --> 00:15:00,890
to so the idea here is that I can

00:14:56,089 --> 00:15:03,320
implement augmented ifs just using an

00:15:00,890 --> 00:15:06,560
OSC file and as well as

00:15:03,320 --> 00:15:07,699
that was some X database the semantics

00:15:06,560 --> 00:15:10,040
here are slightly different than how

00:15:07,699 --> 00:15:11,839
overpass works since overpass uses

00:15:10,040 --> 00:15:15,589
timestamps and not the replication

00:15:11,839 --> 00:15:20,480
sequence IDs all that documentation is

00:15:15,589 --> 00:15:22,940
on the other some wiki on this page you

00:15:20,480 --> 00:15:27,199
can also read my issue about it in the

00:15:22,940 --> 00:15:29,449
OS MX github issues tracker but to give

00:15:27,199 --> 00:15:37,009
you the idea of how this works I'm going

00:15:29,449 --> 00:15:40,190
to go back to the terminal and run this

00:15:37,009 --> 00:15:45,290
Luckman to diff program so you can see I

00:15:40,190 --> 00:15:50,660
would take in a osm X database as well

00:15:45,290 --> 00:15:52,399
as an OSC file in order to know which

00:15:50,660 --> 00:15:55,730
sequence number I'm at I can do and it

00:15:52,399 --> 00:15:59,720
was some xquery on that so I need to

00:15:55,730 --> 00:16:02,569
apply sequence to six four eight so

00:15:59,720 --> 00:16:04,430
before I apply the diff I can run out

00:16:02,569 --> 00:16:07,610
this lock might say diff Python program

00:16:04,430 --> 00:16:15,079
on two six four eight and then let's

00:16:07,610 --> 00:16:17,380
output it to diff XML so now I have a

00:16:15,079 --> 00:16:17,380
diff

00:16:18,410 --> 00:16:23,750
that shows me all the actions like

00:16:20,720 --> 00:16:27,709
modified create or delete I can even go

00:16:23,750 --> 00:16:32,810
into my browser and use HIV which

00:16:27,709 --> 00:16:39,740
visualizes log my two dips and then drag

00:16:32,810 --> 00:16:41,899
and drop my output onto here and it

00:16:39,740 --> 00:16:43,870
shows me all of the things that happened

00:16:41,899 --> 00:16:46,610
in that daily diff so I can click on

00:16:43,870 --> 00:16:50,449
away in more detail and see more

00:16:46,610 --> 00:16:52,010
information like that I'm going to talk

00:16:50,449 --> 00:16:56,360
about some of the next steps for both

00:16:52,010 --> 00:17:00,019
movie extracts and Ellison Express so

00:16:56,360 --> 00:17:01,850
the library itself is fairly feature

00:17:00,019 --> 00:17:05,089
complete as it is I want to keep it

00:17:01,850 --> 00:17:06,530
quite minimal and I intend for it to be

00:17:05,089 --> 00:17:09,980
more of the building block for other

00:17:06,530 --> 00:17:12,760
programs so performance and operational

00:17:09,980 --> 00:17:15,020
simplicity are the overarching goals

00:17:12,760 --> 00:17:16,189
some of the things I want to add our

00:17:15,020 --> 00:17:17,310
support for more languages especially

00:17:16,189 --> 00:17:18,840
spatial support

00:17:17,310 --> 00:17:21,600
Python that would require bringing in

00:17:18,840 --> 00:17:26,310
the s2 library other languages something

00:17:21,600 --> 00:17:29,250
about or especially go Java and rust the

00:17:26,310 --> 00:17:31,320
build process can be improved right now

00:17:29,250 --> 00:17:34,200
there is a hard dependency on open SSL

00:17:31,320 --> 00:17:39,540
that would need to be patched in s2

00:17:34,200 --> 00:17:41,130
upstream and I do intend to keep the

00:17:39,540 --> 00:17:43,830
minimally extracts as a free service

00:17:41,130 --> 00:17:46,790
offered by proto Mouse bunny company to

00:17:43,830 --> 00:17:49,260
improve the mapping experience for both

00:17:46,790 --> 00:17:53,430
people that are editing the map and map

00:17:49,260 --> 00:17:54,840
users I am supporting this through some

00:17:53,430 --> 00:17:57,560
commercial offerings you should go to a

00:17:54,840 --> 00:18:03,060
programmatic combo check those out and

00:17:57,560 --> 00:18:04,620
also if you need integration with om

00:18:03,060 --> 00:18:07,410
Express or you want to sponsor features

00:18:04,620 --> 00:18:10,880
please contact me at Brandon at proto

00:18:07,410 --> 00:18:10,880
Mouse calm thanks

00:18:18,380 --> 00:18:26,460
Thank You Brandon there was a lot of

00:18:21,870 --> 00:18:31,230
information in those 20 minutes there so

00:18:26,460 --> 00:18:35,850
we have some questions from the audience

00:18:31,230 --> 00:18:39,540
first question what do you think are the

00:18:35,850 --> 00:18:42,390
advantages of overpass over OS m Express

00:18:39,540 --> 00:18:43,860
and you talked a little bit about the

00:18:42,390 --> 00:18:49,020
differences between you two but what are

00:18:43,860 --> 00:18:50,790
the advantages one over the other right

00:18:49,020 --> 00:18:53,040
so overpass is something that I use a

00:18:50,790 --> 00:18:56,100
lot it is a much more full-featured

00:18:53,040 --> 00:18:58,350
application it has sort of like a server

00:18:56,100 --> 00:19:00,270
process that you run so like if you

00:18:58,350 --> 00:19:02,850
wanted to build like a pretty simple

00:19:00,270 --> 00:19:05,130
program that only needs to query it like

00:19:02,850 --> 00:19:08,730
you don't want to have to run entire

00:19:05,130 --> 00:19:11,580
like set of server processes to run

00:19:08,730 --> 00:19:13,590
overpass so my focus was more on

00:19:11,580 --> 00:19:16,110
building something that is like a like a

00:19:13,590 --> 00:19:18,000
really low level building block and it's

00:19:16,110 --> 00:19:19,920
sort of like more maintainable and

00:19:18,000 --> 00:19:22,350
easier to operationalize if you're

00:19:19,920 --> 00:19:23,400
building a production service you might

00:19:22,350 --> 00:19:25,620
want to just use something that's like

00:19:23,400 --> 00:19:28,020
very minimal and doesn't have all the

00:19:25,620 --> 00:19:29,160
nice features of overpass since with

00:19:28,020 --> 00:19:32,040
overpass you can do a lot of things you

00:19:29,160 --> 00:19:34,830
can query by time you can query by by

00:19:32,040 --> 00:19:38,310
area but all those great features kind

00:19:34,830 --> 00:19:45,090
of make it like a lot more more on

00:19:38,310 --> 00:19:47,760
ability to operationalize somebody asked

00:19:45,090 --> 00:19:51,960
is there a difference compared to the

00:19:47,760 --> 00:19:56,400
download function of Jocelin there

00:19:51,960 --> 00:19:59,760
should be there should be some slight

00:19:56,400 --> 00:20:02,910
differences so a load function of

00:19:59,760 --> 00:20:06,090
Johnson will hit the OSM API so that's

00:20:02,910 --> 00:20:12,150
like like slash zero point six slash API

00:20:06,090 --> 00:20:15,180
slash map and that only supports pretty

00:20:12,150 --> 00:20:16,470
limited numbers of data like it'd be I'd

00:20:15,180 --> 00:20:18,590
be surprised if you could get more than

00:20:16,470 --> 00:20:22,440
like it like a couple hundred megabytes

00:20:18,590 --> 00:20:24,600
from the jaws M download apportion so if

00:20:22,440 --> 00:20:25,850
you wanted to get a much larger chunk of

00:20:24,600 --> 00:20:28,410
data

00:20:25,850 --> 00:20:31,320
you could use vanilla extracts or you

00:20:28,410 --> 00:20:34,530
could use this extract service but in

00:20:31,320 --> 00:20:36,810
theory the PPF you get should be

00:20:34,530 --> 00:20:38,250
completely usable as if you were

00:20:36,810 --> 00:20:40,860
downloading from another download site

00:20:38,250 --> 00:20:43,920
like geo fabric there is that small

00:20:40,860 --> 00:20:48,090
caveat that for untag nodes I don't

00:20:43,920 --> 00:20:49,230
store metadata so if you it's not 100%

00:20:48,090 --> 00:20:52,230
complete that's more of a compromise

00:20:49,230 --> 00:20:55,470
that I made in that design but for most

00:20:52,230 --> 00:21:01,740
these cases it should be more than

00:20:55,470 --> 00:21:04,140
enough so there was so there's a several

00:21:01,740 --> 00:21:07,680
questions that people have asked ahead

00:21:04,140 --> 00:21:10,260
of time and that brandon has answered in

00:21:07,680 --> 00:21:13,950
the hack pad itself I'm not going to

00:21:10,260 --> 00:21:15,300
read them out loud but there is one

00:21:13,950 --> 00:21:17,100
question here that was apparently

00:21:15,300 --> 00:21:19,320
answered on Twitter so I'm gonna go

00:21:17,100 --> 00:21:22,080
ahead and ask it so the audience gets

00:21:19,320 --> 00:21:25,470
the benefit of that question which is

00:21:22,080 --> 00:21:26,100
can you share the graph simplification

00:21:25,470 --> 00:21:30,510
tricks

00:21:26,100 --> 00:21:37,070
I think that's related to something else

00:21:30,510 --> 00:21:37,070
that I posted on Twitter not part of

00:21:37,310 --> 00:21:43,320
it's not part of us and Express but like

00:21:40,530 --> 00:21:45,930
it is related in that if you have access

00:21:43,320 --> 00:21:48,450
to raw SM geometries instead of a

00:21:45,930 --> 00:21:51,000
special feature in Postgres you can act

00:21:48,450 --> 00:21:54,120
on those features as a graph instead of

00:21:51,000 --> 00:21:56,850
just as line strings so you can do some

00:21:54,120 --> 00:22:00,030
clever things related to things like

00:21:56,850 --> 00:22:03,630
cartography of road networks if you're

00:22:00,030 --> 00:22:06,060
acting on osm data itself and not like a

00:22:03,630 --> 00:22:09,480
not like you know not like an OD see

00:22:06,060 --> 00:22:11,760
simple features like line string but

00:22:09,480 --> 00:22:18,750
that's that's like pretty tendon pretty

00:22:11,760 --> 00:22:21,420
not related to that talk yeah so I think

00:22:18,750 --> 00:22:23,370
during the talk you mentioned I think

00:22:21,420 --> 00:22:25,440
this was from minute Li expressed that

00:22:23,370 --> 00:22:28,800
there were you could have like four

00:22:25,440 --> 00:22:34,020
queries going on at once and so there

00:22:28,800 --> 00:22:36,240
might be a line how how much youths are

00:22:34,020 --> 00:22:37,530
are you seeing is this is there

00:22:36,240 --> 00:22:38,950
something that that's good that's going

00:22:37,530 --> 00:22:42,200
to get overloaded

00:22:38,950 --> 00:22:43,820
not right now maybe I'm under estimating

00:22:42,200 --> 00:22:46,940
the amount of people that want to

00:22:43,820 --> 00:22:50,680
download some data I feel like that's

00:22:46,940 --> 00:22:54,440
like pretty DS and I'd be surprised if

00:22:50,680 --> 00:22:56,000
if it was like overloaded but I think in

00:22:54,440 --> 00:22:59,210
general like I'd encourage people to use

00:22:56,000 --> 00:23:00,740
it because I do feel like the benefit is

00:22:59,210 --> 00:23:04,820
that you can take advantage of things

00:23:00,740 --> 00:23:07,610
you upload immediately to osm because to

00:23:04,820 --> 00:23:09,800
me like one of the central issues that

00:23:07,610 --> 00:23:12,080
like it's a challenge for OSM is sort of

00:23:09,800 --> 00:23:13,610
being alienated from the things you're

00:23:12,080 --> 00:23:16,310
adding to the data set it's like you can

00:23:13,610 --> 00:23:18,050
like there's this value prop up on some

00:23:16,310 --> 00:23:20,870
day you can edit the data like so anyone

00:23:18,050 --> 00:23:23,720
can edit the data but once you you you

00:23:20,870 --> 00:23:25,400
like you add it in and you have to wait

00:23:23,720 --> 00:23:27,680
like a day before I shows up on some

00:23:25,400 --> 00:23:30,530
download extract site that's like kind

00:23:27,680 --> 00:23:34,070
of dampens the mood so I'd really

00:23:30,530 --> 00:23:35,180
encourage people to use it more that's

00:23:34,070 --> 00:23:37,580
kind of why I wanted to make it really

00:23:35,180 --> 00:23:39,860
fast so if you're just working on some

00:23:37,580 --> 00:23:41,870
little neighborhood or even like a small

00:23:39,860 --> 00:23:46,730
size city you should be dining with in

00:23:41,870 --> 00:23:52,070
like a couple of seconds well we'll see

00:23:46,730 --> 00:23:55,070
how popular this talk ends up you may be

00:23:52,070 --> 00:24:01,190
you may end up getting more use than you

00:23:55,070 --> 00:24:05,300
anticipated so you you suggested so

00:24:01,190 --> 00:24:08,390
somebody asked what use cases you

00:24:05,300 --> 00:24:13,780
thought might benefit from immediately

00:24:08,390 --> 00:24:18,610
extracts at osm and you mentioned maybe

00:24:13,780 --> 00:24:23,480
live updated statistics or vandalism

00:24:18,610 --> 00:24:27,530
this what I was wondering was can you go

00:24:23,480 --> 00:24:33,470
into a little more detail about how how

00:24:27,530 --> 00:24:38,240
someone would I how what's the what is

00:24:33,470 --> 00:24:41,300
the benefit of using minute layout

00:24:38,240 --> 00:24:47,120
tracks and os MX versus I think just

00:24:41,300 --> 00:24:49,580
getting the the minute change sets so

00:24:47,120 --> 00:24:52,220
from my understanding the minute change

00:24:49,580 --> 00:24:54,830
sets are it used that much for an

00:24:52,220 --> 00:24:55,400
Linux or like vandalism detection that

00:24:54,830 --> 00:24:58,450
kind of thing

00:24:55,400 --> 00:25:02,090
most applications use augmented diffs

00:24:58,450 --> 00:25:03,440
and augment like are kind of an open

00:25:02,090 --> 00:25:06,080
specification that's published on the

00:25:03,440 --> 00:25:09,110
wiki but from my understanding the only

00:25:06,080 --> 00:25:10,909
implementation is inside overpass so you

00:25:09,110 --> 00:25:13,309
still kind of have this like this

00:25:10,909 --> 00:25:15,400
dependency on probably a public overpass

00:25:13,309 --> 00:25:17,900
server if you wanted to build a system

00:25:15,400 --> 00:25:22,669
like you're kind of relying on overpass

00:25:17,900 --> 00:25:24,200
to to provide the data so what I'm

00:25:22,669 --> 00:25:26,600
really trying to do is like try to try

00:25:24,200 --> 00:25:30,620
trying to like diversify the tooling

00:25:26,600 --> 00:25:32,150
around these change sets so that if you

00:25:30,620 --> 00:25:34,580
wanted to build for example another

00:25:32,150 --> 00:25:36,409
change to analyzer you could do that in

00:25:34,580 --> 00:25:38,210
a very self-contained way and you could

00:25:36,409 --> 00:25:42,230
even do that in a way that is totally

00:25:38,210 --> 00:25:44,450
offline so if you had a server that was

00:25:42,230 --> 00:25:46,820
like off the grid and you could only

00:25:44,450 --> 00:25:49,400
consume change sets from Planet Oh Simon

00:25:46,820 --> 00:25:52,610
org you know like once a week you could

00:25:49,400 --> 00:25:55,640
still operate on that Oh some data and

00:25:52,610 --> 00:25:57,500
do interesting things because you

00:25:55,640 --> 00:26:01,720
essentially have like a mirror of that

00:25:57,500 --> 00:26:04,940
data losslessly so I think in general

00:26:01,720 --> 00:26:09,289
it's not as much that I'm adding

00:26:04,940 --> 00:26:12,530
features to these dips it's more that

00:26:09,289 --> 00:26:14,480
I'm providing a new and more sort of

00:26:12,530 --> 00:26:30,130
low-level building block way of creating

00:26:14,480 --> 00:26:36,940
them and then you I think you mentioned

00:26:30,130 --> 00:26:49,460
in your last slide your sort of roadmap

00:26:36,940 --> 00:26:52,400
for for the projects what I what do you

00:26:49,460 --> 00:26:56,870
think do you think you'll have an update

00:26:52,400 --> 00:26:59,830
for state of the math us or what what's

00:26:56,870 --> 00:26:59,830
what's the timeline

00:27:00,420 --> 00:27:05,940
in terms of updates the thing I want to

00:27:03,600 --> 00:27:08,820
do the most is add support for more

00:27:05,940 --> 00:27:10,170
languages because like so SM is like

00:27:08,820 --> 00:27:12,090
really diverse in terms of the

00:27:10,170 --> 00:27:13,530
developers working on it you know

00:27:12,090 --> 00:27:16,970
there's like people that use things like

00:27:13,530 --> 00:27:21,630
net or Ruby and I think one of the most

00:27:16,970 --> 00:27:23,400
impactful things to do yet is to support

00:27:21,630 --> 00:27:27,570
more languages so that even if you're

00:27:23,400 --> 00:27:29,580
not you know let a like C++ program or a

00:27:27,570 --> 00:27:32,520
Python programmer you can take advantage

00:27:29,580 --> 00:27:33,900
of using the data format and that's

00:27:32,520 --> 00:27:38,460
really going to be driven by the demand

00:27:33,900 --> 00:27:41,220
of developers so I invite basically all

00:27:38,460 --> 00:27:43,920
devs to go onto the github and post

00:27:41,220 --> 00:27:47,520
issues on what you want because I'm

00:27:43,920 --> 00:27:49,910
hoping this will be like a like a like a

00:27:47,520 --> 00:27:52,980
project that's managed by the community

00:27:49,910 --> 00:27:54,330
so I don't have any concrete steps on

00:27:52,980 --> 00:27:57,440
what I want to accomplish in the next

00:27:54,330 --> 00:27:59,940
months or the next year it's more like

00:27:57,440 --> 00:28:01,620
like if people have a specific problem

00:27:59,940 --> 00:28:03,930
they're trying to solve or like a

00:28:01,620 --> 00:28:07,280
language they're using I'd be more

00:28:03,930 --> 00:28:07,280
interested in helping them do that so

00:28:07,850 --> 00:28:17,010
everybody get on github and post your

00:28:11,850 --> 00:28:22,290
issues actually brand it if you could

00:28:17,010 --> 00:28:24,990
post into the hackpad the github repo

00:28:22,290 --> 00:28:35,930
the link to the github repo so everyone

00:28:24,990 --> 00:28:35,930
has the benefit of that yep reconnect

00:28:38,650 --> 00:28:45,490
and it is all your documentation in the

00:28:42,410 --> 00:28:49,460
github repo or do you have a website

00:28:45,490 --> 00:28:52,310
there is a documentation website that's

00:28:49,460 --> 00:28:55,940
more long form it is a proto Maps comm

00:28:52,310 --> 00:28:58,870
slash Doc's do CS but there is a link to

00:28:55,940 --> 00:29:01,150
that in the github so the link ax or

00:28:58,870 --> 00:29:07,490
sorry they've read me out github has

00:29:01,150 --> 00:29:09,650
links to most of the other resources all

00:29:07,490 --> 00:29:13,970
right so the github link is now in the

00:29:09,650 --> 00:29:19,910
hackpad great so I think anybody who

00:29:13,970 --> 00:29:23,600
wants to explore further is it is minute

00:29:19,910 --> 00:29:24,620
Li I know you talked about a couple of

00:29:23,600 --> 00:29:27,320
different things you talked about the

00:29:24,620 --> 00:29:29,600
index and you talked about literally

00:29:27,320 --> 00:29:32,750
express those different links or is that

00:29:29,600 --> 00:29:35,660
all in one place they should all be in

00:29:32,750 --> 00:29:37,610
the same place right now I've focused

00:29:35,660 --> 00:29:42,260
everything like into that one github

00:29:37,610 --> 00:29:44,450
repo it's possible that there might be

00:29:42,260 --> 00:29:52,690
more in the future but I'll be using the

00:29:44,450 --> 00:29:52,690
github readme at central place right oh

00:29:57,580 --> 00:30:06,350
well I think that that is it for the

00:30:03,260 --> 00:30:13,940
questions that were not answered ahead

00:30:06,350 --> 00:30:16,520
of time so any closing thoughts I'll

00:30:13,940 --> 00:30:19,760
address one question I saw multiple

00:30:16,520 --> 00:30:22,760
people have which is supporting extracts

00:30:19,760 --> 00:30:24,350
by region that it is something that I'm

00:30:22,760 --> 00:30:27,020
working on it's a bit challenging

00:30:24,350 --> 00:30:29,300
because if any of you have worked with

00:30:27,020 --> 00:30:32,120
admin boundaries in osm before you know

00:30:29,300 --> 00:30:34,700
they are a nightmare especially once you

00:30:32,120 --> 00:30:36,320
get into super relations like if you

00:30:34,700 --> 00:30:39,590
wanted to get the entire United States

00:30:36,320 --> 00:30:41,840
as one relation that has like tens of

00:30:39,590 --> 00:30:44,750
thousands of nodes so that's the main

00:30:41,840 --> 00:30:45,860
challenge in making that work but that

00:30:44,750 --> 00:30:48,650
is something that I want to support the

00:30:45,860 --> 00:30:49,890
site which is being able to extract for

00:30:48,650 --> 00:30:52,200
example adjust your say

00:30:49,890 --> 00:30:54,180
or even just your neighborhood as long

00:30:52,200 --> 00:30:57,810
as there is an awesome relation for that

00:30:54,180 --> 00:31:03,210
place so that yeah that is one feature

00:30:57,810 --> 00:31:03,870
that I am actively working on all right

00:31:03,210 --> 00:31:06,930
great

00:31:03,870 --> 00:31:09,230
Thank You Brandon everyone go check out

00:31:06,930 --> 00:31:09,230
their kids

00:31:17,690 --> 00:31:19,750

YouTube URL: https://www.youtube.com/watch?v=lnoxVVMUy1I


