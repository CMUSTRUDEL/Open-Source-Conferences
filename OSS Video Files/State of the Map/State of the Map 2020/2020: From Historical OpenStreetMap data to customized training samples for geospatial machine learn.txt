Title: 2020: From Historical OpenStreetMap data to customized training samples for geospatial machine learn
Publication date: 2020-07-18
Playlist: State of the Map 2020
Description: 
	https://media.ccc.de/v/state-of-the-map-2020-academic-track-4527-from-historical-openstreetmap-data-to-customized-training-samples-for-geospatial-machine-learning



Recently, OpenStreetMap (OSM) shows great potentials in providing massive and freely accessible training samples to further empower geospatial machine learning activities. We developed a flexible framework to automatically generate customized training samples from historical OSM data, which in the meantime provide the OSM intrinsic quality measurements as an additional feature. Moreover, different satellite imagery APIs and machine learning tasks are supported within the framework.

After more than a decade rapid development of volunteered geographic information (VGI), VGI has already become one of the most important research topics in GIScience community [1]. Almost in the meantime, we have witnessed the ever-fast growth of geospatial machine learning technologies in intelligent GiServices [2] or addressing remote sensing tasks [3], for instance land use land cover classification, object detection, and change detection. Nevertheless, the lack of abundant training samples as well as accurate semantic information has been long identified as a modelling  bottleneck of such data-hungry machine learning application. Correspondingly, OpenStreetMap (OSM) shows great potentials in tackling this bottleneck challenge by providing massive and freely accessible geospatial training samples [4]. More importantly, OSM has exclusive access to its full historical data [5], which could be further analyzed and employed to provide intrinsic data quality measurements of the training samples. Therefore, a flexible framework for labeling customized geospatial objects using historical OSM data allows more effective and efficient machine learning.

This work approaches the topic of labeling geospatial machine learning samples by providing a flexible framework for automatically customized training samples generation and intrinsic data quality measurement. In more detail, we explored the historical OSM data for twofold purposes of feature extraction and intrinsic assessment. For examples, when training a building detection convolutional neural networks (CNNs), the OSM features with tags as building=residential or building=house are certainly of interests while the data quality of such features might play an important role later in the CNNs training phase. Therefore, besides the acquisition of the user-defined OSM features, we provide additional intrinsic quality measurements. Currently, we consider some basic statistics, such as the areas of buildings tagged with different OSM tags, the amount of distinct contributors in the last six months, or the equisdistance of polygons with landuse=cropland etc , since the existing research suggested that the lower equisdistance of the current polygon, the better relative quality of the polygon, which due to the further refining and editing from users [6]. In the future, one could also easily extend the current framework and develop other sophisticated quality indicators for specific “fitness-for-use” purposes.

Heterogeneous remote sensing APIs are supported within the framework, user’s option ranges from commercial satellite image providers (e.g., Bing or Mapbox) to government satellite missions (e.g., Sentinel-hub), even user-defined tile map service (TMS) API. Correspond to OSM features, the satellite image would be automatically downloaded via TMS and tiled into proper size. Moreover, this framework also supports different machine learning tasks, like classification, object detection, and semantic segmentation, which requires distinct sample formats. The preliminary test is performed to extract the geographical information of water dams with OSM tag waterway=dam, which enables the training of water dams detection CNNs, where users could easily change the geospatial water dams to customize objects as long as the corresponding OSM tags are identified.

This work aim to promote the application of geospatial machine learning by generating and assessing OSM training samples of user-specified objects, which not only allows user to train geospatial detection models, but also introduce the intrinsic quality assessment into the “black box” of the training of machine learning models. Based on a deeper understanding of training samples quality, future efforts are needed towards more understandable and geographical aware machine learning models.
References

[1]     Yan, Y.,   Feng, C.,  Huang, W., Fan, H.,  Wang, Y. & Zipf, A., (2020) Volunteered geographic information research in the first decade: a narrative review of selected journal articles in GIScience, International Journal of Geographical Information Science.

[2]    Yue, P., Baumann, P., Bugbee, K. & Jiang, L., (2015). Towards intelligent GIServices. Earth Sci Inform 8, 463–481. 

[3]     Zhu, X., Tuia, D., Mou, L., Xia, G., Zhang, L., Xu, F. & Fraundorfer, F. (2017) Deep Learnin
Captions: 
	00:00:07,600 --> 00:00:11,440
hello everyone

00:00:08,559 --> 00:00:11,920
um uh thank you for coming to this

00:00:11,440 --> 00:00:15,200
session

00:00:11,920 --> 00:00:18,000
my name is gordon yabua and i will be um

00:00:15,200 --> 00:00:19,119
your session chair uh for this talk and

00:00:18,000 --> 00:00:22,720
um

00:00:19,119 --> 00:00:26,880
so for this um talk if um

00:00:22,720 --> 00:00:31,840
you want to ask any questions um you can

00:00:26,880 --> 00:00:31,840
go to um the conference um

00:00:32,239 --> 00:00:38,079
you can go to the conference webpage i'm

00:00:34,880 --> 00:00:38,079
going to show you the link

00:00:41,120 --> 00:00:44,800
so once you go to the conference web

00:00:43,200 --> 00:00:50,160
page here

00:00:44,800 --> 00:00:54,320
you can go to the talks for today

00:00:50,160 --> 00:00:56,559
and then uh scroll to

00:00:54,320 --> 00:00:58,320
this presentation that we're about to

00:00:56,559 --> 00:01:00,160
listen to

00:00:58,320 --> 00:01:02,079
and then on the left side you will see a

00:01:00,160 --> 00:01:06,000
session part which is

00:01:02,079 --> 00:01:08,560
a part for asking questions so

00:01:06,000 --> 00:01:10,640
what we're going to do is to listen to a

00:01:08,560 --> 00:01:13,600
recorded version of the talk

00:01:10,640 --> 00:01:14,560
and then uh after that we will have a

00:01:13,600 --> 00:01:16,799
question announces

00:01:14,560 --> 00:01:18,640
uh uh session and this is what we're

00:01:16,799 --> 00:01:21,439
going to use so as the talk is

00:01:18,640 --> 00:01:23,200
going on you can um put your questions

00:01:21,439 --> 00:01:26,400
here

00:01:23,200 --> 00:01:28,799
and then you can also put comments here

00:01:26,400 --> 00:01:30,799
also you can also have further

00:01:28,799 --> 00:01:31,360
information or read further information

00:01:30,799 --> 00:01:33,280
uh

00:01:31,360 --> 00:01:35,119
from the conference proceedings here the

00:01:33,280 --> 00:01:38,720
links are provided

00:01:35,119 --> 00:01:40,720
in the part here and

00:01:38,720 --> 00:01:41,759
you can also have some links uh which is

00:01:40,720 --> 00:01:43,759
linked to the

00:01:41,759 --> 00:01:44,799
i think the codes for the program for

00:01:43,759 --> 00:01:47,840
the for the um

00:01:44,799 --> 00:01:48,240
study that we uh you're about to um uh

00:01:47,840 --> 00:01:49,920
here

00:01:48,240 --> 00:01:52,799
and then also if you're interested you

00:01:49,920 --> 00:01:56,079
can also go to osm science mailing list

00:01:52,799 --> 00:02:00,560
uh to register and

00:01:56,079 --> 00:02:00,560
discuss research ideas in the future

00:02:00,799 --> 00:02:05,600
so now i will share my screen and then

00:02:06,799 --> 00:02:10,720
introduce the uh presenter and then we

00:02:08,800 --> 00:02:14,160
listen to the recorded um

00:02:10,720 --> 00:02:16,560
presentation so um

00:02:14,160 --> 00:02:17,840
two people uh two uh speakers are going

00:02:16,560 --> 00:02:21,200
to uh

00:02:17,840 --> 00:02:24,480
present uh this study um one is uh

00:02:21,200 --> 00:02:27,599
chao yan uh chauyan wu and uh har

00:02:24,480 --> 00:02:30,239
lee so uh for

00:02:27,599 --> 00:02:32,160
charion wu chiang yuu uh studies for his

00:02:30,239 --> 00:02:35,680
phd in wuhan university

00:02:32,160 --> 00:02:38,319
and joined a year science uh group

00:02:35,680 --> 00:02:38,959
at heidelberg university um as an

00:02:38,319 --> 00:02:42,560
exchange

00:02:38,959 --> 00:02:45,040
phd scholar his research

00:02:42,560 --> 00:02:46,000
interests include a volunteer geographic

00:02:45,040 --> 00:02:47,840
information

00:02:46,000 --> 00:02:50,319
geospatial deep learning on a high

00:02:47,840 --> 00:02:54,239
performance geographic computing

00:02:50,319 --> 00:02:57,680
and harley the second speaker or the

00:02:54,239 --> 00:02:59,760
the next speaker the person presenting

00:02:57,680 --> 00:03:02,720
with uh charlie and wu

00:02:59,760 --> 00:03:03,680
is currently works at um as a phd

00:03:02,720 --> 00:03:05,200
researcher in

00:03:03,680 --> 00:03:07,360
gi science group at heidelberg

00:03:05,200 --> 00:03:07,840
university his research interests

00:03:07,360 --> 00:03:10,319
include

00:03:07,840 --> 00:03:11,360
volunteered geographic information

00:03:10,319 --> 00:03:14,879
geosemantics

00:03:11,360 --> 00:03:18,000
and remote sensing applications

00:03:14,879 --> 00:03:18,480
the the title as you can see on the

00:03:18,000 --> 00:03:21,280
title

00:03:18,480 --> 00:03:23,440
on the webpage the title of the of the

00:03:21,280 --> 00:03:25,920
talk is from historical openstreetmap

00:03:23,440 --> 00:03:26,640
data to customized uh training samples

00:03:25,920 --> 00:03:29,680
for

00:03:26,640 --> 00:03:32,799
uh geospatial machine learning so

00:03:29,680 --> 00:03:38,319
now i will hand over to

00:03:32,799 --> 00:03:38,319
charion woo to start the presentation

00:03:40,239 --> 00:03:46,319
hello everyone my name is joey woo

00:03:43,360 --> 00:03:47,200
and i am a phd student in ohio

00:03:46,319 --> 00:03:50,239
university

00:03:47,200 --> 00:03:53,280
china from last

00:03:50,239 --> 00:03:56,319
year i came to hatbury university

00:03:53,280 --> 00:04:00,640
and joined the g science group as a

00:03:56,319 --> 00:04:04,159
exchange phd student today my topic is

00:04:00,640 --> 00:04:07,280
from historical openstreetmap data

00:04:04,159 --> 00:04:09,599
to customize the training samples for

00:04:07,280 --> 00:04:12,720
geospatial machine learning

00:04:09,599 --> 00:04:16,000
the topic were given by me and how

00:04:12,720 --> 00:04:20,720
how a phd student

00:04:16,000 --> 00:04:20,720
in g science group hedberg university

00:04:21,359 --> 00:04:27,280
the topic were divided into four parts

00:04:25,040 --> 00:04:28,080
the first part introduction and the

00:04:27,280 --> 00:04:31,199
second part

00:04:28,080 --> 00:04:35,440
package description were given by me

00:04:31,199 --> 00:04:38,720
and the rest part were given by holly

00:04:35,440 --> 00:04:41,120
and let's get started

00:04:38,720 --> 00:04:43,919
with the development of the machine

00:04:41,120 --> 00:04:46,560
learning and deep learning technology

00:04:43,919 --> 00:04:47,600
a lot of research have been done in

00:04:46,560 --> 00:04:50,960
developing

00:04:47,600 --> 00:04:51,919
gai analysis and solving geospatial

00:04:50,960 --> 00:04:55,120
tasks

00:04:51,919 --> 00:04:58,880
like land use land cover classification

00:04:55,120 --> 00:05:01,759
disaster quick response nevertheless

00:04:58,880 --> 00:05:02,880
the lack of abundant training samples

00:05:01,759 --> 00:05:05,440
has been long

00:05:02,880 --> 00:05:06,960
considered as the main bottleneck of

00:05:05,440 --> 00:05:09,919
this research

00:05:06,960 --> 00:05:11,840
however osm shows great potential in

00:05:09,919 --> 00:05:14,639
tackling search challenge

00:05:11,840 --> 00:05:15,759
since it can provide massive and freely

00:05:14,639 --> 00:05:19,440
accessible

00:05:15,759 --> 00:05:20,479
geospatial data for generating training

00:05:19,440 --> 00:05:24,240
samples

00:05:20,479 --> 00:05:25,199
more importantly osm has exclusively

00:05:24,240 --> 00:05:28,000
access to

00:05:25,199 --> 00:05:30,160
its full historical data which means

00:05:28,000 --> 00:05:33,440
some intrinsic quality measurements

00:05:30,160 --> 00:05:37,600
can be provided to give an insight into

00:05:33,440 --> 00:05:40,639
the quality of the training samples

00:05:37,600 --> 00:05:43,759
actually before us there are already two

00:05:40,639 --> 00:05:47,440
great applications developed

00:05:43,759 --> 00:05:49,039
one is label maker and the second one is

00:05:47,440 --> 00:05:52,800
robo set

00:05:49,039 --> 00:05:55,840
a label maker can prepare the

00:05:52,800 --> 00:05:59,360
satellite image training sample

00:05:55,840 --> 00:06:03,919
for for geospatial machine learning

00:05:59,360 --> 00:06:06,960
and both of them are

00:06:03,919 --> 00:06:08,400
great application however they do have

00:06:06,960 --> 00:06:11,520
some cons

00:06:08,400 --> 00:06:12,880
for label maker it is poor at leveling

00:06:11,520 --> 00:06:16,240
sparse targets

00:06:12,880 --> 00:06:19,280
in large area for example if you want to

00:06:16,240 --> 00:06:19,280
label the whole

00:06:19,520 --> 00:06:24,240
the water then in the whole journey it

00:06:22,319 --> 00:06:27,759
may takes you

00:06:24,240 --> 00:06:30,880
three or four hours to get the results

00:06:27,759 --> 00:06:32,560
the rover set is an end-to-end pipeline

00:06:30,880 --> 00:06:35,840
for feature extraction

00:06:32,560 --> 00:06:38,960
from area and the satellite image

00:06:35,840 --> 00:06:42,880
using deep learning technology but

00:06:38,960 --> 00:06:47,199
it can only support building

00:06:42,880 --> 00:06:51,440
parking road features and if you want to

00:06:47,199 --> 00:06:55,759
extract the land use or something

00:06:51,440 --> 00:06:58,880
nothing this list is just impossible

00:06:55,759 --> 00:07:01,440
besides that it only supports

00:06:58,880 --> 00:07:03,840
pi touch and the limited deep learning

00:07:01,440 --> 00:07:07,039
models

00:07:03,840 --> 00:07:08,880
if you want to use tensorflow or some

00:07:07,039 --> 00:07:12,319
new deep learning model it's

00:07:08,880 --> 00:07:16,319
also impossible both of them lack of

00:07:12,319 --> 00:07:19,280
historical osm data support

00:07:16,319 --> 00:07:20,880
intermediate output and quality

00:07:19,280 --> 00:07:23,440
indicator

00:07:20,880 --> 00:07:24,400
the most annoying thing is that both of

00:07:23,440 --> 00:07:27,759
them are

00:07:24,400 --> 00:07:31,360
very hard to set up and

00:07:27,759 --> 00:07:35,840
due to their they are based on

00:07:31,360 --> 00:07:39,680
qa tiles so it's very difficult to

00:07:35,840 --> 00:07:44,240
turn the input data to modify it

00:07:39,680 --> 00:07:48,479
so we proposed a new python package

00:07:44,240 --> 00:07:52,720
named awesome to label what is awesome

00:07:48,479 --> 00:07:56,160
thanks to hacky people awesome is a high

00:07:52,720 --> 00:07:56,879
they develop awesome and awesome is a

00:07:56,160 --> 00:08:00,720
high level

00:07:56,879 --> 00:08:04,319
open street map history data analysis

00:08:00,720 --> 00:08:07,840
platform and the awesome api

00:08:04,319 --> 00:08:09,039
lets you analyze the rich data source of

00:08:07,840 --> 00:08:12,080
the open street

00:08:09,039 --> 00:08:14,400
map history and is based on the open

00:08:12,080 --> 00:08:17,759
street map history database

00:08:14,400 --> 00:08:20,240
osh db and

00:08:17,759 --> 00:08:21,280
you can find more detail on the github

00:08:20,240 --> 00:08:24,360
or

00:08:21,280 --> 00:08:27,520
on there wiki on

00:08:24,360 --> 00:08:30,879
openstreetmap and awesome has

00:08:27,520 --> 00:08:32,560
three functions the first one is osm

00:08:30,879 --> 00:08:35,200
data aggregation

00:08:32,560 --> 00:08:36,479
and the second one is history data

00:08:35,200 --> 00:08:39,200
extraction

00:08:36,479 --> 00:08:40,800
and the third one is user contributions

00:08:39,200 --> 00:08:45,680
that statistic

00:08:40,800 --> 00:08:48,800
and based on the history data extraction

00:08:45,680 --> 00:08:51,839
we have the material to generate

00:08:48,800 --> 00:08:55,200
the deep learning

00:08:51,839 --> 00:08:56,480
learning sample and based on the awesome

00:08:55,200 --> 00:08:59,600
data aggregation

00:08:56,480 --> 00:09:00,560
and the user contribution statistic we

00:08:59,600 --> 00:09:04,240
can

00:09:00,560 --> 00:09:07,600
generate some intrinsic osm

00:09:04,240 --> 00:09:10,399
quality indicator so based on

00:09:07,600 --> 00:09:11,519
or is awesome we develop awesome to

00:09:10,399 --> 00:09:14,720
label

00:09:11,519 --> 00:09:18,480
and convert the historical osm into

00:09:14,720 --> 00:09:18,480
geospatial training samples

00:09:19,519 --> 00:09:27,040
let me show you the package

00:09:22,880 --> 00:09:30,880
and this is the workflow figure

00:09:27,040 --> 00:09:33,760
for the awesome to label style with

00:09:30,880 --> 00:09:35,760
one mail config we can get intrinsic

00:09:33,760 --> 00:09:39,360
quality from awesome

00:09:35,760 --> 00:09:41,360
also we can download awesome osm data

00:09:39,360 --> 00:09:44,959
from awesome and

00:09:41,360 --> 00:09:48,160
the result format is in json

00:09:44,959 --> 00:09:50,000
so we can easily modify it if you want

00:09:48,160 --> 00:09:53,120
to add some feature or just

00:09:50,000 --> 00:09:54,560
delete some feature and after that use

00:09:53,120 --> 00:09:57,600
awesome to label

00:09:54,560 --> 00:10:00,800
we clip the whole

00:09:57,600 --> 00:10:03,920
json into tile and gets

00:10:00,800 --> 00:10:07,760
a lot of tile based georges json

00:10:03,920 --> 00:10:11,360
based on those child based stages and

00:10:07,760 --> 00:10:13,519
a vector tile will be rendered and

00:10:11,360 --> 00:10:14,800
a coco like the annotation will be

00:10:13,519 --> 00:10:18,079
generated

00:10:14,800 --> 00:10:21,680
and also the training image

00:10:18,079 --> 00:10:25,200
will be downloaded from some map api

00:10:21,680 --> 00:10:29,680
like bing map or mailbox

00:10:25,200 --> 00:10:33,680
and after that we can preview the

00:10:29,680 --> 00:10:34,480
label and let me show you some more

00:10:33,680 --> 00:10:37,920
detail

00:10:34,480 --> 00:10:41,279
uh this is the one ml config

00:10:37,920 --> 00:10:44,399
and it consists of three parts

00:10:41,279 --> 00:10:50,079
and the first part is project parts

00:10:44,399 --> 00:10:52,560
in this part you can specify the

00:10:50,079 --> 00:10:53,440
machine learning task like object

00:10:52,560 --> 00:10:56,240
detection

00:10:53,440 --> 00:10:58,320
and the segmentation and right now we

00:10:56,240 --> 00:11:01,440
only support

00:10:58,320 --> 00:11:04,640
such two kind tasks and

00:11:01,440 --> 00:11:07,920
the second part is osm config

00:11:04,640 --> 00:11:12,880
and in the tech config

00:11:07,920 --> 00:11:12,880
you can specify the

00:11:13,680 --> 00:11:17,839
label which is the

00:11:18,130 --> 00:11:23,279
[Music]

00:11:19,519 --> 00:11:26,160
class category in the uh

00:11:23,279 --> 00:11:27,440
cocoa annotation and the key and the

00:11:26,160 --> 00:11:31,839
value is just

00:11:27,440 --> 00:11:35,279
the osm tag and

00:11:31,839 --> 00:11:39,200
here is the timestamps you can specify

00:11:35,279 --> 00:11:39,200
timestamps and get the

00:11:39,360 --> 00:11:46,640
osm data from any time

00:11:43,040 --> 00:11:50,399
and right now we only support polygon

00:11:46,640 --> 00:11:51,600
feature and the polyline feature is our

00:11:50,399 --> 00:11:54,639
next step

00:11:51,600 --> 00:11:57,839
and the third part is the image part

00:11:54,639 --> 00:11:58,880
and now we support download image from

00:11:57,839 --> 00:12:03,040
bing map

00:11:58,880 --> 00:12:06,160
map box and sentinel hoop

00:12:03,040 --> 00:12:09,839
also the user custom the

00:12:06,160 --> 00:12:12,959
reptile service is also

00:12:09,839 --> 00:12:16,399
and here is the command

00:12:12,959 --> 00:12:19,600
sequence awesome to label have five

00:12:16,399 --> 00:12:22,839
functions the first is awesome to label

00:12:19,600 --> 00:12:26,480
vector which downloaded the

00:12:22,839 --> 00:12:30,240
osm uh json from the

00:12:26,480 --> 00:12:33,279
awesome api and it will put in the

00:12:30,240 --> 00:12:36,839
raw folder and the second is

00:12:33,279 --> 00:12:38,480
awesome to level quality and they use

00:12:36,839 --> 00:12:41,360
this

00:12:38,480 --> 00:12:42,720
command you can get three different

00:12:41,360 --> 00:12:45,760
picture

00:12:42,720 --> 00:12:48,880
the first one is area density

00:12:45,760 --> 00:12:51,680
the second one is count density and the

00:12:48,880 --> 00:12:55,360
last one is user density

00:12:51,680 --> 00:12:58,560
the density means that is the amount

00:12:55,360 --> 00:13:02,079
in square per per square

00:12:58,560 --> 00:13:02,079
kilometers and

00:13:04,320 --> 00:13:07,839
this figure shows the

00:13:08,079 --> 00:13:15,040
land land use in

00:13:11,600 --> 00:13:18,560
land use classification in hardback area

00:13:15,040 --> 00:13:21,440
and from the first two pictures

00:13:18,560 --> 00:13:21,440
you can see that

00:13:21,839 --> 00:13:29,040
the curve of each each class

00:13:25,680 --> 00:13:33,519
is very flat which means uh

00:13:29,040 --> 00:13:36,639
hepburn has great osm data quality and

00:13:33,519 --> 00:13:38,480
is very suitable for generating good

00:13:36,639 --> 00:13:41,680
training samples

00:13:38,480 --> 00:13:45,279
and the third one is awesome to label

00:13:41,680 --> 00:13:49,440
label and this command is the most

00:13:45,279 --> 00:13:52,959
important one and it will generate tile

00:13:49,440 --> 00:13:56,240
based uh render the

00:13:52,959 --> 00:13:58,720
tile and the annotation

00:13:56,240 --> 00:13:58,720
and the

00:13:59,600 --> 00:14:03,360
tile-based json and you can see the

00:14:02,880 --> 00:14:08,000
third

00:14:03,360 --> 00:14:11,120
place that you're jason is putting the

00:14:08,000 --> 00:14:15,600
tile folder and the the annotation is

00:14:11,120 --> 00:14:19,760
judges i just call collector json

00:14:15,600 --> 00:14:23,040
we choose the cocoa annotation format

00:14:19,760 --> 00:14:24,320
it is because the microsoft cochlea is

00:14:23,040 --> 00:14:28,399
very widely

00:14:24,320 --> 00:14:33,920
used in in deep learning

00:14:28,399 --> 00:14:37,519
communities so it's just a good

00:14:33,920 --> 00:14:39,760
format to use in

00:14:37,519 --> 00:14:40,639
different machine learning or deep

00:14:39,760 --> 00:14:44,320
learning

00:14:40,639 --> 00:14:47,440
algorithm and the label

00:14:44,320 --> 00:14:50,880
folder contains the render the

00:14:47,440 --> 00:14:55,279
label image and the left

00:14:50,880 --> 00:14:56,240
one is instant segmentation label and

00:14:55,279 --> 00:14:59,920
the right one

00:14:56,240 --> 00:15:02,959
is the object detection label

00:14:59,920 --> 00:15:04,399
and the fourth command is awesome to

00:15:02,959 --> 00:15:07,839
label image

00:15:04,399 --> 00:15:09,279
and it will download the area image or

00:15:07,839 --> 00:15:13,440
satellite image

00:15:09,279 --> 00:15:15,680
or even you use the

00:15:13,440 --> 00:15:17,519
opening area image you can download the

00:15:15,680 --> 00:15:21,360
drawing image

00:15:17,519 --> 00:15:24,560
and the last command is awesome to

00:15:21,360 --> 00:15:28,639
label visualize which produce the

00:15:24,560 --> 00:15:32,880
the preview of the label you can see

00:15:28,639 --> 00:15:37,120
we can provide two type of

00:15:32,880 --> 00:15:39,920
visualize the first one is overlay type

00:15:37,120 --> 00:15:40,639
which means the level is overlay on the

00:15:39,920 --> 00:15:43,519
satellite

00:15:40,639 --> 00:15:44,480
image and the second one is combined

00:15:43,519 --> 00:15:47,839
with type

00:15:44,480 --> 00:15:51,360
and it is means

00:15:47,839 --> 00:15:52,560
it means that the label image is side by

00:15:51,360 --> 00:15:57,519
side the

00:15:52,560 --> 00:16:00,639
satellite image and next uh

00:15:57,519 --> 00:16:02,240
parts were given by heart hello everyone

00:16:00,639 --> 00:16:05,440
here is holly

00:16:02,240 --> 00:16:08,639
and then um i will leave you guys

00:16:05,440 --> 00:16:11,440
to go through some examples of using

00:16:08,639 --> 00:16:13,600
awesome to level in the real machine

00:16:11,440 --> 00:16:16,800
learning applications

00:16:13,600 --> 00:16:17,360
as the first example we try to solve

00:16:16,800 --> 00:16:19,440
this

00:16:17,360 --> 00:16:20,720
land use land cover classification

00:16:19,440 --> 00:16:23,639
problem

00:16:20,720 --> 00:16:24,959
proposed first by michelle schutz at

00:16:23,639 --> 00:16:28,240
00:16:24,959 --> 00:16:31,120
we can see here with the drive class uh

00:16:28,240 --> 00:16:33,759
land use land cover classifications and

00:16:31,120 --> 00:16:37,279
the class range from the residential

00:16:33,759 --> 00:16:41,199
to the industry and to the water bodies

00:16:37,279 --> 00:16:42,160
and for each um land use land cover

00:16:41,199 --> 00:16:45,199
classif

00:16:42,160 --> 00:16:45,920
classification levels we can see we

00:16:45,199 --> 00:16:49,600
defined

00:16:45,920 --> 00:16:54,079
a range of corresponding osm values

00:16:49,600 --> 00:16:57,839
so by such kind of setup

00:16:54,079 --> 00:16:58,560
we can actually prepare the land use

00:16:57,839 --> 00:17:00,959
land cover

00:16:58,560 --> 00:17:02,000
training samples using the awesome to

00:17:00,959 --> 00:17:04,799
level

00:17:02,000 --> 00:17:05,679
as we can see here in the left side it's

00:17:04,799 --> 00:17:09,439
the satellite

00:17:05,679 --> 00:17:12,240
image provided by the bing map service

00:17:09,439 --> 00:17:14,160
and in the right side it's actually the

00:17:12,240 --> 00:17:15,039
land use land cover classification

00:17:14,160 --> 00:17:18,880
levels

00:17:15,039 --> 00:17:22,000
by this kind of definition over here

00:17:18,880 --> 00:17:23,039
so unless you once you have this kind of

00:17:22,000 --> 00:17:27,120
training samples

00:17:23,039 --> 00:17:29,919
available you can start to

00:17:27,120 --> 00:17:30,640
design your classification models for

00:17:29,919 --> 00:17:33,360
example

00:17:30,640 --> 00:17:34,240
together with julian we have proposed a

00:17:33,360 --> 00:17:37,200
very

00:17:34,240 --> 00:17:39,760
a deep residue neural networks for land

00:17:37,200 --> 00:17:41,919
use land cover classification

00:17:39,760 --> 00:17:44,000
and for this deep residue neural

00:17:41,919 --> 00:17:47,360
networks it have some

00:17:44,000 --> 00:17:50,080
key characters and first because

00:17:47,360 --> 00:17:50,720
this kind of networks it's consists of

00:17:50,080 --> 00:17:53,200
several

00:17:50,720 --> 00:17:54,480
residue blocks and for each kind of

00:17:53,200 --> 00:17:58,720
residue blocks

00:17:54,480 --> 00:18:01,919
you would have a fully pre activation

00:17:58,720 --> 00:18:02,480
function to the deeper layers so that

00:18:01,919 --> 00:18:06,640
means

00:18:02,480 --> 00:18:09,679
for such kind of networks led layers

00:18:06,640 --> 00:18:12,160
can be formulated at the feature space

00:18:09,679 --> 00:18:12,160
of the

00:18:12,240 --> 00:18:18,240
features so that means with this kind of

00:18:15,360 --> 00:18:22,000
rest nets it can be very deep for

00:18:18,240 --> 00:18:25,039
sometimes it can be more than 100 layers

00:18:22,000 --> 00:18:27,440
and that's also means to train such a

00:18:25,039 --> 00:18:28,880
west knights land use land cover

00:18:27,440 --> 00:18:30,720
classification model

00:18:28,880 --> 00:18:32,000
you would need a massive training

00:18:30,720 --> 00:18:35,200
samples and

00:18:32,000 --> 00:18:38,000
in this case our awesome 2 level could

00:18:35,200 --> 00:18:39,440
meet such kind of requirements by

00:18:38,000 --> 00:18:42,240
preparing

00:18:39,440 --> 00:18:45,039
this kind of massive training samples

00:18:42,240 --> 00:18:48,080
out of osm data sets

00:18:45,039 --> 00:18:48,400
and let's see some preliminary results

00:18:48,080 --> 00:18:51,919
of

00:18:48,400 --> 00:18:53,360
our classification model actually we

00:18:51,919 --> 00:18:56,640
have trained

00:18:53,360 --> 00:18:57,600
the rest nights for land use land cover

00:18:56,640 --> 00:19:01,039
classification

00:18:57,600 --> 00:19:04,400
in entire germany so um

00:19:01,039 --> 00:19:06,799
all the osm training samples across

00:19:04,400 --> 00:19:08,559
the germany has been included into a

00:19:06,799 --> 00:19:11,280
single model

00:19:08,559 --> 00:19:11,919
and then by implementing this model to

00:19:11,280 --> 00:19:15,280
the

00:19:11,919 --> 00:19:17,679
sentinel 2 image um in the whole germany

00:19:15,280 --> 00:19:19,120
we would be able to give the land use

00:19:17,679 --> 00:19:22,000
land cover predictions

00:19:19,120 --> 00:19:23,280
across the country and as you can see

00:19:22,000 --> 00:19:26,400
here this is a

00:19:23,280 --> 00:19:28,559
classification map for the headback area

00:19:26,400 --> 00:19:31,360
and we can see with this kind of rest

00:19:28,559 --> 00:19:35,520
nights and it can

00:19:31,360 --> 00:19:38,559
detect the forced areas it can detach

00:19:35,520 --> 00:19:38,880
the urban areas as well as the croplands

00:19:38,559 --> 00:19:42,080
and

00:19:38,880 --> 00:19:42,799
the rivers very well so that's also

00:19:42,080 --> 00:19:45,840
means

00:19:42,799 --> 00:19:47,120
the awesome to level it's indeed a

00:19:45,840 --> 00:19:49,360
powerful tool

00:19:47,120 --> 00:19:52,400
for this kind of land use land cover

00:19:49,360 --> 00:19:55,360
classification problems and

00:19:52,400 --> 00:19:56,240
next we would have a look at another

00:19:55,360 --> 00:19:59,440
example

00:19:56,240 --> 00:20:00,320
we are doing object detections tasks

00:19:59,440 --> 00:20:03,039
over here

00:20:00,320 --> 00:20:04,480
to be more specific we want to detect

00:20:03,039 --> 00:20:07,440
the human segments

00:20:04,480 --> 00:20:07,840
the buildings from the satellite image

00:20:07,440 --> 00:20:10,880
and

00:20:07,840 --> 00:20:12,480
in the left side it's the image provided

00:20:10,880 --> 00:20:16,240
by the open area map

00:20:12,480 --> 00:20:19,039
by the by this um kind of image capture

00:20:16,240 --> 00:20:20,960
very high resolution image captured by

00:20:19,039 --> 00:20:24,000
the uav device

00:20:20,960 --> 00:20:25,360
and then in the left side we can see we

00:20:24,000 --> 00:20:27,760
overlay the

00:20:25,360 --> 00:20:28,799
existing open street map building

00:20:27,760 --> 00:20:33,200
footprints

00:20:28,799 --> 00:20:36,000
and in the image in order to make the

00:20:33,200 --> 00:20:36,320
labels for our training samples and in

00:20:36,000 --> 00:20:39,120
such

00:20:36,320 --> 00:20:40,480
way we would be able to train our object

00:20:39,120 --> 00:20:43,600
detection networks

00:20:40,480 --> 00:20:45,360
to detect buildings from the satellite

00:20:43,600 --> 00:20:49,039
image

00:20:45,360 --> 00:20:51,440
and this is the building detection

00:20:49,039 --> 00:20:54,480
architectures we are using here

00:20:51,440 --> 00:20:55,760
we are using the mask rcn pre-trained on

00:20:54,480 --> 00:21:00,159
the microsoft

00:20:55,760 --> 00:21:01,840
0 data sets why we want to pretend this

00:21:00,159 --> 00:21:03,440
why we want to get this pre-trained

00:21:01,840 --> 00:21:06,880
network it's because

00:21:03,440 --> 00:21:10,559
this musk rcn gets really a huge

00:21:06,880 --> 00:21:12,000
um set of parameters so in order to get

00:21:10,559 --> 00:21:15,360
a stable performance

00:21:12,000 --> 00:21:17,039
we have to pretend such kind of network

00:21:15,360 --> 00:21:20,400
on the standard data sets

00:21:17,039 --> 00:21:24,000
and then we fine-tuned it uh the mask

00:21:20,400 --> 00:21:28,159
rcn on our um osm

00:21:24,000 --> 00:21:31,200
building training samples so

00:21:28,159 --> 00:21:34,159
by fan tuning this mask rcn

00:21:31,200 --> 00:21:36,240
we would be able to achieve the building

00:21:34,159 --> 00:21:38,880
instant segmentation model

00:21:36,240 --> 00:21:40,960
and for this kind of model the only

00:21:38,880 --> 00:21:44,480
thing you need to trim the model

00:21:40,960 --> 00:21:46,240
it's the satellite image it's an image

00:21:44,480 --> 00:21:49,280
from the open area map

00:21:46,240 --> 00:21:51,679
together with osm building features

00:21:49,280 --> 00:21:52,320
and as a result you can see in the right

00:21:51,679 --> 00:21:55,840
hand

00:21:52,320 --> 00:21:58,159
that this model can detect

00:21:55,840 --> 00:21:59,679
the buildings from different kind of

00:21:58,159 --> 00:22:02,799
buildings from the

00:21:59,679 --> 00:22:04,960
open area map image but

00:22:02,799 --> 00:22:07,919
there is also some limitations as you

00:22:04,960 --> 00:22:10,400
can see some small buildings is missing

00:22:07,919 --> 00:22:11,760
and some buildings some building

00:22:10,400 --> 00:22:14,320
footprints

00:22:11,760 --> 00:22:16,000
inaccurate only half of the building is

00:22:14,320 --> 00:22:19,200
captured by the model

00:22:16,000 --> 00:22:20,640
so for such kind of limitations it also

00:22:19,200 --> 00:22:24,000
depends on

00:22:20,640 --> 00:22:27,120
how many training samples you got and

00:22:24,000 --> 00:22:32,240
also together with the quality of the

00:22:27,120 --> 00:22:32,240
of the image you fit into your model

00:22:32,799 --> 00:22:40,559
but in general um awesome to model

00:22:36,640 --> 00:22:44,559
it's a python software that

00:22:40,559 --> 00:22:47,360
can allow you to define your own

00:22:44,559 --> 00:22:48,640
objects or your own machine learning

00:22:47,360 --> 00:22:51,440
training samples

00:22:48,640 --> 00:22:52,880
by querying the user-defined historic

00:22:51,440 --> 00:22:55,280
osm data

00:22:52,880 --> 00:22:56,240
and the package is pure written in

00:22:55,280 --> 00:22:58,720
peasant

00:22:56,240 --> 00:23:00,080
and another course for the package is

00:22:58,720 --> 00:23:04,159
that the package is

00:23:00,080 --> 00:23:07,360
easy to set up and and more importantly

00:23:04,159 --> 00:23:10,720
for the based on the awesome api

00:23:07,360 --> 00:23:13,679
we are able to provide some

00:23:10,720 --> 00:23:15,919
osm intrinsic quality indicators

00:23:13,679 --> 00:23:18,400
together with the training samples

00:23:15,919 --> 00:23:18,960
and i believe for such an intrinsic

00:23:18,400 --> 00:23:22,480
quality

00:23:18,960 --> 00:23:24,159
indicators would help us to understand

00:23:22,480 --> 00:23:26,000
the performance of such kind of

00:23:24,159 --> 00:23:27,200
geospatial machine learnings in the

00:23:26,000 --> 00:23:29,679
future

00:23:27,200 --> 00:23:31,280
um as a future work we would like to

00:23:29,679 --> 00:23:34,400
extend the package

00:23:31,280 --> 00:23:38,000
to support polyline features

00:23:34,400 --> 00:23:41,440
would extends the current intrinsic

00:23:38,000 --> 00:23:42,640
quality indicators to tell based quality

00:23:41,440 --> 00:23:45,200
analysis

00:23:42,640 --> 00:23:46,960
and we would also like to extend the

00:23:45,200 --> 00:23:50,480
package and support

00:23:46,960 --> 00:23:54,320
more machine learning tasks annotations

00:23:50,480 --> 00:23:57,440
so you can find our package in gtap and

00:23:54,320 --> 00:23:59,840
it's totally open source and

00:23:57,440 --> 00:24:02,080
any comments and suggestions is always

00:23:59,840 --> 00:24:05,200
welcome

00:24:02,080 --> 00:24:07,840
and so that's a reference and

00:24:05,200 --> 00:24:08,960
uh thanks for your time and uh thanks

00:24:07,840 --> 00:24:14,159
for

00:24:08,960 --> 00:24:14,159
coming to our talks um is there any

00:24:16,840 --> 00:24:19,840
questions

00:24:51,600 --> 00:25:01,840
okay i'm waiting for

00:24:54,880 --> 00:25:01,840
go ahead

00:25:03,440 --> 00:25:05,840
hello

00:25:10,159 --> 00:25:13,200
can you see me yeah i can see you now i

00:25:12,720 --> 00:25:15,120
think

00:25:13,200 --> 00:25:16,320
they have to give us a go ahead before

00:25:15,120 --> 00:25:20,320
they go live with a q

00:25:16,320 --> 00:25:23,360
a oh sorry i have to mute the

00:25:20,320 --> 00:25:25,120
video right no no it's not no you have

00:25:23,360 --> 00:25:26,240
to put it on because they want to see

00:25:25,120 --> 00:25:29,279
you

00:25:26,240 --> 00:25:32,400
but i cannot hear you clearly

00:25:29,279 --> 00:25:35,279
right now hello can you hear me now yeah

00:25:32,400 --> 00:25:36,880
i can hear you right now all right okay

00:25:35,279 --> 00:25:43,840
you have to wait for the video team to

00:25:36,880 --> 00:25:43,840
give us go ahead before

00:25:45,279 --> 00:25:48,480
okay go ahead

00:25:52,559 --> 00:25:58,799
okay thank you very much uh uh charion

00:25:55,840 --> 00:25:59,679
for the excellent uh presentation um

00:25:58,799 --> 00:26:01,919
it's time now

00:25:59,679 --> 00:26:03,039
for uh questions and that questions and

00:26:01,919 --> 00:26:05,520
answers

00:26:03,039 --> 00:26:06,159
um i have my own but i think there are

00:26:05,520 --> 00:26:08,640
interesting

00:26:06,159 --> 00:26:10,960
ones also coming up on the session part

00:26:08,640 --> 00:26:13,340
or the question part so

00:26:10,960 --> 00:26:15,279
i will uh

00:26:13,340 --> 00:26:19,840
[Music]

00:26:15,279 --> 00:26:23,120
let's see how it goes so uh question one

00:26:19,840 --> 00:26:25,360
someone is asking does uh awesome uh

00:26:23,120 --> 00:26:27,200
awesome to label um also your reference

00:26:25,360 --> 00:26:29,279
the results that is land use vectors

00:26:27,200 --> 00:26:32,480
build and footprints um

00:26:29,279 --> 00:26:32,480
building footprint vectors

00:26:33,039 --> 00:26:40,559
uh okay the asymptote label

00:26:36,640 --> 00:26:44,320
the result is in a sleepy map tile

00:26:40,559 --> 00:26:47,600
so which is in xyz format

00:26:44,320 --> 00:26:50,880
means you carry each

00:26:47,600 --> 00:26:54,720
25 secs multiply

00:26:50,880 --> 00:26:56,799
256 tiles so it is your reference that

00:26:54,720 --> 00:26:57,679
we have provide function that can

00:26:56,799 --> 00:27:00,720
convert the

00:26:57,679 --> 00:27:04,640
tile into the uh

00:27:00,720 --> 00:27:07,200
into the coordinates okay brilliant

00:27:04,640 --> 00:27:08,480
thanks um there is another question uh

00:27:07,200 --> 00:27:10,720
from renee

00:27:08,480 --> 00:27:12,080
um i hope it's already i know um hello

00:27:10,720 --> 00:27:15,440
there um

00:27:12,080 --> 00:27:17,679
uh thanks a lot for your talk and um

00:27:15,440 --> 00:27:19,760
i'm one and he's wondering how you your

00:27:17,679 --> 00:27:22,559
approach performs in areas with uh

00:27:19,760 --> 00:27:23,760
lower osm data quality or with sparser

00:27:22,559 --> 00:27:26,080
uh coverage

00:27:23,760 --> 00:27:28,399
um so have you uh he's asking have you

00:27:26,080 --> 00:27:31,120
conducted a systematic performance test

00:27:28,399 --> 00:27:32,559
uh in corresponding areas i think that's

00:27:31,120 --> 00:27:33,279
first question uh would you be

00:27:32,559 --> 00:27:35,760
interested in

00:27:33,279 --> 00:27:37,039
interesting would you be interest uh

00:27:35,760 --> 00:27:39,840
would be interesting

00:27:37,039 --> 00:27:41,520
in support of your ongoing work in the

00:27:39,840 --> 00:27:44,960
global assault in particular

00:27:41,520 --> 00:27:46,480
oh he's still writing actually um so uh

00:27:44,960 --> 00:27:48,320
i think i don't know whether he got it

00:27:46,480 --> 00:27:50,240
but i think his main uh

00:27:48,320 --> 00:27:51,600
question here is have you conducted a

00:27:50,240 --> 00:27:53,840
systematic performance test

00:27:51,600 --> 00:27:55,360
in corresponding areas i think he's

00:27:53,840 --> 00:27:56,000
talking about spatial transferability

00:27:55,360 --> 00:28:00,080
here

00:27:56,000 --> 00:28:00,559
okay okay thank you for your question

00:28:00,080 --> 00:28:04,480
it's an

00:28:00,559 --> 00:28:04,480
interesting question and

00:28:05,039 --> 00:28:12,240
for the low quality

00:28:08,399 --> 00:28:15,760
osm data quality or sparse coverage

00:28:12,240 --> 00:28:17,039
it's actually it's two questions for the

00:28:15,760 --> 00:28:21,120
sparse coverage

00:28:17,039 --> 00:28:25,120
like the uh the

00:28:21,120 --> 00:28:29,120
example i mentioned in the talk that

00:28:25,120 --> 00:28:32,559
the water dam in the whole germany it is

00:28:29,120 --> 00:28:33,679
perform very well it may takes three or

00:28:32,559 --> 00:28:36,720
four minutes

00:28:33,679 --> 00:28:39,039
well you will get the results and for

00:28:36,720 --> 00:28:43,440
the low

00:28:39,039 --> 00:28:46,240
osm data quality area

00:28:43,440 --> 00:28:47,200
actually you still can get the result

00:28:46,240 --> 00:28:51,200
because

00:28:47,200 --> 00:28:54,480
uh we filtered the um

00:28:51,200 --> 00:28:56,799
the tile that not contain osm data but

00:28:54,480 --> 00:29:00,480
we don't have the stress hold

00:28:56,799 --> 00:29:04,159
that filter the

00:29:00,480 --> 00:29:08,159
tile that only contain one or two

00:29:04,159 --> 00:29:11,520
osm osm data

00:29:08,159 --> 00:29:14,720
and you have to

00:29:11,520 --> 00:29:17,919
filter the lower data quality tile

00:29:14,720 --> 00:29:22,000
in the later later works

00:29:17,919 --> 00:29:23,919
and actually we are

00:29:22,000 --> 00:29:25,279
going to add this function to the

00:29:23,919 --> 00:29:28,799
awesome to label

00:29:25,279 --> 00:29:32,000
is this clear um yes

00:29:28,799 --> 00:29:35,200
i think he says yes it is um i

00:29:32,000 --> 00:29:36,000
i think it's clear to renee um so there

00:29:35,200 --> 00:29:38,240
are no

00:29:36,000 --> 00:29:39,679
further questions but i have some if

00:29:38,240 --> 00:29:41,840
there are no

00:29:39,679 --> 00:29:43,679
questions coming um i think i can jump

00:29:41,840 --> 00:29:46,159
into some of the few i have

00:29:43,679 --> 00:29:47,360
um it's interesting i'm seeing about uh

00:29:46,159 --> 00:29:49,679
21 or 20

00:29:47,360 --> 00:29:50,799
uh people in attendance so that's very

00:29:49,679 --> 00:29:53,120
good um

00:29:50,799 --> 00:29:54,559
and thank you everyone for attending um

00:29:53,120 --> 00:29:56,320
you can still um

00:29:54,559 --> 00:29:58,159
provide questions here or any comments

00:29:56,320 --> 00:29:59,120
that you have and why is uh the

00:29:58,159 --> 00:30:02,080
discussion is going

00:29:59,120 --> 00:30:03,039
ongoing um so um i think from you the

00:30:02,080 --> 00:30:05,120
last

00:30:03,039 --> 00:30:06,480
uh issue that you talked about i mean

00:30:05,120 --> 00:30:08,640
touching on tiles

00:30:06,480 --> 00:30:10,000
um i have a question here uh for the

00:30:08,640 --> 00:30:12,080
tiles um

00:30:10,000 --> 00:30:14,000
uh which zoom level or levels do you

00:30:12,080 --> 00:30:14,320
usually use in the algorithm i think i

00:30:14,000 --> 00:30:17,520
saw

00:30:14,320 --> 00:30:20,399
um zoom levels uh uh 17 and 14

00:30:17,520 --> 00:30:22,799
in slide 11 where you showed some quotes

00:30:20,399 --> 00:30:26,399
so if you can comment on that

00:30:22,799 --> 00:30:30,080
okay for the zoom level uh actually it

00:30:26,399 --> 00:30:33,679
depends on what you are interesting

00:30:30,080 --> 00:30:37,919
because for like land use length

00:30:33,679 --> 00:30:41,200
you if you get very high resolution

00:30:37,919 --> 00:30:42,480
data then you can set the zoom level

00:30:41,200 --> 00:30:46,480
very high like

00:30:42,480 --> 00:30:50,159
17 18 but when we do the

00:30:46,480 --> 00:30:55,279
uh the land cover land use

00:30:50,159 --> 00:30:57,840
experiment we only get the sentinel 2

00:30:55,279 --> 00:30:59,279
data so the resolution is about 10

00:30:57,840 --> 00:31:03,600
meters so we

00:30:59,279 --> 00:31:07,360
choose the choose the

00:31:03,600 --> 00:31:10,640
tile at 40 level that can

00:31:07,360 --> 00:31:12,799
provide about 10 meter

00:31:10,640 --> 00:31:14,440
tile at the resolution of the tile is

00:31:12,799 --> 00:31:18,240
about 10 meter maybe

00:31:14,440 --> 00:31:21,279
9.5 or something like that and

00:31:18,240 --> 00:31:23,039
for building detection if you have very

00:31:21,279 --> 00:31:26,240
high resolution like

00:31:23,039 --> 00:31:30,080
the bing map or the

00:31:26,240 --> 00:31:31,600
other uh source then you can set the

00:31:30,080 --> 00:31:34,640
zoom level very high

00:31:31,600 --> 00:31:36,960
and get very detailed uh tile

00:31:34,640 --> 00:31:37,919
and that's the answer okay thank you

00:31:36,960 --> 00:31:40,559
very much um

00:31:37,919 --> 00:31:41,279
i appreciate that um so i have another

00:31:40,559 --> 00:31:44,640
one here

00:31:41,279 --> 00:31:47,039
um so how is uh um

00:31:44,640 --> 00:31:48,960
awesome to label um applicable to uh

00:31:47,039 --> 00:31:51,200
informal about areas like slumps

00:31:48,960 --> 00:31:52,000
which is something of interesting to me

00:31:51,200 --> 00:31:53,679
so

00:31:52,000 --> 00:31:56,640
um to be interesting if you can

00:31:53,679 --> 00:32:00,559
highlight a bit on that

00:31:56,640 --> 00:32:00,559
oh sorry the internet is

00:32:01,679 --> 00:32:07,360
i'll repeat so i was asking um how is uh

00:32:04,799 --> 00:32:11,039
awesome to label um applicable to

00:32:07,360 --> 00:32:16,159
informal urban areas like slums

00:32:11,039 --> 00:32:19,840
slums oh yeah um areas where you know um

00:32:16,159 --> 00:32:23,200
um i don't know the uh ah

00:32:19,840 --> 00:32:26,799
okay are you clear now yeah yeah

00:32:23,200 --> 00:32:30,480
actually the the second uh

00:32:26,799 --> 00:32:34,240
the second example uh is in

00:32:30,480 --> 00:32:39,039
bangla and i think there are

00:32:34,240 --> 00:32:39,039
areas on the slums and

00:32:39,919 --> 00:32:42,240
some

00:32:43,840 --> 00:32:53,440
how to say although they have some

00:32:49,679 --> 00:32:57,200
high resolution image satellite image or

00:32:53,440 --> 00:32:58,159
drawing image but the osm data is not

00:32:57,200 --> 00:33:02,480
sufficient

00:32:58,159 --> 00:33:06,480
so you may training the

00:33:02,480 --> 00:33:09,279
training the model in other area and

00:33:06,480 --> 00:33:13,519
then you choose some

00:33:09,279 --> 00:33:15,360
image in the your study area

00:33:13,519 --> 00:33:17,600
and then do some transfer learning

00:33:15,360 --> 00:33:20,799
tricks then you can get

00:33:17,600 --> 00:33:21,679
a well-trained model and awesome to

00:33:20,799 --> 00:33:25,360
label is

00:33:21,679 --> 00:33:29,279
actually uh data preparation

00:33:25,360 --> 00:33:32,320
tools so you have to

00:33:29,279 --> 00:33:35,360
do some other tricks to fulfill your

00:33:32,320 --> 00:33:38,000
goal and that's my answer

00:33:35,360 --> 00:33:38,720
um thank you uh charlie charion wool for

00:33:38,000 --> 00:33:42,799
the

00:33:38,720 --> 00:33:45,760
excellent answer um okay i can see um

00:33:42,799 --> 00:33:46,399
um someone uh trying to compose a

00:33:45,760 --> 00:33:49,279
question

00:33:46,399 --> 00:33:51,200
uh here i'll wait for the person but i

00:33:49,279 --> 00:33:55,600
have one here

00:33:51,200 --> 00:33:57,679
which is also somehow linked to the

00:33:55,600 --> 00:33:59,120
limitations that you uh pointed out with

00:33:57,679 --> 00:34:01,840
regard to the

00:33:59,120 --> 00:34:02,240
existing methods like robosat and others

00:34:01,840 --> 00:34:04,320
so

00:34:02,240 --> 00:34:06,480
um you indicated that one of the

00:34:04,320 --> 00:34:09,440
limitations of robosat um

00:34:06,480 --> 00:34:11,520
and other type based approaches is um

00:34:09,440 --> 00:34:13,520
setup uh difficulty so from what you

00:34:11,520 --> 00:34:16,720
have done so far do you think uh

00:34:13,520 --> 00:34:17,760
awesome to label is um is easy to use in

00:34:16,720 --> 00:34:21,440
comparison with this

00:34:17,760 --> 00:34:25,280
previous methods yeah actually

00:34:21,440 --> 00:34:29,040
it's very easy to set up it's purely

00:34:25,280 --> 00:34:30,320
right in python and what you need to do

00:34:29,040 --> 00:34:34,000
is just

00:34:30,320 --> 00:34:36,320
input the pipe install or too

00:34:34,000 --> 00:34:38,079
in your command line and you will get it

00:34:36,320 --> 00:34:40,720
and you can start to use it

00:34:38,079 --> 00:34:41,839
and you can follow the instruction on

00:34:40,720 --> 00:34:45,599
our github

00:34:41,839 --> 00:34:49,839
and there are sample config file

00:34:45,599 --> 00:34:53,040
and you can play around with it

00:34:49,839 --> 00:34:54,560
oh brilliant uh thank you for that uh so

00:34:53,040 --> 00:34:56,320
i'll assume you have already some

00:34:54,560 --> 00:34:56,960
tutorials or guidance regarding the

00:34:56,320 --> 00:35:01,119
setup

00:34:56,960 --> 00:35:03,119
um and also i'll assume also that uh the

00:35:01,119 --> 00:35:05,280
from what you've just said uh the

00:35:03,119 --> 00:35:08,560
limitation will be around um

00:35:05,280 --> 00:35:08,560
knowledge in python right

00:35:09,680 --> 00:35:15,200
yeah that's totally writing python okay

00:35:13,200 --> 00:35:16,400
thank you very much um okay i think we

00:35:15,200 --> 00:35:19,680
can go to the next

00:35:16,400 --> 00:35:20,400
uh question which is um how do you

00:35:19,680 --> 00:35:22,720
ensure

00:35:20,400 --> 00:35:23,520
i think it's about offsets or skewness

00:35:22,720 --> 00:35:25,839
so how do you

00:35:23,520 --> 00:35:28,839
how do you ensure the imagery is exactly

00:35:25,839 --> 00:35:31,839
uh wgs84 with no skew before you start

00:35:28,839 --> 00:35:31,839
um

00:35:32,480 --> 00:35:38,000
yeah so he's pointing out uh bank is bad

00:35:35,680 --> 00:35:39,440
uh being imagery is bad mother is also

00:35:38,000 --> 00:35:41,200
often bad so

00:35:39,440 --> 00:35:45,839
i don't know whether you have any views

00:35:41,200 --> 00:35:45,839
on this um

00:35:46,960 --> 00:35:53,119
uh actually we don't

00:35:50,480 --> 00:35:54,720
we don't process with the bing map we

00:35:53,119 --> 00:35:58,000
just download the tile

00:35:54,720 --> 00:36:01,520
image from it and so that's not

00:35:58,000 --> 00:36:04,880
our issue to make sure that

00:36:01,520 --> 00:36:08,480
the beam map is totally

00:36:04,880 --> 00:36:08,480
wgs 84 or

00:36:08,880 --> 00:36:14,960
like that oh i see

00:36:12,000 --> 00:36:15,839
so um you are you saying that the

00:36:14,960 --> 00:36:20,240
algorithm

00:36:15,839 --> 00:36:20,240
is independent of uh coordinate systems

00:36:21,119 --> 00:36:24,720
okay brilliant that's very interesting

00:36:23,920 --> 00:36:27,119
um

00:36:24,720 --> 00:36:28,079
i uh okay the person hasn't got a name

00:36:27,119 --> 00:36:30,079
here but i think you

00:36:28,079 --> 00:36:31,119
you follow up with that um i'm quite

00:36:30,079 --> 00:36:33,200
interested in this um

00:36:31,119 --> 00:36:35,680
because that might be very helpful uh

00:36:33,200 --> 00:36:37,280
because coordination can be really um

00:36:35,680 --> 00:36:39,200
a pain when you're doing these things

00:36:37,280 --> 00:36:43,040
yeah yeah yeah and

00:36:39,200 --> 00:36:48,030
actually we we just uh

00:36:43,040 --> 00:36:49,119
uh the geojson is in epsg

00:36:48,030 --> 00:36:52,240
[Music]

00:36:49,119 --> 00:36:57,520
cannot remember the coordinates

00:36:52,240 --> 00:36:57,520
code but it's in a common use the

00:36:58,480 --> 00:37:06,560
coordinate system and we turn that

00:37:02,880 --> 00:37:09,760
coordinate into wgs bus 84

00:37:06,560 --> 00:37:13,520
and and render the tile

00:37:09,760 --> 00:37:17,200
and the download tile the image is in

00:37:13,520 --> 00:37:19,359
the same coordinate system

00:37:17,200 --> 00:37:19,359
so

00:37:20,880 --> 00:37:23,839
so

00:37:24,320 --> 00:37:30,880
actually um i'm not clear with

00:37:27,599 --> 00:37:37,839
the question that why

00:37:30,880 --> 00:37:37,839
bmap is not always wgs 84

00:37:40,880 --> 00:37:45,839
um yeah i think um yeah

00:37:44,320 --> 00:37:47,280
i think yeah probably that's the case

00:37:45,839 --> 00:37:48,320
because i think that it's not always

00:37:47,280 --> 00:37:49,440
like exactly

00:37:48,320 --> 00:37:51,839
i think the person is putting that

00:37:49,440 --> 00:37:55,440
exactly wgs84

00:37:51,839 --> 00:37:58,079
um um if yours

00:37:55,440 --> 00:38:00,079
oh jidani chidani here chennai put his

00:37:58,079 --> 00:38:04,000
name there so janani um if you hit us

00:38:00,079 --> 00:38:07,200
uh you can clarify regarding um what uh

00:38:04,000 --> 00:38:07,680
chang yan uh said now i'll go to the

00:38:07,200 --> 00:38:11,599
next

00:38:07,680 --> 00:38:14,640
uh question um which is about um

00:38:11,599 --> 00:38:16,320
uh okay so in some works um

00:38:14,640 --> 00:38:18,079
in some works land use land cover

00:38:16,320 --> 00:38:18,960
information have been derived from your

00:38:18,079 --> 00:38:21,280
social

00:38:18,960 --> 00:38:22,400
media data especially from shared uh

00:38:21,280 --> 00:38:24,800
photos

00:38:22,400 --> 00:38:26,160
do you see any potential for augmenting

00:38:24,800 --> 00:38:29,599
your approach taking

00:38:26,160 --> 00:38:30,079
um into account also or taking taking

00:38:29,599 --> 00:38:32,960
account

00:38:30,079 --> 00:38:34,960
also of these data sets in some areas

00:38:32,960 --> 00:38:35,599
especially regards to possibly achieving

00:38:34,960 --> 00:38:38,800
the

00:38:35,599 --> 00:38:40,640
temporary resolution um

00:38:38,800 --> 00:38:42,079
probably let's let's address this first

00:38:40,640 --> 00:38:45,200
before that we go to the next

00:38:42,079 --> 00:38:46,000
question i don't know is it clear yeah

00:38:45,200 --> 00:38:47,680
yes

00:38:46,000 --> 00:38:49,280
okay then please address it before we go

00:38:47,680 --> 00:38:50,000
i think there are two questions in one

00:38:49,280 --> 00:38:53,119
so

00:38:50,000 --> 00:38:56,560
we can go to the other okay

00:38:53,119 --> 00:39:00,320
so um

00:38:56,560 --> 00:39:04,160
actually for the social media data

00:39:00,320 --> 00:39:04,160
i think it's easily

00:39:05,200 --> 00:39:11,240
application specified so it

00:39:09,119 --> 00:39:14,560
works different way in different

00:39:11,240 --> 00:39:14,560
applications so

00:39:16,079 --> 00:39:22,640
like the area each it's

00:39:19,440 --> 00:39:26,960
much more difficult to

00:39:22,640 --> 00:39:30,480
handle in a insider

00:39:26,960 --> 00:39:42,320
form so we still not considered

00:39:30,480 --> 00:39:46,720
to add the jaw social media

00:39:42,320 --> 00:39:50,000
hello how are you there yeah

00:39:46,720 --> 00:39:51,760
okay okay so everyone i think it's a bit

00:39:50,000 --> 00:39:54,000
the streaming is a bit slow um

00:39:51,760 --> 00:39:55,599
but we manage with that we have about um

00:39:54,000 --> 00:39:57,920
uh two minutes more to go

00:39:55,599 --> 00:39:59,119
so um i would think uh probably for the

00:39:57,920 --> 00:40:02,480
next questions you can

00:39:59,119 --> 00:40:04,400
just be um uh a bit short in your answer

00:40:02,480 --> 00:40:05,359
so that we can address or if not then i

00:40:04,400 --> 00:40:09,440
think we can

00:40:05,359 --> 00:40:12,000
throw over to um uh discussions later

00:40:09,440 --> 00:40:12,800
after the after the talk so um the next

00:40:12,000 --> 00:40:14,960
question is can you

00:40:12,800 --> 00:40:16,480
discuss more about your future plans for

00:40:14,960 --> 00:40:19,040
the osm quality measurement

00:40:16,480 --> 00:40:19,760
uh will uh would be interesting to know

00:40:19,040 --> 00:40:25,839
so

00:40:19,760 --> 00:40:25,839
this is a question from someone

00:40:36,839 --> 00:40:39,839
is

00:40:50,839 --> 00:40:53,839
uh

00:40:56,560 --> 00:41:00,800
um it's a bit slow here i'm not sure

00:40:58,640 --> 00:41:04,079
whether you've completed answering the

00:41:00,800 --> 00:41:07,119
question um

00:41:04,079 --> 00:41:10,800
so i'll go to the next

00:41:07,119 --> 00:41:10,800
uh chariot are you there

00:41:14,079 --> 00:41:18,880
okay um i would suggest maybe um it's

00:41:16,880 --> 00:41:20,880
almost time so i suggest maybe uh

00:41:18,880 --> 00:41:22,640
for the rest of the answers and the

00:41:20,880 --> 00:41:24,720
comments maybe you can

00:41:22,640 --> 00:41:26,319
uh address the questions uh on the

00:41:24,720 --> 00:41:30,079
session part or the question part

00:41:26,319 --> 00:41:32,640
um and so um i think um i'll end here

00:41:30,079 --> 00:41:34,480
and thank you very much for your ex

00:41:32,640 --> 00:41:36,480
interesting um work

00:41:34,480 --> 00:41:38,160
and i'm quite interested and i'll follow

00:41:36,480 --> 00:41:40,160
up on that um

00:41:38,160 --> 00:41:42,400
and thank you everyone uh we now have

00:41:40,160 --> 00:41:44,720
about i think uh 21 people

00:41:42,400 --> 00:41:47,280
in attendance and thank you everyone for

00:41:44,720 --> 00:41:48,000
uh for your patience with us and for uh

00:41:47,280 --> 00:41:50,880
participating

00:41:48,000 --> 00:41:51,680
in this session and thank you again uh

00:41:50,880 --> 00:41:54,640
uh

00:41:51,680 --> 00:41:56,079
uh charion woo and haaoli and uh um

00:41:54,640 --> 00:41:58,000
alexander for

00:41:56,079 --> 00:42:03,839
this study thank you everyone and i hope

00:41:58,000 --> 00:42:03,839

YouTube URL: https://www.youtube.com/watch?v=47aOI7Zl134


