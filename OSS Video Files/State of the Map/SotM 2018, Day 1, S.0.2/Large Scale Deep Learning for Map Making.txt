Title: Large Scale Deep Learning for Map Making
Publication date: 2018-08-13
Playlist: SotM 2018, Day 1, S.0.2
Description: 
	Alina Negreanu and Bogdan Gliga (Telenav), State of the Map 2018
https://2018.stateofthemap.org/2018/T115-Large_Scale_Deep_Learning_for_Map_Making/

In this talk, the Telenav OSM team talks about what we have learned from our experience building a horizontally scalable deep learning pipeline that can process the over 120 million images in the OpenStreetCam database. We will offer a technical perspective about how we used state of the art algorithms to detect a large number of traffic signs, extract road features like number of lanes visible on a road, and accurately perform text recognition on signs. This technology is now open source and available for anyone to use and improve upon!
Captions: 
	00:00:02,389 --> 00:00:08,780
so hello my name is Adina and together

00:00:06,319 --> 00:00:10,580
with my colleague for Dan we will

00:00:08,780 --> 00:00:13,839
present today the topic called

00:00:10,580 --> 00:00:17,150
large-scale deep learning for map making

00:00:13,839 --> 00:00:20,300
so both Dan and I both work Italian now

00:00:17,150 --> 00:00:24,980
I am part of the map analyst team and

00:00:20,300 --> 00:00:27,350
she's part of the AI team the problem

00:00:24,980 --> 00:00:31,340
that we want to discuss and solve today

00:00:27,350 --> 00:00:33,559
is that manually identifying map

00:00:31,340 --> 00:00:34,550
features from images is very time

00:00:33,559 --> 00:00:37,160
consuming

00:00:34,550 --> 00:00:40,190
why because well imagine the fact that

00:00:37,160 --> 00:00:42,710
you have a bunch of dashcam images and

00:00:40,190 --> 00:00:45,350
you want to add from them all the turn

00:00:42,710 --> 00:00:47,630
restrictions to do this you will have to

00:00:45,350 --> 00:00:50,090
go to all of them and search for the

00:00:47,630 --> 00:00:52,550
sign that you're interested in and even

00:00:50,090 --> 00:00:56,180
though you may find that sign that sign

00:00:52,550 --> 00:00:58,100
could already exist in osm so if you

00:00:56,180 --> 00:01:00,170
decide I don't know to add also the

00:00:58,100 --> 00:01:03,530
traffic lights you will have to go to

00:01:00,170 --> 00:01:07,490
the same process once again so this

00:01:03,530 --> 00:01:10,610
takes a lot of time the challenge is to

00:01:07,490 --> 00:01:13,240
solve this problem by creating a

00:01:10,610 --> 00:01:19,400
pipeline that can identify these

00:01:13,240 --> 00:01:22,100
features automatically and at scale the

00:01:19,400 --> 00:01:24,140
solution that we did I tell enough to

00:01:22,100 --> 00:01:27,860
solve this problem consists of the

00:01:24,140 --> 00:01:32,510
following steps the first step was to

00:01:27,860 --> 00:01:35,510
gather the images we we gathered the

00:01:32,510 --> 00:01:37,490
images using the open Street cam app I

00:01:35,510 --> 00:01:41,180
don't know how many of you have heard of

00:01:37,490 --> 00:01:45,229
it it's a free and open source app which

00:01:41,180 --> 00:01:47,030
records dash cam images and here is the

00:01:45,229 --> 00:01:49,960
sample of the images that we have

00:01:47,030 --> 00:01:49,960
recorded

00:01:53,800 --> 00:02:00,200
and to give you a sense of the amount of

00:01:57,350 --> 00:02:02,390
data that we currently have here is a

00:02:00,200 --> 00:02:07,430
heat map with the coverage in the Berlin

00:02:02,390 --> 00:02:11,380
area at present in open street camera

00:02:07,430 --> 00:02:16,340
have about 146 million images and about

00:02:11,380 --> 00:02:18,410
650 7,000 distinction emitters so the

00:02:16,340 --> 00:02:21,620
first step was to gather the images the

00:02:18,410 --> 00:02:24,530
next step was to create the tag data set

00:02:21,620 --> 00:02:26,840
what this means is if you have an image

00:02:24,530 --> 00:02:28,580
you want to let me image all the science

00:02:26,840 --> 00:02:31,340
that you consider of interest to be

00:02:28,580 --> 00:02:35,120
tagged for example one weighs the

00:02:31,340 --> 00:02:38,270
restrictions signpost to do this a lot

00:02:35,120 --> 00:02:41,450
of manual work needed to be done this

00:02:38,270 --> 00:02:43,430
was done by my team using a tool that we

00:02:41,450 --> 00:02:47,500
have developed to support the tagging

00:02:43,430 --> 00:02:51,530
and let's see how this tool looks like

00:02:47,500 --> 00:02:54,410
so you have this image you want in this

00:02:51,530 --> 00:02:56,810
image to tag all the signs that are

00:02:54,410 --> 00:03:00,050
important for navigation for example

00:02:56,810 --> 00:03:02,090
traffic lights one way no entry signs to

00:03:00,050 --> 00:03:06,080
do this you will have to draw bounding

00:03:02,090 --> 00:03:10,130
box as big as the sign select the sign

00:03:06,080 --> 00:03:12,830
category and validated the tool is very

00:03:10,130 --> 00:03:15,410
intuitive in my opinion because you have

00:03:12,830 --> 00:03:18,860
the possibility to validate detections

00:03:15,410 --> 00:03:21,260
or manual tagging to invalidate them to

00:03:18,860 --> 00:03:22,489
resize a certain sign the bounding box

00:03:21,260 --> 00:03:24,920
was not correct

00:03:22,489 --> 00:03:27,019
here in the bar you can see all the

00:03:24,920 --> 00:03:30,410
detections or the manual tagging that

00:03:27,019 --> 00:03:33,610
were done in the trip that is shown here

00:03:30,410 --> 00:03:37,790
and also the protections and detect

00:03:33,610 --> 00:03:44,510
images that are in the current photo are

00:03:37,790 --> 00:03:47,090
highlighted so using this tool we

00:03:44,510 --> 00:03:51,380
labeled about 70,000 images from the

00:03:47,090 --> 00:03:55,880
United States and we added about 220,000

00:03:51,380 --> 00:03:58,280
labels the most important lessons that

00:03:55,880 --> 00:04:01,370
we tagged for one way to inspection

00:03:58,280 --> 00:04:03,950
signpost turn lanes stop and yield signs

00:04:01,370 --> 00:04:06,080
and in the chart you can see the

00:04:03,950 --> 00:04:09,950
progress that we did from December

00:04:06,080 --> 00:04:12,880
until now we have about 160 signs that

00:04:09,950 --> 00:04:16,940
have at least one text a one-take

00:04:12,880 --> 00:04:22,730
instance and about 42 signs that have at

00:04:16,940 --> 00:04:25,700
least 1000 instant respect so hello

00:04:22,730 --> 00:04:28,490
everyone I'm Bob time I work in the AI

00:04:25,700 --> 00:04:30,920
team where we mainly do machine learning

00:04:28,490 --> 00:04:33,800
for computer vision and image processing

00:04:30,920 --> 00:04:35,450
and I'm gonna continue today's

00:04:33,800 --> 00:04:38,600
presentation so Alan I just stopped to

00:04:35,450 --> 00:04:42,110
talk to you about how we started by we

00:04:38,600 --> 00:04:44,030
started this with this pipeline by first

00:04:42,110 --> 00:04:45,890
gathering a lot of images we are

00:04:44,030 --> 00:04:48,770
constantly adding to those images using

00:04:45,890 --> 00:04:51,380
Copa street cam then creating a tag data

00:04:48,770 --> 00:04:53,750
set right now the next logical step is

00:04:51,380 --> 00:04:56,930
to create an AI system which leverages

00:04:53,750 --> 00:04:59,480
these two parts right these images and

00:04:56,930 --> 00:05:01,790
the tag dataset which then will be able

00:04:59,480 --> 00:05:05,300
to recognize those traffic signs in

00:05:01,790 --> 00:05:07,280
other images like in all of the images

00:05:05,300 --> 00:05:09,110
that we have gathered without the need

00:05:07,280 --> 00:05:11,030
for human intervention so this is the

00:05:09,110 --> 00:05:13,430
number three right creating an AI system

00:05:11,030 --> 00:05:16,460
that can detect all sentient images we

00:05:13,430 --> 00:05:18,890
have built this in our dedicated AI team

00:05:16,460 --> 00:05:20,450
along which I am part of of course you

00:05:18,890 --> 00:05:22,370
have used deep learning for object

00:05:20,450 --> 00:05:24,440
detection in order to build this because

00:05:22,370 --> 00:05:26,570
the talk is called the large-scale deep

00:05:24,440 --> 00:05:29,240
learning and on large-scale it clauses

00:05:26,570 --> 00:05:31,610
but we have used deep learning because

00:05:29,240 --> 00:05:34,190
it's the current state of the art in um

00:05:31,610 --> 00:05:36,290
in this problem which is conceptually

00:05:34,190 --> 00:05:38,630
called auto detection because you have

00:05:36,290 --> 00:05:40,910
to like detect different stuff in images

00:05:38,630 --> 00:05:42,200
in our case traffic signs so while

00:05:40,910 --> 00:05:44,720
building this we have gone through

00:05:42,200 --> 00:05:47,000
multiple iterations from various deep

00:05:44,720 --> 00:05:49,400
learning frameworks and architectures we

00:05:47,000 --> 00:05:52,760
have started with a two-stage solution

00:05:49,400 --> 00:05:55,730
building cafe which is a deep learning

00:05:52,760 --> 00:05:58,640
framework we have been gone to using a

00:05:55,730 --> 00:06:00,140
single stage solution mainly names you

00:05:58,640 --> 00:06:02,180
know saw detector and lately we have

00:06:00,140 --> 00:06:03,860
gone to an architecture called Verity

00:06:02,180 --> 00:06:06,020
Nannette which is the current state of

00:06:03,860 --> 00:06:08,480
the art in in object detection right

00:06:06,020 --> 00:06:09,860
okay so we have built this and because

00:06:08,480 --> 00:06:12,260
you're engineers and directed major

00:06:09,860 --> 00:06:14,000
stuff let's see some numbers we got to

00:06:12,260 --> 00:06:17,000
about 92%

00:06:14,000 --> 00:06:21,170
traducciÃ³n 55 different classes of signs

00:06:17,000 --> 00:06:24,410
and as far as the infrastructure we are

00:06:21,170 --> 00:06:26,840
able to run this whole pipeline about

00:06:24,410 --> 00:06:29,150
1.3 seconds per image on an Nvidia

00:06:26,840 --> 00:06:32,120
viajando chip used because all of these

00:06:29,150 --> 00:06:34,520
all of these deep learning algorithms

00:06:32,120 --> 00:06:36,650
need to be run on GPUs in order to be

00:06:34,520 --> 00:06:38,660
able to massively paralyzed all

00:06:36,650 --> 00:06:41,030
deformation necessary of course if maybe

00:06:38,660 --> 00:06:43,400
we can just add more worker knows a more

00:06:41,030 --> 00:06:46,610
diffuse meaner pipeline to process more

00:06:43,400 --> 00:06:49,580
and more images so let's see how a trip

00:06:46,610 --> 00:06:52,310
which has me run through the detections

00:06:49,580 --> 00:06:54,140
looks like and you can just see a lot of

00:06:52,310 --> 00:06:56,540
speed limits being detected a lot of

00:06:54,140 --> 00:06:58,850
yield signs lot of traffic lights turn

00:06:56,540 --> 00:07:01,430
restrictions and so on and so forth

00:06:58,850 --> 00:07:03,200
right and this actually enables us if we

00:07:01,430 --> 00:07:05,930
have like hundreds of thousands of

00:07:03,200 --> 00:07:09,680
images in the land just to take the ones

00:07:05,930 --> 00:07:11,419
which for example have like maybe turn

00:07:09,680 --> 00:07:13,640
restitution in them right so as you can

00:07:11,419 --> 00:07:16,669
see right there so if this enables us

00:07:13,640 --> 00:07:18,979
not to not to look through them manually

00:07:16,669 --> 00:07:21,470
but only look at the ones which are

00:07:18,979 --> 00:07:24,500
interested to ourselves and that's nice

00:07:21,470 --> 00:07:26,360
and that's good and this shortens the

00:07:24,500 --> 00:07:29,210
time needed to add those math features

00:07:26,360 --> 00:07:32,000
in the map but the questions come can we

00:07:29,210 --> 00:07:35,960
do more can we efficiently more than

00:07:32,000 --> 00:07:37,669
more this process and did the question

00:07:35,960 --> 00:07:40,100
and the answer is well of course yes

00:07:37,669 --> 00:07:42,290
because we started with this task being

00:07:40,100 --> 00:07:44,360
able to automatically filter images with

00:07:42,290 --> 00:07:46,610
specific signs in them right because you

00:07:44,360 --> 00:07:48,770
don't want to manually review hundreds

00:07:46,610 --> 00:07:52,310
of thousands of images because one well

00:07:48,770 --> 00:07:54,440
it takes out of Simon - we could do it

00:07:52,310 --> 00:07:57,140
faster so we believe it we have managed

00:07:54,440 --> 00:07:59,450
to do this so by using this AI system

00:07:57,140 --> 00:08:01,490
but what we have also discovered when

00:07:59,450 --> 00:08:04,520
manually adding these features into a

00:08:01,490 --> 00:08:07,550
map it is that detecting the affected

00:08:04,520 --> 00:08:09,470
way ID of a particular sign for example

00:08:07,550 --> 00:08:12,260
have a speed limit announced in an image

00:08:09,470 --> 00:08:13,880
well when you add that in Jasmine Apple

00:08:12,260 --> 00:08:16,280
Street Map you have to say well look

00:08:13,880 --> 00:08:18,530
this image and this side effects this

00:08:16,280 --> 00:08:20,060
particular way right so and then you

00:08:18,530 --> 00:08:22,370
have to look whether or not that

00:08:20,060 --> 00:08:24,710
particular way they already has this

00:08:22,370 --> 00:08:25,849
information added in them right so this

00:08:24,710 --> 00:08:28,969
takes a lot of time and

00:08:25,849 --> 00:08:31,099
we wanted to see if we can automate it

00:08:28,969 --> 00:08:32,449
such that we can already match the

00:08:31,099 --> 00:08:34,610
detection to await the end we can

00:08:32,449 --> 00:08:36,829
automatically compare so it so I said to

00:08:34,610 --> 00:08:38,930
shorten that time even more right so

00:08:36,829 --> 00:08:41,690
that's that's exactly what we have tried

00:08:38,930 --> 00:08:43,940
we have tried to do okay so step number

00:08:41,690 --> 00:08:46,579
four localize the detection what does

00:08:43,940 --> 00:08:49,220
this mean sexually is to be able to

00:08:46,579 --> 00:08:51,019
compute the detected road sign GPS

00:08:49,220 --> 00:08:53,839
location right so let's look an example

00:08:51,019 --> 00:08:54,440
to like better understand what you're

00:08:53,839 --> 00:08:56,060
talking about

00:08:54,440 --> 00:08:57,529
let's assume you have this image in

00:08:56,060 --> 00:08:59,170
which you have detected those traffic

00:08:57,529 --> 00:09:02,480
lights they're far away in the distance

00:08:59,170 --> 00:09:04,190
in order to match it alterior at an

00:09:02,480 --> 00:09:06,829
interior point to that to one particular

00:09:04,190 --> 00:09:08,899
street you need to know the GPS location

00:09:06,829 --> 00:09:11,899
right so as you can see from this image

00:09:08,899 --> 00:09:14,180
signs are observable and images from 50

00:09:11,899 --> 00:09:16,519
100 200 meters away right so you need to

00:09:14,180 --> 00:09:19,009
compute that particular offset from the

00:09:16,519 --> 00:09:22,130
car GPS location to the English GPS

00:09:19,009 --> 00:09:23,720
location right so you need to taken the

00:09:22,130 --> 00:09:26,209
image location upon this point you need

00:09:23,720 --> 00:09:28,130
to correctly localize maybe a stop sign

00:09:26,209 --> 00:09:29,630
in that particular intersection right so

00:09:28,130 --> 00:09:31,490
how do we do this now we're not using

00:09:29,630 --> 00:09:33,500
deep learning or machine learning here

00:09:31,490 --> 00:09:35,750
because we don't need it right it's not

00:09:33,500 --> 00:09:38,329
it's not like a one tool to solve them

00:09:35,750 --> 00:09:40,579
all what we use is like a simple system

00:09:38,329 --> 00:09:43,189
which takes a little bit of a little bit

00:09:40,579 --> 00:09:45,439
of input first of all we know the

00:09:43,189 --> 00:09:48,110
traffic sign bounding box location and

00:09:45,439 --> 00:09:50,480
size in an image right because we have

00:09:48,110 --> 00:09:52,699
detected it we are able to localize then

00:09:50,480 --> 00:09:53,569
see how big that particular traffic sign

00:09:52,699 --> 00:09:56,050
is in the image

00:09:53,569 --> 00:09:59,120
second of all we know the real-life

00:09:56,050 --> 00:10:02,209
dimensions of the signs because a stop

00:09:59,120 --> 00:10:05,600
sign is like a local traffic light has a

00:10:02,209 --> 00:10:07,009
pretty standard set size like and

00:10:05,600 --> 00:10:10,040
dimensions throughout a particular

00:10:07,009 --> 00:10:12,079
region and that and that is where public

00:10:10,040 --> 00:10:13,880
information we already know it and third

00:10:12,079 --> 00:10:16,399
of all we know the camera parameters

00:10:13,880 --> 00:10:18,589
because each each one of our iPhones or

00:10:16,399 --> 00:10:20,389
an Android phones has different camera

00:10:18,589 --> 00:10:23,689
with different camera parameters which

00:10:20,389 --> 00:10:26,000
affect how images are distorted like how

00:10:23,689 --> 00:10:28,189
object are distorted in this images now

00:10:26,000 --> 00:10:30,259
if you take all of these three stuff

00:10:28,189 --> 00:10:33,290
they sprinkle a bit of math over them

00:10:30,259 --> 00:10:35,449
and then you can actually compute that

00:10:33,290 --> 00:10:38,180
particular offset and compute the GPS

00:10:35,449 --> 00:10:38,769
floaters and well that's nice and that's

00:10:38,180 --> 00:10:41,379
good and

00:10:38,769 --> 00:10:45,220
helps like know the GPS location right

00:10:41,379 --> 00:10:47,800
but this is the moment when the large

00:10:45,220 --> 00:10:49,629
scale comes into into the stuff this is

00:10:47,800 --> 00:10:51,759
the moment when you realize that you

00:10:49,629 --> 00:10:53,350
need to cluster multiple detections

00:10:51,759 --> 00:10:55,540
together what does this means

00:10:53,350 --> 00:10:57,999
conceptually is that we need a system

00:10:55,540 --> 00:11:00,220
which needs if you can aggregate the

00:10:57,999 --> 00:11:03,749
detections which refer to the same

00:11:00,220 --> 00:11:06,639
physical sign now remember we do have

00:11:03,749 --> 00:11:08,769
tens of millions of photos in throughout

00:11:06,639 --> 00:11:11,139
the world that means that on a majority

00:11:08,769 --> 00:11:14,319
of the street we do have multiple

00:11:11,139 --> 00:11:16,899
streets multiple trips going on the same

00:11:14,319 --> 00:11:19,679
street right that makes sense so what

00:11:16,899 --> 00:11:22,989
this means is that imagine this this

00:11:19,679 --> 00:11:25,809
this situation in which you have like a

00:11:22,989 --> 00:11:27,730
particular detection being being

00:11:25,809 --> 00:11:29,439
detected there like it may be a stop

00:11:27,730 --> 00:11:32,379
sign but they want to realize that you

00:11:29,439 --> 00:11:35,319
have multiple trips on better but on

00:11:32,379 --> 00:11:37,299
that way ID so maybe you have multiple

00:11:35,319 --> 00:11:40,449
detections but which one reality is the

00:11:37,299 --> 00:11:42,759
same physical sign right and then maybe

00:11:40,449 --> 00:11:45,490
you have another bunch of trips which

00:11:42,759 --> 00:11:47,799
detect stolen a different physical stop

00:11:45,490 --> 00:11:50,499
sign on an intersection nearby now what

00:11:47,799 --> 00:11:53,529
you could do is review every single one

00:11:50,499 --> 00:11:55,089
of those of those infections but that

00:11:53,529 --> 00:11:57,579
that's pretty inefficient if you have

00:11:55,089 --> 00:11:59,589
added the speed limit ones I don't want

00:11:57,579 --> 00:12:02,019
to look like that at a hundred images of

00:11:59,589 --> 00:12:04,269
the same speed limit right so what you

00:12:02,019 --> 00:12:08,139
need to do is cluster this and say look

00:12:04,269 --> 00:12:10,689
v6 our single cluster Daleks are another

00:12:08,139 --> 00:12:12,910
cluster in order to do this we use the

00:12:10,689 --> 00:12:16,240
simple clustering algorithm from a

00:12:12,910 --> 00:12:18,999
scalar called DB scan in which we which

00:12:16,240 --> 00:12:21,429
each which can cluster those detection

00:12:18,999 --> 00:12:24,189
based on GPS location the heading of the

00:12:21,429 --> 00:12:26,799
sign and the type of the particles right

00:12:24,189 --> 00:12:29,169
now and after you do this the good part

00:12:26,799 --> 00:12:31,589
is that you can compute the cluster

00:12:29,169 --> 00:12:34,989
centroid which is basically the average

00:12:31,589 --> 00:12:37,360
GPS location like averaged from the

00:12:34,989 --> 00:12:39,730
members of that particular cluster why

00:12:37,360 --> 00:12:42,189
is that helpful well because as you can

00:12:39,730 --> 00:12:44,139
see when we compute the GPS location of

00:12:42,189 --> 00:12:46,509
that particular class of the each

00:12:44,139 --> 00:12:48,939
detection each has a bit of error right

00:12:46,509 --> 00:12:49,370
because this is not perfect it has a few

00:12:48,939 --> 00:12:51,380
meters

00:12:49,370 --> 00:12:53,570
of error right from the real sign but

00:12:51,380 --> 00:12:56,690
when you average them out together the

00:12:53,570 --> 00:12:59,029
error gets reduced and to get to a more

00:12:56,690 --> 00:13:01,610
approximate location of the real

00:12:59,029 --> 00:13:03,410
physical sign so at the end of the day

00:13:01,610 --> 00:13:06,830
you're left with just the Scholastic

00:13:03,410 --> 00:13:09,710
centroids so such that you can you can

00:13:06,830 --> 00:13:12,020
look at those and of course situation is

00:13:09,710 --> 00:13:13,820
not as simple in reality because you

00:13:12,020 --> 00:13:17,690
have tons of thousands of detections

00:13:13,820 --> 00:13:19,400
each cluster together very close in

00:13:17,690 --> 00:13:23,660
nature then you need to do something

00:13:19,400 --> 00:13:26,120
like this but we do the algorithm then a

00:13:23,660 --> 00:13:29,510
scaler and DB scan manages to do this

00:13:26,120 --> 00:13:31,339
really really quickly so we cluster them

00:13:29,510 --> 00:13:33,589
and that's fine that reduces the time

00:13:31,339 --> 00:13:35,839
needed to because if we don't have to

00:13:33,589 --> 00:13:38,180
review hundreds of duplicate detection

00:13:35,839 --> 00:13:39,980
and here comes step number six each

00:13:38,180 --> 00:13:41,690
means and we have talked about this

00:13:39,980 --> 00:13:44,360
right in the beginning is to match the

00:13:41,690 --> 00:13:47,000
cluster centroid to a particular street

00:13:44,360 --> 00:13:49,339
and conceptually what this means is to

00:13:47,000 --> 00:13:51,440
determine which street or road side

00:13:49,339 --> 00:13:53,270
effect right because we can expect them

00:13:51,440 --> 00:13:55,370
to do it automatically we don't have too

00:13:53,270 --> 00:13:58,130
big manually because remember in a like

00:13:55,370 --> 00:14:00,170
Union image you can see maybe signs from

00:13:58,130 --> 00:14:02,720
parallel roads or four adjacent

00:14:00,170 --> 00:14:05,810
perpendicular roads or maybe signs from

00:14:02,720 --> 00:14:08,360
like a bridge over you like this and

00:14:05,810 --> 00:14:11,120
that and manually mapping manually doing

00:14:08,360 --> 00:14:13,130
this and I reviewing that sign in the

00:14:11,120 --> 00:14:16,310
Java stuff like that like it takes a lot

00:14:13,130 --> 00:14:17,750
of time right so upon this point you do

00:14:16,310 --> 00:14:20,720
have the cluster and the cluster

00:14:17,750 --> 00:14:22,310
centroid computed for you and then what

00:14:20,720 --> 00:14:24,470
you can do it just match it to a

00:14:22,310 --> 00:14:26,480
particular roads right because you have

00:14:24,470 --> 00:14:28,070
the GPS location or it's heading you

00:14:26,480 --> 00:14:30,470
know it's cross the street and you can

00:14:28,070 --> 00:14:31,940
then just match to a street now why is

00:14:30,470 --> 00:14:34,370
this important why is it important

00:14:31,940 --> 00:14:36,380
technique magic to a street well very

00:14:34,370 --> 00:14:39,170
simply step number seven in which you

00:14:36,380 --> 00:14:41,000
can compare again the OSM information

00:14:39,170 --> 00:14:42,860
right because o in a noisy and there are

00:14:41,000 --> 00:14:46,130
already millions of tourists Rishon and

00:14:42,860 --> 00:14:48,110
millions of speed limits right so we

00:14:46,130 --> 00:14:50,600
don't want to waste time with doing

00:14:48,110 --> 00:14:52,670
anything that's already in or SM right

00:14:50,600 --> 00:14:54,500
so if you could just filter out the

00:14:52,670 --> 00:14:57,260
information which already exists that

00:14:54,500 --> 00:14:59,440
actually reduces the time needed to add

00:14:57,260 --> 00:15:01,269
all the transition in Milan right if

00:14:59,440 --> 00:15:03,550
don't have to look at the hundreds of

00:15:01,269 --> 00:15:06,009
thousand which are already added so a

00:15:03,550 --> 00:15:09,910
button up until this point what you're

00:15:06,009 --> 00:15:11,740
left with is that these detections with

00:15:09,910 --> 00:15:14,350
these clusters then let's say there are

00:15:11,740 --> 00:15:16,750
like spin limits we know on which way

00:15:14,350 --> 00:15:18,459
each one of them those effects you don't

00:15:16,750 --> 00:15:20,350
have to do this manually and you can

00:15:18,459 --> 00:15:22,660
also we can look at the tags on those

00:15:20,350 --> 00:15:24,670
particular way these and see loop the

00:15:22,660 --> 00:15:27,550
speed limit already is no SM the

00:15:24,670 --> 00:15:28,959
information is already there so boom we

00:15:27,550 --> 00:15:32,019
don't have to look at them forty percent

00:15:28,959 --> 00:15:33,610
of the reviewing time right so this is

00:15:32,019 --> 00:15:35,980
how the dissipate in it and this allows

00:15:33,610 --> 00:15:39,279
us to reduce the time needed to complete

00:15:35,980 --> 00:15:42,550
a map like too large to a large degree

00:15:39,279 --> 00:15:44,819
okay so that's all for me I'm gonna pass

00:15:42,550 --> 00:15:44,819
it to

00:15:46,430 --> 00:15:49,710
[Applause]

00:16:04,759 --> 00:16:11,699
okay so let's make a small recap with

00:16:07,860 --> 00:16:14,699
what I've discussed so far so the first

00:16:11,699 --> 00:16:17,879
step was to gather the images the next

00:16:14,699 --> 00:16:20,369
one was to create the tag data set well

00:16:17,879 --> 00:16:22,709
and then train the algorithm with the

00:16:20,369 --> 00:16:26,339
manual tagging that way we have time to

00:16:22,709 --> 00:16:28,800
detect road signs localize them cluster

00:16:26,339 --> 00:16:32,459
them and match the central to the

00:16:28,800 --> 00:16:34,559
streets that it affects the last step is

00:16:32,459 --> 00:16:37,439
to run the OpenStreetMap compare that

00:16:34,559 --> 00:16:39,959
Bob Don talked about to see only the

00:16:37,439 --> 00:16:45,300
detection of the signs that are not

00:16:39,959 --> 00:16:47,850
currently in OpenStreetMap we have open

00:16:45,300 --> 00:16:52,199
sourced everything to engage the

00:16:47,850 --> 00:16:56,040
community to build a better results we

00:16:52,199 --> 00:17:00,839
open our datasets you can find them on

00:16:56,040 --> 00:17:03,329
our github we also open source our

00:17:00,839 --> 00:17:06,059
networks we train whales you can

00:17:03,329 --> 00:17:10,770
download the algorithm train it and run

00:17:06,059 --> 00:17:13,199
it on your own images the tagging tool

00:17:10,770 --> 00:17:17,809
is available for everyone in the

00:17:13,199 --> 00:17:20,789
community all detections can be viewed

00:17:17,809 --> 00:17:23,520
validated and validated on the open

00:17:20,789 --> 00:17:26,010
street cam you have two options you have

00:17:23,520 --> 00:17:28,140
a trip mode which means that in a trip

00:17:26,010 --> 00:17:30,690
you will see all the detection on all

00:17:28,140 --> 00:17:32,970
the manual taking that has been done or

00:17:30,690 --> 00:17:35,520
assigned view where you can see from all

00:17:32,970 --> 00:17:41,190
the images a certain sign that has been

00:17:35,520 --> 00:17:45,990
detected or take we also currently run a

00:17:41,190 --> 00:17:47,850
competition on coda lab so the members

00:17:45,990 --> 00:17:49,980
are the community and being challenged

00:17:47,850 --> 00:17:53,789
to create a better solution than with it

00:17:49,980 --> 00:17:56,120
and anyone who's interested can join and

00:17:53,789 --> 00:18:01,799
if you beat our score you will win the

00:17:56,120 --> 00:18:03,990
$10,000 our future work involves

00:18:01,799 --> 00:18:09,809
detecting more classes of course

00:18:03,990 --> 00:18:11,260
image segmentation and OCR that's it

00:18:09,809 --> 00:18:14,960
thanks

00:18:11,260 --> 00:18:14,960
[Applause]

00:18:23,940 --> 00:18:32,380
what's about the local mappers if they

00:18:28,090 --> 00:18:35,530
make map which is up to date and then

00:18:32,380 --> 00:18:38,950
other mappers look at pictures which are

00:18:35,530 --> 00:18:42,520
old and bring it back to the old state

00:18:38,950 --> 00:18:46,300
then the local mapper has to drive two

00:18:42,520 --> 00:18:49,030
times 30 kilometers in order to see it's

00:18:46,300 --> 00:18:51,460
a change no it didn't change so a change

00:18:49,030 --> 00:18:54,640
effect then the next one comes since the

00:18:51,460 --> 00:18:55,420
pictures makes the old state so the

00:18:54,640 --> 00:19:01,500
local mapper

00:18:55,420 --> 00:19:05,430
there is the day where he will give up

00:19:01,500 --> 00:19:05,430
contributing to your Open Street Map

00:19:06,030 --> 00:19:15,940
okay so when so when we are running this

00:19:12,850 --> 00:19:18,220
ai algorithm on images detect new signs

00:19:15,940 --> 00:19:21,550
we're always trying because we're all or

00:19:18,220 --> 00:19:24,580
like we were constantly adding like new

00:19:21,550 --> 00:19:27,400
images in Opa street cam we are or we

00:19:24,580 --> 00:19:29,200
are always trying to make the tensions

00:19:27,400 --> 00:19:31,870
on like up-to-date images which have

00:19:29,200 --> 00:19:34,390
been taking like like in recent like not

00:19:31,870 --> 00:19:35,980
like 5 years ago so that so that all of

00:19:34,390 --> 00:19:38,380
detections are up-to-date and we don't

00:19:35,980 --> 00:19:40,420
get to the like very valid situation

00:19:38,380 --> 00:19:46,450
that you have so that's how we that's

00:19:40,420 --> 00:19:47,920
how we manage it thank you for your

00:19:46,450 --> 00:19:51,160
presentation I would like to ask you

00:19:47,920 --> 00:19:53,020
whether you you think that the tools are

00:19:51,160 --> 00:19:57,790
related especially toward mental reality

00:19:53,020 --> 00:20:00,700
so photogrammetry and instruction for

00:19:57,790 --> 00:20:03,700
motion or just our Laxus parallax

00:20:00,700 --> 00:20:06,700
effects could affect your approach or

00:20:03,700 --> 00:20:09,580
even you already evaluated pros and cons

00:20:06,700 --> 00:20:14,970
for the these kind of techniques to

00:20:09,580 --> 00:20:14,970
localize something from a 2d image in 3d

00:20:15,540 --> 00:20:23,650
okay so so currently for localization we

00:20:21,730 --> 00:20:26,770
do have like some

00:20:23,650 --> 00:20:28,630
maybe some ideas on how to improve the

00:20:26,770 --> 00:20:32,350
localization because all of our images

00:20:28,630 --> 00:20:34,360
come from like a wide variety of phones

00:20:32,350 --> 00:20:36,490
and Whelan's cameras and so on so we do

00:20:34,360 --> 00:20:39,040
have like some problems with it but we

00:20:36,490 --> 00:20:40,720
haven't invested like currently that

00:20:39,040 --> 00:20:43,090
much time into adding those those like

00:20:40,720 --> 00:20:44,950
complex like algorithms that you have

00:20:43,090 --> 00:20:46,750
mentioned but that's certainly an idea

00:20:44,950 --> 00:20:49,500
that we plan to explore in the future

00:20:46,750 --> 00:20:49,500
thank you very much

00:20:49,930 --> 00:20:55,059
do you actually propose to map

00:20:52,300 --> 00:20:56,950
individual signs or you do u transpose

00:20:55,059 --> 00:20:58,720
your data back to the street I mean a

00:20:56,950 --> 00:21:01,720
speed limit is a sign which is at a

00:20:58,720 --> 00:21:05,650
specific position I actually proposing

00:21:01,720 --> 00:21:07,690
to map the sign and map your data or

00:21:05,650 --> 00:21:09,460
your position back to that specific sign

00:21:07,690 --> 00:21:19,540
or actually proposing to map that back

00:21:09,460 --> 00:21:22,270
to a certain part of the street okay so

00:21:19,540 --> 00:21:25,600
what we do is that we localize the sign

00:21:22,270 --> 00:21:27,850
we see which road effects we compare if

00:21:25,600 --> 00:21:30,610
that information already exists in Open

00:21:27,850 --> 00:21:32,890
Street Map and if it's not your we show

00:21:30,610 --> 00:21:33,940
them and we say okay look here is the

00:21:32,890 --> 00:21:36,460
speed limit

00:21:33,940 --> 00:21:42,460
check it see if it's correct and if it

00:21:36,460 --> 00:21:44,410
is manually add it into the map because

00:21:42,460 --> 00:21:46,420
also in you know SM for example for

00:21:44,410 --> 00:21:48,580
specific type of science for example

00:21:46,420 --> 00:21:50,470
speed limits you just add the

00:21:48,580 --> 00:21:53,620
information to the way ID that it

00:21:50,470 --> 00:21:58,150
affects it you don't yeah yeah you can

00:21:53,620 --> 00:21:59,860
map both yeah I do because I originally

00:21:58,150 --> 00:22:01,900
added only the speed limits of a street

00:21:59,860 --> 00:22:06,429
but in the end when you have a symmetric

00:22:01,900 --> 00:22:08,470
speed limits on roads getting very not

00:22:06,429 --> 00:22:10,990
all non-obvious agree where speed limits

00:22:08,470 --> 00:22:13,240
start in which direction so starting to

00:22:10,990 --> 00:22:15,490
map individual signs and their exact

00:22:13,240 --> 00:22:17,320
location is it much more easy to and

00:22:15,490 --> 00:22:17,860
later validate if your speed limit

00:22:17,320 --> 00:22:19,900
correct

00:22:17,860 --> 00:22:22,480
so because we do have the localized

00:22:19,900 --> 00:22:24,130
detection we maybe could like do both of

00:22:22,480 --> 00:22:26,380
them so but we started from the

00:22:24,130 --> 00:22:30,300
beginning with this idea but it can be

00:22:26,380 --> 00:22:30,300

YouTube URL: https://www.youtube.com/watch?v=a-XU1t5sgP8


