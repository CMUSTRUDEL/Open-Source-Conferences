Title: How Deep Learning could help to improve OSM Data Quality?
Publication date: 2018-08-13
Playlist: SotM 2018, Day 1, S.0.2
Description: 
	Olivier Courtin (DataPink), State of the Map 2018
https://2018.stateofthemap.org/2018/T068-How_Deep_Learning_could_help_to_improve_OSM_Data_Quality__/

How DeepLearning, and semantic segmentation, can be an efficient way to detect and spot inconsistency in OSM dataset ?

Machine and DeepLearning can succeed to tackle some old issues, in a far more convenient and efficient way than ever before… For instance DeepLearning, with aerial imagery semantic segmentation can improve features detection ability and allow us to spot dataset inconsistencies.

In this presentation we will focus on how an OpenStreetMap subset dataset (for instance roads and buildings on an area), can be evaluated to produce quality metric.

We wanna focus on:

Deep Learning vision, and specific Satellite imagery considerations (high and low resolutions, multispectral dimensions, dataset aggregation…)

How to qualify a good enough labelled DataSet (to allow supervised learning)

FOSS4G (PostGIS and Grass) integration with Python ML/DL framework

Concrete solution for efficient treatments for wide coverages
Captions: 
	00:00:02,429 --> 00:00:14,990
so hi everyone this tolkien this talk is

00:00:09,930 --> 00:00:17,520
about some improving them that quality

00:00:14,990 --> 00:00:21,720
wisdom is deep learning and the purple

00:00:17,520 --> 00:00:25,470
is true to detect inconsistency between

00:00:21,720 --> 00:00:28,290
two kind of data set the Ariel one like

00:00:25,470 --> 00:00:30,960
a satellite imagery for example and the

00:00:28,290 --> 00:00:36,690
vector of for instance buildings or

00:00:30,960 --> 00:00:40,289
roads if we look at the fate of thought

00:00:36,690 --> 00:00:42,660
to what we get to do that right now we

00:00:40,289 --> 00:00:46,620
already have some open source tool law

00:00:42,660 --> 00:00:49,260
to achieve it in OpenStreetMap ecosystem

00:00:46,620 --> 00:00:53,190
the first one is provided by a

00:00:49,260 --> 00:00:58,739
development seed and they provide a tool

00:00:53,190 --> 00:01:02,329
to help to to generate LaBelle's and

00:00:58,739 --> 00:01:06,330
then to to launch the training that a

00:01:02,329 --> 00:01:09,270
data set itself they will present

00:01:06,330 --> 00:01:10,050
something in this early conference them

00:01:09,270 --> 00:01:11,970
today

00:01:10,050 --> 00:01:15,450
at the end of the day so if you are

00:01:11,970 --> 00:01:20,880
interesting in it could be nice to see

00:01:15,450 --> 00:01:26,850
them the other tool already exist and

00:01:20,880 --> 00:01:30,570
would just been open to awesome a few

00:01:26,850 --> 00:01:36,990
weeks ago is robust apps from Neff tools

00:01:30,570 --> 00:01:42,330
from my boxes and the the robust add

00:01:36,990 --> 00:01:48,140
some application is based on the slippy

00:01:42,330 --> 00:01:48,140
map tag and it's a lot of different

00:01:48,560 --> 00:01:57,410
small small program you can just call

00:01:53,640 --> 00:02:03,600
them it's really really modular in fact

00:01:57,410 --> 00:02:06,450
and so the aim is to idle all the

00:02:03,600 --> 00:02:09,690
technical server on machine learning

00:02:06,450 --> 00:02:15,099
itself so it provides a high-level way

00:02:09,690 --> 00:02:20,109
to to launch a training on level

00:02:15,099 --> 00:02:25,540
imagery and it's really a state of art

00:02:20,109 --> 00:02:29,999
on the algorithm in itself and it's open

00:02:25,540 --> 00:02:32,109
source is an MIT open source solution so

00:02:29,999 --> 00:02:37,959
the basic on Daisy

00:02:32,109 --> 00:02:43,540
it's a unit combination stuff so the

00:02:37,959 --> 00:02:47,849
point is to classify I like how they

00:02:43,540 --> 00:02:52,120
already present in the telling of

00:02:47,849 --> 00:02:58,120
presentation but then also perform the

00:02:52,120 --> 00:03:02,290
classification you will their segments

00:02:58,120 --> 00:03:08,680
as each pixel to get a class on it

00:03:02,290 --> 00:03:12,090
so from an animator you got the same

00:03:08,680 --> 00:03:15,939
resolution but with the classification

00:03:12,090 --> 00:03:19,620
there isn't so several step to perform

00:03:15,939 --> 00:03:24,239
it the first one is to grab imagery and

00:03:19,620 --> 00:03:27,639
feature at the reason and to rasterize

00:03:24,239 --> 00:03:30,370
your jaw reason to to them to get the

00:03:27,639 --> 00:03:32,799
levels once you've done that you have to

00:03:30,370 --> 00:03:38,049
subset it with a train and volition

00:03:32,799 --> 00:03:44,939
validation LaBella and imagism then you

00:03:38,049 --> 00:03:50,109
can compute some specific or a parameter

00:03:44,939 --> 00:03:53,290
onion on your data set to improve the

00:03:50,109 --> 00:03:56,079
training zone in part and lunch the

00:03:53,290 --> 00:04:02,949
training itself so here in the pink

00:03:56,079 --> 00:04:06,329
it's robust at tool zone and here in

00:04:02,949 --> 00:04:12,340
gray it is a slippy map sides directory

00:04:06,329 --> 00:04:15,579
and there you get the model and once you

00:04:12,340 --> 00:04:18,909
train that your model is that there are

00:04:15,579 --> 00:04:21,130
ready to perform prediction on it so to

00:04:18,909 --> 00:04:24,340
perform prediction you've got another

00:04:21,130 --> 00:04:27,779
kind of imagery and you will predict

00:04:24,340 --> 00:04:27,779
with your model

00:04:27,790 --> 00:04:38,640
probabilities and then make them to get

00:04:31,510 --> 00:04:43,570
mass prediction so the process is from

00:04:38,640 --> 00:04:48,130
image and feature you create a data set

00:04:43,570 --> 00:04:52,030
you train it you get a model and once

00:04:48,130 --> 00:04:55,930
you get your model you can predict with

00:04:52,030 --> 00:05:00,190
your model and with other image okay and

00:04:55,930 --> 00:05:03,700
once you are able to to use your other

00:05:00,190 --> 00:05:09,220
image you can predict messages I learned

00:05:03,700 --> 00:05:13,150
from this one on Belgium data set with

00:05:09,220 --> 00:05:20,640
building feature it's um also aerial

00:05:13,150 --> 00:05:24,400
imagery on the zoom level and 18 and

00:05:20,640 --> 00:05:28,120
with only a little data set with only

00:05:24,400 --> 00:05:31,030
few tiles the result at the end is

00:05:28,120 --> 00:05:36,540
already quite decent event it could be

00:05:31,030 --> 00:05:41,290
improved and on the kind of our results

00:05:36,540 --> 00:05:45,670
from an al imagery you can grab the

00:05:41,290 --> 00:05:48,940
probabilities and the mask related to

00:05:45,670 --> 00:05:52,540
that obviously it doesn't work in all

00:05:48,940 --> 00:05:56,860
cases and in some cases you do something

00:05:52,540 --> 00:06:00,250
with less accuracy and for instance if

00:05:56,860 --> 00:06:03,820
my data set is not a well designed at

00:06:00,250 --> 00:06:06,850
the end the result is a less accurate

00:06:03,820 --> 00:06:10,240
because there I wanted to to grab

00:06:06,850 --> 00:06:21,310
buildings and not road

00:06:10,240 --> 00:06:25,200
so the indicator to to to perform as a

00:06:21,310 --> 00:06:27,790
training is based on a metric called

00:06:25,200 --> 00:06:30,520
intersection of Union and this

00:06:27,790 --> 00:06:35,050
intersection of all Union gives you a

00:06:30,520 --> 00:06:36,560
similarity between two images as metrics

00:06:35,050 --> 00:06:42,460
and

00:06:36,560 --> 00:06:46,370
these and this metric will help on each

00:06:42,460 --> 00:06:51,650
each step to improve your model and what

00:06:46,370 --> 00:06:58,580
we do then is a two on three create the

00:06:51,650 --> 00:07:00,320
product mask to to grab someone some

00:06:58,580 --> 00:07:04,730
picture from OpenStreetMap to rasterize

00:07:00,320 --> 00:07:10,700
it and to check what is the distance

00:07:04,730 --> 00:07:16,490
between a new mask and the one we just

00:07:10,700 --> 00:07:21,560
predict and if we do that you can check

00:07:16,490 --> 00:07:26,900
that if there is an aerial imagery there

00:07:21,560 --> 00:07:32,450
is a mask related to EEMA but there is

00:07:26,900 --> 00:07:36,800
nothing on on osm the intersection value

00:07:32,450 --> 00:07:39,650
union will be quite quite low if it's a

00:07:36,800 --> 00:07:43,070
tile or with nothing related in it will

00:07:39,650 --> 00:07:46,970
be alone something low but if it's

00:07:43,070 --> 00:07:49,300
something far more related it will be it

00:07:46,970 --> 00:07:58,340
will go in through so it could be a way

00:07:49,300 --> 00:08:02,780
at this point to say okay we can we can

00:07:58,340 --> 00:08:06,080
have a quick way to get an indicator of

00:08:02,780 --> 00:08:06,590
quality it is that simple in fact not at

00:08:06,080 --> 00:08:09,370
all

00:08:06,590 --> 00:08:14,440
because on this one you don't at all

00:08:09,370 --> 00:08:14,440
trainer model to a single size between

00:08:15,370 --> 00:08:21,919
between buildings on nail imagery you

00:08:19,520 --> 00:08:28,070
only do that for a specific resolution

00:08:21,919 --> 00:08:30,440
at a specific zoom level with some kind

00:08:28,070 --> 00:08:32,930
of landscape here is Belgium and so on

00:08:30,440 --> 00:08:36,380
and so on so it's not a generalized

00:08:32,930 --> 00:08:40,339
enough to be usable at scale it will

00:08:36,380 --> 00:08:43,789
only work with this really kind of the

00:08:40,339 --> 00:08:46,730
same imagery in input so the question

00:08:43,789 --> 00:08:49,410
now is what kind of data set do we have

00:08:46,730 --> 00:08:53,370
now a to to perform this kind

00:08:49,410 --> 00:08:56,450
training one is called a space net and

00:08:53,370 --> 00:08:58,890
space nets on a coverage is quite huge

00:08:56,450 --> 00:09:03,360
compared to the one I just used before

00:08:58,890 --> 00:09:06,660
and it's not respectful but is only

00:09:03,360 --> 00:09:11,970
focus on city ISM so there is nothing

00:09:06,660 --> 00:09:16,200
about countryside and so on but for big

00:09:11,970 --> 00:09:20,430
cities yeah it's it's a 1 but the

00:09:16,200 --> 00:09:23,100
license is not that for me see because

00:09:20,430 --> 00:09:28,380
for instance you can do anything you

00:09:23,100 --> 00:09:32,460
want with with the data you train you

00:09:28,380 --> 00:09:37,470
train them another data set is a in here

00:09:32,460 --> 00:09:41,190
one is only focused on lab on buildings

00:09:37,470 --> 00:09:43,950
now there is several kind of city from a

00:09:41,190 --> 00:09:46,800
small one to big ones but there is

00:09:43,950 --> 00:09:51,170
nothing about the countryside it should

00:09:46,800 --> 00:09:54,210
be on public domain but there is nothing

00:09:51,170 --> 00:09:59,700
explicitly said that so it has to be

00:09:54,210 --> 00:10:05,900
checked and the other one the one I use

00:09:59,700 --> 00:10:13,640
though is is a is based on the Belgium

00:10:05,900 --> 00:10:18,030
landscape so there is a countryside an

00:10:13,640 --> 00:10:20,730
area covered and it covered roads

00:10:18,030 --> 00:10:23,940
buildings and what else if I see is on

00:10:20,730 --> 00:10:26,520
the labeled part but on the license it's

00:10:23,940 --> 00:10:31,440
a research project only so you cannot

00:10:26,520 --> 00:10:33,660
choose to do anything you want so so the

00:10:31,440 --> 00:10:37,610
point here is to say what can we do

00:10:33,660 --> 00:10:41,520
about open data set if we look back on

00:10:37,610 --> 00:10:46,290
the on the past all the the progress who

00:10:41,520 --> 00:10:51,090
have been done in machine learning based

00:10:46,290 --> 00:10:55,650
on vision are begin is a image net

00:10:51,090 --> 00:10:59,310
collection it's a collection about one

00:10:55,650 --> 00:11:03,710
man on million of images and these are

00:10:59,310 --> 00:11:07,800
collisional images was the way to

00:11:03,710 --> 00:11:13,320
improve as a contest each year and to

00:11:07,800 --> 00:11:15,530
increase the accuracy and the way to to

00:11:13,320 --> 00:11:25,410
perform classification and segmentation

00:11:15,530 --> 00:11:27,570
but it's not only a way to to help to

00:11:25,410 --> 00:11:33,570
save time to launch a computation and

00:11:27,570 --> 00:11:39,690
the first one is it will help you to

00:11:33,570 --> 00:11:42,390
save time but it will also be a way to

00:11:39,690 --> 00:11:44,010
compare the results because as since as

00:11:42,390 --> 00:11:46,020
you are able to compare your results

00:11:44,010 --> 00:11:49,830
with someone else because they are based

00:11:46,020 --> 00:11:53,400
on the same data set your you've got to

00:11:49,830 --> 00:11:56,280
a way to to check if the kind of

00:11:53,400 --> 00:11:59,370
treatment you don't you chosen in your

00:11:56,280 --> 00:12:04,020
training was won or not

00:11:59,370 --> 00:12:06,810
so on at the moment as since as there is

00:12:04,020 --> 00:12:10,440
an open data sets and a volleyball

00:12:06,810 --> 00:12:14,460
became a point where you you've got

00:12:10,440 --> 00:12:18,660
already trained model so at a point we

00:12:14,460 --> 00:12:22,050
can we can bet that there will be a

00:12:18,660 --> 00:12:25,350
trained model on OpenStreetMap data set

00:12:22,050 --> 00:12:29,070
who came on as since as you've got a

00:12:25,350 --> 00:12:32,610
decent open data set but to perform that

00:12:29,070 --> 00:12:36,510
but as since you don't have good

00:12:32,610 --> 00:12:39,390
training data set you cannot wait for a

00:12:36,510 --> 00:12:42,780
pregnant pregnant alone it and the next

00:12:39,390 --> 00:12:46,860
step is on analysis works application so

00:12:42,780 --> 00:12:49,250
what will be an ideal open data set you

00:12:46,860 --> 00:12:52,620
have to be open data license compliance

00:12:49,250 --> 00:12:56,250
world where landscapers and achieve with

00:12:52,620 --> 00:13:01,800
mixed resolution and mix and so RGB but

00:12:56,250 --> 00:13:04,740
not only and coverage masks so it

00:13:01,800 --> 00:13:08,370
implies for example on the world that

00:13:04,740 --> 00:13:14,760
roles are not included as a

00:13:08,370 --> 00:13:16,080
but other area so from from

00:13:14,760 --> 00:13:19,560
OpenStreetMap it could be it could

00:13:16,080 --> 00:13:24,089
change because as since as your focus on

00:13:19,560 --> 00:13:29,970
the matrix oil imagery your roles have

00:13:24,089 --> 00:13:34,650
to be encoded as a surface what else I

00:13:29,970 --> 00:13:38,880
have to be big enough and it could be

00:13:34,650 --> 00:13:42,660
nice to get the data acquisition and the

00:13:38,880 --> 00:13:46,800
sands of time so it's an ideal but it

00:13:42,660 --> 00:13:51,240
could give us some some lead to what

00:13:46,800 --> 00:13:55,680
could be the reason already initiative

00:13:51,240 --> 00:13:59,880
to say okay what could be a level

00:13:55,680 --> 00:14:04,589
training on Sentinel true so this kind

00:13:59,880 --> 00:14:09,930
of open data set on coverage for IRL

00:14:04,589 --> 00:14:15,660
misery already exists but the point here

00:14:09,930 --> 00:14:19,430
is to say what can we do more to to

00:14:15,660 --> 00:14:26,940
improve that if you want to play with

00:14:19,430 --> 00:14:29,430
there is a early knife tutorial from one

00:14:26,940 --> 00:14:34,290
of the developer from my box will

00:14:29,430 --> 00:14:37,860
perform on a robust at program so this

00:14:34,290 --> 00:14:40,260
one is an Israeli way to to begin to

00:14:37,860 --> 00:14:43,290
play with and this one are all the

00:14:40,260 --> 00:14:47,420
resources to play with and if you want

00:14:43,290 --> 00:14:51,720
to contribute the labeling

00:14:47,420 --> 00:14:54,270
itself could be really interesting on

00:14:51,720 --> 00:14:57,560
space nets for instance for instance

00:14:54,270 --> 00:15:01,950
because it's best available imagery

00:14:57,560 --> 00:15:04,500
provided but even if it's good for the

00:15:01,950 --> 00:15:09,180
buildings it's really poor for the world

00:15:04,500 --> 00:15:11,510
so if we want to add two of them similar

00:15:09,180 --> 00:15:14,850
simultaneous recommendations on wrong

00:15:11,510 --> 00:15:16,620
space net clone and Kinross labeling

00:15:14,850 --> 00:15:20,370
could be real nice

00:15:16,620 --> 00:15:25,460
and everything can do on open aerial map

00:15:20,370 --> 00:15:29,790
labeling will Alps - and the other thing

00:15:25,460 --> 00:15:32,490
could be a nice - is an right now the

00:15:29,790 --> 00:15:37,200
Robo set application is really brand new

00:15:32,490 --> 00:15:42,090
and the post-processing is something we

00:15:37,200 --> 00:15:45,180
just begin on this application so

00:15:42,090 --> 00:15:48,150
everything will help to a post process

00:15:45,180 --> 00:15:54,540
the feature could be really nice to

00:15:48,150 --> 00:16:00,240
improve the process so the goal at some

00:15:54,540 --> 00:16:03,360
point is to see what for your Kegel team

00:16:00,240 --> 00:16:06,750
already achieved before from acetate

00:16:03,360 --> 00:16:09,930
satellite imagery they perform to get a

00:16:06,750 --> 00:16:13,980
really nice 70 semantics validation but

00:16:09,930 --> 00:16:17,700
to achieve that there to process the

00:16:13,980 --> 00:16:21,510
imagery and they have to use a really

00:16:17,700 --> 00:16:25,050
high resolution imagery and then to post

00:16:21,510 --> 00:16:31,350
process them so if we want to to get

00:16:25,050 --> 00:16:35,970
that at scale and openly available right

00:16:31,350 --> 00:16:39,860
now we already assumed the tool and

00:16:35,970 --> 00:16:44,400
thanks to map box but we don't have

00:16:39,860 --> 00:16:49,260
either the data set or either the

00:16:44,400 --> 00:16:53,400
post-processing part what will be the

00:16:49,260 --> 00:16:55,620
next disruptive point it will be to have

00:16:53,400 --> 00:16:59,130
a lower resolution imagery semantic

00:16:55,620 --> 00:17:02,280
cementation for example on something

00:16:59,130 --> 00:17:05,190
else - alternate lab all tuned to

00:17:02,280 --> 00:17:08,310
achieve that with multi with different

00:17:05,190 --> 00:17:11,640
kind of sensor not only il imagery but

00:17:08,310 --> 00:17:17,510
for instance early Midori and GPS track

00:17:11,640 --> 00:17:21,420
for example as a conclusions tool are

00:17:17,510 --> 00:17:28,750
nowadays available but the current

00:17:21,420 --> 00:17:34,450
bottleneck is open data set tomorrow

00:17:28,750 --> 00:17:36,820
i lunch on their room it's one that 6:00

00:17:34,450 --> 00:17:40,660
on Sunday at the beginning of the

00:17:36,820 --> 00:17:43,810
afternoon above to just talk about what

00:17:40,660 --> 00:17:46,060
can we do about open data set is it

00:17:43,810 --> 00:17:50,470
something we can we can contribute

00:17:46,060 --> 00:17:53,530
together or not to to help to improve

00:17:50,470 --> 00:17:55,780
this kind of thing and so to help the

00:17:53,530 --> 00:18:10,960
wool process of machine learning based

00:17:55,780 --> 00:18:13,120
on the idea of my dream and since I are

00:18:10,960 --> 00:18:15,610
thanks for thought and I'll have two

00:18:13,120 --> 00:18:18,100
questions so the first question is

00:18:15,610 --> 00:18:20,560
whether you have tried to predict

00:18:18,100 --> 00:18:24,370
multiple categories objects together

00:18:20,560 --> 00:18:28,660
like within one you know image how you

00:18:24,370 --> 00:18:30,640
may see houses both houses and Joe's and

00:18:28,660 --> 00:18:33,010
you know four ways or lakes

00:18:30,640 --> 00:18:35,560
together yes I wonder if you have tried

00:18:33,010 --> 00:18:39,670
to predict a margin of multiple

00:18:35,560 --> 00:18:42,790
categories objects gathered together or

00:18:39,670 --> 00:18:45,610
to only focus on either you know

00:18:42,790 --> 00:18:48,430
beauties or other words at one time at

00:18:45,610 --> 00:18:50,440
this moment sir I focus only on

00:18:48,430 --> 00:18:53,740
buildings because it's a more easy to

00:18:50,440 --> 00:18:54,400
tackle because available because of the

00:18:53,740 --> 00:19:01,000
labonza

00:18:54,400 --> 00:19:05,530
buildings are easier to get rods for

00:19:01,000 --> 00:19:08,500
example or because most of the syllables

00:19:05,530 --> 00:19:11,260
are based on line string so I since as

00:19:08,500 --> 00:19:16,720
your ability is as a line string it's

00:19:11,260 --> 00:19:19,780
harder to to get a good good results at

00:19:16,720 --> 00:19:23,020
the end and the other point is are right

00:19:19,780 --> 00:19:24,510
now robust at I just used for these are

00:19:23,020 --> 00:19:27,670
only

00:19:24,510 --> 00:19:30,250
able to perform one classification at a

00:19:27,670 --> 00:19:32,320
time so if you want to have a multiple

00:19:30,250 --> 00:19:35,590
segmentation yeah with several places

00:19:32,320 --> 00:19:39,370
you have to improve it all to do a

00:19:35,590 --> 00:19:40,750
several time and to try to to remove all

00:19:39,370 --> 00:19:43,180
the intersection between your

00:19:40,750 --> 00:19:44,890
classification sounds good and the

00:19:43,180 --> 00:19:47,290
second question is about the

00:19:44,890 --> 00:19:50,200
misalignment between or OpenStreetMap

00:19:47,290 --> 00:19:52,270
Tayla and the satellite imagery so it

00:19:50,200 --> 00:19:54,700
happens quite often right so I wonder

00:19:52,270 --> 00:19:58,360
like when you do the cross-validation

00:19:54,700 --> 00:20:01,360
stop well if you have considered this

00:19:58,360 --> 00:20:04,750
problem as a challenge or try to tackle

00:20:01,360 --> 00:20:07,390
it could you repeat your your question

00:20:04,750 --> 00:20:08,700
answer the questions about the

00:20:07,390 --> 00:20:11,950
misalignment between

00:20:08,700 --> 00:20:14,050
OpenStreetMap data and satellite imagery

00:20:11,950 --> 00:20:16,750
yeah I wonder when you do the

00:20:14,050 --> 00:20:25,450
cross-validation stuff if you have tried

00:20:16,750 --> 00:20:26,800
to you know tackle this challenge for

00:20:25,450 --> 00:20:30,190
the shape of the beauty on the

00:20:26,800 --> 00:20:32,800
OpenStreetMap data right there Maya has

00:20:30,190 --> 00:20:35,230
an offset compared with satellite

00:20:32,800 --> 00:20:38,500
imagery you might observe an offset

00:20:35,230 --> 00:20:44,650
between though the beauty opens remap

00:20:38,500 --> 00:20:46,420
and the satellite imagery right sorry I

00:20:44,650 --> 00:20:48,640
guess I can just follow up with the

00:20:46,420 --> 00:20:49,030
details is very hard to describe your

00:20:48,640 --> 00:20:52,650
problem

00:20:49,030 --> 00:20:52,650
mmm thank you you're welcome

00:21:00,080 --> 00:21:06,120
so okay so in fact that we don't turn we

00:21:04,110 --> 00:21:09,630
don't walk on them

00:21:06,120 --> 00:21:14,250
Wes I mean itself will walk on the Lebel

00:21:09,630 --> 00:21:20,040
and so the next step is to compare as a

00:21:14,250 --> 00:21:22,320
LaBelle and the OSM victor in itself so

00:21:20,040 --> 00:21:25,170
you you don't compare

00:21:22,320 --> 00:21:28,620
in fact the satellite imagery with OS

00:21:25,170 --> 00:21:31,490
Emma you compare in fact the Lebel from

00:21:28,620 --> 00:21:36,990
your data set with the Lebel from

00:21:31,490 --> 00:21:40,800
OpenStreetMap also its eurozone is the

00:21:36,990 --> 00:21:44,940
OSM rasterization between your mas will

00:21:40,800 --> 00:21:50,070
come from the prediction so in fact you

00:21:44,940 --> 00:21:56,610
never compare the angle and as well but

00:21:50,070 --> 00:22:03,090
you compare yeah to to victor

00:21:56,610 --> 00:22:05,400
restoration and beyond between I'm a bit

00:22:03,090 --> 00:22:08,850
taking a question how much do you think

00:22:05,400 --> 00:22:11,370
that multispectral imagery helps in

00:22:08,850 --> 00:22:12,780
addition to like normal imagery for

00:22:11,370 --> 00:22:15,000
example for our country we have 10

00:22:12,780 --> 00:22:17,250
centimeter open data for satellite just

00:22:15,000 --> 00:22:19,410
this month's release but say you only

00:22:17,250 --> 00:22:22,710
have the visible parts the obvious one

00:22:19,410 --> 00:22:25,130
shouldn't we have also this multi

00:22:22,710 --> 00:22:25,130
spectrum

00:22:31,090 --> 00:22:37,480
if for example they achieve a really

00:22:33,580 --> 00:22:40,090
good result because the got higher

00:22:37,480 --> 00:22:40,690
resolution as multispectral but they

00:22:40,090 --> 00:22:43,480
achieve it

00:22:40,690 --> 00:22:46,330
on a really small data set and the point

00:22:43,480 --> 00:22:51,280
is more you got data unless you need a

00:22:46,330 --> 00:22:53,760
multispectral but on the other way if

00:22:51,280 --> 00:22:56,560
you go to multispectral you vote

00:22:53,760 --> 00:23:01,060
additional information and so it really

00:22:56,560 --> 00:23:03,070
could help especially if the resolution

00:23:01,060 --> 00:23:06,070
you use or for example with something l2

00:23:03,070 --> 00:23:09,250
is lower so it could be a balanced

00:23:06,070 --> 00:23:10,180
between the resolution you get and the

00:23:09,250 --> 00:23:15,160
number banda

00:23:10,180 --> 00:23:19,030
you've got and and if you are able to to

00:23:15,160 --> 00:23:22,450
compare between a multispectral with the

00:23:19,030 --> 00:23:24,520
i'll resolution and with a multi-phase

00:23:22,450 --> 00:23:27,160
problem with a lower resolution at a

00:23:24,520 --> 00:23:32,110
point you're able even with a low

00:23:27,160 --> 00:23:38,410
resolution aerial imagery like to to to

00:23:32,110 --> 00:23:41,590
bet to go to get a decent result idea ok

00:23:38,410 --> 00:23:43,540
second question is how different do you

00:23:41,590 --> 00:23:46,030
think that the models will be depend the

00:23:43,540 --> 00:23:49,090
source data for example if i have

00:23:46,030 --> 00:23:54,090
different regions can I reuse the same

00:23:49,090 --> 00:23:55,330
model for Manono planetlab the data from

00:23:54,090 --> 00:23:59,680
sentinel

00:23:55,330 --> 00:24:02,770
if we just work with the result will be

00:23:59,680 --> 00:24:09,580
poor if you use it just like it

00:24:02,770 --> 00:24:14,740
you have to train it again to to to get

00:24:09,580 --> 00:24:22,740
a decent result and during the imagery

00:24:14,740 --> 00:24:22,740
has to be somehow comparable on the Colo

00:24:22,800 --> 00:24:29,640
ratio for example in internet it's a

00:24:25,960 --> 00:24:34,120
huge problem for them to calibrate the

00:24:29,640 --> 00:24:36,790
rule data and to have something current

00:24:34,120 --> 00:24:41,330
enough to perform any kind of treatment

00:24:36,790 --> 00:24:44,930
so it will be something really touchy

00:24:41,330 --> 00:24:49,490
to go to one single data set with enough

00:24:44,930 --> 00:24:56,570
information to allow at a point some

00:24:49,490 --> 00:25:02,090
kind of generic system to perform with

00:24:56,570 --> 00:25:06,560
any kind of sensor a quite decent result

00:25:02,090 --> 00:25:09,830
but you can use fine training so you you

00:25:06,560 --> 00:25:12,860
begin to train it on the generic data

00:25:09,830 --> 00:25:16,610
set and at the end you you finalize it

00:25:12,860 --> 00:25:18,500
on your specific data sets and on this

00:25:16,610 --> 00:25:28,890
way it could be a good way to achieve

00:25:18,500 --> 00:25:30,590
that thank you once a lot

00:25:28,890 --> 00:25:36,019
[Music]

00:25:30,590 --> 00:25:36,019

YouTube URL: https://www.youtube.com/watch?v=QyWFRY0Whq8


