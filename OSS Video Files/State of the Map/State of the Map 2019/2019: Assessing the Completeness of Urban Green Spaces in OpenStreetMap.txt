Title: 2019: Assessing the Completeness of Urban Green Spaces in OpenStreetMap
Publication date: 2020-07-18
Playlist: State of the Map 2019
Description: 
	OpenStreetMap provides a lot of valuable information about urban green spaces, but the numerous and conceptually overlapping OSM tags that describe such features lead to spatially heterogenous representations in OSM. We developed an exploratory data analysis methodology to identify locally relevant OSM tags for mapping green spaces in a specific area and compared the extracted OSM features to administrative data to evaluate the level of completeness in regard to urban green spaces.

Urban green spaces provide a variety of important ecosystem services such as micro-climate regulation, increase of biodiversity and the provision of recreational and cultural services for citizens. Thus, they are an important factor for the quality of life in cities (Bolund and Hunhammar, 1999). However, in order to take advantage of these services citizens need to have sufficient information about the location and qualities of nearby green spaces. Within the project “meinGrün” we are addressing this issue by developing a web-based recommendation service which helps citizens find suitable green spaces that satisfy their personal needs. 
OpenStreetMap (OSM) plays an important role in this project, since it provides a lot of valuable information about urban green spaces such as their location and the amenities they provide (playgrounds, benches, toilets etc.) However, its spatially heterogeneous data quality, especially in regard to the level of completeness, provides challenges for its usage in a recommendation system. Therefore, the integration of OSM data for our purposes requires a prior assessment of the completeness of urban green spaces.
The completeness of certain geographic objects is one of the main fields of investigation in regard to OSM data quality. In recent years several studies investigated the completeness of OSM data with respect to the road network (Barrington-Leigh and Millard-Ball, 2017), buildings (Hecht et al., 2013) or land use features (Jokar Arsanjani et al., 2015). Urban green spaces, on the other hand, were rarely the focus of completeness studies. Ali et al. (2016) developed a method to quantify the plausibility of vegetation-related tags being assigned to specific OSM features and Lopes et al. (2017) evaluated the potential of OSM for extracting information about natural local climate zones. 
Since both of these studies do not explicitly address the completeness of urban green spaces, we developed a new methodology for this purpose. In contrast to buildings and highways, this poses unique challenges due to the variety of vegetation-related OSM tags and the many different forms of urban vegetation ranging from large parks over private gardens to roadside greenery. OSM tags that describe natural objects are numerous and sometimes conceptually overlapping e.g. some features could be tagged as leisure=park or leisure=garden. This leads to different representations of urban green spaces in OSM across different geographical regions. Defining one set of relevant OSM tags to measure the completeness of urban green spaces that can be applied everywhere is therefore not possible.
To solve this issue, we developed an explorative data analysis methodology based on OSM and satellite imagery to identify locally relevant OSM tags that indicate urban green spaces. The analysis is based on statistical and graphical methods to evaluate the association between a certain OSM tag and the presence of vegetation. After the relevant tags have been identified, features representing green spaces are extracted from OSM and compared to an administrative data set to assess the level of completeness. As a basis for this comparison, the study area is divided into patches of homogenous land use based on natural and human-made barriers such as the road network, rivers or objects that mark changes in land use (fences, walls, etc.). On this basis, features from both data sets are joined and the level of completeness is assessed using different extrinsic data quality measures. 
In our talk we will present our methodology along with the results of the completeness assessment for the City of Dresden, which is a pilot city of “meinGrün”, a project funded by the Federal Ministry of Transport and Digital Infrastructure (BMVI).

References:
Ali, A., Sirilertworakul, N., Zipf, A., Mobasheri, A., 2016. Guided classification system for conceptual overlapping classes in OpenStreetMap. ISPRS Int. J. Geo-Inf. 5, 87.
Barrington-Leigh, C., Millard-Ball, A., 2017. The world’s user-generated road map is more than 80% complete. PLOS ONE 12, e0180698. https://doi.org/10.1371/journal.pone.0180698
Bolund, P., Hunhammar, S., 1999. Ecosystem services in urban areas. Ecol. Econ. 29, 293–301. https://doi.org/10.1016/S0921-8009(99)00013-0
Hecht, R., Kunze, C., Hahmann, S., 2013. Measuring completeness of building footprints in OpenStreetMap over space a
Captions: 
	00:00:07,970 --> 00:00:11,030
okay so

00:00:11,470 --> 00:00:14,970
not least talk of the

00:00:15,020 --> 00:00:20,130
introduce yes Tina Ludwig which is a PhD

00:00:18,150 --> 00:00:22,380
student right here and that at the GI

00:00:20,130 --> 00:00:25,919
science research group in Heidelberg and

00:00:22,380 --> 00:00:29,599
she'll be talking about urban green

00:00:25,919 --> 00:00:34,739
spaces in OpenStreetMap so go ahead

00:00:29,599 --> 00:00:37,589
thank you I'm going to give you a little

00:00:34,739 --> 00:00:39,480
insight into urban green spaces in

00:00:37,589 --> 00:00:43,920
OpenStreetMap and the challenges that we

00:00:39,480 --> 00:00:45,600
faced when trying to assess them so

00:00:43,920 --> 00:00:47,730
first of all the question what is an

00:00:45,600 --> 00:00:50,789
urban green space if you take it

00:00:47,730 --> 00:00:52,859
literally it could be like a public park

00:00:50,789 --> 00:00:55,770
roadside greenery or like private

00:00:52,859 --> 00:00:57,420
gardens they're all important provide

00:00:55,770 --> 00:00:59,190
important ecosystem services like they

00:00:57,420 --> 00:01:02,430
have a cooling impact on the urban

00:00:59,190 --> 00:01:06,420
climate they provide habitat therefore

00:01:02,430 --> 00:01:09,720
increase the biodiversity our study were

00:01:06,420 --> 00:01:13,369
actually only focused on public green

00:01:09,720 --> 00:01:16,259
spaces because we're actually focused on

00:01:13,369 --> 00:01:18,330
because they provide recreational and

00:01:16,259 --> 00:01:20,580
cultural services to people living in

00:01:18,330 --> 00:01:24,179
cities okay so if you want to go place

00:01:20,580 --> 00:01:25,890
boards or meet friends they're an

00:01:24,179 --> 00:01:27,479
important factor for the quality of life

00:01:25,890 --> 00:01:30,739
so it's always good to know where is the

00:01:27,479 --> 00:01:33,030
next green space for you to go and

00:01:30,739 --> 00:01:37,039
that's where our project mangu

00:01:33,030 --> 00:01:40,110
he is focused on so we're trying to

00:01:37,039 --> 00:01:42,420
develop a recommendation system which

00:01:40,110 --> 00:01:45,330
will recommend you always like the best

00:01:42,420 --> 00:01:47,700
or most suitable green space nearby that

00:01:45,330 --> 00:01:51,179
will satisfy your needs and activities

00:01:47,700 --> 00:01:55,050
okay so if you want to have a quiet

00:01:51,179 --> 00:01:58,500
green space to read a book or a green

00:01:55,050 --> 00:02:02,789
space with a large grass surface to play

00:01:58,500 --> 00:02:04,140
soccer for example for this of course we

00:02:02,789 --> 00:02:08,580
need a lot of information about green

00:02:04,140 --> 00:02:11,670
spaces which is not available so far so

00:02:08,580 --> 00:02:15,030
we're using different like municipal

00:02:11,670 --> 00:02:17,760
data satellite imageries social media

00:02:15,030 --> 00:02:21,810
data and of course web data to derive

00:02:17,760 --> 00:02:23,459
these kinds of information and urban

00:02:21,810 --> 00:02:25,520
street map is a very rich data source

00:02:23,459 --> 00:02:27,860
but as we know

00:02:25,520 --> 00:02:29,150
before you use it you should know what

00:02:27,860 --> 00:02:34,250
you're actually working with and how

00:02:29,150 --> 00:02:37,550
reliable data is in in aspects so that's

00:02:34,250 --> 00:02:41,510
what we assessment which I'm going to

00:02:37,550 --> 00:02:44,870
present now in my green we actually have

00:02:41,510 --> 00:02:47,380
to study sites to pilot cities the title

00:02:44,870 --> 00:02:51,320
bag where we are right now and Dresden

00:02:47,380 --> 00:02:54,590
in this like talk today will focus on

00:02:51,320 --> 00:02:57,950
Dresden and we look at the study site

00:02:54,590 --> 00:03:01,310
which is in the center of Dresden

00:02:57,950 --> 00:03:04,370
actually okay so the first step when you

00:03:01,310 --> 00:03:06,410
want to assess anything is basically

00:03:04,370 --> 00:03:09,010
extracting the data and that's actually

00:03:06,410 --> 00:03:11,750
where the problems already start because

00:03:09,010 --> 00:03:13,400
they have been like studies about

00:03:11,750 --> 00:03:15,230
checking the completeness of highways or

00:03:13,400 --> 00:03:17,270
buildings and there's quite easy you

00:03:15,230 --> 00:03:19,430
just extract by all the features that

00:03:17,270 --> 00:03:23,750
contain like a building key or a highway

00:03:19,430 --> 00:03:25,550
key okay but for green spaces it's not

00:03:23,750 --> 00:03:27,290
that easy okay there's not just one key

00:03:25,550 --> 00:03:30,470
but there's like several keys which are

00:03:27,290 --> 00:03:33,620
relevant so for Heidelberg for example

00:03:30,470 --> 00:03:37,280
in the previous study we basically just

00:03:33,620 --> 00:03:40,790
manually compiled a list of relevant osm

00:03:37,280 --> 00:03:43,010
tags and if you use them you actually

00:03:40,790 --> 00:03:45,170
get a good representation of most green

00:03:43,010 --> 00:03:47,570
spaces in heidelberg so it's a good fit

00:03:45,170 --> 00:03:50,810
here and for example we will have land

00:03:47,570 --> 00:03:52,760
use cemetery for example which is a good

00:03:50,810 --> 00:03:54,860
fit in Germany because here cemeteries

00:03:52,760 --> 00:03:56,900
are always green and always vegetated

00:03:54,860 --> 00:03:59,060
but if you look at other countries for

00:03:56,900 --> 00:04:01,160
example in Israel Tel Aviv some

00:03:59,060 --> 00:04:04,490
cemeteries are almost never red to

00:04:01,160 --> 00:04:07,100
change it okay so we need to find

00:04:04,490 --> 00:04:10,600
methods how to find the relevant

00:04:07,100 --> 00:04:14,840
osm tags that actually mark green spaces

00:04:10,600 --> 00:04:18,560
so how can we do that we can compare the

00:04:14,840 --> 00:04:20,210
SMD basically to satellite imagery okay

00:04:18,560 --> 00:04:22,610
this on the right this was sent in a to

00:04:20,210 --> 00:04:27,230
image or it's actually a vegetation

00:04:22,610 --> 00:04:30,980
index derived from a 2018 satellite

00:04:27,230 --> 00:04:32,930
composite and just basically indicate a

00:04:30,980 --> 00:04:36,169
lot of vegetation low values no

00:04:32,930 --> 00:04:37,140
vegetation so what we do now is

00:04:36,169 --> 00:04:39,600
basically

00:04:37,140 --> 00:04:42,120
do a solo statistics okay so it will

00:04:39,600 --> 00:04:45,060
take like all the features that contain

00:04:42,120 --> 00:04:47,730
a certain tag land-use are grass and

00:04:45,060 --> 00:04:49,710
then we extract all the NDVI values that

00:04:47,730 --> 00:04:52,980
are located within features that have

00:04:49,710 --> 00:04:55,710
this tag we do this for like several

00:04:52,980 --> 00:05:02,670
hours M tags and we plot them on a

00:04:55,710 --> 00:05:06,210
histogram has the amenity parking tag

00:05:02,670 --> 00:05:08,430
will have like usually is associated DVI

00:05:06,210 --> 00:05:12,570
values okay because normally it's paved

00:05:08,430 --> 00:05:16,110
while features with the tag letter

00:05:12,570 --> 00:05:19,640
equals park usually are associated with

00:05:16,110 --> 00:05:22,590
high vegetation values and are vegetated

00:05:19,640 --> 00:05:25,530
so there's lots of text in OpenStreetMap

00:05:22,590 --> 00:05:28,080
so I would have to look at hundreds of

00:05:25,530 --> 00:05:31,110
histograms to find the relevant tags in

00:05:28,080 --> 00:05:33,060
order to speed this a bit up and

00:05:31,110 --> 00:05:35,750
basically deriving three values from

00:05:33,060 --> 00:05:37,830
each histogram basically just in

00:05:35,750 --> 00:05:40,950
increasing the size of the bins of the

00:05:37,830 --> 00:05:42,630
histogram so I'm using I'm counting

00:05:40,950 --> 00:05:45,540
basically all the NDVI values that are

00:05:42,630 --> 00:05:47,370
larger than 0.6 okay and that's basic

00:05:45,540 --> 00:05:49,860
all the pixels that are green that are

00:05:47,370 --> 00:05:53,340
vegetation then I count the pixels which

00:05:49,860 --> 00:05:56,100
are lower than 0.3 and also for sure

00:05:53,340 --> 00:05:58,110
paved everything I mean it's kind of

00:05:56,100 --> 00:06:00,060
uncertain okay those are usually mixed

00:05:58,110 --> 00:06:03,600
pixels where a country stays in

00:06:00,060 --> 00:06:05,940
vegetation or is it not and I do this I

00:06:03,600 --> 00:06:08,490
derived those three values for all the

00:06:05,940 --> 00:06:10,020
tags okay I can print them in like this

00:06:08,490 --> 00:06:14,220
form so this would be nature park

00:06:10,020 --> 00:06:17,690
basically has a 98% probability that it

00:06:14,220 --> 00:06:21,300
is vegetated and 11 percent uncertainty

00:06:17,690 --> 00:06:24,480
basically and if I do this for all the

00:06:21,300 --> 00:06:27,750
tags I have a get like the summary okay

00:06:24,480 --> 00:06:31,380
and I rank them by the probability for

00:06:27,750 --> 00:06:34,760
greenness or like vegetation and then I

00:06:31,380 --> 00:06:39,330
get basically those M tags that have the

00:06:34,760 --> 00:06:40,650
highest association with greenness so of

00:06:39,330 --> 00:06:41,850
course there's land use forests which is

00:06:40,650 --> 00:06:44,190
basically the best indicator and it

00:06:41,850 --> 00:06:47,390
always shows up land use grass metal

00:06:44,190 --> 00:06:51,000
parks or the ones that we actually also

00:06:47,390 --> 00:06:53,870
expect and there's one here like land

00:06:51,000 --> 00:06:56,610
use allotments and this basically yet

00:06:53,870 --> 00:06:58,920
some private gardens it's very common in

00:06:56,610 --> 00:07:01,080
Germany I'll show you later and this tag

00:06:58,920 --> 00:07:01,920
for example associated was like a very

00:07:01,080 --> 00:07:04,640
high uncertainty

00:07:01,920 --> 00:07:10,110
okay we'll see you later why that is

00:07:04,640 --> 00:07:12,030
just maybe remember this and so all of

00:07:10,110 --> 00:07:14,340
them as I said before were focused on

00:07:12,030 --> 00:07:15,780
public green spaces so I'm actually not

00:07:14,340 --> 00:07:17,970
really interested in land use

00:07:15,780 --> 00:07:19,590
residential and the reason where land

00:07:17,970 --> 00:07:21,420
residential is such a good is so

00:07:19,590 --> 00:07:22,950
associated with high vegetation values

00:07:21,420 --> 00:07:25,530
it's basically that Germans really like

00:07:22,950 --> 00:07:26,730
vegetated gardens but private gardens

00:07:25,530 --> 00:07:28,950
are usually not mapped in OpenStreetMap

00:07:26,730 --> 00:07:30,630
so all of those vegetation values

00:07:28,950 --> 00:07:34,410
basically are attributed to language

00:07:30,630 --> 00:07:37,140
residential so basically now I have a

00:07:34,410 --> 00:07:39,510
good list of relevant tags and their

00:07:37,140 --> 00:07:41,340
association actually with greenness and

00:07:39,510 --> 00:07:42,930
what we can see here it's also there's

00:07:41,340 --> 00:07:44,370
not really one cutoff value where I

00:07:42,930 --> 00:07:46,530
could say okay those are the tags that

00:07:44,370 --> 00:07:49,860
are relevant and these are not so it's

00:07:46,530 --> 00:07:53,000
best actually just to like keep working

00:07:49,860 --> 00:07:56,520
with those probability probabilities and

00:07:53,000 --> 00:07:58,740
yeah about the publicness becomes just

00:07:56,520 --> 00:08:03,150
like have one assumption could look at

00:07:58,740 --> 00:08:05,790
the X's tag which is provided in osm if

00:08:03,150 --> 00:08:08,280
it's XS yes it's public if it's XS no

00:08:05,790 --> 00:08:10,710
its private it's but it seldom be given

00:08:08,280 --> 00:08:11,970
actually so we basically assume that

00:08:10,710 --> 00:08:15,240
everything that's mapped in

00:08:11,970 --> 00:08:17,040
OpenStreetMap is public besides

00:08:15,240 --> 00:08:20,660
everything it has a key land use

00:08:17,040 --> 00:08:23,700
residential which would be private okay

00:08:20,660 --> 00:08:25,470
so now we basically have our relevant

00:08:23,700 --> 00:08:27,450
tags but now the problem is that in

00:08:25,470 --> 00:08:29,130
OpenStreetMap features are overlapping

00:08:27,450 --> 00:08:30,570
rights there's language also dental and

00:08:29,130 --> 00:08:33,930
then there's a buff there's a letter

00:08:30,570 --> 00:08:37,229
like letter Park for example so I need

00:08:33,930 --> 00:08:39,690
to kind of decide which one is the more

00:08:37,229 --> 00:08:41,550
important one that's of basically

00:08:39,690 --> 00:08:43,140
generating a mesh of polygons which

00:08:41,550 --> 00:08:47,280
actually where each polygon has like a

00:08:43,140 --> 00:08:49,320
homogeneous land-use type works like

00:08:47,280 --> 00:08:51,810
this so this is just an orthophoto of

00:08:49,320 --> 00:08:54,570
dresden at first we extract from

00:08:51,810 --> 00:08:57,020
OpenStreetMap all you know topographic

00:08:54,570 --> 00:08:59,130
elements like roads waterways railways

00:08:57,020 --> 00:09:02,270
we extract the

00:08:59,130 --> 00:09:07,350
most important ones the bigger ones and

00:09:02,270 --> 00:09:09,240
form city blocks okay then we buffer the

00:09:07,350 --> 00:09:13,290
roads and the railways to exclude like

00:09:09,240 --> 00:09:15,930
the traffic area and then we're using

00:09:13,290 --> 00:09:18,210
the additional osm object that contains

00:09:15,930 --> 00:09:20,490
some land-use information such as letter

00:09:18,210 --> 00:09:22,830
Park for example or land use residential

00:09:20,490 --> 00:09:27,240
and then we're forming like this

00:09:22,830 --> 00:09:29,310
hierarchy like basically feature which

00:09:27,240 --> 00:09:30,300
is smaller then another one has like a

00:09:29,310 --> 00:09:33,930
higher hierarchy

00:09:30,300 --> 00:09:36,330
okay so then do use so this for example

00:09:33,930 --> 00:09:39,570
if this was a land use park later Park

00:09:36,330 --> 00:09:41,970
and around this man use residential this

00:09:39,570 --> 00:09:43,920
would be attacked or as natural part

00:09:41,970 --> 00:09:45,210
while the surrounding area would be land

00:09:43,920 --> 00:09:48,750
use residential because of a lower

00:09:45,210 --> 00:09:50,130
priority in the end we also cut out like

00:09:48,750 --> 00:09:55,350
the buildings they're basically the top

00:09:50,130 --> 00:09:57,600
priority and we also like cut the city

00:09:55,350 --> 00:10:01,020
blocks again using like a path the

00:09:57,600 --> 00:10:02,850
pathways so now we have like this

00:10:01,020 --> 00:10:04,380
polygon mesh and we got like the

00:10:02,850 --> 00:10:07,080
relevant text and now we're finally

00:10:04,380 --> 00:10:09,570
ready to actually extract the green

00:10:07,080 --> 00:10:14,430
spaces and this is where you come up

00:10:09,570 --> 00:10:18,480
with our first yeah map of green space

00:10:14,430 --> 00:10:19,770
is extracted from osm on the right

00:10:18,480 --> 00:10:23,220
that's giving like it's the probability

00:10:19,770 --> 00:10:25,410
that a certain polygon is actually a

00:10:23,220 --> 00:10:30,000
public green space and this is basically

00:10:25,410 --> 00:10:33,540
derived from this basically ranking of

00:10:30,000 --> 00:10:34,740
all semtex with their probabilities so

00:10:33,540 --> 00:10:37,530
we can see like the bigger ones are

00:10:34,740 --> 00:10:39,300
given and the darker it is the more

00:10:37,530 --> 00:10:44,550
certain I am that it's actually really a

00:10:39,300 --> 00:10:45,960
green space so we got the data but now

00:10:44,550 --> 00:10:47,460
we need to know okay how good is it

00:10:45,960 --> 00:10:49,800
actually so the first thing you do is

00:10:47,460 --> 00:10:51,780
just compare it to an external data set

00:10:49,800 --> 00:10:55,140
okay we got miss musical data from

00:10:51,780 --> 00:10:57,930
Dresden where we extracted green spaces

00:10:55,140 --> 00:11:00,660
Park cemeteries playgrounds allotments

00:10:57,930 --> 00:11:03,680
and forests the ones that we actually

00:11:00,660 --> 00:11:06,600
find relevant for public green spaces

00:11:03,680 --> 00:11:08,880
and then we basically do like a basic

00:11:06,600 --> 00:11:10,380
intersect so all the red areas are

00:11:08,880 --> 00:11:14,940
actually things that would

00:11:10,380 --> 00:11:18,720
missing in OpenStreetMap remember I said

00:11:14,940 --> 00:11:20,520
before allotments have like this high

00:11:18,720 --> 00:11:23,010
degree of uncertainty attached to them

00:11:20,520 --> 00:11:24,990
when I compared from the NDVI so these

00:11:23,010 --> 00:11:26,610
ones are actually not extracted from osm

00:11:24,990 --> 00:11:29,010
okay because they don't have like a real

00:11:26,610 --> 00:11:30,690
clear association with greenness so

00:11:29,010 --> 00:11:32,970
that's why they are actually not in this

00:11:30,690 --> 00:11:34,410
map and so this is not a problem of

00:11:32,970 --> 00:11:36,480
awesome but that's basically a problem

00:11:34,410 --> 00:11:42,060
now if the methodology or we don't have

00:11:36,480 --> 00:11:44,460
enough evidence to actually derive it if

00:11:42,060 --> 00:11:47,280
we take them out or they actually

00:11:44,460 --> 00:11:48,540
there's another picture actually so this

00:11:47,280 --> 00:11:50,460
is basically how it looks so in the

00:11:48,540 --> 00:11:52,350
office treatment it's basically a map as

00:11:50,460 --> 00:11:53,880
land-use allotments but there's like all

00:11:52,350 --> 00:11:56,430
those little Hut's which are not mapped

00:11:53,880 --> 00:11:58,950
okay and in some cities in Karlsruhe has

00:11:56,430 --> 00:12:02,040
seen everyone they mapped it so this

00:11:58,950 --> 00:12:06,720
issue wouldn't be as big here but here

00:12:02,040 --> 00:12:09,810
it's not there so if we take them out

00:12:06,720 --> 00:12:12,960
they're still like a few left but some

00:12:09,810 --> 00:12:14,340
of them are really missing but a lot of

00:12:12,960 --> 00:12:16,020
them are also like other issues like

00:12:14,340 --> 00:12:18,930
Heroes M is actually more up to date

00:12:16,020 --> 00:12:20,520
than the municipal data set and there

00:12:18,930 --> 00:12:23,340
was a forest which was removed which was

00:12:20,520 --> 00:12:26,790
actually described to know SM but not

00:12:23,340 --> 00:12:29,550
updated in the municipal area and on

00:12:26,790 --> 00:12:31,620
there's also the problems with the

00:12:29,550 --> 00:12:33,750
definition of a green space okay so the

00:12:31,620 --> 00:12:36,330
red area is actually paved it's like a

00:12:33,750 --> 00:12:39,840
pedestrian zone tactus of justin zone

00:12:36,330 --> 00:12:41,400
and OpenStreetMap act but in a municipal

00:12:39,840 --> 00:12:43,350
data actually the whole thing is

00:12:41,400 --> 00:12:47,900
classified as a green space okay so

00:12:43,350 --> 00:12:50,610
awesome it's actually more has a higher

00:12:47,900 --> 00:12:52,920
degree of detail basically so it's not

00:12:50,610 --> 00:12:55,140
an arrow but it shows up as an arrow so

00:12:52,920 --> 00:12:56,850
we see that this is not really working

00:12:55,140 --> 00:12:58,440
because the definitions of a green space

00:12:56,850 --> 00:13:00,690
and the datasets are so different that I

00:12:58,440 --> 00:13:05,640
would have to check every feature which

00:13:00,690 --> 00:13:08,550
I'm not really willing to do so public

00:13:05,640 --> 00:13:11,160
green spaces are like fuzzy can't really

00:13:08,550 --> 00:13:16,600
do anything about it so extrinsic

00:13:11,160 --> 00:13:19,510
comparisons are not really suitable yeah

00:13:16,600 --> 00:13:21,940
so instead of this we were actually

00:13:19,510 --> 00:13:23,980
looking at are there like intrinsic ways

00:13:21,940 --> 00:13:28,110
of finding missing public green space

00:13:23,980 --> 00:13:28,110
notes and from the data itself and

00:13:29,190 --> 00:13:33,850
there's a great example actually within

00:13:32,170 --> 00:13:35,920
the study area so those are like

00:13:33,850 --> 00:13:38,680
basically four building blocks apartment

00:13:35,920 --> 00:13:41,710
buildings three of them seem to contain

00:13:38,680 --> 00:13:44,110
green spaces one of them doesn't also

00:13:41,710 --> 00:13:45,700
like their structure you know the size

00:13:44,110 --> 00:13:48,279
of the buildings there's a playground

00:13:45,700 --> 00:13:50,710
there's pathways all hint at the fact

00:13:48,279 --> 00:13:52,330
that it's actually a public space and

00:13:50,710 --> 00:13:54,310
when we compare it to a satellite image

00:13:52,330 --> 00:13:56,830
we also see that it's also vegetated

00:13:54,310 --> 00:13:59,589
okay so for some reason someone didn't

00:13:56,830 --> 00:14:03,960
take this explicitly as a green space so

00:13:59,589 --> 00:14:06,730
the idea was is it possible to find such

00:14:03,960 --> 00:14:10,960
area such missing green spaces just from

00:14:06,730 --> 00:14:14,980
the data itself so we're gathering ED

00:14:10,960 --> 00:14:16,870
evidence from Geographic context so

00:14:14,980 --> 00:14:19,290
we're looking for a dense path network

00:14:16,870 --> 00:14:21,910
would be an evidence for public access

00:14:19,290 --> 00:14:23,589
the presence of a Pui such as a

00:14:21,910 --> 00:14:26,610
playground and other evidence for

00:14:23,589 --> 00:14:28,990
publicness and a high vegetation index

00:14:26,610 --> 00:14:31,570
derived from the satellite data as shown

00:14:28,990 --> 00:14:36,400
before would be an evidence for

00:14:31,570 --> 00:14:38,709
greenness now the problem is that this

00:14:36,400 --> 00:14:40,990
is just evidence which has like higher

00:14:38,709 --> 00:14:45,040
degrees of uncertainty okay so for

00:14:40,990 --> 00:14:47,200
example with the play if there is no

00:14:45,040 --> 00:14:49,060
playground mapped in osm it could either

00:14:47,200 --> 00:14:51,640
be that there is no playground in

00:14:49,060 --> 00:14:54,190
reality or there is a playground it's

00:14:51,640 --> 00:14:57,130
just not mapped okay so I don't know

00:14:54,190 --> 00:14:59,470
what the case actually is and with a

00:14:57,130 --> 00:15:01,660
vegetation index as I've seen us set

00:14:59,470 --> 00:15:03,910
before like there's some mixed pixels

00:15:01,660 --> 00:15:06,250
which also have some kind of uncertainty

00:15:03,910 --> 00:15:09,790
where I can't really decide is it green

00:15:06,250 --> 00:15:12,790
or not so the idea was to use them to

00:15:09,790 --> 00:15:15,160
shape a theory of evidence to actually

00:15:12,790 --> 00:15:18,940
fuse these different sources of evidence

00:15:15,160 --> 00:15:23,290
and thereby explicitly considered answer

00:15:18,940 --> 00:15:25,030
okay so just a little introduction to

00:15:23,290 --> 00:15:29,020
the theory it's basically a framework

00:15:25,030 --> 00:15:31,810
for reasoning under uncertainty okay the

00:15:29,020 --> 00:15:34,240
evidence is converted to beliefs or they

00:15:31,810 --> 00:15:35,680
actually or masses and using belief

00:15:34,240 --> 00:15:39,040
functions so it's similar to

00:15:35,680 --> 00:15:41,380
probabilities but not quite that's why

00:15:39,040 --> 00:15:42,880
it has a different name and the

00:15:41,380 --> 00:15:45,490
difference is the probability theory is

00:15:42,880 --> 00:15:48,610
that beliefs can be a set about a set of

00:15:45,490 --> 00:15:52,240
events and not just single ones so for

00:15:48,610 --> 00:15:53,830
example you you're able to represent the

00:15:52,240 --> 00:15:55,360
state of total ignorance okay so

00:15:53,830 --> 00:15:59,140
probability theory if you have a coin

00:15:55,360 --> 00:16:01,150
and you don't know anything about it you

00:15:59,140 --> 00:16:03,910
would assume okay at a 50-50 shot its

00:16:01,150 --> 00:16:06,970
chance in terms of shape with you of

00:16:03,910 --> 00:16:10,030
evidence I would assign 0% to head zero

00:16:06,970 --> 00:16:12,250
to tails and one to heads or tails

00:16:10,030 --> 00:16:18,780
because I'm sure that one of them will

00:16:12,250 --> 00:16:21,910
actually happen so apply to our problem

00:16:18,780 --> 00:16:27,550
this could work like this okay so from

00:16:21,910 --> 00:16:30,310
those NDVI values I can derive like a

00:16:27,550 --> 00:16:32,980
mass function or mass for greenness

00:16:30,310 --> 00:16:37,390
repeat for example 3% for a Manitou

00:16:32,980 --> 00:16:39,220
parking 74% for gray and 23% is like the

00:16:37,390 --> 00:16:43,330
uncertainty it could be gray or green

00:16:39,220 --> 00:16:45,970
for playgrounds if there's no playground

00:16:43,330 --> 00:16:47,770
actually I have no idea because I don't

00:16:45,970 --> 00:16:49,630
know whether there is no playground or

00:16:47,770 --> 00:16:52,570
it wasn't mapped but if there is a

00:16:49,630 --> 00:16:55,780
playground I have some evidence that is

00:16:52,570 --> 00:17:01,000
public ok I'm not completely sure but I

00:16:55,780 --> 00:17:03,250
have more evidence for and with the past

00:17:01,000 --> 00:17:05,620
entity it's basically similar so the

00:17:03,250 --> 00:17:08,819
higher the path density the higher my

00:17:05,620 --> 00:17:14,790
belief that it's actually public

00:17:08,819 --> 00:17:19,390
so I'm fusing these evidences using the

00:17:14,790 --> 00:17:21,220
combination rule from them Shafer and I

00:17:19,390 --> 00:17:23,170
get the following map so on the left

00:17:21,220 --> 00:17:24,459
side that's basically the green spaces

00:17:23,170 --> 00:17:27,250
that I've dissected before that

00:17:24,459 --> 00:17:29,620
explicitly mapped and these are the ones

00:17:27,250 --> 00:17:31,900
that were detected from from the

00:17:29,620 --> 00:17:33,370
geographic context okay and you can also

00:17:31,900 --> 00:17:35,800
see this is the bit degree of belief

00:17:33,370 --> 00:17:38,140
that this is part of the class public

00:17:35,800 --> 00:17:40,690
green space and now we can see that this

00:17:38,140 --> 00:17:42,280
place actually shows up because we have

00:17:40,690 --> 00:17:45,340
the high density of put Meg and we have

00:17:42,280 --> 00:17:47,800
the plague and in addition to this

00:17:45,340 --> 00:17:49,930
actually other blocks also show up like

00:17:47,800 --> 00:17:52,240
this one also has a playground but other

00:17:49,930 --> 00:17:55,870
blocks which only have like single

00:17:52,240 --> 00:17:59,320
houses no playgrounds no no no path

00:17:55,870 --> 00:18:04,150
network will show up as private green

00:17:59,320 --> 00:18:07,720
spaces actually so apply to the whole

00:18:04,150 --> 00:18:09,880
area so that light blue one areas are

00:18:07,720 --> 00:18:11,860
the ones that are that we've extracted

00:18:09,880 --> 00:18:13,720
before that are explicitly in

00:18:11,860 --> 00:18:15,910
OpenStreetMap and now the other ones are

00:18:13,720 --> 00:18:18,940
basically the one the ones that we

00:18:15,910 --> 00:18:20,190
derived from geographic context and we

00:18:18,940 --> 00:18:23,560
can see that there's a lot of

00:18:20,190 --> 00:18:25,900
playgrounds in dresden and the OSM

00:18:23,560 --> 00:18:27,730
community is very very busy mapping all

00:18:25,900 --> 00:18:30,220
of them and those two paths network is a

00:18:27,730 --> 00:18:32,080
very high and completeness actually

00:18:30,220 --> 00:18:38,140
that's what what makes this method

00:18:32,080 --> 00:18:39,880
actually also work yeah so with this

00:18:38,140 --> 00:18:42,640
method we were able to like detect some

00:18:39,880 --> 00:18:45,610
of the the green spaces that were missed

00:18:42,640 --> 00:18:48,850
before but there's some some was also

00:18:45,610 --> 00:18:50,590
bit left and the good thing about them

00:18:48,850 --> 00:18:53,500
such a pair of stands the series also

00:18:50,590 --> 00:18:54,970
that and we can also get like an

00:18:53,500 --> 00:18:57,640
uncertainty measure of our final

00:18:54,970 --> 00:19:00,340
classification okay so as we've seen

00:18:57,640 --> 00:19:02,170
before like allotments I don't have I

00:19:00,340 --> 00:19:04,480
have not enough evidence from that so

00:19:02,170 --> 00:19:06,760
those areas actually they all show up

00:19:04,480 --> 00:19:08,740
with high uncertainties okay so they're

00:19:06,760 --> 00:19:10,480
not assigned like some random class that

00:19:08,740 --> 00:19:12,550
has the highest probability but they

00:19:10,480 --> 00:19:14,050
actually show up as I don't know what it

00:19:12,550 --> 00:19:15,550
actually is and then I can like also

00:19:14,050 --> 00:19:16,930
take a look at those areas and try to

00:19:15,550 --> 00:19:22,390
get more evidence from other data

00:19:16,930 --> 00:19:26,320
sources so to conclude we've seen that

00:19:22,390 --> 00:19:28,510
there are several and tags that indicate

00:19:26,320 --> 00:19:30,270
public green spaces and they all have

00:19:28,510 --> 00:19:32,680
like varying degrees of certainty

00:19:30,270 --> 00:19:35,200
there's not just like one set of them

00:19:32,680 --> 00:19:38,620
but it's varying and it's also varying

00:19:35,200 --> 00:19:39,720
with regions a quantitative comparison

00:19:38,620 --> 00:19:43,220
is not really

00:19:39,720 --> 00:19:47,429
because green spaces are fuzzy and

00:19:43,220 --> 00:19:51,330
definitions just vary greatly also in

00:19:47,429 --> 00:19:54,029
the data we've also seen that you can

00:19:51,330 --> 00:19:57,059
get some indicators for missing public

00:19:54,029 --> 00:20:01,169
green space from geographic context with

00:19:57,059 --> 00:20:05,039
still a simple prototype and the outlook

00:20:01,169 --> 00:20:06,299
would be to include additional aspects

00:20:05,039 --> 00:20:09,029
of geographic context now there's

00:20:06,299 --> 00:20:11,100
benches there's also the building

00:20:09,029 --> 00:20:14,760
geometries that could give you more more

00:20:11,100 --> 00:20:17,190
evidence for it and in this prototype I

00:20:14,760 --> 00:20:19,140
basically define the belief functions

00:20:17,190 --> 00:20:22,950
myself but actually this is like a

00:20:19,140 --> 00:20:24,960
classic problem where machine learning

00:20:22,950 --> 00:20:27,299
in data mining can actually also help to

00:20:24,960 --> 00:20:28,649
set up those rules in addition there's

00:20:27,299 --> 00:20:30,270
also machine learning methods that

00:20:28,649 --> 00:20:32,250
explicitly consider the uncertainty

00:20:30,270 --> 00:20:38,990
which would also be worth investigating

00:20:32,250 --> 00:20:38,990
for this so thank you for your attention

00:20:43,280 --> 00:20:51,960
Thank You Kristina for being perfectly

00:20:46,410 --> 00:21:05,670
on time and for a very deep analysis so

00:20:51,960 --> 00:21:07,890
questions should a few hi I was super

00:21:05,670 --> 00:21:10,170
interesting and really easy to follow

00:21:07,890 --> 00:21:14,460
along with some it's obviously really

00:21:10,170 --> 00:21:17,100
complex I'm so good job um I had a

00:21:14,460 --> 00:21:20,280
question regarding if there's any kind

00:21:17,100 --> 00:21:23,070
of opportunities for you to do some sort

00:21:20,280 --> 00:21:24,570
of field based validation of like the

00:21:23,070 --> 00:21:27,690
comparison between areas where you have

00:21:24,570 --> 00:21:30,030
high and low uncertainty to maybe

00:21:27,690 --> 00:21:33,060
identify like a threshold of everything

00:21:30,030 --> 00:21:35,610
above 60% for example certainty is

00:21:33,060 --> 00:21:46,440
actually green space to kind of confirm

00:21:35,610 --> 00:21:48,210
or maybe further classify the data just

00:21:46,440 --> 00:21:50,070
a very difficult question I guess you're

00:21:48,210 --> 00:21:54,360
having maybe additional ground truth

00:21:50,070 --> 00:21:55,830
data I mean because at some point also

00:21:54,360 --> 00:21:57,900
for the recommendations we have to make

00:21:55,830 --> 00:22:01,680
a decision basically what do we include

00:21:57,900 --> 00:22:04,170
and what do we exclude we haven't in

00:22:01,680 --> 00:22:06,120
this analysis we haven't included like

00:22:04,170 --> 00:22:08,790
the municipal data which is also maybe

00:22:06,120 --> 00:22:12,170
gives like some evidence of what - which

00:22:08,790 --> 00:22:15,900
green space is actually then to include

00:22:12,170 --> 00:22:19,470
but yeah that's definitely a thing of

00:22:15,900 --> 00:22:26,340
very subjective thing than to set those

00:22:19,470 --> 00:22:30,990
thresholds in the end probably yeah okay

00:22:26,340 --> 00:22:34,050
so I'll take the liberty so I think that

00:22:30,990 --> 00:22:36,870
using the dump of Scheffer theory is a

00:22:34,050 --> 00:22:41,010
really neat idea but the limitation is

00:22:36,870 --> 00:22:43,230
that you have to define what makes you

00:22:41,010 --> 00:22:47,330
believe that somewhere some places is a

00:22:43,230 --> 00:22:50,460
green space and that would make it

00:22:47,330 --> 00:22:52,050
culturally dependent so you it you

00:22:50,460 --> 00:22:55,170
wouldn't be able to generalize that I

00:22:52,050 --> 00:22:56,380
was thinking maybe you can look every

00:22:55,170 --> 00:23:00,309
far about looking

00:22:56,380 --> 00:23:02,380
to the history of osm and see whether

00:23:00,309 --> 00:23:07,049
there are contextual stuff that later

00:23:02,380 --> 00:23:07,049
became green spaces and used that as

00:23:08,160 --> 00:23:13,299
interesting I mean yeah that's what was

00:23:11,799 --> 00:23:15,730
the idea about using machine learning

00:23:13,299 --> 00:23:18,460
data man actually to to mine those rules

00:23:15,730 --> 00:23:20,770
not just to define them but actually see

00:23:18,460 --> 00:23:23,020
also regionally differently okay which

00:23:20,770 --> 00:23:24,610
geographic context variable variables

00:23:23,020 --> 00:23:27,250
actually hint at the fact that that's a

00:23:24,610 --> 00:23:29,440
green space and a good thing is like I

00:23:27,250 --> 00:23:31,809
think in every city almost there are

00:23:29,440 --> 00:23:33,760
some green spaces already mapped and

00:23:31,809 --> 00:23:36,330
then you could use those basically as

00:23:33,760 --> 00:23:38,470
training data together maybe the

00:23:36,330 --> 00:23:41,320
geographic context variables that are

00:23:38,470 --> 00:23:43,780
relevant and it's definitely also data

00:23:41,320 --> 00:23:46,960
quality issue this thing only works

00:23:43,780 --> 00:23:48,850
interesting because there is like a lot

00:23:46,960 --> 00:23:51,159
of playgrounds are mapped and the past

00:23:48,850 --> 00:23:53,169
are map so I would definitely do this

00:23:51,159 --> 00:23:56,250
analysis then at different points in

00:23:53,169 --> 00:23:59,350
time maybe five years ago four years ago

00:23:56,250 --> 00:24:02,620
and then see whether like at what point

00:23:59,350 --> 00:24:04,600
it actually works and maybe also if the

00:24:02,620 --> 00:24:06,010
the context variable said the relevant

00:24:04,600 --> 00:24:10,330
also changed so that's there that's

00:24:06,010 --> 00:24:11,340
actually an interesting thing okay thank

00:24:10,330 --> 00:24:15,540
you

00:24:11,340 --> 00:24:18,599
so yeah

00:24:15,540 --> 00:24:18,599
[Music]

00:24:20,460 --> 00:24:27,610
thank you very much one of the previous

00:24:23,580 --> 00:24:30,159
publications about the Mancunian project

00:24:27,610 --> 00:24:33,009
was about korean routing if I recall

00:24:30,159 --> 00:24:35,399
correctly which was aiming at suggesting

00:24:33,009 --> 00:24:39,460
routes based on OpenStreetMap data which

00:24:35,399 --> 00:24:40,899
went along over recreational areas do

00:24:39,460 --> 00:24:44,710
you think or is it even planned to

00:24:40,899 --> 00:24:48,820
combine the this presentation with the

00:24:44,710 --> 00:24:58,899
routing to deal with the uncertainty in

00:24:48,820 --> 00:25:01,029
the routing process proof like the

00:24:58,899 --> 00:25:03,519
databases so also to include satellite

00:25:01,029 --> 00:25:16,330
imagery and other possibility to also

00:25:03,519 --> 00:25:18,039
would be - will be probably the public

00:25:16,330 --> 00:25:20,470
or private aspect will not be as

00:25:18,039 --> 00:25:22,210
important for that but I guess that's

00:25:20,470 --> 00:25:24,279
also maybe going to be something that we

00:25:22,210 --> 00:25:26,590
have to evaluate with both people

00:25:24,279 --> 00:25:31,750
testing the routing then if that makes a

00:25:26,590 --> 00:25:33,100
difference or not - question you started

00:25:31,750 --> 00:25:35,500
with saying that it was for an

00:25:33,100 --> 00:25:38,070
application for finding green spaces for

00:25:35,500 --> 00:25:41,039
particular purposes can you derive

00:25:38,070 --> 00:25:42,850
suitability for those purposes

00:25:41,039 --> 00:25:45,220
automatically with any degree of

00:25:42,850 --> 00:25:47,139
certainty like whether somewhere else

00:25:45,220 --> 00:25:47,679
might be to be peaceful or suitable for

00:25:47,139 --> 00:25:50,980
games

00:25:47,679 --> 00:25:54,990
yeah like OpenStreetMap is not our only

00:25:50,980 --> 00:25:57,220
source of information about that is

00:25:54,990 --> 00:26:00,759
often also derived from social media

00:25:57,220 --> 00:26:02,710
data because people post tweets about

00:26:00,759 --> 00:26:05,740
that so it's a great place to play

00:26:02,710 --> 00:26:12,039
soccer or something we combine it also

00:26:05,740 --> 00:26:13,809
so in in regard to quiet places by like

00:26:12,039 --> 00:26:16,779
noise measurements from the city or

00:26:13,809 --> 00:26:18,549
noise maps to derive this information so

00:26:16,779 --> 00:26:20,409
yeah we try to get as much as

00:26:18,549 --> 00:26:21,909
information from our same as possible

00:26:20,409 --> 00:26:24,070
like this like they are from the PIO

00:26:21,909 --> 00:26:26,380
eyes

00:26:24,070 --> 00:26:32,410
it's definitely going to be a big data

00:26:26,380 --> 00:26:34,510
integration task okay so I would thank

00:26:32,410 --> 00:26:36,400
you once again and to all the

00:26:34,510 --> 00:26:39,040
participants of the session of the

00:26:36,400 --> 00:26:42,150
academic track which was really great

00:26:39,040 --> 00:26:42,150
yeah thank you

00:26:44,080 --> 00:26:49,140

YouTube URL: https://www.youtube.com/watch?v=znE3LmdrihM


