Title: 2019: Data Quality and Feature Extraction at scale with RoboSat.pink
Publication date: 2020-07-18
Playlist: State of the Map 2019
Description: 
	How to use plain OpenData and Imagery, to train, an accurate Deep Learning model, able to detect inconsistencies in OSM dataset, to spot it and to extract features.
And make it works at scale, with OpenSource solution, named: RoboSat.pink.

Deep Learning approaches already proves that they can be helpful for QA or MissingMap areas.

RoboSat.pink as an efficient OpenSource Deep Learning toolbox dedicated to GeoSpatial Imagery, can definitely help to quickly compare two datasets, as OSM and a coverage Imagery, and do it at scale.

And spot where differences are significant enough, to value, that a human give them a look.

This talk will focus on:
- How to create an accurate trained model, for buildings and roads detection, from plain OpenData, without the needs to spend to much for hand-labeling features.

- How to generate predictions faster, to lower the IT hardware footprint as much as we can.

Point here, is to allow that anyone with a recent gamer video card, already can play with this tools.

For information, RoboSat.pink main characteristics:
- Provides several command line tools, you can combine together to build your own workflow
- Follows geospatial standards to ease interoperability and data preparation
- OSM data loader (using PyOsmium)
- Build-in cutting edge Computer Vision model and loss implementations (and allows to replace by your owns)
- Support either RGB or multibands imagery (as multispectral)
- Allows Data Fusion
- Rich and efficient Data Augmentation abilities (using Albumentations)
- Static Web-UI tools to easily display, hilight or select results
- High performances

Olivier Courtin

https://pretalx.com/sotm2019/talk/7ZXRXB/
Captions: 
	00:00:34,910 --> 00:00:40,650
yeah you should be so very in fact two

00:00:37,860 --> 00:00:43,310
goals a first is to be able to detect

00:00:40,650 --> 00:00:48,420
inconsistency between two data set and

00:00:43,310 --> 00:00:51,870
the other goal is the ability to train a

00:00:48,420 --> 00:00:56,130
model on a small area and then to

00:00:51,870 --> 00:00:58,710
predict on a larger one so in fact there

00:00:56,130 --> 00:01:05,430
is two goals and you can use one or the

00:00:58,710 --> 00:01:07,790
other I will maybe just wait for one one

00:01:05,430 --> 00:01:12,780
single minutes to let them come

00:01:07,790 --> 00:01:15,180
so the first goal is um with a detector

00:01:12,780 --> 00:01:17,100
inconsistency is the ability with an

00:01:15,180 --> 00:01:20,790
imagery and with something else to

00:01:17,100 --> 00:01:24,119
support if there is inconsistency tile

00:01:20,790 --> 00:01:27,780
by tile between the two and the other

00:01:24,119 --> 00:01:30,540
one you train a model on a small area

00:01:27,780 --> 00:01:34,800
with accurate levels and on the model is

00:01:30,540 --> 00:01:38,790
train it on a wide area with similar

00:01:34,800 --> 00:01:41,159
imagery and landscape and you predict at

00:01:38,790 --> 00:01:45,140
scaler that's the two kind of thing we

00:01:41,159 --> 00:01:49,200
can achieve with this kind of tool and I

00:01:45,140 --> 00:01:52,590
I go on so what kind of solution do you

00:01:49,200 --> 00:01:54,900
use we use robust at that pink it's a

00:01:52,590 --> 00:01:58,860
computer vision framework dedicated to

00:01:54,900 --> 00:02:02,820
your special imagery and his aim is to

00:01:58,860 --> 00:02:05,159
perform three kind of feature data

00:02:02,820 --> 00:02:07,489
quality analysis chin detection and

00:02:05,159 --> 00:02:11,519
feature attraction

00:02:07,489 --> 00:02:13,200
now one thing things matter things

00:02:11,519 --> 00:02:15,870
matter because there is in fact to

00:02:13,200 --> 00:02:19,650
project robust at and robust at that

00:02:15,870 --> 00:02:22,470
pink if you want to have any further

00:02:19,650 --> 00:02:25,140
information about the why and how and

00:02:22,470 --> 00:02:29,940
and so on there is a link with the

00:02:25,140 --> 00:02:34,170
description or later to add to that how

00:02:29,940 --> 00:02:35,880
does it work in in concept first you

00:02:34,170 --> 00:02:38,850
have to train a model is supervised

00:02:35,880 --> 00:02:41,669
model supervised training so here your

00:02:38,850 --> 00:02:44,950
model have to be trained with labelled

00:02:41,669 --> 00:02:47,590
from an imagery and it's trained we

00:02:44,950 --> 00:02:49,959
a loss function dedicated to extract

00:02:47,590 --> 00:02:52,120
meaningful information from the

00:02:49,959 --> 00:02:54,940
difference between these two data set

00:02:52,120 --> 00:02:59,470
so once you've trained this model enough

00:02:54,940 --> 00:03:04,720
you can only use your imagine more doll

00:02:59,470 --> 00:03:06,640
and predict something related to the

00:03:04,720 --> 00:03:08,110
kind of labelled you train your model

00:03:06,640 --> 00:03:10,060
Luiza so if you train with building

00:03:08,110 --> 00:03:12,569
you've got buildings if you train with

00:03:10,060 --> 00:03:16,150
forest you've got forests and so on and

00:03:12,569 --> 00:03:17,530
the point here is also to compare your

00:03:16,150 --> 00:03:19,209
prediction with something else and

00:03:17,530 --> 00:03:21,849
something else could be for instance

00:03:19,209 --> 00:03:26,019
open switch map vector data or something

00:03:21,849 --> 00:03:30,010
else and I think you go you've got to

00:03:26,019 --> 00:03:31,569
design these this process you're able to

00:03:30,010 --> 00:03:33,400
train a model and to compare with a

00:03:31,569 --> 00:03:36,069
little data set

00:03:33,400 --> 00:03:40,090
what kind of imagery are we able to

00:03:36,069 --> 00:03:44,650
under raster coverage a web service ism

00:03:40,090 --> 00:03:46,989
in input and related to to vector it

00:03:44,650 --> 00:03:51,160
could be or semi put a birth Posey is

00:03:46,989 --> 00:03:53,260
the reason so the only point is to be to

00:03:51,160 --> 00:03:57,970
have an imagery readable by G doll and

00:03:53,260 --> 00:04:00,190
reference and here a vector that sits as

00:03:57,970 --> 00:04:03,609
since you've got that in input you are

00:04:00,190 --> 00:04:06,579
able to train your model and to generate

00:04:03,609 --> 00:04:08,739
mass prediction and once you've got mass

00:04:06,579 --> 00:04:13,030
prediction you're able to compare them

00:04:08,739 --> 00:04:16,229
to specify the differences area and so

00:04:13,030 --> 00:04:21,639
to extract a vector off from your mask

00:04:16,229 --> 00:04:24,850
so that you will process what kind of

00:04:21,639 --> 00:04:29,550
information can we a spot and in the

00:04:24,850 --> 00:04:35,169
output here we configure the mask to be

00:04:29,550 --> 00:04:37,990
in pink and so automatically the Lebel

00:04:35,169 --> 00:04:41,039
will be configure to be in green because

00:04:37,990 --> 00:04:43,120
it's the complementary color so if you

00:04:41,039 --> 00:04:47,590
superpose pink and green

00:04:43,120 --> 00:04:49,930
it became gray so here it's pink it's

00:04:47,590 --> 00:04:54,280
mean that only the model detects

00:04:49,930 --> 00:04:56,710
something it's only here in green it

00:04:54,280 --> 00:04:58,740
means that only the information is

00:04:56,710 --> 00:05:01,919
provided by the ball

00:04:58,740 --> 00:05:04,500
and yes because it's been is a tree so

00:05:01,919 --> 00:05:07,110
the oil information can convey any

00:05:04,500 --> 00:05:10,259
meaningful information about that and if

00:05:07,110 --> 00:05:16,259
it's in gray it means that both agree

00:05:10,259 --> 00:05:21,470
and so mask and prediction sorry masking

00:05:16,259 --> 00:05:27,120
levels are agree you shall be none time

00:05:21,470 --> 00:05:30,690
so how does it works it works on by a

00:05:27,120 --> 00:05:33,300
small common lines so you don't have the

00:05:30,690 --> 00:05:35,940
need to program in Python if you want

00:05:33,300 --> 00:05:38,120
you can but it's not mandatory and you

00:05:35,940 --> 00:05:41,580
can launch it only with small

00:05:38,120 --> 00:05:43,800
command-line tools somehow it's a bit

00:05:41,580 --> 00:05:45,479
like gee doll if you already use

00:05:43,800 --> 00:05:48,120
something like gee doll on the command

00:05:45,479 --> 00:05:50,460
line it's really the same kind of small

00:05:48,120 --> 00:05:54,530
tools you can chain together to pick

00:05:50,460 --> 00:05:54,530
only the ones you need for the decade

00:05:54,710 --> 00:06:02,699
process oh can we play with them there

00:05:59,400 --> 00:06:06,469
is a tutorial one one and with each

00:06:02,699 --> 00:06:09,509
tutorial you can in only 3-4 hours

00:06:06,469 --> 00:06:12,030
launch all the step with an imagery a

00:06:09,509 --> 00:06:17,490
training and prediction and compare so

00:06:12,030 --> 00:06:20,820
if we look up online on the 101 what we

00:06:17,490 --> 00:06:22,469
do here and we configure as well sir so

00:06:20,820 --> 00:06:25,740
it's only few lines of configuration

00:06:22,469 --> 00:06:29,990
file we retrieve an imagery is the one

00:06:25,740 --> 00:06:31,500
in Tanzania was been built up by drone

00:06:29,990 --> 00:06:35,280
last year

00:06:31,500 --> 00:06:38,880
we tell the all the three from the

00:06:35,280 --> 00:06:42,330
imagery on this area and also on this

00:06:38,880 --> 00:06:47,310
also area is provided by the imagery and

00:06:42,330 --> 00:06:51,840
so here it's some tiles at the zoom

00:06:47,310 --> 00:06:54,120
volume it's some 11 with Retina tiles so

00:06:51,840 --> 00:06:57,030
it's means that it's double size ax and

00:06:54,120 --> 00:07:00,690
tile them it's really slow above the

00:06:57,030 --> 00:07:01,889
connection so maybe I have to go in

00:07:00,690 --> 00:07:07,730
another place where it's already

00:07:01,889 --> 00:07:10,950
uncashed yep yeah so

00:07:07,730 --> 00:07:15,030
the imagery once we've got the imagery

00:07:10,950 --> 00:07:18,660
retriever Jersey label and we process

00:07:15,030 --> 00:07:21,960
them with only one wincing a line to

00:07:18,660 --> 00:07:26,030
grab syllables once we don't that we can

00:07:21,960 --> 00:07:31,680
create a data set train the model and

00:07:26,030 --> 00:07:37,470
the raster predict retrieve new imagery

00:07:31,680 --> 00:07:40,740
from another place tile it again royal

00:07:37,470 --> 00:07:44,970
trees official OpenStreetMap data on

00:07:40,740 --> 00:07:48,030
this new area and we create the

00:07:44,970 --> 00:07:50,270
prediction from the Train model and so

00:07:48,030 --> 00:07:54,630
on we done that we can thereafter

00:07:50,270 --> 00:07:56,610
comparables so by comparing the boss we

00:07:54,630 --> 00:08:00,419
can have something will look like that

00:07:56,610 --> 00:08:03,780
and on all the places where we launched

00:08:00,419 --> 00:08:06,150
the prediction on the new imagery and

00:08:03,780 --> 00:08:08,250
with the official opens with map data we

00:08:06,150 --> 00:08:12,390
can Spotify the differences between the

00:08:08,250 --> 00:08:13,980
two and each time you've got here a pink

00:08:12,390 --> 00:08:16,590
square it means that there is a

00:08:13,980 --> 00:08:18,840
meaningful differences between the two

00:08:16,590 --> 00:08:20,790
data set the one who came from the trend

00:08:18,840 --> 00:08:23,010
model and the one who came from the

00:08:20,790 --> 00:08:27,419
official OpenStreetMap data and you just

00:08:23,010 --> 00:08:31,820
have to zoom on the place where there is

00:08:27,419 --> 00:08:35,700
pink square and you get this kind of

00:08:31,820 --> 00:08:37,770
prediction and because it's only in pink

00:08:35,700 --> 00:08:39,419
it means that it's not present on the

00:08:37,770 --> 00:08:42,780
official open signal data at this moment

00:08:39,419 --> 00:08:44,730
it couldn't it could be because there is

00:08:42,780 --> 00:08:48,089
no feature or because they are not

00:08:44,730 --> 00:08:51,660
labeled as building so sometimes they

00:08:48,089 --> 00:08:56,010
are really on on the data set but not

00:08:51,660 --> 00:09:00,150
rightly flagged on the attributes apart

00:08:56,010 --> 00:09:05,990
so it's really a time-saver a tool to

00:09:00,150 --> 00:09:08,670
help to Spotify and to pick up only the

00:09:05,990 --> 00:09:11,339
places where there is inconsistency and

00:09:08,670 --> 00:09:15,230
don't you don't have the need to zoom

00:09:11,339 --> 00:09:19,260
and to care about other kind of data

00:09:15,230 --> 00:09:21,180
okay so it's easy to deploy it's just a

00:09:19,260 --> 00:09:23,120
single line peep tree in solve

00:09:21,180 --> 00:09:25,770
that pink and everything come with it

00:09:23,120 --> 00:09:31,440
that's it

00:09:25,770 --> 00:09:32,940
so all you need is imagery GPU few

00:09:31,440 --> 00:09:35,880
skills and labels

00:09:32,940 --> 00:09:40,470
so as imagery anything readable by G

00:09:35,880 --> 00:09:45,150
doll as a GPU at least eight jjigae ram

00:09:40,470 --> 00:09:48,900
from nvidia and it works in Colaba as

00:09:45,150 --> 00:09:52,080
initial skill at released geospatial

00:09:48,900 --> 00:09:56,790
data and command-line fluency that's all

00:09:52,080 --> 00:10:04,890
and and or but the key pointer is Allah

00:09:56,790 --> 00:10:10,350
bells because the reason lack of open

00:10:04,890 --> 00:10:15,210
data set available and the reason

00:10:10,350 --> 00:10:18,420
several initiative to list them to list

00:10:15,210 --> 00:10:21,540
all the open data set or lately to show

00:10:18,420 --> 00:10:25,140
special but because the labels is a very

00:10:21,540 --> 00:10:28,170
expensive task we are lack of accurate

00:10:25,140 --> 00:10:31,610
enough lubbers why is that because here

00:10:28,170 --> 00:10:35,460
it's an aerial imagery so if you took

00:10:31,610 --> 00:10:35,910
OpenStreetMap footprints it's a good

00:10:35,460 --> 00:10:39,720
start

00:10:35,910 --> 00:10:42,060
it will perform some some good results

00:10:39,720 --> 00:10:45,300
but it will be really different if its

00:10:42,060 --> 00:10:48,390
roof prints because it's a early madri

00:10:45,300 --> 00:10:50,790
and shoe pixel could make such a

00:10:48,390 --> 00:10:53,970
difference at the end so it's not

00:10:50,790 --> 00:10:57,360
because you have already all the feature

00:10:53,970 --> 00:10:59,970
labelled though that it will be a good

00:10:57,360 --> 00:11:05,190
enough a training data set if you want

00:10:59,970 --> 00:11:07,260
really i a curate quality so using this

00:11:05,190 --> 00:11:09,390
is enough for they take a change

00:11:07,260 --> 00:11:12,120
addiction but it's not enough if you

00:11:09,390 --> 00:11:16,380
want to directly extract the feature in

00:11:12,120 --> 00:11:18,450
one path the key concept is garbage in

00:11:16,380 --> 00:11:21,230
garbage out if you have local data

00:11:18,450 --> 00:11:25,710
labels in input you will have locality

00:11:21,230 --> 00:11:27,990
mask prediction in output what could be

00:11:25,710 --> 00:11:30,810
an idle open data set

00:11:27,990 --> 00:11:34,200
it will be open the term compliance it

00:11:30,810 --> 00:11:35,820
will convey a lot of landscape from

00:11:34,200 --> 00:11:40,050
worldwide

00:11:35,820 --> 00:11:43,860
being big resolution tile and mixed

00:11:40,050 --> 00:11:46,019
bands resolution and sensory Madri and

00:11:43,860 --> 00:11:48,269
obviously convey several kind of level

00:11:46,019 --> 00:11:51,690
building rows vegetation and so on with

00:11:48,269 --> 00:11:55,350
pixel accuracy I insist on that if you

00:11:51,690 --> 00:11:58,560
have a line related to two Road it's not

00:11:55,350 --> 00:12:01,620
enough you we must have the surface of

00:11:58,560 --> 00:12:09,389
the road to be able to perform well with

00:12:01,620 --> 00:12:12,360
this kind of approach last year there is

00:12:09,389 --> 00:12:14,310
talk about that in Milan and notice if

00:12:12,360 --> 00:12:17,639
you can progress has been made on this

00:12:14,310 --> 00:12:21,839
release forum topics in the last year so

00:12:17,639 --> 00:12:24,690
today there is a discussion at three

00:12:21,839 --> 00:12:29,100
o'clock in a cleaner also so if you are

00:12:24,690 --> 00:12:32,339
interested in all we can create an idle

00:12:29,100 --> 00:12:36,360
open data set or at least to increment

00:12:32,339 --> 00:12:39,000
to improve the open data set stuff with

00:12:36,360 --> 00:12:44,069
an open street map initiative thanks to

00:12:39,000 --> 00:12:47,370
come right now what can we do if we

00:12:44,069 --> 00:12:51,329
don't if we don't have an idle open data

00:12:47,370 --> 00:12:54,480
set we can do it in two in two paths so

00:12:51,329 --> 00:12:58,500
there is another tutorial help you to

00:12:54,480 --> 00:13:01,199
create a better data set even if the

00:12:58,500 --> 00:13:04,500
first one is not perfect so what when

00:13:01,199 --> 00:13:07,560
what do we do we retrieve an imagery

00:13:04,500 --> 00:13:09,779
from an open data it's a city in France

00:13:07,560 --> 00:13:12,990
it's called young and we retreat from

00:13:09,779 --> 00:13:17,209
the official city Metropole as the

00:13:12,990 --> 00:13:22,410
imagery we retrieve also the official

00:13:17,209 --> 00:13:25,560
roof prints attributes from from the

00:13:22,410 --> 00:13:28,260
city we create and training data set we

00:13:25,560 --> 00:13:31,829
train it we prayed predict and then we

00:13:28,260 --> 00:13:33,569
compare and that is interesting in the

00:13:31,829 --> 00:13:36,930
compare that there is a lot of places

00:13:33,569 --> 00:13:40,139
where here you can spot that there is an

00:13:36,930 --> 00:13:43,130
inconsistency and it looked like the

00:13:40,139 --> 00:13:46,709
other is missing maps in the official

00:13:43,130 --> 00:13:48,090
open that from from the city so what

00:13:46,709 --> 00:13:52,230
will we do

00:13:48,090 --> 00:13:54,870
isn't to retrieve them only the ones

00:13:52,230 --> 00:13:58,050
where there is a significant difference

00:13:54,870 --> 00:14:01,560
and it's something like 10% of the wool

00:13:58,050 --> 00:14:05,400
time data set and create with the small

00:14:01,560 --> 00:14:07,350
tool a way to compare them and when it's

00:14:05,400 --> 00:14:09,570
something related to the model because

00:14:07,350 --> 00:14:12,300
we train it only with few a box so

00:14:09,570 --> 00:14:15,510
really quickly we keep it when when it's

00:14:12,300 --> 00:14:18,270
related to a missing maps in the

00:14:15,510 --> 00:14:21,630
official data we select it to be able to

00:14:18,270 --> 00:14:25,680
remove these tiles from the training

00:14:21,630 --> 00:14:28,830
data set for further training and we can

00:14:25,680 --> 00:14:33,990
do it really quickly so because we

00:14:28,830 --> 00:14:37,290
reduce the amount of tile to check by a

00:14:33,990 --> 00:14:40,770
factor 10 and because this tool allow

00:14:37,290 --> 00:14:44,820
you to really made a quick decision so

00:14:40,770 --> 00:14:47,010
at the end we just copy the tool we

00:14:44,820 --> 00:14:50,280
select to the clipboard and that's it

00:14:47,010 --> 00:14:53,220
so it helped us to really quickly made a

00:14:50,280 --> 00:14:58,380
good decision to extract the only kind

00:14:53,220 --> 00:15:01,740
of the only kind of tile we want and so

00:14:58,380 --> 00:15:07,800
to improve as you data set to train and

00:15:01,740 --> 00:15:09,840
so at the end with a pure open data data

00:15:07,800 --> 00:15:12,110
set we can improve it and get better

00:15:09,840 --> 00:15:18,150
results as an official open data set

00:15:12,110 --> 00:15:23,040
convey so the rubber setting is also

00:15:18,150 --> 00:15:25,320
interesting because it's its use on set

00:15:23,040 --> 00:15:28,170
of thought computer vision loss function

00:15:25,320 --> 00:15:30,930
there is the tankmen tation and it's

00:15:28,170 --> 00:15:34,140
also something you can extend by design

00:15:30,930 --> 00:15:35,640
so it's a plugin mechanism so if for

00:15:34,140 --> 00:15:40,290
example if you want to change the matrix

00:15:35,640 --> 00:15:46,490
change model you can plug it and that's

00:15:40,290 --> 00:15:46,490
it the stack is a designer about foss4g

00:15:46,880 --> 00:15:54,350
stack they're ism computer vision and

00:15:50,340 --> 00:15:56,790
deep learning component it's open source

00:15:54,350 --> 00:15:59,970
and because it's open so there is a

00:15:56,790 --> 00:16:01,150
several subjects we already identified

00:15:59,970 --> 00:16:03,370
to be

00:16:01,150 --> 00:16:06,130
improver so if you want to participate

00:16:03,370 --> 00:16:10,779
you're very welcome to send a pull

00:16:06,130 --> 00:16:13,870
request or to found some some subject if

00:16:10,779 --> 00:16:18,160
you want to make it improve again as a

00:16:13,870 --> 00:16:22,150
performance metrics so one megapixel is

00:16:18,160 --> 00:16:24,700
related to 16 tiles or forward in a tile

00:16:22,150 --> 00:16:26,860
and there is here some metrics related

00:16:24,700 --> 00:16:32,550
to the performances we can already

00:16:26,860 --> 00:16:35,410
achieve on here a low cost GPU server

00:16:32,550 --> 00:16:38,290
it's Kayla so if you want to train it

00:16:35,410 --> 00:16:40,210
faster you just have to add more GPU if

00:16:38,290 --> 00:16:42,850
you want to tile it faster you had to

00:16:40,210 --> 00:16:46,180
add more CPU and if you want to predict

00:16:42,850 --> 00:16:49,120
faster you can use an external dedicate

00:16:46,180 --> 00:16:53,490
insurance high-performance system big

00:16:49,120 --> 00:16:57,820
and export the model in an annex format

00:16:53,490 --> 00:17:00,580
Oh to use that with a cost-effective

00:16:57,820 --> 00:17:03,929
approach if you want your own server it

00:17:00,580 --> 00:17:07,900
could be used only by GPU and CPU

00:17:03,929 --> 00:17:10,449
cost-effective approach with something

00:17:07,900 --> 00:17:13,720
not that expensive and if you want to

00:17:10,449 --> 00:17:15,309
use it on a cloud you can also so it's

00:17:13,720 --> 00:17:19,709
something for the wall

00:17:15,309 --> 00:17:23,890
even with cost-effective approach and

00:17:19,709 --> 00:17:27,640
the Y performance matter because for

00:17:23,890 --> 00:17:30,340
yourself when it's something you going

00:17:27,640 --> 00:17:33,730
fast you can learn you can change some

00:17:30,340 --> 00:17:35,650
parameters and learn from your last

00:17:33,730 --> 00:17:38,500
experience and improve it

00:17:35,650 --> 00:17:41,260
obviously it's time and will saver and

00:17:38,500 --> 00:17:46,420
also its save computation time and so

00:17:41,260 --> 00:17:49,780
help to reduce the carbon cost of the

00:17:46,420 --> 00:17:52,990
wool stuff so while using the planning

00:17:49,780 --> 00:17:55,090
for mapping so it's an easy to specify a

00:17:52,990 --> 00:17:57,700
scale inconsistency between two data

00:17:55,090 --> 00:18:01,590
sets and if you provide good labels on

00:17:57,700 --> 00:18:06,760
imagery you can infer on the last scale

00:18:01,590 --> 00:18:10,810
similar new imagery why using your

00:18:06,760 --> 00:18:12,670
beside pink because there is a quite an

00:18:10,810 --> 00:18:14,460
integration with all the OpenStreetMap

00:18:12,670 --> 00:18:17,610
and ecosystem

00:18:14,460 --> 00:18:19,619
what ue i show you is integrated with

00:18:17,610 --> 00:18:20,059
all the command so you had nothing to do

00:18:19,619 --> 00:18:22,409
anymore

00:18:20,059 --> 00:18:26,309
it's a performance Siri it's easy to

00:18:22,409 --> 00:18:29,279
deploy compliant to the standard it call

00:18:26,309 --> 00:18:32,190
also on the multi bands imagery and the

00:18:29,279 --> 00:18:35,159
diffusion saturate it's accessible by

00:18:32,190 --> 00:18:39,629
design and support source it's provided

00:18:35,159 --> 00:18:41,580
by data pink and as a takeaway message

00:18:39,629 --> 00:18:43,830
it says that you already have an

00:18:41,580 --> 00:18:46,799
industrial solution to perform such a

00:18:43,830 --> 00:18:49,740
thing the performance that's already ok

00:18:46,799 --> 00:18:54,269
to use it for for instance a region a

00:18:49,740 --> 00:18:56,970
small country even on shootin on a GPU

00:18:54,269 --> 00:18:59,909
server and it's scale obviously if you

00:18:56,970 --> 00:19:02,970
provide better adware so you can use it

00:18:59,909 --> 00:19:05,789
on something bigger if you provide the

00:19:02,970 --> 00:19:07,679
right infrastructure there is no need

00:19:05,789 --> 00:19:11,399
anymore to be a computer vision expect

00:19:07,679 --> 00:19:15,360
to play with you only have to to be able

00:19:11,399 --> 00:19:18,629
to to understand your data and what you

00:19:15,360 --> 00:19:21,090
want to achieve with plain open data can

00:19:18,629 --> 00:19:26,369
be used to train a model even if it's a

00:19:21,090 --> 00:19:29,610
bit longer and what will be a game

00:19:26,369 --> 00:19:31,289
changer I said it again it's will the

00:19:29,610 --> 00:19:34,019
ability to have a pixel accurate level

00:19:31,289 --> 00:19:36,869
in training up a data set that will

00:19:34,019 --> 00:19:40,519
change everything so for those we are

00:19:36,869 --> 00:19:42,900
interested in there is a decision a tree

00:19:40,519 --> 00:19:49,600
thanks

00:19:42,900 --> 00:19:52,610
[Applause]

00:19:49,600 --> 00:19:56,090
thanks Oliver for an enlightening

00:19:52,610 --> 00:19:58,460
session if everyone anybody else needs

00:19:56,090 --> 00:20:00,800
to talk to him feather I think he will

00:19:58,460 --> 00:20:03,950
be in the foyer in their breakout

00:20:00,800 --> 00:20:08,350
sessions now I think we'll can take a

00:20:03,950 --> 00:20:08,350
few questions just for five minutes okay

00:20:30,740 --> 00:20:37,460
what about transfer learning are there

00:20:32,990 --> 00:20:40,190
any pre-trained models available this

00:20:37,460 --> 00:20:42,440
some about the medulla it's a unit like

00:20:40,190 --> 00:20:45,440
who is a resident 50 as an encoder and

00:20:42,440 --> 00:20:48,169
by default it's already trained on

00:20:45,440 --> 00:20:51,710
imaginet so by default it's already a

00:20:48,169 --> 00:20:54,799
fine tuning system you can buy on the

00:20:51,710 --> 00:20:57,890
configuration file choose to suppress

00:20:54,799 --> 00:21:01,429
the freight train stuff and train it

00:20:57,890 --> 00:21:03,260
from scratch if you want so it's it's

00:21:01,429 --> 00:21:06,380
open and if you want to bring your own

00:21:03,260 --> 00:21:08,990
model I said it's extensible by design

00:21:06,380 --> 00:21:12,080
so you just put your own model in the

00:21:08,990 --> 00:21:13,970
model directory and call it by his name

00:21:12,080 --> 00:21:18,500
from the configuration file and that's

00:21:13,970 --> 00:21:25,490
it so you have a total you can do what

00:21:18,500 --> 00:21:27,500
you want about this point yeah so I

00:21:25,490 --> 00:21:29,470
understand that it's pixel wise

00:21:27,500 --> 00:21:33,440
projections but do you do anything with

00:21:29,470 --> 00:21:36,350
node data with sorry ID enter of the

00:21:33,440 --> 00:21:41,240
node so single points as opposed to

00:21:36,350 --> 00:21:42,830
outlines well a building could be

00:21:41,240 --> 00:21:45,559
labeled as an outline or it could be

00:21:42,830 --> 00:21:49,279
labeled as a single oh yeah in fact Iran

00:21:45,559 --> 00:21:51,289
we classify each pixel yes so each pixel

00:21:49,279 --> 00:21:53,120
it will be in fact for instance a

00:21:51,289 --> 00:21:56,870
building or buildings or it could be a

00:21:53,120 --> 00:21:58,610
forest no forest and so on so if what

00:21:56,870 --> 00:22:02,260
you have in your labelled is only single

00:21:58,610 --> 00:22:05,390
dots it will be really odd to make it

00:22:02,260 --> 00:22:10,429
understand what you what you want so it

00:22:05,390 --> 00:22:14,899
will really be something walk already

00:22:10,429 --> 00:22:17,600
with surface so with with polygons with

00:22:14,899 --> 00:22:20,690
Leonia it will be other because the

00:22:17,600 --> 00:22:22,549
topology itself means ax and so it will

00:22:20,690 --> 00:22:28,340
be really other if it's only single

00:22:22,549 --> 00:22:30,470
lines and with dots it it's not it will

00:22:28,340 --> 00:22:33,940
be even other because it's on these

00:22:30,470 --> 00:22:33,940
small dots on the other ground

00:22:47,920 --> 00:22:56,540
hi great work great work open-source

00:22:53,240 --> 00:22:58,340
models I love them I want to I like the

00:22:56,540 --> 00:23:00,350
idea of having a tool to assess the

00:22:58,340 --> 00:23:05,300
quality of the label of the labeling in

00:23:00,350 --> 00:23:08,380
the training set but I was thinking why

00:23:05,300 --> 00:23:11,180
can't you already automate the

00:23:08,380 --> 00:23:12,260
classification of the ties as good as if

00:23:11,180 --> 00:23:14,570
they're good or not

00:23:12,260 --> 00:23:15,800
because I mean if as the examples we

00:23:14,570 --> 00:23:16,940
were showing they were pretty obvious

00:23:15,800 --> 00:23:19,220
there was a prediction

00:23:16,940 --> 00:23:20,990
I know label on top of it so you can

00:23:19,220 --> 00:23:25,310
already discard that automatically and

00:23:20,990 --> 00:23:27,580
in fact the point is if you will look to

00:23:25,310 --> 00:23:29,780
all the labels where there is a

00:23:27,580 --> 00:23:31,100
inconsistency at first it could be

00:23:29,780 --> 00:23:33,710
either because there is a lack of the

00:23:31,100 --> 00:23:38,270
labels or it could be because the model

00:23:33,710 --> 00:23:41,860
is not able at this point to classify it

00:23:38,270 --> 00:23:46,280
well for instance something a bit tricky

00:23:41,860 --> 00:23:48,980
didn't seen it enough and if you train

00:23:46,280 --> 00:23:52,940
it only on shoe a box at this moment is

00:23:48,980 --> 00:23:53,450
not already in a am able to classify it

00:23:52,940 --> 00:23:58,070
well

00:23:53,450 --> 00:24:01,820
so it is the reason because human will

00:23:58,070 --> 00:24:03,980
make a better decision but we won't

00:24:01,820 --> 00:24:07,100
bother a human to make a decision on the

00:24:03,980 --> 00:24:12,440
whole data set but only on the few where

00:24:07,100 --> 00:24:14,840
there is doubt so the approach say what

00:24:12,440 --> 00:24:16,820
was recalled then in because I mean you

00:24:14,840 --> 00:24:18,740
can say you look at recall so you can

00:24:16,820 --> 00:24:20,540
look at many buildings you lose on

00:24:18,740 --> 00:24:21,800
average per image so you you have you

00:24:20,540 --> 00:24:24,080
can have an idea of how much you're

00:24:21,800 --> 00:24:27,740
losing you know what I mean in fact on

00:24:24,080 --> 00:24:31,880
this one I have um a 20k a tiled I have

00:24:27,740 --> 00:24:37,660
only to check on 2000 and I remove

00:24:31,880 --> 00:24:37,660
something like 500 yeah on this example

00:24:40,649 --> 00:24:46,090
okay thanks everybody

00:24:43,090 --> 00:24:46,749
we I think our session is has come to an

00:24:46,090 --> 00:24:49,029
end

00:24:46,749 --> 00:24:51,509
it's time to prepare for the next

00:24:49,029 --> 00:24:51,509
session

00:24:51,800 --> 00:24:54,980
[Applause]

00:24:57,159 --> 00:24:59,220

YouTube URL: https://www.youtube.com/watch?v=fhCRg9fUvTY


