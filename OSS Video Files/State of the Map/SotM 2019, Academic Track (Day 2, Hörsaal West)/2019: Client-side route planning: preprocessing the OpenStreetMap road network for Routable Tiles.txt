Title: 2019: Client-side route planning: preprocessing the OpenStreetMap road network for Routable Tiles
Publication date: 2019-09-28
Playlist: SotM 2019, Academic Track (Day 2, HÃ¶rsaal West)
Description: 
	Travelers have high expectations of their route planners. We explore how preprocessing techniques applied to Linked Open Data derived from OSM (Routable Tiles) can provide a satisfying performance for client-side route planning.

Travelers have higher expectations than current route planning providers can fulfill, yet new solutions struggle to break through. Matching user experience from existing applications is already challenging without the large-scale infrastructure most of them have at their disposal; additionally integrating datasets such as the road network, public transportation schedules, or even real time air quality data is an even more laborious endeavour. 
W3C and OGC mention the usage of Linked Open Data as a best practice for publishing interoperable geospatial datasets. Instead of relying on proprietary data formats or monolithic CSV files, Linked Open Data uses the RDF data model as a framework for existing domain models. Every data element, and even the relations between them, receives a Uniform Resource Identifier (URI). Data publishers can reuse these identifiers to unambiguously refer to resources on the Web, thus making individual data sets more interoperable. The ultimate goal being automated integration, giving even clients the power to execute the queries. Client-side querying differs from traditional approaches but provides some advantages: (i) it takes the load off the service provider, (ii) the data can be cached for subsequent queries, and (iii) the user leaks less personal data.

The OSM road network has recently been published as routable Linked Open Data, following a similar approach to vector tiles (http://pieter.pm/demo-paper-routable-tiles/). However, executing route planning queries on the client is still an unsolved problem. Long-distance queries require large amounts of data and downloading all the data takes a long time. It also makes caching less effective because caches have a fixed capacity, and writing to a full cache will evict other data. Moreover, even when all the data ingredients are there, processing them may still take a long time. State-of-the-art route planning algorithms achieve better query execution times by using auxiliary data that has been computed in a preprocessing phase. The biggest bottleneck in client-side querying is bandwidth; downloading more data to improve query times will ultimately make querying even slower. Client-side route planning requires a different approach to match the quality of service of existing services.

We explore several ways of preprocessing the tiles to improve the user-perceived performance of query evaluation. As a first step, we compute how to efficiently traverse pedestrian areas. Only the boundary edges of these areas are defined in OSM which means that most routing engines route along these edges, yielding suboptimal paths. Secondly, we identify which nodes and ways are actually needed to cross an individual tile, filtering out the elements that are only used for local traffic. Queries only need the full tiles around the departure and arrival locations. Finally, a hierarchical network graph is computed using an adaptation of the contraction hierarchies algorithm. Each step yields a different view of the tile data and the results are published as Linked Open Data, in accordance with the W3C and OGC best practices.

We integrated the results into a route planner for public transportation. The road network is used to route to and from public transport stops. We found that short-distance one-to-many queries such as getting to the closest nearby station that initially took around 400 ms to complete only take around 260 ms now, and the first results are presented after 140 ms. The difference becomes bigger over long distances; queries that used to take minutes to complete can now be answered in seconds. More importantly, downloading and querying the road network is no longer the main bottleneck. The majority of the querying time is currently spent on parsing the data files, which seems like a tooling issue that should resolve itself as the linked data ecosystem matures.

Harm Delva

https://pretalx.com/sotm2019-at/talk/GRJC7W/
Captions: 
	00:00:07,830 --> 00:00:13,470
I'm then this is Hiram and we're here to

00:00:10,890 --> 00:00:16,970
present new hot route

00:00:13,470 --> 00:00:20,520
and that we hope will interest you all

00:00:16,970 --> 00:00:22,290
so i'm ben i part of Oak Street Map

00:00:20,520 --> 00:00:25,410
Belgium also part of the humanitarian

00:00:22,290 --> 00:00:28,590
sweet nap team but I'm also part of the

00:00:25,410 --> 00:00:30,869
open planner team and that team is a

00:00:28,590 --> 00:00:33,090
public is a partnership between some

00:00:30,869 --> 00:00:35,610
private companies among which anyways my

00:00:33,090 --> 00:00:39,180
company and the University of Kent where

00:00:35,610 --> 00:00:41,190
Hiram works so I will be presenting the

00:00:39,180 --> 00:00:45,239
first part of this presentation how to

00:00:41,190 --> 00:00:47,610
move to the second part so what is this

00:00:45,239 --> 00:00:50,250
about so if most route buyers out there

00:00:47,610 --> 00:00:53,370
do the same work over and over and over

00:00:50,250 --> 00:00:55,110
again so you have it's it's not the open

00:00:53,370 --> 00:00:56,940
source project in itself but even all of

00:00:55,110 --> 00:00:59,310
the route planning instances out there

00:00:56,940 --> 00:01:02,610
pre-process the same data over and over

00:00:59,310 --> 00:01:05,759
again the same the same road network the

00:01:02,610 --> 00:01:08,100
same public transport schedules all over

00:01:05,759 --> 00:01:09,720
all over every time again so does it

00:01:08,100 --> 00:01:11,759
make sense to share the result yeah we

00:01:09,720 --> 00:01:14,189
think of course yes otherwise you

00:01:11,759 --> 00:01:18,060
wouldn't be here so I will explain a

00:01:14,189 --> 00:01:20,850
little bit but linked data and and how

00:01:18,060 --> 00:01:24,780
we published the OpenStreetMap network

00:01:20,850 --> 00:01:27,720
in a new way and then Adam will present

00:01:24,780 --> 00:01:29,790
the actual work that was done in the

00:01:27,720 --> 00:01:32,670
second part where the interesting stuff

00:01:29,790 --> 00:01:35,100
is happening so basically linked

00:01:32,670 --> 00:01:36,600
geospatial data so I think in the

00:01:35,100 --> 00:01:38,970
OpenStreetMap community we don't really

00:01:36,600 --> 00:01:42,030
think about this way of publishing the

00:01:38,970 --> 00:01:44,820
open network and I think we should think

00:01:42,030 --> 00:01:46,409
about this a little bit more it makes

00:01:44,820 --> 00:01:48,780
sense to publish data like this

00:01:46,409 --> 00:01:50,640
basically generate the URI for

00:01:48,780 --> 00:01:55,799
everything link all the things together

00:01:50,640 --> 00:01:58,320
is great so we should do this so what

00:01:55,799 --> 00:02:00,960
did we actually do so we we made linked

00:01:58,320 --> 00:02:03,840
data fragments for the OPA street nut

00:02:00,960 --> 00:02:07,140
plant so what does this mean so you have

00:02:03,840 --> 00:02:09,179
on the left side or is it on the left

00:02:07,140 --> 00:02:11,580
side you have dated them so this

00:02:09,179 --> 00:02:14,790
basically means you publish the whole

00:02:11,580 --> 00:02:17,069
data set in one in one go you compare

00:02:14,790 --> 00:02:21,030
this to the planet file you have the

00:02:17,069 --> 00:02:24,150
planet osm file or on the right you have

00:02:21,030 --> 00:02:26,040
a service that that you can query you

00:02:24,150 --> 00:02:26,550
don't publish any data you just ask the

00:02:26,040 --> 00:02:29,520
server

00:02:26,550 --> 00:02:35,280
for information compare this to overpass

00:02:29,520 --> 00:02:38,460
or something like that so what did we do

00:02:35,280 --> 00:02:40,460
just open Sweden up ass link data

00:02:38,460 --> 00:02:43,670
fragments so if we use the tiling system

00:02:40,460 --> 00:02:46,830
we made a decent ontology for the tags

00:02:43,670 --> 00:02:49,550
we figured out how to publish this and

00:02:46,830 --> 00:02:52,680
make it like for the whole planet it was

00:02:49,550 --> 00:02:56,100
pretty challenging in itself and we

00:02:52,680 --> 00:02:59,190
publish this as json-ld data currently

00:02:56,100 --> 00:03:01,800
we don't update this live but the idea

00:02:59,190 --> 00:03:06,420
is to keep updating this data along with

00:03:01,800 --> 00:03:10,170
OS M live stream changes so why are we

00:03:06,420 --> 00:03:12,450
doing this basically on the left you see

00:03:10,170 --> 00:03:14,730
classic route planning service so you

00:03:12,450 --> 00:03:17,220
see the little red thingy there means

00:03:14,730 --> 00:03:19,140
the server is doing a lot of work so all

00:03:17,220 --> 00:03:20,970
the clients asking routes asking routes

00:03:19,140 --> 00:03:22,920
and the only one doing work is the

00:03:20,970 --> 00:03:26,190
server so you want to share the load

00:03:22,920 --> 00:03:28,110
between server and client so basically

00:03:26,190 --> 00:03:30,180
what we have done now is reduce the

00:03:28,110 --> 00:03:32,340
server to just the service publishing

00:03:30,180 --> 00:03:35,070
data and the clients will do the route

00:03:32,340 --> 00:03:37,620
planning so there are a few trade-offs I

00:03:35,070 --> 00:03:40,590
think arm will also discuss this shortly

00:03:37,620 --> 00:03:43,230
I don't know but one of them is for

00:03:40,590 --> 00:03:45,959
example privacy the server will never

00:03:43,230 --> 00:03:50,430
know origin and destination it will only

00:03:45,959 --> 00:03:52,709
know what area you download it also it

00:03:50,430 --> 00:03:54,510
gets the client can configure routing

00:03:52,709 --> 00:03:58,850
profiles for example so the routing

00:03:54,510 --> 00:04:02,430
profile is very possibly very dynamic

00:03:58,850 --> 00:04:07,260
yeah so can we do this yes we can but

00:04:02,430 --> 00:04:09,060
currently it's slow of course if you if

00:04:07,260 --> 00:04:11,190
you know about route planning and you

00:04:09,060 --> 00:04:13,620
hear about this idea the first thing you

00:04:11,190 --> 00:04:14,360
do is think well this is crazy it will

00:04:13,620 --> 00:04:16,890
never work

00:04:14,360 --> 00:04:20,459
but Tyron will show you in a second that

00:04:16,890 --> 00:04:24,600
it is possible currently it also

00:04:20,459 --> 00:04:26,190
downloads a lot of data so yeah so hiram

00:04:24,600 --> 00:04:31,160
is going to talk about this in the next

00:04:26,190 --> 00:04:36,700
steps so yeah go Adam

00:04:31,160 --> 00:04:39,710
this work and let's capture the person

00:04:36,700 --> 00:04:41,390
okay so are we gonna try to do is gonna

00:04:39,710 --> 00:04:43,460
add some pre-processing to the reachable

00:04:41,390 --> 00:04:44,770
piles so that you're not already working

00:04:43,460 --> 00:04:46,910
on the raw data you're going to add some

00:04:44,770 --> 00:04:48,860
there are pre commutations to make it

00:04:46,910 --> 00:04:52,790
easier for the clients to ingest the the

00:04:48,860 --> 00:04:55,010
yeah to ingest the data so going back to

00:04:52,790 --> 00:04:56,630
the spectrum we saw earlier gonna move a

00:04:55,010 --> 00:04:58,340
bit further away from the data dumps a

00:04:56,630 --> 00:05:00,500
bit closer to the full-fledged route

00:04:58,340 --> 00:05:03,490
planning service but in sensually we're

00:05:00,500 --> 00:05:06,080
still gonna publish data and the ideas

00:05:03,490 --> 00:05:07,370
most route planners do something similar

00:05:06,080 --> 00:05:10,760
right no suite plans already do a

00:05:07,370 --> 00:05:14,450
pre-processing step to make the query

00:05:10,760 --> 00:05:17,990
time performance way better so yeah why

00:05:14,450 --> 00:05:20,780
should we make sense of course so what

00:05:17,990 --> 00:05:22,990
are the first things we did we noticed

00:05:20,780 --> 00:05:27,020
at pedestrian areas are pretty hard to

00:05:22,990 --> 00:05:31,130
use yeah in general usually these are

00:05:27,020 --> 00:05:32,860
defined as polygon areas basically only

00:05:31,130 --> 00:05:34,730
the edges are defines an open street map

00:05:32,860 --> 00:05:36,200
which is fine because you know that

00:05:34,730 --> 00:05:37,910
information is there but just the rich

00:05:36,200 --> 00:05:40,700
man is pretty hard to actually use that

00:05:37,910 --> 00:05:42,080
information so what we try to do is

00:05:40,700 --> 00:05:45,380
materialize information that's already

00:05:42,080 --> 00:05:46,670
in there and yeah the idea is very

00:05:45,380 --> 00:05:48,410
simple so basically we just create like

00:05:46,670 --> 00:05:50,360
a visibility graph inside of a polygon

00:05:48,410 --> 00:05:52,070
I'm just gonna generate all the edges

00:05:50,360 --> 00:05:54,590
the light on the interior of the polygon

00:05:52,070 --> 00:05:56,030
it's basically this defines that you can

00:05:54,590 --> 00:05:57,920
walk from this edge to this edge without

00:05:56,030 --> 00:06:00,680
leaving the polygon so basically that's

00:05:57,920 --> 00:06:03,280
what a pedestrian areas and that's how

00:06:00,680 --> 00:06:05,360
you get the image up top which you

00:06:03,280 --> 00:06:07,280
barely see the lines anymore they're so

00:06:05,360 --> 00:06:08,600
many lines is just a yellow glow but

00:06:07,280 --> 00:06:10,540
there's so much data if you would

00:06:08,600 --> 00:06:13,280
publish this and then become even slowly

00:06:10,540 --> 00:06:16,150
so of course you have to work around

00:06:13,280 --> 00:06:18,770
this and then the solution is pretty

00:06:16,150 --> 00:06:20,810
simple or straightforward it would be

00:06:18,770 --> 00:06:23,180
basically do a lot of one-to-many dextra

00:06:20,810 --> 00:06:25,520
queries in the area around it we

00:06:23,180 --> 00:06:28,370
basically see yeah well others tells us

00:06:25,520 --> 00:06:31,490
is at which of those yellows edges are

00:06:28,370 --> 00:06:32,960
actually used by route planner so this

00:06:31,490 --> 00:06:36,020
is it's probably a bit of a brute force

00:06:32,960 --> 00:06:39,430
approach but that actually works because

00:06:36,020 --> 00:06:43,520
yes literally how a grid panel works

00:06:39,430 --> 00:06:45,440
and as reasonable as this is we are

00:06:43,520 --> 00:06:48,230
definitely not the first to try this and

00:06:45,440 --> 00:06:50,120
this is why we are second slide loss a

00:06:48,230 --> 00:06:54,350
lot of us are doing the same P

00:06:50,120 --> 00:06:55,790
computations over and over again and it

00:06:54,350 --> 00:06:57,410
seems strange because we're all handling

00:06:55,790 --> 00:06:59,960
the same data and the same way to do the

00:06:57,410 --> 00:07:02,630
same thing and so this is an example

00:06:59,960 --> 00:07:04,700
from the open play planet I think it's

00:07:02,630 --> 00:07:05,990
at least from what I can tell the only

00:07:04,700 --> 00:07:08,660
autoroute pattern that does the same

00:07:05,990 --> 00:07:11,570
thing as I just explained but they do it

00:07:08,660 --> 00:07:14,710
way better for all it's worth and also

00:07:11,570 --> 00:07:17,390
put a lot more work in it but it was

00:07:14,710 --> 00:07:18,950
what I'm getting at is that like a

00:07:17,390 --> 00:07:20,480
second column is like the comments they

00:07:18,950 --> 00:07:23,030
have on there their configuration page

00:07:20,480 --> 00:07:25,520
and they say like these calculations can

00:07:23,030 --> 00:07:26,810
be time-consuming so why do we keep

00:07:25,520 --> 00:07:28,190
repeating the same stuff over and over

00:07:26,810 --> 00:07:30,200
again right you could if you can just

00:07:28,190 --> 00:07:32,990
publish the results or the

00:07:30,200 --> 00:07:35,590
pre-processing everyone can just ingest

00:07:32,990 --> 00:07:37,820
the results and then everyone is happier

00:07:35,590 --> 00:07:40,580
that's just an aside it will get back to

00:07:37,820 --> 00:07:42,170
this eventually continue in with our own

00:07:40,580 --> 00:07:44,690
pre-processing to make your own stuff

00:07:42,170 --> 00:07:46,400
faster for now we also noticed something

00:07:44,690 --> 00:07:49,430
else that if you just download your all

00:07:46,400 --> 00:07:51,050
data you're basically downloading way

00:07:49,430 --> 00:07:54,050
too much data which makes sense of

00:07:51,050 --> 00:07:55,790
course because has if you'd only known

00:07:54,050 --> 00:07:56,810
as the data you need back to the roots

00:07:55,790 --> 00:08:01,340
near the proof fledged

00:07:56,810 --> 00:08:03,860
witch panic service but essentially if

00:08:01,340 --> 00:08:06,830
you're trying to land a 100 kilometer

00:08:03,860 --> 00:08:08,660
journey you're probably not interested

00:08:06,830 --> 00:08:10,460
and all the dead-end streets in the

00:08:08,660 --> 00:08:11,990
middle of your journey because why would

00:08:10,460 --> 00:08:14,750
you go there it's a dead end

00:08:11,990 --> 00:08:17,750
and so we apply the same principle to

00:08:14,750 --> 00:08:19,600
the original tiles we basically notice

00:08:17,750 --> 00:08:22,160
that if you if you don't have to be and

00:08:19,600 --> 00:08:23,750
one specific tile that is just a pile

00:08:22,160 --> 00:08:24,980
you're passing through not really

00:08:23,750 --> 00:08:26,480
interested in all the data that's in

00:08:24,980 --> 00:08:28,730
there you're only interested in then and

00:08:26,480 --> 00:08:30,650
what ways do I need to get for one point

00:08:28,730 --> 00:08:34,310
or for one edge of the tile to the other

00:08:30,650 --> 00:08:35,840
edge of the tile so yeah same principle

00:08:34,310 --> 00:08:37,520
as the pedestrian areas a lot of

00:08:35,840 --> 00:08:38,870
one-to-many takes our queries from one

00:08:37,520 --> 00:08:41,240
edge of the tile to another and

00:08:38,870 --> 00:08:43,130
eventually we see which ways are

00:08:41,240 --> 00:08:45,170
actually needed and I will publish those

00:08:43,130 --> 00:08:48,350
separately is like a derived version of

00:08:45,170 --> 00:08:50,990
the writable tiles and this is an

00:08:48,350 --> 00:08:52,580
example of downtown Center event where

00:08:50,990 --> 00:08:54,560
because he all the red stuff is being

00:08:52,580 --> 00:08:56,840
discarded and the red stuff here in the

00:08:54,560 --> 00:08:57,410
here in the middle is the zoom for

00:08:56,840 --> 00:08:59,270
example

00:08:57,410 --> 00:09:03,140
that's why would you need to do data if

00:08:59,270 --> 00:09:05,530
you just drive in your car so this is

00:09:03,140 --> 00:09:08,690
pretty cool and it reduces the effective

00:09:05,530 --> 00:09:11,420
file size by about 40 percent that's

00:09:08,690 --> 00:09:14,260
already a great start but the cool thing

00:09:11,420 --> 00:09:18,590
is if this works yes perfect

00:09:14,260 --> 00:09:20,510
so the fragments sensed the data similar

00:09:18,590 --> 00:09:22,430
to all all the OpenStreetMap data

00:09:20,510 --> 00:09:24,740
basically you have the X Y Z style

00:09:22,430 --> 00:09:26,660
system so we have zoom levels of course

00:09:24,740 --> 00:09:28,490
and the higher the zoom level is the

00:09:26,660 --> 00:09:30,800
board is from the more effective this

00:09:28,490 --> 00:09:35,840
the reduction becomes for example this

00:09:30,800 --> 00:09:37,070
is the area around you in France this is

00:09:35,840 --> 00:09:38,720
pretty significant

00:09:37,070 --> 00:09:41,480
please large area pretty densely

00:09:38,720 --> 00:09:44,660
populated up so it's 570 square

00:09:41,480 --> 00:09:47,480
kilometers which is the size of lumps

00:09:44,660 --> 00:09:51,710
zoom level 10 tile in that area and

00:09:47,480 --> 00:09:54,770
basically if he try to express in the

00:09:51,710 --> 00:09:58,040
same region using zoom level 11 transit

00:09:54,770 --> 00:09:59,510
styles we need 7.1 megabytes of

00:09:58,040 --> 00:10:01,160
uncompressed data this was already

00:09:59,510 --> 00:10:03,140
pretty decent right because it's already

00:10:01,160 --> 00:10:05,720
transits viral so it's already reduced

00:10:03,140 --> 00:10:08,060
several steps and basically the

00:10:05,720 --> 00:10:10,610
difference from going the difference and

00:10:08,060 --> 00:10:13,700
been in Furman yeah difference and going

00:10:10,610 --> 00:10:16,310
from a level 11 zoom level to a zoom

00:10:13,700 --> 00:10:18,470
level 10 there's a lot of 40% and this

00:10:16,310 --> 00:10:20,390
is like incremental improvements if you

00:10:18,470 --> 00:10:23,120
go to left like a zoom level 8 for

00:10:20,390 --> 00:10:25,550
example this tile this region would be

00:10:23,120 --> 00:10:27,530
expressing like eight hundred kilobytes

00:10:25,550 --> 00:10:28,100
I think that's before compression like

00:10:27,530 --> 00:10:32,120
gzip

00:10:28,100 --> 00:10:33,770
so this is already this is becoming this

00:10:32,120 --> 00:10:39,830
is becoming useful this is coming like a

00:10:33,770 --> 00:10:42,890
practical file size that is more so it's

00:10:39,830 --> 00:10:44,960
not only mean of always yeah it's not

00:10:42,890 --> 00:10:47,450
only the roads that are not always

00:10:44,960 --> 00:10:49,850
useful a lot of the notes and OSM aren't

00:10:47,450 --> 00:10:51,890
useful for rich banners eaters like a

00:10:49,850 --> 00:10:53,630
lot of them are only there to define the

00:10:51,890 --> 00:10:54,920
shape of the roads but if your route

00:10:53,630 --> 00:10:56,960
planner doesn't care about that it's

00:10:54,920 --> 00:10:59,960
also it would make sense to not publish

00:10:56,960 --> 00:11:02,210
that data as well so that's what we did

00:10:59,960 --> 00:11:04,019
is we basically do a contraction of that

00:11:02,210 --> 00:11:06,660
note so basically we're gonna replace

00:11:04,019 --> 00:11:08,369
notes marriages gonna get rid of a note

00:11:06,660 --> 00:11:11,189
and then publish the the distances

00:11:08,369 --> 00:11:13,220
between the leftover notes and the notes

00:11:11,189 --> 00:11:15,420
you're going to retain are all the

00:11:13,220 --> 00:11:16,679
rounded notes that I think would be most

00:11:15,420 --> 00:11:18,720
interesting for a wristband if for

00:11:16,679 --> 00:11:21,899
example the the beginning and the end of

00:11:18,720 --> 00:11:24,480
the street intersections pedestrian

00:11:21,899 --> 00:11:26,699
crossings traffic lights stuff like that

00:11:24,480 --> 00:11:30,239
and in the end this reduces the file

00:11:26,699 --> 00:11:34,110
size by another forty percent so yeah

00:11:30,239 --> 00:11:35,730
the same 570 square kilometers region I

00:11:34,110 --> 00:11:38,309
was talking about in the previous slides

00:11:35,730 --> 00:11:41,360
is now only 2 megabytes before

00:11:38,309 --> 00:11:45,420
compression and this is becoming really

00:11:41,360 --> 00:11:48,420
it's becoming way more practical and

00:11:45,420 --> 00:11:50,939
just to prove that it is now let's go to

00:11:48,420 --> 00:11:53,429
the next section is about how do we use

00:11:50,939 --> 00:11:55,019
this process data and a route planner or

00:11:53,429 --> 00:11:57,619
an any which management doesn't have to

00:11:55,019 --> 00:11:59,879
be this one of course and so this is

00:11:57,619 --> 00:12:01,769
yeah I have to be honest really

00:11:59,879 --> 00:12:04,199
pre-processed like this bounding box or

00:12:01,769 --> 00:12:06,119
unbalanced so I'm gonna have to limit

00:12:04,199 --> 00:12:08,220
myself to that like let's say for

00:12:06,119 --> 00:12:10,319
example if you want to go from I'm gonna

00:12:08,220 --> 00:12:12,990
give an example or later of Brussels to

00:12:10,319 --> 00:12:18,240
approach this is about 100 kilometers in

00:12:12,990 --> 00:12:22,529
distance so this is my computer so this

00:12:18,240 --> 00:12:24,299
is all life I'm glad it works so so you

00:12:22,529 --> 00:12:26,999
can see it's dynamically downloading

00:12:24,299 --> 00:12:29,730
more data as it goes each time it gets

00:12:26,999 --> 00:12:31,410
to the edge of a model of the tiles that

00:12:29,730 --> 00:12:33,779
already download this is the basic day

00:12:31,410 --> 00:12:36,959
extract implementation we kept it simple

00:12:33,779 --> 00:12:38,610
for now and each time it gets to the

00:12:36,959 --> 00:12:40,259
edge of one of the tiles that already

00:12:38,610 --> 00:12:42,629
has it's gonna fetch in the next tile

00:12:40,259 --> 00:12:45,119
and as you can see it's always going to

00:12:42,629 --> 00:12:46,860
fetch large and larger tiles that's

00:12:45,119 --> 00:12:48,240
because the puzzle derated the transit

00:12:46,860 --> 00:12:50,490
styles were defined right if you don't

00:12:48,240 --> 00:12:52,199
have to be there control available stuff

00:12:50,490 --> 00:12:53,910
so basically it's going to fetch it the

00:12:52,199 --> 00:12:57,269
largest possible tile that doesn't

00:12:53,910 --> 00:12:58,499
include the begin and end location and

00:12:57,269 --> 00:13:00,809
that's why you get like this this we're

00:12:58,499 --> 00:13:02,449
to bottom up box tree structure which is

00:13:00,809 --> 00:13:04,470
really fun to watch

00:13:02,449 --> 00:13:07,559
and of course yeah a lot like Ben

00:13:04,470 --> 00:13:09,569
already says and at low points the this

00:13:07,559 --> 00:13:12,299
client sneak to the server where it's

00:13:09,569 --> 00:13:14,669
going or what it's trying to do or in

00:13:12,299 --> 00:13:16,619
fact if the client already had the data

00:13:14,669 --> 00:13:17,200
cache somewhere the server wouldn't even

00:13:16,619 --> 00:13:19,420
know we

00:13:17,200 --> 00:13:25,269
region you were trying to go to so these

00:13:19,420 --> 00:13:27,060
are all interesting benefits and yeah of

00:13:25,269 --> 00:13:30,610
course yeah and as you can see it's

00:13:27,060 --> 00:13:33,310
still significantly slower than most

00:13:30,610 --> 00:13:34,480
route banners most people are using but

00:13:33,310 --> 00:13:37,600
a bit it's getting there right is this

00:13:34,480 --> 00:13:41,949
is close to being close to being good

00:13:37,600 --> 00:13:45,820
enough for actual usage I think I'll see

00:13:41,949 --> 00:13:47,589
you much tiny Jesus just yeah that's

00:13:45,820 --> 00:13:49,510
another downside of maps lights there's

00:13:47,589 --> 00:13:56,350
like a massive SVG on the next slide

00:13:49,510 --> 00:13:59,829
not Church is Frank okay my mom might

00:13:56,350 --> 00:14:02,829
have seen my Dulce me frozen what's also

00:13:59,829 --> 00:14:06,040
nice no just just got improved for us

00:14:02,829 --> 00:14:06,430
this comes skipping that slides next

00:14:06,040 --> 00:14:09,399
slide

00:14:06,430 --> 00:14:11,889
perfect don't skip it anyway it's fine

00:14:09,399 --> 00:14:14,769
okay so the overall impact on query

00:14:11,889 --> 00:14:16,720
times so this is the same example as I

00:14:14,769 --> 00:14:19,000
just gave in a live demo Brussels

00:14:16,720 --> 00:14:20,380
Airport to Bruges well more or less the

00:14:19,000 --> 00:14:21,579
more or less one than exactly 100

00:14:20,380 --> 00:14:24,490
kilometers depending on where you click

00:14:21,579 --> 00:14:27,730
and using the raw data the this this

00:14:24,490 --> 00:14:29,380
requires about 250 megabytes of

00:14:27,730 --> 00:14:31,690
transferring data so this is compressed

00:14:29,380 --> 00:14:33,269
gzip data that's that's a lot of data if

00:14:31,690 --> 00:14:35,470
you have to squeeze that into apply

00:14:33,269 --> 00:14:37,690
especially if that client is like a

00:14:35,470 --> 00:14:40,060
mobile phone or something it becomes

00:14:37,690 --> 00:14:42,279
really impractical and that's probably

00:14:40,060 --> 00:14:44,019
also write the query time is so horrible

00:14:42,279 --> 00:14:46,390
there's a lot of it's all being shoved

00:14:44,019 --> 00:14:47,980
into the JavaScript virtual machine so

00:14:46,390 --> 00:14:50,110
the more data you put in there the the

00:14:47,980 --> 00:14:52,660
more annoyed the garbage collection gets

00:14:50,110 --> 00:14:54,100
and then yeah the the query times have

00:14:52,660 --> 00:14:56,320
essentially were close to one hour

00:14:54,100 --> 00:14:58,810
that's about what we said it it was it

00:14:56,320 --> 00:15:02,050
works but it's really slow was really

00:14:58,810 --> 00:15:04,800
slow but now it's down to 20 seconds and

00:15:02,050 --> 00:15:07,569
that's the demo I just gave so yeah it's

00:15:04,800 --> 00:15:09,779
still is 20 seconds and pretty happy

00:15:07,569 --> 00:15:11,529
with that and the download the data

00:15:09,779 --> 00:15:12,100
should have been around to nine

00:15:11,529 --> 00:15:15,760
megabytes

00:15:12,100 --> 00:15:18,790
I tried tested it doing some monkey

00:15:15,760 --> 00:15:20,410
patching in the fetch library but they

00:15:18,790 --> 00:15:23,350
actually nine megabytes more or less

00:15:20,410 --> 00:15:25,360
depending on you know specifics where

00:15:23,350 --> 00:15:27,160
when you clicked but it's a massive

00:15:25,360 --> 00:15:28,499
difference right is it been from 250

00:15:27,160 --> 00:15:31,559
megabytes off

00:15:28,499 --> 00:15:34,829
yeah that's fine to decide just have my

00:15:31,559 --> 00:15:39,689
own time so here in any case it's a huge

00:15:34,829 --> 00:15:40,469
improvement right okay that like more or

00:15:39,689 --> 00:15:44,159
less brings us to the conclusion

00:15:40,469 --> 00:15:48,239
actually like going back to to one of

00:15:44,159 --> 00:15:49,739
their first slices there is like there

00:15:48,239 --> 00:15:52,199
is an obvious benefits to sharing data

00:15:49,739 --> 00:15:53,609
right because you know I don't have to

00:15:52,199 --> 00:15:57,179
tell you guys about sharing data of

00:15:53,609 --> 00:15:59,759
course but the seems like like anthem

00:15:57,179 --> 00:16:01,859
like we don't really share the routing

00:15:59,759 --> 00:16:04,559
data enough yet I mean like I said we do

00:16:01,859 --> 00:16:06,959
a lot of pre-processing on the same data

00:16:04,559 --> 00:16:09,029
but you never shared results even though

00:16:06,959 --> 00:16:10,739
I think it would make sense like it's

00:16:09,029 --> 00:16:13,259
like for example the instance of open

00:16:10,739 --> 00:16:15,509
crypt Landers all its users are doing

00:16:13,259 --> 00:16:17,189
the same pre computations as also know

00:16:15,509 --> 00:16:21,359
why don't they share it with themselves

00:16:17,189 --> 00:16:23,159
at least basically that this is one of

00:16:21,359 --> 00:16:24,689
the the core research questions of a

00:16:23,159 --> 00:16:26,309
research group against university is

00:16:24,689 --> 00:16:27,949
like why don't people share their what's

00:16:26,309 --> 00:16:30,269
what's stopping them from sharing data

00:16:27,949 --> 00:16:32,189
and in this case I think it's mostly

00:16:30,269 --> 00:16:33,899
down to two points first one is pretty

00:16:32,189 --> 00:16:35,599
obvious in the cost like who's gonna pay

00:16:33,899 --> 00:16:37,709
for the people things gonna pay for the

00:16:35,599 --> 00:16:39,359
effort all the effort put into it who's

00:16:37,709 --> 00:16:42,359
gonna pay for the hosting is gonna pay

00:16:39,359 --> 00:16:44,249
for all of it well the benefit of the

00:16:42,359 --> 00:16:46,829
the techniques I just discussed is that

00:16:44,249 --> 00:16:48,629
everything is pretty Oh relatively keep

00:16:46,829 --> 00:16:50,459
at least linked data fragments are made

00:16:48,629 --> 00:16:52,529
to be easy to host because they're all

00:16:50,459 --> 00:16:55,139
just data files I'm hosting all of this

00:16:52,529 --> 00:16:58,079
on the digital ocean has cost me 5 euros

00:16:55,139 --> 00:17:00,029
per month and it's only running nginx

00:16:58,079 --> 00:17:01,529
and it's already you know and I have a

00:17:00,029 --> 00:17:05,519
roots banner diffusing the data and it

00:17:01,529 --> 00:17:07,889
works of course yes and although it's

00:17:05,519 --> 00:17:10,079
gonna be I'm not going to be able to

00:17:07,889 --> 00:17:12,750
process the entire world basically so

00:17:10,079 --> 00:17:15,179
that's one of the open questions but in

00:17:12,750 --> 00:17:16,829
any case should be workable I think at

00:17:15,179 --> 00:17:20,490
some point so something else on this

00:17:16,829 --> 00:17:22,259
probably less obvious is trust like like

00:17:20,490 --> 00:17:24,299
I said I'm publishing all this data but

00:17:22,259 --> 00:17:26,399
don't really expect any of you to

00:17:24,299 --> 00:17:28,019
immediately use this data because I

00:17:26,399 --> 00:17:28,439
don't have any published metadata to go

00:17:28,019 --> 00:17:30,210
with it

00:17:28,439 --> 00:17:33,659
like I don't really specify how I use

00:17:30,210 --> 00:17:36,179
this oh yeah well then I did it's what

00:17:33,659 --> 00:17:38,639
the data version of my algorithm did

00:17:36,179 --> 00:17:40,590
what like side effects that some of the

00:17:38,639 --> 00:17:41,450
styles where they all download it

00:17:40,590 --> 00:17:43,010
correctly and stuff

00:17:41,450 --> 00:17:44,390
I can eat a lot of like provenance

00:17:43,010 --> 00:17:46,490
metadata to actually convince people

00:17:44,390 --> 00:17:48,040
that's this data that are generated is

00:17:46,490 --> 00:17:50,120
actually useful it's actually reliable

00:17:48,040 --> 00:17:51,620
and that's also like an open question

00:17:50,120 --> 00:17:53,060
like how do you convince people that

00:17:51,620 --> 00:17:55,400
your data is of high quality especially

00:17:53,060 --> 00:17:56,900
if it's like derived linked open data

00:17:55,400 --> 00:17:58,460
it's not always very obvious where it's

00:17:56,900 --> 00:18:00,680
coming from and it's always it's like

00:17:58,460 --> 00:18:04,610
like a bit of a black box even like make

00:18:00,680 --> 00:18:08,030
it more white and yeah and that's

00:18:04,610 --> 00:18:10,400
actually that's confusion over talk yeah

00:18:08,030 --> 00:18:12,020
main points that serve roofless rothcall

00:18:10,400 --> 00:18:14,090
serves no like client base which panic

00:18:12,020 --> 00:18:17,780
seems feasible at least build on down to

00:18:14,090 --> 00:18:19,580
like workable performance and the other

00:18:17,780 --> 00:18:21,590
point is of course you could share more

00:18:19,580 --> 00:18:24,610
data that's useful for a lot of people

00:18:21,590 --> 00:18:24,610
say thank you

00:18:30,960 --> 00:18:37,500
I also wanted to mention like what harm

00:18:35,520 --> 00:18:40,770
was doing was fixing the worst case

00:18:37,500 --> 00:18:44,220
performance of this thing so this 100

00:18:40,770 --> 00:18:46,380
kilometer route is a huge problem but we

00:18:44,220 --> 00:18:49,200
are already using this type of thing for

00:18:46,380 --> 00:18:51,120
pedestrian and cycling route planning so

00:18:49,200 --> 00:18:54,240
when the roots are relatively short the

00:18:51,120 --> 00:18:56,970
performance is very realistic and very

00:18:54,240 --> 00:18:59,670
doable so it's it is very usable for

00:18:56,970 --> 00:19:02,250
certain scenarios but we know that for

00:18:59,670 --> 00:19:03,150
other use cases it's it's difficult and

00:19:02,250 --> 00:19:10,670
that's no problem

00:19:03,150 --> 00:19:10,670
you are working on right yeah questions

00:19:13,070 --> 00:19:18,030
first one here and then we have another

00:19:15,300 --> 00:19:19,140
one I think

00:19:18,030 --> 00:19:21,510
thanks very much that was a very

00:19:19,140 --> 00:19:23,760
interesting talk I wonder if you've seen

00:19:21,510 --> 00:19:24,990
the Valhalla routing system which is

00:19:23,760 --> 00:19:27,600
also tile-based

00:19:24,990 --> 00:19:29,400
and what the major differences are

00:19:27,600 --> 00:19:33,660
between between your system and their

00:19:29,400 --> 00:19:37,680
system yeah actually yeah let's go to

00:19:33,660 --> 00:19:39,780
two speakers yeah there is the

00:19:37,680 --> 00:19:43,370
difference is pretty small but we can I

00:19:39,780 --> 00:19:46,260
would have to guess what we use school

00:19:43,370 --> 00:19:47,430
yes basically the difference is that

00:19:46,260 --> 00:19:49,410
well how it also is like this is

00:19:47,430 --> 00:19:51,060
hierarchical structure right but the

00:19:49,410 --> 00:19:52,890
thing is they only look at the tax as

00:19:51,060 --> 00:19:55,410
they are all right the top level only

00:19:52,890 --> 00:19:56,520
has like the the high rate and primary

00:19:55,410 --> 00:19:58,770
roads and then there's a second level

00:19:56,520 --> 00:20:01,860
that's secondary I guess the all the way

00:19:58,770 --> 00:20:03,210
to die presidential stuff we do

00:20:01,860 --> 00:20:04,830
something similar but little it's all

00:20:03,210 --> 00:20:06,750
dynamic so it's actually based on how

00:20:04,830 --> 00:20:08,700
the routes the roads are actually used

00:20:06,750 --> 00:20:10,680
so that the creepy song residential

00:20:08,700 --> 00:20:14,040
streets in there if that happens to be

00:20:10,680 --> 00:20:16,200
the most efficient route so that that's

00:20:14,040 --> 00:20:17,610
why the main difference yeah the

00:20:16,200 --> 00:20:19,020
downside of course is this takes a lot

00:20:17,610 --> 00:20:22,470
more computation and therefore how to

00:20:19,020 --> 00:20:23,220
generate any volatiles and but yeah

00:20:22,470 --> 00:20:24,990
that's the main difference

00:20:23,220 --> 00:20:28,230
yeah and I guess also the that is

00:20:24,990 --> 00:20:30,360
json-ld link data format which is also a

00:20:28,230 --> 00:20:32,520
big difference yeah yeah this would also

00:20:30,360 --> 00:20:35,940
be easier to ingest for general routine

00:20:32,520 --> 00:20:38,660
applications hopefully you can of course

00:20:35,940 --> 00:20:38,660
try this out

00:20:39,190 --> 00:20:45,170
you have a question there so are you

00:20:42,580 --> 00:20:46,940
comparing the routes you're creating

00:20:45,170 --> 00:20:48,950
with the quality of the routes on the

00:20:46,940 --> 00:20:51,020
established routing engines I think

00:20:48,950 --> 00:20:54,880
you're talking about the performance

00:20:51,020 --> 00:20:54,880
optimizations but what about the quality

00:20:56,920 --> 00:21:00,500
yeah we didn't really mention it but

00:20:58,940 --> 00:21:02,180
there's like a rich planning profile

00:21:00,500 --> 00:21:03,790
behind all of this and that one was

00:21:02,180 --> 00:21:06,860
based on those modes so it's

00:21:03,790 --> 00:21:08,270
theoretically it should do more or less

00:21:06,860 --> 00:21:09,500
the same thing as all smart I mean there

00:21:08,270 --> 00:21:11,480
are small difference on differences

00:21:09,500 --> 00:21:13,940
because we know publishing all the data

00:21:11,480 --> 00:21:15,710
I caused not have a elevation data about

00:21:13,940 --> 00:21:17,930
something really happened to our client

00:21:15,710 --> 00:21:21,830
yet but otherwise it yeah that the rate

00:21:17,930 --> 00:21:22,970
is pretty pretty okay I would say I

00:21:21,830 --> 00:21:24,530
haven't actually tested at that

00:21:22,970 --> 00:21:26,480
real-world of course I just like didn't

00:21:24,530 --> 00:21:27,550
like toy examples and see that results

00:21:26,480 --> 00:21:32,390
makes sense

00:21:27,550 --> 00:21:34,640
yeah yeah we also like if you imagine

00:21:32,390 --> 00:21:38,180
this client-side route planning we also

00:21:34,640 --> 00:21:41,480
have a version where we combine this

00:21:38,180 --> 00:21:43,400
with public transport so the this

00:21:41,480 --> 00:21:45,740
combination happens on the client as

00:21:43,400 --> 00:21:47,840
well there's no server building this

00:21:45,740 --> 00:21:49,940
model of the world and containing the

00:21:47,840 --> 00:21:51,800
whole planet worth of public

00:21:49,940 --> 00:21:54,830
transportation data know you can just

00:21:51,800 --> 00:21:57,620
fetch the data you need from where you

00:21:54,830 --> 00:22:00,260
are and plan routes like that so the

00:21:57,620 --> 00:22:02,660
idea is much bigger than just this small

00:22:00,260 --> 00:22:05,780
piece of the puzzle we are presenting

00:22:02,660 --> 00:22:08,650
now it's it's I think it's it's it's

00:22:05,780 --> 00:22:08,650
awesome

00:22:09,380 --> 00:22:17,430
yeah okay thanks for this presentation I

00:22:14,760 --> 00:22:18,990
found it somewhat funny that at the

00:22:17,430 --> 00:22:21,720
moment that the first speaker handed

00:22:18,990 --> 00:22:24,600
over to the second his last slide

00:22:21,720 --> 00:22:27,180
mentioned data ethics and then he handed

00:22:24,600 --> 00:22:29,700
over to harm and I was wondering what

00:22:27,180 --> 00:22:31,710
are we getting here but that's all my

00:22:29,700 --> 00:22:33,900
question my question is really on you

00:22:31,710 --> 00:22:36,390
know you report a system that is using

00:22:33,900 --> 00:22:38,970
pre-processed data so I'm sort of

00:22:36,390 --> 00:22:42,630
curious how much pre-process day that

00:22:38,970 --> 00:22:46,590
will you have to what level is this

00:22:42,630 --> 00:22:49,770
sensitive to your tile size choices and

00:22:46,590 --> 00:22:52,860
how will this scale if you do this for

00:22:49,770 --> 00:22:55,830
all of Europe all of other continents

00:22:52,860 --> 00:22:58,160
did you say something to that like the

00:22:55,830 --> 00:23:01,020
efficiency of generating the data or

00:22:58,160 --> 00:23:02,730
storage storage storage your

00:23:01,020 --> 00:23:04,590
pre-processing right so you're paying

00:23:02,730 --> 00:23:07,770
somewhere I want to know how much you're

00:23:04,590 --> 00:23:09,420
paying because the whole point of what

00:23:07,770 --> 00:23:12,360
we are trying to do is because of course

00:23:09,420 --> 00:23:13,860
the more data you're pre-process larger

00:23:12,360 --> 00:23:15,660
the pre-process data is the more data

00:23:13,860 --> 00:23:17,220
the client would have to download so

00:23:15,660 --> 00:23:20,520
it's something that we intentionally try

00:23:17,220 --> 00:23:23,640
to keep as minimal as possible so I I

00:23:20,520 --> 00:23:27,180
would have to check but I think overall

00:23:23,640 --> 00:23:30,410
this our process of that up until zoom

00:23:27,180 --> 00:23:34,500
level 8 I think and overall I think the

00:23:30,410 --> 00:23:37,800
files were like the storage size tripled

00:23:34,500 --> 00:23:39,480
and totaled so that's compared to that

00:23:37,800 --> 00:23:41,880
the raw data because you have all the

00:23:39,480 --> 00:23:43,890
layers on top of that so I think it's

00:23:41,880 --> 00:23:48,120
pretty doable at least yeah at the

00:23:43,890 --> 00:23:51,690
planet so the full planet data is about

00:23:48,120 --> 00:23:55,110
200 gigabytes on when we have it just

00:23:51,690 --> 00:23:58,860
for me at just the raw data json-ld

00:23:55,110 --> 00:24:01,020
output but we the actual root of all

00:23:58,860 --> 00:24:03,270
file server doesn't actually store the

00:24:01,020 --> 00:24:08,550
json-ld it stores the OpenStreetMap data

00:24:03,270 --> 00:24:10,169
in much more efficient way so so sort of

00:24:08,550 --> 00:24:12,909
answer you

00:24:10,169 --> 00:24:15,280
also this pre-processing the idea is

00:24:12,909 --> 00:24:17,500
that if it takes some work to

00:24:15,280 --> 00:24:19,690
pre-process it's not it's not a huge

00:24:17,500 --> 00:24:31,870
problem because the whole idea is to do

00:24:19,690 --> 00:24:33,970
it basically once so I like the comment

00:24:31,870 --> 00:24:36,340
you made about trust and the question of

00:24:33,970 --> 00:24:40,179
how to build trust in this it reminded

00:24:36,340 --> 00:24:45,100
me of the reason that we put routing

00:24:40,179 --> 00:24:47,289
services on the OSM de org right main

00:24:45,100 --> 00:24:50,049
website which is which is partly to

00:24:47,289 --> 00:24:52,120
improve the route able data in OS m so

00:24:50,049 --> 00:24:53,710
there's a kind of a deliberate feedback

00:24:52,120 --> 00:24:58,179
loop introduced there and I wondered if

00:24:53,710 --> 00:25:00,870
a similar thing could help your idea so

00:24:58,179 --> 00:25:06,220
you have both the the root of all tiles

00:25:00,870 --> 00:25:08,740
available conspicuously within the

00:25:06,220 --> 00:25:10,630
community and that improves the root of

00:25:08,740 --> 00:25:14,140
all data as well as improved as well as

00:25:10,630 --> 00:25:16,390
building testing time yes probably and

00:25:14,140 --> 00:25:19,150
something I would really love to do is

00:25:16,390 --> 00:25:21,760
to do I mentioned the updating of these

00:25:19,150 --> 00:25:24,789
files so we want to make this update

00:25:21,760 --> 00:25:28,120
life so it should enable for shorter

00:25:24,789 --> 00:25:30,190
routes to route plan data that is being

00:25:28,120 --> 00:25:32,380
edited like two minutes ago

00:25:30,190 --> 00:25:34,570
currently the problem is people edit the

00:25:32,380 --> 00:25:36,820
map and then two days later the route

00:25:34,570 --> 00:25:39,880
planning is updated and this could

00:25:36,820 --> 00:25:41,669
enable potentially immediate feedback on

00:25:39,880 --> 00:25:44,110
the route planning so that's something

00:25:41,669 --> 00:25:50,440
that I think would be very useful for

00:25:44,110 --> 00:25:55,530
over-serving my website Thanks other

00:25:50,440 --> 00:25:57,970
questions still have a couple of minutes

00:25:55,530 --> 00:26:00,700
yeah thanks for your talk I like the

00:25:57,970 --> 00:26:02,710
idea of how you pre-process the map data

00:26:00,700 --> 00:26:04,090
so other route planning applications

00:26:02,710 --> 00:26:06,669
could benefit from it but I was

00:26:04,090 --> 00:26:09,070
wondering and what if you do not want to

00:26:06,669 --> 00:26:11,890
do to use these tiles and do this

00:26:09,070 --> 00:26:14,169
client-side but what if you wanted to do

00:26:11,890 --> 00:26:16,179
like a classic server-side route

00:26:14,169 --> 00:26:17,649
planning application could you use the

00:26:16,179 --> 00:26:19,330
same data in the same pre-processing

00:26:17,649 --> 00:26:21,790
steps

00:26:19,330 --> 00:26:24,610
the route planner I built it didn't all

00:26:21,790 --> 00:26:27,940
already uses the tiles because it's just

00:26:24,610 --> 00:26:29,680
easier to say to projects and clients

00:26:27,940 --> 00:26:32,110
using this like you don't have to

00:26:29,680 --> 00:26:34,630
download any OpenStreetMap data you just

00:26:32,110 --> 00:26:36,580
set up the route planner and it's either

00:26:34,630 --> 00:26:38,200
it starts fetching piles when you plan

00:26:36,580 --> 00:26:40,420
the first route or you define an area

00:26:38,200 --> 00:26:42,100
and it will just fetch the data it needs

00:26:40,420 --> 00:26:43,390
but you would have to go through the

00:26:42,100 --> 00:26:45,520
tiles you couldn't download the whole

00:26:43,390 --> 00:26:47,440
thing once well then it downloads the

00:26:45,520 --> 00:26:49,510
whole thing once and then does a regular

00:26:47,440 --> 00:26:51,490
thing the route planners do now so

00:26:49,510 --> 00:26:55,060
basically it replaces the planet dump

00:26:51,490 --> 00:26:56,740
files that's what what is what is OK

00:26:55,060 --> 00:26:59,980
theoretically also we use the

00:26:56,740 --> 00:27:01,240
pre-processing logic as well the main

00:26:59,980 --> 00:27:04,570
thing would then be to not always

00:27:01,240 --> 00:27:05,290
building not an edge graph of the entire

00:27:04,570 --> 00:27:07,720
world

00:27:05,290 --> 00:27:10,060
so is create long bumper query basically

00:27:07,720 --> 00:27:12,280
yeah but also that will scale diff

00:27:10,060 --> 00:27:15,070
difficult Lee because the the

00:27:12,280 --> 00:27:16,870
pre-processing to make these styles is

00:27:15,070 --> 00:27:19,300
takes a lot of time it takes probably

00:27:16,870 --> 00:27:21,670
more than building a regular contraction

00:27:19,300 --> 00:27:23,740
hierarchy so it's probably not that

00:27:21,670 --> 00:27:25,990
useful if you probably do if you do it

00:27:23,740 --> 00:27:27,880
once and publish the data then it

00:27:25,990 --> 00:27:29,710
becomes useful but if you do it every

00:27:27,880 --> 00:27:32,860
time you set up a route flying system

00:27:29,710 --> 00:27:34,930
I'm not sure if it's feasible yes but

00:27:32,860 --> 00:27:36,790
for example the pedestrian area we saw

00:27:34,930 --> 00:27:38,650
like this pre-processing step oh yeah

00:27:36,790 --> 00:27:40,570
you could use yeah and that's what open

00:27:38,650 --> 00:27:42,700
trip planner hustles well so that would

00:27:40,570 --> 00:27:51,490
that would definitely work yeah thank

00:27:42,700 --> 00:27:53,380
you ok any other question or comment ok

00:27:51,490 --> 00:27:57,300
we can close the session here thanks

00:27:53,380 --> 00:27:57,300
again Ben and harm and thank you again

00:28:00,800 --> 00:28:02,860

YouTube URL: https://www.youtube.com/watch?v=_hH8qLEwL6M


