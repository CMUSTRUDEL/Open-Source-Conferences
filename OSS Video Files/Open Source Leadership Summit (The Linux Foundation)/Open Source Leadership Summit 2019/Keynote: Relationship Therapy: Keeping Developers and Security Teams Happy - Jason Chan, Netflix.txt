Title: Keynote: Relationship Therapy: Keeping Developers and Security Teams Happy - Jason Chan, Netflix
Publication date: 2019-03-13
Playlist: Open Source Leadership Summit 2019
Description: 
	Keynote: Relationship Therapy: Using Data and Automation to Keep Developers and Security Teams Happy - Jason Chan, Vice President of Information Security, NetflixÂ 

Relationships between security and development teams have historically been strained - developers want to move fast and innovate to advance the business while security teams want to moderate changes to mitigate risk. We'll cover a variety of strategies and principles for building trust and improving the relationship between engineering and security teams through innovative uses of data and automation.

Jason Chan
Netflix
Vice President, Information Security
Los Gatos, CA
Jason leads the teams at Netflix responsible for corporate infosec, product and application security, privacy engineering, security operations, infrastructure, and incident response. Prior to joining Netflix, he led the information security team at VMware. He spent most of his earlier career in security consulting for firms such as @stake and iSEC Partners.
Captions: 
	00:00:00,060 --> 00:00:06,359
let's appreciate it thank you think my

00:00:03,990 --> 00:00:07,740
jobs gonna be easier now thanks

00:00:06,359 --> 00:00:09,360
everybody for coming in and and thank

00:00:07,740 --> 00:00:10,860
you very much for having me certainly my

00:00:09,360 --> 00:00:12,840
pleasure to be here for you with you

00:00:10,860 --> 00:00:15,480
today so I'm gonna talk about

00:00:12,840 --> 00:00:17,580
relationships between software

00:00:15,480 --> 00:00:19,710
engineering teams and the security teams

00:00:17,580 --> 00:00:21,390
they work with so I've been in security

00:00:19,710 --> 00:00:22,920
pretty much my whole career and this is

00:00:21,390 --> 00:00:24,660
definitely one of the more complicated

00:00:22,920 --> 00:00:26,670
relationships that I've had to navigate

00:00:24,660 --> 00:00:29,010
but I do think it's important that these

00:00:26,670 --> 00:00:30,660
groups work together and I want to talk

00:00:29,010 --> 00:00:33,120
a bit about why have these relationships

00:00:30,660 --> 00:00:36,239
been problematic and maybe what we can

00:00:33,120 --> 00:00:37,590
do about it but I work at Netflix so I

00:00:36,239 --> 00:00:40,520
think it's important to start with movie

00:00:37,590 --> 00:00:42,809
trivia so does anybody recognize this

00:00:40,520 --> 00:00:47,190
handsome fella on the right-hand side or

00:00:42,809 --> 00:00:49,440
maybe the movie it comes from yes Monty

00:00:47,190 --> 00:00:50,850
Python and the Holy Grail which happens

00:00:49,440 --> 00:00:52,739
to be streaming on Netflix if you

00:00:50,850 --> 00:00:54,420
haven't seen it I'm gonna give some

00:00:52,739 --> 00:00:55,949
spoilers for this movie but I think it's

00:00:54,420 --> 00:00:58,739
about 40 years old so hopefully you

00:00:55,949 --> 00:01:00,120
forgive me so the bridge keeper in in

00:00:58,739 --> 00:01:01,590
the movie if you want to cross the

00:01:00,120 --> 00:01:03,270
bridge you go talk to the bridge keeper

00:01:01,590 --> 00:01:06,060
and he's going to ask you some questions

00:01:03,270 --> 00:01:07,979
right which seems reasonable but the

00:01:06,060 --> 00:01:09,450
problem is you have no you would have no

00:01:07,979 --> 00:01:11,939
reason to know the answers to the

00:01:09,450 --> 00:01:13,799
questions he's gonna ask and if you get

00:01:11,939 --> 00:01:16,500
them wrong you don't just like come back

00:01:13,799 --> 00:01:17,909
the next day and maybe try again he

00:01:16,500 --> 00:01:20,240
shoots you into a pit of lava so it's

00:01:17,909 --> 00:01:22,830
pretty pretty serious consequences for

00:01:20,240 --> 00:01:24,270
getting the wrong answers but I think

00:01:22,830 --> 00:01:25,560
this is how software engineers think

00:01:24,270 --> 00:01:27,810
about the security people they work with

00:01:25,560 --> 00:01:30,090
right they're they're they're kind of

00:01:27,810 --> 00:01:32,040
like strange-looking and they ask me

00:01:30,090 --> 00:01:33,990
these confusing questions I don't know

00:01:32,040 --> 00:01:35,340
how they're making decisions they're

00:01:33,990 --> 00:01:36,780
trying to slow me down they're trying to

00:01:35,340 --> 00:01:39,360
stop me from getting where I want to go

00:01:36,780 --> 00:01:41,070
but I don't want to be too one-sided so

00:01:39,360 --> 00:01:43,590
this is how security teams think about

00:01:41,070 --> 00:01:46,049
developers right there they always want

00:01:43,590 --> 00:01:47,820
to use the the latest technology they're

00:01:46,049 --> 00:01:49,500
not thinking about the risk that they're

00:01:47,820 --> 00:01:52,020
that they're exposing the business to

00:01:49,500 --> 00:01:53,850
but when you when you dig in a little

00:01:52,020 --> 00:01:56,549
bit to what motivates each of these

00:01:53,850 --> 00:01:58,170
groups it's really not surprising so

00:01:56,549 --> 00:01:59,759
developers right this is kind of the

00:01:58,170 --> 00:02:01,140
mantra for the modern developer of

00:01:59,759 --> 00:02:03,270
course this is from Facebook from a few

00:02:01,140 --> 00:02:05,490
years ago but the idea is that if you're

00:02:03,270 --> 00:02:06,390
not breaking things every once every

00:02:05,490 --> 00:02:08,459
once in a while you're probably not

00:02:06,390 --> 00:02:10,020
moving fast enough because we all know

00:02:08,459 --> 00:02:11,489
when developers when they deliver cool

00:02:10,020 --> 00:02:13,500
stuff right they get their pictures

00:02:11,489 --> 00:02:15,660
taken they get gold medals

00:02:13,500 --> 00:02:17,370
you know they're famous right but

00:02:15,660 --> 00:02:20,460
security teams this is kind of our

00:02:17,370 --> 00:02:22,680
mantra so we spend a lot of our time and

00:02:20,460 --> 00:02:25,530
energy trying to prevent bad things from

00:02:22,680 --> 00:02:27,240
happening and one strategy to prevent

00:02:25,530 --> 00:02:28,830
bad things from happening is to just

00:02:27,240 --> 00:02:31,320
prevent all things from happening and

00:02:28,830 --> 00:02:33,330
that's kind of how we get that that

00:02:31,320 --> 00:02:35,130
reputation as being the bridge keeper

00:02:33,330 --> 00:02:37,260
because this is what security people

00:02:35,130 --> 00:02:38,940
want we want to be the dog like laying

00:02:37,260 --> 00:02:41,640
in front of the fireplace everything is

00:02:38,940 --> 00:02:44,160
quiet it's calm no one's bothering us

00:02:41,640 --> 00:02:45,600
there's nothing bad happening so you put

00:02:44,160 --> 00:02:47,940
these two things side by side and you

00:02:45,600 --> 00:02:50,310
say okay well it makes sense that this

00:02:47,940 --> 00:02:52,590
is going to be kind of problematic a bit

00:02:50,310 --> 00:02:54,690
of friction and maybe this is just kind

00:02:52,590 --> 00:02:57,540
of the technology equivalent to cats and

00:02:54,690 --> 00:03:00,240
dogs and I think it's somewhat true but

00:02:57,540 --> 00:03:03,360
what I would say is now we really don't

00:03:00,240 --> 00:03:05,340
have the option to kind of sort of

00:03:03,360 --> 00:03:07,860
tolerate this level of dysfunction and

00:03:05,340 --> 00:03:10,680
it's really driven from from both sides

00:03:07,860 --> 00:03:12,990
of this so on the software side this is

00:03:10,680 --> 00:03:15,209
this is a quote from I think 2011 but

00:03:12,990 --> 00:03:17,640
the idea is that for many companies

00:03:15,209 --> 00:03:19,860
their ability to deliver software is

00:03:17,640 --> 00:03:21,450
tied directly to their ability to be

00:03:19,860 --> 00:03:24,390
successful right that's certainly how we

00:03:21,450 --> 00:03:26,280
think of things at Netflix and there's

00:03:24,390 --> 00:03:28,500
just more and more software out there at

00:03:26,280 --> 00:03:30,390
you know higher velocity I think a lot

00:03:28,500 --> 00:03:32,670
of the tools and the innovation and the

00:03:30,390 --> 00:03:35,070
technology here about at this conference

00:03:32,670 --> 00:03:39,360
is really around letting developers move

00:03:35,070 --> 00:03:40,739
faster right and on the security side we

00:03:39,360 --> 00:03:42,950
kind of have this seat at the proverbial

00:03:40,739 --> 00:03:45,540
table now right nobody is really

00:03:42,950 --> 00:03:47,910
thinking hey Security's not important so

00:03:45,540 --> 00:03:50,220
believe it or not for the first half of

00:03:47,910 --> 00:03:51,690
my career I spent a lot of time trying

00:03:50,220 --> 00:03:53,010
to convince people that security was

00:03:51,690 --> 00:03:55,650
important but I think generally people

00:03:53,010 --> 00:03:57,090
get it now there's really a tremendous

00:03:55,650 --> 00:03:59,220
amount of demand in the security space

00:03:57,090 --> 00:04:00,660
so we hear a lot of a lot of times about

00:03:59,220 --> 00:04:03,750
this skill shortage where there's just

00:04:00,660 --> 00:04:06,360
not enough people so this guy when you

00:04:03,750 --> 00:04:08,160
take a kind of naturally dysfunctional

00:04:06,360 --> 00:04:10,230
relationship and then you layer on these

00:04:08,160 --> 00:04:11,880
elements if you kind of feel like this

00:04:10,230 --> 00:04:13,910
is a disaster waiting to happen like

00:04:11,880 --> 00:04:16,410
this is just not gonna end well

00:04:13,910 --> 00:04:19,200
but that's where actually I've had this

00:04:16,410 --> 00:04:21,539
kind of Pleasant professional irony I've

00:04:19,200 --> 00:04:24,270
been able to experience and say the last

00:04:21,539 --> 00:04:26,120
10 years and that's really that the the

00:04:24,270 --> 00:04:28,370
tools and the techniques

00:04:26,120 --> 00:04:30,350
the operational patterns the the sort of

00:04:28,370 --> 00:04:33,350
practices that developers are latching

00:04:30,350 --> 00:04:36,020
onto to deliver faster and to deliver a

00:04:33,350 --> 00:04:38,540
bigger scale those are the same things

00:04:36,020 --> 00:04:39,889
that security teams can latch on to to

00:04:38,540 --> 00:04:42,199
catch up with the security with their

00:04:39,889 --> 00:04:43,790
software teams and what I believe is is

00:04:42,199 --> 00:04:45,620
to make the relationships better and

00:04:43,790 --> 00:04:48,320
also I think meaningfully improve

00:04:45,620 --> 00:04:50,090
security so I don't know if we can quite

00:04:48,320 --> 00:04:51,800
end up like this kind of dog and cat

00:04:50,090 --> 00:04:54,650
relationship but I do think we can move

00:04:51,800 --> 00:04:55,729
move closer and I think we need to so I

00:04:54,650 --> 00:04:57,500
want to spend the rest of the time

00:04:55,729 --> 00:04:59,240
talking about what I view is some

00:04:57,500 --> 00:05:01,040
principles that security teams can

00:04:59,240 --> 00:05:03,200
embrace and then talk about a few

00:05:01,040 --> 00:05:04,700
examples of some open source that we

00:05:03,200 --> 00:05:07,160
built at Netflix to help kind of make

00:05:04,700 --> 00:05:10,430
this take theory into practice

00:05:07,160 --> 00:05:12,320
so the first principle I have it I think

00:05:10,430 --> 00:05:14,419
is super important is around

00:05:12,320 --> 00:05:16,430
transparency so I think it's it's

00:05:14,419 --> 00:05:18,229
important for security teams to expose

00:05:16,430 --> 00:05:19,850
their decision making and how they're

00:05:18,229 --> 00:05:22,070
deciding about certain things to

00:05:19,850 --> 00:05:23,330
developers it shouldn't be opaque we

00:05:22,070 --> 00:05:24,560
shouldn't be like the bridge keeper

00:05:23,330 --> 00:05:27,139
where who knows how we're going to

00:05:24,560 --> 00:05:29,360
decide we need to think about friction

00:05:27,139 --> 00:05:30,410
and reducing friction and any kind of

00:05:29,360 --> 00:05:32,090
interaction where it could be

00:05:30,410 --> 00:05:34,880
potentially problematic we need to think

00:05:32,090 --> 00:05:36,139
about how we can kind of lower the

00:05:34,880 --> 00:05:37,820
intensity of that and make it go

00:05:36,139 --> 00:05:40,070
smoother and then finally of course is

00:05:37,820 --> 00:05:42,380
scaled so if we're producing more

00:05:40,070 --> 00:05:44,570
software if we have this this cyber

00:05:42,380 --> 00:05:46,400
security skill shortage we need to think

00:05:44,570 --> 00:05:48,680
about how we can more effectively

00:05:46,400 --> 00:05:51,830
address a really really large portfolio

00:05:48,680 --> 00:05:54,590
software so let's going to walk through

00:05:51,830 --> 00:05:56,479
a couple of examples here of some some

00:05:54,590 --> 00:05:59,599
work we've done at Netflix and the first

00:05:56,479 --> 00:06:02,300
example it seems really simple but it's

00:05:59,599 --> 00:06:04,490
probably one of the gnarliest security

00:06:02,300 --> 00:06:07,700
developer interactions that you can have

00:06:04,490 --> 00:06:09,770
and that's how do you provide developers

00:06:07,700 --> 00:06:11,810
access to what they need how do you give

00:06:09,770 --> 00:06:13,250
them the permissions they need and I'm

00:06:11,810 --> 00:06:16,490
gonna use this opportunity to use my

00:06:13,250 --> 00:06:19,280
favorite Grace Hopper quote I don't

00:06:16,490 --> 00:06:21,650
think she was talking about developer

00:06:19,280 --> 00:06:23,240
permissions I could be wrong but when

00:06:21,650 --> 00:06:25,849
when you read that quote it kind of

00:06:23,240 --> 00:06:27,889
gives you the the gist of the problem is

00:06:25,849 --> 00:06:29,870
that sometimes when you're asking

00:06:27,889 --> 00:06:32,030
permission right it's going to take some

00:06:29,870 --> 00:06:34,490
time there's a risk that your request

00:06:32,030 --> 00:06:35,990
will be denied so sometimes you just

00:06:34,490 --> 00:06:37,490
kind of want to do your thing right you

00:06:35,990 --> 00:06:38,759
just want to sort of move fast and maybe

00:06:37,490 --> 00:06:41,490
break some things

00:06:38,759 --> 00:06:43,020
and some of what we've seen historically

00:06:41,490 --> 00:06:45,089
can kind of make that seem like a good

00:06:43,020 --> 00:06:46,499
idea because usually when you need

00:06:45,089 --> 00:06:49,559
permissions or you need to some kind of

00:06:46,499 --> 00:06:51,210
you see needs some new capability you

00:06:49,559 --> 00:06:53,370
have to go take it to somebody who

00:06:51,210 --> 00:06:54,930
decides whether or not you get it maybe

00:06:53,370 --> 00:06:56,669
it's a Change review board or it's an

00:06:54,930 --> 00:06:58,979
architecture review board or it's the

00:06:56,669 --> 00:07:00,719
security team or whatever it is in your

00:06:58,979 --> 00:07:03,059
organization somebody has the

00:07:00,719 --> 00:07:05,339
opportunity to be the bridge keeper for

00:07:03,059 --> 00:07:07,650
you right and to tell you know and then

00:07:05,339 --> 00:07:09,779
on the on the security side this is

00:07:07,650 --> 00:07:11,039
probably some I don't remember but it's

00:07:09,779 --> 00:07:13,229
probably something I've done in my

00:07:11,039 --> 00:07:14,580
career but it's sometimes what we'll do

00:07:13,229 --> 00:07:17,399
in security as we'll see a permission

00:07:14,580 --> 00:07:19,649
we'll see a firewall rule we don't know

00:07:17,399 --> 00:07:22,379
what it is so we say well let's just

00:07:19,649 --> 00:07:24,330
disable it and see who complains but

00:07:22,379 --> 00:07:26,189
like this is not the kind of behavior

00:07:24,330 --> 00:07:27,749
that builds trust right if you do this

00:07:26,189 --> 00:07:29,399
kind of thing and then somebody's app

00:07:27,749 --> 00:07:31,080
breaks over the weekend and they get

00:07:29,399 --> 00:07:33,210
paged they're not gonna be happy

00:07:31,080 --> 00:07:34,349
so is there is can we do something

00:07:33,210 --> 00:07:37,110
better than this this seems pretty

00:07:34,349 --> 00:07:40,020
dysfunctional so I'm gonna talk about

00:07:37,110 --> 00:07:41,610
how we do cloud permissions at Netflix

00:07:40,020 --> 00:07:44,490
so we primarily use the Amazon Web

00:07:41,610 --> 00:07:45,990
Services and I there's probably a better

00:07:44,490 --> 00:07:47,789
phrase for this but I kind of called the

00:07:45,990 --> 00:07:50,669
magic of infrastructure as a service

00:07:47,789 --> 00:07:52,889
because I think when you the cloud is

00:07:50,669 --> 00:07:54,719
not really about like let's take an app

00:07:52,889 --> 00:07:56,849
from the data center and just kind of

00:07:54,719 --> 00:07:58,979
run it in the cloud write it to me I

00:07:56,849 --> 00:08:00,930
think you really get a lot of leverage

00:07:58,979 --> 00:08:02,759
when you start using the other services

00:08:00,930 --> 00:08:04,709
that your cloud provider gives you so

00:08:02,759 --> 00:08:06,539
for example if your app needs to send

00:08:04,709 --> 00:08:08,639
email to your customers instead of

00:08:06,539 --> 00:08:09,959
managing this massive email delivery

00:08:08,639 --> 00:08:11,999
infrastructure you just call an API

00:08:09,959 --> 00:08:13,439
right you have a ton of velocity a ton

00:08:11,999 --> 00:08:16,169
of capability just by using those

00:08:13,439 --> 00:08:17,520
services but this is where some of the

00:08:16,169 --> 00:08:19,199
some of the tricky part comes in because

00:08:17,520 --> 00:08:22,319
then how do you provide the developers

00:08:19,199 --> 00:08:24,209
the permissions they need because it's

00:08:22,319 --> 00:08:26,399
not clear the nice thing is that many

00:08:24,209 --> 00:08:28,800
cloud providers including AWS give you

00:08:26,399 --> 00:08:32,490
pretty detailed information about how

00:08:28,800 --> 00:08:34,110
you're using the cloud and so AWS has

00:08:32,490 --> 00:08:35,490
two services one is called cloud trail

00:08:34,110 --> 00:08:37,709
the other one's called access advisor

00:08:35,490 --> 00:08:39,329
that gives you insight into how you're

00:08:37,709 --> 00:08:41,190
using the cloud and then what we do what

00:08:39,329 --> 00:08:42,659
the security team does is we then use

00:08:41,190 --> 00:08:45,360
that information to help make better

00:08:42,659 --> 00:08:46,890
decisions so if you were a developer at

00:08:45,360 --> 00:08:49,079
Netflix and you wanted to create

00:08:46,890 --> 00:08:50,760
whatever app you wanted to create what

00:08:49,079 --> 00:08:51,500
we would do is give you a base set of

00:08:50,760 --> 00:08:53,870
permissions

00:08:51,500 --> 00:08:56,570
so we'd observed thousands of

00:08:53,870 --> 00:08:58,940
applications over many years and we have

00:08:56,570 --> 00:09:01,400
a good sense of how most applications

00:08:58,940 --> 00:09:02,840
interact with AWS so what we do is we

00:09:01,400 --> 00:09:05,720
give you that base set of permissions

00:09:02,840 --> 00:09:07,520
and you can you can imagine there well

00:09:05,720 --> 00:09:08,540
it's it's slightly over provision right

00:09:07,520 --> 00:09:10,220
because you're gonna have permissions

00:09:08,540 --> 00:09:11,900
you don't need but we believe that that

00:09:10,220 --> 00:09:14,000
to start with is a pretty good trade-off

00:09:11,900 --> 00:09:15,230
because it allows every developer you

00:09:14,000 --> 00:09:18,050
don't need to come ask anybody you just

00:09:15,230 --> 00:09:19,550
kind of go and do stuff we think that's

00:09:18,050 --> 00:09:21,440
a good trade-off between velocity and

00:09:19,550 --> 00:09:23,480
security and then what we do is once

00:09:21,440 --> 00:09:26,210
your app is running we just watch what

00:09:23,480 --> 00:09:27,620
it does right we take a look well what

00:09:26,210 --> 00:09:30,470
is your app doing and it doesn't matter

00:09:27,620 --> 00:09:32,330
what you think your app does or what you

00:09:30,470 --> 00:09:33,950
ask for the only thing that matters is

00:09:32,330 --> 00:09:35,810
the data and what your app how your app

00:09:33,950 --> 00:09:38,840
actually interacts with the cloud and

00:09:35,810 --> 00:09:40,970
then what we do is we just take a Delta

00:09:38,840 --> 00:09:42,680
so we have what permissions you have and

00:09:40,970 --> 00:09:44,960
what you what you haven't used and we

00:09:42,680 --> 00:09:47,090
just remove those permissions but what

00:09:44,960 --> 00:09:48,860
we don't do is we don't just blindly get

00:09:47,090 --> 00:09:50,690
rid of those and you know hope nothing

00:09:48,860 --> 00:09:52,460
breaks what we do is we we push

00:09:50,690 --> 00:09:54,950
notifications to developers through our

00:09:52,460 --> 00:09:56,960
standard change notification platform we

00:09:54,950 --> 00:09:58,160
let you know hey your app hasn't used

00:09:56,960 --> 00:09:59,570
these permissions we're gonna go ahead

00:09:58,160 --> 00:10:01,490
and take them away if you have any

00:09:59,570 --> 00:10:03,770
questions go check out the docs come

00:10:01,490 --> 00:10:05,600
come talk to us in our slack channel so

00:10:03,770 --> 00:10:07,220
if if everything's fine there's no

00:10:05,600 --> 00:10:10,070
there's no interaction needed right it

00:10:07,220 --> 00:10:11,930
just all works so we built that and we

00:10:10,070 --> 00:10:14,330
open-source that as a tool called repo

00:10:11,930 --> 00:10:16,190
kid so if that's at all interest to you

00:10:14,330 --> 00:10:18,170
go go take a look at it we've got a lot

00:10:16,190 --> 00:10:20,600
of good contributions and feedback from

00:10:18,170 --> 00:10:22,910
the community and and what we do with

00:10:20,600 --> 00:10:24,740
repo kid is just transparent and

00:10:22,910 --> 00:10:26,360
automated right there's no there's no

00:10:24,740 --> 00:10:28,610
permissions be there you don't have to

00:10:26,360 --> 00:10:30,620
ask anybody right you just it just works

00:10:28,610 --> 00:10:33,200
it simplifies the developer experience

00:10:30,620 --> 00:10:35,870
it minimizes the human interaction and

00:10:33,200 --> 00:10:37,730
it written it introduces one of the core

00:10:35,870 --> 00:10:39,950
philosophies that we have at Netflix

00:10:37,730 --> 00:10:42,230
from a security perspective is this idea

00:10:39,950 --> 00:10:44,090
of guardrails instead of gates right so

00:10:42,230 --> 00:10:46,370
how do we let people move fast but stay

00:10:44,090 --> 00:10:49,730
safe at the same time it's that kind of

00:10:46,370 --> 00:10:51,380
balance between velocity and security so

00:10:49,730 --> 00:10:53,510
the next item I want to talk about is

00:10:51,380 --> 00:10:55,160
what we call application risk assessment

00:10:53,510 --> 00:10:56,990
maybe you you may call this something

00:10:55,160 --> 00:10:59,780
different at your place of employment

00:10:56,990 --> 00:11:02,060
but it's really the process where the

00:10:59,780 --> 00:11:03,380
security team comes to know context

00:11:02,060 --> 00:11:04,560
about new systems that are being

00:11:03,380 --> 00:11:06,930
developed new applique

00:11:04,560 --> 00:11:10,499
and so we can decide how much to invest

00:11:06,930 --> 00:11:11,999
in how much security effort to invest so

00:11:10,499 --> 00:11:13,499
are you building like the next

00:11:11,999 --> 00:11:14,790
generation Global Payments

00:11:13,499 --> 00:11:16,800
infrastructure that's going to be

00:11:14,790 --> 00:11:18,360
handling all kinds of credit cards or

00:11:16,800 --> 00:11:20,160
are you building an app to show the

00:11:18,360 --> 00:11:21,749
lunch menu right so we're going to

00:11:20,160 --> 00:11:23,639
invest differentially there as you would

00:11:21,749 --> 00:11:24,870
imagine but how do we determine who's

00:11:23,639 --> 00:11:27,449
building the payments infrastructure

00:11:24,870 --> 00:11:29,339
who's building the lunch menu so what

00:11:27,449 --> 00:11:33,059
we've typically done as a security

00:11:29,339 --> 00:11:36,029
industry is we will ask people to fill

00:11:33,059 --> 00:11:37,860
out spreadsheets or surveys so tell us

00:11:36,029 --> 00:11:40,860
about your app so then we can decide

00:11:37,860 --> 00:11:42,959
what we think about it the problem is is

00:11:40,860 --> 00:11:45,420
that your people are going to avoid you

00:11:42,959 --> 00:11:46,319
you're not gonna catch everybody and one

00:11:45,420 --> 00:11:48,360
of the one of the things I've found

00:11:46,319 --> 00:11:49,920
which may or may not be surprising to

00:11:48,360 --> 00:11:52,350
the audience is that sometimes people

00:11:49,920 --> 00:11:54,660
lie and it's not necessarily malicious

00:11:52,350 --> 00:11:57,300
but they they just fill the thing out

00:11:54,660 --> 00:11:59,579
incorrectly we we may ask a question

00:11:57,300 --> 00:12:02,790
that we think is simple like does this

00:11:59,579 --> 00:12:04,829
application process secure data sounds

00:12:02,790 --> 00:12:07,259
simple the problem is what is secure

00:12:04,829 --> 00:12:09,000
data is it intellectual property is it

00:12:07,259 --> 00:12:11,490
credit cards is it social security

00:12:09,000 --> 00:12:13,199
numbers you're very it's gonna be very

00:12:11,490 --> 00:12:15,509
unlikely you get consistent answers to

00:12:13,199 --> 00:12:18,149
this and also what we typically do with

00:12:15,509 --> 00:12:20,399
this survey process is we ask one time

00:12:18,149 --> 00:12:22,800
right when you're first building the app

00:12:20,399 --> 00:12:24,120
and of course we all know applications

00:12:22,800 --> 00:12:25,680
and never change functionality over

00:12:24,120 --> 00:12:26,939
their lifetime right it's whatever it's

00:12:25,680 --> 00:12:29,730
you start with that's how it always

00:12:26,939 --> 00:12:32,550
intended so what we end up with is an

00:12:29,730 --> 00:12:34,589
incomplete data set that's incorrect and

00:12:32,550 --> 00:12:37,649
out-of-date right but this is what

00:12:34,589 --> 00:12:39,240
security teams have to use to decide

00:12:37,649 --> 00:12:42,209
where they're going to invest that's not

00:12:39,240 --> 00:12:44,519
really a great situation so one of the

00:12:42,209 --> 00:12:48,089
one of the neat things about you know as

00:12:44,519 --> 00:12:50,129
technology advances and as new patterns

00:12:48,089 --> 00:12:53,579
emerge and his new capabilities emerge

00:12:50,129 --> 00:12:55,649
you start to have the capabilities to

00:12:53,579 --> 00:12:57,480
start thinking about problems in in kind

00:12:55,649 --> 00:12:59,389
of a fundamentally different way and I

00:12:57,480 --> 00:13:01,139
think this tweet from from years ago

00:12:59,389 --> 00:13:04,379
captures it pretty well

00:13:01,139 --> 00:13:06,569
so Netflix is a large proponent of micro

00:13:04,379 --> 00:13:08,639
service architectures and you really

00:13:06,569 --> 00:13:09,749
there's there's just a lot of them you

00:13:08,639 --> 00:13:11,129
can't really think about how they all

00:13:09,749 --> 00:13:13,110
fit together it doesn't really work in

00:13:11,129 --> 00:13:15,089
your brain but you know there's api's

00:13:13,110 --> 00:13:16,790
there's data there's you know IPC

00:13:15,089 --> 00:13:18,150
mechanism you there's a bunch of

00:13:16,790 --> 00:13:19,680
information at your

00:13:18,150 --> 00:13:21,210
disposal to let you automate your

00:13:19,680 --> 00:13:24,660
reasoning about the environment so

00:13:21,210 --> 00:13:27,060
that's what we set out to do we wanted

00:13:24,660 --> 00:13:29,130
to create a an automated risk analysis

00:13:27,060 --> 00:13:32,520
for micro-service architectures so

00:13:29,130 --> 00:13:35,310
instead of asking developers to fill out

00:13:32,520 --> 00:13:37,170
a spreadsheet or a survey or rely on

00:13:35,310 --> 00:13:40,980
human judgment what we wanted to do was

00:13:37,170 --> 00:13:42,480
observe right so what's the connectivity

00:13:40,980 --> 00:13:44,670
look like you know how is the cloud

00:13:42,480 --> 00:13:46,920
configured how is the app configured and

00:13:44,670 --> 00:13:49,820
then we want to develop a risk scoring

00:13:46,920 --> 00:13:52,560
based on observations that we're making

00:13:49,820 --> 00:13:55,050
and we do it continuously right it's not

00:13:52,560 --> 00:13:56,640
just when you first create it so we we

00:13:55,050 --> 00:13:58,490
can tell when things change in the

00:13:56,640 --> 00:14:01,230
environment and we can adjust our

00:13:58,490 --> 00:14:02,700
classification so the heart of this

00:14:01,230 --> 00:14:04,860
system is based on what we would call an

00:14:02,700 --> 00:14:06,540
observation and this is an example

00:14:04,860 --> 00:14:08,970
observation this one here we call

00:14:06,540 --> 00:14:11,640
dependent applications so just imagine

00:14:08,970 --> 00:14:14,400
you run a service and say 300 other

00:14:11,640 --> 00:14:16,590
services depend on your service I might

00:14:14,400 --> 00:14:17,880
use that data and say oh okay well that

00:14:16,590 --> 00:14:19,560
might be a critical service because you

00:14:17,880 --> 00:14:21,720
have a lot of services are depending on

00:14:19,560 --> 00:14:23,880
you being available so what we can do is

00:14:21,720 --> 00:14:25,800
then use that data to kind of nudge a

00:14:23,880 --> 00:14:27,720
risk or up or down based on what we

00:14:25,800 --> 00:14:29,220
think about that but that's just one

00:14:27,720 --> 00:14:31,770
observation right so there's other

00:14:29,220 --> 00:14:34,200
observations you have there's is the

00:14:31,770 --> 00:14:36,390
system on the internet does it connect

00:14:34,200 --> 00:14:38,460
to a sensitive data store how many

00:14:36,390 --> 00:14:40,170
instances run in its scaling group or

00:14:38,460 --> 00:14:42,710
does it run in a sensitive cloud

00:14:40,170 --> 00:14:45,690
environment and really the key is that

00:14:42,710 --> 00:14:48,300
it's a flexible framework and you can

00:14:45,690 --> 00:14:50,280
add more observations and what we

00:14:48,300 --> 00:14:52,680
believe is that the more observations we

00:14:50,280 --> 00:14:54,120
make the better sense we have about the

00:14:52,680 --> 00:14:56,640
true risk and the true criticality of

00:14:54,120 --> 00:14:59,580
the system and then what we do is we add

00:14:56,640 --> 00:15:01,020
that with some other metadata to help

00:14:59,580 --> 00:15:02,100
our team become more efficient and more

00:15:01,020 --> 00:15:03,870
effective when they're working through

00:15:02,100 --> 00:15:05,700
say security incidents or security

00:15:03,870 --> 00:15:07,230
vulnerabilities so these are these are

00:15:05,700 --> 00:15:09,750
other elements of what you might call

00:15:07,230 --> 00:15:12,030
security support ability so for any

00:15:09,750 --> 00:15:13,980
given application like what's the what's

00:15:12,030 --> 00:15:15,750
the what team owns it what's their

00:15:13,980 --> 00:15:17,850
on-call rotation you know where is their

00:15:15,750 --> 00:15:19,470
Jenkins jobs where is their source code

00:15:17,850 --> 00:15:20,580
repo all these kind of things you want

00:15:19,470 --> 00:15:22,170
to have at hand when you're working

00:15:20,580 --> 00:15:24,330
security issues so it kind of aggregates

00:15:22,170 --> 00:15:27,360
all this data and then this is just an

00:15:24,330 --> 00:15:29,520
example scorecard of a few different

00:15:27,360 --> 00:15:31,470
measures and sort of how it rolls up and

00:15:29,520 --> 00:15:33,240
what you can imagine is that we have

00:15:31,470 --> 00:15:35,610
number of measures that are continuously

00:15:33,240 --> 00:15:38,250
sort of polling and evaluating the

00:15:35,610 --> 00:15:39,990
environment and the portfolio is is you

00:15:38,250 --> 00:15:42,000
know say many or several thousand

00:15:39,990 --> 00:15:43,620
applications and then what this does is

00:15:42,000 --> 00:15:44,670
it provides a security team a good start

00:15:43,620 --> 00:15:47,700
for thinking about where they're going

00:15:44,670 --> 00:15:49,620
to invest so the heart of this system

00:15:47,700 --> 00:15:51,270
what we built it on was called scum blur

00:15:49,620 --> 00:15:53,160
so we open-source scum blur a few years

00:15:51,270 --> 00:15:55,200
ago it's really a mechanism for kind of

00:15:53,160 --> 00:15:57,750
running these kind of data evaluation

00:15:55,200 --> 00:16:00,480
jobs and bringing them back and then the

00:15:57,750 --> 00:16:02,730
takeaways they're really theirs to me

00:16:00,480 --> 00:16:04,620
the key is that there's no no human

00:16:02,730 --> 00:16:06,900
requirement right there's nobody there's

00:16:04,620 --> 00:16:08,070
no survey provided there's no wandering

00:16:06,900 --> 00:16:09,570
to somebody answer the question

00:16:08,070 --> 00:16:12,150
incorrectly they're just observations

00:16:09,570 --> 00:16:13,650
right and this really helps us move away

00:16:12,150 --> 00:16:15,600
from that bridgekeeper model because

00:16:13,650 --> 00:16:17,190
it's very clear how we're evaluating the

00:16:15,600 --> 00:16:19,200
risk score and how we're generating that

00:16:17,190 --> 00:16:22,050
so it's objective it's transparent it's

00:16:19,200 --> 00:16:23,540
continuous so just wrapping up kind of

00:16:22,050 --> 00:16:25,950
getting back to those principles I

00:16:23,540 --> 00:16:27,600
brought up at the beginning transparency

00:16:25,950 --> 00:16:29,610
is really important I think this is

00:16:27,600 --> 00:16:30,990
perhaps the number one thing when you're

00:16:29,610 --> 00:16:32,820
thinking about building trust between a

00:16:30,990 --> 00:16:34,290
security team and a software team you

00:16:32,820 --> 00:16:35,640
have to be transparent you can't have

00:16:34,290 --> 00:16:37,590
this feeling that you're just making

00:16:35,640 --> 00:16:39,570
arbitrary decisions so anything we can

00:16:37,590 --> 00:16:42,780
do with technology that will promote

00:16:39,570 --> 00:16:44,820
this we want to invest in second write

00:16:42,780 --> 00:16:46,860
friction lowering friction to me the

00:16:44,820 --> 00:16:48,570
best way to lower friction in a human

00:16:46,860 --> 00:16:50,550
interaction is to not have the human

00:16:48,570 --> 00:16:52,650
interaction right so if we can remove

00:16:50,550 --> 00:16:54,360
the human interaction it's going to make

00:16:52,650 --> 00:16:56,010
it much simpler and then it's also going

00:16:54,360 --> 00:16:57,660
to lead to that last principle which is

00:16:56,010 --> 00:16:59,670
scale because we know we're going to be

00:16:57,660 --> 00:17:01,620
constrained resource wise but we know

00:16:59,670 --> 00:17:03,030
somehow the the engineering teams keep

00:17:01,620 --> 00:17:05,070
building more software so we have to

00:17:03,030 --> 00:17:06,270
figure out how to address that so I know

00:17:05,070 --> 00:17:08,340
that was a bunch of information but I

00:17:06,270 --> 00:17:10,210
that's it for me I certainly appreciate

00:17:08,340 --> 00:17:16,180
your time thanks for having me

00:17:10,210 --> 00:17:16,180

YouTube URL: https://www.youtube.com/watch?v=WGkAf4x94rQ


