Title: Multi-touch Screens in the Open Source World
Publication date: 2011-03-09
Playlist: Open Source Google Tech Talks
Description: 
	Google Tech Talks
June 9, 2008

ABSTRACT

Multi-touch is a new way of human computer interaction, which recognizes multiple simultaneous touch points, as opposed to the standard touchscreen, which recognizes only one touch point at a time. There are many forms of natural input in order to simplify the way people interact with their PC's and devices, however with the introduction of Apple iPhone/iPod Touch, Microsoft Surface and other devices, multi-touch is becoming more and more popular. In this tech talk I will describe what is the history behind multi-touch screens, what kind of multi-touch devices are available and how do they work, focusing mostly on FTIR and DI technique. We will discuss how to receive multi-touch events in our applications using TUIO protocol and how to write multi-touch applications using just a simulator. We will look into available open source projects that can be used to operate multi-touch screens and that are being developed by Natural User Interface Group (NUI Group) community.

Speaker: Pawel Solyga
Pawel Solyga is a computer science student at Politechnika Wroclawska, Poland. He is a co-founder of Natural User Interface Group (NUI Group), whose main areas of interest are modern user interfaces and in particular mutli-touch sreens. Pawel is also a former Google Summer of Code student. For GSoC 2008, he's working as organization administrator and mentor for the NUI Group. When not contributing to Open Source projects, he's a software engineer at Natural User Interface Europe AB, working on innovative multitouch applications.
Captions: 
	00:00:22,630 --> 00:00:26,470
good afternoon ladies and gentlemen and

00:00:24,490 --> 00:00:28,420
welcome to today's Tech Talk multi-touch

00:00:26,470 --> 00:00:30,190
screens in the open source world our

00:00:28,420 --> 00:00:31,779
speaker today is mr. pibbles so yeah

00:00:30,190 --> 00:00:32,470
from the Wroclaw University of

00:00:31,779 --> 00:00:34,480
Technology

00:00:32,470 --> 00:00:36,910
two-time google Summer of Code student

00:00:34,480 --> 00:00:39,850
and now a mentor for the natural user

00:00:36,910 --> 00:00:44,530
interface group well tick right Thank

00:00:39,850 --> 00:00:46,840
you Thank You Leslie so thank you for

00:00:44,530 --> 00:00:49,270
having me here it's my second tactic

00:00:46,840 --> 00:00:52,770
here I was here one year ago talking

00:00:49,270 --> 00:00:55,930
about my google Summer of Code project

00:00:52,770 --> 00:00:59,729
actually one of these projects will be

00:00:55,930 --> 00:01:02,290
gonna be a part of this detector today

00:00:59,729 --> 00:01:04,479
so I'd like to talk today about two

00:01:02,290 --> 00:01:06,520
things basically one is open-source

00:01:04,479 --> 00:01:09,790
software and the other thing is

00:01:06,520 --> 00:01:12,040
multi-touch screens and how those two

00:01:09,790 --> 00:01:15,250
can be used together and what can we do

00:01:12,040 --> 00:01:18,330
with them so as you know Google is

00:01:15,250 --> 00:01:21,070
supporting open-source in many ways

00:01:18,330 --> 00:01:22,360
Google Summer of Code Google highly open

00:01:21,070 --> 00:01:25,770
participation countries and many

00:01:22,360 --> 00:01:28,829
open-source project so that's a good

00:01:25,770 --> 00:01:34,509
place to talk about open source project

00:01:28,829 --> 00:01:36,850
so I can talk about history behind user

00:01:34,509 --> 00:01:39,810
interface in general and multi-touch

00:01:36,850 --> 00:01:42,189
screens then a little bit about

00:01:39,810 --> 00:01:45,340
available multi-touch devices that we

00:01:42,189 --> 00:01:48,609
can buy right now or see some prototypes

00:01:45,340 --> 00:01:52,270
and how those devices work and more

00:01:48,609 --> 00:01:55,210
details from the learn about the

00:01:52,270 --> 00:01:56,560
implementation that is required from the

00:01:55,210 --> 00:01:58,840
hardware point of view and from the

00:01:56,560 --> 00:02:02,399
software point of view what is required

00:01:58,840 --> 00:02:05,460
to make that multi-touch screen work

00:02:02,399 --> 00:02:08,380
then of course what kind of open source

00:02:05,460 --> 00:02:11,040
projects exist to enable you to operate

00:02:08,380 --> 00:02:13,090
multi-touch screen and how to create

00:02:11,040 --> 00:02:16,320
multi-touch screen using open source

00:02:13,090 --> 00:02:19,210
software and then a little bit about

00:02:16,320 --> 00:02:21,460
events that can gather sent from

00:02:19,210 --> 00:02:23,200
multi-touch device to your application

00:02:21,460 --> 00:02:25,690
and what can you do with them and about

00:02:23,200 --> 00:02:30,160
200 protocol which is tangible user

00:02:25,690 --> 00:02:32,370
interface objects protocol used by many

00:02:30,160 --> 00:02:36,160
open source projects for handling

00:02:32,370 --> 00:02:40,210
multi-touch events then about

00:02:36,160 --> 00:02:42,940
and the most fun part I think will be

00:02:40,210 --> 00:02:46,260
the demonstration of some of the

00:02:42,940 --> 00:02:51,190
applications and and multi-touch screen

00:02:46,260 --> 00:02:56,380
so let's jump right in into history so

00:02:51,190 --> 00:02:59,440
in early 70s at Xerox Palo Alto Research

00:02:56,380 --> 00:03:02,410
Center they've been working on something

00:02:59,440 --> 00:03:04,630
called win window icon menu pointing

00:03:02,410 --> 00:03:09,940
device which you are probably familiar

00:03:04,630 --> 00:03:12,660
with they worked on WIMP on his on their

00:03:09,940 --> 00:03:17,140
first computer

00:03:12,660 --> 00:03:21,510
Zarek's Alto with the graphic user

00:03:17,140 --> 00:03:25,990
interface which looked like this and

00:03:21,510 --> 00:03:28,870
right now after more than 30 years we

00:03:25,990 --> 00:03:32,830
have Windows Vista we have Mac OSX leo

00:03:28,870 --> 00:03:36,910
board or Linux with cool 3d effects for

00:03:32,830 --> 00:03:40,120
using xgl and really now not much has

00:03:36,910 --> 00:03:42,730
changed since since early 70s we still

00:03:40,120 --> 00:03:45,910
have Windows we still have icons menus

00:03:42,730 --> 00:03:49,680
and the pointing device keyboard and the

00:03:45,910 --> 00:03:49,680
mouse that is used as a pointing device

00:03:50,220 --> 00:04:01,330
in the meantime in the late 70s at MIT

00:03:56,550 --> 00:04:04,300
speech interface group they worked on a

00:04:01,330 --> 00:04:09,340
more natural way of interacting with

00:04:04,300 --> 00:04:11,830
computer I think the most interesting

00:04:09,340 --> 00:04:15,160
project or those two the pushed out

00:04:11,830 --> 00:04:20,709
there in 1979 and a spatial data

00:04:15,160 --> 00:04:22,470
management project in 1980 using the the

00:04:20,709 --> 00:04:25,480
pushed out there you could basically

00:04:22,470 --> 00:04:27,250
move the objects by showing them by your

00:04:25,480 --> 00:04:32,950
finger without even touching the screen

00:04:27,250 --> 00:04:36,280
and also use the voice comments to to do

00:04:32,950 --> 00:04:39,790
something like take this object move it

00:04:36,280 --> 00:04:42,940
here and things like that and the

00:04:39,790 --> 00:04:44,530
spatial data management project is more

00:04:42,940 --> 00:04:46,419
about Zoe

00:04:44,530 --> 00:04:48,340
interfaces which is zoom able user

00:04:46,419 --> 00:04:50,980
interface which is now

00:04:48,340 --> 00:04:54,010
used also in multi-touch screens world

00:04:50,980 --> 00:04:59,610
where you can zoom in zoom out and have

00:04:54,010 --> 00:05:02,949
a big work space on which you can work

00:04:59,610 --> 00:05:05,979
and also I won't like I would like to

00:05:02,949 --> 00:05:09,070
mention that computer mouse has been

00:05:05,979 --> 00:05:12,639
around it took Mouse around more than 30

00:05:09,070 --> 00:05:16,660
years also to be widely used because it

00:05:12,639 --> 00:05:20,169
was invented in 663 and it was widely

00:05:16,660 --> 00:05:23,520
used with Windows 95 so it was more than

00:05:20,169 --> 00:05:29,200
more than 30 years to be widely used so

00:05:23,520 --> 00:05:34,090
even though multi-touch screens it's not

00:05:29,200 --> 00:05:36,220
really something new because even in an

00:05:34,090 --> 00:05:37,360
85 the bill paxton from Microsoft

00:05:36,220 --> 00:05:40,620
Research he's working right now at

00:05:37,360 --> 00:05:43,289
Microsoft Research but an 85 he was

00:05:40,620 --> 00:05:46,660
working at the University of Toronto he

00:05:43,289 --> 00:05:48,729
started project called the multi-touch

00:05:46,660 --> 00:05:52,240
three-dimensional touch sensitive tablet

00:05:48,729 --> 00:05:55,180
and 85 so multi-touch isn't really

00:05:52,240 --> 00:05:58,120
something new it was it's known for more

00:05:55,180 --> 00:06:05,590
there more than 30 years 20 years right

00:05:58,120 --> 00:06:09,010
now so we have so sometime to get it to

00:06:05,590 --> 00:06:11,919
state where it is widely used then later

00:06:09,010 --> 00:06:17,669
on a 95 key also work on project called

00:06:11,919 --> 00:06:20,860
interactive desk it was a project with

00:06:17,669 --> 00:06:26,560
Microsoft Research and University of

00:06:20,860 --> 00:06:30,580
Toronto so what the multi-touch screen

00:06:26,560 --> 00:06:32,500
really is and how does it work you're

00:06:30,580 --> 00:06:35,169
probably familiar with the regular

00:06:32,500 --> 00:06:38,919
touchscreen which only enable you to

00:06:35,169 --> 00:06:42,220
sense one point of contact so like

00:06:38,919 --> 00:06:46,300
machines like ATMs or palm tops or

00:06:42,220 --> 00:06:48,700
tablets they usually just have the

00:06:46,300 --> 00:06:52,889
touchscreen which can which can only

00:06:48,700 --> 00:06:55,720
sense one one point multi-touch screen

00:06:52,889 --> 00:06:58,599
allows you to sense many points

00:06:55,720 --> 00:07:01,150
simultaneously so at the same at the

00:06:58,599 --> 00:07:01,750
same time you can use many fingers you

00:07:01,150 --> 00:07:05,320
can

00:07:01,750 --> 00:07:08,020
also multi the screen is also a

00:07:05,320 --> 00:07:10,030
multi-user device however because it

00:07:08,020 --> 00:07:12,580
allows many users to work on the same

00:07:10,030 --> 00:07:16,660
screen at the same time there are

00:07:12,580 --> 00:07:22,390
different techniques for doing

00:07:16,660 --> 00:07:23,980
multi-touch screens the one that I want

00:07:22,390 --> 00:07:25,210
to talk about is the frustrated total

00:07:23,980 --> 00:07:28,180
internal reflection

00:07:25,210 --> 00:07:32,230
it's called FTIR and diffused

00:07:28,180 --> 00:07:37,300
illumination di and those two are based

00:07:32,230 --> 00:07:40,810
on image processing mostly I'm going to

00:07:37,300 --> 00:07:43,360
talk about them a little bit more in the

00:07:40,810 --> 00:07:47,020
next slides there are also many other

00:07:43,360 --> 00:07:49,840
ways to handle multi-touch there is some

00:07:47,020 --> 00:07:52,180
electronic field sensing technique which

00:07:49,840 --> 00:07:54,190
was used by Mitsubishi electronic

00:07:52,180 --> 00:07:56,620
research lab there are also techniques

00:07:54,190 --> 00:07:59,350
that are patented for example the

00:07:56,620 --> 00:08:04,090
technique that is used and iPhones iPod

00:07:59,350 --> 00:08:06,520
Touch or MacBook Air and pro multi multi

00:08:04,090 --> 00:08:08,830
touch pads those are from the company

00:08:06,520 --> 00:08:12,400
that upwork wired a couple years ago

00:08:08,830 --> 00:08:15,400
called finger works so I'm not going to

00:08:12,400 --> 00:08:19,120
talk about those but more I gonna poke

00:08:15,400 --> 00:08:24,010
focus more on image processing ways of

00:08:19,120 --> 00:08:25,979
doing multi-touch screens and basically

00:08:24,010 --> 00:08:28,660
multi-touch is a new way of

00:08:25,979 --> 00:08:32,620
human-computer interaction that's how

00:08:28,660 --> 00:08:35,890
it's most many ways in many places

00:08:32,620 --> 00:08:37,719
described so about the available

00:08:35,890 --> 00:08:40,089
solutions what kind of multi-touch

00:08:37,719 --> 00:08:42,430
devices we have right now on the market

00:08:40,089 --> 00:08:45,520
or the prototypes that that have been

00:08:42,430 --> 00:08:52,180
developed one of them is the reactive

00:08:45,520 --> 00:08:54,040
vision table or react table it was it

00:08:52,180 --> 00:08:56,620
was made at the one of the University

00:08:54,040 --> 00:09:00,850
and one of the universities at in Spain

00:08:56,620 --> 00:09:03,730
it's a sound synthesizer which allows

00:09:00,850 --> 00:09:06,580
you to sense multiple fingers and also

00:09:03,730 --> 00:09:12,470
sends markers that are placed on the

00:09:06,580 --> 00:09:13,820
screen those markers are named fiducials

00:09:12,470 --> 00:09:17,950
and as you can see there are different

00:09:13,820 --> 00:09:20,480
different markers on the screen and this

00:09:17,950 --> 00:09:23,390
multi-touch screen allows you to sense

00:09:20,480 --> 00:09:25,820
the position of them also rotation and

00:09:23,390 --> 00:09:28,100
that way and I will enable you to create

00:09:25,820 --> 00:09:30,470
really really innovative applications

00:09:28,100 --> 00:09:33,890
like this one is that this is a sound

00:09:30,470 --> 00:09:38,060
something some synthesizer that was also

00:09:33,890 --> 00:09:40,190
used at one of the concerts of the orc

00:09:38,060 --> 00:09:43,130
I'm not sure if you if you heard about

00:09:40,190 --> 00:09:44,000
that and the other device is called

00:09:43,130 --> 00:09:47,870
diamond touch

00:09:44,000 --> 00:09:52,900
it's from Mitsubishi electronic research

00:09:47,870 --> 00:09:56,840
lab it allows you to also sense multiple

00:09:52,900 --> 00:10:00,650
fingers at the same time and allows you

00:09:56,840 --> 00:10:03,200
to identify which finger belongs to

00:10:00,650 --> 00:10:05,000
which person there are special chairs

00:10:03,200 --> 00:10:08,860
out there it uses the technique called

00:10:05,000 --> 00:10:13,910
electronic field sensing so thanks to

00:10:08,860 --> 00:10:18,170
electronic field and our body it allows

00:10:13,910 --> 00:10:21,560
you to sense which finger belongs to to

00:10:18,170 --> 00:10:24,110
who and you can up to four

00:10:21,560 --> 00:10:27,410
I think there's up to four persons can

00:10:24,110 --> 00:10:30,500
use the table at the same time and also

00:10:27,410 --> 00:10:31,810
there are other devices that are

00:10:30,500 --> 00:10:38,510
available that you probably are familiar

00:10:31,810 --> 00:10:40,310
with it's Jeff Hannes FTIR screens that

00:10:38,510 --> 00:10:44,930
I'm gonna talk about a little more and

00:10:40,310 --> 00:10:45,710
about the FTIR itself later Microsoft

00:10:44,930 --> 00:10:48,020
Surface

00:10:45,710 --> 00:10:53,180
it's space on this diffuse illumination

00:10:48,020 --> 00:10:56,300
technique and also iPhone and iPod Touch

00:10:53,180 --> 00:10:59,570
this is based on the on the technology

00:10:56,300 --> 00:11:01,700
from the company finger works of course

00:10:59,570 --> 00:11:03,950
there also there's also MacBook Air and

00:11:01,700 --> 00:11:08,150
my pro which has the same technology

00:11:03,950 --> 00:11:11,830
used in iPhone and iPod Touch just

00:11:08,150 --> 00:11:14,150
without the screen and there's one more

00:11:11,830 --> 00:11:17,720
just I don't I want I would like to

00:11:14,150 --> 00:11:22,839
mention is called chess moutains L'Amour

00:11:17,720 --> 00:11:26,870
it's a multi-touch screen small one

00:11:22,839 --> 00:11:29,390
which is used for visualizations and

00:11:26,870 --> 00:11:33,280
also for sound synthesizer at the sound

00:11:29,390 --> 00:11:36,350
sound to sizer and has a really great

00:11:33,280 --> 00:11:38,030
configurable and programmable and

00:11:36,350 --> 00:11:43,880
graphic user interface this is the one

00:11:38,030 --> 00:11:46,100
on the left so the list of those devices

00:11:43,880 --> 00:11:47,959
can go on and go on and we could talk

00:11:46,100 --> 00:11:50,990
about an hour about Yahoo that are

00:11:47,959 --> 00:11:57,230
available but the one that I would like

00:11:50,990 --> 00:12:01,220
to mention after today's project by john

00:11:57,230 --> 00:12:06,020
lee a researcher from Carnegie Mellon

00:12:01,220 --> 00:12:09,800
University which worked on some remote

00:12:06,020 --> 00:12:16,130
hacks that allows you to send multiple

00:12:09,800 --> 00:12:20,209
points using just v controller and it's

00:12:16,130 --> 00:12:23,089
embedded infrared infrared camera I will

00:12:20,209 --> 00:12:26,030
try to present that during during this

00:12:23,089 --> 00:12:32,660
detector how does it work and what can

00:12:26,030 --> 00:12:36,170
we do that there are also Microsoft and

00:12:32,660 --> 00:12:41,690
Dell is working on some solutions for

00:12:36,170 --> 00:12:44,900
multi-touch laptops and recently they

00:12:41,690 --> 00:12:49,130
announced a technological touch wall or

00:12:44,900 --> 00:12:52,850
Lasser touch which uses three lathers to

00:12:49,130 --> 00:12:55,459
sense multi-touch this is the video in

00:12:52,850 --> 00:12:58,670
the middle and also they announced that

00:12:55,459 --> 00:13:03,500
Windows 7 will be full multi-touch

00:12:58,670 --> 00:13:07,250
system the video on the right with Dell

00:13:03,500 --> 00:13:12,170
Latitude XT laptop with some duo Sense

00:13:07,250 --> 00:13:14,870
technology that thou has developed but

00:13:12,170 --> 00:13:18,310
let's switch maybe to those technologies

00:13:14,870 --> 00:13:22,160
behind I've used image image processing

00:13:18,310 --> 00:13:25,100
those are the demos by Jeff Hahn from

00:13:22,160 --> 00:13:29,650
the company that he started called

00:13:25,100 --> 00:13:33,949
perceptive pixel in 2005 he showed first

00:13:29,650 --> 00:13:36,130
prototype of his device using uses the

00:13:33,949 --> 00:13:42,050
frustrated total internal reflection

00:13:36,130 --> 00:13:44,420
for sensing multi-touch tenon and 2006 a

00:13:42,050 --> 00:13:49,160
little bit bigger prototype with some

00:13:44,420 --> 00:13:55,520
really impressive demo applications and

00:13:49,160 --> 00:14:00,200
in 2007 he showed case pretty big wall a

00:13:55,520 --> 00:14:02,150
multi-touch wall with many great great

00:14:00,200 --> 00:14:05,030
multi-touch applications this is for

00:14:02,150 --> 00:14:10,580
example Google Google Earth using using

00:14:05,030 --> 00:14:14,090
multi-touch so what really makes

00:14:10,580 --> 00:14:15,950
multi-touch screens work actually we can

00:14:14,090 --> 00:14:18,230
talk about image processing so for image

00:14:15,950 --> 00:14:21,890
processing techniques it's it's light

00:14:18,230 --> 00:14:27,830
it's light it's all sorts of light maybe

00:14:21,890 --> 00:14:31,060
not that big bulb but actually more we

00:14:27,830 --> 00:14:34,460
use LEDs different kind of lights

00:14:31,060 --> 00:14:37,820
usually it's it's infrared LEDs the

00:14:34,460 --> 00:14:40,940
actually the top top left image shows my

00:14:37,820 --> 00:14:45,650
lights that I use for building my first

00:14:40,940 --> 00:14:48,320
multi-touch prototype and those LEDs are

00:14:45,650 --> 00:14:49,670
used for the technique that are going to

00:14:48,320 --> 00:14:52,370
describe right now it's called

00:14:49,670 --> 00:14:56,060
frustrated total internal reflection fgr

00:14:52,370 --> 00:15:00,160
and how does the work so you can imagine

00:14:56,060 --> 00:15:03,980
that we have a acrylic piece of acrylic

00:15:00,160 --> 00:15:07,160
and we have infrared LEDs that shine on

00:15:03,980 --> 00:15:11,780
the both edges and the light from

00:15:07,160 --> 00:15:14,810
infrared LED bounces inside inside the

00:15:11,780 --> 00:15:17,600
acrylic and we have also an infrared

00:15:14,810 --> 00:15:21,620
camera that can sense those this

00:15:17,600 --> 00:15:26,530
infrared light and once we once we touch

00:15:21,620 --> 00:15:30,080
the screen the light frustrates

00:15:26,530 --> 00:15:32,240
frustrates from the from the acrylic and

00:15:30,080 --> 00:15:35,230
it's picked up by the infrared camera

00:15:32,240 --> 00:15:37,490
and what we see it on the video input is

00:15:35,230 --> 00:15:40,700
something like this image something like

00:15:37,490 --> 00:15:43,970
this one with those white blobs in the

00:15:40,700 --> 00:15:45,900
place where you where you touch so then

00:15:43,970 --> 00:15:49,290
later on using

00:15:45,900 --> 00:15:51,390
using image processing and algorithm

00:15:49,290 --> 00:15:56,720
like blob detection or blob tracking you

00:15:51,390 --> 00:15:59,760
can really easily sense multi-touch

00:15:56,720 --> 00:16:02,180
using this FTR technique and this is

00:15:59,760 --> 00:16:06,060
that that technique that Jeff Han

00:16:02,180 --> 00:16:08,280
invented three two years ago there's one

00:16:06,060 --> 00:16:10,110
problem when you're trying to if you

00:16:08,280 --> 00:16:12,060
don't have a silicon rubber that is

00:16:10,110 --> 00:16:14,430
sometimes needed there's a problem when

00:16:12,060 --> 00:16:17,610
you're trying to draw drug-drug things

00:16:14,430 --> 00:16:20,010
around on the screen so we use silicon

00:16:17,610 --> 00:16:23,040
rubber as an another layer on top of the

00:16:20,010 --> 00:16:25,620
acrylic and then a project projection

00:16:23,040 --> 00:16:27,750
surface projection screen and the

00:16:25,620 --> 00:16:31,460
silicon rubber really helps and when you

00:16:27,750 --> 00:16:31,460
do things like drug drag-and-drop

00:16:32,270 --> 00:16:39,120
the good thing about FTIR technique is

00:16:35,940 --> 00:16:42,270
that the blobs that we get as you can

00:16:39,120 --> 00:16:44,190
see on this image on the right or have

00:16:42,270 --> 00:16:47,310
have really strong contrast and it's

00:16:44,190 --> 00:16:51,950
really easy to find them using using

00:16:47,310 --> 00:16:55,440
image processing techniques the final

00:16:51,950 --> 00:16:56,190
final setup of FTIR screen looks

00:16:55,440 --> 00:16:59,220
something like that

00:16:56,190 --> 00:17:05,000
we have a projector we have a mirror and

00:16:59,220 --> 00:17:08,030
we have a computer acrylic lats and

00:17:05,000 --> 00:17:11,310
infrared camera which can see those

00:17:08,030 --> 00:17:14,790
white white blobs when you touch when it

00:17:11,310 --> 00:17:18,030
has the surface so that's the basic idea

00:17:14,790 --> 00:17:20,880
behind the FDLR screen

00:17:18,030 --> 00:17:22,800
another technique that is for example

00:17:20,880 --> 00:17:26,450
used by a Microsoft Surface

00:17:22,800 --> 00:17:30,000
it's called di diffused illumination

00:17:26,450 --> 00:17:33,150
it's almost the same as the FTA are but

00:17:30,000 --> 00:17:35,340
instead of having I infrared LEDs on the

00:17:33,150 --> 00:17:38,430
edges of the screen we actually have the

00:17:35,340 --> 00:17:42,390
infrared illuminators just next to

00:17:38,430 --> 00:17:44,220
infrared camera which shine a light in

00:17:42,390 --> 00:17:48,840
the direction of our hands into the

00:17:44,220 --> 00:17:53,040
direction of the surface and what we get

00:17:48,840 --> 00:17:55,650
is the image like this one on the on the

00:17:53,040 --> 00:17:57,320
on the top the rarer it's this this one

00:17:55,650 --> 00:18:00,020
this technique is also called rare

00:17:57,320 --> 00:18:03,040
rare diffuse illumination because we use

00:18:00,020 --> 00:18:05,540
the light from infrared illuminators

00:18:03,040 --> 00:18:07,870
however there is also a technique called

00:18:05,540 --> 00:18:11,390
from the front diffuse illumination

00:18:07,870 --> 00:18:15,080
which where you don't really have to use

00:18:11,390 --> 00:18:18,950
infrared illuminators or you can just

00:18:15,080 --> 00:18:21,500
use the ambient light that is around and

00:18:18,950 --> 00:18:26,210
in the room that you actually have the

00:18:21,500 --> 00:18:29,690
multi-touch screen so those two video

00:18:26,210 --> 00:18:32,960
input frames showed on the right this

00:18:29,690 --> 00:18:35,960
one and the rare D I showed you how do

00:18:32,960 --> 00:18:39,400
you see the fingers when they touch the

00:18:35,960 --> 00:18:42,260
surface and the other one the front di

00:18:39,400 --> 00:18:44,630
using the ambient light shows you how do

00:18:42,260 --> 00:18:47,920
you see the shadow that is created when

00:18:44,630 --> 00:18:54,020
you touch when you touch the front di

00:18:47,920 --> 00:18:56,000
multi-touch screen the final di setup

00:18:54,020 --> 00:18:58,960
looks something like this so it's pretty

00:18:56,000 --> 00:19:02,930
pretty much the same as as the FTIR one

00:18:58,960 --> 00:19:05,450
but instead you have those infrared

00:19:02,930 --> 00:19:07,820
illuminators if you use front di or you

00:19:05,450 --> 00:19:13,640
don't really have nothing at all you

00:19:07,820 --> 00:19:17,540
have nothing at all if you if you use if

00:19:13,640 --> 00:19:20,180
you use where di you you have those

00:19:17,540 --> 00:19:22,520
infrared illuminators if you use from di

00:19:20,180 --> 00:19:26,060
you use ambient light so you don't

00:19:22,520 --> 00:19:31,510
really need them so how does how does

00:19:26,060 --> 00:19:37,330
the look from the camera point of view

00:19:31,510 --> 00:19:39,680
what I see on on on the video capture

00:19:37,330 --> 00:19:41,690
when I capture the the frame from the

00:19:39,680 --> 00:19:45,590
camera is something like that and what I

00:19:41,690 --> 00:19:47,780
have to do is use special image

00:19:45,590 --> 00:19:50,750
processing filters the one that we use

00:19:47,780 --> 00:19:53,920
is high pass filter to filter out

00:19:50,750 --> 00:19:57,140
everything other than the touch and

00:19:53,920 --> 00:20:00,900
actually it works pretty well this is

00:19:57,140 --> 00:20:03,720
this is the example that I've put in

00:20:00,900 --> 00:20:05,730
in quartz composer on Mac OSX using just

00:20:03,720 --> 00:20:11,789
the filters that are available in Mac

00:20:05,730 --> 00:20:16,070
Mac OSX and this is the output of the

00:20:11,789 --> 00:20:18,539
filter chain and how we can sense

00:20:16,070 --> 00:20:20,340
multiple fingers and how we can filter

00:20:18,539 --> 00:20:24,860
out everything at it and then the touch

00:20:20,340 --> 00:20:27,710
on the on the diffused illumination

00:20:24,860 --> 00:20:31,230
setup so actually you can see that

00:20:27,710 --> 00:20:34,799
here's the the input video and the

00:20:31,230 --> 00:20:39,960
output shows pretty well when when and

00:20:34,799 --> 00:20:41,909
where you touch the screen so actually

00:20:39,960 --> 00:20:44,940
you have to do those image processing

00:20:41,909 --> 00:20:47,370
things so you start with video input you

00:20:44,940 --> 00:20:49,559
capture the frames then you do image

00:20:47,370 --> 00:20:52,049
filtering using high-pass filters

00:20:49,559 --> 00:20:55,169
background subtraction and other other

00:20:52,049 --> 00:20:58,649
filters that are used for that when you

00:20:55,169 --> 00:21:02,490
get the really clear image of the

00:20:58,649 --> 00:21:07,130
fingers which usually is the Binnorie

00:21:02,490 --> 00:21:09,330
image you use the blob detection

00:21:07,130 --> 00:21:13,440
algorithm and the size of the blobs and

00:21:09,330 --> 00:21:18,059
then later on you do blow up tracking to

00:21:13,440 --> 00:21:21,809
assign finger and ID and track its

00:21:18,059 --> 00:21:26,100
position based on the data from the blob

00:21:21,809 --> 00:21:28,320
tracking algorithm you can easily send

00:21:26,100 --> 00:21:32,580
events to to your to your user

00:21:28,320 --> 00:21:34,649
application and based on the events that

00:21:32,580 --> 00:21:39,419
you going to send you can do get your

00:21:34,649 --> 00:21:40,950
recognition before we go to the before I

00:21:39,419 --> 00:21:43,950
going to talk about the open source

00:21:40,950 --> 00:21:46,850
project that are used to handle

00:21:43,950 --> 00:21:50,730
multi-touch and operate multi-touch

00:21:46,850 --> 00:21:55,710
screens I would like to talk a little

00:21:50,730 --> 00:21:58,770
bit about anyway group it's our natural

00:21:55,710 --> 00:22:02,909
user interface group it's an open source

00:21:58,770 --> 00:22:06,000
community behind modern user interfaces

00:22:02,909 --> 00:22:08,419
and in particular multi-touch screens we

00:22:06,000 --> 00:22:10,660
started that two years ago in September

00:22:08,419 --> 00:22:14,050
start the forum

00:22:10,660 --> 00:22:16,360
in January 2007 and most of the project

00:22:14,050 --> 00:22:18,580
that we work on or released as open

00:22:16,360 --> 00:22:22,240
source software we have a forum block

00:22:18,580 --> 00:22:25,600
Vikki IRC Channel and right now we have

00:22:22,240 --> 00:22:28,300
over 2,000 members that are working on

00:22:25,600 --> 00:22:31,090
different tutorials hardware and

00:22:28,300 --> 00:22:33,820
software tutorials also share a lot of

00:22:31,090 --> 00:22:37,660
photos videos how to create your own

00:22:33,820 --> 00:22:40,960
multi-touch screen and we really have a

00:22:37,660 --> 00:22:42,750
lot of students PhD students researchers

00:22:40,960 --> 00:22:45,040
from around the world

00:22:42,750 --> 00:22:47,470
programmers graphic designers interface

00:22:45,040 --> 00:22:51,910
designers so it's really it's really

00:22:47,470 --> 00:22:54,910
really nice community for example from

00:22:51,910 --> 00:23:00,280
May 2008 this is a new a group comm we

00:22:54,910 --> 00:23:03,100
we got almost 60,000 visits from five

00:23:00,280 --> 00:23:06,220
over 5,000 different cities all over the

00:23:03,100 --> 00:23:09,190
world so we are getting a lot of

00:23:06,220 --> 00:23:12,370
attention and we are really happy about

00:23:09,190 --> 00:23:17,200
that and our good thing about that is

00:23:12,370 --> 00:23:19,960
that actually in 2008 we got into google

00:23:17,200 --> 00:23:21,310
Summer of Code it's our first time in

00:23:19,960 --> 00:23:27,250
google Summer of Code

00:23:21,310 --> 00:23:31,000
I'm a former ji-suk student and for this

00:23:27,250 --> 00:23:32,470
organization I'm also a mentor and we

00:23:31,000 --> 00:23:36,670
group is an umbrella organization

00:23:32,470 --> 00:23:40,720
because we have a set of projects that

00:23:36,670 --> 00:23:44,170
we are working on so we got seven slots

00:23:40,720 --> 00:23:48,340
which is really amazing number we we

00:23:44,170 --> 00:23:52,620
received over 40 over 40 amazing

00:23:48,340 --> 00:23:56,080
proposals and it was really hard job to

00:23:52,620 --> 00:23:58,660
pick those only those seven those are

00:23:56,080 --> 00:24:04,000
the projects that we are we are working

00:23:58,660 --> 00:24:06,610
on with the students some of them are

00:24:04,000 --> 00:24:09,330
really really really interesting and for

00:24:06,610 --> 00:24:12,760
example South Sandler this is a really

00:24:09,330 --> 00:24:16,030
great student he's been in our community

00:24:12,760 --> 00:24:19,570
for from almost a peck at the beginning

00:24:16,030 --> 00:24:21,850
and he's actually working on a new I

00:24:19,570 --> 00:24:24,220
touch framework and and flash to handle

00:24:21,850 --> 00:24:26,760
multi-touch applications and there is a

00:24:24,220 --> 00:24:29,170
lot more like Mac OSX open touch

00:24:26,760 --> 00:24:31,210
conversion this is I've been working on

00:24:29,170 --> 00:24:34,120
the open touch project during the google

00:24:31,210 --> 00:24:37,300
Summer of Code 2007 and right now the

00:24:34,120 --> 00:24:40,300
student is we convert convert this code

00:24:37,300 --> 00:24:42,820
that I wrote in C++ to make it more OSX

00:24:40,300 --> 00:24:48,610
specific and when he will write it and

00:24:42,820 --> 00:24:51,550
and and imported to Objective C so I've

00:24:48,610 --> 00:24:53,500
talked a little bit about techniques

00:24:51,550 --> 00:24:57,610
that can be used for sensing multi touch

00:24:53,500 --> 00:25:00,600
and multi-touch in general and so it's

00:24:57,610 --> 00:25:03,240
maybe now switch to to those multi-touch

00:25:00,600 --> 00:25:07,690
open-source projects that are available

00:25:03,240 --> 00:25:11,080
and we can use to operate multi-touch

00:25:07,690 --> 00:25:14,770
screen so this is this is a list of some

00:25:11,080 --> 00:25:18,550
of the projects that noe group is

00:25:14,770 --> 00:25:23,140
working on and also our that our other

00:25:18,550 --> 00:25:24,730
developers are working on the two three

00:25:23,140 --> 00:25:26,500
that I'm going to talk about today is

00:25:24,730 --> 00:25:29,200
called the first one is called touch

00:25:26,500 --> 00:25:31,810
sleep the other one is Tabata and the

00:25:29,200 --> 00:25:35,040
open print touch this is my project from

00:25:31,810 --> 00:25:37,330
google Summer of Code 2007 there's a why

00:25:35,040 --> 00:25:39,760
there's a lot of different other other

00:25:37,330 --> 00:25:42,700
projects that are available likely they

00:25:39,760 --> 00:25:46,500
leap FA GS and it's Britain and in part

00:25:42,700 --> 00:25:50,230
on MPX it's an extension to X Windows

00:25:46,500 --> 00:25:54,370
Server to handle multi-touch on X

00:25:50,230 --> 00:25:59,110
servers open table it's written in Java

00:25:54,370 --> 00:26:01,360
dotnet multi-touch framework is wrapper

00:25:59,110 --> 00:26:05,110
to to touch sleep in c-sharp

00:26:01,360 --> 00:26:07,360
touch api is a project and flash that

00:26:05,110 --> 00:26:10,000
allows you to receive multi-touch events

00:26:07,360 --> 00:26:11,530
and flash BB touch is a new project that

00:26:10,000 --> 00:26:16,890
is right now on the open touch

00:26:11,530 --> 00:26:16,890
repository it's for objective-c

00:26:17,220 --> 00:26:23,110
project for handling FTIR screens and

00:26:20,140 --> 00:26:25,870
there's a lot a lot more actually I

00:26:23,110 --> 00:26:28,970
typed in multi-touch and at Google Code

00:26:25,870 --> 00:26:32,780
project hosting and

00:26:28,970 --> 00:26:36,590
I got 24 different projects some of them

00:26:32,780 --> 00:26:40,190
are here some are not here but there's

00:26:36,590 --> 00:26:44,840
really a lot going on in open-source and

00:26:40,190 --> 00:26:46,850
multi-touch so I'm gonna talk a little

00:26:44,840 --> 00:26:50,540
bit about touch sleep this is actually

00:26:46,850 --> 00:26:53,660
the first open source project to operate

00:26:50,540 --> 00:26:57,230
multi-touch screens started by David

00:26:53,660 --> 00:27:01,640
walling from Pennsylvania it supports

00:26:57,230 --> 00:27:04,400
both FTIR and di techniques right now we

00:27:01,640 --> 00:27:07,040
will start only with FTIR support and

00:27:04,400 --> 00:27:09,950
right now there's like seven developers

00:27:07,040 --> 00:27:12,320
that work on this project and even

00:27:09,950 --> 00:27:16,760
though the first version was released

00:27:12,320 --> 00:27:19,820
only by David it uses OpenCV it's the

00:27:16,760 --> 00:27:22,000
library released a couple years ago by

00:27:19,820 --> 00:27:26,390
PI Intel open computer vision library

00:27:22,000 --> 00:27:31,010
for it uses it for image filtering and

00:27:26,390 --> 00:27:34,730
it supports the 2eo protocol for sending

00:27:31,010 --> 00:27:36,830
events to to your final application I'm

00:27:34,730 --> 00:27:40,750
gonna talk about two-year protocol in a

00:27:36,830 --> 00:27:45,710
little bit and it uses a wide range of

00:27:40,750 --> 00:27:48,290
external libraries to handle cameras and

00:27:45,710 --> 00:27:51,410
you can use TS video lip video wrappers

00:27:48,290 --> 00:27:53,630
CMU firewire driver and video for linux

00:27:51,410 --> 00:28:00,100
so you can use many different cameras

00:27:53,630 --> 00:28:00,100
with roughly how does it work

00:28:00,130 --> 00:28:07,280
this is a showcase of some of the

00:28:02,450 --> 00:28:10,190
applications that are that are made

00:28:07,280 --> 00:28:15,230
using touch lip touch lip is used for

00:28:10,190 --> 00:28:17,060
for blob detection blob tracking and

00:28:15,230 --> 00:28:21,020
those image filters that are needed for

00:28:17,060 --> 00:28:23,990
a tird or di setups and for sending

00:28:21,020 --> 00:28:26,800
events to to your final applications so

00:28:23,990 --> 00:28:30,830
here you have some smoke demo in OpenGL

00:28:26,800 --> 00:28:34,390
here is some water effect in flash some

00:28:30,830 --> 00:28:38,650
image viewer also in flash some

00:28:34,390 --> 00:28:41,500
application and processing on the left

00:28:38,650 --> 00:28:44,650
those although all those videos are from

00:28:41,500 --> 00:28:49,660
our and we group members and that kind

00:28:44,650 --> 00:28:53,910
of videos are available also at our web

00:28:49,660 --> 00:28:53,910
page if you'd like to check it out

00:29:01,780 --> 00:29:07,940
my project and I was working on Google

00:29:05,360 --> 00:29:10,210
doing Google Summer of Code 2007 it's

00:29:07,940 --> 00:29:13,820
called open touch this is actually how

00:29:10,210 --> 00:29:17,960
the how the input from FTIR screen looks

00:29:13,820 --> 00:29:20,570
like you can see those white white blobs

00:29:17,960 --> 00:29:22,970
when I touch the screen and how the blob

00:29:20,570 --> 00:29:27,950
detection algorithm works and the texts

00:29:22,970 --> 00:29:34,370
where is the what's the position of the

00:29:27,950 --> 00:29:37,460
finger so this was blob blob detection

00:29:34,370 --> 00:29:41,210
algorithm stration this is a blob

00:29:37,460 --> 00:29:43,970
detection and blob tracking algorithm

00:29:41,210 --> 00:29:49,300
instruction so we can see that each

00:29:43,970 --> 00:29:53,980
finger after it is detected it has ID

00:29:49,300 --> 00:29:57,650
and using blob tracking algorithm we can

00:29:53,980 --> 00:30:00,620
track track the fingers and send those

00:29:57,650 --> 00:30:03,440
events to some external application as

00:30:00,620 --> 00:30:05,810
you can see on the top right this is

00:30:03,440 --> 00:30:08,030
actually the external application that

00:30:05,810 --> 00:30:13,910
receives the events from from open touch

00:30:08,030 --> 00:30:18,020
using the two-year protocol this is

00:30:13,910 --> 00:30:21,890
another example simple example open

00:30:18,020 --> 00:30:24,890
touch is sending even to processing

00:30:21,890 --> 00:30:26,950
application which is a Java environment

00:30:24,890 --> 00:30:31,460
for doing visualizations and this is

00:30:26,950 --> 00:30:34,820
just a simple demo of some drawing with

00:30:31,460 --> 00:30:39,970
multi-touch so actually I can draw using

00:30:34,820 --> 00:30:44,770
many fingers at the same time and then a

00:30:39,970 --> 00:30:48,740
year ago I started a project to extend

00:30:44,770 --> 00:30:50,980
quartz composer on Mac OS X it's not

00:30:48,740 --> 00:30:53,900
finished yet

00:30:50,980 --> 00:30:57,110
it allows you to receive events in

00:30:53,900 --> 00:31:01,250
quartz composer on Mac OS X and actually

00:30:57,110 --> 00:31:04,780
do some kind of visualizations using the

00:31:01,250 --> 00:31:08,090
data that you receive from open touch

00:31:04,780 --> 00:31:10,760
this was the explosion a simple

00:31:08,090 --> 00:31:12,640
explosion example this is simple

00:31:10,760 --> 00:31:18,120
particle systems

00:31:12,640 --> 00:31:22,950
which trucks your finger finger position

00:31:18,120 --> 00:31:28,240
and that's pretty much how open touch

00:31:22,950 --> 00:31:31,960
works and what can we do with it of

00:31:28,240 --> 00:31:33,640
course to to ride your multi-touch

00:31:31,960 --> 00:31:37,150
applications you need to receive those

00:31:33,640 --> 00:31:40,570
multi-touch events and we have three we

00:31:37,150 --> 00:31:44,679
use three events for that first one is

00:31:40,570 --> 00:31:47,410
finger down it happens when you when the

00:31:44,679 --> 00:31:50,140
new finger appears on the screen

00:31:47,410 --> 00:31:53,140
then we have finger up when the

00:31:50,140 --> 00:31:56,309
previously detected finger disappears

00:31:53,140 --> 00:31:59,440
from the screen and the third one

00:31:56,309 --> 00:32:01,740
happens when it's finger update it

00:31:59,440 --> 00:32:05,770
happens when previously detected finger

00:32:01,740 --> 00:32:10,870
changes its position and based on those

00:32:05,770 --> 00:32:13,510
three events we do also get your

00:32:10,870 --> 00:32:17,429
recognition for sending events as I

00:32:13,510 --> 00:32:21,880
talked before we use tui or protocol

00:32:17,429 --> 00:32:26,440
it's based on open sound control it's

00:32:21,880 --> 00:32:29,470
similar to MIDI format it uses UDP to

00:32:26,440 --> 00:32:31,600
send packets to Europe to to your

00:32:29,470 --> 00:32:34,919
application it was created by the the

00:32:31,600 --> 00:32:38,559
same team that created the react table

00:32:34,919 --> 00:32:41,440
and reactivation software that I showed

00:32:38,559 --> 00:32:43,240
you before the good thing about about

00:32:41,440 --> 00:32:44,679
two year is that it was released with

00:32:43,240 --> 00:32:47,049
many implementations with

00:32:44,679 --> 00:32:51,690
implementations in C++ and Java and

00:32:47,049 --> 00:32:55,059
c-sharp and in flash and also another

00:32:51,690 --> 00:32:58,390
visualization there are some available

00:32:55,059 --> 00:33:00,970
some patches and plugins for other

00:32:58,390 --> 00:33:06,750
visualization software like pure data or

00:33:00,970 --> 00:33:09,880
max/msp it uses two types of comments

00:33:06,750 --> 00:33:11,620
one is the cursor which is used when you

00:33:09,880 --> 00:33:13,929
touch with your finger and the other one

00:33:11,620 --> 00:33:16,470
is marker fiducial which is used when

00:33:13,929 --> 00:33:19,299
you place a fiducial on the screen

00:33:16,470 --> 00:33:23,230
fiducials looks something like the image

00:33:19,299 --> 00:33:26,769
on the right there is I think about 50

00:33:23,230 --> 00:33:29,320
50 50 fiducials available

00:33:26,769 --> 00:33:30,970
and it supports right now all the

00:33:29,320 --> 00:33:33,399
multi-touch screens are an entity

00:33:30,970 --> 00:33:34,990
because we have a flat flat surface but

00:33:33,399 --> 00:33:39,100
you never know what's gonna happen in a

00:33:34,990 --> 00:33:42,250
couple years so - we are supports 2d and

00:33:39,100 --> 00:33:45,669
3d events so if something's gonna happen

00:33:42,250 --> 00:33:48,010
and tweedy later on a couple years to

00:33:45,669 --> 00:33:52,929
year also supports that and as I'm as I

00:33:48,010 --> 00:33:56,230
mentioned before touch sleep T beta and

00:33:52,929 --> 00:33:57,130
open touch projects those that we all

00:33:56,230 --> 00:33:59,769
support

00:33:57,130 --> 00:34:02,529
- yo for sending events to your

00:33:59,769 --> 00:34:05,649
applications so once once we have those

00:34:02,529 --> 00:34:07,630
events in our applications we can do

00:34:05,649 --> 00:34:09,490
gesture recognition what kind of guest

00:34:07,630 --> 00:34:12,669
sure we can do we can do one finger

00:34:09,490 --> 00:34:15,580
gesture just like Mouse gestures or we

00:34:12,669 --> 00:34:17,740
can do multiple finger gestures some if

00:34:15,580 --> 00:34:21,659
you if you're a I phone owner you

00:34:17,740 --> 00:34:24,280
probably know the zoom pinch rotate or

00:34:21,659 --> 00:34:28,000
if you're a Mac owner you also know how

00:34:24,280 --> 00:34:32,379
to scroll with two fingers there's a lot

00:34:28,000 --> 00:34:35,950
more if your Mac bougar owner you can

00:34:32,379 --> 00:34:37,929
use pinch expand taps the second

00:34:35,950 --> 00:34:42,190
secondary click we're using using two

00:34:37,929 --> 00:34:45,790
fingers click track and swipe using many

00:34:42,190 --> 00:34:47,409
fingers you can use those regular

00:34:45,790 --> 00:34:50,020
gastrous that are pretty pretty much the

00:34:47,409 --> 00:34:52,899
multi that's standard right now you can

00:34:50,020 --> 00:34:54,730
use three three fingers for tilting or

00:34:52,899 --> 00:34:56,980
scrolling you can use two fingers for

00:34:54,730 --> 00:34:59,800
rotating two fingers for zooming on

00:34:56,980 --> 00:35:02,470
scaling but you can also have different

00:34:59,800 --> 00:35:03,880
gestures dependent which you are

00:35:02,470 --> 00:35:05,470
dependent on the under your gesture

00:35:03,880 --> 00:35:09,580
recognition algorithm and your gesture

00:35:05,470 --> 00:35:11,410
recognition software those some some

00:35:09,580 --> 00:35:15,359
proof of concepts of something like

00:35:11,410 --> 00:35:21,400
confirm except cancel delay exit or a

00:35:15,359 --> 00:35:24,640
new ad there's also a lot more gestures

00:35:21,400 --> 00:35:27,099
available actually the company that

00:35:24,640 --> 00:35:30,790
Apple acquired the company finger works

00:35:27,099 --> 00:35:33,900
has a great PDF file under under webpage

00:35:30,790 --> 00:35:37,869
it's a multi multi-touch gestures

00:35:33,900 --> 00:35:40,420
dictionary which has many many

00:35:37,869 --> 00:35:43,920
for examples of gestures that can be

00:35:40,420 --> 00:35:46,960
used on multiple surfaces if you are a

00:35:43,920 --> 00:35:51,220
software engineer if you're a developer

00:35:46,960 --> 00:35:53,470
programmer you probably want to know

00:35:51,220 --> 00:35:55,630
what kind of languages you can use to

00:35:53,470 --> 00:35:59,980
develop multi-touch applications

00:35:55,630 --> 00:36:03,789
absolutely actually it's I would say in

00:35:59,980 --> 00:36:06,339
many languages starting from C C++ going

00:36:03,789 --> 00:36:08,440
through c-sharp Java Objective C right

00:36:06,339 --> 00:36:12,759
now we have two EO framework for

00:36:08,440 --> 00:36:15,749
receiving 2 EO events in an objective-c

00:36:12,759 --> 00:36:19,779
then a new group also works on

00:36:15,749 --> 00:36:22,450
ActionScript libraries that can handle 2

00:36:19,779 --> 00:36:25,150
EO so you can develop applications in

00:36:22,450 --> 00:36:28,839
flash and in Python there's a project

00:36:25,150 --> 00:36:31,980
called pi 2 EO also to receive to your

00:36:28,839 --> 00:36:37,029
events and you can implement your own

00:36:31,980 --> 00:36:40,529
implement your own 2 EO protocol library

00:36:37,029 --> 00:36:45,039
in any other language that supports UDP

00:36:40,529 --> 00:36:47,009
however if you're doing if you're making

00:36:45,039 --> 00:36:48,640
creating your own multi-touch

00:36:47,009 --> 00:36:52,599
application what you have to remember

00:36:48,640 --> 00:36:54,999
about is that design really matters that

00:36:52,599 --> 00:36:59,529
Mouse is not the same thing as a finger

00:36:54,999 --> 00:37:01,839
and when you when you design your your

00:36:59,529 --> 00:37:04,480
user interface if you're an interaction

00:37:01,839 --> 00:37:06,960
designer or your interface designer and

00:37:04,480 --> 00:37:11,650
you need to remember about the precision

00:37:06,960 --> 00:37:14,259
with your finger because you can you

00:37:11,650 --> 00:37:16,480
cannot be it's gonna be so precise as a

00:37:14,259 --> 00:37:19,329
mouse so the balance should be bigger

00:37:16,480 --> 00:37:23,950
and and things like that you really have

00:37:19,329 --> 00:37:26,079
to remember about that but also if you

00:37:23,950 --> 00:37:28,720
have the final application how do you

00:37:26,079 --> 00:37:30,910
how do you test it what happens if you

00:37:28,720 --> 00:37:33,009
really don't have a hardware device that

00:37:30,910 --> 00:37:36,279
allows you to sense multi multi touch

00:37:33,009 --> 00:37:38,349
and how do you test your multi-touch

00:37:36,279 --> 00:37:40,809
applications they're actually two ways

00:37:38,349 --> 00:37:45,730
you can use the hardware that you might

00:37:40,809 --> 00:37:47,650
not have this is this is also a little

00:37:45,730 --> 00:37:49,480
bit of a hassle because you really need

00:37:47,650 --> 00:37:51,220
this multi-touch device next to you when

00:37:49,480 --> 00:37:53,200
you develop your application

00:37:51,220 --> 00:37:56,440
and sometimes the easiest way is the

00:37:53,200 --> 00:37:59,380
software software testing of multi-touch

00:37:56,440 --> 00:38:01,540
you can use there's a project to code to

00:37:59,380 --> 00:38:03,880
your simulator that you can use to

00:38:01,540 --> 00:38:07,360
simulate multi-touch cash and

00:38:03,880 --> 00:38:08,920
multi-touch events and send them to your

00:38:07,360 --> 00:38:11,530
final applications without having a

00:38:08,920 --> 00:38:13,450
hardware you can use just Mouse I'm

00:38:11,530 --> 00:38:16,720
gonna show you how to how to use just

00:38:13,450 --> 00:38:18,850
Mouse - to emulate multi-touch and you

00:38:16,720 --> 00:38:21,400
can develop your own protocol if you

00:38:18,850 --> 00:38:23,470
want - to send those events to your

00:38:21,400 --> 00:38:25,990
final application and use some kind of a

00:38:23,470 --> 00:38:29,260
simulator actually what we are working

00:38:25,990 --> 00:38:33,370
on right now is a application called ite

00:38:29,260 --> 00:38:35,530
Oh for iPhone which uses multi-touch

00:38:33,370 --> 00:38:38,920
screen on the iPhone and allows you to

00:38:35,530 --> 00:38:41,380
send to your events of over wireless

00:38:38,920 --> 00:38:43,330
network to your multi-touch applications

00:38:41,380 --> 00:38:46,960
so you really don't need multi-touch

00:38:43,330 --> 00:38:48,880
screen but just an iPhone - to send

00:38:46,960 --> 00:38:51,070
those even then and then later on you

00:38:48,880 --> 00:38:54,330
can test that on on a bigger bigger

00:38:51,070 --> 00:38:58,000
surface and should work the same way so

00:38:54,330 --> 00:39:04,530
what I'm gonna try to demonstrate right

00:38:58,000 --> 00:39:08,320
now let me start with two-year simulator

00:39:04,530 --> 00:39:11,830
how it works and how we can send events

00:39:08,320 --> 00:39:14,410
to multi-touch applications and I will

00:39:11,830 --> 00:39:17,890
try to show you how it works in action

00:39:14,410 --> 00:39:22,330
by running my application called touch

00:39:17,890 --> 00:39:26,710
earth which is multi-touch Google Earth

00:39:22,330 --> 00:39:30,340
it's it uses Google Earth comm API - to

00:39:26,710 --> 00:39:32,650
extend it and handle multi-touch events

00:39:30,340 --> 00:39:37,680
in Google Earth so I will use through

00:39:32,650 --> 00:39:40,120
your simulator to operate touch surf

00:39:37,680 --> 00:39:42,070
after that I will showcase

00:39:40,120 --> 00:39:44,560
anyway framework this is a framework

00:39:42,070 --> 00:39:48,010
that we developed at the company that I

00:39:44,560 --> 00:39:53,560
work for for creating multi-touch

00:39:48,010 --> 00:39:58,300
applications and for many easy

00:39:53,560 --> 00:40:02,070
prototyping of Multi Touch apps

00:39:58,300 --> 00:40:06,060
and after that we will try to use

00:40:02,070 --> 00:40:11,770
Wiimote and the technique that generally

00:40:06,060 --> 00:40:14,380
showed on YouTube to do interactive

00:40:11,770 --> 00:40:19,420
whiteboards I actually just have one

00:40:14,380 --> 00:40:22,300
infrared pen so we really want to have

00:40:19,420 --> 00:40:28,180
multi that's interactive whiteboard put

00:40:22,300 --> 00:40:33,640
just just and one one point interactive

00:40:28,180 --> 00:40:38,380
whiteboard and after that what we gonna

00:40:33,640 --> 00:40:45,330
do is I can try build simple multi touch

00:40:38,380 --> 00:40:51,040
sensor using cardboard box picture frame

00:40:45,330 --> 00:40:55,480
tracing paper and I have infrared camera

00:40:51,040 --> 00:40:58,240
here so you're gonna see if that if that

00:40:55,480 --> 00:40:59,650
works this is actually a project biceps

00:40:58,240 --> 00:41:05,770
and ler the student that I mentioned

00:40:59,650 --> 00:41:08,680
before so this is a really low cost a

00:41:05,770 --> 00:41:13,600
nice way to put a multi-touch sensor and

00:41:08,680 --> 00:41:16,810
early five minutes and using this mmm

00:41:13,600 --> 00:41:18,910
project called empty mini you can try to

00:41:16,810 --> 00:41:22,180
test some of the multi-touch flash

00:41:18,910 --> 00:41:26,400
applications some simple draw

00:41:22,180 --> 00:41:31,480
application fire application and physics

00:41:26,400 --> 00:41:38,760
example and that's about it so let's

00:41:31,480 --> 00:41:38,760
jump in to some demonstrations

00:41:42,230 --> 00:41:46,540
I try start with

00:41:57,220 --> 00:42:06,250
okay here's the reactive vision - video

00:42:02,470 --> 00:42:12,329
simulator I can use mouse to just

00:42:06,250 --> 00:42:17,650
simulate one finger and if I press shift

00:42:12,329 --> 00:42:21,970
the finger will stay and I can do

00:42:17,650 --> 00:42:27,810
another finger and another and later on

00:42:21,970 --> 00:42:35,050
I can move this one or disable this one

00:42:27,810 --> 00:42:36,310
I can put a fiducial here rotate it so

00:42:35,050 --> 00:42:38,680
actually I don't really need a

00:42:36,310 --> 00:42:41,410
multi-touch table just to simulate a

00:42:38,680 --> 00:42:43,540
little bit or just play with with

00:42:41,410 --> 00:42:45,760
multi-touch applications actually that

00:42:43,540 --> 00:42:48,099
the torture publication that I developed

00:42:45,760 --> 00:42:53,200
was done without multi-touch screen at

00:42:48,099 --> 00:42:55,990
all just using this dis simulator so now

00:42:53,200 --> 00:43:01,089
what I have to do because the touch

00:42:55,990 --> 00:43:05,740
refworks on Google Earth application for

00:43:01,089 --> 00:43:10,060
Windows so I need to run Windows and for

00:43:05,740 --> 00:43:10,480
others in order to show show you how it

00:43:10,060 --> 00:43:14,099
works

00:43:10,480 --> 00:43:14,099
this will take a little bit

00:43:15,810 --> 00:43:21,210
there is a way to to control Google

00:43:19,140 --> 00:43:25,050
Earth on Mac OSX to using AppleScript

00:43:21,210 --> 00:43:28,650
and there is there is actually some team

00:43:25,050 --> 00:43:33,450
developed Python multi-touch framework

00:43:28,650 --> 00:43:36,960
and they send Hubble script events to to

00:43:33,450 --> 00:43:41,070
Google Earth on OS X but I never really

00:43:36,960 --> 00:43:46,640
had a chance to develop that so just a

00:43:41,070 --> 00:43:46,640
minute a way to windows starts

00:43:51,780 --> 00:44:00,870
so yes I can put many many fiducials on

00:43:58,230 --> 00:44:05,820
the screen rotate them each fiducial has

00:44:00,870 --> 00:44:09,810
a different ID so that way I know which

00:44:05,820 --> 00:44:14,490
fiducial is is where and what it's it's

00:44:09,810 --> 00:44:18,090
oriented orientation and also two years

00:44:14,490 --> 00:44:21,810
supports those two comments different

00:44:18,090 --> 00:44:23,340
for for cursors and different for for

00:44:21,810 --> 00:44:28,130
fiducials so that way I know whether

00:44:23,340 --> 00:44:28,130
it's a cursor or or fiducial

00:44:45,150 --> 00:44:50,599
this is going to take a little while

00:44:46,980 --> 00:44:50,599
just a second

00:45:04,810 --> 00:45:14,070
to check what's the what's the IP

00:45:07,540 --> 00:45:14,070
address of the per hour session

00:46:01,040 --> 00:46:07,980
that's slow cuz it's in in four hours

00:46:06,300 --> 00:46:11,609
okay

00:46:07,980 --> 00:46:16,369
so what we have here is full screen

00:46:11,609 --> 00:46:22,040
touch earth application which uses

00:46:16,369 --> 00:46:26,130
Google Earth on top and I can easily

00:46:22,040 --> 00:46:34,380
navigate using finger using to video

00:46:26,130 --> 00:46:38,310
simulator I can zoom in or rotate using

00:46:34,380 --> 00:46:43,290
two fingers I place this one here and

00:46:38,310 --> 00:46:44,010
then using second finger I can do things

00:46:43,290 --> 00:46:48,180
like that

00:46:44,010 --> 00:46:51,630
zoom in zoom out and using three fingers

00:46:48,180 --> 00:46:54,690
actually I can tilt so I place two

00:46:51,630 --> 00:46:59,010
fingers in one in the same position and

00:46:54,690 --> 00:47:04,609
then using the third finger I can tilt

00:46:59,010 --> 00:47:09,119
the screen too so that's basically

00:47:04,609 --> 00:47:11,040
what's what is possible with the comb

00:47:09,119 --> 00:47:14,210
API of Google Earth what is possible

00:47:11,040 --> 00:47:16,200
using to your simulator and and

00:47:14,210 --> 00:47:20,099
multi-touch screen the same thing should

00:47:16,200 --> 00:47:22,500
work just fine just same as with to your

00:47:20,099 --> 00:47:25,829
simulator it should work on any

00:47:22,500 --> 00:47:34,730
multi-touch screen that can handle to

00:47:25,829 --> 00:47:34,730
eat to be a bit even okay that's about

00:47:38,740 --> 00:47:47,369
okay the second demo I'm gonna try to

00:47:43,810 --> 00:47:47,369
find is - anyway framework

00:48:00,300 --> 00:48:08,220
you can bring bring up the menu we have

00:48:04,230 --> 00:48:10,740
some sort of applications if some games

00:48:08,220 --> 00:48:14,160
won't bone we have viewer draw

00:48:10,740 --> 00:48:18,330
application box select viewer for

00:48:14,160 --> 00:48:19,560
example here and right now I'm not using

00:48:18,330 --> 00:48:24,230
to your simulator at all

00:48:19,560 --> 00:48:29,760
I'm emulating multi-touch to finger

00:48:24,230 --> 00:48:32,849
touch with right click to the first

00:48:29,760 --> 00:48:36,869
finger and then with this second click

00:48:32,849 --> 00:48:39,420
with using left click to for this for

00:48:36,869 --> 00:48:42,060
the second finger and I can move the

00:48:39,420 --> 00:48:45,810
application around zoom in zoom out I

00:48:42,060 --> 00:48:51,540
can inside the application I can also

00:48:45,810 --> 00:48:56,089
zoom in zoom out move around things I

00:48:51,540 --> 00:49:00,450
can bring up another application like

00:48:56,089 --> 00:49:03,540
example warm which is pretty pretty cool

00:49:00,450 --> 00:49:07,080
game I cannot showcase it and then full

00:49:03,540 --> 00:49:10,530
power right now because I'll need two

00:49:07,080 --> 00:49:14,210
players you just touch the surface to

00:49:10,530 --> 00:49:14,210
create this line and

00:49:15,110 --> 00:49:21,860
that's basically how it works then we

00:49:18,080 --> 00:49:28,100
have draw plication to draw on the

00:49:21,860 --> 00:49:34,580
screen using using multi-touch - and all

00:49:28,100 --> 00:49:38,960
those applications are or also they can

00:49:34,580 --> 00:49:42,650
receive multi-touch events and then use

00:49:38,960 --> 00:49:46,520
two cashiers to zoom in or zoom out or

00:49:42,650 --> 00:49:50,120
change change its size what else we can

00:49:46,520 --> 00:49:51,550
bring up here we have a nice game old

00:49:50,120 --> 00:49:55,430
box

00:49:51,550 --> 00:50:01,640
multi-user game you pick up your bug and

00:49:55,430 --> 00:50:03,560
you try to catch them together if you

00:50:01,640 --> 00:50:07,250
catch them give catch two or three of

00:50:03,560 --> 00:50:09,320
them the bug becomes bigger and the

00:50:07,250 --> 00:50:15,320
winner is the one who gets the biggest

00:50:09,320 --> 00:50:17,780
bug and that way using multi-touch many

00:50:15,320 --> 00:50:19,990
users can play the same game at the same

00:50:17,780 --> 00:50:19,990
time

00:50:26,010 --> 00:50:31,220
yeah so let's try this okay yeah

00:50:32,990 --> 00:50:41,680
quick here and it's quick

00:50:38,300 --> 00:50:41,680
okay so that was

00:50:42,930 --> 00:50:53,160
I was there anyway framework and not was

00:50:45,000 --> 00:50:59,460
the Microsoft Windows sparked now let's

00:50:53,160 --> 00:51:03,050
try to play with with the remote and the

00:50:59,460 --> 00:51:03,050
infrared infrared pen

00:51:09,390 --> 00:51:12,499
see if that works

00:51:21,570 --> 00:51:24,350
okay

00:51:25,920 --> 00:51:33,270
so generally released his software for

00:51:29,970 --> 00:51:36,240
Windows I think and probably for Linux -

00:51:33,270 --> 00:51:40,890
as an open source project and then later

00:51:36,240 --> 00:51:46,530
on somebody created a project called

00:51:40,890 --> 00:51:51,830
Wiimote whiteboard which is part of that

00:51:46,530 --> 00:51:51,830
- - OSX it's actually written in Java

00:51:54,740 --> 00:52:04,390
okay here we have we moved whiteboard

00:52:00,320 --> 00:52:04,390
then I try to calibrate the device

00:52:12,330 --> 00:52:17,930
okay I got some exception try again

00:52:51,730 --> 00:52:57,890
okay

00:52:53,600 --> 00:53:00,710
so it detected remote it says it's

00:52:57,890 --> 00:53:03,920
calibrated but it's really not so we

00:53:00,710 --> 00:53:10,280
need to recalibrate it and what I will

00:53:03,920 --> 00:53:16,430
try to do is select this screen we can

00:53:10,280 --> 00:53:21,230
see the air camera monitor and this is

00:53:16,430 --> 00:53:24,140
the infrared pen I like that I are

00:53:21,230 --> 00:53:27,970
working and basically I have infrared

00:53:24,140 --> 00:53:31,220
LED here and just a simple button and

00:53:27,970 --> 00:53:34,940
and we mode has the embedded infrared

00:53:31,220 --> 00:53:39,260
camera which can sense up to four white

00:53:34,940 --> 00:53:42,440
blobs from the from the infrared lad so

00:53:39,260 --> 00:53:49,630
if I do something like that you can see

00:53:42,440 --> 00:53:49,630
that a here's here is some

00:53:51,220 --> 00:53:57,760
some block that it can detect and truck

00:53:54,010 --> 00:54:00,130
so up to four points it's that way you

00:53:57,760 --> 00:54:02,800
can get a multi-touch also like using

00:54:00,130 --> 00:54:05,470
two two pens for example I actually I

00:54:02,800 --> 00:54:09,390
just have one here but we're gonna try

00:54:05,470 --> 00:54:13,980
to do is we're gonna try to calibrate

00:54:09,390 --> 00:54:17,619
this screen okay it's a little bit up

00:54:13,980 --> 00:54:21,930
maybe just a part here and see if that

00:54:17,619 --> 00:54:21,930
works and try to

00:54:28,980 --> 00:54:31,579
Hey

00:54:38,750 --> 00:54:45,820
and now let's fire some paint

00:54:43,070 --> 00:54:45,820
application

00:54:48,210 --> 00:54:54,240
and now when and uh wiimote it actually

00:54:52,740 --> 00:54:56,849
shouldn't be there should be like some

00:54:54,240 --> 00:54:59,069
somewhere here or at the top of the

00:54:56,849 --> 00:55:03,809
screen you know it works much better but

00:54:59,069 --> 00:55:08,329
when it sends the infrared pen and it

00:55:03,809 --> 00:55:08,329
actually allows you to to draw easily

00:55:16,050 --> 00:55:22,950
it's not at the best surface I guess

00:55:24,880 --> 00:55:28,630
because it's not calibrated on the whole

00:55:26,710 --> 00:55:30,960
screen it's just a burden and in this

00:55:28,630 --> 00:55:30,960
part

00:55:49,319 --> 00:55:56,699
okay seems to work so that way if you

00:55:53,699 --> 00:55:59,249
have second finger you can do

00:55:56,699 --> 00:56:02,359
multi-touch also but actually this is

00:55:59,249 --> 00:56:06,059
the wrong position for the for the

00:56:02,359 --> 00:56:08,269
Wiimote but that's that's the way it

00:56:06,059 --> 00:56:08,269
works

00:56:19,740 --> 00:56:30,839
so very easily very very fast way to

00:56:23,690 --> 00:56:35,390
change any surface to interactive

00:56:30,839 --> 00:56:35,390
whiteboard or a multi-touch while boy

00:56:35,780 --> 00:56:38,780
okay

00:56:39,830 --> 00:56:47,900
okay and what I'm gonna try to do now is

00:56:42,110 --> 00:56:56,450
I have a chair here I have a cardboard

00:56:47,900 --> 00:56:59,270
box I brought here from Poland and I'm

00:56:56,450 --> 00:57:04,190
gonna try to build empty mini really

00:56:59,270 --> 00:57:14,540
quickly just to show you how he better

00:57:04,190 --> 00:57:24,820
works with with empty me this is going

00:57:14,540 --> 00:57:29,900
to be okay what I have here also is

00:57:24,820 --> 00:57:35,630
picture frame with tracing paper without

00:57:29,900 --> 00:57:40,510
the back back is actually here and I put

00:57:35,630 --> 00:57:43,370
it here as my multi-touch sensor

00:57:40,510 --> 00:57:47,690
other than that I have a FireWire

00:57:43,370 --> 00:57:50,660
infrared camera I have a set of filters

00:57:47,690 --> 00:57:53,180
actually we gonna use the ambient light

00:57:50,660 --> 00:57:58,010
without any infrared illuminators

00:57:53,180 --> 00:58:00,830
without any infrared LEDs that is used

00:57:58,010 --> 00:58:04,760
for FTIR setups so I don't really need

00:58:00,830 --> 00:58:07,790
this this is the visible light filter we

00:58:04,760 --> 00:58:09,740
use when we have a FTIR setup so that

00:58:07,790 --> 00:58:13,400
way we only see those white blobs

00:58:09,740 --> 00:58:15,230
without any external light so I don't

00:58:13,400 --> 00:58:23,340
really need that for for now because I

00:58:15,230 --> 00:58:27,080
gonna use an ambient light okay

00:58:23,340 --> 00:58:27,080
but the camera inside

00:58:47,360 --> 00:58:50,320
okay

00:58:55,910 --> 00:59:04,009
here is the T better software this is

00:58:59,450 --> 00:59:09,289
what we see on the on the screen and

00:59:04,009 --> 00:59:14,119
actually you can see how I can sense one

00:59:09,289 --> 00:59:18,680
finger two fingers three fingers without

00:59:14,119 --> 00:59:22,519
any without actually anything it's just

00:59:18,680 --> 00:59:27,289
just a cardboard box and just a frame

00:59:22,519 --> 00:59:30,859
right and thanks to this application and

00:59:27,289 --> 00:59:34,729
also that it supports to you I will try

00:59:30,859 --> 00:59:36,890
to demonstrate some multi-touch flash

00:59:34,729 --> 00:59:39,319
applications this applications was

00:59:36,890 --> 00:59:41,089
actually developed mostly by self

00:59:39,319 --> 00:59:43,700
Sandler as I mentioned before and then

00:59:41,089 --> 00:59:49,039
Christian more so I'd like to thank them

00:59:43,700 --> 00:59:54,069
right now for all that work so now I'm

00:59:49,039 --> 00:59:54,069
gonna try demo those flash apps

00:59:55,920 --> 01:00:02,940
problem with flash is that it doesn't

00:59:58,180 --> 01:00:05,890
support UDP so when I send UDP to flash

01:00:02,940 --> 01:00:09,849
I actually have to use another

01:00:05,890 --> 01:00:15,420
application called FL OSC which received

01:00:09,849 --> 01:00:20,010
OSC and converts them to XML data that

01:00:15,420 --> 01:00:24,299
flash can receive so I have to run the

01:00:20,010 --> 01:00:24,299
FL OSC application first

01:00:30,400 --> 01:00:38,370
okay I got it got it running here still

01:00:36,100 --> 01:00:38,370
works

01:00:40,490 --> 01:00:43,090
okay

01:00:45,000 --> 01:00:52,310
and maybe let's try with fire

01:00:49,320 --> 01:00:52,310
application

01:00:58,240 --> 01:01:05,490
your simple fire application so this is

01:01:03,520 --> 01:01:11,260
a flash application which receives

01:01:05,490 --> 01:01:13,810
even's from FL OSC first I sent from

01:01:11,260 --> 01:01:16,720
from Tibet ice and two events to a

01:01:13,810 --> 01:01:24,240
fellow at C then F LLC converts them to

01:01:16,720 --> 01:01:29,250
to XML and here we have simple

01:01:24,240 --> 01:01:38,640
multi-touch application so this is a

01:01:29,250 --> 01:01:38,640
fire fimo we have some paint up also

01:01:55,440 --> 01:02:02,040
since sometimes what happens sometimes

01:02:00,150 --> 01:02:04,620
if I use the ambient light is that I

01:02:02,040 --> 01:02:07,350
sometimes get a random blobs if the

01:02:04,620 --> 01:02:09,840
light conditions changes a little bit so

01:02:07,350 --> 01:02:19,530
that's why it is going correct crazy

01:02:09,840 --> 01:02:24,230
sometimes let's change the color yeah so

01:02:19,530 --> 01:02:24,230
this is simple paint

01:02:30,829 --> 01:02:45,920
simple physics using one of the flash

01:02:39,369 --> 01:02:48,519
open source physics library you can move

01:02:45,920 --> 01:02:48,519
things around

01:03:05,180 --> 01:03:12,859
yeah so those are the three applications

01:03:08,299 --> 01:03:17,809
and I go for you today so you can have a

01:03:12,859 --> 01:03:23,170
look how it works with that I'm being

01:03:17,809 --> 01:03:23,170
light and I can put more fingers also

01:03:25,140 --> 01:03:30,210
and this is the final result from the

01:03:28,020 --> 01:03:33,930
image processing you see nothing else

01:03:30,210 --> 01:03:39,810
but just white wops and those white flop

01:03:33,930 --> 01:03:42,450
some are sent to blob blob detection

01:03:39,810 --> 01:03:50,160
algorithm and then to plop-plop tracking

01:03:42,450 --> 01:03:52,730
a girl also those random oh yeah right

01:03:50,160 --> 01:03:56,190
now we can see that there is this random

01:03:52,730 --> 01:03:57,810
blob which shouldn't a cure but because

01:03:56,190 --> 01:04:00,690
we are using this ambient light and this

01:03:57,810 --> 01:04:03,060
is not well configured and not all the

01:04:00,690 --> 01:04:08,330
values are way they should be

01:04:03,060 --> 01:04:08,330
we might get sometimes some random block

01:04:13,810 --> 01:04:24,160
okay so this was T beta application and

01:04:20,420 --> 01:04:24,160
now it's going back to the slides

01:04:27,550 --> 01:04:32,920
so we are almost there what's the future

01:04:30,310 --> 01:04:35,680
of multi-touch screens I believe that in

01:04:32,920 --> 01:04:37,270
couple years maybe even at Google you

01:04:35,680 --> 01:04:40,720
guys gonna have multi-touch screens in

01:04:37,270 --> 01:04:42,400
your conference rooms maybe there gonna

01:04:40,720 --> 01:04:45,100
be some solution for multi-site

01:04:42,400 --> 01:04:47,440
collaboration where you can work on the

01:04:45,100 --> 01:04:50,080
same surface around the different

01:04:47,440 --> 01:04:52,390
offices around the world we're gonna see

01:04:50,080 --> 01:04:54,490
multi-touch screens and hotels claps and

01:04:52,390 --> 01:04:58,380
restaurants and many public places

01:04:54,490 --> 01:05:02,410
actually ms surfaces right now and atnt

01:04:58,380 --> 01:05:05,710
stores it's gone it's gonna be also in

01:05:02,410 --> 01:05:08,530
hotels and in casinos the video that you

01:05:05,710 --> 01:05:12,850
can see here is from CNN they actually

01:05:08,530 --> 01:05:15,910
bought a a prototype or just a product

01:05:12,850 --> 01:05:19,720
from Jeff Hahn so they have a big

01:05:15,910 --> 01:05:24,250
multi-touch wall so it's also used by

01:05:19,720 --> 01:05:30,730
television stations and in when when it

01:05:24,250 --> 01:05:34,000
become even cheaper we might see it at

01:05:30,730 --> 01:05:38,230
our homes - and actually Microsoft with

01:05:34,000 --> 01:05:40,540
his touch wall technological and

01:05:38,230 --> 01:05:43,630
touchable technology is trying to make

01:05:40,540 --> 01:05:47,500
it as cheap as possible so a couple of

01:05:43,630 --> 01:05:50,070
years you never know maybe your kitchen

01:05:47,500 --> 01:05:54,940
a kitchen table gonna be a multi-touch

01:05:50,070 --> 01:05:57,310
and I would if you'd like to get some

01:05:54,940 --> 01:06:00,820
more information about multi-touch

01:05:57,310 --> 01:06:02,890
screens and from the hardware point of

01:06:00,820 --> 01:06:07,840
view and software point of view please

01:06:02,890 --> 01:06:11,170
visit our web page at WWE Groupon anyway

01:06:07,840 --> 01:06:14,590
group comm and also forums which is

01:06:11,170 --> 01:06:17,320
really active anywhere group.com slash

01:06:14,590 --> 01:06:20,800
forums I think this is the right time

01:06:17,320 --> 01:06:23,830
for huge fangs to all of our

01:06:20,800 --> 01:06:26,890
contributors like to mention Christian

01:06:23,830 --> 01:06:28,900
more Seth Sandler Tim Roth Harry van der

01:06:26,890 --> 01:06:31,570
Veen David Rowland and Lawrence Murrell

01:06:28,900 --> 01:06:33,550
many many more of our community members

01:06:31,570 --> 01:06:36,160
that have been working on those

01:06:33,550 --> 01:06:39,290
applications and are still contributing

01:06:36,160 --> 01:06:43,010
in many ways so thank you very much

01:06:39,290 --> 01:06:46,760
to them and I'm not sure if we have time

01:06:43,010 --> 01:06:51,110
but I would like to open up for Q&A if

01:06:46,760 --> 01:06:51,680
there are any questions okay any

01:06:51,110 --> 01:06:54,640
questions

01:06:51,680 --> 01:06:54,640
sure

01:07:02,690 --> 01:07:07,910
projection and yeah so we mentioned the

01:07:06,170 --> 01:07:09,890
question

01:07:07,910 --> 01:07:14,119
yes yes so the question what barriers

01:07:09,890 --> 01:07:16,940
exist enables us to do to have a flat

01:07:14,119 --> 01:07:22,309
multi-touch screens something like on a

01:07:16,940 --> 01:07:24,619
LCD or or plasma this place actually the

01:07:22,309 --> 01:07:27,369
one that Apple is using the one for the

01:07:24,619 --> 01:07:31,670
company and they acquired that this

01:07:27,369 --> 01:07:33,769
finger works company is something that

01:07:31,670 --> 01:07:37,009
enables you to do that on on any flat

01:07:33,769 --> 01:07:39,710
surface there are some more but I think

01:07:37,009 --> 01:07:42,740
they are patented and they're not so

01:07:39,710 --> 01:07:45,170
widely used yet but I believe this is

01:07:42,740 --> 01:07:47,930
going this is going to change and then a

01:07:45,170 --> 01:07:50,660
couple years to because I know that

01:07:47,930 --> 01:07:57,910
Panasonic and LG are also working on

01:07:50,660 --> 01:08:01,220
some ll LCD LCD multi-touch screens and

01:07:57,910 --> 01:08:02,779
also this technology that I mentioned

01:08:01,220 --> 01:08:09,160
this last hour touch technology is just

01:08:02,779 --> 01:08:11,779
as just a sensor next to the next to the

01:08:09,160 --> 01:08:14,000
surface attached so it actually can be

01:08:11,779 --> 01:08:18,020
placed on whatever surface you want

01:08:14,000 --> 01:08:20,690
whether it's a LCD or Plasma or any

01:08:18,020 --> 01:08:27,859
other surface so yeah probably in a

01:08:20,690 --> 01:08:30,529
couple of years so how does my work if

01:08:27,859 --> 01:08:33,859
it's not an image processing probably

01:08:30,529 --> 01:08:36,259
some electromagnetic sensing or some

01:08:33,859 --> 01:08:39,489
something like that I'm not I'm not

01:08:36,259 --> 01:08:43,180
really in those technologies yet but

01:08:39,489 --> 01:08:46,549
probably something that is

01:08:43,180 --> 01:08:48,170
are there any accessibility implications

01:08:46,549 --> 01:08:50,299
for any of this stuff because it seems

01:08:48,170 --> 01:08:54,080
like you know this is very cool visually

01:08:50,299 --> 01:08:57,710
but I wonder if it affects how you know

01:08:54,080 --> 01:08:58,940
how other people can use the system you

01:08:57,710 --> 01:09:01,339
know people who can who aren't that

01:08:58,940 --> 01:09:04,940
dexterous or you know are people that

01:09:01,339 --> 01:09:06,650
are blind or whatever the good thing

01:09:04,940 --> 01:09:09,710
about those technologies is that they

01:09:06,650 --> 01:09:12,830
are really intuitive and for example for

01:09:09,710 --> 01:09:14,960
children or for elderly elderly people

01:09:12,830 --> 01:09:16,790
it's really simple if it's like first

01:09:14,960 --> 01:09:19,010
it's their first contact with the

01:09:16,790 --> 01:09:21,799
computer and they can just touch

01:09:19,010 --> 01:09:23,870
something I like just zoom in or drag

01:09:21,799 --> 01:09:26,660
and drop something and things like that

01:09:23,870 --> 01:09:30,710
just like on their desk it's really

01:09:26,660 --> 01:09:33,020
intuitive but other than that I don't

01:09:30,710 --> 01:09:35,900
think there is anything about that

01:09:33,020 --> 01:09:37,730
accessibility accessibility yeah yet

01:09:35,900 --> 01:09:39,770
because it's pretty new there I mean

01:09:37,730 --> 01:09:41,870
it's not new it's known for over 20

01:09:39,770 --> 01:09:43,910
years but it's got a lot of attention

01:09:41,870 --> 01:09:46,220
over like the last two years or the last

01:09:43,910 --> 01:09:48,370
two years how many of you have heard

01:09:46,220 --> 01:09:53,630
about multi-touch screen two years ago

01:09:48,370 --> 01:09:56,780
probably okay so one person on so yeah

01:09:53,630 --> 01:09:59,030
and it's known for over 20 years so

01:09:56,780 --> 01:10:01,880
thanks to iPhone and Microsoft Surface

01:09:59,030 --> 01:10:05,420
and things like that it's it's more

01:10:01,880 --> 01:10:10,580
popular and there's not really like any

01:10:05,420 --> 01:10:12,740
standard for also for gassers and I'm

01:10:10,580 --> 01:10:15,910
not really sure about the accessibility

01:10:12,740 --> 01:10:15,910
accessibility issues

01:10:18,599 --> 01:10:24,989
um so multi pointer X was recently

01:10:22,440 --> 01:10:27,810
merged into mainline X so the next

01:10:24,989 --> 01:10:30,800
version of the main distribution line

01:10:27,810 --> 01:10:34,710
its distribution should have multi point

01:10:30,800 --> 01:10:37,110
in the Xserve how do you think that's

01:10:34,710 --> 01:10:40,469
going to affect like adoption of multi

01:10:37,110 --> 01:10:43,349
point stuff and is this compatible with

01:10:40,469 --> 01:10:47,639
the stuff you've been doing well the

01:10:43,349 --> 01:10:50,310
thing with Empire MPX is that it's also

01:10:47,639 --> 01:10:51,690
used for multiple Mouse's right you can

01:10:50,310 --> 01:10:54,690
use it when you'd have like three

01:10:51,690 --> 01:10:56,909
Mouse's or things like that but what you

01:10:54,690 --> 01:10:59,280
also need for like this techniques for

01:10:56,909 --> 01:11:01,380
FTIR RDI you need another additional

01:10:59,280 --> 01:11:03,090
software that will do this image

01:11:01,380 --> 01:11:08,510
processing and they will send those

01:11:03,090 --> 01:11:11,670
evens to your to your X server or

01:11:08,510 --> 01:11:13,949
whatever other application I believe

01:11:11,670 --> 01:11:18,389
like tab sleep is also working on Linux

01:11:13,949 --> 01:11:20,639
right now so I believe guys are that new

01:11:18,389 --> 01:11:22,800
right group gonna also create some sort

01:11:20,639 --> 01:11:26,670
of maybe live CD or something with MP

01:11:22,800 --> 01:11:31,050
and px and top sleep on on on the CD you

01:11:26,670 --> 01:11:33,929
can just run touch sleep and then MPX

01:11:31,050 --> 01:11:36,480
and Guetta and get a multi-touch X

01:11:33,929 --> 01:11:38,880
window but what needs also it will

01:11:36,480 --> 01:11:40,949
happen is because it's it's a different

01:11:38,880 --> 01:11:44,670
way of interaction it's also we can we

01:11:40,949 --> 01:11:47,219
can really use those menus and small

01:11:44,670 --> 01:11:48,869
icons and small buttons and things like

01:11:47,219 --> 01:11:50,070
that so if you create a multi-touch

01:11:48,869 --> 01:11:53,239
applications you have to think about

01:11:50,070 --> 01:11:57,050
that so working with just regular

01:11:53,239 --> 01:11:59,969
applications and just using multi-touch

01:11:57,050 --> 01:12:02,639
table I'm not sure it's it's a it's a

01:11:59,969 --> 01:12:04,560
good good way of doing things so I think

01:12:02,639 --> 01:12:07,320
there should be new applications

01:12:04,560 --> 01:12:10,250
developed on the x window that will

01:12:07,320 --> 01:12:13,650
allow multi-touch but they will be

01:12:10,250 --> 01:12:16,349
developed by thinking of a multi-touch

01:12:13,650 --> 01:12:19,739
and by designing for multi-touch and not

01:12:16,349 --> 01:12:22,950
using the previous house I'm not sure if

01:12:19,739 --> 01:12:26,090
that answers your questions

01:12:22,950 --> 01:12:26,090

YouTube URL: https://www.youtube.com/watch?v=u5RqAz_AZSE


