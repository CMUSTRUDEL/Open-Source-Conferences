Title: Google Open Source Live "Diversity, Equity and Inclusion day" | Fireside chat
Publication date: 2021-03-08
Playlist: Google Open Source Live
Description: 
	
Captions: 
	00:00:10,465 --> 00:00:13,215
Hi everybody, welcome to this fireside chat.

00:00:13,954 --> 00:00:15,006
My name is Maria Cruz.

00:00:15,006 --> 00:00:18,427
I'm a program manager at the Google Open Source program office

00:00:18,797 --> 00:00:23,598
and I have here with me Caroline Sinders, machine learning researcher and artist.

00:00:24,038 --> 00:00:27,663
Caroline and I met while working at the Wikimedia Foundation

00:00:27,933 --> 00:00:32,206
and she's here today to talk about remote workplace toxicity

00:00:32,206 --> 00:00:33,546
and online harassment.

00:00:33,666 --> 00:00:36,584
Caroline, welcome! Would you like to introduce yourself?

00:00:37,267 --> 00:00:38,638
Sure, thank you for having me!

00:00:38,638 --> 00:00:39,937
I'm Caroline Sinders.

00:00:39,937 --> 00:00:43,034
I run Convocation Design + Research, a consulting firm

00:00:43,418 --> 00:00:48,557
where we use design and R&D to analyze complex problems

00:00:48,557 --> 00:00:49,900
on different kinds of platforms

00:00:49,900 --> 00:00:52,458
and looking at how technology affects society.

00:00:53,386 --> 00:00:56,611
Recently, I've been working on a report with McKinsey (MAC) group

00:00:56,611 --> 00:00:58,727
and Project Include with Ellen Pao

00:00:58,727 --> 00:01:04,017
on remote workplace toxicity and harassment with a focus on COVID-19

00:01:04,017 --> 00:01:08,753
since the COVID-19 stay-at-home orders across the globe have forced workplaces

00:01:08,753 --> 00:01:11,802
to go from being in-person to being totally remote

00:01:12,027 --> 00:01:14,801
and within this we saw a lot of problems start to arise

00:01:14,801 --> 00:01:19,821
and we wanted to create a report to try to address different issues we were seeing.

00:01:21,558 --> 00:01:24,779
Great, thank you for being here.

00:01:28,409 --> 00:01:29,851
I was reflecting on the fact that…

00:01:29,851 --> 00:01:31,038
looking at your work

00:01:31,548 --> 00:01:36,393
at how you look into words

00:01:36,393 --> 00:01:38,872
that are used in conversations

00:01:38,872 --> 00:01:41,729
from a quantitative perspective

00:01:42,942 --> 00:01:46,702
I was wondering if you could reflect a little bit more

00:01:47,310 --> 00:01:52,488
on the choice of words we use when talking to each other online.

00:01:54,582 --> 00:01:59,070
What is the weight that words have in conversation?

00:01:59,070 --> 00:02:03,999
Why is it so taxing for us when somebody says something mean to us?

00:02:05,273 --> 00:02:06,507
For sure, thank you for that.

00:02:07,027 --> 00:02:10,938
I tend to look at actions, words, events

00:02:10,938 --> 00:02:14,407
in the design affordances of systems around us

00:02:14,407 --> 00:02:18,838
so how a person builds a mental model of the technology around them

00:02:18,838 --> 00:02:20,088
that they exist in.

00:02:20,487 --> 00:02:24,967
Generally, I look at people inside of networks and platforms.

00:02:24,967 --> 00:02:26,363
So, when I'm studying a problem

00:02:26,363 --> 00:02:29,735
I'm looking at how someone may be facing harassment

00:02:29,735 --> 00:02:31,163
inside of something like Facebook

00:02:31,163 --> 00:02:35,787
or how someone can face harm using GitHub.

00:02:35,787 --> 00:02:39,542
So, what the design of that platform is

00:02:39,948 --> 00:02:44,824
and then what are the tools someone has at hand to mitigate that harm.

00:02:44,908 --> 00:02:48,312
And then I'm looking at the different kinds and levels of harm within that

00:02:48,312 --> 00:02:52,312
so the words people use, and sometimes the words people don't use.

00:02:54,122 --> 00:02:56,050
It's a very multi-pronged problem.

00:02:56,776 --> 00:02:58,459
One thing that's important to keep in mind

00:02:58,459 --> 00:03:01,562
and I'm sure I don't have to spend a lot of time arguing this

00:03:01,562 --> 00:03:03,298
I'm sure this audience would agree with me

00:03:03,298 --> 00:03:07,072
that our online lives are as real as our offline lives

00:03:07,072 --> 00:03:09,241
so something that someone says to you online

00:03:09,241 --> 00:03:12,649
is as hurtful as something someone says to you offline.

00:03:12,743 --> 00:03:17,237
If you were to tell me over video chat that you didn't like my lipstick color

00:03:17,237 --> 00:03:20,502
that wouldn't feel good because I thought we were friends, right?

00:03:20,602 --> 00:03:24,073
But also, that would be a very rude thing to say to the invited speaker!

00:03:24,430 --> 00:03:27,824
And so, while that could be an innocuous statement

00:03:27,824 --> 00:03:32,257
how you would articulate that to me would still be somewhat hurtful.

00:03:32,697 --> 00:03:36,345
What I think is important is to look at the different kinds of words and languages

00:03:36,345 --> 00:03:38,520
people use in response to harassment.

00:03:39,559 --> 00:03:41,500
We could have more direct forms of harassment

00:03:41,500 --> 00:03:45,338
like a direct threat, curse words

00:03:45,802 --> 00:03:48,055
words that are generally agreed to be harmful.

00:03:48,979 --> 00:03:52,041
So that can be describing different kinds of abuse

00:03:52,041 --> 00:03:54,068
or leveling abuse at someone.

00:03:54,128 --> 00:03:58,128
Again, things like curse words or talking about physical harm.

00:03:58,443 --> 00:04:04,486
But there are also forms of language and actions that may seem more innocuous

00:04:04,486 --> 00:04:06,264
that are, in fact, quite toxic.

00:04:06,861 --> 00:04:09,515
This is where we're looking at things like microaggressions.

00:04:09,715 --> 00:04:13,358
Someone saying to you, "You speak so well"

00:04:13,358 --> 00:04:15,012
and saying that in a surprised way

00:04:15,012 --> 00:04:19,309
or just generally saying that, is a form of microaggression that is toxic.

00:04:19,539 --> 00:04:23,404
It just may not initially read to someone as toxic

00:04:23,552 --> 00:04:25,978
so it's not necessarily innocuous.

00:04:25,978 --> 00:04:28,782
So, that phrase, "You speak so well"

00:04:29,464 --> 00:04:34,770
"you (pause) speak… so… well," all those as different words

00:04:34,770 --> 00:04:38,322
may not seem toxic, or as toxic as toxic as a swear word

00:04:38,532 --> 00:04:43,194
but when stung together it has a sort of cultural, biased weight behind it

00:04:43,194 --> 00:04:45,335
that is then harmful to the recipient.

00:04:45,558 --> 00:04:47,170
So, I look at things like this

00:04:47,170 --> 00:04:50,882
like what are the norms of a group inside of a space

00:04:50,882 --> 00:04:57,382
and then what are varying levels of veiled harm that are leveled at people

00:04:57,562 --> 00:05:00,464
and how do we elevate that and talk about that.

00:05:00,464 --> 00:05:04,464
I'm extremely interested in toxicity

00:05:04,761 --> 00:05:10,048
and I think what more privileged groups could think of as innocuous harm

00:05:10,048 --> 00:05:13,562
that are probably best described as microaggressions.

00:05:15,183 --> 00:05:20,012
I think you're touching on a very interesting topic here

00:05:20,012 --> 00:05:22,546
which is what are the different ways

00:05:22,546 --> 00:05:27,092
in which we can enter conflict in a conversation.

00:05:27,092 --> 00:05:31,121
I remember a presentation you gave at Wikimania 2017

00:05:31,121 --> 00:05:34,270
where you started the conversation

00:05:34,270 --> 00:05:38,753
by stating an important distinction

00:05:38,753 --> 00:05:41,911
between conflict, harassment, and abuse.

00:05:42,743 --> 00:05:47,297
I was wondering if you could speak a little bit about that difference.

00:05:48,727 --> 00:05:50,320
For sure, so…

00:05:51,010 --> 00:05:53,360
I think there are varying levels of interactions

00:05:53,360 --> 00:05:55,217
and frictions people can encounter.

00:05:56,058 --> 00:05:58,404
Conflict is really natural.

00:05:58,422 --> 00:06:01,470
One thing I like to say is community doesn't mean friendship.

00:06:01,470 --> 00:06:03,438
Just because we're in a community together

00:06:03,438 --> 00:06:06,918
that doesn't mean I need to like you or vice versa.

00:06:07,098 --> 00:06:09,464
But that doesn't give you carte blanche

00:06:09,464 --> 00:06:14,466
to be mean to me or be mean to someone else.

00:06:15,704 --> 00:06:18,274
Communities will naturally have friction within them.

00:06:18,554 --> 00:06:19,900
People will not get along.

00:06:19,900 --> 00:06:23,067
And that is actually pretty natural.

00:06:23,333 --> 00:06:27,601
It's how you manifest that friction and how you respond to someone

00:06:27,601 --> 00:06:32,492
that's actually where harassment and abuse can lie.

00:06:32,492 --> 00:06:37,735
One thing that's important to think about I think is intent versus impact.

00:06:38,582 --> 00:06:43,844
Someone may say something and not understand the impact of their words.

00:06:43,844 --> 00:06:47,306
Perhaps there's a cultural difference, perhaps there's a generational difference

00:06:47,306 --> 00:06:51,489
perhaps they just said something off the cuff and didn't really think about it.

00:06:53,653 --> 00:06:55,217
Their intent is not to harm

00:06:55,217 --> 00:06:58,281
but the impact of their actions actually causes harm.

00:06:58,281 --> 00:07:02,916
I think it's important to look at the impact versus the intent.

00:07:04,246 --> 00:07:08,732
This is where I really advise communities to create a ladder of consequences

00:07:08,732 --> 00:07:13,958
so being able to say this kind of action is going to have this kind of response

00:07:13,958 --> 00:07:15,464
from us as the organizers

00:07:15,464 --> 00:07:18,197
and this is how it matches up to our terms of service

00:07:18,337 --> 00:07:22,337
community guidelines, code of conduct, employee handbook, etc.

00:07:22,692 --> 00:07:26,473
So, if someone does accidentally say something

00:07:26,473 --> 00:07:31,709
and it's considered a lower form of harassment or abuse

00:07:31,992 --> 00:07:34,293
we can handle it more as just general conflict

00:07:34,599 --> 00:07:40,776
where an intermediary can step in, explain why that was harmful, give an action

00:07:41,002 --> 00:07:42,759
so that could be a punitive response

00:07:42,759 --> 00:07:46,315
that could be education, that could say you have to issue an apology

00:07:46,808 --> 00:07:49,102
and then move on.

00:07:50,044 --> 00:07:52,071
So, when you have this ladder of consequences

00:07:52,071 --> 00:07:53,579
you can start to look at actions

00:07:53,579 --> 00:07:58,131
and ask what is the severity of them and where do they fall within this

00:07:58,390 --> 00:07:59,929
and map out responses.

00:07:59,929 --> 00:08:03,929
You can have a structured response that can be an agreed-upon response.

00:08:04,421 --> 00:08:07,921
So, if someone engages in, let's say, physical violence

00:08:08,399 --> 00:08:10,323
the ladder of consequences may say

00:08:10,323 --> 00:08:15,358
all physical violence results in immediate dismissal from our community

00:08:15,358 --> 00:08:17,962
and we've all agreed upon that because it's in our code of conduct

00:08:18,408 --> 00:08:21,617
and we've mapped it in our ladder of consequences on the top step

00:08:22,103 --> 00:08:25,286
which is where immediate dismissal is.

00:08:25,653 --> 00:08:27,779
So, it's really important to be able to understand

00:08:27,779 --> 00:08:33,083
that not all actions are necessarily abusive.

00:08:34,419 --> 00:08:39,391
Lower forms of abuse that we can put into the conflict area, if they continue

00:08:39,706 --> 00:08:43,332
especially after someone has said, "I'm uncomfortable. Please don't do that"

00:08:43,705 --> 00:08:47,429
those lower forms stack up and can create a very toxic

00:08:47,429 --> 00:08:49,887
harmful, and abusive environment.

00:08:50,316 --> 00:08:53,957
So, the repeated engagement of bad actions

00:08:55,730 --> 00:08:58,402
needs to be mapped out and analyzed as well.

00:08:59,011 --> 00:09:04,571
In my presentation at Wikimania 2017 something I was really interested in is

00:09:04,571 --> 00:09:09,660
how do we look at repeating lower forms of toxicity

00:09:09,855 --> 00:09:12,145
especially within the Wikimedia universe.

00:09:12,271 --> 00:09:16,112
So, if someone is constantly correcting you

00:09:16,112 --> 00:09:17,862
or undoing your edits

00:09:18,631 --> 00:09:20,423
that at first can look like conflict

00:09:20,423 --> 00:09:24,936
but if it continues and you've asked this person to stop

00:09:25,493 --> 00:09:31,688
your edits have no reason to be undone or re-edited in any way

00:09:31,925 --> 00:09:35,766
that is a form of harassment because you've asked someone to stop

00:09:35,766 --> 00:09:38,127
and they're not listening to you setting a boundary

00:09:38,127 --> 00:09:40,351
and they're actually invading your boundary.

00:09:41,271 --> 00:09:47,512
I see clearly the role of people and moderators

00:09:47,512 --> 00:09:50,625
in these processes that you describe.

00:09:51,743 --> 00:09:55,867
I was wondering, what role can technology

00:09:56,277 --> 00:09:58,252
and specifically, machine learning

00:09:58,322 --> 00:10:04,972
play in holding or supporting a code of conduct

00:10:04,972 --> 00:10:08,162
for an open source project, for example

00:10:08,162 --> 00:10:11,089
or for any online community?

00:10:12,976 --> 00:10:17,382
How far can we go with using this technology

00:10:17,382 --> 00:10:19,855
to support these processes?

00:10:20,854 --> 00:10:25,446
I don't really know what the role of technology should be within this

00:10:25,446 --> 00:10:30,133
or rather, I do know, and my advice is often "not a big a role"

00:10:30,133 --> 00:10:34,754
because I think to solve human problems you need human responses.

00:10:34,754 --> 00:10:36,154
In the case of moderation

00:10:36,494 --> 00:10:40,734
you can use machine learning to try to build a classifier on abusive language

00:10:40,734 --> 00:10:43,991
and what you're really building is a keyword filter I think at that point

00:10:44,192 --> 00:10:49,270
because a lot of harassment and toxicity are the things we say in context

00:10:49,548 --> 00:10:54,773
so someone telling me, or someone saying to you

00:10:54,773 --> 00:10:58,637
"You speak so well," that can be extremely harmful, right?

00:10:58,637 --> 00:11:02,580
But to any kind of tone analyzer or sentiment analysis

00:11:02,580 --> 00:11:05,938
that seems almost like a positive statement.

00:11:06,654 --> 00:11:12,197
I think what's important to recognize is that harassment at times is not very blatant.

00:11:12,197 --> 00:11:17,376
It's very contextual and/or it's tailored specifically to the victim.

00:11:18,990 --> 00:11:23,604
Machine learning can't help in analyzing that.

00:11:23,660 --> 00:11:27,392
What does help, I think, is training with diversity and inclusion experts

00:11:27,392 --> 00:11:28,938
and racial justice experts

00:11:28,938 --> 00:11:32,381
to recognize those kinds of interactions when they pop up

00:11:33,071 --> 00:11:37,162
for communities to build a plan and a ladder of consequences

00:11:37,162 --> 00:11:40,555
and implement that plan and that ladder of consequences

00:11:40,555 --> 00:11:41,683
when harm arises

00:11:41,683 --> 00:11:46,839
and to do it quickly and to feel confident in their response

00:11:46,839 --> 00:11:47,699
meaning…

00:11:47,779 --> 00:11:51,533
I notice this a lot in a lot of communities I've been in

00:11:51,843 --> 00:11:55,926
particularly also in the Wikimedia community where people would lean back a little bit

00:11:55,926 --> 00:11:58,967
and say, "How do we know that that person…

00:11:59,297 --> 00:12:00,617
maybe they didn't mean it."

00:12:01,108 --> 00:12:07,051
And I always liked to say that the intent and impact are very different things.

00:12:07,421 --> 00:12:12,176
The intent of someone doesn't lessen the impact of their actions

00:12:12,176 --> 00:12:13,969
or the harm of their actions.

00:12:14,179 --> 00:12:17,863
I may not intend to hurt you but I have hurt you.

00:12:18,333 --> 00:12:21,820
And so I think it's important to separate intent and impact

00:12:22,189 --> 00:12:28,064
when we're looking at responding to varying levels of toxicity and harm.

00:12:30,467 --> 00:12:34,002
Yeah, I agree, definitely.

00:12:34,002 --> 00:12:36,891
I think some of the most common misunderstandings

00:12:39,025 --> 00:12:40,802
or disconnect between people

00:12:40,802 --> 00:12:47,359
happen when there is that gap between "Oh, I actually tried to say X"

00:12:47,359 --> 00:12:52,136
and the impact that had was completely different.

00:12:54,183 --> 00:12:57,888
So, I think acknowledging that that's a difference

00:12:59,505 --> 00:13:05,251
is probably one of the first steps away from abuse or harassment.

00:13:07,219 --> 00:13:08,359
Let's go back a little bit

00:13:08,359 --> 00:13:12,089
to the research project you're working on right now.

00:13:13,073 --> 00:13:18,885
You were talking about different information inputs that you were analyzing

00:13:19,755 --> 00:13:24,841
from different companies that were providing data

00:13:24,841 --> 00:13:28,307
and there's also a survey. Is that right?

00:13:29,418 --> 00:13:32,570
Yeah, so we're not actually taking data from companies.

00:13:32,570 --> 00:13:36,920
We're looking at pre-existing literature that companies have published

00:13:37,895 --> 00:13:42,700
like their own findings in response to remote work during the pandemic.

00:13:43,348 --> 00:13:49,771
What are the next steps when you've analyzed all of this data?

00:13:50,625 --> 00:13:52,909
How do you hope to apply this?

00:13:55,840 --> 00:13:59,344
Is it going to be available for other companies to learn from?

00:13:59,754 --> 00:14:02,052
Is it going to be accompanied by a guide?

00:14:02,052 --> 00:14:04,317
How do you see this project going forward?

00:14:05,059 --> 00:14:06,780
Sure, yeah, thank you for that question.

00:14:07,188 --> 00:14:08,978
It's going to be a research report

00:14:08,978 --> 00:14:12,207
with specific recommendations for what companies can do

00:14:12,207 --> 00:14:13,495
right now in this moment.

00:14:13,880 --> 00:14:15,999
We're confident and hopeful

00:14:15,999 --> 00:14:19,599
that the recommendations will work for various sized companies

00:14:19,599 --> 00:14:21,749
from companies potentially as large as Google

00:14:21,749 --> 00:14:26,277
to companies as small as a consulting firm of one or two people.

00:14:28,035 --> 00:14:31,859
Our goal is to create widespread impact

00:14:31,859 --> 00:14:36,529
and also think about scale when suggesting different kinds of solutions

00:14:36,529 --> 00:14:40,398
and we are thinking about how scale affects implementation.

00:14:40,905 --> 00:14:43,651
Primarily for us, we are trying to be really actionable

00:14:43,651 --> 00:14:45,318
also in these recommendations

00:14:45,318 --> 00:14:48,870
so they won't be necessarily pie-in-the-sky recommendations

00:14:48,870 --> 00:14:52,976
but things we have learned from conducting our research.

00:14:53,454 --> 00:14:56,513
I can share a few with you, like what we've started to notice already

00:14:56,513 --> 00:15:00,311
though we're still in the process of finishing up research

00:15:00,311 --> 00:15:01,932
and we're going to start writing soon.

00:15:03,950 --> 00:15:08,052
Yeah, did you say you wanted to share a little bit about where you are?

00:15:08,293 --> 00:15:09,423
Yeah, sure!

00:15:09,712 --> 00:15:14,470
So, one thing we've learned is that companies really need plans and structure.

00:15:14,470 --> 00:15:17,479
I know I said this earlier, but it's something where

00:15:17,479 --> 00:15:21,842
they need to have an answer for every kind of scenario that can pop up.

00:15:21,842 --> 00:15:28,779
One thing we've seen is companies offer free time or time off available to employees

00:15:28,779 --> 00:15:32,017
that is time off that you don't have to take vacation for

00:15:32,017 --> 00:15:34,525
just blanket time off during the pandemic.

00:15:34,796 --> 00:15:37,245
And what we've learned from different people we've interviewed

00:15:37,245 --> 00:15:40,567
is that particularly when their companies offer this

00:15:40,567 --> 00:15:47,489
the company didn't actually make a plan of how someone could access that time off.

00:15:48,064 --> 00:15:51,737
And then it turned out that time off was only actually available

00:15:51,737 --> 00:15:53,666
to some employees with children.

00:15:54,226 --> 00:15:57,393
So, one person, or a few people we interviewed

00:15:57,393 --> 00:16:00,471
really highlighted wanting to access this benefit

00:16:00,471 --> 00:16:05,149
and their managers actually didn't know how they could access that benefit

00:16:05,149 --> 00:16:07,961
so the managers had to go up the chain

00:16:08,072 --> 00:16:10,727
and then figure out actually what that would look like.

00:16:11,083 --> 00:16:14,585
So, the company made time off available

00:16:14,585 --> 00:16:20,441
but they didn't also make a plan for who would fill in the gaps of that time off

00:16:20,441 --> 00:16:22,470
so who picks up the slack

00:16:23,800 --> 00:16:28,393
if a third of the company decides to go 50% time.

00:16:29,363 --> 00:16:32,604
Offering that kind of support is one thing

00:16:32,907 --> 00:16:36,197
but you need to have a plan to implement that support

00:16:36,599 --> 00:16:39,820
so the company doesn't fall into chaos.

00:16:39,934 --> 00:16:42,602
In this case, there wasn't really a plan.

00:16:42,948 --> 00:16:45,254
Part of the implication was perhaps that

00:16:45,895 --> 00:16:50,378
the employees that were not taking time off would try to pick up some of the slack

00:16:50,378 --> 00:16:54,290
but that doesn't alleviate the employees who are working full time.

00:16:54,290 --> 00:16:55,799
That doesn't alleviate their stress

00:16:56,129 --> 00:17:02,459
or even the general anxiety they could feel in response to COVID-19 and working from home

00:17:02,459 --> 00:17:04,308
and the general stress of the pandemic

00:17:04,308 --> 00:17:05,844
which is stressful.

00:17:05,844 --> 00:17:10,844
One thing we also noticed is people generally feel much more anxiety now

00:17:10,844 --> 00:17:12,811
than they did before the pandemic.

00:17:13,004 --> 00:17:16,020
While that may seem like an obvious takeaway

00:17:16,020 --> 00:17:21,330
what that means is if your company is letting some employees take off and others not

00:17:21,730 --> 00:17:26,023
already emotionally taxed employees are now more taxed—they're over-taxed.

00:17:27,054 --> 00:17:28,185
So, that was a big thing.

00:17:28,255 --> 00:17:31,101
Another thing was we noticed some companies

00:17:32,656 --> 00:17:34,978
in response to working remotely

00:17:35,943 --> 00:17:37,334
created no work plan.

00:17:38,522 --> 00:17:40,630
Some people we interviewed remarked how

00:17:41,136 --> 00:17:46,563
their day-to-day accountability was just water-cooler chats with their manager.

00:17:46,812 --> 00:17:52,047
So, how do we translate a water-cooler chat in a remote workplace?

00:17:52,496 --> 00:17:56,860
That can be someone just randomly Slacking you or sending you a Gchat

00:17:57,366 --> 00:18:02,745
but while that sounds all so innocuous, imagine if you're knee-deep in a problem

00:18:02,745 --> 00:18:04,083
trying to problem-solve something

00:18:04,083 --> 00:18:06,136
and your manager just pings you out of nowhere.

00:18:06,216 --> 00:18:09,502
Trying to switch gears to respond to that can be stressful

00:18:09,502 --> 00:18:12,209
especially if you don't know when you're going to get pinged.

00:18:13,080 --> 00:18:15,370
That also means that at any point and any time

00:18:15,370 --> 00:18:18,476
if you got up to go to the bathroom, nobody knows that

00:18:18,953 --> 00:18:23,821
and so someone pings and you come back 20 minutes later to maybe "Where were you?"

00:18:23,961 --> 00:18:27,476
If you're in a very stressful workplace

00:18:27,476 --> 00:18:30,784
they may not trust that you were working and didn't see it.

00:18:30,784 --> 00:18:34,798
They may make all kinds of assumptions about your work.

00:18:35,725 --> 00:18:37,342
Also what I mean is that

00:18:37,742 --> 00:18:42,199
this lack of structure places a lot of stress on employees

00:18:42,199 --> 00:18:46,531
because it can be harder for them to show the work that they did during a day

00:18:46,531 --> 00:18:49,044
because there's no way to…

00:18:50,935 --> 00:18:53,171
there's no outline of what they're supposed to do.

00:18:53,790 --> 00:18:58,236
Or also it just means that they're working in these incredibly stressful short sprints

00:18:58,236 --> 00:19:02,156
if every day the plan is just tell your boss what you're working on.

00:19:02,156 --> 00:19:05,374
That is not a good project management plan.

00:19:06,036 --> 00:19:08,004
This also increases anxiety.

00:19:09,678 --> 00:19:14,308
Also, people are getting Slacked not during work hours

00:19:14,308 --> 00:19:20,599
and then feeling a general anxiety that they should be available to any message

00:19:20,599 --> 00:19:26,067
when in fact you are allowed to not respond to work

00:19:26,067 --> 00:19:29,461
if it's like 8 p.m. your time and that's not the time you work.

00:19:30,641 --> 00:19:31,885
So, different things like that.

00:19:31,885 --> 00:19:33,509
Another thing also is

00:19:34,667 --> 00:19:40,865
some companies we've noticed their way to try to make accountability

00:19:40,865 --> 00:19:44,324
is to just fill the day with different Zoom calls

00:19:44,324 --> 00:19:46,890
or different kinds of video calls and check-ins

00:19:47,168 --> 00:19:53,368
which also doesn't make an easier work day, because if you spend six hours in video calls

00:19:53,368 --> 00:19:55,823
when are you actually supposed to do your work?

00:19:57,023 --> 00:20:01,023
So it's different things like that that are actually extremely problematic

00:20:01,530 --> 00:20:04,068
and that are really disruptive for people's work styles

00:20:04,068 --> 00:20:07,137
and are increasing the level of stress that they're feeling.

00:20:07,834 --> 00:20:13,632
Yeah, and it sounds like key takeaways that you were mentioning are

00:20:13,859 --> 00:20:20,773
designing more structure for employees, but also designing with a user in mind

00:20:20,773 --> 00:20:26,430
so if there are benefits around taking time off

00:20:27,127 --> 00:20:30,083
designing that for the people that need it

00:20:30,663 --> 00:20:32,649
that may or may not have kids

00:20:32,649 --> 00:20:37,469
or may or may not have sick relatives or people they have to take care of.

00:20:38,777 --> 00:20:40,250
This is really fascinating.

00:20:40,250 --> 00:20:43,776
I hope that, yeah…

00:20:44,461 --> 00:20:49,393
I'm looking forward to reading the report and seeing where this goes.

00:20:54,289 --> 00:20:59,666
Great, so I think we covered all the topics

00:20:59,666 --> 00:21:02,849
that we had in our agenda.

00:21:02,947 --> 00:21:06,274
Is there anything else that I'm missing

00:21:06,274 --> 00:21:12,784
or anything else that you'd like to speak about?

00:21:14,532 --> 00:21:20,344
Sure, I think one thing I really want to emphasize for people listening to this is

00:21:22,215 --> 00:21:25,936
right now is a really stressful and taxing time for anybody

00:21:25,936 --> 00:21:30,361
regardless of the location they're in and regardless of who they are

00:21:30,361 --> 00:21:35,260
but it is especially stressful for marginalized groups

00:21:35,260 --> 00:21:37,069
and people of color right now.

00:21:38,990 --> 00:21:43,711
When we're designing things that can feel as mundane as a work structure

00:21:43,711 --> 00:21:45,853
those are not mundane structures.

00:21:45,853 --> 00:21:52,146
That will dictate how someone spends seven or eight or nine of their waking hours

00:21:52,146 --> 00:21:55,520
maybe even more, like 10 or 12, depending upon where someone works.

00:21:57,294 --> 00:21:59,505
One thing I often reflect on is

00:22:01,721 --> 00:22:05,721
I've been working remotely since 2016

00:22:06,051 --> 00:22:08,233
and at one place I worked at

00:22:08,563 --> 00:22:12,002
so much of my day was just being on video calls

00:22:12,002 --> 00:22:16,945
that I didn't have enough time in my day to actually do my job

00:22:16,945 --> 00:22:18,622
which was doing design research.

00:22:20,095 --> 00:22:23,622
My manager didn't really understand that.

00:22:23,622 --> 00:22:24,519
He didn't understand

00:22:24,519 --> 00:22:28,614
if I had a meeting and then an hour free time

00:22:28,674 --> 00:22:31,228
and then two meetings and then an hour free time

00:22:31,228 --> 00:22:34,362
why I couldn't get my work done.

00:22:35,064 --> 00:22:38,253
It was because he was not a researcher; he was a product manager

00:22:38,579 --> 00:22:42,677
and trying to explain to him how difficult it is to switch gears

00:22:42,677 --> 00:22:46,998
from writing to not writing to then answering emails

00:22:46,998 --> 00:22:49,273
that that just wasn't possible

00:22:50,098 --> 00:22:52,701
proved to be a really hard conversation with him.

00:22:53,608 --> 00:22:55,650
So, one thing I want to think about is that.

00:22:56,366 --> 00:22:58,748
Are they giving their employees time

00:22:58,748 --> 00:23:02,162
to build a work schedule that makes sense for them?

00:23:02,410 --> 00:23:05,254
For me, what would have been helpful is

00:23:05,254 --> 00:23:08,497
one day of work calls

00:23:09,181 --> 00:23:11,657
and then, let's say in a week

00:23:11,657 --> 00:23:15,139
if I needed to have 15 work calls

00:23:15,579 --> 00:23:18,621
can I spread that out across two days?

00:23:18,621 --> 00:23:22,907
Can I put that into two days, and then that's it?

00:23:22,907 --> 00:23:26,669
And then the rest of the week, can I have time for writing

00:23:27,162 --> 00:23:30,411
maybe one-on-one feedback on what I'm writing, etc.?

00:23:30,411 --> 00:23:35,487
That would have been a way for me to have been successful in my job.

00:23:37,272 --> 00:23:42,642
My manager made it seem like it was possible for our work to be that flexible

00:23:42,642 --> 00:23:43,855
when it really wasn't.

00:23:45,348 --> 00:23:50,475
No one would respect my time if I said, "I'm actually full with meetings."

00:23:50,475 --> 00:23:53,065
And "meetings" being like "I'm writing."

00:23:53,276 --> 00:23:54,196
So, that's what I mean.

00:23:54,196 --> 00:23:58,196
I want people to really reflect on that and interact with their employees

00:23:58,196 --> 00:24:01,674
and ask, "What do you need to be most successful?"

00:24:01,674 --> 00:24:07,696
And then to listen to their employees and give them that space and those boundaries

00:24:08,126 --> 00:24:11,526
so they can actually succeed during a time where it's really hard.

00:24:11,980 --> 00:24:14,111
One of our interviewees pointed out something

00:24:14,111 --> 00:24:18,360
that even though they're single and they don't have dependents

00:24:18,360 --> 00:24:21,934
it's really a stressful time for them because they're totally alone

00:24:22,311 --> 00:24:25,663
and that even doing basic things like going to the doctor

00:24:26,025 --> 00:24:27,967
can take three times as long

00:24:28,647 --> 00:24:30,374
or going and getting groceries.

00:24:31,165 --> 00:24:33,559
These regular, mundane things we do

00:24:33,559 --> 00:24:36,714
are also much harder to do

00:24:37,121 --> 00:24:40,267
and their schedule wasn't allowing for that

00:24:40,799 --> 00:24:44,293
and their manager didn't seem to understand that either.

00:24:44,495 --> 00:24:46,438
It was like, "Oh, but you don't have a dependent

00:24:46,438 --> 00:24:47,564
so why is it hard for you?"

00:24:47,564 --> 00:24:49,449
Well, it is stressful going to the grocery store

00:24:49,449 --> 00:24:51,322
if it takes me four hours to do that.

00:24:52,634 --> 00:24:55,525
Or it is stressful if I get a call from the doctor

00:24:55,525 --> 00:24:58,894
and they suddenly have something open, otherwise it's a three-month wait.

00:24:58,894 --> 00:25:01,625
That is stress-inducing

00:25:01,781 --> 00:25:07,522
and so this is what I mean where I think companies can't just say they're listening

00:25:07,522 --> 00:25:08,579
or that they want to help.

00:25:08,579 --> 00:25:11,601
They actually have to put that help into practice

00:25:11,706 --> 00:25:13,984
and design a system that responds to it.

00:25:14,935 --> 00:25:21,111
Another person mentioned how their workplace was going to have a day with no meetings

00:25:21,421 --> 00:25:26,073
but didn't actually think about how to redesign their work

00:25:26,073 --> 00:25:28,368
so they needed fewer meetings.

00:25:28,642 --> 00:25:30,964
So it's like, "OK, if you give us a day with no meetings

00:25:30,964 --> 00:25:34,876
all the meetings have to go somewhere else then

00:25:34,876 --> 00:25:38,097
unless we figure out a way to really eliminate meetings

00:25:38,254 --> 00:25:40,402
or eliminate some unnecessary meetings."

00:25:40,402 --> 00:25:42,128
And this is what I mean with a structure.

00:25:42,428 --> 00:25:45,988
Saying you can have time off or saying we're going to have fewer meetings

00:25:45,988 --> 00:25:49,632
you have to translate that into a structure

00:25:49,632 --> 00:25:53,238
and a plan that makes space and time for that.

00:25:53,328 --> 00:25:54,776
That may mean bringing on

00:25:55,152 --> 00:25:57,509
for this one company that said, "You can all work part time"

00:25:57,754 --> 00:26:00,349
that may mean bringing on more part-time employees

00:26:00,736 --> 00:26:02,084
so the work can still get done.

00:26:02,188 --> 00:26:04,603
If another company is saying they want to have fewer meetings

00:26:04,603 --> 00:26:06,254
that means sitting down and asking

00:26:07,232 --> 00:26:09,238
"How can we translate some of these meetings

00:26:09,238 --> 00:26:15,774
into digital asynchronous standups that happen across messaging platforms?

00:26:16,322 --> 00:26:19,185
How can we better translate meetings into emails?"

00:26:22,525 --> 00:26:23,828
Thank you so much, Caroline.

00:26:23,828 --> 00:26:29,713
Thank you for joining this fireside chat and for sharing what you have learned

00:26:31,098 --> 00:26:34,238
and what you're learning in the process as well.

00:26:36,159 --> 00:26:39,563
We look forward to reading the outcomes of your research.

00:26:40,104 --> 00:26:42,484

YouTube URL: https://www.youtube.com/watch?v=JfI4O_4BIlU


