Title: Bazel Remote Execution and Remote Caching w  Uber and TwoSigma
Publication date: 2017-12-08
Playlist: BazelCon 2017
Description: 
	Presented by George Gensure (Uber) and Alpha Lam (Two Sigma)
Captions: 
	00:00:00,000 --> 00:00:04,980
alpha from 2 Sigma and George from uber

00:00:02,639 --> 00:00:07,560
have been contributing actively to our

00:00:04,980 --> 00:00:09,420
bill farm effort that I just looked up

00:00:07,560 --> 00:00:13,170
on the agendas we started talking about

00:00:09,420 --> 00:00:14,790
this in April and somewhere in August

00:00:13,170 --> 00:00:18,600
George particularly started committing

00:00:14,790 --> 00:00:20,520
large masses of code 53 commits masses

00:00:18,600 --> 00:00:22,890
but for an open source project it's

00:00:20,520 --> 00:00:25,800
great and we've been meeting weekly with

00:00:22,890 --> 00:00:28,380
this group since April and initially the

00:00:25,800 --> 00:00:32,489
core team members were of George from

00:00:28,380 --> 00:00:35,640
uber and and alpha and also we've got

00:00:32,489 --> 00:00:37,710
Huawei contributors as well as Twitter

00:00:35,640 --> 00:00:39,930
our team was very interested in coming

00:00:37,710 --> 00:00:41,610
to the latest sessions so welcome for

00:00:39,930 --> 00:00:43,710
you to join the session this is a

00:00:41,610 --> 00:00:46,020
monthly working group where we're

00:00:43,710 --> 00:00:48,390
discussing the community efforts and

00:00:46,020 --> 00:00:50,070
feel free to contribute at this point

00:00:48,390 --> 00:00:51,840
it's also available for you to use but

00:00:50,070 --> 00:00:59,850
George and alpha will tell you all about

00:00:51,840 --> 00:01:02,789
that hello everyone so my name is alpha

00:00:59,850 --> 00:01:04,949
lamb so today my topic I'm gonna go

00:01:02,789 --> 00:01:06,720
first go talk a little bit about the

00:01:04,949 --> 00:01:09,180
remote cash first because that's one of

00:01:06,720 --> 00:01:12,390
the critical part that you know that the

00:01:09,180 --> 00:01:13,860
remote X is gonna base on so so here's a

00:01:12,390 --> 00:01:16,830
little bit of disclaimer from our

00:01:13,860 --> 00:01:20,009
company I have to give this if you guys

00:01:16,830 --> 00:01:25,290
know about marketing to you so I wear

00:01:20,009 --> 00:01:27,390
mine so Who am I so I worked in a team

00:01:25,290 --> 00:01:30,000
call sdlc software development lifecycle

00:01:27,390 --> 00:01:32,400
for platform engineering or two sigma

00:01:30,000 --> 00:01:34,920
investment so we based in New York so

00:01:32,400 --> 00:01:37,470
our team is most so our team's function

00:01:34,920 --> 00:01:40,920
is to manage the infrastructure for our

00:01:37,470 --> 00:01:42,720
build test and artifact storage and a

00:01:40,920 --> 00:01:44,310
content distribution network for the

00:01:42,720 --> 00:01:47,460
artifact storage is there are the

00:01:44,310 --> 00:01:49,530
artifacts so I want to talk a little bit

00:01:47,460 --> 00:01:51,990
about our build and why do we use Bezos

00:01:49,530 --> 00:01:54,210
so internally we have a build system

00:01:51,990 --> 00:01:55,049
that's stitched together about 7,000

00:01:54,210 --> 00:01:56,969
built modules

00:01:55,049 --> 00:02:00,090
it's each of them is a pretty bulky one

00:01:56,969 --> 00:02:02,009
so and we we practice like this mono

00:02:00,090 --> 00:02:05,340
repo approach which means every single

00:02:02,009 --> 00:02:08,369
push we will build test everything right

00:02:05,340 --> 00:02:10,890
so given we have 600 engineers around

00:02:08,369 --> 00:02:13,200
that number we're doing about 5,000 full

00:02:10,890 --> 00:02:14,050
builds a day and about half a million

00:02:13,200 --> 00:02:16,600
module

00:02:14,050 --> 00:02:18,670
and a lot of tests that we running for

00:02:16,600 --> 00:02:20,680
every single push so are we really

00:02:18,670 --> 00:02:22,690
hoping that moving to Basel will speed

00:02:20,680 --> 00:02:25,240
this up so we've successfully migrated a

00:02:22,690 --> 00:02:27,280
couple of the modules about total 10,000

00:02:25,240 --> 00:02:30,700
new actions to basel we're actively

00:02:27,280 --> 00:02:33,760
trying to do this more so what is our

00:02:30,700 --> 00:02:36,730
challenges when we move to Basel right

00:02:33,760 --> 00:02:39,490
so first we really need fast farm build

00:02:36,730 --> 00:02:42,070
right like we have so many full builds a

00:02:39,490 --> 00:02:43,900
day and each of the module builds can

00:02:42,070 --> 00:02:46,180
share code and a lot of duplication

00:02:43,900 --> 00:02:47,710
actions between them so we want to be

00:02:46,180 --> 00:02:49,570
able to execute really fast and not

00:02:47,710 --> 00:02:52,090
waste any time of doing these things and

00:02:49,570 --> 00:02:54,280
the users one do really fast local

00:02:52,090 --> 00:02:56,020
builds as well that means they go into

00:02:54,280 --> 00:02:57,670
work they check out the code and they

00:02:56,020 --> 00:02:59,920
bill and they you know in a couple

00:02:57,670 --> 00:03:02,440
minutes they should be able to see you

00:02:59,920 --> 00:03:04,150
know and work from there and so so as

00:03:02,440 --> 00:03:07,120
the user can have multiple clones so

00:03:04,150 --> 00:03:09,430
same reason goes there and we have a

00:03:07,120 --> 00:03:11,770
pretty resource heavy of a test farm we

00:03:09,430 --> 00:03:13,930
have a test for about six thousand cores

00:03:11,770 --> 00:03:15,610
so we really it's really resource heavy

00:03:13,930 --> 00:03:18,070
and time consuming to run all those

00:03:15,610 --> 00:03:20,800
tests so what is a solution to this

00:03:18,070 --> 00:03:24,670
problem a solution to this problem is to

00:03:20,800 --> 00:03:27,190
build a remote cache that is used to

00:03:24,670 --> 00:03:30,340
store the bill artifacts and a test

00:03:27,190 --> 00:03:32,830
results and the cache is you know being

00:03:30,340 --> 00:03:36,010
remote means it can be shared between

00:03:32,830 --> 00:03:37,810
the bill bots and the users so like they

00:03:36,010 --> 00:03:40,840
would just share the bill result they

00:03:37,810 --> 00:03:43,180
execute and they go so we we contributed

00:03:40,840 --> 00:03:45,760
the first remote cache implementation to

00:03:43,180 --> 00:03:48,340
basel and over time it has you know a

00:03:45,760 --> 00:03:50,230
lot of improvements made from

00:03:48,340 --> 00:03:53,320
contributors your damned catholic he

00:03:50,230 --> 00:03:56,320
introduced the rest implementation so if

00:03:53,320 --> 00:03:58,360
we just talked here he implemented the

00:03:56,320 --> 00:04:00,520
local disk cache and recently made it

00:03:58,360 --> 00:04:03,490
possible so that the remote cache works

00:04:00,520 --> 00:04:05,380
with sandboxing and other remote no

00:04:03,490 --> 00:04:07,600
other spawn strategies like worker

00:04:05,380 --> 00:04:09,370
strategy so and then of course there are

00:04:07,600 --> 00:04:11,860
many other contributors that I probably

00:04:09,370 --> 00:04:14,860
missed here so thank you everyone for

00:04:11,860 --> 00:04:17,290
contributing to that so what is it

00:04:14,860 --> 00:04:20,350
capable off in days Oh today about

00:04:17,290 --> 00:04:23,350
remote cache so you can use it for build

00:04:20,350 --> 00:04:25,540
and test and it'll work for general and

00:04:23,350 --> 00:04:27,370
sky lock rules as long as they are high

00:04:25,540 --> 00:04:28,180
Matic you don't look you don't tag them

00:04:27,370 --> 00:04:30,039
as local

00:04:28,180 --> 00:04:32,650
romantically then you can use it with

00:04:30,039 --> 00:04:35,470
the remote cash so it can work with

00:04:32,650 --> 00:04:38,620
local sandbox execution that means you

00:04:35,470 --> 00:04:39,250
run your executed job in action in a

00:04:38,620 --> 00:04:41,889
sandbox

00:04:39,250 --> 00:04:44,680
fetch the results and then you can share

00:04:41,889 --> 00:04:47,020
with the other users and theoretically

00:04:44,680 --> 00:04:48,699
it can support any you know size of the

00:04:47,020 --> 00:04:51,100
artifacts so there's chunking supporting

00:04:48,699 --> 00:04:53,740
the G RPC implementation and then in the

00:04:51,100 --> 00:04:55,660
latest version of basil and master it

00:04:53,740 --> 00:04:57,729
should support like our text stream so

00:04:55,660 --> 00:05:01,900
for risk implementation it should

00:04:57,729 --> 00:05:04,000
support any size - so so from this point

00:05:01,900 --> 00:05:05,889
on I'm gonna go dive deep a little bit

00:05:04,000 --> 00:05:10,780
about how this works as an intro for

00:05:05,889 --> 00:05:13,030
George so how does basil execute so it

00:05:10,780 --> 00:05:14,680
you know everybody knows I mean most of

00:05:13,030 --> 00:05:17,050
you knows that basil is split into three

00:05:14,680 --> 00:05:19,870
phases so loading phase and Alice a

00:05:17,050 --> 00:05:22,360
phase so after these two phases at the

00:05:19,870 --> 00:05:25,389
end of it during the execution phase you

00:05:22,360 --> 00:05:26,949
have you have an action graph and the

00:05:25,389 --> 00:05:30,430
action is actually what we call it

00:05:26,949 --> 00:05:32,979
spawns in basil so in this example you

00:05:30,430 --> 00:05:35,860
see about three spawns so the first one

00:05:32,979 --> 00:05:37,900
is a spawn that compiles a code

00:05:35,860 --> 00:05:39,520
generator you know and in the second one

00:05:37,900 --> 00:05:41,979
runs the code generator spits out a

00:05:39,520 --> 00:05:44,860
header file and the third one takes in

00:05:41,979 --> 00:05:47,770
the header file generate a header file

00:05:44,860 --> 00:05:50,110
come house to it so this is the same for

00:05:47,770 --> 00:05:52,539
Bill and tests so each of them like like

00:05:50,110 --> 00:05:54,610
you've just mentioned each of the bill

00:05:52,539 --> 00:05:57,310
and test action translate you're just

00:05:54,610 --> 00:06:00,370
saying something called spawn and so

00:05:57,310 --> 00:06:03,669
what goes into a spawn so because we

00:06:00,370 --> 00:06:06,039
give basil really fine information about

00:06:03,669 --> 00:06:08,860
its dependencies each spawns knows about

00:06:06,039 --> 00:06:11,110
what is the exact input and output files

00:06:08,860 --> 00:06:12,909
and the tools that are needed and you we

00:06:11,110 --> 00:06:14,949
know about the command-line arguments

00:06:12,909 --> 00:06:17,020
and then the environment variables and

00:06:14,949 --> 00:06:20,610
other things such as the platform and

00:06:17,020 --> 00:06:23,080
what your Hardware requires okay and

00:06:20,610 --> 00:06:26,500
then we added something new to this

00:06:23,080 --> 00:06:29,409
picture call a spawn cache a spawn cache

00:06:26,500 --> 00:06:32,530
has three functions so first it takes a

00:06:29,409 --> 00:06:34,570
spawn and compute it as a key right so

00:06:32,530 --> 00:06:37,060
we take the input files computer mirco

00:06:34,570 --> 00:06:38,919
tree hash to it we have a key and we add

00:06:37,060 --> 00:06:40,840
in arguments and then we add in our

00:06:38,919 --> 00:06:41,930
environment variables a bunch of inputs

00:06:40,840 --> 00:06:44,090
to respond and then we

00:06:41,930 --> 00:06:47,330
have a unique key to identify this part

00:06:44,090 --> 00:06:49,490
and we once we have this key we can use

00:06:47,330 --> 00:06:51,139
this to store the result of the spawn

00:06:49,490 --> 00:06:52,550
meaning that whether it compiles

00:06:51,139 --> 00:06:54,889
successfully whether the Testament

00:06:52,550 --> 00:06:56,840
successfully and in the list of output

00:06:54,889 --> 00:07:00,770
files that are associated with this

00:06:56,840 --> 00:07:03,590
spawn and we also this de-spawn cache

00:07:00,770 --> 00:07:06,680
also has a content addressable store so

00:07:03,590 --> 00:07:09,050
with a list of output files being hash

00:07:06,680 --> 00:07:11,690
keys or mirco tree hash you can duo

00:07:09,050 --> 00:07:14,360
download the output files from the

00:07:11,690 --> 00:07:16,520
content-addressable store and we make

00:07:14,360 --> 00:07:18,650
changes to the spawn excuse execution

00:07:16,520 --> 00:07:21,110
strategies so that before it go execute

00:07:18,650 --> 00:07:23,150
it it computes the hash look it up in a

00:07:21,110 --> 00:07:24,919
cache if it is there now all the stuff

00:07:23,150 --> 00:07:27,110
it is not there running locally and

00:07:24,919 --> 00:07:29,870
uploads the results that's how the the

00:07:27,110 --> 00:07:32,539
remote cache works so there are three

00:07:29,870 --> 00:07:35,090
backends for the remote cash today

00:07:32,539 --> 00:07:38,509
so there are rest cache like I mentioned

00:07:35,090 --> 00:07:41,539
earlier like then Dan fablet implemented

00:07:38,509 --> 00:07:44,060
this so there are two endpoints the

00:07:41,539 --> 00:07:46,610
arrest cache so one like I said earlier

00:07:44,060 --> 00:07:49,940
one is the action cache which is just

00:07:46,610 --> 00:07:51,530
tells you the the result of action of a

00:07:49,940 --> 00:07:54,349
spawn and then there's a content

00:07:51,530 --> 00:07:56,120
addressable endpoint which goes to

00:07:54,349 --> 00:07:58,130
download the files in the directories

00:07:56,120 --> 00:07:59,570
and you use it by the flag there there's

00:07:58,130 --> 00:08:02,449
only three methods you need to implement

00:07:59,570 --> 00:08:04,220
the head checks if the key is there the

00:08:02,449 --> 00:08:06,770
get downloads the key to put you know

00:08:04,220 --> 00:08:09,409
uploads the key and then there's a G RPC

00:08:06,770 --> 00:08:11,570
implementation which is a lot more

00:08:09,409 --> 00:08:14,389
performant and it's being actively

00:08:11,570 --> 00:08:16,580
worked on so you use it by the flag

00:08:14,389 --> 00:08:18,190
again you point it to a G RPC endpoint

00:08:16,580 --> 00:08:21,139
and this should go white like that and

00:08:18,190 --> 00:08:23,720
and lastly there's a there's a new

00:08:21,139 --> 00:08:26,120
experimental local disk cache

00:08:23,720 --> 00:08:28,490
implementation which means you can you

00:08:26,120 --> 00:08:30,199
know switch between clones and point it

00:08:28,490 --> 00:08:32,930
to that flag and we will share the cache

00:08:30,199 --> 00:08:36,469
between the clumps between workspaces of

00:08:32,930 --> 00:08:38,719
course and so today I'm gonna focus a

00:08:36,469 --> 00:08:40,729
little bit more about the rest cache so

00:08:38,719 --> 00:08:43,130
in order to use it you just need to flex

00:08:40,729 --> 00:08:45,800
right so in and now I'm talking about a

00:08:43,130 --> 00:08:47,720
master so in an older version you don't

00:08:45,800 --> 00:08:50,060
have this flag and just go to the master

00:08:47,720 --> 00:08:51,740
with this flag with experimental remote

00:08:50,060 --> 00:08:54,140
spawn casually those are true and then

00:08:51,740 --> 00:08:55,910
you pass in the endpoint of the rest

00:08:54,140 --> 00:08:58,850
cache and you should be able to

00:08:55,910 --> 00:09:01,940
use it immediately and like I said it's

00:08:58,850 --> 00:09:03,890
the same goes for boo and test so here's

00:09:01,940 --> 00:09:06,560
a little bit of a benchmark taken from

00:09:03,890 --> 00:09:08,750
our build hope you know how much is feed

00:09:06,560 --> 00:09:11,600
up it can give us so we have we take a

00:09:08,750 --> 00:09:14,900
bill of a couple modules they have about

00:09:11,600 --> 00:09:17,240
10,000 build steps most of them are see

00:09:14,900 --> 00:09:20,030
compilation step and cogeneration step

00:09:17,240 --> 00:09:22,070
using skylark and general in a local

00:09:20,030 --> 00:09:24,590
bill using a 16 course machine would

00:09:22,070 --> 00:09:27,080
take about 10 minutes to do it and with

00:09:24,590 --> 00:09:28,760
a cash build mostly is just downloading

00:09:27,080 --> 00:09:31,040
everything nothing has to be executed

00:09:28,760 --> 00:09:32,930
it's about 30 seconds so we expect that

00:09:31,040 --> 00:09:34,190
if you use a cache like that will give

00:09:32,930 --> 00:09:39,020
you a magnitude or two magnitude

00:09:34,190 --> 00:09:40,970
magnitude of speed okay so I would like

00:09:39,020 --> 00:09:43,400
to share a little bit more about how we

00:09:40,970 --> 00:09:47,510
implemented our distributed or remote

00:09:43,400 --> 00:09:50,390
cash inside to Sigma so into Sigma we we

00:09:47,510 --> 00:09:53,060
use Facebook has pretty extensively so

00:09:50,390 --> 00:09:55,340
hey sook has is a distributed in memory

00:09:53,060 --> 00:09:57,500
cache there's written in Java is pretty

00:09:55,340 --> 00:10:01,490
easy to set up so we combine it with

00:09:57,500 --> 00:10:03,680
kubernetes so it has built in rest cache

00:10:01,490 --> 00:10:06,260
support so you can just simply point

00:10:03,680 --> 00:10:08,150
basil edit or run so what about fault

00:10:06,260 --> 00:10:11,000
tolerance I like I mentioned earlier we

00:10:08,150 --> 00:10:12,530
use kubernetes so we use kubernetes to

00:10:11,000 --> 00:10:16,220
set up let's say for this for this

00:10:12,530 --> 00:10:19,340
example a replication of two parts and

00:10:16,220 --> 00:10:21,410
they form a memory cluster inside and

00:10:19,340 --> 00:10:23,540
then kubernetes provide us the load

00:10:21,410 --> 00:10:25,970
balancers so you switch between a two

00:10:23,540 --> 00:10:29,360
and Akash's switch and is replicated

00:10:25,970 --> 00:10:31,280
across two machines and their Lu cache

00:10:29,360 --> 00:10:33,770
support by default and it's pretty easy

00:10:31,280 --> 00:10:36,740
to monitor we just put it in other jmock

00:10:33,770 --> 00:10:39,140
strands and send it to like stats D and

00:10:36,740 --> 00:10:41,750
you can easily do this is easy to setup

00:10:39,140 --> 00:10:44,090
there's no code at all it gives you full

00:10:41,750 --> 00:10:47,330
tolerance and replication that's pretty

00:10:44,090 --> 00:10:49,190
nice so what are the best practices from

00:10:47,330 --> 00:10:52,160
what we learn for using the rest cache

00:10:49,190 --> 00:10:53,630
or remote area in general so first of

00:10:52,160 --> 00:10:55,880
all is to write formatic

00:10:53,630 --> 00:10:58,730
rules and try to use sandbox as much as

00:10:55,880 --> 00:11:01,070
possible and I try to avoid using like

00:10:58,730 --> 00:11:03,080
absolute paths in your gen rule or your

00:11:01,070 --> 00:11:04,850
skylight rule right because across

00:11:03,080 --> 00:11:06,080
machines those could be different and

00:11:04,850 --> 00:11:08,000
you don't want them to be different

00:11:06,080 --> 00:11:09,740
because that gives you incorrect results

00:11:08,000 --> 00:11:13,130
in your executions

00:11:09,740 --> 00:11:15,590
and so and more importantly if you have

00:11:13,130 --> 00:11:17,600
a form of billboards it's good to have

00:11:15,590 --> 00:11:18,830
them all using the same tool chain so

00:11:17,600 --> 00:11:21,410
the way that we do that is by using

00:11:18,830 --> 00:11:23,330
containers and kubernetes so we ship out

00:11:21,410 --> 00:11:25,280
bill BOTS and kubernetes and make sure

00:11:23,330 --> 00:11:30,140
they all have the same bits on the disk

00:11:25,280 --> 00:11:32,420
and and lastly what I say one thing I

00:11:30,140 --> 00:11:34,310
mentioned is uh it's also good to try to

00:11:32,420 --> 00:11:36,590
check in your two chains for example

00:11:34,310 --> 00:11:38,690
checking your JDK to a chain or even GCC

00:11:36,590 --> 00:11:41,360
or clang to make sure that everybody has

00:11:38,690 --> 00:11:43,340
the same bits for them and then they you

00:11:41,360 --> 00:11:45,560
have a reliable cache and then at the

00:11:43,340 --> 00:11:47,690
end is trying to avoid cache

00:11:45,560 --> 00:11:49,670
contamination meaning that you have bad

00:11:47,690 --> 00:11:51,380
users that uploading that stuff that you

00:11:49,670 --> 00:11:53,480
know points and everybody that's

00:11:51,380 --> 00:11:55,310
something to prevent the way that we do

00:11:53,480 --> 00:11:57,290
it today is not so nice where you have

00:11:55,310 --> 00:11:59,510
to explicitly disable that for the Deaf

00:11:57,290 --> 00:12:03,700
machines but maybe in the future we can

00:11:59,510 --> 00:12:06,770
improve that okay I'll give you my patch

00:12:03,700 --> 00:12:09,770
that's cool so uh so here's a little bit

00:12:06,770 --> 00:12:11,330
of a limitations about the rest cache

00:12:09,770 --> 00:12:13,160
implementation there's no authentication

00:12:11,330 --> 00:12:15,980
so it doesn't work with you if you have

00:12:13,160 --> 00:12:18,080
Kerberos or other off mechanism there's

00:12:15,980 --> 00:12:20,420
no chunking so I'll give it a try on

00:12:18,080 --> 00:12:22,250
like uploading large files if it doesn't

00:12:20,420 --> 00:12:25,580
work file some issues will work on it

00:12:22,250 --> 00:12:28,250
and then there's a common issue about

00:12:25,580 --> 00:12:30,590
all these remote cache implementation is

00:12:28,250 --> 00:12:32,450
that you have to download all in the

00:12:30,590 --> 00:12:34,370
media artifacts you have to execute it

00:12:32,450 --> 00:12:37,520
because that's that's a way currently it

00:12:34,370 --> 00:12:39,260
is implemented so I want to talk a

00:12:37,520 --> 00:12:40,820
little bit about this limitations and

00:12:39,260 --> 00:12:43,550
there's some potential improvements

00:12:40,820 --> 00:12:45,740
maybe we can do in the future so he was

00:12:43,550 --> 00:12:47,990
a huge example that I mentioned earlier

00:12:45,740 --> 00:12:49,430
so on the left you have the code

00:12:47,990 --> 00:12:51,470
generator you compile a code generator

00:12:49,430 --> 00:12:54,140
the second one you run a code generator

00:12:51,470 --> 00:12:56,000
and there a third one you use you take

00:12:54,140 --> 00:12:59,240
the generator header and run the final

00:12:56,000 --> 00:13:01,550
binary so the cache works by hashing the

00:12:59,240 --> 00:13:05,150
input of the command line and a content

00:13:01,550 --> 00:13:07,310
of the files of the direct input or that

00:13:05,150 --> 00:13:09,320
spawn and because of that we have to

00:13:07,310 --> 00:13:12,020
download the result from the previous

00:13:09,320 --> 00:13:14,150
spawns or at least a manifest of it to

00:13:12,020 --> 00:13:15,860
know the hash you know to compute the

00:13:14,150 --> 00:13:18,080
hash for the next action then order

00:13:15,860 --> 00:13:20,540
download the results right and so that's

00:13:18,080 --> 00:13:22,490
why you know it eats up a lot of your

00:13:20,540 --> 00:13:25,130
network bandwidth

00:13:22,490 --> 00:13:28,220
and it's you know of course wasteful so

00:13:25,130 --> 00:13:30,830
in your one potential improvement in the

00:13:28,220 --> 00:13:34,040
future is that we can we could make the

00:13:30,830 --> 00:13:36,050
hashkee transitive meaning that the the

00:13:34,040 --> 00:13:37,760
cash key for the first action can be

00:13:36,050 --> 00:13:39,260
used immediately for the next one you

00:13:37,760 --> 00:13:41,660
don't have to download the results and

00:13:39,260 --> 00:13:43,580
so with this all you need is just to

00:13:41,660 --> 00:13:46,339
have the source files on disk and you

00:13:43,580 --> 00:13:48,320
can have a whole Mirko tree graph of the

00:13:46,339 --> 00:13:51,470
entire action and then you can you know

00:13:48,320 --> 00:13:52,820
take anybody at any point in time at any

00:13:51,470 --> 00:13:55,820
point in the graph and try to download

00:13:52,820 --> 00:13:57,350
the results and execute from there so so

00:13:55,820 --> 00:13:58,700
like I said this is a pretension

00:13:57,350 --> 00:14:00,380
provement that you've told me this is

00:13:58,700 --> 00:14:03,920
gonna be a really big change but we'll

00:14:00,380 --> 00:14:05,959
see so from this point on I'm gonna give

00:14:03,920 --> 00:14:07,640
it to George to talk a little bit more a

00:14:05,959 --> 00:14:16,300
lot more actually about remote execution

00:14:07,640 --> 00:14:19,279
is pretty cool demo thanks APIs so

00:14:16,300 --> 00:14:21,500
before I even jump into my talk I'll say

00:14:19,279 --> 00:14:24,320
that I've got a fairly large build

00:14:21,500 --> 00:14:28,330
running here a hundred thousand actions

00:14:24,320 --> 00:14:30,589
spinning on my 8 core machine and

00:14:28,330 --> 00:14:33,650
occupying further little memory but

00:14:30,589 --> 00:14:35,779
doing very fairly CPU can intensive

00:14:33,650 --> 00:14:38,120
things I've got about 50,000 CPU seconds

00:14:35,779 --> 00:14:39,740
worth of computation to be done in this

00:14:38,120 --> 00:14:43,490
build and I've been running it since the

00:14:39,740 --> 00:14:45,560
presentation has started keep in mind we

00:14:43,490 --> 00:14:47,660
haven't even computed the the right-hand

00:14:45,560 --> 00:14:49,550
side of that action count because we're

00:14:47,660 --> 00:14:52,180
still at 80,000 it'll eventually go to a

00:14:49,550 --> 00:14:57,110
hundred thousand or ninety nine thousand

00:14:52,180 --> 00:14:59,570
hi I'm George I'm from over I am the

00:14:57,110 --> 00:15:01,400
lead build engineer for uber ATG the

00:14:59,570 --> 00:15:06,350
autonomous vehicles division of uber

00:15:01,400 --> 00:15:08,480
it's about all I can say about it I've

00:15:06,350 --> 00:15:09,260
been a build system engineer for about

00:15:08,480 --> 00:15:11,390
ten years

00:15:09,260 --> 00:15:13,550
hopped around and done a bunch of

00:15:11,390 --> 00:15:17,570
different things built a couple of my

00:15:13,550 --> 00:15:19,339
build systems myself but where I come at

00:15:17,570 --> 00:15:21,170
this from his I'm the Linux systems

00:15:19,339 --> 00:15:23,500
programmer I'm used to dealing with

00:15:21,170 --> 00:15:26,810
hardware I'm used to dealing with

00:15:23,500 --> 00:15:28,910
bottlenecks that don't really get to be

00:15:26,810 --> 00:15:30,829
avoidable you have to take shortcuts

00:15:28,910 --> 00:15:34,280
around everything and that's what we're

00:15:30,829 --> 00:15:36,500
doing we're trying to make

00:15:34,280 --> 00:15:38,780
the build system that you know and love

00:15:36,500 --> 00:15:40,250
that you get exposed to every day that

00:15:38,780 --> 00:15:43,250
all of your developers have to interface

00:15:40,250 --> 00:15:45,830
with try be able to utilize resources

00:15:43,250 --> 00:15:48,830
beyond just the crappy laptop that you

00:15:45,830 --> 00:15:50,840
gave them the eight cores that you gave

00:15:48,830 --> 00:15:52,610
them are never enough the 64 core is on

00:15:50,840 --> 00:15:55,520
the big core station machine are never

00:15:52,610 --> 00:15:57,770
enough the one gig network that you

00:15:55,520 --> 00:15:59,890
built is never enough and so we need to

00:15:57,770 --> 00:16:08,630
build something that's going to be

00:15:59,890 --> 00:16:09,260
usable at scale and at I would say if

00:16:08,630 --> 00:16:11,420
you

00:16:09,260 --> 00:16:12,860
you can't even budget in many cases in

00:16:11,420 --> 00:16:15,140
terms of build systems going forward

00:16:12,860 --> 00:16:17,690
this is just anecdotal stuff for me

00:16:15,140 --> 00:16:19,670
I can't budget for the number of people

00:16:17,690 --> 00:16:21,410
that I expect to have or the amount of

00:16:19,670 --> 00:16:24,080
lines of code that I expect to have or

00:16:21,410 --> 00:16:25,970
the resources that I expect to support

00:16:24,080 --> 00:16:27,950
or the number of different distributions

00:16:25,970 --> 00:16:29,660
or different tool chains with parallel

00:16:27,950 --> 00:16:35,060
executions that I attend the support

00:16:29,660 --> 00:16:37,400
because everything is quadratic so I

00:16:35,060 --> 00:16:39,650
have to leverage the only ability that I

00:16:37,400 --> 00:16:41,180
have to executing quadratic frameworks

00:16:39,650 --> 00:16:42,800
and that's to put more things and more

00:16:41,180 --> 00:16:47,240
racks and B make them more accessible

00:16:42,800 --> 00:16:49,790
all the time so that comes down to what

00:16:47,240 --> 00:16:53,240
Google has released as the version one

00:16:49,790 --> 00:16:55,130
test API for remote execution which

00:16:53,240 --> 00:16:58,670
includes not just elements of remote

00:16:55,130 --> 00:17:00,530
caching and elements of content

00:16:58,670 --> 00:17:04,640
addressable storage but also this little

00:17:00,530 --> 00:17:07,100
execution API the institution API is the

00:17:04,640 --> 00:17:09,020
entrance into how we're going to

00:17:07,100 --> 00:17:10,970
distribute work over these clusters and

00:17:09,020 --> 00:17:14,480
our lingua franca our primitive

00:17:10,970 --> 00:17:16,220
operation is the action I'm sorry I

00:17:14,480 --> 00:17:18,380
didn't coordinate with with alpha before

00:17:16,220 --> 00:17:21,460
but in his terminology who have spawned

00:17:18,380 --> 00:17:24,650
squads are actually instances of actions

00:17:21,460 --> 00:17:26,000
or one way or another in short I'm going

00:17:24,650 --> 00:17:27,200
to I'm gonna refer to these things as

00:17:26,000 --> 00:17:30,350
actions and I hope that's going to be

00:17:27,200 --> 00:17:31,490
clear going forward our initial

00:17:30,350 --> 00:17:34,370
implementation our reference

00:17:31,490 --> 00:17:37,280
implementation of what the Google team

00:17:34,370 --> 00:17:39,890
brought us in terms of the three core

00:17:37,280 --> 00:17:42,050
services has come out in a project

00:17:39,890 --> 00:17:43,700
called Bill farm I have a little link

00:17:42,050 --> 00:17:45,710
here through our open source project and

00:17:43,700 --> 00:17:47,299
it lives under the vaso community and

00:17:45,710 --> 00:17:48,379
theoretically is

00:17:47,299 --> 00:17:52,549
you know a little bit sanctioned by you

00:17:48,379 --> 00:17:56,029
guys our architecture for build farm

00:17:52,549 --> 00:17:58,519
models very closely to the api's

00:17:56,029 --> 00:18:01,070
definition it is a services our Gator

00:17:58,519 --> 00:18:04,100
you might also call it an instance

00:18:01,070 --> 00:18:05,509
multiplexer and if if the latter part of

00:18:04,100 --> 00:18:07,100
that is confusing to you hopefully I'll

00:18:05,509 --> 00:18:10,249
get to it in the lair sections of the

00:18:07,100 --> 00:18:11,720
slides the services the main three

00:18:10,249 --> 00:18:13,039
services that we're supporting are as

00:18:11,720 --> 00:18:17,179
alpha mentioned the content addressable

00:18:13,039 --> 00:18:19,730
storage an action cache and an execution

00:18:17,179 --> 00:18:21,109
service the interface for the top two is

00:18:19,730 --> 00:18:24,109
very similar the air fish at the bottom

00:18:21,109 --> 00:18:27,559
is very different and then the instances

00:18:24,109 --> 00:18:30,619
are ways that we divide the selectable

00:18:27,559 --> 00:18:32,509
pools that we want to access from the

00:18:30,619 --> 00:18:34,100
client meaning if I want to access the

00:18:32,509 --> 00:18:36,320
high performance pool or the memory of

00:18:34,100 --> 00:18:38,210
the pool or the locally available pour

00:18:36,320 --> 00:18:39,830
the Europe pool or the u.s. pool

00:18:38,210 --> 00:18:42,859
whatever we need to get get access to

00:18:39,830 --> 00:18:44,570
this is actually up to how people are

00:18:42,859 --> 00:18:48,080
doing it at the build farm installations

00:18:44,570 --> 00:18:51,379
themselves so our content addressable

00:18:48,080 --> 00:18:54,320
storage is used by both the execute

00:18:51,379 --> 00:18:57,859
framework and the action cache unit and

00:18:54,320 --> 00:19:00,919
it's interfaced to the client for

00:18:57,859 --> 00:19:02,929
retrieving blobs when I say a blob I

00:19:00,919 --> 00:19:04,340
mean a bag of bytes and that bag of

00:19:02,929 --> 00:19:07,359
bytes has a key in the content

00:19:04,340 --> 00:19:10,220
addressable storage system that is

00:19:07,359 --> 00:19:12,169
unique hopefully to the content that

00:19:10,220 --> 00:19:14,179
you're putting in but more specifically

00:19:12,169 --> 00:19:16,190
is deterministic based on the content

00:19:14,179 --> 00:19:19,129
that lives in there so your bag of bytes

00:19:16,190 --> 00:19:22,369
that you're storing for hello world the

00:19:19,129 --> 00:19:23,960
string does not differ from anyone

00:19:22,369 --> 00:19:26,419
else's storage for it it will always map

00:19:23,960 --> 00:19:28,220
to the same key the key for this is the

00:19:26,419 --> 00:19:30,559
cotton is the computed digest of those

00:19:28,220 --> 00:19:32,989
bytes and then the value is the mapping

00:19:30,559 --> 00:19:36,320
I hope my crude little diagram has been

00:19:32,989 --> 00:19:38,600
efficient and illustrative in terms of

00:19:36,320 --> 00:19:40,970
what we have here so you can only have

00:19:38,600 --> 00:19:43,489
keys that map to your specific values

00:19:40,970 --> 00:19:46,190
which means you cannot associate knowns

00:19:43,489 --> 00:19:47,779
to unknowns we can only find things that

00:19:46,190 --> 00:19:50,059
we know about and then be able to

00:19:47,779 --> 00:19:54,980
retrieve a larger a larger

00:19:50,059 --> 00:19:56,629
representation of that getting into what

00:19:54,980 --> 00:19:58,490
the execute system does and what the

00:19:56,629 --> 00:20:00,700
action cache system does we have to get

00:19:58,490 --> 00:20:03,020
down to action definitions

00:20:00,700 --> 00:20:05,270
Alfa's covered a lot of this this is

00:20:03,020 --> 00:20:08,179
essentially required for remote caching

00:20:05,270 --> 00:20:10,010
it represents the definition meaning it

00:20:08,179 --> 00:20:12,080
is a message and it describes the

00:20:10,010 --> 00:20:14,090
individual action or spawn that you're

00:20:12,080 --> 00:20:15,830
going to be performing and it includes a

00:20:14,090 --> 00:20:19,010
Merkel tree of inputs it includes the

00:20:15,830 --> 00:20:20,510
execution commands and the environment

00:20:19,010 --> 00:20:23,030
that you're required to get to the

00:20:20,510 --> 00:20:25,160
outputs that you want to get and it says

00:20:23,030 --> 00:20:27,530
here are the places in which I expect

00:20:25,160 --> 00:20:30,380
you to provide outputs that is to say

00:20:27,530 --> 00:20:31,820
file names not file contents because we

00:20:30,380 --> 00:20:33,980
don't know about file contents at this

00:20:31,820 --> 00:20:38,960
point but it expects to produce you know

00:20:33,980 --> 00:20:41,270
a dot zero for compiling a dot C etc so

00:20:38,960 --> 00:20:43,190
taking those action definitions we get

00:20:41,270 --> 00:20:44,960
to use our action cache this is

00:20:43,190 --> 00:20:50,870
different from the casting really only

00:20:44,960 --> 00:20:54,020
one way in that the key is not computed

00:20:50,870 --> 00:20:55,549
based on the value the key is the digest

00:20:54,020 --> 00:20:57,289
of the action definition from the

00:20:55,549 --> 00:20:59,539
previous page the spawn definition of

00:20:57,289 --> 00:21:01,789
what we actually want to store inside

00:20:59,539 --> 00:21:03,679
the action graph and what we retrieve

00:21:01,789 --> 00:21:05,780
out of that is a message that describes

00:21:03,679 --> 00:21:08,330
what that action did so we're looking

00:21:05,780 --> 00:21:10,760
forward into the future and saying based

00:21:08,330 --> 00:21:12,500
on having needed to do this action that

00:21:10,760 --> 00:21:15,320
was perfectly hermetically described

00:21:12,500 --> 00:21:16,970
with all its inputs enumerated and all

00:21:15,320 --> 00:21:20,059
the environment variables that it read

00:21:16,970 --> 00:21:22,010
on execution here is the output of it

00:21:20,059 --> 00:21:23,510
and here's where you can go get that the

00:21:22,010 --> 00:21:26,809
actual result includes a whole bunch of

00:21:23,510 --> 00:21:28,580
different things specifically a list of

00:21:26,809 --> 00:21:31,130
all of the inputs that were specified

00:21:28,580 --> 00:21:35,630
and the way to get them and the keys

00:21:31,130 --> 00:21:38,090
that you can use to get them so if we

00:21:35,630 --> 00:21:40,640
have action caches and we have action

00:21:38,090 --> 00:21:43,159
definitions what we really want to do to

00:21:40,640 --> 00:21:46,700
get off of that laptop and off of that

00:21:43,159 --> 00:21:49,280
you know one machine or into the larger

00:21:46,700 --> 00:21:51,140
world of execution is an execution

00:21:49,280 --> 00:21:52,429
service and an execution service is

00:21:51,140 --> 00:21:55,159
going to interact with a couple of

00:21:52,429 --> 00:21:57,250
different public api's most notably the

00:21:55,159 --> 00:21:59,299
Google long running operation API and

00:21:57,250 --> 00:22:00,770
currently the Google watch your API

00:21:59,299 --> 00:22:03,130
although the basic guys keep telling me

00:22:00,770 --> 00:22:08,210
that they're going to cut that out

00:22:03,130 --> 00:22:10,130
this is how we get from your action

00:22:08,210 --> 00:22:12,620
definition in the case where we have a

00:22:10,130 --> 00:22:14,090
Miss in the action cache through to the

00:22:12,620 --> 00:22:16,580
action results

00:22:14,090 --> 00:22:18,950
so this request is really simple and in

00:22:16,580 --> 00:22:21,500
the spirit of the former illustrative

00:22:18,950 --> 00:22:25,070
diagrams we have said the entry point is

00:22:21,500 --> 00:22:27,200
the execute action and the result is the

00:22:25,070 --> 00:22:29,060
operation that you can then query to

00:22:27,200 --> 00:22:30,350
retrieve your action results your action

00:22:29,060 --> 00:22:32,510
status whether or not I completed

00:22:30,350 --> 00:22:34,250
successfully and then this thing will

00:22:32,510 --> 00:22:36,860
actually upload into the action cache

00:22:34,250 --> 00:22:41,960
all on its own as long as the writing

00:22:36,860 --> 00:22:45,790
parameter was specified so those are

00:22:41,960 --> 00:22:48,110
three things that are fairly intuitive

00:22:45,790 --> 00:22:50,090
instances get a little bit harder and

00:22:48,110 --> 00:22:51,380
the reason I want to highlight them is

00:22:50,090 --> 00:22:55,070
because we've sort of ignored them in

00:22:51,380 --> 00:22:57,320
most of our talks both within Google and

00:22:55,070 --> 00:22:59,120
without where we know that people want

00:22:57,320 --> 00:23:01,160
to identify a set of resources and we

00:22:59,120 --> 00:23:03,710
know that people want to change their

00:23:01,160 --> 00:23:06,440
behavior depending upon who is asking

00:23:03,710 --> 00:23:08,090
for what but this the instances are

00:23:06,440 --> 00:23:11,470
really the way to do that so our build

00:23:08,090 --> 00:23:14,210
form endpoints all three of them casts

00:23:11,470 --> 00:23:16,310
execution and action cache as well as

00:23:14,210 --> 00:23:18,890
all the the subsidiary api's that we're

00:23:16,310 --> 00:23:20,750
using all know about these instances and

00:23:18,890 --> 00:23:22,820
they're baked into the resource names or

00:23:20,750 --> 00:23:24,620
they're baked into the requests and they

00:23:22,820 --> 00:23:28,100
allow you to do resource partitioning

00:23:24,620 --> 00:23:30,770
which means saying that you by

00:23:28,100 --> 00:23:33,980
requesting the pool high mem or high CPU

00:23:30,770 --> 00:23:36,350
or whatever can go to the right set of

00:23:33,980 --> 00:23:39,770
resources for execution and even better

00:23:36,350 --> 00:23:41,600
than that as service installers I know

00:23:39,770 --> 00:23:43,880
we're not DevOps people by any means but

00:23:41,600 --> 00:23:45,770
sometimes it tends to come up that you

00:23:43,880 --> 00:23:48,230
need to know how machines talk to one

00:23:45,770 --> 00:23:50,710
another you have the ability with

00:23:48,230 --> 00:23:53,450
instances to serve transparently route

00:23:50,710 --> 00:23:55,760
requests to different resources if you

00:23:53,450 --> 00:23:57,410
want your resource to be named local

00:23:55,760 --> 00:24:02,390
than it may be it picks the right place

00:23:57,410 --> 00:24:05,210
if you want your resource to be the some

00:24:02,390 --> 00:24:06,830
sort of a a cascading set of hierarchy

00:24:05,210 --> 00:24:09,440
of resource accesses that's what we're

00:24:06,830 --> 00:24:12,080
aiming for it's funny that we bring up

00:24:09,440 --> 00:24:15,170
the local executions we're actually

00:24:12,080 --> 00:24:17,480
preparing in many ways to live in a

00:24:15,170 --> 00:24:19,730
tiered world where we can go to a local

00:24:17,480 --> 00:24:21,680
thing that then proxies through to

00:24:19,730 --> 00:24:22,940
remote that then proxies through to

00:24:21,680 --> 00:24:24,560
production resources that are only

00:24:22,940 --> 00:24:26,090
accessible to CI machines that sort of

00:24:24,560 --> 00:24:28,220
thing

00:24:26,090 --> 00:24:29,990
the interactions between those are as

00:24:28,220 --> 00:24:32,570
I've said we've got the possibility of

00:24:29,990 --> 00:24:34,990
delegation we've got the possibility of

00:24:32,570 --> 00:24:38,840
intermediate caching which means we can

00:24:34,990 --> 00:24:41,270
sort of fan requests through on demand

00:24:38,840 --> 00:24:44,600
to intermediate levels and make sure

00:24:41,270 --> 00:24:47,900
that those propagate and get stored in

00:24:44,600 --> 00:24:49,700
some higher higher coherent to the

00:24:47,900 --> 00:24:51,740
execution or higher cohere to the client

00:24:49,700 --> 00:24:54,740
cache location and then we've also got

00:24:51,740 --> 00:24:56,840
the ability to limit access levels not

00:24:54,740 --> 00:24:58,910
just based on endpoint requesters but

00:24:56,840 --> 00:25:01,250
also based on which instance you're

00:24:58,910 --> 00:25:02,660
requesting having credentials that go

00:25:01,250 --> 00:25:04,280
into this service and we are

00:25:02,660 --> 00:25:09,440
credentialed even though I turned off

00:25:04,280 --> 00:25:11,900
the moment have that ability to specify

00:25:09,440 --> 00:25:13,400
access to this one of the one of the

00:25:11,900 --> 00:25:17,300
things I read in the original BigTable

00:25:13,400 --> 00:25:19,460
doc was the fact that we the quotas

00:25:17,300 --> 00:25:21,590
weren't built-in initially and I I sort

00:25:19,460 --> 00:25:23,180
of liked that because it felt like every

00:25:21,590 --> 00:25:26,960
other system that I had ever prototyped

00:25:23,180 --> 00:25:30,200
and that we had to get somewhere in

00:25:26,960 --> 00:25:32,300
terms of trying to delineate not just

00:25:30,200 --> 00:25:34,970
access by resource specification but

00:25:32,300 --> 00:25:38,510
also access by the qualifications of the

00:25:34,970 --> 00:25:42,380
client and let us limit that out so our

00:25:38,510 --> 00:25:46,600
reference implementation goal was simply

00:25:42,380 --> 00:25:49,760
to take the the API that was given to me

00:25:46,600 --> 00:25:51,290
given that given to all of us and run it

00:25:49,760 --> 00:25:53,840
through a smoke test we came up with

00:25:51,290 --> 00:25:55,430
some very small implementational detail

00:25:53,840 --> 00:25:57,710
issues that we wanted to bring up to the

00:25:55,430 --> 00:25:59,180
community some small issues in Basel

00:25:57,710 --> 00:26:03,260
those all got corrected thank you guys

00:25:59,180 --> 00:26:05,060
and then provide something really simple

00:26:03,260 --> 00:26:07,670
that can work in scale for execution our

00:26:05,060 --> 00:26:09,410
design is not complicated at all if you

00:26:07,670 --> 00:26:11,120
go and take a look at the service online

00:26:09,410 --> 00:26:13,970
you're going to see one layer for

00:26:11,120 --> 00:26:16,670
service one layer for each one of these

00:26:13,970 --> 00:26:18,140
instances that gets provided and a

00:26:16,670 --> 00:26:20,360
couple of other different sort of

00:26:18,140 --> 00:26:22,370
utility mechanisms for just defining the

00:26:20,360 --> 00:26:24,140
abstraction layers that we want to

00:26:22,370 --> 00:26:26,120
access each one of the primitives that

00:26:24,140 --> 00:26:29,480
we interact with meaning the caste the

00:26:26,120 --> 00:26:32,330
action cache and the the execution

00:26:29,480 --> 00:26:34,250
worker and we define that core instance

00:26:32,330 --> 00:26:35,900
pattern so that if anybody wants to pick

00:26:34,250 --> 00:26:38,040
this up and write their own instance on

00:26:35,900 --> 00:26:40,950
top of Redis or

00:26:38,040 --> 00:26:42,570
Oh cast or memcached or whatever I'm

00:26:40,950 --> 00:26:45,930
showing my age in terms of tools I

00:26:42,570 --> 00:26:48,210
realize but the results that we got out

00:26:45,930 --> 00:26:50,730
of this were pretty cool we came up with

00:26:48,210 --> 00:26:53,550
male ru casts that need an expiration

00:26:50,730 --> 00:26:55,410
callback because I implemented the

00:26:53,550 --> 00:26:58,170
action cache and then the outstanding

00:26:55,410 --> 00:27:01,260
operations in terms of executions in

00:26:58,170 --> 00:27:02,730
terms of the cast storage when the cast

00:27:01,260 --> 00:27:06,030
expired that I wanted to kill it in the

00:27:02,730 --> 00:27:08,340
other mapping we have an operation queue

00:27:06,030 --> 00:27:12,180
service which was the bare bones of what

00:27:08,340 --> 00:27:14,220
I thought I needed to ship work off to a

00:27:12,180 --> 00:27:15,450
requesting workers so a worker comes in

00:27:14,220 --> 00:27:18,930
says give me some work here's my

00:27:15,450 --> 00:27:22,620
platform the the operation queue service

00:27:18,930 --> 00:27:24,120
responds to that with work when he's

00:27:22,620 --> 00:27:26,130
done he comes back and ask for it or

00:27:24,120 --> 00:27:28,170
whatever he's able to retrieve more work

00:27:26,130 --> 00:27:30,780
he does that that means that I had to

00:27:28,170 --> 00:27:32,790
implement a reference worker the only

00:27:30,780 --> 00:27:35,460
way in which this is reference is that

00:27:32,790 --> 00:27:36,720
we have used the operation queue service

00:27:35,460 --> 00:27:38,760
which is not a part of the remote

00:27:36,720 --> 00:27:40,650
execution API but I encourage you to

00:27:38,760 --> 00:27:43,860
tell me that I'm crazy or tell me that

00:27:40,650 --> 00:27:45,810
I'm wrong and using this and instances

00:27:43,860 --> 00:27:47,730
are not bound to this in terms of

00:27:45,810 --> 00:27:49,890
requiring the implementation of the

00:27:47,730 --> 00:27:51,440
worker exactly the way that I did maybe

00:27:49,890 --> 00:27:54,090
they want to implement some other way we

00:27:51,440 --> 00:27:56,730
do a platform only match which is not

00:27:54,090 --> 00:27:59,160
too exciting I'm not great at bin

00:27:56,730 --> 00:28:02,640
packing I hear some of you guys are but

00:27:59,160 --> 00:28:05,700
we can match up in individual platforms

00:28:02,640 --> 00:28:07,470
based on any set of string based

00:28:05,700 --> 00:28:09,630
parameters that you request in if an

00:28:07,470 --> 00:28:11,390
action says it needs something we find a

00:28:09,630 --> 00:28:14,610
worker that matches it otherwise we hang

00:28:11,390 --> 00:28:16,500
and the last thing was that was kind of

00:28:14,610 --> 00:28:17,760
cool was implementing cancellations last

00:28:16,500 --> 00:28:21,690
week because I had a bunch of Road drop

00:28:17,760 --> 00:28:23,640
jobs running on my my worker cluster had

00:28:21,690 --> 00:28:26,570
to kill his off and to do it I had to

00:28:23,640 --> 00:28:26,570

YouTube URL: https://www.youtube.com/watch?v=_bPyEbAyC0s


