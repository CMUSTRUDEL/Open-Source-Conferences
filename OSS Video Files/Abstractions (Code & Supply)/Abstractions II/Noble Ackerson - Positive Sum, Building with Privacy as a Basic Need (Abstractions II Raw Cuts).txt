Title: Noble Ackerson - Positive Sum, Building with Privacy as a Basic Need (Abstractions II Raw Cuts)
Publication date: 2019-11-25
Playlist: Abstractions II
Description: 
	Presented at Abstractions II, a software conference Code & Supply in Pittsburgh, PA August 21-23, 2019. Learn more at http://www.codeandsupply.co or https://abstractions.io. 

The RAW CUTS series is comprised of selections from a few of our stages wherein the raw video was of high enough quality for C&S to release it before post-production. 

Post-production for a community-run conference with as many speakers and as low of a budget as Abstractions is an enormous and time-consuming undertaking. If you're interested in volunteering your time and CPU cycles to help with post-production, we can use your help. Email us at support@codeandsupply.co and we'll get you into the mix. You'll be permitted to credit yourself in the video pre-roll and credits and we'll thank you in this text and on social media.

Interested in sponsoring professional post-production costs in exchange for your company's name and logo in the video forevermore? Contact us at sponsorship@abstractions.io. Opportunities start at $1,000.

-----

Personal data privacy is a hot-button item today. It can often seem overly burdensome for the software developer looking to change the world. Developers and designers may look at regulations and current trends in data privacy as negative impacts to product innovation.

This is the wrong lens by which we should look at this.

In this talk, Noble shares opportunities to innovate around the growth in data, the growth in regulations like the GDPR. He shares insights on human-centered design opportunities that can help both independent developers or an established corporation. He presents practical examples to minimize the data you collect and best practices on asking for data in software only when it provides value for the user.

https://abstractions.io/schedule/#Positive%20Sum,%20Building%20with%20Privacy%20as%20a%20Basic%20Need-Noble%20Ackerson
Captions: 
	00:00:02,210 --> 00:00:09,630
so we have a lot to cover in a very

00:00:06,930 --> 00:00:12,179
short period of time I'm gonna go ahead

00:00:09,630 --> 00:00:16,139
and get started as people file in hope

00:00:12,179 --> 00:00:19,640
that's not too uncalled for

00:00:16,139 --> 00:00:22,939
you guys ready awesome

00:00:19,640 --> 00:00:25,289
well first thanks everyone here for

00:00:22,939 --> 00:00:27,779
investing your afternoon with me

00:00:25,289 --> 00:00:29,640
especially since we sort of changed

00:00:27,779 --> 00:00:33,630
plans a little bit we moved it so it's a

00:00:29,640 --> 00:00:37,170
little confusing and so my thanks to you

00:00:33,630 --> 00:00:40,680
my thanks to the organizers as well for

00:00:37,170 --> 00:00:45,420
being accommodating has everybody had

00:00:40,680 --> 00:00:48,450
fun abstraction so far it is this my

00:00:45,420 --> 00:00:51,270
first time in Pittsburgh and it has been

00:00:48,450 --> 00:00:53,850
just phenomenal this is one of the best

00:00:51,270 --> 00:00:57,180
run conferences that have actually had

00:00:53,850 --> 00:00:59,250
the luxury of being part of and so today

00:00:57,180 --> 00:01:04,680
we're going to talk about data trust and

00:00:59,250 --> 00:01:07,500
data privacy privacy building apps in a

00:01:04,680 --> 00:01:09,360
way that we consider privacy in the same

00:01:07,500 --> 00:01:11,790
way we consider security in the same way

00:01:09,360 --> 00:01:14,520
we consider backing up our data that

00:01:11,790 --> 00:01:17,939
kind of stuff and so let's jump right in

00:01:14,520 --> 00:01:19,619
if everyone's sort of ready again we're

00:01:17,939 --> 00:01:21,869
gonna cover a couple things we're gonna

00:01:19,619 --> 00:01:25,140
talk about the evolving landscape but

00:01:21,869 --> 00:01:28,590
there are a the two core pieces in the

00:01:25,140 --> 00:01:31,439
next 30 minutes that we invest together

00:01:28,590 --> 00:01:33,840
in this room that I want you to take

00:01:31,439 --> 00:01:36,600
away with so on Monday when you are

00:01:33,840 --> 00:01:38,430
joining your colleagues at at work or

00:01:36,600 --> 00:01:40,850
you know if you're in the middle of

00:01:38,430 --> 00:01:44,970
building your app as an entrepreneur or

00:01:40,850 --> 00:01:48,079
you know your startup I want to help you

00:01:44,970 --> 00:01:54,600
understand how we got here

00:01:48,079 --> 00:01:57,750
how Trust in my view has been broken and

00:01:54,600 --> 00:02:01,710
how that affects what we build and how

00:01:57,750 --> 00:02:04,649
we build in and then next make this a

00:02:01,710 --> 00:02:07,920
little bit more practical show you some

00:02:04,649 --> 00:02:09,140
guidelines and some patterns that you

00:02:07,920 --> 00:02:12,640
can take again

00:02:09,140 --> 00:02:17,780
to work to consider as you build

00:02:12,640 --> 00:02:21,260
impactful applications that matter so by

00:02:17,780 --> 00:02:24,980
show of hands how many people feel in

00:02:21,260 --> 00:02:27,590
control of their data online so for

00:02:24,980 --> 00:02:31,900
example like are you clear on what

00:02:27,590 --> 00:02:35,239
happens to your data when you Bank

00:02:31,900 --> 00:02:37,940
doesn't one guy here I did not expect a

00:02:35,239 --> 00:02:41,709
single hand to go up but someone here

00:02:37,940 --> 00:02:45,410
trusts that they know exactly what

00:02:41,709 --> 00:02:47,630
happens to their data um so consumer

00:02:45,410 --> 00:02:51,260
Trust is broken but before we get into

00:02:47,630 --> 00:02:53,540
that I want to talk about a little bit

00:02:51,260 --> 00:02:55,190
about myself I am one of the founding

00:02:53,540 --> 00:02:58,580
members of something called the open AR

00:02:55,190 --> 00:03:01,070
cloud I sit on the privacy working group

00:02:58,580 --> 00:03:04,900
there you can learn a little bit more

00:03:01,070 --> 00:03:08,530
about the park or the open AR cloud at

00:03:04,900 --> 00:03:11,420
right they have my Twitter handle there

00:03:08,530 --> 00:03:15,140
that's me if you want to sort of tweet

00:03:11,420 --> 00:03:17,030
at me right there but I focus mostly as

00:03:15,140 --> 00:03:19,880
a product strategist and product manager

00:03:17,030 --> 00:03:22,190
and immersive technologies but that

00:03:19,880 --> 00:03:27,220
these same principles apply to mobile

00:03:22,190 --> 00:03:29,810
native apps web IOT any way that we

00:03:27,220 --> 00:03:33,590
consume information in a manner that

00:03:29,810 --> 00:03:35,150
benefits the people that we need the

00:03:33,590 --> 00:03:36,620
stock is going to be a little weird it's

00:03:35,150 --> 00:03:40,610
going to be from a perspective of you

00:03:36,620 --> 00:03:44,360
and I people who depend on these

00:03:40,610 --> 00:03:46,100
services that that we need to use every

00:03:44,360 --> 00:03:47,930
day in our daily lives and it's also

00:03:46,100 --> 00:03:50,120
going to be from a perspective of

00:03:47,930 --> 00:03:51,829
developers in this room or designers or

00:03:50,120 --> 00:03:56,299
researchers or decision makers business

00:03:51,829 --> 00:04:00,350
leaders that things to consider as you

00:03:56,299 --> 00:04:03,709
are going you know building great things

00:04:00,350 --> 00:04:06,320
I bridge that gap as a product manager a

00:04:03,709 --> 00:04:08,510
multi-disciplined and this talk is has

00:04:06,320 --> 00:04:09,850
adapted and involved to various

00:04:08,510 --> 00:04:13,519
audiences

00:04:09,850 --> 00:04:19,190
I'll leave time for for questions at the

00:04:13,519 --> 00:04:21,950
end hopefully so let's get started

00:04:19,190 --> 00:04:26,360
so as we said of one guy in this room

00:04:21,950 --> 00:04:29,690
that truly believes they trust that when

00:04:26,360 --> 00:04:34,480
they bank that data is right where they

00:04:29,690 --> 00:04:36,650
left it that is not reflected with

00:04:34,480 --> 00:04:42,910
pretty much it's not reflective of

00:04:36,650 --> 00:04:46,840
anyone that I know and so I see that

00:04:42,910 --> 00:04:51,440
that consumer trust that suffers from

00:04:46,840 --> 00:04:53,320
you know you know where data gets how

00:04:51,440 --> 00:04:56,600
they to get stored how long we keep it

00:04:53,320 --> 00:04:59,180
actually goes into affecting our bottom

00:04:56,600 --> 00:05:01,160
line and you know the quality of our app

00:04:59,180 --> 00:05:04,340
our user experience so we'll talk about

00:05:01,160 --> 00:05:06,470
that in the first part I really bit

00:05:04,340 --> 00:05:09,200
about me a little bit more about me and

00:05:06,470 --> 00:05:10,370
why I think I'm qualified to speak to

00:05:09,200 --> 00:05:12,320
you today about date oppressed

00:05:10,370 --> 00:05:14,930
I was one of those Google glass holes as

00:05:12,320 --> 00:05:19,550
you guys called me I was one of the

00:05:14,930 --> 00:05:25,480
first explorers and in this cropped

00:05:19,550 --> 00:05:28,250
photo that you see here the entire row

00:05:25,480 --> 00:05:31,780
first row of that conference where

00:05:28,250 --> 00:05:34,790
people wearing those face computers and

00:05:31,780 --> 00:05:36,560
I'd still have mine I wear it from time

00:05:34,790 --> 00:05:41,919
to time didn't choose to wear it today I

00:05:36,560 --> 00:05:45,310
didn't want to stand out but that entire

00:05:41,919 --> 00:05:49,460
experience sort of evolved my thinking

00:05:45,310 --> 00:05:51,740
about data it actually changed the way I

00:05:49,460 --> 00:05:54,470
understood I started understanding that

00:05:51,740 --> 00:05:59,000
society sort of renegotiating norms

00:05:54,470 --> 00:06:02,390
around what we considered our private

00:05:59,000 --> 00:06:04,790
information versus the services that we

00:06:02,390 --> 00:06:09,560
depended on what they considered data

00:06:04,790 --> 00:06:12,740
privacy and in my role I quit a startup

00:06:09,560 --> 00:06:15,050
and I started a fitness app collecting

00:06:12,740 --> 00:06:16,790
biometric information or to benefit

00:06:15,050 --> 00:06:20,000
people who wanted to live healthier

00:06:16,790 --> 00:06:22,340
lives biometric information is personal

00:06:20,000 --> 00:06:27,070
health information and so I quickly

00:06:22,340 --> 00:06:29,479
learned to be a good steward of user

00:06:27,070 --> 00:06:31,599
information personally identifiable

00:06:29,479 --> 00:06:35,559
information so that's what this talk

00:06:31,599 --> 00:06:37,479
I'm gonna try to thread that narrative

00:06:35,559 --> 00:06:48,939
that that experienced through my startup

00:06:37,479 --> 00:06:55,959
through this top today oh that's a

00:06:48,939 --> 00:06:59,559
little delay so it's 2013 I've got my

00:06:55,959 --> 00:07:01,659
fancy Google glasses and I'm going to a

00:06:59,559 --> 00:07:04,029
conference to speak about being the

00:07:01,659 --> 00:07:05,649
first black person to wear a Google

00:07:04,029 --> 00:07:07,270
glasses and to do something with it

00:07:05,649 --> 00:07:09,939
that I thought I thought I was the first

00:07:07,270 --> 00:07:13,830
black person that probably wasn't so I

00:07:09,939 --> 00:07:19,240
get into you know I pick up my cell and

00:07:13,830 --> 00:07:22,869
order an uber you know share my location

00:07:19,240 --> 00:07:24,969
hop on check my calendar system French

00:07:22,869 --> 00:07:27,189
to shoot some emails off arrive at the

00:07:24,969 --> 00:07:30,629
airport go through little scanner as we

00:07:27,189 --> 00:07:34,990
all familiar with I enter the plane and

00:07:30,629 --> 00:07:36,969
but I sat down the flight attendant

00:07:34,990 --> 00:07:43,629
comes to me and goes you need to take

00:07:36,969 --> 00:07:45,399
that off I go why is there a problem she

00:07:43,629 --> 00:07:49,689
goes well we have a passenger that's

00:07:45,399 --> 00:07:51,219
concerned about your glasses and we

00:07:49,689 --> 00:07:54,550
think you're you might be recording

00:07:51,219 --> 00:07:57,399
things and so after some back and forth

00:07:54,550 --> 00:07:59,649
I basically settle on well I will take

00:07:57,399 --> 00:08:01,240
it off but it has my prescriptions on it

00:07:59,649 --> 00:08:03,189
if you notice in that previous slide

00:08:01,240 --> 00:08:04,719
those are my prescription glasses it

00:08:03,189 --> 00:08:07,869
just had a fancy faced computer attached

00:08:04,719 --> 00:08:12,779
to it so I'll take it off I'll put it

00:08:07,869 --> 00:08:15,339
like this to make people less uneasy I

00:08:12,779 --> 00:08:19,619
just want to mention that whoever is

00:08:15,339 --> 00:08:19,619
complaining came through an airport

00:08:20,129 --> 00:08:26,169
right the information is out there so I

00:08:24,579 --> 00:08:28,839
think the argument there was about

00:08:26,169 --> 00:08:31,779
sousveillance me potentially recording

00:08:28,839 --> 00:08:33,490
versus surveillance I mean if the other

00:08:31,779 --> 00:08:34,870
camera that was pointing at them and

00:08:33,490 --> 00:08:36,099
collected information as they walked

00:08:34,870 --> 00:08:38,469
through the airport from that journey

00:08:36,099 --> 00:08:41,140
from when they you know checked in their

00:08:38,469 --> 00:08:43,060
bags all the way to entering the plane

00:08:41,140 --> 00:08:46,210
the point in that then with men weird

00:08:43,060 --> 00:08:48,730
was this to defend myself again several

00:08:46,210 --> 00:08:50,680
years later I would have had to be like

00:08:48,730 --> 00:08:53,620
the creepiest of creeps just to stare at

00:08:50,680 --> 00:08:55,090
this person the entire time too and get

00:08:53,620 --> 00:08:57,640
one within my field of view in order to

00:08:55,090 --> 00:08:59,530
record them and the technology would

00:08:57,640 --> 00:09:01,930
have had to be amazing because that

00:08:59,530 --> 00:09:05,050
tinyface computer would have had to have

00:09:01,930 --> 00:09:08,550
some technology advances to record the

00:09:05,050 --> 00:09:11,650
entire time without burning my face off

00:09:08,550 --> 00:09:14,470
the pen is that it was at that point

00:09:11,650 --> 00:09:16,480
that I realized that societal norms are

00:09:14,470 --> 00:09:18,940
changing people were woke people were

00:09:16,480 --> 00:09:28,690
like aware it's like this is my

00:09:18,940 --> 00:09:30,850
information but is it yours as it's

00:09:28,690 --> 00:09:33,340
talking to a friend of my some of that

00:09:30,850 --> 00:09:37,510
just met with this conference and and he

00:09:33,340 --> 00:09:40,120
put it best he said that with technology

00:09:37,510 --> 00:09:42,300
we always seem to get it right the first

00:09:40,120 --> 00:09:42,300
time

00:09:43,260 --> 00:09:52,240
Livan 90s it cost a $3,000 for about 15

00:09:49,300 --> 00:09:56,890
Meg's I was sorry about yeah like five

00:09:52,240 --> 00:09:59,080
Meg's rather of data so the entire stack

00:09:56,890 --> 00:10:03,670
are the the way we collected information

00:09:59,080 --> 00:10:05,440
as software our practitioners was sort

00:10:03,670 --> 00:10:07,390
of built around not storing all that

00:10:05,440 --> 00:10:10,600
information all that once we got it

00:10:07,390 --> 00:10:14,020
right but then data became ubiquitous it

00:10:10,600 --> 00:10:18,160
became very very cheap we also found

00:10:14,020 --> 00:10:21,250
that so tempering the volume of data

00:10:18,160 --> 00:10:25,180
that we got against the variety of data

00:10:21,250 --> 00:10:28,360
that we got against the volume of data

00:10:25,180 --> 00:10:32,260
that we got created a competitive

00:10:28,360 --> 00:10:36,130
advantage and so an industry was born it

00:10:32,260 --> 00:10:40,870
was called big data and if you were able

00:10:36,130 --> 00:10:42,550
to find the right set of tools right you

00:10:40,870 --> 00:10:44,560
could like machine learning you could

00:10:42,550 --> 00:10:48,880
basically have an edge on the next

00:10:44,560 --> 00:10:52,490
company but that in itself sort of

00:10:48,880 --> 00:10:55,100
brought that awareness to consumers

00:10:52,490 --> 00:10:57,500
through incidents maybe that I'm gonna

00:10:55,100 --> 00:11:02,300
talk about here in a second that we

00:10:57,500 --> 00:11:05,420
needed to rethink how we were treating

00:11:02,300 --> 00:11:07,910
other people's information how we either

00:11:05,420 --> 00:11:09,610
shared our what happened when we shared

00:11:07,910 --> 00:11:15,740
our information and where we actually

00:11:09,610 --> 00:11:19,180
shedding information so are these a

00:11:15,740 --> 00:11:19,180
couple terms we're going to define them

00:11:19,240 --> 00:11:25,540
little move that data trust all right I

00:11:25,900 --> 00:11:32,120
trust from a company standpoint I'm the

00:11:29,270 --> 00:11:38,480
startup building a fitness thing I hope

00:11:32,120 --> 00:11:42,320
that the value that I deliver sort of

00:11:38,480 --> 00:11:45,500
provides another value to bring more

00:11:42,320 --> 00:11:47,240
customers in but for the end user trust

00:11:45,500 --> 00:11:50,120
I want to define from the end-user

00:11:47,240 --> 00:11:53,420
standpoint my customer standpoint it is

00:11:50,120 --> 00:11:59,030
how transparent is this startup or

00:11:53,420 --> 00:12:02,720
enterprise or app how they transparent

00:11:59,030 --> 00:12:06,470
with my information do I know what's

00:12:02,720 --> 00:12:09,590
happening with that data how can I

00:12:06,470 --> 00:12:13,700
temper weather how much I know with a

00:12:09,590 --> 00:12:16,040
value that is being delivered and how do

00:12:13,700 --> 00:12:18,200
I know that if there is a problem ask

00:12:16,040 --> 00:12:21,350
them there's a high likelihood there

00:12:18,200 --> 00:12:26,030
that there's going to be that this

00:12:21,350 --> 00:12:27,710
company is gonna do right by me so we

00:12:26,030 --> 00:12:30,920
fall into various fiefdom

00:12:27,710 --> 00:12:34,010
we go that we use the entire Apple

00:12:30,920 --> 00:12:37,490
ecosystem because we trust Apple they

00:12:34,010 --> 00:12:43,130
you know Tim Apple I believe his name is

00:12:37,490 --> 00:12:46,340
comes onstage and says we are privacy

00:12:43,130 --> 00:12:48,560
first we do not sell ads so then I go

00:12:46,340 --> 00:12:50,780
out and buy an iPhone and I use all the

00:12:48,560 --> 00:12:52,370
services and I get a credit card all

00:12:50,780 --> 00:12:54,380
that data is shared with goldman sachs

00:12:52,370 --> 00:12:56,720
out it's fine like trust Apple

00:12:54,380 --> 00:12:59,450
well that value that apple provides me I

00:12:56,720 --> 00:13:01,270
bought it and I accept the consequence

00:12:59,450 --> 00:13:04,160
that

00:13:01,270 --> 00:13:09,460
you know that may happen if there is a

00:13:04,160 --> 00:13:09,460
leak or a vulnerability or a breach

00:13:11,620 --> 00:13:18,920
another it's data privacy here in a

00:13:14,030 --> 00:13:21,050
second I mentioned before that we're

00:13:18,920 --> 00:13:23,210
renegotiating societal norms and I

00:13:21,050 --> 00:13:25,840
talked about big data I'm gonna double

00:13:23,210 --> 00:13:25,840
tap into that

00:13:32,420 --> 00:13:39,340
there's a little bit of delay there's

00:13:35,450 --> 00:13:43,190
been a growth in data we all know this

00:13:39,340 --> 00:13:45,140
there we shed a lot of information we

00:13:43,190 --> 00:13:46,610
use various services I gave you that

00:13:45,140 --> 00:13:49,190
scenario where I woke up in the morning

00:13:46,610 --> 00:13:52,700
and to the point where I hit the airport

00:13:49,190 --> 00:13:54,800
I'd used you know different companies

00:13:52,700 --> 00:13:58,300
had gotten my personal information

00:13:54,800 --> 00:14:03,320
through my location my name my email

00:13:58,300 --> 00:14:05,480
photos you know my health information if

00:14:03,320 --> 00:14:08,780
I wanted to get a meal through you know

00:14:05,480 --> 00:14:11,990
ooh BRR eats or whatever so there's a

00:14:08,780 --> 00:14:14,840
rise in the volume of data that I shed

00:14:11,990 --> 00:14:19,450
there's a rise in the variety of data

00:14:14,840 --> 00:14:22,280
that I shed then there's a rise in the

00:14:19,450 --> 00:14:24,740
volume variety and velocity in the the

00:14:22,280 --> 00:14:28,220
amount of data and the the speed at

00:14:24,740 --> 00:14:32,210
which it gets to be aggregated by these

00:14:28,220 --> 00:14:36,290
various companies we know this with that

00:14:32,210 --> 00:14:37,700
rise in data outcomes arise cause an

00:14:36,290 --> 00:14:41,330
effect right a rise in potential

00:14:37,700 --> 00:14:46,990
breaches and vulnerabilities and as a

00:14:41,330 --> 00:14:50,180
citizen if or as a human if I put a

00:14:46,990 --> 00:14:51,740
person in elected office there's

00:14:50,180 --> 00:14:53,840
naturally going to be a rise in

00:14:51,740 --> 00:14:59,060
regulations because we put them there to

00:14:53,840 --> 00:15:01,310
protect our information right so the

00:14:59,060 --> 00:15:04,610
building regulations examples being of

00:15:01,310 --> 00:15:06,470
the CCPA or the GDP are pretty sure you

00:15:04,610 --> 00:15:09,470
all got those privacy we've changed our

00:15:06,470 --> 00:15:11,690
privacy policy emails and I'm always

00:15:09,470 --> 00:15:14,750
wondering what happened and then what

00:15:11,690 --> 00:15:16,220
you know what happened with that so if

00:15:14,750 --> 00:15:20,780
we put people in power in order to

00:15:16,220 --> 00:15:23,320
protect us and so in this room assuming

00:15:20,780 --> 00:15:25,610
I'm talking to business leaders

00:15:23,320 --> 00:15:29,660
developers researchers designers

00:15:25,610 --> 00:15:33,440
everyone in between we at some point

00:15:29,660 --> 00:15:35,840
have had to contend like contend with

00:15:33,440 --> 00:15:38,270
how we secure this information how long

00:15:35,840 --> 00:15:41,450
we retain this information classifying

00:15:38,270 --> 00:15:44,610
the types of information that we that we

00:15:41,450 --> 00:15:47,579
have and we look at that as a chore

00:15:44,610 --> 00:15:50,489
right sometimes or it's just another

00:15:47,579 --> 00:15:52,769
thing that we need to do well I think

00:15:50,489 --> 00:15:55,459
that's the wrong lens of which we should

00:15:52,769 --> 00:16:00,480
look at this I think they're positive

00:15:55,459 --> 00:16:03,889
the the notion that we the citizen or

00:16:00,480 --> 00:16:08,309
the human the data subject gives away

00:16:03,889 --> 00:16:11,459
information to a service for free or

00:16:08,309 --> 00:16:14,489
paid in order to give us value that's a

00:16:11,459 --> 00:16:17,249
zero sum that's too one-sided our

00:16:14,489 --> 00:16:22,110
fearless should be a positive sum if I

00:16:17,249 --> 00:16:24,389
the human gives a company data I should

00:16:22,110 --> 00:16:28,350
have control over that data

00:16:24,389 --> 00:16:30,059
I should have context and information as

00:16:28,350 --> 00:16:33,989
to what that data is going to be used

00:16:30,059 --> 00:16:35,639
for I should have the choice as to

00:16:33,989 --> 00:16:39,230
whether that data should be collected at

00:16:35,639 --> 00:16:41,639
all this is some of the principles that

00:16:39,230 --> 00:16:45,269
poorly written and well written

00:16:41,639 --> 00:16:46,949
regulations are trying to sort of bring

00:16:45,269 --> 00:16:49,319
together the cat's out of the bag

00:16:46,949 --> 00:16:51,499
toothpaste out of the tube so what do we

00:16:49,319 --> 00:16:51,499
do

00:16:57,160 --> 00:17:07,000
jeez I'll start using this now so we

00:17:04,000 --> 00:17:09,870
talked about dated trust now let's talk

00:17:07,000 --> 00:17:14,170
a bit about data privacy

00:17:09,870 --> 00:17:18,970
well the privacy is exactly what I just

00:17:14,170 --> 00:17:21,550
mentioned it is bringing together the

00:17:18,970 --> 00:17:26,220
user or what the legal people call the

00:17:21,550 --> 00:17:30,390
data subject me the human the control

00:17:26,220 --> 00:17:35,920
the context the choice there's one more

00:17:30,390 --> 00:17:40,090
respect like do you build your

00:17:35,920 --> 00:17:44,020
applications in a manner that assumes no

00:17:40,090 --> 00:17:49,600
trust zero trust you or do you learn on

00:17:44,020 --> 00:17:51,790
Amazon's AWS services to then just trust

00:17:49,600 --> 00:17:53,920
that they're gonna secure your

00:17:51,790 --> 00:17:58,900
applications I'm gonna talk about that

00:17:53,920 --> 00:18:02,740
here in a little bit so one of the

00:17:58,900 --> 00:18:06,190
practical things that you're going to

00:18:02,740 --> 00:18:10,180
take away hopefully today is designing

00:18:06,190 --> 00:18:12,900
privacy into you working with your your

00:18:10,180 --> 00:18:16,240
UX team your designers your researchers

00:18:12,900 --> 00:18:18,550
or even your architects to this is to

00:18:16,240 --> 00:18:25,060
bake in data privacy into your design

00:18:18,550 --> 00:18:26,530
process and then you're designing it you

00:18:25,060 --> 00:18:27,970
traditionally there's so many ways to

00:18:26,530 --> 00:18:30,640
sort of hack at it you've got the

00:18:27,970 --> 00:18:33,460
discovery phase you've got the learning

00:18:30,640 --> 00:18:36,310
phase they use and and of course you

00:18:33,460 --> 00:18:37,780
know their goal I'm gonna sort of take

00:18:36,310 --> 00:18:42,610
that framework and it's twisted a little

00:18:37,780 --> 00:18:44,260
bit while the babies did a privacy the

00:18:42,610 --> 00:18:46,810
definition that I gave here to sort of

00:18:44,260 --> 00:18:50,980
walk us through that process so your

00:18:46,810 --> 00:18:52,780
first experience firstly be context what

00:18:50,980 --> 00:18:55,930
are some transparency considerations are

00:18:52,780 --> 00:18:58,980
that you're baking into your privacy

00:18:55,930 --> 00:19:03,160
process how well are you communicating

00:18:58,980 --> 00:19:06,150
that the users data as to how that users

00:19:03,160 --> 00:19:06,150
data is going to be used

00:19:10,830 --> 00:19:16,500
we get those privacy banners and all

00:19:13,600 --> 00:19:24,160
that stuff and they only have one choice

00:19:16,500 --> 00:19:30,100
except are we giving an option to opt

00:19:24,160 --> 00:19:32,500
out of some of these things and then how

00:19:30,100 --> 00:19:35,530
much control do you give the user in

00:19:32,500 --> 00:19:39,160
order to afford that confidence and that

00:19:35,530 --> 00:19:43,120
trust that they actually control some of

00:19:39,160 --> 00:19:47,530
that information and do we actually

00:19:43,120 --> 00:19:48,760
afford them with that consequence

00:19:47,530 --> 00:19:51,460
acceptance thing that I talked about

00:19:48,760 --> 00:19:55,660
like you know what are we doing to sort

00:19:51,460 --> 00:19:57,790
of validate that we respect their data

00:19:55,660 --> 00:20:02,560
or on their side how do they feel

00:19:57,790 --> 00:20:05,110
respected by using your solution so

00:20:02,560 --> 00:20:10,060
let's dive into that first we're going

00:20:05,110 --> 00:20:13,300
to talk about context a clear reason why

00:20:10,060 --> 00:20:17,410
you're using my information I'm going to

00:20:13,300 --> 00:20:22,420
use an example very balanced everyone

00:20:17,410 --> 00:20:25,960
picks on face phones on Facebook then we

00:20:22,420 --> 00:20:28,510
shouldn't pick on the tool we we should

00:20:25,960 --> 00:20:31,210
actually consider what's happening

00:20:28,510 --> 00:20:34,210
behind the scenes there so you probably

00:20:31,210 --> 00:20:36,610
know recently Facebook announced this

00:20:34,210 --> 00:20:38,290
facial recognition feature they did some

00:20:36,610 --> 00:20:45,370
things right they did some things very

00:20:38,290 --> 00:20:48,100
wrong very loud so the concept of this

00:20:45,370 --> 00:20:50,380
feature is they have a Photos app and if

00:20:48,100 --> 00:20:52,620
I were to show up at this conference of

00:20:50,380 --> 00:20:54,910
abstractions and yours to take a picture

00:20:52,620 --> 00:20:56,860
if I were to take my phone and take this

00:20:54,910 --> 00:20:59,860
picture right now like a selfie maybe I

00:20:56,860 --> 00:21:01,540
should do that and someone happened to

00:20:59,860 --> 00:21:04,150
be in this picture I shared this to my

00:21:01,540 --> 00:21:07,150
circle of friends on Facebook well I got

00:21:04,150 --> 00:21:09,370
you know the good side of this gentleman

00:21:07,150 --> 00:21:09,790
right here well he's not in my circle of

00:21:09,370 --> 00:21:12,640
friends

00:21:09,790 --> 00:21:15,780
he doesn't know with this feature on the

00:21:12,640 --> 00:21:19,900
Photos app this job what's your name

00:21:15,780 --> 00:21:21,490
Gary would get a notification right it's

00:21:19,900 --> 00:21:23,170
like hey I'm sorry

00:21:21,490 --> 00:21:26,800
you don't use Facebook neither do I but

00:21:23,170 --> 00:21:28,930
it's okay we make police here I don't

00:21:26,800 --> 00:21:30,280
use Facebook it'd be kind of weird if I

00:21:28,930 --> 00:21:34,540
use Facebook all right

00:21:30,280 --> 00:21:38,560
so given this time um make the leave

00:21:34,540 --> 00:21:40,420
land so Gary gets a notification it's

00:21:38,560 --> 00:21:41,740
like hey you're an abstractions caught

00:21:40,420 --> 00:21:43,540
because you checked in and showed your

00:21:41,740 --> 00:21:45,040
location in it we know you had your

00:21:43,540 --> 00:21:47,950
instructional console a took a picture

00:21:45,040 --> 00:21:52,210
of you check it out do you want to be

00:21:47,950 --> 00:21:55,090
tagged in it we're actually gonna ask

00:21:52,210 --> 00:21:58,450
the question here I took the picture I

00:21:55,090 --> 00:22:01,060
don't know Gary does Gary own that image

00:21:58,450 --> 00:22:03,010
cuz he's in it show of hands

00:22:01,060 --> 00:22:07,980
how do people feel that he owns the

00:22:03,010 --> 00:22:11,500
image he owns his likeness interesting

00:22:07,980 --> 00:22:16,420
but does he do we read the Terms of

00:22:11,500 --> 00:22:20,080
Service I don't wanna get into that so

00:22:16,420 --> 00:22:20,680
so the concept on its face it's a great

00:22:20,080 --> 00:22:26,050
idea

00:22:20,680 --> 00:22:30,130
I think right but yeah we talked about

00:22:26,050 --> 00:22:34,120
context like I know the benefit I see

00:22:30,130 --> 00:22:35,920
the value but do I have the choice well

00:22:34,120 --> 00:22:40,740
if you can figure out the management

00:22:35,920 --> 00:22:50,140
data settings and read through 160 words

00:22:40,740 --> 00:22:51,550
here I counted no I didn't control right

00:22:50,140 --> 00:22:54,100
we'll get into that a little bit but

00:22:51,550 --> 00:22:58,810
that context leads if I'm able to

00:22:54,100 --> 00:23:01,930
understand what that data is then I can

00:22:58,810 --> 00:23:05,110
certainly claim that picture as mine I

00:23:01,930 --> 00:23:07,210
can download it offline and keep it and

00:23:05,110 --> 00:23:09,670
put it in my little album a my little

00:23:07,210 --> 00:23:15,360
server I'll print it out and put it up

00:23:09,670 --> 00:23:18,040
in the room just a show Google I think

00:23:15,360 --> 00:23:20,470
that's some things right and also does

00:23:18,040 --> 00:23:22,029
some things wrong Google started years

00:23:20,470 --> 00:23:27,369
ago had a bad

00:23:22,029 --> 00:23:29,950
of road bandits that were looking very

00:23:27,369 --> 00:23:31,960
human centered with with how they

00:23:29,950 --> 00:23:33,639
approached the various services some

00:23:31,960 --> 00:23:35,469
people that had executive sponsors

00:23:33,639 --> 00:23:37,059
decided to form something called the day

00:23:35,469 --> 00:23:39,099
to deliver the DLF the day of the

00:23:37,059 --> 00:23:41,619
liberation in front say that three times

00:23:39,099 --> 00:23:43,960
fast well the deal's off had an

00:23:41,619 --> 00:23:46,179
initiative let's just give back that

00:23:43,960 --> 00:23:49,119
information that we collect across all

00:23:46,179 --> 00:23:51,580
of our services today that feature going

00:23:49,119 --> 00:23:54,789
to do coincidentally becomes a

00:23:51,580 --> 00:23:58,119
requirement you have to provide context

00:23:54,789 --> 00:24:00,549
and provide the choice the control to

00:23:58,119 --> 00:24:05,080
the users in order to do business in the

00:24:00,549 --> 00:24:07,929
EU for example or with a ue resident by

00:24:05,080 --> 00:24:09,729
the way the gdpr did not go into went

00:24:07,929 --> 00:24:11,499
into effect last year but the gdpr

00:24:09,729 --> 00:24:15,159
didn't start last year it actually

00:24:11,499 --> 00:24:20,080
started you know two three years ago in

00:24:15,159 --> 00:24:22,690
2016 and that's been a lot of they had

00:24:20,080 --> 00:24:27,479
two years to prepare and no one did not

00:24:22,690 --> 00:24:27,479
even the EU that which is kind of weird

00:24:27,629 --> 00:24:31,929
so I talked a bit about some of the

00:24:30,820 --> 00:24:36,789
opportunities and some of the

00:24:31,929 --> 00:24:40,019
innovations that that that you had just

00:24:36,789 --> 00:24:43,330
because you're giving away information

00:24:40,019 --> 00:24:45,339
they'll feel that not giving contact by

00:24:43,330 --> 00:24:46,629
giving context you're taking away the

00:24:45,339 --> 00:24:49,029
people are sort of seeing behind the

00:24:46,629 --> 00:24:51,609
curtain actually provides you with new

00:24:49,029 --> 00:24:54,039
opportunities people can actually take

00:24:51,609 --> 00:24:55,960
that information that photo that you

00:24:54,039 --> 00:24:58,719
claimed as yours could actually go to

00:24:55,960 --> 00:25:00,700
benefit Google in another way Facebook

00:24:58,719 --> 00:25:03,580
could actually sort of see some benefits

00:25:00,700 --> 00:25:05,679
of doing it right by sharing that

00:25:03,580 --> 00:25:07,599
information being transferred to what

00:25:05,679 --> 00:25:10,149
other avenues that

00:25:07,599 --> 00:25:13,149
personally-identifiable biometric

00:25:10,149 --> 00:25:18,009
information but with my face what other

00:25:13,149 --> 00:25:23,049
value that brings to me and I'm not

00:25:18,009 --> 00:25:24,190
value acceptance is something you're

00:25:23,049 --> 00:25:26,739
there to companies that I'm picking on

00:25:24,190 --> 00:25:28,899
today that and then by no means am i

00:25:26,739 --> 00:25:30,759
endorsing Google on the bright side but

00:25:28,899 --> 00:25:33,519
this is very controversial with their

00:25:30,759 --> 00:25:35,590
Timeline feature they provided a lot of

00:25:33,519 --> 00:25:38,679
context they they gave you

00:25:35,590 --> 00:25:40,840
everything they said we're gonna track

00:25:38,679 --> 00:25:42,250
you everywhere you go with that

00:25:40,840 --> 00:25:46,779
supercomputer in your pocket

00:25:42,250 --> 00:25:49,390
we're gonna tell you later where you've

00:25:46,779 --> 00:25:52,990
been this is several years ago I told in

00:25:49,390 --> 00:25:55,450
2017 I was giving a talk in Maui

00:25:52,990 --> 00:25:57,909
I've never been to Maui but I'd like to

00:25:55,450 --> 00:25:59,980
relive my steps well I can go to Todd

00:25:57,909 --> 00:26:02,049
the time line right now and I see some

00:25:59,980 --> 00:26:04,090
value in knowing so that if I were to

00:26:02,049 --> 00:26:07,179
give advice to Gary if he is going to

00:26:04,090 --> 00:26:09,100
the grand Malaya as to you know what

00:26:07,179 --> 00:26:12,520
past it takes and whether he should just

00:26:09,100 --> 00:26:20,640
walk or not could come up there's some

00:26:12,520 --> 00:26:23,529
value there so much was my choice I mean

00:26:20,640 --> 00:26:31,950
as a developer am i or designer am i

00:26:23,529 --> 00:26:31,950
giving agency the choice to my users

00:26:32,309 --> 00:26:37,770
about you know with the data that I'm

00:26:34,510 --> 00:26:40,360
collecting and as a consumer

00:26:37,770 --> 00:26:43,299
do I have the choice do I have the

00:26:40,360 --> 00:26:48,549
option to opt out for example of being

00:26:43,299 --> 00:26:50,110
tracked I was looking at you know

00:26:48,549 --> 00:26:52,870
there's something called a right to

00:26:50,110 --> 00:26:55,890
rectification one of the gdpr our

00:26:52,870 --> 00:26:58,179
tenants and I'll just do some research

00:26:55,890 --> 00:27:01,779
around the soft it's how to figure out

00:26:58,179 --> 00:27:04,929
can I feasibly go into this is not my

00:27:01,779 --> 00:27:10,120
whatsapp I don't use that either can I

00:27:04,929 --> 00:27:14,649
go into what's that today and find out

00:27:10,120 --> 00:27:16,210
and choose to opt out of something first

00:27:14,649 --> 00:27:18,130
find out what information they have on

00:27:16,210 --> 00:27:19,840
me in order to then choose to opt out of

00:27:18,130 --> 00:27:23,440
one thing or another the other option I

00:27:19,840 --> 00:27:25,090
have is to delete my account and then I

00:27:23,440 --> 00:27:27,120
don't even know if I do delete my

00:27:25,090 --> 00:27:32,140
account if it's actually really gone

00:27:27,120 --> 00:27:34,720
right so when we talk about choice

00:27:32,140 --> 00:27:37,090
you know we afford the first you need to

00:27:34,720 --> 00:27:39,760
afford the right to access your content

00:27:37,090 --> 00:27:41,910
and then give them the choice to do

00:27:39,760 --> 00:27:45,330
something with it

00:27:41,910 --> 00:27:47,100
one thing that I have noticed if anyone

00:27:45,330 --> 00:27:49,440
went to scotch I did not see Scott

00:27:47,100 --> 00:27:52,350
Jensen's talk yesterday but he talked

00:27:49,440 --> 00:27:55,260
about you know game developers and and

00:27:52,350 --> 00:27:57,510
how they influenced user experience and

00:27:55,260 --> 00:27:59,070
how they lead user experience that's all

00:27:57,510 --> 00:28:02,370
I know about his talk because he told me

00:27:59,070 --> 00:28:05,310
about it a one of the patterns that game

00:28:02,370 --> 00:28:07,950
developers use very effectively that we

00:28:05,310 --> 00:28:11,060
can take into our apps is something

00:28:07,950 --> 00:28:12,720
called progressive disclosure right

00:28:11,060 --> 00:28:15,630
progressively the squares of talk

00:28:12,720 --> 00:28:18,600
touches a couple different patterns like

00:28:15,630 --> 00:28:20,220
data minimization and that's just jargon

00:28:18,600 --> 00:28:21,810
for how much information are you

00:28:20,220 --> 00:28:25,110
collecting upfront and do you need to

00:28:21,810 --> 00:28:26,790
collect all that information well or do

00:28:25,110 --> 00:28:31,130
you progressively get that information

00:28:26,790 --> 00:28:35,300
so this is an example I'm going to this

00:28:31,130 --> 00:28:41,130
mock-up of a you know restaurant app

00:28:35,300 --> 00:28:43,080
pizza app and as a business I have the

00:28:41,130 --> 00:28:46,970
justifiable reason to improve my

00:28:43,080 --> 00:28:49,470
services right so I want to know whether

00:28:46,970 --> 00:28:53,030
that pizza was actually good or not one

00:28:49,470 --> 00:28:55,590
way to do that is digitally you can

00:28:53,030 --> 00:28:57,380
provide them a survey form like a type

00:28:55,590 --> 00:28:59,850
form or a Google farmer survey monkey

00:28:57,380 --> 00:29:03,210
with you know a whole bunch of options

00:28:59,850 --> 00:29:06,060
well at the point of a notification or

00:29:03,210 --> 00:29:08,850
reengagement opportunity you ask them

00:29:06,060 --> 00:29:09,240
this little smiley face did you enjoy

00:29:08,850 --> 00:29:11,520
your meal

00:29:09,240 --> 00:29:12,270
they can you can just continue to just

00:29:11,520 --> 00:29:14,640
leave it at that

00:29:12,270 --> 00:29:15,870
well if you'll and if you didn't enjoy

00:29:14,640 --> 00:29:17,340
your meal and you wanted to complain

00:29:15,870 --> 00:29:19,920
well the business there's no way to

00:29:17,340 --> 00:29:22,890
reach out to you to give you a coupon

00:29:19,920 --> 00:29:25,560
for next time right or thank you if you

00:29:22,890 --> 00:29:28,700
did enjoy the meal come back well then

00:29:25,560 --> 00:29:31,590
you have a choice and unfurls

00:29:28,700 --> 00:29:33,600
additional information that should be

00:29:31,590 --> 00:29:35,070
optional right gives you the option of

00:29:33,600 --> 00:29:37,710
just providing two pieces of information

00:29:35,070 --> 00:29:40,110
because all you really need as a

00:29:37,710 --> 00:29:42,840
business is to address someone by their

00:29:40,110 --> 00:29:44,720
name and you need a medium or vehicle to

00:29:42,840 --> 00:29:47,760
contact that person so name an email

00:29:44,720 --> 00:29:50,040
nothing else I'll give this talk

00:29:47,760 --> 00:29:52,440
University of Louisiana Lafayette and

00:29:50,040 --> 00:29:54,000
I'd right before my talk I just needed

00:29:52,440 --> 00:29:58,380
to get on the Wi-Fi they were asking for

00:29:54,000 --> 00:30:00,300
my home address not sure why you need

00:29:58,380 --> 00:30:06,140
that information I just want to give my

00:30:00,300 --> 00:30:06,140
talk somehow control

00:30:11,260 --> 00:30:19,790
so that pictures supposed to be Macbeth

00:30:15,350 --> 00:30:21,200
right because if you read if you have a

00:30:19,790 --> 00:30:23,840
glass of wine and you want to read the

00:30:21,200 --> 00:30:31,310
Apple iTunes terms and conditions that's

00:30:23,840 --> 00:30:33,800
a over about 20,000 words and no one

00:30:31,310 --> 00:30:35,120
does that we actually there's some and

00:30:33,800 --> 00:30:36,890
that's actually one of the challenges

00:30:35,120 --> 00:30:39,410
with designing for trust and designing

00:30:36,890 --> 00:30:43,040
for for you know considering data

00:30:39,410 --> 00:30:46,130
privacy is because at this point you

00:30:43,040 --> 00:30:48,800
have the cognitive load of a consumer

00:30:46,130 --> 00:30:53,120
just wanting to get to your thing right

00:30:48,800 --> 00:30:57,050
so how do you design with being very

00:30:53,120 --> 00:31:00,080
clear about what your intention is with

00:30:57,050 --> 00:31:05,300
that data and how do you temper that

00:31:00,080 --> 00:31:08,600
against getting them to their goal they

00:31:05,300 --> 00:31:09,410
say Apple Adam and Eve did not read the

00:31:08,600 --> 00:31:13,190
service

00:31:09,410 --> 00:31:15,020
I love the slide but no one reads it no

00:31:13,190 --> 00:31:17,780
one reads terms and conditions except

00:31:15,020 --> 00:31:21,580
for that gentleman and that because

00:31:17,780 --> 00:31:24,080
that's actually why you believe yeah so

00:31:21,580 --> 00:31:25,730
I'm gonna go back to my startup for a

00:31:24,080 --> 00:31:28,190
second so a little bit more about it

00:31:25,730 --> 00:31:30,740
essentially what we did was you had a we

00:31:28,190 --> 00:31:32,570
believed we you know everyone was gonna

00:31:30,740 --> 00:31:34,700
be wearing a face computer or wearing a

00:31:32,570 --> 00:31:37,700
Fitbit or an Apple watch in the near

00:31:34,700 --> 00:31:40,370
future that you'd go to your optometrist

00:31:37,700 --> 00:31:42,190
and you'd have a choice of getting I had

00:31:40,370 --> 00:31:44,240
a lot of glasses like I'm laying or

00:31:42,190 --> 00:31:46,960
glasses with the add on other face

00:31:44,240 --> 00:31:50,030
computer so we decided to add the

00:31:46,960 --> 00:31:52,580
accelerate the IMU the accelerometer in

00:31:50,030 --> 00:31:54,140
order to track motion outside of steps

00:31:52,580 --> 00:31:56,840
like jumping jacks and all that stuff

00:31:54,140 --> 00:31:59,300
and what's more you would be able to

00:31:56,840 --> 00:32:01,670
pass share that information with a

00:31:59,300 --> 00:32:03,950
fitness trainer or nutritionist in order

00:32:01,670 --> 00:32:07,160
to get you know better because they

00:32:03,950 --> 00:32:10,040
could tell that your your pace was on

00:32:07,160 --> 00:32:13,490
point or not your intensity was lacking

00:32:10,040 --> 00:32:15,530
and or needed to to increase because you

00:32:13,490 --> 00:32:18,080
could do better because we could track

00:32:15,530 --> 00:32:22,930
your heartbeat and so we would share all

00:32:18,080 --> 00:32:24,220
this information so how do you think we

00:32:22,930 --> 00:32:25,900
to solve the problem by the way this is

00:32:24,220 --> 00:32:29,470
a mock-up we never really launched this

00:32:25,900 --> 00:32:31,780
until later until we were just about to

00:32:29,470 --> 00:32:34,540
sell it we learned that we don't really

00:32:31,780 --> 00:32:37,810
need to collect as much information from

00:32:34,540 --> 00:32:41,770
our users as we need it so on the screen

00:32:37,810 --> 00:32:47,310
what you see here is just a bare minimum

00:32:41,770 --> 00:32:52,780
we are providing the with providing

00:32:47,310 --> 00:32:55,120
context right we tell our end user why

00:32:52,780 --> 00:32:57,550
we need their name and email right

00:32:55,120 --> 00:32:59,980
because if you want to sort of save

00:32:57,550 --> 00:33:01,780
something you want to be able to sort of

00:32:59,980 --> 00:33:05,050
you know store it somewhere and your

00:33:01,780 --> 00:33:07,120
email is a unique identifier for us we

00:33:05,050 --> 00:33:08,680
want to be able to email you with you

00:33:07,120 --> 00:33:10,480
know a little personal so we need your

00:33:08,680 --> 00:33:15,370
name and we want to secure it through a

00:33:10,480 --> 00:33:18,550
password we provide you it's not working

00:33:15,370 --> 00:33:20,800
on C well we provide you with the choice

00:33:18,550 --> 00:33:23,410
or in the clicks or in the control saw

00:33:20,800 --> 00:33:24,970
here with our privacy settings we do not

00:33:23,410 --> 00:33:29,080
have that little thing at the bottom

00:33:24,970 --> 00:33:31,630
that pops up but we do have is this is

00:33:29,080 --> 00:33:36,400
our Terms of Service right broken up

00:33:31,630 --> 00:33:38,800
easy to read you can click on it and get

00:33:36,400 --> 00:33:41,650
the legalese but it's written to be

00:33:38,800 --> 00:33:44,680
plain English and you choose to accept

00:33:41,650 --> 00:33:46,390
it unfortunately if you do not accept

00:33:44,680 --> 00:33:49,630
the Terms and Conditions you cannot use

00:33:46,390 --> 00:33:53,170
the app why because I have a justifiable

00:33:49,630 --> 00:33:56,860
reason to protect my company in case of

00:33:53,170 --> 00:34:00,580
an issue what I can to give you the

00:33:56,860 --> 00:34:04,720
choice is my cookie policy or my

00:34:00,580 --> 00:34:07,590
marketing initiatives right you can

00:34:04,720 --> 00:34:07,590
choose to decline that

00:34:09,940 --> 00:34:21,190
that leads us to respect the assumption

00:34:14,710 --> 00:34:22,599
that we want to afford that consequence

00:34:21,190 --> 00:34:25,569
acceptance thing that I talked about in

00:34:22,599 --> 00:34:28,690
order to increase trust that data is

00:34:25,569 --> 00:34:31,780
secure at the point of storage all the

00:34:28,690 --> 00:34:34,780
way while it's in transit and when it's

00:34:31,780 --> 00:34:39,129
on my device that we're doing something

00:34:34,780 --> 00:34:44,679
to afford both visually for the user and

00:34:39,129 --> 00:34:47,679
on the backend right so there may be

00:34:44,679 --> 00:34:51,220
some concepts and we have an kevorkian

00:34:47,679 --> 00:34:52,869
we have the Canadians to thank for the

00:34:51,220 --> 00:34:56,250
privacy by design principles I'm going

00:34:52,869 --> 00:34:56,250
to talk about that here in a second but

00:34:56,609 --> 00:35:04,660
zero trust is the assumption that Amazon

00:35:01,869 --> 00:35:06,940
had this web host or the services that

00:35:04,660 --> 00:35:10,480
were using aren't gonna be secure enough

00:35:06,940 --> 00:35:12,490
and we're not gonna end up with a you

00:35:10,480 --> 00:35:14,170
know Capital One breach for those

00:35:12,490 --> 00:35:17,289
Americans that are familiar with the

00:35:14,170 --> 00:35:20,039
company Capital One they lost a lot of

00:35:17,289 --> 00:35:22,029
information that was personal and

00:35:20,039 --> 00:35:24,460
essentially with a lot of these

00:35:22,029 --> 00:35:28,359
vulnerabilities and breaches that happen

00:35:24,460 --> 00:35:32,049
I fear that and the reason I'm giving

00:35:28,359 --> 00:35:33,789
this talk is that I feel that we're at

00:35:32,049 --> 00:35:36,549
the point where we're just we've just

00:35:33,789 --> 00:35:41,470
given up we feel that the data is all

00:35:36,549 --> 00:35:44,559
out there anyway so we do have an

00:35:41,470 --> 00:35:46,150
opportunity it affects our bottom line I

00:35:44,559 --> 00:35:49,900
could talk about it in a positive way to

00:35:46,150 --> 00:35:53,829
innovate around building that trust up

00:35:49,900 --> 00:35:57,940
again with our apps are these some

00:35:53,829 --> 00:36:01,359
examples as in some new innovations in

00:35:57,940 --> 00:36:05,740
this space us to sort of afford that

00:36:01,359 --> 00:36:07,720
respect and build that up Apple recently

00:36:05,740 --> 00:36:10,029
announced that they were using something

00:36:07,720 --> 00:36:12,549
called differential privacy on their

00:36:10,029 --> 00:36:15,190
apps and that they had the justifiable

00:36:12,549 --> 00:36:17,619
reason to improve their applications but

00:36:15,190 --> 00:36:19,240
there was no way this differential

00:36:17,619 --> 00:36:22,450
privacy technology

00:36:19,240 --> 00:36:24,340
no real reason to share that Gary you

00:36:22,450 --> 00:36:28,980
only named that I know here sorry for

00:36:24,340 --> 00:36:32,680
picking on you Gary was using iTunes or

00:36:28,980 --> 00:36:36,880
name the app what differential privacy

00:36:32,680 --> 00:36:41,830
does is at the edge on your device sort

00:36:36,880 --> 00:36:46,480
of add some noise to your solution to

00:36:41,830 --> 00:36:49,270
your data set and securely sensitive

00:36:46,480 --> 00:36:53,110
transit to Apple servers classifies it

00:36:49,270 --> 00:36:56,440
in a specific area that it needs to sort

00:36:53,110 --> 00:36:58,750
of help focus on and they seen some

00:36:56,440 --> 00:37:00,670
satisfactory trade-offs as to the

00:36:58,750 --> 00:37:03,480
getting anything information they need

00:37:00,670 --> 00:37:07,270
to improve that piece of the application

00:37:03,480 --> 00:37:12,430
without treading on your name email and

00:37:07,270 --> 00:37:16,780
and location information as it were we

00:37:12,430 --> 00:37:19,090
see a lot of examples of differential

00:37:16,780 --> 00:37:22,210
privacy today actually most of Google

00:37:19,090 --> 00:37:23,710
and Microsoft's and some of these larger

00:37:22,210 --> 00:37:26,470
firms are using differential privacy

00:37:23,710 --> 00:37:30,520
today you know those little suggestion

00:37:26,470 --> 00:37:33,940
chips you know those quick replies in

00:37:30,520 --> 00:37:36,760
your app well this day will need to sort

00:37:33,940 --> 00:37:40,240
of type that too

00:37:36,760 --> 00:37:41,830
you know with you append my photo for

00:37:40,240 --> 00:37:44,050
example it has nothing to do with

00:37:41,830 --> 00:37:46,930
anything but if you have that notion

00:37:44,050 --> 00:37:49,180
that data is ubiquitous is just a

00:37:46,930 --> 00:37:50,890
commodity you will just collect as much

00:37:49,180 --> 00:37:52,990
information because the volume of data

00:37:50,890 --> 00:37:55,540
tempered with the variety of data

00:37:52,990 --> 00:37:56,980
tempered with the velocity of that

00:37:55,540 --> 00:38:01,180
information gives me a competitive edge

00:37:56,980 --> 00:38:03,100
I don't know that the folks and if

00:38:01,180 --> 00:38:05,109
anyone here works at gravely I don't

00:38:03,100 --> 00:38:07,440
know what they do in the backend but I

00:38:05,109 --> 00:38:09,750
would imagine that they would also

00:38:07,440 --> 00:38:13,359
family by the way

00:38:09,750 --> 00:38:16,450
let's helps me not embarrass myself when

00:38:13,359 --> 00:38:19,410
I send emails just a plug in and sort of

00:38:16,450 --> 00:38:21,820
checks my grammar and checks my spelling

00:38:19,410 --> 00:38:23,020
well they don't need my information in

00:38:21,820 --> 00:38:25,450
order to improve their application if

00:38:23,020 --> 00:38:28,270
there's that's their goal so I'd imagine

00:38:25,450 --> 00:38:30,400
that would be a great use of

00:38:28,270 --> 00:38:32,740
differential privacy this more on

00:38:30,400 --> 00:38:35,320
differential privacy

00:38:32,740 --> 00:38:38,030
our link it at the end of the slide

00:38:35,320 --> 00:38:39,500
definitely look it up type in Apple

00:38:38,030 --> 00:38:41,120
differential privacy I think they did a

00:38:39,500 --> 00:38:43,490
very really really good job

00:38:41,120 --> 00:38:45,260
Facebook also uses two different prefer

00:38:43,490 --> 00:38:50,270
n chill privacy now are they've done a

00:38:45,260 --> 00:38:53,770
white paper on it I talked about privacy

00:38:50,270 --> 00:38:58,400
by design principles and they're pretty

00:38:53,770 --> 00:39:00,110
like the three basic things that you

00:38:58,400 --> 00:39:02,210
shouldn't wait until we're in trouble

00:39:00,110 --> 00:39:04,790
until the GDP are dropped to send a

00:39:02,210 --> 00:39:05,840
million privacy has changed emails to

00:39:04,790 --> 00:39:11,420
our customers we need to be more

00:39:05,840 --> 00:39:12,950
proactive with that they're not

00:39:11,420 --> 00:39:21,280
collecting my personal information I

00:39:12,950 --> 00:39:24,280
promise I think I hope it doesn't okay

00:39:21,280 --> 00:39:24,280
right

00:39:25,150 --> 00:39:32,510
that privacy is a human right right

00:39:30,050 --> 00:39:36,920
again we talked about control contacts

00:39:32,510 --> 00:39:38,869
choice and respect I mean I said so have

00:39:36,920 --> 00:39:41,720
you just take some time for you to sort

00:39:38,869 --> 00:39:42,710
of ingest some of these private policies

00:39:41,720 --> 00:39:46,550
here I'm not gonna go through every

00:39:42,710 --> 00:39:50,210
single one of them but on the choice

00:39:46,550 --> 00:39:54,349
piece of a story to help wrap this talk

00:39:50,210 --> 00:39:56,540
up this is my daughter I did not ask her

00:39:54,349 --> 00:40:01,490
consent to take this picture because

00:39:56,540 --> 00:40:04,880
she's 4 at the time of this picture she

00:40:01,490 --> 00:40:09,700
goes to kindergarten as she's actually

00:40:04,880 --> 00:40:14,300
going to start in a few in next week and

00:40:09,700 --> 00:40:17,390
this was in preschool pre-k she she's

00:40:14,300 --> 00:40:20,119
putting the care of teachers a principal

00:40:17,390 --> 00:40:22,359
to feed her teacher and show her a good

00:40:20,119 --> 00:40:22,359
time

00:40:22,960 --> 00:40:31,339
that is the agreement it's a school

00:40:25,880 --> 00:40:32,710
right but if the school wants to do

00:40:31,339 --> 00:40:34,880
something else

00:40:32,710 --> 00:40:38,450
outside of the bounds of that standard

00:40:34,880 --> 00:40:44,510
agreement they come to me right I'm the

00:40:38,450 --> 00:40:46,339
dad I mean there's no controversy about

00:40:44,510 --> 00:40:47,630
that if you want to see if she if the

00:40:46,339 --> 00:40:50,080
school wants to take her to the splash

00:40:47,630 --> 00:40:54,109
park or can't stem it over there like a

00:40:50,080 --> 00:40:57,680
Kings Dominion or Disneyland or just two

00:40:54,109 --> 00:41:01,160
swimming pool library they ask

00:40:57,680 --> 00:41:05,930
permission and I say yes or say note

00:41:01,160 --> 00:41:08,540
that is the lens but which I look at

00:41:05,930 --> 00:41:13,760
data trust and data privacy

00:41:08,540 --> 00:41:17,800
it's my data right if I've give my

00:41:13,760 --> 00:41:20,950
information my name my email and

00:41:17,800 --> 00:41:26,180
everything else that Facebook has on me

00:41:20,950 --> 00:41:31,310
that's fine that's zero it's it's it's a

00:41:26,180 --> 00:41:36,620
zero-sum game today but I have an

00:41:31,310 --> 00:41:38,960
expectation that I gave up my face

00:41:36,620 --> 00:41:43,000
to that facial-recognition thing in

00:41:38,960 --> 00:41:45,500
order to get the value of being notified

00:41:43,000 --> 00:41:49,400
that I was in some picture that I didn't

00:41:45,500 --> 00:41:53,030
know was taken right if that picture is

00:41:49,400 --> 00:41:55,610
then sent to law enforcement for another

00:41:53,030 --> 00:42:01,100
value proposition they should come to me

00:41:55,610 --> 00:42:05,120
I am the data subject I own that data so

00:42:01,100 --> 00:42:07,660
you're right but I have to we have to

00:42:05,120 --> 00:42:07,660
fight for that

00:42:12,750 --> 00:42:21,280
so definitely the privacy and a

00:42:17,410 --> 00:42:25,690
depressed again just a DoubleTap the sum

00:42:21,280 --> 00:42:29,850
of data transparency how much context

00:42:25,690 --> 00:42:35,500
you provide with value delivery

00:42:29,850 --> 00:42:38,220
combining that choice and context with

00:42:35,500 --> 00:42:41,220
that respect that consequence acceptance

00:42:38,220 --> 00:42:41,220
right

00:42:50,890 --> 00:42:56,540
so this talk has actually not the

00:42:55,160 --> 00:42:59,570
teacher about data privacy because we

00:42:56,540 --> 00:43:01,070
know we're we're just trying to we're

00:42:59,570 --> 00:43:04,670
still in the middle of renegotiating

00:43:01,070 --> 00:43:09,490
these norms but I'm hoping that you walk

00:43:04,670 --> 00:43:13,880
into the office on Monday and you're

00:43:09,490 --> 00:43:17,869
given an anti-pattern or an unethical

00:43:13,880 --> 00:43:21,710
choice or the thing that we've always

00:43:17,869 --> 00:43:25,250
done because that's how we do it that

00:43:21,710 --> 00:43:29,300
we're armed with information as to where

00:43:25,250 --> 00:43:31,510
we want to go as a people around our

00:43:29,300 --> 00:43:31,510
data

00:43:33,930 --> 00:43:41,820

YouTube URL: https://www.youtube.com/watch?v=GW3COxipbgY


