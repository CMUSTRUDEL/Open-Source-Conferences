Title: Building Edge AI Stack and AI-aaS in Cloud Native Way - Yin Ding, Futurewei
Publication date: 2020-12-03
Playlist: Open Source Summit Japan & Automotive Linux Summit 2020
Description: 
	Building Edge AI Stack and AI-aaS in Cloud Native Way - Yin Ding, Futurewei
Captions: 
	00:00:05,120 --> 00:00:09,120
hello everyone

00:00:06,080 --> 00:00:12,160
uh thank you to attend my session so

00:00:09,120 --> 00:00:14,799
the title is building edge ai stack

00:00:12,160 --> 00:00:15,759
with ai and service in the cloud native

00:00:14,799 --> 00:00:18,960
way

00:00:15,759 --> 00:00:20,560
so uh my name is ending i come from a

00:00:18,960 --> 00:00:24,160
future way uh

00:00:20,560 --> 00:00:24,160
very nice to meet you guys here

00:00:26,480 --> 00:00:30,880
so uh first let's talk about the problem

00:00:29,279 --> 00:00:33,680
and challenges

00:00:30,880 --> 00:00:35,280
why we need this as cloud computing and

00:00:33,680 --> 00:00:39,040
edge ai

00:00:35,280 --> 00:00:41,600
so with the 5g and all the iot booming

00:00:39,040 --> 00:00:42,960
this edge cloud computing is more and

00:00:41,600 --> 00:00:46,320
more urgent

00:00:42,960 --> 00:00:49,440
so why we need it because with iot

00:00:46,320 --> 00:00:52,079
or remote site

00:00:49,440 --> 00:00:53,760
sensors there's a lot of data generated

00:00:52,079 --> 00:00:57,520
in the remote side

00:00:53,760 --> 00:01:00,239
so we want to efficiently compute

00:00:57,520 --> 00:01:01,120
with this data so near data computation

00:01:00,239 --> 00:01:04,400
is a

00:01:01,120 --> 00:01:05,199
request that's why we want to process

00:01:04,400 --> 00:01:07,439
data

00:01:05,199 --> 00:01:09,920
on the edge side instead of transfer all

00:01:07,439 --> 00:01:13,439
data back to the data center

00:01:09,920 --> 00:01:17,360
also there's other three main problem

00:01:13,439 --> 00:01:20,080
first latency you can see uh

00:01:17,360 --> 00:01:21,280
even though the internet is faster

00:01:20,080 --> 00:01:24,560
however you cannot

00:01:21,280 --> 00:01:26,560
exceed the light of speed and if

00:01:24,560 --> 00:01:27,920
the data center in the other another

00:01:26,560 --> 00:01:31,119
cost of your

00:01:27,920 --> 00:01:35,840
uh place the data generated

00:01:31,119 --> 00:01:38,960
so it take maybe 100 or 200 milliseconds

00:01:35,840 --> 00:01:41,600
to transfer the data however i have some

00:01:38,960 --> 00:01:44,320
user requests say okay can we do

00:01:41,600 --> 00:01:46,000
the processing within 20 milliseconds or

00:01:44,320 --> 00:01:48,320
40 milliseconds

00:01:46,000 --> 00:01:49,840
if the data center is cannot guarantee

00:01:48,320 --> 00:01:53,360
is very close

00:01:49,840 --> 00:01:54,640
you cannot i mean conquer this problem

00:01:53,360 --> 00:01:57,439
you have to

00:01:54,640 --> 00:01:59,040
put some computation near to the data

00:01:57,439 --> 00:02:01,439
generated site

00:01:59,040 --> 00:02:02,640
so that's why we need to add cloud

00:02:01,439 --> 00:02:05,920
computing

00:02:02,640 --> 00:02:06,960
also uh because a large amount of data

00:02:05,920 --> 00:02:10,239
are generated

00:02:06,960 --> 00:02:11,120
so the bandwidth is precious you don't

00:02:10,239 --> 00:02:13,440
want to waste

00:02:11,120 --> 00:02:14,720
all the user bandwidth upload the raw

00:02:13,440 --> 00:02:17,280
data there

00:02:14,720 --> 00:02:17,760
because some data redundancy some data

00:02:17,280 --> 00:02:21,040
is not

00:02:17,760 --> 00:02:22,400
clean up and we want to save some

00:02:21,040 --> 00:02:26,000
bandwidth for the other

00:02:22,400 --> 00:02:28,400
uh using usage we cannot

00:02:26,000 --> 00:02:29,680
do that all for the transportation of

00:02:28,400 --> 00:02:32,640
the data

00:02:29,680 --> 00:02:33,200
the third not the last but very

00:02:32,640 --> 00:02:36,319
important

00:02:33,200 --> 00:02:38,720
data privacy so

00:02:36,319 --> 00:02:41,040
not all people want to upload data to

00:02:38,720 --> 00:02:44,720
the cloud for computation

00:02:41,040 --> 00:02:47,680
not only for personal they have a pii

00:02:44,720 --> 00:02:49,280
also for the industry all the factories

00:02:47,680 --> 00:02:52,239
they may not want to upgrade

00:02:49,280 --> 00:02:53,360
upload all this raw data to data center

00:02:52,239 --> 00:02:57,599
because

00:02:53,360 --> 00:03:00,560
it's this could expose their uh

00:02:57,599 --> 00:03:02,239
business confidential information even

00:03:00,560 --> 00:03:04,800
with data mining or other

00:03:02,239 --> 00:03:06,720
things so they want to do the data

00:03:04,800 --> 00:03:09,840
cleanup

00:03:06,720 --> 00:03:10,800
so then they can take care i mean take

00:03:09,840 --> 00:03:13,280
advantage of

00:03:10,800 --> 00:03:15,440
cloud computing the large resource

00:03:13,280 --> 00:03:18,480
computation resource to

00:03:15,440 --> 00:03:20,879
compute this data is clean up

00:03:18,480 --> 00:03:22,239
and they already hide sensitive

00:03:20,879 --> 00:03:24,879
information

00:03:22,239 --> 00:03:26,480
the third one the last one uh it's a new

00:03:24,879 --> 00:03:29,360
is the ai of loading

00:03:26,480 --> 00:03:30,080
for example we have more and more

00:03:29,360 --> 00:03:33,040
powerful

00:03:30,080 --> 00:03:34,239
devices especially mobile phones mobile

00:03:33,040 --> 00:03:37,040
devices

00:03:34,239 --> 00:03:39,120
however the mobile phone have only

00:03:37,040 --> 00:03:42,400
limited battery attached

00:03:39,120 --> 00:03:44,879
so uh this uh ai inference

00:03:42,400 --> 00:03:45,599
i mean not mentioned the training but

00:03:44,879 --> 00:03:48,720
the inference

00:03:45,599 --> 00:03:51,840
also could be a very compute

00:03:48,720 --> 00:03:54,720
intense that means

00:03:51,840 --> 00:03:55,920
your cell phone may not keep up with the

00:03:54,720 --> 00:03:59,200
algorithm

00:03:55,920 --> 00:04:01,040
also more important this computation

00:03:59,200 --> 00:04:02,959
takes a lot of energy that means it's

00:04:01,040 --> 00:04:06,000
draining battery really fast

00:04:02,959 --> 00:04:08,560
that's people don't like they want their

00:04:06,000 --> 00:04:09,519
mobile device to hold long hold for a

00:04:08,560 --> 00:04:11,599
long time

00:04:09,519 --> 00:04:13,200
that's why we want to offload some this

00:04:11,599 --> 00:04:15,920
ai inference

00:04:13,200 --> 00:04:18,079
to the edge so we don't need to transfer

00:04:15,920 --> 00:04:21,280
all the way to the data center

00:04:18,079 --> 00:04:24,960
to have a fast and low latency response

00:04:21,280 --> 00:04:26,960
however it will save the energy and also

00:04:24,960 --> 00:04:30,479
take advantage of more complicated

00:04:26,960 --> 00:04:33,040
models for the inference

00:04:30,479 --> 00:04:35,120
so now we know why we need this edge

00:04:33,040 --> 00:04:38,479
computing and edge ai

00:04:35,120 --> 00:04:39,600
so the major major challenge we need to

00:04:38,479 --> 00:04:43,120
solve is

00:04:39,600 --> 00:04:46,320
first network reliability so you know

00:04:43,120 --> 00:04:49,600
um it's not seem like

00:04:46,320 --> 00:04:53,600
within data center so the edge node and

00:04:49,600 --> 00:04:56,639
cloud is connected through the internet

00:04:53,600 --> 00:04:58,639
so the internet is not reliable and

00:04:56,639 --> 00:05:00,400
their latency is not consistent it could

00:04:58,639 --> 00:05:03,360
be fast could be

00:05:00,400 --> 00:05:04,400
i mean could be slow and also the

00:05:03,360 --> 00:05:07,120
network bandwidth

00:05:04,400 --> 00:05:08,240
is limited so as i said the user only

00:05:07,120 --> 00:05:11,520
purchased

00:05:08,240 --> 00:05:14,960
a limited amount of a bandwidth

00:05:11,520 --> 00:05:18,720
it's not guaranteed to be

00:05:14,960 --> 00:05:20,160
wide enough and also most of the time

00:05:18,720 --> 00:05:22,720
edge devices have

00:05:20,160 --> 00:05:25,120
relative constraints results constrained

00:05:22,720 --> 00:05:28,720
in the edge node that means it could be

00:05:25,120 --> 00:05:32,080
as small as a a small iot

00:05:28,720 --> 00:05:33,120
gateway within uh some some someone's

00:05:32,080 --> 00:05:36,000
home

00:05:33,120 --> 00:05:37,600
also it could be a large server however

00:05:36,000 --> 00:05:38,639
compared to the cloud is still

00:05:37,600 --> 00:05:42,560
constrained

00:05:38,639 --> 00:05:45,919
that means the hardware may be

00:05:42,560 --> 00:05:49,120
outdated or is a it's a

00:05:45,919 --> 00:05:50,240
previous or even older generation they

00:05:49,120 --> 00:05:53,360
have a limited

00:05:50,240 --> 00:05:56,160
computation ability

00:05:53,360 --> 00:05:57,039
and it's very important for the edge

00:05:56,160 --> 00:06:00,240
autonomy

00:05:57,039 --> 00:06:01,440
that means uh as we said the network is

00:06:00,240 --> 00:06:04,000
not reliable

00:06:01,440 --> 00:06:05,440
when the network is disconnected or

00:06:04,000 --> 00:06:08,960
temporarily

00:06:05,440 --> 00:06:12,000
done we need the edge to run

00:06:08,960 --> 00:06:14,240
autonomously at the outside without

00:06:12,000 --> 00:06:15,199
communicating with the cloud they can

00:06:14,240 --> 00:06:18,840
run

00:06:15,199 --> 00:06:20,720
autonomously the last one is a highly

00:06:18,840 --> 00:06:21,680
distributed and heterogeneous device

00:06:20,720 --> 00:06:25,919
management

00:06:21,680 --> 00:06:28,960
so with the 5g and iot you can see

00:06:25,919 --> 00:06:29,919
old agile and devices are geo

00:06:28,960 --> 00:06:32,319
distributed

00:06:29,919 --> 00:06:33,840
all around the system and also they are

00:06:32,319 --> 00:06:36,160
heterogeneous

00:06:33,840 --> 00:06:37,680
from different vendors different

00:06:36,160 --> 00:06:40,000
operating system

00:06:37,680 --> 00:06:41,680
different hardware architectures we need

00:06:40,000 --> 00:06:45,680
to solve this problem

00:06:41,680 --> 00:06:45,680
that's the challenge we are facing

00:06:47,039 --> 00:06:50,960
so uh when we try to solve this problem

00:06:50,240 --> 00:06:53,919
we start

00:06:50,960 --> 00:06:55,280
with our core open source project it's

00:06:53,919 --> 00:06:58,080
called kubernetes

00:06:55,280 --> 00:06:59,199
so kubernetes currently is a cncf cloud

00:06:58,080 --> 00:07:03,199
native foundation

00:06:59,199 --> 00:07:06,400
incubation project so we graduated

00:07:03,199 --> 00:07:08,240
in this year september

00:07:06,400 --> 00:07:10,000
so this could be edge built upon

00:07:08,240 --> 00:07:12,639
creatives so it's

00:07:10,000 --> 00:07:13,759
take advantage all the kubernetes have

00:07:12,639 --> 00:07:16,400
for the

00:07:13,759 --> 00:07:17,520
application orchestration deployment

00:07:16,400 --> 00:07:20,880
lifecycle management

00:07:17,520 --> 00:07:22,960
etc and it provides fundamental

00:07:20,880 --> 00:07:24,720
fundamental infrastructure support for

00:07:22,960 --> 00:07:28,840
networking

00:07:24,720 --> 00:07:30,240
or also this app deployment metadata

00:07:28,840 --> 00:07:34,160
synchronization

00:07:30,240 --> 00:07:36,560
the cloud edge so the developer is only

00:07:34,160 --> 00:07:39,039
focusing on developer their business

00:07:36,560 --> 00:07:42,880
logic to solve their problem

00:07:39,039 --> 00:07:45,680
we don't worry about all these

00:07:42,880 --> 00:07:47,599
issues the network that the platform can

00:07:45,680 --> 00:07:51,440
provide

00:07:47,599 --> 00:07:54,720
so with this the kubernetes provide

00:07:51,440 --> 00:07:57,360
first seamless cloud add communication

00:07:54,720 --> 00:08:00,319
so this communication i include not only

00:07:57,360 --> 00:08:03,840
the data communication but also metadata

00:08:00,319 --> 00:08:06,400
and ad autonomy that means

00:08:03,840 --> 00:08:07,440
doing temporary internet connection

00:08:06,400 --> 00:08:11,759
issues

00:08:07,440 --> 00:08:15,599
so the ads can run autonomously

00:08:11,759 --> 00:08:19,360
without connect to the cloud

00:08:15,599 --> 00:08:22,240
and also when the connection uh restored

00:08:19,360 --> 00:08:24,160
and we're going to resynchronize the

00:08:22,240 --> 00:08:27,680
metadata to make sure

00:08:24,160 --> 00:08:30,240
the edge is running as we expected in

00:08:27,680 --> 00:08:32,800
the desired state

00:08:30,240 --> 00:08:33,680
the third one is a low resource ready

00:08:32,800 --> 00:08:37,360
that means

00:08:33,680 --> 00:08:40,800
as we mentioned the problem of facing is

00:08:37,360 --> 00:08:42,479
someone time the aginode have only

00:08:40,800 --> 00:08:45,519
constrained the resource

00:08:42,479 --> 00:08:46,560
it's including probably low memory low

00:08:45,519 --> 00:08:49,839
bandwidth

00:08:46,560 --> 00:08:53,040
and a low compute ability

00:08:49,839 --> 00:08:56,720
so a coupe edge can vary to

00:08:53,040 --> 00:08:59,200
suitable for high computation resource

00:08:56,720 --> 00:09:04,480
even the low computing resource

00:08:59,200 --> 00:09:07,600
so we can the cube edge can

00:09:04,480 --> 00:09:10,800
deploy to edge node as low as a

00:09:07,600 --> 00:09:14,000
megabytes memory

00:09:10,800 --> 00:09:17,200
and we recommend it at least 256 mega

00:09:14,000 --> 00:09:19,279
megabytes and also we provide

00:09:17,200 --> 00:09:20,320
simplified device communication that

00:09:19,279 --> 00:09:23,600
means we provide

00:09:20,320 --> 00:09:26,720
a device twin device shadowing so

00:09:23,600 --> 00:09:29,040
from the cloud you can easily manage the

00:09:26,720 --> 00:09:32,480
iot devices

00:09:29,040 --> 00:09:32,480
without some actual work

00:09:33,839 --> 00:09:37,680
now here let's go over the kubernetes

00:09:35,760 --> 00:09:40,560
architecture you can see

00:09:37,680 --> 00:09:41,600
on the top on the this is a three part

00:09:40,560 --> 00:09:44,959
we show the

00:09:41,600 --> 00:09:47,440
cloud edge and device collaboration

00:09:44,959 --> 00:09:48,640
on the top part is cloud you can see in

00:09:47,440 --> 00:09:51,360
the center

00:09:48,640 --> 00:09:52,399
is the kubernetes that means the

00:09:51,360 --> 00:09:55,920
kubernetes

00:09:52,399 --> 00:10:00,080
uh is the we require kubernetes deploy

00:09:55,920 --> 00:10:03,200
in order to deploy uh kubernetes

00:10:00,080 --> 00:10:03,839
and with kubernetes we use the standard

00:10:03,200 --> 00:10:06,240
of kuber

00:10:03,839 --> 00:10:07,760
control as the command line so we

00:10:06,240 --> 00:10:10,079
inherit the most of the

00:10:07,760 --> 00:10:11,440
we support most of the kubercontrol

00:10:10,079 --> 00:10:15,120
commands

00:10:11,440 --> 00:10:17,839
and you can see uh the core part is

00:10:15,120 --> 00:10:18,880
of the kubernetes called the cloud core

00:10:17,839 --> 00:10:21,440
does include

00:10:18,880 --> 00:10:23,440
edge controller device controller sync

00:10:21,440 --> 00:10:26,160
controller and cloud hub

00:10:23,440 --> 00:10:26,720
this means uh edge controller of course

00:10:26,160 --> 00:10:29,440
that means

00:10:26,720 --> 00:10:30,079
it's controlled edge node so we have

00:10:29,440 --> 00:10:33,200
this

00:10:30,079 --> 00:10:35,440
dark line the edge node draw there but

00:10:33,200 --> 00:10:36,480
the actual edge node is on the bottom

00:10:35,440 --> 00:10:38,240
left

00:10:36,480 --> 00:10:40,640
that's the drill down the edge

00:10:38,240 --> 00:10:44,079
controller is

00:10:40,640 --> 00:10:44,640
handled how we add manage edge node to

00:10:44,079 --> 00:10:47,440
make it

00:10:44,640 --> 00:10:47,839
drawn the cluster and the delegate all

00:10:47,440 --> 00:10:50,800
the

00:10:47,839 --> 00:10:53,760
command from the cloud to the edge

00:10:50,800 --> 00:10:57,040
device controller is we use a crd

00:10:53,760 --> 00:11:00,160
device crd to define the devices

00:10:57,040 --> 00:11:03,040
so with device controller you

00:11:00,160 --> 00:11:05,839
can control or view the status of a

00:11:03,040 --> 00:11:07,600
device attached to the edge node

00:11:05,839 --> 00:11:10,399
sync controller is for the

00:11:07,600 --> 00:11:14,399
synchronization especially when the uh

00:11:10,399 --> 00:11:17,839
you first draw on the cluster or

00:11:14,399 --> 00:11:20,800
some network issue happened

00:11:17,839 --> 00:11:21,760
the network connection is restored so

00:11:20,800 --> 00:11:24,880
that means uh

00:11:21,760 --> 00:11:27,600
with sync controller it

00:11:24,880 --> 00:11:28,000
synchronize the data and metadata

00:11:27,600 --> 00:11:30,240
between

00:11:28,000 --> 00:11:31,279
the cloud and edge to make sure edge

00:11:30,240 --> 00:11:34,640
node will run

00:11:31,279 --> 00:11:38,000
in the desired state the last part is

00:11:34,640 --> 00:11:40,480
called hub basically uh is set up the

00:11:38,000 --> 00:11:43,440
connections between the cloud and edge

00:11:40,480 --> 00:11:44,160
as we know the edge probably i mean

00:11:43,440 --> 00:11:47,040
deployed

00:11:44,160 --> 00:11:48,399
in behind some firewalls either the

00:11:47,040 --> 00:11:52,399
copenhagen firewall

00:11:48,399 --> 00:11:56,000
or even your home firewall so that means

00:11:52,399 --> 00:11:56,480
is that if it is not set up by net that

00:11:56,000 --> 00:11:59,120
means

00:11:56,480 --> 00:12:01,200
there's no public ip for your edge node

00:11:59,120 --> 00:12:04,399
so it's impossible for your ad

00:12:01,200 --> 00:12:07,600
to build cloud to access the ad directly

00:12:04,399 --> 00:12:10,880
and so we set up this web socket

00:12:07,600 --> 00:12:11,760
so when the edge node joined the cluster

00:12:10,880 --> 00:12:14,880
we set up this

00:12:11,760 --> 00:12:18,639
websocket connections that's

00:12:14,880 --> 00:12:22,639
duplex that means we can send combined

00:12:18,639 --> 00:12:26,160
from cloud to the edge so the edge core

00:12:22,639 --> 00:12:27,279
part have an ad hub i mean compared to

00:12:26,160 --> 00:12:30,560
the cloud top to

00:12:27,279 --> 00:12:32,560
for the connections and also

00:12:30,560 --> 00:12:33,760
uh the edge currently support a

00:12:32,560 --> 00:12:37,440
continuity

00:12:33,760 --> 00:12:42,079
creole docker container and

00:12:37,440 --> 00:12:45,760
we have uh support some ci entry ci size

00:12:42,079 --> 00:12:47,920
for uh good head storage

00:12:45,760 --> 00:12:50,800
to the container running on the edge

00:12:47,920 --> 00:12:53,519
side also you can see that some

00:12:50,800 --> 00:12:56,639
a mosquito there is the uh pops up

00:12:53,519 --> 00:12:56,639
broker so we

00:12:57,760 --> 00:13:04,320
so we have this uh devices that we

00:13:00,800 --> 00:13:07,680
support different iot

00:13:04,320 --> 00:13:09,440
protocols include mqd the motorbike

00:13:07,680 --> 00:13:12,800
bluetooth opc ua

00:13:09,440 --> 00:13:16,560
that's popular industry uh

00:13:12,800 --> 00:13:20,560
industry iot protocol

00:13:16,560 --> 00:13:24,320
so uh with this uh mqtt

00:13:20,560 --> 00:13:28,160
iot protocol we can let system

00:13:24,320 --> 00:13:28,160
control and manage devices

00:13:28,240 --> 00:13:34,160
now i'm introducing another

00:13:31,519 --> 00:13:34,959
open source project so we based on

00:13:34,160 --> 00:13:38,639
kubernetes

00:13:34,959 --> 00:13:41,680
we think it's very useful to demonstrate

00:13:38,639 --> 00:13:44,720
ai abilities that's why we

00:13:41,680 --> 00:13:46,800
in the lf edge acronym community we

00:13:44,720 --> 00:13:48,720
set up this kubernetes and service

00:13:46,800 --> 00:13:52,320
blueprint project

00:13:48,720 --> 00:13:52,880
so this project is focusing on device

00:13:52,320 --> 00:13:56,079
edge

00:13:52,880 --> 00:13:59,440
cloud collaboration framework a build

00:13:56,079 --> 00:14:02,959
around the kubash so this blueprint

00:13:59,440 --> 00:14:06,720
the verticals focusing could be iot

00:14:02,959 --> 00:14:08,800
could it be mec the mac the scenario

00:14:06,720 --> 00:14:11,040
so the key component of this project is

00:14:08,800 --> 00:14:15,120
the kube edge as we said this is a

00:14:11,040 --> 00:14:17,680
csf open source project

00:14:15,120 --> 00:14:20,000
so the first type we're introducing into

00:14:17,680 --> 00:14:21,199
this project is focusing building an ad

00:14:20,000 --> 00:14:24,320
stack

00:14:21,199 --> 00:14:27,120
the user case is ml inference offloading

00:14:24,320 --> 00:14:28,240
to the ad servers that means if you have

00:14:27,120 --> 00:14:29,920
a

00:14:28,240 --> 00:14:31,519
mobile device you want to do some

00:14:29,920 --> 00:14:34,240
inference you want to offload that to

00:14:31,519 --> 00:14:37,519
the ad server i'm going to give a demo

00:14:34,240 --> 00:14:40,959
uh in the following talk

00:14:37,519 --> 00:14:44,000
in the following slides and then

00:14:40,959 --> 00:14:46,880
so this print blueprint family is kind

00:14:44,000 --> 00:14:47,440
this is a kind of end-to-end open source

00:14:46,880 --> 00:14:51,040
project

00:14:47,440 --> 00:14:53,839
solution so we'll leverage the various

00:14:51,040 --> 00:14:54,399
infrastructure so that means they

00:14:53,839 --> 00:14:58,240
support

00:14:54,399 --> 00:15:01,920
x86 arm or a risk

00:14:58,240 --> 00:15:04,160
risk of fi so so this blueprint is an

00:15:01,920 --> 00:15:07,519
infrastructure neutral we want to

00:15:04,160 --> 00:15:12,000
support all kinds of infrastructures

00:15:07,519 --> 00:15:15,120
heterogeneous infrastructures

00:15:12,000 --> 00:15:15,120
here is the

00:15:17,680 --> 00:15:21,760
offloading function block diagram so you

00:15:21,040 --> 00:15:25,199
can see

00:15:21,760 --> 00:15:28,800
uh in the central part is the edge

00:15:25,199 --> 00:15:31,920
and the central column is

00:15:28,800 --> 00:15:35,279
edge and in the middle of the

00:15:31,920 --> 00:15:35,920
horizontal one is the kubernetes so that

00:15:35,279 --> 00:15:38,480
means

00:15:35,920 --> 00:15:40,560
in the cloud we build a kubernetes

00:15:38,480 --> 00:15:43,600
multiple kubernetes

00:15:40,560 --> 00:15:44,720
and in the edge we deploy kube edge so

00:15:43,600 --> 00:15:47,920
the kubernetes

00:15:44,720 --> 00:15:52,000
have covered

00:15:47,920 --> 00:15:54,399
cloud edge and devices so the first

00:15:52,000 --> 00:15:56,880
user case we are going to demonstrate is

00:15:54,399 --> 00:15:59,279
called emotion recognition

00:15:56,880 --> 00:16:01,279
basically we are running the training

00:15:59,279 --> 00:16:02,240
service in the cloud we train the new

00:16:01,279 --> 00:16:04,959
model

00:16:02,240 --> 00:16:05,519
we deploy using the cover deploy the

00:16:04,959 --> 00:16:08,560
model

00:16:05,519 --> 00:16:12,160
and application to the edge then

00:16:08,560 --> 00:16:15,759
host this services to serve the devices

00:16:12,160 --> 00:16:18,639
the device is only do the email pre

00:16:15,759 --> 00:16:21,120
preparation or pre-processing then

00:16:18,639 --> 00:16:24,720
offload this inference to the edge

00:16:21,120 --> 00:16:28,720
i'm going to demo this later

00:16:24,720 --> 00:16:31,839
so that means uh

00:16:28,720 --> 00:16:34,560
if our devices has a limited resource

00:16:31,839 --> 00:16:35,680
or want to save energy so they can

00:16:34,560 --> 00:16:38,560
offload this

00:16:35,680 --> 00:16:41,360
inference to the edge and there's a

00:16:38,560 --> 00:16:44,480
typical offloading approach

00:16:41,360 --> 00:16:47,680
we offload the inference to

00:16:44,480 --> 00:16:48,800
from the device to the edge and all the

00:16:47,680 --> 00:16:52,240
training is happening

00:16:48,800 --> 00:16:54,560
in the cloud so this collaboration

00:16:52,240 --> 00:16:55,519
framework is very essential to the ml of

00:16:54,560 --> 00:16:58,639
loading

00:16:55,519 --> 00:17:00,320
so combat provide underlying software

00:16:58,639 --> 00:17:03,040
platform including

00:17:00,320 --> 00:17:04,240
the application deployment model

00:17:03,040 --> 00:17:06,880
deployment

00:17:04,240 --> 00:17:08,640
this uh in the future we are going to

00:17:06,880 --> 00:17:12,160
support a data set

00:17:08,640 --> 00:17:12,160
deployment update also

00:17:15,120 --> 00:17:22,400
so here is the user case

00:17:18,319 --> 00:17:25,679
for this emotion recognition we

00:17:22,400 --> 00:17:29,679
now the abstract blocks diagram we

00:17:25,679 --> 00:17:32,880
see that we show some details is

00:17:29,679 --> 00:17:34,160
device edge cloud collaboration so the

00:17:32,880 --> 00:17:36,559
cloud we are running

00:17:34,160 --> 00:17:37,600
the training and provide a model

00:17:36,559 --> 00:17:40,799
resource

00:17:37,600 --> 00:17:44,240
and the edge will run the inference

00:17:40,799 --> 00:17:45,120
services and provide emotion recognition

00:17:44,240 --> 00:17:49,039
service

00:17:45,120 --> 00:17:52,559
and provide this offloading apis

00:17:49,039 --> 00:17:53,919
so it will accept the application deploy

00:17:52,559 --> 00:17:56,960
the application

00:17:53,919 --> 00:17:57,760
provide a inference model to do the

00:17:56,960 --> 00:18:00,960
inference

00:17:57,760 --> 00:18:02,559
the device do the image pre-process

00:18:00,960 --> 00:18:06,480
include

00:18:02,559 --> 00:18:09,919
resize convert to rgb

00:18:06,480 --> 00:18:13,120
image to a pixel array also

00:18:09,919 --> 00:18:16,240
and then it's offload upload this

00:18:13,120 --> 00:18:17,360
pixel array for to the edge for the

00:18:16,240 --> 00:18:20,160
inference

00:18:17,360 --> 00:18:22,960
then the edge will run inference

00:18:20,160 --> 00:18:26,880
algorithm then reply the result to the

00:18:22,960 --> 00:18:30,240
device here let me uh

00:18:26,880 --> 00:18:31,919
i have a about a four minutes demo let

00:18:30,240 --> 00:18:35,200
me show this to you to see

00:18:31,919 --> 00:18:36,559
how this uh inference ml offloading

00:18:35,200 --> 00:18:40,840
inferences running

00:18:36,559 --> 00:18:43,840
look like with uh how the coupe edge is

00:18:40,840 --> 00:18:43,840
working

00:18:46,960 --> 00:18:53,760
so in this demo you can see uh we

00:18:50,640 --> 00:18:56,960
deploy our cloud part to a aws

00:18:53,760 --> 00:18:59,919
ec2 instance the edge part is

00:18:56,960 --> 00:19:02,400
a physical server running behind a

00:18:59,919 --> 00:19:05,679
corporate firewall

00:19:02,400 --> 00:19:06,320
and the devices we because all this

00:19:05,679 --> 00:19:08,880
pandemic

00:19:06,320 --> 00:19:11,919
we work at home so we use vpn connect to

00:19:08,880 --> 00:19:14,960
the server but in the real life

00:19:11,919 --> 00:19:18,240
the devices should probably

00:19:14,960 --> 00:19:20,240
within connect to the same subnet behind

00:19:18,240 --> 00:19:21,520
the same firewall of the added server so

00:19:20,240 --> 00:19:25,840
we don't need to have this

00:19:21,520 --> 00:19:25,840
vpn issues

00:19:27,679 --> 00:19:30,799
so in the two terminal window the top

00:19:30,400 --> 00:19:35,760
one

00:19:30,799 --> 00:19:35,760
is the cloud the bottom one is the edge

00:19:35,840 --> 00:19:41,600
first we can see

00:19:39,360 --> 00:19:43,440
we already installed we pre-installed

00:19:41,600 --> 00:19:46,799
the kubernetes

00:19:43,440 --> 00:19:49,360
in the cloud

00:19:46,799 --> 00:19:50,400
so there's only one node it's the master

00:19:49,360 --> 00:19:53,679
node

00:19:50,400 --> 00:19:57,520
so we it's on the aws public cloud

00:19:53,679 --> 00:20:00,960
so now we are going to uh

00:19:57,520 --> 00:20:04,480
let our ash node behind our copyright

00:20:00,960 --> 00:20:05,760
join this completed cluster the cluster

00:20:04,480 --> 00:20:07,280
master

00:20:05,760 --> 00:20:09,520
control plane is running in the public

00:20:07,280 --> 00:20:09,520
cloud

00:20:11,280 --> 00:20:15,120
so uh in the cloud server we only need

00:20:14,799 --> 00:20:18,720
to

00:20:15,120 --> 00:20:20,080
open one port is it's configurable it's

00:20:18,720 --> 00:20:23,919
now is default is

00:20:20,080 --> 00:20:26,799
10000 so what we do

00:20:23,919 --> 00:20:27,919
in the actional they say we use this uh

00:20:26,799 --> 00:20:31,360
k-admin

00:20:27,919 --> 00:20:35,600
tool is similar to kuber admin to draw

00:20:31,360 --> 00:20:38,720
our edge node to the cloud server

00:20:35,600 --> 00:20:42,400
the cloud cluster the community's cloud

00:20:38,720 --> 00:20:46,000
running on the cloud so you can see it

00:20:42,400 --> 00:20:46,000
really fast the uh

00:20:46,159 --> 00:20:53,919
it's already drawn let's

00:20:49,840 --> 00:21:03,840
verify that the server is joining the

00:20:53,919 --> 00:21:03,840
cluster already drawn cluster

00:21:06,159 --> 00:21:09,200
so you can see there's a two nodes right

00:21:08,480 --> 00:21:12,000
now one

00:21:09,200 --> 00:21:13,600
is the master running in the cloud edit

00:21:12,000 --> 00:21:16,720
server is

00:21:13,600 --> 00:21:19,039
the one running behind our corporate

00:21:16,720 --> 00:21:21,679
firewall

00:21:19,039 --> 00:21:23,280
now in the action you can see nothing is

00:21:21,679 --> 00:21:25,679
running

00:21:23,280 --> 00:21:26,799
then we are going to deploy our

00:21:25,679 --> 00:21:29,440
offloading

00:21:26,799 --> 00:21:32,080
services application from the cloud to

00:21:29,440 --> 00:21:32,080
the edge

00:21:34,400 --> 00:21:40,480
so this is a tenth floor

00:21:37,760 --> 00:21:40,480
tenth floor

00:21:41,520 --> 00:21:45,840
we are using the tens floor framework

00:21:45,919 --> 00:21:48,320
using

00:21:53,600 --> 00:21:58,320
so you can see we do this deployment

00:21:56,400 --> 00:22:03,200
cooper can draw applied

00:21:58,320 --> 00:22:05,840
and from the cloud you can see the

00:22:03,200 --> 00:22:07,760
the poly running on the edge on the edge

00:22:05,840 --> 00:22:09,919
node

00:22:07,760 --> 00:22:11,679
you can see that's already successfully

00:22:09,919 --> 00:22:14,000
deployed

00:22:11,679 --> 00:22:15,840
let's come to the edge to verify yes we

00:22:14,000 --> 00:22:18,640
can see the docker container is running

00:22:15,840 --> 00:22:18,640
on the edge node

00:22:24,000 --> 00:22:30,240
let's do some

00:22:27,200 --> 00:22:33,120
yep let's tell this log to show when

00:22:30,240 --> 00:22:35,120
what happened when we uh have this

00:22:33,120 --> 00:22:39,600
inference

00:22:35,120 --> 00:22:42,880
request come in on the left we have a

00:22:39,600 --> 00:22:43,919
android emulator running to to demo

00:22:42,880 --> 00:22:47,679
what's happening

00:22:43,919 --> 00:22:50,240
so first we open our

00:22:47,679 --> 00:22:51,039
photo book to upload yeah you can see

00:22:50,240 --> 00:22:54,400
the service is

00:22:51,039 --> 00:22:59,200
quickly running we uh

00:22:54,400 --> 00:23:01,280
upload a uh yeah we pre-process a

00:22:59,200 --> 00:23:02,559
portrait picture and then we upload it

00:23:01,280 --> 00:23:05,520
and give our answer back

00:23:02,559 --> 00:23:06,880
let's do another one so this even is a

00:23:05,520 --> 00:23:10,240
blur

00:23:06,880 --> 00:23:11,679
picture we convert to pixel array upload

00:23:10,240 --> 00:23:13,919
the service

00:23:11,679 --> 00:23:15,200
up a request for the service then we

00:23:13,919 --> 00:23:17,679
have a

00:23:15,200 --> 00:23:19,280
number come back for this one we got the

00:23:17,679 --> 00:23:23,200
result back too

00:23:19,280 --> 00:23:26,240
so the emotion we recognize

00:23:23,200 --> 00:23:31,440
is angry with the

00:23:26,240 --> 00:23:34,559
confidence 999 0.9997

00:23:31,440 --> 00:23:35,440
it's pretty confident that's a angry

00:23:34,559 --> 00:23:37,679
face

00:23:35,440 --> 00:23:39,200
so that's the base on our the model we

00:23:37,679 --> 00:23:44,159
trained so

00:23:39,200 --> 00:23:47,840
in this demo i show i showed

00:23:44,159 --> 00:23:50,320
how we deploy a set of air

00:23:47,840 --> 00:23:52,880
how we set up a cluster kubernetes

00:23:50,320 --> 00:23:56,240
kubernetes plus kubernetes cluster

00:23:52,880 --> 00:23:59,760
so i assume the kubernetes class

00:23:56,240 --> 00:24:00,559
already deployed then we have the

00:23:59,760 --> 00:24:04,880
actional

00:24:00,559 --> 00:24:06,640
join the kubernetes cluster even the

00:24:04,880 --> 00:24:08,400
control plane is in running in the

00:24:06,640 --> 00:24:10,960
public cloud the action

00:24:08,400 --> 00:24:12,880
behind firewall we don't have any issues

00:24:10,960 --> 00:24:15,919
and with this websocket

00:24:12,880 --> 00:24:18,480
setup we can it's duplex we can push

00:24:15,919 --> 00:24:22,720
command from the cloud to the edge node

00:24:18,480 --> 00:24:22,720
then we show we deploy a

00:24:22,799 --> 00:24:27,600
application based on test floor to do

00:24:25,679 --> 00:24:31,679
the emotion recognition

00:24:27,600 --> 00:24:33,919
and we use the emulator so

00:24:31,679 --> 00:24:34,960
to emulate a mobile device running in

00:24:33,919 --> 00:24:37,919
the same network

00:24:34,960 --> 00:24:38,799
with the edge server to do the ai of

00:24:37,919 --> 00:24:41,919
loading

00:24:38,799 --> 00:24:44,080
so the emulator the the app

00:24:41,919 --> 00:24:46,159
the mobile app let's do the

00:24:44,080 --> 00:24:47,840
pre-processing the image convert to the

00:24:46,159 --> 00:24:50,799
pixel array

00:24:47,840 --> 00:24:52,480
and send this pixel array to the

00:24:50,799 --> 00:24:54,640
inference service running in the ad

00:24:52,480 --> 00:25:01,840
server to get the result back

00:24:54,640 --> 00:25:01,840
so that's the summary of a demo

00:25:04,880 --> 00:25:12,159
so let's come back to our talk

00:25:09,200 --> 00:25:12,720
so this demo is relatively simple it

00:25:12,159 --> 00:25:15,279
only

00:25:12,720 --> 00:25:16,159
shows the inference the inference of

00:25:15,279 --> 00:25:21,360
loading

00:25:16,159 --> 00:25:21,360
so how about more complicated cases

00:25:22,000 --> 00:25:28,880
so uh we have more challenges so first

00:25:25,760 --> 00:25:30,480
all this edge is geo distributed and

00:25:28,880 --> 00:25:33,520
they have data set

00:25:30,480 --> 00:25:37,440
geo distributed can we take advantage

00:25:33,520 --> 00:25:40,960
i mean to conquer these issues and also

00:25:37,440 --> 00:25:44,159
these samples are not

00:25:40,960 --> 00:25:48,080
universally distributed some node have

00:25:44,159 --> 00:25:48,080
more data some node have less data

00:25:48,240 --> 00:25:54,640
and so and also because of this uh

00:25:52,559 --> 00:25:57,440
non-universal distributed data

00:25:54,640 --> 00:25:58,320
so the performance of a uni universal am

00:25:57,440 --> 00:26:02,080
model is

00:25:58,320 --> 00:26:03,120
degraded on the edge and also the

00:26:02,080 --> 00:26:06,960
resource

00:26:03,120 --> 00:26:08,840
is constrained and edge and when you try

00:26:06,960 --> 00:26:11,120
to run

00:26:08,840 --> 00:26:14,159
some federated learning

00:26:11,120 --> 00:26:16,480
issues and it's

00:26:14,159 --> 00:26:18,240
hard i mean we have few short samples

00:26:16,480 --> 00:26:21,120
it's hard to convert

00:26:18,240 --> 00:26:23,120
so we are thinking so uh with we are

00:26:21,120 --> 00:26:26,559
going to build a

00:26:23,120 --> 00:26:26,880
edge ai framework based on kobe edge to

00:26:26,559 --> 00:26:30,960
see

00:26:26,880 --> 00:26:34,080
if we can help to solve this problem

00:26:30,960 --> 00:26:39,840
here is our design

00:26:34,080 --> 00:26:39,840
the purpose is a we want to

00:26:40,240 --> 00:26:45,520
have a edge cloud collaborated

00:26:43,760 --> 00:26:47,440
machine learning framework based on

00:26:45,520 --> 00:26:50,960
kubat

00:26:47,440 --> 00:26:53,279
with this embedded credit collaborative

00:26:50,960 --> 00:26:55,760
training joint inference algorithm it

00:26:53,279 --> 00:26:59,120
helps the developer to develop

00:26:55,760 --> 00:27:01,520
new algorithms so we are trying to work

00:26:59,120 --> 00:27:03,120
with existing am framework for example

00:27:01,520 --> 00:27:07,039
tensorflow or pytorch

00:27:03,120 --> 00:27:09,600
we are not inventing a new air framework

00:27:07,039 --> 00:27:10,159
so it's have built in three features

00:27:09,600 --> 00:27:12,559
joint

00:27:10,159 --> 00:27:14,559
inference increment learning

00:27:12,559 --> 00:27:17,360
collaborative

00:27:14,559 --> 00:27:18,880
collaborative training is federated

00:27:17,360 --> 00:27:22,080
learning

00:27:18,880 --> 00:27:23,679
so our target user is a domain specific

00:27:22,080 --> 00:27:26,080
air developers

00:27:23,679 --> 00:27:26,880
so they are building and publish edge

00:27:26,080 --> 00:27:29,600
cloud cloud

00:27:26,880 --> 00:27:31,200
collaborated ai service function they

00:27:29,600 --> 00:27:34,640
can do that easily

00:27:31,200 --> 00:27:36,799
and also we are targeting

00:27:34,640 --> 00:27:38,960
the application developers so they can

00:27:36,799 --> 00:27:42,159
use edge cloud

00:27:38,960 --> 00:27:43,120
collaborative ai abili capabilities so

00:27:42,159 --> 00:27:46,399
without

00:27:43,120 --> 00:27:49,039
any learning curves

00:27:46,399 --> 00:27:49,760
so the central part you can see is a

00:27:49,039 --> 00:27:52,880
based on

00:27:49,760 --> 00:27:56,880
the kube edge we build edge cloud

00:27:52,880 --> 00:27:56,880
collaborative machine learning framework

00:27:57,200 --> 00:28:04,640
so it supports heterogeneous hardware

00:28:00,799 --> 00:28:07,039
either s86 arm servers

00:28:04,640 --> 00:28:09,039
and also based on this framework you can

00:28:07,039 --> 00:28:17,279
easily build a computing region

00:28:09,039 --> 00:28:19,360
speech nlp applications

00:28:17,279 --> 00:28:20,720
so architecture you can see uh we

00:28:19,360 --> 00:28:24,080
divided to uh

00:28:20,720 --> 00:28:27,360
cloud and edge on the cloud part

00:28:24,080 --> 00:28:30,480
we are running kubernetes platform so

00:28:27,360 --> 00:28:33,840
they have a worker application running

00:28:30,480 --> 00:28:37,840
and this support tensorflow patch

00:28:33,840 --> 00:28:39,440
we have our sdk libraries there and

00:28:37,840 --> 00:28:40,960
then you can train the model in the

00:28:39,440 --> 00:28:44,480
cloud

00:28:40,960 --> 00:28:45,679
and we have this called a gc is a global

00:28:44,480 --> 00:28:50,000
coordinator to

00:28:45,679 --> 00:28:53,279
coordinate all these uh services

00:28:50,000 --> 00:28:56,720
on the edge we run kubej so

00:28:53,279 --> 00:28:59,440
uh this also have the worker i mean

00:28:56,720 --> 00:29:00,640
communicated with their workers running

00:28:59,440 --> 00:29:03,840
on the cloud

00:29:00,640 --> 00:29:07,279
so it's probably uh instead of a run

00:29:03,840 --> 00:29:10,399
uh training it could run inferencing

00:29:07,279 --> 00:29:13,279
and also uh when you do the

00:29:10,399 --> 00:29:13,840
increment training or collaborative

00:29:13,279 --> 00:29:18,159
training

00:29:13,840 --> 00:29:21,760
you do you run training in the edge too

00:29:18,159 --> 00:29:24,159
so based on the kubernetes you can

00:29:21,760 --> 00:29:27,440
deploy a local resource management

00:29:24,159 --> 00:29:31,440
for the job monitoring management

00:29:27,440 --> 00:29:31,440
and peer management also so

00:29:31,760 --> 00:29:35,440
that's our architecture

00:29:36,640 --> 00:29:40,720
and let's elaborate all three features

00:29:39,120 --> 00:29:43,360
first is

00:29:40,720 --> 00:29:44,880
collaborated join the inference in this

00:29:43,360 --> 00:29:48,960
case you can see uh

00:29:44,880 --> 00:29:51,360
we have a uh as we demoed in the rml

00:29:48,960 --> 00:29:52,159
uploading in the previous demo you can

00:29:51,360 --> 00:29:55,440
see we

00:29:52,159 --> 00:29:58,320
run the inference in the edge however

00:29:55,440 --> 00:30:00,640
the edge could only have

00:29:58,320 --> 00:30:01,440
restrained resources it can outrun

00:30:00,640 --> 00:30:04,960
become more

00:30:01,440 --> 00:30:07,440
very complicated model in this case

00:30:04,960 --> 00:30:08,720
we do this uh collaborative drawing

00:30:07,440 --> 00:30:12,080
inference that means

00:30:08,720 --> 00:30:15,520
in the edge especially in the

00:30:12,080 --> 00:30:18,559
in the low resource edge

00:30:15,520 --> 00:30:21,360
node we run a shallow model

00:30:18,559 --> 00:30:22,000
that means this probably handles 70-80

00:30:21,360 --> 00:30:25,520
percent of

00:30:22,000 --> 00:30:29,520
scenarios if we get a very

00:30:25,520 --> 00:30:32,880
uh confident results back

00:30:29,520 --> 00:30:36,000
uh however if you and

00:30:32,880 --> 00:30:38,720
if the result come back if only a 40 50

00:30:36,000 --> 00:30:40,640
percent of confidence so we cannot tell

00:30:38,720 --> 00:30:43,840
the result back to the user

00:30:40,640 --> 00:30:46,320
so we offload this

00:30:43,840 --> 00:30:47,039
another one to another layer to the

00:30:46,320 --> 00:30:49,679
cloud

00:30:47,039 --> 00:30:50,880
so in the cloud we run a more deeper

00:30:49,679 --> 00:30:54,080
deep model

00:30:50,880 --> 00:30:57,440
just require more computation

00:30:54,080 --> 00:31:00,880
resources so

00:30:57,440 --> 00:31:03,679
that's one is should

00:31:00,880 --> 00:31:04,799
calculate or inference have a better

00:31:03,679 --> 00:31:07,360
result back

00:31:04,799 --> 00:31:09,440
and send this result back to the ad edge

00:31:07,360 --> 00:31:12,240
pass-through to the user

00:31:09,440 --> 00:31:13,440
so all these models is trained by the ai

00:31:12,240 --> 00:31:16,720
developers

00:31:13,440 --> 00:31:20,080
so when you do the training you train

00:31:16,720 --> 00:31:20,720
you generate a deeper model and a shadow

00:31:20,080 --> 00:31:23,039
model

00:31:20,720 --> 00:31:24,640
the deep model is require more

00:31:23,039 --> 00:31:26,960
competitive resource it's

00:31:24,640 --> 00:31:28,080
suitable for running in the cloud and

00:31:26,960 --> 00:31:31,679
the shallow model is

00:31:28,080 --> 00:31:34,880
required only

00:31:31,679 --> 00:31:35,679
a part of this result so it's suitable

00:31:34,880 --> 00:31:40,799
to run on

00:31:35,679 --> 00:31:40,799
edge especially in the low resource edge

00:31:40,960 --> 00:31:47,200
incrementing uh learning

00:31:44,080 --> 00:31:48,080
so in this case so the aid app

00:31:47,200 --> 00:31:51,360
developers

00:31:48,080 --> 00:31:54,159
use this ai library

00:31:51,360 --> 00:31:56,240
so to integrate the collaborating

00:31:54,159 --> 00:31:59,679
increment learning function

00:31:56,240 --> 00:32:03,919
so uh when

00:31:59,679 --> 00:32:06,320
the the sample detect organ in the edge

00:32:03,919 --> 00:32:07,440
identify a sample with a low influence

00:32:06,320 --> 00:32:10,799
confidence

00:32:07,440 --> 00:32:13,840
so in this case similar to the uh

00:32:10,799 --> 00:32:14,880
collaborative inference we upload this

00:32:13,840 --> 00:32:17,679
one to the cloud

00:32:14,880 --> 00:32:19,440
for the labeling service so in the cloud

00:32:17,679 --> 00:32:22,000
is running a

00:32:19,440 --> 00:32:25,120
label services it's manually or

00:32:22,000 --> 00:32:28,000
periodically or with uh

00:32:25,120 --> 00:32:29,039
i mean ai assist we are labeled the

00:32:28,000 --> 00:32:31,760
samples

00:32:29,039 --> 00:32:32,320
so the system automatically performs

00:32:31,760 --> 00:32:34,399
increment

00:32:32,320 --> 00:32:36,640
training is based on the current model

00:32:34,399 --> 00:32:39,120
you train

00:32:36,640 --> 00:32:40,000
and generate a new better model then you

00:32:39,120 --> 00:32:43,360
push this

00:32:40,000 --> 00:32:44,399
model back to the edge so the edge have

00:32:43,360 --> 00:32:47,440
a better model

00:32:44,399 --> 00:32:49,360
so if you get another hard example or

00:32:47,440 --> 00:32:53,279
difficult example you cannot

00:32:49,360 --> 00:32:56,399
achieve a high confidence level you

00:32:53,279 --> 00:32:59,440
upload to the cloud to further labeling

00:32:56,399 --> 00:33:01,440
labeling and to generate an even better

00:32:59,440 --> 00:33:03,440
model so that's called increment

00:33:01,440 --> 00:33:06,240
training that means uh

00:33:03,440 --> 00:33:07,120
you don't have the data set at whole

00:33:06,240 --> 00:33:10,159
data setting

00:33:07,120 --> 00:33:14,399
at the very beginning as you increment

00:33:10,159 --> 00:33:14,399
training your model better and better

00:33:15,039 --> 00:33:18,799
federated learning so

00:33:19,600 --> 00:33:23,760
so this one is especially for the data

00:33:22,320 --> 00:33:26,240
privacy issues

00:33:23,760 --> 00:33:27,039
so the raw data is never transmitted out

00:33:26,240 --> 00:33:29,440
of the edge

00:33:27,039 --> 00:33:30,880
so it's only stayed locally so the model

00:33:29,440 --> 00:33:33,600
is generated

00:33:30,880 --> 00:33:34,000
by the knowledge aggregation so that

00:33:33,600 --> 00:33:37,279
means

00:33:34,000 --> 00:33:41,440
in the edge node we have our local

00:33:37,279 --> 00:33:44,320
i mean data set so that's very uh data

00:33:41,440 --> 00:33:45,919
probably a sensitive data so you never

00:33:44,320 --> 00:33:49,200
transfer to the

00:33:45,919 --> 00:33:53,840
cloud you do your training locally at

00:33:49,200 --> 00:33:57,679
edge node then after you're trained

00:33:53,840 --> 00:33:57,679
you upload this model

00:33:58,240 --> 00:34:04,159
to the cloud then the cloud

00:34:01,279 --> 00:34:05,600
will do a cross ad transforming and

00:34:04,159 --> 00:34:08,720
model aggregation

00:34:05,600 --> 00:34:10,079
so that's our library will provide so do

00:34:08,720 --> 00:34:13,200
the aggregation

00:34:10,079 --> 00:34:13,599
algorithm and then on the cloud after

00:34:13,200 --> 00:34:17,280
that

00:34:13,599 --> 00:34:20,399
you send back your result back to the

00:34:17,280 --> 00:34:24,240
edge to refresh to get a

00:34:20,399 --> 00:34:27,440
more better model back to the edge

00:34:24,240 --> 00:34:31,200
so with this first you save your time

00:34:27,440 --> 00:34:32,960
transfer your time and the bandwidth

00:34:31,200 --> 00:34:36,159
transfer the raw data back to the

00:34:32,960 --> 00:34:38,480
account also

00:34:36,159 --> 00:34:40,079
it's very important for data privacy you

00:34:38,480 --> 00:34:42,000
never transfer your data out of your

00:34:40,079 --> 00:34:44,960
edge you have a confidence you have full

00:34:42,000 --> 00:34:44,960
control of your data

00:34:46,480 --> 00:34:52,960
now let's show is how easy is that so we

00:34:50,399 --> 00:34:53,760
are not as we mentioned we we are not

00:34:52,960 --> 00:34:57,359
targeting

00:34:53,760 --> 00:35:01,280
to invent a a new air framework

00:34:57,359 --> 00:35:04,480
so we are comparing a compatible

00:35:01,280 --> 00:35:08,400
with current ai framework for example

00:35:04,480 --> 00:35:10,960
tensorflow the current example is our

00:35:08,400 --> 00:35:11,920
we use the drawing inference uh based on

00:35:10,960 --> 00:35:14,960
tensorflow

00:35:11,920 --> 00:35:16,560
so you can see the most of the functions

00:35:14,960 --> 00:35:19,440
or

00:35:16,560 --> 00:35:20,400
most of the writing is similar to very

00:35:19,440 --> 00:35:24,560
similar to

00:35:20,400 --> 00:35:27,200
the ai developer used for test floor for

00:35:24,560 --> 00:35:28,000
inferencing the only difference is we

00:35:27,200 --> 00:35:31,520
have our

00:35:28,000 --> 00:35:35,359
include our library and have this

00:35:31,520 --> 00:35:38,880
transfer the cloud algorithm so in case

00:35:35,359 --> 00:35:40,560
your confidence level the confidence

00:35:38,880 --> 00:35:43,200
level

00:35:40,560 --> 00:35:44,079
does not match the goal this automatic

00:35:43,200 --> 00:35:46,640
transfer the cloud

00:35:44,079 --> 00:35:49,119
for the second layer is a drawing

00:35:46,640 --> 00:35:49,119
inference

00:35:49,839 --> 00:35:54,000
so the developer do not need to change

00:35:52,000 --> 00:35:57,119
other part of the code only

00:35:54,000 --> 00:36:00,160
need to uh using our

00:35:57,119 --> 00:36:02,480
sdk to config and generate this azure

00:36:00,160 --> 00:36:02,480
cloud

00:36:04,720 --> 00:36:08,480
join the inference federated learning

00:36:08,160 --> 00:36:10,960
you

00:36:08,480 --> 00:36:12,160
the similar thing you can see we are

00:36:10,960 --> 00:36:15,280
compatible

00:36:12,160 --> 00:36:16,480
with all the style everything you most

00:36:15,280 --> 00:36:19,760
of the code you can

00:36:16,480 --> 00:36:23,680
use the same you don't need to change

00:36:19,760 --> 00:36:25,839
existing code so and also you don't need

00:36:23,680 --> 00:36:27,599
to learn a new framework you uh

00:36:25,839 --> 00:36:29,040
if you are familiar with tensorflow you

00:36:27,599 --> 00:36:31,920
tensorflow if you are

00:36:29,040 --> 00:36:34,560
familiar with python you pad touch so

00:36:31,920 --> 00:36:38,079
there's a no learning curve

00:36:34,560 --> 00:36:39,839
so uh to use this the library you only

00:36:38,079 --> 00:36:44,320
need to uh

00:36:39,839 --> 00:36:44,320
import our library and then

00:36:44,560 --> 00:36:49,599
use the training loss function optimizer

00:36:47,119 --> 00:36:52,560
and the collaborative training function

00:36:49,599 --> 00:36:53,760
from the library then you can achieve

00:36:52,560 --> 00:36:56,480
federated learning

00:36:53,760 --> 00:36:56,480
very easily

00:36:57,280 --> 00:37:04,240
so uh let me conclude my presentation

00:37:01,119 --> 00:37:07,520
so in this in this

00:37:04,240 --> 00:37:10,720
talk i talk about mainly uh talk about

00:37:07,520 --> 00:37:12,480
how we build the edge ai framework so

00:37:10,720 --> 00:37:13,760
this framework is based on the coupe

00:37:12,480 --> 00:37:17,200
edge so

00:37:13,760 --> 00:37:20,240
first the coupe edge is a cncf

00:37:17,200 --> 00:37:23,760
incubation project

00:37:20,240 --> 00:37:26,960
so here i list the project website

00:37:23,760 --> 00:37:30,240
and also the code repository is

00:37:26,960 --> 00:37:33,280
public to github the slack channel

00:37:30,240 --> 00:37:34,880
mailing list and all the meeting

00:37:33,280 --> 00:37:39,040
community meetings are recorded

00:37:34,880 --> 00:37:39,040
uploaded to the youtube you can

00:37:39,200 --> 00:37:43,119
take a look if you miss any meetings you

00:37:41,680 --> 00:37:44,400
are in you are interested in any

00:37:43,119 --> 00:37:46,720
meetings

00:37:44,400 --> 00:37:47,920
and and the meeting knows is the host in

00:37:46,720 --> 00:37:50,960
the google doc

00:37:47,920 --> 00:37:52,880
it's public to everybody

00:37:50,960 --> 00:37:55,040
so here is the link to the meeting

00:37:52,880 --> 00:37:58,079
calendars so it's host

00:37:55,040 --> 00:38:01,680
in in the night

00:37:58,079 --> 00:38:03,839
there's a every week one uh

00:38:01,680 --> 00:38:04,720
one week is suitable for the united

00:38:03,839 --> 00:38:07,119
states people

00:38:04,720 --> 00:38:08,560
north american people attend the other

00:38:07,119 --> 00:38:11,839
is more friendly to

00:38:08,560 --> 00:38:13,760
the european people your people

00:38:11,839 --> 00:38:16,240
so you can see the meeting calendar with

00:38:13,760 --> 00:38:19,359
some link and here is the

00:38:16,240 --> 00:38:22,720
zoom meeting id

00:38:19,359 --> 00:38:26,160
another uh project i mentioned

00:38:22,720 --> 00:38:29,599
is the uh lf edge krino kuba

00:38:26,160 --> 00:38:33,280
service blueprint so

00:38:29,599 --> 00:38:36,800
instead of a project website

00:38:33,280 --> 00:38:39,280
is the public akrino wiki site

00:38:36,800 --> 00:38:40,240
it's have a everything including a

00:38:39,280 --> 00:38:42,880
document

00:38:40,240 --> 00:38:44,000
and also the ai frame edge ai framework

00:38:42,880 --> 00:38:47,280
i mentioned

00:38:44,000 --> 00:38:50,320
all this diagram and all the service

00:38:47,280 --> 00:38:53,119
samples is hosted in this

00:38:50,320 --> 00:38:54,960
wiki page so you can go there and take a

00:38:53,119 --> 00:38:57,760
look at the document

00:38:54,960 --> 00:38:58,320
and also we have a weekly meeting so it

00:38:57,760 --> 00:39:02,640
happened

00:38:58,320 --> 00:39:06,079
in the 1900 pacific standard time

00:39:02,640 --> 00:39:06,960
here is the zoom link and also there's a

00:39:06,079 --> 00:39:09,680
slack channel

00:39:06,960 --> 00:39:11,440
so if you have anything you can chime in

00:39:09,680 --> 00:39:12,560
and jump to the slack channel to ask

00:39:11,440 --> 00:39:16,560
questions

00:39:12,560 --> 00:39:17,440
so both uh linux foundation area one is

00:39:16,560 --> 00:39:20,000
the cncf

00:39:17,440 --> 00:39:21,119
and both are lining foundation uh open

00:39:20,000 --> 00:39:24,320
source project

00:39:21,119 --> 00:39:24,800
so both are welcome to everyone to join

00:39:24,320 --> 00:39:28,720
and

00:39:24,800 --> 00:39:31,839
chime in so

00:39:28,720 --> 00:39:34,560
thank you this concludes my talk i

00:39:31,839 --> 00:39:35,680
leave about about eight minutes for the

00:39:34,560 --> 00:39:43,280
questions

00:39:35,680 --> 00:39:43,280

YouTube URL: https://www.youtube.com/watch?v=XwknNmYMx-Q


