Title: Acceleration Techniques of Image Preprocessing and Their Effect for Machine Learning System
Publication date: 2020-12-03
Playlist: Open Source Summit Japan & Automotive Linux Summit 2020
Description: 
	Acceleration Techniques of Image Preprocessing and Their Effect for Machine Learning System - Kyosuke Hashimoto & Masahiro Ito, Hitachi, Ltd.
Captions: 
	00:00:05,520 --> 00:00:08,480
hi

00:00:05,920 --> 00:00:10,240
thanks for coming to our session today

00:00:08,480 --> 00:00:12,559
we are going to talk about

00:00:10,240 --> 00:00:13,679
acceleration techniques of image

00:00:12,559 --> 00:00:15,440
pre-processing

00:00:13,679 --> 00:00:17,279
and the effect for machine learning

00:00:15,440 --> 00:00:19,920
system

00:00:17,279 --> 00:00:21,439
before beginning our talk please let us

00:00:19,920 --> 00:00:24,160
introduce ourselves

00:00:21,439 --> 00:00:24,800
i'm kyosuke hashimoto and i'm research

00:00:24,160 --> 00:00:28,000
engineer

00:00:24,800 --> 00:00:30,800
at hitachi and my current interest is

00:00:28,000 --> 00:00:32,719
developing ai solutions with open source

00:00:30,800 --> 00:00:35,520
software such as qflow

00:00:32,719 --> 00:00:38,559
and public cloud such as aws and

00:00:35,520 --> 00:00:42,160
microsoft azure

00:00:38,559 --> 00:00:45,600
hi i'm masahiro ito i work at the

00:00:42,160 --> 00:00:48,160
heather team as a software engineer

00:00:45,600 --> 00:00:49,360
are responsible for levitating open

00:00:48,160 --> 00:00:53,280
source software

00:00:49,360 --> 00:00:56,239
with to big data and ai

00:00:53,280 --> 00:00:57,360
i'm developing big data and ai solutions

00:00:56,239 --> 00:00:59,199
for customers

00:00:57,360 --> 00:01:01,359
who are going to build enterprise

00:00:59,199 --> 00:01:03,920
systems

00:01:01,359 --> 00:01:05,360
i've been developing data lakes on the

00:01:03,920 --> 00:01:08,799
data pipelines

00:01:05,360 --> 00:01:12,000
using apache hadoop spark hdbs

00:01:08,799 --> 00:01:15,119
kafka and more

00:01:12,000 --> 00:01:16,080
now i'm focusing on developing ml of

00:01:15,119 --> 00:01:19,280
solutions

00:01:16,080 --> 00:01:19,280
using qubit flow

00:01:21,280 --> 00:01:29,600
okay this is the outline of our talk

00:01:25,840 --> 00:01:32,560
our presentation is in five parts

00:01:29,600 --> 00:01:33,119
first we will introduce our business and

00:01:32,560 --> 00:01:35,840
why we

00:01:33,119 --> 00:01:37,759
focus on image preprocessing with deep

00:01:35,840 --> 00:01:40,320
learning

00:01:37,759 --> 00:01:41,759
next we would like to talk about the

00:01:40,320 --> 00:01:45,040
evaluation scenario

00:01:41,759 --> 00:01:48,240
of image preprocessing

00:01:45,040 --> 00:01:52,560
in part 3 and part 4 we will

00:01:48,240 --> 00:01:55,200
introduce our evaluation results

00:01:52,560 --> 00:01:57,759
finally we will give some discussion

00:01:55,200 --> 00:02:00,479
about the evaluation results

00:01:57,759 --> 00:02:02,960
and give a brief summary of what we have

00:02:00,479 --> 00:02:02,960
covered

00:02:04,560 --> 00:02:09,840
okay let's move on to the introduction

00:02:10,479 --> 00:02:15,760
to begin with i'm going to talk about

00:02:13,360 --> 00:02:17,360
our motivations to focus on deep

00:02:15,760 --> 00:02:20,160
learning

00:02:17,360 --> 00:02:21,200
deep learning technology is vitally used

00:02:20,160 --> 00:02:24,239
for processing

00:02:21,200 --> 00:02:28,560
various data such as image

00:02:24,239 --> 00:02:29,440
text and audio these data processing

00:02:28,560 --> 00:02:32,480
technologies

00:02:29,440 --> 00:02:35,440
are applied in various industries

00:02:32,480 --> 00:02:36,959
such as healthcare manufacturing

00:02:35,440 --> 00:02:40,560
security

00:02:36,959 --> 00:02:43,120
and automotive our company

00:02:40,560 --> 00:02:44,000
hitachi has a lot of products on the

00:02:43,120 --> 00:02:47,440
services

00:02:44,000 --> 00:02:50,720
in these industries

00:02:47,440 --> 00:02:53,200
image processing is especially used in

00:02:50,720 --> 00:02:56,640
such industries

00:02:53,200 --> 00:02:57,200
for example image processing is applied

00:02:56,640 --> 00:02:59,920
to

00:02:57,200 --> 00:03:01,280
medical image analysis action

00:02:59,920 --> 00:03:06,159
recognition

00:03:01,280 --> 00:03:06,159
biometrics and the self-driving cars

00:03:07,760 --> 00:03:11,360
let's talk about production machine

00:03:10,080 --> 00:03:14,959
learning systems

00:03:11,360 --> 00:03:15,519
with deep learning production machine

00:03:14,959 --> 00:03:18,640
learning

00:03:15,519 --> 00:03:22,640
system contains various components

00:03:18,640 --> 00:03:26,480
such as data processing model training

00:03:22,640 --> 00:03:29,680
serving and model monitoring

00:03:26,480 --> 00:03:30,000
so model training with deep learning is

00:03:29,680 --> 00:03:33,200
just

00:03:30,000 --> 00:03:36,640
a single part in

00:03:33,200 --> 00:03:38,720
these parts data preprocessing is an

00:03:36,640 --> 00:03:41,040
important part of the machine learning

00:03:38,720 --> 00:03:44,080
system

00:03:41,040 --> 00:03:48,400
data purpose system is required in both

00:03:44,080 --> 00:03:48,400
model training and serving phase

00:03:48,560 --> 00:03:52,000
these figures shows a data processing

00:03:51,040 --> 00:03:55,760
flow during

00:03:52,000 --> 00:03:55,760
training and solving phases

00:03:55,920 --> 00:04:00,000
in the training phase data scientists

00:03:58,560 --> 00:04:03,599
create a machine learning

00:04:00,000 --> 00:04:06,560
model in this phase

00:04:03,599 --> 00:04:08,720
data scientists exact features from raw

00:04:06,560 --> 00:04:11,040
data

00:04:08,720 --> 00:04:12,000
data scientists developed this data

00:04:11,040 --> 00:04:15,760
pre-processing

00:04:12,000 --> 00:04:18,880
logic by feature engineering

00:04:15,760 --> 00:04:21,440
the extracted features are used to train

00:04:18,880 --> 00:04:21,440
models

00:04:21,519 --> 00:04:27,360
by speed up data pre-processing data

00:04:24,720 --> 00:04:28,240
scientists can perform more experiments

00:04:27,360 --> 00:04:31,040
to improve

00:04:28,240 --> 00:04:31,040
their models

00:04:31,360 --> 00:04:35,680
in the serving phase machine learning

00:04:34,320 --> 00:04:38,479
system provides

00:04:35,680 --> 00:04:42,320
predictions using a trained model in a

00:04:38,479 --> 00:04:45,600
production environment in

00:04:42,320 --> 00:04:46,800
this phase the model the model requires

00:04:45,600 --> 00:04:50,720
the same format

00:04:46,800 --> 00:04:53,600
of input data during training

00:04:50,720 --> 00:04:55,199
so we need to deploy the same data

00:04:53,600 --> 00:04:58,639
pre-processing logic

00:04:55,199 --> 00:04:58,639
as in the training phase

00:04:59,520 --> 00:05:03,360
therefore speed up data pre-processing

00:05:02,560 --> 00:05:07,919
can reduce

00:05:03,360 --> 00:05:10,639
both experimental and infants time

00:05:07,919 --> 00:05:13,600
that's why we focus on speed up data

00:05:10,639 --> 00:05:13,600
pre-processing

00:05:15,280 --> 00:05:19,360
i'd like to talk about open source deep

00:05:17,919 --> 00:05:23,280
learning frameworks

00:05:19,360 --> 00:05:25,680
and data processing libraries

00:05:23,280 --> 00:05:28,080
there is a lot of open source software

00:05:25,680 --> 00:05:30,479
in this category

00:05:28,080 --> 00:05:31,199
the lower left graph shows the popular

00:05:30,479 --> 00:05:34,479
frameworks

00:05:31,199 --> 00:05:37,759
and libraries as

00:05:34,479 --> 00:05:39,520
you can see tensorflow and python have

00:05:37,759 --> 00:05:42,000
become very popular developing

00:05:39,520 --> 00:05:44,880
frameworks

00:05:42,000 --> 00:05:45,360
python has image preprocessing library

00:05:44,880 --> 00:05:48,880
named

00:05:45,360 --> 00:05:51,199
touch vision opencv

00:05:48,880 --> 00:05:54,160
is a popular computer vision and machine

00:05:51,199 --> 00:05:54,160
learning library

00:05:54,560 --> 00:06:00,560
so opencp is often used for imaginable

00:05:57,840 --> 00:06:00,560
processing

00:06:01,039 --> 00:06:07,840
in this presentation we focus on

00:06:04,000 --> 00:06:07,840
television and open safety

00:06:09,039 --> 00:06:12,800
i'll explain the evaluation outline for

00:06:11,840 --> 00:06:17,360
touch vision

00:06:12,800 --> 00:06:19,199
and opencv for imaginable processing

00:06:17,360 --> 00:06:20,800
in order to speed up imaginable

00:06:19,199 --> 00:06:23,600
preprocessing

00:06:20,800 --> 00:06:25,120
we applied acceleration techniques for

00:06:23,600 --> 00:06:28,960
these libraries

00:06:25,120 --> 00:06:31,520
and evaluated their effects

00:06:28,960 --> 00:06:32,319
we compared performance between touch

00:06:31,520 --> 00:06:35,520
vision and

00:06:32,319 --> 00:06:36,400
opencv using acceleration techniques in

00:06:35,520 --> 00:06:40,800
solving and

00:06:36,400 --> 00:06:43,520
training phase in the surfing phase

00:06:40,800 --> 00:06:46,639
we evaluated the performance of image

00:06:43,520 --> 00:06:46,639
processing only

00:06:46,960 --> 00:06:52,080
this evaluation does not include

00:06:49,120 --> 00:06:54,319
influence by model

00:06:52,080 --> 00:06:55,840
firstly we check the baseline

00:06:54,319 --> 00:06:58,479
performance

00:06:55,840 --> 00:07:00,240
then we evaluate the performance of

00:06:58,479 --> 00:07:04,000
imageable processing when

00:07:00,240 --> 00:07:04,000
applying acceleration techniques

00:07:04,240 --> 00:07:07,759
in the training phase we evaluated to

00:07:07,120 --> 00:07:10,639
combine

00:07:07,759 --> 00:07:13,199
performance of data processing and model

00:07:10,639 --> 00:07:13,199
training

00:07:13,680 --> 00:07:18,160
next we are going to explain our

00:07:15,680 --> 00:07:20,400
evaluation scenario

00:07:18,160 --> 00:07:21,919
in order to evaluate the pre-processing

00:07:20,400 --> 00:07:25,199
performance in general

00:07:21,919 --> 00:07:27,840
we needed to find a good sample scenario

00:07:25,199 --> 00:07:29,840
we thought that evaluation scenario for

00:07:27,840 --> 00:07:32,400
deep learning's application

00:07:29,840 --> 00:07:33,199
should cover general image processing

00:07:32,400 --> 00:07:36,240
techniques

00:07:33,199 --> 00:07:38,880
as we have shown on the left table

00:07:36,240 --> 00:07:40,080
left in the left table we have shown the

00:07:38,880 --> 00:07:42,319
classification

00:07:40,080 --> 00:07:43,680
and examples of image preprocessing

00:07:42,319 --> 00:07:46,319
techniques

00:07:43,680 --> 00:07:46,960
we can classify the pre-processing

00:07:46,319 --> 00:07:50,160
techniques

00:07:46,960 --> 00:07:52,720
in three class class one of them is

00:07:50,160 --> 00:07:55,120
emphasizing valuable features

00:07:52,720 --> 00:07:56,720
and second one is removing noise from

00:07:55,120 --> 00:08:00,800
value-less features

00:07:56,720 --> 00:08:03,840
and third one is automatic features

00:08:00,800 --> 00:08:05,759
and we have chosen mlperv for

00:08:03,840 --> 00:08:07,120
evaluating deep learning system

00:08:05,759 --> 00:08:10,000
performance

00:08:07,120 --> 00:08:11,360
ml perf is a benchmarking project for

00:08:10,000 --> 00:08:14,479
machine learning system

00:08:11,360 --> 00:08:16,960
that is presented in 2018

00:08:14,479 --> 00:08:18,720
and both cloud enterprises such as

00:08:16,960 --> 00:08:20,960
google and microsoft

00:08:18,720 --> 00:08:22,800
and also hardware industries such as

00:08:20,960 --> 00:08:27,199
intel and nvidia

00:08:22,800 --> 00:08:30,000
joins the project

00:08:27,199 --> 00:08:30,800
we selected object detection provided by

00:08:30,000 --> 00:08:34,080
ml perf

00:08:30,800 --> 00:08:34,640
as an evaluation scenario please look at

00:08:34,080 --> 00:08:38,399
the left

00:08:34,640 --> 00:08:39,599
table ml perf covers the general deep

00:08:38,399 --> 00:08:42,880
learning techniques

00:08:39,599 --> 00:08:46,000
as we have shown in the table and why we

00:08:42,880 --> 00:08:48,080
selected objective detection is that

00:08:46,000 --> 00:08:49,040
it covers general pre-processing

00:08:48,080 --> 00:08:52,560
techniques

00:08:49,040 --> 00:08:54,800
and also it is widely used in various

00:08:52,560 --> 00:08:58,560
areas such as autonomous driving

00:08:54,800 --> 00:09:02,240
and cancer detection please look at the

00:08:58,560 --> 00:09:04,320
right figure it indicates the image

00:09:02,240 --> 00:09:05,680
pre-processing needed for object

00:09:04,320 --> 00:09:09,279
detection

00:09:05,680 --> 00:09:12,080
as you can see in the figure it covers

00:09:09,279 --> 00:09:13,279
all classifications of general image

00:09:12,080 --> 00:09:16,800
pre-processing

00:09:13,279 --> 00:09:20,160
such as emphasizing augmenting

00:09:16,800 --> 00:09:23,360
images and deleting some

00:09:20,160 --> 00:09:26,480
unused features as we have showed

00:09:23,360 --> 00:09:28,959
in the previous slide

00:09:26,480 --> 00:09:30,080
now we are going to explain how we

00:09:28,959 --> 00:09:32,160
evaluated

00:09:30,080 --> 00:09:33,360
the effect of accelerating

00:09:32,160 --> 00:09:36,959
pre-processing

00:09:33,360 --> 00:09:39,600
in serving phase we assumed

00:09:36,959 --> 00:09:41,680
that we needed to process as much images

00:09:39,600 --> 00:09:44,240
as possible in production

00:09:41,680 --> 00:09:45,920
we used this hardware and software for

00:09:44,240 --> 00:09:48,880
the evaluation

00:09:45,920 --> 00:09:50,160
please look at the left top table this

00:09:48,880 --> 00:09:53,040
is the evaluation

00:09:50,160 --> 00:09:56,320
environment we have used we used the

00:09:53,040 --> 00:09:58,720
machine which has multi-cpu cores

00:09:56,320 --> 00:09:59,760
next please look at the left bottom

00:09:58,720 --> 00:10:02,720
table

00:09:59,760 --> 00:10:04,079
this is the parameter set we change the

00:10:02,720 --> 00:10:07,360
number of processes

00:10:04,079 --> 00:10:10,079
from 1 to 20 to observe the effect of

00:10:07,360 --> 00:10:12,959
parallelism in production

00:10:10,079 --> 00:10:16,560
also we iterated the pre-processing by

00:10:12,959 --> 00:10:16,560
1000 times this time

00:10:16,640 --> 00:10:23,120
finally please look at the right table

00:10:19,920 --> 00:10:25,360
this is a software specification we

00:10:23,120 --> 00:10:27,760
selected open source softwares

00:10:25,360 --> 00:10:30,160
and versions as we have shown in this

00:10:27,760 --> 00:10:32,480
table

00:10:30,160 --> 00:10:33,600
this figure indicates the overall

00:10:32,480 --> 00:10:36,720
processes we

00:10:33,600 --> 00:10:38,160
evaluated we compared the performance

00:10:36,720 --> 00:10:41,839
between torch vision

00:10:38,160 --> 00:10:44,560
and opencv using acceleration techniques

00:10:41,839 --> 00:10:45,200
our evaluation scope included reading

00:10:44,560 --> 00:10:47,839
files

00:10:45,200 --> 00:10:49,360
pre-processing files and writing image

00:10:47,839 --> 00:10:51,600
files

00:10:49,360 --> 00:10:52,800
to begin with we applied parallel

00:10:51,600 --> 00:10:56,880
religion as an

00:10:52,800 --> 00:10:59,760
acceleration technique we compared the

00:10:56,880 --> 00:11:02,160
processing time and average cpu usage

00:10:59,760 --> 00:11:02,399
during pre-processing with torque vision

00:11:02,160 --> 00:11:05,839
and

00:11:02,399 --> 00:11:06,480
opencv we could increase the number of

00:11:05,839 --> 00:11:10,079
process

00:11:06,480 --> 00:11:12,560
by inputting arguments on ml perf codes

00:11:10,079 --> 00:11:13,600
please look at the left figure it

00:11:12,560 --> 00:11:17,120
indicates the

00:11:13,600 --> 00:11:20,079
processing time x-axis represents

00:11:17,120 --> 00:11:21,279
the number of processes as you can see

00:11:20,079 --> 00:11:23,680
in the figure

00:11:21,279 --> 00:11:26,640
pre-processing time was reduced by

00:11:23,680 --> 00:11:31,040
increasing the number of processes

00:11:26,640 --> 00:11:35,200
please look at the next light figure

00:11:31,040 --> 00:11:37,440
it indicates the average cpu usage

00:11:35,200 --> 00:11:38,880
x-axis represents the number of

00:11:37,440 --> 00:11:42,480
processes

00:11:38,880 --> 00:11:45,279
as you can see in this figure cpu usage

00:11:42,480 --> 00:11:46,079
of opencv was much higher than touch

00:11:45,279 --> 00:11:50,480
vision

00:11:46,079 --> 00:11:52,800
and also it increased almost 100 percent

00:11:50,480 --> 00:11:53,600
when we increased the number of

00:11:52,800 --> 00:11:57,040
processes

00:11:53,600 --> 00:11:59,600
by full

00:11:57,040 --> 00:12:00,639
next we compare the total time of

00:11:59,600 --> 00:12:03,040
preprocessing

00:12:00,639 --> 00:12:04,560
and file output with torque vision and

00:12:03,040 --> 00:12:07,279
opencv

00:12:04,560 --> 00:12:08,959
please look at the left figure it

00:12:07,279 --> 00:12:12,480
indicates the total time

00:12:08,959 --> 00:12:15,040
of pre-processing and output files

00:12:12,480 --> 00:12:16,000
as you can see in the figure total time

00:12:15,040 --> 00:12:18,480
stayed steady

00:12:16,000 --> 00:12:20,959
even if we increased the number of

00:12:18,480 --> 00:12:20,959
process

00:12:21,040 --> 00:12:25,200
also we compared the average cpu usage

00:12:23,920 --> 00:12:28,399
during pre-processing

00:12:25,200 --> 00:12:29,440
and file output please look at the right

00:12:28,399 --> 00:12:33,839
figure

00:12:29,440 --> 00:12:35,920
it indicates the average cpu usage

00:12:33,839 --> 00:12:37,200
x-axis represents the number of

00:12:35,920 --> 00:12:40,079
processes

00:12:37,200 --> 00:12:43,519
and as you can see in the picture cpu

00:12:40,079 --> 00:12:47,120
usage state approximately eighty percent

00:12:43,519 --> 00:12:49,760
when it comes to opencv that means

00:12:47,120 --> 00:12:50,639
that we cannot make the most of cpu

00:12:49,760 --> 00:12:55,360
usage

00:12:50,639 --> 00:12:58,639
after we added outputting files

00:12:55,360 --> 00:12:59,440
now let us discuss why parallelism did

00:12:58,639 --> 00:13:02,320
not improve

00:12:59,440 --> 00:13:03,519
overall performance after we added file

00:13:02,320 --> 00:13:05,839
output

00:13:03,519 --> 00:13:07,360
as you see in this figure after

00:13:05,839 --> 00:13:10,320
finishing pre-processing

00:13:07,360 --> 00:13:12,800
in every single thread pre-processed

00:13:10,320 --> 00:13:15,120
images are stored in result queue

00:13:12,800 --> 00:13:16,399
and waiting for the next file output

00:13:15,120 --> 00:13:19,200
procedure

00:13:16,399 --> 00:13:21,120
in this architecture however file output

00:13:19,200 --> 00:13:24,399
is high loaded procedure

00:13:21,120 --> 00:13:26,560
and takes much time than pre-processing

00:13:24,399 --> 00:13:28,639
then the result queue is full and

00:13:26,560 --> 00:13:31,120
degrades the third point

00:13:28,639 --> 00:13:32,560
thus we decided to increase the number

00:13:31,120 --> 00:13:36,079
of result kills

00:13:32,560 --> 00:13:38,800
and observed the performance

00:13:36,079 --> 00:13:40,480
we increased the number of result queues

00:13:38,800 --> 00:13:41,600
which is equal to the number of

00:13:40,480 --> 00:13:44,399
processes

00:13:41,600 --> 00:13:44,720
made output filed procedure in parallel

00:13:44,399 --> 00:13:46,480
and

00:13:44,720 --> 00:13:48,000
compared the total time of

00:13:46,480 --> 00:13:51,199
pre-processing and file

00:13:48,000 --> 00:13:52,480
output by both prototyping and opencv

00:13:51,199 --> 00:13:54,959
case

00:13:52,480 --> 00:13:55,680
please look at the left figure it

00:13:54,959 --> 00:13:58,079
indicates

00:13:55,680 --> 00:14:00,720
the total time of pre-processing and

00:13:58,079 --> 00:14:01,760
output files by increasing the number of

00:14:00,720 --> 00:14:04,639
queues

00:14:01,760 --> 00:14:05,199
x-axis represents the number of result

00:14:04,639 --> 00:14:08,480
queues

00:14:05,199 --> 00:14:11,199
which is equal to the number of process

00:14:08,480 --> 00:14:12,160
as you can see in this figure total time

00:14:11,199 --> 00:14:15,519
was reduced

00:14:12,160 --> 00:14:18,399
in both 3rd division and opencv case

00:14:15,519 --> 00:14:20,079
by increasing the number of queues to

00:14:18,399 --> 00:14:23,199
output files

00:14:20,079 --> 00:14:26,720
please look at the right figure

00:14:23,199 --> 00:14:27,120
it indicates the comparison of total

00:14:26,720 --> 00:14:29,120
time

00:14:27,120 --> 00:14:31,199
when we change the number of result

00:14:29,120 --> 00:14:34,240
queues from 1 to 10

00:14:31,199 --> 00:14:36,880
and also pre-processing only

00:14:34,240 --> 00:14:38,639
please note that the number process is

00:14:36,880 --> 00:14:41,199
10 this time

00:14:38,639 --> 00:14:43,360
as you can see in this figure by

00:14:41,199 --> 00:14:46,720
increasing the number of result queues

00:14:43,360 --> 00:14:50,320
the total time became closed to the time

00:14:46,720 --> 00:14:50,320
we did pre-processing only

00:14:50,480 --> 00:14:55,360
next we compare the cpu usage after

00:14:53,360 --> 00:14:58,639
increasing the number of result queues

00:14:55,360 --> 00:14:59,519
respectively please look at the left

00:14:58,639 --> 00:15:02,639
figure

00:14:59,519 --> 00:15:04,880
it indicates the average cp usage of

00:15:02,639 --> 00:15:07,440
pre-processing and output files

00:15:04,880 --> 00:15:08,320
by increasing the number of queues

00:15:07,440 --> 00:15:11,120
x-axis

00:15:08,320 --> 00:15:12,720
represents the number of result queues

00:15:11,120 --> 00:15:16,079
which is equal to the number

00:15:12,720 --> 00:15:18,800
process as you can see in this figure

00:15:16,079 --> 00:15:20,880
in turn division case cpu usage

00:15:18,800 --> 00:15:21,360
increased by increasing the number of

00:15:20,880 --> 00:15:24,560
queues

00:15:21,360 --> 00:15:26,160
while file output on the other hand in

00:15:24,560 --> 00:15:28,880
opencv case

00:15:26,160 --> 00:15:29,519
cpu usage stayed approximately 100

00:15:28,880 --> 00:15:31,519
percent

00:15:29,519 --> 00:15:33,279
by increasing the number of queues for

00:15:31,519 --> 00:15:36,240
file output

00:15:33,279 --> 00:15:37,120
these trends appeared when we compared

00:15:36,240 --> 00:15:39,839
the average

00:15:37,120 --> 00:15:40,240
of cpu usage after increasing the number

00:15:39,839 --> 00:15:43,279
of

00:15:40,240 --> 00:15:46,560
result kills and pre-processing only

00:15:43,279 --> 00:15:48,720
in both case cpu usage became close

00:15:46,560 --> 00:15:50,079
by increasing the number of queues for

00:15:48,720 --> 00:15:53,120
file output

00:15:50,079 --> 00:15:56,880
but in opencv case when

00:15:53,120 --> 00:15:59,519
the number of process is 10 cpu usage up

00:15:56,880 --> 00:16:02,399
reached approximately 100

00:15:59,519 --> 00:16:04,000
which implies that even if we increase

00:16:02,399 --> 00:16:06,720
the number of result queues

00:16:04,000 --> 00:16:09,040
and the number process we could make the

00:16:06,720 --> 00:16:11,199
most of cpue resources

00:16:09,040 --> 00:16:12,320
and total time might not improve that

00:16:11,199 --> 00:16:15,199
much

00:16:12,320 --> 00:16:16,240
thus we can say that we should apply

00:16:15,199 --> 00:16:18,880
total vision

00:16:16,240 --> 00:16:20,720
in pre-processing where we can increase

00:16:18,880 --> 00:16:22,800
as much processes

00:16:20,720 --> 00:16:24,720
on the other hand when the number of

00:16:22,800 --> 00:16:28,399
process is limited

00:16:24,720 --> 00:16:28,399
we should apply opencv

00:16:29,120 --> 00:16:32,720
next we are going to evaluate the effect

00:16:31,519 --> 00:16:36,639
of accelerating

00:16:32,720 --> 00:16:39,279
processing in training fades

00:16:36,639 --> 00:16:40,560
in training phase we assumed that the

00:16:39,279 --> 00:16:42,720
data scientists

00:16:40,560 --> 00:16:44,320
often use high performance computer

00:16:42,720 --> 00:16:47,279
which held multi-core

00:16:44,320 --> 00:16:48,240
cpus and gpus for pre-processing and

00:16:47,279 --> 00:16:50,800
training

00:16:48,240 --> 00:16:52,800
we used this hardware and software for

00:16:50,800 --> 00:16:56,399
the evaluation

00:16:52,800 --> 00:16:59,360
we adopted ubuntu this time since

00:16:56,399 --> 00:17:00,800
it's better for utilizing latest open

00:16:59,360 --> 00:17:03,360
soft software

00:17:00,800 --> 00:17:06,160
and also please note that we change the

00:17:03,360 --> 00:17:08,880
number of processes from 1 to 12

00:17:06,160 --> 00:17:10,400
which is the same number of cpu cores

00:17:08,880 --> 00:17:14,160
and we can expect

00:17:10,400 --> 00:17:15,360
the best processing time the software

00:17:14,160 --> 00:17:18,880
specification

00:17:15,360 --> 00:17:21,760
are shown in the right table

00:17:18,880 --> 00:17:23,360
this figure shows the evaluation scope

00:17:21,760 --> 00:17:25,679
in training phase

00:17:23,360 --> 00:17:28,079
we compare the performance in a

00:17:25,679 --> 00:17:30,000
combination of data pre-processing and

00:17:28,079 --> 00:17:33,280
modular planning

00:17:30,000 --> 00:17:37,520
in data pre-processing library we

00:17:33,280 --> 00:17:40,320
used tortivision and opencv in cpu mode

00:17:37,520 --> 00:17:41,360
and model training framework we adopted

00:17:40,320 --> 00:17:45,360
pytorch

00:17:41,360 --> 00:17:48,559
in gpu mode and our evaluation scope

00:17:45,360 --> 00:17:49,520
includes reading files pre-processing

00:17:48,559 --> 00:17:52,960
images

00:17:49,520 --> 00:17:55,360
and also training models

00:17:52,960 --> 00:17:58,000
we compare the total time and resource

00:17:55,360 --> 00:17:58,559
usage of pre-processing on cpu in

00:17:58,000 --> 00:18:01,120
parallel

00:17:58,559 --> 00:18:02,880
and training on gpu with torque division

00:18:01,120 --> 00:18:05,840
and opencv

00:18:02,880 --> 00:18:07,600
please look at the left figure it

00:18:05,840 --> 00:18:10,320
indicates the total time

00:18:07,600 --> 00:18:11,600
of pre-processing on cpu and training on

00:18:10,320 --> 00:18:15,280
gpu

00:18:11,600 --> 00:18:17,919
please note that the number of gpu is 1.

00:18:15,280 --> 00:18:18,960
as you can see in this figure total time

00:18:17,919 --> 00:18:21,360
stays steady

00:18:18,960 --> 00:18:23,200
even if we increase the number process

00:18:21,360 --> 00:18:25,679
from 1 to 12

00:18:23,200 --> 00:18:27,760
we can explain why the trend happens

00:18:25,679 --> 00:18:30,960
when we observe the resource usage

00:18:27,760 --> 00:18:33,200
in the right video this right figure

00:18:30,960 --> 00:18:35,039
indicates the resource usage of

00:18:33,200 --> 00:18:38,080
pre-processing on cpu

00:18:35,039 --> 00:18:39,200
and training on gpu as you can see in

00:18:38,080 --> 00:18:42,000
this figure

00:18:39,200 --> 00:18:45,360
gpu usage for training was much higher

00:18:42,000 --> 00:18:48,000
than the cpu usage for pre-processing

00:18:45,360 --> 00:18:49,760
thus we can say that the effect of

00:18:48,000 --> 00:18:52,320
acceleration of pre-process

00:18:49,760 --> 00:18:55,440
was weak since training took much time

00:18:52,320 --> 00:18:55,440
than pre-processing

00:18:55,520 --> 00:18:58,960
in order to improve the vault

00:18:57,039 --> 00:19:01,200
performance in this case

00:18:58,960 --> 00:19:02,080
we increased the number of gpu for

00:19:01,200 --> 00:19:04,320
training

00:19:02,080 --> 00:19:06,160
and observed the total time of

00:19:04,320 --> 00:19:09,600
pre-processing and training

00:19:06,160 --> 00:19:11,120
with author division and opencv please

00:19:09,600 --> 00:19:13,280
look at the figure

00:19:11,120 --> 00:19:15,039
it indicates the total time of

00:19:13,280 --> 00:19:18,400
pre-processing on cpu

00:19:15,039 --> 00:19:20,400
and training on gpu in both opencv and

00:19:18,400 --> 00:19:22,480
total vision case

00:19:20,400 --> 00:19:23,679
please note that the number process is

00:19:22,480 --> 00:19:26,320
one

00:19:23,679 --> 00:19:26,960
as you can see in this figure total time

00:19:26,320 --> 00:19:29,280
reduced

00:19:26,960 --> 00:19:30,720
after we increase the number of gpu for

00:19:29,280 --> 00:19:33,120
training

00:19:30,720 --> 00:19:34,240
from this figure we can say that for

00:19:33,120 --> 00:19:36,480
this use case

00:19:34,240 --> 00:19:38,400
we should increase the number of gpu for

00:19:36,480 --> 00:19:41,280
training rather than increasing the

00:19:38,400 --> 00:19:44,640
number of gpu for pre-processing

00:19:41,280 --> 00:19:46,000
also we can say that we should use gpu

00:19:44,640 --> 00:19:48,400
for training only

00:19:46,000 --> 00:19:49,200
since training consumes lots of gpu

00:19:48,400 --> 00:19:53,840
resource

00:19:49,200 --> 00:19:53,840
and it cannot afford processing anymore

00:19:54,080 --> 00:19:59,520
now let us discuss how we accelerate the

00:19:57,039 --> 00:20:03,039
pre-processing and wall performance

00:19:59,520 --> 00:20:04,880
in both serving and training phase

00:20:03,039 --> 00:20:07,280
we discuss how we design the

00:20:04,880 --> 00:20:08,559
pre-processing system in both serving

00:20:07,280 --> 00:20:11,200
and training fades

00:20:08,559 --> 00:20:13,039
in serving phase parallelism and cueing

00:20:11,200 --> 00:20:16,080
enabled us to reduce the wall

00:20:13,039 --> 00:20:18,400
inference of last time on the other hand

00:20:16,080 --> 00:20:20,240
in training phase we can say that we

00:20:18,400 --> 00:20:22,799
need to discuss whether we need to

00:20:20,240 --> 00:20:25,440
accelerate image preprocessing or not

00:20:22,799 --> 00:20:27,679
according to the purpose of the system

00:20:25,440 --> 00:20:29,679
table below shows the direction for

00:20:27,679 --> 00:20:32,159
designing preprocessing system

00:20:29,679 --> 00:20:33,600
in training phase we think there are two

00:20:32,159 --> 00:20:35,520
types of design patterns in

00:20:33,600 --> 00:20:37,679
pre-processing system

00:20:35,520 --> 00:20:40,000
one of them is pre-processing and

00:20:37,679 --> 00:20:41,520
training are executed continuously such

00:20:40,000 --> 00:20:43,919
as this case

00:20:41,520 --> 00:20:46,799
in this case the advantage of the design

00:20:43,919 --> 00:20:49,280
is that we can accelerate the total time

00:20:46,799 --> 00:20:51,280
whether we need to tune pre-processing

00:20:49,280 --> 00:20:52,880
depends on the situation

00:20:51,280 --> 00:20:54,960
we need to investigate whether

00:20:52,880 --> 00:20:56,640
pre-processing and training degrades the

00:20:54,960 --> 00:20:59,120
world performance

00:20:56,640 --> 00:21:00,320
the appropriate purpose of this design

00:20:59,120 --> 00:21:02,320
is training models

00:21:00,320 --> 00:21:04,559
every time in different data such as

00:21:02,320 --> 00:21:06,720
incremental learning

00:21:04,559 --> 00:21:08,960
the other of them is that pre-processing

00:21:06,720 --> 00:21:10,559
and training are executed in a different

00:21:08,960 --> 00:21:12,720
system

00:21:10,559 --> 00:21:15,600
in this case the advantage of the design

00:21:12,720 --> 00:21:17,200
is that we can save the resource cost

00:21:15,600 --> 00:21:18,640
we should tune pre-processing

00:21:17,200 --> 00:21:20,320
performance this time

00:21:18,640 --> 00:21:22,400
since we can accelerate the wall

00:21:20,320 --> 00:21:24,480
performance by accelerating both

00:21:22,400 --> 00:21:26,640
pre-processing and training

00:21:24,480 --> 00:21:28,799
appropriate purpose of the design is

00:21:26,640 --> 00:21:32,240
that training models in the same data

00:21:28,799 --> 00:21:35,039
such as parameter tuning

00:21:32,240 --> 00:21:37,120
in conclusion we evaluated the

00:21:35,039 --> 00:21:38,159
acceleration techniques of image

00:21:37,120 --> 00:21:42,080
pre-processing

00:21:38,159 --> 00:21:44,960
and its fit in deep learning application

00:21:42,080 --> 00:21:45,200
from this research we got new insights

00:21:44,960 --> 00:21:47,919
of

00:21:45,200 --> 00:21:48,799
how we utilized multiple open source

00:21:47,919 --> 00:21:50,960
softwares

00:21:48,799 --> 00:21:52,880
to get better performance in deep

00:21:50,960 --> 00:21:55,679
learning application

00:21:52,880 --> 00:21:56,960
from serving point of view techniques

00:21:55,679 --> 00:21:59,120
such as parallelism

00:21:56,960 --> 00:22:00,480
and cueing could accelerate image

00:21:59,120 --> 00:22:02,480
preprocessing

00:22:00,480 --> 00:22:04,240
and it could accelerate the wall

00:22:02,480 --> 00:22:06,400
influence performance

00:22:04,240 --> 00:22:08,480
on the other hand from training point of

00:22:06,400 --> 00:22:11,440
view we need to judge

00:22:08,480 --> 00:22:12,960
whether we apply acceleration techniques

00:22:11,440 --> 00:22:15,760
according to the purpose

00:22:12,960 --> 00:22:15,760
of the system

00:22:16,799 --> 00:22:21,520
this is the end of our presentation

00:22:19,600 --> 00:22:23,919
thanks for joining us

00:22:21,520 --> 00:22:24,960
if you have any questions and comments

00:22:23,919 --> 00:22:28,000
please leave

00:22:24,960 --> 00:22:41,840
your feedback via text just again thank

00:22:28,000 --> 00:22:41,840
you very much

00:22:45,760 --> 00:22:47,840

YouTube URL: https://www.youtube.com/watch?v=rr-dloWYZec


