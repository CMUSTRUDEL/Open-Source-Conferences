Title: Introduction to Stream Processing with Apache Flink - Marta Paes, Ververica
Publication date: 2020-12-04
Playlist: Open Source Summit Japan & Automotive Linux Summit 2020
Description: 
	Introduction to Stream Processing with Apache Flink - Marta Paes, Ververica
Captions: 
	00:00:13,599 --> 00:00:21,199
hello everyone

00:00:16,320 --> 00:00:24,640
thank you for coming to my session today

00:00:21,199 --> 00:00:29,519
i hope you can hear me see me fine

00:00:24,640 --> 00:00:32,000
and see my slides um

00:00:29,519 --> 00:00:33,200
thanks for thanks for taking the time to

00:00:32,000 --> 00:00:37,200
attend this uh

00:00:33,200 --> 00:00:37,840
talk it's uh middle of the day in japan

00:00:37,200 --> 00:00:40,719
i think

00:00:37,840 --> 00:00:41,280
i'm in berlin in germany and it's 5 00

00:00:40,719 --> 00:00:44,000
a.m

00:00:41,280 --> 00:00:46,399
so i can't promise that my brain will be

00:00:44,000 --> 00:00:49,760
fully functioning

00:00:46,399 --> 00:00:52,320
i'm marta i'm a developer advocate at

00:00:49,760 --> 00:00:53,520
barbarica and today i want to give you

00:00:52,320 --> 00:00:57,120
an introduction to

00:00:53,520 --> 00:00:59,600
stream processing and apache flight

00:00:57,120 --> 00:01:00,239
so i tried to make this talk accessible

00:00:59,600 --> 00:01:03,440
so that

00:01:00,239 --> 00:01:05,360
you can follow it uh independent of

00:01:03,440 --> 00:01:06,560
your background or if you ever heard

00:01:05,360 --> 00:01:10,000
about flink before

00:01:06,560 --> 00:01:10,560
or not i put a little poll here on the

00:01:10,000 --> 00:01:12,799
side

00:01:10,560 --> 00:01:14,479
just so you can tell me if it's your

00:01:12,799 --> 00:01:17,920
first time hearing about flink

00:01:14,479 --> 00:01:18,159
or if you're maybe already used using it

00:01:17,920 --> 00:01:20,080
or

00:01:18,159 --> 00:01:22,400
maybe you've heard of it before so if

00:01:20,080 --> 00:01:25,520
you can click that and let me know

00:01:22,400 --> 00:01:28,720
that would be pretty cool

00:01:25,520 --> 00:01:29,439
and for those of you that never heard

00:01:28,720 --> 00:01:32,240
about

00:01:29,439 --> 00:01:33,520
the company of america before um you

00:01:32,240 --> 00:01:36,640
might know it as

00:01:33,520 --> 00:01:38,479
or it is a company of the people who

00:01:36,640 --> 00:01:40,400
created apache flink

00:01:38,479 --> 00:01:42,960
and this means that every day i get to

00:01:40,400 --> 00:01:44,880
work with the core maintainers

00:01:42,960 --> 00:01:46,960
of flink and be involved in this really

00:01:44,880 --> 00:01:48,159
active uh and growing open source

00:01:46,960 --> 00:01:50,640
community

00:01:48,159 --> 00:01:51,680
and what viverica does besides working

00:01:50,640 --> 00:01:54,399
on flink

00:01:51,680 --> 00:01:55,360
uh is offer an enterprise enterprise

00:01:54,399 --> 00:01:58,479
version of

00:01:55,360 --> 00:02:01,520
um flink called for verified platform

00:01:58,479 --> 00:02:04,079
and what it does is just it's it's just

00:02:01,520 --> 00:02:06,159
uh it really just streamlines a lot of

00:02:04,079 --> 00:02:07,680
the operational side of deploying and

00:02:06,159 --> 00:02:11,200
maintaining stream processing

00:02:07,680 --> 00:02:13,360
applications and since the beginning of

00:02:11,200 --> 00:02:16,560
last year the company is part of

00:02:13,360 --> 00:02:19,440
alibaba who is also

00:02:16,560 --> 00:02:20,160
one of the biggest users but also one of

00:02:19,440 --> 00:02:22,319
the biggest

00:02:20,160 --> 00:02:24,720
contributors to the open source project

00:02:22,319 --> 00:02:24,720
out there

00:02:26,239 --> 00:02:29,360
and so i'll i'll just start with a

00:02:28,319 --> 00:02:31,760
really quick

00:02:29,360 --> 00:02:32,879
uh recap that introduces you to stream

00:02:31,760 --> 00:02:34,879
processing if you're

00:02:32,879 --> 00:02:36,480
not really familiar with the concept or

00:02:34,879 --> 00:02:37,519
you have a different uh different

00:02:36,480 --> 00:02:40,800
background

00:02:37,519 --> 00:02:42,959
so if you have at least been working

00:02:40,800 --> 00:02:45,200
with uh data for some time

00:02:42,959 --> 00:02:46,160
maybe the scenario will will be familiar

00:02:45,200 --> 00:02:49,680
to you so

00:02:46,160 --> 00:02:52,160
not that long ago this is what

00:02:49,680 --> 00:02:53,040
analytics used to look like so you had a

00:02:52,160 --> 00:02:55,519
bunch of

00:02:53,040 --> 00:02:57,920
transactional databases maybe you had

00:02:55,519 --> 00:03:00,959
some static sources of data as well

00:02:57,920 --> 00:03:01,280
you would run some etl process processes

00:03:00,959 --> 00:03:04,000
to

00:03:01,280 --> 00:03:04,640
integrate and combine all this data into

00:03:04,000 --> 00:03:08,319
something

00:03:04,640 --> 00:03:10,640
useful for your business and then

00:03:08,319 --> 00:03:11,680
you would store all of this away in a

00:03:10,640 --> 00:03:15,200
data warehouse

00:03:11,680 --> 00:03:18,800
in nicely in nicely structured tables

00:03:15,200 --> 00:03:21,440
that serve again some business process

00:03:18,800 --> 00:03:23,040
and maybe you'd already have something

00:03:21,440 --> 00:03:26,159
like a data lake where

00:03:23,040 --> 00:03:27,920
you just put the raw source data and

00:03:26,159 --> 00:03:30,799
that you use instead but

00:03:27,920 --> 00:03:32,640
this is basically the picture of how

00:03:30,799 --> 00:03:34,879
analytics looked at least

00:03:32,640 --> 00:03:37,599
for me very recently in my in my

00:03:34,879 --> 00:03:37,599
previous job

00:03:37,760 --> 00:03:41,920
and so your your quests to your quest

00:03:40,480 --> 00:03:43,840
for data would look

00:03:41,920 --> 00:03:45,120
something like this you you would run

00:03:43,840 --> 00:03:48,159
some really long

00:03:45,120 --> 00:03:49,040
nightly jobs and after some hours you

00:03:48,159 --> 00:03:52,720
would have

00:03:49,040 --> 00:03:55,599
your results but in reality what happens

00:03:52,720 --> 00:03:56,720
is one or one or more of these nightly

00:03:55,599 --> 00:03:59,840
jobs

00:03:56,720 --> 00:04:00,720
would fail because your processes run

00:03:59,840 --> 00:04:03,760
out of memory

00:04:00,720 --> 00:04:05,920
or because someone decided to use single

00:04:03,760 --> 00:04:07,599
single quotes instead of double quotes

00:04:05,920 --> 00:04:10,080
uh in their input

00:04:07,599 --> 00:04:12,879
and then someone would have to wake up

00:04:10,080 --> 00:04:16,320
fix the problem rerun these jobs

00:04:12,879 --> 00:04:19,919
a lot of times a person was me and

00:04:16,320 --> 00:04:23,040
someone then probably a stakeholder

00:04:19,919 --> 00:04:26,320
would complain that their data is late

00:04:23,040 --> 00:04:30,479
and after all of this then

00:04:26,320 --> 00:04:34,160
you get your results but they're late

00:04:30,479 --> 00:04:37,759
and in the end if you look at it most

00:04:34,160 --> 00:04:39,199
of the source data that you are using

00:04:37,759 --> 00:04:41,840
for all these processes

00:04:39,199 --> 00:04:43,840
is continuously produced so it doesn't

00:04:41,840 --> 00:04:46,320
really make sense that someone is

00:04:43,840 --> 00:04:47,919
waiting for for yesterday's data or that

00:04:46,320 --> 00:04:48,800
i am waking up in the middle of the

00:04:47,919 --> 00:04:52,560
night

00:04:48,800 --> 00:04:55,440
uh because most of the logic that

00:04:52,560 --> 00:04:58,560
you use to run to run this etl processes

00:04:55,440 --> 00:05:00,160
doesn't really change it's not something

00:04:58,560 --> 00:05:01,759
it's not something that is evolving or

00:05:00,160 --> 00:05:03,919
changing every day

00:05:01,759 --> 00:05:04,960
and what is evolving and changing all

00:05:03,919 --> 00:05:10,160
the time

00:05:04,960 --> 00:05:13,199
is the data that you're processing

00:05:10,160 --> 00:05:15,360
so something we can't really escape is

00:05:13,199 --> 00:05:18,000
this concept that nowadays everything

00:05:15,360 --> 00:05:18,000
is a stream

00:05:18,400 --> 00:05:24,720
and what used to be your static

00:05:21,759 --> 00:05:26,800
batch data are now events that are

00:05:24,720 --> 00:05:28,960
continuously produced and

00:05:26,800 --> 00:05:30,240
you should also be able to continuously

00:05:28,960 --> 00:05:32,320
process them

00:05:30,240 --> 00:05:34,800
so you have a set of event sources that

00:05:32,320 --> 00:05:37,440
can be anything these days so from

00:05:34,800 --> 00:05:38,240
connected devices and vehicles to web

00:05:37,440 --> 00:05:40,479
clicks

00:05:38,240 --> 00:05:41,919
application logs uh financial

00:05:40,479 --> 00:05:44,720
transactions

00:05:41,919 --> 00:05:46,960
you name it and all of them are

00:05:44,720 --> 00:05:50,479
continuously producing events that

00:05:46,960 --> 00:05:53,600
that end up at some point in some

00:05:50,479 --> 00:05:54,720
uh in a centralized distributed log

00:05:53,600 --> 00:05:58,720
something like

00:05:54,720 --> 00:06:01,759
kafka or pulsar or kinesis

00:05:58,720 --> 00:06:02,960
and over this sequence of events that

00:06:01,759 --> 00:06:05,919
are produced

00:06:02,960 --> 00:06:07,919
you likely want to run a set of

00:06:05,919 --> 00:06:09,919
transformations or computations to kind

00:06:07,919 --> 00:06:13,360
of mold this data into something

00:06:09,919 --> 00:06:15,280
that is useful for you so you might want

00:06:13,360 --> 00:06:16,240
to do things like filtering out some

00:06:15,280 --> 00:06:18,800
garbage or

00:06:16,240 --> 00:06:20,000
correlating events or just doing

00:06:18,800 --> 00:06:23,280
aggregations over

00:06:20,000 --> 00:06:24,880
time maybe in the in the

00:06:23,280 --> 00:06:26,960
somewhere in the process you want to

00:06:24,880 --> 00:06:27,440
persist some intermediate results to

00:06:26,960 --> 00:06:31,360
some

00:06:27,440 --> 00:06:34,639
um long-term storage like s3 or

00:06:31,360 --> 00:06:37,680
hdfs and then

00:06:34,639 --> 00:06:38,960
in the end you publish your output to a

00:06:37,680 --> 00:06:42,800
sync

00:06:38,960 --> 00:06:46,000
and the time it takes from data to go

00:06:42,800 --> 00:06:48,319
from the event sources to your syncs

00:06:46,000 --> 00:06:49,840
might be more or less critical depending

00:06:48,319 --> 00:06:52,479
on your use case

00:06:49,840 --> 00:06:53,360
but you certainly don't want to wait a

00:06:52,479 --> 00:06:59,199
whole day

00:06:53,360 --> 00:06:59,199
or sometimes more to get your results

00:07:00,400 --> 00:07:05,440
so in the simplest terms that i could

00:07:03,120 --> 00:07:08,720
find to try to explain this

00:07:05,440 --> 00:07:11,599
stream processing is is really

00:07:08,720 --> 00:07:11,840
what what i just described so you have

00:07:11,599 --> 00:07:15,280
an

00:07:11,840 --> 00:07:17,440
infinite data set that is continuous

00:07:15,280 --> 00:07:18,400
continuously flowing it's called a data

00:07:17,440 --> 00:07:21,280
stream

00:07:18,400 --> 00:07:22,960
and you have your code that is going to

00:07:21,280 --> 00:07:23,520
perform whatever transformations you

00:07:22,960 --> 00:07:26,560
want to

00:07:23,520 --> 00:07:27,280
to do on this data and you want to

00:07:26,560 --> 00:07:30,479
process

00:07:27,280 --> 00:07:32,160
this data stream event by event

00:07:30,479 --> 00:07:33,520
so use your code to apply

00:07:32,160 --> 00:07:36,720
transformations

00:07:33,520 --> 00:07:37,759
and then just output this transform the

00:07:36,720 --> 00:07:40,800
events

00:07:37,759 --> 00:07:43,280
downstream and things

00:07:40,800 --> 00:07:44,960
start getting a bit more interesting

00:07:43,280 --> 00:07:47,360
when you want to do something

00:07:44,960 --> 00:07:48,639
that is uh more than just stateless

00:07:47,360 --> 00:07:51,280
operations so

00:07:48,639 --> 00:07:53,520
something like mapping or filtering uh

00:07:51,280 --> 00:07:57,360
our stateless operations

00:07:53,520 --> 00:08:01,520
uh and this is when you you enter the

00:07:57,360 --> 00:08:04,639
the world of stateful stream processing

00:08:01,520 --> 00:08:07,919
and here you have the same simple model

00:08:04,639 --> 00:08:10,400
as before you have your input data your

00:08:07,919 --> 00:08:12,879
transformations and your output

00:08:10,400 --> 00:08:14,000
but now you have this concept of memory

00:08:12,879 --> 00:08:17,199
or the ability

00:08:14,000 --> 00:08:20,319
to remember events as they flow through

00:08:17,199 --> 00:08:20,879
your code and the the real challenge of

00:08:20,319 --> 00:08:23,120
doing

00:08:20,879 --> 00:08:24,639
stateful stream processing are of kind

00:08:23,120 --> 00:08:26,479
of keeping track of what you are

00:08:24,639 --> 00:08:28,000
processing to influence

00:08:26,479 --> 00:08:29,599
what you're going to process in the

00:08:28,000 --> 00:08:32,320
future is

00:08:29,599 --> 00:08:32,959
exactly this memory or your state

00:08:32,320 --> 00:08:35,599
because

00:08:32,959 --> 00:08:36,479
you not only have to manage this state

00:08:35,599 --> 00:08:39,279
distributed

00:08:36,479 --> 00:08:41,039
across multiple machines but you also

00:08:39,279 --> 00:08:44,640
have to make sure

00:08:41,039 --> 00:08:48,240
that it doesn't just vanish when you

00:08:44,640 --> 00:08:48,240
have some kind of machine failure

00:08:50,160 --> 00:08:56,399
so what is apache flank

00:08:53,279 --> 00:09:00,640
the whole reason why uh

00:08:56,399 --> 00:09:02,000
we're here today so flink is an open

00:09:00,640 --> 00:09:04,240
source framework

00:09:02,000 --> 00:09:06,080
and a distributed engine that allows you

00:09:04,240 --> 00:09:07,920
to do exactly what i was

00:09:06,080 --> 00:09:09,200
explaining before staple stream

00:09:07,920 --> 00:09:11,600
processing

00:09:09,200 --> 00:09:12,640
so flic flink can continuously consume

00:09:11,600 --> 00:09:15,519
data from

00:09:12,640 --> 00:09:16,480
whatever sources you want to plug it

00:09:15,519 --> 00:09:18,959
into

00:09:16,480 --> 00:09:20,560
it applies some stateful computation

00:09:18,959 --> 00:09:23,519
computations on these

00:09:20,560 --> 00:09:25,760
data streams and as it processes it

00:09:23,519 --> 00:09:26,080
builds up some context so it keeps track

00:09:25,760 --> 00:09:29,200
of

00:09:26,080 --> 00:09:30,160
this state as it goes and then it

00:09:29,200 --> 00:09:33,120
produces some

00:09:30,160 --> 00:09:34,320
output is this could be anything so an

00:09:33,120 --> 00:09:39,120
api call

00:09:34,320 --> 00:09:39,120
updates to a database other data streams

00:09:39,839 --> 00:09:45,040
and what what makes flink

00:09:42,880 --> 00:09:46,720
really really powerful and what

00:09:45,040 --> 00:09:50,000
differentiates it from

00:09:46,720 --> 00:09:52,399
other from other stream processors is

00:09:50,000 --> 00:09:54,399
is the way it really handles this

00:09:52,399 --> 00:09:57,200
distributed state

00:09:54,399 --> 00:09:59,279
and what then makes it really flexible

00:09:57,200 --> 00:10:02,720
is that it's able to do this one at a

00:09:59,279 --> 00:10:02,720
time event processing

00:10:02,839 --> 00:10:08,959
consistently

00:10:05,680 --> 00:10:12,160
and because it is such a wide

00:10:08,959 --> 00:10:15,440
um such a such a white paradigm

00:10:12,160 --> 00:10:18,160
and uh such a such a flexible framework

00:10:15,440 --> 00:10:20,800
uh this this really gives you a very a

00:10:18,160 --> 00:10:23,360
very solid foundation to address

00:10:20,800 --> 00:10:24,720
a wide range of use cases so the use

00:10:23,360 --> 00:10:27,600
cases that we see

00:10:24,720 --> 00:10:30,720
companies using fling4 kind of fall into

00:10:27,600 --> 00:10:33,839
three different categories

00:10:30,720 --> 00:10:36,240
so at the core you have uh classical

00:10:33,839 --> 00:10:39,279
stream processing use cases so

00:10:36,240 --> 00:10:43,200
here uh our use cases that really build

00:10:39,279 --> 00:10:47,360
on uh the the core primitives of

00:10:43,200 --> 00:10:50,720
of link so events state and time

00:10:47,360 --> 00:10:54,000
um where data platform um

00:10:50,720 --> 00:10:55,200
data or platform engineers are really

00:10:54,000 --> 00:10:58,640
exploring

00:10:55,200 --> 00:10:59,200
um or are really trying to max out flink

00:10:58,640 --> 00:11:02,160
to do

00:10:59,200 --> 00:11:02,720
complex or heavy computations a lot of

00:11:02,160 --> 00:11:06,079
logic

00:11:02,720 --> 00:11:08,880
customization and the goal uh

00:11:06,079 --> 00:11:10,959
here is to maximize the performance and

00:11:08,880 --> 00:11:12,000
reliability of the systems that you're

00:11:10,959 --> 00:11:15,920
building

00:11:12,000 --> 00:11:17,519
so some examples of these use cases are

00:11:15,920 --> 00:11:19,920
there there's a lot of companies out

00:11:17,519 --> 00:11:23,200
there using flink to build their core

00:11:19,920 --> 00:11:24,320
um data infrastructure so one example is

00:11:23,200 --> 00:11:26,399
netflix

00:11:24,320 --> 00:11:28,079
uh they're using flink as a basis for

00:11:26,399 --> 00:11:31,279
their internal data platform

00:11:28,079 --> 00:11:34,560
called keystone and they're processing

00:11:31,279 --> 00:11:37,920
i think around three billion events per

00:11:34,560 --> 00:11:39,760
day so

00:11:37,920 --> 00:11:42,320
large-scale data pipelines is a very

00:11:39,760 --> 00:11:44,959
common use case

00:11:42,320 --> 00:11:46,079
then for example you have fujitsu that

00:11:44,959 --> 00:11:50,399
has

00:11:46,079 --> 00:11:52,800
also built a real-time iot

00:11:50,399 --> 00:11:54,160
data platform for example to process

00:11:52,800 --> 00:11:58,160
data from

00:11:54,160 --> 00:12:01,360
for autonomous vehicles and

00:11:58,160 --> 00:12:04,800
another example is aws who

00:12:01,360 --> 00:12:08,000
is using flink for log analysis

00:12:04,800 --> 00:12:10,079
to monitor um to

00:12:08,000 --> 00:12:12,560
monitor and detect anomalies in their

00:12:10,079 --> 00:12:12,560
clusters

00:12:14,320 --> 00:12:22,000
and then on on the other side um

00:12:17,760 --> 00:12:24,240
kind of the the rising use cases um

00:12:22,000 --> 00:12:25,839
are are on streaming analytics and

00:12:24,240 --> 00:12:27,760
machine learning

00:12:25,839 --> 00:12:29,760
and here in contrast to what i was

00:12:27,760 --> 00:12:33,600
saying before like this more

00:12:29,760 --> 00:12:36,320
uh core infrastructure use cases

00:12:33,600 --> 00:12:36,880
um in in this kind of cases flink is

00:12:36,320 --> 00:12:40,079
used

00:12:36,880 --> 00:12:43,440
a bit more on a high level and

00:12:40,079 --> 00:12:45,360
in the main specific situation so that

00:12:43,440 --> 00:12:45,680
can be easily modeled with something

00:12:45,360 --> 00:12:49,519
like

00:12:45,680 --> 00:12:50,639
sql or python and simple abstractions

00:12:49,519 --> 00:12:53,920
like

00:12:50,639 --> 00:12:56,079
tab like tables so here

00:12:53,920 --> 00:12:57,440
the focus is not so much on

00:12:56,079 --> 00:13:01,680
implementation

00:12:57,440 --> 00:13:04,399
details but it's more on

00:13:01,680 --> 00:13:04,720
quickly being able to build the logic to

00:13:04,399 --> 00:13:08,079
meet

00:13:04,720 --> 00:13:09,040
business requirements and these are use

00:13:08,079 --> 00:13:11,839
cases where

00:13:09,040 --> 00:13:13,360
you might have also mixed batch and

00:13:11,839 --> 00:13:15,839
streaming workloads

00:13:13,360 --> 00:13:16,720
and i didn't mention this before but

00:13:15,839 --> 00:13:19,920
flink

00:13:16,720 --> 00:13:20,800
is also able to do efficient batch

00:13:19,920 --> 00:13:22,800
processing

00:13:20,800 --> 00:13:24,800
it's a streaming first it's a streaming

00:13:22,800 --> 00:13:27,920
first framework that can also do

00:13:24,800 --> 00:13:30,959
efficient patch processing and

00:13:27,920 --> 00:13:31,360
so here you might want you might want to

00:13:30,959 --> 00:13:35,040
do

00:13:31,360 --> 00:13:36,560
max mixed batch and streaming workloads

00:13:35,040 --> 00:13:39,680
for example for things like

00:13:36,560 --> 00:13:42,560
uh backfilling historical data

00:13:39,680 --> 00:13:44,800
and the goal is again to maximize

00:13:42,560 --> 00:13:48,079
developer speed and autonomy so

00:13:44,800 --> 00:13:50,880
basically make users more independent

00:13:48,079 --> 00:13:52,320
in their data needs and this is made

00:13:50,880 --> 00:13:54,959
possible by using

00:13:52,320 --> 00:13:57,199
like i said before rapid prototyping

00:13:54,959 --> 00:14:00,160
languages like sql python

00:13:57,199 --> 00:14:00,800
that allow you some also some degree of

00:14:00,160 --> 00:14:04,320
freedom

00:14:00,800 --> 00:14:04,959
like writing your own user-defined

00:14:04,320 --> 00:14:07,519
functions

00:14:04,959 --> 00:14:08,320
integrating with useful tools like

00:14:07,519 --> 00:14:12,000
notebooks

00:14:08,320 --> 00:14:12,000
or machine learning libraries

00:14:12,160 --> 00:14:14,480
and

00:14:15,360 --> 00:14:22,399
oops sorry i skipped the use cases

00:14:19,519 --> 00:14:24,160
and uh some examples here on the

00:14:22,399 --> 00:14:25,680
streaming analytics and machine learning

00:14:24,160 --> 00:14:29,120
side you have for example

00:14:25,680 --> 00:14:32,240
weibo which is a social really big

00:14:29,120 --> 00:14:33,920
social network in china

00:14:32,240 --> 00:14:36,480
is using flint to build unified

00:14:33,920 --> 00:14:38,240
pipelines for online and offline model

00:14:36,480 --> 00:14:41,440
training

00:14:38,240 --> 00:14:44,720
um uber is also

00:14:41,440 --> 00:14:47,920
as also has an internal data platform

00:14:44,720 --> 00:14:51,120
um that

00:14:47,920 --> 00:14:53,279
that allows users to build end-to-end

00:14:51,120 --> 00:14:54,880
streaming analytics pipelines so users

00:14:53,279 --> 00:14:56,959
can just submit

00:14:54,880 --> 00:14:58,720
sql statements and then uber built a

00:14:56,959 --> 00:15:00,240
platform that just compiled everything

00:14:58,720 --> 00:15:02,639
down to flink jobs

00:15:00,240 --> 00:15:03,440
but users are able to just write plain

00:15:02,639 --> 00:15:07,680
sql

00:15:03,440 --> 00:15:10,959
without any kind of of code and

00:15:07,680 --> 00:15:13,199
in the last criteo also has um

00:15:10,959 --> 00:15:15,199
has created a platform that makes it

00:15:13,199 --> 00:15:18,639
really easy to generate features for

00:15:15,199 --> 00:15:18,639
machine learning model training

00:15:19,680 --> 00:15:25,360
and on the other side of the spectrum

00:15:22,959 --> 00:15:28,000
there's also event driven applications

00:15:25,360 --> 00:15:28,720
and i'm not going into a lot of detail

00:15:28,000 --> 00:15:31,360
um

00:15:28,720 --> 00:15:32,560
here because it's a bit of a new field

00:15:31,360 --> 00:15:34,160
for flink and it

00:15:32,560 --> 00:15:35,759
might be confusing if you never heard

00:15:34,160 --> 00:15:38,880
about flint before

00:15:35,759 --> 00:15:42,399
but if you are

00:15:38,880 --> 00:15:46,079
interested in stable serverless

00:15:42,399 --> 00:15:48,639
and and all this all this universe

00:15:46,079 --> 00:15:50,240
uh then then i dropped some links in

00:15:48,639 --> 00:15:55,839
here and then you can check

00:15:50,240 --> 00:15:55,839
um this new api called staple functions

00:15:58,160 --> 00:16:03,360
and with this really wide range of use

00:16:01,680 --> 00:16:07,199
cases that i showed you before

00:16:03,360 --> 00:16:08,959
flink is powering a lot of the largest

00:16:07,199 --> 00:16:12,000
companies in the world and

00:16:08,959 --> 00:16:15,279
it serves a very different

00:16:12,000 --> 00:16:16,959
or very diverse industry vertical so

00:16:15,279 --> 00:16:20,079
anything from entertainment

00:16:16,959 --> 00:16:20,079
to agrotech

00:16:20,959 --> 00:16:28,160
and to give you an idea of the scale

00:16:24,399 --> 00:16:30,639
fling can go to uh

00:16:28,160 --> 00:16:32,079
the biggest uh production use case that

00:16:30,639 --> 00:16:35,120
we know of is really

00:16:32,079 --> 00:16:36,959
what alibaba is doing on the double 11

00:16:35,120 --> 00:16:40,320
or singles day

00:16:36,959 --> 00:16:41,680
um and on this day their infrastructure

00:16:40,320 --> 00:16:45,519
flink is

00:16:41,680 --> 00:16:48,240
is backing most of alibaba's real-time

00:16:45,519 --> 00:16:50,040
data applications in this day so like

00:16:48,240 --> 00:16:54,000
search and recommendations

00:16:50,040 --> 00:16:56,320
advertisements and even like this huge

00:16:54,000 --> 00:16:57,600
gmv dashboard that you see all over

00:16:56,320 --> 00:17:01,199
media

00:16:57,600 --> 00:17:02,880
uh flink is running on the our flinking

00:17:01,199 --> 00:17:04,720
is crunching all the data to actually

00:17:02,880 --> 00:17:08,240
produce those numbers so

00:17:04,720 --> 00:17:11,439
um and so so so that you have

00:17:08,240 --> 00:17:14,559
a specific idea of uh numbers

00:17:11,439 --> 00:17:16,319
here they run flink on thousands and

00:17:14,559 --> 00:17:18,480
thousands of machines

00:17:16,319 --> 00:17:19,760
and at peak they are processing four

00:17:18,480 --> 00:17:22,799
billion events per

00:17:19,760 --> 00:17:25,280
second and they do all of this

00:17:22,799 --> 00:17:26,319
with sub second latency so including

00:17:25,280 --> 00:17:28,720
updates to

00:17:26,319 --> 00:17:30,960
uh feature vector vectors that go into

00:17:28,720 --> 00:17:35,520
the recommendation system so

00:17:30,960 --> 00:17:37,840
uh this is really flink maxed out

00:17:35,520 --> 00:17:39,520
uh we always say it's a flink at alibaba

00:17:37,840 --> 00:17:41,679
scale because it's the biggest

00:17:39,520 --> 00:17:42,799
it's the biggest biggest scale use case

00:17:41,679 --> 00:17:46,400
that that we

00:17:42,799 --> 00:17:48,000
that we know but

00:17:46,400 --> 00:17:49,679
this doesn't mean that you can only use

00:17:48,000 --> 00:17:53,360
fling for huge

00:17:49,679 --> 00:17:56,640
uh production setups uh you can also go

00:17:53,360 --> 00:17:57,600
go small so in in one of our in one of

00:17:56,640 --> 00:18:00,320
our conferences

00:17:57,600 --> 00:18:01,919
recently there there was a company

00:18:00,320 --> 00:18:04,880
called you hopper

00:18:01,919 --> 00:18:05,200
that showed how you can run flink simply

00:18:04,880 --> 00:18:08,320
on

00:18:05,200 --> 00:18:11,280
a cluster of five raspberry pi's

00:18:08,320 --> 00:18:13,280
to process and aggregate real world iot

00:18:11,280 --> 00:18:16,480
data from connected vehicles

00:18:13,280 --> 00:18:18,080
so this is really a big contrast

00:18:16,480 --> 00:18:20,320
when you see the use case that i just

00:18:18,080 --> 00:18:21,280
talked about where you have thousands of

00:18:20,320 --> 00:18:24,320
machines

00:18:21,280 --> 00:18:24,960
uh running running flink and here you

00:18:24,320 --> 00:18:28,480
have

00:18:24,960 --> 00:18:31,600
blink running on a on a mini cluster of

00:18:28,480 --> 00:18:32,640
raspberry pi so it also gives you this

00:18:31,600 --> 00:18:35,840
flexibility

00:18:32,640 --> 00:18:35,840
in in use cases

00:18:37,360 --> 00:18:43,200
and you can just use your laptop you

00:18:40,480 --> 00:18:45,840
know fire it up open an ide

00:18:43,200 --> 00:18:49,039
and then just run or debug your flink

00:18:45,840 --> 00:18:49,039
applications locally

00:18:49,600 --> 00:18:56,720
and now i'd like to talk about what

00:18:54,080 --> 00:18:57,600
really makes all of this possible under

00:18:56,720 --> 00:19:01,440
the hood so

00:18:57,600 --> 00:19:05,120
what makes all these use cases uh

00:19:01,440 --> 00:19:07,760
what allows flink to to to go

00:19:05,120 --> 00:19:08,799
to go to the scale that alibaba takes it

00:19:07,760 --> 00:19:11,919
for example

00:19:08,799 --> 00:19:13,840
so what what makes flink flink and it's

00:19:11,919 --> 00:19:15,200
it's basically a combination of four

00:19:13,840 --> 00:19:18,480
different things that

00:19:15,200 --> 00:19:19,679
relate to how flink was engineered since

00:19:18,480 --> 00:19:24,160
the beginning so

00:19:19,679 --> 00:19:28,320
it has a set of really flexible apis

00:19:24,160 --> 00:19:31,360
it's able to do stateful processing

00:19:28,320 --> 00:19:32,640
it's really optimized and built from the

00:19:31,360 --> 00:19:35,600
ground

00:19:32,640 --> 00:19:37,520
from the ground up for high performance

00:19:35,600 --> 00:19:40,880
and

00:19:37,520 --> 00:19:44,080
it has a fault tolerance

00:19:40,880 --> 00:19:45,520
mechanism that allows you to that allows

00:19:44,080 --> 00:19:47,760
you to achieve

00:19:45,520 --> 00:19:48,799
the highest degree of consistency even

00:19:47,760 --> 00:19:52,160
when you have

00:19:48,799 --> 00:19:55,200
machine failures and i would also

00:19:52,160 --> 00:19:57,280
consider that the community uh

00:19:55,200 --> 00:19:58,799
is also something that makes flink what

00:19:57,280 --> 00:20:01,200
it is because

00:19:58,799 --> 00:20:02,480
it's a really really active open source

00:20:01,200 --> 00:20:05,840
community

00:20:02,480 --> 00:20:07,919
um yeah from from flink release to flink

00:20:05,840 --> 00:20:11,280
release we see the number of

00:20:07,919 --> 00:20:14,960
contributors growing and growing so

00:20:11,280 --> 00:20:17,120
uh it is it is uh one of the most

00:20:14,960 --> 00:20:19,039
i think the most active project in the

00:20:17,120 --> 00:20:20,720
apache software foundation so

00:20:19,039 --> 00:20:22,720
i would say that community is also

00:20:20,720 --> 00:20:25,520
really a really fundamental part

00:20:22,720 --> 00:20:25,520
to to flink

00:20:25,919 --> 00:20:29,520
and so i'm going to try not to give you

00:20:28,000 --> 00:20:32,320
an overview of how

00:20:29,520 --> 00:20:32,880
all of this is achieved hopefully

00:20:32,320 --> 00:20:36,320
without

00:20:32,880 --> 00:20:39,840
getting too much into

00:20:36,320 --> 00:20:39,840
the nitty-gritty of it

00:20:39,919 --> 00:20:46,799
so starting off with the apis

00:20:43,440 --> 00:20:50,000
flink has a layered structure with

00:20:46,799 --> 00:20:53,039
different apis that trade off how

00:20:50,000 --> 00:20:54,559
easy it is to use and how expressive you

00:20:53,039 --> 00:20:57,120
can get with it

00:20:54,559 --> 00:20:58,400
so this means that at a higher level you

00:20:57,120 --> 00:21:01,679
have apis

00:20:58,400 --> 00:21:04,720
like sql and the table api

00:21:01,679 --> 00:21:07,520
and pythlink there are closer to a

00:21:04,720 --> 00:21:11,600
relational way of thinking about data

00:21:07,520 --> 00:21:14,159
so these apis allow you to

00:21:11,600 --> 00:21:15,520
quickly express problems in a very

00:21:14,159 --> 00:21:18,880
concise way

00:21:15,520 --> 00:21:20,880
and do and let flink do

00:21:18,880 --> 00:21:22,720
all the operational heavy lifting for

00:21:20,880 --> 00:21:25,120
you so you don't have to worry about

00:21:22,720 --> 00:21:27,679
state management and all these things

00:21:25,120 --> 00:21:29,679
and you can use languages are familiar

00:21:27,679 --> 00:21:33,200
to you and they're

00:21:29,679 --> 00:21:35,520
a bit a bit more

00:21:33,200 --> 00:21:37,360
yeah a bit more either the main specific

00:21:35,520 --> 00:21:40,559
or a bit quicker to

00:21:37,360 --> 00:21:45,039
to to to use or more immediate like sql

00:21:40,559 --> 00:21:46,080
and python and as you go down the api

00:21:45,039 --> 00:21:48,640
stack

00:21:46,080 --> 00:21:49,760
using using the api starts getting a bit

00:21:48,640 --> 00:21:51,840
more complex

00:21:49,760 --> 00:21:53,520
but you also get more and more control

00:21:51,840 --> 00:21:56,320
over the programs that you are

00:21:53,520 --> 00:21:57,360
implementing and also how they are

00:21:56,320 --> 00:21:59,600
executed

00:21:57,360 --> 00:22:01,440
so and when you reach the core building

00:21:59,600 --> 00:22:02,960
blocks of fling so if you're really

00:22:01,440 --> 00:22:07,520
working at this level

00:22:02,960 --> 00:22:09,600
of process functions which are like the

00:22:07,520 --> 00:22:11,120
the smallest unit in flink if you want

00:22:09,600 --> 00:22:13,840
to call it that

00:22:11,120 --> 00:22:15,039
um and you're dealing with state and

00:22:13,840 --> 00:22:17,280
time

00:22:15,039 --> 00:22:18,480
and having fine-grained control over all

00:22:17,280 --> 00:22:21,120
of this

00:22:18,480 --> 00:22:26,559
you really can you really can do

00:22:21,120 --> 00:22:28,240
anything with me and

00:22:26,559 --> 00:22:30,799
it's it's pretty straightforward to look

00:22:28,240 --> 00:22:32,799
at this api stack and kind of think

00:22:30,799 --> 00:22:35,919
where the use cases that i mentioned

00:22:32,799 --> 00:22:39,120
before or the categories of use cases

00:22:35,919 --> 00:22:42,400
fall into and

00:22:39,120 --> 00:22:45,440
the good news is that you're not really

00:22:42,400 --> 00:22:48,240
you don't really have to choose one api

00:22:45,440 --> 00:22:50,240
uh all the apis make are integrate with

00:22:48,240 --> 00:22:53,520
each other so you can mix and match

00:22:50,240 --> 00:22:57,919
all the apis you can for example in

00:22:53,520 --> 00:23:02,000
invoke a python user-defined function

00:22:57,919 --> 00:23:06,000
in a flink sql query or you can convert

00:23:02,000 --> 00:23:07,440
a table into a stream and vice versa so

00:23:06,000 --> 00:23:09,360
you really can there's a lot of

00:23:07,440 --> 00:23:12,960
interplay here to really

00:23:09,360 --> 00:23:15,280
um to really fit whatever use case

00:23:12,960 --> 00:23:17,600
and whatever level of abstraction need

00:23:15,280 --> 00:23:17,600
you have

00:23:18,240 --> 00:23:24,240
and at the core of all of it

00:23:21,360 --> 00:23:25,120
and no matter what api you choose to

00:23:24,240 --> 00:23:27,600
work with

00:23:25,120 --> 00:23:28,320
what everything what what it boils down

00:23:27,600 --> 00:23:30,640
to

00:23:28,320 --> 00:23:31,760
is again the very simple model that we

00:23:30,640 --> 00:23:34,840
started with

00:23:31,760 --> 00:23:36,000
so your code will define where to

00:23:34,840 --> 00:23:38,799
consume

00:23:36,000 --> 00:23:39,840
the data streams from which here is your

00:23:38,799 --> 00:23:43,440
source

00:23:39,840 --> 00:23:46,880
what transformations to apply to it

00:23:43,440 --> 00:23:47,360
and where to sync the results so in this

00:23:46,880 --> 00:23:50,320
case

00:23:47,360 --> 00:23:51,360
i'm using the data stream api so one of

00:23:50,320 --> 00:23:54,720
the lower level

00:23:51,360 --> 00:23:57,360
apis to write a very simple

00:23:54,720 --> 00:23:59,440
java program that consumes uh

00:23:57,360 --> 00:24:03,279
temperature sensor data from

00:23:59,440 --> 00:24:06,400
in this case kafka it could be anything

00:24:03,279 --> 00:24:08,240
and so this is how you build a flank

00:24:06,400 --> 00:24:11,520
program so you have you add

00:24:08,240 --> 00:24:13,679
a kafka consumer as a source

00:24:11,520 --> 00:24:14,799
then you apply some transformations

00:24:13,679 --> 00:24:16,880
first

00:24:14,799 --> 00:24:20,159
a map operation that converts a

00:24:16,880 --> 00:24:24,720
temperature from fahrenheit to celsius

00:24:20,159 --> 00:24:26,880
then you key uh your events by sensor id

00:24:24,720 --> 00:24:28,240
and then you collect all these events in

00:24:26,880 --> 00:24:32,080
a time window of

00:24:28,240 --> 00:24:34,240
uh five seconds uh and then you

00:24:32,080 --> 00:24:37,520
calculate the average temperature

00:24:34,240 --> 00:24:38,960
and sends all of this into an elastic

00:24:37,520 --> 00:24:40,799
search sink

00:24:38,960 --> 00:24:42,000
so what we are basically doing is we

00:24:40,799 --> 00:24:45,760
have an incoming

00:24:42,000 --> 00:24:49,360
uh stream of data from sensors

00:24:45,760 --> 00:24:51,120
every five seconds we are calculating

00:24:49,360 --> 00:24:54,240
for each sensor

00:24:51,120 --> 00:24:57,039
the average temperature and then we are

00:24:54,240 --> 00:24:57,039
outputting it

00:24:59,039 --> 00:25:02,920
so and this is how you would write a

00:25:01,120 --> 00:25:04,320
streaming application with flinx so

00:25:02,920 --> 00:25:07,039
[Music]

00:25:04,320 --> 00:25:08,320
this is this is then underneath uh all

00:25:07,039 --> 00:25:11,600
converted into

00:25:08,320 --> 00:25:15,039
a logical representation of operators so

00:25:11,600 --> 00:25:18,159
and this is your streaming data flow

00:25:15,039 --> 00:25:18,640
so no matter what api you use uh even if

00:25:18,159 --> 00:25:22,080
you use

00:25:18,640 --> 00:25:23,279
flink sql and you're just writing a pure

00:25:22,080 --> 00:25:25,919
sql statement

00:25:23,279 --> 00:25:26,720
in the end flink will compile everything

00:25:25,919 --> 00:25:30,480
down

00:25:26,720 --> 00:25:30,480
into this streaming data flow

00:25:31,440 --> 00:25:36,799
and then you don't really just run this

00:25:34,240 --> 00:25:38,799
on one machine that's the whole point of

00:25:36,799 --> 00:25:41,440
using flink right you want to run this

00:25:38,799 --> 00:25:45,039
distributed across multiple machines

00:25:41,440 --> 00:25:48,480
and to segment the work and and

00:25:45,039 --> 00:25:50,400
and process it and what flink does is

00:25:48,480 --> 00:25:52,799
it takes care of distributing the

00:25:50,400 --> 00:25:55,760
workload across all the machines

00:25:52,799 --> 00:25:56,400
and including resharding your state so

00:25:55,760 --> 00:26:00,000
that

00:25:56,400 --> 00:26:03,679
each group of keys so like each

00:26:00,000 --> 00:26:06,480
sensor in in this case or each

00:26:03,679 --> 00:26:10,080
group of sensors is processed in a in a

00:26:06,480 --> 00:26:12,960
different instance

00:26:10,080 --> 00:26:13,600
so in our case we have a window operator

00:26:12,960 --> 00:26:16,000
which is

00:26:13,600 --> 00:26:16,720
stateful if you if you remember what i

00:26:16,000 --> 00:26:20,159
said before

00:26:16,720 --> 00:26:23,360
about remembering events um

00:26:20,159 --> 00:26:25,360
what what we are doing is um in in the

00:26:23,360 --> 00:26:27,200
small code snippet that i showed before

00:26:25,360 --> 00:26:30,960
is that we are collecting

00:26:27,200 --> 00:26:32,000
events for uh five seconds before we

00:26:30,960 --> 00:26:34,320
trigger

00:26:32,000 --> 00:26:35,520
um before we trigger our average

00:26:34,320 --> 00:26:38,559
computation

00:26:35,520 --> 00:26:41,279
so flink for every five seconds flink

00:26:38,559 --> 00:26:45,520
needs to keep track of what comes in

00:26:41,279 --> 00:26:46,480
and um blink always stores this state

00:26:45,520 --> 00:26:48,640
locally

00:26:46,480 --> 00:26:50,400
to the in instance that is processing

00:26:48,640 --> 00:26:53,679
the data so this is

00:26:50,400 --> 00:26:57,279
done either in memory on the jvm uh

00:26:53,679 --> 00:26:57,840
heap or on disk in an embedded key value

00:26:57,279 --> 00:27:01,840
store

00:26:57,840 --> 00:27:04,320
called roxdb that is just embedded into

00:27:01,840 --> 00:27:04,960
into flink and this means that state

00:27:04,320 --> 00:27:07,279
access

00:27:04,960 --> 00:27:08,080
for your computations is always super

00:27:07,279 --> 00:27:11,039
fast

00:27:08,080 --> 00:27:13,440
so it's either at in memory or at disk

00:27:11,039 --> 00:27:13,440
speed

00:27:15,440 --> 00:27:19,279
and like i mentioned before one thing

00:27:18,640 --> 00:27:21,840
that you

00:27:19,279 --> 00:27:24,159
kind of don't want is to lose all the

00:27:21,840 --> 00:27:27,440
state if something fails

00:27:24,159 --> 00:27:30,480
so uh

00:27:27,440 --> 00:27:34,240
flink flink really allows you to

00:27:30,480 --> 00:27:35,200
make sure that your applications can

00:27:34,240 --> 00:27:38,399
survive

00:27:35,200 --> 00:27:39,440
any kind of failure or downtime but

00:27:38,399 --> 00:27:43,200
still produce

00:27:39,440 --> 00:27:43,200
correct and consistent results

00:27:43,679 --> 00:27:47,120
and the way flink makes sure that this

00:27:45,760 --> 00:27:50,399
happens or that's

00:27:47,120 --> 00:27:53,760
your state is fault tolerant

00:27:50,399 --> 00:27:56,640
is by taking periodic snapshots of

00:27:53,760 --> 00:27:57,679
this application state write these

00:27:56,640 --> 00:28:02,000
snapshots

00:27:57,679 --> 00:28:04,880
to persistent storage like s3 or hdfs

00:28:02,000 --> 00:28:05,279
or another blob store that you have in

00:28:04,880 --> 00:28:09,039
your

00:28:05,279 --> 00:28:12,320
cloud provider and this action is done

00:28:09,039 --> 00:28:14,799
asynchronously so which means that flink

00:28:12,320 --> 00:28:16,399
flink is backing up your state but it

00:28:14,799 --> 00:28:18,720
still continues to process

00:28:16,399 --> 00:28:21,200
this data during during this uh this

00:28:18,720 --> 00:28:23,520
this snapshotting process

00:28:21,200 --> 00:28:24,240
and in this case because we are using

00:28:23,520 --> 00:28:27,679
kafka

00:28:24,240 --> 00:28:28,840
as a source which is uh durable but also

00:28:27,679 --> 00:28:32,720
re

00:28:28,840 --> 00:28:35,520
replayable the snapshot of state will

00:28:32,720 --> 00:28:36,880
include not just your window operator

00:28:35,520 --> 00:28:40,240
operator state

00:28:36,880 --> 00:28:42,240
but it will also include the offset or

00:28:40,240 --> 00:28:44,799
the position in the input stream that

00:28:42,240 --> 00:28:48,000
that you are consuming

00:28:44,799 --> 00:28:49,039
so when something goes wrong like if you

00:28:48,000 --> 00:28:52,080
lose a worker

00:28:49,039 --> 00:28:54,960
or your jobs get cancelled uh

00:28:52,080 --> 00:28:56,399
then flink just automatically recovers

00:28:54,960 --> 00:28:59,520
all the embedded states

00:28:56,399 --> 00:29:00,159
based on the most recent snapshot and it

00:28:59,520 --> 00:29:02,240
just

00:29:00,159 --> 00:29:03,919
uh because here we are using a

00:29:02,240 --> 00:29:06,640
replayable source

00:29:03,919 --> 00:29:08,240
then it also resets the the positions of

00:29:06,640 --> 00:29:10,640
the input stream so

00:29:08,240 --> 00:29:12,399
you can continue processing your data

00:29:10,640 --> 00:29:14,480
like nothing happened

00:29:12,399 --> 00:29:17,760
and you can still achieve the highest

00:29:14,480 --> 00:29:21,120
level of consistency so you can still

00:29:17,760 --> 00:29:24,000
achieve exactly once processing

00:29:21,120 --> 00:29:24,640
and exactly once here doesn't really

00:29:24,000 --> 00:29:27,520
mean that

00:29:24,640 --> 00:29:29,840
the events are processed only once it

00:29:27,520 --> 00:29:32,559
means that even if they are processed

00:29:29,840 --> 00:29:34,159
multiple times they only affect your

00:29:32,559 --> 00:29:36,480
application states

00:29:34,159 --> 00:29:36,480
once

00:29:37,679 --> 00:29:43,840
and something more that uh flinx

00:29:40,880 --> 00:29:44,240
flank offers based on this mechanism on

00:29:43,840 --> 00:29:46,720
the of

00:29:44,240 --> 00:29:49,200
on this uh snapshotting mechanism is

00:29:46,720 --> 00:29:52,799
also the possibility to trigger

00:29:49,200 --> 00:29:56,080
uh these snapshots manually for whenever

00:29:52,799 --> 00:29:59,279
you need to do planned manual

00:29:56,080 --> 00:30:01,600
backups of of your application

00:29:59,279 --> 00:30:04,399
this allows you to handle downtime

00:30:01,600 --> 00:30:06,240
situations like when you want to do

00:30:04,399 --> 00:30:09,120
you want to upgrade your flank version

00:30:06,240 --> 00:30:10,640
or you want to migrate to a new cluster

00:30:09,120 --> 00:30:13,600
but you don't really want to lose your

00:30:10,640 --> 00:30:15,600
state or you want to make changes to

00:30:13,600 --> 00:30:16,080
your code and restart the processing

00:30:15,600 --> 00:30:18,320
just

00:30:16,080 --> 00:30:19,840
when you're ready like if you want to

00:30:18,320 --> 00:30:23,200
increase the parallelism

00:30:19,840 --> 00:30:25,200
of your jobs for example so

00:30:23,200 --> 00:30:26,640
with with the snapshotting mechanism

00:30:25,200 --> 00:30:29,840
then you can always recover

00:30:26,640 --> 00:30:30,640
and restore um your your application

00:30:29,840 --> 00:30:33,840
state and

00:30:30,640 --> 00:30:37,600
resume processing like nothing like the

00:30:33,840 --> 00:30:39,600
application was never done

00:30:37,600 --> 00:30:41,520
and the last thing that i want to

00:30:39,600 --> 00:30:43,600
mention here is the way that flink

00:30:41,520 --> 00:30:46,880
handles time because it's also

00:30:43,600 --> 00:30:50,559
important to understand um

00:30:46,880 --> 00:30:53,600
understand this consistency story

00:30:50,559 --> 00:30:55,919
so in flink you have support for

00:30:53,600 --> 00:30:57,679
two different notions of time so you

00:30:55,919 --> 00:30:59,919
have event time and you have on the

00:30:57,679 --> 00:31:04,000
other side processing time

00:30:59,919 --> 00:31:06,799
and the easiest way to explain

00:31:04,000 --> 00:31:07,440
the difference between these two is to

00:31:06,799 --> 00:31:11,120
look at

00:31:07,440 --> 00:31:14,799
star wars movies so the order in which

00:31:11,120 --> 00:31:16,720
um each of the movies were released

00:31:14,799 --> 00:31:18,080
is not the same order in which the

00:31:16,720 --> 00:31:21,360
events actually

00:31:18,080 --> 00:31:24,880
happened in the start timeline

00:31:21,360 --> 00:31:27,360
so in flink choosing one or the other

00:31:24,880 --> 00:31:28,559
so choosing between using event time or

00:31:27,360 --> 00:31:32,480
processing time for

00:31:28,559 --> 00:31:34,799
for your application mostly affects um

00:31:32,480 --> 00:31:36,399
the latency with which you're able to

00:31:34,799 --> 00:31:38,799
process your events

00:31:36,399 --> 00:31:40,799
and also the correctness of of your

00:31:38,799 --> 00:31:42,960
results

00:31:40,799 --> 00:31:44,000
so if you want to process your events

00:31:42,960 --> 00:31:45,840
exactly

00:31:44,000 --> 00:31:47,120
in the order that they happened in the

00:31:45,840 --> 00:31:49,279
real world

00:31:47,120 --> 00:31:51,679
you can configure flink to use event

00:31:49,279 --> 00:31:54,480
time and this guarantees that

00:31:51,679 --> 00:31:55,679
your results are deterministic so always

00:31:54,480 --> 00:31:59,120
the same

00:31:55,679 --> 00:32:02,000
and in our in our little sensor

00:31:59,120 --> 00:32:02,880
data processing use case for example

00:32:02,000 --> 00:32:06,480
this would mean that

00:32:02,880 --> 00:32:10,480
even if a sensor was down for

00:32:06,480 --> 00:32:12,640
any time let's say 10 minutes 30 minutes

00:32:10,480 --> 00:32:14,080
uh flink would still be able to process

00:32:12,640 --> 00:32:17,679
it in the in the correct

00:32:14,080 --> 00:32:17,679
time window and

00:32:17,840 --> 00:32:24,320
because uh because flinx

00:32:21,200 --> 00:32:26,080
flink gives you um tooling that allows

00:32:24,320 --> 00:32:29,200
you to really reason about

00:32:26,080 --> 00:32:32,880
and and handle out of order or even

00:32:29,200 --> 00:32:35,919
late events if you use event time

00:32:32,880 --> 00:32:38,320
and you can always just choose

00:32:35,919 --> 00:32:40,480
what trade-off you want to make between

00:32:38,320 --> 00:32:43,840
result completeness and latency

00:32:40,480 --> 00:32:43,840
in processing your results

00:32:44,159 --> 00:32:47,600
and on the other hand if you only care

00:32:46,320 --> 00:32:49,440
about speed

00:32:47,600 --> 00:32:51,440
and you don't really care about how

00:32:49,440 --> 00:32:53,679
correct your results are

00:32:51,440 --> 00:32:56,880
you can also configure flink to just use

00:32:53,679 --> 00:33:01,039
processing time

00:32:56,880 --> 00:33:03,679
and just to recap what makes flink

00:33:01,039 --> 00:33:04,559
uh different to other stream processors

00:33:03,679 --> 00:33:07,120
in this

00:33:04,559 --> 00:33:08,840
is this combination of uh

00:33:07,120 --> 00:33:12,240
characteristics

00:33:08,840 --> 00:33:15,360
so on one side it gives you

00:33:12,240 --> 00:33:18,399
flexible apis that allow you to

00:33:15,360 --> 00:33:20,000
choose between um ease of use and

00:33:18,399 --> 00:33:23,360
expressiveness

00:33:20,000 --> 00:33:25,120
and allow you to cover a really wide

00:33:23,360 --> 00:33:28,159
range of use cases

00:33:25,120 --> 00:33:28,159
and also skills

00:33:28,399 --> 00:33:34,399
it treats state as a first class citizen

00:33:31,840 --> 00:33:35,840
and it has a rich time semantics that

00:33:34,399 --> 00:33:37,600
allow you to

00:33:35,840 --> 00:33:40,320
not give up or not have to choose

00:33:37,600 --> 00:33:43,120
between correctness and completeness

00:33:40,320 --> 00:33:45,679
and also allows you to reprocess

00:33:43,120 --> 00:33:49,440
historical data consistently

00:33:45,679 --> 00:33:52,720
and it's optimized for high performance

00:33:49,440 --> 00:33:54,480
with local state access uh that allows

00:33:52,720 --> 00:33:57,600
you to perform computations at

00:33:54,480 --> 00:33:58,159
in memory speed and allows you also to

00:33:57,600 --> 00:34:01,360
achieve

00:33:58,159 --> 00:34:06,000
high throughput but really low latency

00:34:01,360 --> 00:34:07,840
and in lastly it it also ensures

00:34:06,000 --> 00:34:10,639
that your applications are fault

00:34:07,840 --> 00:34:11,359
tolerant and that can handle failures

00:34:10,639 --> 00:34:14,159
with

00:34:11,359 --> 00:34:16,560
the highest level of consistency if you

00:34:14,159 --> 00:34:16,560
need it

00:34:19,440 --> 00:34:25,760
and yeah so like i said i

00:34:22,879 --> 00:34:26,879
my intention was to give you an overview

00:34:25,760 --> 00:34:29,839
of flink

00:34:26,879 --> 00:34:30,720
not really to dive really deep into it

00:34:29,839 --> 00:34:33,679
um

00:34:30,720 --> 00:34:34,000
so here if if you want to know more

00:34:33,679 --> 00:34:35,760
about

00:34:34,000 --> 00:34:37,679
flink or if you're interested in trying

00:34:35,760 --> 00:34:41,119
it out i'm leaving here

00:34:37,679 --> 00:34:43,599
some links um that that you can use to

00:34:41,119 --> 00:34:46,159
do that depending on

00:34:43,599 --> 00:34:47,359
whatever whatever background you have or

00:34:46,159 --> 00:34:51,679
whatever

00:34:47,359 --> 00:34:55,679
programming language you prefer so

00:34:51,679 --> 00:34:58,240
if you're a java scholar person you can

00:34:55,679 --> 00:35:00,560
start with the self-paced training that

00:34:58,240 --> 00:35:02,480
that is in the documentation

00:35:00,560 --> 00:35:04,720
if on the other hand you just want to

00:35:02,480 --> 00:35:07,920
write sql

00:35:04,720 --> 00:35:10,079
and uh not not code at all

00:35:07,920 --> 00:35:13,040
uh you could there is a really good uh

00:35:10,079 --> 00:35:16,400
github repository that has a functional

00:35:13,040 --> 00:35:17,359
walkthrough and if you're a python

00:35:16,400 --> 00:35:20,960
person

00:35:17,359 --> 00:35:22,480
uh their documentation also has a really

00:35:20,960 --> 00:35:27,040
good pipeline

00:35:22,480 --> 00:35:29,440
tutorial and you can also get started on

00:35:27,040 --> 00:35:31,680
apache zeppelin notebooks there are also

00:35:29,440 --> 00:35:33,440
some guides out there

00:35:31,680 --> 00:35:36,160
that make it really really easy to write

00:35:33,440 --> 00:35:39,920
your first blank application

00:35:36,160 --> 00:35:39,920
and other than that you can visit

00:35:40,040 --> 00:35:43,440
flink.apache.org

00:35:41,760 --> 00:35:45,119
and you can subscribe to the user

00:35:43,440 --> 00:35:47,520
mailing list if you need help

00:35:45,119 --> 00:35:49,839
or or just use stack overflow the

00:35:47,520 --> 00:35:53,200
community is really responsive

00:35:49,839 --> 00:35:55,200
uh in both and you will

00:35:53,200 --> 00:35:57,119
you will get an answer usually from a

00:35:55,200 --> 00:35:59,359
maintainer from someone else in the

00:35:57,119 --> 00:36:02,400
community

00:35:59,359 --> 00:36:05,920
considerably considerably fast

00:36:02,400 --> 00:36:08,079
and if you want to keep up with what's

00:36:05,920 --> 00:36:11,520
going on in fling so

00:36:08,079 --> 00:36:12,000
for example we are about to have a new

00:36:11,520 --> 00:36:15,200
release

00:36:12,000 --> 00:36:16,000
of flink 112. uh the best way to stay up

00:36:15,200 --> 00:36:19,200
to date

00:36:16,000 --> 00:36:22,000
is uh by following apache

00:36:19,200 --> 00:36:22,000
link on twitter

00:36:23,680 --> 00:36:28,560
and another way another way that you can

00:36:26,160 --> 00:36:31,200
that you can get started is also just

00:36:28,560 --> 00:36:32,320
using the vertical platform community

00:36:31,200 --> 00:36:36,000
edition

00:36:32,320 --> 00:36:39,359
it is pretty easy to set up it's

00:36:36,000 --> 00:36:41,599
free forever um

00:36:39,359 --> 00:36:42,960
you don't have a limit on the the size

00:36:41,599 --> 00:36:43,680
of the applications that you can build

00:36:42,960 --> 00:36:46,720
with it

00:36:43,680 --> 00:36:48,480
and also it recently introduced support

00:36:46,720 --> 00:36:51,200
for flink sql so

00:36:48,480 --> 00:36:51,680
it has a nice editor where you can just

00:36:51,200 --> 00:36:54,880
or

00:36:51,680 --> 00:36:58,480
a nice interface where you can just

00:36:54,880 --> 00:36:58,480
write sql statements and

00:36:58,720 --> 00:37:05,760
and submit and submit submit jobs

00:37:02,400 --> 00:37:05,760
to to a fund cluster

00:37:07,440 --> 00:37:23,839
yeah that's it thank you so much i will

00:37:10,480 --> 00:37:23,839
take questions if there are any

00:37:28,560 --> 00:37:35,440
uh i don't think

00:37:32,000 --> 00:37:37,599
there are any questions

00:37:35,440 --> 00:37:40,079
there's still time so i will give it a

00:37:37,599 --> 00:37:42,320
couple of minutes

00:37:40,079 --> 00:37:42,320
if

00:37:45,040 --> 00:37:51,280
if you want to ask a question

00:37:48,480 --> 00:37:52,640
otherwise you can always you can always

00:37:51,280 --> 00:37:56,000
just find me

00:37:52,640 --> 00:37:59,040
on either on the open source summit

00:37:56,000 --> 00:38:02,240
uh slack or you can

00:37:59,040 --> 00:38:05,680
follow me on twitter send me dm and

00:38:02,240 --> 00:38:08,720
ask away

00:38:05,680 --> 00:38:12,800
i will also leave here

00:38:08,720 --> 00:38:12,800
the link to the slides

00:38:13,440 --> 00:38:16,880
in case you want to check them out the

00:38:15,680 --> 00:38:19,839
links are clickable

00:38:16,880 --> 00:38:19,839
so

00:38:20,079 --> 00:38:36,479
just go for it

00:38:33,340 --> 00:38:36,479
[Music]

00:38:44,839 --> 00:38:47,839
and

00:38:51,119 --> 00:38:59,119
if there are no questions

00:38:55,040 --> 00:39:01,760
i will close a session

00:38:59,119 --> 00:39:03,520
and please feel free to reach out to me

00:39:01,760 --> 00:39:06,560
at any time in any platform

00:39:03,520 --> 00:39:07,920
i will be glad to to chat and to give

00:39:06,560 --> 00:39:11,119
you some more directions

00:39:07,920 --> 00:39:14,160
into getting started with link if

00:39:11,119 --> 00:39:22,160
if you need them so thank you so much

00:39:14,160 --> 00:39:22,160

YouTube URL: https://www.youtube.com/watch?v=GTl_kdf1nGo


