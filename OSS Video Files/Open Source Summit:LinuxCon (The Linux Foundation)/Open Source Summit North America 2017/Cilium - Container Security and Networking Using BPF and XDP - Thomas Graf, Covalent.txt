Title: Cilium - Container Security and Networking Using BPF and XDP - Thomas Graf, Covalent
Publication date: 2017-09-14
Playlist: Open Source Summit North America 2017
Description: 
	Cilium - Container Security and Networking Using BPF and XDP - Thomas Graf, Covalent

This talk introduces Cilium, a fast emerging open source project leveraging BPF to provide networking and security for containers. We will do a quick deep dive into BPF, possibly the most promising low level technology to address challenges in application and network security, networking, tracing, and visibility. We will discuss how BPF became capable of universally extending and instrumenting both the Linux kernel and user space applications. The introduction is followed by a concrete example of how the Cilium open source project applies BPF to solve networking, security, and load balancing for highly distributed applications. We will discuss how Cilium can be combined with orchestration systems such as Kubernetes to provide security and networking for cloud native applications.

About Thomas Graf
Thomas Graf has been a Linux kernel developer for 15 years, working on a variety of networking and security subsystems. His current focus is on BPF/XDP and how it can be applied to solve challenges of distributed applications. This includes providing secure networking with transparent encryption, application aware security, tracing, visibility, and mitigation of DDoS attacks. Thomas is a contributor to various open source projects including the Linux kernel, Cilium, Open vSwitch, Docker, and Kubernetes.
Captions: 
	00:00:00,000 --> 00:00:05,580
what I want to talk about is cilium

00:00:03,290 --> 00:00:08,610
Andre in the last session talked about

00:00:05,580 --> 00:00:11,670
ipv6 and then working side I will I will

00:00:08,610 --> 00:00:14,670
focus on the network security or the

00:00:11,670 --> 00:00:21,060
security side of this so what is cilium

00:00:14,670 --> 00:00:23,699
about so salem is about BPF who has

00:00:21,060 --> 00:00:26,849
heard about BPF berkeley packet filter

00:00:23,699 --> 00:00:29,490
alright see a couple of hands for those

00:00:26,849 --> 00:00:32,759
who have not heard of it I think most of

00:00:29,490 --> 00:00:36,180
you have used TCP dump or you can where

00:00:32,759 --> 00:00:38,520
you can monitor packets on orc

00:00:36,180 --> 00:00:41,190
interfaces on the wire when you specify

00:00:38,520 --> 00:00:43,620
a filter expression with TCP dump what

00:00:41,190 --> 00:00:47,340
actually happens is that TCP dump will

00:00:43,620 --> 00:00:50,370
compile and generate a BPF program load

00:00:47,340 --> 00:00:53,280
that into the kernel and that program

00:00:50,370 --> 00:00:54,239
decides which packets to display when

00:00:53,280 --> 00:00:56,430
you're on TCP dump

00:00:54,239 --> 00:00:59,160
so if most of you have been using BPF

00:00:56,430 --> 00:01:00,840
even without knowing it so this has been

00:00:59,160 --> 00:01:03,390
invented many many years ago 30 years

00:01:00,840 --> 00:01:06,090
ago but it has been extended since and

00:01:03,390 --> 00:01:09,680
it's become a revolution inside the

00:01:06,090 --> 00:01:12,930
Linux kernel it's been revolutionizing

00:01:09,680 --> 00:01:14,970
tracing and profiling if you hurt

00:01:12,930 --> 00:01:16,860
Brendan Gregg talk about this I think

00:01:14,970 --> 00:01:19,049
you have been you have noticed and you

00:01:16,860 --> 00:01:21,840
have experienced that this is changing

00:01:19,049 --> 00:01:24,869
how we can do performance analyzes one

00:01:21,840 --> 00:01:27,299
example and I'm just using one is

00:01:24,869 --> 00:01:30,270
showing how we can use BPF to generate

00:01:27,299 --> 00:01:32,189
histograms directly in the kernel so

00:01:30,270 --> 00:01:35,040
instead of sampling everything to use a

00:01:32,189 --> 00:01:36,930
space and then looking at the samples

00:01:35,040 --> 00:01:38,759
and deciding something or what to do

00:01:36,930 --> 00:01:41,100
with the samples we can actually do that

00:01:38,759 --> 00:01:43,320
inside a colon why was this even needed

00:01:41,100 --> 00:01:45,210
because the number of samples were too

00:01:43,320 --> 00:01:47,729
high to even export them to users face

00:01:45,210 --> 00:01:50,100
this is why tracing at the tracing and

00:01:47,729 --> 00:01:53,220
profiling subsystem has moved moved to

00:01:50,100 --> 00:01:56,880
BPF but tracing and profiling is not the

00:01:53,220 --> 00:02:00,390
only option of the only subsystem or the

00:01:56,880 --> 00:02:02,399
only field DPF eat revolutionising

00:02:00,390 --> 00:02:05,850
another one is not working that's the

00:02:02,399 --> 00:02:07,890
one where we focus on most some of you

00:02:05,850 --> 00:02:10,920
have may have seen Daniel Berkman's

00:02:07,890 --> 00:02:13,080
presentation yesterday he talked about

00:02:10,920 --> 00:02:16,710
BPF in general on xt

00:02:13,080 --> 00:02:19,080
the expressed data plain HTTP is a

00:02:16,710 --> 00:02:21,870
framework which allows us to run BPF

00:02:19,080 --> 00:02:25,470
programs at the network driver level of

00:02:21,870 --> 00:02:28,440
linux so very close to the actual harder

00:02:25,470 --> 00:02:30,240
than nick what i'm showing here is an

00:02:28,440 --> 00:02:33,900
experiment that we've done we've

00:02:30,240 --> 00:02:37,080
basically measured actually be BPF DDoS

00:02:33,900 --> 00:02:39,960
mitigation filter compared to an IP set

00:02:37,080 --> 00:02:42,570
based DDoS mitigation filter so IP set

00:02:39,960 --> 00:02:46,200
is an IP tables extension which allows

00:02:42,570 --> 00:02:48,390
you to match on a set of IPs or ports

00:02:46,200 --> 00:02:49,680
what we've done here is basically have

00:02:48,390 --> 00:02:52,470
connected two machines together

00:02:49,680 --> 00:02:55,050
back-to-back with a 10 gigabit network

00:02:52,470 --> 00:02:59,310
card and we've loaded the filters to

00:02:55,050 --> 00:03:01,170
filter on 16 million IP addresses we

00:02:59,310 --> 00:03:04,530
would then use one machine to send as

00:03:01,170 --> 00:03:06,120
many 64 byte packets as possible and the

00:03:04,530 --> 00:03:08,850
receiver would have to drop them as

00:03:06,120 --> 00:03:10,590
quickly as possible so let's look at the

00:03:08,850 --> 00:03:11,070
numbers real quick if for all the

00:03:10,590 --> 00:03:13,020
details

00:03:11,070 --> 00:03:14,670
Daniel has shared his presentation and

00:03:13,020 --> 00:03:16,560
you can look into the details there's

00:03:14,670 --> 00:03:18,480
also we also have a demo recording where

00:03:16,560 --> 00:03:20,040
you can see the actual video how this

00:03:18,480 --> 00:03:22,709
happens but let's look into the real

00:03:20,040 --> 00:03:25,709
numbers real quick so the the sender is

00:03:22,709 --> 00:03:28,440
able to generate sixteen point eleven

00:03:25,709 --> 00:03:30,600
point six million packets per second if

00:03:28,440 --> 00:03:33,690
you're using IP set we can actually only

00:03:30,600 --> 00:03:35,970
ever drop 7.1 million packets per second

00:03:33,690 --> 00:03:37,590
so all the resources on the machine are

00:03:35,970 --> 00:03:39,989
actually not enough to even draw all of

00:03:37,590 --> 00:03:42,330
these packets if actually peeper can

00:03:39,989 --> 00:03:46,080
easily drop all of these packets so what

00:03:42,330 --> 00:03:48,690
happens if we if you load if you load

00:03:46,080 --> 00:03:50,070
the rules these 16 million rules while

00:03:48,690 --> 00:03:52,620
we generate traffic how long does it

00:03:50,070 --> 00:03:54,300
actually load to even - other than how

00:03:52,620 --> 00:03:57,150
long has it even take to load all of

00:03:54,300 --> 00:03:58,560
these rules with with IP tables IPSec

00:03:57,150 --> 00:04:01,440
this took over three minutes

00:03:58,560 --> 00:04:03,239
if HTTP we were down to 31 seconds this

00:04:01,440 --> 00:04:04,980
is not exciting projects I notice here

00:04:03,239 --> 00:04:06,900
what about the latency and then

00:04:04,980 --> 00:04:09,630
throughput of a machine while it's on a

00:04:06,900 --> 00:04:11,459
DDoS attack if you're running an IP set

00:04:09,630 --> 00:04:13,739
based filtering basing the laser latency

00:04:11,459 --> 00:04:17,060
goes up to two point three milliseconds

00:04:13,739 --> 00:04:19,709
and the throughput goes to like point

00:04:17,060 --> 00:04:21,690
zero one for gigabit it's basically

00:04:19,709 --> 00:04:24,930
nothing while we've actually P the

00:04:21,690 --> 00:04:26,160
latency stays extreme we can we can

00:04:24,930 --> 00:04:28,710
still use a

00:04:26,160 --> 00:04:31,170
good portion of our bandwidth in terms

00:04:28,710 --> 00:04:33,210
of handling TCP requests per second

00:04:31,170 --> 00:04:35,790
that's the lowest metric like with IP

00:04:33,210 --> 00:04:38,580
tables IP set based filtering we can we

00:04:35,790 --> 00:04:40,920
can do a couple of hundred requests per

00:04:38,580 --> 00:04:43,470
second if you have an HDPE based filter

00:04:40,920 --> 00:04:45,150
we can still handle thousands of

00:04:43,470 --> 00:04:46,710
requests per second so basically even

00:04:45,150 --> 00:04:48,930
though the machine was on there a DDoS

00:04:46,710 --> 00:04:50,760
attack the machine remains reachable

00:04:48,930 --> 00:04:52,770
with low latency and can actually handle

00:04:50,760 --> 00:04:54,420
workloads so this is how Linux in the

00:04:52,770 --> 00:04:57,570
future will be capable of protecting

00:04:54,420 --> 00:04:58,230
itself from DDoS attacks this is one

00:04:57,570 --> 00:05:00,870
example

00:04:58,230 --> 00:05:04,350
the second expo what we want to talk is

00:05:00,870 --> 00:05:08,220
Facebook published numbers at net F this

00:05:04,350 --> 00:05:09,840
year and basically announced our to

00:05:08,220 --> 00:05:12,120
almost say that they're switching their

00:05:09,840 --> 00:05:14,520
load balancers the layer 3 layer 4 load

00:05:12,120 --> 00:05:17,070
balancers over from IP vs which is a

00:05:14,520 --> 00:05:20,070
Linux load balancing technology to BPF

00:05:17,070 --> 00:05:21,900
HDPE so we're talking about this piece

00:05:20,070 --> 00:05:24,150
here so between ecmp hardware based

00:05:21,900 --> 00:05:27,180
local answers and TL 7 local ancestor is

00:05:24,150 --> 00:05:28,860
running on l3 l4 local answer and these

00:05:27,180 --> 00:05:31,920
are the numbers and the numbers are mine

00:05:28,860 --> 00:05:35,280
or my employing the the bar below is the

00:05:31,920 --> 00:05:37,890
IP vs throughput and the upper bar is

00:05:35,280 --> 00:05:40,140
the xdp BPF throughput so packets per

00:05:37,890 --> 00:05:42,419
second and there's almost a 10x

00:05:40,140 --> 00:05:43,680
improvement and this is this is amazing

00:05:42,419 --> 00:05:46,350
anybody has been in an hour working

00:05:43,680 --> 00:05:47,790
field knows that 10x improvements don't

00:05:46,350 --> 00:05:49,800
come every day so this is definitely

00:05:47,790 --> 00:05:52,140
even though Facebook is not sharing the

00:05:49,800 --> 00:05:55,110
absolute numbers they're sharing the the

00:05:52,140 --> 00:05:56,490
performance Delta between the two this

00:05:55,110 --> 00:05:58,950
is not what I'm going to focus around I

00:05:56,490 --> 00:06:02,610
wanted to give you a outlook into how

00:05:58,950 --> 00:06:04,710
bps PPF is changing the chronal and how

00:06:02,610 --> 00:06:06,240
we do networking security and profiling

00:06:04,710 --> 00:06:09,210
if you want to know about this specific

00:06:06,240 --> 00:06:12,000
use case the network maintainer David

00:06:09,210 --> 00:06:14,160
Miller has done a keynote talk this year

00:06:12,000 --> 00:06:18,090
and there is a recording I have included

00:06:14,160 --> 00:06:20,610
it in this light here this is not just

00:06:18,090 --> 00:06:23,070
changing software networking though at

00:06:20,610 --> 00:06:25,560
future net a couple of weeks ago all of

00:06:23,070 --> 00:06:27,450
the smart NIC vendors have announced

00:06:25,560 --> 00:06:30,150
that they're going to support or all are

00:06:27,450 --> 00:06:33,150
already supporting BPF as an offloading

00:06:30,150 --> 00:06:35,370
engine so as we write DPF programs our

00:06:33,150 --> 00:06:37,050
software engineers smart necks in the

00:06:35,370 --> 00:06:39,100
future will actually be able to offload

00:06:37,050 --> 00:06:41,110
and run these at even higher speed

00:06:39,100 --> 00:06:42,490
and the DDoS mitigation filter I

00:06:41,110 --> 00:06:46,420
explained about I talked about it's just

00:06:42,490 --> 00:06:49,450
one example alright so what about

00:06:46,420 --> 00:06:51,220
security there's multiple projects I

00:06:49,450 --> 00:06:53,080
want to have mentioned one which is land

00:06:51,220 --> 00:06:55,230
lock it's changing how we can do

00:06:53,080 --> 00:06:58,180
sandboxing so it will be another

00:06:55,230 --> 00:06:59,920
low-level tool and framework ow for

00:06:58,180 --> 00:07:02,350
example something like a darker runtime

00:06:59,920 --> 00:07:05,700
or a rocket runtime can contain rise or

00:07:02,350 --> 00:07:09,670
sandbox applications and obviously

00:07:05,700 --> 00:07:11,980
cilium so how the cilium revolutionized

00:07:09,670 --> 00:07:15,430
security and I want to give you guys an

00:07:11,980 --> 00:07:17,980
example on what we focus on on what we

00:07:15,430 --> 00:07:20,380
figured is something that is currently

00:07:17,980 --> 00:07:23,320
unsolved that needs to be solved and I

00:07:20,380 --> 00:07:25,330
will I will take you a cue to the full

00:07:23,320 --> 00:07:26,560
thinking process that we that we went

00:07:25,330 --> 00:07:29,470
through so if you look at how

00:07:26,560 --> 00:07:31,960
applications have been delivered or

00:07:29,470 --> 00:07:33,760
developed and deployed many many years

00:07:31,960 --> 00:07:35,500
ago we started with servers and we would

00:07:33,760 --> 00:07:37,480
deploy maybe yearly we would set up the

00:07:35,500 --> 00:07:39,370
server it would be a mail server group a

00:07:37,480 --> 00:07:40,840
DNS server it would be a database we

00:07:39,370 --> 00:07:42,970
would deploy a yearly would apply

00:07:40,840 --> 00:07:43,660
security fixes right at that time is

00:07:42,970 --> 00:07:46,030
long gone

00:07:43,660 --> 00:07:48,730
we went on to virtualization and we

00:07:46,030 --> 00:07:52,200
would deploy VMs we would deploy we

00:07:48,730 --> 00:07:55,060
maybe we're now entering this phase of

00:07:52,200 --> 00:07:56,680
micro services or service oriented

00:07:55,060 --> 00:07:58,660
architecture we can call it whatever we

00:07:56,680 --> 00:08:01,200
want but it's a world where application

00:07:58,660 --> 00:08:03,880
developers deploy multiple times a day

00:08:01,200 --> 00:08:05,560
we've seen a lot of tooling improve a

00:08:03,880 --> 00:08:08,560
lot of tooling that provides automation

00:08:05,560 --> 00:08:10,450
but there's been infrastructure

00:08:08,560 --> 00:08:13,150
deployments to terraform ansible

00:08:10,450 --> 00:08:16,330
cfengine and so on we see containers

00:08:13,150 --> 00:08:19,420
evolve we see kubernetes coming up these

00:08:16,330 --> 00:08:22,360
are all tools which help us deliver and

00:08:19,420 --> 00:08:23,830
deploy applications quicker eventually

00:08:22,360 --> 00:08:25,540
if the goal that we can disrupt other

00:08:23,830 --> 00:08:28,030
businesses because our application teams

00:08:25,540 --> 00:08:30,360
can evolve faster if you look at

00:08:28,030 --> 00:08:33,580
networking though we have seen a move

00:08:30,360 --> 00:08:36,400
hardware appliances to servers in the

00:08:33,580 --> 00:08:38,650
world in the VM in the VM move we have

00:08:36,400 --> 00:08:41,169
not seen much after that so if you look

00:08:38,650 --> 00:08:43,719
at current for example cuban others

00:08:41,169 --> 00:08:47,200
networking solutions even kubernetes

00:08:43,719 --> 00:08:49,390
itself still maps to IP tables and IP

00:08:47,200 --> 00:08:51,370
tables I worked on IP tables myself for

00:08:49,390 --> 00:08:52,089
many many years my background as an OS

00:08:51,370 --> 00:08:54,040
kernel development

00:08:52,089 --> 00:08:56,290
I've done that for 15 years I know what

00:08:54,040 --> 00:08:59,110
iptables has been designed for has been

00:08:56,290 --> 00:09:02,170
designed as a firewall for servers so it

00:08:59,110 --> 00:09:03,879
filters on ports and eyepiece and I'm

00:09:02,170 --> 00:09:05,110
using IP tables here we could use any

00:09:03,879 --> 00:09:07,509
virtual switch here

00:09:05,110 --> 00:09:11,860
that's flow based it's based on IPs and

00:09:07,509 --> 00:09:13,749
ports so why is that not enough well if

00:09:11,860 --> 00:09:15,730
you're looking at this modern cloud

00:09:13,749 --> 00:09:19,809
native applications they would typically

00:09:15,730 --> 00:09:21,910
use a protocol such as G RPC rest Kafka

00:09:19,809 --> 00:09:23,529
and so on and what you typically see is

00:09:21,910 --> 00:09:25,329
that most of the communication between

00:09:23,529 --> 00:09:26,860
these containers or micro services is

00:09:25,329 --> 00:09:29,199
over port 18

00:09:26,860 --> 00:09:30,970
like if it's rest or chair PC which

00:09:29,199 --> 00:09:32,709
means that as you as a network engineer

00:09:30,970 --> 00:09:34,480
as you open up the port you basically

00:09:32,709 --> 00:09:36,279
open up everything right

00:09:34,480 --> 00:09:38,019
all of a sudden whether whoever can talk

00:09:36,279 --> 00:09:40,389
to whoever can basically use all of the

00:09:38,019 --> 00:09:43,300
functionality and this is a problem and

00:09:40,389 --> 00:09:45,759
I will talk you through a specific use

00:09:43,300 --> 00:09:47,889
case why this is the problem so in this

00:09:45,759 --> 00:09:49,540
example we'll look at Gordon for those

00:09:47,889 --> 00:09:51,339
of you don't know Gordon Gordon is one

00:09:49,540 --> 00:09:53,920
of the mascot mascots of docker

00:09:51,339 --> 00:09:55,689
so Gordon is an intern and has a

00:09:53,920 --> 00:09:58,689
brilliant idea right he sees that

00:09:55,689 --> 00:10:01,809
company struggling to to fulfill all of

00:09:58,689 --> 00:10:03,399
the hiring needs so he's he's on Twitter

00:10:01,809 --> 00:10:04,720
all day so he figures why don't they

00:10:03,399 --> 00:10:06,249
write a micro service that will

00:10:04,720 --> 00:10:09,579
basically tweet out all of the job

00:10:06,249 --> 00:10:11,259
openings that my company has so he goes

00:10:09,579 --> 00:10:13,179
along and he wants to create that micro

00:10:11,259 --> 00:10:15,459
service and in order to do that he needs

00:10:13,179 --> 00:10:17,740
to have access to the data of all all

00:10:15,459 --> 00:10:20,079
the job openings so what does he do he

00:10:17,740 --> 00:10:23,110
accesses an API which has the invictus

00:10:20,079 --> 00:10:24,879
information this information this API

00:10:23,110 --> 00:10:27,009
has a couple of API endpoints but all of

00:10:24,879 --> 00:10:28,720
you using kubernetes all of the service

00:10:27,009 --> 00:10:31,059
basically have this gets left health

00:10:28,720 --> 00:10:33,160
which which cubanelles will call to

00:10:31,059 --> 00:10:35,410
figure out whether a part is healthy it

00:10:33,160 --> 00:10:38,439
you can access it to to get the actual

00:10:35,410 --> 00:10:40,209
job postings the database also stores

00:10:38,439 --> 00:10:42,100
the applicants that applied for the job

00:10:40,209 --> 00:10:44,319
and you can actually create new jobs

00:10:42,100 --> 00:10:45,759
these jobs or his data might actually

00:10:44,319 --> 00:10:47,589
might be backed by something like

00:10:45,759 --> 00:10:49,870
MongoDB or something else all right so

00:10:47,589 --> 00:10:51,699
far so good so Gordon basically writes

00:10:49,870 --> 00:10:54,160
his micro services and for his purpose

00:10:51,699 --> 00:10:58,389
he needs to get access to the get slash

00:10:54,160 --> 00:11:00,579
jobs API to retrieve the job openings he

00:10:58,389 --> 00:11:03,069
goes along it because obviously Gordon

00:11:00,579 --> 00:11:05,860
is a good citizen and good a software

00:11:03,069 --> 00:11:08,920
locker so Gordon uses mutual TLS

00:11:05,860 --> 00:11:12,220
right good thinking Gordon developer

00:11:08,920 --> 00:11:13,329
etiquette super simple stuff does TLS

00:11:12,220 --> 00:11:15,730
buy us anything

00:11:13,329 --> 00:11:17,380
TLS basically says anything from this

00:11:15,730 --> 00:11:19,690
container this container from this app

00:11:17,380 --> 00:11:21,940
to this app is encrypted but it doesn't

00:11:19,690 --> 00:11:23,950
actually do anything on API called level

00:11:21,940 --> 00:11:26,500
that we can still do all of the API

00:11:23,950 --> 00:11:28,029
calls that we want so let's dive into

00:11:26,500 --> 00:11:29,589
the networking level so how will be

00:11:28,029 --> 00:11:32,260
secure and try to securities on a

00:11:29,589 --> 00:11:34,180
networking level if you apply something

00:11:32,260 --> 00:11:36,550
like a Cuban others Network policy it

00:11:34,180 --> 00:11:39,370
will get translated into an IP tables

00:11:36,550 --> 00:11:42,310
rule like this which says well this

00:11:39,370 --> 00:11:44,620
tweet service container has this IP so

00:11:42,310 --> 00:11:46,750
you can talk to this job's API container

00:11:44,620 --> 00:11:49,839
or jobs API service and you can do that

00:11:46,750 --> 00:11:51,220
on TCP on port 80 so this is how the

00:11:49,839 --> 00:11:53,380
rule will look like this is how your

00:11:51,220 --> 00:11:55,480
firewall will look like so this will

00:11:53,380 --> 00:11:57,779
allow the containers to talk but at the

00:11:55,480 --> 00:12:01,750
same time it exposes all of the API

00:11:57,779 --> 00:12:04,180
endpoints so if the intern for whatever

00:12:01,750 --> 00:12:05,649
reason introduces little bug and that

00:12:04,180 --> 00:12:07,360
application is misbehaving

00:12:05,649 --> 00:12:09,310
worst case scenario it can actually

00:12:07,360 --> 00:12:11,050
tweet out all the applicants that are

00:12:09,310 --> 00:12:13,300
played applied for that for that job

00:12:11,050 --> 00:12:15,519
which is definitely something that we

00:12:13,300 --> 00:12:17,470
don't want on the other hand the integer

00:12:15,519 --> 00:12:18,970
could also use this API to even create a

00:12:17,470 --> 00:12:23,290
job if he wants to stay at the company

00:12:18,970 --> 00:12:25,120
but it's definitely not least privileged

00:12:23,290 --> 00:12:26,800
security like this is definitely not

00:12:25,120 --> 00:12:28,329
least privileged security so what can we

00:12:26,800 --> 00:12:31,240
do about this and this is the problem

00:12:28,329 --> 00:12:32,920
we're solving we're saying let's go back

00:12:31,240 --> 00:12:35,230
to the drawing board what we want is

00:12:32,920 --> 00:12:36,910
something very simple which is I want

00:12:35,230 --> 00:12:38,680
containers to talk to each other pulse

00:12:36,910 --> 00:12:41,529
to talk to each other but I want to

00:12:38,680 --> 00:12:43,720
expose the least amount of api service

00:12:41,529 --> 00:12:46,690
possible so least privileged security on

00:12:43,720 --> 00:12:48,490
api call level so in this example we

00:12:46,690 --> 00:12:50,980
allow the tweet service to talk to the

00:12:48,490 --> 00:12:53,440
job it's jobs api service but it can

00:12:50,980 --> 00:12:55,690
only do the get to slash jobs api call

00:12:53,440 --> 00:12:58,449
if it attempts to do the other api calls

00:12:55,690 --> 00:13:00,519
we will block this so even if the intern

00:12:58,449 --> 00:13:02,579
screws up you cannot leak the data such

00:13:00,519 --> 00:13:06,279
as applicants data or create new jobs

00:13:02,579 --> 00:13:08,019
all right sounds neat right we want a

00:13:06,279 --> 00:13:11,589
demo and this is this is open source

00:13:08,019 --> 00:13:13,800
uninstall demo so the demo I'm about to

00:13:11,589 --> 00:13:13,800
shoot

00:13:13,890 --> 00:13:20,459
kubernetes faced who think cuba netis or

00:13:17,310 --> 00:13:23,519
is planning to use kubernetes right

00:13:20,459 --> 00:13:26,149
about half the hands does somebody have

00:13:23,519 --> 00:13:27,300
no clue at all about cuba cuban Eddie's

00:13:26,149 --> 00:13:28,380
awesome

00:13:27,300 --> 00:13:29,610
all right don't needed work you bananas

00:13:28,380 --> 00:13:32,279
in topic I said I would have really

00:13:29,610 --> 00:13:34,709
struggle to do that but yeah it could

00:13:32,279 --> 00:13:36,990
where's in a minor nutshell what one

00:13:34,709 --> 00:13:39,420
word one sentence it allows you to run

00:13:36,990 --> 00:13:41,670
Cuba net allows you to run containers at

00:13:39,420 --> 00:13:43,740
scale on multiple notes and it will

00:13:41,670 --> 00:13:47,610
orchestrate all of this and takes away a

00:13:43,740 --> 00:13:51,930
lot management burden right so this demo

00:13:47,610 --> 00:13:53,660
is a demo that has a scene so let's look

00:13:51,930 --> 00:13:56,160
at that

00:13:53,660 --> 00:13:58,410
some of you may remember his intro a

00:13:56,160 --> 00:14:01,529
long time ago in a container cluster far

00:13:58,410 --> 00:14:03,990
far away is a period of World War the

00:14:01,529 --> 00:14:05,190
Empire has adopted micro-services and

00:14:03,990 --> 00:14:08,279
continuous delivery

00:14:05,190 --> 00:14:10,170
despite this rebel spaceships striking

00:14:08,279 --> 00:14:11,880
from a hidden cluster have won their

00:14:10,170 --> 00:14:14,640
first victory against the evil Galactic

00:14:11,880 --> 00:14:16,890
Empire during the battle rebel spies

00:14:14,640 --> 00:14:19,680
managed to steal the swagger API

00:14:16,890 --> 00:14:22,260
specification of the Empire's ultimate

00:14:19,680 --> 00:14:25,769
weapon the Death Star so this is the

00:14:22,260 --> 00:14:28,290
intro to our demo and what I have here

00:14:25,769 --> 00:14:30,269
is basically this is my laptop VM and I

00:14:28,290 --> 00:14:33,690
have a mini cube which is basically a

00:14:30,269 --> 00:14:37,490
entire Cuban Etta's cluster fitted into

00:14:33,690 --> 00:14:37,490
one VM so I have a full

00:14:37,830 --> 00:14:43,290
and right now is one know my VM I have

00:14:40,560 --> 00:14:44,550
nothing running so let's do it get parts

00:14:43,290 --> 00:14:47,220
this would be the containers running I

00:14:44,550 --> 00:14:50,190
have nothing running so there as a first

00:14:47,220 --> 00:14:51,750
step I will deploy that far right so

00:14:50,190 --> 00:14:53,910
that's the Empire wants to deploy def

00:14:51,750 --> 00:14:55,260
star what is the death star a def store

00:14:53,910 --> 00:14:56,670
is a service which is basically the

00:14:55,260 --> 00:14:59,070
local engine construct that's not

00:14:56,670 --> 00:15:01,200
important here and it has a deployment

00:14:59,070 --> 00:15:03,269
which is a way of describing I want to

00:15:01,200 --> 00:15:06,450
deploy in container or a part

00:15:03,269 --> 00:15:09,420
what's important is use labels along

00:15:06,450 --> 00:15:11,880
this demo so the Death Star has labels

00:15:09,420 --> 00:15:15,899
and it's a long story organization

00:15:11,880 --> 00:15:18,060
Empire and it's has a class it's and

00:15:15,899 --> 00:15:19,589
then down here you basically describe

00:15:18,060 --> 00:15:23,579
what type of container I'm running I'm

00:15:19,589 --> 00:15:25,500
running a Star Wars container image so

00:15:23,579 --> 00:15:29,220
let's deploy that this is how you deploy

00:15:25,500 --> 00:15:31,950
in Cuban Aries cool so this is deploy

00:15:29,220 --> 00:15:35,279
now the DEF store is getting constructed

00:15:31,950 --> 00:15:36,950
we now want to have spaceships land on

00:15:35,279 --> 00:15:39,990
the Death Star

00:15:36,950 --> 00:15:41,850
so spaceships are basically containers

00:15:39,990 --> 00:15:44,430
as well so this is our different of a

00:15:41,850 --> 00:15:47,310
spaceship it's a container image and

00:15:44,430 --> 00:15:53,279
that container has labels so it's

00:15:47,310 --> 00:15:58,560
orbiting Empire and class spaceship so

00:15:53,279 --> 00:16:00,660
let's create that as well you can now

00:15:58,560 --> 00:16:03,600
get these and they should be coming up

00:16:00,660 --> 00:16:05,970
so they're still creating in them and

00:16:03,600 --> 00:16:08,579
while these are spinning up the we want

00:16:05,970 --> 00:16:11,279
to establish a policy so we want to have

00:16:08,579 --> 00:16:12,060
or we want to allow spaceships to talk

00:16:11,279 --> 00:16:13,950
to the Death Star

00:16:12,060 --> 00:16:17,190
how do we do that in kubernetes you do

00:16:13,950 --> 00:16:18,589
this with policy and a policy could look

00:16:17,190 --> 00:16:22,170
something like this

00:16:18,589 --> 00:16:24,990
the policy simply basically says this

00:16:22,170 --> 00:16:28,040
policy applies to all parts which have

00:16:24,990 --> 00:16:31,980
two labels Empire the class test or

00:16:28,040 --> 00:16:34,440
organization Empire and you can talk to

00:16:31,980 --> 00:16:36,779
me if you have to label class spaceship

00:16:34,440 --> 00:16:39,980
so there's no IP addresses we do policy

00:16:36,779 --> 00:16:39,980
through labels

00:16:41,150 --> 00:16:53,560
so I'm going to imply that I don't offer

00:16:50,300 --> 00:16:53,560
Wi-Fi let's see

00:17:03,110 --> 00:17:08,050
not missing part I see why it's not

00:17:05,630 --> 00:17:08,050
coming up

00:17:11,770 --> 00:17:17,500
all right let's let's start over let's

00:17:13,870 --> 00:17:22,089
try again you're not even at the selling

00:17:17,500 --> 00:17:25,980
part yet so what you get with bleeding

00:17:22,089 --> 00:17:25,980
edge technology and doing a live demo

00:17:32,100 --> 00:17:40,590
all right cool let's try again okay

00:17:46,750 --> 00:17:52,280
achieve this doesn't comment it will not

00:17:49,760 --> 00:17:53,450
sure why maybe the Wi-Fi is very slow so

00:17:52,280 --> 00:17:54,740
what's happening if you're on a

00:17:53,450 --> 00:17:56,570
container it will actually check with

00:17:54,740 --> 00:17:58,789
DDOT with you container registry where

00:17:56,570 --> 00:18:01,730
Ares and your image may be able so this

00:17:58,789 --> 00:18:03,799
is typically while why dock related demo

00:18:01,730 --> 00:18:08,090
fail on stage because you don't have

00:18:03,799 --> 00:18:09,950
Wi-Fi in case it's failing we've did

00:18:08,090 --> 00:18:11,630
this demo a talker con there's video

00:18:09,950 --> 00:18:13,400
recordings or worse case I will refer

00:18:11,630 --> 00:18:16,990
you to the video recording it doesn't

00:18:13,400 --> 00:18:16,990
doesn't look like it will be coming up

00:18:17,350 --> 00:18:24,440
alright sorry about that let's let's go

00:18:20,570 --> 00:18:26,390
back so what is psyllium well actually

00:18:24,440 --> 00:18:27,530
let me let me talk you through what what

00:18:26,390 --> 00:18:28,640
the dam would actually have showed you

00:18:27,530 --> 00:18:31,970
it what I've showed you that we can

00:18:28,640 --> 00:18:33,830
import a layer 3 policy and lay a four

00:18:31,970 --> 00:18:36,280
policy to have containers or pots talk

00:18:33,830 --> 00:18:38,870
to each other but then we also support

00:18:36,280 --> 00:18:41,419
importing layer 7 policies some of you

00:18:38,870 --> 00:18:43,520
have may have come by our booth and saw

00:18:41,419 --> 00:18:47,530
how we basically used layer 7 policy

00:18:43,520 --> 00:18:51,140
secure communication on API call level

00:18:47,530 --> 00:18:54,200
so how do we do this we as I enjoy we

00:18:51,140 --> 00:18:55,580
certainly was all about BPF so what

00:18:54,200 --> 00:18:58,850
what's the purpose of psyllium what does

00:18:55,580 --> 00:19:01,580
the psyllium do psyllium runs as a agent

00:18:58,850 --> 00:19:04,429
on all of your servers in the kubernetes

00:19:01,580 --> 00:19:07,610
case this would deploy nibbly deployment

00:19:04,429 --> 00:19:10,309
deployed as a daemon so running as a pod

00:19:07,610 --> 00:19:14,450
on all your servers it would then

00:19:10,309 --> 00:19:17,390
generate PPF bytecode BPF programs and

00:19:14,450 --> 00:19:19,760
inject them into the kernel so what is p

00:19:17,390 --> 00:19:22,250
PF or what what can you do with p PF p

00:19:19,760 --> 00:19:24,250
PF allows you to inject bytecode in the

00:19:22,250 --> 00:19:26,510
kernel and extend the kernel at runtime

00:19:24,250 --> 00:19:28,549
while doing so it goes through a

00:19:26,510 --> 00:19:31,539
verifier so the kernel ensures that you

00:19:28,549 --> 00:19:34,309
cannot crash the kernel you could not

00:19:31,539 --> 00:19:36,919
you have to run to completion and so on

00:19:34,309 --> 00:19:39,230
so it it's basically similar to a kernel

00:19:36,919 --> 00:19:41,210
module but you cannot crash the kernel

00:19:39,230 --> 00:19:42,770
because it goes through a verifier so

00:19:41,210 --> 00:19:47,450
it's basically the next generation of

00:19:42,770 --> 00:19:49,429
making the kernel extendable the

00:19:47,450 --> 00:19:51,650
bytecode after verification go through a

00:19:49,429 --> 00:19:56,090
JIT compiler and just-in-time compiler

00:19:51,650 --> 00:19:58,280
which the BPF bytecode and translates it

00:19:56,090 --> 00:19:59,180
to the instructions that your CPU

00:19:58,280 --> 00:20:03,080
understand so

00:19:59,180 --> 00:20:04,700
the DPF program in the end as x86

00:20:03,080 --> 00:20:06,140
instructions or arm instructions so

00:20:04,700 --> 00:20:10,010
there is no overhead in terms of

00:20:06,140 --> 00:20:13,400
performance so this is our data path or

00:20:10,010 --> 00:20:15,050
our our kernel side the upper side is

00:20:13,400 --> 00:20:17,390
basically how we integrate with the rest

00:20:15,050 --> 00:20:19,100
of the world so we have a CLI which

00:20:17,390 --> 00:20:21,350
basically allows you to retrieve

00:20:19,100 --> 00:20:24,020
debugging information and so on we have

00:20:21,350 --> 00:20:25,730
a policy repository this could be your

00:20:24,020 --> 00:20:27,410
kubernetes control place or this could

00:20:25,730 --> 00:20:30,740
be given artists resources or it could

00:20:27,410 --> 00:20:32,510
be a key value store we have plugins we

00:20:30,740 --> 00:20:35,179
have plugins for kubernetes for

00:20:32,510 --> 00:20:38,390
mesosphere for darker we have plugins

00:20:35,179 --> 00:20:40,429
for different container runtimes and so

00:20:38,390 --> 00:20:42,590
on this is how you interact or integrate

00:20:40,429 --> 00:20:44,360
with the rest of the world and we have a

00:20:42,590 --> 00:20:46,640
cilium monitor this is the monitoring

00:20:44,360 --> 00:20:48,980
component which can listen to events

00:20:46,640 --> 00:20:51,740
that happen on the data path so for

00:20:48,980 --> 00:20:54,020
example whenever a cilium drops a packet

00:20:51,740 --> 00:20:56,480
or a request because of policy we will

00:20:54,020 --> 00:20:59,059
generate an event in through a framework

00:20:56,480 --> 00:21:01,090
called perf ring buffer this perf ring

00:20:59,059 --> 00:21:03,170
buffer is coming out of this tracing and

00:21:01,090 --> 00:21:05,270
profiling revolution in the kernel and

00:21:03,170 --> 00:21:07,850
it's a very fast data structure we can

00:21:05,270 --> 00:21:09,350
expose millions of events per second

00:21:07,850 --> 00:21:11,510
through this so this is radically

00:21:09,350 --> 00:21:13,059
changing how we can give visibility into

00:21:11,510 --> 00:21:15,530
what's happening

00:21:13,059 --> 00:21:16,730
running TCP dump in a production why I

00:21:15,530 --> 00:21:19,970
mean it's definitely not something that

00:21:16,730 --> 00:21:21,920
you want to do running iptables jelly

00:21:19,970 --> 00:21:23,990
lock is something that you don't want to

00:21:21,920 --> 00:21:25,970
do but this has low overhead this is

00:21:23,990 --> 00:21:27,830
something that you can do and you can

00:21:25,970 --> 00:21:29,809
you can run this where needed and when

00:21:27,830 --> 00:21:31,490
you stop running it the overhead will be

00:21:29,809 --> 00:21:33,440
gone so it's basically something that

00:21:31,490 --> 00:21:34,790
you can start monitoring and gaining

00:21:33,440 --> 00:21:37,790
visibility into your production

00:21:34,790 --> 00:21:40,490
workloads a very nice property of this

00:21:37,790 --> 00:21:43,670
BPF cogeneration is that we can replace

00:21:40,490 --> 00:21:45,950
these programs at runtime without any

00:21:43,670 --> 00:21:47,690
disruption which means that and this

00:21:45,950 --> 00:21:50,600
we've done this a couple of times we

00:21:47,690 --> 00:21:52,370
find a bug we can fix it and we can

00:21:50,600 --> 00:21:54,740
deploy it not a single connection was

00:21:52,370 --> 00:21:57,200
lost so basically how does this work we

00:21:54,740 --> 00:21:59,120
we compile a new program we verify it

00:21:57,200 --> 00:22:00,770
gets cheese compiled and then it the

00:21:59,120 --> 00:22:03,350
program gets replaced in a so called

00:22:00,770 --> 00:22:05,090
atomic operation none of the state is

00:22:03,350 --> 00:22:07,190
lost this is really changing how we can

00:22:05,090 --> 00:22:09,710
do how we can do in our key what does it

00:22:07,190 --> 00:22:11,240
allow us to do it allows us to do hot

00:22:09,710 --> 00:22:12,390
fixing it allows us to basically if

00:22:11,240 --> 00:22:15,090
something is not working

00:22:12,390 --> 00:22:17,880
we can compile in debug instructions on

00:22:15,090 --> 00:22:20,070
the fly I'm a kernel developer how do

00:22:17,880 --> 00:22:21,930
you depart kernels you add print Kate

00:22:20,070 --> 00:22:23,790
printf equivalent statements

00:22:21,930 --> 00:22:25,620
you recompile you reboot the machine and

00:22:23,790 --> 00:22:27,540
try to reproduce what we can do in

00:22:25,620 --> 00:22:29,880
studies we can compile in this d box to

00:22:27,540 --> 00:22:31,830
debug statements without change without

00:22:29,880 --> 00:22:33,660
rebooting so the problem is still

00:22:31,830 --> 00:22:35,700
occurring we can debug it live or we can

00:22:33,660 --> 00:22:38,100
even hotfix it live so this is a

00:22:35,700 --> 00:22:41,430
completely new way of doing kernel level

00:22:38,100 --> 00:22:42,810
of nor nor kingdom load so I talked a

00:22:41,430 --> 00:22:46,350
little bit about our kubernetes

00:22:42,810 --> 00:22:48,960
integration we basically integrate with

00:22:46,350 --> 00:22:50,850
the standard resources I'm listing them

00:22:48,960 --> 00:22:53,670
here so now policy in our policy was

00:22:50,850 --> 00:22:57,600
recently declared GA part of the

00:22:53,670 --> 00:23:00,210
official cubes resource API with NOC

00:22:57,600 --> 00:23:03,030
policy you can define layer 3 and layer

00:23:00,210 --> 00:23:05,160
4 Ingres network policy you can say this

00:23:03,030 --> 00:23:07,080
part can talk to this part we can say

00:23:05,160 --> 00:23:09,450
you can talk to me on port 80 and so on

00:23:07,080 --> 00:23:11,130
right now you could not define egress

00:23:09,450 --> 00:23:13,320
policy but this has been worked on right

00:23:11,130 --> 00:23:15,660
now and will most likely be included in

00:23:13,320 --> 00:23:18,240
the next release right now you cannot

00:23:15,660 --> 00:23:19,890
define egress side rules for example but

00:23:18,240 --> 00:23:22,860
this will also be clearly included in

00:23:19,890 --> 00:23:24,420
the next couple of releases we also as

00:23:22,860 --> 00:23:26,520
on dimensional in the in the last

00:23:24,420 --> 00:23:28,620
session we also implement services when

00:23:26,520 --> 00:23:31,950
we say services we implement a part two

00:23:28,620 --> 00:23:33,720
part services IP tables so typically

00:23:31,950 --> 00:23:35,730
this is done by IP tables there's a

00:23:33,720 --> 00:23:38,730
distinctive disadvantage if you do this

00:23:35,730 --> 00:23:42,720
by using IP tables for every service to

00:23:38,730 --> 00:23:45,150
define cube proxy will inject about 5 IP

00:23:42,720 --> 00:23:47,070
tables roles what our IP tables rules

00:23:45,150 --> 00:23:49,500
there are is like a sequential list of

00:23:47,070 --> 00:23:51,410
rules that every packet walks through so

00:23:49,500 --> 00:23:54,330
as you scale up the number of services

00:23:51,410 --> 00:23:57,390
it will get slower and slower and slower

00:23:54,330 --> 00:23:59,460
and slower with PPF this is a hash table

00:23:57,390 --> 00:24:01,890
the cost is exactly the same whether

00:23:59,460 --> 00:24:03,630
it's one service or 50,000 services it's

00:24:01,890 --> 00:24:05,340
exactly the same even our policy

00:24:03,630 --> 00:24:07,260
enforcement it's a hash table it's the

00:24:05,340 --> 00:24:09,480
same the numbers look the same better we

00:24:07,260 --> 00:24:12,410
have one rule or 5,000 or 10,000 rules

00:24:09,480 --> 00:24:15,300
so we're we're doing we're redoing

00:24:12,410 --> 00:24:17,040
networking with a scope of micro

00:24:15,300 --> 00:24:19,200
services where we have hyper scale and

00:24:17,040 --> 00:24:23,130
you're talking to hundreds of thousands

00:24:19,200 --> 00:24:24,900
of endpoints eventually we recognize

00:24:23,130 --> 00:24:26,880
parts why do we need to even

00:24:24,900 --> 00:24:28,830
all that part we look at parts and we'd

00:24:26,880 --> 00:24:30,930
read the labels of the pot so this is

00:24:28,830 --> 00:24:32,700
how you define a policy we saw this in

00:24:30,930 --> 00:24:33,930
the first two minutes of the demo this

00:24:32,700 --> 00:24:35,820
is how you define a policy you don't

00:24:33,930 --> 00:24:38,550
define a policy based on IP addresses

00:24:35,820 --> 00:24:40,230
you say any container if the label foo

00:24:38,550 --> 00:24:41,970
can talk to any container of the label

00:24:40,230 --> 00:24:44,040
bar you don't care if you're running one

00:24:41,970 --> 00:24:46,410
container or 10,000 containers from a

00:24:44,040 --> 00:24:49,860
policy perspective you don't care it

00:24:46,410 --> 00:24:52,350
doesn't matter we integrate with notes

00:24:49,860 --> 00:24:53,940
so why do we need notes we actually have

00:24:52,350 --> 00:24:56,640
what we call a zero configuration

00:24:53,940 --> 00:24:58,650
networking mode where instead of using

00:24:56,640 --> 00:25:00,510
an external key value store or something

00:24:58,650 --> 00:25:03,210
we basically just use kubernetes as the

00:25:00,510 --> 00:25:05,640
control plane what does that mean

00:25:03,210 --> 00:25:07,800
it means that as andre explained as well

00:25:05,640 --> 00:25:10,740
as last session we how do we know about

00:25:07,800 --> 00:25:12,180
what nodes host which outsiders what are

00:25:10,740 --> 00:25:15,360
the IP addresses that are used another

00:25:12,180 --> 00:25:17,280
host we use the cube netis control plane

00:25:15,360 --> 00:25:19,680
to do this so instead of inventing our

00:25:17,280 --> 00:25:23,340
own we basically leverage and use

00:25:19,680 --> 00:25:26,460
communities for this and last but not

00:25:23,340 --> 00:25:29,010
least now our policy does not allow you

00:25:26,460 --> 00:25:32,040
to do egress it doesn't allow you to do

00:25:29,010 --> 00:25:34,760
layer 7 yet we are working on extending

00:25:32,040 --> 00:25:37,560
this and making this a core property of

00:25:34,760 --> 00:25:39,660
that policy in the meantime we offer a

00:25:37,560 --> 00:25:40,530
custom resource definition this was

00:25:39,660 --> 00:25:42,630
previously called

00:25:40,530 --> 00:25:46,620
third-party resource it's Kuban ettus

00:25:42,630 --> 00:25:48,900
way of allowing evolution or development

00:25:46,620 --> 00:25:51,150
pre standards so we can basically

00:25:48,900 --> 00:25:52,440
everybody can define this and use them

00:25:51,150 --> 00:25:55,650
and then what makes sense eventually

00:25:52,440 --> 00:25:58,350
gets into the standardized EPS so this

00:25:55,650 --> 00:26:01,800
is how you can use kubernetes and layer

00:25:58,350 --> 00:26:03,270
7 policy today what do we do before

00:26:01,800 --> 00:26:05,010
networking and this is the big question

00:26:03,270 --> 00:26:06,540
that everybody's asking if I'm doing

00:26:05,010 --> 00:26:08,580
multi know networking should I use an

00:26:06,540 --> 00:26:11,040
encapsulation protocol or should I do

00:26:08,580 --> 00:26:13,050
direct routing so cilium supports both

00:26:11,040 --> 00:26:15,000
we have an overlay mode and this is

00:26:13,050 --> 00:26:17,250
default which basically means that you

00:26:15,000 --> 00:26:19,230
create a so-called overlay or UDP

00:26:17,250 --> 00:26:21,240
encapsulation between all the nodes so

00:26:19,230 --> 00:26:23,550
it's basically a tunnel you hide the

00:26:21,240 --> 00:26:27,060
part IPS from your underlying network

00:26:23,550 --> 00:26:30,330
this is easy works out of the box but

00:26:27,060 --> 00:26:32,310
there is a performance penalty it's very

00:26:30,330 --> 00:26:33,900
simple to set up you basically run the

00:26:32,310 --> 00:26:35,940
cube controller manage manager with the

00:26:33,900 --> 00:26:37,559
allocate node ciders and

00:26:35,940 --> 00:26:39,090
Cuban artists will automatically handle

00:26:37,559 --> 00:26:40,950
all of this so this is the only thing

00:26:39,090 --> 00:26:43,230
you have to provide your psyllium and it

00:26:40,950 --> 00:26:47,070
will have Knowlton no networking

00:26:43,230 --> 00:26:51,660
easy but overhead so use case is

00:26:47,070 --> 00:26:55,220
typically PLC or if if you don't care

00:26:51,660 --> 00:26:58,500
about the last percent of performance

00:26:55,220 --> 00:27:00,120
the second mode native routing mode is

00:26:58,500 --> 00:27:02,010
basically the mode where you're running

00:27:00,120 --> 00:27:03,630
a routing daemon or you won't use the

00:27:02,010 --> 00:27:06,030
cloud providers routing functionality

00:27:03,630 --> 00:27:08,460
this case psyllium basically just gives

00:27:06,030 --> 00:27:10,530
the packet to the router to Linux you

00:27:08,460 --> 00:27:12,000
know what to do either the cloud or the

00:27:10,530 --> 00:27:13,740
cloud provider knows how to do with this

00:27:12,000 --> 00:27:15,690
or you're running a like a routing

00:27:13,740 --> 00:27:18,510
protocol and two routing protocol

00:27:15,690 --> 00:27:21,419
disputes all the route typically what

00:27:18,510 --> 00:27:22,980
you just do what you do post POC you and

00:27:21,419 --> 00:27:24,419
you know what you're doing and you're

00:27:22,980 --> 00:27:26,850
setting everything up for production

00:27:24,419 --> 00:27:29,370
it's faster and the network actually

00:27:26,850 --> 00:27:31,289
knows East apartheid peace I will go

00:27:29,370 --> 00:27:33,980
into more details here but basically the

00:27:31,289 --> 00:27:37,919
bottom line is you can run with psyllium

00:27:33,980 --> 00:27:39,600
so how are policies actually defined we

00:27:37,919 --> 00:27:42,440
saw this in the first part of the demo

00:27:39,600 --> 00:27:44,549
this is a l3 label based policy

00:27:42,440 --> 00:27:46,860
basically there's lots of information

00:27:44,549 --> 00:27:49,140
here what really matters is this part

00:27:46,860 --> 00:27:51,600
and this part so the plot this part of

00:27:49,140 --> 00:27:53,549
the policy says this policy applies to

00:27:51,600 --> 00:27:55,950
all parts which have to label stuff

00:27:53,549 --> 00:27:58,679
store and Empire right and then you say

00:27:55,950 --> 00:28:00,950
all parts with the label class spaceship

00:27:58,679 --> 00:28:03,720
can talk to this so this is how you do

00:28:00,950 --> 00:28:08,400
connectivity layer three part two part

00:28:03,720 --> 00:28:10,950
very simple what do you do if you want

00:28:08,400 --> 00:28:13,350
to for example limit access to external

00:28:10,950 --> 00:28:15,419
services for example you have a micro

00:28:13,350 --> 00:28:17,970
services which which uses stripe comm

00:28:15,419 --> 00:28:20,070
services you don't want that Microsoft

00:28:17,970 --> 00:28:21,870
to be to reach the entire world you want

00:28:20,070 --> 00:28:24,720
to limit it to what it what it needs

00:28:21,870 --> 00:28:27,059
like lease privilege in this case we're

00:28:24,720 --> 00:28:30,450
saying this policy applies to all all

00:28:27,059 --> 00:28:33,750
parts with spaceship and Empire and you

00:28:30,450 --> 00:28:36,659
can only talk to the external IP 8888

00:28:33,750 --> 00:28:38,520
Google's DNS server so this this policy

00:28:36,659 --> 00:28:42,289
would allow the partner to talk to the

00:28:38,520 --> 00:28:42,289
Google DNS server but not

00:28:44,310 --> 00:28:50,460
i'ma try to rearrange this all right al

00:28:47,970 --> 00:28:52,380
for Policy same principle you have this

00:28:50,460 --> 00:28:54,060
selector which selects the parts that

00:28:52,380 --> 00:28:58,020
work should apply to and then you say

00:28:54,060 --> 00:28:59,520
you can only talk going on port 80 TCP

00:28:58,020 --> 00:29:00,750
so you cannot for example use a

00:28:59,520 --> 00:29:03,510
different port when you're talking

00:29:00,750 --> 00:29:05,040
outside and so actually it is ingress so

00:29:03,510 --> 00:29:09,270
this is incoming you can only be talked

00:29:05,040 --> 00:29:11,070
to on port TCP and then layer seven this

00:29:09,270 --> 00:29:13,020
is the part where the demo would have

00:29:11,070 --> 00:29:15,360
been awesome because it was that it was

00:29:13,020 --> 00:29:17,940
starburst seemed this this basically

00:29:15,360 --> 00:29:20,760
says is an extension for the of the

00:29:17,940 --> 00:29:24,570
layer four rule and it says you can do

00:29:20,760 --> 00:29:25,560
these two API calls only so you can talk

00:29:24,570 --> 00:29:29,700
port 80

00:29:25,560 --> 00:29:32,970
TCP and you can only get two /we one or

00:29:29,700 --> 00:29:37,080
you can do a put two slash exhaust port

00:29:32,970 --> 00:29:39,570
if half the HTTP header X has forced

00:29:37,080 --> 00:29:41,070
true set so some of you may know this

00:29:39,570 --> 00:29:42,750
read a dog the better demo was going it

00:29:41,070 --> 00:29:43,980
was definitely some def start

00:29:42,750 --> 00:29:45,690
construction was with definitely I've

00:29:43,980 --> 00:29:49,860
been going on so this is how you can how

00:29:45,690 --> 00:29:51,930
you can define layer seven policy how

00:29:49,860 --> 00:29:54,870
are these policy is enforced so we

00:29:51,930 --> 00:29:58,260
talked about BPF are we using only DPR

00:29:54,870 --> 00:30:00,930
for this for the layer 3 layer 4 part

00:29:58,260 --> 00:30:05,760
it's all DPF the kernel can do this

00:30:00,930 --> 00:30:07,350
today right now layer 7 policies where

00:30:05,760 --> 00:30:09,930
can do this we will be able to do this

00:30:07,350 --> 00:30:11,550
in BPF right now we're using a sidecar

00:30:09,930 --> 00:30:15,870
proxy for this I will explain what a

00:30:11,550 --> 00:30:17,940
sidecar proxy is so what is the sidecar

00:30:15,870 --> 00:30:20,820
proxy a cycle proxy is basically if you

00:30:17,940 --> 00:30:24,240
have two services talking to you run a

00:30:20,820 --> 00:30:26,580
proxy as a sidecar next to them so

00:30:24,240 --> 00:30:29,880
basically you place a proxy in accident

00:30:26,580 --> 00:30:32,640
and then all communication goes first

00:30:29,880 --> 00:30:35,040
through the proxy proxy to proxy and

00:30:32,640 --> 00:30:38,040
then proxy to service this is what is

00:30:35,040 --> 00:30:41,250
called a services mash as well some of

00:30:38,040 --> 00:30:45,390
you might have heard of sto Envoy linker

00:30:41,250 --> 00:30:47,850
D some people have nginx and H a proxy

00:30:45,390 --> 00:30:49,080
beforehand what this allows to do is

00:30:47,850 --> 00:30:51,380
basically provide networking

00:30:49,080 --> 00:30:53,520
functionality on layer 7 so I can do

00:30:51,380 --> 00:30:56,580
HTTP our local ancing

00:30:53,520 --> 00:30:59,550
I can say if I do local ancing and my

00:30:56,580 --> 00:31:02,630
request to the back-end fails I can try

00:30:59,550 --> 00:31:05,430
another one I gain visibility

00:31:02,630 --> 00:31:07,590
latency data I do into I get tracing

00:31:05,430 --> 00:31:10,640
information and so on so right now this

00:31:07,590 --> 00:31:13,620
services mesh is not focused on security

00:31:10,640 --> 00:31:15,900
just on load balancing routing and so on

00:31:13,620 --> 00:31:17,700
but you can use this technology to do to

00:31:15,900 --> 00:31:21,060
enforce security and this is what we use

00:31:17,700 --> 00:31:22,710
it for so how does this look like on the

00:31:21,060 --> 00:31:25,080
networking level it basically means that

00:31:22,710 --> 00:31:26,730
all traffic goes out of the socket a TCP

00:31:25,080 --> 00:31:28,830
down here this is basically coral and

00:31:26,730 --> 00:31:31,110
down here you have an IP tables rule or

00:31:28,830 --> 00:31:32,730
a PPF rule that basically redirects

00:31:31,110 --> 00:31:35,040
everything back to the proxy the proxy

00:31:32,730 --> 00:31:36,570
does whatever it has to do sends it out

00:31:35,040 --> 00:31:38,460
it goes over the network and it goes

00:31:36,570 --> 00:31:40,470
through a psycho proxy here as well so

00:31:38,460 --> 00:31:43,640
basically from service to service you're

00:31:40,470 --> 00:31:46,440
going through the TCP stack 6 times

00:31:43,640 --> 00:31:48,480
that's it times the number of memory

00:31:46,440 --> 00:31:50,940
resources and this is non-trivial if

00:31:48,480 --> 00:31:52,650
you're running that's a public cloud

00:31:50,940 --> 00:31:54,960
provider images you may have to bump the

00:31:52,650 --> 00:31:59,340
image size just because the memory needs

00:31:54,960 --> 00:32:01,380
or bigger so your bill will increase the

00:31:59,340 --> 00:32:04,770
latency is how big because you're going

00:32:01,380 --> 00:32:06,030
through TCP stacks multiple time context

00:32:04,770 --> 00:32:08,310
switches this is basically switching

00:32:06,030 --> 00:32:09,930
back between Crowell and users face this

00:32:08,310 --> 00:32:12,810
adds latency and there's a ton of

00:32:09,930 --> 00:32:14,970
complexity but most previously one

00:32:12,810 --> 00:32:16,590
connection is now three TCP connections

00:32:14,970 --> 00:32:18,540
to have two services talk to each other

00:32:16,590 --> 00:32:21,300
so can we do something about this and

00:32:18,540 --> 00:32:23,550
this is what or can be turned a side car

00:32:21,300 --> 00:32:26,220
into a race car and this is where k

00:32:23,550 --> 00:32:30,480
proxy comes in Zork a proxy is kernel

00:32:26,220 --> 00:32:32,370
proxy K proxy basically brings some of

00:32:30,480 --> 00:32:35,370
this sidecar functionality into the

00:32:32,370 --> 00:32:37,140
kernel basically at the socket layer so

00:32:35,370 --> 00:32:38,940
this is what applications use to talk to

00:32:37,140 --> 00:32:41,370
each other if they do if they run TCP

00:32:38,940 --> 00:32:44,580
and this is where we basically would

00:32:41,370 --> 00:32:47,670
look at this payload with PPF and make a

00:32:44,580 --> 00:32:51,570
decision or ad localizing function layer

00:32:47,670 --> 00:32:53,220
or anything at this at this layer if you

00:32:51,570 --> 00:32:55,770
look at this picture this is very simple

00:32:53,220 --> 00:32:56,400
I one T or two TCP stack traversals you

00:32:55,770 --> 00:32:58,680
go over the network

00:32:56,400 --> 00:33:00,870
simple then the question came up like

00:32:58,680 --> 00:33:02,760
all right what about SSL TLS what is

00:33:00,870 --> 00:33:04,680
what if my application is you and to end

00:33:02,760 --> 00:33:06,750
encryption how can I handle that and

00:33:04,680 --> 00:33:10,110
this is why this was not possible

00:33:06,750 --> 00:33:12,960
previously but recently k TLS colonel

00:33:10,110 --> 00:33:16,020
Els was merged Katie Ellis - Katie Ellis

00:33:12,960 --> 00:33:18,480
allows the colonel to take over the

00:33:16,020 --> 00:33:21,870
symmetric encryption part which means

00:33:18,480 --> 00:33:24,090
open SSL the library will still do the

00:33:21,870 --> 00:33:25,530
handshake the where all the Box in the

00:33:24,090 --> 00:33:27,360
code are so basically in all the

00:33:25,530 --> 00:33:28,559
exploits that we saw over the last 15

00:33:27,360 --> 00:33:31,200
years they were all in the control

00:33:28,559 --> 00:33:33,809
handshake part and then once you have

00:33:31,200 --> 00:33:35,580
negotiated everything you pass down the

00:33:33,809 --> 00:33:37,080
key to the kernel and the kernel will do

00:33:35,580 --> 00:33:39,420
the actual encryption that is the

00:33:37,080 --> 00:33:42,059
expensive part you gain about 3/4

00:33:39,420 --> 00:33:44,520
percent of performance simply through

00:33:42,059 --> 00:33:46,950
this and this is why some static content

00:33:44,520 --> 00:33:48,960
providers are interested in this more

00:33:46,950 --> 00:33:51,299
importantly this allows the kernel to

00:33:48,960 --> 00:33:52,860
the clear text payload even if the

00:33:51,299 --> 00:33:54,960
application is doing and to an

00:33:52,860 --> 00:33:57,360
encryption if we're going back to this

00:33:54,960 --> 00:33:58,830
picture the worst case scenario is that

00:33:57,360 --> 00:34:00,840
you're doing end-to-end encryption and

00:33:58,830 --> 00:34:03,570
the proxy actual needs to decrypt here

00:34:00,840 --> 00:34:06,299
it will decrypt look at the header make

00:34:03,570 --> 00:34:09,210
a decision re encrypt it will send it

00:34:06,299 --> 00:34:11,429
over decrypt look at the data re-encrypt

00:34:09,210 --> 00:34:14,790
you're wasting a ton of that your AWS

00:34:11,429 --> 00:34:25,020
available basically double at least boy

00:34:14,790 --> 00:34:26,429
there's a question so yes and no so the

00:34:25,020 --> 00:34:29,100
question was is to cycle proxy just

00:34:26,429 --> 00:34:30,780
becoming a control plane here the kernel

00:34:29,100 --> 00:34:32,429
will have limits in terms of complexity

00:34:30,780 --> 00:34:34,260
can handle so what we're doing basically

00:34:32,429 --> 00:34:35,669
is we're saying if we can handle it we

00:34:34,260 --> 00:34:37,320
can handle it in a kernel and otherwise

00:34:35,669 --> 00:34:39,240
we can basically punt it to the sidecar

00:34:37,320 --> 00:34:42,600
proxy and user space still so it's more

00:34:39,240 --> 00:34:51,359
like an an offload from that sense which

00:34:42,600 --> 00:34:53,460
means exactly so the statement here was

00:34:51,359 --> 00:34:55,290
just for the video recording you can you

00:34:53,460 --> 00:34:57,030
can opt in what to handle and everything

00:34:55,290 --> 00:34:59,010
else will still be on about user space

00:34:57,030 --> 00:35:00,450
sidecar proxy and we can do this as on

00:34:59,010 --> 00:35:02,040
the request basis so it's not just

00:35:00,450 --> 00:35:04,020
connection so if you have let's a long

00:35:02,040 --> 00:35:06,300
left HTTP - connection we can do this

00:35:04,020 --> 00:35:08,550
per request so even if just one of the

00:35:06,300 --> 00:35:10,320
requests inside of the connection cannot

00:35:08,550 --> 00:35:12,660
be handle we can punt this out to use a

00:35:10,320 --> 00:35:15,900
space proxy and it gets even more

00:35:12,660 --> 00:35:17,400
excited exciting because we introduced

00:35:15,900 --> 00:35:19,470
or we're introducing something called

00:35:17,400 --> 00:35:21,420
socket redirect which is basically if we

00:35:19,470 --> 00:35:22,870
go back to here it allows us to

00:35:21,420 --> 00:35:25,420
basically jump from here

00:35:22,870 --> 00:35:27,010
to here like soccer - soccer which means

00:35:25,420 --> 00:35:30,210
if we have to punt to the userspace

00:35:27,010 --> 00:35:33,100
proxy we can say if this very expensive

00:35:30,210 --> 00:35:34,990
hairpin down through the TCP stack and

00:35:33,100 --> 00:35:38,080
back up we're basically just can can

00:35:34,990 --> 00:35:40,420
copy over which even if we cannot do it

00:35:38,080 --> 00:35:43,270
in the kernel we will still save a ton

00:35:40,420 --> 00:35:45,520
of cycles now we can basically say well

00:35:43,270 --> 00:35:46,990
this is safe we can delay the encryption

00:35:45,520 --> 00:35:49,090
or the dig yeah we can delay the

00:35:46,990 --> 00:35:51,250
encryption so we can move the encryption

00:35:49,090 --> 00:35:53,470
from here over to here so we don't have

00:35:51,250 --> 00:35:56,200
to decrypt andrian crypt again so this

00:35:53,470 --> 00:35:58,300
is how we see the future of services

00:35:56,200 --> 00:36:02,440
mash enforcement data play or they are

00:35:58,300 --> 00:36:04,030
certain functionality in general yeah

00:36:02,440 --> 00:36:05,620
this is a socket redirect I just talked

00:36:04,030 --> 00:36:09,610
about so you're basically getting rid of

00:36:05,620 --> 00:36:11,260
this of this part below so just to give

00:36:09,610 --> 00:36:12,670
you an idea of performance and I'm

00:36:11,260 --> 00:36:14,650
leaking company information right here

00:36:12,670 --> 00:36:16,780
this is coming directly by our internal

00:36:14,650 --> 00:36:18,790
slack channel so baby Sean faster

00:36:16,780 --> 00:36:20,830
Manistee is the code that is currently

00:36:18,790 --> 00:36:23,830
working on this he did a performance

00:36:20,830 --> 00:36:27,010
measurement and the numbers below maybe

00:36:23,830 --> 00:36:29,440
if you cannot see it it's 5.5 gigabytes

00:36:27,010 --> 00:36:30,390
per second is if one application is

00:36:29,440 --> 00:36:35,320
talking to another

00:36:30,390 --> 00:36:38,200
locally through TCP or the loopback the

00:36:35,320 --> 00:36:41,080
above example is socket redirect with a

00:36:38,200 --> 00:36:43,510
filter applied we're actually faster the

00:36:41,080 --> 00:36:46,510
socket redirect because we're not going

00:36:43,510 --> 00:36:48,460
through the TCP stack so you gain policy

00:36:46,510 --> 00:36:51,010
you gain layer seven functionality and

00:36:48,460 --> 00:36:53,470
you're faster as you would have you are

00:36:51,010 --> 00:36:55,930
faster than act and then you you were

00:36:53,470 --> 00:36:59,470
before so the number in that the upper

00:36:55,930 --> 00:37:04,300
box is six point seven six point six

00:36:59,470 --> 00:37:09,100
gigabits per second so the before and

00:37:04,300 --> 00:37:13,510
the after it's pretty simple right so to

00:37:09,100 --> 00:37:14,440
summarize so cilium uses BPF to do

00:37:13,510 --> 00:37:16,860
networking

00:37:14,440 --> 00:37:20,410
lopa lansing and network security

00:37:16,860 --> 00:37:22,450
firewall on layers three we can do label

00:37:20,410 --> 00:37:24,610
based as we saw defining policy based on

00:37:22,450 --> 00:37:27,100
labels we can do cider based filtering

00:37:24,610 --> 00:37:29,170
ingress egress you can say I want this

00:37:27,100 --> 00:37:30,760
legacy right cool Oracle database to

00:37:29,170 --> 00:37:33,640
connect to my micro service or I only

00:37:30,760 --> 00:37:36,310
want two despot to be able to contact

00:37:33,640 --> 00:37:36,760
stripe calm IPS we can do layer for

00:37:36,310 --> 00:37:39,100
Paulo

00:37:36,760 --> 00:37:41,680
see we can do layer policy right now we

00:37:39,100 --> 00:37:43,690
can do HTTP we're currently in the in

00:37:41,680 --> 00:37:47,250
the doing that work to transition over

00:37:43,690 --> 00:37:50,950
to using envoy as the sidecar proxy to

00:37:47,250 --> 00:37:53,440
enforce this already supports G RPC and

00:37:50,950 --> 00:37:57,220
 so if this transition will start

00:37:53,440 --> 00:38:00,250
supporting HTTP and G RPC and then

00:37:57,220 --> 00:38:01,930
we'll add more protocols that the most

00:38:00,250 --> 00:38:06,490
likely candidate is definitely Kafka

00:38:01,930 --> 00:38:08,260
like Kafka is if you look at Kafka and

00:38:06,490 --> 00:38:11,080
the potential health is secured as it's

00:38:08,260 --> 00:38:13,240
obvious you have micro services sharing

00:38:11,080 --> 00:38:15,070
a message bus Kafka has a concept of

00:38:13,240 --> 00:38:17,080
topics where that the same message bus

00:38:15,070 --> 00:38:18,790
can be used for different topics it's

00:38:17,080 --> 00:38:21,670
obvious that you want to have a policy

00:38:18,790 --> 00:38:24,220
and say this micro service only needs

00:38:21,670 --> 00:38:26,110
access to this topic only granted access

00:38:24,220 --> 00:38:28,930
to this topic so you cannot steal data

00:38:26,110 --> 00:38:31,210
you cannot steal messages you can say

00:38:28,930 --> 00:38:33,520
you can imagine a policy which says this

00:38:31,210 --> 00:38:35,140
is a producer it only ever writes to the

00:38:33,520 --> 00:38:37,450
Kafka messenger boss so you say it can

00:38:35,140 --> 00:38:39,670
only write another component is a

00:38:37,450 --> 00:38:41,970
consumer so it can only take something

00:38:39,670 --> 00:38:45,010
off the messaging bus these are obvious

00:38:41,970 --> 00:38:50,290
reasons why you would want to secure on

00:38:45,010 --> 00:38:52,450
calf:cow level we saw the low balancing

00:38:50,290 --> 00:38:54,970
bit and we saw the performance numbers

00:38:52,450 --> 00:38:57,130
what we observed in our DDoS mitigation

00:38:54,970 --> 00:38:58,990
use case which is very similar to being

00:38:57,130 --> 00:39:01,150
a low plunge and the Facebook use case

00:38:58,990 --> 00:39:04,270
basically being able to compete with

00:39:01,150 --> 00:39:07,420
user space networking solutions all in

00:39:04,270 --> 00:39:08,950
kernel all well integrated I didn't talk

00:39:07,420 --> 00:39:10,660
a lot about the dependencies because you

00:39:08,950 --> 00:39:12,940
don't have many the only dependencies

00:39:10,660 --> 00:39:15,310
that dependency that we have is an

00:39:12,940 --> 00:39:17,260
external key value store in the edge of

00:39:15,310 --> 00:39:19,030
clown native micro services this is how

00:39:17,260 --> 00:39:21,160
you interact or how you share state

00:39:19,030 --> 00:39:24,190
between components so a key value store

00:39:21,160 --> 00:39:26,080
is basically a key value store database

00:39:24,190 --> 00:39:28,900
where you can keys and a value

00:39:26,080 --> 00:39:31,030
associated with them you can use HD or

00:39:28,900 --> 00:39:34,230
console right but these are the two

00:39:31,030 --> 00:39:34,230
options that we support yes

00:39:36,519 --> 00:39:42,920
so the question is if I'm running

00:39:38,450 --> 00:39:46,509
keeping address - I still need this yes

00:39:42,920 --> 00:39:48,890
but you can use the Cuban Eddie's HCG

00:39:46,509 --> 00:39:50,450
key-value store if you want to even

00:39:48,890 --> 00:39:52,999
though I would not recommend this at a

00:39:50,450 --> 00:39:59,390
certain scale right it city will have a

00:39:52,999 --> 00:40:01,700
certain scale limitation and yeah so we

00:39:59,390 --> 00:40:03,680
are talked about Cuban Eddie's so we

00:40:01,700 --> 00:40:05,299
come as a sea and I plug in but we also

00:40:03,680 --> 00:40:06,829
have a lip in network integration so if

00:40:05,299 --> 00:40:09,349
you're running docker swarm you can also

00:40:06,829 --> 00:40:11,569
run psyllium Mazouz recently added

00:40:09,349 --> 00:40:13,519
seeing board as well so we are

00:40:11,569 --> 00:40:17,329
supporting the mesosphere ecosystem as

00:40:13,519 --> 00:40:19,219
well if you want to get started if you

00:40:17,329 --> 00:40:21,499
if you if you got intrigued and you want

00:40:19,219 --> 00:40:24,140
to try this out we have a getting

00:40:21,499 --> 00:40:25,969
started guide a tutorial which is using

00:40:24,140 --> 00:40:28,999
a way grant box you can call the silly

00:40:25,969 --> 00:40:32,390
my or / try and basically try this out

00:40:28,999 --> 00:40:35,029
including layer 7 top on kubernetes

00:40:32,390 --> 00:40:37,339
Meadows or darker and it's an open

00:40:35,029 --> 00:40:39,259
source project so we are on get up feel

00:40:37,339 --> 00:40:40,969
free to start us we have a Twitter

00:40:39,259 --> 00:40:43,430
handle we're sharing news feel free to

00:40:40,969 --> 00:40:44,630
follow I think I saw a sign up for one

00:40:43,430 --> 00:40:45,890
minute so I think we have a little bit

00:40:44,630 --> 00:40:47,839
of question but I think the coffee break

00:40:45,890 --> 00:40:50,210
is next so I think we can use some time

00:40:47,839 --> 00:40:53,260
for questions all right here we go

00:40:50,210 --> 00:40:53,260
[Music]

00:40:54,260 --> 00:40:57,950
so what the Russian is what is the

00:40:56,069 --> 00:41:00,960
relationship between psyllium and envoy

00:40:57,950 --> 00:41:03,329
envoy will be our primary sidecar proxy

00:41:00,960 --> 00:41:06,599
which means that it will be the default

00:41:03,329 --> 00:41:08,579
to handle layer 7 policies if we can do

00:41:06,599 --> 00:41:10,109
that in the kernel for example for Kafka

00:41:08,579 --> 00:41:11,790
which is a very simple protocol we will

00:41:10,109 --> 00:41:13,859
definitely do that in kernel which means

00:41:11,790 --> 00:41:16,200
we can do it at lower cost higher speeds

00:41:13,859 --> 00:41:17,760
lower latency so we already have

00:41:16,200 --> 00:41:21,540
multiple people working on envoy to

00:41:17,760 --> 00:41:32,309
basically prepare it for is on what will

00:41:21,540 --> 00:41:34,589
be our primary psycho proxy the question

00:41:32,309 --> 00:41:37,410
is can you can you only use the layer 7

00:41:34,589 --> 00:41:39,119
bits right now the thing about security

00:41:37,410 --> 00:41:42,690
is that you want to make it very hard

00:41:39,119 --> 00:41:44,069
ideal impossible to pipe bypasses the

00:41:42,690 --> 00:41:45,869
way we do this is we take over

00:41:44,069 --> 00:41:48,140
networking because in this way we can we

00:41:45,869 --> 00:41:51,450
can guarantee that we see everything

00:41:48,140 --> 00:41:54,119
which right now there is no there's no

00:41:51,450 --> 00:41:55,290
way to do this but you're not the first

00:41:54,119 --> 00:41:58,380
to ask this question and we're currently

00:41:55,290 --> 00:41:59,940
investigating what do this in this in

00:41:58,380 --> 00:42:01,200
the in that in that scenario you would

00:41:59,940 --> 00:42:03,030
it wouldn't you would not be installed

00:42:01,200 --> 00:42:06,000
through a C&I plugging anymore but they

00:42:03,030 --> 00:42:07,950
basically run it on top of another CNI

00:42:06,000 --> 00:42:11,309
plugin for example but you can already

00:42:07,950 --> 00:42:14,670
do for example I want to use for example

00:42:11,309 --> 00:42:16,770
calicos routing daemon and but but you

00:42:14,670 --> 00:42:18,660
see Liam so that would be compatible or

00:42:16,770 --> 00:42:20,760
you could say I'm using a flannel and

00:42:18,660 --> 00:42:23,819
running psyllium on top that would also

00:42:20,760 --> 00:42:29,339
be possible but right now it's it's not

00:42:23,819 --> 00:42:32,510
like generically decoupled yet more

00:42:29,339 --> 00:42:32,510
questions yep

00:42:38,560 --> 00:42:45,620
so the question is can I integrate this

00:42:40,910 --> 00:42:48,550
with nginx or Apache what do you mean by

00:42:45,620 --> 00:42:48,550
directly on an hour

00:42:54,180 --> 00:42:58,360
all right so the question is can I could

00:42:56,650 --> 00:43:00,520
I use the nginx configuration interface

00:42:58,360 --> 00:43:02,560
to use this it's not the question ok so

00:43:00,520 --> 00:43:04,720
right now you can't so right now you can

00:43:02,560 --> 00:43:06,460
we have an API that you can use to

00:43:04,720 --> 00:43:08,350
actually configure this or you can use a

00:43:06,460 --> 00:43:09,820
kubernetes resource file as we saw in

00:43:08,350 --> 00:43:12,190
the example these are the current ways

00:43:09,820 --> 00:43:17,650
I'm happy to explore how that could look

00:43:12,190 --> 00:43:20,620
like I haven't looked into that yet all

00:43:17,650 --> 00:43:24,100
right so we do have t-shirts feel free

00:43:20,620 --> 00:43:25,330
to stop by we also have and please store

00:43:24,100 --> 00:43:26,060
us and get up all right thank you thank

00:43:25,330 --> 00:43:31,980
you very much

00:43:26,060 --> 00:43:31,980

YouTube URL: https://www.youtube.com/watch?v=CcGtDMm1SJA


