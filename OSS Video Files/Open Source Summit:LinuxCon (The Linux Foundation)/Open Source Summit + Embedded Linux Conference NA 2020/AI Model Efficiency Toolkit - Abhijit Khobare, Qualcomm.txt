Title: AI Model Efficiency Toolkit - Abhijit Khobare, Qualcomm
Publication date: 2020-09-03
Playlist: Open Source Summit + Embedded Linux Conference NA 2020
Description: 
	AI Model Efficiency Toolkit - Abhijit Khobare, Qualcomm
Captions: 
	00:00:07,839 --> 00:00:11,679
hi welcome everyone

00:00:09,360 --> 00:00:12,719
to this talk on ai model efficiency

00:00:11,679 --> 00:00:15,599
toolkit

00:00:12,719 --> 00:00:18,320
uh my name is avi cobre i work for

00:00:15,599 --> 00:00:21,680
qualcomm ai research

00:00:18,320 --> 00:00:23,920
and you know i focus on

00:00:21,680 --> 00:00:25,920
this field called model efficiency and i

00:00:23,920 --> 00:00:29,119
want to motivate to you

00:00:25,920 --> 00:00:30,720
why why is model efficiency important

00:00:29,119 --> 00:00:33,680
in this talk and i also want to

00:00:30,720 --> 00:00:37,120
introduce this this toolkit to you

00:00:33,680 --> 00:00:38,559
um so while i focus on this model

00:00:37,120 --> 00:00:41,600
efficiency

00:00:38,559 --> 00:00:42,719
space you know i and my team also work

00:00:41,600 --> 00:00:46,640
on building

00:00:42,719 --> 00:00:48,640
these tools that help you know engineers

00:00:46,640 --> 00:00:50,320
within qualcomm but like we want to

00:00:48,640 --> 00:00:53,840
actually

00:00:50,320 --> 00:00:53,840
impact the wider community

00:00:56,000 --> 00:01:01,600
so um as we all know you know

00:00:59,359 --> 00:01:02,640
deep learning and deep neural networks

00:01:01,600 --> 00:01:05,840
are all the rage

00:01:02,640 --> 00:01:09,439
currently um if you look

00:01:05,840 --> 00:01:12,799
over time uh the

00:01:09,439 --> 00:01:14,799
the networks have grown more and more

00:01:12,799 --> 00:01:17,920
complex

00:01:14,799 --> 00:01:19,920
and you know they've grown in size both

00:01:17,920 --> 00:01:21,520
in like space but they've also grown in

00:01:19,920 --> 00:01:23,920
complexity

00:01:21,520 --> 00:01:24,799
and if you if you take all of this

00:01:23,920 --> 00:01:28,240
together and

00:01:24,799 --> 00:01:32,079
if you see on like the y-axis

00:01:28,240 --> 00:01:33,920
the the the networks you know the energy

00:01:32,079 --> 00:01:37,439
consumption of the networks

00:01:33,920 --> 00:01:38,960
keeps growing up you know exponentially

00:01:37,439 --> 00:01:42,320
if you may

00:01:38,960 --> 00:01:44,960
um and there is you know there's no uh

00:01:42,320 --> 00:01:45,360
current limit in sight on when this is

00:01:44,960 --> 00:01:48,399
gonna

00:01:45,360 --> 00:01:51,040
end so um

00:01:48,399 --> 00:01:52,240
yeah we while this is all good for us

00:01:51,040 --> 00:01:54,320
but i think you know it

00:01:52,240 --> 00:01:55,600
it's we need to solve this in some

00:01:54,320 --> 00:01:58,240
better fashion

00:01:55,600 --> 00:01:59,439
uh because clearly we can't let the

00:01:58,240 --> 00:02:02,240
energy

00:01:59,439 --> 00:02:04,240
uh consumption of these uh deep neural

00:02:02,240 --> 00:02:06,880
network solutions keep growing at the

00:02:04,240 --> 00:02:06,880
current pace

00:02:07,360 --> 00:02:15,840
so how do we go about this right so um

00:02:12,000 --> 00:02:15,840
a lot traditionally a lot of the

00:02:15,920 --> 00:02:20,319
neural networks they run on the cloud

00:02:18,080 --> 00:02:21,040
and that will continue to be the case i

00:02:20,319 --> 00:02:23,599
think you know

00:02:21,040 --> 00:02:24,560
a lot of applications have been enabled

00:02:23,599 --> 00:02:27,680
by the cloud and

00:02:24,560 --> 00:02:30,800
that's not going away however

00:02:27,680 --> 00:02:32,000
um if you look at the devices around you

00:02:30,800 --> 00:02:34,080
right if you look at

00:02:32,000 --> 00:02:36,160
just what you have at the moment you

00:02:34,080 --> 00:02:37,680
have cell phones you have tablets

00:02:36,160 --> 00:02:41,440
computers you have

00:02:37,680 --> 00:02:44,400
smart watches you have your cars

00:02:41,440 --> 00:02:45,120
you have your tvs your refrigerators air

00:02:44,400 --> 00:02:47,760
vrs

00:02:45,120 --> 00:02:50,879
headsets there's a whole bunch of

00:02:47,760 --> 00:02:54,319
devices around us each of these devices

00:02:50,879 --> 00:02:56,959
is a ai device if you may

00:02:54,319 --> 00:02:58,879
right so they are even today they are

00:02:56,959 --> 00:03:00,959
probably running

00:02:58,879 --> 00:03:02,239
some machine learning some deep neural

00:03:00,959 --> 00:03:04,720
networks

00:03:02,239 --> 00:03:06,400
but definitely in the future this is

00:03:04,720 --> 00:03:08,879
just going to keep growing

00:03:06,400 --> 00:03:10,000
uh and this is actually a good thing so

00:03:08,879 --> 00:03:13,120
this uh

00:03:10,000 --> 00:03:14,319
the having the on device ai will

00:03:13,120 --> 00:03:17,200
complement

00:03:14,319 --> 00:03:18,159
uh ai running on the cloud nothing you

00:03:17,200 --> 00:03:20,000
know

00:03:18,159 --> 00:03:21,440
no one is the winner they they just

00:03:20,000 --> 00:03:25,200
complement each other

00:03:21,440 --> 00:03:26,799
and so this is the on device ai has you

00:03:25,200 --> 00:03:27,760
know certain characteristics that are

00:03:26,799 --> 00:03:31,440
actually

00:03:27,760 --> 00:03:33,519
uh make it uh much more appealing

00:03:31,440 --> 00:03:35,599
and one of the characteristics is

00:03:33,519 --> 00:03:39,360
privacy a lot of times like

00:03:35,599 --> 00:03:41,519
you know let's say we are doing uh

00:03:39,360 --> 00:03:43,360
you know something running on the phone

00:03:41,519 --> 00:03:45,519
and trying to do some

00:03:43,360 --> 00:03:47,599
trying to listen to your voice and give

00:03:45,519 --> 00:03:49,360
you some you know

00:03:47,599 --> 00:03:50,720
do something for you write an email type

00:03:49,360 --> 00:03:53,840
something up

00:03:50,720 --> 00:03:56,480
uh any any of these uh interactions that

00:03:53,840 --> 00:03:59,599
we have with the devices that we touch

00:03:56,480 --> 00:04:00,720
uh generally are private and so privacy

00:03:59,599 --> 00:04:04,080
is a big concern

00:04:00,720 --> 00:04:07,599
and you know having keeping that

00:04:04,080 --> 00:04:11,519
communication local is is appealing

00:04:07,599 --> 00:04:14,799
to users similar if you look at like

00:04:11,519 --> 00:04:17,519
things like automotive uh you

00:04:14,799 --> 00:04:19,040
you require a lot of reliability you

00:04:17,519 --> 00:04:20,479
don't want just because your network

00:04:19,040 --> 00:04:22,400
connection has gone down you don't want

00:04:20,479 --> 00:04:26,160
your car to go crash somewhere

00:04:22,400 --> 00:04:28,479
so you want um your device to keep

00:04:26,160 --> 00:04:30,240
uh operating irrespective of you know

00:04:28,479 --> 00:04:32,000
what kind of network connection you have

00:04:30,240 --> 00:04:34,880
so you need reliability

00:04:32,000 --> 00:04:36,479
uh also low latency which you know may

00:04:34,880 --> 00:04:39,280
be impacted by going

00:04:36,479 --> 00:04:40,880
going to the cloud and back and also if

00:04:39,280 --> 00:04:44,720
you see

00:04:40,880 --> 00:04:47,680
these devices keep you know producing

00:04:44,720 --> 00:04:48,479
uh ever-growing gazillion uh amount of

00:04:47,680 --> 00:04:50,800
information

00:04:48,479 --> 00:04:52,800
and even with like these 5g networks

00:04:50,800 --> 00:04:54,080
coming up and we are going to see like a

00:04:52,800 --> 00:04:56,639
humongous

00:04:54,080 --> 00:04:57,120
growth and capability of the networks

00:04:56,639 --> 00:05:01,199
but

00:04:57,120 --> 00:05:04,080
nevertheless uh by keeping

00:05:01,199 --> 00:05:06,880
some you know not needed information off

00:05:04,080 --> 00:05:08,840
the network is is good because you can

00:05:06,880 --> 00:05:12,479
reduce your network bandwidth save

00:05:08,840 --> 00:05:12,479
energy help the planet

00:05:14,080 --> 00:05:18,000
so all this is good so what's the

00:05:17,520 --> 00:05:20,560
problem

00:05:18,000 --> 00:05:21,680
and the problem is if you look at the

00:05:20,560 --> 00:05:24,560
deep learning

00:05:21,680 --> 00:05:25,600
networks or machine learning workloads

00:05:24,560 --> 00:05:27,759
today

00:05:25,600 --> 00:05:28,880
you see that they're very compute

00:05:27,759 --> 00:05:31,919
intensive

00:05:28,880 --> 00:05:33,199
um and you they have these

00:05:31,919 --> 00:05:34,960
you know while they're computer

00:05:33,199 --> 00:05:37,039
intensive they also you know depending

00:05:34,960 --> 00:05:38,720
on the application you may have

00:05:37,039 --> 00:05:41,199
real-time constraints you may want to

00:05:38,720 --> 00:05:42,479
like look at a video stream and you know

00:05:41,199 --> 00:05:45,120
do some

00:05:42,479 --> 00:05:46,400
segmentation on the fly or you know

00:05:45,120 --> 00:05:48,080
change

00:05:46,400 --> 00:05:49,919
as you're looking at yourselves in the

00:05:48,080 --> 00:05:51,440
phone

00:05:49,919 --> 00:05:52,960
you may want to like change lighting

00:05:51,440 --> 00:05:54,880
conditions and so on so there's a

00:05:52,960 --> 00:05:57,120
real-time aspect to it

00:05:54,880 --> 00:05:58,720
um some applications are always on like

00:05:57,120 --> 00:06:00,880
when we are for example

00:05:58,720 --> 00:06:02,639
trying to tell our watch to you know

00:06:00,880 --> 00:06:04,160
follow google or wake up

00:06:02,639 --> 00:06:05,919
right so those are always on

00:06:04,160 --> 00:06:06,560
applications so there are all these

00:06:05,919 --> 00:06:09,840
there are

00:06:06,560 --> 00:06:10,479
these challenging ai workloads but on

00:06:09,840 --> 00:06:13,520
the

00:06:10,479 --> 00:06:16,800
on the right hand side you have these

00:06:13,520 --> 00:06:18,400
mobile these edge devices have a very

00:06:16,800 --> 00:06:21,280
constrained environment

00:06:18,400 --> 00:06:22,800
and they want depending on uh if they

00:06:21,280 --> 00:06:24,080
are battery powered or even if they are

00:06:22,800 --> 00:06:27,680
not battery powered you

00:06:24,080 --> 00:06:30,560
do you want them to be very efficient

00:06:27,680 --> 00:06:31,120
um you you know they are generally sleek

00:06:30,560 --> 00:06:33,600
and

00:06:31,120 --> 00:06:35,680
lightweight designs uh if their battery

00:06:33,600 --> 00:06:38,160
power they require long battery

00:06:35,680 --> 00:06:40,319
battery life you know early usage those

00:06:38,160 --> 00:06:43,919
kind of things and they also have

00:06:40,319 --> 00:06:46,479
limited storage memory um

00:06:43,919 --> 00:06:48,800
constraints maybe limited bandwidth

00:06:46,479 --> 00:06:52,240
maybe limited

00:06:48,800 --> 00:06:54,960
but all of these limitations you know

00:06:52,240 --> 00:06:56,000
as uh you know moose law keeps evolving

00:06:54,960 --> 00:06:57,360
i think

00:06:56,000 --> 00:07:00,160
the devices become more and more

00:06:57,360 --> 00:07:01,840
powerful but there is

00:07:00,160 --> 00:07:03,440
they are constrained compared to the

00:07:01,840 --> 00:07:05,440
cloud right that will i think always

00:07:03,440 --> 00:07:08,720
remain the case

00:07:05,440 --> 00:07:11,120
so we need we can't just

00:07:08,720 --> 00:07:12,800
you know potentially just do what we do

00:07:11,120 --> 00:07:13,199
on the cloud on the device i think that

00:07:12,800 --> 00:07:17,199
that

00:07:13,199 --> 00:07:19,919
is not going to scale

00:07:17,199 --> 00:07:21,440
so what do we do so you know we at

00:07:19,919 --> 00:07:24,160
qualcomm believe that we can

00:07:21,440 --> 00:07:24,880
we have to tackle this in multiple ways

00:07:24,160 --> 00:07:27,680
um

00:07:24,880 --> 00:07:29,759
so we you see them in the middle bar

00:07:27,680 --> 00:07:31,599
over there

00:07:29,759 --> 00:07:34,160
some of the ways in which we want to

00:07:31,599 --> 00:07:36,560
make these models efficient

00:07:34,160 --> 00:07:38,319
are model quantization in the middle

00:07:36,560 --> 00:07:41,360
we'll we'll look a little bit of

00:07:38,319 --> 00:07:43,919
that what that means but

00:07:41,360 --> 00:07:45,840
at a high level what that does is

00:07:43,919 --> 00:07:48,400
instead of running

00:07:45,840 --> 00:07:50,479
at high precision let's say you're doing

00:07:48,400 --> 00:07:51,039
uh 32-bit floating point precision

00:07:50,479 --> 00:07:53,120
models

00:07:51,039 --> 00:07:54,720
uh while training or even you know

00:07:53,120 --> 00:07:57,680
influencers on the cloud

00:07:54,720 --> 00:07:58,800
on the on the edge devices you could

00:07:57,680 --> 00:08:02,000
scale it down

00:07:58,800 --> 00:08:02,800
and use lower precision math and we'll

00:08:02,000 --> 00:08:05,039
look at

00:08:02,800 --> 00:08:06,400
why that is useful there is model

00:08:05,039 --> 00:08:07,759
compression that you see on the left

00:08:06,400 --> 00:08:09,840
which is

00:08:07,759 --> 00:08:11,360
you know can we take these models that

00:08:09,840 --> 00:08:14,960
we have

00:08:11,360 --> 00:08:17,520
developed after a lot of sweat and tears

00:08:14,960 --> 00:08:18,560
but given a particular use case right it

00:08:17,520 --> 00:08:20,160
may be

00:08:18,560 --> 00:08:22,400
a model may be designed for something

00:08:20,160 --> 00:08:23,840
but then you want to detect faces out of

00:08:22,400 --> 00:08:24,400
it it could detect a whole lot of things

00:08:23,840 --> 00:08:26,240
but you

00:08:24,400 --> 00:08:28,080
you specifically want to detect faces

00:08:26,240 --> 00:08:30,319
out of it can we make

00:08:28,080 --> 00:08:32,159
that model can we compress it down for

00:08:30,319 --> 00:08:32,719
the particular use case such that it is

00:08:32,159 --> 00:08:35,680
a

00:08:32,719 --> 00:08:37,360
smaller model a more compute less

00:08:35,680 --> 00:08:39,440
compute intensive model

00:08:37,360 --> 00:08:41,839
so that's called model compression we'll

00:08:39,440 --> 00:08:43,839
look at a look at that a little bit

00:08:41,839 --> 00:08:46,399
uh and then there are other techniques

00:08:43,839 --> 00:08:48,560
like you know compilation can we use

00:08:46,399 --> 00:08:50,240
a machine learning compiler to you know

00:08:48,560 --> 00:08:53,040
optimize this up just like we

00:08:50,240 --> 00:08:54,080
write code and a compiler you know makes

00:08:53,040 --> 00:08:56,480
uh

00:08:54,080 --> 00:08:57,839
you know looks looks at our code and uh

00:08:56,480 --> 00:09:00,320
tries to take away the

00:08:57,839 --> 00:09:01,680
redundancies and makes it more efficient

00:09:00,320 --> 00:09:03,040
uh at runtime

00:09:01,680 --> 00:09:04,560
can we do the same thing with machine

00:09:03,040 --> 00:09:06,399
learning model so we are you know

00:09:04,560 --> 00:09:09,519
exploring all these angles

00:09:06,399 --> 00:09:11,120
um and also of course at the bottom is

00:09:09,519 --> 00:09:12,480
you know different hardware

00:09:11,120 --> 00:09:13,600
architectures different hardware

00:09:12,480 --> 00:09:15,360
accelerators

00:09:13,600 --> 00:09:16,800
uh those are being researched uh

00:09:15,360 --> 00:09:20,240
including you know stuff like

00:09:16,800 --> 00:09:22,320
can we just do compute and memory can do

00:09:20,240 --> 00:09:23,760
do we need a specific compute can be

00:09:22,320 --> 00:09:25,120
some other compute we just done in

00:09:23,760 --> 00:09:28,399
memory so there are all these

00:09:25,120 --> 00:09:29,839
exciting different areas of making

00:09:28,399 --> 00:09:31,760
models sufficient

00:09:29,839 --> 00:09:32,880
for this particular talk we are going to

00:09:31,760 --> 00:09:34,720
focus on that

00:09:32,880 --> 00:09:36,560
on the one in the middle quantized model

00:09:34,720 --> 00:09:38,080
quantization and model compression

00:09:36,560 --> 00:09:40,320
and these are the techniques that are

00:09:38,080 --> 00:09:42,880
built into this ai model efficiency

00:09:40,320 --> 00:09:42,880
toolkit

00:09:43,120 --> 00:09:48,720
so let's move to the next slide

00:09:46,720 --> 00:09:50,160
okay so what is a network quantization

00:09:48,720 --> 00:09:53,839
and i

00:09:50,160 --> 00:09:57,279
told you in a very at a very high level

00:09:53,839 --> 00:09:57,600
um it basically involves like if you see

00:09:57,279 --> 00:09:59,920
the

00:09:57,600 --> 00:10:00,640
picture on the right it's trying to

00:09:59,920 --> 00:10:04,000
motivate

00:10:00,640 --> 00:10:07,120
through completely unrelated example

00:10:04,000 --> 00:10:07,839
it's saying like if you had a higher bit

00:10:07,120 --> 00:10:11,040
width

00:10:07,839 --> 00:10:13,680
image and if you you know reduce the

00:10:11,040 --> 00:10:14,320
you know pixel bit width of the image

00:10:13,680 --> 00:10:16,640
you can see

00:10:14,320 --> 00:10:18,160
artifacts you know going from 24 to 8

00:10:16,640 --> 00:10:21,200
bits and then if you go

00:10:18,160 --> 00:10:22,720
down to one bit you would like basically

00:10:21,200 --> 00:10:26,480
lose the color

00:10:22,720 --> 00:10:29,440
and so on so forth so um

00:10:26,480 --> 00:10:29,920
in a very similar fashion you can apply

00:10:29,440 --> 00:10:33,519
uh

00:10:29,920 --> 00:10:36,160
analog that similar analogy to a

00:10:33,519 --> 00:10:37,120
neural network model and so what happens

00:10:36,160 --> 00:10:39,440
is

00:10:37,120 --> 00:10:40,880
uh you can you know you when we train

00:10:39,440 --> 00:10:43,279
the models you would have

00:10:40,880 --> 00:10:46,480
you know floating point 32-bit floating

00:10:43,279 --> 00:10:48,160
point numbers for the model parameters

00:10:46,480 --> 00:10:50,640
and then each layer like if you're doing

00:10:48,160 --> 00:10:54,160
a convolutional area convolving

00:10:50,640 --> 00:10:57,519
using a floating point 32-bit

00:10:54,160 --> 00:11:00,560
you know multiplying accumulates can we

00:10:57,519 --> 00:11:03,680
change that into integer so

00:11:00,560 --> 00:11:06,000
going from floating point uh compute to

00:11:03,680 --> 00:11:08,959
integer compute is itself a big

00:11:06,000 --> 00:11:11,440
leap uh but then you know do we need 32

00:11:08,959 --> 00:11:11,760
bits can we scale it down to 16 bits can

00:11:11,440 --> 00:11:13,920
we

00:11:11,760 --> 00:11:15,360
even scale it down to eight bits maybe

00:11:13,920 --> 00:11:18,079
you know beyond that

00:11:15,360 --> 00:11:19,279
so uh these are the things uh you know

00:11:18,079 --> 00:11:21,600
scaling down

00:11:19,279 --> 00:11:23,519
from floating point to integer and then

00:11:21,600 --> 00:11:24,720
scaling down the bitrate from 32 to

00:11:23,519 --> 00:11:26,839
let's say eight

00:11:24,720 --> 00:11:28,240
is generally what is called network

00:11:26,839 --> 00:11:31,200
quantization

00:11:28,240 --> 00:11:31,920
and so the way this works is uh not only

00:11:31,200 --> 00:11:34,160
do the

00:11:31,920 --> 00:11:35,760
parameters get quantized but the compute

00:11:34,160 --> 00:11:37,839
gets quantized as well

00:11:35,760 --> 00:11:38,800
so you're doing like in this particular

00:11:37,839 --> 00:11:40,959
picture

00:11:38,800 --> 00:11:42,000
i don't have a point at a point but look

00:11:40,959 --> 00:11:45,040
at the first blue

00:11:42,000 --> 00:11:47,760
layer that's a convolutional layer

00:11:45,040 --> 00:11:48,720
and then you have a second layer in this

00:11:47,760 --> 00:11:52,240
yellow color

00:11:48,720 --> 00:11:54,160
and that's also a convolutional layer so

00:11:52,240 --> 00:11:55,440
let's say the input comes in at eight

00:11:54,160 --> 00:11:56,959
bit integers

00:11:55,440 --> 00:11:59,120
and you have eight bit parameters

00:11:56,959 --> 00:12:01,760
feeding into that convolutional layer

00:11:59,120 --> 00:12:02,959
the blue one uh so the output of that

00:12:01,760 --> 00:12:04,720
layer would be like

00:12:02,959 --> 00:12:06,000
uh at an accumulator bit width like

00:12:04,720 --> 00:12:09,120
you'll do multiply neck

00:12:06,000 --> 00:12:10,480
ads and you know soon you will grow from

00:12:09,120 --> 00:12:13,040
your 8-bit to

00:12:10,480 --> 00:12:14,880
let's say back to 32 bits because and

00:12:13,040 --> 00:12:16,320
depending on how much you're convolving

00:12:14,880 --> 00:12:19,440
you need to accumulate

00:12:16,320 --> 00:12:21,360
a lot of values and so

00:12:19,440 --> 00:12:22,880
what would happen is you would like

00:12:21,360 --> 00:12:26,079
convert those

00:12:22,880 --> 00:12:29,200
32-bit integers back into 8-bit

00:12:26,079 --> 00:12:32,320
and the way you do that is

00:12:29,200 --> 00:12:34,480
you know finding a scale a scale

00:12:32,320 --> 00:12:38,560
factor for every every layer so let's

00:12:34,480 --> 00:12:40,720
take a look at that

00:12:38,560 --> 00:12:42,560
yeah but before we get there so what's

00:12:40,720 --> 00:12:43,760
why why do all this what what do we gain

00:12:42,560 --> 00:12:46,880
out of this right

00:12:43,760 --> 00:12:48,480
so um of course we know

00:12:46,880 --> 00:12:50,959
uh you know we can do the math and we

00:12:48,480 --> 00:12:53,519
say okay 32 bits to eight bits that's

00:12:50,959 --> 00:12:54,240
uh reduction and memory usage right so

00:12:53,519 --> 00:12:56,880
we

00:12:54,240 --> 00:12:58,000
that's a 4x reduction right there as you

00:12:56,880 --> 00:13:01,120
can see

00:12:58,000 --> 00:13:02,320
in the left picture but that's not the

00:13:01,120 --> 00:13:05,200
whole story

00:13:02,320 --> 00:13:06,000
right if you look at the latency it's

00:13:05,200 --> 00:13:07,839
not only that

00:13:06,000 --> 00:13:11,120
we have reduced the memory but we have

00:13:07,839 --> 00:13:13,600
actually reduced the compute needed

00:13:11,120 --> 00:13:14,560
from uh floating point of math to

00:13:13,600 --> 00:13:17,360
integer map

00:13:14,560 --> 00:13:18,639
and so that has us you know as a speed

00:13:17,360 --> 00:13:20,399
up if you may in

00:13:18,639 --> 00:13:22,639
how many inferences per second you can

00:13:20,399 --> 00:13:24,480
do but

00:13:22,639 --> 00:13:26,480
now start looking at other things where

00:13:24,480 --> 00:13:27,760
you can see more dramatic gains like if

00:13:26,480 --> 00:13:28,720
you look at the power consumption

00:13:27,760 --> 00:13:31,920
numbers

00:13:28,720 --> 00:13:34,160
uh if you look at add and multiply

00:13:31,920 --> 00:13:36,079
those are the tables on the left you

00:13:34,160 --> 00:13:39,120
would see like dramatic gains

00:13:36,079 --> 00:13:42,320
right uh i mean we are talking here on

00:13:39,120 --> 00:13:43,120
a factor of 30 factor of 20 kind of

00:13:42,320 --> 00:13:45,519
gains

00:13:43,120 --> 00:13:47,760
uh compared to floating point uh 32-bit

00:13:45,519 --> 00:13:51,279
versus integer 8-bit

00:13:47,760 --> 00:13:52,880
and you know a lot of it don't take you

00:13:51,279 --> 00:13:54,399
know these exact numbers too hard i

00:13:52,880 --> 00:13:56,160
think it all depends on you know how

00:13:54,399 --> 00:13:57,040
your hardware is designed and so on so

00:13:56,160 --> 00:14:00,240
forth

00:13:57,040 --> 00:14:00,959
but i think the takeaway point here is

00:14:00,240 --> 00:14:04,480
that

00:14:00,959 --> 00:14:07,440
you get dramatic gains same way you know

00:14:04,480 --> 00:14:08,160
not only having less memory usage is

00:14:07,440 --> 00:14:10,880
good to

00:14:08,160 --> 00:14:11,440
you know have require less memory but it

00:14:10,880 --> 00:14:14,720
also

00:14:11,440 --> 00:14:15,279
has a benefit of reducing your memory

00:14:14,720 --> 00:14:16,880
access

00:14:15,279 --> 00:14:18,560
because a lot of times when when you're

00:14:16,880 --> 00:14:20,639
running uh machine

00:14:18,560 --> 00:14:22,480
or ai workloads what you're doing is

00:14:20,639 --> 00:14:24,399
you're like taking you know

00:14:22,480 --> 00:14:26,320
let's say the model parameters or even

00:14:24,399 --> 00:14:28,000
the activations from a layer

00:14:26,320 --> 00:14:29,920
saving it to memory reading it back from

00:14:28,000 --> 00:14:32,079
memory and so you're going back and

00:14:29,920 --> 00:14:34,160
forth with memory a lot so if you have

00:14:32,079 --> 00:14:35,920
less things to you know go fetch from

00:14:34,160 --> 00:14:36,880
memory better for you less power

00:14:35,920 --> 00:14:39,519
consumption

00:14:36,880 --> 00:14:41,199
faster so and so forth and on the right

00:14:39,519 --> 00:14:44,240
you would see that

00:14:41,199 --> 00:14:46,720
uh just because doing integer

00:14:44,240 --> 00:14:48,160
mathematics is uh much simpler than

00:14:46,720 --> 00:14:49,040
doing floating point mathematics you

00:14:48,160 --> 00:14:51,760
have a

00:14:49,040 --> 00:14:53,120
dramatic you know reduction in silicon

00:14:51,760 --> 00:14:56,000
area as well

00:14:53,120 --> 00:14:57,760
so the way you look at this is you know

00:14:56,000 --> 00:15:00,959
silicon area

00:14:57,760 --> 00:15:02,560
can translate to cost uh can also

00:15:00,959 --> 00:15:04,639
translate to more

00:15:02,560 --> 00:15:06,240
capability like if you you know

00:15:04,639 --> 00:15:07,920
something requires less you could do

00:15:06,240 --> 00:15:09,040
more of it

00:15:07,920 --> 00:15:11,519
right so all of these are like

00:15:09,040 --> 00:15:13,600
trade-offs that we can play against but

00:15:11,519 --> 00:15:15,760
across the board you see like there is

00:15:13,600 --> 00:15:16,000
there are significant benefits of you

00:15:15,760 --> 00:15:20,720
know

00:15:16,000 --> 00:15:24,240
doing things in eight bit integers

00:15:20,720 --> 00:15:27,199
okay so all that is good so let's do it

00:15:24,240 --> 00:15:28,800
uh of course every no no free lunch so

00:15:27,199 --> 00:15:31,839
everything comes at a cost

00:15:28,800 --> 00:15:33,519
and so the way um you

00:15:31,839 --> 00:15:34,959
generally do there are lots of ways in

00:15:33,519 --> 00:15:38,240
which you can do these

00:15:34,959 --> 00:15:39,120
kind of 8-bit integer computations let's

00:15:38,240 --> 00:15:41,920
say

00:15:39,120 --> 00:15:43,120
but generally what what gets done is at

00:15:41,920 --> 00:15:44,800
a layer

00:15:43,120 --> 00:15:46,880
basis so let's say if you doing a

00:15:44,800 --> 00:15:47,440
convolutional layer what you would do is

00:15:46,880 --> 00:15:50,320
you would

00:15:47,440 --> 00:15:50,639
find a scale factor for that layer right

00:15:50,320 --> 00:15:54,240
so

00:15:50,639 --> 00:15:55,440
you would say um the table on the left

00:15:54,240 --> 00:15:58,480
it's a little too dense

00:15:55,440 --> 00:15:59,040
uh here but bear with me so if you look

00:15:58,480 --> 00:16:01,839
at that

00:15:59,040 --> 00:16:03,839
a transpose kind of matrix on the left

00:16:01,839 --> 00:16:04,480
pretend that that's a weight matrix and

00:16:03,839 --> 00:16:07,120
it has some

00:16:04,480 --> 00:16:07,759
floating point numbers as you can see

00:16:07,120 --> 00:16:10,800
only

00:16:07,759 --> 00:16:12,720
down to two bits of precision but like

00:16:10,800 --> 00:16:14,480
think of those as floating front numbers

00:16:12,720 --> 00:16:16,639
now the way you convert them into

00:16:14,480 --> 00:16:19,279
integer numbers is you could say hey

00:16:16,639 --> 00:16:21,279
how about i find a scale factor right so

00:16:19,279 --> 00:16:23,440
if i find a scale factor

00:16:21,279 --> 00:16:24,720
and in this case that scale factor is

00:16:23,440 --> 00:16:28,240
let's say 1 over 2

00:16:24,720 --> 00:16:31,120
255 so i keep that scale factor

00:16:28,240 --> 00:16:33,040
for remember that for this layer and now

00:16:31,120 --> 00:16:34,480
if i apply that scale factor to these

00:16:33,040 --> 00:16:36,560
floating point numbers i get some

00:16:34,480 --> 00:16:38,880
integer numbers and they

00:16:36,560 --> 00:16:40,160
happen to be nicely from you know 0 to

00:16:38,880 --> 00:16:43,360
00:16:40,160 --> 00:16:44,480
okay so now i have like 0 to 255 is 2

00:16:43,360 --> 00:16:48,839
raised to 8. so we can

00:16:44,480 --> 00:16:51,600
represent these numbers in 8 bits

00:16:48,839 --> 00:16:54,399
um so that that's how

00:16:51,600 --> 00:16:55,519
things are done but however uh what

00:16:54,399 --> 00:16:56,800
would happen is

00:16:55,519 --> 00:16:58,320
you know what what's the meaning of

00:16:56,800 --> 00:17:00,079
these numbers right so if you take these

00:16:58,320 --> 00:17:01,920
numbers and start multiplying them and

00:17:00,079 --> 00:17:04,079
adding them and so on so forth

00:17:01,920 --> 00:17:05,039
you get some other numbers but

00:17:04,079 --> 00:17:08,079
eventually you are

00:17:05,039 --> 00:17:10,319
you have to convert it back into this

00:17:08,079 --> 00:17:12,240
um you know something that you can

00:17:10,319 --> 00:17:12,880
understand into this float domain if you

00:17:12,240 --> 00:17:15,439
may

00:17:12,880 --> 00:17:17,280
and so when you do if you if you do if

00:17:15,439 --> 00:17:20,720
you apply a scale and then you

00:17:17,280 --> 00:17:24,559
sort of remove the scale and you look at

00:17:20,720 --> 00:17:25,039
the output you will see that there is an

00:17:24,559 --> 00:17:28,160
error

00:17:25,039 --> 00:17:30,240
right there is an error because in in

00:17:28,160 --> 00:17:32,400
case of a 32 bit floating point number

00:17:30,240 --> 00:17:37,280
you have a lot of precision

00:17:32,400 --> 00:17:39,919
and with 8-bit integers you have

00:17:37,280 --> 00:17:42,320
255 values right so clearly you can

00:17:39,919 --> 00:17:43,200
specify a lot more values with floating

00:17:42,320 --> 00:17:44,960
point numbers

00:17:43,200 --> 00:17:46,480
as opposed to the 8-bit numbers and so

00:17:44,960 --> 00:17:49,200
what would happen is

00:17:46,480 --> 00:17:50,240
what we are doing is we are mapping you

00:17:49,200 --> 00:17:53,440
know some

00:17:50,240 --> 00:17:56,320
buckets of floating point numbers to one

00:17:53,440 --> 00:17:56,960
uh number represented by an integer

00:17:56,320 --> 00:18:01,200
right so

00:17:56,960 --> 00:18:04,080
there is a rounding error if you may

00:18:01,200 --> 00:18:06,000
and all of this uh translates into

00:18:04,080 --> 00:18:08,080
errors at the end of the model right so

00:18:06,000 --> 00:18:11,840
we want to reduce this we want to get

00:18:08,080 --> 00:18:13,360
we want to uh have our cake and heated

00:18:11,840 --> 00:18:15,440
too so we want to

00:18:13,360 --> 00:18:16,400
use all of those benefits we saw earlier

00:18:15,440 --> 00:18:18,000
with integers but

00:18:16,400 --> 00:18:20,880
you know not lose any accuracy and

00:18:18,000 --> 00:18:23,120
that's that's the whole trick over here

00:18:20,880 --> 00:18:24,000
so we at uh qualcomm ai research have

00:18:23,120 --> 00:18:26,080
been like

00:18:24,000 --> 00:18:27,840
doing a whole bunch of you know research

00:18:26,080 --> 00:18:28,559
on quantization techniques and you'll

00:18:27,840 --> 00:18:31,679
see

00:18:28,559 --> 00:18:32,720
some papers there on the top including

00:18:31,679 --> 00:18:34,960
papers on

00:18:32,720 --> 00:18:36,799
these very novel techniques called add

00:18:34,960 --> 00:18:37,760
around and pastion bits that are coming

00:18:36,799 --> 00:18:40,960
up

00:18:37,760 --> 00:18:43,200
in icml so

00:18:40,960 --> 00:18:45,120
we do we have been doing this research

00:18:43,200 --> 00:18:48,480
and publishing our you know what we

00:18:45,120 --> 00:18:49,280
uh see uh not not just to help us but to

00:18:48,480 --> 00:18:52,320
help everybody

00:18:49,280 --> 00:18:53,280
the whole industry uh but now what we

00:18:52,320 --> 00:18:56,320
are also

00:18:53,280 --> 00:18:58,559
trying to do is um you know can we

00:18:56,320 --> 00:18:59,520
take these techniques and make them

00:18:58,559 --> 00:19:03,360
available through

00:18:59,520 --> 00:19:05,520
tools and so it's uh easier for somebody

00:19:03,360 --> 00:19:07,360
for a user to you know instead of

00:19:05,520 --> 00:19:09,280
reading a paper and trying to

00:19:07,360 --> 00:19:10,559
do that math themselves they just use

00:19:09,280 --> 00:19:14,400
two right so that

00:19:10,559 --> 00:19:16,640
there are two pronged strategy to try to

00:19:14,400 --> 00:19:16,640
help

00:19:18,559 --> 00:19:23,760
okay so having said that we created this

00:19:22,320 --> 00:19:27,360
toolkit called

00:19:23,760 --> 00:19:31,120
ai model efficiency toolkit amet for

00:19:27,360 --> 00:19:31,840
short and so what this toolkit does is

00:19:31,120 --> 00:19:33,440
has

00:19:31,840 --> 00:19:35,039
these model quantization and model

00:19:33,440 --> 00:19:38,160
compression techniques

00:19:35,039 --> 00:19:42,240
um and the way we have

00:19:38,160 --> 00:19:45,760
uh designed a met is it takes in

00:19:42,240 --> 00:19:48,320
a trained model uh so you

00:19:45,760 --> 00:19:50,880
uh you know this could be a model uh

00:19:48,320 --> 00:19:54,559
like by torch or tensorflow models

00:19:50,880 --> 00:19:58,000
and it you inject that model into this

00:19:54,559 --> 00:19:58,960
tool and out comes a more optimized

00:19:58,000 --> 00:20:02,240
model

00:19:58,960 --> 00:20:05,520
so uh the toolkit itself is not

00:20:02,240 --> 00:20:06,640
meant to uh you know create a quantized

00:20:05,520 --> 00:20:09,360
model for example

00:20:06,640 --> 00:20:09,679
it's me it's an efficiency toolkit so

00:20:09,360 --> 00:20:12,240
it's

00:20:09,679 --> 00:20:12,880
it it optimizes so it makes the model

00:20:12,240 --> 00:20:15,200
better

00:20:12,880 --> 00:20:16,000
for something so it makes the model

00:20:15,200 --> 00:20:18,320
better for

00:20:16,000 --> 00:20:20,080
running on quantized hardware or makes

00:20:18,320 --> 00:20:23,120
the model

00:20:20,080 --> 00:20:25,120
smaller by compressing it and we can

00:20:23,120 --> 00:20:28,240
apply both of them together

00:20:25,120 --> 00:20:28,720
right and the way it has been designed

00:20:28,240 --> 00:20:30,320
is

00:20:28,720 --> 00:20:32,840
we will see like for some of the

00:20:30,320 --> 00:20:35,360
techniques both from quantization and

00:20:32,840 --> 00:20:37,360
compression you may want to train the

00:20:35,360 --> 00:20:40,400
model a little bit further

00:20:37,360 --> 00:20:42,880
and this has dramatic

00:20:40,400 --> 00:20:44,240
improvements and accuracy and so this

00:20:42,880 --> 00:20:46,320
has been

00:20:44,240 --> 00:20:47,840
designed such that you know the model

00:20:46,320 --> 00:20:50,240
the optimized model that you can

00:20:47,840 --> 00:20:51,440
get back you can train with it a little

00:20:50,240 --> 00:20:53,679
bit and so it's

00:20:51,440 --> 00:20:55,039
still a training time it's not a model

00:20:53,679 --> 00:20:57,520
that is just you know

00:20:55,039 --> 00:20:58,080
you run on target so you can train it a

00:20:57,520 --> 00:21:01,120
little bit

00:20:58,080 --> 00:21:02,960
improve accuracy and then you basically

00:21:01,120 --> 00:21:04,720
take it to target so if you

00:21:02,960 --> 00:21:06,240
you know the one in the middle is how

00:21:04,720 --> 00:21:09,120
you take your model

00:21:06,240 --> 00:21:10,960
you know uh how you inject uh emet into

00:21:09,120 --> 00:21:11,280
your workflow it's so it's designed to

00:21:10,960 --> 00:21:17,840
be

00:21:11,280 --> 00:21:21,280
like a plug-in to your existing workflow

00:21:17,840 --> 00:21:24,559
and uh just in may

00:21:21,280 --> 00:21:25,120
we made this an open source project so

00:21:24,559 --> 00:21:28,080
we are

00:21:25,120 --> 00:21:30,080
very very happy uh that this is

00:21:28,080 --> 00:21:33,520
available as an open source project

00:21:30,080 --> 00:21:36,799
you can access it on github.com slash

00:21:33,520 --> 00:21:39,679
quick slash amend quick or quic

00:21:36,799 --> 00:21:40,159
stands for qualcomm innovation center so

00:21:39,679 --> 00:21:43,039
this

00:21:40,159 --> 00:21:45,200
that's the entity that makes amet

00:21:43,039 --> 00:21:47,679
available

00:21:45,200 --> 00:21:48,960
and one of the things you know i think

00:21:47,679 --> 00:21:52,000
there's a

00:21:48,960 --> 00:21:55,679
a lot of other

00:21:52,000 --> 00:21:57,360
open source projects with respect to

00:21:55,679 --> 00:21:59,360
even in the model efficiency field but

00:21:57,360 --> 00:22:01,280
definitely in the machine learning field

00:21:59,360 --> 00:22:03,280
uh so what we have tried to do with this

00:22:01,280 --> 00:22:05,200
project is in addition to just making

00:22:03,280 --> 00:22:06,320
you know source available we've tried to

00:22:05,200 --> 00:22:08,799
make it

00:22:06,320 --> 00:22:09,760
user friendly so it includes

00:22:08,799 --> 00:22:12,559
documentation

00:22:09,760 --> 00:22:14,000
includes code examples api

00:22:12,559 --> 00:22:16,960
documentations

00:22:14,000 --> 00:22:18,000
it has documentation on the techniques

00:22:16,960 --> 00:22:20,880
we also created

00:22:18,000 --> 00:22:21,919
of video tutorials that we have uploaded

00:22:20,880 --> 00:22:24,480
to youtube

00:22:21,919 --> 00:22:24,960
uh we'll have a link on that later on

00:22:24,480 --> 00:22:27,520
and

00:22:24,960 --> 00:22:28,880
uh so yeah we've tried to make this you

00:22:27,520 --> 00:22:30,960
know not only

00:22:28,880 --> 00:22:32,559
uh something that people can contribute

00:22:30,960 --> 00:22:33,520
to and like look at the source see what

00:22:32,559 --> 00:22:36,240
we have done

00:22:33,520 --> 00:22:38,840
but also it is something that can be

00:22:36,240 --> 00:22:41,840
easily used by

00:22:38,840 --> 00:22:41,840
somebody

00:22:42,880 --> 00:22:48,080
so what you know why why did we make it

00:22:45,600 --> 00:22:52,400
open source or what what are our goals

00:22:48,080 --> 00:22:53,760
um so you know as we saw i think the

00:22:52,400 --> 00:22:56,640
overall goal is to

00:22:53,760 --> 00:22:58,159
enable you know the whole ecosystem the

00:22:56,640 --> 00:23:02,159
whole

00:22:58,159 --> 00:23:03,919
academia industry to leverage these low

00:23:02,159 --> 00:23:07,039
power edge devices and

00:23:03,919 --> 00:23:09,360
push more and more ai workloads to these

00:23:07,039 --> 00:23:13,120
edge devices so that's our

00:23:09,360 --> 00:23:16,320
overall you know goal and

00:23:13,120 --> 00:23:18,720
there are uh you know in this one of the

00:23:16,320 --> 00:23:20,880
ways to

00:23:18,720 --> 00:23:22,000
impact the ecosystem is through

00:23:20,880 --> 00:23:25,039
releasing open source

00:23:22,000 --> 00:23:25,600
tools because that's the way um there's

00:23:25,039 --> 00:23:27,440
a

00:23:25,600 --> 00:23:28,880
much better way of collaborating with

00:23:27,440 --> 00:23:29,520
others because there are a whole bunch

00:23:28,880 --> 00:23:32,799
of other

00:23:29,520 --> 00:23:35,360
tools being developed as well um

00:23:32,799 --> 00:23:36,159
in this space and you know we we don't

00:23:35,360 --> 00:23:38,000
want to

00:23:36,159 --> 00:23:40,400
uh to the second point we don't want to

00:23:38,000 --> 00:23:42,240
like uh necessarily do

00:23:40,400 --> 00:23:43,760
uh just repeat what others are doing we

00:23:42,240 --> 00:23:46,000
want to do something that is

00:23:43,760 --> 00:23:46,799
an add-on and so we have designed these

00:23:46,000 --> 00:23:49,120
tools to

00:23:46,799 --> 00:23:50,000
plug in uh let's say with pytorch or

00:23:49,120 --> 00:23:53,039
tensorflow we

00:23:50,000 --> 00:23:55,200
build on top of other uh tools

00:23:53,039 --> 00:23:56,080
and there may be other tools that users

00:23:55,200 --> 00:23:57,679
are using and

00:23:56,080 --> 00:23:59,600
i think this is designed to such that

00:23:57,679 --> 00:24:02,080
you can layer this up you

00:23:59,600 --> 00:24:04,400
it's not meant to replace anything it's

00:24:02,080 --> 00:24:07,760
meant to be added on

00:24:04,400 --> 00:24:10,320
and overall like if at the end of this

00:24:07,760 --> 00:24:12,400
we can you know drive the community

00:24:10,320 --> 00:24:14,799
towards you know low precision inference

00:24:12,400 --> 00:24:16,000
i think that's that's the main main goal

00:24:14,799 --> 00:24:19,039
so i think if you look at

00:24:16,000 --> 00:24:20,880
uh generally people um

00:24:19,039 --> 00:24:22,159
there's a belief that you know hey

00:24:20,880 --> 00:24:25,440
models run

00:24:22,159 --> 00:24:27,919
good with 32-bit floats maybe 16

00:24:25,440 --> 00:24:29,919
bit floats is good enough but if you go

00:24:27,919 --> 00:24:31,760
down to 16-bit integers oh wow

00:24:29,919 --> 00:24:33,520
this is going to be a problem eight bit

00:24:31,760 --> 00:24:36,559
integers no that's not going to work

00:24:33,520 --> 00:24:38,960
so i think that there is uh this

00:24:36,559 --> 00:24:40,159
you know some folks have this perception

00:24:38,960 --> 00:24:42,559
and we want to

00:24:40,159 --> 00:24:44,400
uh remove that perception and you know

00:24:42,559 --> 00:24:46,320
make it

00:24:44,400 --> 00:24:47,679
easily possible for users to move

00:24:46,320 --> 00:24:51,600
towards integer

00:24:47,679 --> 00:24:54,320
inference so here's a very

00:24:51,600 --> 00:24:55,840
thousand foot or even higher for view of

00:24:54,320 --> 00:24:58,320
the architecture

00:24:55,840 --> 00:24:59,360
so i think what i want you to take away

00:24:58,320 --> 00:25:01,279
from this is

00:24:59,360 --> 00:25:03,840
uh there are a bunch of techniques built

00:25:01,279 --> 00:25:06,080
into these into this toolkit and

00:25:03,840 --> 00:25:07,840
while i may not go into detail on any

00:25:06,080 --> 00:25:09,840
one of those techniques here

00:25:07,840 --> 00:25:12,159
but you know the documentation is there

00:25:09,840 --> 00:25:15,679
the videos are there so you could

00:25:12,159 --> 00:25:17,360
browse those at your leisure uh i will

00:25:15,679 --> 00:25:19,520
motivate a few of those techniques a

00:25:17,360 --> 00:25:21,039
little bit uh

00:25:19,520 --> 00:25:23,440
so there are a bunch of techniques built

00:25:21,039 --> 00:25:25,120
in and the way we have designed this

00:25:23,440 --> 00:25:28,400
toolkit is we have

00:25:25,120 --> 00:25:31,440
have the model optimizations part of

00:25:28,400 --> 00:25:33,520
uh the code is separate from the

00:25:31,440 --> 00:25:35,840
extensions for tensorflow and pi dot

00:25:33,520 --> 00:25:37,840
so we want to make it easy for people i

00:25:35,840 --> 00:25:40,960
think pytorch and tensorflow are more

00:25:37,840 --> 00:25:42,159
common training frameworks so we wanted

00:25:40,960 --> 00:25:45,520
to make them easy

00:25:42,159 --> 00:25:48,720
for people to plug in their models into

00:25:45,520 --> 00:25:50,240
amet and so we have these extensions

00:25:48,720 --> 00:25:51,919
built in but we didn't want the

00:25:50,240 --> 00:25:54,000
optimizations to be tied to the

00:25:51,919 --> 00:25:56,159
extensions right so tomorrow

00:25:54,000 --> 00:25:58,000
if you know some collaborator wants to

00:25:56,159 --> 00:26:01,600
come in and use it with other

00:25:58,000 --> 00:26:04,559
uh frameworks or they may have their

00:26:01,600 --> 00:26:06,480
homegrown framework and they just want

00:26:04,559 --> 00:26:07,760
to use the optimizations i think that is

00:26:06,480 --> 00:26:11,279
possible for them to do

00:26:07,760 --> 00:26:13,039
of course if you use it with the these

00:26:11,279 --> 00:26:14,400
tensorflow python extensions you get

00:26:13,039 --> 00:26:17,440
higher level apis

00:26:14,400 --> 00:26:20,880
you use the model optimization library

00:26:17,440 --> 00:26:25,840
you have somewhat lower level apis

00:26:20,880 --> 00:26:25,840
but it's possible

00:26:26,480 --> 00:26:30,880
so um here's a one slide introduction to

00:26:30,240 --> 00:26:32,640
a

00:26:30,880 --> 00:26:34,640
couple of features on the quantization

00:26:32,640 --> 00:26:35,200
side and like i said i think there are

00:26:34,640 --> 00:26:37,520
actually

00:26:35,200 --> 00:26:38,400
a bunch of features that are already in

00:26:37,520 --> 00:26:40,880
and we are

00:26:38,400 --> 00:26:43,200
continuing to add more features like we

00:26:40,880 --> 00:26:46,880
saw the ad around feature coming in

00:26:43,200 --> 00:26:50,720
uh paper coming out in icml

00:26:46,880 --> 00:26:54,080
uh next month uh and so we are going to

00:26:50,720 --> 00:26:56,320
uh basically you know try to bring that

00:26:54,080 --> 00:26:59,120
into aim it as well

00:26:56,320 --> 00:27:00,159
but if you uh here's two features the

00:26:59,120 --> 00:27:02,720
one on the left

00:27:00,159 --> 00:27:03,840
is called data free quantization so this

00:27:02,720 --> 00:27:07,200
was a

00:27:03,840 --> 00:27:10,960
paper we released last year and this

00:27:07,200 --> 00:27:14,320
technique it's actually very very

00:27:10,960 --> 00:27:16,880
very applies very well to these

00:27:14,320 --> 00:27:18,799
traditionally harder to quantize models

00:27:16,880 --> 00:27:21,919
and the mobilenet family from

00:27:18,799 --> 00:27:23,440
google so mobilenet architecture is

00:27:21,919 --> 00:27:25,279
designed for these depth-wise

00:27:23,440 --> 00:27:27,600
convolutional layers or that twice

00:27:25,279 --> 00:27:30,320
separable layers

00:27:27,600 --> 00:27:31,120
and they are very efficient at doing you

00:27:30,320 --> 00:27:33,440
know

00:27:31,120 --> 00:27:34,559
machine learning like vision kind of use

00:27:33,440 --> 00:27:38,320
cases

00:27:34,559 --> 00:27:40,480
uh but when we take these models uh like

00:27:38,320 --> 00:27:42,559
for example the mobilenet v2 model

00:27:40,480 --> 00:27:43,760
the version two model take it to a

00:27:42,559 --> 00:27:45,679
quantized target

00:27:43,760 --> 00:27:47,679
you see a sharp drop in accuracy and

00:27:45,679 --> 00:27:51,919
depending on how the model is trained

00:27:47,679 --> 00:27:54,640
you will get you know less sharp and

00:27:51,919 --> 00:27:56,480
more sharp uh but nevertheless it's a

00:27:54,640 --> 00:27:59,279
sharp drop in accuracy

00:27:56,480 --> 00:28:00,640
and to the extent that it's not usable

00:27:59,279 --> 00:28:02,880
so these techniques

00:28:00,640 --> 00:28:04,880
are we call them the one on the left

00:28:02,880 --> 00:28:06,880
that data free quantization is a post

00:28:04,880 --> 00:28:10,159
training technique meaning we don't

00:28:06,880 --> 00:28:11,840
actually require the users to do any

00:28:10,159 --> 00:28:14,159
further training

00:28:11,840 --> 00:28:15,039
so you simply apply this technique and

00:28:14,159 --> 00:28:17,919
you get back

00:28:15,039 --> 00:28:18,559
uh a better model for quantization so

00:28:17,919 --> 00:28:21,600
it's a more

00:28:18,559 --> 00:28:23,520
in a magical fashion uh and though there

00:28:21,600 --> 00:28:25,919
are a bunch of you know different

00:28:23,520 --> 00:28:28,159
parts to this so the first part cross

00:28:25,919 --> 00:28:30,240
layer equalization and bias absorption

00:28:28,159 --> 00:28:31,679
basically what they are doing is you're

00:28:30,240 --> 00:28:33,440
looking at these

00:28:31,679 --> 00:28:34,880
layers in the model and you're

00:28:33,440 --> 00:28:38,640
equalizing the weights

00:28:34,880 --> 00:28:40,960
of adjacent layers so that

00:28:38,640 --> 00:28:42,080
across the channels in those layers you

00:28:40,960 --> 00:28:45,120
have more

00:28:42,080 --> 00:28:46,640
uniformity and which helps with

00:28:45,120 --> 00:28:49,279
quantization because when we are trying

00:28:46,640 --> 00:28:52,480
to find that scale factor across the

00:28:49,279 --> 00:28:54,080
channels if you had disparate like

00:28:52,480 --> 00:28:58,080
ranges in the channels

00:28:54,080 --> 00:29:00,240
you would find non-optimal scale

00:28:58,080 --> 00:29:01,919
factors on the other hand if you they

00:29:00,240 --> 00:29:04,559
were channels were more or

00:29:01,919 --> 00:29:05,520
less homogeneous then it's easy to find

00:29:04,559 --> 00:29:07,279
uh

00:29:05,520 --> 00:29:09,279
better scale factors so that's what

00:29:07,279 --> 00:29:10,320
those are doing the last technique bias

00:29:09,279 --> 00:29:12,880
correction

00:29:10,320 --> 00:29:14,799
is also an interesting artifact so with

00:29:12,880 --> 00:29:17,120
these depth wise separable layers

00:29:14,799 --> 00:29:19,679
you have less number of parameters and

00:29:17,120 --> 00:29:23,600
so i think there's more of a chance that

00:29:19,679 --> 00:29:25,600
just by rounding to the nearest you may

00:29:23,600 --> 00:29:26,880
you may have a shift in the output of

00:29:25,600 --> 00:29:29,279
layers and

00:29:26,880 --> 00:29:31,039
it's just like shift like a shift so we

00:29:29,279 --> 00:29:33,279
can observe that shift

00:29:31,039 --> 00:29:34,960
through passing some data and then we

00:29:33,279 --> 00:29:36,480
can correct that shift

00:29:34,960 --> 00:29:38,159
and so that's that's what those

00:29:36,480 --> 00:29:39,600
techniques are so the one on the left

00:29:38,159 --> 00:29:40,000
data free quantization as a post

00:29:39,600 --> 00:29:42,000
training

00:29:40,000 --> 00:29:45,279
technique one on the right is

00:29:42,000 --> 00:29:47,440
quantization aware training

00:29:45,279 --> 00:29:49,679
and basically this is a technique you

00:29:47,440 --> 00:29:52,960
will find in other tools as well

00:29:49,679 --> 00:29:56,000
but we have added a few tweaks to it

00:29:52,960 --> 00:29:58,080
so overall what happens here is

00:29:56,000 --> 00:29:59,279
you have a model like here you see a

00:29:58,080 --> 00:30:01,279
snippet of the model like a

00:29:59,279 --> 00:30:04,159
convolutional layer followed by a bias

00:30:01,279 --> 00:30:06,320
ad folder by relu

00:30:04,159 --> 00:30:07,520
so we add those green bubbles in here

00:30:06,320 --> 00:30:10,000
and these are

00:30:07,520 --> 00:30:11,360
called quantization simulation nodes

00:30:10,000 --> 00:30:13,520
into this model

00:30:11,360 --> 00:30:14,880
uh and what they would do is they would

00:30:13,520 --> 00:30:17,039
try to simulate

00:30:14,880 --> 00:30:18,240
uh then the quantization noise so

00:30:17,039 --> 00:30:20,720
specifically

00:30:18,240 --> 00:30:22,480
we saw a few slides back that you have

00:30:20,720 --> 00:30:23,039
the scale factor that you apply right

00:30:22,480 --> 00:30:25,520
and you

00:30:23,039 --> 00:30:26,399
you can apply the scale factor and you

00:30:25,520 --> 00:30:28,320
know uh

00:30:26,399 --> 00:30:29,520
sort of let's say divide by scale and

00:30:28,320 --> 00:30:32,720
multiply by scale

00:30:29,520 --> 00:30:35,360
so you uh these

00:30:32,720 --> 00:30:37,440
you get that noise due to the fact of

00:30:35,360 --> 00:30:40,159
getting rounded to the nearest integer

00:30:37,440 --> 00:30:41,919
right so those green nodes are going to

00:30:40,159 --> 00:30:43,840
simulate that noise

00:30:41,919 --> 00:30:45,360
and so when you simulate that noise what

00:30:43,840 --> 00:30:47,120
happens is now

00:30:45,360 --> 00:30:48,559
you're in your forward pass if you do an

00:30:47,120 --> 00:30:49,919
inference on the model using the

00:30:48,559 --> 00:30:53,760
simulation nodes in built

00:30:49,919 --> 00:30:56,960
in uh you will see that the accuracy now

00:30:53,760 --> 00:30:58,960
starts mimicking the accuracy you will

00:30:56,960 --> 00:31:00,880
see on a quantized target so that's

00:30:58,960 --> 00:31:01,679
that's good in itself like off target

00:31:00,880 --> 00:31:03,200
you get uh

00:31:01,679 --> 00:31:04,880
sort of you know how much am i going to

00:31:03,200 --> 00:31:07,200
get on target you get like a

00:31:04,880 --> 00:31:08,960
simulated score but now you can train

00:31:07,200 --> 00:31:10,159
with this and so what happens in this

00:31:08,960 --> 00:31:11,919
training is

00:31:10,159 --> 00:31:14,000
interestingly like the model knows that

00:31:11,919 --> 00:31:15,120
there is this noise in the forward pass

00:31:14,000 --> 00:31:17,760
and it will learn

00:31:15,120 --> 00:31:19,760
to counteract that noise so the couple

00:31:17,760 --> 00:31:22,320
of tweaks we've added with those green

00:31:19,760 --> 00:31:24,240
ops is we have a way of like inserting

00:31:22,320 --> 00:31:26,480
those nodes in the right place

00:31:24,240 --> 00:31:28,159
so i think it it turns out that we know

00:31:26,480 --> 00:31:31,279
we need to insert them in

00:31:28,159 --> 00:31:32,480
in the places that uh how things would

00:31:31,279 --> 00:31:34,880
run on target

00:31:32,480 --> 00:31:36,159
uh inserting it all over the place or a

00:31:34,880 --> 00:31:38,000
bit like let's say between the

00:31:36,159 --> 00:31:40,240
convolution and the bias add or

00:31:38,000 --> 00:31:41,679
between the bias and the railways is not

00:31:40,240 --> 00:31:44,159
the right thing to do

00:31:41,679 --> 00:31:45,440
and so we have a way of like inserting

00:31:44,159 --> 00:31:46,960
in the right place and we have a

00:31:45,440 --> 00:31:47,440
configurable way of doing this so you

00:31:46,960 --> 00:31:49,440
can

00:31:47,440 --> 00:31:52,799
change the configuration and you know

00:31:49,440 --> 00:31:56,880
adapt it to a particular runtime

00:31:52,799 --> 00:31:56,880
other things are those green

00:31:57,039 --> 00:32:00,960
nodes are also figuring out what scale

00:31:59,600 --> 00:32:04,080
factors to use

00:32:00,960 --> 00:32:07,120
and we have a advanced technique for

00:32:04,080 --> 00:32:09,679
finding out which we call uh

00:32:07,120 --> 00:32:10,720
signal to quantize noise ratio so we try

00:32:09,679 --> 00:32:14,000
to find

00:32:10,720 --> 00:32:18,000
the scale these optimal scale factors

00:32:14,000 --> 00:32:18,399
which may exclude certain outlier values

00:32:18,000 --> 00:32:20,320
and

00:32:18,399 --> 00:32:22,399
you know just try to have more

00:32:20,320 --> 00:32:25,919
resolution over the more uh

00:32:22,399 --> 00:32:30,159
probable uh values that we see

00:32:25,919 --> 00:32:30,159
in a particular activation or weight

00:32:30,240 --> 00:32:33,760
so here is uh some results out of this

00:32:32,559 --> 00:32:37,440
and i i

00:32:33,760 --> 00:32:39,360
i can obviously understand that

00:32:37,440 --> 00:32:41,519
with that one slide i think you're not

00:32:39,360 --> 00:32:42,240
gonna perhaps understand everything that

00:32:41,519 --> 00:32:44,890
i said

00:32:42,240 --> 00:32:47,000
but if you go back to uh

00:32:44,890 --> 00:32:49,279
[Music]

00:32:47,000 --> 00:32:50,640
github.com you will see uh

00:32:49,279 --> 00:32:52,480
user guides which explain these

00:32:50,640 --> 00:32:54,480
techniques a little more in detail

00:32:52,480 --> 00:32:56,559
and also we have those videos on youtube

00:32:54,480 --> 00:32:57,440
so please look at those so here are some

00:32:56,559 --> 00:32:59,279
results

00:32:57,440 --> 00:33:01,120
uh we applied these uh data free

00:32:59,279 --> 00:33:03,760
quantization techniques

00:33:01,120 --> 00:33:05,120
uh and this is like you see different

00:33:03,760 --> 00:33:06,640
models but let's look at like the

00:33:05,120 --> 00:33:09,120
mobilenet v2 model

00:33:06,640 --> 00:33:09,760
uh floating point accuracy so what i

00:33:09,120 --> 00:33:11,120
want to take

00:33:09,760 --> 00:33:12,880
you to take away is like if you look at

00:33:11,120 --> 00:33:14,640
the interior 8

00:33:12,880 --> 00:33:16,480
inference versus the floating point

00:33:14,640 --> 00:33:19,279
32-bit inference

00:33:16,480 --> 00:33:20,880
there is uh not a whole lot of

00:33:19,279 --> 00:33:22,640
difference between them right so they

00:33:20,880 --> 00:33:24,240
have come very close

00:33:22,640 --> 00:33:26,399
you're running you're getting all these

00:33:24,240 --> 00:33:28,000
benefits that we saw but you are

00:33:26,399 --> 00:33:30,159
getting the accuracy that you would have

00:33:28,000 --> 00:33:32,480
gotten if you ran it in floating point

00:33:30,159 --> 00:33:34,080
and you can actually apply this data

00:33:32,480 --> 00:33:34,640
free quantization and the quantization

00:33:34,080 --> 00:33:38,080
of it

00:33:34,640 --> 00:33:39,919
training techniques uh or combine

00:33:38,080 --> 00:33:42,080
them together so you can apply this and

00:33:39,919 --> 00:33:42,960
then do quantization of a training on

00:33:42,080 --> 00:33:45,519
top of this

00:33:42,960 --> 00:33:46,480
and that actually helps uh quite a bit

00:33:45,519 --> 00:33:49,679
so you would

00:33:46,480 --> 00:33:50,880
further close the gap so specifically

00:33:49,679 --> 00:33:53,120
for mobile knight we do

00:33:50,880 --> 00:33:54,399
uh i just wanted to like uh interesting

00:33:53,120 --> 00:33:57,360
data point is

00:33:54,399 --> 00:33:59,360
uh you have you know starting 71.72

00:33:57,360 --> 00:34:01,279
floating point accuracy if you

00:33:59,360 --> 00:34:02,480
depending on which model you use if you

00:34:01,279 --> 00:34:05,279
take it to target

00:34:02,480 --> 00:34:06,159
it's going to show you on integer 8-bit

00:34:05,279 --> 00:34:07,919
targets

00:34:06,159 --> 00:34:10,480
it will show you like close to zero

00:34:07,919 --> 00:34:13,119
percent accuracy it's a very sharp drop

00:34:10,480 --> 00:34:13,599
depending on the model obviously uh but

00:34:13,119 --> 00:34:16,079
then

00:34:13,599 --> 00:34:18,000
you can see that even with those sharply

00:34:16,079 --> 00:34:21,839
dropped models we have recovered it back

00:34:18,000 --> 00:34:21,839
almost close to where it was

00:34:23,440 --> 00:34:27,520
so uh i mentioned that we've tried to

00:34:26,879 --> 00:34:29,919
make this

00:34:27,520 --> 00:34:31,359
uh as user friendly as possible and so i

00:34:29,919 --> 00:34:33,839
think this is one slide which

00:34:31,359 --> 00:34:35,520
sort of tries to motivate that so the

00:34:33,839 --> 00:34:35,839
data free quantization techniques like

00:34:35,520 --> 00:34:37,599
you

00:34:35,839 --> 00:34:39,599
saw there are multiple techniques that

00:34:37,599 --> 00:34:41,599
go in there and if you

00:34:39,599 --> 00:34:43,040
peel the onion there's actually other

00:34:41,599 --> 00:34:45,679
things that happen like

00:34:43,040 --> 00:34:47,040
bias batch normal layers get folded and

00:34:45,679 --> 00:34:50,480
so on so forth

00:34:47,040 --> 00:34:52,480
all of that gets wrapped up in this

00:34:50,480 --> 00:34:54,079
uh in the first call you see their

00:34:52,480 --> 00:34:56,879
equalizer underscore model

00:34:54,079 --> 00:34:58,079
so make one call give it a model in this

00:34:56,879 --> 00:35:00,560
case this is our

00:34:58,079 --> 00:35:01,359
by torch model from torch vision uh give

00:35:00,560 --> 00:35:02,960
it that model

00:35:01,359 --> 00:35:05,040
tell you know what is the input shape to

00:35:02,960 --> 00:35:07,920
your model and that's it

00:35:05,040 --> 00:35:08,240
in place that model will be made better

00:35:07,920 --> 00:35:10,480
and

00:35:08,240 --> 00:35:11,680
all those techniques get applied uh the

00:35:10,480 --> 00:35:14,800
second half

00:35:11,680 --> 00:35:16,480
uh shows how uh you can

00:35:14,800 --> 00:35:17,920
apply these quantization simulation

00:35:16,480 --> 00:35:20,560
nodes and again you

00:35:17,920 --> 00:35:21,280
you know give it a model you make one

00:35:20,560 --> 00:35:22,800
call to

00:35:21,280 --> 00:35:24,640
compute end codecs which is going to

00:35:22,800 --> 00:35:27,839
find those scale factors which

00:35:24,640 --> 00:35:28,800
we call as encodings as well and once

00:35:27,839 --> 00:35:31,920
you've done that you

00:35:28,800 --> 00:35:34,320
have this simulated model sim dot model

00:35:31,920 --> 00:35:36,320
which has these nodes inserted into it

00:35:34,320 --> 00:35:38,800
now you can invoke your

00:35:36,320 --> 00:35:42,160
existing pipeline like this evaluate

00:35:38,800 --> 00:35:44,320
model is the user pipeline to evaluate

00:35:42,160 --> 00:35:45,680
and like if you did evaluate underscore

00:35:44,320 --> 00:35:47,440
model and past it

00:35:45,680 --> 00:35:48,720
model you will get the floating point

00:35:47,440 --> 00:35:50,560
accuracy if you did

00:35:48,720 --> 00:35:52,160
evaluate model and pass and sim dot

00:35:50,560 --> 00:35:54,240
model you get

00:35:52,160 --> 00:35:56,400
the integer or a simulation of the

00:35:54,240 --> 00:35:59,119
integer eight bit accuracy

00:35:56,400 --> 00:35:59,520
and uh it's it's fairly simple it plugs

00:35:59,119 --> 00:36:01,359
in

00:35:59,520 --> 00:36:02,640
with existing pipelines i think that's

00:36:01,359 --> 00:36:05,839
the main

00:36:02,640 --> 00:36:05,839
takeaway from the slide

00:36:06,480 --> 00:36:12,320
uh so going on to um compression

00:36:10,160 --> 00:36:13,200
uh so there are a bunch of compression

00:36:12,320 --> 00:36:15,920
features

00:36:13,200 --> 00:36:17,520
um one on the left is our tensor

00:36:15,920 --> 00:36:18,880
decomposition kind of feature so what

00:36:17,520 --> 00:36:22,480
happens here

00:36:18,880 --> 00:36:25,520
is you take a layer like a convolutional

00:36:22,480 --> 00:36:28,000
layer and you split it into two layers

00:36:25,520 --> 00:36:29,200
and you would say oh that's not

00:36:28,000 --> 00:36:32,880
compressing that's like

00:36:29,200 --> 00:36:34,960
inflating but the the way you

00:36:32,880 --> 00:36:36,800
compress you split it into these two

00:36:34,960 --> 00:36:39,440
layers

00:36:36,800 --> 00:36:40,320
you have two smaller layers and the

00:36:39,440 --> 00:36:42,240
combination

00:36:40,320 --> 00:36:43,359
even with the two layers combined the

00:36:42,240 --> 00:36:45,520
combination

00:36:43,359 --> 00:36:46,880
it is much smaller than the layer you

00:36:45,520 --> 00:36:50,000
started out with

00:36:46,880 --> 00:36:53,440
and uh so the way this works is you see

00:36:50,000 --> 00:36:55,440
like you may have a weight matrix on

00:36:53,440 --> 00:36:56,960
this lay on this convolutional layer you

00:36:55,440 --> 00:36:59,280
started out with

00:36:56,960 --> 00:37:00,240
we flatten it into a two dimensional

00:36:59,280 --> 00:37:03,920
space

00:37:00,240 --> 00:37:05,680
and then we basically apply the singular

00:37:03,920 --> 00:37:05,920
value decomposition technique from you

00:37:05,680 --> 00:37:08,480
know

00:37:05,920 --> 00:37:09,839
from your math classes and you get like

00:37:08,480 --> 00:37:14,000
two different

00:37:09,839 --> 00:37:16,480
uh two uh reduced uh

00:37:14,000 --> 00:37:18,079
uh matrices so generally with singular

00:37:16,480 --> 00:37:19,839
value decomposition you have three

00:37:18,079 --> 00:37:21,760
matrices the second the third one in the

00:37:19,839 --> 00:37:24,240
middle let's

00:37:21,760 --> 00:37:25,680
diagonal matrix with singular values or

00:37:24,240 --> 00:37:28,000
small numbers

00:37:25,680 --> 00:37:29,440
uh and what we do is you can throw away

00:37:28,000 --> 00:37:30,880
some of those numbers they are small so

00:37:29,440 --> 00:37:34,079
you can throw them away

00:37:30,880 --> 00:37:34,880
and so now you get essentially two

00:37:34,079 --> 00:37:37,920
smaller

00:37:34,880 --> 00:37:39,760
layers if you combine that back into

00:37:37,920 --> 00:37:41,200
into two layers so you take that

00:37:39,760 --> 00:37:42,880
diagonal matrix

00:37:41,200 --> 00:37:44,480
throw away some of the values and then

00:37:42,880 --> 00:37:46,320
combine it back

00:37:44,480 --> 00:37:47,599
multiply it back with the one on the

00:37:46,320 --> 00:37:50,160
left and one on the right

00:37:47,599 --> 00:37:52,240
you get new smaller layers the technique

00:37:50,160 --> 00:37:53,760
on the right channel pruning that is

00:37:52,240 --> 00:37:55,920
going to take convolutional layers let's

00:37:53,760 --> 00:37:57,520
say and throw away some of the input

00:37:55,920 --> 00:37:59,839
channels to those convolutional layers

00:37:57,520 --> 00:38:01,839
because maybe not all of the features

00:37:59,839 --> 00:38:04,400
are as important to the final accuracy

00:38:01,839 --> 00:38:07,200
of the model given your task and

00:38:04,400 --> 00:38:08,640
it basically throws it away changes the

00:38:07,200 --> 00:38:10,240
model architecture because you have to

00:38:08,640 --> 00:38:12,960
change the remaining

00:38:10,240 --> 00:38:14,000
architecture in place so because you

00:38:12,960 --> 00:38:16,720
have changed

00:38:14,000 --> 00:38:18,240
the dimension of this particular layer

00:38:16,720 --> 00:38:20,640
so it goes to the previous layers and

00:38:18,240 --> 00:38:24,240
changes its dimension and so on

00:38:20,640 --> 00:38:24,720
um and one thing that i want you to take

00:38:24,240 --> 00:38:26,000
away is

00:38:24,720 --> 00:38:28,320
while there are these techniques and

00:38:26,000 --> 00:38:30,400
there is you know a bunch of like

00:38:28,320 --> 00:38:32,560
nitty gritty details and math involved

00:38:30,400 --> 00:38:34,640
in them

00:38:32,560 --> 00:38:36,079
how these techniques are applied and how

00:38:34,640 --> 00:38:37,920
you select

00:38:36,079 --> 00:38:39,200
how much to compress each layer all of

00:38:37,920 --> 00:38:42,880
that is done in a

00:38:39,200 --> 00:38:44,720
somewhat automatic fashion and so uh

00:38:42,880 --> 00:38:46,320
the automatic selection of these you

00:38:44,720 --> 00:38:47,440
know per layer compressions is i think

00:38:46,320 --> 00:38:49,839
one of the

00:38:47,440 --> 00:38:51,119
key takeaways from it so it's easy to

00:38:49,839 --> 00:38:53,200
use and

00:38:51,119 --> 00:38:55,440
you can go you can you don't have to use

00:38:53,200 --> 00:38:58,240
the easy to use apis you can go and

00:38:55,440 --> 00:39:00,720
use the more underlying apis if you

00:38:58,240 --> 00:39:03,200
wanted to try something different

00:39:00,720 --> 00:39:04,960
so these techniques can be applied like

00:39:03,200 --> 00:39:06,640
back to back the spatial svd and channel

00:39:04,960 --> 00:39:08,960
pruning techniques and here is

00:39:06,640 --> 00:39:10,640
here are uh some results like resonant

00:39:08,960 --> 00:39:12,400
50 and resonant 18 these are some of the

00:39:10,640 --> 00:39:15,760
more popular models

00:39:12,400 --> 00:39:18,320
and you will see that um

00:39:15,760 --> 00:39:19,520
we achieved quite a good reduction

00:39:18,320 --> 00:39:22,880
there's a 50

00:39:19,520 --> 00:39:23,280
mac reduction and the accuracy stays you

00:39:22,880 --> 00:39:25,520
know

00:39:23,280 --> 00:39:26,880
very close to where we started out from

00:39:25,520 --> 00:39:30,320
so very uh

00:39:26,880 --> 00:39:34,400
very interesting and heartening results

00:39:30,320 --> 00:39:37,680
and i have a demo for you to show

00:39:34,400 --> 00:39:40,079
i'm gonna share my screen uh so

00:39:37,680 --> 00:39:41,280
it's it's a real-time pose estimation

00:39:40,079 --> 00:39:43,680
model and let me

00:39:41,280 --> 00:39:44,720
share my screen and show you so it's

00:39:43,680 --> 00:39:47,280
easier

00:39:44,720 --> 00:39:47,280
for you to see

00:39:48,960 --> 00:39:53,760
so uh what you're going to see in this

00:39:50,720 --> 00:39:56,400
video is

00:39:53,760 --> 00:39:57,520
here is a just a computer monitor and

00:39:56,400 --> 00:39:59,280
it's playing a video

00:39:57,520 --> 00:40:00,640
of you know some people dancing on the

00:39:59,280 --> 00:40:04,160
beach or

00:40:00,640 --> 00:40:07,040
close to the beach and we have

00:40:04,160 --> 00:40:08,880
two phones over here uh these are

00:40:07,040 --> 00:40:11,040
actually commercial phones uh

00:40:08,880 --> 00:40:13,280
so you know more funky business going on

00:40:11,040 --> 00:40:16,160
here and the one of the

00:40:13,280 --> 00:40:17,680
on the top is using an uncompressed

00:40:16,160 --> 00:40:19,839
model the one on the

00:40:17,680 --> 00:40:21,760
bottom is using a compressed model in

00:40:19,839 --> 00:40:23,599
this case this pose estimation model is

00:40:21,760 --> 00:40:25,839
a fairly heavy model

00:40:23,599 --> 00:40:27,200
so if you run it uncompressed you get

00:40:25,839 --> 00:40:29,440
only like

00:40:27,200 --> 00:40:30,319
five frames per second that's the

00:40:29,440 --> 00:40:32,880
inference

00:40:30,319 --> 00:40:34,240
it's all gated by how much how fast you

00:40:32,880 --> 00:40:36,160
can run the inferences

00:40:34,240 --> 00:40:38,000
whereas on the compressed model we

00:40:36,160 --> 00:40:41,040
compress that model down

00:40:38,000 --> 00:40:44,960
you know more than four times and

00:40:41,040 --> 00:40:46,000
um not only is it you see on paper gains

00:40:44,960 --> 00:40:48,160
but you can see like

00:40:46,000 --> 00:40:49,440
real gains on device where the

00:40:48,160 --> 00:40:51,599
inferences have

00:40:49,440 --> 00:40:52,560
sped up by you know close to a factor of

00:40:51,599 --> 00:40:54,160
four

00:40:52,560 --> 00:40:57,040
right so i'm gonna play this video the

00:40:54,160 --> 00:41:00,079
way uh we've tried to

00:40:57,040 --> 00:41:00,960
show this is we do the inferences and

00:41:00,079 --> 00:41:03,119
then we

00:41:00,960 --> 00:41:04,079
superimpose the results on top of the

00:41:03,119 --> 00:41:07,040
video

00:41:04,079 --> 00:41:09,040
um and so the video it's just taking the

00:41:07,040 --> 00:41:13,280
video stream from the camera here right

00:41:09,040 --> 00:41:16,079
uh so you see that the the skeletons lag

00:41:13,280 --> 00:41:18,240
the people and that's just a way of

00:41:16,079 --> 00:41:20,160
showing that the inferences were so late

00:41:18,240 --> 00:41:21,359
whereas you see on the bottom the

00:41:20,160 --> 00:41:24,400
compressed model

00:41:21,359 --> 00:41:26,880
you can see those that those uh

00:41:24,400 --> 00:41:27,920
skeletons actually are very much tight

00:41:26,880 --> 00:41:32,160
on top of the

00:41:27,920 --> 00:41:32,160
actual uh people in the video

00:41:32,640 --> 00:41:35,839
so um

00:41:36,560 --> 00:41:40,880
yeah hopefully that was interesting for

00:41:38,720 --> 00:41:40,880
you

00:41:41,119 --> 00:41:45,920
uh we also have uh built-in uh

00:41:43,440 --> 00:41:47,920
visualizations like tools to help you

00:41:45,920 --> 00:41:49,200
see you know how your model is how is

00:41:47,920 --> 00:41:51,040
the compression going how

00:41:49,200 --> 00:41:52,800
you know is it good for quantization not

00:41:51,040 --> 00:41:55,920
good for quantization so there are built

00:41:52,800 --> 00:41:59,599
up number of built-in visualizations

00:41:55,920 --> 00:42:03,200
um so yeah i wanted to like sort of

00:41:59,599 --> 00:42:05,280
end with some sort of insights on we

00:42:03,200 --> 00:42:06,400
as we you know did this open source

00:42:05,280 --> 00:42:08,319
project now what were

00:42:06,400 --> 00:42:09,839
some of the learnings we had as part of

00:42:08,319 --> 00:42:13,040
this and

00:42:09,839 --> 00:42:16,079
um you know one thing we

00:42:13,040 --> 00:42:19,200
sort of uh realized is like

00:42:16,079 --> 00:42:21,599
we we would like you know as people make

00:42:19,200 --> 00:42:22,400
uh comments and you know as contributors

00:42:21,599 --> 00:42:24,720
come in and

00:42:22,400 --> 00:42:26,800
uh help me come and see what since the

00:42:24,720 --> 00:42:29,680
time we launched they have been like

00:42:26,800 --> 00:42:32,400
close to 100 comments already made just

00:42:29,680 --> 00:42:35,760
within the last month or so

00:42:32,400 --> 00:42:37,680
and we want those commits to be uh

00:42:35,760 --> 00:42:39,200
you know regressed so we don't want we

00:42:37,680 --> 00:42:41,920
want to make sure that you know

00:42:39,200 --> 00:42:42,319
as the commits come in uh they don't

00:42:41,920 --> 00:42:46,160
break

00:42:42,319 --> 00:42:50,000
existing stuff so we have to set up we

00:42:46,160 --> 00:42:52,319
we are using jenkins uh ci

00:42:50,000 --> 00:42:53,040
and we you know set it up on an aws

00:42:52,319 --> 00:42:55,680
instance we

00:42:53,040 --> 00:42:58,640
set up some dockers so that we can have

00:42:55,680 --> 00:43:02,079
a reproducible environment and then we

00:42:58,640 --> 00:43:03,680
from github from the pr so we drive

00:43:02,079 --> 00:43:05,440
these jobs

00:43:03,680 --> 00:43:07,359
so that has helped a lot so that was one

00:43:05,440 --> 00:43:09,119
thing that we

00:43:07,359 --> 00:43:10,640
you know had to think through and say

00:43:09,119 --> 00:43:11,280
okay this is something that we would

00:43:10,640 --> 00:43:14,160
need

00:43:11,280 --> 00:43:14,800
uh same thing we had to make our unit

00:43:14,160 --> 00:43:18,400
tests

00:43:14,800 --> 00:43:20,160
be much more expanded um we used to test

00:43:18,400 --> 00:43:21,839
like some through unit tests and some

00:43:20,160 --> 00:43:23,359
some full-blown tests with these big

00:43:21,839 --> 00:43:25,599
models and so on

00:43:23,359 --> 00:43:27,200
and it just doesn't help to have those

00:43:25,599 --> 00:43:29,680
big models be part of

00:43:27,200 --> 00:43:31,200
a pr regression you want the pr

00:43:29,680 --> 00:43:34,480
regressions to be fairly

00:43:31,200 --> 00:43:36,640
tight small short and so we wanted to

00:43:34,480 --> 00:43:38,400
express the same so we expanded our unit

00:43:36,640 --> 00:43:40,319
test to cover a whole lot of

00:43:38,400 --> 00:43:42,240
scenarios so we don't need to run it

00:43:40,319 --> 00:43:45,280
with these full-blown models

00:43:42,240 --> 00:43:47,119
um and then one thing that we haven't we

00:43:45,280 --> 00:43:48,079
still are working on is like we realized

00:43:47,119 --> 00:43:50,079
that

00:43:48,079 --> 00:43:51,599
people have disparate development

00:43:50,079 --> 00:43:55,200
environment so

00:43:51,599 --> 00:43:56,880
while we assumed that hey

00:43:55,200 --> 00:43:59,680
most people would have workstations with

00:43:56,880 --> 00:44:00,400
cuda enabled workstations like with gpus

00:43:59,680 --> 00:44:02,079
on them

00:44:00,400 --> 00:44:04,319
uh and it's it's actually helps for

00:44:02,079 --> 00:44:06,160
these techniques to have

00:44:04,319 --> 00:44:08,000
cooler because we do accelerate some of

00:44:06,160 --> 00:44:10,880
these techniques using included

00:44:08,000 --> 00:44:12,800
but you know if for folks who are

00:44:10,880 --> 00:44:14,400
developers who don't have

00:44:12,800 --> 00:44:16,160
that environment you know we should make

00:44:14,400 --> 00:44:16,880
it available such that they can still

00:44:16,160 --> 00:44:18,960
run

00:44:16,880 --> 00:44:20,000
a little bit slower but they they should

00:44:18,960 --> 00:44:21,599
still be able to run

00:44:20,000 --> 00:44:23,119
and so i think that last item is

00:44:21,599 --> 00:44:26,000
something that we learned but we are

00:44:23,119 --> 00:44:26,000
still working on

00:44:27,280 --> 00:44:33,760
so yeah in summary uh uh we

00:44:31,599 --> 00:44:36,319
have you know very happy to launch this

00:44:33,760 --> 00:44:38,480
ei model efficiency toolkit

00:44:36,319 --> 00:44:40,160
and it has these state of art

00:44:38,480 --> 00:44:43,040
quantization and compression

00:44:40,160 --> 00:44:44,240
techniques and more are being in the

00:44:43,040 --> 00:44:46,560
works and we

00:44:44,240 --> 00:44:48,720
hope to work along with the community

00:44:46,560 --> 00:44:50,880
and keep adding more and we would really

00:44:48,720 --> 00:44:52,079
love to see contributors come in and

00:44:50,880 --> 00:44:55,440
help us

00:44:52,079 --> 00:44:57,359
expand this toolkit

00:44:55,440 --> 00:44:59,520
and we currently support tensorflow and

00:44:57,359 --> 00:45:01,680
pytorch models and we

00:44:59,520 --> 00:45:02,960
perhaps add some more support for keras

00:45:01,680 --> 00:45:04,640
going forward and

00:45:02,960 --> 00:45:06,880
you know with more contributions we

00:45:04,640 --> 00:45:08,880
could do more um

00:45:06,880 --> 00:45:10,560
and yeah the main thing is we are trying

00:45:08,880 --> 00:45:14,240
to design a user-friendly

00:45:10,560 --> 00:45:15,280
uh way of optimizations uh so please

00:45:14,240 --> 00:45:17,440
come

00:45:15,280 --> 00:45:18,319
visit us collaborate with us at

00:45:17,440 --> 00:45:21,359
github.com

00:45:18,319 --> 00:45:23,280
quick amet and here's a link to

00:45:21,359 --> 00:45:25,359
if you go to youtube and you search for

00:45:23,280 --> 00:45:29,119
qualcomm innovation center

00:45:25,359 --> 00:45:31,839
uh or quick space amet

00:45:29,119 --> 00:45:32,319
you will see a whole set of videos like

00:45:31,839 --> 00:45:34,880
about

00:45:32,319 --> 00:45:37,040
six or so and they they would go into

00:45:34,880 --> 00:45:37,680
much more detail including code examples

00:45:37,040 --> 00:45:41,440
and so on

00:45:37,680 --> 00:45:44,800
uh into these features

00:45:41,440 --> 00:45:47,359
so um that's it

00:45:44,800 --> 00:45:48,960
thanks for the for you know paying

00:45:47,359 --> 00:45:51,280
attention and let me uh

00:45:48,960 --> 00:45:54,720
explain these things to you so i see

00:45:51,280 --> 00:45:54,720
that there are some questions

00:45:55,520 --> 00:46:04,160
that have come in

00:46:00,480 --> 00:46:07,440
so um one question

00:46:04,160 --> 00:46:10,800
is um if we

00:46:07,440 --> 00:46:15,280
quantize the parameters uh we won't have

00:46:10,800 --> 00:46:17,599
the best model accuracy um

00:46:15,280 --> 00:46:19,119
meaning i i guess the question here is

00:46:17,599 --> 00:46:21,119
uh perhaps that hey

00:46:19,119 --> 00:46:24,000
if you quantize you know what happens to

00:46:21,119 --> 00:46:26,160
your accuracy and as we saw through the

00:46:24,000 --> 00:46:28,480
uh through the deck i think it all

00:46:26,160 --> 00:46:31,440
depends there are some models

00:46:28,480 --> 00:46:32,079
uh resonant 18 is a good example i think

00:46:31,440 --> 00:46:35,200
it you know

00:46:32,079 --> 00:46:38,319
just by doing basic quantizations

00:46:35,200 --> 00:46:39,040
techniques you can actually run it on

00:46:38,319 --> 00:46:41,359
8-bit

00:46:39,040 --> 00:46:44,079
integers and not see a huge drop like

00:46:41,359 --> 00:46:46,000
less than a percent of accuracy drop

00:46:44,079 --> 00:46:48,000
uh but other models like the mobilenet

00:46:46,000 --> 00:46:49,599
v2 example we saw that there is a sharp

00:46:48,000 --> 00:46:50,960
drop in accuracy so it all depends on

00:46:49,599 --> 00:46:53,839
your on the model

00:46:50,960 --> 00:46:55,440
uh but yeah we believe these techniques

00:46:53,839 --> 00:46:57,839
help with some morals as they are not

00:46:55,440 --> 00:47:00,560
magic bullets to help with all models

00:46:57,839 --> 00:47:02,240
but we continue to find uh like research

00:47:00,560 --> 00:47:03,520
other techniques like the head around

00:47:02,240 --> 00:47:07,760
and nation beds and

00:47:03,520 --> 00:47:10,960
more stuff is are coming and uh

00:47:07,760 --> 00:47:13,200
we we think that for the for the vast

00:47:10,960 --> 00:47:16,160
majority of the models out there we

00:47:13,200 --> 00:47:17,440
we should be able to run them on 8-bit

00:47:16,160 --> 00:47:18,880
integer

00:47:17,440 --> 00:47:20,960
and you know there are certain models

00:47:18,880 --> 00:47:24,559
where if that is

00:47:20,960 --> 00:47:26,160
super hard to do some layers not all

00:47:24,559 --> 00:47:28,640
have some layers could be run

00:47:26,160 --> 00:47:31,280
at 16 bit integer and i think with 16

00:47:28,640 --> 00:47:33,680
bit integer our experience has been that

00:47:31,280 --> 00:47:36,400
practically all models can you know run

00:47:33,680 --> 00:47:39,839
with almost no drop in accuracy

00:47:36,400 --> 00:47:42,480
so yeah so i think yeah quantizing

00:47:39,839 --> 00:47:44,079
does have a impact but i think the

00:47:42,480 --> 00:47:45,440
techniques and that's the reason for

00:47:44,079 --> 00:47:49,359
tools like amet

00:47:45,440 --> 00:47:49,359
to help recover back the accuracy

00:47:49,680 --> 00:47:54,000
i think another question was um

00:47:54,240 --> 00:47:59,280
uh how to use the rest apis i assume you

00:47:57,520 --> 00:48:00,160
know can the canvas be invoked using

00:47:59,280 --> 00:48:02,559
rest apis

00:48:00,160 --> 00:48:04,319
and i think while there is nothing built

00:48:02,559 --> 00:48:08,800
in here for this tool for

00:48:04,319 --> 00:48:11,200
rest apis but you can like host this

00:48:08,800 --> 00:48:13,280
tool anywhere and you know build some

00:48:11,200 --> 00:48:15,280
rest apis on top should be fairly simple

00:48:13,280 --> 00:48:17,599
to do i would think

00:48:15,280 --> 00:48:20,240
so yeah nothing precludes not that it

00:48:17,599 --> 00:48:21,119
has today but any sdps board but nothing

00:48:20,240 --> 00:48:23,760
precludes that

00:48:21,119 --> 00:48:23,760
to be added

00:48:26,720 --> 00:48:30,960
another question was uh does qualcomm

00:48:28,960 --> 00:48:33,280
have any specific chip or edge device to

00:48:30,960 --> 00:48:35,839
work on ai or deep learning

00:48:33,280 --> 00:48:37,520
so yeah if you if you look at you know a

00:48:35,839 --> 00:48:38,000
lot of the cell phones i mean which is

00:48:37,520 --> 00:48:40,640
the most

00:48:38,000 --> 00:48:41,760
uh you know simple device that you may

00:48:40,640 --> 00:48:45,599
have access to

00:48:41,760 --> 00:48:47,680
um a lot of the cell phones have

00:48:45,599 --> 00:48:48,960
uh snapdragon chipsets them synthesis

00:48:47,680 --> 00:48:52,880
snapdragon chipsets

00:48:48,960 --> 00:48:54,960
have uh ai influencer inference engines

00:48:52,880 --> 00:48:58,160
uh specific

00:48:54,960 --> 00:48:59,119
which also run with integer quantized

00:48:58,160 --> 00:49:01,359
models

00:48:59,119 --> 00:49:02,480
and get all those benefits that we

00:49:01,359 --> 00:49:05,680
looked at up front so

00:49:02,480 --> 00:49:08,000
yes definitely qualcomm is uh

00:49:05,680 --> 00:49:08,800
in the edge ai business if you may and

00:49:08,000 --> 00:49:10,160
so they have

00:49:08,800 --> 00:49:17,760
different we have different solutions

00:49:10,160 --> 00:49:22,079
for this

00:49:17,760 --> 00:49:25,440
uh can you place the link to github uh

00:49:22,079 --> 00:49:26,559
uh yeah uh yeah i don't need to i think

00:49:25,440 --> 00:49:27,920
place it i guess you can go to

00:49:26,559 --> 00:49:31,839
github.com

00:49:27,920 --> 00:49:35,200
quick q i c slash aim at a i m e key

00:49:31,839 --> 00:49:35,200
and that's it

00:49:39,839 --> 00:49:44,599
uh where is another question will this

00:49:41,599 --> 00:49:46,559
work without nvidia gpu cards let's say

00:49:44,599 --> 00:49:48,640
opencl

00:49:46,559 --> 00:49:50,160
uh it says in the installation procedure

00:49:48,640 --> 00:49:53,359
that this is the requirement

00:49:50,160 --> 00:49:54,079
so uh yeah thanks for that question

00:49:53,359 --> 00:49:56,720
alexander

00:49:54,079 --> 00:49:58,480
yeah like i mentioned in the one of the

00:49:56,720 --> 00:50:00,079
key learnings we have had is i think you

00:49:58,480 --> 00:50:00,880
know people's development environments

00:50:00,079 --> 00:50:03,680
are different

00:50:00,880 --> 00:50:05,200
so at the very moment yeah there is some

00:50:03,680 --> 00:50:08,319
the way it is built

00:50:05,200 --> 00:50:11,119
uh it assumes uh uh cuda

00:50:08,319 --> 00:50:12,400
but we are i think working on uh making

00:50:11,119 --> 00:50:15,680
a version which

00:50:12,400 --> 00:50:17,040
would not have uh cuda requirements

00:50:15,680 --> 00:50:19,920
and then if you wanted to use some other

00:50:17,040 --> 00:50:23,119
accelerators like opencl or whatnot

00:50:19,920 --> 00:50:26,559
you you can definitely do that

00:50:23,119 --> 00:50:28,559
you have to make a few code changes but

00:50:26,559 --> 00:50:29,599
please come work with us there is a

00:50:28,559 --> 00:50:33,839
forum as well for

00:50:29,599 --> 00:50:36,319
q a going from that same github location

00:50:33,839 --> 00:50:36,880
uh and we we would love to chat with you

00:50:36,319 --> 00:50:38,720
to see

00:50:36,880 --> 00:50:41,839
you know if that's something that we can

00:50:38,720 --> 00:50:41,839
collaborate on

00:50:43,920 --> 00:50:49,620
maybe one last question

00:50:46,450 --> 00:50:49,620
[Music]

00:50:50,720 --> 00:50:56,800
how do we select features which

00:50:54,480 --> 00:50:57,599
do not create an impact do we

00:50:56,800 --> 00:51:01,040
independently

00:50:57,599 --> 00:51:04,640
train the model for each feature

00:51:01,040 --> 00:51:05,839
so i'm not sure exactly i follow the

00:51:04,640 --> 00:51:09,200
question but

00:51:05,839 --> 00:51:10,960
um yeah so let me ask answer it in a

00:51:09,200 --> 00:51:12,720
more generic fashion so

00:51:10,960 --> 00:51:15,680
let's say if you take resnap 50 as an

00:51:12,720 --> 00:51:15,680
architecture right so that

00:51:15,920 --> 00:51:19,520
has a very uh robust architecture for

00:51:18,720 --> 00:51:22,960
you know

00:51:19,520 --> 00:51:26,079
uh finding features from a vision

00:51:22,960 --> 00:51:28,160
use case right so if you give it images

00:51:26,079 --> 00:51:31,520
it's going to find these kind of

00:51:28,160 --> 00:51:34,000
features in it and uh now you put some

00:51:31,520 --> 00:51:35,040
sort of head networks generally that's

00:51:34,000 --> 00:51:37,359
what people do

00:51:35,040 --> 00:51:39,040
on top of the resnet and then like you

00:51:37,359 --> 00:51:40,400
may be interested in specific

00:51:39,040 --> 00:51:42,079
learning specific things like you may

00:51:40,400 --> 00:51:45,119
want to do face detection

00:51:42,079 --> 00:51:48,400
and that's that's your task so

00:51:45,119 --> 00:51:49,520
uh yeah maybe i think what i meant was

00:51:48,400 --> 00:51:52,400
that for

00:51:49,520 --> 00:51:53,920
so you you are you know base model can

00:51:52,400 --> 00:51:57,200
do a lot more

00:51:53,920 --> 00:51:58,319
uh than what your what your immediate

00:51:57,200 --> 00:52:01,200
task is

00:51:58,319 --> 00:52:01,760
and so given uh something like this use

00:52:01,200 --> 00:52:04,480
case

00:52:01,760 --> 00:52:06,880
that base model that resident 50 model

00:52:04,480 --> 00:52:09,119
is over parameterized it's you know

00:52:06,880 --> 00:52:11,440
it can do a lot more than what you need

00:52:09,119 --> 00:52:12,800
and so this is a very good use case for

00:52:11,440 --> 00:52:14,240
applying these model compression

00:52:12,800 --> 00:52:15,839
techniques that we looked at

00:52:14,240 --> 00:52:18,000
and so that that's where you can get

00:52:15,839 --> 00:52:20,559
those gains reduce the complexity

00:52:18,000 --> 00:52:21,440
of the model in an automatic fashion

00:52:20,559 --> 00:52:24,960
without

00:52:21,440 --> 00:52:28,319
having a hit on accuracy

00:52:24,960 --> 00:52:29,280
so uh right about the time that i think

00:52:28,319 --> 00:52:32,400
i was

00:52:29,280 --> 00:52:33,040
alerted uh so thanks a lot for attending

00:52:32,400 --> 00:52:36,960
this

00:52:33,040 --> 00:52:38,160
lecture um had real fun i think please

00:52:36,960 --> 00:52:41,119
continue

00:52:38,160 --> 00:52:41,839
uh questions on the slack channel and

00:52:41,119 --> 00:52:44,480
i'll

00:52:41,839 --> 00:52:45,920
stick around and answer uh some of those

00:52:44,480 --> 00:52:47,680
questions

00:52:45,920 --> 00:52:49,440
and yeah thanks for giving me this

00:52:47,680 --> 00:53:01,839
opportunity and thanks to the linux

00:52:49,440 --> 00:53:01,839
foundation as well

00:53:13,520 --> 00:53:15,599

YouTube URL: https://www.youtube.com/watch?v=w7uBYZZkGms


