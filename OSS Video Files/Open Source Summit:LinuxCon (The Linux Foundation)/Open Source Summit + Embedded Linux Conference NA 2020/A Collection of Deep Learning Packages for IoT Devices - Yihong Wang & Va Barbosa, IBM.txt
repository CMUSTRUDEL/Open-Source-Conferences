Title: A Collection of Deep Learning Packages for IoT Devices - Yihong Wang & Va Barbosa, IBM
Publication date: 2020-09-10
Playlist: Open Source Summit + Embedded Linux Conference NA 2020
Description: 
	A Collection of Deep Learning Packages for IoT Devices - Yihong Wang & Va Barbosa, IBM
Captions: 
	00:00:08,639 --> 00:00:11,759
hello

00:00:09,679 --> 00:00:13,599
thank you for joining us today we

00:00:11,759 --> 00:00:15,360
appreciate everyone taking the time to

00:00:13,599 --> 00:00:17,199
listen to us today

00:00:15,360 --> 00:00:18,960
and hopefully everyone is healthy and

00:00:17,199 --> 00:00:21,840
staying safe

00:00:18,960 --> 00:00:24,560
i am var babosa developer advocate at

00:00:21,840 --> 00:00:26,000
ibm's center for open source data and ai

00:00:24,560 --> 00:00:28,240
technologies

00:00:26,000 --> 00:00:29,119
and presenting with me today is yee hong

00:00:28,240 --> 00:00:32,079
wang

00:00:29,119 --> 00:00:34,320
software engineer for the ibm cognitive

00:00:32,079 --> 00:00:35,840
open technologies group

00:00:34,320 --> 00:00:37,760
today we'll be discussing machine

00:00:35,840 --> 00:00:39,920
learning on edge devices

00:00:37,760 --> 00:00:42,640
and more specifically how can you

00:00:39,920 --> 00:00:44,399
integrate node-red and tensorflow.js

00:00:42,640 --> 00:00:48,559
to make it easier to incorporate some

00:00:44,399 --> 00:00:48,559
machine learning into your iot device

00:00:48,719 --> 00:00:52,320
now it's no big secret that edge

00:00:50,640 --> 00:00:54,000
computing is on the rise

00:00:52,320 --> 00:00:56,879
and the internet of things is a hot

00:00:54,000 --> 00:00:57,600
topic the growth of connected devices is

00:00:56,879 --> 00:01:00,079
staggering

00:00:57,600 --> 00:01:01,600
you have home automation systems smart

00:01:00,079 --> 00:01:04,720
cars and appliances

00:01:01,600 --> 00:01:07,680
mobile phones and even personal drones

00:01:04,720 --> 00:01:09,840
data from iot analytics show that there

00:01:07,680 --> 00:01:10,960
are about 7 billion iot devices

00:01:09,840 --> 00:01:14,080
worldwide

00:01:10,960 --> 00:01:17,280
and as predicted by the end of 2020

00:01:14,080 --> 00:01:21,520
there will be more than iot devices

00:01:17,280 --> 00:01:24,960
than laptops desktops and phones

00:01:21,520 --> 00:01:27,280
and by 2025 a gartner projects the

00:01:24,960 --> 00:01:30,400
number of iot connected devices

00:01:27,280 --> 00:01:32,560
will surpass 21 billion

00:01:30,400 --> 00:01:34,640
considering the sheer number and variety

00:01:32,560 --> 00:01:38,840
of these devices and sensors

00:01:34,640 --> 00:01:40,079
getting started with iot can pose many

00:01:38,840 --> 00:01:42,159
challenges

00:01:40,079 --> 00:01:44,079
first each device has its own set of

00:01:42,159 --> 00:01:48,159
requirements and restrictions

00:01:44,079 --> 00:01:50,640
around its interface protocol and so on

00:01:48,159 --> 00:01:52,560
also trying to set up these devices to

00:01:50,640 --> 00:01:54,720
communicate with each other

00:01:52,560 --> 00:01:56,640
or even just trying to get messages off

00:01:54,720 --> 00:02:00,079
of one of these devices

00:01:56,640 --> 00:02:03,600
can prove to be time consuming and often

00:02:00,079 --> 00:02:05,040
times are non-trivial so solutions

00:02:03,600 --> 00:02:08,560
require pulling together

00:02:05,040 --> 00:02:10,879
different devices apis services

00:02:08,560 --> 00:02:12,560
and sometimes protocols and then trying

00:02:10,879 --> 00:02:16,000
to get them to interact

00:02:12,560 --> 00:02:18,400
and work together tools are needed

00:02:16,000 --> 00:02:20,239
that make all this easier and allow you

00:02:18,400 --> 00:02:22,400
to bring all these various pieces of

00:02:20,239 --> 00:02:25,840
hardware and software together

00:02:22,400 --> 00:02:25,840
in a manner that is approachable

00:02:26,000 --> 00:02:30,800
enter node-red node-red is a flow-based

00:02:29,280 --> 00:02:33,120
programming tool

00:02:30,800 --> 00:02:34,400
for wiring together hardware devices

00:02:33,120 --> 00:02:36,239
apis

00:02:34,400 --> 00:02:38,480
and online services in new and

00:02:36,239 --> 00:02:41,280
interesting ways

00:02:38,480 --> 00:02:42,879
it is a visual programming tool with a

00:02:41,280 --> 00:02:44,720
browser-based editor

00:02:42,879 --> 00:02:46,080
that makes it easy to wire together an

00:02:44,720 --> 00:02:47,920
iot flow

00:02:46,080 --> 00:02:50,800
and deploy it to your device with just a

00:02:47,920 --> 00:02:53,440
single click

00:02:50,800 --> 00:02:55,680
node drive runtime is lightweight and

00:02:53,440 --> 00:02:57,280
built on top of node.js

00:02:55,680 --> 00:03:00,640
taking full advantage of the

00:02:57,280 --> 00:03:03,280
event-driven non-blocking model

00:03:00,640 --> 00:03:04,640
node-red makes it easier for more people

00:03:03,280 --> 00:03:06,720
to get started quickly

00:03:04,640 --> 00:03:08,000
without having to immediately dig into

00:03:06,720 --> 00:03:10,239
code

00:03:08,000 --> 00:03:11,120
so rather than having to write tons of

00:03:10,239 --> 00:03:13,840
code

00:03:11,120 --> 00:03:15,280
you instead just drag and drop nodes

00:03:13,840 --> 00:03:17,519
into a workspace

00:03:15,280 --> 00:03:19,519
and connect them to each other to build

00:03:17,519 --> 00:03:22,319
your solution

00:03:19,519 --> 00:03:24,159
because of the slow code approach it has

00:03:22,319 --> 00:03:26,879
become an ideal tool

00:03:24,159 --> 00:03:28,000
for low cost hardware such as raspberry

00:03:26,879 --> 00:03:30,159
pi

00:03:28,000 --> 00:03:33,840
but you can also run it from the cloud

00:03:30,159 --> 00:03:36,480
or locally on your laptop or desktop

00:03:33,840 --> 00:03:38,080
through its drag-and-drop user interface

00:03:36,480 --> 00:03:40,640
you can develop and deploy

00:03:38,080 --> 00:03:41,920
powerful applications with minimal

00:03:40,640 --> 00:03:44,879
coding

00:03:41,920 --> 00:03:44,879
so let's have a look

00:03:45,040 --> 00:03:49,519
this is the node-red editor and as you

00:03:47,200 --> 00:03:50,799
can see we access it with a browser

00:03:49,519 --> 00:03:53,280
and you can access it through the

00:03:50,799 --> 00:03:55,680
browser after you've installed node-red

00:03:53,280 --> 00:03:57,040
on the left-hand side you'll notice is

00:03:55,680 --> 00:03:58,480
the palette area

00:03:57,040 --> 00:04:00,239
which consists of a large set of

00:03:58,480 --> 00:04:01,599
pre-installed nodes

00:04:00,239 --> 00:04:04,560
you have nodes for all sorts of

00:04:01,599 --> 00:04:06,959
functionality services devices

00:04:04,560 --> 00:04:08,720
now along with the set of pre-installed

00:04:06,959 --> 00:04:11,040
nodes that comes with node-red

00:04:08,720 --> 00:04:12,720
you can easily add more nodes and you

00:04:11,040 --> 00:04:15,840
can find nodes out in

00:04:12,720 --> 00:04:17,680
the node-red library so for example you

00:04:15,840 --> 00:04:19,040
can just search for a particular area or

00:04:17,680 --> 00:04:20,799
particular service and you can find

00:04:19,040 --> 00:04:22,479
nodes related to that

00:04:20,799 --> 00:04:23,919
and so you can find nodes in the node

00:04:22,479 --> 00:04:27,680
red library you can also

00:04:23,919 --> 00:04:29,759
find nodes on github as well as npm

00:04:27,680 --> 00:04:31,120
but along with these nodes that you can

00:04:29,759 --> 00:04:33,840
find out there in the community

00:04:31,120 --> 00:04:35,199
you can also create your own custom node

00:04:33,840 --> 00:04:39,680
and install it for you to use

00:04:35,199 --> 00:04:42,960
in your flow and on the right side

00:04:39,680 --> 00:04:44,800
you'll see we have the tools sidebar

00:04:42,960 --> 00:04:46,160
and the tool sidebar just provides a

00:04:44,800 --> 00:04:49,040
number of resources

00:04:46,160 --> 00:04:49,919
to assist you in working with your flow

00:04:49,040 --> 00:04:52,639
you have the info

00:04:49,919 --> 00:04:52,960
section which you can find information

00:04:52,639 --> 00:04:54,960
and

00:04:52,960 --> 00:04:56,880
like help and documentation for a

00:04:54,960 --> 00:04:59,840
particular node

00:04:56,880 --> 00:05:01,759
you also have the debug and that's where

00:04:59,840 --> 00:05:02,639
you'd have your debug messaging and your

00:05:01,759 --> 00:05:04,160
logging

00:05:02,639 --> 00:05:07,199
when you're running and testing your

00:05:04,160 --> 00:05:09,919
flows and there are other stuff in the

00:05:07,199 --> 00:05:13,280
right sidebar along with a dashboard and

00:05:09,919 --> 00:05:16,639
configuration information as well

00:05:13,280 --> 00:05:18,639
and in the middle area that's where

00:05:16,639 --> 00:05:19,919
you would be your workspace and that's

00:05:18,639 --> 00:05:23,199
where you would go about

00:05:19,919 --> 00:05:24,160
wiring together your flows now to create

00:05:23,199 --> 00:05:27,039
a flow

00:05:24,160 --> 00:05:28,240
it's as straightforward as just finding

00:05:27,039 --> 00:05:31,440
a node

00:05:28,240 --> 00:05:32,880
dragging it into the flow area into the

00:05:31,440 --> 00:05:36,080
workspace area excuse me

00:05:32,880 --> 00:05:37,600
and then you can go ahead and add

00:05:36,080 --> 00:05:38,000
multiple nodes and then you would just

00:05:37,600 --> 00:05:41,840
go ahead

00:05:38,000 --> 00:05:43,440
and connect the nodes and there we go we

00:05:41,840 --> 00:05:45,919
have a very simple

00:05:43,440 --> 00:05:47,199
node red float and now if we go to the

00:05:45,919 --> 00:05:48,880
information

00:05:47,199 --> 00:05:50,800
you can see if i click on one of these

00:05:48,880 --> 00:05:52,800
nodes it gives me the help information

00:05:50,800 --> 00:05:54,320
about that particular node

00:05:52,800 --> 00:05:56,400
so now that i have this node i can go

00:05:54,320 --> 00:05:58,400
ahead and deploy it

00:05:56,400 --> 00:06:00,319
and since i have it installed locally

00:05:58,400 --> 00:06:02,160
it's just being deployed locally but for

00:06:00,319 --> 00:06:04,000
example if i had it installed

00:06:02,160 --> 00:06:05,199
on a device it would be deploying it to

00:06:04,000 --> 00:06:08,160
that device

00:06:05,199 --> 00:06:09,039
and if i just trigger this node we can

00:06:08,160 --> 00:06:11,919
see this was

00:06:09,039 --> 00:06:12,639
this this injectors it sent the

00:06:11,919 --> 00:06:14,319
timestamp

00:06:12,639 --> 00:06:16,160
to the debug node and the debug node

00:06:14,319 --> 00:06:18,720
just logged that information

00:06:16,160 --> 00:06:19,440
so that's the typically uh how you'd go

00:06:18,720 --> 00:06:21,039
about

00:06:19,440 --> 00:06:22,080
wiring your flow and testing it but

00:06:21,039 --> 00:06:24,160
let's go ahead and make something a

00:06:22,080 --> 00:06:28,800
little bit more interesting

00:06:24,160 --> 00:06:33,120
so let me go ahead and find the http

00:06:28,800 --> 00:06:35,600
request node let me put that there

00:06:33,120 --> 00:06:37,440
and then i'm going to wire up this to

00:06:35,600 --> 00:06:40,560
http request and then the

00:06:37,440 --> 00:06:43,120
http request it to the

00:06:40,560 --> 00:06:43,759
debug and when i double click on one of

00:06:43,120 --> 00:06:45,600
these nodes

00:06:43,759 --> 00:06:47,039
it brings up the edit panel and this

00:06:45,600 --> 00:06:48,479
edit panel is where you can configure

00:06:47,039 --> 00:06:49,759
the particular node if the node accepts

00:06:48,479 --> 00:06:51,280
any configuration

00:06:49,759 --> 00:06:52,880
so i'm going to change this from

00:06:51,280 --> 00:06:55,440
timestamp to

00:06:52,880 --> 00:06:57,520
numbers so i'm going to come up with a

00:06:55,440 --> 00:07:00,560
number so let's say 19.

00:06:57,520 --> 00:07:02,720
so what's going to happen when i

00:07:00,560 --> 00:07:03,919
click on this it's going to inject the

00:07:02,720 --> 00:07:06,319
number 19.

00:07:03,919 --> 00:07:07,919
but let's go to the http request node

00:07:06,319 --> 00:07:09,599
and what i'm going to do is i'm going to

00:07:07,919 --> 00:07:11,280
put it to an endpoint that i want the

00:07:09,599 --> 00:07:12,720
request note to hit

00:07:11,280 --> 00:07:14,720
so in this case i'm just going to use

00:07:12,720 --> 00:07:16,720
the numbers api endpoint

00:07:14,720 --> 00:07:17,919
which is a rest endpoint that you can

00:07:16,720 --> 00:07:19,440
send it a number

00:07:17,919 --> 00:07:21,919
and then it'll give you a random fact

00:07:19,440 --> 00:07:24,560
about that number so i got that

00:07:21,919 --> 00:07:24,960
so i have my flow all set so i can go

00:07:24,560 --> 00:07:28,400
ahead

00:07:24,960 --> 00:07:29,919
and deploy it

00:07:28,400 --> 00:07:31,280
and now that it's successfully deployed

00:07:29,919 --> 00:07:33,759
i'll go ahead and run it and we can see

00:07:31,280 --> 00:07:33,759
what it does

00:07:34,080 --> 00:07:37,840
and you see it's set to number 19 and we

00:07:36,400 --> 00:07:40,479
get 19 is the

00:07:37,840 --> 00:07:42,000
number of years and 235 illuminations

00:07:40,479 --> 00:07:44,400
and let's try it one more time see if it

00:07:42,000 --> 00:07:45,680
gives us something different oh no i

00:07:44,400 --> 00:07:46,080
guess there's not much for oh there we

00:07:45,680 --> 00:07:48,639
go

00:07:46,080 --> 00:07:49,680
19 is the final year of a person is a

00:07:48,639 --> 00:07:53,199
teenager

00:07:49,680 --> 00:07:54,960
so this is basically what it is for

00:07:53,199 --> 00:07:56,400
for the idea of round the flow and

00:07:54,960 --> 00:07:57,759
creating a flow node red

00:07:56,400 --> 00:08:00,240
and what you can also do with these

00:07:57,759 --> 00:08:02,639
flows is you can actually export them

00:08:00,240 --> 00:08:04,560
as a json file and it's as you can see

00:08:02,639 --> 00:08:07,680
here the flow is just

00:08:04,560 --> 00:08:11,280
a json file and so you can easily share

00:08:07,680 --> 00:08:11,280
it flows with others as well

00:08:11,599 --> 00:08:15,759
so that's all good and great but what if

00:08:14,319 --> 00:08:17,840
you want to incorporate

00:08:15,759 --> 00:08:19,520
machine learning into your flow so that

00:08:17,840 --> 00:08:20,560
you can just as easily as i did here

00:08:19,520 --> 00:08:22,400
drag and drop nodes

00:08:20,560 --> 00:08:24,080
you can drag and drop a machine learning

00:08:22,400 --> 00:08:27,199
node to perform some

00:08:24,080 --> 00:08:29,280
ai task for you and that is where

00:08:27,199 --> 00:08:31,440
tensorflow.js comes in

00:08:29,280 --> 00:08:32,959
tensorflow.js is an open source

00:08:31,440 --> 00:08:35,279
javascript library

00:08:32,959 --> 00:08:36,000
to build train and run machine learning

00:08:35,279 --> 00:08:38,240
models

00:08:36,000 --> 00:08:40,399
in javascript environments such as the

00:08:38,240 --> 00:08:42,640
browser and node.js

00:08:40,399 --> 00:08:45,440
it's tensorflow rewritten for the

00:08:42,640 --> 00:08:48,640
javascript ecosystem

00:08:45,440 --> 00:08:50,560
and it includes a low-level api

00:08:48,640 --> 00:08:52,959
that allows for linear algebra and

00:08:50,560 --> 00:08:54,399
complex matrix math to be done all in

00:08:52,959 --> 00:08:57,279
javascript

00:08:54,399 --> 00:08:59,440
but it also includes a high level api

00:08:57,279 --> 00:09:00,160
that closely follows the keras api for

00:08:59,440 --> 00:09:03,200
constructing

00:09:00,160 --> 00:09:03,200
machine learning models

00:09:03,279 --> 00:09:06,880
and let's go ahead and take a look at a

00:09:05,920 --> 00:09:10,200
tensorflow.js

00:09:06,880 --> 00:09:11,360
example the best place to start with

00:09:10,200 --> 00:09:14,000
tensorflow.js

00:09:11,360 --> 00:09:15,920
is actually their website and in their

00:09:14,000 --> 00:09:19,200
website you'll find demos

00:09:15,920 --> 00:09:20,880
as well as tutorials and also their api

00:09:19,200 --> 00:09:22,959
documentation

00:09:20,880 --> 00:09:24,080
and they do have very good api

00:09:22,959 --> 00:09:25,760
documentation

00:09:24,080 --> 00:09:28,000
so let's go ahead and take a look at

00:09:25,760 --> 00:09:28,000
that

00:09:28,640 --> 00:09:32,160
now quickly looking through this you can

00:09:30,880 --> 00:09:33,440
see there are a lot of functions

00:09:32,160 --> 00:09:35,440
available to you

00:09:33,440 --> 00:09:38,000
so you have some tensorflow creation and

00:09:35,440 --> 00:09:39,839
transformation functions

00:09:38,000 --> 00:09:43,120
you also have model functions for

00:09:39,839 --> 00:09:45,519
working with models

00:09:43,120 --> 00:09:46,560
and you have the layers functions for

00:09:45,519 --> 00:09:49,680
defining

00:09:46,560 --> 00:09:52,560
the layers of your model

00:09:49,680 --> 00:09:53,360
and there are also operations for doing

00:09:52,560 --> 00:09:56,800
the linear

00:09:53,360 --> 00:10:00,880
algebra and matrix math operation work

00:09:56,800 --> 00:10:00,880
so and there's also much much more

00:10:01,279 --> 00:10:04,880
so now since we're talking about

00:10:03,040 --> 00:10:05,839
javascript and javascript runs on the

00:10:04,880 --> 00:10:08,160
browser

00:10:05,839 --> 00:10:08,880
you can easily run and try a lot of

00:10:08,160 --> 00:10:11,839
these

00:10:08,880 --> 00:10:13,519
functionality right here in the docs so

00:10:11,839 --> 00:10:16,560
for example i can just go ahead and

00:10:13,519 --> 00:10:18,800
run this and this right here just

00:10:16,560 --> 00:10:20,079
define the tensor and then printed it

00:10:18,800 --> 00:10:22,000
out

00:10:20,079 --> 00:10:23,200
now once you import tensorflow.js you

00:10:22,000 --> 00:10:25,040
actually have this tf

00:10:23,200 --> 00:10:28,800
variable which you can use for all your

00:10:25,040 --> 00:10:33,440
calls so let me go ahead and edit this

00:10:28,800 --> 00:10:35,519
and try something a little different

00:10:33,440 --> 00:10:37,360
so all i'm doing here is defining a

00:10:35,519 --> 00:10:40,399
two-dimensional tensor

00:10:37,360 --> 00:10:41,760
with these values in it and then i'm

00:10:40,399 --> 00:10:44,399
going to take that tensor

00:10:41,760 --> 00:10:45,760
get the log of it then square that and

00:10:44,399 --> 00:10:48,720
then print out the value

00:10:45,760 --> 00:10:51,200
so i'll go ahead and run this and then

00:10:48,720 --> 00:10:53,920
we get the results of that

00:10:51,200 --> 00:10:55,360
so in addition to all these api

00:10:53,920 --> 00:10:57,040
functions that you see here

00:10:55,360 --> 00:10:58,560
there are additional functions that are

00:10:57,040 --> 00:10:59,360
specific to the environment that you're

00:10:58,560 --> 00:11:02,480
running in

00:10:59,360 --> 00:11:05,680
so for example we have the node.js

00:11:02,480 --> 00:11:06,320
api which has some additional functions

00:11:05,680 --> 00:11:09,200
for

00:11:06,320 --> 00:11:10,880
node.js and then you have the react

00:11:09,200 --> 00:11:14,399
native api for when working

00:11:10,880 --> 00:11:17,440
in react native and you have a tfjs

00:11:14,399 --> 00:11:19,680
vis which is for visualizing

00:11:17,440 --> 00:11:20,880
what the model is doing so creating bar

00:11:19,680 --> 00:11:23,920
charts and

00:11:20,880 --> 00:11:26,880
uh heat maps and things of that nature

00:11:23,920 --> 00:11:30,079
so now let's go ahead and take a look at

00:11:26,880 --> 00:11:30,079
a more in-depth example

00:11:30,480 --> 00:11:35,920
and here we have an example code showing

00:11:33,120 --> 00:11:37,519
running inferencing with tensorflow.js

00:11:35,920 --> 00:11:39,600
so as you can see the first thing we do

00:11:37,519 --> 00:11:41,600
is just go ahead and load the model

00:11:39,600 --> 00:11:44,640
and in this case we're loading the model

00:11:41,600 --> 00:11:46,320
from a url on tensorflow hub

00:11:44,640 --> 00:11:48,240
and with the model loaded you would

00:11:46,320 --> 00:11:50,480
pre-process the input

00:11:48,240 --> 00:11:52,160
and in this case the input is going to

00:11:50,480 --> 00:11:52,800
be an image so we're going to take that

00:11:52,160 --> 00:11:56,079
image

00:11:52,800 --> 00:11:58,160
and convert it to a tensor

00:11:56,079 --> 00:12:00,399
and once we have the input tensor we can

00:11:58,160 --> 00:12:02,800
go ahead and run the model

00:12:00,399 --> 00:12:05,040
and once we have the output from the

00:12:02,800 --> 00:12:05,440
model we would go ahead and pre-process

00:12:05,040 --> 00:12:07,920
it

00:12:05,440 --> 00:12:09,279
so in turning into something that's a

00:12:07,920 --> 00:12:10,160
little bit more human readable or

00:12:09,279 --> 00:12:13,519
consumable

00:12:10,160 --> 00:12:15,519
and later on further on down the flow

00:12:13,519 --> 00:12:17,360
so the whole entire flow would basically

00:12:15,519 --> 00:12:20,480
be load the model

00:12:17,360 --> 00:12:22,560
pre-process the input run the model

00:12:20,480 --> 00:12:24,720
and then take the prediction and process

00:12:22,560 --> 00:12:26,720
the output so that's the basic flow for

00:12:24,720 --> 00:12:28,240
running inferencing with tensorflow

00:12:26,720 --> 00:12:30,560
now what if you wanted to create your

00:12:28,240 --> 00:12:32,639
model so this example here

00:12:30,560 --> 00:12:34,480
shows how you could go about building a

00:12:32,639 --> 00:12:36,160
model with tensorflow.js

00:12:34,480 --> 00:12:37,680
so in this case we're building a

00:12:36,160 --> 00:12:39,600
sequential model

00:12:37,680 --> 00:12:41,519
and we're taking the sequential model

00:12:39,600 --> 00:12:42,079
and we're adding a number of layers to

00:12:41,519 --> 00:12:44,320
it

00:12:42,079 --> 00:12:45,200
so the we add a couple convolutional

00:12:44,320 --> 00:12:47,920
layers

00:12:45,200 --> 00:12:50,399
a couple max pooling layers where we

00:12:47,920 --> 00:12:53,519
specify the activation and other

00:12:50,399 --> 00:12:55,360
properties that the layer it takes and

00:12:53,519 --> 00:12:55,839
then after that we go ahead and flatten

00:12:55,360 --> 00:12:58,480
it

00:12:55,839 --> 00:12:59,040
and then finally we provide a dense

00:12:58,480 --> 00:13:01,600
layer

00:12:59,040 --> 00:13:03,120
with the soft max activation and once we

00:13:01,600 --> 00:13:04,160
have all the layers in place we can go

00:13:03,120 --> 00:13:06,320
ahead and

00:13:04,160 --> 00:13:09,120
compile the model with the appropriate

00:13:06,320 --> 00:13:11,920
optimizer and loss function

00:13:09,120 --> 00:13:12,240
so since both node-red and tensorflow.js

00:13:11,920 --> 00:13:14,320
run

00:13:12,240 --> 00:13:16,399
in node.js combining the two is

00:13:14,320 --> 00:13:18,480
inevitable

00:13:16,399 --> 00:13:20,320
so the goal is to get to a point where

00:13:18,480 --> 00:13:22,959
you can just launch node-red

00:13:20,320 --> 00:13:24,880
import a tensorflow.js model node and

00:13:22,959 --> 00:13:26,959
then drag the node into your flow and

00:13:24,880 --> 00:13:29,120
wire it to your device

00:13:26,959 --> 00:13:31,600
much like you saw me do earlier in the

00:13:29,120 --> 00:13:33,440
in the with the default node red nodes

00:13:31,600 --> 00:13:35,680
you should be able to do the same thing

00:13:33,440 --> 00:13:40,079
with custom tensorflow.js models

00:13:35,680 --> 00:13:43,680
in node-red but why combine node-red

00:13:40,079 --> 00:13:45,440
and tensorflow.js as you saw

00:13:43,680 --> 00:13:48,320
node-red makes it simple to wire

00:13:45,440 --> 00:13:50,560
together devices as well as apis

00:13:48,320 --> 00:13:51,680
and tensorflow.js makes it possible to

00:13:50,560 --> 00:13:54,880
build and deploy

00:13:51,680 --> 00:13:56,079
machine learning models in javascript so

00:13:54,880 --> 00:13:58,320
the two together

00:13:56,079 --> 00:13:59,279
make it easier for developers and iot

00:13:58,320 --> 00:14:01,279
enthusiasts

00:13:59,279 --> 00:14:03,199
to incorporate machine learning into

00:14:01,279 --> 00:14:05,360
their device

00:14:03,199 --> 00:14:06,880
if you bring tensorflow.js models into

00:14:05,360 --> 00:14:08,959
the node-red platform

00:14:06,880 --> 00:14:09,920
there is a lower barrier to entry into

00:14:08,959 --> 00:14:12,000
machine learning

00:14:09,920 --> 00:14:14,800
that the visual programming environment

00:14:12,000 --> 00:14:16,800
of node-red helps facilitate

00:14:14,800 --> 00:14:17,920
you also get an increase in privacy and

00:14:16,800 --> 00:14:19,760
data security

00:14:17,920 --> 00:14:22,000
that comes with being able to perform

00:14:19,760 --> 00:14:24,480
predictions directly on the device

00:14:22,000 --> 00:14:25,920
collecting the data and not have to try

00:14:24,480 --> 00:14:27,680
to send the data

00:14:25,920 --> 00:14:30,240
across the network or have the data

00:14:27,680 --> 00:14:33,120
leave the device and

00:14:30,240 --> 00:14:34,160
keeping keeping it all on the device

00:14:33,120 --> 00:14:36,240
makes it possible

00:14:34,160 --> 00:14:37,199
to perform inferencing in remote

00:14:36,240 --> 00:14:39,600
locations

00:14:37,199 --> 00:14:42,639
or in areas with unreliable or no

00:14:39,600 --> 00:14:45,199
network connectivity

00:14:42,639 --> 00:14:47,120
but to get to that point first we need

00:14:45,199 --> 00:14:49,040
to have these custom nodes

00:14:47,120 --> 00:14:50,560
luckily there are already a number of

00:14:49,040 --> 00:14:52,079
tensorflow.js nodes

00:14:50,560 --> 00:14:54,320
that you can find in the node-red

00:14:52,079 --> 00:14:56,639
community library as well as in

00:14:54,320 --> 00:14:58,240
github these custom nodes help you

00:14:56,639 --> 00:15:00,560
quickly get started with adding

00:14:58,240 --> 00:15:01,519
machine learning tasks into your iot

00:15:00,560 --> 00:15:04,160
flow

00:15:01,519 --> 00:15:06,880
you can find some general nodes for

00:15:04,160 --> 00:15:10,240
loading and running tensorflow.js nodes

00:15:06,880 --> 00:15:12,399
and models as well as nodes for specific

00:15:10,240 --> 00:15:12,639
use case models like the birth tokenizer

00:15:12,399 --> 00:15:16,000
or

00:15:12,639 --> 00:15:17,360
object detection but what about

00:15:16,000 --> 00:15:20,560
when you can't find an existing

00:15:17,360 --> 00:15:22,800
tensorflow.js node for your use case

00:15:20,560 --> 00:15:24,240
well for these scenarios nerd red is

00:15:22,800 --> 00:15:27,600
highly extensible

00:15:24,240 --> 00:15:28,959
and you can create your own custom node

00:15:27,600 --> 00:15:30,959
the first thing to understand about

00:15:28,959 --> 00:15:32,480
creating node-red modules

00:15:30,959 --> 00:15:34,000
is what are the pieces that make up a

00:15:32,480 --> 00:15:36,079
node-red node

00:15:34,000 --> 00:15:38,560
a node-red node consists of three main

00:15:36,079 --> 00:15:41,199
files you have your javascript file

00:15:38,560 --> 00:15:42,800
that defines the no what the node does

00:15:41,199 --> 00:15:45,120
you have the html file

00:15:42,800 --> 00:15:46,079
that defines the notes properties the

00:15:45,120 --> 00:15:48,160
edit dialog

00:15:46,079 --> 00:15:49,120
as well as the help test text for the

00:15:48,160 --> 00:15:51,519
node

00:15:49,120 --> 00:15:53,759
and then you have the package.json file

00:15:51,519 --> 00:15:56,800
which is used to package it all together

00:15:53,759 --> 00:15:57,680
as an npm module and let's go ahead and

00:15:56,800 --> 00:16:00,720
quickly look at an

00:15:57,680 --> 00:16:03,199
example custom node red node

00:16:00,720 --> 00:16:05,920
so we'll first look at the package.json

00:16:03,199 --> 00:16:09,199
which is similar to the package.json of

00:16:05,920 --> 00:16:10,399
any npm module with the slight

00:16:09,199 --> 00:16:12,560
difference of having the

00:16:10,399 --> 00:16:14,320
node red section and this section right

00:16:12,560 --> 00:16:15,680
here is just defining

00:16:14,320 --> 00:16:18,959
the node red nodes that are going to be

00:16:15,680 --> 00:16:22,000
available in this package

00:16:18,959 --> 00:16:25,120
next if we look at the html file

00:16:22,000 --> 00:16:28,079
this is made up of three script tags and

00:16:25,120 --> 00:16:29,519
the first one defines the edit dialog so

00:16:28,079 --> 00:16:31,440
this is what's going to show up when the

00:16:29,519 --> 00:16:33,519
user double clicks on the node

00:16:31,440 --> 00:16:35,279
and they get presented with edit dialog

00:16:33,519 --> 00:16:37,040
where they can go ahead and edit

00:16:35,279 --> 00:16:39,360
any of the configurations that the node

00:16:37,040 --> 00:16:42,399
may accept

00:16:39,360 --> 00:16:43,199
and then we have the javascript tag

00:16:42,399 --> 00:16:44,639
section

00:16:43,199 --> 00:16:47,040
and what this does is it basically

00:16:44,639 --> 00:16:49,360
registers the node with node red

00:16:47,040 --> 00:16:50,399
and it's also where you can set your

00:16:49,360 --> 00:16:54,639
default

00:16:50,399 --> 00:16:56,639
parameters for any of the nodes settings

00:16:54,639 --> 00:16:57,839
and lastly we have the script tag for

00:16:56,639 --> 00:16:59,839
the help section

00:16:57,839 --> 00:17:02,000
or the help info so this is when the

00:16:59,839 --> 00:17:04,559
user clicks on a node and they go to the

00:17:02,000 --> 00:17:07,839
info sidebar this is the information

00:17:04,559 --> 00:17:07,839
that will be presented to them

00:17:08,319 --> 00:17:11,760
and lastly we have the javascript which

00:17:10,160 --> 00:17:12,640
is actually going to define the behavior

00:17:11,760 --> 00:17:14,640
of the node

00:17:12,640 --> 00:17:16,720
so the javascript file is just going to

00:17:14,640 --> 00:17:19,360
export a single function

00:17:16,720 --> 00:17:21,120
and this function is going to have to go

00:17:19,360 --> 00:17:23,760
ahead and register for it

00:17:21,120 --> 00:17:25,760
on input event and what that is it's

00:17:23,760 --> 00:17:28,160
going to get alerted whenever a message

00:17:25,760 --> 00:17:29,760
comes into the node's input and once

00:17:28,160 --> 00:17:31,440
that message comes in it can go ahead

00:17:29,760 --> 00:17:35,280
and take appropriate action

00:17:31,440 --> 00:17:37,360
so if we see here in this example

00:17:35,280 --> 00:17:40,160
when the message comes in we're going to

00:17:37,360 --> 00:17:41,520
go ahead and pre-process the input

00:17:40,160 --> 00:17:43,600
then we're going to take that

00:17:41,520 --> 00:17:46,160
pre-processed input tensor

00:17:43,600 --> 00:17:47,520
and go ahead and run the prediction on

00:17:46,160 --> 00:17:49,200
it against the model

00:17:47,520 --> 00:17:50,960
then once we have the prediction we're

00:17:49,200 --> 00:17:52,400
going to process the output

00:17:50,960 --> 00:17:54,880
and this is the similar flow that you

00:17:52,400 --> 00:17:57,360
saw in the basic tensorflow.js example

00:17:54,880 --> 00:17:59,120
so an input comes in we preprocess it we

00:17:57,360 --> 00:18:00,160
run inferencing and then we go ahead and

00:17:59,120 --> 00:18:02,480
process the output

00:18:00,160 --> 00:18:04,080
and we to get the output in a nice json

00:18:02,480 --> 00:18:06,320
format and then we can go ahead and

00:18:04,080 --> 00:18:07,520
send it out the node to the next node in

00:18:06,320 --> 00:18:09,520
the flow

00:18:07,520 --> 00:18:11,440
and then we have the same stuff we had

00:18:09,520 --> 00:18:12,240
before which is for example loading the

00:18:11,440 --> 00:18:16,400
model

00:18:12,240 --> 00:18:18,960
in here so this is the basic

00:18:16,400 --> 00:18:19,760
building blocks of a particular node-red

00:18:18,960 --> 00:18:22,720
node

00:18:19,760 --> 00:18:25,280
so with this we can now go ahead and see

00:18:22,720 --> 00:18:27,679
this node in action

00:18:25,280 --> 00:18:30,000
so here we have a node-red flow using

00:18:27,679 --> 00:18:32,640
that custom tensorflow.js node

00:18:30,000 --> 00:18:33,679
we just went over and the way this flow

00:18:32,640 --> 00:18:36,720
is going to work is

00:18:33,679 --> 00:18:39,120
once i trigger this inject node

00:18:36,720 --> 00:18:41,200
this image will be sent over to the

00:18:39,120 --> 00:18:44,400
custom node

00:18:41,200 --> 00:18:47,200
the node will pre-process the image

00:18:44,400 --> 00:18:48,880
and turn it into a tensor run inference

00:18:47,200 --> 00:18:51,440
on that tensor

00:18:48,880 --> 00:18:54,400
process the prediction and then send it

00:18:51,440 --> 00:18:57,600
out to the debug node

00:18:54,400 --> 00:18:59,760
i also have here an image preview node

00:18:57,600 --> 00:19:02,240
and it is just so that we can see what

00:18:59,760 --> 00:19:06,240
image is being sent to the custom node

00:19:02,240 --> 00:19:06,240
let's go ahead and deploy this flow

00:19:07,360 --> 00:19:12,320
it is not successfully deployed and we

00:19:09,200 --> 00:19:12,320
can go ahead and run it

00:19:14,400 --> 00:19:19,039
when we run it we get a preview of the

00:19:16,320 --> 00:19:22,400
image that was used

00:19:19,039 --> 00:19:22,400
and looking at the debug

00:19:23,120 --> 00:19:26,880
we can examine the prediction that was

00:19:24,640 --> 00:19:28,400
returned

00:19:26,880 --> 00:19:30,720
you'll notice it is an array with

00:19:28,400 --> 00:19:33,520
objects corresponding to the

00:19:30,720 --> 00:19:36,799
what was detected in the image and in

00:19:33,520 --> 00:19:39,919
this case we have three objects

00:19:36,799 --> 00:19:42,080
each one being a person and we get along

00:19:39,919 --> 00:19:44,799
with that we get the accuracy score

00:19:42,080 --> 00:19:45,520
as well as the bounding box which

00:19:44,799 --> 00:19:47,919
outlines

00:19:45,520 --> 00:19:49,840
where in the image the specific object

00:19:47,919 --> 00:19:51,760
was detected

00:19:49,840 --> 00:19:53,440
and just like that we have a custom

00:19:51,760 --> 00:19:55,120
tensorflow.js node

00:19:53,440 --> 00:19:58,799
that allows us to add machine learning

00:19:55,120 --> 00:20:01,200
capabilities to our iot devices

00:19:58,799 --> 00:20:02,799
that is great we can now create node-red

00:20:01,200 --> 00:20:05,440
nodes with tensorflow.js

00:20:02,799 --> 00:20:08,640
that anyone can just add into their flow

00:20:05,440 --> 00:20:11,039
and effortlessly deploy to their device

00:20:08,640 --> 00:20:12,720
as straightforward as this may appear

00:20:11,039 --> 00:20:13,760
there can still be challenges and things

00:20:12,720 --> 00:20:16,000
to keep in mind

00:20:13,760 --> 00:20:17,440
if you are to bring tensorflow.js models

00:20:16,000 --> 00:20:19,200
to node-red

00:20:17,440 --> 00:20:21,760
for starters we need to think about the

00:20:19,200 --> 00:20:23,840
model such as storing a model

00:20:21,760 --> 00:20:25,200
should it be packaged with node.js

00:20:23,840 --> 00:20:28,880
module or do you

00:20:25,200 --> 00:20:30,799
prefer to serve it from an external url

00:20:28,880 --> 00:20:32,840
or cdn

00:20:30,799 --> 00:20:34,159
how well would the model perform on edge

00:20:32,840 --> 00:20:36,240
devices

00:20:34,159 --> 00:20:37,600
not all models are optimized or can

00:20:36,240 --> 00:20:40,960
easily be optimized

00:20:37,600 --> 00:20:43,120
for running on low compute devices

00:20:40,960 --> 00:20:45,280
model optimization can be a whole talk

00:20:43,120 --> 00:20:47,520
in itself

00:20:45,280 --> 00:20:49,120
you also have to think about how best to

00:20:47,520 --> 00:20:51,039
run the model

00:20:49,120 --> 00:20:53,840
should it be kept in a main thread or

00:20:51,039 --> 00:20:57,679
move to a worker thread

00:20:53,840 --> 00:21:00,080
how should loading caching be handled

00:20:57,679 --> 00:21:01,440
where in the life cycle is it best to

00:21:00,080 --> 00:21:03,120
load the model

00:21:01,440 --> 00:21:05,520
should it be added into the global

00:21:03,120 --> 00:21:09,360
context the flow context

00:21:05,520 --> 00:21:12,000
or just left it within the node context

00:21:09,360 --> 00:21:13,200
and as far as data goes you can have at

00:21:12,000 --> 00:21:16,559
your disposal

00:21:13,200 --> 00:21:19,520
audio inputs video inputs and all kinds

00:21:16,559 --> 00:21:21,679
of sensor input data

00:21:19,520 --> 00:21:24,240
how much of the model input output

00:21:21,679 --> 00:21:26,640
should be processed by the node red node

00:21:24,240 --> 00:21:29,679
versus letting the user of your node

00:21:26,640 --> 00:21:31,039
handle that themselves in their flow

00:21:29,679 --> 00:21:32,640
a lot of these questions will be

00:21:31,039 --> 00:21:33,120
answered by the model you're working

00:21:32,640 --> 00:21:37,280
with

00:21:33,120 --> 00:21:37,280
and the use case you're trying to solve

00:21:37,520 --> 00:21:41,600
and with that i'll pass it on to yee

00:21:39,919 --> 00:21:43,840
hong to take you through

00:21:41,600 --> 00:21:45,600
additional example flows and to talk

00:21:43,840 --> 00:21:47,679
more in detail

00:21:45,600 --> 00:21:50,240
to an interesting solution he was

00:21:47,679 --> 00:21:52,960
recently playing around with

00:21:50,240 --> 00:21:55,120
thanks for helping everyone my name is

00:21:52,960 --> 00:21:57,840
and i use the company for open parent

00:21:55,120 --> 00:21:58,799
group and ibm so now that you know a

00:21:57,840 --> 00:22:02,000
thing or two about

00:21:58,799 --> 00:22:04,720
our new rate and principle zr and

00:22:02,000 --> 00:22:05,360
the way we combine them together um

00:22:04,720 --> 00:22:08,400
let's

00:22:05,360 --> 00:22:10,559
look into some example flow to help

00:22:08,400 --> 00:22:14,960
showcase the technology in action

00:22:10,559 --> 00:22:17,600
and hopefully inspire some of your ideas

00:22:14,960 --> 00:22:18,400
so far just showed a basic object

00:22:17,600 --> 00:22:20,640
detection

00:22:18,400 --> 00:22:22,400
flow um with the sample that you don't

00:22:20,640 --> 00:22:24,799
know of which would

00:22:22,400 --> 00:22:27,360
look something like this the flow is

00:22:24,799 --> 00:22:31,600
very simple um there is a

00:22:27,360 --> 00:22:35,280
camera as the input node and here is the

00:22:31,600 --> 00:22:38,400
um custom tutorial node and then

00:22:35,280 --> 00:22:42,880
we will do the objective exactly

00:22:38,400 --> 00:22:46,000
um the major logic um is inside

00:22:42,880 --> 00:22:49,039
the tutorial node um we use

00:22:46,000 --> 00:22:52,080
a dfts models npm package

00:22:49,039 --> 00:22:52,559
um which has a nice api and hide all the

00:22:52,080 --> 00:22:55,600
pre

00:22:52,559 --> 00:22:58,480
and post processing in many cases um

00:22:55,600 --> 00:22:58,960
this is great i'm using the prepackaged

00:22:58,480 --> 00:23:02,480
model

00:22:58,960 --> 00:23:06,559
api is easy and works

00:23:02,480 --> 00:23:09,679
for many cases however you are limited

00:23:06,559 --> 00:23:13,120
to just the cases and the models that

00:23:09,679 --> 00:23:13,120
are used by the packaging

00:23:13,679 --> 00:23:20,840
here is another example in this flow

00:23:17,440 --> 00:23:24,159
i use some transport as custom

00:23:20,840 --> 00:23:27,600
node bar mentioned earlier

00:23:24,159 --> 00:23:31,520
where you extract the functionalities

00:23:27,600 --> 00:23:35,039
of the tutorial node into several

00:23:31,520 --> 00:23:38,720
individual nodes from here here

00:23:35,039 --> 00:23:39,360
and here so the flow itself is very

00:23:38,720 --> 00:23:41,919
simple

00:23:39,360 --> 00:23:42,559
you just take the input from the camera

00:23:41,919 --> 00:23:44,720
and do

00:23:42,559 --> 00:23:45,919
some pre-processing and then pass the

00:23:44,720 --> 00:23:48,960
data

00:23:45,919 --> 00:23:53,039
into a model node and run

00:23:48,960 --> 00:23:56,880
their model inference and then

00:23:53,039 --> 00:23:59,039
pass to a post-processing node and to

00:23:56,880 --> 00:23:59,919
do some post-processing against the

00:23:59,039 --> 00:24:03,120
output of

00:23:59,919 --> 00:24:05,919
the model node and finally

00:24:03,120 --> 00:24:06,559
he passed the data to a bounding box

00:24:05,919 --> 00:24:09,600
node

00:24:06,559 --> 00:24:13,039
and then he would draw the bounding box

00:24:09,600 --> 00:24:16,080
as well as the label onto

00:24:13,039 --> 00:24:19,840
the images so without further ado

00:24:16,080 --> 00:24:19,840
let's try it out

00:24:24,400 --> 00:24:28,640
so you actually detect one person and a

00:24:27,520 --> 00:24:32,559
cell phone

00:24:28,640 --> 00:24:35,600
so let's go into the detail of the flow

00:24:32,559 --> 00:24:38,159
for the the the second note here

00:24:35,600 --> 00:24:38,960
uh is actually uh a key of a function

00:24:38,159 --> 00:24:42,240
node

00:24:38,960 --> 00:24:45,200
um it's doing the processing logic

00:24:42,240 --> 00:24:48,400
and the logic here is very simple um you

00:24:45,200 --> 00:24:51,919
just call uh tensorflow.js api

00:24:48,400 --> 00:24:55,600
to decode the image and then um

00:24:51,919 --> 00:24:58,720
convert the data into tf

00:24:55,600 --> 00:25:00,320
objects so inside the ta function node

00:24:58,720 --> 00:25:04,480
that you can access

00:25:00,320 --> 00:25:08,159
all the tensorflow.json api under the df

00:25:04,480 --> 00:25:12,320
variable and at the end of the code

00:25:08,159 --> 00:25:16,159
we try to uncompose and

00:25:12,320 --> 00:25:19,520
main object and containing um the

00:25:16,159 --> 00:25:23,039
image tensors that's the format

00:25:19,520 --> 00:25:27,200
that our monumental need from here

00:25:23,039 --> 00:25:29,600
is actually the model known so it's a tf

00:25:27,200 --> 00:25:30,799
node in the df model node then you need

00:25:29,600 --> 00:25:34,159
to surface by

00:25:30,799 --> 00:25:37,760
um your model uil so it is an

00:25:34,159 --> 00:25:40,960
object detection uh project model um

00:25:37,760 --> 00:25:42,960
you um when you use dollar flow um you

00:25:40,960 --> 00:25:46,000
will try to

00:25:42,960 --> 00:25:48,640
retrieve the model um from this url

00:25:46,000 --> 00:25:49,440
so you can assign it to point to a

00:25:48,640 --> 00:25:52,080
remote

00:25:49,440 --> 00:25:53,200
um url you can also point to your local

00:25:52,080 --> 00:25:56,320
file system

00:25:53,200 --> 00:25:57,679
if it is a remote url um you will try to

00:25:56,320 --> 00:26:00,320
retrieve the model

00:25:57,679 --> 00:26:01,039
um store it into on your local file

00:26:00,320 --> 00:26:03,520
system

00:26:01,039 --> 00:26:05,840
and cache it you will also maintain the

00:26:03,520 --> 00:26:05,840
cache

00:26:06,400 --> 00:26:10,320
and when you are you kick off the flow

00:26:09,360 --> 00:26:13,440
um

00:26:10,320 --> 00:26:17,279
and the data flow through this node

00:26:13,440 --> 00:26:21,039
it will um run the model inference

00:26:17,279 --> 00:26:23,919
and then um it will pass the uh

00:26:21,039 --> 00:26:24,480
the model inference result to the next

00:26:23,919 --> 00:26:26,640
node

00:26:24,480 --> 00:26:28,080
so the next node is actually a

00:26:26,640 --> 00:26:31,440
post-processing

00:26:28,080 --> 00:26:33,520
because the uh the result of the

00:26:31,440 --> 00:26:34,720
model inference the object detection

00:26:33,520 --> 00:26:38,000
model is

00:26:34,720 --> 00:26:41,200
actually um either an

00:26:38,000 --> 00:26:46,080
tensor um or an array of tensor

00:26:41,200 --> 00:26:49,679
so um we need the post-processing node

00:26:46,080 --> 00:26:52,799
um to convert it to a more

00:26:49,679 --> 00:26:55,919
friendly format as you can see here

00:26:52,799 --> 00:26:58,960
after uh the post-processing um

00:26:55,919 --> 00:27:02,080
the data will become um

00:26:58,960 --> 00:27:05,520
an array of objects and these objects

00:27:02,080 --> 00:27:08,880
actually are the objects that detect

00:27:05,520 --> 00:27:10,720
are in the images so the information

00:27:08,880 --> 00:27:14,480
containing

00:27:10,720 --> 00:27:17,840
the class name and also

00:27:14,480 --> 00:27:21,840
the coordinates of the detected are

00:27:17,840 --> 00:27:26,080
the objects

00:27:21,840 --> 00:27:29,520
so um then in the flow we try to combine

00:27:26,080 --> 00:27:30,000
the result from post processing as well

00:27:29,520 --> 00:27:33,679
as

00:27:30,000 --> 00:27:36,880
the result of the original camera

00:27:33,679 --> 00:27:40,320
and then we um combine these two

00:27:36,880 --> 00:27:43,279
data and then then send it to the

00:27:40,320 --> 00:27:44,399
bounding box note in the bunny box no

00:27:43,279 --> 00:27:47,919
you don't need to

00:27:44,399 --> 00:27:49,120
provide any configurations so you will

00:27:47,919 --> 00:27:52,480
automatically

00:27:49,120 --> 00:27:56,000
uh using the information you pass in

00:27:52,480 --> 00:27:59,440
um including the image as well as

00:27:56,000 --> 00:28:02,799
the body box information and then

00:27:59,440 --> 00:28:05,840
draw these um

00:28:02,799 --> 00:28:08,960
information onto the pictures

00:28:05,840 --> 00:28:12,080
as you can see here so

00:28:08,960 --> 00:28:15,360
um you can see the node here

00:28:12,080 --> 00:28:18,960
and here um those are the

00:28:15,360 --> 00:28:20,960
tensorflow custom nodes so

00:28:18,960 --> 00:28:23,120
the only thing you need to provide to

00:28:20,960 --> 00:28:26,480
them is actually

00:28:23,120 --> 00:28:30,240
here is the model url and also

00:28:26,480 --> 00:28:33,840
the class definition and json file

00:28:30,240 --> 00:28:37,039
and that's it and i think the only code

00:28:33,840 --> 00:28:38,159
um i have i programmed is only the

00:28:37,039 --> 00:28:41,360
pre-processing

00:28:38,159 --> 00:28:44,720
but even here the logic

00:28:41,360 --> 00:28:48,080
is very simple so you can see by

00:28:44,720 --> 00:28:51,919
leveraging those um custom nodes

00:28:48,080 --> 00:28:52,559
you can compose your model inference

00:28:51,919 --> 00:28:55,679
flow

00:28:52,559 --> 00:28:59,279
uh very easily um so in this

00:28:55,679 --> 00:29:02,640
case we use the object detection

00:28:59,279 --> 00:29:06,080
so if you for example if you

00:29:02,640 --> 00:29:09,760
um train another object detection

00:29:06,080 --> 00:29:12,399
and with your own classes

00:29:09,760 --> 00:29:13,520
the only thing you need to change is

00:29:12,399 --> 00:29:16,640
modify

00:29:13,520 --> 00:29:19,840
this url and to point to

00:29:16,640 --> 00:29:22,559
your model and also

00:29:19,840 --> 00:29:22,960
in the post processing node you change

00:29:22,559 --> 00:29:26,720
the

00:29:22,960 --> 00:29:30,240
classes class url to point to

00:29:26,720 --> 00:29:33,279
your class definition file then

00:29:30,240 --> 00:29:36,399
you can um around the flow

00:29:33,279 --> 00:29:38,799
so it's very easy

00:29:36,399 --> 00:29:40,320
there is quite a bit uh you can do is

00:29:38,799 --> 00:29:42,960
update detection

00:29:40,320 --> 00:29:43,679
as for the no great part i also found

00:29:42,960 --> 00:29:46,480
something

00:29:43,679 --> 00:29:48,399
quite interesting because no raid is

00:29:46,480 --> 00:29:51,200
running on node.js

00:29:48,399 --> 00:29:53,120
and the benefit of using node.js is you

00:29:51,200 --> 00:29:56,480
can run it on many type

00:29:53,120 --> 00:29:59,600
of environments from your laptop

00:29:56,480 --> 00:30:03,440
to the cloud platform so

00:29:59,600 --> 00:30:06,480
let's try around something um h device

00:30:03,440 --> 00:30:09,760
uh the door closed hardwares um such

00:30:06,480 --> 00:30:13,440
as raspberry pi or json nano um

00:30:09,760 --> 00:30:16,480
luckily i do have json minor by hand

00:30:13,440 --> 00:30:17,039
and in the next flow i'd like to show

00:30:16,480 --> 00:30:20,480
you

00:30:17,039 --> 00:30:23,440
an auto garage door flow

00:30:20,480 --> 00:30:24,480
in this flow i use several device our

00:30:23,440 --> 00:30:27,760
first one

00:30:24,480 --> 00:30:30,559
is this json nano um it's a small and

00:30:27,760 --> 00:30:31,200
inexpensive single board computer and it

00:30:30,559 --> 00:30:36,799
also has

00:30:31,200 --> 00:30:36,799
gpu on it um running a model influencer

00:30:37,200 --> 00:30:41,919
you can see i also attach um a wi-fi usb

00:30:41,120 --> 00:30:45,039
adapter

00:30:41,919 --> 00:30:48,320
to it um it allows me to

00:30:45,039 --> 00:30:51,679
control my id camera here and so

00:30:48,320 --> 00:30:54,480
i can take a snake

00:30:51,679 --> 00:30:56,480
up from this heavy camera and retrieve

00:30:54,480 --> 00:31:00,720
the image

00:30:56,480 --> 00:31:04,080
and lastly i use a garage door opener up

00:31:00,720 --> 00:31:07,120
to control my garage door opener um so

00:31:04,080 --> 00:31:09,440
you also are very cheap

00:31:07,120 --> 00:31:11,519
let's look at the floor on my desktop

00:31:09,440 --> 00:31:16,240
first or later on i will deploy

00:31:11,519 --> 00:31:18,880
this flow on to the json nano

00:31:16,240 --> 00:31:20,240
but before we look at the flow let's

00:31:18,880 --> 00:31:23,760
look at the

00:31:20,240 --> 00:31:26,640
model that i'm going to use i found the

00:31:23,760 --> 00:31:28,960
uh auto license plate recognition model

00:31:26,640 --> 00:31:32,399
uh from list repository

00:31:28,960 --> 00:31:35,600
and you already provide a future model

00:31:32,399 --> 00:31:38,880
and the accuracy is pretty good so i

00:31:35,600 --> 00:31:41,360
directly convert this project model

00:31:38,880 --> 00:31:42,480
into on tensorflow js web friendly

00:31:41,360 --> 00:31:46,240
format

00:31:42,480 --> 00:31:49,120
and you provide a two approach to use

00:31:46,240 --> 00:31:51,519
this model the first approach is that

00:31:49,120 --> 00:31:55,120
you send the image

00:31:51,519 --> 00:31:58,640
into the model and you will recognize

00:31:55,120 --> 00:31:59,600
the license plate as well as the numbers

00:31:58,640 --> 00:32:02,799
and characters

00:31:59,600 --> 00:32:06,399
on it but when i run

00:32:02,799 --> 00:32:09,919
in this approach on my just amino

00:32:06,399 --> 00:32:13,440
it took me about 50 seconds

00:32:09,919 --> 00:32:14,559
so i think it's too long so i use the

00:32:13,440 --> 00:32:16,960
second approach

00:32:14,559 --> 00:32:18,000
in the second approach it actually has

00:32:16,960 --> 00:32:21,360
two steps

00:32:18,000 --> 00:32:23,919
uh the first step is the same you send

00:32:21,360 --> 00:32:26,159
the image into the model

00:32:23,919 --> 00:32:27,760
but you will only return you on the

00:32:26,159 --> 00:32:30,720
license plate

00:32:27,760 --> 00:32:31,760
found in the image so you use that

00:32:30,720 --> 00:32:34,640
information

00:32:31,760 --> 00:32:36,799
and to do the uh image quoting and

00:32:34,640 --> 00:32:40,559
probing out the license plate

00:32:36,799 --> 00:32:44,320
so then you send the image only

00:32:40,559 --> 00:32:47,919
the license plate into the model again

00:32:44,320 --> 00:32:49,039
so you will return you the numbers and

00:32:47,919 --> 00:32:52,720
characters

00:32:49,039 --> 00:32:53,519
on the license plate and by using the

00:32:52,720 --> 00:32:57,440
second

00:32:53,519 --> 00:33:00,640
approach which means about 5 seconds

00:32:57,440 --> 00:33:04,720
on the sesame so i think

00:33:00,640 --> 00:33:08,480
it's pretty good so let's look at the

00:33:04,720 --> 00:33:09,279
detail of 4 here the third thing is that

00:33:08,480 --> 00:33:12,480
i try to

00:33:09,279 --> 00:33:14,000
trigger on the shoulder on the camera so

00:33:12,480 --> 00:33:17,200
i took a

00:33:14,000 --> 00:33:19,360
picture um from that camera

00:33:17,200 --> 00:33:20,640
and the second step is i try to

00:33:19,360 --> 00:33:23,440
retribute that

00:33:20,640 --> 00:33:24,080
because it's a heavy camera so the thing

00:33:23,440 --> 00:33:27,440
i did

00:33:24,080 --> 00:33:30,720
is that i use the api call

00:33:27,440 --> 00:33:33,840
um to do those stuff and then

00:33:30,720 --> 00:33:36,640
uh after i retrieve the image back i do

00:33:33,840 --> 00:33:37,200
um the same the image processing and

00:33:36,640 --> 00:33:40,640
then i

00:33:37,200 --> 00:33:45,120
send it to the auto lightning player

00:33:40,640 --> 00:33:48,320
with engine model in here you see that

00:33:45,120 --> 00:33:52,960
i stole the the model in

00:33:48,320 --> 00:33:54,720
my local file system and then

00:33:52,960 --> 00:33:56,799
like i mentioned earlier we will

00:33:54,720 --> 00:34:00,080
retrieve the license plate

00:33:56,799 --> 00:34:00,799
um which the uh is coordinates if we

00:34:00,080 --> 00:34:04,000
find any

00:34:00,799 --> 00:34:07,279
license plate inside the image then i do

00:34:04,000 --> 00:34:10,639
the grouping so then i do

00:34:07,279 --> 00:34:13,359
uh then i need to do the processing

00:34:10,639 --> 00:34:14,800
against the license plate image again

00:34:13,359 --> 00:34:16,879
then send into the model

00:34:14,800 --> 00:34:17,919
the second time and the second time

00:34:16,879 --> 00:34:22,480
you're

00:34:17,919 --> 00:34:26,320
returning back those um the character

00:34:22,480 --> 00:34:29,599
the detector um license plate

00:34:26,320 --> 00:34:32,480
and in here i tried to output in to

00:34:29,599 --> 00:34:33,440
the block message so you can see i also

00:34:32,480 --> 00:34:36,960
attached

00:34:33,440 --> 00:34:40,399
a camera input node here

00:34:36,960 --> 00:34:43,760
because i want to try it on my

00:34:40,399 --> 00:34:44,159
desktop first and make sure everything

00:34:43,760 --> 00:34:48,000
works

00:34:44,159 --> 00:34:50,079
mostly and then i can deploy it to

00:34:48,000 --> 00:34:52,079
the teacher you know and i'm a general

00:34:50,079 --> 00:34:56,240
of course i will

00:34:52,079 --> 00:34:59,040
go with this flow here

00:34:56,240 --> 00:35:00,400
let's try this flow on my desktop first

00:34:59,040 --> 00:35:02,960
and you can see

00:35:00,400 --> 00:35:04,480
i'm holding a license plate and let me

00:35:02,960 --> 00:35:08,560
trigger

00:35:04,480 --> 00:35:17,839
before by using the

00:35:08,560 --> 00:35:17,839
front facing camera on my uh laptop

00:35:23,680 --> 00:35:27,119
so you can see it's actually uh

00:35:25,599 --> 00:35:30,000
successfully uh detect

00:35:27,119 --> 00:35:31,200
all the character and numbers on my

00:35:30,000 --> 00:35:34,240
license plate

00:35:31,200 --> 00:35:37,040
but you know this is not um

00:35:34,240 --> 00:35:37,839
it's quite slow um actually the reason

00:35:37,040 --> 00:35:41,520
is that

00:35:37,839 --> 00:35:45,040
i display the image so

00:35:41,520 --> 00:35:48,400
i send the image back and forth uh

00:35:45,040 --> 00:35:52,240
from the device so

00:35:48,400 --> 00:35:55,520
so when you deploy the flow on

00:35:52,240 --> 00:35:57,760
the device and you need to disable the

00:35:55,520 --> 00:35:59,520
image viewer and you can improve your

00:35:57,760 --> 00:36:01,839
performance

00:35:59,520 --> 00:36:04,480
so let's look at the flow of json you

00:36:01,839 --> 00:36:08,160
know um

00:36:04,480 --> 00:36:08,480
the last node on the flow uh to samurai

00:36:08,160 --> 00:36:11,440
is

00:36:08,480 --> 00:36:12,320
a little bit different um i switch this

00:36:11,440 --> 00:36:16,000
note from

00:36:12,320 --> 00:36:19,520
debug to brush opener

00:36:16,000 --> 00:36:22,560
note in this note i try to call the

00:36:19,520 --> 00:36:25,680
bar door opener hub to open

00:36:22,560 --> 00:36:26,240
the clutch door if the license plate

00:36:25,680 --> 00:36:29,680
detect

00:36:26,240 --> 00:36:30,960
on the image are matched to my license

00:36:29,680 --> 00:36:34,640
plate

00:36:30,960 --> 00:36:34,640
and this is my

00:36:34,800 --> 00:36:41,440
id camera that i attach um

00:36:37,839 --> 00:36:42,720
onto on the top of my garage door

00:36:41,440 --> 00:36:47,119
outside

00:36:42,720 --> 00:36:50,240
and this is the garage door opener hub

00:36:47,119 --> 00:36:53,680
he can i can send the

00:36:50,240 --> 00:36:56,880
signal to on this hub then he will send

00:36:53,680 --> 00:36:59,359
the open or close a signal to the garage

00:36:56,880 --> 00:37:03,280
door opener

00:36:59,359 --> 00:37:06,839
so i have a video on yesterday

00:37:03,280 --> 00:37:09,839
then i it will show you how this phone

00:37:06,839 --> 00:37:09,839
works

00:37:35,359 --> 00:37:39,280
as you can see i'm pretty satisfied with

00:37:37,839 --> 00:37:42,160
the result i got

00:37:39,280 --> 00:37:42,560
making those type of objectification for

00:37:42,160 --> 00:37:46,000
is

00:37:42,560 --> 00:37:46,960
very easy and quick however you are not

00:37:46,000 --> 00:37:50,079
limited to just

00:37:46,960 --> 00:37:55,119
image based apps as you can load and

00:37:50,079 --> 00:37:55,119
run any tensorflow.js model um

00:37:55,359 --> 00:37:59,920
we even uh have a flow for using a bird

00:37:58,640 --> 00:38:02,720
model

00:37:59,920 --> 00:38:04,960
for cinnamon analysis on things like

00:38:02,720 --> 00:38:07,920
youtube comments and twists

00:38:04,960 --> 00:38:08,720
so many things you can do to recap with

00:38:07,920 --> 00:38:11,200
the vast

00:38:08,720 --> 00:38:12,400
amount of sensor data provided by a

00:38:11,200 --> 00:38:15,760
variety of

00:38:12,400 --> 00:38:18,079
iot device in innovating unlist

00:38:15,760 --> 00:38:19,760
our data and creating applications from

00:38:18,079 --> 00:38:23,280
them is free of those

00:38:19,760 --> 00:38:26,880
noise and principles to channel as

00:38:23,280 --> 00:38:30,079
you saw on no way provide a platform

00:38:26,880 --> 00:38:32,160
that is super flexible and extensible

00:38:30,079 --> 00:38:33,280
if some function functionalities that

00:38:32,160 --> 00:38:36,640
you want doesn't

00:38:33,280 --> 00:38:37,359
exist yet you can easily create a norway

00:38:36,640 --> 00:38:40,320
node

00:38:37,359 --> 00:38:42,640
potentially i use some of the hundreds

00:38:40,320 --> 00:38:43,520
of thousands of the ambient package out

00:38:42,640 --> 00:38:46,960
there

00:38:43,520 --> 00:38:50,000
there are also a lot of principal models

00:38:46,960 --> 00:38:53,280
that you can use tensorflow.js

00:38:50,000 --> 00:38:56,720
even has several model apis

00:38:53,280 --> 00:38:59,440
already packaged as npm modules

00:38:56,720 --> 00:39:01,440
like the object detection model that

00:38:59,440 --> 00:39:04,079
about showed earlier

00:39:01,440 --> 00:39:04,560
the fact that these two technologies

00:39:04,079 --> 00:39:07,920
both

00:39:04,560 --> 00:39:11,359
live in the nodes as ecosystem max

00:39:07,920 --> 00:39:14,320
integration are relatively symbolized

00:39:11,359 --> 00:39:15,280
with tensorflow.js um since model

00:39:14,320 --> 00:39:18,560
inference

00:39:15,280 --> 00:39:21,520
is done locally on data privacy

00:39:18,560 --> 00:39:23,119
shouldn't be a concern and also you

00:39:21,520 --> 00:39:25,520
don't have to rely on

00:39:23,119 --> 00:39:26,880
internet connectivity for your model to

00:39:25,520 --> 00:39:30,320
work

00:39:26,880 --> 00:39:32,880
norway and um tensorflow.js can be used

00:39:30,320 --> 00:39:34,000
rapidly on view ai enabled iot

00:39:32,880 --> 00:39:37,359
applications

00:39:34,000 --> 00:39:39,599
the speed of realizing on this class of

00:39:37,359 --> 00:39:41,119
applications is a strength of these

00:39:39,599 --> 00:39:44,400
technologies

00:39:41,119 --> 00:39:47,440
air is democratized and made

00:39:44,400 --> 00:39:51,119
even more accessible

00:39:47,440 --> 00:39:54,480
and with that we provide uh some link

00:39:51,119 --> 00:39:57,599
to where you can learn more and

00:39:54,480 --> 00:39:59,920
they conclude this second thank you so

00:39:57,599 --> 00:39:59,920
much

00:40:09,040 --> 00:40:12,400
hello thank you everyone for listening

00:40:11,280 --> 00:40:15,520
to the talk and

00:40:12,400 --> 00:40:18,319
any questions feel free to reach out to

00:40:15,520 --> 00:40:20,160
yihong or myself or ask in the chat

00:40:18,319 --> 00:40:22,960
and early in the chat a couple people

00:40:20,160 --> 00:40:25,599
were asking about accessing the video

00:40:22,960 --> 00:40:26,000
and the slides so the open source summit

00:40:25,599 --> 00:40:28,480
team

00:40:26,000 --> 00:40:30,079
will be making all the content available

00:40:28,480 --> 00:40:33,440
but in addition you can actually

00:40:30,079 --> 00:40:35,359
find our video and the slide if you go

00:40:33,440 --> 00:40:39,359
to ibm.biz

00:40:35,359 --> 00:40:43,280
slash tfjs dash node red

00:40:39,359 --> 00:40:46,640
dash oss 2020

00:40:43,280 --> 00:40:46,640
so now let's see if we have any

00:40:50,839 --> 00:40:53,839
questions

00:40:56,960 --> 00:41:00,560
all right i don't see any questions at

00:40:58,880 --> 00:41:02,160
the moment so we'll just give people a

00:41:00,560 --> 00:41:07,839
moment to see if they have any questions

00:41:02,160 --> 00:41:07,839
to ask

00:41:29,440 --> 00:41:33,599
actually hong i have a question for you

00:41:32,079 --> 00:41:34,160
how long would you say it took you to

00:41:33,599 --> 00:41:35,839
get that

00:41:34,160 --> 00:41:38,960
flow together and get it working with

00:41:35,839 --> 00:41:42,000
your garage door opener

00:41:38,960 --> 00:41:46,800
um i guess is it

00:41:42,000 --> 00:41:50,480
took me about uh i would say

00:41:46,800 --> 00:41:53,760
do if including the the device setup

00:41:50,480 --> 00:41:55,119
i need to mount the every camera on top

00:41:53,760 --> 00:41:57,520
of the garage door

00:41:55,119 --> 00:41:58,880
if including those stuff i think it

00:41:57,520 --> 00:42:02,079
would took me about

00:41:58,880 --> 00:42:04,240
um um two hours yeah

00:42:02,079 --> 00:42:05,599
the the tricky part is that you need to

00:42:04,240 --> 00:42:08,800
find an angle

00:42:05,599 --> 00:42:09,920
that the angle can uh can get your

00:42:08,800 --> 00:42:14,640
license plate

00:42:09,920 --> 00:42:17,839
and also um uh the benefit of using that

00:42:14,640 --> 00:42:20,560
ib camera is that is wide angle so

00:42:17,839 --> 00:42:21,119
i need to face the camera down a little

00:42:20,560 --> 00:42:24,720
bit

00:42:21,119 --> 00:42:27,520
and focus on the the front end of

00:42:24,720 --> 00:42:29,440
the vehicle only i need to i don't have

00:42:27,520 --> 00:42:31,520
to shoot the whole the vehicle they're

00:42:29,440 --> 00:42:35,680
coming up to my driveway

00:42:31,520 --> 00:42:38,880
yeah and code about the coding part

00:42:35,680 --> 00:42:42,240
is i think it took me about

00:42:38,880 --> 00:42:43,839
maybe less than one hour to to do the

00:42:42,240 --> 00:42:46,480
coding because

00:42:43,839 --> 00:42:47,920
those know are pre-existing

00:42:46,480 --> 00:42:51,119
tensorflow.js custom

00:42:47,920 --> 00:42:54,319
packages so those are easy

00:42:51,119 --> 00:42:58,079
but i need to write some programming to

00:42:54,319 --> 00:43:00,800
for example to coping the image

00:42:58,079 --> 00:43:01,680
um with the license plate that's the

00:43:00,800 --> 00:43:04,240
first part

00:43:01,680 --> 00:43:05,200
and the second part is i need to once i

00:43:04,240 --> 00:43:08,640
get the

00:43:05,200 --> 00:43:11,280
uh the output from the uh the model

00:43:08,640 --> 00:43:12,720
um tell me the license plate uh

00:43:11,280 --> 00:43:15,680
character and digit

00:43:12,720 --> 00:43:17,680
i need to do the comparison that's

00:43:15,680 --> 00:43:20,800
that's the part i need to copy here

00:43:17,680 --> 00:43:24,480
right now i i hot code my license plate

00:43:20,800 --> 00:43:28,319
on that flow so you can only recognize

00:43:24,480 --> 00:43:31,280
my vehicle yeah

00:43:28,319 --> 00:43:32,960
and uh okay so someone has a question

00:43:31,280 --> 00:43:35,359
and they said the camera node

00:43:32,960 --> 00:43:36,000
was already available correct so that

00:43:35,359 --> 00:43:37,760
was just

00:43:36,000 --> 00:43:39,760
the default camera node available in the

00:43:37,760 --> 00:43:41,760
node

00:43:39,760 --> 00:43:44,800
node-red library correct so it wasn't a

00:43:41,760 --> 00:43:48,000
special camera node that you used

00:43:44,800 --> 00:43:48,800
um if uh let me answer the question

00:43:48,000 --> 00:43:52,079
properly

00:43:48,800 --> 00:43:55,760
um if um he are talking about

00:43:52,079 --> 00:43:56,000
the camera node that camera node on the

00:43:55,760 --> 00:43:59,119
no

00:43:56,000 --> 00:44:00,160
red node is actually um using the

00:43:59,119 --> 00:44:03,599
built-in camera

00:44:00,160 --> 00:44:07,280
on your desktop it's not using that

00:44:03,599 --> 00:44:10,319
ib camera api

00:44:07,280 --> 00:44:11,119
so that that camera know is actually

00:44:10,319 --> 00:44:13,839
linked to

00:44:11,119 --> 00:44:14,640
uh your building browser viewing camera

00:44:13,839 --> 00:44:17,920
is your

00:44:14,640 --> 00:44:20,319
front facing uh camera so

00:44:17,920 --> 00:44:21,040
um the way i control the camera is

00:44:20,319 --> 00:44:24,400
through the

00:44:21,040 --> 00:44:25,599
api call because that that camera is an

00:44:24,400 --> 00:44:29,920
ip camera

00:44:25,599 --> 00:44:33,520
so i call the remote api call to get

00:44:29,920 --> 00:44:34,640
to um have photoshop and then retrieve

00:44:33,520 --> 00:44:37,599
the image back

00:44:34,640 --> 00:44:38,480
but i believe now that they those ib

00:44:37,599 --> 00:44:40,720
camera

00:44:38,480 --> 00:44:42,079
actually provide a lot of features for

00:44:40,720 --> 00:44:45,440
example they have

00:44:42,079 --> 00:44:48,720
motion sensor so you can have you use

00:44:45,440 --> 00:44:51,359
some sort of workhook so

00:44:48,720 --> 00:44:52,560
when he detects a motion sensor he will

00:44:51,359 --> 00:44:56,240
notify you

00:44:52,560 --> 00:44:58,319
so in in that sense then if you

00:44:56,240 --> 00:44:59,680
detect the motion sensor at the motion

00:44:58,319 --> 00:45:03,119
sense detect motion

00:44:59,680 --> 00:45:04,400
then it can trigger ufo to start your

00:45:03,119 --> 00:45:06,880
for

00:45:04,400 --> 00:45:08,000
when you see the demo in my video

00:45:06,880 --> 00:45:11,359
actually

00:45:08,000 --> 00:45:13,839
i manually trigger that flow because

00:45:11,359 --> 00:45:15,200
i don't have the motion sensor for my ib

00:45:13,839 --> 00:45:18,400
camera yet

00:45:15,200 --> 00:45:21,920
but i believe those iv

00:45:18,400 --> 00:45:26,560
camera with the sensor is very common

00:45:21,920 --> 00:45:26,560
right now so

00:45:29,760 --> 00:45:35,920
thanks so any other question

00:45:32,960 --> 00:45:36,400
is there any ai library can be used with

00:45:35,920 --> 00:45:38,720
no

00:45:36,400 --> 00:45:38,720
way

00:45:39,760 --> 00:45:43,280
i think for our talk that we try to

00:45:42,640 --> 00:45:46,400
focus

00:45:43,280 --> 00:45:47,760
uh integrate the tensorflow.js so

00:45:46,400 --> 00:45:50,319
tensorflow.js itself

00:45:47,760 --> 00:45:51,359
is actually an ai library machine

00:45:50,319 --> 00:45:54,000
learning library

00:45:51,359 --> 00:45:55,359
so like uh bob mentioned earlier you can

00:45:54,000 --> 00:45:57,760
you not only can

00:45:55,359 --> 00:45:58,400
um do the inference on it you actually

00:45:57,760 --> 00:46:03,359
also can

00:45:58,400 --> 00:46:03,359
run training on it so you can

00:46:04,480 --> 00:46:09,520
most of time you will use um return

00:46:09,680 --> 00:46:12,800
model maybe

00:46:13,520 --> 00:46:15,839
that

00:46:22,640 --> 00:46:29,680
there are other ai library exists

00:46:26,400 --> 00:46:33,040
but i think um

00:46:29,680 --> 00:46:34,640
pfds unique uh part is that it also

00:46:33,040 --> 00:46:38,079
support training

00:46:34,640 --> 00:46:41,599
i think most of other ai library they

00:46:38,079 --> 00:46:45,680
only um support uh inference on the

00:46:41,599 --> 00:46:48,800
browser or maybe on the node.js site

00:46:45,680 --> 00:46:51,920
mostly those ai library

00:46:48,800 --> 00:46:53,200
do the training and inference in the

00:46:51,920 --> 00:46:57,839
python

00:46:53,200 --> 00:46:57,839
language bindings

00:47:07,599 --> 00:47:11,599
if somebody was asking for the link

00:47:09,920 --> 00:47:12,839
again to the high res video and the

00:47:11,599 --> 00:47:25,839
slides that's

00:47:12,839 --> 00:47:25,839
ibm.biz slash tfj

00:47:26,400 --> 00:47:30,800
and sure maybe you can share it let's

00:47:28,640 --> 00:47:30,800
see

00:47:34,680 --> 00:47:43,200
ibm.biz slash tfjs dash

00:47:37,920 --> 00:47:43,200
node red dash oss 2020

00:47:49,280 --> 00:47:52,400
all right i'm not sure i think we have

00:47:50,800 --> 00:48:07,839
another minute or two

00:47:52,400 --> 00:48:07,839
if there's any other questions

00:48:15,280 --> 00:48:18,640
all right everyone thank you for joining

00:48:16,960 --> 00:48:21,760
us and again

00:48:18,640 --> 00:48:22,559
you can find the the open source summit

00:48:21,760 --> 00:48:24,800
team will

00:48:22,559 --> 00:48:25,920
be making all this content available so

00:48:24,800 --> 00:48:27,359
you can get it through them

00:48:25,920 --> 00:48:29,079
or you can get it through the link that

00:48:27,359 --> 00:48:33,119
i mentioned earlier which is

00:48:29,079 --> 00:48:37,760
ibm.biz slash tfjs

00:48:33,119 --> 00:48:41,280
dash node red dash oss 2020

00:48:37,760 --> 00:48:41,280
alright and with that thank you very

00:48:46,839 --> 00:48:50,480
much

00:48:48,400 --> 00:48:50,480

YouTube URL: https://www.youtube.com/watch?v=qlXx4SwPTWk


