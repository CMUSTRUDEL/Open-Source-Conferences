Title: Privacy, Consent and Security Within Modern Applications - Tim Mackey, Synopsys
Publication date: 2019-09-16
Playlist: Open Source Summit & Embedded Linux Conference NA 2019
Description: 
	Privacy, Consent and Security Within Modern Applications - Tim Mackey, Synopsys

Rapid application innovation is characterized in part using shared code from open source components. While open source development offers many benefits, when regulators change the rules our strengths can prove problematic for ongoing regulatory compliance. For example, in January 2019 French regulators highlighted that the initial experience with Android violated consent and transparency provisions in GDPR imposing a hefty fine upon Google. Given privacy regulations like GDPR exist due to security issues within product offerings, it’s time to look at software development not just through a security lens but also through a consent and privacy one.In this session we’ll cover:- Security expectations regulators are creating for consumers- How to identify sensitive data as defined by regulators- The role and lifecycle of user consent in product operations- Models to identify data processing and third-party data transfers
Captions: 
	00:00:00,060 --> 00:00:07,830
good morning everyone I think I'm gonna

00:00:03,210 --> 00:00:10,230
get started just a touch early so my

00:00:07,830 --> 00:00:11,730
name is Tim Mackey I am a principal

00:00:10,230 --> 00:00:14,880
security strategist within the cyber

00:00:11,730 --> 00:00:16,650
research center over at synopsis which

00:00:14,880 --> 00:00:19,020
is one of the three divisions of our

00:00:16,650 --> 00:00:21,060
companies goodness and today we're going

00:00:19,020 --> 00:00:22,560
to be talking about privacy consent

00:00:21,060 --> 00:00:23,789
trust and security within modern

00:00:22,560 --> 00:00:28,109
application modern application

00:00:23,789 --> 00:00:30,359
development this is a shortened version

00:00:28,109 --> 00:00:33,270
of a talk that I gave at blackhat a

00:00:30,359 --> 00:00:36,180
couple weeks back and this has been also

00:00:33,270 --> 00:00:38,700
tuned towards an open source scenario

00:00:36,180 --> 00:00:41,340
the key takeaway that I would love

00:00:38,700 --> 00:00:43,890
everyone to have is that there's a lot

00:00:41,340 --> 00:00:47,340
that we can do as practitioners that

00:00:43,890 --> 00:00:50,820
will impact the overall security of the

00:00:47,340 --> 00:00:52,920
data that's being processed if we start

00:00:50,820 --> 00:00:56,789
thinking about what it means to collect

00:00:52,920 --> 00:00:59,699
and process data and so I'm not a lawyer

00:00:56,789 --> 00:01:01,739
I'm a techie guy so my lawyers like me

00:00:59,699 --> 00:01:03,420
to say things like please don't take

00:01:01,739 --> 00:01:06,240
everything that I have in here as legal

00:01:03,420 --> 00:01:11,159
advice because well 30-minute session

00:01:06,240 --> 00:01:13,880
probably not a best idea so I'm gonna

00:01:11,159 --> 00:01:17,280
give a whole bunch of examples about

00:01:13,880 --> 00:01:20,100
things that we could be doing better and

00:01:17,280 --> 00:01:23,640
what the true implications are so from a

00:01:20,100 --> 00:01:28,409
starting perspective being a security

00:01:23,640 --> 00:01:33,329
target today is a hugely hugely big deal

00:01:28,409 --> 00:01:36,900
so in a three-week period from May into

00:01:33,329 --> 00:01:39,869
June we had disclosure from a company

00:01:36,900 --> 00:01:41,640
called a MCA who was breached they

00:01:39,869 --> 00:01:43,460
happened to be a credit processing

00:01:41,640 --> 00:01:45,360
company behind LabCorp and quest

00:01:43,460 --> 00:01:46,890
Diagnostics which would do lab work

00:01:45,360 --> 00:01:50,640
blood work that your doctor might

00:01:46,890 --> 00:01:52,229
prescribe we had records from the

00:01:50,640 --> 00:01:54,270
Customs and Border Protection people for

00:01:52,229 --> 00:01:55,860
faces that they had collected and

00:01:54,270 --> 00:01:57,840
information they collected on travelers

00:01:55,860 --> 00:02:00,060
and we had a whole bunch of information

00:01:57,840 --> 00:02:01,799
from a dating site that belief that

00:02:00,060 --> 00:02:04,259
encryption was really really just a

00:02:01,799 --> 00:02:08,429
bunch of well if I hash it an XOR and

00:02:04,259 --> 00:02:12,420
we're good right so every year in July

00:02:08,429 --> 00:02:13,230
for the last eight or ten years IBM in

00:02:12,420 --> 00:02:14,010
conjunction with the Ponte Motta

00:02:13,230 --> 00:02:15,720
Institute put out

00:02:14,010 --> 00:02:18,720
a report that says here's what it

00:02:15,720 --> 00:02:20,549
actually costs for a dative breach in

00:02:18,720 --> 00:02:23,040
the last year's data so this is what

00:02:20,549 --> 00:02:25,319
2018 s data looked like reported this

00:02:23,040 --> 00:02:29,569
year the average cost of a breach went

00:02:25,319 --> 00:02:31,890
up from 4.2 million to 8.1 9 million

00:02:29,569 --> 00:02:33,750
customer turnover went up quite

00:02:31,890 --> 00:02:36,000
dramatically but on the plus side and

00:02:33,750 --> 00:02:37,530
this is a huge plus for the first time

00:02:36,000 --> 00:02:39,659
in the last four years we've actually

00:02:37,530 --> 00:02:41,400
gone down in the length of time it takes

00:02:39,659 --> 00:02:44,939
to identify and contain a breach we're

00:02:41,400 --> 00:02:46,049
now only at 240 for five days unless of

00:02:44,939 --> 00:02:51,000
course we're in healthcare in which case

00:02:46,049 --> 00:02:53,340
we're at 412 and so all of this is

00:02:51,000 --> 00:02:58,019
framing the attack landscape that we

00:02:53,340 --> 00:03:00,510
effectively live within and as we have

00:02:58,019 --> 00:03:01,950
more or more data and we more and more

00:03:00,510 --> 00:03:03,810
data-driven environment

00:03:01,950 --> 00:03:05,519
regulators are kind of saying but wait

00:03:03,810 --> 00:03:09,720
hang on a minute you guys have got it

00:03:05,519 --> 00:03:12,239
wrong and so most people at this point

00:03:09,720 --> 00:03:14,159
in corporate application development

00:03:12,239 --> 00:03:16,950
have come across something called gdpr

00:03:14,159 --> 00:03:19,139
which is a European regulation and you

00:03:16,950 --> 00:03:21,090
may even see at our booth that we've got

00:03:19,139 --> 00:03:23,000
a little sign that says how we collect

00:03:21,090 --> 00:03:26,720
data which is one of the requirements

00:03:23,000 --> 00:03:28,859
Canada has their version called pip ETA

00:03:26,720 --> 00:03:31,829
Australia has the notifiable data

00:03:28,859 --> 00:03:33,150
breaches Act India is in the midst of

00:03:31,829 --> 00:03:34,980
trying to figure out what theirs would

00:03:33,150 --> 00:03:38,849
be so there's a draft bill called bill

00:03:34,980 --> 00:03:41,510
21 2008 teen because well it's 2018 that

00:03:38,849 --> 00:03:44,400
they came up with it now while the

00:03:41,510 --> 00:03:46,889
preceding ones are very centered on what

00:03:44,400 --> 00:03:48,599
to do around data that is being managed

00:03:46,889 --> 00:03:50,639
the Indian one has an additional

00:03:48,599 --> 00:03:52,109
provision around data sovereignty and it

00:03:50,639 --> 00:03:55,349
basically says the authoritative data

00:03:52,109 --> 00:03:59,639
source for all Indian residents must be

00:03:55,349 --> 00:04:01,919
maintained in India that's a bit of a

00:03:59,639 --> 00:04:04,079
change California has the Consumer

00:04:01,919 --> 00:04:07,530
Protection Act which nominally comes on

00:04:04,079 --> 00:04:08,940
line in January of this year but that

00:04:07,530 --> 00:04:12,629
has been delayed through a series of

00:04:08,940 --> 00:04:15,239
amendments to maybe June maybe July I'm

00:04:12,629 --> 00:04:17,010
still a little bit squishy but because

00:04:15,239 --> 00:04:20,250
all of this data is really really

00:04:17,010 --> 00:04:22,560
sensitive and we see large organizations

00:04:20,250 --> 00:04:24,270
like your googles and your Facebook's

00:04:22,560 --> 00:04:26,260
and your Twitter's and so forth having

00:04:24,270 --> 00:04:28,210
access to all of this

00:04:26,260 --> 00:04:30,820
it's not just the regulations that we

00:04:28,210 --> 00:04:35,680
have but it's the actual what do we do

00:04:30,820 --> 00:04:37,180
next and so yesterday a group of states

00:04:35,680 --> 00:04:38,950
attorney general decided that they're

00:04:37,180 --> 00:04:42,310
going to start probing in a little bit

00:04:38,950 --> 00:04:44,950
more serious way what actual data

00:04:42,310 --> 00:04:48,190
management is happening with in big tech

00:04:44,950 --> 00:04:49,990
and so they're going to take a look

00:04:48,190 --> 00:04:51,700
through not necessarily the technical

00:04:49,990 --> 00:04:53,260
lens that we would all love them to look

00:04:51,700 --> 00:04:55,600
at but they're gonna take a look at it

00:04:53,260 --> 00:04:57,250
through I'm a politician and I'm a

00:04:55,600 --> 00:04:59,280
lawyer and that might not be exactly

00:04:57,250 --> 00:05:03,220
what we expect

00:04:59,280 --> 00:05:04,480
so from an open source perspective one

00:05:03,220 --> 00:05:07,390
of the interesting things that happened

00:05:04,480 --> 00:05:09,280
was the whole Equifax data breach which

00:05:07,390 --> 00:05:11,590
was an attack vector through an

00:05:09,280 --> 00:05:15,130
unpatched instance of Apache stress

00:05:11,590 --> 00:05:17,800
brought a lot of focus on well what is

00:05:15,130 --> 00:05:19,450
open source who is the vendor of open

00:05:17,800 --> 00:05:21,010
source where did I get this from

00:05:19,450 --> 00:05:22,900
gee-whiz they don't seem to be doing

00:05:21,010 --> 00:05:25,750
security all that well so maybe I need

00:05:22,900 --> 00:05:27,490
to go to a different vendor who can I go

00:05:25,750 --> 00:05:29,290
to a different vendor than this open

00:05:27,490 --> 00:05:31,090
source and they asked a lot of questions

00:05:29,290 --> 00:05:32,920
that just didn't make a whole lot of

00:05:31,090 --> 00:05:33,970
sense and in one part of our business we

00:05:32,920 --> 00:05:37,690
actually deal with that kind of

00:05:33,970 --> 00:05:40,060
downstream I'd like to be a student of

00:05:37,690 --> 00:05:41,830
other people's failures I like to learn

00:05:40,060 --> 00:05:42,970
from them so I don't make the mistakes

00:05:41,830 --> 00:05:45,490
and one of the things that I encourage

00:05:42,970 --> 00:05:49,060
everyone in this room to do is to read

00:05:45,490 --> 00:05:51,760
the Senate report on the Equifax breach

00:05:49,060 --> 00:05:55,900
I refer to this lovingly as 72 pages of

00:05:51,760 --> 00:05:58,420
absolute awesomeness this was about a

00:05:55,900 --> 00:06:01,000
two-year investigation and it found as

00:05:58,420 --> 00:06:03,670
you would expect that the majority of

00:06:01,000 --> 00:06:05,830
the issues associated with the Equifax

00:06:03,670 --> 00:06:08,830
breach had absolutely nothing to do with

00:06:05,830 --> 00:06:11,200
the actual technology per se but really

00:06:08,830 --> 00:06:13,120
were people process breakdown

00:06:11,200 --> 00:06:15,340
off the top of my head I believe it was

00:06:13,120 --> 00:06:20,200
8,500 unpatched vulnerabilities within

00:06:15,340 --> 00:06:23,590
their software infrastructure the person

00:06:20,200 --> 00:06:26,620
who how CVE information was disseminated

00:06:23,590 --> 00:06:28,660
was a 400 person distribution list we're

00:06:26,620 --> 00:06:31,210
all new CVEs would just kind of go in at

00:06:28,660 --> 00:06:34,480
the top and given the volume of CBE's

00:06:31,210 --> 00:06:37,510
that we see last year was a little over

00:06:34,480 --> 00:06:39,300
17,000 new ones if you're getting 17,000

00:06:37,510 --> 00:06:41,160
emails from a distribution list

00:06:39,300 --> 00:06:43,110
if you're anything like me you've now

00:06:41,160 --> 00:06:45,930
built a male rule that says I'm going to

00:06:43,110 --> 00:06:49,200
ignore most of that turns out that the

00:06:45,930 --> 00:06:52,470
owner of the system that actually was

00:06:49,200 --> 00:06:54,270
the breach vector wasn't on that 400

00:06:52,470 --> 00:06:56,160
person mailing list and when he asked

00:06:54,270 --> 00:06:57,450
the question his boss said no you really

00:06:56,160 --> 00:07:00,660
don't want to be on that list trust me

00:06:57,450 --> 00:07:02,190
dude and so there was a long period of

00:07:00,660 --> 00:07:05,970
time and so one of the interesting

00:07:02,190 --> 00:07:08,300
things from a identification and

00:07:05,970 --> 00:07:11,100
remediation perspective is that it

00:07:08,300 --> 00:07:12,840
actually took Equifax less than 90 days

00:07:11,100 --> 00:07:15,570
to identify and contain the breach

00:07:12,840 --> 00:07:20,880
so two hundred forty-five number Equifax

00:07:15,570 --> 00:07:22,650
did way better than the average now when

00:07:20,880 --> 00:07:25,440
we look at how data is managed there are

00:07:22,650 --> 00:07:27,360
a few truisms and rule number one is you

00:07:25,440 --> 00:07:31,740
can't possibly secure data you don't

00:07:27,360 --> 00:07:33,600
know you're processing so that needs us

00:07:31,740 --> 00:07:35,640
to have a couple of definitions and

00:07:33,600 --> 00:07:37,800
there are a few notes in here that

00:07:35,640 --> 00:07:40,860
there's legal nuances around this so

00:07:37,800 --> 00:07:43,440
again I don't play one on TV I just read

00:07:40,860 --> 00:07:46,830
stuff so one of the things that I

00:07:43,440 --> 00:07:50,220
actually get questioned about is why

00:07:46,830 --> 00:07:52,650
don't we have a version of gdpr in the

00:07:50,220 --> 00:07:54,240
US why do we have a patchwork of each

00:07:52,650 --> 00:07:56,730
state having their own version of what

00:07:54,240 --> 00:08:00,030
data protection really means and I like

00:07:56,730 --> 00:08:01,440
to look at we do have some national

00:08:00,030 --> 00:08:03,450
standards around this healthcare

00:08:01,440 --> 00:08:05,880
information anyone who's ever gone to a

00:08:03,450 --> 00:08:07,620
doctor Hospital clinician had blood

00:08:05,880 --> 00:08:09,000
drawn you've got the litany of papers

00:08:07,620 --> 00:08:11,070
that say here's what's going to happen

00:08:09,000 --> 00:08:12,270
most people don't read them because well

00:08:11,070 --> 00:08:13,230
they wouldn't understand half of what

00:08:12,270 --> 00:08:15,690
was in there anyway

00:08:13,230 --> 00:08:19,350
but it basically defines what data means

00:08:15,690 --> 00:08:21,270
and here's their definition normal

00:08:19,350 --> 00:08:22,620
people tend to define data is any

00:08:21,270 --> 00:08:24,120
information about myself which is

00:08:22,620 --> 00:08:26,400
provided to somebody else in order to

00:08:24,120 --> 00:08:29,490
give me some kind of service that's data

00:08:26,400 --> 00:08:30,900
and within my development team because

00:08:29,490 --> 00:08:32,460
we're from the Northeast we modify

00:08:30,900 --> 00:08:36,630
things a little bit and it's actually

00:08:32,460 --> 00:08:39,660
dater so if you hear me say that that's

00:08:36,630 --> 00:08:41,490
where that's coming from so from a data

00:08:39,660 --> 00:08:44,250
privacy perspective we need a definition

00:08:41,490 --> 00:08:50,040
as well and so I so very nicely defines

00:08:44,250 --> 00:08:51,960
it in 29,000 2011 as a set of shared

00:08:50,040 --> 00:08:52,440
values governing the privacy protection

00:08:51,960 --> 00:08:54,510
so

00:08:52,440 --> 00:08:58,440
you're defining privacy using the word

00:08:54,510 --> 00:09:00,930
privacy in your definition so yeah there

00:08:58,440 --> 00:09:05,450
is no common legal definition across the

00:09:00,930 --> 00:09:09,060
board using the Canadian example it is

00:09:05,450 --> 00:09:12,170
not actually defined but it has a set of

00:09:09,060 --> 00:09:16,920
protections around right to life liberty

00:09:12,170 --> 00:09:18,750
security of the person and in the u.s.

00:09:16,920 --> 00:09:22,200
we have similar things around some of

00:09:18,750 --> 00:09:24,390
the constitutional amendments they give

00:09:22,200 --> 00:09:26,900
us the beginnings of what privacy might

00:09:24,390 --> 00:09:30,720
look like but they're not necessarily

00:09:26,900 --> 00:09:32,100
defined within a legal construct now of

00:09:30,720 --> 00:09:33,360
course if I'm a normal person I say that

00:09:32,100 --> 00:09:35,850
that's an expectation that I have

00:09:33,360 --> 00:09:38,460
whatever data I just gave you is going

00:09:35,850 --> 00:09:41,100
to be properly protected so what are you

00:09:38,460 --> 00:09:45,990
gonna do about that and so I'm going to

00:09:41,100 --> 00:09:48,150
give an example and I can give the whole

00:09:45,990 --> 00:09:50,490
story behind this but I'm just gonna

00:09:48,150 --> 00:09:53,490
highlight the little yellow bits so

00:09:50,490 --> 00:09:55,800
we've all gotten emails from somebody

00:09:53,490 --> 00:09:56,520
else that we didn't expect to have and

00:09:55,800 --> 00:09:58,500
so I got one

00:09:56,520 --> 00:10:01,530
from Wells Fargo the person opened an

00:09:58,500 --> 00:10:04,470
account and type out the email address

00:10:01,530 --> 00:10:05,880
and it says you requested an update to

00:10:04,470 --> 00:10:08,940
your email this little link will expire

00:10:05,880 --> 00:10:10,650
in 90 days so I ignored that I figured

00:10:08,940 --> 00:10:13,590
that there must be something behind it

00:10:10,650 --> 00:10:15,330
whatever a couple days later I got oh

00:10:13,590 --> 00:10:17,310
wait a minute you've added this person

00:10:15,330 --> 00:10:19,170
as a new Zell recipient here's their

00:10:17,310 --> 00:10:21,900
phone number and they're now going to

00:10:19,170 --> 00:10:24,510
receive this okay maybe I should try and

00:10:21,900 --> 00:10:26,600
do something then a day later wait a

00:10:24,510 --> 00:10:29,670
minute here are all these transactions

00:10:26,600 --> 00:10:31,590
so wait a minute I just sent out a whole

00:10:29,670 --> 00:10:33,720
bunch I just received a whole bunch of

00:10:31,590 --> 00:10:38,040
information that was sent to me assuming

00:10:33,720 --> 00:10:39,510
that that email address was legit try

00:10:38,040 --> 00:10:41,280
calling them and explaining the

00:10:39,510 --> 00:10:45,540
situation and seeing if they can resolve

00:10:41,280 --> 00:10:48,990
it that's a fun conversation another

00:10:45,540 --> 00:10:51,390
variation on this so plum benefits is a

00:10:48,990 --> 00:10:53,790
company that does benefits management

00:10:51,390 --> 00:10:56,640
for smaller organizations in this

00:10:53,790 --> 00:10:58,640
instance one of the people decided that

00:10:56,640 --> 00:11:01,950
they were going to book a hotel in

00:10:58,640 --> 00:11:05,730
Baltimore by the airport on these dates

00:11:01,950 --> 00:11:06,000
here's their name so what do I have here

00:11:05,730 --> 00:11:07,440
that

00:11:06,000 --> 00:11:10,110
I can use to go and impersonate them

00:11:07,440 --> 00:11:12,260
what do I now know about them that could

00:11:10,110 --> 00:11:14,250
facilitate a different type of attack

00:11:12,260 --> 00:11:17,040
this was a one-off

00:11:14,250 --> 00:11:20,070
turns out that it was legit they were

00:11:17,040 --> 00:11:22,260
surprised that I received it try having

00:11:20,070 --> 00:11:26,100
that conversation that I didn't just

00:11:22,260 --> 00:11:27,570
just my email address drusen number two

00:11:26,100 --> 00:11:29,580
if your users don't know what you're

00:11:27,570 --> 00:11:31,620
doing with their data you increase the

00:11:29,580 --> 00:11:37,080
reputational risk to your organization

00:11:31,620 --> 00:11:39,480
if something goes wrong and this gets us

00:11:37,080 --> 00:11:42,780
to consent and consent it's a hugely

00:11:39,480 --> 00:11:44,130
tricky construct gdpr defines it as all

00:11:42,780 --> 00:11:48,000
that and I'm not going to read it for

00:11:44,130 --> 00:11:49,290
you all the slides are on the the thing

00:11:48,000 --> 00:11:51,080
or actually I think I need to put an

00:11:49,290 --> 00:11:53,940
update and I did a couple tweaks in here

00:11:51,080 --> 00:11:55,470
but it basically boils down to before I

00:11:53,940 --> 00:11:57,930
consent to anything I need to know what

00:11:55,470 --> 00:12:00,210
you're doing with my data oh you're

00:11:57,930 --> 00:12:02,790
gonna share it with how long it's gonna

00:12:00,210 --> 00:12:05,700
be around and oh by the way I can change

00:12:02,790 --> 00:12:07,980
my mind later so just because I consent

00:12:05,700 --> 00:12:10,640
it right now doesn't mean that it's

00:12:07,980 --> 00:12:14,220
going to be in perpetuity

00:12:10,640 --> 00:12:15,600
similarly Trust is a really complicated

00:12:14,220 --> 00:12:17,940
concept and there's no legal framework

00:12:15,600 --> 00:12:19,589
around this I went back and forth with

00:12:17,940 --> 00:12:20,700
our internal attorneys around what we

00:12:19,589 --> 00:12:22,050
could call this from a legal perspective

00:12:20,700 --> 00:12:25,020
couldn't come up with anything

00:12:22,050 --> 00:12:26,660
so the PR agency defines it as

00:12:25,020 --> 00:12:28,589
reputational risk is the risk of loss

00:12:26,660 --> 00:12:31,440
associated from damage to an

00:12:28,589 --> 00:12:33,240
organization's reputation the AMA

00:12:31,440 --> 00:12:34,680
defines it as from a consumer

00:12:33,240 --> 00:12:36,450
perspective brand equity is based on

00:12:34,680 --> 00:12:38,220
consumer attitudes about positive brand

00:12:36,450 --> 00:12:41,730
attributes and favorable consequences of

00:12:38,220 --> 00:12:44,280
brand use would you trust a brand that

00:12:41,730 --> 00:12:48,360
just leaked a hundred thousand hundred

00:12:44,280 --> 00:12:50,280
million a billion records were there in

00:12:48,360 --> 00:12:53,430
the news every day people are growing

00:12:50,280 --> 00:12:56,010
numb to these things common definition

00:12:53,430 --> 00:12:57,810
I don't just trust my data everyone if

00:12:56,010 --> 00:12:59,880
the provider is one whose brand I trust

00:12:57,810 --> 00:13:03,240
or one solves a real problem for me I'm

00:12:59,880 --> 00:13:06,270
more likely so it's not an absolute to

00:13:03,240 --> 00:13:10,860
give them data but again I reserve the

00:13:06,270 --> 00:13:12,360
right to change my mind so in the

00:13:10,860 --> 00:13:14,459
blackhat version of this that was the

00:13:12,360 --> 00:13:15,810
top ten but we're open sourcing so it

00:13:14,459 --> 00:13:18,350
can go a little bit more detailed in

00:13:15,810 --> 00:13:21,930
here so top ten questions

00:13:18,350 --> 00:13:24,420
does the person who you're collecting

00:13:21,930 --> 00:13:26,220
the data from and from an open-source

00:13:24,420 --> 00:13:28,530
perspective this is huge because the

00:13:26,220 --> 00:13:32,700
components could be used anywhere in any

00:13:28,530 --> 00:13:36,150
context is there clarity around why the

00:13:32,700 --> 00:13:39,060
data is being collected if it's being

00:13:36,150 --> 00:13:41,000
sent to a third party is the user clear

00:13:39,060 --> 00:13:44,820
on who that might be

00:13:41,000 --> 00:13:47,220
because if they get breached I need a

00:13:44,820 --> 00:13:48,440
way to know that I should be maybe doing

00:13:47,220 --> 00:13:52,410
something different

00:13:48,440 --> 00:13:55,640
is there an opt-in or opt-out context

00:13:52,410 --> 00:14:00,690
around this under gdpr

00:13:55,640 --> 00:14:02,310
opt-out isn't consent opt-in is who

00:14:00,690 --> 00:14:04,710
internally could have access to the data

00:14:02,310 --> 00:14:07,050
maybe I'm logging every attribute that

00:14:04,710 --> 00:14:09,060
comes in well that was kind of movie

00:14:07,050 --> 00:14:11,220
pass example from yesterday where

00:14:09,060 --> 00:14:13,140
there's a whole bunch of Splunk data

00:14:11,220 --> 00:14:15,180
that was up in an unsecured s3 bucket

00:14:13,140 --> 00:14:17,100
and it includes all of your card data

00:14:15,180 --> 00:14:18,840
oops

00:14:17,100 --> 00:14:22,290
does it require any specialized

00:14:18,840 --> 00:14:23,760
processing encryption hashes in New York

00:14:22,290 --> 00:14:26,760
State there's a draft bill called the

00:14:23,760 --> 00:14:28,260
shield act and in the shield act it says

00:14:26,760 --> 00:14:32,280
that all sensitive data must be

00:14:28,260 --> 00:14:36,210
encrypted does it specify how or what

00:14:32,280 --> 00:14:39,570
sensitive might be so I figure md4 is

00:14:36,210 --> 00:14:40,770
probably good enough how would you know

00:14:39,570 --> 00:14:42,750
if somebody accessed the data in the

00:14:40,770 --> 00:14:44,160
first place have you informed the

00:14:42,750 --> 00:14:46,770
consumer how long you're going to have

00:14:44,160 --> 00:14:48,270
it for I can't remember the name of the

00:14:46,770 --> 00:14:51,590
organization now but three weeks ago

00:14:48,270 --> 00:14:53,910
there's an organization that had phone

00:14:51,590 --> 00:14:55,110
records from customer support agents

00:14:53,910 --> 00:15:01,260
that go back to 2015

00:14:55,110 --> 00:15:02,880
why Oh for the purposes of training the

00:15:01,260 --> 00:15:04,140
person on the call probably isn't an

00:15:02,880 --> 00:15:07,010
employee there anymore because they're

00:15:04,140 --> 00:15:09,240
in a call center what's the purpose if

00:15:07,010 --> 00:15:12,360
regulations allow the user to delete or

00:15:09,240 --> 00:15:15,450
correct the data what's the process how

00:15:12,360 --> 00:15:16,980
would the user know what data is being

00:15:15,450 --> 00:15:19,140
transferred as part of a phone home

00:15:16,980 --> 00:15:22,980
mechanism we love phone home mechanisms

00:15:19,140 --> 00:15:25,650
and tech these days do people know that

00:15:22,980 --> 00:15:28,410
that's happening the web services used

00:15:25,650 --> 00:15:30,480
how is that transmitted data handled

00:15:28,410 --> 00:15:31,910
where does it go downstream these are

00:15:30,480 --> 00:15:34,310
really really key questions

00:15:31,910 --> 00:15:36,100
that everyone can be asking for every

00:15:34,310 --> 00:15:41,810
piece of software that we're developing

00:15:36,100 --> 00:15:43,340
so gdpr had a reputation of what we're

00:15:41,810 --> 00:15:46,610
just going to solve data breach problems

00:15:43,340 --> 00:15:50,630
but in January Google found out that

00:15:46,610 --> 00:15:52,220
it's not quite so simple so the

00:15:50,630 --> 00:15:54,920
onboarding experience for a new Android

00:15:52,220 --> 00:15:58,900
device was brought to the French

00:15:54,920 --> 00:16:02,090
regulators CNIL because it included a

00:15:58,900 --> 00:16:04,880
perceived obligation to go and have a

00:16:02,090 --> 00:16:06,860
Google account and there are a bunch of

00:16:04,880 --> 00:16:09,590
other things that were hey you can

00:16:06,860 --> 00:16:12,380
opt-out Google found much to its great

00:16:09,590 --> 00:16:15,950
dismay that despite having a European

00:16:12,380 --> 00:16:17,720
presence in Ireland no data processing

00:16:15,950 --> 00:16:18,980
decisions and data security decisions

00:16:17,720 --> 00:16:22,030
were actually occurring in that location

00:16:18,980 --> 00:16:25,250
so French regulators had jurisdiction

00:16:22,030 --> 00:16:28,040
French regulators annoyingly prefer to

00:16:25,250 --> 00:16:30,740
do things in French and when you're an

00:16:28,040 --> 00:16:32,600
American company French law doesn't

00:16:30,740 --> 00:16:35,030
always necessarily make the same amount

00:16:32,600 --> 00:16:38,000
of sense as you would expect so Google

00:16:35,030 --> 00:16:39,740
complained but in the end Google now

00:16:38,000 --> 00:16:42,290
assigned what's known as a data

00:16:39,740 --> 00:16:44,120
protection officer to be part of the

00:16:42,290 --> 00:16:46,820
Dublin operations for Google and there

00:16:44,120 --> 00:16:48,890
was an entire reorganization in December

00:16:46,820 --> 00:16:52,390
around how those operations were going

00:16:48,890 --> 00:16:55,400
to be occurring

00:16:52,390 --> 00:16:56,960
fast-forward to two weeks ago and German

00:16:55,400 --> 00:16:58,760
regulators in Hamburg decided that it

00:16:56,960 --> 00:17:02,570
would be a fantastically brilliant idea

00:16:58,760 --> 00:17:04,040
to say well let's invoke article 66 of

00:17:02,570 --> 00:17:05,600
gdpr which says that there's an

00:17:04,040 --> 00:17:07,310
egregious issue going on and we need to

00:17:05,600 --> 00:17:10,520
stop this now the moral equivalent of an

00:17:07,310 --> 00:17:14,150
injunction and they were upset about

00:17:10,520 --> 00:17:17,270
Google assistants that were having some

00:17:14,150 --> 00:17:21,020
aspect of the data being processed by

00:17:17,270 --> 00:17:22,550
humans but that was never disclosed so

00:17:21,020 --> 00:17:25,370
they said we're gonna shut all this down

00:17:22,550 --> 00:17:26,690
as it turns out Apple was doing the same

00:17:25,370 --> 00:17:28,040
they shouted down Amazon was doing the

00:17:26,690 --> 00:17:29,600
same when I shut it down or at least

00:17:28,040 --> 00:17:30,890
they've deferred it it's a 90-day period

00:17:29,600 --> 00:17:33,200
where they got to figure out what the

00:17:30,890 --> 00:17:35,450
right answer is but change in

00:17:33,200 --> 00:17:37,700
application and product behavior and

00:17:35,450 --> 00:17:40,180
that could have a serious implication to

00:17:37,700 --> 00:17:42,710
what the future might look like for data

00:17:40,180 --> 00:17:44,000
so when a data incident occurs the only

00:17:42,710 --> 00:17:45,690
data that can ever possibly be

00:17:44,000 --> 00:17:48,300
exfiltrated which is

00:17:45,690 --> 00:17:51,330
sent out in stolen is the data you

00:17:48,300 --> 00:17:53,460
retained in the first place so if you

00:17:51,330 --> 00:17:55,620
don't have a need for the data say

00:17:53,460 --> 00:17:57,330
there's no regulatory requirement to

00:17:55,620 --> 00:18:00,680
keep it for longer than a couple of days

00:17:57,330 --> 00:18:02,790
a couple of weeks why are you keeping it

00:18:00,680 --> 00:18:04,020
that's just an open invitation to

00:18:02,790 --> 00:18:07,080
something getting out there that

00:18:04,020 --> 00:18:08,970
shouldn't and that can have serious

00:18:07,080 --> 00:18:10,860
reputational implications when say the

00:18:08,970 --> 00:18:13,470
company you're working for happens to

00:18:10,860 --> 00:18:14,910
get bought as marriott found out after

00:18:13,470 --> 00:18:16,440
acquiring Starwood and finding out that

00:18:14,910 --> 00:18:18,510
there was a whole lot of passport data

00:18:16,440 --> 00:18:21,240
that had been being breached for a

00:18:18,510 --> 00:18:23,820
multi-year period starting in 2014 and

00:18:21,240 --> 00:18:26,190
so you can have goodwill impairments SEC

00:18:23,820 --> 00:18:28,080
filing requirements you could have churn

00:18:26,190 --> 00:18:30,090
of customers a whole lot of marriott

00:18:28,080 --> 00:18:32,120
customers who said yeah you know what no

00:18:30,090 --> 00:18:33,510
thank you I'm going someplace else

00:18:32,120 --> 00:18:36,150
potential for a bankruptcy

00:18:33,510 --> 00:18:40,080
reorganization AMCA the company that was

00:18:36,150 --> 00:18:43,400
behind the quest Diagnostics breach

00:18:40,080 --> 00:18:46,890
they lost 90 percent of their customers

00:18:43,400 --> 00:18:49,080
revenue in a span of about a week and

00:18:46,890 --> 00:18:51,380
they filed for chapter 13 bankruptcy

00:18:49,080 --> 00:18:53,160
protection they have two customers left

00:18:51,380 --> 00:18:55,650
and they're trying to figure out what

00:18:53,160 --> 00:18:58,680
this actually means obviously regulatory

00:18:55,650 --> 00:19:00,780
finds potential for impact on the supply

00:18:58,680 --> 00:19:03,150
chain and increased cost of customer

00:19:00,780 --> 00:19:04,380
acquisition do I really want to trust

00:19:03,150 --> 00:19:06,660
this brand what does it mean to

00:19:04,380 --> 00:19:09,330
reacquire and we see that throughout

00:19:06,660 --> 00:19:12,630
brand management and appendant of

00:19:09,330 --> 00:19:15,030
cybersecurity issues number four as

00:19:12,630 --> 00:19:17,700
applications evolve original decisions

00:19:15,030 --> 00:19:19,860
around data collection become opaque so

00:19:17,700 --> 00:19:21,780
the moral equivalent of this is woohoo

00:19:19,860 --> 00:19:24,090
I've got dator what can I do with this

00:19:21,780 --> 00:19:26,010
data so as long as I've got that I'm

00:19:24,090 --> 00:19:28,230
going to find a good way to do something

00:19:26,010 --> 00:19:30,420
interesting with it and it's probably

00:19:28,230 --> 00:19:33,030
not something that the people who gave

00:19:30,420 --> 00:19:36,060
it to you originally thought about so

00:19:33,030 --> 00:19:42,270
that gets us to the idea of anonymizing

00:19:36,060 --> 00:19:43,620
data so in july london imperial college

00:19:42,270 --> 00:19:45,180
of london put out a report where they

00:19:43,620 --> 00:19:47,040
were able to take some anonymized data

00:19:45,180 --> 00:19:49,170
sets and basically say yeah you know

00:19:47,040 --> 00:19:51,510
what this person who suffers from this

00:19:49,170 --> 00:19:54,180
illness who happens to be receiving care

00:19:51,510 --> 00:19:57,050
and drives to this location in a

00:19:54,180 --> 00:19:59,550
Vauxhall Astra well their name is

00:19:57,050 --> 00:20:01,170
because they could marry all of this

00:19:59,550 --> 00:20:02,910
together and figure out who drove a

00:20:01,170 --> 00:20:08,810
Vauxhall Astra and lived in this

00:20:02,910 --> 00:20:11,340
location a couple days ago in Australia

00:20:08,810 --> 00:20:15,200
the office of Victorian information

00:20:11,340 --> 00:20:18,120
commissioner looked at a few million

00:20:15,200 --> 00:20:19,910
records that were released under the my

00:20:18,120 --> 00:20:22,770
key travel information so this is a

00:20:19,910 --> 00:20:25,160
smart card that is used to go and get

00:20:22,770 --> 00:20:29,220
into trams and buses and so forth and

00:20:25,160 --> 00:20:32,370
the Commissioner had released anonymized

00:20:29,220 --> 00:20:33,420
information for this which said I'm not

00:20:32,370 --> 00:20:35,670
going to include the card number I'm

00:20:33,420 --> 00:20:37,890
gonna put a UUID behind it and I'm now

00:20:35,670 --> 00:20:39,720
going to be able to connect the dots and

00:20:37,890 --> 00:20:41,520
say well this person got on here and got

00:20:39,720 --> 00:20:44,580
off there and so now well what's the

00:20:41,520 --> 00:20:47,010
average duration what lots of research

00:20:44,580 --> 00:20:49,730
value to this type of information up

00:20:47,010 --> 00:20:52,170
until the point where they said you know

00:20:49,730 --> 00:20:53,910
it looks like these people are always

00:20:52,170 --> 00:20:55,980
getting on here and getting off there

00:20:53,910 --> 00:20:58,890
and it looks like on the way home they

00:20:55,980 --> 00:21:01,490
do this so isn't that the minister of

00:20:58,890 --> 00:21:04,140
something in the Australian government

00:21:01,490 --> 00:21:06,000
aren't these these people we don't know

00:21:04,140 --> 00:21:08,700
if with a hundred percent certainty but

00:21:06,000 --> 00:21:10,080
and so this is the what can happen when

00:21:08,700 --> 00:21:11,700
you have anonymized data that gets

00:21:10,080 --> 00:21:13,890
married with other publicly accessible

00:21:11,700 --> 00:21:16,230
information like say and overlay on a

00:21:13,890 --> 00:21:17,940
Google map and suddenly you can pin

00:21:16,230 --> 00:21:21,210
things and say well what's going on

00:21:17,940 --> 00:21:23,340
and so when releasing datasets which

00:21:21,210 --> 00:21:25,380
personally I'm in favor of any kind of

00:21:23,340 --> 00:21:27,510
research that we can do on this we need

00:21:25,380 --> 00:21:29,250
to be very very cognizant to the fact

00:21:27,510 --> 00:21:31,830
that the data is going to be married to

00:21:29,250 --> 00:21:34,490
something else eventually maybe not

00:21:31,830 --> 00:21:37,620
today maybe not next week but eventually

00:21:34,490 --> 00:21:38,880
number five given access to data people

00:21:37,620 --> 00:21:41,730
will find a way to use it and

00:21:38,880 --> 00:21:45,330
potentially misuse it the lots of

00:21:41,730 --> 00:21:48,090
examples of this with but the real

00:21:45,330 --> 00:21:50,760
challenge is that today an application

00:21:48,090 --> 00:21:52,980
is really a mash-up of things and so Web

00:21:50,760 --> 00:21:56,220
Services API is really changed stuff I

00:21:52,980 --> 00:21:58,230
fly Delta Airlines a lot onboard Delta

00:21:56,220 --> 00:22:00,030
Airlines they have the ability to buy

00:21:58,230 --> 00:22:03,840
stuff and you swipe your card behind

00:22:00,030 --> 00:22:06,930
that was a company called 24/7 IO 24/7

00:22:03,840 --> 00:22:09,060
IO was breached year and a half ago I

00:22:06,930 --> 00:22:10,560
had never heard of them up until that

00:22:09,060 --> 00:22:11,940
point but I got a nice little letter

00:22:10,560 --> 00:22:13,410
from Delta saying I'm sorry but your

00:22:11,940 --> 00:22:17,130
credit card appears to have been used as

00:22:13,410 --> 00:22:18,900
it's like what and so the supply chain

00:22:17,130 --> 00:22:21,000
of web services becomes a real

00:22:18,900 --> 00:22:23,480
interesting scenario and so you have to

00:22:21,000 --> 00:22:25,260
ask these kinds of hard questions and

00:22:23,480 --> 00:22:27,540
managing consent can be really

00:22:25,260 --> 00:22:29,850
complicated so you've got voice

00:22:27,540 --> 00:22:32,480
assistance I set up my voice assistant I

00:22:29,850 --> 00:22:35,160
give consent my girlfriend's in the room

00:22:32,480 --> 00:22:36,840
what was her consent to potentially

00:22:35,160 --> 00:22:39,030
being recorded if the thing is always on

00:22:36,840 --> 00:22:41,550
if there's a software update and I

00:22:39,030 --> 00:22:44,550
perform the update but my colleague

00:22:41,550 --> 00:22:47,010
originally gave consent is that a

00:22:44,550 --> 00:22:49,280
legitimate scenario earth I'm on a

00:22:47,010 --> 00:22:52,230
mobile device and I have a jurisdiction

00:22:49,280 --> 00:22:54,300
associated with consent is my

00:22:52,230 --> 00:22:56,250
jurisdiction where my mobile device was

00:22:54,300 --> 00:23:00,860
accessing legit what if I'm over Wi-Fi

00:22:56,250 --> 00:23:04,260
versus 4G or 5g what if I change my mind

00:23:00,860 --> 00:23:06,450
how do I identify myself in a way that

00:23:04,260 --> 00:23:09,390
will allow for me to find out what

00:23:06,450 --> 00:23:11,640
you've got so if I'm an innocent third

00:23:09,390 --> 00:23:14,010
party and there's an Alexa on the table

00:23:11,640 --> 00:23:16,350
how do I identify myself to Google to

00:23:14,010 --> 00:23:18,810
say I want to have all data associated

00:23:16,350 --> 00:23:21,000
with me these are hard problems that we

00:23:18,810 --> 00:23:23,400
still haven't solved today which is why

00:23:21,000 --> 00:23:25,320
we need to understand when we're

00:23:23,400 --> 00:23:26,790
collecting data why we're collecting it

00:23:25,320 --> 00:23:31,140
and make certain we don't have it for

00:23:26,790 --> 00:23:33,570
any longer than we need to so I'm gonna

00:23:31,140 --> 00:23:36,720
show how this could evolve in a very

00:23:33,570 --> 00:23:39,480
simple scenario I want to design it nice

00:23:36,720 --> 00:23:44,610
new shiny IOT device because that's kind

00:23:39,480 --> 00:23:47,490
of all the rage that statement has a lot

00:23:44,610 --> 00:23:49,230
of implications so I have an IOT device

00:23:47,490 --> 00:23:52,380
hunk of hardware gonna be bolted to the

00:23:49,230 --> 00:23:55,320
wall it needs to be cheap do exactly

00:23:52,380 --> 00:23:57,930
what I want to do and did I mention

00:23:55,320 --> 00:24:00,030
cheap so I'm gonna choose whatever I can

00:23:57,930 --> 00:24:01,560
do to get the costs on that down now

00:24:00,030 --> 00:24:02,490
that has to be configured so I'm

00:24:01,560 --> 00:24:04,530
probably going to have a mobile device

00:24:02,490 --> 00:24:06,600
I'm gonna scan a QR and I'm going to

00:24:04,530 --> 00:24:08,190
have a Bluetooth low-energy connection

00:24:06,600 --> 00:24:13,230
to it and it's now going to inherit my

00:24:08,190 --> 00:24:15,030
Wi-Fi connection that device is probably

00:24:13,230 --> 00:24:17,220
going to need to communicate with some

00:24:15,030 --> 00:24:18,990
centralized service so maybe there's a

00:24:17,220 --> 00:24:22,110
TLS stack maybe there's a protocol on it

00:24:18,990 --> 00:24:24,180
okay so now I've got some constraints

00:24:22,110 --> 00:24:25,590
around this device maybe there's a TLS

00:24:24,180 --> 00:24:27,160
stack that's definitely a Wi-Fi stack

00:24:25,590 --> 00:24:30,430
there's a Bluetooth stack does TCP

00:24:27,160 --> 00:24:31,920
involved that's a lot of overhead if

00:24:30,430 --> 00:24:34,800
you've ever looked at those protocols

00:24:31,920 --> 00:24:36,910
for this little cheap device to handle

00:24:34,800 --> 00:24:39,270
what are the concessions that are going

00:24:36,910 --> 00:24:41,800
to happen okay so I've got my mqt broker

00:24:39,270 --> 00:24:43,570
mqtt broker in this example I've got my

00:24:41,800 --> 00:24:44,920
analysis engine I've got a database I've

00:24:43,570 --> 00:24:47,020
got well I'm probably gonna

00:24:44,920 --> 00:24:49,540
micro-service containerize the thing as

00:24:47,020 --> 00:24:51,550
best I can I want to have a web UI I've

00:24:49,540 --> 00:24:54,880
got some html5 probably gonna do this

00:24:51,550 --> 00:24:57,370
all up and no or react and obviously I

00:24:54,880 --> 00:24:58,780
got a mobile interface down and all of

00:24:57,370 --> 00:25:01,180
these things that are up in the cloud

00:24:58,780 --> 00:25:03,850
well I can update them in a DevOps e-way

00:25:01,180 --> 00:25:05,140
very easily but my eye o T device needs

00:25:03,850 --> 00:25:08,620
some mechanism so I'm gonna have an

00:25:05,140 --> 00:25:11,890
over-the-air so I've now put all of

00:25:08,620 --> 00:25:14,290
these constraints on this system that

00:25:11,890 --> 00:25:16,990
have design implications security

00:25:14,290 --> 00:25:20,290
implications and privacy implications so

00:25:16,990 --> 00:25:21,430
from the outset I need to make certain

00:25:20,290 --> 00:25:24,850
that I'm setting the platform

00:25:21,430 --> 00:25:26,770
requirements and from a design goal that

00:25:24,850 --> 00:25:28,590
means selecting a tool chain that is

00:25:26,770 --> 00:25:31,840
going to be the best for this particular

00:25:28,590 --> 00:25:33,880
device I may have different CPUs

00:25:31,840 --> 00:25:35,680
different memory configurations

00:25:33,880 --> 00:25:37,420
different interface chips that I can use

00:25:35,680 --> 00:25:39,790
this is the perfect time to build one of

00:25:37,420 --> 00:25:42,430
each you get a reference board and then

00:25:39,790 --> 00:25:44,710
fuzz those protocols to see which is the

00:25:42,430 --> 00:25:46,360
thing that's most stable is going to

00:25:44,710 --> 00:25:48,970
give me the most amount of room for my

00:25:46,360 --> 00:25:50,380
application because that broom for my

00:25:48,970 --> 00:25:52,080
application is going to allow me to

00:25:50,380 --> 00:25:54,850
manage the privacy of what's in there

00:25:52,080 --> 00:25:57,460
better because that device instability

00:25:54,850 --> 00:26:00,760
could be an entry point we've seen

00:25:57,460 --> 00:26:02,860
examples after examples of devices that

00:26:00,760 --> 00:26:04,570
were unstable as that instability that

00:26:02,860 --> 00:26:08,160
becomes the ultimate attack vector into

00:26:04,570 --> 00:26:10,810
some organization home or business

00:26:08,160 --> 00:26:12,730
similarly the development frameworks are

00:26:10,810 --> 00:26:14,920
going to have a role to play in this

00:26:12,730 --> 00:26:17,070
because a lot of architectures where

00:26:14,920 --> 00:26:19,660
I've got very distributed processing

00:26:17,070 --> 00:26:22,150
that's going to mean some level of data

00:26:19,660 --> 00:26:24,730
transfer so how am i securing the data

00:26:22,150 --> 00:26:26,800
in flight how am i securing it at the

00:26:24,730 --> 00:26:30,070
other end if I've gone to a cloud-based

00:26:26,800 --> 00:26:32,080
service how much of the ownership of the

00:26:30,070 --> 00:26:33,700
infrastructure that I'm transferring to

00:26:32,080 --> 00:26:35,620
that cloud-based service is actually

00:26:33,700 --> 00:26:37,630
going to be something I need to worry

00:26:35,620 --> 00:26:39,430
about from a regulatory perspective like

00:26:37,630 --> 00:26:41,080
if I'm taking credit card information is

00:26:39,430 --> 00:26:43,420
the underlying

00:26:41,080 --> 00:26:47,440
something that can handle credit-card

00:26:43,420 --> 00:26:49,240
information under PCI guidelines these

00:26:47,440 --> 00:26:51,430
are the kinds of questions to be asking

00:26:49,240 --> 00:26:53,830
at the architecture side of the

00:26:51,430 --> 00:26:55,570
decision-making process obviously as I'm

00:26:53,830 --> 00:26:57,520
doing my development I want to make

00:26:55,570 --> 00:26:59,080
certain that I have continuous

00:26:57,520 --> 00:27:01,030
assessments that are happening because

00:26:59,080 --> 00:27:02,830
if my developers don't have the right

00:27:01,030 --> 00:27:04,450
level of security training they're

00:27:02,830 --> 00:27:06,430
probably also not going to have the

00:27:04,450 --> 00:27:08,770
right level of data management training

00:27:06,430 --> 00:27:10,630
to ask the right questions so what can

00:27:08,770 --> 00:27:12,820
we do to uplevel the skill set within

00:27:10,630 --> 00:27:14,440
the development teams themselves so they

00:27:12,820 --> 00:27:18,670
can start to ask those hard questions

00:27:14,440 --> 00:27:20,350
and be part of the solution similarly

00:27:18,670 --> 00:27:21,820
when we're building all this I'm gonna

00:27:20,350 --> 00:27:25,000
assume everybody's using some form of CI

00:27:21,820 --> 00:27:27,910
at this point in time what is the test

00:27:25,000 --> 00:27:30,190
coverage can I actually identify what

00:27:27,910 --> 00:27:33,000
the data flow is within the application

00:27:30,190 --> 00:27:35,350
to a degree where I can say this was

00:27:33,000 --> 00:27:37,150
encrypted form at this point but

00:27:35,350 --> 00:27:39,370
everything before here this is now

00:27:37,150 --> 00:27:41,710
tainted and unavailable data to me and

00:27:39,370 --> 00:27:43,690
have some form of centralized process

00:27:41,710 --> 00:27:46,570
where I can go and say how good are we

00:27:43,690 --> 00:27:48,370
getting we all know that version 1 is

00:27:46,570 --> 00:27:50,140
probably not as secure as we would want

00:27:48,370 --> 00:27:53,320
it to be but as long as we're capturing

00:27:50,140 --> 00:27:54,730
what version 1.1 1.2 and so forth looks

00:27:53,320 --> 00:27:56,410
like I'm moving towards the right

00:27:54,730 --> 00:27:58,210
direction we're baking it in from the

00:27:56,410 --> 00:27:59,560
outset not necessarily trying to bolt it

00:27:58,210 --> 00:28:02,230
on later we're asking the hard questions

00:27:59,560 --> 00:28:06,550
when they're inexpensive to be asked at

00:28:02,230 --> 00:28:08,580
the outset and lastly as we release this

00:28:06,550 --> 00:28:11,740
and personally from my perspective

00:28:08,580 --> 00:28:13,930
everything before the time that we

00:28:11,740 --> 00:28:17,590
actually release software is an academic

00:28:13,930 --> 00:28:19,900
exercise it really doesn't matter how

00:28:17,590 --> 00:28:21,940
secure insecure things are up until the

00:28:19,900 --> 00:28:23,380
point that we ship it so we need to make

00:28:21,940 --> 00:28:26,140
certain that at the point we ship it we

00:28:23,380 --> 00:28:27,910
understand what the governance rules are

00:28:26,140 --> 00:28:29,140
wherever this device is going to be

00:28:27,910 --> 00:28:30,520
shipped because there might be a period

00:28:29,140 --> 00:28:31,750
of time where say six months of

00:28:30,520 --> 00:28:34,450
development needs to happen before that

00:28:31,750 --> 00:28:36,700
be one of our nice shiny IOT device can

00:28:34,450 --> 00:28:38,200
be out in the world and somebody might

00:28:36,700 --> 00:28:40,810
have come up with a new regulation and

00:28:38,200 --> 00:28:44,860
now we have to kind of go and ask

00:28:40,810 --> 00:28:49,270
ourselves some hard questions and so

00:28:44,860 --> 00:28:52,900
that pretty much gets me to very key

00:28:49,270 --> 00:28:54,730
takeaways for this from an open-source

00:28:52,900 --> 00:28:57,250
perspective I want to look at the

00:28:54,730 --> 00:28:59,530
contributors side of the equation we

00:28:57,250 --> 00:29:02,049
want to ensure that everyone who's

00:28:59,530 --> 00:29:04,900
contributing code that touches data in

00:29:02,049 --> 00:29:06,340
any project is able to question why that

00:29:04,900 --> 00:29:08,530
data was collected in the first place

00:29:06,340 --> 00:29:10,559
why that data is part of that workflow

00:29:08,530 --> 00:29:13,600
and be able to communicate that out

00:29:10,559 --> 00:29:16,049
because that component is going to end

00:29:13,600 --> 00:29:19,510
up someplace you didn't expect it to be

00:29:16,049 --> 00:29:21,309
and I can say with all honesty and it

00:29:19,510 --> 00:29:25,210
will live for a lot longer than you

00:29:21,309 --> 00:29:26,799
expect it to live well one part of our

00:29:25,210 --> 00:29:28,960
business actually goes and looks at

00:29:26,799 --> 00:29:31,120
commercial soft work we found a

00:29:28,960 --> 00:29:34,510
vulnerability and a version of FreeBSD

00:29:31,120 --> 00:29:38,260
before FreeBSD was a thing and it was

00:29:34,510 --> 00:29:41,650
still in production last year gay team

00:29:38,260 --> 00:29:44,590
so we want make certain reviewers can

00:29:41,650 --> 00:29:46,720
identify what sensitive data is involved

00:29:44,590 --> 00:29:48,100
and where things are going we want to

00:29:46,720 --> 00:29:53,410
make certain that we're disclosing in

00:29:48,100 --> 00:29:55,390
whatever our readme doc hubs wiki our

00:29:53,410 --> 00:29:58,240
expectations around data processing and

00:29:55,390 --> 00:30:00,400
data collection are and we need to move

00:29:58,240 --> 00:30:02,320
away from self-documenting code because

00:30:00,400 --> 00:30:04,330
the people who are going to make those

00:30:02,320 --> 00:30:05,679
kinds of determinations are not the

00:30:04,330 --> 00:30:08,860
people who are going to be able to read

00:30:05,679 --> 00:30:10,960
the code if we assume that kind of game

00:30:08,860 --> 00:30:13,390
over from that point we need to make

00:30:10,960 --> 00:30:15,490
certain the government is a cooperative

00:30:13,390 --> 00:30:16,480
action between project leadership and

00:30:15,490 --> 00:30:18,850
the development teams

00:30:16,480 --> 00:30:22,600
no more merging with looks good to me if

00:30:18,850 --> 00:30:25,030
there's data involved or +1 asked the

00:30:22,600 --> 00:30:26,590
questions what tests were performed do

00:30:25,030 --> 00:30:28,890
you know whether or not this is going to

00:30:26,590 --> 00:30:31,540
be encrypted correctly is the default

00:30:28,890 --> 00:30:33,250
plain text or is the default something

00:30:31,540 --> 00:30:35,380
that is securely hashed by today's

00:30:33,250 --> 00:30:37,150
standards oh we need to change our

00:30:35,380 --> 00:30:39,669
hashing rules or our encryption rules

00:30:37,150 --> 00:30:41,320
why are we making these changes are we

00:30:39,669 --> 00:30:44,890
ensuring that we're actually using a

00:30:41,320 --> 00:30:46,840
library or not rolling our own we can't

00:30:44,890 --> 00:30:48,549
assume that the component is a say only

00:30:46,840 --> 00:30:50,650
going to live in the u.s. because in the

00:30:48,549 --> 00:30:52,059
u.s. is a patchwork of regulations we

00:30:50,650 --> 00:30:53,860
can't assume the components only going

00:30:52,059 --> 00:30:56,440
to live in Europe because there's still

00:30:53,860 --> 00:30:58,030
a patchwork of regulations one of our

00:30:56,440 --> 00:30:58,990
customers and financial services

00:30:58,030 --> 00:31:02,860
described at best

00:30:58,990 --> 00:31:06,880
his application has to adhere to 378

00:31:02,860 --> 00:31:08,280
separate global regulations how can we

00:31:06,880 --> 00:31:09,720
make certain that our opens

00:31:08,280 --> 00:31:12,120
components that we're contributing to

00:31:09,720 --> 00:31:14,700
and we love can actually satisfy that

00:31:12,120 --> 00:31:15,840
kind of environment those are the types

00:31:14,700 --> 00:31:17,280
of hard questions that we should be

00:31:15,840 --> 00:31:19,830
asking and documenting all of these

00:31:17,280 --> 00:31:21,570
decisions so that when somebody in say a

00:31:19,830 --> 00:31:23,790
highly regulated financial services

00:31:21,570 --> 00:31:25,740
world decides to consume something they

00:31:23,790 --> 00:31:26,970
can at least know that well you thought

00:31:25,740 --> 00:31:28,500
about these problems they might not

00:31:26,970 --> 00:31:30,630
agree with for assessment but you

00:31:28,500 --> 00:31:34,710
thought about the problem beforehand and

00:31:30,630 --> 00:31:36,630
now a conversation can happen and by

00:31:34,710 --> 00:31:40,020
definition we're going to have legacy

00:31:36,630 --> 00:31:43,200
stuff out there and so we need to have

00:31:40,020 --> 00:31:45,630
some process where the project defines a

00:31:43,200 --> 00:31:47,490
policy around how it's going to manage

00:31:45,630 --> 00:31:50,340
data governance so we all have

00:31:47,490 --> 00:31:52,530
contributing MD we need to have some

00:31:50,340 --> 00:31:55,230
variation on that that talks about data

00:31:52,530 --> 00:31:56,430
collection and data processing we need

00:31:55,230 --> 00:31:58,410
to make certain that we're reviewing our

00:31:56,430 --> 00:32:00,960
default configurations because the

00:31:58,410 --> 00:32:03,270
version 1o default configuration might

00:32:00,960 --> 00:32:05,220
be insecure by today's standards and it

00:32:03,270 --> 00:32:07,950
might be a simple case of tweaking those

00:32:05,220 --> 00:32:10,230
defaults to make it a lot better knowing

00:32:07,950 --> 00:32:12,150
that somebody is probably going to trip

00:32:10,230 --> 00:32:13,920
over a version 100 and say woohoo that's

00:32:12,150 --> 00:32:15,390
awesome I really want that version not

00:32:13,920 --> 00:32:19,890
realizing that there is in fact version

00:32:15,390 --> 00:32:23,010
2 and fundamentally start thinking about

00:32:19,890 --> 00:32:25,500
the software lifecycle in commercial

00:32:23,010 --> 00:32:27,090
software will have this is an alpha this

00:32:25,500 --> 00:32:29,100
is a beta this is a release candidate

00:32:27,090 --> 00:32:30,840
we're released some lifespans some

00:32:29,100 --> 00:32:32,640
updates oh wait a minute we're going to

00:32:30,840 --> 00:32:33,900
end of sale we're going to end of

00:32:32,640 --> 00:32:36,060
maintenance we're going to end of life

00:32:33,900 --> 00:32:37,500
and there's a lot of documentation that

00:32:36,060 --> 00:32:39,960
goes around this and customers know

00:32:37,500 --> 00:32:43,200
about these things but if it's an open

00:32:39,960 --> 00:32:46,110
source project well it's the time it

00:32:43,200 --> 00:32:47,250
just gets abandoned on github and you

00:32:46,110 --> 00:32:49,620
see oh wait a minute hasn't been any

00:32:47,250 --> 00:32:51,480
update in three years is that because it

00:32:49,620 --> 00:32:53,970
works and there's not really anything

00:32:51,480 --> 00:32:55,830
more to do with it or is it because the

00:32:53,970 --> 00:32:57,420
person who was originally maintaining it

00:32:55,830 --> 00:32:59,130
decided that was something else cool to

00:32:57,420 --> 00:33:00,990
do and they went off and did that or

00:32:59,130 --> 00:33:02,730
life happened and now they're playing

00:33:00,990 --> 00:33:04,920
with their kids instead or something and

00:33:02,730 --> 00:33:07,560
there's no way of knowing this so that

00:33:04,920 --> 00:33:10,830
when you decide that you know what I'm

00:33:07,560 --> 00:33:12,480
done with this update the readme if

00:33:10,830 --> 00:33:15,000
nothing else to say you know what I'm

00:33:12,480 --> 00:33:17,550
done with this this is the last version

00:33:15,000 --> 00:33:19,650
if you fork this it's kind of on you to

00:33:17,550 --> 00:33:21,870
go and do stuff but I am done with this

00:33:19,650 --> 00:33:23,640
and at that point you don't necessarily

00:33:21,870 --> 00:33:26,250
a whole bunch of issues where people are

00:33:23,640 --> 00:33:28,470
saying why haven't you process my pull

00:33:26,250 --> 00:33:31,230
request I mean like seriously I thought

00:33:28,470 --> 00:33:34,470
you liked me and you don't have those

00:33:31,230 --> 00:33:35,640
kinds of scenarios and so that's it for

00:33:34,470 --> 00:33:37,220
my talk I've got a whole bunch of

00:33:35,640 --> 00:33:40,289
references for all those lovely

00:33:37,220 --> 00:33:41,640
regulations up there I thank everyone I

00:33:40,289 --> 00:33:47,000
think we have about two minutes for

00:33:41,640 --> 00:33:47,000
questions if there's any questions yes

00:33:54,800 --> 00:34:01,830
so I think it would be unfair to say

00:33:59,100 --> 00:34:03,360
that we have a solution per se as much

00:34:01,830 --> 00:34:06,750
as this is a paradigm that we should all

00:34:03,360 --> 00:34:08,820
be working towards and so if we're

00:34:06,750 --> 00:34:10,770
looking at from we're consuming those

00:34:08,820 --> 00:34:13,050
types of devices there's not a whole lot

00:34:10,770 --> 00:34:15,840
that we can do short of starting to

00:34:13,050 --> 00:34:17,310
question the providers of those services

00:34:15,840 --> 00:34:19,620
or the manufacturers of those devices

00:34:17,310 --> 00:34:21,030
and say what do you have on me how are

00:34:19,620 --> 00:34:24,110
you collecting it what have you done

00:34:21,030 --> 00:34:26,370
with it give me all of the details

00:34:24,110 --> 00:34:28,980
regulations like gdpr have that

00:34:26,370 --> 00:34:32,460
obligation associated with them not all

00:34:28,980 --> 00:34:34,740
regulations do and even under gdpr

00:34:32,460 --> 00:34:37,200
there's no standardized process and

00:34:34,740 --> 00:34:39,270
there's no standardized return form for

00:34:37,200 --> 00:34:40,740
the data so you don't necessarily have a

00:34:39,270 --> 00:34:42,120
hundred percent confidence that what you

00:34:40,740 --> 00:34:45,960
get back is going to be something that

00:34:42,120 --> 00:34:47,340
is in fact useable to you or maybe for

00:34:45,960 --> 00:34:50,520
us in the room it might be more usable

00:34:47,340 --> 00:34:51,679
but usable to the layperson so excellent

00:34:50,520 --> 00:34:56,630
question though

00:34:51,679 --> 00:34:56,630
any others yes

00:35:01,980 --> 00:35:07,180
so I have a couple theories and one of

00:35:04,870 --> 00:35:09,570
the simplest is in a healthcare

00:35:07,180 --> 00:35:12,220
environment the longer time is

00:35:09,570 --> 00:35:14,950
fundamentally a realization that doctors

00:35:12,220 --> 00:35:16,230
aren't tech people and as long as it's

00:35:14,950 --> 00:35:18,490
kind of working they're good enough

00:35:16,230 --> 00:35:20,620
because they'd much rather go and fix

00:35:18,490 --> 00:35:24,010
your leg or whatever else is ailing you

00:35:20,620 --> 00:35:25,720
then worry about patching things I think

00:35:24,010 --> 00:35:30,040
that that is fundamentally what it is

00:35:25,720 --> 00:35:32,650
and now you effectively have an attack

00:35:30,040 --> 00:35:34,150
scenario where the malicious actors know

00:35:32,650 --> 00:35:37,330
that there's a lot of value in health

00:35:34,150 --> 00:35:40,540
care information and the ability to

00:35:37,330 --> 00:35:45,100
secure it is not as strong at the local

00:35:40,540 --> 00:35:47,050
level so hopefully we can do better but

00:35:45,100 --> 00:35:48,430
it's through talks like this that

00:35:47,050 --> 00:35:49,840
shining a little bit of a light and

00:35:48,430 --> 00:35:53,410
having people start asking the questions

00:35:49,840 --> 00:35:55,420
is really good so I believe I'm done for

00:35:53,410 --> 00:35:56,610
time so thank you ever so much for

00:35:55,420 --> 00:36:01,349
everyone

00:35:56,610 --> 00:36:01,349

YouTube URL: https://www.youtube.com/watch?v=n2R3RJ9Y7IM


