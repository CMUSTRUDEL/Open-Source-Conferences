Title: The Digital Hearth: An In-the-Wild Automated Group Speech to Text System
Publication date: 2019-09-16
Playlist: Open Source Summit & Embedded Linux Conference NA 2019
Description: 
	The Digital Hearth: An In-the-Wild Automated Group Speech to Text System - Wesley Chow, Cortico / MIT Media Lab

Cortico and the Social Machines group at the MIT Media Lab are building a network of hyper local conversation centers in order to raise unknown and underrepresented issues into public discourse. To do so, we've built the digital hearth, a group conversation recording device deployed into communities to capture speech and ideas.Wes will describe the design and technical capabilities of the digital hearth, which operates disconnected from the Internet but periodically syncs its data with Cortico's servers, downstream speech to text, and natural language processing systems. He will talk about the hardware configuration (a custom 8 channel mic that interfaces with an embedded Raspberry Pi), as well as the in-device Raspbian based software stack that allows for offline operation and remote debugging. Wes will also talk about how features of the hardware implementation affect Cortico's automated speech recognizer and speaker identification systems.
Captions: 
	00:00:01,610 --> 00:00:11,300
alright go ahead and get started since

00:00:05,910 --> 00:00:15,540
uh quite a few slides to go through so

00:00:11,300 --> 00:00:17,520
thanks everyone for coming I'm Wes Chou

00:00:15,540 --> 00:00:20,880
I mean to be talking about the digital

00:00:17,520 --> 00:00:22,500
hearth which is a device that the

00:00:20,880 --> 00:00:24,660
research group and the nonprofit that

00:00:22,500 --> 00:00:27,599
I'm in has been designing to facilitate

00:00:24,660 --> 00:00:29,279
group conversations this is probably

00:00:27,599 --> 00:00:31,140
gonna be a little bit one of the more

00:00:29,279 --> 00:00:33,390
unusual talks here at the conference you

00:00:31,140 --> 00:00:34,440
can turn off your technical brain for

00:00:33,390 --> 00:00:36,149
about 10 minutes and then we'll actually

00:00:34,440 --> 00:00:37,559
start to dive into some some details on

00:00:36,149 --> 00:00:39,629
how this thing works

00:00:37,559 --> 00:00:42,530
I'm honestly not sure why the conference

00:00:39,629 --> 00:00:44,969
accepted my my proposal but here we are

00:00:42,530 --> 00:00:48,329
so I work for a nonprofit called quarter

00:00:44,969 --> 00:00:51,059
Co which is closely attached to one of

00:00:48,329 --> 00:00:53,460
the research labs inside of the MIT

00:00:51,059 --> 00:00:57,059
Media Lab the lab for social machines

00:00:53,460 --> 00:00:59,370
it's kind of a mouthful sorry we we are

00:00:57,059 --> 00:01:01,079
a kind of deployment arm for the

00:00:59,370 --> 00:01:03,390
research that's inside of social

00:01:01,079 --> 00:01:06,060
machines so first I'll give an overview

00:01:03,390 --> 00:01:08,010
of the goals of this project and then

00:01:06,060 --> 00:01:17,009
I'll go into the details of how this

00:01:08,010 --> 00:01:21,180
thing works okay I am NOT able to

00:01:17,009 --> 00:01:26,040
advance slides give me a sec here we go

00:01:21,180 --> 00:01:27,180
ok so so my boss is Debra Roy who runs

00:01:26,040 --> 00:01:30,270
the research group as well as a

00:01:27,180 --> 00:01:33,170
non-profit he is the former chief media

00:01:30,270 --> 00:01:35,579
scientist of Twitter and so a lot of his

00:01:33,170 --> 00:01:37,140
his old research was around the

00:01:35,579 --> 00:01:39,869
characteristics of online discourse

00:01:37,140 --> 00:01:42,090
particularly on Twitter and I have this

00:01:39,869 --> 00:01:43,860
secret theory that he was tired of

00:01:42,090 --> 00:01:47,700
people asking him to think about online

00:01:43,860 --> 00:01:50,159
toxicity and so he pivoted to a thing

00:01:47,700 --> 00:01:52,590
that was a completely opposite of what

00:01:50,159 --> 00:01:55,170
you might be able to do online so the

00:01:52,590 --> 00:01:58,740
question there was is there some kind of

00:01:55,170 --> 00:02:00,750
a social medium that might be more

00:01:58,740 --> 00:02:02,899
representative of ground truth than what

00:02:00,750 --> 00:02:05,369
you see on Twitter and Facebook

00:02:02,899 --> 00:02:07,950
this book was going around the lab at

00:02:05,369 --> 00:02:09,929
the time and it was starting to to kind

00:02:07,950 --> 00:02:12,569
of catch in people's minds this is the

00:02:09,929 --> 00:02:14,909
politics of resentment by Cathy Kramer

00:02:12,569 --> 00:02:16,950
Kathy is a is a researcher at the

00:02:14,909 --> 00:02:19,799
University of Wisconsin and what she did

00:02:16,950 --> 00:02:21,299
was for something like I think like ten

00:02:19,799 --> 00:02:24,810
years she drove around Wisconsin

00:02:21,299 --> 00:02:26,010
inserting herself into conversations and

00:02:24,810 --> 00:02:27,989
these these things actually called

00:02:26,010 --> 00:02:30,090
coffee klatches which is basically a

00:02:27,989 --> 00:02:32,370
group of people that were naturally

00:02:30,090 --> 00:02:35,000
congregating and you know and she she

00:02:32,370 --> 00:02:39,359
would go in and ask kind of very uh

00:02:35,000 --> 00:02:40,409
passively directed questions so one

00:02:39,359 --> 00:02:42,780
example from the book is that there was

00:02:40,409 --> 00:02:44,129
a group of of men who were nude and

00:02:42,780 --> 00:02:46,319
getting together for something like ten

00:02:44,129 --> 00:02:48,510
years to grab coffee at a gas station

00:02:46,319 --> 00:02:50,579
before going into work so you know so

00:02:48,510 --> 00:02:53,970
she was is these communities and found

00:02:50,579 --> 00:02:56,340
those people she the the tail end of her

00:02:53,970 --> 00:02:59,879
fieldwork overlapped with the Scott

00:02:56,340 --> 00:03:04,939
Walker recall vote which if you remember

00:02:59,879 --> 00:03:07,760
so Scott Walker was a conservative

00:03:04,939 --> 00:03:12,030
union-busting governor of Wisconsin and

00:03:07,760 --> 00:03:14,040
the teachers union in particular in in

00:03:12,030 --> 00:03:16,319
Madison was not particularly happy with

00:03:14,040 --> 00:03:19,829
him and they garnered enough public

00:03:16,319 --> 00:03:22,049
support to to start a recall vote to get

00:03:19,829 --> 00:03:23,579
him kicked out of office and it was

00:03:22,049 --> 00:03:26,209
widely reported in the media at the time

00:03:23,579 --> 00:03:28,650
that he would probably be kicked out

00:03:26,209 --> 00:03:32,040
surprise surprise he was not kicked out

00:03:28,650 --> 00:03:34,409
and Cathy actually didn't believe that

00:03:32,040 --> 00:03:35,760
he would be kicked out based off of the

00:03:34,409 --> 00:03:37,859
conversations that she was having with

00:03:35,760 --> 00:03:41,220
people in rural Wisconsin so they're

00:03:37,859 --> 00:03:42,780
kind of you know shades of what you hear

00:03:41,220 --> 00:03:44,579
people like Peter teal talking about

00:03:42,780 --> 00:03:46,500
right now where there's you know there's

00:03:44,579 --> 00:03:48,900
a notion of preference falsification

00:03:46,500 --> 00:03:51,180
which is that what people reveal sort of

00:03:48,900 --> 00:03:53,729
publicly in surveys is not what they

00:03:51,180 --> 00:03:56,909
actually reveal if you talk to them in

00:03:53,729 --> 00:03:58,709
person so so we started thinking about

00:03:56,909 --> 00:04:00,659
Kathy's work and we we wanted to figure

00:03:58,709 --> 00:04:02,639
out a way to scale her work up and so we

00:04:00,659 --> 00:04:07,220
started on on the local voices network

00:04:02,639 --> 00:04:09,090
network or LVN so LVN is centered around

00:04:07,220 --> 00:04:11,849
facilitated conversations with the

00:04:09,090 --> 00:04:14,759
intent to surface diverse and under

00:04:11,849 --> 00:04:17,669
heard voices to do it at scale we need

00:04:14,759 --> 00:04:20,340
more than one Cathy ideally we'd be able

00:04:17,669 --> 00:04:22,320
to very cheaply scale out Cathy we can't

00:04:20,340 --> 00:04:25,160
have her spawn lots of copies of herself

00:04:22,320 --> 00:04:27,530
so we returned to technology to do this

00:04:25,160 --> 00:04:31,700
so we use hardware to help us with the

00:04:27,530 --> 00:04:33,140
collection of data but since since these

00:04:31,700 --> 00:04:35,540
are conversations with people we also

00:04:33,140 --> 00:04:38,240
need to have a good way of pulling in

00:04:35,540 --> 00:04:40,010
participants so we have a network that

00:04:38,240 --> 00:04:43,100
we've we've kind of layered on top of

00:04:40,010 --> 00:04:44,990
this the large is a large volunteer

00:04:43,100 --> 00:04:48,110
network and the idea with it is that it

00:04:44,990 --> 00:04:51,500
kind of sustains the other growth of the

00:04:48,110 --> 00:04:52,640
data collection our future interest is

00:04:51,500 --> 00:04:55,250
going to lie in the strength of his

00:04:52,640 --> 00:04:57,320
network and we think that it's it will

00:04:55,250 --> 00:04:59,240
be the basis for connecting communities

00:04:57,320 --> 00:05:00,080
and for crossing social boundaries and

00:04:59,240 --> 00:05:04,520
I'll give you an idea of how that

00:05:00,080 --> 00:05:07,330
happens later in the talk finally uh so

00:05:04,520 --> 00:05:10,070
we we like for LVN to have a real

00:05:07,330 --> 00:05:12,410
outcome in the world this is the reason

00:05:10,070 --> 00:05:16,220
why quarter coexist it's because because

00:05:12,410 --> 00:05:18,250
we can set up quarter COSO the as an as

00:05:16,220 --> 00:05:21,350
an institution it's metrics of success

00:05:18,250 --> 00:05:23,900
are not things like papers published

00:05:21,350 --> 00:05:29,540
which is what you know what the labs and

00:05:23,900 --> 00:05:31,340
metrics are so quartic Oh through

00:05:29,540 --> 00:05:34,760
through LVN then sets up this channel

00:05:31,340 --> 00:05:36,350
for for policy makers and journalists to

00:05:34,760 --> 00:05:38,390
get a better idea of what people are

00:05:36,350 --> 00:05:40,160
talking about in their communities so

00:05:38,390 --> 00:05:43,160
policymakers and journalists right now

00:05:40,160 --> 00:05:45,530
our target users so our very first

00:05:43,160 --> 00:05:48,320
experiment was in it was in Mott Haven

00:05:45,530 --> 00:05:51,590
in the Bronx in New York so this is this

00:05:48,320 --> 00:05:53,960
was like our alpha so Mott Haven is the

00:05:51,590 --> 00:05:57,410
poorest congressional district in the

00:05:53,960 --> 00:05:59,690
u.s. we put out flyers like this to get

00:05:57,410 --> 00:06:01,880
people to come in we also I believe we

00:05:59,690 --> 00:06:04,510
published this in the was it in the Mott

00:06:01,880 --> 00:06:07,100
Haven Herald so so the local newspaper

00:06:04,510 --> 00:06:09,590
and you know over the course of a couple

00:06:07,100 --> 00:06:11,150
of days we had just just a steady stream

00:06:09,590 --> 00:06:15,650
of people coming in and talking to us

00:06:11,150 --> 00:06:17,540
this is the the very first version of

00:06:15,650 --> 00:06:18,740
our thing or the the the alphabet we

00:06:17,540 --> 00:06:21,970
called it at the time the conversation

00:06:18,740 --> 00:06:24,440
box and it was designed for for

00:06:21,970 --> 00:06:27,010
conversations with just one person like

00:06:24,440 --> 00:06:29,180
more more like an interview style thing

00:06:27,010 --> 00:06:32,420
what this thing actually is it's just a

00:06:29,180 --> 00:06:34,490
wood box around a tablet it was kind of

00:06:32,420 --> 00:06:38,060
the fastest way for us to get to get

00:06:34,490 --> 00:06:38,720
something going you know being a bunch

00:06:38,060 --> 00:06:40,700
of engine

00:06:38,720 --> 00:06:42,350
at MIT we still of course had had some

00:06:40,700 --> 00:06:44,870
peasant issues and things things

00:06:42,350 --> 00:06:46,730
actually caught fire because we deployed

00:06:44,870 --> 00:06:49,280
this thing in the summer in New York and

00:06:46,730 --> 00:06:51,410
it was getting - I think it was I think

00:06:49,280 --> 00:06:53,380
was over a hundred degree days and there

00:06:51,410 --> 00:06:55,970
were no ventilation holes in the box so

00:06:53,380 --> 00:06:57,530
we we learned our lesson in future

00:06:55,970 --> 00:06:58,730
versions anytime that we like kind of

00:06:57,530 --> 00:06:59,960
smelled smoke or thought that something

00:06:58,730 --> 00:07:01,400
was on fire that would that was our

00:06:59,960 --> 00:07:05,180
first our first thought is that we need

00:07:01,400 --> 00:07:07,310
more more holes in the enclosure this is

00:07:05,180 --> 00:07:09,530
max Resnick at the time he was a student

00:07:07,310 --> 00:07:11,210
and he ran a lot of the conversation for

00:07:09,530 --> 00:07:16,610
us now he's a full-time employee of

00:07:11,210 --> 00:07:20,600
quartic oh so what kind of questions do

00:07:16,610 --> 00:07:22,700
we ask what do you like most about your

00:07:20,600 --> 00:07:26,150
community what do you like least about

00:07:22,700 --> 00:07:28,310
your community and in Mott Haven the

00:07:26,150 --> 00:07:31,550
responses to this question was actually

00:07:28,310 --> 00:07:34,250
a surprisingly unified people talked a

00:07:31,550 --> 00:07:36,980
lot about the diversity in the in the

00:07:34,250 --> 00:07:38,480
population there and that's what they

00:07:36,980 --> 00:07:39,680
loved about it what they're all

00:07:38,480 --> 00:07:43,760
concerned about actually was gang

00:07:39,680 --> 00:07:45,740
violence so as we were getting all this

00:07:43,760 --> 00:07:47,870
audio we were showing this around to

00:07:45,740 --> 00:07:50,570
various people to some potential donors

00:07:47,870 --> 00:07:52,490
and one one one donor said that he

00:07:50,570 --> 00:07:54,740
actually knew that the NYPD was planning

00:07:52,490 --> 00:07:56,450
on defunding the gang violence unit and

00:07:54,740 --> 00:07:58,250
so this this we kind of latched on to

00:07:56,450 --> 00:07:59,600
this as like a you know like a piece of

00:07:58,250 --> 00:08:01,370
evidence that it's possible for these

00:07:59,600 --> 00:08:04,610
conversations to - may be surfaced some

00:08:01,370 --> 00:08:06,080
views that weren't quite obvious but so

00:08:04,610 --> 00:08:10,850
these conversations were isolated and

00:08:06,080 --> 00:08:12,710
there were one-on-one so how we turn our

00:08:10,850 --> 00:08:14,330
attention to trying to figure out how we

00:08:12,710 --> 00:08:17,120
would bridge people and how we would try

00:08:14,330 --> 00:08:19,820
to get people talking to each other so

00:08:17,120 --> 00:08:21,320
this is a version one of our of our

00:08:19,820 --> 00:08:24,860
group system our group conversation

00:08:21,320 --> 00:08:27,020
system so these these conversations were

00:08:24,860 --> 00:08:28,760
there they're still facilitator directed

00:08:27,020 --> 00:08:30,590
so there's a person who's trained

00:08:28,760 --> 00:08:32,210
trained in how to use the equipment and

00:08:30,590 --> 00:08:33,469
the person asks the kind of passive

00:08:32,210 --> 00:08:35,810
style questions that I just showed in

00:08:33,469 --> 00:08:38,659
the last slide the conversations

00:08:35,810 --> 00:08:40,610
included include typically between four

00:08:38,659 --> 00:08:41,750
to six participants and they're quite

00:08:40,610 --> 00:08:46,820
long they're about an hour and a half

00:08:41,750 --> 00:08:48,949
long the the conversations are also the

00:08:46,820 --> 00:08:50,959
the the hearth has to work kind of

00:08:48,949 --> 00:08:53,540
in an offline way for you know for a

00:08:50,959 --> 00:08:54,679
variety of reasons so that that inform

00:08:53,540 --> 00:08:54,980
the design and I'll talk about that

00:08:54,679 --> 00:08:57,759
later

00:08:54,980 --> 00:09:00,170
and there's also a highlights system

00:08:57,759 --> 00:09:04,369
that we built into the interface and

00:09:00,170 --> 00:09:08,749
I'll talk about that later as well so so

00:09:04,369 --> 00:09:11,269
this is version one of the hearth one of

00:09:08,749 --> 00:09:13,910
the the principles in the design was

00:09:11,269 --> 00:09:16,609
that it had to be a very human object

00:09:13,910 --> 00:09:18,049
and we have found that that the quality

00:09:16,609 --> 00:09:19,759
of the conversation is different when

00:09:18,049 --> 00:09:21,139
you have people sitting around something

00:09:19,759 --> 00:09:23,359
like this like versus something that

00:09:21,139 --> 00:09:26,029
might be you know that looks more like

00:09:23,359 --> 00:09:29,720
an echo or like a Google home so it's

00:09:26,029 --> 00:09:32,149
it's a it's it's completely solid wood

00:09:29,720 --> 00:09:34,609
you know it's very it's it's it's nice

00:09:32,149 --> 00:09:36,439
and hefty there's a soft speaker girl on

00:09:34,609 --> 00:09:39,319
the top of it and then there's LED ring

00:09:36,439 --> 00:09:41,449
that serves as a as a state kind of

00:09:39,319 --> 00:09:43,009
state indicator for for the hearth when

00:09:41,449 --> 00:09:45,499
it's recording it's orange and people

00:09:43,009 --> 00:09:47,179
actually stare at it in the same way

00:09:45,499 --> 00:09:48,559
that when people are sitting around a

00:09:47,179 --> 00:09:51,980
fireplace they stare at the fire and

00:09:48,559 --> 00:09:57,169
talk it just kind of talked to the whole

00:09:51,980 --> 00:09:58,939
group in that way so Cathy Kramer she

00:09:57,169 --> 00:10:01,879
came on as an advisor to court ago and

00:09:58,939 --> 00:10:05,509
and and is doing her sabbatical in the

00:10:01,879 --> 00:10:08,389
lab group and we deployed our first set

00:10:05,509 --> 00:10:11,809
of hearts about a dozen of them in in to

00:10:08,389 --> 00:10:15,259
Madison Wisconsin in January why Madison

00:10:11,809 --> 00:10:17,720
well cuz of Cathy she has very strong

00:10:15,259 --> 00:10:20,389
connections to people to the community

00:10:17,720 --> 00:10:22,669
there in people there but also at the

00:10:20,389 --> 00:10:25,699
time they were in the process of

00:10:22,669 --> 00:10:27,679
electing a new mayor so we went into

00:10:25,699 --> 00:10:29,119
January I believe the February the the

00:10:27,679 --> 00:10:31,129
primaries were in February and in the

00:10:29,119 --> 00:10:34,699
actual election was in April so they

00:10:31,129 --> 00:10:36,410
were about I think there were something

00:10:34,699 --> 00:10:39,199
like eight candidates when we first went

00:10:36,410 --> 00:10:42,529
in and and half of them had access to

00:10:39,199 --> 00:10:44,419
the LVN data and then of the the two

00:10:42,529 --> 00:10:46,699
final candidates one had access to the

00:10:44,419 --> 00:10:50,899
LVN data and that was a person who who

00:10:46,699 --> 00:10:52,579
won we also gave access to journalists

00:10:50,899 --> 00:10:53,929
in the area so the cap times is a local

00:10:52,579 --> 00:10:56,929
newspaper there and so they wrote some

00:10:53,929 --> 00:10:58,309
some pieces using the LVN data we

00:10:56,929 --> 00:11:00,870
partnered closely with the Madison

00:10:58,309 --> 00:11:03,540
Public Library for distribution and

00:11:00,870 --> 00:11:04,890
keeping track of the hearth as a

00:11:03,540 --> 00:11:06,270
long-term strategy this is the thing

00:11:04,890 --> 00:11:08,070
that we've talked about a lot is trying

00:11:06,270 --> 00:11:09,810
to put these things into libraries

00:11:08,070 --> 00:11:11,910
there's approximately one library for

00:11:09,810 --> 00:11:14,370
every 10,000 people in the US so it's a

00:11:11,910 --> 00:11:17,040
it's a good kind of a kind of a vector

00:11:14,370 --> 00:11:20,520
for in for distribution and so these

00:11:17,040 --> 00:11:22,020
hearts are still running now at this

00:11:20,520 --> 00:11:28,230
point we've accumulated several hundred

00:11:22,020 --> 00:11:31,620
hours of speech okay so enough of the

00:11:28,230 --> 00:11:35,339
mushy human stuff I'll talk about the

00:11:31,620 --> 00:11:37,350
cold heart attack now so this is the one

00:11:35,339 --> 00:11:40,500
of the hearth when it's in this state we

00:11:37,350 --> 00:11:42,510
actually call this open heart surgery at

00:11:40,500 --> 00:11:45,810
the core of it is is this small

00:11:42,510 --> 00:11:47,730
raspberry pie and what you know which

00:11:45,810 --> 00:11:50,430
which which serves as as a place where

00:11:47,730 --> 00:11:52,680
we kind of centralize all the complexity

00:11:50,430 --> 00:11:54,150
in the system there's a speaker in the

00:11:52,680 --> 00:11:55,470
middle of it and the speaker is used for

00:11:54,150 --> 00:11:58,710
highlight playback and I'll talk a bit

00:11:55,470 --> 00:12:01,500
more more about that later there's a LED

00:11:58,710 --> 00:12:03,300
ring that I I mentioned before the heart

00:12:01,500 --> 00:12:06,270
itself doesn't have a whole lot of

00:12:03,300 --> 00:12:08,450
controls on it so we use a an iPhone

00:12:06,270 --> 00:12:11,010
that's paired with the hearth to

00:12:08,450 --> 00:12:15,779
actually start start and stop playback

00:12:11,010 --> 00:12:17,760
and stuff and then yeah yeah like again

00:12:15,779 --> 00:12:19,529
like like it has like the the entire

00:12:17,760 --> 00:12:21,959
feel of it is like much more substantial

00:12:19,529 --> 00:12:23,520
in human than you know then the consumer

00:12:21,959 --> 00:12:28,820
devices that you're probably used to

00:12:23,520 --> 00:12:32,880
seeing so version one was a solid wood

00:12:28,820 --> 00:12:35,250
we encountered some issues with solid

00:12:32,880 --> 00:12:37,920
wood solid wood namely it swells and we

00:12:35,250 --> 00:12:39,120
also didn't really plan properly the the

00:12:37,920 --> 00:12:42,510
amount of Tolerance that we might need

00:12:39,120 --> 00:12:44,700
in in the screw holes so within a day or

00:12:42,510 --> 00:12:46,410
two after assembling these hearts it

00:12:44,700 --> 00:12:49,380
became impossible to actually pull the

00:12:46,410 --> 00:12:51,150
pie out so our you know our yield here

00:12:49,380 --> 00:12:54,300
wasn't it wasn't great but we did get a

00:12:51,150 --> 00:12:57,570
good a good number of hearts out so this

00:12:54,300 --> 00:12:59,430
is version 1.1 it's there's a there's a

00:12:57,570 --> 00:13:01,380
kind of internal pie wood structure

00:12:59,430 --> 00:13:04,020
which is much more tolerant to you know

00:13:01,380 --> 00:13:05,390
to things like humidity and in the

00:13:04,020 --> 00:13:08,520
outside of the hearth is a wood veneer

00:13:05,390 --> 00:13:11,820
you actually can't tell like if you're

00:13:08,520 --> 00:13:13,440
just a just to look at it from you know

00:13:11,820 --> 00:13:14,290
from a couple feet away you can't tell

00:13:13,440 --> 00:13:17,019
you would have to pick

00:13:14,290 --> 00:13:18,730
of the 1.1 heart and actually examine

00:13:17,019 --> 00:13:20,410
like the kind of woods seen lines to be

00:13:18,730 --> 00:13:23,709
able to tell that it's not the same as

00:13:20,410 --> 00:13:28,180
the first the first set these are the

00:13:23,709 --> 00:13:31,000
custom PCBs that we had printed so this

00:13:28,180 --> 00:13:32,380
this deals with the power circuitry and

00:13:31,000 --> 00:13:36,209
the microphone array that's in the

00:13:32,380 --> 00:13:38,319
hearth and I'll go into that in a bit

00:13:36,209 --> 00:13:39,819
this is our assembly room in the

00:13:38,319 --> 00:13:43,360
Cambridge Innovation Center which is a

00:13:39,819 --> 00:13:46,000
co-working space in Boston the this

00:13:43,360 --> 00:13:47,620
office is actually it's I have the

00:13:46,000 --> 00:13:49,779
intersection of two hallways so people

00:13:47,620 --> 00:13:50,860
are always kind of peering in and kind

00:13:49,779 --> 00:13:53,949
of wondering what's going on because

00:13:50,860 --> 00:13:55,990
most of the of the you know the

00:13:53,949 --> 00:13:58,779
companies in this space are just people

00:13:55,990 --> 00:14:00,579
staring at monitors this is where we

00:13:58,779 --> 00:14:02,139
test all of our components and try out

00:14:00,579 --> 00:14:06,639
different kinds of hardware

00:14:02,139 --> 00:14:09,699
configurations this is our Canadian team

00:14:06,639 --> 00:14:12,130
member who's curling the hearth if you

00:14:09,699 --> 00:14:13,839
can't tell this is actually fake news we

00:14:12,130 --> 00:14:17,019
were we were actually concerned about

00:14:13,839 --> 00:14:20,139
air travel in security so we had the

00:14:17,019 --> 00:14:22,990
Canadians on the team go first we the

00:14:20,139 --> 00:14:24,339
the the hearts themself have a have a

00:14:22,990 --> 00:14:26,560
switch that completely cuts the power

00:14:24,339 --> 00:14:28,930
off just in case there is some some kind

00:14:26,560 --> 00:14:30,010
of a battery issue so yeah so as the

00:14:28,930 --> 00:14:34,029
safety mechanism we have that in place

00:14:30,010 --> 00:14:35,649
and if people at the if the TSA at the

00:14:34,029 --> 00:14:37,089
airport ever ever asked what the thing

00:14:35,649 --> 00:14:39,250
is we just say that it's a speaker and

00:14:37,089 --> 00:14:42,730
yeah like it seems it seems like that

00:14:39,250 --> 00:14:46,300
could be plausible okay so how do we

00:14:42,730 --> 00:14:48,430
control the thing so we we have this all

00:14:46,300 --> 00:14:49,949
each each heart is paired with with an

00:14:48,430 --> 00:14:53,949
iPhone and there's an app on it that

00:14:49,949 --> 00:14:57,279
that that controls all the activity on

00:14:53,949 --> 00:15:00,790
the hearth the the app updates are tied

00:14:57,279 --> 00:15:04,060
to deploys on the PI I'll explain how

00:15:00,790 --> 00:15:06,850
that's done in a bit and the the

00:15:04,060 --> 00:15:08,319
connectivity so we we tried a couple of

00:15:06,850 --> 00:15:10,660
things the first thing that we tried

00:15:08,319 --> 00:15:13,689
actually was for for the iPhone app to

00:15:10,660 --> 00:15:16,269
to talk to the harvest over Bluetooth we

00:15:13,689 --> 00:15:19,180
had some issues with this the the app

00:15:16,269 --> 00:15:20,380
itself some of the request payloads are

00:15:19,180 --> 00:15:22,689
quite big in the app itself is actually

00:15:20,380 --> 00:15:24,880
quite big and it it loads off the off

00:15:22,689 --> 00:15:26,050
the PI when it first starts off so we

00:15:24,880 --> 00:15:27,470
were seeing Layton sees that were kind

00:15:26,050 --> 00:15:29,840
of unacceptable for

00:15:27,470 --> 00:15:32,480
of our interactive use also just just a

00:15:29,840 --> 00:15:36,110
issue play and pause commands like you

00:15:32,480 --> 00:15:38,000
expect you expect it to you know the the

00:15:36,110 --> 00:15:39,290
heart to respond pretty quickly and we

00:15:38,000 --> 00:15:39,770
weren't able to get like a good latency

00:15:39,290 --> 00:15:42,830
from it

00:15:39,770 --> 00:15:47,000
so our next try actually was we we put a

00:15:42,830 --> 00:15:49,010
secondary Wi-Fi dongle it's it's plugged

00:15:47,000 --> 00:15:51,950
into the USB ports in the PI like inside

00:15:49,010 --> 00:15:54,680
of the heart so so the the the PI has to

00:15:51,950 --> 00:15:57,200
to Wi-Fi interfaces and we have a medium

00:15:54,680 --> 00:15:59,540
post where we go into all the details of

00:15:57,200 --> 00:16:01,010
the configuration of the you know the

00:15:59,540 --> 00:16:04,160
operating system its raspbian and you

00:16:01,010 --> 00:16:07,070
know how we pull this off so the PI has

00:16:04,160 --> 00:16:10,430
two to two by five interfaces one goes

00:16:07,070 --> 00:16:12,490
to the public Wi-Fi and the second one

00:16:10,430 --> 00:16:15,650
is is private and it broadcasts a unique

00:16:12,490 --> 00:16:18,140
SSID so in this case you know hearth met

00:16:15,650 --> 00:16:21,290
five corresponds to one hearth and so

00:16:18,140 --> 00:16:23,210
when you start up the the phone you've

00:16:21,290 --> 00:16:26,630
just you just pick the SSID that you

00:16:23,210 --> 00:16:28,220
want that phone to you know like which

00:16:26,630 --> 00:16:31,870
heart that you would like that phone to

00:16:28,220 --> 00:16:35,810
control and so that's how you pair it

00:16:31,870 --> 00:16:38,270
the phone makes API calls to a web

00:16:35,810 --> 00:16:41,420
server that's on the PI that's that's

00:16:38,270 --> 00:16:45,380
bound the PI dot local address the PI

00:16:41,420 --> 00:16:47,390
runs around the zeroconf deben so PI dot

00:16:45,380 --> 00:16:49,850
local resolves correctly when the phone

00:16:47,390 --> 00:16:53,290
connects and the PI also serves as a DNS

00:16:49,850 --> 00:16:57,140
server for for the phone and the phone

00:16:53,290 --> 00:17:01,190
talks talks over the private Wi-Fi to

00:16:57,140 --> 00:17:05,390
the web server so the phone can issue

00:17:01,190 --> 00:17:08,420
these these API calls to the PI to

00:17:05,390 --> 00:17:11,120
control the the playback and recording

00:17:08,420 --> 00:17:13,160
hardware the the phone app can also

00:17:11,120 --> 00:17:15,949
configure the PI's Wi-Fi so this is how

00:17:13,160 --> 00:17:17,420
we get get the entire thing onto the

00:17:15,949 --> 00:17:19,670
internet it can it can pass through a

00:17:17,420 --> 00:17:21,709
you know password and everything and

00:17:19,670 --> 00:17:23,990
then once the PI gets on the internet it

00:17:21,709 --> 00:17:26,120
sets of IP forwarding so the pie itself

00:17:23,990 --> 00:17:28,730
actually acts as a gateway for the phone

00:17:26,120 --> 00:17:29,390
and so that's how the phone can do can

00:17:28,730 --> 00:17:34,400
do i OSS

00:17:29,390 --> 00:17:36,380
updates as a side-effect this allows us

00:17:34,400 --> 00:17:37,880
to get through login pages so like if

00:17:36,380 --> 00:17:41,210
we're on a network that requires you to

00:17:37,880 --> 00:17:43,670
you know to accept a you know TOS

00:17:41,210 --> 00:17:45,440
since the the IB traffic is just passing

00:17:43,670 --> 00:17:47,630
through to the phone we can actually see

00:17:45,440 --> 00:17:51,350
it see the Terms of Service on the phone

00:17:47,630 --> 00:17:53,300
say yes there and then but since since

00:17:51,350 --> 00:17:58,010
since the packets are passing through

00:17:53,300 --> 00:18:00,740
the PI the MAC address that that the

00:17:58,010 --> 00:18:05,480
public router keys on is actually the

00:18:00,740 --> 00:18:07,370
PI's and not the phone's the hearth is

00:18:05,480 --> 00:18:09,110
stored inside of the madison public

00:18:07,370 --> 00:18:12,350
library system which serves as a home

00:18:09,110 --> 00:18:14,510
base so these are our codes on the

00:18:12,350 --> 00:18:16,130
Hart's so they're they're actually part

00:18:14,510 --> 00:18:18,080
of the circulation where they're checked

00:18:16,130 --> 00:18:20,810
in and checked out when they're checked

00:18:18,080 --> 00:18:24,830
in and in a library on the library's

00:18:20,810 --> 00:18:31,310
Wi-Fi then the PI will will sync stuff

00:18:24,830 --> 00:18:33,650
to and from our servers so offline

00:18:31,310 --> 00:18:35,600
operation so oftentimes the Hart's are

00:18:33,650 --> 00:18:38,780
are used in environments where there

00:18:35,600 --> 00:18:41,150
isn't easy access to power or to Wi-Fi

00:18:38,780 --> 00:18:43,100
so we had to build this into the design

00:18:41,150 --> 00:18:44,720
of the thing you know so for instance

00:18:43,100 --> 00:18:46,790
for instance here this is a short stack

00:18:44,720 --> 00:18:50,690
eatery which is supposedly the best

00:18:46,790 --> 00:18:52,610
pancake house in Madison you can notice

00:18:50,690 --> 00:18:55,670
that the drink on top of the hearth of

00:18:52,610 --> 00:18:57,380
we didn't plan for people to actually

00:18:55,670 --> 00:18:59,570
put put a any kind of locust on the

00:18:57,380 --> 00:19:04,130
hearth we're lucky we haven't had any of

00:18:59,570 --> 00:19:07,400
any accidents can't plan for everything

00:19:04,130 --> 00:19:11,030
since the pie has to run offline it

00:19:07,400 --> 00:19:13,550
needs a nice big battery the the PI

00:19:11,030 --> 00:19:15,200
consumes typically between 500 and 1,000

00:19:13,550 --> 00:19:19,880
milligrams of power and this this is a

00:19:15,200 --> 00:19:23,060
stupid big USB battery pack it's 26,000

00:19:19,880 --> 00:19:25,550
millions so we get about you know one to

00:19:23,060 --> 00:19:26,690
two days of continuous operation here we

00:19:25,550 --> 00:19:29,360
don't ever run the thing for that long

00:19:26,690 --> 00:19:31,460
so so there's a microcontroller that's

00:19:29,360 --> 00:19:33,770
in the PCB that provides power to the PI

00:19:31,460 --> 00:19:36,680
and it also listens for power button

00:19:33,770 --> 00:19:39,710
on/off events and the and the micro

00:19:36,680 --> 00:19:41,390
needs a tiny amount of power 4 to 4 to

00:19:39,710 --> 00:19:43,460
run one of the issues that we

00:19:41,390 --> 00:19:45,590
encountered actually is that if the if

00:19:43,460 --> 00:19:47,060
the USB battery I guess has a maybe a

00:19:45,590 --> 00:19:50,420
safety mechanism or something but if the

00:19:47,060 --> 00:19:52,130
USB battery doesn't detect a power draw

00:19:50,420 --> 00:19:54,020
above some threshold it just completely

00:19:52,130 --> 00:19:54,759
cuts power off and so the micro was

00:19:54,020 --> 00:19:57,699
underneath this

00:19:54,759 --> 00:20:00,009
shoulde so what we did was we set the

00:19:57,699 --> 00:20:03,399
microwave so there is there's a there's

00:20:00,009 --> 00:20:05,289
an an LED that's internal to to the

00:20:03,399 --> 00:20:06,849
hearth that the micro-cycles on and off

00:20:05,289 --> 00:20:10,269
and that consumes just enough power to

00:20:06,849 --> 00:20:11,799
keep the USB battery going so this when

00:20:10,269 --> 00:20:13,119
everything is operating correctly this

00:20:11,799 --> 00:20:15,789
actually extends our runway to about a

00:20:13,119 --> 00:20:18,549
month if the the PI's power down but the

00:20:15,789 --> 00:20:21,459
micros on our next version of the hearth

00:20:18,549 --> 00:20:26,979
will have much more well-thought-out

00:20:21,459 --> 00:20:30,309
power circuitry okay so how do we do

00:20:26,979 --> 00:20:34,509
software updates um so the the iPhone

00:20:30,309 --> 00:20:37,509
app itself is updated through the the

00:20:34,509 --> 00:20:41,229
App Store but we actually don't push

00:20:37,509 --> 00:20:44,259
updates to the app very often we use a

00:20:41,229 --> 00:20:45,909
framework called Apache Cordova which is

00:20:44,259 --> 00:20:47,589
it was formerly called PhoneGap so it's

00:20:45,909 --> 00:20:49,269
basically it's a it's a way for you to

00:20:47,589 --> 00:20:52,629
write a JavaScript application that has

00:20:49,269 --> 00:20:55,299
access to the native controls of the

00:20:52,629 --> 00:20:58,599
phone through a web browser so so

00:20:55,299 --> 00:21:01,089
essentially the app itself is just it's

00:20:58,599 --> 00:21:04,509
just a web browser that doesn't have any

00:21:01,089 --> 00:21:06,609
of you know the navigation controls on

00:21:04,509 --> 00:21:07,959
it and then it runs your your your

00:21:06,609 --> 00:21:09,459
JavaScript application as if it was a

00:21:07,959 --> 00:21:12,519
website you know just a normal website

00:21:09,459 --> 00:21:14,769
um so we host the JavaScript on the PI

00:21:12,519 --> 00:21:17,109
so when the app starts up it's

00:21:14,769 --> 00:21:20,229
configured to grab the current version

00:21:17,109 --> 00:21:24,069
of the control app from the PI and so in

00:21:20,229 --> 00:21:26,109
this way we can sync the updates for for

00:21:24,069 --> 00:21:28,089
the for the iPhone control device and

00:21:26,109 --> 00:21:32,529
the and the software that's on the PI

00:21:28,089 --> 00:21:34,539
like in you know all-in-one deploy we

00:21:32,529 --> 00:21:37,779
have a version database so we keep track

00:21:34,539 --> 00:21:42,669
of which versions of what software is

00:21:37,779 --> 00:21:45,690
running on each hearth and we push the

00:21:42,669 --> 00:21:48,879
updates outs through a through ansible

00:21:45,690 --> 00:21:51,489
now a typical ansible run assumes that

00:21:48,879 --> 00:21:54,009
your your hosts are actually online but

00:21:51,489 --> 00:21:57,999
in our case our our hosts are usually

00:21:54,009 --> 00:22:02,169
offline and so we came up with kind of

00:21:57,999 --> 00:22:03,789
an like an async update a system or when

00:22:02,169 --> 00:22:05,829
when the hearts come online they check

00:22:03,789 --> 00:22:07,130
to make sure that they have the the

00:22:05,829 --> 00:22:10,670
correct version

00:22:07,130 --> 00:22:13,700
the other source code if if there's a

00:22:10,670 --> 00:22:14,960
version difference then they'll download

00:22:13,700 --> 00:22:16,640
the new version of the source code which

00:22:14,960 --> 00:22:18,380
contains a bunch of the ansible files in

00:22:16,640 --> 00:22:19,490
it and then they'll run ansible locally

00:22:18,380 --> 00:22:21,050
so that's that's that's how we keep

00:22:19,490 --> 00:22:23,240
these things you know these things up to

00:22:21,050 --> 00:22:24,950
date and in sync we have a monitoring

00:22:23,240 --> 00:22:26,600
system so we know which version and

00:22:24,950 --> 00:22:27,860
every hearth is that when was the last

00:22:26,600 --> 00:22:29,980
time that it was applying and so on and

00:22:27,860 --> 00:22:34,370
so forth

00:22:29,980 --> 00:22:38,170
all right so the microarray so this

00:22:34,370 --> 00:22:41,720
thing has eight microphones in it the

00:22:38,170 --> 00:22:44,530
the diameters some are not probably not

00:22:41,720 --> 00:22:47,510
quite a foot and a half or so we use

00:22:44,530 --> 00:22:52,580
MEMS mics they're pretty good for this

00:22:47,510 --> 00:22:54,380
purpose and the the PI gets gets the

00:22:52,580 --> 00:22:58,220
audio data from the mics over the GPIO

00:22:54,380 --> 00:22:59,900
pins and since their mics we get eight

00:22:58,220 --> 00:23:02,270
channels of audio and eight channels of

00:22:59,900 --> 00:23:05,750
audio is actually quite a lot of audio

00:23:02,270 --> 00:23:09,410
to be sending the over GPIO so we had to

00:23:05,750 --> 00:23:11,570
invent a kind of interleaving scheme so

00:23:09,410 --> 00:23:14,210
we take these these these eight channels

00:23:11,570 --> 00:23:17,120
and you know what we do is we we bring

00:23:14,210 --> 00:23:19,460
them down from 32 bit samples to 18 bit

00:23:17,120 --> 00:23:24,500
samples and then we sample at a 16

00:23:19,460 --> 00:23:26,630
kilohertz rate after all that I thought

00:23:24,500 --> 00:23:29,830
that reduction we can then stuff that

00:23:26,630 --> 00:23:33,260
into two channels of 48 kilohertz 32 bit

00:23:29,830 --> 00:23:35,840
samples and so what the what the Pisces

00:23:33,260 --> 00:23:37,220
actually is to is to channel audio that

00:23:35,840 --> 00:23:38,450
is completely nonsensical they're

00:23:37,220 --> 00:23:41,780
actually a channels of data that are

00:23:38,450 --> 00:23:43,250
stuffed into two channels and and the

00:23:41,780 --> 00:23:46,400
way that we stuff those those those 8

00:23:43,250 --> 00:23:49,910
channels in is with this scheme so so

00:23:46,400 --> 00:23:51,590
here here here 8 8 words and so I'm not

00:23:49,910 --> 00:23:53,120
sure you can tell the first kind of row

00:23:51,590 --> 00:23:55,010
of colors this is dark red so that's

00:23:53,120 --> 00:23:57,770
that's the first sample from from the

00:23:55,010 --> 00:23:59,660
first channel so it's should be 18 bits

00:23:57,770 --> 00:24:01,700
and then there are 16 bits of channel

00:23:59,660 --> 00:24:05,420
markers so the channel markers all start

00:24:01,700 --> 00:24:07,280
with 0 1 0 and then the last 3 bits show

00:24:05,420 --> 00:24:09,110
which which channel number the previous

00:24:07,280 --> 00:24:11,800
sample was from so 0 0 0 is the first

00:24:09,110 --> 00:24:14,510
channel the next color is pink there are

00:24:11,800 --> 00:24:17,300
18 bits per sample their channel marker

00:24:14,510 --> 00:24:20,170
starting 0 1 0 and then 0 0 1 which says

00:24:17,300 --> 00:24:24,040
hey this is channel 2

00:24:20,170 --> 00:24:26,470
and so the the pie grabs all of this in

00:24:24,040 --> 00:24:28,360
various places downstream we will de

00:24:26,470 --> 00:24:30,460
intra leave this and convert these files

00:24:28,360 --> 00:24:32,260
we call these CA one files will convert

00:24:30,460 --> 00:24:34,870
them into into a channel wav files for

00:24:32,260 --> 00:24:38,110
processing and we were initially doing

00:24:34,870 --> 00:24:40,720
this in Python but Python kind of proved

00:24:38,110 --> 00:24:44,380
to be too slow so we we converted it it

00:24:40,720 --> 00:24:46,510
to we actually use numpy and so we we

00:24:44,380 --> 00:24:47,950
rewrote some of the core code to use

00:24:46,510 --> 00:24:52,000
vectorized math in which case it was

00:24:47,950 --> 00:24:54,940
fast enough but we we had some some

00:24:52,000 --> 00:24:57,190
issues with the PI kind of losing a few

00:24:54,940 --> 00:24:59,050
bits here and there um or like partial

00:24:57,190 --> 00:25:01,360
words which would kind of shift the

00:24:59,050 --> 00:25:02,620
entire bit stream over and you know and

00:25:01,360 --> 00:25:05,410
then the vectorized math wouldn't

00:25:02,620 --> 00:25:08,650
wouldn't work very well so in the end we

00:25:05,410 --> 00:25:11,140
just we just bit the bullet and wrote

00:25:08,650 --> 00:25:13,570
the entire thing in C so now it's much

00:25:11,140 --> 00:25:16,450
faster it's it's much more robust to

00:25:13,570 --> 00:25:18,670
failures this audio is then posted into

00:25:16,450 --> 00:25:20,740
our pipeline okay so here's our

00:25:18,670 --> 00:25:22,300
processing pipeline I'll just run

00:25:20,740 --> 00:25:23,560
through these steps and then and the

00:25:22,300 --> 00:25:27,040
knife slides on each one and then I go

00:25:23,560 --> 00:25:28,540
into details so so so we take these out

00:25:27,040 --> 00:25:30,910
to one files and we asynchronously

00:25:28,540 --> 00:25:32,680
upload while while they're docked at the

00:25:30,910 --> 00:25:35,080
library by async here I doesn't mean

00:25:32,680 --> 00:25:36,880
that that the audio gets sent not when

00:25:35,080 --> 00:25:39,550
the audio is finished recording boat

00:25:36,880 --> 00:25:42,970
when when the hearth goes back online so

00:25:39,550 --> 00:25:45,130
so we push this audio of on the library

00:25:42,970 --> 00:25:48,400
to our servers the first first thing

00:25:45,130 --> 00:25:52,120
that we do is we we normalize the audio

00:25:48,400 --> 00:25:54,610
levels and then we send it to to two

00:25:52,120 --> 00:25:57,250
different transcription services one is

00:25:54,610 --> 00:25:58,750
human base and one is the Google API we

00:25:57,250 --> 00:26:00,460
also have a third one that's that's the

00:25:58,750 --> 00:26:02,140
base off of our own stuff I'll talk a

00:26:00,460 --> 00:26:04,240
little bit about that but its own it's

00:26:02,140 --> 00:26:08,650
it's currently not really in production

00:26:04,240 --> 00:26:11,100
for for the hearth and then we when the

00:26:08,650 --> 00:26:14,110
audio comes back we do do some metrics

00:26:11,100 --> 00:26:16,830
calculations we calculate top terms top

00:26:14,110 --> 00:26:19,390
terms are kind of its kind of like a

00:26:16,830 --> 00:26:21,490
topic modeling thing that we we show in

00:26:19,390 --> 00:26:23,110
the interface and then we do a thing

00:26:21,490 --> 00:26:26,950
called topic indexing which would you

00:26:23,110 --> 00:26:29,110
know which I'll show some some some some

00:26:26,950 --> 00:26:31,000
examples of that so each one of these

00:26:29,110 --> 00:26:33,070
things is a distinct stuff step in the

00:26:31,000 --> 00:26:33,789
pipeline um we're not very cohesive

00:26:33,070 --> 00:26:35,440
about

00:26:33,789 --> 00:26:39,070
we string these things together so in

00:26:35,440 --> 00:26:41,850
some cases the the phase is triggered

00:26:39,070 --> 00:26:45,279
through you know through job Q through o

00:26:41,850 --> 00:26:47,590
we use rabbit internally we have like a

00:26:45,279 --> 00:26:50,700
like a slightly older queuing system

00:26:47,590 --> 00:26:55,690
that's based off of Google watermarks in

00:26:50,700 --> 00:26:59,799
from from no wheel I think and then we

00:26:55,690 --> 00:27:01,749
also in some cases use s3 triggers we

00:26:59,799 --> 00:27:04,929
like to make this all like one cohesive

00:27:01,749 --> 00:27:09,009
thing but you know maybe sometime in the

00:27:04,929 --> 00:27:10,570
future okay so this is raw raw audio on

00:27:09,009 --> 00:27:13,109
the left and then the range compressed

00:27:10,570 --> 00:27:16,389
audio on the right so you can see the

00:27:13,109 --> 00:27:18,039
the raw audio is actually quite low it's

00:27:16,389 --> 00:27:20,320
not that that we're not really picking

00:27:18,039 --> 00:27:21,940
up the audio well it's just it's it's

00:27:20,320 --> 00:27:25,149
actually that the these mics are quite

00:27:21,940 --> 00:27:27,519
sensitive so so they're actually they

00:27:25,149 --> 00:27:30,460
actually do a pretty good job right so

00:27:27,519 --> 00:27:31,960
we normalize it as it's a is range

00:27:30,460 --> 00:27:33,729
compressed mostly for human consumption

00:27:31,960 --> 00:27:36,639
when we send the audio to the

00:27:33,729 --> 00:27:37,779
transcription service the humans have to

00:27:36,639 --> 00:27:41,019
be able to hear it

00:27:37,779 --> 00:27:42,519
speech detect systems like Google's API

00:27:41,019 --> 00:27:48,279
will typically do their own kind of

00:27:42,519 --> 00:27:52,419
range compression so right so we use two

00:27:48,279 --> 00:27:55,539
transcription services one is Rev which

00:27:52,419 --> 00:27:56,889
is humans and the others Google API Rev

00:27:55,539 --> 00:27:58,749
is fairly accurate but it's very

00:27:56,889 --> 00:28:01,809
expensive it's about thirty times as

00:27:58,749 --> 00:28:03,070
expensive as a Google API Google is of

00:28:01,809 --> 00:28:06,340
course less accurate but it's it are

00:28:03,070 --> 00:28:08,049
cheap so what we do is we we run the

00:28:06,340 --> 00:28:09,309
translations through Google first and we

00:28:08,049 --> 00:28:11,549
show those transcripts and there's like

00:28:09,309 --> 00:28:13,899
a little thing that says hey you know

00:28:11,549 --> 00:28:16,659
come back here for for higher-quality

00:28:13,899 --> 00:28:18,729
transcripts Rev usually gets their

00:28:16,659 --> 00:28:22,330
version of the transcripts to us between

00:28:18,729 --> 00:28:23,979
a couple of hours and 24 hours one kind

00:28:22,330 --> 00:28:25,539
of an interesting technical problem here

00:28:23,979 --> 00:28:28,570
actually is that Rev gives us the

00:28:25,539 --> 00:28:30,729
transcripts with time and lineman's on

00:28:28,570 --> 00:28:32,649
speaker turns so like when a person

00:28:30,729 --> 00:28:34,659
starts speaking Rev says oh right now

00:28:32,649 --> 00:28:36,789
it's you know I think that says one

00:28:34,659 --> 00:28:39,700
minute and 14 seconds in or something

00:28:36,789 --> 00:28:42,639
but in our interface we allow the user

00:28:39,700 --> 00:28:44,210
to click on a word and have the audio

00:28:42,639 --> 00:28:46,610
jump to

00:28:44,210 --> 00:28:48,140
to where that word is regardless of if

00:28:46,610 --> 00:28:52,400
that word is the start of a speaker turn

00:28:48,140 --> 00:28:55,550
so we have a system that that does some

00:28:52,400 --> 00:28:58,670
sort of light speech to text on that and

00:28:55,550 --> 00:29:01,160
then we'll take the reve reve supplied

00:28:58,670 --> 00:29:05,300
alignments and and align those are those

00:29:01,160 --> 00:29:06,440
word boundaries to the transcripts so in

00:29:05,300 --> 00:29:08,720
addition to these two transcription

00:29:06,440 --> 00:29:10,340
services were also working on improving

00:29:08,720 --> 00:29:11,750
our own internal thing which is based

00:29:10,340 --> 00:29:15,590
off of an open source framework called

00:29:11,750 --> 00:29:17,210
call D and that's a set up that we that

00:29:15,590 --> 00:29:19,310
we built from from a different project

00:29:17,210 --> 00:29:21,380
where we're transcribing about 3,000

00:29:19,310 --> 00:29:22,340
hours of talk radio per day and we've

00:29:21,380 --> 00:29:25,070
been doing that for about a year and a

00:29:22,340 --> 00:29:26,660
half at that rate of transcription and

00:29:25,070 --> 00:29:31,190
it would be prohibitively costly to even

00:29:26,660 --> 00:29:33,320
use Google so after these conversations

00:29:31,190 --> 00:29:35,660
are transcribed we run some analysis to

00:29:33,320 --> 00:29:37,100
characterize the speech so so we so we

00:29:35,660 --> 00:29:40,880
look at things like like the speed of

00:29:37,100 --> 00:29:42,470
the dialogue worse per hour how how long

00:29:40,880 --> 00:29:45,290
are you know are each of the speaker

00:29:42,470 --> 00:29:48,530
turns mean inter speaking silence I

00:29:45,290 --> 00:29:51,350
guess is is how awkward the conversation

00:29:48,530 --> 00:29:53,420
is how awkwardly silent is turn-taking

00:29:51,350 --> 00:29:56,810
balances neat so this is an information

00:29:53,420 --> 00:29:59,240
theoretic measure of of like how spread

00:29:56,810 --> 00:30:01,930
out is is a speech in the converse in in

00:29:59,240 --> 00:30:04,010
in this conversation so if if one person

00:30:01,930 --> 00:30:06,230
speaks for 99 percent of the time and

00:30:04,010 --> 00:30:08,150
then everyone else kind of takes turns

00:30:06,230 --> 00:30:10,010
for the last one percent that value

00:30:08,150 --> 00:30:12,110
actually is very close to zero whereas

00:30:10,010 --> 00:30:14,090
if every single participant speaks for

00:30:12,110 --> 00:30:16,850
the same amount of time and then then

00:30:14,090 --> 00:30:18,560
that value is very close to one yes

00:30:16,850 --> 00:30:20,810
there's an interruption rate the matter

00:30:18,560 --> 00:30:23,600
of lexical diversity is a measure of how

00:30:20,810 --> 00:30:25,720
many unique words there are from a you

00:30:23,600 --> 00:30:29,740
know I take a sample of a thousand words

00:30:25,720 --> 00:30:31,700
and then mean word length a 4.38 words

00:30:29,740 --> 00:30:36,050
conversations love to have four-letter

00:30:31,700 --> 00:30:37,490
words so oh and then the the this very

00:30:36,050 --> 00:30:40,030
last metric is actually an important one

00:30:37,490 --> 00:30:42,890
so that's that's the speech-to-text

00:30:40,030 --> 00:30:45,350
transcribers word error rate and we do

00:30:42,890 --> 00:30:48,200
some some research on speech errors and

00:30:45,350 --> 00:30:50,120
bias in particular so we can we actually

00:30:48,200 --> 00:30:51,860
run run the audio through through

00:30:50,120 --> 00:30:54,170
general classification so we know for

00:30:51,860 --> 00:30:55,680
instance of what the with the over the

00:30:54,170 --> 00:30:57,990
ASR error rated

00:30:55,680 --> 00:30:59,640
on a gender breakdown as well as

00:30:57,990 --> 00:31:01,290
geography in the case of talk radio data

00:30:59,640 --> 00:31:03,870
and we we believe that geography is a

00:31:01,290 --> 00:31:06,090
good proxy for accents and so so there

00:31:03,870 --> 00:31:08,310
we have some papers coming out that that

00:31:06,090 --> 00:31:09,960
show that in you know that indeed a

00:31:08,310 --> 00:31:12,690
system like you know like the Google API

00:31:09,960 --> 00:31:17,490
does have have a bias against you know

00:31:12,690 --> 00:31:20,730
certain ethnic groups so we calculate

00:31:17,490 --> 00:31:22,650
top terms which roughly corresponds to

00:31:20,730 --> 00:31:23,940
the topics of speech during the

00:31:22,650 --> 00:31:25,650
conversation and then we link them into

00:31:23,940 --> 00:31:28,200
the parts of the conversation that are

00:31:25,650 --> 00:31:31,500
about those terms so these these terms

00:31:28,200 --> 00:31:33,840
these are tf-idf computed terms so

00:31:31,500 --> 00:31:36,120
basically unusually frequent terms but

00:31:33,840 --> 00:31:37,530
they're filtered down by the topic

00:31:36,120 --> 00:31:41,370
indexing phase which I'll talk about in

00:31:37,530 --> 00:31:44,280
the next slide this this interface is

00:31:41,370 --> 00:31:49,800
actually a primary method of discovery

00:31:44,280 --> 00:31:52,200
for users of the site topic indexing so

00:31:49,800 --> 00:31:53,610
this is a curated set of things that we

00:31:52,200 --> 00:31:55,890
care about that we like to track in

00:31:53,610 --> 00:31:59,130
these conversations and the way that

00:31:55,890 --> 00:32:02,190
this works is is for for any category

00:31:59,130 --> 00:32:04,110
here let's say childcare we curate a a

00:32:02,190 --> 00:32:06,210
set of very high precise terms for that

00:32:04,110 --> 00:32:08,100
topic so we say school has a lot to do

00:32:06,210 --> 00:32:10,500
with childcare education has a lot to do

00:32:08,100 --> 00:32:13,890
with childcare for instance then we

00:32:10,500 --> 00:32:16,710
build a words of ech a word embedding

00:32:13,890 --> 00:32:20,610
model on on the talk radio corpus and

00:32:16,710 --> 00:32:22,920
then we look for words in the embedding

00:32:20,610 --> 00:32:25,920
that are mutually close to all of those

00:32:22,920 --> 00:32:29,220
high precision terms so so this thing

00:32:25,920 --> 00:32:31,680
for instance it naturally discovered

00:32:29,220 --> 00:32:34,650
that the phrase creative writing for

00:32:31,680 --> 00:32:36,240
instance has a lot to do with with the

00:32:34,650 --> 00:32:40,560
high position terms that we picked for

00:32:36,240 --> 00:32:43,710
childcare so we set up these topics and

00:32:40,560 --> 00:32:46,110
then we can we can link from this into

00:32:43,710 --> 00:32:47,370
conversations and the portions of of

00:32:46,110 --> 00:32:51,960
those conversations that people are

00:32:47,370 --> 00:32:54,480
talking about these topics so this is a

00:32:51,960 --> 00:32:57,390
work in progress you know you talked

00:32:54,480 --> 00:32:58,520
about the other microphone array but and

00:32:57,390 --> 00:33:00,750
didn't actually say what we use it for

00:32:58,520 --> 00:33:02,910
the goal with the microphone array is to

00:33:00,750 --> 00:33:05,610
be able to diuresis speech so this is to

00:33:02,910 --> 00:33:09,120
separate out voices from from the audio

00:33:05,610 --> 00:33:10,710
and transcribe them separately so

00:33:09,120 --> 00:33:15,180
the Google API is really bad at doing

00:33:10,710 --> 00:33:17,640
this Rev is pretty good and we can trap

00:33:15,180 --> 00:33:22,560
his ground truth but even still humans

00:33:17,640 --> 00:33:24,060
get things wrong so it like particularly

00:33:22,560 --> 00:33:25,320
happens like if in a very long

00:33:24,060 --> 00:33:26,670
conversation sometimes you can tell that

00:33:25,320 --> 00:33:28,320
the transcribers like getting fatigued

00:33:26,670 --> 00:33:31,830
or something and just it just becomes

00:33:28,320 --> 00:33:33,390
more lazy like near the end of it miss

00:33:31,830 --> 00:33:37,800
at repeated speech is a big deal for us

00:33:33,390 --> 00:33:40,290
we allow participants to retract audio

00:33:37,800 --> 00:33:42,930
and most of the retractions come in two

00:33:40,290 --> 00:33:45,090
flavors one is take out my name which we

00:33:42,930 --> 00:33:47,430
take names out anyways and the second

00:33:45,090 --> 00:33:49,530
kind of attraction was hey that wasn't

00:33:47,430 --> 00:33:52,230
me so these conversations oftentimes

00:33:49,530 --> 00:33:54,660
have very like highly personal stories

00:33:52,230 --> 00:33:56,400
in them and if you you know someone is

00:33:54,660 --> 00:33:57,930
talking about like childhood trauma and

00:33:56,400 --> 00:34:01,140
you say oh this was John but it was in

00:33:57,930 --> 00:34:04,890
fact Jack that's a problem so so like

00:34:01,140 --> 00:34:07,110
even if the accuracies is 99% if we get

00:34:04,890 --> 00:34:10,920
it wrong 1% of the time in those cases

00:34:07,110 --> 00:34:13,470
and you know then that's not cool so so

00:34:10,920 --> 00:34:16,230
any kind of advantage that we can get

00:34:13,470 --> 00:34:18,150
two separated speakers will take so on

00:34:16,230 --> 00:34:21,540
on the left is a clustering of speakers

00:34:18,150 --> 00:34:23,280
using speaker and beddings a it's a

00:34:21,540 --> 00:34:26,520
method that's published by Google called

00:34:23,280 --> 00:34:28,290
D vectors and I believe we use an

00:34:26,520 --> 00:34:31,350
open-source package for this and that's

00:34:28,290 --> 00:34:34,530
based off the of the frequency spectrum

00:34:31,350 --> 00:34:36,480
and so you can see the labelings

00:34:34,530 --> 00:34:38,160
and the you know and a space in the

00:34:36,480 --> 00:34:42,360
visualization the projection is kind of

00:34:38,160 --> 00:34:45,930
its kind of muddled the second image is

00:34:42,360 --> 00:34:51,360
also stacking in information about time

00:34:45,930 --> 00:34:55,950
delays in the microphones right that we

00:34:51,360 --> 00:34:58,410
can see so the the the amount of time

00:34:55,950 --> 00:34:59,940
separation between two two microphones

00:34:58,410 --> 00:35:02,090
at opposite ends of the hearth is about

00:34:59,940 --> 00:35:05,820
it's about one one thousandth of a

00:35:02,090 --> 00:35:07,620
second I believe and so you can see

00:35:05,820 --> 00:35:11,280
these clusters are much more distinct so

00:35:07,620 --> 00:35:12,750
so this is the thing that we were

00:35:11,280 --> 00:35:14,790
working on this past summer and we'll be

00:35:12,750 --> 00:35:18,120
integrating it into the pipeline soon

00:35:14,790 --> 00:35:19,680
there's a paper coming out probably this

00:35:18,120 --> 00:35:21,870
academic year about these methods and

00:35:19,680 --> 00:35:24,410
and we're hoping to also publish a

00:35:21,870 --> 00:35:24,410
maintain source

00:35:25,040 --> 00:35:30,170
okay so the last thing of note are our

00:35:28,220 --> 00:35:31,940
highlights so the highlights in the

00:35:30,170 --> 00:35:35,540
system are curated by a special set of

00:35:31,940 --> 00:35:37,280
users and what happens is is that these

00:35:35,540 --> 00:35:39,950
these conversations are paused about

00:35:37,280 --> 00:35:42,170
halfway and the facilitator will play a

00:35:39,950 --> 00:35:44,930
highlight and then ask for a response

00:35:42,170 --> 00:35:46,550
from from that group and so we get a lot

00:35:44,930 --> 00:35:48,380
of like interesting responses like this

00:35:46,550 --> 00:35:52,400
this is a way to kind of force differing

00:35:48,380 --> 00:35:53,780
viewpoints like into the audio and the

00:35:52,400 --> 00:35:55,190
phone interface like has a way for you

00:35:53,780 --> 00:35:58,940
to pick which highlights get synched to

00:35:55,190 --> 00:36:01,190
which hearts since the hearts have to -

00:35:58,940 --> 00:36:03,110
to work offline what happens is when

00:36:01,190 --> 00:36:04,760
they do go online in the libraries

00:36:03,110 --> 00:36:06,010
they'll download all of the the

00:36:04,760 --> 00:36:09,410
highlights that they're supposed to have

00:36:06,010 --> 00:36:12,560
and then you know and and then the phone

00:36:09,410 --> 00:36:15,470
app can play them so we initially built

00:36:12,560 --> 00:36:19,400
this thing using kind of a duct tape our

00:36:15,470 --> 00:36:20,869
sync based system but then after a

00:36:19,400 --> 00:36:23,900
couple of weeks of operation we switched

00:36:20,869 --> 00:36:26,000
to a to a custom API which gave us a lot

00:36:23,900 --> 00:36:30,080
more control about you know unlike how

00:36:26,000 --> 00:36:32,510
the sync is done and then what happens

00:36:30,080 --> 00:36:33,920
with the highlights is so if you think

00:36:32,510 --> 00:36:36,200
about the conversations as nodes in a

00:36:33,920 --> 00:36:38,060
graph a highlight is an edge between two

00:36:36,200 --> 00:36:39,859
nodes and so this just forms a kind of

00:36:38,060 --> 00:36:43,040
network structure and so we're starting

00:36:39,859 --> 00:36:46,750
to look into how how these these

00:36:43,040 --> 00:36:50,990
highlights are cross pollinated the the

00:36:46,750 --> 00:36:52,420
decision to to to share a highlight in

00:36:50,990 --> 00:36:54,470
some conversation is made by the

00:36:52,420 --> 00:36:57,290
facilitator it's not it's not a thing

00:36:54,470 --> 00:36:59,090
that we curate and so with enough of a

00:36:57,290 --> 00:37:01,430
network and enough kind of people out

00:36:59,090 --> 00:37:02,740
there doing doing this you know this

00:37:01,430 --> 00:37:05,200
kind of work we should be able to

00:37:02,740 --> 00:37:07,070
discover sort of structure and the

00:37:05,200 --> 00:37:09,590
structures in the network that we didn't

00:37:07,070 --> 00:37:11,300
think you think were there but yeah so

00:37:09,590 --> 00:37:13,010
our future work will be focused on this

00:37:11,300 --> 00:37:15,290
cross-pollination and it's it's it's

00:37:13,010 --> 00:37:16,790
like the manifestation of like the kind

00:37:15,290 --> 00:37:17,960
of worldly outcome that we're trying to

00:37:16,790 --> 00:37:21,950
get with just actually bridge

00:37:17,960 --> 00:37:24,859
communities so where to next

00:37:21,950 --> 00:37:26,420
so can a squat wooden disk lead to the

00:37:24,859 --> 00:37:28,790
Hydra Civic journalism of smarter

00:37:26,420 --> 00:37:29,990
journalism it's kind of a a kind of a

00:37:28,790 --> 00:37:32,000
snarky title doesn't quite capture

00:37:29,990 --> 00:37:34,790
exactly what it is that we're trying to

00:37:32,000 --> 00:37:35,560
do because our our work is in centers

00:37:34,790 --> 00:37:37,240
specific

00:37:35,560 --> 00:37:39,550
they around the hearth but it's it's a

00:37:37,240 --> 00:37:40,840
the the the harder part of our work is

00:37:39,550 --> 00:37:43,870
actually human network that we're trying

00:37:40,840 --> 00:37:46,360
to build so all of the labs research is

00:37:43,870 --> 00:37:48,010
as interested in the way that humans and

00:37:46,360 --> 00:37:49,330
technology kind of back and forth can

00:37:48,010 --> 00:37:51,010
augment each other that's that's that's

00:37:49,330 --> 00:37:55,300
the that's the origin of the name social

00:37:51,010 --> 00:37:57,640
machines and so so so LVN is just one

00:37:55,300 --> 00:38:01,150
instance of that we're continuing to

00:37:57,640 --> 00:38:02,620
scale this out by 2020 hopefully we'll

00:38:01,150 --> 00:38:03,190
be nationwide just in time for the

00:38:02,620 --> 00:38:06,700
election

00:38:03,190 --> 00:38:08,770
um beyond 2020 I mean the the

00:38:06,700 --> 00:38:10,450
fantastical vision of this is that it

00:38:08,770 --> 00:38:12,250
actually creates a new kind of a civic

00:38:10,450 --> 00:38:14,890
institution and so maybe every year

00:38:12,250 --> 00:38:17,410
you'll decide to go and give one and a

00:38:14,890 --> 00:38:20,610
half hours of your life to the project

00:38:17,410 --> 00:38:22,780
and talk with people in your community

00:38:20,610 --> 00:38:25,600
to do this like we need a lot of people

00:38:22,780 --> 00:38:27,910
involved there are 60 active volunteers

00:38:25,600 --> 00:38:29,950
in Madison I think we had a waitlist of

00:38:27,910 --> 00:38:31,150
something like 50 or 60 people who

00:38:29,950 --> 00:38:32,200
wanted to be trained on the device but

00:38:31,150 --> 00:38:34,860
we didn't think that we could actually

00:38:32,200 --> 00:38:37,060
handle that kind of capacity so

00:38:34,860 --> 00:38:38,350
coordinating so that's just just one

00:38:37,060 --> 00:38:40,270
city if we want to be in hundreds or

00:38:38,350 --> 00:38:41,140
possibly thousands of cities like what

00:38:40,270 --> 00:38:44,620
we're looking at actually is the

00:38:41,140 --> 00:38:45,910
coordination of a very large human human

00:38:44,620 --> 00:38:48,280
network is like it's more of a human

00:38:45,910 --> 00:38:50,440
problem than a technical one we are

00:38:48,280 --> 00:38:53,140
currently in the Bronx so that's in the

00:38:50,440 --> 00:38:55,990
works our Wisconsin deployment is going

00:38:53,140 --> 00:38:58,450
out into the rural areas will be in

00:38:55,990 --> 00:39:01,150
Alabama I believe within a couple of

00:38:58,450 --> 00:39:05,470
months probably in Arizona in a few

00:39:01,150 --> 00:39:08,260
months as well so yeah that's that's a

00:39:05,470 --> 00:39:09,520
talk if you have any questions I'll take

00:39:08,260 --> 00:39:12,830
both technical and non-technical

00:39:09,520 --> 00:39:18,659
questions Thanks

00:39:12,830 --> 00:39:18,659
[Applause]

00:39:20,310 --> 00:39:29,620
some carriers who who thinks that this

00:39:23,350 --> 00:39:32,230
is a good idea all right all right it's

00:39:29,620 --> 00:39:36,070
a it's it's it's been an interesting

00:39:32,230 --> 00:39:39,130
human scale problem we get a lot of

00:39:36,070 --> 00:39:40,210
excitement over it but it's also hard to

00:39:39,130 --> 00:39:45,900
get people to come in to actually have

00:39:40,210 --> 00:39:45,900
conversations no yep

00:39:55,109 --> 00:40:01,589
yeah it's so it's not the question is is

00:40:00,329 --> 00:40:03,299
the motivation from this from the

00:40:01,589 --> 00:40:04,559
previous election it's definitely it's a

00:40:03,299 --> 00:40:06,989
thing that's that's like on the back of

00:40:04,559 --> 00:40:07,799
our minds but it's not really it's it's

00:40:06,989 --> 00:40:10,739
not a thing that we talk about

00:40:07,799 --> 00:40:13,979
constantly we'd like for it to be a more

00:40:10,739 --> 00:40:17,369
general purpose Civic tool that it's not

00:40:13,979 --> 00:40:18,809
specifically to like deal with politics

00:40:17,369 --> 00:40:20,999
but it's also to get different

00:40:18,809 --> 00:40:24,119
communities talking to each other and

00:40:20,999 --> 00:40:27,269
different communities like we'd like for

00:40:24,119 --> 00:40:30,239
them to be able to empathize and so we

00:40:27,269 --> 00:40:31,979
are you know our kind of hypothesis I

00:40:30,239 --> 00:40:33,269
think we call it theory our theory of

00:40:31,979 --> 00:40:35,219
social change right is that it's easier

00:40:33,269 --> 00:40:37,890
for that to happen in person than it is

00:40:35,219 --> 00:40:43,910
at scale like through Facebook or

00:40:37,890 --> 00:40:43,910
Twitter it's some questions here yep

00:40:51,860 --> 00:40:56,300
okay that's a good question okay so

00:40:54,710 --> 00:40:58,010
what's what's what's what's the

00:40:56,300 --> 00:41:00,110
relationship between the study of the

00:40:58,010 --> 00:41:01,970
talk radio data and Elvia and there

00:41:00,110 --> 00:41:04,340
isn't really a direct relationship aside

00:41:01,970 --> 00:41:06,700
from the fact that many of the same

00:41:04,340 --> 00:41:10,000
engineers and researchers are involved

00:41:06,700 --> 00:41:12,020
the talk radio thing was much more a

00:41:10,000 --> 00:41:14,480
started off much more like a purely

00:41:12,020 --> 00:41:17,060
academic kind of a pursuit right which

00:41:14,480 --> 00:41:20,960
is that there's as far as we know like

00:41:17,060 --> 00:41:23,540
nobody is storing or analyzing that

00:41:20,960 --> 00:41:25,190
amount of talk radio data like we think

00:41:23,540 --> 00:41:26,870
it's the largest corpus that has ever

00:41:25,190 --> 00:41:30,290
existed by probably several orders of

00:41:26,870 --> 00:41:31,700
magnitude so so as like sort of

00:41:30,290 --> 00:41:34,240
computational social scientists it's

00:41:31,700 --> 00:41:37,490
actually too great a set of data to have

00:41:34,240 --> 00:41:40,880
and quartic Oh part of the reason for

00:41:37,490 --> 00:41:43,040
Court ago when it was first built was

00:41:40,880 --> 00:41:45,110
was to really production eyes and run

00:41:43,040 --> 00:41:47,570
that talk radio system the production

00:41:45,110 --> 00:41:48,680
izing of a thing that you know the thing

00:41:47,570 --> 00:41:51,140
that grad students shouldn't really be

00:41:48,680 --> 00:41:53,120
spending their time on and then just

00:41:51,140 --> 00:41:54,710
naturally from there the sort of focus

00:41:53,120 --> 00:41:57,350
on the transcription and the speech work

00:41:54,710 --> 00:42:04,720
kind of made its way into into our

00:41:57,350 --> 00:42:12,080
designs for LVN how do we recognize the

00:42:04,720 --> 00:42:14,300
the conversational bias oh well so we

00:42:12,080 --> 00:42:18,340
don't really calculate a measure of bias

00:42:14,300 --> 00:42:20,510
we have that that measure of sort of

00:42:18,340 --> 00:42:21,620
complexity to language but this is you

00:42:20,510 --> 00:42:23,090
know this is more like a matter of just

00:42:21,620 --> 00:42:25,310
just just like like how many different

00:42:23,090 --> 00:42:27,070
topics are people talking about but we

00:42:25,310 --> 00:42:33,530
currently don't really do anything about

00:42:27,070 --> 00:42:34,910
yeah about bias yeah there is so in in

00:42:33,530 --> 00:42:37,310
some instances with with

00:42:34,910 --> 00:42:39,560
cross-pollination we found that

00:42:37,310 --> 00:42:40,610
different conversations different roofs

00:42:39,560 --> 00:42:43,160
of people have very different

00:42:40,610 --> 00:42:45,080
perspectives on the same thing so we

00:42:43,160 --> 00:42:46,730
have the beginnings right so like we

00:42:45,080 --> 00:42:48,380
know oh hey this highlight from this

00:42:46,730 --> 00:42:50,870
conversation was pollinated into this

00:42:48,380 --> 00:42:52,520
conversation so we have that link and so

00:42:50,870 --> 00:42:55,250
we do have the beginnings of a way to

00:42:52,520 --> 00:42:57,770
kind of I I wouldn't say like pick out

00:42:55,250 --> 00:42:59,360
bias but more like you know like

00:42:57,770 --> 00:43:02,150
accentuate different perspectives on the

00:42:59,360 --> 00:43:04,270
same thing but we're still working on

00:43:02,150 --> 00:43:04,270
that

00:43:19,870 --> 00:43:24,160
No yeah so the question is do we have

00:43:22,220 --> 00:43:28,580
any kind of noise reduction mechanism

00:43:24,160 --> 00:43:32,890
the range compression does reasonably

00:43:28,580 --> 00:43:35,090
well to sort of D accentuate white noise

00:43:32,890 --> 00:43:36,320
but if there are a lot of people talking

00:43:35,090 --> 00:43:40,490
in the background then that is an issue

00:43:36,320 --> 00:43:42,890
and we have had problems where people

00:43:40,490 --> 00:43:44,300
bring the hearts into you know into like

00:43:42,890 --> 00:43:45,650
a restaurant or a bar we actually had

00:43:44,300 --> 00:43:47,390
conversations occur in a bar and there

00:43:45,650 --> 00:43:49,940
it's like even the human transcribers

00:43:47,390 --> 00:43:51,440
have have problems um so I don't know if

00:43:49,940 --> 00:43:55,340
this is a thing that will actually be

00:43:51,440 --> 00:43:57,470
able to really properly solve but you

00:43:55,340 --> 00:43:58,790
know we do put guidelines in like we ask

00:43:57,470 --> 00:44:01,160
that people don't stand up and walk

00:43:58,790 --> 00:44:02,810
around for instance which makes the the

00:44:01,160 --> 00:44:05,000
sort of clustering in the location of

00:44:02,810 --> 00:44:06,710
like using the microphone array to write

00:44:05,000 --> 00:44:07,790
to locate one voice if it's if we can

00:44:06,710 --> 00:44:08,990
make the assumption that it's not moving

00:44:07,790 --> 00:44:12,410
around that actually makes things much

00:44:08,990 --> 00:44:14,030
easier but yeah we still there's a one

00:44:12,410 --> 00:44:16,730
conversation that I I frequently work

00:44:14,030 --> 00:44:18,320
with that there's a dog in the

00:44:16,730 --> 00:44:20,390
conversation and it starts barking and

00:44:18,320 --> 00:44:22,850
it just like I mean it does like crazy

00:44:20,390 --> 00:44:24,230
things to the audio and then like it

00:44:22,850 --> 00:44:25,940
barks a couple of times while people are

00:44:24,230 --> 00:44:28,550
talking and then someone like stands up

00:44:25,940 --> 00:44:30,320
walks the dog out of the room and like

00:44:28,550 --> 00:44:32,570
slams the door shut so it's like all

00:44:30,320 --> 00:44:34,850
sorts of like stuff stuff that um you

00:44:32,570 --> 00:44:38,260
know probably uh not typical inputs into

00:44:34,850 --> 00:44:38,260
you know into speech systems

00:44:49,190 --> 00:44:53,840
okay so that's a that's a great question

00:44:51,320 --> 00:44:56,150
okay so the question is you know as this

00:44:53,840 --> 00:44:58,520
expands nationally can we use this to

00:44:56,150 --> 00:45:02,960
map the progression of possibly fake

00:44:58,520 --> 00:45:04,640
news well so the fake the fake part of

00:45:02,960 --> 00:45:07,250
it I don't know i i'm you know i'm i'm

00:45:04,640 --> 00:45:08,810
honestly not sure if fakeness is you

00:45:07,250 --> 00:45:11,020
know really a thing that as a

00:45:08,810 --> 00:45:13,400
computational social scientist we should

00:45:11,020 --> 00:45:16,160
we can like really effectively tackle

00:45:13,400 --> 00:45:17,390
the mapping of the the movement of ideas

00:45:16,160 --> 00:45:19,160
is definitely saying that we've talked

00:45:17,390 --> 00:45:21,290
about in the lab and there's another

00:45:19,160 --> 00:45:22,820
form of this actually one of the the

00:45:21,290 --> 00:45:26,510
outputs of the talk radio research

00:45:22,820 --> 00:45:29,420
actually is how we can we can map the

00:45:26,510 --> 00:45:33,620
transmission of ideas on twitter to talk

00:45:29,420 --> 00:45:36,080
radio and back that is not very precise

00:45:33,620 --> 00:45:39,320
because we don't have a good good

00:45:36,080 --> 00:45:41,960
measure for instance of well okay so

00:45:39,320 --> 00:45:43,400
with tweets of small percentage of

00:45:41,960 --> 00:45:44,840
tweets are actually geo located so we

00:45:43,400 --> 00:45:46,490
actually don't know where a lot of

00:45:44,840 --> 00:45:47,840
tweets are we can infer from social

00:45:46,490 --> 00:45:49,340
graphs what the location of some one

00:45:47,840 --> 00:45:52,310
might be but you know that's that's not

00:45:49,340 --> 00:45:53,240
you know it's not always correct the

00:45:52,310 --> 00:45:56,420
second thing is that we have the

00:45:53,240 --> 00:45:58,430
broadcast ranges of the radio stations

00:45:56,420 --> 00:46:00,350
we don't really know of like someone

00:45:58,430 --> 00:46:02,540
who's actually has a as the radio turned

00:46:00,350 --> 00:46:04,280
on and it's harder or not so it's it's

00:46:02,540 --> 00:46:05,960
it's a very it's a very imprecise thing

00:46:04,280 --> 00:46:07,700
but that was that was the idea what the

00:46:05,960 --> 00:46:10,700
research was to be able to track the

00:46:07,700 --> 00:46:13,070
progression of some particular idea you

00:46:10,700 --> 00:46:15,140
know through the network and that came

00:46:13,070 --> 00:46:17,030
out of previous research in the lab that

00:46:15,140 --> 00:46:19,220
actually looked at fake news you know

00:46:17,030 --> 00:46:24,470
news i was debunked and how it spread

00:46:19,220 --> 00:46:28,270
purely on twitter no so i think i'm at a

00:46:24,470 --> 00:46:28,270

YouTube URL: https://www.youtube.com/watch?v=7szjhiJs1kg


