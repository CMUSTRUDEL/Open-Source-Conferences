Title: Adopting Service Mesh Patterns for Cloud Native Microservices in the Telecommunications Industry
Publication date: 2020-10-29
Playlist: Open Source Summit & Embedded Linux Conference Europe 2020
Description: 
	Lightning Talk: Adopting Service Mesh Patterns for Cloud Native Microservices in the Telecommunications Industry - Sudeep Batra, Ericsson
Captions: 
	00:00:06,960 --> 00:00:11,120
hello everyone

00:00:08,480 --> 00:00:11,599
welcome to the lightning talk on service

00:00:11,120 --> 00:00:14,960
mesh

00:00:11,599 --> 00:00:18,080
patterns from a telecom perspective

00:00:14,960 --> 00:00:20,320
my name is sudeep bhatra and i work as a

00:00:18,080 --> 00:00:22,480
cloud architect for ericsson

00:00:20,320 --> 00:00:23,439
the company that builds telecom networks

00:00:22,480 --> 00:00:27,119
for the telco

00:00:23,439 --> 00:00:27,119
operators across the globe

00:00:28,240 --> 00:00:32,800
okay so let's get started we all love

00:00:31,519 --> 00:00:36,079
our phone

00:00:32,800 --> 00:00:39,760
however a lot goes behind the scene

00:00:36,079 --> 00:00:43,280
that enables us to talk text browse

00:00:39,760 --> 00:00:44,559
and be connected for work or to our

00:00:43,280 --> 00:00:47,120
loved ones

00:00:44,559 --> 00:00:47,920
so let's take a look at a high level

00:00:47,120 --> 00:00:52,960
view

00:00:47,920 --> 00:00:52,960
of the basic telecommunication network

00:00:53,199 --> 00:00:58,160
in this diagram you can see the user

00:00:56,840 --> 00:01:00,960
equipment

00:00:58,160 --> 00:01:01,520
which is our favorite handset connecting

00:01:00,960 --> 00:01:06,000
to the

00:01:01,520 --> 00:01:08,880
access network over the air interface

00:01:06,000 --> 00:01:10,640
then our data which is basically the

00:01:08,880 --> 00:01:13,680
voice video text

00:01:10,640 --> 00:01:16,720
chat or the browsing data gets

00:01:13,680 --> 00:01:20,320
carried over the transport network

00:01:16,720 --> 00:01:23,759
or the backhaul to the core network

00:01:20,320 --> 00:01:24,799
much of the action happens here in terms

00:01:23,759 --> 00:01:28,000
of connecting us

00:01:24,799 --> 00:01:28,960
to another person or device and also

00:01:28,000 --> 00:01:32,320
connecting us

00:01:28,960 --> 00:01:34,799
to the internet cloud native

00:01:32,320 --> 00:01:37,759
transformation is happening now

00:01:34,799 --> 00:01:40,880
across the telecommunication network so

00:01:37,759 --> 00:01:43,680
let's see how

00:01:40,880 --> 00:01:44,560
initially the telecommunication network

00:01:43,680 --> 00:01:48,000
was built

00:01:44,560 --> 00:01:50,560
using physical network functions or pnf

00:01:48,000 --> 00:01:53,280
which were deployed manually on

00:01:50,560 --> 00:01:56,479
proprietary hardware and software

00:01:53,280 --> 00:01:59,600
in most of the cases then we got

00:01:56,479 --> 00:02:02,240
open stack and the pnfs

00:01:59,600 --> 00:02:04,240
were transformed into virtual network

00:02:02,240 --> 00:02:06,560
functions or vnf

00:02:04,240 --> 00:02:07,680
hosted on the infrastructure as a

00:02:06,560 --> 00:02:12,080
solution

00:02:07,680 --> 00:02:15,120
platform powered by openstack

00:02:12,080 --> 00:02:18,000
now the vnfs are being transformed to

00:02:15,120 --> 00:02:18,800
cloud native functions taking advantage

00:02:18,000 --> 00:02:21,360
of

00:02:18,800 --> 00:02:24,319
kubernetes and cloud native technologies

00:02:21,360 --> 00:02:27,440
like service mesh

00:02:24,319 --> 00:02:29,920
also the orchestration layer

00:02:27,440 --> 00:02:32,000
is transforming from the ability to

00:02:29,920 --> 00:02:35,280
orchestrate the virtual machines

00:02:32,000 --> 00:02:38,640
to orchestrating the containers as

00:02:35,280 --> 00:02:41,920
well in the next slide we will see

00:02:38,640 --> 00:02:45,519
how the cnfs are used in a typical

00:02:41,920 --> 00:02:45,519
5g core network

00:02:47,519 --> 00:02:53,760
so this is a typical solution of

00:02:50,560 --> 00:02:54,239
ericsson 5g core network which is built

00:02:53,760 --> 00:02:57,360
upon

00:02:54,239 --> 00:02:58,159
many cloud native functions in this

00:02:57,360 --> 00:03:01,200
diagram

00:02:58,159 --> 00:03:04,080
we can see the 5g core

00:03:01,200 --> 00:03:05,519
is broken into the data layer the

00:03:04,080 --> 00:03:09,440
control plane

00:03:05,519 --> 00:03:13,040
and the user plane the data layer

00:03:09,440 --> 00:03:16,239
stores the subscriber data

00:03:13,040 --> 00:03:20,400
the control plane in the middle

00:03:16,239 --> 00:03:23,440
that manages the traffic and signaling

00:03:20,400 --> 00:03:24,720
it includes functions like dns load

00:03:23,440 --> 00:03:29,120
balancing

00:03:24,720 --> 00:03:32,400
network slice selection functions etc

00:03:29,120 --> 00:03:35,680
the user plane is where the user traffic

00:03:32,400 --> 00:03:38,879
flows each of these blue boxes

00:03:35,680 --> 00:03:41,920
could be considered as a cnf

00:03:38,879 --> 00:03:44,400
fulfilling a specific function

00:03:41,920 --> 00:03:46,720
in the 5g core network there are a

00:03:44,400 --> 00:03:50,000
couple of ways the telco operators

00:03:46,720 --> 00:03:50,480
ask for the cnf deployment depending on

00:03:50,000 --> 00:03:54,879
their

00:03:50,480 --> 00:03:57,360
needs the simplest case could be all cnf

00:03:54,879 --> 00:03:59,120
from a single vendor on a single

00:03:57,360 --> 00:04:02,319
kubernetes cluster

00:03:59,120 --> 00:04:03,439
or it could be all cnfs from different

00:04:02,319 --> 00:04:05,680
vendors

00:04:03,439 --> 00:04:06,720
it could also be cnf from different

00:04:05,680 --> 00:04:10,080
vendor

00:04:06,720 --> 00:04:12,720
on separate dedicated kubernetes cluster

00:04:10,080 --> 00:04:14,400
so in the next slide we will see how the

00:04:12,720 --> 00:04:18,400
service mesh comes

00:04:14,400 --> 00:04:21,040
into the picture operators want to

00:04:18,400 --> 00:04:24,720
leverage the benefits of service mesh

00:04:21,040 --> 00:04:27,120
like istio for security observability

00:04:24,720 --> 00:04:28,000
traffic management and policies when

00:04:27,120 --> 00:04:30,479
they deploy their

00:04:28,000 --> 00:04:31,360
cnfs and they want service mesh to be

00:04:30,479 --> 00:04:33,919
deployed

00:04:31,360 --> 00:04:35,840
according to their use cases so let's

00:04:33,919 --> 00:04:39,040
start with the four patterns

00:04:35,840 --> 00:04:39,600
which can be adopted according to the

00:04:39,040 --> 00:04:43,520
unique

00:04:39,600 --> 00:04:46,080
requirement of an operator

00:04:43,520 --> 00:04:48,160
so the first pattern in this we have a

00:04:46,080 --> 00:04:51,280
single kubernetes cluster

00:04:48,160 --> 00:04:54,160
all cnf shown as service a in workspace

00:04:51,280 --> 00:04:56,000
1 namespace and service b in the

00:04:54,160 --> 00:04:59,280
workspace 2 namespace

00:04:56,000 --> 00:05:01,280
are from a single vendor essentially we

00:04:59,280 --> 00:05:05,840
have a single service mesh

00:05:01,280 --> 00:05:08,400
to manage the cnf in its own namespaces

00:05:05,840 --> 00:05:10,080
please assume that cnf is made up of

00:05:08,400 --> 00:05:12,960
multiple service or kubernetes

00:05:10,080 --> 00:05:14,080
powered and objects but for simplicity

00:05:12,960 --> 00:05:17,360
we only see

00:05:14,080 --> 00:05:19,039
replica of two services then we have a

00:05:17,360 --> 00:05:24,320
single ingress and aggress

00:05:19,039 --> 00:05:27,759
gateway for both workload

00:05:24,320 --> 00:05:29,039
now in the next pattern we have a single

00:05:27,759 --> 00:05:32,320
kubernetes cluster

00:05:29,039 --> 00:05:33,919
and cnf from different vendors but we

00:05:32,320 --> 00:05:36,960
have a single service mesh

00:05:33,919 --> 00:05:38,880
to manage each cnf in its own separate

00:05:36,960 --> 00:05:40,800
namespace

00:05:38,880 --> 00:05:42,960
also we have separate ingress and

00:05:40,800 --> 00:05:45,039
address gateway for each vendor

00:05:42,960 --> 00:05:46,320
providing separate data plane traffic

00:05:45,039 --> 00:05:50,160
flow within the

00:05:46,320 --> 00:05:50,160
same kubernetes cluster

00:05:51,039 --> 00:05:54,960
in this pattern we have again a single

00:05:53,120 --> 00:05:58,160
kubernetes cluster

00:05:54,960 --> 00:05:58,560
but cnfs from different vendor and we

00:05:58,160 --> 00:06:01,360
have

00:05:58,560 --> 00:06:02,319
dedicated service mesh for each vendor

00:06:01,360 --> 00:06:04,400
and its cnf

00:06:02,319 --> 00:06:06,080
in its own namespace within the single

00:06:04,400 --> 00:06:08,240
kubernetes cluster

00:06:06,080 --> 00:06:10,160
also in this case we can see that the

00:06:08,240 --> 00:06:14,720
ingress and aggress gateway

00:06:10,160 --> 00:06:17,600
are separate for each of the cnf

00:06:14,720 --> 00:06:19,759
finally we have multiple kubernetes

00:06:17,600 --> 00:06:22,880
cluster from multiple vendors

00:06:19,759 --> 00:06:25,840
each vendor deploys its cnf in its

00:06:22,880 --> 00:06:27,440
dedicated kubernetes cluster and we have

00:06:25,840 --> 00:06:30,400
a dedicated service mesh

00:06:27,440 --> 00:06:32,319
for each vendor and also we have

00:06:30,400 --> 00:06:34,000
separate ingress gateway and aggress

00:06:32,319 --> 00:06:36,240
gateway for each vendor

00:06:34,000 --> 00:06:37,120
so we have separate control traffic and

00:06:36,240 --> 00:06:41,039
data traffic

00:06:37,120 --> 00:06:43,440
for each cnn

00:06:41,039 --> 00:06:45,360
that's all i have in this session thank

00:06:43,440 --> 00:06:49,840
you for listening

00:06:45,360 --> 00:06:49,840

YouTube URL: https://www.youtube.com/watch?v=okhN1gaErJI


