Title: Challenges of Using V4L2 to Capture and Process Video Sensor Images - Eugen Hristev
Publication date: 2020-10-29
Playlist: Open Source Summit & Embedded Linux Conference Europe 2020
Description: 
	Challenges of Using V4L2 to Capture and Process Video Sensor Images - Eugen Hristev, Microchip Technology, Inc.
Captions: 
	00:00:06,480 --> 00:00:10,480
hello

00:00:07,440 --> 00:00:11,679
and welcome to this session named

00:00:10,480 --> 00:00:14,320
challenges of using

00:00:11,679 --> 00:00:17,520
v4 l2 that's video for linux 2 to

00:00:14,320 --> 00:00:18,880
capture and process video sensor images

00:00:17,520 --> 00:00:20,960
thank you for attending this

00:00:18,880 --> 00:00:25,039
presentation

00:00:20,960 --> 00:00:28,080
i will start by first introducing myself

00:00:25,039 --> 00:00:30,720
my name is eugene christev and i'm an

00:00:28,080 --> 00:00:34,399
embedded linux engineer at microchip

00:00:30,720 --> 00:00:36,640
and i'm part of the mpu32 linux team

00:00:34,399 --> 00:00:38,320
we are a division inside microchip my

00:00:36,640 --> 00:00:40,719
main area of

00:00:38,320 --> 00:00:41,680
developing and focus and interest is

00:00:40,719 --> 00:00:45,120
regarding

00:00:41,680 --> 00:00:47,039
stage 2 and state reboot loaders and

00:00:45,120 --> 00:00:48,719
i'm also developing linux kernel device

00:00:47,039 --> 00:00:50,000
drivers

00:00:48,719 --> 00:00:52,800
the main point regarding the

00:00:50,000 --> 00:00:54,879
presentation the most interesting fact

00:00:52,800 --> 00:00:56,000
is that i am also maintaining developing

00:00:54,879 --> 00:00:58,480
the

00:00:56,000 --> 00:01:00,079
v4l2 drivers for microchip video for

00:00:58,480 --> 00:01:01,600
linux two drivers which are the

00:01:00,079 --> 00:01:04,239
metal sensor controller and the new

00:01:01,600 --> 00:01:07,520
sensor interface

00:01:04,239 --> 00:01:09,360
so that's about myself let's uh have a

00:01:07,520 --> 00:01:11,680
small agenda about what i will be

00:01:09,360 --> 00:01:14,799
presenting today

00:01:11,680 --> 00:01:17,040
and the summary states the following i

00:01:14,799 --> 00:01:18,880
will start by explaining how digital

00:01:17,040 --> 00:01:22,159
sensor words work

00:01:18,880 --> 00:01:23,920
how they uh working how they send images

00:01:22,159 --> 00:01:25,600
and then i will try to continue with

00:01:23,920 --> 00:01:28,640
what happens with the data

00:01:25,600 --> 00:01:31,119
once it gets into our pipeline

00:01:28,640 --> 00:01:33,040
to hardware into software and how this

00:01:31,119 --> 00:01:36,240
data is turned into

00:01:33,040 --> 00:01:37,360
real photos that you can see on your

00:01:36,240 --> 00:01:39,600
screen in the end

00:01:37,360 --> 00:01:40,560
of the pipeline then i will try to

00:01:39,600 --> 00:01:42,720
present

00:01:40,560 --> 00:01:44,720
what can happen during this process what

00:01:42,720 --> 00:01:47,600
issues can occur what challenges we have

00:01:44,720 --> 00:01:48,720
to see to obtain a better photo a better

00:01:47,600 --> 00:01:50,399
quality of the photo

00:01:48,720 --> 00:01:52,320
and how we can cope with these

00:01:50,399 --> 00:01:55,119
situations how we can

00:01:52,320 --> 00:01:57,600
alter the pipeline functionality and how

00:01:55,119 --> 00:01:58,320
v4l2 widowfulness to subsystem can help

00:01:57,600 --> 00:02:00,560
us

00:01:58,320 --> 00:02:01,759
by finding the cause of the issues and

00:02:00,560 --> 00:02:03,759
to uh

00:02:01,759 --> 00:02:05,119
alter the the pipeline the software in

00:02:03,759 --> 00:02:06,799
the heart pipeline to get a better

00:02:05,119 --> 00:02:07,040
picture quality and to solve the issues

00:02:06,799 --> 00:02:10,479
that

00:02:07,040 --> 00:02:10,479
we'll be presenting today

00:02:10,879 --> 00:02:15,040
at the start i will show you in the

00:02:13,280 --> 00:02:17,280
system diagram of the system that i will

00:02:15,040 --> 00:02:19,599
be presenting and

00:02:17,280 --> 00:02:21,599
this is the the top diagram the complete

00:02:19,599 --> 00:02:23,840
diagram and we will get into details in

00:02:21,599 --> 00:02:25,760
the following slides

00:02:23,840 --> 00:02:26,959
as a small summary of the beginning you

00:02:25,760 --> 00:02:28,879
can see

00:02:26,959 --> 00:02:30,080
how the user interacts through video for

00:02:28,879 --> 00:02:31,760
instance system

00:02:30,080 --> 00:02:34,239
with the harder and the software the

00:02:31,760 --> 00:02:35,200
drivers and how where is the sensor

00:02:34,239 --> 00:02:38,480
placed

00:02:35,200 --> 00:02:40,720
according to the harder pipeline the

00:02:38,480 --> 00:02:43,200
sensor control driver video forums2 and

00:02:40,720 --> 00:02:45,120
the user itself

00:02:43,200 --> 00:02:47,040
regarding user space and also kernel

00:02:45,120 --> 00:02:49,680
space

00:02:47,040 --> 00:02:50,720
so as i said in the agenda let's move to

00:02:49,680 --> 00:02:53,599
the

00:02:50,720 --> 00:02:55,599
first topic and we start from the

00:02:53,599 --> 00:02:57,920
beginning which means

00:02:55,599 --> 00:02:59,280
what is the digital video sensor and how

00:02:57,920 --> 00:03:01,040
does the sensor works

00:02:59,280 --> 00:03:03,360
how do you obtain the data we need for

00:03:01,040 --> 00:03:06,080
taking a photo

00:03:03,360 --> 00:03:08,480
and to explain that let's see the exact

00:03:06,080 --> 00:03:10,800
functionality of a sensor

00:03:08,480 --> 00:03:12,560
on the right side of the slide you will

00:03:10,800 --> 00:03:14,720
see

00:03:12,560 --> 00:03:16,080
an explanation of the image sensor and

00:03:14,720 --> 00:03:18,640
how the lights

00:03:16,080 --> 00:03:20,400
the light enters the sensor through

00:03:18,640 --> 00:03:22,239
those photosensitive cells

00:03:20,400 --> 00:03:23,680
and how the light is being split into

00:03:22,239 --> 00:03:26,159
different uh

00:03:23,680 --> 00:03:27,120
color types of different spectrum and we

00:03:26,159 --> 00:03:30,400
can see that

00:03:27,120 --> 00:03:33,200
inside the sensor we have

00:03:30,400 --> 00:03:35,920
different photocells which are sensitive

00:03:33,200 --> 00:03:38,239
to green to blue and to red

00:03:35,920 --> 00:03:39,599
and this photosensitive cells then

00:03:38,239 --> 00:03:41,920
convert the

00:03:39,599 --> 00:03:45,040
absorbed light into data which we can

00:03:41,920 --> 00:03:47,360
obtain at a later point

00:03:45,040 --> 00:03:49,519
this array that we have inside the

00:03:47,360 --> 00:03:51,680
sensor is called the buyer array

00:03:49,519 --> 00:03:52,799
this by array is depicted on the photo

00:03:51,680 --> 00:03:56,000
on the left side

00:03:52,799 --> 00:03:57,760
of the of the slide and we can see the

00:03:56,000 --> 00:04:00,720
exact

00:03:57,760 --> 00:04:02,720
look of this array how it looks like and

00:04:00,720 --> 00:04:03,519
how the pixels are displayed in this

00:04:02,720 --> 00:04:06,319
array

00:04:03,519 --> 00:04:08,080
the blue the green and the red so this

00:04:06,319 --> 00:04:09,680
happens inside the sensor in summary

00:04:08,080 --> 00:04:10,879
with the light is being split into

00:04:09,680 --> 00:04:14,319
different colors

00:04:10,879 --> 00:04:16,880
and then captured inside the binary

00:04:14,319 --> 00:04:18,160
this by array looks in this way and

00:04:16,880 --> 00:04:21,440
let's see

00:04:18,160 --> 00:04:24,639
if we can think about what this bi array

00:04:21,440 --> 00:04:27,040
involves and why this virus was chosen

00:04:24,639 --> 00:04:29,120
like this

00:04:27,040 --> 00:04:30,400
um again if we look at the bi array we

00:04:29,120 --> 00:04:33,280
see that we

00:04:30,400 --> 00:04:34,720
actually have more green pixels than red

00:04:33,280 --> 00:04:37,759
or blue

00:04:34,720 --> 00:04:39,280
and uh if we notice that we can answer

00:04:37,759 --> 00:04:41,520
that question

00:04:39,280 --> 00:04:43,600
and the answer is that the human eye is

00:04:41,520 --> 00:04:46,639
much more sensitive to green light

00:04:43,600 --> 00:04:47,919
rather than blue or red light so the bi

00:04:46,639 --> 00:04:50,000
array tries to get

00:04:47,919 --> 00:04:51,680
more information from the incoming light

00:04:50,000 --> 00:04:54,320
considering the green light rather than

00:04:51,680 --> 00:04:57,440
the blue and the red

00:04:54,320 --> 00:04:59,840
and white this pattern was chosen it was

00:04:57,440 --> 00:05:03,440
chosen to make um

00:04:59,840 --> 00:05:07,759
less cost and be effective and to

00:05:03,440 --> 00:05:11,039
make it simpler to develop afterwards

00:05:07,759 --> 00:05:12,479
if we see this buyer array we can ask

00:05:11,039 --> 00:05:15,440
ourselves

00:05:12,479 --> 00:05:16,720
if we lose color information during this

00:05:15,440 --> 00:05:18,320
process if the pixels

00:05:16,720 --> 00:05:20,400
the distance between the pixels is too

00:05:18,320 --> 00:05:22,400
big or what happens

00:05:20,400 --> 00:05:24,639
if we lose color information considering

00:05:22,400 --> 00:05:26,400
one pixel is blue one pixel is green one

00:05:24,639 --> 00:05:28,560
pixel is red

00:05:26,400 --> 00:05:30,320
we will see that in the following slide

00:05:28,560 --> 00:05:32,720
what happens with the color information

00:05:30,320 --> 00:05:34,960
and how we manage to not lose color

00:05:32,720 --> 00:05:37,199
information from one pixel to another

00:05:34,960 --> 00:05:38,479
and we will also see what we can do with

00:05:37,199 --> 00:05:41,600
this um

00:05:38,479 --> 00:05:45,199
this information and convert the pixels

00:05:41,600 --> 00:05:47,280
from the bioarray into a real photo

00:05:45,199 --> 00:05:48,560
if we look at the down part of the slide

00:05:47,280 --> 00:05:50,560
we can notice that

00:05:48,560 --> 00:05:52,479
this photo is actually an interpretation

00:05:50,560 --> 00:05:54,800
of the wire array

00:05:52,479 --> 00:05:56,800
seeing we can see it exactly as the

00:05:54,800 --> 00:05:58,639
buyer array sees it we can distinguish

00:05:56,800 --> 00:06:00,080
the green pixels the red pixels and the

00:05:58,639 --> 00:06:02,560
blue pixels

00:06:00,080 --> 00:06:04,800
on this photo and while we look at it we

00:06:02,560 --> 00:06:06,880
understand what's in the photo but

00:06:04,800 --> 00:06:08,560
um it's not really does not really look

00:06:06,880 --> 00:06:10,479
like a photo which

00:06:08,560 --> 00:06:12,319
we can normally see and normally take

00:06:10,479 --> 00:06:14,319
with a photo camera

00:06:12,319 --> 00:06:15,919
so the we will see the process of

00:06:14,319 --> 00:06:20,319
turning this bia radius photo into a

00:06:15,919 --> 00:06:22,880
real photo which we can use

00:06:20,319 --> 00:06:24,400
the photocells get the information the

00:06:22,880 --> 00:06:27,360
light information as i said

00:06:24,400 --> 00:06:29,199
actually the sensor uses um analog

00:06:27,360 --> 00:06:32,319
digital converter and we see the

00:06:29,199 --> 00:06:32,319
information as bits

00:06:32,639 --> 00:06:36,400
so this was the talk related to the bi

00:06:35,520 --> 00:06:38,319
array

00:06:36,400 --> 00:06:40,720
i explained how what is the bi-ray and

00:06:38,319 --> 00:06:42,319
how it works how it captures light and

00:06:40,720 --> 00:06:45,199
how this light is turned into

00:06:42,319 --> 00:06:46,160
bits but with this pixel data what

00:06:45,199 --> 00:06:49,360
happens next

00:06:46,160 --> 00:06:53,280
what do we do with these bits

00:06:49,360 --> 00:06:55,680
and how can we obtain a real image

00:06:53,280 --> 00:06:58,000
and the answer to that looking at the bi

00:06:55,680 --> 00:07:00,720
array and to solve this problem is

00:06:58,000 --> 00:07:02,560
what is called the buyer interpolation

00:07:00,720 --> 00:07:05,759
the body interpolation is a process

00:07:02,560 --> 00:07:08,479
in which each pixel from the bioarray

00:07:05,759 --> 00:07:08,880
will get information from the neighbors

00:07:08,479 --> 00:07:12,080
the

00:07:08,880 --> 00:07:14,319
neighboring pixels to get enriched

00:07:12,080 --> 00:07:15,280
and obtain data such that each pixel

00:07:14,319 --> 00:07:18,800
will have

00:07:15,280 --> 00:07:21,120
all the channels information like we are

00:07:18,800 --> 00:07:23,360
expecting from a real photo

00:07:21,120 --> 00:07:25,440
we can see on the left side we have a

00:07:23,360 --> 00:07:27,280
photo that is a

00:07:25,440 --> 00:07:29,280
bio array we can see the whole pixels

00:07:27,280 --> 00:07:31,840
the difference between the pixels

00:07:29,280 --> 00:07:32,800
and on the downside of the slide in the

00:07:31,840 --> 00:07:36,160
bottom part

00:07:32,800 --> 00:07:37,840
you can see the pixel split per channel

00:07:36,160 --> 00:07:40,160
so we have a red channel green channel

00:07:37,840 --> 00:07:41,520
and the blue channel for the bird

00:07:40,160 --> 00:07:44,080
actually in the green channel are both

00:07:41,520 --> 00:07:46,639
green channels and on the middle

00:07:44,080 --> 00:07:48,879
of the slide on the upper part we can

00:07:46,639 --> 00:07:50,800
see the photo which was taken after the

00:07:48,879 --> 00:07:53,039
biointerpolation

00:07:50,800 --> 00:07:54,879
so this biointerpretation process is the

00:07:53,039 --> 00:07:57,120
process in which actually

00:07:54,879 --> 00:07:58,319
every pixel from the bioarray will get

00:07:57,120 --> 00:08:01,039
information

00:07:58,319 --> 00:08:02,479
from the neighbors and it will be

00:08:01,039 --> 00:08:04,160
enriched with data

00:08:02,479 --> 00:08:06,800
such that in the end we have a photo

00:08:04,160 --> 00:08:08,720
that looks exactly what we expect

00:08:06,800 --> 00:08:11,599
a photo which is not pixelated and not

00:08:08,720 --> 00:08:14,240
split in per channels in the buyer array

00:08:11,599 --> 00:08:17,680
so this interpolation process is done in

00:08:14,240 --> 00:08:17,680
the pipeline in hardware

00:08:18,400 --> 00:08:22,319
by hardware dedicated block they will

00:08:20,080 --> 00:08:24,840
perform this calculation for each pixel

00:08:22,319 --> 00:08:27,360
on the incoming pixel

00:08:24,840 --> 00:08:29,199
stream

00:08:27,360 --> 00:08:30,639
okay we understand what is in the the

00:08:29,199 --> 00:08:33,839
bio interpolation we

00:08:30,639 --> 00:08:36,560
see what happens

00:08:33,839 --> 00:08:36,880
when we take pixel data after the sensor

00:08:36,560 --> 00:08:38,560
but

00:08:36,880 --> 00:08:40,080
the issue and the challenge that we have

00:08:38,560 --> 00:08:42,560
here with this interpolation

00:08:40,080 --> 00:08:43,519
we ask ourselves if this process is

00:08:42,560 --> 00:08:46,800
flawless

00:08:43,519 --> 00:08:50,160
does it have any issues can we find

00:08:46,800 --> 00:08:54,399
some problems with this process or not

00:08:50,160 --> 00:08:55,760
and to answer that we see

00:08:54,399 --> 00:08:57,839
yes we have some issues with

00:08:55,760 --> 00:08:59,920
interpolation and what can happen

00:08:57,839 --> 00:09:02,320
the pitfall of the interpolation process

00:08:59,920 --> 00:09:05,200
or or the demo sizing process

00:09:02,320 --> 00:09:05,839
is the fact that on edges we can have

00:09:05,200 --> 00:09:08,640
strange

00:09:05,839 --> 00:09:09,680
artifacts appearing in the photo if we

00:09:08,640 --> 00:09:13,120
closely look at the

00:09:09,680 --> 00:09:15,200
photo which we have on this slide

00:09:13,120 --> 00:09:17,040
if we notice on the upper part there are

00:09:15,200 --> 00:09:19,519
some strange artifacts

00:09:17,040 --> 00:09:21,440
and maybe you have not seen it yet but i

00:09:19,519 --> 00:09:23,600
will try to put another photo which is

00:09:21,440 --> 00:09:24,640
zoomed in on the artifacts i wanted to

00:09:23,600 --> 00:09:27,360
show you

00:09:24,640 --> 00:09:28,640
and circled in black you can see that on

00:09:27,360 --> 00:09:31,040
this edge

00:09:28,640 --> 00:09:33,200
there are specific light artifacts and

00:09:31,040 --> 00:09:36,320
pixels that should not be there

00:09:33,200 --> 00:09:39,680
some strange colored pixels on the edge

00:09:36,320 --> 00:09:41,040
and why this happens on the

00:09:39,680 --> 00:09:43,040
because of the binary because of the

00:09:41,040 --> 00:09:45,200
interpolation

00:09:43,040 --> 00:09:46,399
it's because the pixels which are right

00:09:45,200 --> 00:09:49,120
on the edge will get

00:09:46,399 --> 00:09:50,000
neighbor information from the neighbors

00:09:49,120 --> 00:09:52,240
which are on the other

00:09:50,000 --> 00:09:53,920
side of the edge so the edge will be

00:09:52,240 --> 00:09:54,800
mixed up between all the pixels at the

00:09:53,920 --> 00:09:57,600
edge we do not have

00:09:54,800 --> 00:09:59,760
clear edges with this interpolation

00:09:57,600 --> 00:10:03,519
algorithm

00:09:59,760 --> 00:10:03,519
what can we do to solve that

00:10:03,600 --> 00:10:07,040
we can see another photo of the same

00:10:06,079 --> 00:10:09,200
scenery or seem

00:10:07,040 --> 00:10:11,040
very similar scenery in which the

00:10:09,200 --> 00:10:12,880
artifacts are missing and this time the

00:10:11,040 --> 00:10:15,519
artifacts have been fixed

00:10:12,880 --> 00:10:16,480
and what we can do about this is in the

00:10:15,519 --> 00:10:19,360
dedicated

00:10:16,480 --> 00:10:20,800
hardware we can compute the fact that we

00:10:19,360 --> 00:10:24,000
have an edge we can detect

00:10:20,800 --> 00:10:26,640
edges so sometimes it is possible you're

00:10:24,000 --> 00:10:27,120
using a special algorithm to detect if

00:10:26,640 --> 00:10:30,480
we have

00:10:27,120 --> 00:10:32,880
edges inside the photo and we do that

00:10:30,480 --> 00:10:34,000
by uh actually seeing if there are

00:10:32,880 --> 00:10:35,839
pixels

00:10:34,000 --> 00:10:37,040
of the same colors and there is a very

00:10:35,839 --> 00:10:38,640
big difference between

00:10:37,040 --> 00:10:41,519
a lot of pixels on one side and the

00:10:38,640 --> 00:10:43,600
other side of the edge

00:10:41,519 --> 00:10:45,839
sometimes it works sometimes it does not

00:10:43,600 --> 00:10:46,560
not all the edges are fully detected at

00:10:45,839 --> 00:10:49,600
all times

00:10:46,560 --> 00:10:51,440
but this algorithm will try to prevent

00:10:49,600 --> 00:10:54,000
the strange artifacts which i showed

00:10:51,440 --> 00:10:54,000
previously

00:10:54,079 --> 00:10:59,120
inside the system what happens

00:10:57,120 --> 00:11:00,320
is that the image sensor produces the

00:10:59,120 --> 00:11:02,480
pixel stream

00:11:00,320 --> 00:11:04,640
we can see on the left side of the

00:11:02,480 --> 00:11:06,000
screen and the wire interpolation and

00:11:04,640 --> 00:11:08,480
the edge detection mechanism

00:11:06,000 --> 00:11:10,320
inside the hardware pipeline will be

00:11:08,480 --> 00:11:12,160
responsible to do the interpolation and

00:11:10,320 --> 00:11:13,920
hardware detection

00:11:12,160 --> 00:11:15,920
and the user can interact with this

00:11:13,920 --> 00:11:17,360
using the video formulas to subsystem

00:11:15,920 --> 00:11:18,160
interface which is the arrow on the left

00:11:17,360 --> 00:11:20,800
side

00:11:18,160 --> 00:11:21,920
the resulting image is then taken by the

00:11:20,800 --> 00:11:23,200
user

00:11:21,920 --> 00:11:24,880
from the kernel space through the

00:11:23,200 --> 00:11:26,240
special character device so this is a

00:11:24,880 --> 00:11:28,480
small diagram of

00:11:26,240 --> 00:11:31,279
exactly how things happen inside linux

00:11:28,480 --> 00:11:31,279
and inside the system

00:11:31,519 --> 00:11:36,000
now let me explain another issue that

00:11:34,640 --> 00:11:37,920
can happen

00:11:36,000 --> 00:11:39,360
during the process of image acquisition

00:11:37,920 --> 00:11:41,600
of image processing

00:11:39,360 --> 00:11:42,560
during the hardware software pipeline

00:11:41,600 --> 00:11:44,800
and

00:11:42,560 --> 00:11:46,959
this one problem which i want to explain

00:11:44,800 --> 00:11:49,600
is what i call the color problem

00:11:46,959 --> 00:11:52,000
and this is closely entirely related to

00:11:49,600 --> 00:11:55,120
how we see the light

00:11:52,000 --> 00:11:56,880
normally we see light as a single entity

00:11:55,120 --> 00:11:58,880
just light we call it light

00:11:56,880 --> 00:12:01,200
but in fact what they will tell you is

00:11:58,880 --> 00:12:03,920
that the light has a temperature

00:12:01,200 --> 00:12:05,600
and this temperature affects the way we

00:12:03,920 --> 00:12:07,600
see the light and the way the sensor

00:12:05,600 --> 00:12:10,959
sees the lights

00:12:07,600 --> 00:12:12,720
in this photo we can see that specific

00:12:10,959 --> 00:12:16,480
light on the left side

00:12:12,720 --> 00:12:19,760
has a specific light color which is

00:12:16,480 --> 00:12:22,000
more orange more yellowish

00:12:19,760 --> 00:12:22,880
and we can see on the right side that

00:12:22,000 --> 00:12:25,360
the other light

00:12:22,880 --> 00:12:25,920
is more bluish and the color temperature

00:12:25,360 --> 00:12:28,000
of each

00:12:25,920 --> 00:12:29,760
of these lights is on the left side is

00:12:28,000 --> 00:12:32,880
1000 kelvin and on the

00:12:29,760 --> 00:12:34,079
right side is 10 000 kelvin we can see a

00:12:32,880 --> 00:12:36,320
very big difference in the

00:12:34,079 --> 00:12:39,680
the light color affects how we actually

00:12:36,320 --> 00:12:43,200
see the object's colors

00:12:39,680 --> 00:12:44,639
and we can move further and i will try

00:12:43,200 --> 00:12:47,519
to show you a photo

00:12:44,639 --> 00:12:49,040
let's take an example of a photo and we

00:12:47,519 --> 00:12:50,639
can see

00:12:49,040 --> 00:12:53,600
we have a close look at this photo we

00:12:50,639 --> 00:12:55,519
can watch it for a few seconds

00:12:53,600 --> 00:12:57,440
not no problem with that and we can see

00:12:55,519 --> 00:13:00,720
it we can distinguish

00:12:57,440 --> 00:13:03,120
a rock some water sky some

00:13:00,720 --> 00:13:04,880
trees that's okay we can distinguish

00:13:03,120 --> 00:13:08,160
that we can see it

00:13:04,880 --> 00:13:10,639
what i will ask you now is what is the

00:13:08,160 --> 00:13:12,320
color of the water in this photo what is

00:13:10,639 --> 00:13:13,839
the color of the rock what is the color

00:13:12,320 --> 00:13:15,519
of the sky

00:13:13,839 --> 00:13:17,440
maybe we are tempted to say that the

00:13:15,519 --> 00:13:20,720
water is blue the sky is blue the

00:13:17,440 --> 00:13:24,079
rock is white that's one thing to say

00:13:20,720 --> 00:13:26,880
about this photo we can see that

00:13:24,079 --> 00:13:28,880
i will ask you again the same thing on

00:13:26,880 --> 00:13:30,800
this photo which is actually

00:13:28,880 --> 00:13:32,839
almost the same photo but not quite the

00:13:30,800 --> 00:13:34,560
same you can see some differences in

00:13:32,839 --> 00:13:37,040
color

00:13:34,560 --> 00:13:41,120
we can see that in this photo the the

00:13:37,040 --> 00:13:43,839
light and the color is much more natural

00:13:41,120 --> 00:13:45,440
we can see the exact blue water the blue

00:13:43,839 --> 00:13:47,120
sky and the white rock

00:13:45,440 --> 00:13:48,880
is there any big difference between the

00:13:47,120 --> 00:13:51,600
other photo

00:13:48,880 --> 00:13:51,600
and why is that

00:13:52,480 --> 00:13:58,399
actually what i'm trying to tell you is

00:13:56,000 --> 00:14:00,160
that we also see with our brain not just

00:13:58,399 --> 00:14:02,480
with our eyes

00:14:00,160 --> 00:14:03,920
let's look at this black and white photo

00:14:02,480 --> 00:14:06,240
which is again a

00:14:03,920 --> 00:14:07,360
simple photo taken in black and white

00:14:06,240 --> 00:14:09,680
and can distinguish

00:14:07,360 --> 00:14:11,600
a sky and maybe some trees or some

00:14:09,680 --> 00:14:14,880
bushes and some rock

00:14:11,600 --> 00:14:17,680
on on this photo but

00:14:14,880 --> 00:14:19,360
um do we understand what's in this photo

00:14:17,680 --> 00:14:20,639
do we see the colors there it's black

00:14:19,360 --> 00:14:21,279
and white we can't see the colors that

00:14:20,639 --> 00:14:23,199
clear but

00:14:21,279 --> 00:14:24,800
our brain can understand the colors

00:14:23,199 --> 00:14:26,480
there we can actually

00:14:24,800 --> 00:14:31,040
picture with our mind that we have some

00:14:26,480 --> 00:14:32,800
green bushes and the blue sky

00:14:31,040 --> 00:14:34,800
if we remember from old times

00:14:32,800 --> 00:14:37,600
photography long ago

00:14:34,800 --> 00:14:38,800
that we used to have what is called cpr

00:14:37,600 --> 00:14:41,680
photography

00:14:38,800 --> 00:14:43,040
and again the same photo we see now in

00:14:41,680 --> 00:14:45,680
sepia

00:14:43,040 --> 00:14:47,040
and if you look at this photo i will ask

00:14:45,680 --> 00:14:49,199
you again do you see colors in this

00:14:47,040 --> 00:14:50,800
photo or not

00:14:49,199 --> 00:14:52,240
maybe you will say okay there are not

00:14:50,800 --> 00:14:54,560
many many colors

00:14:52,240 --> 00:14:56,160
but then i will say what's the

00:14:54,560 --> 00:14:57,440
difference between the cpf photography

00:14:56,160 --> 00:14:58,880
and the black and white which you see

00:14:57,440 --> 00:15:02,240
previously

00:14:58,880 --> 00:15:05,519
and i will tell you that sepia is again

00:15:02,240 --> 00:15:07,839
a monochrome photo so cpa is a

00:15:05,519 --> 00:15:09,680
photography made of shades of brown

00:15:07,839 --> 00:15:10,399
while black and white is made of shades

00:15:09,680 --> 00:15:12,720
of gray

00:15:10,399 --> 00:15:14,480
so actually cpa is not a color photo

00:15:12,720 --> 00:15:17,360
it's just a monochrome photo

00:15:14,480 --> 00:15:18,959
but our brain can understand the chorus

00:15:17,360 --> 00:15:21,839
even if this is a monochrome

00:15:18,959 --> 00:15:23,920
photo so what i'm trying to emphasize

00:15:21,839 --> 00:15:25,839
with all this talk regarding colors

00:15:23,920 --> 00:15:27,600
is that our brain can see much more than

00:15:25,839 --> 00:15:29,199
our eyes can see

00:15:27,600 --> 00:15:31,360
and that the sensor does not have a

00:15:29,199 --> 00:15:34,560
brain and needs to be teached

00:15:31,360 --> 00:15:36,560
to be understand what is the light

00:15:34,560 --> 00:15:38,480
around it and how it can adapt

00:15:36,560 --> 00:15:41,920
the coloring to the specific light that

00:15:38,480 --> 00:15:44,560
is seen in the scenery

00:15:41,920 --> 00:15:45,600
how we do that how we can do that this

00:15:44,560 --> 00:15:49,360
is a process which

00:15:45,600 --> 00:15:50,639
is called white balancing and uh

00:15:49,360 --> 00:15:52,639
again i will show you the picture side

00:15:50,639 --> 00:15:56,079
by side to see the differences before

00:15:52,639 --> 00:15:57,920
white balancing it after white balancing

00:15:56,079 --> 00:15:59,839
more examples with the same photo which

00:15:57,920 --> 00:16:02,320
we saw in black and white and

00:15:59,839 --> 00:16:02,320
sepia

00:16:03,120 --> 00:16:08,160
another photo before white balancing and

00:16:05,199 --> 00:16:10,639
after white balancing

00:16:08,160 --> 00:16:11,759
examples of what we can see how it's

00:16:10,639 --> 00:16:14,320
adapted to

00:16:11,759 --> 00:16:17,120
specific coloring to specific light

00:16:14,320 --> 00:16:19,759
inside and outside

00:16:17,120 --> 00:16:20,560
as i said we need to teach the sensor to

00:16:19,759 --> 00:16:23,680
adapt

00:16:20,560 --> 00:16:27,440
to specific coloring and how we do that

00:16:23,680 --> 00:16:27,440
we will see in the following slides

00:16:28,320 --> 00:16:32,000
i will ask you another question one more

00:16:30,959 --> 00:16:34,800
question this time

00:16:32,000 --> 00:16:38,240
to see to to see how we can teach the

00:16:34,800 --> 00:16:39,920
sensor and first question that comes is

00:16:38,240 --> 00:16:41,360
if we look at this photo which you can

00:16:39,920 --> 00:16:44,639
see on this slide

00:16:41,360 --> 00:16:47,360
i will ask you what is the average

00:16:44,639 --> 00:16:48,880
color of this photo you can see a simple

00:16:47,360 --> 00:16:51,440
photo and the question is what is the

00:16:48,880 --> 00:16:54,079
average color

00:16:51,440 --> 00:16:56,079
we see we look at the photo and we see

00:16:54,079 --> 00:16:56,639
white we see black with some shades of

00:16:56,079 --> 00:17:00,720
gray

00:16:56,639 --> 00:17:00,720
and in the middle a big patch of gray

00:17:01,519 --> 00:17:04,799
if we sum them up all the colors here

00:17:04,079 --> 00:17:07,839
and

00:17:04,799 --> 00:17:08,880
think about the average it's natural to

00:17:07,839 --> 00:17:10,480
conclude that the

00:17:08,880 --> 00:17:13,039
average color of this photo of this

00:17:10,480 --> 00:17:14,640
frame is grey this is natural

00:17:13,039 --> 00:17:17,760
if we consider all the colors in the

00:17:14,640 --> 00:17:18,000
frame i will move to another photo and

00:17:17,760 --> 00:17:21,679
this

00:17:18,000 --> 00:17:23,280
time this frame is full of colors and i

00:17:21,679 --> 00:17:26,799
will ask you the same thing

00:17:23,280 --> 00:17:29,360
what is the average color of this photo

00:17:26,799 --> 00:17:30,960
if we look at it we see again the bottom

00:17:29,360 --> 00:17:34,080
part some shades of gray

00:17:30,960 --> 00:17:36,000
and on the upper part we see

00:17:34,080 --> 00:17:38,080
a lot of colors some red some blue some

00:17:36,000 --> 00:17:40,960
green what happens if we

00:17:38,080 --> 00:17:42,080
add them up some patches miss red some

00:17:40,960 --> 00:17:44,880
patches have reds

00:17:42,080 --> 00:17:45,520
veggies miss blues veggies miss green

00:17:44,880 --> 00:17:47,760
but

00:17:45,520 --> 00:17:49,600
the surprise is that if we patch them up

00:17:47,760 --> 00:17:50,640
if we add them up together and complete

00:17:49,600 --> 00:17:53,760
the average

00:17:50,640 --> 00:17:57,360
again we will see that this color card

00:17:53,760 --> 00:18:00,240
has an average of gray and

00:17:57,360 --> 00:18:01,840
we will use this thing that this average

00:18:00,240 --> 00:18:04,000
color of this photo is grey

00:18:01,840 --> 00:18:05,039
to learn the sense or how to adapt to

00:18:04,000 --> 00:18:07,520
colors

00:18:05,039 --> 00:18:08,799
and this is done with what we call the

00:18:07,520 --> 00:18:12,320
grey world

00:18:08,799 --> 00:18:14,160
assumption and the grey world algorithm

00:18:12,320 --> 00:18:16,400
what we will teach the sensor is the

00:18:14,160 --> 00:18:19,280
fact that the gray color is grey for

00:18:16,400 --> 00:18:20,799
us and it means that it must be gray for

00:18:19,280 --> 00:18:22,160
the sensor as well

00:18:20,799 --> 00:18:24,080
of course this must be done in the

00:18:22,160 --> 00:18:27,280
ambient light so that light must be

00:18:24,080 --> 00:18:29,120
taken into account in this calculation

00:18:27,280 --> 00:18:30,799
so for this we use this chorological

00:18:29,120 --> 00:18:33,120
card which we see in this photo which is

00:18:30,799 --> 00:18:36,640
exactly what i showed you previously

00:18:33,120 --> 00:18:38,400
the gray assumption so actually we take

00:18:36,640 --> 00:18:42,160
the assumption that every scenery

00:18:38,400 --> 00:18:43,919
which is diverse enough is gray

00:18:42,160 --> 00:18:46,240
how we will implement this in our driver

00:18:43,919 --> 00:18:50,160
in video for linux to adapt

00:18:46,240 --> 00:18:51,600
to our um our driver our pipeline our

00:18:50,160 --> 00:18:53,679
hardware our software

00:18:51,600 --> 00:18:56,320
to teach the sensor to understand that

00:18:53,679 --> 00:18:57,280
we have a great scenery and adapt our

00:18:56,320 --> 00:19:00,160
gray color

00:18:57,280 --> 00:19:01,200
to be grey for us as well so we will

00:19:00,160 --> 00:19:03,280
take this photo which

00:19:01,200 --> 00:19:04,720
we see on the left side which you seen

00:19:03,280 --> 00:19:07,280
previously in the presentation but now

00:19:04,720 --> 00:19:09,280
we will have a closer look at it

00:19:07,280 --> 00:19:12,160
and we see that this photo is somehow

00:19:09,280 --> 00:19:15,200
greenish with a very low blue

00:19:12,160 --> 00:19:18,080
this is a visible with the naked eye

00:19:15,200 --> 00:19:20,559
and actually you want to emphasize the

00:19:18,080 --> 00:19:23,200
grey world we want to adapt this scenery

00:19:20,559 --> 00:19:24,000
to be gray in average grain average

00:19:23,200 --> 00:19:26,960
means that all

00:19:24,000 --> 00:19:28,480
the components of the photo the green

00:19:26,960 --> 00:19:33,039
the red and the blue

00:19:28,480 --> 00:19:33,039
have the same amount in the average

00:19:33,120 --> 00:19:37,200
to do that we use what is called the

00:19:34,960 --> 00:19:38,400
histogram the histogram is computed by

00:19:37,200 --> 00:19:40,799
the hardware

00:19:38,400 --> 00:19:42,160
and the histogram tells us exactly how

00:19:40,799 --> 00:19:45,440
much of each color

00:19:42,160 --> 00:19:46,320
is inside the frame the photo if we look

00:19:45,440 --> 00:19:49,440
on the left side

00:19:46,320 --> 00:19:51,280
right side of this slide we will see the

00:19:49,440 --> 00:19:53,120
histogram for each channel

00:19:51,280 --> 00:19:55,200
we see a histogram for red for green and

00:19:53,120 --> 00:19:57,600
for blue this histogram is actually a

00:19:55,200 --> 00:19:59,280
representation of how many pixels of

00:19:57,600 --> 00:20:01,840
each value we have

00:19:59,280 --> 00:20:03,200
in the frame we can see looking at the

00:20:01,840 --> 00:20:05,679
histogram that

00:20:03,200 --> 00:20:06,240
there are more pixels of high value of

00:20:05,679 --> 00:20:09,280
green

00:20:06,240 --> 00:20:10,080
rather than blue so we see that green is

00:20:09,280 --> 00:20:12,400
predominant

00:20:10,080 --> 00:20:13,360
in this photo by looking at judging by

00:20:12,400 --> 00:20:15,520
the histogram

00:20:13,360 --> 00:20:17,520
we have also red but the blue is very

00:20:15,520 --> 00:20:19,360
low so

00:20:17,520 --> 00:20:20,640
looking with the negative the photo we

00:20:19,360 --> 00:20:22,880
see the same thing

00:20:20,640 --> 00:20:24,000
the fact that there is little blue in

00:20:22,880 --> 00:20:27,360
this photo

00:20:24,000 --> 00:20:30,400
and that there is plenty of green so

00:20:27,360 --> 00:20:31,760
doing this computation is a histogram we

00:20:30,400 --> 00:20:35,280
can see this

00:20:31,760 --> 00:20:37,600
so what can we do to adapt our

00:20:35,280 --> 00:20:39,440
hardware and software to solve this

00:20:37,600 --> 00:20:40,240
problem and to adjust the photos such

00:20:39,440 --> 00:20:43,440
that it will look

00:20:40,240 --> 00:20:45,440
fine we apply the grey world algorithm

00:20:43,440 --> 00:20:47,360
that everything is grey so we need to

00:20:45,440 --> 00:20:49,760
adjust this histogram

00:20:47,360 --> 00:20:50,640
to look the same for every channel and

00:20:49,760 --> 00:20:52,720
how we do that

00:20:50,640 --> 00:20:54,240
we compute the average of the photo the

00:20:52,720 --> 00:20:56,960
average of the gray

00:20:54,240 --> 00:20:58,799
and then we adjust the red and the blue

00:20:56,960 --> 00:21:02,799
and the green

00:20:58,799 --> 00:21:05,760
to make it such that they are aligned

00:21:02,799 --> 00:21:07,440
and we divide the sum of the red the sum

00:21:05,760 --> 00:21:08,400
of the blue by the average and we

00:21:07,440 --> 00:21:10,799
compute

00:21:08,400 --> 00:21:11,919
uh two things which are called the gain

00:21:10,799 --> 00:21:14,240
and the offset

00:21:11,919 --> 00:21:15,600
the gain is a multiplier on a channel

00:21:14,240 --> 00:21:17,360
and the offset is a

00:21:15,600 --> 00:21:20,320
constant which is added or subtracted

00:21:17,360 --> 00:21:23,039
from the channel so each channel is

00:21:20,320 --> 00:21:23,760
associated with a gain and an offset so

00:21:23,039 --> 00:21:25,440
we'll actually

00:21:23,760 --> 00:21:27,520
the gain will multiply the channel it

00:21:25,440 --> 00:21:29,520
will increase the values

00:21:27,520 --> 00:21:31,039
while the offset will just add to every

00:21:29,520 --> 00:21:32,799
pixel

00:21:31,039 --> 00:21:34,799
so once we apply the grey world and we

00:21:32,799 --> 00:21:35,840
compute these gains and offsets and we

00:21:34,799 --> 00:21:39,120
apply them

00:21:35,840 --> 00:21:39,840
on the channel we obtain the photo which

00:21:39,120 --> 00:21:43,440
we call

00:21:39,840 --> 00:21:44,799
is white balance adjusted so if we look

00:21:43,440 --> 00:21:46,559
again at this photo which is

00:21:44,799 --> 00:21:47,919
white balance adjusted and we compute

00:21:46,559 --> 00:21:50,400
again the histograms

00:21:47,919 --> 00:21:51,840
for this photo we can see on the right

00:21:50,400 --> 00:21:52,640
side that the histograms for the

00:21:51,840 --> 00:21:55,760
channels are

00:21:52,640 --> 00:21:57,280
nearly identical and what this means

00:21:55,760 --> 00:21:58,400
that the histogram for the channels are

00:21:57,280 --> 00:22:00,400
nearly identical

00:21:58,400 --> 00:22:02,799
is that if we sum them up we actually

00:22:00,400 --> 00:22:04,640
obtain gray so the average photo of this

00:22:02,799 --> 00:22:07,039
white balance adjusted photo is great

00:22:04,640 --> 00:22:08,799
exactly what we wanted to obtain with

00:22:07,039 --> 00:22:11,039
the grey world algorithm

00:22:08,799 --> 00:22:12,960
and looking on the left side photo which

00:22:11,039 --> 00:22:15,280
is now

00:22:12,960 --> 00:22:17,360
fixed it looks much better and the

00:22:15,280 --> 00:22:19,200
colors are much more natural

00:22:17,360 --> 00:22:21,440
about what we expect when we look at the

00:22:19,200 --> 00:22:24,240
scenery and the photo which we take

00:22:21,440 --> 00:22:24,240
with our camera

00:22:25,280 --> 00:22:29,520
to do this in a video for linux and how

00:22:27,280 --> 00:22:30,799
video formats exposes this interface for

00:22:29,520 --> 00:22:32,720
us

00:22:30,799 --> 00:22:35,200
is done through the video for linux

00:22:32,720 --> 00:22:37,440
controls and here i have a slide

00:22:35,200 --> 00:22:38,640
uh showing the exact values of the

00:22:37,440 --> 00:22:41,919
controls

00:22:38,640 --> 00:22:44,000
it may look confusing at start but if we

00:22:41,919 --> 00:22:46,960
take a closer look we can see

00:22:44,000 --> 00:22:48,320
the exact uh gains and offsets which i

00:22:46,960 --> 00:22:51,200
was saying previously we have a

00:22:48,320 --> 00:22:53,120
red component gain a blue component gain

00:22:51,200 --> 00:22:55,600
green red component giving green blue

00:22:53,120 --> 00:22:57,760
for the buyer array remember you have a

00:22:55,600 --> 00:22:58,960
green cell on the red row and a green

00:22:57,760 --> 00:23:01,760
cell on the blue row

00:22:58,960 --> 00:23:03,600
so we have four channels in the binary

00:23:01,760 --> 00:23:07,280
and by default this has

00:23:03,600 --> 00:23:09,760
you have specific values which are 512

00:23:07,280 --> 00:23:13,360
for the gains and zero for the offsets

00:23:09,760 --> 00:23:15,600
these are the default values and once we

00:23:13,360 --> 00:23:17,200
apply the gray world algorithm by doing

00:23:15,600 --> 00:23:20,159
the do-white balance

00:23:17,200 --> 00:23:22,640
procedure applying degree work one time

00:23:20,159 --> 00:23:24,559
video foreign helps us with this control

00:23:22,640 --> 00:23:25,440
which is the white balance we press this

00:23:24,559 --> 00:23:28,559
control and

00:23:25,440 --> 00:23:31,440
we have the values obtained

00:23:28,559 --> 00:23:34,000
and we can see on our photo that the

00:23:31,440 --> 00:23:36,240
gain for the blue for example now is

00:23:34,000 --> 00:23:37,280
three thousand you can see it with red

00:23:36,240 --> 00:23:40,240
in the slide

00:23:37,280 --> 00:23:42,880
you see it increased a lot and the green

00:23:40,240 --> 00:23:46,320
component offsets are negative

00:23:42,880 --> 00:23:48,240
so we see that the the gains and offsets

00:23:46,320 --> 00:23:49,440
have been adjusted in a way somehow we

00:23:48,240 --> 00:23:51,840
expected this

00:23:49,440 --> 00:23:52,960
we expected that the blue is increased

00:23:51,840 --> 00:23:55,600
with a high gain

00:23:52,960 --> 00:23:57,200
and the green is reduced by using a

00:23:55,600 --> 00:23:58,559
negative offset so this is what we

00:23:57,200 --> 00:23:59,840
actually expected by looking at the

00:23:58,559 --> 00:24:01,840
histogram

00:23:59,840 --> 00:24:03,120
so video for linux controls helps us

00:24:01,840 --> 00:24:05,760
with this

00:24:03,120 --> 00:24:07,520
implementing this on the photo on the

00:24:05,760 --> 00:24:10,880
channels

00:24:07,520 --> 00:24:11,679
and we also have a control that will do

00:24:10,880 --> 00:24:14,480
this very well

00:24:11,679 --> 00:24:15,520
adjustment for us in the driver inside

00:24:14,480 --> 00:24:17,520
the hardware

00:24:15,520 --> 00:24:19,360
pipeline and software the real world

00:24:17,520 --> 00:24:21,520
algorithm

00:24:19,360 --> 00:24:23,039
this is how it looks from a command line

00:24:21,520 --> 00:24:24,960
perspective but

00:24:23,039 --> 00:24:26,159
what it happens when we have an embedded

00:24:24,960 --> 00:24:28,400
linux camera

00:24:26,159 --> 00:24:30,080
it looks maybe something similar to this

00:24:28,400 --> 00:24:32,799
maybe you have seen this

00:24:30,080 --> 00:24:34,720
on a camera you have an exactly white

00:24:32,799 --> 00:24:37,279
balance button

00:24:34,720 --> 00:24:38,960
and this exact same thing happens when

00:24:37,279 --> 00:24:41,600
you press the white balance button

00:24:38,960 --> 00:24:42,880
it will auto adjust the gains and the

00:24:41,600 --> 00:24:44,720
offsets for you

00:24:42,880 --> 00:24:46,960
instead of using a difference control

00:24:44,720 --> 00:24:49,039
behind it you just press a button which

00:24:46,960 --> 00:24:51,520
in fact leads to the same thing

00:24:49,039 --> 00:24:52,480
and call to the video for news api that

00:24:51,520 --> 00:24:55,279
goes to the driver

00:24:52,480 --> 00:24:58,080
and it will call the white balance

00:24:55,279 --> 00:25:00,720
algorithm inside the driver

00:24:58,080 --> 00:25:02,640
so this is a clear picture of what the

00:25:00,720 --> 00:25:06,000
white balance button does

00:25:02,640 --> 00:25:06,000
for an embedded linux camera

00:25:06,960 --> 00:25:10,559
what happens with cameras usually is

00:25:09,279 --> 00:25:12,960
what we it's called the

00:25:10,559 --> 00:25:15,679
auto white balance this is a actually a

00:25:12,960 --> 00:25:17,919
simple white balance that is performed

00:25:15,679 --> 00:25:20,240
uh continuously all the time such that

00:25:17,919 --> 00:25:23,039
if we moved from a scenery to scenery to

00:25:20,240 --> 00:25:23,760
adjust automatically to the specific

00:25:23,039 --> 00:25:25,440
light

00:25:23,760 --> 00:25:27,200
so you can see this even if you expand

00:25:25,440 --> 00:25:28,720
your smartphone you will

00:25:27,200 --> 00:25:30,320
move your smartphone from one light to

00:25:28,720 --> 00:25:32,480
another and you will see

00:25:30,320 --> 00:25:34,159
how the white balance adjusts to the

00:25:32,480 --> 00:25:36,960
specific light if you move from indoor

00:25:34,159 --> 00:25:39,360
to outdoors for example

00:25:36,960 --> 00:25:41,919
another way to present the gains in the

00:25:39,360 --> 00:25:43,279
offset if the command line is not really

00:25:41,919 --> 00:25:46,320
very clear

00:25:43,279 --> 00:25:47,919
you can even make a gui for this with

00:25:46,320 --> 00:25:50,799
sliders that you can

00:25:47,919 --> 00:25:51,360
manually adjust the auto-white balance

00:25:50,799 --> 00:25:53,840
has also

00:25:51,360 --> 00:25:56,320
some drawbacks see for example the

00:25:53,840 --> 00:25:58,720
scenery is not really gray maybe you're

00:25:56,320 --> 00:25:59,440
you're using your phone inside of a red

00:25:58,720 --> 00:26:01,679
patch

00:25:59,440 --> 00:26:03,600
photo or red box or something like that

00:26:01,679 --> 00:26:06,960
it will auto adjust to get the

00:26:03,600 --> 00:26:08,960
red part of the scenery into grey which

00:26:06,960 --> 00:26:10,720
is a pitfall of this algorithm which is

00:26:08,960 --> 00:26:13,440
not perfect of course

00:26:10,720 --> 00:26:14,480
it can be improved by different other

00:26:13,440 --> 00:26:16,320
aspects like

00:26:14,480 --> 00:26:18,240
detecting the gray object inside the

00:26:16,320 --> 00:26:21,520
photo or maybe

00:26:18,240 --> 00:26:23,440
do like photoshop is doing doing two

00:26:21,520 --> 00:26:25,200
white balances one for black and one for

00:26:23,440 --> 00:26:28,080
white

00:26:25,200 --> 00:26:30,159
and of course you can experiment and do

00:26:28,080 --> 00:26:32,080
manual tuning as i said earlier just

00:26:30,159 --> 00:26:32,640
move the sliders and see the effect it

00:26:32,080 --> 00:26:34,240
has

00:26:32,640 --> 00:26:39,760
on the white balance procedure on your

00:26:34,240 --> 00:26:42,480
camera and on the resulting photo

00:26:39,760 --> 00:26:44,240
to continue and to complete this chapter

00:26:42,480 --> 00:26:46,960
regarding white balance

00:26:44,240 --> 00:26:48,799
i also added a part of the diagram

00:26:46,960 --> 00:26:51,120
regarding the system

00:26:48,799 --> 00:26:53,760
and you can see how the user can

00:26:51,120 --> 00:26:56,240
interact with the white balance module

00:26:53,760 --> 00:26:56,799
inside video for news inside the driver

00:26:56,240 --> 00:26:58,640
so the

00:26:56,799 --> 00:27:01,679
user space true on user space

00:26:58,640 --> 00:27:04,799
application will call the interface api

00:27:01,679 --> 00:27:06,640
and actually the sensor control driver

00:27:04,799 --> 00:27:08,320
will be called to adjust

00:27:06,640 --> 00:27:10,960
the white balance with the gains and the

00:27:08,320 --> 00:27:12,880
offsets and the pixel stream coming from

00:27:10,960 --> 00:27:14,720
the sensor from the previous stage of

00:27:12,880 --> 00:27:17,120
the pipeline will be adjusted according

00:27:14,720 --> 00:27:18,720
to the values inside the hardware

00:27:17,120 --> 00:27:21,360
and in the end the resulting image will

00:27:18,720 --> 00:27:23,679
be taken again through the interface

00:27:21,360 --> 00:27:24,960
to the back of the user space to the to

00:27:23,679 --> 00:27:27,600
the user

00:27:24,960 --> 00:27:29,600
so this is a small diagram of what

00:27:27,600 --> 00:27:33,039
happens inside the system

00:27:29,600 --> 00:27:34,960
when the user adjusts the

00:27:33,039 --> 00:27:37,200
the gains and the offsets from a video

00:27:34,960 --> 00:27:37,919
foreign control and the video for news

00:27:37,200 --> 00:27:41,919
exp

00:27:37,919 --> 00:27:45,039
perspective so this was the

00:27:41,919 --> 00:27:47,360
discussion related to white balance

00:27:45,039 --> 00:27:48,720
and how we can teach the sensor to adapt

00:27:47,360 --> 00:27:51,919
to white balance

00:27:48,720 --> 00:27:52,320
and to the temperature of the light of

00:27:51,919 --> 00:27:56,080
the

00:27:52,320 --> 00:27:57,600
scenery what i will try to explain next

00:27:56,080 --> 00:28:00,240
is another challenge another issue that

00:27:57,600 --> 00:28:03,440
we can have with our sensor with the

00:28:00,240 --> 00:28:03,760
image capture and image acquisition is

00:28:03,440 --> 00:28:07,600
the

00:28:03,760 --> 00:28:10,320
what you call the quantity of light and

00:28:07,600 --> 00:28:12,720
the question is does it matter how much

00:28:10,320 --> 00:28:14,000
light we absorb during our sensor and

00:28:12,720 --> 00:28:16,960
how can this affect the

00:28:14,000 --> 00:28:18,960
photo that we take and uh how can we

00:28:16,960 --> 00:28:20,080
solve that or how can what algorithm we

00:28:18,960 --> 00:28:23,120
can apply

00:28:20,080 --> 00:28:25,440
how can we try to find a solution and uh

00:28:23,120 --> 00:28:27,279
how can the driver or the hardware or

00:28:25,440 --> 00:28:30,399
video foreign help us

00:28:27,279 --> 00:28:33,760
to obtain a better quality of the photo

00:28:30,399 --> 00:28:36,480
that we take so

00:28:33,760 --> 00:28:37,760
let's have a look at the following

00:28:36,480 --> 00:28:40,000
photos

00:28:37,760 --> 00:28:41,279
on the left side we have a photo which

00:28:40,000 --> 00:28:42,799
we can see that

00:28:41,279 --> 00:28:44,880
it has a lot of light in it there are a

00:28:42,799 --> 00:28:46,559
lot of white pixels

00:28:44,880 --> 00:28:48,960
and on the right side we have a much

00:28:46,559 --> 00:28:50,559
more natural photo it's much more clear

00:28:48,960 --> 00:28:52,399
and much better

00:28:50,559 --> 00:28:55,120
and what i can tell you is that the

00:28:52,399 --> 00:28:57,520
photo on the left side is overexposed

00:28:55,120 --> 00:28:58,799
meaning that the the pixels are much

00:28:57,520 --> 00:29:02,320
more

00:28:58,799 --> 00:29:05,120
saturated with light and there are

00:29:02,320 --> 00:29:07,039
many white pixels so we cannot really

00:29:05,120 --> 00:29:10,720
distinguish anything from the

00:29:07,039 --> 00:29:10,720
white pixels in this photo

00:29:10,960 --> 00:29:15,840
you can see another type of photo in the

00:29:13,520 --> 00:29:18,880
left side again we have a photo which is

00:29:15,840 --> 00:29:20,480
with very little light and this time you

00:29:18,880 --> 00:29:22,080
can see that we have a lot of black

00:29:20,480 --> 00:29:24,480
pixels so

00:29:22,080 --> 00:29:26,080
the pixels are not sensitive to light

00:29:24,480 --> 00:29:29,679
and in this case this photo is

00:29:26,080 --> 00:29:30,799
underexposed so we can see a clear

00:29:29,679 --> 00:29:32,880
difference between

00:29:30,799 --> 00:29:35,039
an overexposed photo and an under

00:29:32,880 --> 00:29:38,399
exposed photo compared with

00:29:35,039 --> 00:29:41,279
somewhat normally exposed photo

00:29:38,399 --> 00:29:42,720
and once we see these pictures we can

00:29:41,279 --> 00:29:45,440
see the challenge of

00:29:42,720 --> 00:29:47,520
saying how much exposure we need to

00:29:45,440 --> 00:29:48,480
select for our sensor in our pipeline or

00:29:47,520 --> 00:29:50,880
hardware

00:29:48,480 --> 00:29:51,520
how we can configure that how can select

00:29:50,880 --> 00:29:53,679
that and

00:29:51,520 --> 00:29:54,799
is there a way for the video for linux

00:29:53,679 --> 00:29:58,240
or the driver to

00:29:54,799 --> 00:30:00,960
do this for us and the answer is yes

00:29:58,240 --> 00:30:02,640
again we can use our friend histogram

00:30:00,960 --> 00:30:04,480
which can help us to

00:30:02,640 --> 00:30:06,080
understand how much light we have in a

00:30:04,480 --> 00:30:09,360
photo and if we can

00:30:06,080 --> 00:30:12,240
adjust our picture and our frame

00:30:09,360 --> 00:30:14,480
to make it better and if you look at the

00:30:12,240 --> 00:30:16,240
two photos which we looked earlier

00:30:14,480 --> 00:30:19,120
one is overexposed and one is

00:30:16,240 --> 00:30:20,480
underexposed let's compute a histogram

00:30:19,120 --> 00:30:22,399
this time we will not compute a

00:30:20,480 --> 00:30:23,279
histogram for each channel the red the

00:30:22,399 --> 00:30:25,760
blue and

00:30:23,279 --> 00:30:27,039
green we will compute a complete

00:30:25,760 --> 00:30:29,039
histogram a sum

00:30:27,039 --> 00:30:30,480
of the whole histogram the whole

00:30:29,039 --> 00:30:35,679
channels together added them

00:30:30,480 --> 00:30:37,440
up and we see on the right side that

00:30:35,679 --> 00:30:39,440
the histogram looks in a specific way we

00:30:37,440 --> 00:30:42,559
have a lot of pixels which are

00:30:39,440 --> 00:30:45,039
very very high value and for the dark

00:30:42,559 --> 00:30:47,679
photo which is underexposed we have

00:30:45,039 --> 00:30:48,880
plenty of pixels which are dark which

00:30:47,679 --> 00:30:51,039
are black

00:30:48,880 --> 00:30:53,039
so the histogram looks like this for

00:30:51,039 --> 00:30:54,799
overexposed and for under exposed

00:30:53,039 --> 00:30:57,039
let's see how the histogram should look

00:30:54,799 --> 00:30:58,960
like for a normal photo

00:30:57,039 --> 00:31:00,960
and our normal photo we can see that our

00:30:58,960 --> 00:31:02,000
histogram is much more aligned towards

00:31:00,960 --> 00:31:04,720
the middle

00:31:02,000 --> 00:31:06,320
so that means that we have pixels which

00:31:04,720 --> 00:31:08,080
are in the middle range

00:31:06,320 --> 00:31:09,360
not very exposed to light and not very

00:31:08,080 --> 00:31:10,799
dark

00:31:09,360 --> 00:31:13,840
so the goal would be to use this

00:31:10,799 --> 00:31:15,760
histogram to adjust

00:31:13,840 --> 00:31:17,679
the gains and the offsets the actually

00:31:15,760 --> 00:31:19,919
the actual exposure

00:31:17,679 --> 00:31:20,799
for this uh photo for the incoming pixel

00:31:19,919 --> 00:31:23,760
stream

00:31:20,799 --> 00:31:24,880
such that we obtain uh what a photo that

00:31:23,760 --> 00:31:27,120
we can actually use

00:31:24,880 --> 00:31:28,720
a photo we can actually see not too dark

00:31:27,120 --> 00:31:30,799
not too bright

00:31:28,720 --> 00:31:33,039
and again we can use video for linux to

00:31:30,799 --> 00:31:36,480
control our exposure

00:31:33,039 --> 00:31:39,600
directly to the sub-device to the sensor

00:31:36,480 --> 00:31:41,600
such that the sensor will expose the

00:31:39,600 --> 00:31:43,600
the photo cells more or less for each

00:31:41,600 --> 00:31:46,399
incoming frame

00:31:43,600 --> 00:31:47,200
so again we have a video for this

00:31:46,399 --> 00:31:49,760
control

00:31:47,200 --> 00:31:50,880
with an exposure setting this can be

00:31:49,760 --> 00:31:53,360
modified

00:31:50,880 --> 00:31:55,840
from a command line from a interface

00:31:53,360 --> 00:31:58,240
from an api directly to video for linux

00:31:55,840 --> 00:31:58,960
and if we look at the camera maybe we

00:31:58,240 --> 00:32:01,039
know

00:31:58,960 --> 00:32:02,240
how to use exposure compensation to

00:32:01,039 --> 00:32:05,039
increase and discreet

00:32:02,240 --> 00:32:05,600
directly from a button which can do that

00:32:05,039 --> 00:32:07,440
for us

00:32:05,600 --> 00:32:09,600
looking at the camera so at the high

00:32:07,440 --> 00:32:11,600
level on the camera it's a button

00:32:09,600 --> 00:32:14,000
if we look at the api it's a call to the

00:32:11,600 --> 00:32:16,559
system that will modify the exposure for

00:32:14,000 --> 00:32:17,919
us in the whole uh from the sensor from

00:32:16,559 --> 00:32:20,640
the whole pipeline

00:32:17,919 --> 00:32:21,760
that we obtain so this is related to

00:32:20,640 --> 00:32:25,200
exposure that is

00:32:21,760 --> 00:32:28,720
directly involved with the sensor

00:32:25,200 --> 00:32:31,679
on one other aspect which i wanted to

00:32:28,720 --> 00:32:33,760
explain is related to brightness again

00:32:31,679 --> 00:32:34,799
brightness is a video for use control

00:32:33,760 --> 00:32:38,480
which can be

00:32:34,799 --> 00:32:39,519
modified through the api and i will show

00:32:38,480 --> 00:32:42,799
you a photo

00:32:39,519 --> 00:32:44,240
taken on this scenery with a positive

00:32:42,799 --> 00:32:47,200
brightness applied

00:32:44,240 --> 00:32:47,679
so you can see that the pixels are have

00:32:47,200 --> 00:32:50,399
a

00:32:47,679 --> 00:32:51,120
positive brightness i will show exactly

00:32:50,399 --> 00:32:52,880
what that means

00:32:51,120 --> 00:32:54,240
positive brightness applied but you can

00:32:52,880 --> 00:32:57,600
see that

00:32:54,240 --> 00:33:00,720
the photo is pretty much light and

00:32:57,600 --> 00:33:02,080
white if we have a negative brightness

00:33:00,720 --> 00:33:04,799
applied

00:33:02,080 --> 00:33:06,960
we can see the photo is very dark as in

00:33:04,799 --> 00:33:09,679
the same scenery applied with the

00:33:06,960 --> 00:33:12,080
negative brightness on this frame

00:33:09,679 --> 00:33:14,159
capture

00:33:12,080 --> 00:33:16,240
this exactly what i wanted to show you

00:33:14,159 --> 00:33:18,720
is the fact that brightness is an

00:33:16,240 --> 00:33:20,399
uh constant that is added to the

00:33:18,720 --> 00:33:22,880
luminosity path

00:33:20,399 --> 00:33:25,760
inside the pipeline this means that

00:33:22,880 --> 00:33:27,039
actual value of the pixel is being

00:33:25,760 --> 00:33:31,039
increased or decreased with the

00:33:27,039 --> 00:33:34,480
brightness value coming from the sensor

00:33:31,039 --> 00:33:37,200
so um we have this brightness we have

00:33:34,480 --> 00:33:39,919
exposure that is presented earlier

00:33:37,200 --> 00:33:40,799
and one question that can come to our

00:33:39,919 --> 00:33:43,519
mind is

00:33:40,799 --> 00:33:44,640
why do we need exposure if we have

00:33:43,519 --> 00:33:47,360
brightness

00:33:44,640 --> 00:33:48,799
and why do we need brightness if we have

00:33:47,360 --> 00:33:51,120
exposure

00:33:48,799 --> 00:33:52,000
the thing is that actually we they are

00:33:51,120 --> 00:33:56,080
not the same

00:33:52,000 --> 00:33:58,399
thing because the exposure will

00:33:56,080 --> 00:33:59,440
allow more or less light coming into the

00:33:58,399 --> 00:34:02,640
sensor

00:33:59,440 --> 00:34:04,960
so we need to have more

00:34:02,640 --> 00:34:06,480
information about the light incoming

00:34:04,960 --> 00:34:09,119
light while the brown

00:34:06,480 --> 00:34:09,839
brightness will actually remove some of

00:34:09,119 --> 00:34:11,679
the

00:34:09,839 --> 00:34:13,119
information some of the entropy that we

00:34:11,679 --> 00:34:14,879
receive from the sensor

00:34:13,119 --> 00:34:16,480
what i'm trying to say is that we have

00:34:14,879 --> 00:34:18,800
an overexposed

00:34:16,480 --> 00:34:20,159
photo or under exposed photo regardless

00:34:18,800 --> 00:34:21,760
of what we do with the brightness we

00:34:20,159 --> 00:34:22,480
will not obtain more data from the

00:34:21,760 --> 00:34:25,679
sensor

00:34:22,480 --> 00:34:27,520
if we have only bright pixels regardless

00:34:25,679 --> 00:34:29,440
of what brightness we apply

00:34:27,520 --> 00:34:31,440
we will get still pixels which are

00:34:29,440 --> 00:34:35,040
saturated so actually if

00:34:31,440 --> 00:34:37,200
our pixel can detect color or light on

00:34:35,040 --> 00:34:38,800
10 bits we will only use one bit or two

00:34:37,200 --> 00:34:39,280
bits so we lose color information we

00:34:38,800 --> 00:34:42,320
lose

00:34:39,280 --> 00:34:46,000
luminosity information by having a photo

00:34:42,320 --> 00:34:46,000
overexposed or underexposed

00:34:46,079 --> 00:34:51,520
so we need both brightness and exposure

00:34:49,040 --> 00:34:54,079
to obtain a good quality of photo

00:34:51,520 --> 00:34:55,520
once we have exposure set correctly we

00:34:54,079 --> 00:34:57,680
have enough pixel data

00:34:55,520 --> 00:35:01,359
so we can apply brightness a negative

00:34:57,680 --> 00:35:01,359
positive to obtain a better photo

00:35:01,520 --> 00:35:05,280
this was the difference between

00:35:03,920 --> 00:35:06,720
brightness and exposure and how we can

00:35:05,280 --> 00:35:10,480
use both to obtain

00:35:06,720 --> 00:35:11,839
high quality photo so this happens with

00:35:10,480 --> 00:35:13,760
pixel data

00:35:11,839 --> 00:35:16,720
we can see also on this small screen

00:35:13,760 --> 00:35:19,040
that you also have contrast i especially

00:35:16,720 --> 00:35:21,119
left this on the slide so we can move to

00:35:19,040 --> 00:35:23,839
contrast which we can see

00:35:21,119 --> 00:35:24,800
that contrast is actually a multiplier

00:35:23,839 --> 00:35:27,520
applied on the

00:35:24,800 --> 00:35:28,720
luminosity path but we expect that

00:35:27,520 --> 00:35:31,839
contrast

00:35:28,720 --> 00:35:34,000
also adjust its colors so if you look at

00:35:31,839 --> 00:35:36,960
the bigger picture we can see that

00:35:34,000 --> 00:35:40,320
brightness can apply as a constant

00:35:36,960 --> 00:35:42,240
towards our uh luminosity path

00:35:40,320 --> 00:35:44,160
brightness yes it's illuminati path and

00:35:42,240 --> 00:35:47,200
contrast will apply as a multiplier

00:35:44,160 --> 00:35:49,119
to both brightness and colors

00:35:47,200 --> 00:35:50,480
and to make it simple inside the

00:35:49,119 --> 00:35:52,480
hardware or inside the

00:35:50,480 --> 00:35:53,920
software we will use what is called the

00:35:52,480 --> 00:35:56,960
yuv representation

00:35:53,920 --> 00:36:00,079
in which we convert the rgb space to

00:35:56,960 --> 00:36:01,200
yuv and we have a separate path for

00:36:00,079 --> 00:36:03,280
luminosity

00:36:01,200 --> 00:36:04,800
and there are separate two paths for

00:36:03,280 --> 00:36:07,119
difference from blue and difference from

00:36:04,800 --> 00:36:09,280
red is called cb and cr

00:36:07,119 --> 00:36:11,280
and these are multiplied with the

00:36:09,280 --> 00:36:13,599
specific contrast

00:36:11,280 --> 00:36:15,520
and again video for linux can help us to

00:36:13,599 --> 00:36:16,960
control this hardware block

00:36:15,520 --> 00:36:19,280
through the interface through video

00:36:16,960 --> 00:36:21,760
information controls and can help us to

00:36:19,280 --> 00:36:25,200
try to obtain a better quality photo by

00:36:21,760 --> 00:36:28,800
adjusting these sliders these knobs

00:36:25,200 --> 00:36:30,560
on the interface and we can also see how

00:36:28,800 --> 00:36:31,680
the contrast can be applied to a

00:36:30,560 --> 00:36:33,520
specific photo and

00:36:31,680 --> 00:36:35,760
what are the differences in what is the

00:36:33,520 --> 00:36:37,200
effect that can have on the specific

00:36:35,760 --> 00:36:39,440
photo

00:36:37,200 --> 00:36:41,040
let's look at this photo this has a

00:36:39,440 --> 00:36:43,599
small contrast so the

00:36:41,040 --> 00:36:45,680
contrast is small the multiplier is

00:36:43,599 --> 00:36:48,880
somewhat subunitary that means that

00:36:45,680 --> 00:36:49,280
the values will be reduced and we can

00:36:48,880 --> 00:36:51,839
see

00:36:49,280 --> 00:36:54,079
that there is not much brightness and

00:36:51,839 --> 00:36:56,800
there's not much color in this photo

00:36:54,079 --> 00:36:57,599
with a low contrast applied if we apply

00:36:56,800 --> 00:37:00,320
a

00:36:57,599 --> 00:37:00,720
higher contrast we can see that there is

00:37:00,320 --> 00:37:02,079
also

00:37:00,720 --> 00:37:03,920
luminosity because contrast is

00:37:02,079 --> 00:37:05,440
multiplied on the luma path

00:37:03,920 --> 00:37:07,440
and we can also see that the difference

00:37:05,440 --> 00:37:08,960
is color is greater the difference in

00:37:07,440 --> 00:37:11,280
colors is greater

00:37:08,960 --> 00:37:13,280
because we also apply the contours as a

00:37:11,280 --> 00:37:16,480
multiplier between colors

00:37:13,280 --> 00:37:18,160
on the cb and cr paths the chroma paths

00:37:16,480 --> 00:37:20,560
in the ui uv representation of the

00:37:18,160 --> 00:37:20,560
colors

00:37:20,640 --> 00:37:25,040
so this was the the discussion related

00:37:23,599 --> 00:37:27,359
to contrast again

00:37:25,040 --> 00:37:29,440
you know foreign can help us to to

00:37:27,359 --> 00:37:30,320
modify and to alter the pipeline such

00:37:29,440 --> 00:37:33,280
that we

00:37:30,320 --> 00:37:34,400
can uh expect or try to experiment with

00:37:33,280 --> 00:37:37,280
our pipeline

00:37:34,400 --> 00:37:38,320
to see if we can obtain a better quality

00:37:37,280 --> 00:37:40,640
of the

00:37:38,320 --> 00:37:40,640
image

00:37:41,760 --> 00:37:46,400
again brightness and contrast from a

00:37:44,240 --> 00:37:47,119
very high level user perspective can be

00:37:46,400 --> 00:37:50,160
seen

00:37:47,119 --> 00:37:53,520
on an embedded linux camera

00:37:50,160 --> 00:37:54,480
just by having a fancy menu interface

00:37:53,520 --> 00:37:56,640
where you can just

00:37:54,480 --> 00:37:58,079
select with some buttons the the

00:37:56,640 --> 00:37:59,280
brightness in the contrast that you wish

00:37:58,079 --> 00:38:01,839
to be applied

00:37:59,280 --> 00:38:03,680
but in behind the scenes again video for

00:38:01,839 --> 00:38:05,760
linux api comes in and

00:38:03,680 --> 00:38:07,839
alters the pipeline through the driver

00:38:05,760 --> 00:38:11,520
directly to the hardware

00:38:07,839 --> 00:38:12,079
an underlying hardware so inside the

00:38:11,520 --> 00:38:14,960
system

00:38:12,079 --> 00:38:16,560
what happens is that the user through

00:38:14,960 --> 00:38:19,040
video for news control

00:38:16,560 --> 00:38:20,160
will alter the hardware block which is

00:38:19,040 --> 00:38:22,079
corresponding to the

00:38:20,160 --> 00:38:23,280
exposure correction contrast and

00:38:22,079 --> 00:38:24,960
brightness settings

00:38:23,280 --> 00:38:26,480
actually it will call the driver the

00:38:24,960 --> 00:38:28,000
sensor control driver

00:38:26,480 --> 00:38:30,400
which will compute the necessary

00:38:28,000 --> 00:38:32,560
adjustments and we'll

00:38:30,400 --> 00:38:34,240
configure the hardware accordingly such

00:38:32,560 --> 00:38:35,839
that the pixel stream that comes out

00:38:34,240 --> 00:38:38,800
from the hardware pipeline

00:38:35,839 --> 00:38:40,560
is somewhat more what the user expects

00:38:38,800 --> 00:38:43,599
to see in the resulting image

00:38:40,560 --> 00:38:45,520
that is then copied to the user space

00:38:43,599 --> 00:38:47,440
and the user can actually take this

00:38:45,520 --> 00:38:50,480
photo and then

00:38:47,440 --> 00:38:53,520
use it later on and have a look at it

00:38:50,480 --> 00:38:57,440
with the display so this is what

00:38:53,520 --> 00:38:57,440
happens inside the system

00:38:58,160 --> 00:39:02,880
so in the as a summary as a first

00:39:01,440 --> 00:39:04,000
summary of what i wanted to show you

00:39:02,880 --> 00:39:07,599
today

00:39:04,000 --> 00:39:10,320
is um a small explanation about

00:39:07,599 --> 00:39:10,960
um the fact that digital sensors need

00:39:10,320 --> 00:39:14,160
tuning

00:39:10,960 --> 00:39:15,520
user sensors just capture light convert

00:39:14,160 --> 00:39:18,560
it to binary data

00:39:15,520 --> 00:39:19,520
and then what happens in hardware and

00:39:18,560 --> 00:39:22,240
software

00:39:19,520 --> 00:39:24,000
is that we anyone can use a pipeline

00:39:22,240 --> 00:39:25,760
that is made of several modules that

00:39:24,000 --> 00:39:28,640
affect the pixel stream

00:39:25,760 --> 00:39:30,079
and this pipeline is also in harder but

00:39:28,640 --> 00:39:32,800
also in software

00:39:30,079 --> 00:39:34,800
and video foreign can modify or alter

00:39:32,800 --> 00:39:35,839
this pipeline through an interface or an

00:39:34,800 --> 00:39:37,760
api

00:39:35,839 --> 00:39:39,280
and help the user to obtain better

00:39:37,760 --> 00:39:41,520
quality photo

00:39:39,280 --> 00:39:43,359
i explained to you today some several

00:39:41,520 --> 00:39:46,560
issues or challenges that can appear

00:39:43,359 --> 00:39:49,839
during digital photography and

00:39:46,560 --> 00:39:52,000
how can a driver or specific hardware

00:39:49,839 --> 00:39:54,880
product or specific software

00:39:52,000 --> 00:39:56,320
can try to expose such settings to the

00:39:54,880 --> 00:39:59,119
user as

00:39:56,320 --> 00:40:00,880
video for linux captures the images and

00:39:59,119 --> 00:40:03,599
sends them to the user

00:40:00,880 --> 00:40:05,040
but it's somewhat somewhat agnostic of

00:40:03,599 --> 00:40:05,839
what happens here really inside the

00:40:05,040 --> 00:40:07,520
image

00:40:05,839 --> 00:40:09,200
we see what happens with the edge

00:40:07,520 --> 00:40:10,560
detection with interpolation how this

00:40:09,200 --> 00:40:12,640
can affect the photo

00:40:10,560 --> 00:40:14,079
we see what happens with white balancing

00:40:12,640 --> 00:40:17,359
brightness exposure

00:40:14,079 --> 00:40:18,720
contrast simple things or not so simple

00:40:17,359 --> 00:40:19,839
things which can affect digital

00:40:18,720 --> 00:40:22,839
photography

00:40:19,839 --> 00:40:23,839
how we can use linux and an embedded

00:40:22,839 --> 00:40:28,000
system building

00:40:23,839 --> 00:40:31,040
camera that can help us in obtaining

00:40:28,000 --> 00:40:33,520
better digital photography and we can

00:40:31,040 --> 00:40:34,560
see that with buttons with sliders with

00:40:33,520 --> 00:40:37,440
command line

00:40:34,560 --> 00:40:38,319
with a real camera that is in a box in

00:40:37,440 --> 00:40:41,520
fact has

00:40:38,319 --> 00:40:43,440
a pipeline inside the hardware and how

00:40:41,520 --> 00:40:45,200
this is exposed to the user space can be

00:40:43,440 --> 00:40:47,040
done for example like in this photo on

00:40:45,200 --> 00:40:50,160
the right side of the slide

00:40:47,040 --> 00:40:52,079
which you can see the exact

00:40:50,160 --> 00:40:53,200
sliders which are exposed during the

00:40:52,079 --> 00:40:55,599
presentation

00:40:53,200 --> 00:40:57,599
how they can be adjusted such that the

00:40:55,599 --> 00:41:00,160
user has a more visual interpretation of

00:40:57,599 --> 00:41:03,359
the controls

00:41:00,160 --> 00:41:04,000
another kind of summary is the exact

00:41:03,359 --> 00:41:07,200
complete

00:41:04,000 --> 00:41:11,200
view of the pipeline of the driver

00:41:07,200 --> 00:41:11,760
and how the sensor control driver can

00:41:11,200 --> 00:41:13,760
affect

00:41:11,760 --> 00:41:16,480
how the user can interact with the

00:41:13,760 --> 00:41:16,720
system to alter and to solve such kind

00:41:16,480 --> 00:41:20,000
of

00:41:16,720 --> 00:41:21,760
issues and challenges because normally

00:41:20,000 --> 00:41:23,359
things are not really seamless when you

00:41:21,760 --> 00:41:24,480
take a photo you just look at it

00:41:23,359 --> 00:41:26,720
there are a lot plenty of things

00:41:24,480 --> 00:41:26,960
happening behind the scenes and there

00:41:26,720 --> 00:41:29,520
are

00:41:26,960 --> 00:41:30,160
several parameters which can affect a

00:41:29,520 --> 00:41:33,440
lot

00:41:30,160 --> 00:41:37,040
the quality and the result of the photo

00:41:33,440 --> 00:41:40,000
this is the small summary of

00:41:37,040 --> 00:41:42,480
as a diagram of what happens inside the

00:41:40,000 --> 00:41:42,480
system

00:41:42,880 --> 00:41:49,839
and i will try also now to show you

00:41:46,400 --> 00:41:52,160
a small demonstration of

00:41:49,839 --> 00:41:54,400
exactly some things which happen which i

00:41:52,160 --> 00:41:57,839
discussed today during the presentation

00:41:54,400 --> 00:41:59,119
and for that i have a hard dedicated

00:41:57,839 --> 00:42:02,160
pipeline next to my site

00:41:59,119 --> 00:42:03,680
at this moment and i will while you see

00:42:02,160 --> 00:42:06,480
me on this uh

00:42:03,680 --> 00:42:07,119
webcam live preview i will also show you

00:42:06,480 --> 00:42:09,920
another

00:42:07,119 --> 00:42:11,119
uh live preview using uh our dedicated

00:42:09,920 --> 00:42:14,839
pipeline

00:42:11,119 --> 00:42:17,119
and to see this you will see a live

00:42:14,839 --> 00:42:20,079
preview

00:42:17,119 --> 00:42:21,680
which is exactly of what my camera is

00:42:20,079 --> 00:42:24,880
seeing right now

00:42:21,680 --> 00:42:28,880
so i have next to me a camera

00:42:24,880 --> 00:42:32,000
with our pipeline and it takes frames

00:42:28,880 --> 00:42:33,200
it performs the wire interpolation it

00:42:32,000 --> 00:42:36,400
converts into

00:42:33,200 --> 00:42:38,640
rgb it makes edge detection

00:42:36,400 --> 00:42:41,040
it performs color correction white

00:42:38,640 --> 00:42:44,000
balance gray world algorithm

00:42:41,040 --> 00:42:45,119
and it's the photo is then streamed over

00:42:44,000 --> 00:42:48,400
the network

00:42:45,119 --> 00:42:51,200
so you can see it and you can also see

00:42:48,400 --> 00:42:52,400
this time you can see me as well on this

00:42:51,200 --> 00:42:56,000
photo

00:42:52,400 --> 00:42:57,280
so hello and i will show you some

00:42:56,000 --> 00:43:00,400
examples of

00:42:57,280 --> 00:43:03,359
what happens in ambient scenery

00:43:00,400 --> 00:43:05,760
as we discussed maybe you remember this

00:43:03,359 --> 00:43:09,680
little friend

00:43:05,760 --> 00:43:13,839
which i uh shown you in the presentation

00:43:09,680 --> 00:43:17,200
and you can see if i get this

00:43:13,839 --> 00:43:19,599
card scorcher card nearby the camera

00:43:17,200 --> 00:43:20,480
how the white balance algorithm will

00:43:19,599 --> 00:43:23,119
apply

00:43:20,480 --> 00:43:25,200
and the auto white balance will adjust

00:43:23,119 --> 00:43:27,599
and try to understand

00:43:25,200 --> 00:43:29,760
how different colors are adjusted you

00:43:27,599 --> 00:43:32,800
can see now

00:43:29,760 --> 00:43:36,160
the light becomes maybe more bluish

00:43:32,800 --> 00:43:38,640
because at some point it will detect

00:43:36,160 --> 00:43:39,359
it will try to adjust the gray and we do

00:43:38,640 --> 00:43:43,040
not have an

00:43:39,359 --> 00:43:46,000
average gray in this scenery

00:43:43,040 --> 00:43:47,520
you can see how the algorithm will auto

00:43:46,000 --> 00:43:49,200
adjust itself

00:43:47,520 --> 00:43:50,880
to the ambient light now it's more

00:43:49,200 --> 00:43:52,960
greenish and now it's adjusted

00:43:50,880 --> 00:43:55,520
it's adjusted again to the ambient

00:43:52,960 --> 00:43:57,440
scenery

00:43:55,520 --> 00:43:59,520
this ecological card can help us with

00:43:57,440 --> 00:44:02,960
that so once we have the

00:43:59,520 --> 00:44:04,880
ecological card inside the full frame

00:44:02,960 --> 00:44:07,280
the colors are perfect according to the

00:44:04,880 --> 00:44:10,240
grey world algorithm

00:44:07,280 --> 00:44:12,400
once we remove it it will try to adjust

00:44:10,240 --> 00:44:14,240
to what's in the scenery maybe it's gray

00:44:12,400 --> 00:44:16,480
maybe it's not gray maybe

00:44:14,240 --> 00:44:18,319
if you see something like this fully red

00:44:16,480 --> 00:44:20,839
it will try to adjust this red

00:44:18,319 --> 00:44:23,359
to gray which is a pitfall of the

00:44:20,839 --> 00:44:26,000
algorithm

00:44:23,359 --> 00:44:27,280
so this is what i wanted to show you

00:44:26,000 --> 00:44:28,800
related to

00:44:27,280 --> 00:44:30,960
white balance and what we discussed

00:44:28,800 --> 00:44:33,359
today during this presentation

00:44:30,960 --> 00:44:35,359
i hope you enjoyed this live demo even

00:44:33,359 --> 00:44:38,720
if it's

00:44:35,359 --> 00:44:43,599
not not on the moment but it's

00:44:38,720 --> 00:44:48,079
live right now as i'm recording this

00:44:43,599 --> 00:44:50,560
and this is all related to the

00:44:48,079 --> 00:44:51,680
presentation we have a separate

00:44:50,560 --> 00:44:54,640
questions

00:44:51,680 --> 00:44:55,839
q and a section and in the end i

00:44:54,640 --> 00:44:57,920
provided with

00:44:55,839 --> 00:44:59,040
resources related to where is the driver

00:44:57,920 --> 00:45:02,319
inside the linux kernel

00:44:59,040 --> 00:45:04,240
and links to all the photos and the

00:45:02,319 --> 00:45:06,079
board that was used to capture the

00:45:04,240 --> 00:45:08,079
scenery that you've seen in today's

00:45:06,079 --> 00:45:10,800
presentation

00:45:08,079 --> 00:45:11,200
so thank you very much for attending the

00:45:10,800 --> 00:45:13,119
video

00:45:11,200 --> 00:45:15,760
challenges of using beautiful news 2 to

00:45:13,119 --> 00:45:18,480
capture and process video images

00:45:15,760 --> 00:45:19,119
i hope the presentation was of interest

00:45:18,480 --> 00:45:22,160
for

00:45:19,119 --> 00:45:25,280
at least some of you and i wait for you

00:45:22,160 --> 00:45:33,839
for the live q a session

00:45:25,280 --> 00:45:33,839

YouTube URL: https://www.youtube.com/watch?v=kNYplyluP4s


