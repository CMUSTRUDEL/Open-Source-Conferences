Title: Building Trustworthy AI: Lessons from Open Source - Abigail Cabunoc Mayes, Mozilla
Publication date: 2020-10-29
Playlist: Open Source Summit & Embedded Linux Conference Europe 2020
Description: 
	Building Trustworthy AI: Lessons from Open Source - Abigail Cabunoc Mayes, Mozilla
Captions: 
	00:00:06,080 --> 00:00:10,160
hi everyone uh welcome to my talk

00:00:08,320 --> 00:00:11,840
i'm really thrilled to be here to talk

00:00:10,160 --> 00:00:14,559
to you about building trustworthy ai

00:00:11,840 --> 00:00:16,320
lessons from open source uh so first off

00:00:14,559 --> 00:00:17,760
huge thanks to all the organizers and

00:00:16,320 --> 00:00:19,680
for all of you watching

00:00:17,760 --> 00:00:21,520
i really appreciate it um i really

00:00:19,680 --> 00:00:23,840
appreciate your support and your help

00:00:21,520 --> 00:00:25,119
and so hi my name is abby abby cubanock

00:00:23,840 --> 00:00:26,960
maze

00:00:25,119 --> 00:00:29,199
i lead mozilla's developer focus

00:00:26,960 --> 00:00:30,480
strategy around trustworthy ai and open

00:00:29,199 --> 00:00:32,960
source

00:00:30,480 --> 00:00:34,640
around mozfest and before this i founded

00:00:32,960 --> 00:00:36,960
and led mozilla open leaders

00:00:34,640 --> 00:00:37,920
we just worked with over 600 projects

00:00:36,960 --> 00:00:40,000
globally

00:00:37,920 --> 00:00:42,160
and i really want to take these lessons

00:00:40,000 --> 00:00:43,680
from working with so many open projects

00:00:42,160 --> 00:00:45,280
and see how we can apply this to

00:00:43,680 --> 00:00:47,440
trustworthy ai and building machine

00:00:45,280 --> 00:00:50,640
learning technology today

00:00:47,440 --> 00:00:52,800
so let's get my slides up

00:00:50,640 --> 00:00:55,039
and there you can also see my twitter

00:00:52,800 --> 00:00:58,000
handle there i'm abbycabs on twitter

00:00:55,039 --> 00:00:59,359
um and i'm a kabunak on github so if you

00:00:58,000 --> 00:00:59,760
have any questions at all during this

00:00:59,359 --> 00:01:01,920
talk

00:00:59,760 --> 00:01:02,800
feel free to put me there or if you're

00:01:01,920 --> 00:01:06,080
watching the recording

00:01:02,800 --> 00:01:06,080
you can follow up with me afterwards

00:01:06,400 --> 00:01:10,240
so let's get started i do want to talk

00:01:08,400 --> 00:01:13,680
about three things today

00:01:10,240 --> 00:01:15,360
uh first is how ai influences our lives

00:01:13,680 --> 00:01:17,119
i think this is obvious to many of us

00:01:15,360 --> 00:01:18,320
but i just wanted to recap this in a

00:01:17,119 --> 00:01:21,439
little bit

00:01:18,320 --> 00:01:23,840
a second that code is power and then

00:01:21,439 --> 00:01:24,960
third open source practices can shift

00:01:23,840 --> 00:01:26,640
power

00:01:24,960 --> 00:01:28,080
and i think that'll be the bulk of my

00:01:26,640 --> 00:01:31,040
talk today

00:01:28,080 --> 00:01:33,439
so first up ai influence our lives let's

00:01:31,040 --> 00:01:35,360
take a look at some ai today

00:01:33,439 --> 00:01:37,759
and if you've been on the internet at

00:01:35,360 --> 00:01:40,320
all over the summer you may have seen

00:01:37,759 --> 00:01:42,079
this language model released by openai

00:01:40,320 --> 00:01:46,159
called gpth3

00:01:42,079 --> 00:01:48,640
and that first example on the left

00:01:46,159 --> 00:01:50,799
really is mind-blowing but he built a

00:01:48,640 --> 00:01:52,640
layout generator where he just describes

00:01:50,799 --> 00:01:54,799
the layout he wants

00:01:52,640 --> 00:01:57,280
i think it's he's saying um yes

00:01:54,799 --> 00:02:00,640
something says welcome to my newsletter

00:01:57,280 --> 00:02:02,240
and then gbt3 actually generates working

00:02:00,640 --> 00:02:04,159
jsx code

00:02:02,240 --> 00:02:05,680
um that creates that website so it

00:02:04,159 --> 00:02:07,280
really blows my mind and you can watch

00:02:05,680 --> 00:02:08,000
him just sort of editing what he types

00:02:07,280 --> 00:02:11,120
there

00:02:08,000 --> 00:02:13,760
and then the code just it just generates

00:02:11,120 --> 00:02:17,360
that code magically it's pretty amazing

00:02:13,760 --> 00:02:19,920
and then as a compliment to that um

00:02:17,360 --> 00:02:20,560
i brought on this other tweet by janelle

00:02:19,920 --> 00:02:23,200
shane

00:02:20,560 --> 00:02:24,800
so she blogs at aiweerness.com which i

00:02:23,200 --> 00:02:26,879
highly recommend

00:02:24,800 --> 00:02:27,920
um but she and put the part in bold she

00:02:26,879 --> 00:02:30,239
wrote janelle shane

00:02:27,920 --> 00:02:31,280
stared at her computer screen and then

00:02:30,239 --> 00:02:32,720
gpt-3

00:02:31,280 --> 00:02:34,959
generated the rest of this which is

00:02:32,720 --> 00:02:37,040
pretty amazing it says it was filled

00:02:34,959 --> 00:02:38,400
with 300 lines of carefully written

00:02:37,040 --> 00:02:40,319
python code

00:02:38,400 --> 00:02:42,560
it was the best code she'd ever written

00:02:40,319 --> 00:02:44,879
the best code anyone had ever written

00:02:42,560 --> 00:02:46,560
it was way better than her old code

00:02:44,879 --> 00:02:47,360
which was better than her supervisor's

00:02:46,560 --> 00:02:48,959
code

00:02:47,360 --> 00:02:51,440
which was better than her co-workers

00:02:48,959 --> 00:02:52,560
code it was better than any code she'd

00:02:51,440 --> 00:02:54,160
ever read

00:02:52,560 --> 00:02:57,200
better than any code she'd ever heard

00:02:54,160 --> 00:03:00,159
about she stared at it for a long time

00:02:57,200 --> 00:03:01,440
then she deleted it and i thought that

00:03:00,159 --> 00:03:03,760
was so poetic

00:03:01,440 --> 00:03:05,200
and it has this nice spectrum of gpt3

00:03:03,760 --> 00:03:09,840
being able to generate

00:03:05,200 --> 00:03:11,920
both working code and beautiful poetry

00:03:09,840 --> 00:03:13,120
um that poetry that really spoke to me

00:03:11,920 --> 00:03:14,720
as someone who's

00:03:13,120 --> 00:03:17,680
written some beautiful code in the past

00:03:14,720 --> 00:03:19,920
but then had to delete it off

00:03:17,680 --> 00:03:21,440
so this is um obviously i think there's

00:03:19,920 --> 00:03:22,959
probably a bit of cherry picking in

00:03:21,440 --> 00:03:26,159
these examples

00:03:22,959 --> 00:03:28,799
but it does raise a few risks

00:03:26,159 --> 00:03:29,599
and i will say that open ai ai has been

00:03:28,799 --> 00:03:32,000
pretty good at

00:03:29,599 --> 00:03:33,440
regulating the production apps using

00:03:32,000 --> 00:03:35,440
gpt3

00:03:33,440 --> 00:03:37,760
to help prevent some of these risks but

00:03:35,440 --> 00:03:40,720
these risks are still there

00:03:37,760 --> 00:03:43,040
so this is an article that was written

00:03:40,720 --> 00:03:45,440
actually last year in response to gpt2

00:03:43,040 --> 00:03:48,560
the precursor to dpt3

00:03:45,440 --> 00:03:50,720
and in here they interview um jeremy

00:03:48,560 --> 00:03:53,280
howard the co-founder of fastai

00:03:50,720 --> 00:03:55,280
and he says we have the technology to

00:03:53,280 --> 00:03:55,840
totally fill twitter email and the web

00:03:55,280 --> 00:03:57,599
app

00:03:55,840 --> 00:03:58,879
with reasonable sounding context

00:03:57,599 --> 00:04:00,480
appropriate prose

00:03:58,879 --> 00:04:02,560
which would drown out all other speech

00:04:00,480 --> 00:04:04,640
and be impossible to filter

00:04:02,560 --> 00:04:05,920
and it's a little scary thinking about

00:04:04,640 --> 00:04:07,439
twitter being filled with this

00:04:05,920 --> 00:04:09,840
auto-generated content and what that

00:04:07,439 --> 00:04:11,760
could mean

00:04:09,840 --> 00:04:13,760
and then rachel thomas the other

00:04:11,760 --> 00:04:15,680
co-founder of fast ai

00:04:13,760 --> 00:04:17,519
she's also the director of the center

00:04:15,680 --> 00:04:20,160
for applied science at

00:04:17,519 --> 00:04:21,919
center for applied data ethics sorry at

00:04:20,160 --> 00:04:25,040
usf

00:04:21,919 --> 00:04:27,280
and here she talks about how in 2017 the

00:04:25,040 --> 00:04:29,680
fcc received over a million

00:04:27,280 --> 00:04:32,240
fake pro-repeal net neutrality comments

00:04:29,680 --> 00:04:34,320
so anti-net neutrality comments

00:04:32,240 --> 00:04:36,240
that had a kind of mad lib structure to

00:04:34,320 --> 00:04:37,360
them so if you look at the examples i

00:04:36,240 --> 00:04:38,080
don't know if it's big enough for you to

00:04:37,360 --> 00:04:39,919
see here

00:04:38,080 --> 00:04:42,400
but like all the green pieces it's just

00:04:39,919 --> 00:04:45,440
replacing americans

00:04:42,400 --> 00:04:46,400
with individual citizens or with people

00:04:45,440 --> 00:04:49,280
like me

00:04:46,400 --> 00:04:50,639
and it's just it's just like mail merge

00:04:49,280 --> 00:04:52,639
style

00:04:50,639 --> 00:04:54,080
uh replacements across all of these so

00:04:52,639 --> 00:04:56,320
it was pretty easy

00:04:54,080 --> 00:04:58,000
to figure out that these were fake but

00:04:56,320 --> 00:04:59,040
consider how much more sophisticated

00:04:58,000 --> 00:05:02,000
these would be

00:04:59,040 --> 00:05:03,520
with gpt-3 powering them it would be

00:05:02,000 --> 00:05:06,720
really hard to detect

00:05:03,520 --> 00:05:08,479
um and it has the potential to really

00:05:06,720 --> 00:05:10,320
sway where things go

00:05:08,479 --> 00:05:12,080
where if you think public opinion is

00:05:10,320 --> 00:05:14,720
swaying in one way but in reality it's

00:05:12,080 --> 00:05:18,080
just one person with a gpt3

00:05:14,720 --> 00:05:21,039
generating them all so that's gpt3

00:05:18,080 --> 00:05:22,320
some risks there um another one that's

00:05:21,039 --> 00:05:24,800
gotten a lot of press

00:05:22,320 --> 00:05:26,400
is uh youtube's recommendation system so

00:05:24,800 --> 00:05:27,440
this is a great article by zainab

00:05:26,400 --> 00:05:28,880
tufekci

00:05:27,440 --> 00:05:30,479
she's a researcher on social movements

00:05:28,880 --> 00:05:31,759
but she's also been writing a lot about

00:05:30,479 --> 00:05:33,520
copen19

00:05:31,759 --> 00:05:35,039
um so you're probably familiar with her

00:05:33,520 --> 00:05:38,160
work there

00:05:35,039 --> 00:05:40,720
and in this article back from 2018

00:05:38,160 --> 00:05:43,199
she talks about how this algorithm is

00:05:40,720 --> 00:05:45,360
just continually recommending

00:05:43,199 --> 00:05:46,479
and auto playing more and more radical

00:05:45,360 --> 00:05:47,919
content

00:05:46,479 --> 00:05:50,160
because that's what's keeping people

00:05:47,919 --> 00:05:53,360
staying on youtube longer

00:05:50,160 --> 00:05:53,919
so it's led to the radicalization of a

00:05:53,360 --> 00:05:55,680
lot of

00:05:53,919 --> 00:05:57,199
people and led to the rise in the

00:05:55,680 --> 00:05:59,360
anti-vaccine movement

00:05:57,199 --> 00:06:00,400
white supremacy and more so it's a

00:05:59,360 --> 00:06:04,000
little scary just

00:06:00,400 --> 00:06:04,319
how an ai a simple recommendation engine

00:06:04,000 --> 00:06:08,319
has

00:06:04,319 --> 00:06:08,319
really affected society so much

00:06:08,960 --> 00:06:14,560
so those are just two examples of how ai

00:06:13,199 --> 00:06:16,160
influences our lives

00:06:14,560 --> 00:06:18,000
and i didn't want this to be too much of

00:06:16,160 --> 00:06:20,240
a downer so i'm just gonna

00:06:18,000 --> 00:06:21,919
leave it at those two i want this talk

00:06:20,240 --> 00:06:23,360
to be mostly positive

00:06:21,919 --> 00:06:27,120
and the lessons we can learn from open

00:06:23,360 --> 00:06:29,600
source so we'll move on to code is power

00:06:27,120 --> 00:06:30,800
and i think it is easy to feel like

00:06:29,600 --> 00:06:32,960
you're just

00:06:30,800 --> 00:06:34,000
a lowly engineer you don't really have a

00:06:32,960 --> 00:06:36,800
say in what the product

00:06:34,000 --> 00:06:38,479
is doing or how it's used but you have

00:06:36,800 --> 00:06:40,800
so much power as someone who's building

00:06:38,479 --> 00:06:42,319
this technology that people use

00:06:40,800 --> 00:06:43,919
and i think it's important to recognize

00:06:42,319 --> 00:06:47,199
the power that you have

00:06:43,919 --> 00:06:49,520
and if marvel has taught me anything

00:06:47,199 --> 00:06:50,720
is that with a great power comes a great

00:06:49,520 --> 00:06:53,759
responsibility

00:06:50,720 --> 00:06:58,400
and i just i just i do really love this

00:06:53,759 --> 00:07:01,360
picture super cute

00:06:58,400 --> 00:07:02,080
um yeah we do have a lot of power and i

00:07:01,360 --> 00:07:05,280
think

00:07:02,080 --> 00:07:08,160
um this next slide that from

00:07:05,280 --> 00:07:09,599
uh jamel watson daniel i caught her talk

00:07:08,160 --> 00:07:11,840
at the participatory approaches to

00:07:09,599 --> 00:07:13,759
machine learning workshop in the summer

00:07:11,840 --> 00:07:15,599
and i just i love the slide so much i

00:07:13,759 --> 00:07:18,560
just cut and paste it

00:07:15,599 --> 00:07:20,960
right into this talk here but she talks

00:07:18,560 --> 00:07:21,919
about these power imbalances in machine

00:07:20,960 --> 00:07:24,800
learning

00:07:21,919 --> 00:07:25,919
so as a technical community you and i we

00:07:24,800 --> 00:07:28,479
have control over

00:07:25,919 --> 00:07:29,680
what data is collected what data is used

00:07:28,479 --> 00:07:31,680
for training

00:07:29,680 --> 00:07:34,160
how much to reveal about training data

00:07:31,680 --> 00:07:35,120
sets choosing models to be applied to

00:07:34,160 --> 00:07:37,599
data

00:07:35,120 --> 00:07:39,680
interpreting models and model outputs

00:07:37,599 --> 00:07:42,479
assessment and verification of models

00:07:39,680 --> 00:07:44,479
deployment of algorithms based on models

00:07:42,479 --> 00:07:46,639
and i think even past this

00:07:44,479 --> 00:07:48,800
every time you're tweaking a variable or

00:07:46,639 --> 00:07:51,440
waving something a little bit different

00:07:48,800 --> 00:07:53,199
that has real effects downstream that

00:07:51,440 --> 00:07:55,280
you might not know about

00:07:53,199 --> 00:07:56,479
and so this really i think this slide

00:07:55,280 --> 00:07:58,319
really highlights

00:07:56,479 --> 00:07:59,599
this power balance how people in the

00:07:58,319 --> 00:08:01,840
technical community

00:07:59,599 --> 00:08:03,120
have so much power shaping what's being

00:08:01,840 --> 00:08:06,160
used and consumed

00:08:03,120 --> 00:08:06,160
by the rest of the world

00:08:06,240 --> 00:08:09,680
so this next slide might seem like a bit

00:08:07,919 --> 00:08:11,280
of a non-sequitur

00:08:09,680 --> 00:08:12,800
but over the summer i did join a book

00:08:11,280 --> 00:08:15,520
club where we read

00:08:12,800 --> 00:08:17,440
how to be anti-racist by even mex candy

00:08:15,520 --> 00:08:18,720
and one of the big takeaways from this

00:08:17,440 --> 00:08:20,319
book for me

00:08:18,720 --> 00:08:22,639
was this idea that the opposite of

00:08:20,319 --> 00:08:25,120
racist isn't not racist

00:08:22,639 --> 00:08:26,160
but it's anti-racist so this idea that

00:08:25,120 --> 00:08:28,720
if you just go through

00:08:26,160 --> 00:08:29,840
life being neutral and just like not

00:08:28,720 --> 00:08:31,919
being a racist

00:08:29,840 --> 00:08:34,320
you're still implicitly supporting the

00:08:31,919 --> 00:08:35,200
existing structures and existing bias in

00:08:34,320 --> 00:08:37,519
society

00:08:35,200 --> 00:08:38,240
so by doing nothing you're still

00:08:37,519 --> 00:08:41,039
supporting

00:08:38,240 --> 00:08:42,399
racism so he really calls for us to be

00:08:41,039 --> 00:08:45,040
anti-racist

00:08:42,399 --> 00:08:46,560
and look ways where we can shift power

00:08:45,040 --> 00:08:48,160
and change those power structures and

00:08:46,560 --> 00:08:50,000
dynamics

00:08:48,160 --> 00:08:51,200
so i bring this up because i'm seeing a

00:08:50,000 --> 00:08:54,320
really a similar

00:08:51,200 --> 00:08:55,890
through line with ai

00:08:54,320 --> 00:08:57,519
so over the summer um

00:08:55,890 --> 00:08:59,519
[Music]

00:08:57,519 --> 00:09:01,120
patricia clory from stanford and the

00:08:59,519 --> 00:09:03,440
co-creator of the radical ai network

00:09:01,120 --> 00:09:05,360
wrote this nature commentary piece

00:09:03,440 --> 00:09:06,959
where she writes that many researchers

00:09:05,360 --> 00:09:09,440
think that ai is neutral

00:09:06,959 --> 00:09:12,399
and often beneficial marred only by

00:09:09,440 --> 00:09:14,399
biased data drawn from an unfair society

00:09:12,399 --> 00:09:15,920
in reality an indifferent field serves

00:09:14,399 --> 00:09:19,040
the powerful

00:09:15,920 --> 00:09:21,279
and i thought that was really powerful

00:09:19,040 --> 00:09:22,640
a really powerful idea just a lot of

00:09:21,279 --> 00:09:25,360
times we think of

00:09:22,640 --> 00:09:27,200
technology and ai as being neutral and

00:09:25,360 --> 00:09:28,720
it's just neutral technology

00:09:27,200 --> 00:09:30,640
but by being neutral it's just

00:09:28,720 --> 00:09:32,160
amplifying the bias that's already there

00:09:30,640 --> 00:09:34,240
and making it even worse

00:09:32,160 --> 00:09:36,080
like we saw with the youtube

00:09:34,240 --> 00:09:39,120
recommendation engine

00:09:36,080 --> 00:09:40,160
so she really calls for us to ask how ai

00:09:39,120 --> 00:09:42,080
ships power

00:09:40,160 --> 00:09:44,399
rather than asks if it's any good or

00:09:42,080 --> 00:09:44,399
fair

00:09:46,720 --> 00:09:50,240
all right this brings me to the last

00:09:48,160 --> 00:09:52,640
point open source practices

00:09:50,240 --> 00:09:54,720
can shift power and if you're keeping

00:09:52,640 --> 00:09:56,320
time i think majority of my talk will be

00:09:54,720 --> 00:09:58,399
on this section

00:09:56,320 --> 00:09:59,760
so i do want to start with a story and

00:09:58,399 --> 00:10:02,320
just look back at

00:09:59,760 --> 00:10:03,120
the history of open source so it starts

00:10:02,320 --> 00:10:06,160
with

00:10:03,120 --> 00:10:07,040
a mosaic browser and that skip navigator

00:10:06,160 --> 00:10:08,720
after that

00:10:07,040 --> 00:10:10,079
and this is a time when millions of

00:10:08,720 --> 00:10:12,880
people were discovering this new

00:10:10,079 --> 00:10:15,440
resource the internet for the first time

00:10:12,880 --> 00:10:16,480
and pretty quickly microsoft uses

00:10:15,440 --> 00:10:18,720
windows to turn

00:10:16,480 --> 00:10:20,800
internet explorer into monopoly so if

00:10:18,720 --> 00:10:23,040
you look in the early 2000s

00:10:20,800 --> 00:10:24,399
internet explorer had almost 100 of the

00:10:23,040 --> 00:10:26,800
browser usage

00:10:24,399 --> 00:10:27,680
and this gave microsoft a ton of power

00:10:26,800 --> 00:10:29,200
over the web

00:10:27,680 --> 00:10:30,959
so there's a quote from mitchell baker

00:10:29,200 --> 00:10:32,720
on what she saw at the time she's the

00:10:30,959 --> 00:10:34,399
founder and ceo of mozilla

00:10:32,720 --> 00:10:36,320
she said the internet was going to be a

00:10:34,399 --> 00:10:38,640
stack of microsoft products

00:10:36,320 --> 00:10:40,399
from windows to internet explorer to

00:10:38,640 --> 00:10:43,360
office to servers

00:10:40,399 --> 00:10:45,519
to file formats to protocols and you

00:10:43,360 --> 00:10:47,680
know that's almost the entire stack

00:10:45,519 --> 00:10:49,200
and there was a real risk that microsoft

00:10:47,680 --> 00:10:50,240
was going to move the web in its own

00:10:49,200 --> 00:10:52,160
direction

00:10:50,240 --> 00:10:55,360
away from these open building blocks

00:10:52,160 --> 00:10:57,519
that we come to know of as the open web

00:10:55,360 --> 00:10:59,120
so netscape did something that's pretty

00:10:57,519 --> 00:11:01,839
radical at the time

00:10:59,120 --> 00:11:03,680
they publicly released the code behind

00:11:01,839 --> 00:11:08,000
their browser for anyone to use

00:11:03,680 --> 00:11:10,560
copy remix and share and

00:11:08,000 --> 00:11:12,880
actually this action was the first time

00:11:10,560 --> 00:11:14,320
that the term open source was used

00:11:12,880 --> 00:11:15,760
in reaction to this so i thought that

00:11:14,320 --> 00:11:18,240
was pretty cool a nice piece of history

00:11:15,760 --> 00:11:20,240
with open source

00:11:18,240 --> 00:11:22,160
so yeah with the code out there in the

00:11:20,240 --> 00:11:23,920
wild people started to band together and

00:11:22,160 --> 00:11:25,760
call themselves mozilla

00:11:23,920 --> 00:11:26,959
it's this informal community of

00:11:25,760 --> 00:11:30,399
designers

00:11:26,959 --> 00:11:33,040
engineers writers community organizers

00:11:30,399 --> 00:11:35,120
that really wanted to take this open

00:11:33,040 --> 00:11:36,480
source code and build something together

00:11:35,120 --> 00:11:38,320
build something better than they could

00:11:36,480 --> 00:11:41,360
on their own

00:11:38,320 --> 00:11:44,079
and they did they released firefox

00:11:41,360 --> 00:11:45,200
a few years after and mozilla actually

00:11:44,079 --> 00:11:48,320
took out an ad

00:11:45,200 --> 00:11:49,279
in the new york times where um on that

00:11:48,320 --> 00:11:51,600
left-hand side

00:11:49,279 --> 00:11:53,600
say all those tiny words behind the logo

00:11:51,600 --> 00:11:56,000
they actually printed the names

00:11:53,600 --> 00:11:57,120
of every single contributor to firefox

00:11:56,000 --> 00:11:59,040
to really show that this was a

00:11:57,120 --> 00:12:00,480
grassroots effort this was a community

00:11:59,040 --> 00:12:02,399
of people that came together

00:12:00,480 --> 00:12:04,639
it wasn't just like a microsoft or

00:12:02,399 --> 00:12:06,320
netscape but really this big group

00:12:04,639 --> 00:12:07,839
that wanted to build something that no

00:12:06,320 --> 00:12:10,399
one else had

00:12:07,839 --> 00:12:11,440
and this was a huge hit people loved it

00:12:10,399 --> 00:12:14,079
it was fast

00:12:11,440 --> 00:12:16,320
there was pop-up blocking and you know

00:12:14,079 --> 00:12:16,880
it obviously didn't put microsoft out of

00:12:16,320 --> 00:12:19,600
business

00:12:16,880 --> 00:12:21,279
microsoft is still here but it did break

00:12:19,600 --> 00:12:23,120
up their monopoly over the web

00:12:21,279 --> 00:12:25,040
and really gave us the web we have today

00:12:23,120 --> 00:12:26,800
where we still have these open building

00:12:25,040 --> 00:12:28,639
blocks of the web

00:12:26,800 --> 00:12:30,560
and um yeah it really sparked this new

00:12:28,639 --> 00:12:32,959
way of thinking around open

00:12:30,560 --> 00:12:35,519
and modern life and this isn't the only

00:12:32,959 --> 00:12:36,959
time we've seen the story like this

00:12:35,519 --> 00:12:39,040
i'm a little bit biased when i picked

00:12:36,959 --> 00:12:40,720
firefox but really i could have picked

00:12:39,040 --> 00:12:44,560
any of these examples

00:12:40,720 --> 00:12:46,959
and it's it's really exciting to see how

00:12:44,560 --> 00:12:49,279
open source has really democratized a

00:12:46,959 --> 00:12:50,800
lot of the technology we have today

00:12:49,279 --> 00:12:52,560
and i do want to point out at the bottom

00:12:50,800 --> 00:12:53,920
there are organizations like the free

00:12:52,560 --> 00:12:55,519
software foundation

00:12:53,920 --> 00:12:57,839
the open source initiative and even

00:12:55,519 --> 00:13:00,079
creative commons that are really vetting

00:12:57,839 --> 00:13:02,560
and stewarding these open licenses

00:13:00,079 --> 00:13:04,320
so that everyone can do the same thing

00:13:02,560 --> 00:13:06,800
that mozilla did

00:13:04,320 --> 00:13:07,760
everyone can start an open project and

00:13:06,800 --> 00:13:09,839
today

00:13:07,760 --> 00:13:12,320
if you open a github project it's just a

00:13:09,839 --> 00:13:14,560
drop-down menu of open licenses it's so

00:13:12,320 --> 00:13:17,279
easy to pick a license and then just

00:13:14,560 --> 00:13:19,920
build something great with it so that

00:13:17,279 --> 00:13:21,600
was a fun story about open source

00:13:19,920 --> 00:13:23,360
but i do want to look at a few lessons

00:13:21,600 --> 00:13:25,839
from that story

00:13:23,360 --> 00:13:27,279
so the first one is that it was a legal

00:13:25,839 --> 00:13:29,279
mechanism

00:13:27,279 --> 00:13:32,000
that sort of sparked itself off and that

00:13:29,279 --> 00:13:34,720
enabled lesson two the collective action

00:13:32,000 --> 00:13:36,480
that improved innovation and then all of

00:13:34,720 --> 00:13:38,720
this was reproducible through

00:13:36,480 --> 00:13:39,680
number three reusable structures so i'm

00:13:38,720 --> 00:13:41,040
going to go through each of those

00:13:39,680 --> 00:13:43,600
individually

00:13:41,040 --> 00:13:46,000
so first is that legal mechanism so in

00:13:43,600 --> 00:13:47,680
netscape set their open source code free

00:13:46,000 --> 00:13:50,240
um they actually wrote a license called

00:13:47,680 --> 00:13:52,240
mozilla public license 1.0

00:13:50,240 --> 00:13:53,760
that enabled anyone to use remix

00:13:52,240 --> 00:13:55,760
distribute that work

00:13:53,760 --> 00:13:57,760
and in terms of shifting power this

00:13:55,760 --> 00:14:00,639
mechanism protected user rights

00:13:57,760 --> 00:14:02,560
and made it possible for the public to

00:14:00,639 --> 00:14:03,839
use and help shape that code

00:14:02,560 --> 00:14:05,760
so that brings us to the second point

00:14:03,839 --> 00:14:07,600
that collective action where the

00:14:05,760 --> 00:14:09,760
grassroots community came together

00:14:07,600 --> 00:14:12,160
that happened because of step one but

00:14:09,760 --> 00:14:14,160
they did it by working openly

00:14:12,160 --> 00:14:16,160
so my favorite definition of working

00:14:14,160 --> 00:14:17,760
open is from the mozilla wiki

00:14:16,160 --> 00:14:19,360
where it talks about being both public

00:14:17,760 --> 00:14:21,440
and participatory

00:14:19,360 --> 00:14:22,800
this requires structuring efforts so

00:14:21,440 --> 00:14:24,800
that outsiders can meaningfully

00:14:22,800 --> 00:14:26,560
participate and become insiders as

00:14:24,800 --> 00:14:29,360
appropriate

00:14:26,560 --> 00:14:30,000
so this shifts power by allowing others

00:14:29,360 --> 00:14:32,480
to co-create

00:14:30,000 --> 00:14:34,079
with you it allows outsiders to have

00:14:32,480 --> 00:14:35,040
power and shape what you're making in

00:14:34,079 --> 00:14:37,040
the end

00:14:35,040 --> 00:14:39,120
so i think this is a great example of

00:14:37,040 --> 00:14:41,360
like democratizing technology

00:14:39,120 --> 00:14:44,000
and using that collective action uh to

00:14:41,360 --> 00:14:45,519
shift power

00:14:44,000 --> 00:14:47,760
and then the third one is that reusable

00:14:45,519 --> 00:14:48,959
structure like we've seen this happen

00:14:47,760 --> 00:14:51,440
time and time again

00:14:48,959 --> 00:14:52,320
because of groups like the free software

00:14:51,440 --> 00:14:54,000
foundation

00:14:52,320 --> 00:14:55,600
the open source initiative and creative

00:14:54,000 --> 00:14:57,680
commons who are vetting and

00:14:55,600 --> 00:14:59,760
standardizing these open licenses

00:14:57,680 --> 00:15:01,760
and make it so easy to start an open

00:14:59,760 --> 00:15:04,320
license or an open project today

00:15:01,760 --> 00:15:05,839
i don't need a lawyer i can just pick a

00:15:04,320 --> 00:15:06,959
license i don't even need to sign

00:15:05,839 --> 00:15:09,519
anything it's

00:15:06,959 --> 00:15:11,120
really easy so these reusable structures

00:15:09,519 --> 00:15:11,760
gave everyone the power to start an open

00:15:11,120 --> 00:15:14,000
project

00:15:11,760 --> 00:15:14,880
which really shifted power to users to

00:15:14,000 --> 00:15:16,480
be able to do

00:15:14,880 --> 00:15:18,880
to do this anyone can start an open

00:15:16,480 --> 00:15:18,880
project

00:15:20,079 --> 00:15:23,360
all right so there's the summary

00:15:24,160 --> 00:15:28,240
that legal mechanism enabled connect

00:15:26,880 --> 00:15:30,320
collective action

00:15:28,240 --> 00:15:33,120
and improved innovation and this is all

00:15:30,320 --> 00:15:36,720
reproduced through reusable structures

00:15:33,120 --> 00:15:39,199
so now i want to apply these to ai today

00:15:36,720 --> 00:15:40,720
and this ai landscape i think there's

00:15:39,199 --> 00:15:43,120
two ways to do this

00:15:40,720 --> 00:15:45,839
that i'm going to talk about at least uh

00:15:43,120 --> 00:15:48,160
first is around data stewardship

00:15:45,839 --> 00:15:49,680
i think the open source license is great

00:15:48,160 --> 00:15:51,519
for opening up code

00:15:49,680 --> 00:15:52,959
but a lot of the power in machine

00:15:51,519 --> 00:15:57,360
learning algorithms is through

00:15:52,959 --> 00:15:58,800
data so what can we do around data to

00:15:57,360 --> 00:16:01,120
help shift power

00:15:58,800 --> 00:16:02,880
and the second is to participatory ml

00:16:01,120 --> 00:16:03,680
how can we be building machine learning

00:16:02,880 --> 00:16:05,440
in a way

00:16:03,680 --> 00:16:07,759
that brings in others that takes a lot

00:16:05,440 --> 00:16:11,040
of these lessons from open source

00:16:07,759 --> 00:16:13,120
to yeah to build something collectively

00:16:11,040 --> 00:16:16,160
and shift power

00:16:13,120 --> 00:16:18,240
so back to data stewardship so back to

00:16:16,160 --> 00:16:21,519
that first question like do we need

00:16:18,240 --> 00:16:25,759
a new legal mechanism today for the

00:16:21,519 --> 00:16:27,759
trustworthy al landscape so

00:16:25,759 --> 00:16:30,000
if you look at the internet today eight

00:16:27,759 --> 00:16:30,800
companies wield enormous power over the

00:16:30,000 --> 00:16:32,320
internet

00:16:30,800 --> 00:16:34,160
i'm sure you're familiar with many of

00:16:32,320 --> 00:16:36,399
these logos um

00:16:34,160 --> 00:16:38,160
but every internet user interacts with

00:16:36,399 --> 00:16:39,360
at least one of these companies on a

00:16:38,160 --> 00:16:41,519
daily basis

00:16:39,360 --> 00:16:42,639
and often it's really hard to understand

00:16:41,519 --> 00:16:44,639
their revenue model

00:16:42,639 --> 00:16:46,000
i'm not for all of them but for some of

00:16:44,639 --> 00:16:49,120
them a lot of them

00:16:46,000 --> 00:16:50,160
have so much power because they've spent

00:16:49,120 --> 00:16:53,360
years or

00:16:50,160 --> 00:16:54,800
just collecting user data and that data

00:16:53,360 --> 00:16:56,000
is really helping them

00:16:54,800 --> 00:16:58,240
create these machine learning

00:16:56,000 --> 00:16:59,680
technologies or ai

00:16:58,240 --> 00:17:02,240
that gives them even more power on the

00:16:59,680 --> 00:17:04,640
internet so

00:17:02,240 --> 00:17:06,720
mozilla's done a lot of research around

00:17:04,640 --> 00:17:08,240
alternative data governance approaches

00:17:06,720 --> 00:17:10,240
um

00:17:08,240 --> 00:17:11,600
in machine learning so this is there's a

00:17:10,240 --> 00:17:13,360
lot of words on here i'm not going to

00:17:11,600 --> 00:17:15,919
talk through all of them

00:17:13,360 --> 00:17:17,760
but they have surfaced a bunch of

00:17:15,919 --> 00:17:19,439
different ones from data commons

00:17:17,760 --> 00:17:21,039
data cooperatives data trust data

00:17:19,439 --> 00:17:23,039
marketplaces

00:17:21,039 --> 00:17:25,039
and i do want to talk about two of them

00:17:23,039 --> 00:17:26,799
right now

00:17:25,039 --> 00:17:29,039
so the first one is data trust which i

00:17:26,799 --> 00:17:30,640
think is a great example of that legal

00:17:29,039 --> 00:17:31,679
mechanism that leads to collective

00:17:30,640 --> 00:17:34,799
action

00:17:31,679 --> 00:17:37,919
so a data trust in itself here's my

00:17:34,799 --> 00:17:40,240
rudimentary diagram

00:17:37,919 --> 00:17:41,919
is a legal mechanism that acts as an

00:17:40,240 --> 00:17:43,840
independent intermediary

00:17:41,919 --> 00:17:45,760
and that sits in between the data

00:17:43,840 --> 00:17:46,960
subjects so the people creating the data

00:17:45,760 --> 00:17:48,640
are the users

00:17:46,960 --> 00:17:50,640
and the data collectors these are the

00:17:48,640 --> 00:17:52,640
companies that collect the data

00:17:50,640 --> 00:17:53,919
so the data trust is loyal to its

00:17:52,640 --> 00:17:55,919
subjects

00:17:53,919 --> 00:17:57,440
but then it negotiates the data used

00:17:55,919 --> 00:17:58,960
with the companies according to the term

00:17:57,440 --> 00:18:00,799
set by the trust

00:17:58,960 --> 00:18:03,200
so a lot of people see this as instead

00:18:00,799 --> 00:18:05,120
of logging into google or facebook you

00:18:03,200 --> 00:18:06,960
would log into your data trust

00:18:05,120 --> 00:18:08,320
and then your trust would send data to

00:18:06,960 --> 00:18:10,559
google or facebook

00:18:08,320 --> 00:18:12,559
on your behalf according to the terms

00:18:10,559 --> 00:18:13,440
you've set so this gives you a lot more

00:18:12,559 --> 00:18:16,559
power

00:18:13,440 --> 00:18:17,200
and as a group as members of the state

00:18:16,559 --> 00:18:19,280
of trust

00:18:17,200 --> 00:18:21,120
you have a lot more collective action in

00:18:19,280 --> 00:18:24,559
how your data is being used

00:18:21,120 --> 00:18:26,480
um and like what it's used for

00:18:24,559 --> 00:18:28,160
the one thing is it doesn't quite have a

00:18:26,480 --> 00:18:29,840
reusable structure yet

00:18:28,160 --> 00:18:32,160
so if i wanted to start a data trust

00:18:29,840 --> 00:18:33,440
today i would definitely need a lawyer

00:18:32,160 --> 00:18:34,960
to help me out

00:18:33,440 --> 00:18:37,039
so it's not quite the drop down on

00:18:34,960 --> 00:18:37,679
github yet but people are working on

00:18:37,039 --> 00:18:39,360
that

00:18:37,679 --> 00:18:41,520
and a great example of this is the uk

00:18:39,360 --> 00:18:43,039
biobank which is a charitable company

00:18:41,520 --> 00:18:45,520
with trustees and they manage the

00:18:43,039 --> 00:18:47,760
genetic data from half a million people

00:18:45,520 --> 00:18:48,880
so that trust negotiates with

00:18:47,760 --> 00:18:51,440
researchers

00:18:48,880 --> 00:18:52,880
on how they'll use that data from those

00:18:51,440 --> 00:18:57,520
the different patients

00:18:52,880 --> 00:18:58,880
who donated their genetic data

00:18:57,520 --> 00:19:00,799
and the other example i want to talk

00:18:58,880 --> 00:19:02,640
about is data commons

00:19:00,799 --> 00:19:04,400
which is that data collected and shared

00:19:02,640 --> 00:19:06,720
as a common resource

00:19:04,400 --> 00:19:08,160
and the classic example of this is

00:19:06,720 --> 00:19:11,600
wikipedia

00:19:08,160 --> 00:19:13,919
where the crowdsourced articles are made

00:19:11,600 --> 00:19:14,799
and shared with everyone and wikipedia

00:19:13,919 --> 00:19:18,720
has

00:19:14,799 --> 00:19:18,720
changed how a lot of us use the internet

00:19:19,760 --> 00:19:22,880
but the other example i want to talk

00:19:20,960 --> 00:19:24,320
about is common voice which is a mozilla

00:19:22,880 --> 00:19:25,600
project

00:19:24,320 --> 00:19:27,679
but if you look at the voice

00:19:25,600 --> 00:19:28,480
technologies today a lot of the big

00:19:27,679 --> 00:19:31,840
players are

00:19:28,480 --> 00:19:33,440
like alexa siri google home and a lot of

00:19:31,840 --> 00:19:34,640
them are able to create these

00:19:33,440 --> 00:19:36,320
technologies

00:19:34,640 --> 00:19:38,320
because they've been collecting our

00:19:36,320 --> 00:19:40,160
voice data for years

00:19:38,320 --> 00:19:41,760
and they just have so much voice data

00:19:40,160 --> 00:19:44,880
they're able to create these

00:19:41,760 --> 00:19:46,559
personal assistants but it's really hard

00:19:44,880 --> 00:19:48,160
for an outsider to come in

00:19:46,559 --> 00:19:50,240
and compete with that because they

00:19:48,160 --> 00:19:53,200
haven't collected all this data

00:19:50,240 --> 00:19:53,679
um yeah they just don't have this data

00:19:53,200 --> 00:19:56,960
set

00:19:53,679 --> 00:19:59,360
so mozilla started um common voice

00:19:56,960 --> 00:20:00,799
where people can donate their data and

00:19:59,360 --> 00:20:04,240
anyone can use this

00:20:00,799 --> 00:20:07,360
public domain data set excuse me

00:20:04,240 --> 00:20:09,360
to build technologies uh so if you're

00:20:07,360 --> 00:20:11,520
interested in donating your data

00:20:09,360 --> 00:20:13,200
uh your voice to this uh please go to

00:20:11,520 --> 00:20:15,360
common voice always looking for more

00:20:13,200 --> 00:20:17,760
gender diversity or global diversity

00:20:15,360 --> 00:20:19,280
and i was looking for more languages so

00:20:17,760 --> 00:20:21,760
it's a great way to

00:20:19,280 --> 00:20:22,320
help shift power away from those big

00:20:21,760 --> 00:20:24,240
tech

00:20:22,320 --> 00:20:26,480
by enabling others to create more voice

00:20:24,240 --> 00:20:28,799
technology

00:20:26,480 --> 00:20:30,320
right so those are just two of the many

00:20:28,799 --> 00:20:32,559
different data governance

00:20:30,320 --> 00:20:34,400
types that are out there in the world

00:20:32,559 --> 00:20:36,960
and recently mozilla published

00:20:34,400 --> 00:20:38,799
the state of futures research which is

00:20:36,960 --> 00:20:39,679
research to shift power through data

00:20:38,799 --> 00:20:41,039
governance

00:20:39,679 --> 00:20:42,799
so you can go to that url if you're

00:20:41,039 --> 00:20:46,559
interested and they go over

00:20:42,799 --> 00:20:48,400
seven different data governance models

00:20:46,559 --> 00:20:51,360
along with some examples of how this is

00:20:48,400 --> 00:20:51,360
happening in the world today

00:20:53,200 --> 00:20:56,480
so yeah i recommend you check that out

00:20:55,840 --> 00:20:58,559
all right

00:20:56,480 --> 00:20:59,520
and this last section is participatory

00:20:58,559 --> 00:21:02,799
ml

00:20:59,520 --> 00:21:04,720
where can we apply working open today

00:21:02,799 --> 00:21:06,880
um and i think we're starting to see

00:21:04,720 --> 00:21:08,880
more people talk about participatory ml

00:21:06,880 --> 00:21:10,559
and realize that there's so much power

00:21:08,880 --> 00:21:11,200
with the technical community building

00:21:10,559 --> 00:21:12,880
this

00:21:11,200 --> 00:21:14,799
how can you open up different parts of

00:21:12,880 --> 00:21:16,960
it so that you're co-designing with some

00:21:14,799 --> 00:21:19,120
of the end users so you understand some

00:21:16,960 --> 00:21:20,640
of the impacts down the line

00:21:19,120 --> 00:21:22,400
so i do think working open is a great

00:21:20,640 --> 00:21:24,640
way to shift power

00:21:22,400 --> 00:21:25,520
back to that definition i love so much

00:21:24,640 --> 00:21:28,320
we're working open

00:21:25,520 --> 00:21:29,840
is public and participatory this

00:21:28,320 --> 00:21:32,320
requires structuring efforts that

00:21:29,840 --> 00:21:35,200
outsiders can meaningfully participate

00:21:32,320 --> 00:21:36,720
and become insiders as appropriate and i

00:21:35,200 --> 00:21:39,760
do want to say that

00:21:36,720 --> 00:21:42,240
if you're intentionally including those

00:21:39,760 --> 00:21:43,679
traditionally excluded from shaping tech

00:21:42,240 --> 00:21:46,159
to become insiders

00:21:43,679 --> 00:21:47,600
working open is great at shifting power

00:21:46,159 --> 00:21:50,400
however if you're only

00:21:47,600 --> 00:21:52,000
inviting those who already have power

00:21:50,400 --> 00:21:52,880
working open doesn't shift power you're

00:21:52,000 --> 00:21:55,760
just

00:21:52,880 --> 00:21:56,320
defending the status quo quo so working

00:21:55,760 --> 00:21:58,400
open

00:21:56,320 --> 00:22:00,080
can shift power i i don't think it

00:21:58,400 --> 00:22:01,600
always does

00:22:00,080 --> 00:22:03,760
and i think you can see that in the open

00:22:01,600 --> 00:22:05,840
source community today where it's done a

00:22:03,760 --> 00:22:07,840
great job of democratizing technology

00:22:05,840 --> 00:22:10,240
and giving so many people access

00:22:07,840 --> 00:22:12,960
but open source still has its share of

00:22:10,240 --> 00:22:15,039
diversity issues um

00:22:12,960 --> 00:22:16,799
yeah so there's ways you have to be

00:22:15,039 --> 00:22:19,840
intentional about the way you work open

00:22:16,799 --> 00:22:22,080
so that it can shift power

00:22:19,840 --> 00:22:23,760
so i wanted to give you a bit of a

00:22:22,080 --> 00:22:25,440
framework to think through

00:22:23,760 --> 00:22:28,000
so this is a framework i use when i'm

00:22:25,440 --> 00:22:30,400
teaching open source

00:22:28,000 --> 00:22:32,640
but these are five open source practices

00:22:30,400 --> 00:22:35,120
that you can implement in your own work

00:22:32,640 --> 00:22:36,159
so there's three categories here one's a

00:22:35,120 --> 00:22:37,679
giving where you're just giving

00:22:36,159 --> 00:22:40,480
something away for free

00:22:37,679 --> 00:22:41,919
listening either passively or actively

00:22:40,480 --> 00:22:42,320
and then collaborating either with a

00:22:41,919 --> 00:22:45,280
team

00:22:42,320 --> 00:22:46,640
or through partnerships so this is based

00:22:45,280 --> 00:22:48,080
on research from the copenhagen

00:22:46,640 --> 00:22:50,320
institute for interaction design and

00:22:48,080 --> 00:22:52,159
mosul open innovation

00:22:50,320 --> 00:22:53,600
so i'm going to go through each of these

00:22:52,159 --> 00:22:57,280
and talk about what they are

00:22:53,600 --> 00:22:57,280
and how you can use them to shift power

00:22:57,360 --> 00:23:01,200
all right so the first one is gifting so

00:22:59,280 --> 00:23:03,200
this is no strings attached to giving of

00:23:01,200 --> 00:23:04,960
valued products and services

00:23:03,200 --> 00:23:07,039
and the example from the study is google

00:23:04,960 --> 00:23:08,159
android that gifted a development

00:23:07,039 --> 00:23:10,720
platform

00:23:08,159 --> 00:23:12,000
to encourage new users new uses by

00:23:10,720 --> 00:23:14,159
developers

00:23:12,000 --> 00:23:15,520
so this incentivizes adoption it's a

00:23:14,159 --> 00:23:17,120
great advantage

00:23:15,520 --> 00:23:18,720
people will use your thing if you just

00:23:17,120 --> 00:23:20,720
gift it to them for free

00:23:18,720 --> 00:23:22,000
this can help drive a standard if you

00:23:20,720 --> 00:23:24,400
have more people adopting

00:23:22,000 --> 00:23:25,440
your work you can use that to drive a

00:23:24,400 --> 00:23:28,720
standard and

00:23:25,440 --> 00:23:30,400
generate interoperability um and it also

00:23:28,720 --> 00:23:32,000
leads to improved products and services

00:23:30,400 --> 00:23:33,679
if more people are using it

00:23:32,000 --> 00:23:36,480
you know how to start improving it and

00:23:33,679 --> 00:23:38,000
you can build a better product that way

00:23:36,480 --> 00:23:39,679
so if you're thinking of using gifting

00:23:38,000 --> 00:23:41,200
as a way to shift power

00:23:39,679 --> 00:23:43,200
uh first i'd advise you to make sure

00:23:41,200 --> 00:23:45,200
it's accessible to as many people as

00:23:43,200 --> 00:23:46,880
possible that you're not just gifting to

00:23:45,200 --> 00:23:48,640
people who already have power

00:23:46,880 --> 00:23:50,880
but that you are gifting to people who

00:23:48,640 --> 00:23:52,080
really need this and don't have power

00:23:50,880 --> 00:23:53,760
now

00:23:52,080 --> 00:23:56,240
and then just a question to ask yourself

00:23:53,760 --> 00:23:58,880
like who does not have access your work

00:23:56,240 --> 00:24:01,760
who should have and maybe try to gift it

00:23:58,880 --> 00:24:01,760
intentionally to them

00:24:03,200 --> 00:24:06,480
next is soliciting ideas we're in the

00:24:05,039 --> 00:24:08,320
listening section now

00:24:06,480 --> 00:24:10,320
this is using a community to generate

00:24:08,320 --> 00:24:12,000
ideas and solutions

00:24:10,320 --> 00:24:13,760
and i really like this example i

00:24:12,000 --> 00:24:15,039
actually didn't know about this before i

00:24:13,760 --> 00:24:17,440
read the study

00:24:15,039 --> 00:24:20,000
but there's a lego ideas platform that

00:24:17,440 --> 00:24:22,720
allows anyone to propose a kit idea

00:24:20,000 --> 00:24:23,600
which then can be voted into production

00:24:22,720 --> 00:24:25,440
so

00:24:23,600 --> 00:24:27,200
as the open advantage here is it helps

00:24:25,440 --> 00:24:28,880
you understand your community

00:24:27,200 --> 00:24:31,200
and you can generate additional

00:24:28,880 --> 00:24:33,919
offerings from the community

00:24:31,200 --> 00:24:35,440
and in terms of shifting power can you

00:24:33,919 --> 00:24:37,360
solicit ideas specifically for

00:24:35,440 --> 00:24:39,760
marginalized groups that may be affected

00:24:37,360 --> 00:24:41,440
by your work

00:24:39,760 --> 00:24:43,120
and then also are there experts from

00:24:41,440 --> 00:24:44,799
other fields

00:24:43,120 --> 00:24:46,880
like social science or race and gender

00:24:44,799 --> 00:24:48,559
studies that you can listen to

00:24:46,880 --> 00:24:51,279
um i think a lot of times when we're

00:24:48,559 --> 00:24:53,520
building responsible or trustworthy tech

00:24:51,279 --> 00:24:54,960
we're not listening to the people who've

00:24:53,520 --> 00:24:56,400
been studying this for a long time like

00:24:54,960 --> 00:24:58,320
the social sciences

00:24:56,400 --> 00:25:01,840
who's been looking at society and

00:24:58,320 --> 00:25:01,840
technology for ages

00:25:03,120 --> 00:25:06,400
okay on the other side of listening

00:25:04,559 --> 00:25:08,000
there's learning through use

00:25:06,400 --> 00:25:10,159
this is collecting and analyzing

00:25:08,000 --> 00:25:14,159
activity to improve products or services

00:25:10,159 --> 00:25:16,799
this is that passive side of listening

00:25:14,159 --> 00:25:16,799
excuse me

00:25:17,200 --> 00:25:20,720
i've been recording this for a while all

00:25:19,200 --> 00:25:22,640
right so the example they have here is

00:25:20,720 --> 00:25:24,880
spotify discover weekly

00:25:22,640 --> 00:25:26,559
which learns a user's taste and then

00:25:24,880 --> 00:25:28,480
creates playlists

00:25:26,559 --> 00:25:29,679
which it's a feature i actually really

00:25:28,480 --> 00:25:32,000
like

00:25:29,679 --> 00:25:32,880
it creates that for me a little playlist

00:25:32,000 --> 00:25:34,640
i can use

00:25:32,880 --> 00:25:36,400
um so the open advantage here is it

00:25:34,640 --> 00:25:38,000
helps you understand your users

00:25:36,400 --> 00:25:40,000
you can improve your products and you

00:25:38,000 --> 00:25:42,159
can fail fast you can understand when

00:25:40,000 --> 00:25:44,799
something you're making isn't working

00:25:42,159 --> 00:25:46,159
but in terms of shifting power really

00:25:44,799 --> 00:25:47,520
look at how marginalized groups are

00:25:46,159 --> 00:25:48,960
using your software

00:25:47,520 --> 00:25:50,640
is there something you can do to really

00:25:48,960 --> 00:25:54,000
optimize for them

00:25:50,640 --> 00:25:58,159
um so that yeah they're getting some

00:25:54,000 --> 00:25:58,159
power in the design of your your work

00:25:59,279 --> 00:26:03,120
and then moving on to the collaborating

00:26:01,039 --> 00:26:06,159
section there's creating together

00:26:03,120 --> 00:26:07,520
the very traditional open source thing

00:26:06,159 --> 00:26:09,520
that you think about

00:26:07,520 --> 00:26:12,080
this is sharing the tasks and costs of

00:26:09,520 --> 00:26:14,320
achieving a pre-established goal

00:26:12,080 --> 00:26:16,320
and so local motors invites designers to

00:26:14,320 --> 00:26:17,840
use an online shared database of parts

00:26:16,320 --> 00:26:19,840
to co-develop products

00:26:17,840 --> 00:26:22,159
and the advantages here you have a

00:26:19,840 --> 00:26:23,760
better product you lower operating costs

00:26:22,159 --> 00:26:25,520
and you really give ownership to the

00:26:23,760 --> 00:26:28,480
community they feel like they've helped

00:26:25,520 --> 00:26:30,320
build this and that part of it's theirs

00:26:28,480 --> 00:26:32,000
so in terms of shifting power

00:26:30,320 --> 00:26:33,600
um really think about who should be

00:26:32,000 --> 00:26:36,080
build a part of building this

00:26:33,600 --> 00:26:38,400
but isn't and can you invite experts

00:26:36,080 --> 00:26:42,480
from other fields to build this with you

00:26:38,400 --> 00:26:44,000
and i do i do think of the

00:26:42,480 --> 00:26:45,600
of the options of the community

00:26:44,000 --> 00:26:48,320
interactions this one

00:26:45,600 --> 00:26:49,760
takes the most effort on your end to

00:26:48,320 --> 00:26:51,919
create the structures that others can

00:26:49,760 --> 00:26:53,360
co-create with you it's really hard um

00:26:51,919 --> 00:26:55,200
it's much easier to give something away

00:26:53,360 --> 00:26:58,400
for free or even ask for ideas

00:26:55,200 --> 00:26:59,600
this takes a lot of effort so be

00:26:58,400 --> 00:27:01,600
be aware of that when you're choosing

00:26:59,600 --> 00:27:02,480
which one to do i do think this is a

00:27:01,600 --> 00:27:04,159
great one

00:27:02,480 --> 00:27:05,840
and it's like the best way to shift

00:27:04,159 --> 00:27:07,679
power like fully

00:27:05,840 --> 00:27:09,440
but you can still shift power in smaller

00:27:07,679 --> 00:27:11,760
ways through gifting so listening ideas

00:27:09,440 --> 00:27:14,640
etc

00:27:11,760 --> 00:27:15,919
and then the final one is a networking

00:27:14,640 --> 00:27:17,440
common interests

00:27:15,919 --> 00:27:19,120
this is coordinating to ensure that

00:27:17,440 --> 00:27:20,000
individual activities achieve more

00:27:19,120 --> 00:27:21,840
towards a shared

00:27:20,000 --> 00:27:24,320
mission and the example here is from

00:27:21,840 --> 00:27:25,360
ashoka which serves as a platform for

00:27:24,320 --> 00:27:27,360
innovators

00:27:25,360 --> 00:27:29,120
that share an overall objective but each

00:27:27,360 --> 00:27:30,399
sets their own project

00:27:29,120 --> 00:27:32,799
so this is definitely more about

00:27:30,399 --> 00:27:33,679
partnerships so if you're running a

00:27:32,799 --> 00:27:35,440
project

00:27:33,679 --> 00:27:37,440
is there another aligned project you can

00:27:35,440 --> 00:27:39,440
partner with and you can do more

00:27:37,440 --> 00:27:41,679
together than you would on your own

00:27:39,440 --> 00:27:43,600
so as an open advantage this advances

00:27:41,679 --> 00:27:45,200
common playing fields

00:27:43,600 --> 00:27:47,600
it enables separate groups to help each

00:27:45,200 --> 00:27:49,600
other it lowers operating costs

00:27:47,600 --> 00:27:51,600
and you can improve products by learning

00:27:49,600 --> 00:27:53,840
from your partners

00:27:51,600 --> 00:27:55,520
so in terms of shifting power are there

00:27:53,840 --> 00:27:58,320
aligned projects you can partner with

00:27:55,520 --> 00:27:58,320
and share power

00:27:58,640 --> 00:28:03,039
so back to the overview these are five

00:28:01,919 --> 00:28:05,520
open source prod

00:28:03,039 --> 00:28:06,159
practices that can shift power some of

00:28:05,520 --> 00:28:08,080
them are

00:28:06,159 --> 00:28:09,760
like weaker ways to shift power weaker

00:28:08,080 --> 00:28:11,039
ways of participation others are much

00:28:09,760 --> 00:28:13,279
stronger

00:28:11,039 --> 00:28:15,360
i recommend you go as strong as you can

00:28:13,279 --> 00:28:17,120
if you really do want to shift power but

00:28:15,360 --> 00:28:18,720
i understand that not all projects have

00:28:17,120 --> 00:28:21,360
the resources to do that

00:28:18,720 --> 00:28:22,640
so i hope this helps you think through

00:28:21,360 --> 00:28:24,399
your own work

00:28:22,640 --> 00:28:26,240
and think about ways you can open things

00:28:24,399 --> 00:28:29,200
up a little bit at least

00:28:26,240 --> 00:28:31,679
so i do want to ask these two questions

00:28:29,200 --> 00:28:33,360
after talking about these practices

00:28:31,679 --> 00:28:34,960
but where can you include others and

00:28:33,360 --> 00:28:37,520
share power in your work

00:28:34,960 --> 00:28:38,960
and then who will you include really

00:28:37,520 --> 00:28:41,440
think about

00:28:38,960 --> 00:28:42,960
that power dynamic and who who really

00:28:41,440 --> 00:28:43,679
traditionally doesn't have power in what

00:28:42,960 --> 00:28:46,000
you're building

00:28:43,679 --> 00:28:47,600
what is most affected by it and like

00:28:46,000 --> 00:28:50,559
what ways can you start to include them

00:28:47,600 --> 00:28:52,480
in the design of your work

00:28:50,559 --> 00:28:53,840
so you can think about that after this

00:28:52,480 --> 00:28:56,640
talk

00:28:53,840 --> 00:28:58,320
so i do work at mozilla our mission is

00:28:56,640 --> 00:28:59,679
to ensure that the internet is a global

00:28:58,320 --> 00:29:02,399
public resource

00:28:59,679 --> 00:29:05,120
open and accessible to all and right now

00:29:02,399 --> 00:29:07,039
we are really focused on trustworthy ai

00:29:05,120 --> 00:29:08,159
and that's ai that's demonstrably worthy

00:29:07,039 --> 00:29:10,080
of trust

00:29:08,159 --> 00:29:11,360
where privacy transparency and human

00:29:10,080 --> 00:29:13,840
well-being are key

00:29:11,360 --> 00:29:15,200
considerations and their mechanisms for

00:29:13,840 --> 00:29:17,520
accountability

00:29:15,200 --> 00:29:19,360
so if you're at all interested in this i

00:29:17,520 --> 00:29:20,559
do co-chair the building trust for the

00:29:19,360 --> 00:29:22,799
ai working group

00:29:20,559 --> 00:29:23,760
this is actually um mozfest's pilot

00:29:22,799 --> 00:29:26,399
working group

00:29:23,760 --> 00:29:27,840
and we've recently selected six projects

00:29:26,399 --> 00:29:29,520
that we're going to be working on

00:29:27,840 --> 00:29:31,520
leading up to the festival which is in

00:29:29,520 --> 00:29:34,640
march 2021

00:29:31,520 --> 00:29:36,799
and these projects range from sort of

00:29:34,640 --> 00:29:38,159
defining best practices around building

00:29:36,799 --> 00:29:40,559
trustworthy ai

00:29:38,159 --> 00:29:42,640
to including more diverse stakeholders

00:29:40,559 --> 00:29:45,200
in the creation of this technology

00:29:42,640 --> 00:29:45,760
um to creating building blocks that are

00:29:45,200 --> 00:29:48,559
needed

00:29:45,760 --> 00:29:50,880
to build more trustworthy ai sustainably

00:29:48,559 --> 00:29:54,000
so if you that interests you at all

00:29:50,880 --> 00:29:55,919
join us i think as of this time

00:29:54,000 --> 00:29:57,919
when you're watching it our next meeting

00:29:55,919 --> 00:30:00,320
will be the next morning after

00:29:57,919 --> 00:30:01,919
so come join us you can hear about the

00:30:00,320 --> 00:30:03,760
projects we're just starting them now so

00:30:01,919 --> 00:30:06,159
now's a great time to jump in

00:30:03,760 --> 00:30:08,720
and start yeah start working towards

00:30:06,159 --> 00:30:10,640
better ai

00:30:08,720 --> 00:30:12,159
and that leads us to mozfest where we're

00:30:10,640 --> 00:30:14,000
working on these projects all the way up

00:30:12,159 --> 00:30:15,919
to march 2021

00:30:14,000 --> 00:30:17,520
um and so this is mozilla's annual

00:30:15,919 --> 00:30:18,480
festival that's really a celebration of

00:30:17,520 --> 00:30:20,720
the internet

00:30:18,480 --> 00:30:22,000
and i love our tagline that's come with

00:30:20,720 --> 00:30:23,760
an idea

00:30:22,000 --> 00:30:25,279
leave with the community um we are

00:30:23,760 --> 00:30:26,320
virtual this year like many other

00:30:25,279 --> 00:30:27,760
conferences

00:30:26,320 --> 00:30:29,919
and our call for proposals actually

00:30:27,760 --> 00:30:32,960
opened yesterday as of this recording

00:30:29,919 --> 00:30:33,200
i don't have a url because i'm recording

00:30:32,960 --> 00:30:35,520
it

00:30:33,200 --> 00:30:37,039
earlier wait it opened yesterday as of

00:30:35,520 --> 00:30:39,120
when you're watching this that's that's

00:30:37,039 --> 00:30:41,120
the correct way to say this

00:30:39,120 --> 00:30:42,880
um so if you're working on anything

00:30:41,120 --> 00:30:44,720
related to this at all

00:30:42,880 --> 00:30:46,000
um the whole theme of the festival is

00:30:44,720 --> 00:30:47,760
trustworthy ai

00:30:46,000 --> 00:30:49,279
and we do want to look at this from like

00:30:47,760 --> 00:30:52,000
the developer's perspective from

00:30:49,279 --> 00:30:53,520
policy perspective from consumers really

00:30:52,000 --> 00:30:55,200
any way that we can get to

00:30:53,520 --> 00:30:57,039
more trust for the aai we're really

00:30:55,200 --> 00:30:58,960
interested in hearing from you

00:30:57,039 --> 00:31:01,440
and i think mozfest is a great way to

00:30:58,960 --> 00:31:02,880
come and find others who with aligned

00:31:01,440 --> 00:31:03,919
ideas

00:31:02,880 --> 00:31:05,919
and you really do leave with the

00:31:03,919 --> 00:31:09,360
community so

00:31:05,919 --> 00:31:11,279
check out mozfast and uh yeah i just

00:31:09,360 --> 00:31:16,399
want to close with a huge thank you

00:31:11,279 --> 00:31:18,080
so many people who bounced ideas off of

00:31:16,399 --> 00:31:19,679
shared slides with me and thanks for

00:31:18,080 --> 00:31:20,159
many of you who did the actual work that

00:31:19,679 --> 00:31:23,679
i'm just

00:31:20,159 --> 00:31:26,000
showing off in this presentation

00:31:23,679 --> 00:31:27,440
so with that uh thanks you so much for

00:31:26,000 --> 00:31:29,039
watching um if you're watching the

00:31:27,440 --> 00:31:31,200
recording you have any questions

00:31:29,039 --> 00:31:32,320
you can tweet me i'll be sure to follow

00:31:31,200 --> 00:31:32,960
up i think that's a good way to get in

00:31:32,320 --> 00:31:35,760
touch

00:31:32,960 --> 00:31:36,480
but i believe i'll be here live after

00:31:35,760 --> 00:31:39,200
this

00:31:36,480 --> 00:31:39,600
uh to answer some of your questions live

00:31:39,200 --> 00:31:47,600
so

00:31:39,600 --> 00:31:49,679
uh thanks everyone and i'll see

00:31:47,600 --> 00:31:49,679

YouTube URL: https://www.youtube.com/watch?v=DhssHxI_yok


