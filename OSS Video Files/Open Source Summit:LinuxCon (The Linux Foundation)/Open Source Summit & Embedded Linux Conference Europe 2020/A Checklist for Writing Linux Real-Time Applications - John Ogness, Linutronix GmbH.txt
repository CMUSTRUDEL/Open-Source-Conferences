Title: A Checklist for Writing Linux Real-Time Applications - John Ogness, Linutronix GmbH
Publication date: 2020-11-03
Playlist: Open Source Summit & Embedded Linux Conference Europe 2020
Description: 
	A Checklist for Writing Linux Real-Time Applications - John Ogness, Linutronix GmbH
Captions: 
	00:00:06,080 --> 00:00:09,120
hello

00:00:06,799 --> 00:00:11,200
my name is john agnes and i'm here to do

00:00:09,120 --> 00:00:12,480
a talk about

00:00:11,200 --> 00:00:14,799
everything you need to know about

00:00:12,480 --> 00:00:16,560
writing an application a real-time

00:00:14,799 --> 00:00:18,240
application under linux

00:00:16,560 --> 00:00:19,840
and there's a lot of small details you

00:00:18,240 --> 00:00:21,680
really need to pay attention to

00:00:19,840 --> 00:00:23,199
when you're writing an application on a

00:00:21,680 --> 00:00:24,080
general purpose operating system like

00:00:23,199 --> 00:00:26,400
linux

00:00:24,080 --> 00:00:29,039
and i hope that we can go through the

00:00:26,400 --> 00:00:30,160
critical points here so that

00:00:29,039 --> 00:00:32,079
basically at the end you'll have a

00:00:30,160 --> 00:00:34,000
checklist and you can just just as a

00:00:32,079 --> 00:00:36,239
reminder of everything that you need to

00:00:34,000 --> 00:00:36,239
do

00:00:37,760 --> 00:00:41,600
so let's begin by talking about what

00:00:40,399 --> 00:00:43,360
real time actually

00:00:41,600 --> 00:00:44,800
is because that's also an important

00:00:43,360 --> 00:00:46,000
thing to understand what is a real-time

00:00:44,800 --> 00:00:47,039
application

00:00:46,000 --> 00:00:49,440
so of course when we're writing

00:00:47,039 --> 00:00:51,360
applications we want them to be bug free

00:00:49,440 --> 00:00:52,640
that's an important aspect to any

00:00:51,360 --> 00:00:54,079
application

00:00:52,640 --> 00:00:55,600
but when you're talking about a

00:00:54,079 --> 00:00:55,920
real-time application you're talking

00:00:55,600 --> 00:00:57,840
about

00:00:55,920 --> 00:00:59,680
not only that it's running without bugs

00:00:57,840 --> 00:01:02,320
but correctness means

00:00:59,680 --> 00:01:04,400
running at the correct time so when

00:01:02,320 --> 00:01:05,280
let's say a certain task needs to wake

00:01:04,400 --> 00:01:06,240
up

00:01:05,280 --> 00:01:07,840
then it's really important for a

00:01:06,240 --> 00:01:10,080
real-time application that that task

00:01:07,840 --> 00:01:12,080
wakes up when it wanted to wake up yeah

00:01:10,080 --> 00:01:13,600
and if it wakes up later than that then

00:01:12,080 --> 00:01:14,320
that's a certain latency that we can

00:01:13,600 --> 00:01:16,799
measure

00:01:14,320 --> 00:01:17,600
and if the latency is larger than that

00:01:16,799 --> 00:01:19,840
which we

00:01:17,600 --> 00:01:21,280
have as our requirements then we've

00:01:19,840 --> 00:01:23,280
failed to meet our requirements and the

00:01:21,280 --> 00:01:25,439
real-time system has failed

00:01:23,280 --> 00:01:27,119
now to really consider your system a

00:01:25,439 --> 00:01:29,200
real-time system

00:01:27,119 --> 00:01:31,200
you it's not just enough that you would

00:01:29,200 --> 00:01:33,119
like your application to meet certain

00:01:31,200 --> 00:01:35,200
timing requirements or that it's

00:01:33,119 --> 00:01:36,640
important for you but it's actually a

00:01:35,200 --> 00:01:38,880
requirement which means

00:01:36,640 --> 00:01:40,320
if when it fails to meet these

00:01:38,880 --> 00:01:42,960
requirements you actually have an

00:01:40,320 --> 00:01:44,960
error in your system then you can call

00:01:42,960 --> 00:01:47,439
your system a real-time system

00:01:44,960 --> 00:01:49,600
so it's really important that you define

00:01:47,439 --> 00:01:52,159
which tasks on my system

00:01:49,600 --> 00:01:52,880
which applications or which threads are

00:01:52,159 --> 00:01:55,200
actually

00:01:52,880 --> 00:01:56,560
time critical this is actually a quite

00:01:55,200 --> 00:01:58,240
important step

00:01:56,560 --> 00:01:59,759
because a lot of people make the mistake

00:01:58,240 --> 00:02:01,119
of saying okay we have a real time

00:01:59,759 --> 00:02:02,560
system so let's just make everything on

00:02:01,119 --> 00:02:06,479
the system real time

00:02:02,560 --> 00:02:08,160
and this is generally fall false it's a

00:02:06,479 --> 00:02:10,000
you're going to have a lot of problems

00:02:08,160 --> 00:02:11,440
because real-time applications have

00:02:10,000 --> 00:02:13,120
totally different requirements than

00:02:11,440 --> 00:02:14,560
applications that are not real-time so

00:02:13,120 --> 00:02:15,440
it's really important that you take a

00:02:14,560 --> 00:02:17,840
moment

00:02:15,440 --> 00:02:19,920
to really analyze your system say what

00:02:17,840 --> 00:02:22,959
actually has the timing requirements

00:02:19,920 --> 00:02:23,920
that we have to meet on our system now

00:02:22,959 --> 00:02:27,120
in order to

00:02:23,920 --> 00:02:28,800
have a real-time system an operating

00:02:27,120 --> 00:02:31,440
system that supports real time

00:02:28,800 --> 00:02:33,120
there's really three main tasks that

00:02:31,440 --> 00:02:34,879
have to be satisfied

00:02:33,120 --> 00:02:36,640
so the first is that you have to have

00:02:34,879 --> 00:02:39,519
some sort of deterministic

00:02:36,640 --> 00:02:40,160
run time or scheduling behavior

00:02:39,519 --> 00:02:41,360
otherwise

00:02:40,160 --> 00:02:43,280
you have no way of controlling the

00:02:41,360 --> 00:02:45,200
system at all if i call a function

00:02:43,280 --> 00:02:46,560
and it could run days or it could run

00:02:45,200 --> 00:02:48,160
microseconds

00:02:46,560 --> 00:02:50,160
this does not help me i have no chance

00:02:48,160 --> 00:02:52,640
of doing a deterministic

00:02:50,160 --> 00:02:53,599
low latency real-time system it's also

00:02:52,640 --> 00:02:54,560
important that the system is

00:02:53,599 --> 00:02:56,319
interruptible

00:02:54,560 --> 00:02:57,840
because the cpu is always doing

00:02:56,319 --> 00:02:59,440
something right

00:02:57,840 --> 00:03:01,040
so it's really important in the system

00:02:59,440 --> 00:03:03,440
that's able to uh

00:03:01,040 --> 00:03:04,720
interrupt whatever is currently running

00:03:03,440 --> 00:03:06,800
and to

00:03:04,720 --> 00:03:08,720
do something else yeah my important task

00:03:06,800 --> 00:03:09,040
my real time task when it needs to wake

00:03:08,720 --> 00:03:10,400
up

00:03:09,040 --> 00:03:13,360
then we need to kick somebody off the

00:03:10,400 --> 00:03:14,159
cpu for that and third we need a way to

00:03:13,360 --> 00:03:17,680
avoid

00:03:14,159 --> 00:03:18,640
priority inversion now priority

00:03:17,680 --> 00:03:20,879
inversion

00:03:18,640 --> 00:03:23,440
is a situation where a high priority

00:03:20,879 --> 00:03:25,120
task is waiting for a low priority task

00:03:23,440 --> 00:03:27,360
so in this particular picture that we

00:03:25,120 --> 00:03:30,319
see here we have

00:03:27,360 --> 00:03:32,319
task 3 which is low priority and in this

00:03:30,319 --> 00:03:33,680
scenario we can say that task three is

00:03:32,319 --> 00:03:36,080
holding a lock

00:03:33,680 --> 00:03:38,400
now task one comes along has a higher

00:03:36,080 --> 00:03:40,400
priority and task one wants that lock

00:03:38,400 --> 00:03:42,000
that situation is okay you're allowed to

00:03:40,400 --> 00:03:43,920
grab locks as low priority

00:03:42,000 --> 00:03:45,519
and it could possibly be a situation

00:03:43,920 --> 00:03:47,200
that the high priority task wants that

00:03:45,519 --> 00:03:49,920
lock

00:03:47,200 --> 00:03:52,080
anyway in that case the scheduler does

00:03:49,920 --> 00:03:53,599
something intelligent it puts task 3

00:03:52,080 --> 00:03:55,519
back on the cpu

00:03:53,599 --> 00:03:57,200
because task 1 wants that the high

00:03:55,519 --> 00:03:59,200
priority test wants that lock and so the

00:03:57,200 --> 00:03:59,840
only one who can free that lock is task

00:03:59,200 --> 00:04:02,400
three

00:03:59,840 --> 00:04:04,159
so it's put on back on the cpu but now

00:04:02,400 --> 00:04:06,959
let's assume

00:04:04,159 --> 00:04:09,040
that task two comes along task two has

00:04:06,959 --> 00:04:10,640
nothing to do with task one

00:04:09,040 --> 00:04:12,319
nothing to do with test three nothing to

00:04:10,640 --> 00:04:13,599
do with this lock and this contention

00:04:12,319 --> 00:04:16,959
that we have there

00:04:13,599 --> 00:04:17,840
but task 2 is higher priority than task

00:04:16,959 --> 00:04:20,320
3.

00:04:17,840 --> 00:04:21,919
so when task 2 comes along is actually a

00:04:20,320 --> 00:04:24,960
correct decision

00:04:21,919 --> 00:04:27,680
for the cpu to be

00:04:24,960 --> 00:04:28,720
assigned to task 2 when task 3 was

00:04:27,680 --> 00:04:31,040
previously there

00:04:28,720 --> 00:04:33,600
so now we have that problem that on a

00:04:31,040 --> 00:04:36,400
problem that a totally unrelated task

00:04:33,600 --> 00:04:37,840
is now holding up task 3 and actually

00:04:36,400 --> 00:04:39,520
indirectly task 1.

00:04:37,840 --> 00:04:41,680
now this is the priority inversion

00:04:39,520 --> 00:04:43,840
situation the priority version is not

00:04:41,680 --> 00:04:45,919
between task one and task three

00:04:43,840 --> 00:04:47,199
the priority inversion is between task

00:04:45,919 --> 00:04:49,440
one and task

00:04:47,199 --> 00:04:50,400
two here we have a high priority task

00:04:49,440 --> 00:04:53,520
task one

00:04:50,400 --> 00:04:56,960
waiting indirectly on the

00:04:53,520 --> 00:04:58,960
pr uh the lower priority task task two

00:04:56,960 --> 00:05:00,880
and task two might run forever and this

00:04:58,960 --> 00:05:01,840
is actually quite serious problem and it

00:05:00,880 --> 00:05:04,960
can happen

00:05:01,840 --> 00:05:05,600
uh very easily in a complex system like

00:05:04,960 --> 00:05:08,720
linux

00:05:05,600 --> 00:05:10,800
if you're not very careful now one way

00:05:08,720 --> 00:05:14,000
that linux can handle this

00:05:10,800 --> 00:05:16,000
is that in the moment when task 1 wants

00:05:14,000 --> 00:05:19,120
that lock that task 2

00:05:16,000 --> 00:05:21,039
that task 3 has then

00:05:19,120 --> 00:05:22,639
linux will do something called priority

00:05:21,039 --> 00:05:25,199
boosting and it'll actually

00:05:22,639 --> 00:05:26,400
boost the priority right actually called

00:05:25,199 --> 00:05:27,759
priority inheritance

00:05:26,400 --> 00:05:30,080
but we often talk about priority

00:05:27,759 --> 00:05:30,639
boosting the priority of task three will

00:05:30,080 --> 00:05:33,919
actually get

00:05:30,639 --> 00:05:37,120
boosted to the level of task one

00:05:33,919 --> 00:05:38,320
and now when task three is running to

00:05:37,120 --> 00:05:40,720
free that lock

00:05:38,320 --> 00:05:41,919
there is no chance that task 2 can

00:05:40,720 --> 00:05:43,840
become involved

00:05:41,919 --> 00:05:46,080
because task 2 has a lower priority than

00:05:43,840 --> 00:05:47,840
task 1 and task 3 currently is running

00:05:46,080 --> 00:05:50,240
at the priority of task 1.

00:05:47,840 --> 00:05:51,039
now in the moment when task 3 gives up

00:05:50,240 --> 00:05:53,440
that lock

00:05:51,039 --> 00:05:55,360
in that exact moment then task three

00:05:53,440 --> 00:05:56,160
will be deboosted it'll go back to its

00:05:55,360 --> 00:05:59,680
old priority

00:05:56,160 --> 00:06:00,960
and now task one can run with the lock

00:05:59,680 --> 00:06:04,240
so we can actually grab the lock

00:06:00,960 --> 00:06:05,039
and keep running so this is how priority

00:06:04,240 --> 00:06:07,840
inversion

00:06:05,039 --> 00:06:07,840
is avoided

00:06:08,800 --> 00:06:12,639
now in general when you're writing

00:06:11,280 --> 00:06:14,639
real-time applications

00:06:12,639 --> 00:06:16,319
under linux and this is actually one of

00:06:14,639 --> 00:06:17,120
the nice features of writing real-time

00:06:16,319 --> 00:06:19,360
applications

00:06:17,120 --> 00:06:21,520
under linux is that everything is done

00:06:19,360 --> 00:06:22,560
with the postx api so there actually is

00:06:21,520 --> 00:06:25,280
a real-time

00:06:22,560 --> 00:06:26,960
extension to posix that's defined in the

00:06:25,280 --> 00:06:30,560
posix standard and

00:06:26,960 --> 00:06:34,000
this is what linux is using to implement

00:06:30,560 --> 00:06:37,280
the real-time functionality

00:06:34,000 --> 00:06:38,960
for linux right so basically if you're

00:06:37,280 --> 00:06:40,880
used to working with file descriptors

00:06:38,960 --> 00:06:42,160
and opening close and reads and writes

00:06:40,880 --> 00:06:43,280
and creating sockets and all these

00:06:42,160 --> 00:06:46,240
things

00:06:43,280 --> 00:06:47,680
that are posix then you'll also be very

00:06:46,240 --> 00:06:50,960
comfortable writing things

00:06:47,680 --> 00:06:53,919
for linux with real time and in fact

00:06:50,960 --> 00:06:55,599
sked.h time.h and p thread.h are the

00:06:53,919 --> 00:06:58,240
only headers you really need

00:06:55,599 --> 00:07:00,000
to have full access to all of the

00:06:58,240 --> 00:07:01,520
real-time functions in linux so this is

00:07:00,000 --> 00:07:02,800
something that's really nice for writing

00:07:01,520 --> 00:07:05,440
applications real-time applications

00:07:02,800 --> 00:07:05,440
under linux

00:07:05,520 --> 00:07:10,800
now the scheduling policies in linux

00:07:08,560 --> 00:07:12,560
vary depending on real-time or non-real

00:07:10,800 --> 00:07:14,639
time so there are currently

00:07:12,560 --> 00:07:16,240
three different scheduling policies for

00:07:14,639 --> 00:07:17,840
non-real-time tasks

00:07:16,240 --> 00:07:19,520
and really the important thing to

00:07:17,840 --> 00:07:21,599
understand between non-real-time

00:07:19,520 --> 00:07:24,160
policies and real-time policies

00:07:21,599 --> 00:07:25,759
is that non-real-time policies have a

00:07:24,160 --> 00:07:29,120
fixed time slice

00:07:25,759 --> 00:07:29,840
so it means at some point it doesn't

00:07:29,120 --> 00:07:32,639
matter if it's

00:07:29,840 --> 00:07:33,280
in a busy waiting loop in an infinite

00:07:32,639 --> 00:07:34,960
loop just

00:07:33,280 --> 00:07:36,800
going and going going if it's a

00:07:34,960 --> 00:07:39,199
non-real-time priority

00:07:36,800 --> 00:07:40,000
it will eventually get scheduled out

00:07:39,199 --> 00:07:41,520
right

00:07:40,000 --> 00:07:43,280
and this is actually what's nice so we

00:07:41,520 --> 00:07:44,960
don't have to worry about applications

00:07:43,280 --> 00:07:45,520
going out of control or taking over the

00:07:44,960 --> 00:07:47,680
system

00:07:45,520 --> 00:07:50,479
because they have certain time slices

00:07:47,680 --> 00:07:53,680
and actually on your real-time system i

00:07:50,479 --> 00:07:54,720
expect that most of the tasks running on

00:07:53,680 --> 00:07:57,039
that system

00:07:54,720 --> 00:07:58,080
will be with the non-real-time priority

00:07:57,039 --> 00:08:00,639
right so we have

00:07:58,080 --> 00:08:02,000
logging daemons or maybe web servers or

00:08:00,639 --> 00:08:04,879
any other kinds of uh

00:08:02,000 --> 00:08:05,840
in middleware tasks and databases and

00:08:04,879 --> 00:08:07,280
things like this

00:08:05,840 --> 00:08:09,120
things that are accessing the file

00:08:07,280 --> 00:08:10,960
system these

00:08:09,120 --> 00:08:13,199
probably should not be running as real

00:08:10,960 --> 00:08:15,039
time tasks and so these are all things

00:08:13,199 --> 00:08:15,759
that are very well suited for non-real

00:08:15,039 --> 00:08:17,280
time

00:08:15,759 --> 00:08:18,879
now some people could ask well why am i

00:08:17,280 --> 00:08:20,000
even talking about non-real time this is

00:08:18,879 --> 00:08:22,000
a real time talk

00:08:20,000 --> 00:08:24,879
and the reason is is because even these

00:08:22,000 --> 00:08:27,919
non-real-time tasks you have a lot of

00:08:24,879 --> 00:08:31,520
chances to still configure

00:08:27,919 --> 00:08:33,039
how they take over the cpu or how they

00:08:31,520 --> 00:08:34,399
get their piece of cpu so there's things

00:08:33,039 --> 00:08:36,159
like nice values

00:08:34,399 --> 00:08:37,680
there are things like control groups

00:08:36,159 --> 00:08:39,519
where you can actually limit

00:08:37,680 --> 00:08:41,440
for different tasks how much cpu they

00:08:39,519 --> 00:08:42,880
can have now this is

00:08:41,440 --> 00:08:45,279
not this has nothing to do with real

00:08:42,880 --> 00:08:46,399
time but it gives you the opportunity to

00:08:45,279 --> 00:08:48,160
say for example

00:08:46,399 --> 00:08:50,399
my web server is more important than

00:08:48,160 --> 00:08:52,320
mine logging daemon or vice versa

00:08:50,399 --> 00:08:55,279
or to say i want to make sure if i have

00:08:52,320 --> 00:08:57,279
a web browser running on my

00:08:55,279 --> 00:08:58,959
real-time system i want to make sure the

00:08:57,279 --> 00:09:00,880
web browser never takes more than twenty

00:08:58,959 --> 00:09:03,360
percent of the cpu and things like this

00:09:00,880 --> 00:09:06,000
these are all things that i can package

00:09:03,360 --> 00:09:08,560
my non-real-time applications into cages

00:09:06,000 --> 00:09:09,680
and as i really strongly encourage you

00:09:08,560 --> 00:09:12,720
to take the time

00:09:09,680 --> 00:09:15,040
to not only evaluate the real-time tasks

00:09:12,720 --> 00:09:16,399
but to say how can i optimally the

00:09:15,040 --> 00:09:19,040
non-real-time task

00:09:16,399 --> 00:09:20,160
within each other under with you know

00:09:19,040 --> 00:09:21,760
for them

00:09:20,160 --> 00:09:23,279
this whole group of non-real-time tasks

00:09:21,760 --> 00:09:26,160
how can i optimally

00:09:23,279 --> 00:09:27,760
make sure that they are also sharing the

00:09:26,160 --> 00:09:29,120
cpu in a way that makes sense for my

00:09:27,760 --> 00:09:31,519
system

00:09:29,120 --> 00:09:32,640
now for the real-time tasks these are

00:09:31,519 --> 00:09:34,720
all tasks

00:09:32,640 --> 00:09:36,000
that run as long as they want to run so

00:09:34,720 --> 00:09:37,600
the only chance

00:09:36,000 --> 00:09:39,760
for example if i have a real time task

00:09:37,600 --> 00:09:40,320
with priority 30 and the only way i'm

00:09:39,760 --> 00:09:43,760
going to be

00:09:40,320 --> 00:09:45,279
that is going to end is if a priority

00:09:43,760 --> 00:09:46,959
you know something higher than 30

00:09:45,279 --> 00:09:47,360
actually comes in and says i want to do

00:09:46,959 --> 00:09:49,360
something

00:09:47,360 --> 00:09:51,120
becomes runnable right so with a

00:09:49,360 --> 00:09:52,480
real-time task you have to be really

00:09:51,120 --> 00:09:54,240
careful with your code

00:09:52,480 --> 00:09:56,080
you're not allowed to have some bugs

00:09:54,240 --> 00:09:56,720
like possible infinite loops because it

00:09:56,080 --> 00:09:59,440
could really

00:09:56,720 --> 00:10:00,240
render the system dead or appear to be

00:09:59,440 --> 00:10:02,240
dead

00:10:00,240 --> 00:10:04,640
just because this high priority task is

00:10:02,240 --> 00:10:06,480
has run away with the cpu right

00:10:04,640 --> 00:10:08,880
now the sched fifo is typically what

00:10:06,480 --> 00:10:10,560
people use this means that i get the cpu

00:10:08,880 --> 00:10:11,760
as long as i want and then at some point

00:10:10,560 --> 00:10:13,279
i'll go to sleep

00:10:11,760 --> 00:10:15,120
because i want to go to sleep because

00:10:13,279 --> 00:10:16,640
i'm waiting for an event or maybe i'm

00:10:15,120 --> 00:10:17,680
blocking them some sort of i o or

00:10:16,640 --> 00:10:19,360
there's some there's some reason for me

00:10:17,680 --> 00:10:20,959
to block i'm blocking a resource

00:10:19,360 --> 00:10:23,120
and at that point i will actually go

00:10:20,959 --> 00:10:26,720
into maybe the d state or the s state

00:10:23,120 --> 00:10:28,399
and freely give up the cpu right

00:10:26,720 --> 00:10:29,680
but as long as i actually have something

00:10:28,399 --> 00:10:31,760
to do as long as i'm in the runnable

00:10:29,680 --> 00:10:33,120
state i can run as long as i want

00:10:31,760 --> 00:10:35,279
unless someone with higher priority

00:10:33,120 --> 00:10:37,360
comes and with sched fifa you have

00:10:35,279 --> 00:10:40,800
priorities from 1 to 99

00:10:37,360 --> 00:10:43,040
1 is the lowest 99 is the highest

00:10:40,800 --> 00:10:44,000
although please don't ever use 99 for

00:10:43,040 --> 00:10:45,519
your applications

00:10:44,000 --> 00:10:47,920
there are some kernel threads that are

00:10:45,519 --> 00:10:49,279
very important that run at priority 99

00:10:47,920 --> 00:10:51,279
uh they are more important than your

00:10:49,279 --> 00:10:52,640
application so

00:10:51,279 --> 00:10:54,800
in my opinion you should never run

00:10:52,640 --> 00:10:57,440
between more than 98

00:10:54,800 --> 00:10:59,120
for your highest priority now there's

00:10:57,440 --> 00:11:01,680
another policy called sched

00:10:59,120 --> 00:11:02,959
robins get rr and this is exactly like

00:11:01,680 --> 00:11:04,800
sched fifo actually

00:11:02,959 --> 00:11:07,600
the only difference is if i have two

00:11:04,800 --> 00:11:10,000
prior two tasks with the same priority

00:11:07,600 --> 00:11:11,680
then there actually will be time slices

00:11:10,000 --> 00:11:13,440
between these two tasks of the same

00:11:11,680 --> 00:11:15,680
priority right so if i choose to make

00:11:13,440 --> 00:11:17,279
myself sched round robin if i

00:11:15,680 --> 00:11:19,600
if i'm a task running with sched round

00:11:17,279 --> 00:11:22,560
robin then i have set a

00:11:19,600 --> 00:11:23,200
time slice for myself if there's another

00:11:22,560 --> 00:11:24,959
task

00:11:23,200 --> 00:11:26,240
with the same priority that's waiting to

00:11:24,959 --> 00:11:27,600
get on the cpu right

00:11:26,240 --> 00:11:30,000
that's the only time otherwise it's

00:11:27,600 --> 00:11:31,680
exactly the same as sched fifo

00:11:30,000 --> 00:11:33,120
deadline i'm not going to talk about it

00:11:31,680 --> 00:11:35,120
all this actually doesn't

00:11:33,120 --> 00:11:37,600
fit into this picture it's a as another

00:11:35,120 --> 00:11:41,200
type of priority management

00:11:37,600 --> 00:11:42,480
in which case the scheduler decides on

00:11:41,200 --> 00:11:45,519
the priorities

00:11:42,480 --> 00:11:47,760
based on timing constraints there's some

00:11:45,519 --> 00:11:49,519
great talks from steven rosted if you go

00:11:47,760 --> 00:11:50,639
on youtube or something like this

00:11:49,519 --> 00:11:52,720
if you're interested about sched

00:11:50,639 --> 00:11:54,480
deadline the only thing that i want to

00:11:52,720 --> 00:11:55,760
mention here is if you do do anything

00:11:54,480 --> 00:11:58,560
with sched

00:11:55,760 --> 00:12:00,800
scad deadline wins over the highest

00:11:58,560 --> 00:12:03,680
priority scad fifo scout rod robin

00:12:00,800 --> 00:12:04,959
yeah so sched deadline if you decide to

00:12:03,680 --> 00:12:06,560
do something with scared deadline it

00:12:04,959 --> 00:12:09,200
will always win

00:12:06,560 --> 00:12:11,440
and the sched fifo scheduled robin they

00:12:09,200 --> 00:12:14,000
take a back seat just get deadline

00:12:11,440 --> 00:12:15,200
so you mixing them is a is a little bit

00:12:14,000 --> 00:12:16,880
strange uh

00:12:15,200 --> 00:12:18,639
almost a little bit of guaranteed

00:12:16,880 --> 00:12:20,399
priority inversion but you might be

00:12:18,639 --> 00:12:22,000
interested in only skid deadline

00:12:20,399 --> 00:12:24,480
you won't learn about that in this talk

00:12:22,000 --> 00:12:25,600
but you should know about it

00:12:24,480 --> 00:12:27,920
now one thing i mention here at the

00:12:25,600 --> 00:12:30,399
bottom which is really important is that

00:12:27,920 --> 00:12:33,040
by default the linux kernel

00:12:30,399 --> 00:12:34,880
limits the amount of time that all

00:12:33,040 --> 00:12:36,079
real-time tasks are allowed to use the

00:12:34,880 --> 00:12:39,279
cpu

00:12:36,079 --> 00:12:41,519
so if the combination of cpu site cpu

00:12:39,279 --> 00:12:43,920
time for all of the real-time tasks

00:12:41,519 --> 00:12:47,040
adds up to more than 95 percent of a

00:12:43,920 --> 00:12:49,760
second 950 milliseconds within a second

00:12:47,040 --> 00:12:51,519
then for those last 50 milliseconds no

00:12:49,760 --> 00:12:53,360
real time task is allowed to run

00:12:51,519 --> 00:12:54,639
now this is the worst kind of priority

00:12:53,360 --> 00:12:55,680
version you could have and you need to

00:12:54,639 --> 00:12:58,240
make sure

00:12:55,680 --> 00:12:58,959
that that does not happen in your system

00:12:58,240 --> 00:13:02,000
so

00:12:58,959 --> 00:13:04,880
this proxis kernel scad rt runtime

00:13:02,000 --> 00:13:07,120
us this is an option that where you can

00:13:04,880 --> 00:13:09,680
configure that maximum time

00:13:07,120 --> 00:13:11,279
setting that to a minus 1 will disable

00:13:09,680 --> 00:13:12,959
this feature because

00:13:11,279 --> 00:13:14,639
this is really a dangerous feature in a

00:13:12,959 --> 00:13:16,959
real time system

00:13:14,639 --> 00:13:18,240
because if you do hit that limit and it

00:13:16,959 --> 00:13:20,000
you'll see a message to show up in the

00:13:18,240 --> 00:13:20,880
kernel log so d message you'll see that

00:13:20,000 --> 00:13:23,920
it hit that

00:13:20,880 --> 00:13:25,839
it's called a runtime throttling and if

00:13:23,920 --> 00:13:27,680
you hit this runtime throttling

00:13:25,839 --> 00:13:29,519
then basically your system is broken

00:13:27,680 --> 00:13:30,000
because you went 50 50 milliseconds

00:13:29,519 --> 00:13:32,399
without

00:13:30,000 --> 00:13:33,440
any real-time tasks at all so make sure

00:13:32,399 --> 00:13:36,240
to disable that

00:13:33,440 --> 00:13:37,440
it's not a compiler option uh it won't

00:13:36,240 --> 00:13:39,279
it's not persistent you're going to

00:13:37,440 --> 00:13:41,600
actually have to write a boot script

00:13:39,279 --> 00:13:42,639
to echo a minus one into there every

00:13:41,600 --> 00:13:45,839
single time you boot

00:13:42,639 --> 00:13:48,160
don't forget this really important

00:13:45,839 --> 00:13:50,240
this slide is just basically showing you

00:13:48,160 --> 00:13:51,680
how you can set the priority of tasks so

00:13:50,240 --> 00:13:54,880
every single thread

00:13:51,680 --> 00:13:56,959
a task is a thread or a process

00:13:54,880 --> 00:13:58,720
and every single thread or tab i'm going

00:13:56,959 --> 00:14:01,040
to say the word task but it means

00:13:58,720 --> 00:14:03,120
threads or processes every task can have

00:14:01,040 --> 00:14:05,519
its own real time priority or sched

00:14:03,120 --> 00:14:09,040
other with nice values things like this

00:14:05,519 --> 00:14:12,880
with the chrt tool here is how i can

00:14:09,040 --> 00:14:15,040
set the real time priority and policy

00:14:12,880 --> 00:14:16,000
for certain tasks so with the minus

00:14:15,040 --> 00:14:18,079
there's a minus p

00:14:16,000 --> 00:14:20,000
option that i can give and this will

00:14:18,079 --> 00:14:23,279
specify for example the

00:14:20,000 --> 00:14:25,279
the thread id of a running task

00:14:23,279 --> 00:14:27,839
so i can actually modify the real time

00:14:25,279 --> 00:14:30,320
priority and policy of a running task

00:14:27,839 --> 00:14:31,920
or i can actually start an application

00:14:30,320 --> 00:14:35,279
running so i do chrt

00:14:31,920 --> 00:14:36,639
minus f for fifo priority of 10

00:14:35,279 --> 00:14:38,079
and then i can actually type the name of

00:14:36,639 --> 00:14:40,240
the application and actually start with

00:14:38,079 --> 00:14:42,480
that priority

00:14:40,240 --> 00:14:43,360
here you also see within skid.h you can

00:14:42,480 --> 00:14:45,920
use

00:14:43,360 --> 00:14:46,480
set scheduler you can also through this

00:14:45,920 --> 00:14:48,800
function

00:14:46,480 --> 00:14:50,000
programmatically set your own priorities

00:14:48,800 --> 00:14:52,480
so if you prefer that

00:14:50,000 --> 00:14:53,279
instead of your boot scripts or external

00:14:52,480 --> 00:14:54,880
scripts

00:14:53,279 --> 00:14:56,160
properly setting the priorities you can

00:14:54,880 --> 00:14:56,959
actually hard code this in your

00:14:56,160 --> 00:14:58,639
applications

00:14:56,959 --> 00:15:02,320
that when they start they automatically

00:14:58,639 --> 00:15:02,320
choose the priorities that you feel fit

00:15:03,440 --> 00:15:07,440
scheduling is one topic but cpu affinity

00:15:06,079 --> 00:15:10,000
is also something that's

00:15:07,440 --> 00:15:12,480
very important because sometimes if i'm

00:15:10,000 --> 00:15:13,440
running my real-time applications it may

00:15:12,480 --> 00:15:15,440
be critical

00:15:13,440 --> 00:15:16,639
that i actually have them isolated on

00:15:15,440 --> 00:15:18,959
certain certain cpi

00:15:16,639 --> 00:15:21,120
cpus so i could let's say i have a

00:15:18,959 --> 00:15:22,320
system with eight cpus which is pretty

00:15:21,120 --> 00:15:24,399
common these days

00:15:22,320 --> 00:15:26,000
then maybe i have six cpus that i'm

00:15:24,399 --> 00:15:28,160
dedicating for the general

00:15:26,000 --> 00:15:29,440
system the web server logging daemon

00:15:28,160 --> 00:15:31,839
systemd maybe

00:15:29,440 --> 00:15:32,639
and then i have seep that the top two

00:15:31,839 --> 00:15:34,160
cpus

00:15:32,639 --> 00:15:36,880
i'm just using for the real-time

00:15:34,160 --> 00:15:39,120
application right so with cpu affinity

00:15:36,880 --> 00:15:41,440
cpu affinity is basically a bit mask of

00:15:39,120 --> 00:15:41,920
the cpus that a task is allowed to run

00:15:41,440 --> 00:15:44,800
on

00:15:41,920 --> 00:15:46,320
and this is also per task so this is per

00:15:44,800 --> 00:15:48,079
thread or per process

00:15:46,320 --> 00:15:49,839
you can actually say that this one task

00:15:48,079 --> 00:15:51,600
is only allowed to run on this cpu or

00:15:49,839 --> 00:15:53,759
these three cpus

00:15:51,600 --> 00:15:56,000
or however you want right so you can set

00:15:53,759 --> 00:15:59,040
the cpu affinity for tasks

00:15:56,000 --> 00:16:01,759
but you can also set cpu affinities

00:15:59,040 --> 00:16:02,720
for hardware interrupts which we'll look

00:16:01,759 --> 00:16:04,720
at in a second

00:16:02,720 --> 00:16:05,839
so when a hardware interrupt comes an

00:16:04,720 --> 00:16:08,399
actual interrupt on the

00:16:05,839 --> 00:16:10,240
in the interrupt line one of the cpus is

00:16:08,399 --> 00:16:13,519
going to have to service that interrupt

00:16:10,240 --> 00:16:15,360
and actually everyone is allowed to

00:16:13,519 --> 00:16:16,639
service it right so there is it doesn't

00:16:15,360 --> 00:16:17,680
matter who's allowed

00:16:16,639 --> 00:16:19,759
who's going to interrupt but it's

00:16:17,680 --> 00:16:22,160
whoever services that hardware interrupt

00:16:19,759 --> 00:16:24,320
is going to be interrupting whatever

00:16:22,160 --> 00:16:26,639
task was on the cpu before that

00:16:24,320 --> 00:16:27,360
right so if i have a real-time

00:16:26,639 --> 00:16:30,800
application

00:16:27,360 --> 00:16:32,959
on a certain cpu and i want to

00:16:30,800 --> 00:16:34,800
prevent it from being interrupted for

00:16:32,959 --> 00:16:37,040
example from hardware interrupts

00:16:34,800 --> 00:16:38,320
you can also set cpu affinities for the

00:16:37,040 --> 00:16:40,240
hardware interrupt handlers we'll take a

00:16:38,320 --> 00:16:42,160
look at that in a second

00:16:40,240 --> 00:16:44,160
and lastly it is also it's actually the

00:16:42,160 --> 00:16:46,399
third point the second point here is you

00:16:44,160 --> 00:16:47,199
can also boot the kernel and tell the

00:16:46,399 --> 00:16:49,920
kernel

00:16:47,199 --> 00:16:51,199
not to put any of its own kernel threads

00:16:49,920 --> 00:16:53,440
onto certain cpi

00:16:51,199 --> 00:16:54,240
cpus right so this is so a way that you

00:16:53,440 --> 00:16:55,279
can

00:16:54,240 --> 00:16:57,279
so you could do it so that when your

00:16:55,279 --> 00:16:59,920
computer boots your system boots

00:16:57,279 --> 00:17:00,639
you already have some cpus that are free

00:16:59,920 --> 00:17:01,920
for

00:17:00,639 --> 00:17:04,319
being assigned to your real-time

00:17:01,920 --> 00:17:06,720
application and the kernel will not be

00:17:04,319 --> 00:17:08,319
using that for itself

00:17:06,720 --> 00:17:09,839
now i will want to mention here in this

00:17:08,319 --> 00:17:11,039
last point here in this last little

00:17:09,839 --> 00:17:12,160
paragraph there

00:17:11,039 --> 00:17:15,360
it's really important that you

00:17:12,160 --> 00:17:17,760
understand that in a lot of systems

00:17:15,360 --> 00:17:18,799
the multiple cpus will share the same

00:17:17,760 --> 00:17:21,679
caches

00:17:18,799 --> 00:17:23,600
so make sure you're aware of how your

00:17:21,679 --> 00:17:25,679
system is architected

00:17:23,600 --> 00:17:27,679
that you know that for example two of

00:17:25,679 --> 00:17:29,039
the cpus are sharing a certain level two

00:17:27,679 --> 00:17:30,640
cache

00:17:29,039 --> 00:17:31,760
those are the two cpus that probably

00:17:30,640 --> 00:17:32,640
should be hosting the real-time

00:17:31,760 --> 00:17:33,919
application

00:17:32,640 --> 00:17:36,880
because otherwise if you have

00:17:33,919 --> 00:17:38,480
non-real-time tasks and real-time tasks

00:17:36,880 --> 00:17:40,559
they may be on different cpus but if

00:17:38,480 --> 00:17:42,960
they're sharing caches

00:17:40,559 --> 00:17:44,320
then that non-real-time task can have an

00:17:42,960 --> 00:17:45,679
adverse effect on the real-time

00:17:44,320 --> 00:17:46,799
application so you should just be aware

00:17:45,679 --> 00:17:50,720
of that

00:17:46,799 --> 00:17:50,720
of caching it's really important topic

00:17:51,600 --> 00:17:54,799
so in this example we're seeing how we

00:17:53,200 --> 00:17:57,600
can control the

00:17:54,799 --> 00:17:59,440
cpu affinity for applications so with

00:17:57,600 --> 00:18:01,440
the task set tool

00:17:59,440 --> 00:18:03,280
i can either start a program with a

00:18:01,440 --> 00:18:06,559
certain cpu affinity mask

00:18:03,280 --> 00:18:08,880
or i can modify the ta any task

00:18:06,559 --> 00:18:10,799
uh the cpu affinity mask for that task

00:18:08,880 --> 00:18:12,880
right so if i say task set minus p

00:18:10,799 --> 00:18:14,160
then it says pid but you're actually the

00:18:12,880 --> 00:18:17,440
task that there's a tid

00:18:14,160 --> 00:18:18,880
actually the task id that you provide

00:18:17,440 --> 00:18:19,840
there because you can do it per thread

00:18:18,880 --> 00:18:22,799
so i can actually

00:18:19,840 --> 00:18:24,640
set the mask for a thread now if i don't

00:18:22,799 --> 00:18:27,360
provide a mask i just say minus p

00:18:24,640 --> 00:18:29,600
and give the pid it'll actually tell me

00:18:27,360 --> 00:18:30,640
what the mask is for that thread at the

00:18:29,600 --> 00:18:33,679
moment right so i can

00:18:30,640 --> 00:18:35,120
look at what what the current mask is

00:18:33,679 --> 00:18:37,200
and also set new ones by the way that

00:18:35,120 --> 00:18:39,039
also works for

00:18:37,200 --> 00:18:40,480
chrt the tool we just looked at for

00:18:39,039 --> 00:18:42,559
changing priorities you can also

00:18:40,480 --> 00:18:45,520
see what is the current priority

00:18:42,559 --> 00:18:49,280
although in ps you can see that anyway

00:18:45,520 --> 00:18:50,720
so just like with setting the priorities

00:18:49,280 --> 00:18:53,280
in code we can also

00:18:50,720 --> 00:18:55,120
set the cpu affinity and code so if you

00:18:53,280 --> 00:18:56,240
want applications to set their own cpu

00:18:55,120 --> 00:18:59,120
affinity

00:18:56,240 --> 00:19:00,960
you can do that as well the reason why

00:18:59,120 --> 00:19:01,679
you need the new source to find here is

00:19:00,960 --> 00:19:04,559
because

00:19:01,679 --> 00:19:06,799
the sched set affinity is actually a

00:19:04,559 --> 00:19:08,640
function that is not part of posix it's

00:19:06,799 --> 00:19:10,960
implemented in the g lib c

00:19:08,640 --> 00:19:12,720
so but with this defined gnu source

00:19:10,960 --> 00:19:13,919
basically we're saying we know we're

00:19:12,720 --> 00:19:16,559
using a glibc

00:19:13,919 --> 00:19:17,679
so this function is available and you

00:19:16,559 --> 00:19:19,120
actually need that define

00:19:17,679 --> 00:19:21,440
for it to be available in the header

00:19:19,120 --> 00:19:21,440
file

00:19:22,160 --> 00:19:25,600
i talked about the boot parameters so

00:19:23,760 --> 00:19:28,400
you can actually have the kernel boot up

00:19:25,600 --> 00:19:30,160
and only see certain c only use certain

00:19:28,400 --> 00:19:31,520
cpus right so you have

00:19:30,160 --> 00:19:33,760
two different options for this one is

00:19:31,520 --> 00:19:37,440
called mac cpus this actually

00:19:33,760 --> 00:19:40,240
limits the number of cpus that the

00:19:37,440 --> 00:19:41,520
kernel can see right so i can actually

00:19:40,240 --> 00:19:42,080
for example if i have an eight core

00:19:41,520 --> 00:19:43,760
system

00:19:42,080 --> 00:19:46,559
i could actually if i set max cores to

00:19:43,760 --> 00:19:49,039
four uh the kernel will only

00:19:46,559 --> 00:19:50,160
allow four cpus to be used right so the

00:19:49,039 --> 00:19:53,679
other four cpus

00:19:50,160 --> 00:19:55,280
will be left completely alone and uh

00:19:53,679 --> 00:19:58,160
some people will use this for example to

00:19:55,280 --> 00:20:02,240
run certain bare metal applications

00:19:58,160 --> 00:20:04,880
perhaps for real um hardcore uh

00:20:02,240 --> 00:20:06,480
real time where they need basically busy

00:20:04,880 --> 00:20:08,400
waiting pulling applications

00:20:06,480 --> 00:20:09,679
uh similar to micro microprocessor

00:20:08,400 --> 00:20:10,000
applications that are running directly

00:20:09,679 --> 00:20:12,559
on

00:20:10,000 --> 00:20:14,000
bare metal on the hardware and those can

00:20:12,559 --> 00:20:15,520
then communicate through shared memory

00:20:14,000 --> 00:20:17,760
with linux or something like this

00:20:15,520 --> 00:20:19,120
anyway using mac cpus you can do that so

00:20:17,760 --> 00:20:20,400
we can restrict linux to a certain

00:20:19,120 --> 00:20:21,760
number of cores and then we can run our

00:20:20,400 --> 00:20:22,799
bare metal applications on the other

00:20:21,760 --> 00:20:26,000
course

00:20:22,799 --> 00:20:26,640
iso cpus works differently with iso cpus

00:20:26,000 --> 00:20:28,559
express

00:20:26,640 --> 00:20:29,679
they specify certain cpus where i want

00:20:28,559 --> 00:20:31,919
linux to

00:20:29,679 --> 00:20:33,120
not put any of its own kernels and when

00:20:31,919 --> 00:20:34,960
it starts applica

00:20:33,120 --> 00:20:36,880
any of its own kernel threads and when

00:20:34,960 --> 00:20:38,159
it starts applications it will also

00:20:36,880 --> 00:20:38,720
start those applications with the

00:20:38,159 --> 00:20:40,880
default

00:20:38,720 --> 00:20:42,960
cpu affinity mask so that nothing

00:20:40,880 --> 00:20:44,640
appears on those cpus so basically we've

00:20:42,960 --> 00:20:47,280
isolated some cpus

00:20:44,640 --> 00:20:48,720
however linux is aware of those cpus and

00:20:47,280 --> 00:20:50,559
is allowed to use them right so

00:20:48,720 --> 00:20:52,240
basically when the system boots

00:20:50,559 --> 00:20:54,240
there will certain there'll be some cpus

00:20:52,240 --> 00:20:55,840
that are free and then i can choose to

00:20:54,240 --> 00:20:59,440
start my real-time applications

00:20:55,840 --> 00:21:01,919
on those cpus the next two sections of

00:20:59,440 --> 00:21:03,760
the slide they're showing how you can

00:21:01,919 --> 00:21:06,799
set the default cpu

00:21:03,760 --> 00:21:08,799
this the default smpf affinity

00:21:06,799 --> 00:21:10,720
for for example when a new interrupt

00:21:08,799 --> 00:21:14,240
handler is registered

00:21:10,720 --> 00:21:16,400
what do i want the cpu affinity for that

00:21:14,240 --> 00:21:18,000
hardware interrupt handler to be yeah so

00:21:16,400 --> 00:21:20,000
that'll be the default

00:21:18,000 --> 00:21:21,039
and for interrupts that are already

00:21:20,000 --> 00:21:23,440
registered

00:21:21,039 --> 00:21:24,240
you can actually go into proc irq and

00:21:23,440 --> 00:21:26,000
then you can

00:21:24,240 --> 00:21:27,440
look in the effective affinity this is

00:21:26,000 --> 00:21:29,919
what's showing you what

00:21:27,440 --> 00:21:30,880
the cpu affinity mask for that hardware

00:21:29,919 --> 00:21:33,919
interrupt handler

00:21:30,880 --> 00:21:37,039
and you can write values write mask

00:21:33,919 --> 00:21:37,600
values into the smp affinity virtual

00:21:37,039 --> 00:21:39,440
file

00:21:37,600 --> 00:21:41,840
to actually change that just make sure

00:21:39,440 --> 00:21:43,600
you look in the effective affinity

00:21:41,840 --> 00:21:45,280
after you write into the s p affinity

00:21:43,600 --> 00:21:49,280
because some hardware is not

00:21:45,280 --> 00:21:50,880
capable of arbitrarily assigning cpus to

00:21:49,280 --> 00:21:52,480
hardware interrupt handlers right so

00:21:50,880 --> 00:21:54,080
you can put whatever value you want into

00:21:52,480 --> 00:21:56,480
smp affinity then

00:21:54,080 --> 00:21:59,840
check the effective affinity to see what

00:21:56,480 --> 00:21:59,840
was actually set

00:22:00,480 --> 00:22:04,080
memory management with real-time

00:22:02,159 --> 00:22:06,159
applications is actually

00:22:04,080 --> 00:22:08,240
probably the most important topic when

00:22:06,159 --> 00:22:10,400
you're talking about real-time

00:22:08,240 --> 00:22:11,440
developing and possible latency it's

00:22:10,400 --> 00:22:15,440
because the

00:22:11,440 --> 00:22:18,000
kernel memory management func functions

00:22:15,440 --> 00:22:18,960
as i'll explain right now basically

00:22:18,000 --> 00:22:21,919
anytime

00:22:18,960 --> 00:22:23,600
you allocate memory you don't actually

00:22:21,919 --> 00:22:25,679
get the physical memory

00:22:23,600 --> 00:22:28,240
assigned to you so you do a malloc

00:22:25,679 --> 00:22:30,320
you're going to receive a pointer back

00:22:28,240 --> 00:22:32,080
and it's going to be marked in your mmu

00:22:30,320 --> 00:22:34,240
table so it's going to be marked that

00:22:32,080 --> 00:22:36,640
okay this amount of memory has been

00:22:34,240 --> 00:22:37,840
assigned in my virtual address space but

00:22:36,640 --> 00:22:40,159
there are actually no

00:22:37,840 --> 00:22:41,440
physical memory mappings behind that

00:22:40,159 --> 00:22:43,039
there are no pages that have been

00:22:41,440 --> 00:22:45,039
assigned to that yet

00:22:43,039 --> 00:22:46,960
and this is only when you actually

00:22:45,039 --> 00:22:49,039
access that memory

00:22:46,960 --> 00:22:50,240
the first time when i try to write to it

00:22:49,039 --> 00:22:52,960
for example

00:22:50,240 --> 00:22:54,720
that generated a mmu exception and

00:22:52,960 --> 00:22:57,120
actually create a page fault

00:22:54,720 --> 00:22:58,640
the kernel has a handler for this page

00:22:57,120 --> 00:23:00,880
fault and in that moment it's

00:22:58,640 --> 00:23:01,760
going to find a free page so if you're

00:23:00,880 --> 00:23:03,760
generally four

00:23:01,760 --> 00:23:05,440
kilobyte block of memory physical ram

00:23:03,760 --> 00:23:07,200
it'll search for a free one

00:23:05,440 --> 00:23:08,880
and then it'll do the assignment and

00:23:07,200 --> 00:23:11,679
then the application can continue

00:23:08,880 --> 00:23:13,120
right so malik is actually very very

00:23:11,679 --> 00:23:14,880
fast if you do timing you can see that

00:23:13,120 --> 00:23:16,799
malik is really really fast

00:23:14,880 --> 00:23:18,559
but as soon as you start touching that

00:23:16,799 --> 00:23:20,080
data then all of a sudden it's really

00:23:18,559 --> 00:23:21,520
expensive the first time

00:23:20,080 --> 00:23:23,600
once that page fault is happening and

00:23:21,520 --> 00:23:25,360
the memory is there then we're okay

00:23:23,600 --> 00:23:26,880
and this is not just for the heap with

00:23:25,360 --> 00:23:29,120
malik's this is for

00:23:26,880 --> 00:23:29,919
all components of the processor virtual

00:23:29,120 --> 00:23:33,120
address space

00:23:29,919 --> 00:23:35,360
so even the text segment the initialize

00:23:33,120 --> 00:23:36,480
initialized data segments the stack and

00:23:35,360 --> 00:23:38,559
the heap right

00:23:36,480 --> 00:23:40,400
so for example we're talking about the

00:23:38,559 --> 00:23:43,520
stack when the stack grows

00:23:40,400 --> 00:23:44,559
just moving into the next page because

00:23:43,520 --> 00:23:46,960
the stack

00:23:44,559 --> 00:23:48,480
stack has grown to the next page that's

00:23:46,960 --> 00:23:49,039
going to initially cause a page fault

00:23:48,480 --> 00:23:51,760
right so

00:23:49,039 --> 00:23:52,640
the page faults are quite expensive

00:23:51,760 --> 00:23:54,000
which means

00:23:52,640 --> 00:23:55,440
we this is something that you want to

00:23:54,000 --> 00:23:57,679
avoid and i'll show you how to avoid

00:23:55,440 --> 00:23:59,840
that

00:23:57,679 --> 00:24:01,919
there's basically three steps that you

00:23:59,840 --> 00:24:04,400
need to do when you're doing avoiding

00:24:01,919 --> 00:24:05,520
the first one is you need to tune glib

00:24:04,400 --> 00:24:07,600
see's malloc

00:24:05,520 --> 00:24:10,000
to make sure it's actually using the

00:24:07,600 --> 00:24:11,840
heap because there are two ways that

00:24:10,000 --> 00:24:13,679
glibc can allocate memory it can

00:24:11,840 --> 00:24:15,520
actually use its heap whereas

00:24:13,679 --> 00:24:17,840
calling really calling the the system

00:24:15,520 --> 00:24:19,039
break system call to actually increase

00:24:17,840 --> 00:24:21,840
the the heap as

00:24:19,039 --> 00:24:22,960
most people learn in universities the

00:24:21,840 --> 00:24:25,360
other method that

00:24:22,960 --> 00:24:26,159
glibc can use to allocate memory is it

00:24:25,360 --> 00:24:28,000
can actually do an

00:24:26,159 --> 00:24:29,679
map and in this case it's actually

00:24:28,000 --> 00:24:30,480
requesting the memory directly from the

00:24:29,679 --> 00:24:32,880
kernel

00:24:30,480 --> 00:24:34,000
and that kernel is going to provide a

00:24:32,880 --> 00:24:35,520
block of memory

00:24:34,000 --> 00:24:37,120
that's not within this heap it's

00:24:35,520 --> 00:24:39,760
something totally separate

00:24:37,120 --> 00:24:40,799
right and we don't want to use the

00:24:39,760 --> 00:24:43,520
separate memory

00:24:40,799 --> 00:24:45,120
this separate uh memory mapping version

00:24:43,520 --> 00:24:47,679
of allocation

00:24:45,120 --> 00:24:48,320
because when i get something from the

00:24:47,679 --> 00:24:50,320
kernel

00:24:48,320 --> 00:24:52,080
within within malik and this art within

00:24:50,320 --> 00:24:52,480
this way and then i do a free then it

00:24:52,080 --> 00:24:55,039
goes

00:24:52,480 --> 00:24:56,880
back to the kernel and that means that

00:24:55,039 --> 00:24:57,279
the next time i do a malik i will get

00:24:56,880 --> 00:24:59,120
some

00:24:57,279 --> 00:25:01,039
fresh i'm going to get some fresh

00:24:59,120 --> 00:25:03,120
unpaged memory again

00:25:01,039 --> 00:25:04,640
i need to page all of that that first

00:25:03,120 --> 00:25:07,360
addre that first

00:25:04,640 --> 00:25:09,039
axis is very expensive and when i do a

00:25:07,360 --> 00:25:11,120
free it's gone again right so you're

00:25:09,039 --> 00:25:12,640
guaranteed if when you do the map

00:25:11,120 --> 00:25:14,000
is you're going to keep getting lots and

00:25:12,640 --> 00:25:14,720
lots of page faults and we don't want

00:25:14,000 --> 00:25:16,880
this

00:25:14,720 --> 00:25:19,039
what we want is we want basically to use

00:25:16,880 --> 00:25:22,640
this heap area with our malik

00:25:19,039 --> 00:25:24,080
and we want that to be paged

00:25:22,640 --> 00:25:26,240
to be paged in so we're going to cause

00:25:24,080 --> 00:25:27,039
these page faults and we want to hold on

00:25:26,240 --> 00:25:30,000
to that so

00:25:27,039 --> 00:25:30,880
that's what we need to tune glib c to

00:25:30,000 --> 00:25:33,520
make sure it's

00:25:30,880 --> 00:25:33,919
always using the heap never going with

00:25:33,520 --> 00:25:37,200
the

00:25:33,919 --> 00:25:39,200
memory mappings we also need to

00:25:37,200 --> 00:25:40,480
lock down the allocated pages because we

00:25:39,200 --> 00:25:42,159
want to make sure

00:25:40,480 --> 00:25:43,919
that pages that we've allocated memory

00:25:42,159 --> 00:25:47,120
of allocate never goes back

00:25:43,919 --> 00:25:48,400
into the kernel or is never recycled or

00:25:47,120 --> 00:25:50,080
used for something else

00:25:48,400 --> 00:25:52,240
now this is typically we know this as

00:25:50,080 --> 00:25:53,440
swapping and some of you out there by

00:25:52,240 --> 00:25:54,799
saying we have an embedded system we

00:25:53,440 --> 00:25:58,400
don't do swapping

00:25:54,799 --> 00:26:00,880
you're wrong there are pieces of your

00:25:58,400 --> 00:26:02,640
process address space that are available

00:26:00,880 --> 00:26:05,200
on disk and that's for example

00:26:02,640 --> 00:26:07,360
the tech segments so if the kernel

00:26:05,200 --> 00:26:09,919
really runs low on physical ram

00:26:07,360 --> 00:26:11,039
it's going to start recycling all of the

00:26:09,919 --> 00:26:12,799
pages it can

00:26:11,039 --> 00:26:14,720
where it knows they can get a copy again

00:26:12,799 --> 00:26:17,120
so this includes for example

00:26:14,720 --> 00:26:18,640
the text segment so the function the

00:26:17,120 --> 00:26:19,520
execu the code that's actually getting

00:26:18,640 --> 00:26:21,679
executed

00:26:19,520 --> 00:26:23,120
could actually get paged out right and

00:26:21,679 --> 00:26:24,159
this would be horrible because it means

00:26:23,120 --> 00:26:26,159
the next time

00:26:24,159 --> 00:26:27,840
your application gets the cpu and tries

00:26:26,159 --> 00:26:29,200
to execute an instruction

00:26:27,840 --> 00:26:31,200
that's going to cause a page fault and

00:26:29,200 --> 00:26:32,640
it has to pull that back from disk which

00:26:31,200 --> 00:26:34,159
could be quite expensive

00:26:32,640 --> 00:26:35,840
so don't think just because you don't

00:26:34,159 --> 00:26:36,880
have a swap file you're immune from

00:26:35,840 --> 00:26:39,279
swapping

00:26:36,880 --> 00:26:40,159
that is not true so we need to make sure

00:26:39,279 --> 00:26:43,279
we lock down

00:26:40,159 --> 00:26:46,159
our pages for our real-time application

00:26:43,279 --> 00:26:47,840
so that they cannot be paged out

00:26:46,159 --> 00:26:49,679
on the third step on here is

00:26:47,840 --> 00:26:52,400
pre-faulting and this means

00:26:49,679 --> 00:26:54,000
we want to create a heap and we want to

00:26:52,400 --> 00:26:55,520
pre-fault we want to cause all the page

00:26:54,000 --> 00:26:58,960
faults in that heap

00:26:55,520 --> 00:27:00,640
and then we have memory available to us

00:26:58,960 --> 00:27:02,799
that's already ready to go

00:27:00,640 --> 00:27:04,880
right and this also goes for the stack

00:27:02,799 --> 00:27:07,200
we don't want our stack to be growing

00:27:04,880 --> 00:27:08,720
and then suddenly we move into a new

00:27:07,200 --> 00:27:09,520
page and it causes a page fault we don't

00:27:08,720 --> 00:27:12,080
want that

00:27:09,520 --> 00:27:13,520
we want or it doesn't matter how deep we

00:27:12,080 --> 00:27:15,039
go in our stack we want to make sure

00:27:13,520 --> 00:27:15,919
that's already memory that has already

00:27:15,039 --> 00:27:18,159
generated page

00:27:15,919 --> 00:27:19,120
page faults so that we don't get

00:27:18,159 --> 00:27:22,559
surprised

00:27:19,120 --> 00:27:22,559
if our stack gets a little bit bigger

00:27:22,799 --> 00:27:26,240
so here we can see for the first two

00:27:25,039 --> 00:27:29,200
steps of

00:27:26,240 --> 00:27:30,159
how we can tune glib c so here in this

00:27:29,200 --> 00:27:33,120
first one we see

00:27:30,159 --> 00:27:34,000
the mal opt function here first of all

00:27:33,120 --> 00:27:36,080
we're telling

00:27:34,000 --> 00:27:37,039
the maximum we're saying the maximum

00:27:36,080 --> 00:27:40,080
size

00:27:37,039 --> 00:27:42,320
for doing an map is zero which basically

00:27:40,080 --> 00:27:44,880
is disabling it which means

00:27:42,320 --> 00:27:46,640
glibc will never do an map to get that

00:27:44,880 --> 00:27:48,399
memory for this application it will

00:27:46,640 --> 00:27:49,600
always go to the heap which is what we

00:27:48,399 --> 00:27:50,799
want

00:27:49,600 --> 00:27:53,679
the second thing we're doing here is

00:27:50,799 --> 00:27:56,159
we're disabling the trimming of the heap

00:27:53,679 --> 00:27:56,720
so this is also implemented in glib c

00:27:56,159 --> 00:27:58,720
that

00:27:56,720 --> 00:28:00,320
in our heap which is growing if there's

00:27:58,720 --> 00:28:01,760
a if there's a large area that happens

00:28:00,320 --> 00:28:02,559
to be a contiguous area that happens to

00:28:01,760 --> 00:28:04,559
be free

00:28:02,559 --> 00:28:06,880
glibc will actually trim that it's

00:28:04,559 --> 00:28:07,360
called trimming and reduce that heap so

00:28:06,880 --> 00:28:09,520
that that

00:28:07,360 --> 00:28:10,799
physical memory is available to another

00:28:09,520 --> 00:28:12,480
application on the system

00:28:10,799 --> 00:28:14,480
we also don't want to do that we're

00:28:12,480 --> 00:28:17,120
going to go through the effort of

00:28:14,480 --> 00:28:18,000
paging of pre-faulting calling causing

00:28:17,120 --> 00:28:19,679
page faults

00:28:18,000 --> 00:28:20,799
for all of this heap we don't want to be

00:28:19,679 --> 00:28:22,039
giving it back we don't want to give

00:28:20,799 --> 00:28:25,679
back any

00:28:22,039 --> 00:28:27,840
pre-faulted memory that's for us to keep

00:28:25,679 --> 00:28:31,120
so that's why we turn off the trimming

00:28:27,840 --> 00:28:33,520
threshold there then the m lock all this

00:28:31,120 --> 00:28:34,720
is where we can lock our memory into

00:28:33,520 --> 00:28:36,559
actually lock it into ram that i

00:28:34,720 --> 00:28:38,320
mentioned and here's

00:28:36,559 --> 00:28:40,159
the flags current and future so any

00:28:38,320 --> 00:28:41,520
memory we've allocate now or we will be

00:28:40,159 --> 00:28:44,559
allocating

00:28:41,520 --> 00:28:45,919
that we want that all to stay most of it

00:28:44,559 --> 00:28:47,120
for example if i don't have a swap file

00:28:45,919 --> 00:28:50,480
there's a lot of things that won't

00:28:47,120 --> 00:28:52,720
get won't be paged out anyway but

00:28:50,480 --> 00:28:54,240
just to make sure with mlok all we know

00:28:52,720 --> 00:28:55,360
the entire virtual address space for

00:28:54,240 --> 00:28:57,600
this application

00:28:55,360 --> 00:29:00,480
cannot be paged out for any reason under

00:28:57,600 --> 00:29:00,480
any circumstance

00:29:01,120 --> 00:29:05,120
here's an example of how you can do heap

00:29:03,200 --> 00:29:06,159
pre-faulting yeah so we see we have a

00:29:05,120 --> 00:29:07,840
simple function

00:29:06,159 --> 00:29:10,240
a prefault heap that gets some sort of

00:29:07,840 --> 00:29:13,360
size it's going to alec

00:29:10,240 --> 00:29:15,919
allocate a repeat a very large

00:29:13,360 --> 00:29:16,880
chunk of memory ideally you should see

00:29:15,919 --> 00:29:18,720
the worst case

00:29:16,880 --> 00:29:20,320
for my application what's the worst case

00:29:18,720 --> 00:29:22,240
size that i'm going to need

00:29:20,320 --> 00:29:23,440
maybe i need 10 megabytes 12 megabytes

00:29:22,240 --> 00:29:26,720
100 megabytes

00:29:23,440 --> 00:29:28,080
and we want to allocate this in the heap

00:29:26,720 --> 00:29:29,600
and then we're just going to go through

00:29:28,080 --> 00:29:31,200
each page and we're going to touch all

00:29:29,600 --> 00:29:32,960
of that memory and i'm really writing a

00:29:31,200 --> 00:29:33,600
non-zero value in there just to make

00:29:32,960 --> 00:29:36,880
sure

00:29:33,600 --> 00:29:38,559
we're definitely writing to each page

00:29:36,880 --> 00:29:40,480
and that's going to be quite expensive

00:29:38,559 --> 00:29:42,480
this is a quite expensive for loop

00:29:40,480 --> 00:29:44,320
and at the end we're going to do a free

00:29:42,480 --> 00:29:45,440
right so we're allocating a big chunk of

00:29:44,320 --> 00:29:48,000
memory that's going to

00:29:45,440 --> 00:29:49,039
since we have already configured glibc

00:29:48,000 --> 00:29:50,320
to go to the heap

00:29:49,039 --> 00:29:52,000
it's going to do the system break it's

00:29:50,320 --> 00:29:52,720
going to grab all of that really into

00:29:52,000 --> 00:29:54,640
the heap

00:29:52,720 --> 00:29:56,159
we're going to touch all of that which

00:29:54,640 --> 00:29:57,919
is going to cause page faults

00:29:56,159 --> 00:29:59,600
and then we're going to give it free and

00:29:57,919 --> 00:30:01,039
now we have this huge heap area that's

00:29:59,600 --> 00:30:03,440
already been pre-faulted

00:30:01,039 --> 00:30:06,720
and since we turned trimming off we know

00:30:03,440 --> 00:30:06,720
it's not going to go back down

00:30:07,200 --> 00:30:11,039
something similar for the stack

00:30:08,880 --> 00:30:12,559
pre-faulting but instead of doing a

00:30:11,039 --> 00:30:14,640
malloc that we get it from the heap

00:30:12,559 --> 00:30:16,080
we're just going to create a very large

00:30:14,640 --> 00:30:17,600
stack frame something that we learned

00:30:16,080 --> 00:30:19,520
we're never allowed to do

00:30:17,600 --> 00:30:21,440
in this case we want to do this right so

00:30:19,520 --> 00:30:23,120
here this is an example from a 512

00:30:21,440 --> 00:30:26,640
kilobyte stack that i want

00:30:23,120 --> 00:30:30,720
i'm just going to have a function that i

00:30:26,640 --> 00:30:32,320
go into that has a 512 kilobyte

00:30:30,720 --> 00:30:34,320
character array sitting in the stack

00:30:32,320 --> 00:30:36,080
frame and i'm just going to touch all

00:30:34,320 --> 00:30:36,880
that so basically we've created a huge

00:30:36,080 --> 00:30:38,880
stack frame

00:30:36,880 --> 00:30:41,039
we're just going to touch all of that or

00:30:38,880 --> 00:30:43,760
one page from each of that

00:30:41,039 --> 00:30:44,640
and then when the function ends the

00:30:43,760 --> 00:30:46,640
stack frame

00:30:44,640 --> 00:30:47,679
disappears from the stack and now we

00:30:46,640 --> 00:30:50,640
have this huge

00:30:47,679 --> 00:30:52,039
stack area that's that's ready and it's

00:30:50,640 --> 00:30:54,960
already been

00:30:52,039 --> 00:30:56,240
pre-faulted yeah and that also is not

00:30:54,960 --> 00:30:57,519
going to be given back

00:30:56,240 --> 00:30:59,760
because that is also something because

00:30:57,519 --> 00:31:02,000
we've done m lock all the kernel cannot

00:30:59,760 --> 00:31:03,279
take back that stack memory it's ours to

00:31:02,000 --> 00:31:04,720
keep

00:31:03,279 --> 00:31:06,080
now both of these functions pre-fall

00:31:04,720 --> 00:31:07,600
heat and prefault stack we only have to

00:31:06,080 --> 00:31:09,200
do once in our application right at the

00:31:07,600 --> 00:31:10,559
beginning just a startup so the startup

00:31:09,200 --> 00:31:12,159
is maybe a little bit slower

00:31:10,559 --> 00:31:15,919
but now we have all of our memory

00:31:12,159 --> 00:31:15,919
available ready to go

00:31:16,640 --> 00:31:19,679
so that was memory management right

00:31:18,159 --> 00:31:21,840
avoid the page faults

00:31:19,679 --> 00:31:24,240
now we're going to talk about locking

00:31:21,840 --> 00:31:26,080
the post 6 provides the mutex for

00:31:24,240 --> 00:31:27,679
locking and the mutex is a very

00:31:26,080 --> 00:31:29,760
important object

00:31:27,679 --> 00:31:31,200
for synchronization because it has the

00:31:29,760 --> 00:31:33,600
concept of owners

00:31:31,200 --> 00:31:35,039
so for example if a certain task on a

00:31:33,600 --> 00:31:37,200
system on a system

00:31:35,039 --> 00:31:38,480
takes a lock that's actually the only

00:31:37,200 --> 00:31:40,480
task on the whole system

00:31:38,480 --> 00:31:41,919
that can release this lock and this is

00:31:40,480 --> 00:31:44,640
an important attribute

00:31:41,919 --> 00:31:46,080
because if one thread takes a lock and

00:31:44,640 --> 00:31:46,799
another thread comes along and wants

00:31:46,080 --> 00:31:49,120
that lock

00:31:46,799 --> 00:31:50,480
the kernel needs to know who do i need

00:31:49,120 --> 00:31:53,120
to put back on the cpu

00:31:50,480 --> 00:31:54,480
to free that lock yeah and the only way

00:31:53,120 --> 00:31:55,840
it can know that is if you're using

00:31:54,480 --> 00:31:57,519
mutex and if you're using something like

00:31:55,840 --> 00:31:58,240
semaphores or some other locking

00:31:57,519 --> 00:32:00,399
mechanism

00:31:58,240 --> 00:32:01,679
where there is no owners involved the

00:32:00,399 --> 00:32:02,960
kernel cannot help you

00:32:01,679 --> 00:32:04,960
yeah so you're guaranteed to have

00:32:02,960 --> 00:32:07,760
priority inversion there

00:32:04,960 --> 00:32:09,039
also really important is uh there's this

00:32:07,760 --> 00:32:10,399
priority inheritance that i already

00:32:09,039 --> 00:32:13,440
showed you unfortunately

00:32:10,399 --> 00:32:15,519
this feature is not the default for

00:32:13,440 --> 00:32:17,039
thread mutexes so you actually have to

00:32:15,519 --> 00:32:18,240
turn that on

00:32:17,039 --> 00:32:20,080
always turn that on i don't know why you

00:32:18,240 --> 00:32:22,240
would not turn it on and then there are

00:32:20,080 --> 00:32:24,159
a couple attributes like robustness and

00:32:22,240 --> 00:32:26,159
shared that you might have to turn on

00:32:24,159 --> 00:32:28,320
if your mutex is sitting in shared

00:32:26,159 --> 00:32:31,200
memory and you're doing so multi-process

00:32:28,320 --> 00:32:32,640
application rather multi-threaded so

00:32:31,200 --> 00:32:33,600
this is just a really simple example

00:32:32,640 --> 00:32:37,919
that shows you

00:32:33,600 --> 00:32:40,000
uh that you have here mutex here

00:32:37,919 --> 00:32:41,840
there's an attribute object and i can

00:32:40,000 --> 00:32:43,440
initialize this attribute object for

00:32:41,840 --> 00:32:44,799
example to say i want to use priority

00:32:43,440 --> 00:32:47,039
inheritance

00:32:44,799 --> 00:32:48,320
and then i can initialize my mutex using

00:32:47,039 --> 00:32:50,559
this

00:32:48,320 --> 00:32:52,720
attribute object from the mutex then i

00:32:50,559 --> 00:32:54,559
can do locking and unlocking

00:32:52,720 --> 00:32:57,039
pretty common most people probably aware

00:32:54,559 --> 00:33:00,240
of this

00:32:57,039 --> 00:33:02,480
the p thread the shared and robust

00:33:00,240 --> 00:33:04,559
attributes are something to of interest

00:33:02,480 --> 00:33:06,720
to you when you're doing multi-process

00:33:04,559 --> 00:33:07,679
so i have multiple processes not threads

00:33:06,720 --> 00:33:09,600
but processes

00:33:07,679 --> 00:33:11,279
and maybe a shared error shared memory

00:33:09,600 --> 00:33:12,399
and there's actually a mutex sitting in

00:33:11,279 --> 00:33:14,399
that shared memory

00:33:12,399 --> 00:33:16,480
it is critical that i activate the

00:33:14,399 --> 00:33:18,080
shared attribute for this

00:33:16,480 --> 00:33:19,840
also there's a feature called robust i'm

00:33:18,080 --> 00:33:21,279
not going to go into but

00:33:19,840 --> 00:33:24,000
there's a man page there that you can

00:33:21,279 --> 00:33:25,840
look at how robust mutexes work

00:33:24,000 --> 00:33:27,679
this is also very interesting for

00:33:25,840 --> 00:33:29,679
multi-process architecture

00:33:27,679 --> 00:33:30,960
so you have multiple programs that are

00:33:29,679 --> 00:33:33,519
using shared memory to communicate and

00:33:30,960 --> 00:33:36,080
there's a mutex in that shared memory

00:33:33,519 --> 00:33:36,640
this robust feature may be very

00:33:36,080 --> 00:33:39,200
interesting

00:33:36,640 --> 00:33:40,720
just be aware that if you turn on robust

00:33:39,200 --> 00:33:42,000
there's also a lot of code you have to

00:33:40,720 --> 00:33:43,840
write you can't just

00:33:42,000 --> 00:33:45,120
turn on robust and everything's fine

00:33:43,840 --> 00:33:47,200
there's actually more things your

00:33:45,120 --> 00:33:49,120
application has to do at that point just

00:33:47,200 --> 00:33:51,360
be aware of that

00:33:49,120 --> 00:33:52,159
so that was locking another thing is

00:33:51,360 --> 00:33:53,360
signaling

00:33:52,159 --> 00:33:54,799
if i have two different threads that

00:33:53,360 --> 00:33:56,640
want to communicate through each other

00:33:54,799 --> 00:33:58,159
with signals

00:33:56,640 --> 00:33:59,760
then there's something called

00:33:58,159 --> 00:34:01,840
conditional variables

00:33:59,760 --> 00:34:03,200
and conditional variables are very nice

00:34:01,840 --> 00:34:06,000
because they

00:34:03,200 --> 00:34:06,960
connect a weight object the conditional

00:34:06,000 --> 00:34:10,079
variable is a weight

00:34:06,960 --> 00:34:11,839
object with a locking object so if you

00:34:10,079 --> 00:34:13,679
have the pattern in your code

00:34:11,839 --> 00:34:15,119
where i'm waiting for something and i

00:34:13,679 --> 00:34:16,000
wake up and the next thing i do is i

00:34:15,119 --> 00:34:17,280
grab a lock

00:34:16,000 --> 00:34:19,040
if you have that pattern i'm waiting for

00:34:17,280 --> 00:34:20,960
something i wake up and i grab a lock

00:34:19,040 --> 00:34:22,480
that's exactly what the conditional

00:34:20,960 --> 00:34:25,679
variables were made for

00:34:22,480 --> 00:34:27,839
because it will actually connect that

00:34:25,679 --> 00:34:28,960
conditional variable with the lock

00:34:27,839 --> 00:34:30,800
object

00:34:28,960 --> 00:34:33,040
if you're doing anything with real time

00:34:30,800 --> 00:34:34,399
you probably want to avoid using signals

00:34:33,040 --> 00:34:36,879
for example

00:34:34,399 --> 00:34:38,639
just because with signals you have a

00:34:36,879 --> 00:34:40,879
really hard time

00:34:38,639 --> 00:34:42,079
actually it's not even really possible

00:34:40,879 --> 00:34:45,520
to control

00:34:42,079 --> 00:34:47,200
the environment that when this

00:34:45,520 --> 00:34:49,200
signal handler comes you're in an

00:34:47,200 --> 00:34:50,079
environment you're not really in control

00:34:49,200 --> 00:34:51,520
of

00:34:50,079 --> 00:34:53,440
you know when you're using signals

00:34:51,520 --> 00:34:55,440
basically you register a callback

00:34:53,440 --> 00:34:57,200
and when that callback gets called you

00:34:55,440 --> 00:34:58,240
know what's my priority am i allowed to

00:34:57,200 --> 00:35:00,000
take locks

00:34:58,240 --> 00:35:01,440
uh you know what what kinds of things

00:35:00,000 --> 00:35:02,880
can i do there what's my scheduling

00:35:01,440 --> 00:35:04,560
policy and things like this

00:35:02,880 --> 00:35:06,960
you actually don't know and it actually

00:35:04,560 --> 00:35:08,000
depends and it depends also on the glibc

00:35:06,960 --> 00:35:09,680
implementation or the libc

00:35:08,000 --> 00:35:11,520
implementation you're using so

00:35:09,680 --> 00:35:12,640
just try to avoid signals the only thing

00:35:11,520 --> 00:35:16,480
signals are really good for is

00:35:12,640 --> 00:35:17,760
terminating your application

00:35:16,480 --> 00:35:19,200
and also really important with

00:35:17,760 --> 00:35:20,320
conditional variables and we're going to

00:35:19,200 --> 00:35:22,960
see this in a minute

00:35:20,320 --> 00:35:24,560
uh that the person who's sending the

00:35:22,960 --> 00:35:26,000
signal it's really important

00:35:24,560 --> 00:35:28,800
that they send the signal while they're

00:35:26,000 --> 00:35:31,200
still holding the mutex

00:35:28,800 --> 00:35:33,520
so here's an example first of all of

00:35:31,200 --> 00:35:35,680
initializing the conditional

00:35:33,520 --> 00:35:36,640
variable there's also a conditional

00:35:35,680 --> 00:35:38,480
attribute

00:35:36,640 --> 00:35:40,640
conditional variable attribute but this

00:35:38,480 --> 00:35:42,640
convoy attribute is only used if it's

00:35:40,640 --> 00:35:43,760
sitting in shared memory so if it's not

00:35:42,640 --> 00:35:44,720
sitting in shared memory for

00:35:43,760 --> 00:35:46,480
multi-process

00:35:44,720 --> 00:35:47,920
it's just sitting in memory that's

00:35:46,480 --> 00:35:49,200
shared between different threads of the

00:35:47,920 --> 00:35:52,560
same process

00:35:49,200 --> 00:35:53,359
then actually you don't need a attribute

00:35:52,560 --> 00:35:56,720
and you can just use

00:35:53,359 --> 00:35:58,400
null here for this second option

00:35:56,720 --> 00:36:00,400
so here's an example what the code looks

00:35:58,400 --> 00:36:02,480
like so we have the waiter

00:36:00,400 --> 00:36:03,920
yeah and we see that the waiter also has

00:36:02,480 --> 00:36:06,240
to take the lock

00:36:03,920 --> 00:36:07,920
and then it calls this cond wait

00:36:06,240 --> 00:36:09,599
function and it goes into

00:36:07,920 --> 00:36:11,119
waiting and in that moment where it

00:36:09,599 --> 00:36:11,760
begins to wait actually the lock is

00:36:11,119 --> 00:36:14,560
released

00:36:11,760 --> 00:36:15,760
you know this is an atomic operation

00:36:14,560 --> 00:36:18,880
that i go to sleep

00:36:15,760 --> 00:36:21,280
and i release the lock atomically

00:36:18,880 --> 00:36:23,280
and when i wake up again i will receive

00:36:21,280 --> 00:36:24,720
that lock again so from the perspective

00:36:23,280 --> 00:36:26,720
of the receiver

00:36:24,720 --> 00:36:27,920
i never lost the lock right i grabbed

00:36:26,720 --> 00:36:29,839
the lock i'm waiting

00:36:27,920 --> 00:36:31,359
and then when the wait function's done i

00:36:29,839 --> 00:36:32,000
still have the lock i still have it

00:36:31,359 --> 00:36:34,320
right

00:36:32,000 --> 00:36:35,760
but i got it back and then i have to

00:36:34,320 --> 00:36:37,200
unlock it again

00:36:35,760 --> 00:36:38,800
if i'm the sender if i'm the person

00:36:37,200 --> 00:36:41,280
who's doing the notification

00:36:38,800 --> 00:36:42,000
i'm also going to grab that log do the

00:36:41,280 --> 00:36:43,359
special

00:36:42,000 --> 00:36:45,280
work on that special area that's

00:36:43,359 --> 00:36:48,079
synchronized and then i can do a

00:36:45,280 --> 00:36:50,240
broadcast to wake up whoever's waiting

00:36:48,079 --> 00:36:51,760
on this weight object and then i can do

00:36:50,240 --> 00:36:53,040
the unlock and here's what i'm talking

00:36:51,760 --> 00:36:55,280
about where it's important i do the

00:36:53,040 --> 00:36:57,200
broadcast before the unlock

00:36:55,280 --> 00:36:59,280
the reason why this is important is

00:36:57,200 --> 00:37:01,040
because in the moment when i'm holding a

00:36:59,280 --> 00:37:03,359
p thread mutex

00:37:01,040 --> 00:37:04,800
i might be extremely critical for the

00:37:03,359 --> 00:37:06,960
system and i don't know

00:37:04,800 --> 00:37:08,640
i'm not aware of it right so we saw this

00:37:06,960 --> 00:37:10,079
example of priority inheritance as

00:37:08,640 --> 00:37:11,920
priority boosting

00:37:10,079 --> 00:37:13,520
this will only hap happen when i'm

00:37:11,920 --> 00:37:14,640
holding a mutex so it might be that all

00:37:13,520 --> 00:37:16,000
of a sudden i'm extremely

00:37:14,640 --> 00:37:18,320
important for the system maybe my

00:37:16,000 --> 00:37:20,320
priority was boosted this is the moment

00:37:18,320 --> 00:37:22,480
i should send the broadcast if i wait

00:37:20,320 --> 00:37:24,720
until after i release that mute

00:37:22,480 --> 00:37:26,320
release that mutex i might never get to

00:37:24,720 --> 00:37:27,760
the broadcast right so maybe in the

00:37:26,320 --> 00:37:29,040
moment when i release that broadcast now

00:37:27,760 --> 00:37:30,480
i'm not important anymore

00:37:29,040 --> 00:37:32,480
and there could be some higher priority

00:37:30,480 --> 00:37:33,839
tasks waiting on that

00:37:32,480 --> 00:37:35,599
conditional variable so it's really

00:37:33,839 --> 00:37:38,160
important that i do the broadcast before

00:37:35,599 --> 00:37:40,320
the unlock

00:37:38,160 --> 00:37:41,599
when you're dealing with clocks you're

00:37:40,320 --> 00:37:43,359
also it's important that you're using

00:37:41,599 --> 00:37:45,520
the monotonic clock

00:37:43,359 --> 00:37:46,560
so the monotonic clock is a clock that

00:37:45,520 --> 00:37:48,800
always moves forward

00:37:46,560 --> 00:37:49,760
it always respects the human definition

00:37:48,800 --> 00:37:51,760
for seconds

00:37:49,760 --> 00:37:53,040
and for example it doesn't get changed

00:37:51,760 --> 00:37:55,839
twice a year for

00:37:53,040 --> 00:37:56,560
daylight savings it's not adjusted by

00:37:55,839 --> 00:37:59,040
ntp

00:37:56,560 --> 00:38:00,560
to you know push the time forward and

00:37:59,040 --> 00:38:01,680
back or because of time zones or

00:38:00,560 --> 00:38:03,359
anything like this

00:38:01,680 --> 00:38:05,119
it always just moves forward but it

00:38:03,359 --> 00:38:06,880
moves with a tick

00:38:05,119 --> 00:38:09,280
that the humans define as seconds so

00:38:06,880 --> 00:38:12,720
it's still using our

00:38:09,280 --> 00:38:14,160
correct units of seconds microseconds

00:38:12,720 --> 00:38:16,320
nanoseconds

00:38:14,160 --> 00:38:17,200
but it is always moving one direction

00:38:16,320 --> 00:38:20,320
which is a much

00:38:17,200 --> 00:38:21,280
better clock to work with and also it's

00:38:20,320 --> 00:38:24,400
important that you're using

00:38:21,280 --> 00:38:26,480
absolute times right don't try to

00:38:24,400 --> 00:38:27,920
calculate for example if i'm in a cyclic

00:38:26,480 --> 00:38:29,520
test which we'll see in a second

00:38:27,920 --> 00:38:30,960
i shouldn't try to calculate how long i

00:38:29,520 --> 00:38:32,000
want to sleep for the next wake up i

00:38:30,960 --> 00:38:35,200
should just increment

00:38:32,000 --> 00:38:36,480
an absolute time and just wake up at

00:38:35,200 --> 00:38:37,520
that time right i shouldn't be

00:38:36,480 --> 00:38:39,040
calculating

00:38:37,520 --> 00:38:40,880
here's an example of that if we look

00:38:39,040 --> 00:38:42,079
down here at the cycle task main

00:38:40,880 --> 00:38:43,440
function

00:38:42,079 --> 00:38:45,839
we're just sitting in a loop before we

00:38:43,440 --> 00:38:47,599
go into the loop we get the clock once

00:38:45,839 --> 00:38:48,880
we go into this loop and we're just

00:38:47,599 --> 00:38:51,440
in this loop we're just going to do our

00:38:48,880 --> 00:38:52,640
critical real time work

00:38:51,440 --> 00:38:54,720
then we're going to increment the

00:38:52,640 --> 00:38:56,480
absolute time to sleep until and then we

00:38:54,720 --> 00:38:57,040
go to sleep and then we wake up we do

00:38:56,480 --> 00:38:58,960
our work

00:38:57,040 --> 00:39:00,079
we increment that absolute time so we're

00:38:58,960 --> 00:39:01,680
not even checking the time

00:39:00,079 --> 00:39:03,760
in this case we're just incrementing

00:39:01,680 --> 00:39:05,599
that absolute time and going back to

00:39:03,760 --> 00:39:07,359
sleep

00:39:05,599 --> 00:39:09,839
there's so there's no way even if like

00:39:07,359 --> 00:39:11,359
in 10 years down the road we look at

00:39:09,839 --> 00:39:12,880
what this program is doing it's still

00:39:11,359 --> 00:39:15,119
exactly waking up

00:39:12,880 --> 00:39:16,560
when it's supposed to maybe exactly on

00:39:15,119 --> 00:39:20,079
the second every second

00:39:16,560 --> 00:39:20,880
of forever because we're using absolute

00:39:20,079 --> 00:39:23,920
times

00:39:20,880 --> 00:39:25,280
and uh we're not calculating how long we

00:39:23,920 --> 00:39:26,880
should sleep because you lose

00:39:25,280 --> 00:39:28,240
that's you get a lot of jitter and

00:39:26,880 --> 00:39:29,040
variation when you try to work like that

00:39:28,240 --> 00:39:30,240
way

00:39:29,040 --> 00:39:32,560
the only thing to mention here is we

00:39:30,240 --> 00:39:34,160
have this norm ts function this is just

00:39:32,560 --> 00:39:37,119
up here it's implemented

00:39:34,160 --> 00:39:38,480
just because the time spec definition

00:39:37,119 --> 00:39:40,000
the nanosecond

00:39:38,480 --> 00:39:42,160
field is not allowed to be more the

00:39:40,000 --> 00:39:42,480
number of nanoseconds in a second right

00:39:42,160 --> 00:39:44,240
so

00:39:42,480 --> 00:39:45,760
it's just a normalization function to

00:39:44,240 --> 00:39:49,119
make sure that that

00:39:45,760 --> 00:39:50,480
stays true when you want to evaluate

00:39:49,119 --> 00:39:52,640
real time system

00:39:50,480 --> 00:39:54,960
cyclic test is probably the best tool

00:39:52,640 --> 00:39:56,480
for that

00:39:54,960 --> 00:39:58,160
the cyclic test is simply a tool that

00:39:56,480 --> 00:40:00,400
measures and tracks latencies

00:39:58,160 --> 00:40:01,680
at a certain priority level right so i

00:40:00,400 --> 00:40:03,599
can call it for example

00:40:01,680 --> 00:40:05,440
typically with cyclic test minus capital

00:40:03,599 --> 00:40:06,720
s minus m minus p

00:40:05,440 --> 00:40:08,960
with the priority level that i'm

00:40:06,720 --> 00:40:11,680
interested in measuring the latency for

00:40:08,960 --> 00:40:13,440
also the second line task is argument is

00:40:11,680 --> 00:40:15,520
also quite important

00:40:13,440 --> 00:40:16,880
and generally you'll start this task and

00:40:15,520 --> 00:40:18,000
it's basically all it's doing is going

00:40:16,880 --> 00:40:19,599
to sleep

00:40:18,000 --> 00:40:21,119
and it knows when it's supposed to wake

00:40:19,599 --> 00:40:22,960
up and when it actually does wake up it

00:40:21,119 --> 00:40:24,000
just checks the clock and see how what

00:40:22,960 --> 00:40:25,119
was the latency there right

00:40:24,000 --> 00:40:27,440
it just does it again and again and

00:40:25,119 --> 00:40:30,000
again and it actually creates statistics

00:40:27,440 --> 00:40:31,680
you can generate histograms for what is

00:40:30,000 --> 00:40:33,200
the latency at this level and i say at

00:40:31,680 --> 00:40:35,599
this level because

00:40:33,200 --> 00:40:37,599
at priority 20 there might be different

00:40:35,599 --> 00:40:38,319
types of latencies than a priority 90

00:40:37,599 --> 00:40:40,640
because

00:40:38,319 --> 00:40:41,440
there are real-time applications running

00:40:40,640 --> 00:40:43,200
right so

00:40:41,440 --> 00:40:45,440
i don't just want to know what's my

00:40:43,200 --> 00:40:46,160
real-time priority 99 this is not very

00:40:45,440 --> 00:40:47,680
useful

00:40:46,160 --> 00:40:49,440
i want to know okay my app my

00:40:47,680 --> 00:40:51,920
application is running it for example

00:40:49,440 --> 00:40:54,000
real-time priority 30 then probably

00:40:51,920 --> 00:40:55,200
running cyclic tests on 31 is a good

00:40:54,000 --> 00:40:58,400
place just to see

00:40:55,200 --> 00:41:00,319
what kind of latencies priority 30 can

00:40:58,400 --> 00:41:02,079
expect while my application is running

00:41:00,319 --> 00:41:04,079
the reason i say 31 instead of 30 is

00:41:02,079 --> 00:41:04,640
because we don't want that priority 30

00:41:04,079 --> 00:41:07,040
task

00:41:04,640 --> 00:41:08,960
to be affecting the latencies of the

00:41:07,040 --> 00:41:11,119
test

00:41:08,960 --> 00:41:12,800
now while you're doing the cyclic tasks

00:41:11,119 --> 00:41:13,920
basically you want to generate a lot of

00:41:12,800 --> 00:41:18,240
loads

00:41:13,920 --> 00:41:20,400
just for the system and try to basically

00:41:18,240 --> 00:41:21,920
cause latencies right so there's tools

00:41:20,400 --> 00:41:22,480
like hack bench which do scheduling

00:41:21,920 --> 00:41:24,480
loads

00:41:22,480 --> 00:41:26,319
you can have an external ping flood not

00:41:24,480 --> 00:41:26,800
internal but externally a ping flood

00:41:26,319 --> 00:41:28,960
coming

00:41:26,800 --> 00:41:30,800
generates a lot of interrupts i can do

00:41:28,960 --> 00:41:33,599
things like running top minus d0

00:41:30,800 --> 00:41:35,839
on serial or ssh which just generates a

00:41:33,599 --> 00:41:37,359
lot of packets and a lot of interrupts

00:41:35,839 --> 00:41:39,200
particularly with serial that's pretty

00:41:37,359 --> 00:41:41,359
painful

00:41:39,200 --> 00:41:42,560
i can run oom killer so basically i'm

00:41:41,359 --> 00:41:45,520
taking every

00:41:42,560 --> 00:41:46,880
page of free memory and the system is

00:41:45,520 --> 00:41:48,560
starting to panic a little bit and it's

00:41:46,880 --> 00:41:50,960
starting to kill applications

00:41:48,560 --> 00:41:52,480
in order to free up memory even in this

00:41:50,960 --> 00:41:52,960
situation my real-time application

00:41:52,480 --> 00:41:54,240
should run

00:41:52,960 --> 00:41:56,079
fine if i've configured everything

00:41:54,240 --> 00:41:58,000
correctly and i've done the tips that i

00:41:56,079 --> 00:42:00,319
showed you before

00:41:58,000 --> 00:42:01,040
there's the stressng tool obviously you

00:42:00,319 --> 00:42:02,800
want to stress

00:42:01,040 --> 00:42:04,000
all the components of my system so if i

00:42:02,800 --> 00:42:05,839
have bluetooth i should be doing

00:42:04,000 --> 00:42:06,240
bluetooth stressing if i have an sd card

00:42:05,839 --> 00:42:08,160
i should do

00:42:06,240 --> 00:42:09,760
sd card stress testing all of these

00:42:08,160 --> 00:42:11,280
things the components are testing

00:42:09,760 --> 00:42:12,079
because i really want to shake out is

00:42:11,280 --> 00:42:14,319
there any

00:42:12,079 --> 00:42:16,480
possible code paths where i really do

00:42:14,319 --> 00:42:17,920
have a high latency situation

00:42:16,480 --> 00:42:20,480
i need to shake those out and find them

00:42:17,920 --> 00:42:22,480
and whatever the worst case i find

00:42:20,480 --> 00:42:23,839
that's the worst case for this system

00:42:22,480 --> 00:42:27,040
right so if you see a

00:42:23,839 --> 00:42:27,920
very value you don't like that's what

00:42:27,040 --> 00:42:29,920
you got so

00:42:27,920 --> 00:42:31,280
it's maybe a bug in the kernel maybe

00:42:29,920 --> 00:42:32,480
your kernel is not configured correctly

00:42:31,280 --> 00:42:33,520
maybe your applications are not

00:42:32,480 --> 00:42:36,319
configured correctly

00:42:33,520 --> 00:42:37,440
but that's the reality of the situation

00:42:36,319 --> 00:42:40,560
and lastly

00:42:37,440 --> 00:42:42,000
don't forget to test an idle system

00:42:40,560 --> 00:42:43,520
right so

00:42:42,000 --> 00:42:45,680
that's sometimes the biggest killer of

00:42:43,520 --> 00:42:46,160
real-time applications is the idle

00:42:45,680 --> 00:42:48,079
system

00:42:46,160 --> 00:42:49,760
right so if i said cyclic test to wake

00:42:48,079 --> 00:42:51,920
up at once a second

00:42:49,760 --> 00:42:53,760
uh and the system keeps going into low

00:42:51,920 --> 00:42:55,760
power cpu modes and things like this

00:42:53,760 --> 00:42:59,040
that actually be my actually might be my

00:42:55,760 --> 00:43:00,480
worst latency

00:42:59,040 --> 00:43:01,839
so we're running out of time here so i

00:43:00,480 --> 00:43:03,839
just want to quickly mention a couple

00:43:01,839 --> 00:43:06,960
things perf is a great tool

00:43:03,839 --> 00:43:08,880
just to track count

00:43:06,960 --> 00:43:10,480
certain hardware events for example page

00:43:08,880 --> 00:43:11,920
faults cache misses things like this i

00:43:10,480 --> 00:43:15,200
can i can try i can ca

00:43:11,920 --> 00:43:16,560
i can track with perf there's also some

00:43:15,200 --> 00:43:18,880
examples here

00:43:16,560 --> 00:43:20,400
uh of how you can call that so for

00:43:18,880 --> 00:43:22,160
example if my system is running in a

00:43:20,400 --> 00:43:24,960
pretty critical situation

00:43:22,160 --> 00:43:26,640
it's nice to start perf and have it

00:43:24,960 --> 00:43:27,200
track are we getting page faults in this

00:43:26,640 --> 00:43:29,839
situation

00:43:27,200 --> 00:43:31,359
are we getting a lot of cpu cycles and

00:43:29,839 --> 00:43:32,079
we can actually actually look at things

00:43:31,359 --> 00:43:34,640
like

00:43:32,079 --> 00:43:36,640
which task or which symbol is causing

00:43:34,640 --> 00:43:38,880
the most cpu cycles or things like this

00:43:36,640 --> 00:43:40,800
perf is really a powerful tool profiling

00:43:38,880 --> 00:43:42,880
tool to identify

00:43:40,800 --> 00:43:44,079
places in your system or in your

00:43:42,880 --> 00:43:47,119
application

00:43:44,079 --> 00:43:48,560
where you have optimization available

00:43:47,119 --> 00:43:50,240
right if i see that my application is

00:43:48,560 --> 00:43:51,920
causing a lot of page faults

00:43:50,240 --> 00:43:53,200
this is obviously something i can fix

00:43:51,920 --> 00:43:55,520
right i've shown you how to fix your

00:43:53,200 --> 00:43:57,200
page faults

00:43:55,520 --> 00:43:59,359
there's also a tracing infrastructure

00:43:57,200 --> 00:44:01,680
available in linux this doesn't just

00:43:59,359 --> 00:44:03,359
profile what happens but it actually

00:44:01,680 --> 00:44:03,920
takes time stamps of the events you can

00:44:03,359 --> 00:44:06,079
see

00:44:03,920 --> 00:44:07,119
when it happens so here's an example

00:44:06,079 --> 00:44:09,760
with trace command

00:44:07,119 --> 00:44:11,920
where i can for example trace wake up

00:44:09,760 --> 00:44:13,359
and scheduling events

00:44:11,920 --> 00:44:15,280
and you can even look at these

00:44:13,359 --> 00:44:16,079
graphically right so this can actually

00:44:15,280 --> 00:44:17,760
show me

00:44:16,079 --> 00:44:20,000
in this particular picture i can see

00:44:17,760 --> 00:44:22,160
that the mate terminal

00:44:20,000 --> 00:44:23,920
lost the cpu yeah probably because the

00:44:22,160 --> 00:44:27,359
end of its time slam

00:44:23,920 --> 00:44:30,720
times time slice but strangely enough

00:44:27,359 --> 00:44:32,319
cpu0 is free here right so i see there's

00:44:30,720 --> 00:44:34,079
actually a moment

00:44:32,319 --> 00:44:35,760
where mate terminal is in the runnable

00:44:34,079 --> 00:44:37,040
state and i actually have an idle cpu

00:44:35,760 --> 00:44:37,920
right so things like that could be

00:44:37,040 --> 00:44:40,560
interesting

00:44:37,920 --> 00:44:42,160
why is our application not on a cpu when

00:44:40,560 --> 00:44:43,920
we have a cpu free right

00:44:42,160 --> 00:44:46,079
and with the traces you can actually see

00:44:43,920 --> 00:44:47,440
these things and it can go really deep

00:44:46,079 --> 00:44:48,240
in depth so we can actually see the

00:44:47,440 --> 00:44:49,599
events

00:44:48,240 --> 00:44:51,359
for when for example the wake up

00:44:49,599 --> 00:44:54,480
happened and we're coming out of

00:44:51,359 --> 00:44:55,920
maybe a p p 3 mutex lock

00:44:54,480 --> 00:44:57,359
where schedule switching is happening

00:44:55,920 --> 00:44:57,920
actually this would be the broadcast

00:44:57,359 --> 00:44:59,599
there

00:44:57,920 --> 00:45:01,440
a switch is happening and this one's

00:44:59,599 --> 00:45:03,680
coming then out of the

00:45:01,440 --> 00:45:05,119
weight would be probably this condition

00:45:03,680 --> 00:45:06,640
right and you can actually with kernel

00:45:05,119 --> 00:45:07,520
shark you can very easily just measure

00:45:06,640 --> 00:45:10,079
these distance

00:45:07,520 --> 00:45:12,960
distances and so you can get really good

00:45:10,079 --> 00:45:14,880
accurate microsecond accurate values

00:45:12,960 --> 00:45:15,760
uh for how long these things are taking

00:45:14,880 --> 00:45:16,400
and you can actually see what's

00:45:15,760 --> 00:45:18,079
happening

00:45:16,400 --> 00:45:19,680
and it's nice to view things graphically

00:45:18,079 --> 00:45:21,839
because you can see what's going on

00:45:19,680 --> 00:45:21,839
there

00:45:22,800 --> 00:45:26,240
the last thing here really is the

00:45:24,400 --> 00:45:27,520
optimal real-time configuration if

00:45:26,240 --> 00:45:30,319
you're doing your kernel

00:45:27,520 --> 00:45:30,960
this is basically just a list of options

00:45:30,319 --> 00:45:32,720
that don't

00:45:30,960 --> 00:45:34,400
necessarily mean that your kernel is not

00:45:32,720 --> 00:45:36,000
configured correctly

00:45:34,400 --> 00:45:38,160
but they're really things to look at so

00:45:36,000 --> 00:45:39,119
if i look at a kernel from somebody and

00:45:38,160 --> 00:45:41,680
i want to see is it

00:45:39,119 --> 00:45:43,599
optimal for for real time these are the

00:45:41,680 --> 00:45:44,960
configurations i'm looking at just to

00:45:43,599 --> 00:45:47,440
see how they're configured

00:45:44,960 --> 00:45:49,520
and if we say okay you're using a cpu

00:45:47,440 --> 00:45:51,920
idle

00:45:49,520 --> 00:45:53,280
is this something that for example you

00:45:51,920 --> 00:45:56,079
need do you need the low

00:45:53,280 --> 00:45:57,280
low power cpu states or not is power

00:45:56,079 --> 00:45:59,040
saving important or

00:45:57,280 --> 00:46:01,200
is real time more important things like

00:45:59,040 --> 00:46:01,680
this right so these are just some things

00:46:01,200 --> 00:46:03,200
to be

00:46:01,680 --> 00:46:06,079
aware of when you're looking at the

00:46:03,200 --> 00:46:07,440
kernel lastly here is the checklist that

00:46:06,079 --> 00:46:08,880
you've all been waiting for

00:46:07,440 --> 00:46:10,960
where you just need to go through your

00:46:08,880 --> 00:46:12,560
consider your real-time priorities and

00:46:10,960 --> 00:46:13,359
also your non-real-time priorities i

00:46:12,560 --> 00:46:15,920
can't emphasize

00:46:13,359 --> 00:46:17,359
that enough use nice and control groups

00:46:15,920 --> 00:46:18,880
to your advantage

00:46:17,359 --> 00:46:20,480
so that the things that are not real

00:46:18,880 --> 00:46:21,359
time are still running the way you want

00:46:20,480 --> 00:46:24,000
them

00:46:21,359 --> 00:46:26,160
the cpu affinity avoid page faults they

00:46:24,000 --> 00:46:27,599
are deadly for real time

00:46:26,160 --> 00:46:29,359
make sure you're using the monotonic

00:46:27,599 --> 00:46:30,720
clock with absolute time

00:46:29,359 --> 00:46:33,119
make sure your kernel is configured

00:46:30,720 --> 00:46:34,880
optimally

00:46:33,119 --> 00:46:36,400
don't use signals for anything except

00:46:34,880 --> 00:46:38,400
for killing your application

00:46:36,400 --> 00:46:40,079
priority inversion it's the killer for

00:46:38,400 --> 00:46:41,440
all real-time applications

00:46:40,079 --> 00:46:42,880
and make sure you're verifying your

00:46:41,440 --> 00:46:44,079
results don't just assume you've

00:46:42,880 --> 00:46:46,640
programmed it correctly

00:46:44,079 --> 00:46:48,560
trace it analyze it profile it and look

00:46:46,640 --> 00:46:49,760
at those situations that you think

00:46:48,560 --> 00:46:51,440
are happening if you think there's a

00:46:49,760 --> 00:46:52,480
situation where priority inheritance

00:46:51,440 --> 00:46:54,960
could really happen

00:46:52,480 --> 00:46:56,480
trace it see it happening and make sure

00:46:54,960 --> 00:46:57,040
you're aware yes we did implement

00:46:56,480 --> 00:46:58,640
correctly

00:46:57,040 --> 00:47:00,640
i can see the priority boosting

00:46:58,640 --> 00:47:02,480
happening right and now you know okay we

00:47:00,640 --> 00:47:04,400
did it well because maybe you forgot to

00:47:02,480 --> 00:47:05,920
activate priority inheritance for the

00:47:04,400 --> 00:47:08,400
mutex and it won't happen right

00:47:05,920 --> 00:47:10,160
you need to see it happening so really

00:47:08,400 --> 00:47:13,440
trace and verify those results

00:47:10,160 --> 00:47:15,440
and lastly nmis non-maskable interrupts

00:47:13,440 --> 00:47:16,319
are the absolute killer on any real-time

00:47:15,440 --> 00:47:18,400
system

00:47:16,319 --> 00:47:19,839
because linux can't do anything about it

00:47:18,400 --> 00:47:21,839
they're just going to come

00:47:19,839 --> 00:47:23,040
and jump into some bios vector or

00:47:21,839 --> 00:47:25,119
something

00:47:23,040 --> 00:47:26,400
make sure you know about them make sure

00:47:25,119 --> 00:47:28,800
you know how to avoid them

00:47:26,400 --> 00:47:31,040
uh talk to your hardware vendors and and

00:47:28,800 --> 00:47:32,800
get that cleared up

00:47:31,040 --> 00:47:34,400
so thank you i went a little bit over i

00:47:32,800 --> 00:47:36,880
hope uh that's okay

00:47:34,400 --> 00:47:38,480
uh i really appreciate you taking some

00:47:36,880 --> 00:47:40,079
time to look at this

00:47:38,480 --> 00:47:41,599
virtual conference is a little bit

00:47:40,079 --> 00:47:44,720
difficult this year

00:47:41,599 --> 00:47:46,960
and the real-time wiki site is the

00:47:44,720 --> 00:47:48,240
address i've got there go there there's

00:47:46,960 --> 00:47:50,319
information about the

00:47:48,240 --> 00:47:52,559
configuring real-time kernel also

00:47:50,319 --> 00:47:53,680
examples of writing applications

00:47:52,559 --> 00:47:56,079
and if you see there's an article

00:47:53,680 --> 00:47:56,559
missing write one it's a great place to

00:47:56,079 --> 00:47:59,760
go

00:47:56,559 --> 00:48:07,839
so i thank you for your time and have

00:47:59,760 --> 00:48:07,839
fun with real time linux

00:48:09,280 --> 00:48:11,359

YouTube URL: https://www.youtube.com/watch?v=NrjXEaTSyrw


