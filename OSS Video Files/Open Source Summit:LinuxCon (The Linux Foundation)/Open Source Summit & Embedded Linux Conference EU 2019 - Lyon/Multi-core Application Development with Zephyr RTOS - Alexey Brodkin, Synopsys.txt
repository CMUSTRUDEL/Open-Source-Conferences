Title: Multi-core Application Development with Zephyr RTOS - Alexey Brodkin, Synopsys
Publication date: 2019-10-29
Playlist: Open Source Summit & Embedded Linux Conference EU 2019 - Lyon
Description: 
	Multi-core Application Development with Zephyr RTOS - Alexey Brodkin, Synopsys*

Performance in Desktop, Server, HPC and even smartphone applications has been scaling rapidly in recent years via multi-core, continuously increasing the number of cores on a processor chip. The same principle has been extending to embedded systems, where multi-core designs are increasingly more pervasive in applications such as 5G data processor, edge IoT, Machine Learning and many more.

This presentation will examine multi-core application options and considerations using the Zephyr. We'll start from exploration of use-cases where multiple CPU cores might be beneficial for deeply embedded system including both asymmetric & symmetric multiprocessing (AMP & SMP). Then we'll discuss current state of multi-core support in Zephyr: what is already implemented and what's still missing. And in the end we will highlight challenges associated with designing high performance software applications for multi-core hardware using samples on boards currently supported in upstream Zephyr project.
Captions: 
	00:00:00,680 --> 00:00:06,540
hello everybody okay obviously you make

00:00:04,529 --> 00:00:11,670
here me but so I'll try to adjust it a

00:00:06,540 --> 00:00:13,410
little bit is it okay if I speak that

00:00:11,670 --> 00:00:16,289
way I don't need to be closer to the

00:00:13,410 --> 00:00:19,529
microphone okay

00:00:16,289 --> 00:00:21,270
again hello everybody my name is Alexey

00:00:19,529 --> 00:00:24,740
Braaten and today we are going to talk

00:00:21,270 --> 00:00:28,470
about how our toasts might be helpful to

00:00:24,740 --> 00:00:32,989
leverage all the benefits of your modern

00:00:28,470 --> 00:00:36,719
multi-core design and so let me start

00:00:32,989 --> 00:00:38,730
first a couple of words about myself

00:00:36,719 --> 00:00:41,340
you may read something here basically

00:00:38,730 --> 00:00:43,020
I've been doing number its software

00:00:41,340 --> 00:00:44,879
development for a couple of years well

00:00:43,020 --> 00:00:46,860
more than 10 years already and mostly

00:00:44,879 --> 00:00:50,010
these are the implemented things on

00:00:46,860 --> 00:00:52,320
modern 32-bit microprocessor for my

00:00:50,010 --> 00:00:54,930
controllers if you will and so I've been

00:00:52,320 --> 00:00:57,030
doing a lot of open source as well and

00:00:54,930 --> 00:00:58,920
so lately I started to deal with zipper

00:00:57,030 --> 00:01:03,390
art sauce so what are we going to talk

00:00:58,920 --> 00:01:05,040
about today first we'll see I'll try to

00:01:03,390 --> 00:01:08,460
convince you that so there is actually a

00:01:05,040 --> 00:01:11,189
demand on of multi-core deeply embedded

00:01:08,460 --> 00:01:14,189
or basically embedded systems and so

00:01:11,189 --> 00:01:16,700
hopefully you'll see what is a real need

00:01:14,189 --> 00:01:20,390
for that and then we'll go to a

00:01:16,700 --> 00:01:23,100
discussion about two fundamental or

00:01:20,390 --> 00:01:25,770
fundamentally different approaches with

00:01:23,100 --> 00:01:28,680
multi-core design and so then we'll see

00:01:25,770 --> 00:01:30,960
how those are mapped to the Zephyr art

00:01:28,680 --> 00:01:32,640
sauce how it could be used there and so

00:01:30,960 --> 00:01:36,119
then we'll spend a little bit more time

00:01:32,640 --> 00:01:38,790
with SMP because it is from one point of

00:01:36,119 --> 00:01:41,100
view it is more standards and so that's

00:01:38,790 --> 00:01:43,890
why people to a wide variety of

00:01:41,100 --> 00:01:45,630
different hardware but so then it is

00:01:43,890 --> 00:01:47,369
also quite a tricky one because it

00:01:45,630 --> 00:01:49,950
requires you to do with a couple of

00:01:47,369 --> 00:01:54,479
interesting things so let me continue

00:01:49,950 --> 00:01:57,090
then with what we have here so why

00:01:54,479 --> 00:01:59,520
actually we might want to use multi-core

00:01:57,090 --> 00:02:01,649
in the embedded systems it sounds quite

00:01:59,520 --> 00:02:05,219
strange today but we are getting there

00:02:01,649 --> 00:02:06,930
so what happens we there is no such

00:02:05,219 --> 00:02:09,270
thing as enough performance because

00:02:06,930 --> 00:02:11,530
whenever we have for more performance we

00:02:09,270 --> 00:02:13,240
are trying to do more funky stuff and

00:02:11,530 --> 00:02:15,670
that's why at some point we end up

00:02:13,240 --> 00:02:19,300
having way too many work to be done and

00:02:15,670 --> 00:02:20,710
so what we do we try to achieve more so

00:02:19,300 --> 00:02:22,960
what what we need to do we need to

00:02:20,710 --> 00:02:25,570
execute more instructions per second for

00:02:22,960 --> 00:02:27,160
example and how we achieve that if we

00:02:25,570 --> 00:02:29,350
are not talking about improvements in

00:02:27,160 --> 00:02:32,760
CPU architecture so we are trying to

00:02:29,350 --> 00:02:36,280
execute instructions faster so we try to

00:02:32,760 --> 00:02:38,260
make our clock being higher and higher

00:02:36,280 --> 00:02:40,450
and at some point we end up with a

00:02:38,260 --> 00:02:43,390
couple of things so either together or

00:02:40,450 --> 00:02:46,209
separately so we may have a problem

00:02:43,390 --> 00:02:47,770
because we cannot scale our frequency

00:02:46,209 --> 00:02:50,110
any longer because our attack process

00:02:47,770 --> 00:02:52,209
doesn't allow us to do so or we may see

00:02:50,110 --> 00:02:53,950
that so we are already dissipating so

00:02:52,209 --> 00:02:57,790
much power that's our package just

00:02:53,950 --> 00:03:02,050
cannot reduce that so we cannot increase

00:02:57,790 --> 00:03:04,120
our frequency and your longer but then

00:03:02,050 --> 00:03:07,000
we may have another challenges so for

00:03:04,120 --> 00:03:12,400
example what if we have a critical task

00:03:07,000 --> 00:03:16,060
we cannot afford switching off and let

00:03:12,400 --> 00:03:18,010
another task another application to be

00:03:16,060 --> 00:03:20,950
running so then we want that particular

00:03:18,010 --> 00:03:25,030
threat of execution to be always to

00:03:20,950 --> 00:03:27,070
always have real Hardware to work on so

00:03:25,030 --> 00:03:29,170
we may immediately start it or we may

00:03:27,070 --> 00:03:30,790
not even stop it and so another very

00:03:29,170 --> 00:03:33,790
interesting topic we may have a very

00:03:30,790 --> 00:03:37,360
specific test like convolution neural

00:03:33,790 --> 00:03:39,880
network or DSP of some kinds which if

00:03:37,360 --> 00:03:41,709
implemented on a normal general purpose

00:03:39,880 --> 00:03:43,630
CPU it will ruin all the performance

00:03:41,709 --> 00:03:44,920
because it will require so much compute

00:03:43,630 --> 00:03:46,959
time that you won't be able to do

00:03:44,920 --> 00:03:50,920
anything else while doing even not that

00:03:46,959 --> 00:03:55,450
many of DSP or CNN so what then we may

00:03:50,920 --> 00:03:59,769
do we may use just more CPUs and so then

00:03:55,450 --> 00:04:02,380
these CPU cores were different CPUs

00:03:59,769 --> 00:04:04,630
itself with that we have a scaling of

00:04:02,380 --> 00:04:07,239
megahertz so we used to have one CPU and

00:04:04,630 --> 00:04:09,970
now we have two so we used to have

00:04:07,239 --> 00:04:11,830
megahertz budget like 1,000 megahertz

00:04:09,970 --> 00:04:13,959
and now we have two or three or four

00:04:11,830 --> 00:04:16,720
whatever so we may obviously do more or

00:04:13,959 --> 00:04:18,640
we may keep one more for executional for

00:04:16,720 --> 00:04:21,340
something and so all the rest for

00:04:18,640 --> 00:04:22,680
anything else that we need and that's

00:04:21,340 --> 00:04:24,900
why we gain

00:04:22,680 --> 00:04:28,110
not pewter but real parallel execution

00:04:24,900 --> 00:04:29,970
which also helps or we may want to use a

00:04:28,110 --> 00:04:32,160
special accelerator course which will do

00:04:29,970 --> 00:04:34,740
something very efficiently like that CNN

00:04:32,160 --> 00:04:36,389
or DS P or something so well that's what

00:04:34,740 --> 00:04:38,639
we are getting and so I hear a couple of

00:04:36,389 --> 00:04:41,360
real-life example so for example LTE

00:04:38,639 --> 00:04:44,940
modems they are interesting because

00:04:41,360 --> 00:04:46,800
computational amount of communications

00:04:44,940 --> 00:04:49,500
we need to do to implement LT stack is

00:04:46,800 --> 00:04:51,900
tremendous and it is not only a control

00:04:49,500 --> 00:04:53,370
stack we have a lot of DSP calculations

00:04:51,900 --> 00:04:55,800
so typical designs they consist of a

00:04:53,370 --> 00:04:57,840
couple of GS piece or even a sips and so

00:04:55,800 --> 00:04:59,340
also we have a general purpose CPU as

00:04:57,840 --> 00:05:01,320
well because we need to do all these

00:04:59,340 --> 00:05:03,150
calculations and why we need multi-core

00:05:01,320 --> 00:05:04,830
because we may even have a telephone

00:05:03,150 --> 00:05:06,570
call like a voice call and we want to

00:05:04,830 --> 00:05:08,100
process that as well and not being

00:05:06,570 --> 00:05:12,090
interrupted because we are transferring

00:05:08,100 --> 00:05:13,740
data one other good example is all video

00:05:12,090 --> 00:05:15,750
DSP because they want to have your cell

00:05:13,740 --> 00:05:18,780
phone playing music but not consuming

00:05:15,750 --> 00:05:21,000
all your battery in an hour or as I

00:05:18,780 --> 00:05:24,030
mentioned already a i/o or a video

00:05:21,000 --> 00:05:25,740
recognition video processors you want to

00:05:24,030 --> 00:05:27,990
have a separate core which may have four

00:05:25,740 --> 00:05:29,820
like couple of thousands max which will

00:05:27,990 --> 00:05:32,820
do multiplication and accumulation in

00:05:29,820 --> 00:05:34,620
one cycle compared to you to what you

00:05:32,820 --> 00:05:37,410
have like one or two or max on your

00:05:34,620 --> 00:05:39,690
normal or CPU and so that might be a

00:05:37,410 --> 00:05:41,280
very efficient as well and another thing

00:05:39,690 --> 00:05:43,590
you may have like user interface which

00:05:41,280 --> 00:05:45,570
consumes a lot of computer resources and

00:05:43,590 --> 00:05:47,520
still you want to be to be it to be

00:05:45,570 --> 00:05:50,669
smooth and do something else as well and

00:05:47,520 --> 00:05:52,830
so that's a typical design which we used

00:05:50,669 --> 00:05:54,510
to have for lately so we have probably

00:05:52,830 --> 00:05:57,930
we usually have only one core but then

00:05:54,510 --> 00:05:59,760
we went with multiple cores and so still

00:05:57,930 --> 00:06:02,130
that looks quite simple but so that

00:05:59,760 --> 00:06:04,050
example that's just you were a cell

00:06:02,130 --> 00:06:05,849
phone or something and then you want so

00:06:04,050 --> 00:06:07,919
to play music on the go and so again

00:06:05,849 --> 00:06:10,620
keep your battery safe and not so

00:06:07,919 --> 00:06:12,960
drained in an hour so you add these peak

00:06:10,620 --> 00:06:14,880
or which does only wanting it decode

00:06:12,960 --> 00:06:17,610
something and so if it's your attack for

00:06:14,880 --> 00:06:19,560
example and so that thing communicates

00:06:17,610 --> 00:06:22,199
with your CPU through a special mailbox

00:06:19,560 --> 00:06:24,389
for example it's not obligatory so but

00:06:22,199 --> 00:06:26,699
so let's assume that so to display

00:06:24,389 --> 00:06:28,139
complexity which we may face and then

00:06:26,699 --> 00:06:30,810
you want so something else you want your

00:06:28,139 --> 00:06:32,729
phone to consume again no power or one

00:06:30,810 --> 00:06:34,650
in standby mode but so then you want it

00:06:32,729 --> 00:06:35,559
to react on something when you for

00:06:34,650 --> 00:06:37,059
example

00:06:35,559 --> 00:06:39,339
when you walk and it will count your

00:06:37,059 --> 00:06:41,559
steps worried for example if you talk to

00:06:39,339 --> 00:06:44,499
that so hello my device it also wakes up

00:06:41,559 --> 00:06:47,079
so you have a separate very downscale

00:06:44,499 --> 00:06:48,399
CPU or which only talks with sensors and

00:06:47,079 --> 00:06:51,399
send interrupts to the main core

00:06:48,399 --> 00:06:54,089
whenever it is whenever it thinks it's

00:06:51,399 --> 00:06:56,529
at the right time and so then you have a

00:06:54,089 --> 00:06:59,049
desire also to recognize object with

00:06:56,529 --> 00:07:01,629
your camera on your smartphone and so

00:06:59,049 --> 00:07:03,849
that's how you end up with a vision

00:07:01,629 --> 00:07:07,149
processor which again had have a couple

00:07:03,849 --> 00:07:09,999
of thousand multiplication units and may

00:07:07,149 --> 00:07:12,909
do that recognition in a snap without

00:07:09,999 --> 00:07:15,579
actually consuming a lot of power and so

00:07:12,909 --> 00:07:20,559
what we may see here actually the first

00:07:15,579 --> 00:07:22,659
part is a big cluster which an MP stands

00:07:20,559 --> 00:07:23,949
for a symmetric multiprocessor cluster

00:07:22,659 --> 00:07:26,259
which means we have two completely

00:07:23,949 --> 00:07:27,909
different CPUs here and so we have to

00:07:26,259 --> 00:07:29,859
deal somehow with that and we have

00:07:27,909 --> 00:07:32,499
something more generic which is a big

00:07:29,859 --> 00:07:35,949
cluster which means we have which is

00:07:32,499 --> 00:07:37,179
sense for symmetric multiprocessing

00:07:35,949 --> 00:07:40,209
which means we have exactly the same

00:07:37,179 --> 00:07:42,279
CPUs here and you may see that entire

00:07:40,209 --> 00:07:45,639
picture as a quite a cool example of

00:07:42,279 --> 00:07:47,469
modern heterogeneous or SOC and most of

00:07:45,639 --> 00:07:49,360
the SOC to this day they they look like

00:07:47,469 --> 00:07:51,309
that so you see they're quite complex

00:07:49,360 --> 00:07:53,229
because you use different processors you

00:07:51,309 --> 00:07:55,479
use different means of communications

00:07:53,229 --> 00:07:57,729
between them and now let's take a deeper

00:07:55,479 --> 00:07:59,619
look at all those different types of

00:07:57,729 --> 00:08:01,479
multi processing implementation the

00:07:59,619 --> 00:08:03,369
first is a MP and the first because

00:08:01,479 --> 00:08:05,139
that's the simplest in some sense

00:08:03,369 --> 00:08:07,599
because you may take a completely

00:08:05,139 --> 00:08:09,609
different CPUs which will differ even in

00:08:07,599 --> 00:08:11,019
instruction set architecture they may

00:08:09,609 --> 00:08:13,209
have access to different peripherals

00:08:11,019 --> 00:08:16,239
different memories and all that and so

00:08:13,209 --> 00:08:19,299
we have it into same one design into

00:08:16,239 --> 00:08:21,819
same sound into same associ and so that

00:08:19,299 --> 00:08:24,039
will work they may use different

00:08:21,819 --> 00:08:25,959
communication channels or they may not

00:08:24,039 --> 00:08:27,999
have any communication channels as well

00:08:25,959 --> 00:08:30,489
you have a lot of flexibility here but

00:08:27,999 --> 00:08:32,319
for that you have to pay it's hard to

00:08:30,489 --> 00:08:34,120
implement something which works for any

00:08:32,319 --> 00:08:36,129
design and so it's hard to add yet

00:08:34,120 --> 00:08:38,259
another core because you will need so

00:08:36,129 --> 00:08:40,449
two thing about software partitioning

00:08:38,259 --> 00:08:43,450
before you actually deploy that on your

00:08:40,449 --> 00:08:46,060
SOC on your device

00:08:43,450 --> 00:08:47,650
and it's hard to update it later you

00:08:46,060 --> 00:08:50,440
need to update in either Nutella firmer

00:08:47,650 --> 00:08:53,410
or if you have a PJs one of the members

00:08:50,440 --> 00:08:55,180
here you have even harder time so it's

00:08:53,410 --> 00:08:59,200
not scalable and you need to think and

00:08:55,180 --> 00:09:00,880
advance a lot but that's simple another

00:08:59,200 --> 00:09:03,520
thing you have SMP which stands for

00:09:00,880 --> 00:09:06,820
symmetric multiprocessing that is easier

00:09:03,520 --> 00:09:10,000
and harder at the same time it's easier

00:09:06,820 --> 00:09:11,950
because you may for example run the same

00:09:10,000 --> 00:09:14,020
software which you need to either record

00:09:11,950 --> 00:09:15,880
pile or even use it in non reconcilable

00:09:14,020 --> 00:09:18,430
form because it may accumulate from one

00:09:15,880 --> 00:09:20,470
to say four course and it will scale

00:09:18,430 --> 00:09:22,420
automatically on the on those execution

00:09:20,470 --> 00:09:26,080
units that you have with help of its

00:09:22,420 --> 00:09:27,970
built-in scheduler for example but what

00:09:26,080 --> 00:09:29,980
is more complex because it really it has

00:09:27,970 --> 00:09:32,260
quite a strong requirement even you want

00:09:29,980 --> 00:09:33,970
to run the same binary the same software

00:09:32,260 --> 00:09:35,950
on all the course you need to have

00:09:33,970 --> 00:09:38,020
obviously the same memory you wish which

00:09:35,950 --> 00:09:41,350
they share and see if you have caches

00:09:38,020 --> 00:09:44,020
you need even to have the those caches

00:09:41,350 --> 00:09:47,710
coherent so we which itself adds young

00:09:44,020 --> 00:09:49,270
hardware problems but what else here you

00:09:47,710 --> 00:09:51,010
need to think about scheduling in a run

00:09:49,270 --> 00:09:52,090
time that's good and that's bad that's

00:09:51,010 --> 00:09:53,380
good because you don't need to think

00:09:52,090 --> 00:09:55,780
about that in advance before you

00:09:53,380 --> 00:09:58,630
actually deploy that but then you need

00:09:55,780 --> 00:10:01,390
to intern a scheduler in such a good way

00:09:58,630 --> 00:10:03,940
so that it may actually allow you to use

00:10:01,390 --> 00:10:06,340
your performance of your hardware in the

00:10:03,940 --> 00:10:09,490
best way and not spending wasting time

00:10:06,340 --> 00:10:11,260
on doing something useless so yeah and

00:10:09,490 --> 00:10:13,000
you need to think about load balancing

00:10:11,260 --> 00:10:15,700
ability to probably pin your tests to

00:10:13,000 --> 00:10:18,160
some poor so there are quite a lot of

00:10:15,700 --> 00:10:20,170
things you need to think about so why we

00:10:18,160 --> 00:10:23,110
are talking about thats in conjunction

00:10:20,170 --> 00:10:25,600
with zephyr arts house operating system

00:10:23,110 --> 00:10:27,100
allows us to simplify development quite

00:10:25,600 --> 00:10:29,920
a lot because it allows us to use

00:10:27,100 --> 00:10:31,540
already implemented abstractions and so

00:10:29,920 --> 00:10:33,520
especially talking about multi-core

00:10:31,540 --> 00:10:35,200
designs if you do if you want to do from

00:10:33,520 --> 00:10:38,620
scratch and entirely yourself you need

00:10:35,200 --> 00:10:40,930
to think about scheduling interfaces for

00:10:38,620 --> 00:10:42,790
communications and so gyrus and all that

00:10:40,930 --> 00:10:44,470
but when you use already exist an

00:10:42,790 --> 00:10:47,110
operating system which at least surprise

00:10:44,470 --> 00:10:49,120
you drivers and some subsystems this is

00:10:47,110 --> 00:10:50,950
completely different situation that's

00:10:49,120 --> 00:10:53,260
much easier and seen in the best case

00:10:50,950 --> 00:10:55,330
money or money aboard is already

00:10:53,260 --> 00:10:57,460
supported what you need to do yeah just

00:10:55,330 --> 00:10:59,470
you just need sort

00:10:57,460 --> 00:11:01,690
creates a simple application which will

00:10:59,470 --> 00:11:03,490
print hello world and so it will be

00:11:01,690 --> 00:11:04,779
printed on the council so that's a

00:11:03,490 --> 00:11:07,029
benefit and that's why we are

00:11:04,779 --> 00:11:10,990
implementing a special supporter for

00:11:07,029 --> 00:11:14,080
either empty or smpm Zephyr as well so

00:11:10,990 --> 00:11:16,120
what we have for for AP in Zephyr from

00:11:14,080 --> 00:11:17,529
this from the very first committee MP

00:11:16,120 --> 00:11:19,480
was already there and so there was a

00:11:17,529 --> 00:11:22,900
platform which is now discontinued which

00:11:19,480 --> 00:11:25,210
is called Arduino or genuine 101 which

00:11:22,900 --> 00:11:27,640
was produced by Intel and so there we

00:11:25,210 --> 00:11:30,790
had two different course into the x86

00:11:27,640 --> 00:11:34,210
and arc en poor and they were working

00:11:30,790 --> 00:11:38,170
together they were on the same SOC and

00:11:34,210 --> 00:11:40,089
so they used only shared memory and some

00:11:38,170 --> 00:11:42,250
control systems control signals for

00:11:40,089 --> 00:11:45,310
communication with each other all in

00:11:42,250 --> 00:11:48,040
fact on the x86 core was able to tell

00:11:45,310 --> 00:11:50,170
something to signal something to our

00:11:48,040 --> 00:11:51,580
core but so no the other way around but

00:11:50,170 --> 00:11:54,850
they shared memory so they headed a

00:11:51,580 --> 00:11:58,240
channel for data exchange but now we

00:11:54,850 --> 00:12:00,430
have more of them we have an XP board we

00:11:58,240 --> 00:12:03,520
have as T and some other sense I think

00:12:00,430 --> 00:12:06,100
with in future we'll see more and so

00:12:03,520 --> 00:12:08,560
here you may see how that's actually

00:12:06,100 --> 00:12:12,760
communication between we're used to work

00:12:08,560 --> 00:12:15,550
on x86 core on power on we just put some

00:12:12,760 --> 00:12:18,190
value in a control register which then

00:12:15,550 --> 00:12:20,350
generated a signal to watch restart our

00:12:18,190 --> 00:12:22,330
core which then signaled okay if it was

00:12:20,350 --> 00:12:24,070
able to start or not so it was that

00:12:22,330 --> 00:12:27,100
simple and we didn't need to implement

00:12:24,070 --> 00:12:29,800
some other funky stuff still it was true

00:12:27,100 --> 00:12:31,930
multi-core system also endeavor we have

00:12:29,800 --> 00:12:34,570
for something called open MP that's a de

00:12:31,930 --> 00:12:36,640
facto standard for a MP system sense it

00:12:34,570 --> 00:12:40,060
allows a lot of flexibility it uses

00:12:36,640 --> 00:12:42,220
virtual for as a transports interface so

00:12:40,060 --> 00:12:44,230
it could be used for completely

00:12:42,220 --> 00:12:46,209
different situations for different

00:12:44,230 --> 00:12:48,790
designs anti recommends if you have any

00:12:46,209 --> 00:12:51,940
interests about that to take a look at

00:12:48,790 --> 00:12:55,240
that presentation which was done on we

00:12:51,940 --> 00:12:57,010
narrow connect last year I think so we

00:12:55,240 --> 00:12:58,270
have a link here download my slides and

00:12:57,010 --> 00:13:01,570
so you'll be able to get much more

00:12:58,270 --> 00:13:05,440
information about that but in Safari

00:13:01,570 --> 00:13:06,740
have open MP also we have for a sort of

00:13:05,440 --> 00:13:10,339
a sub

00:13:06,740 --> 00:13:12,709
of OpenMP which only use rpm messages so

00:13:10,339 --> 00:13:14,990
you cannot saw without control execution

00:13:12,709 --> 00:13:17,390
or a lifecycle of your software bots you

00:13:14,990 --> 00:13:20,420
may basically change it between course

00:13:17,390 --> 00:13:22,010
it is very tiny it is small and nice and

00:13:20,420 --> 00:13:24,260
very suitable for really deeply embedded

00:13:22,010 --> 00:13:25,760
things and again if you want so to get

00:13:24,260 --> 00:13:27,170
more details you have another link for

00:13:25,760 --> 00:13:30,620
another presentation which covers that

00:13:27,170 --> 00:13:33,830
in much more details and now talking

00:13:30,620 --> 00:13:35,930
about a Centene zephyr it's started to

00:13:33,830 --> 00:13:39,830
appear much later and so probably you'll

00:13:35,930 --> 00:13:44,810
understand why so its first was

00:13:39,830 --> 00:13:47,360
implemented in February 2018 for ESPE

00:13:44,810 --> 00:13:49,850
boards and so that was interesting

00:13:47,360 --> 00:13:52,310
because that's words that SOC has

00:13:49,850 --> 00:13:54,080
actually two cores but so the only way

00:13:52,310 --> 00:13:56,480
of communication between no two courses

00:13:54,080 --> 00:13:59,029
shared memory they don't even cross core

00:13:56,480 --> 00:14:02,839
interrupts which I will touch a little

00:13:59,029 --> 00:14:06,130
bit later and so then one year later

00:14:02,839 --> 00:14:10,190
exactly exactly there was support for

00:14:06,130 --> 00:14:12,350
SMP for x86 in Hulme you answer one of

00:14:10,190 --> 00:14:16,850
the reasons for that actually a 64-bit

00:14:12,350 --> 00:14:20,899
version x86 to be supported was to

00:14:16,850 --> 00:14:22,399
leverage SMP in simulation because

00:14:20,899 --> 00:14:24,290
before that you had to use that

00:14:22,399 --> 00:14:26,690
particular port which you may not have

00:14:24,290 --> 00:14:29,089
on your desk and now with QM you you may

00:14:26,690 --> 00:14:31,970
actually play with SMP on any computer

00:14:29,089 --> 00:14:33,770
so that that's quite convenient and then

00:14:31,970 --> 00:14:35,180
finally a couple of months ago we

00:14:33,770 --> 00:14:38,089
introduced as a free support for

00:14:35,180 --> 00:14:39,980
architecture and so that's interesting

00:14:38,089 --> 00:14:42,920
because that's the real first real

00:14:39,980 --> 00:14:44,540
harder which is or fully supported for

00:14:42,920 --> 00:14:46,399
us Andy because we have not only shared

00:14:44,540 --> 00:14:49,279
memory but we have four cross core

00:14:46,399 --> 00:14:51,310
interrupts and that really helps to

00:14:49,279 --> 00:14:54,110
implement SMP in a very efficient way

00:14:51,310 --> 00:14:58,760
and we support as well as simulation

00:14:54,110 --> 00:15:01,279
platform and billboard as well now

00:14:58,760 --> 00:15:05,000
speaking about has some feel in a little

00:15:01,279 --> 00:15:06,260
bit more details so still though there

00:15:05,000 --> 00:15:09,370
are a couple of things we might improve

00:15:06,260 --> 00:15:12,649
because so these are still early days

00:15:09,370 --> 00:15:14,630
but anyway so you know these points we

00:15:12,649 --> 00:15:16,370
use so I can share the memory we use

00:15:14,630 --> 00:15:17,470
cross core interrupt so to inform

00:15:16,370 --> 00:15:19,600
another core that's

00:15:17,470 --> 00:15:22,089
that or needs a job for that task which

00:15:19,600 --> 00:15:24,310
being used which being executed tanks or

00:15:22,089 --> 00:15:27,399
switch to something more important for

00:15:24,310 --> 00:15:31,480
example we use so cluster wise or cloth

00:15:27,399 --> 00:15:33,490
so every core might get some feel enough

00:15:31,480 --> 00:15:35,529
for if it's the time to do something

00:15:33,490 --> 00:15:39,100
else for example to run scheduler again

00:15:35,529 --> 00:15:40,600
and so we use atomic instructions

00:15:39,100 --> 00:15:42,279
because otherwise so it's hard to

00:15:40,600 --> 00:15:44,439
implement synchronization primitives

00:15:42,279 --> 00:15:46,629
here as well another interesting feature

00:15:44,439 --> 00:15:48,399
which was introduced or not long ago is

00:15:46,629 --> 00:15:50,790
ability to pin your tasks for a

00:15:48,399 --> 00:15:53,439
particular CPU core as I mentioned

00:15:50,790 --> 00:15:54,970
sometimes we want to do that and so the

00:15:53,439 --> 00:15:57,279
reason we want to do that because

00:15:54,970 --> 00:15:59,170
actually migration of a test from one

00:15:57,279 --> 00:16:02,529
CPU core to another might be quite

00:15:59,170 --> 00:16:04,629
costly because it might not be seen to

00:16:02,529 --> 00:16:07,120
the software developer but internally we

00:16:04,629 --> 00:16:08,740
have a lot of cash states like obviously

00:16:07,120 --> 00:16:11,139
we have instruction caches we have data

00:16:08,740 --> 00:16:12,759
caches we have multiple level of caches

00:16:11,139 --> 00:16:15,399
but it's not all we have branch

00:16:12,759 --> 00:16:17,410
predictor caches we have if we use a

00:16:15,399 --> 00:16:19,509
menu which we don't use in zephyr so far

00:16:17,410 --> 00:16:22,600
we have a manual for mm you have TLB

00:16:19,509 --> 00:16:24,220
cache and so all of that so when we go

00:16:22,600 --> 00:16:26,800
from one port to another we'll lose all

00:16:24,220 --> 00:16:29,860
that cache information and that means we

00:16:26,800 --> 00:16:31,630
need so to get it first before we can go

00:16:29,860 --> 00:16:32,920
full steam and that's important

00:16:31,630 --> 00:16:35,980
consideration especially thinking about

00:16:32,920 --> 00:16:38,139
Zephyr which is therefore very

00:16:35,980 --> 00:16:40,149
diplomatic things and every cycle is

00:16:38,139 --> 00:16:43,420
very important for us we cannot so spend

00:16:40,149 --> 00:16:46,060
1000 cycles just for task switching but

00:16:43,420 --> 00:16:49,600
anyways there is a way to pin a task

00:16:46,060 --> 00:16:52,560
even though only with one type of

00:16:49,600 --> 00:16:57,389
scheduler which is called so dump

00:16:52,560 --> 00:17:00,100
scheduler which just a normal queue for

00:16:57,389 --> 00:17:02,620
threat and so why don't we have it for

00:17:00,100 --> 00:17:04,659
other type of schedule is because for

00:17:02,620 --> 00:17:06,159
others you may have for example pry

00:17:04,659 --> 00:17:07,990
higher priority and task of higher

00:17:06,159 --> 00:17:11,020
priority in our sauce by definition

00:17:07,990 --> 00:17:12,880
won't be scheduled to way it will

00:17:11,020 --> 00:17:14,770
execute until it is done so if we have

00:17:12,880 --> 00:17:16,900
for some test which has high priority

00:17:14,770 --> 00:17:19,620
and it is always executed it will occupy

00:17:16,900 --> 00:17:23,350
that or infinitely so it's not a problem

00:17:19,620 --> 00:17:24,880
so what are we going to do or else so

00:17:23,350 --> 00:17:26,230
obviously we need to add more plasma

00:17:24,880 --> 00:17:28,720
because so far we have as I mentioned

00:17:26,230 --> 00:17:29,940
extensor we have for each 36 which makes

00:17:28,720 --> 00:17:32,039
not much sense in them

00:17:29,940 --> 00:17:35,159
Klim barrett world and our obviously we

00:17:32,039 --> 00:17:37,559
need to add arm there or risk 5 and

00:17:35,159 --> 00:17:40,919
whatever meeps probably if it is still a

00:17:37,559 --> 00:17:44,730
life it of any interest then we want to

00:17:40,919 --> 00:17:46,169
add more benchmarks and tests so we may

00:17:44,730 --> 00:17:47,519
get a feeling how your simply

00:17:46,169 --> 00:17:49,320
implementation really works and there

00:17:47,519 --> 00:17:52,049
are quite some communiques we have four

00:17:49,320 --> 00:17:54,539
very basic tests so far and I used it

00:17:52,049 --> 00:17:55,889
personally for development but again we

00:17:54,539 --> 00:17:59,789
need more and so we'll get to that a

00:17:55,889 --> 00:18:01,320
little bit later as well well at some

00:17:59,789 --> 00:18:03,269
point we may want to add more cores to

00:18:01,320 --> 00:18:05,610
the cluster and so there is no real

00:18:03,269 --> 00:18:07,950
technical limitation of supporting four

00:18:05,610 --> 00:18:11,460
cores so far but just because we never

00:18:07,950 --> 00:18:13,799
used any more and that's why we were

00:18:11,460 --> 00:18:15,809
happy and it's easier to add more and so

00:18:13,799 --> 00:18:18,720
obviously wants to think about more

00:18:15,809 --> 00:18:20,490
complicated and more you know smart

00:18:18,720 --> 00:18:24,779
scheduler mechanism which will take into

00:18:20,490 --> 00:18:27,629
account exactly those things we need so

00:18:24,779 --> 00:18:30,450
to care about like scheduling penalty

00:18:27,629 --> 00:18:33,960
and peculiarities of for this particular

00:18:30,450 --> 00:18:36,990
CPU our this particular design now

00:18:33,960 --> 00:18:42,779
speaking about things that we had to do

00:18:36,990 --> 00:18:45,090
in in zephyr to support SMP we had to do

00:18:42,779 --> 00:18:47,220
quite a lot of things and so still

00:18:45,090 --> 00:18:49,200
what's interesting although most of

00:18:47,220 --> 00:18:51,389
these things they were architecture

00:18:49,200 --> 00:18:53,759
independent which means whenever we get

00:18:51,389 --> 00:18:55,620
so that done all the architectures

00:18:53,759 --> 00:18:57,029
already may benefit from that they may

00:18:55,620 --> 00:19:00,200
just be used as a force and all

00:18:57,029 --> 00:19:03,000
implements one tiny thing which is

00:19:00,200 --> 00:19:05,460
functionality which actually switches

00:19:03,000 --> 00:19:07,259
threads that's pretty much the one thing

00:19:05,460 --> 00:19:10,230
that is required from the architecture

00:19:07,259 --> 00:19:12,600
so what we had to do we had so to add

00:19:10,230 --> 00:19:14,909
initialization or slave course because

00:19:12,600 --> 00:19:16,730
previously one we had only one core and

00:19:14,909 --> 00:19:18,720
one execution one execution unit

00:19:16,730 --> 00:19:20,610
essentially we had to initialize that

00:19:18,720 --> 00:19:23,220
but now we need to initialize those

00:19:20,610 --> 00:19:25,230
cores which which might even start

00:19:23,220 --> 00:19:26,759
halted or they might start running and

00:19:25,230 --> 00:19:28,950
we need to hold them when we initialize

00:19:26,759 --> 00:19:32,279
and to let them run once again execute

00:19:28,950 --> 00:19:34,980
not very useful stuff also we need so we

00:19:32,279 --> 00:19:37,649
had to rework how locking primitives

00:19:34,980 --> 00:19:39,990
because one you have only one execution

00:19:37,649 --> 00:19:41,399
you need the only problem you may face

00:19:39,990 --> 00:19:42,970
is interrupt because that's how you may

00:19:41,399 --> 00:19:43,990
get so execution of the same

00:19:42,970 --> 00:19:46,570
which you used to execute before

00:19:43,990 --> 00:19:48,610
interrupts but in case of for multiple

00:19:46,570 --> 00:19:50,980
course you may get to execution of the

00:19:48,610 --> 00:19:52,990
same quarter of the same code just by

00:19:50,980 --> 00:19:54,429
another core and so now we need to think

00:19:52,990 --> 00:19:56,559
about spin locks so we may have a

00:19:54,429 --> 00:19:57,580
critical section which is not entered by

00:19:56,559 --> 00:20:00,309
anybody else

00:19:57,580 --> 00:20:02,289
while one executor is already using that

00:20:00,309 --> 00:20:04,750
and that's that obviously adds

00:20:02,289 --> 00:20:07,059
complexity and we pay for that because

00:20:04,750 --> 00:20:11,110
whenever two cores want to access the

00:20:07,059 --> 00:20:13,360
same critical or code path some of them

00:20:11,110 --> 00:20:16,059
will wait just wasting time which is not

00:20:13,360 --> 00:20:19,480
good but we have to do that now also we

00:20:16,059 --> 00:20:21,490
had or to improve scheduler in such a

00:20:19,480 --> 00:20:23,380
way so we know that we have a couple of

00:20:21,490 --> 00:20:25,750
execution units again before we had just

00:20:23,380 --> 00:20:27,549
one execution unit we have a long list

00:20:25,750 --> 00:20:29,530
of threads for example and we just

00:20:27,549 --> 00:20:31,179
executed it in one by one now we have

00:20:29,530 --> 00:20:33,570
multiple execution units and we need to

00:20:31,179 --> 00:20:37,419
think about how to schedule those

00:20:33,570 --> 00:20:39,640
multiple tasks on different CPUs small

00:20:37,419 --> 00:20:41,590
tenuously or like one by one so well

00:20:39,640 --> 00:20:43,600
there were quite a few complexities and

00:20:41,590 --> 00:20:45,309
in the end we had to implement a little

00:20:43,600 --> 00:20:46,690
bit different scheduling not scheduling

00:20:45,309 --> 00:20:50,169
but test switch in mechanism because

00:20:46,690 --> 00:20:54,070
before we had a couple of logs there in

00:20:50,169 --> 00:20:56,350
the code and given that code is being

00:20:54,070 --> 00:20:59,320
executed being implemented in low-level

00:20:56,350 --> 00:21:01,270
assembly now we didn't want to have any

00:20:59,320 --> 00:21:04,870
locks implemented and in assembly so

00:21:01,270 --> 00:21:07,000
that's why we moved most of the culture

00:21:04,870 --> 00:21:08,970
to generic parts and it's only left a

00:21:07,000 --> 00:21:10,570
very minimal amount of force

00:21:08,970 --> 00:21:12,820
implementation which is architecture

00:21:10,570 --> 00:21:16,299
specific and obviously is really an

00:21:12,820 --> 00:21:18,130
assembly so quite a lot of things were

00:21:16,299 --> 00:21:20,350
done and so it worked quite well well

00:21:18,130 --> 00:21:21,700
now speaking about so hardware

00:21:20,350 --> 00:21:24,220
peculiarities we need to think about

00:21:21,700 --> 00:21:27,309
when we are talking about so true a

00:21:24,220 --> 00:21:29,409
simpie system and so it it has to do not

00:21:27,309 --> 00:21:31,780
only with zephyr but any other operating

00:21:29,409 --> 00:21:34,750
system or an operating system as well so

00:21:31,780 --> 00:21:36,760
here you see a block diagram of again

00:21:34,750 --> 00:21:39,460
quite more than SOC which consists of

00:21:36,760 --> 00:21:40,960
two cores and some other things so what

00:21:39,460 --> 00:21:43,120
is important when we are talking about

00:21:40,960 --> 00:21:44,710
SMP again we need to have exactly the

00:21:43,120 --> 00:21:46,510
same instruction set architecture so

00:21:44,710 --> 00:21:47,330
that we may use exactly the same binary

00:21:46,510 --> 00:21:49,159
on

00:21:47,330 --> 00:21:51,980
or execute the same binary by all

00:21:49,159 --> 00:21:53,389
execution units and we need to have

00:21:51,980 --> 00:21:55,220
shared memory and with shared memory

00:21:53,389 --> 00:21:57,350
it's not that easy I mentioned already

00:21:55,220 --> 00:21:59,509
that if you have caches they have to be

00:21:57,350 --> 00:22:02,210
coherent but so there is another thing

00:21:59,509 --> 00:22:06,590
most of our work with a lot of embedded

00:22:02,210 --> 00:22:09,139
systems what they have they have very

00:22:06,590 --> 00:22:11,059
fast on board on chip memory which is

00:22:09,139 --> 00:22:12,889
nice because instead of a couple of

00:22:11,059 --> 00:22:15,679
hundred cycles latency you have like one

00:22:12,889 --> 00:22:18,139
or two cycles which is nice but as it

00:22:15,679 --> 00:22:20,109
turned out since we came from single

00:22:18,139 --> 00:22:22,999
core designs a lot of those memories

00:22:20,109 --> 00:22:25,039
might be so-called private which means

00:22:22,999 --> 00:22:27,379
they are accepting access accessed only

00:22:25,039 --> 00:22:28,909
from one core and in our case it doesn't

00:22:27,379 --> 00:22:30,559
work because given we use the same

00:22:28,909 --> 00:22:32,899
variable which is supposed to be mapped

00:22:30,559 --> 00:22:34,669
to address X we can access it from one

00:22:32,899 --> 00:22:36,739
core and write something but in other

00:22:34,669 --> 00:22:39,889
core won't treat whatever previous score

00:22:36,739 --> 00:22:41,779
the first core role there so then we

00:22:39,889 --> 00:22:43,730
need to use only memory which is shared

00:22:41,779 --> 00:22:44,779
between all the CPUs and visible exactly

00:22:43,730 --> 00:22:46,309
in the same way so it might be a

00:22:44,779 --> 00:22:47,960
situation when you may access that

00:22:46,309 --> 00:22:49,970
private memory from another core through

00:22:47,960 --> 00:22:51,529
some debug interface for example but it

00:22:49,970 --> 00:22:52,999
won't working into access exactly the

00:22:51,529 --> 00:22:54,590
same variable at exactly the same

00:22:52,999 --> 00:22:57,049
address and read the same value which

00:22:54,590 --> 00:22:59,210
was written before by not by another

00:22:57,049 --> 00:23:02,359
core so we have to be careful with that

00:22:59,210 --> 00:23:06,139
also it's important to have ability to

00:23:02,359 --> 00:23:08,659
or to to you to implement interrupts

00:23:06,139 --> 00:23:09,980
between course so that's one core

00:23:08,659 --> 00:23:12,739
amazing on another because otherwise

00:23:09,980 --> 00:23:15,379
what happens if we have if we don't have

00:23:12,739 --> 00:23:17,710
interrupts between course one core start

00:23:15,379 --> 00:23:20,600
to execute tasks and execute that so

00:23:17,710 --> 00:23:22,669
until we decide it needs to stop

00:23:20,600 --> 00:23:24,289
execution and only then it starts

00:23:22,669 --> 00:23:26,600
scheduler and may pick up another thread

00:23:24,289 --> 00:23:30,679
another execution another application

00:23:26,600 --> 00:23:32,239
but what if we we know so far that we

00:23:30,679 --> 00:23:33,470
need to drop the execution of that thing

00:23:32,239 --> 00:23:36,739
because we have something of higher

00:23:33,470 --> 00:23:40,070
priority and since we don't have any way

00:23:36,739 --> 00:23:42,049
to or to inform that or from outside so

00:23:40,070 --> 00:23:44,090
we'll just need to wait until it gets

00:23:42,049 --> 00:23:45,710
interrupt from the timer for example run

00:23:44,090 --> 00:23:47,720
scheduler and then understand ok I need

00:23:45,710 --> 00:23:50,119
to do something else but if we have that

00:23:47,720 --> 00:23:52,009
ability to inform it so I like to force

00:23:50,119 --> 00:23:54,409
or do it something where at least

00:23:52,009 --> 00:23:56,779
trigger execution of the scheduler it

00:23:54,409 --> 00:23:59,790
helps to lower latencies significantly

00:23:56,779 --> 00:24:01,710
so that's a really hardened requirement

00:23:59,790 --> 00:24:04,290
and so cluster clock as I mentioned so

00:24:01,710 --> 00:24:07,080
is also important because we it's much

00:24:04,290 --> 00:24:10,110
easier to check time and know whenever I

00:24:07,080 --> 00:24:11,130
need to do something and so that's how

00:24:10,110 --> 00:24:13,980
it really works

00:24:11,130 --> 00:24:16,890
now speaking about challenges we may

00:24:13,980 --> 00:24:18,720
face developing software for SMP system

00:24:16,890 --> 00:24:20,880
we need to think about scheduling

00:24:18,720 --> 00:24:22,770
because we do it in run time and so if

00:24:20,880 --> 00:24:25,980
we don't don't do it right then we may

00:24:22,770 --> 00:24:28,080
lose our performance for nothing and we

00:24:25,980 --> 00:24:30,510
need to think about migration costs for

00:24:28,080 --> 00:24:32,190
between CPUs and so we need to do it so

00:24:30,510 --> 00:24:34,020
for benchmarking otherwise so that's

00:24:32,190 --> 00:24:36,330
hard to to understand what's really

00:24:34,020 --> 00:24:38,840
going on and we have to take care about

00:24:36,330 --> 00:24:41,550
shared resources because we cannot use

00:24:38,840 --> 00:24:43,320
the same peripheral simultaneously by

00:24:41,550 --> 00:24:45,480
two cores and so then we need to

00:24:43,320 --> 00:24:48,030
implement all those locking and so

00:24:45,480 --> 00:24:51,120
that's why we may load the loose or some

00:24:48,030 --> 00:24:52,950
performance as well and so now I wanted

00:24:51,120 --> 00:24:54,780
to show that how easy it is so if your

00:24:52,950 --> 00:24:56,160
platform and your board is supported so

00:24:54,780 --> 00:24:58,350
you can see for configuration utility

00:24:56,160 --> 00:25:00,150
you just say ok I want to use S&P I have

00:24:58,350 --> 00:25:03,750
a couple of course and you reboot and

00:25:00,150 --> 00:25:04,800
get it executed so well that that's that

00:25:03,750 --> 00:25:06,840
it is that simple

00:25:04,800 --> 00:25:10,400
and so speaking about test which we are

00:25:06,840 --> 00:25:14,250
not so have enough enough for quantity

00:25:10,400 --> 00:25:15,990
to actually measure how we may use what

00:25:14,250 --> 00:25:17,340
kind of scaling we may get with multiple

00:25:15,990 --> 00:25:19,290
cores I had to implement my own

00:25:17,340 --> 00:25:21,180
implication which is yet to be accepted

00:25:19,290 --> 00:25:23,760
even though there are no more comments

00:25:21,180 --> 00:25:26,250
and probably it will be pulled in like

00:25:23,760 --> 00:25:28,740
any day now so what the duplication does

00:25:26,250 --> 00:25:29,760
it's or creates multiple threads and in

00:25:28,740 --> 00:25:36,150
which of the threads

00:25:29,760 --> 00:25:39,330
it's just compute so the in certain with

00:25:36,150 --> 00:25:45,060
a certain amount of four symbols with a

00:25:39,330 --> 00:25:47,490
certain precision and so when I compile

00:25:45,060 --> 00:25:51,360
it and execute it and use it to

00:25:47,490 --> 00:25:53,820
different precision so one of us or 120

00:25:51,360 --> 00:25:56,250
digits and another was so twice more so

00:25:53,820 --> 00:25:58,470
you may see here how performance

00:25:56,250 --> 00:26:00,710
actually scales and that's really nice

00:25:58,470 --> 00:26:03,150
to see that when you have tests which

00:26:00,710 --> 00:26:05,280
consume so quite a lot of time I mean it

00:26:03,150 --> 00:26:08,520
is not interrupted quite rapidly you may

00:26:05,280 --> 00:26:11,400
actually get almost off in half times

00:26:08,520 --> 00:26:12,509
performance bump which is good it means

00:26:11,400 --> 00:26:15,989
you have four cores you

00:26:12,509 --> 00:26:17,759
gets almost four times more stuff to be

00:26:15,989 --> 00:26:20,579
done but when you start decreasing

00:26:17,759 --> 00:26:23,579
amount of work you do in one month tasks

00:26:20,579 --> 00:26:25,049
you may see how significantly your

00:26:23,579 --> 00:26:27,209
performance may drop so even you have

00:26:25,049 --> 00:26:32,099
four cores you barely get to two and a

00:26:27,209 --> 00:26:34,259
4x but that's not all so if I get back

00:26:32,099 --> 00:26:36,149
to our stuff we run on Linux and so

00:26:34,259 --> 00:26:38,969
that's one of the tests of a MBC

00:26:36,149 --> 00:26:40,559
benchmark NBC Multi bench in that

00:26:38,969 --> 00:26:42,749
benchmark initially that's even

00:26:40,559 --> 00:26:46,829
execution on for coarse doesn't give us

00:26:42,749 --> 00:26:48,749
even to two times of improvement so in

00:26:46,829 --> 00:26:51,479
that basically means the dependent on

00:26:48,749 --> 00:26:53,849
you in your use case you may either get

00:26:51,479 --> 00:26:55,979
quite a nice improvement of performance

00:26:53,849 --> 00:27:00,299
or you may get pretty much nothing so

00:26:55,979 --> 00:27:02,089
it's important to really make your duty

00:27:00,299 --> 00:27:04,859
profile in not even estimation but

00:27:02,089 --> 00:27:06,509
preferably profiling and figure out what

00:27:04,859 --> 00:27:09,899
is your workload and how you may improve

00:27:06,509 --> 00:27:13,739
on that so we're getting to the end of

00:27:09,899 --> 00:27:16,379
that quite a short talk so what I wanted

00:27:13,739 --> 00:27:18,440
to highlight here so zephyr provide you

00:27:16,379 --> 00:27:20,549
with enough for capabilities to leverage

00:27:18,440 --> 00:27:24,359
multi-core designs of different types

00:27:20,549 --> 00:27:25,949
beads or simple and ordinary S&P or

00:27:24,359 --> 00:27:28,169
these high tech genius system because

00:27:25,949 --> 00:27:30,179
together with SMP you may have as I

00:27:28,169 --> 00:27:32,069
showed on my blog diagram before you may

00:27:30,179 --> 00:27:34,859
have different CPUs who you have really

00:27:32,069 --> 00:27:36,659
SMP plus NP as well it is also possible

00:27:34,859 --> 00:27:38,669
and so that's what we typically have and

00:27:36,659 --> 00:27:41,039
so that's always good to have in think

00:27:38,669 --> 00:27:42,719
you are harder team and software teams

00:27:41,039 --> 00:27:44,819
so that you have hardware which is

00:27:42,719 --> 00:27:46,979
already probably supported in your

00:27:44,819 --> 00:27:48,419
software and from software standpoint

00:27:46,979 --> 00:27:51,479
you have all the required hardware

00:27:48,419 --> 00:27:53,549
interfaces and mechanisms that so you'd

00:27:51,479 --> 00:27:58,139
like to actually use in your software

00:27:53,549 --> 00:28:00,179
and so then I invite you to participate

00:27:58,139 --> 00:28:02,459
in Zephyr development so that's quite

00:28:00,179 --> 00:28:03,569
nice community with all the development

00:28:02,459 --> 00:28:05,549
on github

00:28:03,569 --> 00:28:08,789
you are welcome with your bug reports

00:28:05,549 --> 00:28:11,819
pull requests and so so I'll be able to

00:28:08,789 --> 00:28:13,440
see more people contributing oh thanks

00:28:11,819 --> 00:28:15,539
so that's pretty much it from my side

00:28:13,440 --> 00:28:17,759
I'll be happy to answer questions if you

00:28:15,539 --> 00:28:22,379
have any we have about five minutes for

00:28:17,759 --> 00:28:25,459
that sure are we going to provide a

00:28:22,379 --> 00:28:25,459
microphone or something

00:28:28,470 --> 00:28:37,240
Jenny deterrent on okay but it's one we

00:28:33,100 --> 00:28:39,279
captured from the records so I noticed

00:28:37,240 --> 00:28:41,220
in your code example for calculating PI

00:28:39,279 --> 00:28:43,389
that you are using competitive threats

00:28:41,220 --> 00:28:44,950
doesn't using competitive threats and

00:28:43,389 --> 00:28:47,919
SNP and running them in multiple course

00:28:44,950 --> 00:28:50,379
break the comparative please repeat this

00:28:47,919 --> 00:28:52,659
again yeah so in your your code example

00:28:50,379 --> 00:28:54,249
you were using comparative threats

00:28:52,659 --> 00:28:56,619
unless I'm mistaken because you're using

00:28:54,249 --> 00:28:59,440
the macro to create threads of

00:28:56,619 --> 00:29:01,779
comparative priority competitive threats

00:28:59,440 --> 00:29:05,019
by definition they executed sequentially

00:29:01,779 --> 00:29:06,580
if you execute them in in multiple cores

00:29:05,019 --> 00:29:10,539
that means they're executing at the same

00:29:06,580 --> 00:29:12,429
time so shouldn't in parallel yeah but

00:29:10,539 --> 00:29:13,539
that's the point so the point of a

00:29:12,429 --> 00:29:15,909
competitive threat the theory is that

00:29:13,539 --> 00:29:17,379
you do you know that you're not going to

00:29:15,909 --> 00:29:19,330
be preempted by another competitive

00:29:17,379 --> 00:29:21,460
threat there at least or by the only way

00:29:19,330 --> 00:29:23,740
an ISR really yes by doing that and

00:29:21,460 --> 00:29:27,460
you're breaking the co-operative threat

00:29:23,740 --> 00:29:29,830
contract well here are intentionally

00:29:27,460 --> 00:29:32,649
what I did I just saw made priority or

00:29:29,830 --> 00:29:34,450
for those threats the first priority is

00:29:32,649 --> 00:29:36,909
the same for all those extra threads and

00:29:34,450 --> 00:29:39,309
it is even higher than your main threat

00:29:36,909 --> 00:29:41,350
so that's all the computational power

00:29:39,309 --> 00:29:42,850
that you have or will be used by your

00:29:41,350 --> 00:29:45,580
threat and given they have the same

00:29:42,850 --> 00:29:47,889
priority they will be scheduled to as

00:29:45,580 --> 00:29:50,889
many CPUs as you as you have and then

00:29:47,889 --> 00:29:52,899
whenever one task and so another one

00:29:50,889 --> 00:29:56,110
gets scheduled to this CPU and that's

00:29:52,899 --> 00:29:58,509
why I used here 16 threads and given I

00:29:56,110 --> 00:30:03,309
run it on Torf work or configuration it

00:29:58,509 --> 00:30:05,259
means we have an enough of reruns of the

00:30:03,309 --> 00:30:11,019
pretty much the same thread on different

00:30:05,259 --> 00:30:13,899
CPUs I wonder if I should really rethink

00:30:11,019 --> 00:30:15,789
whether a competitive threat or two

00:30:13,899 --> 00:30:18,190
competitive threats should be allowed to

00:30:15,789 --> 00:30:19,869
run concurrently on two cores because if

00:30:18,190 --> 00:30:21,639
you did that for certain subsystems that

00:30:19,869 --> 00:30:23,350
we have now that rely on the fact that

00:30:21,639 --> 00:30:25,990
cooperative threats cannot be preempted

00:30:23,350 --> 00:30:27,820
by a or cannot run it concurrently with

00:30:25,990 --> 00:30:31,119
another cooperative thread that's gonna

00:30:27,820 --> 00:30:33,460
break so some of the subsystems so you

00:30:31,119 --> 00:30:34,960
know well probably we'd better discuss

00:30:33,460 --> 00:30:37,460
it offline because I don't quite

00:30:34,960 --> 00:30:39,690
understand and I like to

00:30:37,460 --> 00:30:41,550
because we saw that and then immediately

00:30:39,690 --> 00:30:43,590
thought of some subsystems that rely on

00:30:41,550 --> 00:30:45,630
that fact if not neither does you were

00:30:43,590 --> 00:30:47,250
gonna compile that for an SMP system and

00:30:45,630 --> 00:30:49,140
those cooperatives retroactively

00:30:47,250 --> 00:30:52,530
scheduled to run multiple CPUs that

00:30:49,140 --> 00:30:58,040
would break today yeah that's okay

00:30:52,530 --> 00:31:00,810
anybody else yes I have one question I

00:30:58,040 --> 00:31:03,900
seen in slides that you are introducing

00:31:00,810 --> 00:31:05,910
the global SMP LOC about 12 years ago

00:31:03,900 --> 00:31:08,370
there was huge work in all peak

00:31:05,910 --> 00:31:10,890
operating system like Linux BSD s and so

00:31:08,370 --> 00:31:15,270
on to basically get rid of that concept

00:31:10,890 --> 00:31:18,300
because it slows down whole kernel this

00:31:15,270 --> 00:31:21,510
is temple our solution until pair

00:31:18,300 --> 00:31:23,280
subsystems locks will appear or because

00:31:21,510 --> 00:31:26,280
of simplicity of the software we are

00:31:23,280 --> 00:31:28,110
going to have the unblock I think will

00:31:26,280 --> 00:31:30,780
go in the same way as linens development

00:31:28,110 --> 00:31:33,360
goes we are not so planning that far in

00:31:30,780 --> 00:31:35,250
advance so as long as it works so that

00:31:33,360 --> 00:31:37,680
good I understand there are quite a few

00:31:35,250 --> 00:31:41,130
limitations of that but if there is any

00:31:37,680 --> 00:31:43,440
better solution and somebody is willing

00:31:41,130 --> 00:31:45,390
to fix that because it really hits him

00:31:43,440 --> 00:31:48,540
on performance side I'm pretty sure that

00:31:45,390 --> 00:31:50,250
will be done but so so far again what I

00:31:48,540 --> 00:31:52,950
mentioned we are quite in early days

00:31:50,250 --> 00:31:56,310
here and so I don't think there are any

00:31:52,950 --> 00:31:58,080
real products which use that right so

00:31:56,310 --> 00:32:00,480
whenever we start seeing people

00:31:58,080 --> 00:32:02,840
implementing that in real products

00:32:00,480 --> 00:32:06,270
essentially we will get that fixed I

00:32:02,840 --> 00:32:08,310
think that on the very beginning the

00:32:06,270 --> 00:32:10,380
Gantt lock is something which is

00:32:08,310 --> 00:32:12,830
perceived like as easy to use and

00:32:10,380 --> 00:32:15,750
solving the problem the question is

00:32:12,830 --> 00:32:20,610
could we basically avoid the mistake

00:32:15,750 --> 00:32:24,120
made by others well probably so I don't

00:32:20,610 --> 00:32:26,130
have any ready answer like I don't know

00:32:24,120 --> 00:32:28,380
lianna's may correct me but we don't

00:32:26,130 --> 00:32:31,550
have anything in the issues filed on

00:32:28,380 --> 00:32:36,980
that like we want to get rid of that

00:32:31,550 --> 00:32:36,980
okay I will fire back sure that's good

00:32:42,309 --> 00:32:49,269
just a question about a pen amp last

00:32:45,549 --> 00:32:53,140
year there was a big step in opening

00:32:49,269 --> 00:32:55,120
release that should improve open up this

00:32:53,140 --> 00:32:55,539
message we please talk a little bit

00:32:55,120 --> 00:32:58,899
louder

00:32:55,539 --> 00:33:03,399
I probably me sorry so last year there

00:32:58,899 --> 00:33:07,649
was an open release that should fix a

00:33:03,399 --> 00:33:12,610
part of the convention I would like to

00:33:07,649 --> 00:33:14,230
know if you you compare up a message

00:33:12,610 --> 00:33:17,769
delete an open um

00:33:14,230 --> 00:33:20,529
based on the order release also then I

00:33:17,769 --> 00:33:24,429
would say the risk which now integrated

00:33:20,529 --> 00:33:29,760
in the field I am sorry I cannot

00:33:24,429 --> 00:33:33,720
sexually understand yet she may make

00:33:29,760 --> 00:33:40,600
somewhere between our Father French so

00:33:33,720 --> 00:33:41,860
in October 2018 opponent has been

00:33:40,600 --> 00:33:46,210
released

00:33:41,860 --> 00:33:49,570
we saw what a pair an NPC MP has been

00:33:46,210 --> 00:33:57,399
released with some improvement in term

00:33:49,570 --> 00:34:00,399
of footprint in dam of API decoupling of

00:33:57,399 --> 00:34:03,610
remote pocket in change and I would like

00:34:00,399 --> 00:34:06,730
to know if you status you show you was

00:34:03,610 --> 00:34:09,070
based on this new released or was based

00:34:06,730 --> 00:34:12,159
on the the previous winners well

00:34:09,070 --> 00:34:14,679
personally I haven't been dealing with

00:34:12,159 --> 00:34:16,599
openmp are quite water at near a simmer

00:34:14,679 --> 00:34:21,159
in there so probably Sheen also will be

00:34:16,599 --> 00:34:23,889
better what is the status on that I just

00:34:21,159 --> 00:34:25,960
say that that Nordic we've created the

00:34:23,889 --> 00:34:28,450
benchmark to compare open a MP NRP

00:34:25,960 --> 00:34:29,440
message light and we've actually made it

00:34:28,450 --> 00:34:32,619
public on a branch

00:34:29,440 --> 00:34:35,230
so the if that sort of where you're

00:34:32,619 --> 00:34:37,750
going we and yes and integrates the

00:34:35,230 --> 00:34:41,260
latest version of open MP miners some

00:34:37,750 --> 00:34:43,119
commits in the head so so I don't know

00:34:41,260 --> 00:34:44,740
where those numbers came from but if you

00:34:43,119 --> 00:34:47,290
talking about benchmarking open MP in

00:34:44,740 --> 00:34:49,240
the context of Zephir yes we do have the

00:34:47,290 --> 00:34:50,859
latest version and yes we've run

00:34:49,240 --> 00:34:52,300
benchmarks to compare it to other a MP

00:34:50,859 --> 00:34:53,190
systems and if you're interested there's

00:34:52,300 --> 00:34:56,519
a branch there too

00:34:53,190 --> 00:34:58,950
actually run it on an on the Express OPC

00:34:56,519 --> 00:35:04,069
50 I can't remember the number but that

00:34:58,950 --> 00:35:08,400
one which was mentioned in the slides so

00:35:04,069 --> 00:35:11,450
okay thank you do have any more time or

00:35:08,400 --> 00:35:14,279
we need to conclude on that

00:35:11,450 --> 00:35:15,850
okay so thanks a lot so I'll be happy to

00:35:14,279 --> 00:35:21,920
answer any other questions

00:35:15,850 --> 00:35:21,920

YouTube URL: https://www.youtube.com/watch?v=w3HYIPBEpu8


