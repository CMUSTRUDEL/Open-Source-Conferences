Title: V4L2: A Status Update - Hans Verkuil, Cisco Systems Norway
Publication date: 2019-10-29
Playlist: Open Source Summit & Embedded Linux Conference EU 2019 - Lyon
Description: 
	V4L2: A Status Update - Hans Verkuil, Cisco Systems Norway*

Since the beginning of 2018 a lot of work has been put into improving the V4L2 subsystem. The main addition was the Request API, which is required for stateless hardware codecs, and will help improve complex camera pipelines. Codecs in general saw a lot of attention and our virtual drivers (such as the new vicodec driver) are now being used in test frameworks. So it is time to present an overview of the current state of V4L2 and what can be expected from it in the future.
Captions: 
	00:00:00,030 --> 00:00:07,080
okay welcome so what I'm talking about

00:00:05,100 --> 00:00:09,750
first of all I'm hamster cow I'm one of

00:00:07,080 --> 00:00:14,639
the co maintains a video for Linux I

00:00:09,750 --> 00:00:16,710
work for Cisco and so it was time to

00:00:14,639 --> 00:00:19,380
give status updates every so often I do

00:00:16,710 --> 00:00:22,640
that just what is going on in video for

00:00:19,380 --> 00:00:26,519
Linux land in the in that subsystem and

00:00:22,640 --> 00:00:28,560
there are two main topics today the

00:00:26,519 --> 00:00:31,019
biggest one is Hardware codec support

00:00:28,560 --> 00:00:35,899
because that has seen a huge amount of

00:00:31,019 --> 00:00:35,899
work in the past year year and a half

00:00:36,500 --> 00:00:42,210
what was particularly interesting about

00:00:39,690 --> 00:00:44,850
that projects was how many different

00:00:42,210 --> 00:00:50,000
people developers and organizations were

00:00:44,850 --> 00:00:54,660
involved from boot lean collabora Google

00:00:50,000 --> 00:00:57,050
Peggy tronics outreach he Linux there's

00:00:54,660 --> 00:01:01,940
a project going on now no the smokes

00:00:57,050 --> 00:01:04,260
outreaching yeah I'm sure I miss people

00:01:01,940 --> 00:01:05,400
but that made it really interesting to

00:01:04,260 --> 00:01:08,070
see all these different companies

00:01:05,400 --> 00:01:12,150
working together to make a good API for

00:01:08,070 --> 00:01:15,000
a certain class of hardware codecs so

00:01:12,150 --> 00:01:19,830
first a little bit of overview for how

00:01:15,000 --> 00:01:23,100
does a hardware kodak look you have this

00:01:19,830 --> 00:01:25,680
user space use space prepares buffers

00:01:23,100 --> 00:01:28,590
containing of one thing that should

00:01:25,680 --> 00:01:31,439
mention at the start unless I stayed

00:01:28,590 --> 00:01:33,659
otherwise I'm talking about decoders so

00:01:31,439 --> 00:01:36,479
you get compressed frames go in and you

00:01:33,659 --> 00:01:38,640
get decoded frames out it gets really

00:01:36,479 --> 00:01:40,740
awkward if I all the time have to

00:01:38,640 --> 00:01:42,030
explain how it works for an encoded but

00:01:40,740 --> 00:01:44,159
in the knockout door is just swapped

00:01:42,030 --> 00:01:45,810
writes you get a raw framing you get

00:01:44,159 --> 00:01:47,460
compressed frames out so I'm not going

00:01:45,810 --> 00:01:51,960
to mention that anymore unless I really

00:01:47,460 --> 00:01:54,360
need to so for a decoder you send in

00:01:51,960 --> 00:01:57,540
buffers containing the byte stream

00:01:54,360 --> 00:02:00,450
basically you compress my dream the

00:01:57,540 --> 00:02:04,619
hardware codec takes a buffer decodes it

00:02:00,450 --> 00:02:06,600
and the results go on go out on the

00:02:04,619 --> 00:02:10,800
other side so there you get the first

00:02:06,600 --> 00:02:12,670
containing the decoded frames and at the

00:02:10,800 --> 00:02:16,360
end they are

00:02:12,670 --> 00:02:21,810
d cute so you you space now has access

00:02:16,360 --> 00:02:21,810
to the role to the drove compress frames

00:02:22,470 --> 00:02:26,290
one thing that is important for codex

00:02:24,820 --> 00:02:29,410
and I will go through this very quickly

00:02:26,290 --> 00:02:31,630
this is not a course in how codecs work

00:02:29,410 --> 00:02:34,300
but this bit is important so that's why

00:02:31,630 --> 00:02:35,980
I made a made a slide of it or actually

00:02:34,300 --> 00:02:38,910
I stole a slide for it

00:02:35,980 --> 00:02:44,500
that's a nice Wikipedia reference there

00:02:38,910 --> 00:02:47,430
so you have iframes those are basically

00:02:44,500 --> 00:02:49,930
JPEGs look at it like that so they

00:02:47,430 --> 00:02:52,840
compress the image independent of any

00:02:49,930 --> 00:02:55,180
others and then for video you also have

00:02:52,840 --> 00:02:57,640
predicted pictures so they basically are

00:02:55,180 --> 00:03:01,239
the diff between an iframe and the

00:02:57,640 --> 00:03:05,830
picture that you want to create and you

00:03:01,239 --> 00:03:08,200
have bi-directional frames they take

00:03:05,830 --> 00:03:11,230
both the predicted frame and iframe and

00:03:08,200 --> 00:03:14,620
then basically built up the picture from

00:03:11,230 --> 00:03:17,489
death I leave it to as an exercise to

00:03:14,620 --> 00:03:19,810
the reader to understand why when you do

00:03:17,489 --> 00:03:22,870
videoconferencing you never have B

00:03:19,810 --> 00:03:25,170
frames think about it and you will

00:03:22,870 --> 00:03:27,519
figure it out

00:03:25,170 --> 00:03:30,760
but this is this type of stuff that the

00:03:27,519 --> 00:03:34,180
codec needs to support so we have two

00:03:30,760 --> 00:03:37,209
different codecs hardware CODIS the one

00:03:34,180 --> 00:03:40,209
is called stateful codecs basically you

00:03:37,209 --> 00:03:42,190
gave it the byte stream the codec will

00:03:40,209 --> 00:03:47,110
parse the byte stream extract all the

00:03:42,190 --> 00:03:49,600
metadata and start decoding so all the

00:03:47,110 --> 00:03:51,730
states involved in this is kept in the

00:03:49,600 --> 00:03:53,830
hardware or the firmware doesn't matter

00:03:51,730 --> 00:04:02,350
for us it's a black box and it's all in

00:03:53,830 --> 00:04:04,330
there ideally stateful codec you can

00:04:02,350 --> 00:04:07,840
just give it the byte stream without any

00:04:04,330 --> 00:04:10,480
regards to boundaries but there are some

00:04:07,840 --> 00:04:12,160
that can do that but there are also the

00:04:10,480 --> 00:04:13,959
most of them require you that you at

00:04:12,160 --> 00:04:17,729
least parse the byte stream in news

00:04:13,959 --> 00:04:21,130
space so you get the frame boundaries

00:04:17,729 --> 00:04:23,440
there is a capability or something that

00:04:21,130 --> 00:04:26,080
lets you know and only user space level

00:04:23,440 --> 00:04:29,500
whether or not it can

00:04:26,080 --> 00:04:34,750
parce a completely your all-white stream

00:04:29,500 --> 00:04:37,150
or not so this has been supported for a

00:04:34,750 --> 00:04:40,180
long time the main thing that has been

00:04:37,150 --> 00:04:42,789
added is that we really wrote down all

00:04:40,180 --> 00:04:45,370
the rules in the API on how to do things

00:04:42,789 --> 00:04:47,379
like Sikhs when you have dynamic

00:04:45,370 --> 00:04:49,569
resolution changes middle in the middle

00:04:47,379 --> 00:04:52,150
of the stream and all these these corner

00:04:49,569 --> 00:04:55,030
cases they have been clearly written

00:04:52,150 --> 00:04:59,740
down Google has contributed much of that

00:04:55,030 --> 00:05:03,520
work the detail the code specification

00:04:59,740 --> 00:05:07,719
is now in mainline or will be this five

00:05:03,520 --> 00:05:09,520
five for the encoder there are still a

00:05:07,719 --> 00:05:13,620
few details that we want to figure out

00:05:09,520 --> 00:05:13,620
so but hopefully that will go in soon

00:05:15,509 --> 00:05:20,560
basically this works so several of the

00:05:18,460 --> 00:05:22,449
existing drivers are being updated to

00:05:20,560 --> 00:05:24,219
complete to nicely follow the

00:05:22,449 --> 00:05:29,190
specification that are no differences

00:05:24,219 --> 00:05:32,650
between drivers we also decided to make

00:05:29,190 --> 00:05:34,629
because we really like to test our API s

00:05:32,650 --> 00:05:37,779
because they are complex it's videos

00:05:34,629 --> 00:05:39,550
always complex so being able to test

00:05:37,779 --> 00:05:42,849
that without having actual hardware

00:05:39,550 --> 00:05:49,029
would be very nice so if I codec driver

00:05:42,849 --> 00:05:52,479
was written and it allows us to do the

00:05:49,029 --> 00:05:54,460
prototyping so it supports stateful at

00:05:52,479 --> 00:05:56,469
the stage for codecs it's actually has

00:05:54,460 --> 00:05:58,770
its own codec it was developed by

00:05:56,469 --> 00:06:05,289
someone as a university project

00:05:58,770 --> 00:06:07,569
guaranteed IP free by the way and we are

00:06:05,289 --> 00:06:09,789
using the compliance utility in order to

00:06:07,569 --> 00:06:12,370
test this and that's working very well

00:06:09,789 --> 00:06:16,089
we're using it in in daily regression

00:06:12,370 --> 00:06:17,500
tests the other class of codecs and

00:06:16,089 --> 00:06:19,599
that's the main topic are stateless

00:06:17,500 --> 00:06:21,969
codecs so basically these are hardware

00:06:19,599 --> 00:06:24,339
designers that are too lazy and they

00:06:21,969 --> 00:06:25,839
just do compressing parts and everything

00:06:24,339 --> 00:06:29,020
else all the parsing and getting the

00:06:25,839 --> 00:06:33,430
metadata is it's farmed out to use the

00:06:29,020 --> 00:06:36,089
space these have been around for several

00:06:33,430 --> 00:06:36,089
years and

00:06:36,600 --> 00:06:42,330
the thing is that you require as an API

00:06:39,810 --> 00:06:45,330
to be able to send both the compressed

00:06:42,330 --> 00:06:48,990
frame plus all the metadata to the

00:06:45,330 --> 00:06:54,600
hardware and for deaths we used to have

00:06:48,990 --> 00:07:00,570
I developed I'm one page too early

00:06:54,600 --> 00:07:02,040
already so this just required a new API

00:07:00,570 --> 00:07:06,600
and I will come to that in the next

00:07:02,040 --> 00:07:09,090
slide for stateless decoders we now have

00:07:06,600 --> 00:07:11,550
several in MA in the kernel we don't

00:07:09,090 --> 00:07:17,700
have stateless encoders yet but we will

00:07:11,550 --> 00:07:19,710
they will appear the detailed

00:07:17,700 --> 00:07:21,870
specification again we really need to

00:07:19,710 --> 00:07:24,060
detail this dispatch specified is very

00:07:21,870 --> 00:07:25,410
clearly how you do seeks and dynamic

00:07:24,060 --> 00:07:27,420
resolution changes and all these things

00:07:25,410 --> 00:07:30,360
that's been merged for stateless

00:07:27,420 --> 00:07:32,340
decoders and will appear in five five

00:07:30,360 --> 00:07:38,400
again google has done a lot of work on

00:07:32,340 --> 00:07:42,150
that it's very very nice as part of the

00:07:38,400 --> 00:07:45,900
outreach projects Daphna ish felts and I

00:07:42,150 --> 00:07:48,000
saw her in the public there she is she

00:07:45,900 --> 00:07:59,310
did the work of adding stateless decoder

00:07:48,000 --> 00:08:02,340
supports to the feature codec driver and

00:07:59,310 --> 00:08:03,990
vivre to CTL utility can support it and

00:08:02,340 --> 00:08:07,970
we don't have compliance tests for

00:08:03,990 --> 00:08:10,560
deaths yes unfortunately there is also a

00:08:07,970 --> 00:08:12,300
preliminary version for stateless and

00:08:10,560 --> 00:08:14,310
coda supports but that's not merged yet

00:08:12,300 --> 00:08:21,420
because we know we haven't agreed on the

00:08:14,310 --> 00:08:25,020
API for that so since we need to do per

00:08:21,420 --> 00:08:26,900
frame configuration this requires a new

00:08:25,020 --> 00:08:31,560
framework which is called request API

00:08:26,900 --> 00:08:33,990
and we currently have two drivers merged

00:08:31,560 --> 00:08:36,780
one is ceteris for the Allwinner SOC s

00:08:33,990 --> 00:08:38,370
and one is a hum troll that is IP used

00:08:36,780 --> 00:08:42,599
in rock chip

00:08:38,370 --> 00:08:44,430
I am x8 I believe it's actually used in

00:08:42,599 --> 00:08:47,679
some Allwinner versions as well I'm not

00:08:44,430 --> 00:08:49,839
entirely sure but I heard that

00:08:47,679 --> 00:08:53,559
currently supported codecs and back to

00:08:49,839 --> 00:08:57,490
h.264 HEV C merge last week so this is

00:08:53,559 --> 00:08:59,769
brand spanking new and VPS I know vp9 is

00:08:57,490 --> 00:09:07,420
in the works but I haven't seen patches

00:08:59,769 --> 00:09:09,279
yet all of this is in staging I want to

00:09:07,420 --> 00:09:12,069
keep it in staging until we also have

00:09:09,279 --> 00:09:13,809
stateless encoders so we assure that we

00:09:12,069 --> 00:09:17,290
didn't miss anything when we wrote the

00:09:13,809 --> 00:09:18,699
api's we also want to mature have it

00:09:17,290 --> 00:09:20,559
matured a little bit that we didn't

00:09:18,699 --> 00:09:24,369
forget anything that you actually need

00:09:20,559 --> 00:09:26,769
in order to to decode complex h.264

00:09:24,369 --> 00:09:28,480
streams for example so it's but I'm

00:09:26,769 --> 00:09:33,029
hopeful that it will be moved to

00:09:28,480 --> 00:09:42,910
mainline let's say first half next year

00:09:33,029 --> 00:09:46,300
be careful about that the request API so

00:09:42,910 --> 00:09:47,889
that is actually it was basically the

00:09:46,300 --> 00:09:50,290
biggest holdout it was the base main

00:09:47,889 --> 00:09:54,850
reason why it took so long to be able to

00:09:50,290 --> 00:09:59,410
do stateless codec support you need to

00:09:54,850 --> 00:10:03,639
supply both state information and a

00:09:59,410 --> 00:10:06,429
compress frame to the hardware a long

00:10:03,639 --> 00:10:08,649
time ago when Google start of Chrome OS

00:10:06,429 --> 00:10:10,689
started to use stateless decoders they

00:10:08,649 --> 00:10:12,549
had exactly the same issues and at a

00:10:10,689 --> 00:10:18,369
time I wrote an API called the

00:10:12,549 --> 00:10:21,100
configuration store API that used the

00:10:18,369 --> 00:10:23,589
control framework it originally it was

00:10:21,100 --> 00:10:25,480
designed to to set up controls like

00:10:23,589 --> 00:10:27,689
brightness and contrast but it's evolved

00:10:25,480 --> 00:10:32,170
quite a bit is much more powerful now

00:10:27,689 --> 00:10:34,540
and use a control framework to associate

00:10:32,170 --> 00:10:37,709
controls with a frame so you could

00:10:34,540 --> 00:10:40,329
actually do this per frame configuration

00:10:37,709 --> 00:10:42,240
and it turns out that Chrome OS have

00:10:40,329 --> 00:10:44,559
been using this for quite a few years

00:10:42,240 --> 00:10:46,389
but it was blocked for mainline

00:10:44,559 --> 00:10:50,019
inclusion because it simply was too

00:10:46,389 --> 00:10:53,399
specific for that one use case and the

00:10:50,019 --> 00:10:53,399
intention was to make it more generic

00:10:53,610 --> 00:11:01,259
after several attempts and frankly

00:10:57,370 --> 00:11:01,259
that's a presentation in itself

00:11:01,520 --> 00:11:07,920
lots of things went wrong so it took a

00:11:05,340 --> 00:11:09,990
really long time before we finally had

00:11:07,920 --> 00:11:11,850
to request API that was generic enough

00:11:09,990 --> 00:11:13,290
it will still need some more work for

00:11:11,850 --> 00:11:18,390
the more advanced use cases but for

00:11:13,290 --> 00:11:20,670
codec support is now perfectly fine so

00:11:18,390 --> 00:11:23,250
the basic idea is you create this is not

00:11:20,670 --> 00:11:26,250
we stole that from Android so you have a

00:11:23,250 --> 00:11:28,350
request objects you associate your

00:11:26,250 --> 00:11:31,770
buffer with it you associate a metadata

00:11:28,350 --> 00:11:33,870
with it then you queue it to the

00:11:31,770 --> 00:11:37,410
hardware to the driver so you have this

00:11:33,870 --> 00:11:39,600
sort of opaque objects caps internally

00:11:37,410 --> 00:11:41,460
with all the information and the

00:11:39,600 --> 00:11:45,920
hardware can enter at the driver Danny

00:11:41,460 --> 00:11:45,920
interprets it and programs the hardware

00:11:48,200 --> 00:11:53,340
so as I said currently it is only used

00:11:51,210 --> 00:11:58,470
by codecs but we want to use it for

00:11:53,340 --> 00:12:01,020
complex camera pipelines as well the API

00:11:58,470 --> 00:12:03,150
will needs changes or improvements for

00:12:01,020 --> 00:12:05,010
death because it's not internal

00:12:03,150 --> 00:12:06,600
framework is not powerful enough to do

00:12:05,010 --> 00:12:09,510
everything that we want to do there I

00:12:06,600 --> 00:12:12,450
have there's no ETA I have no idea when

00:12:09,510 --> 00:12:18,330
that will happen or how but that's been

00:12:12,450 --> 00:12:22,080
the intention so stateless encoders so

00:12:18,330 --> 00:12:24,570
for the state information that is all

00:12:22,080 --> 00:12:26,370
set to controls except that when you set

00:12:24,570 --> 00:12:29,550
a control it is actually set in the

00:12:26,370 --> 00:12:36,030
request objects and not directly in the

00:12:29,550 --> 00:12:41,190
hardware basically all the metadata that

00:12:36,030 --> 00:12:43,560
is specified by codec standards is made

00:12:41,190 --> 00:12:50,840
available as a control it's effectively

00:12:43,560 --> 00:12:53,190
a struct that you store in memory and

00:12:50,840 --> 00:12:56,040
since this is all standardized so all

00:12:53,190 --> 00:12:58,560
the information all the information in

00:12:56,040 --> 00:13:01,050
these trucks are completely specific to

00:12:58,560 --> 00:13:03,870
a codec there is no hardware specifics

00:13:01,050 --> 00:13:05,010
in there it's just you will actually see

00:13:03,870 --> 00:13:06,540
in the hardest you will see the

00:13:05,010 --> 00:13:10,060
references to the sections in the

00:13:06,540 --> 00:13:13,390
standards that they implement

00:13:10,060 --> 00:13:15,580
this would allow you to have so

00:13:13,390 --> 00:13:17,140
different hardware implementing the same

00:13:15,580 --> 00:13:19,480
codec would still use the same API

00:13:17,140 --> 00:13:22,810
because it's really completely defined

00:13:19,480 --> 00:13:25,420
by the code extenders and not by the

00:13:22,810 --> 00:13:29,710
hardware it has to be like that because

00:13:25,420 --> 00:13:33,520
a codec the decoding part of a codec is

00:13:29,710 --> 00:13:35,380
fixed because otherwise different

00:13:33,520 --> 00:13:39,220
hardware I would decode a stream

00:13:35,380 --> 00:13:41,290
differently that's not what you want the

00:13:39,220 --> 00:13:44,980
encoding part gives a lot more leeway to

00:13:41,290 --> 00:13:47,200
Hardware implementers to do fancy stuff

00:13:44,980 --> 00:13:52,030
as long as it can be decoded in a

00:13:47,200 --> 00:13:54,430
standard way but for the decoder we do

00:13:52,030 --> 00:13:58,440
not really expect to see Hardware

00:13:54,430 --> 00:14:01,210
specific controls there it should all be

00:13:58,440 --> 00:14:02,560
just specific to a codec - codec

00:14:01,210 --> 00:14:06,010
standard so that's very important for

00:14:02,560 --> 00:14:09,120
the Oh API otherwise it would be a

00:14:06,010 --> 00:14:09,120
nightmare to implement

00:14:14,190 --> 00:14:20,709
so we have two devices one is a video

00:14:17,260 --> 00:14:23,380
note traditional through which the q and

00:14:20,709 --> 00:14:25,390
e cayuga buffers the other is a media

00:14:23,380 --> 00:14:27,580
device and that's the one that creates

00:14:25,390 --> 00:14:31,120
the request objects it's it's you could

00:14:27,580 --> 00:14:33,910
see it as a global device that is not

00:14:31,120 --> 00:14:39,760
specific to to an input an output or a

00:14:33,910 --> 00:14:42,720
capture cue it's just just a device that

00:14:39,760 --> 00:14:46,570
allows you to create and request objects

00:14:42,720 --> 00:14:51,630
use that to set values there and then

00:14:46,570 --> 00:14:51,630
view it you commit it to to the driver

00:14:54,540 --> 00:14:59,529
so one one result of for stateless

00:14:57,459 --> 00:15:03,520
codecs is that user space has to parse

00:14:59,529 --> 00:15:05,620
the byte stream that for a state full

00:15:03,520 --> 00:15:07,029
codec you can just give it the byte

00:15:05,620 --> 00:15:10,270
severe you need to parse it you need to

00:15:07,029 --> 00:15:16,240
extract all the metadata you need to

00:15:10,270 --> 00:15:18,220
extract the compress frame and it has to

00:15:16,240 --> 00:15:20,079
be done a used space it's really really

00:15:18,220 --> 00:15:21,790
bad idea to try to do this in kernel

00:15:20,079 --> 00:15:23,260
space because if there's one thing that

00:15:21,790 --> 00:15:26,079
you get the sparse in byte streams

00:15:23,260 --> 00:15:26,950
that's before all flows you don't want

00:15:26,079 --> 00:15:31,510
that in the kernel

00:15:26,950 --> 00:15:34,420
in addition parsing a byte stream is

00:15:31,510 --> 00:15:36,370
actually hard particularly if you do

00:15:34,420 --> 00:15:39,750
something like video conferencing where

00:15:36,370 --> 00:15:42,310
you may have packet loss so how do you

00:15:39,750 --> 00:15:44,560
what do you do if information is missing

00:15:42,310 --> 00:15:47,680
how do you fill that in and that is a

00:15:44,560 --> 00:15:49,810
lot of the selling points of different

00:15:47,680 --> 00:15:51,880
companies how well while and products

00:15:49,810 --> 00:15:53,920
how well do they handle that so you

00:15:51,880 --> 00:15:55,540
don't want it in the kernel you want to

00:15:53,920 --> 00:15:58,329
customize that you want to do your own

00:15:55,540 --> 00:16:02,640
fancy magic sauce in order to make this

00:15:58,329 --> 00:16:05,800
work so that's why this all has to be in

00:16:02,640 --> 00:16:08,950
user space actually this is why a lot of

00:16:05,800 --> 00:16:11,709
people working on decoder software

00:16:08,950 --> 00:16:13,899
really prefer stateless codecs because

00:16:11,709 --> 00:16:15,730
they can do the parsing themselves they

00:16:13,899 --> 00:16:18,579
can do all the magic stuff to fill in

00:16:15,730 --> 00:16:19,899
missing pieces instead of leaving it to

00:16:18,579 --> 00:16:21,959
hardware and you don't know what it's

00:16:19,899 --> 00:16:21,959
doing

00:16:22,400 --> 00:16:28,880
so that's the code that you use is just

00:16:27,080 --> 00:16:31,640
a single I also for the media device

00:16:28,880 --> 00:16:35,630
there you allocate request objects so

00:16:31,640 --> 00:16:37,460
typically if you have you need to

00:16:35,630 --> 00:16:43,760
allocate 10 buffers you typically will

00:16:37,460 --> 00:16:46,570
create one objects per buffer so this is

00:16:43,760 --> 00:16:48,529
a little bit of a reminder because what

00:16:46,570 --> 00:16:50,960
what is now happening if you're a

00:16:48,529 --> 00:16:53,570
stateless codec a stateful codec it just

00:16:50,960 --> 00:16:55,760
kept track of all the iframes and P

00:16:53,570 --> 00:16:57,550
frames internally it you don't need to

00:16:55,760 --> 00:17:00,670
do anything it's all magically happening

00:16:57,550 --> 00:17:05,390
for stateless codec you actually need to

00:17:00,670 --> 00:17:07,730
provide that information so a P frame

00:17:05,390 --> 00:17:09,949
depends on an iframe which you need to

00:17:07,730 --> 00:17:13,400
tell it which one it is so you actually

00:17:09,949 --> 00:17:15,079
also need to keep the buffer around so

00:17:13,400 --> 00:17:17,179
the iframe is decoded in a buffer and

00:17:15,079 --> 00:17:20,120
you need to actually give it a reference

00:17:17,179 --> 00:17:25,459
to that buffer when you decode the p

00:17:20,120 --> 00:17:27,559
frame what you also need to do since B

00:17:25,459 --> 00:17:30,140
frames depends on both an eye and a p

00:17:27,559 --> 00:17:30,770
frame you actually cue the buffers in a

00:17:30,140 --> 00:17:32,480
different order

00:17:30,770 --> 00:17:35,270
you refers to the iframe and then the p

00:17:32,480 --> 00:17:37,970
frame and then the B frames because when

00:17:35,270 --> 00:17:39,920
you decode it when you decode to be

00:17:37,970 --> 00:17:42,850
frame it needs to have references to the

00:17:39,920 --> 00:17:46,700
decoded I and P frame so you're actually

00:17:42,850 --> 00:17:50,140
reorganizing the the buffers how the

00:17:46,700 --> 00:17:50,140
buffers are being processed

00:17:59,600 --> 00:18:06,570
so how do you do this you have an output

00:18:03,540 --> 00:18:09,450
buffer so the by the way point of view

00:18:06,570 --> 00:18:11,130
and video of Linux is user space so when

00:18:09,450 --> 00:18:12,990
you send something to Hardware that's an

00:18:11,130 --> 00:18:14,550
output buffer you go out and when you

00:18:12,990 --> 00:18:17,430
receive something back from hardware

00:18:14,550 --> 00:18:19,170
let's capture buffer you just have to

00:18:17,430 --> 00:18:20,820
know this it's a point of view these

00:18:19,170 --> 00:18:25,440
days we would probably call it sink or

00:18:20,820 --> 00:18:29,130
source or whatever so first of all you

00:18:25,440 --> 00:18:30,840
see that you set a request FD that means

00:18:29,130 --> 00:18:32,700
that this buffer will not be queued

00:18:30,840 --> 00:18:38,340
directly to the art where it will be

00:18:32,700 --> 00:18:41,309
queued to a request object you also set

00:18:38,340 --> 00:18:43,170
a time stamp and actually for codex it's

00:18:41,309 --> 00:18:45,450
not a time stamp it's really interpreted

00:18:43,170 --> 00:18:48,929
as a tag it's a unique identifier of

00:18:45,450 --> 00:18:53,280
that buffer and exactly what will be

00:18:48,929 --> 00:18:54,750
used to identify that buffer for a be

00:18:53,280 --> 00:19:00,690
friends and B frame so I thought they

00:18:54,750 --> 00:19:02,910
can refer to it then there is a magic

00:19:00,690 --> 00:19:06,780
function that takes a time Val and

00:19:02,910 --> 00:19:09,800
returns it to as as nanoseconds because

00:19:06,780 --> 00:19:12,929
all the references are 64-bit numbers

00:19:09,800 --> 00:19:15,179
unfortunately the current API uses a

00:19:12,929 --> 00:19:20,040
time time Val

00:19:15,179 --> 00:19:22,320
structure so this this is a unique way

00:19:20,040 --> 00:19:24,150
of converting the timestamp to a 64-bit

00:19:22,320 --> 00:19:28,530
number that you can then later use as

00:19:24,150 --> 00:19:30,300
the reference it's it awkward's and we

00:19:28,530 --> 00:19:34,559
hope to fix it in the future but for now

00:19:30,300 --> 00:19:36,929
this is the way it has to work so this

00:19:34,559 --> 00:19:39,059
is you don't need to know this in detail

00:19:36,929 --> 00:19:41,429
but the important bits is this is these

00:19:39,059 --> 00:19:45,600
are the structures the controls for the

00:19:41,429 --> 00:19:47,850
impact encoder you can see that so this

00:19:45,600 --> 00:19:50,429
is the sequence header it has a

00:19:47,850 --> 00:19:51,929
reference to the standard where you find

00:19:50,429 --> 00:19:53,910
all the details in the meaning of the

00:19:51,929 --> 00:19:57,750
fields so this is basically just a

00:19:53,910 --> 00:20:00,450
reflection of the standard same for the

00:19:57,750 --> 00:20:03,559
picture header again complete reference

00:20:00,450 --> 00:20:03,559
to where this is defined

00:20:03,830 --> 00:20:14,070
that way here is that here's the actual

00:20:10,020 --> 00:20:17,640
control slice param and this this one

00:20:14,070 --> 00:20:19,860
has two reference time stamps so use 64

00:20:17,640 --> 00:20:21,420
so you would fill these in for Abby

00:20:19,860 --> 00:20:23,460
frame you would fill them in both for

00:20:21,420 --> 00:20:25,380
the P frame you would fill in one for

00:20:23,460 --> 00:20:30,030
iframe they are ignored because it's not

00:20:25,380 --> 00:20:33,270
depending on anything and then this is

00:20:30,030 --> 00:20:35,370
the control ID where you pass in this

00:20:33,270 --> 00:20:39,900
structure and which contains the

00:20:35,370 --> 00:20:42,390
sequence and picture other structures so

00:20:39,900 --> 00:20:49,230
a control really contains just to make

00:20:42,390 --> 00:20:51,390
the data associated with decoding and is

00:20:49,230 --> 00:20:54,030
this is a requirement so you cannot

00:20:51,390 --> 00:20:55,710
change this because if you do that if

00:20:54,030 --> 00:20:58,560
you make it Hardware specific then it's

00:20:55,710 --> 00:21:00,500
no longer a generic API and that defeats

00:20:58,560 --> 00:21:02,790
the whole purpose

00:21:00,500 --> 00:21:05,370
so these control definitions are

00:21:02,790 --> 00:21:08,100
currently not public so their internal

00:21:05,370 --> 00:21:10,640
kernel internal headers because they

00:21:08,100 --> 00:21:10,640
will change

00:21:11,600 --> 00:21:19,560
mpeg-2 vp8 seems pretty okay but for a

00:21:15,390 --> 00:21:23,580
c64 and very new HEV see we still see

00:21:19,560 --> 00:21:26,130
some changes and you know the the little

00:21:23,580 --> 00:21:33,210
nitty gritty stuff is being defines that

00:21:26,130 --> 00:21:34,950
we forgot so an application will parse

00:21:33,210 --> 00:21:40,800
the headers from the byte stream fill in

00:21:34,950 --> 00:21:43,680
fill this in and then set a control and

00:21:40,800 --> 00:21:45,860
it would do it like this what's the best

00:21:43,680 --> 00:21:45,860
size

00:21:48,600 --> 00:21:55,710
so this is the structure itself for the

00:21:51,269 --> 00:21:57,840
control you fill in the parameters in

00:21:55,710 --> 00:21:59,960
this case you this is the P frame so you

00:21:57,840 --> 00:22:03,509
fill in the backward reference as well

00:21:59,960 --> 00:22:05,820
that you got from when you pute the

00:22:03,509 --> 00:22:08,210
iframe so when you queue the iframe you

00:22:05,820 --> 00:22:12,210
set as you show you I set a timestamp

00:22:08,210 --> 00:22:14,159
that defines the reference ID Ruffus tag

00:22:12,210 --> 00:22:19,500
for that buffer and you would use that

00:22:14,159 --> 00:22:23,220
here to refer to that iframe boilerplate

00:22:19,500 --> 00:22:26,250
code again you set the requests file

00:22:23,220 --> 00:22:28,289
descriptor this means that this control

00:22:26,250 --> 00:22:32,190
isn't sent directly in hardware it goes

00:22:28,289 --> 00:22:35,929
to the request object first and then you

00:22:32,190 --> 00:22:35,929
actually set the control

00:22:38,529 --> 00:22:43,149
rust is relatively easy you cue the

00:22:41,230 --> 00:22:57,129
capture buffer that will receive the

00:22:43,149 --> 00:23:01,179
result you cue the request objects yes

00:22:57,129 --> 00:23:03,519
and once the request object is cutes now

00:23:01,179 --> 00:23:05,470
the driver has both the output buffer

00:23:03,519 --> 00:23:07,690
associated with the request it has the

00:23:05,470 --> 00:23:09,460
metadata associated with the request it

00:23:07,690 --> 00:23:12,100
has a capture buffer that it can send

00:23:09,460 --> 00:23:17,679
result to so now it can do its decoding

00:23:12,100 --> 00:23:19,929
step when it's done the request objects

00:23:17,679 --> 00:23:23,159
gets a signal it's it will send an event

00:23:19,929 --> 00:23:26,799
to use the space saying hey I'm done and

00:23:23,159 --> 00:23:28,509
if the driver would return additional

00:23:26,799 --> 00:23:30,580
information it's not the case here but

00:23:28,509 --> 00:23:35,110
it might happen so it can give you

00:23:30,580 --> 00:23:37,990
results information or for example if

00:23:35,110 --> 00:23:39,850
you have would have a sense or it's in a

00:23:37,990 --> 00:23:42,940
more complicated camera pipeline it

00:23:39,850 --> 00:23:45,009
could return statistics information so

00:23:42,940 --> 00:23:49,360
you could extract that from the request

00:23:45,009 --> 00:23:50,980
objects before destroying it in this

00:23:49,360 --> 00:23:52,419
case you don't need it you just have to

00:23:50,980 --> 00:23:53,320
wait until the request is done because

00:23:52,419 --> 00:23:59,289
then you know okay

00:23:53,320 --> 00:24:00,879
the frame is decoded final step you DQ

00:23:59,289 --> 00:24:02,669
both the outputs and capture buffer

00:24:00,879 --> 00:24:05,409
you're done with it

00:24:02,669 --> 00:24:07,720
now when you leak DQ it's then the

00:24:05,409 --> 00:24:09,519
capture buffer timestamp will be the

00:24:07,720 --> 00:24:12,100
same as the output buffer stamp stamp

00:24:09,519 --> 00:24:15,159
because it's copied it's copied over so

00:24:12,100 --> 00:24:17,049
when it when you decode an output buffer

00:24:15,159 --> 00:24:20,830
the timestamp is copied to the capture

00:24:17,049 --> 00:24:23,110
buffer let's done because you need to

00:24:20,830 --> 00:24:25,029
refer to that output to that capture

00:24:23,110 --> 00:24:28,539
buffer because that contains the decoded

00:24:25,029 --> 00:24:31,049
iframe so when you cue P frame it needs

00:24:28,539 --> 00:24:33,519
to refer to death buffer and that's all

00:24:31,049 --> 00:24:35,559
the administration is all done

00:24:33,519 --> 00:24:37,720
internally in the kernel so you don't

00:24:35,559 --> 00:24:39,940
have to worry about that but you have to

00:24:37,720 --> 00:24:42,159
really understand how these these tag

00:24:39,940 --> 00:24:45,250
values are copied from one from an

00:24:42,159 --> 00:24:48,179
output buffer to capture buffer and then

00:24:45,250 --> 00:24:48,179
you can refer to it

00:24:50,800 --> 00:25:00,020
so I would at work you pew a knife

00:24:56,810 --> 00:25:03,920
decode iframe you give a tag one so TV

00:25:00,020 --> 00:25:06,500
sex in a timestamp is set to one then

00:25:03,920 --> 00:25:08,960
you do a P frame you give it another tag

00:25:06,500 --> 00:25:12,020
to and you set the backward reference to

00:25:08,960 --> 00:25:14,600
one because that's to decode it that

00:25:12,020 --> 00:25:17,080
will refer to the decoded frame of the

00:25:14,600 --> 00:25:21,200
iframe decode the buffer of the iframe

00:25:17,080 --> 00:25:23,360
then you do the B frames so there you

00:25:21,200 --> 00:25:25,430
will never refer to the B frame at least

00:25:23,360 --> 00:25:27,620
for this codec so you don't need to set

00:25:25,430 --> 00:25:29,570
attack but you need do need to set the

00:25:27,620 --> 00:25:33,050
backwards and forwards references of the

00:25:29,570 --> 00:25:36,770
iframe and b4b frame so you keep doing

00:25:33,050 --> 00:25:39,260
that and that's the way this is working

00:25:36,770 --> 00:25:40,850
and the nice thing about is you can

00:25:39,260 --> 00:25:44,170
actually if you know the whole sequence

00:25:40,850 --> 00:25:46,520
you can actually start viewing buffers

00:25:44,170 --> 00:25:48,890
for the decode you don't have to wait

00:25:46,520 --> 00:25:50,930
every time until one frame is decoded

00:25:48,890 --> 00:25:52,970
and then send the next one and you can

00:25:50,930 --> 00:25:55,810
actually do it in advance as long as you

00:25:52,970 --> 00:25:55,810
keep track of all attacks

00:26:05,840 --> 00:26:12,920
very recently last week we added one

00:26:08,840 --> 00:26:16,400
missing bit that slicing support so what

00:26:12,920 --> 00:26:18,740
happens is with h.264 and HTV see you

00:26:16,400 --> 00:26:20,750
can actually deal with slices instead of

00:26:18,740 --> 00:26:26,000
food frames so just horizontal strips

00:26:20,750 --> 00:26:27,950
basically which improves latency you cue

00:26:26,000 --> 00:26:32,030
the slices and you want to collect them

00:26:27,950 --> 00:26:34,220
all in the same output buffer result of

00:26:32,030 --> 00:26:36,800
that is that you you cannot return this

00:26:34,220 --> 00:26:38,390
output buffer after one slice is decoded

00:26:36,800 --> 00:26:42,100
you have to wait until they are all done

00:26:38,390 --> 00:26:44,780
before you can return it to this space

00:26:42,100 --> 00:26:49,100
so basically you need to hold on to that

00:26:44,780 --> 00:26:51,110
output buffer to very annoying you have

00:26:49,100 --> 00:26:54,950
to hold on to that capture buffer until

00:26:51,110 --> 00:26:57,580
it's completely full and you set a

00:26:54,950 --> 00:26:57,580
special flag

00:27:09,570 --> 00:27:15,119
yeah so you set above the flag basically

00:27:13,889 --> 00:27:18,359
saying hold on to the capture buffer

00:27:15,119 --> 00:27:19,859
don't return it yet when the system

00:27:18,359 --> 00:27:21,570
detects that the new frame starts it

00:27:19,859 --> 00:27:24,090
will automatically return the capture

00:27:21,570 --> 00:27:26,399
buffer but you have a corner case when

00:27:24,090 --> 00:27:28,889
you stop streaming you may end up with

00:27:26,399 --> 00:27:31,769
one capture buffer still left being hold

00:27:28,889 --> 00:27:33,929
on so you need to flush it in that case

00:27:31,769 --> 00:27:37,679
to say okay I'm completely done return

00:27:33,929 --> 00:27:42,720
it so this is new support it was just

00:27:37,679 --> 00:27:47,009
added and it's really the final missing

00:27:42,720 --> 00:27:51,690
bits for h.264 and htpc decoders that we

00:27:47,009 --> 00:27:53,909
really needed so that's about half an

00:27:51,690 --> 00:27:57,809
hour talk about codecs and we really did

00:27:53,909 --> 00:27:59,580
a lot of work in that area but the other

00:27:57,809 --> 00:28:02,099
bit that we did a lot of work on is

00:27:59,580 --> 00:28:04,139
testing and especially using the virtual

00:28:02,099 --> 00:28:08,159
drivers that we have which emulate

00:28:04,139 --> 00:28:12,239
hardware that has seen a lot of work a

00:28:08,159 --> 00:28:15,090
lot of improvements so the main one is

00:28:12,239 --> 00:28:18,749
vivid which emulates webcams

00:28:15,090 --> 00:28:22,590
HDMI receivers a vertical blanking

00:28:18,749 --> 00:28:23,129
interface very recently metadata support

00:28:22,590 --> 00:28:25,229
was added

00:28:23,129 --> 00:28:27,859
so again histogram information for

00:28:25,229 --> 00:28:31,529
example that can be returned in metadata

00:28:27,859 --> 00:28:34,169
and that was done by Vandana as part of

00:28:31,529 --> 00:28:35,849
Linux kernel mentorship program so kudos

00:28:34,169 --> 00:28:37,909
to Hertz he's still working on it so

00:28:35,849 --> 00:28:41,669
hopefully we will get support for

00:28:37,909 --> 00:28:46,559
touchpads which basically to return an

00:28:41,669 --> 00:28:48,539
image of the pressure points and

00:28:46,559 --> 00:28:50,190
software-defined radio transmitter

00:28:48,539 --> 00:28:54,210
that's one that's been missing for a

00:28:50,190 --> 00:28:56,580
long time hopefully hopefully she can

00:28:54,210 --> 00:28:58,080
finish it before the mentorship ends but

00:28:56,580 --> 00:29:00,299
she's already done great work getting

00:28:58,080 --> 00:29:02,159
the metadata support in and we find by

00:29:00,299 --> 00:29:04,320
doing this we actually find corner cases

00:29:02,159 --> 00:29:09,389
in our API that we didn't think about

00:29:04,320 --> 00:29:11,429
before VI m2m that's a memory to memory

00:29:09,389 --> 00:29:16,139
processing device like at the inter

00:29:11,429 --> 00:29:19,399
laser or a convertor VI MC a complex

00:29:16,139 --> 00:29:22,169
memory camera complex camera pipeline

00:29:19,399 --> 00:29:22,830
it's seeing a lot of work that is also

00:29:22,169 --> 00:29:25,380
part

00:29:22,830 --> 00:29:28,230
Helen's work at the university of sao

00:29:25,380 --> 00:29:34,440
paulo with volunteers who are looking

00:29:28,230 --> 00:29:36,809
into into this drive to improve it and

00:29:34,440 --> 00:29:38,659
of course the vy codec the virtual codec

00:29:36,809 --> 00:29:41,549
in the driver

00:29:38,659 --> 00:29:44,120
it currently implements stateful encoder

00:29:41,549 --> 00:29:46,769
stateful decoder and stateless decoder

00:29:44,120 --> 00:29:48,419
fetches for a stateless encoder are

00:29:46,769 --> 00:29:50,970
there because as I said the API isn't

00:29:48,419 --> 00:29:55,409
finalized there so we be holding on to

00:29:50,970 --> 00:29:57,539
that only mover we do a lot of testing

00:29:55,409 --> 00:30:01,320
they are part of our own daily

00:29:57,539 --> 00:30:03,510
regression testing as a test media

00:30:01,320 --> 00:30:07,679
script that actually that I use a lot to

00:30:03,510 --> 00:30:09,750
just test test with all these virtual

00:30:07,679 --> 00:30:11,250
drivers and do all sort of nasty things

00:30:09,750 --> 00:30:13,769
like unloading them while you are

00:30:11,250 --> 00:30:16,260
streaming just making sure that the API

00:30:13,769 --> 00:30:20,549
that you didn't introduce a regression

00:30:16,260 --> 00:30:23,460
in a kernel I believe it's now also used

00:30:20,549 --> 00:30:25,320
in kernel CI a-- dot org i really need

00:30:23,460 --> 00:30:30,000
to talk to them to see what the current

00:30:25,320 --> 00:30:32,370
status is of data continually improving

00:30:30,000 --> 00:30:35,519
the compliance tests I could really use

00:30:32,370 --> 00:30:37,679
more support there have some more people

00:30:35,519 --> 00:30:39,720
working on those it's getting quite

00:30:37,679 --> 00:30:44,210
complicated what I would really like to

00:30:39,720 --> 00:30:47,580
have is a parser of h.264 codec similar

00:30:44,210 --> 00:30:51,419
that just takes the byte stream parses

00:30:47,580 --> 00:30:53,519
it and puts it in controls and extracts

00:30:51,419 --> 00:30:55,380
the compressed frames so we can actually

00:30:53,519 --> 00:31:01,980
easily integrate it in the compliance

00:30:55,380 --> 00:31:04,320
test a lot of work on the documentation

00:31:01,980 --> 00:31:07,230
as I said already so the whole new API

00:31:04,320 --> 00:31:11,279
in the stateless decoder spec is all

00:31:07,230 --> 00:31:13,440
merged so that's very good work writing

00:31:11,279 --> 00:31:16,529
documentation is amazingly useful to

00:31:13,440 --> 00:31:18,600
find corner cases so you're writing it

00:31:16,529 --> 00:31:21,269
and then you're thinking ok but what if

00:31:18,600 --> 00:31:24,120
I want to stop streaming and there

00:31:21,269 --> 00:31:28,139
hasn't been any buffers acute what

00:31:24,120 --> 00:31:30,419
happens in that case and it's been

00:31:28,139 --> 00:31:31,260
extreme so that you have you I see it as

00:31:30,419 --> 00:31:33,779
a three

00:31:31,260 --> 00:31:35,360
you have the virtual drivers you have

00:31:33,779 --> 00:31:37,550
your documentation and you have

00:31:35,360 --> 00:31:40,610
compliance testing and you develop them

00:31:37,550 --> 00:31:43,250
all together and it really helps making

00:31:40,610 --> 00:31:46,550
a good quality API because you get to

00:31:43,250 --> 00:31:48,020
see that all your errors very early on

00:31:46,550 --> 00:31:50,320
because you really have to think about

00:31:48,020 --> 00:31:50,320
it

00:31:50,870 --> 00:31:56,960
sis port and Cisco are they have been

00:31:53,200 --> 00:31:59,420
finding way too many issues they are now

00:31:56,960 --> 00:32:02,470
also using the virtual drivers for

00:31:59,420 --> 00:32:02,470
testing so that's very useful

00:32:09,230 --> 00:32:16,290
resources so first of all you see

00:32:14,430 --> 00:32:23,220
specification itself you can find it

00:32:16,290 --> 00:32:27,990
there if you want to go into the

00:32:23,220 --> 00:32:32,190
documentation for the Codex then you get

00:32:27,990 --> 00:32:34,170
that link the propose stateful and code

00:32:32,190 --> 00:32:35,850
specification since that not yet that's

00:32:34,170 --> 00:32:38,850
not yet in mainline but you can see that

00:32:35,850 --> 00:32:41,250
there as well you have two extreme gets

00:32:38,850 --> 00:32:43,830
repository of our stuff it's a test

00:32:41,250 --> 00:32:49,140
utility for the setters decoder that can

00:32:43,830 --> 00:32:52,020
be useful all the utilities are found in

00:32:49,140 --> 00:32:56,270
the FIFO utils git repository mailing

00:32:52,020 --> 00:32:59,490
list and I want to emphasize this one

00:32:56,270 --> 00:33:02,040
we're keeping a list of open source

00:32:59,490 --> 00:33:04,200
projects for volunteers to look at and

00:33:02,040 --> 00:33:06,030
most of them relate to these virtual

00:33:04,200 --> 00:33:11,190
drivers to improve them to get new

00:33:06,030 --> 00:33:16,020
features in if you're interested contact

00:33:11,190 --> 00:33:17,670
us there's also much to do in this area

00:33:16,020 --> 00:33:19,440
especially in testing and improving

00:33:17,670 --> 00:33:22,440
these virtual drivers make them more

00:33:19,440 --> 00:33:24,270
realistic I'd love to get some more

00:33:22,440 --> 00:33:28,230
people involved and it's a great

00:33:24,270 --> 00:33:30,510
learning experience so I very much

00:33:28,230 --> 00:33:37,890
recommend it if you have time to look at

00:33:30,510 --> 00:33:40,080
this that's it for me questions oh one

00:33:37,890 --> 00:33:43,680
more thing I wanted to mention peak

00:33:40,080 --> 00:33:45,840
review into the future one of the big

00:33:43,680 --> 00:33:47,520
problems that we have at the moment if

00:33:45,840 --> 00:33:49,380
you are working with video of Linux is

00:33:47,520 --> 00:33:52,770
the distinction between single and multi

00:33:49,380 --> 00:33:54,810
planar formats so multiplanar means that

00:33:52,770 --> 00:34:00,180
chroma and luma are in different areas

00:33:54,810 --> 00:34:03,300
in memory and the whole streaming i/o is

00:34:00,180 --> 00:34:06,120
getting old and getting complex to use

00:34:03,300 --> 00:34:08,850
so we're looking into creating new I

00:34:06,120 --> 00:34:12,120
hope dos that do this much more

00:34:08,850 --> 00:34:14,130
efficiently and smarter so it's very

00:34:12,120 --> 00:34:16,409
early stages yet we have some RFC

00:34:14,130 --> 00:34:18,990
proposals but I think after the codecs

00:34:16,409 --> 00:34:20,700
this will be the next big developments

00:34:18,990 --> 00:34:22,889
that we are actively look

00:34:20,700 --> 00:34:26,520
because it's getting it's getting too

00:34:22,889 --> 00:34:28,950
complicated to program a user space so

00:34:26,520 --> 00:34:32,480
we want to make that a much smoother

00:34:28,950 --> 00:34:35,909
experience for people also the

00:34:32,480 --> 00:34:39,740
cooperation with DRM that we are a bit

00:34:35,909 --> 00:34:48,379
more aligned to what they are doing so

00:34:39,740 --> 00:34:48,379
little bit preview any questions

00:34:50,179 --> 00:34:55,399
everybody asleep oh yeah someone is

00:34:53,159 --> 00:34:55,399
awake

00:35:00,180 --> 00:35:03,980
is there any difference in performance

00:35:01,470 --> 00:35:05,490
between stateful and state glass

00:35:03,980 --> 00:35:10,460
decoders

00:35:05,490 --> 00:35:13,680
I think it's next to impossible to say I

00:35:10,460 --> 00:35:16,530
don't have any performance results but I

00:35:13,680 --> 00:35:19,380
think even as I suspect that most

00:35:16,530 --> 00:35:21,720
stateful encoders and decoders actually

00:35:19,380 --> 00:35:25,200
do this the parsing and everything in

00:35:21,720 --> 00:35:30,210
firmware so it completely depends on how

00:35:25,200 --> 00:35:31,920
that is implemented from what I

00:35:30,210 --> 00:35:33,750
understand from people who are actively

00:35:31,920 --> 00:35:35,339
working on the codes is they actually

00:35:33,750 --> 00:35:37,109
prefer the stateless version because

00:35:35,339 --> 00:35:38,910
then they can do you know what do you do

00:35:37,109 --> 00:35:41,940
when you're missing packets and how do

00:35:38,910 --> 00:35:43,890
you pre-process and parse the stream

00:35:41,940 --> 00:35:45,210
that is where they want to make a

00:35:43,890 --> 00:35:48,780
difference so they're actually very

00:35:45,210 --> 00:35:50,960
interesting interested in doing that

00:35:48,780 --> 00:35:50,960
themselves

00:36:18,230 --> 00:36:24,510
yeah so the question is so just the

00:36:22,050 --> 00:36:28,650
remark really is that a lot of these

00:36:24,510 --> 00:36:30,840
stateful codecs actually do this as I

00:36:28,650 --> 00:36:32,250
said this parsing themselves so ideally

00:36:30,840 --> 00:36:36,270
it would be great if we could just

00:36:32,250 --> 00:36:39,660
bypass the parsing step and use it as a

00:36:36,270 --> 00:36:48,800
stateless codec so go straight to the

00:36:39,660 --> 00:36:48,800
state am i right yeah

00:37:04,000 --> 00:37:11,890
okay so basically even if you have a

00:37:07,750 --> 00:37:14,610
stageful decoder and it does the parsing

00:37:11,890 --> 00:37:16,990
inside the firmware you still have

00:37:14,610 --> 00:37:19,270
parsing in the user space if you use

00:37:16,990 --> 00:37:21,790
these three mirror of ffmpeg because

00:37:19,270 --> 00:37:24,280
they use these parsed data for other

00:37:21,790 --> 00:37:26,860
things so if you use a stateless decoder

00:37:24,280 --> 00:37:29,200
you don't to the redundant parsing in

00:37:26,860 --> 00:37:30,940
the firmer just have the one in the user

00:37:29,200 --> 00:37:40,360
space you actually save them some time

00:37:30,940 --> 00:37:43,720
right yes so that's actually correct

00:37:40,360 --> 00:37:47,550
some of the parsing is being redundant

00:37:43,720 --> 00:37:50,620
and could be redundant multiple time

00:37:47,550 --> 00:37:53,230
though there are some bits that we have

00:37:50,620 --> 00:37:56,170
to parse to drive a stateless codec that

00:37:53,230 --> 00:37:59,680
we don't parse in this room are ffmpeg

00:37:56,170 --> 00:38:02,190
in order to decode well they called to

00:37:59,680 --> 00:38:02,190
hardware

00:38:08,710 --> 00:38:11,640
all the questions

00:38:16,380 --> 00:38:18,410
Oh

00:38:26,830 --> 00:38:31,990
with the stateless decoder is it

00:38:29,470 --> 00:38:35,140
possible to zero copy in the data or do

00:38:31,990 --> 00:38:37,270
you always need a copy in that path no

00:38:35,140 --> 00:38:43,150
there should be zero copied that's the

00:38:37,270 --> 00:38:45,610
intention is it because there is a well

00:38:43,150 --> 00:38:46,990
you need to fill so if you're you know

00:38:45,610 --> 00:38:49,480
you need to parse the byte stream of

00:38:46,990 --> 00:38:51,310
course that you receive so depth and you

00:38:49,480 --> 00:38:54,040
need to copy that into the buffer so

00:38:51,310 --> 00:38:56,110
that's that's you always have to so

00:38:54,040 --> 00:38:59,920
that's what I mean do you also need to

00:38:56,110 --> 00:39:08,890
parse the framed a tiny byte stream or

00:38:59,920 --> 00:39:11,530
just the headers you I'm not entirely

00:39:08,890 --> 00:39:13,390
sure if I'm the best person died yeah

00:39:11,530 --> 00:39:15,580
Nikolas knows a heck of a lot more about

00:39:13,390 --> 00:39:19,750
it it's a it's a it's a white question

00:39:15,580 --> 00:39:22,240
it's per codec as an example in h.264

00:39:19,750 --> 00:39:24,700
you have to parse up to the slice

00:39:22,240 --> 00:39:27,460
headers but the rest you don't have to

00:39:24,700 --> 00:39:29,260
parse for most of for the hardware we

00:39:27,460 --> 00:39:30,850
know right now that's why it's still

00:39:29,260 --> 00:39:37,390
unstable we're trying to get more

00:39:30,850 --> 00:39:39,700
hardware so the frame data itself is

00:39:37,390 --> 00:39:43,330
passed in as a pointer and not you don't

00:39:39,700 --> 00:39:46,570
have to copy it into a structure this is

00:39:43,330 --> 00:39:49,480
a guide but for this default zero copy

00:39:46,570 --> 00:39:51,610
support this is per driver there's some

00:39:49,480 --> 00:39:54,540
limitation with some type of allocation

00:39:51,610 --> 00:39:54,540
of memory and blah blah blah

00:39:59,180 --> 00:40:05,450
I did you give a overview of what the

00:40:02,770 --> 00:40:07,910
current state of light you stream and

00:40:05,450 --> 00:40:12,020
ffmpeg is was supporting the stateless

00:40:07,910 --> 00:40:15,380
decoders does that work it's probably

00:40:12,020 --> 00:40:18,140
Nicholas who knows at best I I do the

00:40:15,380 --> 00:40:19,940
kernel stuff right just provide

00:40:18,140 --> 00:40:22,070
infrastructure so that people like

00:40:19,940 --> 00:40:24,110
Nicholas can makes great parents work on

00:40:22,070 --> 00:40:26,720
it so don't give me any credit the

00:40:24,110 --> 00:40:29,300
entire support have been tested with a

00:40:26,720 --> 00:40:32,030
patch set on ffmpeg but it's not

00:40:29,300 --> 00:40:34,130
upstream yet because there's kind of a

00:40:32,030 --> 00:40:36,850
chicken and an egg issue of we're

00:40:34,130 --> 00:40:41,420
changing the API we're changing ffmpeg

00:40:36,850 --> 00:40:44,270
on GStreamer side we have a kind of by

00:40:41,420 --> 00:40:50,210
accident working prototype on the API

00:40:44,270 --> 00:40:51,650
driver we'll see what what futures and I

00:40:50,210 --> 00:40:54,230
won't just want to remind you that the

00:40:51,650 --> 00:40:56,960
API is still in staging right it it will

00:40:54,230 --> 00:40:59,020
change a little bit so this is there's a

00:40:56,960 --> 00:41:01,910
lot of work being done here also for

00:40:59,020 --> 00:41:03,890
Libre a Lac Cody as people are looking

00:41:01,910 --> 00:41:05,630
into this and there's a lot of they

00:41:03,890 --> 00:41:08,030
really want this but it is a little bit

00:41:05,630 --> 00:41:10,250
too early yet to make this a public API

00:41:08,030 --> 00:41:12,380
we're still finding little corner cases

00:41:10,250 --> 00:41:15,740
little things that we didn't realize

00:41:12,380 --> 00:41:18,200
need to be in the metadata as well so

00:41:15,740 --> 00:41:20,450
the the problems are not with the basic

00:41:18,200 --> 00:41:22,850
API there are with the controls

00:41:20,450 --> 00:41:24,650
containing the metadata that those have

00:41:22,850 --> 00:41:28,910
to be completely if you miss something

00:41:24,650 --> 00:41:30,500
there we like to have we like to be

00:41:28,910 --> 00:41:34,280
fairly confident that we didn't miss

00:41:30,500 --> 00:41:35,900
anything before making it public we're

00:41:34,280 --> 00:41:37,700
not going to be unreasonable so this is

00:41:35,900 --> 00:41:41,960
not something that will stay in staging

00:41:37,700 --> 00:41:43,640
for three years but let's say first half

00:41:41,960 --> 00:41:45,950
of next year as I said I really hope we

00:41:43,640 --> 00:41:48,160
can get the first ones out of staging

00:41:45,950 --> 00:41:50,630
and into my line I forgot to mention

00:41:48,160 --> 00:41:53,360
there's also support in chromium and

00:41:50,630 --> 00:41:55,400
there's a port to the new API because

00:41:53,360 --> 00:41:57,550
they had supported us for a few years

00:41:55,400 --> 00:41:57,550
already

00:41:58,420 --> 00:42:04,630
are you done with time I think we need

00:42:01,119 --> 00:42:10,260
to stop here thank you very much

00:42:04,630 --> 00:42:10,260

YouTube URL: https://www.youtube.com/watch?v=RUe7_Tx0vOI


