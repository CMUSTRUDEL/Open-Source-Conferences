Title: Supporting Hardware Codecs in a Linux system - Maxime Ripard, Bootlin
Publication date: 2018-10-25
Playlist: Open Source Summit Europe & ELC + OpenIoT Summit Europe 2018
Description: 
	Supporting Hardware Codecs in a Linux system - Maxime Ripard, Bootlin

Every modern multimedia-oriented ARM SoC usually has a hardware controller to decode and encode video streams. The Linux kernel framework of choice to support these controllers is the v4l2 subsystem.

This talk will walk through the changes that were needed to support our codec in the v4l2 stack, the challenges we faced during the driver development and, once the driver development done, the issues we faced
to make the hardware decoding useful to general-purpose video players like Kodi, gstreamer or VLC.

The presentation is based on the work we have done to develop a v4l2 driver for the Allwinner video encoder/decoder controller on top of a mainline kernel.

About Maxime Ripard
Maxime Ripard is an embedded Linux engineer and trainer at Bootlin since 2011. Maxime has pioneered the support for Allwinner SoCs in the official Linux kernel, and is the co-maintainer of this platform. He is the primary author of the DRM driver for the Allwinner display controller. He also occasionnally contributes to other projects such as U-Boot, Barebox or Buildroot.
Captions: 
	00:00:00,030 --> 00:00:07,740
hi everyone I'm Maxum ERCOT from boot

00:00:04,259 --> 00:00:11,219
lien and I've been working on on a video

00:00:07,740 --> 00:00:13,769
codec so to be able to do a video

00:00:11,219 --> 00:00:15,420
hard-coding on nor wiener platform so

00:00:13,769 --> 00:00:17,850
enormous you'll see and I'm going to

00:00:15,420 --> 00:00:20,310
talk a bit about how did we manage to

00:00:17,850 --> 00:00:22,890
make it work and how it's going to work

00:00:20,310 --> 00:00:25,250
in the next Channel releases because

00:00:22,890 --> 00:00:28,980
it's something that is brand new so

00:00:25,250 --> 00:00:30,840
first let me introduce myself so I've

00:00:28,980 --> 00:00:35,270
been an embedded engineer at boot lean

00:00:30,840 --> 00:00:37,260
for the last seven years and a half and

00:00:35,270 --> 00:00:40,140
basically we're doing a MIDI Linux

00:00:37,260 --> 00:00:43,350
development and embedded Linux training

00:00:40,140 --> 00:00:46,530
and I've been contributing a lot as part

00:00:43,350 --> 00:00:50,899
of this job so I'm the co maintainer of

00:00:46,530 --> 00:00:52,800
the old Wiener Assoc support in UNIX for

00:00:50,899 --> 00:00:56,370
exactly six years now

00:00:52,800 --> 00:01:01,140
we started working on it and ELC 2012 so

00:00:56,370 --> 00:01:03,600
it's awesome I've been for like a couple

00:01:01,140 --> 00:01:07,100
of weeks the common trainer of the DRM

00:01:03,600 --> 00:01:10,650
misc subsystem which is basically the

00:01:07,100 --> 00:01:13,260
subsystem responsible for the graphical

00:01:10,650 --> 00:01:15,659
stack in Linux and the missed out being

00:01:13,260 --> 00:01:19,740
basically everything that is not Nvidia

00:01:15,659 --> 00:01:21,960
Intel or AMD and I've been contributing

00:01:19,740 --> 00:01:24,540
to a lot of open source projects over

00:01:21,960 --> 00:01:30,150
the time so bill roots you boot bear box

00:01:24,540 --> 00:01:33,720
and so on so let's get started on video

00:01:30,150 --> 00:01:36,869
decoding so first we need to talk a bit

00:01:33,720 --> 00:01:40,049
about what an encoded an encoded video

00:01:36,869 --> 00:01:43,130
is and it's basically two things you

00:01:40,049 --> 00:01:46,710
usually will have so the file itself

00:01:43,130 --> 00:01:48,720
will not be the video itself it's first

00:01:46,710 --> 00:01:51,380
a container so the container will be

00:01:48,720 --> 00:01:55,740
basically the format that is used to

00:01:51,380 --> 00:01:58,469
organize within that file the video

00:01:55,740 --> 00:02:01,049
streams the audio streams and some other

00:01:58,469 --> 00:02:02,909
metadata for example subtitles and so on

00:02:01,049 --> 00:02:08,280
so it's basically how the files is laid

00:02:02,909 --> 00:02:10,319
out to store all the streams and data at

00:02:08,280 --> 00:02:11,250
all well basically what you can expect

00:02:10,319 --> 00:02:15,510
when you are playing this

00:02:11,250 --> 00:02:18,750
and then you have one on multiple codecs

00:02:15,510 --> 00:02:22,320
if you have video and audio which will

00:02:18,750 --> 00:02:26,130
encode the data that need to be stored

00:02:22,320 --> 00:02:29,370
in a compressed format that you can have

00:02:26,130 --> 00:02:32,820
a yeah decent fine size and not blow

00:02:29,370 --> 00:02:36,660
your hardest because you are you have

00:02:32,820 --> 00:02:38,520
like two or three video files so we are

00:02:36,660 --> 00:02:40,710
only going to talk a bit we are only

00:02:38,520 --> 00:02:42,120
going to talk about the codec itself we

00:02:40,710 --> 00:02:46,220
are not going to talk about containers

00:02:42,120 --> 00:02:48,390
because as far as video hardware

00:02:46,220 --> 00:02:51,390
accelerators are concerned the

00:02:48,390 --> 00:02:54,270
containers are really not important it's

00:02:51,390 --> 00:02:56,490
usually the video player or one of its

00:02:54,270 --> 00:03:00,060
libraries that will extract the video

00:02:56,490 --> 00:03:02,790
stream from the from the from the file

00:03:00,060 --> 00:03:07,130
and pass it to the decoder so yeah we're

00:03:02,790 --> 00:03:09,510
only going to talk about the codec and

00:03:07,130 --> 00:03:13,080
the codec basically relies on something

00:03:09,510 --> 00:03:14,820
that is called a bit stream and the

00:03:13,080 --> 00:03:17,250
Wikipedia definition for it isn't very

00:03:14,820 --> 00:03:19,170
helpful so the bit stream if you look at

00:03:17,250 --> 00:03:23,459
Wikipedia is basically a sequence of

00:03:19,170 --> 00:03:27,390
bits great but in the context of codecs

00:03:23,459 --> 00:03:30,540
it basically is compressed output of the

00:03:27,390 --> 00:03:34,980
encoder so it's going to be your encoded

00:03:30,540 --> 00:03:37,170
video data that is sitting on your hard

00:03:34,980 --> 00:03:41,549
disk when you have downloaded or encoded

00:03:37,170 --> 00:03:45,120
a video and it's mainly composed of

00:03:41,549 --> 00:03:48,120
three things so we are talking in

00:03:45,120 --> 00:03:51,390
general here some more advanced codecs

00:03:48,120 --> 00:03:53,250
have more things in the in the bit

00:03:51,390 --> 00:03:56,340
stream but basically you will always

00:03:53,250 --> 00:04:01,019
find a separator between frames so that

00:03:56,340 --> 00:04:05,549
you are able by just reading that stream

00:04:01,019 --> 00:04:08,580
of bits to tell which one frame starts

00:04:05,549 --> 00:04:10,830
and when frame stops then the metadata

00:04:08,580 --> 00:04:13,920
which are holding the compression

00:04:10,830 --> 00:04:16,560
parameters so for example one of these

00:04:13,920 --> 00:04:18,989
parameters might be the references of

00:04:16,560 --> 00:04:21,440
the image that have been used as

00:04:18,989 --> 00:04:24,719
references to be able to compress that

00:04:21,440 --> 00:04:27,280
image and

00:04:24,719 --> 00:04:29,949
things that are called slices which are

00:04:27,280 --> 00:04:34,389
basically the compressed output directly

00:04:29,949 --> 00:04:36,789
so it's basically the data and so coder

00:04:34,389 --> 00:04:40,800
usually will look like this so you have

00:04:36,789 --> 00:04:44,770
your video files here on the left and

00:04:40,800 --> 00:04:48,240
you will see within the container the

00:04:44,770 --> 00:04:50,319
video bit stream with each slice

00:04:48,240 --> 00:04:54,580
containing a probe data and they are

00:04:50,319 --> 00:04:57,879
separated by separators and you take the

00:04:54,580 --> 00:05:00,129
raw data yeah the coding is actually a

00:04:57,879 --> 00:05:03,909
multi-step processes first you are going

00:05:00,129 --> 00:05:05,379
to take those real data's and give them

00:05:03,909 --> 00:05:07,719
to something that is called a bit stream

00:05:05,379 --> 00:05:11,500
parser which is going to extract the

00:05:07,719 --> 00:05:14,620
metadata and the slices from the whole

00:05:11,500 --> 00:05:17,830
data that are stored in that in that

00:05:14,620 --> 00:05:22,240
file and so once you have the metadata

00:05:17,830 --> 00:05:24,219
and the slices you will give it to two

00:05:22,240 --> 00:05:26,169
different units the first one being is a

00:05:24,219 --> 00:05:30,909
controller that will take the metadata

00:05:26,169 --> 00:05:33,699
and control but career is actually doing

00:05:30,909 --> 00:05:37,210
and the decoder will also take as input

00:05:33,699 --> 00:05:40,060
the slice so that it knows using the

00:05:37,210 --> 00:05:42,129
combination of those metadata and the

00:05:40,060 --> 00:05:43,870
slice itself it's able to produce a

00:05:42,129 --> 00:05:46,649
decompressed frame that you are able to

00:05:43,870 --> 00:05:50,500
well look at and hopefully display or

00:05:46,649 --> 00:05:53,740
whatever you want to do with it

00:05:50,500 --> 00:05:56,409
in most codecs that decoded frame will

00:05:53,740 --> 00:05:59,259
also be used as input for the subsequent

00:05:56,409 --> 00:06:03,159
frames to be able to perform a decent

00:05:59,259 --> 00:06:06,659
compression and so yeah the decoded

00:06:03,159 --> 00:06:13,950
frame is also the input of the next

00:06:06,659 --> 00:06:17,510
frame city code and so

00:06:13,950 --> 00:06:20,730
when you're looking at how to decoders

00:06:17,510 --> 00:06:24,870
so the one that are found in SOC is

00:06:20,730 --> 00:06:28,170
abused most of the time at least in in

00:06:24,870 --> 00:06:31,440
the past they've been based on a design

00:06:28,170 --> 00:06:33,570
that is called stateful codex and the

00:06:31,440 --> 00:06:35,970
stateful codex actually quite nice at

00:06:33,570 --> 00:06:38,850
least from a programming model point of

00:06:35,970 --> 00:06:40,670
view because it will just be taking

00:06:38,850 --> 00:06:43,770
those road data I was telling you about

00:06:40,670 --> 00:06:47,160
give them to the codec and the codec

00:06:43,770 --> 00:06:50,850
will have all the units and that need to

00:06:47,160 --> 00:06:54,510
perform the job in hardware so it will

00:06:50,850 --> 00:06:57,020
be sorry it will just give it the raw

00:06:54,510 --> 00:07:00,060
data and get back a decoded output

00:06:57,020 --> 00:07:05,730
without any law intervention from from

00:07:00,060 --> 00:07:06,990
your part which is very nice from yeah a

00:07:05,730 --> 00:07:11,490
programming model point of view because

00:07:06,990 --> 00:07:14,100
it's quite simple but from what I've

00:07:11,490 --> 00:07:16,290
heard it's actually pretty difficult to

00:07:14,100 --> 00:07:18,330
get right in order so most of the time

00:07:16,290 --> 00:07:20,190
you will have the outer we will not

00:07:18,330 --> 00:07:22,650
complicate it you will have to have film

00:07:20,190 --> 00:07:25,800
wires in place that you will have to

00:07:22,650 --> 00:07:28,320
develop and so on so it has been

00:07:25,800 --> 00:07:32,880
replaced by some kind of a new design

00:07:28,320 --> 00:07:37,100
and that is called stateless clicks and

00:07:32,880 --> 00:07:40,380
that we are going to talk about later on

00:07:37,100 --> 00:07:43,380
so if we wanted to talk about if we

00:07:40,380 --> 00:07:46,440
wanted to support stateful codex in

00:07:43,380 --> 00:07:47,760
linux the api that we want to use and

00:07:46,440 --> 00:07:52,110
the framework that we need to use is

00:07:47,760 --> 00:07:54,960
called v4 higher for video for linux -

00:07:52,110 --> 00:07:58,470
in particular and so video for linux -

00:07:54,960 --> 00:08:01,650
has been introduced quite a while ago so

00:07:58,470 --> 00:08:04,800
in 2002 and it's basically supporting

00:08:01,650 --> 00:08:08,250
everything related to video in linux has

00:08:04,800 --> 00:08:14,180
its name suggests but it's not about

00:08:08,250 --> 00:08:14,180
only the codecs it's also that cameras

00:08:14,360 --> 00:08:21,090
DVB receivers this kind of devices so

00:08:19,260 --> 00:08:26,729
everything that will produce all consume

00:08:21,090 --> 00:08:30,089
video in in linux and so

00:08:26,729 --> 00:08:31,800
yeah the video for linux is using some

00:08:30,089 --> 00:08:34,649
kind of a sub framework that is called

00:08:31,800 --> 00:08:37,849
m2m for memory to memory in order to

00:08:34,649 --> 00:08:40,729
support this kind of stateful codecs and

00:08:37,849 --> 00:08:44,310
if you're looking at a very damp

00:08:40,729 --> 00:08:47,130
pipeline using a file you will be having

00:08:44,310 --> 00:08:51,300
an application that will feed and before

00:08:47,130 --> 00:08:53,870
to driver the road they tap buffer that

00:08:51,300 --> 00:08:57,180
we were talking about and we'll get back

00:08:53,870 --> 00:08:59,550
the decoded pictures as soon as the

00:08:57,180 --> 00:09:01,680
decompression is done so that part is

00:08:59,550 --> 00:09:06,660
pretty simple

00:09:01,680 --> 00:09:09,630
the only thing that is a bit unintuitive

00:09:06,660 --> 00:09:15,389
at least my opinion is a month later of

00:09:09,630 --> 00:09:17,790
the queues and the weather output and

00:09:15,389 --> 00:09:21,480
capture actually output and capture so

00:09:17,790 --> 00:09:24,060
it's actually seen from the user space

00:09:21,480 --> 00:09:27,630
application and not from the system

00:09:24,060 --> 00:09:29,670
itself so for example there whoa the

00:09:27,630 --> 00:09:33,060
user that you are going to put inside

00:09:29,670 --> 00:09:35,220
the codec for to come perform fault

00:09:33,060 --> 00:09:39,209
coding is actually your output and you

00:09:35,220 --> 00:09:41,339
will get back your decoded frame using

00:09:39,209 --> 00:09:48,029
the capture interface which is kind of

00:09:41,339 --> 00:09:52,370
weird to me but yeah anyway and so yeah

00:09:48,029 --> 00:09:55,139
if we wanted to support a stateful codec

00:09:52,370 --> 00:09:58,290
we would have something like this on the

00:09:55,139 --> 00:10:00,029
application possibly using libraries and

00:09:58,290 --> 00:10:03,810
frameworks and so on

00:10:00,029 --> 00:10:08,339
we'll check the bitstream split those

00:10:03,810 --> 00:10:10,949
frames at each separate O's feed the

00:10:08,339 --> 00:10:12,899
data to the to the side full track and

00:10:10,949 --> 00:10:18,120
get back the decoded frame everything is

00:10:12,899 --> 00:10:22,230
fine and this is actually working quite

00:10:18,120 --> 00:10:24,510
well I so basically every codec

00:10:22,230 --> 00:10:28,319
supported in exists days is a stateful

00:10:24,510 --> 00:10:30,000
crack so for example the Bay Libre guys

00:10:28,319 --> 00:10:34,019
have been doing some great work on the

00:10:30,000 --> 00:10:36,720
illogic SOC is recently they did for

00:10:34,019 --> 00:10:38,430
example great talk at a MIDI 3 cp850

00:10:36,720 --> 00:10:39,540
weeks ago and they were talking about

00:10:38,430 --> 00:10:42,089
the video correct

00:10:39,540 --> 00:10:44,399
the video codec on the EMA logic SOC is

00:10:42,089 --> 00:10:45,899
actually a stateful crack it's decoded

00:10:44,399 --> 00:10:49,350
you have plenty of support in the user

00:10:45,899 --> 00:10:51,600
space libraries framework and and so on

00:10:49,350 --> 00:10:54,390
to be able to use it everything rubs

00:10:51,600 --> 00:10:56,279
weight except when you start to

00:10:54,390 --> 00:10:59,339
introduce the video correct stateful

00:10:56,279 --> 00:11:03,180
collects which will only have the

00:10:59,339 --> 00:11:05,519
decoder part in our where and so

00:11:03,180 --> 00:11:10,950
everything else is a bit string power

00:11:05,519 --> 00:11:12,630
sing the controller and so ended frame

00:11:10,950 --> 00:11:16,050
and so on so that the decoder is able to

00:11:12,630 --> 00:11:22,160
do its job has to be done summerhouse

00:11:16,050 --> 00:11:24,149
and so the design decision has been that

00:11:22,160 --> 00:11:26,790
especially the bit stream parsing had to

00:11:24,149 --> 00:11:29,640
be done in the user space because a bit

00:11:26,790 --> 00:11:30,930
stream is basically a file coming from

00:11:29,640 --> 00:11:33,209
somewhere else

00:11:30,930 --> 00:11:37,019
that basically cannot rest so being able

00:11:33,209 --> 00:11:40,260
to pair that file in the kernel is quite

00:11:37,019 --> 00:11:42,720
first difficult and then you have whole

00:11:40,260 --> 00:11:45,959
kind of security issues that you cannot

00:11:42,720 --> 00:11:48,449
prevent know if it would be difficult to

00:11:45,959 --> 00:11:52,440
prevent so the decision has been done to

00:11:48,449 --> 00:11:54,720
have the bits from passing in the user

00:11:52,440 --> 00:11:59,880
space and so you have to kind of split

00:11:54,720 --> 00:12:03,140
everything apart and it's especially

00:11:59,880 --> 00:12:05,430
more difficult with before i/o because

00:12:03,140 --> 00:12:07,560
between the controller and Guerrera you

00:12:05,430 --> 00:12:10,529
have to pass all those controls to be

00:12:07,560 --> 00:12:14,089
able to write tune the decoder so that

00:12:10,529 --> 00:12:19,589
it's able to decode that frame properly

00:12:14,089 --> 00:12:21,420
and so you had an API for that and all

00:12:19,589 --> 00:12:24,180
that list of high up tools that were

00:12:21,420 --> 00:12:28,050
able to do exactly that operation in

00:12:24,180 --> 00:12:31,019
before L 2 except that you had it was

00:12:28,050 --> 00:12:33,449
completely separated from the buffers

00:12:31,019 --> 00:12:37,740
themselves so you were able to change

00:12:33,449 --> 00:12:39,930
the controls but you are not being able

00:12:37,740 --> 00:12:42,060
to synchronize that to a buffer and so

00:12:39,930 --> 00:12:46,500
in this particular case you have to

00:12:42,060 --> 00:12:48,600
change exactly the controls in lockstep

00:12:46,500 --> 00:12:51,779
with each buffer so that the decoder is

00:12:48,600 --> 00:12:54,689
able to do this job properly

00:12:51,779 --> 00:12:56,670
so there's been some support of some

00:12:54,689 --> 00:12:58,980
work at least for quite some time on

00:12:56,670 --> 00:13:00,930
something that was called and that is

00:12:58,980 --> 00:13:03,480
still called there are requests API

00:13:00,930 --> 00:13:08,370
which is basically an API that allows

00:13:03,480 --> 00:13:10,500
you to combine and have those control

00:13:08,370 --> 00:13:13,019
change in lockstep with the buffers

00:13:10,500 --> 00:13:17,750
themself so being able to be able to do

00:13:13,019 --> 00:13:22,500
that so the first RFC was sent in 2015

00:13:17,750 --> 00:13:24,839
and then it basically hopped over a few

00:13:22,500 --> 00:13:26,550
people because it was also something

00:13:24,839 --> 00:13:32,790
that could be used for cameras for

00:13:26,550 --> 00:13:34,889
example to be able to so for cameras for

00:13:32,790 --> 00:13:37,319
example changes changing the exposure of

00:13:34,889 --> 00:13:39,209
a camera is they chose basically the

00:13:37,319 --> 00:13:40,920
same issue so when you change the

00:13:39,209 --> 00:13:44,910
exposure and capture some friends you

00:13:40,920 --> 00:13:48,180
have no way at least at the moment to

00:13:44,910 --> 00:13:50,699
say when at which frame exactly the

00:13:48,180 --> 00:13:52,500
actual exposure had been changed which

00:13:50,699 --> 00:13:56,730
is gentleman an issue as well on some

00:13:52,500 --> 00:14:00,300
use cases so the API went back and forth

00:13:56,730 --> 00:14:04,559
between the codec use case and more the

00:14:00,300 --> 00:14:07,589
camera use case over the years with a

00:14:04,559 --> 00:14:09,300
bunch of people stepping in to help and

00:14:07,589 --> 00:14:16,259
try to address it for their particular

00:14:09,300 --> 00:14:18,720
use case yeah the codec side at least

00:14:16,259 --> 00:14:20,730
was finally merged in well what would

00:14:18,720 --> 00:14:22,680
what will become photo training or

00:14:20,730 --> 00:14:24,660
whatever it's called

00:14:22,680 --> 00:14:27,000
so at least now we have support for

00:14:24,660 --> 00:14:29,250
stateless codecs at least an API that

00:14:27,000 --> 00:14:36,180
allows us to support stateless codecs

00:14:29,250 --> 00:14:39,389
and v4 l2 which is great and so if we go

00:14:36,180 --> 00:14:42,860
back to the stack that we were

00:14:39,389 --> 00:14:44,430
discussing before now it looks kind of

00:14:42,860 --> 00:14:47,129
like this

00:14:44,430 --> 00:14:49,709
so you will still have your container of

00:14:47,129 --> 00:14:52,980
video good stream your data that are

00:14:49,709 --> 00:14:57,449
going to be fed and passed by your

00:14:52,980 --> 00:15:01,439
application which will then feed the

00:14:57,449 --> 00:15:03,509
slices and modify the controls using the

00:15:01,439 --> 00:15:04,490
whatever are coming from the slice and

00:15:03,509 --> 00:15:07,630
the media that

00:15:04,490 --> 00:15:10,970
Tullius oil driver which will in turn

00:15:07,630 --> 00:15:12,530
give you a Ducati frame that you will

00:15:10,970 --> 00:15:15,890
keep so that you can use it as reference

00:15:12,530 --> 00:15:18,620
for later frames and so on and so only

00:15:15,890 --> 00:15:20,900
the decoding part is now in Linux and

00:15:18,620 --> 00:15:30,770
everything else is in at least use of

00:15:20,900 --> 00:15:33,830
space yeah and so we've been working

00:15:30,770 --> 00:15:37,430
that job mostly on the winner is UCS and

00:15:33,830 --> 00:15:39,440
so a winner produces multimedia so see

00:15:37,430 --> 00:15:43,670
that are mostly targeted at tablets and

00:15:39,440 --> 00:15:45,650
stds it's one of the associate that are

00:15:43,670 --> 00:15:49,100
very likely to be found in what those

00:15:45,650 --> 00:15:52,370
tube cheap SBC's that you are finding at

00:15:49,100 --> 00:15:57,140
like less than $10 on Alibaba for

00:15:52,370 --> 00:15:59,300
example and so just like any multimedia

00:15:57,140 --> 00:16:03,440
SSDs I have hardware you need to be able

00:15:59,300 --> 00:16:07,370
to decode and encode videos except that

00:16:03,440 --> 00:16:10,910
it's using a stateless codec so we had

00:16:07,370 --> 00:16:16,700
to have a particular design to be able

00:16:10,910 --> 00:16:20,210
to use it and so a winner is giving like

00:16:16,700 --> 00:16:23,720
all the armies receive endures a BSP

00:16:20,210 --> 00:16:26,810
stack and in the case of a winner it's

00:16:23,720 --> 00:16:29,000
kind of an outdated one so the camel

00:16:26,810 --> 00:16:31,730
that they are shipping is actually

00:16:29,000 --> 00:16:35,540
either 3.43 dot ten even these days

00:16:31,730 --> 00:16:38,570
which is pretty old and for the

00:16:35,540 --> 00:16:41,660
particular hardware codec they are not

00:16:38,570 --> 00:16:45,460
using this for l2 but they basically

00:16:41,660 --> 00:16:49,520
have some kind of private API and it's

00:16:45,460 --> 00:16:52,940
based on a stack that is basically split

00:16:49,520 --> 00:16:56,840
into parts where you will have a kernel

00:16:52,940 --> 00:16:59,180
driver that is basically just here to

00:16:56,840 --> 00:17:02,660
manage the resources but just the clock

00:16:59,180 --> 00:17:06,680
be able to get interrupts memory map the

00:17:02,660 --> 00:17:09,970
registers of the unit and so on and all

00:17:06,680 --> 00:17:15,060
the logic will actually be in user space

00:17:09,970 --> 00:17:17,460
that part was closed for quite a while

00:17:15,060 --> 00:17:21,300
so we had basically no idea how the

00:17:17,460 --> 00:17:23,270
hardware was actually working and that

00:17:21,300 --> 00:17:26,730
kind of design would not fly with

00:17:23,270 --> 00:17:32,160
mainline kernel we were kind of stuck

00:17:26,730 --> 00:17:35,660
for quite some time except that there's

00:17:32,160 --> 00:17:40,670
been some reverse engineering a thought

00:17:35,660 --> 00:17:40,670
that have been done on this particular

00:17:41,420 --> 00:17:48,270
driver which is so the hardware unit is

00:17:45,300 --> 00:17:50,990
called sidao like the tree and so the

00:17:48,270 --> 00:17:54,330
reverse engineering was called ceteris

00:17:50,990 --> 00:17:59,100
and so it was basically an AFOL to be

00:17:54,330 --> 00:18:01,100
able to have an an open source stack and

00:17:59,100 --> 00:18:04,260
based on to be able to drive that

00:18:01,100 --> 00:18:06,240
particular hardware unit and that

00:18:04,260 --> 00:18:08,730
reverse engineering was done for

00:18:06,240 --> 00:18:11,520
basically all the meaningful video

00:18:08,730 --> 00:18:15,420
codecs and decoding and then only h.264

00:18:11,520 --> 00:18:17,430
encoding but it's not because they

00:18:15,420 --> 00:18:19,710
didn't have the time to do it it's

00:18:17,430 --> 00:18:22,530
because the units actually only able to

00:18:19,710 --> 00:18:25,490
encode in h.264 so we basically had most

00:18:22,530 --> 00:18:30,000
of the codecs and features figured out

00:18:25,490 --> 00:18:32,970
but it was mostly targeted at winners

00:18:30,000 --> 00:18:38,700
BSP so it was just a way to be able to

00:18:32,970 --> 00:18:41,970
replace the closed source coding part

00:18:38,700 --> 00:18:44,130
that we were telling you about and it

00:18:41,970 --> 00:18:46,280
was still relying on the same API that

00:18:44,130 --> 00:18:50,210
open era was providing so that small

00:18:46,280 --> 00:18:54,210
kernel kernel driver so it was

00:18:50,210 --> 00:18:56,370
completely functional there's even been

00:18:54,210 --> 00:19:01,470
some SBC van those that were shipping

00:18:56,370 --> 00:19:06,240
and this reverse engineering project as

00:19:01,470 --> 00:19:10,650
part of their ESP to the customers so it

00:19:06,240 --> 00:19:15,330
was completely working but since the

00:19:10,650 --> 00:19:18,690
kalman was quite outdated and not really

00:19:15,330 --> 00:19:21,570
maintained anymore it wasn't really a

00:19:18,690 --> 00:19:23,750
way for world it was just a way to have

00:19:21,570 --> 00:19:26,810
a stopgap measure

00:19:23,750 --> 00:19:28,090
and we were not able to use it in my

00:19:26,810 --> 00:19:33,620
line

00:19:28,090 --> 00:19:36,980
oh yeah and they were providing as well

00:19:33,620 --> 00:19:38,630
Oliva Depot implementation so that you

00:19:36,980 --> 00:19:42,170
would be able to use it with his popular

00:19:38,630 --> 00:19:45,190
media players solid video Depot being an

00:19:42,170 --> 00:19:48,850
API one of the LPI to be able to provide

00:19:45,190 --> 00:19:51,350
decoding capabilities to like regular

00:19:48,850 --> 00:19:53,600
multimedia players so you would be able

00:19:51,350 --> 00:19:54,490
to use VLC and so on using that that

00:19:53,600 --> 00:19:57,200
work

00:19:54,490 --> 00:20:05,750
it was great reverse engineering fault

00:19:57,200 --> 00:20:08,840
but like not quite enough for us and so

00:20:05,750 --> 00:20:11,570
at summer 2016 we actually had an intern

00:20:08,840 --> 00:20:17,110
for the summer that started working on

00:20:11,570 --> 00:20:17,110
that kind of driver and worked on an IRC

00:20:18,010 --> 00:20:23,630
considering that it was only about two

00:20:21,290 --> 00:20:26,690
months two months is I guess it was

00:20:23,630 --> 00:20:28,760
actually very successful so by the end

00:20:26,690 --> 00:20:32,240
of the months of the two monsters he had

00:20:28,760 --> 00:20:36,070
an impact to implementation working at

00:20:32,240 --> 00:20:39,230
least mpeg-2 decoding working and

00:20:36,070 --> 00:20:43,340
Liberty a implementation to be able to

00:20:39,230 --> 00:20:45,890
integrate in the popular media players

00:20:43,340 --> 00:20:48,470
so I was telling you about levy Depot

00:20:45,890 --> 00:20:53,450
video is basically a standard that is

00:20:48,470 --> 00:20:56,480
pushed by Nvidia I think while Libya is

00:20:53,450 --> 00:20:59,780
mostly about by Intel and actually the

00:20:56,480 --> 00:21:05,690
reveai API worked better for us so we

00:20:59,780 --> 00:21:08,540
chose to go with VI yeah so we had

00:21:05,690 --> 00:21:11,750
basically some basic support for mpeg-2

00:21:08,540 --> 00:21:16,010
decoding and some integration to the

00:21:11,750 --> 00:21:20,030
popular media players but it was the own

00:21:16,010 --> 00:21:23,210
video prototype so you could have well

00:21:20,030 --> 00:21:26,240
we definitely still had bugs for example

00:21:23,210 --> 00:21:28,400
we had frames that were backwards so you

00:21:26,240 --> 00:21:30,680
had one friend and the friend that was

00:21:28,400 --> 00:21:32,600
supposed to be a befall that one was

00:21:30,680 --> 00:21:35,720
actually after her so it looked

00:21:32,600 --> 00:21:39,200
some weird glitches and it's actually

00:21:35,720 --> 00:21:40,760
because in video codecs the encoding

00:21:39,200 --> 00:21:42,170
order is actually different from the

00:21:40,760 --> 00:21:45,380
displaying order so that you can

00:21:42,170 --> 00:21:47,390
compress more efficiently so you have to

00:21:45,380 --> 00:21:49,640
take that into order and we didn't at

00:21:47,390 --> 00:21:56,120
the time which led to some interesting

00:21:49,640 --> 00:22:00,860
bugs at least artifacts but the main

00:21:56,120 --> 00:22:05,720
issues were actually that it was really

00:22:00,860 --> 00:22:08,770
slow so we could only play videos that

00:22:05,720 --> 00:22:10,840
were at the resolution of the screen

00:22:08,770 --> 00:22:15,340
otherwise it wasn't really working

00:22:10,840 --> 00:22:18,380
actually on the displaying side so and

00:22:15,340 --> 00:22:22,180
who cares about mpeg-2 I mean everyone

00:22:18,380 --> 00:22:26,360
is playing h.264 h.264 video these days

00:22:22,180 --> 00:22:28,460
so it was a great way to yeah able to

00:22:26,360 --> 00:22:30,080
the type make sure it's working but it

00:22:28,460 --> 00:22:36,650
was nothing more than a proof of concept

00:22:30,080 --> 00:22:38,810
and for a year and a half we've had a

00:22:36,650 --> 00:22:41,240
lot of people coming in interested into

00:22:38,810 --> 00:22:45,170
like pushing that proof of concept for

00:22:41,240 --> 00:22:47,090
war but it was a significant effort and

00:22:45,170 --> 00:22:49,220
we were not able to do it without

00:22:47,090 --> 00:22:52,580
funding but no one really wanted to

00:22:49,220 --> 00:22:54,320
found that a fault on their own so we

00:22:52,580 --> 00:22:57,440
finally had the idea to fund it through

00:22:54,320 --> 00:23:01,400
a Kickstarter campaign that started at

00:22:57,440 --> 00:23:03,320
the beginning of 2018 and it actually

00:23:01,400 --> 00:23:06,080
worked great it was the first time for

00:23:03,320 --> 00:23:08,360
us that we actually even tried or even

00:23:06,080 --> 00:23:12,350
considered doing a Kickstarter campaign

00:23:08,360 --> 00:23:16,610
to fund mainline development and we

00:23:12,350 --> 00:23:21,040
achieved our goals even beyond what we

00:23:16,610 --> 00:23:24,050
were expecting so we even committed to

00:23:21,040 --> 00:23:26,690
develop the drivers for more sushi and

00:23:24,050 --> 00:23:32,200
we were intentional initially intending

00:23:26,690 --> 00:23:36,380
and we committed to develop a 360 h.265

00:23:32,200 --> 00:23:40,280
coding and it allowed us to firm the

00:23:36,380 --> 00:23:42,320
full-time intern for six months plus a

00:23:40,280 --> 00:23:44,920
tough time engineer so the full-time in

00:23:42,320 --> 00:23:48,250
town being both coastal ski

00:23:44,920 --> 00:23:50,260
and the part-time engineer being me

00:23:48,250 --> 00:23:54,790
and we basically built on top of the

00:23:50,260 --> 00:23:56,590
prototype to be able to well work on

00:23:54,790 --> 00:24:03,660
Noah so serious a number of bugs

00:23:56,590 --> 00:24:09,970
obviously and try to work on the

00:24:03,660 --> 00:24:14,050
slowness issues that we were seeing and

00:24:09,970 --> 00:24:17,770
so here is what the seller stack is

00:24:14,050 --> 00:24:19,480
looking like so we have the bitstream

00:24:17,770 --> 00:24:22,270
pasture that will actually be part of

00:24:19,480 --> 00:24:24,820
the deep layers of video frameworks so

00:24:22,270 --> 00:24:30,240
things like VLC ffmpeg and things like

00:24:24,820 --> 00:24:32,950
that we will get from the video player

00:24:30,240 --> 00:24:35,560
metadata and slice that have been passed

00:24:32,950 --> 00:24:37,960
already and they are given to all DBA

00:24:35,560 --> 00:24:41,820
implementation that we called levy a

00:24:37,960 --> 00:24:45,190
referral to request and actually because

00:24:41,820 --> 00:24:47,320
things that API is pretty generate and

00:24:45,190 --> 00:24:51,730
the Libya API is really generic as well

00:24:47,320 --> 00:24:54,550
it can be made to work on any stateless

00:24:51,730 --> 00:24:58,210
codec that we need to support so it's

00:24:54,550 --> 00:25:00,310
some generated piece of code that has

00:24:58,210 --> 00:25:02,490
been tested on a single SOC so far so

00:25:00,310 --> 00:25:06,970
it's probably not generic enough yet but

00:25:02,490 --> 00:25:10,300
should be generate and we have and we

00:25:06,970 --> 00:25:16,230
have a default driver that is made for

00:25:10,300 --> 00:25:16,230
particular serious driver

00:25:18,150 --> 00:25:25,360
the video recording actually works works

00:25:21,610 --> 00:25:27,760
pretty well but actually where we found

00:25:25,360 --> 00:25:30,510
them what we find the more difficult was

00:25:27,760 --> 00:25:34,360
actually displaying that decoded frame

00:25:30,510 --> 00:25:39,700
so in an idle word and it's basically

00:25:34,360 --> 00:25:41,620
what Cody is doing you would have the

00:25:39,700 --> 00:25:43,750
Linux kernel who is the default to the

00:25:41,620 --> 00:25:47,610
driver that we have all the

00:25:43,750 --> 00:25:53,020
implementation driving the decoded

00:25:47,610 --> 00:25:55,870
driving the set verse decoder so giving

00:25:53,020 --> 00:25:58,750
it the bitstream getting back and the

00:25:55,870 --> 00:26:00,520
decoded the decoded frames and then Cody

00:25:58,750 --> 00:26:02,440
would take that you could eat frame give

00:26:00,520 --> 00:26:07,500
it to the kms drivers that we have in

00:26:02,440 --> 00:26:09,610
the kernel and everything is displayed

00:26:07,500 --> 00:26:12,610
except that

00:26:09,610 --> 00:26:16,450
so the liquidy format is actually in a

00:26:12,610 --> 00:26:19,930
proprietary format which is not that

00:26:16,450 --> 00:26:23,820
difficult gas I mean it's so it's a y UV

00:26:19,930 --> 00:26:26,140
tied format and actually most of the

00:26:23,820 --> 00:26:28,780
hardware in China actually outputting

00:26:26,140 --> 00:26:31,180
some variant of a tight format somewhere

00:26:28,780 --> 00:26:33,040
and it's actually because it's not

00:26:31,180 --> 00:26:36,430
optimal in order to be able to work

00:26:33,040 --> 00:26:39,790
trying that so they basically all do but

00:26:36,430 --> 00:26:41,230
the exact tiling so the tiling in both

00:26:39,790 --> 00:26:43,210
directions are basically always

00:26:41,230 --> 00:26:47,230
different from one vendor to another so

00:26:43,210 --> 00:26:50,710
you have to figure out figure it out but

00:26:47,230 --> 00:26:52,090
fortunately for us displaying the

00:26:50,710 --> 00:26:54,250
display and Ryan actually able to

00:26:52,090 --> 00:26:55,900
process that proprietary format without

00:26:54,250 --> 00:26:59,290
any conversion so we can just take the

00:26:55,900 --> 00:27:02,700
video decoder output and give it to the

00:26:59,290 --> 00:27:04,140
display and shine and everything works

00:27:02,700 --> 00:27:09,520
[Music]

00:27:04,140 --> 00:27:12,310
another issue would be that scaling also

00:27:09,520 --> 00:27:15,310
so that you can well upscale all down

00:27:12,310 --> 00:27:21,780
scale the video to match the one of your

00:27:15,310 --> 00:27:26,440
screen is is not doable problem easily

00:27:21,780 --> 00:27:29,380
so we could just use once again the

00:27:26,440 --> 00:27:30,710
display in giant be able to use it it

00:27:29,380 --> 00:27:33,650
actually has a hardware scale

00:27:30,710 --> 00:27:36,080
so be able to use that scaler to be able

00:27:33,650 --> 00:27:37,910
to scale down scale without any

00:27:36,080 --> 00:27:41,110
performance hit or anything it's

00:27:37,910 --> 00:27:41,110
basically completely done in hardware

00:27:41,200 --> 00:27:46,450
but x11 doesn't allow you to do that

00:27:45,470 --> 00:27:51,400
easily

00:27:46,450 --> 00:27:54,260
so we basically hit the wall there and

00:27:51,400 --> 00:27:58,160
x11 pretty much expect that the format

00:27:54,260 --> 00:28:01,520
is not kind and it doesn't have any kind

00:27:58,160 --> 00:28:06,500
of hardware acceleration for scaling so

00:28:01,520 --> 00:28:08,900
ya didn't rework for us so we tried a

00:28:06,500 --> 00:28:12,590
number of solutions the first one being

00:28:08,900 --> 00:28:17,800
well let's convert that ID format and in

00:28:12,590 --> 00:28:21,620
software so it's actually very very slow

00:28:17,800 --> 00:28:25,960
so on small resolutions it's actually

00:28:21,620 --> 00:28:29,530
kind of works so for example 480p it's

00:28:25,960 --> 00:28:32,300
good enough except that when you start

00:28:29,530 --> 00:28:34,430
coding higher resolutions videos it just

00:28:32,300 --> 00:28:36,590
doesn't work anymore and it's kind of

00:28:34,430 --> 00:28:38,720
taking all the CPUs to be able to decode

00:28:36,590 --> 00:28:41,930
your videos which was kind of the point

00:28:38,720 --> 00:28:44,930
of using well kind of the point of using

00:28:41,930 --> 00:28:46,580
how we're coding was actually to offload

00:28:44,930 --> 00:28:50,090
work from the cpu so if you're using

00:28:46,580 --> 00:28:55,190
just as much CPU then it doesn't it

00:28:50,090 --> 00:28:58,850
really isn't worth it anymore and then

00:28:55,190 --> 00:29:02,840
x11 has a extension that is called X

00:28:58,850 --> 00:29:05,960
video that is meant to be able to kind

00:29:02,840 --> 00:29:09,620
of a accelerators kind of with kind of

00:29:05,960 --> 00:29:11,390
issues except that when we started

00:29:09,620 --> 00:29:13,550
reaching out for example to VLC

00:29:11,390 --> 00:29:15,020
developers they were basically starting

00:29:13,550 --> 00:29:16,670
that it was stating that it was

00:29:15,020 --> 00:29:19,070
completely deprecated and they would

00:29:16,670 --> 00:29:21,440
remove it in the next release does that

00:29:19,070 --> 00:29:26,990
didn't in the end but it didn't really

00:29:21,440 --> 00:29:30,980
look like a way for world we would have

00:29:26,990 --> 00:29:33,980
had some glitches as well because in X

00:29:30,980 --> 00:29:35,660
all the composition so the layout of the

00:29:33,980 --> 00:29:40,010
values windows from strands is between

00:29:35,660 --> 00:29:43,020
them and so on kind of expect that X all

00:29:40,010 --> 00:29:46,020
the buffers and X video would

00:29:43,020 --> 00:29:47,850
take one of those buffers out of but X

00:29:46,020 --> 00:29:50,190
is expecting so we would have had some

00:29:47,850 --> 00:29:57,350
issues for example with transparencies

00:29:50,190 --> 00:29:57,350
and so on which wouldn't really work so

00:29:57,710 --> 00:30:03,750
we tried something else we tried to

00:30:01,110 --> 00:30:08,430
import the decoded format in the GPU and

00:30:03,750 --> 00:30:11,550
do the untangling and scaling in the GPU

00:30:08,430 --> 00:30:14,940
itself except that we are using

00:30:11,550 --> 00:30:20,180
malee GPU which so now is not really

00:30:14,940 --> 00:30:23,250
supported quite good enough in upstream

00:30:20,180 --> 00:30:25,080
open-source drivers and the OpenGL blob

00:30:23,250 --> 00:30:28,380
has a lot of constraints including the

00:30:25,080 --> 00:30:31,770
one that it cannot really just work for

00:30:28,380 --> 00:30:33,600
us we had some kind of weird bugs when

00:30:31,770 --> 00:30:35,340
we were trying to use a shader to be

00:30:33,600 --> 00:30:38,220
able to do that and tiling with like

00:30:35,340 --> 00:30:42,770
lots of Precision's on the tile edges

00:30:38,220 --> 00:30:48,150
and so on and we actually have some

00:30:42,770 --> 00:30:50,940
quite low memory bandwidth so if we can

00:30:48,150 --> 00:30:52,920
avoid having American back and forth

00:30:50,940 --> 00:30:56,870
between hardware units and main memory

00:30:52,920 --> 00:30:56,870
it's good

00:30:57,020 --> 00:31:01,830
and then we considered Wayland as well

00:30:59,640 --> 00:31:05,520
which was which is supposed to actually

00:31:01,830 --> 00:31:09,330
be able to deal with this kind of issues

00:31:05,520 --> 00:31:14,610
except that we would obviously give all

00:31:09,330 --> 00:31:17,460
of our users using wet x11 in the cold

00:31:14,610 --> 00:31:19,740
and then we would have to patch all the

00:31:17,460 --> 00:31:24,680
way down capacitors to be able to

00:31:19,740 --> 00:31:32,530
support of proprietary format which

00:31:24,680 --> 00:31:36,220
doesn't seem really ideal either yeah

00:31:32,530 --> 00:31:38,210
so what the current state is is

00:31:36,220 --> 00:31:41,690
politically the request API has been

00:31:38,210 --> 00:31:45,320
merged in the next camel race so thanks

00:31:41,690 --> 00:31:47,090
to hands for that we have a VA

00:31:45,320 --> 00:31:49,820
implementation that is working in top of

00:31:47,090 --> 00:31:54,290
it on top of it with that supports and

00:31:49,820 --> 00:31:57,110
back to h.264 and h.265 decoding we also

00:31:54,290 --> 00:31:58,820
developed as part of our private

00:31:57,110 --> 00:32:01,130
development effort some kind of tool

00:31:58,820 --> 00:32:05,530
that is called the referral to request

00:32:01,130 --> 00:32:08,840
test that basically will we'll play a

00:32:05,530 --> 00:32:12,049
video that we captured so basically a

00:32:08,840 --> 00:32:14,179
levy a kind of session and we can just

00:32:12,049 --> 00:32:17,360
reply it over and over time using the

00:32:14,179 --> 00:32:19,010
just that - and the kernel itself which

00:32:17,360 --> 00:32:20,600
is quite nice when you want to just work

00:32:19,010 --> 00:32:22,700
on the decoding and you don't care about

00:32:20,600 --> 00:32:26,630
all the rest of the user space tag that

00:32:22,700 --> 00:32:28,760
you want to integrate into and we have

00:32:26,630 --> 00:32:32,690
the first part of our citrus drivers

00:32:28,760 --> 00:32:35,200
that has been merged in 420 so it only

00:32:32,690 --> 00:32:38,150
supports mpeg-2 for now but we have

00:32:35,200 --> 00:32:42,620
h.264 on each with 65 patches that have

00:32:38,150 --> 00:32:47,570
been sent and it has been merged in

00:32:42,620 --> 00:32:49,190
staging for now because and the since

00:32:47,570 --> 00:32:51,049
it's pretty much the same the first user

00:32:49,190 --> 00:32:55,630
to use that API and that API is quite

00:32:51,049 --> 00:32:59,720
new we actually wanted to be able to

00:32:55,630 --> 00:33:01,010
change that API if you want and well if

00:32:59,720 --> 00:33:05,270
you want to do that you have to be in

00:33:01,010 --> 00:33:07,400
staging otherwise the ABI rules are kind

00:33:05,270 --> 00:33:13,610
of strict so that's why we are on

00:33:07,400 --> 00:33:16,280
staging and I'll be doing a demo I think

00:33:13,610 --> 00:33:20,480
it's tomorrow and the technical booth of

00:33:16,280 --> 00:33:23,630
this of this were basically so we as

00:33:20,480 --> 00:33:25,900
Cody running on top of Olivia

00:33:23,630 --> 00:33:29,620
implementation and a Linux kernel

00:33:25,900 --> 00:33:36,110
decoding h.264 video so if you want to

00:33:29,620 --> 00:33:40,580
come take a look please do so that's it

00:33:36,110 --> 00:33:42,070
for me do you have any questions there's

00:33:40,580 --> 00:33:45,300
some mic

00:33:42,070 --> 00:33:45,300
both sides of them

00:33:49,510 --> 00:33:53,940
the questions well a one

00:33:56,090 --> 00:34:02,630
so what's the use of space sport like in

00:33:59,330 --> 00:34:05,330
external libraries for this kind of code

00:34:02,630 --> 00:34:08,480
I imagine it's it's lived VA but does

00:34:05,330 --> 00:34:12,220
ffmpeg have a shortcut or does it have

00:34:08,480 --> 00:34:16,100
to go so in VA we actually wanted to

00:34:12,220 --> 00:34:18,800
tell the end goal is actually to be able

00:34:16,100 --> 00:34:21,740
to have a v MPEG and GStreamer and some

00:34:18,800 --> 00:34:25,190
be able to directly use a request API to

00:34:21,740 --> 00:34:26,660
talk to the colonel and all really

00:34:25,190 --> 00:34:29,420
implementation is basically just a

00:34:26,660 --> 00:34:32,080
stopgap measure so it's so that we can

00:34:29,420 --> 00:34:34,340
have something working now but

00:34:32,080 --> 00:34:36,140
considering that the discriminant guys

00:34:34,340 --> 00:34:38,000
have been starting some work on it and

00:34:36,140 --> 00:34:40,670
so on I don't really expect it to last

00:34:38,000 --> 00:34:44,000
more than a few years before being

00:34:40,670 --> 00:34:46,510
completely right duplicated because FFF

00:34:44,000 --> 00:34:49,900
FFM begged people to talk to me directly

00:34:46,510 --> 00:34:49,900
good thank you

00:34:55,210 --> 00:35:02,520
there's no more questions and I just

00:34:57,609 --> 00:35:02,520
said sit for me thanks for attending

00:35:02,750 --> 00:35:07,280

YouTube URL: https://www.youtube.com/watch?v=KRrO9e5UugA


