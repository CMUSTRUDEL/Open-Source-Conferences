Title: Keynote: Apache Kafka and the Rise of the Streaming Platform - Neha Narkhede, Co-Founder & CTO
Publication date: 2017-10-24
Playlist: Open Source Summit Europe & Embedded Linux Conference Europe 2017
Description: 
	Keynote: Apache Kafka and the Rise of the Streaming Platform - Neha Narkhede, Co-Founder & CTO, Confluent 

Streaming platforms are emerging as a new trend. However, what exactly is a streaming platform? With Apache Kafka at the core, it’s an entirely new perspective on managing the flow of data. Part messaging system, part Hadoop made fast, part fast ETL and scalable data integration, a streaming platform is a new way to stream, store and process data across the business. In this keynote, Neha will share examples of Kafka in action and why Kafka is becoming a central nervous system that ties together the modern, digital business.

About Neha Narkhede
Neha Narkhede is co-founder and CTO at Confluent, the company behind the popular Apache Kafka streaming platform. Prior to founding Confluent, Neha led streams infrastructure at LinkedIn, where she was responsible for LinkedIn’s streaming infrastructure built on top of Apache Kafka and Apache Samza. She is one of the initial authors of Apache Kafka and a committer and PMC member on the project.
Captions: 
	00:00:00,210 --> 00:00:04,170
hello everyone welcome to this

00:00:02,879 --> 00:00:05,790
conference I hope you're looking forward

00:00:04,170 --> 00:00:09,059
to a fantastic day

00:00:05,790 --> 00:00:10,380
it's my first time at speaking at open

00:00:09,059 --> 00:00:12,630
source summit and I'm really excited

00:00:10,380 --> 00:00:15,690
about it today I'm going to talk about

00:00:12,630 --> 00:00:18,240
Apache Kafka and the rise of a streaming

00:00:15,690 --> 00:00:19,770
platform but before I begin can I get a

00:00:18,240 --> 00:00:22,310
quick show of hands of people who have

00:00:19,770 --> 00:00:25,170
heard about Apache Kafka or used tape

00:00:22,310 --> 00:00:26,460
all right that's most of you it's still

00:00:25,170 --> 00:00:28,349
going to be a relevant talk I promise

00:00:26,460 --> 00:00:30,300
you that

00:00:28,349 --> 00:00:32,219
avoid I've been working in this

00:00:30,300 --> 00:00:35,660
real-time beta in stream processing

00:00:32,219 --> 00:00:37,950
space for close to a decade now and

00:00:35,660 --> 00:00:41,070
during these years one of the biggest

00:00:37,950 --> 00:00:44,100
shifts have noticed is the rise of real

00:00:41,070 --> 00:00:46,170
time data in production and this is

00:00:44,100 --> 00:00:48,750
happening as part of companies becoming

00:00:46,170 --> 00:00:51,239
more digital you know as part of my day

00:00:48,750 --> 00:00:53,460
job I get to talk to companies that are

00:00:51,239 --> 00:00:56,460
natively digital lots of them back in

00:00:53,460 --> 00:00:58,500
Silicon Valley but I also get to talk to

00:00:56,460 --> 00:01:00,690
brick-and-mortar businesses that are

00:00:58,500 --> 00:01:03,989
transforming themselves into digital

00:01:00,690 --> 00:01:07,409
ones and one of those trends I've

00:01:03,989 --> 00:01:10,140
noticed is that the modern sort of

00:01:07,409 --> 00:01:12,930
enterprise is moving to being digital

00:01:10,140 --> 00:01:16,530
and this is the real impetus for the

00:01:12,930 --> 00:01:19,009
rise of real-time so in my talk today I

00:01:16,530 --> 00:01:21,869
want to put forth a simple thesis I

00:01:19,009 --> 00:01:24,090
think we are witnessing the rise of a

00:01:21,869 --> 00:01:27,119
major new category of infrastructure

00:01:24,090 --> 00:01:29,520
software and this new way of thinking

00:01:27,119 --> 00:01:31,290
about your data is not something we've

00:01:29,520 --> 00:01:32,909
had to do very often you know if you've

00:01:31,290 --> 00:01:34,979
been in the industry long enough you've

00:01:32,909 --> 00:01:38,280
seen this kind of thing happen with a

00:01:34,979 --> 00:01:39,900
number of major technologies like you

00:01:38,280 --> 00:01:41,630
know database systems that shape the

00:01:39,900 --> 00:01:44,340
whole category of business applications

00:01:41,630 --> 00:01:46,350
data warehouses that shaped a whole

00:01:44,340 --> 00:01:49,649
category of business intelligence and

00:01:46,350 --> 00:01:51,990
analytics apps I think this whole area

00:01:49,649 --> 00:01:54,420
of stream processing is going to be like

00:01:51,990 --> 00:01:56,909
that we're watching the emergence of

00:01:54,420 --> 00:01:59,659
another category of infrastructure

00:01:56,909 --> 00:02:02,340
software which is the streaming platform

00:01:59,659 --> 00:02:04,680
but then what's the evidence that this

00:02:02,340 --> 00:02:07,170
is happening let's take a look at

00:02:04,680 --> 00:02:09,539
Kafka's journey so far it started back

00:02:07,170 --> 00:02:11,580
in Silicon Valley several years ago we

00:02:09,539 --> 00:02:13,420
created Kafka we open sourced it and

00:02:11,580 --> 00:02:16,840
very soon

00:02:13,420 --> 00:02:19,569
a growing list of the most technically

00:02:16,840 --> 00:02:21,640
sophisticated Silicon Valley companies

00:02:19,569 --> 00:02:25,750
started to rebuild their architecture

00:02:21,640 --> 00:02:27,940
around Kafka and after that it turned

00:02:25,750 --> 00:02:29,470
out that this wasn't just a phenomenon

00:02:27,940 --> 00:02:32,890
that was limited to the Silicon Valley

00:02:29,470 --> 00:02:34,480
crowd like a few things we do there to

00:02:32,890 --> 00:02:36,790
give you an example one of the things

00:02:34,480 --> 00:02:39,340
that we hadn't thought about when we

00:02:36,790 --> 00:02:40,810
created Kafka was this whole space of

00:02:39,340 --> 00:02:42,819
the Internet of Things I think Jim

00:02:40,810 --> 00:02:44,410
mentioned that before you know when I

00:02:42,819 --> 00:02:47,380
first heard about this I was a bit

00:02:44,410 --> 00:02:49,950
skeptical but then it turns out that

00:02:47,380 --> 00:02:52,269
companies are doing amazing things

00:02:49,950 --> 00:02:54,580
connecting cars globally around the

00:02:52,269 --> 00:02:57,400
world capturing streams of events from

00:02:54,580 --> 00:02:59,920
the car feeding those streams back into

00:02:57,400 --> 00:03:01,630
the features of those cars into apps

00:02:59,920 --> 00:03:03,900
that go along with the car into

00:03:01,630 --> 00:03:07,060
analytics above the customer base and

00:03:03,900 --> 00:03:08,920
this sort of thing is happening with a

00:03:07,060 --> 00:03:11,310
lot of industry verticals from

00:03:08,920 --> 00:03:13,870
manufacturing all the way to logistics

00:03:11,310 --> 00:03:16,330
you know having been in a web tech

00:03:13,870 --> 00:03:18,430
company myself have a pretty good idea

00:03:16,330 --> 00:03:20,980
of what it means when you can instrument

00:03:18,430 --> 00:03:24,519
your business at that level and optimize

00:03:20,980 --> 00:03:26,260
it not only is this happening with the

00:03:24,519 --> 00:03:28,660
Internet of Things space but another

00:03:26,260 --> 00:03:30,910
industry that's undergoing this is the

00:03:28,660 --> 00:03:33,910
whole financial services and banking

00:03:30,910 --> 00:03:37,989
space now this is an entire industry

00:03:33,910 --> 00:03:40,959
that's built on real-time data but now

00:03:37,989 --> 00:03:43,000
having a modern distributed platform

00:03:40,959 --> 00:03:45,700
like Kafka is making a lot more things

00:03:43,000 --> 00:03:48,340
possible now being able to break down

00:03:45,700 --> 00:03:51,700
the silos that exists in these banks and

00:03:48,340 --> 00:03:53,790
get data flowing in real time breaking

00:03:51,700 --> 00:03:57,579
the monolith into event-driven

00:03:53,790 --> 00:03:59,500
microservices this transformation is

00:03:57,579 --> 00:04:02,410
making a lot more applications possible

00:03:59,500 --> 00:04:06,359
from instant credit card processing to

00:04:02,410 --> 00:04:08,829
real time fraud detection and so on even

00:04:06,359 --> 00:04:12,370
traditional businesses like the retail

00:04:08,829 --> 00:04:14,620
industry are adopting Kafka aggressively

00:04:12,370 --> 00:04:18,070
to compete better to become more

00:04:14,620 --> 00:04:21,370
efficient and today we know that about a

00:04:18,070 --> 00:04:23,020
third of Fortune 500 uses Kafka in

00:04:21,370 --> 00:04:25,570
mission-critical applications and this

00:04:23,020 --> 00:04:26,800
includes the top banks insurance in

00:04:25,570 --> 00:04:30,970
travel companies

00:04:26,800 --> 00:04:33,900
and so we all know that we are on to

00:04:30,970 --> 00:04:37,030
something here I think all this data

00:04:33,900 --> 00:04:40,900
points to the emergence of this new

00:04:37,030 --> 00:04:43,060
phenomenon the streaming platform this

00:04:40,900 --> 00:04:47,110
is the thing that's powering these use

00:04:43,060 --> 00:04:49,479
cases this is the architecture of these

00:04:47,110 --> 00:04:51,879
technically savvy companies I think this

00:04:49,479 --> 00:04:53,650
is destined to be a major infrastructure

00:04:51,879 --> 00:04:56,530
platform that will exist in every

00:04:53,650 --> 00:04:58,900
company in the world but then what's the

00:04:56,530 --> 00:05:02,319
role of this streaming platform what is

00:04:58,900 --> 00:05:04,659
it supposed to do in a company the role

00:05:02,319 --> 00:05:07,330
of a streaming platform is to sit at the

00:05:04,659 --> 00:05:10,210
center of a company be able to

00:05:07,330 --> 00:05:12,069
interconnect all your micro services be

00:05:10,210 --> 00:05:14,560
able to capture streams of events from

00:05:12,069 --> 00:05:18,460
applications connect your data systems

00:05:14,560 --> 00:05:22,539
and do all that in real time and a

00:05:18,460 --> 00:05:25,180
global skill this streaming platform is

00:05:22,539 --> 00:05:27,310
what allows a company to have a central

00:05:25,180 --> 00:05:28,930
nervous system that allows capturing

00:05:27,310 --> 00:05:31,990
everything happening in your business in

00:05:28,930 --> 00:05:34,690
real time but then what does it look

00:05:31,990 --> 00:05:37,270
like there are a couple of core

00:05:34,690 --> 00:05:40,870
technical capabilities you need to have

00:05:37,270 --> 00:05:43,150
around streams of events the first is

00:05:40,870 --> 00:05:45,969
the ability to publish and subscribe to

00:05:43,150 --> 00:05:48,069
streams of data now we we've had

00:05:45,969 --> 00:05:50,860
messaging systems that have done this

00:05:48,069 --> 00:05:53,349
for a long time now I think the real

00:05:50,860 --> 00:05:56,590
difference now is the ability to store

00:05:53,349 --> 00:05:58,779
these streams of events and do that in a

00:05:56,590 --> 00:06:02,590
distributed replicated manner at scale

00:05:58,779 --> 00:06:06,370
and the final capability is the ability

00:06:02,590 --> 00:06:09,750
to process these streams of events to

00:06:06,370 --> 00:06:11,830
act as a Center for stream processing

00:06:09,750 --> 00:06:14,440
initially what started off as a

00:06:11,830 --> 00:06:16,870
messaging system caf-co today has

00:06:14,440 --> 00:06:19,330
evolved into being a full-fledged

00:06:16,870 --> 00:06:21,849
distributed streaming platform there

00:06:19,330 --> 00:06:25,630
embodies these characteristics of being

00:06:21,849 --> 00:06:28,630
one so now switching gears a little bit

00:06:25,630 --> 00:06:30,159
when people encounter this new idea of a

00:06:28,630 --> 00:06:32,560
streaming platform like some of you

00:06:30,159 --> 00:06:34,479
might be thinking now think they come

00:06:32,560 --> 00:06:37,630
from a variety of different backgrounds

00:06:34,479 --> 00:06:40,000
and each background lets them to viewing

00:06:37,630 --> 00:06:43,240
this technology in a slightly

00:06:40,000 --> 00:06:46,030
from where the first lens is the

00:06:43,240 --> 00:06:48,010
enterprise messaging lens you know there

00:06:46,030 --> 00:06:50,530
has been a whole category of software

00:06:48,010 --> 00:06:53,560
around real-time delivery of messages

00:06:50,530 --> 00:06:55,660
between applications and many people

00:06:53,560 --> 00:06:58,120
would think of Apache Kafka and more

00:06:55,660 --> 00:07:00,220
broadly a streaming platform is just an

00:06:58,120 --> 00:07:03,850
evolution of messaging though messaging

00:07:00,220 --> 00:07:06,910
done right if you might I think there is

00:07:03,850 --> 00:07:10,420
some truth to this view our streaming

00:07:06,910 --> 00:07:12,580
platform does support many of the kind

00:07:10,420 --> 00:07:15,970
of core applications that enterprise

00:07:12,580 --> 00:07:18,669
messaging system support and there are

00:07:15,970 --> 00:07:20,440
lots of initiatives out there to replace

00:07:18,669 --> 00:07:21,760
these enterprise messaging systems what

00:07:20,440 --> 00:07:26,169
of apache Kafka

00:07:21,760 --> 00:07:27,760
however thinking of Kafka as just a

00:07:26,169 --> 00:07:31,200
messaging system is overly limiting

00:07:27,760 --> 00:07:34,780
there are at least three big differences

00:07:31,200 --> 00:07:38,200
the first is that a streaming platform

00:07:34,780 --> 00:07:41,050
is built on a modern distributed systems

00:07:38,200 --> 00:07:44,110
foundation and can scale to the scope of

00:07:41,050 --> 00:07:46,300
an entire company whereas enterprise

00:07:44,110 --> 00:07:50,050
messaging systems were built to support

00:07:46,300 --> 00:07:53,320
a handful of applications now this might

00:07:50,050 --> 00:07:56,440
seem like a small difference but it

00:07:53,320 --> 00:07:58,900
completely changes the nature and the

00:07:56,440 --> 00:08:01,630
scope of what this platform is supposed

00:07:58,900 --> 00:08:04,120
to do for your company it isn't just the

00:08:01,630 --> 00:08:06,970
case that Kafka can handle more messages

00:08:04,120 --> 00:08:10,060
than enterprise messaging systems but

00:08:06,970 --> 00:08:13,210
it's that Kafka can act as a backbone

00:08:10,060 --> 00:08:16,210
for not just a handful of applications

00:08:13,210 --> 00:08:20,260
but for hundreds of thousands of micro

00:08:16,210 --> 00:08:22,300
services and because it has to prove

00:08:20,260 --> 00:08:25,120
inability to do that and some of the

00:08:22,300 --> 00:08:27,640
largest tech companies on earth it can

00:08:25,120 --> 00:08:31,300
act as a true integration plane for your

00:08:27,640 --> 00:08:33,370
company the second difference is that

00:08:31,300 --> 00:08:35,440
Kafka is a true storage system for

00:08:33,370 --> 00:08:37,060
streams of data there are Kafka clusters

00:08:35,440 --> 00:08:38,710
out there that store petabytes of data

00:08:37,060 --> 00:08:42,880
there are some that stored a time

00:08:38,710 --> 00:08:45,730
definitely this ability to store streams

00:08:42,880 --> 00:08:49,420
of data in a messaging system it didn't

00:08:45,730 --> 00:08:51,610
arrive in Kafka by accident we added

00:08:49,420 --> 00:08:54,180
that to solve one big problem that we

00:08:51,610 --> 00:08:57,640
envisioned a lot of companies

00:08:54,180 --> 00:09:00,370
which is integrating the batch analytics

00:08:57,640 --> 00:09:03,010
world with the online request/response

00:09:00,370 --> 00:09:05,410
world this is the ability that's

00:09:03,010 --> 00:09:08,020
required to integrate batch analytics

00:09:05,410 --> 00:09:10,750
with real-time messaging to have one

00:09:08,020 --> 00:09:14,950
unified way of processing all your data

00:09:10,750 --> 00:09:17,710
in real time the final difference

00:09:14,950 --> 00:09:19,570
between a Afghanistan platform and

00:09:17,710 --> 00:09:22,240
messaging is the ability to process

00:09:19,570 --> 00:09:24,460
these streams of data not only is this

00:09:22,240 --> 00:09:26,410
possible through the native streams API

00:09:24,460 --> 00:09:28,450
in Apache Kafka but there are lots of

00:09:26,410 --> 00:09:31,210
stream processing systems out there that

00:09:28,450 --> 00:09:33,100
are built to work with the streaming

00:09:31,210 --> 00:09:37,150
abstractions that Kafka provides out of

00:09:33,100 --> 00:09:39,910
the box okay so moving on to the second

00:09:37,150 --> 00:09:43,630
lens this is about a real-time version

00:09:39,910 --> 00:09:45,250
of Hadoop or even a warehouse I think

00:09:43,630 --> 00:09:48,550
there is some truth to this view as well

00:09:45,250 --> 00:09:51,460
after all just like a data warehouse or

00:09:48,550 --> 00:09:53,650
Hadoop Kafka can act as a place where

00:09:51,460 --> 00:09:55,300
data comes together from the rest of

00:09:53,650 --> 00:10:00,730
your organization in one central

00:09:55,300 --> 00:10:02,830
location in fact now Kafka also has the

00:10:00,730 --> 00:10:04,990
kind of rich sequel layer that you've

00:10:02,830 --> 00:10:08,110
come to expect from Hadoop or data

00:10:04,990 --> 00:10:10,570
warehouses Kay sequel is the open source

00:10:08,110 --> 00:10:13,120
streaming sequel engine for Apache Kafka

00:10:10,570 --> 00:10:15,970
it allows you to do sophisticated stream

00:10:13,120 --> 00:10:18,820
processing operations from stream table

00:10:15,970 --> 00:10:23,200
joins to aggregation session ization and

00:10:18,820 --> 00:10:26,470
a lot more I think something like Kay

00:10:23,200 --> 00:10:30,280
sequel is a big step forward in enabling

00:10:26,470 --> 00:10:32,200
a streaming first world with months of

00:10:30,280 --> 00:10:34,540
history stored in Apache Kafka and

00:10:32,200 --> 00:10:38,350
exactly ones processing now possible on

00:10:34,540 --> 00:10:40,150
it Kay sequel on Apache Kafka enables a

00:10:38,350 --> 00:10:43,660
lot more things that were previously not

00:10:40,150 --> 00:10:46,080
easily possible first is enabling

00:10:43,660 --> 00:10:49,090
real-time monitoring and analytics

00:10:46,080 --> 00:10:51,040
allowing you to shift away from batch

00:10:49,090 --> 00:10:53,740
analytics for things that are critical

00:10:51,040 --> 00:10:55,990
to your business the second is making

00:10:53,740 --> 00:10:57,820
streaming ETL possible natively in

00:10:55,990 --> 00:11:00,010
Apache Kafka so you don't have to duct

00:10:57,820 --> 00:11:02,640
tape together a bunch of bad GTL scripts

00:11:00,010 --> 00:11:06,130
to get data flowing and organization in

00:11:02,640 --> 00:11:07,390
short it is a true bridge between the

00:11:06,130 --> 00:11:11,860
batch analytics war

00:11:07,390 --> 00:11:14,470
and the online databases world so that

00:11:11,860 --> 00:11:16,779
means that there are some parallels

00:11:14,470 --> 00:11:20,110
between the Hadoop and data warehouse

00:11:16,779 --> 00:11:23,730
stack and Kafka now but the difference

00:11:20,110 --> 00:11:27,339
is that be it sequel queries or

00:11:23,730 --> 00:11:29,529
processing jobs or applications things

00:11:27,339 --> 00:11:32,829
that are built with Apache Kafka are

00:11:29,529 --> 00:11:35,350
naturally built to continuously update

00:11:32,829 --> 00:11:38,790
with every single event that arrives

00:11:35,350 --> 00:11:40,720
rather than in a batch fashion and that

00:11:38,790 --> 00:11:43,420
particular difference

00:11:40,720 --> 00:11:46,480
it changes the role of the streaming

00:11:43,420 --> 00:11:48,399
platform in an organization relative to

00:11:46,480 --> 00:11:51,130
what you might think Hadoop and data

00:11:48,399 --> 00:11:53,890
warehouse is supposed to do now data

00:11:51,130 --> 00:11:56,440
warehouses are very good at solving the

00:11:53,890 --> 00:11:59,350
traditional domains of a warehouse and

00:11:56,440 --> 00:12:00,970
why they were created to act as a Center

00:11:59,350 --> 00:12:04,450
for business intelligence and analytics

00:12:00,970 --> 00:12:06,459
I think a streaming platform is unlikely

00:12:04,450 --> 00:12:10,089
to displace later warehouses for what

00:12:06,459 --> 00:12:11,829
they are built to do but where a data

00:12:10,089 --> 00:12:13,930
warehouse and Hadoop point falls short

00:12:11,829 --> 00:12:16,029
is when you're trying to build

00:12:13,930 --> 00:12:20,350
applications that feed directly back

00:12:16,029 --> 00:12:23,560
into the business after all for creating

00:12:20,350 --> 00:12:28,089
reports a batch ETL script services and

00:12:23,560 --> 00:12:30,550
works just fine but for powering a much

00:12:28,089 --> 00:12:32,140
more real-time and richer customer

00:12:30,550 --> 00:12:34,660
experience it is a non-starter

00:12:32,140 --> 00:12:37,329
your customers do not understand 24

00:12:34,660 --> 00:12:39,610
hours stale data and the simple

00:12:37,329 --> 00:12:41,860
mechanics of building an application

00:12:39,610 --> 00:12:44,199
that depends on a batch ETL cycle

00:12:41,860 --> 00:12:48,190
feeding back into that application is

00:12:44,199 --> 00:12:51,220
extremely complex so then I think the

00:12:48,190 --> 00:12:54,100
domains and use cases where a streaming

00:12:51,220 --> 00:12:55,839
platform truly shines are the kinds of

00:12:54,100 --> 00:13:00,310
examples that I showed earlier in my

00:12:55,839 --> 00:13:04,589
talk these are not examples of things

00:13:00,310 --> 00:13:07,870
that involve reporting your business or

00:13:04,589 --> 00:13:12,070
analyzing it after the fact but it is

00:13:07,870 --> 00:13:14,410
very much about directly powering it so

00:13:12,070 --> 00:13:16,510
that brings me to the third and final

00:13:14,410 --> 00:13:19,060
lens for viewing a streaming platform

00:13:16,510 --> 00:13:20,610
and that is about ETL and data

00:13:19,060 --> 00:13:21,750
integration

00:13:20,610 --> 00:13:24,060
you know there have been a whole

00:13:21,750 --> 00:13:26,610
generation of technologies to handle

00:13:24,060 --> 00:13:29,310
data movement we've had enterprise

00:13:26,610 --> 00:13:33,630
integration tools and Enterprise Service

00:13:29,310 --> 00:13:36,750
buzzes that handle low quick slow data

00:13:33,630 --> 00:13:38,790
and then we've had ETL tools that

00:13:36,750 --> 00:13:42,300
handles scalable data flow but not in

00:13:38,790 --> 00:13:42,930
real time and so this gives us a hard

00:13:42,300 --> 00:13:45,120
choice

00:13:42,930 --> 00:13:49,190
you know scalability and flexibility on

00:13:45,120 --> 00:13:52,260
one hand and latency on the other I

00:13:49,190 --> 00:13:54,630
think one view of a streaming platform

00:13:52,260 --> 00:13:58,980
is kind of a unification and up

00:13:54,630 --> 00:14:01,680
levelling of this in Kafka the e and L

00:13:58,980 --> 00:14:04,500
or Kafka's Connect api's they allow you

00:14:01,680 --> 00:14:06,029
to build and use connectors to a variety

00:14:04,500 --> 00:14:08,010
of different systems and there are

00:14:06,029 --> 00:14:12,269
dozens of connectors out there that you

00:14:08,010 --> 00:14:15,930
can use today and the T is stream

00:14:12,269 --> 00:14:18,360
processing be it using kafka streams API

00:14:15,930 --> 00:14:21,899
or any other stream processing system

00:14:18,360 --> 00:14:24,899
available out there so there are

00:14:21,899 --> 00:14:28,140
parallels between this ETL view and a

00:14:24,899 --> 00:14:31,829
streaming platform as well but what the

00:14:28,140 --> 00:14:34,860
traditional ETL view misses is the use

00:14:31,829 --> 00:14:37,890
of this platform as an application

00:14:34,860 --> 00:14:40,320
development platform but streaming

00:14:37,890 --> 00:14:42,449
platform isn't just meant for getting

00:14:40,320 --> 00:14:46,199
data from place a to place B and

00:14:42,449 --> 00:14:47,880
munching it along the way it is a true

00:14:46,199 --> 00:14:50,370
infrastructure platform that allows

00:14:47,880 --> 00:14:55,019
building sophisticated applications on

00:14:50,370 --> 00:14:57,060
top of it you know these lenses in

00:14:55,019 --> 00:14:59,699
isolation they don't communicate the

00:14:57,060 --> 00:15:02,190
full picture they make it harder to see

00:14:59,699 --> 00:15:05,310
the full power of a streaming platform

00:15:02,190 --> 00:15:09,060
because each group has their own use

00:15:05,310 --> 00:15:10,709
cases and their own vocabulary but I

00:15:09,060 --> 00:15:12,899
think this is the process of

00:15:10,709 --> 00:15:15,690
understanding a new category of software

00:15:12,899 --> 00:15:17,519
in fact I think it is the hallmark of a

00:15:15,690 --> 00:15:20,190
new category where you have something

00:15:17,519 --> 00:15:24,839
that cuts across a number of use cases

00:15:20,190 --> 00:15:26,790
in a way that was impossible before so

00:15:24,839 --> 00:15:28,620
what does it look like when you can use

00:15:26,790 --> 00:15:32,970
the streaming platform and put into

00:15:28,620 --> 00:15:34,380
practice in an organization you have a

00:15:32,970 --> 00:15:36,810
real-time platform

00:15:34,380 --> 00:15:37,920
that powers applications like a

00:15:36,810 --> 00:15:41,370
messaging system

00:15:37,920 --> 00:15:45,930
the powers data flow like an ETL tool

00:15:41,370 --> 00:15:48,900
and that acts as a central hub for all

00:15:45,930 --> 00:15:53,220
data processing and analytics like

00:15:48,900 --> 00:15:54,510
Hadoop or a data warehouse cluster so

00:15:53,220 --> 00:15:57,630
what does the future hold

00:15:54,510 --> 00:15:59,490
I think the future here is pretty bright

00:15:57,630 --> 00:16:01,230
we are seeing tons of innovation

00:15:59,490 --> 00:16:02,820
happening in the stream processing space

00:16:01,230 --> 00:16:04,800
there are lots of stream processing

00:16:02,820 --> 00:16:06,690
systems out there and there are lots of

00:16:04,800 --> 00:16:10,010
streaming data services that are

00:16:06,690 --> 00:16:13,230
released by the public cloud provider

00:16:10,010 --> 00:16:15,570
confluence role is to make this

00:16:13,230 --> 00:16:17,160
streaming platform more accessible to

00:16:15,570 --> 00:16:19,230
companies make it something you can

00:16:17,160 --> 00:16:21,390
download and use and put into production

00:16:19,230 --> 00:16:25,050
quickly make it's something that you can

00:16:21,390 --> 00:16:27,960
use in a public cloud the confluent

00:16:25,050 --> 00:16:30,090
platform is meant to be a full open

00:16:27,960 --> 00:16:31,940
source streaming platform we believe as

00:16:30,090 --> 00:16:35,220
people want to create applications

00:16:31,940 --> 00:16:39,060
around a platform that is completely

00:16:35,220 --> 00:16:41,010
open the console platform is an open

00:16:39,060 --> 00:16:43,260
source distribution of Apache Kafka with

00:16:41,010 --> 00:16:45,630
all kinds of developer tools clients in

00:16:43,260 --> 00:16:47,960
various languages connectors to lots of

00:16:45,630 --> 00:16:50,730
different kinds of systems it is meant

00:16:47,960 --> 00:16:53,430
to get you started with Apache Kafka

00:16:50,730 --> 00:16:55,830
quickly and I'll say something I think

00:16:53,430 --> 00:16:58,170
this is not only important on premise

00:16:55,830 --> 00:17:01,170
but also in the public cloud it turns

00:16:58,170 --> 00:17:03,510
out that these two major trends which is

00:17:01,170 --> 00:17:06,240
the rise of real-time as part of

00:17:03,510 --> 00:17:08,310
digitization and the move to the public

00:17:06,240 --> 00:17:13,610
cloud they're happening at roughly the

00:17:08,310 --> 00:17:16,170
same time so what you want is a hosted

00:17:13,610 --> 00:17:18,839
streaming platform that is open that has

00:17:16,170 --> 00:17:20,790
open API is that you can program to so

00:17:18,839 --> 00:17:23,430
you can preserve the optionality of

00:17:20,790 --> 00:17:25,199
switching between cloud providers if you

00:17:23,430 --> 00:17:29,130
choose to without having to rewrite all

00:17:25,199 --> 00:17:31,650
the applications so that's the thesis

00:17:29,130 --> 00:17:34,290
that I would put forward that this

00:17:31,650 --> 00:17:36,420
streaming platform category is really

00:17:34,290 --> 00:17:38,520
going to be one of the biggest and most

00:17:36,420 --> 00:17:41,090
exciting new categories of

00:17:38,520 --> 00:17:43,590
infrastructure software during our time

00:17:41,090 --> 00:17:45,030
so if you think about your data as you

00:17:43,590 --> 00:17:47,280
go back to work think about your

00:17:45,030 --> 00:17:48,060
applications think about how the

00:17:47,280 --> 00:17:52,110
streaming

00:17:48,060 --> 00:17:55,380
form notion changes your view off using

00:17:52,110 --> 00:18:03,900
Apache Kafka in a company thank you very

00:17:55,380 --> 00:18:07,500
much if you don't mind one ask a couple

00:18:03,900 --> 00:18:10,380
questions of you so when you first got

00:18:07,500 --> 00:18:13,140
involved with Kafka you were you at

00:18:10,380 --> 00:18:15,900
LinkedIn at the time that's right eight

00:18:13,140 --> 00:18:19,530
years ago and so in charge of streaming

00:18:15,900 --> 00:18:21,510
there and so tell us how Kafka came

00:18:19,530 --> 00:18:23,490
about it's sort of your involvement and

00:18:21,510 --> 00:18:27,600
it was at one of these sort of scratch

00:18:23,490 --> 00:18:31,800
your own itch open source moments so I

00:18:27,600 --> 00:18:33,510
sort of came about even working on Kafka

00:18:31,800 --> 00:18:36,180
even thinking about it sort of by

00:18:33,510 --> 00:18:37,890
accident you know it was hired to work

00:18:36,180 --> 00:18:39,510
on search at LinkedIn and the thing

00:18:37,890 --> 00:18:41,400
about searches it's only useful if you

00:18:39,510 --> 00:18:44,670
have access to all the data in the

00:18:41,400 --> 00:18:46,680
company and that was the problem that we

00:18:44,670 --> 00:18:48,840
had at LinkedIn was there were two

00:18:46,680 --> 00:18:51,810
trends that were playing out one is that

00:18:48,840 --> 00:18:53,940
you know we needed all access to a lot

00:18:51,810 --> 00:18:57,270
more data sources than just the database

00:18:53,940 --> 00:18:59,790
feeds and there were a lot of

00:18:57,270 --> 00:19:02,040
distributed systems starting to be put

00:18:59,790 --> 00:19:03,810
into place you know Hadoop was one but

00:19:02,040 --> 00:19:06,510
then there was elastic and there were

00:19:03,810 --> 00:19:08,460
lots of systems and the question was you

00:19:06,510 --> 00:19:11,820
know how do you solve this n square data

00:19:08,460 --> 00:19:14,490
flow problem between applications of all

00:19:11,820 --> 00:19:16,380
sorts and systems of all sorts and the

00:19:14,490 --> 00:19:18,780
thing was enterprise messaging systems

00:19:16,380 --> 00:19:21,120
did not scale and the ETL tools were not

00:19:18,780 --> 00:19:22,920
real-time so we thought that you know

00:19:21,120 --> 00:19:25,560
there has to be a real platform that

00:19:22,920 --> 00:19:28,710
brought these two worlds together and we

00:19:25,560 --> 00:19:31,860
ended up creating Kafka very cool so you

00:19:28,710 --> 00:19:33,660
you are a big leader in open source and

00:19:31,860 --> 00:19:36,030
I know a lot of developers look up to

00:19:33,660 --> 00:19:38,490
you what advice would you give to

00:19:36,030 --> 00:19:40,650
someone who wants to get started in open

00:19:38,490 --> 00:19:42,900
source or participate in a project like

00:19:40,650 --> 00:19:43,920
Kafka what what any advice that you give

00:19:42,900 --> 00:19:45,990
because I know there are a lot of folks

00:19:43,920 --> 00:19:48,000
out here who are just getting started

00:19:45,990 --> 00:19:50,010
yeah I think the thing I like about open

00:19:48,000 --> 00:19:52,500
source is that it's you know

00:19:50,010 --> 00:19:55,080
fundamentally meritocratic by nature so

00:19:52,500 --> 00:19:57,690
this is what I have found useful is you

00:19:55,080 --> 00:20:00,810
can go read some dogs join the community

00:19:57,690 --> 00:20:01,770
ask questions and just take up some new

00:20:00,810 --> 00:20:04,230
v-0 and gets

00:20:01,770 --> 00:20:06,630
with it I know that a lot of open-source

00:20:04,230 --> 00:20:08,910
communities are pretty accepting or

00:20:06,630 --> 00:20:12,330
inviting to new developers I know Apache

00:20:08,910 --> 00:20:14,880
Kafka is but you do need some patience

00:20:12,330 --> 00:20:17,040
to stick with it because it's you know

00:20:14,880 --> 00:20:18,660
all for free commuters may not get to

00:20:17,040 --> 00:20:20,010
your patch immediately but that

00:20:18,660 --> 00:20:22,170
shouldn't be the thing that discourages

00:20:20,010 --> 00:20:23,600
you all right well good advice thank you

00:20:22,170 --> 00:20:27,260
so much for coming

00:20:23,600 --> 00:20:27,260

YouTube URL: https://www.youtube.com/watch?v=jdB1FLIDALs


