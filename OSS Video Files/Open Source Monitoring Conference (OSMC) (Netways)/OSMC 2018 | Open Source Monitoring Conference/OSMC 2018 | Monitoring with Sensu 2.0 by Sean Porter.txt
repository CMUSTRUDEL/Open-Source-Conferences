Title: OSMC 2018 | Monitoring with Sensu 2.0 by Sean Porter
Publication date: 2018-11-16
Playlist: OSMC 2018 | Open Source Monitoring Conference
Description: 
	Applications are complex systems. Their many moving parts, component and dependency services, may span any number of infrastructure technologies and platforms, from bare metal to serverless. As the number of services increases, teams responsible for them will naturally develop their own preferences, such as how they instrument their code or how and when they receive alerts. Sean will demonstrate how Sensu 2.0 is designed to monitor these ever changing heterogeneous environments. Sensu 2.0 is the next release of the open source monitoring framework, rewritten in Go, with new capabilities and reduced operational overhead. Sean will go over various patterns of data collection, including scraping Prometheus metrics, and show how Sensu enables self-service monitoring and alerting for service owners.


NETWAYS
Konferenzen: https://www.netways.de/events
Schulungen: https://www.netways.de/schulungen
Shop: https://shop.netways.de/
Blog: http://blog.netways.de/
NWS: https://nws.netways.de

Webinare
Archiv Link: https://www.netways.de/webinare/archi...
Aktuell: https://www.netways.de/wb

Social Media
SlideShare: http://de.slideshare.net/netways
YouTube: https://www.netways.de/youtube
Facebook: https://www.facebook.com/netways
Twitter: https://twitter.com/netways
Instagram: https://www.instagram.com/netwaysgmbh/

www.musicfox.com
Captions: 
	00:00:01,940 --> 00:00:13,270
[Music]

00:00:15,740 --> 00:00:22,470
hi hello so I'm just really curious who

00:00:20,160 --> 00:00:26,430
in the audience has heard of sensu put

00:00:22,470 --> 00:00:28,680
your hand out okay awesome so you've

00:00:26,430 --> 00:00:30,029
heard of it do you how many of you have

00:00:28,680 --> 00:00:35,130
a good understanding of what since you

00:00:30,029 --> 00:00:36,540
is and what it does fuer okay that's

00:00:35,130 --> 00:00:37,590
awesome I mean you're in the rim so

00:00:36,540 --> 00:00:40,800
clearly you've heard of it

00:00:37,590 --> 00:00:42,480
so yeah I'm Shawn Porter the original

00:00:40,800 --> 00:00:45,360
author of the sense you open source

00:00:42,480 --> 00:00:47,340
monitoring project and today I really

00:00:45,360 --> 00:00:50,789
want to just talk about since you where

00:00:47,340 --> 00:00:54,329
it's going what we're working on so yeah

00:00:50,789 --> 00:00:56,190
I I use Porter tech as my handle

00:00:54,329 --> 00:01:00,480
you can find me on Twitter or IRC or

00:00:56,190 --> 00:01:02,250
many different slack communities so

00:01:00,480 --> 00:01:04,739
we're all technologists right we we

00:01:02,250 --> 00:01:06,450
solve our problems with with technology

00:01:04,739 --> 00:01:08,760
so I really want to just talk about this

00:01:06,450 --> 00:01:11,990
problem space that we all live in on a

00:01:08,760 --> 00:01:16,110
daily basis have a remote I can move

00:01:11,990 --> 00:01:19,259
awesome but we also create new problems

00:01:16,110 --> 00:01:23,490
with technology right it's this vicious

00:01:19,259 --> 00:01:25,290
vicious cycle and a really good example

00:01:23,490 --> 00:01:28,049
of this is starting you know with how

00:01:25,290 --> 00:01:29,909
infrastructure has evolved to solve our

00:01:28,049 --> 00:01:34,979
delivery problems right so starting with

00:01:29,909 --> 00:01:36,900
bare metal I get it so we had a bare

00:01:34,979 --> 00:01:40,259
metal host right that we want to run one

00:01:36,900 --> 00:01:42,150
or more applications on it was fairly

00:01:40,259 --> 00:01:43,649
simple I mean we had some problems of

00:01:42,150 --> 00:01:45,689
like how do we get the apps on there how

00:01:43,649 --> 00:01:48,720
do we get apps off of it do we

00:01:45,689 --> 00:01:50,579
reprovision the host and we had some

00:01:48,720 --> 00:01:52,159
utilization problems so you know we

00:01:50,579 --> 00:01:55,530
wanted a greater sense of agility

00:01:52,159 --> 00:01:57,000
packaging deployment so we brought

00:01:55,530 --> 00:01:58,799
around this idea of virtual machines

00:01:57,000 --> 00:02:01,710
right how do we how do we cut up these

00:01:58,799 --> 00:02:05,189
bare metal machines in way they give us

00:02:01,710 --> 00:02:07,079
better isolation better flexibility how

00:02:05,189 --> 00:02:08,849
can we migrate these VMs from one bare

00:02:07,079 --> 00:02:11,489
metal host to the other still feel like

00:02:08,849 --> 00:02:12,959
that's a little magical but then we felt

00:02:11,489 --> 00:02:13,830
like that that didn't introduce enough

00:02:12,959 --> 00:02:16,530
problems we just

00:02:13,830 --> 00:02:18,780
to add containers to the story to get

00:02:16,530 --> 00:02:21,690
further isolation a little bit more

00:02:18,780 --> 00:02:23,250
around service management and then we we

00:02:21,690 --> 00:02:24,960
were able to package up our apps on that

00:02:23,250 --> 00:02:27,450
so really we end up with this this

00:02:24,960 --> 00:02:29,400
sandwich all the way down and you know

00:02:27,450 --> 00:02:32,160
some of our our organization has

00:02:29,400 --> 00:02:34,560
knowledge of which layers work and in

00:02:32,160 --> 00:02:36,090
and how they work but really it just

00:02:34,560 --> 00:02:37,740
becomes a little bit more complex I

00:02:36,090 --> 00:02:41,340
think this is true in our industry right

00:02:37,740 --> 00:02:43,920
you know complexity is ever-increasing I

00:02:41,340 --> 00:02:46,350
don't think it's like hyperbolic growth

00:02:43,920 --> 00:02:48,600
like I think it's fairly linear like it

00:02:46,350 --> 00:02:50,280
it's not getting super crazy super quick

00:02:48,600 --> 00:02:51,480
it's just a gradual increase in the

00:02:50,280 --> 00:02:54,030
amount of complexity that we deal with

00:02:51,480 --> 00:02:55,620
and I mean this is fine right I think we

00:02:54,030 --> 00:02:57,060
all come to terms with this this is what

00:02:55,620 --> 00:03:00,150
we do in the technology industry and

00:02:57,060 --> 00:03:02,910
then as exciting and entertaining but

00:03:00,150 --> 00:03:04,680
what makes this even more of an issue

00:03:02,910 --> 00:03:07,620
though is like these components going

00:03:04,680 --> 00:03:08,880
from you know a host which doesn't

00:03:07,620 --> 00:03:11,250
really change that off and you probably

00:03:08,880 --> 00:03:13,560
have 10 or 100 or 200 of them maybe a

00:03:11,250 --> 00:03:15,810
thousand to vm's which you're getting

00:03:13,560 --> 00:03:17,490
more of them to containers and these

00:03:15,810 --> 00:03:21,209
things are all shifting around now on

00:03:17,490 --> 00:03:23,790
top you know a ephemeral infrastructure

00:03:21,209 --> 00:03:25,920
becomes the normal thing this idea that

00:03:23,790 --> 00:03:29,010
we can scale out and scale back in on

00:03:25,920 --> 00:03:31,080
demand to meet up with you know seasonal

00:03:29,010 --> 00:03:32,760
traffic spikes that kind of thing this

00:03:31,080 --> 00:03:35,100
is this is the normal thing we see today

00:03:32,760 --> 00:03:36,690
and again I already mentioned this is

00:03:35,100 --> 00:03:40,230
the number of things we manage is also

00:03:36,690 --> 00:03:42,140
increasing so servers VMs containers now

00:03:40,230 --> 00:03:43,590
function calls on server list platforms

00:03:42,140 --> 00:03:45,269
it's fine

00:03:43,590 --> 00:03:48,390
I think this is where we're we're very

00:03:45,269 --> 00:03:50,489
comfortable multi-generational

00:03:48,390 --> 00:03:51,840
infrastructure is a thing right old is

00:03:50,489 --> 00:03:54,900
forever you know

00:03:51,840 --> 00:03:56,489
new is exciting but fleeting anything

00:03:54,900 --> 00:03:59,489
that we adopt today we're gonna probably

00:03:56,489 --> 00:04:03,980
be managing and maintaining for you know

00:03:59,489 --> 00:04:06,750
the next decade and the fact that

00:04:03,980 --> 00:04:08,630
applications span is full technology

00:04:06,750 --> 00:04:10,590
spectrum you know like as our

00:04:08,630 --> 00:04:13,470
organizations continue and our

00:04:10,590 --> 00:04:15,180
technology stack grows a good chance

00:04:13,470 --> 00:04:17,580
that your application touches many

00:04:15,180 --> 00:04:19,650
different generations of technology you

00:04:17,580 --> 00:04:24,090
know a good piece of evidence with this

00:04:19,650 --> 00:04:26,380
is IBM's mainframe business grew by 32

00:04:24,090 --> 00:04:30,060
percent in q4 of 2017

00:04:26,380 --> 00:04:33,790
I mean they're still selling mainframes

00:04:30,060 --> 00:04:36,160
so I think that's a good point to just

00:04:33,790 --> 00:04:37,570
keep in mind and that people are still

00:04:36,160 --> 00:04:41,530
deploying these technologies and

00:04:37,570 --> 00:04:42,490
maintaining them to further compound on

00:04:41,530 --> 00:04:43,960
this issue you know we have

00:04:42,490 --> 00:04:46,630
organizations that grow with this

00:04:43,960 --> 00:04:49,330
technology right and becomes larger we

00:04:46,630 --> 00:04:51,550
get silos within it we get those people

00:04:49,330 --> 00:04:53,440
with specific knowledge and preferences

00:04:51,550 --> 00:04:55,420
within a very small subset of our

00:04:53,440 --> 00:04:58,240
company communication between them might

00:04:55,420 --> 00:05:01,300
not be optimal so you you you end up

00:04:58,240 --> 00:05:03,310
with a need for multi-tenancy within

00:05:01,300 --> 00:05:05,380
your company so I think this is the

00:05:03,310 --> 00:05:09,940
reality that we you know I think we can

00:05:05,380 --> 00:05:11,440
all agree that we all now live in if you

00:05:09,940 --> 00:05:13,890
don't agree I want to know what that's

00:05:11,440 --> 00:05:17,770
like and come talk to me after this talk

00:05:13,890 --> 00:05:20,620
I might want to come work with you so my

00:05:17,770 --> 00:05:23,290
story so back in 2010 I joined a company

00:05:20,620 --> 00:05:25,330
called Sounion Sounion was an

00:05:23,290 --> 00:05:28,180
e-discovery or email archiving business

00:05:25,330 --> 00:05:31,450
I know super exciting but it was on on

00:05:28,180 --> 00:05:34,720
cloud infrastructure in 2010 and that

00:05:31,450 --> 00:05:36,430
was a know quite a big shift for what

00:05:34,720 --> 00:05:40,000
would traditionally be a very enterprise

00:05:36,430 --> 00:05:41,620
feeling company and organization so we

00:05:40,000 --> 00:05:44,400
were early adopters in many regards we

00:05:41,620 --> 00:05:47,590
used elastic before it was elasticsearch

00:05:44,400 --> 00:05:50,410
we really paved the way in terms of you

00:05:47,590 --> 00:05:53,110
know cloud automation on on ec2 as well

00:05:50,410 --> 00:05:57,430
as you know clouds that no longer exist

00:05:53,110 --> 00:05:59,740
like IBM SmartCloud and Rackspace so it

00:05:57,430 --> 00:06:01,210
was an interesting place and for me it

00:05:59,740 --> 00:06:03,700
was really cool as an operator because I

00:06:01,210 --> 00:06:06,070
ran into these new problems for me which

00:06:03,700 --> 00:06:07,540
is we have multiple clouds or public

00:06:06,070 --> 00:06:10,000
infrastructure we've got a ephemeral

00:06:07,540 --> 00:06:11,890
infrastructure consuming you know spot

00:06:10,000 --> 00:06:13,720
instances and auto-scaling groups to

00:06:11,890 --> 00:06:16,660
churn through to petabytes of data

00:06:13,720 --> 00:06:18,430
sitting on s3 and public networks you

00:06:16,660 --> 00:06:20,140
know not owning that Network stack not

00:06:18,430 --> 00:06:22,180
understanding how the underlying

00:06:20,140 --> 00:06:25,060
infrastructure has been laid beneath me

00:06:22,180 --> 00:06:28,480
and then service check investment you

00:06:25,060 --> 00:06:31,870
know I had a good amount of experience

00:06:28,480 --> 00:06:34,570
with operational monitoring tools in the

00:06:31,870 --> 00:06:37,030
service check space and a lot of those

00:06:34,570 --> 00:06:39,580
tools didn't work given the first three

00:06:37,030 --> 00:06:40,210
problems things just broke down because

00:06:39,580 --> 00:06:42,430
they were

00:06:40,210 --> 00:06:47,800
and in an era where these things simply

00:06:42,430 --> 00:06:49,690
weren't problems so enter July 20 2011 I

00:06:47,800 --> 00:06:52,570
created an open-source project on a

00:06:49,690 --> 00:06:55,660
weekend with a hunch that I could create

00:06:52,570 --> 00:06:58,419
you know I take a different approach to

00:06:55,660 --> 00:07:00,930
monitoring to be able to to monitor in

00:06:58,419 --> 00:07:04,630
this you know very ephemeral

00:07:00,930 --> 00:07:06,250
infrastructure and immediately after oh

00:07:04,630 --> 00:07:10,360
god I gotta take my phone in my pocket

00:07:06,250 --> 00:07:14,530
cause I'm tethering immediately after I

00:07:10,360 --> 00:07:18,009
got permission to publish under the very

00:07:14,530 --> 00:07:19,840
liberal MIT license for management and

00:07:18,009 --> 00:07:21,940
it became an open source project that

00:07:19,840 --> 00:07:23,889
people started to gravitate towards and

00:07:21,940 --> 00:07:25,389
what's interesting is they didn't

00:07:23,889 --> 00:07:27,759
necessarily contribute straight to the

00:07:25,389 --> 00:07:29,680
core of this product it started to

00:07:27,759 --> 00:07:32,440
create this ecosystem around at plugins

00:07:29,680 --> 00:07:34,360
and and dashboards and things to really

00:07:32,440 --> 00:07:35,710
consume the api's and that's what

00:07:34,360 --> 00:07:37,479
excited me greatly because it showed

00:07:35,710 --> 00:07:38,889
that it had value to people and people

00:07:37,479 --> 00:07:40,509
would then adopt it and start

00:07:38,889 --> 00:07:42,370
integrating it into their own projects

00:07:40,509 --> 00:07:45,580
and I think that's when I knew that this

00:07:42,370 --> 00:07:47,590
thing actually had some legs in February

00:07:45,580 --> 00:07:49,150
of 2013 I joined a company called heavy

00:07:47,590 --> 00:07:51,639
water we are DevOps automation

00:07:49,150 --> 00:07:53,349
consultancy and we're doing a lot of

00:07:51,639 --> 00:07:55,300
chef work puppet work and then

00:07:53,349 --> 00:07:56,710
eventually ansible and deploying since

00:07:55,300 --> 00:07:58,510
he was part of this like reference stack

00:07:56,710 --> 00:08:01,320
for monitoring for people moving from

00:07:58,510 --> 00:08:04,150
bare metal infrastructure onto the cloud

00:08:01,320 --> 00:08:08,970
ago really starting to experience the

00:08:04,150 --> 00:08:11,229
pain that I did in 2010 we found that

00:08:08,970 --> 00:08:13,300
when we're doing these projects for a

00:08:11,229 --> 00:08:15,039
larger like fortune 100 companies since

00:08:13,300 --> 00:08:17,409
he was extremely sticky and valuable to

00:08:15,039 --> 00:08:19,300
them so what we ended up doing was

00:08:17,409 --> 00:08:22,000
pivoting this company from heavy water

00:08:19,300 --> 00:08:23,800
which was consultancy to a company

00:08:22,000 --> 00:08:25,780
called sensu Inc which we just did

00:08:23,800 --> 00:08:28,210
sense.you and really the the overall

00:08:25,780 --> 00:08:30,970
thing here was that we want to create

00:08:28,210 --> 00:08:33,339
the next gen of sense you to take the

00:08:30,970 --> 00:08:35,620
project which is now 10 years old and

00:08:33,339 --> 00:08:37,510
set it up for another 10 years of

00:08:35,620 --> 00:08:38,890
success given the change in our

00:08:37,510 --> 00:08:41,020
infrastructure landscape right we've got

00:08:38,890 --> 00:08:43,479
kubernetes got openshift we've got even

00:08:41,020 --> 00:08:44,950
more ephemeral infrastructure and then

00:08:43,479 --> 00:08:47,610
things that are harder to model like how

00:08:44,950 --> 00:08:50,529
do we do extreme Microsystems or civilus

00:08:47,610 --> 00:08:53,320
so what I really want to show you today

00:08:50,529 --> 00:08:54,010
and talk about in demo is since you go

00:08:53,320 --> 00:08:55,750
which is this

00:08:54,010 --> 00:08:58,240
next product we've actually gone and

00:08:55,750 --> 00:09:01,720
rewritten sends you from the ground up

00:08:58,240 --> 00:09:03,490
one more time and go with a different

00:09:01,720 --> 00:09:05,680
architecture to address these new

00:09:03,490 --> 00:09:07,900
problems we're actually going GA with it

00:09:05,680 --> 00:09:11,470
at the end of November so we're it's

00:09:07,900 --> 00:09:14,290
going to become the main project that

00:09:11,470 --> 00:09:16,960
cincy drives so I really want to just

00:09:14,290 --> 00:09:18,730
talk about design quickly because I

00:09:16,960 --> 00:09:20,350
think this is what set sends you apart

00:09:18,730 --> 00:09:22,630
from other tools in the in the beginning

00:09:20,350 --> 00:09:24,100
and continues to do so so it's an

00:09:22,630 --> 00:09:25,540
agent-based monitoring system you run an

00:09:24,100 --> 00:09:27,520
agent on all the things that you want to

00:09:25,540 --> 00:09:30,430
monitor whether it be a host container

00:09:27,520 --> 00:09:31,990
VM and when it starts up it says hello

00:09:30,430 --> 00:09:34,840
I'm here here's some information about

00:09:31,990 --> 00:09:36,220
me I'm a Linux machine I've got my

00:09:34,840 --> 00:09:38,620
sequel running on me

00:09:36,220 --> 00:09:41,650
maybe a little Apache app you know some

00:09:38,620 --> 00:09:44,530
context there just to say Here I am this

00:09:41,650 --> 00:09:46,270
is who I am same can be said when that

00:09:44,530 --> 00:09:47,500
thing goes away or gets decommission er

00:09:46,270 --> 00:09:49,210
shuts down gracefully you can say

00:09:47,500 --> 00:09:51,550
goodbye I've done my duty

00:09:49,210 --> 00:09:53,290
I mean decommissioned this is extremely

00:09:51,550 --> 00:09:55,720
important today because again we scale

00:09:53,290 --> 00:09:58,870
out we also scale back down in at night

00:09:55,720 --> 00:10:01,660
that kind of thing or offseason we also

00:09:58,870 --> 00:10:03,280
expose a number of AP is in the agent so

00:10:01,660 --> 00:10:05,770
that we can ingest data from other

00:10:03,280 --> 00:10:07,480
things external sources and then that

00:10:05,770 --> 00:10:10,060
goes over the transport to a back-end

00:10:07,480 --> 00:10:11,980
the backend here can actually consume

00:10:10,060 --> 00:10:14,020
that data and do a little bit of state

00:10:11,980 --> 00:10:15,370
management expose it via an API and

00:10:14,020 --> 00:10:17,890
process it I'll get more into the

00:10:15,370 --> 00:10:19,450
details shortly the same API is exist in

00:10:17,890 --> 00:10:21,520
the backend so you don't actually need

00:10:19,450 --> 00:10:23,800
an agent to you sensor you can just use

00:10:21,520 --> 00:10:25,570
the backend component if if you choose

00:10:23,800 --> 00:10:29,710
and simply just throw data into its

00:10:25,570 --> 00:10:32,310
api's ingestion points since u is a

00:10:29,710 --> 00:10:35,260
scheduling platform as mentioned earlier

00:10:32,310 --> 00:10:38,980
you peek under any modern tool and it's

00:10:35,260 --> 00:10:42,130
yet another cron so since who is yet

00:10:38,980 --> 00:10:43,750
another cron system but it's a little

00:10:42,130 --> 00:10:45,670
bit more powerful and I'll explain why

00:10:43,750 --> 00:10:48,070
but basically it can instruct certain

00:10:45,670 --> 00:10:51,070
groups of agents to execute service

00:10:48,070 --> 00:10:52,510
checks which will then push data back so

00:10:51,070 --> 00:10:54,910
what makes sense.you unique is its

00:10:52,510 --> 00:10:57,910
pub/sub design its architecture in that

00:10:54,910 --> 00:10:59,290
a back-end can target groups of agents

00:10:57,910 --> 00:11:01,060
based on what are called subscriptions

00:10:59,290 --> 00:11:03,550
an agent when it comes up

00:11:01,060 --> 00:11:05,110
self-identifies is a system that has a

00:11:03,550 --> 00:11:07,140
set of subscriptions i'm a database

00:11:05,110 --> 00:11:09,480
server i'm an app server i'm a

00:11:07,140 --> 00:11:11,730
kubernetes hosts and then checks can

00:11:09,480 --> 00:11:13,920
target those subscriptions and and and

00:11:11,730 --> 00:11:16,170
go to those machines coordinated so if I

00:11:13,920 --> 00:11:17,760
target production only my agents in the

00:11:16,170 --> 00:11:19,920
production subscription will receive

00:11:17,760 --> 00:11:22,200
that check and publish the result back I

00:11:19,920 --> 00:11:25,110
can also do round-robin so I can say I

00:11:22,200 --> 00:11:27,240
need one agent within this group to run

00:11:25,110 --> 00:11:29,190
this check to collect this data this is

00:11:27,240 --> 00:11:31,260
extremely useful one you do you're doing

00:11:29,190 --> 00:11:34,019
network device monitoring I can say hey

00:11:31,260 --> 00:11:35,519
highly available group of agents I need

00:11:34,019 --> 00:11:37,440
one of you to execute this check right

00:11:35,519 --> 00:11:40,490
now on behalf of this external resource

00:11:37,440 --> 00:11:42,990
so it's a another really useful feature

00:11:40,490 --> 00:11:45,269
the backend itself can be clustered it

00:11:42,990 --> 00:11:47,519
can scale out agents can connect any one

00:11:45,269 --> 00:11:48,779
of the backends and they can failover to

00:11:47,519 --> 00:11:51,209
other ones you can also put a load

00:11:48,779 --> 00:11:53,730
balancer in front of the backends this

00:11:51,209 --> 00:11:57,450
connection is actually just a persistent

00:11:53,730 --> 00:12:00,660
TCP WebSocket connection

00:11:57,450 --> 00:12:04,800
TLS encrypted and yes so you can proxy

00:12:00,660 --> 00:12:06,899
it all communication is done over this

00:12:04,800 --> 00:12:09,540
transport with just events that get

00:12:06,899 --> 00:12:12,089
context enriched and added to and then

00:12:09,540 --> 00:12:14,760
it gets back and protest this is kind of

00:12:12,089 --> 00:12:17,820
what an event looks like you have a

00:12:14,760 --> 00:12:19,260
timestamp just an epoch timestamp you've

00:12:17,820 --> 00:12:20,579
got entities which can be used to

00:12:19,260 --> 00:12:22,399
represent anything that you want to

00:12:20,579 --> 00:12:24,390
monitor whether it be a container an

00:12:22,399 --> 00:12:26,040
application a function call within it

00:12:24,390 --> 00:12:29,820
you can just describe things with this

00:12:26,040 --> 00:12:31,829
this primitive called an entity actually

00:12:29,820 --> 00:12:34,140
and then you can have checks and metrics

00:12:31,829 --> 00:12:35,699
which I'll dive into shortly so the idea

00:12:34,140 --> 00:12:37,920
was sense you and this is where it's

00:12:35,699 --> 00:12:39,720
super power comes from is its back-end

00:12:37,920 --> 00:12:41,220
components so when events come in we

00:12:39,720 --> 00:12:44,190
store them in the database you can

00:12:41,220 --> 00:12:46,199
access to that data via the API having a

00:12:44,190 --> 00:12:47,850
REST API is extremely helpful because it

00:12:46,199 --> 00:12:50,430
helps you integrate with other tools and

00:12:47,850 --> 00:12:53,130
then you get this pipeline which allows

00:12:50,430 --> 00:12:55,500
you to filter certain data out mutate

00:12:53,130 --> 00:12:58,050
and transform data into other formats or

00:12:55,500 --> 00:12:59,699
scrape data or enrich it and then

00:12:58,050 --> 00:13:03,060
handlers to take action on it whether it

00:12:59,699 --> 00:13:05,850
be sending an email SMS provisioning

00:13:03,060 --> 00:13:09,360
additional infrastructure really you

00:13:05,850 --> 00:13:10,290
know more powerful actions so an event

00:13:09,360 --> 00:13:14,339
can actually go through multiple

00:13:10,290 --> 00:13:17,120
pipelines so if I run a check that looks

00:13:14,339 --> 00:13:19,589
at the state of something I can have it

00:13:17,120 --> 00:13:21,040
send data to multiple data sources so

00:13:19,589 --> 00:13:23,279
since you can integrate with

00:13:21,040 --> 00:13:26,380
I'm serious databases like in flux DB

00:13:23,279 --> 00:13:27,970
messaging systems like slack incident

00:13:26,380 --> 00:13:30,720
management systems like Pedro Duty and

00:13:27,970 --> 00:13:34,149
in log management systems like grey log

00:13:30,720 --> 00:13:36,610
and and that's part of senses power it

00:13:34,149 --> 00:13:38,199
becomes this like central hub for all of

00:13:36,610 --> 00:13:40,199
your monitoring data and then it can

00:13:38,199 --> 00:13:42,940
push it all out to different sources in

00:13:40,199 --> 00:13:43,779
interesting ways so a configuration for

00:13:42,940 --> 00:13:47,410
since he was done

00:13:43,779 --> 00:13:50,110
see how I'm on time awesome is done

00:13:47,410 --> 00:13:52,420
through the REST API so anything that

00:13:50,110 --> 00:13:54,040
talks that the API can configure it this

00:13:52,420 --> 00:13:56,920
is a sense you cuddle tool which allows

00:13:54,040 --> 00:13:58,449
operators from their laptops to interact

00:13:56,920 --> 00:14:01,139
with it similar to you would with

00:13:58,449 --> 00:14:03,160
kubernetes through cube CTO and a web UI

00:14:01,139 --> 00:14:07,899
for all those that don't want to live

00:14:03,160 --> 00:14:11,019
within the CLI we have role based access

00:14:07,899 --> 00:14:12,850
controls built into it and namespaces so

00:14:11,019 --> 00:14:15,069
you can have a single sense of install

00:14:12,850 --> 00:14:17,589
and slice it up for multiple silos

00:14:15,069 --> 00:14:19,500
within your organization so you can give

00:14:17,589 --> 00:14:22,600
a slice of your monitoring

00:14:19,500 --> 00:14:25,720
infrastructure to a dev team to a

00:14:22,600 --> 00:14:27,850
database team and they can effectively

00:14:25,720 --> 00:14:29,170
self-service themselves through that as

00:14:27,850 --> 00:14:31,360
well as get assistance from

00:14:29,170 --> 00:14:33,639
administrators so I can say hey I'm the

00:14:31,360 --> 00:14:36,310
ops team here's a standard set of checks

00:14:33,639 --> 00:14:39,089
here's your namespace have fun so they

00:14:36,310 --> 00:14:41,709
can add things customize things further

00:14:39,089 --> 00:14:43,060
so it's really all about like how does

00:14:41,709 --> 00:14:45,250
how does sense you enable an

00:14:43,060 --> 00:14:47,440
organization to get from a very

00:14:45,250 --> 00:14:50,139
distributed large system and get under

00:14:47,440 --> 00:14:52,149
you know one umbrella kind of thing all

00:14:50,139 --> 00:14:54,579
storage for state and configuration

00:14:52,149 --> 00:14:56,889
within since these back-end is actually

00:14:54,579 --> 00:15:00,610
a net CD and replicated amongst all

00:14:56,889 --> 00:15:03,220
back-end nodes so that means you know if

00:15:00,610 --> 00:15:05,079
you use the embedded at CD you just have

00:15:03,220 --> 00:15:07,600
to run the backend and you can run one

00:15:05,079 --> 00:15:09,699
three or five nodes or you can run a

00:15:07,600 --> 00:15:12,550
separate at CD cluster outside of sensu

00:15:09,699 --> 00:15:15,250
and then it's completely detached which

00:15:12,550 --> 00:15:16,540
separates your concerns but it just ends

00:15:15,250 --> 00:15:19,120
up being one more service that you have

00:15:16,540 --> 00:15:21,040
to maintain separately so three methods

00:15:19,120 --> 00:15:22,930
of collection service checks we're all

00:15:21,040 --> 00:15:24,759
very familiar with these it's a script

00:15:22,930 --> 00:15:27,550
standard out exit status code and

00:15:24,759 --> 00:15:29,230
Keith's severity check my sequel so

00:15:27,550 --> 00:15:31,269
since you can use all of Nagios our

00:15:29,230 --> 00:15:33,130
icing and plugins as well as since use

00:15:31,269 --> 00:15:34,150
community plugins there's a few hundred

00:15:33,130 --> 00:15:36,220
of them

00:15:34,150 --> 00:15:38,160
so a vast ecosystem that you can

00:15:36,220 --> 00:15:40,030
leverage again it's it's all about

00:15:38,160 --> 00:15:42,840
determine whether something's up or down

00:15:40,030 --> 00:15:46,810
here's an example event that contains

00:15:42,840 --> 00:15:48,700
some an execution so I could tell an

00:15:46,810 --> 00:15:50,560
agent I need you to run this this check

00:15:48,700 --> 00:15:51,850
it'll run it and populate some event

00:15:50,560 --> 00:15:54,940
data that gets stuck through goes

00:15:51,850 --> 00:15:56,640
through the back-end pipeline so it's

00:15:54,940 --> 00:15:58,840
really all about like how do we monitor

00:15:56,640 --> 00:16:01,420
symptoms in your infrastructure whether

00:15:58,840 --> 00:16:03,700
something is up or down or showing signs

00:16:01,420 --> 00:16:06,430
that it's going to be in trouble and

00:16:03,700 --> 00:16:08,410
then since you handles this very simple

00:16:06,430 --> 00:16:12,040
state machine maintains some sort of

00:16:08,410 --> 00:16:15,100
historical context for that that for

00:16:12,040 --> 00:16:17,410
those symptoms the other important thing

00:16:15,100 --> 00:16:20,580
to point out is Negus plugins from long

00:16:17,410 --> 00:16:22,600
time has this idea of you know perf data

00:16:20,580 --> 00:16:24,670
earlier today I was mentioned that we

00:16:22,600 --> 00:16:26,350
throw ridiculous balance out there

00:16:24,670 --> 00:16:28,000
because really what we actually wanted

00:16:26,350 --> 00:16:29,230
was just to get this data and what's

00:16:28,000 --> 00:16:31,960
cool is since you've supports the

00:16:29,230 --> 00:16:35,290
ability to extract this data and we can

00:16:31,960 --> 00:16:36,790
and create events with metric metric

00:16:35,290 --> 00:16:38,230
format which supports multiple

00:16:36,790 --> 00:16:39,520
dimensions and then we can do

00:16:38,230 --> 00:16:42,310
interesting things with it like stored

00:16:39,520 --> 00:16:45,400
it in flux or graphite or Open TS DB or

00:16:42,310 --> 00:16:47,170
all the above which is really

00:16:45,400 --> 00:16:50,710
interesting so we can do more with a

00:16:47,170 --> 00:16:52,570
perf data than we could existing one big

00:16:50,710 --> 00:16:54,580
problem with service checks however is

00:16:52,570 --> 00:16:56,710
dependency management again this morning

00:16:54,580 --> 00:16:58,480
that got called out I should really just

00:16:56,710 --> 00:17:01,810
put your talk up as like a preamble for

00:16:58,480 --> 00:17:03,790
mine it's wonderful is that when you

00:17:01,810 --> 00:17:05,440
instruct a machine to run a check you

00:17:03,790 --> 00:17:07,120
know it needs scripts and plugins and

00:17:05,440 --> 00:17:09,370
dependencies locally in order to be able

00:17:07,120 --> 00:17:11,140
to run it so since you solves this

00:17:09,370 --> 00:17:13,680
problem with what's called assets

00:17:11,140 --> 00:17:16,630
effectively web resources that you can

00:17:13,680 --> 00:17:18,640
identifies dependencies for a check to

00:17:16,630 --> 00:17:21,090
run so this might be a tar file with a

00:17:18,640 --> 00:17:24,610
bin directory that contains one or more

00:17:21,090 --> 00:17:27,130
binaries and what since you will do is

00:17:24,610 --> 00:17:29,680
it's associated with a check the agent

00:17:27,130 --> 00:17:32,560
will fetch it verify the integrity with

00:17:29,680 --> 00:17:34,240
512 checksum you know using SSL there if

00:17:32,560 --> 00:17:37,830
I peer to make sure that you're not

00:17:34,240 --> 00:17:40,480
you're not fetching a unsafe asset

00:17:37,830 --> 00:17:42,460
extract it to a sandbox add it to the

00:17:40,480 --> 00:17:45,130
run path and then then execute it so

00:17:42,460 --> 00:17:47,140
really it's all about dynamic dependency

00:17:45,130 --> 00:17:47,920
management through the monitoring tool

00:17:47,140 --> 00:17:49,630
itself so service

00:17:47,920 --> 00:17:52,420
checks are extremely since simple

00:17:49,630 --> 00:17:54,730
accessible shareable as well as there's

00:17:52,420 --> 00:17:57,130
such a vast variety of plugins out there

00:17:54,730 --> 00:17:58,540
really anything under the Sun I mean

00:17:57,130 --> 00:18:01,600
there now you just plug in yeah there's

00:17:58,540 --> 00:18:02,800
like 2,000 plugins or something if

00:18:01,600 --> 00:18:04,090
there's a device out there there's got

00:18:02,800 --> 00:18:05,470
to be some script somewhere that

00:18:04,090 --> 00:18:08,110
somebody's written I can monitor it so

00:18:05,470 --> 00:18:11,440
events API I mentioned this earlier in

00:18:08,110 --> 00:18:13,930
the design section really it's just a

00:18:11,440 --> 00:18:15,510
way that you can manage entities to

00:18:13,930 --> 00:18:18,280
describe objects you want to monitor

00:18:15,510 --> 00:18:19,930
external checks so you can have things

00:18:18,280 --> 00:18:22,090
like backup scripts right to it and then

00:18:19,930 --> 00:18:24,520
metric collection so here's some

00:18:22,090 --> 00:18:26,310
examples so here I am just creating an

00:18:24,520 --> 00:18:29,350
event to register an entity called

00:18:26,310 --> 00:18:31,510
Leviathan which is an application so I

00:18:29,350 --> 00:18:34,950
can I can describe things I could also

00:18:31,510 --> 00:18:37,870
do this for my network gear my routers

00:18:34,950 --> 00:18:40,150
databases you know even AWS services I

00:18:37,870 --> 00:18:43,450
can model them in this way Here I am

00:18:40,150 --> 00:18:45,730
having a backup script that failed emit

00:18:43,450 --> 00:18:49,150
an event to sense you saying hey I

00:18:45,730 --> 00:18:51,670
failed here's why I failed tell somebody

00:18:49,150 --> 00:18:54,160
about it I can also set a TTL this one

00:18:51,670 --> 00:18:55,870
is just saying six hours that expect

00:18:54,160 --> 00:18:58,090
another result from me within six hours

00:18:55,870 --> 00:19:00,790
if not raise an alarm effectively a

00:18:58,090 --> 00:19:03,010
Deadman switch right so we can know that

00:19:00,790 --> 00:19:04,900
this backup script is expected to run on

00:19:03,010 --> 00:19:08,110
a regular basis and we're supposed to

00:19:04,900 --> 00:19:11,760
get data from it here's an example of an

00:19:08,110 --> 00:19:13,870
application or in this case this is the

00:19:11,760 --> 00:19:17,980
copy of the slide from the perf data

00:19:13,870 --> 00:19:19,570
example but emitting some information

00:19:17,980 --> 00:19:20,550
about my sequel and writing it to in

00:19:19,570 --> 00:19:23,230
flux dB

00:19:20,550 --> 00:19:25,180
another method of data collection the

00:19:23,230 --> 00:19:26,590
sense of agent has a stats D listener on

00:19:25,180 --> 00:19:28,930
it if you're familiar with this it's a

00:19:26,590 --> 00:19:31,480
very simple line protocol if you're not

00:19:28,930 --> 00:19:34,060
familiar with it I mean that you can use

00:19:31,480 --> 00:19:36,130
to increment counters and measure things

00:19:34,060 --> 00:19:37,930
with gauges and it does some stats

00:19:36,130 --> 00:19:39,910
aggregation this is an example of the

00:19:37,930 --> 00:19:41,380
line protocol it's actually very

00:19:39,910 --> 00:19:45,130
straightforward and powerful it just

00:19:41,380 --> 00:19:46,660
over UDP and what it sensu agent will

00:19:45,130 --> 00:19:48,520
actually do is take that stats D

00:19:46,660 --> 00:19:50,950
protocol transform it into this

00:19:48,520 --> 00:19:52,750
normalized metric format and then that

00:19:50,950 --> 00:19:54,670
goes to your sensory pipeline so it's

00:19:52,750 --> 00:19:56,920
all about you know this giant funnel of

00:19:54,670 --> 00:19:58,240
how do we get all this data into the

00:19:56,920 --> 00:20:00,040
sensory pipeline and then the sensory

00:19:58,240 --> 00:20:01,419
pipelines all about what do we do with

00:20:00,040 --> 00:20:03,399
this data what do we care about

00:20:01,419 --> 00:20:05,139
what do we drop in the floor what do we

00:20:03,399 --> 00:20:05,999
elevate what do we send out kind of

00:20:05,139 --> 00:20:09,879
thing

00:20:05,999 --> 00:20:12,729
so I actually just want to make sure

00:20:09,879 --> 00:20:19,450
that I can I can do a live demo once my

00:20:12,729 --> 00:20:22,049
talk until awesome all right I've got

00:20:19,450 --> 00:20:24,820
you all stuck in here for a long time

00:20:22,049 --> 00:20:26,889
all right so I hope you can see this

00:20:24,820 --> 00:20:28,779
okay let's just get that down there

00:20:26,889 --> 00:20:32,169
all right so this I'm gonna take you on

00:20:28,779 --> 00:20:34,559
a journey through my terminal so all my

00:20:32,169 --> 00:20:37,479
local laptop I have a very trivial

00:20:34,559 --> 00:20:38,889
community set up so hopefully you don't

00:20:37,479 --> 00:20:40,869
have to understand kubernetes to

00:20:38,889 --> 00:20:42,849
understand this demo but I'm just using

00:20:40,869 --> 00:20:45,700
it as a way of demonstrating how since

00:20:42,849 --> 00:20:48,159
he works in a very ephemeral environment

00:20:45,700 --> 00:20:51,519
it's also just a fun way to script up

00:20:48,159 --> 00:20:54,099
demos some information about my

00:20:51,519 --> 00:20:56,709
kubernetes deployment very simple I've

00:20:54,099 --> 00:20:59,469
got helm there I'm not using it there's

00:20:56,709 --> 00:21:01,329
a thing called cube steep metrics which

00:20:59,469 --> 00:21:03,399
is a service all I'll demonstrate how

00:21:01,329 --> 00:21:05,169
it's used later but basically what it

00:21:03,399 --> 00:21:06,700
does is measure some things about kerbin

00:21:05,169 --> 00:21:09,489
AIDS and expose it via Prometheus

00:21:06,700 --> 00:21:11,109
endpoint just so I know you know how

00:21:09,489 --> 00:21:13,450
many pods have been provisioned how many

00:21:11,109 --> 00:21:15,239
are in what state that kind of thing all

00:21:13,450 --> 00:21:19,059
right so for the purpose of this demo

00:21:15,239 --> 00:21:23,339
I'm gonna go ahead and deploy an app

00:21:19,059 --> 00:21:28,989
that I've a Polly named dummy

00:21:23,339 --> 00:21:30,369
so the dummy app is a web service if

00:21:28,989 --> 00:21:35,769
you're not familiar Bernays I just

00:21:30,369 --> 00:21:38,709
deployed containers so if I curl I don't

00:21:35,769 --> 00:21:40,779
want to give that away so if I curl the

00:21:38,709 --> 00:21:44,019
dummy app service it's exposed via this

00:21:40,779 --> 00:21:45,759
this DNS record I can see that there's

00:21:44,019 --> 00:21:49,419
two instances it's being load-balanced

00:21:45,759 --> 00:21:53,320
between the two and what's interesting

00:21:49,419 --> 00:21:56,849
about this is that oh boy okay let me

00:21:53,320 --> 00:21:56,849
just type this out the old-fashioned way

00:21:58,109 --> 00:22:04,119
this app exposes a healthy endpoint

00:22:01,599 --> 00:22:05,440
which does one thing really is it says a

00:22:04,119 --> 00:22:08,259
string whether it's healthier and a

00:22:05,440 --> 00:22:12,940
healthy uses a status code 200 for okay

00:22:08,259 --> 00:22:15,040
500 for failing if I post to it I can I

00:22:12,940 --> 00:22:16,930
just cause a failure so if I

00:22:15,040 --> 00:22:18,430
rotate it we can see one is healthy now

00:22:16,930 --> 00:22:20,500
one is unhealthy damn that's really

00:22:18,430 --> 00:22:24,700
small let's see if we can meet was a

00:22:20,500 --> 00:22:28,360
little larger for you and if I post

00:22:24,700 --> 00:22:31,150
again ill it'll see now they're both

00:22:28,360 --> 00:22:32,350
unhealthy that's unfortunate and now

00:22:31,150 --> 00:22:35,320
let's get them both healthy again

00:22:32,350 --> 00:22:37,240
awesome so that's our dummy app it's

00:22:35,320 --> 00:22:38,740
just responding returns its hostname and

00:22:37,240 --> 00:22:40,750
housing health CN point it also has a

00:22:38,740 --> 00:22:42,640
slash metrics endpoint

00:22:40,750 --> 00:22:46,300
so I've instrumented it with the

00:22:42,640 --> 00:22:48,960
Prometheus golang instrumentation tool

00:22:46,300 --> 00:22:52,750
so we're getting some you know some go

00:22:48,960 --> 00:22:56,350
program telemetry here so that that's

00:22:52,750 --> 00:22:58,540
that's it on on the application side if

00:22:56,350 --> 00:23:00,460
I do get pods we can just see the two

00:22:58,540 --> 00:23:03,070
instances there so what I want to do

00:23:00,460 --> 00:23:05,410
next is deploy since you go the new

00:23:03,070 --> 00:23:09,310
version of sense you that's giing

00:23:05,410 --> 00:23:15,220
at the end of this month so let's just

00:23:09,310 --> 00:23:17,320
go ahead and deploy that so I'm just

00:23:15,220 --> 00:23:21,790
applying a single instance here if I do

00:23:17,320 --> 00:23:24,130
get pods I can see I've just deployed

00:23:21,790 --> 00:23:26,800
since you back in it's up and running

00:23:24,130 --> 00:23:28,690
that's cool I'm gonna use that since you

00:23:26,800 --> 00:23:30,520
cuddle tool I mentioned earlier to

00:23:28,690 --> 00:23:32,800
interact with it so what I'm gonna do is

00:23:30,520 --> 00:23:35,770
run configure and it's gonna prompt me

00:23:32,800 --> 00:23:37,330
for some information about my install it

00:23:35,770 --> 00:23:40,750
remembers that from last time there's a

00:23:37,330 --> 00:23:42,460
built-in user called admin and I'm gonna

00:23:40,750 --> 00:23:46,390
try to remember the overly-complicated

00:23:42,460 --> 00:23:48,820
default password and here we go on that

00:23:46,390 --> 00:23:50,950
the multi-tenancy stuff so right now

00:23:48,820 --> 00:23:52,630
it's organization and then environment

00:23:50,950 --> 00:23:54,550
within it I'm gonna use the default

00:23:52,630 --> 00:23:57,310
default and then I'll walk us through

00:23:54,550 --> 00:24:00,480
just creating a a new environment so if

00:23:57,310 --> 00:24:02,860
I do is since you cuddle entity doest

00:24:00,480 --> 00:24:06,280
we can see what we're monitoring which

00:24:02,860 --> 00:24:08,770
is nothing right so that's it though

00:24:06,280 --> 00:24:10,180
we've we've deployed a sense you back in

00:24:08,770 --> 00:24:12,000
we've got the pipeline up and running

00:24:10,180 --> 00:24:17,170
we've authenticated with my CLI and

00:24:12,000 --> 00:24:21,190
actually if I switch over here alright

00:24:17,170 --> 00:24:23,290
how do we get out escape hate the touch

00:24:21,190 --> 00:24:29,170
bar on this thing

00:24:23,290 --> 00:24:31,660
if we go to web UI oh thank you

00:24:29,170 --> 00:24:36,100
so here's the the back end also has a

00:24:31,660 --> 00:24:38,140
web UI if we log in here sweet its cache

00:24:36,100 --> 00:24:43,360
things from my last time awesome good

00:24:38,140 --> 00:24:44,860
job shown do it for the purpose of this

00:24:43,360 --> 00:24:49,150
talk I'll use Safari which I haven't

00:24:44,860 --> 00:24:53,010
launched in a very long time oh god it's

00:24:49,150 --> 00:24:53,010
got some cash too alright here we go

00:24:53,520 --> 00:25:00,040
wicked alright so here we can see the

00:24:56,260 --> 00:25:02,500
very basic web UI what's interesting is

00:25:00,040 --> 00:25:04,000
it's multi-tenant as well so I can

00:25:02,500 --> 00:25:05,890
switch currently there's only the

00:25:04,000 --> 00:25:08,170
default org and environment so let's go

00:25:05,890 --> 00:25:10,480
ahead and start to build out this

00:25:08,170 --> 00:25:13,150
deployment a little bit so I'm gonna go

00:25:10,480 --> 00:25:16,090
ahead and create an organization so this

00:25:13,150 --> 00:25:19,780
is top-level kind of business units

00:25:16,090 --> 00:25:22,600
generally get organization we're gonna

00:25:19,780 --> 00:25:24,970
call it acne and then I'm gonna go ahead

00:25:22,600 --> 00:25:26,980
and set as my default so when I'm

00:25:24,970 --> 00:25:29,380
interacting with sense.you it's gonna

00:25:26,980 --> 00:25:32,650
know that I'm gonna talk to this one by

00:25:29,380 --> 00:25:36,940
default okay now let's create a

00:25:32,650 --> 00:25:39,460
environment within it and what's really

00:25:36,940 --> 00:25:41,260
cool about the since you cuddle is that

00:25:39,460 --> 00:25:43,450
has an interactive mode so it'll prompt

00:25:41,260 --> 00:25:46,590
me for for the flags I don't need to

00:25:43,450 --> 00:25:49,480
know everything out of the box so demo

00:25:46,590 --> 00:25:52,660
it knows I'm defaulting to acne so it's

00:25:49,480 --> 00:25:54,700
just clear the demo environment okay

00:25:52,660 --> 00:26:01,720
that's all so just quickly set that is

00:25:54,700 --> 00:26:03,040
our default wicked alright because I'm

00:26:01,720 --> 00:26:06,850
lazy I'm going to use Michelle history

00:26:03,040 --> 00:26:09,220
here I'm gonna create a role called dev

00:26:06,850 --> 00:26:10,900
that has full read/write access to this

00:26:09,220 --> 00:26:18,550
organization and that environment within

00:26:10,900 --> 00:26:21,400
it I am then going to create a user I'm

00:26:18,550 --> 00:26:23,290
going to create a user called demo I'm

00:26:21,400 --> 00:26:26,470
gonna set the super-secretive password

00:26:23,290 --> 00:26:28,840
of password give them the dev access so

00:26:26,470 --> 00:26:30,640
now this person demo has full rewrite

00:26:28,840 --> 00:26:32,680
access to that slice if they try to

00:26:30,640 --> 00:26:34,240
manipulate other namespaces of the sense

00:26:32,680 --> 00:26:35,830
you install they won't be able to do it

00:26:34,240 --> 00:26:36,670
nor can they see data that gets

00:26:35,830 --> 00:26:39,620
published there

00:26:36,670 --> 00:26:49,160
I'm gonna go ahead and reconfigure my

00:26:39,620 --> 00:26:51,170
tool to use it wicked if we do list

00:26:49,160 --> 00:26:52,730
again nothing's monitored all right so

00:26:51,170 --> 00:26:55,400
that we've now set up a multi-tenant

00:26:52,730 --> 00:27:03,290
sensu deployment let's go ahead and

00:26:55,400 --> 00:27:06,620
deploy see we want to now deploy a

00:27:03,290 --> 00:27:08,450
sidecar so basically what we're gonna do

00:27:06,620 --> 00:27:11,000
this is a common pattern on kubernetes

00:27:08,450 --> 00:27:15,080
and other container platforms is you

00:27:11,000 --> 00:27:17,540
deploy a sidecar what it's called or a

00:27:15,080 --> 00:27:19,880
dependent dependency service in tandem

00:27:17,540 --> 00:27:21,110
with your application container if we do

00:27:19,880 --> 00:27:22,760
this we're going to deploy sense.you

00:27:21,110 --> 00:27:27,640
agent for each of those dummy app

00:27:22,760 --> 00:27:29,750
instances out there so ideally if I run

00:27:27,640 --> 00:27:31,490
entity list we can see that they've now

00:27:29,750 --> 00:27:34,730
registered themselves with the sensu

00:27:31,490 --> 00:27:37,100
system you can also create agents agent

00:27:34,730 --> 00:27:39,320
users which have limited access to

00:27:37,100 --> 00:27:41,540
certain namespaces in this case this

00:27:39,320 --> 00:27:45,560
agent user has the ability to connect

00:27:41,540 --> 00:27:47,510
and write data into Acme demo so here we

00:27:45,560 --> 00:27:50,180
go so we've got these things under

00:27:47,510 --> 00:27:52,040
management if I do an event list we can

00:27:50,180 --> 00:27:53,600
see we're getting keeper lives so this

00:27:52,040 --> 00:27:55,280
is the mechanism that we know that

00:27:53,600 --> 00:27:56,600
agents are still out there and alive

00:27:55,280 --> 00:27:58,520
they're effectively like a heartbeat

00:27:56,600 --> 00:28:01,460
mechanism if they were to fail to check

00:27:58,520 --> 00:28:03,500
in since we will raise an event that can

00:28:01,460 --> 00:28:04,940
then go out to like email pager duty

00:28:03,500 --> 00:28:07,910
that kind of thing to say hey this thing

00:28:04,940 --> 00:28:10,730
is supposed to be checking in ok let's

00:28:07,910 --> 00:28:11,840
create a an event handler so we probably

00:28:10,730 --> 00:28:17,420
want to be able to send messages

00:28:11,840 --> 00:28:19,430
somewhere let's see so what's really

00:28:17,420 --> 00:28:25,670
neat about since you cuddled two is that

00:28:19,430 --> 00:28:29,180
it can read config files from disk much

00:28:25,670 --> 00:28:31,160
as just like cube CTL for kubernetes so

00:28:29,180 --> 00:28:33,050
here I have an asset earlier I mentioned

00:28:31,160 --> 00:28:35,330
how assets could be used for check

00:28:33,050 --> 00:28:36,920
runtime dependencies same thing could be

00:28:35,330 --> 00:28:39,170
used for pipeline components so here I

00:28:36,920 --> 00:28:40,370
have a slack handler basically this is

00:28:39,170 --> 00:28:42,230
where it is on the internet it's a

00:28:40,370 --> 00:28:45,680
tarball that includes standard Linux

00:28:42,230 --> 00:28:46,760
directories here's a 512 some and we're

00:28:45,680 --> 00:28:49,059
going to create it within the Acme

00:28:46,760 --> 00:28:51,249
organization so

00:28:49,059 --> 00:28:55,659
much like cube cuddle you can do sense a

00:28:51,249 --> 00:28:58,479
cuddle creak - F give it the file

00:28:55,659 --> 00:29:02,889
I actually just create this handler last

00:28:58,479 --> 00:29:04,599
night so hopefully it works all right so

00:29:02,889 --> 00:29:07,139
that created the asset so now we can

00:29:04,599 --> 00:29:10,259
actually go ahead and create the handler

00:29:07,139 --> 00:29:13,779
so this handler is basically gonna say

00:29:10,259 --> 00:29:15,699
event checks that use me as a handler

00:29:13,779 --> 00:29:17,979
I'm going to create I'm going to send

00:29:15,699 --> 00:29:22,679
incident notifications to slack if that

00:29:17,979 --> 00:29:26,589
makes sense so let's create that handler

00:29:22,679 --> 00:29:32,999
wicked let me just check what we did

00:29:26,589 --> 00:29:35,349
there we're gonna debug this together oh

00:29:32,999 --> 00:29:44,309
yeah you're also getting my secrets

00:29:35,349 --> 00:29:46,389
right now sweet greetings weak slack

00:29:44,309 --> 00:29:51,339
invalid that that's a really helpful

00:29:46,389 --> 00:29:57,279
hear her message right is it is it

00:29:51,339 --> 00:30:00,279
getting escaped out good eye good eye

00:29:57,279 --> 00:30:04,569
that's why I have you here let's try

00:30:00,279 --> 00:30:09,819
that now wicked bonus points a round of

00:30:04,569 --> 00:30:14,469
applause actually thank you so now if I

00:30:09,819 --> 00:30:16,539
do handler info slack we can see that

00:30:14,469 --> 00:30:18,309
we've created with since you cuddled

00:30:16,539 --> 00:30:19,989
through the REST API we've registered a

00:30:18,309 --> 00:30:22,479
component the backend so that's created

00:30:19,989 --> 00:30:25,569
check now before we do that let's see

00:30:22,479 --> 00:30:31,299
you since you cuddle create - F config

00:30:25,569 --> 00:30:34,479
assets so let's create I've got a asset

00:30:31,299 --> 00:30:36,729
containing a whole bunch of negus

00:30:34,479 --> 00:30:37,989
plugins as well as I've got one for a

00:30:36,729 --> 00:30:41,079
prometheus collector which I'll show

00:30:37,989 --> 00:30:43,329
afterwards so if I do an asset list we

00:30:41,079 --> 00:30:45,489
can see we have our slack Handler one

00:30:43,329 --> 00:30:48,279
we've got our check runtime dependencies

00:30:45,489 --> 00:30:50,709
for both Nagios plugins as well as

00:30:48,279 --> 00:30:52,929
Prometheus collector registered so now

00:30:50,709 --> 00:30:59,829
we can create some fun checks so let's

00:30:52,929 --> 00:31:02,469
hurry up and create a check for dummy

00:30:59,829 --> 00:31:03,280
app health Z endpoint so this will be

00:31:02,469 --> 00:31:05,530
like you tradition

00:31:03,280 --> 00:31:10,299
HDB check right so what we've done now

00:31:05,530 --> 00:31:13,230
if I do a check info I don't want to

00:31:10,299 --> 00:31:15,490
type that out I've had too much coffee

00:31:13,230 --> 00:31:17,470
alright so we've created a check what

00:31:15,490 --> 00:31:20,289
we're saying is we're gonna monitor the

00:31:17,470 --> 00:31:22,240
health CN point with check HTTP we're

00:31:20,289 --> 00:31:24,190
gonna run it on I can walk over here I

00:31:22,240 --> 00:31:26,350
got freedom subscriptions we're going to

00:31:24,190 --> 00:31:29,409
run on any agent that's identifies is

00:31:26,350 --> 00:31:31,780
the dummy subscription we have a runtime

00:31:29,409 --> 00:31:33,250
asset on check plugins so if I if the

00:31:31,780 --> 00:31:36,250
agent doesn't have it it's gonna fetch

00:31:33,250 --> 00:31:39,990
it and this is just within the Acme and

00:31:36,250 --> 00:31:43,900
Emmy demo environment so now if I do a

00:31:39,990 --> 00:31:45,580
let's see if this thing works cool so we

00:31:43,900 --> 00:31:50,380
can see we've got do I move that to the

00:31:45,580 --> 00:31:52,990
top yeah I could type so we can see

00:31:50,380 --> 00:31:55,539
we're running that check the agents

00:31:52,990 --> 00:31:57,700
didn't have that plug-in so they pulled

00:31:55,539 --> 00:32:01,020
it down verified the integrity extracted

00:31:57,700 --> 00:32:04,750
into a sandbox ran the check now if I do

00:32:01,020 --> 00:32:07,539
opposed to make one unhealthy within 10

00:32:04,750 --> 00:32:10,740
seconds we should get an update there we

00:32:07,539 --> 00:32:10,740
go so one is unhealthy

00:32:12,930 --> 00:32:18,299
[Music]

00:32:14,229 --> 00:32:21,460
oh god is it gonna work is it gonna work

00:32:18,299 --> 00:32:25,659
well I came in drag things this is a

00:32:21,460 --> 00:32:29,289
terrible let's go full screen full

00:32:25,659 --> 00:32:32,289
commitment given that that backslash was

00:32:29,289 --> 00:32:34,330
not actually an error it should pop up

00:32:32,289 --> 00:32:39,419
here while we're waiting for that to

00:32:34,330 --> 00:32:44,159
happen let's just toggle them both back

00:32:39,419 --> 00:32:44,159
so we don't keep getting alert in there

00:32:44,220 --> 00:32:47,739
cool so they're both healthy now so

00:32:46,629 --> 00:32:49,989
we're able to see that we were able to

00:32:47,739 --> 00:32:51,279
create an asset created check deploy it

00:32:49,989 --> 00:32:53,889
out to agents they are able to fetch

00:32:51,279 --> 00:32:55,960
those dependencies run it and then we're

00:32:53,889 --> 00:32:58,799
able to create incidents that ideally

00:32:55,960 --> 00:33:03,999
eventually got to slack my god come on

00:32:58,799 --> 00:33:07,629
let's just reload reload I mean it is

00:33:03,999 --> 00:33:09,970
off my phone so alright well I'll come

00:33:07,629 --> 00:33:12,009
back to that one we don't need to debug

00:33:09,970 --> 00:33:14,979
anything else today

00:33:12,009 --> 00:33:18,159
alright so let's do another interesting

00:33:14,979 --> 00:33:24,070
thing let's create a in flux DB instance

00:33:18,159 --> 00:33:26,349
so cube CTL apply deploy we're going to

00:33:24,070 --> 00:33:28,899
deploy in flux DB with which is a great

00:33:26,349 --> 00:33:30,820
time series database it also is going to

00:33:28,899 --> 00:33:33,970
have a sensitive agent sidecar so if we

00:33:30,820 --> 00:33:39,249
do sense a cuddle entity list we can see

00:33:33,970 --> 00:33:40,359
that that is now added itself let's have

00:33:39,249 --> 00:33:43,029
some fun real quick before I forget

00:33:40,359 --> 00:33:45,759
let's scale up the number of dummy apps

00:33:43,029 --> 00:33:48,039
to ten just to show how since use

00:33:45,759 --> 00:33:52,539
discovery and D registration works if we

00:33:48,039 --> 00:33:53,499
do a entity list now come on come

00:33:52,539 --> 00:33:55,149
Bernays there we go

00:33:53,499 --> 00:33:56,470
so now that everything's come up we've

00:33:55,149 --> 00:34:00,190
got a lot more we've just scaled our app

00:33:56,470 --> 00:34:02,950
up but we're not that serious let's take

00:34:00,190 --> 00:34:05,109
it back down to one

00:34:02,950 --> 00:34:07,690
so what will happen now is as kubernetes

00:34:05,109 --> 00:34:10,299
just to remove them and they go down

00:34:07,690 --> 00:34:13,000
gracefully since he's able to determine

00:34:10,299 --> 00:34:17,020
that they happen gracefully and now

00:34:13,000 --> 00:34:18,460
we're down to just one so I think that's

00:34:17,020 --> 00:34:20,169
one of sin C's great strengths is that

00:34:18,460 --> 00:34:25,050
it's very good in this extremely

00:34:20,169 --> 00:34:29,110
ephemeral in infrastructure all right

00:34:25,050 --> 00:34:39,550
next thing we want to do is let's see

00:34:29,110 --> 00:34:41,980
let's create let's create an influx DB

00:34:39,550 --> 00:34:45,630
Handler asset so this is how it's going

00:34:41,980 --> 00:34:48,130
to fetch it since you cuddle chef config

00:34:45,630 --> 00:34:52,420
handlers we're gonna create an influx DB

00:34:48,130 --> 00:34:55,960
handler if I do a ham there in the foe

00:34:52,420 --> 00:34:59,950
and flux DB all right so this one what

00:34:55,960 --> 00:35:02,560
we're gonna do is anything that any

00:34:59,950 --> 00:35:03,100
event this is a built-in filter at part

00:35:02,560 --> 00:35:05,860
of the pipeline's

00:35:03,100 --> 00:35:07,750
that has metric data that goes to this

00:35:05,860 --> 00:35:10,300
handler we're gonna send it to this in

00:35:07,750 --> 00:35:14,290
flux DB instance with these credentials

00:35:10,300 --> 00:35:15,700
again don't steal my secrets so now what

00:35:14,290 --> 00:35:18,400
we need to do is create a check that

00:35:15,700 --> 00:35:20,770
produces some some metrics what we're

00:35:18,400 --> 00:35:29,020
going to do is we're going to collect

00:35:20,770 --> 00:35:32,170
the Prometheus metric data from the

00:35:29,020 --> 00:35:36,280
dummy app instance so let's see let's

00:35:32,170 --> 00:35:38,200
create dummy a Prometheus and it's just

00:35:36,280 --> 00:35:40,180
gonna scrape that slash metrics endpoint

00:35:38,200 --> 00:35:41,590
it's gonna extract that data into the

00:35:40,180 --> 00:35:44,350
sanzu format that's going to go through

00:35:41,590 --> 00:35:46,990
the pipeline ideally this handler should

00:35:44,350 --> 00:35:51,310
work unlike slack and write it too in

00:35:46,990 --> 00:35:59,080
flux DB is it working and never did work

00:35:51,310 --> 00:36:01,960
come on slack is it god that's why

00:35:59,080 --> 00:36:04,810
you're here another round of applause

00:36:01,960 --> 00:36:08,440
[Applause]

00:36:04,810 --> 00:36:13,180
let's see well now it's a fresh Channel

00:36:08,440 --> 00:36:15,340
oh man oh man let's see okay we'll come

00:36:13,180 --> 00:36:18,130
back to it we'll come back to it alright

00:36:15,340 --> 00:36:21,850
so if I do sense a cuddle event list

00:36:18,130 --> 00:36:23,110
it's gonna be a little ugly we can see

00:36:21,850 --> 00:36:24,550
that this cheque is outputting some

00:36:23,110 --> 00:36:26,470
Prometheus metrics actually in the

00:36:24,550 --> 00:36:32,530
influx DB line protocol since is

00:36:26,470 --> 00:36:35,590
extracting it actually let's see it's in

00:36:32,530 --> 00:36:38,830
my history a little lazy so oh my god

00:36:35,590 --> 00:36:41,080
I've clearly done this a few times there

00:36:38,830 --> 00:36:43,540
we go okay sweet so I just hit the

00:36:41,080 --> 00:36:45,310
influx API we can see that we've got

00:36:43,540 --> 00:36:47,200
some series data from Prometheus in

00:36:45,310 --> 00:36:48,520
there which is really cool let's do a

00:36:47,200 --> 00:36:50,260
little bit more with it though let's

00:36:48,520 --> 00:36:57,070
deploy graph on ax which is a great

00:36:50,260 --> 00:37:02,620
visualization tool deploying your phone

00:36:57,070 --> 00:37:08,560
on it's got a sidecar as well so let's

00:37:02,620 --> 00:37:10,320
go over oh oh it working there we go

00:37:08,560 --> 00:37:13,240
thank you very much it's the demo

00:37:10,320 --> 00:37:16,810
Channel I should probably read what I

00:37:13,240 --> 00:37:18,280
can figure fantastic so we should

00:37:16,810 --> 00:37:20,020
actually stop that

00:37:18,280 --> 00:37:22,120
we'll see it resolved the next time it

00:37:20,020 --> 00:37:23,680
runs too so you could also create

00:37:22,120 --> 00:37:25,330
filters that are associated with the

00:37:23,680 --> 00:37:27,970
slack Handler so we could say you know I

00:37:25,330 --> 00:37:29,530
only there go just resolved there I only

00:37:27,970 --> 00:37:31,750
want to know about these incidents every

00:37:29,530 --> 00:37:33,550
30 minutes like you can do a little bit

00:37:31,750 --> 00:37:37,360
of instant management suppression

00:37:33,550 --> 00:37:40,270
through the pipeline using filters very

00:37:37,360 --> 00:37:42,570
cool alright so let's go over to this

00:37:40,270 --> 00:37:42,570
browser

00:37:43,120 --> 00:37:50,490
hopefully this cache doesn't bust me up

00:37:45,130 --> 00:37:53,140
see let's go full screen admin password

00:37:50,490 --> 00:37:55,930
so this is running on cue Bernays it's

00:37:53,140 --> 00:37:58,360
actually gone ahead and provision the

00:37:55,930 --> 00:38:01,030
influx DB data source so we have as a

00:37:58,360 --> 00:38:06,190
time series database that's credit quite

00:38:01,030 --> 00:38:10,630
quick graph that is not a real one so we

00:38:06,190 --> 00:38:13,470
can select in flux DB let's do yeah

00:38:10,630 --> 00:38:22,390
everyone loves garbage collection

00:38:13,470 --> 00:38:27,040
No let's see last 30 minutes we want to

00:38:22,390 --> 00:38:28,960
group by since the event ID interval I

00:38:27,040 --> 00:38:29,980
think it's 10 seconds we really want to

00:38:28,960 --> 00:38:32,349
show there we go

00:38:29,980 --> 00:38:34,240
we can drill down here so we can see

00:38:32,349 --> 00:38:37,270
that we've where's now collecting from

00:38:34,240 --> 00:38:39,579
this if I scale that back up let's go

00:38:37,270 --> 00:38:41,920
back up to like 6 goes you know now our

00:38:39,579 --> 00:38:44,650
dummy apps you know processing orders or

00:38:41,920 --> 00:38:46,660
something and what we'll see is when

00:38:44,650 --> 00:38:50,650
those ones come up we'll start to see

00:38:46,660 --> 00:38:53,500
new data over here broken down by those

00:38:50,650 --> 00:38:55,510
sensitive agents as well so we've now

00:38:53,500 --> 00:38:57,520
created a check that's you know basic is

00:38:55,510 --> 00:38:59,440
it up or down check we've also created

00:38:57,520 --> 00:39:00,970
one that's tell me information about you

00:38:59,440 --> 00:39:04,089
I want to capture it starting a time

00:39:00,970 --> 00:39:06,010
series database and then visualize it so

00:39:04,089 --> 00:39:07,900
since he's all about again composing

00:39:06,010 --> 00:39:10,750
this system using best-of-breed tools to

00:39:07,900 --> 00:39:13,150
solve these very specialized problems

00:39:10,750 --> 00:39:17,890
there's not one tool that can do all

00:39:13,150 --> 00:39:19,660
these given things very well so that

00:39:17,890 --> 00:39:22,240
that's kind of the the model that that

00:39:19,660 --> 00:39:27,040
sensor uses it's it's more of a glue or

00:39:22,240 --> 00:39:34,809
framework or a hub piece let's see I've

00:39:27,040 --> 00:39:36,490
got time for few more things actually

00:39:34,809 --> 00:39:38,470
I'm going to deploy what's called a

00:39:36,490 --> 00:39:40,960
daemon set basically it deploys just a

00:39:38,470 --> 00:39:47,140
sensu agent per kubernetes node in my

00:39:40,960 --> 00:39:49,450
cube cluster if I do this actually I'm

00:39:47,140 --> 00:39:52,359
going to do a node exporter daemon set

00:39:49,450 --> 00:39:56,109
and I'm going to create a sense you

00:39:52,359 --> 00:40:02,680
agent daemon set so now if I just do a

00:39:56,109 --> 00:40:05,799
cube cuttle get pods what do we want to

00:40:02,680 --> 00:40:07,359
show so here's the daemon set so if my

00:40:05,799 --> 00:40:09,250
kubernetes cluster was to be larger I

00:40:07,359 --> 00:40:11,230
would end up with a sense uu agent on

00:40:09,250 --> 00:40:13,150
every Cooper nase node now what I can

00:40:11,230 --> 00:40:15,510
use with this is I can have my continues

00:40:13,150 --> 00:40:18,280
just emit data to that local sensu agent

00:40:15,510 --> 00:40:20,049
which provides a great mean you don't

00:40:18,280 --> 00:40:21,790
have to run a million sensu agents for

00:40:20,049 --> 00:40:23,859
all your container sidecars you can run

00:40:21,790 --> 00:40:26,509
one as a daemon set exposed those api's

00:40:23,859 --> 00:40:28,309
have your apps emit data to it

00:40:26,509 --> 00:40:31,759
as well as I can leverage them to

00:40:28,309 --> 00:40:36,079
monitor Cooper neighs itself let's just

00:40:31,759 --> 00:40:37,700
quickly throw these out there so we can

00:40:36,079 --> 00:40:40,329
use that prometheus collector for two

00:40:37,700 --> 00:40:43,369
other checks we're gonna do one for node

00:40:40,329 --> 00:40:47,660
the node exporter and then we're gonna

00:40:43,369 --> 00:40:51,109
also do it for that steep Prometheus

00:40:47,660 --> 00:40:53,539
service cube state metrics we're going

00:40:51,109 --> 00:40:56,839
to measure that as well so if we do like

00:40:53,539 --> 00:41:03,589
a since you cuddle event list it's a

00:40:56,839 --> 00:41:09,470
little ugly see if I can only type on

00:41:03,589 --> 00:41:10,700
this keyboard event info there we go so

00:41:09,470 --> 00:41:13,039
we're now collecting information about

00:41:10,700 --> 00:41:15,890
carbon Nettie's so we're now able to

00:41:13,039 --> 00:41:17,210
deploy service checks monitor things on

00:41:15,890 --> 00:41:20,930
Cabernets with it we're also able to

00:41:17,210 --> 00:41:24,259
monitor and measure with Prometheus

00:41:20,930 --> 00:41:26,450
metrics since who's all about using

00:41:24,259 --> 00:41:28,130
established protocols we're not about

00:41:26,450 --> 00:41:31,369
introducing new ones so that's why we

00:41:28,130 --> 00:41:33,859
use newest plugins we use Prometheus we

00:41:31,369 --> 00:41:36,049
use in flex line protocol existing

00:41:33,859 --> 00:41:38,690
things we want to just be able to pull

00:41:36,049 --> 00:41:40,279
it all in again funnel it in pull it

00:41:38,690 --> 00:41:45,140
through the pipeline and then put it out

00:41:40,279 --> 00:41:46,819
to useful places sweet okay proof that

00:41:45,140 --> 00:41:48,710
it resolved we didn't get keep continue

00:41:46,819 --> 00:41:52,130
to get spammed there so that's kind of

00:41:48,710 --> 00:41:53,900
the the demo that I wanted to show with

00:41:52,130 --> 00:41:56,779
with since you go how easy it was to

00:41:53,900 --> 00:41:58,640
deploy how easy it was to create a

00:41:56,779 --> 00:42:03,049
multi-tenant environment how easy it was

00:41:58,640 --> 00:42:05,900
to start monitoring a fairly functional

00:42:03,049 --> 00:42:09,920
application so I think I have a few

00:42:05,900 --> 00:42:11,390
minutes for questions all right well

00:42:09,920 --> 00:42:14,140
first of all that's that's my talk thank

00:42:11,390 --> 00:42:14,140
you all for coming

00:42:18,620 --> 00:42:23,810
all right who asked questions Dave

00:42:28,250 --> 00:42:33,300
perhaps a ugly one how did the agents in

00:42:31,470 --> 00:42:35,010
the back ends talk to each other how do

00:42:33,300 --> 00:42:38,130
you look how do you manage the TLS part

00:42:35,010 --> 00:42:39,930
of that is that a built into sensor is

00:42:38,130 --> 00:42:42,270
that up someone else's problem yes so

00:42:39,930 --> 00:42:45,380
for the last 10 years since he's always

00:42:42,270 --> 00:42:47,670
used a transport like rabbitmq or

00:42:45,380 --> 00:42:50,070
activemq as the mechanism for

00:42:47,670 --> 00:42:51,990
inter-process communication and since

00:42:50,070 --> 00:42:53,850
you go it's built into the backend in

00:42:51,990 --> 00:42:55,590
the agent itself and it's actually just

00:42:53,850 --> 00:42:58,290
using persistent WebSocket connections

00:42:55,590 --> 00:43:00,960
over TLS and then you can proxy it and

00:42:58,290 --> 00:43:04,020
load-balanced it as you like it's super

00:43:00,960 --> 00:43:06,270
super basic what we basically identified

00:43:04,020 --> 00:43:08,400
over 10 years of sensu is what value do

00:43:06,270 --> 00:43:10,470
we get out of the transport what what

00:43:08,400 --> 00:43:12,990
qualities do we like and that's what we

00:43:10,470 --> 00:43:30,270
engineered into the new new transport

00:43:12,990 --> 00:43:34,920
mechanism so we use go gorilla for the

00:43:30,270 --> 00:43:36,750
WebSocket server and it supports the

00:43:34,920 --> 00:43:38,490
extended CA certificate chain

00:43:36,750 --> 00:43:40,400
configuration but in terms of like

00:43:38,490 --> 00:43:43,500
rolling out changes to that it still

00:43:40,400 --> 00:43:45,060
relies on like configuration management

00:43:43,500 --> 00:43:49,620
like a chef or puppet or ansible

00:43:45,060 --> 00:43:51,660
to do the rolling certificate change the

00:43:49,620 --> 00:43:53,430
the thing is is like with in tandem with

00:43:51,660 --> 00:43:55,410
the are back model you don't have to

00:43:53,430 --> 00:43:57,750
rotate your certificate certificates as

00:43:55,410 --> 00:43:59,550
much because you at least have user

00:43:57,750 --> 00:44:01,860
permissions tied to specific groups of

00:43:59,550 --> 00:44:03,330
agents as well so it's kind of like you

00:44:01,860 --> 00:44:05,250
you come up with your own strategy of

00:44:03,330 --> 00:44:07,410
how you want to keep this thing secure

00:44:05,250 --> 00:44:09,330
and moving forward as you decommission

00:44:07,410 --> 00:44:11,390
infrastructure does that answer your

00:44:09,330 --> 00:44:11,390
question

00:44:15,750 --> 00:44:21,250
it's bi-directional so the the connect

00:44:19,480 --> 00:44:23,200
the persistent connection is used so

00:44:21,250 --> 00:44:24,610
that the back end can schedule checks on

00:44:23,200 --> 00:44:26,710
it and say hey I need you to run this

00:44:24,610 --> 00:44:28,060
thing at the same time the agent uses

00:44:26,710 --> 00:44:38,020
the same connection to push the data

00:44:28,060 --> 00:44:40,210
back no it's all agent agent to back

00:44:38,020 --> 00:44:42,460
ends so the way it traverses is you

00:44:40,210 --> 00:44:44,500
expose one port in your back-end via

00:44:42,460 --> 00:44:46,210
firewall what have you all your agents

00:44:44,500 --> 00:44:48,310
connect give multiple clouds multiple

00:44:46,210 --> 00:44:50,050
winds what have you and then they

00:44:48,310 --> 00:44:51,190
maintain the persistent connection so

00:44:50,050 --> 00:44:52,900
the back-end itself doesn't actually

00:44:51,190 --> 00:44:54,820
need to understand where your

00:44:52,900 --> 00:44:58,060
infrastructure is and where where it is

00:44:54,820 --> 00:45:01,030
because it all comes up and says hi with

00:44:58,060 --> 00:45:02,290
the credentials of course okay if you

00:45:01,030 --> 00:45:04,090
have any other question I think Shawn

00:45:02,290 --> 00:45:06,610
will be around yeah I'll be around all

00:45:04,090 --> 00:45:08,320
day tomorrow today and tomorrow yeah

00:45:06,610 --> 00:45:09,820
it's lunchtime now but I want to say

00:45:08,320 --> 00:45:11,100
thank you very much for being sweet

00:45:09,820 --> 00:45:13,780
thank you very much

00:45:11,100 --> 00:45:19,220
awesome Tom thanks again everyone

00:45:13,780 --> 00:45:31,080
[Applause]

00:45:19,220 --> 00:45:31,080

YouTube URL: https://www.youtube.com/watch?v=pUUnUehRIDo


