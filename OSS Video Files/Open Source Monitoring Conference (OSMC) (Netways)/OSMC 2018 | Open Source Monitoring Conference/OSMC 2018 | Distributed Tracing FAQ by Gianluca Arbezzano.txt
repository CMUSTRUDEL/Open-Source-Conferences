Title: OSMC 2018 | Distributed Tracing FAQ by Gianluca Arbezzano
Publication date: 2018-11-16
Playlist: OSMC 2018 | Open Source Monitoring Conference
Description: 
	Microservices, containers and more in general distributed systems have opened a different point of view on our system and applications. We need to understand how a single event or requests cross our app jumping over networks, containers, virtual machines and sometime clod provider. There is a specific practice called distributed tracing to increase observability of systems like that. After this talk, you will have a solid idea around what tracing means, how you can instrument your applications and you will be ready to trace your application across many languages using open source technologies like OpenTracing, OpenCensus, Zipkin, Jaeger, InfluxDB. You will ask yourself how you survived until today!

NETWAYS
Konferenzen: https://www.netways.de/events
Schulungen: https://www.netways.de/schulungen
Shop: https://shop.netways.de/
Blog: http://blog.netways.de/
NWS: https://nws.netways.de

Webinare
Archiv Link: https://www.netways.de/webinare/archi...
Aktuell: https://www.netways.de/wb

Social Media
SlideShare: http://de.slideshare.net/netways
YouTube: https://www.netways.de/youtube
Facebook: https://www.facebook.com/netways
Twitter: https://twitter.com/netways
Instagram: https://www.instagram.com/netwaysgmbh/

www.musicfox.com
Captions: 
	00:00:01,940 --> 00:00:13,270
[Music]

00:00:14,570 --> 00:00:18,619
thank you so it was a really kind

00:00:17,730 --> 00:00:21,390
introduction

00:00:18,619 --> 00:00:23,990
yeah I'm here to speak about distributed

00:00:21,390 --> 00:00:26,730
tracing because I spent the last year

00:00:23,990 --> 00:00:28,680
kind of wrapping my head about

00:00:26,730 --> 00:00:31,619
distributed tracing about open around

00:00:28,680 --> 00:00:32,250
open tracing and how all these stuff

00:00:31,619 --> 00:00:34,460
works

00:00:32,250 --> 00:00:37,770
I spend the Year instrumenting

00:00:34,460 --> 00:00:40,710
instrumenting our applications and so

00:00:37,770 --> 00:00:43,020
these and sharing what I learned so this

00:00:40,710 --> 00:00:45,180
is kind of presentation about few

00:00:43,020 --> 00:00:48,750
questions that I got about tracing that

00:00:45,180 --> 00:00:51,360
I think can be helpful to be answered

00:00:48,750 --> 00:00:54,870
all together so I'm Gianluca Rebbetzin

00:00:51,360 --> 00:00:56,039
I'm an s3 at influx data and you can

00:00:54,870 --> 00:00:58,500
find me on internet

00:00:56,039 --> 00:01:01,320
other than coding and make dirty hacks

00:00:58,500 --> 00:01:04,350
to looks also I grow my vegetables so I

00:01:01,320 --> 00:01:08,420
have a garden I like to grow my gardens

00:01:04,350 --> 00:01:11,909
and I travel for fun work so that's it

00:01:08,420 --> 00:01:13,530
in flux de vivre I feel at home at the

00:01:11,909 --> 00:01:15,540
open source monitoring conference

00:01:13,530 --> 00:01:18,930
because my company provides a set of

00:01:15,540 --> 00:01:21,270
open source tools to spin up monitoring

00:01:18,930 --> 00:01:23,369
system so the most famous one is

00:01:21,270 --> 00:01:25,799
probably in flux to be it's a time

00:01:23,369 --> 00:01:27,420
serious database it's single so it's a

00:01:25,799 --> 00:01:30,119
single binary you spin up the time

00:01:27,420 --> 00:01:31,680
series and you start to insert points

00:01:30,119 --> 00:01:34,290
and event inside it

00:01:31,680 --> 00:01:36,689
after that we discovered that there are

00:01:34,290 --> 00:01:39,960
more needs and storing data is not

00:01:36,689 --> 00:01:42,030
enough so what we released was Telegraph

00:01:39,960 --> 00:01:45,030
it is an agent that you can install in

00:01:42,030 --> 00:01:46,829
all the servers and it collects data so

00:01:45,030 --> 00:01:49,649
there are a lot of input and output

00:01:46,829 --> 00:01:52,710
plugins so you can use Telegraph even

00:01:49,649 --> 00:01:55,079
with other databases like graphite or

00:01:52,710 --> 00:01:57,600
cloud watch or stack driver there are a

00:01:55,079 --> 00:02:00,810
lot of output plug-in and input plug-in

00:01:57,600 --> 00:02:03,000
so there are more than 100 input plugins

00:02:00,810 --> 00:02:05,070
that you can use so you can scrape data

00:02:03,000 --> 00:02:07,439
from almost everything and it's open

00:02:05,070 --> 00:02:09,989
source so if something is missed it can

00:02:07,439 --> 00:02:12,690
be coded and another project it's

00:02:09,989 --> 00:02:13,500
capacitor capacitor is our down sampling

00:02:12,690 --> 00:02:16,140
and alert

00:02:13,500 --> 00:02:18,180
system so it's a way to proactive do

00:02:16,140 --> 00:02:20,640
something with your data because as you

00:02:18,180 --> 00:02:22,470
probably know data are just data we need

00:02:20,640 --> 00:02:26,130
to make them useful in some way so

00:02:22,470 --> 00:02:28,290
capacitor is our way to proactive take

00:02:26,130 --> 00:02:30,959
action on the data the others is just

00:02:28,290 --> 00:02:31,980
one of the possible things that you can

00:02:30,959 --> 00:02:35,459
do with the data

00:02:31,980 --> 00:02:37,980
chrono graph is an alternative to refine

00:02:35,459 --> 00:02:40,050
as to what we saw and it's a dashboard

00:02:37,980 --> 00:02:42,840
this is a dashboard that other than

00:02:40,050 --> 00:02:45,450
providing graphs it also helps you to

00:02:42,840 --> 00:02:47,459
visit to visually manage all the tick

00:02:45,450 --> 00:02:49,560
stacks so you can beat alerts or you can

00:02:47,459 --> 00:02:51,720
see what your Telegraph's are and all

00:02:49,560 --> 00:02:54,030
these kind of stuff but it also works

00:02:51,720 --> 00:02:57,630
with graph and also play with what you

00:02:54,030 --> 00:02:59,910
want so the first question who I do any

00:02:57,630 --> 00:03:01,790
distributed tracing and this is a good

00:02:59,910 --> 00:03:05,370
question thank you for raising death

00:03:01,790 --> 00:03:07,890
well the first issue is that few years

00:03:05,370 --> 00:03:09,900
ago we had this monolithic application

00:03:07,890 --> 00:03:13,020
or even if it was a if it wasn't a

00:03:09,900 --> 00:03:16,410
monolithic it was not that distributed

00:03:13,020 --> 00:03:19,670
as we have now so now we have Micro

00:03:16,410 --> 00:03:21,840
Services or in general we have more

00:03:19,670 --> 00:03:24,989
requests that are going through the

00:03:21,840 --> 00:03:27,780
network inside our network and also we

00:03:24,989 --> 00:03:30,030
use a lot more third-party services for

00:03:27,780 --> 00:03:31,590
example probably you use cloud zero to

00:03:30,030 --> 00:03:33,930
manage authentication it's really

00:03:31,590 --> 00:03:35,850
powerful as a service tool to manage

00:03:33,930 --> 00:03:38,910
that residual in the authentication or

00:03:35,850 --> 00:03:42,299
you have other system that you integrate

00:03:38,910 --> 00:03:45,150
with so all this stuff that are going

00:03:42,299 --> 00:03:48,680
out from your application needs to be in

00:03:45,150 --> 00:03:51,000
some way monitoring and they have a

00:03:48,680 --> 00:03:54,540
gravity on your system because it makes

00:03:51,000 --> 00:03:57,180
everything more complicated so we need

00:03:54,540 --> 00:03:58,980
distributed system to describe the

00:03:57,180 --> 00:04:02,040
distribution complexity and the

00:03:58,980 --> 00:04:03,989
distribution capacity is a lot more now

00:04:02,040 --> 00:04:05,820
that we have Micro Services for cloud

00:04:03,989 --> 00:04:08,630
environment and this kind of stuff so

00:04:05,820 --> 00:04:12,360
that's why we need distributed tracing

00:04:08,630 --> 00:04:15,540
in practice what you have you still have

00:04:12,360 --> 00:04:18,540
a set of points or logs it's just a

00:04:15,540 --> 00:04:21,060
different angle of these points so a

00:04:18,540 --> 00:04:23,280
trace is made of points

00:04:21,060 --> 00:04:25,169
the start and the hand point and there

00:04:23,280 --> 00:04:27,389
are other points then describe what

00:04:25,169 --> 00:04:29,789
happened in the middle but it's just the

00:04:27,389 --> 00:04:34,590
front aggregation with logs and traces

00:04:29,789 --> 00:04:36,689
so nothing really new and has I said

00:04:34,590 --> 00:04:42,419
before they tell you the story of your

00:04:36,689 --> 00:04:45,419
distributed system how a trace looks

00:04:42,419 --> 00:04:47,999
like if you never saw a trace but you

00:04:45,419 --> 00:04:50,099
probably did because a trace is when you

00:04:47,999 --> 00:04:52,319
are profiling an application and you get

00:04:50,099 --> 00:04:53,249
the profile page with all the lines and

00:04:52,319 --> 00:04:55,289
all the functions

00:04:53,249 --> 00:04:59,909
that's a trace or when you are

00:04:55,289 --> 00:05:02,159
inspecting in a pea web page in chrome

00:04:59,909 --> 00:05:05,189
and you are in the chrome development

00:05:02,159 --> 00:05:06,990
tool tools you just you just see a trace

00:05:05,189 --> 00:05:10,500
of all the requests that are going out

00:05:06,990 --> 00:05:14,250
from your from your browser so that's a

00:05:10,500 --> 00:05:17,189
trace a trace is made of span so every

00:05:14,250 --> 00:05:19,759
single line is called span and it's the

00:05:17,189 --> 00:05:25,460
smallest units that we use to describe

00:05:19,759 --> 00:05:29,879
trace a span is may is used to describe

00:05:25,460 --> 00:05:31,919
HTTP HTTP request or a database query if

00:05:29,879 --> 00:05:35,879
you interact with my sequel maybe a

00:05:31,919 --> 00:05:37,500
query is a span a message a single

00:05:35,879 --> 00:05:39,539
message exactly that in a queue system

00:05:37,500 --> 00:05:42,330
so when you put a message in the queue

00:05:39,539 --> 00:05:44,849
and the worker pick up that message and

00:05:42,330 --> 00:05:47,969
execute the message that's that can be

00:05:44,849 --> 00:05:51,000
described as a span so obviously if your

00:05:47,969 --> 00:05:53,699
queue retries you have a lot more spans

00:05:51,000 --> 00:05:56,460
because it keeps creating new one or

00:05:53,699 --> 00:06:00,449
when you when you look up with a key

00:05:56,460 --> 00:06:03,569
value store a key from a value store so

00:06:00,449 --> 00:06:06,899
usually a span has a span ID and it is

00:06:03,569 --> 00:06:10,409
unique inside a trace it has a trace ID

00:06:06,899 --> 00:06:14,250
to group together spans that come from

00:06:10,409 --> 00:06:16,710
the same request usually it has a parent

00:06:14,250 --> 00:06:21,210
ID because it helps you to build a year

00:06:16,710 --> 00:06:23,460
key between spans it has labels labels

00:06:21,210 --> 00:06:27,000
are metadata that you attach to have a

00:06:23,460 --> 00:06:28,589
span and it keep and it gives you more

00:06:27,000 --> 00:06:31,110
information about what it what it's

00:06:28,589 --> 00:06:32,969
doing or what it did for example if your

00:06:31,110 --> 00:06:35,459
instrument is as I tell you before if

00:06:32,969 --> 00:06:37,680
your instrumenting cue system probably

00:06:35,459 --> 00:06:40,139
one of the label can be the message

00:06:37,680 --> 00:06:41,310
itself or part of the message if you are

00:06:40,139 --> 00:06:42,930
instrumenting

00:06:41,310 --> 00:06:46,020
there is a popular use case that Twitter

00:06:42,930 --> 00:06:48,270
release that they was heating a bag with

00:06:46,020 --> 00:06:50,340
their cash system and they wasn't able

00:06:48,270 --> 00:06:52,950
to understand when the cash was hidden

00:06:50,340 --> 00:06:55,950
and when it wasn't so they traced that

00:06:52,950 --> 00:06:59,130
part and they discovered that for some

00:06:55,950 --> 00:07:01,830
key they wasn't eating the the cash has

00:06:59,130 --> 00:07:04,110
it was supposed to be so it is also

00:07:01,830 --> 00:07:06,360
another possible use case and the label

00:07:04,110 --> 00:07:09,360
in this case can be the key they look up

00:07:06,360 --> 00:07:11,130
kefir from the cache other than labels

00:07:09,360 --> 00:07:14,640
we have another key value pair that is

00:07:11,130 --> 00:07:17,400
equal is called span context but in

00:07:14,640 --> 00:07:19,620
particular span context is propagated

00:07:17,400 --> 00:07:21,870
through the network so husband has I

00:07:19,620 --> 00:07:24,120
told you it's a distributed tracing so

00:07:21,870 --> 00:07:26,790
in some way the information need to go

00:07:24,120 --> 00:07:30,090
from the service Abe to the service B

00:07:26,790 --> 00:07:33,060
they usually go over a network so the

00:07:30,090 --> 00:07:35,850
span context is propagated to turn

00:07:33,060 --> 00:07:39,420
through the network and obviously logs

00:07:35,850 --> 00:07:41,550
can be part of this of the span some I

00:07:39,420 --> 00:07:43,980
will I will show you how it can be done

00:07:41,550 --> 00:07:45,450
but in the simpler the simple stuff that

00:07:43,980 --> 00:07:48,630
you can do is that you create your

00:07:45,450 --> 00:07:51,030
logger and you put the trace ID inside

00:07:48,630 --> 00:07:53,190
every line so you can grab for the trace

00:07:51,030 --> 00:07:55,080
ID and you can have trace and locks and

00:07:53,190 --> 00:07:56,790
match them together so this is the easy

00:07:55,080 --> 00:08:01,170
stuff that you can do and that's what I

00:07:56,790 --> 00:08:04,650
do this is a trace so a span is the

00:08:01,170 --> 00:08:07,380
smallest unit we can have but a trace it

00:08:04,650 --> 00:08:11,010
what it's what we are looking for so

00:08:07,380 --> 00:08:13,080
every line is a span and we have the

00:08:11,010 --> 00:08:15,930
list of services that we are heating in

00:08:13,080 --> 00:08:18,660
this example I see I simulated I should

00:08:15,930 --> 00:08:22,500
be recast so usually you have nginx or

00:08:18,660 --> 00:08:25,080
your ingress proxy and you have service

00:08:22,500 --> 00:08:27,780
a that probably reach to a my sequel and

00:08:25,080 --> 00:08:31,440
maybe you have also a worker so this is

00:08:27,780 --> 00:08:34,380
representation of a trace the nginx is

00:08:31,440 --> 00:08:36,360
the biggest span because you have viewed

00:08:34,380 --> 00:08:38,580
in this case I don't return any any

00:08:36,360 --> 00:08:40,890
requests until everything is done so we

00:08:38,580 --> 00:08:44,220
have the longest span there and you have

00:08:40,890 --> 00:08:46,290
the your application s a that is that

00:08:44,220 --> 00:08:49,980
has a enter that is the create user so

00:08:46,290 --> 00:08:51,930
it's your API and what it does it check

00:08:49,980 --> 00:08:54,480
if the user already exists on my sequel

00:08:51,930 --> 00:08:55,529
so the first line the user exists is a

00:08:54,480 --> 00:08:57,930
query

00:08:55,529 --> 00:09:00,689
and it insert the user if it doesn't

00:08:57,930 --> 00:09:03,060
exist in this case it insert it and it's

00:09:00,689 --> 00:09:05,220
send an email using a work queue so this

00:09:03,060 --> 00:09:09,689
is what you can get tracing an

00:09:05,220 --> 00:09:11,910
application that's the idea as I told

00:09:09,689 --> 00:09:15,029
you there are labels and times and

00:09:11,910 --> 00:09:17,220
duration so what you get in a span is

00:09:15,029 --> 00:09:20,129
the service name so the service that

00:09:17,220 --> 00:09:22,589
generated the span you have trace ID

00:09:20,129 --> 00:09:25,139
that is a unique value and you have a

00:09:22,589 --> 00:09:28,499
span ID that is unique inside the trace

00:09:25,139 --> 00:09:31,170
ID and you have this plan name so user

00:09:28,499 --> 00:09:35,430
exists you have the duration so how long

00:09:31,170 --> 00:09:37,170
it takes it took and the start time so

00:09:35,430 --> 00:09:40,709
in this way you can build the graph that

00:09:37,170 --> 00:09:43,559
you would be just so obviously label I

00:09:40,709 --> 00:09:47,459
took the user exists so probably you can

00:09:43,559 --> 00:09:50,309
put has a key value the query so you

00:09:47,459 --> 00:09:52,319
will have the query inside the span and

00:09:50,309 --> 00:09:56,100
the user that made the query so this is

00:09:52,319 --> 00:09:58,920
just a prototype let's say how do I

00:09:56,100 --> 00:10:00,000
follow our cast obviously it depends of

00:09:58,920 --> 00:10:03,149
your application

00:10:00,000 --> 00:10:05,129
but one of the example you need to

00:10:03,149 --> 00:10:08,490
instrument your application if you have

00:10:05,129 --> 00:10:12,809
a HTTP server server usually they they

00:10:08,490 --> 00:10:15,449
get propagated via header same for GPC

00:10:12,809 --> 00:10:18,209
just your PC if it goes over TCP it has

00:10:15,449 --> 00:10:19,920
others so you can use others and the

00:10:18,209 --> 00:10:22,110
same example if your if you have a cue

00:10:19,920 --> 00:10:24,360
system you can embed these data has a

00:10:22,110 --> 00:10:27,839
payload inside the message

00:10:24,360 --> 00:10:29,759
so if obviously you need to try to the

00:10:27,839 --> 00:10:31,769
couple these two codes the

00:10:29,759 --> 00:10:33,180
instrumentation code from the code for

00:10:31,769 --> 00:10:36,120
the business logic of your application

00:10:33,180 --> 00:10:38,519
but that really depends on what

00:10:36,120 --> 00:10:41,370
operating languages you what languages

00:10:38,519 --> 00:10:43,980
you are using or what framework you are

00:10:41,370 --> 00:10:46,079
using for example I develop and go every

00:10:43,980 --> 00:10:48,360
day so the go has this concept of

00:10:46,079 --> 00:10:50,939
middleware that probably no js' also has

00:10:48,360 --> 00:10:52,499
so you can usually you wrap the tracing

00:10:50,939 --> 00:10:55,019
code in a middleware that gets

00:10:52,499 --> 00:10:57,179
propagated into the application if you

00:10:55,019 --> 00:10:59,730
work in a in a framework that has is

00:10:57,179 --> 00:11:02,639
more even based like some framework in

00:10:59,730 --> 00:11:06,959
PHP or whatever you can probably hook

00:11:02,639 --> 00:11:09,130
and attach to listeners in your casts so

00:11:06,959 --> 00:11:13,420
the goal is to keep this codes

00:11:09,130 --> 00:11:16,420
like far from each other as I told you

00:11:13,420 --> 00:11:19,930
there are there are different way to

00:11:16,420 --> 00:11:23,110
propagate had headers and opens if King

00:11:19,930 --> 00:11:26,950
is a project developed by Twitter in

00:11:23,110 --> 00:11:30,220
Java and they put together these set of

00:11:26,950 --> 00:11:33,040
specs and rules to propagate headers

00:11:30,220 --> 00:11:37,150
that is call it b3 propagation and a lot

00:11:33,040 --> 00:11:39,520
of tracers use and read it so it's good

00:11:37,150 --> 00:11:44,080
if you're looking for something to to

00:11:39,520 --> 00:11:46,960
start or to start with it's good do I

00:11:44,080 --> 00:11:48,790
need a standard for tracing you always

00:11:46,960 --> 00:11:50,800
need a standard so the answer is yes

00:11:48,790 --> 00:11:53,590
there is not enough standards that

00:11:50,800 --> 00:11:55,390
that's how it is but yeah you need a

00:11:53,590 --> 00:11:58,900
standard you need a protocol for at

00:11:55,390 --> 00:12:00,640
least two reasons one because other than

00:11:58,900 --> 00:12:02,830
having a distributed system and a

00:12:00,640 --> 00:12:04,510
micro-services environment we also write

00:12:02,830 --> 00:12:07,180
application in different languages and

00:12:04,510 --> 00:12:10,420
we don't work all in the same team so in

00:12:07,180 --> 00:12:12,550
some way even if we are so different or

00:12:10,420 --> 00:12:15,250
far from each other at the hand of the

00:12:12,550 --> 00:12:16,990
story we need to build a trace so to

00:12:15,250 --> 00:12:19,330
build a trace we need to agree on the

00:12:16,990 --> 00:12:22,390
same protocol so if it's a protocol if

00:12:19,330 --> 00:12:24,910
it's a standard you need something if

00:12:22,390 --> 00:12:28,000
you use out if you use a wide widely

00:12:24,910 --> 00:12:31,270
supported standard I will show you one

00:12:28,000 --> 00:12:33,850
of them later obviously there is less

00:12:31,270 --> 00:12:36,610
vendor lock-in because you can switch

00:12:33,850 --> 00:12:38,980
between has a service or in-house

00:12:36,610 --> 00:12:41,790
tracers without ring instrument in your

00:12:38,980 --> 00:12:44,050
application this is important because

00:12:41,790 --> 00:12:46,480
instrumenting the application for

00:12:44,050 --> 00:12:48,190
tracing is not something that comes for

00:12:46,480 --> 00:12:50,910
free it's something that you need to go

00:12:48,190 --> 00:12:53,080
and put in your code so if you

00:12:50,910 --> 00:12:56,710
instrument all your application and it

00:12:53,080 --> 00:12:59,020
takes you weeks to do that and at some

00:12:56,710 --> 00:13:01,420
point your vendors trying to the is

00:12:59,020 --> 00:13:02,920
getting too much more expensive and you

00:13:01,420 --> 00:13:04,690
can pay it you need to ring instrument

00:13:02,920 --> 00:13:07,390
your application so if you adopt a

00:13:04,690 --> 00:13:12,430
standard or some bridges it's gonna be

00:13:07,390 --> 00:13:15,100
safer for you so one of the widely

00:13:12,430 --> 00:13:18,340
adopted standards it's open tracing open

00:13:15,100 --> 00:13:20,530
trace income it's a incubated project

00:13:18,340 --> 00:13:22,930
from the CNC F so the cloud knitting

00:13:20,530 --> 00:13:27,749
foundation the same foundation that

00:13:22,930 --> 00:13:30,249
sponsors Prometheus capacitor kubernetes

00:13:27,749 --> 00:13:31,990
encoded cÃ¡rdenas and a lot of other

00:13:30,249 --> 00:13:35,290
cloud projects that are cool these days

00:13:31,990 --> 00:13:41,829
so Oberon tracings operon tracing try to

00:13:35,290 --> 00:13:44,079
standardize trace and a lot of this

00:13:41,829 --> 00:13:46,059
concept comes from what I show you

00:13:44,079 --> 00:13:48,279
before so you have the spans and you

00:13:46,059 --> 00:13:49,869
have the participant the child spans and

00:13:48,279 --> 00:13:51,910
you have the key value storage that the

00:13:49,869 --> 00:13:54,100
labels you have the span context oh

00:13:51,910 --> 00:13:58,269
heavily things works as I told you

00:13:54,100 --> 00:14:00,309
before so you have a tracers because

00:13:58,269 --> 00:14:02,709
obviously it's a standard so you can

00:14:00,309 --> 00:14:05,439
have more than one tracers and there are

00:14:02,709 --> 00:14:08,410
open source close source has a service

00:14:05,439 --> 00:14:13,240
solution I'm gonna show you some of them

00:14:08,410 --> 00:14:15,839
later it's a wide like widely adopted

00:14:13,240 --> 00:14:20,290
standard because then if it get up

00:14:15,839 --> 00:14:22,240
joined Twitter Airbnb doctor and a lot

00:14:20,290 --> 00:14:26,139
of other companies and projects are

00:14:22,240 --> 00:14:29,199
using it already and also it is well

00:14:26,139 --> 00:14:31,720
supported it is an open source community

00:14:29,199 --> 00:14:34,689
so there are a lot of languages and a

00:14:31,720 --> 00:14:37,389
lot of frameworks that already implement

00:14:34,689 --> 00:14:40,959
this standard for free so if you use

00:14:37,389 --> 00:14:43,779
your PC it comes from the tracing the

00:14:40,959 --> 00:14:46,899
open tracing SDK and capabilities if you

00:14:43,779 --> 00:14:49,329
use Django or Python or whatever there

00:14:46,899 --> 00:14:55,300
are libraries for almost every languages

00:14:49,329 --> 00:14:58,720
every language I put some example in go

00:14:55,300 --> 00:15:01,959
because I developing go so the idea is

00:14:58,720 --> 00:15:04,629
that in your main function you ask for

00:15:01,959 --> 00:15:07,029
the open tracing library this also works

00:15:04,629 --> 00:15:08,799
for the Java one or for the PHP one and

00:15:07,029 --> 00:15:10,420
the Python one so the concept are the

00:15:08,799 --> 00:15:12,759
same just the language is different but

00:15:10,420 --> 00:15:15,519
you have a globe a global tracer and

00:15:12,759 --> 00:15:17,439
that is the open tracing one you inject

00:15:15,519 --> 00:15:19,540
the one that the concrete one that you

00:15:17,439 --> 00:15:23,439
are using so there are a lot of tracers

00:15:19,540 --> 00:15:25,809
around you can use neurotic or you know

00:15:23,439 --> 00:15:27,629
zip kinis open source and as I told you

00:15:25,809 --> 00:15:31,059
before the Jager is another one in go

00:15:27,629 --> 00:15:32,679
extra Amazon extra supports open tracing

00:15:31,059 --> 00:15:35,279
stack drivers

00:15:32,679 --> 00:15:36,820
so there are tracers for a lot of

00:15:35,279 --> 00:15:39,670
services

00:15:36,820 --> 00:15:42,340
and what you configure it and you inject

00:15:39,670 --> 00:15:44,710
it in this in the Global tracer and from

00:15:42,340 --> 00:15:47,230
this point in time you in your

00:15:44,710 --> 00:15:49,840
application you just speak with open

00:15:47,230 --> 00:15:51,850
tracing API it means that if tomorrow

00:15:49,840 --> 00:15:53,920
you need to use another tracer what you

00:15:51,850 --> 00:15:55,720
can do is just with a feature flag or

00:15:53,920 --> 00:15:57,760
with a flag with flags you can just

00:15:55,720 --> 00:16:00,270
change the entry point in the tracer

00:15:57,760 --> 00:16:04,300
that you're using to use a different one

00:16:00,270 --> 00:16:06,730
the open tracing API looks like this so

00:16:04,300 --> 00:16:08,800
you start a spam you can start a new

00:16:06,730 --> 00:16:11,080
span or you can start a new span from

00:16:08,800 --> 00:16:13,120
account from a context the context

00:16:11,080 --> 00:16:14,830
usually has already information about

00:16:13,120 --> 00:16:17,980
the trace ID and all this kind of stuff

00:16:14,830 --> 00:16:20,140
so what you get is usually start span

00:16:17,980 --> 00:16:23,890
from a context and you give the name of

00:16:20,140 --> 00:16:26,530
the span so user exists' or insert user

00:16:23,890 --> 00:16:29,770
that we saw before will be the operation

00:16:26,530 --> 00:16:31,810
name and go has this concept of the fair

00:16:29,770 --> 00:16:34,990
that it's executed when the function

00:16:31,810 --> 00:16:37,570
ends so at the hand of the function when

00:16:34,990 --> 00:16:40,750
you are interesting to and the span you

00:16:37,570 --> 00:16:43,420
call the span finish in the meantime you

00:16:40,750 --> 00:16:47,170
can associate logs or you can actually

00:16:43,420 --> 00:16:49,600
associate events or the label that we

00:16:47,170 --> 00:16:52,270
spoke about so there are API is that you

00:16:49,600 --> 00:16:56,860
can use to enrich the span with all the

00:16:52,270 --> 00:16:58,780
information that you are collecting as I

00:16:56,860 --> 00:17:01,840
told you you you also have the ability

00:16:58,780 --> 00:17:04,120
to start child span so you can start as

00:17:01,840 --> 00:17:09,430
funny you can pass the parent span

00:17:04,120 --> 00:17:11,950
inside and you have a chance one another

00:17:09,430 --> 00:17:14,110
it's not a standard this one but it's

00:17:11,950 --> 00:17:16,810
called open senses that is in it is

00:17:14,110 --> 00:17:19,990
sponsored by Google it's a specification

00:17:16,810 --> 00:17:21,970
format for instrumentation libraries so

00:17:19,990 --> 00:17:24,250
let's start from the beginning it's a

00:17:21,970 --> 00:17:28,150
specification so if you look at the

00:17:24,250 --> 00:17:29,530
repository it's long markdown file with

00:17:28,150 --> 00:17:32,350
documentation about how it should work

00:17:29,530 --> 00:17:36,370
and they also provide a set of libraries

00:17:32,350 --> 00:17:38,590
that implement the specification so what

00:17:36,370 --> 00:17:40,450
you get is a library that you embed in

00:17:38,590 --> 00:17:43,150
yours in your application and add in it

00:17:40,450 --> 00:17:45,550
it helps you to implement to

00:17:43,150 --> 00:17:47,770
instrumental application so you can put

00:17:45,550 --> 00:17:49,830
push starts into the library collects

00:17:47,770 --> 00:17:53,370
and aggregate metrics on

00:17:49,830 --> 00:17:55,470
can also push traces so and it works in

00:17:53,370 --> 00:17:58,080
the same way with the same constant has

00:17:55,470 --> 00:18:01,049
open tracing so you inject the exporter

00:17:58,080 --> 00:18:04,440
it can be a log exporter or event

00:18:01,049 --> 00:18:06,269
exporter or a tracing exporter and from

00:18:04,440 --> 00:18:11,190
the back in your application you just

00:18:06,269 --> 00:18:15,390
used the API that it provides so it's a

00:18:11,190 --> 00:18:19,620
abstraction layer how much racing

00:18:15,390 --> 00:18:21,360
infrastructure looks like if you're

00:18:19,620 --> 00:18:23,419
using open tracing it looks like this so

00:18:21,360 --> 00:18:26,190
you have all your applications it can be

00:18:23,419 --> 00:18:28,169
just an application it can be a micro

00:18:26,190 --> 00:18:30,000
application it can be a lambda function

00:18:28,169 --> 00:18:32,610
and can be whatever you want you have

00:18:30,000 --> 00:18:35,309
the code you punch the code to the open

00:18:32,610 --> 00:18:39,090
to the tracer and it gets trace is

00:18:35,309 --> 00:18:42,360
stored so tracer can beat Zipkin Jager

00:18:39,090 --> 00:18:46,470
and whatever can I have a tracing

00:18:42,360 --> 00:18:49,019
infrastructure on pram yes there are

00:18:46,470 --> 00:18:52,100
open source alternatives - like Zipkin

00:18:49,019 --> 00:18:55,169
Java and Jager ingo Jaeger is is

00:18:52,100 --> 00:18:57,960
provided by uber uber started it and

00:18:55,169 --> 00:19:00,419
they donated scene C F so if you are go

00:18:57,960 --> 00:19:02,309
friend Li and you're looking for elastic

00:19:00,419 --> 00:19:05,130
search or Cassandra backends you can use

00:19:02,309 --> 00:19:07,649
Jaeger 15 is in Java and it's also

00:19:05,130 --> 00:19:10,380
support my sequel if you are my secret

00:19:07,649 --> 00:19:12,600
person obviously all these stores are

00:19:10,380 --> 00:19:14,820
having obstructions so you can implement

00:19:12,600 --> 00:19:20,340
an interface and have your storage tied

00:19:14,820 --> 00:19:21,929
to it but it requires some work there

00:19:20,340 --> 00:19:24,149
are other service tracing tracing

00:19:21,929 --> 00:19:25,830
infrastructure that also a really good

00:19:24,149 --> 00:19:28,380
question and it's also very important

00:19:25,830 --> 00:19:30,240
because when something gets wrong here

00:19:28,380 --> 00:19:32,399
in your application is like the

00:19:30,240 --> 00:19:34,380
monitoring if you type the monitor too

00:19:32,399 --> 00:19:35,460
close to your application and goes down

00:19:34,380 --> 00:19:38,010
with your application your

00:19:35,460 --> 00:19:40,260
infrastructure you won't know so that

00:19:38,010 --> 00:19:42,809
doesn't really fit well in what we are

00:19:40,260 --> 00:19:45,809
trying to do so outsourcing this kind of

00:19:42,809 --> 00:19:49,440
stuff it's usually not a too bad idea

00:19:45,809 --> 00:19:51,600
and yes the resolution as I told you in

00:19:49,440 --> 00:19:55,590
your new relic is open tracing

00:19:51,600 --> 00:19:57,330
compatible honeycomb that is a start up

00:19:55,590 --> 00:20:00,960
observability start up is also

00:19:57,330 --> 00:20:03,660
compatible like steps a stepped up and

00:20:00,960 --> 00:20:07,380
tracing and if you are on Amazon AWS 6

00:20:03,660 --> 00:20:11,640
or Google stackdriver they both hands

00:20:07,380 --> 00:20:17,430
open tracing stuff can I store traces

00:20:11,640 --> 00:20:19,530
everywhere yes as your own risk so the

00:20:17,430 --> 00:20:21,930
problem with trace is is that every cast

00:20:19,530 --> 00:20:24,300
that goes to your system has a trace ID

00:20:21,930 --> 00:20:25,920
and usually a trace ID is the one that

00:20:24,300 --> 00:20:29,550
you are using to look up the information

00:20:25,920 --> 00:20:31,830
so you need to have that data that

00:20:29,550 --> 00:20:34,410
information index set to for a fast

00:20:31,830 --> 00:20:36,870
lookup so it means that the cardinality

00:20:34,410 --> 00:20:39,150
can be really high obviously there are

00:20:36,870 --> 00:20:42,210
strategy you can sample or you can

00:20:39,150 --> 00:20:44,340
instrument your application to not send

00:20:42,210 --> 00:20:47,430
all the metrics all the traces from

00:20:44,340 --> 00:20:49,050
other casts so think about the if you're

00:20:47,430 --> 00:20:50,940
using a load balancer usually a load

00:20:49,050 --> 00:20:53,340
balancer to use an entry point to check

00:20:50,940 --> 00:20:55,380
if everything is fine and if coal is

00:20:53,340 --> 00:20:58,500
every call your application having 10

00:20:55,380 --> 00:21:00,990
second every whatever so if you trace

00:20:58,500 --> 00:21:03,270
every time that that request can be used

00:21:00,990 --> 00:21:06,360
useless so what you can do is probably

00:21:03,270 --> 00:21:09,870
in out of tracers assumes that there is

00:21:06,360 --> 00:21:12,270
a header that says this trace is a that

00:21:09,870 --> 00:21:15,060
doesn't need to be stored so maybe you

00:21:12,270 --> 00:21:18,900
can tweak your instrumentation library

00:21:15,060 --> 00:21:21,510
to do that and obviously databases with

00:21:18,900 --> 00:21:24,480
hive write scruples are better so

00:21:21,510 --> 00:21:25,620
usually a lot of people use Cassandra we

00:21:24,480 --> 00:21:29,280
can all remote would it be because it

00:21:25,620 --> 00:21:30,930
can handle a lot of rights and so yeah

00:21:29,280 --> 00:21:32,250
you can do whatever you want zip King by

00:21:30,930 --> 00:21:34,140
default starts with an in-memory

00:21:32,250 --> 00:21:37,320
database so if you have a lot of memory

00:21:34,140 --> 00:21:43,320
you can use that but yeah it's expensive

00:21:37,320 --> 00:21:49,140
so that's it before moving I'm just

00:21:43,320 --> 00:21:51,990
gonna show you this is small this is a

00:21:49,140 --> 00:21:55,170
trace that comes from I was the bagging

00:21:51,990 --> 00:21:58,380
before coming here so this is one of the

00:21:55,170 --> 00:22:00,060
trades I have I developed in infancy B

00:21:58,380 --> 00:22:01,500
we have an apple we have a SAS offering

00:22:00,060 --> 00:22:03,780
so we have a provision or an

00:22:01,500 --> 00:22:07,440
Orchestrator that spin up stuff in AWS

00:22:03,780 --> 00:22:10,580
so what I do i instrumented this flow

00:22:07,440 --> 00:22:13,350
with open tracing so as you can see

00:22:10,580 --> 00:22:15,090
there is a HTTP request where you can

00:22:13,350 --> 00:22:17,190
see that there is a URL so this is the

00:22:15,090 --> 00:22:20,880
front of my application

00:22:17,190 --> 00:22:23,040
and I made a reactive planning so I have

00:22:20,880 --> 00:22:25,890
a lot of a bunch of steps that get

00:22:23,040 --> 00:22:28,230
executed by a scheduler so the first

00:22:25,890 --> 00:22:30,300
step is mark has pending so it gets my

00:22:28,230 --> 00:22:33,020
clusters and it says hey this cluster is

00:22:30,300 --> 00:22:38,220
in a pending state and it's storied to

00:22:33,020 --> 00:22:39,840
influ ABCD and after that it gets a

00:22:38,220 --> 00:22:43,080
bunch of stuff it also interact with the

00:22:39,840 --> 00:22:46,140
WS so I have I have instrumented the AWS

00:22:43,080 --> 00:22:49,380
SDK to trade to be traded so every time

00:22:46,140 --> 00:22:52,230
that I get a call to the - AWS I know

00:22:49,380 --> 00:22:55,170
which action I'm doing so I'm describing

00:22:52,230 --> 00:22:56,550
a subnet in this case and I am also

00:22:55,170 --> 00:22:58,320
logging the body of the request

00:22:56,550 --> 00:23:01,710
obviously you need to be careful about

00:22:58,320 --> 00:23:03,240
what you do but in my case this is a

00:23:01,710 --> 00:23:05,670
scalar so it doesn't have a lot of

00:23:03,240 --> 00:23:08,160
traffic but I need to be precise and

00:23:05,670 --> 00:23:11,400
have a lot of information when something

00:23:08,160 --> 00:23:13,320
gets wrong so that's why I'm logging

00:23:11,400 --> 00:23:16,470
recast a response and whatever I can

00:23:13,320 --> 00:23:19,470
because it has its alt me it has me

00:23:16,470 --> 00:23:21,300
obviously tracing can also be used if

00:23:19,470 --> 00:23:25,580
you if you work with the WS with other

00:23:21,300 --> 00:23:28,430
API you probably know that you have

00:23:25,580 --> 00:23:31,200
sometimes you get back a request ID and

00:23:28,430 --> 00:23:34,230
usually that request ID can be looked at

00:23:31,200 --> 00:23:35,940
as a trace so we with the support team

00:23:34,230 --> 00:23:39,180
and with our our customer we are also

00:23:35,940 --> 00:23:41,850
teaching them to remember the request ID

00:23:39,180 --> 00:23:43,770
and told us the request ID when there

00:23:41,850 --> 00:23:46,650
are there are problems oh this is very

00:23:43,770 --> 00:23:48,330
good feedback look back because they get

00:23:46,650 --> 00:23:50,430
the rest idea when it fails and they

00:23:48,330 --> 00:23:53,790
give us okay this doesn't work and this

00:23:50,430 --> 00:23:56,160
is a request ID from so I can go I can

00:23:53,790 --> 00:23:58,950
attract a study and from the record

00:23:56,160 --> 00:24:02,420
study I can look up the trace in the bug

00:23:58,950 --> 00:24:02,420
no that's it

00:24:05,510 --> 00:24:14,430
so so good in time so there's time left

00:24:10,980 --> 00:24:18,840
for questions so don't be shy I can had

00:24:14,430 --> 00:24:20,730
them in my slides so please okay so no

00:24:18,840 --> 00:24:23,570
question but there's a question from me

00:24:20,730 --> 00:24:27,410
so if I implement that open trace

00:24:23,570 --> 00:24:30,210
libraries into my application like go

00:24:27,410 --> 00:24:33,780
how big is the performance impact on the

00:24:30,210 --> 00:24:36,900
go team and article process itself if it

00:24:33,780 --> 00:24:38,940
will grow I mean almost nothing

00:24:36,900 --> 00:24:42,210
obviously depends how much data you are

00:24:38,940 --> 00:24:44,430
handling and but it was in in in

00:24:42,210 --> 00:24:46,170
background so it just collect metrics so

00:24:44,430 --> 00:24:48,960
we will probably discover a little bit

00:24:46,170 --> 00:24:53,520
of spike in memory but not that much in

00:24:48,960 --> 00:24:55,980
the end it gets the trace back to to the

00:24:53,520 --> 00:25:00,120
centralized server so it's not that

00:24:55,980 --> 00:25:02,810
impact there is not did not increase the

00:25:00,120 --> 00:25:04,250
load of the application itself no no no

00:25:02,810 --> 00:25:08,060
okay

00:25:04,250 --> 00:25:08,060
yeah there's a question

00:25:17,040 --> 00:25:24,230
I have a question so can every span at

00:25:20,810 --> 00:25:27,240
labels to the global trace is there any

00:25:24,230 --> 00:25:28,950
is there a lot of all trades at these

00:25:27,240 --> 00:25:32,850
labels or you need to look for the

00:25:28,950 --> 00:25:35,250
labors of every span can you repeat

00:25:32,850 --> 00:25:37,980
please so are there any labels at the

00:25:35,250 --> 00:25:40,350
trace level of only at the span level

00:25:37,980 --> 00:25:42,150
and if there are the trace leave are do

00:25:40,350 --> 00:25:45,420
you need to put them when you create the

00:25:42,150 --> 00:25:48,240
trace or can every span add labels to

00:25:45,420 --> 00:25:50,310
the complete trace yeah no there are no

00:25:48,240 --> 00:25:52,320
labels in the trace in the trace itself

00:25:50,310 --> 00:25:54,210
so what you can do is you use the span

00:25:52,320 --> 00:25:59,610
context and all the spans has that

00:25:54,210 --> 00:26:04,190
labels that's the idea okay further

00:25:59,610 --> 00:26:07,770
questions you still have some time no

00:26:04,190 --> 00:26:11,990
okay then Gianluca thank you thank you

00:26:07,770 --> 00:26:11,990
for being here thank you

00:26:20,900 --> 00:26:22,960

YouTube URL: https://www.youtube.com/watch?v=3LpclL7Akrg


