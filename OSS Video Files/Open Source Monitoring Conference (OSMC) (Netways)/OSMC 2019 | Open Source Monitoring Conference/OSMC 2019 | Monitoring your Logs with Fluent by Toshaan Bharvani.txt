Title: OSMC 2019 | Monitoring your Logs with Fluent by Toshaan Bharvani
Publication date: 2019-11-18
Playlist: OSMC 2019 | Open Source Monitoring Conference
Description: 
	This presentation shows how to setup Icinga2 with Fluent and Grafana, for logging, monitoring, dashboarding and notifications. In the first part the presentation show how to setup FluentD the server part of Fluent for log aggregation, Fluentbit is the client that ships logs to the log server for both systems and applications. In the second part of the presentation the setup of Grafana for dashboarding is explained. In the third part the setup of Icinga2 for monitoring and notifications is explained. And finally the integration between these part is explained so you can get an integrated solution. At the end of the presentation a demo will show how this works with some examples.


NETWAYS
Konferenzen: https://www.netways.de/events
Schulungen: https://www.netways.de/schulungen
Shop: https://shop.netways.de/
Blog: http://blog.netways.de/
NWS: https://nws.netways.de

Webinare
Archiv Link: https://www.netways.de/webinare/archi...
Aktuell: https://www.netways.de/wb

Social Media
SlideShare: http://de.slideshare.net/netways
YouTube: https://www.netways.de/youtube
Facebook: https://www.facebook.com/netways
Twitter: https://twitter.com/netways
Instagram: https://www.instagram.com/netwaysgmbh/

Musik: FRAMETRAXX
Captions: 
	00:00:10,300 --> 00:00:15,789
[Applause]

00:00:21,710 --> 00:00:23,769
you

00:05:13,340 --> 00:05:21,840
so yeah lightweight demon it takes

00:05:18,120 --> 00:05:24,719
inputs and it sends them out so it's not

00:05:21,840 --> 00:05:26,400
doing a lot it's basically just wanting

00:05:24,719 --> 00:05:28,259
inputs and we'll send that to flow and D

00:05:26,400 --> 00:05:31,259
but it t erratically could send that

00:05:28,259 --> 00:05:34,229
also to other systems so it even has

00:05:31,259 --> 00:05:36,960
integration with gray log with carbon

00:05:34,229 --> 00:05:41,009
with many other things so it doesn't

00:05:36,960 --> 00:05:43,169
necessarily need fluent D there one of

00:05:41,009 --> 00:05:47,430
the other advantages it's much easier to

00:05:43,169 --> 00:05:50,580
set up TLS so syslog can do TLS but it's

00:05:47,430 --> 00:05:52,379
mostly or most people find a little bit

00:05:50,580 --> 00:05:55,199
more complicated and cumbersome to set

00:05:52,379 --> 00:05:59,389
up fluent bit comes directly with TLS

00:05:55,199 --> 00:06:02,430
support built in and there is an extra

00:05:59,389 --> 00:06:04,830
repository where you can actually create

00:06:02,430 --> 00:06:07,020
the certificates and if you're using

00:06:04,830 --> 00:06:09,150
fluent D you can even do certificate

00:06:07,020 --> 00:06:10,800
distribution through fluent D which

00:06:09,150 --> 00:06:16,199
makes it a little bit easier to set up

00:06:10,800 --> 00:06:18,779
and easier to manage so now we need

00:06:16,199 --> 00:06:22,889
something to store all this data in I

00:06:18,779 --> 00:06:26,610
use carbon or graphite so it's basically

00:06:22,889 --> 00:06:29,460
another project written in Python which

00:06:26,610 --> 00:06:31,949
has a jungle web framework where you can

00:06:29,460 --> 00:06:34,259
do API calls against Carbon will

00:06:31,949 --> 00:06:36,089
actually process all these metrics that

00:06:34,259 --> 00:06:40,139
come in and write them to the whisper

00:06:36,089 --> 00:06:42,169
database the whisper database is a time

00:06:40,139 --> 00:06:45,500
series database but it's basically on

00:06:42,169 --> 00:06:49,560
file based system a file based database

00:06:45,500 --> 00:06:52,649
which makes it as performant as your

00:06:49,560 --> 00:06:54,689
file system is that's good and bad

00:06:52,649 --> 00:06:56,879
that's why carbon is actually there in

00:06:54,689 --> 00:06:58,979
the middle it does a lot of the caching

00:06:56,879 --> 00:07:02,300
so it can actually handle a lot more

00:06:58,979 --> 00:07:03,889
data while it's not yet written to disk

00:07:02,300 --> 00:07:06,810
[Music]

00:07:03,889 --> 00:07:09,750
for for normal set ups this works quite

00:07:06,810 --> 00:07:11,339
well you could choose other projects

00:07:09,750 --> 00:07:13,620
there's in flux dB

00:07:11,339 --> 00:07:16,949
there are a few other ones that are

00:07:13,620 --> 00:07:19,319
available we chose this because this is

00:07:16,949 --> 00:07:21,449
well this was the first one that we had

00:07:19,319 --> 00:07:23,779
and we had the most experience using

00:07:21,449 --> 00:07:23,779
this

00:07:25,120 --> 00:07:31,250
then of course we need to have nice

00:07:27,580 --> 00:07:33,620
dashboards and have or have the

00:07:31,250 --> 00:07:37,810
possibility to correlate graphs and

00:07:33,620 --> 00:07:41,090
predictive analysis with all this data

00:07:37,810 --> 00:07:44,570
so we use graph on ax which is basically

00:07:41,090 --> 00:07:46,490
a visualization tool but it also has the

00:07:44,570 --> 00:07:48,310
possibility to integrate with log

00:07:46,490 --> 00:07:52,400
management so you can actually see

00:07:48,310 --> 00:07:54,560
graphs next to logs and aggregate these

00:07:52,400 --> 00:07:56,660
logs together

00:07:54,560 --> 00:07:59,540
it also has metrics overview because it

00:07:56,660 --> 00:08:02,120
basically hooks up to an external

00:07:59,540 --> 00:08:04,310
back-end in this case carbon and we'll

00:08:02,120 --> 00:08:07,270
get all the data from carbon so that it

00:08:04,310 --> 00:08:09,770
can actually display these things nicely

00:08:07,270 --> 00:08:12,170
it's written in golang so it basically

00:08:09,770 --> 00:08:15,140
wants single binary which you can run

00:08:12,170 --> 00:08:17,660
somewhere it doesn't necessarily need to

00:08:15,140 --> 00:08:20,230
be all on the same host you could spread

00:08:17,660 --> 00:08:22,670
that out if you want high availability

00:08:20,230 --> 00:08:27,170
typically we only run one graph on ax

00:08:22,670 --> 00:08:30,790
because it's not that important what

00:08:27,170 --> 00:08:30,790
that depends on on what you want to do

00:08:31,330 --> 00:08:38,030
yeah we use I singer for the monitoring

00:08:34,160 --> 00:08:40,219
so we would like to have one web portal

00:08:38,030 --> 00:08:43,130
where an end user or customer can

00:08:40,219 --> 00:08:45,620
actually log in and see whether the the

00:08:43,130 --> 00:08:48,860
host the service or the process is

00:08:45,620 --> 00:08:51,200
running and we use I singer for

00:08:48,860 --> 00:08:54,410
monitoring for the alerting

00:08:51,200 --> 00:08:56,600
also for the notification I have another

00:08:54,410 --> 00:08:58,490
presentation where we actually abused

00:08:56,600 --> 00:09:01,760
notification and try to do some

00:08:58,490 --> 00:09:03,440
self-healing through that for most of

00:09:01,760 --> 00:09:05,270
the end users actually the business

00:09:03,440 --> 00:09:07,490
overview is more important they are more

00:09:05,270 --> 00:09:09,830
interested to know is my website working

00:09:07,490 --> 00:09:11,810
is my service still up and running they

00:09:09,830 --> 00:09:15,680
don't want to be able to always dig down

00:09:11,810 --> 00:09:16,730
for other people like developers they

00:09:15,680 --> 00:09:18,920
want to know exactly what is happening

00:09:16,730 --> 00:09:20,600
so they can actually dig down and see

00:09:18,920 --> 00:09:23,330
the logs of the machine or the

00:09:20,600 --> 00:09:24,800
application and then better understand

00:09:23,330 --> 00:09:28,300
what applications are doing and how

00:09:24,800 --> 00:09:28,300
machines are reacting towards that

00:09:33,120 --> 00:09:38,390
there's a little bit small but it

00:09:34,890 --> 00:09:41,640
basically is you have the fluent bits on

00:09:38,390 --> 00:09:45,000
this side which talk to multiple fluent

00:09:41,640 --> 00:09:49,040
DS so the fluent D is highly available

00:09:45,000 --> 00:09:52,080
typically you can set up two or three

00:09:49,040 --> 00:09:55,200
nodes in the fluent bit so if one of

00:09:52,080 --> 00:09:57,330
your fluent D machines goes down or you

00:09:55,200 --> 00:09:58,950
have any issues it directly communicates

00:09:57,330 --> 00:10:01,860
with the other one once the other ones

00:09:58,950 --> 00:10:05,250
come back up they they are back

00:10:01,860 --> 00:10:08,730
available and from fluent D then it goes

00:10:05,250 --> 00:10:12,500
into carbon which has all your metrics

00:10:08,730 --> 00:10:15,090
and your data also all your logs there

00:10:12,500 --> 00:10:16,950
and then graph anna does the

00:10:15,090 --> 00:10:19,890
visualization and icinga is more or less

00:10:16,950 --> 00:10:31,200
the front-end towards the customer

00:10:19,890 --> 00:10:33,930
facing side is that clear now if you

00:10:31,200 --> 00:10:36,570
have to set that all up manually that's

00:10:33,930 --> 00:10:40,320
quite a lot of work and something you

00:10:36,570 --> 00:10:43,020
don't like doing manually so we use

00:10:40,320 --> 00:10:46,170
ansible to to orchestrate and to manage

00:10:43,020 --> 00:10:50,850
all the configuration so it's another

00:10:46,170 --> 00:10:54,150
tool this basically runs a bunch of play

00:10:50,850 --> 00:10:56,610
books which are divided into rows which

00:10:54,150 --> 00:10:58,890
will create the VMS for us which will

00:10:56,610 --> 00:11:02,100
configure flow and D through all the

00:10:58,890 --> 00:11:04,770
hosts with fluent bit will configure

00:11:02,100 --> 00:11:06,240
graph Anna will configure icinga so if a

00:11:04,770 --> 00:11:08,540
machine goes down we can actually

00:11:06,240 --> 00:11:14,070
reproduce all the infrastructure

00:11:08,540 --> 00:11:17,400
automatically again so how do we

00:11:14,070 --> 00:11:19,920
actually build the stuff so for the

00:11:17,400 --> 00:11:23,760
fluent D it's quite basic setup it

00:11:19,920 --> 00:11:28,350
basically runs on a part and it does by

00:11:23,760 --> 00:11:30,900
default API calls over HTTP and then you

00:11:28,350 --> 00:11:33,530
basically give it a place where it can

00:11:30,900 --> 00:11:37,650
store the data temporary or permanently

00:11:33,530 --> 00:11:41,190
and it uses the the filesystem to do its

00:11:37,650 --> 00:11:42,810
caching before it gives the outputs you

00:11:41,190 --> 00:11:45,030
can even configure that you keep a local

00:11:42,810 --> 00:11:48,990
copy so you have all the data and

00:11:45,030 --> 00:11:50,160
finally they're also from an application

00:11:48,990 --> 00:11:53,460
point of view you can do automatic

00:11:50,160 --> 00:11:54,660
forwarding you can do access control or

00:11:53,460 --> 00:11:56,760
registers

00:11:54,660 --> 00:11:59,070
so that means that in this case it would

00:11:56,760 --> 00:12:00,500
be able to send certain data to

00:11:59,070 --> 00:12:05,280
elasticsearch if you're using

00:12:00,500 --> 00:12:09,210
elasticsearch or it can even segregate

00:12:05,280 --> 00:12:11,910
and do mappings which will automatically

00:12:09,210 --> 00:12:13,920
send data to the right system or will

00:12:11,910 --> 00:12:20,370
automatically highlight certain specific

00:12:13,920 --> 00:12:22,440
things if you want to run it as a syslog

00:12:20,370 --> 00:12:24,720
you basically just configure it to run

00:12:22,440 --> 00:12:27,930
in syslog mode and it will get all the

00:12:24,720 --> 00:12:30,420
data and then you can do some expression

00:12:27,930 --> 00:12:34,260
handling on it and filter out on things

00:12:30,420 --> 00:12:36,540
where this is more relevant or which you

00:12:34,260 --> 00:12:44,940
want to get highlighted or pushed faster

00:12:36,540 --> 00:12:46,890
or slower to your front ends in in our

00:12:44,940 --> 00:12:49,650
case we push everything to carbon so we

00:12:46,890 --> 00:12:51,950
basically have a key which basically is

00:12:49,650 --> 00:12:56,430
used by carbon then to put the data away

00:12:51,950 --> 00:12:58,980
and it allows fluent d2 to write all the

00:12:56,430 --> 00:13:03,050
data to carbon and we have a nice time

00:12:58,980 --> 00:13:03,050
series there of all the data itself

00:13:04,970 --> 00:13:10,980
fluent bit is like I said a very

00:13:07,800 --> 00:13:12,960
lightweight forwarder

00:13:10,980 --> 00:13:15,660
the configuration is also quite simple

00:13:12,960 --> 00:13:18,030
it basically tells where it has to send

00:13:15,660 --> 00:13:21,240
and what input it has and what output it

00:13:18,030 --> 00:13:25,400
has in this point you can then configure

00:13:21,240 --> 00:13:34,800
it to use flow Andy or any other

00:13:25,400 --> 00:13:38,160
aggregation tool to send data to carbon

00:13:34,800 --> 00:13:41,520
the the way that carbon works is you

00:13:38,160 --> 00:13:44,760
need to predefined the time series so

00:13:41,520 --> 00:13:46,200
that's the only disadvantage in it when

00:13:44,760 --> 00:13:48,570
you're setting it up you need to tell it

00:13:46,200 --> 00:13:51,720
how many how much data it will retain

00:13:48,570 --> 00:13:53,970
over its lifespan which means that you

00:13:51,720 --> 00:13:56,730
need to in advance tell it how long and

00:13:53,970 --> 00:13:58,150
what intervals it will have and then it

00:13:56,730 --> 00:14:08,040
creates an internal

00:13:58,150 --> 00:14:10,690
database structure of that for the

00:14:08,040 --> 00:14:14,340
graphite part which is the API which

00:14:10,690 --> 00:14:17,530
graph on ax and other tools can call it

00:14:14,340 --> 00:14:20,290
basically sets up a little API tool

00:14:17,530 --> 00:14:23,740
where you can get a lot of functions out

00:14:20,290 --> 00:14:25,480
I sing graph on ax typically have all

00:14:23,740 --> 00:14:28,060
the API calls in it you just need to

00:14:25,480 --> 00:14:30,280
point to the right direction and then

00:14:28,060 --> 00:14:37,900
Carbon will do all the stuff with

00:14:30,280 --> 00:14:40,750
graphite at the backend so how do we do

00:14:37,900 --> 00:14:44,440
the automation is basically running a

00:14:40,750 --> 00:14:47,020
small script we create a new VM we

00:14:44,440 --> 00:14:50,980
configure the flow and D and carbon on

00:14:47,020 --> 00:14:54,600
it and then we use the bits so the

00:14:50,980 --> 00:14:58,330
flowing bits to install the client side

00:14:54,600 --> 00:14:59,200
and that's basically now how much work

00:14:58,330 --> 00:15:01,420
we have on it

00:14:59,200 --> 00:15:03,730
so setting up a new infrastructure for

00:15:01,420 --> 00:15:05,740
customers is is running typically three

00:15:03,730 --> 00:15:15,010
or four play books and everything is

00:15:05,740 --> 00:15:17,950
done automatically so we've been able to

00:15:15,010 --> 00:15:21,040
build an integrated open source tool

00:15:17,950 --> 00:15:24,970
that does monitoring and logging and

00:15:21,040 --> 00:15:27,390
it's able to send data the front-end

00:15:24,970 --> 00:15:30,970
visualization isn't fully integrated yet

00:15:27,390 --> 00:15:33,270
so I can't show you that but we we have

00:15:30,970 --> 00:15:36,550
side by side things which are working

00:15:33,270 --> 00:15:38,710
the next step is to actually get all the

00:15:36,550 --> 00:15:41,020
logs and be able to correlate when

00:15:38,710 --> 00:15:42,580
events happen and to select them so that

00:15:41,020 --> 00:15:50,500
we can actually see what is happening

00:15:42,580 --> 00:15:53,820
and when things go wrong I think I'm

00:15:50,500 --> 00:15:53,820
done quite quickly

00:15:55,240 --> 00:16:05,870
no idea what time it is

00:15:57,680 --> 00:16:05,870
[Applause]

00:16:06,980 --> 00:16:10,449
yeah questions

00:16:21,120 --> 00:16:28,660
thank you some years ago I tried to

00:16:25,149 --> 00:16:31,660
replace fluently with flambeed on some

00:16:28,660 --> 00:16:33,519
machine with very high traffic from 10

00:16:31,660 --> 00:16:36,300
machine like a thousand thousand of

00:16:33,519 --> 00:16:39,310
requests for seconds and then quartered

00:16:36,300 --> 00:16:42,040
performance problems fluently was

00:16:39,310 --> 00:16:47,170
working quite good but flan bitten off

00:16:42,040 --> 00:16:49,500
with I users of CPU and losing log lines

00:16:47,170 --> 00:16:52,480
you have encountered things like this

00:16:49,500 --> 00:16:56,949
yeah so the first versions of fluent bit

00:16:52,480 --> 00:17:00,250
were written in go and at some point

00:16:56,949 --> 00:17:03,940
they rewrote everything in C I presume

00:17:00,250 --> 00:17:07,089
it has to do with that I didn't follow

00:17:03,940 --> 00:17:09,819
up what the problems were exactly but

00:17:07,089 --> 00:17:13,059
the new implementation in C has much

00:17:09,819 --> 00:17:16,600
less problems typically they say they

00:17:13,059 --> 00:17:20,140
can handle about if I remember well

00:17:16,600 --> 00:17:22,630
about 20,000 requests per second should

00:17:20,140 --> 00:17:25,510
be enough with a with a small little

00:17:22,630 --> 00:17:28,209
demon if you want to do more than that

00:17:25,510 --> 00:17:30,130
then typically what they advise is to do

00:17:28,209 --> 00:17:32,710
a little bit more optimization in the

00:17:30,130 --> 00:17:35,470
bits configuration and spread it out

00:17:32,710 --> 00:17:40,059
over multiple configuration means

00:17:35,470 --> 00:17:42,960
multiple threads in that way okay thank

00:17:40,059 --> 00:17:42,960
you I will try again

00:17:47,030 --> 00:17:56,600
I think for a great talk I have a

00:17:53,720 --> 00:17:59,300
question regarding the fluent ear in the

00:17:56,600 --> 00:18:02,480
middle with a student transformation is

00:17:59,300 --> 00:18:04,880
it better to have a D file cache if

00:18:02,480 --> 00:18:08,720
there is too much not what the buffer

00:18:04,880 --> 00:18:10,490
cache store all the locks which cannot

00:18:08,720 --> 00:18:13,790
be written to the graphite maybe it's

00:18:10,490 --> 00:18:15,260
out of something so that depends on how

00:18:13,790 --> 00:18:18,560
much memory you allocate to you're

00:18:15,260 --> 00:18:20,600
fluent D machines if you have a lot of

00:18:18,560 --> 00:18:22,430
memory you can do buffering because

00:18:20,600 --> 00:18:25,340
basically we'll just use your memory for

00:18:22,430 --> 00:18:27,830
that if you don't have that much memory

00:18:25,340 --> 00:18:29,930
then putting it on disk is the only

00:18:27,830 --> 00:18:33,920
option the disk is of course much more

00:18:29,930 --> 00:18:38,030
expensive if you have SSDs again that

00:18:33,920 --> 00:18:41,060
makes it a little bit faster but yeah

00:18:38,030 --> 00:18:42,890
that's it it also depends how much data

00:18:41,060 --> 00:18:45,410
you are pushing through there if it is

00:18:42,890 --> 00:18:47,840
very limited then it's fine by doing it

00:18:45,410 --> 00:18:50,660
in memory if it's larger then you will

00:18:47,840 --> 00:18:53,050
end up having to put it on disk okay

00:18:50,660 --> 00:18:53,050
thanks

00:19:04,940 --> 00:19:16,399
any more questions don't be afraid one

00:19:14,179 --> 00:19:18,919
more thing like I said we run a few

00:19:16,399 --> 00:19:22,039
conferences this is conflict management

00:19:18,919 --> 00:19:22,879
camp from the 3rd to the 5th of February

00:19:22,039 --> 00:19:25,720
after FOSDEM

00:19:22,879 --> 00:19:28,700
the CFP still open you can also register

00:19:25,720 --> 00:19:31,489
it's a free event so registration is

00:19:28,700 --> 00:19:38,239
just for crowd control and because the

00:19:31,489 --> 00:19:40,989
venue has a limited space so yeah ok

00:19:38,239 --> 00:19:40,989
thank you very much

00:19:43,600 --> 00:19:47,390
[Applause]

00:19:52,870 --> 00:19:54,930

YouTube URL: https://www.youtube.com/watch?v=0UVlbH-FPUU


