Title: OSMC 2019 | Monitoring Event Pipelines: Why you need one, and why you should stop rolling your own
Publication date: 2019-11-18
Playlist: OSMC 2019 | Open Source Monitoring Conference
Description: 
	by Sean Porter

The rules have changed. The shift from static to dynamic infrastructure requires a change in approach to monitoring, from host-based to functional role-based. Connectivity moves from remote polling to publish-subscribe and push APIs. The control plane moves from point-and-click interfaces to infrastructure-as-code workflows and self-service, developer-friendly APIs.

Now — more than ever before — organizations are faced with a deluge of data in various formats. As operators and as natural system integrators, our response to these challenges is likely to roll our own solution, construct a scalable data collection and processing pipeline and combine a number of best-of-breed tools. This is an idea and journey that I am all too familiar with. In 2010, as an operator, working for an early Cloud adopter, I was faced with these challenges, and fought for better visibility. I hacked for the greater good. In this talk, I will give an overview of what I consider to be attributes of an effective monitoring pipeline. I will recount my experience in creating Sensu, the open source monitoring pipeline, and the pitfalls the project has encountered. I will then live demo Sensu monitoring pipelines in action and make my case for not rolling your own solution from scratch.


NETWAYS
Konferenzen: https://www.netways.de/events
Schulungen: https://www.netways.de/schulungen
Shop: https://shop.netways.de/
Blog: http://blog.netways.de/
NWS: https://nws.netways.de

Webinare
Archiv Link: https://www.netways.de/webinare/archi...
Aktuell: https://www.netways.de/wb

Social Media
SlideShare: http://de.slideshare.net/netways
YouTube: https://www.netways.de/youtube
Facebook: https://www.facebook.com/netways
Twitter: https://twitter.com/netways
Instagram: https://www.instagram.com/netwaysgmbh/

Musik: FRAMETRAXX
Captions: 
	00:00:05,120 --> 00:00:08,719
[Music]

00:00:11,179 --> 00:00:18,570
thank you alrighty so yeah thank you so

00:00:16,049 --> 00:00:20,400
much for for joining me to talk about my

00:00:18,570 --> 00:00:21,930
earning event pipelines this has been

00:00:20,400 --> 00:00:24,289
something I've wanted to talk about for

00:00:21,930 --> 00:00:27,449
a long time but I never got around to

00:00:24,289 --> 00:00:29,250
forming a series of thoughts on the

00:00:27,449 --> 00:00:33,090
matter that I could share in a

00:00:29,250 --> 00:00:33,989
repeatable way so yeah actually I'm

00:00:33,090 --> 00:00:36,210
going to talk about monitoring event

00:00:33,989 --> 00:00:38,850
pipelines why you need one and why you

00:00:36,210 --> 00:00:40,980
should stop trying to roll your own so

00:00:38,850 --> 00:00:43,440
who am i first my name is Shawn Porter

00:00:40,980 --> 00:00:46,140
thank you for that nice introduction I'm

00:00:43,440 --> 00:00:49,890
the creator of the sensi open source

00:00:46,140 --> 00:00:52,320
project let's start it back in 2010 and

00:00:49,890 --> 00:00:54,719
I'll talk a bit about that in this talk

00:00:52,320 --> 00:00:57,449
I'm the co-founder and CTO of sense you

00:00:54,719 --> 00:00:59,460
Inc the commercial entity that's behind

00:00:57,449 --> 00:01:01,530
that project and you know really does

00:00:59,460 --> 00:01:05,369
the majority of the core development

00:01:01,530 --> 00:01:08,490
work and then online my handle is porter

00:01:05,369 --> 00:01:10,530
tech on on twitter or IRC although i'm

00:01:08,490 --> 00:01:14,549
not lurking there that often anymore or

00:01:10,530 --> 00:01:16,650
slack you can find me via that handle so

00:01:14,549 --> 00:01:18,420
a little overview of what this talk is

00:01:16,650 --> 00:01:20,490
going to cover I just want to talk about

00:01:18,420 --> 00:01:22,560
our shared reality as operators and

00:01:20,490 --> 00:01:23,790
developers you know what we experience

00:01:22,560 --> 00:01:27,000
on the day-to-day and what we're going

00:01:23,790 --> 00:01:29,970
to experience I'm gonna share my

00:01:27,000 --> 00:01:31,680
experience in building sense you for

00:01:29,970 --> 00:01:34,619
some background and some context about

00:01:31,680 --> 00:01:36,720
some of the topics I'm gonna discuss I'm

00:01:34,619 --> 00:01:40,470
gonna explain what a monitoring pipeline

00:01:36,720 --> 00:01:42,420
is I've actually been surprised over the

00:01:40,470 --> 00:01:45,299
last two days to hear this term actually

00:01:42,420 --> 00:01:47,490
thrown around by other speakers which is

00:01:45,299 --> 00:01:49,710
good because it means I'm not just

00:01:47,490 --> 00:01:51,960
talking about you know I made up subject

00:01:49,710 --> 00:01:55,560
or term or some hype it's it's it's got

00:01:51,960 --> 00:01:56,939
some concrete weight behind it I'm gonna

00:01:55,560 --> 00:01:59,130
talk about some attributes of an

00:01:56,939 --> 00:02:01,860
effective pipeline so you know if you

00:01:59,130 --> 00:02:06,360
build one or use one what is gonna give

00:02:01,860 --> 00:02:08,489
you a higher rate of success in that

00:02:06,360 --> 00:02:10,830
effort I'm gonna do a number of demos

00:02:08,489 --> 00:02:13,530
live demos I got a prayed to the demo

00:02:10,830 --> 00:02:16,200
gods that all work so and

00:02:13,530 --> 00:02:19,500
the future of pipelines kind of where I

00:02:16,200 --> 00:02:23,250
see the technology going as well as like

00:02:19,500 --> 00:02:27,209
practices and general approaches so our

00:02:23,250 --> 00:02:29,370
shared reality I mean for the last ten

00:02:27,209 --> 00:02:31,800
years it's just been a slow steady

00:02:29,370 --> 00:02:33,840
growth in terms of complexity over time

00:02:31,800 --> 00:02:35,670
right our applications have gotten more

00:02:33,840 --> 00:02:39,150
complex and the infrastructure that

00:02:35,670 --> 00:02:41,250
drives them has also got as complex if

00:02:39,150 --> 00:02:44,069
not more right we've gone from monoliths

00:02:41,250 --> 00:02:45,510
to micro services from bare metal to VMs

00:02:44,069 --> 00:02:48,209
to containers to function based

00:02:45,510 --> 00:02:50,130
computing the the amount of complexity

00:02:48,209 --> 00:02:52,310
that's involved in even like you know a

00:02:50,130 --> 00:02:54,720
simple ecommerce app to buy shoes

00:02:52,310 --> 00:02:58,620
somehow it requires a hundred servers

00:02:54,720 --> 00:03:00,989
and 300 micro services the number of

00:02:58,620 --> 00:03:03,390
things is also increasing right you know

00:03:00,989 --> 00:03:06,239
we always we used to operate in a number

00:03:03,390 --> 00:03:07,650
of tens to hundreds and a thousands now

00:03:06,239 --> 00:03:10,950
we're talking tens of thousands of

00:03:07,650 --> 00:03:15,300
machines for even medium sized

00:03:10,950 --> 00:03:16,980
organizations and the technologies

00:03:15,300 --> 00:03:18,959
themselves because the unit just keeps

00:03:16,980 --> 00:03:21,420
getting smaller there's more of them and

00:03:18,959 --> 00:03:23,880
again it just leads that complexity we

00:03:21,420 --> 00:03:26,340
now have containers and functions which

00:03:23,880 --> 00:03:27,810
are also extremely ephemeral and some of

00:03:26,340 --> 00:03:29,910
them only run for a matter of

00:03:27,810 --> 00:03:32,190
milliseconds and then they're gone like

00:03:29,910 --> 00:03:35,970
how do you observe something that is so

00:03:32,190 --> 00:03:38,010
fleeting right and really like we've

00:03:35,970 --> 00:03:40,650
been experiencing not just one paradigm

00:03:38,010 --> 00:03:42,600
shift not to probably about three in the

00:03:40,650 --> 00:03:45,780
last ten years the first being like

00:03:42,600 --> 00:03:48,180
cloud infrastructure then we have you

00:03:45,780 --> 00:03:50,390
know containerization revamped even that

00:03:48,180 --> 00:03:52,950
we've had containers for like 25 years

00:03:50,390 --> 00:03:55,440
and now a function based computing based

00:03:52,950 --> 00:03:56,910
on these platforms but what it's meant

00:03:55,440 --> 00:03:59,430
for monitoring is that we've needed to

00:03:56,910 --> 00:04:01,170
shift our models and how we approach

00:03:59,430 --> 00:04:03,660
these problems from things like host

00:04:01,170 --> 00:04:05,670
based monitoring where we're talking

00:04:03,660 --> 00:04:07,590
about individual machines and more role

00:04:05,670 --> 00:04:09,420
based monitoring where things are

00:04:07,590 --> 00:04:11,910
responsible for certain actions and

00:04:09,420 --> 00:04:14,940
services that's how we need to target

00:04:11,910 --> 00:04:16,950
and monitor and alert on pulling models

00:04:14,940 --> 00:04:18,810
change because we're no longer able to

00:04:16,950 --> 00:04:21,870
talk about the individual server and and

00:04:18,810 --> 00:04:24,180
pull them aggressively because they can

00:04:21,870 --> 00:04:26,220
be gone in a few in an instant

00:04:24,180 --> 00:04:27,250
we need to change how we do this till I

00:04:26,220 --> 00:04:29,410
publish subscribe

00:04:27,250 --> 00:04:32,020
push api's right we have to allow things

00:04:29,410 --> 00:04:34,120
to funnel into these pipelines and then

00:04:32,020 --> 00:04:35,440
point-and-click tools they don't really

00:04:34,120 --> 00:04:36,820
scale well we're moving to

00:04:35,440 --> 00:04:38,320
infrastructures code whether that's

00:04:36,820 --> 00:04:41,470
something like a chef or puppet or

00:04:38,320 --> 00:04:43,360
ansible or even a Yama file for

00:04:41,470 --> 00:04:44,920
kubernetes that's infrastructure as code

00:04:43,360 --> 00:04:46,270
that's kind of how we define what our

00:04:44,920 --> 00:04:50,350
infrastructure looks like and how we

00:04:46,270 --> 00:04:53,080
interact with it so a common issue that

00:04:50,350 --> 00:04:54,940
we're all presented with as operators on

00:04:53,080 --> 00:04:56,950
a daily basis is I hear a bunch of

00:04:54,940 --> 00:04:59,500
constraints whether it be like budget

00:04:56,950 --> 00:05:01,870
requirements or Hardware availability or

00:04:59,500 --> 00:05:05,340
people in time and you got to get data

00:05:01,870 --> 00:05:09,550
and format a into data format B C and D

00:05:05,340 --> 00:05:11,290
with very limited resources so we have

00:05:09,550 --> 00:05:14,169
to get creative and I think we're

00:05:11,290 --> 00:05:16,750
actually very creative people we've

00:05:14,169 --> 00:05:19,240
we've spent our careers trying to work

00:05:16,750 --> 00:05:20,710
through these problems and and we always

00:05:19,240 --> 00:05:21,910
surprise ourselves and what we come up

00:05:20,710 --> 00:05:23,980
with and sometimes we get proud

00:05:21,910 --> 00:05:25,990
sometimes we're horrified of the result

00:05:23,980 --> 00:05:28,419
right it's like here's a bunch of bash I

00:05:25,990 --> 00:05:32,410
just wrote Huck it over the fence it

00:05:28,419 --> 00:05:33,700
works and to make this a bit more of an

00:05:32,410 --> 00:05:35,350
issue though is that the amount of the

00:05:33,700 --> 00:05:37,180
data that you need to get from A to B is

00:05:35,350 --> 00:05:40,570
also increasing

00:05:37,180 --> 00:05:45,210
you know now-now medium-sized businesses

00:05:40,570 --> 00:05:47,680
are pushing petabytes of data I mean

00:05:45,210 --> 00:05:50,950
this is I believe this is most of us

00:05:47,680 --> 00:05:53,740
maybe you know maybe don't smoke but

00:05:50,950 --> 00:05:55,960
probably drink a little bit it's kind of

00:05:53,740 --> 00:05:57,669
like I've I know no worries write this

00:05:55,960 --> 00:05:59,919
this is not new to most of us I think

00:05:57,669 --> 00:06:01,330
we're aware of these problems or we're

00:05:59,919 --> 00:06:05,050
aware that they're gonna start occurring

00:06:01,330 --> 00:06:07,540
for us in organizations and you think I

00:06:05,050 --> 00:06:09,880
know a number of tools to solve a bunch

00:06:07,540 --> 00:06:12,220
of these problems III can combine them

00:06:09,880 --> 00:06:14,590
in a way that I can create a full

00:06:12,220 --> 00:06:16,630
package solution I think there's even a

00:06:14,590 --> 00:06:18,490
lot of consultants in the audience and

00:06:16,630 --> 00:06:20,650
then I know you all package a number of

00:06:18,490 --> 00:06:23,169
tools together as solutions and then

00:06:20,650 --> 00:06:24,550
sell them and then support them I think

00:06:23,169 --> 00:06:26,460
as individuals and teams we do this

00:06:24,550 --> 00:06:29,290
internally in our own companies as well

00:06:26,460 --> 00:06:30,669
we know we need to integrate things but

00:06:29,290 --> 00:06:33,010
to integrate things we have to build

00:06:30,669 --> 00:06:36,700
something whether it be bash or Perl or

00:06:33,010 --> 00:06:40,479
Ruby or golang and then we need to scale

00:06:36,700 --> 00:06:40,810
these things and then of course your

00:06:40,479 --> 00:06:42,580
present

00:06:40,810 --> 00:06:45,370
with that question all the time was I do

00:06:42,580 --> 00:06:46,720
I build or buy right now you still have

00:06:45,370 --> 00:06:48,610
to integrate and build when you buy

00:06:46,720 --> 00:06:50,080
something but maybe it gets you a little

00:06:48,610 --> 00:06:53,350
bit further they sell you on that

00:06:50,080 --> 00:06:56,380
turnkey experience but really you you

00:06:53,350 --> 00:06:57,580
hesitate to build in most cases because

00:06:56,380 --> 00:06:59,530
you're aware of this problem that you

00:06:57,580 --> 00:07:02,440
need to maintain whatever it is that you

00:06:59,530 --> 00:07:04,840
build right I think this is the the

00:07:02,440 --> 00:07:06,220
highest cost for building any sort of

00:07:04,840 --> 00:07:13,000
solution in the space to solve these

00:07:06,220 --> 00:07:14,410
problems yeah that was basics so if you

00:07:13,000 --> 00:07:17,260
if you're thinking about building

00:07:14,410 --> 00:07:19,300
something just hold that thought so I'll

00:07:17,260 --> 00:07:23,770
talk about my experience I did this

00:07:19,300 --> 00:07:25,240
exact thing in in 2010-2011 where I had

00:07:23,770 --> 00:07:25,810
to scratch my own itch and solve my

00:07:25,240 --> 00:07:27,310
problems

00:07:25,810 --> 00:07:29,770
I can't we just talked about just

00:07:27,310 --> 00:07:32,229
briefly my experience in that journey

00:07:29,770 --> 00:07:34,570
and I'll get to monitoring pipelines

00:07:32,229 --> 00:07:36,790
right after so I joined a company called

00:07:34,570 --> 00:07:40,870
Sonia in 2010 John is an automation

00:07:36,790 --> 00:07:41,950
engineer I was an operator working at a

00:07:40,870 --> 00:07:43,300
company that was on the bleeding edge

00:07:41,950 --> 00:07:45,460
early adopters of a number of

00:07:43,300 --> 00:07:48,760
technologies AWS one there was only like

00:07:45,460 --> 00:07:52,120
three services the ec2 us three and one

00:07:48,760 --> 00:07:55,690
other one and then EBS was actually a

00:07:52,120 --> 00:07:57,160
separate service for a brief moment and

00:07:55,690 --> 00:07:58,390
there's an extreme high rate of change

00:07:57,160 --> 00:08:02,260
right the team is just growing rapidly

00:07:58,390 --> 00:08:04,660
our technology stack kept changing but

00:08:02,260 --> 00:08:06,430
right after I joined I was woken up you

00:08:04,660 --> 00:08:09,190
know every time I was on call we're

00:08:06,430 --> 00:08:12,850
getting 45 pages on average at night so

00:08:09,190 --> 00:08:14,800
I was waking up very often you know I

00:08:12,850 --> 00:08:18,729
was not effective during the daytime

00:08:14,800 --> 00:08:20,470
because I wasn't sleeping and really it

00:08:18,729 --> 00:08:22,960
was like these as cloud infrastructure

00:08:20,470 --> 00:08:25,419
that early paradigm shift causing all

00:08:22,960 --> 00:08:27,789
these problems for us that existing

00:08:25,419 --> 00:08:29,380
tools didn't really work we looked at

00:08:27,789 --> 00:08:31,600
buying things there weren't really any

00:08:29,380 --> 00:08:34,750
products we're too early for a lot of

00:08:31,600 --> 00:08:36,700
stuff so we needed to solve it so I came

00:08:34,750 --> 00:08:38,950
out with a project with some goals in

00:08:36,700 --> 00:08:41,229
2011 to handle a femoral compute

00:08:38,950 --> 00:08:43,089
leverage existing familiar technologies

00:08:41,229 --> 00:08:45,339
so be able to use my service checks my

00:08:43,089 --> 00:08:48,010
Nagios plugins I mean there's over

00:08:45,339 --> 00:08:49,990
decades of people's time invest in that

00:08:48,010 --> 00:08:52,330
and it needs to be easy to drive with

00:08:49,990 --> 00:08:54,730
config management easy to scale

00:08:52,330 --> 00:08:58,630
horizontally not up but out

00:08:54,730 --> 00:09:00,310
and then api's god-like in 2010 why was

00:08:58,630 --> 00:09:03,220
it that no monitoring tool had a bloody

00:09:00,310 --> 00:09:05,860
API I was like here's a UNIX domain

00:09:03,220 --> 00:09:10,510
socket - cat and then read some data

00:09:05,860 --> 00:09:12,190
from so I ended up doing a weekend

00:09:10,510 --> 00:09:14,260
project that create an agent-based

00:09:12,190 --> 00:09:16,560
system with auto discoveries so it just

00:09:14,260 --> 00:09:19,269
self-register all your monitoring agents

00:09:16,560 --> 00:09:22,089
it used a message bus for communication

00:09:19,269 --> 00:09:25,060
so that gave me the ease of a horizontal

00:09:22,089 --> 00:09:27,610
scale simple key value data store was

00:09:25,060 --> 00:09:29,350
easy to operationalize central service

00:09:27,610 --> 00:09:30,519
check scheduler Jason configuration

00:09:29,350 --> 00:09:33,970
which is easy to drive with config

00:09:30,519 --> 00:09:35,350
management and of course REST API s so

00:09:33,970 --> 00:09:40,990
this is my first diagram that I made for

00:09:35,350 --> 00:09:43,389
a blog post back in 2011 it shows that I

00:09:40,990 --> 00:09:44,980
check and walk over here this is the

00:09:43,389 --> 00:09:46,709
back end scheduler and you can scale it

00:09:44,980 --> 00:09:49,660
out horizontally and it basically

00:09:46,709 --> 00:09:51,790
publishes check requests or like I need

00:09:49,660 --> 00:09:54,130
these groups of machines to run this

00:09:51,790 --> 00:09:56,529
thing it goes through here you can see

00:09:54,130 --> 00:09:58,959
that I've got elastic and web server

00:09:56,529 --> 00:10:00,850
here so those the correct check requests

00:09:58,959 --> 00:10:02,079
go on to those clients they execute them

00:10:00,850 --> 00:10:04,329
and then push results back for

00:10:02,079 --> 00:10:06,160
processing we store it and then we can

00:10:04,329 --> 00:10:08,589
serve it up via the API and we can do

00:10:06,160 --> 00:10:10,329
interesting things we also have api's

00:10:08,589 --> 00:10:13,529
and ingestion points into the client so

00:10:10,329 --> 00:10:15,160
you can push data in this was quite

00:10:13,529 --> 00:10:17,319
interesting at the time it's very

00:10:15,160 --> 00:10:20,920
different than many of the tools in

00:10:17,319 --> 00:10:22,329
2010-2011 and I actually got it people

00:10:20,920 --> 00:10:23,500
gave me a hard time for this diagram

00:10:22,329 --> 00:10:25,600
because it's not that great but also

00:10:23,500 --> 00:10:27,850
they said there's too many arrows on it

00:10:25,600 --> 00:10:32,139
and they're like we need to use Nagios

00:10:27,850 --> 00:10:33,760
to monitor sense you here's a cool anime

00:10:32,139 --> 00:10:36,190
gif I made after for those people that

00:10:33,760 --> 00:10:38,829
gave me a hard time just demonstrating

00:10:36,190 --> 00:10:41,550
kind of the flow of this really

00:10:38,829 --> 00:10:44,800
rudimentary simple agent based system

00:10:41,550 --> 00:10:47,529
and and really this allowed me to make

00:10:44,800 --> 00:10:51,430
those shifts right from host-based to

00:10:47,529 --> 00:10:55,510
role based monitoring from pole bays to

00:10:51,430 --> 00:10:56,889
pub/sub and push it could really address

00:10:55,510 --> 00:11:01,269
a lot of those problems to that design

00:10:56,889 --> 00:11:03,120
so it was designed for the cloud ok cool

00:11:01,269 --> 00:11:04,990
proved to handle a femoral compute

00:11:03,120 --> 00:11:07,149
operated securely on public networks

00:11:04,990 --> 00:11:08,620
because I just leveraged an existing

00:11:07,149 --> 00:11:11,440
message bus for Evan MQ

00:11:08,620 --> 00:11:13,870
I had proper TLS ecl's and a few other

00:11:11,440 --> 00:11:15,970
things so it worked great in public net

00:11:13,870 --> 00:11:19,000
or insecure networks which I would argue

00:11:15,970 --> 00:11:21,070
is every network and really just

00:11:19,000 --> 00:11:23,560
focusing on composability and

00:11:21,070 --> 00:11:25,120
extensibility you know creating those

00:11:23,560 --> 00:11:27,280
reusable components and building blocks

00:11:25,120 --> 00:11:28,630
was really the only way that I could cut

00:11:27,280 --> 00:11:32,050
down on the cost of that maintenance

00:11:28,630 --> 00:11:34,480
right so by making it so extensible but

00:11:32,050 --> 00:11:37,120
creating a framework for people in which

00:11:34,480 --> 00:11:38,770
to operate and extend kind of keep

00:11:37,120 --> 00:11:41,830
things within the guidelines you don't

00:11:38,770 --> 00:11:45,460
have so much sprawl and almost diversity

00:11:41,830 --> 00:11:47,590
in the code base so what we ended up

00:11:45,460 --> 00:11:49,060
with wear this cool framework and these

00:11:47,590 --> 00:11:51,040
components are at the time I called

00:11:49,060 --> 00:11:53,290
primitives where you could create your

00:11:51,040 --> 00:11:56,170
check objects you create your filters

00:11:53,290 --> 00:11:58,090
your mutaters and your handlers and what

00:11:56,170 --> 00:11:59,950
you ended up with is an emitter of an

00:11:58,090 --> 00:12:02,650
event being the check filters to

00:11:59,950 --> 00:12:04,690
self-select and drop some mutaters to

00:12:02,650 --> 00:12:06,640
transform and then handlers to take

00:12:04,690 --> 00:12:10,720
actions such as alerting or writing to a

00:12:06,640 --> 00:12:13,690
time-series database or triggering an

00:12:10,720 --> 00:12:15,670
danceable run for auto remediation named

00:12:13,690 --> 00:12:16,950
it sense you I spent two months in Japan

00:12:15,670 --> 00:12:19,180
I was obsessed with Japanese culture

00:12:16,950 --> 00:12:22,000
plus since he was actually the Japanese

00:12:19,180 --> 00:12:24,700
word for folding fan which made from

00:12:22,000 --> 00:12:28,480
bamboo and paper and that's why our logo

00:12:24,700 --> 00:12:31,600
is actually a fan so info there we open

00:12:28,480 --> 00:12:36,600
sourced it under MIT and was interesting

00:12:31,600 --> 00:12:39,310
is let's see if conference Wi-Fi works

00:12:36,600 --> 00:12:41,050
this is the sense you plugins project

00:12:39,310 --> 00:12:44,140
that kind of just came out at the same

00:12:41,050 --> 00:12:45,850
time and by being by focusing on

00:12:44,140 --> 00:12:47,890
composability and extensibility and

00:12:45,850 --> 00:12:50,650
these frameworks it made it extremely

00:12:47,890 --> 00:12:52,270
easy for anyone to not only write check

00:12:50,650 --> 00:12:54,340
plug-ins but also filter plug-ins

00:12:52,270 --> 00:12:56,920
mutator plugins and handler plugins and

00:12:54,340 --> 00:12:58,480
we basically just got this momentum

00:12:56,920 --> 00:13:00,970
around this open source project around

00:12:58,480 --> 00:13:02,620
this so I made me ask the question it's

00:13:00,970 --> 00:13:04,780
like why is this picking up steam and

00:13:02,620 --> 00:13:06,750
people are using it you know what is it

00:13:04,780 --> 00:13:09,160
about composability and extensibility

00:13:06,750 --> 00:13:11,290
and you know using this like message bus

00:13:09,160 --> 00:13:15,100
and pub/sub model that's making sense to

00:13:11,290 --> 00:13:16,930
all these people and for a while you

00:13:15,100 --> 00:13:19,030
know we had this narrative were like

00:13:16,930 --> 00:13:21,190
what is sense to you and it was

00:13:19,030 --> 00:13:22,450
difficult I explaining what the heck

00:13:21,190 --> 00:13:24,940
since he was I was like

00:13:22,450 --> 00:13:26,920
an open-source Nagios replacement it was

00:13:24,940 --> 00:13:28,690
the easiest way I could explain it but

00:13:26,920 --> 00:13:31,030
then people started to to kind of

00:13:28,690 --> 00:13:33,270
gravitate to the monitoring framework

00:13:31,030 --> 00:13:35,590
right that composability framework

00:13:33,270 --> 00:13:37,450
extensibility framework monitor router

00:13:35,590 --> 00:13:39,880
it can route data it's different data

00:13:37,450 --> 00:13:42,280
lakes or data bagels or wherever you

00:13:39,880 --> 00:13:44,080
want to put your stuff or the monitoring

00:13:42,280 --> 00:13:46,450
bus right it's something I just throw

00:13:44,080 --> 00:13:52,480
data onto and it ends up in the right

00:13:46,450 --> 00:13:53,620
place and then eventually you know we

00:13:52,480 --> 00:13:55,270
kind of landed on the monitoring

00:13:53,620 --> 00:13:58,330
pipeline this is something I think as

00:13:55,270 --> 00:14:00,520
2013 when we started to message this

00:13:58,330 --> 00:14:01,840
because you know we have pipelines for

00:14:00,520 --> 00:14:04,740
other parts of our infrastructure right

00:14:01,840 --> 00:14:07,540
we have CI like C ICD pipelines

00:14:04,740 --> 00:14:10,030
deployment pipelines ways that we

00:14:07,540 --> 00:14:12,130
construct from an action or something

00:14:10,030 --> 00:14:14,410
emits data here then there's a series of

00:14:12,130 --> 00:14:14,770
events and then something happens over

00:14:14,410 --> 00:14:16,840
there

00:14:14,770 --> 00:14:20,920
so it was a it was a easy way to

00:14:16,840 --> 00:14:22,300
describe sensu that was close to the

00:14:20,920 --> 00:14:25,060
things that people were already starting

00:14:22,300 --> 00:14:26,680
to build now what's interesting is in

00:14:25,060 --> 00:14:28,830
the last two months

00:14:26,680 --> 00:14:30,730
you know observability seems to be like

00:14:28,830 --> 00:14:32,230
everyone's just replacing the word

00:14:30,730 --> 00:14:35,410
monitoring with observability and it's

00:14:32,230 --> 00:14:37,390
the same thing but i would say that you

00:14:35,410 --> 00:14:38,860
know monitoring is the what and

00:14:37,390 --> 00:14:41,560
observability is the how or the deep

00:14:38,860 --> 00:14:43,720
introspection but now this is starting

00:14:41,560 --> 00:14:45,400
to become a popular term and I'm happy

00:14:43,720 --> 00:14:47,740
about that finally like it's only been

00:14:45,400 --> 00:14:49,270
six years I mean trying to explain the

00:14:47,740 --> 00:14:52,030
modern pipeline now they called them the

00:14:49,270 --> 00:14:53,680
observability pipeline which is great

00:14:52,030 --> 00:14:56,080
for me because now everybody's starting

00:14:53,680 --> 00:14:59,320
to understand the the idea and the

00:14:56,080 --> 00:15:02,020
concept so what is a monitoring pipeline

00:14:59,320 --> 00:15:04,330
my best way that I can summarize it is a

00:15:02,020 --> 00:15:05,950
unified data collection and processing

00:15:04,330 --> 00:15:08,710
for all types of monitoring events

00:15:05,950 --> 00:15:11,080
basically one way to collect your

00:15:08,710 --> 00:15:13,090
monitoring data and one way to process

00:15:11,080 --> 00:15:14,830
it and push it into something this

00:15:13,090 --> 00:15:18,040
applies to your service checks your

00:15:14,830 --> 00:15:20,260
metrics your traces your logs your

00:15:18,040 --> 00:15:22,420
inventory like I just found new servers

00:15:20,260 --> 00:15:25,840
new network gear that kind of thing

00:15:22,420 --> 00:15:28,480
these are all monitoring events there

00:15:25,840 --> 00:15:30,760
are two critical layers to a monitoring

00:15:28,480 --> 00:15:33,940
event pipeline the data plane and

00:15:30,760 --> 00:15:35,530
control plane the data plane you can

00:15:33,940 --> 00:15:36,250
think of this is the body of the system

00:15:35,530 --> 00:15:39,120
it's really

00:15:36,250 --> 00:15:41,530
you know data input data transportation

00:15:39,120 --> 00:15:42,130
durability routing low balancing

00:15:41,530 --> 00:15:44,590
failover

00:15:42,130 --> 00:15:47,050
it's kind of the it's just the vessel

00:15:44,590 --> 00:15:49,270
right it's it's just there to load the

00:15:47,050 --> 00:15:51,270
data on and get it somewhere and this

00:15:49,270 --> 00:15:53,110
happens to be the layer that developers

00:15:51,270 --> 00:15:55,030
traditionally interact with these are

00:15:53,110 --> 00:15:56,590
the api's right just give me a socket

00:15:55,030 --> 00:15:58,720
and a protocol that's all I wanted to

00:15:56,590 --> 00:16:00,190
develop her I don't want to I don't want

00:15:58,720 --> 00:16:02,590
to know about your pipelines or whatever

00:16:00,190 --> 00:16:04,030
your you're talking about just tell me

00:16:02,590 --> 00:16:05,230
where I got to put my data and then show

00:16:04,030 --> 00:16:08,290
me where I got a look to see the

00:16:05,230 --> 00:16:09,760
dashboard then you've got the control

00:16:08,290 --> 00:16:13,440
plane and I would argue that this is

00:16:09,760 --> 00:16:15,910
actually the most important part of a

00:16:13,440 --> 00:16:17,410
monitoring pipeline it is the the brain

00:16:15,910 --> 00:16:19,090
for the body it is the central

00:16:17,410 --> 00:16:22,150
management unit the orchestrator the

00:16:19,090 --> 00:16:23,950
configuration security off this is

00:16:22,150 --> 00:16:26,260
composed everything from the API is the

00:16:23,950 --> 00:16:28,900
agent the data processors anything that

00:16:26,260 --> 00:16:30,820
really informs the pipeline how it works

00:16:28,900 --> 00:16:32,740
or how it should work and what to do

00:16:30,820 --> 00:16:34,810
with certain types of data this is the

00:16:32,740 --> 00:16:36,750
layer operators interact with right

00:16:34,810 --> 00:16:40,240
because we compose these pipelines for

00:16:36,750 --> 00:16:43,410
simply to be consumed by developers I

00:16:40,240 --> 00:16:46,000
would say that anyone can build this

00:16:43,410 --> 00:16:48,010
this is easy right this is let's grab

00:16:46,000 --> 00:16:50,290
Kafka right that's the best data plane

00:16:48,010 --> 00:16:52,150
that you can just grab what I'd say is

00:16:50,290 --> 00:16:55,090
the the difficult part and the harder

00:16:52,150 --> 00:16:57,970
part to maintain is the brain is the

00:16:55,090 --> 00:16:59,350
control plane now if you're confused on

00:16:57,970 --> 00:17:02,350
what data plane control plane and all

00:16:59,350 --> 00:17:04,150
this jargon there's a great YouTube

00:17:02,350 --> 00:17:06,760
video that was actually put out there by

00:17:04,150 --> 00:17:08,980
Microsoft and hashey Corp and they they

00:17:06,760 --> 00:17:11,080
explained the data plane and control

00:17:08,980 --> 00:17:13,090
plane kind of separation as it applies

00:17:11,080 --> 00:17:15,400
to service meshes and what's interesting

00:17:13,090 --> 00:17:17,590
is like a service mesh isn't all that

00:17:15,400 --> 00:17:20,380
different from a monitoring and pipeline

00:17:17,590 --> 00:17:21,700
it's a great great great simple

00:17:20,380 --> 00:17:24,340
explanation of a what the heck is a

00:17:21,700 --> 00:17:28,180
service mesh and B what what is the

00:17:24,340 --> 00:17:30,100
separation mean to operators now you've

00:17:28,180 --> 00:17:32,110
got those two layers and and but you

00:17:30,100 --> 00:17:33,490
need the end result right where's this

00:17:32,110 --> 00:17:35,020
data going how our people are going to

00:17:33,490 --> 00:17:37,360
consume it how is it going to be useful

00:17:35,020 --> 00:17:39,850
so you're gonna have any sort of time

00:17:37,360 --> 00:17:42,880
series storage or event storage log

00:17:39,850 --> 00:17:44,680
storage alert mechanisms chats that kind

00:17:42,880 --> 00:17:49,030
of thing or incident management like

00:17:44,680 --> 00:17:49,570
ServiceNow or bigquery and BigTable at

00:17:49,030 --> 00:17:52,120
Google

00:17:49,570 --> 00:17:54,779
if you have a big data problem so

00:17:52,120 --> 00:17:57,399
there's a this is kind of like a common

00:17:54,779 --> 00:17:58,840
bi-directional monitoring pipeline or

00:17:57,399 --> 00:18:00,960
observability pipeline that's being

00:17:58,840 --> 00:18:03,519
thrown around in the last six months

00:18:00,960 --> 00:18:05,289
where you have your VM your container

00:18:03,519 --> 00:18:07,990
your data collector that pushes into a

00:18:05,289 --> 00:18:10,059
pipeline it's probably Kafka or Amazon

00:18:07,990 --> 00:18:11,830
Kinesis or something then you have one

00:18:10,059 --> 00:18:13,870
or more data routers which are

00:18:11,830 --> 00:18:15,909
processing that information there's some

00:18:13,870 --> 00:18:18,070
sort of rules engine and then it writes

00:18:15,909 --> 00:18:20,799
it to a data back in and it's just

00:18:18,070 --> 00:18:23,169
surprising to me how many people set out

00:18:20,799 --> 00:18:24,909
to build this themselves like I know I

00:18:23,169 --> 00:18:29,649
can solve that problem hold my beer I

00:18:24,909 --> 00:18:31,240
got this I'm gonna build this and you

00:18:29,649 --> 00:18:32,769
know it can be scary because if you're

00:18:31,240 --> 00:18:34,450
looking at how many technologies are at

00:18:32,769 --> 00:18:37,389
play here right and that it's gonna

00:18:34,450 --> 00:18:39,039
differ between a job here and if you

00:18:37,389 --> 00:18:42,399
leave and go somewhere else it's gonna

00:18:39,039 --> 00:18:44,710
be a wholly different version so I think

00:18:42,399 --> 00:18:46,690
there's a lot of merit to this but no

00:18:44,710 --> 00:18:48,100
why the heck would you do this

00:18:46,690 --> 00:18:49,750
right there's a lot of components

00:18:48,100 --> 00:18:52,299
there's a lot of complexity that's a lot

00:18:49,750 --> 00:18:54,159
to maintain so why would you do it I

00:18:52,299 --> 00:18:56,500
think the main reason why you do a

00:18:54,159 --> 00:18:58,720
modern pipeline is to not only die

00:18:56,500 --> 00:19:00,250
tackle these challenges around these

00:18:58,720 --> 00:19:02,529
paradigm shifts and changes on our

00:19:00,250 --> 00:19:04,750
infrastructure and applications but it's

00:19:02,529 --> 00:19:08,700
really about the ability to change your

00:19:04,750 --> 00:19:13,360
mind right even if we look at this one

00:19:08,700 --> 00:19:14,889
the constant here is this right you're

00:19:13,360 --> 00:19:17,019
collecting your six types of monitoring

00:19:14,889 --> 00:19:20,409
event data that's the constant that

00:19:17,019 --> 00:19:22,450
doesn't really change what changes is on

00:19:20,409 --> 00:19:24,340
the right side here the data routers and

00:19:22,450 --> 00:19:26,500
the data back ends right and you can you

00:19:24,340 --> 00:19:28,419
interchange them you can try another

00:19:26,500 --> 00:19:30,909
time series database you can write to

00:19:28,419 --> 00:19:33,309
both time series databases you can even

00:19:30,909 --> 00:19:35,830
not pay that database for h.a and you

00:19:33,309 --> 00:19:37,629
just double right to two instances you

00:19:35,830 --> 00:19:39,580
can do interesting things I think you

00:19:37,629 --> 00:19:40,899
know the freedom to change your mind is

00:19:39,580 --> 00:19:43,179
really the power you can change your

00:19:40,899 --> 00:19:44,980
data store you can change your metric

00:19:43,179 --> 00:19:46,779
formats you can change your

00:19:44,980 --> 00:19:49,419
visualization component although why

00:19:46,779 --> 00:19:51,100
would you just use graph on ax you can

00:19:49,419 --> 00:19:53,440
change your sampling method right I

00:19:51,100 --> 00:19:55,600
think now we're starting to talk about

00:19:53,440 --> 00:19:58,419
tracing and retrace and we sample at the

00:19:55,600 --> 00:20:00,669
edge but what if you say let's throw all

00:19:58,419 --> 00:20:01,990
my data into my pipeline let's sample at

00:20:00,669 --> 00:20:03,100
the end where it can be more intelligent

00:20:01,990 --> 00:20:04,539
you know

00:20:03,100 --> 00:20:06,549
that these are kind of changes you can

00:20:04,539 --> 00:20:08,019
make quite easily you can change

00:20:06,549 --> 00:20:10,059
platforms you can add support for other

00:20:08,019 --> 00:20:13,149
platforms you can make change

00:20:10,059 --> 00:20:16,389
inexpensive I mean this in the amount of

00:20:13,149 --> 00:20:17,980
time to effort and cost because really

00:20:16,389 --> 00:20:20,200
you end up punching above your weight in

00:20:17,980 --> 00:20:22,659
terms of functionality you have to like

00:20:20,200 --> 00:20:24,639
pay big dollars to get anything close to

00:20:22,659 --> 00:20:28,690
this kind of functionality in a

00:20:24,639 --> 00:20:30,610
commercial you know product even like

00:20:28,690 --> 00:20:32,169
spunk right they try and build this

00:20:30,610 --> 00:20:34,809
giant behemoth that does all these

00:20:32,169 --> 00:20:37,179
things but you also want to make a

00:20:34,809 --> 00:20:38,919
future-proof right like as I said that

00:20:37,179 --> 00:20:41,590
the changes in are in the way that we

00:20:38,919 --> 00:20:44,620
deploy infrastructure and manage it it's

00:20:41,590 --> 00:20:46,929
just getting getting accelerated so we

00:20:44,620 --> 00:20:48,490
have to be able to take an approach

00:20:46,929 --> 00:20:50,529
where I'm gonna go all the way back to

00:20:48,490 --> 00:20:53,259
this we can have some constants in our

00:20:50,529 --> 00:20:56,169
life right one agent you know five

00:20:53,259 --> 00:20:58,149
metric formats whatever that is some way

00:20:56,169 --> 00:21:02,259
of like having a rock to really build

00:20:58,149 --> 00:21:05,350
our backbone of our nervous system for

00:21:02,259 --> 00:21:08,289
infrastructure on another reason is pure

00:21:05,350 --> 00:21:10,750
agents right less edge services to

00:21:08,289 --> 00:21:12,639
support resource utilization is better

00:21:10,750 --> 00:21:14,350
you don't have so many side cars you

00:21:12,639 --> 00:21:16,509
like deploy you're like tiny web app on

00:21:14,350 --> 00:21:18,250
kubernetes and then like eight sidecar

00:21:16,509 --> 00:21:19,659
processes then you look at your

00:21:18,250 --> 00:21:20,230
utilization chart you're like that's

00:21:19,659 --> 00:21:22,870
cool

00:21:20,230 --> 00:21:28,179
I'm spending like 50% of my compute

00:21:22,870 --> 00:21:30,549
cluster on side cars cost savings yeah I

00:21:28,179 --> 00:21:32,980
think it's just you know I've kind of

00:21:30,549 --> 00:21:34,840
touched on how you can save on that so

00:21:32,980 --> 00:21:37,179
let's jump into attributes of an

00:21:34,840 --> 00:21:40,450
effective pipeline so really what makes

00:21:37,179 --> 00:21:43,090
a good pipeline I would say it means

00:21:40,450 --> 00:21:45,909
event payload either one kind of a

00:21:43,090 --> 00:21:46,480
unified payload or a set of unified

00:21:45,909 --> 00:21:49,570
payloads

00:21:46,480 --> 00:21:51,309
and with unique IDs we need to be able

00:21:49,570 --> 00:21:53,710
to source and identify where a

00:21:51,309 --> 00:21:56,440
particular data came from and its path

00:21:53,710 --> 00:21:58,299
through the pipeline capture context at

00:21:56,440 --> 00:22:01,389
collection time so we need to be a

00:21:58,299 --> 00:22:03,100
ability to understand when something

00:22:01,389 --> 00:22:04,480
happens as captured as much as we can

00:22:03,100 --> 00:22:07,000
and represent that within our single

00:22:04,480 --> 00:22:09,070
payload that's incredibly important for

00:22:07,000 --> 00:22:11,980
triaging issues and working through

00:22:09,070 --> 00:22:13,929
incidents support for additional

00:22:11,980 --> 00:22:16,570
metadata it needs to be freeform so that

00:22:13,929 --> 00:22:16,990
any developer can simply I start adding

00:22:16,570 --> 00:22:19,419
lis

00:22:16,990 --> 00:22:21,370
and tags and annotations really to

00:22:19,419 --> 00:22:23,740
enrich the data to make it easier for

00:22:21,370 --> 00:22:26,140
the operator on the other end or whoever

00:22:23,740 --> 00:22:27,429
is getting woken up at night and it's

00:22:26,140 --> 00:22:29,559
really about supporting efficient

00:22:27,429 --> 00:22:31,299
debugging because we've replaced our

00:22:29,559 --> 00:22:33,039
monolith with micro services so that

00:22:31,299 --> 00:22:40,020
every outage can be more like a murder

00:22:33,039 --> 00:22:43,899
mystery I mean we do this to ourselves

00:22:40,020 --> 00:22:46,720
there's no one else to blame so here's

00:22:43,899 --> 00:22:48,909
an example of like event pail this is

00:22:46,720 --> 00:22:50,529
actually what since you go uses I'll be

00:22:48,909 --> 00:22:51,820
using a lot of like disclaimer I'm gonna

00:22:50,529 --> 00:22:53,919
be using a lot of sensitive stuff as

00:22:51,820 --> 00:22:55,179
examples for these components that's

00:22:53,919 --> 00:22:56,380
what I'm most familiar with and we've

00:22:55,179 --> 00:22:59,200
designed it in the way that we believe

00:22:56,380 --> 00:23:00,789
is the best way to do it so you end up

00:22:59,200 --> 00:23:02,799
with an event payload you have metadata

00:23:00,789 --> 00:23:06,029
which can be annotations and labels if

00:23:02,799 --> 00:23:09,039
you use kubernetes the exact same thing

00:23:06,029 --> 00:23:11,260
every event has an entity this is the

00:23:09,039 --> 00:23:13,120
context around the thing that you're

00:23:11,260 --> 00:23:15,309
monitoring this is incredibly important

00:23:13,120 --> 00:23:18,580
that you build your design a payload to

00:23:15,309 --> 00:23:20,919
always can contain the context of the

00:23:18,580 --> 00:23:23,649
source so this will describe a host or

00:23:20,919 --> 00:23:27,330
an application container and then we'll

00:23:23,649 --> 00:23:30,399
have a timestamp there's also a check

00:23:27,330 --> 00:23:33,190
representation because check information

00:23:30,399 --> 00:23:35,470
or check data is really around this like

00:23:33,190 --> 00:23:39,580
state machine right is it up sit down

00:23:35,470 --> 00:23:40,870
did it resolve is it flapping so if

00:23:39,580 --> 00:23:43,270
you're gonna if you're gonna put service

00:23:40,870 --> 00:23:44,620
checks into a pipeline payload you need

00:23:43,270 --> 00:23:47,500
to facilitate that with a very

00:23:44,620 --> 00:23:51,220
specialized kind of type for that steep

00:23:47,500 --> 00:23:53,020
machine modeling metrics is you also

00:23:51,220 --> 00:23:55,600
need a way that you can represent

00:23:53,020 --> 00:23:58,120
metrics within your payload and support

00:23:55,600 --> 00:23:59,590
many dimensions so you know tags and

00:23:58,120 --> 00:24:01,779
labels are a great way of adding

00:23:59,590 --> 00:24:03,279
dimensions to your to your metrics I

00:24:01,779 --> 00:24:06,039
think yesterday it was mentioned you

00:24:03,279 --> 00:24:08,440
know 50 percent of people were still

00:24:06,039 --> 00:24:10,840
putting like host names in their metric

00:24:08,440 --> 00:24:13,380
series names don't do that

00:24:10,840 --> 00:24:15,539
it should just be a tag or label

00:24:13,380 --> 00:24:18,100
collection agent should be lightweight

00:24:15,539 --> 00:24:20,080
multi-platform support many of us here

00:24:18,100 --> 00:24:23,470
use Linux and windows and Solaris and

00:24:20,080 --> 00:24:25,240
AIX I'm so sorry and a whole smattering

00:24:23,470 --> 00:24:26,559
of other technologies it needs to

00:24:25,240 --> 00:24:29,049
support them all because you need to

00:24:26,559 --> 00:24:30,789
have this single agent to deploy that

00:24:29,049 --> 00:24:32,320
consistency across everything

00:24:30,789 --> 00:24:34,719
again it's all about getting that

00:24:32,320 --> 00:24:36,820
consistency and that stability and that

00:24:34,719 --> 00:24:39,759
constant right that that collection

00:24:36,820 --> 00:24:41,679
agent in that pipeline established and

00:24:39,759 --> 00:24:44,949
you really need bi-directional

00:24:41,679 --> 00:24:46,989
communication that earlier pipeline an

00:24:44,949 --> 00:24:49,359
example that I showed was uni uni

00:24:46,989 --> 00:24:51,489
directional and the the agent just

00:24:49,359 --> 00:24:53,709
pushes data why I say it has to be

00:24:51,489 --> 00:24:57,579
bi-directional well you need your data

00:24:53,709 --> 00:25:00,429
plane can can still be simple but your

00:24:57,579 --> 00:25:02,349
control plane the brain of the pipeline

00:25:00,429 --> 00:25:04,119
needs to be able to orchestrate things

00:25:02,349 --> 00:25:06,909
needs to be able to install dependencies

00:25:04,119 --> 00:25:09,459
on agents needs to be able to say hey

00:25:06,909 --> 00:25:10,959
you should be monitoring this right we

00:25:09,459 --> 00:25:13,119
don't want just a push world we want

00:25:10,959 --> 00:25:15,609
push but they also the ability to

00:25:13,119 --> 00:25:18,549
pub/sub pull objects you need that

00:25:15,609 --> 00:25:20,109
bi-directional communication are we

00:25:18,549 --> 00:25:22,959
registration at the backend right this

00:25:20,109 --> 00:25:24,999
is to address the the ephemeral issue

00:25:22,959 --> 00:25:27,729
right things that come up should just

00:25:24,999 --> 00:25:29,229
simply be found you should become aware

00:25:27,729 --> 00:25:33,190
of them and then they should deregister

00:25:29,229 --> 00:25:34,629
when it comes time to remove should

00:25:33,190 --> 00:25:37,059
provide platform information system

00:25:34,629 --> 00:25:38,799
details and role and responsibilities

00:25:37,059 --> 00:25:41,409
auto discovery this should just be part

00:25:38,799 --> 00:25:42,969
of the agent there should be a keepalive

00:25:41,409 --> 00:25:45,519
heartbeat mechanism so you know when an

00:25:42,969 --> 00:25:47,769
agent dies when the host wasn't

00:25:45,519 --> 00:25:50,229
decommissioned you need service check

00:25:47,769 --> 00:25:52,809
execution support the thing is is like I

00:25:50,229 --> 00:25:54,849
find over here and in Germany and in

00:25:52,809 --> 00:25:57,639
Europe in general service checks are

00:25:54,849 --> 00:25:59,319
still so prevalent and and used I don't

00:25:57,639 --> 00:26:01,239
really have a hard time justifying this

00:25:59,319 --> 00:26:02,739
it's interesting to see like service

00:26:01,239 --> 00:26:06,279
checks are commonly overlooked and

00:26:02,739 --> 00:26:08,369
underappreciated in other areas and it's

00:26:06,279 --> 00:26:11,289
a great way of leveraging decades of

00:26:08,369 --> 00:26:14,319
investment you need to have some sort of

00:26:11,289 --> 00:26:17,049
durable outbound queue Telegraph is cool

00:26:14,319 --> 00:26:18,819
yesterday to see the Telegraph Q and the

00:26:17,049 --> 00:26:20,379
configurable queue length on the

00:26:18,819 --> 00:26:22,839
outbound stuff I think that's a good

00:26:20,379 --> 00:26:24,579
example is like we we know things can be

00:26:22,839 --> 00:26:25,989
unreliable we need to buffer data when

00:26:24,579 --> 00:26:29,349
it's unable to write and commit to the

00:26:25,989 --> 00:26:32,289
database the agent should have several

00:26:29,349 --> 00:26:34,209
data inputs industry standards let's

00:26:32,289 --> 00:26:35,739
support the standard metric format so

00:26:34,209 --> 00:26:37,899
that our developers can push data in

00:26:35,739 --> 00:26:41,319
using libraries they already have same a

00:26:37,899 --> 00:26:43,509
trace and structured logging our data

00:26:41,319 --> 00:26:44,570
transport needs to support TLS

00:26:43,509 --> 00:26:47,179
encryption

00:26:44,570 --> 00:26:50,000
Tway 19 you shouldn't be talking over

00:26:47,179 --> 00:26:53,120
any network if it's plaintext charlie

00:26:50,000 --> 00:26:54,889
encrypted should support a standard

00:26:53,120 --> 00:26:57,169
protocol something that he can run a

00:26:54,889 --> 00:27:00,590
load balancer or an application proxy

00:26:57,169 --> 00:27:03,710
with to like help traverse complex

00:27:00,590 --> 00:27:05,000
network topologies as well as the agents

00:27:03,710 --> 00:27:06,350
should initiate the connection to the

00:27:05,000 --> 00:27:08,870
back end so that you're not having to

00:27:06,350 --> 00:27:11,200
punch holes from like the central DMZ

00:27:08,870 --> 00:27:13,549
into all these separate data centers

00:27:11,200 --> 00:27:17,029
data processor has to be able to scale

00:27:13,549 --> 00:27:18,889
horizontally there should be as little

00:27:17,029 --> 00:27:21,500
coordination with its peers as possible

00:27:18,889 --> 00:27:25,159
this is really like distributed

00:27:21,500 --> 00:27:27,080
computers are paying the but we you want

00:27:25,159 --> 00:27:28,850
to eliminate these kind of distributed

00:27:27,080 --> 00:27:30,980
problems whenever you're possible so by

00:27:28,850 --> 00:27:32,690
limiting coordination kind of sharding

00:27:30,980 --> 00:27:35,269
between the separate independent

00:27:32,690 --> 00:27:37,669
backends will get you some some

00:27:35,269 --> 00:27:40,009
ease-of-use gains they also have to

00:27:37,669 --> 00:27:41,960
represent or present a good amount of

00:27:40,009 --> 00:27:44,059
concurrency and parallelism in the

00:27:41,960 --> 00:27:45,559
backend as well because as I said

00:27:44,059 --> 00:27:46,820
earlier the amount of data that we have

00:27:45,559 --> 00:27:48,980
to process through this pipeline is a

00:27:46,820 --> 00:27:51,649
virtue ever growing and we don't want to

00:27:48,980 --> 00:27:54,620
have to run you know like 50 machines to

00:27:51,649 --> 00:27:59,059
compute the data from 50 web

00:27:54,620 --> 00:28:00,799
applications needs to be easy to extend

00:27:59,059 --> 00:28:02,450
and integrate and I think this is what I

00:28:00,799 --> 00:28:04,909
hit on early and kind of ended up

00:28:02,450 --> 00:28:07,610
landing on this idea of the pipeline was

00:28:04,909 --> 00:28:10,360
that it's all about simple api's and

00:28:07,610 --> 00:28:13,399
clear specs and providing that framework

00:28:10,360 --> 00:28:15,230
that makes these things maintainable

00:28:13,399 --> 00:28:17,360
without that it's just the Wild West

00:28:15,230 --> 00:28:19,460
it's crazy you're not gonna have a fun

00:28:17,360 --> 00:28:21,500
time or more importantly whoever comes

00:28:19,460 --> 00:28:23,000
after you is definitely not having a

00:28:21,500 --> 00:28:24,919
good time

00:28:23,000 --> 00:28:27,799
multi-tenancy to enable self-service

00:28:24,919 --> 00:28:30,289
we're seeing a lot now where operators

00:28:27,799 --> 00:28:32,120
and our teams within organizations are

00:28:30,289 --> 00:28:34,460
providing platforms who become more of a

00:28:32,120 --> 00:28:38,509
platform team for developers so we

00:28:34,460 --> 00:28:40,490
provide a like monitoring as a service

00:28:38,509 --> 00:28:42,769
right so I need to be able to slice and

00:28:40,490 --> 00:28:45,230
dice my pipeline in a way that I can be

00:28:42,769 --> 00:28:46,909
like you get a pipeline you get pipeline

00:28:45,230 --> 00:28:50,750
you get a pipe I was like the Oprah

00:28:46,909 --> 00:28:53,029
Winfrey of of monitoring filtering this

00:28:50,750 --> 00:28:55,039
is the secret sauce any effective

00:28:53,029 --> 00:28:57,740
pipeline has to be able to have granular

00:28:55,039 --> 00:28:58,700
routing right does this does this event

00:28:57,740 --> 00:29:01,130
data

00:28:58,700 --> 00:29:03,260
indicate an incident right a resolution

00:29:01,130 --> 00:29:05,290
does it contain metric data is it

00:29:03,260 --> 00:29:08,030
production is it during office hours

00:29:05,290 --> 00:29:09,760
right this is this is a part of that

00:29:08,030 --> 00:29:13,210
brain this is part of the control plane

00:29:09,760 --> 00:29:15,110
without it you just have a dumb pipe

00:29:13,210 --> 00:29:17,780
transformation you need to be able to

00:29:15,110 --> 00:29:19,010
transform things so having that API and

00:29:17,780 --> 00:29:20,840
that spec to be able to write these

00:29:19,010 --> 00:29:23,900
extensions that can take that format a

00:29:20,840 --> 00:29:25,280
and turn into format be efficiently this

00:29:23,900 --> 00:29:26,600
is great because you can just funnel

00:29:25,280 --> 00:29:28,040
more and more different types of data

00:29:26,600 --> 00:29:30,620
into your pipeline and these

00:29:28,040 --> 00:29:33,950
transformers can take it and process it

00:29:30,620 --> 00:29:36,620
in a repeatable way and then pass it on

00:29:33,950 --> 00:29:38,600
to actions so actions are really the

00:29:36,620 --> 00:29:41,270
bread and butter part of the pipeline

00:29:38,600 --> 00:29:43,220
right you're alert notifications you're

00:29:41,270 --> 00:29:46,790
incident management metric an event

00:29:43,220 --> 00:29:48,110
storage inventory our mediation you name

00:29:46,790 --> 00:29:53,600
it this is kind of what you're actually

00:29:48,110 --> 00:29:56,150
doing with that data so this is an

00:29:53,600 --> 00:29:58,010
example of a monitoring pipeline right

00:29:56,150 --> 00:30:00,020
and what's interesting is you can have a

00:29:58,010 --> 00:30:02,690
single event actually hit multiple

00:30:00,020 --> 00:30:04,370
pipelines kind of confusing because you

00:30:02,690 --> 00:30:05,750
have a monitoring event pipeline but

00:30:04,370 --> 00:30:09,140
within it there's actually multiple

00:30:05,750 --> 00:30:11,510
pipelines what I mean by that is that I

00:30:09,140 --> 00:30:14,600
can have say a service check run and it

00:30:11,510 --> 00:30:15,740
says the system is down I actually want

00:30:14,600 --> 00:30:17,929
to handle that in a number of different

00:30:15,740 --> 00:30:20,510
ways so I pass it to all my pipelines is

00:30:17,929 --> 00:30:22,309
it an incident yes so goes through here

00:30:20,510 --> 00:30:24,140
do I need to transform the event data no

00:30:22,309 --> 00:30:25,580
goes to the action what am I gonna do

00:30:24,140 --> 00:30:27,280
with it I'm gonna send it to pager duty

00:30:25,580 --> 00:30:30,650
I now have an incident in page of duty

00:30:27,280 --> 00:30:33,559
over here once every 30 minutes okay

00:30:30,650 --> 00:30:37,190
well it's not the right time so drop it

00:30:33,559 --> 00:30:40,550
we're not gonna send it to slack filter

00:30:37,190 --> 00:30:41,270
only metrics well it's a check so it's

00:30:40,550 --> 00:30:43,640
not gonna go this way

00:30:41,270 --> 00:30:45,590
drop it only production it is production

00:30:43,640 --> 00:30:47,929
let's transform it let's add some

00:30:45,590 --> 00:30:50,600
annotations we go it's from this data

00:30:47,929 --> 00:30:52,190
center this team responded to it passed

00:30:50,600 --> 00:30:55,070
to the action what do we do with it we

00:30:52,190 --> 00:30:59,150
write to elastic right we're gonna add

00:30:55,070 --> 00:31:00,290
this to our event store so that we can

00:30:59,150 --> 00:31:02,630
do reporting on it later

00:31:00,290 --> 00:31:05,270
only logs not log data only incidents

00:31:02,630 --> 00:31:07,730
yes transform nothing action it goes

00:31:05,270 --> 00:31:11,059
into ServiceNow so that single service

00:31:07,730 --> 00:31:12,230
check by our filtering logic went to

00:31:11,059 --> 00:31:16,070
pager duty

00:31:12,230 --> 00:31:18,559
servicenow and elastic that's pretty

00:31:16,070 --> 00:31:20,929
cool right and to that point about

00:31:18,559 --> 00:31:22,549
earlier making it easy to change I can

00:31:20,929 --> 00:31:25,720
simply add and remove as many pipelines

00:31:22,549 --> 00:31:28,190
as I want here I can be like duet

00:31:25,720 --> 00:31:30,679
elastics give me a hard time yeah by

00:31:28,190 --> 00:31:36,049
really like MongoDB for some reason I'm

00:31:30,679 --> 00:31:38,690
gonna put my data in there so going back

00:31:36,049 --> 00:31:41,090
to this the issues with this where a was

00:31:38,690 --> 00:31:43,910
bespoke it was created by an

00:31:41,090 --> 00:31:47,330
organization there's no like defined

00:31:43,910 --> 00:31:50,169
framework right it's uni-directional

00:31:47,330 --> 00:31:52,760
so it's going from the left to the right

00:31:50,169 --> 00:31:56,419
there's a very strong data plane very

00:31:52,760 --> 00:31:57,770
weak control plane and then if you leave

00:31:56,419 --> 00:31:59,809
this company you're gonna have to

00:31:57,770 --> 00:32:00,890
recreate all that from scratch unless

00:31:59,809 --> 00:32:03,020
you're able to open-source certain

00:32:00,890 --> 00:32:05,059
components and then god forbid people

00:32:03,020 --> 00:32:06,020
think it's cool and then they use it and

00:32:05,059 --> 00:32:11,450
then congratulations you're an

00:32:06,020 --> 00:32:14,059
open-source maintainer so i want to just

00:32:11,450 --> 00:32:16,549
do some actual demos now of sense.you in

00:32:14,059 --> 00:32:19,040
action and how i can create some

00:32:16,549 --> 00:32:20,840
pipelines with it and and demonstrate

00:32:19,040 --> 00:32:22,910
how i believe it

00:32:20,840 --> 00:32:24,740
sense.you itself has a number of

00:32:22,910 --> 00:32:25,250
attributes that make it effective for

00:32:24,740 --> 00:32:26,929
pipelining

00:32:25,250 --> 00:32:32,000
also i don't know where this gif has

00:32:26,929 --> 00:32:33,169
been my whole life so for this demo i

00:32:32,000 --> 00:32:35,809
hope you all can read that action i'll

00:32:33,169 --> 00:32:37,610
make it a little bit bigger i totally

00:32:35,809 --> 00:32:39,650
gotta get rid of this prompt cuz it

00:32:37,610 --> 00:32:42,740
takes up do you makin a third of my

00:32:39,650 --> 00:32:44,750
screen I'm using kubernetes for this

00:32:42,740 --> 00:32:46,790
demo but that's really just a way that I

00:32:44,750 --> 00:32:48,950
can easily spin up infrastructure on my

00:32:46,790 --> 00:32:51,770
laptop in a way that kind of looks like

00:32:48,950 --> 00:32:58,880
regular infrastructure so what I've done

00:32:51,770 --> 00:33:00,169
is I've actually created a project so

00:32:58,880 --> 00:33:03,140
I've create a repo that's open to the

00:33:00,169 --> 00:33:08,030
public called OS MC demos and everything

00:33:03,140 --> 00:33:09,650
I'm doing it here up on stage is is

00:33:08,030 --> 00:33:10,820
available in this repo so you can

00:33:09,650 --> 00:33:13,730
actually follow along either when the

00:33:10,820 --> 00:33:15,530
video gets posted or afterwards with all

00:33:13,730 --> 00:33:17,510
the steps I do giving you have

00:33:15,530 --> 00:33:19,880
kubernetes and docker for Mac or some

00:33:17,510 --> 00:33:22,429
other means of running kubernetes

00:33:19,880 --> 00:33:25,570
locally so what I'm gonna do is I'm just

00:33:22,429 --> 00:33:25,570
gonna first

00:33:27,520 --> 00:33:39,200
hope this works that conference Wi-Fi

00:33:31,179 --> 00:33:44,350
error sweet Oh mind that ain't no

00:33:39,200 --> 00:33:44,350
attention okay so what have I done there

00:33:44,410 --> 00:33:53,270
I've just deployed a h8 since you've

00:33:47,960 --> 00:33:55,669
back in cluster that's cool so I've got

00:33:53,270 --> 00:33:56,870
a three node cluster they've all stood

00:33:55,669 --> 00:33:59,390
up and they're communicating with each

00:33:56,870 --> 00:34:02,960
other I'm gonna go ahead and use this

00:33:59,390 --> 00:34:04,640
insu cuddle a local command-line tool to

00:34:02,960 --> 00:34:09,649
interact with it I'm gonna use the

00:34:04,640 --> 00:34:12,530
default admin user default namespace as

00:34:09,649 --> 00:34:15,470
that multi-tenancy I talked about and

00:34:12,530 --> 00:34:17,480
that's just you an entity list so this

00:34:15,470 --> 00:34:20,119
is our inventory right currently we're

00:34:17,480 --> 00:34:21,230
not marking anything that's cool what

00:34:20,119 --> 00:34:26,629
we're gonna do now is we're gonna

00:34:21,230 --> 00:34:28,609
monitor a thing if you're not familiar

00:34:26,629 --> 00:34:30,020
with kubernetes don't worry about it

00:34:28,609 --> 00:34:33,980
it's just gonna take over your life in

00:34:30,020 --> 00:34:36,859
the next ten years so now what we're

00:34:33,980 --> 00:34:40,399
gonna do is we're gonna deploy an app

00:34:36,859 --> 00:34:43,850
called web it's a simple web app it's

00:34:40,399 --> 00:34:47,270
got a load balancer in front of it I do

00:34:43,850 --> 00:34:48,679
get pods we can see that an instance of

00:34:47,270 --> 00:34:50,179
our application is running on both of

00:34:48,679 --> 00:34:52,520
them as well as a sense you agent

00:34:50,179 --> 00:34:53,840
sidecar so one sidecar for all your

00:34:52,520 --> 00:34:58,160
since you are for all your monitoring

00:34:53,840 --> 00:35:01,010
data now if I do the entity list we can

00:34:58,160 --> 00:35:02,720
see on God it's large font is wrapping

00:35:01,010 --> 00:35:04,340
but we can see that those side cars

00:35:02,720 --> 00:35:06,470
automatically registered with the

00:35:04,340 --> 00:35:08,090
pipeline that's cool now what's

00:35:06,470 --> 00:35:09,950
interesting is they've self-identified

00:35:08,090 --> 00:35:13,190
as a web server and then they've got

00:35:09,950 --> 00:35:15,500
their unique generated container pod

00:35:13,190 --> 00:35:17,270
name with their application named entity

00:35:15,500 --> 00:35:22,990
so that's how we can I'd you Nikkei

00:35:17,270 --> 00:35:22,990
identify them so what I want to do is

00:35:23,440 --> 00:35:27,970
let's create a pipeline so I have a

00:35:26,270 --> 00:35:30,619
number of pipelines here in this repo

00:35:27,970 --> 00:35:32,450
one for PG Duty one for slack one for

00:35:30,619 --> 00:35:33,859
influx and one for elastic and really I

00:35:32,450 --> 00:35:36,920
just chose these because I think they're

00:35:33,859 --> 00:35:37,750
a fairly good representation of alert

00:35:36,920 --> 00:35:40,300
notification

00:35:37,750 --> 00:35:44,140
and incident management time series data

00:35:40,300 --> 00:35:47,550
and report generation so I'm gonna do is

00:35:44,140 --> 00:35:52,540
I mean since you cut all create a chef

00:35:47,550 --> 00:35:56,470
pipelines Peter G and while that's

00:35:52,540 --> 00:35:58,030
running I'll show you what that does so

00:35:56,470 --> 00:35:59,560
it's really cool about sensors as these

00:35:58,030 --> 00:36:03,130
things called assets which are really

00:35:59,560 --> 00:36:06,130
tar balls with binaries in it we use a

00:36:03,130 --> 00:36:09,250
shot 512 some and verify peer to verify

00:36:06,130 --> 00:36:11,320
their integrity but here we have a cool

00:36:09,250 --> 00:36:13,570
filter called severity filter this is a

00:36:11,320 --> 00:36:15,850
filter plugin we're gonna pull it down

00:36:13,570 --> 00:36:17,410
we're gonna create a resource for it and

00:36:15,850 --> 00:36:19,150
then we're gonna create a filter called

00:36:17,410 --> 00:36:21,220
important and what we're gonna say is

00:36:19,150 --> 00:36:23,950
we're gonna use that severity filter

00:36:21,220 --> 00:36:25,720
asset we're gonna say we want only

00:36:23,950 --> 00:36:28,060
events that are forewarning or critical

00:36:25,720 --> 00:36:30,490
severity then after that we're gonna

00:36:28,060 --> 00:36:32,140
fetch the event handler to take an

00:36:30,490 --> 00:36:34,780
action which is going to be to create a

00:36:32,140 --> 00:36:37,450
page of duty incident and then we're

00:36:34,780 --> 00:36:39,100
going to apply that filter that that

00:36:37,450 --> 00:36:40,660
called important as well as to built-in

00:36:39,100 --> 00:36:44,500
filters to that handler so now what

00:36:40,660 --> 00:36:45,400
we've created here is actually touch on

00:36:44,500 --> 00:36:47,470
this and then we're going to create a

00:36:45,400 --> 00:36:49,360
check that uses this pipeline that's

00:36:47,470 --> 00:36:51,670
gonna monitor the health Z endpoint of

00:36:49,360 --> 00:36:53,620
our web app so we've got our check over

00:36:51,670 --> 00:36:55,630
here that's saying is the application up

00:36:53,620 --> 00:36:57,490
or down and healthy then it goes through

00:36:55,630 --> 00:36:59,320
and hits that filter is it warning and

00:36:57,490 --> 00:37:03,970
critical basically we're just filtering

00:36:59,320 --> 00:37:05,260
out okay and unknowns and then if it

00:37:03,970 --> 00:37:10,870
passes through that it's gonna go to

00:37:05,260 --> 00:37:14,590
page of duty let's just see it should be

00:37:10,870 --> 00:37:16,560
empty it's yo triggering cool so I'm

00:37:14,590 --> 00:37:19,120
just gonna drop out of that real quick

00:37:16,560 --> 00:37:21,160
I'm gonna post that endpoint because it

00:37:19,120 --> 00:37:24,540
just it switches the pool over to be

00:37:21,160 --> 00:37:28,750
failing and then we're just gonna like

00:37:24,540 --> 00:37:32,800
pray to the demo gods that it's gonna

00:37:28,750 --> 00:37:34,450
work when triggered sweet so we just

00:37:32,800 --> 00:37:36,550
created we just deployed an H a

00:37:34,450 --> 00:37:38,800
deployment of Senseo right we just

00:37:36,550 --> 00:37:39,540
deployed containers with sidecars that

00:37:38,800 --> 00:37:42,310
autodiscover

00:37:39,540 --> 00:37:44,080
we just created a whole pipeline with

00:37:42,310 --> 00:37:46,360
one command with that one cool little

00:37:44,080 --> 00:37:49,150
yeah Mille document that created a check

00:37:46,360 --> 00:37:50,290
a filter and a handler pretty rad let's

00:37:49,150 --> 00:37:51,920
do it with something more interesting

00:37:50,290 --> 00:37:53,570
now

00:37:51,920 --> 00:37:56,530
actually it's not the more interesting

00:37:53,570 --> 00:37:56,530
we'll just create it anyways

00:37:58,780 --> 00:38:05,540
Randy slack actually I've got secrets in

00:38:03,980 --> 00:38:06,860
this repo so I'm gonna delete them all

00:38:05,540 --> 00:38:16,190
don't think you can posted this

00:38:06,860 --> 00:38:21,530
afterwards so what I'm gonna do now pipe

00:38:16,190 --> 00:38:22,790
lines slack so in here we're doing a

00:38:21,530 --> 00:38:24,380
similar thing again we've got a

00:38:22,790 --> 00:38:26,630
different filter plug-in called fatigue

00:38:24,380 --> 00:38:28,880
filter this one what it allows us to do

00:38:26,630 --> 00:38:31,130
is create a filter that says only alert

00:38:28,880 --> 00:38:33,260
me on the first occurrence and then once

00:38:31,130 --> 00:38:35,090
every 30-minute reminders right don't

00:38:33,260 --> 00:38:37,160
spam me with the same message over and

00:38:35,090 --> 00:38:38,330
over again this is a great filter to use

00:38:37,160 --> 00:38:41,210
when you're doing things like email and

00:38:38,330 --> 00:38:45,190
SMS directly because god who needs all

00:38:41,210 --> 00:38:47,990
that and then I have a simple handler

00:38:45,190 --> 00:38:51,380
there's my secret you can spam that

00:38:47,990 --> 00:38:54,350
channel right now if you like but we're

00:38:51,380 --> 00:38:56,510
gonna use this as a means of notifying a

00:38:54,350 --> 00:38:57,620
channel so this page of Duty is this

00:38:56,510 --> 00:38:59,060
something that's like going through the

00:38:57,620 --> 00:39:00,410
rotation actually waking people up

00:38:59,060 --> 00:39:02,000
that's very important things

00:39:00,410 --> 00:39:05,210
slack is more like the stream of

00:39:02,000 --> 00:39:10,460
consciousness or the awareness of the

00:39:05,210 --> 00:39:15,130
system let me just toggle the other want

00:39:10,460 --> 00:39:17,810
to be unhealthy and then hopefully Rick

00:39:15,130 --> 00:39:19,280
was pretty sweet so there we go

00:39:17,810 --> 00:39:21,730
we just detected that that's it's

00:39:19,280 --> 00:39:25,340
failing no it's really neat as I can

00:39:21,730 --> 00:39:27,170
toggle both those back and hopefully the

00:39:25,340 --> 00:39:28,520
resolution will come through but what we

00:39:27,170 --> 00:39:30,350
just did is to create a different

00:39:28,520 --> 00:39:32,600
pipeline with a different filter with a

00:39:30,350 --> 00:39:34,850
different handler again with just one

00:39:32,600 --> 00:39:43,040
command and hopefully it's gonna work

00:39:34,850 --> 00:39:48,850
here maybe we'll come back its eventual

00:39:43,040 --> 00:39:50,480
hotel Wi-Fi cool alright next pipeline

00:39:48,850 --> 00:39:53,350
this one's interesting

00:39:50,480 --> 00:39:58,070
we need some more infrastructure though

00:39:53,350 --> 00:40:01,520
I'll use apply this one is going to be

00:39:58,070 --> 00:40:03,260
in flux DB so I just created a new

00:40:01,520 --> 00:40:04,910
pipeline and this one's really

00:40:03,260 --> 00:40:05,330
interesting because we've done service

00:40:04,910 --> 00:40:09,580
check

00:40:05,330 --> 00:40:09,580
she was that I swear I'm paging somebody

00:40:10,210 --> 00:40:15,920
so this one is I'm just deploying in

00:40:14,300 --> 00:40:17,210
flux DB there I'm gonna go ahead

00:40:15,920 --> 00:40:18,290
actually just create the pipeline I'll

00:40:17,210 --> 00:40:23,920
show you the pipeline I think that's

00:40:18,290 --> 00:40:23,920
more interesting pipelines in flux DB I

00:40:24,280 --> 00:40:35,960
also need a cube CTL create Jeff I need

00:40:33,950 --> 00:40:37,610
Griffin ax cuz I need to visualize it

00:40:35,960 --> 00:40:43,840
while I'm at it I'm gonna just spin up

00:40:37,610 --> 00:40:52,370
elastic so that everything's set up

00:40:43,840 --> 00:40:54,770
Rene's is a hell of a drug now I'm bad

00:40:52,370 --> 00:40:57,130
for conference Wi-Fi and I always give

00:40:54,770 --> 00:41:00,020
it such crap but this is pretty sweet

00:40:57,130 --> 00:41:03,290
alright so let's do the next pipeline

00:41:00,020 --> 00:41:04,940
I've got four minutes don't worry I'll

00:41:03,290 --> 00:41:10,070
take questions in the in the hallway

00:41:04,940 --> 00:41:12,620
afterwards so what I'm gonna do here is

00:41:10,070 --> 00:41:14,420
I'm gonna create the in flux DB pipeline

00:41:12,620 --> 00:41:17,180
and what's interesting about this

00:41:14,420 --> 00:41:19,550
pipeline is we did service checks

00:41:17,180 --> 00:41:21,230
already this is metrics now so we have a

00:41:19,550 --> 00:41:24,230
in flux DB handler so this takes

00:41:21,230 --> 00:41:26,240
collected metrics and really I'm just

00:41:24,230 --> 00:41:27,860
using the one built in filter here

00:41:26,240 --> 00:41:30,190
called has metrics so if an event has

00:41:27,860 --> 00:41:33,410
metrics it's going to go to this handler

00:41:30,190 --> 00:41:34,790
and then I've created a check which is

00:41:33,410 --> 00:41:36,680
going to scrape the problem or the

00:41:34,790 --> 00:41:39,290
Prometheus endpoint on my application

00:41:36,680 --> 00:41:40,910
it's going to extract that line format

00:41:39,290 --> 00:41:43,430
and transform it and the one that the

00:41:40,910 --> 00:41:50,870
handler will understand or our common

00:41:43,430 --> 00:41:55,430
one so actually if I do a six suite so

00:41:50,870 --> 00:41:57,710
that's our GCE go GC duration seconds so

00:41:55,430 --> 00:42:00,590
we're now not only we monitoring the

00:41:57,710 --> 00:42:03,470
uptime and the service health of the

00:42:00,590 --> 00:42:05,500
service we're now also measuring the

00:42:03,470 --> 00:42:10,190
runtime statistics and application

00:42:05,500 --> 00:42:16,660
telemetry if I go over here and reload

00:42:10,190 --> 00:42:21,370
it should yell at me we go in here

00:42:16,660 --> 00:42:23,710
I think I have to like just poke it good

00:42:21,370 --> 00:42:28,870
it's working sweet I'm having a lot of

00:42:23,710 --> 00:42:36,870
good luck okay so if we add a query for

00:42:28,870 --> 00:42:40,240
influx DB in the last five minutes last

00:42:36,870 --> 00:42:43,150
previous so now we've got service checks

00:42:40,240 --> 00:42:45,220
now you have telemetry suite one thing

00:42:43,150 --> 00:42:47,470
we're missing now that resolution never

00:42:45,220 --> 00:42:51,790
did come through so I guess I messed up

00:42:47,470 --> 00:42:55,540
my config it happens we're gonna create

00:42:51,790 --> 00:42:59,440
another pipeline for elastic this one's

00:42:55,540 --> 00:43:00,850
really cool our friends over at NCR

00:42:59,440 --> 00:43:03,070
which is a company that's been around

00:43:00,850 --> 00:43:05,260
for like over a hundred years

00:43:03,070 --> 00:43:06,970
they're using since you go for some

00:43:05,260 --> 00:43:09,730
interesting things and they're now

00:43:06,970 --> 00:43:11,830
creating plugins that work not only on

00:43:09,730 --> 00:43:13,720
Linux but also on Windows and they're

00:43:11,830 --> 00:43:15,640
also creating some really cool handlers

00:43:13,720 --> 00:43:17,470
like this one that can take since you

00:43:15,640 --> 00:43:19,630
event data that you've thrown you know

00:43:17,470 --> 00:43:21,760
that unified payload and write it to

00:43:19,630 --> 00:43:27,970
elastic so that you can search it so I'm

00:43:21,760 --> 00:43:32,770
just updating the check now so that what

00:43:27,970 --> 00:43:39,580
port is that that's 9200 sweet so now we

00:43:32,770 --> 00:43:41,230
should be able to update this and we can

00:43:39,580 --> 00:43:42,880
see that as events come through the

00:43:41,230 --> 00:43:45,010
pipeline we're gonna store all the

00:43:42,880 --> 00:43:47,710
incidents into elastic now we can use it

00:43:45,010 --> 00:43:50,830
for generating RSL aslo and all that all

00:43:47,710 --> 00:43:53,920
those reports outages and interesting

00:43:50,830 --> 00:43:59,050
things in facts so I really I really

00:43:53,920 --> 00:44:04,300
hope that I made a it works it's fine

00:43:59,050 --> 00:44:05,350
just five minutes late so yeah so with

00:44:04,300 --> 00:44:07,060
sense you you can do some cool things

00:44:05,350 --> 00:44:09,550
there's other things I want to show but

00:44:07,060 --> 00:44:13,840
I don't have any time to keep doing the

00:44:09,550 --> 00:44:15,700
demo this is kind of like the web UI so

00:44:13,840 --> 00:44:17,140
that you can get some visibility into

00:44:15,700 --> 00:44:18,990
your pipeline and what's going through

00:44:17,140 --> 00:44:21,850
in this current state kind of thing

00:44:18,990 --> 00:44:24,370
let's go back here I can wrap up I got

00:44:21,850 --> 00:44:26,440
one minute or 30 seconds future of

00:44:24,370 --> 00:44:28,360
pipelines I think we're gonna see a lot

00:44:26,440 --> 00:44:29,920
more of the bespoke ones we're gonna see

00:44:28,360 --> 00:44:30,370
a lot of people putting themselves in

00:44:29,920 --> 00:44:32,560
the end for

00:44:30,370 --> 00:44:36,160
unit situation of maintaining fresh new

00:44:32,560 --> 00:44:38,380
projects I think you know since you

00:44:36,160 --> 00:44:40,810
creates a situation where we can not

00:44:38,380 --> 00:44:43,390
only make it cheaper and less expensive

00:44:40,810 --> 00:44:44,920
to change but also because we use this

00:44:43,390 --> 00:44:47,380
framework that's common amongst multiple

00:44:44,920 --> 00:44:49,260
companies you can take your workflows

00:44:47,380 --> 00:44:51,610
your pipelines that you've constructed

00:44:49,260 --> 00:44:54,430
forklift from one and drop it into

00:44:51,610 --> 00:44:59,500
another which is super excited exciting

00:44:54,430 --> 00:45:01,570
I think we're gonna see another thing I

00:44:59,500 --> 00:45:03,580
think we're gonna see more people

00:45:01,570 --> 00:45:05,650
sharing how they build their pipelines

00:45:03,580 --> 00:45:08,350
this is how since you shares those

00:45:05,650 --> 00:45:10,480
assets like this is all I did to find

00:45:08,350 --> 00:45:12,870
one for pager duty I went in here and

00:45:10,480 --> 00:45:15,520
then there's a handler for page of Duty

00:45:12,870 --> 00:45:16,960
so we're we're having more people

00:45:15,520 --> 00:45:18,880
building pipelines more people

00:45:16,960 --> 00:45:21,430
understanding the value of pipelines and

00:45:18,880 --> 00:45:22,870
then since he's just trying to provide a

00:45:21,430 --> 00:45:25,210
framework so people can do that

00:45:22,870 --> 00:45:28,030
consistently and collaboratively

00:45:25,210 --> 00:45:29,710
I think pipelines are gonna get more

00:45:28,030 --> 00:45:31,240
observable in themselves we're gonna get

00:45:29,710 --> 00:45:32,530
a better sense of what's going through

00:45:31,240 --> 00:45:34,780
those pipelines how they're operating

00:45:32,530 --> 00:45:37,300
air rates within the pipes themselves

00:45:34,780 --> 00:45:39,430
how we can improve them also I think

00:45:37,300 --> 00:45:41,890
we're gonna see pipelines start to make

00:45:39,430 --> 00:45:45,790
suggestions you know we notice you're

00:45:41,890 --> 00:45:47,770
monitoring my sequel 70% of you know

00:45:45,790 --> 00:45:50,890
sense.you or other tool users do it like

00:45:47,770 --> 00:45:53,080
this I think we're gonna see more

00:45:50,890 --> 00:45:56,080
two-way integrations right now it's

00:45:53,080 --> 00:45:58,120
while it's bi-directional internally its

00:45:56,080 --> 00:45:59,290
uni-directional with integrations I

00:45:58,120 --> 00:46:01,500
think we're gonna see a lot more data

00:45:59,290 --> 00:46:04,840
coming back from other service providers

00:46:01,500 --> 00:46:06,940
so that's it for time my name is Shawn

00:46:04,840 --> 00:46:08,650
Porter Porter tech online if you're

00:46:06,940 --> 00:46:11,320
interested in cents you come talk to me

00:46:08,650 --> 00:46:14,410
or my two colleagues I've got Anthony

00:46:11,320 --> 00:46:16,150
Goddard and Cameron Johnston here and

00:46:14,410 --> 00:46:17,830
we're happy to talk about our visit our

00:46:16,150 --> 00:46:19,630
website I hope that didn't come across

00:46:17,830 --> 00:46:21,670
as too vendor pitchy but I honestly

00:46:19,630 --> 00:46:24,640
believe that since he was quite cool as

00:46:21,670 --> 00:46:26,530
a technology and I think monitoring

00:46:24,640 --> 00:46:29,140
event pipelines are the way forward in

00:46:26,530 --> 00:46:31,390
terms of how we manage all this data and

00:46:29,140 --> 00:46:34,780
and the challenges that are presented to

00:46:31,390 --> 00:46:41,699
us so that's it thank you

00:46:34,780 --> 00:46:41,699
[Applause]

00:46:43,020 --> 00:46:52,329
any time for questions

00:46:44,920 --> 00:46:53,079
was it lunchtime I hope so yeah for your

00:46:52,329 --> 00:47:03,910
nice talk

00:46:53,079 --> 00:47:07,180
thank you what's really nice talking to

00:47:03,910 --> 00:47:09,490
the Box man okay no problem

00:47:07,180 --> 00:47:13,059
it's a TLS encryption you you mentioned

00:47:09,490 --> 00:47:16,119
built-in by standard so you spin up the

00:47:13,059 --> 00:47:20,559
agent and they use an encryption we

00:47:16,119 --> 00:47:22,779
should okay so so yeah like for somehow

00:47:20,559 --> 00:47:25,119
some reason TLS is still not easy in

00:47:22,779 --> 00:47:29,200
2019 for a lot of people so it's not

00:47:25,119 --> 00:47:30,490
secure by default it is plain text but

00:47:29,200 --> 00:47:33,339
you know we have a number of different

00:47:30,490 --> 00:47:35,200
guides on on like sensor dogs to help

00:47:33,339 --> 00:47:41,520
people do it the right way from the

00:47:35,200 --> 00:47:41,520
beginning thanks for calling that out

00:47:42,210 --> 00:47:50,500
anyone else on the box yeah I want to

00:47:44,859 --> 00:47:50,980
throw it oh thank you I hope you have

00:47:50,500 --> 00:47:53,589
insurance

00:47:50,980 --> 00:47:56,289
all right so that was really interesting

00:47:53,589 --> 00:47:58,299
I'm curious what's in this eight car

00:47:56,289 --> 00:48:00,130
configuration does it autodiscover like

00:47:58,299 --> 00:48:01,960
metric endpoints and logs or do you have

00:48:00,130 --> 00:48:04,420
to kind of point them towards all that

00:48:01,960 --> 00:48:06,369
so I think where we have the benefit of

00:48:04,420 --> 00:48:09,309
being a sidecar and local hosts

00:48:06,369 --> 00:48:11,260
availability so currently you can write

00:48:09,309 --> 00:48:12,970
plug-ins to discover things but

00:48:11,260 --> 00:48:15,309
generally right now the sidecar pattern

00:48:12,970 --> 00:48:17,260
is it's quite assumptive you just assume

00:48:15,309 --> 00:48:20,680
there's metrics like a prometheus

00:48:17,260 --> 00:48:23,140
endpoint and then a lot of is push based

00:48:20,680 --> 00:48:24,730
API is so the application is aware of

00:48:23,140 --> 00:48:26,799
that localhost and and the sense you

00:48:24,730 --> 00:48:28,210
api's are there so I think I think

00:48:26,799 --> 00:48:29,950
there's definitely a good opportunity to

00:48:28,210 --> 00:48:33,339
do more discovery within the sidecar

00:48:29,950 --> 00:48:35,200
pattern but right now it's just you know

00:48:33,339 --> 00:48:37,029
you kind of have a rigid framework for

00:48:35,200 --> 00:48:39,599
what since you expects and what your

00:48:37,029 --> 00:48:41,859
application expects

00:48:39,599 --> 00:48:46,989
it's good question

00:48:41,859 --> 00:48:50,530
good anyone else well I guess thanks

00:48:46,989 --> 00:48:53,580
again thank you

00:48:50,530 --> 00:49:04,580
[Applause]

00:48:53,580 --> 00:49:04,580
[Music]

00:49:08,170 --> 00:49:10,959

YouTube URL: https://www.youtube.com/watch?v=UBpg_VmNLEU


