Title: OSMC 2016 | ZMON: Zalando's OS approach to monitoring in the cloud and DCs (EN) by Jan Mussler
Publication date: 2016-12-12
Playlist: OSMC 2016 | Open Source Monitoring Conference
Description: 
	Two years ago we set out to build our own monitoring tool replacing Icinga. Our biggest focus was flexibility and autonomy for the growing number of teams and engineers to enable them to monitor their services from small micro services to databases to higher level business KPIs. Today ZMON provides teams with a federated monitoring solution that gathers data not only in our DCs but also in the connected AWS VPCs and assists teams with service auto discovery and sharing of checks/alerts to make everyone's life easier. ZMON comes along with Grafana2 and KairosDB enabling rich data driven dashboards.
Captions: 
	00:00:09,620 --> 00:00:14,549
our first talk today is from young

00:00:12,090 --> 00:00:16,830
Muslim from solando he will talk about

00:00:14,549 --> 00:00:18,450
their monitoring interest or how they

00:00:16,830 --> 00:00:21,689
monitor the infrastructure the cloud

00:00:18,450 --> 00:00:28,349
services on the website so give her a

00:00:21,689 --> 00:00:29,910
welcome yes thank you thank you now I'm

00:00:28,349 --> 00:00:32,099
much more pleased with the outcome of

00:00:29,910 --> 00:00:34,260
people listening to my talk than five

00:00:32,099 --> 00:00:36,180
minutes ago and yeah my name is John

00:00:34,260 --> 00:00:38,160
musleh I work in the Berlin office from

00:00:36,180 --> 00:00:40,170
zalando I am a software engineer by

00:00:38,160 --> 00:00:43,020
trade I studied it in Aachen many years

00:00:40,170 --> 00:00:46,230
ago and I want today to show you how we

00:00:43,020 --> 00:00:48,450
basically do the monitoring there's very

00:00:46,230 --> 00:00:50,730
very little I singer in here so if you

00:00:48,450 --> 00:00:53,520
are big fans of this I hope I can show

00:00:50,730 --> 00:00:55,560
you something else today so let's touch

00:00:53,520 --> 00:00:57,300
briefly on the land oh I'm pretty

00:00:55,560 --> 00:00:59,220
confident that most people here now it

00:00:57,300 --> 00:01:01,739
by now that was different when we

00:00:59,220 --> 00:01:03,390
visited conferences in the past but we

00:01:01,739 --> 00:01:05,850
consider ourselves to be Europe's

00:01:03,390 --> 00:01:08,520
leading online fashion platform we are

00:01:05,850 --> 00:01:10,950
present in 15 countries we have right

00:01:08,520 --> 00:01:14,340
about now kind of 19 million active

00:01:10,950 --> 00:01:16,740
customers we have roughly 160 million

00:01:14,340 --> 00:01:18,990
unique visitors a month we have

00:01:16,740 --> 00:01:21,750
something around about 200,000 articles

00:01:18,990 --> 00:01:25,320
in on the page so in stock there is much

00:01:21,750 --> 00:01:28,260
more we currently advise around three

00:01:25,320 --> 00:01:29,940
billion euro revenue yearly and probably

00:01:28,260 --> 00:01:33,659
the most interesting number here is that

00:01:29,940 --> 00:01:36,150
we actually have 1,600 people in tech so

00:01:33,659 --> 00:01:38,760
this includes a lot of software

00:01:36,150 --> 00:01:41,100
engineers a lot of engineering power to

00:01:38,760 --> 00:01:42,840
basically build our own software from

00:01:41,100 --> 00:01:44,820
the front end everyone knows but also

00:01:42,840 --> 00:01:47,430
down to the logistics software that is

00:01:44,820 --> 00:01:49,110
responsible for steering processes in

00:01:47,430 --> 00:01:50,880
the warehouse and there's actually why

00:01:49,110 --> 00:01:53,250
the past six years for me have been

00:01:50,880 --> 00:01:55,260
quite a good ride I mean there were

00:01:53,250 --> 00:01:58,770
scaling topics there is a lot of stuff

00:01:55,260 --> 00:02:01,320
to do you see this year many years ago

00:01:58,770 --> 00:02:03,720
there was PHP MySQL hidden in magento

00:02:01,320 --> 00:02:05,970
than we switched away and became very

00:02:03,720 --> 00:02:07,680
big fans of the job and the postgres

00:02:05,970 --> 00:02:09,750
world we had a very strict environment

00:02:07,680 --> 00:02:11,549
here so everything wasn't Java and in

00:02:09,750 --> 00:02:13,980
Postgres and there was a patchy solar

00:02:11,549 --> 00:02:15,420
and game also but we weren't so open to

00:02:13,980 --> 00:02:18,719
other technologies that you would expect

00:02:15,420 --> 00:02:20,969
from a start-up basically but can the

00:02:18,719 --> 00:02:23,069
past years this has changed if you want

00:02:20,969 --> 00:02:24,629
to hire engineers you need more freedom

00:02:23,069 --> 00:02:26,790
need to tell everyone who can do it in

00:02:24,629 --> 00:02:29,670
Scala you need to tell everyone you can

00:02:26,790 --> 00:02:33,480
use go if you want to so right now I'm

00:02:29,670 --> 00:02:36,090
losing headsets here this has changed so

00:02:33,480 --> 00:02:40,230
there came beginning of last year I

00:02:36,090 --> 00:02:42,629
think this team Tom radical agility and

00:02:40,230 --> 00:02:44,519
it's mostly about autonomy so we gave

00:02:42,629 --> 00:02:46,859
all the teams a lot of decision power

00:02:44,519 --> 00:02:49,620
first of all there came a WS so we can

00:02:46,859 --> 00:02:52,079
go into the cloud now we can use all the

00:02:49,620 --> 00:02:55,049
technologies the team things fit except

00:02:52,079 --> 00:02:56,700
some of them but this obviously is a

00:02:55,049 --> 00:02:58,200
very interesting change suddenly you

00:02:56,700 --> 00:03:00,209
have this heterogeneous environment

00:02:58,200 --> 00:03:01,620
everyone is doing what he wants everyone

00:03:00,209 --> 00:03:04,079
picks the database you want and you

00:03:01,620 --> 00:03:07,439
still want to monitor across this vast

00:03:04,079 --> 00:03:09,150
array of technologies so how do we

00:03:07,439 --> 00:03:11,219
deploy in one sentence will baby

00:03:09,150 --> 00:03:13,260
understand there is one AWS account for

00:03:11,219 --> 00:03:15,719
team this means basically one closed of

00:03:13,260 --> 00:03:17,699
virtual network for everyone we deploy

00:03:15,719 --> 00:03:19,379
with docker so this is the baseline we

00:03:17,699 --> 00:03:21,540
agreed upon so if you want to deploy

00:03:19,379 --> 00:03:23,819
something you put it in a docker image

00:03:21,540 --> 00:03:26,699
and you can run this somewhere on an ec2

00:03:23,819 --> 00:03:28,349
instance we have ssh access for all the

00:03:26,699 --> 00:03:30,989
team members to all the hosts so there

00:03:28,349 --> 00:03:33,180
is no limitation there the other thing

00:03:30,989 --> 00:03:35,280
we employs there is rest and walls

00:03:33,180 --> 00:03:37,650
between all the services it's all going

00:03:35,280 --> 00:03:39,449
why as a public internet and in the end

00:03:37,650 --> 00:03:41,549
important part for us is also

00:03:39,449 --> 00:03:43,650
traceability of changes so all its

00:03:41,549 --> 00:03:46,079
streams and so on but if we take a look

00:03:43,650 --> 00:03:48,030
at this basically means there is a if

00:03:46,079 --> 00:03:50,340
you pick two teams out of the hundreds

00:03:48,030 --> 00:03:52,049
of teams they have their own domain

00:03:50,340 --> 00:03:54,629
somewhere they have all the services and

00:03:52,049 --> 00:03:57,239
internet-facing load balancers they talk

00:03:54,629 --> 00:03:59,310
HTTPS and then they use oils too so

00:03:57,239 --> 00:04:01,409
sending a token for authentication or

00:03:59,310 --> 00:04:03,810
authorization and that's basically how

00:04:01,409 --> 00:04:06,419
it works so there is no VPN and there is

00:04:03,810 --> 00:04:10,079
no special connectivity it's like the

00:04:06,419 --> 00:04:11,759
internet is supposed to work so along

00:04:10,079 --> 00:04:13,650
with this came obviously also a lot of

00:04:11,759 --> 00:04:16,709
responsibility and ownership into the

00:04:13,650 --> 00:04:19,109
teams so while some of you may still be

00:04:16,709 --> 00:04:21,750
and we had also very long time ago been

00:04:19,109 --> 00:04:23,130
basically in this world recently quickly

00:04:21,750 --> 00:04:24,960
added the slide yesterday we had lots of

00:04:23,130 --> 00:04:26,580
teams we had a system engineering team

00:04:24,960 --> 00:04:28,469
they were writing tickets for the team

00:04:26,580 --> 00:04:30,210
responsible for this monitoring solution

00:04:28,469 --> 00:04:32,400
and they were basically monitoring

00:04:30,210 --> 00:04:34,469
everything but I mean everyone can

00:04:32,400 --> 00:04:36,479
imagine this explodes if everyone can

00:04:34,469 --> 00:04:37,070
use what everyone's has its own freedom

00:04:36,479 --> 00:04:39,620
this does

00:04:37,070 --> 00:04:41,960
work so what we actually kept in mind

00:04:39,620 --> 00:04:43,970
and this is the big important thing year

00:04:41,960 --> 00:04:46,130
that has changed is that teams are

00:04:43,970 --> 00:04:48,650
solely responsible for monitoring their

00:04:46,130 --> 00:04:49,850
stuff I mean you can say def orbs and

00:04:48,650 --> 00:04:52,250
also on there's all these buzzwords

00:04:49,850 --> 00:04:53,930
around but basically the team is

00:04:52,250 --> 00:04:55,610
responsible for their stuff they are

00:04:53,930 --> 00:04:57,560
monitoring their application they are

00:04:55,610 --> 00:05:00,500
monitoring their kpi's they are

00:04:57,560 --> 00:05:02,630
monitoring the system metrics so when we

00:05:00,500 --> 00:05:04,580
set out to build a tool I think whatever

00:05:02,630 --> 00:05:06,560
the three and a half years ago this was

00:05:04,580 --> 00:05:08,810
the strong focus basically enabling

00:05:06,560 --> 00:05:10,550
teams to do the monitoring on their own

00:05:08,810 --> 00:05:12,470
do their own decisions on what they want

00:05:10,550 --> 00:05:14,630
to look at and we are not talking like

00:05:12,470 --> 00:05:17,390
CPU memory most of the monitoring is

00:05:14,630 --> 00:05:19,220
also in higher level metrics so do we

00:05:17,390 --> 00:05:21,590
have enough orders in France and a

00:05:19,220 --> 00:05:23,510
certain payment method do we have enough

00:05:21,590 --> 00:05:26,780
visitors from the certain channel so

00:05:23,510 --> 00:05:28,700
really higher level AP ice yeah so this

00:05:26,780 --> 00:05:30,710
is just one example how it basically can

00:05:28,700 --> 00:05:32,090
look like in this modern cloud world so

00:05:30,710 --> 00:05:33,620
you have different hosts everyone

00:05:32,090 --> 00:05:35,540
running their applications you need to

00:05:33,620 --> 00:05:39,440
know what is running where to do the

00:05:35,540 --> 00:05:40,940
monitoring efficiently so and here is

00:05:39,440 --> 00:05:43,370
where that one comes into play it

00:05:40,940 --> 00:05:45,440
resulted from a heck week project back

00:05:43,370 --> 00:05:48,080
then so a few engineers set together and

00:05:45,440 --> 00:05:49,910
started building something we called it

00:05:48,080 --> 00:05:52,160
that one too because there was already

00:05:49,910 --> 00:05:54,350
basically a UI for what we had earlier

00:05:52,160 --> 00:05:55,940
but now we renamed it to that one you

00:05:54,350 --> 00:05:59,060
can find it on the web it's all open

00:05:55,940 --> 00:06:00,980
source and that is really what we are

00:05:59,060 --> 00:06:03,320
running that is the key part there is no

00:06:00,980 --> 00:06:05,270
hidden magic so we run a 100-percent

00:06:03,320 --> 00:06:07,280
open source project on our internal

00:06:05,270 --> 00:06:08,750
infrastructure we commit and show

00:06:07,280 --> 00:06:10,940
everything to the outside that we are

00:06:08,750 --> 00:06:13,160
using including all the features we need

00:06:10,940 --> 00:06:15,650
for this multi region monitoring because

00:06:13,160 --> 00:06:17,150
we have data centers we have AWS and we

00:06:15,650 --> 00:06:19,010
have all this federated into one

00:06:17,150 --> 00:06:20,480
solution so let's take a look at how it

00:06:19,010 --> 00:06:24,170
looks like maybe more way more

00:06:20,480 --> 00:06:26,240
interesting so you see in the next few

00:06:24,170 --> 00:06:28,340
slides basically a feature set of that

00:06:26,240 --> 00:06:30,470
one so what kind of do and how do people

00:06:28,340 --> 00:06:32,330
achieve this and I just want to

00:06:30,470 --> 00:06:34,910
highlight here a few key points so

00:06:32,330 --> 00:06:36,950
basically on to scare the first guys

00:06:34,910 --> 00:06:38,570
away there's pison and play and you have

00:06:36,950 --> 00:06:41,080
something like checks for data gathering

00:06:38,570 --> 00:06:45,230
you have alerts for alerting on metrics

00:06:41,080 --> 00:06:47,510
and all this is in Python but stay with

00:06:45,230 --> 00:06:50,060
me it's really tiny snippets of code so

00:06:47,510 --> 00:06:51,020
this works well the other important part

00:06:50,060 --> 00:06:52,970
if you drive such a big

00:06:51,020 --> 00:06:54,800
platforms integration so everything is

00:06:52,970 --> 00:06:57,800
basically controllable and configurable

00:06:54,800 --> 00:06:59,599
the via REST API so if you have a new

00:06:57,800 --> 00:07:01,430
host or a new piece of software a new

00:06:59,599 --> 00:07:03,110
application you make one rest call you

00:07:01,430 --> 00:07:05,419
announced basically your service to that

00:07:03,110 --> 00:07:08,270
money didn't come from there on I would

00:07:05,419 --> 00:07:10,789
start monitoring it and for some systems

00:07:08,270 --> 00:07:12,710
like AWS and Cuban ETS we ought

00:07:10,789 --> 00:07:15,080
obviously have all the discovery so

00:07:12,710 --> 00:07:17,090
whenever someone spawns something on AWS

00:07:15,080 --> 00:07:19,490
it will immediately appear in the system

00:07:17,090 --> 00:07:21,379
and be well covered by all the checks

00:07:19,490 --> 00:07:23,150
that existed before I mean this is

00:07:21,379 --> 00:07:24,800
crucial basically and earlier when you

00:07:23,150 --> 00:07:26,780
think about the data center we had the

00:07:24,800 --> 00:07:28,069
configuration management database where

00:07:26,780 --> 00:07:29,569
all the hosts were in with their

00:07:28,069 --> 00:07:31,669
physical model and so on you will see

00:07:29,569 --> 00:07:34,039
later so all this happened automatically

00:07:31,669 --> 00:07:36,580
so whether it was an HP server or dell

00:07:34,039 --> 00:07:38,990
server it's all basically covered um

00:07:36,580 --> 00:07:41,180
yeah for most of the other stuff that's

00:07:38,990 --> 00:07:42,889
basically you I driven from the user so

00:07:41,180 --> 00:07:45,889
there is he doesn't have to go anywhere

00:07:42,889 --> 00:07:48,949
you can do all the stuff by himself and

00:07:45,889 --> 00:07:51,590
in terms of scaling we basically put

00:07:48,949 --> 00:07:53,449
together a fairly proven set of

00:07:51,590 --> 00:07:56,120
technologies here there is Cassandra and

00:07:53,449 --> 00:07:58,130
therefore combined with kyros DB which

00:07:56,120 --> 00:08:00,409
is great for basically time-series data

00:07:58,130 --> 00:08:03,259
on top of this everyone wants to have

00:08:00,409 --> 00:08:05,569
graph on R 3 so this is all in a little

00:08:03,259 --> 00:08:07,580
bit of Redis to power the UI also so we

00:08:05,569 --> 00:08:09,800
are not afraid of growing the system

00:08:07,580 --> 00:08:12,139
basically what did I not cover the

00:08:09,800 --> 00:08:14,449
that's all then so how does it look like

00:08:12,139 --> 00:08:16,400
on first thing we basically built this

00:08:14,449 --> 00:08:17,840
dashboard so you want to have your TV

00:08:16,400 --> 00:08:19,190
screens on the office you want to have

00:08:17,840 --> 00:08:21,440
it on your desktop you want to quickly

00:08:19,190 --> 00:08:23,449
see when stuff goes wrong so what do we

00:08:21,440 --> 00:08:24,860
have we have basically alerts that are

00:08:23,449 --> 00:08:27,349
triggered and people can assign

00:08:24,860 --> 00:08:29,719
basically colors between red and yellow

00:08:27,349 --> 00:08:31,580
this is not the old state like warning

00:08:29,719 --> 00:08:33,529
or critical because no one looks at

00:08:31,580 --> 00:08:35,450
warning if we are honest so everything

00:08:33,529 --> 00:08:40,010
basically is up to the team to say it's

00:08:35,450 --> 00:08:41,750
either red yellow or orange we have area

00:08:40,010 --> 00:08:44,029
on top basically where people can add

00:08:41,750 --> 00:08:46,310
custom widgets from signals that values

00:08:44,029 --> 00:08:48,770
to text values to other basically kyros

00:08:46,310 --> 00:08:50,899
power charts and this is what people who

00:08:48,770 --> 00:08:52,520
basically render on one TV screen so

00:08:50,899 --> 00:08:55,010
they have the critical alerts up they

00:08:52,520 --> 00:08:57,079
have some of the key KP is written on

00:08:55,010 --> 00:08:59,089
top and normally you will see a second

00:08:57,079 --> 00:09:02,209
TV screen rendering a graph on or three

00:08:59,089 --> 00:09:03,890
dashboard what we basically put here in

00:09:02,209 --> 00:09:04,940
also from learning and stuff like you

00:09:03,890 --> 00:09:06,770
immediately want to see

00:09:04,940 --> 00:09:08,690
how you came to this a lot so basically

00:09:06,770 --> 00:09:10,550
if you are tracking metrics we also

00:09:08,690 --> 00:09:12,380
render the charts immediately because

00:09:10,550 --> 00:09:14,120
it's a difference whether you're a lot

00:09:12,380 --> 00:09:17,270
came up in the last two minutes or in

00:09:14,120 --> 00:09:19,580
the last 14 days basically we have a

00:09:17,270 --> 00:09:21,950
little bit of tiny data in here like for

00:09:19,580 --> 00:09:24,200
example this ! and this is basically

00:09:21,950 --> 00:09:27,710
showing a technical error during data

00:09:24,200 --> 00:09:29,120
acquisition so basically showing you we

00:09:27,710 --> 00:09:31,190
are not certain what the system is

00:09:29,120 --> 00:09:32,720
showing we couldn't gather the data so

00:09:31,190 --> 00:09:34,610
you better take a look at it so you are

00:09:32,720 --> 00:09:37,310
not basically blind we are not hiding

00:09:34,610 --> 00:09:39,500
this error from you so how does it

00:09:37,310 --> 00:09:41,300
quickly look like we go briefly into

00:09:39,500 --> 00:09:43,250
more details later but you see here a

00:09:41,300 --> 00:09:45,380
combination of an alert expression and

00:09:43,250 --> 00:09:47,240
to check expression so basically when

00:09:45,380 --> 00:09:49,400
you go to the check command first I hope

00:09:47,240 --> 00:09:51,890
this is somewhat visible we tell that

00:09:49,400 --> 00:09:55,040
one basically make an HTTP request to

00:09:51,890 --> 00:09:58,190
some system every minute and return us

00:09:55,040 --> 00:10:00,920
the status code and then you say okay if

00:09:58,190 --> 00:10:03,200
my status code is not in 200 400 and 400

00:10:00,920 --> 00:10:05,270
for please trigger this a lot so this is

00:10:03,200 --> 00:10:07,850
really like high level and I think

00:10:05,270 --> 00:10:09,230
everyone can understand it maybe take

00:10:07,850 --> 00:10:11,510
with you that there's something like an

00:10:09,230 --> 00:10:14,480
entity filter here but we come into this

00:10:11,510 --> 00:10:17,540
later so this is how it looks like and

00:10:14,480 --> 00:10:19,490
this basically means we find all the

00:10:17,540 --> 00:10:22,460
stuff that is matching our filter we do

00:10:19,490 --> 00:10:24,260
the HTTP request against it so we have

00:10:22,460 --> 00:10:26,450
five different applications here they

00:10:24,260 --> 00:10:29,240
return different status codes down here

00:10:26,450 --> 00:10:31,940
one of them fails with a timeout because

00:10:29,240 --> 00:10:34,280
the port is not open and so this is

00:10:31,940 --> 00:10:36,380
basically how we render a lot state for

00:10:34,280 --> 00:10:38,780
this check so the team now basically

00:10:36,380 --> 00:10:40,670
knows okay one of my five entities is

00:10:38,780 --> 00:10:46,700
wrong I better take a look at why this

00:10:40,670 --> 00:10:48,380
is not open so what else did we add we

00:10:46,700 --> 00:10:50,000
went into this microservice world so

00:10:48,380 --> 00:10:51,920
people started deploying stuff like

00:10:50,000 --> 00:10:53,810
crazy and you want to give them a better

00:10:51,920 --> 00:10:56,030
overview of what is going on in their

00:10:53,810 --> 00:10:58,910
account and since we knew we are doing

00:10:56,030 --> 00:11:00,740
HTTP almost everywhere we now kind of

00:10:58,910 --> 00:11:03,260
how we deploy we built in something like

00:11:00,740 --> 00:11:06,980
this application overview this is

00:11:03,260 --> 00:11:08,960
basically showing all the services one

00:11:06,980 --> 00:11:10,490
particular team has in his account so

00:11:08,960 --> 00:11:12,980
basically we show the different micro

00:11:10,490 --> 00:11:15,500
services and we also quickly show the

00:11:12,980 --> 00:11:17,240
data you are kind of care for so how

00:11:15,500 --> 00:11:18,560
many instances is it running how many

00:11:17,240 --> 00:11:21,529
requests on

00:11:18,560 --> 00:11:23,420
only 400 500 and latency and so on so by

00:11:21,529 --> 00:11:27,200
looking at this you can basically get a

00:11:23,420 --> 00:11:29,180
quick impression at your services if you

00:11:27,200 --> 00:11:31,430
care for more data you pick one of the

00:11:29,180 --> 00:11:33,680
services you dive into detail here and

00:11:31,430 --> 00:11:35,330
you basically get I just copied this

00:11:33,680 --> 00:11:37,640
from the demo so the request count is

00:11:35,330 --> 00:11:39,230
pretty low but what you can imagine

00:11:37,640 --> 00:11:41,270
years if you're looking into this

00:11:39,230 --> 00:11:43,279
microservice world and you have rest api

00:11:41,270 --> 00:11:45,230
is everywhere what you want to see is

00:11:43,279 --> 00:11:46,910
basically not in an average over all

00:11:45,230 --> 00:11:49,339
your endpoints because they vary in

00:11:46,910 --> 00:11:51,980
behavior but you are basically caring

00:11:49,339 --> 00:11:54,170
for the key api's people are calling and

00:11:51,980 --> 00:11:56,510
how do they behave so we built some more

00:11:54,170 --> 00:12:00,740
you I around this the data gathering is

00:11:56,510 --> 00:12:02,630
the old way you saw before then everyone

00:12:00,740 --> 00:12:04,610
I think coming from other tools you like

00:12:02,630 --> 00:12:06,380
to have this overview so let's give me

00:12:04,610 --> 00:12:08,180
all the hosts and show me all the stuff

00:12:06,380 --> 00:12:10,730
that is good or not so good so you can

00:12:08,180 --> 00:12:12,350
also do this you can basically select a

00:12:10,730 --> 00:12:15,080
subset of the stuff you're monitoring

00:12:12,350 --> 00:12:17,360
and we will render for you basically one

00:12:15,080 --> 00:12:19,310
green box for an alert that is fine and

00:12:17,360 --> 00:12:21,710
then depending on them configured colors

00:12:19,310 --> 00:12:24,980
there's yellow and red boxes for stuff

00:12:21,710 --> 00:12:26,720
that is not okay so when we go back here

00:12:24,980 --> 00:12:28,550
earlier i think the worker here that

00:12:26,720 --> 00:12:30,410
this fight was basically the one error

00:12:28,550 --> 00:12:32,210
you saw before it's this one red box

00:12:30,410 --> 00:12:37,580
that there is no status code returned

00:12:32,210 --> 00:12:39,740
here so um the user interface you saw

00:12:37,580 --> 00:12:41,780
earlier basically is requiring really

00:12:39,740 --> 00:12:43,850
full authentication because we built

00:12:41,780 --> 00:12:45,950
this in the salon dewalt we still needed

00:12:43,850 --> 00:12:47,690
to expose this to everyone we also

00:12:45,950 --> 00:12:50,180
wanted to expose us to everyone without

00:12:47,690 --> 00:12:51,860
VPN so this is basically running out

00:12:50,180 --> 00:12:53,660
there on the internet you don't need

00:12:51,860 --> 00:12:57,050
anything special to access it except

00:12:53,660 --> 00:12:58,700
your credentials obviously we support in

00:12:57,050 --> 00:13:00,710
the open source version basically

00:12:58,700 --> 00:13:02,660
logging in via github because this is

00:13:00,710 --> 00:13:05,240
the most convenient way to implement so

00:13:02,660 --> 00:13:07,160
people can quickly get started then we

00:13:05,240 --> 00:13:08,720
have filters on github organizations and

00:13:07,160 --> 00:13:10,700
usernames so this works out of the box

00:13:08,720 --> 00:13:13,550
so everyone who basically goes now to

00:13:10,700 --> 00:13:14,990
the demo zetman dot IO he can login with

00:13:13,550 --> 00:13:18,110
this github account and start playing

00:13:14,990 --> 00:13:19,670
around another use case you often faces

00:13:18,110 --> 00:13:20,810
you want to have TV dashboards in your

00:13:19,670 --> 00:13:22,700
office but you don't want your

00:13:20,810 --> 00:13:24,380
credentials in there so you need to make

00:13:22,700 --> 00:13:26,330
this possible so we built these

00:13:24,380 --> 00:13:28,670
basically one time log and tokens so

00:13:26,330 --> 00:13:31,850
everyone can basically activate a TV

00:13:28,670 --> 00:13:32,150
screen on his behalf graph on R 3 is an

00:13:31,850 --> 00:13:34,160
hour

00:13:32,150 --> 00:13:36,740
software so basically we reimplemented

00:13:34,160 --> 00:13:38,660
the graph on our back-end API so that

00:13:36,740 --> 00:13:40,910
there is really one UI you log in once

00:13:38,660 --> 00:13:42,770
and you get full access to both zetman

00:13:40,910 --> 00:13:45,290
and Griffin I was in there we store the

00:13:42,770 --> 00:13:46,850
dashboards for you tagging starring all

00:13:45,290 --> 00:13:49,550
the stuff you basically know from before

00:13:46,850 --> 00:13:52,520
but just you get all the data we gather

00:13:49,550 --> 00:13:54,320
out of the box this also means that we

00:13:52,520 --> 00:13:56,750
basically have an authentication proxy

00:13:54,320 --> 00:13:58,760
and there in front of kyros DB so we

00:13:56,750 --> 00:14:01,160
also connect other data sources in the

00:13:58,760 --> 00:14:02,690
salon do platform so enabling teams to

00:14:01,160 --> 00:14:04,760
have their own Kairos to be somewhere

00:14:02,690 --> 00:14:07,160
for their metrics and then they can

00:14:04,760 --> 00:14:11,240
render that dashboard in that one for

00:14:07,160 --> 00:14:12,740
their data and the monitoring data we

00:14:11,240 --> 00:14:14,060
see this in graph Anna basically when

00:14:12,740 --> 00:14:15,470
you look back in the trend photograph

00:14:14,060 --> 00:14:17,330
Anna did they built the same thing

00:14:15,470 --> 00:14:19,790
though they build also the spec end and

00:14:17,330 --> 00:14:21,200
go I think two years ago and we did this

00:14:19,790 --> 00:14:24,320
slightly before because everyone

00:14:21,200 --> 00:14:26,000
basically needs authentication how does

00:14:24,320 --> 00:14:28,070
it look like I mean graph on everyone

00:14:26,000 --> 00:14:30,080
knows it so everything you track every

00:14:28,070 --> 00:14:32,150
every numeric values at that one

00:14:30,080 --> 00:14:34,280
acquires goes into Kairos to be and you

00:14:32,150 --> 00:14:35,810
can chart it it's annotated little

00:14:34,280 --> 00:14:38,780
basically where's it coming from this

00:14:35,810 --> 00:14:40,400
value when was it basically measured and

00:14:38,780 --> 00:14:42,680
this is basically what gives you will

00:14:40,400 --> 00:14:44,540
see it later pretty nice metrics so this

00:14:42,680 --> 00:14:46,340
also allows you for example to track

00:14:44,540 --> 00:14:48,410
behavior across different software

00:14:46,340 --> 00:14:50,060
versions and so on so did you fix

00:14:48,410 --> 00:14:52,070
something did you improve something did

00:14:50,060 --> 00:14:54,260
latency become slower with a new version

00:14:52,070 --> 00:14:56,630
and so on this is basically all

00:14:54,260 --> 00:14:58,340
happening automatically since we are

00:14:56,630 --> 00:15:00,020
talking about monitoring there's one

00:14:58,340 --> 00:15:01,460
question you want you want to learning

00:15:00,020 --> 00:15:03,920
when you're not looking at your screen

00:15:01,460 --> 00:15:07,100
so on email is there we can basically

00:15:03,920 --> 00:15:08,720
trigger slack we can trigger hipchat we

00:15:07,100 --> 00:15:13,130
are working on the basically baiting

00:15:08,720 --> 00:15:15,590
right now Trillia phone calls so this is

00:15:13,130 --> 00:15:17,330
all there we also have support for Pedro

00:15:15,590 --> 00:15:19,400
duty and ops Genie so I mean this is

00:15:17,330 --> 00:15:21,050
easy they all have a rest api just need

00:15:19,400 --> 00:15:23,870
to trigger them there is no magic there

00:15:21,050 --> 00:15:25,940
but I kind of prefer this twilio thing

00:15:23,870 --> 00:15:28,910
it has a very low harder to get into it

00:15:25,940 --> 00:15:31,280
and it's not so expensive we also

00:15:28,910 --> 00:15:32,960
recently added push notifications for

00:15:31,280 --> 00:15:34,550
basically the web browser this is a

00:15:32,960 --> 00:15:36,650
pretty neat thing so you have the

00:15:34,550 --> 00:15:38,630
notifications on your desktop but this

00:15:36,650 --> 00:15:40,310
also works flawlessly on android phone

00:15:38,630 --> 00:15:41,750
so that the website renders on the

00:15:40,310 --> 00:15:43,940
mobile phone and you can just subscribe

00:15:41,750 --> 00:15:45,560
to the same amount of alerts there and

00:15:43,940 --> 00:15:47,650
you get the trigger on the phone

00:15:45,560 --> 00:15:50,240
even if you are not opening your Chrome

00:15:47,650 --> 00:15:52,160
at what we have here basically is you

00:15:50,240 --> 00:15:54,200
tell the system I care for this team's

00:15:52,160 --> 00:15:56,150
alerts with a priority one which would

00:15:54,200 --> 00:15:57,980
be all the red alerts please show me a

00:15:56,150 --> 00:15:59,720
notification if something like this pops

00:15:57,980 --> 00:16:01,760
up and this is how people steer

00:15:59,720 --> 00:16:05,839
criticality and alerting and their

00:16:01,760 --> 00:16:08,089
software so um let's look a little bit

00:16:05,839 --> 00:16:09,830
at how that one achieves this so there

00:16:08,089 --> 00:16:11,750
is entities in place and this is

00:16:09,830 --> 00:16:14,600
basically what we use to describe our

00:16:11,750 --> 00:16:16,339
infrastructure so if we take one step

00:16:14,600 --> 00:16:18,200
further basically there is one entity

00:16:16,339 --> 00:16:20,510
for every physical host for every

00:16:18,200 --> 00:16:21,770
database we have there but also for kind

00:16:20,510 --> 00:16:24,740
of logical stuff for an application

00:16:21,770 --> 00:16:26,420
which is not really describing a host in

00:16:24,740 --> 00:16:29,180
particular but maybe only application

00:16:26,420 --> 00:16:32,089
properties there is instances for AWS

00:16:29,180 --> 00:16:34,070
ec2 instances there are elb entities for

00:16:32,089 --> 00:16:36,830
load balances and so on and this is

00:16:34,070 --> 00:16:38,510
basically whenever you have software you

00:16:36,830 --> 00:16:41,750
want to integrate you basically push

00:16:38,510 --> 00:16:44,300
entities and you basically create a JSON

00:16:41,750 --> 00:16:46,460
document describe the properties i hope

00:16:44,300 --> 00:16:48,290
everyone sees this here there's like an

00:16:46,460 --> 00:16:50,420
ID that is unique and then it's a host

00:16:48,290 --> 00:16:52,670
and IP address and whatever you want and

00:16:50,420 --> 00:16:55,580
when you later say okay now I want to

00:16:52,670 --> 00:16:57,830
see if all my hosts are up via ICMP you

00:16:55,580 --> 00:17:00,980
do a filter for type hosts and then you

00:16:57,830 --> 00:17:03,230
write your check doing an ICMP stuff and

00:17:00,980 --> 00:17:05,720
this is basically how it all works so

00:17:03,230 --> 00:17:07,520
what is crucially is that this entity

00:17:05,720 --> 00:17:09,679
they give you a lot of flexibility and

00:17:07,520 --> 00:17:11,540
describing your infrastructure so when

00:17:09,679 --> 00:17:13,339
you look at like what teams are doing

00:17:11,540 --> 00:17:14,900
they have entities for the application

00:17:13,339 --> 00:17:16,400
and then it's tagged basically with

00:17:14,900 --> 00:17:18,439
their team name with the replication

00:17:16,400 --> 00:17:19,640
name with the replication version so

00:17:18,439 --> 00:17:22,040
this is how they then go on and

00:17:19,640 --> 00:17:24,709
basically filter and how data and graph

00:17:22,040 --> 00:17:26,720
ana's are notated it's basically reusing

00:17:24,709 --> 00:17:29,690
fields from these entities to see where

00:17:26,720 --> 00:17:31,670
data is coming from and this is also how

00:17:29,690 --> 00:17:35,600
we basically connect right now so when

00:17:31,670 --> 00:17:37,670
you said earlier AWS auto-discovery this

00:17:35,600 --> 00:17:40,100
basically means for a new ec2 instance

00:17:37,670 --> 00:17:42,260
we create one new instance entity and in

00:17:40,100 --> 00:17:43,670
the data center we do the same thing if

00:17:42,260 --> 00:17:45,650
there is a new physical machine

00:17:43,670 --> 00:17:47,450
somewhere we also do this there is a

00:17:45,650 --> 00:17:49,040
command line client for do this for

00:17:47,450 --> 00:17:51,020
doing this so it can push the ml files

00:17:49,040 --> 00:17:52,520
makes working with it very easy but

00:17:51,020 --> 00:17:55,010
obviously if you really want to automate

00:17:52,520 --> 00:17:56,720
this there is also a Python library that

00:17:55,010 --> 00:17:58,670
you can pull from your system and

00:17:56,720 --> 00:17:59,240
directly push into the other system and

00:17:58,670 --> 00:18:01,400
this is

00:17:59,240 --> 00:18:04,460
kind of how we integrate into services

00:18:01,400 --> 00:18:06,559
so next thing is the check basically the

00:18:04,460 --> 00:18:08,450
check is the data acquisition so you saw

00:18:06,559 --> 00:18:11,150
earlier we are grabbing the status code

00:18:08,450 --> 00:18:13,250
but this is very the tiniest example we

00:18:11,150 --> 00:18:16,040
have so this gives you one numeric value

00:18:13,250 --> 00:18:18,110
but in reality of it's much more complex

00:18:16,040 --> 00:18:20,570
so most checks they return like

00:18:18,110 --> 00:18:22,670
dictionary objects so if you look at cpu

00:18:20,570 --> 00:18:24,500
load you normally track the one-minute

00:18:22,670 --> 00:18:26,720
average the 5-minute average and the

00:18:24,500 --> 00:18:28,429
15-minute average this doesn't mean you

00:18:26,720 --> 00:18:29,960
have three checks in place just means

00:18:28,429 --> 00:18:31,700
you have one simple check returning

00:18:29,960 --> 00:18:34,160
these three values in a nested data

00:18:31,700 --> 00:18:35,840
structure and where he did all the

00:18:34,160 --> 00:18:37,670
integration in the past because we had

00:18:35,840 --> 00:18:39,650
this huge environment already so we have

00:18:37,670 --> 00:18:41,870
like support for querying postgres

00:18:39,650 --> 00:18:44,660
databases support for Cassandra

00:18:41,870 --> 00:18:49,610
elasticsearch mysql amazon cloud watch

00:18:44,660 --> 00:18:52,160
so accessible Oracle SNMP and nagios

00:18:49,610 --> 00:18:53,960
nrpe execution is also in so this is

00:18:52,160 --> 00:18:55,970
kind of important if you look at what

00:18:53,960 --> 00:18:59,240
most people have an data center maybe

00:18:55,970 --> 00:19:01,220
that's what they want to do and this

00:18:59,240 --> 00:19:03,410
Python code is then also often used to

00:19:01,220 --> 00:19:05,600
do some filtering data formatting or

00:19:03,410 --> 00:19:08,480
kind of sometimes switching the

00:19:05,600 --> 00:19:10,850
dimensions here and in the end we see

00:19:08,480 --> 00:19:12,500
this that no one returns a single value

00:19:10,850 --> 00:19:14,750
from the checks right now mostly it's

00:19:12,500 --> 00:19:18,140
much more complex because most objects

00:19:14,750 --> 00:19:21,020
monitored have a set of properties so um

00:19:18,140 --> 00:19:23,000
yeah so this earlier quick recap here so

00:19:21,020 --> 00:19:24,950
really you fight right a little bit of

00:19:23,000 --> 00:19:27,080
Python code for your data acquisition so

00:19:24,950 --> 00:19:29,840
you go somewhere you go to certain pass

00:19:27,080 --> 00:19:33,110
you return Jason and then you do some

00:19:29,840 --> 00:19:36,170
filtering what does kind of might scare

00:19:33,110 --> 00:19:38,150
people away it's that you look at see a

00:19:36,170 --> 00:19:40,520
lot of code right now but what is

00:19:38,150 --> 00:19:42,020
basically truest you do this once so one

00:19:40,520 --> 00:19:44,120
team comes up with elasticsearch

00:19:42,020 --> 00:19:45,830
monitoring they write a certain set of

00:19:44,120 --> 00:19:48,200
checks for elasticsearch and every other

00:19:45,830 --> 00:19:50,000
team can reuse this check because the

00:19:48,200 --> 00:19:51,710
check in itself is not really tightly

00:19:50,000 --> 00:19:54,080
coupled to their particular software

00:19:51,710 --> 00:19:56,090
it's basically coupled to elasticsearch

00:19:54,080 --> 00:19:57,980
so whenever someone else comes along and

00:19:56,090 --> 00:19:59,960
say oh I have elasticsearch to he

00:19:57,980 --> 00:20:02,450
creates an alert and reuses basically

00:19:59,960 --> 00:20:04,820
this check so benefiting usually from

00:20:02,450 --> 00:20:06,950
knowledge people expert to the

00:20:04,820 --> 00:20:08,929
technology already put into it this for

00:20:06,950 --> 00:20:11,030
example happened with Cassandra happens

00:20:08,929 --> 00:20:12,310
for most of the AWS infrastructure and

00:20:11,030 --> 00:20:15,640
so on

00:20:12,310 --> 00:20:17,950
um yeah so just I threw this in

00:20:15,640 --> 00:20:20,080
yesterday because it up to I got the

00:20:17,950 --> 00:20:22,510
impression that most people are more

00:20:20,080 --> 00:20:24,310
interested in like or some people at

00:20:22,510 --> 00:20:25,930
least would be and can we do this

00:20:24,310 --> 00:20:28,180
monitoring of infrastructure where

00:20:25,930 --> 00:20:30,670
nagios and SNMP and so on and all these

00:20:28,180 --> 00:20:32,500
yd walks are still crucial we can do

00:20:30,670 --> 00:20:34,450
this so you basically see people

00:20:32,500 --> 00:20:36,460
monitoring here a dell machine with a

00:20:34,450 --> 00:20:38,680
different command from the HP machine to

00:20:36,460 --> 00:20:41,890
monitor the rate and so on this can all

00:20:38,680 --> 00:20:43,330
be done yeah the SNMP I mean everyone

00:20:41,890 --> 00:20:46,140
looks so this looks like this is a

00:20:43,330 --> 00:20:46,140
little bit more ugly

00:20:46,730 --> 00:20:51,960
okay um yeah also rest api to manage all

00:20:50,370 --> 00:20:55,740
this stuff but right now it's all you I

00:20:51,960 --> 00:20:57,419
driven so that is that's the old flow

00:20:55,740 --> 00:20:59,279
was basically people have the check

00:20:57,419 --> 00:21:02,009
somewhere and get and then also import

00:20:59,279 --> 00:21:05,159
it but that doesn't work people want to

00:21:02,009 --> 00:21:07,019
use your eyes yeah there is a trial run

00:21:05,159 --> 00:21:08,789
so this is basically the debug mode you

00:21:07,019 --> 00:21:10,289
go in there um you type your commands

00:21:08,789 --> 00:21:12,330
you press run it will run on the whole

00:21:10,289 --> 00:21:14,070
infrastructure UCR this is the stuff I

00:21:12,330 --> 00:21:16,169
want or you fiddle with it and you press

00:21:14,070 --> 00:21:18,179
run again and so on so this is basically

00:21:16,169 --> 00:21:21,149
helping the everyday developer in the

00:21:18,179 --> 00:21:24,149
workflow yeah let's let's go to alerts

00:21:21,149 --> 00:21:25,830
and questions we can do later hope you

00:21:24,149 --> 00:21:28,320
someone's got the idea write something

00:21:25,830 --> 00:21:32,429
get data in and then start alerting on

00:21:28,320 --> 00:21:34,259
it yeah lots are attached to checks they

00:21:32,429 --> 00:21:35,970
are owned by teams basically there's

00:21:34,259 --> 00:21:39,000
stuff like inheritance so you can reuse

00:21:35,970 --> 00:21:40,950
the Lots also but in the end it runs a

00:21:39,000 --> 00:21:42,990
Python expression takes the metrics

00:21:40,950 --> 00:21:45,379
gathered and say okay now I triggers you

00:21:42,990 --> 00:21:49,350
a lot or not that's basically very easy

00:21:45,379 --> 00:21:50,970
and again you have pison so you can do a

00:21:49,350 --> 00:21:52,289
lot of stuff you can also look at the

00:21:50,970 --> 00:21:54,509
history data because we have the

00:21:52,289 --> 00:21:55,950
historic data you can look at that's the

00:21:54,509 --> 00:21:58,289
well you deviate from last week's

00:21:55,950 --> 00:22:00,330
behavior from the average behavior in

00:21:58,289 --> 00:22:01,980
the past few weeks all this stuff if you

00:22:00,330 --> 00:22:04,710
want but you need to a little bit of

00:22:01,980 --> 00:22:06,419
brain power to do it yourself but there

00:22:04,710 --> 00:22:09,210
is code basically helping you to achieve

00:22:06,419 --> 00:22:11,009
this yeah no warning state no unknown

00:22:09,210 --> 00:22:13,950
state or anything like this there's only

00:22:11,009 --> 00:22:16,590
like technical exception or a lot up or

00:22:13,950 --> 00:22:17,909
down we have the priorities they are

00:22:16,590 --> 00:22:21,240
free to use you saw this earlier

00:22:17,909 --> 00:22:22,950
reflected in the colors so if we if we

00:22:21,240 --> 00:22:25,830
go somewhere here basically let's look

00:22:22,950 --> 00:22:27,899
at Cassandra we do a jmx query to to a

00:22:25,830 --> 00:22:29,940
beam in Cassandra return something and

00:22:27,899 --> 00:22:32,340
then we want to see us the down end

00:22:29,940 --> 00:22:34,139
point count come by a dream it's bigger

00:22:32,340 --> 00:22:36,149
than one so is one note down in

00:22:34,139 --> 00:22:40,980
Cassandra let's please trigger this

00:22:36,149 --> 00:22:42,419
alone so this is no big magic there is

00:22:40,980 --> 00:22:43,980
stuff like downtime so everyone knows

00:22:42,419 --> 00:22:45,960
you to deploy software and during

00:22:43,980 --> 00:22:47,850
deployment everything goes red so

00:22:45,960 --> 00:22:49,950
basically you can announce to that one I

00:22:47,850 --> 00:22:52,500
want to deploy this application please

00:22:49,950 --> 00:22:55,980
don't trigger anything on it so this is

00:22:52,500 --> 00:22:58,679
basically how we manage this scenario so

00:22:55,980 --> 00:22:59,460
there is a REST API saying okay host 01

00:22:58,679 --> 00:23:04,110
will go down

00:22:59,460 --> 00:23:05,549
on on please don't do anything um yeah I

00:23:04,110 --> 00:23:06,960
said a little bit about this it's

00:23:05,549 --> 00:23:09,270
crucial to understand that there is a

00:23:06,960 --> 00:23:11,190
lot of reuse going on so basically some

00:23:09,270 --> 00:23:12,779
teams are ahead and monitoring are ahead

00:23:11,190 --> 00:23:14,460
of knowledge they write something and

00:23:12,779 --> 00:23:17,580
other people basically look it up they

00:23:14,460 --> 00:23:19,440
reuse it and this is very helpful the

00:23:17,580 --> 00:23:21,750
other thing is everyone can do this so

00:23:19,440 --> 00:23:24,419
we have product managers doing KPI

00:23:21,750 --> 00:23:27,120
monitoring with it we have system

00:23:24,419 --> 00:23:29,760
engineers looking at cpu load there is

00:23:27,120 --> 00:23:32,039
KP is monitored and exercise a huge huge

00:23:29,760 --> 00:23:34,440
basically data warehouse there is stuff

00:23:32,039 --> 00:23:36,000
monitored in phosphorus and you you see

00:23:34,440 --> 00:23:38,100
the vast array of stuff that is

00:23:36,000 --> 00:23:40,409
basically in there and that's easy

00:23:38,100 --> 00:23:42,330
because pison the stuff the data

00:23:40,409 --> 00:23:44,610
gathering pison is very compatible to

00:23:42,330 --> 00:23:48,059
almost anything you use you're not

00:23:44,610 --> 00:23:50,279
really constrained there and yeah and

00:23:48,059 --> 00:23:51,840
the other thing is basically by reusing

00:23:50,279 --> 00:23:54,390
alerts from other teams you are also

00:23:51,840 --> 00:23:56,850
able to monitor your downstream systems

00:23:54,390 --> 00:23:58,799
so when you talk always to this API and

00:23:56,850 --> 00:24:00,899
it's crucial for you you maybe want to

00:23:58,799 --> 00:24:08,100
have your own a lot to see if this stuff

00:24:00,899 --> 00:24:10,289
is behaving as you expect it so yeah so

00:24:08,100 --> 00:24:12,840
let's let's make one example maybe from

00:24:10,289 --> 00:24:14,970
the real world so we set out last year

00:24:12,840 --> 00:24:16,919
to build our own oil infrastructure so I

00:24:14,970 --> 00:24:18,929
said we needed something to create

00:24:16,919 --> 00:24:22,260
tokens and we need something to verify

00:24:18,929 --> 00:24:24,179
tokens and we both this stuff we built a

00:24:22,260 --> 00:24:27,149
multi-region solution using cassandra in

00:24:24,179 --> 00:24:29,429
the back end and java web tokens or JSON

00:24:27,149 --> 00:24:31,740
web tokens basically to do verification

00:24:29,429 --> 00:24:33,630
it's very nice you just need to do you

00:24:31,740 --> 00:24:35,940
have basically Jason you put a signature

00:24:33,630 --> 00:24:38,640
on it with elliptic curve and then the

00:24:35,940 --> 00:24:41,520
verification is really cheap and fast so

00:24:38,640 --> 00:24:43,909
just as a basically impression Black

00:24:41,520 --> 00:24:46,590
Friday last week was somewhere in the

00:24:43,909 --> 00:24:49,590
45,000 verifications for tokens per

00:24:46,590 --> 00:24:52,409
second so it's really working so go is

00:24:49,590 --> 00:24:55,559
really fast and you can achieve a 1.5

00:24:52,409 --> 00:24:58,260
millisecond basically what is it 98 99

00:24:55,559 --> 00:25:00,450
percentile so this is great you need

00:24:58,260 --> 00:25:02,130
some software to get a token so do some

00:25:00,450 --> 00:25:04,770
credential verification this is written

00:25:02,130 --> 00:25:06,630
in Java and then there is Cassandra in

00:25:04,770 --> 00:25:10,289
the back end basically only storing user

00:25:06,630 --> 00:25:12,539
credentials so we have a huge Cassandra

00:25:10,289 --> 00:25:13,200
array to store a few user password

00:25:12,539 --> 00:25:15,659
combination

00:25:13,200 --> 00:25:17,970
but you have to keep in mind this is

00:25:15,659 --> 00:25:20,639
crucial if this goes down everything

00:25:17,970 --> 00:25:23,220
stops so basically running really a core

00:25:20,639 --> 00:25:25,740
piece of software and in front for those

00:25:23,220 --> 00:25:27,870
not familiar with Amazon it's an EOB so

00:25:25,740 --> 00:25:30,409
a load balancer could be anything H a

00:25:27,870 --> 00:25:34,169
proxy f5 whatever you can come up with

00:25:30,409 --> 00:25:36,450
so there is this agent goes to the AWS

00:25:34,169 --> 00:25:38,760
you is as described instances describe

00:25:36,450 --> 00:25:40,830
lbs and what we get is basically the

00:25:38,760 --> 00:25:43,559
stuff you saw in the picture before by

00:25:40,830 --> 00:25:45,960
crawling the AWS API we get something

00:25:43,559 --> 00:25:48,149
like an ec2 instance here just to put a

00:25:45,960 --> 00:25:51,029
bit more picture into how an entity can

00:25:48,149 --> 00:25:52,950
look like so we have the application ID

00:25:51,029 --> 00:25:54,630
we have the host we have an

00:25:52,950 --> 00:25:57,269
infrastructure account so we know where

00:25:54,630 --> 00:25:59,429
it's running in the AWS world we know

00:25:57,269 --> 00:26:01,529
the instance type so maybe you can later

00:25:59,429 --> 00:26:03,510
see our ok they've shown so much memory

00:26:01,529 --> 00:26:05,460
there's on so much course so depending

00:26:03,510 --> 00:26:07,590
on one's you want to see you have the

00:26:05,460 --> 00:26:10,049
region and so on but what from this you

00:26:07,590 --> 00:26:12,649
can basically grasp how people build the

00:26:10,049 --> 00:26:15,510
filtering on their checks and alerts on

00:26:12,649 --> 00:26:17,789
second example elastic load balancer the

00:26:15,510 --> 00:26:20,309
same thing we enrich it with a bit more

00:26:17,789 --> 00:26:22,049
metadata so people can build alerts on

00:26:20,309 --> 00:26:24,990
for example number of active members

00:26:22,049 --> 00:26:26,820
number of failing members and so on so

00:26:24,990 --> 00:26:28,740
this is sometimes hidden away and the

00:26:26,820 --> 00:26:32,070
entity and makes it also kind of useful

00:26:28,740 --> 00:26:34,049
for monitoring properties if we then

00:26:32,070 --> 00:26:36,840
look at like physical machine monitoring

00:26:34,049 --> 00:26:38,940
in the Amazon world some stuff is in

00:26:36,840 --> 00:26:41,240
cloud watch with this Amazon metrics but

00:26:38,940 --> 00:26:43,799
for the other stuff we basically have

00:26:41,240 --> 00:26:45,659
reused the Prometheus agent so

00:26:43,799 --> 00:26:47,429
Prometheus at this other monitoring

00:26:45,659 --> 00:26:50,130
buzzword right now and they have pretty

00:26:47,429 --> 00:26:52,230
nice agents so ok let's use their agent

00:26:50,130 --> 00:26:54,419
for system metrics run it on every ec2

00:26:52,230 --> 00:26:57,059
instance and with this we basically have

00:26:54,419 --> 00:26:59,100
access to disk storage disk used by

00:26:57,059 --> 00:27:01,380
partitioned and attached volumes to

00:26:59,100 --> 00:27:04,919
memory and CPU metrics that aren't all

00:27:01,380 --> 00:27:06,779
in the Amazon monitoring by default so

00:27:04,919 --> 00:27:09,029
basically we run one docker image on an

00:27:06,779 --> 00:27:11,309
ec2 instance we run a logging agent

00:27:09,029 --> 00:27:14,580
shipping our logs to two scalar or other

00:27:11,309 --> 00:27:16,620
solutions and there is the note agent on

00:27:14,580 --> 00:27:19,289
a different pot so we can basically with

00:27:16,620 --> 00:27:23,370
HTTP monitor all the stuff that is

00:27:19,289 --> 00:27:26,460
crucial to our infrastructure slightly

00:27:23,370 --> 00:27:27,149
more complex example here but maybe you

00:27:26,460 --> 00:27:29,070
can see

00:27:27,149 --> 00:27:31,200
we want to look at different stuff so

00:27:29,070 --> 00:27:33,389
failure detection and latency for

00:27:31,200 --> 00:27:35,279
read/write and we iterate over it and

00:27:33,389 --> 00:27:37,499
this is basically the rough idea here so

00:27:35,279 --> 00:27:40,229
we track Cassandra up down state and

00:27:37,499 --> 00:27:42,570
Layton sees and what happens here is

00:27:40,229 --> 00:27:45,179
basically after running you get back

00:27:42,570 --> 00:27:47,099
this jason from zetman and it shows you

00:27:45,179 --> 00:27:49,859
all the fields you selected earlier I

00:27:47,099 --> 00:27:52,919
hope this is kind of understood by now

00:27:49,859 --> 00:27:55,739
and this data goes straight into kyros

00:27:52,919 --> 00:27:58,229
DB into what is it here ten different

00:27:55,739 --> 00:28:00,330
time series for one particular host and

00:27:58,229 --> 00:28:03,239
then you can start basically building

00:28:00,330 --> 00:28:04,739
your dashboard with this and this is so

00:28:03,239 --> 00:28:06,929
for some people that Mon sometimes is

00:28:04,739 --> 00:28:08,729
just this cron job grabbing a number

00:28:06,929 --> 00:28:10,109
putting it into graph honor so that they

00:28:08,729 --> 00:28:12,599
have a chart it's not always about

00:28:10,109 --> 00:28:15,809
really active alerting but very very

00:28:12,599 --> 00:28:18,419
helpful so how does it look like here

00:28:15,809 --> 00:28:20,639
from the UI perspective everyone not

00:28:18,419 --> 00:28:22,229
everyone I hope everyone has seen graph

00:28:20,639 --> 00:28:24,570
honor because it's a great open source

00:28:22,229 --> 00:28:26,369
product to use you see here the

00:28:24,570 --> 00:28:29,339
different curves the different tags and

00:28:26,369 --> 00:28:30,779
annotations looking back at the that Mon

00:28:29,339 --> 00:28:33,690
you I basically this is a dynamic

00:28:30,779 --> 00:28:35,399
dashboard so for every check we can

00:28:33,690 --> 00:28:37,229
basically pre create one dashboard

00:28:35,399 --> 00:28:38,789
because we understand how the metrics

00:28:37,229 --> 00:28:40,440
are stored so you don't need for every

00:28:38,789 --> 00:28:42,179
check to build your dashboard the

00:28:40,440 --> 00:28:44,099
default behavior like showing the

00:28:42,179 --> 00:28:45,839
different values is in there we have

00:28:44,099 --> 00:28:47,940
stuff like deep links so this is also

00:28:45,839 --> 00:28:50,039
easy to integrate so this tiny cloud

00:28:47,940 --> 00:28:52,769
icon is a deep link into the Amazon UI

00:28:50,039 --> 00:28:54,299
which is really helpful so you have the

00:28:52,769 --> 00:28:56,309
instance ID and the entity and then you

00:28:54,299 --> 00:28:58,559
can directly link and filter to Amazon

00:28:56,309 --> 00:29:00,389
and then you get your instance there and

00:28:58,559 --> 00:29:02,159
you can imagine you can also do this for

00:29:00,389 --> 00:29:06,179
other tooling because you have the data

00:29:02,159 --> 00:29:08,580
present in the UI so here's one example

00:29:06,179 --> 00:29:09,929
basically switching traffic and Amazon

00:29:08,580 --> 00:29:12,419
so basically we have two different

00:29:09,929 --> 00:29:14,639
versions so the craft here is the upper

00:29:12,419 --> 00:29:17,309
one is the requests per over time at the

00:29:14,639 --> 00:29:19,619
lower one is latency so basically we

00:29:17,309 --> 00:29:21,570
deploy here traffic goes down on one

00:29:19,619 --> 00:29:23,789
stack and goes up on the other and then

00:29:21,570 --> 00:29:25,379
you have this latency skew and the new

00:29:23,789 --> 00:29:27,509
one is slow in the beginning and the

00:29:25,379 --> 00:29:30,359
other one becomes slow by and basically

00:29:27,509 --> 00:29:32,549
EOB metrics becoming less less traffic

00:29:30,359 --> 00:29:33,599
means often the latency increase but it

00:29:32,549 --> 00:29:35,460
is really how it looks like in

00:29:33,599 --> 00:29:37,320
production when you monitor stuff and

00:29:35,460 --> 00:29:39,029
this would also enable you like with

00:29:37,320 --> 00:29:40,620
your human eye to see okay the new

00:29:39,029 --> 00:29:43,020
version is slower

00:29:40,620 --> 00:29:45,510
latency doubled and so on but basically

00:29:43,020 --> 00:29:47,160
this shows you we have this metadata in

00:29:45,510 --> 00:29:48,960
there to understand this is a new

00:29:47,160 --> 00:29:53,640
software version from this point in time

00:29:48,960 --> 00:29:55,890
and this is helpful to yeah um this we

00:29:53,640 --> 00:29:58,760
had so their stuff like also template

00:29:55,890 --> 00:30:01,980
variable replacement from the alerting

00:29:58,760 --> 00:30:03,360
not really much metric don't think so

00:30:01,980 --> 00:30:05,400
much about the plus year for the

00:30:03,360 --> 00:30:07,620
percentage and maybe a talk later

00:30:05,400 --> 00:30:11,970
talking you not to some percentage but

00:30:07,620 --> 00:30:13,830
it's a different use case yeah this is

00:30:11,970 --> 00:30:15,990
already shown basically graph on the

00:30:13,830 --> 00:30:18,420
tables does also work nicely with the

00:30:15,990 --> 00:30:21,540
software so what have we learned so far

00:30:18,420 --> 00:30:24,450
a lot of people do HTTP requests which

00:30:21,540 --> 00:30:27,360
is fine we read read data for jmx so

00:30:24,450 --> 00:30:28,800
from Cassandra we reach prometheus data

00:30:27,360 --> 00:30:31,530
and this promise yet format from

00:30:28,800 --> 00:30:34,800
Prometheus agents we use cloud watch to

00:30:31,530 --> 00:30:37,170
monitor the EOB and we go to our logging

00:30:34,800 --> 00:30:39,720
providers rest api to do the default

00:30:37,170 --> 00:30:43,950
lock file analysis so monitoring for

00:30:39,720 --> 00:30:46,590
warning error and so on yeah now we will

00:30:43,950 --> 00:30:48,450
scare you a little bit away is quickly

00:30:46,590 --> 00:30:50,300
covering the deployment and you can

00:30:48,450 --> 00:30:53,580
imagine this is not basically for free

00:30:50,300 --> 00:30:55,830
but there is docker to the rescue and

00:30:53,580 --> 00:30:59,010
those will show you later so this is

00:30:55,830 --> 00:31:01,080
just the tech stuff involved here so

00:30:59,010 --> 00:31:02,730
this basically why it's fun to work on

00:31:01,080 --> 00:31:04,410
this project it's a project where you

00:31:02,730 --> 00:31:07,380
have everything you ever want to work

00:31:04,410 --> 00:31:12,210
with so that's really cool from from the

00:31:07,380 --> 00:31:14,280
engineering perspective but one part

00:31:12,210 --> 00:31:16,410
down here is like Cassandra Kairos to be

00:31:14,280 --> 00:31:18,480
so this everyone can use for time series

00:31:16,410 --> 00:31:20,340
and disconnect from that one but

00:31:18,480 --> 00:31:22,530
obviously some people are scared by

00:31:20,340 --> 00:31:25,020
Cassandra that's kind of true but it's

00:31:22,530 --> 00:31:27,870
also one of the the easiest basically to

00:31:25,020 --> 00:31:30,540
get running and walking Rattus Rattus is

00:31:27,870 --> 00:31:32,580
basically a very reliable piece of

00:31:30,540 --> 00:31:34,170
technology so that's also easy to run

00:31:32,580 --> 00:31:35,970
and then you have our own components

00:31:34,170 --> 00:31:38,490
around this basically the controller

00:31:35,970 --> 00:31:40,980
driving the UI the scheduler who takes

00:31:38,490 --> 00:31:42,780
part of running what and when and the

00:31:40,980 --> 00:31:45,120
worker was doing the heavy lifting who

00:31:42,780 --> 00:31:48,179
receives a task go somewhere grabs data

00:31:45,120 --> 00:31:50,730
and persisted for all the stuff you see

00:31:48,179 --> 00:31:52,830
here we are basically providing docker

00:31:50,730 --> 00:31:54,090
images so as I said we run this in our

00:31:52,830 --> 00:31:56,279
infrastructure to

00:31:54,090 --> 00:31:58,799
so we configure the whole software using

00:31:56,279 --> 00:32:01,890
environment variables and we provide

00:31:58,799 --> 00:32:04,080
basically the demo on demoed at mendota

00:32:01,890 --> 00:32:06,480
oh and the whole setup is also in github

00:32:04,080 --> 00:32:08,700
it's one shell script and you can see

00:32:06,480 --> 00:32:11,580
it's basically 56 environment variables

00:32:08,700 --> 00:32:13,169
per component but it's understandable we

00:32:11,580 --> 00:32:15,059
we know that there are some other

00:32:13,169 --> 00:32:17,279
deployments also some new ones in the

00:32:15,059 --> 00:32:19,080
recent weeks and they have managed with

00:32:17,279 --> 00:32:21,029
the documentation to basically get this

00:32:19,080 --> 00:32:23,100
running and one guy he's even running

00:32:21,029 --> 00:32:26,100
this federated set up so he is doing

00:32:23,100 --> 00:32:27,899
multi-region stuff with it also and here

00:32:26,100 --> 00:32:30,840
I mean this is the other big buzzword

00:32:27,899 --> 00:32:32,970
right now Cuban it is everywhere so we

00:32:30,840 --> 00:32:34,830
also have a repository describing how to

00:32:32,970 --> 00:32:36,419
deploy on cuban eaters with all the

00:32:34,830 --> 00:32:38,940
service definitions the deployment

00:32:36,419 --> 00:32:41,370
definitions and this is i mean the the

00:32:38,940 --> 00:32:43,740
prime example for cuba need is also

00:32:41,370 --> 00:32:45,539
running on your local host you get going

00:32:43,740 --> 00:32:48,299
in like five minutes depending on your

00:32:45,539 --> 00:32:49,919
download bandwidth because like there is

00:32:48,299 --> 00:32:51,890
mini cube you run it locally that's

00:32:49,919 --> 00:32:55,529
great and that's also easy to run on

00:32:51,890 --> 00:32:58,140
anyones basically playground so this is

00:32:55,529 --> 00:33:03,600
like all the components you need this is

00:32:58,140 --> 00:33:05,669
straight available okay um some of the

00:33:03,600 --> 00:33:08,220
special topics I don't want to go so

00:33:05,669 --> 00:33:10,140
much into detail but we came from a word

00:33:08,220 --> 00:33:11,640
with two data centers basically

00:33:10,140 --> 00:33:14,309
connected to each other so shared

00:33:11,640 --> 00:33:16,440
network but that's not always true and

00:33:14,309 --> 00:33:17,880
for a SS for us it's not true at all so

00:33:16,440 --> 00:33:19,919
we built these features in there that

00:33:17,880 --> 00:33:22,110
people might need they might need

00:33:19,919 --> 00:33:23,580
basically to be able to to split

00:33:22,110 --> 00:33:25,710
workloads into two different data

00:33:23,580 --> 00:33:27,899
centers and to do different vlans and so

00:33:25,710 --> 00:33:30,210
on so this can all be achieved we put

00:33:27,899 --> 00:33:33,659
this into basically by a dynamic filter

00:33:30,210 --> 00:33:35,990
so it can depend on filters or entity

00:33:33,659 --> 00:33:39,990
properties where stuff gets executed

00:33:35,990 --> 00:33:42,330
yeah that is interesting for some people

00:33:39,990 --> 00:33:44,399
I hope um yeah this is how it looks like

00:33:42,330 --> 00:33:46,740
for us or how anyone does this multi

00:33:44,399 --> 00:33:48,779
region stuff so we run something is the

00:33:46,740 --> 00:33:50,940
appliance or a subset of the components

00:33:48,779 --> 00:33:53,630
you saw earlier and they kind of in a

00:33:50,940 --> 00:33:57,059
federated manner send data back to our

00:33:53,630 --> 00:33:59,220
teams AWS account where we provide the

00:33:57,059 --> 00:34:01,260
service of running Cassandra the UI and

00:33:59,220 --> 00:34:03,330
everything they need to do it they just

00:34:01,260 --> 00:34:06,620
pick these few components start it up in

00:34:03,330 --> 00:34:06,620
their account and they are good to go

00:34:07,110 --> 00:34:12,359
the microservice world I showed this

00:34:10,020 --> 00:34:14,040
already earlier that is really like what

00:34:12,359 --> 00:34:16,919
we added recently just to briefly go

00:34:14,040 --> 00:34:18,419
into I think this is very very helpful

00:34:16,919 --> 00:34:20,280
when you think about looking at your

00:34:18,419 --> 00:34:23,010
life performance this is really like

00:34:20,280 --> 00:34:24,600
read time it refreshes every 60 seconds

00:34:23,010 --> 00:34:26,220
so you get really a good impression of

00:34:24,600 --> 00:34:28,830
what is going running your service and

00:34:26,220 --> 00:34:31,080
this is slightly the paradigm shift also

00:34:28,830 --> 00:34:34,379
that this is the first time we build a

00:34:31,080 --> 00:34:36,240
UI to out-of-the-box do stuff so maybe

00:34:34,379 --> 00:34:39,210
you understood earlier people needed to

00:34:36,240 --> 00:34:41,280
do something needed to do check and a

00:34:39,210 --> 00:34:43,560
lot in the graph on a dashboard and now

00:34:41,280 --> 00:34:46,440
we have the slight more service shift

00:34:43,560 --> 00:34:50,070
change so we are now providing like for

00:34:46,440 --> 00:34:52,139
HTTP API is a better user experience so

00:34:50,070 --> 00:34:54,179
people get used to New Relic or

00:34:52,139 --> 00:34:55,950
epidemics they log in there they throw

00:34:54,179 --> 00:34:58,140
this java agent somewhere and they get

00:34:55,950 --> 00:35:00,869
this dashboard and obviously we need to

00:34:58,140 --> 00:35:03,119
compete with this internally also so we

00:35:00,869 --> 00:35:06,480
started building better UI for the

00:35:03,119 --> 00:35:10,190
default use cases and obviously running

00:35:06,480 --> 00:35:12,900
microservices is the prime use case here

00:35:10,190 --> 00:35:14,670
yea the deep dive into a special service

00:35:12,900 --> 00:35:16,770
so that's kind of okay you see over time

00:35:14,670 --> 00:35:19,170
the basically exceptions and the non

00:35:16,770 --> 00:35:21,960
okay status code so you can easily track

00:35:19,170 --> 00:35:24,060
this we render also the timing chart so

00:35:21,960 --> 00:35:26,190
this helps a lot and how do we do this

00:35:24,060 --> 00:35:28,470
basically we have libraries for all the

00:35:26,190 --> 00:35:31,710
common frameworks and they expose on a

00:35:28,470 --> 00:35:33,510
per application note these metrics so if

00:35:31,710 --> 00:35:35,430
you if you want to expose this you just

00:35:33,510 --> 00:35:37,320
included and you're good to go there's

00:35:35,430 --> 00:35:39,450
almost no work required on the

00:35:37,320 --> 00:35:42,060
engineering side besides adding this

00:35:39,450 --> 00:35:43,859
dependency in maven and lining or

00:35:42,060 --> 00:35:48,150
whatever people choose to use and

00:35:43,859 --> 00:35:51,600
obviously this drives adoption also okay

00:35:48,150 --> 00:35:55,350
um I think I'm a little bit ahead of

00:35:51,600 --> 00:35:57,990
time but maybe we can do Q&A these are

00:35:55,350 --> 00:36:01,650
the URLs go to the demo take a look

00:35:57,990 --> 00:36:03,420
around go to the other pages we have a

00:36:01,650 --> 00:36:05,460
slack chat set up so if you want to join

00:36:03,420 --> 00:36:07,440
and discuss stuff with us or need some

00:36:05,460 --> 00:36:09,300
help we are happy to do this you're

00:36:07,440 --> 00:36:12,270
really hoping to find at least a few

00:36:09,300 --> 00:36:15,150
more people willing to try it out yeah

00:36:12,270 --> 00:36:18,260
thanks for listening today and enjoy the

00:36:15,150 --> 00:36:20,250
other two days of talks and monitoring

00:36:18,260 --> 00:36:27,450
thank you young

00:36:20,250 --> 00:36:43,670
a lot of information thank you so any

00:36:27,450 --> 00:36:47,870
questions no one why kyros TB for Time

00:36:43,670 --> 00:36:52,490
series mmm that was a lucky coincidence

00:36:47,870 --> 00:36:55,250
we had one other team that basically

00:36:52,490 --> 00:36:58,320
outperformed graphite at the time and

00:36:55,250 --> 00:37:01,290
they looked around and they saw Kairos

00:36:58,320 --> 00:37:04,020
to be and for us it was in a perfect fit

00:37:01,290 --> 00:37:05,520
because cars to be has an HTTP API which

00:37:04,020 --> 00:37:07,680
was perfect for us to basically

00:37:05,520 --> 00:37:09,480
integrate with the data structure we had

00:37:07,680 --> 00:37:11,700
in the worker and we just started

00:37:09,480 --> 00:37:15,120
writing to it and this basically worked

00:37:11,700 --> 00:37:16,620
from the get-go and for me the crucial

00:37:15,120 --> 00:37:19,110
part it's basically it relies on

00:37:16,620 --> 00:37:21,030
Cassandra and everyone or at least that

00:37:19,110 --> 00:37:23,310
we had experience with Cassandra itude

00:37:21,030 --> 00:37:24,720
it works it scales and we know how to

00:37:23,310 --> 00:37:27,930
operate it in this mutti host

00:37:24,720 --> 00:37:31,110
environment and that's just the great or

00:37:27,930 --> 00:37:33,840
the good fit for us right now little bit

00:37:31,110 --> 00:37:35,610
maybe the Cassandra you have to ideally

00:37:33,840 --> 00:37:38,010
use one of the newer Cassandra versions

00:37:35,610 --> 00:37:39,990
because of how our data is stored over

00:37:38,010 --> 00:37:43,800
time in Cassandra so don't use the older

00:37:39,990 --> 00:37:46,200
versions but we wrote the stone this is

00:37:43,800 --> 00:37:48,630
it independent of that one really a very

00:37:46,200 --> 00:37:51,270
cool time series data base that is very

00:37:48,630 --> 00:38:01,860
nice to use graph on on stuff from very

00:37:51,270 --> 00:38:09,300
easy HTTP API so for pushing data any

00:38:01,860 --> 00:38:12,840
other question yes again for kairos to

00:38:09,300 --> 00:38:17,280
be how long you are staring storing the

00:38:12,840 --> 00:38:20,910
metrics data for viewing and having

00:38:17,280 --> 00:38:24,870
dashboards for the alarms we we promised

00:38:20,910 --> 00:38:30,930
users to do three months on that's not

00:38:24,870 --> 00:38:33,180
100% achieved okay but when you really

00:38:30,930 --> 00:38:34,090
wonder other like Cassandra introduced

00:38:33,180 --> 00:38:36,880
recently this

00:38:34,090 --> 00:38:39,100
data compaction which makes it really it

00:38:36,880 --> 00:38:41,020
doesn't care anymore about how many data

00:38:39,100 --> 00:38:43,300
there is you could now do years it's

00:38:41,020 --> 00:38:45,220
really nicely partitioned into we have

00:38:43,300 --> 00:38:47,530
basically one Cassandra data file per

00:38:45,220 --> 00:38:49,810
day and this is perfect so basically on

00:38:47,530 --> 00:38:52,300
the old ones would always do this huge

00:38:49,810 --> 00:38:55,300
merging of files but the new cassandra

00:38:52,300 --> 00:38:57,250
has this basically time-based compaction

00:38:55,300 --> 00:38:59,560
so it's really one file one day and then

00:38:57,250 --> 00:39:02,620
after three months one file is dropped

00:38:59,560 --> 00:39:04,510
no I all work no rescanning of existing

00:39:02,620 --> 00:39:07,480
data all the time so this helped a lot

00:39:04,510 --> 00:39:09,760
and so for me that's but I do three

00:39:07,480 --> 00:39:12,760
months or one year is just money

00:39:09,760 --> 00:39:14,470
question obviously querying one year of

00:39:12,760 --> 00:39:25,510
data points without roll-up will not

00:39:14,470 --> 00:39:29,340
work but when i understudied in student

00:39:25,510 --> 00:39:32,110
right you have different teams yes can

00:39:29,340 --> 00:39:35,380
build different checks and so on and

00:39:32,110 --> 00:39:39,280
every team can do what they want so how

00:39:35,380 --> 00:39:42,280
do you is there any requests to will for

00:39:39,280 --> 00:39:45,940
four checks for example if one team has

00:39:42,280 --> 00:39:54,130
a check it's called a check disk see

00:39:45,940 --> 00:39:57,370
with the with the warning ratio of

00:39:54,130 --> 00:39:59,200
eighty percent and critical for ninety

00:39:57,370 --> 00:40:02,650
percent and so on and the other team is

00:39:59,200 --> 00:40:05,140
doing it for 85 and 95 and so on and

00:40:02,650 --> 00:40:09,730
then call it a little different so you

00:40:05,140 --> 00:40:12,850
have maybe ten checks who are slightly

00:40:09,730 --> 00:40:16,150
the same but but not even so there's a

00:40:12,850 --> 00:40:21,940
lot of checks you don't really need so

00:40:16,150 --> 00:40:23,970
is there any kind of a to who who says

00:40:21,940 --> 00:40:27,010
okay this check is already present

00:40:23,970 --> 00:40:30,570
please choose this one because we don't

00:40:27,010 --> 00:40:34,150
want to have so many different checks

00:40:30,570 --> 00:40:36,130
first of all just that I will say one

00:40:34,150 --> 00:40:39,100
sense to the initial setup so basically

00:40:36,130 --> 00:40:40,720
for just not to mix this stuff so first

00:40:39,100 --> 00:40:42,940
there's like check just only the data

00:40:40,720 --> 00:40:45,160
acquisition so give you number of bytes

00:40:42,940 --> 00:40:47,740
free on your disk or partitions and so

00:40:45,160 --> 00:40:50,580
on so this is what people would

00:40:47,740 --> 00:40:53,490
normally like look for in the existing

00:40:50,580 --> 00:40:56,020
existing amount of checks so they would

00:40:53,490 --> 00:40:57,369
sadly not all the time but most of the

00:40:56,020 --> 00:40:59,890
time they would see did someone have a

00:40:57,369 --> 00:41:01,660
check to give me this space from from

00:40:59,890 --> 00:41:03,280
this particular class of hosts already

00:41:01,660 --> 00:41:06,490
so the checks have a pretty good

00:41:03,280 --> 00:41:10,000
percentage of reuse and whether teams

00:41:06,490 --> 00:41:12,070
then basically put a lot thresholds they

00:41:10,000 --> 00:41:15,220
pick that's really up to them and this

00:41:12,070 --> 00:41:18,490
is some we don't care really so much and

00:41:15,220 --> 00:41:20,350
there is no requests on this so so we

00:41:18,490 --> 00:41:22,180
provide basically we have a Vicki

00:41:20,350 --> 00:41:24,520
internally and a hip chat for the user

00:41:22,180 --> 00:41:26,260
base so pretty active internally on

00:41:24,520 --> 00:41:28,930
helping each other with all the use

00:41:26,260 --> 00:41:31,330
cases and we we link the most common

00:41:28,930 --> 00:41:35,080
ones to reuse so beat from this space to

00:41:31,330 --> 00:41:38,200
memory to to Apia to load balancing so

00:41:35,080 --> 00:41:40,180
there we have a kind of basically 1012

00:41:38,200 --> 00:41:42,610
checks most people reuse but then the

00:41:40,180 --> 00:41:46,330
threshold stuff is up to team's sales so

00:41:42,610 --> 00:41:48,700
you pre-select through categories yeah

00:41:46,330 --> 00:41:50,680
basically you can just search and look

00:41:48,700 --> 00:42:04,090
at what people are doing here okay fine

00:41:50,680 --> 00:42:07,210
thank you okay where do you do the the

00:42:04,090 --> 00:42:10,119
threat of the check for threshold if

00:42:07,210 --> 00:42:13,180
there's a threat odds are matched or not

00:42:10,119 --> 00:42:17,230
in the times Reese database to you to do

00:42:13,180 --> 00:42:20,830
a query and then then check it or yes so

00:42:17,230 --> 00:42:22,570
basically um there is you saw the Python

00:42:20,830 --> 00:42:25,119
code and the Python code we basically

00:42:22,570 --> 00:42:27,430
have a lot of functions prepared for

00:42:25,119 --> 00:42:30,100
either be at posterous or there's the

00:42:27,430 --> 00:42:32,800
same basically prepared code for

00:42:30,100 --> 00:42:34,330
accessing the the kairos DB so you can

00:42:32,800 --> 00:42:36,070
then basically within a check or an

00:42:34,330 --> 00:42:38,290
alert basically use something called

00:42:36,070 --> 00:42:40,210
history wrapper and then you write

00:42:38,290 --> 00:42:42,850
history and then there is a it

00:42:40,210 --> 00:42:44,680
automatically understands on which hosts

00:42:42,850 --> 00:42:47,320
it's running so it will automatically

00:42:44,680 --> 00:42:49,240
carry the curve for this host but you

00:42:47,320 --> 00:42:51,640
can basically constrain it in any way

00:42:49,240 --> 00:42:54,130
you want and then you basically get the

00:42:51,640 --> 00:42:55,570
time series data back in your alert or

00:42:54,130 --> 00:42:58,240
check context and then you do it

00:42:55,570 --> 00:43:01,300
yourself so when you look at for example

00:42:58,240 --> 00:43:03,430
the the order week on week a lot

00:43:01,300 --> 00:43:06,280
in the check there's three different

00:43:03,430 --> 00:43:09,540
queries to going back seven 14 and 21

00:43:06,280 --> 00:43:13,750
days and time getting the value and then

00:43:09,540 --> 00:43:15,370
computing on this but this is not we

00:43:13,750 --> 00:43:17,230
provide kind of the framework of

00:43:15,370 --> 00:43:20,290
functions that can be executed be it

00:43:17,230 --> 00:43:22,570
from like you saw HTTP to SQL and all

00:43:20,290 --> 00:43:24,760
the other systems plus some core

00:43:22,570 --> 00:43:36,870
functionality to talk to the data we

00:43:24,760 --> 00:43:36,870
have in place okay thank you very much

00:43:37,700 --> 00:43:45,469

YouTube URL: https://www.youtube.com/watch?v=NJ4auXwCXjY


