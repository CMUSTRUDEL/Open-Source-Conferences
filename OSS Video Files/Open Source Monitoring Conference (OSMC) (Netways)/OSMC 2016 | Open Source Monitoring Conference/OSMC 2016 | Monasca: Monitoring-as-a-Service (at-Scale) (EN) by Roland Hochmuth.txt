Title: OSMC 2016 | Monasca: Monitoring-as-a-Service (at-Scale) (EN) by Roland Hochmuth
Publication date: 2016-12-12
Playlist: OSMC 2016 | Open Source Monitoring Conference
Description: 
	Monasca, http://monasca.io/ ist eine Turn-Key Open Source OpenStack Monitoring-as-a-Service Plattform, die Authentifizierung und multi-Tenancy mittels OpenStack Keystone Identity Service unterstützt. Monasca ist eine hoch skalierbare, leistungsfähige und Fehler-tolerante Monitoring-as-a-Service Lösung, die Push-based Streaming-Metrics, Gesundheit/Status, Alarmierung/Thresholding und Benachrichtigungen unterstützt. Logging-as-a-Service befindet sich in der Entwicklung, und das Ziel ist es eine umfassende und integrierte Monitoring Lösung für Open Stack Clouds zur Verfügung zu stellen, die auch Kennzahlen, Events und Logs unterstützt.
Captions: 
	00:00:09,519 --> 00:00:16,990
yeah good good morning and welcome to

00:00:13,929 --> 00:00:20,439
the second day although use em Oh smc

00:00:16,990 --> 00:00:29,079
sorry and we have slept more than three

00:00:20,439 --> 00:00:34,090
hours one row okay okay let's start with

00:00:29,079 --> 00:00:38,200
Roland from Colorado and the talk about

00:00:34,090 --> 00:00:41,230
Mona's car and it's an OpenStack as a

00:00:38,200 --> 00:00:45,220
service monitoring thing Thank You Liz

00:00:41,230 --> 00:00:48,550
go ahead ok so title of talk is minh

00:00:45,220 --> 00:00:53,579
askah monitoring and logging i added

00:00:48,550 --> 00:00:58,530
that logging part as a service at scale

00:00:53,579 --> 00:01:01,300
so I'm Roland Hawk liffe and despite my

00:00:58,530 --> 00:01:04,110
German sounding name I am NOT from

00:01:01,300 --> 00:01:06,759
Germany I'm from Fort Collins Colorado

00:01:04,110 --> 00:01:10,240
so it's a pleasure to be here I thank

00:01:06,759 --> 00:01:13,810
the organizers for inviting me to

00:01:10,240 --> 00:01:16,149
present here and it's been a great

00:01:13,810 --> 00:01:20,619
experience so far very nice conference

00:01:16,149 --> 00:01:26,350
oh and i work for Hewlett Packard

00:01:20,619 --> 00:01:27,969
Enterprise I tend to be fine kind of

00:01:26,350 --> 00:01:30,670
wordy on my slides because if I don't

00:01:27,969 --> 00:01:32,279
put it on the slides I'll forget it but

00:01:30,670 --> 00:01:36,090
I'll try and touch on the main points as

00:01:32,279 --> 00:01:38,499
well but my agenda today is to describe

00:01:36,090 --> 00:01:40,450
more or less how to build a highly

00:01:38,499 --> 00:01:43,119
scalable monitoring and logging as a

00:01:40,450 --> 00:01:44,499
service platform and so I'll kind of go

00:01:43,119 --> 00:01:47,409
over some of the architectural and

00:01:44,499 --> 00:01:50,109
design principles that we used in the

00:01:47,409 --> 00:01:53,109
Nazca i'll talk about scale and high

00:01:50,109 --> 00:01:54,880
availability I'll also talk about the

00:01:53,109 --> 00:01:57,909
Manassa serve itself and try to provide

00:01:54,880 --> 00:02:00,939
an overview of that and cover the

00:01:57,909 --> 00:02:03,249
features the API and time permitting

00:02:00,939 --> 00:02:05,349
we'll do a demo I have a lot of slides

00:02:03,249 --> 00:02:08,280
to go through but I do have a little

00:02:05,349 --> 00:02:11,590
demo at the end if we we make it there

00:02:08,280 --> 00:02:12,340
ok so first principles I just want to

00:02:11,590 --> 00:02:15,150
make sure that we're all in the same

00:02:12,340 --> 00:02:19,600
page with some definitions what is

00:02:15,150 --> 00:02:22,390
monitoring as a service so that's the as

00:02:19,600 --> 00:02:22,900
a service part that's the the new part

00:02:22,390 --> 00:02:26,010
there

00:02:22,900 --> 00:02:29,319
and a lot of people are familiar with

00:02:26,010 --> 00:02:33,220
services like Amazon Cloud watch data

00:02:29,319 --> 00:02:35,019
dog New Relic librado and la Gliese one

00:02:33,220 --> 00:02:37,629
that does logging and there's many

00:02:35,019 --> 00:02:40,680
others so it's typically a monitoring or

00:02:37,629 --> 00:02:42,879
logging solution that's deployed as

00:02:40,680 --> 00:02:45,609
software-as-a-service it's usually run

00:02:42,879 --> 00:02:49,840
by run and hosted by a web services

00:02:45,609 --> 00:02:53,709
company it has a first-class preferably

00:02:49,840 --> 00:02:56,620
restful HTTP API it supports

00:02:53,709 --> 00:02:58,780
authentication multi-tenancy and

00:02:56,620 --> 00:03:01,269
multi-tenancy means that I can take my

00:02:58,780 --> 00:03:03,420
data and I can have users come in into

00:03:01,269 --> 00:03:06,459
this service and all their data is

00:03:03,420 --> 00:03:10,209
stored under their account or their

00:03:06,459 --> 00:03:12,549
tenant it can provide self-provisioning

00:03:10,209 --> 00:03:15,340
to users and tenants of the servers

00:03:12,549 --> 00:03:16,780
meaning that the user or the operations

00:03:15,340 --> 00:03:20,079
group doesn't have to deploy it

00:03:16,780 --> 00:03:23,769
themselves it's typically designed to be

00:03:20,079 --> 00:03:27,069
highly reliable and operate at scale or

00:03:23,769 --> 00:03:30,280
massive scale and it's typically run by

00:03:27,069 --> 00:03:32,949
an operations team doing full-out web

00:03:30,280 --> 00:03:36,180
services so highly specialized team is

00:03:32,949 --> 00:03:40,540
usually running this sort of software

00:03:36,180 --> 00:03:46,180
okay so who's familiar with OpenStack in

00:03:40,540 --> 00:03:48,010
the room okay oh not quite half okay so

00:03:46,180 --> 00:03:50,739
what is I'll cover this what is

00:03:48,010 --> 00:03:52,780
OpenStack so OpenStack is a cloud

00:03:50,739 --> 00:03:54,699
operating system that controls large

00:03:52,780 --> 00:03:57,760
pools of compute stored and networking

00:03:54,699 --> 00:04:00,549
resources the a better way to probably

00:03:57,760 --> 00:04:03,540
think about it which is not a definition

00:04:00,549 --> 00:04:06,579
but it's an open-source alternative to

00:04:03,540 --> 00:04:10,180
amazon web services microsoft azor

00:04:06,579 --> 00:04:14,260
google cloud and other options that are

00:04:10,180 --> 00:04:18,549
available it can be deployed in both

00:04:14,260 --> 00:04:20,859
public and or private clouds so a lot of

00:04:18,549 --> 00:04:23,139
OpenStack momentum these days is in the

00:04:20,859 --> 00:04:25,479
private cloud where you see a lot of

00:04:23,139 --> 00:04:29,110
enterprises deploying it or even web

00:04:25,479 --> 00:04:32,590
services company using it internally but

00:04:29,110 --> 00:04:35,510
there are public cloud deployments of

00:04:32,590 --> 00:04:39,970
OpenStack as well that are out there

00:04:35,510 --> 00:04:43,640
okay so what is Nazca and all this so

00:04:39,970 --> 00:04:45,890
menaka is an open source monitoring and

00:04:43,640 --> 00:04:48,860
logging as a service platform for

00:04:45,890 --> 00:04:52,460
OpenStack it's the official monitoring

00:04:48,860 --> 00:04:55,600
as a service project for OpenStack so we

00:04:52,460 --> 00:04:59,120
are governed under the OpenStack

00:04:55,600 --> 00:05:03,590
governance as part of it what they call

00:04:59,120 --> 00:05:07,070
the big tent in terms of dependencies on

00:05:03,590 --> 00:05:09,260
OpenStack there's not a huge number the

00:05:07,070 --> 00:05:11,420
one that is kind of a dependency today

00:05:09,260 --> 00:05:14,360
although it's a loosely defined

00:05:11,420 --> 00:05:17,480
dependency is on their identity service

00:05:14,360 --> 00:05:20,450
which is called Keystone and so Keystone

00:05:17,480 --> 00:05:24,260
does our authentication and we submit

00:05:20,450 --> 00:05:29,390
auth tokens to Keystone and assuming

00:05:24,260 --> 00:05:31,700
it's validated then we allow the the

00:05:29,390 --> 00:05:34,370
HTTP requests that are coming into our

00:05:31,700 --> 00:05:37,010
API to be handled and processed further

00:05:34,370 --> 00:05:41,390
okay so i won't be covering a lot of

00:05:37,010 --> 00:05:42,560
Keystone today that's almost it but that

00:05:41,390 --> 00:05:45,230
probably mentioned a couple of other

00:05:42,560 --> 00:05:48,440
times okay so we are in microservices

00:05:45,230 --> 00:05:50,210
message bust a architecture I'll have

00:05:48,440 --> 00:05:54,250
some slides later that will talk about

00:05:50,210 --> 00:05:57,710
that we're first class restful api

00:05:54,250 --> 00:06:00,620
meaning that the api wasn't added after

00:05:57,710 --> 00:06:03,970
the fact and it was built in designed in

00:06:00,620 --> 00:06:05,020
from the start around the api and

00:06:03,970 --> 00:06:09,190
[Music]

00:06:05,020 --> 00:06:14,180
everything that we do within monoski

00:06:09,190 --> 00:06:17,840
occurs via the API we're primarily a

00:06:14,180 --> 00:06:19,490
push-based metrics you in the world of

00:06:17,840 --> 00:06:22,220
metrics there's you know there's the two

00:06:19,490 --> 00:06:26,330
religions there's the push-based pulvis

00:06:22,220 --> 00:06:30,260
who's a pusher who's a puller there's

00:06:26,330 --> 00:06:33,050
two pullers know pushers okay raise your

00:06:30,260 --> 00:06:35,750
hand quick all right so I'm gonna ask

00:06:33,050 --> 00:06:39,490
was pushed based and for those familiar

00:06:35,750 --> 00:06:42,640
with prometheus prometheus is pull based

00:06:39,490 --> 00:06:45,140
one thing that we've been focusing on is

00:06:42,640 --> 00:06:47,660
consolidating both your operational

00:06:45,140 --> 00:06:48,650
monitoring and monitoring as a service

00:06:47,660 --> 00:06:52,669
and metering and bill

00:06:48,650 --> 00:06:55,880
and other solutions I used to work on

00:06:52,669 --> 00:06:57,560
HP's public cloud when we had one did

00:06:55,880 --> 00:06:59,690
have obstinately I worked on their

00:06:57,560 --> 00:07:05,000
monitoring systems and then asked is

00:06:59,690 --> 00:07:07,160
largely a outcome of that development we

00:07:05,000 --> 00:07:09,259
more or less when we did our public

00:07:07,160 --> 00:07:12,259
cloud we had three monitoring systems we

00:07:09,259 --> 00:07:15,220
had a fairly large team ground I say 14

00:07:12,259 --> 00:07:18,199
15 people doing all this and we had

00:07:15,220 --> 00:07:20,360
three monitoring systems we had our

00:07:18,199 --> 00:07:23,440
monitoring as a service we had an

00:07:20,360 --> 00:07:26,120
internal metrics processing system and

00:07:23,440 --> 00:07:28,190
which which I was responsible mainly for

00:07:26,120 --> 00:07:31,639
that one and then we had nagios and

00:07:28,190 --> 00:07:34,460
after we got done deploying all that we

00:07:31,639 --> 00:07:37,699
weren't very happy because we had three

00:07:34,460 --> 00:07:39,229
sub teams no sub team knew about a whole

00:07:37,699 --> 00:07:42,470
lot we knew about it but we didn't know

00:07:39,229 --> 00:07:45,440
how to really operate the other teams

00:07:42,470 --> 00:07:47,330
infrastructure that created a lot of

00:07:45,440 --> 00:07:50,990
problems we were all on call all the

00:07:47,330 --> 00:07:53,300
time pretty much even though we had a

00:07:50,990 --> 00:07:55,099
very large team and it was very

00:07:53,300 --> 00:07:57,949
complicated and we wanted to simplify

00:07:55,099 --> 00:08:00,880
that so manaslu is around consolidating

00:07:57,949 --> 00:08:03,650
meaning instead of running multiple

00:08:00,880 --> 00:08:07,340
monitoring systems to handle all these

00:08:03,650 --> 00:08:10,729
different use cases we wanted to deploy

00:08:07,340 --> 00:08:12,889
a single system to handle them all and

00:08:10,729 --> 00:08:16,340
we think we've been largely successful

00:08:12,889 --> 00:08:19,340
at doing that it's designed for elastic

00:08:16,340 --> 00:08:23,000
cloud environments and deployments so

00:08:19,340 --> 00:08:25,909
elasticity means that these environments

00:08:23,000 --> 00:08:28,880
can change over time new services new

00:08:25,909 --> 00:08:33,950
nodes are added they're removed and so

00:08:28,880 --> 00:08:35,779
manasa is designed around that high

00:08:33,950 --> 00:08:38,089
availability and clustering has been

00:08:35,779 --> 00:08:40,580
built in it's a horizontally scalable

00:08:38,089 --> 00:08:42,890
and vertically tiered layered

00:08:40,580 --> 00:08:46,600
architecture I'll show that a little bit

00:08:42,890 --> 00:08:50,270
later and it's capable of long-term data

00:08:46,600 --> 00:08:54,380
data retention it meaning that we don't

00:08:50,270 --> 00:08:57,079
just focus on the data that is a day old

00:08:54,380 --> 00:09:01,130
or a few days old we're designed to

00:08:57,079 --> 00:09:02,100
handle and store your data for in our

00:09:01,130 --> 00:09:05,100
case

00:09:02,100 --> 00:09:08,550
13 months or beyond if you need to and

00:09:05,100 --> 00:09:10,290
that's really important maybe if you're

00:09:08,550 --> 00:09:11,790
a pure operator and you're just trying

00:09:10,290 --> 00:09:13,860
to keep services up it's really not

00:09:11,790 --> 00:09:16,730
important to you but if you're operating

00:09:13,860 --> 00:09:19,970
a cloud or you're operating a service

00:09:16,730 --> 00:09:22,440
you have things like SLA metrics or

00:09:19,970 --> 00:09:24,690
capacity planning and trend analysis

00:09:22,440 --> 00:09:29,310
metrics or we might need to go back and

00:09:24,690 --> 00:09:31,980
do post hoc root cause analysis or if

00:09:29,310 --> 00:09:33,990
your data scientists you might need to

00:09:31,980 --> 00:09:36,120
go back in time and look at things and

00:09:33,990 --> 00:09:37,769
do all sorts of analysis on it so

00:09:36,120 --> 00:09:42,089
there's lots of other cases where data

00:09:37,769 --> 00:09:44,130
retention is important okay and then

00:09:42,089 --> 00:09:48,569
finally our system is designed to be

00:09:44,130 --> 00:09:50,250
extensible and composable and just a

00:09:48,569 --> 00:09:51,660
couple words on extensibility bikes

00:09:50,250 --> 00:09:54,360
there's there's lots of ways to extend

00:09:51,660 --> 00:09:57,209
systems but I mean extend it not only

00:09:54,360 --> 00:10:01,230
from external components but extend it

00:09:57,209 --> 00:10:05,910
internally and composable meaning i can

00:10:01,230 --> 00:10:07,769
combine things together and you know i

00:10:05,910 --> 00:10:10,319
can combine loosely coupled systems

00:10:07,769 --> 00:10:12,810
together and compose them and create

00:10:10,319 --> 00:10:16,230
some additional use cases that or

00:10:12,810 --> 00:10:18,389
satisfy additional use cases so before I

00:10:16,230 --> 00:10:20,730
get into my architecture pitch because

00:10:18,389 --> 00:10:22,050
I'm trying to cater this talk to not

00:10:20,730 --> 00:10:23,490
just people that want to know what

00:10:22,050 --> 00:10:25,069
features our mask of the people that

00:10:23,490 --> 00:10:27,930
might want to know about large-scale

00:10:25,069 --> 00:10:31,230
services I got a few things to cover

00:10:27,930 --> 00:10:34,980
here one is called the log and the log

00:10:31,230 --> 00:10:38,339
was a famous blog written by Jake reps

00:10:34,980 --> 00:10:40,949
from LinkedIn Jake reps is the crater of

00:10:38,339 --> 00:10:43,980
several very important pieces of

00:10:40,949 --> 00:10:45,949
software in the Big Data community and

00:10:43,980 --> 00:10:51,240
one that he created was called Apache

00:10:45,949 --> 00:10:52,529
Kafka so there's a link there what every

00:10:51,240 --> 00:10:55,290
software engineer should know about

00:10:52,529 --> 00:10:56,880
real-time data is unifying abstract I

00:10:55,290 --> 00:10:58,949
really encourage people that aren't

00:10:56,880 --> 00:11:00,899
familiar with that to check that link

00:10:58,949 --> 00:11:02,670
out Jake reps has written a book you can

00:11:00,899 --> 00:11:05,370
go read that book now as well it's a

00:11:02,670 --> 00:11:09,000
fairly short or Riley series book I

00:11:05,370 --> 00:11:10,970
don't know like 150 pages or so I could

00:11:09,000 --> 00:11:13,380
probably read it in a couple of hours

00:11:10,970 --> 00:11:15,540
but encourage people get familiar with

00:11:13,380 --> 00:11:16,019
that but there's a couple things I want

00:11:15,540 --> 00:11:18,600
you to

00:11:16,019 --> 00:11:21,119
take away from this slide one is what is

00:11:18,600 --> 00:11:23,970
a log I'm not talking about your logging

00:11:21,119 --> 00:11:27,239
data I'm talking about something called

00:11:23,970 --> 00:11:30,600
a log which is an append only totally

00:11:27,239 --> 00:11:33,989
ordered sequence of Records ordered by

00:11:30,600 --> 00:11:38,119
time okay so that's what a log is and in

00:11:33,989 --> 00:11:42,619
the context of Kafka it's a distributed

00:11:38,119 --> 00:11:48,209
highly available durable performant log

00:11:42,619 --> 00:11:50,040
and that's used within menaka and I'll

00:11:48,209 --> 00:11:51,749
cover that the other thing here is in

00:11:50,040 --> 00:11:55,319
the bottom on the left and on the right

00:11:51,749 --> 00:11:57,329
I got two pictures and it linked in when

00:11:55,319 --> 00:11:59,639
they were first starting out their

00:11:57,329 --> 00:12:03,149
infrastructure was looking like that

00:11:59,639 --> 00:12:06,029
where we basically had a connection from

00:12:03,149 --> 00:12:08,100
every service to every other service in

00:12:06,029 --> 00:12:10,319
it and they found out that that was

00:12:08,100 --> 00:12:12,929
really the bottleneck in their system

00:12:10,319 --> 00:12:14,850
not just the performance bottleneck but

00:12:12,929 --> 00:12:19,079
a bottleneck in terms of getting things

00:12:14,850 --> 00:12:22,079
done in terms of being productive so

00:12:19,079 --> 00:12:24,809
when they created so patchy Kafka was

00:12:22,079 --> 00:12:27,389
largely created out of that and they

00:12:24,809 --> 00:12:29,459
went from that picture on the left to

00:12:27,389 --> 00:12:33,119
this picture on the right and so they

00:12:29,459 --> 00:12:37,369
use apache Kafka for storing all of

00:12:33,119 --> 00:12:40,019
their messages and so you've got

00:12:37,369 --> 00:12:42,449
publishers of messages publishing into

00:12:40,019 --> 00:12:44,249
the log and these publishers don't know

00:12:42,449 --> 00:12:46,949
anything about the consumer so this is

00:12:44,249 --> 00:12:50,399
your typical message queuing type

00:12:46,949 --> 00:12:52,769
architecture only in this system this is

00:12:50,399 --> 00:12:55,139
designed to handle millions of messages

00:12:52,769 --> 00:12:58,069
a second and billions and messages a day

00:12:55,139 --> 00:13:01,169
you can only imagine what LinkedIn's

00:12:58,069 --> 00:13:05,970
infrastructure is has to be designed to

00:13:01,169 --> 00:13:08,309
handle in terms of messages so so that's

00:13:05,970 --> 00:13:09,839
a very key concept and that served

00:13:08,309 --> 00:13:12,049
reason why I put it up there is to serve

00:13:09,839 --> 00:13:16,290
to some of the inspiration behind

00:13:12,049 --> 00:13:17,999
monoski okay we finally made it and I'll

00:13:16,290 --> 00:13:19,499
have a few other architectural slides

00:13:17,999 --> 00:13:24,600
like that later on but we finally made

00:13:19,499 --> 00:13:28,240
it to what is our architecture okay and

00:13:24,600 --> 00:13:30,490
let me just check my time

00:13:28,240 --> 00:13:35,860
all right 40 okay no there's a good

00:13:30,490 --> 00:13:37,240
clock of that great okay so I reason why

00:13:35,860 --> 00:13:39,459
I check the time as I can sometimes

00:13:37,240 --> 00:13:41,920
spend a half hour on this one slide and

00:13:39,459 --> 00:13:44,290
put everybody asleep I don't want to do

00:13:41,920 --> 00:13:47,529
that today and I got a lot of other

00:13:44,290 --> 00:13:50,620
slides to get through so all right so

00:13:47,529 --> 00:13:54,279
this long horizontal line here the

00:13:50,620 --> 00:13:56,890
Manassa API that's basically our primary

00:13:54,279 --> 00:13:59,680
ingestion point we have an optional

00:13:56,890 --> 00:14:01,779
agent up in the upper right there by

00:13:59,680 --> 00:14:03,610
optional I mean as part of the vanassa

00:14:01,779 --> 00:14:08,260
project we have our own age and it's

00:14:03,610 --> 00:14:11,770
written in Python and but but you could

00:14:08,260 --> 00:14:13,720
use anything is just an HTTP endpoint so

00:14:11,770 --> 00:14:16,149
so we have a well-defined api

00:14:13,720 --> 00:14:19,209
specification that's out there anybody

00:14:16,149 --> 00:14:23,350
in the world can code to that ok so this

00:14:19,209 --> 00:14:25,870
agent post metrics to our API not shown

00:14:23,350 --> 00:14:29,200
in this diagram is that the agent gets a

00:14:25,870 --> 00:14:32,140
auth token from Keystone so when

00:14:29,200 --> 00:14:35,950
submitting those metrics to the API it

00:14:32,140 --> 00:14:38,380
has an auth token and our API it

00:14:35,950 --> 00:14:41,920
validates all the incoming requests and

00:14:38,380 --> 00:14:46,270
the next thing it does is it publishes

00:14:41,920 --> 00:14:50,410
to Kafka which is our center box there

00:14:46,270 --> 00:14:53,050
and so you got this metrics message or

00:14:50,410 --> 00:14:56,170
messages sitting on this metrics topic

00:14:53,050 --> 00:15:00,490
now we don't have too many consumers

00:14:56,170 --> 00:15:03,550
here and picture hi some diagrams later

00:15:00,490 --> 00:15:07,540
we a lot more consumers but basically

00:15:03,550 --> 00:15:10,360
that's the end of the pipeline for the

00:15:07,540 --> 00:15:12,399
API at that point and so we've got our

00:15:10,360 --> 00:15:15,610
messages they're stored in this thing

00:15:12,399 --> 00:15:17,770
called Apache Kafka they it's a durable

00:15:15,610 --> 00:15:22,209
message queue it's performance it's

00:15:17,770 --> 00:15:24,520
scalable it's distributed so a bit so

00:15:22,209 --> 00:15:28,120
we've got your data ok so then we've got

00:15:24,520 --> 00:15:30,820
components here this persister 10 and

00:15:28,120 --> 00:15:34,410
when I draw these boxes here I've tried

00:15:30,820 --> 00:15:37,120
to show that these systems are running

00:15:34,410 --> 00:15:39,400
clustered or replicated within the

00:15:37,120 --> 00:15:41,649
infrastructure so that's not just a

00:15:39,400 --> 00:15:43,869
single

00:15:41,649 --> 00:15:45,850
component that's running our usual

00:15:43,869 --> 00:15:48,819
deployments that we kind of focus on is

00:15:45,850 --> 00:15:51,910
usually on three physical compute three

00:15:48,819 --> 00:15:54,160
physical nodes or servers and that's why

00:15:51,910 --> 00:15:57,639
I've got three boxes but it could be way

00:15:54,160 --> 00:15:59,410
more than three and we've been looking a

00:15:57,639 --> 00:16:01,899
lot at containerization lately and

00:15:59,410 --> 00:16:06,459
looking at scaling out the number of

00:16:01,899 --> 00:16:09,850
containers that we're running but so all

00:16:06,459 --> 00:16:11,889
these services are running at least in

00:16:09,850 --> 00:16:16,899
this diagram kind of shown in three

00:16:11,889 --> 00:16:19,209
physical computers okay so getting back

00:16:16,899 --> 00:16:22,540
to the data flow here so our messages

00:16:19,209 --> 00:16:25,449
come into Kafka are persisters consume

00:16:22,540 --> 00:16:29,230
those messages and they buffer them in

00:16:25,449 --> 00:16:33,220
memory for a short period of time or the

00:16:29,230 --> 00:16:36,399
size of the batch and then periodically

00:16:33,220 --> 00:16:39,369
they send them to our time series

00:16:36,399 --> 00:16:40,689
database our time series database we

00:16:39,369 --> 00:16:43,119
don't we don't create our own time

00:16:40,689 --> 00:16:44,199
series databases on our project I would

00:16:43,119 --> 00:16:47,319
have loved to have done that and

00:16:44,199 --> 00:16:49,449
sometimes I think I should have but our

00:16:47,319 --> 00:16:52,319
two officially supported time series

00:16:49,449 --> 00:16:54,399
databases today are in flux TV and

00:16:52,319 --> 00:16:55,959
vertica I'll go a little bit more to

00:16:54,399 --> 00:16:59,470
those later on and those are fully

00:16:55,959 --> 00:17:01,449
clustered databases okay so now our data

00:16:59,470 --> 00:17:03,370
stored now we have this component here

00:17:01,449 --> 00:17:06,669
called the threshold engine the

00:17:03,370 --> 00:17:08,289
threshold engine and this is a micro

00:17:06,669 --> 00:17:10,449
services based architecture of our

00:17:08,289 --> 00:17:12,610
threshold engine is another component or

00:17:10,449 --> 00:17:14,230
micro service in this architecture our

00:17:12,610 --> 00:17:19,779
threshold engines job is consumed

00:17:14,230 --> 00:17:21,640
metrics evaluate whether those values

00:17:19,779 --> 00:17:24,309
that we're receiving exceed some

00:17:21,640 --> 00:17:27,730
threshold and if they do publish a

00:17:24,309 --> 00:17:30,520
message back to Kafka so it publishes it

00:17:27,730 --> 00:17:35,799
publishes alarm state transition events

00:17:30,520 --> 00:17:39,039
back to Kafka on another topic okay then

00:17:35,799 --> 00:17:42,820
our notification engine over here bottom

00:17:39,039 --> 00:17:45,700
left consumes the alarm state transition

00:17:42,820 --> 00:17:48,370
events looks at them and says should I

00:17:45,700 --> 00:17:50,110
send a notification like an email or

00:17:48,370 --> 00:17:53,440
should I create a page or duty incident

00:17:50,110 --> 00:17:55,330
should I send it HipChat or slathered

00:17:53,440 --> 00:17:58,300
there's a hora web hook

00:17:55,330 --> 00:18:00,400
orgy or ticket and we're adding more and

00:17:58,300 --> 00:18:03,040
that anyway so that's what the

00:18:00,400 --> 00:18:05,770
notifications engine job is to create

00:18:03,040 --> 00:18:08,890
notifications from alarm state

00:18:05,770 --> 00:18:13,330
transition events additionally the

00:18:08,890 --> 00:18:15,430
persister also consumes those alarm

00:18:13,330 --> 00:18:18,430
state transition events and stores them

00:18:15,430 --> 00:18:21,160
into our time series database so we have

00:18:18,430 --> 00:18:24,250
a complete history of all the

00:18:21,160 --> 00:18:27,100
transitions in our alarms and I didn't

00:18:24,250 --> 00:18:31,840
mention this but alarms are the stateful

00:18:27,100 --> 00:18:34,720
resources in menasha okay bottom left

00:18:31,840 --> 00:18:36,160
our config database that has the

00:18:34,720 --> 00:18:38,470
information about all the alarm

00:18:36,160 --> 00:18:40,960
definitions and alarms notification

00:18:38,470 --> 00:18:44,260
methods it has the state of all the

00:18:40,960 --> 00:18:47,620
alarms in there why are there two

00:18:44,260 --> 00:18:50,680
databases in our system some people ask

00:18:47,620 --> 00:18:52,150
that question and so I'll answer before

00:18:50,680 --> 00:18:54,100
the questions asked because some

00:18:52,150 --> 00:18:56,380
databases are really good at storing

00:18:54,100 --> 00:18:59,800
time series data and doing analytics and

00:18:56,380 --> 00:19:01,780
other databases are good at more like

00:18:59,800 --> 00:19:04,360
transactional type stuff or storing

00:19:01,780 --> 00:19:06,730
records and updating records analytics

00:19:04,360 --> 00:19:09,790
databases are typically very very bad at

00:19:06,730 --> 00:19:12,220
updates or deletes data and so if you

00:19:09,790 --> 00:19:13,840
have a record like an alarm that needs

00:19:12,220 --> 00:19:16,390
to be updated you can't store that in

00:19:13,840 --> 00:19:19,210
your time series data base but my sequel

00:19:16,390 --> 00:19:24,370
postgres those are really good at that

00:19:19,210 --> 00:19:26,260
more transactional type stuff okay we

00:19:24,370 --> 00:19:28,450
have a couple of ways of doing

00:19:26,260 --> 00:19:30,220
visualization there's an OpenStack

00:19:28,450 --> 00:19:32,260
there's something called horizon horizon

00:19:30,220 --> 00:19:36,930
which I'll show you later in the demo is

00:19:32,260 --> 00:19:39,160
the dashboard that's used for

00:19:36,930 --> 00:19:41,770
interacting with all of OpenStack and we

00:19:39,160 --> 00:19:46,000
have our own monitoring or monoski panel

00:19:41,770 --> 00:19:50,140
that plugs into that and then we also

00:19:46,000 --> 00:19:52,630
support growth fauna so we have a manasa

00:19:50,140 --> 00:19:54,850
data source that was developed for

00:19:52,630 --> 00:20:00,490
Bafana so that allows you to visualize

00:19:54,850 --> 00:20:03,970
all the metrics okay a couple other

00:20:00,490 --> 00:20:06,670
things on this slide so for querying

00:20:03,970 --> 00:20:09,220
data out of the system that all goes

00:20:06,670 --> 00:20:11,350
through our API and

00:20:09,220 --> 00:20:14,110
upper left shows you can query metrics

00:20:11,350 --> 00:20:16,710
alarm definitions alarms notification

00:20:14,110 --> 00:20:19,690
that it's everything else from the API

00:20:16,710 --> 00:20:24,130
okay I've got a couple points later on

00:20:19,690 --> 00:20:25,840
this topic too ok so Kafka highly

00:20:24,130 --> 00:20:27,520
performant distributed durable

00:20:25,840 --> 00:20:29,140
publish-subscribe message and stream

00:20:27,520 --> 00:20:32,620
processing system if you're not familiar

00:20:29,140 --> 00:20:34,780
that there's some very good articles I

00:20:32,620 --> 00:20:38,530
didn't put a link for that here but to

00:20:34,780 --> 00:20:42,070
check that out so metrics logs and other

00:20:38,530 --> 00:20:45,210
events so all the domain events for our

00:20:42,070 --> 00:20:49,150
system are published two topics in Kafka

00:20:45,210 --> 00:20:51,429
microservices register in a consumer

00:20:49,150 --> 00:20:57,070
group consumer group is a concept in

00:20:51,429 --> 00:20:59,679
Kafka as a consumer and microservices

00:20:57,070 --> 00:21:02,200
subscribe to topics and consume metrics

00:20:59,679 --> 00:21:05,890
logs and events met messages are

00:21:02,200 --> 00:21:09,610
replicated / consumer group so in that

00:21:05,890 --> 00:21:11,950
in this diagram previously if you had

00:21:09,610 --> 00:21:15,460
three persisters you put usually would

00:21:11,950 --> 00:21:21,789
have a persister consumer group the

00:21:15,460 --> 00:21:25,690
messages are distributed across the

00:21:21,789 --> 00:21:32,110
persisters in there based on the key

00:21:25,690 --> 00:21:34,750
that is supplied we we use time as our

00:21:32,110 --> 00:21:37,809
key so it's fairly uniformly distributed

00:21:34,750 --> 00:21:40,299
across all resistors based on time at

00:21:37,809 --> 00:21:43,270
other points in the system we can group

00:21:40,299 --> 00:21:46,000
on other keys like something else so you

00:21:43,270 --> 00:21:48,850
might be wanting to groupon like a

00:21:46,000 --> 00:21:50,919
service name or something okay so

00:21:48,850 --> 00:21:52,720
messages are replicated messages are

00:21:50,919 --> 00:21:54,159
load balance that's really important in

00:21:52,720 --> 00:21:58,289
all this so if you're looking at

00:21:54,159 --> 00:22:01,750
designing a system to balance your load

00:21:58,289 --> 00:22:09,100
Kafka's a nice point in the system do

00:22:01,750 --> 00:22:13,260
that and as micro services are added or

00:22:09,100 --> 00:22:15,820
let's just say they die off Kafka will

00:22:13,260 --> 00:22:18,100
basically and I didn't mention this

00:22:15,820 --> 00:22:20,679
concept on this slide and I want to go

00:22:18,100 --> 00:22:22,870
into all the details of Kafka but

00:22:20,679 --> 00:22:26,010
they're 44

00:22:22,870 --> 00:22:27,850
or a topic you're going to have these

00:22:26,010 --> 00:22:30,730
topics going to be divided up into

00:22:27,850 --> 00:22:34,150
partitions and if you add or remove

00:22:30,730 --> 00:22:36,270
these microservices from groups they're

00:22:34,150 --> 00:22:42,370
going to redistribute those partitions

00:22:36,270 --> 00:22:47,830
across microservices okay so basically

00:22:42,370 --> 00:22:50,410
you've got on a true elasticity ok so we

00:22:47,830 --> 00:22:52,570
guarantee at least once semantics

00:22:50,410 --> 00:22:55,600
guarantees on message delivery so when

00:22:52,570 --> 00:22:58,870
you send a metric or log messages to our

00:22:55,600 --> 00:23:00,429
system as long as it makes it to Kafka

00:22:58,870 --> 00:23:02,650
and if it doesn't make the kafka we tell

00:23:00,429 --> 00:23:04,179
you that so you get an HTTP error in

00:23:02,650 --> 00:23:07,120
that case but as long as it makes it a

00:23:04,179 --> 00:23:11,710
Kafka and like the data center doesn't

00:23:07,120 --> 00:23:13,960
burn down instantaneously then your data

00:23:11,710 --> 00:23:16,179
is guaranteed to make it into our

00:23:13,960 --> 00:23:19,720
database and to the threshold engine and

00:23:16,179 --> 00:23:22,540
everywhere else it needs to go kind of

00:23:19,720 --> 00:23:24,540
interestingly we also use Kafka for

00:23:22,540 --> 00:23:26,790
storm

00:23:24,540 --> 00:23:30,270
our domain events the main events are

00:23:26,790 --> 00:23:34,440
things like when alarm definition is

00:23:30,270 --> 00:23:36,330
created we use it or delete it or when a

00:23:34,440 --> 00:23:39,900
notification method is created those

00:23:36,330 --> 00:23:42,450
things so so Kafka is not only used for

00:23:39,900 --> 00:23:44,640
all this hi streaming data content in

00:23:42,450 --> 00:23:48,320
our system we use it for it's become

00:23:44,640 --> 00:23:50,460
internalized into our application as

00:23:48,320 --> 00:23:52,980
domain events and domain events that

00:23:50,460 --> 00:23:56,990
comes from domain driven design by eric

00:23:52,980 --> 00:24:01,640
evans and so if you familiar with that

00:23:56,990 --> 00:24:06,180
that's what I'm referring to there's a

00:24:01,640 --> 00:24:07,560
great YouTube video by la Glee it was

00:24:06,180 --> 00:24:10,170
done a few years ago because they use

00:24:07,560 --> 00:24:14,040
Kafka and they're logging as a service

00:24:10,170 --> 00:24:15,720
solution internally and then you'll see

00:24:14,040 --> 00:24:19,740
something quoted they're always accept

00:24:15,720 --> 00:24:22,560
data never drop data true elasticity

00:24:19,740 --> 00:24:25,170
that's what Kafka gave them that's what

00:24:22,560 --> 00:24:27,360
that's what their main points are okay

00:24:25,170 --> 00:24:29,640
command query responsibility this is a

00:24:27,360 --> 00:24:31,980
part this is an architectural principle

00:24:29,640 --> 00:24:35,670
in vanassa how we've divided up the

00:24:31,980 --> 00:24:42,620
pipeline if you go look at this pipeline

00:24:35,670 --> 00:24:46,740
again oops there okay data comes in

00:24:42,620 --> 00:24:49,200
right and then it's stored for so those

00:24:46,740 --> 00:24:51,270
are the commands metrics logs come into

00:24:49,200 --> 00:24:54,120
the system that published a Kafka and

00:24:51,270 --> 00:24:55,830
they're written to the database that's

00:24:54,120 --> 00:24:58,140
the command part the query part of

00:24:55,830 --> 00:25:00,210
command query responsibility is the API

00:24:58,140 --> 00:25:03,060
queering things directly out of the time

00:25:00,210 --> 00:25:04,890
series database a lot of people ask well

00:25:03,060 --> 00:25:07,230
why didn't you just send the data

00:25:04,890 --> 00:25:10,590
directly from the API into the time

00:25:07,230 --> 00:25:13,290
series database and that would not be

00:25:10,590 --> 00:25:17,460
very efficient and there is several

00:25:13,290 --> 00:25:20,250
other reasons for doing it this way okay

00:25:17,460 --> 00:25:22,110
so there's a great link there I know you

00:25:20,250 --> 00:25:27,060
can't read that but if you're interested

00:25:22,110 --> 00:25:29,400
in seek urs I turns out as I was

00:25:27,060 --> 00:25:31,950
preparing for this presentation that I

00:25:29,400 --> 00:25:33,660
was like you know so we have the sea QRS

00:25:31,950 --> 00:25:37,320
architecture I'm wondering if anybody

00:25:33,660 --> 00:25:40,049
else has realized how

00:25:37,320 --> 00:25:42,450
synergistic kafka is with this and so I

00:25:40,049 --> 00:25:45,720
googled you know seek urs and Kafka and

00:25:42,450 --> 00:25:48,960
I found this link from confluent that

00:25:45,720 --> 00:25:50,250
was just published in September which I

00:25:48,960 --> 00:25:52,470
thought was amazing it's a really good

00:25:50,250 --> 00:25:55,019
presentations and confluent is the

00:25:52,470 --> 00:25:57,509
company that's basically trying to

00:25:55,019 --> 00:25:59,789
commercialize cough gather they have

00:25:57,509 --> 00:26:01,889
support they're maintaining it Jake reps

00:25:59,789 --> 00:26:04,230
left linkedin and started up the company

00:26:01,889 --> 00:26:06,500
clute confluent but that's also that's a

00:26:04,230 --> 00:26:10,980
very good article that'll really explain

00:26:06,500 --> 00:26:14,399
how apache cough can be used in terms of

00:26:10,980 --> 00:26:16,740
events sourcing & Seek urs okay so

00:26:14,399 --> 00:26:19,769
microservices why do i call this a micro

00:26:16,740 --> 00:26:21,690
service architecture so micro servicers

00:26:19,769 --> 00:26:24,000
are small autonomous decouple services

00:26:21,690 --> 00:26:26,399
that are deployed independently and work

00:26:24,000 --> 00:26:29,580
together as a single application that's

00:26:26,399 --> 00:26:32,159
what we have here each component in this

00:26:29,580 --> 00:26:36,210
system is kind of more or less single

00:26:32,159 --> 00:26:38,820
purpose and they all communicate over a

00:26:36,210 --> 00:26:43,230
network using Kafka as the intermediary

00:26:38,820 --> 00:26:46,620
and we can change services independently

00:26:43,230 --> 00:26:48,629
and we've done that so you can rewrite a

00:26:46,620 --> 00:26:52,259
service and drop it in and as long as

00:26:48,629 --> 00:26:55,379
all you need to do is consume or publish

00:26:52,259 --> 00:26:58,860
messages from Kafka you can that the

00:26:55,379 --> 00:27:01,049
system will work the same some benefits

00:26:58,860 --> 00:27:03,409
and microservices resilient scale ease

00:27:01,049 --> 00:27:07,309
of deployment organization alignment and

00:27:03,409 --> 00:27:09,509
optimized for change replace ability

00:27:07,309 --> 00:27:12,750
okay so I kind of covered the post

00:27:09,509 --> 00:27:14,669
metric sequence but basically when you

00:27:12,750 --> 00:27:18,000
post a metric it goes through API it's

00:27:14,669 --> 00:27:20,519
published a Kafka a persister process

00:27:18,000 --> 00:27:23,250
those metrics periodically writes them

00:27:20,519 --> 00:27:26,190
to our time series database and our

00:27:23,250 --> 00:27:29,669
threshold engine consumes them evaluates

00:27:26,190 --> 00:27:31,080
alarms and if they've exceeded a

00:27:29,669 --> 00:27:35,340
threshold that published as a message

00:27:31,080 --> 00:27:38,100
back to Kafka I just want to touch on

00:27:35,340 --> 00:27:41,190
the main event sequence so creating an

00:27:38,100 --> 00:27:44,429
alarm definition is one domain event in

00:27:41,190 --> 00:27:46,409
our system it is if that comes if some

00:27:44,429 --> 00:27:49,100
if some clients creates an alarm

00:27:46,409 --> 00:27:52,789
definition

00:27:49,100 --> 00:27:57,140
that is then stored and updated in my

00:27:52,789 --> 00:27:59,600
sequel so that box there and we also

00:27:57,140 --> 00:28:03,410
publish that alarm definition to Kafka

00:27:59,600 --> 00:28:05,539
and then other consumers or micro

00:28:03,410 --> 00:28:06,980
services in the system can consume that

00:28:05,539 --> 00:28:09,740
our threshold engine would be very

00:28:06,980 --> 00:28:14,270
interested in that our threshold engine

00:28:09,740 --> 00:28:16,460
is a real-time near real-time streaming

00:28:14,270 --> 00:28:19,280
threshold engine it keeps everything in

00:28:16,460 --> 00:28:22,460
memory so when it starts up it reads

00:28:19,280 --> 00:28:26,299
from my sequel once and from there on

00:28:22,460 --> 00:28:31,630
out all it does is get these events via

00:28:26,299 --> 00:28:31,630
Kafka and updates in its internal state

00:28:31,840 --> 00:28:38,630
so that's how you get performance and

00:28:35,059 --> 00:28:40,700
scale to some extent out of the system

00:28:38,630 --> 00:28:43,070
you could you wouldn't want to go to my

00:28:40,700 --> 00:28:44,480
sequel every time and query it and say

00:28:43,070 --> 00:28:46,870
well tell me about all alarms and you

00:28:44,480 --> 00:28:51,080
want to want to do that periodically

00:28:46,870 --> 00:28:53,480
okay not to start speeding up a little

00:28:51,080 --> 00:28:56,870
bit okay so deployment models typically

00:28:53,480 --> 00:28:58,309
we're deployed in a clustered there are

00:28:56,870 --> 00:29:00,320
many ways to deployment Oscar but we're

00:28:58,309 --> 00:29:02,929
typically deployed in a cluster or high

00:29:00,320 --> 00:29:04,760
available configuration three nodes is

00:29:02,929 --> 00:29:06,260
more or less what we kind of focus on

00:29:04,760 --> 00:29:09,440
but there's people that are deploying

00:29:06,260 --> 00:29:11,830
more than that if any nota microservers

00:29:09,440 --> 00:29:14,299
fails the cluster remains operational

00:29:11,830 --> 00:29:18,940
your date will be redistributed across

00:29:14,299 --> 00:29:21,260
park kafka and the remaining components

00:29:18,940 --> 00:29:24,409
preferably database is run on a separate

00:29:21,260 --> 00:29:30,770
three nose or five nodes because there

00:29:24,409 --> 00:29:32,210
is contention at the dr level like if

00:29:30,770 --> 00:29:34,400
Kafka's writing lots of data to the

00:29:32,210 --> 00:29:37,159
drive and your database is writing lots

00:29:34,400 --> 00:29:40,520
of data to the drive you're constantly

00:29:37,159 --> 00:29:44,360
seeking data on disk unless you're in an

00:29:40,520 --> 00:29:47,450
SSD in which case things can be run more

00:29:44,360 --> 00:29:49,190
or less on the same system you can run

00:29:47,450 --> 00:29:52,659
manaslu on a single node is running

00:29:49,190 --> 00:29:55,070
right now on my laptop in a vm

00:29:52,659 --> 00:29:58,040
non-clustered and we're looking at

00:29:55,070 --> 00:30:03,169
containerization this is our metrics

00:29:58,040 --> 00:30:03,559
model so our metrics this is a posting

00:30:03,169 --> 00:30:06,169
to

00:30:03,559 --> 00:30:09,259
the metrics end point that has a name

00:30:06,169 --> 00:30:12,080
called htd the name in this case is

00:30:09,259 --> 00:30:13,759
called HDTV status there's this thing

00:30:12,080 --> 00:30:17,120
called dimensions in prometheus they're

00:30:13,759 --> 00:30:19,970
called labels and in flux TV either

00:30:17,120 --> 00:30:21,289
called tags and cloud watch I think

00:30:19,970 --> 00:30:22,940
they're called dimensions everyone's got

00:30:21,289 --> 00:30:28,669
a different name essentially it's a

00:30:22,940 --> 00:30:31,460
dictionary of key value pairs and so we

00:30:28,669 --> 00:30:33,740
have in that regard a similar model to

00:30:31,460 --> 00:30:39,110
some of these more modern monitoring

00:30:33,740 --> 00:30:42,919
systems so the combination of your

00:30:39,110 --> 00:30:46,460
metric name and your dimensions uniquely

00:30:42,919 --> 00:30:48,950
identify a metric we have a timestamp in

00:30:46,460 --> 00:30:51,769
milliseconds from the epoch we have a

00:30:48,950 --> 00:30:54,529
float value we have this other thing

00:30:51,769 --> 00:30:57,970
here called value meta value meta

00:30:54,529 --> 00:31:01,129
describes is used to supply additional

00:30:57,970 --> 00:31:03,649
information about the value I don't

00:31:01,129 --> 00:31:08,179
think Prometheus has this concept in

00:31:03,649 --> 00:31:10,580
there but and sometimes people do this

00:31:08,179 --> 00:31:13,490
in the dimensions but I like to keep it

00:31:10,580 --> 00:31:16,730
separate for various reasons what this

00:31:13,490 --> 00:31:19,490
allows you to do is describe a

00:31:16,730 --> 00:31:21,379
measurement in more detail if you're

00:31:19,490 --> 00:31:26,470
monitoring is you're getting stuff from

00:31:21,379 --> 00:31:26,470
something that's purely binary data or

00:31:26,499 --> 00:31:33,090
you've got some sort of categorical data

00:31:30,100 --> 00:31:36,270
maybe it's you know okay

00:31:33,090 --> 00:31:38,160
warning critical unknown status like

00:31:36,270 --> 00:31:40,590
from nagios that was one of our use

00:31:38,160 --> 00:31:43,200
cases for adding this and you've got a

00:31:40,590 --> 00:31:45,810
message associated as well so you can

00:31:43,200 --> 00:31:49,650
supply that so we have the metric value

00:31:45,810 --> 00:31:55,260
can be anything but it could be like 0 1

00:31:49,650 --> 00:31:57,510
2 or 3 in the case of nagios and so for

00:31:55,260 --> 00:31:58,980
okay warning critical or known and then

00:31:57,510 --> 00:32:01,350
you can use value meta in the case that

00:31:58,980 --> 00:32:03,770
you've got something that's warning or

00:32:01,350 --> 00:32:06,690
critical are known to supply additional

00:32:03,770 --> 00:32:09,990
metadata about that measurement in this

00:32:06,690 --> 00:32:13,710
case status code is 500 and the messages

00:32:09,990 --> 00:32:16,410
internal server error one of the things

00:32:13,710 --> 00:32:18,600
we want to do since we had nagios we had

00:32:16,410 --> 00:32:20,490
our metrics processing systems head

00:32:18,600 --> 00:32:23,490
monitoring as a services consolidate and

00:32:20,490 --> 00:32:29,730
this more or less basically allowed us

00:32:23,490 --> 00:32:32,010
to replace or yeah replace the

00:32:29,730 --> 00:32:35,640
capabilities that we had and nog us with

00:32:32,010 --> 00:32:39,180
woof monoski so I covered push for a

00:32:35,640 --> 00:32:40,770
little bit but just want to mention

00:32:39,180 --> 00:32:43,770
there's a few things that you can't do

00:32:40,770 --> 00:32:45,810
with pull so you can't really do

00:32:43,770 --> 00:32:48,510
monitoring as a service with a pulled a

00:32:45,810 --> 00:32:52,560
system you can put a proxy on top of in

00:32:48,510 --> 00:32:56,310
front of things but you can't and that's

00:32:52,560 --> 00:32:58,020
a little bit different that's but you

00:32:56,310 --> 00:33:00,690
can't always pull due to firewalls and

00:32:58,020 --> 00:33:04,590
network issues it's you can push all the

00:33:00,690 --> 00:33:08,900
time usually but you can't pull you also

00:33:04,590 --> 00:33:08,900
can't do like low latency sub second

00:33:09,020 --> 00:33:15,630
response time in a pull model so if you

00:33:13,080 --> 00:33:18,660
were trying to detect a vm going down or

00:33:15,630 --> 00:33:21,090
container going down and you want to do

00:33:18,660 --> 00:33:23,430
that in less than a second sub second

00:33:21,090 --> 00:33:27,540
latency that be difficult more difficult

00:33:23,430 --> 00:33:29,900
of a pull model it's much easier to when

00:33:27,540 --> 00:33:33,060
you do that detective looking at process

00:33:29,900 --> 00:33:35,520
or vm process when that vm goes down

00:33:33,060 --> 00:33:37,920
send a metric and assuming your alarm

00:33:35,520 --> 00:33:41,760
system can handle that quickly enough

00:33:37,920 --> 00:33:43,020
then you can process that it doesn't

00:33:41,760 --> 00:33:46,680
require service discovery and

00:33:43,020 --> 00:33:49,380
registration so when entities

00:33:46,680 --> 00:33:51,510
nodes or services come online they can

00:33:49,380 --> 00:33:53,790
just start sending metrics there's no

00:33:51,510 --> 00:33:57,390
intermediary step I can't handle events

00:33:53,790 --> 00:33:59,790
well and one thing that we do in the

00:33:57,390 --> 00:34:03,120
Nazca is if we can't reach the service

00:33:59,790 --> 00:34:05,880
we temporarily cash metrics by temporary

00:34:03,120 --> 00:34:08,090
I mean maybe up to an hour two or four

00:34:05,880 --> 00:34:10,560
hours it's it's edible in the agent a

00:34:08,090 --> 00:34:15,030
reason why we do that is if we're

00:34:10,560 --> 00:34:16,950
sending metering data into our system we

00:34:15,030 --> 00:34:19,310
want to have all that data the vm could

00:34:16,950 --> 00:34:22,080
have been alive for a tenant in

00:34:19,310 --> 00:34:25,260
OpenStack we don't want to lose their

00:34:22,080 --> 00:34:27,930
data even though the network might have

00:34:25,260 --> 00:34:35,160
been the service the Manassa API might

00:34:27,930 --> 00:34:36,810
have been unreachable okay so a little

00:34:35,160 --> 00:34:39,150
bit of our API primary point for

00:34:36,810 --> 00:34:41,550
publishing metrics the Authenticator

00:34:39,150 --> 00:34:43,950
requests our primary resources are

00:34:41,550 --> 00:34:46,260
metrics alarm definitions alarms and

00:34:43,950 --> 00:34:49,260
notification methods there is a full api

00:34:46,260 --> 00:34:56,580
specification it's horizontally scalable

00:34:49,260 --> 00:34:58,530
and move quick now for sister so we kind

00:34:56,580 --> 00:35:00,540
of covered what its rules are it

00:34:58,530 --> 00:35:03,470
consumes metrics and alarm state

00:35:00,540 --> 00:35:06,060
transition events and it publishes them

00:35:03,470 --> 00:35:09,500
it consumes them from Kafka and it

00:35:06,060 --> 00:35:12,210
stores and then our time series database

00:35:09,500 --> 00:35:17,820
at least once matches message delivery

00:35:12,210 --> 00:35:19,590
semantics so basically like if you were

00:35:17,820 --> 00:35:22,500
in the process of writing to the

00:35:19,590 --> 00:35:24,990
database and then right after you wrote

00:35:22,500 --> 00:35:27,990
you failed or somebody stopped you or

00:35:24,990 --> 00:35:30,330
kill you if you don't get a chance to

00:35:27,990 --> 00:35:32,760
update your offsets where you are in

00:35:30,330 --> 00:35:35,940
Kafka since that's client controlled

00:35:32,760 --> 00:35:38,040
then there's a you when you restart you

00:35:35,940 --> 00:35:40,830
might read the same messages again and

00:35:38,040 --> 00:35:44,750
we don't remove duplicates we don't try

00:35:40,830 --> 00:35:47,250
to and it's a che and fault-tolerant

00:35:44,750 --> 00:35:50,220
okay there's two databases time series

00:35:47,250 --> 00:35:52,350
databases in our system for storing

00:35:50,220 --> 00:35:54,300
metrics or alarm state history we

00:35:52,350 --> 00:35:56,000
support vertica and this is an open

00:35:54,300 --> 00:35:58,530
source conference but vertica is a

00:35:56,000 --> 00:35:59,930
enterprise-class proprietary closed

00:35:58,530 --> 00:36:03,020
stores haan on X date

00:35:59,930 --> 00:36:05,690
days and we support influx DB which is

00:36:03,020 --> 00:36:08,600
open source for single nodes they

00:36:05,690 --> 00:36:12,680
unfortunately went close source for

00:36:08,600 --> 00:36:17,990
their clustered solution April fourth I

00:36:12,680 --> 00:36:20,240
believe of this year but there are some

00:36:17,990 --> 00:36:22,360
alternatives for doing that in flux DB

00:36:20,240 --> 00:36:26,690
has something called in flux DB relay

00:36:22,360 --> 00:36:28,610
and we can we are you can also do a lot

00:36:26,690 --> 00:36:32,080
of things with Kafka replicating data

00:36:28,610 --> 00:36:35,630
across multiple in flux DB nodes or

00:36:32,080 --> 00:36:37,610
partitioning data across in flux DB

00:36:35,630 --> 00:36:40,160
nodes and so we are gonna spend more

00:36:37,610 --> 00:36:42,740
time on that we're investigating this

00:36:40,160 --> 00:36:45,590
has been a topic now for a while

00:36:42,740 --> 00:36:48,890
investigating other altered alternative

00:36:45,590 --> 00:36:52,250
database is we looked at Cassandra we

00:36:48,890 --> 00:36:53,780
don't feel too strongly about that if

00:36:52,250 --> 00:36:55,670
anybody wants to know more I can talk to

00:36:53,780 --> 00:37:00,470
them about that and we're looking at

00:36:55,670 --> 00:37:02,180
elastic search as well okay so a config

00:37:00,470 --> 00:37:04,040
database that was no nonetheless stores

00:37:02,180 --> 00:37:07,010
a lot of information in there about all

00:37:04,040 --> 00:37:09,950
the data in the system our threshold

00:37:07,010 --> 00:37:12,410
engine this is our near real-time

00:37:09,950 --> 00:37:14,480
streaming process clustered and highly

00:37:12,410 --> 00:37:18,550
available threshold engine based on a

00:37:14,480 --> 00:37:24,820
patchy storm okay so that's another

00:37:18,550 --> 00:37:28,840
Apache project and that allows you to

00:37:24,820 --> 00:37:31,340
define a topology account of

00:37:28,840 --> 00:37:35,360
computational elements they call those

00:37:31,340 --> 00:37:36,770
elements bolts so they're they're

00:37:35,360 --> 00:37:38,570
terminologies a little strange but they

00:37:36,770 --> 00:37:40,880
got spouts and bolts with the bolts do

00:37:38,570 --> 00:37:42,680
the calculations so we define this

00:37:40,880 --> 00:37:46,910
topology that's distributed across a

00:37:42,680 --> 00:37:51,260
cluster and so that guarantees that we

00:37:46,910 --> 00:37:53,540
don't lose any data and basically it

00:37:51,260 --> 00:37:56,360
evaluates if thresholds amix have been

00:37:53,540 --> 00:37:59,870
exceeded it supports both simple and

00:37:56,360 --> 00:38:03,530
compound alarm expressions in our

00:37:59,870 --> 00:38:07,490
notification engine consumes alarm state

00:38:03,530 --> 00:38:11,400
transition events publishes or sends

00:38:07,490 --> 00:38:13,799
emails or SMS or whatever else

00:38:11,400 --> 00:38:15,660
there's a plug-in design for the

00:38:13,799 --> 00:38:18,450
notification engine so if you want to

00:38:15,660 --> 00:38:23,970
develop another plug-in that's easy to

00:38:18,450 --> 00:38:25,500
do we have SNMP in progress and I've

00:38:23,970 --> 00:38:28,079
been feeling a little bit of Prometheus

00:38:25,500 --> 00:38:32,660
entity lately so I want to add support

00:38:28,079 --> 00:38:36,390
for grouping of notifications in menaka

00:38:32,660 --> 00:38:40,049
okay our schema for our cough guts

00:38:36,390 --> 00:38:41,160
topics is published and that's what so

00:38:40,049 --> 00:38:44,490
that's not something that's just an

00:38:41,160 --> 00:38:46,260
internal thing that's used and change it

00:38:44,490 --> 00:38:49,829
could change something that's well

00:38:46,260 --> 00:38:53,250
defined okay so we're gonna get to the

00:38:49,829 --> 00:38:58,349
API so you can create query and get

00:38:53,250 --> 00:39:00,450
statistics for metrics okay so and those

00:38:58,349 --> 00:39:02,609
are our so you can get all the metrics

00:39:00,450 --> 00:39:04,529
all the unique metrics in the system

00:39:02,609 --> 00:39:07,950
that's that top one and all the unique

00:39:04,529 --> 00:39:11,750
metric names in your system like cpu

00:39:07,950 --> 00:39:14,760
user percent i can get all the unique

00:39:11,750 --> 00:39:19,819
metric dimension names like a dimension

00:39:14,760 --> 00:39:22,859
name would be hostname region cluster

00:39:19,819 --> 00:39:24,930
service component things like that and

00:39:22,859 --> 00:39:27,180
get all those unique names and then you

00:39:24,930 --> 00:39:31,589
can get all the unique values for those

00:39:27,180 --> 00:39:33,839
names with that last query there and all

00:39:31,589 --> 00:39:37,260
those things are fully paginate 'add you

00:39:33,839 --> 00:39:39,270
can sort group filter on various aspects

00:39:37,260 --> 00:39:42,720
of them and this is to guarantee that

00:39:39,270 --> 00:39:47,299
our user interfaces run very fast when

00:39:42,720 --> 00:39:47,299
you have a lot of data in your system

00:39:47,390 --> 00:39:52,230
measurements pretty simple once you

00:39:50,220 --> 00:39:53,819
store all these measurements away you

00:39:52,230 --> 00:39:57,510
want to get them out you want to query

00:39:53,819 --> 00:39:59,250
them later on so you can supply like a

00:39:57,510 --> 00:40:03,119
metric name that you're interested in a

00:39:59,250 --> 00:40:05,599
start and time you got these two

00:40:03,119 --> 00:40:08,250
additional flags for merging metrics

00:40:05,599 --> 00:40:11,369
different metrics together into a series

00:40:08,250 --> 00:40:14,190
or grouping them by various dimension

00:40:11,369 --> 00:40:17,970
names so if I wanted to get all the

00:40:14,190 --> 00:40:22,920
measurements for cpu user percent for

00:40:17,970 --> 00:40:24,920
all of my VMS i could specify a group by

00:40:22,920 --> 00:40:27,509
of like resource ID

00:40:24,920 --> 00:40:30,930
as resource ID is something that's

00:40:27,509 --> 00:40:34,019
unique for vm and then i would get in

00:40:30,930 --> 00:40:37,319
one query not just a single metric i

00:40:34,019 --> 00:40:41,599
would get 1020 let's say I 20 VMs i

00:40:37,319 --> 00:40:45,539
would get 20 separate unique sets of

00:40:41,599 --> 00:40:53,729
measurements returned all grouped by

00:40:45,539 --> 00:40:55,529
resource ID statistics so if you want to

00:40:53,729 --> 00:40:56,849
not just get every measurement back but

00:40:55,529 --> 00:40:59,190
you want to get the average and then

00:40:56,849 --> 00:41:02,789
next summer count for those measurements

00:40:59,190 --> 00:41:06,239
back based on some period in seconds

00:41:02,789 --> 00:41:09,059
like five minutes or one hour or one day

00:41:06,239 --> 00:41:11,549
periods you can do that with our API and

00:41:09,059 --> 00:41:16,200
you can also group by or merge those

00:41:11,549 --> 00:41:19,130
metrics together okay so there's the API

00:41:16,200 --> 00:41:21,390
forgetting metric names dimension names

00:41:19,130 --> 00:41:22,829
dimension values we kind of covered this

00:41:21,390 --> 00:41:25,079
earlier and I got to start getting

00:41:22,829 --> 00:41:28,019
through my slides which I'm a little bit

00:41:25,079 --> 00:41:30,479
behind alarm definitions i want to touch

00:41:28,019 --> 00:41:33,329
on this you don't create alarms in an

00:41:30,479 --> 00:41:35,640
oscar you create alarm definitions alarm

00:41:33,329 --> 00:41:38,849
definitions are like templates or

00:41:35,640 --> 00:41:42,690
factories that are used to automatically

00:41:38,849 --> 00:41:44,549
integrate alarms based on some pattern

00:41:42,690 --> 00:41:47,400
matching that's going on our pattern

00:41:44,549 --> 00:41:51,450
matching is fairly simplistic we pattern

00:41:47,400 --> 00:41:55,769
match exactly on the metric name and a

00:41:51,450 --> 00:41:57,089
dimension name that has been asbestos or

00:41:55,769 --> 00:42:01,410
dimension name value that's been

00:41:57,089 --> 00:42:07,710
specified but it turns out you can also

00:42:01,410 --> 00:42:10,079
do a match by clause here as well and so

00:42:07,710 --> 00:42:13,890
if you specified an alarm and you said I

00:42:10,079 --> 00:42:15,989
want to monitor all of my CP you use a

00:42:13,890 --> 00:42:19,019
percent for all VMS i would say match by

00:42:15,989 --> 00:42:21,569
resource ID when metrics show up now

00:42:19,019 --> 00:42:25,019
that have cpu user percent as the metric

00:42:21,569 --> 00:42:27,390
name and resource ID as one of the

00:42:25,019 --> 00:42:29,549
dimensions and that resource the actual

00:42:27,390 --> 00:42:33,359
value of it differs we automatically

00:42:29,549 --> 00:42:34,829
create alarms in our system it doesn't

00:42:33,359 --> 00:42:36,660
mean we start sending alerts out that

00:42:34,829 --> 00:42:38,520
just means we create this stateful thing

00:42:36,660 --> 00:42:41,910
called an alarm

00:42:38,520 --> 00:42:45,110
and then all metrics that subsequently

00:42:41,910 --> 00:42:47,850
show up we'll go to that alarm right

00:42:45,110 --> 00:42:50,480
alarms have States they are tri-state

00:42:47,850 --> 00:42:53,190
okay alarm and undetermined by default

00:42:50,480 --> 00:42:55,800
you can also specify what we call

00:42:53,190 --> 00:42:59,160
deterministic alarms which only have the

00:42:55,800 --> 00:43:01,140
okay and alarm state the undetermined

00:42:59,160 --> 00:43:05,310
state shows up when metrics are no being

00:43:01,140 --> 00:43:08,640
no longer being received right so if you

00:43:05,310 --> 00:43:12,660
if you were monitoring a node for a long

00:43:08,640 --> 00:43:14,310
time and then that node disappeared the

00:43:12,660 --> 00:43:18,450
alarm would transition to the

00:43:14,310 --> 00:43:19,950
undetermined state and in some cases you

00:43:18,450 --> 00:43:21,450
don't really want it to transition to

00:43:19,950 --> 00:43:24,630
the undetermined state so if you're

00:43:21,450 --> 00:43:27,900
creating metrics from log messages for

00:43:24,630 --> 00:43:30,350
example then what you would end up doing

00:43:27,900 --> 00:43:32,490
is creating this deterministic alarm and

00:43:30,350 --> 00:43:35,040
you only have those two states so you

00:43:32,490 --> 00:43:38,220
can just send metrics when when they're

00:43:35,040 --> 00:43:40,200
detected in log files and when you don't

00:43:38,220 --> 00:43:42,120
find any errors you won't have your

00:43:40,200 --> 00:43:45,900
alarms go to undetermined state they

00:43:42,120 --> 00:43:47,790
will stay in the ok state something also

00:43:45,900 --> 00:43:50,520
unique here I should have put it in blue

00:43:47,790 --> 00:43:53,700
thresholds can be I dynamically adjusted

00:43:50,520 --> 00:43:55,440
on the fly this is really useful if you

00:43:53,700 --> 00:43:57,810
got your system your monitoring a whole

00:43:55,440 --> 00:44:01,410
bunch of stuff you want to baseline the

00:43:57,810 --> 00:44:05,340
number of messages received or sent or

00:44:01,410 --> 00:44:08,580
the latency on your HTTP API this is

00:44:05,340 --> 00:44:09,750
stuff that you know dynamically you know

00:44:08,580 --> 00:44:13,740
once you get your system up and running

00:44:09,750 --> 00:44:18,930
assuming it's sort of stays within some

00:44:13,740 --> 00:44:22,290
sort of mean then you you know you set

00:44:18,930 --> 00:44:24,450
those thresholds and then at 2am if they

00:44:22,290 --> 00:44:26,100
if all of a sudden you're going beyond

00:44:24,450 --> 00:44:31,410
those specials you can adjust those

00:44:26,100 --> 00:44:35,010
alarms without without doing any code

00:44:31,410 --> 00:44:36,810
deployment or anything okay so you can

00:44:35,010 --> 00:44:38,400
query alarms you can say tell me all the

00:44:36,810 --> 00:44:40,670
alarms in my system we've got a lot of

00:44:38,400 --> 00:44:43,710
parameters that can be supplied to this

00:44:40,670 --> 00:44:45,690
so you can basically cleary alarms and

00:44:43,710 --> 00:44:47,940
supply some parameters to filter on like

00:44:45,690 --> 00:44:52,110
the metric names states or severity

00:44:47,940 --> 00:44:54,240
'he's the updated time or created time

00:44:52,110 --> 00:44:56,280
it's fully paginate it and you can sort

00:44:54,240 --> 00:45:03,360
by lots of different things at four

00:44:56,280 --> 00:45:04,800
alarms okay alarm counts is another API

00:45:03,360 --> 00:45:07,920
we have this usually shows up in

00:45:04,800 --> 00:45:12,240
dashboards where you're trying to show

00:45:07,920 --> 00:45:13,890
you an example a next page so i don't

00:45:12,240 --> 00:45:16,140
know if you can see that but in this

00:45:13,890 --> 00:45:17,970
case we've got some dashboards being

00:45:16,140 --> 00:45:20,670
shown we only got one alarm in the

00:45:17,970 --> 00:45:23,400
critical state for for the compute

00:45:20,670 --> 00:45:28,140
service and that's probably networking

00:45:23,400 --> 00:45:31,110
and out of one out of 35 one out of 142

00:45:28,140 --> 00:45:32,550
and if you want to show percentages and

00:45:31,110 --> 00:45:35,040
things like that you'd have to do the

00:45:32,550 --> 00:45:37,080
calculations in your client or in this

00:45:35,040 --> 00:45:40,230
case the browser with some JavaScript

00:45:37,080 --> 00:45:41,910
but but that's what that query is about

00:45:40,230 --> 00:45:44,790
and you can when you're getting those

00:45:41,910 --> 00:45:47,640
counts you can say well I want to group

00:45:44,790 --> 00:45:50,490
them by like again a dimension I can

00:45:47,640 --> 00:45:53,510
group them by like service in this case

00:45:50,490 --> 00:45:57,000
is what they're being grouped by and

00:45:53,510 --> 00:46:03,090
then I can also group them by severity

00:45:57,000 --> 00:46:05,400
or a state this is group by by by the

00:46:03,090 --> 00:46:07,410
service dimension and state and then you

00:46:05,400 --> 00:46:09,540
can get your accounts and do any math

00:46:07,410 --> 00:46:11,520
that you need to do I can mentioned

00:46:09,540 --> 00:46:13,980
earlier we have our alarm history that

00:46:11,520 --> 00:46:16,770
is all sorts every time there's an alarm

00:46:13,980 --> 00:46:18,930
state transition we store that you can

00:46:16,770 --> 00:46:21,090
go back in time look at all of your

00:46:18,930 --> 00:46:23,130
alarms really useful if you want to

00:46:21,090 --> 00:46:26,190
understand whether some service is

00:46:23,130 --> 00:46:29,610
flapping or if you want to understand

00:46:26,190 --> 00:46:31,110
like a month ago what happened with this

00:46:29,610 --> 00:46:33,560
service like this this looks like

00:46:31,110 --> 00:46:35,940
something that in the past i came across

00:46:33,560 --> 00:46:37,710
let me see if i can understand the

00:46:35,940 --> 00:46:39,330
patterns here i can go back and look at

00:46:37,710 --> 00:46:42,420
my alarms i can go back and look at

00:46:39,330 --> 00:46:48,990
those metrics and i can start to figure

00:46:42,420 --> 00:46:51,030
things out hopefully okay notification

00:46:48,990 --> 00:46:53,610
methods these are the things that are

00:46:51,030 --> 00:46:56,750
created they have a name a type in an

00:46:53,610 --> 00:47:00,510
address email address in this example

00:46:56,750 --> 00:47:03,180
those are associated with your alarm

00:47:00,510 --> 00:47:05,400
state transitions so when you go from

00:47:03,180 --> 00:47:08,880
okay to alarm

00:47:05,400 --> 00:47:11,640
a alarm action and when you go alarm

00:47:08,880 --> 00:47:13,980
back to ok that's an okay action you can

00:47:11,640 --> 00:47:17,700
associate notification methods with them

00:47:13,980 --> 00:47:23,490
and those will be invoked by the

00:47:17,700 --> 00:47:27,330
notification engine ok so our agent it's

00:47:23,490 --> 00:47:29,790
a Python agent it's optional we we

00:47:27,330 --> 00:47:33,950
monitor lots of stuff you know there's

00:47:29,790 --> 00:47:36,980
no huge intellectual

00:47:33,950 --> 00:47:39,710
property here but we do your normal

00:47:36,980 --> 00:47:42,109
system that tricks we do several

00:47:39,710 --> 00:47:46,089
services nice equal Kafka and many

00:47:42,109 --> 00:47:49,960
others we have a built-in stats d-demon

00:47:46,089 --> 00:47:52,099
to our agent so if you want to do

00:47:49,960 --> 00:47:54,829
instrumentation of an application you

00:47:52,099 --> 00:47:58,820
can do that we have our own library that

00:47:54,829 --> 00:48:01,730
adds support for dimensions in agents as

00:47:58,820 --> 00:48:04,730
will we monitor VMS we monitor open V

00:48:01,730 --> 00:48:07,700
switch we can do active checks like HTTP

00:48:04,730 --> 00:48:10,010
status checks system up down checks we

00:48:07,700 --> 00:48:13,040
can run any nagios plugin or check in k

00:48:10,010 --> 00:48:14,990
script it's extensible its pluggable

00:48:13,040 --> 00:48:17,000
additional stuff can be easily added

00:48:14,990 --> 00:48:21,140
we've been in the process of adding

00:48:17,000 --> 00:48:24,109
support for dr. and Cooper Nettie's and

00:48:21,140 --> 00:48:26,510
that's those lately and I've warned that

00:48:24,109 --> 00:48:30,400
detail just a couple of fine points here

00:48:26,510 --> 00:48:30,400
I loved to Koh as cover the fine points

00:48:31,180 --> 00:48:38,420
so the only the main point here other

00:48:35,810 --> 00:48:40,520
than the authentication so our agent

00:48:38,420 --> 00:48:43,670
authenticates a keystone so when you

00:48:40,520 --> 00:48:45,319
deploy the agent you have to supply at

00:48:43,670 --> 00:48:47,630
the username password of your account

00:48:45,319 --> 00:48:50,750
and then it requests those auth tokens

00:48:47,630 --> 00:48:52,490
from Keystone and then that third bullet

00:48:50,750 --> 00:48:55,819
was the one I mentioned early it will

00:48:52,490 --> 00:48:57,890
cache data if it can't reach the API for

00:48:55,819 --> 00:49:01,280
some period of time so you don't lose

00:48:57,890 --> 00:49:03,460
data in our system and that's important

00:49:01,280 --> 00:49:07,819
because we're not just handling

00:49:03,460 --> 00:49:09,650
operational data we're handling data for

00:49:07,819 --> 00:49:11,569
the customer that we've have a service

00:49:09,650 --> 00:49:13,339
level agreement with that says we got

00:49:11,569 --> 00:49:19,670
all your data for two weeks or four

00:49:13,339 --> 00:49:22,400
weeks sometimes and oh yeah there are

00:49:19,670 --> 00:49:25,510
roles within OpenStack and we use them

00:49:22,400 --> 00:49:28,310
in monoski so the agent can't query

00:49:25,510 --> 00:49:31,130
alarms or delete alarms the only thing

00:49:28,310 --> 00:49:35,720
it's allowed to do is post metrics so we

00:49:31,130 --> 00:49:38,089
think we're fairly secure all right we

00:49:35,720 --> 00:49:39,770
have graph on ax integration I'm going

00:49:38,089 --> 00:49:42,950
to try to get to my demo the last five

00:49:39,770 --> 00:49:46,430
minutes we have a manasa data source we

00:49:42,950 --> 00:49:47,160
also do keystone authentication and one

00:49:46,430 --> 00:49:48,990
Griffin

00:49:47,160 --> 00:49:51,330
or is out or maybe it is out and I don't

00:49:48,990 --> 00:49:55,190
even know but when it when it's out will

00:49:51,330 --> 00:50:01,550
add support for learning there is a

00:49:55,190 --> 00:50:06,120
screenshot of Agra fauna support ok so

00:50:01,550 --> 00:50:08,820
logging logging is similar to the

00:50:06,120 --> 00:50:12,480
architecture is similar and that's in

00:50:08,820 --> 00:50:14,250
part why we did this but manaslu isn't

00:50:12,480 --> 00:50:16,410
just about monitoring as a service it's

00:50:14,250 --> 00:50:19,080
about logging as a service and the best

00:50:16,410 --> 00:50:21,780
way to think about that is probably to

00:50:19,080 --> 00:50:24,990
think about la glee but we have a

00:50:21,780 --> 00:50:27,090
logging API and we've got several in

00:50:24,990 --> 00:50:29,940
this case we didn't have to develop our

00:50:27,090 --> 00:50:34,320
own plugin we leveraged beaver and log

00:50:29,940 --> 00:50:36,510
stash we have our own I forgot the terms

00:50:34,320 --> 00:50:40,260
that they use but our own plugins to

00:50:36,510 --> 00:50:42,620
those agents that post to our API they

00:50:40,260 --> 00:50:45,450
do the authentication they post the API

00:50:42,620 --> 00:50:49,470
the concept is the same log messages are

00:50:45,450 --> 00:50:51,390
published to Kafka in this case we

00:50:49,470 --> 00:50:55,560
didn't write as much code we leveraged

00:50:51,390 --> 00:50:58,620
log stash a lot but logstash consumes

00:50:55,560 --> 00:51:02,370
those parcels them we store that data in

00:50:58,620 --> 00:51:03,810
elastic search as it turns out and

00:51:02,370 --> 00:51:09,810
that's the database down here on the

00:51:03,810 --> 00:51:12,720
left and then Cabana is used to query

00:51:09,810 --> 00:51:15,890
that data out and we have a modified

00:51:12,720 --> 00:51:18,810
version of Cabana that authentication

00:51:15,890 --> 00:51:26,340
key stone authentication has been added

00:51:18,810 --> 00:51:28,200
to it so so so those are I mean the main

00:51:26,340 --> 00:51:29,880
points that of change here the Cabana

00:51:28,200 --> 00:51:34,310
stuff has changed to add the Keystone

00:51:29,880 --> 00:51:38,970
authentication and filtering based on

00:51:34,310 --> 00:51:41,610
token and or sorry by tenant ID and then

00:51:38,970 --> 00:51:43,950
the output plugins have been created

00:51:41,610 --> 00:51:48,090
there's been some development in the log

00:51:43,950 --> 00:51:51,210
stash components I won't get too much

00:51:48,090 --> 00:51:53,850
into our logging API but they're the

00:51:51,210 --> 00:51:58,020
same dimensions concept is there as well

00:51:53,850 --> 00:51:59,290
so we can enrich log messages with these

00:51:58,020 --> 00:52:03,280
dimensions

00:51:59,290 --> 00:52:05,710
the same way that we do for metrics and

00:52:03,280 --> 00:52:08,020
that's very useful for filtering and

00:52:05,710 --> 00:52:17,260
sorting and ordering and grouping things

00:52:08,020 --> 00:52:24,370
on by later on okay where am I mentioned

00:52:17,260 --> 00:52:26,350
that mentioned that composability so one

00:52:24,370 --> 00:52:29,200
thing that manasa allows you to do is

00:52:26,350 --> 00:52:32,140
compose systems together we do that via

00:52:29,200 --> 00:52:34,960
Kafka one thing that we want to do was

00:52:32,140 --> 00:52:38,800
create metrics and alarm and

00:52:34,960 --> 00:52:41,830
notifications when like error messages

00:52:38,800 --> 00:52:48,490
occur in log files and the way that

00:52:41,830 --> 00:52:50,950
works is on the left here we are our

00:52:48,490 --> 00:52:54,460
logging infrastructure can create

00:52:50,950 --> 00:52:56,820
metrics and publish them back to the

00:52:54,460 --> 00:53:00,310
same metrics topic that all the other

00:52:56,820 --> 00:53:03,190
metrics are showing up on which means

00:53:00,310 --> 00:53:06,070
that you can they're stored in the

00:53:03,190 --> 00:53:09,220
database and you can alarm and threshold

00:53:06,070 --> 00:53:14,260
on them and you can send notifications

00:53:09,220 --> 00:53:19,200
on them okay so that's just a bit of the

00:53:14,260 --> 00:53:19,200
composability story around the Nazca

00:53:19,470 --> 00:53:26,410
okay so microservices extensibility

00:53:23,050 --> 00:53:28,720
composability this slide is a little

00:53:26,410 --> 00:53:31,990
different than the earlier slide that I

00:53:28,720 --> 00:53:35,020
showed that two new components here one

00:53:31,990 --> 00:53:37,870
is this transform engine it's really

00:53:35,020 --> 00:53:41,440
transform and aggregation engine and its

00:53:37,870 --> 00:53:43,660
role is to consume metrics and aggregate

00:53:41,440 --> 00:53:46,060
them we can aggregate them in many

00:53:43,660 --> 00:53:49,690
different ways it's mainly focused on

00:53:46,060 --> 00:53:51,760
capacity type use cases today but we can

00:53:49,690 --> 00:53:53,980
take metrics coming from different

00:53:51,760 --> 00:53:56,170
physical hosts and aggregate them

00:53:53,980 --> 00:53:59,980
usually we want to aggregate them like

00:53:56,170 --> 00:54:02,260
for my overall deployment like data

00:53:59,980 --> 00:54:05,880
center wide or I want to aggregate them

00:54:02,260 --> 00:54:08,170
in the metering billing cases per tenant

00:54:05,880 --> 00:54:11,540
and tell them how many bytes they're

00:54:08,170 --> 00:54:16,430
using in the object storage

00:54:11,540 --> 00:54:18,020
system in OpenStack and this component I

00:54:16,430 --> 00:54:20,540
think it's totally optional you can add

00:54:18,020 --> 00:54:22,640
it drop it in and use it or not well but

00:54:20,540 --> 00:54:26,240
all it does is consumed metrics and

00:54:22,640 --> 00:54:28,730
publish metrics and the analytics engine

00:54:26,240 --> 00:54:34,600
is a little different but the analytics

00:54:28,730 --> 00:54:37,880
engine is focused on doing more

00:54:34,600 --> 00:54:40,250
complicated things with metrics and

00:54:37,880 --> 00:54:47,120
alarm state transition events like

00:54:40,250 --> 00:54:49,040
anomaly detection and like what we call

00:54:47,120 --> 00:54:52,100
alarm clustering the best way to find

00:54:49,040 --> 00:54:54,350
that is like what Moog soft and big

00:54:52,100 --> 00:54:57,530
panda is doing but taking a bunch of

00:54:54,350 --> 00:55:04,550
alarms and grouping them together based

00:54:57,530 --> 00:55:07,910
on some criteria like some similarity

00:55:04,550 --> 00:55:11,630
type criteria so I'm going to skip over

00:55:07,910 --> 00:55:14,840
those two things we have large number of

00:55:11,630 --> 00:55:18,080
distributions and deployments out there

00:55:14,840 --> 00:55:21,260
Charter Communications is our fire

00:55:18,080 --> 00:55:22,970
number one user of monoski they run

00:55:21,260 --> 00:55:26,210
OpenStack internally in their private

00:55:22,970 --> 00:55:28,850
cloud and they're using mehnaz bhangra

00:55:26,210 --> 00:55:31,130
fauna and they're not just using it for

00:55:28,850 --> 00:55:33,590
operational monitoring they're doing the

00:55:31,130 --> 00:55:35,710
true monitoring as a service they are

00:55:33,590 --> 00:55:39,170
actually the ones that added manasa

00:55:35,710 --> 00:55:45,200
datasource to grow fauna they've got two

00:55:39,170 --> 00:55:48,230
data centers 600 to 700 total that

00:55:45,200 --> 00:55:50,000
number seems low thousand VMs their

00:55:48,230 --> 00:55:52,220
processing fairly know number of metrics

00:55:50,000 --> 00:55:54,380
they're very careful they with their

00:55:52,220 --> 00:55:56,180
metrics they they don't just throw all

00:55:54,380 --> 00:55:59,000
the metrics at the system that they can

00:55:56,180 --> 00:56:00,530
they've been very picky and so they have

00:55:59,000 --> 00:56:03,230
a fairly low metrics number which is

00:56:00,530 --> 00:56:04,670
good firewire lab if you look at that

00:56:03,230 --> 00:56:07,940
link there you can see what they've

00:56:04,670 --> 00:56:09,410
discussed what they've deployed there is

00:56:07,940 --> 00:56:10,850
Hewlett Packard Enterprise we're on

00:56:09,410 --> 00:56:15,050
frontal we're using it in our cloud

00:56:10,850 --> 00:56:20,330
system and OpenStack projects and kind

00:56:15,050 --> 00:56:21,660
of go another five minutes or okay it

00:56:20,330 --> 00:56:26,490
could

00:56:21,660 --> 00:56:27,960
uh just making sure and fujitsu is

00:56:26,490 --> 00:56:30,809
involved in the project any seeds

00:56:27,960 --> 00:56:35,549
involved in others and we've all got odd

00:56:30,809 --> 00:56:38,099
points out there some various statistics

00:56:35,549 --> 00:56:45,650
we've got 31 organizations 97

00:56:38,099 --> 00:56:51,780
contributors in the past I guess year

00:56:45,650 --> 00:56:55,859
1075 commits 4080 reviews that's the the

00:56:51,780 --> 00:56:58,829
ecosystem around us so charter NEC Cisco

00:56:55,859 --> 00:57:01,349
cloud-based solutions suisei I put them

00:56:58,829 --> 00:57:03,920
on their green but they're that's kind

00:57:01,349 --> 00:57:06,809
of new to hewlett-packard as

00:57:03,920 --> 00:57:08,700
partnerships so I'm sure they'll become

00:57:06,809 --> 00:57:12,059
involved they're not quite involved yet

00:57:08,700 --> 00:57:14,730
although then there's SolidFire SI p

00:57:12,059 --> 00:57:17,400
fujitsu an essay p by the way are here

00:57:14,730 --> 00:57:20,760
in in germany and I I stopped and

00:57:17,400 --> 00:57:22,950
visited fujitsu in munich on monday and

00:57:20,760 --> 00:57:27,180
tuesday this week pray firewall

00:57:22,950 --> 00:57:33,270
apparatus and Broadcom so i think i'm

00:57:27,180 --> 00:57:37,130
going to end the slides there and i can

00:57:33,270 --> 00:57:43,410
do a very very very quick demo or i can

00:57:37,130 --> 00:57:49,349
take you a as i only got a couple

00:57:43,410 --> 00:57:51,630
minutes back demo okay all right so how

00:57:49,349 --> 00:57:56,059
does this work all right this is horizon

00:57:51,630 --> 00:57:56,059
dashboard this is OpenStack dashboard

00:57:57,140 --> 00:58:03,750
all right so I'm logging into that and

00:58:00,270 --> 00:58:05,369
what's new here is this monitoring panel

00:58:03,750 --> 00:58:07,859
that we've added if I click on that and

00:58:05,369 --> 00:58:09,089
go to the overview page there's not a

00:58:07,859 --> 00:58:12,450
whole lot there right now since i

00:58:09,089 --> 00:58:15,180
haven't created any alarms yet and i can

00:58:12,450 --> 00:58:17,039
go into bruh fauna and you'll notice

00:58:15,180 --> 00:58:19,520
there's a logon page if you're looking

00:58:17,039 --> 00:58:22,770
at go fauna today you won't see that

00:58:19,520 --> 00:58:25,680
then we can mom we can log in to grow

00:58:22,770 --> 00:58:29,150
fauna so we've basically made Bafana a

00:58:25,680 --> 00:58:32,490
multi-tenant system we have monoski and

00:58:29,150 --> 00:58:34,990
it's been added as a data source into

00:58:32,490 --> 00:58:39,740
the system so

00:58:34,990 --> 00:58:43,220
if I click on that and I can save and

00:58:39,740 --> 00:58:47,230
test that and data source has it's there

00:58:43,220 --> 00:58:51,170
I can come in I've got a dashboard and

00:58:47,230 --> 00:58:53,000
there's my demo dashboard and I create

00:58:51,170 --> 00:58:56,240
this earlier this is just monitoring the

00:58:53,000 --> 00:58:59,720
cpu user percent of the vm that been

00:58:56,240 --> 00:59:02,240
running on this system so i can go ad a

00:58:59,720 --> 00:59:06,799
row to this and we'll add a graph row

00:59:02,240 --> 00:59:15,170
and then we'll edit that and we can go

00:59:06,799 --> 00:59:18,019
look for like other metrics disk that's

00:59:15,170 --> 00:59:21,200
not a very useful one let's just go make

00:59:18,019 --> 00:59:24,109
another cpu user % 1 i'm not being

00:59:21,200 --> 00:59:25,640
feeling very creative today and we've

00:59:24,109 --> 00:59:29,809
got these functions here so that's

00:59:25,640 --> 00:59:32,900
currently average i'll say nun and it

00:59:29,809 --> 00:59:35,240
updates we can specify dimensions here

00:59:32,900 --> 00:59:37,069
there's not too many dimensions in the

00:59:35,240 --> 00:59:40,549
system very small system I can select

00:59:37,069 --> 00:59:48,470
hostname I can say that the name of the

00:59:40,549 --> 00:59:50,809
VN is devstack and there it is again ok

00:59:48,470 --> 00:59:53,599
so what else is interesting here i can

00:59:50,809 --> 00:59:55,670
create alarm definitions we're going to

00:59:53,599 --> 01:00:00,579
create an alarm definition will call it

00:59:55,670 --> 01:00:03,769
cpu utilization description will be

01:00:00,579 --> 01:00:08,150
description and severity will give it a

01:00:03,769 --> 01:00:09,920
medium severity will click next and will

01:00:08,150 --> 01:00:14,589
give an expression so the expression

01:00:09,920 --> 01:00:15,730
will be if the average of my metric cpu

01:00:14,589 --> 01:00:17,620
user

01:00:15,730 --> 01:00:22,550
[Music]

01:00:17,620 --> 01:00:24,080
% the comparator is greater than we're

01:00:22,550 --> 01:00:29,150
going to make sure that this thing fires

01:00:24,080 --> 01:00:31,520
so greater than to this thing is going

01:00:29,150 --> 01:00:38,060
to go off so and we won't give it any

01:00:31,520 --> 01:00:39,410
notifications notification oh it goes

01:00:38,060 --> 01:00:43,130
okay so we'll come back to this overview

01:00:39,410 --> 01:00:45,800
page and in a second we will have an

01:00:43,130 --> 01:00:49,220
alarm that's been created remember we

01:00:45,800 --> 01:00:51,650
create alarm definitions and we do

01:00:49,220 --> 01:00:56,810
pattern matching when the metrics show

01:00:51,650 --> 01:00:59,180
up we see the the alarms being quite so

01:00:56,810 --> 01:01:02,690
there are two boxes at it there this

01:00:59,180 --> 01:01:04,640
panel is just displaying there's

01:01:02,690 --> 01:01:08,420
actually a dimension called service and

01:01:04,640 --> 01:01:10,640
in this case its value is monitoring but

01:01:08,420 --> 01:01:12,320
we've got really one alarm but they're

01:01:10,640 --> 01:01:14,180
being grouped different ways that what

01:01:12,320 --> 01:01:17,180
the top row is grouped by service and

01:01:14,180 --> 01:01:19,580
the bottom row is grouped by server in

01:01:17,180 --> 01:01:22,490
this case it's my vm the vm name is

01:01:19,580 --> 01:01:24,500
devstack so i can go look at the alarms

01:01:22,490 --> 01:01:27,590
and there it is and it's in this

01:01:24,500 --> 01:01:29,720
undetermined state because i said the

01:01:27,590 --> 01:01:31,550
average of this metric over time and we

01:01:29,720 --> 01:01:34,460
don't have enough values to actually

01:01:31,550 --> 01:01:38,150
evaluate that average yet so this will

01:01:34,460 --> 01:01:40,190
transition to pry the warning state in a

01:01:38,150 --> 01:01:44,810
minute or two which I'm not going to

01:01:40,190 --> 01:01:49,040
have time to show apparently so that's

01:01:44,810 --> 01:01:52,220
basically everything I have for today

01:01:49,040 --> 01:01:53,900
then a really short demo but gives you a

01:01:52,220 --> 01:01:56,780
flavor of what we've done in terms of

01:01:53,900 --> 01:01:58,820
integration of OpenStack and what

01:01:56,780 --> 01:02:02,690
capabilities are in the user interface

01:01:58,820 --> 01:02:06,860
and what Griffin I can do I didn't show

01:02:02,690 --> 01:02:10,100
any log stash or Cabana running but you

01:02:06,860 --> 01:02:12,920
can do similar sorts of things with

01:02:10,100 --> 01:02:15,530
logging messages there that's it but

01:02:12,920 --> 01:02:17,590
thank you everyone

01:02:15,530 --> 01:02:17,590

YouTube URL: https://www.youtube.com/watch?v=v2UmvB6EE38


