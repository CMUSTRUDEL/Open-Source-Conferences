Title: OSMC 2016 | Friends and foes in API Monitoring (EN) by Dr. Heinrich Hartmann
Publication date: 2016-12-12
Playlist: OSMC 2016 | Open Source Monitoring Conference
Description: 
	APIs are everywhere. In modern (micro) service oriented architectures they become the central entity that needs to be monitored. Questions that need to be answered include:

- Is user experience degraded for some of our customers?
- What is the likely cause of the service degradation?
- What are the business implications of a service degradation?

Answering these questions is not straight forward and requires careful choice of metrics, as well as awareness of several statistical pitfalls. In the talk, we will discuss several approaches for monitoring APIs, point out common missconceptions in reading API metrics and show how histograms can be used to extract correct and robust service level statistics from APIs.
Captions: 
	00:00:09,599 --> 00:00:15,150
so welcome everyone to our next talk

00:00:12,660 --> 00:00:16,740
dr. Heinrich Hoffmann will tell us about

00:00:15,150 --> 00:00:20,490
the friends and foes and hope the

00:00:16,740 --> 00:00:27,000
technical ones in monitoring api's give

00:00:20,490 --> 00:00:27,570
him a welcome applause thank you very

00:00:27,000 --> 00:00:29,910
much

00:00:27,570 --> 00:00:31,769
you always note that you are at a German

00:00:29,910 --> 00:00:34,410
conference when they say the doctor in

00:00:31,769 --> 00:00:35,760
front of your name as well but it's a

00:00:34,410 --> 00:00:36,750
great opportunity to hear thank you

00:00:35,760 --> 00:00:39,050
thank you very much to the organizers

00:00:36,750 --> 00:00:41,460
and thanks for showing up to the talk

00:00:39,050 --> 00:00:43,949
yeah I'm going to talk about monitoring

00:00:41,460 --> 00:00:45,989
api's before I do I

00:00:43,949 --> 00:00:48,750
I just wanted to give you a brief

00:00:45,989 --> 00:00:52,170
introduction about myself like this is

00:00:48,750 --> 00:00:55,260
how I look you might have guessed by me

00:00:52,170 --> 00:00:57,210
being here my background is I'm a

00:00:55,260 --> 00:00:59,340
mathematician I did a PhD in pure

00:00:57,210 --> 00:01:01,199
mathematics a while back in inborn

00:00:59,340 --> 00:01:03,180
I'm originally from mines shelves from

00:01:01,199 --> 00:01:07,369
the vine Valley I've spent most of my my

00:01:03,180 --> 00:01:10,680
my life near the Rhine after like a

00:01:07,369 --> 00:01:13,979
pretty extended journey in academia I

00:01:10,680 --> 00:01:16,830
finally switched to two IT and to system

00:01:13,979 --> 00:01:18,869
administration and IT infrastructure it

00:01:16,830 --> 00:01:21,509
was like a interesting journey you can

00:01:18,869 --> 00:01:23,369
ask me over at a beer tonight how that

00:01:21,509 --> 00:01:25,380
precisely went but right now I'm the

00:01:23,369 --> 00:01:28,380
analytics lead for a monitoring company

00:01:25,380 --> 00:01:32,700
called SoCo knows who of you has heard

00:01:28,380 --> 00:01:36,360
of SoCo knows for perfect

00:01:32,700 --> 00:01:38,369
so more than I expected this is the

00:01:36,360 --> 00:01:41,750
perfect excuse to just say two or three

00:01:38,369 --> 00:01:45,330
more words about the conus because I

00:01:41,750 --> 00:01:46,709
it's actually a pretty nice from product

00:01:45,330 --> 00:01:49,770
and pretty nice platform that is a

00:01:46,709 --> 00:01:51,660
little bit not so well known so yeah

00:01:49,770 --> 00:01:53,550
right we are an analytics vendor or a

00:01:51,660 --> 00:01:55,500
monitoring vendor we have a SAS product

00:01:53,550 --> 00:01:56,580
and actually an on-premise product that

00:01:55,500 --> 00:01:59,670
you can use to monitor your

00:01:56,580 --> 00:02:02,940
infrastructure we are actually pretty

00:01:59,670 --> 00:02:04,979
old so we are from 2010 we were one of

00:02:02,940 --> 00:02:07,410
the first companies who did monitoring

00:02:04,979 --> 00:02:08,970
as a SAS product back then when the

00:02:07,410 --> 00:02:10,349
infrastructure landscape looked very

00:02:08,970 --> 00:02:11,670
different from it is now we were

00:02:10,349 --> 00:02:13,680
basically competing vanagas

00:02:11,670 --> 00:02:15,569
back then and right now we're still

00:02:13,680 --> 00:02:18,959
competing but Nagios but also with other

00:02:15,569 --> 00:02:20,940
people we come we are a spin-off from a

00:02:18,959 --> 00:02:23,970
consulting company called Omni tea I

00:02:20,940 --> 00:02:26,520
also Washington dc-based which

00:02:23,970 --> 00:02:28,920
specialized in Postgres monitoring

00:02:26,520 --> 00:02:30,960
it's OCONUS was a spinoff because our

00:02:28,920 --> 00:02:33,510
founder just couldn't stand the pain

00:02:30,960 --> 00:02:35,670
anymore of using this tools back then to

00:02:33,510 --> 00:02:37,610
to monitor their infrastructure so he

00:02:35,670 --> 00:02:42,090
decided he has to build something else

00:02:37,610 --> 00:02:45,180
and so the culture within our company is

00:02:42,090 --> 00:02:48,990
very engineering focused and engineering

00:02:45,180 --> 00:02:50,370
heavy so we basically build most of our

00:02:48,990 --> 00:02:52,890
infrastructure completely on our own

00:02:50,370 --> 00:02:55,470
first thing is we run our own operating

00:02:52,890 --> 00:02:57,810
system it's called Omni OS which is a

00:02:55,470 --> 00:03:00,500
product of the company only TI which we

00:02:57,810 --> 00:03:03,810
are spin-off off its a lot Alerus based

00:03:00,500 --> 00:03:05,940
operating system which has like ZFS and

00:03:03,810 --> 00:03:07,980
zones as core features of Solaris some

00:03:05,940 --> 00:03:09,720
of you will know zones is the stuff

00:03:07,980 --> 00:03:12,240
which is now called docker and

00:03:09,720 --> 00:03:14,760
containers it's been in Solaris for 10

00:03:12,240 --> 00:03:17,640
years plus 15 years maybe so all that

00:03:14,760 --> 00:03:19,500
we've been using this for a while we

00:03:17,640 --> 00:03:22,650
have our own in-house database it's

00:03:19,500 --> 00:03:25,140
basically a time series data base which

00:03:22,650 --> 00:03:27,390
is Cassandra like highly scalable vfo

00:03:25,140 --> 00:03:29,340
unhewn system we have like build a ton

00:03:27,390 --> 00:03:32,850
of things on our own a very very

00:03:29,340 --> 00:03:34,440
engineering focused company and we are

00:03:32,850 --> 00:03:35,940
actually using our own tools of course

00:03:34,440 --> 00:03:38,850
to monitor our own infrastructure as

00:03:35,940 --> 00:03:40,230
well so this is a little bit in contrast

00:03:38,850 --> 00:03:42,690
and I have to had this discussion that

00:03:40,230 --> 00:03:45,420
with Avishai who is here today as well

00:03:42,690 --> 00:03:47,430
it's very much in contrast with what for

00:03:45,420 --> 00:03:49,050
people nowadays do like we see a lot of

00:03:47,430 --> 00:03:52,710
people who go to the cloud and have a

00:03:49,050 --> 00:03:56,250
wreath in application stack on their own

00:03:52,710 --> 00:03:58,200
and try to outsource everything else we

00:03:56,250 --> 00:03:59,790
do the opposite thing if we just have

00:03:58,200 --> 00:04:01,740
everything build out ourselves

00:03:59,790 --> 00:04:04,530
which has advantages and disadvantages

00:04:01,740 --> 00:04:07,170
but it's also monitoring is a very

00:04:04,530 --> 00:04:09,510
different type of stuff you do then

00:04:07,170 --> 00:04:11,820
operating a web store or something like

00:04:09,510 --> 00:04:14,130
that it's very different type of read

00:04:11,820 --> 00:04:15,859
load and write loaded you're serving so

00:04:14,130 --> 00:04:17,820
it might be it might be interesting

00:04:15,859 --> 00:04:20,250
trade-off actually it works quite well

00:04:17,820 --> 00:04:22,049
for us so one thing that we can do well

00:04:20,250 --> 00:04:25,130
this we are extremely cost efficient our

00:04:22,049 --> 00:04:29,130
infrastructure so we have clients which

00:04:25,130 --> 00:04:32,640
push like like we had one which was was

00:04:29,130 --> 00:04:35,130
doing like around the scale of 50

00:04:32,640 --> 00:04:37,800
million metrics and they were using 60

00:04:35,130 --> 00:04:40,050
nodes for doing their monitoring so we

00:04:37,800 --> 00:04:42,599
cut that down to seven nodes

00:04:40,050 --> 00:04:44,250
with our own database so like their the

00:04:42,599 --> 00:04:45,750
scaling effects are there and it's its

00:04:44,250 --> 00:04:49,979
dependent because we controlled

00:04:45,750 --> 00:04:51,300
everything on the full stack so advanced

00:04:49,979 --> 00:04:52,710
analytics I will talk about this a

00:04:51,300 --> 00:04:54,300
little bit more and show you a few

00:04:52,710 --> 00:04:56,460
things that we can do with different

00:04:54,300 --> 00:04:58,650
parts it has forecasting method it has

00:04:56,460 --> 00:05:00,629
anomaly detection outlier detection and

00:04:58,650 --> 00:05:03,330
a query language that we call capable

00:05:00,629 --> 00:05:08,460
and below here I put some of our

00:05:03,330 --> 00:05:10,979
customers right so right so I misused

00:05:08,460 --> 00:05:14,220
are actually shamelessly used this time

00:05:10,979 --> 00:05:17,130
I had here to talk about our offerings

00:05:14,220 --> 00:05:18,539
that we have as a as a product but

00:05:17,130 --> 00:05:19,949
actually it's an open source conference

00:05:18,539 --> 00:05:22,289
so I just wanted to say we actually

00:05:19,949 --> 00:05:24,090
consume open source and we contribute

00:05:22,289 --> 00:05:27,840
open source as well I mean first of all

00:05:24,090 --> 00:05:29,280
I'm the OS is a open source operating

00:05:27,840 --> 00:05:32,610
system that you can also download

00:05:29,280 --> 00:05:34,400
yourself and we have a few tools

00:05:32,610 --> 00:05:36,900
available in the monitoring landscape

00:05:34,400 --> 00:05:39,440
which are interesting they don't have a

00:05:36,900 --> 00:05:42,000
terribly high uptake but they are used

00:05:39,440 --> 00:05:44,009
like by us extensively and then some

00:05:42,000 --> 00:05:44,759
some other people as well so first of

00:05:44,009 --> 00:05:47,190
all is nad

00:05:44,759 --> 00:05:53,659
it's a node-based lightweight monitoring

00:05:47,190 --> 00:05:56,340
agent which is actually pretty neat so

00:05:53,659 --> 00:05:58,650
first of all the extensibility aspects

00:05:56,340 --> 00:06:01,490
of it are pretty nice and here's a thing

00:05:58,650 --> 00:06:06,020
I'll just briefly talk about there is a

00:06:01,490 --> 00:06:08,099
ongoing debate about push versus pull in

00:06:06,020 --> 00:06:10,710
monitoring so you can either either

00:06:08,099 --> 00:06:12,900
expose an HTTP port and you just pull

00:06:10,710 --> 00:06:15,389
the metrics out or you can point your

00:06:12,900 --> 00:06:18,120
agents at a centralized host and say

00:06:15,389 --> 00:06:20,880
please get the metrics in both have

00:06:18,120 --> 00:06:22,830
advantages and disadvantages one thing

00:06:20,880 --> 00:06:25,620
that is often confused is here that you

00:06:22,830 --> 00:06:27,810
are actually doing two things you are

00:06:25,620 --> 00:06:29,729
opening a connection and you are

00:06:27,810 --> 00:06:33,270
requesting data over that connection and

00:06:29,729 --> 00:06:36,150
you can switch the direction of those

00:06:33,270 --> 00:06:37,710
two you can decide which side initiates

00:06:36,150 --> 00:06:41,779
is the connection and which side

00:06:37,710 --> 00:06:45,750
initiates the or pulls the data and

00:06:41,779 --> 00:06:48,120
we've use for this agent a method we

00:06:45,750 --> 00:06:50,130
call reverse pull where the agent opens

00:06:48,120 --> 00:06:52,800
the connection and the server then

00:06:50,130 --> 00:06:53,700
requests the data this has very nice

00:06:52,800 --> 00:06:56,250
implication

00:06:53,700 --> 00:06:58,560
so it doesn't matter if you have behind

00:06:56,250 --> 00:07:00,420
that not your attack surface is lower

00:06:58,560 --> 00:07:03,480
because they don't expose it to port the

00:07:00,420 --> 00:07:04,920
agent opens the connection but the

00:07:03,480 --> 00:07:07,890
monitoring system has the ability

00:07:04,920 --> 00:07:11,430
control to control the data collection

00:07:07,890 --> 00:07:13,500
cadence so for example if you do

00:07:11,430 --> 00:07:16,260
real-time dashboards you might want to

00:07:13,500 --> 00:07:17,730
have one second cadence so if you're

00:07:16,260 --> 00:07:19,800
debugging something you want to know

00:07:17,730 --> 00:07:21,480
every second what's going on and this

00:07:19,800 --> 00:07:24,000
stuff you can can do nicely with the

00:07:21,480 --> 00:07:26,190
reverse pull okay

00:07:24,000 --> 00:07:28,320
then there's reconnoiter which is are

00:07:26,190 --> 00:07:29,700
what we call broker also very

00:07:28,320 --> 00:07:31,170
interesting piece of technologies which

00:07:29,700 --> 00:07:32,940
allow us to aggregate metrics and stream

00:07:31,170 --> 00:07:37,500
them forward and also run checks on its

00:07:32,940 --> 00:07:40,860
own this is a FQ that's a message queue

00:07:37,500 --> 00:07:44,300
let m2 F it's a c-level application

00:07:40,860 --> 00:07:46,680
framework we use heavily inside our own

00:07:44,300 --> 00:07:49,890
infrastructure it's a little bit bad

00:07:46,680 --> 00:07:52,710
documented but it's also like really a

00:07:49,890 --> 00:07:56,850
power horse and then there is lip circle

00:07:52,710 --> 00:07:58,830
hist it's a histogram tool and I will

00:07:56,850 --> 00:08:00,990
talk a little bit about that later this

00:07:58,830 --> 00:08:04,680
is also available open source and

00:08:00,990 --> 00:08:07,950
actually today is a very important day

00:08:04,680 --> 00:08:11,040
for us as a company as well and right

00:08:07,950 --> 00:08:14,100
here right now is the time where we will

00:08:11,040 --> 00:08:18,240
announce a big release of a new product

00:08:14,100 --> 00:08:19,530
which is called IMDB it actually fits

00:08:18,240 --> 00:08:21,420
this purpose very well I didn't really

00:08:19,530 --> 00:08:22,920
know that I was we would be speaking

00:08:21,420 --> 00:08:27,360
here today to actually make that

00:08:22,920 --> 00:08:29,820
announcement because it's a it's a time

00:08:27,360 --> 00:08:32,040
series back end for graphite so if you

00:08:29,820 --> 00:08:34,350
run graphite and you know you can do

00:08:32,040 --> 00:08:38,330
whisper files you can do carbon can do

00:08:34,350 --> 00:08:42,500
influx TB now you have a way to actually

00:08:38,330 --> 00:08:45,330
ingest graphite data data into our own

00:08:42,500 --> 00:08:47,760
proprietary time zeroes database and

00:08:45,330 --> 00:08:52,050
this is a distributor time series

00:08:47,760 --> 00:08:55,800
database which is like highly scalable

00:08:52,050 --> 00:08:58,200
can do millions of metrics and is from

00:08:55,800 --> 00:08:59,820
like you can install that on premise

00:08:58,200 --> 00:09:02,790
it's not a SAS product just to download

00:08:59,820 --> 00:09:04,590
it you need to run on the OS so at the

00:09:02,790 --> 00:09:06,390
moment you have on the u.s. packages for

00:09:04,590 --> 00:09:07,500
the for this we will have an ami for

00:09:06,390 --> 00:09:09,300
that soon so you

00:09:07,500 --> 00:09:11,330
just stand up in the amazon node and

00:09:09,300 --> 00:09:13,680
just say here point the metrics to it

00:09:11,330 --> 00:09:15,390
but it's it's distributed on the nose so

00:09:13,680 --> 00:09:19,860
you can can run as many nodes as you

00:09:15,390 --> 00:09:21,860
want the pricing is the first 25 metrics

00:09:19,860 --> 00:09:24,300
to get 25,000 metrics you get for free

00:09:21,860 --> 00:09:29,240
and then we have pricing steps of

00:09:24,300 --> 00:09:29,240
100,000 metrics and 100 million metrics

00:09:29,300 --> 00:09:35,190
this is so the first 25,000 metrics you

00:09:33,630 --> 00:09:37,320
get for free you can use as many nodes

00:09:35,190 --> 00:09:38,730
for this as you want you can use it on a

00:09:37,320 --> 00:09:40,080
single node but you can also have five

00:09:38,730 --> 00:09:42,150
nodes or something like that so you get

00:09:40,080 --> 00:09:44,430
the distribution aspect for this for

00:09:42,150 --> 00:09:46,770
free and if you are really buying a

00:09:44,430 --> 00:09:50,430
large account we will be at a price of

00:09:46,770 --> 00:09:54,240
one cent per metric per year this is

00:09:50,430 --> 00:09:57,210
yearly pricing so it's actually pretty

00:09:54,240 --> 00:09:59,280
cheap if you are going that scale right

00:09:57,210 --> 00:10:01,020
so I won't take too much time to about

00:09:59,280 --> 00:10:05,220
to talk more about this come approach me

00:10:01,020 --> 00:10:06,870
i we have a little bit of marketing

00:10:05,220 --> 00:10:08,160
material down there at the road so if

00:10:06,870 --> 00:10:09,810
you want to pick up a t-shirt like that

00:10:08,160 --> 00:10:12,420
or stickers we have it over there and

00:10:09,810 --> 00:10:19,680
and come come to me if you want to know

00:10:12,420 --> 00:10:22,710
more about it okay so API monitoring

00:10:19,680 --> 00:10:24,990
this talk is actually comes from a

00:10:22,710 --> 00:10:28,140
history of talks and topics we have been

00:10:24,990 --> 00:10:30,000
discussing in the last year it has been

00:10:28,140 --> 00:10:32,490
there has been I've been talking about

00:10:30,000 --> 00:10:35,340
statistics for engineers a lot we have

00:10:32,490 --> 00:10:37,620
I've written about much of this actually

00:10:35,340 --> 00:10:39,080
in the ACM queue and the CI CM

00:10:37,620 --> 00:10:41,220
communications of the ACM

00:10:39,080 --> 00:10:44,930
there there are two articles they're

00:10:41,220 --> 00:10:48,330
also called statistics for engineers and

00:10:44,930 --> 00:10:50,010
it's basically the story about how to

00:10:48,330 --> 00:10:51,840
apply statistics in the monitoring

00:10:50,010 --> 00:10:55,140
domain and it's how to do that well and

00:10:51,840 --> 00:10:57,480
it's particularly relevant for api's so

00:10:55,140 --> 00:10:59,160
I will have the slides online soon and

00:10:57,480 --> 00:11:01,410
you can can have a look at the

00:10:59,160 --> 00:11:03,150
references there as well but this is not

00:11:01,410 --> 00:11:05,790
coming from the vacuum this is actually

00:11:03,150 --> 00:11:08,700
a a long time effort we have to to talk

00:11:05,790 --> 00:11:11,400
about how to do statistics properly and

00:11:08,700 --> 00:11:15,290
how to read the data that is emitted and

00:11:11,400 --> 00:11:17,850
stored in your monitoring system so to

00:11:15,290 --> 00:11:20,940
make this a little bit more plastic I

00:11:17,850 --> 00:11:23,490
have chosen to use

00:11:20,940 --> 00:11:25,230
example use case we can all relate to so

00:11:23,490 --> 00:11:29,940
this is a completely frictional web

00:11:25,230 --> 00:11:33,170
fashion store called solando which store

00:11:29,940 --> 00:11:35,850
like surfs fashion products and it has a

00:11:33,170 --> 00:11:38,070
catalog which it serves over a web api

00:11:35,850 --> 00:11:39,780
and they have this funny property that

00:11:38,070 --> 00:11:42,180
they lose money if the request is take

00:11:39,780 --> 00:11:44,100
too long I mean many people will be able

00:11:42,180 --> 00:11:48,270
to rate to this the site is slow and

00:11:44,100 --> 00:11:49,950
it's a problem and this is just an

00:11:48,270 --> 00:11:50,970
example I mean API so basically

00:11:49,950 --> 00:11:53,310
everywhere and they're getting more and

00:11:50,970 --> 00:11:54,810
more important but right now this is the

00:11:53,310 --> 00:11:57,330
easiest example you just serve web

00:11:54,810 --> 00:11:59,700
requests what do you want to do with the

00:11:57,330 --> 00:12:01,380
monitoring um I think the first and the

00:11:59,700 --> 00:12:02,820
most important thing is that you want to

00:12:01,380 --> 00:12:05,370
measure the user experience that you

00:12:02,820 --> 00:12:06,990
have you don't really care if the data

00:12:05,370 --> 00:12:09,210
center is burning to use this famous

00:12:06,990 --> 00:12:10,710
method metaphor is as long as the users

00:12:09,210 --> 00:12:12,560
being served so you know we didn't

00:12:10,710 --> 00:12:15,450
understand how your users are behaving

00:12:12,560 --> 00:12:17,880
you wanna like assess quality of service

00:12:15,450 --> 00:12:20,340
if you have a formalized SLA or

00:12:17,880 --> 00:12:23,880
something like that's um to measure the

00:12:20,340 --> 00:12:29,730
user experience you won't always be able

00:12:23,880 --> 00:12:31,800
to serve perfect quality service so you

00:12:29,730 --> 00:12:33,510
might want to know where's the problem

00:12:31,800 --> 00:12:35,040
and help to locate this this is actually

00:12:33,510 --> 00:12:37,530
not on the slide but that's a very

00:12:35,040 --> 00:12:39,960
important property of that and you want

00:12:37,530 --> 00:12:42,270
to be able to negotiate on some level of

00:12:39,960 --> 00:12:45,000
service degradation you want to allow

00:12:42,270 --> 00:12:47,040
and have some budgets with the engineer

00:12:45,000 --> 00:12:49,440
so they can trade off like fast-paced

00:12:47,040 --> 00:12:50,970
development versus high quality of

00:12:49,440 --> 00:12:53,070
service right if you don't change your

00:12:50,970 --> 00:12:55,830
code then it's may easier to have good

00:12:53,070 --> 00:12:58,950
response times so these are like broadly

00:12:55,830 --> 00:13:00,690
the goals right and what I will do here

00:12:58,950 --> 00:13:02,820
is I will take you to a journey how you

00:13:00,690 --> 00:13:05,190
will might start out with trying to

00:13:02,820 --> 00:13:08,790
achieve that goal and do that and and

00:13:05,190 --> 00:13:10,710
talk about the pitfalls and then explain

00:13:08,790 --> 00:13:14,420
some some things we can do better and

00:13:10,710 --> 00:13:20,040
you can can do worse so very first thing

00:13:14,420 --> 00:13:22,470
you might want to do with this API so

00:13:20,040 --> 00:13:24,570
you want to apply external monitoring to

00:13:22,470 --> 00:13:27,120
it external monitoring is the notion

00:13:24,570 --> 00:13:29,820
that you have an agent sitting somewhere

00:13:27,120 --> 00:13:31,530
on a different server outside of your

00:13:29,820 --> 00:13:33,210
infrastructure and it reaches out to

00:13:31,530 --> 00:13:34,620
your servers every minute or every

00:13:33,210 --> 00:13:37,770
collection interval

00:13:34,620 --> 00:13:40,830
and makes a request and then it measures

00:13:37,770 --> 00:13:45,030
is this at all working is your side up

00:13:40,830 --> 00:13:48,740
and if so what's the latency and this

00:13:45,030 --> 00:13:53,910
are the diagrams usually see if you are

00:13:48,740 --> 00:13:56,700
if you are doing that it's actually good

00:13:53,910 --> 00:13:58,980
for measuring of availability it's a

00:13:56,700 --> 00:14:01,590
good to alert on outages this is the

00:13:58,980 --> 00:14:03,810
very first thing you should just do it's

00:14:01,590 --> 00:14:06,510
actually pretty bad for measuring user

00:14:03,810 --> 00:14:08,490
experience so because actually you're

00:14:06,510 --> 00:14:10,140
not measuring any user but you're really

00:14:08,490 --> 00:14:12,330
measuring is just a robot coming to your

00:14:10,140 --> 00:14:14,370
side and very often you just hit the

00:14:12,330 --> 00:14:17,070
front page it has just it slash the

00:14:14,370 --> 00:14:18,810
route which is served from cache most of

00:14:17,070 --> 00:14:22,410
the time so this durations here usually

00:14:18,810 --> 00:14:23,970
are just a measure for the the network

00:14:22,410 --> 00:14:27,180
performance between you and the

00:14:23,970 --> 00:14:29,760
monitoring agent so it certainly has

00:14:27,180 --> 00:14:34,890
some problems but there's actually a far

00:14:29,760 --> 00:14:39,330
more severe problem then the well

00:14:34,890 --> 00:14:41,550
actually they have few problems so let's

00:14:39,330 --> 00:14:43,110
talk about this one this is a funny

00:14:41,550 --> 00:14:47,310
thing maybe I can demo this right away

00:14:43,110 --> 00:14:52,910
so this is how the crest latency graph

00:14:47,310 --> 00:14:56,640
looks like on a instead it is very slow

00:14:52,910 --> 00:15:00,090
yeah there we go so this is how it look

00:14:56,640 --> 00:15:01,680
the data looks like on a very high

00:15:00,090 --> 00:15:03,360
granularity you have this measurements

00:15:01,680 --> 00:15:10,920
of maybe fifteen or twenty milliseconds

00:15:03,360 --> 00:15:14,820
if I go to a two hour range then oh yeah

00:15:10,920 --> 00:15:19,860
network is just terrible yeah good that

00:15:14,820 --> 00:15:21,540
I have screenshots great yeah so you saw

00:15:19,860 --> 00:15:25,620
these see the full data but it should if

00:15:21,540 --> 00:15:26,850
you go back like four weeks and more you

00:15:25,620 --> 00:15:29,220
won't be able to see the actual data

00:15:26,850 --> 00:15:35,580
anymore and many people don't realize

00:15:29,220 --> 00:15:37,830
this if you look at the values here the

00:15:35,580 --> 00:15:41,040
the scaling also adjusts but this is a

00:15:37,830 --> 00:15:42,870
four here right this is not a 20 that we

00:15:41,040 --> 00:15:45,450
have seen here we have the data from the

00:15:42,870 --> 00:15:48,540
last two RSA over here the values are

00:15:45,450 --> 00:15:52,920
much lower than what we see before

00:15:48,540 --> 00:15:55,530
so why is this it looks crazy if you go

00:15:52,920 --> 00:15:58,110
back more it's even worse and this this

00:15:55,530 --> 00:16:01,800
is a year scale off of data just worth

00:15:58,110 --> 00:16:03,810
of data so the basic problem is we are

00:16:01,800 --> 00:16:06,510
displaying here a total of maybe five

00:16:03,810 --> 00:16:12,600
hundred values across the x-axis and we

00:16:06,510 --> 00:16:16,350
collected 1,400 data points per day

00:16:12,600 --> 00:16:17,700
which is times 300 around four hundred

00:16:16,350 --> 00:16:20,130
five hundred thousand data points we

00:16:17,700 --> 00:16:23,130
have for the year so we are going back

00:16:20,130 --> 00:16:25,110
from 500,000 to 500 at appoints this

00:16:23,130 --> 00:16:27,510
means every data point we display here

00:16:25,110 --> 00:16:30,900
this is an ever aggregate of 1000 data

00:16:27,510 --> 00:16:32,310
points so you have to make choices and

00:16:30,900 --> 00:16:35,820
what's the usual choice well we just

00:16:32,310 --> 00:16:38,190
take the average it's um and the actual

00:16:35,820 --> 00:16:40,050
average data doesn't need necessarily

00:16:38,190 --> 00:16:42,150
have much to do with the original data

00:16:40,050 --> 00:16:45,960
so you see what kind of variance you

00:16:42,150 --> 00:16:48,060
have in there and that's actually a yeah

00:16:45,960 --> 00:16:50,070
so taking the average was just doing

00:16:48,060 --> 00:16:52,130
gross injustice to your to your data

00:16:50,070 --> 00:16:55,140
here you're seeing a lot of effects and

00:16:52,130 --> 00:16:57,300
actually things I always complain a

00:16:55,140 --> 00:17:00,230
little bad about lying graphs so you

00:16:57,300 --> 00:17:04,530
know it here that we are that we are

00:17:00,230 --> 00:17:06,780
just using um discrete steps and not

00:17:04,530 --> 00:17:08,370
disconnected lines as Anna does for

00:17:06,780 --> 00:17:11,520
example or like many other products do

00:17:08,370 --> 00:17:14,190
for this kind of measurements drawing a

00:17:11,520 --> 00:17:17,370
continuous line between those two things

00:17:14,190 --> 00:17:19,170
is completely meaningless it's just it

00:17:17,370 --> 00:17:21,810
was two-week fests we happen to be at a

00:17:19,170 --> 00:17:23,339
certain time there's no guarantee that a

00:17:21,810 --> 00:17:25,079
request which have been like on the

00:17:23,339 --> 00:17:27,390
30-second mark here would have a latency

00:17:25,079 --> 00:17:29,190
somewhere in the middle so there's

00:17:27,390 --> 00:17:31,110
there's really no point here so the best

00:17:29,190 --> 00:17:34,020
way to represent this would actually be

00:17:31,110 --> 00:17:36,900
a just dots saying I had some samples

00:17:34,020 --> 00:17:39,360
here if you do that you can do that

00:17:36,900 --> 00:17:41,100
actually with the tool and then you can

00:17:39,360 --> 00:17:44,630
also draw much more data points you

00:17:41,100 --> 00:17:47,510
don't necessarily just have to war the

00:17:44,630 --> 00:17:52,920
the let me drive you can do that life

00:17:47,510 --> 00:17:54,900
you don't do not necessarily only have

00:17:52,920 --> 00:17:56,700
to draw the the roll-ups but you can you

00:17:54,900 --> 00:17:59,340
can just show all the data that you have

00:17:56,700 --> 00:18:01,560
in there so you will see a lot of

00:17:59,340 --> 00:18:02,460
sprinkles over where around which is

00:18:01,560 --> 00:18:05,059
actually just

00:18:02,460 --> 00:18:08,190
for the individual measurements and

00:18:05,059 --> 00:18:10,080
actually um with Sue Kona's we have this

00:18:08,190 --> 00:18:13,559
funny property that we don't throw away

00:18:10,080 --> 00:18:16,830
data ever so we just store the

00:18:13,559 --> 00:18:19,139
one-minute data for years and it means

00:18:16,830 --> 00:18:21,210
that even like a few days back it's

00:18:19,139 --> 00:18:23,309
really hard to see here but the idea is

00:18:21,210 --> 00:18:24,809
that you have for this interval which is

00:18:23,309 --> 00:18:27,210
a 20-minute interval you actually have

00:18:24,809 --> 00:18:29,940
20 measurements and you have two modes

00:18:27,210 --> 00:18:31,529
and you have some outliers so this is

00:18:29,940 --> 00:18:34,289
how your data actually looks like and

00:18:31,529 --> 00:18:35,940
and you can use this histogram education

00:18:34,289 --> 00:18:37,679
method we call in history aggregation to

00:18:35,940 --> 00:18:40,289
do that and I did put it here on the

00:18:37,679 --> 00:18:42,240
slide so you see your the modes again so

00:18:40,289 --> 00:18:44,039
here's the the lower mode here's the

00:18:42,240 --> 00:18:45,840
outliers then the mean value will

00:18:44,039 --> 00:18:47,879
fluctuate somewhere in between and if

00:18:45,840 --> 00:18:51,869
you look at the maximum values over some

00:18:47,879 --> 00:18:53,730
one day intervals and it's up there so

00:18:51,869 --> 00:18:56,039
basically if you are looking at this

00:18:53,730 --> 00:18:58,019
kind of latency graphs at a scale of

00:18:56,039 --> 00:19:00,330
weeks you have actually no idea how the

00:18:58,019 --> 00:19:03,509
actual measurements look like and this

00:19:00,330 --> 00:19:06,330
is a pretty serious issue with a lot of

00:19:03,509 --> 00:19:08,999
graphs you see and actually if you throw

00:19:06,330 --> 00:19:10,850
away your um your one-minute data and

00:19:08,999 --> 00:19:14,129
roll it up and only store the roll-ups

00:19:10,850 --> 00:19:21,360
you are in the completely blind to these

00:19:14,129 --> 00:19:23,190
kinds of effects right great stuff so we

00:19:21,360 --> 00:19:27,320
have a so far only talked about a very

00:19:23,190 --> 00:19:30,659
very basic way of monitoring which is

00:19:27,320 --> 00:19:33,149
which is just external monitoring

00:19:30,659 --> 00:19:36,929
pinging the service from from the

00:19:33,149 --> 00:19:41,309
outside log analysis and log files might

00:19:36,929 --> 00:19:44,070
be the the ultimate thing for for

00:19:41,309 --> 00:19:48,749
monitoring log files are unbelievably

00:19:44,070 --> 00:19:52,289
great basic idea is every time you make

00:19:48,749 --> 00:19:53,850
a request you write a lock out with some

00:19:52,289 --> 00:19:56,519
basic information about that request

00:19:53,850 --> 00:19:58,919
including the time of completion the

00:19:56,519 --> 00:20:00,600
request latency basically usually you

00:19:58,919 --> 00:20:03,269
take the time of arrival not the time of

00:20:00,600 --> 00:20:06,360
completion how long it took and you can

00:20:03,269 --> 00:20:08,279
um add further metadata here you can do

00:20:06,360 --> 00:20:10,830
the HTTP return code you can do the full

00:20:08,279 --> 00:20:14,609
URL that was requested so it's very very

00:20:10,830 --> 00:20:16,230
much it's super trivial to add logging

00:20:14,609 --> 00:20:18,090
instrumentation well

00:20:16,230 --> 00:20:21,269
it's subtle but you can start with just

00:20:18,090 --> 00:20:26,159
printf which is like way more easy than

00:20:21,269 --> 00:20:29,240
other things and the only drawback with

00:20:26,159 --> 00:20:32,580
logging is that it can be pretty slow

00:20:29,240 --> 00:20:35,370
actually because it's so expensive on

00:20:32,580 --> 00:20:37,409
the data side so a log line maybe for

00:20:35,370 --> 00:20:39,870
primary characters if it's just verbose

00:20:37,409 --> 00:20:43,470
Jason or maybe you can get away with 200

00:20:39,870 --> 00:20:49,320
so it's 200 bytes a single float value

00:20:43,470 --> 00:20:53,039
is just 4 bytes or I think 4 bytes right

00:20:49,320 --> 00:20:54,690
so it's it's very heavier and you're not

00:20:53,039 --> 00:20:56,909
only collecting one every minute you

00:20:54,690 --> 00:20:58,440
might have thousands every minute this

00:20:56,909 --> 00:20:58,950
might actually work for it for

00:20:58,440 --> 00:21:01,679
low-volume

00:20:58,950 --> 00:21:03,870
API is very well if he is actually

00:21:01,679 --> 00:21:08,970
everywhere so what would you for example

00:21:03,870 --> 00:21:13,159
do is we collect IO latency 8 API state

00:21:08,970 --> 00:21:15,109
on Io latency api's for the block

00:21:13,159 --> 00:21:17,269
devices on every disk that we have in

00:21:15,109 --> 00:21:19,729
our data center this are like millions

00:21:17,269 --> 00:21:22,659
of requests every second that come in

00:21:19,729 --> 00:21:25,099
and this is an interesting API also

00:21:22,659 --> 00:21:27,109
syscalls are very interesting API to

00:21:25,099 --> 00:21:28,879
look at and you might think about just

00:21:27,109 --> 00:21:30,889
collecting latency information about all

00:21:28,879 --> 00:21:33,099
sis calls that you make I know that

00:21:30,889 --> 00:21:36,139
Cystic has some pretty nice

00:21:33,099 --> 00:21:38,629
visualizations and tooling for this and

00:21:36,139 --> 00:21:40,399
it's an a goal in actually also possible

00:21:38,629 --> 00:21:44,599
I'll talk about this data to collect it

00:21:40,399 --> 00:21:46,759
in a monitoring tool but you are you you

00:21:44,599 --> 00:21:49,099
cannot actually you can physically not

00:21:46,759 --> 00:21:51,080
collect syscall data with log files

00:21:49,099 --> 00:21:53,210
because we will make source codes for

00:21:51,080 --> 00:21:58,129
writing the log files for every Cisco so

00:21:53,210 --> 00:22:00,950
you will have a problem there but if you

00:21:58,129 --> 00:22:02,389
can afford to do logs and it's as fast

00:22:00,950 --> 00:22:04,129
enough for unisys and it's just a

00:22:02,389 --> 00:22:07,460
billion way because it conveys the full

00:22:04,129 --> 00:22:12,889
information that you have yet you have

00:22:07,460 --> 00:22:14,389
about your data or about the API the

00:22:12,889 --> 00:22:17,989
main drawback is that is just super

00:22:14,389 --> 00:22:21,559
expensive so what what I've put here on

00:22:17,989 --> 00:22:25,249
the chart is just um a way to visualize

00:22:21,559 --> 00:22:27,349
log data and to actually in get out the

00:22:25,249 --> 00:22:29,419
numerical digest what I would call it

00:22:27,349 --> 00:22:32,389
the numerical digest of the of the logs

00:22:29,419 --> 00:22:35,029
so I've years this is a timeline view of

00:22:32,389 --> 00:22:37,399
your your API you get a request coming

00:22:35,029 --> 00:22:39,379
in you get on the request going out and

00:22:37,399 --> 00:22:42,590
it took some some defined amount of time

00:22:39,379 --> 00:22:46,039
and actually at which point in time here

00:22:42,590 --> 00:22:50,210
with the log message be emitted if your

00:22:46,039 --> 00:22:52,279
request comes in this goes out at the

00:22:50,210 --> 00:22:53,869
end right important subtlety you only

00:22:52,279 --> 00:22:55,639
know how long the confess'd took if the

00:22:53,869 --> 00:22:58,519
request is finished you won't see in

00:22:55,639 --> 00:23:00,729
flight requests in your log all well at

00:22:58,519 --> 00:23:03,200
least if you do the standard stuff so

00:23:00,729 --> 00:23:04,729
actually if I if I want to do this

00:23:03,200 --> 00:23:06,710
request late entry chart which I

00:23:04,729 --> 00:23:09,529
introduced here you always want to put

00:23:06,710 --> 00:23:11,539
the the latency on the end because only

00:23:09,529 --> 00:23:13,159
then you know when the when the request

00:23:11,539 --> 00:23:14,899
finished so you can complete your chart

00:23:13,159 --> 00:23:18,229
to certain type team when you are at

00:23:14,899 --> 00:23:20,330
that time so and and visualizing in this

00:23:18,229 --> 00:23:23,570
this way you actually have a pretty good

00:23:20,330 --> 00:23:25,429
way to visualize your API complete API

00:23:23,570 --> 00:23:27,049
information latency information that you

00:23:25,429 --> 00:23:28,610
have you have the request

00:23:27,049 --> 00:23:30,769
time on the excess isn't have delight

00:23:28,610 --> 00:23:33,289
and see on the y-axis and this this

00:23:30,769 --> 00:23:35,419
charge gives you just a perfect overview

00:23:33,289 --> 00:23:41,419
about all numerical data that's in there

00:23:35,419 --> 00:23:43,070
and now you can ask some of my patients

00:23:41,419 --> 00:23:44,749
what to do with this data this is

00:23:43,070 --> 00:23:46,159
basically if you give them a chart like

00:23:44,749 --> 00:23:47,749
this they will be extremely happy

00:23:46,159 --> 00:23:51,950
because they know what they are dealing

00:23:47,749 --> 00:23:54,409
with so if I now have my mathematical

00:23:51,950 --> 00:23:56,659
hat on I will just just look at this and

00:23:54,409 --> 00:23:58,369
say well great I have all this latency

00:23:56,659 --> 00:23:59,989
information I will just forget when the

00:23:58,369 --> 00:24:02,090
requests arrived and project everything

00:23:59,989 --> 00:24:03,980
to the y-axis and then I have a lot of

00:24:02,090 --> 00:24:05,869
dots here on the y-axis and then I can

00:24:03,980 --> 00:24:08,239
maybe do a histogram so this is a

00:24:05,869 --> 00:24:10,669
latency recraft latency histogram here

00:24:08,239 --> 00:24:12,739
or I could the other thing I can do is

00:24:10,669 --> 00:24:14,299
just project to the x-axis and say well

00:24:12,739 --> 00:24:16,820
I don't care how long they would test

00:24:14,299 --> 00:24:19,090
actually took I just care when they

00:24:16,820 --> 00:24:23,109
arrived and this is here the realm of

00:24:19,090 --> 00:24:25,609
queueing Theory not completely about but

00:24:23,109 --> 00:24:27,710
stochastic processes like this might be

00:24:25,609 --> 00:24:29,779
a pulse on distribution you see here if

00:24:27,710 --> 00:24:32,090
also theory from that angle and the

00:24:29,779 --> 00:24:35,029
third angle which is just maybe an aside

00:24:32,090 --> 00:24:37,039
here the request for its whole duration

00:24:35,029 --> 00:24:38,600
might not actually be doing work most of

00:24:37,039 --> 00:24:40,820
the time but it might have it has been

00:24:38,600 --> 00:24:43,159
working waiting in a queue before it was

00:24:40,820 --> 00:24:46,539
actually like processed so you might

00:24:43,159 --> 00:24:49,820
have some some internal states that this

00:24:46,539 --> 00:24:54,049
requests had in the middle and if you

00:24:49,820 --> 00:24:55,429
want to go deep into the theory what's

00:24:54,049 --> 00:24:57,350
happening within the request then

00:24:55,429 --> 00:25:00,470
queuing theory is the angle you wanna

00:24:57,350 --> 00:25:02,179
you want to look at but this from this

00:25:00,470 --> 00:25:05,619
perspective you can you can see

00:25:02,179 --> 00:25:08,690
everything right

00:25:05,619 --> 00:25:10,609
this was the mathematicians view if you

00:25:08,690 --> 00:25:13,399
are going to your sales or your

00:25:10,609 --> 00:25:15,259
marketing team or you to your CEO he

00:25:13,399 --> 00:25:17,989
might actually have a pretty other view

00:25:15,259 --> 00:25:20,419
about this thing because actually every

00:25:17,989 --> 00:25:23,739
single week fest through your whole

00:25:20,419 --> 00:25:27,139
infrastructure it serves the purpose of

00:25:23,739 --> 00:25:29,749
serving your users if you are looking at

00:25:27,139 --> 00:25:32,989
HTTP requests every single HTTP request

00:25:29,749 --> 00:25:35,990
will be some user and they might be

00:25:32,989 --> 00:25:38,389
happy or less happy oh there might be

00:25:35,990 --> 00:25:41,400
the Googlebot and don't have emotions

00:25:38,389 --> 00:25:45,300
what they still want to be served

00:25:41,400 --> 00:25:46,590
so this is a thing that is it's just

00:25:45,300 --> 00:25:54,390
important to stress from time to time

00:25:46,590 --> 00:25:56,400
that every request has to do with user

00:25:54,390 --> 00:26:00,090
experience that always users waiting at

00:25:56,400 --> 00:26:01,980
the other end and what if you are just

00:26:00,090 --> 00:26:03,690
taking averages or talking about or the

00:26:01,980 --> 00:26:05,220
percentile was a little bit low it

00:26:03,690 --> 00:26:06,750
always means that you'll use a very

00:26:05,220 --> 00:26:08,700
affected so you should care about all

00:26:06,750 --> 00:26:10,350
your requests and don't throw away data

00:26:08,700 --> 00:26:21,560
about the requests and just just take

00:26:10,350 --> 00:26:25,440
care of every single one okay now

00:26:21,560 --> 00:26:26,940
basically we have seen what we can do

00:26:25,440 --> 00:26:29,070
with the logs and we have seen what we

00:26:26,940 --> 00:26:30,960
can do with the external monitoring with

00:26:29,070 --> 00:26:32,730
logs the problem is always it's

00:26:30,960 --> 00:26:34,500
sometimes you can just not afford use to

00:26:32,730 --> 00:26:37,230
the use logs because just looks like

00:26:34,500 --> 00:26:39,390
incredibly voluminous this is the one of

00:26:37,230 --> 00:26:43,080
the only ways to you can really get big

00:26:39,390 --> 00:26:45,300
data and and just analyzing high volume

00:26:43,080 --> 00:26:48,150
API is this just logs it's just very

00:26:45,300 --> 00:26:50,480
slow and very expensive so sometimes you

00:26:48,150 --> 00:26:55,590
can just can't do logs you need metrics

00:26:50,480 --> 00:26:57,270
right so what do you do with with API

00:26:55,590 --> 00:27:00,150
metrics what sensible choices do you

00:26:57,270 --> 00:27:02,430
have so one common choice is what you

00:27:00,150 --> 00:27:05,220
can use to monitor your API is to use

00:27:02,430 --> 00:27:09,510
mean values important thing to notice

00:27:05,220 --> 00:27:12,150
you have to first decide on what your

00:27:09,510 --> 00:27:15,450
reporting period is say a minute and you

00:27:12,150 --> 00:27:17,370
take all requests that came in ten

00:27:15,450 --> 00:27:19,680
minutes and you look at the or completed

00:27:17,370 --> 00:27:22,260
in that minute actually um and then you

00:27:19,680 --> 00:27:23,940
take the average of all the latencies

00:27:22,260 --> 00:27:26,760
that were observed so average is this

00:27:23,940 --> 00:27:29,880
nice formula just the sum divided by the

00:27:26,760 --> 00:27:33,780
number it's great and you can use that

00:27:29,880 --> 00:27:35,610
for monitoring yeah so this has the

00:27:33,780 --> 00:27:38,400
great advantage that you are actually

00:27:35,610 --> 00:27:41,070
measuring your users this is not

00:27:38,400 --> 00:27:43,410
completely artificial data if users are

00:27:41,070 --> 00:27:47,340
requesting sites which load slowly then

00:27:43,410 --> 00:27:49,350
this average will go up it's very cheap

00:27:47,340 --> 00:27:52,710
to collect and compare to log files just

00:27:49,350 --> 00:27:54,250
a single data point per minute the the

00:27:52,710 --> 00:27:55,330
problems are that the that

00:27:54,250 --> 00:27:57,130
you're compressing a lot of information

00:27:55,330 --> 00:27:59,650
into a single value and there's the

00:27:57,130 --> 00:28:01,600
famous quote by by Optimizely doggin

00:27:59,650 --> 00:28:03,550
from Optimizely is measuring the average

00:28:01,600 --> 00:28:06,550
latency is like measuring the average

00:28:03,550 --> 00:28:07,450
temperature in the hospital so don't

00:28:06,550 --> 00:28:08,800
really care about the average

00:28:07,450 --> 00:28:10,810
temperature you care about the

00:28:08,800 --> 00:28:13,750
temperature of your patient which is

00:28:10,810 --> 00:28:15,310
dying in front of you and the average

00:28:13,750 --> 00:28:18,100
temperature might not help you so much

00:28:15,310 --> 00:28:20,320
there so it can get screwed in both

00:28:18,100 --> 00:28:22,200
directions you have the the one large

00:28:20,320 --> 00:28:24,640
value which could be just hours

00:28:22,200 --> 00:28:27,370
completed there will skew the average up

00:28:24,640 --> 00:28:29,530
a ton and actually you might have a lot

00:28:27,370 --> 00:28:32,230
of requests here on being stuff from

00:28:29,530 --> 00:28:34,240
cash if it's which skew the average to

00:28:32,230 --> 00:28:36,550
the low end so both things can happen

00:28:34,240 --> 00:28:40,360
you never really sure which about happen

00:28:36,550 --> 00:28:45,640
and actually the more funny effects so

00:28:40,360 --> 00:28:49,030
this is an API and then you see the the

00:28:45,640 --> 00:28:50,170
API so the mean value of the F in the

00:28:49,030 --> 00:28:52,990
eye light and see a computed over

00:28:50,170 --> 00:28:55,180
minutes it looks fairly okay here you

00:28:52,990 --> 00:28:57,280
sometimes see the the outliers so

00:28:55,180 --> 00:28:59,590
there's some one one request which took

00:28:57,280 --> 00:29:02,640
really long which drags that up and then

00:28:59,590 --> 00:29:04,990
you see complete madness here at besides

00:29:02,640 --> 00:29:10,980
somebody have an idea how how that

00:29:04,990 --> 00:29:13,120
madness might be caused yeah precisely

00:29:10,980 --> 00:29:15,550
you've seen that this is just at night

00:29:13,120 --> 00:29:16,840
so there's no volume on the API and then

00:29:15,550 --> 00:29:17,560
you're dividing by a number which is

00:29:16,840 --> 00:29:21,790
close to zero

00:29:17,560 --> 00:29:24,600
so anything can happen yeah you might

00:29:21,790 --> 00:29:31,480
not want to alert on the mean value here

00:29:24,600 --> 00:29:31,900
good so yeah so you want to do better

00:29:31,480 --> 00:29:33,520
than that

00:29:31,900 --> 00:29:36,460
and of course you all know about this

00:29:33,520 --> 00:29:39,700
already you can actually get rid of most

00:29:36,460 --> 00:29:41,800
of these problems by taking an instead

00:29:39,700 --> 00:29:45,580
of the mean value a median value which

00:29:41,800 --> 00:29:47,500
median is just take a central value out

00:29:45,580 --> 00:29:49,510
of here so that the amount of edges

00:29:47,500 --> 00:29:54,100
which are larger and that our lower is

00:29:49,510 --> 00:29:56,650
equal so it's a central value less

00:29:54,100 --> 00:30:00,160
unknown method is the so called

00:29:56,650 --> 00:30:03,310
truncated means so the idea is you

00:30:00,160 --> 00:30:05,920
interpolate between the mean value and

00:30:03,310 --> 00:30:08,169
the median value by throwing away the

00:30:05,920 --> 00:30:09,879
extreme values so your trunk

00:30:08,169 --> 00:30:11,950
hating your dataset by say you're

00:30:09,879 --> 00:30:13,840
throwing away a third or half of your

00:30:11,950 --> 00:30:17,200
requests and then you just take them in

00:30:13,840 --> 00:30:20,739
value here combine the advantages of of

00:30:17,200 --> 00:30:23,889
both both methods

00:30:20,739 --> 00:30:27,700
I've not seen used it a lot I don't

00:30:23,889 --> 00:30:30,249
think we offer it like directly in our

00:30:27,700 --> 00:30:32,919
tool but it's it's certainly a thing you

00:30:30,249 --> 00:30:34,899
should be aware of when you are

00:30:32,919 --> 00:30:37,830
designing such a system or working the

00:30:34,899 --> 00:30:41,909
best values that might might be a viable

00:30:37,830 --> 00:30:45,369
alternative to means or medians

00:30:41,909 --> 00:30:46,869
deviation measures are also interesting

00:30:45,369 --> 00:30:48,820
to look at if you want to know how much

00:30:46,869 --> 00:30:51,159
noise is in your data standard

00:30:48,820 --> 00:30:52,869
deviations are generally bad because

00:30:51,159 --> 00:30:55,869
they suffer from these very same

00:30:52,869 --> 00:30:57,909
problems with outliers they can affect

00:30:55,869 --> 00:30:59,529
the a standard deviation very heavily so

00:30:57,909 --> 00:31:01,690
a little bit better than that is the

00:30:59,529 --> 00:31:05,230
mean absolute deviation where you just

00:31:01,690 --> 00:31:06,730
sum be absolute deviations and not the

00:31:05,230 --> 00:31:10,889
squared absolute deviations that you

00:31:06,730 --> 00:31:10,889
would do for a standard deviation right

00:31:10,950 --> 00:31:15,129
okay so our next step is actually

00:31:13,389 --> 00:31:19,090
percent on monitoring and I know many of

00:31:15,129 --> 00:31:21,210
you are already doing this so the basic

00:31:19,090 --> 00:31:23,859
idea here is that instead of just

00:31:21,210 --> 00:31:27,700
reporting the mean value you want to get

00:31:23,859 --> 00:31:33,090
some more insight into the full

00:31:27,700 --> 00:31:35,679
distribution of your of your latencies

00:31:33,090 --> 00:31:37,809
so a percentile is basically a value

00:31:35,679 --> 00:31:40,570
which divides the data set in two parts

00:31:37,809 --> 00:31:42,519
for example in the 99th percentile the

00:31:40,570 --> 00:31:44,109
the upper part should be below one

00:31:42,519 --> 00:31:48,070
percent and the lower part should be

00:31:44,109 --> 00:31:50,559
below 99 percent and there's always a

00:31:48,070 --> 00:31:53,379
special case when you just hit precisely

00:31:50,559 --> 00:31:55,570
one sample then it will not up some up

00:31:53,379 --> 00:31:57,369
to ten here but it's only two nine so

00:31:55,570 --> 00:31:59,489
you the definition is actually more

00:31:57,369 --> 00:32:02,230
subtle than you might think and

00:31:59,489 --> 00:32:04,749
percentiles actually non-unique for a

00:32:02,230 --> 00:32:07,929
related reason so for example here the

00:32:04,749 --> 00:32:12,340
90th percentile can just be everything

00:32:07,929 --> 00:32:15,489
from here to here since on the the

00:32:12,340 --> 00:32:18,789
condition is always fulfilled dead less

00:32:15,489 --> 00:32:20,440
than 10% is above and more than ninety

00:32:18,789 --> 00:32:22,310
percent is less than ninety percent is

00:32:20,440 --> 00:32:24,110
below so you can go

00:32:22,310 --> 00:32:27,050
down to here or up to there it's all

00:32:24,110 --> 00:32:28,520
90th percentiles might be confusing

00:32:27,050 --> 00:32:31,160
might have thought that they're not just

00:32:28,520 --> 00:32:33,200
present or something unique well

00:32:31,160 --> 00:32:34,160
actually you can make that unique and

00:32:33,200 --> 00:32:36,320
just make a choice

00:32:34,160 --> 00:32:40,310
maybe you just say you always take half

00:32:36,320 --> 00:32:45,200
and Wikipedia lists eight different ways

00:32:40,310 --> 00:32:46,970
to make percentiles unique so always

00:32:45,200 --> 00:32:49,010
asks some questions which percentile are

00:32:46,970 --> 00:32:51,350
you meaning so it might actually not be

00:32:49,010 --> 00:32:53,360
well-defined at all so it's I mean if

00:32:51,350 --> 00:32:54,650
the value the volume is very high then

00:32:53,360 --> 00:32:56,780
usually there is not so much of a

00:32:54,650 --> 00:32:59,180
question but if you're just two data

00:32:56,780 --> 00:33:00,680
points it's actually a good exercise if

00:32:59,180 --> 00:33:04,970
you're just two data points what the

00:33:00,680 --> 00:33:08,390
33rd percenter of this just can be

00:33:04,970 --> 00:33:11,120
anything in between are actually should

00:33:08,390 --> 00:33:15,980
be the lower one fiftieth percentile can

00:33:11,120 --> 00:33:17,390
be anything because every every cut in

00:33:15,980 --> 00:33:18,560
the middle divides the data sent in half

00:33:17,390 --> 00:33:21,080
doesn't matter which well you could

00:33:18,560 --> 00:33:24,170
choose the 35th percentile is the lower

00:33:21,080 --> 00:33:26,510
and just only the low end but but

00:33:24,170 --> 00:33:28,700
anyways this is a fun exercise but it's

00:33:26,510 --> 00:33:29,990
more also more subtle and most people

00:33:28,700 --> 00:33:34,280
are aware of this definition of

00:33:29,990 --> 00:33:36,230
percentile right so what do you have to

00:33:34,280 --> 00:33:39,380
do to do percentile monitoring well you

00:33:36,230 --> 00:33:41,390
actually again very important you select

00:33:39,380 --> 00:33:43,520
your reporting period first you say

00:33:41,390 --> 00:33:49,250
which requests am I looking at a one

00:33:43,520 --> 00:33:52,490
minute slice then you measure the 50th

00:33:49,250 --> 00:33:55,160
90th 99 s 99.9% hell or whatever set of

00:33:52,490 --> 00:33:56,780
percentiles you choose and then for

00:33:55,160 --> 00:33:59,240
example you can use it for learning so

00:33:56,780 --> 00:34:05,390
you alert when it goes over the special

00:33:59,240 --> 00:34:07,520
value so some pros and cons pros are you

00:34:05,390 --> 00:34:10,640
again measure requests by actual people

00:34:07,520 --> 00:34:12,830
not synthetic requests it's pretty cheap

00:34:10,640 --> 00:34:14,930
to collect or analyze its robust to

00:34:12,830 --> 00:34:20,090
outliers so a single request doesn't

00:34:14,930 --> 00:34:23,060
affect the percent how much and so

00:34:20,090 --> 00:34:24,830
negatives are here upfront choice of

00:34:23,060 --> 00:34:26,330
percent house is needed so you need to

00:34:24,830 --> 00:34:28,670
know which percent else you're looking

00:34:26,330 --> 00:34:30,530
at and the second point percentiles

00:34:28,670 --> 00:34:33,320
cannot be aggregated and I talked about

00:34:30,530 --> 00:34:34,270
this a little more so this is how it

00:34:33,320 --> 00:34:37,639
looks

00:34:34,270 --> 00:34:40,310
so this is their 50th the 90s and the

00:34:37,639 --> 00:34:41,990
99th percentile so the lowest one

00:34:40,310 --> 00:34:44,200
directly competes with here so remember

00:34:41,990 --> 00:34:47,510
how that looked like

00:34:44,200 --> 00:34:49,730
and now the 50th percentile so 50th

00:34:47,510 --> 00:34:51,740
percentile you know it is this bikes to

00:34:49,730 --> 00:34:54,919
the top are gone so you're seeing this

00:34:51,740 --> 00:34:56,629
robustness here the 90th percentile is

00:34:54,919 --> 00:34:58,910
actually a little bit more fuzzy but it

00:34:56,629 --> 00:35:00,619
still looks pretty stable and the 99th

00:34:58,910 --> 00:35:03,770
percentile is just you see a lot of

00:35:00,619 --> 00:35:05,530
outliers going on so this is like at

00:35:03,770 --> 00:35:08,630
this point it gets a little bit fuzzy

00:35:05,530 --> 00:35:10,339
and this this also expected if you go

00:35:08,630 --> 00:35:12,349
higher you will see more noise because

00:35:10,339 --> 00:35:13,990
then the outliers will start to affect

00:35:12,349 --> 00:35:17,480
your percentile actually in that range

00:35:13,990 --> 00:35:19,609
interesting bit here at night times when

00:35:17,480 --> 00:35:21,380
the volume is low you still see all

00:35:19,609 --> 00:35:23,750
their problems so this problem just

00:35:21,380 --> 00:35:26,180
doesn't go away if you are using

00:35:23,750 --> 00:35:26,869
percentile monitoring the percentage of

00:35:26,180 --> 00:35:29,390
percentiles

00:35:26,869 --> 00:35:35,599
will be very high if you're just not

00:35:29,390 --> 00:35:38,210
seeing much requests yeah so then here's

00:35:35,599 --> 00:35:40,700
here's the point again percent house

00:35:38,210 --> 00:35:45,200
can't be aggregated and this is also a

00:35:40,700 --> 00:35:49,490
fact which is a little bit under rated

00:35:45,200 --> 00:35:51,829
or less well known in the community if

00:35:49,490 --> 00:35:53,780
you are you are computing let's say you

00:35:51,829 --> 00:35:55,790
if they have very many levels of

00:35:53,780 --> 00:35:57,260
aggregation that you are can look at for

00:35:55,790 --> 00:35:58,609
example if I have a one minute period

00:35:57,260 --> 00:36:00,920
here and the one minute period here

00:35:58,609 --> 00:36:03,109
right next to it calculate the 50th

00:36:00,920 --> 00:36:05,150
percentile here 50th percentile here

00:36:03,109 --> 00:36:09,319
what's the 50th percentile of the

00:36:05,150 --> 00:36:10,640
overall 2 minute period the answer is

00:36:09,319 --> 00:36:12,980
you just have no idea

00:36:10,640 --> 00:36:15,470
you just have to recompute it over the 2

00:36:12,980 --> 00:36:17,780
minute period can be you have bounce it

00:36:15,470 --> 00:36:19,640
can not be lower than either of the two

00:36:17,780 --> 00:36:21,020
that lower than the mini moment cannot

00:36:19,640 --> 00:36:22,609
be higher than the maximum but you can

00:36:21,020 --> 00:36:27,560
can't construct examples where it's

00:36:22,609 --> 00:36:29,510
either of those same if you have three

00:36:27,560 --> 00:36:31,130
database nodes and you have the 50th

00:36:29,510 --> 00:36:33,770
percentile over the same one-minute

00:36:31,130 --> 00:36:35,720
period of all three of them what's the

00:36:33,770 --> 00:36:39,650
overall percentage of the whole database

00:36:35,720 --> 00:36:41,720
cluster the overall percentile answer is

00:36:39,650 --> 00:36:45,200
you just don't know if no way to

00:36:41,720 --> 00:36:47,580
calculate this except just collect the

00:36:45,200 --> 00:36:49,620
raw data get all date and C requests to

00:36:47,580 --> 00:36:51,990
central pier to central place and then

00:36:49,620 --> 00:36:54,480
calculate the percent outs there it's

00:36:51,990 --> 00:37:00,710
the only um like you cannot do anything

00:36:54,480 --> 00:37:00,710
else and so they're like actually three

00:37:01,370 --> 00:37:06,000
three three aggregation levels usually

00:37:03,750 --> 00:37:07,710
see first of all the time time

00:37:06,000 --> 00:37:09,480
aggregation second service level

00:37:07,710 --> 00:37:11,640
aggregation and also for the same

00:37:09,480 --> 00:37:13,620
service the end points right you don't

00:37:11,640 --> 00:37:15,120
have don't have flash and you have many

00:37:13,620 --> 00:37:17,490
many different endpoints that are served

00:37:15,120 --> 00:37:19,560
you might be interested in the the whole

00:37:17,490 --> 00:37:21,270
aggregate of all week receiver serving

00:37:19,560 --> 00:37:23,370
across all endpoints so there are at

00:37:21,270 --> 00:37:24,600
least three different aggregations and

00:37:23,370 --> 00:37:26,640
for each of those you have to make

00:37:24,600 --> 00:37:28,440
choices and actually fourth choice you

00:37:26,640 --> 00:37:30,270
have to you choose the percent house

00:37:28,440 --> 00:37:33,480
that you want to compute so if you have

00:37:30,270 --> 00:37:35,550
a 90s and the fiftieth percentile if no

00:37:33,480 --> 00:37:37,260
way to compute the 75th percentile from

00:37:35,550 --> 00:37:39,780
there so all of this needs to be

00:37:37,260 --> 00:37:42,300
computed from raw data so you're making

00:37:39,780 --> 00:37:43,950
a lot of choices and it's can explode

00:37:42,300 --> 00:37:45,420
and it's actually can if you just want

00:37:43,950 --> 00:37:49,740
to do it properly and calculate

00:37:45,420 --> 00:37:52,350
everything right then your this explodes

00:37:49,740 --> 00:37:55,280
pretty soon because you have to multiply

00:37:52,350 --> 00:37:57,660
your amount of percentiles you collect

00:37:55,280 --> 00:37:59,640
for every endpoint for every aggregation

00:37:57,660 --> 00:38:00,360
level for every time period for every

00:37:59,640 --> 00:38:02,280
percentile

00:38:00,360 --> 00:38:04,980
just like thousands of percent uh for a

00:38:02,280 --> 00:38:07,590
single service this is a little bit bad

00:38:04,980 --> 00:38:09,930
so people actually don't care much they

00:38:07,590 --> 00:38:11,460
say I don't care if it's just minus five

00:38:09,930 --> 00:38:15,150
percent if I'm doing the aggregation

00:38:11,460 --> 00:38:17,280
wrong and this is actually what I would

00:38:15,150 --> 00:38:20,700
I got when I talked about this had money

00:38:17,280 --> 00:38:23,880
to Rama this year at at one fan of mine

00:38:20,700 --> 00:38:24,420
then then I don't really know who he's

00:38:23,880 --> 00:38:26,910
working for

00:38:24,420 --> 00:38:28,350
but he applauded me and said percentiles

00:38:26,910 --> 00:38:30,540
can't be aggregated finally somebody's

00:38:28,350 --> 00:38:32,460
making that point and then John Rosa he

00:38:30,540 --> 00:38:34,740
is a data scientist at snapchat and said

00:38:32,460 --> 00:38:36,480
well actually he's pretty annoyed by

00:38:34,740 --> 00:38:38,340
that statement because you actually can

00:38:36,480 --> 00:38:41,130
get pretty meaningful values if you just

00:38:38,340 --> 00:38:46,710
take averages of percentiles and well I

00:38:41,130 --> 00:38:48,390
said actually yeah you you make mistakes

00:38:46,710 --> 00:38:51,150
and it's actually a serious issue and

00:38:48,390 --> 00:38:53,130
you can do better and I just it

00:38:51,150 --> 00:38:56,640
triggered that actually it's more like a

00:38:53,130 --> 00:38:57,900
letter but it's a tweet and then he said

00:38:56,640 --> 00:38:59,370
well actually you can agree a

00:38:57,900 --> 00:39:01,380
percentiles and here's how you can do it

00:38:59,370 --> 00:39:04,800
so this is like the juice

00:39:01,380 --> 00:39:08,150
StuffIt end 10-page blog post where he

00:39:04,800 --> 00:39:10,670
does a simulation with different

00:39:08,150 --> 00:39:13,020
distributions of request latencies and

00:39:10,670 --> 00:39:15,780
different percentiles that are

00:39:13,020 --> 00:39:18,090
calculated and then he said well

00:39:15,780 --> 00:39:19,950
actually it's not so bad if you are with

00:39:18,090 --> 00:39:23,820
your latency distribution follows this

00:39:19,950 --> 00:39:28,200
and this then the average of percentiles

00:39:23,820 --> 00:39:29,400
is not too far off of the correctly

00:39:28,200 --> 00:39:32,760
calculate percentiles

00:39:29,400 --> 00:39:35,340
this is okay all is like okay right he

00:39:32,760 --> 00:39:43,200
has really thought about this well maybe

00:39:35,340 --> 00:39:45,660
I should just off Kim well then but but

00:39:43,200 --> 00:39:48,810
I did I didn't and i looked at actual

00:39:45,660 --> 00:39:53,670
data so actual data is never so nice as

00:39:48,810 --> 00:39:56,160
is hypothetical data so this is a heat

00:39:53,670 --> 00:39:58,740
map representation of all requests that

00:39:56,160 --> 00:40:00,180
are made in a certain interval so i will

00:39:58,740 --> 00:40:02,040
talk about this in a bit but the

00:40:00,180 --> 00:40:04,260
important bit is you can actually

00:40:02,040 --> 00:40:07,080
calculate the true percent house from

00:40:04,260 --> 00:40:09,630
this information so what you see here in

00:40:07,080 --> 00:40:11,580
red is the average percentile over one

00:40:09,630 --> 00:40:13,470
minute periods so you can calculate the

00:40:11,580 --> 00:40:15,870
Crescenta over one minute and you take

00:40:13,470 --> 00:40:19,530
the average of an hour so this will get

00:40:15,870 --> 00:40:22,170
a a Chetta

00:40:19,530 --> 00:40:24,240
a i don't really know what the thing the

00:40:22,170 --> 00:40:28,320
english word for this is so estimation

00:40:24,240 --> 00:40:30,330
for the the 90th percentile 90th

00:40:28,320 --> 00:40:33,300
percentile correct and you know here is

00:40:30,330 --> 00:40:35,040
the true percentile so this is an era of

00:40:33,300 --> 00:40:38,130
just three hundred percent that you make

00:40:35,040 --> 00:40:40,860
just there which is pretty significant

00:40:38,130 --> 00:40:42,780
by any means and actually first thing of

00:40:40,860 --> 00:40:45,000
all the people asked here is if this

00:40:42,780 --> 00:40:46,560
always goes in the same direction and

00:40:45,000 --> 00:40:49,260
the answer is no it's just it flips like

00:40:46,560 --> 00:40:50,970
here right here and it's at least 150

00:40:49,260 --> 00:40:54,030
percent error right here in the other

00:40:50,970 --> 00:40:56,100
direction so it's pretty crazy the

00:40:54,030 --> 00:40:58,950
errors you can see if you just aggregate

00:40:56,100 --> 00:41:01,140
percentiles on the nose that might be

00:40:58,950 --> 00:41:03,240
places where your leaders better behaved

00:41:01,140 --> 00:41:06,570
but this is not even the worst examples

00:41:03,240 --> 00:41:08,730
that we had ever you can get away with

00:41:06,570 --> 00:41:12,090
just averaging percentiles but most of

00:41:08,730 --> 00:41:13,710
the time I mean you just don't know you

00:41:12,090 --> 00:41:14,880
don't have any bounds for the error you

00:41:13,710 --> 00:41:23,279
were making and it

00:41:14,880 --> 00:41:27,599
can be pretty far off so new chapter

00:41:23,279 --> 00:41:31,289
here so far we have basically seen two

00:41:27,599 --> 00:41:35,579
different kinds of two different kinds

00:41:31,289 --> 00:41:38,190
of mistakes that we have applied to

00:41:35,579 --> 00:41:39,930
operations data and they had two

00:41:38,190 --> 00:41:43,230
different properties the first property

00:41:39,930 --> 00:41:46,079
that you want from a statistic is that

00:41:43,230 --> 00:41:49,859
it's robust but if you have an outlier

00:41:46,079 --> 00:41:52,109
then it doesn't affect the the statistic

00:41:49,859 --> 00:41:54,660
much for example percentiles are robust

00:41:52,109 --> 00:41:56,640
and the second property you want to

00:41:54,660 --> 00:41:59,009
submerge ability and this relates to

00:41:56,640 --> 00:42:02,849
what we've seen here so you can compute

00:41:59,009 --> 00:42:06,359
the statistic from of the joint data set

00:42:02,849 --> 00:42:08,480
from the individual data sets so this is

00:42:06,359 --> 00:42:11,640
a variable and actually this yeah okay

00:42:08,480 --> 00:42:13,230
using much time here so I don't go too

00:42:11,640 --> 00:42:14,789
much into the details but essentially

00:42:13,230 --> 00:42:17,160
I'm saying here percentiles can't be

00:42:14,789 --> 00:42:20,160
aggregated means percentiles are not

00:42:17,160 --> 00:42:22,740
mirja ball so these are two desirable

00:42:20,160 --> 00:42:27,089
properties and I made a little chart of

00:42:22,740 --> 00:42:28,859
what the properties are of different

00:42:27,089 --> 00:42:31,109
aggregation measures that we've talked

00:42:28,859 --> 00:42:33,059
about so mean values mirja ball if you

00:42:31,109 --> 00:42:35,069
have two means of two minutes then you

00:42:33,059 --> 00:42:37,680
can get the total mean at least if you

00:42:35,069 --> 00:42:39,930
have stored the count along the mean so

00:42:37,680 --> 00:42:42,779
you know how many samples you averaged

00:42:39,930 --> 00:42:44,910
over but the median you don't have this

00:42:42,779 --> 00:42:48,900
merge ability property you cannot tell

00:42:44,910 --> 00:42:51,720
what the median was but it's robust you

00:42:48,900 --> 00:42:54,059
gain that and a standard deviation it's

00:42:51,720 --> 00:42:56,759
the same story here this is mirja ball

00:42:54,059 --> 00:42:58,680
if your if you are calculating the if

00:42:56,759 --> 00:43:00,480
you are also tracking the count and the

00:42:58,680 --> 00:43:03,180
mean then the standard deviation is

00:43:00,480 --> 00:43:07,319
mirja ball so now it's exercise if you

00:43:03,180 --> 00:43:08,940
are mathematically interested try to try

00:43:07,319 --> 00:43:12,660
to get come up with a formula for the

00:43:08,940 --> 00:43:14,009
aggregate standard deviation and if the

00:43:12,660 --> 00:43:16,319
interquartile range

00:43:14,009 --> 00:43:18,690
some people will know this it's you take

00:43:16,319 --> 00:43:21,480
the 25th and 75th percentile take the

00:43:18,690 --> 00:43:23,759
difference this good measure for the for

00:43:21,480 --> 00:43:26,579
the deviation you have any data set this

00:43:23,759 --> 00:43:28,500
is robust but north mirja ball and so

00:43:26,579 --> 00:43:28,829
our percentiles per se they are robust

00:43:28,500 --> 00:43:31,289
but

00:43:28,829 --> 00:43:32,849
not merge able so it really looks like

00:43:31,289 --> 00:43:35,549
you have to to choose between the two

00:43:32,849 --> 00:43:37,619
and this is a basic trade-off either I

00:43:35,549 --> 00:43:40,680
can can you can do averages over them

00:43:37,619 --> 00:43:42,719
and do the sensible aggregation but you

00:43:40,680 --> 00:43:48,420
will be susceptible to outliers or you

00:43:42,719 --> 00:43:54,539
get to the other way around and now

00:43:48,420 --> 00:43:56,959
comes the the big surprise histograms so

00:43:54,539 --> 00:44:01,259
histograms are the idea is pretty simple

00:43:56,959 --> 00:44:06,989
to collect a latency histogram you just

00:44:01,259 --> 00:44:10,170
have to cook decide on a bidding of your

00:44:06,989 --> 00:44:13,589
Y scale here are your latency scale you

00:44:10,170 --> 00:44:15,660
just entered your just bin the the scale

00:44:13,589 --> 00:44:17,880
into certain intervals and then you

00:44:15,660 --> 00:44:23,309
count how many samples fall in those

00:44:17,880 --> 00:44:27,809
bins and you just store for each of

00:44:23,309 --> 00:44:31,170
those bins the count and you have to

00:44:27,809 --> 00:44:33,059
just globally decide on on one binning

00:44:31,170 --> 00:44:35,969
this is actually and then we have a good

00:44:33,059 --> 00:44:37,920
way to do that and then this counts you

00:44:35,969 --> 00:44:41,339
can store them quite efficiently if you

00:44:37,920 --> 00:44:43,079
use gap encoding for them so you just

00:44:41,339 --> 00:44:47,279
don't store a large array of all I think

00:44:43,079 --> 00:44:51,869
we have 32,000 different bins but you

00:44:47,279 --> 00:44:53,849
just basically store key values right

00:44:51,869 --> 00:44:55,949
so it's who you're you're retaining if

00:44:53,849 --> 00:44:58,559
you store histograms you're retaining

00:44:55,949 --> 00:45:00,690
the full distribution information of

00:44:58,559 --> 00:45:03,509
your of your latencies you're not

00:45:00,690 --> 00:45:05,640
throwing away much it depends how much

00:45:03,509 --> 00:45:11,519
accuracy you you lose depends on how

00:45:05,640 --> 00:45:13,469
large your bins are so you can store

00:45:11,519 --> 00:45:16,079
that actually many people record this

00:45:13,469 --> 00:45:17,910
already they use in in the monitoring

00:45:16,079 --> 00:45:19,650
agents they are they're accumulating

00:45:17,910 --> 00:45:21,670
histograms and they use that to

00:45:19,650 --> 00:45:23,799
calculate the percent

00:45:21,670 --> 00:45:27,730
else but they're not forwarding the

00:45:23,799 --> 00:45:31,150
histograms to the monitoring back-end if

00:45:27,730 --> 00:45:34,990
some people do google gave actually the

00:45:31,150 --> 00:45:36,279
talk after mine at monitor ama and they

00:45:34,990 --> 00:45:37,299
were saying what we actually just

00:45:36,279 --> 00:45:38,589
precisely do that

00:45:37,299 --> 00:45:40,539
we store for every end point the

00:45:38,589 --> 00:45:42,430
histogram and then we aggregate get it

00:45:40,539 --> 00:45:44,380
later so you can't actually do it in

00:45:42,430 --> 00:45:49,569
there like big companies do that already

00:45:44,380 --> 00:45:51,099
and the the compared to logs the amount

00:45:49,569 --> 00:45:53,650
of memory you need to store it on disk

00:45:51,099 --> 00:45:56,740
is just minimal it's likely you have

00:45:53,650 --> 00:45:58,269
average of 300 bytes per per histogram

00:45:56,740 --> 00:46:00,730
we are taking in and those can be

00:45:58,269 --> 00:46:03,579
massive so we do that for I all agencies

00:46:00,730 --> 00:46:05,079
which have millions of samples in a one

00:46:03,579 --> 00:46:08,079
minute interval maybe hundreds of

00:46:05,079 --> 00:46:10,660
millions even so just that you to give

00:46:08,079 --> 00:46:18,250
you an impression how that looks like so

00:46:10,660 --> 00:46:20,680
this is actually so we have a this is

00:46:18,250 --> 00:46:24,880
this year of data so here we have a

00:46:20,680 --> 00:46:26,500
total of 35 million samples for each

00:46:24,880 --> 00:46:28,809
aggregation period of one day

00:46:26,500 --> 00:46:30,519
and if I hover over that you see for

00:46:28,809 --> 00:46:32,470
every day the complete the complete

00:46:30,519 --> 00:46:33,309
latency distribution which is very

00:46:32,470 --> 00:46:35,799
boring here

00:46:33,309 --> 00:46:38,589
but you see like how that evolves and

00:46:35,799 --> 00:46:40,390
you can also calculate stuff on top of

00:46:38,589 --> 00:46:43,180
this so this are some some different

00:46:40,390 --> 00:46:45,400
api's and you see how the histograms

00:46:43,180 --> 00:46:46,990
change over time and you overlaid the

00:46:45,400 --> 00:46:48,819
percentile so you see the 50th

00:46:46,990 --> 00:46:53,200
percentile here so usually you would

00:46:48,819 --> 00:46:55,690
just have the the this this value here

00:46:53,200 --> 00:47:01,660
but you can on top of this just store

00:46:55,690 --> 00:47:03,849
the whole distribution right so what

00:47:01,660 --> 00:47:11,410
what do you gain by place should you

00:47:03,849 --> 00:47:13,779
care so first of all histograms look

00:47:11,410 --> 00:47:16,599
nice okay good

00:47:13,779 --> 00:47:18,339
maybe not such a big point so histograms

00:47:16,599 --> 00:47:21,309
are robust so you just capture all

00:47:18,339 --> 00:47:23,319
information they are not is like if it

00:47:21,309 --> 00:47:25,210
doesn't really make sense to say it's

00:47:23,319 --> 00:47:26,950
robust but in a certain sense it is it

00:47:25,210 --> 00:47:29,799
is not distorted by outliers it just

00:47:26,950 --> 00:47:32,160
accept them source them so it's not it

00:47:29,799 --> 00:47:34,720
doesn't on you lose don't lose anything

00:47:32,160 --> 00:47:35,200
but they're the really amazing thing

00:47:34,720 --> 00:47:37,390
about

00:47:35,200 --> 00:47:40,060
mr. grams and the root of their power is

00:47:37,390 --> 00:47:42,460
that that they emerge about and they are

00:47:40,060 --> 00:47:45,430
trivially so if you have two histograms

00:47:42,460 --> 00:47:48,940
with the same binning you just add the

00:47:45,430 --> 00:47:51,460
counts for each bin it's a trivial and

00:47:48,940 --> 00:47:54,820
you can do that across time you can do

00:47:51,460 --> 00:47:58,030
that across less service levels you can

00:47:54,820 --> 00:48:00,820
do that across endpoints and more than

00:47:58,030 --> 00:48:02,940
that you can actually derive all the

00:48:00,820 --> 00:48:08,140
different or at least approximate to a

00:48:02,940 --> 00:48:11,760
good precision all the statistics you

00:48:08,140 --> 00:48:14,800
are talking about earlier so you can

00:48:11,760 --> 00:48:17,200
have that on a chart you can compute the

00:48:14,800 --> 00:48:19,960
percent house and the mean values from

00:48:17,200 --> 00:48:21,940
the histogram so then now you can go and

00:48:19,960 --> 00:48:23,140
first aggregate the histogram and then

00:48:21,940 --> 00:48:25,300
calculate the percentiles

00:48:23,140 --> 00:48:27,640
and this is precisely how I produced

00:48:25,300 --> 00:48:30,369
this graphs here so you can get the true

00:48:27,640 --> 00:48:31,630
values by 2d here you see our query

00:48:30,369 --> 00:48:34,089
language which select a bunch of

00:48:31,630 --> 00:48:36,250
histograms then we aggregate the

00:48:34,089 --> 00:48:38,290
histograms here over a window then we

00:48:36,250 --> 00:48:40,540
take the percentile or we take the

00:48:38,290 --> 00:48:43,210
percentile first and then we aggregate

00:48:40,540 --> 00:48:45,460
over a window of time so it can swap

00:48:43,210 --> 00:48:48,760
that around which would be not possible

00:48:45,460 --> 00:48:50,260
if you just have the numerators stuff so

00:48:48,760 --> 00:48:51,730
here's another example how that looks

00:48:50,260 --> 00:48:53,710
like and this is our most beautiful

00:48:51,730 --> 00:48:55,720
example because it's just so nice that

00:48:53,710 --> 00:48:58,030
you can see so much so you see you have

00:48:55,720 --> 00:49:00,940
three week rest modes so you have one

00:48:58,030 --> 00:49:02,980
notes modes that is soft very fast

00:49:00,940 --> 00:49:05,260
that's here probably lying in cash and

00:49:02,980 --> 00:49:06,849
then you have one thing that spins off

00:49:05,260 --> 00:49:07,960
here and one thing that spins off here

00:49:06,849 --> 00:49:11,770
and you have in the middle another

00:49:07,960 --> 00:49:13,480
little maximum here so you see three

00:49:11,770 --> 00:49:15,310
different kinds of users that are using

00:49:13,480 --> 00:49:17,619
your API you often see that with like

00:49:15,310 --> 00:49:20,430
mobile users or users on different

00:49:17,619 --> 00:49:22,900
carriers which have different network

00:49:20,430 --> 00:49:27,339
latency so you often see like the kind

00:49:22,900 --> 00:49:29,230
of latency distribution there right and

00:49:27,339 --> 00:49:30,790
in this case actually very funny because

00:49:29,230 --> 00:49:34,180
you actually see how that distribution

00:49:30,790 --> 00:49:40,030
here changes over time and this was

00:49:34,180 --> 00:49:41,829
actually a bug in which cost in a web

00:49:40,030 --> 00:49:43,240
server which was appending to a list

00:49:41,829 --> 00:49:45,160
every time you made a request and this

00:49:43,240 --> 00:49:46,599
list which people got slow and slower so

00:49:45,160 --> 00:49:47,230
one of the modes first going getting

00:49:46,599 --> 00:49:49,180
higher and higher

00:49:47,230 --> 00:49:52,510
just really see all

00:49:49,180 --> 00:49:55,030
the performance behavior of that in the

00:49:52,510 --> 00:49:57,369
in the histogram right and this is just

00:49:55,030 --> 00:49:59,319
the same data and then I overlay the the

00:49:57,369 --> 00:50:01,540
mean values and percentiles and rates

00:49:59,319 --> 00:50:05,770
you can also calculate the rates right

00:50:01,540 --> 00:50:07,869
and okay so so far I've just talked

00:50:05,770 --> 00:50:11,710
about that that histograms are a great

00:50:07,869 --> 00:50:13,960
great way to to to to to do monitoring

00:50:11,710 --> 00:50:16,359
which gives you the the possibility to

00:50:13,960 --> 00:50:18,040
aggregate your data properly to do

00:50:16,359 --> 00:50:22,390
correct computations to gain more

00:50:18,040 --> 00:50:27,819
insight but actually it goes further

00:50:22,390 --> 00:50:32,280
than that this is a very simple exercise

00:50:27,819 --> 00:50:34,329
if you have the histogram data say your

00:50:32,280 --> 00:50:36,040
acceptance threshold of your users

00:50:34,329 --> 00:50:37,720
something like 40 milliseconds this is

00:50:36,040 --> 00:50:40,059
hypothetical but at some point people

00:50:37,720 --> 00:50:41,530
will get really annoyed let's say well

00:50:40,059 --> 00:50:43,059
it's this took longer in us in a second

00:50:41,530 --> 00:50:46,059
to load this is unacceptable for me or

00:50:43,059 --> 00:50:48,130
legmen in ten seconds if you have the

00:50:46,059 --> 00:50:50,609
histogram data you can just count how

00:50:48,130 --> 00:50:53,859
many people had that bad experience and

00:50:50,609 --> 00:50:56,260
if you compare this many of the problems

00:50:53,859 --> 00:50:58,960
we had before just going away because

00:50:56,260 --> 00:51:02,470
yes you were serving 99 percent of your

00:50:58,960 --> 00:51:05,670
users badly at night but it was only to

00:51:02,470 --> 00:51:08,500
users so I'm not getting paged for that

00:51:05,670 --> 00:51:11,770
and also if you want to when I have

00:51:08,500 --> 00:51:15,190
sensible reporting you can just sum them

00:51:11,770 --> 00:51:16,720
up to do integral across this day and

00:51:15,190 --> 00:51:18,970
then you know at the end they were all

00:51:16,720 --> 00:51:21,910
fought a total of four thousand requests

00:51:18,970 --> 00:51:24,069
or four thousand users that were not

00:51:21,910 --> 00:51:28,109
getting the the right performance out of

00:51:24,069 --> 00:51:31,839
your all of your IP I so this kind of

00:51:28,109 --> 00:51:34,000
analysis are very easy and very simple

00:51:31,839 --> 00:51:39,010
to do I mean if you have the right data

00:51:34,000 --> 00:51:40,720
set to do it on so just expanding on

00:51:39,010 --> 00:51:42,220
that idea of not getting around doing

00:51:40,720 --> 00:51:43,900
this but but sometimes you can also

00:51:42,220 --> 00:51:46,210
estimate the amount of financial loss

00:51:43,900 --> 00:51:51,069
you're suffering because you know what

00:51:46,210 --> 00:51:53,290
your rate of users is that will go to a

00:51:51,069 --> 00:51:55,299
different service depending on how much

00:51:53,290 --> 00:51:56,890
latency we're so if you if it takes

00:51:55,299 --> 00:51:59,020
longer than three seconds they have a

00:51:56,890 --> 00:52:01,690
certain purpose probability to get go

00:51:59,020 --> 00:52:02,830
away if it's longer than 15 seconds then

00:52:01,690 --> 00:52:04,510
they have another of

00:52:02,830 --> 00:52:06,100
ability and one can try to build a

00:52:04,510 --> 00:52:08,980
little bit more sophisticated models on

00:52:06,100 --> 00:52:11,230
top of that so I don't know how well

00:52:08,980 --> 00:52:12,970
this would work but they're like you can

00:52:11,230 --> 00:52:15,670
think of a lot of things that you can

00:52:12,970 --> 00:52:16,420
can apply and and you can you can do

00:52:15,670 --> 00:52:18,580
with that data

00:52:16,420 --> 00:52:20,530
but I mean just very simple reporting is

00:52:18,580 --> 00:52:25,210
this even it's possible and pretty

00:52:20,530 --> 00:52:27,040
trivial right so I will close with this

00:52:25,210 --> 00:52:29,200
some take away see on the last slide

00:52:27,040 --> 00:52:31,290
don't trust your line graphs at least on

00:52:29,200 --> 00:52:33,400
scale because you have spike erosion

00:52:31,290 --> 00:52:36,730
don't aggregate percent Hertz

00:52:33,400 --> 00:52:38,530
really if you if you must do but if you

00:52:36,730 --> 00:52:40,810
can get away with storing histograms or

00:52:38,530 --> 00:52:43,510
are using logs or for doing your

00:52:40,810 --> 00:52:45,010
reporting it's much better keep your

00:52:43,510 --> 00:52:46,390
data if you're throwing away the one

00:52:45,010 --> 00:52:48,730
minute days I just have the averages

00:52:46,390 --> 00:52:51,130
then not much information left and

00:52:48,730 --> 00:52:56,330
strive for meaningful metrics and have a

00:52:51,130 --> 00:53:03,489
peak at IOD B don't forget it Thanks

00:52:56,330 --> 00:53:03,489

YouTube URL: https://www.youtube.com/watch?v=DdNYat2CLQ4


