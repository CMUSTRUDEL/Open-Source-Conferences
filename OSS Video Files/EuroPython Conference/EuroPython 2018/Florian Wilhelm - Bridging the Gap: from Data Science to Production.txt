Title: Florian Wilhelm - Bridging the Gap: from Data Science to Production
Publication date: 2018-08-22
Playlist: EuroPython 2018
Description: 
	Bridging the Gap: from Data Science to Production
[EuroPython 2018 - Talk - 2018-07-25 - PyCharm [PyData]]
[Edinburgh, UK]

By Florian Wilhelm

A recent but quite common observation in industry is that although there is an overall high adoption of data science, many companies struggle to get it into production. Huge teams of well-payed data scientists often present one fancy model after the other to their managers but their proof of concepts never manifest into something business relevant. The frustration grows on both sides, managers and data scientists.

In my talk I elaborate on the many reasons why data science to production is such a hard nut to crack. I start with a taxonomy of data use cases in order to easier assess technical requirements. Based thereon, my focus lies on overcoming the two-language-problem which is Python/R loved by data scientists vs. the enterprise-established Java/Scala. From my project experiences I present three different solutions, namely 1) migrating to a single language, 2) reimplementation and 3) usage of a framework. The advantages and disadvantages of each approach is presented and general advices based on the introduced taxonomy is given. 

Additionally, my talk also addresses organisational as well as problems in quality assurance and deployment. Best practices and further references are presented on a high-level in order to cover all facets of data science to production.

With my talk I hope to convey the message that breakdowns on the road from data science to production are rather the rule than the exception, so you are not alone. At the end of my talk, you will have a better understanding of why your team and you are struggling and what to do about it.



License: This video is licensed under the CC BY-NC-SA 3.0 license: https://creativecommons.org/licenses/by-nc-sa/3.0/
Please see our speaker release agreement for details: https://ep2018.europython.eu/en/speaker-release-agreement/
Captions: 
	00:00:00,260 --> 00:00:04,830
yeah thanks a lot welcome to my talk

00:00:02,790 --> 00:00:09,030
bridging the gap from data science to

00:00:04,830 --> 00:00:10,620
production after the introduction a few

00:00:09,030 --> 00:00:13,469
words about myself so I'm a data

00:00:10,620 --> 00:00:15,179
scientist at inuvik's I have a

00:00:13,469 --> 00:00:17,310
mathematical background so this is why I

00:00:15,179 --> 00:00:18,750
really like mathematical modeling I mean

00:00:17,310 --> 00:00:21,240
this is important for being a data

00:00:18,750 --> 00:00:22,949
scientist I've done a few projects in

00:00:21,240 --> 00:00:25,710
recommendation system which is a really

00:00:22,949 --> 00:00:27,630
nice and interesting topic of course I'm

00:00:25,710 --> 00:00:30,300
always interested to bring things into

00:00:27,630 --> 00:00:33,420
production meaning that I don't just

00:00:30,300 --> 00:00:36,540
look to make some proof of concept some

00:00:33,420 --> 00:00:38,340
some nice models one time and then like

00:00:36,540 --> 00:00:40,500
kind of forget about it so I really want

00:00:38,340 --> 00:00:43,110
to see the gained well you that you only

00:00:40,500 --> 00:00:46,379
get if you put things into production

00:00:43,110 --> 00:00:51,120
and of course I'm a big fan of the the

00:00:46,379 --> 00:00:53,910
patent data stack just a few words about

00:00:51,120 --> 00:00:56,430
the company I work for for innovates

00:00:53,910 --> 00:00:59,300
whose giving me the possibility to speak

00:00:56,430 --> 00:01:01,980
at cool conferences like the European

00:00:59,300 --> 00:01:04,680
innovates is an IT project house with a

00:01:01,980 --> 00:01:06,810
focus on digital transformation and we

00:01:04,680 --> 00:01:08,970
offer everything around this meaning

00:01:06,810 --> 00:01:11,159
from operation to application

00:01:08,970 --> 00:01:14,220
development Big Data and data science of

00:01:11,159 --> 00:01:18,420
course and we got many offices all over

00:01:14,220 --> 00:01:19,470
Germany so to the actual topic data

00:01:18,420 --> 00:01:23,130
science to production

00:01:19,470 --> 00:01:25,590
I mean who of you have already like

00:01:23,130 --> 00:01:27,330
worked on on a data science project and

00:01:25,590 --> 00:01:29,250
in the end you had some some some really

00:01:27,330 --> 00:01:32,700
cool proof-of-concept but it was never

00:01:29,250 --> 00:01:34,799
really put into production and maybe ok

00:01:32,700 --> 00:01:36,780
so it seems like this really is a big

00:01:34,799 --> 00:01:41,189
topic and a lot of people are talking

00:01:36,780 --> 00:01:43,979
about this and it's it's also a source

00:01:41,189 --> 00:01:46,200
of frustration I mean data scientists

00:01:43,979 --> 00:01:48,000
get frustrated after a while if they see

00:01:46,200 --> 00:01:49,619
like one proof-of-concept after the

00:01:48,000 --> 00:01:52,170
other that not really moves to

00:01:49,619 --> 00:01:55,290
production and also the business sites

00:01:52,170 --> 00:01:57,899
gets frustrated so they have maybe hired

00:01:55,290 --> 00:01:59,640
a huge team of data scientists that do

00:01:57,899 --> 00:02:02,460
cool things but in the end they can ever

00:01:59,640 --> 00:02:05,369
say ok our data scientists they did this

00:02:02,460 --> 00:02:07,079
and now we have maybe increased our

00:02:05,369 --> 00:02:10,349
revenue by 10 percent and this is

00:02:07,079 --> 00:02:11,400
exactly why one should care about moving

00:02:10,349 --> 00:02:13,590
things to production

00:02:11,400 --> 00:02:15,300
and this topic is death

00:02:13,590 --> 00:02:17,700
not an easy one it has many different

00:02:15,300 --> 00:02:20,519
facets and throughout the talk I'm going

00:02:17,700 --> 00:02:24,480
to touch many of them before and

00:02:20,519 --> 00:02:27,030
actually one of the important things is

00:02:24,480 --> 00:02:32,160
the actual use case so this data product

00:02:27,030 --> 00:02:34,110
or this model you are building so we're

00:02:32,160 --> 00:02:36,390
gonna now look at this from a really

00:02:34,110 --> 00:02:38,190
high-level perspective so this data

00:02:36,390 --> 00:02:42,030
product you want to build in a company

00:02:38,190 --> 00:02:43,890
and if you look at that you can

00:02:42,030 --> 00:02:46,590
basically say ok it's it's quite easy

00:02:43,890 --> 00:02:48,810
you have some some data somewhere you

00:02:46,590 --> 00:02:51,540
have your you have your model this is

00:02:48,810 --> 00:02:53,849
basically doing some transformations and

00:02:51,540 --> 00:02:56,400
in the end you have some results be it

00:02:53,849 --> 00:02:57,810
predictions or like decisions or

00:02:56,400 --> 00:03:00,560
whatever so this is the really

00:02:57,810 --> 00:03:02,700
high-level perspective but from this

00:03:00,560 --> 00:03:06,810
components from these three components

00:03:02,700 --> 00:03:10,170
we can already kind of classify what our

00:03:06,810 --> 00:03:12,120
use case is and this we have to later

00:03:10,170 --> 00:03:13,920
keep in mind if we wanna things put

00:03:12,120 --> 00:03:16,590
things into production for instance the

00:03:13,920 --> 00:03:19,380
data is it coming from some relational

00:03:16,590 --> 00:03:21,540
database or some some known SQL database

00:03:19,380 --> 00:03:24,150
is it coming from some distributed file

00:03:21,540 --> 00:03:26,239
system or do you have to deal with

00:03:24,150 --> 00:03:28,980
stream based data that's your model

00:03:26,239 --> 00:03:32,010
really the whole time need to consume

00:03:28,980 --> 00:03:34,799
data as a stream so this is important

00:03:32,010 --> 00:03:37,950
question and depending on your use case

00:03:34,799 --> 00:03:39,569
you have to clarify how you're going to

00:03:37,950 --> 00:03:43,079
do this in production and what the

00:03:39,569 --> 00:03:44,910
reasons in recency requirements are so

00:03:43,079 --> 00:03:47,280
like are you dueling with batch data

00:03:44,910 --> 00:03:49,380
does your model need to react near

00:03:47,280 --> 00:03:53,160
real-time real time or in a stream based

00:03:49,380 --> 00:03:54,810
fashion then the model itself and with

00:03:53,160 --> 00:03:56,760
the model when I'm talking about model

00:03:54,810 --> 00:03:58,230
I'm not only talking about the machine

00:03:56,760 --> 00:04:01,079
learning algorithm so a lot of people

00:03:58,230 --> 00:04:02,880
say like yeah my model and they actually

00:04:01,079 --> 00:04:05,599
think yeah that's the artificial neural

00:04:02,880 --> 00:04:07,910
network or that's the random forests but

00:04:05,599 --> 00:04:10,319
actually the model includes everything

00:04:07,910 --> 00:04:14,130
from the point where you get your raw

00:04:10,319 --> 00:04:15,959
data to the point where you give back

00:04:14,130 --> 00:04:19,139
some kind of results so this includes

00:04:15,959 --> 00:04:21,269
also the pre-processing so how you do

00:04:19,139 --> 00:04:23,729
cleansing importation how you scale your

00:04:21,269 --> 00:04:26,460
data may be all kind of feature

00:04:23,729 --> 00:04:27,090
engineering you do like construction of

00:04:26,460 --> 00:04:29,580
noodle

00:04:27,090 --> 00:04:31,889
features like some exponential moving

00:04:29,580 --> 00:04:34,350
average and so on so this is all part of

00:04:31,889 --> 00:04:37,260
the model because if you do this on your

00:04:34,350 --> 00:04:39,150
laptop in some proof of concept you

00:04:37,260 --> 00:04:41,580
later have to also put this into

00:04:39,150 --> 00:04:44,729
protection and you need to do you need

00:04:41,580 --> 00:04:48,570
to think about this and that you don't

00:04:44,729 --> 00:04:51,990
kind of re-implemented thing so then the

00:04:48,570 --> 00:04:54,180
last part is the results so what do you

00:04:51,990 --> 00:04:56,760
do with your result I mean in a proof of

00:04:54,180 --> 00:05:00,360
concept your results basically are maybe

00:04:56,760 --> 00:05:03,450
some some CSV file and you make some

00:05:00,360 --> 00:05:05,940
nice plots and show it to some suzanne

00:05:03,450 --> 00:05:07,740
product manager but in production you

00:05:05,940 --> 00:05:09,930
need to care so do we put this in

00:05:07,740 --> 00:05:13,620
another database and are the consumers

00:05:09,930 --> 00:05:15,900
of my predictions of my decisions or

00:05:13,620 --> 00:05:17,940
whatever are they reading from the

00:05:15,900 --> 00:05:20,760
database so the data base would be your

00:05:17,940 --> 00:05:22,919
your interface or is it again some

00:05:20,760 --> 00:05:27,479
distributed file system are you writing

00:05:22,919 --> 00:05:30,060
back new topics in a stream or maybe in

00:05:27,479 --> 00:05:32,669
a real-time use case like how it's many

00:05:30,060 --> 00:05:34,889
of how it is quite often the case for

00:05:32,669 --> 00:05:37,139
recommendation system that you have to

00:05:34,889 --> 00:05:39,510
provide some kind of REST API so that

00:05:37,139 --> 00:05:43,440
people asked real-time for

00:05:39,510 --> 00:05:48,360
recommendations given a user user

00:05:43,440 --> 00:05:51,150
preferences so looking back now at the

00:05:48,360 --> 00:05:52,950
whole picture we have our data we have a

00:05:51,150 --> 00:05:54,750
model and we have a result and

00:05:52,950 --> 00:05:58,080
everything needs to be in the end in

00:05:54,750 --> 00:06:01,320
production so we care about deploying

00:05:58,080 --> 00:06:04,110
this model and I've already said a lot

00:06:01,320 --> 00:06:07,080
about that we need interfaces so we are

00:06:04,110 --> 00:06:11,940
in control of the model and you need to

00:06:07,080 --> 00:06:14,580
define how you access the DD data and

00:06:11,940 --> 00:06:19,190
how you in the end return the results

00:06:14,580 --> 00:06:23,760
and they're most of the times many other

00:06:19,190 --> 00:06:26,039
like like teams exist who are in control

00:06:23,760 --> 00:06:28,130
of this so it's important to to speak to

00:06:26,039 --> 00:06:33,900
them to communicate and to define

00:06:28,130 --> 00:06:37,260
interfaces so to actually give some more

00:06:33,900 --> 00:06:39,229
characteristics of a use case we said

00:06:37,260 --> 00:06:40,650
already it's the delivery so you can

00:06:39,229 --> 00:06:42,900
depending on your

00:06:40,650 --> 00:06:44,759
data-use case you can say it says you

00:06:42,900 --> 00:06:47,009
need to have a web service or stream or

00:06:44,759 --> 00:06:49,889
database then important it's also the

00:06:47,009 --> 00:06:51,389
problem class that you early on decide

00:06:49,889 --> 00:06:53,669
okay I wanna do a classification

00:06:51,389 --> 00:06:56,280
regression recommendation I need or do

00:06:53,669 --> 00:06:58,050
not need explained ability because this

00:06:56,280 --> 00:07:00,240
will later on decide what kind of

00:06:58,050 --> 00:07:03,539
libraries you can use so it's important

00:07:00,240 --> 00:07:07,949
to to think about this early on then the

00:07:03,539 --> 00:07:10,169
volume and velocity this will later tell

00:07:07,949 --> 00:07:12,150
you how your model what kind of

00:07:10,169 --> 00:07:14,970
scalability requirements your model

00:07:12,150 --> 00:07:16,949
needs to have then the in fear ins and

00:07:14,970 --> 00:07:20,160
prediction is it enough to do the

00:07:16,949 --> 00:07:23,820
inference like once a day in a batch way

00:07:20,160 --> 00:07:27,180
or again real-time or stream so all this

00:07:23,820 --> 00:07:30,810
will later on decide how you go and put

00:07:27,180 --> 00:07:32,849
things into production additionally you

00:07:30,810 --> 00:07:35,030
have a technical side conditions maybe

00:07:32,849 --> 00:07:37,620
you're working in a company where

00:07:35,030 --> 00:07:39,210
there's a huge Chavez Tech I mean many

00:07:37,620 --> 00:07:41,280
companies they have a Chavez Tech and

00:07:39,210 --> 00:07:43,919
this could be that this won't that they

00:07:41,280 --> 00:07:46,500
say ok but in the end we can only roll

00:07:43,919 --> 00:07:48,330
out in a scaleable bait some Java models

00:07:46,500 --> 00:07:50,910
and this is a technical condition and

00:07:48,330 --> 00:07:53,490
you should think about this early on

00:07:50,910 --> 00:07:56,610
because if you do then everything in

00:07:53,490 --> 00:07:58,440
pure Python then you will be bound to

00:07:56,610 --> 00:08:01,500
just providing a proof-of-concept

00:07:58,440 --> 00:08:03,690
because your code will not be able to be

00:08:01,500 --> 00:08:08,070
moved to protection what other things

00:08:03,690 --> 00:08:11,699
are like is it gonna be an on-premise

00:08:08,070 --> 00:08:13,050
solution or maybe in the cloud so one

00:08:11,699 --> 00:08:16,139
important thing is there's no

00:08:13,050 --> 00:08:19,169
one-size-fits-all solution for this I

00:08:16,139 --> 00:08:22,650
mean their provider offering like like

00:08:19,169 --> 00:08:25,760
some Holy Grail like use our framework

00:08:22,650 --> 00:08:29,159
and everything will work so for me it's

00:08:25,760 --> 00:08:32,310
yeah this is not true so do you really

00:08:29,159 --> 00:08:34,440
have to evaluate your use case before

00:08:32,310 --> 00:08:38,430
and then decide on a use case by youth

00:08:34,440 --> 00:08:40,520
case basis so the takeaway and the

00:08:38,430 --> 00:08:43,709
learnings from this high level

00:08:40,520 --> 00:08:46,170
perspective of your data use case your

00:08:43,709 --> 00:08:47,970
data product is that you need to do

00:08:46,170 --> 00:08:51,089
state the requirements of your use case

00:08:47,970 --> 00:08:52,680
early on think about how to move things

00:08:51,089 --> 00:08:53,700
in production before you actually start

00:08:52,680 --> 00:08:56,370
some kind of proof of

00:08:53,700 --> 00:08:59,610
concept identify and check your data

00:08:56,370 --> 00:09:02,430
sources so that means don't just get one

00:08:59,610 --> 00:09:05,460
time data dump that someone gave you on

00:09:02,430 --> 00:09:07,170
an OS B stick rather think okay where's

00:09:05,460 --> 00:09:10,800
the data coming from and how could I

00:09:07,170 --> 00:09:13,500
later access this data in a productive

00:09:10,800 --> 00:09:16,830
way then define interfaces with other

00:09:13,500 --> 00:09:19,500
departments meaning like if there's a

00:09:16,830 --> 00:09:24,360
special team for the management of the

00:09:19,500 --> 00:09:26,970
of the databases and the guys who are

00:09:24,360 --> 00:09:29,310
filling the the databases so that you

00:09:26,970 --> 00:09:31,620
define how the data should be formatted

00:09:29,310 --> 00:09:33,480
and so on this will be important for

00:09:31,620 --> 00:09:36,680
production because if someone later

00:09:33,480 --> 00:09:39,180
changes maybe the schema often database

00:09:36,680 --> 00:09:43,050
everything could fail of course and

00:09:39,180 --> 00:09:46,380
another another good advice actually is

00:09:43,050 --> 00:09:48,060
to test the whole data flow early on

00:09:46,380 --> 00:09:51,270
with some kind of dummy model or some

00:09:48,060 --> 00:09:54,330
kind of heuristic meaning that you try

00:09:51,270 --> 00:09:56,640
to make the whole process from data

00:09:54,330 --> 00:09:59,730
reading a simple transformation and

00:09:56,640 --> 00:10:01,500
writing it back into a database or

00:09:59,730 --> 00:10:04,290
writing the results back into a stream

00:10:01,500 --> 00:10:06,990
that you test this technically early on

00:10:04,290 --> 00:10:12,420
to directly see where things could go

00:10:06,990 --> 00:10:15,390
wrong so this is the part about the the

00:10:12,420 --> 00:10:17,640
more like organizational or more like

00:10:15,390 --> 00:10:19,680
the use case aspect another big

00:10:17,640 --> 00:10:21,210
important thing I see in the topic of

00:10:19,680 --> 00:10:25,290
data sensor protection is actually

00:10:21,210 --> 00:10:29,190
quality insurance for especially for

00:10:25,290 --> 00:10:33,390
data scientists it's quite often so that

00:10:29,190 --> 00:10:35,580
they that they yeah that they program in

00:10:33,390 --> 00:10:39,140
notebooks and so on and code is more

00:10:35,580 --> 00:10:43,860
like a one-shot kind of deal but

00:10:39,140 --> 00:10:45,990
actually building a data product it's an

00:10:43,860 --> 00:10:48,990
iterative process and this isn't really

00:10:45,990 --> 00:10:51,720
old method actually it's has been

00:10:48,990 --> 00:10:54,150
invented by by IBM and it's more than

00:10:51,720 --> 00:10:57,480
twenty years old it's the cross in this

00:10:54,150 --> 00:11:00,600
industry all has done that process for

00:10:57,480 --> 00:11:03,120
data mining and already there they said

00:11:00,600 --> 00:11:06,000
okay if you do data mining then it's

00:11:03,120 --> 00:11:07,970
gonna be an iterative process so you're

00:11:06,000 --> 00:11:10,250
gonna grab your day

00:11:07,970 --> 00:11:12,050
you're gonna prepare your data you come

00:11:10,250 --> 00:11:14,060
up with modelling you evaluate you get

00:11:12,050 --> 00:11:16,700
more insights about the data and discuss

00:11:14,060 --> 00:11:18,860
goes on and on and on and the same goes

00:11:16,700 --> 00:11:22,580
actually for for any kind of data

00:11:18,860 --> 00:11:24,560
product so if you have now in mind that

00:11:22,580 --> 00:11:27,020
it's going to be iterative of course

00:11:24,560 --> 00:11:30,380
quality is gonna be an important aspect

00:11:27,020 --> 00:11:33,800
so quality and different in different

00:11:30,380 --> 00:11:36,140
regions for instance if you program

00:11:33,800 --> 00:11:38,840
something even if you just start with a

00:11:36,140 --> 00:11:43,220
with a kind of proof of concept make

00:11:38,840 --> 00:11:45,130
your code clean so what I see quite

00:11:43,220 --> 00:11:47,810
often is that people use a lot of

00:11:45,130 --> 00:11:49,820
two-bit a lab to be their notebooks and

00:11:47,810 --> 00:11:54,920
just put everything into a huge huge

00:11:49,820 --> 00:11:57,350
notebook and if they have a similar task

00:11:54,920 --> 00:12:01,670
they just copy over things and so on

00:11:57,350 --> 00:12:04,090
this is not really good clean coding and

00:12:01,670 --> 00:12:06,530
here we can actually learn a lot from

00:12:04,090 --> 00:12:08,720
clean coding principles that Java

00:12:06,530 --> 00:12:11,030
developers most of the times have like

00:12:08,720 --> 00:12:14,180
software design patterns the solid

00:12:11,030 --> 00:12:16,340
principle and especially the clean code

00:12:14,180 --> 00:12:19,940
developer I mean who knows the website

00:12:16,340 --> 00:12:22,700
clean code developer who's not so many

00:12:19,940 --> 00:12:24,860
hands yeah this is actually what I what

00:12:22,700 --> 00:12:28,730
I thought so a clean code is really

00:12:24,860 --> 00:12:30,110
important in the end for if you want to

00:12:28,730 --> 00:12:31,580
things move things into production

00:12:30,110 --> 00:12:33,770
because other people are going to read

00:12:31,580 --> 00:12:36,410
your code you have to make adjustments

00:12:33,770 --> 00:12:39,290
and so on and so there are many good

00:12:36,410 --> 00:12:41,300
resources and even or even or especially

00:12:39,290 --> 00:12:46,130
as a Python developer you should care

00:12:41,300 --> 00:12:48,650
about this another practical thing one

00:12:46,130 --> 00:12:52,430
should care about and two is continuous

00:12:48,650 --> 00:12:53,930
integration so that you continuously if

00:12:52,430 --> 00:12:55,790
you're if your team works and something

00:12:53,930 --> 00:12:58,150
that you can continuously integrate your

00:12:55,790 --> 00:13:01,070
code into a master code that you have

00:12:58,150 --> 00:13:03,410
unit tests that continuously test your

00:13:01,070 --> 00:13:05,510
code that you think about versioning

00:13:03,410 --> 00:13:08,060
about packaging about putting your

00:13:05,510 --> 00:13:10,550
packages your artifact on an artifact

00:13:08,060 --> 00:13:14,030
store that you autumn eyes this and

00:13:10,550 --> 00:13:19,520
embrace some kind of development process

00:13:14,030 --> 00:13:20,840
this and this is actually quite easy to

00:13:19,520 --> 00:13:23,480
be done I mean there's no

00:13:20,840 --> 00:13:25,640
Hoss tools Jenkins I mean I guess most

00:13:23,480 --> 00:13:27,710
of you know Jenkins who knows Jenkins

00:13:25,640 --> 00:13:30,860
who's who knows and who is actually

00:13:27,710 --> 00:13:34,310
using Jenkins okay that's good

00:13:30,860 --> 00:13:38,240
so what I always do when I when I start

00:13:34,310 --> 00:13:41,200
a project directly implement a really

00:13:38,240 --> 00:13:43,760
simple continuous integration process

00:13:41,200 --> 00:13:47,330
because it will help you so much later

00:13:43,760 --> 00:13:50,360
on and you're gonna need it then later

00:13:47,330 --> 00:13:55,190
for production anyways another thing is

00:13:50,360 --> 00:13:57,200
monitoring so if you if you do any kind

00:13:55,190 --> 00:13:58,850
of data product you of course interested

00:13:57,200 --> 00:14:01,460
in improving some key performance

00:13:58,850 --> 00:14:04,340
indicator but like recommendations could

00:14:01,460 --> 00:14:08,090
be we can improve our click-through rate

00:14:04,340 --> 00:14:10,130
our conversions and so on so if you do

00:14:08,090 --> 00:14:12,790
that of course you need the whole time

00:14:10,130 --> 00:14:15,620
to monitor things so how was it before

00:14:12,790 --> 00:14:18,170
you implemented your cool new algorithm

00:14:15,620 --> 00:14:20,750
how it was it before maybe you tuned

00:14:18,170 --> 00:14:23,390
something or you retrained so it's

00:14:20,750 --> 00:14:25,880
important to really monitor your KPIs

00:14:23,390 --> 00:14:29,390
it's also important to monitor the whole

00:14:25,880 --> 00:14:33,350
the whole setup like how many requests

00:14:29,390 --> 00:14:36,170
did you have if you provide your your

00:14:33,350 --> 00:14:39,650
recommendations or your predictions as

00:14:36,170 --> 00:14:42,380
as a rest service to see if this comes

00:14:39,650 --> 00:14:44,120
to some kind of limit then also check

00:14:42,380 --> 00:14:45,650
the total number of predictions maybe

00:14:44,120 --> 00:14:48,170
something was wrong in the data

00:14:45,650 --> 00:14:50,870
ingestion and now you you're predicting

00:14:48,170 --> 00:14:54,800
not enough and check the runtimes and so

00:14:50,870 --> 00:14:57,050
on so monitoring keeps you the side so

00:14:54,800 --> 00:15:00,050
not having any kind of monitoring is

00:14:57,050 --> 00:15:02,660
like like flying an airplane blindfolded

00:15:00,050 --> 00:15:05,720
and this is also something that that

00:15:02,660 --> 00:15:07,790
google says so there's there's an

00:15:05,720 --> 00:15:10,070
open-source book by Google the side

00:15:07,790 --> 00:15:13,220
reliability engineering guide and they

00:15:10,070 --> 00:15:15,530
have this nice Hiroki where they say for

00:15:13,220 --> 00:15:18,650
any kind of product the most important

00:15:15,530 --> 00:15:21,200
and fundamental thing they ask at Google

00:15:18,650 --> 00:15:23,630
is actually we have to have monitoring

00:15:21,200 --> 00:15:25,910
in place and I've seen so many times

00:15:23,630 --> 00:15:28,070
that people start with some some data

00:15:25,910 --> 00:15:31,360
science project and no one actually

00:15:28,070 --> 00:15:34,160
cares until monetary about monitoring

00:15:31,360 --> 00:15:34,579
especially important for data science

00:15:34,160 --> 00:15:39,470
and

00:15:34,579 --> 00:15:41,600
and data product is also monitoring how

00:15:39,470 --> 00:15:44,600
good the quality of your model is and I

00:15:41,600 --> 00:15:46,369
mean this is yeah you you have normally

00:15:44,600 --> 00:15:48,410
your metrics and of course you check

00:15:46,369 --> 00:15:50,839
your metrics but you can also do this in

00:15:48,410 --> 00:15:54,350
a live test so here is the so called

00:15:50,839 --> 00:15:56,209
response distribution analysis and it's

00:15:54,350 --> 00:15:58,459
a classification let's say you're

00:15:56,209 --> 00:16:02,929
classifying if a picture is a cat or a

00:15:58,459 --> 00:16:05,179
dog and if you just make a histogram

00:16:02,929 --> 00:16:08,239
over all the results so if it's rather

00:16:05,179 --> 00:16:09,980
around zero a cat or around one a dog

00:16:08,239 --> 00:16:11,689
and if you'd make a histogram over all

00:16:09,980 --> 00:16:14,869
the responses you would directly see

00:16:11,689 --> 00:16:16,910
okay a is a working model and B is a

00:16:14,869 --> 00:16:19,819
rather confused model so it's not really

00:16:16,910 --> 00:16:21,980
sure about what it's outputting and

00:16:19,819 --> 00:16:25,790
having a simple thing like this in place

00:16:21,980 --> 00:16:29,509
will tell you directly if the model you

00:16:25,790 --> 00:16:31,879
maybe just deployed is it's nonsense and

00:16:29,509 --> 00:16:35,360
you have to replace it or fall back to

00:16:31,879 --> 00:16:36,619
another model or or not I mean it's

00:16:35,360 --> 00:16:39,649
definitely better to see this yourself

00:16:36,619 --> 00:16:42,889
before another department calls or maybe

00:16:39,649 --> 00:16:45,860
a customer telling you that yeah

00:16:42,889 --> 00:16:48,410
whatever you just employed is not

00:16:45,860 --> 00:16:50,899
predicting anything meaningful

00:16:48,410 --> 00:16:54,110
another thing regarding monitoring is

00:16:50,899 --> 00:16:58,339
think about a/b tests so if you go to

00:16:54,110 --> 00:17:00,829
production you will you will care about

00:16:58,339 --> 00:17:02,660
those iterative processes you will start

00:17:00,829 --> 00:17:05,029
implementing new features you will make

00:17:02,660 --> 00:17:08,539
improvements to your model so it becomes

00:17:05,029 --> 00:17:11,419
really important to keep track of how

00:17:08,539 --> 00:17:13,250
much you improved with respect to the

00:17:11,419 --> 00:17:14,539
current baseline and it's not always

00:17:13,250 --> 00:17:18,139
like this that you can do this in an

00:17:14,539 --> 00:17:20,480
offline test you also have to show this

00:17:18,139 --> 00:17:21,649
in online metrics and in the end the

00:17:20,480 --> 00:17:24,139
business unit

00:17:21,649 --> 00:17:27,799
order the product owner the stakeholder

00:17:24,139 --> 00:17:30,260
will care about the KPIs because this is

00:17:27,799 --> 00:17:35,299
what he or she gonna report to their

00:17:30,260 --> 00:17:39,889
superiors nice additional advantage you

00:17:35,299 --> 00:17:42,529
have if you are using a BTS is that you

00:17:39,889 --> 00:17:44,389
can for instance also use hyper

00:17:42,529 --> 00:17:47,179
parameter optimization with the help of

00:17:44,389 --> 00:17:48,350
multi armed bandits the technical

00:17:47,179 --> 00:17:50,809
requirements you have

00:17:48,350 --> 00:17:53,230
for AP tests of course you have to have

00:17:50,809 --> 00:17:57,830
versioning in place over I'm really

00:17:53,230 --> 00:17:59,900
eager on versioning so version your

00:17:57,830 --> 00:18:01,610
models version your things provide

00:17:59,900 --> 00:18:04,460
proper Python packages because those

00:18:01,610 --> 00:18:06,679
versions you need a link to the test

00:18:04,460 --> 00:18:09,590
groups if you do some AP tests that you

00:18:06,679 --> 00:18:14,570
see this was version 1.0 and this was

00:18:09,590 --> 00:18:17,240
version 1.1 with a new cool feature and

00:18:14,570 --> 00:18:18,950
also you need to be able in production

00:18:17,240 --> 00:18:20,630
to deploy then several models at the

00:18:18,950 --> 00:18:24,559
same time because you're going to have

00:18:20,630 --> 00:18:26,690
at least two groups and you need to be

00:18:24,559 --> 00:18:28,520
able to track the results really until

00:18:26,690 --> 00:18:31,070
the point where it's facing the customer

00:18:28,520 --> 00:18:32,450
or whatever consumer you have so in case

00:18:31,070 --> 00:18:35,539
of recommendations for instance this

00:18:32,450 --> 00:18:37,700
would be you need to track that this

00:18:35,539 --> 00:18:42,650
prediction or this recommendation from

00:18:37,700 --> 00:18:45,200
model a was shown to this user in in

00:18:42,650 --> 00:18:49,850
Group A and so all this tracking has to

00:18:45,200 --> 00:18:51,559
be in place as if you're using a tensor

00:18:49,850 --> 00:18:53,480
flow I can recommend so in one project

00:18:51,559 --> 00:18:56,900
we use tensor flow serving with this

00:18:53,480 --> 00:18:59,650
which is a tool and open source tool by

00:18:56,900 --> 00:19:02,179
by Google which does a lot for this

00:18:59,650 --> 00:19:08,030
organization and management of different

00:19:02,179 --> 00:19:10,730
models for you so those where some some

00:19:08,030 --> 00:19:13,220
Quality Assurance aspect another big

00:19:10,730 --> 00:19:15,530
topic in the field of data science to

00:19:13,220 --> 00:19:18,710
production is actually organizational

00:19:15,530 --> 00:19:23,900
problems or like cultural problems and

00:19:18,710 --> 00:19:27,049
again it's nothing really new so if we

00:19:23,900 --> 00:19:29,240
look at the problems that normally just

00:19:27,049 --> 00:19:32,030
normal developers and operations have

00:19:29,240 --> 00:19:33,860
most of the time if it's like if you

00:19:32,030 --> 00:19:36,850
have a group like a team of pure

00:19:33,860 --> 00:19:40,340
developers and a team of pure operations

00:19:36,850 --> 00:19:44,510
people then the developers they say ok

00:19:40,340 --> 00:19:47,630
our responsibility is to to code to test

00:19:44,510 --> 00:19:49,940
to make releases of course they use

00:19:47,630 --> 00:19:52,190
version control they do in the best case

00:19:49,940 --> 00:19:54,470
also continuous integration and so on

00:19:52,190 --> 00:19:56,450
and when they are happy with something

00:19:54,470 --> 00:19:59,480
they make this release they throw it

00:19:56,450 --> 00:20:01,970
over the wall of confusion and

00:19:59,480 --> 00:20:04,460
the operations team like yeah thank you

00:20:01,970 --> 00:20:06,110
and now we got a package this and we

00:20:04,460 --> 00:20:08,840
don't understand what's in there but we

00:20:06,110 --> 00:20:10,580
have to package this we deploy it we do

00:20:08,840 --> 00:20:11,750
the whole lifecycle of course there's

00:20:10,580 --> 00:20:15,620
going to be some configuration

00:20:11,750 --> 00:20:17,510
management to do we have to care about

00:20:15,620 --> 00:20:20,480
the security in the monitoring and if

00:20:17,510 --> 00:20:23,539
you keep this completely split up then

00:20:20,480 --> 00:20:27,039
people already realize like years ago

00:20:23,539 --> 00:20:30,950
that this is not the way you can really

00:20:27,039 --> 00:20:33,529
fast and efficiently develop software

00:20:30,950 --> 00:20:38,059
and with data science and data products

00:20:33,529 --> 00:20:40,010
this thinking even hurts more so it's

00:20:38,059 --> 00:20:42,830
especially dangerous for data products

00:20:40,010 --> 00:20:44,779
and teams and you seriously gonna have a

00:20:42,830 --> 00:20:46,789
problem with all your speed and time to

00:20:44,779 --> 00:20:48,950
markets if you just think as a data

00:20:46,789 --> 00:20:51,289
scientists yeah how do I get the things

00:20:48,950 --> 00:20:53,809
in production I don't care it's not my

00:20:51,289 --> 00:20:56,570
job so this is definitely the wrong way

00:20:53,809 --> 00:20:58,610
of thinking so the better way of

00:20:56,570 --> 00:21:01,309
thinking is that you have a team that

00:20:58,610 --> 00:21:04,070
things let's build a great data product

00:21:01,309 --> 00:21:06,049
and not okay I made a great model so

00:21:04,070 --> 00:21:08,570
this is just a different way of thinking

00:21:06,049 --> 00:21:11,090
and for the well for the world of

00:21:08,570 --> 00:21:14,360
software engineering actually there's

00:21:11,090 --> 00:21:17,450
this big movement how many of you know

00:21:14,360 --> 00:21:20,330
DevOps DevOps culture have heard of it

00:21:17,450 --> 00:21:23,299
okay so few so that the idea is just to

00:21:20,330 --> 00:21:25,460
to overcome this wall of confusion to

00:21:23,299 --> 00:21:27,860
make a continuous delivery so that's

00:21:25,460 --> 00:21:29,720
continuous integration but one step

00:21:27,860 --> 00:21:32,809
further that you killed at any point in

00:21:29,720 --> 00:21:36,049
time if you decide also deploy and

00:21:32,809 --> 00:21:38,149
deliver your software and that you have

00:21:36,049 --> 00:21:42,399
hitter heterogeneous teams of developers

00:21:38,149 --> 00:21:47,950
and operations people working together

00:21:42,399 --> 00:21:52,039
so now on on the side of of data

00:21:47,950 --> 00:21:53,840
scientists it's actually yeah we can

00:21:52,039 --> 00:21:56,419
apply the same things so for my

00:21:53,840 --> 00:21:58,429
experience like having pure teams of

00:21:56,419 --> 00:22:00,950
data scientists they don't get anything

00:21:58,429 --> 00:22:03,440
into production because they just lack

00:22:00,950 --> 00:22:06,799
the knowledge to knowledge how to deploy

00:22:03,440 --> 00:22:08,659
and how to do all those things you need

00:22:06,799 --> 00:22:12,649
to do to get it in protraction so let me

00:22:08,659 --> 00:22:13,370
so the the learning is actually that you

00:22:12,649 --> 00:22:15,920
have to have head

00:22:13,370 --> 00:22:18,290
Jeanne's teams of software engineers of

00:22:15,920 --> 00:22:22,640
data scientists of data engineers of

00:22:18,290 --> 00:22:25,070
operations people and if they all work

00:22:22,640 --> 00:22:28,309
together they also start sharing their

00:22:25,070 --> 00:22:31,610
knowledge and they can work together and

00:22:28,309 --> 00:22:34,250
on on a single product and see is there

00:22:31,610 --> 00:22:38,870
responsible a responsibility to get that

00:22:34,250 --> 00:22:41,600
product into production and as a rule of

00:22:38,870 --> 00:22:43,430
thumb it's even that for a single data

00:22:41,600 --> 00:22:46,070
scientists you need two to three data

00:22:43,430 --> 00:22:49,490
engineers which do things which help to

00:22:46,070 --> 00:22:51,440
do the things around so it's really you

00:22:49,490 --> 00:22:55,429
don't actually need that many data

00:22:51,440 --> 00:22:57,980
scientists and right now it's even

00:22:55,429 --> 00:23:00,260
harder to find good data engineers at

00:22:57,980 --> 00:23:03,890
least on a German market than to find

00:23:00,260 --> 00:23:07,280
good data scientists optimally but it's

00:23:03,890 --> 00:23:09,650
also a good thing is to have a product

00:23:07,280 --> 00:23:12,650
manager also embedded directly in the

00:23:09,650 --> 00:23:17,390
team and if your data product is anyway

00:23:12,650 --> 00:23:20,420
related to some yeah for instance like

00:23:17,390 --> 00:23:24,070
again the recommendation topic if you if

00:23:20,420 --> 00:23:26,510
you see if you have a customer facing

00:23:24,070 --> 00:23:29,840
user interface and it's also good to

00:23:26,510 --> 00:23:33,830
have directly the the user interface or

00:23:29,840 --> 00:23:37,670
UX expert in your team because how you

00:23:33,830 --> 00:23:40,610
show things to your customer will also

00:23:37,670 --> 00:23:43,280
dramatically influence the results so

00:23:40,610 --> 00:23:45,290
it's good to have this close and not in

00:23:43,280 --> 00:23:47,510
another team where they maybe do

00:23:45,290 --> 00:23:50,210
completely different decisions without a

00:23:47,510 --> 00:23:55,160
telling you about it a company that

00:23:50,210 --> 00:23:58,280
actually does a lot of this organization

00:23:55,160 --> 00:24:00,559
is Spotify so they are really advanced

00:23:58,280 --> 00:24:04,480
when it comes to this they have fully

00:24:00,559 --> 00:24:07,270
autonomous teams for for every feature

00:24:04,480 --> 00:24:10,100
so they call it it's like vertical teams

00:24:07,270 --> 00:24:12,679
with an end-to-end responsibility so

00:24:10,100 --> 00:24:15,470
really from from the design and from

00:24:12,679 --> 00:24:18,679
where the data comes to how it is shown

00:24:15,470 --> 00:24:21,040
in the in the Spotify application on the

00:24:18,679 --> 00:24:23,600
Spotify website they're completely

00:24:21,040 --> 00:24:26,330
responsibility responsible for this and

00:24:23,600 --> 00:24:27,260
this allows them to to iterate really

00:24:26,330 --> 00:24:30,130
fast

00:24:27,260 --> 00:24:34,460
to have especially less politics and

00:24:30,130 --> 00:24:37,430
this is I've added a link here so you

00:24:34,460 --> 00:24:39,170
can later read about it's it's really

00:24:37,430 --> 00:24:41,860
interesting to see and there are also a

00:24:39,170 --> 00:24:48,100
lot of talks on the web how how Spotify

00:24:41,860 --> 00:24:52,370
organizes their teams around this so

00:24:48,100 --> 00:24:54,320
this was the organizational or more like

00:24:52,370 --> 00:24:57,220
the cultural aspect of data science

00:24:54,320 --> 00:25:00,590
reproduction but we also have a language

00:24:57,220 --> 00:25:04,850
aspects or as I would call it like a two

00:25:00,590 --> 00:25:07,160
language problem so as I've said before

00:25:04,850 --> 00:25:10,040
in the industry

00:25:07,160 --> 00:25:13,490
many people use Java and the reasons

00:25:10,040 --> 00:25:15,710
artists for this are acquired yeah quite

00:25:13,490 --> 00:25:19,180
operas so many people argue that having

00:25:15,710 --> 00:25:22,400
a strongly typed language is so more

00:25:19,180 --> 00:25:26,870
safe because already the compiler finds

00:25:22,400 --> 00:25:29,750
a lot of edge cases and so on and it has

00:25:26,870 --> 00:25:32,000
a strong emphasis on on robustness and

00:25:29,750 --> 00:25:35,320
edge cases then it's it has been an

00:25:32,000 --> 00:25:38,210
industrial standard for many ages and

00:25:35,320 --> 00:25:40,310
for many years and people know how to

00:25:38,210 --> 00:25:44,030
deploy things so if you go in many

00:25:40,310 --> 00:25:45,560
companies you will find that if there's

00:25:44,030 --> 00:25:46,430
a separate operation team they will say

00:25:45,560 --> 00:25:48,770
ok

00:25:46,430 --> 00:25:50,540
only Java things will get into

00:25:48,770 --> 00:25:52,550
production in the end so I don't care

00:25:50,540 --> 00:25:54,650
what you do as a data scientist but it's

00:25:52,550 --> 00:25:56,600
gonna be Java in the end and then

00:25:54,650 --> 00:25:59,330
there's the other side the other world

00:25:56,600 --> 00:26:03,290
where as a data scientist you're more

00:25:59,330 --> 00:26:05,450
like science guy or science person and

00:26:03,290 --> 00:26:08,570
you of course like peyten

00:26:05,450 --> 00:26:10,940
or are you like the dynamic nature of

00:26:08,570 --> 00:26:13,040
the language and you have a stronger

00:26:10,940 --> 00:26:16,220
emphasis on a cool methods and cool

00:26:13,040 --> 00:26:18,230
results and not on on robustness maybe

00:26:16,220 --> 00:26:19,880
and you are happy as long as it runs on

00:26:18,230 --> 00:26:24,050
your machine and so they are just two

00:26:19,880 --> 00:26:26,420
sides and of course there are many ways

00:26:24,050 --> 00:26:30,050
to resolve this problem and I'm gonna

00:26:26,420 --> 00:26:33,340
present now several ways how I've seen

00:26:30,050 --> 00:26:36,679
in projects how it was done and

00:26:33,340 --> 00:26:38,990
can discuss this for instance one is

00:26:36,679 --> 00:26:42,470
just to select one to rule them all

00:26:38,990 --> 00:26:44,870
so I've once been in a project where it

00:26:42,470 --> 00:26:49,010
was said that in the end yeah okay it's

00:26:44,870 --> 00:26:51,650
gotta be Java in the end so right

00:26:49,010 --> 00:26:53,720
directly start doing everything in in

00:26:51,650 --> 00:26:55,880
Java and I know that I've heard of

00:26:53,720 --> 00:26:57,530
I heard that Netflix for instance for

00:26:55,880 --> 00:27:01,520
their recommenders they do directly

00:26:57,530 --> 00:27:04,910
everything in in cha-cha so this has the

00:27:01,520 --> 00:27:06,440
the the up side of it is that if you

00:27:04,910 --> 00:27:08,510
have a single language of course its

00:27:06,440 --> 00:27:11,360
greatest gonna reduce the complexity of

00:27:08,510 --> 00:27:13,250
your deployment I mean most companies

00:27:11,360 --> 00:27:14,690
they know how what to do with Java you

00:27:13,250 --> 00:27:17,300
can package everything in it to a nice

00:27:14,690 --> 00:27:21,140
char and run it in some application

00:27:17,300 --> 00:27:23,870
server or so on and the downside the

00:27:21,140 --> 00:27:25,780
huge downside of of it is of course that

00:27:23,870 --> 00:27:28,490
you're completely abandoning one

00:27:25,780 --> 00:27:32,000
ecosystem in case of Java it would be

00:27:28,490 --> 00:27:34,640
the the peyten ecosystem so you don't

00:27:32,000 --> 00:27:36,740
have scikit-learn you don't have pandas

00:27:34,640 --> 00:27:39,860
and so on so you have to reemployment a

00:27:36,740 --> 00:27:42,679
lot but it's a it's a solution that some

00:27:39,860 --> 00:27:45,040
companies do another thing is if you

00:27:42,679 --> 00:27:48,920
just say okay a patent is the winner how

00:27:45,040 --> 00:27:51,559
about putting everything in patent in

00:27:48,920 --> 00:27:53,740
production this is yeah especially cool

00:27:51,559 --> 00:27:56,900
if you are in a data scientist because

00:27:53,740 --> 00:28:00,470
you can still do your favorite

00:27:56,900 --> 00:28:02,480
programming language I've found from my

00:28:00,470 --> 00:28:05,750
experiences that it's especially useful

00:28:02,480 --> 00:28:08,090
for the batch prediction use cases so in

00:28:05,750 --> 00:28:10,990
the categorization I've shown before so

00:28:08,090 --> 00:28:14,530
if you're doing some kind of predictions

00:28:10,990 --> 00:28:18,020
that you only have to do once a day

00:28:14,530 --> 00:28:20,630
something like like we did it we wonder

00:28:18,020 --> 00:28:23,600
that you you're predicting the demand of

00:28:20,630 --> 00:28:26,240
the next two weeks or so if you have if

00:28:23,600 --> 00:28:28,190
you if you have 24 hours to do one batch

00:28:26,240 --> 00:28:32,720
prediction then it's a perfect use case

00:28:28,190 --> 00:28:35,090
for for Python actually if you need some

00:28:32,720 --> 00:28:36,860
kind of web service still Ruby of course

00:28:35,090 --> 00:28:38,390
you have many partners as a

00:28:36,860 --> 00:28:41,450
general-purpose language you have many

00:28:38,390 --> 00:28:45,919
nice libraries like flask to make some

00:28:41,450 --> 00:28:46,580
small rest service when you do Python

00:28:45,919 --> 00:28:48,950
you can all

00:28:46,580 --> 00:28:51,740
so always just scale horizontally if

00:28:48,950 --> 00:28:54,500
someone comes with the with the point

00:28:51,740 --> 00:28:57,019
that maybe Titan is not fast enough

00:28:54,500 --> 00:28:58,789
compared to Java you can always scale

00:28:57,019 --> 00:29:02,149
horizontally during prediction and

00:28:58,789 --> 00:29:03,950
during training it's what I like the

00:29:02,149 --> 00:29:07,130
most is to have just a big metal node

00:29:03,950 --> 00:29:09,590
with many cores a huge number a huge

00:29:07,130 --> 00:29:12,080
amount of RAM where you can then train

00:29:09,590 --> 00:29:13,970
your model and the good thing with

00:29:12,080 --> 00:29:17,870
python is that you are also not only

00:29:13,970 --> 00:29:20,870
bound to the the patent ecosystem you

00:29:17,870 --> 00:29:23,240
can also tap into the Hadoop world for

00:29:20,870 --> 00:29:25,669
instance with using PI spark and PI hive

00:29:23,240 --> 00:29:28,850
so their libraries they of course have

00:29:25,669 --> 00:29:32,080
some limitations compared to the Java

00:29:28,850 --> 00:29:37,760
libraries but you can do you can

00:29:32,080 --> 00:29:41,600
nowadays with spark 2.3 use a lot of

00:29:37,760 --> 00:29:44,750
things from from Python and if you then

00:29:41,600 --> 00:29:46,460
later I want to deploy something it's

00:29:44,750 --> 00:29:48,919
good to think about our insulated

00:29:46,460 --> 00:29:50,960
containers and maybe use docker for it

00:29:48,919 --> 00:29:53,419
just to have the all the dependencies

00:29:50,960 --> 00:29:56,419
and so on in packaged in one thing

00:29:53,419 --> 00:29:58,190
because there exists nothing like like a

00:29:56,419 --> 00:30:01,880
char file for instance where you have

00:29:58,190 --> 00:30:04,130
everything packaged another solution to

00:30:01,880 --> 00:30:08,269
the problem is what I think is the worst

00:30:04,130 --> 00:30:11,600
case scenario is you let a team of data

00:30:08,269 --> 00:30:14,990
scientists do something in in in Titan

00:30:11,600 --> 00:30:17,269
or R and then some poor person has to

00:30:14,990 --> 00:30:19,700
rewrite everything in Java so this is

00:30:17,269 --> 00:30:21,769
something which once happened to me that

00:30:19,700 --> 00:30:24,230
I brought a lot of Python and then we

00:30:21,769 --> 00:30:26,510
were sitting together and making a

00:30:24,230 --> 00:30:29,029
conversion to Java because it was only

00:30:26,510 --> 00:30:32,840
allowed to have Java and protection it's

00:30:29,029 --> 00:30:35,929
really lots of effort it's slow if you

00:30:32,840 --> 00:30:37,490
then later on we said it's building a

00:30:35,929 --> 00:30:39,440
data product it's an iterative process

00:30:37,490 --> 00:30:42,980
so if you later on decide on new

00:30:39,440 --> 00:30:45,850
features then of course you implement

00:30:42,980 --> 00:30:48,559
them first in in titan then someone

00:30:45,850 --> 00:30:51,529
moves it over to java it's it takes

00:30:48,559 --> 00:30:54,889
forever it's causing a lot of bugs if

00:30:51,529 --> 00:30:57,770
you see a back in production it's always

00:30:54,889 --> 00:30:59,789
hard to find out ok is the back maybe in

00:30:57,770 --> 00:31:02,549
the java code

00:30:59,789 --> 00:31:04,710
or is an actual reason in the in

00:31:02,549 --> 00:31:09,270
diversity in the in the Python code so

00:31:04,710 --> 00:31:10,740
is it by design a mistake so the the

00:31:09,270 --> 00:31:15,659
upside is that everyone gets what they

00:31:10,740 --> 00:31:19,140
want but I would never argue in favor of

00:31:15,659 --> 00:31:20,750
this solution to the to the two language

00:31:19,140 --> 00:31:22,289
problem

00:31:20,750 --> 00:31:25,679
[Music]

00:31:22,289 --> 00:31:29,549
so another thing I've never really tried

00:31:25,679 --> 00:31:31,590
out is that you say okay let's just use

00:31:29,549 --> 00:31:35,159
exchangeable formats I mean there are

00:31:31,590 --> 00:31:37,770
many rounds like PMML or an annex and so

00:31:35,159 --> 00:31:40,140
on they work great in theory but if you

00:31:37,770 --> 00:31:42,270
try a little bit algorithm so just we

00:31:40,140 --> 00:31:44,340
retested it once we never put something

00:31:42,270 --> 00:31:46,470
like this in production is that they

00:31:44,340 --> 00:31:50,039
have quite a limited functionality you

00:31:46,470 --> 00:31:52,200
have no guarantee that if use Python you

00:31:50,039 --> 00:31:54,240
do your model you save it in some

00:31:52,200 --> 00:31:57,900
exchangeable format and then you read it

00:31:54,240 --> 00:32:00,240
in in Java for instance that it really

00:31:57,900 --> 00:32:01,309
does the same thing so you have to image

00:32:00,240 --> 00:32:05,070
you have to trust those two

00:32:01,309 --> 00:32:08,250
implementations and yeah I mean it's

00:32:05,070 --> 00:32:11,159
just like even with something like HTML

00:32:08,250 --> 00:32:13,020
you never to websites and never render

00:32:11,159 --> 00:32:15,900
the same way on two different browsers

00:32:13,020 --> 00:32:18,950
so why would it be why would it work

00:32:15,900 --> 00:32:21,690
then for those exchangeable formats so

00:32:18,950 --> 00:32:23,490
yeah and another downside they often

00:32:21,690 --> 00:32:26,070
have they don't include a pre-processing

00:32:23,490 --> 00:32:27,270
and future generation so this is what I

00:32:26,070 --> 00:32:29,190
said before when I'm talking about the

00:32:27,270 --> 00:32:31,799
model it's not only the machine learning

00:32:29,190 --> 00:32:33,630
algorithm it's also all the imputations

00:32:31,799 --> 00:32:37,320
and all the things you did beforehand

00:32:33,630 --> 00:32:39,720
and of course those exchangeable formats

00:32:37,320 --> 00:32:43,620
they need to be able to specify this

00:32:39,720 --> 00:32:47,010
otherwise your reimplemented things

00:32:43,620 --> 00:32:51,299
again another solution for the language

00:32:47,010 --> 00:32:53,669
problem is using frameworks so we've

00:32:51,299 --> 00:32:55,590
used tensorflow for especially for some

00:32:53,669 --> 00:32:59,010
recommendation tasks and it's really

00:32:55,590 --> 00:33:01,380
nice in the way that you use peyten

00:32:59,010 --> 00:33:05,250
to train your model you save it in some

00:33:01,380 --> 00:33:08,610
some binary format some protobuf based a

00:33:05,250 --> 00:33:11,250
format and then this this binary blob

00:33:08,610 --> 00:33:15,120
can be read in by Java and so

00:33:11,250 --> 00:33:17,280
by Java and this is a really nice thing

00:33:15,120 --> 00:33:20,760
there are there are frameworks of course

00:33:17,280 --> 00:33:23,580
h2o is quite common we've also done

00:33:20,760 --> 00:33:25,500
something with this and there we had a

00:33:23,580 --> 00:33:28,500
little bit of problem that not it

00:33:25,500 --> 00:33:30,690
doesn't allow so much pre-processing so

00:33:28,500 --> 00:33:32,760
there you have basic machine learning

00:33:30,690 --> 00:33:35,250
algorithms in there but not all of the

00:33:32,760 --> 00:33:38,250
pre-processing and there's also that you

00:33:35,250 --> 00:33:40,530
use Python to build your model then you

00:33:38,250 --> 00:33:44,070
save everything into a mode show file

00:33:40,530 --> 00:33:46,380
it's called and later on - I can run it

00:33:44,070 --> 00:33:48,360
if you opt for this solution which I

00:33:46,380 --> 00:33:51,990
think can be a valid one depending on

00:33:48,360 --> 00:33:53,520
your use case as I said many times but

00:33:51,990 --> 00:33:57,660
of course you should always keep in mind

00:33:53,520 --> 00:34:00,330
that you are paying with flexibility so

00:33:57,660 --> 00:34:03,030
if you decide on a framework you will

00:34:00,330 --> 00:34:07,280
only ever be able to do what if what the

00:34:03,030 --> 00:34:10,230
framework provides which can be fine but

00:34:07,280 --> 00:34:14,460
maybe it's a little it's limitation also

00:34:10,230 --> 00:34:17,970
so we've basically we have seen

00:34:14,460 --> 00:34:20,879
different ways different possibilities

00:34:17,970 --> 00:34:23,460
different doors how to how to overcome

00:34:20,879 --> 00:34:26,370
this two language problem there's the

00:34:23,460 --> 00:34:28,500
reimplementation just we implement

00:34:26,370 --> 00:34:30,990
everything in Java or use a framework or

00:34:28,500 --> 00:34:34,139
deciding a single language so from my

00:34:30,990 --> 00:34:38,520
experience definitely reimplementation

00:34:34,139 --> 00:34:42,690
is no option so don't do this I've been

00:34:38,520 --> 00:34:45,899
there it's it's not working so good

00:34:42,690 --> 00:34:49,169
of course frameworks our valid solution

00:34:45,899 --> 00:34:50,790
if you use tensorflow or h2o they can

00:34:49,169 --> 00:34:53,669
really help you get things into

00:34:50,790 --> 00:34:55,409
production way easier and overcoming the

00:34:53,669 --> 00:34:57,360
the two language problem and if you

00:34:55,409 --> 00:35:00,030
decide on a single language okay I'm a

00:34:57,360 --> 00:35:04,650
bit biased here I would definitely

00:35:00,030 --> 00:35:08,640
choose Python and not let data scientist

00:35:04,650 --> 00:35:16,460
program in in Java because this is

00:35:08,640 --> 00:35:20,490
really frustrating or even Scala so

00:35:16,460 --> 00:35:22,890
talking about yeah so we've talked about

00:35:20,490 --> 00:35:23,400
the language problem and now a little

00:35:22,890 --> 00:35:26,450
bit more

00:35:23,400 --> 00:35:30,660
about deployment and some may be general

00:35:26,450 --> 00:35:31,589
advices and good practices of course the

00:35:30,660 --> 00:35:33,380
deployment

00:35:31,589 --> 00:35:37,289
there's no as I said before there's no

00:35:33,380 --> 00:35:40,190
one-size-fits-all it heavily depends on

00:35:37,289 --> 00:35:42,750
your use case and of the use case

00:35:40,190 --> 00:35:46,470
evaluation that you have done before of

00:35:42,750 --> 00:35:48,150
course there are software engineering

00:35:46,470 --> 00:35:49,950
principles that you should always use

00:35:48,150 --> 00:35:52,380
like as I said before continuous

00:35:49,950 --> 00:35:57,150
integration continuous delivery I can

00:35:52,380 --> 00:36:01,230
say it often enough just do it and also

00:35:57,150 --> 00:36:04,230
think about what part of your machine

00:36:01,230 --> 00:36:06,000
learning code actually how big it is

00:36:04,230 --> 00:36:08,910
compared to all the other things so

00:36:06,000 --> 00:36:12,660
there's a nice paper by Scully 2015

00:36:08,910 --> 00:36:14,910
already a few years old it's it's saying

00:36:12,660 --> 00:36:17,609
where the technical depth in machine

00:36:14,910 --> 00:36:19,829
learning systems actually is and we see

00:36:17,609 --> 00:36:21,420
that in the middle your machine learning

00:36:19,829 --> 00:36:25,829
code there's not much technical debt in

00:36:21,420 --> 00:36:28,380
there but everything around just tech

00:36:25,829 --> 00:36:31,500
doesn't get enough focus and a lot of

00:36:28,380 --> 00:36:35,279
those boxes are actually related to

00:36:31,500 --> 00:36:38,069
deployment so your configuration your

00:36:35,279 --> 00:36:39,990
process management your machine rules

00:36:38,069 --> 00:36:42,630
resource management your serving

00:36:39,990 --> 00:36:44,430
infrastructure your monitor especially

00:36:42,630 --> 00:36:46,500
those are all things you need to care

00:36:44,430 --> 00:36:49,710
about and this doesn't get enough

00:36:46,500 --> 00:36:52,470
attention in in really many projects so

00:36:49,710 --> 00:36:57,000
this Scalli paper was a kind of survey

00:36:52,470 --> 00:37:00,960
and it's good to keep this in in in mind

00:36:57,000 --> 00:37:03,450
so general principles again version your

00:37:00,960 --> 00:37:07,200
things package have processes and

00:37:03,450 --> 00:37:09,059
quality manages management in place it

00:37:07,200 --> 00:37:10,440
also helps to keep the development and

00:37:09,059 --> 00:37:13,260
production environment as similar as

00:37:10,440 --> 00:37:16,470
possible as possible of course so like

00:37:13,260 --> 00:37:19,109
programming your one thing on a Mac and

00:37:16,470 --> 00:37:21,180
moving everything else then on on a

00:37:19,109 --> 00:37:24,119
Linux system I mean already there you

00:37:21,180 --> 00:37:27,329
can run into problem even if it's with

00:37:24,119 --> 00:37:28,680
Titan automate as much as possible again

00:37:27,329 --> 00:37:32,010
continuous integration continuous

00:37:28,680 --> 00:37:34,400
delivery and this also byte avoids human

00:37:32,010 --> 00:37:36,510
errors and think about controllable

00:37:34,400 --> 00:37:39,390
environments like

00:37:36,510 --> 00:37:42,080
like for instance by using docker or at

00:37:39,390 --> 00:37:45,980
least having Condor environments or

00:37:42,080 --> 00:37:50,010
other environments that you can pin

00:37:45,980 --> 00:37:53,910
persons down Google also thinks a lot

00:37:50,010 --> 00:37:56,280
about this and they have also nice a

00:37:53,910 --> 00:37:58,410
blog post about best practices for

00:37:56,280 --> 00:38:01,340
machine learning engineering I'm not

00:37:58,410 --> 00:38:05,220
going to go through all those different

00:38:01,340 --> 00:38:07,619
rules basically many have been already a

00:38:05,220 --> 00:38:09,960
set design and implement metrics and so

00:38:07,619 --> 00:38:12,600
on most of them are actually if you want

00:38:09,960 --> 00:38:14,700
to bring things in into production most

00:38:12,600 --> 00:38:17,700
of things are actually engineering

00:38:14,700 --> 00:38:20,369
problems so this is it's in the end it's

00:38:17,700 --> 00:38:22,470
not your cool data science model it's

00:38:20,369 --> 00:38:24,869
really a lot of engineering problems you

00:38:22,470 --> 00:38:30,240
have to overcome to bring things into

00:38:24,869 --> 00:38:33,750
production just as as a practical tip

00:38:30,240 --> 00:38:38,130
how easy or practical advice how easy it

00:38:33,750 --> 00:38:40,890
is to do continuous integration there

00:38:38,130 --> 00:38:43,260
it's also a blog post link you will

00:38:40,890 --> 00:38:46,770
later see the slides but if you use

00:38:43,260 --> 00:38:51,060
champions and let's say the FBI artifact

00:38:46,770 --> 00:38:53,700
store - to save your rebuild packages

00:38:51,060 --> 00:38:56,040
it's just like - chops you have one

00:38:53,700 --> 00:38:59,130
chenkin shops that clones to repo builds

00:38:56,040 --> 00:39:02,160
the package pushes it in some unstable

00:38:59,130 --> 00:39:06,300
index then you have another Jenkins job

00:39:02,160 --> 00:39:11,400
that installs the package runs the unit

00:39:06,300 --> 00:39:13,800
tests after having cloned the repository

00:39:11,400 --> 00:39:16,590
again and then depending on the results

00:39:13,800 --> 00:39:19,890
of the unit test pushes it back into

00:39:16,590 --> 00:39:22,800
some time testing or some stable index

00:39:19,890 --> 00:39:26,430
and then other people can use the new

00:39:22,800 --> 00:39:29,280
version and speaking about packaging so

00:39:26,430 --> 00:39:31,440
a really cool tool for doing this and

00:39:29,280 --> 00:39:34,109
it's really easy to use it's like a five

00:39:31,440 --> 00:39:36,600
seconds thing it's PI scaffold it

00:39:34,109 --> 00:39:39,650
provides you easy insane Python packages

00:39:36,600 --> 00:39:43,320
it's just giving you a kind of template

00:39:39,650 --> 00:39:45,869
tool for this template a scaffold for a

00:39:43,320 --> 00:39:47,880
typical Python project it provides you

00:39:45,869 --> 00:39:49,530
with versioning for every commit so you

00:39:47,880 --> 00:39:52,200
basically just do

00:39:49,530 --> 00:39:55,050
get tax and so on for the version and

00:39:52,200 --> 00:39:58,890
then it enumerates the commit so you

00:39:55,050 --> 00:40:02,490
have unique versions out-of-the-box it

00:39:58,890 --> 00:40:05,280
integrates really well with with git has

00:40:02,490 --> 00:40:08,579
pre commit you have a declarative way of

00:40:05,280 --> 00:40:10,800
defining all the the configuration for

00:40:08,579 --> 00:40:13,680
your for your package with the help of

00:40:10,800 --> 00:40:16,410
setup config it follows community

00:40:13,680 --> 00:40:22,970
standards and you can even extend it

00:40:16,410 --> 00:40:27,180
with your extension so as the last light

00:40:22,970 --> 00:40:29,849
short recap what we learned so the key

00:40:27,180 --> 00:40:32,190
learnings really are for data science to

00:40:29,849 --> 00:40:34,920
production that there's no

00:40:32,190 --> 00:40:37,349
one-size-fits-all solution evaluate your

00:40:34,920 --> 00:40:40,530
use case and then think about how you

00:40:37,349 --> 00:40:44,520
can bring things into production early

00:40:40,530 --> 00:40:47,609
on think about quality Quality Assurance

00:40:44,520 --> 00:40:49,980
is really important try to establish a

00:40:47,609 --> 00:40:51,750
def ops culture and the team

00:40:49,980 --> 00:40:54,599
responsibility for the whole data

00:40:51,750 --> 00:40:57,450
product and not just for some fancy data

00:40:54,599 --> 00:41:00,270
science model then think about how you

00:40:57,450 --> 00:41:03,030
overcome the two language a problem that

00:41:00,270 --> 00:41:05,970
you might have as a Python developer and

00:41:03,030 --> 00:41:09,450
praised processes and automate automate

00:41:05,970 --> 00:41:11,310
as much as possible and the key thing

00:41:09,450 --> 00:41:14,490
really is production is not an

00:41:11,310 --> 00:41:17,400
afterthought so think early on about how

00:41:14,490 --> 00:41:20,490
you can later move things into

00:41:17,400 --> 00:41:23,490
production with this I want to close my

00:41:20,490 --> 00:41:25,970
talk thank you for your patience and

00:41:23,490 --> 00:41:25,970
your attention

00:41:29,990 --> 00:41:33,420
thank you very much florium very

00:41:32,400 --> 00:41:35,790
interesting talk

00:41:33,420 --> 00:41:37,920
and many interesting and important

00:41:35,790 --> 00:41:43,320
things you have to do and we develop

00:41:37,920 --> 00:41:46,440
software any questions yes well thanks

00:41:43,320 --> 00:41:47,940
thanks we'll talk is really great to see

00:41:46,440 --> 00:41:50,120
some putting effort in sharing those

00:41:47,940 --> 00:41:53,970
insights I've got a question on the

00:41:50,120 --> 00:41:56,460
monitoring part of your talk how would

00:41:53,970 --> 00:41:59,550
you put a process in place to monitor

00:41:56,460 --> 00:42:02,390
the performance of the model whether

00:41:59,550 --> 00:42:06,840
it's making suitable recommendations or

00:42:02,390 --> 00:42:08,970
predictions after right because a thing

00:42:06,840 --> 00:42:10,740
you mentioned a technique whereby you

00:42:08,970 --> 00:42:13,800
can visually see if the model is

00:42:10,740 --> 00:42:15,360
confused but what about when we don't

00:42:13,800 --> 00:42:17,460
really know what's of input the model is

00:42:15,360 --> 00:42:19,140
gonna is going to get how can we later

00:42:17,460 --> 00:42:21,450
on and see if we can improve the model

00:42:19,140 --> 00:42:25,170
based on Arizona might have done and put

00:42:21,450 --> 00:42:27,960
a processor on that yes so I would

00:42:25,170 --> 00:42:31,050
divide monitoring in in several parts of

00:42:27,960 --> 00:42:33,390
course you need to have some monitoring

00:42:31,050 --> 00:42:35,640
for the incoming data this is really

00:42:33,390 --> 00:42:38,010
important because then you can easily

00:42:35,640 --> 00:42:41,400
see all the errors which are just due to

00:42:38,010 --> 00:42:44,400
the fact that you got new outliers or

00:42:41,400 --> 00:42:46,530
maybe just not available value somewhere

00:42:44,400 --> 00:42:49,380
so you should have monitoring in place

00:42:46,530 --> 00:42:51,930
this is the incoming data does it still

00:42:49,380 --> 00:42:56,550
look like last week you can define

00:42:51,930 --> 00:42:59,130
alarms on this and like okay suddenly we

00:42:56,550 --> 00:43:03,120
have not seven categories in this

00:42:59,130 --> 00:43:05,460
feature but ten or why are the number of

00:43:03,120 --> 00:43:08,220
not available values went up from 10

00:43:05,460 --> 00:43:10,950
percent to 50 percent and so on so this

00:43:08,220 --> 00:43:13,980
is like the early alarming what goes

00:43:10,950 --> 00:43:17,850
into your model and then you have the

00:43:13,980 --> 00:43:20,490
monitoring some some after your models

00:43:17,850 --> 00:43:22,800
so the results of your model there you

00:43:20,490 --> 00:43:25,170
can check simple things like how many

00:43:22,800 --> 00:43:28,410
predictions did I make is the number of

00:43:25,170 --> 00:43:31,080
predictions still as high as maybe last

00:43:28,410 --> 00:43:32,460
week if you're yeah I don't know

00:43:31,080 --> 00:43:34,320
depending on your use case what you are

00:43:32,460 --> 00:43:38,190
at predicting then what I showed before

00:43:34,320 --> 00:43:41,520
this one slide about that you really

00:43:38,190 --> 00:43:43,320
check each result and do this histogram

00:43:41,520 --> 00:43:49,170
this response analysis of

00:43:43,320 --> 00:43:53,220
model this can really help and of course

00:43:49,170 --> 00:43:55,470
also those when you iterate and make a

00:43:53,220 --> 00:43:59,700
new model you will have some offline

00:43:55,470 --> 00:44:02,760
metrics that you also save those and put

00:43:59,700 --> 00:44:05,040
the version number next to it that you

00:44:02,760 --> 00:44:08,400
can see maybe I mean it looked good

00:44:05,040 --> 00:44:11,550
offline but then the online KPI metrics

00:44:08,400 --> 00:44:14,250
went down so this is again like offline

00:44:11,550 --> 00:44:17,490
offline metrics there you can autumn is

00:44:14,250 --> 00:44:20,610
a lot and check for accuracy or recall

00:44:17,490 --> 00:44:24,420
or whatever you want to check and at the

00:44:20,610 --> 00:44:28,050
same times you have to look at yeah at

00:44:24,420 --> 00:44:30,450
the KPI switch my might be then the the

00:44:28,050 --> 00:44:31,710
click-through rate so there are many it

00:44:30,450 --> 00:44:33,590
really depends on the use case for there

00:44:31,710 --> 00:44:36,930
are many aspects so I would say input

00:44:33,590 --> 00:44:39,570
output then the model quality technical

00:44:36,930 --> 00:44:41,550
things like also is there maybe maybe

00:44:39,570 --> 00:44:45,180
your model is getting slower and you

00:44:41,550 --> 00:44:53,280
running into a lot of time outs and all

00:44:45,180 --> 00:44:57,480
those things so what did you ask you

00:44:53,280 --> 00:45:01,290
about the debacle tool now you have the

00:44:57,480 --> 00:45:03,750
Bob's culture okay if you have

00:45:01,290 --> 00:45:07,230
experienced that before and what

00:45:03,750 --> 00:45:13,080
problems did you find integrated the

00:45:07,230 --> 00:45:18,060
whole different thing skills to to work

00:45:13,080 --> 00:45:19,980
as a system thinking so I've in in one

00:45:18,060 --> 00:45:21,780
project it was before that that we were

00:45:19,980 --> 00:45:24,660
like only data scientists and then we

00:45:21,780 --> 00:45:27,240
had all those problems then there was a

00:45:24,660 --> 00:45:31,410
decision made that we have heterogeneous

00:45:27,240 --> 00:45:34,350
teams and then we were yeah doing more a

00:45:31,410 --> 00:45:37,110
DevOps culture I mean of course first of

00:45:34,350 --> 00:45:39,450
all it's a little bit ok why do we will

00:45:37,110 --> 00:45:41,640
now work together and people react

00:45:39,450 --> 00:45:45,170
differently on this and then there's

00:45:41,640 --> 00:45:47,400
also this like struggles sometimes if

00:45:45,170 --> 00:45:49,620
let's say there comes the software

00:45:47,400 --> 00:45:51,570
engineer and asks you about your model

00:45:49,620 --> 00:45:53,820
and then make some people get critical

00:45:51,570 --> 00:45:56,060
like so hey I'm the data scientist what

00:45:53,820 --> 00:45:58,400
are you asking me

00:45:56,060 --> 00:46:01,490
why I'm am I doing this in my model I am

00:45:58,400 --> 00:46:04,730
the expert and for some people this can

00:46:01,490 --> 00:46:07,850
be quite hard at first but yeah you have

00:46:04,730 --> 00:46:10,610
to overcome this you you you need to

00:46:07,850 --> 00:46:12,500
communicate and you need to think okay

00:46:10,610 --> 00:46:15,530
this person has another background but

00:46:12,500 --> 00:46:17,960
it has all the person has all the rights

00:46:15,530 --> 00:46:20,630
to know what is going on in the model so

00:46:17,960 --> 00:46:23,120
there's at least starts with a little

00:46:20,630 --> 00:46:25,400
struggle I would say but then it comes

00:46:23,120 --> 00:46:26,810
down and it's definitely better in the

00:46:25,400 --> 00:46:30,920
end then it was before from my

00:46:26,810 --> 00:46:34,850
experience but yeah it's it also depends

00:46:30,920 --> 00:46:36,740
on what kind of people are in your team

00:46:34,850 --> 00:46:39,710
if you have maybe some completely

00:46:36,740 --> 00:46:44,480
introverted data scientist and it could

00:46:39,710 --> 00:46:47,390
be hard for them maybe so yeah okay last

00:46:44,480 --> 00:46:50,660
question hi

00:46:47,390 --> 00:46:53,360
so I think the choice of the language is

00:46:50,660 --> 00:46:56,570
definitely a big issue in my company so

00:46:53,360 --> 00:46:59,210
basically we have a very heavy and Java

00:46:56,570 --> 00:47:01,670
lacus need process it is served two

00:46:59,210 --> 00:47:04,730
things one thing is a big like pipeline

00:47:01,670 --> 00:47:06,590
like unit one to sing one thing and then

00:47:04,730 --> 00:47:09,980
feed the data to unit to their own

00:47:06,590 --> 00:47:12,440
injera but now we want to plug in PI

00:47:09,980 --> 00:47:14,570
sending computations so the way we are

00:47:12,440 --> 00:47:16,490
trying it is from individual we still

00:47:14,570 --> 00:47:18,770
keep the pike bone as a Java and then an

00:47:16,490 --> 00:47:21,020
individual node we try to wrap around

00:47:18,770 --> 00:47:23,720
the Python script but basically Java

00:47:21,020 --> 00:47:26,540
wrap around a pison and then fire up the

00:47:23,720 --> 00:47:28,250
Tyson process you know the data and

00:47:26,540 --> 00:47:30,320
caching certainly the problem so we

00:47:28,250 --> 00:47:33,500
would like to you know explore like

00:47:30,320 --> 00:47:36,710
Apache arrow in the near future so do

00:47:33,500 --> 00:47:39,320
you have any you know experience of you

00:47:36,710 --> 00:47:41,210
know Java fire up fireplace and

00:47:39,320 --> 00:47:46,070
personnel share the cache sort of

00:47:41,210 --> 00:47:48,170
experiment actually also try to I once

00:47:46,070 --> 00:47:50,690
had the idea yeah well I just do some

00:47:48,170 --> 00:47:53,930
char where I put in all my Python code

00:47:50,690 --> 00:47:55,400
and then run it and I had extreme

00:47:53,930 --> 00:47:57,890
problem getting this to run with any

00:47:55,400 --> 00:48:01,010
kind of library like like numpy and so

00:47:57,890 --> 00:48:04,610
on there is just PI for J you can do

00:48:01,010 --> 00:48:07,220
things like this and for simple for

00:48:04,610 --> 00:48:09,260
really simple Python application it

00:48:07,220 --> 00:48:12,380
works but really simple

00:48:09,260 --> 00:48:15,100
would not it's really it's a hack and if

00:48:12,380 --> 00:48:18,200
you then have any numpy which is see

00:48:15,100 --> 00:48:21,340
also wrapped in this and you have those

00:48:18,200 --> 00:48:25,090
conversion costs but then again I'm not

00:48:21,340 --> 00:48:28,520
I'm no expert in in those Java to

00:48:25,090 --> 00:48:31,369
tighten thing like on a on a really

00:48:28,520 --> 00:48:35,450
software level I know I know

00:48:31,369 --> 00:48:38,420
arrow and it's in spark 2.3 and things

00:48:35,450 --> 00:48:42,050
get a lot faster but I've never broke

00:48:38,420 --> 00:48:44,869
 with arrow directly because but I

00:48:42,050 --> 00:48:48,260
would actually I would be careful with

00:48:44,869 --> 00:48:51,200
doing things like this wrapping your

00:48:48,260 --> 00:48:53,840
Python things in in in in Java

00:48:51,200 --> 00:48:57,710
sounds like you check to me I would

00:48:53,840 --> 00:49:00,470
rather go for establishing interfaces I

00:48:57,710 --> 00:49:02,540
mean if you have a pipeline and I mean

00:49:00,470 --> 00:49:05,180
depending on your runtime requirements

00:49:02,540 --> 00:49:07,520
if you can say you use a database as an

00:49:05,180 --> 00:49:09,320
interface kind of thing that it's safe

00:49:07,520 --> 00:49:11,390
there and you grab it from Python you do

00:49:09,320 --> 00:49:13,880
your calculation you save it there then

00:49:11,390 --> 00:49:15,619
it could work depending how fast it

00:49:13,880 --> 00:49:18,890
needs to be in the end but I would

00:49:15,619 --> 00:49:22,730
rather define some clear interfaces and

00:49:18,890 --> 00:49:27,250
not do any kind of black magic with pipe

00:49:22,730 --> 00:49:27,250

YouTube URL: https://www.youtube.com/watch?v=ItcMqTR7Cds


