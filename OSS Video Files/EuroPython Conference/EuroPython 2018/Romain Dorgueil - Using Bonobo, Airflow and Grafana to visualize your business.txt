Title: Romain Dorgueil - Using Bonobo, Airflow and Grafana to visualize your business
Publication date: 2018-08-22
Playlist: EuroPython 2018
Description: 
	Using Bonobo, Airflow and Grafana to visualize your business
[EuroPython 2018 - Talk - 2018-07-25 - PyCharm [PyData]]
[Edinburgh, UK]

By Romain Dorgueil

Zero-to-one hands-on introduction to building a business dashboard using Bonobo ETL, Airflow, and a bit of Grafana (because graphs are cool).

There is no need of prior knowledge about any of those tools.

After a short introduction about the tools, we'll go through the following topics, using the real data of a small SaaS software:


One can expect to be able to build a similar system at the end of the talk in a few days (of course, the implementation is only a small part of this process, data is what really matters).

«Metrics you watch tend to improve over time»



License: This video is licensed under the CC BY-NC-SA 3.0 license: https://creativecommons.org/licenses/by-nc-sa/3.0/
Please see our speaker release agreement for details: https://ep2018.europython.eu/en/speaker-release-agreement/
Captions: 
	00:00:06,379 --> 00:00:14,070
thank you very much for the introduction

00:00:09,080 --> 00:00:16,440
so yes today I want to tell a bit of a

00:00:14,070 --> 00:00:20,670
story of how we build business

00:00:16,440 --> 00:00:22,560
dashboards for for products I am indeed

00:00:20,670 --> 00:00:24,900
the creator of boo no boo but I want to

00:00:22,560 --> 00:00:28,410
talk just about bonobo I will show

00:00:24,900 --> 00:00:30,210
different tools and so yes using bonobo

00:00:28,410 --> 00:00:32,070
afro and graphing are all together to

00:00:30,210 --> 00:00:37,140
build really quickly some business

00:00:32,070 --> 00:00:40,590
dashboard before we start so I'm Honda I

00:00:37,140 --> 00:00:43,860
am making computer related stuff since

00:00:40,590 --> 00:00:47,129
quite a long time now and this year my

00:00:43,860 --> 00:00:48,960
focus is I decided to change quite a bit

00:00:47,129 --> 00:00:52,440
what I doing and I'm building a new

00:00:48,960 --> 00:00:55,949
company called Maker squad my goal is to

00:00:52,440 --> 00:00:59,190
build cloud native products mostly SAS

00:00:55,949 --> 00:01:04,229
products using containers and stuff like

00:00:59,190 --> 00:01:08,820
this for either myself and live on

00:01:04,229 --> 00:01:12,299
subscription or either clients and onion

00:01:08,820 --> 00:01:14,070
just help them achieve this this cloud

00:01:12,299 --> 00:01:16,560
native stuff which is not really natural

00:01:14,070 --> 00:01:18,390
for a lot so there is a lot of stuff

00:01:16,560 --> 00:01:20,820
today I'm so if I'm good too fast

00:01:18,390 --> 00:01:24,090
sometime but I will give you a sidekick

00:01:20,820 --> 00:01:27,299
link after with all the all the code and

00:01:24,090 --> 00:01:29,490
everything the IDS I will introduce the

00:01:27,299 --> 00:01:31,320
product so you know what we're talking

00:01:29,490 --> 00:01:34,290
about it's a bit of background context

00:01:31,320 --> 00:01:38,670
then we'll see how to plan what we want

00:01:34,290 --> 00:01:40,619
to - bada is and we'll go into the

00:01:38,670 --> 00:01:41,939
technical part which is implementing the

00:01:40,619 --> 00:01:45,659
data pipelines using burnable

00:01:41,939 --> 00:01:48,509
visualizing it using Rafina and running

00:01:45,659 --> 00:01:52,079
seriously in production with a fro on

00:01:48,509 --> 00:01:55,710
the bit of what we'll go from there

00:01:52,079 --> 00:01:58,439
after that but yeah that will be it so

00:01:55,710 --> 00:02:01,500
it has been said but I created bonobos

00:01:58,439 --> 00:02:03,420
off so I'm a bit buys it here I'm sorry

00:02:01,500 --> 00:02:05,219
about that I'll try to be objective but

00:02:03,420 --> 00:02:07,229
make your own opinion if you're building

00:02:05,219 --> 00:02:08,819
a product you're bringing anything make

00:02:07,229 --> 00:02:11,599
your own research take a look a lot of

00:02:08,819 --> 00:02:14,150
time in planning it's very important

00:02:11,599 --> 00:02:15,799
yeah I recommend nothing but maybe it's

00:02:14,150 --> 00:02:21,379
an idea you could try to apply to you

00:02:15,799 --> 00:02:24,920
your own products and business so the

00:02:21,379 --> 00:02:28,159
product it's a pretty simple thing it's

00:02:24,920 --> 00:02:33,230
something that's you give a neural size

00:02:28,159 --> 00:02:35,540
and it returns an image it was in fact a

00:02:33,230 --> 00:02:37,790
service that's a friend of mine develop

00:02:35,540 --> 00:02:39,560
had a long time ago like 10 years ago an

00:02:37,790 --> 00:02:42,469
infinite amount of time in the internet

00:02:39,560 --> 00:02:46,790
age and it was written like this in

00:02:42,469 --> 00:02:50,419
January if we time Delta years 9 I added

00:02:46,790 --> 00:02:52,909
a parameter to time Delta here we come

00:02:50,419 --> 00:02:56,480
to February way decided that it was not

00:02:52,909 --> 00:02:58,790
making money it was using a lot of time

00:02:56,480 --> 00:03:01,280
wasting a lot of time and it was time to

00:02:58,790 --> 00:03:03,739
shut down the service and this time I

00:03:01,280 --> 00:03:07,430
called him and we agreed on me taking

00:03:03,739 --> 00:03:10,040
over the service with one new thing and

00:03:07,430 --> 00:03:13,340
so in March he started to send me his

00:03:10,040 --> 00:03:14,780
traffic and I didn't think he had this

00:03:13,340 --> 00:03:18,169
many traffic so I started serving

00:03:14,780 --> 00:03:20,840
gateway timeouts but after a bit of work

00:03:18,169 --> 00:03:22,790
a lot of work actually I would serve the

00:03:20,840 --> 00:03:26,150
new version of the of the website with

00:03:22,790 --> 00:03:28,519
which was no PHP anymore all Python and

00:03:26,150 --> 00:03:30,259
you see after how it worked

00:03:28,519 --> 00:03:33,409
few months after I started to measure

00:03:30,259 --> 00:03:35,419
everything technical it's the background

00:03:33,409 --> 00:03:40,250
to be able to measure business things

00:03:35,419 --> 00:03:42,769
after in July also known as last week

00:03:40,250 --> 00:03:46,459
literally we launched the private beta

00:03:42,769 --> 00:03:51,620
and started to win on board all the old

00:03:46,459 --> 00:03:54,469
users there was yeah so things did not

00:03:51,620 --> 00:03:56,599
go exactly as expected but I'm pretty

00:03:54,469 --> 00:03:57,199
happy it was a nice problem to have too

00:03:56,599 --> 00:03:59,239
much traffic

00:03:57,199 --> 00:04:02,169
actually when I measure the thing I

00:03:59,239 --> 00:04:05,359
could say it was around 1 million a

00:04:02,169 --> 00:04:07,159
images self debate by day which is not a

00:04:05,359 --> 00:04:10,479
lot if you're Google but which is a lot

00:04:07,159 --> 00:04:14,949
if you just have a few servers somewhere

00:04:10,479 --> 00:04:14,949
yeah so nice program twelve

00:04:19,979 --> 00:04:26,169
so just so you understand how which

00:04:25,780 --> 00:04:29,740
works

00:04:26,169 --> 00:04:33,039
that's basically the world service that

00:04:29,740 --> 00:04:36,190
is the world user-facing service

00:04:33,039 --> 00:04:38,110
it's very standard on the website it's

00:04:36,190 --> 00:04:40,240
there is a load balancer that sounds

00:04:38,110 --> 00:04:42,550
traffic both to a django website which

00:04:40,240 --> 00:04:45,310
is the marketing website and the user

00:04:42,550 --> 00:04:48,430
accounts manage the api key is the

00:04:45,310 --> 00:04:50,139
billing or stuff like this and sons are

00:04:48,430 --> 00:04:52,240
sort of traffic to the api server if

00:04:50,139 --> 00:04:54,580
it's an API query which is which I'm

00:04:52,240 --> 00:04:56,800
using tornado not really mother I'm not

00:04:54,580 --> 00:05:00,760
really sexy but it's really fast and it

00:04:56,800 --> 00:05:02,710
really works well for us this API server

00:05:00,760 --> 00:05:05,949
basically just have to serve images as

00:05:02,710 --> 00:05:09,400
fast assists as it can whenever an image

00:05:05,949 --> 00:05:12,190
is not here which happens quite often it

00:05:09,400 --> 00:05:15,699
sends a miss event to a message queue a

00:05:12,190 --> 00:05:17,380
rabbitmq message queue another service

00:05:15,699 --> 00:05:19,690
called jenny top picks it up decide

00:05:17,380 --> 00:05:21,699
update the status first decide whether

00:05:19,690 --> 00:05:25,660
or not this request is legit as this

00:05:21,699 --> 00:05:28,240
domain not fluid is this is this some

00:05:25,660 --> 00:05:30,460
kind of abuse etc and if it decided

00:05:28,240 --> 00:05:32,949
legit it sends a message to another

00:05:30,460 --> 00:05:36,010
message queue a spider picks it up open

00:05:32,949 --> 00:05:39,699
the image save make of screenshots

00:05:36,010 --> 00:05:42,370
resize its compress it blah blah uploads

00:05:39,699 --> 00:05:44,530
it and at the end it sends either

00:05:42,370 --> 00:05:47,349
created or failed message to do events

00:05:44,530 --> 00:05:49,539
message queue which will be which will

00:05:47,349 --> 00:05:51,699
be picked up by the janitor once again

00:05:49,539 --> 00:05:53,590
and denita will update in readies so the

00:05:51,699 --> 00:05:56,849
API server can serve the request next

00:05:53,590 --> 00:06:03,220
time an user asks for it basically that

00:05:56,849 --> 00:06:05,500
all the service is what I said but to

00:06:03,220 --> 00:06:08,169
manage that we also have a lot of data

00:06:05,500 --> 00:06:10,690
producing services in the backend I

00:06:08,169 --> 00:06:12,520
won't detail all of those services but

00:06:10,690 --> 00:06:14,889
mostly we have primitives which is a

00:06:12,520 --> 00:06:17,199
timestamp oriented database that course

00:06:14,889 --> 00:06:22,030
matrix from services and stores them

00:06:17,199 --> 00:06:24,699
into a bundled timestamp database TSG be

00:06:22,030 --> 00:06:28,960
and also provide a query language that

00:06:24,699 --> 00:06:30,110
amongst other graph anna can ask can

00:06:28,960 --> 00:06:34,310
query and get

00:06:30,110 --> 00:06:37,010
which from to build up from that and as

00:06:34,310 --> 00:06:40,280
it's a REST API like HTTP API you can

00:06:37,010 --> 00:06:43,460
also just grab it yourself and will use

00:06:40,280 --> 00:06:46,400
it to get some data and very important

00:06:43,460 --> 00:06:48,410
to we have external services which is

00:06:46,400 --> 00:06:51,380
pretty much services you know Google

00:06:48,410 --> 00:06:53,000
Analytics stripe mail gun etc and that's

00:06:51,380 --> 00:06:55,490
interesting because there is a lot of

00:06:53,000 --> 00:06:58,220
data produced here too and mostly the

00:06:55,490 --> 00:07:01,430
most interesting insight we can get even

00:06:58,220 --> 00:07:04,190
if it's not not any anyone and big data

00:07:01,430 --> 00:07:06,440
if it's small data but the biggest

00:07:04,190 --> 00:07:09,170
insight we can get is when we curse the

00:07:06,440 --> 00:07:14,200
data from internal things with external

00:07:09,170 --> 00:07:16,490
things so at this point I already have

00:07:14,200 --> 00:07:18,350
dashboards of technical metrics and I

00:07:16,490 --> 00:07:20,900
insist on this technical world because

00:07:18,350 --> 00:07:22,670
it's not what we want to do after but we

00:07:20,900 --> 00:07:24,680
already have those dashboards made in

00:07:22,670 --> 00:07:26,870
graph a now it's really easy to build

00:07:24,680 --> 00:07:29,630
you just write a query and you have the

00:07:26,870 --> 00:07:32,810
graph it's very quick to do we have this

00:07:29,630 --> 00:07:35,540
CPU memory network like standard

00:07:32,810 --> 00:07:37,630
monitoring thing and we also have also

00:07:35,540 --> 00:07:40,550
standard monitoring thing but more

00:07:37,630 --> 00:07:43,060
related to one service like Ingenix is

00:07:40,550 --> 00:07:47,120
returning

00:07:43,060 --> 00:07:48,830
well the amount of 200 300 forward 500

00:07:47,120 --> 00:07:50,870
we have per second written by M Chinese

00:07:48,830 --> 00:07:54,710
the timing of request so we can know

00:07:50,870 --> 00:07:57,170
what or not things are going nicely and

00:07:54,710 --> 00:07:59,150
I insist once again on the fact it's

00:07:57,170 --> 00:08:01,010
technical metrics because there's a lot

00:07:59,150 --> 00:08:03,470
of data every 15 seconds primitive

00:08:01,010 --> 00:08:06,290
scores everything and and and saws new

00:08:03,470 --> 00:08:07,970
data but we don't want to store forever

00:08:06,290 --> 00:08:10,190
this data because we can't make

00:08:07,970 --> 00:08:12,560
decisions based on that it's just data

00:08:10,190 --> 00:08:16,790
that helps us restore the service

00:08:12,560 --> 00:08:18,500
whenever an incident arise or just react

00:08:16,790 --> 00:08:20,570
to what's happening it's it's good to

00:08:18,500 --> 00:08:24,560
know what's currently happening in the

00:08:20,570 --> 00:08:27,790
service but it's good to know we have

00:08:24,560 --> 00:08:27,790
that before we

00:08:32,510 --> 00:08:37,180
also planning for many what're you

00:08:34,580 --> 00:08:41,780
drinking a conference is very important

00:08:37,180 --> 00:08:43,789
so the plan is basically person based on

00:08:41,780 --> 00:08:45,110
that if you can't measure something it's

00:08:43,789 --> 00:08:48,860
really hard to improve it you're just

00:08:45,110 --> 00:08:51,260
blind blindly running in anything as

00:08:48,860 --> 00:08:53,720
it's very negative I like better the

00:08:51,260 --> 00:08:57,680
other version which says what gets

00:08:53,720 --> 00:08:59,570
measures get improved it's not as easy

00:08:57,680 --> 00:09:01,760
as that because there is metrics that

00:08:59,570 --> 00:09:04,820
you can look at after as much as you

00:09:01,760 --> 00:09:07,880
want and it's just a consequence and

00:09:04,820 --> 00:09:10,460
effects so you can try to improve it but

00:09:07,880 --> 00:09:12,040
if you don't fix the cause it won't but

00:09:10,460 --> 00:09:14,930
if you choose your metrics wisely

00:09:12,040 --> 00:09:17,000
choosing cause metrics really having

00:09:14,930 --> 00:09:18,380
your focus on yeah that's that's all

00:09:17,000 --> 00:09:20,990
goal that's what team go oh that's what

00:09:18,380 --> 00:09:23,030
my goal will really help you improve

00:09:20,990 --> 00:09:25,670
that and of course there's not one

00:09:23,030 --> 00:09:27,650
answer to this question do answer which

00:09:25,670 --> 00:09:29,660
is not an answer is that you should not

00:09:27,650 --> 00:09:31,730
focus on vanity metrics for example so

00:09:29,660 --> 00:09:33,470
now I said there is 1 million requests

00:09:31,730 --> 00:09:36,800
on the API per day that's a perfect

00:09:33,470 --> 00:09:38,540
example of example of vanity metric it's

00:09:36,800 --> 00:09:41,260
good to say yeah we have some traffic

00:09:38,540 --> 00:09:44,780
it's good to say to you user we're not

00:09:41,260 --> 00:09:46,400
we're not a tiny service but if you

00:09:44,780 --> 00:09:48,380
focus on that it will just waste your

00:09:46,400 --> 00:09:51,710
time because I could serve 1 billion

00:09:48,380 --> 00:09:53,600
requests it will be just costs if none

00:09:51,710 --> 00:09:57,520
of those requests are actually built it

00:09:53,600 --> 00:09:57,520
it doesn't mean anything

00:09:58,660 --> 00:10:06,530
so to plan the metrics we want to to to

00:10:03,140 --> 00:10:09,080
measure it's important to consider the

00:10:06,530 --> 00:10:11,030
business you are in like we are in

00:10:09,080 --> 00:10:13,190
software as a service but there is

00:10:11,030 --> 00:10:14,750
different metrics for different kind of

00:10:13,190 --> 00:10:17,810
business I will give you some pointers

00:10:14,750 --> 00:10:20,750
to to find the state the state of the

00:10:17,810 --> 00:10:24,050
art and industry in in this regard after

00:10:20,750 --> 00:10:26,210
that it's important to not look at the

00:10:24,050 --> 00:10:29,150
same thing if you're like early stage

00:10:26,210 --> 00:10:31,490
business preview pre market free product

00:10:29,150 --> 00:10:33,200
market fit or if you know less search

00:10:31,490 --> 00:10:35,780
business you won't look at the same kind

00:10:33,200 --> 00:10:38,209
of thing hopefully a lot of people are

00:10:35,780 --> 00:10:39,980
really smart people built frameworks for

00:10:38,209 --> 00:10:42,050
that and that's I'm speaking about

00:10:39,980 --> 00:10:43,939
business frameworks and not technical

00:10:42,050 --> 00:10:48,319
frameworks but one you may have

00:10:43,939 --> 00:10:50,629
about is the well-known a framework also

00:10:48,319 --> 00:10:53,569
called I don't know if I say that

00:10:50,629 --> 00:10:57,139
correctly also called the pirate matrix

00:10:53,569 --> 00:10:59,539
framework which says okay users are

00:10:57,139 --> 00:11:02,689
complicated and we will segment the the

00:10:59,539 --> 00:11:07,939
user the user journey within a service

00:11:02,689 --> 00:11:11,859
into five kind of steps mapped when we

00:11:07,939 --> 00:11:14,449
attract new users when we get them to

00:11:11,859 --> 00:11:16,789
give give us a little something like

00:11:14,449 --> 00:11:19,039
when we activate them for example it

00:11:16,789 --> 00:11:20,689
could be they leave the email that could

00:11:19,039 --> 00:11:22,249
be the create an account them but that

00:11:20,689 --> 00:11:24,559
could also be they give you a phone call

00:11:22,249 --> 00:11:27,649
or maybe they download your application

00:11:24,559 --> 00:11:29,659
if you're on a mobile app then you have

00:11:27,649 --> 00:11:31,189
the retention phase where you say okay

00:11:29,659 --> 00:11:34,309
that's good you do I know who you are

00:11:31,189 --> 00:11:36,079
but now I need to have you really come

00:11:34,309 --> 00:11:40,449
and come again need me every day or

00:11:36,079 --> 00:11:43,220
every period of time you you defined I

00:11:40,449 --> 00:11:45,049
reverse the the to an ting I didn't do

00:11:43,220 --> 00:11:47,149
it on the slide but the then you have

00:11:45,049 --> 00:11:51,109
the revenue how do you get money from

00:11:47,149 --> 00:11:54,559
the from this user and that's not

00:11:51,109 --> 00:11:57,619
necessarily a paste directly it can it

00:11:54,559 --> 00:11:59,539
can generate money and directly also and

00:11:57,619 --> 00:12:03,169
you have the referral phase that I put

00:11:59,539 --> 00:12:05,299
really at the end because in fact for

00:12:03,169 --> 00:12:08,299
user to recommend your service it must

00:12:05,299 --> 00:12:11,509
be like deeply in love with your service

00:12:08,299 --> 00:12:14,209
and it must love your service so much

00:12:11,509 --> 00:12:16,869
that is willing to actually risk

00:12:14,209 --> 00:12:19,279
something of his social existence to

00:12:16,869 --> 00:12:21,079
recommend to his friend so for example

00:12:19,279 --> 00:12:23,899
to explain that

00:12:21,079 --> 00:12:26,229
people recommend slack because they

00:12:23,899 --> 00:12:30,619
think slack makes them like look cool

00:12:26,229 --> 00:12:33,739
but if you app a site or some strange

00:12:30,619 --> 00:12:35,839
service somewhere people don't think for

00:12:33,739 --> 00:12:38,059
now that you're cool so you can try to

00:12:35,839 --> 00:12:41,089
make referrals but that won't happen at

00:12:38,059 --> 00:12:43,939
this stage another way to present the

00:12:41,089 --> 00:12:49,549
same thing is the a Schmoyer version you

00:12:43,939 --> 00:12:52,369
will you will have all that after if you

00:12:49,549 --> 00:12:55,399
want if this is not enough there is

00:12:52,369 --> 00:12:57,200
people like Alastair Kroll and Benjamin

00:12:55,399 --> 00:12:59,900
news covets that works

00:12:57,200 --> 00:13:01,610
the Brooklyn analytics on much more

00:12:59,900 --> 00:13:03,920
detailed version of the same thing

00:13:01,610 --> 00:13:08,600
actually it's the same thing you can

00:13:03,920 --> 00:13:11,690
look for the difference AAA or faith on

00:13:08,600 --> 00:13:13,820
this but there are a whole year but then

00:13:11,690 --> 00:13:17,660
it's much more finely grained and you

00:13:13,820 --> 00:13:19,850
can find it's fine-tuning it's it's

00:13:17,660 --> 00:13:23,780
optimization it's so as its

00:13:19,850 --> 00:13:26,150
optimizations for later for today the

00:13:23,780 --> 00:13:28,220
plan is to focus on the activation phase

00:13:26,150 --> 00:13:32,810
like let's say acquisition to activation

00:13:28,220 --> 00:13:36,740
phase and we'll just use our that's

00:13:32,810 --> 00:13:39,740
enough so to summarize what business

00:13:36,740 --> 00:13:42,770
software service its stage like the

00:13:39,740 --> 00:13:45,680
defining inland analytics which is very

00:13:42,770 --> 00:13:49,070
early stage we need to know if the if

00:13:45,680 --> 00:13:51,200
the the people of because we have users

00:13:49,070 --> 00:13:53,630
but we need to convert them to member so

00:13:51,200 --> 00:13:57,140
do we have enough do we trigger enough

00:13:53,630 --> 00:14:01,210
emotion to make them want to become

00:13:57,140 --> 00:14:05,720
members and do we trigger enough

00:14:01,210 --> 00:14:07,430
Ninian's was that actually they stick to

00:14:05,720 --> 00:14:11,300
the service and come back and use it and

00:14:07,430 --> 00:14:13,940
use the apk so for now because I don't

00:14:11,300 --> 00:14:16,100
have a lot of time we will focus on

00:14:13,940 --> 00:14:19,280
weight from acquisition to activation

00:14:16,100 --> 00:14:21,650
and quality of service both because we

00:14:19,280 --> 00:14:25,160
want to measure it to improve it and

00:14:21,650 --> 00:14:26,950
both because it's the main testimonial

00:14:25,160 --> 00:14:29,660
we can of if we are transparent not

00:14:26,950 --> 00:14:32,210
quality of service to users they may

00:14:29,660 --> 00:14:34,750
think we are truly serious on how we

00:14:32,210 --> 00:14:34,750
doing it

00:14:40,000 --> 00:14:46,870
so first of the first of the three

00:14:44,139 --> 00:14:49,839
technical steps is actually using bonobo

00:14:46,870 --> 00:14:54,149
to implement some data pipelines to

00:14:49,839 --> 00:14:57,399
integrate data in some metric database

00:14:54,149 --> 00:14:59,620
very simple we get some data we

00:14:57,399 --> 00:15:02,319
aggregate it eventually normalize it and

00:14:59,620 --> 00:15:05,769
we put that in metric metric value

00:15:02,319 --> 00:15:08,019
database most probably time stamps so I

00:15:05,769 --> 00:15:10,329
thought about the most simple model I

00:15:08,019 --> 00:15:14,680
could find about that and actually it

00:15:10,329 --> 00:15:19,870
looks like this it's matrix hourly

00:15:14,680 --> 00:15:23,079
values daily values that's very quick to

00:15:19,870 --> 00:15:25,839
write probably not the best but it works

00:15:23,079 --> 00:15:29,439
for this stage and it's important to

00:15:25,839 --> 00:15:32,170
note that the technical metrics yield a

00:15:29,439 --> 00:15:35,079
lot of data those metrics will yield not

00:15:32,170 --> 00:15:37,779
a lot if we have one data point per

00:15:35,079 --> 00:15:41,680
metric per hour it's 24 data points per

00:15:37,779 --> 00:15:44,050
day it's really not a lot so that will

00:15:41,680 --> 00:15:45,910
be enough if you need to build a much

00:15:44,050 --> 00:15:47,379
bigger system of course I with Star and

00:15:45,910 --> 00:15:50,459
snowflake schema so you can find a lot

00:15:47,379 --> 00:15:54,370
of literature on the Internet

00:15:50,459 --> 00:15:56,170
and yeah so just a quick introduction

00:15:54,370 --> 00:15:58,420
because I guess you may not know

00:15:56,170 --> 00:16:01,050
burnable as it's really young projects

00:15:58,420 --> 00:16:03,730
to you less than two years old now but

00:16:01,050 --> 00:16:07,170
bonobo is an expections from LOD

00:16:03,730 --> 00:16:10,059
framework the goal of this is you build

00:16:07,170 --> 00:16:12,670
assembly lines of data transformations

00:16:10,059 --> 00:16:14,649
with independent stages and you will

00:16:12,670 --> 00:16:19,000
pass rows of data from one stage to

00:16:14,649 --> 00:16:23,759
another so less metaphorically you will

00:16:19,000 --> 00:16:27,250
use okay fitting you will use different

00:16:23,759 --> 00:16:30,579
calibers and iterators and classes

00:16:27,250 --> 00:16:32,290
instances to get some data and here we

00:16:30,579 --> 00:16:32,829
are selecting some data from the

00:16:32,290 --> 00:16:34,930
database

00:16:32,829 --> 00:16:36,910
we're qualifying it with joining two

00:16:34,930 --> 00:16:40,389
other database and sending emails and

00:16:36,910 --> 00:16:43,059
the point is the send email function

00:16:40,389 --> 00:16:45,819
will run while the Select function is

00:16:43,059 --> 00:16:48,220
still yielding results so the first

00:16:45,819 --> 00:16:52,569
report will be sent and maybe select a

00:16:48,220 --> 00:16:53,800
still 1 million were to select each

00:16:52,569 --> 00:16:55,990
one's in in the

00:16:53,800 --> 00:17:00,100
and thread that ice pacifists in first

00:16:55,990 --> 00:17:02,800
out it's kind of kind of stupid it's of

00:17:00,100 --> 00:17:04,449
course I have my example was linear but

00:17:02,800 --> 00:17:06,939
it supports any kind of directed acyclic

00:17:04,449 --> 00:17:10,959
graphs and we'll see that after you know

00:17:06,939 --> 00:17:13,360
imports its standard Python so you can

00:17:10,959 --> 00:17:16,150
use it in bonobo or outside born aboard

00:17:13,360 --> 00:17:19,839
the same code that's pretty neat

00:17:16,150 --> 00:17:21,429
getting started is three lines and if I

00:17:19,839 --> 00:17:25,990
add a long sentence you could have done

00:17:21,429 --> 00:17:28,390
it before I finish so let's write two

00:17:25,990 --> 00:17:30,790
jobs once again apologies if the code is

00:17:28,390 --> 00:17:33,340
if I'm going too fast for the code it's

00:17:30,790 --> 00:17:36,070
why I put up an URL I will upload the

00:17:33,340 --> 00:17:39,550
code and notify as soon as it's done at

00:17:36,070 --> 00:17:43,000
the end but first extractor looks like

00:17:39,550 --> 00:17:47,200
this it's an object country though so

00:17:43,000 --> 00:17:50,140
this object can't really build a sequel

00:17:47,200 --> 00:17:53,170
query which is was a simple it counts

00:17:50,140 --> 00:17:56,800
objects in a table and formats that as a

00:17:53,170 --> 00:18:00,070
topper of dictionary of dimensions and

00:17:56,800 --> 00:18:05,620
dictionary of metrics of course the

00:18:00,070 --> 00:18:08,340
queries parametrized so the person zero

00:18:05,620 --> 00:18:11,470
needs to be filled and for that we'll

00:18:08,340 --> 00:18:14,559
simply use a dictionary that is a

00:18:11,470 --> 00:18:19,179
dictionary of table two metric name and

00:18:14,559 --> 00:18:23,620
we'll create an iterator using the items

00:18:19,179 --> 00:18:25,660
the items built-in that will pass data

00:18:23,620 --> 00:18:28,330
first-in-first-out to object count

00:18:25,660 --> 00:18:30,730
reader that will then send the request

00:18:28,330 --> 00:18:33,700
to the database and etc we'll see more

00:18:30,730 --> 00:18:36,820
when we aggregate all the thing the

00:18:33,700 --> 00:18:39,100
normalize is not a real normalization on

00:18:36,820 --> 00:18:41,020
it there is no validation here but it

00:18:39,100 --> 00:18:43,630
will do the job for the proof concepts

00:18:41,020 --> 00:18:46,809
we will just say okay whatever comes

00:18:43,630 --> 00:18:48,429
here is I I need to field and first one

00:18:46,809 --> 00:18:51,340
is called dims to confirm is called

00:18:48,429 --> 00:18:53,559
metrics we don't validate anything but

00:18:51,340 --> 00:18:57,130
it's really easy then to replace this

00:18:53,559 --> 00:18:59,080
simple stupid thing with will schema

00:18:57,130 --> 00:19:02,220
validation of whatever is inside if you

00:18:59,080 --> 00:19:02,220
need to be more solid

00:19:02,350 --> 00:19:09,250
we need something that writes to the

00:19:04,539 --> 00:19:11,649
matrix database so I wrote one that can

00:19:09,250 --> 00:19:17,259
write both to the holy values and and

00:19:11,649 --> 00:19:19,889
and and daily values tables it filters

00:19:17,259 --> 00:19:22,659
out the rows it doesn't need and then

00:19:19,889 --> 00:19:25,779
it's not really important to get the

00:19:22,659 --> 00:19:28,389
details of that but simply it will be

00:19:25,779 --> 00:19:30,549
called on each may each dimension metric

00:19:28,389 --> 00:19:32,950
topper and it will put it in the into

00:19:30,549 --> 00:19:34,480
the database and of course we need to

00:19:32,950 --> 00:19:35,559
compose all that which is probably the

00:19:34,480 --> 00:19:38,320
most important part

00:19:35,559 --> 00:19:41,110
so we instantiate or normalize thing at

00:19:38,320 --> 00:19:43,059
the top we create a graph instance that

00:19:41,110 --> 00:19:43,899
get the readers we had before so the

00:19:43,059 --> 00:19:46,960
dictums

00:19:43,899 --> 00:19:49,629
and object on Twitter then we normalize

00:19:46,960 --> 00:19:52,779
it just the instance above and we had

00:19:49,629 --> 00:19:56,889
two chains with two instance of analysis

00:19:52,779 --> 00:20:00,009
writer which will filter out non hourly

00:19:56,889 --> 00:20:02,110
metrics and instead our metrics in

00:20:00,009 --> 00:20:05,169
database and user 1 with Fatah filter

00:20:02,110 --> 00:20:07,960
out our metrics and insert daily metrics

00:20:05,169 --> 00:20:11,080
into the database because it's better

00:20:07,960 --> 00:20:16,120
when we visualize each I skip as a slide

00:20:11,080 --> 00:20:17,830
that will do that so it will be pass

00:20:16,120 --> 00:20:21,370
first in first on between all and after

00:20:17,830 --> 00:20:23,379
the state field the data will be passed

00:20:21,370 --> 00:20:25,690
both were data analytics greater and

00:20:23,379 --> 00:20:28,360
both and to earlier on each writer and

00:20:25,690 --> 00:20:32,289
it's their war to filter out the the

00:20:28,360 --> 00:20:34,120
words it doesn't want just before we

00:20:32,289 --> 00:20:37,080
passed the database connection

00:20:34,120 --> 00:20:42,639
implementation so it's sequel alchemy

00:20:37,080 --> 00:20:46,210
databases in engine sorry but yeah not

00:20:42,639 --> 00:20:49,179
of course you need to connect you can

00:20:46,210 --> 00:20:51,870
run it you will have linear status but

00:20:49,179 --> 00:20:54,820
it's not you know okay we got it

00:20:51,870 --> 00:20:58,149
let's add a lot of readers again I'm

00:20:54,820 --> 00:21:00,610
running quick but you you you yet have

00:20:58,149 --> 00:21:02,529
that we connect to Google Analytics so

00:21:00,610 --> 00:21:05,009
we provide a service we call Google

00:21:02,529 --> 00:21:09,669
Analytics so of course we will provide

00:21:05,009 --> 00:21:12,789
client implementation in the services

00:21:09,669 --> 00:21:14,870
dictionary but here same ID we send a

00:21:12,789 --> 00:21:16,730
query to an API and

00:21:14,870 --> 00:21:20,030
we yield a tuple of two dictionaries

00:21:16,730 --> 00:21:22,370
dimensions matrix we can call Prometheus

00:21:20,030 --> 00:21:24,380
you do not have to know what's the API

00:21:22,370 --> 00:21:27,050
of primitives but you have a query range

00:21:24,380 --> 00:21:30,950
and point we query the thing we ask for

00:21:27,050 --> 00:21:33,080
some matrix and the one we need we often

00:21:30,950 --> 00:21:35,930
it's an egg it's an aggregate query so

00:21:33,080 --> 00:21:39,320
we just take holy averages or things

00:21:35,930 --> 00:21:42,020
like this and again wield two

00:21:39,320 --> 00:21:44,660
dictionaries dimensions matrix we have

00:21:42,020 --> 00:21:46,940
spiders count so we have a lot of

00:21:44,660 --> 00:21:49,100
spiders burning some inactives on

00:21:46,940 --> 00:21:52,429
achieve so we get all this thing and

00:21:49,100 --> 00:21:55,100
we'll use a concept similar to func

00:21:52,429 --> 00:21:57,350
tools that reduce in Python but adapted

00:21:55,100 --> 00:22:00,040
to the stream processing thing and

00:21:57,350 --> 00:22:03,230
release so we'll use a reducer that will

00:22:00,040 --> 00:22:07,190
take elements two by two and just make

00:22:03,230 --> 00:22:10,220
one so we take the spider statuses and

00:22:07,190 --> 00:22:13,280
we make dictionary of counts of active

00:22:10,220 --> 00:22:16,100
and inactive spiders which look like

00:22:13,280 --> 00:22:18,260
this so the you need to initialize to

00:22:16,100 --> 00:22:20,809
give an initializer to the to the

00:22:18,260 --> 00:22:23,510
register thing and a function to reduce

00:22:20,809 --> 00:22:27,470
so everything that goes out of spiders

00:22:23,510 --> 00:22:29,720
Widow the status of spiders goes into

00:22:27,470 --> 00:22:31,550
this reducer two by two and as soon as

00:22:29,720 --> 00:22:33,350
its variable its psyllid and we use a

00:22:31,550 --> 00:22:35,870
lambda here to just format to the

00:22:33,350 --> 00:22:39,320
dictionary of dimension dictionary of

00:22:35,870 --> 00:22:42,170
metrics I hope I didn't lose you

00:22:39,320 --> 00:22:45,260
completely that's my biggest fear here

00:22:42,170 --> 00:22:49,100
but the results graphically looks like

00:22:45,260 --> 00:22:51,080
this if we put all the readers at the

00:22:49,100 --> 00:22:54,020
same time in the same graph and this

00:22:51,080 --> 00:22:55,610
graph can be executed you don't have to

00:22:54,020 --> 00:22:57,559
execute everything at the same time but

00:22:55,610 --> 00:23:02,030
this graph can be executed and we have

00:22:57,559 --> 00:23:04,100
some kind of bigger status if someone

00:23:02,030 --> 00:23:07,010
knows how to write ask your trees in

00:23:04,100 --> 00:23:11,600
console I really love to discuss the

00:23:07,010 --> 00:23:13,640
algorithm because for now I can't again

00:23:11,600 --> 00:23:17,000
I'm by side but it's really easy to

00:23:13,640 --> 00:23:19,340
replace parts and that's that's that's

00:23:17,000 --> 00:23:21,500
really what what I like most is that for

00:23:19,340 --> 00:23:24,020
example the normalizer I still this set

00:23:21,500 --> 00:23:26,510
field thing tomorrow I will use maybe

00:23:24,020 --> 00:23:28,610
something like Cerberus or any schema

00:23:26,510 --> 00:23:31,670
validation library to

00:23:28,610 --> 00:23:39,710
that's my my data is at in the right

00:23:31,670 --> 00:23:42,200
format enough talking about bonobo we

00:23:39,710 --> 00:23:43,850
need to visualize things and we already

00:23:42,200 --> 00:23:46,549
have a graph and I instance installed so

00:23:43,850 --> 00:23:48,110
it will be quite easy to just take some

00:23:46,549 --> 00:23:50,290
of those metrics and make graphs with

00:23:48,110 --> 00:23:50,290
that

00:23:51,309 --> 00:23:55,240
so I guess who doesn't know graphing our

00:23:54,440 --> 00:24:00,650
tour

00:23:55,240 --> 00:24:04,520
ok so graphing is quite all software I

00:24:00,650 --> 00:24:07,220
think it was a fork of another suit like

00:24:04,520 --> 00:24:09,470
this before and the goal is to connect

00:24:07,220 --> 00:24:12,110
data sources and to graphically

00:24:09,470 --> 00:24:14,960
configure graphs by making queries so

00:24:12,110 --> 00:24:17,660
the interface to configure graph looks

00:24:14,960 --> 00:24:19,730
like this you just have a query editor

00:24:17,660 --> 00:24:22,640
you put the query and you get the graph

00:24:19,730 --> 00:24:24,049
that's pretty much as simple as that of

00:24:22,640 --> 00:24:28,220
course if you don't have data you can't

00:24:24,049 --> 00:24:30,200
visualize anything but all all the

00:24:28,220 --> 00:24:33,200
configuration is done in the web

00:24:30,200 --> 00:24:37,630
interface and so for example this graph

00:24:33,200 --> 00:24:41,270
is one of those we use for the QoS thing

00:24:37,630 --> 00:24:44,240
which shows how many events we got every

00:24:41,270 --> 00:24:46,070
hour about how many Me's we give we got

00:24:44,240 --> 00:24:48,080
how many created event we got or many

00:24:46,070 --> 00:24:51,110
failed event we got so we can compute

00:24:48,080 --> 00:24:55,549
the ratio between created failed

00:24:51,110 --> 00:24:58,460
for example etc we have also the one

00:24:55,549 --> 00:25:01,460
that passed through the reducer thing is

00:24:58,460 --> 00:25:03,710
the number of spiders so when we launch

00:25:01,460 --> 00:25:06,620
more we see the number of inactive

00:25:03,710 --> 00:25:08,630
spiders active spiders we can walk we

00:25:06,620 --> 00:25:11,480
could walk on better display here

00:25:08,630 --> 00:25:16,250
because it's what means inactive maybe

00:25:11,480 --> 00:25:18,040
it's just resting so anyway but much

00:25:16,250 --> 00:25:21,110
more readable for users we have this

00:25:18,040 --> 00:25:25,640
graph of how many time does it take to

00:25:21,110 --> 00:25:28,270
get a new picture and at the time I took

00:25:25,640 --> 00:25:30,700
this graph on average it was 16 second

00:25:28,270 --> 00:25:33,620
if probably you don't have all these

00:25:30,700 --> 00:25:36,890
advertising things JavaScript thing that

00:25:33,620 --> 00:25:38,929
make the Browse a lot very long maybe

00:25:36,890 --> 00:25:39,140
you were in the nine seconds range which

00:25:38,929 --> 00:25:43,000
is

00:25:39,140 --> 00:25:46,190
minimum we get here not you

00:25:43,000 --> 00:25:47,930
so we use that also to the same kind of

00:25:46,190 --> 00:25:50,270
system to build of public dashboards

00:25:47,930 --> 00:25:53,780
here the front-end is something based on

00:25:50,270 --> 00:25:56,300
this III and that's just the parentage

00:25:53,780 --> 00:26:00,140
is not very important but that's how we

00:25:56,300 --> 00:26:02,240
show to users actual status but

00:26:00,140 --> 00:26:04,190
interesting also is that as you can

00:26:02,240 --> 00:26:11,000
write sequel queries directly in graph a

00:26:04,190 --> 00:26:12,890
now you can sorry you can actually make

00:26:11,000 --> 00:26:15,620
computation directly using your database

00:26:12,890 --> 00:26:17,930
and joins engine so here we had user

00:26:15,620 --> 00:26:19,850
accounts we had musicians from analytics

00:26:17,930 --> 00:26:23,210
so use accounts coming from the count of

00:26:19,850 --> 00:26:25,490
objects that we computed every however

00:26:23,210 --> 00:26:29,330
before musician that coming from Google

00:26:25,490 --> 00:26:32,510
Analytics API API calls and you can just

00:26:29,330 --> 00:26:34,640
divide one by the other like subtract

00:26:32,510 --> 00:26:38,140
the maximum on a day with the minimum

00:26:34,640 --> 00:26:40,610
energy of number of users then make

00:26:38,140 --> 00:26:44,320
simple division and get the conversion

00:26:40,610 --> 00:26:47,180
rate between acquisition and activation

00:26:44,320 --> 00:26:49,340
here it's a bit strange because the we

00:26:47,180 --> 00:26:51,880
have a that's actually will data and we

00:26:49,340 --> 00:26:55,250
have like a twenty five percent

00:26:51,880 --> 00:26:57,410
conversion rate at the beginning so you

00:26:55,250 --> 00:27:00,260
have to cross also with Evans because

00:26:57,410 --> 00:27:02,930
it's the deal when we mailed every

00:27:00,260 --> 00:27:05,480
people that said a I want an account we

00:27:02,930 --> 00:27:08,180
sent the the mails this day so of course

00:27:05,480 --> 00:27:11,750
the this kind of acquisition where it is

00:27:08,180 --> 00:27:13,910
not possible normally unless all your

00:27:11,750 --> 00:27:18,170
traffic actually already said they

00:27:13,910 --> 00:27:21,710
wanted an account that's very highly as

00:27:18,170 --> 00:27:24,590
you seen in the in the timeline

00:27:21,710 --> 00:27:27,590
injection at the beginning that's a fair

00:27:24,590 --> 00:27:31,630
of the last month and last weeks of work

00:27:27,590 --> 00:27:34,340
but yeah that's that's a basis for for

00:27:31,630 --> 00:27:36,110
seeing a lot more thing and we really

00:27:34,340 --> 00:27:39,170
want to base our decisions and data so

00:27:36,110 --> 00:27:41,440
that's the the basis to make the service

00:27:39,170 --> 00:27:41,440
evolve

00:27:47,730 --> 00:27:54,190
so until then that's pretty good it went

00:27:52,629 --> 00:27:58,690
on my computer it wins and the

00:27:54,190 --> 00:28:04,149
prediction servers but this iteration

00:27:58,690 --> 00:28:06,009
zero let's say is yeah if it needed to

00:28:04,149 --> 00:28:09,100
work real quick so a cron job was

00:28:06,009 --> 00:28:11,200
winning everything every 30 minutes when

00:28:09,100 --> 00:28:12,730
something fails actually we could know

00:28:11,200 --> 00:28:16,929
if something fails because it was

00:28:12,730 --> 00:28:19,450
kubernetes cron jobs but it's you need

00:28:16,929 --> 00:28:20,919
to using to have a look maybe if you

00:28:19,450 --> 00:28:23,769
have a lot of job that phase you don't

00:28:20,919 --> 00:28:26,080
know which one failed some expensive

00:28:23,769 --> 00:28:28,480
tasks we're running every 30 minutes it

00:28:26,080 --> 00:28:30,190
was hard to run manually so because you

00:28:28,480 --> 00:28:32,019
have to export the cron job into a job

00:28:30,190 --> 00:28:34,539
we scheduled that into the into the

00:28:32,019 --> 00:28:37,389
scheduler and then eventually delete the

00:28:34,539 --> 00:28:40,740
job afterwards so a lot of things and we

00:28:37,389 --> 00:28:44,980
wanted to do to do better on this side

00:28:40,740 --> 00:28:50,620
so my cat's gently purposed to handle

00:28:44,980 --> 00:28:55,750
that I declined the proposal we

00:28:50,620 --> 00:28:57,610
installed a flow to manage that so as

00:28:55,750 --> 00:28:59,379
you may know a flow is a platform to

00:28:57,610 --> 00:29:01,240
programmatically auto schedule and

00:28:59,379 --> 00:29:06,250
monitor workflows that the official Docs

00:29:01,240 --> 00:29:08,320
and I think it's a pretty precise and we

00:29:06,250 --> 00:29:12,850
mostly use it to schedule and monitor

00:29:08,320 --> 00:29:18,340
here once again who doesn't know a flow

00:29:12,850 --> 00:29:21,460
at all okay so it's a project that was

00:29:18,340 --> 00:29:23,649
created a few years ago by a B&B it's

00:29:21,460 --> 00:29:25,600
now on a project under the Apache

00:29:23,649 --> 00:29:28,600
incubation program so that's a really

00:29:25,600 --> 00:29:30,960
great use for the future of this and the

00:29:28,600 --> 00:29:34,600
role is to schedule and monitor jobs

00:29:30,960 --> 00:29:36,399
either with like if I run it on my

00:29:34,600 --> 00:29:38,350
computer to just schedule jobs on my

00:29:36,399 --> 00:29:41,169
computer directly or if you're running

00:29:38,350 --> 00:29:43,480
on a cluster for example kubernetes but

00:29:41,169 --> 00:29:45,580
also kind of cluster can walk to you can

00:29:43,480 --> 00:29:48,129
distribute workloads using salary tasks

00:29:45,580 --> 00:29:50,909
or even they are working on a cube

00:29:48,129 --> 00:29:54,460
Anytus executors of soon it could even

00:29:50,909 --> 00:29:56,200
submit cuban itís workloads directly and

00:29:54,460 --> 00:29:57,580
it can run pretty much anything your

00:29:56,200 --> 00:30:01,810
computer can run

00:29:57,580 --> 00:30:04,480
peyten being special case of anything a

00:30:01,810 --> 00:30:05,800
computer can run but it can run anything

00:30:04,480 --> 00:30:09,210
and it's written in Python so the

00:30:05,800 --> 00:30:11,650
configuration is actually Python code

00:30:09,210 --> 00:30:13,300
without too much details the

00:30:11,650 --> 00:30:16,360
architecture of air flow which is

00:30:13,300 --> 00:30:17,950
important to well if you want to run a

00:30:16,360 --> 00:30:19,600
flow you need to understand a bit do

00:30:17,950 --> 00:30:22,870
architecture because otherwise it could

00:30:19,600 --> 00:30:25,030
be held to to run but there is a web

00:30:22,870 --> 00:30:28,780
interface which were just after that

00:30:25,030 --> 00:30:30,820
helps you updating the metadata database

00:30:28,780 --> 00:30:33,970
and there is a schedule a service that

00:30:30,820 --> 00:30:37,180
reads the metadata metadata database the

00:30:33,970 --> 00:30:40,120
data is hard to say with that and just

00:30:37,180 --> 00:30:42,790
say oh but hey I have a task to schedule

00:30:40,120 --> 00:30:44,860
so let me find a worker that us ok you

00:30:42,790 --> 00:30:47,530
can run it so it's and the workload to

00:30:44,860 --> 00:30:51,640
worker get the results get do log file

00:30:47,530 --> 00:30:53,890
and update the metadata with that for us

00:30:51,640 --> 00:30:56,950
it looks like this so we all the tasks

00:30:53,890 --> 00:31:01,570
we configured before we defined it as

00:30:56,950 --> 00:31:07,380
tags or directed acyclic graphs which is

00:31:01,570 --> 00:31:14,650
the name of the task in in F row and

00:31:07,380 --> 00:31:18,580
time I shut down ok which is so a task

00:31:14,650 --> 00:31:20,380
in a flow and here we could separate for

00:31:18,580 --> 00:31:23,320
example the cleanup tasks at the very

00:31:20,380 --> 00:31:25,420
top is only one daily because it deletes

00:31:23,320 --> 00:31:27,550
a bunch of course in database no need to

00:31:25,420 --> 00:31:31,000
run it every hour and all the rest is

00:31:27,550 --> 00:31:33,340
one holy which is what is great is that

00:31:31,000 --> 00:31:37,270
you can get the log files of one

00:31:33,340 --> 00:31:39,130
individual task you can get you can get

00:31:37,270 --> 00:31:41,200
all the all the ones you can run one

00:31:39,130 --> 00:31:43,840
manually you can know the timings of

00:31:41,200 --> 00:31:46,600
different individual tasks so as we plan

00:31:43,840 --> 00:31:48,910
to add much more it's great to have and

00:31:46,600 --> 00:31:50,680
we also plan to have dependencies

00:31:48,910 --> 00:31:52,690
between tasks because the main goal of a

00:31:50,680 --> 00:31:55,060
flow is also to say ok I need to run the

00:31:52,690 --> 00:31:57,370
five tasks here and once all the other

00:31:55,060 --> 00:32:00,330
all our own let's run this thing and

00:31:57,370 --> 00:32:04,450
then dance then send the report

00:32:00,330 --> 00:32:07,150
bonobo would do on one data sets first

00:32:04,450 --> 00:32:09,430
in first out at the world level F load

00:32:07,150 --> 00:32:12,790
does that have at the job level and

00:32:09,430 --> 00:32:16,500
that's something you find in I mean

00:32:12,790 --> 00:32:18,760
legacy 8 years like Tallinn and

00:32:16,500 --> 00:32:21,520
plantiveau things like this you you

00:32:18,760 --> 00:32:24,070
often can manage the workflow between

00:32:21,520 --> 00:32:27,310
jobs and between tasks here we use two

00:32:24,070 --> 00:32:30,630
different tools we'll click the

00:32:27,310 --> 00:32:35,110
configuration so you build ghg objects

00:32:30,630 --> 00:32:39,100
here we build simple geg object with

00:32:35,110 --> 00:32:42,580
just one Operator which ones Python code

00:32:39,100 --> 00:32:45,730
in another virtual environment we build

00:32:42,580 --> 00:32:50,170
a lot of dikes using this function

00:32:45,730 --> 00:32:54,790
dynamically so for each metric each data

00:32:50,170 --> 00:32:57,820
source we build one dag and we be at the

00:32:54,790 --> 00:33:01,000
end to clean all which just delete

00:32:57,820 --> 00:33:03,010
things from database one thing F ro

00:33:01,000 --> 00:33:05,670
managed to is connections so here we

00:33:03,010 --> 00:33:09,100
created opposite events and opposite

00:33:05,670 --> 00:33:12,480
website connections in a flow into

00:33:09,100 --> 00:33:15,730
directly in the web interface and we use

00:33:12,480 --> 00:33:19,240
probably suboptimal trick to just use

00:33:15,730 --> 00:33:21,910
those thing passes using the system

00:33:19,240 --> 00:33:24,790
environment and so application that

00:33:21,910 --> 00:33:27,250
already respects pretty much the 12

00:33:24,790 --> 00:33:29,980
factor principle can just use the

00:33:27,250 --> 00:33:33,810
database connection from the environment

00:33:29,980 --> 00:33:33,810
and we can just configure it in a flow

00:33:34,020 --> 00:33:39,610
there was a bit of question we had to

00:33:37,150 --> 00:33:42,940
solve we needed to know where to start

00:33:39,610 --> 00:33:45,880
the GG so we can locally the same as

00:33:42,940 --> 00:33:46,540
production we decided to put it in

00:33:45,880 --> 00:33:48,880
directory

00:33:46,540 --> 00:33:50,590
you know only code base we have one code

00:33:48,880 --> 00:33:52,360
base that works all the different

00:33:50,590 --> 00:33:55,030
services with different entry points and

00:33:52,360 --> 00:34:04,170
that's one mantra point so we built an

00:33:55,030 --> 00:34:07,690
image not imported it was probably a bit

00:34:04,170 --> 00:34:09,790
complex to set up at first probably us

00:34:07,690 --> 00:34:13,179
also because we didn't have a lot of

00:34:09,790 --> 00:34:16,120
experience with that we finally found

00:34:13,179 --> 00:34:17,860
that the home shot in the community are

00:34:16,120 --> 00:34:21,640
not very good so we found a company

00:34:17,860 --> 00:34:22,690
called astronomer that's that I think

00:34:21,640 --> 00:34:26,560
they provide

00:34:22,690 --> 00:34:29,800
a flu as a service and they built really

00:34:26,560 --> 00:34:31,240
good quality images helmet charts so

00:34:29,800 --> 00:34:34,720
hand me the packaging thing for

00:34:31,240 --> 00:34:36,849
Humanity's yeah the last thing also is

00:34:34,720 --> 00:34:40,179
that we had to read a lot of the airflow

00:34:36,849 --> 00:34:41,889
sauce because yeah probably I will try

00:34:40,179 --> 00:34:43,690
to contribute a bit to the documentation

00:34:41,889 --> 00:34:46,480
but there is a lot of thing that lacks

00:34:43,690 --> 00:34:50,649
in the documentation so prepare to wit

00:34:46,480 --> 00:34:53,730
code which is also true with burnable

00:34:50,649 --> 00:34:59,170
and not with grana which is really well

00:34:53,730 --> 00:35:05,410
packaged so from there I have about five

00:34:59,170 --> 00:35:08,020
minutes left from the plan n plus one is

00:35:05,410 --> 00:35:10,180
pretty much the same as plan n except

00:35:08,020 --> 00:35:13,150
that it's really easy to lose a lot of

00:35:10,180 --> 00:35:16,890
time when running this kind of

00:35:13,150 --> 00:35:20,109
experiment so what I suggest is that

00:35:16,890 --> 00:35:23,740
every experiment you do on business data

00:35:20,109 --> 00:35:26,740
is should be time boxed for example as

00:35:23,740 --> 00:35:29,319
you ten books for example sprints in in

00:35:26,740 --> 00:35:31,569
development process you should time box

00:35:29,319 --> 00:35:34,420
experiments and data and decide before

00:35:31,569 --> 00:35:37,390
and what are the results the numeric

00:35:34,420 --> 00:35:40,210
results that you actually define as

00:35:37,390 --> 00:35:43,510
success and define as failure or not

00:35:40,210 --> 00:35:45,339
success and saying yeah I will measure

00:35:43,510 --> 00:35:48,040
that in two weeks is important because

00:35:45,339 --> 00:35:50,710
otherwise you could say oh that that's

00:35:48,040 --> 00:35:53,319
not yet or objective let's wait a bit

00:35:50,710 --> 00:35:56,440
let's wait a bit and probably maybe two

00:35:53,319 --> 00:35:56,859
years after you're still there again ash

00:35:56,440 --> 00:36:01,210
Maurya

00:35:56,859 --> 00:36:03,460
built some simple canvases apparently

00:36:01,210 --> 00:36:05,560
canvases are easy to sell so they but

00:36:03,460 --> 00:36:09,520
that you should use something like this

00:36:05,560 --> 00:36:11,829
to write before on on the paper while

00:36:09,520 --> 00:36:13,930
you're trying an experiment what what it

00:36:11,829 --> 00:36:18,400
possesses you you need to do to prove

00:36:13,930 --> 00:36:22,660
wrong also what get what kind of line in

00:36:18,400 --> 00:36:25,210
the sand you you're putting down and and

00:36:22,660 --> 00:36:27,579
yes so one week to week one months after

00:36:25,210 --> 00:36:29,829
you can just say okay do I did I

00:36:27,579 --> 00:36:35,960
validate something yes no what's the

00:36:29,829 --> 00:36:38,630
next section yeah yeah I would

00:36:35,960 --> 00:36:41,390
gonna beat on the text side yeah we have

00:36:38,630 --> 00:36:42,890
we want to show in graphing a month on

00:36:41,390 --> 00:36:46,220
month data you're on your data very

00:36:42,890 --> 00:36:49,220
important to see that the movements we

00:36:46,220 --> 00:36:56,450
have a lot of ideas we will probably use

00:36:49,220 --> 00:37:08,390
a very complex process yeah just so just

00:36:56,450 --> 00:37:12,589
to finish that the to go back to the

00:37:08,390 --> 00:37:15,530
assembly line analogy F flow is really a

00:37:12,589 --> 00:37:17,630
very good factory manager I mean you you

00:37:15,530 --> 00:37:20,750
you you're building a lot of different

00:37:17,630 --> 00:37:22,580
thing it it doesn't care about the jobs

00:37:20,750 --> 00:37:26,869
contents it can help you building

00:37:22,580 --> 00:37:28,400
dependency between small teams and some

00:37:26,869 --> 00:37:30,920
of you assembly lines could be built

00:37:28,400 --> 00:37:33,349
with buna bone maybe once again make

00:37:30,920 --> 00:37:38,780
your own research and buys it so I don't

00:37:33,349 --> 00:37:41,390
want to advise something I can't do a

00:37:38,780 --> 00:37:44,320
lot of the work here is based on very

00:37:41,390 --> 00:37:46,430
good books so I need to make

00:37:44,320 --> 00:37:49,520
advertisement for things I have no

00:37:46,430 --> 00:37:51,770
interest in like site reliability

00:37:49,520 --> 00:37:55,339
engineer which is the best book ever you

00:37:51,770 --> 00:37:59,119
can read about managing systems in

00:37:55,339 --> 00:38:01,070
production linear ethics when you can

00:37:59,119 --> 00:38:03,890
find all the schemas for different kind

00:38:01,070 --> 00:38:06,880
of businesses like the one I showed at

00:38:03,890 --> 00:38:09,410
the beginning and scaling in which is

00:38:06,880 --> 00:38:11,650
book by a Schmoyer whether to scheme out

00:38:09,410 --> 00:38:14,180
two different canvases or coming from

00:38:11,650 --> 00:38:16,160
but if there is one you should read its

00:38:14,180 --> 00:38:18,320
site very busy engineering and it's free

00:38:16,160 --> 00:38:20,720
you can you can get it from Google

00:38:18,320 --> 00:38:25,130
directly on the web of course if you um

00:38:20,720 --> 00:38:29,270
the paper version in Spain I really like

00:38:25,130 --> 00:38:31,250
feedback so I said before my I was

00:38:29,270 --> 00:38:33,470
frightened to send too much information

00:38:31,250 --> 00:38:36,230
here so I really I'd really like to know

00:38:33,470 --> 00:38:38,660
what you thought about this presentation

00:38:36,230 --> 00:38:42,080
so for that I will provide a link which

00:38:38,660 --> 00:38:44,570
is the same link as where you you'll

00:38:42,080 --> 00:38:46,250
find all the code example as soon as I

00:38:44,570 --> 00:38:47,290
can upload them so probably this

00:38:46,250 --> 00:38:50,590
afternoon Oh

00:38:47,290 --> 00:38:53,830
evening and I will announce on Twitter

00:38:50,590 --> 00:38:55,240
to and this weekend Saturday Sunday I

00:38:53,830 --> 00:38:57,160
will announce it again in the sprint

00:38:55,240 --> 00:39:00,040
announcement session but there will be a

00:38:57,160 --> 00:39:02,080
sprint and burnable if you want to come

00:39:00,040 --> 00:39:04,060
just feel free it's very open you don't

00:39:02,080 --> 00:39:08,710
you don't need to be expert in anything

00:39:04,060 --> 00:39:10,870
you beginners experts Python estas non

00:39:08,710 --> 00:39:12,250
Python estas everybody is welcome and

00:39:10,870 --> 00:39:14,440
even if you don't want to go to Boone

00:39:12,250 --> 00:39:16,330
abou ETL sprints you should really

00:39:14,440 --> 00:39:19,270
consider Sprint's which is a really nice

00:39:16,330 --> 00:39:21,100
way to learn things other sprints I

00:39:19,270 --> 00:39:25,870
don't know which one dies this year but

00:39:21,100 --> 00:39:28,960
really good thing all the resources will

00:39:25,870 --> 00:39:30,580
be available on this link you can i will

00:39:28,960 --> 00:39:32,590
announce on twitter as soon as it's

00:39:30,580 --> 00:39:35,800
updated with the code and there was a

00:39:32,590 --> 00:39:37,870
link for feedback so that would be

00:39:35,800 --> 00:39:40,360
really nice of you if you can just send

00:39:37,870 --> 00:39:43,000
me a line that was stupid that was good

00:39:40,360 --> 00:39:44,740
that was i I would have added this or

00:39:43,000 --> 00:39:48,430
this was hard to understand I really

00:39:44,740 --> 00:39:50,980
like this yeah and basically that's it

00:39:48,430 --> 00:39:54,480
so thank you very much and if I don't

00:39:50,980 --> 00:39:54,480
know if you have time for questions but

00:39:58,960 --> 00:40:03,620
thank you very much for this very

00:40:01,040 --> 00:40:06,080
interesting talk we have time for a

00:40:03,620 --> 00:40:08,630
couple of questions but I also want to

00:40:06,080 --> 00:40:11,600
remind one saying if you downloaded the

00:40:08,630 --> 00:40:14,420
app there is also a way to rate all the

00:40:11,600 --> 00:40:16,970
talks please do that give five four

00:40:14,420 --> 00:40:20,290
three whatever stars for all the talks

00:40:16,970 --> 00:40:20,290
any questions

00:40:28,810 --> 00:40:39,140
hi thank you for the talk so I wonder

00:40:35,870 --> 00:40:41,860
about the air flow deployment you have

00:40:39,140 --> 00:40:48,440
been you seen some what type of a secure

00:40:41,860 --> 00:40:51,650
so was a cuter executor yes local or

00:40:48,440 --> 00:40:57,440
celery it's a cuter you can talk a bit

00:40:51,650 --> 00:41:02,060
about the deployment okay so we used

00:40:57,440 --> 00:41:04,220
both so let's start with my computer on

00:41:02,060 --> 00:41:05,990
my computer I just went with the local

00:41:04,220 --> 00:41:08,720
executor and it's pretty easy to have

00:41:05,990 --> 00:41:11,560
it's hard to get do logs because there

00:41:08,720 --> 00:41:14,570
is a bit of communication problems but I

00:41:11,560 --> 00:41:16,430
so exactly I built the docker image with

00:41:14,570 --> 00:41:18,230
both the Africa based based on

00:41:16,430 --> 00:41:21,680
astronomical distribution of airflow

00:41:18,230 --> 00:41:23,900
with the upper side code bundled in a

00:41:21,680 --> 00:41:26,840
different virtual environment and I just

00:41:23,900 --> 00:41:29,150
want the Chimeran my computer to deploy

00:41:26,840 --> 00:41:31,730
it to production the same docker image

00:41:29,150 --> 00:41:33,470
is deployed to humanities cluster but

00:41:31,730 --> 00:41:36,650
the configuration is using the suruí

00:41:33,470 --> 00:41:46,840
executors so the cell we execute oh are

00:41:36,650 --> 00:41:52,370
you familiar with survey a bit okay so

00:41:46,840 --> 00:41:54,770
survey as a like manager thing I don't

00:41:52,370 --> 00:41:57,320
really know the name but that one's in

00:41:54,770 --> 00:42:00,020
the scheduler of a flow and that will

00:41:57,320 --> 00:42:03,400
just handle sending messages and

00:42:00,020 --> 00:42:07,760
receiving results from the workers so

00:42:03,400 --> 00:42:12,350
the deployment on aside is made using

00:42:07,760 --> 00:42:15,050
the kubernetes recipes that we got from

00:42:12,350 --> 00:42:18,790
astronomer we changed it a bit I can

00:42:15,050 --> 00:42:21,130
share that also if you if you'd need

00:42:18,790 --> 00:42:23,480
[Music]

00:42:21,130 --> 00:42:25,130
mostly the struggle was to understand

00:42:23,480 --> 00:42:28,400
the architecture it's it's it's why I

00:42:25,130 --> 00:42:30,680
did put the the Afro architectural

00:42:28,400 --> 00:42:33,080
diagram here because as soon as we

00:42:30,680 --> 00:42:36,320
really took the time to understand what

00:42:33,080 --> 00:42:41,130
was happening everything came in pretty

00:42:36,320 --> 00:42:44,519
logical but as it's a distributed system

00:42:41,130 --> 00:42:48,329
just trying to put a thing could create

00:42:44,519 --> 00:42:54,240
some WTF moments about that does that

00:42:48,329 --> 00:42:56,309
answer your question okay hello SEC next

00:42:54,240 --> 00:43:01,710
question that is maybe a little bit

00:42:56,309 --> 00:43:04,529
related how do you actually combine air

00:43:01,710 --> 00:43:06,450
flow and bono both because I guess both

00:43:04,529 --> 00:43:14,690
perhaps they make individual graphs

00:43:06,450 --> 00:43:18,569
defined okay so actually it was done

00:43:14,690 --> 00:43:23,940
here we actually run another Python

00:43:18,569 --> 00:43:25,890
process from the walkers in in what a

00:43:23,940 --> 00:43:30,630
flow workers will run Python process

00:43:25,890 --> 00:43:34,170
that just wins graphs again already so

00:43:30,630 --> 00:43:38,789
probably you you can just take the text

00:43:34,170 --> 00:43:40,910
version but it's in in fact we really

00:43:38,789 --> 00:43:43,589
use a flow to manage the execution

00:43:40,910 --> 00:43:47,009
lifecycle of the other job and we really

00:43:43,589 --> 00:43:48,569
use bonobo to do the actual work that's

00:43:47,009 --> 00:43:50,549
not the only way you can use a flow

00:43:48,569 --> 00:43:53,009
there is also ways you can pass data

00:43:50,549 --> 00:43:58,609
from one job to another but the

00:43:53,009 --> 00:44:04,710
dependency management of a flow is more

00:43:58,609 --> 00:44:07,049
easy is more gearing towards waiting for

00:44:04,710 --> 00:44:08,730
things to complete because we know we

00:44:07,049 --> 00:44:11,250
need a completion before we learn

00:44:08,730 --> 00:44:14,490
something else while bonobos trying to

00:44:11,250 --> 00:44:18,079
do as soon as available let's continue

00:44:14,490 --> 00:44:20,490
the pipeline so it's more streamlined

00:44:18,079 --> 00:44:33,960
bonobo is modeling data streaming so

00:44:20,490 --> 00:44:41,279
both are combined about exactly three

00:44:33,960 --> 00:44:44,160
today it's actually deployed using

00:44:41,279 --> 00:44:46,680
kubernetes so we have a community square

00:44:44,160 --> 00:44:49,380
so if you not don't know kubernetes it's

00:44:46,680 --> 00:44:51,390
a bit out of topic but basically you

00:44:49,380 --> 00:44:53,519
define manifest of your services you

00:44:51,390 --> 00:44:54,750
just put the manifest on kubernetes and

00:44:53,519 --> 00:44:56,850
the scheduler in

00:44:54,750 --> 00:44:58,770
in kubernetes once the docker image you

00:44:56,850 --> 00:45:01,620
define in your manifest and you deploy

00:44:58,770 --> 00:45:05,760
kubernetes by hand no no we use a

00:45:01,620 --> 00:45:10,620
managed version of communities on be ok

00:45:05,760 --> 00:45:12,520
friend or whatever ok thank you very

00:45:10,620 --> 00:45:19,699
much again

00:45:12,520 --> 00:45:19,699

YouTube URL: https://www.youtube.com/watch?v=FCKrfWXBPE4


