Title: Craig Kerstiens - Postgres at any scale
Publication date: 2018-08-22
Playlist: EuroPython 2018
Description: 
	Postgres at any scale
[EuroPython 2018 - Talk - 2018-07-25 - Lammermuir]
[Edinburgh, UK]

By Craig Kerstiens

We’ll start with the basics you need to know as an app developer about interacting with your database, then dig into how you can start to analyze performance. We’ll look at things you need to know for a small application, then the things you should be cautious of as you start to layer in other items you need to be aware of for performance including:


Cache hit ratio
Index hit ratio
Proper use of indexes
Bloat
Efficient joins
Sharding




License: This video is licensed under the CC BY-NC-SA 3.0 license: https://creativecommons.org/licenses/by-nc-sa/3.0/
Please see our speaker release agreement for details: https://ep2018.europython.eu/en/speaker-release-agreement/
Captions: 
	00:00:00,230 --> 00:00:02,469
[Applause]

00:00:03,859 --> 00:00:07,500
awesome thank you uh you'll have to bear

00:00:06,299 --> 00:00:09,780
with me a little bit on the flight over

00:00:07,500 --> 00:00:12,090
I managed to catch a cold so powering

00:00:09,780 --> 00:00:15,360
through a little bit so between the jet

00:00:12,090 --> 00:00:17,100
lag and cold I'll do my best here really

00:00:15,360 --> 00:00:20,369
quick show of hands does anyone here not

00:00:17,100 --> 00:00:22,529
use Postgres a few hands okay hopefully

00:00:20,369 --> 00:00:24,330
I can convince you by the end the rest

00:00:22,529 --> 00:00:27,390
of you you're all my people so I'll talk

00:00:24,330 --> 00:00:31,050
to the rest of you so really quickly Who

00:00:27,390 --> 00:00:33,059
am I I work at situs data we turn

00:00:31,050 --> 00:00:35,460
Postgres into a distributed horizontally

00:00:33,059 --> 00:00:37,590
scalable database think of it like as

00:00:35,460 --> 00:00:39,870
charting without all the work basically

00:00:37,590 --> 00:00:43,200
scalable like no sequel all the goodness

00:00:39,870 --> 00:00:44,730
of Postgres I curate Postgres weekly so

00:00:43,200 --> 00:00:47,399
if you've subscribed to like Python

00:00:44,730 --> 00:00:49,829
weekly or PI coders weekly post press

00:00:47,399 --> 00:00:52,670
weekly is a similar newsletter really

00:00:49,829 --> 00:00:54,329
focused on more active than DBA so

00:00:52,670 --> 00:00:56,489
hopefully you can find something you

00:00:54,329 --> 00:01:00,320
like in there I blog a good bit about

00:00:56,489 --> 00:01:02,579
just like tech startups Postgres as well

00:01:00,320 --> 00:01:06,330
previously I was at Heroku and launched

00:01:02,579 --> 00:01:07,530
the Python support there so python is

00:01:06,330 --> 00:01:10,830
definitely my world when it's not

00:01:07,530 --> 00:01:12,270
Postgres so today we're gonna kind of

00:01:10,830 --> 00:01:15,509
walk through different stages of like

00:01:12,270 --> 00:01:16,860
how to deal with you know data at any

00:01:15,509 --> 00:01:19,619
size and what things you should be doing

00:01:16,860 --> 00:01:21,390
and caring about I don't know how many

00:01:19,619 --> 00:01:23,009
of you run data bases that are like one

00:01:21,390 --> 00:01:25,409
terabyte Postgres can handle that pretty

00:01:23,009 --> 00:01:27,900
well most people are probably more in

00:01:25,409 --> 00:01:29,310
the small medium category but there are

00:01:27,900 --> 00:01:31,110
some things you can do with those stages

00:01:29,310 --> 00:01:34,560
that make life a little bit easier or

00:01:31,110 --> 00:01:37,470
spend kind of the the time investing so

00:01:34,560 --> 00:01:41,700
first starting a little bit small before

00:01:37,470 --> 00:01:44,520
I dig into that why Postgres as a a

00:01:41,700 --> 00:01:46,860
coworker said it's the Emacs of data

00:01:44,520 --> 00:01:51,600
bases and I think this is a really

00:01:46,860 --> 00:01:54,320
telling comment I'm a VI guy but I think

00:01:51,600 --> 00:01:57,600
the the sentiment makes a lot of sense

00:01:54,320 --> 00:01:59,930
Emacs is as much a platform as it is a

00:01:57,600 --> 00:02:02,340
text editor Postgres is much as much a

00:01:59,930 --> 00:02:04,530
data platform as is a relational

00:02:02,340 --> 00:02:06,420
database you see and to think about its

00:02:04,530 --> 00:02:08,099
being really really rigid now it has a

00:02:06,420 --> 00:02:10,289
lot more in the box if we look at a you

00:02:08,099 --> 00:02:12,900
know there's a lot of really really rich

00:02:10,289 --> 00:02:13,410
data types has probably more data types

00:02:12,900 --> 00:02:15,660
than in the

00:02:13,410 --> 00:02:17,640
the database that I know of rich

00:02:15,660 --> 00:02:19,530
geospatial support it's well regarded as

00:02:17,640 --> 00:02:23,040
the most advanced open source geospatial

00:02:19,530 --> 00:02:25,320
database index types we'll get to this a

00:02:23,040 --> 00:02:28,620
little bit later but Postgres adds a new

00:02:25,320 --> 00:02:30,810
index type almost every year these are

00:02:28,620 --> 00:02:33,270
like deep hangout another academic

00:02:30,810 --> 00:02:37,040
foundation but can have really really

00:02:33,270 --> 00:02:40,190
practical use cases full text search

00:02:37,040 --> 00:02:44,430
JSON B deserves its own kind of call-out

00:02:40,190 --> 00:02:46,230
Postgres JSON support in 9.2 which now

00:02:44,430 --> 00:02:50,880
is six years ago but it was just text

00:02:46,230 --> 00:02:53,910
validation JSON B is binary JSON in your

00:02:50,880 --> 00:02:55,830
database so think like binary JSON

00:02:53,910 --> 00:02:57,210
documents that you can index search

00:02:55,830 --> 00:02:58,820
query on so you don't have time

00:02:57,210 --> 00:03:02,400
everything gets normalized tables and

00:02:58,820 --> 00:03:04,800
then extensions extensions really are

00:03:02,400 --> 00:03:06,180
kind of where some of that it's the

00:03:04,800 --> 00:03:08,010
Emacs of database comes in

00:03:06,180 --> 00:03:09,810
now you Postgres can get new features

00:03:08,010 --> 00:03:11,730
without having to wait for a year long

00:03:09,810 --> 00:03:15,420
release cycle so a lot of this stuff

00:03:11,730 --> 00:03:16,830
like GIS full-text search comes on as as

00:03:15,420 --> 00:03:19,200
part of that extension framework so

00:03:16,830 --> 00:03:24,300
really low-level API is I like you

00:03:19,200 --> 00:03:25,350
extend things all right so when you're

00:03:24,300 --> 00:03:27,540
small what do you need to worry about

00:03:25,350 --> 00:03:28,740
the first thing I would say is pay

00:03:27,540 --> 00:03:30,840
attention to data types

00:03:28,740 --> 00:03:32,490
I talked to a lot of people that say I

00:03:30,840 --> 00:03:33,900
want to use the most generic thing

00:03:32,490 --> 00:03:36,540
possible in case I want to up and move

00:03:33,900 --> 00:03:40,080
my from Postgres to MySQL or PostgreSQL

00:03:36,540 --> 00:03:41,850
or something else the reality then is

00:03:40,080 --> 00:03:45,600
you're limiting yourself really really

00:03:41,850 --> 00:03:46,890
heavily to the you know the worst set of

00:03:45,600 --> 00:03:49,350
all things that are shared across

00:03:46,890 --> 00:03:51,000
databases sequel Lite is a great example

00:03:49,350 --> 00:03:53,070
of this where it lists null is a data

00:03:51,000 --> 00:03:54,600
type not as a value but is a data type

00:03:53,070 --> 00:03:58,080
I'm not even sure what that means and

00:03:54,600 --> 00:04:00,120
database since but if you look and say

00:03:58,080 --> 00:04:03,120
hey you know MySQL I want to treat you

00:04:00,120 --> 00:04:05,040
know text the same as Postgres MySQL if

00:04:03,120 --> 00:04:06,690
you insert something too long it just

00:04:05,040 --> 00:04:09,870
truncates it it doesn't say that's

00:04:06,690 --> 00:04:11,610
invalid it just truncates it I care a

00:04:09,870 --> 00:04:13,200
little bit more about the quality and

00:04:11,610 --> 00:04:15,930
sanity of my data so if I want something

00:04:13,200 --> 00:04:18,810
to be explicitly you know say 140

00:04:15,930 --> 00:04:21,750
characters long like a tweet well not so

00:04:18,810 --> 00:04:26,340
valid today but I want to use like a

00:04:21,750 --> 00:04:27,090
varchar' 255 or 140 their timestamp

00:04:26,340 --> 00:04:30,270
verse

00:04:27,090 --> 00:04:32,280
time stamp with time zone post dates are

00:04:30,270 --> 00:04:34,290
hard like there was a great blog post I

00:04:32,280 --> 00:04:37,290
think a month ago that hit hacker news

00:04:34,290 --> 00:04:39,630
of like by Zack Holman it was a fun read

00:04:37,290 --> 00:04:42,930
if you haven't seen it go read it dates

00:04:39,630 --> 00:04:44,550
times are very very hard time zones date

00:04:42,930 --> 00:04:47,100
mat all that sort of thing

00:04:44,550 --> 00:04:48,480
Postgres is really really good time

00:04:47,100 --> 00:04:51,150
stamp with time zone is probably what

00:04:48,480 --> 00:04:53,010
you want by default as theta comes in it

00:04:51,150 --> 00:04:54,720
can convert the time zone for you it's

00:04:53,010 --> 00:04:57,330
still stores in all under the covers as

00:04:54,720 --> 00:04:59,690
the equivalent of UTC but it does that

00:04:57,330 --> 00:05:03,120
map for you which is really nice

00:04:59,690 --> 00:05:06,540
JSON verse JSON be post Prescott JSON

00:05:03,120 --> 00:05:09,450
support in 92 and 94 we got what I would

00:05:06,540 --> 00:05:11,700
call real JSON support in 92 it was just

00:05:09,450 --> 00:05:13,950
text that was validated as JSON as it

00:05:11,700 --> 00:05:16,290
came in but it was stored as text some

00:05:13,950 --> 00:05:18,270
of the covers JSON be is a binary

00:05:16,290 --> 00:05:21,120
representation of it which is really

00:05:18,270 --> 00:05:23,220
fast you can index it all of that if

00:05:21,120 --> 00:05:26,580
you're using something like a logging

00:05:23,220 --> 00:05:28,190
service or recording just inputs from an

00:05:26,580 --> 00:05:30,720
API and you want to preserve whitespace

00:05:28,190 --> 00:05:32,310
use JSON there's a valid case for it

00:05:30,720 --> 00:05:35,729
still to exist that's about the only

00:05:32,310 --> 00:05:37,110
case so the first thing is like leverage

00:05:35,729 --> 00:05:38,940
your data types if you have it in your

00:05:37,110 --> 00:05:42,410
application code as a certain data type

00:05:38,940 --> 00:05:46,020
look at using the same in your database

00:05:42,410 --> 00:05:47,880
alright constraints this is a thing I

00:05:46,020 --> 00:05:51,120
find most people don't intentionally put

00:05:47,880 --> 00:05:52,500
in but and just assume the applications

00:05:51,120 --> 00:05:55,169
going to take care of it

00:05:52,500 --> 00:05:56,630
the reality is without database

00:05:55,169 --> 00:05:59,370
constraints you can definitely have

00:05:56,630 --> 00:06:01,979
invalid data within your database things

00:05:59,370 --> 00:06:03,510
like you know limiting the the length of

00:06:01,979 --> 00:06:04,800
strings if you really want to you should

00:06:03,510 --> 00:06:07,889
have that same constraint within your

00:06:04,800 --> 00:06:10,410
database Postgres has things for like IP

00:06:07,889 --> 00:06:13,200
address datatype is it actually a valid

00:06:10,410 --> 00:06:14,880
IP address or not foreign keys are great

00:06:13,200 --> 00:06:17,389
so that if you delete you know a user

00:06:14,880 --> 00:06:20,039
are you deleting all that users data

00:06:17,389 --> 00:06:21,510
that's more of a concern now with gdpr

00:06:20,039 --> 00:06:23,460
and those sort of things so making sure

00:06:21,510 --> 00:06:24,930
you actually have like foreign keys so

00:06:23,460 --> 00:06:26,190
that as you delete something you make

00:06:24,930 --> 00:06:28,710
sure it Cascades are really really

00:06:26,190 --> 00:06:30,479
important this is a lot easier to do

00:06:28,710 --> 00:06:31,500
when you first start when you first

00:06:30,479 --> 00:06:33,450
start you're probably thinking I just

00:06:31,500 --> 00:06:35,520
want to build something fast putting

00:06:33,450 --> 00:06:36,870
this in place early makes all the

00:06:35,520 --> 00:06:38,880
difference coming back in and adding

00:06:36,870 --> 00:06:40,470
that you know years down the line it's a

00:06:38,880 --> 00:06:40,800
lot of work and you realize you actually

00:06:40,470 --> 00:06:45,870
got to go

00:06:40,800 --> 00:06:47,699
clean up data at that point this is one

00:06:45,870 --> 00:06:50,340
that's really common in the rails

00:06:47,699 --> 00:06:51,720
community I don't see it as much in the

00:06:50,340 --> 00:06:55,319
Python community but I think it's a

00:06:51,720 --> 00:06:57,780
really good pattern in rails they don't

00:06:55,319 --> 00:06:59,250
actually delete data which I know is

00:06:57,780 --> 00:07:01,169
probably a concern now for privacy and

00:06:59,250 --> 00:07:04,409
other things but there's a basically a

00:07:01,169 --> 00:07:06,810
flag on every model they create that

00:07:04,409 --> 00:07:08,280
says deleted at is null and they just

00:07:06,810 --> 00:07:10,229
set that value and then they filter that

00:07:08,280 --> 00:07:12,270
out constantly so we're deleted at is

00:07:10,229 --> 00:07:14,610
not null then you don't return that in

00:07:12,270 --> 00:07:16,080
the query this is really really nice if

00:07:14,610 --> 00:07:19,110
you've ever accidentally run a query

00:07:16,080 --> 00:07:22,169
which we never have you know deletes you

00:07:19,110 --> 00:07:25,620
know from users and then you forget the

00:07:22,169 --> 00:07:28,500
where clause and everyone remembers you

00:07:25,620 --> 00:07:30,360
know immediately after like it wasn't a

00:07:28,500 --> 00:07:32,310
full second as soon as you hit enter

00:07:30,360 --> 00:07:33,599
you're trying to cancel it and what just

00:07:32,310 --> 00:07:36,840
happened

00:07:33,599 --> 00:07:39,629
it's still a pain to clean up with you

00:07:36,840 --> 00:07:42,360
know update set deleted at but this is

00:07:39,629 --> 00:07:43,800
far far far better to clean up then

00:07:42,360 --> 00:07:45,180
where you actually went and deleted it

00:07:43,800 --> 00:07:48,449
and have to do a point-in-time recovery

00:07:45,180 --> 00:07:50,099
against your database so soft deletes

00:07:48,449 --> 00:07:52,349
are a pattern I really really like and

00:07:50,099 --> 00:07:53,699
would like to see more of I'd encourage

00:07:52,349 --> 00:07:58,020
you to consider if they can work for you

00:07:53,699 --> 00:08:00,060
all so the other thing is I would say

00:07:58,020 --> 00:08:02,099
spend some time mastering your tools how

00:08:00,060 --> 00:08:05,490
many here have like a batch RCE or like

00:08:02,099 --> 00:08:08,419
a vim or C set up okay most hands how

00:08:05,490 --> 00:08:10,740
many have a piece equal our C setup

00:08:08,419 --> 00:08:14,400
that's actually more than I expected

00:08:10,740 --> 00:08:16,259
maybe 10 to 15 or so piece equal is a

00:08:14,400 --> 00:08:17,759
really really great post press editor

00:08:16,259 --> 00:08:21,300
it's the CLI tool that ships with

00:08:17,759 --> 00:08:22,770
Postgres out-of-the-box it's okay but

00:08:21,300 --> 00:08:24,690
what you can do is customize it it has a

00:08:22,770 --> 00:08:26,479
lot of really built in richness so you

00:08:24,690 --> 00:08:29,219
can add things like tab completion

00:08:26,479 --> 00:08:31,379
backslash X Auto is an awesome feature

00:08:29,219 --> 00:08:33,779
that based on the width of your screen

00:08:31,379 --> 00:08:35,610
and the width of the query output will

00:08:33,779 --> 00:08:37,229
auto format the output of the query so

00:08:35,610 --> 00:08:39,779
that it either like word wraps or puts

00:08:37,229 --> 00:08:43,829
like a entire kind of record line by

00:08:39,779 --> 00:08:46,019
line by line one thing I like to do if

00:08:43,829 --> 00:08:48,810
you search for like P sequel in my blog

00:08:46,019 --> 00:08:51,990
I like to say the history of every

00:08:48,810 --> 00:08:53,550
command I run against a database so for

00:08:51,990 --> 00:08:54,570
every database based on the name I have

00:08:53,550 --> 00:08:56,279
a history

00:08:54,570 --> 00:08:57,870
if you've ever had someone come to you

00:08:56,279 --> 00:08:59,610
and say hey can you run this report for

00:08:57,870 --> 00:09:02,339
me and you hop into the database you run

00:08:59,610 --> 00:09:04,649
a query sending the report great you're

00:09:02,339 --> 00:09:06,120
done three months later they come back

00:09:04,649 --> 00:09:08,010
and say hey do you remember that report

00:09:06,120 --> 00:09:10,410
you ran for me can I get an updated copy

00:09:08,010 --> 00:09:12,779
of it I'm like I have no idea what you

00:09:10,410 --> 00:09:14,670
asked for what I ran

00:09:12,779 --> 00:09:16,709
I got recreated it's probably not the

00:09:14,670 --> 00:09:18,630
exact same thing like saving the history

00:09:16,709 --> 00:09:20,339
of every query I run it's great to come

00:09:18,630 --> 00:09:22,140
back through and some swarm of ad hoc

00:09:20,339 --> 00:09:23,459
analysis and I don't have to do anything

00:09:22,140 --> 00:09:26,730
extra by just setting that up in my

00:09:23,459 --> 00:09:28,890
piece equal history file back slash

00:09:26,730 --> 00:09:30,930
timing is a nice tool that shows the

00:09:28,890 --> 00:09:36,720
output on every query you run how long

00:09:30,930 --> 00:09:39,620
it ran all right so backups

00:09:36,720 --> 00:09:42,240
who here has backups on their database

00:09:39,620 --> 00:09:47,670
who here tested them within the last

00:09:42,240 --> 00:09:49,950
month all right so backups do not exist

00:09:47,670 --> 00:09:51,870
unless you test him setting up backup

00:09:49,950 --> 00:09:53,279
from the start is good if you haven't

00:09:51,870 --> 00:09:55,320
tested them like I know you think they

00:09:53,279 --> 00:09:57,810
work I don't know people saw come and be

00:09:55,320 --> 00:09:59,550
get lab incident from maybe it was a

00:09:57,810 --> 00:10:01,050
year ago now and they tried not just

00:09:59,550 --> 00:10:03,630
five different backups like five

00:10:01,050 --> 00:10:06,240
different methods of backups and failure

00:10:03,630 --> 00:10:07,740
failure failure start a process of

00:10:06,240 --> 00:10:11,459
testing your backups it doesn't have to

00:10:07,740 --> 00:10:14,339
be daily weekly monthly is probably a

00:10:11,459 --> 00:10:16,190
good interval I would go and do that now

00:10:14,339 --> 00:10:20,579
try to restore your latest backup and

00:10:16,190 --> 00:10:21,810
let me know if it failed or succeeded if

00:10:20,579 --> 00:10:22,709
you're not testing them there's no point

00:10:21,810 --> 00:10:26,100
in even putting you in place because

00:10:22,709 --> 00:10:26,279
they're probably not gonna work all

00:10:26,100 --> 00:10:29,310
right

00:10:26,279 --> 00:10:29,970
so early on I would say you know invest

00:10:29,310 --> 00:10:31,890
in those things

00:10:29,970 --> 00:10:34,320
that's probably pre-tin gigs of data

00:10:31,890 --> 00:10:35,790
right a lot a lot of small projects a

00:10:34,320 --> 00:10:38,190
lot of things that aren't gonna have a

00:10:35,790 --> 00:10:40,770
lot of users done a lot of data in terms

00:10:38,190 --> 00:10:42,120
of like medium sized data now you need

00:10:40,770 --> 00:10:43,470
to start to learn a little bit more

00:10:42,120 --> 00:10:45,810
about Postgres you don't have to become

00:10:43,470 --> 00:10:48,390
a DBA or an expert but a few kind of key

00:10:45,810 --> 00:10:49,709
things will go a long way here we're

00:10:48,390 --> 00:10:54,060
looking at something probably like 10

00:10:49,709 --> 00:10:56,220
gigs of data up to 100 gigs or so a few

00:10:54,060 --> 00:10:57,630
basic things you're gonna want to do set

00:10:56,220 --> 00:10:59,910
up logging make sure you have log

00:10:57,630 --> 00:11:01,680
rotation the number of times I've seen

00:10:59,910 --> 00:11:04,230
where people set up logs and then don't

00:11:01,680 --> 00:11:06,899
setup log rotation run out a space on

00:11:04,230 --> 00:11:09,809
their database because it just logs

00:11:06,899 --> 00:11:11,579
it happens make sure you do some these

00:11:09,809 --> 00:11:14,339
sort of things configure your memory

00:11:11,579 --> 00:11:16,110
Postgres is it great by default at its

00:11:14,339 --> 00:11:18,600
memory settings but it's not that hard

00:11:16,110 --> 00:11:21,389
to configure tweak vacuum adjust your

00:11:18,600 --> 00:11:23,309
checkpoints but the biggest thing here

00:11:21,389 --> 00:11:25,559
is don't try to be an expert in all of

00:11:23,309 --> 00:11:27,779
those settings there's a number of tools

00:11:25,559 --> 00:11:29,670
like PG tomb where you can go and

00:11:27,779 --> 00:11:31,709
putting some some data about your

00:11:29,670 --> 00:11:33,899
database say hey I have this much data

00:11:31,709 --> 00:11:36,209
this size instance what should all of

00:11:33,899 --> 00:11:37,889
these settings be this is one area when

00:11:36,209 --> 00:11:40,230
I say like don't try to learn too much

00:11:37,889 --> 00:11:42,720
there's like 200 different settings and

00:11:40,230 --> 00:11:44,059
configs within postgres just set them

00:11:42,720 --> 00:11:46,439
once and then you're pretty much good

00:11:44,059 --> 00:11:49,050
and there's a few talks out here on this

00:11:46,439 --> 00:11:51,209
as well a great one from PyCon i think

00:11:49,050 --> 00:11:53,579
two years ago was PostgreSQL when it's

00:11:51,209 --> 00:11:55,980
not your day job Christoph Pettis walks

00:11:53,579 --> 00:11:57,389
through a bunch of set this config don't

00:11:55,980 --> 00:11:58,439
worry about what means set this config

00:11:57,389 --> 00:12:00,089
if you're on a table yes don't worry

00:11:58,439 --> 00:12:05,040
about what it means to get you a good

00:12:00,089 --> 00:12:07,050
solid setup alright so the number one

00:12:05,040 --> 00:12:08,730
thing I pay attention to when I first

00:12:07,050 --> 00:12:11,160
look at a database is the cache hit

00:12:08,730 --> 00:12:12,740
ratio is anyone else excited that

00:12:11,160 --> 00:12:15,449
DuckTales has come back

00:12:12,740 --> 00:12:22,050
I'm Way too excited for this with my

00:12:15,449 --> 00:12:25,769
kids anyways so running this simple

00:12:22,050 --> 00:12:28,220
simple query against your database will

00:12:25,769 --> 00:12:31,199
tell you the cache hit ratio Postgres

00:12:28,220 --> 00:12:33,929
keeps a lot of data about the queries it

00:12:31,199 --> 00:12:35,639
runs such as you know which things were

00:12:33,929 --> 00:12:37,889
served from in memory which things went

00:12:35,639 --> 00:12:39,240
to disk as we know going to disk much

00:12:37,889 --> 00:12:40,860
much slower than in a memory you've got

00:12:39,240 --> 00:12:42,269
to look at a hundred to one a thousand

00:12:40,860 --> 00:12:45,480
to one difference in kind of performance

00:12:42,269 --> 00:12:46,620
time here this super simple query is

00:12:45,480 --> 00:12:49,379
going to give you back something that

00:12:46,620 --> 00:12:52,170
looks like this and here what I'm going

00:12:49,379 --> 00:12:53,999
to look for in most applications and

00:12:52,170 --> 00:12:55,350
this is for a transactional web app if

00:12:53,999 --> 00:12:58,620
you're in data warehousing it's

00:12:55,350 --> 00:13:00,959
completely different but most web

00:12:58,620 --> 00:13:03,749
applications that I come across you want

00:13:00,959 --> 00:13:06,569
to see a cache hit ratio of 99% if this

00:13:03,749 --> 00:13:08,459
is too low the easiest things to do to

00:13:06,569 --> 00:13:10,769
improve performance is go get a bigger

00:13:08,459 --> 00:13:13,639
instance upgrade your database add more

00:13:10,769 --> 00:13:16,589
memory to the box things will be happier

00:13:13,639 --> 00:13:18,410
when you go from 99% to something like

00:13:16,589 --> 00:13:20,700
ninety eight ninety five percent

00:13:18,410 --> 00:13:22,380
performance doesn't go from one

00:13:20,700 --> 00:13:24,870
second - - it goes from like one

00:13:22,380 --> 00:13:26,540
millisecond to like 100 milliseconds he

00:13:24,870 --> 00:13:30,810
falls off a cliff really really quickly

00:13:26,540 --> 00:13:33,390
so querying this on a weekly monthly

00:13:30,810 --> 00:13:34,680
basis is a good thing to do

00:13:33,390 --> 00:13:36,360
sending it ups with some of your regular

00:13:34,680 --> 00:13:40,080
alerts check it out and see when you

00:13:36,360 --> 00:13:42,420
need to upgrade the next thing I'm going

00:13:40,080 --> 00:13:45,090
to look at is am i properly using index

00:13:42,420 --> 00:13:46,500
so just like how many things are served

00:13:45,090 --> 00:13:49,650
from cache first how many things are

00:13:46,500 --> 00:13:52,440
served from disk Postgres has index hit

00:13:49,650 --> 00:13:54,030
rate this query is going to give us

00:13:52,440 --> 00:13:55,770
something that we have to do a little

00:13:54,030 --> 00:13:58,050
bit more thinking through it's gonna

00:13:55,770 --> 00:13:59,430
show the number of times I use the

00:13:58,050 --> 00:14:01,500
percentage of time I use in index

00:13:59,430 --> 00:14:05,310
against this table on my queries and the

00:14:01,500 --> 00:14:08,250
number of rows in my table as a rough

00:14:05,310 --> 00:14:10,530
rule of thumb what I'd go for is you

00:14:08,250 --> 00:14:11,880
know if I've got more than 10,000 rows

00:14:10,530 --> 00:14:14,010
and I'm doing a lot of really short

00:14:11,880 --> 00:14:16,800
lookups I want to have an index hit rate

00:14:14,010 --> 00:14:18,510
of 95 percent or higher this is gonna

00:14:16,800 --> 00:14:19,680
vary based on application sometimes you

00:14:18,510 --> 00:14:20,970
may want it a little lower if you're

00:14:19,680 --> 00:14:23,490
doing a lot of reporting against one

00:14:20,970 --> 00:14:26,780
table but single row inserts you want to

00:14:23,490 --> 00:14:28,890
typically inserts lookups updates

00:14:26,780 --> 00:14:30,840
because you're getting a single row you

00:14:28,890 --> 00:14:32,880
want to have you know it in cache or

00:14:30,840 --> 00:14:37,740
using an index so here you're looking

00:14:32,880 --> 00:14:39,960
for a higher index hit rate and so here

00:14:37,740 --> 00:14:41,040
we can see like these top three tables

00:14:39,960 --> 00:14:44,910
we won't probably want to come in and

00:14:41,040 --> 00:14:46,620
add some indexes on all right

00:14:44,910 --> 00:14:48,900
so looking at it from the other

00:14:46,620 --> 00:14:51,540
perspective if you've got a certain page

00:14:48,900 --> 00:14:53,640
in your application you're running some

00:14:51,540 --> 00:14:55,830
you want to improve the performance you

00:14:53,640 --> 00:14:57,060
know it's slow you don't know why you

00:14:55,830 --> 00:14:58,710
can see the queries it's running

00:14:57,060 --> 00:15:00,930
Postgres has something called an

00:14:58,710 --> 00:15:03,270
explained plan if you put an explained

00:15:00,930 --> 00:15:04,740
in front of any query and run it it's

00:15:03,270 --> 00:15:08,850
gonna tell you what it thinks it's going

00:15:04,740 --> 00:15:11,130
to do from a performance perspective you

00:15:08,850 --> 00:15:12,210
run to explain analyze it's going to

00:15:11,130 --> 00:15:13,980
tell you what it thinks it's gonna do

00:15:12,210 --> 00:15:17,310
and it's also gonna run the query and

00:15:13,980 --> 00:15:19,170
give you what actually happened if there

00:15:17,310 --> 00:15:20,880
is a really really really horribly

00:15:19,170 --> 00:15:22,470
performant query be careful with running

00:15:20,880 --> 00:15:26,370
explain analyze because it's also going

00:15:22,470 --> 00:15:27,870
to run the query for you I've worked

00:15:26,370 --> 00:15:30,780
with Postgres for a little over ten

00:15:27,870 --> 00:15:33,330
years now I still look at explain plans

00:15:30,780 --> 00:15:33,640
and have to like pause get come some

00:15:33,330 --> 00:15:35,790
coffee

00:15:33,640 --> 00:15:39,940
and like look at what's going on there

00:15:35,790 --> 00:15:43,660
it's not it shouldn't be as confusing as

00:15:39,940 --> 00:15:46,060
it is so uh some rough guidelines first

00:15:43,660 --> 00:15:47,950
like for web application I'm thinking

00:15:46,060 --> 00:15:50,230
okay can I get you know really really

00:15:47,950 --> 00:15:52,240
common page response times down under

00:15:50,230 --> 00:15:53,830
ten milliseconds now with things like

00:15:52,240 --> 00:15:57,010
single page apps that's more like one

00:15:53,830 --> 00:15:58,690
second common queries so still in my

00:15:57,010 --> 00:16:01,030
application I want ten milliseconds or

00:15:58,690 --> 00:16:03,940
less more rare queries under 100

00:16:01,030 --> 00:16:07,000
milliseconds so coming back to this

00:16:03,940 --> 00:16:09,640
query there's a couple of things here so

00:16:07,000 --> 00:16:12,760
if you can see in red there there's two

00:16:09,640 --> 00:16:16,000
different values those values that

00:16:12,760 --> 00:16:17,680
actual time is separated by two dots

00:16:16,000 --> 00:16:20,380
those are two different values I want to

00:16:17,680 --> 00:16:22,480
pay attention to the second one that is

00:16:20,380 --> 00:16:25,150
what it actually ran as in that case

00:16:22,480 --> 00:16:28,480
it's 295 milliseconds to complete this

00:16:25,150 --> 00:16:30,250
step of that operation so knowing that

00:16:28,480 --> 00:16:32,700
hey if I want things under 1

00:16:30,250 --> 00:16:35,290
milliseconds I can see okay this is

00:16:32,700 --> 00:16:36,640
total run time is slow and that one

00:16:35,290 --> 00:16:38,620
operation that's happening right there

00:16:36,640 --> 00:16:42,220
is the sequential scan not using an

00:16:38,620 --> 00:16:44,620
index so what do I want to do I want to

00:16:42,220 --> 00:16:46,180
come in and add an index in this case

00:16:44,620 --> 00:16:49,780
I'm just gonna add it on salary because

00:16:46,180 --> 00:16:51,490
I've got that filter there rerun this

00:16:49,780 --> 00:16:54,700
and that's gonna bring it down to 1.7

00:16:51,490 --> 00:16:56,320
milliseconds there's a tool if you

00:16:54,700 --> 00:17:00,310
search for understanding explaining

00:16:56,320 --> 00:17:01,750
there's a tool by this does Pez I don't

00:17:00,310 --> 00:17:04,660
actually know how you say his name just

00:17:01,750 --> 00:17:06,400
from the internet it's great that kind

00:17:04,660 --> 00:17:08,380
of helps like take an explained plan

00:17:06,400 --> 00:17:12,550
paste it in it'll highlight the really

00:17:08,380 --> 00:17:14,020
bad steps for you it calls out kind of

00:17:12,550 --> 00:17:19,089
basically where you need to optimize and

00:17:14,020 --> 00:17:24,339
within this step so that helps if you

00:17:19,089 --> 00:17:26,680
know you've got a specific query but a

00:17:24,339 --> 00:17:28,420
lot of times you have an application you

00:17:26,680 --> 00:17:31,930
know like things are slow can you tell

00:17:28,420 --> 00:17:33,940
me what like queries are all over I have

00:17:31,930 --> 00:17:35,680
all sorts of things being executed for

00:17:33,940 --> 00:17:39,100
my ORM I have no idea what the queries

00:17:35,680 --> 00:17:41,590
actually are Postgres had this extension

00:17:39,100 --> 00:17:43,060
called PG stat statements it records

00:17:41,590 --> 00:17:45,010
every query that's run against your

00:17:43,060 --> 00:17:47,080
database essentially parameter eise's it

00:17:45,010 --> 00:17:49,120
so the query that would have actually

00:17:47,080 --> 00:17:50,919
run in this case would be select star

00:17:49,120 --> 00:17:53,500
from users where email equals Craig at

00:17:50,919 --> 00:17:54,909
situs datacom it strips at Craig at site

00:17:53,500 --> 00:17:56,919
estate and calm because it's different

00:17:54,909 --> 00:17:58,899
for every user in my application it

00:17:56,919 --> 00:18:01,390
records all these internal things like

00:17:58,899 --> 00:18:02,830
how many blocks were dirty how many you

00:18:01,390 --> 00:18:05,590
know buffers were dirty how many new

00:18:02,830 --> 00:18:07,029
blocks were written I don't care about

00:18:05,590 --> 00:18:10,019
much of this you can drill and if you

00:18:07,029 --> 00:18:12,820
want what I really want to see though is

00:18:10,019 --> 00:18:15,130
how many times a query was ran how long

00:18:12,820 --> 00:18:16,720
did it take on average and how much time

00:18:15,130 --> 00:18:19,710
is it consuming an aggregate against my

00:18:16,720 --> 00:18:23,169
system so this one query will give you

00:18:19,710 --> 00:18:27,460
something that looks like this select ID

00:18:23,169 --> 00:18:30,250
from users was run a ton of times in

00:18:27,460 --> 00:18:32,289
average 10 milliseconds an aggregate

00:18:30,250 --> 00:18:34,000
it's run for 295 seconds against my

00:18:32,289 --> 00:18:34,720
database since I've started recording

00:18:34,000 --> 00:18:36,730
the stats

00:18:34,720 --> 00:18:40,779
I've got another query that's this other

00:18:36,730 --> 00:18:43,510
select star from on average it's 80

00:18:40,779 --> 00:18:46,330
milliseconds and it's run almost as much

00:18:43,510 --> 00:18:47,679
time as that other one coming back doing

00:18:46,330 --> 00:18:49,299
some of that math thinking okay if I

00:18:47,679 --> 00:18:51,549
know I can get a query down typically to

00:18:49,299 --> 00:18:54,240
1 millisecond if I were to go and

00:18:51,549 --> 00:18:58,690
optimize that second one I'm gonna get

00:18:54,240 --> 00:18:59,980
an order of two orders of magnitude back

00:18:58,690 --> 00:19:02,799
in overall performance against my

00:18:59,980 --> 00:19:04,840
database so really handy without like

00:19:02,799 --> 00:19:06,850
having to dig into the application code

00:19:04,840 --> 00:19:10,840
which queries are being run from where

00:19:06,850 --> 00:19:13,269
and being able to optimize them alright

00:19:10,840 --> 00:19:15,940
so I mentioned indexes as a reason that

00:19:13,269 --> 00:19:17,799
Postgres is great

00:19:15,940 --> 00:19:20,049
Postgres has a lot of indexes mostly in

00:19:17,799 --> 00:19:21,220
the basis if you if you have a CS degree

00:19:20,049 --> 00:19:24,639
you probably learned about a b-tree

00:19:21,220 --> 00:19:25,659
index in school you probably didn't

00:19:24,639 --> 00:19:30,490
learn about the rest of these these

00:19:25,659 --> 00:19:32,049
other indexes gen gifs SPG is Brynn post

00:19:30,490 --> 00:19:33,970
pressed pretty much gets a new one every

00:19:32,049 --> 00:19:36,269
year there's a group within the post

00:19:33,970 --> 00:19:38,950
Christ community known as the Russians

00:19:36,269 --> 00:19:41,110
one of them is a professor of

00:19:38,950 --> 00:19:45,340
astrophysics at the University of Moscow

00:19:41,110 --> 00:19:47,710
and for fun he acts on Postgres we have

00:19:45,340 --> 00:19:50,350
different definitions of fun but they

00:19:47,710 --> 00:19:52,870
usually show up with some crazy you know

00:19:50,350 --> 00:19:56,260
academic paper saying hey here's this

00:19:52,870 --> 00:19:59,440
new index type that I read a paper on

00:19:56,260 --> 00:20:00,020
you know space partition gifs which is

00:19:59,440 --> 00:20:03,380
gender

00:20:00,020 --> 00:20:04,309
search tree they show up on the mailing

00:20:03,380 --> 00:20:06,410
list they're like hey we're gonna

00:20:04,309 --> 00:20:09,140
implement this people like that sounds

00:20:06,410 --> 00:20:10,429
crazy they it's like they go into a cave

00:20:09,140 --> 00:20:12,740
and they come back three months later

00:20:10,429 --> 00:20:18,020
with like code and everyone's like okay

00:20:12,740 --> 00:20:20,120
that looks good let's commit it but if

00:20:18,020 --> 00:20:21,620
you read through each of those even in

00:20:20,120 --> 00:20:24,050
the Postgres talks and kind of look

00:20:21,620 --> 00:20:27,590
through them like which do I use I have

00:20:24,050 --> 00:20:29,240
no idea I read through I look at the

00:20:27,590 --> 00:20:30,710
papers and I'm like okay I kind of

00:20:29,240 --> 00:20:32,480
understand what's going on here maybe a

00:20:30,710 --> 00:20:33,950
little bit but how do I actually put

00:20:32,480 --> 00:20:38,410
this into practice that's a completely

00:20:33,950 --> 00:20:41,030
different story so this is slightly

00:20:38,410 --> 00:20:44,090
oversimplified but generally will work

00:20:41,030 --> 00:20:45,890
for 99% of times b-tree this is usually

00:20:44,090 --> 00:20:49,309
what you want when you're doing a lookup

00:20:45,890 --> 00:20:51,800
based on you know email address or a

00:20:49,309 --> 00:20:53,660
filter where you know salary is less or

00:20:51,800 --> 00:21:02,679
greater than this this is usually what

00:20:53,660 --> 00:21:05,300
you want to use gin so gin is useful

00:21:02,679 --> 00:21:07,070
when there are multiple values within a

00:21:05,300 --> 00:21:08,420
single column so if you think of a

00:21:07,070 --> 00:21:10,640
single data type a single column

00:21:08,420 --> 00:21:12,500
something like an array H store which is

00:21:10,640 --> 00:21:14,420
a key value data type in Postgres or

00:21:12,500 --> 00:21:15,620
JSON B where you've got multiple

00:21:14,420 --> 00:21:17,660
different values inside that JSON

00:21:15,620 --> 00:21:22,370
document this is usually what you want

00:21:17,660 --> 00:21:23,750
to use generally search stream this

00:21:22,370 --> 00:21:27,230
one's a little more confusing you can

00:21:23,750 --> 00:21:29,360
think about it as when values overlap

00:21:27,230 --> 00:21:31,429
between rows so if you think of like

00:21:29,360 --> 00:21:33,410
shapes you've got polygons right you've

00:21:31,429 --> 00:21:35,300
got a circle that's in you know one row

00:21:33,410 --> 00:21:37,550
you've got another circle that is in

00:21:35,300 --> 00:21:39,260
another row some of the values within

00:21:37,550 --> 00:21:41,030
those polygons within those circles can

00:21:39,260 --> 00:21:42,650
overlap some will not

00:21:41,030 --> 00:21:45,500
same thing with full-text search if

00:21:42,650 --> 00:21:47,600
you've got a full sentence some of the

00:21:45,500 --> 00:21:50,559
words overlap with words and other

00:21:47,600 --> 00:21:53,570
sentences some do not so if you've got

00:21:50,559 --> 00:21:55,429
values that overlap between rows this is

00:21:53,570 --> 00:21:56,840
probably what you want to use the

00:21:55,429 --> 00:21:58,610
simplified version is if you're doing

00:21:56,840 --> 00:22:00,950
things with geospatial stuff or

00:21:58,610 --> 00:22:03,130
full-text search just is probably what

00:22:00,950 --> 00:22:03,130
you want

00:22:03,950 --> 00:22:11,030
Espie gist and Brin are generally used

00:22:07,970 --> 00:22:12,770
for really really large tables SP just

00:22:11,030 --> 00:22:13,149
I've asked a lot of the Postgres core

00:22:12,770 --> 00:22:15,159
Commun

00:22:13,149 --> 00:22:16,570
like can you simplify it and the only

00:22:15,159 --> 00:22:18,429
thing I've taken away is if you're

00:22:16,570 --> 00:22:20,739
working with phone numbers you want to

00:22:18,429 --> 00:22:25,119
use SP just that's all I've understood

00:22:20,739 --> 00:22:26,499
thus far Brin is really really good when

00:22:25,119 --> 00:22:29,139
you're scanning a lot of sequential data

00:22:26,499 --> 00:22:31,179
and I say a lot like tables with

00:22:29,139 --> 00:22:36,369
billions and billions of records often

00:22:31,179 --> 00:22:38,950
time series that sort of thing there is

00:22:36,369 --> 00:22:41,799
also another index type that's

00:22:38,950 --> 00:22:43,179
supposedly coming up so I mentioned the

00:22:41,799 --> 00:22:45,940
the Russians are the ones that have

00:22:43,179 --> 00:22:48,489
contributed most of these they felt

00:22:45,940 --> 00:22:52,359
because we had gin with in Postgres we

00:22:48,489 --> 00:22:54,820
also need vodka I wish that was only a

00:22:52,359 --> 00:22:57,279
joke that is the working name for the

00:22:54,820 --> 00:23:03,309
index site so we are getting apparently

00:22:57,279 --> 00:23:06,129
vodka with in Postgres as well so a few

00:23:03,309 --> 00:23:09,519
other index tips be specific with your

00:23:06,129 --> 00:23:11,619
indexes don't just say create index you

00:23:09,519 --> 00:23:14,259
can add composite indexes if you always

00:23:11,619 --> 00:23:16,419
query on first name and last name when

00:23:14,259 --> 00:23:17,950
you're searching at an index on both

00:23:16,419 --> 00:23:21,339
post press will be pretty smart and use

00:23:17,950 --> 00:23:24,759
those composite indexes of functional

00:23:21,339 --> 00:23:27,190
ones if you always query on lower case

00:23:24,759 --> 00:23:29,799
of you know name if you want to have a

00:23:27,190 --> 00:23:31,509
case insensitive search make sure if

00:23:29,799 --> 00:23:33,909
you're sending in you know the lowercase

00:23:31,509 --> 00:23:38,349
version of it you do the same thing

00:23:33,909 --> 00:23:42,309
within your database or conditional ones

00:23:38,349 --> 00:23:43,599
if you have a lot of data but some of it

00:23:42,309 --> 00:23:46,389
you're not usually searching on like a

00:23:43,599 --> 00:23:48,849
great example is if you're a phone book

00:23:46,389 --> 00:23:51,009
and actually within the database you

00:23:48,849 --> 00:23:52,479
have every historical phone number in

00:23:51,009 --> 00:23:54,549
every place everyone has lived prior

00:23:52,479 --> 00:23:55,960
you're probably not frequently searching

00:23:54,549 --> 00:23:57,849
on where I lived you know five

00:23:55,960 --> 00:23:59,619
apartments ago so you could say where

00:23:57,849 --> 00:24:01,719
current address is equal to true and

00:23:59,619 --> 00:24:03,879
it's only gonna index where current

00:24:01,719 --> 00:24:05,469
address is equal to true really nice if

00:24:03,879 --> 00:24:08,109
you want to have an index on a part of

00:24:05,469 --> 00:24:09,969
your data and there I'd look as you know

00:24:08,109 --> 00:24:11,830
do you have ten times the amount of data

00:24:09,969 --> 00:24:17,109
but you are you calmly only filtering on

00:24:11,830 --> 00:24:19,539
a subset of it so within your database

00:24:17,109 --> 00:24:23,139
you usually have a big trade-off between

00:24:19,539 --> 00:24:24,399
faster reads and faster writes I know

00:24:23,139 --> 00:24:28,030
the answer is you want everything to be

00:24:24,399 --> 00:24:32,880
fast sorry it doesn't work that way

00:24:28,030 --> 00:24:36,190
so a few months ago I created this tweet

00:24:32,880 --> 00:24:39,940
this will give you the output to create

00:24:36,190 --> 00:24:43,929
an index on every column of every table

00:24:39,940 --> 00:24:46,360
of your database so you'll have indexes

00:24:43,929 --> 00:24:50,370
on everything everything will be fast on

00:24:46,360 --> 00:24:52,900
the right side this was mostly a joke

00:24:50,370 --> 00:24:56,799
but it's also not a completely crazy

00:24:52,900 --> 00:24:59,440
idea so when you add an index for every

00:24:56,799 --> 00:25:01,510
write you you make its gonna figure out

00:24:59,440 --> 00:25:03,429
the query plan it's gonna write to disk

00:25:01,510 --> 00:25:05,440
it's gonna wait for it to acknowledge

00:25:03,429 --> 00:25:06,790
that right and it's going to return this

00:25:05,440 --> 00:25:10,600
is about a kind of a one millisecond

00:25:06,790 --> 00:25:12,790
round-trip on reasonable disk as you add

00:25:10,600 --> 00:25:14,080
an index it's gonna also update that

00:25:12,790 --> 00:25:16,419
index and make sure there's no like

00:25:14,080 --> 00:25:18,400
constraint violation or just make sure

00:25:16,419 --> 00:25:21,340
the index is up-to-date then it's gonna

00:25:18,400 --> 00:25:23,350
return so I we can just roughly say hey

00:25:21,340 --> 00:25:25,750
I added a couple extra milliseconds down

00:25:23,350 --> 00:25:27,040
and you add another index it's gonna do

00:25:25,750 --> 00:25:29,950
the same thing so it's gonna have to do

00:25:27,040 --> 00:25:31,929
both of these and you have another one

00:25:29,950 --> 00:25:34,059
and it's gonna do the same thing so I go

00:25:31,929 --> 00:25:36,580
and add an index on every single column

00:25:34,059 --> 00:25:38,140
on every single table now I have rights

00:25:36,580 --> 00:25:41,559
that take like two seconds or something

00:25:38,140 --> 00:25:43,179
like that not the best idea but as I

00:25:41,559 --> 00:25:46,299
mentioned Postgres is really really good

00:25:43,179 --> 00:25:49,299
about keeping stats at that medium scale

00:25:46,299 --> 00:25:51,460
it's not terrible to over index things I

00:25:49,299 --> 00:25:53,950
wouldn't go all out and index every

00:25:51,460 --> 00:25:55,530
column of every table but you can be

00:25:53,950 --> 00:25:59,830
pretty generous with your indexes and

00:25:55,530 --> 00:26:02,530
then Postgres has this another super

00:25:59,830 --> 00:26:04,360
super simple query you can run that will

00:26:02,530 --> 00:26:06,400
show all of the unused indexes on your

00:26:04,360 --> 00:26:07,900
database so if you have an index and

00:26:06,400 --> 00:26:10,750
setting they're just slowing down writes

00:26:07,900 --> 00:26:12,940
but maybe your application code changed

00:26:10,750 --> 00:26:15,010
or the data distribution changed and

00:26:12,940 --> 00:26:16,809
it's never using this index you can run

00:26:15,010 --> 00:26:18,730
this query say hey I don't need this and

00:26:16,809 --> 00:26:20,020
then go come back and drop it later so a

00:26:18,730 --> 00:26:21,790
good thing to do to come back and kind

00:26:20,020 --> 00:26:24,640
of start that process of cleaning up

00:26:21,790 --> 00:26:26,890
unused indexes and it'll give you

00:26:24,640 --> 00:26:28,720
something like this of you know how

00:26:26,890 --> 00:26:31,270
large is that index is it really really

00:26:28,720 --> 00:26:33,730
large is it small how many times does it

00:26:31,270 --> 00:26:36,340
use if you see a zero there on index

00:26:33,730 --> 00:26:38,049
scans go ahead and drop it it's not

00:26:36,340 --> 00:26:40,740
getting any sort of value from anywhere

00:26:38,049 --> 00:26:40,740
in your application

00:26:41,490 --> 00:26:47,260
so on database migrations not null is a

00:26:45,640 --> 00:26:50,050
good thing right like if we want to have

00:26:47,260 --> 00:26:54,190
some default value we want it in a you

00:26:50,050 --> 00:26:57,340
know application except when you're

00:26:54,190 --> 00:26:59,830
running a database migration Postgres if

00:26:57,340 --> 00:27:01,870
you add a new column and add a default

00:26:59,830 --> 00:27:03,910
value is going to rewrite that entire

00:27:01,870 --> 00:27:05,800
table it's going to take it and make a

00:27:03,910 --> 00:27:07,960
copy under the covers of it right that

00:27:05,800 --> 00:27:10,120
new value out what that means is it's

00:27:07,960 --> 00:27:13,390
gonna hold a lock on it all new incoming

00:27:10,120 --> 00:27:15,160
data while it's rewriting that table and

00:27:13,390 --> 00:27:17,380
you're staging this is gonna be really

00:27:15,160 --> 00:27:20,100
fast you're gonna write things out and

00:27:17,380 --> 00:27:23,050
it's gonna take you know a few seconds

00:27:20,100 --> 00:27:25,780
even if your staging has you know a gig

00:27:23,050 --> 00:27:27,880
as the table production when you run

00:27:25,780 --> 00:27:29,800
this on a hundred table you're gonna let

00:27:27,880 --> 00:27:31,750
it start running for a few seconds a few

00:27:29,800 --> 00:27:33,760
minutes five to ten minutes and you're

00:27:31,750 --> 00:27:36,340
gonna start wondering when it's gonna

00:27:33,760 --> 00:27:37,870
complete an hour in you're gonna have

00:27:36,340 --> 00:27:39,910
people kind of over at your desk saying

00:27:37,870 --> 00:27:43,000
what's going on when are we back up

00:27:39,910 --> 00:27:46,560
we're down that sort of thing the better

00:27:43,000 --> 00:27:49,230
way to do migrations at any large scale

00:27:46,560 --> 00:27:51,820
is simply break it up to three steps

00:27:49,230 --> 00:27:54,310
first you're gonna allow Knowles and set

00:27:51,820 --> 00:27:55,690
a default value not a database level are

00:27:54,310 --> 00:27:58,330
at the database level and at the

00:27:55,690 --> 00:28:00,150
application so all new data all new

00:27:58,330 --> 00:28:02,680
updates are getting that default value

00:28:00,150 --> 00:28:05,170
you're gonna gradually come back in and

00:28:02,680 --> 00:28:09,280
backfill all the old data so all of

00:28:05,170 --> 00:28:10,690
those hundreds you know gigs of records

00:28:09,280 --> 00:28:12,430
that you have that don't have this value

00:28:10,690 --> 00:28:14,890
in there you're gonna run a background

00:28:12,430 --> 00:28:16,470
job at night updated thousand records at

00:28:14,890 --> 00:28:18,490
a time that sort of thing

00:28:16,470 --> 00:28:20,950
and then you're gonna come back in and

00:28:18,490 --> 00:28:23,980
add your constraint you can do this now

00:28:20,950 --> 00:28:25,450
you know terabyte size tables pretty

00:28:23,980 --> 00:28:28,510
much no downtime like you'll have a few

00:28:25,450 --> 00:28:30,340
seconds maybe of lock writes but overall

00:28:28,510 --> 00:28:31,630
much much safer and you won't find

00:28:30,340 --> 00:28:34,000
yourself bringing down production I

00:28:31,630 --> 00:28:35,620
think every person I've you know seen

00:28:34,000 --> 00:28:37,450
that's really used to working with small

00:28:35,620 --> 00:28:39,610
databases and then it gets bigger and

00:28:37,450 --> 00:28:41,320
bigger runs into this with the first

00:28:39,610 --> 00:28:43,900
time they worked with a a larger size

00:28:41,320 --> 00:28:45,910
database of a hundred gigs or so and

00:28:43,900 --> 00:28:50,170
it's much much more painful the large

00:28:45,910 --> 00:28:51,550
you get so be careful in this one all

00:28:50,170 --> 00:28:53,470
right so that was kind of medium scale

00:28:51,550 --> 00:28:54,130
and I would classify that somewhere from

00:28:53,470 --> 00:28:56,950
like a

00:28:54,130 --> 00:28:59,400
database with 10 gigs of data to 100

00:28:56,950 --> 00:28:59,400
gigs or so

00:29:00,780 --> 00:29:05,860
all right the larger you get you want to

00:29:04,360 --> 00:29:07,720
be a little more careful in particular

00:29:05,860 --> 00:29:09,280
the first thing you're going to want to

00:29:07,720 --> 00:29:11,320
start doing before we you said create

00:29:09,280 --> 00:29:14,230
index now you can always say create

00:29:11,320 --> 00:29:16,390
index concurrently this could not be run

00:29:14,230 --> 00:29:17,860
inside a transaction so inside like your

00:29:16,390 --> 00:29:20,770
your Gengo transactions you're gonna

00:29:17,860 --> 00:29:23,410
have to break this out sorry it's worth

00:29:20,770 --> 00:29:25,810
it created index concurrently does not

00:29:23,410 --> 00:29:28,390
hold on right lock while the index is

00:29:25,810 --> 00:29:29,920
being created technically it does at the

00:29:28,390 --> 00:29:32,110
very very end but that's for a few

00:29:29,920 --> 00:29:33,610
milliseconds what this means is you can

00:29:32,110 --> 00:29:36,970
you know instead of it doing create

00:29:33,610 --> 00:29:38,770
index and everything kind of crawling to

00:29:36,970 --> 00:29:42,100
a halt while you add an index on 100 Gig

00:29:38,770 --> 00:29:43,480
table it's gonna build up that index in

00:29:42,100 --> 00:29:45,130
the background wait for it to be almost

00:29:43,480 --> 00:29:47,110
done then take that lock then cut over

00:29:45,130 --> 00:29:49,240
to it it's roughly two to three times

00:29:47,110 --> 00:29:52,500
slower but doesn't lock writes really

00:29:49,240 --> 00:29:52,500
really key for larger databases

00:29:54,240 --> 00:30:01,810
connection pooling so sequel alchemy has

00:30:00,190 --> 00:30:04,570
connection pooling built in Django has

00:30:01,810 --> 00:30:06,400
connection pulling now built in or at

00:30:04,570 --> 00:30:08,620
least a persistent pool I would

00:30:06,400 --> 00:30:11,470
encourage you also looking at running a

00:30:08,620 --> 00:30:14,050
like a Postgres side connection puller

00:30:11,470 --> 00:30:16,690
so there's basically two ways of kind of

00:30:14,050 --> 00:30:18,070
connection pooling you can have a your

00:30:16,690 --> 00:30:19,690
application having a bunch of open

00:30:18,070 --> 00:30:21,730
connections just waiting to grab one as

00:30:19,690 --> 00:30:23,410
a new request comes in so there's some

00:30:21,730 --> 00:30:26,080
latency there and grabbing like an ssl

00:30:23,410 --> 00:30:28,510
connection to Postgres there's also the

00:30:26,080 --> 00:30:31,510
fact that Postgres doesn't handle a lot

00:30:28,510 --> 00:30:33,430
of connections very very well at a

00:30:31,510 --> 00:30:34,990
thousand connections you have a lot of

00:30:33,430 --> 00:30:37,300
contention it's consuming a lot of

00:30:34,990 --> 00:30:40,480
memory that sort of thing there's a few

00:30:37,300 --> 00:30:43,360
options here PG bouncer PG pull are the

00:30:40,480 --> 00:30:46,360
two big ones I highly highly recommend

00:30:43,360 --> 00:30:47,830
using PG bouncer PG bouncer is a

00:30:46,360 --> 00:30:49,690
connection puller that as a new

00:30:47,830 --> 00:30:52,420
transaction comes in it gives you kind

00:30:49,690 --> 00:30:54,640
of a new connection it watches for that

00:30:52,420 --> 00:30:56,650
to complete you don't have to worry

00:30:54,640 --> 00:30:58,210
about idle connections there's a query

00:30:56,650 --> 00:30:59,860
you can run to see active versus idle

00:30:58,210 --> 00:31:01,330
connections against your database I've

00:30:59,860 --> 00:31:04,480
talked to a lot of people that say hey I

00:31:01,330 --> 00:31:05,980
have 2000 active connections from my

00:31:04,480 --> 00:31:07,740
application I really really need a high

00:31:05,980 --> 00:31:09,330
connection

00:31:07,740 --> 00:31:11,669
they run this query to show how many

00:31:09,330 --> 00:31:13,890
your active humming your idle and active

00:31:11,669 --> 00:31:16,740
is like 10 that means we've got it's you

00:31:13,890 --> 00:31:18,980
know 1900 plus connections doing

00:31:16,740 --> 00:31:21,210
absolutely nothing just consuming

00:31:18,980 --> 00:31:25,679
resources not adding any sort of value

00:31:21,210 --> 00:31:27,000
PG bouncer solves this for you so

00:31:25,679 --> 00:31:28,110
scaling cash

00:31:27,000 --> 00:31:30,870
I mentioned this early on you know

00:31:28,110 --> 00:31:34,049
watching for that cash hit rate if you

00:31:30,870 --> 00:31:37,110
see a drop below 99 go get a box with

00:31:34,049 --> 00:31:39,990
bigger memory that's the easiest thing

00:31:37,110 --> 00:31:41,220
to do in terms of scaling at some level

00:31:39,990 --> 00:31:44,100
what you're gonna do is run into a brick

00:31:41,220 --> 00:31:47,070
wall like AWS only has an instant so

00:31:44,100 --> 00:31:48,720
large okay fine you're gonna leave AWS

00:31:47,070 --> 00:31:51,179
run on your own hardware because you can

00:31:48,720 --> 00:31:52,770
get a really beefy box then you're gonna

00:31:51,179 --> 00:31:56,970
look at you know hey how long does it

00:31:52,770 --> 00:31:58,350
take to rack and stack that you're still

00:31:56,970 --> 00:31:59,520
gonna run to into a limit there maybe

00:31:58,350 --> 00:32:01,470
you can get a box with a terabyte of

00:31:59,520 --> 00:32:04,039
memory but if you keep growing you're

00:32:01,470 --> 00:32:06,480
gonna run into the limits of single node

00:32:04,039 --> 00:32:09,480
the first thing that most people do is

00:32:06,480 --> 00:32:11,039
offload some Reed traffic right okay let

00:32:09,480 --> 00:32:12,600
me have a reed replica things are

00:32:11,039 --> 00:32:15,179
slightly stale by you know a few

00:32:12,600 --> 00:32:18,030
milliseconds or seconds but that's okay

00:32:15,179 --> 00:32:21,450
for these different models for

00:32:18,030 --> 00:32:24,030
replication there's a few options I

00:32:21,450 --> 00:32:27,990
would generally recommend Wally wall G

00:32:24,030 --> 00:32:30,240
or bar man Wally a colleague authored

00:32:27,990 --> 00:32:33,929
back at when we were at Heroku we used

00:32:30,240 --> 00:32:35,460
it to handle replication for around two

00:32:33,929 --> 00:32:37,740
million Postgres databases when we were

00:32:35,460 --> 00:32:40,950
there so I'm pretty sure it works at

00:32:37,740 --> 00:32:43,860
some decent scale we recently rewrote

00:32:40,950 --> 00:32:46,440
and released it as wall G to be a bit

00:32:43,860 --> 00:32:49,799
more faster and performant and go while

00:32:46,440 --> 00:32:51,600
he's in Python give either a look bar

00:32:49,799 --> 00:32:53,360
man's also a popular one so I recommend

00:32:51,600 --> 00:32:57,750
either of these if you're looking at

00:32:53,360 --> 00:32:59,820
setting up streaming replicas the other

00:32:57,750 --> 00:33:01,260
option is sharding so charting is the

00:32:59,820 --> 00:33:04,169
idea of splitting things up you know

00:33:01,260 --> 00:33:07,110
into smaller bits if you have one really

00:33:04,169 --> 00:33:08,730
really large table i usually in an

00:33:07,110 --> 00:33:11,220
application if there's one table that is

00:33:08,730 --> 00:33:13,559
like a crazy amount larger than all

00:33:11,220 --> 00:33:16,890
others it's probably called events

00:33:13,559 --> 00:33:18,929
messages or logs it may not belong in

00:33:16,890 --> 00:33:21,380
your database you can probably move it

00:33:18,929 --> 00:33:21,380
off somewhere else

00:33:21,830 --> 00:33:27,060
there are certain other data models that

00:33:24,540 --> 00:33:28,410
actually kind of fit really well I see

00:33:27,060 --> 00:33:29,790
things like you know one database per

00:33:28,410 --> 00:33:32,150
customer or when schema per customer

00:33:29,790 --> 00:33:34,350
please don't go with those two paths

00:33:32,150 --> 00:33:35,640
there you have other things now when you

00:33:34,350 --> 00:33:38,100
run a migration you have to run it

00:33:35,640 --> 00:33:40,440
across a million databases when you have

00:33:38,100 --> 00:33:42,060
ten customers this isn't a problem when

00:33:40,440 --> 00:33:44,540
you have a thousand it is

00:33:42,060 --> 00:33:46,800
I have things like a thousand schemas

00:33:44,540 --> 00:33:49,080
Postgres backups sometimes just don't

00:33:46,800 --> 00:33:53,070
work it's okay we didn't test them

00:33:49,080 --> 00:33:56,490
anyways the other option is charting

00:33:53,070 --> 00:33:59,220
within your application so sharding is

00:33:56,490 --> 00:34:00,750
definitely the really large scale option

00:33:59,220 --> 00:34:04,320
it's worked for Instagram works for

00:34:00,750 --> 00:34:06,120
Facebook Google Salesforce it used to be

00:34:04,320 --> 00:34:10,470
really really hard it's gotten a little

00:34:06,120 --> 00:34:12,810
bit easier so one option not gonna drill

00:34:10,470 --> 00:34:14,880
too deep into this I work at situs we

00:34:12,810 --> 00:34:16,320
turn Postgres into a charted database

00:34:14,880 --> 00:34:18,240
what's your application it looks like a

00:34:16,320 --> 00:34:20,550
single node so you're still talking to

00:34:18,240 --> 00:34:22,050
one node database it's a peer extension

00:34:20,550 --> 00:34:24,000
it's open source so you can download it

00:34:22,050 --> 00:34:26,820
just use it under the covers there's

00:34:24,000 --> 00:34:29,100
multiple physical instances there so

00:34:26,820 --> 00:34:30,510
still all the benefits of Postgres still

00:34:29,100 --> 00:34:33,780
your application thinks it's single node

00:34:30,510 --> 00:34:37,560
Postgres under the covers it started a

00:34:33,780 --> 00:34:41,520
lot of the principles of sharding the

00:34:37,560 --> 00:34:44,700
instagram talk from a few years ago is a

00:34:41,520 --> 00:34:46,320
great one that basically walks through

00:34:44,700 --> 00:34:48,060
the the best practices that sort of

00:34:46,320 --> 00:34:49,740
thing if you're thinking about that have

00:34:48,060 --> 00:34:56,400
questions happy to filled them

00:34:49,740 --> 00:34:59,310
afterwards backups so when you start out

00:34:56,400 --> 00:35:00,960
you're probably using PG dope that's the

00:34:59,310 --> 00:35:04,410
the one where you get kind of a sequel

00:35:00,960 --> 00:35:08,540
dump you upload it to s3 or locally it's

00:35:04,410 --> 00:35:11,490
human readable it's portable it works

00:35:08,540 --> 00:35:14,430
the other option is a what's known as a

00:35:11,490 --> 00:35:17,220
physical backup with in Postgres this is

00:35:14,430 --> 00:35:18,810
the actual bytes on disk it's a bit like

00:35:17,220 --> 00:35:21,210
operating system dependent you can't

00:35:18,810 --> 00:35:23,100
take like a Linux physical backup and

00:35:21,210 --> 00:35:24,870
restore it to Windows so it's not

00:35:23,100 --> 00:35:26,250
necessarily great for going from you

00:35:24,870 --> 00:35:27,540
know your production environment down to

00:35:26,250 --> 00:35:30,720
your local laptop because you're

00:35:27,540 --> 00:35:33,360
probably running a different OS there's

00:35:30,720 --> 00:35:36,360
some trade-offs between the two of these

00:35:33,360 --> 00:35:37,920
logical that PG dumpling is really good

00:35:36,360 --> 00:35:39,300
across architectures it's great for

00:35:37,920 --> 00:35:42,390
going from production down to a local

00:35:39,300 --> 00:35:45,120
environment it's good for portability it

00:35:42,390 --> 00:35:46,260
does have some load on the database so

00:35:45,120 --> 00:35:48,750
when you run this you're gonna see

00:35:46,260 --> 00:35:51,330
things spike in terms of load and

00:35:48,750 --> 00:35:53,400
performance it works really well less

00:35:51,330 --> 00:35:55,440
than 50 gigabytes of data when you get

00:35:53,400 --> 00:35:57,090
larger at one terabyte I don't think

00:35:55,440 --> 00:35:59,190
I've seen a PG dump successfully work

00:35:57,090 --> 00:36:01,890
you can kind of tweak it and maybe make

00:35:59,190 --> 00:36:03,300
it work it gets really really hard at

00:36:01,890 --> 00:36:05,550
some point you're just gonna have to

00:36:03,300 --> 00:36:08,070
abandon PG dump and go with physical

00:36:05,550 --> 00:36:09,930
backups physical backups have a lot less

00:36:08,070 --> 00:36:14,010
load on the database there is some load

00:36:09,930 --> 00:36:16,320
but it's far far less it scales pretty

00:36:14,010 --> 00:36:17,820
infinitely and it's what you're gonna

00:36:16,320 --> 00:36:19,710
use for things like read replicas as

00:36:17,820 --> 00:36:21,030
well that sort of thing so over time

00:36:19,710 --> 00:36:25,920
you're gonna want to shift from logical

00:36:21,030 --> 00:36:32,030
to physical backups all right that was a

00:36:25,920 --> 00:36:32,030
lot really fast so a quick recap

00:36:32,210 --> 00:36:37,500
leverage your data types

00:36:34,590 --> 00:36:39,930
I think DHH from the rails community

00:36:37,500 --> 00:36:42,390
once said like the database is just a

00:36:39,930 --> 00:36:45,030
dumb hash in the sky I think very

00:36:42,390 --> 00:36:46,560
differently like the data is where a ton

00:36:45,030 --> 00:36:47,550
of the value is like if your data is

00:36:46,560 --> 00:36:50,010
wrong in your database

00:36:47,550 --> 00:36:52,290
it doesn't matter you know that you put

00:36:50,010 --> 00:36:53,340
a pretty UI on it there's a lot of value

00:36:52,290 --> 00:36:55,230
there and you want to make sure you know

00:36:53,340 --> 00:36:56,220
you're getting the most out of your data

00:36:55,230 --> 00:36:58,700
cuz it's one of your most precious

00:36:56,220 --> 00:37:00,960
things so leverage your data types

00:36:58,700 --> 00:37:01,920
please test your backups for everyone

00:37:00,960 --> 00:37:05,130
didn't raise your hand

00:37:01,920 --> 00:37:06,600
go test them see if they work

00:37:05,130 --> 00:37:08,130
and then take it spend some time

00:37:06,600 --> 00:37:09,660
mastering your tools things like you

00:37:08,130 --> 00:37:13,470
know the data types some of the

00:37:09,660 --> 00:37:15,450
extensions and P sequel there's a lot of

00:37:13,470 --> 00:37:16,980
value in your database having a good

00:37:15,450 --> 00:37:18,930
editor that you like if you don't like P

00:37:16,980 --> 00:37:20,910
sequel go fund another one but I would

00:37:18,930 --> 00:37:24,690
say P sequel is already there and it's

00:37:20,910 --> 00:37:27,150
really handy so give it a try as you get

00:37:24,690 --> 00:37:28,980
a little bit larger make sure Postgres

00:37:27,150 --> 00:37:31,790
is well tuned you don't have to become a

00:37:28,980 --> 00:37:34,050
DBA find a consultant if you need to

00:37:31,790 --> 00:37:37,140
look at some of the blog posts or tools

00:37:34,050 --> 00:37:38,700
that are out there or other talks really

00:37:37,140 --> 00:37:40,410
don't invest time I would say in

00:37:38,700 --> 00:37:42,300
becoming a perfect expert in all the

00:37:40,410 --> 00:37:44,760
different configs there's a lot of

00:37:42,300 --> 00:37:46,260
resources out there use them watch your

00:37:44,760 --> 00:37:49,170
cache hit ratio of

00:37:46,260 --> 00:37:51,780
of anything else this is the number one

00:37:49,170 --> 00:37:54,150
thing that affect performance and then

00:37:51,780 --> 00:37:55,620
go ahead and index things there's a lot

00:37:54,150 --> 00:37:58,590
of people that when you're small you

00:37:55,620 --> 00:38:00,330
don't index anything as you get a little

00:37:58,590 --> 00:38:01,860
more you know medium sized they still

00:38:00,330 --> 00:38:03,590
don't have the indexes go ahead and just

00:38:01,860 --> 00:38:06,540
start adding them and see what happens

00:38:03,590 --> 00:38:08,520
that's the worst case if you spend a

00:38:06,540 --> 00:38:09,990
little bit more time saying hey I've got

00:38:08,520 --> 00:38:12,210
these slow queries I can index this

00:38:09,990 --> 00:38:13,590
thing that's definitely better but the

00:38:12,210 --> 00:38:14,670
worst case is just index a bunch of

00:38:13,590 --> 00:38:17,030
stuff then delete it later and see what

00:38:14,670 --> 00:38:17,030
happens

00:38:17,090 --> 00:38:23,550
IG gets that large-scale move away from

00:38:20,190 --> 00:38:25,140
PG don't set up connection pooling how

00:38:23,550 --> 00:38:28,380
many people here run a large-scale

00:38:25,140 --> 00:38:29,730
database okay a few hands how many of

00:38:28,380 --> 00:38:33,150
you run a connection polar like PG

00:38:29,730 --> 00:38:35,180
bouncer actually more hands than large

00:38:33,150 --> 00:38:36,800
database so that's really impressive

00:38:35,180 --> 00:38:39,870
well done

00:38:36,800 --> 00:38:42,330
PG bouncer is the best tool there it's

00:38:39,870 --> 00:38:44,310
not perfect but it's the best that we

00:38:42,330 --> 00:38:45,890
have and hopefully in time and core

00:38:44,310 --> 00:38:48,420
post-crisis gets better connection point

00:38:45,890 --> 00:38:50,970
and then if you need to shard invest in

00:38:48,420 --> 00:38:54,000
the right way look at the Instagram talk

00:38:50,970 --> 00:38:56,250
use a tool to help please don't go like

00:38:54,000 --> 00:38:58,050
down the one schema per customer path

00:38:56,250 --> 00:38:59,370
because you'll go down that path and

00:38:58,050 --> 00:39:01,290
lock yourself in and couple years later

00:38:59,370 --> 00:39:03,930
you'll have even more word thing you had

00:39:01,290 --> 00:39:05,760
to put in initially so and best once you

00:39:03,930 --> 00:39:06,240
get down that path and doing it the

00:39:05,760 --> 00:39:08,670
right way

00:39:06,240 --> 00:39:10,230
try not to do that try to just scale up

00:39:08,670 --> 00:39:12,300
and up and up as long as you have to

00:39:10,230 --> 00:39:17,190
though cuz you know not charting is a

00:39:12,300 --> 00:39:20,220
lot easier than charting alright I think

00:39:17,190 --> 00:39:27,300
that's it any questions

00:39:20,220 --> 00:39:30,990
[Applause]

00:39:27,300 --> 00:39:30,990
so we have

00:39:47,810 --> 00:39:52,130
I pick so I have a question about

00:39:50,360 --> 00:39:52,460
indexes because this got me read their

00:39:52,130 --> 00:39:54,440
stats

00:39:52,460 --> 00:39:56,330
I have this probability I didn't have to

00:39:54,440 --> 00:39:58,370
solve myself but I heard about this many

00:39:56,330 --> 00:40:00,440
times about X scheduling problem when

00:39:58,370 --> 00:40:04,400
you have like let's say rooms and you

00:40:00,440 --> 00:40:06,140
have like very flexible x cap and you

00:40:04,400 --> 00:40:07,880
don't want to of course to schedule two

00:40:06,140 --> 00:40:08,480
meetings in the same room yep so would

00:40:07,880 --> 00:40:12,380
you use

00:40:08,480 --> 00:40:14,210
index for this too to optimize this this

00:40:12,380 --> 00:40:17,270
so a couple of things that we do there

00:40:14,210 --> 00:40:19,970
so one are you using range types so okay

00:40:17,270 --> 00:40:21,950
so within range types now I'm slightly

00:40:19,970 --> 00:40:24,380
blanking we actually have a blog post on

00:40:21,950 --> 00:40:26,750
the situs blog about constraints the way

00:40:24,380 --> 00:40:28,130
you can have is a exclusion country so

00:40:26,750 --> 00:40:30,170
that things don't overlap I forget

00:40:28,130 --> 00:40:32,540
forget if it's related to gist or not I

00:40:30,170 --> 00:40:35,420
think it is search for exclusion

00:40:32,540 --> 00:40:37,280
constraints and range tires for

00:40:35,420 --> 00:40:39,680
calendaring scheduling like range types

00:40:37,280 --> 00:40:41,090
are a type that has a Raman of two for

00:40:39,680 --> 00:40:43,370
people not familiar so if you have like

00:40:41,090 --> 00:40:45,770
a like right now you don't want to talks

00:40:43,370 --> 00:40:48,500
going on at the same time or people you

00:40:45,770 --> 00:40:51,320
know scheduling things for registration

00:40:48,500 --> 00:40:52,820
class you can have an exclusion

00:40:51,320 --> 00:40:59,870
constraint so that things some overlap

00:40:52,820 --> 00:41:06,710
there thank you I took some notes to

00:40:59,870 --> 00:41:12,320
pass it on my DBA some debate my teen

00:41:06,710 --> 00:41:17,260
about using the Postgres but in a you

00:41:12,320 --> 00:41:17,260
know containerized Postgres

00:41:22,810 --> 00:41:28,250
it's a bit of a loaded question so there

00:41:27,020 --> 00:41:31,640
are people that run post press in

00:41:28,250 --> 00:41:35,470
containers we do for development for

00:41:31,640 --> 00:41:38,720
testing not for production personally

00:41:35,470 --> 00:41:42,880
saiful sets are getting better within

00:41:38,720 --> 00:41:46,250
kubernetes it really kind of depends

00:41:42,880 --> 00:41:48,530
there's a a conference i chair out in

00:41:46,250 --> 00:41:50,480
san francisco Postgres open we actually

00:41:48,530 --> 00:41:53,180
have some talks coming up in September

00:41:50,480 --> 00:41:55,400
on that of some places that run Postgres

00:41:53,180 --> 00:41:57,800
within kubernetes within docker stateful

00:41:55,400 --> 00:41:59,270
sets that sort of thing I would say it's

00:41:57,800 --> 00:42:00,740
still a little bit early days people are

00:41:59,270 --> 00:42:01,339
doing it so it kind of varies and

00:42:00,740 --> 00:42:15,200
depends on

00:42:01,339 --> 00:42:18,319
your risk tolerance and expertise yeah

00:42:15,200 --> 00:42:19,789
so built-in replication sill knees kind

00:42:18,319 --> 00:42:21,729
of a little bit of help to set up with

00:42:19,789 --> 00:42:24,259
like something like bar man or Wally

00:42:21,729 --> 00:42:27,229
because you need a base backup and then

00:42:24,259 --> 00:42:28,579
the the right ahead log to catch up if

00:42:27,229 --> 00:42:30,019
you're using replication I wouldn't

00:42:28,579 --> 00:42:31,729
recommend using something like slow knee

00:42:30,019 --> 00:42:34,130
or long DC which are placement for the

00:42:31,729 --> 00:42:37,039
built in so Wally and barman are more

00:42:34,130 --> 00:42:40,099
MIT to supplement and help you use the

00:42:37,039 --> 00:42:42,140
built-in streaming replication it's come

00:42:40,099 --> 00:42:45,289
a long ways it's still got a ways to go

00:42:42,140 --> 00:42:47,509
so the base one right now is like a

00:42:45,289 --> 00:42:49,910
binary format logical replication came

00:42:47,509 --> 00:42:53,749
in in ten like fully bytes we kind of

00:42:49,910 --> 00:42:55,130
got there in nine six but not quite I'm

00:42:53,749 --> 00:42:57,529
a fan of it it's getting better and

00:42:55,130 --> 00:42:59,180
better if you have like specific

00:42:57,529 --> 00:43:19,700
questions like happy to kind of drill in

00:42:59,180 --> 00:43:23,539
all flying to on it not right off that

00:43:19,700 --> 00:43:25,279
is probably the best one yeah that's

00:43:23,539 --> 00:43:26,539
probably your your best case is just

00:43:25,279 --> 00:43:41,469
creating triggers and doing every

00:43:26,539 --> 00:43:44,509
application there yeah you cytus know um

00:43:41,469 --> 00:43:52,160
so it depends on which large scale so

00:43:44,509 --> 00:43:54,440
like yeah optimize a lot of things like

00:43:52,160 --> 00:43:56,719
you're getting to a scale where depends

00:43:54,440 --> 00:43:58,729
on what size instance you're on like as

00:43:56,719 --> 00:44:01,069
you get larger and larger like we run

00:43:58,729 --> 00:44:03,109
site is cloud on top of a ws and see a

00:44:01,069 --> 00:44:05,660
lot of that scale and we have customers

00:44:03,109 --> 00:44:07,130
up to like 900 petabytes or so or sorry

00:44:05,660 --> 00:44:09,799
not any terabytes not quite petabytes

00:44:07,130 --> 00:44:12,290
uh-huh tuning differences between AG

00:44:09,799 --> 00:44:17,750
running phosphorus on AWS

00:44:12,290 --> 00:44:19,250
uh you'll get some more flexibility so

00:44:17,750 --> 00:44:21,920
like you get a little more control

00:44:19,250 --> 00:44:24,470
running it on a double yes yourself then

00:44:21,920 --> 00:44:26,060
RDS I would say RDS can scale to a

00:44:24,470 --> 00:44:28,340
terabyte I've seen up to four terabytes

00:44:26,060 --> 00:44:30,590
on RDS I haven't seen really performant

00:44:28,340 --> 00:44:32,030
ones beyond that scale at that point

00:44:30,590 --> 00:44:34,340
your options really do look to be

00:44:32,030 --> 00:44:36,230
charting of some kind to start split

00:44:34,340 --> 00:44:47,630
things up into smaller bits be able to

00:44:36,230 --> 00:44:50,660
scale things out that it's running

00:44:47,630 --> 00:44:52,190
queries over very large tables and we're

00:44:50,660 --> 00:44:54,350
having all the time.i issues with the

00:44:52,190 --> 00:44:55,670
performance and I guess that the

00:44:54,350 --> 00:44:57,140
recommendations are basically touching

00:44:55,670 --> 00:44:58,760
the index tensors

00:44:57,140 --> 00:45:01,850
check with it because we have many

00:44:58,760 --> 00:45:03,710
indexes you all have issues but also do

00:45:01,850 --> 00:45:06,770
you think that it's better than to have

00:45:03,710 --> 00:45:09,920
one read from one side and no rating a

00:45:06,770 --> 00:45:13,160
different different podcast instance uh

00:45:09,920 --> 00:45:15,140
yes but it depends so having writes got

00:45:13,160 --> 00:45:16,370
one side and then reads on the other can

00:45:15,140 --> 00:45:17,870
actually create issues around

00:45:16,370 --> 00:45:19,760
replication lag so you can create

00:45:17,870 --> 00:45:21,440
latency and make kind of that replica

00:45:19,760 --> 00:45:25,700
like not safe we're not able to catch up

00:45:21,440 --> 00:45:27,230
so in theory yes and practice some of

00:45:25,700 --> 00:45:29,150
the time some of the time I've seen it

00:45:27,230 --> 00:45:30,860
create more issues running queries

00:45:29,150 --> 00:45:32,600
against a read replica can actually

00:45:30,860 --> 00:45:34,640
create replication or create issues on

00:45:32,600 --> 00:45:35,990
the primary as well so it's not to say

00:45:34,640 --> 00:45:37,970
like oh that you have a read replica

00:45:35,990 --> 00:45:40,370
it's perfectly safe to touch so there

00:45:37,970 --> 00:45:42,080
are kind of complexities there generally

00:45:40,370 --> 00:45:43,040
that can be one option the other thing I

00:45:42,080 --> 00:45:45,800
would say is if you're running a

00:45:43,040 --> 00:45:47,360
recommendation engine the order if

00:45:45,800 --> 00:45:49,370
you're probably doing scanning a lot of

00:45:47,360 --> 00:45:50,840
data so it's probably going to disk the

00:45:49,370 --> 00:45:53,300
ordering of data on disk is really

00:45:50,840 --> 00:45:56,570
important I would look into a couple of

00:45:53,300 --> 00:45:58,820
extensions pg repack or PG reorg

00:45:56,570 --> 00:46:02,570
which actually can reorganize data on

00:45:58,820 --> 00:46:04,970
disk there they're really interesting

00:46:02,570 --> 00:46:06,350
powerful extensions they do some really

00:46:04,970 --> 00:46:07,610
awesome things they can also do some

00:46:06,350 --> 00:46:08,990
really scary things like if you misuse

00:46:07,610 --> 00:46:10,970
them they can just make the entire

00:46:08,990 --> 00:46:13,640
database unusable so proceed with

00:46:10,970 --> 00:46:14,900
caution but if you are doing a lot of

00:46:13,640 --> 00:46:17,560
like sequential scan and say could be

00:46:14,900 --> 00:46:17,560
interesting day up to

00:46:20,380 --> 00:46:26,300

YouTube URL: https://www.youtube.com/watch?v=RJ5kRaBCV78


