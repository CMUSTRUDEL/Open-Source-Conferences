Title: Elisabetta Bergamini - Bad hotel again? Find your perfect match!
Publication date: 2018-08-22
Playlist: EuroPython 2018
Description: 
	Bad hotel again? Find your perfect match!
[EuroPython 2018 - Talk - 2018-07-25 - PyCharm [PyData]]
[Edinburgh, UK]

By Elisabetta Bergamini

For most travellers, online reviews play a major role when it comes to choosing which hotel to stay in. But can we actually trust a hotel review? And if yes, how can we select which are the most meaningful and interesting for us among the billions available in platforms such as Booking.com, Tripadvisor, Facebook (just to mention a few)?
For 10 years now, at TrustYou we have built processes that analyze terabytes of hotel reviews at a global scale, and strive to understand what people complain about or like in the hotels worldwide.
Dealing with a huge amount of reviews written in tens of different languages - each having its own subtle shades of meanings - is the challenge we work on everyday. In this talk, we will show what goes on behind the scenes of the TrustYou Metareview and dive into the technologies and the algorithms that allow us to provide travellers with all the information they need to find the perfect hotel.



License: This video is licensed under the CC BY-NC-SA 3.0 license: https://creativecommons.org/licenses/by-nc-sa/3.0/
Please see our speaker release agreement for details: https://ep2018.europython.eu/en/speaker-release-agreement/
Captions: 
	00:00:03,920 --> 00:00:10,740
hello everyone today I will talk to you

00:00:07,980 --> 00:00:12,210
yeah exactly about how to what we do I

00:00:10,740 --> 00:00:14,639
trust you to make it possible for

00:00:12,210 --> 00:00:18,930
travelers all over door to find their

00:00:14,639 --> 00:00:22,350
perfect hotel so just something about

00:00:18,930 --> 00:00:25,199
myself I'm from Italy from Modena Italy

00:00:22,350 --> 00:00:27,990
I have a background in both computer

00:00:25,199 --> 00:00:28,949
science and mathematics so I both let's

00:00:27,990 --> 00:00:35,010
say you're computer science is a

00:00:28,949 --> 00:00:38,280
mathematician or maybe I then did my PhD

00:00:35,010 --> 00:00:40,379
in cars so Germany the topic of my

00:00:38,280 --> 00:00:42,329
thesis was basically development

00:00:40,379 --> 00:00:44,129
algorithms for network analysis and I

00:00:42,329 --> 00:00:45,870
defended my thesis last year in December

00:00:44,129 --> 00:00:47,879
and since February I'm now working as a

00:00:45,870 --> 00:00:50,309
data scientist that trusts you with a

00:00:47,879 --> 00:00:56,070
focus on natural language processing and

00:00:50,309 --> 00:00:58,199
algorithms and machine learning so what

00:00:56,070 --> 00:01:01,219
is it the question that major review

00:00:58,199 --> 00:01:03,239
team I trust you so the team I'm part of

00:01:01,219 --> 00:01:04,830
is working on so what is the problem

00:01:03,239 --> 00:01:07,530
where we're working on so what we're

00:01:04,830 --> 00:01:11,310
gonna do is for every hotel in the world

00:01:07,530 --> 00:01:13,500
we want to provide a summary of traveler

00:01:11,310 --> 00:01:17,549
reviews and why would we want to do this

00:01:13,500 --> 00:01:20,040
why we want to provide a summary well if

00:01:17,549 --> 00:01:23,310
I guess most of you whenever you book a

00:01:20,040 --> 00:01:25,229
hotel you first look at it and reviews

00:01:23,310 --> 00:01:27,000
from other travelers and if you think

00:01:25,229 --> 00:01:29,070
about it this is quite amazing that we

00:01:27,000 --> 00:01:31,259
can do this because maybe 20 years ago

00:01:29,070 --> 00:01:33,180
30 years ago there was no way of doing

00:01:31,259 --> 00:01:36,810
this so whenever booking hotel what

00:01:33,180 --> 00:01:40,290
people could do was basically only pick

00:01:36,810 --> 00:01:42,030
some hotel or based on yeah basic how it

00:01:40,290 --> 00:01:45,000
looks from the outside or just listening

00:01:42,030 --> 00:01:46,409
from some some recommendation from

00:01:45,000 --> 00:01:49,680
friends who had already been to that

00:01:46,409 --> 00:01:51,659
city maybe and what we have now is we

00:01:49,680 --> 00:01:53,640
basically it's like having maybe for a

00:01:51,659 --> 00:01:55,200
city we want to go to millions of

00:01:53,640 --> 00:01:57,719
friends who can tell you their

00:01:55,200 --> 00:02:00,390
experience about the hotels in that city

00:01:57,719 --> 00:02:01,530
and of course we cannot on the other

00:02:00,390 --> 00:02:03,869
hand the problem is that we cannot

00:02:01,530 --> 00:02:05,549
really read millions of reasons whenever

00:02:03,869 --> 00:02:08,280
I wanted to whenever we want to make a

00:02:05,549 --> 00:02:11,009
decision about in which hotel to go to

00:02:08,280 --> 00:02:13,610
and what most people do is they just

00:02:11,009 --> 00:02:15,380
read a few reviews go through a fury

00:02:13,610 --> 00:02:18,650
and then make their decision based on

00:02:15,380 --> 00:02:20,980
that but of course different travelers

00:02:18,650 --> 00:02:23,300
also have different expectations and

00:02:20,980 --> 00:02:26,180
they look for different things in hotels

00:02:23,300 --> 00:02:27,500
so it might be that the experience of

00:02:26,180 --> 00:02:29,870
the few reviews we read from other

00:02:27,500 --> 00:02:31,940
travelers does not really reflect our

00:02:29,870 --> 00:02:34,370
expectations in the hotel so what we

00:02:31,940 --> 00:02:36,680
want to do is basically provide a

00:02:34,370 --> 00:02:38,930
summary containing all the relevant

00:02:36,680 --> 00:02:42,140
information from all the reviews we can

00:02:38,930 --> 00:02:45,890
find for each hotel all the reviews you

00:02:42,140 --> 00:02:47,900
can find online and make it like a short

00:02:45,890 --> 00:02:50,090
summary so that people can can read it

00:02:47,900 --> 00:02:53,270
and immediately get all the important

00:02:50,090 --> 00:02:56,150
information about the hotel so these are

00:02:53,270 --> 00:02:59,690
these are a few examples of information

00:02:56,150 --> 00:03:01,459
we can show about hotel we can show we

00:02:59,690 --> 00:03:05,270
can be interested for example in how the

00:03:01,459 --> 00:03:09,440
building of the hotel is if it's modern

00:03:05,270 --> 00:03:12,250
and clean about the view that the hotel

00:03:09,440 --> 00:03:15,590
has if it's good for parting for example

00:03:12,250 --> 00:03:17,540
and for example another like we can also

00:03:15,590 --> 00:03:20,930
show information such as solar travelers

00:03:17,540 --> 00:03:27,820
complain about TVs so this is the also

00:03:20,930 --> 00:03:30,350
kind of detail we can provide and so

00:03:27,820 --> 00:03:34,190
yeah I just wanted to show how it looks

00:03:30,350 --> 00:03:39,470
from the from our website so this is

00:03:34,190 --> 00:03:41,810
basically can you see no you can't okay

00:03:39,470 --> 00:03:47,600
yeah all right now maybe I'll show it

00:03:41,810 --> 00:03:49,160
later but with this so the this

00:03:47,600 --> 00:03:53,269
information is not only provided on our

00:03:49,160 --> 00:03:54,830
website we also provide this information

00:03:53,269 --> 00:03:58,640
to other websites you probably know

00:03:54,830 --> 00:04:01,730
kayak this and you might have seen this

00:03:58,640 --> 00:04:04,070
on kayak or ADEs or kayak can can show

00:04:01,730 --> 00:04:06,380
you information about hotels for example

00:04:04,070 --> 00:04:09,769
the amenities the vibe location so this

00:04:06,380 --> 00:04:15,530
information is all data we provide to to

00:04:09,769 --> 00:04:18,400
kayak and and not only kayak but also

00:04:15,530 --> 00:04:22,760
Google so whenever you google for hotel

00:04:18,400 --> 00:04:24,979
you see basically you might have seen

00:04:22,760 --> 00:04:27,110
this already on Google so this is also

00:04:24,979 --> 00:04:29,419
data we provide for example here we

00:04:27,110 --> 00:04:35,300
show the score given by different types

00:04:29,419 --> 00:04:37,280
of travelers and and also this is shown

00:04:35,300 --> 00:04:40,159
by Google is also data we provide and

00:04:37,280 --> 00:04:43,550
it's a kind of a shorter version of our

00:04:40,159 --> 00:04:47,449
major review so basically what we show

00:04:43,550 --> 00:04:50,060
here is yeah like a summary for example

00:04:47,449 --> 00:04:53,210
of the rooms guess like the rooms and

00:04:50,060 --> 00:04:55,310
for example they notice that maintenance

00:04:53,210 --> 00:04:57,379
could be improved these are examples or

00:04:55,310 --> 00:05:03,620
information about the location service

00:04:57,379 --> 00:05:06,770
and this are a few examples basically so

00:05:03,620 --> 00:05:10,990
how do we actually get to the to the MIT

00:05:06,770 --> 00:05:14,389
review how do we build our meter review

00:05:10,990 --> 00:05:16,729
every week we crawl reviews from many

00:05:14,389 --> 00:05:19,009
different sources on the Internet we

00:05:16,729 --> 00:05:21,979
have in our database about six hundred

00:05:19,009 --> 00:05:24,289
and twenty thousand hotels and we crawl

00:05:21,979 --> 00:05:26,990
quite a lot of reviews about on average

00:05:24,289 --> 00:05:29,479
3 millions new reviews per week that's

00:05:26,990 --> 00:05:33,409
quite a lot of data we have and we store

00:05:29,479 --> 00:05:37,580
this data in Hadoop cluster and the

00:05:33,409 --> 00:05:40,009
first step that we do basically on

00:05:37,580 --> 00:05:43,400
analyzing this data is the semantic

00:05:40,009 --> 00:05:47,300
analysis of it so basically for each

00:05:43,400 --> 00:05:50,539
review we for each sentence in its

00:05:47,300 --> 00:05:52,599
review we extract we map each part of

00:05:50,539 --> 00:05:55,219
the sentence to categories for example

00:05:52,599 --> 00:05:56,539
this part of the sentence refers to the

00:05:55,219 --> 00:05:59,870
bathroom or this other part of the

00:05:56,539 --> 00:06:03,319
sentence refers to the breakfast of the

00:05:59,870 --> 00:06:05,990
hotel any addition to categorizing these

00:06:03,319 --> 00:06:08,150
parts of the sentences we also compute

00:06:05,990 --> 00:06:10,759
the sentence we compute a sentiment for

00:06:08,150 --> 00:06:13,550
them so what's the sentence positive was

00:06:10,759 --> 00:06:16,159
it negative and after this part we

00:06:13,550 --> 00:06:18,560
basically aggregate this data and we

00:06:16,159 --> 00:06:22,759
apply machine learning algorithms to

00:06:18,560 --> 00:06:25,550
them and in the end we we generate the

00:06:22,759 --> 00:06:28,550
text that you saw before and we provide

00:06:25,550 --> 00:06:32,509
this text we showed this tax on our

00:06:28,550 --> 00:06:35,240
website but we also provide it to Google

00:06:32,509 --> 00:06:38,930
kayak and they're actually more

00:06:35,240 --> 00:06:41,660
hotels.com holiday check to several

00:06:38,930 --> 00:06:43,889
other websites

00:06:41,660 --> 00:06:46,710
so this is just to give you an overview

00:06:43,889 --> 00:06:50,759
of the technologies we use to build a

00:06:46,710 --> 00:06:52,199
metal review of course Python so almost

00:06:50,759 --> 00:06:53,820
all of the code we write is written in

00:06:52,199 --> 00:06:58,139
Python that's why we're I'm presenting

00:06:53,820 --> 00:07:02,250
this here and we use Luigi for pipelines

00:06:58,139 --> 00:07:06,479
we use a dupe and spark for processing

00:07:02,250 --> 00:07:07,860
the large amount of data we have and we

00:07:06,479 --> 00:07:10,560
use yeah

00:07:07,860 --> 00:07:12,720
post query MongoDB as databases and then

00:07:10,560 --> 00:07:14,910
we what you see on the right basically

00:07:12,720 --> 00:07:17,310
are all the some of the libraries we use

00:07:14,910 --> 00:07:23,550
for machine learning just to give you an

00:07:17,310 --> 00:07:25,740
overview okay now there I gave you

00:07:23,550 --> 00:07:28,169
basically an overview of what we do a

00:07:25,740 --> 00:07:29,490
trust you and my tea review team does I

00:07:28,169 --> 00:07:31,650
would like to talk to you about a

00:07:29,490 --> 00:07:34,500
specific problem that my team has been

00:07:31,650 --> 00:07:36,419
working on in the in the last month's

00:07:34,500 --> 00:07:40,139
and specifically its hotel

00:07:36,419 --> 00:07:41,849
classification so the question the

00:07:40,139 --> 00:07:44,009
questions we are trying to answer here

00:07:41,849 --> 00:07:46,199
are for example what are the most

00:07:44,009 --> 00:07:49,710
romantic hotels in town say you might

00:07:46,199 --> 00:07:51,330
want to go to a very romantic hotel to

00:07:49,710 --> 00:07:53,360
America romantic weekend and you're

00:07:51,330 --> 00:07:56,669
looking for the best hotel for this or

00:07:53,360 --> 00:07:59,039
you are looking for a hotel there is

00:07:56,669 --> 00:08:00,900
appropriate for a family holiday or here

00:07:59,039 --> 00:08:03,830
are some more examples for example we

00:08:00,900 --> 00:08:07,190
shot up the best casinos best Lakeview

00:08:03,830 --> 00:08:11,460
are the best ones if you want to go to a

00:08:07,190 --> 00:08:13,470
golf course for example or mmm yeah

00:08:11,460 --> 00:08:15,750
or the best Seaview I mean there are

00:08:13,470 --> 00:08:20,400
many many questions we we can consider

00:08:15,750 --> 00:08:23,759
and our solution of to this problem is

00:08:20,400 --> 00:08:26,570
basically composed of these parts that

00:08:23,759 --> 00:08:29,400
I'm going to describe so first of all we

00:08:26,570 --> 00:08:31,500
basically you represent the reviews as

00:08:29,400 --> 00:08:33,479
vectors that's the first part we need to

00:08:31,500 --> 00:08:35,279
do in order to get and able to apply

00:08:33,479 --> 00:08:37,680
machine learning algorithms to them for

00:08:35,279 --> 00:08:42,479
classification and in particular we

00:08:37,680 --> 00:08:44,490
consider two ways of representing text

00:08:42,479 --> 00:08:46,800
representing reviews as factors one is

00:08:44,490 --> 00:08:49,920
tf-idf which I'm going to present soon

00:08:46,800 --> 00:08:51,810
and the other one is dr. vacuum bad

00:08:49,920 --> 00:08:54,000
links I'm also going to tell you a

00:08:51,810 --> 00:08:55,950
little bit about them and

00:08:54,000 --> 00:08:58,440
third is basically as I said we apply

00:08:55,950 --> 00:09:02,010
machine learning algorithms and another

00:08:58,440 --> 00:09:03,930
thing we do is we also combine basically

00:09:02,010 --> 00:09:05,970
the review content with geographical

00:09:03,930 --> 00:09:07,590
data whenever it applies whenever it

00:09:05,970 --> 00:09:11,430
makes sense to improve our

00:09:07,590 --> 00:09:13,560
classifications so now I'm going to talk

00:09:11,430 --> 00:09:15,930
to you about tf-idf this is the only

00:09:13,560 --> 00:09:17,790
slide with formulas don't be scared I'm

00:09:15,930 --> 00:09:19,350
going to then make an example to give

00:09:17,790 --> 00:09:20,730
you an example it's actually quite a

00:09:19,350 --> 00:09:23,610
simple method

00:09:20,730 --> 00:09:25,740
the idea behind tf-idf which stands for

00:09:23,610 --> 00:09:29,010
term frequency inverse document

00:09:25,740 --> 00:09:31,560
frequency is to reflect reflect the

00:09:29,010 --> 00:09:33,990
importance of a term which we call T for

00:09:31,560 --> 00:09:37,680
a document D in a corpus okay a

00:09:33,990 --> 00:09:39,420
collection of other documents so we can

00:09:37,680 --> 00:09:42,900
introduce the term frequency which is

00:09:39,420 --> 00:09:45,540
basically simply for term T in document

00:09:42,900 --> 00:09:48,090
D the number of occurrences of T in D

00:09:45,540 --> 00:09:54,720
divided by the total number of words in

00:09:48,090 --> 00:09:57,630
D and we might then assume that a term

00:09:54,720 --> 00:09:59,400
is important for the document if it's

00:09:57,630 --> 00:10:00,990
frequency is high right we would say

00:09:59,400 --> 00:10:02,760
okay if a term appears very often in

00:10:00,990 --> 00:10:06,450
document and it should be quite

00:10:02,760 --> 00:10:08,220
important but this is not always the

00:10:06,450 --> 00:10:10,380
case because for example if we consider

00:10:08,220 --> 00:10:12,360
hotel reviews when we might have that

00:10:10,380 --> 00:10:14,100
words such as hotel they're going to

00:10:12,360 --> 00:10:16,760
appear very often in review so it might

00:10:14,100 --> 00:10:21,150
not be so relevant for the specific

00:10:16,760 --> 00:10:24,180
review we are considering and so

00:10:21,150 --> 00:10:26,820
basically there's another term called

00:10:24,180 --> 00:10:31,620
inverse document frequency which gives a

00:10:26,820 --> 00:10:32,910
higher score to words to terms that do

00:10:31,620 --> 00:10:34,589
not appear very often in the other

00:10:32,910 --> 00:10:36,330
documents of the corpus so are more

00:10:34,589 --> 00:10:39,420
specific for the document we are

00:10:36,330 --> 00:10:40,980
considering and this is simply defined

00:10:39,420 --> 00:10:42,300
as the logarithm of n which is the

00:10:40,980 --> 00:10:45,750
number of documents in our corpus

00:10:42,300 --> 00:10:50,220
divided by the number of documents in

00:10:45,750 --> 00:10:52,110
which the term T appears so yeah this

00:10:50,220 --> 00:10:54,480
will be high if the term doesn't appear

00:10:52,110 --> 00:10:57,570
in appears only in a few documents and

00:10:54,480 --> 00:10:59,280
in the end the tf-idf score is simply

00:10:57,570 --> 00:11:01,440
computed as the product of the term

00:10:59,280 --> 00:11:04,230
frequency and universe document

00:11:01,440 --> 00:11:05,940
frequency so to give you an example

00:11:04,230 --> 00:11:07,740
let's say we have a document and this

00:11:05,940 --> 00:11:10,380
document is I hope this talk is not

00:11:07,740 --> 00:11:12,360
boring and the core piece we have is

00:11:10,380 --> 00:11:14,700
composed of I hope this talk is not too

00:11:12,360 --> 00:11:17,010
boring this talk is just as boring as

00:11:14,700 --> 00:11:21,360
filing tax returns and tax returns are

00:11:17,010 --> 00:11:23,780
not that boring so let's say we want to

00:11:21,360 --> 00:11:27,900
compute the tf-idf score of boring and

00:11:23,780 --> 00:11:30,480
okay the term frequency is simply 1/8

00:11:27,900 --> 00:11:33,120
right because there are 8 words in our

00:11:30,480 --> 00:11:37,350
document and boring appears only once so

00:11:33,120 --> 00:11:39,630
that's why we had wine 1/8 but the

00:11:37,350 --> 00:11:41,700
inverse document frequency in this case

00:11:39,630 --> 00:11:43,970
it's the logarithm of 3 because we have

00:11:41,700 --> 00:11:46,620
three documents divided by 3 because

00:11:43,970 --> 00:11:48,690
boring appears in all of them so the

00:11:46,620 --> 00:11:50,730
logarithm 1 is zero so what we have in

00:11:48,690 --> 00:11:53,130
the end is that the tf-idf score of

00:11:50,730 --> 00:11:54,210
boring is also zero okay and this makes

00:11:53,130 --> 00:11:56,550
sense if you think about it because

00:11:54,210 --> 00:11:58,350
boring is not specific for for

00:11:56,550 --> 00:12:01,380
documenting right it appears everywhere

00:11:58,350 --> 00:12:03,330
and if we go see their hope inside we

00:12:01,380 --> 00:12:06,930
have that the term frequency it's just

00:12:03,330 --> 00:12:10,370
the same as for document D as for sorry

00:12:06,930 --> 00:12:12,720
for boring it was appears 1 once and

00:12:10,370 --> 00:12:15,960
bear in this case the inverse document

00:12:12,720 --> 00:12:18,480
frequency is higher because hope appears

00:12:15,960 --> 00:12:20,460
only in this specific document right so

00:12:18,480 --> 00:12:23,190
in this case we have the logarithm of 3

00:12:20,460 --> 00:12:25,580
divided by 1 so in the end we also have

00:12:23,190 --> 00:12:28,790
that this the tf-idf score is higher

00:12:25,580 --> 00:12:32,670
okay now you might be asking yourself

00:12:28,790 --> 00:12:35,520
why do we want to compute the tf-idf

00:12:32,670 --> 00:12:38,160
score of of terms in a document the idea

00:12:35,520 --> 00:12:41,520
is that if we compute the tf-idf score

00:12:38,160 --> 00:12:45,120
for each term we have in the corpus then

00:12:41,520 --> 00:12:47,850
we can represent each document as a

00:12:45,120 --> 00:12:50,100
vector of the tf-idf scores of the terms

00:12:47,850 --> 00:12:52,260
there are present in the corpus so to

00:12:50,100 --> 00:12:55,560
give you an exact to consider the same

00:12:52,260 --> 00:12:56,820
example as before for document D I hope

00:12:55,560 --> 00:12:59,220
this talk is not too worrying we have

00:12:56,820 --> 00:13:03,150
that we can represent it as this vector

00:12:59,220 --> 00:13:06,150
that you see here so you see that a lot

00:13:03,150 --> 00:13:08,100
of in this case a lot of terms of zero

00:13:06,150 --> 00:13:10,560
score for boring we saw it before

00:13:08,100 --> 00:13:12,150
already and for the other terms on on

00:13:10,560 --> 00:13:13,530
the right it's basically because they do

00:13:12,150 --> 00:13:16,100
not appear right they are in the other

00:13:13,530 --> 00:13:19,620
documents of the corpus but not in D so

00:13:16,100 --> 00:13:23,630
their term frequency is zero

00:13:19,620 --> 00:13:27,530
okay and the idea behind this is that

00:13:23,630 --> 00:13:30,600
the tf-idf vectors of similar documents

00:13:27,530 --> 00:13:34,710
will also be similar to each other okay

00:13:30,600 --> 00:13:36,570
so if you consider for example say you

00:13:34,710 --> 00:13:39,180
have a document you have a corp is

00:13:36,570 --> 00:13:41,880
composed of recipes of different foods

00:13:39,180 --> 00:13:43,830
and you consider tf-idf scores of two

00:13:41,880 --> 00:13:47,190
chocolate cake recipes for example

00:13:43,830 --> 00:13:49,140
you'll have that there tf-idf scores the

00:13:47,190 --> 00:13:51,090
IDF idea factors will be close to each

00:13:49,140 --> 00:13:53,550
other we can use words such as chocolate

00:13:51,090 --> 00:13:55,620
butter or whatever other ingredients are

00:13:53,550 --> 00:13:59,460
in a chocolate cake they will have a

00:13:55,620 --> 00:14:02,520
very high tf-idf scores for both recipes

00:13:59,460 --> 00:14:04,770
and yeah in our case of course we're

00:14:02,520 --> 00:14:07,110
talking about trivia so each document is

00:14:04,770 --> 00:14:09,630
this the set of all reviews for a

00:14:07,110 --> 00:14:11,760
certain hotel basically and the idea is

00:14:09,630 --> 00:14:14,670
that if we have a training set so a set

00:14:11,760 --> 00:14:15,810
of hotels for which we know that they

00:14:14,670 --> 00:14:18,870
are of a certain category for example

00:14:15,810 --> 00:14:21,090
family hotels then we can use machine

00:14:18,870 --> 00:14:22,830
learning algorithms to classify also

00:14:21,090 --> 00:14:24,630
other hotels and being able to say

00:14:22,830 --> 00:14:30,090
whether they are also family hotels or

00:14:24,630 --> 00:14:32,100
not yeah so creating training sets is

00:14:30,090 --> 00:14:35,520
quite important so we actually spent

00:14:32,100 --> 00:14:37,110
quite some time on this because if you

00:14:35,520 --> 00:14:40,620
don't really have reliable training sets

00:14:37,110 --> 00:14:43,980
then you can be pretty shorter your also

00:14:40,620 --> 00:14:46,950
your algorithm won't work well so we

00:14:43,980 --> 00:14:48,780
build them based on review content we

00:14:46,950 --> 00:14:51,690
also consider the amenities that this

00:14:48,780 --> 00:14:54,120
hotels had and when it made sense we

00:14:51,690 --> 00:14:55,890
also use geographical information for

00:14:54,120 --> 00:14:57,810
this we use Open Street Map which is

00:14:55,890 --> 00:15:00,360
actually quite quite an amazing project

00:14:57,810 --> 00:15:03,330
it contains geographical information for

00:15:00,360 --> 00:15:06,090
for many many categories so for us it

00:15:03,330 --> 00:15:07,260
was actually very very helpful examples

00:15:06,090 --> 00:15:09,780
of information it contains or

00:15:07,260 --> 00:15:11,520
coordinates of coastlines highways we

00:15:09,780 --> 00:15:13,200
are ski leaves all kinds of tourist

00:15:11,520 --> 00:15:16,310
attractions but also golf courses

00:15:13,200 --> 00:15:19,860
casinos really a lot of information and

00:15:16,310 --> 00:15:22,850
I will also now tell you something now

00:15:19,860 --> 00:15:25,620
about word to back which is also another

00:15:22,850 --> 00:15:27,960
yeah we and let's say the baseline for

00:15:25,620 --> 00:15:30,900
another technique we used and the idea

00:15:27,960 --> 00:15:32,550
here is quite different from tf-idf

00:15:30,900 --> 00:15:36,790
so the idea here is

00:15:32,550 --> 00:15:38,290
we say that words are similar when they

00:15:36,790 --> 00:15:40,269
appear in similar context so we also

00:15:38,290 --> 00:15:42,910
take the context of words into account

00:15:40,269 --> 00:15:45,100
and not to say frequency and what is the

00:15:42,910 --> 00:15:46,689
context of a word for example if you

00:15:45,100 --> 00:15:49,269
consider the sentence here the context

00:15:46,689 --> 00:15:51,610
of Fox is the set of words are

00:15:49,269 --> 00:15:52,779
proceeding then and succeeding Fox so

00:15:51,610 --> 00:15:56,829
for example in this case we have a

00:15:52,779 --> 00:16:00,910
window of two and therefore quick brown

00:15:56,829 --> 00:16:04,389
and jumps over are the context of Fox

00:16:00,910 --> 00:16:07,059
and the basic idea here is that synonyms

00:16:04,389 --> 00:16:10,269
like intelligent and smart for example

00:16:07,059 --> 00:16:14,430
they will appear in similar context

00:16:10,269 --> 00:16:17,980
right and yeah so the basic idea to

00:16:14,430 --> 00:16:20,050
create a word to back model is to train

00:16:17,980 --> 00:16:22,809
a neural network with a with the word

00:16:20,050 --> 00:16:24,220
we're considering and then the hidden

00:16:22,809 --> 00:16:27,040
layer of this neural network will be

00:16:24,220 --> 00:16:28,509
used to represent and the word as a

00:16:27,040 --> 00:16:30,910
vector because it that's in the end what

00:16:28,509 --> 00:16:33,730
we want to do right representing words

00:16:30,910 --> 00:16:35,319
as vectors and yeah so we'll have that

00:16:33,730 --> 00:16:37,750
words with similar context in the end

00:16:35,319 --> 00:16:40,600
will result in similar vectors so this

00:16:37,750 --> 00:16:42,279
is a quite famous plot you might have

00:16:40,600 --> 00:16:44,170
seen it already actually on the website

00:16:42,279 --> 00:16:45,699
where I found it it mentioned that it's

00:16:44,170 --> 00:16:48,959
illegal to talk about worth two back

00:16:45,699 --> 00:16:51,459
without showing it so here's a plot and

00:16:48,959 --> 00:16:53,290
so what you can see here is quite nice

00:16:51,459 --> 00:16:55,990
is that basically were to back

00:16:53,290 --> 00:16:59,819
encapsulate relations between words and

00:16:55,990 --> 00:17:03,730
in particular we have that for example

00:16:59,819 --> 00:17:06,939
the distance between between similar

00:17:03,730 --> 00:17:09,220
words is also pairs of Sigma was also

00:17:06,939 --> 00:17:11,020
the same so the distance between king

00:17:09,220 --> 00:17:12,970
and queen for example is the same as the

00:17:11,020 --> 00:17:15,270
distance between man and woman and we

00:17:12,970 --> 00:17:19,600
can write this this nice equation that

00:17:15,270 --> 00:17:21,939
basically King - oh yeah it's King -

00:17:19,600 --> 00:17:24,370
actually won't have it here King - man

00:17:21,939 --> 00:17:27,149
plus woman is equal to Queen which

00:17:24,370 --> 00:17:30,010
actually actually makes sense

00:17:27,149 --> 00:17:31,630
yeah and in the end we don't want to

00:17:30,010 --> 00:17:33,370
just represent words as vectors we want

00:17:31,630 --> 00:17:36,429
to represent it is right so documents

00:17:33,370 --> 00:17:39,940
and what we use is if we talk to vac

00:17:36,429 --> 00:17:42,190
which combines let's say vectors of all

00:17:39,940 --> 00:17:45,150
words there are in a document into one

00:17:42,190 --> 00:17:47,580
final vector let's see

00:17:45,150 --> 00:17:50,390
okay so to give you an idea then of our

00:17:47,580 --> 00:17:52,680
how our classification pipeline works

00:17:50,390 --> 00:17:54,630
the first thing as I said we want to

00:17:52,680 --> 00:17:57,240
transform right reviews into vectors so

00:17:54,630 --> 00:17:59,730
we do this with our GF idea for doctor

00:17:57,240 --> 00:18:01,470
vacuum bandings and we since we have

00:17:59,730 --> 00:18:06,260
reviews in many different languages we

00:18:01,470 --> 00:18:08,640
do this separately for each language and

00:18:06,260 --> 00:18:10,440
then again separately for each language

00:18:08,640 --> 00:18:12,120
we use a classifier called

00:18:10,440 --> 00:18:13,470
gradient boosting I'm not going to talk

00:18:12,120 --> 00:18:16,680
about it now because we don't really

00:18:13,470 --> 00:18:18,840
have enough time for that but it's

00:18:16,680 --> 00:18:21,150
basically an example of decision trees

00:18:18,840 --> 00:18:23,610
you can take a look at the Wikipedia

00:18:21,150 --> 00:18:27,120
article or you there are many resources

00:18:23,610 --> 00:18:29,809
online and basically in the end what we

00:18:27,120 --> 00:18:32,220
do is we combine the predictions of the

00:18:29,809 --> 00:18:35,700
classifiers for each language into one

00:18:32,220 --> 00:18:37,650
final classifier giving weights based on

00:18:35,700 --> 00:18:39,120
the number of reviews we have in two

00:18:37,650 --> 00:18:42,150
different languages so basically for a

00:18:39,120 --> 00:18:44,520
hotel we have 90% of reviews written in

00:18:42,150 --> 00:18:47,160
German and only a few reviews in Italian

00:18:44,520 --> 00:18:50,090
then we'll give a higher way to to the

00:18:47,160 --> 00:18:52,440
German review to the German classifier

00:18:50,090 --> 00:18:54,870
all right sounds like everything should

00:18:52,440 --> 00:18:57,480
work fine right it doesn't make sense

00:18:54,870 --> 00:19:00,059
yeah it did work it does work quite well

00:18:57,480 --> 00:19:02,190
in most cases but now just I would just

00:19:00,059 --> 00:19:05,670
like to tell you a few examples where we

00:19:02,190 --> 00:19:09,540
a few problematic cases we have they're

00:19:05,670 --> 00:19:11,100
also kind of funny so one problem we had

00:19:09,540 --> 00:19:14,970
is that when we were classifying golf

00:19:11,100 --> 00:19:19,050
hotels we basically realized that some

00:19:14,970 --> 00:19:21,150
hotels that were actually not close to

00:19:19,050 --> 00:19:22,890
any golf course they they got positively

00:19:21,150 --> 00:19:25,080
classified and actually what was

00:19:22,890 --> 00:19:26,880
actually quite weird was that only the

00:19:25,080 --> 00:19:28,470
German classifier so the classifier for

00:19:26,880 --> 00:19:31,800
the German language was really confident

00:19:28,470 --> 00:19:33,420
about these hotels being golf hotels but

00:19:31,800 --> 00:19:35,610
for the other languages this was not the

00:19:33,420 --> 00:19:38,400
case so we were really confused what was

00:19:35,610 --> 00:19:42,690
happening and why only Germans were

00:19:38,400 --> 00:19:45,660
talking about a golf course and know

00:19:42,690 --> 00:19:48,540
what what then we realized is that the

00:19:45,660 --> 00:19:51,660
English word golf is actually golf in

00:19:48,540 --> 00:19:53,850
German so basically the reviews were

00:19:51,660 --> 00:19:55,080
were referring to the Gulf of Naples so

00:19:53,850 --> 00:19:58,080
they were not really view into a golf

00:19:55,080 --> 00:19:58,860
course but still they there were a lot

00:19:58,080 --> 00:20:03,059
of mentions of

00:19:58,860 --> 00:20:06,240
of the world god of course and another

00:20:03,059 --> 00:20:08,790
problem we had is that basically in a

00:20:06,240 --> 00:20:11,760
small town outside Atlantic City there

00:20:08,790 --> 00:20:13,080
were a lot of mentions of casino related

00:20:11,760 --> 00:20:16,200
turns actually a lot of positive

00:20:13,080 --> 00:20:18,510
mentions and although there was no

00:20:16,200 --> 00:20:21,480
casino close to these two these hotels

00:20:18,510 --> 00:20:24,179
so we were a bit confused and basically

00:20:21,480 --> 00:20:26,580
turned out that in fact in these sounds

00:20:24,179 --> 00:20:28,230
there are a bit far from from Atlantic

00:20:26,580 --> 00:20:30,660
City people were really happy about

00:20:28,230 --> 00:20:32,910
being far away from casinos like to be

00:20:30,660 --> 00:20:36,620
in a quiet place and that's why they had

00:20:32,910 --> 00:20:41,700
all these positive mentions of casino

00:20:36,620 --> 00:20:45,030
yeah so basically the solutions we had

00:20:41,700 --> 00:20:48,000
these are of course quite complicated

00:20:45,030 --> 00:20:49,200
problems so but with the solutions we

00:20:48,000 --> 00:20:51,720
found so there's still room for

00:20:49,200 --> 00:20:53,460
improvement of course but the solutions

00:20:51,720 --> 00:20:55,530
we found so far is basically to also use

00:20:53,460 --> 00:20:57,000
Geographic data this also had quite a

00:20:55,530 --> 00:21:02,130
lot for example with problems such as

00:20:57,000 --> 00:21:03,360
yeah casinos golf courses so we could

00:21:02,130 --> 00:21:06,360
also use this information to make sure

00:21:03,360 --> 00:21:09,120
that we don't classify hotels there are

00:21:06,360 --> 00:21:12,840
not close to the amenity we are

00:21:09,120 --> 00:21:14,730
considering and in addition to this we

00:21:12,840 --> 00:21:16,590
we also perform quite an extensive cross

00:21:14,730 --> 00:21:19,260
validation or to be sure that we pick

00:21:16,590 --> 00:21:22,850
parameters that can guarantee as a high

00:21:19,260 --> 00:21:25,500
precision and then ideas for future work

00:21:22,850 --> 00:21:29,760
we could consider actually these

00:21:25,500 --> 00:21:32,070
integration techniques and so it is

00:21:29,760 --> 00:21:33,990
actually an idea that Colleen gave me

00:21:32,070 --> 00:21:36,900
quite recently so this is something we

00:21:33,990 --> 00:21:39,570
might look into and also we could think

00:21:36,900 --> 00:21:40,919
of combining tf-idf with word embeddings

00:21:39,570 --> 00:21:42,990
because what we are doing right now is

00:21:40,919 --> 00:21:44,640
four different categories we are just

00:21:42,990 --> 00:21:48,210
picking the one that works best between

00:21:44,640 --> 00:21:50,549
tf-idf and and dock to vacuum bad things

00:21:48,210 --> 00:21:52,200
but basically there are also ways of

00:21:50,549 --> 00:21:57,480
combining both so this might lead to

00:21:52,200 --> 00:22:01,770
even better results so this is basically

00:21:57,480 --> 00:22:03,330
what I wanted to present you if you have

00:22:01,770 --> 00:22:05,070
any questions feel free to ask or you

00:22:03,330 --> 00:22:07,410
can also contact me this is my email

00:22:05,070 --> 00:22:10,910
address and you can also feel free to

00:22:07,410 --> 00:22:12,680
take a look at our website so

00:22:10,910 --> 00:22:14,810
basically there you can find a little

00:22:12,680 --> 00:22:16,820
bit about what the engineering

00:22:14,810 --> 00:22:18,740
department I trust you is doing also

00:22:16,820 --> 00:22:21,140
something about job openings if you're

00:22:18,740 --> 00:23:05,660
interested and yeah that's basically

00:22:21,140 --> 00:23:07,820
what I'm going to tell you thank you -

00:23:05,660 --> 00:23:11,330
for the nice talk do you have any

00:23:07,820 --> 00:23:17,060
intuition and when tf-idf works best and

00:23:11,330 --> 00:23:19,970
when dr. Beck works well what do we yeah

00:23:17,060 --> 00:23:23,600
okay so my intuition and something there

00:23:19,970 --> 00:23:25,280
has been shown in practice is that dr.

00:23:23,600 --> 00:23:29,210
vac doesn't work very well when your

00:23:25,280 --> 00:23:31,220
document is short so it's in those cases

00:23:29,210 --> 00:23:36,860
it might be the case that tf-idf is

00:23:31,220 --> 00:23:39,970
working better yeah this is basically it

00:23:36,860 --> 00:23:42,890
this is something we still have to

00:23:39,970 --> 00:23:44,950
investigate a bit more though so

00:23:42,890 --> 00:23:47,090
basically what we today is mostly

00:23:44,950 --> 00:23:49,100
comparing the two methods and seeing

00:23:47,090 --> 00:23:51,770
which one was performing best but yeah

00:23:49,100 --> 00:23:53,600
this is also maybe something we can

00:23:51,770 --> 00:23:56,150
investigate a bit more like why exactly

00:23:53,600 --> 00:23:57,770
this is happening but this is quite this

00:23:56,150 --> 00:23:59,780
is certainly one of the reasons so the

00:23:57,770 --> 00:24:03,580
length of the document is influences

00:23:59,780 --> 00:24:03,580
this quite a bit and yeah

00:24:06,580 --> 00:24:11,110
I first of all thank you I think it was

00:24:08,470 --> 00:24:15,340
a great talk and I was wondering where

00:24:11,110 --> 00:24:17,769
you considered that maybe many of those

00:24:15,340 --> 00:24:21,970
reviews might be fake and whether that's

00:24:17,769 --> 00:24:24,279
a problem that you need to tackle yeah

00:24:21,970 --> 00:24:26,649
this is actually a very good question so

00:24:24,279 --> 00:24:28,870
one thing is in general a trustee we're

00:24:26,649 --> 00:24:31,240
only considering reviews from verified

00:24:28,870 --> 00:24:33,640
sources so for example only reviews from

00:24:31,240 --> 00:24:35,440
booking.com where you can know for sure

00:24:33,640 --> 00:24:37,809
that one can post a review only if it

00:24:35,440 --> 00:24:43,120
this person has already has release a to

00:24:37,809 --> 00:24:45,490
the hotel or Google we also use reviews

00:24:43,120 --> 00:24:47,320
from Google so we don't really use

00:24:45,490 --> 00:24:50,070
Google's from sources from which there's

00:24:47,320 --> 00:24:54,370
no way of really identifying the person

00:24:50,070 --> 00:24:56,740
but apart from this whether person

00:24:54,370 --> 00:24:58,799
whether didn't use is fake or not

00:24:56,740 --> 00:25:02,710
whether sorry the reviews is fake or not

00:24:58,799 --> 00:25:05,320
this is not something we're checking yet

00:25:02,710 --> 00:25:08,080
but this is something we talked about so

00:25:05,320 --> 00:25:10,720
there's it might be that in the future

00:25:08,080 --> 00:25:12,899
we certainly plan to consider this as

00:25:10,720 --> 00:25:12,899
well

00:25:29,040 --> 00:25:32,370
thanks for your talk

00:25:30,700 --> 00:25:34,360
it was really good do you have any

00:25:32,370 --> 00:25:37,990
recommendations for tools for labeling

00:25:34,360 --> 00:25:39,480
data i struggle from label it for

00:25:37,990 --> 00:25:41,380
labeling data do you have any

00:25:39,480 --> 00:25:43,360
recommendations for tools or

00:25:41,380 --> 00:25:45,010
applications that help with that okay

00:25:43,360 --> 00:25:47,710
what do you mean exactly like labeling

00:25:45,010 --> 00:25:51,520
say yes so say you've got web pages and

00:25:47,710 --> 00:25:53,710
you want to label the data you find on

00:25:51,520 --> 00:26:02,980
the HTML do you have any tools that help

00:25:53,710 --> 00:26:04,450
with help with that yes so for building

00:26:02,980 --> 00:26:08,440
a for building a training data set

00:26:04,450 --> 00:26:09,940
you've got some review start labeling

00:26:08,440 --> 00:26:14,260
that and you've got lots of them to do

00:26:09,940 --> 00:26:16,030
right so yeah sure yeah any tools we

00:26:14,260 --> 00:26:19,270
didn't really use any tool in our case

00:26:16,030 --> 00:26:22,330
so we mostly yeah so we considered

00:26:19,270 --> 00:26:24,930
mostly review content information the

00:26:22,330 --> 00:26:27,070
frequency of terms and we looked at

00:26:24,930 --> 00:26:28,930
amenities as put and things are

00:26:27,070 --> 00:26:33,880
basically specific to our problem like

00:26:28,930 --> 00:26:36,850
specific to for example Lake hotels or

00:26:33,880 --> 00:26:41,170
the vicinity to lakes for example so we

00:26:36,850 --> 00:26:46,600
didn't use any specific tools okey

00:26:41,170 --> 00:26:48,460
Buchan thank you for the great talk you

00:26:46,600 --> 00:26:50,590
mentioned that example with German where

00:26:48,460 --> 00:26:52,570
golf means two things do you know how

00:26:50,590 --> 00:26:54,820
were to act behaves when when you have

00:26:52,570 --> 00:26:57,970
synonyms like that that fall on the same

00:26:54,820 --> 00:26:59,830
word like golf

00:26:57,970 --> 00:27:01,450
we're different meanings yeah like what

00:26:59,830 --> 00:27:09,000
what is the German golf Victor looked

00:27:01,450 --> 00:27:15,750
like yeah that's a good question I mean

00:27:09,000 --> 00:27:18,750
you know I'm not sure exactly uh yeah

00:27:15,750 --> 00:27:18,750
yeah

00:27:22,019 --> 00:27:34,559
google translator like if we can use

00:27:24,779 --> 00:27:36,179
that or what is the question no no we

00:27:34,559 --> 00:27:38,100
don't so actually we really like the

00:27:36,179 --> 00:27:39,480
classifiers we consider them really

00:27:38,100 --> 00:27:41,429
separately so we don't translate any

00:27:39,480 --> 00:27:43,769
text we have separate classifiers for

00:27:41,429 --> 00:27:52,070
German separate classifiers for English

00:27:43,769 --> 00:27:55,649
we don't use Google Translate yeah

00:27:52,070 --> 00:27:59,850
help thank you for that talk I wonder

00:27:55,649 --> 00:28:02,749
about the data pre-processing so it

00:27:59,850 --> 00:28:07,259
there is some data clean saying that you

00:28:02,749 --> 00:28:10,379
had two major one that we do so kind of

00:28:07,259 --> 00:28:14,610
clean up the dataset and perhaps

00:28:10,379 --> 00:28:19,169
identify a name of places or things like

00:28:14,610 --> 00:28:20,700
that yeah so I can't give you too much

00:28:19,169 --> 00:28:23,159
this is about this because actually this

00:28:20,700 --> 00:28:24,869
is done by a different team this is not

00:28:23,159 --> 00:28:26,399
exactly so there's another team that

00:28:24,869 --> 00:28:28,789
really works on that performs the

00:28:26,399 --> 00:28:31,340
semantic analysis and also takes care of

00:28:28,789 --> 00:28:36,769
yeah cleaning the data for example

00:28:31,340 --> 00:28:39,539
removing stop words yeah tokenization

00:28:36,769 --> 00:28:41,460
lamentation all this kind of things so a

00:28:39,539 --> 00:28:46,499
team there's a team that is taking care

00:28:41,460 --> 00:28:49,769
of that and so sorry your question you

00:28:46,499 --> 00:28:52,019
asked me what we do exactly or yeah I

00:28:49,769 --> 00:28:55,409
was wondering the son general idea that

00:28:52,019 --> 00:28:58,139
you could do that so I can give you just

00:28:55,409 --> 00:28:59,580
these general ideas because I'm this is

00:28:58,139 --> 00:29:02,940
something that a different team does I

00:28:59,580 --> 00:29:06,929
don't know if maybe it's definitely want

00:29:02,940 --> 00:29:08,249
to add something on this or hey well

00:29:06,929 --> 00:29:10,710
maybe we can take this that offline

00:29:08,249 --> 00:29:12,330
there are other people here from my

00:29:10,710 --> 00:29:15,860
company also can give you more details

00:29:12,330 --> 00:29:15,860
ok cool thank you

00:29:19,570 --> 00:29:24,590
okay folks we are out of time so let's

00:29:22,820 --> 00:29:32,060
thank our speaker again

00:29:24,590 --> 00:29:32,060

YouTube URL: https://www.youtube.com/watch?v=ih2reTLOzWI


