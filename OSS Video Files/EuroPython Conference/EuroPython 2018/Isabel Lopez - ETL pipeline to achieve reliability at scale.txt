Title: Isabel Lopez - ETL pipeline to achieve reliability at scale
Publication date: 2018-08-22
Playlist: EuroPython 2018
Description: 
	ETL pipeline to achieve reliability at scale
[EuroPython 2018 - Talk - 2018-07-25 - Fintry [PyData]]
[Edinburgh, UK]

By Isabel Lopez

In an online betting exchange, thousands of money related transactions are generated per minute. This data flow transforms a common and, in general, tedious task such as accounting into an interesting big data engineering problem. At Smarkets, accounting reports serve two main purposes: housekeeping of our financial operations and documentation for the relevant regulation authorities. In both cases, reliability and accuracy are crucial in the final result. The fact that these reports are generated daily, the need to cope with failure when retrieving data from previous days, and the fast growing transaction volume obsoleted the original accounting system and required a new pipeline that could scale.

This talk presents the ETL pipeline designed to meet the constraints highlighted above, and explains the motivations behind the tech stack chosen for the job, which includes Python3, Luigi and Spark among others. These topics will be covered by describing the main technical problems solved with our design:
- Fault tolerance and reliability, i.e ability to identify faulty steps and only rerun those instead of the whole pipeline.
- Fast input/output.
- Fast computations.



License: This video is licensed under the CC BY-NC-SA 3.0 license: https://creativecommons.org/licenses/by-nc-sa/3.0/
Please see our speaker release agreement for details: https://ep2018.europython.eu/en/speaker-release-agreement/
Captions: 
	00:00:04,640 --> 00:00:09,360
hi everybody my name is Sibylle I'm

00:00:07,379 --> 00:00:10,800
massive or engineer ATS markets and

00:00:09,360 --> 00:00:12,330
today I'm going to talk about the ETL

00:00:10,800 --> 00:00:14,670
pipeline that we will to generate the

00:00:12,330 --> 00:00:16,020
accounting reports I'm going to focus on

00:00:14,670 --> 00:00:19,859
the tech stack and the reasoning behind

00:00:16,020 --> 00:00:21,330
the technologies that we chose markets

00:00:19,859 --> 00:00:24,000
is an online meeting exchange where

00:00:21,330 --> 00:00:26,279
people can place bets on different

00:00:24,000 --> 00:00:28,500
events mainly sports but we all support

00:00:26,279 --> 00:00:32,099
other kinds of events such as political

00:00:28,500 --> 00:00:34,410
elections in the strange many many

00:00:32,099 --> 00:00:36,840
related transact transactions are

00:00:34,410 --> 00:00:39,270
generated a those include deposits

00:00:36,840 --> 00:00:41,940
withdrawals orders to place a bet on

00:00:39,270 --> 00:00:45,300
silhouette and so on all of these

00:00:41,940 --> 00:00:47,850
transactions need to be a process to

00:00:45,300 --> 00:00:49,980
generate the accounting reports which

00:00:47,850 --> 00:00:55,079
include account accounting statistics

00:00:49,980 --> 00:00:57,480
such as the total amount of a bet that

00:00:55,079 --> 00:01:00,539
somebody of money that somebody can play

00:00:57,480 --> 00:01:02,910
have placed in bets over a month the

00:01:00,539 --> 00:01:06,270
total amount of deposits withdrawals and

00:01:02,910 --> 00:01:08,189
so on these reports serve two main

00:01:06,270 --> 00:01:10,740
purposes the first one is that they

00:01:08,189 --> 00:01:13,860
allow us to have control over the money

00:01:10,740 --> 00:01:16,110
that comes to market and secondly they

00:01:13,860 --> 00:01:18,390
provide a commutation for the relevant

00:01:16,110 --> 00:01:23,970
regulators so that they can know how we

00:01:18,390 --> 00:01:25,740
handle money at markets the previous

00:01:23,970 --> 00:01:28,470
accounting pipeline was designed back in

00:01:25,740 --> 00:01:31,020
2013 and at that point the number of

00:01:28,470 --> 00:01:35,970
transactions that they need to handle it

00:01:31,020 --> 00:01:38,310
was below a 190,000 the massive business

00:01:35,970 --> 00:01:41,130
growth adds markets during the last four

00:01:38,310 --> 00:01:43,200
years matey's a number of transactions

00:01:41,130 --> 00:01:45,750
increase over an order of magnitude and

00:01:43,200 --> 00:01:48,990
now the the number of transactions that

00:01:45,750 --> 00:01:52,710
the pipeline is to process is more than

00:01:48,990 --> 00:01:54,630
a point eight million the previous

00:01:52,710 --> 00:01:57,060
pipeline was not able to handle this

00:01:54,630 --> 00:01:58,740
number of transactions the main problem

00:01:57,060 --> 00:02:02,189
of the pipeline was that it was a

00:01:58,740 --> 00:02:03,930
collection of scripts without any formal

00:02:02,189 --> 00:02:06,659
dependency definition between them and

00:02:03,930 --> 00:02:08,580
this was creating two issues first it

00:02:06,659 --> 00:02:11,480
was difficult to identify errors and

00:02:08,580 --> 00:02:13,319
secondly even if you managed to identify

00:02:11,480 --> 00:02:15,359
where the error was

00:02:13,319 --> 00:02:17,489
in front it was referred to know which

00:02:15,359 --> 00:02:19,170
steps of the pipeline need to be running

00:02:17,489 --> 00:02:23,099
order to generate again the accounting

00:02:19,170 --> 00:02:24,930
reports a powerful and sorry apart from

00:02:23,099 --> 00:02:26,249
that the system was released low we are

00:02:24,930 --> 00:02:30,090
supposed to generate the accounting

00:02:26,249 --> 00:02:33,299
reports daily I was taking more than 24

00:02:30,090 --> 00:02:35,670
hours to run and finally the pipeline

00:02:33,299 --> 00:02:38,430
was used was using as persistent storage

00:02:35,670 --> 00:02:42,269
Apollo mounted into the host running the

00:02:38,430 --> 00:02:44,099
pipeline this volume was quite expensive

00:02:42,269 --> 00:02:48,090
I need a requirement in us in order to

00:02:44,099 --> 00:02:49,590
ensure that it was not low on disk at

00:02:48,090 --> 00:02:51,239
this point we decided that the best

00:02:49,590 --> 00:02:54,719
solution was to really sign the whole

00:02:51,239 --> 00:02:57,150
pipeline this diagram represents the

00:02:54,719 --> 00:02:58,199
main the main tasks that this pipeline

00:02:57,150 --> 00:03:01,199
needs to do

00:02:58,199 --> 00:03:03,510
first we need to effective transactions

00:03:01,199 --> 00:03:05,280
from the change and we and we need to

00:03:03,510 --> 00:03:07,829
generate transaction files with those

00:03:05,280 --> 00:03:09,900
transactions afterwards we need to

00:03:07,829 --> 00:03:11,370
process this transaction price to

00:03:09,900 --> 00:03:13,620
compute the area monthly account

00:03:11,370 --> 00:03:16,049
statistics and finally using this

00:03:13,620 --> 00:03:19,199
account statistics we need to generate

00:03:16,049 --> 00:03:21,479
the final accounting reports the main

00:03:19,199 --> 00:03:23,699
requirements of the pipeline are fault

00:03:21,479 --> 00:03:25,620
tolerance and reliability if something

00:03:23,699 --> 00:03:28,530
goes wrong we need to be aware of it and

00:03:25,620 --> 00:03:30,930
we should fix it quickly by running the

00:03:28,530 --> 00:03:35,400
those steps of the pipeline that are

00:03:30,930 --> 00:03:38,639
affected by the by the issue in terms of

00:03:35,400 --> 00:03:40,349
storing storage we need a fast reads and

00:03:38,639 --> 00:03:44,040
writes high availability high durability

00:03:40,349 --> 00:03:45,930
and the storage should be cheap we also

00:03:44,040 --> 00:03:47,280
need good processing performance it

00:03:45,930 --> 00:03:49,560
shouldn't take more than a couple of

00:03:47,280 --> 00:03:52,379
hours to generate deep accounting

00:03:49,560 --> 00:03:54,060
reports and finally we need the pipeline

00:03:52,379 --> 00:03:55,829
to be scalable the number of

00:03:54,060 --> 00:03:57,689
transactions at this markets continues

00:03:55,829 --> 00:03:59,040
to grow and we don't know we don't want

00:03:57,689 --> 00:04:01,650
to have to redesign the whole pipeline

00:03:59,040 --> 00:04:06,150
any time soon in the rest of the

00:04:01,650 --> 00:04:08,969
presentation I'm going to describe the

00:04:06,150 --> 00:04:10,769
design decisions that we made to meet

00:04:08,969 --> 00:04:14,609
these requirements and also the

00:04:10,769 --> 00:04:17,099
technologies that we chose the

00:04:14,609 --> 00:04:19,169
accounting pipeline involves fairly long

00:04:17,099 --> 00:04:21,209
batch jobs and things can go wrong while

00:04:19,169 --> 00:04:23,099
they are running in particularly in our

00:04:21,209 --> 00:04:25,680
case the communication with this change

00:04:23,099 --> 00:04:26,970
the fact the transactions may fail in

00:04:25,680 --> 00:04:29,550
order to

00:04:26,970 --> 00:04:31,230
provide for tolerance and reliability in

00:04:29,550 --> 00:04:34,170
this scenario we made the following

00:04:31,230 --> 00:04:36,330
design decisions we store the

00:04:34,170 --> 00:04:38,280
transactions per day and we also compute

00:04:36,330 --> 00:04:40,470
the financial stats per day so if

00:04:38,280 --> 00:04:41,970
something goes wrong a particular day we

00:04:40,470 --> 00:04:43,560
just need to recompute the financial

00:04:41,970 --> 00:04:47,430
status for that day and not for the

00:04:43,560 --> 00:04:51,240
whole month sometimes things go wrong in

00:04:47,430 --> 00:04:54,060
the interchange and this creates some

00:04:51,240 --> 00:04:57,030
problems and we get missing transactions

00:04:54,060 --> 00:04:58,680
or other sort of data corruption in

00:04:57,030 --> 00:05:01,230
order to reduce the impact of these

00:04:58,680 --> 00:05:02,940
issues on the accounting pipeline we

00:05:01,230 --> 00:05:05,400
always compute the stats for the last

00:05:02,940 --> 00:05:08,430
two days worth of transactions and

00:05:05,400 --> 00:05:10,980
finally we broke down the pipeline into

00:05:08,430 --> 00:05:12,810
modular greedy tasks release a Python

00:05:10,980 --> 00:05:15,630
library that allows you to define a

00:05:12,810 --> 00:05:18,570
dependencies between tasks it handles

00:05:15,630 --> 00:05:21,240
the dependency resolution for you if I

00:05:18,570 --> 00:05:23,340
breaking down the pipeline to read it

00:05:21,240 --> 00:05:25,650
tasks it's really easy to identify when

00:05:23,340 --> 00:05:27,930
things go wrong and which steps of the

00:05:25,650 --> 00:05:30,090
pipeline are affected and only run those

00:05:27,930 --> 00:05:32,840
steps instead of the whole pipeline to

00:05:30,090 --> 00:05:37,080
generate again the accounting reports

00:05:32,840 --> 00:05:39,030
this is a simplified version of a task

00:05:37,080 --> 00:05:40,650
that we have in the pipeline which

00:05:39,030 --> 00:05:44,190
basically generates a human readable

00:05:40,650 --> 00:05:47,100
report with account statistics a widget

00:05:44,190 --> 00:05:50,490
task is a Python class that in general

00:05:47,100 --> 00:05:53,310
defines three methods the requires

00:05:50,490 --> 00:05:55,500
methods method allows us to declare all

00:05:53,310 --> 00:05:57,630
the dependencies of the tasks in this

00:05:55,500 --> 00:05:59,910
case they're a human readable accounting

00:05:57,630 --> 00:06:03,210
report tasks depends on the output of

00:05:59,910 --> 00:06:05,490
another widget task that generates a

00:06:03,210 --> 00:06:08,940
file with account statistics but in a

00:06:05,490 --> 00:06:11,580
binary format the RAM method is where

00:06:08,940 --> 00:06:13,290
the processing takes place in this case

00:06:11,580 --> 00:06:16,620
reading the input file with the account

00:06:13,290 --> 00:06:19,890
statistics and generating the TSV file

00:06:16,620 --> 00:06:22,290
with all stats and the output method

00:06:19,890 --> 00:06:24,810
allows us to define the target of the

00:06:22,290 --> 00:06:28,890
task in this case the reporter we want

00:06:24,810 --> 00:06:31,020
to generate this graph is a

00:06:28,890 --> 00:06:33,270
simplification of the dependency graph

00:06:31,020 --> 00:06:36,750
generated by the really central share

00:06:33,270 --> 00:06:39,419
dealer the node in the top in the top

00:06:36,750 --> 00:06:40,500
represent represents that the task that

00:06:39,419 --> 00:06:42,300
we trigger

00:06:40,500 --> 00:06:45,060
in this case will be the generate humor

00:06:42,300 --> 00:06:46,530
readable accounting report and below it

00:06:45,060 --> 00:06:49,290
you can see all the levels of

00:06:46,530 --> 00:06:51,360
dependencies so generate human readable

00:06:49,290 --> 00:06:53,520
accounting report depends on the output

00:06:51,360 --> 00:06:56,130
of generate accounting report which in

00:06:53,520 --> 00:06:59,100
turn depend depends on the output of

00:06:56,130 --> 00:07:02,940
many generate accounting monthly status

00:06:59,100 --> 00:07:05,910
tasks the color of the notes indicates

00:07:02,940 --> 00:07:08,700
the status of the task yellow means

00:07:05,910 --> 00:07:12,540
pending blue means running angry means

00:07:08,700 --> 00:07:14,460
completed the next requirement that we

00:07:12,540 --> 00:07:16,260
wanted to achieve was efficient storage

00:07:14,460 --> 00:07:18,360
in order in order to meet this

00:07:16,260 --> 00:07:21,000
requirement we focused on two aspects

00:07:18,360 --> 00:07:23,670
the format of the files generated by the

00:07:21,000 --> 00:07:25,980
pipeline and also where to store all

00:07:23,670 --> 00:07:28,740
these files regarding the format instead

00:07:25,980 --> 00:07:30,570
of going for a conventional sorry you

00:07:28,740 --> 00:07:34,080
know instead of going for a conventional

00:07:30,570 --> 00:07:36,140
draw based format like a TSP or a CSV we

00:07:34,080 --> 00:07:40,350
decided to use the columnar format

00:07:36,140 --> 00:07:42,870
Burkett the difference between a raw

00:07:40,350 --> 00:07:45,660
waste and a columnar format is the way

00:07:42,870 --> 00:07:48,210
they taste stored in disk in a row based

00:07:45,660 --> 00:07:50,910
format the values of the rows are stored

00:07:48,210 --> 00:07:53,669
sequentially in disk and this is a good

00:07:50,910 --> 00:07:56,190
idea if our access pattern consists of

00:07:53,669 --> 00:08:00,300
accessing particulars the values of

00:07:56,190 --> 00:08:02,780
particular records yeah the values of

00:08:00,300 --> 00:08:06,000
particular records on the contrary

00:08:02,780 --> 00:08:08,610
columnar format in a columnar format the

00:08:06,000 --> 00:08:11,280
data the data the values of the columns

00:08:08,610 --> 00:08:15,330
are stored sequentially in the in the

00:08:11,280 --> 00:08:17,669
disk and this offers a good performance

00:08:15,330 --> 00:08:20,160
for analytical tasks like the ones in

00:08:17,669 --> 00:08:23,460
this pipeline since it allows us to

00:08:20,160 --> 00:08:25,590
fetch only those columns that need to be

00:08:23,460 --> 00:08:28,169
processed instead of having to load all

00:08:25,590 --> 00:08:31,080
the file in memory and this minimizes

00:08:28,169 --> 00:08:33,510
the amount of i/o apart from that since

00:08:31,080 --> 00:08:37,520
data of the same type is stored together

00:08:33,510 --> 00:08:41,909
type specific encoding can be used and

00:08:37,520 --> 00:08:44,850
also general compression algorithms work

00:08:41,909 --> 00:08:46,380
better with a maximize the compression

00:08:44,850 --> 00:08:50,100
factor of this algorithm

00:08:46,380 --> 00:08:52,180
this files and also minimizes the amount

00:08:50,100 --> 00:08:55,899
of i/o

00:08:52,180 --> 00:08:57,850
a park it can be load into pandas

00:08:55,899 --> 00:09:03,070
dataframes and it's also supported by

00:08:57,850 --> 00:09:05,529
all the Hadoop environment in terms of a

00:09:03,070 --> 00:09:08,440
persistent storage we decided to go with

00:09:05,529 --> 00:09:11,470
Amazon s3 since it provides all the

00:09:08,440 --> 00:09:13,750
requirements that we were looking for it

00:09:11,470 --> 00:09:15,820
provides high durability for regulation

00:09:13,750 --> 00:09:18,339
purposes we need to keep the accounting

00:09:15,820 --> 00:09:20,230
reports for several years or high

00:09:18,339 --> 00:09:22,870
durability is very important for us a

00:09:20,230 --> 00:09:27,850
high availability we should be able to

00:09:22,870 --> 00:09:29,800
access the reports whenever we want low

00:09:27,850 --> 00:09:32,580
maintenance within we don't need to care

00:09:29,800 --> 00:09:35,850
about being low on this color yeah

00:09:32,580 --> 00:09:40,209
doesn't really required much maintenance

00:09:35,850 --> 00:09:41,740
Amazon s3 is quite cheap it also allows

00:09:40,209 --> 00:09:43,570
us to decouple the processing from the

00:09:41,740 --> 00:09:45,880
storage and what this means is that we

00:09:43,570 --> 00:09:47,890
can choose the instances of the pipeline

00:09:45,880 --> 00:09:49,360
based on our person needs instead of

00:09:47,890 --> 00:09:51,220
having to worry about high this

00:09:49,360 --> 00:09:53,290
requirement since all the data we

00:09:51,220 --> 00:09:56,500
actually want to persist can be stored

00:09:53,290 --> 00:09:59,170
in s3 it can be accessed from Python

00:09:56,500 --> 00:10:01,540
using the libraries bottle water 3 and

00:09:59,170 --> 00:10:03,550
it comes with a nice web interface where

00:10:01,540 --> 00:10:06,850
you can check all the data that you've

00:10:03,550 --> 00:10:08,470
stored the next requirement that we

00:10:06,850 --> 00:10:10,540
wanted to meet was with processing

00:10:08,470 --> 00:10:12,610
performance we wanted fast data

00:10:10,540 --> 00:10:16,810
processing and we also wanted an engine

00:10:12,610 --> 00:10:19,300
that was able to scale a that's why we

00:10:16,810 --> 00:10:21,370
decided to go with a spark spark is a

00:10:19,300 --> 00:10:26,020
general-purpose data processing engine

00:10:21,370 --> 00:10:28,600
and what SPARC does is it breaks down

00:10:26,020 --> 00:10:31,150
the processing jobs into tasks and

00:10:28,600 --> 00:10:33,339
identifies those tasks that can be run

00:10:31,150 --> 00:10:35,950
in parallel on different data partitions

00:10:33,339 --> 00:10:38,380
and it builds its own execution planks

00:10:35,950 --> 00:10:41,050
by doing so a spark can do a lot of

00:10:38,380 --> 00:10:45,339
processing in parallel another feature

00:10:41,050 --> 00:10:47,620
that allows a spark to be really fast is

00:10:45,339 --> 00:10:49,690
that it keeps that an in memory when

00:10:47,620 --> 00:10:55,660
possible instead of storing intermediate

00:10:49,690 --> 00:10:57,640
results in in in disk and sparks a spark

00:10:55,660 --> 00:11:02,860
comes with Python support through the PI

00:10:57,640 --> 00:11:03,880
spark library at the core of SPARC we

00:11:02,860 --> 00:11:05,600
have the oddities

00:11:03,880 --> 00:11:08,540
which are the fundamental

00:11:05,600 --> 00:11:10,730
unit of data in a spark Rd these are

00:11:08,540 --> 00:11:13,070
resilient because they are immutable and

00:11:10,730 --> 00:11:15,019
they are fault tolerant they are they

00:11:13,070 --> 00:11:17,509
are also distributed because they are

00:11:15,019 --> 00:11:21,050
partitioned across multiple nodes in the

00:11:17,509 --> 00:11:24,680
in the spark cluster and they are a data

00:11:21,050 --> 00:11:26,360
set because they hold data there are two

00:11:24,680 --> 00:11:29,709
kinds of operations that can be applied

00:11:26,360 --> 00:11:32,420
on rdd's transformations and actions a

00:11:29,709 --> 00:11:36,290
transformation applies a function on the

00:11:32,420 --> 00:11:40,300
RTD and creates a new RTD a examples of

00:11:36,290 --> 00:11:44,630
transformations are map filter aggregate

00:11:40,300 --> 00:11:50,319
actions on the other hand return a final

00:11:44,630 --> 00:11:52,940
result or right 8a to internal storage

00:11:50,319 --> 00:11:55,910
transformations in spark are lazy they

00:11:52,940 --> 00:11:59,930
are not executed right after they are

00:11:55,910 --> 00:12:02,680
called but the transformation itself is

00:11:59,930 --> 00:12:07,339
safe on a reference to the data it a

00:12:02,680 --> 00:12:09,709
tile modifies is also safe and saved and

00:12:07,339 --> 00:12:12,529
this is called the data the spark

00:12:09,709 --> 00:12:16,360
lineage and this allows the spark to be

00:12:12,529 --> 00:12:19,519
very efficient and also fault tolerant

00:12:16,360 --> 00:12:23,860
these transformations are only executed

00:12:19,519 --> 00:12:26,000
when an action is triggered in our

00:12:23,860 --> 00:12:28,220
accounting pipeline in our data

00:12:26,000 --> 00:12:31,970
processing pipeline we didn't use our

00:12:28,220 --> 00:12:35,269
IDs directly but we decided to to work

00:12:31,970 --> 00:12:38,569
with spark data frames spark data frames

00:12:35,269 --> 00:12:41,389
are a units of data organized in columns

00:12:38,569 --> 00:12:43,389
and built on top of our Dedes but their

00:12:41,389 --> 00:12:47,709
performance is better than the ADIZ

00:12:43,389 --> 00:12:51,380
performance since or optimizations are

00:12:47,709 --> 00:12:55,250
applied before the actual operations are

00:12:51,380 --> 00:12:59,500
executed and also the data frames api is

00:12:55,250 --> 00:13:03,079
more user-friendly than the rdd's one

00:12:59,500 --> 00:13:06,079
I'm going to split our spark application

00:13:03,079 --> 00:13:08,300
runs spark follows a master/slave

00:13:06,079 --> 00:13:10,360
architecture with a central coordinator

00:13:08,300 --> 00:13:13,399
called the driver and several workers

00:13:10,360 --> 00:13:15,980
distributed workers called executors

00:13:13,399 --> 00:13:19,020
the driver instantiates the spark

00:13:15,980 --> 00:13:22,339
context which is in charge of a

00:13:19,020 --> 00:13:27,320
breaking down the pristine job into

00:13:22,339 --> 00:13:31,220
tasks and creating the execution plans

00:13:27,320 --> 00:13:34,080
one spark has this execution plans the

00:13:31,220 --> 00:13:36,959
task scheduler within the spark context

00:13:34,080 --> 00:13:40,649
is going to ask the cluster manager for

00:13:36,959 --> 00:13:43,230
executors to run these tasks a spark has

00:13:40,649 --> 00:13:46,410
its own a cluster manager and it also

00:13:43,230 --> 00:13:50,910
supports other cluster managers such as

00:13:46,410 --> 00:13:54,000
Hadoop Ian's a spark jobs can be

00:13:50,910 --> 00:13:57,680
triggered from really really comes with

00:13:54,000 --> 00:14:02,610
a PI spark task that can be extended to

00:13:57,680 --> 00:14:05,910
create custom spark jobs in this case

00:14:02,610 --> 00:14:08,760
all the spark operations can be defined

00:14:05,910 --> 00:14:12,180
in the main method of the class so in

00:14:08,760 --> 00:14:15,089
here for example in this a task we are

00:14:12,180 --> 00:14:16,649
creating a report with account status

00:14:15,089 --> 00:14:19,140
with accounting statistics for a

00:14:16,649 --> 00:14:24,180
particular account by filtering out the

00:14:19,140 --> 00:14:25,320
rest of the account IDs the final

00:14:24,180 --> 00:14:28,110
requirement that we wanted to achieve

00:14:25,320 --> 00:14:30,029
was scalability in order to meet this

00:14:28,110 --> 00:14:31,980
requirement instead of having a spark

00:14:30,029 --> 00:14:35,310
running on a single node together with

00:14:31,980 --> 00:14:38,130
the rest of the pipeline components we

00:14:35,310 --> 00:14:41,610
wanted to configure a spark to run on a

00:14:38,130 --> 00:14:43,740
multi node cluster instead of

00:14:41,610 --> 00:14:48,779
configuring our own cluster we decided

00:14:43,740 --> 00:14:51,540
to use spark on EMR EMR provides fast

00:14:48,779 --> 00:14:54,630
deployment it takes around 10 minutes to

00:14:51,540 --> 00:14:56,640
provision a cluster it is quite easy to

00:14:54,630 --> 00:14:59,640
use once you know the types of instances

00:14:56,640 --> 00:15:00,930
that you want for your pipeline and your

00:14:59,640 --> 00:15:03,720
several requirements doing the

00:15:00,930 --> 00:15:05,430
configuration is quite easy it is really

00:15:03,720 --> 00:15:07,260
flexible it allows you to choose among

00:15:05,430 --> 00:15:09,839
many different different kinds of

00:15:07,260 --> 00:15:12,630
instances frameworks to install and you

00:15:09,839 --> 00:15:15,420
can even install sterner software it

00:15:12,630 --> 00:15:18,240
comes with the EMR file system which

00:15:15,420 --> 00:15:20,520
integrates with s3 so all the logs of

00:15:18,240 --> 00:15:22,770
the cluster together with the type data

00:15:20,520 --> 00:15:26,880
generated by the cluster can be stored

00:15:22,770 --> 00:15:29,220
in s3 the cluster can be shut down once

00:15:26,880 --> 00:15:31,890
the process in job is done without any

00:15:29,220 --> 00:15:32,790
data any real data loss course all the

00:15:31,890 --> 00:15:35,810
data that

00:15:32,790 --> 00:15:38,790
want to persist cambia starting in s3

00:15:35,810 --> 00:15:41,370
the cost of running the cluster is quite

00:15:38,790 --> 00:15:44,310
low and you only pay pay while the

00:15:41,370 --> 00:15:46,320
cluster is running and it comes with a

00:15:44,310 --> 00:15:48,270
nice web interface where you can check

00:15:46,320 --> 00:15:51,600
the configuration of the cluster the

00:15:48,270 --> 00:15:57,540
task that you that you Frank in the

00:15:51,600 --> 00:16:00,180
cluster the logs and so on I'm going to

00:15:57,540 --> 00:16:03,900
spring a little bit how SPARC ranks own

00:16:00,180 --> 00:16:06,870
EMR EMR has two kinds of of nodes a

00:16:03,900 --> 00:16:11,160
master node and several slave nodes the

00:16:06,870 --> 00:16:13,310
master node M distributes the data and

00:16:11,160 --> 00:16:16,590
the tasks across the rest of the nodes

00:16:13,310 --> 00:16:18,330
checks the status of the cluster angles

00:16:16,590 --> 00:16:20,580
through the status of the tasks running

00:16:18,330 --> 00:16:22,920
tasks running on the cluster and the

00:16:20,580 --> 00:16:26,700
slave nodes are in charge of running the

00:16:22,920 --> 00:16:31,140
tasks and also storing the the data on

00:16:26,700 --> 00:16:34,050
the file system of the cluster EMR uses

00:16:31,140 --> 00:16:37,760
yarn as the resource manager to allocate

00:16:34,050 --> 00:16:42,030
resources to the tasks submitted to the

00:16:37,760 --> 00:16:44,970
- - EMR to the cluster to run when we

00:16:42,030 --> 00:16:46,440
submit a spark application to EMR the

00:16:44,970 --> 00:16:48,360
first thing that is this this

00:16:46,440 --> 00:16:51,540
application is going to be running on

00:16:48,360 --> 00:16:53,430
several yarn containers in the Indus

00:16:51,540 --> 00:16:55,710
life node the first thing that is going

00:16:53,430 --> 00:16:58,410
to happen is that the SPARC driver is

00:16:55,710 --> 00:17:01,980
going to instantiate the SPARC context

00:16:58,410 --> 00:17:05,400
and this per contest is going to create

00:17:01,980 --> 00:17:07,410
the execution plan once we have this

00:17:05,400 --> 00:17:09,180
execution plan the SPARC context is

00:17:07,410 --> 00:17:13,230
going to ask the yarn resource manager

00:17:09,180 --> 00:17:15,480
for executors to run these tasks the

00:17:13,230 --> 00:17:17,730
exec the SPARC executors which are

00:17:15,480 --> 00:17:19,800
running on different yarn containers are

00:17:17,730 --> 00:17:22,110
going to register with the sparkin a

00:17:19,800 --> 00:17:25,200
with us to the SPARC with the SPARC

00:17:22,110 --> 00:17:27,660
context and this is per context contest

00:17:25,200 --> 00:17:30,990
condensed are sending stat can then

00:17:27,660 --> 00:17:35,340
start sending tasks for execution - to

00:17:30,990 --> 00:17:38,940
the SPARC executors to finish I'm going

00:17:35,340 --> 00:17:42,690
to summarize the main steps involved in

00:17:38,940 --> 00:17:44,490
the accounting pipeline first we we use

00:17:42,690 --> 00:17:46,110
Jenkins to trigger the account in job

00:17:44,490 --> 00:17:49,559
the reason behind it

00:17:46,110 --> 00:17:51,540
that Jenkins allows us to to shuttle the

00:17:49,559 --> 00:17:54,120
job so that it runs daily and he's also

00:17:51,540 --> 00:17:56,520
central a central place for us to have

00:17:54,120 --> 00:17:59,580
where we have most of our patched jobs

00:17:56,520 --> 00:18:02,490
so it allows us to easily monitor a if

00:17:59,580 --> 00:18:04,470
they are all fine the first thing that

00:18:02,490 --> 00:18:06,929
this accounting job is going to do is

00:18:04,470 --> 00:18:07,590
creating a the accounting container with

00:18:06,929 --> 00:18:09,179
the latest

00:18:07,590 --> 00:18:11,730
with the latest image from the register

00:18:09,179 --> 00:18:13,620
and once this container is up and

00:18:11,730 --> 00:18:19,350
running the really central share dealer

00:18:13,620 --> 00:18:21,990
will be started then loui task that has

00:18:19,350 --> 00:18:25,380
as requirements all the widget tasks

00:18:21,990 --> 00:18:28,140
that generate final reports is going to

00:18:25,380 --> 00:18:30,600
be triggered the first ready task that

00:18:28,140 --> 00:18:35,130
needs a spark for processing is going to

00:18:30,600 --> 00:18:38,520
create the spark cluster on EMR and once

00:18:35,130 --> 00:18:40,919
this spark cluster is up and running all

00:18:38,520 --> 00:18:43,049
the Louie tasks that needs a spark

00:18:40,919 --> 00:18:45,809
crossing are going to submit spark

00:18:43,049 --> 00:18:48,419
applications to him at once

00:18:45,809 --> 00:18:52,380
the last Wiggly task that needs a spark

00:18:48,419 --> 00:18:54,559
is done the Louie the sparkler the spark

00:18:52,380 --> 00:18:57,960
cluster will be destroyed

00:18:54,559 --> 00:19:00,059
finally all the data generated by the

00:18:57,960 --> 00:19:05,130
pipeline together with all the reports

00:19:00,059 --> 00:19:07,200
can be found a industry this is the end

00:19:05,130 --> 00:19:09,559
of my talk thank you very much for

00:19:07,200 --> 00:19:09,559
coming

00:19:14,730 --> 00:19:19,380
thanks very much are there any questions

00:19:16,720 --> 00:19:19,380
from the audience

00:19:26,010 --> 00:19:32,110
thanks for the talk you said you used to

00:19:29,650 --> 00:19:35,800
eat cheated to do any comparison with

00:19:32,110 --> 00:19:38,740
the airflow no we don't use we used

00:19:35,800 --> 00:19:41,340
redeeming doing at markets I even used a

00:19:38,740 --> 00:19:44,800
airflow before okay but there's no like

00:19:41,340 --> 00:19:57,190
pros and cons not notary I've never used

00:19:44,800 --> 00:20:00,070
myself airflow before yes yeah so you

00:19:57,190 --> 00:20:02,380
said you started up a EMR cluster and

00:20:00,070 --> 00:20:06,370
run multiple Luigi tasks on it and then

00:20:02,380 --> 00:20:08,500
shut it down at the end as not yeah it's

00:20:06,370 --> 00:20:12,490
not like that we run three tasks with

00:20:08,500 --> 00:20:17,140
thing a note and then the Louie tasks

00:20:12,490 --> 00:20:18,820
admit steps to the to the EMR cluster we

00:20:17,140 --> 00:20:21,610
don't Randall we do tasks on the cluster

00:20:18,820 --> 00:20:24,730
okay I was wondering if you had a way

00:20:21,610 --> 00:20:26,950
for Luigi tasks running outside the

00:20:24,730 --> 00:20:29,200
clusters who to submit jobs to the

00:20:26,950 --> 00:20:34,510
cluster yeah so we had to create our own

00:20:29,200 --> 00:20:38,320
a pie spice path task okay cool I mean I

00:20:34,510 --> 00:20:39,910
can show you is it a source is it no

00:20:38,320 --> 00:20:43,210
it's not open source I mean I can show

00:20:39,910 --> 00:20:45,660
you the code he's not that hot okay cool

00:20:43,210 --> 00:20:45,660
thanks

00:20:53,530 --> 00:21:00,480
you mentioned that you save data in

00:20:56,530 --> 00:21:03,820
Pocket files which are in a stream yeah

00:21:00,480 --> 00:21:05,770
he was another great dog which mentioned

00:21:03,820 --> 00:21:08,410
that they were also using rocket files

00:21:05,770 --> 00:21:11,020
and saving Aaron as you and there was

00:21:08,410 --> 00:21:14,410
shown some wrapper which allows to

00:21:11,020 --> 00:21:17,110
access these pockets I started as or

00:21:14,410 --> 00:21:17,680
from local computer like any other file

00:21:17,110 --> 00:21:19,810
object

00:21:17,680 --> 00:21:24,340
is that even possible if as free like

00:21:19,810 --> 00:21:28,840
can I work with that files in a three

00:21:24,340 --> 00:21:31,780
from my laptop so park it files are

00:21:28,840 --> 00:21:35,770
usually folders right they are not just

00:21:31,780 --> 00:21:37,660
a unique file so when we are working as

00:21:35,770 --> 00:21:41,680
three since we are within the same file

00:21:37,660 --> 00:21:44,650
system you can access them easily with

00:21:41,680 --> 00:21:47,080
both and with like with pandas or with

00:21:44,650 --> 00:21:50,110
spark you don't have to do anything you

00:21:47,080 --> 00:21:53,560
just read them with your with Sparky's

00:21:50,110 --> 00:21:56,710
it comes out of the box however if you

00:21:53,560 --> 00:21:59,820
are in your local machine then what we

00:21:56,710 --> 00:22:03,340
do when we want to test it is

00:21:59,820 --> 00:22:06,100
recursively download the folder so that

00:22:03,340 --> 00:22:10,060
we can then with a spark or with pandas

00:22:06,100 --> 00:22:13,980
read it Thanks meet me again one more

00:22:10,060 --> 00:22:19,720
question yes if you submit those legit

00:22:13,980 --> 00:22:23,050
jobs from from to which run one in one

00:22:19,720 --> 00:22:25,750
cluster and you mentioned that you

00:22:23,050 --> 00:22:28,330
started cluster and finish just for that

00:22:25,750 --> 00:22:30,640
run yeah how do you manage that all

00:22:28,330 --> 00:22:35,110
those tasks run in that one cluster and

00:22:30,640 --> 00:22:38,200
the cluster is that's a good question so

00:22:35,110 --> 00:22:41,260
we create so the first step that the

00:22:38,200 --> 00:22:43,110
first tasks that need that needs EMR is

00:22:41,260 --> 00:22:48,970
going to be the one in charge of

00:22:43,110 --> 00:22:52,650
creating the of creating the cluster and

00:22:48,970 --> 00:22:57,070
then we are not going till up until the

00:22:52,650 --> 00:22:59,230
Samba some of the tasks need EMS we are

00:22:57,070 --> 00:23:03,080
not going to kill the cluster we only

00:22:59,230 --> 00:23:07,630
killed kill it when the last task

00:23:03,080 --> 00:23:10,970
NEADS EMR is now and we do so using a

00:23:07,630 --> 00:23:15,919
live event handler hundreds so basically

00:23:10,970 --> 00:23:29,120
we check whether all the tasks that have

00:23:15,919 --> 00:23:31,580
been scheduled are done thanks anyway so

00:23:29,120 --> 00:23:32,720
usually the thing with SPARC is that you

00:23:31,580 --> 00:23:34,850
have to be very careful about

00:23:32,720 --> 00:23:37,490
partitioning and out of memory errors

00:23:34,850 --> 00:23:39,889
and stuff like that do you have any any

00:23:37,490 --> 00:23:43,070
insight on the subject or does that park

00:23:39,889 --> 00:23:46,130
it intermediate step solve that for you

00:23:43,070 --> 00:23:49,039
or something like that yeah I to be

00:23:46,130 --> 00:23:51,260
honest we didn't get any is any sort of

00:23:49,039 --> 00:23:54,519
a red light that may be because we are

00:23:51,260 --> 00:24:05,230
not handling like huge amounts of data

00:23:54,519 --> 00:24:11,139
okay thanks how many rows yeah in terms

00:24:05,230 --> 00:24:14,769
okay eight point eight million more

00:24:11,139 --> 00:24:17,659
twice twice that course we always

00:24:14,769 --> 00:24:19,730
retrieve the last two days and those are

00:24:17,659 --> 00:24:22,850
just new transactions to generate the

00:24:19,730 --> 00:24:24,679
reports we also have pre-processed data

00:24:22,850 --> 00:24:27,529
that we need to include in the reports

00:24:24,679 --> 00:24:31,059
so draw transactions new transactions

00:24:27,529 --> 00:24:39,409
that we need to generate a stats from is

00:24:31,059 --> 00:24:41,500
around like yeah 19 million yeah more or

00:24:39,409 --> 00:24:41,500
less

00:24:42,429 --> 00:24:45,429
Thanks

00:24:48,110 --> 00:24:56,729
nope okay well like we can cus we cookin

00:24:52,700 --> 00:24:56,729

YouTube URL: https://www.youtube.com/watch?v=jNt37Sj4ebM


