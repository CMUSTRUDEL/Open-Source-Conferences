Title: Francesc Alted - New Trends In Storing Large Data Silos With Python
Publication date: 2015-08-08
Playlist: EuroPython 2015
Description: 
	Francesc Alted - New Trends In Storing Large Data Silos With Python
[EuroPython 2015]
[20 July 2015]
[Bilbao, Euskadi, Spain]

My talk is meant to provide an overview of our current set of tools
for storing data and how we arrived to these.  Then, in the light of
the current bottlenecks, and how hardware and software are evolving,
provide a brief overview of the emerging technologies that will be
important for handling Big Data within Python.  Although I expect my
talk to be a bit prospective, I won't certainly be trying to predict
the future, but rather showing a glimpse on what I expect we would be
doing in the next couple of years for properly leveraging modern
architectures (bar unexpected revolutions ;).

As an example of library adapting to recent trends in hardware, I will
be showing bcolz (https://github.com/Blosc/bcolz), which implements a
couple of data containers (and specially a chunked, columnar 'ctable')
meant for storing large datasets efficiently.
Captions: 
	00:00:00,949 --> 00:00:10,920
so good evenin smearin said I would like

00:00:05,910 --> 00:00:13,759
to share my views with you on how to a

00:00:10,920 --> 00:00:16,590
store and analyze large data silos

00:00:13,759 --> 00:00:20,930
having an account how the modern

00:00:16,590 --> 00:00:24,060
computer architectures are evolving so

00:00:20,930 --> 00:00:26,130
few words about me I am a physicist by

00:00:24,060 --> 00:00:28,680
training again computer scientist by

00:00:26,130 --> 00:00:34,020
passion and I do believe in open source

00:00:28,680 --> 00:00:36,960
and the proof is that I spent a long

00:00:34,020 --> 00:00:40,050
long part of my life doing open-source

00:00:36,960 --> 00:00:43,110
development probably the project that I

00:00:40,050 --> 00:00:46,079
invested the most is pi tables where I

00:00:43,110 --> 00:00:50,460
spent almost 10 years with it although

00:00:46,079 --> 00:00:53,489
my current pet projects are blask and

00:00:50,460 --> 00:00:56,250
because I am going to talk quite

00:00:53,489 --> 00:01:00,149
expression extensively about the last

00:00:56,250 --> 00:01:03,780
ones during my talk so why open source

00:01:00,149 --> 00:01:07,560
well my opinion there is a big duality

00:01:03,780 --> 00:01:12,090
between dreams and reality and many

00:01:07,560 --> 00:01:14,310
times we the programmers think that some

00:01:12,090 --> 00:01:16,979
things can be improved right the thing

00:01:14,310 --> 00:01:19,680
is to try to find time in order to

00:01:16,979 --> 00:01:23,310
implement that I under of the opinion

00:01:19,680 --> 00:01:25,170
that I share the opinion with manual

00:01:23,310 --> 00:01:27,810
ultra for example that the art is in the

00:01:25,170 --> 00:01:30,150
execution of an idea and not in the idea

00:01:27,810 --> 00:01:33,299
itself because there is not much left on

00:01:30,150 --> 00:01:36,329
an idea so the open source allowed me to

00:01:33,299 --> 00:01:38,159
implement my own ideas and it's a nice

00:01:36,329 --> 00:01:44,189
way to fulfill yourself while helping

00:01:38,159 --> 00:01:45,750
others as well so I am going to talk

00:01:44,189 --> 00:01:48,390
first of all to introduce the need for

00:01:45,750 --> 00:01:50,850
speed because the goal is to analyze as

00:01:48,390 --> 00:01:54,210
much as data is possible using the

00:01:50,850 --> 00:01:56,670
existing resources that you have then I

00:01:54,210 --> 00:01:59,820
will talk about new trends in computer

00:01:56,670 --> 00:02:01,380
hardware because I think that seeing

00:01:59,820 --> 00:02:04,649
evolution and the computer hardware is

00:02:01,380 --> 00:02:06,960
is it's very important in order to

00:02:04,649 --> 00:02:09,899
design your data structures and your

00:02:06,960 --> 00:02:12,239
data containers and I will finish

00:02:09,899 --> 00:02:12,930
showing you because which is an example

00:02:12,239 --> 00:02:16,140
just

00:02:12,930 --> 00:02:18,989
Paul of data container for lies large

00:02:16,140 --> 00:02:21,060
data sets that follows the principles of

00:02:18,989 --> 00:02:25,489
these newer computer there for coming

00:02:21,060 --> 00:02:31,650
newer computer architectures okay so why

00:02:25,489 --> 00:02:35,760
we need to speed of course let me remind

00:02:31,650 --> 00:02:38,189
you the main strengths of Python of

00:02:35,760 --> 00:02:41,340
course I think one of the most important

00:02:38,189 --> 00:02:44,489
things about python is that there is a

00:02:41,340 --> 00:02:47,579
rich ecosystem of data oriented

00:02:44,489 --> 00:02:50,639
libraries and most of you will know

00:02:47,579 --> 00:02:55,739
about noon pie pan de psych you learn a

00:02:50,639 --> 00:02:58,230
lot of different libraries and also

00:02:55,739 --> 00:03:00,500
python has a reputation of being slow

00:02:58,230 --> 00:03:04,290
but probably most of you also know that

00:03:00,500 --> 00:03:07,290
it is very easy well it is feasible at

00:03:04,290 --> 00:03:15,480
least to identify the bottlenecks of

00:03:07,290 --> 00:03:18,359
your programs and then use or make see

00:03:15,480 --> 00:03:21,090
extensions in order to retreat see

00:03:18,359 --> 00:03:26,159
performance using excellent tools like

00:03:21,090 --> 00:03:29,129
siphon week or two pi or others but for

00:03:26,159 --> 00:03:31,709
me it is particularly the most important

00:03:29,129 --> 00:03:34,079
thing about python is interactivity okay

00:03:31,709 --> 00:03:39,209
the ability to be able to interact with

00:03:34,079 --> 00:03:41,699
your data and see your filters what what

00:03:39,209 --> 00:03:44,250
the result of your filters result of

00:03:41,699 --> 00:03:47,340
your queries almost in real time this is

00:03:44,250 --> 00:03:50,970
the key the key thing about about life

00:03:47,340 --> 00:03:54,120
for me but of course if you want to

00:03:50,970 --> 00:03:57,269
handle big amounts of data and you want

00:03:54,120 --> 00:04:00,599
to do that interactively you need a

00:03:57,269 --> 00:04:04,199
speed right because if not this is no an

00:04:00,599 --> 00:04:05,970
oval and but designing code for the

00:04:04,199 --> 00:04:08,250
storage performance depends very much on

00:04:05,970 --> 00:04:11,090
the computer architecture and that that

00:04:08,250 --> 00:04:13,739
will be the main point of my talk today

00:04:11,090 --> 00:04:16,259
in my in my opinion exists in Python

00:04:13,739 --> 00:04:17,849
libraries need to invest more effort in

00:04:16,259 --> 00:04:22,370
getting the most out of the Sistine and

00:04:17,849 --> 00:04:22,370
prettier future computer architectures

00:04:23,949 --> 00:04:29,599
also let me be clear about the meaning

00:04:27,380 --> 00:04:32,960
of my talk I mean I am NOT going to talk

00:04:29,599 --> 00:04:37,160
about how to store and analyze data in

00:04:32,960 --> 00:04:40,910
big big clusters of farms of big

00:04:37,160 --> 00:04:43,180
clusters in my opinion this is not

00:04:40,910 --> 00:04:47,120
exactly the needs of Python I mean the

00:04:43,180 --> 00:04:50,599
real workhorse of Python it's been able

00:04:47,120 --> 00:04:54,050
to work on big service maybe but

00:04:50,599 --> 00:04:57,409
especially a mostly in black tops okay a

00:04:54,050 --> 00:05:00,229
lot of people is using Python in their

00:04:57,409 --> 00:05:06,680
own laptops and my goal is to try to

00:05:00,229 --> 00:05:12,880
help them in order to work with more

00:05:06,680 --> 00:05:12,880
data using using laptops or big servers

00:05:13,060 --> 00:05:18,620
but try and optimize for laptops or

00:05:16,159 --> 00:05:20,659
service doesn't mean that this is going

00:05:18,620 --> 00:05:22,310
to be a trivial task because these

00:05:20,659 --> 00:05:25,490
laptops modern laptops and other

00:05:22,310 --> 00:05:29,090
services are very very complex beasts

00:05:25,490 --> 00:05:31,699
okay we had to leverage all we have to

00:05:29,090 --> 00:05:34,880
understand how the architecture is is

00:05:31,699 --> 00:05:38,949
designed how to access memory how the

00:05:34,880 --> 00:05:43,570
different crashes work a lot of things

00:05:38,949 --> 00:05:47,300
so let's have a look at the current

00:05:43,570 --> 00:05:50,630
architectures okay and see how this

00:05:47,300 --> 00:05:56,780
architecture should be leveraged in

00:05:50,630 --> 00:05:58,669
order to design new data structures the

00:05:56,780 --> 00:06:03,860
new trends in computer architecture are

00:05:58,669 --> 00:06:06,560
mainly driving by the the nanotechnology

00:06:03,860 --> 00:06:11,530
okay I think it's very interesting to

00:06:06,560 --> 00:06:16,069
see how Richard Feynman predicted the

00:06:11,530 --> 00:06:19,280
nanotechnology explosion as soon as like

00:06:16,069 --> 00:06:23,380
almost 50 years ago so i think it's it's

00:06:19,280 --> 00:06:26,780
nice for you to check this this talk

00:06:23,380 --> 00:06:29,449
anyway so i think that the most

00:06:26,780 --> 00:06:33,430
important thing with memory protector

00:06:29,449 --> 00:06:35,419
nowadays is the difference in speed

00:06:33,430 --> 00:06:36,620
devolution in speed between memory

00:06:35,419 --> 00:06:39,889
access time versus

00:06:36,620 --> 00:06:44,870
p you cycle time we know that the CPUs

00:06:39,889 --> 00:06:49,639
are are getting faster and faster and in

00:06:44,870 --> 00:06:52,130
fact they speed growls up almost in

00:06:49,639 --> 00:06:57,320
Aspen intial way not exponential but

00:06:52,130 --> 00:07:00,470
close so the more the more law but in

00:06:57,320 --> 00:07:03,860
contrast the memory speed is increasing

00:07:00,470 --> 00:07:05,389
very slowly very very slowly and this is

00:07:03,860 --> 00:07:08,780
creating a big gap a big mismatch

00:07:05,389 --> 00:07:14,780
between CPU speed and memory speed right

00:07:08,780 --> 00:07:18,710
and this and this is very important key

00:07:14,780 --> 00:07:21,740
on devolution architectures so we wish

00:07:18,710 --> 00:07:25,370
we see the revolutionary architectures

00:07:21,740 --> 00:07:28,010
we can see that in the 80s for example

00:07:25,370 --> 00:07:30,530
the architecture the memory architecture

00:07:28,010 --> 00:07:33,889
of of the machines of the or of the

00:07:30,530 --> 00:07:36,919
computers was very simple okay just a

00:07:33,889 --> 00:07:40,520
couple of memory layers then main memory

00:07:36,919 --> 00:07:44,090
and the mechanical disc then in the 90s

00:07:40,520 --> 00:07:46,490
or 2000 vendors realized this problem

00:07:44,090 --> 00:07:48,770
between the mismatch between the memory

00:07:46,490 --> 00:07:51,410
and the cpu speed and they started

00:07:48,770 --> 00:07:54,530
introduce the two additional levels in

00:07:51,410 --> 00:07:57,650
the in the disappears of cash okay and

00:07:54,530 --> 00:08:01,490
nowadays in this decade is very useful

00:07:57,650 --> 00:08:04,639
to have up to six layers of memory okay

00:08:01,490 --> 00:08:06,979
so this is a big change in the paradigm

00:08:04,639 --> 00:08:11,210
and it's not the same thing to program

00:08:06,979 --> 00:08:17,300
for a for a machine in the in the the

00:08:11,210 --> 00:08:20,120
2010 than for a machine in the 80s so in

00:08:17,300 --> 00:08:22,669
order to understand how we can adapt

00:08:20,120 --> 00:08:25,070
better to the new architectures it's

00:08:22,669 --> 00:08:27,320
important to know the difference between

00:08:25,070 --> 00:08:30,560
reference time and transmission time so

00:08:27,320 --> 00:08:35,930
let me splain so when the cpu as for a

00:08:30,560 --> 00:08:39,860
for a for a block of data in memory the

00:08:35,930 --> 00:08:42,140
time that it takes from the cpu request

00:08:39,860 --> 00:08:45,890
until the memories starting to transmit

00:08:42,140 --> 00:08:49,910
the data it is called the reference time

00:08:45,890 --> 00:08:50,500
okay or others call it latin seen as

00:08:49,910 --> 00:08:54,290
well

00:08:50,500 --> 00:08:57,019
and then the time that it takes once the

00:08:54,290 --> 00:09:00,950
request has been received and the

00:08:57,019 --> 00:09:03,880
transmission starts to start and until

00:09:00,950 --> 00:09:07,130
it ends it is called a transmission time

00:09:03,880 --> 00:09:08,959
the thing is you have have a big

00:09:07,130 --> 00:09:11,209
mismatch between the reference time and

00:09:08,959 --> 00:09:13,790
transmission time you are kind you are

00:09:11,209 --> 00:09:17,209
not doing an optimized access to your

00:09:13,790 --> 00:09:18,920
data so the interest and the idea is

00:09:17,209 --> 00:09:20,449
that the reference time and the

00:09:18,920 --> 00:09:27,110
transmission time should be more or less

00:09:20,449 --> 00:09:29,209
in the same order okay but of course not

00:09:27,110 --> 00:09:31,190
all storage layers are created equal

00:09:29,209 --> 00:09:34,100
that means for example that in memory

00:09:31,190 --> 00:09:37,279
which has a reference time typically of

00:09:34,100 --> 00:09:39,769
100 nanoseconds we can transfer up to

00:09:37,279 --> 00:09:44,570
one kilobyte in this in this amount of

00:09:39,769 --> 00:09:46,639
time but for solid state disks we where

00:09:44,570 --> 00:09:50,810
the reference time is 10 microseconds we

00:09:46,639 --> 00:09:52,760
can transfer up to 4 kilobytes ok using

00:09:50,810 --> 00:09:56,839
the same the same time and for

00:09:52,760 --> 00:09:58,040
mechanical disks this block typically

00:09:56,839 --> 00:10:02,600
the reference time is around 10

00:09:58,040 --> 00:10:05,860
milliseconds and the transparent the the

00:10:02,600 --> 00:10:09,079
transfer of the transferred block

00:10:05,860 --> 00:10:11,690
permission time allows to transfer you

00:10:09,079 --> 00:10:13,279
one mega up to one megabyte so the thing

00:10:11,690 --> 00:10:15,430
is that there's lower the media the

00:10:13,279 --> 00:10:18,230
larger the block that should be

00:10:15,430 --> 00:10:20,930
transmitted in order to optimize the

00:10:18,230 --> 00:10:22,880
memory access and again this has

00:10:20,930 --> 00:10:29,630
profound implications on how to access

00:10:22,880 --> 00:10:32,209
storage as we will see soon let me

00:10:29,630 --> 00:10:36,290
finish this part with some trends on

00:10:32,209 --> 00:10:39,500
storage the clear thing is that as we

00:10:36,290 --> 00:10:44,750
have seen the gap between between memory

00:10:39,500 --> 00:10:48,490
and permanent storage her disk is is is

00:10:44,750 --> 00:10:51,500
large and it's eating it's growing right

00:10:48,490 --> 00:10:54,769
now and that means that in order to

00:10:51,500 --> 00:10:57,319
fulfill or two to fill this gap vendors

00:10:54,769 --> 00:11:02,600
are not creating just SS the devices

00:10:57,319 --> 00:11:03,840
that had the same the same interfaces

00:11:02,600 --> 00:11:05,910
and her disks

00:11:03,840 --> 00:11:08,640
than typical harddisk vendors are

00:11:05,910 --> 00:11:13,310
starting to create or to put solid-state

00:11:08,640 --> 00:11:18,740
memory in buses like piss pc pc I and

00:11:13,310 --> 00:11:20,850
also it new protocols are or new

00:11:18,740 --> 00:11:23,250
specifications are being started to

00:11:20,850 --> 00:11:25,800
create two to be introduced in order to

00:11:23,250 --> 00:11:28,680
put all these solid state memory in

00:11:25,800 --> 00:11:30,870
laptops so in your lung on laptop will

00:11:28,680 --> 00:11:34,350
be able to access oi test a memory at

00:11:30,870 --> 00:11:38,130
pci speeds which is very different to

00:11:34,350 --> 00:11:44,460
access solid-state disk via SATA the

00:11:38,130 --> 00:11:46,650
traditional SATA bus and also the

00:11:44,460 --> 00:11:49,410
transverse CPUs is that we are going to

00:11:46,650 --> 00:11:50,670
see more course of course wider vector

00:11:49,410 --> 00:11:53,940
for doing simple instruction multiple

00:11:50,670 --> 00:11:57,060
data and we are going well we have seen

00:11:53,940 --> 00:11:59,730
already integration of the GPUs and the

00:11:57,060 --> 00:12:01,920
CPUs in the same time and these are the

00:11:59,730 --> 00:12:08,340
trend that we should be we sit have in

00:12:01,920 --> 00:12:12,150
mind in order to define or your tool to

00:12:08,340 --> 00:12:15,480
produce aware new data containers so

00:12:12,150 --> 00:12:19,560
what I'm going to do is to show you an

00:12:15,480 --> 00:12:24,270
example of implementation that data

00:12:19,560 --> 00:12:29,010
containers that leverage this this this

00:12:24,270 --> 00:12:33,720
this new computer architectures so big

00:12:29,010 --> 00:12:34,860
calls it's it provides data containers

00:12:33,720 --> 00:12:36,270
it's a library that provides data

00:12:34,860 --> 00:12:39,620
containers that can be used in a similar

00:12:36,270 --> 00:12:43,290
way than numpy pandas di'int or others

00:12:39,620 --> 00:12:45,380
and in because data storage tank not

00:12:43,290 --> 00:12:49,890
contiguous and tank can be compressed

00:12:45,380 --> 00:12:53,160
and there are two flavors one is CRA

00:12:49,890 --> 00:12:55,850
which is meant to host homogeneous types

00:12:53,160 --> 00:12:57,450
and in dimensional data

00:12:55,850 --> 00:13:00,360
multi-dimensional data and then see

00:12:57,450 --> 00:13:07,200
table for a TD genotypes in cologne our

00:13:00,360 --> 00:13:11,070
way is I am going to skip some slides

00:13:07,200 --> 00:13:13,200
slides because I am a little bit short

00:13:11,070 --> 00:13:15,690
of time don't be worried the important

00:13:13,200 --> 00:13:17,730
thing that I want to transmit will be

00:13:15,690 --> 00:13:22,199
the consequences

00:13:17,730 --> 00:13:24,690
of using this dis containers so I'm not

00:13:22,199 --> 00:13:26,279
going to explain in detail the

00:13:24,690 --> 00:13:29,329
difference between contiguous and child

00:13:26,279 --> 00:13:32,940
the only thing that is important is that

00:13:29,329 --> 00:13:34,889
chunky knits important it is it's nice

00:13:32,940 --> 00:13:36,899
because it allows to efficient and large

00:13:34,889 --> 00:13:39,959
enough linking compression is possible

00:13:36,899 --> 00:13:41,490
and in addition to chunk size can be

00:13:39,959 --> 00:13:42,959
adapted to the storage layer do you

00:13:41,490 --> 00:13:45,149
remember that depending on the storage

00:13:42,959 --> 00:13:47,310
layer that you are going to use the

00:13:45,149 --> 00:13:50,480
Chang size should be different right so

00:13:47,310 --> 00:13:53,459
a junk in storage allows you to

00:13:50,480 --> 00:13:59,639
fine-tune the chunk size for your own

00:13:53,459 --> 00:14:01,709
needs so it has another other advantages

00:13:59,639 --> 00:14:04,760
like a pending is much much much faster

00:14:01,709 --> 00:14:08,579
you don't need a copy when you are doing

00:14:04,760 --> 00:14:12,750
a nap in operation on a big old

00:14:08,579 --> 00:14:16,560
container less memory travels to cpu and

00:14:12,750 --> 00:14:20,670
also the table container implemented in

00:14:16,560 --> 00:14:23,610
because is columnar so columnar means

00:14:20,670 --> 00:14:26,160
that the data in columns are next in

00:14:23,610 --> 00:14:30,990
memory okay so when you want to fetch a

00:14:26,160 --> 00:14:34,589
record to a column they are the only

00:14:30,990 --> 00:14:39,120
information that you need to transfer so

00:14:34,589 --> 00:14:42,120
this is the a tip at the case of table

00:14:39,120 --> 00:14:44,519
that is row row wise okay store it in a

00:14:42,120 --> 00:14:46,860
row wise fashion and if you're

00:14:44,519 --> 00:14:49,170
interested in this column in 32 for

00:14:46,860 --> 00:14:51,420
example you are going to transfer much

00:14:49,170 --> 00:14:54,019
more data into the CPU just because of a

00:14:51,420 --> 00:14:58,230
collector of reasons this is how our

00:14:54,019 --> 00:15:01,920
computer works right now on a memory

00:14:58,230 --> 00:15:03,899
column why on a column wise table if you

00:15:01,920 --> 00:15:05,880
are interested in just one color you are

00:15:03,899 --> 00:15:08,880
going to grab only that column and

00:15:05,880 --> 00:15:10,440
transfer it into the cache okay so that

00:15:08,880 --> 00:15:17,010
means also less memory travels to the

00:15:10,440 --> 00:15:20,730
CPU also why compression well the first

00:15:17,010 --> 00:15:25,680
thing is that it allows to store more

00:15:20,730 --> 00:15:28,709
data in memory or disk but after another

00:15:25,680 --> 00:15:31,170
another goal is that if your latest

00:15:28,709 --> 00:15:34,709
compressed maybe may

00:15:31,170 --> 00:15:37,740
it would be better to have this data

00:15:34,709 --> 00:15:39,600
compressed in memory or on disk transfer

00:15:37,740 --> 00:15:42,779
the compressed data into the cash and

00:15:39,600 --> 00:15:44,550
the compress it and maybe this the sum

00:15:42,779 --> 00:15:46,410
of this transmission time and this

00:15:44,550 --> 00:15:48,540
decompression time could be faster in

00:15:46,410 --> 00:15:51,449
some situations than the time that it

00:15:48,540 --> 00:15:56,399
takes to transmit the original data set

00:15:51,449 --> 00:15:58,529
into them into the crashes and at the

00:15:56,399 --> 00:16:00,839
goal applause which is the compressor

00:15:58,529 --> 00:16:04,500
that it uses because behind the scenes

00:16:00,839 --> 00:16:07,949
ok blast the goal is to be faster than a

00:16:04,500 --> 00:16:10,860
mem cpy it uses as a series of

00:16:07,949 --> 00:16:13,699
techniques that I know not going to

00:16:10,860 --> 00:16:16,769
describe but basically leverages new

00:16:13,699 --> 00:16:20,130
architectures in this case for example

00:16:16,769 --> 00:16:23,600
we can see blask decompressing five up

00:16:20,130 --> 00:16:26,459
to five times faster than iming city why

00:16:23,600 --> 00:16:31,079
I'm not going to describe how law works

00:16:26,459 --> 00:16:36,000
there are other talks about this and the

00:16:31,079 --> 00:16:39,420
main the main place to reduce blood is

00:16:36,000 --> 00:16:41,250
basically to accelerate the input output

00:16:39,420 --> 00:16:43,350
not only mechanical this but especially

00:16:41,250 --> 00:16:51,660
on the solid state disks and main memory

00:16:43,350 --> 00:16:54,480
block it's its library latency and it is

00:16:51,660 --> 00:16:56,760
white widely used and especially it is

00:16:54,480 --> 00:17:00,510
it has been used for example in open VDB

00:16:56,760 --> 00:17:03,120
and Houdini which is a library for

00:17:00,510 --> 00:17:07,339
producing animation 3d animation movies

00:17:03,120 --> 00:17:09,900
and maintained by DreamWorks thank you

00:17:07,339 --> 00:17:12,839
there are a series of projects using be

00:17:09,900 --> 00:17:15,720
calls already for example visual fabrics

00:17:12,839 --> 00:17:19,350
bigquery which is meant to do to produce

00:17:15,720 --> 00:17:21,449
out of Koree group buys but on disk not

00:17:19,350 --> 00:17:23,669
in memory because we call supports both

00:17:21,449 --> 00:17:26,819
containers on disk in on this cannon

00:17:23,669 --> 00:17:30,900
memory also continuous blaze is using

00:17:26,819 --> 00:17:36,360
because cuanto pian also has they are

00:17:30,900 --> 00:17:41,480
very excited about using because i'm

00:17:36,360 --> 00:17:41,480
going to skip that I mean this are

00:17:42,639 --> 00:17:48,979
plot where people is showing fall

00:17:45,739 --> 00:17:56,239
because can beat a mono or SD fight for

00:17:48,979 --> 00:18:00,830
their own use cases of course and i'm

00:17:56,239 --> 00:18:03,979
going to close the talk we're saying

00:18:00,830 --> 00:18:07,070
that well justice are that there is a

00:18:03,979 --> 00:18:10,099
data container that fits your needs and

00:18:07,070 --> 00:18:12,859
and this container should be already out

00:18:10,099 --> 00:18:15,589
there ok so my advice is always for you

00:18:12,859 --> 00:18:18,489
to check the existing libraries and to

00:18:15,589 --> 00:18:21,169
choose the one that fits your needs and

00:18:18,489 --> 00:18:25,070
sometimes you can get you can be

00:18:21,169 --> 00:18:26,659
surprised and depending on the stretch

00:18:25,070 --> 00:18:28,999
data structure that you use in your

00:18:26,659 --> 00:18:31,549
using you can get much more performance

00:18:28,999 --> 00:18:36,289
not because of the oven but because of

00:18:31,549 --> 00:18:38,539
the data structure data container also

00:18:36,289 --> 00:18:40,009
you should pay attention to hardware and

00:18:38,539 --> 00:18:41,869
software trends and make informed

00:18:40,009 --> 00:18:43,639
decisions about your current development

00:18:41,869 --> 00:18:50,330
which by the way will be deployed in the

00:18:43,639 --> 00:18:52,190
future so it's important that you are

00:18:50,330 --> 00:18:55,249
conscious about the new computer

00:18:52,190 --> 00:18:57,589
architectures because you are going to

00:18:55,249 --> 00:19:00,679
use them all your applications is going

00:18:57,589 --> 00:19:03,460
to use them and finally in my opinion

00:19:00,679 --> 00:19:07,339
complete compression well I think I

00:19:03,460 --> 00:19:09,320
think I many people I see seen that

00:19:07,339 --> 00:19:12,169
already compression is a useful feature

00:19:09,320 --> 00:19:15,200
not only to store more data but also to

00:19:12,169 --> 00:19:21,529
process data faster under the right the

00:19:15,200 --> 00:19:26,359
right conditions ok so let me conclude

00:19:21,529 --> 00:19:30,679
my talk with my own version of a code by

00:19:26,359 --> 00:19:35,889
Isaac Asimov which I I was a huge fan

00:19:30,679 --> 00:19:38,749
when I was a teenager so it is change

00:19:35,889 --> 00:19:40,309
continuing change and inevitable change

00:19:38,749 --> 00:19:43,909
that is the dominant factor in computer

00:19:40,309 --> 00:19:45,679
science and in my opinion not sensible

00:19:43,909 --> 00:19:47,929
decision can be made any longer without

00:19:45,679 --> 00:19:50,809
taking into account not only the

00:19:47,929 --> 00:19:53,859
computer as it is now but the computer

00:19:50,809 --> 00:19:53,859
as it will be

00:19:54,119 --> 00:20:09,019
okay so thank you very much questions

00:20:09,529 --> 00:20:16,049
okay right yeah I saw happen on

00:20:13,319 --> 00:20:20,519
management I will be talking about the

00:20:16,049 --> 00:20:23,339
continuation we get a question okay yeah

00:20:20,519 --> 00:20:25,949
just maybe because there are some graphs

00:20:23,339 --> 00:20:28,859
about this but just to know for example

00:20:25,949 --> 00:20:30,539
it was some comparison with there

00:20:28,859 --> 00:20:32,789
are some like for example blog very

00:20:30,539 --> 00:20:35,429
snappy so I don't know to which

00:20:32,789 --> 00:20:37,189
reference it is just like because I

00:20:35,429 --> 00:20:40,679
haven't heard so much about it before

00:20:37,189 --> 00:20:43,709
yeah if you what you know or what you

00:20:40,679 --> 00:20:46,289
see as difference for similar patterns

00:20:43,709 --> 00:20:48,659
that were tried by other persons just if

00:20:46,289 --> 00:20:50,249
you have some comparisons if you have

00:20:48,659 --> 00:20:53,189
some advantages of the technologies you

00:20:50,249 --> 00:20:56,939
presented so you mean that moment was

00:20:53,189 --> 00:20:58,409
using a snappy right ya voy a tiger for

00:20:56,939 --> 00:21:00,899
one storage engine for example they're

00:20:58,409 --> 00:21:03,419
using snappy or dead lip but snap yes

00:21:00,899 --> 00:21:04,379
faster for compressing for example but

00:21:03,419 --> 00:21:08,069
there are other things there's also

00:21:04,379 --> 00:21:09,809
rocks DB for this use means that's a

00:21:08,069 --> 00:21:12,679
good question and because as I said

00:21:09,809 --> 00:21:15,509
before it uses a block behind the scenes

00:21:12,679 --> 00:21:16,829
blog is I said that this is it is a

00:21:15,509 --> 00:21:18,839
compressor but it was an

00:21:16,829 --> 00:21:21,209
oversimplification block is actually a

00:21:18,839 --> 00:21:23,519
meta compression so bloss can use

00:21:21,209 --> 00:21:25,229
different compressors and in

00:21:23,519 --> 00:21:28,859
particularly can use snappy behind the

00:21:25,229 --> 00:21:31,859
scenes you can use that lip lc4 which is

00:21:28,859 --> 00:21:33,509
the kind of new trend in compression

00:21:31,859 --> 00:21:36,209
because it's very fast and compresses

00:21:33,509 --> 00:21:38,609
very well as well and also is also has

00:21:36,209 --> 00:21:41,099
support for blood loss LZ so you have a

00:21:38,609 --> 00:21:45,869
range of compressor that you can use in

00:21:41,099 --> 00:21:48,619
order to tailor or to the fine tuned for

00:21:45,869 --> 00:21:48,619
your applications

00:21:53,620 --> 00:21:59,570
maybe silly question I've just been to a

00:21:56,090 --> 00:22:02,930
talk on number and they claim to to

00:21:59,570 --> 00:22:06,500
speed up numpy and stuff like that does

00:22:02,930 --> 00:22:09,230
because work with the number yes I mean

00:22:06,500 --> 00:22:11,780
yeah because it's only providing the

00:22:09,230 --> 00:22:14,240
data layer I'm at the data structure

00:22:11,780 --> 00:22:17,900
right on top of the data structure it

00:22:14,240 --> 00:22:24,050
provides very few machinery just provide

00:22:17,900 --> 00:22:26,360
some Sam for example the Sun function

00:22:24,050 --> 00:22:29,060
but they're a little so the idea is to

00:22:26,360 --> 00:22:31,130
use because for example and on top of

00:22:29,060 --> 00:22:34,880
that you can put number for example for

00:22:31,130 --> 00:22:37,850
doing for doing computations but you can

00:22:34,880 --> 00:22:40,070
also put dash for example which is a way

00:22:37,850 --> 00:22:43,700
to do populations in parallel as well

00:22:40,070 --> 00:22:47,540
and you can put whatever because it's

00:22:43,700 --> 00:22:50,120
providing a generator interface so that

00:22:47,540 --> 00:22:52,700
other other layers on top can leverage

00:22:50,120 --> 00:22:55,970
that you are not bound to use big halls

00:22:52,700 --> 00:22:57,890
infrastructure because machinery for

00:22:55,970 --> 00:23:02,660
doing computation but it only provides

00:22:57,890 --> 00:23:05,990
the storage layer solution I get a

00:23:02,660 --> 00:23:09,770
related question and Kelly's pendants

00:23:05,990 --> 00:23:12,020
with because as the storage engine sorry

00:23:09,770 --> 00:23:17,260
can you repeat can you use pendas with

00:23:12,020 --> 00:23:20,360
Pickers as a storage engine with us a

00:23:17,260 --> 00:23:22,760
comparison with pandas not a comparison

00:23:20,360 --> 00:23:27,050
but can he spend us like all the API of

00:23:22,760 --> 00:23:30,380
painters and still have pickles as the

00:23:27,050 --> 00:23:32,270
storage engine at the story changes yes

00:23:30,380 --> 00:23:34,490
exactly that's another application for

00:23:32,270 --> 00:23:38,000
example yes and for example I've seen

00:23:34,490 --> 00:23:39,950
some references by Jeff I don't remember

00:23:38,000 --> 00:23:44,930
his name the current maintainer of

00:23:39,950 --> 00:23:46,790
pandas yeah he's trying to see for

00:23:44,930 --> 00:23:50,540
example pandas can support different

00:23:46,790 --> 00:23:53,750
backends like a sequel databases or hdf5

00:23:50,540 --> 00:23:56,900
and because can be another backend for

00:23:53,750 --> 00:24:00,400
for pandas itself yes so it can be but

00:23:56,900 --> 00:24:04,880
it isn't now no no I mean there is no

00:24:00,400 --> 00:24:08,300
miss in my in my knowledge there is no

00:24:04,880 --> 00:24:13,310
but I can for panda yet but it could it

00:24:08,300 --> 00:24:16,520
could be done hmm and of course no okay

00:24:13,310 --> 00:24:19,190
so this was everything thank you very

00:24:16,520 --> 00:24:22,250
much just let you know that this was the

00:24:19,190 --> 00:24:25,810
last talk of this room now there will be

00:24:22,250 --> 00:24:29,060
lightning talks at quarter past five and

00:24:25,810 --> 00:24:31,910
that's everything please go into the app

00:24:29,060 --> 00:24:34,520
guidebook and your mobile phones and

00:24:31,910 --> 00:24:37,010
ready talks you are attending to okay

00:24:34,520 --> 00:24:39,020
okay so before leaving just let me a

00:24:37,010 --> 00:24:42,220
quick reminder i will be driving a

00:24:39,020 --> 00:24:45,860
tutorial on wednesday i will be talking

00:24:42,220 --> 00:24:47,990
more about all these data containers and

00:24:45,860 --> 00:24:51,080
doing comparisons between becouse pandas

00:24:47,990 --> 00:24:53,180
storage layers numpy tis like that if

00:24:51,080 --> 00:24:56,380
you are interested please come with us

00:24:53,180 --> 00:24:56,380

YouTube URL: https://www.youtube.com/watch?v=-AlKImuKTcs


