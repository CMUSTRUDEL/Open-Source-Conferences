Title: Anton Caceres - Better asynchronous code with Tornado and Python 3
Publication date: 2015-08-08
Playlist: EuroPython 2015
Description: 
	Anton Caceres - Better asynchronous code with Tornado and Python 3
[EuroPython 2015]
[23 July 2015]
[Bilbao, Euskadi, Spain]

The asyncio module introduced in Python 3.4 is a game-changer for I/O
management and event-driven network programming in Python. Aiming to
be a lower-level implementation of an asynchronous event loop, it
intends that higher level frameworks like Tornado, Twisted or Gevent
will build on top of it, taking advantage of the shared interface for
writing concurrent event-driven code across different Python
frameworks.

This talk connects theory with practice, presenting how Tornado can
run in the asyncio event loop and take advantage of the subgenerator
delegation syntax (yield from) to provide a high degree of concurrency
while keeping the simplicity of sequential code. It explains the
concept of coroutines, futures and ioloop, exposing Python 3 code for
sample web tasks. The talk completes with a basic demo of running this
code on Tornado, comparing its syntax and performance with popular
asynchronous frameworks from other languages.
Captions: 
	00:00:03,470 --> 00:00:09,960
thank you guys thank you for coming

00:00:07,140 --> 00:00:13,019
after this tough party and stuff morning

00:00:09,960 --> 00:00:15,260
I hope I will not disappoint you I will

00:00:13,019 --> 00:00:18,720
try to not make you fall asleep

00:00:15,260 --> 00:00:21,720
therefore first couple of words how will

00:00:18,720 --> 00:00:24,180
we do this today so I have a 40 minute

00:00:21,720 --> 00:00:25,740
slot basically and I do not want you to

00:00:24,180 --> 00:00:29,310
wait till the end of the talk to ask

00:00:25,740 --> 00:00:31,320
questions please rise a hand at any

00:00:29,310 --> 00:00:33,149
point of time we will try to make this

00:00:31,320 --> 00:00:35,700
interactive so of course I have the

00:00:33,149 --> 00:00:37,350
microphone so I'm the boss now but

00:00:35,700 --> 00:00:40,530
you'll guess once you just raise your

00:00:37,350 --> 00:00:42,480
hands we have a nice discussion here so

00:00:40,530 --> 00:00:44,700
I talked to you today about the

00:00:42,480 --> 00:00:46,980
asynchronous web development and tornado

00:00:44,700 --> 00:00:48,750
in particularly how can we make it

00:00:46,980 --> 00:00:51,360
better with tools that come with Python

00:00:48,750 --> 00:00:53,309
3 first of all of course you'd have the

00:00:51,360 --> 00:00:55,680
question who is this guy and what does

00:00:53,309 --> 00:00:57,360
he know to present such stuff so I'm

00:00:55,680 --> 00:01:00,000
just as you just the Python developer

00:00:57,360 --> 00:01:03,270
and I work with Python for like 5 years

00:01:00,000 --> 00:01:06,360
more or less I love it I love it so much

00:01:03,270 --> 00:01:08,939
that I started the PI Munich group that

00:01:06,360 --> 00:01:10,920
is making workshops in Munich and we are

00:01:08,939 --> 00:01:13,140
trying to get more people into Python I

00:01:10,920 --> 00:01:14,939
love it so much that of course they work

00:01:13,140 --> 00:01:17,280
with a company that is very Python

00:01:14,939 --> 00:01:21,900
friendly I'll say a couple of words

00:01:17,280 --> 00:01:24,180
about that too my company Scooby is a

00:01:21,900 --> 00:01:27,299
German ebook subscription service it

00:01:24,180 --> 00:01:30,570
offers lots of ebooks on the monthly

00:01:27,299 --> 00:01:32,759
subscription base like a flat rate we

00:01:30,570 --> 00:01:35,670
have the native apps for Android and iOS

00:01:32,759 --> 00:01:37,229
and people like that apps because they

00:01:35,670 --> 00:01:38,820
put five-star ratings to them even

00:01:37,229 --> 00:01:39,270
though it costs money which is pretty

00:01:38,820 --> 00:01:42,479
cool

00:01:39,270 --> 00:01:44,820
of course being user friendly is nice

00:01:42,479 --> 00:01:47,399
but it's more important to be developer

00:01:44,820 --> 00:01:50,729
friendly so the stuff that I'm going to

00:01:47,399 --> 00:01:53,220
present you today is not some abstract

00:01:50,729 --> 00:01:55,049
blog post that I read a week ago this is

00:01:53,220 --> 00:01:59,219
stuff that runs in production for us for

00:01:55,049 --> 00:02:02,189
years so real thing and basically it

00:01:59,219 --> 00:02:03,750
comes out of the problems that we had so

00:02:02,189 --> 00:02:06,899
I'm presenting user solutions that are

00:02:03,750 --> 00:02:08,849
already deployed there and as I said the

00:02:06,899 --> 00:02:12,640
company runs Python as the main language

00:02:08,849 --> 00:02:14,890
we also like very much to

00:02:12,640 --> 00:02:15,670
participate in Python events share our

00:02:14,890 --> 00:02:18,250
knowledge Asst

00:02:15,670 --> 00:02:19,900
we are sponsoring European and also

00:02:18,250 --> 00:02:23,620
other Python events in Germany

00:02:19,900 --> 00:02:25,900
especially and let's move to the

00:02:23,620 --> 00:02:26,620
challenges that we have from one day to

00:02:25,900 --> 00:02:29,890
another

00:02:26,620 --> 00:02:32,350
that's lead us to these solutions so

00:02:29,890 --> 00:02:35,110
first we have a very distributed system

00:02:32,350 --> 00:02:36,910
meaning that we have not just one server

00:02:35,110 --> 00:02:39,160
we have many services that need to

00:02:36,910 --> 00:02:43,930
communicate over the network over some

00:02:39,160 --> 00:02:46,300
api's most HTTP api so we learned by

00:02:43,930 --> 00:02:48,540
time that doing that asynchronously

00:02:46,300 --> 00:02:51,520
obviously makes it way more efficient

00:02:48,540 --> 00:02:54,790
therefore we could not use just nice and

00:02:51,520 --> 00:02:57,100
fancy django because internally that

00:02:54,790 --> 00:02:59,470
would be not very performance we are

00:02:57,100 --> 00:03:03,400
trying to build tools that speak to each

00:02:59,470 --> 00:03:05,620
other a synchronously and efficiently we

00:03:03,400 --> 00:03:09,250
also on our way to migrate into Python 3

00:03:05,620 --> 00:03:11,050
like probably most of you guys of course

00:03:09,250 --> 00:03:13,270
it's not that easy but some others run

00:03:11,050 --> 00:03:16,060
Python 3 some models still run Python 2

00:03:13,270 --> 00:03:18,580
most of them actually of course so it's

00:03:16,060 --> 00:03:20,230
also a bit of a challenge and we see

00:03:18,580 --> 00:03:24,700
what tools are already usable with

00:03:20,230 --> 00:03:26,620
Python 3 what tools are not we'll have

00:03:24,700 --> 00:03:29,769
to share and this presentation will be

00:03:26,620 --> 00:03:32,320
basically fully practice based this is

00:03:29,769 --> 00:03:34,360
the overview first I'll speak to you

00:03:32,320 --> 00:03:36,850
guys again why do we need this in chrono

00:03:34,360 --> 00:03:40,269
stuff at all and when do we need it

00:03:36,850 --> 00:03:42,340
second how generator delegation syntax

00:03:40,269 --> 00:03:45,340
introduced in Python 3 makes it easier

00:03:42,340 --> 00:03:48,910
and nicer then of course they stink i/o

00:03:45,340 --> 00:03:50,590
this is tool that we heard already on

00:03:48,910 --> 00:03:52,780
this conference wonderful talks by the

00:03:50,590 --> 00:03:54,400
way I'm going to just quickly cover it

00:03:52,780 --> 00:03:57,880
again in case someone is still missing

00:03:54,400 --> 00:03:59,950
this information the internet Oh which

00:03:57,880 --> 00:04:02,260
is the real framer the kind that can be

00:03:59,950 --> 00:04:05,590
usable together with a sinker already at

00:04:02,260 --> 00:04:07,510
this point of time major thing ready for

00:04:05,590 --> 00:04:10,120
production and I'll show you guys a

00:04:07,510 --> 00:04:12,340
little demo of not just tornado of also

00:04:10,120 --> 00:04:17,290
other frameworks how do they perform a

00:04:12,340 --> 00:04:20,489
synchronously together what issues do

00:04:17,290 --> 00:04:20,489
they have comparing to each other

00:04:24,360 --> 00:04:31,500
well I want these to be on the recording

00:04:27,969 --> 00:04:34,080
so doesn't matter much but again good so

00:04:31,500 --> 00:04:38,439
why do we need the synchronous

00:04:34,080 --> 00:04:40,990
communication at all let's have a little

00:04:38,439 --> 00:04:46,030
recap of the web server execution models

00:04:40,990 --> 00:04:49,330
like how how can it work the first

00:04:46,030 --> 00:04:51,039
original idea was to have one thread per

00:04:49,330 --> 00:04:53,439
connection right this is very

00:04:51,039 --> 00:04:55,960
straightforward we have clients coming

00:04:53,439 --> 00:04:58,270
in we create a thread for it we handle

00:04:55,960 --> 00:05:00,069
requests on this thread it's very easy

00:04:58,270 --> 00:05:03,789
very straight it's very easy to share

00:05:00,069 --> 00:05:06,430
the memory we have any show obviously ok

00:05:03,789 --> 00:05:11,199
guys who have seen the threaded web

00:05:06,430 --> 00:05:13,479
server dying anyone okay so this is not

00:05:11,199 --> 00:05:15,310
just me which is good

00:05:13,479 --> 00:05:17,560
threaded web server runs in obvious

00:05:15,310 --> 00:05:21,370
issues when operating system goes out of

00:05:17,560 --> 00:05:24,370
the memory first can do evil things to

00:05:21,370 --> 00:05:26,379
you and the worst is that when our

00:05:24,370 --> 00:05:29,229
system is overloaded not only the new

00:05:26,379 --> 00:05:30,789
clients will experience bad service but

00:05:29,229 --> 00:05:33,520
also existing ones so the whole thing

00:05:30,789 --> 00:05:37,539
crashes total disaster so what would be

00:05:33,520 --> 00:05:40,629
the logical step to fix this issue well

00:05:37,539 --> 00:05:42,819
it would obviously be to have a pool on

00:05:40,629 --> 00:05:44,800
the threaded server that would limit the

00:05:42,819 --> 00:05:46,960
amount of threads or processes doesn't

00:05:44,800 --> 00:05:50,639
really matter in this case so by

00:05:46,960 --> 00:05:53,710
limiting the the thread pool we will not

00:05:50,639 --> 00:05:55,719
push our system into the state where it

00:05:53,710 --> 00:05:58,330
crashes right so we have a fixed number

00:05:55,719 --> 00:06:01,500
of threads when our system works fine

00:05:58,330 --> 00:06:04,120
when it's still performant and nobody

00:06:01,500 --> 00:06:06,250
experiences any problems with it but for

00:06:04,120 --> 00:06:08,949
some new clients that will join when our

00:06:06,250 --> 00:06:11,099
pool is already packed they will just

00:06:08,949 --> 00:06:14,650
have to wait and this is bad because

00:06:11,099 --> 00:06:16,449
obviously even if the thread pool is

00:06:14,650 --> 00:06:18,639
packed that does not mean that our

00:06:16,449 --> 00:06:20,319
system is already out of resources it

00:06:18,639 --> 00:06:22,839
just means that some number that we fix

00:06:20,319 --> 00:06:25,990
is reached but we might and we usually

00:06:22,839 --> 00:06:30,789
do have more resources to handle more

00:06:25,990 --> 00:06:32,480
clients so the next step was to have the

00:06:30,789 --> 00:06:35,990
a synchronous web server

00:06:32,480 --> 00:06:38,630
that has just one thread but it kind of

00:06:35,990 --> 00:06:41,600
turns the picture around turns it a bit

00:06:38,630 --> 00:06:44,480
upside down because this one thread has

00:06:41,600 --> 00:06:46,910
a loop and this I loop controls what

00:06:44,480 --> 00:06:50,330
clients is getting service at which

00:06:46,910 --> 00:06:53,150
points of time and since usually our web

00:06:50,330 --> 00:06:55,340
server our i/o bounds so we are not

00:06:53,150 --> 00:06:59,090
performing any heavy computation in our

00:06:55,340 --> 00:07:01,190
web applications most likely so our CPU

00:06:59,090 --> 00:07:02,930
is pretty ok our memory is also

00:07:01,190 --> 00:07:04,430
predefined we are waiting for something

00:07:02,930 --> 00:07:05,900
we're waiting for the database we're

00:07:04,430 --> 00:07:08,840
waiting for cash waiting for whatever

00:07:05,900 --> 00:07:11,090
thing and so the iya loop can actually

00:07:08,840 --> 00:07:13,490
decide at which point of time which

00:07:11,090 --> 00:07:15,770
client can get service and other client

00:07:13,490 --> 00:07:18,020
can just wait for data to be available

00:07:15,770 --> 00:07:20,030
on a particular socket and I look and

00:07:18,020 --> 00:07:24,320
jungle this connection jungle the client

00:07:20,030 --> 00:07:27,440
and just yeah process every client at

00:07:24,320 --> 00:07:30,860
the right point of time so it does the

00:07:27,440 --> 00:07:32,360
event-driven switching in one thread but

00:07:30,860 --> 00:07:35,270
you say of course I think is not

00:07:32,360 --> 00:07:38,060
something new like this is not the first

00:07:35,270 --> 00:07:40,580
time of course this idea comes and rises

00:07:38,060 --> 00:07:42,890
up again so you are right because

00:07:40,580 --> 00:07:45,740
tornado is like six years old and there

00:07:42,890 --> 00:07:47,540
is also twisted through Python tool for

00:07:45,740 --> 00:07:50,570
the network I still think it's one of

00:07:47,540 --> 00:07:55,190
the best and there are also stuff in

00:07:50,570 --> 00:07:56,750
other languages obviously why we still

00:07:55,190 --> 00:07:59,600
use blocking servers and what's the

00:07:56,750 --> 00:08:02,420
problem because the quencher code is

00:07:59,600 --> 00:08:04,400
obviously way easier to read it's easier

00:08:02,420 --> 00:08:08,300
to test it's easier to maintain and

00:08:04,400 --> 00:08:09,740
extensive we have seen how django was

00:08:08,300 --> 00:08:11,060
successful how Ruby on Rails was

00:08:09,740 --> 00:08:13,490
successful just because of the

00:08:11,060 --> 00:08:17,420
simplicity and nice batteries of course

00:08:13,490 --> 00:08:19,880
so these things do matter and then

00:08:17,420 --> 00:08:22,730
obviously we think why can't we just

00:08:19,880 --> 00:08:24,650
have a synchronous codes to be

00:08:22,730 --> 00:08:26,750
structured and written in the way that

00:08:24,650 --> 00:08:27,260
it can be just readable as synchronous

00:08:26,750 --> 00:08:29,360
codes

00:08:27,260 --> 00:08:32,810
look similar without this callback hell

00:08:29,360 --> 00:08:35,270
and stuff and pythons really lets us do

00:08:32,810 --> 00:08:37,220
that this is something that I'm going to

00:08:35,270 --> 00:08:38,720
present you today this is just a little

00:08:37,220 --> 00:08:43,190
teaser obviously you're most likely

00:08:38,720 --> 00:08:45,779
already seen it but still this utrom is

00:08:43,190 --> 00:08:49,740
the generator sub-delegation syntax

00:08:45,779 --> 00:08:51,449
introduced in Python 3 and it lets us

00:08:49,740 --> 00:08:54,540
write a synchronous code in a

00:08:51,449 --> 00:08:59,009
synchronous fashion again I'll have this

00:08:54,540 --> 00:09:01,860
more details a bit later so now yield

00:08:59,009 --> 00:09:04,350
from it aims to replace callbacks but

00:09:01,860 --> 00:09:06,240
first we need to come to decision what's

00:09:04,350 --> 00:09:09,480
so bad about the callbacks like it's

00:09:06,240 --> 00:09:13,379
something pretty common it's in twisted

00:09:09,480 --> 00:09:16,980
since ages in JavaScript of course it's

00:09:13,379 --> 00:09:19,430
difficult to make it look nice there's

00:09:16,980 --> 00:09:23,639
any one of you guys work with JavaScript

00:09:19,430 --> 00:09:29,249
yeah obviously obviously okay so did you

00:09:23,639 --> 00:09:30,629
guys see this I also do JavaScript and

00:09:29,249 --> 00:09:32,459
they see it this is the real code

00:09:30,629 --> 00:09:34,860
besides it's some testing thing of

00:09:32,459 --> 00:09:38,279
course but still I mean even for testing

00:09:34,860 --> 00:09:40,079
I usually try to avoid this and by the

00:09:38,279 --> 00:09:42,540
way this is a nice resource called back

00:09:40,079 --> 00:09:44,279
hell dot-com so if there is such Dom and

00:09:42,540 --> 00:09:48,720
registered I assume that we are clear

00:09:44,279 --> 00:09:50,579
that we might want to avoid callbacks so

00:09:48,720 --> 00:09:54,180
sequential code obviously looks nicer

00:09:50,579 --> 00:09:58,800
and by introducing yield from in Python

00:09:54,180 --> 00:10:00,809
3 we have this attempt to write a

00:09:58,800 --> 00:10:04,620
synchronous codes on everyday basis

00:10:00,809 --> 00:10:07,319
without callback help now it's time for

00:10:04,620 --> 00:10:09,839
a good example so we have a very simple

00:10:07,319 --> 00:10:13,019
function let's say it's a get handler of

00:10:09,839 --> 00:10:14,730
whatever web framework we have a huge

00:10:13,019 --> 00:10:17,220
database query that is blocking

00:10:14,730 --> 00:10:19,589
obviously the result of that query is

00:10:17,220 --> 00:10:22,370
saved to the result variable and then we

00:10:19,589 --> 00:10:25,529
write this stuff back to the user

00:10:22,370 --> 00:10:26,399
this is blocking right how would we do

00:10:25,529 --> 00:10:28,769
it with callbacks

00:10:26,399 --> 00:10:32,279
so with callbacks we can define a

00:10:28,769 --> 00:10:34,800
function just nested or anywhere that

00:10:32,279 --> 00:10:36,569
will be a callback that will be passed

00:10:34,800 --> 00:10:39,240
as an argument to the huge database

00:10:36,569 --> 00:10:41,730
query and the huge database query will

00:10:39,240 --> 00:10:44,910
call it when the result is ready also

00:10:41,730 --> 00:10:46,529
pretty clear right this is not as bad as

00:10:44,910 --> 00:10:48,420
an example with Java scripts of course

00:10:46,529 --> 00:10:51,329
because at least it's not defined in

00:10:48,420 --> 00:10:53,129
line but still we can make it even

00:10:51,329 --> 00:10:56,850
better with the sub generator based

00:10:53,129 --> 00:11:00,420
Handler so we put yield from just before

00:10:56,850 --> 00:11:03,990
the huge database query hope you guys

00:11:00,420 --> 00:11:06,269
use this think I already saw that ok so

00:11:03,990 --> 00:11:09,540
that I know I stopped a bit on this then

00:11:06,269 --> 00:11:13,769
so what exactly does yield from do here

00:11:09,540 --> 00:11:15,779
so huge database query in this example

00:11:13,769 --> 00:11:17,759
should not return the result so it

00:11:15,779 --> 00:11:20,309
should not block it should return a

00:11:17,759 --> 00:11:22,980
future this is a magic object I'll speak

00:11:20,309 --> 00:11:25,860
about it in a moment but this magic

00:11:22,980 --> 00:11:27,779
object is like a promise that the real

00:11:25,860 --> 00:11:32,160
result will come at the later point and

00:11:27,779 --> 00:11:35,309
we healed this future back to our core

00:11:32,160 --> 00:11:37,439
routine to our i/o loop that will at

00:11:35,309 --> 00:11:39,899
this point switch to any other task that

00:11:37,439 --> 00:11:41,850
it has and whenever the results of the

00:11:39,899 --> 00:11:44,129
future is ready whenever future can be

00:11:41,850 --> 00:11:46,559
evaluated to the result it will push it

00:11:44,129 --> 00:11:49,379
back to this point as if you can imagine

00:11:46,559 --> 00:11:52,049
as yield from would never be there magic

00:11:49,379 --> 00:11:55,799
it will be saved to result and written

00:11:52,049 --> 00:11:57,870
back to the client so what is exactly

00:11:55,799 --> 00:12:01,410
this magic behind it and what async I

00:11:57,870 --> 00:12:04,410
owed us for this so as it was already

00:12:01,410 --> 00:12:06,779
taught a lot on this conference this is

00:12:04,410 --> 00:12:10,529
mostly the event loop and a set of tools

00:12:06,779 --> 00:12:12,449
to use this event loop efficiently event

00:12:10,529 --> 00:12:16,920
loop can register a callback for any

00:12:12,449 --> 00:12:20,129
particular any particular event let's

00:12:16,920 --> 00:12:22,980
say most typical case of course we want

00:12:20,129 --> 00:12:25,799
to get to fetch some network resource so

00:12:22,980 --> 00:12:28,740
we need to make the TCP connection and

00:12:25,799 --> 00:12:30,569
then we just wait so we tell our loop

00:12:28,740 --> 00:12:32,579
hey I hope when the data will be ready

00:12:30,569 --> 00:12:36,149
on this socket please call this function

00:12:32,579 --> 00:12:39,020
and it does that's in a glance what what

00:12:36,149 --> 00:12:43,209
do we need to know about it

00:12:39,020 --> 00:12:46,279
in this example I have a minimal setup

00:12:43,209 --> 00:12:48,260
how can we call it so we have a callback

00:12:46,279 --> 00:12:50,000
function hello Europe I hung it doesn't

00:12:48,260 --> 00:12:52,640
fetch anything it will just be called as

00:12:50,000 --> 00:12:55,430
soon as possible first we need to get

00:12:52,640 --> 00:12:58,430
the events loop instance then we

00:12:55,430 --> 00:13:00,649
schedule the callback by call soon

00:12:58,430 --> 00:13:02,930
Coulson is call at any point of time

00:13:00,649 --> 00:13:05,779
when you can and then we start the I

00:13:02,930 --> 00:13:09,230
loop that's a minimal example so no

00:13:05,779 --> 00:13:12,380
fetching on the socket nothing now to

00:13:09,230 --> 00:13:15,170
get more familiar with this thing let's

00:13:12,380 --> 00:13:18,740
talk a bit about the future object what

00:13:15,170 --> 00:13:20,240
exactly does it do so those of you at

00:13:18,740 --> 00:13:22,730
least who worked with JavaScript

00:13:20,240 --> 00:13:26,300
probably know the defer the promised

00:13:22,730 --> 00:13:28,610
objects most likely so this is a very

00:13:26,300 --> 00:13:33,140
similar thing so this is some object

00:13:28,610 --> 00:13:35,360
that packs a reference to the result we

00:13:33,140 --> 00:13:39,950
have this object just to track the state

00:13:35,360 --> 00:13:42,080
of the of the operations that we want to

00:13:39,950 --> 00:13:45,980
perform let's say we want to fetch the

00:13:42,080 --> 00:13:48,500
database query we call that query and

00:13:45,980 --> 00:13:50,779
the future object is just returns to

00:13:48,500 --> 00:13:53,000
keep a reference to the result it is not

00:13:50,779 --> 00:13:55,670
ready yet but will be ready at some

00:13:53,000 --> 00:13:57,980
point of time or it will fail so we have

00:13:55,670 --> 00:13:59,600
the future to keep the reference to

00:13:57,980 --> 00:14:01,970
something that will be available at

00:13:59,600 --> 00:14:07,550
later points of time so simplest way to

00:14:01,970 --> 00:14:10,130
run a future is just to use this run

00:14:07,550 --> 00:14:11,750
until complete on the IO loop and print

00:14:10,130 --> 00:14:13,310
the future result but this is usually of

00:14:11,750 --> 00:14:18,770
course not the case that we want we want

00:14:13,310 --> 00:14:20,450
it nice a synchronous so then we need to

00:14:18,770 --> 00:14:24,140
have a better syntax we can also yield

00:14:20,450 --> 00:14:26,420
it like here so we define a call routine

00:14:24,140 --> 00:14:29,060
it's also important to mark that

00:14:26,420 --> 00:14:30,380
whatever web framework you are using it

00:14:29,060 --> 00:14:32,480
has to know that you're using

00:14:30,380 --> 00:14:35,870
co-routines otherwise if it's just a

00:14:32,480 --> 00:14:38,810
generator so we are fetching for example

00:14:35,870 --> 00:14:41,089
Google Chrome the results will be a

00:14:38,810 --> 00:14:43,970
future then we yield this future are you

00:14:41,089 --> 00:14:46,370
loop does is a fetching and saves the

00:14:43,970 --> 00:14:48,589
result back to the result variable then

00:14:46,370 --> 00:14:50,640
we print it and of course to make this

00:14:48,589 --> 00:14:55,230
whole thing run we need to

00:14:50,640 --> 00:14:58,470
around the I loop so what about tornado

00:14:55,230 --> 00:15:00,600
here tornado is web framework that is

00:14:58,470 --> 00:15:03,630
already there for six years it has on

00:15:00,600 --> 00:15:05,519
all I elope it has own futures but now

00:15:03,630 --> 00:15:07,610
it has to be obviously compatible with a

00:15:05,519 --> 00:15:10,440
sinker because this is a common

00:15:07,610 --> 00:15:13,829
framework that all of that Python higher

00:15:10,440 --> 00:15:17,390
level libraries should use so tornado is

00:15:13,829 --> 00:15:20,040
already production ready framework and

00:15:17,390 --> 00:15:22,800
its compatibility with I think IO is

00:15:20,040 --> 00:15:25,740
already there basically this is a stack

00:15:22,800 --> 00:15:28,079
how in the best case in the future we

00:15:25,740 --> 00:15:29,730
will see it in the Python world on the

00:15:28,079 --> 00:15:31,470
application framework level we can have

00:15:29,730 --> 00:15:36,570
tornado twisted or whatever as a

00:15:31,470 --> 00:15:39,420
framework then as an i/o loop I think I

00:15:36,570 --> 00:15:41,160
should be used and finally I think is at

00:15:39,420 --> 00:15:43,260
the end just a common interface for the

00:15:41,160 --> 00:15:45,690
operating system specific selectors like

00:15:43,260 --> 00:15:48,930
a Huey pole or Windows selects whatever

00:15:45,690 --> 00:15:52,320
this is how should it be right now even

00:15:48,930 --> 00:15:54,540
if you use Python 2 you can use tornado

00:15:52,320 --> 00:15:57,510
with a known event loop with own futures

00:15:54,540 --> 00:15:59,130
with own everything but since we want to

00:15:57,510 --> 00:16:01,560
develop for the future we want to be

00:15:59,130 --> 00:16:05,430
future compatible we can use async i/o

00:16:01,560 --> 00:16:07,470
as well so let's look at the event loop

00:16:05,430 --> 00:16:12,029
how does it work with tornado and

00:16:07,470 --> 00:16:14,519
compatibility with the sync i/o this is

00:16:12,029 --> 00:16:16,380
first way that you would get the event

00:16:14,519 --> 00:16:18,540
loop in tornado you just select a loop

00:16:16,380 --> 00:16:21,120
current it's a singleton and you start

00:16:18,540 --> 00:16:23,820
it this is the way that you can use

00:16:21,120 --> 00:16:26,459
tornado with a sync event to basically

00:16:23,820 --> 00:16:28,680
again this is the same two lines of code

00:16:26,459 --> 00:16:30,540
with just different syntax pretty easy

00:16:28,680 --> 00:16:33,540
replace one with another you running it

00:16:30,540 --> 00:16:35,339
on a single futures again trainer has

00:16:33,540 --> 00:16:37,170
own futures as think io has own future

00:16:35,339 --> 00:16:38,910
but they are super similar we also have

00:16:37,170 --> 00:16:42,029
concurrent futures back from Python to

00:16:38,910 --> 00:16:44,670
also pretty similar thing but for the

00:16:42,029 --> 00:16:46,529
VIX compatibility we need to use tornado

00:16:44,670 --> 00:16:47,910
magic methods that will convert one type

00:16:46,529 --> 00:16:49,680
of future into another type of future

00:16:47,910 --> 00:16:53,820
which is not a big deal because again

00:16:49,680 --> 00:16:57,060
it's just one line of code now I think

00:16:53,820 --> 00:17:00,480
it's a good time that we have a full get

00:16:57,060 --> 00:17:04,829
handler written in tornado

00:17:00,480 --> 00:17:06,990
let's look at this so in turn ADA we

00:17:04,829 --> 00:17:11,039
need to inherit from the request handler

00:17:06,990 --> 00:17:13,139
we need to mark the method as a core

00:17:11,039 --> 00:17:14,639
routine so that tornado knows that the

00:17:13,139 --> 00:17:15,899
thing that we will be yielding is the

00:17:14,639 --> 00:17:17,850
future and this future should be

00:17:15,899 --> 00:17:18,679
evaluated and then the result should be

00:17:17,850 --> 00:17:21,209
passed back

00:17:18,679 --> 00:17:23,699
we need to instantiate the asynchronous

00:17:21,209 --> 00:17:25,889
HTTP client that will not just block

00:17:23,699 --> 00:17:29,700
instead it will return futures construct

00:17:25,889 --> 00:17:32,309
them and return it for us then we use

00:17:29,700 --> 00:17:36,120
the fetch methods to fetch some really

00:17:32,309 --> 00:17:38,010
slow API whatever we are using the

00:17:36,120 --> 00:17:41,309
future that it will return back to the

00:17:38,010 --> 00:17:42,840
i/o loop a loop will call us back at the

00:17:41,309 --> 00:17:45,320
right point of time when the result is

00:17:42,840 --> 00:17:48,029
available and we have the response here

00:17:45,320 --> 00:17:49,740
alternatively of course there may be no

00:17:48,029 --> 00:17:52,649
results there may be timeout there may

00:17:49,740 --> 00:17:54,630
be 404 whatever then it will be just

00:17:52,649 --> 00:17:57,090
normal Python exception handler handling

00:17:54,630 --> 00:18:00,809
so in this case tornado would just write

00:17:57,090 --> 00:18:04,980
404 HTTP error that's it you catch it

00:18:00,809 --> 00:18:08,029
with normal try except then we write

00:18:04,980 --> 00:18:10,740
response back to the user as pretty

00:18:08,029 --> 00:18:12,809
common for Python web frameworks and

00:18:10,740 --> 00:18:14,880
then we need to call servlet finish

00:18:12,809 --> 00:18:18,210
because this is a coroutine

00:18:14,880 --> 00:18:22,470
so we want to keep control when request

00:18:18,210 --> 00:18:24,960
this cut this is a full example let's

00:18:22,470 --> 00:18:28,080
say that we want to make the HTTP proxy

00:18:24,960 --> 00:18:31,260
we want to pass a URL as a parameter and

00:18:28,080 --> 00:18:34,169
we want tornado with a sinker yo to

00:18:31,260 --> 00:18:36,510
fetch it for us and just stream it back

00:18:34,169 --> 00:18:38,760
to the client so these are all of the

00:18:36,510 --> 00:18:41,580
required is imports there are not that

00:18:38,760 --> 00:18:43,350
much actually this you have already seen

00:18:41,580 --> 00:18:45,929
the way that we construct request

00:18:43,350 --> 00:18:48,210
handler then we just get the URL

00:18:45,929 --> 00:18:52,289
argument from get parameters we again

00:18:48,210 --> 00:18:54,480
create the async HTTP client we fetch

00:18:52,289 --> 00:18:56,340
this URL yield the future to the Iowa

00:18:54,480 --> 00:19:02,330
get the response back right response

00:18:56,340 --> 00:19:02,330
finish response yep please

00:19:09,630 --> 00:19:12,530
yep

00:19:23,610 --> 00:19:26,330
mm-hmm

00:19:33,690 --> 00:19:40,320
very well so I repeat the question the

00:19:37,500 --> 00:19:43,350
question is how exactly does it work

00:19:40,320 --> 00:19:45,030
over here that HTTP clients would

00:19:43,350 --> 00:19:49,190
normally block when you call the fetch

00:19:45,030 --> 00:19:51,600
wait for the resource to be fetched and

00:19:49,190 --> 00:19:52,520
what is this yield from doing in this

00:19:51,600 --> 00:19:55,800
place

00:19:52,520 --> 00:20:00,630
how does this in Chronos magic work very

00:19:55,800 --> 00:20:03,360
good so this is a kind of a spatial HTTP

00:20:00,630 --> 00:20:06,750
clients async is typical and obviously

00:20:03,360 --> 00:20:09,030
so we have a similar library called just

00:20:06,750 --> 00:20:11,130
HTTP client in tornado and it will do

00:20:09,030 --> 00:20:13,470
exactly this thing if you run HTTP

00:20:11,130 --> 00:20:15,750
client dot fetch it would block it would

00:20:13,470 --> 00:20:18,990
wait just like request just like URL

00:20:15,750 --> 00:20:22,170
deep it would block and wait and fetch

00:20:18,990 --> 00:20:25,350
the response may simply TCP client is

00:20:22,170 --> 00:20:27,720
not blocking it's not waiting it quickly

00:20:25,350 --> 00:20:29,670
constructs the future object so not the

00:20:27,720 --> 00:20:32,190
real response object the future objects

00:20:29,670 --> 00:20:34,590
and returns that and since we do not

00:20:32,190 --> 00:20:37,110
need to wait for long time to just build

00:20:34,590 --> 00:20:41,100
a future it's basically just creating an

00:20:37,110 --> 00:20:44,220
object of a class this happens to

00:20:41,100 --> 00:20:46,590
purpose and then we are yielding this

00:20:44,220 --> 00:20:49,080
future so we're so to say extending it

00:20:46,590 --> 00:20:51,080
out of the function back to the aya loop

00:20:49,080 --> 00:20:54,450
that is controlling this whole process

00:20:51,080 --> 00:20:57,030
meanwhile yes this get requests will

00:20:54,450 --> 00:21:00,000
just pause so it's like frozen in this

00:20:57,030 --> 00:21:03,060
state until we have the response of the

00:21:00,000 --> 00:21:05,760
fetch thing but we have other clients

00:21:03,060 --> 00:21:07,170
meanwhile so I loop will in the

00:21:05,760 --> 00:21:10,530
meanwhile it will serve other

00:21:07,170 --> 00:21:13,200
connections for us therefore this gets

00:21:10,530 --> 00:21:15,570
handler will be post but others get

00:21:13,200 --> 00:21:18,030
service and in practice it happens so

00:21:15,570 --> 00:21:22,410
fast that you never see and whenever I

00:21:18,030 --> 00:21:24,570
loop will notice that okay now the URL

00:21:22,410 --> 00:21:26,880
is fetched now we have data on our

00:21:24,570 --> 00:21:29,760
socket it will look up okay who have

00:21:26,880 --> 00:21:32,370
been waiting for it oh it was this proxy

00:21:29,760 --> 00:21:36,480
get thingy and this will call it back

00:21:32,370 --> 00:21:39,630
and by calling it back it will have the

00:21:36,480 --> 00:21:42,000
result that was fetched and it will push

00:21:39,630 --> 00:21:44,550
it just over here so you can imagine

00:21:42,000 --> 00:21:44,980
that after the isle loop was done with

00:21:44,550 --> 00:21:47,770
fetching

00:21:44,980 --> 00:21:49,660
stuff imagine that yield prom was gone

00:21:47,770 --> 00:21:51,730
it was never there there was just the

00:21:49,660 --> 00:21:56,100
fetch operation this is basically in a

00:21:51,730 --> 00:21:56,100
glance how that will work there please

00:21:59,760 --> 00:22:06,520
since its stopping anyway on the yield

00:22:02,440 --> 00:22:10,929
from why do you need a future object a

00:22:06,520 --> 00:22:14,200
future object future okay so why do we

00:22:10,929 --> 00:22:16,059
need a future object here so first of

00:22:14,200 --> 00:22:19,950
all yield from well there was always

00:22:16,059 --> 00:22:23,559
yield resulted from yield from is

00:22:19,950 --> 00:22:25,390
required if we want to get futures from

00:22:23,559 --> 00:22:27,370
another core routine in this case we

00:22:25,390 --> 00:22:29,440
don't have to use utrom we can also use

00:22:27,370 --> 00:22:31,960
just yields but if you are building a

00:22:29,440 --> 00:22:33,880
big system you might have a stack of the

00:22:31,960 --> 00:22:36,340
coroutines one call in each other one

00:22:33,880 --> 00:22:37,809
call in another then you need from but

00:22:36,340 --> 00:22:39,429
this is I guess not the question the

00:22:37,809 --> 00:22:41,860
question is why do we need the future at

00:22:39,429 --> 00:22:44,470
all at this point so we need the future

00:22:41,860 --> 00:22:46,809
because if we return after the fetch

00:22:44,470 --> 00:22:49,480
call if we will return the result we

00:22:46,809 --> 00:22:53,410
obviously need to wait for results here

00:22:49,480 --> 00:22:55,480
so basically this call will block so

00:22:53,410 --> 00:22:57,190
since fetching takes a long time we

00:22:55,480 --> 00:22:58,570
construct the future and constructing

00:22:57,190 --> 00:23:00,520
the future does not take long time

00:22:58,570 --> 00:23:03,490
because it's just creating of a future

00:23:00,520 --> 00:23:05,169
object without waiting this is basically

00:23:03,490 --> 00:23:08,980
how we use futures it's kind of

00:23:05,169 --> 00:23:11,530
abstraction that lets us not wait for

00:23:08,980 --> 00:23:13,419
the response but give something back so

00:23:11,530 --> 00:23:14,740
that caller has a reference to the

00:23:13,419 --> 00:23:17,919
response that will come at the later

00:23:14,740 --> 00:23:20,350
point of time and if you might find

00:23:17,919 --> 00:23:24,220
confusing this yield from syntax you can

00:23:20,350 --> 00:23:26,980
also imagine a real future so if we take

00:23:24,220 --> 00:23:28,900
back to take away yield from just get

00:23:26,980 --> 00:23:33,669
the future and doesn't don't call it

00:23:28,900 --> 00:23:36,820
response call it just future take the

00:23:33,669 --> 00:23:40,290
yield from away then at the later point

00:23:36,820 --> 00:23:40,290
of time to get the response

00:23:42,559 --> 00:23:50,059
I broke it so to get the response of

00:23:47,809 --> 00:23:53,169
this thing at a later point of time we

00:23:50,059 --> 00:23:56,539
can just call the future dot result

00:23:53,169 --> 00:23:58,429
directly and then it will give you the

00:23:56,539 --> 00:24:02,570
result if it's ready so future is pretty

00:23:58,429 --> 00:24:04,970
simple it has status it has a result it

00:24:02,570 --> 00:24:08,539
has an error I guess so you can access

00:24:04,970 --> 00:24:10,429
the results directly but it's just nicer

00:24:08,539 --> 00:24:12,200
if you don't do it and you let the ayah

00:24:10,429 --> 00:24:14,899
loop to it because then you can use the

00:24:12,200 --> 00:24:17,179
magic yield from syntax that will

00:24:14,899 --> 00:24:27,320
extract the results out of the future

00:24:17,179 --> 00:24:30,499
for you now there will be no result I

00:24:27,320 --> 00:24:31,850
guess you can also check if result is

00:24:30,499 --> 00:24:34,070
available so if you want to write a

00:24:31,850 --> 00:24:35,869
really bad code you can write a loop in

00:24:34,070 --> 00:24:38,179
which you would ask if there is out

00:24:35,869 --> 00:24:39,830
there no either is out there no and then

00:24:38,179 --> 00:24:41,299
you will reinvent the I loop because

00:24:39,830 --> 00:24:48,019
basically that that's what is

00:24:41,299 --> 00:24:51,070
responsible for okay we had this example

00:24:48,019 --> 00:24:56,539
as far as I know so let's go further

00:24:51,070 --> 00:25:03,470
demo I have the ipython notebook for you

00:24:56,539 --> 00:25:05,419
to show this thing running let's agree

00:25:03,470 --> 00:25:08,809
on the simple case that we are going to

00:25:05,419 --> 00:25:11,299
test so we have the client that will be

00:25:08,809 --> 00:25:13,519
our ipython notebook we have a web

00:25:11,299 --> 00:25:15,919
server this will be the whatever

00:25:13,519 --> 00:25:18,860
synchronous framework we are testing and

00:25:15,919 --> 00:25:21,289
then we have three api's this three

00:25:18,860 --> 00:25:25,369
api's will be requested in parallel and

00:25:21,289 --> 00:25:27,769
so a synchronously and we want to check

00:25:25,369 --> 00:25:30,139
how well web server is handling this

00:25:27,769 --> 00:25:34,940
rican currents requests to the third

00:25:30,139 --> 00:25:36,769
party API so to simulate this whole

00:25:34,940 --> 00:25:39,590
thing without the external dependencies

00:25:36,769 --> 00:25:41,960
I have everything running on my laptop I

00:25:39,590 --> 00:25:44,210
have tornado server or as a framework

00:25:41,960 --> 00:25:47,389
server to and I have a dummy local

00:25:44,210 --> 00:25:49,909
server that just waits for fix-it time

00:25:47,389 --> 00:25:51,889
out of 10 milliseconds on every request

00:25:49,909 --> 00:25:54,460
and returns a dummy HelloWorld greeting

00:25:51,889 --> 00:25:59,340
and you can see it over here

00:25:54,460 --> 00:25:59,340
this is what my dummy local server does

00:25:59,940 --> 00:26:07,389
now we can test how fast can I fight a

00:26:04,690 --> 00:26:09,519
notebook fetch this dummy server

00:26:07,389 --> 00:26:11,289
response directly so that we have

00:26:09,519 --> 00:26:13,899
something to compare to so it's 16

00:26:11,289 --> 00:26:16,509
milliseconds from this 16 milliseconds

00:26:13,899 --> 00:26:19,330
10 milliseconds is our fix-it delay that

00:26:16,509 --> 00:26:22,840
we have on purpose and 6 milliseconds

00:26:19,330 --> 00:26:26,049
for fetching overhead so first example

00:26:22,840 --> 00:26:28,119
we have just the blocking server just a

00:26:26,049 --> 00:26:30,399
block in tornado server that is using

00:26:28,119 --> 00:26:32,860
HTTP client not a Singh HTTP client

00:26:30,399 --> 00:26:35,559
therefore it does not return futures it

00:26:32,860 --> 00:26:38,019
blocks and it waits for result in this

00:26:35,559 --> 00:26:41,889
list comprehension I have three URLs so

00:26:38,019 --> 00:26:43,749
three dummy URLs that I want to fetch

00:26:41,889 --> 00:26:45,970
and call in fetch on each of them and

00:26:43,749 --> 00:26:49,570
then I'm just looping over responses and

00:26:45,970 --> 00:26:50,169
writing it back to the user this is how

00:26:49,570 --> 00:26:54,789
it will work

00:26:50,169 --> 00:26:56,379
so we requested three times same URL we

00:26:54,789 --> 00:27:00,789
have the response let's see how fast

00:26:56,379 --> 00:27:03,700
does it go okay so this is 54

00:27:00,789 --> 00:27:05,889
milliseconds altogether obviously we

00:27:03,700 --> 00:27:07,659
just multiplies this 16 by 3 because

00:27:05,889 --> 00:27:11,110
it's a blocking server so it did it

00:27:07,659 --> 00:27:13,539
sequentially now let's see how the same

00:27:11,110 --> 00:27:16,119
thing but just using the async HTTP

00:27:13,539 --> 00:27:17,830
client work basically what do we need to

00:27:16,119 --> 00:27:20,350
do to convert blocking codes to non

00:27:17,830 --> 00:27:22,990
blocking code we need to change the HTTP

00:27:20,350 --> 00:27:25,269
client into a sink if you typically so

00:27:22,990 --> 00:27:27,759
add this thing then we need to mark it

00:27:25,269 --> 00:27:31,480
as a core routine in order to let a

00:27:27,759 --> 00:27:34,840
tornado or other framework in I think it

00:27:31,480 --> 00:27:38,769
will be also a curtain decorator we let

00:27:34,840 --> 00:27:40,929
it know that this thing that is beneath

00:27:38,769 --> 00:27:44,610
will yield us back the future so that

00:27:40,929 --> 00:27:48,039
tornado knows to process it accordingly

00:27:44,610 --> 00:27:50,919
so we are calling this thing we have the

00:27:48,039 --> 00:27:53,559
same response and this should be three

00:27:50,919 --> 00:27:55,299
times faster it's not because of the

00:27:53,559 --> 00:27:57,519
overhead of course this whole thing

00:27:55,299 --> 00:28:01,389
io loop and stuff has on overhead but

00:27:57,519 --> 00:28:04,749
it's 22 milliseconds so comparing to 54

00:28:01,389 --> 00:28:06,320
it's two and half times less more less

00:28:04,749 --> 00:28:10,130
and comparing to the

00:28:06,320 --> 00:28:13,519
requesting dummy URL directly 16 versus

00:28:10,130 --> 00:28:17,240
22 we have again about five milliseconds

00:28:13,519 --> 00:28:22,549
of the overhead of tornado now the fun

00:28:17,240 --> 00:28:24,320
part comes nodejs so this is also a

00:28:22,549 --> 00:28:25,820
synchronously framework and probably

00:28:24,320 --> 00:28:27,740
everyone has already seen on the

00:28:25,820 --> 00:28:30,529
internet some article like way might not

00:28:27,740 --> 00:28:33,529
GS on the ec2 micro instance is handling

00:28:30,529 --> 00:28:36,169
I don't know ten hundred thousands of

00:28:33,529 --> 00:28:38,419
connections simultaneously yes this is

00:28:36,169 --> 00:28:40,639
true this does work especially in the

00:28:38,419 --> 00:28:42,379
case of WebSockets it's a perfect case

00:28:40,639 --> 00:28:44,600
for synchronous framework to be used

00:28:42,379 --> 00:28:46,639
because for WebSockets we have many

00:28:44,600 --> 00:28:49,820
connections but all of them are mostly

00:28:46,639 --> 00:28:52,519
idling so we are wasting our CPU if we

00:28:49,820 --> 00:28:55,970
have resources dedicated to each of

00:28:52,519 --> 00:28:58,340
these connections we want to use our

00:28:55,970 --> 00:29:00,940
sources efficiently therefore at one

00:28:58,340 --> 00:29:04,309
point of time we can have just one

00:29:00,940 --> 00:29:07,179
clients getting real work done on the

00:29:04,309 --> 00:29:09,440
backend others can just wait because

00:29:07,179 --> 00:29:11,960
WebSockets do not need everyone to do

00:29:09,440 --> 00:29:18,019
stuff at the same time so this is how it

00:29:11,960 --> 00:29:20,899
works I might of course have it not not

00:29:18,019 --> 00:29:23,240
in the perfect way as some JavaScript

00:29:20,899 --> 00:29:25,100
guru would advise me but I did it in

00:29:23,240 --> 00:29:27,440
purpose because I try to avoid external

00:29:25,100 --> 00:29:29,600
dependencies not GS has a lot of

00:29:27,440 --> 00:29:31,669
external libraries that would make it

00:29:29,600 --> 00:29:35,929
kind of look nicer but this is just pure

00:29:31,669 --> 00:29:40,039
not thinking so what we do here I

00:29:35,929 --> 00:29:43,100
created the option object that keeps

00:29:40,039 --> 00:29:43,759
reference to the local localhost dummy

00:29:43,100 --> 00:29:50,240
URL

00:29:43,759 --> 00:29:52,279
I have the array that is waiting for

00:29:50,240 --> 00:29:55,789
responses that will get the responses

00:29:52,279 --> 00:29:58,009
then I need to loop I'm looping over API

00:29:55,789 --> 00:30:01,179
count which is 3 just to have 3 requests

00:29:58,009 --> 00:30:06,080
and they do HTTP dot get so HTTP is a

00:30:01,179 --> 00:30:09,259
library that is kind of the async HTTP

00:30:06,080 --> 00:30:11,000
client in tornado and then I need to of

00:30:09,259 --> 00:30:13,340
course define a callback what to do

00:30:11,000 --> 00:30:15,019
after we fetch stuff and I'm defining it

00:30:13,340 --> 00:30:17,720
inline in the best tradition of the

00:30:15,019 --> 00:30:19,410
JavaScript need to set encoding I need

00:30:17,720 --> 00:30:20,940
to create the body chunks because

00:30:19,410 --> 00:30:22,320
function will be called snored when the

00:30:20,940 --> 00:30:25,410
result is ready but when the chunk

00:30:22,320 --> 00:30:27,510
arrives so on the data and creating

00:30:25,410 --> 00:30:31,340
another inline function that will push

00:30:27,510 --> 00:30:34,500
this chunk to the array of chunks then

00:30:31,340 --> 00:30:37,350
on the end event that will send us after

00:30:34,500 --> 00:30:40,230
all chunks as here I need to glue it

00:30:37,350 --> 00:30:43,860
back together by using a firkin cat then

00:30:40,230 --> 00:30:45,960
I push responses to the body object and

00:30:43,860 --> 00:30:48,660
finally when I see that okay so

00:30:45,960 --> 00:30:50,610
responses are three just as API counts

00:30:48,660 --> 00:30:55,500
that was three I can say okay everything

00:30:50,610 --> 00:30:57,990
is ready now then I create the response

00:30:55,500 --> 00:31:00,510
text I set headers and that's it I am

00:30:57,990 --> 00:31:04,130
the request at the end we have the same

00:31:00,510 --> 00:31:04,130
thing and let's see how fast this works

00:31:05,420 --> 00:31:10,320
we can remind what was written tornado

00:31:08,010 --> 00:31:12,660
meanwhile so it was 22 milliseconds for

00:31:10,320 --> 00:31:15,960
tornado and it's 18 for not GS

00:31:12,660 --> 00:31:19,170
Bravo not Jes well done we have three

00:31:15,960 --> 00:31:24,000
milliseconds faster but maybe four hours

00:31:19,170 --> 00:31:26,850
more power developer work let's have

00:31:24,000 --> 00:31:30,420
another example Scala wonderful

00:31:26,850 --> 00:31:34,160
performant language I guys just don't

00:31:30,420 --> 00:31:34,160
have time to go through all of this mess

00:31:34,400 --> 00:31:40,200
believe me you don't want to read it I

00:31:37,220 --> 00:31:42,090
of course realize that the people who

00:31:40,200 --> 00:31:44,010
are experts in Scala do this pretty fast

00:31:42,090 --> 00:31:45,810
in fact I was not the guy who wrote this

00:31:44,010 --> 00:31:47,790
because on every conference when I'm

00:31:45,810 --> 00:31:49,170
showing some tornado examples I ask

00:31:47,790 --> 00:31:51,180
someone who know some other a

00:31:49,170 --> 00:31:54,510
synchronous framework to give me the

00:31:51,180 --> 00:31:57,630
example so that I can edit into my

00:31:54,510 --> 00:32:03,090
comparison but the funny thing is that

00:31:57,630 --> 00:32:08,550
this thing is damn performance let's see

00:32:03,090 --> 00:32:12,840
how in practice does it work 22 of

00:32:08,550 --> 00:32:14,970
tornado 1819 slightly more than not okay

00:32:12,840 --> 00:32:16,860
but of course this is not a very fair

00:32:14,970 --> 00:32:21,330
comparison because I have a fixed number

00:32:16,860 --> 00:32:24,270
of backends api's which is three so I

00:32:21,330 --> 00:32:27,000
fetched 380 ice what if we have ten

00:32:24,270 --> 00:32:29,100
whatever we have to entry we don't need

00:32:27,000 --> 00:32:30,269
to speculate I wrote a little benchmark

00:32:29,100 --> 00:32:33,809
that will end

00:32:30,269 --> 00:32:34,529
for us this question so here I have

00:32:33,809 --> 00:32:37,429
tornado

00:32:34,529 --> 00:32:39,749
I have not yes and I have pinnacle and

00:32:37,429 --> 00:32:42,929
I'm going to increase the number of

00:32:39,749 --> 00:32:45,209
concurrent requests from 1 to 20 then

00:32:42,929 --> 00:32:47,279
I'm going to plot a graph that will show

00:32:45,209 --> 00:32:50,249
us how do these different frameworks

00:32:47,279 --> 00:32:53,419
behave under increasing load so on the

00:32:50,249 --> 00:32:58,679
increasing of the concurrent request and

00:32:53,419 --> 00:33:01,440
now it's ready so here you see tornado

00:32:58,679 --> 00:33:03,989
was losing at the beginning but it is

00:33:01,440 --> 00:33:06,089
quite stable at least we see the total

00:33:03,989 --> 00:33:08,849
opposite question with no GS because

00:33:06,089 --> 00:33:12,059
somehow eight five requests it just

00:33:08,849 --> 00:33:14,909
blocks and jumps up and in case of

00:33:12,059 --> 00:33:17,459
skyline pinnacle it's perfect okay

00:33:14,909 --> 00:33:20,879
I have nothing to add here bravo to

00:33:17,459 --> 00:33:23,549
Scala tornado also did a good job and I

00:33:20,879 --> 00:33:25,339
have a feeling that I might just have

00:33:23,549 --> 00:33:28,259
not a perfect configuration for node

00:33:25,339 --> 00:33:32,190
because we obviously see this pattern of

00:33:28,259 --> 00:33:38,459
jumping on every five parallel requests

00:33:32,190 --> 00:33:42,479
edit so I think that's yeah we can stop

00:33:38,459 --> 00:33:50,759
at this point let me then jump back to

00:33:42,479 --> 00:33:53,369
my slides this is the end I will be open

00:33:50,759 --> 00:33:55,649
for my questions in a second just before

00:33:53,369 --> 00:33:59,489
I finish this I want to remind you once

00:33:55,649 --> 00:34:01,799
again that if you want to do this cool

00:33:59,489 --> 00:34:04,289
stuff have time for experiments and so

00:34:01,799 --> 00:34:07,129
on you should maybe go to scoubidou de

00:34:04,289 --> 00:34:10,409
or scooby dot es and check what the jobs

00:34:07,129 --> 00:34:12,200
then I will be happy to pass my

00:34:10,409 --> 00:34:15,149
presentation over to somebody else

00:34:12,200 --> 00:34:18,389
continue with this research have some

00:34:15,149 --> 00:34:21,029
different topic so guys check it again

00:34:18,389 --> 00:34:23,869
scooby these large jobs and thank you

00:34:21,029 --> 00:34:23,869
very much for your attention

00:34:29,629 --> 00:34:43,589
now questions I write for the talk I was

00:34:40,169 --> 00:34:54,690
interested in since async IO and tornado

00:34:43,589 --> 00:34:57,479
have very similar jobs ok good question

00:34:54,690 --> 00:35:01,200
so why do we need tornado on top of a

00:34:57,479 --> 00:35:03,809
sinker at all so I think does have a

00:35:01,200 --> 00:35:05,819
higher level libraries - it's not only

00:35:03,809 --> 00:35:08,219
the IO loop and futures it also has

00:35:05,819 --> 00:35:12,209
tools developed specifically for I think

00:35:08,219 --> 00:35:16,380
I already that is I think httpclient I

00:35:12,209 --> 00:35:20,400
think at least some database drivers

00:35:16,380 --> 00:35:22,709
that are ready but tornado is a web

00:35:20,400 --> 00:35:24,779
framer so you can imagine tornado as a

00:35:22,709 --> 00:35:27,119
subset of jungle it gives you templates

00:35:24,779 --> 00:35:29,459
it gives you base class for request

00:35:27,119 --> 00:35:32,130
handlers gives you basic security stuff

00:35:29,459 --> 00:35:35,099
like CSRF protection and so on cookie

00:35:32,130 --> 00:35:40,729
handling and stuff and I think I can go

00:35:35,099 --> 00:35:40,729
back to that slides where I had a stack

00:35:41,930 --> 00:35:49,880
yeah

00:35:44,660 --> 00:35:52,550
okay yes here thank you

00:35:49,880 --> 00:35:54,170
so tornado is just a higher level it's

00:35:52,550 --> 00:35:55,730
the application level framework that

00:35:54,170 --> 00:35:58,430
lets you build the web applications

00:35:55,730 --> 00:36:00,560
faster can be synchronous and be a

00:35:58,430 --> 00:36:01,940
synchronous asynchronous is just one of

00:36:00,560 --> 00:36:04,070
the options that you would use tornado

00:36:01,940 --> 00:36:06,800
most likely you will do it because you

00:36:04,070 --> 00:36:10,220
can but you don't have to and I think IO

00:36:06,800 --> 00:36:12,800
is a common middleware so to say between

00:36:10,220 --> 00:36:15,470
higher level frameworks like tornado or

00:36:12,800 --> 00:36:18,470
twisted and lower level operating system

00:36:15,470 --> 00:36:21,470
selectors like PQ or a pole or selection

00:36:18,470 --> 00:36:24,980
windows so this is kind of a lower level

00:36:21,470 --> 00:36:28,460
set of tools and yes you can use it to

00:36:24,980 --> 00:36:30,530
directly without tornado but then you

00:36:28,460 --> 00:36:32,540
will need to build the rest of the web

00:36:30,530 --> 00:36:36,370
stack yourself and this is something

00:36:32,540 --> 00:36:36,370
that you would normally wants to avoid

00:36:37,570 --> 00:36:46,880
yeah exactly you can also call the low

00:36:41,780 --> 00:36:49,910
level stuff directly ask a question yeah

00:36:46,880 --> 00:36:52,640
I'm not really a familiar with this

00:36:49,910 --> 00:36:53,930
framework so my question is is there a

00:36:52,640 --> 00:36:56,900
built-in ORM

00:36:53,930 --> 00:36:59,000
if answer is don't is there is Oram of

00:36:56,900 --> 00:37:01,370
choice like preferred one or the one

00:36:59,000 --> 00:37:04,010
that you use and then third and the

00:37:01,370 --> 00:37:08,000
actual question is that how does a sync

00:37:04,010 --> 00:37:13,090
stuff works with or Am's okay very good

00:37:08,000 --> 00:37:15,620
so first do we have the Orion tornado no

00:37:13,090 --> 00:37:18,740
follow-up question what would be the

00:37:15,620 --> 00:37:20,750
realm of the preference well guys I was

00:37:18,740 --> 00:37:24,620
working with Django for quite some time

00:37:20,750 --> 00:37:28,550
and I loved the simplicity but I've also

00:37:24,620 --> 00:37:31,100
seen attempts to put SQL alchemy on top

00:37:28,550 --> 00:37:33,190
of the jungle that worked pretty fine so

00:37:31,100 --> 00:37:35,900
I think that SQL alchemy is kind of the

00:37:33,190 --> 00:37:40,610
standard or ramp for Python in general

00:37:35,900 --> 00:37:43,460
and this is also our choice to be to use

00:37:40,610 --> 00:37:45,890
that in tornado - there is nothing

00:37:43,460 --> 00:37:47,960
special into connecting tornado to SQL

00:37:45,890 --> 00:37:51,140
alchemy it's just two totally different

00:37:47,960 --> 00:37:52,420
things that are easy to use together but

00:37:51,140 --> 00:37:54,670
you don't have to use them together

00:37:52,420 --> 00:37:57,130
in fact in some websites you don't need

00:37:54,670 --> 00:37:59,019
database at all so actually not having

00:37:57,130 --> 00:38:01,450
overhead of the ORM is even better

00:37:59,019 --> 00:38:03,180
sometimes but if you like to have a

00:38:01,450 --> 00:38:07,119
database you like to build a traditional

00:38:03,180 --> 00:38:09,309
websites retire set up I would recommend

00:38:07,119 --> 00:38:12,400
you to use alchemy it's pretty flexible

00:38:09,309 --> 00:38:14,769
and nice but generally you're not

00:38:12,400 --> 00:38:18,400
limited by that you can use any Orem

00:38:14,769 --> 00:38:20,529
that you like there was I think the

00:38:18,400 --> 00:38:21,940
second another part how does it work

00:38:20,529 --> 00:38:26,740
with a single thing yes

00:38:21,940 --> 00:38:29,319
so I also answer that you are very right

00:38:26,740 --> 00:38:32,859
in asking this question because having a

00:38:29,319 --> 00:38:35,859
synchronous execution on the web server

00:38:32,859 --> 00:38:39,119
level does not guarantee us success

00:38:35,859 --> 00:38:41,799
obviously if something that we are

00:38:39,119 --> 00:38:43,329
waiting for like a database or a cache

00:38:41,799 --> 00:38:45,369
does not support the synchronous

00:38:43,329 --> 00:38:48,549
requests we can fix this problem by

00:38:45,369 --> 00:38:50,170
having a thread pool and use thread pool

00:38:48,549 --> 00:38:52,329
executors which is the synchronous in

00:38:50,170 --> 00:38:53,859
Python but this is not cool obviously

00:38:52,329 --> 00:38:55,210
because we end up with a thread pool and

00:38:53,859 --> 00:39:00,339
that is what we wanted to avoid that the

00:38:55,210 --> 00:39:02,109
first place but now with I think i/o we

00:39:00,339 --> 00:39:03,759
are having more and more tools that get

00:39:02,109 --> 00:39:06,069
support for instance for the database

00:39:03,759 --> 00:39:08,319
you most likely like post just because

00:39:06,069 --> 00:39:10,000
everyone likes Postgres we have psycho

00:39:08,319 --> 00:39:13,480
PG to drivers that supports the

00:39:10,000 --> 00:39:16,180
synchronous mode for Eddy's we also have

00:39:13,480 --> 00:39:18,579
the synchronous driver for we have

00:39:16,180 --> 00:39:20,259
pi I think so most of the tools

00:39:18,579 --> 00:39:23,019
are already covered but not all of them

00:39:20,259 --> 00:39:24,819
so you need to really look but now since

00:39:23,019 --> 00:39:26,859
we have this common interface I think I

00:39:24,819 --> 00:39:29,470
you're thinking they will grow that's

00:39:26,859 --> 00:39:31,269
for sure all right we aren't watching

00:39:29,470 --> 00:39:35,710
the earth time that's how I began to

00:39:31,269 --> 00:39:38,030
atone for his presentation thank you for

00:39:35,710 --> 00:39:41,960
listening thank you for coming

00:39:38,030 --> 00:39:41,960

YouTube URL: https://www.youtube.com/watch?v=NKPHP5p0WXA


