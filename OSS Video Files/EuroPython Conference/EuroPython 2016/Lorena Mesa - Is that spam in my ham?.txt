Title: Lorena Mesa - Is that spam in my ham?
Publication date: 2016-07-28
Playlist: EuroPython 2016
Description: 
	Lorena Mesa - Is that spam in my ham?
[EuroPython 2016]
[18 July 2016]
[Bilbao, Euskadi, Spain]
(https://ep2016.europython.eu//conference/talks/is-that-spam-in-my-ham)

Beginning programmers or Python beginners may find it overwhelming to
implement a machine learning algorithm. Increasingly machine learning
is becoming more applicable to many areas. This talk introduces key
concepts and ideas and uses Python to build a basic classifier - a
common type of machine learning problem. Providing some jargon to help
those that may be self-educated or currently learning

-----

Supervised learning, machine learning, classifiers, big data! What in
the world are all of these things? As a beginning programmer the
questions described as "machine learning" questions can be mystifying
at best.

In this talk I will define the scope of a machine learning problem,
identifying an email as ham or spam, from the perspective of a
beginner (non master of all things "machine learning") and show how
Python can help us simply learn how to classify a piece of email.

To begin we must ask, what is spam? How do I know it "when I see it"?
From previous experience of course! We will provide human labeled
examples of spam to our model for it to understand the likelihood of
spam or ham. This approach, using examples and data we already know to
determine the most likely label for a new example, uses the Naive
Bayes classifier.

Our model will look at the words in the body of an email, finding the
frequency of words in both spam and ham emails and the frequency of
spam and ham. Once we know the prior likelihood of spam and what makes
something spam, we can try applying a label to a new example.

Through this exercise we will see at a basic level what types of
questions machine learning asks, learn to model "learning" with
Python, and understand how learning can be measured.
Captions: 
	00:00:00,000 --> 00:00:04,589
good afternoon everyone welcome to this

00:00:02,939 --> 00:00:07,859
afternoon session I'd like to introduce

00:00:04,589 --> 00:00:11,250
Lorena Meza she's a platform engineer at

00:00:07,859 --> 00:00:13,740
sprout social in Chicago and she's a

00:00:11,250 --> 00:00:16,710
Star Trek Star Trek fan and she's gonna

00:00:13,740 --> 00:00:28,230
talk to us about spam and natural

00:00:16,710 --> 00:00:30,269
language process so real fun fact I have

00:00:28,230 --> 00:00:33,510
a loud voice is this too strong or

00:00:30,269 --> 00:00:36,059
should I be a little quieter louder oh

00:00:33,510 --> 00:00:37,550
this is great I can be loud alright

00:00:36,059 --> 00:00:40,079
thank you so much for joining me tonight

00:00:37,550 --> 00:00:43,309
this afternoon i should say the name of

00:00:40,079 --> 00:00:46,079
this talk is is that spam in my hand

00:00:43,309 --> 00:00:50,700
subtext a novices inquiry into

00:00:46,079 --> 00:00:53,039
classification so as my announcer

00:00:50,700 --> 00:00:55,110
already said my name is Lorena Meza and

00:00:53,039 --> 00:00:58,440
as you can see I'm a huge Star Trek fan

00:00:55,110 --> 00:01:01,649
so live long and prosper lahood apart

00:00:58,440 --> 00:01:03,629
from that I'm here from Chicago a little

00:01:01,649 --> 00:01:06,119
bit about me and why I wanted to chat on

00:01:03,629 --> 00:01:08,610
this topic I'm actually a career changer

00:01:06,119 --> 00:01:11,460
so a few years ago I'm came from being a

00:01:08,610 --> 00:01:13,439
data analyst in the social in the social

00:01:11,460 --> 00:01:15,330
science space specifically i worked at

00:01:13,439 --> 00:01:17,430
obama for america doing data governance

00:01:15,330 --> 00:01:19,799
and I then switched into doing software

00:01:17,430 --> 00:01:21,450
engineering about three years ago some

00:01:19,799 --> 00:01:24,150
big questions that we're driving me at

00:01:21,450 --> 00:01:26,310
the time are captured in this talk but

00:01:24,150 --> 00:01:27,750
some other things i do i love Jengo

00:01:26,310 --> 00:01:30,329
girls I helped with the workshop

00:01:27,750 --> 00:01:32,130
yesterday it's a glorious glorious thing

00:01:30,329 --> 00:01:34,140
if you have the opportunity to mentor

00:01:32,130 --> 00:01:36,290
please do if you would like to sign up

00:01:34,140 --> 00:01:38,640
for another one please do it as well I

00:01:36,290 --> 00:01:40,979
pie lady Chicago with a group that I

00:01:38,640 --> 00:01:42,810
found it in Chicago and I recently was

00:01:40,979 --> 00:01:44,939
voted to the board of directors for the

00:01:42,810 --> 00:01:48,149
Python Software Foundation which is very

00:01:44,939 --> 00:01:50,880
exciting so I'm going to chat a little

00:01:48,149 --> 00:01:53,670
bit about this great experience that

00:01:50,880 --> 00:01:55,680
we've all had before I think we might

00:01:53,670 --> 00:01:58,320
have all had some kind of email at some

00:01:55,680 --> 00:02:00,329
point in time where we get something

00:01:58,320 --> 00:02:02,520
that flutters into our inbox and it has

00:02:00,329 --> 00:02:06,180
language like d junk and speed up your

00:02:02,520 --> 00:02:08,399
slow pc and of course we we we would

00:02:06,180 --> 00:02:11,760
trusted email that comes from AOL

00:02:08,399 --> 00:02:13,290
underscore member info at emails yes

00:02:11,760 --> 00:02:15,900
with a Z on it

00:02:13,290 --> 00:02:18,060
aol.com and of course I'm going to trust

00:02:15,900 --> 00:02:20,519
anything that tells me this is free this

00:02:18,060 --> 00:02:23,129
is great you really should do it so I

00:02:20,519 --> 00:02:25,170
think when we see emails like this we

00:02:23,129 --> 00:02:27,150
know visually just by looking at it that

00:02:25,170 --> 00:02:30,540
it's a piece of spam we know it's junk

00:02:27,150 --> 00:02:33,269
we don't care about it we ignore it so

00:02:30,540 --> 00:02:35,040
how do we move from saying I know it

00:02:33,269 --> 00:02:36,629
when I see it to say I can

00:02:35,040 --> 00:02:40,680
programmatically just have to what a

00:02:36,629 --> 00:02:42,299
piece of spam is by using Python so in

00:02:40,680 --> 00:02:45,000
today's chat we're going to be thinking

00:02:42,299 --> 00:02:47,400
about three questions one what is

00:02:45,000 --> 00:02:49,560
machine learning to how is

00:02:47,400 --> 00:02:52,650
classification a part of this world and

00:02:49,560 --> 00:02:54,359
three how can I use Python to solve a

00:02:52,650 --> 00:02:57,810
classification problem like spam

00:02:54,359 --> 00:02:59,480
detection this tech this chat is going

00:02:57,810 --> 00:03:01,530
to be really focused on a beginner

00:02:59,480 --> 00:03:03,030
understanding of machine learning so if

00:03:01,530 --> 00:03:04,889
you are looking for more intermediate

00:03:03,030 --> 00:03:06,750
and advanced talks I definitely know

00:03:04,889 --> 00:03:08,250
this would be a great conference to

00:03:06,750 --> 00:03:09,750
check out some of that but we're going

00:03:08,250 --> 00:03:14,760
to really be taking this from the lens

00:03:09,750 --> 00:03:16,530
of a beginner so machine learning if you

00:03:14,760 --> 00:03:18,949
were to follow the emojis on the left

00:03:16,530 --> 00:03:22,049
hand side the top left would be me

00:03:18,949 --> 00:03:25,680
confused not sure what machine learning

00:03:22,049 --> 00:03:29,040
is I'm like is it a robot is it Johnny

00:03:25,680 --> 00:03:30,959
Five Johnny Five being a superhero from

00:03:29,040 --> 00:03:33,810
a children's movie I loved when I was a

00:03:30,959 --> 00:03:35,449
little kid who's super quirky can arch

00:03:33,810 --> 00:03:38,280
their eyebrows and come save the day

00:03:35,449 --> 00:03:40,560
well I don't really think machine

00:03:38,280 --> 00:03:41,819
learning is Johnny Five so let's go

00:03:40,560 --> 00:03:45,419
ahead and think a little bit about what

00:03:41,819 --> 00:03:47,220
machine learning is one of the things I

00:03:45,419 --> 00:03:48,900
like to do when I begin working in a new

00:03:47,220 --> 00:03:50,909
problem space is I try to find some

00:03:48,900 --> 00:03:53,459
language to actually gravitate myself to

00:03:50,909 --> 00:03:56,280
understand what types of problems I will

00:03:53,459 --> 00:03:58,379
be solving if I were to look around for

00:03:56,280 --> 00:04:00,750
some language defining machine learning

00:03:58,379 --> 00:04:02,639
I might find something like this some

00:04:00,750 --> 00:04:04,729
discussions saying that there's pattern

00:04:02,639 --> 00:04:07,799
recognition computational learning

00:04:04,729 --> 00:04:09,629
artificial intelligence what's going on

00:04:07,799 --> 00:04:11,310
I don't know what that is but there is a

00:04:09,629 --> 00:04:13,889
part of this that does make sense to me

00:04:11,310 --> 00:04:16,500
the study of algorithms that can learn

00:04:13,889 --> 00:04:20,669
and make predictions on data I like data

00:04:16,500 --> 00:04:22,260
I like algorithms tell me more so I

00:04:20,669 --> 00:04:23,760
think a better way we can think about

00:04:22,260 --> 00:04:26,520
machine learning is to borrow some

00:04:23,760 --> 00:04:29,580
language from Tom Mitchell the chair of

00:04:26,520 --> 00:04:31,889
machine learning department at Carnegie

00:04:29,580 --> 00:04:33,720
Mellon hero machine learning which is

00:04:31,889 --> 00:04:35,220
kind of a quintessential text for folks

00:04:33,720 --> 00:04:37,289
who want to start learning about machine

00:04:35,220 --> 00:04:40,139
learning and he says we can think about

00:04:37,289 --> 00:04:44,009
machine learning in three kind of parts

00:04:40,139 --> 00:04:47,580
we can say a computer program is set to

00:04:44,009 --> 00:04:50,250
learn from experience e with respect to

00:04:47,580 --> 00:04:53,580
some task T and some performance

00:04:50,250 --> 00:04:57,620
measurement p if its performance on T as

00:04:53,580 --> 00:05:00,210
measured by P improves with experience e

00:04:57,620 --> 00:05:01,919
okay so we have a task we have

00:05:00,210 --> 00:05:04,860
experience we have a performance

00:05:01,919 --> 00:05:07,380
measurement I can do this this makes

00:05:04,860 --> 00:05:09,360
sense to me so what I think about

00:05:07,380 --> 00:05:11,699
experience how do I know what I know

00:05:09,360 --> 00:05:13,560
well I'm a human and when I went up

00:05:11,699 --> 00:05:16,889
being a human the way that I know what I

00:05:13,560 --> 00:05:19,050
know comes from my memory I I have

00:05:16,889 --> 00:05:20,940
memories stored up that teach me things

00:05:19,050 --> 00:05:23,729
about what I like what I don't like what

00:05:20,940 --> 00:05:26,069
I should do what I shouldn't do so maybe

00:05:23,729 --> 00:05:28,319
as a kid and I was a very hyperactive

00:05:26,069 --> 00:05:30,630
child I would be running around like a

00:05:28,319 --> 00:05:33,060
maniac all the time because I had to be

00:05:30,630 --> 00:05:34,560
super fast but what happens when you run

00:05:33,060 --> 00:05:36,419
around as a little kid and you're

00:05:34,560 --> 00:05:38,849
growing in your body you might be klutzy

00:05:36,419 --> 00:05:39,990
you might fall and skin your knee how

00:05:38,849 --> 00:05:42,539
many times you have to skin your knee

00:05:39,990 --> 00:05:44,909
elbows for me it probably took quite

00:05:42,539 --> 00:05:47,069
some time for me to learn I shouldn't

00:05:44,909 --> 00:05:49,469
run around like a like a maniac I should

00:05:47,069 --> 00:05:51,659
walk around like a normal person so I

00:05:49,469 --> 00:05:54,389
don't hurt myself that pain was a

00:05:51,659 --> 00:05:55,860
teaching experience for me likewise when

00:05:54,389 --> 00:05:58,080
my grandmother was in the kitchen making

00:05:55,860 --> 00:06:00,029
tamales because I love them others I

00:05:58,080 --> 00:06:02,819
would always trying to be sticking my

00:06:00,029 --> 00:06:06,060
hand on the stove and more than once I

00:06:02,819 --> 00:06:08,250
definitely burned my hand the idea of

00:06:06,060 --> 00:06:10,590
putting your hand on red-hot coils not

00:06:08,250 --> 00:06:12,599
very smart so over time I learned to

00:06:10,590 --> 00:06:14,880
recognize that as a sign I should do

00:06:12,599 --> 00:06:17,669
that so when we think of experience as a

00:06:14,880 --> 00:06:19,020
human we may think of our memories what

00:06:17,669 --> 00:06:21,449
does that mean in different problem

00:06:19,020 --> 00:06:23,610
spaces if I were to ask the question

00:06:21,449 --> 00:06:26,219
what is the historical experience of the

00:06:23,610 --> 00:06:28,560
stock market well I could say if I want

00:06:26,219 --> 00:06:30,569
to understand what a piece of stock has

00:06:28,560 --> 00:06:33,300
done historically i might go look at

00:06:30,569 --> 00:06:35,880
what the records tell me about the price

00:06:33,300 --> 00:06:37,979
of that stock two years ago on july

00:06:35,880 --> 00:06:40,050
seventeenth one year ago on july

00:06:37,979 --> 00:06:40,230
seventeenth and you know depending on

00:06:40,050 --> 00:06:42,270
how

00:06:40,230 --> 00:06:44,220
far back I want to do some analysis I

00:06:42,270 --> 00:06:45,540
have historical data that can tell me

00:06:44,220 --> 00:06:47,820
something about the historical

00:06:45,540 --> 00:06:49,950
performance of that stock so we have

00:06:47,820 --> 00:06:52,560
human memories we have some memories

00:06:49,950 --> 00:06:54,270
there but maybe in other spaces again we

00:06:52,560 --> 00:06:57,150
want to go to historical data that can

00:06:54,270 --> 00:06:59,190
teach us something and so coming to

00:06:57,150 --> 00:07:02,130
machine learning and classification what

00:06:59,190 --> 00:07:04,590
does experience actually mean let's

00:07:02,130 --> 00:07:07,020
frame this in mitchell's framework our

00:07:04,590 --> 00:07:10,020
first problem is going to be identifying

00:07:07,020 --> 00:07:13,050
a task for us we want to classify a

00:07:10,020 --> 00:07:16,770
piece of data so our question is is an

00:07:13,050 --> 00:07:18,780
email spam or ham and the idea here of

00:07:16,770 --> 00:07:21,450
ham is just anything that's not spam

00:07:18,780 --> 00:07:24,690
it's cute it rhymes so spam or ham

00:07:21,450 --> 00:07:26,400
that's our task our experience we're

00:07:24,690 --> 00:07:28,770
going to have a set of label training

00:07:26,400 --> 00:07:30,450
data essentially what does that mean we

00:07:28,770 --> 00:07:33,510
have a collection of emails and we have

00:07:30,450 --> 00:07:35,640
a label that's that is saying that the

00:07:33,510 --> 00:07:37,260
email is either ham or spam so we have a

00:07:35,640 --> 00:07:41,070
collection of emails that we already

00:07:37,260 --> 00:07:43,440
know is one thing or the other and then

00:07:41,070 --> 00:07:45,840
our performance measurement is the label

00:07:43,440 --> 00:07:48,840
correct so what we need to do is be able

00:07:45,840 --> 00:07:52,920
to verify if emails are indeed spam or

00:07:48,840 --> 00:07:55,400
ham so thinking about a classifier that

00:07:52,920 --> 00:07:58,100
we can use we can think of naive Bayes

00:07:55,400 --> 00:08:01,080
naive Bayes is a type of probabilistic

00:07:58,100 --> 00:08:03,120
classifier I love this image because I

00:08:01,080 --> 00:08:05,940
really want to know who's the person

00:08:03,120 --> 00:08:08,190
that has a neon light of the Bayes

00:08:05,940 --> 00:08:10,380
theorem like in their office or in their

00:08:08,190 --> 00:08:12,420
front window I don't know who that

00:08:10,380 --> 00:08:15,480
person is but I applaud you you are

00:08:12,420 --> 00:08:17,520
really great so naive Bayes comes to us

00:08:15,480 --> 00:08:20,790
from stats theory it's based on the

00:08:17,520 --> 00:08:23,730
Bayes theorem no surprise one of the key

00:08:20,790 --> 00:08:26,250
things with the Bayes theorem is when we

00:08:23,730 --> 00:08:28,680
talk about the likelihood of events the

00:08:26,250 --> 00:08:30,620
key thing here to note is that we treat

00:08:28,680 --> 00:08:33,300
events as independent of one another

00:08:30,620 --> 00:08:34,680
that's where the naive assumption comes

00:08:33,300 --> 00:08:39,210
from when we say we're going to be using

00:08:34,680 --> 00:08:41,040
a naive Bayes classifier so for those of

00:08:39,210 --> 00:08:43,290
us who may not remember exactly what it

00:08:41,040 --> 00:08:45,210
means when we talk about independent and

00:08:43,290 --> 00:08:47,910
dependent events let's have a quick

00:08:45,210 --> 00:08:49,590
refresher so if I was going to ask you

00:08:47,910 --> 00:08:51,690
what's the probability of flipping a

00:08:49,590 --> 00:08:52,410
quarter six times in a row and getting

00:08:51,690 --> 00:08:54,240
head

00:08:52,410 --> 00:08:56,639
how would you go about solving that

00:08:54,240 --> 00:08:59,069
problem well let's think about it on the

00:08:56,639 --> 00:09:01,410
first flip I have two outcomes I have

00:08:59,069 --> 00:09:04,290
heads or tails so the likelihood of

00:09:01,410 --> 00:09:08,220
getting heads is going to be 0.5 the

00:09:04,290 --> 00:09:11,459
second time I flip that 0.5 third time

00:09:08,220 --> 00:09:13,620
and so forth it's going to be 0.5 so the

00:09:11,459 --> 00:09:15,540
likelihood of flipping a quarter and

00:09:13,620 --> 00:09:17,060
receiving multiple heads in a row is

00:09:15,540 --> 00:09:19,379
going to be independent of one another

00:09:17,060 --> 00:09:22,009
so we talked about independent events

00:09:19,379 --> 00:09:25,170
we're trying to think of it outcomes in

00:09:22,009 --> 00:09:27,240
contrast to dependent events let's say

00:09:25,170 --> 00:09:30,509
we're talking about horse number five on

00:09:27,240 --> 00:09:32,610
the I guess your right hand side if my

00:09:30,509 --> 00:09:34,769
question was what's the likelihood that

00:09:32,610 --> 00:09:37,529
horse number five is going to win the

00:09:34,769 --> 00:09:39,779
big Derby one of the things i would say

00:09:37,529 --> 00:09:41,550
is well we need to think about what are

00:09:39,779 --> 00:09:44,040
what are the weather conditions is it

00:09:41,550 --> 00:09:45,420
rainy is it sunny perhaps we want to

00:09:44,040 --> 00:09:47,790
think about the age of the horse the

00:09:45,420 --> 00:09:50,009
health of the horse there can be other

00:09:47,790 --> 00:09:53,040
things that are that are tied up in the

00:09:50,009 --> 00:09:55,529
likelihood of horse number five winning

00:09:53,040 --> 00:09:57,689
so in this context the probability of

00:09:55,529 --> 00:09:59,759
horse number five winning is going to be

00:09:57,689 --> 00:10:02,220
dependent on other things for example

00:09:59,759 --> 00:10:05,189
the weather so when we talk about naive

00:10:02,220 --> 00:10:07,920
bayes we are assumption is we have

00:10:05,189 --> 00:10:10,380
independent events so when we talk about

00:10:07,920 --> 00:10:12,209
emails we're really going to be thinking

00:10:10,380 --> 00:10:16,019
about the words that make up the emails

00:10:12,209 --> 00:10:17,670
so let's think about these words if I

00:10:16,019 --> 00:10:19,740
was going to say what's the likelihood

00:10:17,670 --> 00:10:21,899
of the word messy appearing with the

00:10:19,740 --> 00:10:24,000
word Barcelona we're going to assume

00:10:21,899 --> 00:10:26,040
that there's no relationship that's what

00:10:24,000 --> 00:10:27,449
naive Bayes tells us to do even though

00:10:26,040 --> 00:10:30,360
in our heads we might think that there's

00:10:27,449 --> 00:10:32,819
a relationship or back to some really

00:10:30,360 --> 00:10:34,889
spammy language we love what's the

00:10:32,819 --> 00:10:36,059
relationship between x and now we're

00:10:34,889 --> 00:10:38,970
going to assume that there is no

00:10:36,059 --> 00:10:41,819
relationship that the likelihood of x is

00:10:38,970 --> 00:10:44,639
not going to be impacting the likelihood

00:10:41,819 --> 00:10:49,050
of now appearing in a corpus of words

00:10:44,639 --> 00:10:51,990
for an email so naive bayes and spam

00:10:49,050 --> 00:10:54,029
classifiers again our question is what

00:10:51,990 --> 00:10:57,329
is the probability of an email beings

00:10:54,029 --> 00:10:59,339
ham or spam so these the Bayes theorem

00:10:57,329 --> 00:11:01,680
here in the middle we've got three

00:10:59,339 --> 00:11:03,959
things we need to kind of think of one

00:11:01,680 --> 00:11:05,000
what's the likelihood of the predictors

00:11:03,959 --> 00:11:08,000
in the class

00:11:05,000 --> 00:11:10,910
to the prior probability of the class

00:11:08,000 --> 00:11:13,220
and three the prior probability of the

00:11:10,910 --> 00:11:15,910
predictor all these together will help

00:11:13,220 --> 00:11:18,890
us compute through the a posteriori

00:11:15,910 --> 00:11:22,730
probability of a class so when I say

00:11:18,890 --> 00:11:24,590
class our class is here ham spam those

00:11:22,730 --> 00:11:27,020
are the only two classes we have our

00:11:24,590 --> 00:11:30,230
predictors are going to be the words in

00:11:27,020 --> 00:11:32,420
the email itself so for example if I'm

00:11:30,230 --> 00:11:34,460
looking at a piece of content and I say

00:11:32,420 --> 00:11:38,050
okay well what's the likelihood of a

00:11:34,460 --> 00:11:40,670
predictor being in the spam or ham class

00:11:38,050 --> 00:11:44,030
we can say if I'm looking at the word

00:11:40,670 --> 00:11:47,270
free we can think of it as well 28 out

00:11:44,030 --> 00:11:51,110
of 50 spam emails have the word free we

00:11:47,270 --> 00:11:53,510
will do this for each word in our email

00:11:51,110 --> 00:11:54,740
and we will find the likelihoods of all

00:11:53,510 --> 00:11:57,140
the predictors and multiply them

00:11:54,740 --> 00:11:59,570
together we also then need to consider

00:11:57,140 --> 00:12:01,550
the prior probability of the class so

00:11:59,570 --> 00:12:04,310
given the entire collection of data

00:12:01,550 --> 00:12:06,620
we're looking at how many of them are of

00:12:04,310 --> 00:12:09,410
one class and how many of another so for

00:12:06,620 --> 00:12:11,750
spam if we have 150 emails we're working

00:12:09,410 --> 00:12:15,589
with we can say 50 of those documents

00:12:11,750 --> 00:12:17,870
are spam so 50 out of 150 and then the

00:12:15,589 --> 00:12:19,940
prior probability of the predictor we're

00:12:17,870 --> 00:12:21,980
here saying well how many times has the

00:12:19,940 --> 00:12:25,520
word free appeared in all of our emails

00:12:21,980 --> 00:12:28,790
let's say it's 72 out of 150 and there

00:12:25,520 --> 00:12:31,070
you go so the Bayes theorem is basically

00:12:28,790 --> 00:12:33,380
frequency tables how many times has this

00:12:31,070 --> 00:12:35,089
thing appeared how many times has it

00:12:33,380 --> 00:12:36,650
appeared in the class how many times has

00:12:35,089 --> 00:12:41,510
this class appeared in the collection of

00:12:36,650 --> 00:12:44,660
things that we're looking at great we've

00:12:41,510 --> 00:12:46,790
we've made some calculations we found we

00:12:44,660 --> 00:12:48,860
found some values between 0 to 1 how do

00:12:46,790 --> 00:12:51,589
we know which one to pick pretty easy

00:12:48,860 --> 00:12:54,470
whichever one has the higher maximum a

00:12:51,589 --> 00:12:56,720
posteriori probability so the reason why

00:12:54,470 --> 00:12:58,250
we would say a posteriori here is we're

00:12:56,720 --> 00:12:59,990
not looking at anything new we're

00:12:58,250 --> 00:13:03,020
looking at historical data things that I

00:12:59,990 --> 00:13:06,320
have already happened once we've made a

00:13:03,020 --> 00:13:08,660
calculation for class ham and for class

00:13:06,320 --> 00:13:11,390
spam we simply just pick the larger of

00:13:08,660 --> 00:13:15,339
the two and we say this email is going

00:13:11,390 --> 00:13:17,540
to be either ham or spam pretty simple

00:13:15,339 --> 00:13:19,730
so why naive Bayes

00:13:17,540 --> 00:13:22,370
well I think just walking through this

00:13:19,730 --> 00:13:23,870
we can arrive at an answer it's pretty

00:13:22,370 --> 00:13:26,120
straightforward it's as simple as

00:13:23,870 --> 00:13:28,160
frequency tables I think we can all do

00:13:26,120 --> 00:13:29,720
this together it may seem a little bit

00:13:28,160 --> 00:13:31,970
daunting at first but once you start

00:13:29,720 --> 00:13:34,160
realizing the application of it you can

00:13:31,970 --> 00:13:36,079
see that it's pretty straightforward so

00:13:34,160 --> 00:13:38,240
for the context of if you are starting

00:13:36,079 --> 00:13:39,769
to think about classifiers and problems

00:13:38,240 --> 00:13:41,149
you want to start looking at I would say

00:13:39,769 --> 00:13:43,370
this is a great one to start with the

00:13:41,149 --> 00:13:45,410
math is accessible and while you can use

00:13:43,370 --> 00:13:47,660
other algorithms we will talk about some

00:13:45,410 --> 00:13:50,120
the limitations in a moment this is a

00:13:47,660 --> 00:13:54,130
good one to start with so that's great

00:13:50,120 --> 00:13:57,079
but how do I use Python to detect spam

00:13:54,130 --> 00:13:59,540
okay well I cheated a little bit I

00:13:57,079 --> 00:14:02,529
didn't do all my own data collection and

00:13:59,540 --> 00:14:05,630
lunging and cleaning as fun as that is I

00:14:02,529 --> 00:14:07,550
instead when to find a data source out

00:14:05,630 --> 00:14:09,319
there that already was cleaned and

00:14:07,550 --> 00:14:11,300
labeled for me and where did I get it I

00:14:09,319 --> 00:14:14,029
got it from Kegel in the classroom so

00:14:11,300 --> 00:14:16,370
this is a this is a website that has

00:14:14,029 --> 00:14:17,839
competitions so the classroom component

00:14:16,370 --> 00:14:19,310
is more they're teaching problems they

00:14:17,839 --> 00:14:22,040
have open competition problems as well

00:14:19,310 --> 00:14:23,839
but I loved that my data was cleaned and

00:14:22,040 --> 00:14:26,029
labeled and I could just get right to

00:14:23,839 --> 00:14:30,670
work building a thing so in our example

00:14:26,029 --> 00:14:34,790
here our training data has 2,500 emails

00:14:30,670 --> 00:14:37,430
7 1721 of them which are labeled one as

00:14:34,790 --> 00:14:40,639
ham and the balance labeled as spam

00:14:37,430 --> 00:14:43,069
which is zero so the labels themselves

00:14:40,639 --> 00:14:45,500
are just in a CSV we have an ID and we

00:14:43,069 --> 00:14:47,990
have the prediction 0 or 1 pretty

00:14:45,500 --> 00:14:50,329
straightforward and the that's a little

00:14:47,990 --> 00:14:52,550
grainy I apologize but the emails

00:14:50,329 --> 00:14:56,029
themselves are collections of text with

00:14:52,550 --> 00:14:58,399
some HTML in it so what are we going to

00:14:56,029 --> 00:15:00,949
use we write our very very simplistic

00:14:58,399 --> 00:15:02,209
naive Bayes spam classifier we're going

00:15:00,949 --> 00:15:03,800
to use these three things we're going to

00:15:02,209 --> 00:15:05,660
use email it's going to go ahead and

00:15:03,800 --> 00:15:08,329
parse our emails into message objects

00:15:05,660 --> 00:15:10,579
we're going to use lxml because as I

00:15:08,329 --> 00:15:12,560
said those emails have some HTML

00:15:10,579 --> 00:15:15,170
embedded in it and right now all i care

00:15:12,560 --> 00:15:17,149
about is the is the words themselves so

00:15:15,170 --> 00:15:19,939
i want to strip that stuff out and then

00:15:17,149 --> 00:15:21,230
we'll use NLT k natural language toolkit

00:15:19,939 --> 00:15:24,410
and that's going to help us to filter

00:15:21,230 --> 00:15:27,910
out stop words so let's go ahead and get

00:15:24,410 --> 00:15:30,980
to it and train the spam filter

00:15:27,910 --> 00:15:33,580
so the training of the Python naive

00:15:30,980 --> 00:15:35,540
bayes classifier when when i say train

00:15:33,580 --> 00:15:37,310
we're going to go through these steps

00:15:35,540 --> 00:15:39,980
the first thing we're going to do is

00:15:37,310 --> 00:15:42,590
we're going to tokenize the text we will

00:15:39,980 --> 00:15:44,450
explain that in just a moment one thing

00:15:42,590 --> 00:15:47,089
I do want to say is when we look at all

00:15:44,450 --> 00:15:49,310
the corpus of words in an email I am NOT

00:15:47,089 --> 00:15:52,100
treating words like shop and shopping as

00:15:49,310 --> 00:15:54,230
the same word you can actually do that

00:15:52,100 --> 00:15:55,850
that's called stemming so that would be

00:15:54,230 --> 00:15:57,350
like a bonus feature i encourage you to

00:15:55,850 --> 00:15:58,910
go try that on your own so I didn't do

00:15:57,350 --> 00:16:00,410
that for this example so we're going to

00:15:58,910 --> 00:16:02,870
go ahead we're going to tokenize our

00:16:00,410 --> 00:16:05,120
words which that we're going to do it

00:16:02,870 --> 00:16:07,760
for each email that we process we wanted

00:16:05,120 --> 00:16:10,490
then keep track of the unique words that

00:16:07,760 --> 00:16:12,980
we see of all the documents that we

00:16:10,490 --> 00:16:15,710
process this will come into effect to

00:16:12,980 --> 00:16:17,180
help us with zero word frequencies we

00:16:15,710 --> 00:16:20,089
are going to then increment increment

00:16:17,180 --> 00:16:22,220
the word frequency for each category so

00:16:20,089 --> 00:16:24,650
our category is here being ham or spam

00:16:22,220 --> 00:16:27,320
we're going to increment the category

00:16:24,650 --> 00:16:29,060
count which again is that prior

00:16:27,320 --> 00:16:31,400
probability of the classes that we need

00:16:29,060 --> 00:16:33,200
to take into account and then we're also

00:16:31,400 --> 00:16:36,350
just going to keep a track of how many

00:16:33,200 --> 00:16:38,060
words are in each category and it's good

00:16:36,350 --> 00:16:39,920
to know how many training examples we've

00:16:38,060 --> 00:16:43,400
actually processed so that's the last

00:16:39,920 --> 00:16:46,070
step so training is pretty much going to

00:16:43,400 --> 00:16:48,740
start with this tokenizing text into a

00:16:46,070 --> 00:16:51,650
bag of words that's what it is it's a

00:16:48,740 --> 00:16:53,089
bag of words so essentially this is very

00:16:51,650 --> 00:16:54,860
simplistic I've kind of trimmed it down

00:16:53,089 --> 00:16:56,420
a little what we want to do is we want

00:16:54,860 --> 00:16:59,540
to pull out the words this is already

00:16:56,420 --> 00:17:01,339
after we've removed the HTML that's

00:16:59,540 --> 00:17:04,160
embedded and we're going to say hey for

00:17:01,339 --> 00:17:06,650
each word in our text let's go ahead

00:17:04,160 --> 00:17:09,800
lowercase the word we're going to say if

00:17:06,650 --> 00:17:11,089
it's a word because why not and we're

00:17:09,800 --> 00:17:13,520
going to say as long as this word isn't

00:17:11,089 --> 00:17:15,650
in our in the corpus of stop words for

00:17:13,520 --> 00:17:18,020
the English language let's go ahead and

00:17:15,650 --> 00:17:21,380
keep it so stop words are words like the

00:17:18,020 --> 00:17:23,089
and or words that have may appear may

00:17:21,380 --> 00:17:25,189
appear often but may not provide us a

00:17:23,089 --> 00:17:29,000
lot of that value when thinking about if

00:17:25,189 --> 00:17:31,580
this thing is going to be spam or not so

00:17:29,000 --> 00:17:35,240
you can get that from NLT k I'm glad I

00:17:31,580 --> 00:17:36,740
didn't have to compile that we go ahead

00:17:35,240 --> 00:17:40,190
we do this for each email and now we

00:17:36,740 --> 00:17:40,940
have a bag of words so remember that 0

00:17:40,190 --> 00:17:43,400
word

00:17:40,940 --> 00:17:45,650
Qin see thing I was talking about well

00:17:43,400 --> 00:17:48,230
let's think about this so I've done my

00:17:45,650 --> 00:17:49,670
training and I have a new email in this

00:17:48,230 --> 00:17:52,040
email that I'm looking at that I'm

00:17:49,670 --> 00:17:55,580
trying to classify I have the word free

00:17:52,040 --> 00:17:57,620
but problem I've never historically have

00:17:55,580 --> 00:17:59,330
seen the word free in the spam

00:17:57,620 --> 00:18:01,100
collection of emails that I've looked at

00:17:59,330 --> 00:18:03,110
so what's going to happen when I

00:18:01,100 --> 00:18:06,530
calculate the likelihood of all my

00:18:03,110 --> 00:18:08,330
predictors I'm going to get zero so to

00:18:06,530 --> 00:18:10,490
offset that what we can do is we can add

00:18:08,330 --> 00:18:12,560
a small constant like which l'appeler

00:18:10,490 --> 00:18:14,600
smoothing permits us to do and that

00:18:12,560 --> 00:18:17,260
allows us to have a small offset so that

00:18:14,600 --> 00:18:21,200
it doesn't throw our math out the window

00:18:17,260 --> 00:18:23,750
so let's talk about classifying alright

00:18:21,200 --> 00:18:26,030
so this is a giant wall of text but i

00:18:23,750 --> 00:18:28,450
just wanted to point out but it's quite

00:18:26,030 --> 00:18:30,620
literally iterations counting's

00:18:28,450 --> 00:18:33,350
dictionaries that's all this is there is

00:18:30,620 --> 00:18:35,480
no black box magic here essentially what

00:18:33,350 --> 00:18:38,120
we do in the classifies we say for each

00:18:35,480 --> 00:18:40,370
category that we're going to create this

00:18:38,120 --> 00:18:42,860
a posterior probability we want to go

00:18:40,370 --> 00:18:45,140
ahead find the probability of all the

00:18:42,860 --> 00:18:47,150
predictors we want to then multiply that

00:18:45,140 --> 00:18:48,950
by the prior probability of the classes

00:18:47,150 --> 00:18:50,330
itself and we're going to pick the one

00:18:48,950 --> 00:18:52,910
that has the higher value and that's

00:18:50,330 --> 00:18:55,550
what we classify the email as not very

00:18:52,910 --> 00:18:57,470
magical so in the get predictors

00:18:55,550 --> 00:18:59,060
probability if we see something we

00:18:57,470 --> 00:19:02,120
haven't seen before we're going to go

00:18:59,060 --> 00:19:04,580
ahead and then add a value of one to

00:19:02,120 --> 00:19:07,490
that and this point right here about

00:19:04,580 --> 00:19:09,500
floating point underflow when you are

00:19:07,490 --> 00:19:13,040
doing computations where you really care

00:19:09,500 --> 00:19:14,420
about having very precise decimal points

00:19:13,040 --> 00:19:17,330
you're going to need to use specific

00:19:14,420 --> 00:19:19,250
objects you could use a log instead but

00:19:17,330 --> 00:19:21,590
in this case I use decimal objects and

00:19:19,250 --> 00:19:23,330
there is a note here which you probably

00:19:21,590 --> 00:19:25,640
can't read i will share these slides

00:19:23,330 --> 00:19:27,500
which comes from the stanford natural

00:19:25,640 --> 00:19:30,790
language processing description about

00:19:27,500 --> 00:19:33,380
how to handle doing a floating-point

00:19:30,790 --> 00:19:36,860
computation and they said use decimals

00:19:33,380 --> 00:19:38,600
so that's what I went with so okay

00:19:36,860 --> 00:19:40,970
performance measurement I've classified

00:19:38,600 --> 00:19:45,470
I picked a thing how do I know how well

00:19:40,970 --> 00:19:48,080
I did okay so I go ahead my detector

00:19:45,470 --> 00:19:50,570
said let's try and evaluate what I

00:19:48,080 --> 00:19:53,150
eventually come out with is I have 223

00:19:50,570 --> 00:19:54,269
better correct 27 incorrect my

00:19:53,150 --> 00:19:56,909
performance measurement

00:19:54,269 --> 00:20:00,779
about eighty nine percent at the small

00:19:56,909 --> 00:20:02,369
footnote the idea of about ninety

00:20:00,779 --> 00:20:05,219
percent accuracy I believe is a

00:20:02,369 --> 00:20:07,259
benchmark we obviously can do better

00:20:05,219 --> 00:20:10,859
here and we'll talk about what doing

00:20:07,259 --> 00:20:12,629
better can mean in a moment so the idea

00:20:10,859 --> 00:20:16,409
of how to split up our training data

00:20:12,629 --> 00:20:18,029
let's do a 9010 split it's pretty much

00:20:16,409 --> 00:20:19,529
what i've seen as a standard i'm sure

00:20:18,029 --> 00:20:20,940
given different problem spaces you might

00:20:19,529 --> 00:20:23,070
want to chunk things up differently but

00:20:20,940 --> 00:20:25,200
i went with a 9010 split essentially all

00:20:23,070 --> 00:20:28,169
i did was say hey on ninety percent of

00:20:25,200 --> 00:20:29,940
my data let's go i have classify let's

00:20:28,169 --> 00:20:31,259
go ahead and train that is and then on

00:20:29,940 --> 00:20:33,749
ten percent we're going to go ahead and

00:20:31,259 --> 00:20:35,399
classify and how do we know if the thing

00:20:33,749 --> 00:20:37,079
is incorrect or correct well whatever

00:20:35,399 --> 00:20:39,509
plot whatever label we ultimately

00:20:37,079 --> 00:20:41,219
assigned it check that labels that CSV

00:20:39,509 --> 00:20:42,690
see if it's correct see if it's

00:20:41,219 --> 00:20:45,149
incorrect and it's basically straight

00:20:42,690 --> 00:20:50,239
map so that's how we got the eighty-nine

00:20:45,149 --> 00:20:54,529
percent so some things to watch out for

00:20:50,239 --> 00:20:57,809
false positives ooh this is really fine

00:20:54,529 --> 00:21:00,029
so for example Google does things really

00:20:57,809 --> 00:21:02,190
well right they do really good with spam

00:21:00,029 --> 00:21:04,349
filtering but even they can have some

00:21:02,190 --> 00:21:06,749
flaws so I do actually like to sign up

00:21:04,349 --> 00:21:08,940
for patagonia emails and this email was

00:21:06,749 --> 00:21:10,829
actually flagged as spam so we basically

00:21:08,940 --> 00:21:13,469
a false positive is when something is

00:21:10,829 --> 00:21:15,929
incorrectly identified right so you can

00:21:13,469 --> 00:21:17,609
run into this so we can say well when

00:21:15,929 --> 00:21:20,070
something is incorrect what's the

00:21:17,609 --> 00:21:21,629
problem is it that our implementation

00:21:20,070 --> 00:21:24,269
because we're talking about naive Bayes

00:21:21,629 --> 00:21:26,700
is it too naive one way we can also

00:21:24,269 --> 00:21:29,039
corrupt this we can tell Google and say

00:21:26,700 --> 00:21:30,719
hey this is actually not spam so i can

00:21:29,039 --> 00:21:32,479
actually validate the data and send it

00:21:30,719 --> 00:21:34,619
to them and they can put it into their

00:21:32,479 --> 00:21:36,479
implementation and try to auto correct

00:21:34,619 --> 00:21:38,279
for that in the future so false

00:21:36,479 --> 00:21:40,950
positives are going to watch out for and

00:21:38,279 --> 00:21:43,709
some limitations with naive bayes and

00:21:40,950 --> 00:21:46,559
some challenges obviously this

00:21:43,709 --> 00:21:49,049
independence assumption is very very

00:21:46,559 --> 00:21:52,200
simplistic if i get a marketing email

00:21:49,049 --> 00:21:53,519
about barcelona and they aren't talking

00:21:52,200 --> 00:21:56,279
about Messi I'm going to be very

00:21:53,519 --> 00:21:58,469
confused i granted there are some talks

00:21:56,279 --> 00:22:00,479
about him being traded so we shall see

00:21:58,469 --> 00:22:02,639
but obviously this independence

00:22:00,479 --> 00:22:03,960
assumption is quite simplistic it is not

00:22:02,639 --> 00:22:06,450
the way that things work in the real

00:22:03,960 --> 00:22:07,740
world what are the side effects of that

00:22:06,450 --> 00:22:08,940
well one of the things that

00:22:07,740 --> 00:22:11,490
then we're going to go ahead and

00:22:08,940 --> 00:22:14,340
overestimate the probability of the of

00:22:11,490 --> 00:22:15,780
the label ultimately selected meaning

00:22:14,340 --> 00:22:17,460
we're going to create more binaries

00:22:15,780 --> 00:22:19,140
we're going to say it's either more to

00:22:17,460 --> 00:22:21,809
left or more to the right and how it

00:22:19,140 --> 00:22:23,700
aligns with a category label and also we

00:22:21,809 --> 00:22:25,980
can think about this remember how I said

00:22:23,700 --> 00:22:28,020
I cheated and I didn't go and label on

00:22:25,980 --> 00:22:30,410
my own data well here's the other thing

00:22:28,020 --> 00:22:32,490
human error this type of algorithm

00:22:30,410 --> 00:22:35,309
classifiers are called supervised

00:22:32,490 --> 00:22:38,190
learning they they require historical

00:22:35,309 --> 00:22:39,780
labeled sets of of data to go ahead and

00:22:38,190 --> 00:22:43,230
learn from in order to make predictions

00:22:39,780 --> 00:22:46,170
well human error can be prone in this

00:22:43,230 --> 00:22:47,910
data process what happens if let's say

00:22:46,170 --> 00:22:50,610
I'm a professor and I'm making use of

00:22:47,910 --> 00:22:52,650
all my student lackeys and some of them

00:22:50,610 --> 00:22:54,300
have been up all night and 10 of them

00:22:52,650 --> 00:22:56,280
looked at the same email and they all

00:22:54,300 --> 00:22:58,050
came up with different labels for it but

00:22:56,280 --> 00:23:00,420
it's in my training set that's going to

00:22:58,050 --> 00:23:02,040
be very inconsistent so I need to think

00:23:00,420 --> 00:23:04,140
about that as well how was the labeling

00:23:02,040 --> 00:23:05,460
of the data happening so as much as we

00:23:04,140 --> 00:23:07,650
don't like to think about data munging

00:23:05,460 --> 00:23:09,660
data cleaning a data collection that's

00:23:07,650 --> 00:23:11,550
actually a really important part of the

00:23:09,660 --> 00:23:12,990
process when working with machine

00:23:11,550 --> 00:23:15,990
learning problem supervised machine

00:23:12,990 --> 00:23:19,380
learning problems so how can we improve

00:23:15,990 --> 00:23:21,450
our performance well we can do more and

00:23:19,380 --> 00:23:23,940
better feature extraction because while

00:23:21,450 --> 00:23:27,059
I would like to say that emails can only

00:23:23,940 --> 00:23:28,620
be identified by the words in them we

00:23:27,059 --> 00:23:30,570
know that's not true predicting

00:23:28,620 --> 00:23:32,040
sentiment of emails is very complicated

00:23:30,570 --> 00:23:34,530
very difficult natural language

00:23:32,040 --> 00:23:36,540
processing is a huge field I'm not

00:23:34,530 --> 00:23:38,070
getting into that myself but you know we

00:23:36,540 --> 00:23:40,400
need to think of other ways we can

00:23:38,070 --> 00:23:42,929
identify spam so what are some things

00:23:40,400 --> 00:23:44,640
perhaps the subject is there something

00:23:42,929 --> 00:23:47,250
weird in the subject i can pay attention

00:23:44,640 --> 00:23:49,410
to what about the images is there an

00:23:47,250 --> 00:23:51,720
abundance of images and spam emails or

00:23:49,410 --> 00:23:53,550
maybe there's none I don't know how

00:23:51,720 --> 00:23:55,740
about the sender remember that like

00:23:53,550 --> 00:23:58,140
really cool email address with the Z in

00:23:55,740 --> 00:24:01,170
it because clearly I would trust AOL

00:23:58,140 --> 00:24:03,630
emails died whatever that was then again

00:24:01,170 --> 00:24:06,210
I don't trust most AOL stuff so that's

00:24:03,630 --> 00:24:07,350
another thing but you know some other

00:24:06,210 --> 00:24:09,720
ones if we were just going to think

00:24:07,350 --> 00:24:12,120
about what to go ahead and consider

00:24:09,720 --> 00:24:14,270
other possible features we can think

00:24:12,120 --> 00:24:17,010
about capitalization your regular

00:24:14,270 --> 00:24:19,260
punctuation things like that ultimately

00:24:17,010 --> 00:24:20,070
we also want more data so do you like

00:24:19,260 --> 00:24:24,060
the adhan starch

00:24:20,070 --> 00:24:26,520
rec and have more want to learn more go

00:24:24,060 --> 00:24:28,200
to kegel they're super sweet I also

00:24:26,520 --> 00:24:29,730
would highly recommend Sarah Guido's

00:24:28,200 --> 00:24:31,770
introduction to machine learning with

00:24:29,730 --> 00:24:33,870
Python she's a great data scientist at

00:24:31,770 --> 00:24:36,750
bit ly and I've heard great things about

00:24:33,870 --> 00:24:38,700
this and also your local friendly Python

00:24:36,750 --> 00:24:40,590
user group we love talking we love

00:24:38,700 --> 00:24:42,330
learning together talk to people here

00:24:40,590 --> 00:24:45,230
there's a great talk after this talking

00:24:42,330 --> 00:24:49,590
more about machine learning stay for it

00:24:45,230 --> 00:24:51,000
so thanks and if anything I hope what

00:24:49,590 --> 00:24:53,160
you may have learned is correlation

00:24:51,000 --> 00:24:56,070
maybe causation or causation maybe

00:24:53,160 --> 00:24:57,630
correlation I don't know so we can

00:24:56,070 --> 00:24:59,820
implement a thing but the question then

00:24:57,630 --> 00:25:01,560
comes to how do we interpret those

00:24:59,820 --> 00:25:03,210
results and that's where I challenge you

00:25:01,560 --> 00:25:06,230
to go ahead and try some things out

00:25:03,210 --> 00:25:06,230
thank you so much

00:25:12,970 --> 00:25:26,690
sure any questions I did such a great

00:25:21,919 --> 00:25:29,630
job no one has any questions all right

00:25:26,690 --> 00:25:31,340
cool well if you do have questions I'll

00:25:29,630 --> 00:25:32,899
be hanging out in this area out here for

00:25:31,340 --> 00:25:34,639
a few minutes but like I said I do you

00:25:32,899 --> 00:25:36,559
want to hear the next talk so i'll be

00:25:34,639 --> 00:25:38,299
around my name is Lorena please reach

00:25:36,559 --> 00:25:41,620
out and say hi it's a pleasure to be

00:25:38,299 --> 00:25:41,620

YouTube URL: https://www.youtube.com/watch?v=a-Dj6MtyqXo


