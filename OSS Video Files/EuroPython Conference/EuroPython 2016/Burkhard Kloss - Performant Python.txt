Title: Burkhard Kloss - Performant Python
Publication date: 2016-07-28
Playlist: EuroPython 2016
Description: 
	Burkhard Kloss - Performant Python
[EuroPython 2016]
[18 July 2016]
[Bilbao, Euskadi, Spain]
(https://ep2016.europython.eu//conference/talks/performant-python)

Python is a great language. Easy to learn, friendly to use, widely used.

It is not, however, renowned for being fast.  In a lot of situations
that does not matter.  Sometimes it really does. This talk will
introduce you to some tools and techniques for making sure your Python
code becomes fast enough – without turning into a maintenance
nightmare. Warning: may contain small bits of other languages.

-----

Python is a great language. Easy to learn, friendly to use, widely used.

It is not, however, renowned for being fast.  In a lot of situations
that does not matter.  Sometimes it really does.  This talk will
introduce you to some tools and techniques for making sure your Python
code becomes fast enough – without turning into a maintenance
nightmare.  Fast code does not have to be unreadable - and when you're
writing Python, it really pays of to think "pythonically".

That does mean using the included batteries, and utilising the
ecosystem of tools around the language, too.

 Warning: may contain small bits of other languages.
Captions: 
	00:00:00,000 --> 00:00:12,030
good morning thank you that's a pleasant

00:00:10,620 --> 00:00:15,299
welcome thank you very much for coming

00:00:12,030 --> 00:00:18,810
to my talk I'm going to talk about

00:00:15,299 --> 00:00:20,010
perform Python now I'm slightly less

00:00:18,810 --> 00:00:21,570
organized and I forgot to bring

00:00:20,010 --> 00:00:23,990
batteries for my clicky things I'll be

00:00:21,570 --> 00:00:29,460
wandering back and forth bear with me

00:00:23,990 --> 00:00:31,949
what do I mean by performing Python I'd

00:00:29,460 --> 00:00:34,440
like us to think about writing good fast

00:00:31,949 --> 00:00:40,170
Python code now they're three words and

00:00:34,440 --> 00:00:42,030
they're good fast and Python and to my

00:00:40,170 --> 00:00:45,899
mind they kind of have equal

00:00:42,030 --> 00:00:50,370
significance let's talk about good code

00:00:45,899 --> 00:00:55,469
first now good code it's complicated as

00:00:50,370 --> 00:00:59,160
a concept we all know good code when we

00:00:55,469 --> 00:01:00,870
see it right there's there's all sorts

00:00:59,160 --> 00:01:02,820
of measurements you can apply and

00:01:00,870 --> 00:01:05,220
there's academic literature about what

00:01:02,820 --> 00:01:07,560
is good code and what's not good code as

00:01:05,220 --> 00:01:09,470
a working definition I'll just say it's

00:01:07,560 --> 00:01:15,830
code that we can easily read and

00:01:09,470 --> 00:01:21,810
understand the next thing is fast code

00:01:15,830 --> 00:01:23,850
now I love Python I've been programming

00:01:21,810 --> 00:01:27,540
in Python for oh I don't know since

00:01:23,850 --> 00:01:29,820
about version 1.6 and there lots of

00:01:27,540 --> 00:01:33,390
things i love about python but i don't

00:01:29,820 --> 00:01:35,939
write poison because it's fast right but

00:01:33,390 --> 00:01:39,420
it is fast enough for pretty much

00:01:35,939 --> 00:01:43,320
everything I need to do and with a few

00:01:39,420 --> 00:01:47,909
tricks it is actually fast enough for

00:01:43,320 --> 00:01:50,850
everything i do at the moment now i have

00:01:47,909 --> 00:01:56,520
to kind of limit that slightly my domain

00:01:50,850 --> 00:01:58,950
is mainly financial simulations so you

00:01:56,520 --> 00:02:01,530
know i do floating-point arithmetic all

00:01:58,950 --> 00:02:06,119
day long and for that is fast enough if

00:02:01,530 --> 00:02:08,700
your domain is web services io huge

00:02:06,119 --> 00:02:10,619
databases you might not get that much

00:02:08,700 --> 00:02:12,170
out of this talk but they're with me

00:02:10,619 --> 00:02:15,500
hopefully you'll enjoy it

00:02:12,170 --> 00:02:25,069
and the last word we want to talk about

00:02:15,500 --> 00:02:26,959
is oops Python we can you know there's

00:02:25,069 --> 00:02:28,310
the old joke about a good pro real

00:02:26,959 --> 00:02:33,830
program we can write for 21 in any

00:02:28,310 --> 00:02:36,800
language and as a card-carrying C++

00:02:33,830 --> 00:02:41,450
programmer I can certainly ride C++ or

00:02:36,800 --> 00:02:42,890
Java in Python particularly when people

00:02:41,450 --> 00:02:44,840
write Java and Python with lots of

00:02:42,890 --> 00:02:50,720
abstract interfaces and abstract methods

00:02:44,840 --> 00:02:52,580
it kind of irritates me but we can so I

00:02:50,720 --> 00:02:56,000
wanted to focus also on writing Python

00:02:52,580 --> 00:02:58,760
code for a for a number of reasons one

00:02:56,000 --> 00:03:03,260
is because it's it's actually much nicer

00:02:58,760 --> 00:03:06,230
to read and write then C++ and Python or

00:03:03,260 --> 00:03:10,280
Java and Python but also it's faster so

00:03:06,230 --> 00:03:14,209
let's move on with the slide that's gone

00:03:10,280 --> 00:03:16,760
out of sync before we talk about speed

00:03:14,209 --> 00:03:20,540
let's reconsider the famous quote from

00:03:16,760 --> 00:03:21,829
Knuth basically nights then percent of

00:03:20,540 --> 00:03:24,920
the time we shouldn't worry about small

00:03:21,829 --> 00:03:27,109
inefficiencies the three percent of the

00:03:24,920 --> 00:03:29,150
time that we should worry about the mid

00:03:27,109 --> 00:03:31,549
really matters so bear that in mind I

00:03:29,150 --> 00:03:34,790
mean one of the things I'm trying to get

00:03:31,549 --> 00:03:39,260
across to people is that my slides are

00:03:34,790 --> 00:03:41,859
out of order no might that computers are

00:03:39,260 --> 00:03:43,880
cheap programmers are expensive right

00:03:41,859 --> 00:03:46,579
you know every now then you hear about

00:03:43,880 --> 00:03:48,230
skills shortages shortage of programmers

00:03:46,579 --> 00:03:52,400
have you ever heard about a shorter of

00:03:48,230 --> 00:03:55,880
computers recently no okay so let's move

00:03:52,400 --> 00:03:57,410
on what do I mean by pythonic we've has

00:03:55,880 --> 00:04:01,430
anybody ever done this read this the

00:03:57,410 --> 00:04:02,870
Senate poison click show hands excellent

00:04:01,430 --> 00:04:04,579
most of you have those of you haven't

00:04:02,870 --> 00:04:08,329
just type in put this at the pies and

00:04:04,579 --> 00:04:12,019
prompt you get the whole lot of this and

00:04:08,329 --> 00:04:13,910
they're like the top three kind of

00:04:12,019 --> 00:04:16,370
making make the most sense to me right

00:04:13,910 --> 00:04:18,950
beautiful is better than ugly who could

00:04:16,370 --> 00:04:21,500
argue with that explicit is better than

00:04:18,950 --> 00:04:22,900
implicit I think that's also very

00:04:21,500 --> 00:04:25,000
important

00:04:22,900 --> 00:04:29,050
and simple is always better than complex

00:04:25,000 --> 00:04:31,330
I have to always tell myself I'm a bear

00:04:29,050 --> 00:04:37,600
little brain and complex code bothers me

00:04:31,330 --> 00:04:39,130
I was it that said the you know

00:04:37,600 --> 00:04:42,160
debugging you code is ten times more

00:04:39,130 --> 00:04:43,780
difficult than writing it so if the code

00:04:42,160 --> 00:04:45,370
you write as as complex as you can write

00:04:43,780 --> 00:04:47,979
it you have no chance of understand of

00:04:45,370 --> 00:04:56,770
being able to debug it so that's always

00:04:47,979 --> 00:05:00,539
something I have to bear in mind okay so

00:04:56,770 --> 00:05:03,699
couple of themes I'll come through here

00:05:00,539 --> 00:05:06,280
pythonic right so by working definition

00:05:03,699 --> 00:05:09,039
of pythonic and I'm happy to have a

00:05:06,280 --> 00:05:12,780
philosophical discussion about this over

00:05:09,039 --> 00:05:18,479
coffee later is just clean and readable

00:05:12,780 --> 00:05:18,479
I will talk a little about profiling I

00:05:18,690 --> 00:05:23,410
don't believe the quote about that you

00:05:21,940 --> 00:05:24,520
can't manage what you can't measure I

00:05:23,410 --> 00:05:27,760
think from a people management

00:05:24,520 --> 00:05:29,169
perspective that's from a

00:05:27,760 --> 00:05:32,669
programming perspective it is absolutely

00:05:29,169 --> 00:05:35,470
correct right there's no point making

00:05:32,669 --> 00:05:36,789
any assumptions or building hypotheses

00:05:35,470 --> 00:05:42,130
about your code unless you can measure

00:05:36,789 --> 00:05:45,010
what your code is doing once you have

00:05:42,130 --> 00:05:50,169
measured it of course the key things to

00:05:45,010 --> 00:05:51,970
speed things up is to do less the

00:05:50,169 --> 00:05:54,940
fastest most reliable code does somebody

00:05:51,970 --> 00:05:57,250
much point out and I pointed out is code

00:05:54,940 --> 00:05:59,530
that you don't right know if code isn't

00:05:57,250 --> 00:06:02,909
there in executors instantaneously it

00:05:59,530 --> 00:06:06,370
has no bugs so whenever you can do less

00:06:02,909 --> 00:06:09,389
or jump ahead and cheat and get somebody

00:06:06,370 --> 00:06:13,599
else to do it for you that is a win in

00:06:09,389 --> 00:06:16,659
Baraga me the other two topics that come

00:06:13,599 --> 00:06:19,330
up a little bit later is vectorizing and

00:06:16,659 --> 00:06:23,199
paralyzing slightly interchangeable

00:06:19,330 --> 00:06:25,240
vectorizing from from my perspective of

00:06:23,199 --> 00:06:27,699
somebody who writes in a relatively slow

00:06:25,240 --> 00:06:30,729
language and like his code to work

00:06:27,699 --> 00:06:33,279
quickly basically means that when we

00:06:30,729 --> 00:06:34,560
pass stuff off to when we pass data off

00:06:33,279 --> 00:06:37,660
to

00:06:34,560 --> 00:06:39,340
faster language or faster subsystem we

00:06:37,660 --> 00:06:42,880
do it in one go and operate on the whole

00:06:39,340 --> 00:06:45,100
batch of data to basically pay the

00:06:42,880 --> 00:06:48,160
overhead of off the cut of the call only

00:06:45,100 --> 00:06:50,050
want and obviously parallelizing means

00:06:48,160 --> 00:06:53,770
using as many cores or computers as he

00:06:50,050 --> 00:06:58,000
can so let's go back to python

00:06:53,770 --> 00:06:59,830
performance now you know on the

00:06:58,000 --> 00:07:02,500
interwebs and all that you constantly

00:06:59,830 --> 00:07:07,140
hear about this python is slow compared

00:07:02,500 --> 00:07:10,360
to XY said what does it mean you know i

00:07:07,140 --> 00:07:12,280
don't think that's you know python being

00:07:10,360 --> 00:07:14,820
things slow isn't really an issue the

00:07:12,280 --> 00:07:17,800
question is this point in too slow I

00:07:14,820 --> 00:07:20,790
don't think it is for any anything that

00:07:17,800 --> 00:07:25,470
I do and I do a fair bit of you know

00:07:20,790 --> 00:07:29,830
perform sensitive stuff in that domain

00:07:25,470 --> 00:07:33,730
and you know we we have a couple hundred

00:07:29,830 --> 00:07:36,520
thousand lines of library code and most

00:07:33,730 --> 00:07:40,330
of that is not performed sensitive at

00:07:36,520 --> 00:07:42,970
all there are a few hot spots where we

00:07:40,330 --> 00:07:44,740
do worry about performance but once you

00:07:42,970 --> 00:07:49,330
were a little bit about them and deal

00:07:44,740 --> 00:07:51,910
with improperly it actually turns out

00:07:49,330 --> 00:07:55,960
our pies on this pass to know so let's

00:07:51,910 --> 00:07:57,690
look at some code hopefully that's big

00:07:55,960 --> 00:08:00,610
enough for the people in the back to see

00:07:57,690 --> 00:08:03,250
so this is this is kind of you know

00:08:00,610 --> 00:08:05,350
python 101 code this is the kind of code

00:08:03,250 --> 00:08:07,860
I would have would have written in 1999

00:08:05,350 --> 00:08:10,720
when it started python programming and

00:08:07,860 --> 00:08:14,740
yeah it's it's simple it's clear it's

00:08:10,720 --> 00:08:19,150
readable it works you know all three of

00:08:14,740 --> 00:08:20,980
those are pretty pretty good attributes

00:08:19,150 --> 00:08:23,740
for a little piece of code to have it

00:08:20,980 --> 00:08:27,400
has a starting point is it fast well

00:08:23,740 --> 00:08:31,450
that's right little gathered to measure

00:08:27,400 --> 00:08:35,500
it this is probably not a similar to

00:08:31,450 --> 00:08:40,150
ipython primate how many I parking users

00:08:35,500 --> 00:08:42,130
in the room cool why don't you but it

00:08:40,150 --> 00:08:43,930
like those of you who don't use ipython

00:08:42,130 --> 00:08:45,850
why not this

00:08:43,930 --> 00:08:48,089
I mean I don't use the notebooks myself

00:08:45,850 --> 00:08:50,529
but as a command line you can't beat it

00:08:48,089 --> 00:08:54,880
so let's look at this code right so if i

00:08:50,529 --> 00:08:58,029
run this and a little bit of test code

00:08:54,880 --> 00:09:00,670
there i'm gonna run 10 out of 10 million

00:08:58,029 --> 00:09:04,029
random numbers and it comes back in just

00:09:00,670 --> 00:09:08,529
over half a second that seems pretty

00:09:04,029 --> 00:09:10,330
damn quick to me um you know I hate to

00:09:08,529 --> 00:09:11,800
play the old man card here but you know

00:09:10,330 --> 00:09:13,660
the computers i started programming on

00:09:11,800 --> 00:09:15,670
couldn't even handle 10 million random

00:09:13,660 --> 00:09:18,910
numbers much less add them up in half a

00:09:15,670 --> 00:09:20,020
second so that's not too bad so why are

00:09:18,910 --> 00:09:23,589
people still worried about python

00:09:20,020 --> 00:09:25,779
performs well they're worried about

00:09:23,589 --> 00:09:32,980
python performs compared to C++ or C

00:09:25,779 --> 00:09:39,580
right so let's look at the same program

00:09:32,980 --> 00:09:44,500
in C boo hiss nobody nobody hates see

00:09:39,580 --> 00:09:48,630
okay good I'll take my c++ chokes out

00:09:44,500 --> 00:09:51,940
later on okay so this is very similar

00:09:48,630 --> 00:09:56,800
but if we time it would point out that

00:09:51,940 --> 00:10:00,870
it is about 40 times faster than our

00:09:56,800 --> 00:10:03,459
Python program which is a bit irritating

00:10:00,870 --> 00:10:05,620
you know just for bragging rights over

00:10:03,459 --> 00:10:07,870
the coffee if you talk to a C++ program

00:10:05,620 --> 00:10:11,050
or if you really have something very

00:10:07,870 --> 00:10:15,970
time critical so let's look at this code

00:10:11,050 --> 00:10:21,209
again this code is actually pretty much

00:10:15,970 --> 00:10:23,770
exactly the same as the C code now I

00:10:21,209 --> 00:10:29,350
think we can make it faster but make me

00:10:23,770 --> 00:10:31,180
a better so if we just go to slightly

00:10:29,350 --> 00:10:33,339
more modern more pythonic style and

00:10:31,180 --> 00:10:37,360
instead of you know accent using random

00:10:33,339 --> 00:10:40,990
access iterated stop again instead of

00:10:37,360 --> 00:10:45,399
using random access and using c style

00:10:40,990 --> 00:10:47,290
for loop if we just use a proper pointin

00:10:45,399 --> 00:10:49,209
for loop and iterate over a collection

00:10:47,290 --> 00:10:54,040
is actually i think a little bit faster

00:10:49,209 --> 00:10:58,080
let's have a look oh yeah the other sort

00:10:54,040 --> 00:11:04,840
to me this is kind of the canonical /

00:10:58,080 --> 00:11:06,790
Python function to do a sum there you

00:11:04,840 --> 00:11:09,040
know the current fashion is forgoing or

00:11:06,790 --> 00:11:12,730
functional programming so I did write a

00:11:09,040 --> 00:11:15,070
functional version of it not desperately

00:11:12,730 --> 00:11:18,250
keen on that myself but you know as a

00:11:15,070 --> 00:11:21,970
follower of fashion now to put it in so

00:11:18,250 --> 00:11:23,530
it does just changing it change your

00:11:21,970 --> 00:11:29,710
code to make it more pythonic actually

00:11:23,530 --> 00:11:32,080
make it faster time yes it does so if

00:11:29,710 --> 00:11:34,960
you look at the the second line down you

00:11:32,080 --> 00:11:36,760
know we've got a hundred percent well

00:11:34,960 --> 00:11:39,070
fifty percent of it whichever way around

00:11:36,760 --> 00:11:40,690
you're measuring in performance

00:11:39,070 --> 00:11:42,670
improvement by making a code a little

00:11:40,690 --> 00:11:48,460
bit simpler a little bit cleaner a

00:11:42,670 --> 00:11:50,860
little bit tidier which is great but

00:11:48,460 --> 00:12:01,300
it's still about 20 times slower than

00:11:50,860 --> 00:12:03,580
C++ okay so hmm so let's think about

00:12:01,300 --> 00:12:05,350
what else we have in our arsenal and

00:12:03,580 --> 00:12:08,980
obviously you're no Python so you know

00:12:05,350 --> 00:12:11,740
that we have a sum function built into

00:12:08,980 --> 00:12:13,950
Python and we should just use that

00:12:11,740 --> 00:12:18,160
instead of reinventing the wheel badly

00:12:13,950 --> 00:12:21,070
and that takes us to pretty much the

00:12:18,160 --> 00:12:23,590
same ballpark as C++ it's still a little

00:12:21,070 --> 00:12:30,190
bit slower but you know at least we're

00:12:23,590 --> 00:12:31,480
in the same town now right so I think

00:12:30,190 --> 00:12:33,990
you know this kind of shows that

00:12:31,480 --> 00:12:36,250
actually if you ride point and properly

00:12:33,990 --> 00:12:38,740
and know the language and use the

00:12:36,250 --> 00:12:41,890
facilities in the language you're going

00:12:38,740 --> 00:12:44,020
to get something that's you know I know

00:12:41,890 --> 00:12:46,030
three or four times slower than C++ but

00:12:44,020 --> 00:12:47,770
that isn't you know an order of

00:12:46,030 --> 00:12:49,210
magnitude or two orders of magnitude so

00:12:47,770 --> 00:12:50,110
it's you know for most things it's

00:12:49,210 --> 00:12:53,950
probably not something you have to worry

00:12:50,110 --> 00:12:56,740
about but we have a few more tricks up

00:12:53,950 --> 00:13:02,500
our sleeve so this is what I do it work

00:12:56,740 --> 00:13:04,210
I basically use numpy and this is this

00:13:02,500 --> 00:13:07,150
is what I kind of mean by cheating right

00:13:04,210 --> 00:13:07,830
so I don't want to write C++ cover all

00:13:07,150 --> 00:13:10,620
day

00:13:07,830 --> 00:13:14,070
why not because you know writing

00:13:10,620 --> 00:13:16,660
optimized numerically fished in C++ code

00:13:14,070 --> 00:13:18,340
it's hard work I'd much rather get

00:13:16,660 --> 00:13:21,000
somebody else to do it for me and the

00:13:18,340 --> 00:13:24,100
nice people that number i have done that

00:13:21,000 --> 00:13:27,370
so this is really good now let's look at

00:13:24,100 --> 00:13:29,380
the performance of that we're cheating

00:13:27,370 --> 00:13:33,160
slightly because we're we're converting

00:13:29,380 --> 00:13:34,450
from a python less to an umpire a

00:13:33,160 --> 00:13:39,190
because it's more efficient data

00:13:34,450 --> 00:13:41,950
structure but glossing over that we're

00:13:39,190 --> 00:13:43,360
actually faster than C++ that surprised

00:13:41,950 --> 00:13:47,710
me a little bit last night when I put

00:13:43,360 --> 00:13:50,230
the slide together but you know it's so

00:13:47,710 --> 00:13:51,270
this is kind of what I you know what we

00:13:50,230 --> 00:13:55,210
do all day is not very surprising

00:13:51,270 --> 00:13:57,010
because we're you know we're comparing

00:13:55,210 --> 00:13:59,160
see code written by somebody who hasn't

00:13:57,010 --> 00:14:01,450
really written C for living for 20 years

00:13:59,160 --> 00:14:03,339
to some of the best C++ programmers in

00:14:01,450 --> 00:14:06,610
the world and they're faster than I am

00:14:03,339 --> 00:14:09,160
that's great so there's other things we

00:14:06,610 --> 00:14:11,620
can do though because sometimes numpy

00:14:09,160 --> 00:14:14,200
it's a little bit awkward to use if

00:14:11,620 --> 00:14:19,960
you're not using you know if you're not

00:14:14,200 --> 00:14:22,030
doing basically matrix arithmetic so we

00:14:19,960 --> 00:14:25,630
can cheat again in a different way oh

00:14:22,030 --> 00:14:30,160
we've vectorized gum pythonic it's cheap

00:14:25,630 --> 00:14:36,820
and this is the slide from before we see

00:14:30,160 --> 00:14:38,170
parton if we use pie pie we get with it

00:14:36,820 --> 00:14:41,260
with any of the version of the code

00:14:38,170 --> 00:14:42,910
we're just as fast as a C++ code so you

00:14:41,260 --> 00:14:45,150
know if you have a performance problem

00:14:42,910 --> 00:14:49,780
look at some of the new jets out there

00:14:45,150 --> 00:14:52,450
pie pie is great you know we didn't even

00:14:49,780 --> 00:14:54,339
have to worry about rewriting anything I

00:14:52,450 --> 00:14:58,270
mean I still think you should write the

00:14:54,339 --> 00:14:59,680
more pythonic burden of the code but the

00:14:58,270 --> 00:15:02,950
performance gain you can get from

00:14:59,680 --> 00:15:06,510
cheating with pie pie is fantastic so

00:15:02,950 --> 00:15:08,950
let's look at that now there's something

00:15:06,510 --> 00:15:12,400
different about this slide from the

00:15:08,950 --> 00:15:15,820
previous slide and that's the fact that

00:15:12,400 --> 00:15:19,140
we're missing the numpy version now PI

00:15:15,820 --> 00:15:19,140
point numpy haven't

00:15:19,840 --> 00:15:26,290
have had problems integrating in the

00:15:21,910 --> 00:15:28,480
past they're slowly getting better that

00:15:26,290 --> 00:15:31,570
I mean I can't actually now install

00:15:28,480 --> 00:15:33,460
numpy and pi PI together and it works I

00:15:31,570 --> 00:15:35,830
just didn't have a chance to try it on

00:15:33,460 --> 00:15:43,180
my laptop before coming to do these

00:15:35,830 --> 00:15:45,400
slides yeah the kind of other thing you

00:15:43,180 --> 00:15:47,860
might want to look at if you want to

00:15:45,400 --> 00:15:52,780
look at jt's is none by number which has

00:15:47,860 --> 00:15:55,750
gives you a number of deployment

00:15:52,780 --> 00:15:57,570
opportunities to to use GPUs if you have

00:15:55,750 --> 00:16:00,880
the kind of problem that fits the GPU

00:15:57,570 --> 00:16:03,850
now in my experience that's one of those

00:16:00,880 --> 00:16:07,740
situations where if your problems fits

00:16:03,850 --> 00:16:10,180
the hardware architecture it's fantastic

00:16:07,740 --> 00:16:11,440
but it has to be a pretty close fit of

00:16:10,180 --> 00:16:13,860
your problem to the hardware

00:16:11,440 --> 00:16:21,750
architecture so your mileage may vary

00:16:13,860 --> 00:16:26,950
let's move on that was a cheat and

00:16:21,750 --> 00:16:28,600
remember this now is interesting this

00:16:26,950 --> 00:16:30,490
quote has probably been stole more than

00:16:28,600 --> 00:16:33,520
any other quote I've run across from

00:16:30,490 --> 00:16:39,100
quote shaker so I've seen it's activated

00:16:33,520 --> 00:16:42,370
to Picasso Tennyson and jobs I don't

00:16:39,100 --> 00:16:45,960
really care if it's good enough for any

00:16:42,370 --> 00:16:48,490
of them it's good enough for me so I

00:16:45,960 --> 00:16:50,230
think to keep one of the real key things

00:16:48,490 --> 00:16:51,910
to getting your point encoded files is

00:16:50,230 --> 00:16:54,910
to actually you know see what other

00:16:51,910 --> 00:16:58,420
workers out there already check what you

00:16:54,910 --> 00:17:03,100
can take from other people and use it

00:16:58,420 --> 00:17:07,600
and improve it moving on profiling and

00:17:03,100 --> 00:17:11,740
doing this so let's start with some

00:17:07,600 --> 00:17:17,860
really not a naughty code so these are

00:17:11,740 --> 00:17:19,870
anagrams yeah then they used to be

00:17:17,860 --> 00:17:21,670
something that people did before the

00:17:19,870 --> 00:17:27,490
internet was invented to keep themselves

00:17:21,670 --> 00:17:31,330
a mutant I'd but they're really tedious

00:17:27,490 --> 00:17:32,520
to work out by hand quite fun sometimes

00:17:31,330 --> 00:17:36,520
with political

00:17:32,520 --> 00:17:37,720
developments but anyway so let's let's

00:17:36,520 --> 00:17:43,290
see if we can get a computer program to

00:17:37,720 --> 00:17:46,510
work them out so what do we do here we

00:17:43,290 --> 00:17:48,430
first of all read the list of addiction

00:17:46,510 --> 00:17:50,200
or dictionary so we have a list of all

00:17:48,430 --> 00:17:53,100
the words we're going to look at and

00:17:50,200 --> 00:17:57,820
then we have a very simple kind of this

00:17:53,100 --> 00:18:01,690
program to find all anagrams now let's

00:17:57,820 --> 00:18:05,260
look at this know that a couple of

00:18:01,690 --> 00:18:10,360
things about this code it works and it

00:18:05,260 --> 00:18:11,680
was really really easy to ride now you

00:18:10,360 --> 00:18:13,390
might not believe me that this works but

00:18:11,680 --> 00:18:18,220
i do have unit tests to prove me see me

00:18:13,390 --> 00:18:23,100
afterwards if you don't want it so if we

00:18:18,220 --> 00:18:26,440
just look at how fast this runs then

00:18:23,100 --> 00:18:27,790
again we're looking a little timing

00:18:26,440 --> 00:18:29,230
harness you know if you're just

00:18:27,790 --> 00:18:31,570
interested in finding a few anagrams

00:18:29,230 --> 00:18:36,100
this code runs in sub-second blah blah

00:18:31,570 --> 00:18:37,720
blah doesn't matter if you want to you

00:18:36,100 --> 00:18:40,810
know do this a lot then you start having

00:18:37,720 --> 00:18:43,540
to profile i think that's useful to

00:18:40,810 --> 00:18:47,950
remember you know it's only worth

00:18:43,540 --> 00:18:51,100
spending time on speeding up code that's

00:18:47,950 --> 00:18:53,530
actually used a hell of a lot right if

00:18:51,100 --> 00:18:56,500
you run the program once a week and it

00:18:53,530 --> 00:18:57,820
takes five hours who cares if you run it

00:18:56,500 --> 00:19:00,190
all the time and has to run in three

00:18:57,820 --> 00:19:03,790
hours then you have a problem so let's

00:19:00,190 --> 00:19:06,790
let's measure this so this is using

00:19:03,790 --> 00:19:10,210
Python 3 on an old laptop takes one

00:19:06,790 --> 00:19:14,800
minute 14 seconds you know it's not not

00:19:10,210 --> 00:19:17,110
slow but interestingly enough when I ran

00:19:14,800 --> 00:19:19,780
this in python 2.7 rather than three

00:19:17,110 --> 00:19:23,680
point forward turn out to be faster hmm

00:19:19,780 --> 00:19:26,440
not so good because we all want to you

00:19:23,680 --> 00:19:31,570
know switch over to three another poll

00:19:26,440 --> 00:19:36,880
who's still using Python 2 as anybody's

00:19:31,570 --> 00:19:38,140
start using Python one no ok ok all

00:19:36,880 --> 00:19:41,020
right so about half of you are using

00:19:38,140 --> 00:19:43,960
Python 3 you can just point out this is

00:19:41,020 --> 00:19:46,060
this is not a general general rule

00:19:43,960 --> 00:19:49,240
Python 3 isn't generally slower than

00:19:46,060 --> 00:19:50,860
Python too so that's no go an upgrade

00:19:49,240 --> 00:19:53,020
get home you know get back to the offers

00:19:50,860 --> 00:19:58,240
switch over to Python 3 the world will

00:19:53,020 --> 00:20:01,720
be a better place so let's run this in

00:19:58,240 --> 00:20:04,480
pie pie and yeah okay we've gone from

00:20:01,720 --> 00:20:09,010
you know one minute something in Python

00:20:04,480 --> 00:20:11,950
3 or 40 seconds and Python 22 22 seconds

00:20:09,010 --> 00:20:13,600
which is pretty damn good you know for

00:20:11,950 --> 00:20:17,560
for not doing anything apart from

00:20:13,600 --> 00:20:19,420
changing the command line but let's

00:20:17,560 --> 00:20:21,670
let's assume that you know we have a

00:20:19,420 --> 00:20:23,020
really mean boss and he says 22 seconds

00:20:21,670 --> 00:20:26,800
are still too long to find all the

00:20:23,020 --> 00:20:30,730
anagrams in the English language so

00:20:26,800 --> 00:20:32,080
let's look at profiling now pythons

00:20:30,730 --> 00:20:35,320
great point and has a profile they

00:20:32,080 --> 00:20:36,760
included it just so I can gauge how

00:20:35,320 --> 00:20:40,930
quickly to go through the profiling

00:20:36,760 --> 00:20:43,180
slides who knows the profiler okay right

00:20:40,930 --> 00:20:45,760
the rest of you should learn it it is

00:20:43,180 --> 00:20:47,440
worth well knowing so the Python

00:20:45,760 --> 00:20:52,420
profiler is really really simple to use

00:20:47,440 --> 00:20:55,660
I don't know if you can see this really

00:20:52,420 --> 00:20:59,350
all we do is call poten- em to invoke

00:20:55,660 --> 00:21:01,930
the module see profile which invokes the

00:20:59,350 --> 00:21:04,420
profiler and that spits out a huge text

00:21:01,930 --> 00:21:06,550
file here your IDE probably had it

00:21:04,420 --> 00:21:09,520
included anyway so just have a quick

00:21:06,550 --> 00:21:11,800
look and run it and that's bits out of

00:21:09,520 --> 00:21:14,670
file that looks a bit like this now I

00:21:11,800 --> 00:21:16,750
don't have my laser pointer but

00:21:14,670 --> 00:21:18,820
basically what it shows us the number of

00:21:16,750 --> 00:21:22,930
calls the time spend time spend per

00:21:18,820 --> 00:21:26,350
called the time spent in the function

00:21:22,930 --> 00:21:28,810
and in a function it calls an end of our

00:21:26,350 --> 00:21:31,570
name in the line number and you know

00:21:28,810 --> 00:21:34,270
unsurprisingly if you look at the

00:21:31,570 --> 00:21:35,620
cumulative time column we spend pretty

00:21:34,270 --> 00:21:38,230
much all of our time and they'll find

00:21:35,620 --> 00:21:40,450
all anagrams functions now in this case

00:21:38,230 --> 00:21:42,040
that's not terribly useful if you're

00:21:40,450 --> 00:21:44,470
profiling a big program obviously

00:21:42,040 --> 00:21:48,790
finding out what functions take all your

00:21:44,470 --> 00:21:49,990
time is that is the first step I mean

00:21:48,790 --> 00:21:51,610
there's no point optimizing all the

00:21:49,990 --> 00:21:57,280
functions you have you need to kind of

00:21:51,610 --> 00:21:59,640
apply a time sensibly so let's see if we

00:21:57,280 --> 00:22:01,780
can do better than this

00:21:59,640 --> 00:22:04,930
you know if you just look at this

00:22:01,780 --> 00:22:08,890
function we can treat L what's going on

00:22:04,930 --> 00:22:11,860
here let's see what other tools we have

00:22:08,890 --> 00:22:13,600
now there's another profile of which

00:22:11,860 --> 00:22:15,040
Sally doesn't come installed with point

00:22:13,600 --> 00:22:18,190
and by default but as easy to install

00:22:15,040 --> 00:22:22,990
pip install I'm profiler takes no time

00:22:18,190 --> 00:22:24,790
at all all you have to do is do an app

00:22:22,990 --> 00:22:26,320
profile decorator on the function that

00:22:24,790 --> 00:22:31,510
you've previously identified as a

00:22:26,320 --> 00:22:33,580
hotspot and then we run current prof so

00:22:31,510 --> 00:22:35,530
it's a slightly from command line not

00:22:33,580 --> 00:22:40,090
too difficult and this gives us some

00:22:35,530 --> 00:22:41,800
really interesting output so first of

00:22:40,090 --> 00:22:44,140
all it tells us how often each line of

00:22:41,800 --> 00:22:48,550
the function is executed and that's in

00:22:44,140 --> 00:22:51,400
this case isn't terribly surprising what

00:22:48,550 --> 00:22:53,650
is I mean sometimes I find the actually

00:22:51,400 --> 00:22:56,710
the hit count more interesting than the

00:22:53,650 --> 00:22:59,950
timings because the headcount can't

00:22:56,710 --> 00:23:02,770
tells you where the hot water but in

00:22:59,950 --> 00:23:04,660
this case you know all our time 99.4

00:23:02,770 --> 00:23:07,930
percent of our time is spent in this if

00:23:04,660 --> 00:23:13,780
candidate and dictionary lookup which is

00:23:07,930 --> 00:23:15,250
slightly surprising while it was

00:23:13,780 --> 00:23:16,600
surprising until I thought about it and

00:23:15,250 --> 00:23:19,360
you guys probably have figured this out

00:23:16,600 --> 00:23:21,580
already the problem is we're doing a

00:23:19,360 --> 00:23:24,520
linear search and a dictionary inside a

00:23:21,580 --> 00:23:27,190
linear inside a for loop so n times n

00:23:24,520 --> 00:23:28,720
gives us no N squared algorithm not a

00:23:27,190 --> 00:23:34,180
great idea if you have large numbers of

00:23:28,720 --> 00:23:35,530
items so we can make a one-line change

00:23:34,180 --> 00:23:38,890
to this function which speeded up

00:23:35,530 --> 00:23:40,360
dramatically and this is again slightly

00:23:38,890 --> 00:23:43,810
cheating so we just change it to a set

00:23:40,360 --> 00:23:45,490
of words it's slightly cheating because

00:23:43,810 --> 00:23:46,960
when sites of online change actually

00:23:45,490 --> 00:23:48,610
were fundamentally changing the data

00:23:46,960 --> 00:23:50,860
structures that the program operates on

00:23:48,610 --> 00:23:53,170
but point makes it nice and convenient

00:23:50,860 --> 00:23:59,520
to do that in this case so we're looking

00:23:53,170 --> 00:24:04,040
pretty good and that now runs in one

00:23:59,520 --> 00:24:07,980
point four seconds which

00:24:04,040 --> 00:24:09,270
yeah I think fast enough compared to the

00:24:07,980 --> 00:24:13,400
one minute 14 seconds that we were

00:24:09,270 --> 00:24:16,170
looking at earlier there's a slight

00:24:13,400 --> 00:24:20,190
surprise ahead after this when I run it

00:24:16,170 --> 00:24:24,840
in pipeline and the pipe I version was

00:24:20,190 --> 00:24:26,520
actually slower now I mean you know that

00:24:24,840 --> 00:24:28,110
isn't isn't terribly surprising if you

00:24:26,520 --> 00:24:31,260
if you think about a little bit because

00:24:28,110 --> 00:24:33,350
it takes takes warm up time and has to

00:24:31,260 --> 00:24:36,750
do some more work than interpreter and

00:24:33,350 --> 00:24:39,360
if your program is running now has such

00:24:36,750 --> 00:24:43,320
a short execution time then it doesn't

00:24:39,360 --> 00:24:45,630
have time to amortize on afterwards but

00:24:43,320 --> 00:24:50,370
yeah anyway so there we go we have with

00:24:45,630 --> 00:24:59,720
a very simple change come to the end

00:24:50,370 --> 00:24:59,720
okay sorry did a missing punch okay okay

00:25:00,029 --> 00:25:11,399
well thank you very much for bearing

00:25:01,710 --> 00:25:14,340
with me no time for questions okay well

00:25:11,399 --> 00:25:18,590
I'll be around for the day so if you

00:25:14,340 --> 00:25:18,590

YouTube URL: https://www.youtube.com/watch?v=2raXkX0Wi2w


