Title: Rafael Monnerat - Hyperconvergence meets BigData
Publication date: 2016-07-28
Playlist: EuroPython 2016
Description: 
	Rafael Monnerat - Hyperconvergence meets BigData
[EuroPython 2016]
[18 July 2016]
[Bilbao, Euskadi, Spain]
(https://ep2016.europython.eu//conference/talks/hyperconvergence-meets-bigdata)

This presentation show how to deploy  **[Wendelin][1]**, the free
software platform for Big Data & Machine Learning, using
**[SlapOS][2]** , the free software hyperconverged Operating System
(hOS).  Written in 100% in Python,  SlapOS and Wendelin, can create a
complete Big Data Infraestruture with out-of-core capabilities ready
to use and operate in just few hours.

[1]: http://www.wedelin.io
[2]: http://community.slapos.org

-----

This presentation aims to demonstrate how to use [SlapOS][1]
(Hyperconverged OS) to deploy an entire Big Data Infrastrucure and
show how "data life cycle" can be managed with [Wendelin][2] -
covering ingestion, analysis, visualization and weaving it into an
application.

We'll show how Wendelin and SlapOS could handle acquisition, analysis
and exploitation of data, making it a potential solution for IOT
scenarios where data is available and needs some logic applied before
being presented as web application, possibly on a commercial basis.

The agenda of the presentation includes an introduction on SlapOS, as
a tool used to deploy a wide range of different services and an
introduction of Wendelin, as a tool in order to make out-of-core
python applications.

After a short introduction, we progress to show the steps to deploy
SlapOS infrastructure and later to deploy Wendelin on the just
deployed SlapOS, including an use case which shows SlapOS deploying a
fluentd instance to ingest data to the Wendelin Database.

To conclude, we make a live demo with an Jupiter using out-of-core
python to handle wav files stored on Wendelin, and a second short demo
on handle computer resources consumption data.

[1]: http://community.slapos.org
[2]: http://www.wendelin.io/
Captions: 
	00:00:00,000 --> 00:00:07,080
oh hello good afternoon my name my name

00:00:04,259 --> 00:00:12,360
is Rafa Rafa manera I'm going to talk

00:00:07,080 --> 00:00:17,609
about I confirmed runs hyper converging

00:00:12,360 --> 00:00:27,810
sea meets big data i work from for NEX

00:00:17,609 --> 00:00:32,450
ID from Paris I will board today a hyper

00:00:27,810 --> 00:00:36,770
conversion see that we do with slap OS

00:00:32,450 --> 00:00:42,629
and how we deploy Big Data projects

00:00:36,770 --> 00:00:45,660
using a Venn during how we deploy it how

00:00:42,629 --> 00:00:48,930
we normally upload data and I will start

00:00:45,660 --> 00:00:51,960
to make a quick demos in the end of the

00:00:48,930 --> 00:00:56,510
presentation so the goal of this

00:00:51,960 --> 00:00:59,070
presentation is it to be a bit mada not

00:00:56,510 --> 00:01:01,199
necessarily you are going to do use that

00:00:59,070 --> 00:01:04,650
OS and not necessarily you are going to

00:01:01,199 --> 00:01:07,560
provide big data with reading so but

00:01:04,650 --> 00:01:14,130
then merge of the two that we have been

00:01:07,560 --> 00:01:19,590
using its it somehow I the key that we

00:01:14,130 --> 00:01:22,170
could imagine for future in globe eight

00:01:19,590 --> 00:01:26,549
and hyper converging see with big data

00:01:22,170 --> 00:01:29,250
in order to collect and automate the

00:01:26,549 --> 00:01:36,600
deployments for big data in an Internet

00:01:29,250 --> 00:01:41,299
of Things so this presentation so these

00:01:36,600 --> 00:01:45,950
two tools and this presentation reflects

00:01:41,299 --> 00:01:49,380
how next idea works with their customers

00:01:45,950 --> 00:01:52,590
so next idea is one of the largest open

00:01:49,380 --> 00:01:55,470
source publishers in the Europe despite

00:01:52,590 --> 00:02:02,070
the fact it is a small company with

00:01:55,470 --> 00:02:07,770
just start 30 or 40 employees we could

00:02:02,070 --> 00:02:14,100
produce a big amount of open source

00:02:07,770 --> 00:02:17,490
software and I've aboard the two of them

00:02:14,100 --> 00:02:20,820
today this is just what they they stack

00:02:17,490 --> 00:02:31,520
that I'm going to bathe myself on today

00:02:20,820 --> 00:02:31,520
and these tools was were mostly created

00:02:31,820 --> 00:02:36,810
22 in Globe eight and need for a

00:02:34,260 --> 00:02:38,670
customer that couldn't find an

00:02:36,810 --> 00:02:43,170
alternative solution for the problem

00:02:38,670 --> 00:02:48,420
that it has and during the presentation

00:02:43,170 --> 00:02:52,650
I will give some examples of how house

00:02:48,420 --> 00:02:56,290
let OS was designer Dan

00:02:52,650 --> 00:03:01,359
implemented and during the evolution of

00:02:56,290 --> 00:03:04,480
the two was targeting to cover topics

00:03:01,359 --> 00:03:11,639
which don't exactly are covered by a

00:03:04,480 --> 00:03:15,629
other tools so this is just a list of I

00:03:11,639 --> 00:03:19,659
start which is fully open source and

00:03:15,629 --> 00:03:23,170
mostly based on Python except the few

00:03:19,659 --> 00:03:25,389
entity one which is actually written in

00:03:23,170 --> 00:03:29,260
Ruby it's not a software that was

00:03:25,389 --> 00:03:33,370
written by night CD but in the market we

00:03:29,260 --> 00:03:38,019
couldn't find an as a reliable solution

00:03:33,370 --> 00:03:42,760
bite on these days so vendor lean core

00:03:38,019 --> 00:03:45,299
is to provide out of out of core by PI

00:03:42,760 --> 00:03:48,639
data which means that we can process

00:03:45,299 --> 00:03:52,269
data which is larger than the realm of

00:03:48,639 --> 00:03:55,780
the computer neo is a distributed

00:03:52,269 --> 00:04:01,090
database for those who knows zou plates

00:03:55,780 --> 00:04:08,709
and distributed Zod be here p 5 was it's

00:04:01,090 --> 00:04:13,299
an open source erp not not so exciting

00:04:08,709 --> 00:04:16,780
only this presentation slap-ass is a is

00:04:13,299 --> 00:04:20,739
the two that were present in follow the

00:04:16,780 --> 00:04:24,699
resist is something that we developed to

00:04:20,739 --> 00:04:28,060
provide mesh interconnected mesh

00:04:24,699 --> 00:04:32,370
networks worldwide for entities to

00:04:28,060 --> 00:04:38,529
collect data and scikit-learn is for do

00:04:32,370 --> 00:04:42,279
machine learning and another's

00:04:38,529 --> 00:04:45,519
so this was the start of this days lat

00:04:42,279 --> 00:04:50,229
OS it was it started in two thousand

00:04:45,519 --> 00:04:53,679
nine or ten I don't remember exactly the

00:04:50,229 --> 00:04:56,949
day today and when it was built for the

00:04:53,679 --> 00:05:00,279
first time we have we were proposing on

00:04:56,949 --> 00:05:03,849
that time and to put servers in the

00:05:00,279 --> 00:05:06,279
people's home so we design a system that

00:05:03,849 --> 00:05:09,209
could be distributed in a way that he

00:05:06,279 --> 00:05:14,379
could works in more than one data center

00:05:09,209 --> 00:05:16,899
so it could walks in Amazon or hack

00:05:14,379 --> 00:05:23,519
space of the age or any other provider

00:05:16,899 --> 00:05:26,499
and also to cover the to be able to host

00:05:23,519 --> 00:05:31,209
services in people's home or office in

00:05:26,499 --> 00:05:34,479
and distributed way it stands to work

00:05:31,209 --> 00:05:39,239
very well and then it with the Internet

00:05:34,479 --> 00:05:46,239
of Things and other projects that it's

00:05:39,239 --> 00:05:51,549
coming up the model was the to this

00:05:46,239 --> 00:05:55,149
level s was became a tool that could be

00:05:51,549 --> 00:06:00,339
installed on machines that we in cars or

00:05:55,149 --> 00:06:03,309
trucks to provide a mobile cloud we have

00:06:00,339 --> 00:06:08,019
a project on going on this it can be

00:06:03,309 --> 00:06:13,989
used to to host services in that people

00:06:08,019 --> 00:06:17,529
the boxes like in France there is a free

00:06:13,989 --> 00:06:21,729
box and so you could produce equivalent

00:06:17,529 --> 00:06:24,120
of it with slap LS it was it is being

00:06:21,729 --> 00:06:29,080
used by in the

00:06:24,120 --> 00:06:35,440
turbines to wind turbines for collect

00:06:29,080 --> 00:06:39,060
data to in order to inform when it there

00:06:35,440 --> 00:06:45,460
is a need for preventive maintenance and

00:06:39,060 --> 00:06:48,040
also it's it's it's also used to create

00:06:45,460 --> 00:06:50,950
Internet of Things routers you get an

00:06:48,040 --> 00:06:53,320
has berry pie and install it then you

00:06:50,950 --> 00:06:55,420
can collect data over the several

00:06:53,320 --> 00:07:00,850
devices that are eventually connected in

00:06:55,420 --> 00:07:06,180
the network in order to collect data or

00:07:00,850 --> 00:07:10,360
manage certain services at your home or

00:07:06,180 --> 00:07:12,940
elsewhere so now we become beyond the

00:07:10,360 --> 00:07:19,510
data centers we can manage at the same

00:07:12,940 --> 00:07:22,030
time mobile cloud and normal CDN using

00:07:19,510 --> 00:07:25,750
data centers using exactly the same

00:07:22,030 --> 00:07:30,660
system without modification can't

00:07:25,750 --> 00:07:30,660
modifications in any of the parts and

00:07:31,020 --> 00:07:44,260
it's important to to show that the these

00:07:40,090 --> 00:07:48,220
lapels can provide nodes everywhere and

00:07:44,260 --> 00:07:50,560
and it uses a central server for now

00:07:48,220 --> 00:07:54,460
it's only one but in future it can be

00:07:50,560 --> 00:07:57,580
more than one master to control any

00:07:54,460 --> 00:08:04,750
amount of computers and devices which

00:07:57,580 --> 00:08:10,500
are with sleep OS install it so just to

00:08:04,750 --> 00:08:15,040
illustrate a bit so what is the slackers

00:08:10,500 --> 00:08:20,160
so this Laplace is composed by whatever

00:08:15,040 --> 00:08:25,630
Linux it install it whatever linux

00:08:20,160 --> 00:08:29,080
available today as base so there is a

00:08:25,630 --> 00:08:31,330
three four components that with the

00:08:29,080 --> 00:08:34,690
slap-a- score that interact that

00:08:31,330 --> 00:08:36,300
coordinates everything we are based then

00:08:34,690 --> 00:08:40,620
build out so

00:08:36,300 --> 00:08:45,890
can reconstruct a software from from

00:08:40,620 --> 00:08:50,250
scratch or use some cash automation to

00:08:45,890 --> 00:08:52,350
share already compilot softwares between

00:08:50,250 --> 00:08:56,220
two machines which we are based on the

00:08:52,350 --> 00:09:02,370
same architecture and we use supervisor

00:08:56,220 --> 00:09:06,380
d4 manage the process on top of it so

00:09:02,370 --> 00:09:10,380
this is what is present on all machines

00:09:06,380 --> 00:09:14,490
so on top of it you have the software

00:09:10,380 --> 00:09:16,350
releases the software releases are some

00:09:14,490 --> 00:09:21,329
kind of equivalent of a group of

00:09:16,350 --> 00:09:23,940
packages that are placed in a special

00:09:21,329 --> 00:09:26,940
way in the system in order to provide

00:09:23,940 --> 00:09:30,870
binaries to run whatever service that

00:09:26,940 --> 00:09:33,390
binaries are supposed for and you can

00:09:30,870 --> 00:09:36,060
have several configurations in one

00:09:33,390 --> 00:09:39,089
machine pole so the same machine can

00:09:36,060 --> 00:09:44,220
have more than one version of my Maria

00:09:39,089 --> 00:09:47,610
DB or Apache or word process running at

00:09:44,220 --> 00:09:51,810
the same time without conflicting each

00:09:47,610 --> 00:09:57,480
other so the soft releases itself don't

00:09:51,810 --> 00:10:00,829
provide any running process just just

00:09:57,480 --> 00:10:00,829
software there and

00:10:01,960 --> 00:10:10,460
then we have a and the software

00:10:05,240 --> 00:10:13,280
instances are the ones that runs the

00:10:10,460 --> 00:10:15,110
services so you can imagine that when

00:10:13,280 --> 00:10:18,080
you install the package it only provides

00:10:15,110 --> 00:10:21,020
the binaries and then on the instance

00:10:18,080 --> 00:10:25,120
sides it will tell how the binaries will

00:10:21,020 --> 00:10:28,010
run how the service will be composed and

00:10:25,120 --> 00:10:32,180
in the software instances it's a bit

00:10:28,010 --> 00:10:34,250
similar as a kind of micro containers so

00:10:32,180 --> 00:10:38,300
it there are containers but they are

00:10:34,250 --> 00:10:42,110
more light in a way that you don't

00:10:38,300 --> 00:10:46,880
provide over head of recopying the same

00:10:42,110 --> 00:10:51,470
group of files everywhere that's why

00:10:46,880 --> 00:10:53,510
there is this major separation so this

00:10:51,470 --> 00:10:57,620
is represents for example one machine

00:10:53,510 --> 00:11:01,360
running anywhere it can be a it can be a

00:10:57,620 --> 00:11:06,610
machine in a data center or my laptop

00:11:01,360 --> 00:11:11,690
which I move around anywhere and can be

00:11:06,610 --> 00:11:17,960
can be hosted in a car before if there

00:11:11,690 --> 00:11:22,160
is a need for it and 11 important things

00:11:17,960 --> 00:11:27,530
to remark is that it can run at the same

00:11:22,160 --> 00:11:31,910
time VMs or virtual machines so a bit

00:11:27,530 --> 00:11:35,750
like what OpenStack does and also other

00:11:31,910 --> 00:11:38,210
services that which are not a big

00:11:35,750 --> 00:11:41,870
virtual machine which are not utilize it

00:11:38,210 --> 00:11:44,000
is just processes so a machine can

00:11:41,870 --> 00:11:47,690
compose many different kinds of services

00:11:44,000 --> 00:11:49,580
in a distributed way so a cluster can

00:11:47,690 --> 00:11:53,090
use modern on machine one machine

00:11:49,580 --> 00:11:57,520
several machines it depends how the

00:11:53,090 --> 00:11:57,520
compo could have the composition

00:11:58,550 --> 00:12:06,710
configure it i will i will later on this

00:12:03,630 --> 00:12:11,100
presentation i will show the case of the

00:12:06,710 --> 00:12:15,180
big data with van Dellen so based on

00:12:11,100 --> 00:12:19,350
that this configuration we can provide

00:12:15,180 --> 00:12:25,500
at the same time using sharing service

00:12:19,350 --> 00:12:29,640
sharing computers severus we can supply

00:12:25,500 --> 00:12:32,610
several projects and run them all at the

00:12:29,640 --> 00:12:35,520
same time sharing the machines and they

00:12:32,610 --> 00:12:38,460
are by this list you can see that they

00:12:35,520 --> 00:12:43,710
are significantly different in terms of

00:12:38,460 --> 00:12:47,339
goals so we are running for example

00:12:43,710 --> 00:12:51,540
today a CDN worldwide which is a present

00:12:47,339 --> 00:12:54,630
in China so we have services in China so

00:12:51,540 --> 00:12:58,410
we have kvm clusters for big data in

00:12:54,630 --> 00:13:02,330
Terra lab which is a which is a french

00:12:58,410 --> 00:13:07,470
project that provides big data for large

00:13:02,330 --> 00:13:10,709
french companies at the Institute min

00:13:07,470 --> 00:13:15,209
telecom so we have been dling for big

00:13:10,709 --> 00:13:17,850
data which i will mention in the

00:13:15,209 --> 00:13:24,350
sequence its ding ding production today

00:13:17,850 --> 00:13:30,120
to provide preventive maintenance for

00:13:24,350 --> 00:13:33,180
wind turbines in Germany and we have

00:13:30,120 --> 00:13:35,779
development we have distribution the

00:13:33,180 --> 00:13:41,190
test nodes some kind of equivalent of

00:13:35,779 --> 00:13:45,620
Jenkins distributed in several machines

00:13:41,190 --> 00:13:49,410
worldwide so we have the automation of

00:13:45,620 --> 00:13:52,650
we have a system that can produce VM

00:13:49,410 --> 00:13:55,920
images so we automate I don't know if

00:13:52,650 --> 00:14:00,390
people know or not we automate the work

00:13:55,920 --> 00:14:02,680
that Packer does for generating MS so we

00:14:00,390 --> 00:14:06,160
can generate previewed VMs

00:14:02,680 --> 00:14:09,820
and we also use to provide the chromium

00:14:06,160 --> 00:14:15,430
OS images for Chromebooks so we have our

00:14:09,820 --> 00:14:18,250
own distribution of chromium OS which is

00:14:15,430 --> 00:14:21,339
called my us and we use webos also to

00:14:18,250 --> 00:14:26,740
build the images for ourselves or for

00:14:21,339 --> 00:14:31,240
the persons that what and from make this

00:14:26,740 --> 00:14:36,300
walks it requires to leverage the way to

00:14:31,240 --> 00:14:39,070
install it everywhere so if you we have

00:14:36,300 --> 00:14:41,709
20 different ways to install the same

00:14:39,070 --> 00:14:45,310
thing based on different architectures

00:14:41,709 --> 00:14:56,500
it will be it will require much more

00:14:45,310 --> 00:15:01,600
effort to deploys anything so I I will

00:14:56,500 --> 00:15:06,130
come back to this one so how we do the

00:15:01,600 --> 00:15:09,970
deployment of it we we have at one line

00:15:06,130 --> 00:15:12,700
in one line installation script that you

00:15:09,970 --> 00:15:15,130
ask you you if you want to connect to

00:15:12,700 --> 00:15:18,029
the master so if you want to connect to

00:15:15,130 --> 00:15:21,700
whatever master you can tell which one

00:15:18,029 --> 00:15:24,070
you connect your device to the machine

00:15:21,700 --> 00:15:27,580
for example this laptop is connected to

00:15:24,070 --> 00:15:32,290
the master so i can use master to deploy

00:15:27,580 --> 00:15:35,440
services on my laptop or if you have a

00:15:32,290 --> 00:15:37,980
mobile cloud it's the same way i can

00:15:35,440 --> 00:15:41,470
control machines based on master

00:15:37,980 --> 00:15:44,680
deploying them the point whatever

00:15:41,470 --> 00:15:47,800
service to whatever machine i it's

00:15:44,680 --> 00:15:50,980
connected to their so we use ansible

00:15:47,800 --> 00:15:57,010
which is also a python to to automate

00:15:50,980 --> 00:16:00,279
the setup of the node it it allow us to

00:15:57,010 --> 00:16:05,230
with the same line we can setup has

00:16:00,279 --> 00:16:09,970
berry pie a laptop like in a Chromebook

00:16:05,230 --> 00:16:11,360
or production data center so in this way

00:16:09,970 --> 00:16:16,490
I

00:16:11,360 --> 00:16:18,930
the ansible take care of the minima the

00:16:16,490 --> 00:16:22,200
particularities of the system that is

00:16:18,930 --> 00:16:25,230
being installed so we can support a very

00:16:22,200 --> 00:16:28,380
large amount of linux distributions for

00:16:25,230 --> 00:16:31,100
example just by using this comment if

00:16:28,380 --> 00:16:34,230
you are preferred distribution is not

00:16:31,100 --> 00:16:41,190
supported for whatever reason we will be

00:16:34,230 --> 00:16:43,530
happy to add we just add on demand so

00:16:41,190 --> 00:16:45,930
you don't have to actually connect

00:16:43,530 --> 00:16:51,810
always to a master you can deploy a

00:16:45,930 --> 00:16:54,120
stand alone I stand alone node by

00:16:51,810 --> 00:16:57,540
Justice keeping the questions and

00:16:54,120 --> 00:17:00,210
running these two comments here so if

00:16:57,540 --> 00:17:04,860
you type slept as node configure local

00:17:00,210 --> 00:17:07,800
you get your computer or figure it to

00:17:04,860 --> 00:17:11,910
use the any software that is available

00:17:07,800 --> 00:17:14,569
in that lab OS and this one is for

00:17:11,910 --> 00:17:23,339
preparing the machines positions and

00:17:14,569 --> 00:17:29,550
folders and so on you don't you you have

00:17:23,339 --> 00:17:31,860
an API for you have the when you install

00:17:29,550 --> 00:17:34,080
this lap OS you also have a command line

00:17:31,860 --> 00:17:38,490
tool that allows you to supply and

00:17:34,080 --> 00:17:42,450
request and and I use a console to

00:17:38,490 --> 00:17:48,360
automate the deployments of the of the

00:17:42,450 --> 00:17:51,750
software that you want to deploy so here

00:17:48,360 --> 00:17:54,800
is an example of a required and supplies

00:17:51,750 --> 00:18:01,710
when deploying a software release of

00:17:54,800 --> 00:18:04,590
manito to to a computer and and then I'm

00:18:01,710 --> 00:18:08,430
requesting to run one instance of this

00:18:04,590 --> 00:18:10,800
monitoring on on this computer so it's

00:18:08,430 --> 00:18:16,070
the equivalent of set up in a monitor

00:18:10,800 --> 00:18:16,070
for y wind turbine for example

00:18:16,480 --> 00:18:23,530
here is the vet here is just variations

00:18:19,000 --> 00:18:27,429
of the services of the request that you

00:18:23,530 --> 00:18:29,650
can be done so when you deploy this

00:18:27,429 --> 00:18:32,559
monitor you already deployed for entity

00:18:29,650 --> 00:18:39,070
which is what collects the logs from the

00:18:32,559 --> 00:18:44,110
machines which leads me to the ventolin

00:18:39,070 --> 00:18:47,770
part so as Laplace is everywhere and

00:18:44,110 --> 00:18:53,500
it's standardized in a way that we can

00:18:47,770 --> 00:18:57,640
put it anywhere so we were able to

00:18:53,500 --> 00:19:03,690
quickly deploy the Evangeline stack

00:18:57,640 --> 00:19:06,750
which is a a tool for provide big data

00:19:03,690 --> 00:19:09,880
analysis and out of or Python and the

00:19:06,750 --> 00:19:16,990
advantage of uses level s on this case

00:19:09,880 --> 00:19:21,640
it doesn't require hours of setup to to

00:19:16,990 --> 00:19:24,190
have this type so even a data scientist

00:19:21,640 --> 00:19:30,580
which has no background on set up in a

00:19:24,190 --> 00:19:35,169
cluster chance at a bit and also allow

00:19:30,580 --> 00:19:39,040
allows the persons that we are not data

00:19:35,169 --> 00:19:41,410
scientists have the full stack of for

00:19:39,040 --> 00:19:47,020
example scikit-learn an umpire out of

00:19:41,410 --> 00:19:51,460
core distributed database and I pie I

00:19:47,020 --> 00:19:55,690
shook the notebook ready to use for make

00:19:51,460 --> 00:20:02,160
some kind of calculation so both sides

00:19:55,690 --> 00:20:07,030
can can benefit from the quick set up by

00:20:02,160 --> 00:20:10,419
noting expending time on learning how to

00:20:07,030 --> 00:20:15,730
pip install moon pie on re

00:20:10,419 --> 00:20:23,080
in rem in the your hostel by or examples

00:20:15,730 --> 00:20:26,830
like this so the defending also was

00:20:23,080 --> 00:20:30,879
designed to work on the commodity

00:20:26,830 --> 00:20:35,230
hardware so it don't requires a super

00:20:30,879 --> 00:20:40,359
powerful machine to be deployed so you

00:20:35,230 --> 00:20:42,369
can keeping the dimension of what you

00:20:40,359 --> 00:20:44,019
are going to do you can make big data

00:20:42,369 --> 00:20:46,809
with machines that you can bind

00:20:44,019 --> 00:20:49,450
supermarket for example you can buy a

00:20:46,809 --> 00:20:51,690
few machines i7 in a supermarket that

00:20:49,450 --> 00:20:55,269
then you can start to make big data

00:20:51,690 --> 00:20:59,019
because it's quite easy to find a 1i 7

00:20:55,269 --> 00:21:03,159
with a 16 or 32 gigabyte of run anywhere

00:20:59,019 --> 00:21:06,509
and SSDs are becoming cheaper and

00:21:03,159 --> 00:21:13,239
cheaper so you can buy a one terabyte

00:21:06,509 --> 00:21:15,609
SSD disk dizam quite easily and as did

00:21:13,239 --> 00:21:19,929
as everything was designed to be

00:21:15,609 --> 00:21:23,470
distributed with this lepo ass you can

00:21:19,929 --> 00:21:26,169
buy several cheap machines and then you

00:21:23,470 --> 00:21:30,609
have big data you don't have to expand

00:21:26,169 --> 00:21:34,090
out 100,000 euros buying expensive

00:21:30,609 --> 00:21:38,789
hardware to start to make what a big

00:21:34,090 --> 00:21:45,519
data so they stack is composed by

00:21:38,789 --> 00:21:47,320
average hardware of course people that

00:21:45,519 --> 00:21:49,989
has conditions can come back and buy

00:21:47,320 --> 00:21:56,169
more reliable hard one but it don't

00:21:49,989 --> 00:21:59,619
requires a special service for it so we

00:21:56,169 --> 00:22:03,940
use this letter OS the year p 5 is just

00:21:59,619 --> 00:22:06,639
as a base tool to provide with no to

00:22:03,940 --> 00:22:09,730
provide an object database that we are

00:22:06,639 --> 00:22:12,489
going to manipulate soon and the psychic

00:22:09,730 --> 00:22:14,909
learn is to provide the machine learning

00:22:12,489 --> 00:22:14,909
and other

00:22:15,290 --> 00:22:26,690
and other features that you can use in

00:22:19,370 --> 00:22:29,690
big data and the year p5 is also used to

00:22:26,690 --> 00:22:38,590
provide them what one already owed but

00:22:29,690 --> 00:22:47,290
equivalent to comparable to the job lead

00:22:38,590 --> 00:22:47,290
so we already had distributed and active

00:22:47,630 --> 00:22:56,000
in English please active active so we

00:22:54,110 --> 00:22:57,680
can provide the background and a

00:22:56,000 --> 00:22:59,750
synchronous the program we can do a

00:22:57,680 --> 00:23:04,790
background in a synchronous programming

00:22:59,750 --> 00:23:06,380
already by 10 or 12 years so sighs I

00:23:04,790 --> 00:23:12,470
started there already doing a

00:23:06,380 --> 00:23:14,660
synchronous programming so but they

00:23:12,470 --> 00:23:17,960
stack is nothing if the data dome are

00:23:14,660 --> 00:23:22,510
right there so you can only do big data

00:23:17,960 --> 00:23:27,620
if the data arrives to the to the tool

00:23:22,510 --> 00:23:29,750
so we use print d mostly because it's

00:23:27,620 --> 00:23:35,750
one of the most reliable tools that

00:23:29,750 --> 00:23:39,350
exist today we make a test in the office

00:23:35,750 --> 00:23:44,330
when we were selecting and we put on a

00:23:39,350 --> 00:23:48,610
laptop in a normal hour normal office

00:23:44,330 --> 00:23:54,110
and we'll let it on during the weekend

00:23:48,610 --> 00:23:57,470
pushing data to the vanillin which is

00:23:54,110 --> 00:24:02,390
the case but we are not analyzing 20 and

00:23:57,470 --> 00:24:07,130
it could last just one registry over a

00:24:02,390 --> 00:24:10,490
million in the space of two weeks which

00:24:07,130 --> 00:24:13,520
is very very real reliable because a

00:24:10,490 --> 00:24:16,640
laptop is turned off and on all the time

00:24:13,520 --> 00:24:19,130
because I suspended in a blitz suspended

00:24:16,640 --> 00:24:20,930
in a learn and the person go home with

00:24:19,130 --> 00:24:24,500
the laptop and connects from the other

00:24:20,930 --> 00:24:28,250
network and then I and then it turned

00:24:24,500 --> 00:24:31,460
off suspend an enabler goes to 3G then

00:24:28,250 --> 00:24:37,670
goes to Wi-Fi again so all of these is

00:24:31,460 --> 00:24:39,200
just lost one registry and for the

00:24:37,670 --> 00:24:44,600
places which you can't we cannot afford

00:24:39,200 --> 00:24:47,420
run 20d process we can just run an HTTP

00:24:44,600 --> 00:24:53,330
and the weekend an HTTP server and we

00:24:47,420 --> 00:24:56,090
can crawl with a flu entity and what we

00:24:53,330 --> 00:24:59,100
extend client ID on this case is to the

00:24:56,090 --> 00:25:03,720
stream binary data

00:24:59,100 --> 00:25:08,070
because I will show soon but we can

00:25:03,720 --> 00:25:12,000
stream a wave wave sounds in a wave dot

00:25:08,070 --> 00:25:19,559
wide format to the vendor Ling and a

00:25:12,000 --> 00:25:23,940
plot and I have to you out of it so how

00:25:19,559 --> 00:25:30,270
we deploy so here we learn how to

00:25:23,940 --> 00:25:35,250
request into whatever computer monitor

00:25:30,270 --> 00:25:37,650
which will come with a 20 and Here We in

00:25:35,250 --> 00:25:42,840
with just the two lines we can request

00:25:37,650 --> 00:25:50,210
the vendor Ling so the full stack with

00:25:42,840 --> 00:25:50,210
all with all tools and scikit-learn

00:25:51,590 --> 00:25:55,610
scikit-learn a lump I

00:25:56,320 --> 00:26:03,559
vendor link or out of data there is

00:26:00,080 --> 00:26:06,950
several other scientific tools installed

00:26:03,559 --> 00:26:11,650
on it is available just by typing these

00:26:06,950 --> 00:26:11,650
two commons in whatever no do you want

00:26:14,289 --> 00:26:21,230
or if you are in the standalone fashion

00:26:19,130 --> 00:26:26,299
you don't want to connect you want to

00:26:21,230 --> 00:26:29,779
just to have an instance on your vm in

00:26:26,299 --> 00:26:37,580
amazon you just type this dis common and

00:26:29,779 --> 00:26:40,549
you get everything so soon we are going

00:26:37,580 --> 00:26:42,289
to release it was not ready for this

00:26:40,549 --> 00:26:45,860
conference but soon we are going to

00:26:42,289 --> 00:26:50,840
release ready to use images for kia moo

00:26:45,860 --> 00:26:54,230
shu and digital cng unaware of the 12

00:26:50,840 --> 00:26:58,159
box and so on which we can which can

00:26:54,230 --> 00:27:04,340
provide ready to use ready to try i

00:26:58,159 --> 00:27:07,250
would say instances of van Dellen so you

00:27:04,340 --> 00:27:19,760
don't have to pay yourself or install

00:27:07,250 --> 00:27:25,059
the data anymore so here it render the

00:27:19,760 --> 00:27:25,059
tags i will show from

00:27:26,450 --> 00:27:32,420
so here is the configuration here is

00:27:29,180 --> 00:27:35,270
what I run earlier today to upload the

00:27:32,420 --> 00:27:40,880
data so you generate a file which is

00:27:35,270 --> 00:27:46,340
basically like this which says a look at

00:27:40,880 --> 00:27:48,560
this folder for wav files save the

00:27:46,340 --> 00:27:55,670
position to know what you already send

00:27:48,560 --> 00:27:58,220
or not then you can tag your your data

00:27:55,670 --> 00:28:03,740
you can have different tags for

00:27:58,220 --> 00:28:06,530
different data and send to send it to

00:28:03,740 --> 00:28:09,860
different ingestion policies to you

00:28:06,530 --> 00:28:15,290
classify or shard or you can do whatever

00:28:09,860 --> 00:28:18,650
you want with your data and here i just

00:28:15,290 --> 00:28:20,990
use the vendor Ling plugin which is

00:28:18,650 --> 00:28:23,990
already come with the monitor that I

00:28:20,990 --> 00:28:26,750
just said but if you judge just for just

00:28:23,990 --> 00:28:30,350
installing the fur entity from treasure

00:28:26,750 --> 00:28:33,530
data you you can easily install is just

00:28:30,350 --> 00:28:35,630
a file in a folder then you say where

00:28:33,530 --> 00:28:37,820
you were you where you are sending to

00:28:35,630 --> 00:28:40,880
and which is the user and which is the

00:28:37,820 --> 00:28:48,950
password and here you can see that it

00:28:40,880 --> 00:28:51,620
founds six waves yes six waves and its

00:28:48,950 --> 00:28:54,920
stream everything to this to design

00:28:51,620 --> 00:29:00,230
gesture so in few minutes you can start

00:28:54,920 --> 00:29:03,500
in just files in your big data so

00:29:00,230 --> 00:29:07,640
probably it also works with the other

00:29:03,500 --> 00:29:10,480
equivalent of plenty like a log log

00:29:07,640 --> 00:29:13,450
stash and

00:29:10,480 --> 00:29:17,230
I forgot the name of the other one which

00:29:13,450 --> 00:29:19,210
was also written in Ruby so you can

00:29:17,230 --> 00:29:21,880
write the plugins which are compatible

00:29:19,210 --> 00:29:26,290
just by making posts and making sure

00:29:21,880 --> 00:29:30,940
that you you already have them you are

00:29:26,290 --> 00:29:34,299
consistent when you send the data so I

00:29:30,940 --> 00:29:37,150
come back now so this is what I just

00:29:34,299 --> 00:29:41,160
show and you can limit the buffer and so

00:29:37,150 --> 00:29:43,510
on if you bothering memory or if you had

00:29:41,160 --> 00:29:47,320
too much streaming of data you can

00:29:43,510 --> 00:29:50,559
buffer in disk and you can just run man

00:29:47,320 --> 00:29:52,270
value like this just a flu entity let's

00:29:50,559 --> 00:29:57,309
see and then you pass the configuration

00:29:52,270 --> 00:29:59,590
file or you can or depending of your

00:29:57,309 --> 00:30:02,340
setup or if you are using slap-ass or

00:29:59,590 --> 00:30:09,070
not you can write a very complex

00:30:02,340 --> 00:30:12,190
configuration file so it takes just a

00:30:09,070 --> 00:30:14,679
few minutes yeah it was just what I show

00:30:12,190 --> 00:30:17,440
when you run it you just say that you

00:30:14,679 --> 00:30:19,950
send data then if you are using

00:30:17,440 --> 00:30:24,669
different plugins for example to get

00:30:19,950 --> 00:30:28,120
syslog or machine consumptions that we

00:30:24,669 --> 00:30:31,390
use to it's a just use a different you

00:30:28,120 --> 00:30:37,510
have just to adjust the path of the

00:30:31,390 --> 00:30:44,559
source I can show another example later

00:30:37,510 --> 00:30:50,100
if I have time so how where the data

00:30:44,559 --> 00:30:50,100
goes so I will just jump quickly

00:30:55,180 --> 00:31:01,960
so the data goes to these so this is the

00:30:59,170 --> 00:31:08,490
ue of year p 5 which will be able we'll

00:31:01,960 --> 00:31:08,490
just start the data and

00:31:11,030 --> 00:31:21,020
by using a fast input you can create the

00:31:15,260 --> 00:31:23,810
entirely part to be ready to use that

00:31:21,020 --> 00:31:26,570
configuration file that you use saw so

00:31:23,810 --> 00:31:29,750
it will create a portal ingestion that

00:31:26,570 --> 00:31:34,090
you can use Python to for example if the

00:31:29,750 --> 00:31:37,010
tag is depending of the tag you cannot

00:31:34,090 --> 00:31:40,790
write in a different data streams and

00:31:37,010 --> 00:31:44,870
not in doing anything complex here what

00:31:40,790 --> 00:31:47,080
arrives I just put in the same stream of

00:31:44,870 --> 00:31:47,080
data

00:31:51,620 --> 00:32:01,150
I can just go to data streams yes so I

00:31:57,590 --> 00:32:01,150
can just search for wave

00:32:02,429 --> 00:32:09,990
so here they have my way that I send

00:32:06,210 --> 00:32:13,409
earlier with the amount of data I can

00:32:09,990 --> 00:32:16,009
manually upload a file which will

00:32:13,409 --> 00:32:20,490
overwrite the file that is already there

00:32:16,009 --> 00:32:23,369
override the data that is there and I

00:32:20,490 --> 00:32:26,490
can append files manually so you don't

00:32:23,369 --> 00:32:28,499
have to only rely on the front ed to

00:32:26,490 --> 00:32:32,220
send data you can upload certain data

00:32:28,499 --> 00:32:34,889
that you have to manipulate or or you

00:32:32,220 --> 00:32:37,450
can make posts for example to upload a

00:32:34,889 --> 00:32:43,899
certain data certain

00:32:37,450 --> 00:32:47,620
data start that you have then how to use

00:32:43,899 --> 00:32:55,289
this data so i have this data represents

00:32:47,620 --> 00:32:59,039
several wave sounds that was trimming 22

00:32:55,289 --> 00:32:59,039
to this computer

00:33:00,120 --> 00:33:07,710
I just showed at araiza Apter when I'm

00:33:03,480 --> 00:33:12,320
starting to do demos so here a demo so I

00:33:07,710 --> 00:33:21,420
install its let OS everywhere I have my

00:33:12,320 --> 00:33:23,910
my van dling setup and so if you are if

00:33:21,420 --> 00:33:30,480
you are in normal speed you can set up

00:33:23,910 --> 00:33:35,010
everything in one day or less and I go

00:33:30,480 --> 00:33:37,680
to my demo so i hope i still have IP the

00:33:35,010 --> 00:33:41,790
sinks i also i will not make demo but

00:33:37,680 --> 00:33:46,680
just show them anything and believe it

00:33:41,790 --> 00:33:53,730
or not I have a I have ipv6 here even if

00:33:46,680 --> 00:33:57,330
you don't tell so so instead of use the

00:33:53,730 --> 00:34:00,800
normal ipython we just makin small

00:33:57,330 --> 00:34:04,140
extension to the normal ipython notebook

00:34:00,800 --> 00:34:06,210
not today entirely too but we just

00:34:04,140 --> 00:34:09,360
create a different kernel that we can

00:34:06,210 --> 00:34:14,370
use with some magic which can make our

00:34:09,360 --> 00:34:19,920
life easier and to be more reliable when

00:34:14,370 --> 00:34:24,600
we deal with data so I was shown that

00:34:19,920 --> 00:34:28,050
you know minimally ipython if you get

00:34:24,600 --> 00:34:33,450
lost raise your hand because that will

00:34:28,050 --> 00:34:38,190
be time to do it so some some magic we

00:34:33,450 --> 00:34:40,020
just this this one to four we just say

00:34:38,190 --> 00:34:45,450
where we are going to collect our

00:34:40,020 --> 00:34:48,900
notebook so it's just a it's just

00:34:45,450 --> 00:34:52,590
reference then when you when you finish

00:34:48,900 --> 00:34:55,590
you get an object called context you can

00:34:52,590 --> 00:34:59,960
see it as a kind of proxy is not exactly

00:34:55,590 --> 00:35:03,170
a proxy but whatever you put contact dot

00:34:59,960 --> 00:35:03,170
get ID

00:35:05,770 --> 00:35:18,430
you are doing a remote call let's see ok

00:35:12,410 --> 00:35:18,430
I don't have a crazy scene now I have

00:35:20,650 --> 00:35:28,980
see yes I have again so I can just call

00:35:25,869 --> 00:35:28,980
whatever I want

00:35:34,140 --> 00:35:42,570
i'm doing a remote call to the object I

00:35:38,000 --> 00:35:45,810
don't have a relative world so based on

00:35:42,570 --> 00:35:48,660
these I can get the data that I strument

00:35:45,810 --> 00:35:51,780
so the data that you saw it's on under

00:35:48,660 --> 00:35:54,090
this path but of course nobody remembers

00:35:51,780 --> 00:35:57,810
the ID of every object that you want to

00:35:54,090 --> 00:36:01,320
manipulate so you can search the object

00:35:57,810 --> 00:36:03,810
by using the catalog so you can make

00:36:01,320 --> 00:36:08,220
queries to the database to know where it

00:36:03,810 --> 00:36:12,900
is the paths and so on so you can you

00:36:08,220 --> 00:36:18,450
just use portal catalog then it starts

00:36:12,900 --> 00:36:21,300
this is an interesting fact so even if

00:36:18,450 --> 00:36:25,230
it's out of off you are not in calling

00:36:21,300 --> 00:36:28,950
the the methods on the ipython notebook

00:36:25,230 --> 00:36:31,830
but you are doing a a remote call to

00:36:28,950 --> 00:36:35,250
manipulate the objects you can still do

00:36:31,830 --> 00:36:38,100
bad things so for example this against

00:36:35,250 --> 00:36:41,430
the entire data which is in the stream

00:36:38,100 --> 00:36:46,430
so if there is one terabyte data it will

00:36:41,430 --> 00:36:52,440
get everything and string to your

00:36:46,430 --> 00:36:54,450
browser not good at all so the only

00:36:52,440 --> 00:36:59,910
thing that you have to make to take care

00:36:54,450 --> 00:37:01,770
is to use a different approaches not not

00:36:59,910 --> 00:37:04,350
so much different but you have to take

00:37:01,770 --> 00:37:07,320
care to not load the data all at once

00:37:04,350 --> 00:37:10,530
when you want to manipulate here is just

00:37:07,320 --> 00:37:14,880
two examples that we are on call that we

00:37:10,530 --> 00:37:16,950
are making the ipython notebook handler

00:37:14,880 --> 00:37:22,470
all the data and here we are just

00:37:16,950 --> 00:37:24,270
managing small chunks of data here is

00:37:22,470 --> 00:37:27,630
just human parts be chopped because i

00:37:24,270 --> 00:37:32,700
have bought a scifi to enter the ways

00:37:27,630 --> 00:37:37,770
that i want then I wanted to make an fft

00:37:32,700 --> 00:37:42,630
without load load entire data and for

00:37:37,770 --> 00:37:46,660
this if you read the code of this read

00:37:42,630 --> 00:37:49,870
function e to expect that it's a file

00:37:46,660 --> 00:37:52,870
as that expect that is a file it could

00:37:49,870 --> 00:37:55,780
use the file IO the stringer yo of

00:37:52,870 --> 00:37:58,330
Python however if I use the string I oh

00:37:55,780 --> 00:38:02,530
I have to load the entire data to give

00:37:58,330 --> 00:38:07,690
to the string I oh that's why I make

00:38:02,530 --> 00:38:14,050
this class as a rapper to makin out of

00:38:07,690 --> 00:38:20,320
core an out of course stream looks like

00:38:14,050 --> 00:38:23,830
a file so when I pal I pass the file

00:38:20,320 --> 00:38:26,800
reader it to behave like a file but

00:38:23,830 --> 00:38:28,750
without loaded the entire data because

00:38:26,800 --> 00:38:34,750
you can imagine that the data can be one

00:38:28,750 --> 00:38:38,640
terabyte in this way by using this file

00:38:34,750 --> 00:38:44,950
I can manipulate a one terabyte fine as

00:38:38,640 --> 00:38:46,840
it is an average file without without

00:38:44,950 --> 00:38:52,480
requires me to have one terabyte of

00:38:46,840 --> 00:38:59,320
memory so here I just get one channel

00:38:52,480 --> 00:39:01,900
and and here I just saving why I'm

00:38:59,320 --> 00:39:07,090
running out of time so here I'm just

00:39:01,900 --> 00:39:09,760
saving the arrays and plotting it so I'm

00:39:07,090 --> 00:39:14,560
just plotting the arrays and and making

00:39:09,760 --> 00:39:18,850
FFT here so i get there i get the array

00:39:14,560 --> 00:39:21,460
i save the array i we get the array in

00:39:18,850 --> 00:39:26,620
order to make it out of core and then I

00:39:21,460 --> 00:39:34,030
save it and I plot I can save images to

00:39:26,620 --> 00:39:37,120
to the database yeah so here is where

00:39:34,030 --> 00:39:43,080
was the previous times that I invoke at

00:39:37,120 --> 00:39:43,080
the FFT so I can see the files oops

00:39:43,220 --> 00:39:45,369
or

00:39:47,910 --> 00:39:55,289
I can rig it much later one array that I

00:39:51,839 --> 00:39:59,510
already process it and report it so i

00:39:55,289 --> 00:40:06,030
can save and recover the arrays that

00:39:59,510 --> 00:40:10,500
then i'm using so when i move to the

00:40:06,030 --> 00:40:13,579
second demo which is now i'm going to

00:40:10,500 --> 00:40:22,380
emulate an a synchronous processing

00:40:13,579 --> 00:40:25,069
using oops i click ok so is the same

00:40:22,380 --> 00:40:25,069
thing as before

00:40:29,640 --> 00:40:35,579
so here I meet Justin calculation to see

00:40:32,549 --> 00:40:45,779
how much data have in the site thirty

00:40:35,579 --> 00:40:49,700
three gigabytes and here I just make the

00:40:45,779 --> 00:40:54,410
same couple as same calculation saving

00:40:49,700 --> 00:41:04,339
the calculation 10 by 10 so I make it I

00:40:54,410 --> 00:41:04,339
put in background processing I just

00:41:08,740 --> 00:41:16,160
so I'm just putting the in the

00:41:11,180 --> 00:41:18,380
background the processing and later I'm

00:41:16,160 --> 00:41:21,500
checking if the processing is already

00:41:18,380 --> 00:41:25,550
finished then I can make the same

00:41:21,500 --> 00:41:28,640
calculation again but in doing a kind of

00:41:25,550 --> 00:41:32,210
map reducing and I using a cluster of

00:41:28,640 --> 00:41:40,850
instances instead of program myself in

00:41:32,210 --> 00:41:42,440
the level of the ipython notebook so

00:41:40,850 --> 00:41:52,160
this is the kind of things that you can

00:41:42,440 --> 00:41:54,830
do in after one day of setup so I ready

00:41:52,160 --> 00:41:58,070
did at synchronous very quickly so you

00:41:54,830 --> 00:42:01,310
could do a direct clip so you can follow

00:41:58,070 --> 00:42:05,600
the tutorial in the link i will make it

00:42:01,310 --> 00:42:07,580
available at Twitter to the side so you

00:42:05,600 --> 00:42:11,600
can make sure the tutorial in the link

00:42:07,580 --> 00:42:15,350
for plot data directly in the browser

00:42:11,600 --> 00:42:19,700
using javascript there is a short

00:42:15,350 --> 00:42:22,070
tutorial and you can use pip install and

00:42:19,700 --> 00:42:24,800
use the core of handling without

00:42:22,070 --> 00:42:30,020
installed a full stack so we can use

00:42:24,800 --> 00:42:31,640
Vendela and out of core features just in

00:42:30,020 --> 00:42:34,280
your computer to make it small

00:42:31,640 --> 00:42:38,870
calculations which exceeds the run that

00:42:34,280 --> 00:42:42,590
you have in your computer well thank you

00:42:38,870 --> 00:42:44,920
very much ma'am I was extended a bit

00:42:42,590 --> 00:42:44,920
sorry

00:42:52,000 --> 00:42:58,010
so now it's I think it's a coffee break

00:42:54,890 --> 00:43:01,400
I lost I still a bit of your coffee bay

00:42:58,010 --> 00:43:04,820
so if anyone they have questions I can

00:43:01,400 --> 00:43:07,090
ask or feel free to to go to cough

00:43:04,820 --> 00:43:07,090
bridge

00:43:17,640 --> 00:43:19,700

YouTube URL: https://www.youtube.com/watch?v=Z-aiV0pkt_8


