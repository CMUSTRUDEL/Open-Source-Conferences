Title: Adrian Meyer - Detecting and Analyzing Solar Panels in Switzerland using Aerial Imagery
Publication date: 2020-09-21
Playlist: EuroPython 2020
Description: 
	"Detecting and Analyzing Solar Panels in Switzerland using Aerial Imagery
EuroPython 2020 - Talk - 2020-07-23 - Parrot Data Science
Online

By Adrian Meyer




License: This video is licensed under the CC BY-NC-SA 3.0 license: https://creativecommons.org/licenses/by-nc-sa/3.0/
Please see our speaker release agreement for details: https://ep2020.europython.eu/events/speaker-release-agreement/

    "
Captions: 
	00:00:06,480 --> 00:00:09,440
uh

00:00:06,799 --> 00:00:10,800
next up here uh we're gonna be uh

00:00:09,440 --> 00:00:13,840
hearing from

00:00:10,800 --> 00:00:16,960
uh adrian meyer

00:00:13,840 --> 00:00:20,240
so making sure we're all ready to go

00:00:16,960 --> 00:00:24,240
on that uh excellent

00:00:20,240 --> 00:00:25,039
uh so a little bit about adrian meyer

00:00:24,240 --> 00:00:29,679
here uh

00:00:25,039 --> 00:00:31,199
he is um data scientist for remote

00:00:29,679 --> 00:00:33,200
sensing and machine learning at the

00:00:31,199 --> 00:00:34,880
institute geomatics

00:00:33,200 --> 00:00:37,520
i can't even pronounce that part i'm not

00:00:34,880 --> 00:00:40,160
going to lie i don't speak

00:00:37,520 --> 00:00:42,160
language and currently working on

00:00:40,160 --> 00:00:45,200
several big projects mainly focusing on

00:00:42,160 --> 00:00:47,280
automated image analysis uh

00:00:45,200 --> 00:00:48,960
telemetry big data processing deep

00:00:47,280 --> 00:00:51,199
learning digital reconstruction

00:00:48,960 --> 00:00:52,239
holy moly this guy does a lot and he's

00:00:51,199 --> 00:00:53,840
interested at

00:00:52,239 --> 00:00:55,840
the interest of the animal biologist by

00:00:53,840 --> 00:00:58,239
training mature during

00:00:55,840 --> 00:00:59,920
analysis of geotag wildlife imagery in

00:00:58,239 --> 00:01:02,800
cape town south africa

00:00:59,920 --> 00:01:04,640
man you you've you've got some uh you've

00:01:02,800 --> 00:01:07,760
got some serious uh

00:01:04,640 --> 00:01:07,760
nerd chops there

00:01:10,159 --> 00:01:13,840
uh so uh thanks for joining us where are

00:01:12,159 --> 00:01:15,680
you joining us from

00:01:13,840 --> 00:01:18,240
uh thanks for the awesome introduction

00:01:15,680 --> 00:01:21,439
um i'm joining today from

00:01:18,240 --> 00:01:23,920
basel that's uh actually from the

00:01:21,439 --> 00:01:25,280
little suburb of basel called mutans

00:01:23,920 --> 00:01:28,400
which is where our

00:01:25,280 --> 00:01:30,960
more or less unpronounceable school is

00:01:28,400 --> 00:01:31,600
situated how do you pronounce that

00:01:30,960 --> 00:01:37,200
because i

00:01:31,600 --> 00:01:40,479
i i the faculty

00:01:37,200 --> 00:01:42,640
bless you

00:01:40,479 --> 00:01:44,000
no see you can do that that's uh among

00:01:42,640 --> 00:01:45,600
your various skills you can pronounce

00:01:44,000 --> 00:01:49,680
that that is awesome i

00:01:45,600 --> 00:01:52,960
i am i i must learn your ways uh

00:01:49,680 --> 00:01:55,119
so i will turn this over to you um and

00:01:52,960 --> 00:01:57,200
it looks like you're gonna be uh talking

00:01:55,119 --> 00:01:59,200
about something that is completely

00:01:57,200 --> 00:02:03,040
blocked on my screen here

00:01:59,200 --> 00:02:04,719
oh come on zoom get out of the way

00:02:03,040 --> 00:02:07,680
and analyzing solar panels in

00:02:04,719 --> 00:02:09,360
switzerland using aerial imagery so

00:02:07,680 --> 00:02:11,680
awesome so i'm going to turn this over

00:02:09,360 --> 00:02:16,400
to you and um

00:02:11,680 --> 00:02:20,319
go for it okay perfect i'm going to

00:02:16,400 --> 00:02:20,319
try to do this screen share thing here

00:02:20,840 --> 00:02:23,840
okay

00:02:26,160 --> 00:02:33,440
well um thank you everyone for

00:02:29,760 --> 00:02:36,480
being part here for uh being interested

00:02:33,440 --> 00:02:39,200
for um

00:02:36,480 --> 00:02:40,160
wanting to listen to to this talk it's

00:02:39,200 --> 00:02:43,920
it's going to be

00:02:40,160 --> 00:02:47,440
um about a specific application case

00:02:43,920 --> 00:02:51,360
of detecting and analyzing solar panels

00:02:47,440 --> 00:02:53,120
um this is a type of big data

00:02:51,360 --> 00:02:55,840
problem that we have been working on

00:02:53,120 --> 00:02:59,040
since about two years now

00:02:55,840 --> 00:03:00,720
at the institute geomatics of the

00:02:59,040 --> 00:03:02,159
university of applied sciences in

00:03:00,720 --> 00:03:04,720
northwestern switzerland which would be

00:03:02,159 --> 00:03:08,319
the appropriate translation for the

00:03:04,720 --> 00:03:09,280
for the german term um i'm not working

00:03:08,319 --> 00:03:12,080
alone on this

00:03:09,280 --> 00:03:13,040
we actually have a couple of student

00:03:12,080 --> 00:03:16,800
projects

00:03:13,040 --> 00:03:19,840
going on here and my two professors

00:03:16,800 --> 00:03:22,879
denis jordan and martin kirsten

00:03:19,840 --> 00:03:26,480
who many of you probably know they

00:03:22,879 --> 00:03:27,440
also join in this project and we perform

00:03:26,480 --> 00:03:31,360
it together with

00:03:27,440 --> 00:03:33,599
the government of switzerland most

00:03:31,360 --> 00:03:34,560
precisely the federal office of for

00:03:33,599 --> 00:03:36,080
energy

00:03:34,560 --> 00:03:38,319
they are interested in the amount of

00:03:36,080 --> 00:03:40,319
solar energy installed in switzerland

00:03:38,319 --> 00:03:42,640
and the energy department of the canton

00:03:40,319 --> 00:03:47,840
argo martin herter and peter varmet

00:03:42,640 --> 00:03:47,840
are our two project partners

00:03:47,920 --> 00:03:51,680
the federal office for energy in

00:03:49,920 --> 00:03:55,360
switzerland has released

00:03:51,680 --> 00:03:57,519
already a map of all the roofs

00:03:55,360 --> 00:03:58,720
of switzerland so they do know where the

00:03:57,519 --> 00:04:00,720
buildings are and they do

00:03:58,720 --> 00:04:02,080
know how steep the roofs are and

00:04:00,720 --> 00:04:04,959
everything like that

00:04:02,080 --> 00:04:06,319
um and they made this awesome map here

00:04:04,959 --> 00:04:09,360
to the right

00:04:06,319 --> 00:04:11,840
which is basically um

00:04:09,360 --> 00:04:13,760
a type of cadastral system where you can

00:04:11,840 --> 00:04:14,799
find out how much potential for solar

00:04:13,760 --> 00:04:16,799
energy usage

00:04:14,799 --> 00:04:17,840
your roof or the roof of your neighbor

00:04:16,799 --> 00:04:19,840
has and

00:04:17,840 --> 00:04:20,959
they incorporated relatively complex

00:04:19,840 --> 00:04:24,320
roof geometries

00:04:20,959 --> 00:04:28,080
i would say like a level lod

00:04:24,320 --> 00:04:30,000
ii and you can see you can click on a

00:04:28,080 --> 00:04:31,680
on a single shape here and it's going to

00:04:30,000 --> 00:04:34,800
give you uh

00:04:31,680 --> 00:04:35,840
the suitability estimate the roof area

00:04:34,800 --> 00:04:39,120
and also how much

00:04:35,840 --> 00:04:42,240
uh swiss francs you can earn um

00:04:39,120 --> 00:04:42,960
by installing panels there so this is

00:04:42,240 --> 00:04:47,040
the side of

00:04:42,960 --> 00:04:50,320
like installing new panels what they um

00:04:47,040 --> 00:04:53,600
what they do not know yet is

00:04:50,320 --> 00:04:56,000
uh how many panels there are so

00:04:53,600 --> 00:04:58,080
we have this data set is based on the

00:04:56,000 --> 00:04:59,360
swiss building's 3d data set from the

00:04:58,080 --> 00:05:02,160
official office

00:04:59,360 --> 00:05:04,400
swiss topu topographical office of

00:05:02,160 --> 00:05:07,120
switzerland

00:05:04,400 --> 00:05:08,560
there the roof shapes are incorporated

00:05:07,120 --> 00:05:11,759
and

00:05:08,560 --> 00:05:16,240
what we also have of the same office is

00:05:11,759 --> 00:05:19,039
the aerial imagery so we have um

00:05:16,240 --> 00:05:21,360
10 centimeter ground resolution which is

00:05:19,039 --> 00:05:22,800
the newest data set and 25 centimeter

00:05:21,360 --> 00:05:26,240
ground resolution

00:05:22,800 --> 00:05:28,560
um which results in about uncompressed

00:05:26,240 --> 00:05:32,479
200 megabytes per square kilometer

00:05:28,560 --> 00:05:34,800
and we also got png tiles that

00:05:32,479 --> 00:05:36,400
you can take out of this which we use

00:05:34,800 --> 00:05:38,880
for our machine learning

00:05:36,400 --> 00:05:41,759
approach by one megapixel and they

00:05:38,880 --> 00:05:44,960
result to two to three megabytes

00:05:41,759 --> 00:05:46,880
as png so we have this we have the

00:05:44,960 --> 00:05:48,800
aerial imagery we have the vector data

00:05:46,880 --> 00:05:49,919
we have the roof size and the solar

00:05:48,800 --> 00:05:52,560
potential

00:05:49,919 --> 00:05:54,240
um we know that there are around two

00:05:52,560 --> 00:05:56,080
million buildings in switzerland which

00:05:54,240 --> 00:05:57,680
could incorporate solar power but what

00:05:56,080 --> 00:06:00,880
we don't have is the location

00:05:57,680 --> 00:06:02,479
of each system we don't have the size

00:06:00,880 --> 00:06:04,800
and we don't have the type of solar

00:06:02,479 --> 00:06:06,000
panels they know some the federal office

00:06:04,800 --> 00:06:09,199
for energy knows some

00:06:06,000 --> 00:06:11,120
because of um government subventions

00:06:09,199 --> 00:06:13,680
like

00:06:11,120 --> 00:06:15,520
money plans paid out for the owners of

00:06:13,680 --> 00:06:18,720
these panels

00:06:15,520 --> 00:06:20,160
but it's far from complete so this is

00:06:18,720 --> 00:06:22,160
what this project is about

00:06:20,160 --> 00:06:24,160
getting a complete idea you're not the

00:06:22,160 --> 00:06:26,800
first ones doing something similar

00:06:24,160 --> 00:06:28,800
this was uh from stanford deep solar

00:06:26,800 --> 00:06:32,240
project in 2018

00:06:28,800 --> 00:06:35,440
they um already used a

00:06:32,240 --> 00:06:38,720
type of segmentation ai system um

00:06:35,440 --> 00:06:41,840
based on google maps imagery which

00:06:38,720 --> 00:06:43,600
has a much more coarse resolution than

00:06:41,840 --> 00:06:45,199
the 10 centimeters or at least back then

00:06:43,600 --> 00:06:47,680
had a much more coarse resolution

00:06:45,199 --> 00:06:49,360
than 10 cm centimeters we are working on

00:06:47,680 --> 00:06:49,919
so we are really trying to figure out

00:06:49,360 --> 00:06:53,440
now

00:06:49,919 --> 00:06:56,880
how far we can get this

00:06:53,440 --> 00:07:00,240
um you get these um

00:06:56,880 --> 00:07:02,319
common types of object detection which

00:07:00,240 --> 00:07:04,160
most of you will be familiar with you

00:07:02,319 --> 00:07:06,240
can classify the whole image you can

00:07:04,160 --> 00:07:09,039
localize an object within the image

00:07:06,240 --> 00:07:10,319
you can detect the objects and

00:07:09,039 --> 00:07:12,560
instantiate them

00:07:10,319 --> 00:07:13,759
so ideally knowing how many cats there

00:07:12,560 --> 00:07:16,160
are in the picture

00:07:13,759 --> 00:07:17,039
or you can do the most difficult

00:07:16,160 --> 00:07:20,400
approach like

00:07:17,039 --> 00:07:20,400
finding the actual shapes

00:07:21,599 --> 00:07:28,000
my work here is based on

00:07:24,960 --> 00:07:30,520
a project i did in 2017 where i

00:07:28,000 --> 00:07:31,599
detected wildlife on um

00:07:30,520 --> 00:07:35,120
[Music]

00:07:31,599 --> 00:07:36,400
on aerial images done by a thermal

00:07:35,120 --> 00:07:38,960
infrared camera

00:07:36,400 --> 00:07:39,840
and i used tensorflow back then really

00:07:38,960 --> 00:07:42,800
successfully

00:07:39,840 --> 00:07:43,520
to to arrive at a detector that can in

00:07:42,800 --> 00:07:46,560
real time

00:07:43,520 --> 00:07:49,280
like identify certain animal species on

00:07:46,560 --> 00:07:49,680
on thermal sensors so we thought okay

00:07:49,280 --> 00:07:52,160
let's

00:07:49,680 --> 00:07:52,720
let's use this let's use the faster rc n

00:07:52,160 --> 00:07:55,840
approach

00:07:52,720 --> 00:07:58,960
uh for as an initial

00:07:55,840 --> 00:08:02,639
base or to find art where these

00:07:58,960 --> 00:08:04,240
panels are on our tiles from the all of

00:08:02,639 --> 00:08:06,400
switzerland

00:08:04,240 --> 00:08:07,280
you guys are very welcome to try this

00:08:06,400 --> 00:08:10,160
type

00:08:07,280 --> 00:08:12,639
of analysis art yourself i made a little

00:08:10,160 --> 00:08:16,400
tutorial notebook about this

00:08:12,639 --> 00:08:19,680
on google collab i can i can show you

00:08:16,400 --> 00:08:21,759
quickly on in a browser how it's going

00:08:19,680 --> 00:08:25,280
to look like

00:08:21,759 --> 00:08:28,400
the link is here so this is

00:08:25,280 --> 00:08:29,680
this google collab there's all the code

00:08:28,400 --> 00:08:32,000
is documented

00:08:29,680 --> 00:08:34,719
make sure when you execute it that you

00:08:32,000 --> 00:08:37,200
first downgrade

00:08:34,719 --> 00:08:38,880
downgrade numpy out of compatibility

00:08:37,200 --> 00:08:41,200
reason because this code is already a

00:08:38,880 --> 00:08:42,479
bit older than a year

00:08:41,200 --> 00:08:44,320
and then you have to restart the

00:08:42,479 --> 00:08:46,720
notebook and it should run completely

00:08:44,320 --> 00:08:50,000
through it downloads the data set

00:08:46,720 --> 00:08:53,760
and then you can actually

00:08:50,000 --> 00:08:55,360
run a little solar detector for yourself

00:08:53,760 --> 00:08:57,519
and

00:08:55,360 --> 00:08:59,440
okay so it's gonna throw you is error

00:08:57,519 --> 00:09:02,000
but there's there's no problem with it

00:08:59,440 --> 00:09:05,839
you just click restart runtime say yes

00:09:02,000 --> 00:09:09,839
and then you can redo it so this is

00:09:05,839 --> 00:09:12,000
this would be that and it's gonna result

00:09:09,839 --> 00:09:14,000
not with quite because it's preset with

00:09:12,000 --> 00:09:16,320
only three thousand steps learning

00:09:14,000 --> 00:09:17,839
and to not take up too much of time well

00:09:16,320 --> 00:09:18,959
it's gonna result with some similar

00:09:17,839 --> 00:09:21,200
images

00:09:18,959 --> 00:09:22,560
and what we got out of taking this code

00:09:21,200 --> 00:09:25,680
then was

00:09:22,560 --> 00:09:27,040
um with pretty high accuracy already

00:09:25,680 --> 00:09:30,080
finding out

00:09:27,040 --> 00:09:32,959
where panels are not

00:09:30,080 --> 00:09:33,360
not the precise shape but where they are

00:09:32,959 --> 00:09:35,680
so

00:09:33,360 --> 00:09:37,200
okay this is not exactly yet what the

00:09:35,680 --> 00:09:39,120
federal office wanted

00:09:37,200 --> 00:09:41,760
but it's it's already going in the right

00:09:39,120 --> 00:09:43,920
direction um

00:09:41,760 --> 00:09:46,080
what we could use it for them because

00:09:43,920 --> 00:09:48,000
the average precision for photovoltaic

00:09:46,080 --> 00:09:49,519
systems was actually really high with

00:09:48,000 --> 00:09:52,720
about 92 percent

00:09:49,519 --> 00:09:54,640
and for thermal it was like about 62

00:09:52,720 --> 00:09:55,760
because a lot of them were detected as

00:09:54,640 --> 00:09:57,680
photovoltaics

00:09:55,760 --> 00:09:59,360
they tend to be a bit smaller a bit

00:09:57,680 --> 00:10:02,399
harder to detect they have a

00:09:59,360 --> 00:10:03,440
higher heterogeneity so we thought okay

00:10:02,399 --> 00:10:05,760
we go for

00:10:03,440 --> 00:10:07,440
a multi-layered workflow we split our

00:10:05,760 --> 00:10:09,920
data set into these tiles

00:10:07,440 --> 00:10:11,519
we use faster identity faster rcnn to

00:10:09,920 --> 00:10:16,000
identify the tiles

00:10:11,519 --> 00:10:18,800
and then we wanted to start a workshop

00:10:16,000 --> 00:10:20,320
where a few professional experts they

00:10:18,800 --> 00:10:23,600
actually

00:10:20,320 --> 00:10:27,920
label the concrete geometries of this

00:10:23,600 --> 00:10:31,360
so subsequently we can try and mask rcnn

00:10:27,920 --> 00:10:33,279
to find the actual geometries

00:10:31,360 --> 00:10:35,200
um i'm gonna run you through this you

00:10:33,279 --> 00:10:36,560
don't have to look at it now in too much

00:10:35,200 --> 00:10:38,240
detail

00:10:36,560 --> 00:10:39,600
because we have actually nice images for

00:10:38,240 --> 00:10:42,399
this the

00:10:39,600 --> 00:10:43,680
mask rcnn a lot of you might be familiar

00:10:42,399 --> 00:10:45,680
with this

00:10:43,680 --> 00:10:47,200
i think metaport started it a couple of

00:10:45,680 --> 00:10:49,200
years ago

00:10:47,200 --> 00:10:50,640
it's actually quite a recent technology

00:10:49,200 --> 00:10:53,839
to find out precise

00:10:50,640 --> 00:10:55,440
segments of objects it's an extension of

00:10:53,839 --> 00:10:58,800
the faster rcnn

00:10:55,440 --> 00:11:01,680
so it's similar deep learning

00:10:58,800 --> 00:11:02,399
but it's based on masks like the name

00:11:01,680 --> 00:11:04,240
suggests

00:11:02,399 --> 00:11:06,079
so we had to generate these masks

00:11:04,240 --> 00:11:08,320
somehow and not only that

00:11:06,079 --> 00:11:10,160
we we can't just do okay this is all

00:11:08,320 --> 00:11:12,480
photovoltaics the red one here

00:11:10,160 --> 00:11:14,000
and the green one is not for example

00:11:12,480 --> 00:11:17,120
those would be roof windows

00:11:14,000 --> 00:11:19,200
i know they they look pretty close

00:11:17,120 --> 00:11:20,560
we also need to instantiate them

00:11:19,200 --> 00:11:23,680
instantiation means

00:11:20,560 --> 00:11:25,680
like in in the image we need to

00:11:23,680 --> 00:11:28,000
give each of them a single id each

00:11:25,680 --> 00:11:30,480
system that is separate from another

00:11:28,000 --> 00:11:34,480
so we actually know how many there are

00:11:30,480 --> 00:11:37,920
and we can form concrete geometries

00:11:34,480 --> 00:11:39,040
um last year's euro python we had a

00:11:37,920 --> 00:11:42,560
short code sprint

00:11:39,040 --> 00:11:43,040
the um where there was a lot of cool

00:11:42,560 --> 00:11:45,440
input

00:11:43,040 --> 00:11:46,959
and then we programmed the small uh

00:11:45,440 --> 00:11:48,800
cloud contribution client

00:11:46,959 --> 00:11:50,160
also from the input that came out from

00:11:48,800 --> 00:11:53,360
the code sprint

00:11:50,160 --> 00:11:54,639
where um people can actually label the

00:11:53,360 --> 00:11:56,800
data

00:11:54,639 --> 00:11:59,360
this was very specifically for a project

00:11:56,800 --> 00:12:02,959
so it's a bit hard to take this over to

00:11:59,360 --> 00:12:04,959
to another project um then we did a

00:12:02,959 --> 00:12:08,000
workshop we invited

00:12:04,959 --> 00:12:10,480
a couple of trained people and let them

00:12:08,000 --> 00:12:11,200
label a bit more than 30 000 polygons on

00:12:10,480 --> 00:12:13,519
the eight

00:12:11,200 --> 00:12:15,600
more or less 8 000 image tiles they are

00:12:13,519 --> 00:12:16,399
not very evenly distributed throughout

00:12:15,600 --> 00:12:18,320
switzerland

00:12:16,399 --> 00:12:19,519
like because we had a much better

00:12:18,320 --> 00:12:21,839
databases

00:12:19,519 --> 00:12:22,560
from our project partners in argo we had

00:12:21,839 --> 00:12:24,320
more there

00:12:22,560 --> 00:12:26,079
argo is like one of the cantons of

00:12:24,320 --> 00:12:29,839
switzerland

00:12:26,079 --> 00:12:31,760
but we also took some higher densities

00:12:29,839 --> 00:12:33,279
population density cities outside of

00:12:31,760 --> 00:12:36,160
that area to

00:12:33,279 --> 00:12:36,160
to get labels

00:12:36,800 --> 00:12:40,399
i'm not gonna run through all of these

00:12:38,959 --> 00:12:43,120
8000 images with you

00:12:40,399 --> 00:12:44,000
this is just two examples i would i was

00:12:43,120 --> 00:12:47,279
looking like

00:12:44,000 --> 00:12:49,120
solar panels are a relatively good thing

00:12:47,279 --> 00:12:51,519
to label because they

00:12:49,120 --> 00:12:52,160
generally don't have extremely complex

00:12:51,519 --> 00:12:54,720
geometry

00:12:52,160 --> 00:12:56,399
so there's a lot of 90 degree angles so

00:12:54,720 --> 00:12:58,079
it's easy to do it with pointing

00:12:56,399 --> 00:12:59,760
other objects you might have to do with

00:12:58,079 --> 00:13:01,760
a brush type of tool

00:12:59,760 --> 00:13:03,760
here you can just digitize them or

00:13:01,760 --> 00:13:06,959
digitize them

00:13:03,760 --> 00:13:09,760
then we generated the masks

00:13:06,959 --> 00:13:11,200
all the elements are instantiated as

00:13:09,760 --> 00:13:14,480
colors

00:13:11,200 --> 00:13:14,880
on png images that have a fairly small

00:13:14,480 --> 00:13:17,120
size

00:13:14,880 --> 00:13:19,120
that fit exactly over the aerial

00:13:17,120 --> 00:13:22,560
inventory tiles

00:13:19,120 --> 00:13:23,440
um you can see what the labels look like

00:13:22,560 --> 00:13:25,920
so we have

00:13:23,440 --> 00:13:26,720
a lot of system solar systems that are

00:13:25,920 --> 00:13:31,279
actually

00:13:26,720 --> 00:13:31,279
smaller than 10 square meters so

00:13:31,519 --> 00:13:36,240
that doesn't necessarily mean that on

00:13:33,519 --> 00:13:38,000
one roof there's only 10 square

00:13:36,240 --> 00:13:39,680
square meters of solar panels there

00:13:38,000 --> 00:13:41,760
might be multiple rows

00:13:39,680 --> 00:13:44,320
of 10 square meter solar panels but then

00:13:41,760 --> 00:13:48,639
generally most connected panels are

00:13:44,320 --> 00:13:52,480
rather in the smaller section so um

00:13:48,639 --> 00:13:54,240
they would fit on one of our tiles

00:13:52,480 --> 00:13:56,560
and the question is okay we get

00:13:54,240 --> 00:13:58,160
implementations for both for pytorch and

00:13:56,560 --> 00:14:00,000
for tensorflow

00:13:58,160 --> 00:14:02,959
sure there are a couple of others but

00:14:00,000 --> 00:14:05,279
there we have um

00:14:02,959 --> 00:14:06,880
a great support from the community from

00:14:05,279 --> 00:14:09,519
these two and we know that there are

00:14:06,880 --> 00:14:11,920
examples using mask rcnn

00:14:09,519 --> 00:14:13,600
and uh we thought we're going for

00:14:11,920 --> 00:14:17,279
pytorch

00:14:13,600 --> 00:14:19,120
as a lot of you might be familiar

00:14:17,279 --> 00:14:21,519
with the library it's got quite a

00:14:19,120 --> 00:14:23,839
pythonic interface it's got a gpu

00:14:21,519 --> 00:14:27,120
support

00:14:23,839 --> 00:14:28,800
and a nice numpy torch tensor bridge

00:14:27,120 --> 00:14:30,959
you get a lot of pre-trained models

00:14:28,800 --> 00:14:33,040
which are available torch vision you can

00:14:30,959 --> 00:14:35,279
try out multiple optimizers

00:14:33,040 --> 00:14:36,800
with a fairly straightforward approach

00:14:35,279 --> 00:14:38,800
you can see it how the learning rate

00:14:36,800 --> 00:14:40,720
scheduler here is optimized with just a

00:14:38,800 --> 00:14:41,920
few variables and the weight decay of

00:14:40,720 --> 00:14:44,480
the optimizer can

00:14:41,920 --> 00:14:45,920
can be set manually or can be programmed

00:14:44,480 --> 00:14:49,199
easily in python

00:14:45,920 --> 00:14:51,040
so this is a this is a great approach

00:14:49,199 --> 00:14:54,480
and we had one of our students uh

00:14:51,040 --> 00:14:57,600
samwich dumb tried us out in 2019

00:14:54,480 --> 00:15:01,199
um also using google collab on

00:14:57,600 --> 00:15:01,920
avalanche early detection it was working

00:15:01,199 --> 00:15:04,639
quite well

00:15:01,920 --> 00:15:05,040
we were actually surprised ourselves so

00:15:04,639 --> 00:15:08,079
this

00:15:05,040 --> 00:15:12,000
is uh this is like webcam imagery

00:15:08,079 --> 00:15:15,279
from from the alps

00:15:12,000 --> 00:15:17,920
and the the red ones

00:15:15,279 --> 00:15:19,360
are detections which could result later

00:15:17,920 --> 00:15:22,639
in an avalanche and the green

00:15:19,360 --> 00:15:26,000
ones are um false that

00:15:22,639 --> 00:15:26,639
do not uh necessarily become an

00:15:26,000 --> 00:15:28,800
avalanche

00:15:26,639 --> 00:15:30,720
so this was uh one of these projects

00:15:28,800 --> 00:15:32,560
that led to us thinking okay

00:15:30,720 --> 00:15:33,759
this is actually quite a cool technology

00:15:32,560 --> 00:15:36,800
to use here

00:15:33,759 --> 00:15:37,920
um we set up our own high performance

00:15:36,800 --> 00:15:41,759
computing system

00:15:37,920 --> 00:15:44,560
which is an um 48 core cpu

00:15:41,759 --> 00:15:45,199
system with a lot of ram and a lot of

00:15:44,560 --> 00:15:47,839
memory

00:15:45,199 --> 00:15:48,399
but most importantly the four high-speed

00:15:47,839 --> 00:15:51,120
uh

00:15:48,399 --> 00:15:51,600
graphic cards the gpu units with a lot

00:15:51,120 --> 00:15:54,880
of

00:15:51,600 --> 00:15:58,079
cuda cores that you need to have

00:15:54,880 --> 00:16:00,639
efficient training running here our

00:15:58,079 --> 00:16:01,600
front end is a jupiter hub system which

00:16:00,639 --> 00:16:04,240
is

00:16:01,600 --> 00:16:06,000
phenomenal it's really great if you know

00:16:04,240 --> 00:16:08,800
what you're doing

00:16:06,000 --> 00:16:09,839
it offers a terminal unix terminal right

00:16:08,800 --> 00:16:12,560
out of the browser

00:16:09,839 --> 00:16:14,720
and you can um it can run while you

00:16:12,560 --> 00:16:16,800
leave the computer so this is great

00:16:14,720 --> 00:16:19,519
for machine learning you don't have to

00:16:16,800 --> 00:16:22,560
have your own laptop clocked up or

00:16:19,519 --> 00:16:24,480
running revving really high at home so a

00:16:22,560 --> 00:16:26,240
server-styled solution is really the way

00:16:24,480 --> 00:16:27,279
to go for also these amounts of data

00:16:26,240 --> 00:16:30,399
sets that we

00:16:27,279 --> 00:16:30,720
are dealing with here and we have quite

00:16:30,399 --> 00:16:33,920
a

00:16:30,720 --> 00:16:37,759
um we've used the torch utils

00:16:33,920 --> 00:16:41,199
data data set option to try out

00:16:37,759 --> 00:16:43,279
some data parallelism this is is not

00:16:41,199 --> 00:16:45,040
exactly easy to implement but it's

00:16:43,279 --> 00:16:47,759
possible so

00:16:45,040 --> 00:16:49,120
we don't have really provided examples

00:16:47,759 --> 00:16:52,639
for the

00:16:49,120 --> 00:16:54,240
parallel multi-gpu system but we figured

00:16:52,639 --> 00:16:57,759
out

00:16:54,240 --> 00:17:00,320
through try and error to use multi-gpu

00:16:57,759 --> 00:17:02,720
support here

00:17:00,320 --> 00:17:04,319
you can see how we instantiate the png

00:17:02,720 --> 00:17:07,039
images the object

00:17:04,319 --> 00:17:07,919
object masks the label masks those are

00:17:07,039 --> 00:17:10,319
all

00:17:07,919 --> 00:17:11,120
predefined data sets that we can just

00:17:10,319 --> 00:17:14,640
use out of

00:17:11,120 --> 00:17:17,919
provided examples and

00:17:14,640 --> 00:17:18,880
this would be the loss graph for one of

00:17:17,919 --> 00:17:21,600
our runs

00:17:18,880 --> 00:17:23,520
where we did the whole data set of the

00:17:21,600 --> 00:17:26,559
thirty thousand polygons

00:17:23,520 --> 00:17:29,679
and you can see like at around this

00:17:26,559 --> 00:17:33,679
six uh epoch it's not

00:17:29,679 --> 00:17:35,919
um it's not really

00:17:33,679 --> 00:17:36,799
getting any better anymore the models

00:17:35,919 --> 00:17:39,440
we're using a

00:17:36,799 --> 00:17:41,600
resin at 50 here and it was about

00:17:39,440 --> 00:17:43,440
expected that it needs about this time

00:17:41,600 --> 00:17:46,080
we achieved this after

00:17:43,440 --> 00:17:48,400
about two hours of training or something

00:17:46,080 --> 00:17:50,559
like that plus minus

00:17:48,400 --> 00:17:51,440
and here's some preliminary results

00:17:50,559 --> 00:17:54,720
where you can see

00:17:51,440 --> 00:17:56,640
where we're going for so we realized

00:17:54,720 --> 00:17:58,160
when you see the differences in the

00:17:56,640 --> 00:18:00,960
precision value here

00:17:58,160 --> 00:18:02,480
in the seconds between using all the

00:18:00,960 --> 00:18:05,280
categories like

00:18:02,480 --> 00:18:06,480
um photovoltaic thermals and other

00:18:05,280 --> 00:18:09,360
panels

00:18:06,480 --> 00:18:11,200
together in one group the precision

00:18:09,360 --> 00:18:14,160
increases increases dramatically

00:18:11,200 --> 00:18:15,679
compared to when you try to have the

00:18:14,160 --> 00:18:17,600
mask rcnn setup

00:18:15,679 --> 00:18:19,440
that it would differentiate them by the

00:18:17,600 --> 00:18:22,080
by itself already

00:18:19,440 --> 00:18:22,720
so what we see here is that we have

00:18:22,080 --> 00:18:26,240
really

00:18:22,720 --> 00:18:28,480
high more than 80 precision running in a

00:18:26,240 --> 00:18:30,320
single class paradigm so this was the

00:18:28,480 --> 00:18:32,320
way to go for us

00:18:30,320 --> 00:18:34,320
you can see also that is running

00:18:32,320 --> 00:18:36,080
relatively smoothly because the

00:18:34,320 --> 00:18:37,919
dependence between the precision and the

00:18:36,080 --> 00:18:41,280
recall is rather linear

00:18:37,919 --> 00:18:42,400
it's it's actually it's actually okay to

00:18:41,280 --> 00:18:45,120
use as an approach

00:18:42,400 --> 00:18:46,240
some examples um qualitatively how it

00:18:45,120 --> 00:18:49,840
looks like

00:18:46,240 --> 00:18:50,880
um the the masks turn out really well

00:18:49,840 --> 00:18:54,000
there's not too much

00:18:50,880 --> 00:18:56,080
uh spill over or under there's obviously

00:18:54,000 --> 00:18:57,919
still some problems there's roof windows

00:18:56,080 --> 00:18:58,400
that look like solar panels or there's

00:18:57,919 --> 00:19:00,080
like

00:18:58,400 --> 00:19:02,160
these gray structures that have

00:19:00,080 --> 00:19:03,760
absolutely the same shape as

00:19:02,160 --> 00:19:05,440
newer panels that are more black and

00:19:03,760 --> 00:19:06,320
white and reflect the sunlight and the

00:19:05,440 --> 00:19:09,679
gray matter

00:19:06,320 --> 00:19:11,200
so there's the challenges also the small

00:19:09,679 --> 00:19:13,919
ones didn't do too too well

00:19:11,200 --> 00:19:15,679
the ones um below three square meters

00:19:13,919 --> 00:19:17,360
but when we cleared them out of the data

00:19:15,679 --> 00:19:19,200
set the

00:19:17,360 --> 00:19:20,799
the precision or the recoil wouldn't

00:19:19,200 --> 00:19:21,600
drastically increase so we thought we'd

00:19:20,799 --> 00:19:25,919
rather keep them

00:19:21,600 --> 00:19:27,200
in um we want to go over our labels

00:19:25,919 --> 00:19:30,000
again like there's a bit

00:19:27,200 --> 00:19:31,840
problems with reflections uh uh

00:19:30,000 --> 00:19:33,280
sometimes labels were created this is

00:19:31,840 --> 00:19:35,120
just a

00:19:33,280 --> 00:19:36,559
playground slide here this is like a

00:19:35,120 --> 00:19:38,559
bitumen roof

00:19:36,559 --> 00:19:40,799
tar roof or something like that they

00:19:38,559 --> 00:19:41,840
look very very similar to solar panels

00:19:40,799 --> 00:19:44,559
so we have to

00:19:41,840 --> 00:19:46,480
um clean these up still this is still

00:19:44,559 --> 00:19:48,640
quite some manual work there's also some

00:19:46,480 --> 00:19:50,880
complete labeling mistakes in between

00:19:48,640 --> 00:19:52,320
but i think with scales like that it's

00:19:50,880 --> 00:19:54,799
relatively normal

00:19:52,320 --> 00:19:55,440
so we have a computational load for a

00:19:54,799 --> 00:19:58,240
single

00:19:55,440 --> 00:19:59,679
run inferencing all these images over

00:19:58,240 --> 00:20:02,640
the complete of switzerland which is

00:19:59,679 --> 00:20:02,640
four million images

00:20:02,880 --> 00:20:10,159
and each image would take

00:20:06,080 --> 00:20:11,120
on on the cpu cores 2.1 seconds of

00:20:10,159 --> 00:20:14,320
inferencing

00:20:11,120 --> 00:20:14,960
and using the parallelized gpus one

00:20:14,320 --> 00:20:18,159
second

00:20:14,960 --> 00:20:21,600
which is still resulting with 46 days of

00:20:18,159 --> 00:20:22,640
inferencing a bit too much to be honest

00:20:21,600 --> 00:20:25,280
this is uh

00:20:22,640 --> 00:20:26,320
the we're running into really big data

00:20:25,280 --> 00:20:29,520
problems here

00:20:26,320 --> 00:20:30,400
and we figured out that the one big

00:20:29,520 --> 00:20:32,799
reason

00:20:30,400 --> 00:20:34,880
um why this is still taking so long is

00:20:32,799 --> 00:20:38,400
the i o the input output

00:20:34,880 --> 00:20:38,960
operations between the between the hard

00:20:38,400 --> 00:20:42,559
drives

00:20:38,960 --> 00:20:44,880
and and the gpu this is actually

00:20:42,559 --> 00:20:46,640
more something about job scheduling what

00:20:44,880 --> 00:20:49,840
we're dealing with here

00:20:46,640 --> 00:20:53,280
so we figured out a job queue approach

00:20:49,840 --> 00:20:58,400
through mongodb nosql database where

00:20:53,280 --> 00:21:02,880
um where all the detections

00:20:58,400 --> 00:21:02,880
thank you where all the detections get

00:21:03,120 --> 00:21:09,520
run on more or less unlimited processes

00:21:06,159 --> 00:21:10,640
that just get thrown onto the gpus one

00:21:09,520 --> 00:21:14,880
after another

00:21:10,640 --> 00:21:16,960
and then written into into the database

00:21:14,880 --> 00:21:18,720
this uh worked really well as an

00:21:16,960 --> 00:21:20,720
approach and we are currently

00:21:18,720 --> 00:21:23,760
influencing the whole country on

00:21:20,720 --> 00:21:26,320
around plus minus 10 days there's still

00:21:23,760 --> 00:21:27,360
potential by optimizing the model and we

00:21:26,320 --> 00:21:30,000
could um

00:21:27,360 --> 00:21:30,559
reduce the inferencing times maybe by

00:21:30,000 --> 00:21:32,640
use

00:21:30,559 --> 00:21:35,520
using a different model but that would

00:21:32,640 --> 00:21:36,960
require probably using tensorflow since

00:21:35,520 --> 00:21:39,919
we don't want to really

00:21:36,960 --> 00:21:42,480
develop a new mask rcnn approach for

00:21:39,919 --> 00:21:44,559
resnet 101 or something for

00:21:42,480 --> 00:21:46,400
for pi torch and shifting the whole

00:21:44,559 --> 00:21:49,679
architecture is a bit of a

00:21:46,400 --> 00:21:51,039
um problem right now so we're not we're

00:21:49,679 --> 00:21:52,880
probably not doing this but rather

00:21:51,039 --> 00:21:55,280
optimize the model that we have and it's

00:21:52,880 --> 00:21:56,559
not too bad the 10 days that's like a

00:21:55,280 --> 00:21:58,000
more realistic

00:21:56,559 --> 00:22:00,240
uh thing and we are running this

00:21:58,000 --> 00:22:01,600
currently it's taking about another two

00:22:00,240 --> 00:22:03,919
days and then the first

00:22:01,600 --> 00:22:05,280
complete switzerland y data set will be

00:22:03,919 --> 00:22:08,640
available

00:22:05,280 --> 00:22:11,200
um so another option would be to use

00:22:08,640 --> 00:22:12,720
hybrid cpu gpu system so to load the

00:22:11,200 --> 00:22:16,799
cpus as well

00:22:12,720 --> 00:22:20,320
with processors for inferencing

00:22:16,799 --> 00:22:22,720
and there is actually still we can see

00:22:20,320 --> 00:22:26,080
the wattage of the gpus here of the four

00:22:22,720 --> 00:22:29,360
tesla gpus and the memory used

00:22:26,080 --> 00:22:31,280
this is not actually running at its full

00:22:29,360 --> 00:22:35,440
capacity at all so we are still

00:22:31,280 --> 00:22:39,440
bottlenecking at the data database level

00:22:35,440 --> 00:22:41,760
and getting the data sets in

00:22:39,440 --> 00:22:43,520
the actual inferencing takes probably

00:22:41,760 --> 00:22:46,080
really quick and we could still

00:22:43,520 --> 00:22:47,120
scale this up um and optimize for a

00:22:46,080 --> 00:22:50,799
higher gpu

00:22:47,120 --> 00:22:53,120
load um i already mentioned this

00:22:50,799 --> 00:22:56,400
slightly that we want to try out maybe

00:22:53,120 --> 00:22:59,840
resonate 101 or there's also this

00:22:56,400 --> 00:23:01,360
new resonant plus inception v2 mask rcn

00:22:59,840 --> 00:23:03,440
approach

00:23:01,360 --> 00:23:04,960
but since we don't want to like start

00:23:03,440 --> 00:23:07,200
this whole up ourselves

00:23:04,960 --> 00:23:08,960
on pytorch we either have to wait a

00:23:07,200 --> 00:23:11,200
little bit here for the community

00:23:08,960 --> 00:23:12,000
or just try it out in tensorflow anyway

00:23:11,200 --> 00:23:15,039
i mean it's

00:23:12,000 --> 00:23:17,520
uh it's it's not wizardry

00:23:15,039 --> 00:23:18,320
it's cool but it's not wizardry um

00:23:17,520 --> 00:23:21,360
obviously

00:23:18,320 --> 00:23:23,679
some more manual labeling would

00:23:21,360 --> 00:23:24,880
be always great like more data is always

00:23:23,679 --> 00:23:27,840
better in our times

00:23:24,880 --> 00:23:29,520
isn't it uh but we also have some post

00:23:27,840 --> 00:23:32,400
classification strategies which

00:23:29,520 --> 00:23:33,280
might render the other um other things

00:23:32,400 --> 00:23:36,559
like

00:23:33,280 --> 00:23:39,039
uh superfluous like we have this

00:23:36,559 --> 00:23:41,039
post classification workflow now set up

00:23:39,039 --> 00:23:43,039
where we run multiple models

00:23:41,039 --> 00:23:44,880
for inferencing like with multiple

00:23:43,039 --> 00:23:48,400
optimizers with multiple

00:23:44,880 --> 00:23:50,880
um with multiple presets my um

00:23:48,400 --> 00:23:51,840
or different uh different data set

00:23:50,880 --> 00:23:55,520
handling

00:23:51,840 --> 00:23:57,520
and different uh tiles cut like a shift

00:23:55,520 --> 00:24:00,320
in the tiles and then we want to

00:23:57,520 --> 00:24:01,279
um doing heuristic analyzers on which

00:24:00,320 --> 00:24:03,840
pixels actually

00:24:01,279 --> 00:24:06,240
which probability by multiple models

00:24:03,840 --> 00:24:06,240
used

00:24:07,200 --> 00:24:11,120
also including the near infrared data as

00:24:10,400 --> 00:24:12,480
an option

00:24:11,120 --> 00:24:14,640
there you can see a map of a 10

00:24:12,480 --> 00:24:17,679
centimeter coverage

00:24:14,640 --> 00:24:19,120
that is currently available so this

00:24:17,679 --> 00:24:21,760
would fit well with our

00:24:19,120 --> 00:24:22,480
multi uh multi model and the heuristic

00:24:21,760 --> 00:24:24,480
analysis

00:24:22,480 --> 00:24:26,480
and in the end we could drop this all

00:24:24,480 --> 00:24:28,080
into a random forest classifier together

00:24:26,480 --> 00:24:31,279
with cadasta data

00:24:28,080 --> 00:24:33,679
um gis attributes uh like

00:24:31,279 --> 00:24:35,039
um there there are a lot of big

00:24:33,679 --> 00:24:37,120
statistics data sets

00:24:35,039 --> 00:24:38,240
area statistic data sets in switzerland

00:24:37,120 --> 00:24:40,880
available

00:24:38,240 --> 00:24:41,520
that uh we could use for this type of

00:24:40,880 --> 00:24:43,840
approach

00:24:41,520 --> 00:24:45,520
and then we would possibly additionally

00:24:43,840 --> 00:24:48,159
run an exception model

00:24:45,520 --> 00:24:48,720
like a classification approach on the

00:24:48,159 --> 00:24:51,440
tiles

00:24:48,720 --> 00:24:53,440
on on the actual masks that we have

00:24:51,440 --> 00:24:55,520
identified already as having solar

00:24:53,440 --> 00:24:57,200
panels in order to figure out which type

00:24:55,520 --> 00:24:59,200
it is is it thermal or is it

00:24:57,200 --> 00:25:02,320
photovoltaic

00:24:59,200 --> 00:25:05,120
okay that would be the end uh

00:25:02,320 --> 00:25:05,840
i'll give you this little goody picture

00:25:05,120 --> 00:25:09,120
for the end

00:25:05,840 --> 00:25:10,880
uh um just uh

00:25:09,120 --> 00:25:12,960
underlining that also humans sometimes

00:25:10,880 --> 00:25:13,679
have difficulties telling things apart

00:25:12,960 --> 00:25:18,000
that look

00:25:13,679 --> 00:25:18,000
very alike okay thank you so much

00:25:18,320 --> 00:25:22,159
thank you so i actually do have a couple

00:25:19,919 --> 00:25:25,679
of questions in here for you

00:25:22,159 --> 00:25:27,600
um so yeah i love the dog and muffin

00:25:25,679 --> 00:25:30,320
scenario

00:25:27,600 --> 00:25:32,080
that's crazy okay so yeah i've i've got

00:25:30,320 --> 00:25:35,840
a couple of good questions here ah so

00:25:32,080 --> 00:25:36,400
um but um i hope i'm not butchering that

00:25:35,840 --> 00:25:38,640
name

00:25:36,400 --> 00:25:41,200
uh said can you not get some of this

00:25:38,640 --> 00:25:42,159
information location of pv panels type

00:25:41,200 --> 00:25:46,480
etc from

00:25:42,159 --> 00:25:46,480
local distribution network operators

00:25:46,559 --> 00:25:53,760
yeah this is true and this is what we

00:25:50,480 --> 00:25:54,559
what we based some of our data sets

00:25:53,760 --> 00:25:56,640
actually on

00:25:54,559 --> 00:25:58,559
like but we only have like a really

00:25:56,640 --> 00:25:59,360
consistent data set for this for the

00:25:58,559 --> 00:26:01,919
canton of

00:25:59,360 --> 00:26:03,120
argo which covers a small part of

00:26:01,919 --> 00:26:04,960
switzerland and the

00:26:03,120 --> 00:26:07,120
whole idea of the project was to have

00:26:04,960 --> 00:26:08,640
like a consistent data set over the

00:26:07,120 --> 00:26:11,679
whole of switzerland

00:26:08,640 --> 00:26:14,559
um there are data sets where there's

00:26:11,679 --> 00:26:15,120
rough point location more or less for

00:26:14,559 --> 00:26:17,679
for

00:26:15,120 --> 00:26:18,400
uh larger photovoltaic systems but for

00:26:17,679 --> 00:26:21,840
the small

00:26:18,400 --> 00:26:22,640
private ones at home um or smaller they

00:26:21,840 --> 00:26:25,520
still might cover

00:26:22,640 --> 00:26:26,480
more than 10 square meters but there the

00:26:25,520 --> 00:26:28,720
data is

00:26:26,480 --> 00:26:30,240
not there yet especially not when it

00:26:28,720 --> 00:26:33,679
comes to

00:26:30,240 --> 00:26:35,039
the actual shape all right and then

00:26:33,679 --> 00:26:36,799
i think we have time for one uh

00:26:35,039 --> 00:26:40,240
hopefully one more maybe both

00:26:36,799 --> 00:26:42,080
um okay so um anonymous person s

00:26:40,240 --> 00:26:44,000
uh there are a lot of different

00:26:42,080 --> 00:26:45,039
solutions to detect pv based on

00:26:44,000 --> 00:26:47,200
satellite images

00:26:45,039 --> 00:26:49,360
and more are coming what is the state of

00:26:47,200 --> 00:26:53,440
art and why are there still various

00:26:49,360 --> 00:26:56,720
companies working on new solutions

00:26:53,440 --> 00:27:00,240
um yeah i i think

00:26:56,720 --> 00:27:04,080
actually uh it depends largely on

00:27:00,240 --> 00:27:07,520
the amount of or the the type of

00:27:04,080 --> 00:27:09,679
input data that you have there are quite

00:27:07,520 --> 00:27:11,760
various approaches to do this but i

00:27:09,679 --> 00:27:13,840
think it crystallizes out in a moment

00:27:11,760 --> 00:27:17,440
that machine learning at least is

00:27:13,840 --> 00:27:21,360
is the way to go there there have been

00:27:17,440 --> 00:27:23,600
um approaches in the past of

00:27:21,360 --> 00:27:24,880
using more like pixel based analysis or

00:27:23,600 --> 00:27:27,840
obia

00:27:24,880 --> 00:27:28,640
these types of approaches but it tends

00:27:27,840 --> 00:27:31,440
that

00:27:28,640 --> 00:27:33,600
it turns out that at the moment probably

00:27:31,440 --> 00:27:36,880
using segmentation based deep learning

00:27:33,600 --> 00:27:36,880
is the state of the art

00:27:37,039 --> 00:27:42,880
maybe using these multi-party approaches

00:27:40,159 --> 00:27:45,440
like having actually multiple parallel

00:27:42,880 --> 00:27:48,159
deep learning networks can increase the

00:27:45,440 --> 00:27:48,559
reliability of these types of analysis

00:27:48,159 --> 00:27:50,159
so

00:27:48,559 --> 00:27:52,320
we are hoping that we are at the state

00:27:50,159 --> 00:27:56,080
of the art

00:27:52,320 --> 00:27:58,080
by doing that excellent and actually i

00:27:56,080 --> 00:28:00,559
think i can get this last one in so

00:27:58,080 --> 00:28:02,000
uh simon asks it was mentioned that a

00:28:00,559 --> 00:28:04,240
mask rcnn was

00:28:02,000 --> 00:28:06,720
trained in about two hours with a resnet

00:28:04,240 --> 00:28:08,320
50 backbone on the mentioned hardware

00:28:06,720 --> 00:28:12,080
was the training done with transfer

00:28:08,320 --> 00:28:12,080
learning or training from scratch

00:28:13,039 --> 00:28:17,600
yeah we do use transfer learning because

00:28:15,919 --> 00:28:19,919
we still think although we have 8

00:28:17,600 --> 00:28:23,200
000 images our data set is not large

00:28:19,919 --> 00:28:26,799
enough to start from scratch

00:28:23,200 --> 00:28:30,000
transfer learning is is much easier

00:28:26,799 --> 00:28:34,159
to implement and you have

00:28:30,000 --> 00:28:34,960
a lot of um a lot of support by the

00:28:34,159 --> 00:28:36,799
community

00:28:34,960 --> 00:28:38,880
you have a lot of experience that is

00:28:36,799 --> 00:28:41,200
already around and

00:28:38,880 --> 00:28:42,080
quite frankly the the the pre-trained

00:28:41,200 --> 00:28:44,399
models they

00:28:42,080 --> 00:28:46,320
they are just better on a lot of things

00:28:44,399 --> 00:28:49,200
than doing it from scratch

00:28:46,320 --> 00:28:50,000
as from from our experience so yeah we

00:28:49,200 --> 00:28:53,039
did use

00:28:50,000 --> 00:28:56,559
um transfer learning

00:28:53,039 --> 00:29:00,399
and we started with coco pre-trained

00:28:56,559 --> 00:29:00,399
excellent thank you so much adrian

00:29:06,960 --> 00:29:13,840
so if anyone has any other questions for

00:29:10,840 --> 00:29:13,840

YouTube URL: https://www.youtube.com/watch?v=h0mmpcBAYfA


