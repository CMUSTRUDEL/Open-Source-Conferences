Title: Laurent PICARD - Building smarter solutions with no expertise in machine learning
Publication date: 2020-09-21
Playlist: EuroPython 2020
Description: 
	"Building smarter solutions with no expertise in machine learning
EuroPython 2020 - Talk - 2020-07-23 - Parrot Data Science
Online

By Laurent PICARD

ML? API? AutoML? Python is the language of choice to solve problems with machine learning, but what can we build in only a few hours or days and without any expertise? In this session, we'll see how to benefit from existing ML models and how to create a custom model with AutoML techniques. Weâ€™ll also be active players of a live demo, so don't put your smartphone on airplane mode!



License: This video is licensed under the CC BY-NC-SA 3.0 license: https://creativecommons.org/licenses/by-nc-sa/3.0/
Please see our speaker release agreement for details: https://ep2020.europython.eu/events/speaker-release-agreement/

    "
Captions: 
	00:00:06,720 --> 00:00:12,880
okay lauren picard is from google

00:00:09,280 --> 00:00:14,920
and yeah let's take it away okay so can

00:00:12,880 --> 00:00:19,119
you start your screen sharing

00:00:14,920 --> 00:00:19,119
yes all done

00:00:20,400 --> 00:00:25,199
so hello everyone thanks uh for having

00:00:23,359 --> 00:00:28,880
me today

00:00:25,199 --> 00:00:28,880
um okay

00:00:29,519 --> 00:00:34,160
i'm going to hide my own window okay a

00:00:32,320 --> 00:00:36,559
quick introduction so my my name is

00:00:34,160 --> 00:00:37,520
lauren piccard as you can you can tell

00:00:36,559 --> 00:00:39,520
i'm french

00:00:37,520 --> 00:00:40,960
i'm actually based in paris and my

00:00:39,520 --> 00:00:44,160
background um

00:00:40,960 --> 00:00:48,480
i am an ebook pioneer so i've been uh

00:00:44,160 --> 00:00:51,440
working in the e-book industry

00:00:48,480 --> 00:00:52,399
for 17 years 20 years ago and for three

00:00:51,440 --> 00:00:54,719
years now

00:00:52,399 --> 00:00:56,000
i'm focusing on cloud technologies uh

00:00:54,719 --> 00:00:59,199
with google cloud

00:00:56,000 --> 00:01:01,120
okay unfortunately i cannot uh see you

00:00:59,199 --> 00:01:03,760
and ask you questions

00:01:01,120 --> 00:01:05,199
um i i very much like to to start with

00:01:03,760 --> 00:01:08,320
this quote from our

00:01:05,199 --> 00:01:10,479
clock uh because it really uh

00:01:08,320 --> 00:01:12,159
shows the feeling i have whenever

00:01:10,479 --> 00:01:12,799
there's something new done with machine

00:01:12,159 --> 00:01:15,920
learning

00:01:12,799 --> 00:01:19,040
and still after a couple of years um

00:01:15,920 --> 00:01:20,159
i feel magic honestly but this is just

00:01:19,040 --> 00:01:22,159
technology

00:01:20,159 --> 00:01:23,520
and and you scratch a little bit this is

00:01:22,159 --> 00:01:26,560
your technology and

00:01:23,520 --> 00:01:28,000
we can all understand what's behind it

00:01:26,560 --> 00:01:30,799
or have a pretty

00:01:28,000 --> 00:01:32,560
good idea and my goal today is to maybe

00:01:30,799 --> 00:01:35,280
scratch a little bit behind

00:01:32,560 --> 00:01:37,439
some stuff you haven't seen my i have my

00:01:35,280 --> 00:01:39,680
own definition of machine learning uh

00:01:37,439 --> 00:01:41,840
that's a weird one but

00:01:39,680 --> 00:01:43,600
for me machine learning is solving

00:01:41,840 --> 00:01:46,079
solutions where you have data

00:01:43,600 --> 00:01:46,880
right you have the data and you want to

00:01:46,079 --> 00:01:49,280
understand

00:01:46,880 --> 00:01:50,159
what's in your data you want to extract

00:01:49,280 --> 00:01:53,840
information

00:01:50,159 --> 00:01:55,200
out of your data so this is my personal

00:01:53,840 --> 00:01:58,159
definition but it's a

00:01:55,200 --> 00:01:59,840
an incorrect one uh the real definition

00:01:58,159 --> 00:02:02,719
is that machine learning is a part

00:01:59,840 --> 00:02:04,159
of ai and within machine learning you

00:02:02,719 --> 00:02:05,920
have deep learning so

00:02:04,159 --> 00:02:07,439
most of the stuff i'm going to show you

00:02:05,920 --> 00:02:09,679
uh today is

00:02:07,439 --> 00:02:10,640
actually deep learning but for

00:02:09,679 --> 00:02:13,920
simplicity

00:02:10,640 --> 00:02:15,360
uh for the sake of simplicity uh i will

00:02:13,920 --> 00:02:18,560
be mentioning machine learning

00:02:15,360 --> 00:02:20,879
uh most of the time uh so how does

00:02:18,560 --> 00:02:21,680
deep learning work so first uh the

00:02:20,879 --> 00:02:23,920
expert

00:02:21,680 --> 00:02:24,959
started to work on the field 40 years

00:02:23,920 --> 00:02:26,959
ago

00:02:24,959 --> 00:02:28,239
last year they actually got the the

00:02:26,959 --> 00:02:30,800
elementary price

00:02:28,239 --> 00:02:31,840
award for that uh it's like the nobel

00:02:30,800 --> 00:02:34,800
prize

00:02:31,840 --> 00:02:35,360
for computer science and they thought at

00:02:34,800 --> 00:02:38,480
the time

00:02:35,360 --> 00:02:39,599
okay let's try to mimic the way we think

00:02:38,480 --> 00:02:41,680
our brain works

00:02:39,599 --> 00:02:42,640
with neural networks for that they

00:02:41,680 --> 00:02:46,000
needed

00:02:42,640 --> 00:02:48,080
many examples and the magic here is that

00:02:46,000 --> 00:02:51,440
they managed to solve problems

00:02:48,080 --> 00:02:52,640
and we don't know exactly why or uh we

00:02:51,440 --> 00:02:54,720
don't have the answer

00:02:52,640 --> 00:02:55,680
uh the systemic answer to solve these

00:02:54,720 --> 00:02:57,599
problems but

00:02:55,680 --> 00:02:59,599
machine learning is now solving these

00:02:57,599 --> 00:03:00,959
problems where we couldn't solve them

00:02:59,599 --> 00:03:03,200
before

00:03:00,959 --> 00:03:04,800
why does it work today uh so first of

00:03:03,200 --> 00:03:08,159
all we are

00:03:04,800 --> 00:03:11,599
inheriting for a century from centuries

00:03:08,159 --> 00:03:12,400
of science and in particular algorithms

00:03:11,599 --> 00:03:16,159
a lot from

00:03:12,400 --> 00:03:19,519
coming from mathematics and physics

00:03:16,159 --> 00:03:23,360
for a couple of decades we now have

00:03:19,519 --> 00:03:26,799
everything we need for big data we're

00:03:23,360 --> 00:03:28,720
able to store data we're able to consult

00:03:26,799 --> 00:03:30,400
a lot of data now thanks to computers

00:03:28,720 --> 00:03:33,760
but and for most

00:03:30,400 --> 00:03:34,640
now for let's say a few years or one

00:03:33,760 --> 00:03:36,400
decade

00:03:34,640 --> 00:03:37,680
now technology and especially cloud

00:03:36,400 --> 00:03:39,680
technologies

00:03:37,680 --> 00:03:41,200
uh give us the computing power to do

00:03:39,680 --> 00:03:43,599
everything of course

00:03:41,200 --> 00:03:45,680
uh personal computers laptops now have

00:03:43,599 --> 00:03:48,560
an amazing computing power

00:03:45,680 --> 00:03:50,879
but uh cloud technologies now allow you

00:03:48,560 --> 00:03:53,280
to go to the next step and do stuff in

00:03:50,879 --> 00:03:55,280
hours or days where it would take uh

00:03:53,280 --> 00:03:58,000
weeks before

00:03:55,280 --> 00:03:58,319
okay to give you an idea so i'm going to

00:03:58,000 --> 00:04:01,200
talk

00:03:58,319 --> 00:04:02,560
generally about machine learning

00:04:01,200 --> 00:04:04,319
possibilities

00:04:02,560 --> 00:04:06,000
but to give you an idea about how much

00:04:04,319 --> 00:04:09,360
important that is at google

00:04:06,000 --> 00:04:11,760
so those are the numbers of projects um

00:04:09,360 --> 00:04:14,239
so it's a couple of years back which

00:04:11,760 --> 00:04:16,479
have a machine learning problem uh

00:04:14,239 --> 00:04:17,519
sorry a machine learning model in their

00:04:16,479 --> 00:04:20,560
projects

00:04:17,519 --> 00:04:23,360
um and you've seen some of them uh as

00:04:20,560 --> 00:04:25,360
results so for instance uh in gmail when

00:04:23,360 --> 00:04:28,080
you start to type a sentence

00:04:25,360 --> 00:04:30,080
you can you have a suggestion suggestion

00:04:28,080 --> 00:04:33,680
to end the sentence

00:04:30,080 --> 00:04:36,479
uh in android you in the late

00:04:33,680 --> 00:04:37,360
version of android there is a local

00:04:36,479 --> 00:04:39,360
customized

00:04:37,360 --> 00:04:41,840
machine learning model learning from

00:04:39,360 --> 00:04:42,800
your habits and optimizing the battery

00:04:41,840 --> 00:04:45,520
life

00:04:42,800 --> 00:04:46,160
and in google photos maybe you've tried

00:04:45,520 --> 00:04:49,120
that

00:04:46,160 --> 00:04:49,759
um if you say okay this is my kid on one

00:04:49,120 --> 00:04:52,960
picture

00:04:49,759 --> 00:04:56,000
it will find a match of your kid on all

00:04:52,960 --> 00:05:00,080
other pictures uh but even uh 10

00:04:56,000 --> 00:05:03,280
years back or two so it's it's very uh

00:05:00,080 --> 00:05:04,400
amazing technology there are three ways

00:05:03,280 --> 00:05:06,240
today uh

00:05:04,400 --> 00:05:07,600
that you can benefit from machine

00:05:06,240 --> 00:05:09,840
learning of course

00:05:07,600 --> 00:05:11,520
if you are an expert then you know a lot

00:05:09,840 --> 00:05:14,080
about it you're dealing with

00:05:11,520 --> 00:05:15,360
neural networks and i hope you will

00:05:14,080 --> 00:05:17,440
learn a few or see

00:05:15,360 --> 00:05:18,720
few things of interest for you for you

00:05:17,440 --> 00:05:21,199
in this talk

00:05:18,720 --> 00:05:21,840
but if you're spending most of your time

00:05:21,199 --> 00:05:23,919
there

00:05:21,840 --> 00:05:25,759
developing solutions then maybe you

00:05:23,919 --> 00:05:27,280
don't have the expertise to

00:05:25,759 --> 00:05:28,800
deal with machine learning but it

00:05:27,280 --> 00:05:30,800
doesn't matter you can

00:05:28,800 --> 00:05:33,360
maybe use existing machine learning

00:05:30,800 --> 00:05:34,080
models they are available through apis

00:05:33,360 --> 00:05:37,360
they are

00:05:34,080 --> 00:05:38,080
ready to use models right and in between

00:05:37,360 --> 00:05:40,160
now for

00:05:38,080 --> 00:05:41,680
cops since a couple of years there are

00:05:40,160 --> 00:05:45,039
there are autoimmune

00:05:41,680 --> 00:05:47,600
techniques uh so it's filling a big gap

00:05:45,039 --> 00:05:48,080
you still don't need expertise but you

00:05:47,600 --> 00:05:50,800
can

00:05:48,080 --> 00:05:52,880
automatically build customary customized

00:05:50,800 --> 00:05:55,280
models for your own needs

00:05:52,880 --> 00:05:56,319
and the purpose of this talk today is to

00:05:55,280 --> 00:05:58,639
give you

00:05:56,319 --> 00:06:00,319
a quick overview of everything you can

00:05:58,639 --> 00:06:03,440
do with these two

00:06:00,319 --> 00:06:06,080
types of technologies okay

00:06:03,440 --> 00:06:07,840
so first the machine learning apis so if

00:06:06,080 --> 00:06:09,840
you remember my own definition

00:06:07,840 --> 00:06:12,400
of machine learning it's solving

00:06:09,840 --> 00:06:16,080
solutions from data and data here

00:06:12,400 --> 00:06:19,120
can be text pictures videos or speech

00:06:16,080 --> 00:06:20,080
then you need models and from that you

00:06:19,120 --> 00:06:23,520
can extract

00:06:20,080 --> 00:06:24,240
information and sometimes the result you

00:06:23,520 --> 00:06:26,479
want is

00:06:24,240 --> 00:06:27,840
your input transform transcribe into

00:06:26,479 --> 00:06:31,199
something else

00:06:27,840 --> 00:06:34,639
right okay now let me start with

00:06:31,199 --> 00:06:37,360
the vision model so i really love

00:06:34,639 --> 00:06:39,039
this kind of model because in the 90s i

00:06:37,360 --> 00:06:41,039
was a student

00:06:39,039 --> 00:06:42,560
so we were not talking about machine

00:06:41,039 --> 00:06:45,280
learning at the time

00:06:42,560 --> 00:06:46,479
but i was trying with other students to

00:06:45,280 --> 00:06:49,039
solve the problem of

00:06:46,479 --> 00:06:50,880
understanding what what's in a picture

00:06:49,039 --> 00:06:53,199
understanding the content of a picture

00:06:50,880 --> 00:06:55,360
to automatically detect stuff

00:06:53,199 --> 00:06:57,039
and at the time we were just trying to

00:06:55,360 --> 00:06:59,919
detect edges

00:06:57,039 --> 00:07:00,560
and it just failed miserably because we

00:06:59,919 --> 00:07:02,319
could do

00:07:00,560 --> 00:07:03,919
it on a few pictures and then as soon as

00:07:02,319 --> 00:07:06,240
we would bring something new

00:07:03,919 --> 00:07:08,400
then it would fail it would not work

00:07:06,240 --> 00:07:09,520
anymore machine learning is the solution

00:07:08,400 --> 00:07:12,400
now

00:07:09,520 --> 00:07:12,960
uh provide a feature to a machine

00:07:12,400 --> 00:07:15,199
learning mode

00:07:12,960 --> 00:07:17,520
a vision model first of all it's

00:07:15,199 --> 00:07:19,840
supposed it's able to give you

00:07:17,520 --> 00:07:20,880
labels to describe you the picture

00:07:19,840 --> 00:07:23,759
what's in the picture

00:07:20,880 --> 00:07:24,880
in general so here this is a picture uh

00:07:23,759 --> 00:07:26,880
um

00:07:24,880 --> 00:07:28,400
about orbiting so between is the place

00:07:26,880 --> 00:07:30,639
in new zealand where the lords

00:07:28,400 --> 00:07:32,560
of the rings the lord of the rings

00:07:30,639 --> 00:07:35,599
movies were shot

00:07:32,560 --> 00:07:39,599
and this picture so this is on the right

00:07:35,599 --> 00:07:42,479
the json stream that i get from the api

00:07:39,599 --> 00:07:43,280
and it tells me that at 95 percent of

00:07:42,479 --> 00:07:45,280
confidence

00:07:43,280 --> 00:07:46,560
it's about nature and so on so that's

00:07:45,280 --> 00:07:48,560
correct

00:07:46,560 --> 00:07:49,919
more precisely so if i take the same

00:07:48,560 --> 00:07:52,639
picture but this time

00:07:49,919 --> 00:07:54,560
i zoomed in a little bit i flipped it

00:07:52,639 --> 00:07:57,440
and cropped it

00:07:54,560 --> 00:07:58,160
then a vision model is also able to

00:07:57,440 --> 00:08:01,120
match

00:07:58,160 --> 00:08:03,199
this feature with an existing one a

00:08:01,120 --> 00:08:04,479
public one on the web and here it's able

00:08:03,199 --> 00:08:06,720
to tell me that

00:08:04,479 --> 00:08:07,680
most likely this this feature is about

00:08:06,720 --> 00:08:10,479
this place

00:08:07,680 --> 00:08:11,520
and i even get the gps location for it

00:08:10,479 --> 00:08:14,080
right

00:08:11,520 --> 00:08:14,879
more precisely here must be a picture of

00:08:14,080 --> 00:08:17,280
the cast

00:08:14,879 --> 00:08:18,639
uh in a restaurant store still in new

00:08:17,280 --> 00:08:20,720
zealand

00:08:18,639 --> 00:08:22,800
it can try to detect entities so it's

00:08:20,720 --> 00:08:25,120
called object detection

00:08:22,800 --> 00:08:26,400
uh so detect entities but precisely with

00:08:25,120 --> 00:08:29,680
the bounding box

00:08:26,400 --> 00:08:32,560
in pictures and here the results

00:08:29,680 --> 00:08:33,120
i get are that there are many persons

00:08:32,560 --> 00:08:35,279
see

00:08:33,120 --> 00:08:36,560
so this one is a person right but there

00:08:35,279 --> 00:08:40,640
are pants here

00:08:36,560 --> 00:08:42,240
uh and even tops okay so it can be very

00:08:40,640 --> 00:08:45,200
precise

00:08:42,240 --> 00:08:46,000
even more precise uh can detect faces in

00:08:45,200 --> 00:08:48,800
general

00:08:46,000 --> 00:08:49,519
faces so it's here it's a trendy

00:08:48,800 --> 00:08:52,399
rendition

00:08:49,519 --> 00:08:52,959
and what i get is the crop box for the

00:08:52,399 --> 00:08:56,080
face

00:08:52,959 --> 00:08:57,519
a large one or close one but i get also

00:08:56,080 --> 00:08:58,560
also the location of the different

00:08:57,519 --> 00:09:00,800
features

00:08:58,560 --> 00:09:02,720
like the eyes the nose the mouse and so

00:09:00,800 --> 00:09:06,640
on i get the position

00:09:02,720 --> 00:09:10,399
of the head in three dimensions and also

00:09:06,640 --> 00:09:13,600
a vision model can be taught to detect

00:09:10,399 --> 00:09:16,080
emotions so here there are a few

00:09:13,600 --> 00:09:16,640
generic emotions and what it detects is

00:09:16,080 --> 00:09:19,279
that

00:09:16,640 --> 00:09:19,839
likely this face is angry and this is

00:09:19,279 --> 00:09:23,279
gulu

00:09:19,839 --> 00:09:27,600
golum is always angry right

00:09:23,279 --> 00:09:30,720
let's move on so now um still on vision

00:09:27,600 --> 00:09:32,560
optical character recognition so ocr

00:09:30,720 --> 00:09:35,519
this is a problem that is now

00:09:32,560 --> 00:09:37,360
fully solved thanks to machine learning

00:09:35,519 --> 00:09:39,920
if i take this screenshot

00:09:37,360 --> 00:09:40,399
the vision model is able to tell me that

00:09:39,920 --> 00:09:43,600
there are

00:09:40,399 --> 00:09:46,959
three main blocks and then inside them

00:09:43,600 --> 00:09:48,080
there are sentences or lines or rows if

00:09:46,959 --> 00:09:51,680
you prefer

00:09:48,080 --> 00:09:54,320
and then words and then symbols um

00:09:51,680 --> 00:09:55,760
it here doesn't make any mistakes it's

00:09:54,320 --> 00:09:59,279
really perfect

00:09:55,760 --> 00:10:01,360
uh so it's a soft problem even if i

00:09:59,279 --> 00:10:02,720
apply some perspective effect so if you

00:10:01,360 --> 00:10:06,320
take a picture on a table

00:10:02,720 --> 00:10:09,040
or on a wall and so on it still works

00:10:06,320 --> 00:10:10,000
really greatly so let's say it's a

00:10:09,040 --> 00:10:12,720
solved problem

00:10:10,000 --> 00:10:14,560
but the next step now for ocr is

00:10:12,720 --> 00:10:17,279
actually handwriting detection

00:10:14,560 --> 00:10:19,360
and it starts to work really great

00:10:17,279 --> 00:10:21,680
already so it's the same principle

00:10:19,360 --> 00:10:23,200
so here this is a handwriting from

00:10:21,680 --> 00:10:26,000
tolkien

00:10:23,200 --> 00:10:27,440
and so it's not perfect it's not as good

00:10:26,000 --> 00:10:30,640
as for typewriting

00:10:27,440 --> 00:10:34,000
but here is detecting the

00:10:30,640 --> 00:10:36,399
lord of the rings so ideally it would

00:10:34,000 --> 00:10:37,760
uh detect the first one here and the

00:10:36,399 --> 00:10:40,000
second one here

00:10:37,760 --> 00:10:41,760
but then it works pretty well and it's

00:10:40,000 --> 00:10:44,480
just making

00:10:41,760 --> 00:10:45,519
one big mistake here shadows so it's

00:10:44,480 --> 00:10:48,079
detecting a v

00:10:45,519 --> 00:10:50,640
instead of the w's something that could

00:10:48,079 --> 00:10:54,320
be uh maybe autocorrected uh

00:10:50,640 --> 00:10:57,360
with uh with natural language processing

00:10:54,320 --> 00:11:00,399
uh but it does very it does

00:10:57,360 --> 00:11:03,040
very little mistakes here there's a

00:11:00,399 --> 00:11:04,399
the bottom of the f is detected as

00:11:03,040 --> 00:11:07,279
something else

00:11:04,399 --> 00:11:08,560
uh so it's almost perfect it's really

00:11:07,279 --> 00:11:11,360
really good

00:11:08,560 --> 00:11:12,560
uh the limit of that of course is if we

00:11:11,360 --> 00:11:15,600
are not able

00:11:12,560 --> 00:11:17,200
ourselves to read back something that is

00:11:15,600 --> 00:11:19,200
and right and written

00:11:17,200 --> 00:11:21,760
then a machine learning model won't be

00:11:19,200 --> 00:11:25,040
either and and the limit might be

00:11:21,760 --> 00:11:26,560
uh doctor prescriptions right

00:11:25,040 --> 00:11:29,279
sometimes they are not even able

00:11:26,560 --> 00:11:32,560
themselves to read them

00:11:29,279 --> 00:11:36,320
okay so and and also

00:11:32,560 --> 00:11:39,040
um it's able to detect entities

00:11:36,320 --> 00:11:39,680
and to match them up with uh something

00:11:39,040 --> 00:11:42,880
uh

00:11:39,680 --> 00:11:46,079
close to it uh found on the web so

00:11:42,880 --> 00:11:48,959
on this example i took a picture

00:11:46,079 --> 00:11:50,000
from a sponge newspaper that i had never

00:11:48,959 --> 00:11:52,480
seen before

00:11:50,000 --> 00:11:53,360
so it's a very rare picture of tokyo

00:11:52,480 --> 00:11:55,360
once again i

00:11:53,360 --> 00:11:57,760
zoomed in i cropped the picture changed

00:11:55,360 --> 00:12:00,079
the colors so there's not any single

00:11:57,760 --> 00:12:02,639
pixel in common with the the original

00:12:00,079 --> 00:12:04,560
one but yet the visual model is able to

00:12:02,639 --> 00:12:07,519
detect this picture

00:12:04,560 --> 00:12:09,200
to to tell me that it's coming from this

00:12:07,519 --> 00:12:12,320
spanish newspaper

00:12:09,200 --> 00:12:14,160
but more than that it's able to match

00:12:12,320 --> 00:12:16,000
with the text on this webpage and tell

00:12:14,160 --> 00:12:19,040
me that most likely

00:12:16,000 --> 00:12:22,560
this picture is about tolkien and

00:12:19,040 --> 00:12:25,920
what i get here so gr tolkien i get an

00:12:22,560 --> 00:12:28,720
entity id so this id lets me

00:12:25,920 --> 00:12:31,040
work with a single any id and i will

00:12:28,720 --> 00:12:34,079
deal with tolkien in this way

00:12:31,040 --> 00:12:36,320
wherever i'm working with these apis

00:12:34,079 --> 00:12:36,320
okay

00:12:37,120 --> 00:12:43,440
can be used so just a few lines

00:12:40,240 --> 00:12:44,959
uh so this is a python client library uh

00:12:43,440 --> 00:12:47,519
that is available uh

00:12:44,959 --> 00:12:49,040
as open source on github and it's a

00:12:47,519 --> 00:12:52,000
wrapper around the api

00:12:49,040 --> 00:12:53,279
so what you have to do is just always

00:12:52,000 --> 00:12:56,320
create a client

00:12:53,279 --> 00:12:58,320
provide a content so an image here

00:12:56,320 --> 00:12:59,760
so i have two pictures called the

00:12:58,320 --> 00:13:02,480
feature you're interested in

00:12:59,760 --> 00:13:04,079
so face detection for instance and then

00:13:02,480 --> 00:13:09,200
you have the results right away

00:13:04,079 --> 00:13:09,200
and you can deal with the results okay

00:13:09,920 --> 00:13:14,000
so we've seen what you can do with

00:13:11,200 --> 00:13:15,760
pictures as of today you can extrapolate

00:13:14,000 --> 00:13:17,440
uh to imagine what you can do with

00:13:15,760 --> 00:13:21,440
videos because videos are

00:13:17,440 --> 00:13:25,120
pictures with a time dimension right

00:13:21,440 --> 00:13:27,920
um so maybe the easiest is to

00:13:25,120 --> 00:13:29,120
show you uh an example if you can

00:13:27,920 --> 00:13:31,760
understand what is

00:13:29,120 --> 00:13:32,639
in a video then it means you can index

00:13:31,760 --> 00:13:34,720
it

00:13:32,639 --> 00:13:36,000
and so this video has gone through the

00:13:34,720 --> 00:13:40,160
video intelligence

00:13:36,000 --> 00:13:43,040
model and i get labels and it tells me

00:13:40,160 --> 00:13:44,160
what what's in the video and where so

00:13:43,040 --> 00:13:48,240
here at the beginning

00:13:44,160 --> 00:13:51,360
i have a spiral galaxy

00:13:48,240 --> 00:13:52,240
the world is made with a bit later i

00:13:51,360 --> 00:13:54,800
have

00:13:52,240 --> 00:13:54,800
humans

00:13:56,160 --> 00:14:03,839
you learn to go and in so doing here i

00:13:58,800 --> 00:14:03,839
have a polar bear

00:14:04,560 --> 00:14:08,160
and then uh you can really understand uh

00:14:06,800 --> 00:14:11,760
what you have

00:14:08,160 --> 00:14:15,120
uh in your data in your input data

00:14:11,760 --> 00:14:18,160
so let's move on uh just one

00:14:15,120 --> 00:14:20,000
code sample so if you're interested to

00:14:18,160 --> 00:14:21,440
to check out how it's done i have

00:14:20,000 --> 00:14:24,240
written a a

00:14:21,440 --> 00:14:24,959
tutorial so it's a code lab here and

00:14:24,240 --> 00:14:27,279
actually

00:14:24,959 --> 00:14:30,079
to generate this or to get this

00:14:27,279 --> 00:14:33,680
information that there is an insect here

00:14:30,079 --> 00:14:35,360
on the vid in a larger video once again

00:14:33,680 --> 00:14:37,360
it's always the same principle you

00:14:35,360 --> 00:14:38,079
create a client you indicate that you're

00:14:37,360 --> 00:14:40,560
interested in

00:14:38,079 --> 00:14:41,600
object tracking and you call annotate

00:14:40,560 --> 00:14:44,639
video

00:14:41,600 --> 00:14:46,000
and then you get the results if your

00:14:44,639 --> 00:14:48,959
video is a couple of

00:14:46,000 --> 00:14:50,000
uh if your video situation is a couple

00:14:48,959 --> 00:14:53,199
minutes

00:14:50,000 --> 00:14:54,320
then after one minute about you will

00:14:53,199 --> 00:14:56,160
have the results

00:14:54,320 --> 00:14:58,560
so it's of course not real time because

00:14:56,160 --> 00:15:00,639
it's a long processing it's a harder

00:14:58,560 --> 00:15:01,600
processing to to read all the frames

00:15:00,639 --> 00:15:04,240
from the video

00:15:01,600 --> 00:15:04,800
and understand what's in it but you can

00:15:04,240 --> 00:15:07,040
actually

00:15:04,800 --> 00:15:08,160
track objects so it's even better than

00:15:07,040 --> 00:15:11,680
on pictures you can

00:15:08,160 --> 00:15:15,120
follow the objects in your videos okay

00:15:11,680 --> 00:15:15,680
so next uh text text so it's a very big

00:15:15,120 --> 00:15:17,600
field

00:15:15,680 --> 00:15:19,600
in computer science it's called nlp

00:15:17,600 --> 00:15:21,839
natural language processing

00:15:19,600 --> 00:15:23,120
i guess we all learned that if we went

00:15:21,839 --> 00:15:26,079
to a computer

00:15:23,120 --> 00:15:27,120
school it's a really big field and

00:15:26,079 --> 00:15:29,279
latest advent

00:15:27,120 --> 00:15:30,320
advancements came from machine learning

00:15:29,279 --> 00:15:33,519
again

00:15:30,320 --> 00:15:34,560
so you provide text and the natural

00:15:33,519 --> 00:15:36,399
language

00:15:34,560 --> 00:15:38,800
model is able to analyze the text and

00:15:36,399 --> 00:15:41,279
give you results so on this sentence

00:15:38,800 --> 00:15:41,920
it will tell me uh first that it's in

00:15:41,279 --> 00:15:45,759
english

00:15:41,920 --> 00:15:48,000
okay it's able to give me the

00:15:45,759 --> 00:15:49,920
precise syntax of the sentence with all

00:15:48,000 --> 00:15:53,120
the different relationships

00:15:49,920 --> 00:15:53,680
uh punctuation is detected lemmas i know

00:15:53,120 --> 00:15:58,560
that

00:15:53,680 --> 00:16:00,480
was relates to the verb to be and so on

00:15:58,560 --> 00:16:02,240
like in pictures it's able to detect

00:16:00,480 --> 00:16:03,920
entities and here i have

00:16:02,240 --> 00:16:05,279
three different classes three different

00:16:03,920 --> 00:16:07,920
types of entities

00:16:05,279 --> 00:16:09,040
in red i have persistence tolkien is a

00:16:07,920 --> 00:16:11,920
person

00:16:09,040 --> 00:16:12,560
and by the way if you notice here i have

00:16:11,920 --> 00:16:16,240
an

00:16:12,560 --> 00:16:19,600
id and it's exactly the same id

00:16:16,240 --> 00:16:23,120
than that for the picture before

00:16:19,600 --> 00:16:27,040
so i can really deal with tolkien here

00:16:23,120 --> 00:16:30,000
on text and on pictures or videos

00:16:27,040 --> 00:16:31,199
and and also one cool thing the natural

00:16:30,000 --> 00:16:34,320
language

00:16:31,199 --> 00:16:37,120
model understands the context so

00:16:34,320 --> 00:16:37,920
here if tolkien was actually not gr

00:16:37,120 --> 00:16:40,560
tolkien

00:16:37,920 --> 00:16:42,000
but christopher tolkien in the song and

00:16:40,560 --> 00:16:44,320
then i will get tolkien

00:16:42,000 --> 00:16:46,160
christopher tolkien uh with a different

00:16:44,320 --> 00:16:47,759
idea of course the unique idea for the

00:16:46,160 --> 00:16:50,880
song

00:16:47,759 --> 00:16:54,320
then british here uh relates to

00:16:50,880 --> 00:16:58,000
the unification and the three books

00:16:54,320 --> 00:17:01,759
here here here are each detected as work

00:16:58,000 --> 00:17:05,280
works of art which is perfectly correct

00:17:01,759 --> 00:17:08,480
okay you can also ask uh

00:17:05,280 --> 00:17:08,799
for classification okay i have a book i

00:17:08,480 --> 00:17:11,360
have

00:17:08,799 --> 00:17:13,199
a chapter i have a paragraph i have a

00:17:11,360 --> 00:17:17,199
sentence you can ask

00:17:13,199 --> 00:17:18,720
um for for content classification and in

00:17:17,199 --> 00:17:19,760
this case tells me that this sentence

00:17:18,720 --> 00:17:22,240
should be classified

00:17:19,760 --> 00:17:23,199
under books and literature with a

00:17:22,240 --> 00:17:27,039
confidence of

00:17:23,199 --> 00:17:30,320
97 percent which is perfect

00:17:27,039 --> 00:17:33,840
and finally like in pictures

00:17:30,320 --> 00:17:36,160
you can try to get a sentiment analysis

00:17:33,840 --> 00:17:38,160
try to understand whether we're talking

00:17:36,160 --> 00:17:41,039
positively or negatively

00:17:38,160 --> 00:17:41,919
uh in the text you provide so to try

00:17:41,039 --> 00:17:46,080
that out

00:17:41,919 --> 00:17:50,240
what i did is i i retrieved um

00:17:46,080 --> 00:17:52,559
two um two articles two reviews

00:17:50,240 --> 00:17:53,760
uh about the hobbit one from the new

00:17:52,559 --> 00:17:56,559
york times uh

00:17:53,760 --> 00:17:59,120
last centuries last the last century and

00:17:56,559 --> 00:18:00,720
one from goodreads it's a social bootnet

00:17:59,120 --> 00:18:02,400
the first one is very positive the

00:18:00,720 --> 00:18:05,919
second one as you can tell

00:18:02,400 --> 00:18:08,720
is very negative and the results are

00:18:05,919 --> 00:18:10,160
i i get are for instance for each

00:18:08,720 --> 00:18:12,720
sentence i get a score

00:18:10,160 --> 00:18:14,559
between minus one and plus one and it

00:18:12,720 --> 00:18:16,960
does work these sentences

00:18:14,559 --> 00:18:18,160
come from the new york times this one

00:18:16,960 --> 00:18:19,840
too it's a neutral one

00:18:18,160 --> 00:18:21,200
most of the sentences of course are

00:18:19,840 --> 00:18:24,240
neutral

00:18:21,200 --> 00:18:25,360
uh the these sentences come from

00:18:24,240 --> 00:18:28,400
pauline's review who

00:18:25,360 --> 00:18:30,559
really hated the book so some companies

00:18:28,400 --> 00:18:33,440
for instance are using that to

00:18:30,559 --> 00:18:34,960
understand how people our users are

00:18:33,440 --> 00:18:38,000
talking about their products

00:18:34,960 --> 00:18:39,840
on twitter or on the web and so on so

00:18:38,000 --> 00:18:41,039
they are actually parsing retrieving

00:18:39,840 --> 00:18:44,160
content

00:18:41,039 --> 00:18:46,080
and using the natural language sentiment

00:18:44,160 --> 00:18:48,400
analysis for that

00:18:46,080 --> 00:18:49,919
uh sorry uh some companies are using

00:18:48,400 --> 00:18:52,000
that on emails

00:18:49,919 --> 00:18:53,360
uh on all the emails they receive to

00:18:52,000 --> 00:18:56,400
understand how

00:18:53,360 --> 00:18:56,880
happy or unhappy their customers are can

00:18:56,400 --> 00:19:00,799
be

00:18:56,880 --> 00:19:02,880
pretty useful again to use that uh

00:19:00,799 --> 00:19:04,559
in python you create a client you

00:19:02,880 --> 00:19:07,919
provide a content a document

00:19:04,559 --> 00:19:10,480
it can be text or html and

00:19:07,919 --> 00:19:11,440
you call analyze sentiment and then you

00:19:10,480 --> 00:19:14,960
have the result

00:19:11,440 --> 00:19:18,160
very very quickly okay

00:19:14,960 --> 00:19:18,720
in the same vein uh translation so i

00:19:18,160 --> 00:19:20,960
won't

00:19:18,720 --> 00:19:21,919
get into detail so i can share something

00:19:20,960 --> 00:19:25,520
with you so

00:19:21,919 --> 00:19:27,840
in 2016 i was still working

00:19:25,520 --> 00:19:28,799
on ebooks and i was using google

00:19:27,840 --> 00:19:32,000
translate

00:19:28,799 --> 00:19:35,360
and someday something happened

00:19:32,000 --> 00:19:37,440
the results were a lot better and what

00:19:35,360 --> 00:19:39,679
happened actually i got the answer since

00:19:37,440 --> 00:19:43,200
then is that

00:19:39,679 --> 00:19:46,240
historically google translate was using

00:19:43,200 --> 00:19:49,360
a machine learning a phrase based

00:19:46,240 --> 00:19:53,120
uh sorry model uh so

00:19:49,360 --> 00:19:56,240
mostly a statistical a statistical model

00:19:53,120 --> 00:19:58,880
and in 2016 google translate switched to

00:19:56,240 --> 00:19:59,360
a pure machine learning model and this

00:19:58,880 --> 00:20:02,080
is

00:19:59,360 --> 00:20:03,280
why at the time and since then it just

00:20:02,080 --> 00:20:06,240
kept improving

00:20:03,280 --> 00:20:08,480
we suddenly got got a big bump uh in

00:20:06,240 --> 00:20:11,280
quality

00:20:08,480 --> 00:20:12,400
okay uh so here i just need two lines to

00:20:11,280 --> 00:20:14,480
use to use it

00:20:12,400 --> 00:20:16,159
i create a client i call translate and i

00:20:14,480 --> 00:20:19,520
have a translation right away

00:20:16,159 --> 00:20:20,559
it works from and to over one 100

00:20:19,520 --> 00:20:23,200
languages

00:20:20,559 --> 00:20:25,760
so that's thousands of different

00:20:23,200 --> 00:20:28,400
combinations

00:20:25,760 --> 00:20:29,679
and finally regarding machine learning

00:20:28,400 --> 00:20:32,960
apis speech

00:20:29,679 --> 00:20:35,200
speech so speech as an input you talk

00:20:32,960 --> 00:20:37,280
and you get you get your speech

00:20:35,200 --> 00:20:39,600
transcribed into text

00:20:37,280 --> 00:20:40,720
so this is also a problem that is now

00:20:39,600 --> 00:20:43,039
solved thanks

00:20:40,720 --> 00:20:44,320
to machine learning if you're able to

00:20:43,039 --> 00:20:47,120
understand

00:20:44,320 --> 00:20:48,000
the speech that is in your data then it

00:20:47,120 --> 00:20:50,640
means you can index

00:20:48,000 --> 00:20:52,720
it so for instance if i have a new audio

00:20:50,640 --> 00:20:57,440
file then i can get the position of

00:20:52,720 --> 00:21:00,799
every word uh in all my sentences

00:20:57,440 --> 00:21:01,520
and to use it also very easy you create

00:21:00,799 --> 00:21:04,799
a client

00:21:01,520 --> 00:21:07,039
you call recognize uh sorry

00:21:04,799 --> 00:21:08,000
yeah you call recognize and and then you

00:21:07,039 --> 00:21:10,799
have the text

00:21:08,000 --> 00:21:11,600
uh coming from your audio so this is

00:21:10,799 --> 00:21:13,919
again

00:21:11,600 --> 00:21:14,799
another tutorial i've written uh you

00:21:13,919 --> 00:21:17,360
will find all

00:21:14,799 --> 00:21:18,880
all the slides uh they are public um so

00:21:17,360 --> 00:21:20,640
you will get the link at the end it's

00:21:18,880 --> 00:21:22,799
also on my on my profile

00:21:20,640 --> 00:21:24,960
on your python if you want to try that

00:21:22,799 --> 00:21:26,480
so what i tried in in this one i

00:21:24,960 --> 00:21:30,000
recorded myself

00:21:26,480 --> 00:21:32,480
uh speaking uh french poetry allowed

00:21:30,000 --> 00:21:33,520
a very famous one from la fontaine and

00:21:32,480 --> 00:21:36,799
just asked

00:21:33,520 --> 00:21:39,440
for uh so i'm helping here a little bit

00:21:36,799 --> 00:21:40,880
telling that i know beforehand that it's

00:21:39,440 --> 00:21:43,840
french

00:21:40,880 --> 00:21:45,919
asking for automatic punctuation so this

00:21:43,840 --> 00:21:46,720
is the new feature that is very very

00:21:45,919 --> 00:21:48,320
important

00:21:46,720 --> 00:21:50,080
uh it will give you the caps it will

00:21:48,320 --> 00:21:52,799
give you commas and so on

00:21:50,080 --> 00:21:53,679
uh and here i'm also asking for the word

00:21:52,799 --> 00:21:57,520
time offsets

00:21:53,679 --> 00:22:01,679
so so that i can index uh my

00:21:57,520 --> 00:22:05,360
my different words okay now the opposite

00:22:01,679 --> 00:22:09,039
text to speech you provide text and then

00:22:05,360 --> 00:22:09,919
you get a speech out of that uh 20 years

00:22:09,039 --> 00:22:12,960
ago

00:22:09,919 --> 00:22:15,120
i used a text-to-speech engine in the

00:22:12,960 --> 00:22:18,400
first european ebook reader we made

00:22:15,120 --> 00:22:21,919
it was a big failure so i i i did work

00:22:18,400 --> 00:22:23,600
uh quite a few uh weeks on it i was very

00:22:21,919 --> 00:22:25,679
proud of the result but

00:22:23,600 --> 00:22:26,799
the result at the time was that you

00:22:25,679 --> 00:22:29,679
pressed

00:22:26,799 --> 00:22:30,640
the play a button to get the book to be

00:22:29,679 --> 00:22:34,159
read aloud

00:22:30,640 --> 00:22:34,880
and the result you got was at least in

00:22:34,159 --> 00:22:37,840
wonderland

00:22:34,880 --> 00:22:40,080
and so on i am a robot talking to you so

00:22:37,840 --> 00:22:42,320
now this is finished this is also a

00:22:40,080 --> 00:22:43,600
solve problem thanks to machine learning

00:22:42,320 --> 00:22:45,360
uh at google this

00:22:43,600 --> 00:22:46,880
is coming from a technology called

00:22:45,360 --> 00:22:48,640
wavenet it's uh

00:22:46,880 --> 00:22:50,240
it's been developed by deepmind maybe

00:22:48,640 --> 00:22:52,559
you know deepmind because they

00:22:50,240 --> 00:22:53,360
they've beaten uh the the go world

00:22:52,559 --> 00:22:57,120
champion

00:22:53,360 --> 00:23:00,000
more recently they are beating gamers

00:22:57,120 --> 00:23:01,039
young people who are champions at

00:23:00,000 --> 00:23:04,799
starcraft

00:23:01,039 --> 00:23:07,679
so deepmind is trying to solve problem

00:23:04,799 --> 00:23:08,559
by starting from scratch and building

00:23:07,679 --> 00:23:11,520
from scratch

00:23:08,559 --> 00:23:12,480
machine learning model and here it's

00:23:11,520 --> 00:23:16,559
really

00:23:12,480 --> 00:23:19,600
amazing let me let me get to you to hear

00:23:16,559 --> 00:23:20,240
these examples so one is the original

00:23:19,600 --> 00:23:23,600
recording

00:23:20,240 --> 00:23:26,960
and the other one is actually the

00:23:23,600 --> 00:23:29,360
the speech synthesized with the same

00:23:26,960 --> 00:23:29,360
sentence

00:23:30,400 --> 00:23:35,440
she earned a doctorate in sociology at

00:23:32,240 --> 00:23:37,360
columbia university

00:23:35,440 --> 00:23:39,120
she earned a doctorate in sociology at

00:23:37,360 --> 00:23:41,520
columbia university

00:23:39,120 --> 00:23:43,440
to tell the difference uh so if you want

00:23:41,520 --> 00:23:46,880
to know this one

00:23:43,440 --> 00:23:47,840
uh the one on the right is the original

00:23:46,880 --> 00:23:50,880
recording

00:23:47,840 --> 00:23:51,840
i try to listen to them very loud and so

00:23:50,880 --> 00:23:55,520
on

00:23:51,840 --> 00:23:58,880
it is a very very natural

00:23:55,520 --> 00:24:01,919
result maybe it's the best model so far

00:23:58,880 --> 00:24:03,120
from everything i've shown to you i have

00:24:01,919 --> 00:24:05,600
to admit

00:24:03,120 --> 00:24:07,279
even though i love the vision model

00:24:05,600 --> 00:24:09,919
because it's solving a problem

00:24:07,279 --> 00:24:10,720
i was trying to solve this one uh is

00:24:09,919 --> 00:24:13,039
honestly a

00:24:10,720 --> 00:24:13,840
really uh amazing because it's hard to

00:24:13,039 --> 00:24:16,640
tell the difference

00:24:13,840 --> 00:24:17,679
this is wavenet is are the voices you

00:24:16,640 --> 00:24:21,200
can hear

00:24:17,679 --> 00:24:25,039
in google homes in google assistants

00:24:21,200 --> 00:24:28,000
and let's uh by the way try something

00:24:25,039 --> 00:24:28,000
all together okay

00:24:30,400 --> 00:24:36,559
so i don't know if you noticed but on um

00:24:34,480 --> 00:24:37,600
on google search you can actually do a

00:24:36,559 --> 00:24:41,919
search

00:24:37,600 --> 00:24:41,919
with your voice so let's try that out

00:24:42,000 --> 00:24:47,840
what is the temperature in paris

00:24:49,760 --> 00:24:55,279
it's 27 degrees in paris right now it's

00:24:52,640 --> 00:24:58,320
giving you results in real time

00:24:55,279 --> 00:24:59,840
um even though it might be wrong at some

00:24:58,320 --> 00:25:01,039
time when i started to pronounce

00:24:59,840 --> 00:25:05,120
temperature

00:25:01,039 --> 00:25:07,279
uh i'm on purpose i use my french accent

00:25:05,120 --> 00:25:09,600
and it's been able to understand me so

00:25:07,279 --> 00:25:13,279
let's try something else

00:25:09,600 --> 00:25:15,840
now i'm going to go to to the french

00:25:13,279 --> 00:25:15,840
version

00:25:25,200 --> 00:25:29,840
let me try again i didn't

00:25:35,679 --> 00:25:41,039
oh i know i forgot i i told you

00:25:38,799 --> 00:25:43,279
i know what i did wrong i told you i'm

00:25:41,039 --> 00:25:43,760
going to go on the french website but

00:25:43,279 --> 00:25:47,520
i'm

00:25:43,760 --> 00:25:50,320
actually still on the english one

00:25:47,520 --> 00:25:57,840
so here now i switch to the french one

00:25:50,320 --> 00:25:57,840
sorry about that

00:26:26,320 --> 00:26:29,919
so i am asking a french a christian in

00:26:28,960 --> 00:26:33,039
french

00:26:29,919 --> 00:26:35,760
but with an english accent

00:26:33,039 --> 00:26:37,919
and uh so i messed up a little bit

00:26:35,760 --> 00:26:38,720
because i started to speak at the wrong

00:26:37,919 --> 00:26:41,919
time

00:26:38,720 --> 00:26:43,440
but uh what you could see uh

00:26:41,919 --> 00:26:45,600
is that you're getting results in real

00:26:43,440 --> 00:26:47,919
time and you are getting the the

00:26:45,600 --> 00:26:48,480
expected result it's able to understand

00:26:47,919 --> 00:26:51,840
me

00:26:48,480 --> 00:26:52,320
uh even though i'm really uh making it

00:26:51,840 --> 00:26:54,880
hard

00:26:52,320 --> 00:26:55,840
to to be understood uh so what does it

00:26:54,880 --> 00:27:00,159
mean it means that

00:26:55,840 --> 00:27:02,000
um the the the speech to text engine has

00:27:00,159 --> 00:27:04,159
understood has been trained and has

00:27:02,000 --> 00:27:07,760
understood how to

00:27:04,159 --> 00:27:10,159
uh make um us understood the essence

00:27:07,760 --> 00:27:12,559
of our language and uh and as understood

00:27:10,159 --> 00:27:15,679
the characteristic the specifics

00:27:12,559 --> 00:27:19,520
of a speech to be able to understand

00:27:15,679 --> 00:27:22,720
the different words okay so we've seen

00:27:19,520 --> 00:27:24,320
everything you can do uh with existing

00:27:22,720 --> 00:27:27,039
models or there are of course

00:27:24,320 --> 00:27:28,320
more features uh many options uh it

00:27:27,039 --> 00:27:30,480
would take a day to

00:27:28,320 --> 00:27:32,399
cover them all uh if you want to

00:27:30,480 --> 00:27:33,200
generate text again i've made uh this

00:27:32,399 --> 00:27:36,159
tutorial

00:27:33,200 --> 00:27:36,799
uh to generate so it does take this to

00:27:36,159 --> 00:27:39,200
generate

00:27:36,799 --> 00:27:40,080
these three sentences in three different

00:27:39,200 --> 00:27:42,480
languages

00:27:40,080 --> 00:27:43,679
what you need to do is to create a

00:27:42,480 --> 00:27:46,880
client again

00:27:43,679 --> 00:27:48,720
you need to call synthesized speech

00:27:46,880 --> 00:27:50,880
and you need to provide some uh

00:27:48,720 --> 00:27:54,080
parameters like the language

00:27:50,880 --> 00:27:56,399
uh your you you want to generate that

00:27:54,080 --> 00:27:57,520
uh the name of the voice so there are

00:27:56,399 --> 00:28:00,559
different uh

00:27:57,520 --> 00:28:03,360
wavenet voices if you want a human uh

00:28:00,559 --> 00:28:04,240
human-like sounding voice and you have

00:28:03,360 --> 00:28:07,120
different uh

00:28:04,240 --> 00:28:07,840
options so here i was only this i can

00:28:07,120 --> 00:28:11,279
generate

00:28:07,840 --> 00:28:13,039
three uh wav files uh you can you can

00:28:11,279 --> 00:28:16,720
try that in this tutorial

00:28:13,039 --> 00:28:19,679
okay so next a big gap uh

00:28:16,720 --> 00:28:21,200
that is filling many many needs automl

00:28:19,679 --> 00:28:23,679
techniques

00:28:21,200 --> 00:28:25,200
so let me uh show you this example you

00:28:23,679 --> 00:28:28,480
will understand better

00:28:25,200 --> 00:28:30,320
if i take these two pictures which are

00:28:28,480 --> 00:28:32,320
different right and

00:28:30,320 --> 00:28:34,559
give them to the vision model it will

00:28:32,320 --> 00:28:37,760
give me almost the same results

00:28:34,559 --> 00:28:38,480
sky cloud sky cloud because those

00:28:37,760 --> 00:28:42,159
pictures

00:28:38,480 --> 00:28:45,520
are actually clouds in the sky

00:28:42,159 --> 00:28:48,240
but if i want to build um a forecasting

00:28:45,520 --> 00:28:49,520
uh service for instance to i need to be

00:28:48,240 --> 00:28:52,320
able to understand

00:28:49,520 --> 00:28:53,760
the shape of the clouds i need to know

00:28:52,320 --> 00:28:56,799
that it's a cyrus here

00:28:53,760 --> 00:28:58,000
and and i'll talk about sphere and then

00:28:56,799 --> 00:29:00,960
i'm stuck because the only

00:28:58,000 --> 00:29:03,200
info i have is that it's a cloud it's a

00:29:00,960 --> 00:29:06,080
cloud in the sky

00:29:03,200 --> 00:29:06,640
so auto email here can help you still

00:29:06,080 --> 00:29:10,320
without

00:29:06,640 --> 00:29:10,320
any expertise in machine learning

00:29:10,640 --> 00:29:15,279
so the difference compared to the api

00:29:13,520 --> 00:29:17,120
the api is that you need

00:29:15,279 --> 00:29:18,720
to work a little bit more you need to

00:29:17,120 --> 00:29:21,120
build you need to provide

00:29:18,720 --> 00:29:22,960
your own data set you need to provide

00:29:21,120 --> 00:29:26,159
training data you need to

00:29:22,960 --> 00:29:29,360
look for examples and and give that

00:29:26,159 --> 00:29:30,240
to the auto email pipeline once you have

00:29:29,360 --> 00:29:33,520
the data set

00:29:30,240 --> 00:29:36,559
you can launch a training uh it's fully

00:29:33,520 --> 00:29:38,000
automated and generally you will need a

00:29:36,559 --> 00:29:40,399
couple of iterations

00:29:38,000 --> 00:29:41,840
to understand how well your data set is

00:29:40,399 --> 00:29:44,240
doing

00:29:41,840 --> 00:29:45,440
and then once you're happy uh you can

00:29:44,240 --> 00:29:46,880
deploy and serve

00:29:45,440 --> 00:29:48,720
and then you'll come back to the

00:29:46,880 --> 00:29:51,679
previous case where you have

00:29:48,720 --> 00:29:53,200
your own this time your own private api

00:29:51,679 --> 00:29:54,320
that you can use in all of your

00:29:53,200 --> 00:29:57,440
solutions

00:29:54,320 --> 00:29:57,840
so it's still work online here if you

00:29:57,440 --> 00:30:00,320
want

00:29:57,840 --> 00:30:01,360
something that can work offline then you

00:30:00,320 --> 00:30:04,480
can try

00:30:01,360 --> 00:30:05,200
you can train a model that we call an

00:30:04,480 --> 00:30:07,679
edge model

00:30:05,200 --> 00:30:08,640
because you will be able to deploy it on

00:30:07,679 --> 00:30:12,080
the edge

00:30:08,640 --> 00:30:14,799
somewhere else so it's a smaller model

00:30:12,080 --> 00:30:15,200
uh not as efficient as the cloud model

00:30:14,799 --> 00:30:18,480
but

00:30:15,200 --> 00:30:21,360
maybe it will uh it can it can work um

00:30:18,480 --> 00:30:22,559
and fulfill your needs so once you have

00:30:21,360 --> 00:30:24,640
trained your edge model

00:30:22,559 --> 00:30:26,559
you can export it and you can get it to

00:30:24,640 --> 00:30:28,960
run in a container

00:30:26,559 --> 00:30:30,080
you can get it to run on your smartphone

00:30:28,960 --> 00:30:33,200
or even

00:30:30,080 --> 00:30:36,240
in a web browser with tensorflow.js

00:30:33,200 --> 00:30:38,720
okay uh so it's very uh

00:30:36,240 --> 00:30:39,440
useful for instance because uh in

00:30:38,720 --> 00:30:42,559
factories

00:30:39,440 --> 00:30:45,679
on projection lines for many reasons

00:30:42,559 --> 00:30:48,960
uh very often you don't have

00:30:45,679 --> 00:30:50,399
um you have internet connectivity or you

00:30:48,960 --> 00:30:52,640
don't want you to to

00:30:50,399 --> 00:30:53,760
have it so you need something that works

00:30:52,640 --> 00:30:57,120
offline

00:30:53,760 --> 00:30:59,360
um even for web browser solutions

00:30:57,120 --> 00:31:00,480
of course you can you need to download

00:30:59,360 --> 00:31:02,559
the mobile first

00:31:00,480 --> 00:31:04,000
but then you can work offline and have

00:31:02,559 --> 00:31:07,440
something that works in your

00:31:04,000 --> 00:31:11,200
browser tab um with a local model

00:31:07,440 --> 00:31:12,080
okay so once um you have built your data

00:31:11,200 --> 00:31:13,600
set so here

00:31:12,080 --> 00:31:15,919
if i want to make a difference i need to

00:31:13,600 --> 00:31:18,159
label them so i have a camera scrimmage

00:31:15,919 --> 00:31:20,399
cable numbers and so on so you label

00:31:18,159 --> 00:31:22,240
your pictures here it's a classification

00:31:20,399 --> 00:31:24,399
problem you want to make the difference

00:31:22,240 --> 00:31:26,320
between different pictures you don't

00:31:24,399 --> 00:31:29,519
need millions of pictures

00:31:26,320 --> 00:31:32,559
like for the big machine learning

00:31:29,519 --> 00:31:35,279
models we've seen before here you just

00:31:32,559 --> 00:31:36,480
need a couple of hundreds of pictures

00:31:35,279 --> 00:31:39,200
per label

00:31:36,480 --> 00:31:41,919
ideally 1000 but with just a couple of

00:31:39,200 --> 00:31:44,080
androids it starts to work really great

00:31:41,919 --> 00:31:45,360
and once you have done your data set you

00:31:44,080 --> 00:31:47,760
can launch a training

00:31:45,360 --> 00:31:48,480
so here this is a one compute hour

00:31:47,760 --> 00:31:50,559
training

00:31:48,480 --> 00:31:52,080
there are three computer training and

00:31:50,559 --> 00:31:55,519
then you get a sense

00:31:52,080 --> 00:31:57,360
of how well it is doing because

00:31:55,519 --> 00:31:59,279
your data set eighty percent of your

00:31:57,360 --> 00:32:01,840
data set is used for training

00:31:59,279 --> 00:32:02,880
ten percent to evaluate uh the best

00:32:01,840 --> 00:32:05,840
architecture

00:32:02,880 --> 00:32:08,159
and the final ten percent ten percent uh

00:32:05,840 --> 00:32:10,960
final the other ten percent are used

00:32:08,159 --> 00:32:11,760
to evaluate how well uh it is it is

00:32:10,960 --> 00:32:15,360
doing

00:32:11,760 --> 00:32:17,679
okay uh you for classification you can

00:32:15,360 --> 00:32:19,360
use the confusion matrix to have an idea

00:32:17,679 --> 00:32:21,279
about how well it is doing

00:32:19,360 --> 00:32:23,679
so here for instance it's doing great

00:32:21,279 --> 00:32:26,000
with cumulative numbers and cumulatives

00:32:23,679 --> 00:32:27,200
uh but doing really bad with the

00:32:26,000 --> 00:32:30,399
altochambers

00:32:27,200 --> 00:32:33,279
uh almost 50 percent of the time

00:32:30,399 --> 00:32:34,399
it is uh confusing it with something

00:32:33,279 --> 00:32:36,799
something else

00:32:34,399 --> 00:32:37,600
so the reason uh there are there are two

00:32:36,799 --> 00:32:40,840
reasons here

00:32:37,600 --> 00:32:42,159
is first we have less samples of

00:32:40,840 --> 00:32:46,080
altocumuluses

00:32:42,159 --> 00:32:50,559
and second they all look alike

00:32:46,080 --> 00:32:54,000
so making data set is going to be

00:32:50,559 --> 00:32:54,720
an art i think you really need to

00:32:54,000 --> 00:32:58,559
understand

00:32:54,720 --> 00:32:59,360
that you want to build a balanced data

00:32:58,559 --> 00:33:02,159
set

00:32:59,360 --> 00:33:02,799
and you want to try to remove as much as

00:33:02,159 --> 00:33:05,679
possible

00:33:02,799 --> 00:33:06,399
the bias that could be in your dataset

00:33:05,679 --> 00:33:08,320
because

00:33:06,399 --> 00:33:10,399
you're going you're going to to get

00:33:08,320 --> 00:33:11,840
projects 10 minutes left to get results

00:33:10,399 --> 00:33:14,559
out of the model

00:33:11,840 --> 00:33:16,799
and and if you if you interpret the

00:33:14,559 --> 00:33:20,720
result as a causality

00:33:16,799 --> 00:33:21,200
uh actually uh it may not be causality

00:33:20,720 --> 00:33:23,279
and and

00:33:21,200 --> 00:33:25,039
this is the the issue that we can have

00:33:23,279 --> 00:33:28,240
with the bias

00:33:25,039 --> 00:33:29,919
okay uh so it should

00:33:28,240 --> 00:33:32,080
could be something interesting

00:33:29,919 --> 00:33:34,799
interesting for

00:33:32,080 --> 00:33:36,799
another talk once you have trained your

00:33:34,799 --> 00:33:40,080
model then you can use it

00:33:36,799 --> 00:33:42,159
in an api you can provide it uh

00:33:40,080 --> 00:33:44,240
with new pictures it has never seen

00:33:42,159 --> 00:33:45,120
before so here this is my own private

00:33:44,240 --> 00:33:48,240
picture

00:33:45,120 --> 00:33:49,120
uh i was in poland that day and it's

00:33:48,240 --> 00:33:52,960
telling me that

00:33:49,120 --> 00:33:56,320
there's a camelot in this picture at 97

00:33:52,960 --> 00:34:00,640
percent really great okay

00:33:56,320 --> 00:34:03,840
so if you remember my definition um

00:34:00,640 --> 00:34:06,640
we need we have data and we want uh

00:34:03,840 --> 00:34:08,000
information so autoimmune techniques as

00:34:06,640 --> 00:34:10,960
of today work

00:34:08,000 --> 00:34:13,839
already on text pictures videos and also

00:34:10,960 --> 00:34:13,839
structured data

00:34:13,919 --> 00:34:21,760
and this time you need to choose

00:34:18,240 --> 00:34:24,879
the features that you want to um to

00:34:21,760 --> 00:34:25,520
to detect so for instance uh you want to

00:34:24,879 --> 00:34:28,000
do

00:34:25,520 --> 00:34:29,520
custom classification maybe you want to

00:34:28,000 --> 00:34:32,079
detect custom objects

00:34:29,520 --> 00:34:33,919
in your pictures uh on videos as of

00:34:32,079 --> 00:34:34,480
today you can do custom classification

00:34:33,919 --> 00:34:36,960
uh

00:34:34,480 --> 00:34:37,679
there are beta features also for custom

00:34:36,960 --> 00:34:40,560
object tracking

00:34:37,679 --> 00:34:41,839
and so on you can build your own models

00:34:40,560 --> 00:34:44,480
on text

00:34:41,839 --> 00:34:46,480
with custom natural language features

00:34:44,480 --> 00:34:48,000
you can do your own custom translation

00:34:46,480 --> 00:34:51,359
and you can do

00:34:48,000 --> 00:34:54,879
custom productions on the

00:34:51,359 --> 00:34:57,040
so it's the new field uh i i would say

00:34:54,879 --> 00:34:58,320
since two years now uh it's just the

00:34:57,040 --> 00:35:00,320
beginning but it's going

00:34:58,320 --> 00:35:02,240
going to be very useful because you

00:35:00,320 --> 00:35:05,280
don't need any expertise to build them

00:35:02,240 --> 00:35:05,839
up so i've done a demo uh that we are

00:35:05,280 --> 00:35:08,079
going to

00:35:05,839 --> 00:35:09,920
be able to try all live if you are on

00:35:08,079 --> 00:35:12,880
youtube there is a delay

00:35:09,920 --> 00:35:13,599
so maybe when you hear that uh it will

00:35:12,880 --> 00:35:15,359
be too late

00:35:13,599 --> 00:35:18,240
and and i don't i don't know how much

00:35:15,359 --> 00:35:20,320
the the delay is on on youtube like

00:35:18,240 --> 00:35:22,079
so uh what i've done is a small demo

00:35:20,320 --> 00:35:23,440
where you're going to be able to upload

00:35:22,079 --> 00:35:26,560
selfies

00:35:23,440 --> 00:35:29,520
and um in the first part i'm going to

00:35:26,560 --> 00:35:30,000
to call the vision api and try to detect

00:35:29,520 --> 00:35:32,480
generic

00:35:30,000 --> 00:35:33,760
emotions but i also i'd like to know i

00:35:32,480 --> 00:35:35,680
don't see you i don't

00:35:33,760 --> 00:35:37,359
i'd like to know if someone is sleeping

00:35:35,680 --> 00:35:40,160
someone is yawning or

00:35:37,359 --> 00:35:41,839
someone is having fun so i've built with

00:35:40,160 --> 00:35:44,079
my teammates and with uh

00:35:41,839 --> 00:35:45,040
attendees from previous conferences i've

00:35:44,079 --> 00:35:49,280
been my own

00:35:45,040 --> 00:35:53,040
private custom model that is able to

00:35:49,280 --> 00:35:56,079
i hope able to detect automatically

00:35:53,040 --> 00:35:58,800
these situations okay

00:35:56,079 --> 00:35:59,440
the way it works is the following so

00:35:58,800 --> 00:36:00,800
from your

00:35:59,440 --> 00:36:02,720
smartphone you're going to be able to

00:36:00,800 --> 00:36:04,800
upload a selfie it will automatically

00:36:02,720 --> 00:36:07,839
trigger a python function

00:36:04,800 --> 00:36:08,320
which we'll call the vision api and

00:36:07,839 --> 00:36:11,200
maybe

00:36:08,320 --> 00:36:12,640
the auto email vision my own api if

00:36:11,200 --> 00:36:14,720
needed

00:36:12,640 --> 00:36:16,640
and then we'll do something here thanks

00:36:14,720 --> 00:36:17,280
to the analysis we'll store the result

00:36:16,640 --> 00:36:20,240
here

00:36:17,280 --> 00:36:22,079
and you will see it on your smartphone

00:36:20,240 --> 00:36:24,160
here this is a serverless

00:36:22,079 --> 00:36:26,480
a small application it's actually my

00:36:24,160 --> 00:36:28,560
administration backend for the demo

00:36:26,480 --> 00:36:29,599
and here on the screen you will see the

00:36:28,560 --> 00:36:33,520
result

00:36:29,599 --> 00:36:37,040
uh from the administration planner okay

00:36:33,520 --> 00:36:37,839
so let's try that out so i invite you to

00:36:37,040 --> 00:36:41,359
open

00:36:37,839 --> 00:36:44,400
uh the

00:36:41,359 --> 00:36:47,839
the camera on your smartphone okay it's

00:36:44,400 --> 00:36:47,839
starting sorry for the delay

00:36:50,880 --> 00:36:56,240
okay so you can uh either flash the qr

00:36:54,000 --> 00:36:57,839
code here or you can enter in your

00:36:56,240 --> 00:37:01,119
browser this url

00:36:57,839 --> 00:37:04,640
bitly slash smart ep 20

00:37:01,119 --> 00:37:08,000
bit dot loi slash

00:37:04,640 --> 00:37:11,440
smart ep for your python 20 smart

00:37:08,000 --> 00:37:14,560
ep 20. okay

00:37:11,440 --> 00:37:17,440
so let if you if you go there you will

00:37:14,560 --> 00:37:21,040
reach this page

00:37:17,440 --> 00:37:22,160
and i'm going to still have about five

00:37:21,040 --> 00:37:25,760
minutes

00:37:22,160 --> 00:37:29,200
i'm going to go to step one okay bit.ly

00:37:25,760 --> 00:37:32,480
slash smart ep 20.

00:37:29,200 --> 00:37:33,680
so it will ask you for authorization to

00:37:32,480 --> 00:37:36,960
use

00:37:33,680 --> 00:37:40,000
uh your webcam so

00:37:36,960 --> 00:37:40,560
here this is the the generic vision

00:37:40,000 --> 00:37:44,000
model

00:37:40,560 --> 00:37:46,160
that is going to be used you can try to

00:37:44,000 --> 00:37:49,280
upload a selfie and try to trigger a

00:37:46,160 --> 00:37:52,079
detection for one of these emotions

00:37:49,280 --> 00:37:52,079
so let's try that

00:37:56,880 --> 00:38:02,240
yeah my my network must be a bit slow

00:37:59,760 --> 00:38:02,240
i'm sorry

00:38:02,400 --> 00:38:05,839
seems to be okay

00:38:07,520 --> 00:38:11,520
but it's in the cloud so maybe you'll

00:38:10,079 --> 00:38:19,359
get faster results

00:38:11,520 --> 00:38:20,960
on your site

00:38:19,359 --> 00:38:23,839
i have no feedback so i don't know if

00:38:20,960 --> 00:38:23,839
it's working for you

00:38:29,280 --> 00:38:35,200
oops i should have gotten the results

00:38:32,720 --> 00:38:35,200
already

00:38:38,000 --> 00:38:41,920
uh maybe i forgot to pray the demo gods

00:38:40,480 --> 00:38:46,400
before

00:38:41,920 --> 00:38:49,760
maybe that's why okay so

00:38:46,400 --> 00:38:50,320
let me try again sorry about it i hope

00:38:49,760 --> 00:39:01,520
it works

00:38:50,320 --> 00:39:04,800
on your side

00:39:01,520 --> 00:39:07,920
okay so i had an issue before uh

00:39:04,800 --> 00:39:10,640
yeah so it does detect surprise with

00:39:07,920 --> 00:39:12,320
a high level of confidence let's try

00:39:10,640 --> 00:39:14,880
another one

00:39:12,320 --> 00:39:16,960
and maybe you've seen i as i have the

00:39:14,880 --> 00:39:19,359
position of the nose the mouse

00:39:16,960 --> 00:39:21,680
uh the eyes everything i could i can

00:39:19,359 --> 00:39:25,280
actually add a mustache to everyone

00:39:21,680 --> 00:39:25,280
uh so let's try this last one

00:39:27,359 --> 00:39:35,440
okay joy with tight confidence

00:39:31,920 --> 00:39:37,359
okay um let's now switch

00:39:35,440 --> 00:39:39,680
you can try a few times if you want

00:39:37,359 --> 00:39:42,480
let's switch to the automl part so

00:39:39,680 --> 00:39:43,760
here if you refresh the page or if you

00:39:42,480 --> 00:39:46,480
click next

00:39:43,760 --> 00:39:46,880
you should be on the same one but with

00:39:46,480 --> 00:39:50,560
my

00:39:46,880 --> 00:39:53,440
own private model and this time try to

00:39:50,560 --> 00:39:53,839
uh to trigger uh try to stick out your

00:39:53,440 --> 00:39:57,839
tone

00:39:53,839 --> 00:39:57,839
to yawn or to sleep okay

00:40:01,520 --> 00:40:05,440
okay it found that i'm yawning let's try

00:40:04,160 --> 00:40:07,760
another one

00:40:05,440 --> 00:40:10,560
this time to make the difference between

00:40:07,760 --> 00:40:14,640
the generic api and my auto ml

00:40:10,560 --> 00:40:18,800
api the mustache will have the french

00:40:14,640 --> 00:40:18,800
flag colors let's try it

00:40:22,480 --> 00:40:27,599
yeah it does work so uh you could

00:40:25,520 --> 00:40:29,280
you could tell that i'm cheating and i'm

00:40:27,599 --> 00:40:32,319
actually cheating because

00:40:29,280 --> 00:40:35,280
i built this model with pictures of me

00:40:32,319 --> 00:40:36,960
pictures of my teammate and uh of other

00:40:35,280 --> 00:40:39,680
previous attendees

00:40:36,960 --> 00:40:40,640
so of course uh it's normal that it

00:40:39,680 --> 00:40:43,119
works

00:40:40,640 --> 00:40:43,680
but we are going to check whether it

00:40:43,119 --> 00:40:48,319
works

00:40:43,680 --> 00:40:48,319
for you to wow wow many people so

00:40:49,760 --> 00:40:54,160
okay so happy people so that was with

00:40:52,400 --> 00:40:58,400
the generic api

00:40:54,160 --> 00:40:58,400
still surprise people so that's me

00:40:59,280 --> 00:41:03,920
uh here here maybe it wasn't surprised i

00:41:02,640 --> 00:41:07,359
wanted to

00:41:03,920 --> 00:41:09,280
trigger it's in between surprise and

00:41:07,359 --> 00:41:13,680
sadness

00:41:09,280 --> 00:41:13,680
uh here's between surprise and joy

00:41:13,839 --> 00:41:19,760
here are two sad people yeah here hungry

00:41:17,839 --> 00:41:21,119
yeah yeah yeah yeah here you're really

00:41:19,760 --> 00:41:23,599
angry

00:41:21,119 --> 00:41:24,480
and my autoimmune model so let's try if

00:41:23,599 --> 00:41:27,760
i have yaya

00:41:24,480 --> 00:41:28,480
so more more pictures are coming you all

00:41:27,760 --> 00:41:31,520
have your

00:41:28,480 --> 00:41:35,119
tongue out great

00:41:31,520 --> 00:41:38,640
tired people good sorry tired people

00:41:35,119 --> 00:41:41,359
yes so you see it's i did input

00:41:38,640 --> 00:41:42,000
people uh yawning with all without their

00:41:41,359 --> 00:41:47,119
uh

00:41:42,000 --> 00:41:50,319
their hand it works and people sleeping

00:41:47,119 --> 00:41:53,040
yeah it works and finally

00:41:50,319 --> 00:41:53,680
if you remember it's able to detect

00:41:53,040 --> 00:41:57,200
objects

00:41:53,680 --> 00:41:58,640
with a precise location so here i have

00:41:57,200 --> 00:42:01,680
the people

00:41:58,640 --> 00:42:02,000
all the attendees with glasses and it

00:42:01,680 --> 00:42:05,119
seems

00:42:02,000 --> 00:42:06,000
to work great okay so a couple of

00:42:05,119 --> 00:42:09,200
minutes so

00:42:06,000 --> 00:42:12,400
you see it's really easy to use to do

00:42:09,200 --> 00:42:16,319
um why not there are two ways to measure

00:42:12,400 --> 00:42:17,839
um how well your model is performing

00:42:16,319 --> 00:42:19,920
and for that you have to understand the

00:42:17,839 --> 00:42:21,680
notion of true and false positives

00:42:19,920 --> 00:42:23,280
of positives and negatives and whether

00:42:21,680 --> 00:42:26,079
they are true or false

00:42:23,280 --> 00:42:26,880
there are four different cases if you're

00:42:26,079 --> 00:42:29,680
focusing

00:42:26,880 --> 00:42:31,680
on quality then the precision is the

00:42:29,680 --> 00:42:34,160
metric you're interested in

00:42:31,680 --> 00:42:34,960
if you are using a search engine then

00:42:34,160 --> 00:42:37,280
you will

00:42:34,960 --> 00:42:38,960
use the recall metric and here you you

00:42:37,280 --> 00:42:41,680
want to minimize the number of

00:42:38,960 --> 00:42:42,319
false negatives you want more results i

00:42:41,680 --> 00:42:45,520
will

00:42:42,319 --> 00:42:47,599
let you have a look at this um

00:42:45,520 --> 00:42:48,880
if you want to a little bit understand

00:42:47,599 --> 00:42:51,119
how to email works

00:42:48,880 --> 00:42:52,800
at least at google there's one specific

00:42:51,119 --> 00:42:54,960
feature

00:42:52,800 --> 00:42:56,400
if you want to do more machine learning

00:42:54,960 --> 00:42:58,560
then you can use

00:42:56,400 --> 00:43:00,400
frameworks one of them is tensorflow so

00:42:58,560 --> 00:43:03,599
it's an open source uh

00:43:00,400 --> 00:43:06,319
uh maybe the most uh

00:43:03,599 --> 00:43:07,920
the most popular one on on github by far

00:43:06,319 --> 00:43:11,520
another one is pytorch

00:43:07,920 --> 00:43:14,000
that i hear a lot from from experts

00:43:11,520 --> 00:43:16,079
so what have we seen uh we've seen that

00:43:14,000 --> 00:43:18,079
there are three ways you can use that

00:43:16,079 --> 00:43:19,839
with the apis you just need a couple of

00:43:18,079 --> 00:43:22,560
hours without email you need

00:43:19,839 --> 00:43:23,839
days and weeks or months if you want to

00:43:22,560 --> 00:43:25,680
become an expert

00:43:23,839 --> 00:43:28,000
the difficulty there's absolutely no

00:43:25,680 --> 00:43:29,920
difficulty with the apis

00:43:28,000 --> 00:43:31,520
uh with the toy mark you need to build

00:43:29,920 --> 00:43:32,720
the data set and for that you need a

00:43:31,520 --> 00:43:36,079
couple of days

00:43:32,720 --> 00:43:39,440
okay a few links if you're interested to

00:43:36,079 --> 00:43:40,640
uh check out uh some solutions here this

00:43:39,440 --> 00:43:43,280
is a

00:43:40,640 --> 00:43:44,319
an online comic coming from google ai

00:43:43,280 --> 00:43:46,800
you will find

00:43:44,319 --> 00:43:48,480
uh lots of the terms so it's a nice

00:43:46,800 --> 00:43:49,520
refresh if you want to understand a bit

00:43:48,480 --> 00:43:51,599
better

00:43:49,520 --> 00:43:54,160
if you want to get uh the slides for

00:43:51,599 --> 00:43:56,560
this talk they are here uh

00:43:54,160 --> 00:43:58,160
you're very much welcome uh to send me

00:43:56,560 --> 00:44:00,640
feedback too

00:43:58,160 --> 00:44:01,359
so thanks a lot for for uh having me

00:44:00,640 --> 00:44:03,520
today

00:44:01,359 --> 00:44:05,520
my goal is was to give you this overview

00:44:03,520 --> 00:44:08,319
of what you can do as a developer

00:44:05,520 --> 00:44:08,640
and and you don't have to be an expert

00:44:08,319 --> 00:44:12,240
uh

00:44:08,640 --> 00:44:15,440
to to do everything you you've seen um

00:44:12,240 --> 00:44:18,800
so uh i hope you learn a few things uh

00:44:15,440 --> 00:44:19,760
and also even i hope uh it gave you a

00:44:18,800 --> 00:44:21,440
few ideas

00:44:19,760 --> 00:44:24,800
thanks a lot for having me today and

00:44:21,440 --> 00:44:28,160
have fun have a great european thank you

00:44:24,800 --> 00:44:30,720
okay thank you very much that was a very

00:44:28,160 --> 00:44:32,880
interesting talk lots of topics lots of

00:44:30,720 --> 00:44:34,800
things covered we do have a number of

00:44:32,880 --> 00:44:36,880
questions

00:44:34,800 --> 00:44:38,000
but the time is already up so i would

00:44:36,880 --> 00:44:41,200
say that

00:44:38,000 --> 00:44:44,960
we basically take them to the uh to the

00:44:41,200 --> 00:44:47,200
talk channel that i posted in the chat

00:44:44,960 --> 00:44:48,960
and then you can answer them there uh it

00:44:47,200 --> 00:44:51,119
would also be a good idea to maybe

00:44:48,960 --> 00:44:53,200
post the links that you have here in the

00:44:51,119 --> 00:44:55,839
slides in the talk channel so that they

00:44:53,200 --> 00:44:59,119
stay up and then are easily reachable

00:44:55,839 --> 00:45:01,280
sure i will do so immediately right so

00:44:59,119 --> 00:45:05,839
let me give you your applause

00:45:01,280 --> 00:45:05,839
well deserved

00:45:11,440 --> 00:45:13,520

YouTube URL: https://www.youtube.com/watch?v=FTFfgTpMjfc


