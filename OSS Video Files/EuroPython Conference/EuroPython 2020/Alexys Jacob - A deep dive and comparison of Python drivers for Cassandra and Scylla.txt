Title: Alexys Jacob - A deep dive and comparison of Python drivers for Cassandra and Scylla
Publication date: 2020-09-15
Playlist: EuroPython 2020
Description: 
	"A deep dive and comparison of Python drivers for Cassandra and Scylla
EuroPython 2020 - Talk - 2020-07-23 - Brian
Online

By Alexys Jacob




License: This video is licensed under the CC BY-NC-SA 3.0 license: https://creativecommons.org/licenses/by-nc-sa/3.0/
Please see our speaker release agreement for details: https://ep2020.europython.eu/events/speaker-release-agreement/

    "
Captions: 
	00:00:06,480 --> 00:00:10,800
okay so

00:00:07,600 --> 00:00:13,280
we're coming to our third session

00:00:10,800 --> 00:00:15,519
in this block and you've just seen

00:00:13,280 --> 00:00:18,080
messages from some of our sponsors

00:00:15,519 --> 00:00:20,000
but some of our sponsors also do talks

00:00:18,080 --> 00:00:23,119
and the next one

00:00:20,000 --> 00:00:27,199
i'd like to invite to us is

00:00:23,119 --> 00:00:29,279
alexis from numberly alexis hello

00:00:27,199 --> 00:00:30,880
hello everyone can you hear me all right

00:00:29,279 --> 00:00:33,040
and see me as well

00:00:30,880 --> 00:00:35,040
this works perfectly and we can see you

00:00:33,040 --> 00:00:37,520
too um

00:00:35,040 --> 00:00:38,239
you are in paris at the moment or in

00:00:37,520 --> 00:00:40,320
france

00:00:38,239 --> 00:00:41,520
yeah in france and so for france

00:00:40,320 --> 00:00:44,719
actually this time

00:00:41,520 --> 00:00:46,640
but i usually live in paris and and work

00:00:44,719 --> 00:00:49,760
in paris

00:00:46,640 --> 00:00:52,640
are you ready to uh do your presentation

00:00:49,760 --> 00:00:54,719
sure i guess so i will just start

00:00:52,640 --> 00:00:58,640
sharing my screen and

00:00:54,719 --> 00:01:02,640
preparing if you're low yes or sure

00:00:58,640 --> 00:01:02,640
okay and let's see if that works

00:01:03,280 --> 00:01:07,200
so hello everyone i'm really happy to be

00:01:06,080 --> 00:01:10,479
remotely as you

00:01:07,200 --> 00:01:13,760
understood with you today

00:01:10,479 --> 00:01:17,040
in this talk i will detail cassandra and

00:01:13,760 --> 00:01:18,159
sila low level architecture and explain

00:01:17,040 --> 00:01:21,200
how it's used

00:01:18,159 --> 00:01:23,439
by python cassandra driver and show you

00:01:21,200 --> 00:01:25,439
how we extended it to write a python

00:01:23,439 --> 00:01:28,799
driver for cila

00:01:25,439 --> 00:01:29,520
there will be diagrams emojis python

00:01:28,799 --> 00:01:31,840
code

00:01:29,520 --> 00:01:34,320
and hopefully some amazing performance

00:01:31,840 --> 00:01:37,840
graphs as well

00:01:34,320 --> 00:01:40,960
um let me introduce a bit about myself

00:01:37,840 --> 00:01:43,600
so hazmat is already told you and

00:01:40,960 --> 00:01:44,880
you can judge from my accent i'm a i'm

00:01:43,600 --> 00:01:47,840
french i'm alexis

00:01:44,880 --> 00:01:49,439
and i'm a cto at numberley uh who

00:01:47,840 --> 00:01:52,840
happens as well to be a

00:01:49,439 --> 00:01:56,159
proud sponsor for europa items since 200

00:01:52,840 --> 00:01:58,479
2014 and we are

00:01:56,159 --> 00:01:59,759
digital marketing experts and we help

00:01:58,479 --> 00:02:03,280
brands establish

00:01:59,759 --> 00:02:05,680
a a relationship a digital relationship

00:02:03,280 --> 00:02:09,039
with their customers

00:02:05,680 --> 00:02:12,319
on the open source world i

00:02:09,039 --> 00:02:14,080
am a gen 2 linux developer

00:02:12,319 --> 00:02:16,160
where i'm part of the cluster and

00:02:14,080 --> 00:02:19,760
containers teams

00:02:16,160 --> 00:02:22,720
which means that i spend some of my time

00:02:19,760 --> 00:02:24,160
working on packaging distributed

00:02:22,720 --> 00:02:26,000
databases such as

00:02:24,160 --> 00:02:27,280
mongodb and sila

00:02:26,000 --> 00:02:29,520
[Music]

00:02:27,280 --> 00:02:31,680
or work on packaging some other cluster

00:02:29,520 --> 00:02:32,959
related tools and work with my friends

00:02:31,680 --> 00:02:36,560
on

00:02:32,959 --> 00:02:38,879
the docker gen2 linux images

00:02:36,560 --> 00:02:39,680
i'm also open source contributor and

00:02:38,879 --> 00:02:42,480
enthusiast

00:02:39,680 --> 00:02:44,560
um i've been contributing to mongodb to

00:02:42,480 --> 00:02:47,519
sila to apache airflow

00:02:44,560 --> 00:02:49,519
and i'm a python software foundation a

00:02:47,519 --> 00:02:53,280
contributing member which means that i

00:02:49,519 --> 00:02:54,959
spend a fair amount of my time uh

00:02:53,280 --> 00:02:56,400
working on or contributing to

00:02:54,959 --> 00:02:59,360
python-based

00:02:56,400 --> 00:02:59,360
open source projects

00:03:00,000 --> 00:03:03,519
before we start i wanted to introduce

00:03:02,720 --> 00:03:05,920
you to a fact

00:03:03,519 --> 00:03:07,840
that you may not know already but uh

00:03:05,920 --> 00:03:08,239
since fight europe item is using this

00:03:07,840 --> 00:03:10,800
chord

00:03:08,239 --> 00:03:11,440
i found interesting to share to you um

00:03:10,800 --> 00:03:14,480
that uh

00:03:11,440 --> 00:03:16,800
discord is using sila as well uh

00:03:14,480 --> 00:03:17,760
if you are interested in understanding

00:03:16,800 --> 00:03:20,400
uh what

00:03:17,760 --> 00:03:21,519
they do i invite you to uh to check out

00:03:20,400 --> 00:03:24,560
this uh the link

00:03:21,519 --> 00:03:26,560
here where mark smith uh introduces uh

00:03:24,560 --> 00:03:27,920
how a discord is using sila it's very

00:03:26,560 --> 00:03:31,280
interesting so

00:03:27,920 --> 00:03:34,080
check it out if you want also

00:03:31,280 --> 00:03:34,720
this is an advanced talk as advertised

00:03:34,080 --> 00:03:36,480
so

00:03:34,720 --> 00:03:38,319
i will suppose that you are familiar

00:03:36,480 --> 00:03:41,440
with the basics of

00:03:38,319 --> 00:03:42,480
consistent hashing and cassandra if

00:03:41,440 --> 00:03:44,400
that's not the case

00:03:42,480 --> 00:03:45,760
or if you simply want to know more about

00:03:44,400 --> 00:03:47,280
consistent hashing

00:03:45,760 --> 00:03:49,760
and even use it in your python

00:03:47,280 --> 00:03:50,720
applications i'm allowing myself to also

00:03:49,760 --> 00:03:53,439
introduce you to

00:03:50,720 --> 00:03:54,959
the talk i gave on this very subject in

00:03:53,439 --> 00:03:58,159
a previous your python

00:03:54,959 --> 00:03:58,959
edition but fear not i've still worked

00:03:58,159 --> 00:04:00,959
on

00:03:58,959 --> 00:04:02,319
not making this a big problem for this

00:04:00,959 --> 00:04:05,120
presentation so

00:04:02,319 --> 00:04:06,480
you you should be able to follow along

00:04:05,120 --> 00:04:08,319
and no problem

00:04:06,480 --> 00:04:11,200
even if you don't know exactly the

00:04:08,319 --> 00:04:13,680
details of consistent hashing

00:04:11,200 --> 00:04:15,680
let's get started now and let me

00:04:13,680 --> 00:04:18,720
introduce you

00:04:15,680 --> 00:04:19,840
to cassandra and sila token running

00:04:18,720 --> 00:04:22,320
architectures

00:04:19,840 --> 00:04:24,720
and we see all they have in common but

00:04:22,320 --> 00:04:25,280
also what sila has done that makes it a

00:04:24,720 --> 00:04:29,840
special

00:04:25,280 --> 00:04:29,840
and worth a dedicated python driver

00:04:30,240 --> 00:04:34,479
the first thing to know is that a

00:04:32,320 --> 00:04:37,440
cassandra or sila cluster

00:04:34,479 --> 00:04:38,240
is a cluster is a collection of nodes or

00:04:37,440 --> 00:04:41,440
instances

00:04:38,240 --> 00:04:42,080
that can be visualized as a ring all the

00:04:41,440 --> 00:04:44,800
nodes

00:04:42,080 --> 00:04:47,040
uh in this ring should be homogeneous

00:04:44,800 --> 00:04:49,120
using a shared nothing approach

00:04:47,040 --> 00:04:52,080
this means that um there's nothing

00:04:49,120 --> 00:04:54,240
special about a node in this topology

00:04:52,080 --> 00:04:55,120
one node one cassandra node on the on

00:04:54,240 --> 00:04:58,320
the ring

00:04:55,120 --> 00:05:01,199
or any sealer node on the ring

00:04:58,320 --> 00:05:03,120
has no special role or anything special

00:05:01,199 --> 00:05:04,479
about it there is no primary or

00:05:03,120 --> 00:05:08,000
secondary or anything

00:05:04,479 --> 00:05:08,000
they all do the same thing

00:05:08,560 --> 00:05:13,919
this ring is called a token ring

00:05:11,840 --> 00:05:15,440
in which the positions of the nodes on

00:05:13,919 --> 00:05:19,520
the ring define

00:05:15,440 --> 00:05:22,080
token ranges and token range partitions

00:05:19,520 --> 00:05:24,240
you can see that before if you go

00:05:22,080 --> 00:05:27,120
clockwise on on the ring

00:05:24,240 --> 00:05:28,400
the range that is preceding a node is

00:05:27,120 --> 00:05:30,479
the token range that

00:05:28,400 --> 00:05:32,479
and or the partition that it is

00:05:30,479 --> 00:05:36,560
responsible for

00:05:32,479 --> 00:05:40,400
a partition is just a subset of data

00:05:36,560 --> 00:05:42,560
that is stored on the node in cql

00:05:40,400 --> 00:05:44,160
the cassandra query language a partition

00:05:42,560 --> 00:05:46,960
appears as a group of sorted

00:05:44,160 --> 00:05:48,479
rows and is the unit of access of

00:05:46,960 --> 00:05:51,520
queried data

00:05:48,479 --> 00:05:53,600
this data is usually replicated across

00:05:51,520 --> 00:05:56,880
nodes thanks to a setting that is called

00:05:53,600 --> 00:05:56,880
the replication factor

00:05:57,680 --> 00:06:03,120
the replication factor defines how data

00:06:01,120 --> 00:06:06,240
is replicated on nodes

00:06:03,120 --> 00:06:08,800
for example a replication factor of 2

00:06:06,240 --> 00:06:09,759
means that a given token or token range

00:06:08,800 --> 00:06:12,240
or partition

00:06:09,759 --> 00:06:13,199
will be stored on two nodes this is the

00:06:12,240 --> 00:06:16,319
case here

00:06:13,199 --> 00:06:19,440
where partition 1 and 2 is stored on an

00:06:16,319 --> 00:06:20,960
x and you can see that partition 2 is

00:06:19,440 --> 00:06:24,639
also stored on

00:06:20,960 --> 00:06:28,319
y while the partition 1 is stored on

00:06:24,639 --> 00:06:31,440
z that means that if we were to lose not

00:06:28,319 --> 00:06:33,199
x we could still read the data from

00:06:31,440 --> 00:06:36,080
partition 1

00:06:33,199 --> 00:06:37,759
from node z this is how high

00:06:36,080 --> 00:06:39,680
availability is achieved and how

00:06:37,759 --> 00:06:42,160
cassandra and cilla

00:06:39,680 --> 00:06:42,880
favor availability and partition

00:06:42,160 --> 00:06:47,039
tolerance

00:06:42,880 --> 00:06:49,280
they are called ap on the cap theorem

00:06:47,039 --> 00:06:51,440
this kind of token ring architecture is

00:06:49,280 --> 00:06:55,360
sensible to data distribution

00:06:51,440 --> 00:06:58,000
among the nodes queries should

00:06:55,360 --> 00:06:58,960
in theory be evenly distributed between

00:06:58,000 --> 00:07:01,680
nodes

00:06:58,960 --> 00:07:02,080
we could get an unbalance of data and

00:07:01,680 --> 00:07:04,880
query

00:07:02,080 --> 00:07:07,680
load in the above scenario where we

00:07:04,880 --> 00:07:10,479
store data in three big partitions

00:07:07,680 --> 00:07:11,280
and each node holds one range of the

00:07:10,479 --> 00:07:16,000
previous one

00:07:11,280 --> 00:07:18,960
and the and one range from the next one

00:07:16,000 --> 00:07:20,000
if one of those partitions were to grow

00:07:18,960 --> 00:07:22,960
larger than

00:07:20,000 --> 00:07:24,560
another one we could then have an

00:07:22,960 --> 00:07:28,479
unbalance of queries

00:07:24,560 --> 00:07:31,759
and over sort of overload on on them

00:07:28,479 --> 00:07:34,080
um to counter and this effect uh

00:07:31,759 --> 00:07:35,840
that we are that we are calling a hot

00:07:34,080 --> 00:07:38,400
node or hot partition

00:07:35,840 --> 00:07:40,560
we need to add more variance in

00:07:38,400 --> 00:07:43,680
partition to node allocation

00:07:40,560 --> 00:07:44,720
and this is done uh using what is called

00:07:43,680 --> 00:07:47,199
virtual nodes

00:07:44,720 --> 00:07:48,240
so instead of placing physical nodes on

00:07:47,199 --> 00:07:50,879
the ring

00:07:48,240 --> 00:07:51,440
we will place many virtual instances of

00:07:50,879 --> 00:07:53,680
them

00:07:51,440 --> 00:07:56,720
called virtual nodes a virtual node

00:07:53,680 --> 00:07:59,680
represents a contiguous range of tokens

00:07:56,720 --> 00:08:00,479
owned by a single node so it's just a

00:07:59,680 --> 00:08:03,680
smaller

00:08:00,479 --> 00:08:06,319
slice of a partition but it's

00:08:03,680 --> 00:08:08,160
more shuffled between nodes a physical

00:08:06,319 --> 00:08:10,080
node may be assigned multiple and

00:08:08,160 --> 00:08:12,479
non-contiguous

00:08:10,080 --> 00:08:14,080
if you remember the preceding slide it

00:08:12,479 --> 00:08:16,160
was contiguous but this time

00:08:14,080 --> 00:08:17,599
they cannot allow for a non-contiguous

00:08:16,160 --> 00:08:21,240
assignment of nodes

00:08:17,599 --> 00:08:24,560
the default um is to split a node into

00:08:21,240 --> 00:08:26,240
356 virtual nodes on the token ring

00:08:24,560 --> 00:08:29,039
since this is true for cassandra and

00:08:26,240 --> 00:08:31,840
this is true for sela as well

00:08:29,039 --> 00:08:34,080
so if you look at how now the partitions

00:08:31,840 --> 00:08:36,159
are distributed among nodes you see

00:08:34,080 --> 00:08:37,680
that there is more variance into this

00:08:36,159 --> 00:08:41,279
which will

00:08:37,680 --> 00:08:43,120
end up in distributing the query better

00:08:41,279 --> 00:08:44,480
this is it for cassandra's data

00:08:43,120 --> 00:08:47,519
distribution but

00:08:44,480 --> 00:08:48,480
sila goes one step further on each

00:08:47,519 --> 00:08:50,480
ceilin node

00:08:48,480 --> 00:08:51,839
tokens of a v node are further

00:08:50,480 --> 00:08:54,240
distributed among

00:08:51,839 --> 00:08:55,440
the cpu cores of the node that are

00:08:54,240 --> 00:08:59,519
called shards

00:08:55,440 --> 00:09:02,080
this means that the data stored on

00:08:59,519 --> 00:09:02,800
a sila cluster is not only bound to a

00:09:02,080 --> 00:09:06,240
node

00:09:02,800 --> 00:09:06,720
but can be traced down to one of its cpu

00:09:06,240 --> 00:09:09,360
cores

00:09:06,720 --> 00:09:11,120
this is really interesting architecture

00:09:09,360 --> 00:09:13,600
and low level design

00:09:11,120 --> 00:09:14,800
this is the feature that we will

00:09:13,600 --> 00:09:18,000
leverage on the python

00:09:14,800 --> 00:09:20,000
site shadow ware driver later on and i

00:09:18,000 --> 00:09:21,839
will explain to you how

00:09:20,000 --> 00:09:23,839
now that we understand how data is

00:09:21,839 --> 00:09:26,720
stored and distributed on the cluster

00:09:23,839 --> 00:09:28,720
let's see how it's created by clients on

00:09:26,720 --> 00:09:31,040
the physical layer a partition

00:09:28,720 --> 00:09:31,920
is the uni is a unit of data stored on a

00:09:31,040 --> 00:09:34,640
node and

00:09:31,920 --> 00:09:36,640
is identified by a partition key you can

00:09:34,640 --> 00:09:39,360
relate a partition key to

00:09:36,640 --> 00:09:41,440
a primary key in the sql world a

00:09:39,360 --> 00:09:44,080
partition key is the primary means

00:09:41,440 --> 00:09:45,839
of looking up a set of rows that

00:09:44,080 --> 00:09:48,640
comprise a partition

00:09:45,839 --> 00:09:50,160
and a partition key serves to identify

00:09:48,640 --> 00:09:53,519
the node in the cluster

00:09:50,160 --> 00:09:55,600
that stores a given partition as well as

00:09:53,519 --> 00:09:56,880
to distribute the data across nodes in

00:09:55,600 --> 00:09:59,839
the cluster

00:09:56,880 --> 00:10:02,079
the partitioner or the partition hash

00:09:59,839 --> 00:10:04,640
function

00:10:02,079 --> 00:10:05,519
using the partition key will help us

00:10:04,640 --> 00:10:07,440
determine

00:10:05,519 --> 00:10:09,279
where the data is stored on the given

00:10:07,440 --> 00:10:12,640
node in the cluster so you take

00:10:09,279 --> 00:10:13,279
the id in this case you see a column id

00:10:12,640 --> 00:10:15,279
you will

00:10:13,279 --> 00:10:16,320
this will be the partition key you take

00:10:15,279 --> 00:10:19,279
the value

00:10:16,320 --> 00:10:20,800
you apply a hash function on it the

00:10:19,279 --> 00:10:22,880
partitioner hash function

00:10:20,800 --> 00:10:25,200
which by default on cassandra and sili

00:10:22,880 --> 00:10:27,519
is murmur hashtag

00:10:25,200 --> 00:10:29,440
and this will give you a token a token

00:10:27,519 --> 00:10:31,920
is like a number which is

00:10:29,440 --> 00:10:32,880
just actually is a number that will be

00:10:31,920 --> 00:10:35,920
placed

00:10:32,880 --> 00:10:37,200
on the token ring and from where it

00:10:35,920 --> 00:10:40,320
leads on token ring

00:10:37,200 --> 00:10:42,480
you will find out which nodes a

00:10:40,320 --> 00:10:43,360
is which node is responsible for this

00:10:42,480 --> 00:10:46,959
data

00:10:43,360 --> 00:10:50,000
that's as simple as this

00:10:46,959 --> 00:10:53,120
okay so let's recap now

00:10:50,000 --> 00:10:53,760
on cassandra the hash of the partition

00:10:53,120 --> 00:10:56,480
key

00:10:53,760 --> 00:10:56,959
gives you a token telling you which node

00:10:56,480 --> 00:10:59,279
has

00:10:56,959 --> 00:11:00,320
the data that you're looking for we can

00:10:59,279 --> 00:11:03,440
see this

00:11:00,320 --> 00:11:06,079
architecture as a shard pair node

00:11:03,440 --> 00:11:06,640
architecture because from the from the

00:11:06,079 --> 00:11:09,519
token

00:11:06,640 --> 00:11:10,560
you get to a node so sharper node on

00:11:09,519 --> 00:11:13,519
sila

00:11:10,560 --> 00:11:15,120
the same hash of the partition key on

00:11:13,519 --> 00:11:17,200
the same of partition key

00:11:15,120 --> 00:11:18,320
gives you the same token but the same

00:11:17,200 --> 00:11:20,959
token not only

00:11:18,320 --> 00:11:21,760
is not only telling you which node has

00:11:20,959 --> 00:11:24,959
the data

00:11:21,760 --> 00:11:27,360
but also which cpu's core

00:11:24,959 --> 00:11:28,079
in this node is responsible for handling

00:11:27,360 --> 00:11:31,360
it

00:11:28,079 --> 00:11:32,640
so this is a short per core architecture

00:11:31,360 --> 00:11:35,920
this is how it's called

00:11:32,640 --> 00:11:40,160
so cassandra is sharper node while

00:11:35,920 --> 00:11:40,160
sila is sharper core

00:11:40,560 --> 00:11:48,000
now let's see how does a client driver

00:11:43,920 --> 00:11:50,800
query a cassandra or a sila cluster

00:11:48,000 --> 00:11:51,839
because now that we know this we could

00:11:50,800 --> 00:11:55,600
guess and expect

00:11:51,839 --> 00:11:59,920
that client drivers uses

00:11:55,600 --> 00:12:02,800
this knowledge to find out and optimize

00:11:59,920 --> 00:12:02,800
their query plan

00:12:03,680 --> 00:12:07,440
a naive client would go on like this

00:12:06,000 --> 00:12:10,160
when a client connects

00:12:07,440 --> 00:12:11,839
to a cassandra or sila cluster it opens

00:12:10,160 --> 00:12:13,440
the connection to every node of the

00:12:11,839 --> 00:12:15,839
cluster

00:12:13,440 --> 00:12:16,880
when it wants to issue a query a knife

00:12:15,839 --> 00:12:19,120
client would pick

00:12:16,880 --> 00:12:21,680
one of its connection randomly let's say

00:12:19,120 --> 00:12:24,240
and issue the query to the node

00:12:21,680 --> 00:12:25,120
the node it issues the query 2 will be

00:12:24,240 --> 00:12:27,360
seen as

00:12:25,120 --> 00:12:28,480
the from the client's perspective it

00:12:27,360 --> 00:12:30,720
will act as what

00:12:28,480 --> 00:12:32,560
is called a coordinator because he is

00:12:30,720 --> 00:12:34,959
coordinating the query

00:12:32,560 --> 00:12:36,160
and is taking the ephemeral

00:12:34,959 --> 00:12:38,160
responsibility

00:12:36,160 --> 00:12:40,560
of routing the query internally in the

00:12:38,160 --> 00:12:42,639
cluster to the right

00:12:40,560 --> 00:12:44,639
nodes that are replicas for this data

00:12:42,639 --> 00:12:45,519
that means that are responsible for the

00:12:44,639 --> 00:12:48,959
partition

00:12:45,519 --> 00:12:51,680
the query belongs to and gathering the

00:12:48,959 --> 00:12:53,519
responses and then responding back to

00:12:51,680 --> 00:12:57,040
the client

00:12:53,519 --> 00:13:00,560
but maybe this coordinator

00:12:57,040 --> 00:13:02,720
is not a replica for the query data

00:13:00,560 --> 00:13:03,760
if it's if it's not the case if the

00:13:02,720 --> 00:13:06,079
coordinator

00:13:03,760 --> 00:13:08,720
is not a replica for the query data it

00:13:06,079 --> 00:13:09,600
has to issue the queries to all replicas

00:13:08,720 --> 00:13:11,760
itself

00:13:09,600 --> 00:13:14,000
that means that you will add it will

00:13:11,760 --> 00:13:17,120
have an extra hub

00:13:14,000 --> 00:13:18,480
inside in inside the cluster to to get

00:13:17,120 --> 00:13:20,639
the responses

00:13:18,480 --> 00:13:23,040
this is a sub-optimal of course as it

00:13:20,639 --> 00:13:25,519
consumes network and processing power

00:13:23,040 --> 00:13:26,880
on the coordinate or node for something

00:13:25,519 --> 00:13:28,639
that

00:13:26,880 --> 00:13:31,600
the client could have guessed in the

00:13:28,639 --> 00:13:33,440
first place right

00:13:31,600 --> 00:13:35,040
because since the partitioner hash

00:13:33,440 --> 00:13:37,360
function is known

00:13:35,040 --> 00:13:39,600
our client library can use it to predict

00:13:37,360 --> 00:13:42,800
data location on the cluster

00:13:39,600 --> 00:13:44,959
and optimize the query routing

00:13:42,800 --> 00:13:46,839
this is what the cassandra driver does

00:13:44,959 --> 00:13:50,079
using the token aware

00:13:46,839 --> 00:13:52,800
policy how does it work

00:13:50,079 --> 00:13:54,160
token aware clients apply the

00:13:52,800 --> 00:13:56,639
partitional logic

00:13:54,160 --> 00:13:57,680
to select the right connection to the

00:13:56,639 --> 00:14:00,320
right node

00:13:57,680 --> 00:14:01,440
and make sure that its coordinator node

00:14:00,320 --> 00:14:06,399
is also

00:14:01,440 --> 00:14:09,040
a replica of the query data this is cool

00:14:06,399 --> 00:14:11,040
and this is very efficient as a result

00:14:09,040 --> 00:14:14,480
we save network hopes

00:14:11,040 --> 00:14:18,079
lower the the cluster internal load

00:14:14,480 --> 00:14:21,680
and get reduced query latency meanings

00:14:18,079 --> 00:14:23,519
meaning faster queries let's see how the

00:14:21,680 --> 00:14:26,000
cassandra driver does it

00:14:23,519 --> 00:14:26,800
for real internally so the token aware

00:14:26,000 --> 00:14:28,399
policy

00:14:26,800 --> 00:14:30,079
from the point of view of the python

00:14:28,399 --> 00:14:33,279
cassandra driver the

00:14:30,079 --> 00:14:35,839
partition key is seen

00:14:33,279 --> 00:14:36,560
as a routing key because it will be used

00:14:35,839 --> 00:14:40,320
to root

00:14:36,560 --> 00:14:42,480
the query right so it is seen as a

00:14:40,320 --> 00:14:44,720
routing key which is used to determine

00:14:42,480 --> 00:14:46,000
which node are the replicas for the

00:14:44,720 --> 00:14:49,360
query

00:14:46,000 --> 00:14:51,279
and to know how to allow our python

00:14:49,360 --> 00:14:52,079
driver to know about the partition key

00:14:51,279 --> 00:14:55,600
of a query

00:14:52,079 --> 00:14:59,279
the query itself must be prepared as a

00:14:55,600 --> 00:15:04,079
server-side statement

00:14:59,279 --> 00:15:06,399
this is how it looks on on in in python

00:15:04,079 --> 00:15:08,880
cassandra's and silas prepare statements

00:15:06,399 --> 00:15:11,519
that can you can see them

00:15:08,880 --> 00:15:12,000
a bit like stored procedures in the sql

00:15:11,519 --> 00:15:15,120
world

00:15:12,000 --> 00:15:18,240
you see if you see statement equals

00:15:15,120 --> 00:15:20,720
decision dot prepare and then you um

00:15:18,240 --> 00:15:21,279
you express the the query that you want

00:15:20,720 --> 00:15:23,760
and

00:15:21,279 --> 00:15:25,040
when you have an argument or parameter

00:15:23,760 --> 00:15:28,720
you just put

00:15:25,040 --> 00:15:31,199
an exclama an integration mark

00:15:28,720 --> 00:15:32,959
and this is the recommended and most

00:15:31,199 --> 00:15:34,079
optimal way to query the data because

00:15:32,959 --> 00:15:37,120
when you have

00:15:34,079 --> 00:15:39,279
prepared your your query

00:15:37,120 --> 00:15:41,680
it is validated and it lives on the

00:15:39,279 --> 00:15:43,519
server side so you don't have to pass it

00:15:41,680 --> 00:15:46,000
and you just have to pass a reference to

00:15:43,519 --> 00:15:48,320
it and then only pass the arguments

00:15:46,000 --> 00:15:50,560
and the arguments one of them will be

00:15:48,320 --> 00:15:51,040
the mandatory routing key partition key

00:15:50,560 --> 00:15:53,920
then

00:15:51,040 --> 00:15:54,800
routing key so statement plus routing

00:15:53,920 --> 00:15:59,040
key equals

00:15:54,800 --> 00:16:02,639
nod and it's very very cool

00:15:59,040 --> 00:16:05,040
another thing to note it is that um

00:16:02,639 --> 00:16:07,279
just like prepared uh stored procedures

00:16:05,040 --> 00:16:08,240
uh prepare statements are also the

00:16:07,279 --> 00:16:10,160
safest way

00:16:08,240 --> 00:16:11,600
because it they prevent query injection

00:16:10,160 --> 00:16:14,079
so please

00:16:11,600 --> 00:16:15,440
in production at the bare minimum only

00:16:14,079 --> 00:16:18,880
use prepare statements

00:16:15,440 --> 00:16:22,720
when you issue queries to cassandra or

00:16:18,880 --> 00:16:26,560
clusters then

00:16:22,720 --> 00:16:29,199
uh the python cassandra driver defaults

00:16:26,560 --> 00:16:29,759
to the token aware to root the query and

00:16:29,199 --> 00:16:32,800
then

00:16:29,759 --> 00:16:35,360
it also defaults to a data center aware

00:16:32,800 --> 00:16:38,800
round robin load balancing query routing

00:16:35,360 --> 00:16:40,079
it's it's a bit long but what it means

00:16:38,800 --> 00:16:43,040
that is that

00:16:40,079 --> 00:16:44,639
it will load balance for you in a

00:16:43,040 --> 00:16:46,639
round-robin fashion so

00:16:44,639 --> 00:16:48,160
one after the other after the other like

00:16:46,639 --> 00:16:50,959
this so it's a

00:16:48,160 --> 00:16:50,959
bare minimal

00:16:51,279 --> 00:16:56,160
load balancing algorithm there is but

00:16:54,399 --> 00:16:59,279
it's still pretty efficient

00:16:56,160 --> 00:17:01,920
so don't worry if even if your

00:16:59,279 --> 00:17:02,800
cluster is not spread between multiple

00:17:01,920 --> 00:17:05,600
data center

00:17:02,800 --> 00:17:07,679
it still works it's just it just happens

00:17:05,600 --> 00:17:08,799
to be the default so it's token aware

00:17:07,679 --> 00:17:12,240
plus

00:17:08,799 --> 00:17:14,480
data center aware round robin

00:17:12,240 --> 00:17:16,160
by doing so the query routine will not

00:17:14,480 --> 00:17:18,959
only hit the right node

00:17:16,160 --> 00:17:21,120
holding a copy of the data that you seek

00:17:18,959 --> 00:17:23,919
remember it's called the replica the

00:17:21,120 --> 00:17:24,720
replica but also load balance the

00:17:23,919 --> 00:17:29,440
queries

00:17:24,720 --> 00:17:32,320
evenly between all its separate class so

00:17:29,440 --> 00:17:33,679
one can think yeah this is awesome and

00:17:32,320 --> 00:17:37,360
optimal

00:17:33,679 --> 00:17:37,840
i mean from a cassandra cluster point of

00:17:37,360 --> 00:17:41,919
view

00:17:37,840 --> 00:17:46,960
it is and we can't do better than this

00:17:41,919 --> 00:17:50,160
but not with a sila one remember sila

00:17:46,960 --> 00:17:52,000
shards the data one way further down to

00:17:50,160 --> 00:17:55,280
node cpus

00:17:52,000 --> 00:17:58,559
so having a talker where

00:17:55,280 --> 00:17:59,440
token awareness is cool but if our

00:17:58,559 --> 00:18:02,559
client had

00:17:59,440 --> 00:18:05,600
shared awareness it would be even cooler

00:18:02,559 --> 00:18:08,160
because this means that a

00:18:05,600 --> 00:18:09,919
token aware client could be extended to

00:18:08,160 --> 00:18:13,039
become a shadower client

00:18:09,919 --> 00:18:16,240
to route its queries not only to nodes

00:18:13,039 --> 00:18:20,080
but right to their cpu cores

00:18:16,240 --> 00:18:20,080
this is very interesting to do

00:18:20,480 --> 00:18:25,200
such drivers they already exist as forks

00:18:23,039 --> 00:18:27,120
of the data stacks and cassandra drivers

00:18:25,200 --> 00:18:29,520
and it's true for the java one and the

00:18:27,120 --> 00:18:32,559
go one as well and they have been uh

00:18:29,520 --> 00:18:35,679
around since uh last year actually

00:18:32,559 --> 00:18:36,320
uh but there was no uh shard aware

00:18:35,679 --> 00:18:39,200
driver

00:18:36,320 --> 00:18:39,840
uh for python and it made it made me sad

00:18:39,200 --> 00:18:43,120
and

00:18:39,840 --> 00:18:46,080
pretty angry so when i attended um

00:18:43,120 --> 00:18:47,120
sila submit last year in san francisco i

00:18:46,080 --> 00:18:49,360
did some lobbying

00:18:47,120 --> 00:18:50,640
and hard lobbying on the on and found

00:18:49,360 --> 00:18:53,440
some sila

00:18:50,640 --> 00:18:54,840
uh developers that are that were willing

00:18:53,440 --> 00:18:58,160
to help

00:18:54,840 --> 00:19:02,480
in in

00:18:58,160 --> 00:19:04,720
in making this happen for python as well

00:19:02,480 --> 00:19:06,640
so we promised each other to make a

00:19:04,720 --> 00:19:10,160
python shadow ware driver

00:19:06,640 --> 00:19:10,559
and good news is that we have obviously

00:19:10,160 --> 00:19:13,600
did

00:19:10,559 --> 00:19:16,720
and i will now explain to you in details

00:19:13,600 --> 00:19:18,640
how it has been done and what we found

00:19:16,720 --> 00:19:22,559
out by doing so

00:19:18,640 --> 00:19:25,840
very very interesting uh as well i think

00:19:22,559 --> 00:19:28,160
so let's start by um

00:19:25,840 --> 00:19:28,960
checking out the expected structural

00:19:28,160 --> 00:19:31,200
differences

00:19:28,960 --> 00:19:33,039
between the cassandra driver and the

00:19:31,200 --> 00:19:36,080
sila driver fork

00:19:33,039 --> 00:19:38,240
um the first thing to see is that the

00:19:36,080 --> 00:19:40,799
token aware cassandra driver

00:19:38,240 --> 00:19:41,679
has when he connects for the first time

00:19:40,799 --> 00:19:43,840
to the cluster

00:19:41,679 --> 00:19:45,679
it opens a control connection this

00:19:43,840 --> 00:19:49,120
control connection allows

00:19:45,679 --> 00:19:51,280
your cassandra driver to

00:19:49,120 --> 00:19:52,320
know about the cluster topology how many

00:19:51,280 --> 00:19:54,960
nodes there are

00:19:52,320 --> 00:19:57,039
which are up which are down what are the

00:19:54,960 --> 00:19:59,360
schemas etcetera etcetera

00:19:57,039 --> 00:20:00,960
it needs to know all this so it opens a

00:19:59,360 --> 00:20:04,080
special connection for this and

00:20:00,960 --> 00:20:05,200
in this connection it refreshes uh from

00:20:04,080 --> 00:20:08,080
time to time

00:20:05,200 --> 00:20:09,679
and then it will open one connection per

00:20:08,080 --> 00:20:12,559
node because this is how the

00:20:09,679 --> 00:20:13,200
token aware policy will be applied to

00:20:12,559 --> 00:20:16,880
select

00:20:13,200 --> 00:20:20,960
the right of those connection based on

00:20:16,880 --> 00:20:23,840
the query and then it will be done by

00:20:20,960 --> 00:20:26,080
the famous token calculation

00:20:23,840 --> 00:20:28,000
and that's how it's done all right on

00:20:26,080 --> 00:20:30,559
the shallower

00:20:28,000 --> 00:20:31,600
client perspective we still need to know

00:20:30,559 --> 00:20:35,520
about the cluster

00:20:31,600 --> 00:20:37,600
topology uh actually but instead of you

00:20:35,520 --> 00:20:39,919
opening one connection per node we will

00:20:37,600 --> 00:20:41,360
be opening one connection per core per

00:20:39,919 --> 00:20:44,640
node

00:20:41,360 --> 00:20:46,799
the token calculation will still be

00:20:44,640 --> 00:20:48,000
useful to select the right node from the

00:20:46,799 --> 00:20:50,320
token perspective

00:20:48,000 --> 00:20:51,360
but then we will need to add a shard id

00:20:50,320 --> 00:20:53,840
calculation because

00:20:51,360 --> 00:20:54,880
we need to go down to the shard or the

00:20:53,840 --> 00:20:57,520
cpu core

00:20:54,880 --> 00:20:58,240
to so to select the connection to the

00:20:57,520 --> 00:21:02,480
right core

00:20:58,240 --> 00:21:06,240
to root the queries let's transform this

00:21:02,480 --> 00:21:07,919
into a to-do uh from the the python code

00:21:06,240 --> 00:21:10,320
perspective

00:21:07,919 --> 00:21:12,320
first thing is since we will be using

00:21:10,320 --> 00:21:15,360
the same kind of control connection

00:21:12,320 --> 00:21:18,080
we don't we just use this as

00:21:15,360 --> 00:21:19,840
is there's nothing to change here we

00:21:18,080 --> 00:21:20,880
will need to change the connection class

00:21:19,840 --> 00:21:24,159
object

00:21:20,880 --> 00:21:26,159
because now when we are going to open a

00:21:24,159 --> 00:21:29,440
connection per cooper node

00:21:26,159 --> 00:21:31,600
we will need to be able to detect if we

00:21:29,440 --> 00:21:33,520
are talking to a selak cluster or to a

00:21:31,600 --> 00:21:37,200
cassandra cluster

00:21:33,520 --> 00:21:39,840
um the sila driver we want it to retain

00:21:37,200 --> 00:21:42,080
maximum compatibility with cassandra as

00:21:39,840 --> 00:21:44,640
well so you can use the sila driver

00:21:42,080 --> 00:21:46,960
to discuss and query your cassandra

00:21:44,640 --> 00:21:50,000
cluster as well

00:21:46,960 --> 00:21:53,600
the host connection pool uh should we

00:21:50,000 --> 00:21:57,039
use those those shadowwear

00:21:53,600 --> 00:21:58,080
connections to and open one connection

00:21:57,039 --> 00:22:02,159
to every uh every

00:21:58,080 --> 00:22:04,000
call of every node the token calculation

00:22:02,159 --> 00:22:06,720
that selects the right node will be the

00:22:04,000 --> 00:22:09,120
same we will just use the vanilla

00:22:06,720 --> 00:22:10,720
and already existing and efficient token

00:22:09,120 --> 00:22:13,039
aware policy

00:22:10,720 --> 00:22:13,760
but then we will need to to extend it

00:22:13,039 --> 00:22:16,880
and add

00:22:13,760 --> 00:22:17,600
uh in the cluster when you issue the

00:22:16,880 --> 00:22:21,200
query

00:22:17,600 --> 00:22:24,400
we will need the cluster class to

00:22:21,200 --> 00:22:26,559
pass down the routing key to the

00:22:24,400 --> 00:22:27,919
to the connection pool and then we will

00:22:26,559 --> 00:22:30,720
apply the shard id

00:22:27,919 --> 00:22:32,240
calculation and then implement the logic

00:22:30,720 --> 00:22:35,039
based on the shard id

00:22:32,240 --> 00:22:38,400
of selecting the right connection to the

00:22:35,039 --> 00:22:38,400
right node to the right shard

00:22:38,559 --> 00:22:42,159
okay sounds like a plan let's do this

00:22:41,280 --> 00:22:45,679
now

00:22:42,159 --> 00:22:48,640
we'll get down into the code um

00:22:45,679 --> 00:22:49,120
before we we we go into this i wanted to

00:22:48,640 --> 00:22:52,240
uh

00:22:49,120 --> 00:22:53,120
to highlight uh and to introduce israel

00:22:52,240 --> 00:22:55,200
israel is a

00:22:53,120 --> 00:22:56,320
stila developer from israel i know it's

00:22:55,200 --> 00:22:59,760
confusing

00:22:56,320 --> 00:23:01,120
but that's how it is and since i know

00:22:59,760 --> 00:23:04,640
he's in the audience

00:23:01,120 --> 00:23:06,720
uh that makes me a some kind of pressure

00:23:04,640 --> 00:23:08,159
as you can guess i wanted to take this

00:23:06,720 --> 00:23:10,559
opportunity to thank him

00:23:08,159 --> 00:23:12,240
and giving him the credits for most of

00:23:10,559 --> 00:23:15,520
what i'm going to present now

00:23:12,240 --> 00:23:19,039
especially the efforts he put into uh ci

00:23:15,520 --> 00:23:22,559
testing the sila driver um

00:23:19,039 --> 00:23:25,360
so the first thing that uh that that

00:23:22,559 --> 00:23:27,520
needed to be done is to add those shard

00:23:25,360 --> 00:23:30,720
information to the connections

00:23:27,520 --> 00:23:33,120
and so this is how it's been done so a

00:23:30,720 --> 00:23:35,360
connection now has a shard id

00:23:33,120 --> 00:23:38,400
assigned to it and sharding information

00:23:35,360 --> 00:23:42,559
discharging information comes from

00:23:38,400 --> 00:23:46,240
the the the server responses uh when we

00:23:42,559 --> 00:23:49,120
issue a query that's what is um

00:23:46,240 --> 00:23:50,480
what is squared in red on the bottom the

00:23:49,120 --> 00:23:53,600
the logic of this

00:23:50,480 --> 00:23:57,120
uh looks like this um

00:23:53,600 --> 00:23:59,279
it is what it's interesting to note um

00:23:57,120 --> 00:24:01,200
is that the cassandra protocol allows

00:23:59,279 --> 00:24:03,600
only for connection

00:24:01,200 --> 00:24:05,360
message options being passed on the

00:24:03,600 --> 00:24:07,520
server response

00:24:05,360 --> 00:24:09,360
this means that when the client

00:24:07,520 --> 00:24:12,880
initially connects

00:24:09,360 --> 00:24:15,039
to cassandra or sila it has no way

00:24:12,880 --> 00:24:15,919
of passing any kind of information to

00:24:15,039 --> 00:24:18,080
the server so

00:24:15,919 --> 00:24:19,039
we are dependent on the server's

00:24:18,080 --> 00:24:23,039
response

00:24:19,039 --> 00:24:26,480
to know about shard

00:24:23,039 --> 00:24:28,000
shard information or whatever it is that

00:24:26,480 --> 00:24:31,440
we need

00:24:28,000 --> 00:24:32,000
if we look at the the message options

00:24:31,440 --> 00:24:33,760
that we get

00:24:32,000 --> 00:24:36,400
back after we have connected to the

00:24:33,760 --> 00:24:38,080
server the first one is one of the most

00:24:36,400 --> 00:24:41,120
interesting for us because

00:24:38,080 --> 00:24:44,400
uh the sila shard information

00:24:41,120 --> 00:24:46,559
tells us um which shard id or core

00:24:44,400 --> 00:24:47,440
was assigned to the connection by the

00:24:46,559 --> 00:24:50,400
server

00:24:47,440 --> 00:24:51,360
and i'm going to say this again this

00:24:50,400 --> 00:24:53,919
information

00:24:51,360 --> 00:24:55,440
tells us what shard id or core why is

00:24:53,919 --> 00:24:58,480
assigned

00:24:55,440 --> 00:25:00,240
to the connection by the server since we

00:24:58,480 --> 00:25:03,360
have no way of

00:25:00,240 --> 00:25:04,320
asking anything when we connect we are

00:25:03,360 --> 00:25:07,520
dependent

00:25:04,320 --> 00:25:09,600
on the server shard allocation to the

00:25:07,520 --> 00:25:13,200
connection that we open

00:25:09,600 --> 00:25:13,200
this is a protocol limitation

00:25:13,679 --> 00:25:18,080
so now we are going to change the the

00:25:17,440 --> 00:25:21,120
the

00:25:18,080 --> 00:25:24,240
host connection pool uh class um

00:25:21,120 --> 00:25:24,799
we need to uh to get the connection

00:25:24,240 --> 00:25:28,000
object

00:25:24,799 --> 00:25:30,080
for every core of the node right so

00:25:28,000 --> 00:25:32,320
the first thing we did is that we got

00:25:30,080 --> 00:25:36,320
rid of the single connection

00:25:32,320 --> 00:25:38,880
that we had before um

00:25:36,320 --> 00:25:41,440
and replaced it with addict where the

00:25:38,880 --> 00:25:42,559
keys are the shard id numerical shard id

00:25:41,440 --> 00:25:45,760
and the values

00:25:42,559 --> 00:25:49,440
are the connections that are bound to

00:25:45,760 --> 00:25:52,240
the specified chart um

00:25:49,440 --> 00:25:53,120
the first time we connect as you can see

00:25:52,240 --> 00:25:56,400
in the first

00:25:53,120 --> 00:25:58,960
square a rectangle the first connection

00:25:56,400 --> 00:26:01,520
allows us to detect if we are connecting

00:25:58,960 --> 00:26:01,840
to a shardaware cluster a stila cluster

00:26:01,520 --> 00:26:04,320
in

00:26:01,840 --> 00:26:05,440
for instance and this is where we get

00:26:04,320 --> 00:26:08,000
the first

00:26:05,440 --> 00:26:09,120
glance at the sharding information and

00:26:08,000 --> 00:26:12,320
we store it

00:26:09,120 --> 00:26:14,480
then i uh the first time i

00:26:12,320 --> 00:26:16,320
i saw the initial implementation like

00:26:14,480 --> 00:26:18,720
this um

00:26:16,320 --> 00:26:19,440
and this is the second part here with

00:26:18,720 --> 00:26:22,640
the four

00:26:19,440 --> 00:26:24,799
uh underscore in range

00:26:22,640 --> 00:26:26,799
we can see that we are doing an

00:26:24,799 --> 00:26:31,760
insynchronous and optimistic way

00:26:26,799 --> 00:26:31,760
to get a connection to every core

00:26:32,159 --> 00:26:35,279
why is that we open a new connection to

00:26:34,559 --> 00:26:38,000
the node

00:26:35,279 --> 00:26:38,480
and stories shard id plus connection

00:26:38,000 --> 00:26:41,600
object

00:26:38,480 --> 00:26:42,559
on the dict and we will do this twice as

00:26:41,600 --> 00:26:45,600
many times

00:26:42,559 --> 00:26:48,880
there are cores on the remote node until

00:26:45,600 --> 00:26:52,000
we have a connection to all charts

00:26:48,880 --> 00:26:54,640
maybe because

00:26:52,000 --> 00:26:55,360
if you remember the client when it

00:26:54,640 --> 00:26:58,400
connects

00:26:55,360 --> 00:27:00,000
cannot specify which charts it want to

00:26:58,400 --> 00:27:02,000
connect to

00:27:00,000 --> 00:27:04,000
so you just happen to connect to the

00:27:02,000 --> 00:27:05,919
server and you get a shard assign

00:27:04,000 --> 00:27:07,200
that's why the initial implementation

00:27:05,919 --> 00:27:10,480
was trying and saying

00:27:07,200 --> 00:27:12,159
okay let's let's try twice as much as

00:27:10,480 --> 00:27:12,640
there are cores available on the remote

00:27:12,159 --> 00:27:15,200
node

00:27:12,640 --> 00:27:16,799
and hopefully we'll get we'll get a full

00:27:15,200 --> 00:27:17,600
connection and a connection for every

00:27:16,799 --> 00:27:21,360
shard

00:27:17,600 --> 00:27:24,399
if we wear a key fine keep on moving

00:27:21,360 --> 00:27:28,000
if not we would raise an exception

00:27:24,399 --> 00:27:30,960
no this is the first time i saw this

00:27:28,000 --> 00:27:32,000
i i understood that there was i

00:27:30,960 --> 00:27:34,880
understood this flow

00:27:32,000 --> 00:27:36,799
in in the client not being able to

00:27:34,880 --> 00:27:38,720
request a specific shard id because of

00:27:36,799 --> 00:27:39,760
the protocol limitation so there is no

00:27:38,720 --> 00:27:42,159
deterministic

00:27:39,760 --> 00:27:45,200
and secure way to get the connection to

00:27:42,159 --> 00:27:48,240
all remote shards of a sila node

00:27:45,200 --> 00:27:49,919
and connecting also synchronously

00:27:48,240 --> 00:27:51,520
means that the startup of our

00:27:49,919 --> 00:27:54,320
application would be as

00:27:51,520 --> 00:27:56,880
slow as connecting to hopefully all

00:27:54,320 --> 00:28:01,279
shards of all nodes

00:27:56,880 --> 00:28:01,279
not acceptable so

00:28:01,840 --> 00:28:06,159
the second thing that that that came to

00:28:04,080 --> 00:28:07,919
my mind was hey

00:28:06,159 --> 00:28:10,080
this also means that all the current

00:28:07,919 --> 00:28:12,640
shadow drivers since it's the protocol

00:28:10,080 --> 00:28:15,520
limitation it's not bound to tighten and

00:28:12,640 --> 00:28:16,399
whatever it's not a python's problem

00:28:15,520 --> 00:28:19,520
it's

00:28:16,399 --> 00:28:21,679
it's a flow or a lack

00:28:19,520 --> 00:28:23,360
maybe you know not a flow but rather

00:28:21,679 --> 00:28:25,120
lack in the protocol itself

00:28:23,360 --> 00:28:26,640
so that means that all the current

00:28:25,120 --> 00:28:30,000
charter drivers are

00:28:26,640 --> 00:28:32,480
lying since none of them

00:28:30,000 --> 00:28:33,440
even today can guarantee to always have

00:28:32,480 --> 00:28:37,360
a connection

00:28:33,440 --> 00:28:40,399
for a given routine key all of this is

00:28:37,360 --> 00:28:42,080
opportunistic and optimistic you will

00:28:40,399 --> 00:28:44,960
eventually get one

00:28:42,080 --> 00:28:45,679
but not all your queries will be able to

00:28:44,960 --> 00:28:47,760
use

00:28:45,679 --> 00:28:49,120
the direct connection to the right child

00:28:47,760 --> 00:28:51,919
so i wrote an

00:28:49,120 --> 00:28:53,600
rfc on the sila dev mailing list to

00:28:51,919 --> 00:28:56,799
discuss this problem

00:28:53,600 --> 00:28:57,600
and the good news is that the consensus

00:28:56,799 --> 00:28:59,280
to a solution

00:28:57,600 --> 00:29:00,640
was recently found

00:28:59,280 --> 00:29:02,720
[Music]

00:29:00,640 --> 00:29:04,080
it will take the form of a new shard

00:29:02,720 --> 00:29:06,559
allocation algorithm

00:29:04,080 --> 00:29:08,159
that will be placed on the server side

00:29:06,559 --> 00:29:11,760
and that will be made available

00:29:08,159 --> 00:29:14,640
as a new listening port on sila

00:29:11,760 --> 00:29:15,600
so since we want and want sila and

00:29:14,640 --> 00:29:18,080
cassandra

00:29:15,600 --> 00:29:18,640
on the their default port to retain the

00:29:18,080 --> 00:29:22,000
same

00:29:18,640 --> 00:29:25,600
um behavior

00:29:22,000 --> 00:29:27,919
if we want to change a bit uh and add a

00:29:25,600 --> 00:29:29,679
and add on the server a new kind of

00:29:27,919 --> 00:29:31,520
allocation port allocation

00:29:29,679 --> 00:29:32,720
we need to do it on the new on your new

00:29:31,520 --> 00:29:35,200
port so

00:29:32,720 --> 00:29:37,520
it will be a shard aware part let's say

00:29:35,200 --> 00:29:40,960
it will just use a sort of modulo

00:29:37,520 --> 00:29:43,840
on the client's socket source port

00:29:40,960 --> 00:29:45,039
to assign the correct and calculate and

00:29:43,840 --> 00:29:46,240
assign the correct chart to the

00:29:45,039 --> 00:29:48,960
connection

00:29:46,240 --> 00:29:50,320
so it means that the clients on the side

00:29:48,960 --> 00:29:54,559
will just have

00:29:50,320 --> 00:29:57,279
just have to calculate

00:29:54,559 --> 00:29:59,360
and select the right socket source port

00:29:57,279 --> 00:30:00,480
to get a connection to the desired child

00:29:59,360 --> 00:30:02,799
id

00:30:00,480 --> 00:30:04,000
this is work in progress but it's not

00:30:02,799 --> 00:30:06,880
done yet so

00:30:04,000 --> 00:30:08,080
i worked on implementing a software and

00:30:06,880 --> 00:30:11,520
optimistic

00:30:08,080 --> 00:30:13,440
and in asynchronous way of dealing with

00:30:11,520 --> 00:30:16,640
this problem

00:30:13,440 --> 00:30:16,640
let's see how it's been done

00:30:17,039 --> 00:30:21,520
um the first thing is that i wrote two

00:30:20,240 --> 00:30:24,559
functions the first one

00:30:21,520 --> 00:30:26,159
is the optimistic one it opens a

00:30:24,559 --> 00:30:27,919
connection

00:30:26,159 --> 00:30:30,159
tries to open a connection and only

00:30:27,919 --> 00:30:33,200
stores it if the reported

00:30:30,159 --> 00:30:36,480
shard id was not connected before

00:30:33,200 --> 00:30:40,240
else we close it so we are only

00:30:36,480 --> 00:30:43,679
interested in the keeping connections to

00:30:40,240 --> 00:30:46,159
missing shard ids but we just

00:30:43,679 --> 00:30:47,760
open it and if it works good if it

00:30:46,159 --> 00:30:51,440
doesn't

00:30:47,760 --> 00:30:53,919
we'll see later then i

00:30:51,440 --> 00:30:55,279
switch the the startup logic to schedule

00:30:53,919 --> 00:30:57,200
as many optimistic

00:30:55,279 --> 00:30:59,279
of those optimistic attempts to get a

00:30:57,200 --> 00:31:01,200
connection to a missing shard id

00:30:59,279 --> 00:31:02,799
as there are shards available on the

00:31:01,200 --> 00:31:06,159
remote node so when you

00:31:02,799 --> 00:31:07,519
connect and you start connecting if you

00:31:06,159 --> 00:31:10,159
have 50 cores

00:31:07,519 --> 00:31:11,679
on your remote server you will issue

00:31:10,159 --> 00:31:12,960
asynchronously and schedule

00:31:11,679 --> 00:31:16,840
asynchronously

00:31:12,960 --> 00:31:20,640
50 items to get a connection to

00:31:16,840 --> 00:31:23,840
shards maybe 25 of them

00:31:20,640 --> 00:31:26,880
will give you different and unique

00:31:23,840 --> 00:31:28,159
shadow disconnected maybe two of them

00:31:26,880 --> 00:31:31,760
maybe 50 of them

00:31:28,159 --> 00:31:34,799
lucky you but now we don't care

00:31:31,760 --> 00:31:37,840
it's optimistic asynchronous and

00:31:34,799 --> 00:31:39,440
it will go on and on again like this as

00:31:37,840 --> 00:31:42,240
we use the driver

00:31:39,440 --> 00:31:43,919
the result is a cluster faster an

00:31:42,240 --> 00:31:46,159
application startup time

00:31:43,919 --> 00:31:47,200
that is as fast as the usual cassandra

00:31:46,159 --> 00:31:50,399
driver

00:31:47,200 --> 00:31:52,720
and a and non-blocking optimistic chart

00:31:50,399 --> 00:31:55,919
connections

00:31:52,720 --> 00:31:57,360
so um the cluster object now it should

00:31:55,919 --> 00:32:00,559
pass down the routing key

00:31:57,360 --> 00:32:04,000
as well um to the pool

00:32:00,559 --> 00:32:04,720
so when you see here when uh you issue a

00:32:04,000 --> 00:32:07,840
query

00:32:04,720 --> 00:32:10,799
in the in the query function and

00:32:07,840 --> 00:32:11,600
we and the cluster looks up cluster

00:32:10,799 --> 00:32:14,480
object

00:32:11,600 --> 00:32:16,240
looks up for a connection there we added

00:32:14,480 --> 00:32:18,799
the routing key

00:32:16,240 --> 00:32:20,000
so that we could apply the shard id

00:32:18,799 --> 00:32:22,399
calculation

00:32:20,000 --> 00:32:23,039
this shard id calculation is a bit

00:32:22,399 --> 00:32:26,559
obscure

00:32:23,039 --> 00:32:28,640
and lucky lucky me

00:32:26,559 --> 00:32:29,600
israel was there to to implement it in

00:32:28,640 --> 00:32:32,480
the first place

00:32:29,600 --> 00:32:33,360
but the first time i tried to use this

00:32:32,480 --> 00:32:36,080
pure python

00:32:33,360 --> 00:32:36,720
implemented shard id calculation it was

00:32:36,080 --> 00:32:39,360
very bad

00:32:36,720 --> 00:32:41,600
on the driver performance we were slower

00:32:39,360 --> 00:32:44,720
than the cassandra driver

00:32:41,600 --> 00:32:46,880
so what israel did is to move

00:32:44,720 --> 00:32:47,919
this shard id computation to saitan

00:32:46,880 --> 00:32:50,480
because actually the

00:32:47,919 --> 00:32:51,840
cassandra driver is using a lot of

00:32:50,480 --> 00:32:55,679
saturn

00:32:51,840 --> 00:32:59,200
in in the background when you install it

00:32:55,679 --> 00:33:03,440
he managed to cut its latency impact

00:32:59,200 --> 00:33:06,240
by almost 7. so kudos again

00:33:03,440 --> 00:33:06,960
israel it was a very very impressive

00:33:06,240 --> 00:33:10,320
move

00:33:06,960 --> 00:33:14,080
and it made it made the difference

00:33:10,320 --> 00:33:16,720
on on the driver's perspective

00:33:14,080 --> 00:33:18,480
so now let's wrap it together and in the

00:33:16,720 --> 00:33:21,679
main shard awareness logic

00:33:18,480 --> 00:33:24,960
in the in the host connection pool um so

00:33:21,679 --> 00:33:27,200
here this is basically where

00:33:24,960 --> 00:33:28,399
the the connection selection happens uh

00:33:27,200 --> 00:33:31,840
and everything is glued

00:33:28,399 --> 00:33:32,320
together so if we are in uh that's line

00:33:31,840 --> 00:33:36,080
two

00:33:32,320 --> 00:33:38,320
if we are on uh a shadow where uh

00:33:36,080 --> 00:33:39,919
communication with a cluster we will

00:33:38,320 --> 00:33:44,159
calculate the shard id

00:33:39,919 --> 00:33:46,480
now from the routing key token

00:33:44,159 --> 00:33:47,200
then we will use the routing key the

00:33:46,480 --> 00:33:50,240
shard id

00:33:47,200 --> 00:33:52,799
and we will try to look up in our

00:33:50,240 --> 00:33:53,519
connection dict if we happen to have a

00:33:52,799 --> 00:33:56,559
connection

00:33:53,519 --> 00:33:59,120
to this direct shard id so to this

00:33:56,559 --> 00:34:02,559
direct core

00:33:59,120 --> 00:34:04,480
if we if we do triumph we will use this

00:34:02,559 --> 00:34:06,320
direct connection to the right core tool

00:34:04,480 --> 00:34:09,760
and root the query there

00:34:06,320 --> 00:34:13,520
almost that's perfect

00:34:09,760 --> 00:34:16,879
that's the best case scenario if not

00:34:13,520 --> 00:34:19,440
we will play an issue asynchronously

00:34:16,879 --> 00:34:20,000
a new attempt to connect to a missing

00:34:19,440 --> 00:34:21,679
shard

00:34:20,000 --> 00:34:23,599
maybe it will be the shard we were

00:34:21,679 --> 00:34:23,919
trying to look at before maybe it will

00:34:23,599 --> 00:34:26,639
be

00:34:23,919 --> 00:34:29,119
another one but that means that as much

00:34:26,639 --> 00:34:32,079
as you issue queries to your cluster

00:34:29,119 --> 00:34:34,879
the more chance you get to have a

00:34:32,079 --> 00:34:37,440
connection to all charts and all cores

00:34:34,879 --> 00:34:39,440
and if you didn't have one we will just

00:34:37,440 --> 00:34:42,240
random pick

00:34:39,440 --> 00:34:44,079
an existing connection so we would be

00:34:42,240 --> 00:34:46,480
just as if we were using the cassandra

00:34:44,079 --> 00:34:46,480
driver

00:34:46,560 --> 00:34:50,320
now that we have seen the implementation

00:34:48,159 --> 00:34:53,040
details does the sila driver

00:34:50,320 --> 00:34:54,159
live up to our expectations is it fast

00:34:53,040 --> 00:34:56,720
and

00:34:54,159 --> 00:34:57,839
how did it work in production because to

00:34:56,720 --> 00:35:01,040
us uh

00:34:57,839 --> 00:35:04,000
and to me the the real values and are

00:35:01,040 --> 00:35:05,280
from must be taken from production so

00:35:04,000 --> 00:35:08,079
let's see

00:35:05,280 --> 00:35:09,200
the first expectations that we check was

00:35:08,079 --> 00:35:11,200
the

00:35:09,200 --> 00:35:13,119
an increase we expect an increase in the

00:35:11,200 --> 00:35:15,599
number of open connections on from

00:35:13,119 --> 00:35:16,160
the cluster's perspective and this is a

00:35:15,599 --> 00:35:18,320
check

00:35:16,160 --> 00:35:20,320
because now that we are opening not only

00:35:18,320 --> 00:35:23,520
one connection to each node but one

00:35:20,320 --> 00:35:26,240
connection to each core of each node we

00:35:23,520 --> 00:35:27,280
we expected to see this increase so you

00:35:26,240 --> 00:35:30,000
can see

00:35:27,280 --> 00:35:30,800
with from the annotation when we re when

00:35:30,000 --> 00:35:33,839
we

00:35:30,800 --> 00:35:35,040
deployed the sila driver we saw this

00:35:33,839 --> 00:35:38,079
increase

00:35:35,040 --> 00:35:41,440
the second one was also an expectation

00:35:38,079 --> 00:35:43,920
to have more cpu requirements

00:35:41,440 --> 00:35:44,880
because you open more connections

00:35:43,920 --> 00:35:47,119
meaning that

00:35:44,880 --> 00:35:49,839
your driver and your cpu has to handle

00:35:47,119 --> 00:35:53,839
more connections and keep alive etc for

00:35:49,839 --> 00:35:57,440
for to keep those connections alive

00:35:53,839 --> 00:36:00,720
we saw that we had to increase

00:35:57,440 --> 00:36:04,240
from on our kubernetes deployments a bit

00:36:00,720 --> 00:36:07,119
the cpu limits to avoid cpu saturation

00:36:04,240 --> 00:36:08,560
and throttling but then what about the

00:36:07,119 --> 00:36:11,440
major impact we wanted

00:36:08,560 --> 00:36:12,240
we want faster queries lower latencies

00:36:11,440 --> 00:36:15,599
right

00:36:12,240 --> 00:36:17,839
how did that translate for real this is

00:36:15,599 --> 00:36:19,280
how what work graph looked like i was

00:36:17,839 --> 00:36:23,280
like

00:36:19,280 --> 00:36:26,800
wow it's amazing we gain between 15

00:36:23,280 --> 00:36:27,839
and 25 performance boost and at lamberly

00:36:26,800 --> 00:36:30,320
we like to

00:36:27,839 --> 00:36:32,400
look at our graph on the worst case

00:36:30,320 --> 00:36:35,680
scenario possible that means that

00:36:32,400 --> 00:36:39,680
if you check this out this is the max

00:36:35,680 --> 00:36:40,880
of our processing this is the the worst

00:36:39,680 --> 00:36:44,160
latency that we get

00:36:40,880 --> 00:36:46,240
from our application perspectives um

00:36:44,160 --> 00:36:48,000
what's inside interesting to note as

00:36:46,240 --> 00:36:50,640
well is that the performance boost

00:36:48,000 --> 00:36:52,000
is progressive since we connect to

00:36:50,640 --> 00:36:55,359
shards in the background

00:36:52,000 --> 00:36:56,400
in an optimistic fashion uh the longer

00:36:55,359 --> 00:36:58,880
our application

00:36:56,400 --> 00:36:59,599
runs the more chance it to have a

00:36:58,880 --> 00:37:02,480
connection

00:36:59,599 --> 00:37:04,160
um to all shard it has and then the

00:37:02,480 --> 00:37:07,599
lower the latency guests

00:37:04,160 --> 00:37:09,200
because we start to have always have

00:37:07,599 --> 00:37:11,200
the right connection to the right core

00:37:09,200 --> 00:37:13,200
for every query

00:37:11,200 --> 00:37:14,240
so you can see that right after the

00:37:13,200 --> 00:37:16,880
deployment

00:37:14,240 --> 00:37:18,160
we get already a fair amount of

00:37:16,880 --> 00:37:20,880
performance boost

00:37:18,160 --> 00:37:22,320
but the longer the time passes the more

00:37:20,880 --> 00:37:25,040
shards connected

00:37:22,320 --> 00:37:26,960
the better the latency that was very

00:37:25,040 --> 00:37:28,000
interesting to see we can see it also

00:37:26,960 --> 00:37:30,640
from afar if we

00:37:28,000 --> 00:37:32,000
apply a moving median on another power

00:37:30,640 --> 00:37:34,320
angry process

00:37:32,000 --> 00:37:35,359
you can clearly see the the big

00:37:34,320 --> 00:37:38,320
difference

00:37:35,359 --> 00:37:38,960
that that the the silas hardware driver

00:37:38,320 --> 00:37:43,119
has made

00:37:38,960 --> 00:37:44,960
in our production applications

00:37:43,119 --> 00:37:48,320
from this we got an unexpected and cool

00:37:44,960 --> 00:37:50,720
side effect is that we manage as well to

00:37:48,320 --> 00:37:53,599
since the cluster load was reduced and

00:37:50,720 --> 00:37:56,400
the client's last latency was lower

00:37:53,599 --> 00:37:57,440
uh our for the same workload we could

00:37:56,400 --> 00:38:00,160
cut by half

00:37:57,440 --> 00:38:02,160
the number of replicas on our deployment

00:38:00,160 --> 00:38:04,480
which was very cool as well so we

00:38:02,160 --> 00:38:07,440
saved actually resources on our

00:38:04,480 --> 00:38:07,440
kubernetes cluster

00:38:07,520 --> 00:38:11,520
recent additions that we've done on the

00:38:09,440 --> 00:38:15,119
driver we have added

00:38:11,520 --> 00:38:17,119
some some helpers to allow you to

00:38:15,119 --> 00:38:18,320
check for shard awareness and to check

00:38:17,119 --> 00:38:21,520
for this

00:38:18,320 --> 00:38:23,839
opportunistic shardaware connections

00:38:21,520 --> 00:38:24,560
so you can actually see how much of it

00:38:23,839 --> 00:38:27,040
is uh

00:38:24,560 --> 00:38:28,480
fully you are not connected when it

00:38:27,040 --> 00:38:32,400
becomes available

00:38:28,480 --> 00:38:34,560
we will be changing also the driver

00:38:32,400 --> 00:38:36,320
to be able to uh select

00:38:34,560 --> 00:38:39,280
deterministically this time

00:38:36,320 --> 00:38:41,280
the the shard id when it connects so

00:38:39,280 --> 00:38:41,920
there are two open pull requests already

00:38:41,280 --> 00:38:44,079
for this

00:38:41,920 --> 00:38:45,040
we're going to still work on improving

00:38:44,079 --> 00:38:47,920
the documentation

00:38:45,040 --> 00:38:50,079
and since it's a cassandra driver fork

00:38:47,920 --> 00:38:54,000
we will imagine rebase the latest

00:38:50,079 --> 00:38:56,960
improvements as well um

00:38:54,000 --> 00:38:59,280
try the sila driver uh it's working

00:38:56,960 --> 00:39:03,119
great it's working production for us for

00:38:59,280 --> 00:39:05,760
now almost almost a month

00:39:03,119 --> 00:39:07,119
and and with the the great impact that

00:39:05,760 --> 00:39:10,400
you've seen before

00:39:07,119 --> 00:39:12,880
uh check it out on the repository uh

00:39:10,400 --> 00:39:14,079
come chat with us as well uh when your

00:39:12,880 --> 00:39:16,320
python is over

00:39:14,079 --> 00:39:18,079
on the sila db uh clusters like we have

00:39:16,320 --> 00:39:22,160
a uh pythonistas

00:39:18,079 --> 00:39:24,800
uh channel where you are all welcome

00:39:22,160 --> 00:39:25,680
and uh that's it for me i want to thank

00:39:24,800 --> 00:39:28,560
everyone

00:39:25,680 --> 00:39:29,599
for for attending and making this europa

00:39:28,560 --> 00:39:32,720
item a success

00:39:29,599 --> 00:39:35,920
there is the the discord torque channel

00:39:32,720 --> 00:39:36,720
where we can keep in touch and and and

00:39:35,920 --> 00:39:39,280
this could

00:39:36,720 --> 00:39:40,079
discuss this further or deeper if you if

00:39:39,280 --> 00:39:43,839
you want

00:39:40,079 --> 00:39:44,560
and tomorrow we also have a sponsor talk

00:39:43,839 --> 00:39:47,839
session

00:39:44,560 --> 00:39:50,240
where we you can uh join in and

00:39:47,839 --> 00:39:51,440
we will be talking about a lot of

00:39:50,240 --> 00:39:53,920
different aspects and

00:39:51,440 --> 00:39:54,800
uh and and have cool guests from another

00:39:53,920 --> 00:39:57,839
as well

00:39:54,800 --> 00:39:58,880
thank you very much thank you very much

00:39:57,839 --> 00:40:01,839
for the talk

00:39:58,880 --> 00:40:04,400
uh we have a minute or two for questions

00:40:01,839 --> 00:40:07,920
do you mind some q a

00:40:04,400 --> 00:40:10,240
oh no of course um

00:40:07,920 --> 00:40:11,359
yes there's one question that has gotten

00:40:10,240 --> 00:40:13,359
some votes

00:40:11,359 --> 00:40:15,040
the code of the drivers seems to be

00:40:13,359 --> 00:40:17,920
python 2 compliant

00:40:15,040 --> 00:40:20,720
but is there an uh essencio part like

00:40:17,920 --> 00:40:24,319
for python 3 5 or better

00:40:20,720 --> 00:40:25,920
yes yes it's it's an old code base

00:40:24,319 --> 00:40:29,119
actually the cassandra driver

00:40:25,920 --> 00:40:30,160
is quite old and since uh uh we have

00:40:29,119 --> 00:40:33,599
been forking it

00:40:30,160 --> 00:40:34,240
uh to extend it uh we inherited this as

00:40:33,599 --> 00:40:37,200
well

00:40:34,240 --> 00:40:38,079
um so yes it is uh still supporting

00:40:37,200 --> 00:40:40,960
python 2

00:40:38,079 --> 00:40:42,720
and there are async io uh and libby ev

00:40:40,960 --> 00:40:45,119
as well

00:40:42,720 --> 00:40:45,760
connection class so you can also change

00:40:45,119 --> 00:40:48,000
your sing

00:40:45,760 --> 00:40:49,280
your connection class the default ones

00:40:48,000 --> 00:40:53,440
is a sim card

00:40:49,280 --> 00:40:57,839
one uh we have a question from roberto

00:40:53,440 --> 00:41:00,720
a q1 charts are pinned to cpu or what

00:40:57,839 --> 00:41:01,440
are there uh corrections for unbalanced

00:41:00,720 --> 00:41:04,640
charts

00:41:01,440 --> 00:41:08,000
eg one cpu to be hit by more than

00:41:04,640 --> 00:41:11,680
uh the others is that correct sorry one

00:41:08,000 --> 00:41:13,680
cpu to be hit by more than the others

00:41:11,680 --> 00:41:14,800
one cpu to be hit by more than the

00:41:13,680 --> 00:41:17,839
others

00:41:14,800 --> 00:41:20,319
yes if you have if you have an imbalance

00:41:17,839 --> 00:41:22,000
in your data distribution you will get

00:41:20,319 --> 00:41:25,200
the same kind of

00:41:22,000 --> 00:41:27,599
problem that you can get on a node but

00:41:25,200 --> 00:41:30,560
instead of impacting it the whole node

00:41:27,599 --> 00:41:30,560
you will be impacting

00:41:30,800 --> 00:41:34,240
a core yeah so yeah this problem exists

00:41:33,760 --> 00:41:36,640
as well

00:41:34,240 --> 00:41:37,520
in this kind of architecture this is

00:41:36,640 --> 00:41:39,359
inherent

00:41:37,520 --> 00:41:41,440
of a consistent hashing based

00:41:39,359 --> 00:41:43,119
architecture actually

00:41:41,440 --> 00:41:44,560
okay thank you very much there's a few

00:41:43,119 --> 00:41:46,560
more questions uh

00:41:44,560 --> 00:41:48,000
in the discord talk channel so you're

00:41:46,560 --> 00:41:51,040
going to find

00:41:48,000 --> 00:41:52,960
that you have raised a lot of interest

00:41:51,040 --> 00:41:54,160
and there was also an off-topic question

00:41:52,960 --> 00:41:55,920
before we let you go

00:41:54,160 --> 00:41:57,640
what's with those papers hanging there

00:41:55,920 --> 00:42:00,240
behind you that's the question

00:41:57,640 --> 00:42:03,040
[Laughter]

00:42:00,240 --> 00:42:03,599
yeah this is a way to keep notes above

00:42:03,040 --> 00:42:06,720
my head

00:42:03,599 --> 00:42:08,880
you know it's perfect

00:42:06,720 --> 00:42:10,240
uh thank you very much for taking the

00:42:08,880 --> 00:42:12,480
time uh to show

00:42:10,240 --> 00:42:13,440
you everyone thank you for sponsoring

00:42:12,480 --> 00:42:15,359
europe python

00:42:13,440 --> 00:42:17,040
and here's a round of applause for you

00:42:15,359 --> 00:42:23,599
and you're going to meet

00:42:17,040 --> 00:42:23,599

YouTube URL: https://www.youtube.com/watch?v=vWgTF5xnx8M


