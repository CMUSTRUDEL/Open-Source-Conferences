Title: Sarah Mount - Message-passing concurrency for Python
Publication date: 2015-04-18
Playlist: EuroPython 2014
Description: 
	Sarah Mount - Message-passing concurrency for Python
[EuroPython 2014]
[22 July 2014]

Concurrency and parallelism in Python are always hot topics. This talk will look the variety of forms of concurrency and parallelism. In particular this talk will give an overview of various forms of message-passing concurrency which have become popular in languages like Scala and Go. A Python library called python-csp which implements similar ideas in a Pythonic way will be introduced and we will look at how this style of programming can be used to avoid deadlocks, race hazards and "callback hell".

-----

Concurrency and parallelism in Python are always hot topics. Early Python versions had a threading library to perform concurrency over operating system threads, Python version 2.6 introduced the multiprocessing library and Python 3.2 has introduced a futures library for asynchronous tasks. In addition to the modules in the standard library a number of packages such as gevent exist on PyPI to implement concurrency with "green threads". 

This talk will look the variety of forms of concurrency and parallelism. When are the different libraries useful and how does their performance compare? Why do programmers want to "remove the GIL" and why is it so hard to do? In particular this talk will give an overview of various forms of message-passing concurrency which have become popular in languages like Scala and Go. A Python library called python-csp which implements similar ideas in a Pythonic way will be introduced and we will look at how this style of programming can be used to avoid deadlocks, race hazards and "callback hell".
Captions: 
	00:00:14,830 --> 00:00:21,580
thank you very much so this is quite a

00:00:17,950 --> 00:00:24,700
broad overview of a talk he's not so

00:00:21,580 --> 00:00:27,640
specifically about my own work but it's

00:00:24,700 --> 00:00:30,820
more sort of ideas in message passing

00:00:27,640 --> 00:00:32,949
concurrency a little bit about how they

00:00:30,820 --> 00:00:34,720
used currently in Python about how they

00:00:32,949 --> 00:00:36,160
might be used in the future because of

00:00:34,720 --> 00:00:41,680
course there are some great

00:00:36,160 --> 00:00:44,050
opportunities with Python 3 so why

00:00:41,680 --> 00:00:46,870
multi-core the reason for worrying about

00:00:44,050 --> 00:00:49,930
all of this concurrency stuff quite so

00:00:46,870 --> 00:00:52,360
much is largely to do with the rise of

00:00:49,930 --> 00:00:54,790
multi-core probably most of you have

00:00:52,360 --> 00:00:58,180
phones in your pockets that are that

00:00:54,790 --> 00:00:59,830
have quad core processes and I'm sure I

00:00:58,180 --> 00:01:02,379
don't need to tell you about what

00:00:59,830 --> 00:01:05,549
Moore's Law is that trend is going to

00:01:02,379 --> 00:01:10,090
continue and speed ups in programs and

00:01:05,549 --> 00:01:12,820
will start to be gained by using more

00:01:10,090 --> 00:01:16,990
cause more efficiently rather than

00:01:12,820 --> 00:01:20,290
simply buying a faster processor that's

00:01:16,990 --> 00:01:23,470
really important what's also important

00:01:20,290 --> 00:01:25,690
is as Hardware becomes cheaper and

00:01:23,470 --> 00:01:28,120
people do more interesting things with

00:01:25,690 --> 00:01:31,480
it different sorts of platforms are

00:01:28,120 --> 00:01:34,210
becoming available so this board that

00:01:31,480 --> 00:01:35,740
you can see on the slide is called the

00:01:34,210 --> 00:01:38,530
parallel aboard and it's by a company

00:01:35,740 --> 00:01:42,040
called a duct eva so this was a

00:01:38,530 --> 00:01:46,150
kickstarter project and I'm afraid I

00:01:42,040 --> 00:01:48,580
haven't bought one with me but this

00:01:46,150 --> 00:01:50,890
board is about the size of a credit card

00:01:48,580 --> 00:01:53,830
says the same sort of form factor as a

00:01:50,890 --> 00:01:57,820
Raspberry Pi and the aim of this company

00:01:53,830 --> 00:01:59,680
is to do for supercomputing what the

00:01:57,820 --> 00:02:01,659
Raspberry Pi is doing for sort of

00:01:59,680 --> 00:02:03,670
general development so to make it

00:02:01,659 --> 00:02:06,040
cheaper to make it more readily

00:02:03,670 --> 00:02:08,440
available on the desktop to all sorts of

00:02:06,040 --> 00:02:12,159
people whether they be hobbyists or

00:02:08,440 --> 00:02:14,140
scientists or whatever so the

00:02:12,159 --> 00:02:16,930
interesting thing about this board is

00:02:14,140 --> 00:02:18,340
that it's it's kind of like the

00:02:16,930 --> 00:02:20,769
Raspberry Pi it's got the sort of

00:02:18,340 --> 00:02:24,850
features you'd expect of a single board

00:02:20,769 --> 00:02:26,870
computer this is a dual core arm sinks

00:02:24,850 --> 00:02:28,640
chip but the really in

00:02:26,870 --> 00:02:31,280
testing thing is this chip that addict

00:02:28,640 --> 00:02:35,299
even made themselves which is a 16-core

00:02:31,280 --> 00:02:37,430
many-core coprocessor and the idea is if

00:02:35,299 --> 00:02:41,209
you want to speed up your programs then

00:02:37,430 --> 00:02:43,159
use this cocoa code processor to help

00:02:41,209 --> 00:02:46,190
you do that so they've got a 16-core

00:02:43,159 --> 00:02:49,549
version at that chip in a 60 Korver 64

00:02:46,190 --> 00:02:54,680
core version of that chip so that makes

00:02:49,549 --> 00:02:57,739
our multiprocessing very cheap very fast

00:02:54,680 --> 00:03:00,230
and also very low energy and that's

00:02:57,739 --> 00:03:02,690
really none but how did you program this

00:03:00,230 --> 00:03:06,260
board so the default libraries are all

00:03:02,690 --> 00:03:07,780
in C and if you want to be experimenting

00:03:06,260 --> 00:03:10,489
with a large amount of data or

00:03:07,780 --> 00:03:13,220
experimenting with making a difficult

00:03:10,489 --> 00:03:16,819
complex scientific analysis a lot faster

00:03:13,220 --> 00:03:19,879
probably going through the sea workflow

00:03:16,819 --> 00:03:21,739
of writing very carefully crafted code

00:03:19,879 --> 00:03:24,290
that doesn't blow up as soon as you run

00:03:21,739 --> 00:03:27,590
it and compiling it and all those other

00:03:24,290 --> 00:03:29,420
things is is not really much fun people

00:03:27,590 --> 00:03:31,849
who use this sort of thing often want to

00:03:29,420 --> 00:03:34,190
explore and explore their data and

00:03:31,849 --> 00:03:37,190
explore their programs and that's where

00:03:34,190 --> 00:03:39,769
dynamic languages really come in so to

00:03:37,190 --> 00:03:42,859
use Python on a board like that would be

00:03:39,769 --> 00:03:44,810
really fantastic but can we do it can we

00:03:42,859 --> 00:03:47,780
do it natively and really nicely we

00:03:44,810 --> 00:03:51,709
don't know yet so message passing

00:03:47,780 --> 00:03:55,519
concurrency is not a new idea it's a

00:03:51,709 --> 00:03:58,220
very very old idea and it came from two

00:03:55,519 --> 00:04:03,139
lines of work one line of work was very

00:03:58,220 --> 00:04:05,239
practical as this old a chip called the

00:04:03,139 --> 00:04:07,069
inmost transmuter and the idea was that

00:04:05,239 --> 00:04:09,139
you would have many of these trans

00:04:07,069 --> 00:04:10,819
beauties they're sort of like a CPU and

00:04:09,139 --> 00:04:12,590
you would put them in a grid and you

00:04:10,819 --> 00:04:15,160
would wire them all together so this is

00:04:12,590 --> 00:04:18,289
like it's at a very early form of

00:04:15,160 --> 00:04:22,220
multi-core the other line of work was

00:04:18,289 --> 00:04:24,740
very theoretical so CSP communicating

00:04:22,220 --> 00:04:27,320
sequential processes are one way of

00:04:24,740 --> 00:04:29,300
mathematically formalizing concurrent

00:04:27,320 --> 00:04:31,280
and parallel processing there are many

00:04:29,300 --> 00:04:32,950
other ways and they're all sort of

00:04:31,280 --> 00:04:35,470
reasonably similar in turn

00:04:32,950 --> 00:04:38,830
of the ideas that are in them and these

00:04:35,470 --> 00:04:40,780
two things went together but they never

00:04:38,830 --> 00:04:43,600
became popular because we had threads

00:04:40,780 --> 00:04:45,790
instead so I'm not going to go through

00:04:43,600 --> 00:04:48,220
all of the sort of mathematical details

00:04:45,790 --> 00:04:51,070
of CSP but I want to give you a flavor

00:04:48,220 --> 00:04:54,670
of what it's all about and why it might

00:04:51,070 --> 00:04:58,390
be important so in the process algebra

00:04:54,670 --> 00:05:01,840
view of the world computation has is

00:04:58,390 --> 00:05:04,300
made up of imperative commands that run

00:05:01,840 --> 00:05:07,960
sequentially and you have lots of those

00:05:04,300 --> 00:05:11,170
but you have them in processes which one

00:05:07,960 --> 00:05:12,910
can currently and can communicate with

00:05:11,170 --> 00:05:14,980
each other so you have different

00:05:12,910 --> 00:05:16,840
processes which are all running their

00:05:14,980 --> 00:05:19,270
same impact their own imperative

00:05:16,840 --> 00:05:21,610
programs and they don't share any

00:05:19,270 --> 00:05:23,830
valuables or any data if they want to

00:05:21,610 --> 00:05:25,960
communicate with each other or

00:05:23,830 --> 00:05:28,450
synchronize with each other they need a

00:05:25,960 --> 00:05:30,610
special way of doing that and a common

00:05:28,450 --> 00:05:34,720
way of doing it but not the only way is

00:05:30,610 --> 00:05:37,420
to pass messages via channels so the way

00:05:34,720 --> 00:05:39,520
to think of this as a sort of broad

00:05:37,420 --> 00:05:42,370
overview is to think about unix

00:05:39,520 --> 00:05:44,740
processes communicating by pipes so you

00:05:42,370 --> 00:05:46,900
have different processes all running in

00:05:44,740 --> 00:05:49,900
parallel and if they want to communicate

00:05:46,900 --> 00:05:53,230
they do so by pipes because they don't

00:05:49,900 --> 00:05:55,480
share any memory with each other but I'm

00:05:53,230 --> 00:05:59,350
sort of alighting a few details there

00:05:55,480 --> 00:06:01,420
because CSP is an abstract idea it's a

00:05:59,350 --> 00:06:04,030
mathematical formalism so when I talk

00:06:01,420 --> 00:06:06,430
about a CSP process that's not

00:06:04,030 --> 00:06:09,310
necessarily an operating system process

00:06:06,430 --> 00:06:11,650
and when CSP talks about events and

00:06:09,310 --> 00:06:13,810
synchronization that's not necessarily

00:06:11,650 --> 00:06:15,820
like the sort of events that you would

00:06:13,810 --> 00:06:17,710
see when you were programming a GUI but

00:06:15,820 --> 00:06:19,620
it might be it might be and I'm going to

00:06:17,710 --> 00:06:23,620
talk about that in a bit more detail

00:06:19,620 --> 00:06:26,560
later on so why would anyone care about

00:06:23,620 --> 00:06:28,600
all this stuff well if you work with

00:06:26,560 --> 00:06:31,740
threads and you've worked with locks you

00:06:28,600 --> 00:06:34,840
know they're really tough to get light

00:06:31,740 --> 00:06:36,460
correctness is important and when you're

00:06:34,840 --> 00:06:38,680
dealing with really low level things

00:06:36,460 --> 00:06:40,810
like locks and pointer if we're taking

00:06:38,680 --> 00:06:42,400
all of this sort of stuff it's hard and

00:06:40,810 --> 00:06:45,040
locking is hard

00:06:42,400 --> 00:06:47,259
and deadlox and starvation and race

00:06:45,040 --> 00:06:51,699
hazards and all those things are hard

00:06:47,259 --> 00:06:54,280
and they don't sit well with us at a

00:06:51,699 --> 00:06:56,949
very high level pythonic view of the

00:06:54,280 --> 00:06:58,930
world which is to use the abstractions

00:06:56,949 --> 00:07:01,630
of the language to make our life really

00:06:58,930 --> 00:07:03,580
simple and hide a lot of the really hard

00:07:01,630 --> 00:07:05,350
things which is a good way to do

00:07:03,580 --> 00:07:07,810
computing it's what computer science is

00:07:05,350 --> 00:07:10,330
all about so the good thing about

00:07:07,810 --> 00:07:13,570
message passing concurrency is that

00:07:10,330 --> 00:07:15,880
message passing removes some of these

00:07:13,570 --> 00:07:18,490
possible faults that you can have with

00:07:15,880 --> 00:07:21,250
locking so you can't have race hazards

00:07:18,490 --> 00:07:23,380
with message passing concurrency but you

00:07:21,250 --> 00:07:26,800
could have deadlock still so you know

00:07:23,380 --> 00:07:28,960
it's not perfect and hopefully if you

00:07:26,800 --> 00:07:31,000
have a good message passing language or

00:07:28,960 --> 00:07:34,150
library then a lot of the difficult

00:07:31,000 --> 00:07:36,810
stuff is hidden away for you in the

00:07:34,150 --> 00:07:41,979
runtime system perhaps or in a library

00:07:36,810 --> 00:07:43,900
so all the cool kids are doing message

00:07:41,979 --> 00:07:45,520
passing at the moment it's an idea

00:07:43,900 --> 00:07:48,669
that's come back around because of

00:07:45,520 --> 00:07:50,889
multi-core and other things so these are

00:07:48,669 --> 00:07:52,870
the next few slides are some examples of

00:07:50,889 --> 00:07:55,419
message passing concurrency in different

00:07:52,870 --> 00:07:57,430
languages so i've already mentioned unix

00:07:55,419 --> 00:08:01,080
and pipes and that's a sort of really

00:07:57,430 --> 00:08:02,979
simple idea of message passing and

00:08:01,080 --> 00:08:06,099
hopefully one most people are familiar

00:08:02,979 --> 00:08:09,520
with so this is a simple sort of hello

00:08:06,099 --> 00:08:12,220
world in go and the syntax here is a

00:08:09,520 --> 00:08:15,460
little maybe a little unfamiliar to

00:08:12,220 --> 00:08:18,310
python people the idea is that here on

00:08:15,460 --> 00:08:20,169
this line we're creating a channel so

00:08:18,310 --> 00:08:23,260
we're creating a new channel that we can

00:08:20,169 --> 00:08:26,889
pass messages around with like our our

00:08:23,260 --> 00:08:30,130
pipe and that'll be bi-directional like

00:08:26,889 --> 00:08:31,930
like a pipe is on the command line this

00:08:30,130 --> 00:08:35,680
thing that looks like a function is a

00:08:31,930 --> 00:08:38,860
function but this special the special

00:08:35,680 --> 00:08:41,469
keyword go in front of it means that

00:08:38,860 --> 00:08:44,380
it's also a go routine so a go routine

00:08:41,469 --> 00:08:46,270
is like a co routine it's a sort of

00:08:44,380 --> 00:08:48,550
lightweight kind of thread it's not a

00:08:46,270 --> 00:08:50,650
thread that's created by the operating

00:08:48,550 --> 00:08:53,380
system so it's much cheaper to create a

00:08:50,650 --> 00:08:54,610
go routine or destroy a go routine than

00:08:53,380 --> 00:08:56,589
an operating system

00:08:54,610 --> 00:08:58,870
read and then what we're doing on this

00:08:56,589 --> 00:09:02,110
line with this sort of funny syntax is

00:08:58,870 --> 00:09:05,680
we're sending the string hello world

00:09:02,110 --> 00:09:07,000
down this channel my channel and then

00:09:05,680 --> 00:09:08,560
we're going to run this go routine

00:09:07,000 --> 00:09:12,000
straightaway so it's going to be running

00:09:08,560 --> 00:09:16,810
in the background of our of our program

00:09:12,000 --> 00:09:19,450
so these sorts of funny bits of syntax

00:09:16,810 --> 00:09:21,820
I'm afraid really pervade this these

00:09:19,450 --> 00:09:24,850
these ideas in languages and you'll see

00:09:21,820 --> 00:09:27,490
a lot of weird syntax the CSP syntax for

00:09:24,850 --> 00:09:30,970
doing this sort of thing is a pling and

00:09:27,490 --> 00:09:34,089
! or to receive something down a channel

00:09:30,970 --> 00:09:36,700
a question mark so it kind of hasn't got

00:09:34,089 --> 00:09:39,490
better through the ages in my view I'm

00:09:36,700 --> 00:09:41,230
afraid so on this line here what we're

00:09:39,490 --> 00:09:42,970
doing is we're receiving something down

00:09:41,230 --> 00:09:44,920
this channel from this channel and

00:09:42,970 --> 00:09:47,529
whatever we receive we're just printing

00:09:44,920 --> 00:09:50,740
out so this is a simple sort of hello

00:09:47,529 --> 00:09:53,470
world in that language rust is another

00:09:50,740 --> 00:09:56,290
new language does similar thing so we've

00:09:53,470 --> 00:09:58,600
got the same sort of idea here we've got

00:09:56,290 --> 00:10:00,370
a channel being created here we've got a

00:09:58,600 --> 00:10:02,170
background process running here where

00:10:00,370 --> 00:10:05,019
we're doing some sending then we're

00:10:02,170 --> 00:10:07,570
receiving this value and printing it out

00:10:05,019 --> 00:10:10,750
what's slightly different with rust is

00:10:07,570 --> 00:10:13,990
that if you are familiar with working

00:10:10,750 --> 00:10:16,209
with pipe unix pipes in c you'll know

00:10:13,990 --> 00:10:18,640
that when you create a unix pipe in see

00:10:16,209 --> 00:10:22,240
what the operating system gives you is

00:10:18,640 --> 00:10:24,160
two ends of the pipe ascending end and a

00:10:22,240 --> 00:10:25,660
receiving end and that's what's

00:10:24,160 --> 00:10:27,579
happening here with rust we got a

00:10:25,660 --> 00:10:29,230
sending end of this channel and we've

00:10:27,579 --> 00:10:31,300
got a receiving end of this channel and

00:10:29,230 --> 00:10:34,269
the idea there is to prevent you from

00:10:31,300 --> 00:10:36,040
doing silly things like sending down the

00:10:34,269 --> 00:10:38,410
receiving end or receiving down the

00:10:36,040 --> 00:10:41,620
sending end so you the programmer in

00:10:38,410 --> 00:10:44,440
must have to decide ahead of time what

00:10:41,620 --> 00:10:46,420
we're in my program am I going to want

00:10:44,440 --> 00:10:47,949
to send down this channel and where am I

00:10:46,420 --> 00:10:49,870
going to want to receive down this

00:10:47,949 --> 00:10:54,430
channel it's something you need to think

00:10:49,870 --> 00:10:57,190
about at compile time so scholar being a

00:10:54,430 --> 00:11:02,550
JVM language is taking up the whole

00:10:57,190 --> 00:11:02,550
screen with its for those braces

00:11:02,880 --> 00:11:09,700
but this is exactly the same sort of

00:11:05,500 --> 00:11:10,990
thing so we have an actor which is

00:11:09,700 --> 00:11:13,240
similar to the sort of background

00:11:10,990 --> 00:11:17,140
processes that we were talking about and

00:11:13,240 --> 00:11:18,700
co routines and so on and we've got this

00:11:17,140 --> 00:11:20,649
slightly backwards here so here we're

00:11:18,700 --> 00:11:23,380
sending so this is really using CSP

00:11:20,649 --> 00:11:25,750
syntax with the pling and in here we're

00:11:23,380 --> 00:11:29,380
receiving something and printing it out

00:11:25,750 --> 00:11:31,810
and Python CSP so Python CSP is my own

00:11:29,380 --> 00:11:34,209
library and some of you in this room

00:11:31,810 --> 00:11:36,490
have been really generous and

00:11:34,209 --> 00:11:40,089
contributing to it particularly stuff on

00:11:36,490 --> 00:11:42,160
over there in previous Europe license so

00:11:40,089 --> 00:11:44,890
this is an attempt at doing something

00:11:42,160 --> 00:11:47,140
like this in a pythonic way for Python

00:11:44,890 --> 00:11:49,870
but built as an add-on to the languages

00:11:47,140 --> 00:11:53,920
along as a library so here we've got to

00:11:49,870 --> 00:11:57,130
CSP processes so we're not saying in the

00:11:53,920 --> 00:12:00,700
code here how those processes are sort

00:11:57,130 --> 00:12:03,160
of verified whether they're co routines

00:12:00,700 --> 00:12:05,170
or threads or operating system processes

00:12:03,160 --> 00:12:07,000
but we've got two processes here that

00:12:05,170 --> 00:12:09,130
can run in parallel with the decorators

00:12:07,000 --> 00:12:11,230
we've got channels that can be shared

00:12:09,130 --> 00:12:13,510
between them and we can read and write

00:12:11,230 --> 00:12:15,610
with those channels and again we're just

00:12:13,510 --> 00:12:19,390
sending hello world printing it out and

00:12:15,610 --> 00:12:22,150
then on this line so this is a much more

00:12:19,390 --> 00:12:24,370
sort of CSP ish way of doing things than

00:12:22,150 --> 00:12:26,050
perhaps the other the other examples

00:12:24,370 --> 00:12:28,630
we're saying well we're going to take

00:12:26,050 --> 00:12:31,510
these two processes and run them in

00:12:28,630 --> 00:12:33,640
parallel and start them off and if we

00:12:31,510 --> 00:12:35,680
had a huge program with many processes

00:12:33,640 --> 00:12:37,930
we might decide well we'll run them all

00:12:35,680 --> 00:12:39,880
in parallel or we might run a few then

00:12:37,930 --> 00:12:41,680
run a few more in sequence whatever we

00:12:39,880 --> 00:12:43,870
whatever we wish so we've got quite a

00:12:41,680 --> 00:12:48,370
lot of flexibility there about how our

00:12:43,870 --> 00:12:51,490
program is sort of put together so this

00:12:48,370 --> 00:12:53,980
last example is by a student of mine Sam

00:12:51,490 --> 00:12:56,020
Giles and what he was looking at was

00:12:53,980 --> 00:12:58,270
really interesting which was can we

00:12:56,020 --> 00:13:01,089
build a language like this that has the

00:12:58,270 --> 00:13:03,399
sort of go or rust style channels and

00:13:01,089 --> 00:13:06,550
concurrence ease on the our Python tool

00:13:03,399 --> 00:13:08,410
chain so can we use the the technology

00:13:06,550 --> 00:13:10,570
that the pipe I team are developed to do

00:13:08,410 --> 00:13:11,710
this so this is exactly the same hello

00:13:10,570 --> 00:13:13,810
world example

00:13:11,710 --> 00:13:16,270
we've got channels here we're going to

00:13:13,810 --> 00:13:18,870
send down that channel a hello world and

00:13:16,270 --> 00:13:23,080
then we've got some sort of unusual

00:13:18,870 --> 00:13:24,820
receive syntax there to receive

00:13:23,080 --> 00:13:28,270
something from the channel and print it

00:13:24,820 --> 00:13:29,800
out and this function here is being run

00:13:28,270 --> 00:13:33,730
in the background as a sort of

00:13:29,800 --> 00:13:35,920
asynchronous co routine so that's a

00:13:33,730 --> 00:13:38,020
really nice project and it's a really

00:13:35,920 --> 00:13:40,420
nice way of working I think obviously

00:13:38,020 --> 00:13:43,060
Sam was a very very good student but I

00:13:40,420 --> 00:13:44,920
think it's a testament to the the good

00:13:43,060 --> 00:13:46,840
engineering of the pipe I team that an

00:13:44,920 --> 00:13:49,540
undergraduate student can produce a

00:13:46,840 --> 00:13:51,970
working language like that in the small

00:13:49,540 --> 00:13:56,200
amount of time for for a final year

00:13:51,970 --> 00:14:00,580
project so I'm not going to talk in

00:13:56,200 --> 00:14:02,610
great detail about optimization and

00:14:00,580 --> 00:14:05,680
speed and efficiency and those sorts of

00:14:02,610 --> 00:14:09,390
those sorts of issues but I just wanted

00:14:05,680 --> 00:14:12,040
to show you quickly one of Sam's

00:14:09,390 --> 00:14:15,370
benchmarks which shows quite nicely that

00:14:12,040 --> 00:14:18,370
with a jit where the tracing it now line

00:14:15,370 --> 00:14:21,100
can perform well compared to other other

00:14:18,370 --> 00:14:23,890
languages of this sort so go here in our

00:14:21,100 --> 00:14:27,850
camp I which is a sort of descendant of

00:14:23,890 --> 00:14:30,010
ockham both compiled languages and now

00:14:27,850 --> 00:14:31,900
line compares pretty pretty reasonably

00:14:30,010 --> 00:14:33,970
well for them and this is only a small

00:14:31,900 --> 00:14:37,030
benchmark so we perhaps shouldn't take

00:14:33,970 --> 00:14:39,400
it as gospel but it's a good indication

00:14:37,030 --> 00:14:43,660
that this sort of way of working might

00:14:39,400 --> 00:14:45,930
might be positive on the other hand I

00:14:43,660 --> 00:14:49,900
haven't got for you here the same

00:14:45,930 --> 00:14:51,940
benchmark with Python CSP but we looked

00:14:49,900 --> 00:14:53,920
at similar things with Python CSP and

00:14:51,940 --> 00:14:57,030
that was engineered very differently so

00:14:53,920 --> 00:15:00,190
I'll talk a little bit more about the

00:14:57,030 --> 00:15:02,800
sort of design decisions that message

00:15:00,190 --> 00:15:04,690
passing concurrency implementers might

00:15:02,800 --> 00:15:07,510
take in the next to the section of the

00:15:04,690 --> 00:15:09,400
talk but what we found with Python CSP

00:15:07,510 --> 00:15:13,150
is that our implementations of channels

00:15:09,400 --> 00:15:16,150
were very very slow very very slow so

00:15:13,150 --> 00:15:18,970
you wouldn't expect I wouldn't expect a

00:15:16,150 --> 00:15:21,280
Python implementation of this to be as

00:15:18,970 --> 00:15:23,760
fast as something like go or kanpai

00:15:21,280 --> 00:15:26,640
that's compiled and has a lot of

00:15:23,760 --> 00:15:29,820
for a lot of engineering going into

00:15:26,640 --> 00:15:33,150
these features but I perhaps wouldn't

00:15:29,820 --> 00:15:35,130
expect I would hope that message passing

00:15:33,150 --> 00:15:37,530
would not be the bottleneck in any

00:15:35,130 --> 00:15:41,760
program and what we actually found was

00:15:37,530 --> 00:15:44,340
that I'll camp I is incredibly fast it's

00:15:41,760 --> 00:15:47,220
designed exactly for this but compared

00:15:44,340 --> 00:15:52,320
to other sorts of interpreted languages

00:15:47,220 --> 00:15:56,550
we looked at JCS p for the JVM thinking

00:15:52,320 --> 00:15:59,070
maybe you know because j CSP is built on

00:15:56,550 --> 00:16:00,930
java threads driver threads are okay but

00:15:59,070 --> 00:16:02,820
you know their operating system threads

00:16:00,930 --> 00:16:04,890
maybe we could get something like that

00:16:02,820 --> 00:16:07,980
performance and we actually got to the

00:16:04,890 --> 00:16:10,050
100 or so times worse and and didn't

00:16:07,980 --> 00:16:13,200
didn't do very well at all so there are

00:16:10,050 --> 00:16:15,240
some lessons learnt there and that

00:16:13,200 --> 00:16:17,250
there's some interesting stories but

00:16:15,240 --> 00:16:19,650
part of the takeaway of this is that

00:16:17,250 --> 00:16:22,710
actually it's very difficult to engineer

00:16:19,650 --> 00:16:25,980
that kind of that kind of performance if

00:16:22,710 --> 00:16:27,390
you're starting from an interpreted

00:16:25,980 --> 00:16:31,050
language that hasn't been built with

00:16:27,390 --> 00:16:34,020
this sort of concurrency in mind so this

00:16:31,050 --> 00:16:36,480
next section of the talk is is all about

00:16:34,020 --> 00:16:40,110
the sorts of varieties of message

00:16:36,480 --> 00:16:42,420
passing concurrency that can be can be

00:16:40,110 --> 00:16:45,390
created and the different decisions that

00:16:42,420 --> 00:16:46,710
an implementer would have to make if

00:16:45,390 --> 00:16:51,210
they were going to implement something

00:16:46,710 --> 00:16:53,610
like this in Python so one choice is

00:16:51,210 --> 00:16:58,500
synchronous channels versus asynchronous

00:16:53,610 --> 00:17:00,360
channels so in the CSP way of thinking

00:16:58,500 --> 00:17:03,860
and in the sort of process eligible way

00:17:00,360 --> 00:17:06,990
of thinking that sort of a mathematical

00:17:03,860 --> 00:17:10,380
formalism the idea is that all channels

00:17:06,990 --> 00:17:12,390
block on reading and writing and you

00:17:10,380 --> 00:17:14,160
don't move forward to the computation

00:17:12,390 --> 00:17:16,949
until you're read or your right is

00:17:14,160 --> 00:17:19,440
finished and some people including me

00:17:16,949 --> 00:17:22,170
think that the nice thing about this is

00:17:19,440 --> 00:17:23,790
it's then very easy to understand what

00:17:22,170 --> 00:17:25,890
your program is doing and reason about

00:17:23,790 --> 00:17:28,290
it because you know exactly in what

00:17:25,890 --> 00:17:30,510
order everything's going to happen you

00:17:28,290 --> 00:17:32,100
know this this piece of code will not

00:17:30,510 --> 00:17:34,530
move forward til it's finished this meat

00:17:32,100 --> 00:17:36,360
and then it'll do this and then all the

00:17:34,530 --> 00:17:40,250
other things that are waiting on it

00:17:36,360 --> 00:17:42,360
we'll be able to move forward as well

00:17:40,250 --> 00:17:44,280
asynchronous channels though are quite

00:17:42,360 --> 00:17:47,040
common as well in different languages

00:17:44,280 --> 00:17:49,290
and some people suggest that they're a

00:17:47,040 --> 00:17:51,360
bit faster and sometimes that seems to

00:17:49,290 --> 00:17:53,760
be true and certainly the benchmark i

00:17:51,360 --> 00:17:56,640
showed you before showed that in that

00:17:53,760 --> 00:17:58,980
particular benchmark sams asynchronous

00:17:56,640 --> 00:18:02,400
channels for now lang were a little bit

00:17:58,980 --> 00:18:04,410
faster than his synchronous ones if you

00:18:02,400 --> 00:18:06,720
do have synchronous channels though you

00:18:04,410 --> 00:18:09,240
need to think a little bit about

00:18:06,720 --> 00:18:11,400
avoiding some of the common problems

00:18:09,240 --> 00:18:14,610
that people have with concurrency like

00:18:11,400 --> 00:18:17,669
starvation and you don't necessarily

00:18:14,610 --> 00:18:19,950
want a process to block for a very long

00:18:17,669 --> 00:18:21,390
time if it doesn't have to sometimes it

00:18:19,950 --> 00:18:23,669
might have to sometimes it might be

00:18:21,390 --> 00:18:25,290
waiting on a long computation but if you

00:18:23,669 --> 00:18:28,020
don't have to block you would probably

00:18:25,290 --> 00:18:30,900
prefer not to so a common feature of

00:18:28,020 --> 00:18:35,299
message passing languages and libraries

00:18:30,900 --> 00:18:38,790
is some way of selecting the next ready

00:18:35,299 --> 00:18:41,220
event to process so if we're thinking in

00:18:38,790 --> 00:18:43,080
terms of events being channels and

00:18:41,220 --> 00:18:44,370
message passing down channels if you

00:18:43,080 --> 00:18:46,710
have a lot of channels that you're

00:18:44,370 --> 00:18:47,910
waiting on and you want to read from so

00:18:46,710 --> 00:18:49,740
for example if you've got a sort of

00:18:47,910 --> 00:18:51,900
MapReduce type problem or a worker

00:18:49,740 --> 00:18:53,790
farmer type problem then you might say

00:18:51,900 --> 00:18:56,990
well give me the one that's ready first

00:18:53,790 --> 00:19:00,660
and that's called alternating instead of

00:18:56,990 --> 00:19:03,330
ockham old-fashioned language or

00:19:00,660 --> 00:19:05,190
selection more generally so you can say

00:19:03,330 --> 00:19:08,400
select for me the channel that's ready

00:19:05,190 --> 00:19:10,830
to read and usually if you're

00:19:08,400 --> 00:19:12,450
implementing that selection you do that

00:19:10,830 --> 00:19:15,570
rather carefully because although you

00:19:12,450 --> 00:19:17,640
might want to select the next most the

00:19:15,570 --> 00:19:20,070
next ready channel to read from if

00:19:17,640 --> 00:19:22,140
you've got a channel that's always ready

00:19:20,070 --> 00:19:23,880
to read from and some that are that are

00:19:22,140 --> 00:19:26,340
taking a little while you don't want

00:19:23,880 --> 00:19:29,850
these other channels to not be processed

00:19:26,340 --> 00:19:33,140
so usually there's a little bit of work

00:19:29,850 --> 00:19:37,470
goes into that to avoid starvation and

00:19:33,140 --> 00:19:38,990
do some good load balancing so that's

00:19:37,470 --> 00:19:41,160
one if you synchronous or asynchronous

00:19:38,990 --> 00:19:44,970
channels or you might say buffered or

00:19:41,160 --> 00:19:48,450
unbuffered channels another issue is are

00:19:44,970 --> 00:19:49,720
your channels bi-directional or are they

00:19:48,450 --> 00:19:53,230
unidirectional

00:19:49,720 --> 00:19:55,900
we saw in rust in rust you get what you

00:19:53,230 --> 00:19:57,880
get in in unix see which is a reed end

00:19:55,900 --> 00:20:01,930
and a right end of a channel and that's

00:19:57,880 --> 00:20:05,770
quite a common way of working with

00:20:01,930 --> 00:20:08,770
channels to avoid Missa avoid some

00:20:05,770 --> 00:20:12,280
mistakes in your in your code if you

00:20:08,770 --> 00:20:14,170
look at the JC SP library which is a

00:20:12,280 --> 00:20:16,180
very nice library because it's been

00:20:14,170 --> 00:20:19,120
engineered very well with a lot of

00:20:16,180 --> 00:20:22,020
thought going into its correctness the

00:20:19,120 --> 00:20:26,500
JC SP library is buried Java like and

00:20:22,020 --> 00:20:28,960
Java people don't mind having thousands

00:20:26,500 --> 00:20:31,510
of classes to choose from and large

00:20:28,960 --> 00:20:34,930
amounts of documentation and they don't

00:20:31,510 --> 00:20:37,570
mind pressing ctrl space in their ID and

00:20:34,930 --> 00:20:41,440
getting a long long long list of things

00:20:37,570 --> 00:20:44,080
and so JCS be sort of works without that

00:20:41,440 --> 00:20:46,750
paradigm and it has lots of different

00:20:44,080 --> 00:20:49,510
channel types that are all classes I

00:20:46,750 --> 00:20:52,780
haven't listed them all because the

00:20:49,510 --> 00:20:54,040
slides are small but so you can have

00:20:52,780 --> 00:20:56,260
things like you can have a one-to-one

00:20:54,040 --> 00:20:58,390
channel that has one reading one writer

00:20:56,260 --> 00:21:00,760
process attached to it at any one time

00:20:58,390 --> 00:21:02,680
you haven't any to any channel that has

00:21:00,760 --> 00:21:05,470
any number attached to them at any time

00:21:02,680 --> 00:21:07,680
and so on and then you always have the

00:21:05,470 --> 00:21:11,410
read end and the right end and that that

00:21:07,680 --> 00:21:14,860
channel wherever you are and the idea

00:21:11,410 --> 00:21:17,710
here is to use the type checker to

00:21:14,860 --> 00:21:21,010
design out a lot of potential faults

00:21:17,710 --> 00:21:24,880
that might creep into your coat so

00:21:21,010 --> 00:21:26,860
that's nice for Java because it fits

00:21:24,880 --> 00:21:28,300
well with the sort of Java way of doing

00:21:26,860 --> 00:21:31,390
things it's what Java people would

00:21:28,300 --> 00:21:34,480
expect so when I wrote Python CSP and

00:21:31,390 --> 00:21:37,120
design that I made all the channels any

00:21:34,480 --> 00:21:39,490
to any channel and I didn't give people

00:21:37,120 --> 00:21:42,070
who read end in a right end I let them

00:21:39,490 --> 00:21:45,190
shoot themselves in the foot because it

00:21:42,070 --> 00:21:47,170
seems to me to be a bit more of a sort

00:21:45,190 --> 00:21:49,960
of dynamic way of doing things and a bit

00:21:47,170 --> 00:21:53,200
more pythonic but not faultless not

00:21:49,960 --> 00:21:55,710
foolproof so those are those are a

00:21:53,200 --> 00:21:59,020
couple of different design choices

00:21:55,710 --> 00:22:01,330
another is mobile or a mobile channels

00:21:59,020 --> 00:22:02,980
so this is something that wasn't built

00:22:01,330 --> 00:22:05,600
into CS peerage

00:22:02,980 --> 00:22:08,840
but it was built into a different price

00:22:05,600 --> 00:22:12,080
of cell to be called called the PI

00:22:08,840 --> 00:22:14,960
calculus by Robin Milner and then the

00:22:12,080 --> 00:22:17,780
Kent the team at Kent University who

00:22:14,960 --> 00:22:19,970
sort of took over the development of our

00:22:17,780 --> 00:22:22,660
camp created aa camp I which sort of

00:22:19,970 --> 00:22:26,240
fused together the PI calculus and the

00:22:22,660 --> 00:22:29,480
CSP way of doing things so a mobile

00:22:26,240 --> 00:22:32,810
channel is a channel that can be sent

00:22:29,480 --> 00:22:36,590
down another channel to a different

00:22:32,810 --> 00:22:39,680
process and the idea of doing that is

00:22:36,590 --> 00:22:42,170
that you can think of your message

00:22:39,680 --> 00:22:45,200
passing program as being like a graph

00:22:42,170 --> 00:22:48,830
where the nodes of the graph are your

00:22:45,200 --> 00:22:50,930
processes and the arcs between processes

00:22:48,830 --> 00:22:55,160
are your channels that link those places

00:22:50,930 --> 00:22:57,770
is together at one time you may wish to

00:22:55,160 --> 00:23:01,100
change the topology of that graph and

00:22:57,770 --> 00:23:04,190
change its shape so two good reasons why

00:23:01,100 --> 00:23:06,620
you might do this one might be a bit to

00:23:04,190 --> 00:23:09,050
do with load balancing if you have a

00:23:06,620 --> 00:23:12,080
computation that split among a lot of

00:23:09,050 --> 00:23:13,700
processes you might find some of them

00:23:12,080 --> 00:23:16,010
are more active than others and you

00:23:13,700 --> 00:23:17,750
might decide to change the load balance

00:23:16,010 --> 00:23:19,760
between them which might also mean

00:23:17,750 --> 00:23:22,340
changing the topology of the graph and

00:23:19,760 --> 00:23:24,680
who's reporting their data back to who

00:23:22,340 --> 00:23:27,800
and who's aggregating the data and so

00:23:24,680 --> 00:23:31,600
forth that's one reason another reason

00:23:27,800 --> 00:23:35,480
might be that you might be running these

00:23:31,600 --> 00:23:37,790
processes across a network so you might

00:23:35,480 --> 00:23:39,950
not only be working with one machine you

00:23:37,790 --> 00:23:42,620
might have some processes farmed out to

00:23:39,950 --> 00:23:45,890
another machine on your network and then

00:23:42,620 --> 00:23:47,720
you might have issues like latency or

00:23:45,890 --> 00:23:51,260
you might have issues like network

00:23:47,720 --> 00:23:54,050
failure or whatever and that might make

00:23:51,260 --> 00:23:57,500
you think well during the running of my

00:23:54,050 --> 00:23:59,870
process my my computation I'd like to

00:23:57,500 --> 00:24:01,610
change the topology to make the most

00:23:59,870 --> 00:24:06,700
efficient use of that network of

00:24:01,610 --> 00:24:09,740
machines so that's one reason so this

00:24:06,700 --> 00:24:13,280
this is this leads to sort of two issues

00:24:09,740 --> 00:24:14,840
mobile channels can be great if you can

00:24:13,280 --> 00:24:16,280
if you can use them really well and

00:24:14,840 --> 00:24:19,700
you've got a good use case for

00:24:16,280 --> 00:24:23,300
if you're in a situation where you you

00:24:19,700 --> 00:24:27,290
need to shut down this network and graph

00:24:23,300 --> 00:24:30,380
of running concurrent processes then you

00:24:27,290 --> 00:24:33,680
need to notify each node in in your

00:24:30,380 --> 00:24:36,590
graph that it needs to shut down and so

00:24:33,680 --> 00:24:38,720
doing that safely is quite an important

00:24:36,590 --> 00:24:41,000
thing to do so in this sort of message

00:24:38,720 --> 00:24:43,010
passing world one way to do this is

00:24:41,000 --> 00:24:45,560
called poisoning which means that you

00:24:43,010 --> 00:24:47,390
tell a channel or the node that decides

00:24:45,560 --> 00:24:50,870
to shut everything down or shut a few

00:24:47,390 --> 00:24:53,180
things down tells a channel or all of

00:24:50,870 --> 00:24:55,070
its channels that it knows about that

00:24:53,180 --> 00:24:57,230
they need to start shutting down and

00:24:55,070 --> 00:25:00,350
they need to propagate the message that

00:24:57,230 --> 00:25:02,750
this program is going to halt and this

00:25:00,350 --> 00:25:05,000
is called poisoning so you poison a

00:25:02,750 --> 00:25:07,370
channel and the idea is that it poisons

00:25:05,000 --> 00:25:09,890
the well of the whole program and each

00:25:07,370 --> 00:25:11,570
process shuts itself down safely and

00:25:09,890 --> 00:25:12,830
that's something that takes a little bit

00:25:11,570 --> 00:25:14,480
of care and a little bit of good

00:25:12,830 --> 00:25:17,540
engineering because you need to think

00:25:14,480 --> 00:25:20,650
well you know if I'm a process and your

00:25:17,540 --> 00:25:24,350
processes and i say i want you to all

00:25:20,650 --> 00:25:26,600
die and then i'm gonna die you know I

00:25:24,350 --> 00:25:29,090
then that that needs to happen in the

00:25:26,600 --> 00:25:34,420
right order if I kill myself first you

00:25:29,090 --> 00:25:38,990
won't know what to do or not who knows

00:25:34,420 --> 00:25:40,690
okay so the other the other we talked

00:25:38,990 --> 00:25:43,610
about channels we talked about mobility

00:25:40,690 --> 00:25:45,740
different sorts of channels the other

00:25:43,610 --> 00:25:47,210
thing is how to represent the processes

00:25:45,740 --> 00:25:53,960
and there are a lot of different choices

00:25:47,210 --> 00:25:58,010
there too so in some languages one CSP

00:25:53,960 --> 00:25:59,750
process is one co routine and that makes

00:25:58,010 --> 00:26:04,540
sense in some paradigm so I think this

00:25:59,750 --> 00:26:06,890
is kind of how and ajs works and that

00:26:04,540 --> 00:26:10,730
least a very fast message passing

00:26:06,890 --> 00:26:13,220
because in the runtime system all those

00:26:10,730 --> 00:26:15,170
processes share memory they're all

00:26:13,220 --> 00:26:17,390
really in the same operating system

00:26:15,170 --> 00:26:19,820
thread so they can do a lot of things

00:26:17,390 --> 00:26:21,770
very very fast and they can pass

00:26:19,820 --> 00:26:24,260
messages down channels very very fast

00:26:21,770 --> 00:26:26,350
but then it's hard to take advantage of

00:26:24,260 --> 00:26:29,090
multi-core if you're all in one thread

00:26:26,350 --> 00:26:31,910
you could have a one-to-one

00:26:29,090 --> 00:26:34,280
being where one CSP process is 10 s

00:26:31,910 --> 00:26:36,890
thread that gives you much slower

00:26:34,280 --> 00:26:39,290
message passing because whoever

00:26:36,890 --> 00:26:40,960
implements that does have to deal with

00:26:39,290 --> 00:26:43,880
locking in all those low level issues

00:26:40,960 --> 00:26:45,680
but then you can start taking advantage

00:26:43,880 --> 00:26:48,590
of the features that your operating

00:26:45,680 --> 00:26:51,890
system has you could make one CSP

00:26:48,590 --> 00:26:54,500
process 10 s process and that's a really

00:26:51,890 --> 00:26:57,380
good choice if you're thinking about

00:26:54,500 --> 00:26:59,510
migrating processes around a network and

00:26:57,380 --> 00:27:01,970
running your code on more than one

00:26:59,510 --> 00:27:05,990
computer at once so they sort of MPI

00:27:01,970 --> 00:27:11,180
style if you're into MPI or you can have

00:27:05,990 --> 00:27:14,840
some sort of multiplexed version of all

00:27:11,180 --> 00:27:17,300
of those options so you have some pros

00:27:14,840 --> 00:27:19,760
at CSP prices that are co routines but

00:27:17,300 --> 00:27:22,490
live inside an OS thread and there are

00:27:19,760 --> 00:27:24,980
other CSP processes that live inside

00:27:22,490 --> 00:27:27,080
another OS thread but are really co

00:27:24,980 --> 00:27:29,600
routines themselves and all sorts of

00:27:27,080 --> 00:27:34,040
combinations there in and this is really

00:27:29,600 --> 00:27:36,350
where why Python CSP was not as fast as

00:27:34,040 --> 00:27:38,240
we'd hoped because we were looking at

00:27:36,350 --> 00:27:40,610
taking advantage of multi-core and the

00:27:38,240 --> 00:27:42,890
network so we were using these sorts of

00:27:40,610 --> 00:27:48,800
one-to-one mappings which are not the

00:27:42,890 --> 00:27:51,850
best in terms of speed so I'm not going

00:27:48,800 --> 00:27:54,920
to talk for a huge amount longer because

00:27:51,850 --> 00:27:58,070
hopefully and we can have a good

00:27:54,920 --> 00:28:03,530
discussion but I wanted to say a little

00:27:58,070 --> 00:28:05,870
bit about message passing in Python so

00:28:03,530 --> 00:28:07,850
there are lots of although we don't have

00:28:05,870 --> 00:28:10,340
although ply thing is not a message

00:28:07,850 --> 00:28:14,210
passing language in the way that go is

00:28:10,340 --> 00:28:17,960
and Rusty's and accurate at all those

00:28:14,210 --> 00:28:20,000
other things Python does sort of have a

00:28:17,960 --> 00:28:24,380
lot of these ideas built into its

00:28:20,000 --> 00:28:27,110
ecosystem and sometimes in libraries

00:28:24,380 --> 00:28:29,570
sometimes in different implementations

00:28:27,110 --> 00:28:31,760
of the interpreter sometimes in all

00:28:29,570 --> 00:28:34,250
sorts of other ways so I was really

00:28:31,760 --> 00:28:36,020
pleased looking through the Europe I

00:28:34,250 --> 00:28:38,480
think schedule to find that actually

00:28:36,020 --> 00:28:41,420
there are a lot of different talks in

00:28:38,480 --> 00:28:42,620
this conference that in some way have

00:28:41,420 --> 00:28:44,300
quite a lot to do

00:28:42,620 --> 00:28:46,660
with the ideas that I've been talking

00:28:44,300 --> 00:28:48,680
about today so not necessarily

00:28:46,660 --> 00:28:50,630
straightforward implementations of

00:28:48,680 --> 00:28:54,080
message passing in the way that Python

00:28:50,630 --> 00:28:56,809
CSP was but they take on some of those

00:28:54,080 --> 00:29:00,470
ideas either by implementing co routines

00:28:56,809 --> 00:29:04,430
or using coatings or using channels and

00:29:00,470 --> 00:29:08,990
so on so in a sense message passing for

00:29:04,430 --> 00:29:13,790
python is already here in a sense and

00:29:08,990 --> 00:29:16,429
also of course in Python 3.4 we have co

00:29:13,790 --> 00:29:19,070
routines built in so there's perhaps a

00:29:16,429 --> 00:29:22,880
big opportunity there to think about

00:29:19,070 --> 00:29:26,600
building these things in to the core of

00:29:22,880 --> 00:29:28,490
the language so if you're interested in

00:29:26,600 --> 00:29:32,030
this stuff then I'd certainly be

00:29:28,490 --> 00:29:34,309
interested in talking to you my next

00:29:32,030 --> 00:29:36,650
steps for this Python CSP has been sort

00:29:34,309 --> 00:29:40,400
of in abeyance for the last three few

00:29:36,650 --> 00:29:43,610
years while my day job is some taken me

00:29:40,400 --> 00:29:46,520
to do different things but high thing

00:29:43,610 --> 00:29:48,980
for the parallel er board will be coming

00:29:46,520 --> 00:29:50,809
out this summer so I've got a project

00:29:48,980 --> 00:29:53,059
working on that this summer starting

00:29:50,809 --> 00:29:56,300
sort of mid-august and we'll be looking

00:29:53,059 --> 00:29:59,260
at nice and hopefully efficient ways of

00:29:56,300 --> 00:30:01,670
using Python for the parallel ER that

00:29:59,260 --> 00:30:04,220
ideally would use message passing in

00:30:01,670 --> 00:30:07,820
some way but we'll see how that works

00:30:04,220 --> 00:30:10,490
out the jury's rather outing on that one

00:30:07,820 --> 00:30:13,220
I'm Python CSP is certainly moving back

00:30:10,490 --> 00:30:16,250
into regular development Sam's language

00:30:13,220 --> 00:30:19,460
now line will be continuing so i'll be

00:30:16,250 --> 00:30:22,040
at the pipe i sprint this Saturday doing

00:30:19,460 --> 00:30:24,200
a little bit more on that and if you are

00:30:22,040 --> 00:30:27,110
interested in this stuff then please do

00:30:24,200 --> 00:30:29,350
come and catch me sometime thank you

00:30:27,110 --> 00:30:29,350
very much

00:30:48,139 --> 00:31:07,860
he had personally fire on the mics on

00:30:51,539 --> 00:31:11,360
either side of the hall hello I have

00:31:07,860 --> 00:31:15,210
seen that we are always a rely on the

00:31:11,360 --> 00:31:19,100
operative system layer for the threads

00:31:15,210 --> 00:31:23,879
or the co routines etc it has been many

00:31:19,100 --> 00:31:25,980
in terms meant on how a processors can

00:31:23,879 --> 00:31:30,899
pass from one to another information

00:31:25,980 --> 00:31:34,950
about besides a a gaseous and all those

00:31:30,899 --> 00:31:37,139
things um yeah so that there's there was

00:31:34,950 --> 00:31:41,070
an interesting development in the open

00:31:37,139 --> 00:31:43,230
MPI library a few years ago when they

00:31:41,070 --> 00:31:45,240
found that their message passing was a

00:31:43,230 --> 00:31:48,419
little bit slower than they would like

00:31:45,240 --> 00:31:50,820
and open mpi people tend to work on

00:31:48,419 --> 00:31:52,919
linux so the Linux kernel brought in a

00:31:50,820 --> 00:31:55,590
new way of doing that which is called

00:31:52,919 --> 00:31:57,990
cross memory attached and the idea of

00:31:55,590 --> 00:32:00,149
cross memory attached I think it is only

00:31:57,990 --> 00:32:01,950
in the next thing now but the idea it is

00:32:00,149 --> 00:32:04,590
that you've got two different operating

00:32:01,950 --> 00:32:06,960
system processes and then rather than

00:32:04,590 --> 00:32:09,059
saying rather than doing what you would

00:32:06,960 --> 00:32:11,909
do in a pipe which is that you copy the

00:32:09,059 --> 00:32:15,620
memory you have you keep the memory in

00:32:11,909 --> 00:32:18,210
one place and then you pass around a

00:32:15,620 --> 00:32:21,299
sort of handle to that memory between

00:32:18,210 --> 00:32:22,980
processes so that's a much quicker way

00:32:21,299 --> 00:32:25,919
of doing it that was built specifically

00:32:22,980 --> 00:32:29,039
for mpi but would possibly be a really

00:32:25,919 --> 00:32:31,019
good way forward for for any other

00:32:29,039 --> 00:32:32,820
implementation like an implementation on

00:32:31,019 --> 00:32:38,549
Python so yeah there's definitely some

00:32:32,820 --> 00:32:41,399
interesting work that hey I wanted to

00:32:38,549 --> 00:32:44,820
ask what the Python csb library provides

00:32:41,399 --> 00:32:48,470
that a seiji event doesn't apart from

00:32:44,820 --> 00:32:48,470
the simpler API

00:32:49,470 --> 00:32:57,910
um well it's a good question it's a

00:32:56,080 --> 00:33:02,110
different API I don't know if it's

00:32:57,910 --> 00:33:06,610
simpler or not Python CSP so they've

00:33:02,110 --> 00:33:08,710
started because I wanted a langport I

00:33:06,610 --> 00:33:11,200
wanted something like this in Python but

00:33:08,710 --> 00:33:14,710
the only things that were available were

00:33:11,200 --> 00:33:17,110
direct ports of the Java JC SP language

00:33:14,710 --> 00:33:21,280
so the idea of this is that it's really

00:33:17,110 --> 00:33:25,810
it's much more similar to a CSP way of

00:33:21,280 --> 00:33:28,060
doing things than anything else so what

00:33:25,810 --> 00:33:30,430
does it provide it provides processes

00:33:28,060 --> 00:33:33,370
which can be ooh which can be various

00:33:30,430 --> 00:33:38,080
sorts of processes it provides channels

00:33:33,370 --> 00:33:41,650
it provides selection alternation it

00:33:38,080 --> 00:33:44,980
provides a small library of built-in

00:33:41,650 --> 00:33:49,330
processes that might be useful so the

00:33:44,980 --> 00:33:51,160
reason for that is that the way that CSP

00:33:49,330 --> 00:33:53,730
people tend to think about this is that

00:33:51,160 --> 00:33:56,980
the more concurrency you have the better

00:33:53,730 --> 00:33:59,740
so rather than saying well I've got my

00:33:56,980 --> 00:34:02,380
nice sequential program how do I split

00:33:59,740 --> 00:34:04,570
it up to make it efficient or concurrent

00:34:02,380 --> 00:34:07,150
or sensible or whatever it is they say

00:34:04,570 --> 00:34:09,820
well you know make everything you

00:34:07,150 --> 00:34:12,400
possibly can concurrent so they tend to

00:34:09,820 --> 00:34:15,370
have libraries of processes that do

00:34:12,400 --> 00:34:17,590
things like have two channels read down

00:34:15,370 --> 00:34:20,440
those to read two numbers from those

00:34:17,590 --> 00:34:24,040
channels add them together and send them

00:34:20,440 --> 00:34:26,169
out down a third channel so a process

00:34:24,040 --> 00:34:28,360
that dust does addition and then a

00:34:26,169 --> 00:34:32,380
process that just does all the other

00:34:28,360 --> 00:34:34,450
arithmetic things so there's support for

00:34:32,380 --> 00:34:36,190
that way of working if that way of

00:34:34,450 --> 00:34:39,610
working is something that's interesting

00:34:36,190 --> 00:34:41,020
to you and I suspect though that that

00:34:39,610 --> 00:34:42,790
way of working is probably only

00:34:41,020 --> 00:34:45,820
interesting to people who are interested

00:34:42,790 --> 00:34:48,400
in CSP for its own sake because it's not

00:34:45,820 --> 00:34:50,380
a terribly pragmatic way of working so I

00:34:48,400 --> 00:34:52,960
mean the answer to your question really

00:34:50,380 --> 00:34:54,760
is it pythons hiss being from it's all

00:34:52,960 --> 00:34:57,250
sort of basic things that you expect of

00:34:54,760 --> 00:34:59,440
a message-passing library it's just a

00:34:57,250 --> 00:35:01,490
matter of how it implements them and how

00:34:59,440 --> 00:35:03,470
well and I think

00:35:01,490 --> 00:35:05,150
we probably score about 5 out of 10 for

00:35:03,470 --> 00:35:12,020
that at the moment but hopefully it'll

00:35:05,150 --> 00:35:14,900
get better so quick question on Python

00:35:12,020 --> 00:35:16,670
CSP and multiple process is it currently

00:35:14,900 --> 00:35:18,850
implemented with multi is disease

00:35:16,670 --> 00:35:21,410
something like multiple processing

00:35:18,850 --> 00:35:23,630
multiprocessing how are you doing the

00:35:21,410 --> 00:35:27,290
the message passing across process is it

00:35:23,630 --> 00:35:29,210
using pickle to serialize them so so

00:35:27,290 --> 00:35:31,610
that we've got two different ways of

00:35:29,210 --> 00:35:33,980
doing it 1-1 with threads and one with

00:35:31,610 --> 00:35:36,710
processes but i didn't use

00:35:33,980 --> 00:35:39,920
multiprocessing i just use OS dot fork

00:35:36,710 --> 00:35:43,160
and that sort of thing so windows is out

00:35:39,920 --> 00:35:47,390
of the question yeah so the idea that

00:35:43,160 --> 00:35:49,250
was that multiprocessing is really built

00:35:47,390 --> 00:35:53,540
for a particular way of working and it

00:35:49,250 --> 00:35:56,690
has a lot of internal code that supports

00:35:53,540 --> 00:35:59,300
that way of working but isn't so useful

00:35:56,690 --> 00:36:01,460
if you want to do things the CSP way so

00:35:59,300 --> 00:36:04,220
for example I think when you when you

00:36:01,460 --> 00:36:06,680
spawn a process in multiprocessing that

00:36:04,220 --> 00:36:10,820
process also spawns a watchdog thread

00:36:06,680 --> 00:36:13,369
for that process but in a CSP library

00:36:10,820 --> 00:36:15,859
you don't need that so the idea is to be

00:36:13,369 --> 00:36:18,140
just a little tiny bit more efficient by

00:36:15,859 --> 00:36:26,060
not having those multiprocessing

00:36:18,140 --> 00:36:29,210
internals I think in reality that if you

00:36:26,060 --> 00:36:30,890
compared a version of Python CSP using

00:36:29,210 --> 00:36:32,810
multiprocessing on one without you

00:36:30,890 --> 00:36:35,750
probably wouldn't find a vast amount of

00:36:32,810 --> 00:36:37,670
difference so you could easily do most

00:36:35,750 --> 00:36:39,950
of these things using multiprocessing

00:36:37,670 --> 00:36:44,600
because you've got pipes in what in in

00:36:39,950 --> 00:36:45,980
the MP library so in that sense python

00:36:44,600 --> 00:36:48,770
has some of these things built in

00:36:45,980 --> 00:36:51,470
already as he use the foot the ice vault

00:36:48,770 --> 00:36:54,920
memory copying to run today message

00:36:51,470 --> 00:36:58,340
passing now to do the processing and

00:36:54,920 --> 00:36:59,869
then I'm Michael and serious okay so I

00:36:58,340 --> 00:37:03,560
think I might know why your message

00:36:59,869 --> 00:37:07,190
passing is the bottle yes I think that's

00:37:03,560 --> 00:37:08,960
a very good yeah absolutely I mean

00:37:07,190 --> 00:37:12,350
something like so shared memory is a

00:37:08,960 --> 00:37:13,820
problem for object passing because you

00:37:12,350 --> 00:37:15,269
still have the question of then who owns

00:37:13,820 --> 00:37:18,339
the reference count

00:37:15,269 --> 00:37:19,980
so some kind of library that could where

00:37:18,339 --> 00:37:22,839
you could have immutable data structures

00:37:19,980 --> 00:37:25,960
where and you you have a convention that

00:37:22,839 --> 00:37:27,579
the receiving channel owns the message

00:37:25,960 --> 00:37:31,269
that's been passed so it's responsible

00:37:27,579 --> 00:37:33,760
for the destruction and then you can

00:37:31,269 --> 00:37:36,970
then you could do reliable message

00:37:33,760 --> 00:37:38,140
passing between between channels yeah I

00:37:36,970 --> 00:37:42,430
think I think that makes a lot of sense

00:37:38,140 --> 00:37:45,339
I mean see so the the version of Python

00:37:42,430 --> 00:37:47,890
CSP that uses OS processes uses sort of

00:37:45,339 --> 00:37:50,710
unique shared memory type things and

00:37:47,890 --> 00:37:53,950
that's still quite slow partly because I

00:37:50,710 --> 00:37:56,079
think shared memory is more efficient

00:37:53,950 --> 00:37:58,839
when you're copying a large amount of

00:37:56,079 --> 00:38:00,760
data or copying data many times see the

00:37:58,839 --> 00:38:03,690
shared memory it's not really intended

00:38:00,760 --> 00:38:06,670
for sort of one-off sends and receives

00:38:03,690 --> 00:38:09,220
which is kind of what you're doing when

00:38:06,670 --> 00:38:11,289
you do a message pass in CSP so it's not

00:38:09,220 --> 00:38:13,240
really the right the right tool for the

00:38:11,289 --> 00:38:22,720
job whereas something like cross memory

00:38:13,240 --> 00:38:25,539
attached might be interesting so where

00:38:22,720 --> 00:38:27,190
do you see the future of message passing

00:38:25,539 --> 00:38:31,599
in Python would it be something like

00:38:27,190 --> 00:38:39,460
pipe is TM or rather something like a

00:38:31,599 --> 00:38:42,039
sink io or so so I think I oh um sort of

00:38:39,460 --> 00:38:44,950
does this kind of thing already but for

00:38:42,039 --> 00:38:47,619
i 0 processes that you want to run in

00:38:44,950 --> 00:38:52,630
the background and for that particular

00:38:47,619 --> 00:38:55,240
use case which is which is great but for

00:38:52,630 --> 00:38:57,220
more general computation I think it

00:38:55,240 --> 00:39:00,849
would be interesting to see message

00:38:57,220 --> 00:39:04,059
passing used together with Python 3.4 co

00:39:00,849 --> 00:39:04,990
routines and see how that goes I think

00:39:04,059 --> 00:39:07,450
that would be a really interesting

00:39:04,990 --> 00:39:10,150
experiment to do and really interesting

00:39:07,450 --> 00:39:13,089
to to benchmark that and see if it could

00:39:10,150 --> 00:39:16,240
get really fast and usable for for those

00:39:13,089 --> 00:39:18,099
sort of you know that as it were the

00:39:16,240 --> 00:39:19,690
ordinary programmer rather than someone

00:39:18,099 --> 00:39:24,910
who's got a particular use case like

00:39:19,690 --> 00:39:28,390
like background i oh so in the pipe is

00:39:24,910 --> 00:39:32,589
TM like would that be any

00:39:28,390 --> 00:39:36,309
any hope so so pipe is TM I is a is a

00:39:32,589 --> 00:39:39,069
fantastic piece of work as I understand

00:39:36,309 --> 00:39:45,910
it the purpose of pipe is TM is to make

00:39:39,069 --> 00:39:48,130
the core interpreter concurrent in a

00:39:45,910 --> 00:39:50,440
sense which means that you can then

00:39:48,130 --> 00:39:52,630
build these high-level sorts of

00:39:50,440 --> 00:39:56,890
concurrency that the programmer would

00:39:52,630 --> 00:39:59,920
see on top of that so I wouldn't expect

00:39:56,890 --> 00:40:02,289
I would expect that I hope pipe is CM is

00:39:59,920 --> 00:40:04,510
really successful I wouldn't expect that

00:40:02,289 --> 00:40:07,000
that would mean that ordinary pipe I

00:40:04,510 --> 00:40:10,299
program is ordinary pike and programmers

00:40:07,000 --> 00:40:12,220
rather use STM in their own applications

00:40:10,299 --> 00:40:14,079
I think that's kind of the wrong level

00:40:12,220 --> 00:40:16,990
of abstraction for the for the

00:40:14,079 --> 00:40:19,569
programmer so I think building message

00:40:16,990 --> 00:40:27,460
passing on top of pipe is TM would be

00:40:19,569 --> 00:40:31,539
would be really interesting yeah I was a

00:40:27,460 --> 00:40:35,380
question already mentioned sectors bison

00:40:31,539 --> 00:40:37,240
did you look into the cobalt intern

00:40:35,380 --> 00:40:39,009
stacker spines they're called task yet

00:40:37,240 --> 00:40:43,589
sand the channels provided best like

00:40:39,009 --> 00:40:48,990
this bison so I didn't quite catch that

00:40:43,589 --> 00:40:50,829
sorry stickers pison is a an alternative

00:40:48,990 --> 00:40:53,380
implementation of the secular I hope

00:40:50,829 --> 00:40:56,710
surprise an interpreter and it already

00:40:53,380 --> 00:40:59,769
provides co routines and channels and

00:40:56,710 --> 00:41:02,710
message passing over these channels and

00:40:59,769 --> 00:41:04,720
did you look into it yeah yeah so so I

00:41:02,710 --> 00:41:06,670
think my understand is that status has a

00:41:04,720 --> 00:41:09,130
different implementation of the Python

00:41:06,670 --> 00:41:16,089
interpreter so it's it's not quite C

00:41:09,130 --> 00:41:19,660
Python which is why status actually it

00:41:16,089 --> 00:41:21,400
is C pizen with some additions listen

00:41:19,660 --> 00:41:24,720
yeah okay with some changes yeah so

00:41:21,400 --> 00:41:28,150
that's fully binary compatible the cyc

00:41:24,720 --> 00:41:30,069
yeah so yeah so I did yeah but that's

00:41:28,150 --> 00:41:37,220
also a really interesting piece of work

00:41:30,069 --> 00:41:39,640
um yeah we do

00:41:37,220 --> 00:41:39,640
less

00:41:54,840 --> 00:41:56,900

YouTube URL: https://www.youtube.com/watch?v=7UIbuwUlE60


