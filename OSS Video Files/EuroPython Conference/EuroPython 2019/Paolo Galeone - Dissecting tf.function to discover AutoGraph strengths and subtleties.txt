Title: Paolo Galeone - Dissecting tf.function to discover AutoGraph strengths and subtleties
Publication date: 2019-09-03
Playlist: EuroPython 2019
Description: 
	"Dissecting tf.function to discover AutoGraph strengths and subtleties
[EuroPython 2019 - Talk - 2019-07-10 - Singapore [PyData track]
[Basel, CH]

By Paolo Galeone

AutoGraph is one of the most exciting new features of Tensorflow 2.0: it allows transforming a subset of Python syntax into its portable, high-performance and language agnostic graph representation bridging the gap between Tensorflow 1.x and the 2.0 release based on eager execution.

Using AutoGraph with the code@tf.fuction/code decorator seems easy, but in practice, writing efficient and correctly graph-convertible code requires to know in detail how AutoGraph and tf.function work.

In particular, knowing how:


A graph is created and when it is re-used;
To deal with functions that create a state;
To correctly use the Tensorflow codetf.Tensor/code object instead of using the Python native types to speed-up the computation;


defines the minimum skill-set required to write correct graph-accelerable code.

The talk will guide you trough AutoGraph and codetf.function/code highlighting all the peculiarities that are worth knowing to build the right skill-set.



License: This video is licensed under the CC BY-NC-SA 3.0 license: https://creativecommons.org/licenses/by-nc-sa/3.0/
Please see our speaker release agreement for details: https://ep2019.europython.eu/events/speaker-release-agreement/
Captions: 
	00:00:03,740 --> 00:00:09,900
everyone in this talk I'm going to show

00:00:07,140 --> 00:00:12,119
you how to design functions they can be

00:00:09,900 --> 00:00:13,559
correctly graph converted they're using

00:00:12,119 --> 00:00:16,520
it through of the most exciting features

00:00:13,559 --> 00:00:20,760
of the new testament floor relays Supino

00:00:16,520 --> 00:00:33,420
autograph and TF function but first let

00:00:20,760 --> 00:00:36,089
me introduce myself so I am publicly

00:00:33,420 --> 00:00:38,339
unit I'm a computer engineer and I do

00:00:36,089 --> 00:00:41,010
computer vision and machine learning for

00:00:38,339 --> 00:00:43,379
a living and I'm literally obsessed with

00:00:41,010 --> 00:00:45,929
tensor flow I started using tensor flow

00:00:43,379 --> 00:00:49,829
as soon as Google released it publicly

00:00:45,929 --> 00:00:51,960
around and November 2005 in 2015

00:00:49,829 --> 00:00:54,089
when I was a research fellow at the

00:00:51,960 --> 00:00:56,460
University of Bologna at the computer of

00:00:54,089 --> 00:01:00,179
visual laboratory and they never stopped

00:00:56,460 --> 00:01:01,739
since none in fact I blog about terms of

00:01:00,179 --> 00:01:04,260
flow you can see the address of my blog

00:01:01,739 --> 00:01:06,060
there I answered class you know on Stack

00:01:04,260 --> 00:01:08,009
Overflow about the tensor flow almost

00:01:06,060 --> 00:01:09,719
daily I brought up in sue software using

00:01:08,009 --> 00:01:12,000
tension flow and I use it as soot flow

00:01:09,719 --> 00:01:14,969
every day at work and for this reason

00:01:12,000 --> 00:01:17,369
Google notice said that is stress strong

00:01:14,969 --> 00:01:18,960
passion and awarded me with the title of

00:01:17,369 --> 00:01:22,829
Google developer expert in machine

00:01:18,960 --> 00:01:25,500
learning so as I mention that I have a

00:01:22,829 --> 00:01:29,159
blog and I invite you to go read it

00:01:25,500 --> 00:01:30,990
mainly because this talk is born from a

00:01:29,159 --> 00:01:34,409
three-part article I brought about

00:01:30,990 --> 00:01:37,679
diffraction and data graph and so after

00:01:34,409 --> 00:01:43,439
this brief introduction we are ready to

00:01:37,679 --> 00:01:45,899
start so in tests of float soup I know

00:01:43,439 --> 00:01:48,060
the concept of graph definition and

00:01:45,899 --> 00:01:50,280
session execution the core of the

00:01:48,060 --> 00:01:53,009
descriptive way of programming use it in

00:01:50,280 --> 00:01:53,789
terms of flow one are disappeared or

00:01:53,009 --> 00:01:56,249
better

00:01:53,789 --> 00:01:59,680
they've been hidin in favor of the

00:01:56,249 --> 00:02:04,240
egress equation again solution as

00:01:59,680 --> 00:02:06,190
every $1 should know is the execution of

00:02:04,240 --> 00:02:08,460
the computation line by line by line

00:02:06,190 --> 00:02:10,960
pure typical of Python

00:02:08,460 --> 00:02:14,260
this new design choice has been made

00:02:10,960 --> 00:02:15,850
with the goal of lower the entry

00:02:14,260 --> 00:02:18,850
barriers making tests offer more

00:02:15,850 --> 00:02:20,470
pythonic and easy to use of course

00:02:18,850 --> 00:02:23,230
there's a skiff enough the computation

00:02:20,470 --> 00:02:25,240
using data flow graphs proper of tensor

00:02:23,230 --> 00:02:28,030
flow one have too many advantages that

00:02:25,240 --> 00:02:31,690
tends to float to math still F for

00:02:28,030 --> 00:02:35,170
instance graphs have a faster execution

00:02:31,690 --> 00:02:38,770
speed are easy to replicate and to

00:02:35,170 --> 00:02:41,320
distribute graph moreover our language

00:02:38,770 --> 00:02:43,510
agnostic representation in fact a graph

00:02:41,320 --> 00:02:46,720
is not a Python program but is a

00:02:43,510 --> 00:02:48,430
description of a computation being an

00:02:46,720 --> 00:02:51,010
obstacle to the language they can be

00:02:48,430 --> 00:02:52,630
creating using Python and then export

00:02:51,010 --> 00:02:55,660
and the end user in any other

00:02:52,630 --> 00:02:57,310
programming language moreover automatic

00:02:55,660 --> 00:02:59,080
differentiation automatic

00:02:57,310 --> 00:03:01,510
differentiation comes almost for free

00:02:59,080 --> 00:03:06,160
when the computation is described using

00:03:01,510 --> 00:03:09,580
graphs so to merge the graph advantages

00:03:06,160 --> 00:03:11,530
proper of 1001 and the ease of use of

00:03:09,580 --> 00:03:20,739
the eager execution tensorflow

00:03:11,530 --> 00:03:23,049
introduced at the TF function and so

00:03:20,739 --> 00:03:26,140
this is the signature of the F function

00:03:23,049 --> 00:03:29,140
and EF action allows you to transform a

00:03:26,140 --> 00:03:30,640
subset of Python syntax into a portable

00:03:29,140 --> 00:03:32,769
and die performance a graph

00:03:30,640 --> 00:03:35,680
representation with AB simple function

00:03:32,769 --> 00:03:37,239
declaration as it can be see from the

00:03:35,680 --> 00:03:40,900
function signature in fact the F

00:03:37,239 --> 00:03:44,590
function is a decorator and uses

00:03:40,900 --> 00:03:46,720
autograph a default autograph lets you

00:03:44,590 --> 00:03:49,420
write a graph code using natural python

00:03:46,720 --> 00:03:51,579
like syntax any particular autograph

00:03:49,420 --> 00:03:54,640
allow you to use a python control flow

00:03:51,579 --> 00:03:57,010
statements like the if as y 4 and so on

00:03:54,640 --> 00:03:59,350
inside the TF function decorated

00:03:57,010 --> 00:04:01,720
function and it ultimately

00:03:59,350 --> 00:04:04,090
automatically converts them into the

00:04:01,720 --> 00:04:07,299
appropriate ends of flow graph nodes for

00:04:04,090 --> 00:04:11,079
instance if statement Python becomes a

00:04:07,299 --> 00:04:13,690
TF cond for loop become TF while and so

00:04:11,079 --> 00:04:16,510
on however in practice

00:04:13,690 --> 00:04:22,870
what happens when a function decorated

00:04:16,510 --> 00:04:24,910
with the F function is called so this is

00:04:22,870 --> 00:04:28,530
a schematic representation of what

00:04:24,910 --> 00:04:31,390
happens and it is a two-phase execution

00:04:28,530 --> 00:04:34,120
in particular the most important thing

00:04:31,390 --> 00:04:36,910
to note it is when a faction decorated

00:04:34,120 --> 00:04:39,130
with the TF action is imported

00:04:36,910 --> 00:04:42,280
eager execution is disabled in that

00:04:39,130 --> 00:04:45,400
context and on the first call the

00:04:42,280 --> 00:04:47,710
function is executed interested been

00:04:45,400 --> 00:04:50,080
eager executed disabled by default every

00:04:47,710 --> 00:04:52,090
TF dot method just defined a TF

00:04:50,080 --> 00:04:54,370
operation they produce a TF tensor

00:04:52,090 --> 00:04:58,510
object as output exactly in the same way

00:04:54,370 --> 00:05:02,620
as tensor flow one is the same except

00:04:58,510 --> 00:05:05,050
behavior at the same time autograft

00:05:02,620 --> 00:05:07,090
starts and is used to detect the Python

00:05:05,050 --> 00:05:08,920
construct that can be converted to the

00:05:07,090 --> 00:05:13,150
graph equivalent so a why it becomes a

00:05:08,920 --> 00:05:16,510
TF while and so on so once gotta read

00:05:13,150 --> 00:05:18,910
all these pieces of information we can

00:05:16,510 --> 00:05:23,050
build the graph so we have the function

00:05:18,910 --> 00:05:25,150
trace autographed representation and so

00:05:23,050 --> 00:05:29,620
since we have to replicate the eager

00:05:25,150 --> 00:05:34,060
execution after every single line what

00:05:29,620 --> 00:05:37,240
happens is that every execution every

00:05:34,060 --> 00:05:39,190
statement is an execution order force at

00:05:37,240 --> 00:05:42,070
a using the terms of flow one that you

00:05:39,190 --> 00:05:43,419
have control dependency statement at the

00:05:42,070 --> 00:05:47,080
end of this process we have built the

00:05:43,419 --> 00:05:49,300
graph then visit on the faction name and

00:05:47,080 --> 00:05:52,110
on the input parameters a unique IDs

00:05:49,300 --> 00:05:55,840
create and it is associated with a graph

00:05:52,110 --> 00:05:59,260
then the graph is placed at the encashed

00:05:55,840 --> 00:06:03,760
into a map so we can just have a map ID

00:05:59,260 --> 00:06:07,360
equal graph any function call then will

00:06:03,760 --> 00:06:08,140
reuse the define that graph only if the

00:06:07,360 --> 00:06:11,980
K matches

00:06:08,140 --> 00:06:14,530
of course since the TF function is a

00:06:11,980 --> 00:06:17,110
decorator if also it forces us to

00:06:14,530 --> 00:06:20,669
organize the code using functions in

00:06:17,110 --> 00:06:23,430
fact functions are the new way of

00:06:20,669 --> 00:06:25,600
executing something new to a session

00:06:23,430 --> 00:06:27,040
now that we have a basic understanding

00:06:25,600 --> 00:06:28,930
of out

00:06:27,040 --> 00:06:30,820
function works we can started using it

00:06:28,930 --> 00:06:33,520
to solve a simple problem and see if

00:06:30,820 --> 00:06:41,200
everything goes as we describe it it

00:06:33,520 --> 00:06:43,600
here so this is a problem the problem is

00:06:41,200 --> 00:06:46,750
really easy it's just a multiplication

00:06:43,600 --> 00:06:49,990
of two constant matrix followed by the

00:06:46,750 --> 00:06:54,280
addition of a scalar variable be really

00:06:49,990 --> 00:06:57,790
really easy so this is the tense of flow

00:06:54,280 --> 00:07:00,100
one solution in terms of flow one we

00:06:57,790 --> 00:07:02,440
have to first describe the computation

00:07:00,100 --> 00:07:04,180
as a graph inside a graph scope by

00:07:02,440 --> 00:07:06,400
default there is a default graph always

00:07:04,180 --> 00:07:10,450
present but in this case we explicitly

00:07:06,400 --> 00:07:12,910
here then we create a special node in we

00:07:10,450 --> 00:07:14,920
with the only goal of initializing the

00:07:12,910 --> 00:07:17,200
variables and everyone familiar with and

00:07:14,920 --> 00:07:20,500
so flow one should have seen that this

00:07:17,200 --> 00:07:22,510
line a thousand of times and then in the

00:07:20,500 --> 00:07:24,430
end we create the session object and

00:07:22,510 --> 00:07:27,010
this is the opposite they received the

00:07:24,430 --> 00:07:30,720
description of the computation the graph

00:07:27,010 --> 00:07:33,160
implicit upon on the coracle outward

00:07:30,720 --> 00:07:34,660
then we can finally use the session

00:07:33,160 --> 00:07:38,680
object to run the computation and

00:07:34,660 --> 00:07:40,750
getting the result so this is the

00:07:38,680 --> 00:07:43,150
standard implementation in terms of Row

00:07:40,750 --> 00:07:45,130
one and the intercept flow to text too

00:07:43,150 --> 00:07:47,910
eager execution the solution of the

00:07:45,130 --> 00:07:50,800
problem is becoming really really easier

00:07:47,910 --> 00:07:52,750
in fact we only have to declare the

00:07:50,800 --> 00:07:55,060
constants and variables and the

00:07:52,750 --> 00:07:57,610
computation is executed directly without

00:07:55,060 --> 00:07:59,110
the need to create a session in order to

00:07:57,610 --> 00:08:00,430
replicate the same behavior of the

00:07:59,110 --> 00:08:03,400
session execution we write the code

00:08:00,430 --> 00:08:05,440
inside a function security in the

00:08:03,400 --> 00:08:07,840
function has in fact the same behavior

00:08:05,440 --> 00:08:10,860
of the previous session doctrine of the

00:08:07,840 --> 00:08:13,990
our top of the node

00:08:10,860 --> 00:08:16,960
the only peculiarity here is that every

00:08:13,990 --> 00:08:19,390
TF operation like the F constant DF

00:08:16,960 --> 00:08:22,090
module and so on produces a TF tensor

00:08:19,390 --> 00:08:24,580
object and not a Python native type or a

00:08:22,090 --> 00:08:26,680
number array therefore for this reason

00:08:24,580 --> 00:08:29,140
as you can see in the last line we have

00:08:26,680 --> 00:08:31,390
to extract from the TF tensor the number

00:08:29,140 --> 00:08:35,500
representation by calling the doctrine

00:08:31,390 --> 00:08:37,780
pipe method we can call the function as

00:08:35,500 --> 00:08:40,419
many times as we want and it works like

00:08:37,780 --> 00:08:43,209
any other Python function so

00:08:40,419 --> 00:08:47,050
right now we have only pure eager

00:08:43,209 --> 00:08:49,750
faction but what happens if we try to

00:08:47,050 --> 00:08:51,579
decorate this function and convert it to

00:08:49,750 --> 00:09:03,579
its graph representation using TF

00:08:51,579 --> 00:09:06,790
function so adding the decorator pretty

00:09:03,579 --> 00:09:09,100
straightforward and of course we might

00:09:06,790 --> 00:09:11,230
expect that since this function work it

00:09:09,100 --> 00:09:13,089
correctly in eager mode we can convert

00:09:11,230 --> 00:09:17,680
it to its Bluff representation just by

00:09:13,089 --> 00:09:19,360
adding the decorator let's try and let's

00:09:17,680 --> 00:09:21,730
see what happens I added the two print

00:09:19,360 --> 00:09:24,430
statements earth-2 before the the return

00:09:21,730 --> 00:09:27,760
statement one it's a print statement

00:09:24,430 --> 00:09:30,070
executed only by Python before the first

00:09:27,760 --> 00:09:32,220
one and the second one is a TF print

00:09:30,070 --> 00:09:34,839
statement that is a node in the graph

00:09:32,220 --> 00:09:44,500
this will help us to understand what's

00:09:34,839 --> 00:09:47,380
going on so this is the first output we

00:09:44,500 --> 00:09:49,420
see on the console and when the function

00:09:47,380 --> 00:09:52,540
is called the process of a graph

00:09:49,420 --> 00:09:54,040
creation starts at this stage only the

00:09:52,540 --> 00:09:56,019
Python code is executed and the

00:09:54,040 --> 00:09:57,880
execution is tray said in order to

00:09:56,019 --> 00:10:00,970
collect the required data to build a

00:09:57,880 --> 00:10:03,459
graph as you can see this is the only

00:10:00,970 --> 00:10:06,910
output we get the TF print call is not

00:10:03,459 --> 00:10:08,589
evaluated since as any other TF method

00:10:06,910 --> 00:10:11,199
tensorflow already knows everything

00:10:08,589 --> 00:10:14,339
about that particular node and therefore

00:10:11,199 --> 00:10:17,529
that is no need to trace their execution

00:10:14,339 --> 00:10:25,750
moving forward we can see the second

00:10:17,529 --> 00:10:27,459
output so we got that exception TF

00:10:25,750 --> 00:10:30,600
function decorating function tried to

00:10:27,459 --> 00:10:33,010
create variables on a node first goal

00:10:30,600 --> 00:10:35,290
but in agrestic yueshen dysfunction

00:10:33,010 --> 00:10:38,139
reported correctly so what's going on

00:10:35,290 --> 00:10:39,970
here the exception of course is a little

00:10:38,139 --> 00:10:42,699
bit misleading since we call it this

00:10:39,970 --> 00:10:46,240
function only once but the TF but the

00:10:42,699 --> 00:10:49,899
exception is called talking about no

00:10:46,240 --> 00:10:52,600
first call but of course they function

00:10:49,899 --> 00:10:54,010
in practice called this function more

00:10:52,600 --> 00:10:56,410
than once a while try

00:10:54,010 --> 00:11:00,250
to trace its execution to create the

00:10:56,410 --> 00:11:01,030
graph but in short as it easy to

00:11:00,250 --> 00:11:02,590
understand

00:11:01,030 --> 00:11:07,780
TF function is complaining about the

00:11:02,590 --> 00:11:10,810
variable object as this first exception

00:11:07,780 --> 00:11:16,510
bring us to our first lesson this talk

00:11:10,810 --> 00:11:18,520
and this is the lesson so TF variable

00:11:16,510 --> 00:11:21,070
object in eager mode is just a Python

00:11:18,520 --> 00:11:23,140
object that gets destroyed as soon as it

00:11:21,070 --> 00:11:25,170
goes after scope and that's why the

00:11:23,140 --> 00:11:28,210
function work is correctly in eager mode

00:11:25,170 --> 00:11:30,610
but a TF variable in a TF decorated

00:11:28,210 --> 00:11:33,400
function is the definition of a node in

00:11:30,610 --> 00:11:37,090
a persistent graph CC since is a eager

00:11:33,400 --> 00:11:39,010
execution is disabled in that context so

00:11:37,090 --> 00:11:40,750
since the graph is persist that we can

00:11:39,010 --> 00:11:44,290
define a variable that every time we

00:11:40,750 --> 00:11:50,650
call a new function and this bring us to

00:11:44,290 --> 00:11:54,340
the solution of the problem the solution

00:11:50,650 --> 00:11:56,710
is to just think about the graph

00:11:54,340 --> 00:11:59,830
definition while defining the function

00:11:56,710 --> 00:12:01,660
so we can declare an variable every time

00:11:59,830 --> 00:12:03,850
the function is called we have to take

00:12:01,660 --> 00:12:05,230
care of this manually declaring a

00:12:03,850 --> 00:12:08,380
variable is a private a private

00:12:05,230 --> 00:12:10,330
attribute of the class F and creating it

00:12:08,380 --> 00:12:12,250
only during the first goal we can

00:12:10,330 --> 00:12:15,550
correctly define a computational graph

00:12:12,250 --> 00:12:20,110
that works as we expect and ensure that

00:12:15,550 --> 00:12:23,260
this bring us to our second lesson the

00:12:20,110 --> 00:12:26,530
second lesson is that eigen function are

00:12:23,260 --> 00:12:28,810
not graph convertible as they are there

00:12:26,530 --> 00:12:30,640
is no guarantee that function the work

00:12:28,810 --> 00:12:32,650
in eager mode our graphical variable

00:12:30,640 --> 00:12:36,480
always defined the function structure

00:12:32,650 --> 00:12:39,940
think about the graph has been built

00:12:36,480 --> 00:12:43,360
okay so this was the first topic of the

00:12:39,940 --> 00:12:45,850
analysis of TF function now we can move

00:12:43,360 --> 00:12:48,460
forward to analyze what happens when the

00:12:45,850 --> 00:12:51,360
input type of a tear function decorated

00:12:48,460 --> 00:12:51,360
function changes

00:12:56,430 --> 00:13:04,240
okay this part of it of the talk is by

00:13:01,930 --> 00:13:06,399
far perhaps the most important part

00:13:04,240 --> 00:13:09,160
since their function should bridge to

00:13:06,399 --> 00:13:11,020
different completely shoo-shoo bridge to

00:13:09,160 --> 00:13:13,690
different completely words in fact

00:13:11,020 --> 00:13:15,670
Python is a dynamically typed language

00:13:13,690 --> 00:13:18,580
where a function can accept any input by

00:13:15,670 --> 00:13:21,550
any input type while tensorflow being a

00:13:18,580 --> 00:13:24,490
C++ library under the hood is a slick T

00:13:21,550 --> 00:13:26,589
statically typed library and every node

00:13:24,490 --> 00:13:32,680
in the graph must have a well-defined at

00:13:26,589 --> 00:13:34,870
the type and also a definite shape so we

00:13:32,680 --> 00:13:36,970
are going to define a function to test

00:13:34,870 --> 00:13:40,440
what's going on when we change the input

00:13:36,970 --> 00:13:45,250
type this is the function is a identity

00:13:40,440 --> 00:13:47,320
and as we can see only one the function

00:13:45,250 --> 00:13:50,170
accept a Python variable X that can be

00:13:47,320 --> 00:13:52,330
literally everything all into we have a

00:13:50,170 --> 00:13:55,240
print function that executes that only

00:13:52,330 --> 00:13:57,399
once during the function tracing on the

00:13:55,240 --> 00:14:00,130
third line we have the TF print function

00:13:57,399 --> 00:14:03,130
that is executed every time the graph is

00:14:00,130 --> 00:14:05,110
evaluated in the end since this is a

00:14:03,130 --> 00:14:13,200
data entity we return the input

00:14:05,110 --> 00:14:16,450
parameter okay this is the first test

00:14:13,200 --> 00:14:18,850
when the input as we can see is a TFT

00:14:16,450 --> 00:14:21,430
answer we expect that the graph is built

00:14:18,850 --> 00:14:23,589
for every different TF tensor the type

00:14:21,430 --> 00:14:26,829
and this should happen of course only

00:14:23,589 --> 00:14:29,410
once and then we have to reuse every

00:14:26,829 --> 00:14:32,500
time we call the same function with the

00:14:29,410 --> 00:14:35,230
same type the same graph created on the

00:14:32,500 --> 00:14:37,180
first call on every second code

00:14:35,230 --> 00:14:39,070
therefore we don't expect to see the

00:14:37,180 --> 00:14:42,450
Python execution line but only the

00:14:39,070 --> 00:14:42,450
output of the graph execution

00:14:47,540 --> 00:14:56,060
as you can see everything when the input

00:14:51,380 --> 00:14:58,430
is a tensor work as we expect and since

00:14:56,060 --> 00:15:00,980
everything is going smoothly we can try

00:14:58,430 --> 00:15:02,990
to deep dive a little bit inside the

00:15:00,980 --> 00:15:04,850
autograph structure and check if the

00:15:02,990 --> 00:15:06,620
graph that is being built after the

00:15:04,850 --> 00:15:09,740
autograph execution at the faction

00:15:06,620 --> 00:15:11,480
tracing is what we think so in short we

00:15:09,740 --> 00:15:14,930
think that we all we should only contain

00:15:11,480 --> 00:15:25,790
that EF print statement and the return

00:15:14,930 --> 00:15:27,830
of the input parameter okay using the TF

00:15:25,790 --> 00:15:29,780
autograph model is it possible to see

00:15:27,830 --> 00:15:32,480
our autograph converts a Python function

00:15:29,780 --> 00:15:35,090
to its graph representation the code of

00:15:32,480 --> 00:15:37,720
course is a mess because it's machine

00:15:35,090 --> 00:15:38,900
generated but we can notice something

00:15:37,720 --> 00:15:49,010
unexpected

00:15:38,900 --> 00:15:52,550
maybe this line this is a little bit

00:15:49,010 --> 00:15:54,830
unexpected in fact there is a reference

00:15:52,550 --> 00:15:58,250
to the Python execution inside the graph

00:15:54,830 --> 00:16:01,570
translation so this is a strange and

00:15:58,250 --> 00:16:08,180
it's not what what we expected when we

00:16:01,570 --> 00:16:11,510
want to just create a graph we can

00:16:08,180 --> 00:16:13,190
analyze only this part and without

00:16:11,510 --> 00:16:15,560
getting too much into the constructor we

00:16:13,190 --> 00:16:17,390
can see that there is the name of the

00:16:15,560 --> 00:16:20,240
function that is Python executed of

00:16:17,390 --> 00:16:22,690
course there is print its argument white

00:16:20,240 --> 00:16:26,180
on execution comics wrap it inside

00:16:22,690 --> 00:16:28,310
control dependency or return the second

00:16:26,180 --> 00:16:31,520
parameter of the autograph converted

00:16:28,310 --> 00:16:35,780
call is the owner and as you can see is

00:16:31,520 --> 00:16:37,970
none this means that there is no package

00:16:35,780 --> 00:16:39,920
known to autograph or tensorflow

00:16:37,970 --> 00:16:45,290
that contains the print function

00:16:39,920 --> 00:16:47,690
definition so in short this line is a

00:16:45,290 --> 00:16:49,850
statement that gets converted to a TF

00:16:47,690 --> 00:16:52,880
new operation and it has the only side

00:16:49,850 --> 00:16:55,100
effect to force the execution order in

00:16:52,880 --> 00:16:58,070
practice we are just coming forcing the

00:16:55,100 --> 00:17:00,740
execution order of the sequence lines in

00:16:58,070 --> 00:17:01,280
the sequel statement after the execution

00:17:00,740 --> 00:17:09,050
of

00:17:01,280 --> 00:17:12,620
TF nope note okay we can see now after

00:17:09,050 --> 00:17:14,660
this short analysis of our function gets

00:17:12,620 --> 00:17:17,000
a graph converted what happens when the

00:17:14,660 --> 00:17:24,770
input is not a TF the answer but is a

00:17:17,000 --> 00:17:26,810
Python native type okay the code is

00:17:24,770 --> 00:17:28,760
similar to the previous one we just

00:17:26,810 --> 00:17:33,860
define it an epic fashion called print

00:17:28,760 --> 00:17:35,270
info to be sure that everything that to

00:17:33,860 --> 00:17:38,330
be sure that we are feeling the correct

00:17:35,270 --> 00:17:39,800
data type to the function since the

00:17:38,330 --> 00:17:43,600
fashion is trivial every aspect of

00:17:39,800 --> 00:17:43,600
course they save behavior we get before

00:17:48,160 --> 00:17:52,730
okay

00:17:49,310 --> 00:17:54,500
as we can see now we can see what

00:17:52,730 --> 00:17:57,140
happens when a Python integral is fed as

00:17:54,500 --> 00:18:01,160
input and something weird is going on

00:17:57,140 --> 00:18:03,470
of course since the pattern execution as

00:18:01,160 --> 00:18:05,570
you can see is displayed not only once

00:18:03,470 --> 00:18:08,360
as we might expect since this is a

00:18:05,570 --> 00:18:11,780
single data type integral but it's

00:18:08,360 --> 00:18:13,400
executed twice the graph therefore is

00:18:11,780 --> 00:18:15,730
barely created at every function

00:18:13,400 --> 00:18:18,950
invocation and this is really weird

00:18:15,730 --> 00:18:21,710
but trust me things are getting even

00:18:18,950 --> 00:18:25,880
worse because now on the first execution

00:18:21,710 --> 00:18:28,460
we have defined two graphs for the one

00:18:25,880 --> 00:18:30,860
value for the two value but what happens

00:18:28,460 --> 00:18:36,440
if we feed now the same value but with a

00:18:30,860 --> 00:18:39,470
different data type so with a float as

00:18:36,440 --> 00:18:42,050
you can see the graph now is not be

00:18:39,470 --> 00:18:45,520
recreated at every invocation but given

00:18:42,050 --> 00:18:48,730
a float input we get an integer output

00:18:45,520 --> 00:18:52,280
so this is no more the identity function

00:18:48,730 --> 00:18:54,800
this is somehow broken in fact the

00:18:52,280 --> 00:18:56,900
return type is wrong and the graph that

00:18:54,800 --> 00:18:58,910
has been built for the integers 1 and

00:18:56,900 --> 00:19:05,720
the integral is being reused for the

00:18:58,910 --> 00:19:08,870
float values 1 and 2 so this e was my

00:19:05,720 --> 00:19:11,300
face when I discovered this so I spent

00:19:08,870 --> 00:19:14,450
some time to figure out was what was

00:19:11,300 --> 00:19:18,830
going on and I summarized that this

00:19:14,450 --> 00:19:26,720
on the next lesson this is lesson number

00:19:18,830 --> 00:19:28,460
three so if function does not

00:19:26,720 --> 00:19:30,860
automatically convert apply tony

00:19:28,460 --> 00:19:33,740
integral to a TF tensor with the d-type

00:19:30,860 --> 00:19:37,100
expected so since the integral in Python

00:19:33,740 --> 00:19:40,520
are 64 bits we expect at TF into 64 and

00:19:37,100 --> 00:19:42,680
so on the graph ID when the input is not

00:19:40,520 --> 00:19:46,910
at EF tensor object is with using the

00:19:42,680 --> 00:19:49,250
variable value not the type this is a

00:19:46,910 --> 00:19:52,190
design choice of the F function outers

00:19:49,250 --> 00:19:54,740
that I don't like that much since it

00:19:52,190 --> 00:19:56,810
makes the graph convention not lateral

00:19:54,740 --> 00:20:00,380
and you have to worry about this

00:19:56,810 --> 00:20:02,210
behavior moreover since this a new graph

00:20:00,380 --> 00:20:06,610
is being recreated for every different

00:20:02,210 --> 00:20:09,080
Python value we have the risk of

00:20:06,610 --> 00:20:12,410
designing a terribly terribly slow

00:20:09,080 --> 00:20:19,280
functions in fact we can see a simple

00:20:12,410 --> 00:20:21,410
performance measurement G is this entity

00:20:19,280 --> 00:20:24,230
fraction here in the first loop G is fed

00:20:21,410 --> 00:20:28,130
with the TF dancer object produced by TF

00:20:24,230 --> 00:20:31,400
range function execution the second

00:20:28,130 --> 00:20:33,380
group is that invokes G with 1000

00:20:31,400 --> 00:20:35,540
different by Tony integers and this

00:20:33,380 --> 00:20:38,480
means that we are building 1000

00:20:35,540 --> 00:20:40,970
different graphs autograph is ugly

00:20:38,480 --> 00:20:42,620
optimized an F works well when the input

00:20:40,970 --> 00:20:47,210
is at the F tensor object as you can see

00:20:42,620 --> 00:20:48,830
from the time a measurement here when it

00:20:47,210 --> 00:20:49,580
creates a new graph of a rebel different

00:20:48,830 --> 00:20:53,240
input parameter

00:20:49,580 --> 00:20:56,030
while the for every different input

00:20:53,240 --> 00:20:58,850
parameter value of while I with huge

00:20:56,030 --> 00:21:05,390
drop in performance and these bring us

00:20:58,850 --> 00:21:08,810
to the first lesson use EF tensor

00:21:05,390 --> 00:21:11,570
everywhere seriously this is the mantra

00:21:08,810 --> 00:21:13,390
to repeat gift answer is not the only

00:21:11,570 --> 00:21:16,880
times of law object that we have to use

00:21:13,390 --> 00:21:19,100
when we are using the F function in fact

00:21:16,880 --> 00:21:21,860
the F function as this well behavior

00:21:19,100 --> 00:21:23,660
when using Python data types but also as

00:21:21,860 --> 00:21:27,250
other where behaviors when using other

00:21:23,660 --> 00:21:27,250
Python and native constructs

00:21:27,570 --> 00:21:33,700
this bring us to the last part of the

00:21:29,980 --> 00:21:38,710
presentation really brief so what

00:21:33,700 --> 00:21:40,570
happens when we just plug plug inside TF

00:21:38,710 --> 00:21:43,360
function to return function some Python

00:21:40,570 --> 00:21:45,850
operator this function works correctly

00:21:43,360 --> 00:21:47,620
in eager mode given the TF tensor leaks

00:21:45,850 --> 00:21:50,049
that all's at the cost and value of one

00:21:47,620 --> 00:21:52,059
we expect to get the output a equal B

00:21:50,049 --> 00:21:52,600
since a and B are the same pattern

00:21:52,059 --> 00:21:56,230
object

00:21:52,600 --> 00:21:57,820
I guess that everyone here should agree

00:21:56,230 --> 00:22:00,570
that the final answer should never be

00:21:57,820 --> 00:22:03,789
rigid because if we feed that a number

00:22:00,570 --> 00:22:07,169
every condition should be satisfied and

00:22:03,789 --> 00:22:10,510
we should never reach there what lines

00:22:07,169 --> 00:22:13,210
but in practice what happens and if we

00:22:10,510 --> 00:22:21,159
execute this this bank-shot this is the

00:22:13,210 --> 00:22:23,530
output but yeah so if in this really

00:22:21,159 --> 00:22:25,690
short there are several problems in the

00:22:23,530 --> 00:22:28,720
function the bigger one that affects

00:22:25,690 --> 00:22:30,760
things will flow from the early races is

00:22:28,720 --> 00:22:33,700
that the Python equal operator is not

00:22:30,760 --> 00:22:36,070
overloaded as a TF equal then the second

00:22:33,700 --> 00:22:38,230
huge problem is that autograph endless

00:22:36,070 --> 00:22:40,450
the conversion of the if a leaf and

00:22:38,230 --> 00:22:42,400
statement but not the combination of the

00:22:40,450 --> 00:22:49,390
boolean expressions they find it using

00:22:42,400 --> 00:22:53,409
the Python visiting operations so in

00:22:49,390 --> 00:22:55,510
short the correct way of writing the

00:22:53,409 --> 00:22:57,820
function is to use the tensorflow

00:22:55,510 --> 00:23:01,530
boolean operators everywhere instead of

00:22:57,820 --> 00:23:04,750
using the Python at the operators and

00:23:01,530 --> 00:23:11,320
this brings us to the last lesson the

00:23:04,750 --> 00:23:13,559
operator lesson is the test of flow

00:23:11,320 --> 00:23:16,360
operators operations everywhere

00:23:13,559 --> 00:23:19,179
seriously otherwise you get that where

00:23:16,360 --> 00:23:24,159
the behaviors completely no sense and

00:23:19,179 --> 00:23:28,510
really hard to debug so we are reaching

00:23:24,159 --> 00:23:31,330
the end and this is a recap of the five

00:23:28,510 --> 00:23:33,549
points so variable and needs a special

00:23:31,330 --> 00:23:35,940
treatment you have to think about the

00:23:33,549 --> 00:23:38,380
graph by designing the function and

00:23:35,940 --> 00:23:40,670
Goethe graph the conversion from eager

00:23:38,380 --> 00:23:42,740
to graph is not as forward

00:23:40,670 --> 00:23:45,950
there is no outer boxing of Python

00:23:42,740 --> 00:23:48,320
Natick types - TF dancer so we have to

00:23:45,950 --> 00:23:49,880
use TF tensor everywhere and also we

00:23:48,320 --> 00:23:57,530
have to use the tensor flow palette or

00:23:49,880 --> 00:24:01,280
explicitly everywhere so this is this is

00:23:57,530 --> 00:24:04,070
the end just I hope you enjoyed the talk

00:24:01,280 --> 00:24:07,400
and I just want to share with you the

00:24:04,070 --> 00:24:09,620
fact that I'm writing a book about the

00:24:07,400 --> 00:24:12,770
so floaty function and neural networks

00:24:09,620 --> 00:24:14,780
and if you want to stay in touch and get

00:24:12,770 --> 00:24:16,880
informative when the book is out or when

00:24:14,780 --> 00:24:20,080
you article about the tension flow or

00:24:16,880 --> 00:24:23,110
the world tense or ecosystem is out just

00:24:20,080 --> 00:24:35,960
leave your email in the subscribe page

00:24:23,110 --> 00:24:38,890
thank you okay we have we have all our

00:24:35,960 --> 00:24:42,760
time this evening to ask you questions

00:24:38,890 --> 00:24:45,770
because it's the last talk in this room

00:24:42,760 --> 00:24:49,160
if no one Minds I would start with one

00:24:45,770 --> 00:24:53,240
question so first please put your slides

00:24:49,160 --> 00:24:55,540
after the talk I really want to

00:24:53,240 --> 00:24:58,310
reproduce the examples you gave us

00:24:55,540 --> 00:25:02,300
because this is what I like about the

00:24:58,310 --> 00:25:04,880
flow like you sometimes get this crazy

00:25:02,300 --> 00:25:10,430
stuff and crazy errors and you have no

00:25:04,880 --> 00:25:15,350
idea what what they mean that was my

00:25:10,430 --> 00:25:18,440
first thought and second what do you

00:25:15,350 --> 00:25:24,410
think the developers of tensorflow

00:25:18,440 --> 00:25:28,220
did they do this on purpose like not how

00:25:24,410 --> 00:25:32,180
I said like all this about less greater

00:25:28,220 --> 00:25:35,720
and equal operators did they do this on

00:25:32,180 --> 00:25:40,220
purpose to not replace them with TF much

00:25:35,720 --> 00:25:43,220
greater and so on so I'm 100% sure that

00:25:40,220 --> 00:25:46,420
TF equal and the underscore underscore

00:25:43,220 --> 00:25:49,640
equal a Python operator has not been

00:25:46,420 --> 00:25:52,730
overloaded because internally the

00:25:49,640 --> 00:25:54,170
African basil they use a TFT answer to

00:25:52,730 --> 00:25:56,480
index

00:25:54,170 --> 00:25:58,580
as I index in the map so they have to be

00:25:56,480 --> 00:26:00,799
a shovel and therefore they can't use

00:25:58,580 --> 00:26:03,140
that EF note equal because the F dot e

00:26:00,799 --> 00:26:05,690
equal Agenor eights annuity FTF

00:26:03,140 --> 00:26:09,320
operation and the four is not something

00:26:05,690 --> 00:26:12,110
a Shabbat and this is the reason for F

00:26:09,320 --> 00:26:15,080
equal the other replacement so for the

00:26:12,110 --> 00:26:18,080
greater lesser and so on they should be

00:26:15,080 --> 00:26:20,240
converted and perhaps they will be

00:26:18,080 --> 00:26:23,660
converted because in the error

00:26:20,240 --> 00:26:26,660
Aleksey they said that of course in the

00:26:23,660 --> 00:26:30,350
future we will handle this comparison

00:26:26,660 --> 00:26:32,660
but since this is a the problem of the

00:26:30,350 --> 00:26:36,910
equal operator perhaps they can't do

00:26:32,660 --> 00:26:41,900
this and they force us to use the F

00:26:36,910 --> 00:26:44,150
boolean operators thank you if you have

00:26:41,900 --> 00:26:48,440
any questions please come to the mic

00:26:44,150 --> 00:26:51,650
because they are not detachable so we

00:26:48,440 --> 00:26:53,770
still have a bit of time for one or two

00:26:51,650 --> 00:26:53,770
questions

00:27:01,040 --> 00:27:06,890
okay then thank you very much for the

00:27:03,600 --> 00:27:13,140
talk and thanks everyone for being here

00:27:06,890 --> 00:27:13,140

YouTube URL: https://www.youtube.com/watch?v=JCpuRWB5BvU


