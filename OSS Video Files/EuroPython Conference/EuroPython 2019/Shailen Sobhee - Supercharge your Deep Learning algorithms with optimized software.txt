Title: Shailen Sobhee - Supercharge your Deep Learning algorithms with optimized software
Publication date: 2019-09-03
Playlist: EuroPython 2019
Description: 
	"Supercharge your Deep Learning algorithms with optimized software
[EuroPython 2019 - Talk - 2019-07-10 - MongoDB  [PyData track]
[Basel, CH]

By Shailen Sobhee

In this talk, you will learn various optimization techniques to improve the runtime performance of your deep learning algorithms on Intel architecture. The presentation will cover how to accelerate the training of your deep neural networks with Tensorflow thanks to the highly optimized Intel® Math Kernel Library (Intel® MKL) and how we boost inferencing with Intel® nGraph and with the Intel® Distribution of OpenVINO™.



License: This video is licensed under the CC BY-NC-SA 3.0 license: https://creativecommons.org/licenses/by-nc-sa/3.0/
Please see our speaker release agreement for details: https://ep2019.europython.eu/events/speaker-release-agreement/
Captions: 
	00:00:02,250 --> 00:00:08,200
thank you very much for being here my

00:00:05,020 --> 00:00:11,320
name is Shallon and I mean AI specialist

00:00:08,200 --> 00:00:13,539
at Intel and internally my title is

00:00:11,320 --> 00:00:15,969
technical consulting engineer where I am

00:00:13,539 --> 00:00:18,480
the link between you guys the end users

00:00:15,969 --> 00:00:23,140
and the core developers who develop

00:00:18,480 --> 00:00:26,289
software that you guys will use so today

00:00:23,140 --> 00:00:30,640
I'm going to show you how we accelerate

00:00:26,289 --> 00:00:33,700
deep learning algorithms and and

00:00:30,640 --> 00:00:37,000
software and I will use a case study a

00:00:33,700 --> 00:00:39,700
real-world case study to to show you

00:00:37,000 --> 00:00:40,990
what we've done so the interesting case

00:00:39,700 --> 00:00:43,240
study that I'm very passionate about

00:00:40,990 --> 00:00:49,950
that I'm involved a lot this year is

00:00:43,240 --> 00:00:53,110
about scanning brain cancer in humans so

00:00:49,950 --> 00:00:59,020
that's the title of today brain tumor

00:00:53,110 --> 00:01:00,610
segmentation using deep learning okay so

00:00:59,020 --> 00:01:05,140
I'm based in Germany and have an

00:01:00,610 --> 00:01:07,630
education from Germany so a brief agenda

00:01:05,140 --> 00:01:10,810
I'm going to describe you the problem

00:01:07,630 --> 00:01:15,490
that we have and how we're trying to

00:01:10,810 --> 00:01:17,350
solve this problem with AI and then I

00:01:15,490 --> 00:01:19,450
will also tell you what software tools

00:01:17,350 --> 00:01:21,700
and packages that we use in order to

00:01:19,450 --> 00:01:25,120
solve this problem and then we have a

00:01:21,700 --> 00:01:27,460
look at some performance numbers what

00:01:25,120 --> 00:01:30,210
you can expect from such a real-world

00:01:27,460 --> 00:01:33,909
case study let's start with some

00:01:30,210 --> 00:01:37,510
statistics as a motivation of why I my

00:01:33,909 --> 00:01:41,890
team and Intel is so passionate and

00:01:37,510 --> 00:01:45,970
involved in this field as per the Gruber

00:01:41,890 --> 00:01:49,180
can it's a world cancer statistics

00:01:45,970 --> 00:01:52,590
research group we found out that there

00:01:49,180 --> 00:01:56,229
are approximately 18 million people

00:01:52,590 --> 00:01:59,080
having cancer so new cancers were

00:01:56,229 --> 00:02:04,240
recorded and if you look at that close

00:01:59,080 --> 00:02:06,729
to half of that number involved people

00:02:04,240 --> 00:02:08,799
dying so if your family is involved in

00:02:06,729 --> 00:02:12,730
there and dying from cancer it's not

00:02:08,799 --> 00:02:14,650
nice so what can we do how can I help in

00:02:12,730 --> 00:02:15,630
there and if you those numbers or just

00:02:14,650 --> 00:02:19,020
in 2000

00:02:15,630 --> 00:02:22,440
18 this year 2019 we can expect similar

00:02:19,020 --> 00:02:26,570
numbers and it's really important to

00:02:22,440 --> 00:02:30,330
diagnose cancer as early as possible and

00:02:26,570 --> 00:02:37,440
find solutions so we can avoid deaths

00:02:30,330 --> 00:02:39,840
right so an introduction to this brain

00:02:37,440 --> 00:02:43,680
tumor topic so there is a technical or

00:02:39,840 --> 00:02:46,740
medical term we use gliomas these are

00:02:43,680 --> 00:02:49,800
the most common occurring types of brain

00:02:46,740 --> 00:02:53,880
tumors and they are very dangerous if

00:02:49,800 --> 00:02:57,330
you have them it can can grow really bad

00:02:53,880 --> 00:03:01,110
and you can die from that and 90% of

00:02:57,330 --> 00:03:06,680
those gliomas belong to a class of

00:03:01,110 --> 00:03:09,690
highly cancerous tumors and to date

00:03:06,680 --> 00:03:11,760
multi sequence MRIs or magnetic

00:03:09,690 --> 00:03:16,350
resonance imaging is like the de-facto

00:03:11,760 --> 00:03:21,410
way to to to screen and diagnose for

00:03:16,350 --> 00:03:23,640
such gliomas and when you do an MRI you

00:03:21,410 --> 00:03:26,490
imagine you know your body your head

00:03:23,640 --> 00:03:29,540
goes into this MRI machine and it takes

00:03:26,490 --> 00:03:32,730
a volumetric 3d scan of your brain and

00:03:29,540 --> 00:03:36,090
for the doctors the challenge to find

00:03:32,730 --> 00:03:38,940
the cancer they have to slice or segment

00:03:36,090 --> 00:03:42,510
that 3d volume and analyze slice by

00:03:38,940 --> 00:03:47,790
slice this is a very time-consuming it's

00:03:42,510 --> 00:03:51,210
an expensive process and but that's a

00:03:47,790 --> 00:03:54,300
very crucial thing so segmenting the

00:03:51,210 --> 00:04:01,790
brain this 3d volume is very important

00:03:54,300 --> 00:04:04,860
and how do you actually fix or cure an

00:04:01,790 --> 00:04:06,870
affected area you can do radiotherapy

00:04:04,860 --> 00:04:10,460
and radiotherapy is actually using a

00:04:06,870 --> 00:04:13,440
laser to grill the the bad cells and

00:04:10,460 --> 00:04:15,660
then another way is actually to actually

00:04:13,440 --> 00:04:18,720
do surgery so you cut the skull and go

00:04:15,660 --> 00:04:20,640
and and remove the bad cells okay I know

00:04:18,720 --> 00:04:22,920
some reactions that's okay sorry about

00:04:20,640 --> 00:04:24,870
that but yeah but in order to do these

00:04:22,920 --> 00:04:28,020
two things you actually have to analyze

00:04:24,870 --> 00:04:29,340
slice by slice of this 3d volume and

00:04:28,020 --> 00:04:33,990
that's why segmentation is

00:04:29,340 --> 00:04:35,820
important now the problem is the

00:04:33,990 --> 00:04:38,610
following and that's the medical trend

00:04:35,820 --> 00:04:41,880
the medical challenge is one fold we

00:04:38,610 --> 00:04:47,639
have a lack of specialized doctors to do

00:04:41,880 --> 00:04:51,090
that and I have a link down there where

00:04:47,639 --> 00:04:53,760
people posted an article about the lack

00:04:51,090 --> 00:04:56,190
of physicians to do to do such kind of

00:04:53,760 --> 00:04:58,050
studies and analysis and the second

00:04:56,190 --> 00:05:01,760
thing this whole process of segmenting

00:04:58,050 --> 00:05:06,510
is time-consuming and very expensive but

00:05:01,760 --> 00:05:09,360
we believe that computers can help so if

00:05:06,510 --> 00:05:12,060
we can automate this process we help

00:05:09,360 --> 00:05:13,740
gain time to the patients to the doctors

00:05:12,060 --> 00:05:17,070
making this whole diagnosis process

00:05:13,740 --> 00:05:19,919
faster and we also improve on the

00:05:17,070 --> 00:05:22,710
segmentation quality the second thing

00:05:19,919 --> 00:05:25,729
where computers can help is in the field

00:05:22,710 --> 00:05:30,840
that we are collecting so much data and

00:05:25,729 --> 00:05:35,070
I got data from 2013 at that time

00:05:30,840 --> 00:05:37,440
approximately 153 exabytes of data were

00:05:35,070 --> 00:05:40,530
collected just in the healthcare sector

00:05:37,440 --> 00:05:43,530
and that number was predicted to grow

00:05:40,530 --> 00:05:45,960
over 2,000 by the year 2020 we are now

00:05:43,530 --> 00:05:48,510
in 2019 I need to check the numbers for

00:05:45,960 --> 00:05:51,650
that bed now you may ask what is an exam

00:05:48,510 --> 00:05:56,639
I tried to give you a perspective that's

00:05:51,650 --> 00:05:58,800
over or close to 250 million DVDs worth

00:05:56,639 --> 00:06:02,820
of information one example and now in

00:05:58,800 --> 00:06:06,870
this year 2019 over two thousand exabyte

00:06:02,820 --> 00:06:08,700
that's a lot of data so having high

00:06:06,870 --> 00:06:11,190
compute power to analyze all of this

00:06:08,700 --> 00:06:17,190
data is great for any great time so this

00:06:11,190 --> 00:06:20,639
is where AI hopefully can help so that's

00:06:17,190 --> 00:06:22,650
the the cred of this talk today and

00:06:20,639 --> 00:06:25,620
let's have a look at the data set that

00:06:22,650 --> 00:06:28,410
we used in order for us to train our

00:06:25,620 --> 00:06:31,139
deep neural network that we used to do

00:06:28,410 --> 00:06:34,320
that so the data set actually comes from

00:06:31,139 --> 00:06:37,229
the brain tumor segmentation of Bharati

00:06:34,320 --> 00:06:38,820
a--'s challenge of 2018 so it's an open

00:06:37,229 --> 00:06:40,380
source dataset provided by the

00:06:38,820 --> 00:06:43,770
University of Pennsylvania

00:06:40,380 --> 00:06:46,740
and the goal for our deep learning

00:06:43,770 --> 00:06:50,490
algorithm is to look at the 3d volumes

00:06:46,740 --> 00:06:54,360
and figure out whether a 3d pixel or

00:06:50,490 --> 00:06:56,850
voxel contains cancer or not so there

00:06:54,360 --> 00:06:59,970
are so healthy tissue or the three types

00:06:56,850 --> 00:07:01,680
of cancers so cancer or no cancer now if

00:06:59,970 --> 00:07:06,950
what cell just to visualize that for you

00:07:01,680 --> 00:07:09,450
it's like that if kind of 3d pixel and

00:07:06,950 --> 00:07:12,680
let's maximize on one of the examples of

00:07:09,450 --> 00:07:15,510
that brain over there so this is it so

00:07:12,680 --> 00:07:17,970
cancer or no cancer and we can color

00:07:15,510 --> 00:07:19,680
label them two different channels on the

00:07:17,970 --> 00:07:23,430
type of cancer that we are looking at

00:07:19,680 --> 00:07:26,930
and I have one flight summary of the

00:07:23,430 --> 00:07:30,480
algorithm we implemented and this is it

00:07:26,930 --> 00:07:32,430
on the complete right we have the input

00:07:30,480 --> 00:07:35,550
image from the machine so that's one

00:07:32,430 --> 00:07:37,710
segment of this MRI scan and then in

00:07:35,550 --> 00:07:40,590
order to train our deep neural network

00:07:37,710 --> 00:07:43,320
we needed label data so a combination of

00:07:40,590 --> 00:07:45,780
this MRI input and what and the middle

00:07:43,320 --> 00:07:48,960
one and that's what the radiologist has

00:07:45,780 --> 00:07:51,150
drawn by looking at the MRI input so he

00:07:48,960 --> 00:07:55,020
has marked the cancer areas and we got

00:07:51,150 --> 00:07:56,940
tons of these input images plus the

00:07:55,020 --> 00:07:59,550
labeled one from the raid from the

00:07:56,940 --> 00:08:02,730
doctor a combination of these two we

00:07:59,550 --> 00:08:05,670
call them a set of labeled data we use

00:08:02,730 --> 00:08:07,890
these two to train our neural network so

00:08:05,670 --> 00:08:12,180
that it can do what we have here the

00:08:07,890 --> 00:08:14,580
predictions or inferred images and this

00:08:12,180 --> 00:08:18,360
is our goal we want our deep neural

00:08:14,580 --> 00:08:21,270
network to start analyzing new patients

00:08:18,360 --> 00:08:23,790
coming in and telling us whether that

00:08:21,270 --> 00:08:26,670
person has a high degree of cancer or

00:08:23,790 --> 00:08:28,830
not where are the cancer areas and so on

00:08:26,670 --> 00:08:32,520
and so forth let's have a look at the

00:08:28,830 --> 00:08:35,729
algorithm used the model in this

00:08:32,520 --> 00:08:39,530
research is a unit model and unit is

00:08:35,729 --> 00:08:43,860
very very popular in the medical sector

00:08:39,530 --> 00:08:46,650
especially for medical imaging and the

00:08:43,860 --> 00:08:48,920
unit neural network looks like a youth

00:08:46,650 --> 00:08:52,119
that's why it's called unit and

00:08:48,920 --> 00:08:54,679
it has lots of convolutions involved and

00:08:52,119 --> 00:08:57,529
a bunch of researchers from the

00:08:54,679 --> 00:08:59,779
University of Freiburg in Germany came

00:08:57,529 --> 00:09:01,579
out with this research and it's really

00:08:59,779 --> 00:09:05,839
great it it's nice it works quite well

00:09:01,579 --> 00:09:07,549
and it it works like an autoencoder so

00:09:05,839 --> 00:09:12,679
one side is encoding and the other side

00:09:07,549 --> 00:09:14,569
is decoding at each stage going for that

00:09:12,679 --> 00:09:17,569
neuron network we're extracting features

00:09:14,569 --> 00:09:20,449
and that's how we can detect at the end

00:09:17,569 --> 00:09:22,639
of the day cancer no concern so

00:09:20,449 --> 00:09:25,009
basically this neuron Network answers

00:09:22,639 --> 00:09:28,910
the question to which class does a

00:09:25,009 --> 00:09:33,199
volumetric pixel or voxel belong cancer

00:09:28,910 --> 00:09:37,189
oh no cancer now you may think all this

00:09:33,199 --> 00:09:40,429
deep learning ai it's complicated well

00:09:37,189 --> 00:09:42,619
not really if you look at the birds

00:09:40,429 --> 00:09:45,319
picture of this whole algorithm how it

00:09:42,619 --> 00:09:47,749
looked like how it looks like is like

00:09:45,319 --> 00:09:50,389
that very simple we have a input data

00:09:47,749 --> 00:09:53,149
set think of this as black boxes input

00:09:50,389 --> 00:09:55,339
data set coming in so label data it goes

00:09:53,149 --> 00:09:57,559
into the neural network then the next

00:09:55,339 --> 00:09:59,419
step is trained that neural network with

00:09:57,559 --> 00:10:02,389
the input data set and once we have that

00:09:59,419 --> 00:10:05,269
we have a trained model job done

00:10:02,389 --> 00:10:08,779
easy-peasy so now we have this trained

00:10:05,269 --> 00:10:11,059
model the new patient comes in and then

00:10:08,779 --> 00:10:15,919
we do inferencing and then we get the

00:10:11,059 --> 00:10:18,019
result so all of this looks great but

00:10:15,919 --> 00:10:22,040
what did we use in order to make this

00:10:18,019 --> 00:10:24,350
happen a bunch of software tools some of

00:10:22,040 --> 00:10:26,419
them the Intel distribution for Python

00:10:24,350 --> 00:10:29,480
for best-in-class Python performance of

00:10:26,419 --> 00:10:32,480
course and then for the neural network

00:10:29,480 --> 00:10:35,660
framework we used tensor flow and since

00:10:32,480 --> 00:10:39,439
then suffer may be painful sometimes we

00:10:35,660 --> 00:10:44,179
leverage chaos as a very nice layer on

00:10:39,439 --> 00:10:47,869
top so making deep learning even easier

00:10:44,179 --> 00:10:50,359
and then however however it is the

00:10:47,869 --> 00:10:54,709
technology by uber it's very interesting

00:10:50,359 --> 00:10:56,989
the car company came up with this piece

00:10:54,709 --> 00:11:00,709
of technology and what does however do

00:10:56,989 --> 00:11:01,490
is actually distributing works it splits

00:11:00,709 --> 00:11:05,990
it

00:11:01,490 --> 00:11:08,149
a job a work into multiple small subsets

00:11:05,990 --> 00:11:10,550
small works and then and distributing

00:11:08,149 --> 00:11:12,529
that work on multiple nodes or machines

00:11:10,550 --> 00:11:14,319
so that they work together and if you

00:11:12,529 --> 00:11:16,429
look at the logo it's like one person

00:11:14,319 --> 00:11:19,009
well however there's actually Russian

00:11:16,429 --> 00:11:20,600
word for a Russian dance and it's like

00:11:19,009 --> 00:11:23,929
one person holding the hand of the other

00:11:20,600 --> 00:11:25,879
person in a circle that's what the logo

00:11:23,929 --> 00:11:27,529
looks like said like the dots are the

00:11:25,879 --> 00:11:30,220
people the heads of the people holding

00:11:27,529 --> 00:11:33,649
hands and this is the key message

00:11:30,220 --> 00:11:35,389
distributed computing one node talking

00:11:33,649 --> 00:11:38,749
to the other node and so on so with all

00:11:35,389 --> 00:11:40,459
of what we split our training process on

00:11:38,749 --> 00:11:43,249
multiple machines so that we could do

00:11:40,459 --> 00:11:46,879
the training of our deep neural network

00:11:43,249 --> 00:11:48,529
faster and then the second stage of the

00:11:46,879 --> 00:11:50,809
training is inferencing how do we do

00:11:48,529 --> 00:11:55,339
inferencing fast is using a tool called

00:11:50,809 --> 00:11:57,110
open window and open window is it's a

00:11:55,339 --> 00:11:59,869
very nice tool that makes inferencing

00:11:57,110 --> 00:12:01,670
easy and fast thanks to its

00:11:59,869 --> 00:12:03,949
optimizations in place in there now

00:12:01,670 --> 00:12:06,679
let's have a look at some numbers I got

00:12:03,949 --> 00:12:11,569
by going through this training process

00:12:06,679 --> 00:12:13,999
now you can imagine we have this MRI

00:12:11,569 --> 00:12:18,110
input coming in from that mesh from that

00:12:13,999 --> 00:12:21,290
MRI device it's it contains high quality

00:12:18,110 --> 00:12:23,929
images it's a huge data set large images

00:12:21,290 --> 00:12:26,839
with lots of detail to train that neural

00:12:23,929 --> 00:12:29,360
network it's very taxing it's very

00:12:26,839 --> 00:12:33,230
intensive for a computer to do all this

00:12:29,360 --> 00:12:37,850
processing so obviously training takes a

00:12:33,230 --> 00:12:41,029
long time and some performance results I

00:12:37,850 --> 00:12:45,139
got complete right when I use tons of

00:12:41,029 --> 00:12:48,379
stock that is from Google and on one

00:12:45,139 --> 00:12:51,319
machine it took me 76 hours to do the

00:12:48,379 --> 00:12:53,990
whole training going for 38 bucks or 30

00:12:51,319 --> 00:12:56,809
times for that neural network I was not

00:12:53,990 --> 00:12:59,540
very happy with 76 hours I thought I

00:12:56,809 --> 00:13:02,569
could do better and of course the next

00:12:59,540 --> 00:13:06,170
step is to actually use a parrot and so

00:13:02,569 --> 00:13:11,470
flew and that's the one which Intel

00:13:06,170 --> 00:13:13,999
optimized and this is the second second

00:13:11,470 --> 00:13:14,760
point in the entire optimist and suffer

00:13:13,999 --> 00:13:17,730
with just

00:13:14,760 --> 00:13:21,450
changing that tensorflow package i

00:13:17,730 --> 00:13:23,820
dropped to almost 50% like better time

00:13:21,450 --> 00:13:26,370
to experiments boost just by using

00:13:23,820 --> 00:13:30,890
software to 43 hours but still I was not

00:13:26,370 --> 00:13:33,180
very happy then I started looking at

00:13:30,890 --> 00:13:36,140
distributed training how can I use

00:13:33,180 --> 00:13:40,680
multiple machines to work together and

00:13:36,140 --> 00:13:44,100
to the training faster so then I looked

00:13:40,680 --> 00:13:46,710
at let's look at that last two parts

00:13:44,100 --> 00:13:49,710
four nodes means four machines with

00:13:46,710 --> 00:13:50,790
HollyRod so eight workers eight workers

00:13:49,710 --> 00:13:56,850
on four machines

00:13:50,790 --> 00:14:00,470
I dropped from 43 43 44 ball park hours

00:13:56,850 --> 00:14:02,790
to 7.5 hours that was great and

00:14:00,470 --> 00:14:06,000
increasing the number of workers to 16

00:14:02,790 --> 00:14:08,070
even better five hours and with our was

00:14:06,000 --> 00:14:09,330
I was more less happy based on that huge

00:14:08,070 --> 00:14:14,520
data said that I had

00:14:09,330 --> 00:14:19,700
so from 76 to 5 the key message there is

00:14:14,520 --> 00:14:19,700
used really optimized software and

00:14:20,120 --> 00:14:24,480
distribute your work and if you have a

00:14:22,410 --> 00:14:26,520
cluster make yourself a cluster why

00:14:24,480 --> 00:14:32,940
should you stick to one machine when you

00:14:26,520 --> 00:14:34,890
can make use of multiple machines so use

00:14:32,940 --> 00:14:38,850
better software of course looking at

00:14:34,890 --> 00:14:41,490
just one node from 76 to 43 for me that

00:14:38,850 --> 00:14:45,150
was mine blowing I really appreciated

00:14:41,490 --> 00:14:47,070
that so without much work from me it's

00:14:45,150 --> 00:14:49,380
leveraging just better software now

00:14:47,070 --> 00:14:51,960
plugging all of this in a big picture

00:14:49,380 --> 00:14:55,340
this is how it looks like on top what I

00:14:51,960 --> 00:14:58,620
wanted to do solve a medical problem

00:14:55,340 --> 00:15:01,230
this was my software stack involved and

00:14:58,620 --> 00:15:03,270
now you may also K what was what is this

00:15:01,230 --> 00:15:06,060
Intel optimized tensorflow

00:15:03,270 --> 00:15:07,950
it is the same types of flow code that

00:15:06,060 --> 00:15:10,920
Google releases and what we do we take

00:15:07,950 --> 00:15:13,320
this code and we plug in our performance

00:15:10,920 --> 00:15:16,650
library in there so this performance

00:15:13,320 --> 00:15:19,020
library it will loves math so my unit

00:15:16,650 --> 00:15:23,190
network does a lot of math intensive

00:15:19,020 --> 00:15:25,050
operations and that library the Intel

00:15:23,190 --> 00:15:25,770
math kernal library for deep neural

00:15:25,050 --> 00:15:28,080
networks

00:15:25,770 --> 00:15:28,680
it loves math whenever it sees much say

00:15:28,080 --> 00:15:33,079
yes

00:15:28,680 --> 00:15:36,839
so then it boosts all those math heavy

00:15:33,079 --> 00:15:38,430
computations so that I could do my

00:15:36,839 --> 00:15:40,470
training faster as you can see the

00:15:38,430 --> 00:15:44,269
numbers that are collected and of course

00:15:40,470 --> 00:15:47,249
I leveraged best-in-class Intel Xeon

00:15:44,269 --> 00:15:50,089
processors in order to do that and you

00:15:47,249 --> 00:15:55,949
saw I had four nodes or four machines

00:15:50,089 --> 00:15:57,779
fog Xeon processors and so I could do

00:15:55,949 --> 00:15:59,819
training faster and I said actually when

00:15:57,779 --> 00:16:01,740
I said one node one processor no it was

00:15:59,819 --> 00:16:05,220
actually two sockets so two physical

00:16:01,740 --> 00:16:07,709
exam processors on one motherboard so I

00:16:05,220 --> 00:16:10,949
had eight physical processors working

00:16:07,709 --> 00:16:17,100
together to give me close to five hours

00:16:10,949 --> 00:16:21,509
dropping from 76 so now you have seen

00:16:17,100 --> 00:16:25,920
that only one slice was being inferred

00:16:21,509 --> 00:16:28,800
so imagine now for that 3d volume that

00:16:25,920 --> 00:16:31,199
came in every slice is being analyzed if

00:16:28,800 --> 00:16:31,829
you had to have a doctor to analyze one

00:16:31,199 --> 00:16:33,360
by one

00:16:31,829 --> 00:16:36,269
that's three expensive time consuming

00:16:33,360 --> 00:16:38,959
it's the doctor may say oh that's too

00:16:36,269 --> 00:16:41,959
much and that's just for one patient and

00:16:38,959 --> 00:16:44,220
AI algorithm doing that for you isn't

00:16:41,959 --> 00:16:45,870
obviously much better easier for

00:16:44,220 --> 00:16:48,269
everybody for the patient for the doctor

00:16:45,870 --> 00:16:52,559
and if you are curious how all of these

00:16:48,269 --> 00:16:55,100
plugs and into afridi this is how I got

00:16:52,559 --> 00:17:01,470
there I used this software called mango

00:16:55,100 --> 00:17:05,339
to draw this 3d volume and that's the

00:17:01,470 --> 00:17:07,140
MRI brain originally and you can see all

00:17:05,339 --> 00:17:10,799
the slices stuck together and it gets

00:17:07,140 --> 00:17:13,470
the volume of cancer there and for the

00:17:10,799 --> 00:17:15,659
doctor who was the radiotherapy or even

00:17:13,470 --> 00:17:18,419
surgery to cut the skull and go there he

00:17:15,659 --> 00:17:20,610
needs to know exactly where all the bad

00:17:18,419 --> 00:17:22,199
cells otherwise he made just for good

00:17:20,610 --> 00:17:28,430
cells and the person goes into coma

00:17:22,199 --> 00:17:31,490
something that so breakfast stuff

00:17:28,430 --> 00:17:33,770
now if you're curious also this whole

00:17:31,490 --> 00:17:36,740
source code and the data that is all

00:17:33,770 --> 00:17:38,660
open source even the AI software tools

00:17:36,740 --> 00:17:40,430
that I showed you from that slide

00:17:38,660 --> 00:17:42,650
earlier that's office tag they are all

00:17:40,430 --> 00:17:44,840
open source and this is entice

00:17:42,650 --> 00:17:47,360
commitment to AI we're going open source

00:17:44,840 --> 00:17:48,770
free software free tools and if you want

00:17:47,360 --> 00:17:49,940
to have a look at my code as well

00:17:48,770 --> 00:17:52,460
especially if you're in the medical

00:17:49,940 --> 00:17:55,010
field I published all my work on my

00:17:52,460 --> 00:17:57,890
github and that's the link there and you

00:17:55,010 --> 00:18:01,190
have instructions on how to get all the

00:17:57,890 --> 00:18:03,410
data set and not to get started and and

00:18:01,190 --> 00:18:07,340
play around you can also reach out to me

00:18:03,410 --> 00:18:11,120
so there's from at github you can get to

00:18:07,340 --> 00:18:11,660
me and that's it thank you very much for

00:18:11,120 --> 00:18:13,940
your attention

00:18:11,660 --> 00:18:21,349
I'm open to questions

00:18:13,940 --> 00:18:21,349
[Applause]

00:18:27,070 --> 00:18:33,110
could you use a microphone because it's

00:18:29,390 --> 00:18:35,330
being recorded it's easier than sorry

00:18:33,110 --> 00:18:37,430
what is the difference between horev and

00:18:35,330 --> 00:18:39,350
in spark because you talked about the

00:18:37,430 --> 00:18:40,850
workers and nodes and all that kind of

00:18:39,350 --> 00:18:44,110
stuff okay

00:18:40,850 --> 00:18:49,730
well so in the SPARC architecture

00:18:44,110 --> 00:18:56,960
leveraging Hadoop and so on so however

00:18:49,730 --> 00:19:00,380
is a pure MPI based package of programs

00:18:56,960 --> 00:19:02,990
so what it's doing is splitting my work

00:19:00,380 --> 00:19:05,630
into MPI processes and sending it to

00:19:02,990 --> 00:19:07,940
native nodes so there's no spark

00:19:05,630 --> 00:19:10,700
involved in there if you would be using

00:19:07,940 --> 00:19:12,860
spark we have another solution it's

00:19:10,700 --> 00:19:15,950
called big deal which is also a spark

00:19:12,860 --> 00:19:17,930
application and with big deal you could

00:19:15,950 --> 00:19:21,290
do the same thing

00:19:17,930 --> 00:19:22,820
splitting work in multiple chunks over

00:19:21,290 --> 00:19:26,240
several Hadoop nodes

00:19:22,820 --> 00:19:32,270
oh yeah and that's the main difference

00:19:26,240 --> 00:19:33,680
so on a native cluster you're the

00:19:32,270 --> 00:19:36,590
Secretary's part because you don't have

00:19:33,680 --> 00:19:39,520
the software stack there and in this

00:19:36,590 --> 00:19:39,520
case you will be over

00:19:44,570 --> 00:19:54,390
one more have you tried other unit

00:19:52,290 --> 00:19:58,559
architectures or just one for this

00:19:54,390 --> 00:20:03,330
experiment very good question so this

00:19:58,559 --> 00:20:07,140
example here is the 2d unit model we

00:20:03,330 --> 00:20:10,980
have also tried the free D unit and if

00:20:07,140 --> 00:20:13,799
you go to my github which I will just

00:20:10,980 --> 00:20:15,960
move here so you guys who are really

00:20:13,799 --> 00:20:21,720
curious I totally recommend you please

00:20:15,960 --> 00:20:26,540
do that go there and you will also have

00:20:21,720 --> 00:20:29,760
my horrid code in place with my cursor

00:20:26,540 --> 00:20:34,030
so this is the 2d version leveraging the

00:20:29,760 --> 00:20:36,679
2d unit and I also have 3d unit and

00:20:34,030 --> 00:20:39,240
[Music]

00:20:36,679 --> 00:20:43,350
training with Harvard all the code is

00:20:39,240 --> 00:20:48,679
there that's really nice so yeah I've

00:20:43,350 --> 00:20:52,110
tried 2d and 3d unit thanks

00:20:48,679 --> 00:20:54,900
any other questions curious about

00:20:52,110 --> 00:20:56,490
anything any Intel software tools

00:20:54,900 --> 00:20:58,230
technologies that prove that you know

00:20:56,490 --> 00:21:07,800
cause me any questions I can answer them

00:20:58,230 --> 00:21:12,860
hopefully finds the Cancer Research this

00:21:07,800 --> 00:21:15,570
is just to demonstrate the capabilities

00:21:12,860 --> 00:21:19,440
ok the question is who funds the Cancer

00:21:15,570 --> 00:21:22,980
Research this stuff is done by us only

00:21:19,440 --> 00:21:26,640
so it's coming from our own motivation

00:21:22,980 --> 00:21:30,660
to try to solve something we have

00:21:26,640 --> 00:21:32,940
partners helping us or even taking this

00:21:30,660 --> 00:21:35,820
code and using that but there's no

00:21:32,940 --> 00:21:37,880
external funding if that's what you were

00:21:35,820 --> 00:21:37,880
referring

00:21:41,870 --> 00:21:45,840
so if there's no more questions let's

00:21:43,400 --> 00:21:52,700
thank the speaker one more time

00:21:45,840 --> 00:21:52,700

YouTube URL: https://www.youtube.com/watch?v=OIyFQXg_uIU


