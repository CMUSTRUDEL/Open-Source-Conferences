Title: Alejandro Saucedo - The state of Machine Learning Operations in 2019
Publication date: 2019-09-23
Playlist: EuroPython 2019
Description: 
	"The state of Machine Learning Operations in 2019
[EuroPython 2019 - Talk - 2019-07-11 - Singapore [PyData track]
[Basel, CH]

By Alejandro Saucedo

This talk will provide an overview of the key challenges and trends in the productization of machine learning systems, including concepts such as reproducibility, explainability and orchestration. The talk will also provide a high level overview of several key open source tools and frameworks available to tackle these issues, which have been identifyed putting together the Awesome Machine Learning Operations list (https://github.com/EthicalML/awesome-machine-learning-operations). 

The key concepts that will be covered are:
* Reproducibility 
* Explainability
* Orchestration of models

The reproducibility piece will cover key motivations as well as practical requirements for model versioning, together with tools that allow data scientists to achieve version control of model+config+data to ensure full model lineage.

The explainability piece will contain a high level overview of why this has become an important topic in machine learning, including the high profile incidents that tech companies have experienced where undesired biases have slipped into data. This will also include a high level overview of some of the tools available.

Finally, the orchestration piece will cover some of the fundamental challenges with large scale serving of models, together with some of the key tools that are available to ensure this challenge can be tackled.



License: This video is licensed under the CC BY-NC-SA 3.0 license: https://creativecommons.org/licenses/by-nc-sa/3.0/
Please see our speaker release agreement for details: https://ep2019.europython.eu/events/speaker-release-agreement/
Captions: 
	00:00:02,930 --> 00:00:11,870
all right so I think we're gonna get

00:00:07,880 --> 00:00:13,570
started so thank you very much to

00:00:11,870 --> 00:00:16,939
everybody for coming I'm quite excited

00:00:13,570 --> 00:00:19,220
today to give you an insight of the

00:00:16,939 --> 00:00:22,730
state of production machine learning in

00:00:19,220 --> 00:00:25,610
2018 this talk is going to be a

00:00:22,730 --> 00:00:28,520
high-level overview of the ecosystem and

00:00:25,610 --> 00:00:31,940
is going to tackle and undyed into three

00:00:28,520 --> 00:00:35,060
key areas the ones that I personally am

00:00:31,940 --> 00:00:38,360
focusing the most so to tell you a bit

00:00:35,060 --> 00:00:39,829
more about myself I am currently the

00:00:38,360 --> 00:00:42,200
chief scientist at the Institute for

00:00:39,829 --> 00:00:44,690
ethically ion machine learning and also

00:00:42,200 --> 00:00:47,780
engineering director at this open source

00:00:44,690 --> 00:00:51,590
open course startup called Selden

00:00:47,780 --> 00:00:54,680
technologies based in London to tell me

00:00:51,590 --> 00:00:58,239
more about both of my roles with the

00:00:54,680 --> 00:01:01,160
Institute I focus primarily on creating

00:00:58,239 --> 00:01:04,579
standards as well as open source

00:01:01,160 --> 00:01:08,240
frameworks that ensure people have the

00:01:04,579 --> 00:01:10,880
right tools and infrastructure to align

00:01:08,240 --> 00:01:13,070
with all those ethical principles that

00:01:10,880 --> 00:01:15,440
are coming out as well as industry

00:01:13,070 --> 00:01:17,570
standards so it basically asks the

00:01:15,440 --> 00:01:20,240
question of what is the infrastructure

00:01:17,570 --> 00:01:22,549
required so that reality matches

00:01:20,240 --> 00:01:25,250
expectation if there's a regulation like

00:01:22,549 --> 00:01:27,470
gdpr that demands the right to explain

00:01:25,250 --> 00:01:29,270
ability it's really questioning what

00:01:27,470 --> 00:01:31,460
does that mean from an infrastructure

00:01:29,270 --> 00:01:35,320
level and what would it be required to

00:01:31,460 --> 00:01:39,020
even enforce it and then from the

00:01:35,320 --> 00:01:40,280
day-to-day so I lead the machine

00:01:39,020 --> 00:01:43,580
learning engineering department at

00:01:40,280 --> 00:01:45,500
Selden Selden is an open-source machine

00:01:43,580 --> 00:01:47,299
learning orchestration library so you

00:01:45,500 --> 00:01:49,820
would basically use Selden if you want

00:01:47,299 --> 00:01:51,860
to deploy models in kubernetes and

00:01:49,820 --> 00:01:53,270
basically manage you know hundreds or

00:01:51,860 --> 00:01:55,100
thousands of models in production and

00:01:53,270 --> 00:01:58,220
some of the examples that I'm gonna be

00:01:55,100 --> 00:02:00,170
diving on are actually going to be using

00:01:58,220 --> 00:02:02,930
some of our open source tools you can

00:02:00,170 --> 00:02:06,170
find the slides as well as everything

00:02:02,930 --> 00:02:09,409
that we're using in that link on the top

00:02:06,170 --> 00:02:11,840
right corner the link is gonna be there

00:02:09,409 --> 00:02:15,019
so you know don't rush to take to take a

00:02:11,840 --> 00:02:16,790
picture so let's get started

00:02:15,019 --> 00:02:18,379
in terms of small data science

00:02:16,790 --> 00:02:20,870
project and just data science projects

00:02:18,379 --> 00:02:22,310
in general they tend to boil down into

00:02:20,870 --> 00:02:24,739
two different steps

00:02:22,310 --> 00:02:28,400
the first one is model development the

00:02:24,739 --> 00:02:29,840
second one is model serving in the first

00:02:28,400 --> 00:02:31,400
one you know the standard steps that you

00:02:29,840 --> 00:02:33,470
would go through is basically getting

00:02:31,400 --> 00:02:35,659
some data you know cleaning the data

00:02:33,470 --> 00:02:38,870
based on some knowledge defining some

00:02:35,659 --> 00:02:40,459
features to transform the data then

00:02:38,870 --> 00:02:43,189
selecting a set of models with hyper

00:02:40,459 --> 00:02:46,069
parameters and then with your scoring

00:02:43,189 --> 00:02:49,400
metrics you would then iterate many many

00:02:46,069 --> 00:02:52,250
times until you're happy and once you're

00:02:49,400 --> 00:02:54,079
happy with the results of what of the

00:02:52,250 --> 00:02:56,569
model that you've built you would want

00:02:54,079 --> 00:02:57,980
to persist this model and then you would

00:02:56,569 --> 00:03:00,260
go to the next step which is you serve

00:02:57,980 --> 00:03:02,269
it in production that's when unseen data

00:03:00,260 --> 00:03:05,169
is gonna go pass through the model and

00:03:02,269 --> 00:03:08,299
you're gonna get predictions and

00:03:05,169 --> 00:03:09,889
inference on that new data that is

00:03:08,299 --> 00:03:12,139
basically you know a very big

00:03:09,889 --> 00:03:14,980
simplification but you know we're gonna

00:03:12,139 --> 00:03:17,720
be using this throughout the talk

00:03:14,980 --> 00:03:19,909
however as your data science

00:03:17,720 --> 00:03:21,799
requirements grow you know we face new

00:03:19,909 --> 00:03:23,930
issues you know it's not just as simple

00:03:21,799 --> 00:03:26,959
as you keeping track of the features and

00:03:23,930 --> 00:03:29,659
and the different algorithms that you

00:03:26,959 --> 00:03:31,940
use at every single stage you know you

00:03:29,659 --> 00:03:34,669
have an increasing complexity on the

00:03:31,940 --> 00:03:37,459
flow of your data right you perhaps had

00:03:34,669 --> 00:03:39,530
a few cron jobs running the models that

00:03:37,459 --> 00:03:42,379
you pushed in production and now that

00:03:39,530 --> 00:03:44,959
you have quite a few you go into a cron

00:03:42,379 --> 00:03:47,989
job he'll write I mean I don't know who

00:03:44,959 --> 00:03:51,530
uses that you know color palette for the

00:03:47,989 --> 00:03:54,250
terminal but I guess each data scientist

00:03:51,530 --> 00:03:56,000
has their own set of tools you know some

00:03:54,250 --> 00:03:59,180
hard tensorflow

00:03:56,000 --> 00:04:01,849
you know some loves our spark you know

00:03:59,180 --> 00:04:03,769
you name it and you know good luck

00:04:01,849 --> 00:04:06,199
trying to take them away not just

00:04:03,769 --> 00:04:08,840
because they just really like them but

00:04:06,199 --> 00:04:11,180
also because some are more useful for

00:04:08,840 --> 00:04:13,009
certain jobs than others so you're gonna

00:04:11,180 --> 00:04:15,109
see a lot of different things that are

00:04:13,009 --> 00:04:16,970
gonna have to put in production serving

00:04:15,109 --> 00:04:19,340
models also becomes increasingly harder

00:04:16,970 --> 00:04:22,789
so you actually have multiple different

00:04:19,340 --> 00:04:24,830
stages that have their own complexities

00:04:22,789 --> 00:04:26,659
in themselves you know building models

00:04:24,830 --> 00:04:29,100
high parameter tuning those in

00:04:26,659 --> 00:04:32,580
themselves become you know one one

00:04:29,100 --> 00:04:34,200
big theme on the Psalms and then when

00:04:32,580 --> 00:04:35,820
stuff goes wrong you know it's actually

00:04:34,200 --> 00:04:37,890
hard to trace back right if something

00:04:35,820 --> 00:04:39,600
goes bad at production you know I said

00:04:37,890 --> 00:04:41,880
because of the bait Engineering's

00:04:39,600 --> 00:04:44,040
piece or the data scientists or the

00:04:41,880 --> 00:04:45,750
software engineer right you always have

00:04:44,040 --> 00:04:48,720
like that the Spider Man you know

00:04:45,750 --> 00:04:50,130
pointing fingers so basically what we

00:04:48,720 --> 00:04:53,370
boil down from there is that as you're

00:04:50,130 --> 00:04:56,070
technical functions grow so should your

00:04:53,370 --> 00:04:58,800
infrastructure and this is what we refer

00:04:56,070 --> 00:05:00,930
to today as machine learning operations

00:04:58,800 --> 00:05:03,420
or just production machine learning

00:05:00,930 --> 00:05:05,370
concepts in this case you know it is it

00:05:03,420 --> 00:05:08,400
is that green layer that involves that

00:05:05,370 --> 00:05:11,160
model on data versioning orchestration

00:05:08,400 --> 00:05:13,380
and you know really it's not just you

00:05:11,160 --> 00:05:15,300
know those two things and there is no

00:05:13,380 --> 00:05:18,180
noise challenging is because we are now

00:05:15,300 --> 00:05:20,160
seeing an intersection of multiple roles

00:05:18,180 --> 00:05:21,500
this is basically software engineers

00:05:20,160 --> 00:05:24,570
they're the scientists and the engineers

00:05:21,500 --> 00:05:26,670
which are best condensing into this role

00:05:24,570 --> 00:05:29,010
of machine learning engineer and you

00:05:26,670 --> 00:05:30,810
know the definition of this role in

00:05:29,010 --> 00:05:33,120
itself is it's quite complex because it

00:05:30,810 --> 00:05:34,560
does fall in expertise in those areas

00:05:33,120 --> 00:05:36,360
and you see that when you look at a job

00:05:34,560 --> 00:05:39,420
description right you know this this

00:05:36,360 --> 00:05:41,010
this AI startups are hiring for this PhD

00:05:39,420 --> 00:05:43,170
with you know 10 years experience in

00:05:41,010 --> 00:05:45,660
software development you know maybe

00:05:43,170 --> 00:05:48,090
three years McKinsey style consulting

00:05:45,660 --> 00:05:50,640
experience for a salary of an intern

00:05:48,090 --> 00:05:53,190
right I mean that's that's basically

00:05:50,640 --> 00:05:54,720
what you have a lot of the times and and

00:05:53,190 --> 00:05:56,250
you know the reason why it is it is

00:05:54,720 --> 00:05:58,140
challenging is because we're not seeing

00:05:56,250 --> 00:06:00,960
things like you know data science at

00:05:58,140 --> 00:06:02,670
scale and you have the requirements for

00:06:00,960 --> 00:06:05,250
the things that you would normally

00:06:02,670 --> 00:06:07,620
follow in the in this sort of like data

00:06:05,250 --> 00:06:09,300
science world to also apply in some of

00:06:07,620 --> 00:06:11,400
the in certain extent in the software

00:06:09,300 --> 00:06:12,720
engineering and DevOps world and you

00:06:11,400 --> 00:06:14,370
know when I say it's challenging is

00:06:12,720 --> 00:06:16,470
because it actually breaks down into a

00:06:14,370 --> 00:06:20,460
lot of concepts and we've actually

00:06:16,470 --> 00:06:23,310
broken down the ecosystem in an open

00:06:20,460 --> 00:06:25,710
source awesome production a machine

00:06:23,310 --> 00:06:27,270
learning list which you know we would

00:06:25,710 --> 00:06:28,710
love for you guys to contribute you know

00:06:27,270 --> 00:06:31,640
you see one of the tools that is missing

00:06:28,710 --> 00:06:34,890
you know is one of the most extensive

00:06:31,640 --> 00:06:38,340
lists specifically focused on production

00:06:34,890 --> 00:06:40,650
machine learning tools so basically you

00:06:38,340 --> 00:06:42,660
know just the explained ability piece

00:06:40,650 --> 00:06:44,720
has you know and

00:06:42,660 --> 00:06:46,590
insane amount of open-source libraries

00:06:44,720 --> 00:06:49,740
but the ones that we're going to be

00:06:46,590 --> 00:06:51,660
diving to today not saying that you know

00:06:49,740 --> 00:06:53,580
they're not the rest are not as

00:06:51,660 --> 00:06:56,130
important for sure but it's the ones

00:06:53,580 --> 00:06:59,580
that I myself work mostly on a

00:06:56,130 --> 00:07:02,160
day-to-day basis are orchestration

00:06:59,580 --> 00:07:04,470
explain ability and reproducibility and

00:07:02,160 --> 00:07:06,060
for each of these principles we're going

00:07:04,470 --> 00:07:08,460
to be diving into the conceptual

00:07:06,060 --> 00:07:11,840
definition of what they mean together

00:07:08,460 --> 00:07:15,570
with an example a hands-on example

00:07:11,840 --> 00:07:16,890
showcasing what is the extent of the

00:07:15,570 --> 00:07:19,980
ways that you can address this this

00:07:16,890 --> 00:07:21,570
challenge as well as a few shout outs to

00:07:19,980 --> 00:07:25,440
other libraries that are available for

00:07:21,570 --> 00:07:27,420
you to check out so to get started model

00:07:25,440 --> 00:07:30,770
orchestration so this is basically

00:07:27,420 --> 00:07:32,940
training and serving models at scale and

00:07:30,770 --> 00:07:37,680
you know this is a challenging problem

00:07:32,940 --> 00:07:39,870
because you are really dealing with I

00:07:37,680 --> 00:07:43,620
guess you know in a very conceptual

00:07:39,870 --> 00:07:45,780
manner handling you know an operating

00:07:43,620 --> 00:07:49,500
system challenge at scale right you need

00:07:45,780 --> 00:07:51,720
to allocate allocate resource resources

00:07:49,500 --> 00:07:53,670
as well as computational hardware

00:07:51,720 --> 00:07:56,490
requirements for example if you have a

00:07:53,670 --> 00:07:58,140
model that requires a GPU then you need

00:07:56,490 --> 00:08:01,440
to make sure that the model executes in

00:07:58,140 --> 00:08:03,540
the area where the GPU is available so

00:08:01,440 --> 00:08:05,250
it is really hard so it's important to

00:08:03,540 --> 00:08:07,440
make sure that you are aware that this

00:08:05,250 --> 00:08:09,720
complexity involves not just the skill

00:08:07,440 --> 00:08:11,400
set of the data scientists but also it

00:08:09,720 --> 00:08:13,770
may require that the sysadmin is an

00:08:11,400 --> 00:08:16,260
infrastructure expertise to be able to

00:08:13,770 --> 00:08:18,840
tackle it and the reason why it also

00:08:16,260 --> 00:08:20,130
gets hard is because having stuff in

00:08:18,840 --> 00:08:21,180
production that is dealing with

00:08:20,130 --> 00:08:24,360
real-world problems

00:08:21,180 --> 00:08:27,780
you know also dives into other areas so

00:08:24,360 --> 00:08:29,870
you have this already ambiguous you know

00:08:27,780 --> 00:08:32,580
role of machine learning engineering and

00:08:29,870 --> 00:08:34,560
it's currently intersecting with the

00:08:32,580 --> 00:08:36,750
rows of you know industry domain

00:08:34,560 --> 00:08:38,820
expertise as well as policy and

00:08:36,750 --> 00:08:41,460
regulation to create this sort of like

00:08:38,820 --> 00:08:43,620
centralized industry standards this

00:08:41,460 --> 00:08:45,510
already introduces that ambiguity of how

00:08:43,620 --> 00:08:47,370
do you have that compliance and

00:08:45,510 --> 00:08:50,670
governance with the models that you

00:08:47,370 --> 00:08:52,200
deploy in production and you know this

00:08:50,670 --> 00:08:54,510
is kind of like the very very high level

00:08:52,200 --> 00:08:57,030
but you know for some of the DevOps

00:08:54,510 --> 00:08:58,800
engineers they may say well

00:08:57,030 --> 00:09:01,080
standardization of metrics right if

00:08:58,800 --> 00:09:03,270
you're in a large organization you may

00:09:01,080 --> 00:09:05,670
actually have to abide by certain SLA s

00:09:03,270 --> 00:09:07,770
and with microservices this SL a's are

00:09:05,670 --> 00:09:10,110
quite standard they are uptime you know

00:09:07,770 --> 00:09:11,460
they could be latency but when it comes

00:09:10,110 --> 00:09:13,530
to machine learning you may actually

00:09:11,460 --> 00:09:16,530
have some some metrics that you have to

00:09:13,530 --> 00:09:18,300
abide by like accuracy things that you

00:09:16,530 --> 00:09:21,330
need to be aware like model divergence

00:09:18,300 --> 00:09:23,580
and of course you could actually put

00:09:21,330 --> 00:09:26,160
together the code required for every

00:09:23,580 --> 00:09:28,080
single one of your deployments but you

00:09:26,160 --> 00:09:29,790
know to a certain extent it is necessary

00:09:28,080 --> 00:09:31,860
to be able to standardize and abstract

00:09:29,790 --> 00:09:32,910
these concepts on an infrastructural

00:09:31,860 --> 00:09:36,450
level and that's what we're going to be

00:09:32,910 --> 00:09:38,730
diving into in certain level today and

00:09:36,450 --> 00:09:40,440
it's not only metrics you know as you

00:09:38,730 --> 00:09:42,450
would know with any micro service or web

00:09:40,440 --> 00:09:45,210
app that you would you know deal with in

00:09:42,450 --> 00:09:47,940
production but it's also logs and errors

00:09:45,210 --> 00:09:50,430
right if you have an error with a

00:09:47,940 --> 00:09:53,310
machine learning model the error may not

00:09:50,430 --> 00:09:55,350
just be a Python exception right this

00:09:53,310 --> 00:09:59,850
may be an error because the new training

00:09:55,350 --> 00:10:01,680
data was potentially biased towards a

00:09:59,850 --> 00:10:03,360
specific class right so you had a class

00:10:01,680 --> 00:10:05,490
imbalance with more examples in one

00:10:03,360 --> 00:10:07,320
class and the other that could be in a

00:10:05,490 --> 00:10:10,080
way leading to errors that are not

00:10:07,320 --> 00:10:11,730
specifically you know PI exceptions

00:10:10,080 --> 00:10:13,650
right so you may not get notified

00:10:11,730 --> 00:10:15,180
because something failed but you know

00:10:13,650 --> 00:10:17,070
you may see stuff failing because of

00:10:15,180 --> 00:10:19,140
that and it's also how do you

00:10:17,070 --> 00:10:21,420
standardize the stuff that comes in and

00:10:19,140 --> 00:10:23,550
out of the models how do you track this

00:10:21,420 --> 00:10:26,640
and then also for example if you have if

00:10:23,550 --> 00:10:30,420
you have images coming into a model you

00:10:26,640 --> 00:10:32,250
know you can't just go into your log you

00:10:30,420 --> 00:10:36,960
know keep on a dashboard and just see

00:10:32,250 --> 00:10:38,790
that like binary dump of the data right

00:10:36,960 --> 00:10:43,230
so it's it's really understanding what

00:10:38,790 --> 00:10:44,730
to log in in those cases now when you

00:10:43,230 --> 00:10:46,350
actually deal with with machine learning

00:10:44,730 --> 00:10:48,570
and production you also dive into

00:10:46,350 --> 00:10:50,820
complex deployment strategies right so

00:10:48,570 --> 00:10:55,920
you normally you may imagine just

00:10:50,820 --> 00:10:57,840
putting a text classifier in production

00:10:55,920 --> 00:11:00,210
but perhaps you may want to reuse

00:10:57,840 --> 00:11:02,820
components or maybe you want a more

00:11:00,210 --> 00:11:05,610
complex computational graph where you

00:11:02,820 --> 00:11:08,610
have some sort of like routine based on

00:11:05,610 --> 00:11:10,649
some conditional cases you may have some

00:11:08,610 --> 00:11:12,749
you know multi-armed bandit optimized

00:11:10,649 --> 00:11:14,430
since that may have different models at

00:11:12,749 --> 00:11:15,990
which they're having it at the end or

00:11:14,430 --> 00:11:18,360
you may have all the things like

00:11:15,990 --> 00:11:19,949
explanations right now you know we're

00:11:18,360 --> 00:11:22,110
gonna dive into that but explanations

00:11:19,949 --> 00:11:24,240
are a big thing in the machine learning

00:11:22,110 --> 00:11:27,959
space and you may want to have those

00:11:24,240 --> 00:11:29,519
things in production so that your domain

00:11:27,959 --> 00:11:31,740
experts can make sense of what's

00:11:29,519 --> 00:11:33,540
currently employed and again you know

00:11:31,740 --> 00:11:35,819
yes you could actually do this custom

00:11:33,540 --> 00:11:37,259
for every single thing but the reason

00:11:35,819 --> 00:11:40,829
why you wouldn't want to do that is

00:11:37,259 --> 00:11:43,470
because if you if you have a manual work

00:11:40,829 --> 00:11:45,929
with every single model what you're

00:11:43,470 --> 00:11:47,850
gonna end up having is you know each

00:11:45,929 --> 00:11:49,829
data scientist having a maximum of say

00:11:47,850 --> 00:11:52,619
for example 10 models that they can

00:11:49,829 --> 00:11:54,480
maintain in production at one possible

00:11:52,619 --> 00:11:55,860
time so if you want to deploy more

00:11:54,480 --> 00:11:58,470
models you're gonna end up having to

00:11:55,860 --> 00:12:01,199
hire more stuff right so you actually

00:11:58,470 --> 00:12:03,029
want to avoid that linear growth of your

00:12:01,199 --> 00:12:07,470
resources technical resources with your

00:12:03,029 --> 00:12:08,819
with your actual internal stuff okay and

00:12:07,470 --> 00:12:09,449
this is where you know the concept of

00:12:08,819 --> 00:12:13,139
get-ups

00:12:09,449 --> 00:12:15,839
comes in and this is this is the concept

00:12:13,139 --> 00:12:17,879
of you define your you use your your

00:12:15,839 --> 00:12:20,429
your github repo or your version control

00:12:17,879 --> 00:12:23,370
system as your single source of truth

00:12:20,429 --> 00:12:25,649
and whatever actually gets updated there

00:12:23,370 --> 00:12:28,170
will reflect what you have in production

00:12:25,649 --> 00:12:30,480
this may not be only limited to the code

00:12:28,170 --> 00:12:32,519
of your application but may also you

00:12:30,480 --> 00:12:34,139
know reach the extent of the

00:12:32,519 --> 00:12:37,470
configuration in which your cluster may

00:12:34,139 --> 00:12:39,089
may actually be currently following and

00:12:37,470 --> 00:12:41,819
in this case you know we're gonna be

00:12:39,089 --> 00:12:43,649
showing an example where we are gonna

00:12:41,819 --> 00:12:46,319
first start with a very very simple

00:12:43,649 --> 00:12:48,509
model we're going to be taking a you

00:12:46,319 --> 00:12:50,550
know very common data set that you're

00:12:48,509 --> 00:12:52,529
probably used and follow the tutorial

00:12:50,550 --> 00:12:54,209
with which is the income classification

00:12:52,529 --> 00:12:56,009
data set and we're gonna basically

00:12:54,209 --> 00:12:58,319
assume that you know we're taking this

00:12:56,009 --> 00:13:00,420
you know data set off of you know

00:12:58,319 --> 00:13:03,540
people's details like you know your

00:13:00,420 --> 00:13:05,160
number of working hours per day your you

00:13:03,540 --> 00:13:06,449
know working class cetera et cetera and

00:13:05,160 --> 00:13:08,549
we're gonna train a machine learning

00:13:06,449 --> 00:13:11,790
model to predict whether that person

00:13:08,549 --> 00:13:13,740
earns more or less than 50k and in

00:13:11,790 --> 00:13:16,069
essence in this example we're gonna

00:13:13,740 --> 00:13:19,019
assume that we're using this matrix for

00:13:16,069 --> 00:13:21,329
approval approving someone's loan right

00:13:19,019 --> 00:13:22,649
if you get more than you know if it

00:13:21,329 --> 00:13:24,450
predicts more than 50k it would be

00:13:22,649 --> 00:13:26,040
approved otherwise rejected

00:13:24,450 --> 00:13:28,410
you know I don't recommend anyone to do

00:13:26,040 --> 00:13:30,600
this in production this is just an

00:13:28,410 --> 00:13:32,130
example and what we're gonna be doing is

00:13:30,600 --> 00:13:35,160
we're gonna be wrapping this this Python

00:13:32,130 --> 00:13:36,690
model and then deploying it and you know

00:13:35,160 --> 00:13:39,300
seeing how we can get some of this like

00:13:36,690 --> 00:13:42,870
standardized metrics getting some of the

00:13:39,300 --> 00:13:45,829
standardized logging etc etc so in this

00:13:42,870 --> 00:13:48,779
case all of these examples are actually

00:13:45,829 --> 00:13:50,670
open source and they're all available on

00:13:48,779 --> 00:13:52,709
on the link so you can actually go and

00:13:50,670 --> 00:13:53,970
try them yourself within an hour I mean

00:13:52,709 --> 00:13:56,490
we're only gonna be able to cover them

00:13:53,970 --> 00:13:59,209
in a high-level perspective so in the in

00:13:56,490 --> 00:14:02,160
this first part of the of the of the

00:13:59,209 --> 00:14:04,110
example we're only going to be creating

00:14:02,160 --> 00:14:05,430
a Python model then we're gonna be

00:14:04,110 --> 00:14:06,810
wrapping it and then we're gonna be

00:14:05,430 --> 00:14:08,820
deploying it in a kubernetes cluster

00:14:06,810 --> 00:14:10,230
right there's gonna be containerized

00:14:08,820 --> 00:14:13,410
with docker and then it's gonna be

00:14:10,230 --> 00:14:16,350
exposing the internal functionality

00:14:13,410 --> 00:14:18,449
through a restful api so the way that we

00:14:16,350 --> 00:14:20,970
would do it is we would set up our

00:14:18,449 --> 00:14:25,079
environment which basically requires you

00:14:20,970 --> 00:14:26,310
to have a cornetist cluster running you

00:14:25,079 --> 00:14:28,260
know i'm not gonna be trusting the

00:14:26,310 --> 00:14:31,019
internet for for for that to actually

00:14:28,260 --> 00:14:34,199
help us today so you know I already have

00:14:31,019 --> 00:14:37,230
everything set up in tabs as you can see

00:14:34,199 --> 00:14:39,690
just in case so what we're gonna be

00:14:37,230 --> 00:14:43,649
doing in this case we're downloading in

00:14:39,690 --> 00:14:46,949
in here the data set so this data set

00:14:43,649 --> 00:14:49,560
contains you know in this case

00:14:46,949 --> 00:14:52,860
applications of people and whether they

00:14:49,560 --> 00:14:55,010
get approved or rejected we do a train

00:14:52,860 --> 00:14:58,040
test split as you would normally would

00:14:55,010 --> 00:15:00,870
and in this case you know you would have

00:14:58,040 --> 00:15:10,529
let's actually have a look at the data

00:15:00,870 --> 00:15:14,459
set yeah so you basically have already a

00:15:10,529 --> 00:15:17,670
normalized data set where you have in

00:15:14,459 --> 00:15:20,819
the first row the age of the people and

00:15:17,670 --> 00:15:22,920
then remaining classes for the rest of

00:15:20,819 --> 00:15:24,870
the other features and then we actually

00:15:22,920 --> 00:15:29,310
come come print the labels as well so I

00:15:24,870 --> 00:15:31,290
think I'm here Oh feature names actually

00:15:29,310 --> 00:15:33,029
we can see the feature names and that's

00:15:31,290 --> 00:15:34,410
basically the order in which we have

00:15:33,029 --> 00:15:37,290
them so as the age the working class

00:15:34,410 --> 00:15:38,760
education etc etc

00:15:37,290 --> 00:15:39,900
perfect so the first thing that we're

00:15:38,760 --> 00:15:42,660
gonna be doing we're gonna be using

00:15:39,900 --> 00:15:44,310
psychic line so just to get a bit of an

00:15:42,660 --> 00:15:46,140
understanding I mean who here has used

00:15:44,310 --> 00:15:48,020
scikit-learn let's see a show of hands

00:15:46,140 --> 00:15:50,580
just for tutorial okay perfect awesome

00:15:48,020 --> 00:15:53,460
so what we're doing here is we're just

00:15:50,580 --> 00:15:58,230
building a a pipeline we're gonna beast

00:15:53,460 --> 00:16:00,780
a scaling our numeric data points as

00:15:58,230 --> 00:16:03,990
well as you know creating a one-hole

00:16:00,780 --> 00:16:06,660
encoding of our categorical data points

00:16:03,990 --> 00:16:09,300
and we're gonna be transforming the data

00:16:06,660 --> 00:16:12,810
with that so now that we've actually you

00:16:09,300 --> 00:16:14,990
know fit our preprocessor we're gonna be

00:16:12,810 --> 00:16:18,330
then training a random forest classifier

00:16:14,990 --> 00:16:21,090
with that sort of data set so that it

00:16:18,330 --> 00:16:22,980
you know takes the pre process data and

00:16:21,090 --> 00:16:24,750
then predicts whether that you know a

00:16:22,980 --> 00:16:27,060
person would be able to get a loan

00:16:24,750 --> 00:16:29,130
approved or rejected once we actually

00:16:27,060 --> 00:16:31,230
train our model we can use the the test

00:16:29,130 --> 00:16:33,270
data set to see how it performs you know

00:16:31,230 --> 00:16:37,170
we can see that in terms of accuracy

00:16:33,270 --> 00:16:40,110
it has about you know 85% you know

00:16:37,170 --> 00:16:42,660
precision recall etc so now we have a

00:16:40,110 --> 00:16:43,230
train model right we have with our

00:16:42,660 --> 00:16:45,480
scikit-learn

00:16:43,230 --> 00:16:49,470
you know CLF is our random forest

00:16:45,480 --> 00:16:52,470
classifier preprocessor is basically our

00:16:49,470 --> 00:16:53,580
pipeline of our standard scaler and the

00:16:52,470 --> 00:16:55,350
one-hot vectorizer

00:16:53,580 --> 00:16:56,580
so then what we're gonna do is we're

00:16:55,350 --> 00:16:58,710
gonna actually take this model and

00:16:56,580 --> 00:17:01,410
containerize it and what we're gonna do

00:16:58,710 --> 00:17:04,380
for this is we're gonna first just dump

00:17:01,410 --> 00:17:06,830
those two models that we've created so

00:17:04,380 --> 00:17:09,000
for that you know preprocessor and

00:17:06,830 --> 00:17:12,060
classifier so we're dumping them in this

00:17:09,000 --> 00:17:18,750
in this folder and you know we can

00:17:12,060 --> 00:17:20,040
actually see the the contents so so we

00:17:18,750 --> 00:17:23,700
can see that we basically dumped it

00:17:20,040 --> 00:17:26,070
there once we have those two models that

00:17:23,700 --> 00:17:28,350
have been already trained we basically

00:17:26,070 --> 00:17:30,090
create a wrapper and this wrapper is

00:17:28,350 --> 00:17:33,120
just going to have a predict function

00:17:30,090 --> 00:17:35,010
that will take whatever input comes in

00:17:33,120 --> 00:17:37,020
you know this predict function is

00:17:35,010 --> 00:17:39,870
exposed it will be exposed through a

00:17:37,020 --> 00:17:42,330
restful api but basically whatever input

00:17:39,870 --> 00:17:43,680
we pass it through the preprocessor and

00:17:42,330 --> 00:17:47,400
we pass it through the classifier and

00:17:43,680 --> 00:17:49,320
then we return their predicted the

00:17:47,400 --> 00:17:51,120
prediction right so this is this very

00:17:49,320 --> 00:17:54,180
simple right so we load the models

00:17:51,120 --> 00:17:56,370
and then we just run whatever is passed

00:17:54,180 --> 00:17:59,130
through this predict function and return

00:17:56,370 --> 00:18:01,410
the predictions right super simple this

00:17:59,130 --> 00:18:03,990
wrapper is basically the interface that

00:18:01,410 --> 00:18:07,260
we just require so that we can actually

00:18:03,990 --> 00:18:08,700
containerize it so for the next one for

00:18:07,260 --> 00:18:11,190
the containerization we just need to

00:18:08,700 --> 00:18:13,590
define any sort of dependencies so in

00:18:11,190 --> 00:18:15,990
this case we use scikit-learn and the

00:18:13,590 --> 00:18:17,910
image because we're actually gonna be

00:18:15,990 --> 00:18:19,080
sending well in this case we actually

00:18:17,910 --> 00:18:21,870
don't need the image just so I could

00:18:19,080 --> 00:18:24,929
learn and then we actually just define

00:18:21,870 --> 00:18:27,890
you know the name of our file and we run

00:18:24,929 --> 00:18:31,470
the basically sty

00:18:27,890 --> 00:18:35,309
CLI tool that basically what it does it

00:18:31,470 --> 00:18:38,220
takes our image our standard image that

00:18:35,309 --> 00:18:41,190
exposes and wraps this model file

00:18:38,220 --> 00:18:43,710
through a RESTful API and G RPC API

00:18:41,190 --> 00:18:45,630
right so once we actually have this

00:18:43,710 --> 00:18:47,309
container so just to get a bit of an

00:18:45,630 --> 00:18:51,179
understanding in the room who here has

00:18:47,309 --> 00:18:53,820
used docker before perfect so here you

00:18:51,179 --> 00:18:55,950
just have a great awesome so so here you

00:18:53,820 --> 00:19:00,150
basically just have a docker image

00:18:55,950 --> 00:19:02,700
called lone classifier 0.1 this docker

00:19:00,150 --> 00:19:04,890
image when you run it the input command

00:19:02,700 --> 00:19:06,620
is basically just gonna run a flask API

00:19:04,890 --> 00:19:09,330
that exposes the predict function

00:19:06,620 --> 00:19:11,850
whatever you send to that predict

00:19:09,330 --> 00:19:14,910
function to that predict endpoint you

00:19:11,850 --> 00:19:17,220
know will be passed through basically

00:19:14,910 --> 00:19:18,750
you know your wrapper so that that is

00:19:17,220 --> 00:19:21,540
basically what it would be doing right

00:19:18,750 --> 00:19:23,790
so once we have that we would just you

00:19:21,540 --> 00:19:26,190
know specified in our kubernetes the

00:19:23,790 --> 00:19:27,420
finishing file so this is you know just

00:19:26,190 --> 00:19:29,490
saying like the container that we're

00:19:27,420 --> 00:19:32,100
gonna have is this lone classifier and

00:19:29,490 --> 00:19:34,710
your computational graph in this case

00:19:32,100 --> 00:19:36,000
just has one element which is the the

00:19:34,710 --> 00:19:38,610
known classifier and that's all

00:19:36,000 --> 00:19:41,400
basically you you would have once you

00:19:38,610 --> 00:19:43,620
define that if it's built now you can

00:19:41,400 --> 00:19:47,340
actually deploy it here you can actually

00:19:43,620 --> 00:19:51,050
see that it's being created in local

00:19:47,340 --> 00:19:55,170
kubernetes cluster so I think it is

00:19:51,050 --> 00:19:57,120
downloading it which is no great but

00:19:55,170 --> 00:19:59,190
basically what you would then see as

00:19:57,120 --> 00:20:01,530
this model is now deployed in our

00:19:59,190 --> 00:20:04,440
kubernetes cluster it's going to be

00:20:01,530 --> 00:20:05,070
listening to any requests so it's

00:20:04,440 --> 00:20:08,730
basically

00:20:05,070 --> 00:20:11,639
if it was a micro-service right and then

00:20:08,730 --> 00:20:13,620
as any other restful endpoint we can

00:20:11,639 --> 00:20:15,450
actually interact with it in this case

00:20:13,620 --> 00:20:19,679
with curl so in this case we're actually

00:20:15,450 --> 00:20:21,269
just sending it you know one instant one

00:20:19,679 --> 00:20:24,330
instance to actually perform an

00:20:21,269 --> 00:20:26,850
inference you know the response is an in

00:20:24,330 --> 00:20:29,159
the array of you know the positive and

00:20:26,850 --> 00:20:31,710
negative label in this case it predicted

00:20:29,159 --> 00:20:33,419
you know a negative label so in this

00:20:31,710 --> 00:20:36,269
case what we've done is we've actually

00:20:33,419 --> 00:20:37,980
wrapped a model with a you know very

00:20:36,269 --> 00:20:40,529
very simple thin layer wrapper put it in

00:20:37,980 --> 00:20:44,129
production the wrapper itself also

00:20:40,529 --> 00:20:45,779
exposes a matrix endpoint which for the

00:20:44,129 --> 00:20:48,539
people that have used Prometheus or

00:20:45,779 --> 00:20:49,590
Gravano in the past you know Prometheus

00:20:48,539 --> 00:20:52,830
you can actually hook it up to this

00:20:49,590 --> 00:20:56,059
matrix endpoint and you're able to get

00:20:52,830 --> 00:20:58,860
some metrics out of the box in this case

00:20:56,059 --> 00:21:00,509
let's see if I can actually show it here

00:20:58,860 --> 00:21:03,720
is basically our income classifier that

00:21:00,509 --> 00:21:05,009
we have deployed and out of the box you

00:21:03,720 --> 00:21:07,200
get you know in this case this is a

00:21:05,009 --> 00:21:08,940
graph on a dashboard you would get

00:21:07,200 --> 00:21:12,720
basically all of the requests per second

00:21:08,940 --> 00:21:15,960
you get you know the the latency for

00:21:12,720 --> 00:21:18,179
that specific container etc etc and

00:21:15,960 --> 00:21:20,759
we're actually going to be diving a bit

00:21:18,179 --> 00:21:24,779
more into some of the metrics in a bit

00:21:20,759 --> 00:21:28,019
you also get some of the logs so again

00:21:24,779 --> 00:21:30,320
this is basically just the output of the

00:21:28,019 --> 00:21:34,679
container is just being collected with a

00:21:30,320 --> 00:21:36,990
fluent the server and then you know

00:21:34,679 --> 00:21:38,309
storing on an elastic search database so

00:21:36,990 --> 00:21:40,470
for the ones that have used Cabana in

00:21:38,309 --> 00:21:44,700
the past this is just basically also oo

00:21:40,470 --> 00:21:47,759
squaring the elastic search for the logs

00:21:44,700 --> 00:21:49,620
and for tabular data is basically what

00:21:47,759 --> 00:21:52,980
you know we actually expose out of the

00:21:49,620 --> 00:21:55,169
box but basically that is an initial

00:21:52,980 --> 00:21:58,080
overview of you know the orchestration

00:21:55,169 --> 00:22:00,570
piece the benefits of actually you know

00:21:58,080 --> 00:22:02,370
continued icing your models of course

00:22:00,570 --> 00:22:04,409
it's obvious in terms of like making it

00:22:02,370 --> 00:22:07,350
available for business consumption but

00:22:04,409 --> 00:22:09,990
the core thing from these is the push

00:22:07,350 --> 00:22:11,940
towards standardization right is if you

00:22:09,990 --> 00:22:14,039
were to have you know a hundred models

00:22:11,940 --> 00:22:16,590
in production you would be able to

00:22:14,039 --> 00:22:18,900
interact with them as if they were micro

00:22:16,590 --> 00:22:20,970
services right and what this allows

00:22:18,900 --> 00:22:22,980
- do you know we have just covered a

00:22:20,970 --> 00:22:24,240
very very simple example but what this

00:22:22,980 --> 00:22:28,080
really allows you to do is to leverage

00:22:24,240 --> 00:22:31,230
these get-ups structure that I was

00:22:28,080 --> 00:22:34,250
talking about earlier and just to see

00:22:31,230 --> 00:22:36,890
here who here is familiar with PI torch

00:22:34,250 --> 00:22:40,230
and with Pytor chub

00:22:36,890 --> 00:22:42,060
okay so PI third job is basically a new

00:22:40,230 --> 00:22:46,470
initiative from PI torch where they

00:22:42,060 --> 00:22:49,650
encouraged people to save trained models

00:22:46,470 --> 00:22:53,070
like Bert or vgg where you can actually

00:22:49,650 --> 00:22:54,960
submit your models to a git repo and

00:22:53,070 --> 00:22:58,170
what that allows you to do is to have a

00:22:54,960 --> 00:23:01,800
central sort of like a standardized

00:22:58,170 --> 00:23:04,080
interface towards your already trained

00:23:01,800 --> 00:23:06,510
models so in this case basically you're

00:23:04,080 --> 00:23:08,430
able to define any model in this case is

00:23:06,510 --> 00:23:10,440
resonate and you say this is how you

00:23:08,430 --> 00:23:13,140
load it and this is where the trained

00:23:10,440 --> 00:23:15,450
binary is located so it's an initiative

00:23:13,140 --> 00:23:17,970
from titer job and what we have been

00:23:15,450 --> 00:23:21,870
able to do is to actually create an

00:23:17,970 --> 00:23:24,570
integration to peiter job where any time

00:23:21,870 --> 00:23:26,970
that you actually point a a new sort of

00:23:24,570 --> 00:23:29,130
like configuration deployment towards a

00:23:26,970 --> 00:23:32,310
repo what it would do is very a very

00:23:29,130 --> 00:23:34,730
thin layer wrapper that just downloads

00:23:32,310 --> 00:23:38,400
that model right because the actual code

00:23:34,730 --> 00:23:39,750
to load it is standardized by the actual

00:23:38,400 --> 00:23:42,030
deployment and you know to be more

00:23:39,750 --> 00:23:45,330
specific the way that we actually do it

00:23:42,030 --> 00:23:48,720
is you know a wrapper where you

00:23:45,330 --> 00:23:50,220
basically take the repo and the name as

00:23:48,720 --> 00:23:52,800
input parameters that you can pass

00:23:50,220 --> 00:23:55,830
through the config files and then when

00:23:52,800 --> 00:23:58,110
it actually loads it downloads the model

00:23:55,830 --> 00:24:00,630
from PI torch all right so you basically

00:23:58,110 --> 00:24:03,600
have a new an ability to dynamically

00:24:00,630 --> 00:24:06,210
publish you know any sort of like Bert

00:24:03,600 --> 00:24:08,430
or vgg like models I mean anyone who was

00:24:06,210 --> 00:24:10,380
actually like tried using Bert or one of

00:24:08,430 --> 00:24:12,240
those you know state-of-the-art models

00:24:10,380 --> 00:24:14,370
would know the pain of you know often

00:24:12,240 --> 00:24:15,600
setting them up so there's a lot of

00:24:14,370 --> 00:24:17,490
benefit of actually trying to

00:24:15,600 --> 00:24:20,580
standardize the way not only to define

00:24:17,490 --> 00:24:21,990
them but also to to deploy them you know

00:24:20,580 --> 00:24:26,220
and again you can actually jump in and

00:24:21,990 --> 00:24:28,800
try these examples so that is basically

00:24:26,220 --> 00:24:31,110
a high-level overview on the

00:24:28,800 --> 00:24:32,400
orchestration part before we jump into

00:24:31,110 --> 00:24:35,310
the explain explain

00:24:32,400 --> 00:24:38,610
ability piece some other libraries to

00:24:35,310 --> 00:24:40,650
watch you know one of them is M leap

00:24:38,610 --> 00:24:42,630
serving so their approach is they

00:24:40,650 --> 00:24:45,380
actually have a single server that

00:24:42,630 --> 00:24:48,390
allows you to ACTU to load standardized

00:24:45,380 --> 00:24:51,360
so like serialization of models so if

00:24:48,390 --> 00:24:54,510
anyone is familiar with the Onan X sort

00:24:51,360 --> 00:24:57,750
of serializable definition of models you

00:24:54,510 --> 00:25:00,360
know you'd be able to have a single

00:24:57,750 --> 00:25:02,880
model that that loads you're trained

00:25:00,360 --> 00:25:06,840
binaries and expose them through again

00:25:02,880 --> 00:25:09,420
an API and then another one that is also

00:25:06,840 --> 00:25:12,930
one to watch is deep detect which

00:25:09,420 --> 00:25:16,080
unifies behind a standardized API a lot

00:25:12,930 --> 00:25:18,120
of this Python based models and these

00:25:16,080 --> 00:25:20,490
are two of you know a large number of

00:25:18,120 --> 00:25:22,710
libraries to check out I definitely

00:25:20,490 --> 00:25:25,280
would advise you to have a look at the

00:25:22,710 --> 00:25:28,890
entire list it's quite extensive

00:25:25,280 --> 00:25:30,390
alright so so the second piece oh it

00:25:28,890 --> 00:25:32,370
should be actually explaining ability so

00:25:30,390 --> 00:25:34,320
we're gonna jump on that one explain

00:25:32,370 --> 00:25:36,840
ability they stagger the problem of

00:25:34,320 --> 00:25:39,780
black box model and white box model

00:25:36,840 --> 00:25:42,240
situations where you have a trained

00:25:39,780 --> 00:25:44,970
model that you want to understand why

00:25:42,240 --> 00:25:48,630
did why did the model predict whatever

00:25:44,970 --> 00:25:51,840
it predicted right and you know this the

00:25:48,630 --> 00:25:54,630
way that we tackle it requires the

00:25:51,840 --> 00:25:56,730
people tackling this issue to go beyond

00:25:54,630 --> 00:25:58,860
the algorithms and the reason why is

00:25:56,730 --> 00:26:01,410
because this is not just an algorithmic

00:25:58,860 --> 00:26:04,260
challenge it does take a lot of the

00:26:01,410 --> 00:26:05,550
domain expertise into account you know

00:26:04,260 --> 00:26:08,970
and the way that we actually emphasize

00:26:05,550 --> 00:26:11,940
this is that interpretability does not

00:26:08,970 --> 00:26:13,860
equal explained ability you may be able

00:26:11,940 --> 00:26:15,480
to interpret something but that doesn't

00:26:13,860 --> 00:26:16,830
mean that you understand it and of

00:26:15,480 --> 00:26:18,720
course you know in terms of like you

00:26:16,830 --> 00:26:21,390
know the English definition of those

00:26:18,720 --> 00:26:24,120
words there is not that that conceptual

00:26:21,390 --> 00:26:25,950
perspective in place but we tend to push

00:26:24,120 --> 00:26:28,740
that sort of way of thinking about it

00:26:25,950 --> 00:26:31,230
because it's not just bringing the data

00:26:28,740 --> 00:26:33,840
scientist to address these challenges it

00:26:31,230 --> 00:26:36,300
may require also the DevOps software

00:26:33,840 --> 00:26:37,890
engineer but also the domain expert to

00:26:36,300 --> 00:26:39,870
be able to understand how the model is

00:26:37,890 --> 00:26:42,620
behaving and we actually did a three and

00:26:39,870 --> 00:26:45,300
a half hour tutorial at the AI O'Reilly

00:26:42,620 --> 00:26:46,290
so each of these things you know we

00:26:45,300 --> 00:26:49,080
could actually dive and

00:26:46,290 --> 00:26:51,120
to an insane amount of detail but just

00:26:49,080 --> 00:26:53,570
for the sake of simplicity today we're

00:26:51,120 --> 00:26:57,060
gonna go and do a high-level cover over

00:26:53,570 --> 00:27:00,180
the standard process that we we often

00:26:57,060 --> 00:27:03,750
suggest to follow it actually extends

00:27:00,180 --> 00:27:05,760
the existing data science workflow that

00:27:03,750 --> 00:27:08,250
we showed previously and it adds three

00:27:05,760 --> 00:27:09,960
new steps which they're not really new

00:27:08,250 --> 00:27:12,210
but they are you know three steps that

00:27:09,960 --> 00:27:14,910
are explicitly outlined four explain

00:27:12,210 --> 00:27:16,980
ability these are you know data analysis

00:27:14,910 --> 00:27:18,690
model evaluation and production

00:27:16,980 --> 00:27:19,860
monitoring production monitoring being

00:27:18,690 --> 00:27:22,830
the one that we're going to dive into

00:27:19,860 --> 00:27:25,290
today in terms of data assessment you

00:27:22,830 --> 00:27:27,540
would want to explore things like class

00:27:25,290 --> 00:27:30,930
imbalances you know things whether

00:27:27,540 --> 00:27:32,310
you're using protected features you know

00:27:30,930 --> 00:27:34,410
correlations within data

00:27:32,310 --> 00:27:36,870
you know perhaps removing a data point

00:27:34,410 --> 00:27:39,120
may not mean that you know your you you

00:27:36,870 --> 00:27:41,880
are actually removing a hundred percent

00:27:39,120 --> 00:27:43,950
of the the input that is actually being

00:27:41,880 --> 00:27:45,870
brought by that as well as data

00:27:43,950 --> 00:27:47,490
represent ability right this is how do

00:27:45,870 --> 00:27:49,740
you make sure that your training data is

00:27:47,490 --> 00:27:51,330
as close as possible to your production

00:27:49,740 --> 00:27:53,160
data and this is you know a very

00:27:51,330 --> 00:27:55,110
well-known problem the second one is

00:27:53,160 --> 00:27:56,910
model evaluation you know this is asking

00:27:55,110 --> 00:27:58,860
questions of what are the techniques

00:27:56,910 --> 00:28:01,080
that you can use to evaluate your models

00:27:58,860 --> 00:28:03,300
things like feature importance whether

00:28:01,080 --> 00:28:05,250
you're using black box techniques or

00:28:03,300 --> 00:28:07,730
white box techniques whether you're

00:28:05,250 --> 00:28:09,870
using local methods or global methods

00:28:07,730 --> 00:28:12,240
you know whether you can actually bring

00:28:09,870 --> 00:28:14,010
domain knowledge into your models and

00:28:12,240 --> 00:28:16,260
this is more this is important because

00:28:14,010 --> 00:28:17,700
you know what what you what your what

00:28:16,260 --> 00:28:20,670
your models are doing their learning

00:28:17,700 --> 00:28:23,970
hidden patterns in your data but if you

00:28:20,670 --> 00:28:27,120
can actually give those patterns upfront

00:28:23,970 --> 00:28:29,310
as features or as you know combinations

00:28:27,120 --> 00:28:31,770
of your initial features that leverage

00:28:29,310 --> 00:28:34,020
some of the domain expertise then you're

00:28:31,770 --> 00:28:36,600
able to actually have much more much

00:28:34,020 --> 00:28:38,220
simpler models doing the processing at

00:28:36,600 --> 00:28:42,390
the end right one of the use cases that

00:28:38,220 --> 00:28:45,570
we had is in in automation in NOP so

00:28:42,390 --> 00:28:47,820
automation of document analysis we were

00:28:45,570 --> 00:28:50,310
we actually have been able to leverage a

00:28:47,820 --> 00:28:52,500
lot of the domain expertise of lawyers

00:28:50,310 --> 00:28:55,020
right asking like meta learning

00:28:52,500 --> 00:28:57,990
questions of how do you know this answer

00:28:55,020 --> 00:28:59,970
is correct or what is the process that

00:28:57,990 --> 00:29:01,919
you go into finding and

00:28:59,970 --> 00:29:06,149
right things like that allow you to

00:29:01,919 --> 00:29:07,649
actually build smarter algorithms and

00:29:06,149 --> 00:29:10,139
not just in the machine learning models

00:29:07,649 --> 00:29:11,340
but in the features as well and then the

00:29:10,139 --> 00:29:13,019
more the most important one is the

00:29:11,340 --> 00:29:14,669
production monitoring right is how can

00:29:13,019 --> 00:29:16,259
you then reflect the constraints that

00:29:14,669 --> 00:29:18,389
you're introduced in your

00:29:16,259 --> 00:29:20,399
experimentation and make sure that you

00:29:18,389 --> 00:29:22,950
can set those in production right if you

00:29:20,399 --> 00:29:26,070
if you think that that precision is the

00:29:22,950 --> 00:29:28,679
most important metric and that you you

00:29:26,070 --> 00:29:31,440
you should not have a set of you know

00:29:28,679 --> 00:29:32,429
false positives or false negatives then

00:29:31,440 --> 00:29:33,779
you need to make sure that you're able

00:29:32,429 --> 00:29:35,669
to have something in production that

00:29:33,779 --> 00:29:38,399
allows you to enforce that and monitor

00:29:35,669 --> 00:29:40,860
them right so evaluation of metrics

00:29:38,399 --> 00:29:42,750
manual human review you know for not

00:29:40,860 --> 00:29:44,730
forgetting that you can leverage humans

00:29:42,750 --> 00:29:46,440
to write like that is also something

00:29:44,730 --> 00:29:49,830
that with machine learning you you can

00:29:46,440 --> 00:29:51,809
definitely do and and the cool thing

00:29:49,830 --> 00:29:53,730
about this is that you know with with it

00:29:51,809 --> 00:29:56,610
with the push that we have into the

00:29:53,730 --> 00:29:59,759
kubernetes a world were able to convert

00:29:56,610 --> 00:30:02,850
this this deployment strategies from

00:29:59,759 --> 00:30:05,580
just things like explainers into design

00:30:02,850 --> 00:30:06,720
patterns so instead of just having a you

00:30:05,580 --> 00:30:09,450
know machine learning model in

00:30:06,720 --> 00:30:11,460
production you can have deployment

00:30:09,450 --> 00:30:13,220
strategies where you may have another

00:30:11,460 --> 00:30:16,799
model that is deployed in production

00:30:13,220 --> 00:30:19,710
whose responsibility is to explain and

00:30:16,799 --> 00:30:22,440
you know reverse engineer your initial

00:30:19,710 --> 00:30:24,450
model right and this this may get into a

00:30:22,440 --> 00:30:26,399
little bit of inception but this is

00:30:24,450 --> 00:30:27,509
actually a pattern that has been seen

00:30:26,399 --> 00:30:29,450
quite effective and a lot of

00:30:27,509 --> 00:30:31,980
organizations are starting to adopt

00:30:29,450 --> 00:30:34,379
which we named the explainer pattern

00:30:31,980 --> 00:30:35,700
which is not very original but this is

00:30:34,379 --> 00:30:37,409
what we're gonna be doing now we're

00:30:35,700 --> 00:30:39,629
going to be the we have already our

00:30:37,409 --> 00:30:41,840
model deployed in production we're

00:30:39,629 --> 00:30:44,490
saying that this model is is predicting

00:30:41,840 --> 00:30:47,009
whether someone's loan should be

00:30:44,490 --> 00:30:48,990
approved or rejected and assuming that

00:30:47,009 --> 00:30:51,179
this is a black box model we're now

00:30:48,990 --> 00:30:53,909
going to deploy an explainer that is

00:30:51,179 --> 00:30:57,389
going to explain why our first model is

00:30:53,909 --> 00:30:58,919
behaving as it is right so that's what

00:30:57,389 --> 00:31:01,320
we're gonna be doing now and we're gonna

00:30:58,919 --> 00:31:04,129
be using that same example that we were

00:31:01,320 --> 00:31:06,509
leveraging so now we have our our

00:31:04,129 --> 00:31:08,070
initial model in production we can

00:31:06,509 --> 00:31:10,169
actually reach it through this through

00:31:08,070 --> 00:31:13,500
this URL so what we're gonna do now is

00:31:10,169 --> 00:31:15,750
we're gonna actually leverage this a

00:31:13,500 --> 00:31:18,720
explain ability library for which they

00:31:15,750 --> 00:31:21,720
are actually many of but this is one

00:31:18,720 --> 00:31:24,990
that we maintain its called alibi and it

00:31:21,720 --> 00:31:27,570
offers basically three main approaches

00:31:24,990 --> 00:31:29,580
to black box model predictions so a

00:31:27,570 --> 00:31:32,220
black box model explanations the first

00:31:29,580 --> 00:31:34,770
one is anchors and anchors it answers

00:31:32,220 --> 00:31:37,020
the question of from the features that

00:31:34,770 --> 00:31:39,570
that you sent to your model for

00:31:37,020 --> 00:31:42,540
inference what are the features that

00:31:39,570 --> 00:31:44,340
influence that prediction the most right

00:31:42,540 --> 00:31:45,630
and the way that it does it is by

00:31:44,340 --> 00:31:47,610
actually not like going through all the

00:31:45,630 --> 00:31:50,940
features and replacing a feature for a

00:31:47,610 --> 00:31:53,430
neutral value and then seeing which one

00:31:50,940 --> 00:31:54,750
effects the output the most right so

00:31:53,430 --> 00:31:56,520
this is anchor and this is what we're

00:31:54,750 --> 00:31:58,110
actually going to be using but there's

00:31:56,520 --> 00:32:00,320
another very interesting one called

00:31:58,110 --> 00:32:02,520
you know counterfactuals and

00:32:00,320 --> 00:32:04,260
counterfactuals are basically the

00:32:02,520 --> 00:32:05,940
opposite well not not really the

00:32:04,260 --> 00:32:08,100
opposite but conceptually is the

00:32:05,940 --> 00:32:11,250
opposite of anchors it has the question

00:32:08,100 --> 00:32:13,350
of what is the minimum changes that I

00:32:11,250 --> 00:32:16,160
can get that I can that I can add to

00:32:13,350 --> 00:32:19,380
this input to make that prediction

00:32:16,160 --> 00:32:21,960
incorrect or at least different to what

00:32:19,380 --> 00:32:24,060
it was right so if you were actually you

00:32:21,960 --> 00:32:25,350
know proving someone's loan the question

00:32:24,060 --> 00:32:28,110
would be what are the changes that you

00:32:25,350 --> 00:32:30,420
can make to that input so that the loan

00:32:28,110 --> 00:32:33,330
is rejected right so this this basically

00:32:30,420 --> 00:32:36,180
allows you to understand things like for

00:32:33,330 --> 00:32:37,590
example with with nest you can ask

00:32:36,180 --> 00:32:40,260
questions of well what are the minimum

00:32:37,590 --> 00:32:42,870
changes that you can do to make that

00:32:40,260 --> 00:32:44,850
four not a four but more interestingly

00:32:42,870 --> 00:32:46,500
you can actually go from one class to

00:32:44,850 --> 00:32:48,630
another you can say what is the minimum

00:32:46,500 --> 00:32:52,320
changes that I can do to this four to

00:32:48,630 --> 00:32:54,930
make it a nine right so what we're going

00:32:52,320 --> 00:32:59,100
to be doing is its first anchors on our

00:32:54,930 --> 00:33:01,770
on our data set so well in here we're

00:32:59,100 --> 00:33:03,270
actually just using our Seldon client to

00:33:01,770 --> 00:33:06,240
also get the prediction so we're

00:33:03,270 --> 00:33:07,440
literally just sending a request and you

00:33:06,240 --> 00:33:09,660
know this is the response which is the

00:33:07,440 --> 00:33:10,890
same as their coral but yeah so we're

00:33:09,660 --> 00:33:14,250
gonna create an explainer and we're

00:33:10,890 --> 00:33:16,560
gonna be using alibi and the anchor

00:33:14,250 --> 00:33:18,240
tabular explainer so for this what we're

00:33:16,560 --> 00:33:19,950
gonna be doing is we're gonna take our

00:33:18,240 --> 00:33:21,960
classifier so that classifier that we

00:33:19,950 --> 00:33:24,179
trained that random forest predictor

00:33:21,960 --> 00:33:26,070
that we trained before and we're gonna

00:33:24,179 --> 00:33:27,240
actually expose that that the the

00:33:26,070 --> 00:33:29,039
predict function

00:33:27,240 --> 00:33:30,720
and we're gonna feed that into our

00:33:29,039 --> 00:33:32,700
anchor tabular right because it's going

00:33:30,720 --> 00:33:34,350
to be interacting with the model as if

00:33:32,700 --> 00:33:35,820
it was a black box model it's only going

00:33:34,350 --> 00:33:38,480
to be interacting with the inputs and

00:33:35,820 --> 00:33:38,480
outputs

00:33:45,130 --> 00:33:52,580
when using text or image only when using

00:33:49,880 --> 00:33:54,140
tabular the reason why is because with

00:33:52,580 --> 00:33:56,930
tabular you need to ask the question of

00:33:54,140 --> 00:33:58,430
what what what would be the neutral

00:33:56,930 --> 00:34:00,170
numbers that you would use to replace

00:33:58,430 --> 00:34:01,970
right and in this case for numeric data

00:34:00,170 --> 00:34:03,620
sets you have to get the minimum and the

00:34:01,970 --> 00:34:05,780
maximum and then you say well I wanted

00:34:03,620 --> 00:34:06,920
to be the quartiles or something like

00:34:05,780 --> 00:34:09,110
that that's the only reason why you

00:34:06,920 --> 00:34:11,120
would use the training data but yeah so

00:34:09,110 --> 00:34:14,050
you would fit it and then you would

00:34:11,120 --> 00:34:17,300
actually you know see what is the the

00:34:14,050 --> 00:34:18,950
inputs that we're gonna be sending you

00:34:17,300 --> 00:34:21,770
know we're actually sending this one you

00:34:18,950 --> 00:34:23,510
know somebody of age 27 and we're gonna

00:34:21,770 --> 00:34:26,840
you know we just predict it as negative

00:34:23,510 --> 00:34:29,120
and we're gonna actually explain it and

00:34:26,840 --> 00:34:32,210
it basically says well what makes this

00:34:29,120 --> 00:34:36,650
prediction what it was is the feature

00:34:32,210 --> 00:34:38,870
marital status of separated and gender

00:34:36,650 --> 00:34:42,050
of female right so that's what basically

00:34:38,870 --> 00:34:44,840
your explanation for this instance is

00:34:42,050 --> 00:34:47,090
and what is now starting to get

00:34:44,840 --> 00:34:51,490
interesting is that we're now going to

00:34:47,090 --> 00:34:55,310
actually use our local explainer on our

00:34:51,490 --> 00:34:57,410
model that we basically deployed already

00:34:55,310 --> 00:35:00,800
right so in this case that predict

00:34:57,410 --> 00:35:04,850
function that we basically had we're now

00:35:00,800 --> 00:35:06,560
going to be you know using sort of like

00:35:04,850 --> 00:35:08,990
that remote model so we're actually

00:35:06,560 --> 00:35:11,780
gonna be sending the the request to the

00:35:08,990 --> 00:35:13,550
to the to the to the to the model that

00:35:11,780 --> 00:35:15,740
is currently in our communities cluster

00:35:13,550 --> 00:35:17,660
and when we actually you know request

00:35:15,740 --> 00:35:19,220
the explanation we're gonna get the same

00:35:17,660 --> 00:35:21,440
thing right the only difference that

00:35:19,220 --> 00:35:23,420
we're now actually reaching to that

00:35:21,440 --> 00:35:24,770
model in production and now we're gonna

00:35:23,420 --> 00:35:26,360
actually follow the same things we're

00:35:24,770 --> 00:35:28,820
gonna just containerize the explainer

00:35:26,360 --> 00:35:31,520
and we're gonna put the explainer in put

00:35:28,820 --> 00:35:33,560
it in in production right so you know

00:35:31,520 --> 00:35:35,660
again we actually create a rapper the

00:35:33,560 --> 00:35:37,190
rapper has a predict function the

00:35:35,660 --> 00:35:40,430
predict function just basically takes

00:35:37,190 --> 00:35:43,640
the input and you know runs explained

00:35:40,430 --> 00:35:45,080
and returns the explanation right so now

00:35:43,640 --> 00:35:48,290
what we have in production

00:35:45,080 --> 00:35:50,900
so we've containerized we deploy it and

00:35:48,290 --> 00:35:53,690
now what we have in production is now

00:35:50,900 --> 00:35:55,580
you know an explainer so we have you

00:35:53,690 --> 00:35:58,410
know our lone classifier explainer as

00:35:55,580 --> 00:36:01,300
well as you know our

00:35:58,410 --> 00:36:02,560
initial model so what this is

00:36:01,300 --> 00:36:04,930
interesting is that now you can actually

00:36:02,560 --> 00:36:07,780
send to one of these components a

00:36:04,930 --> 00:36:09,610
request to do an inference and you can

00:36:07,780 --> 00:36:11,950
send another request to explain that

00:36:09,610 --> 00:36:14,380
inference by interacting with that model

00:36:11,950 --> 00:36:17,170
in production and we can actually

00:36:14,380 --> 00:36:19,210
visualize it here if you remember with

00:36:17,170 --> 00:36:22,030
our income classifier if we actually

00:36:19,210 --> 00:36:23,790
have a look at the logs these are all

00:36:22,030 --> 00:36:27,250
the predictions that have gone through

00:36:23,790 --> 00:36:31,840
the model through through through

00:36:27,250 --> 00:36:34,350
basically as requests so we can do now

00:36:31,840 --> 00:36:38,500
is we can actually take one of this and

00:36:34,350 --> 00:36:40,420
send a request for the the explainer to

00:36:38,500 --> 00:36:42,010
explain what's going on and and look

00:36:40,420 --> 00:36:43,119
this is the exact same thing that you

00:36:42,010 --> 00:36:45,760
just saw in the other one but just

00:36:43,119 --> 00:36:47,800
flashy shiny and colorful right like

00:36:45,760 --> 00:36:50,890
this just basically says for that other

00:36:47,800 --> 00:36:53,200
explanation you still have that you know

00:36:50,890 --> 00:36:55,390
marital status of separated influence

00:36:53,200 --> 00:36:58,090
your prediction by this much you know

00:36:55,390 --> 00:37:00,160
gender female by this much and you know

00:36:58,090 --> 00:37:02,350
capital gain by this much and then you

00:37:00,160 --> 00:37:05,680
also can see you know predictions are

00:37:02,350 --> 00:37:08,010
similar or different but in essence you

00:37:05,680 --> 00:37:10,840
know you're still getting the same

00:37:08,010 --> 00:37:12,670
insights as if you were using it locally

00:37:10,840 --> 00:37:13,720
but again you're getting that those sort

00:37:12,670 --> 00:37:16,690
of standardized metrics so that

00:37:13,720 --> 00:37:19,240
explainer also has the metrics exposed

00:37:16,690 --> 00:37:21,310
also has the logs exposed etc etcetera

00:37:19,240 --> 00:37:24,760
so you get that benefit and that's

00:37:21,310 --> 00:37:26,950
basically the the sort of like example

00:37:24,760 --> 00:37:28,810
to the to the explainers and now we're

00:37:26,950 --> 00:37:31,420
actually going to go one one one level

00:37:28,810 --> 00:37:33,490
deeper but before that I want to give

00:37:31,420 --> 00:37:35,380
some some libraries to watch in the

00:37:33,490 --> 00:37:38,859
expert in the model explanation world

00:37:35,380 --> 00:37:41,290
these are le five which is explained

00:37:38,859 --> 00:37:44,040
like I'm five this very cool project

00:37:41,290 --> 00:37:46,290
they do a lot of different techniques

00:37:44,040 --> 00:37:49,900
shop which you've probably come across

00:37:46,290 --> 00:37:54,070
if you are in this space or have looked

00:37:49,900 --> 00:37:55,900
at moral explanations and xai is one

00:37:54,070 --> 00:37:58,390
that we really specifically focused on

00:37:55,900 --> 00:38:01,090
on data so techniques for class

00:37:58,390 --> 00:38:02,830
imbalance etc etc and then again you

00:38:01,090 --> 00:38:05,859
know as I mentioned there's tons right I

00:38:02,830 --> 00:38:08,290
mean with this a black box model

00:38:05,859 --> 00:38:10,180
explanations you know you can actually

00:38:08,290 --> 00:38:11,950
dive into so many different libraries

00:38:10,180 --> 00:38:13,510
it's a very exciting field

00:38:11,950 --> 00:38:16,299
so I do recommend to actually have a

00:38:13,510 --> 00:38:18,490
look now for the last part for the last

00:38:16,299 --> 00:38:20,920
part is on reproducibility so

00:38:18,490 --> 00:38:23,290
reproducibility this basically answers

00:38:20,920 --> 00:38:26,500
the question of how do you keep the

00:38:23,290 --> 00:38:30,190
state of your model with the full

00:38:26,500 --> 00:38:32,260
lineage of data as well as components

00:38:30,190 --> 00:38:35,589
and this really breaks down into the

00:38:32,260 --> 00:38:37,630
abstraction of its constituent steps for

00:38:35,589 --> 00:38:40,000
every single part of your machine

00:38:37,630 --> 00:38:43,359
learning pipeline you're going to have a

00:38:40,000 --> 00:38:46,510
piece of code configuration input data

00:38:43,359 --> 00:38:49,839
right and for each of those things that

00:38:46,510 --> 00:38:52,270
you have you may want to actually freeze

00:38:49,839 --> 00:38:53,500
that as an atomic step and the reason

00:38:52,270 --> 00:38:55,240
you may want to do that is because you

00:38:53,500 --> 00:38:56,950
may want to perhaps you know debug

00:38:55,240 --> 00:38:59,230
something in production or for

00:38:56,950 --> 00:39:01,450
compliance have audit trails of what

00:38:59,230 --> 00:39:03,400
happened when it happened and what did

00:39:01,450 --> 00:39:05,440
you have in there and the reason why

00:39:03,400 --> 00:39:07,990
it's also hard is because it's not only

00:39:05,440 --> 00:39:10,660
the challenge in an individual step the

00:39:07,990 --> 00:39:13,630
challenge also goes onto your you know

00:39:10,660 --> 00:39:15,430
entire pipeline right so each of the

00:39:13,630 --> 00:39:17,470
components on your pipeline each of

00:39:15,430 --> 00:39:20,109
those reusable components may actually

00:39:17,470 --> 00:39:22,630
require to have that level of

00:39:20,109 --> 00:39:24,819
standardization and you saw it with with

00:39:22,630 --> 00:39:26,470
the configuration definition that we had

00:39:24,819 --> 00:39:28,720
in the previous example where we

00:39:26,470 --> 00:39:30,130
actually had a graph definition right

00:39:28,720 --> 00:39:32,170
there you can have multiple different

00:39:30,130 --> 00:39:34,869
components which are docker containers

00:39:32,170 --> 00:39:37,240
which are containerized pieces of your

00:39:34,869 --> 00:39:38,799
atomic steps and one thing is to

00:39:37,240 --> 00:39:41,140
actually be able to keep those atomic

00:39:38,799 --> 00:39:43,630
steps and another one is to actually be

00:39:41,140 --> 00:39:45,640
able to keep the understanding of the

00:39:43,630 --> 00:39:47,799
metadata of the artifacts that are

00:39:45,640 --> 00:39:50,740
within each of these steps right because

00:39:47,799 --> 00:39:52,510
metadata management is hard right and

00:39:50,740 --> 00:39:54,250
now we're getting into a point where

00:39:52,510 --> 00:39:55,720
it's not only metadata management but

00:39:54,250 --> 00:39:58,510
its metadata management on machine

00:39:55,720 --> 00:40:00,549
learning at scale and you know it's

00:39:58,510 --> 00:40:03,549
doable it's just that it requires to

00:40:00,549 --> 00:40:05,349
sort some areas you know a new way of

00:40:03,549 --> 00:40:07,420
thinking and what we're going to be

00:40:05,349 --> 00:40:09,309
diving into here is basically the point

00:40:07,420 --> 00:40:13,240
that we haven't covered we talked about

00:40:09,309 --> 00:40:15,579
models that are already trained but what

00:40:13,240 --> 00:40:18,250
we haven't talked about is potentially

00:40:15,579 --> 00:40:19,930
the process of training models and we're

00:40:18,250 --> 00:40:23,049
actually currently contributors to this

00:40:19,930 --> 00:40:25,059
project called cube flow which I'm not

00:40:23,049 --> 00:40:25,840
sure if you've heard about but a cube

00:40:25,059 --> 00:40:29,020
flow focuses

00:40:25,840 --> 00:40:32,380
on training and experimentation of

00:40:29,020 --> 00:40:34,090
models on kubernetes and what allows you

00:40:32,380 --> 00:40:36,160
to do is to actually build reusable

00:40:34,090 --> 00:40:39,190
components what we're going to be diving

00:40:36,160 --> 00:40:43,620
into in this last example is going to be

00:40:39,190 --> 00:40:45,820
a reusable NLP pipeline in cube flow and

00:40:43,620 --> 00:40:50,670
what this is going to be more

00:40:45,820 --> 00:40:54,340
specifically let me actually open it

00:40:50,670 --> 00:40:57,490
it's going to be this example which I

00:40:54,340 --> 00:40:59,320
have the Jupiter notebook you can try it

00:40:57,490 --> 00:41:02,560
yourselves but we're going to be

00:40:59,320 --> 00:41:04,630
actually creating a pipeline with this

00:41:02,560 --> 00:41:05,080
individual components if you guys have

00:41:04,630 --> 00:41:07,630
ever done

00:41:05,080 --> 00:41:10,930
NLP tasks we're going to be doing a

00:41:07,630 --> 00:41:13,390
let's call it sentiment analysis where

00:41:10,930 --> 00:41:16,990
you would find the usual steps cleaning

00:41:13,390 --> 00:41:18,700
the text tokenizing it vectorizing it

00:41:16,990 --> 00:41:20,830
and then running it through a logistic

00:41:18,700 --> 00:41:22,390
regression classifier right the first

00:41:20,830 --> 00:41:24,580
step is gonna download the data and

00:41:22,390 --> 00:41:28,060
we're basically using the reddit hate

00:41:24,580 --> 00:41:29,530
speech data set so from our science all

00:41:28,060 --> 00:41:33,250
the comments that were deleted from mods

00:41:29,530 --> 00:41:35,050
you know they've been compiled and yeah

00:41:33,250 --> 00:41:37,360
so basically what we have here is this

00:41:35,050 --> 00:41:38,920
components we would want to actually

00:41:37,360 --> 00:41:42,790
create this computational graph in

00:41:38,920 --> 00:41:44,710
production that uses them as separate

00:41:42,790 --> 00:41:46,540
entities and the reason why you want

00:41:44,710 --> 00:41:49,750
that is because maybe you want to reuse

00:41:46,540 --> 00:41:53,110
your spacey tokenizer for different

00:41:49,750 --> 00:41:57,040
other projects and you want to keep

00:41:53,110 --> 00:41:59,950
perhaps your you know holy made a

00:41:57,040 --> 00:42:01,960
feature store right where you actually

00:41:59,950 --> 00:42:03,550
just pick and choose different things

00:42:01,960 --> 00:42:08,110
you know that ultimate drag-and-drop

00:42:03,550 --> 00:42:09,250
data science world but but yes so so

00:42:08,110 --> 00:42:12,760
basically this is what we're gonna be

00:42:09,250 --> 00:42:14,920
doing in this in this example you know

00:42:12,760 --> 00:42:20,260
from a high level perspective what it's

00:42:14,920 --> 00:42:23,170
going to consist of is five repeats of

00:42:20,260 --> 00:42:26,500
wrapping models but in this case it's

00:42:23,170 --> 00:42:27,760
just wrapping scripts in that same

00:42:26,500 --> 00:42:33,370
process that we did previously

00:42:27,760 --> 00:42:37,030
for example the clean text step is

00:42:33,370 --> 00:42:39,520
basically again just a rapper called

00:42:37,030 --> 00:42:43,030
transformer with a predict function that

00:42:39,520 --> 00:42:46,990
takes you know the text as an umpire ray

00:42:43,030 --> 00:42:48,520
it runs the vectorization of that or in

00:42:46,990 --> 00:42:51,010
this case is that is the actual tf-idf

00:42:48,520 --> 00:42:55,300
vectorizer it runs the vectorization and

00:42:51,010 --> 00:42:58,330
then returns the actual vectorized

00:42:55,300 --> 00:43:00,700
output right and then in terms of the

00:42:58,330 --> 00:43:03,460
actual interface to it it's just like a

00:43:00,700 --> 00:43:06,040
CLI but once we have these components

00:43:03,460 --> 00:43:09,190
then you know we're able to define our

00:43:06,040 --> 00:43:11,800
pipeline and we can upload this pipeline

00:43:09,190 --> 00:43:14,320
into cube flow which then looks like

00:43:11,800 --> 00:43:15,640
this right it's basically all of the

00:43:14,320 --> 00:43:18,010
steps which all with all the

00:43:15,640 --> 00:43:22,540
dependencies the only difference is that

00:43:18,010 --> 00:43:24,430
it uses a volume that is attached to

00:43:22,540 --> 00:43:26,440
each of the components to pass the data

00:43:24,430 --> 00:43:27,400
from one container to the other right so

00:43:26,440 --> 00:43:29,380
for each component

00:43:27,400 --> 00:43:30,700
the volume is attached and the

00:43:29,380 --> 00:43:34,180
interesting thing here is that you can

00:43:30,700 --> 00:43:35,890
actually create sort of like experiments

00:43:34,180 --> 00:43:37,390
through your front-end you know you can

00:43:35,890 --> 00:43:40,120
actually choose what parameters you

00:43:37,390 --> 00:43:42,520
expose and you know here I can actually

00:43:40,120 --> 00:43:49,060
change the number of tf-idf features etc

00:43:42,520 --> 00:43:50,050
etc and then just run our pipeline and

00:43:49,060 --> 00:43:51,460
then you can actually see your your

00:43:50,050 --> 00:43:54,010
experiments you can see which ones have

00:43:51,460 --> 00:43:56,890
run and then for each of the of the

00:43:54,010 --> 00:43:59,650
steps you can actually see the input and

00:43:56,890 --> 00:44:01,000
output as you print it for each of the

00:43:59,650 --> 00:44:03,540
of the components so here we can see the

00:44:01,000 --> 00:44:07,720
text coming in and then the tokens

00:44:03,540 --> 00:44:09,520
coming out from from the other side and

00:44:07,720 --> 00:44:12,100
then the last step you know it's a it's

00:44:09,520 --> 00:44:14,560
a deploy and what that basically does it

00:44:12,100 --> 00:44:17,320
just puts it again in in production

00:44:14,560 --> 00:44:21,040
listening so any requests for this

00:44:17,320 --> 00:44:22,510
specific demo what we've done is you

00:44:21,040 --> 00:44:25,360
know you can see the deployed model here

00:44:22,510 --> 00:44:26,590
so it's an NLP cube flow pipeline and

00:44:25,360 --> 00:44:28,780
you know you can see that there's

00:44:26,590 --> 00:44:29,980
actually live requests through each of

00:44:28,780 --> 00:44:33,040
the component so you can see that the

00:44:29,980 --> 00:44:35,560
clean text the Spacey tokenizer the

00:44:33,040 --> 00:44:37,630
vectorizer etc what we're sending it

00:44:35,560 --> 00:44:40,440
live and this is actually quite funny

00:44:37,630 --> 00:44:43,630
we're actually sending all the tweets

00:44:40,440 --> 00:44:47,920
related to brexit do you guys know what

00:44:43,630 --> 00:44:50,260
breaks it is yeah so it's actually doing

00:44:47,920 --> 00:44:51,580
hate speech classification so the funny

00:44:50,260 --> 00:44:53,350
thing is that doesn't matter what side

00:44:51,580 --> 00:44:56,860
you're in there's a lot of hate

00:44:53,350 --> 00:44:59,230
and we can actually see you know here we

00:44:56,860 --> 00:45:01,660
we have this sort of like nice-looking

00:44:59,230 --> 00:45:03,640
logs but you know as I mentioned you can

00:45:01,660 --> 00:45:06,070
also jump into the Cabana and here you

00:45:03,640 --> 00:45:09,070
can see like you know Celtic directs it

00:45:06,070 --> 00:45:10,270
spring yeah well I don't know I don't

00:45:09,070 --> 00:45:11,550
want to read them out loud because there

00:45:10,270 --> 00:45:15,070
are some that you know not very

00:45:11,550 --> 00:45:17,220
appropriate but yeah so so basically now

00:45:15,070 --> 00:45:20,260
we have just this this like production

00:45:17,220 --> 00:45:21,550
you know breaks a classifier that can

00:45:20,260 --> 00:45:24,280
actually be trained with different data

00:45:21,550 --> 00:45:26,890
sets and it just exchanged automatically

00:45:24,280 --> 00:45:31,470
through this step and the objective here

00:45:26,890 --> 00:45:33,580
is to actually just show the sort of

00:45:31,470 --> 00:45:35,770
complexities of this reproducibility

00:45:33,580 --> 00:45:37,870
piece and how their different tools

00:45:35,770 --> 00:45:39,880
trying to tackle it these dives more

00:45:37,870 --> 00:45:42,280
into the experimentation and training

00:45:39,880 --> 00:45:44,230
part and I haven't even dived into the

00:45:42,280 --> 00:45:46,540
pieces around the complexity for

00:45:44,230 --> 00:45:48,700
tracking metrics as you run experiments

00:45:46,540 --> 00:45:50,500
right this is basically I ran ten

00:45:48,700 --> 00:45:52,660
iterations of the model I want to know

00:45:50,500 --> 00:45:54,280
which perform better how do I keep track

00:45:52,660 --> 00:45:57,220
of my metrics as well as the models that

00:45:54,280 --> 00:45:58,360
I used so you know they each of these

00:45:57,220 --> 00:46:00,040
things that I've covered has so many

00:45:58,360 --> 00:46:02,560
different dimensions to tackle them from

00:46:00,040 --> 00:46:05,980
and you know we actually have talks

00:46:02,560 --> 00:46:08,260
online where we have you know an hour an

00:46:05,980 --> 00:46:09,670
hour and a half of just one of this you

00:46:08,260 --> 00:46:11,980
know today was more of like a high-level

00:46:09,670 --> 00:46:14,680
overview and you know other libraries to

00:46:11,980 --> 00:46:18,310
watch you know data version control DVC

00:46:14,680 --> 00:46:21,970
they're basically a gate like sort of

00:46:18,310 --> 00:46:25,870
CLI that allows you to you know run the

00:46:21,970 --> 00:46:28,120
usual sort of like commit push workflows

00:46:25,870 --> 00:46:29,950
but for that sort of like three

00:46:28,120 --> 00:46:34,330
components of your code configuration

00:46:29,950 --> 00:46:36,430
data etc and another one is ml flow from

00:46:34,330 --> 00:46:38,650
data breaks and this focuses on actually

00:46:36,430 --> 00:46:40,270
experiment tracking we actually have

00:46:38,650 --> 00:46:42,550
some some examples where we integrates

00:46:40,270 --> 00:46:44,290
and pachyderm which dives into full

00:46:42,550 --> 00:46:47,380
compliance so as you can see you know

00:46:44,290 --> 00:46:49,060
the ecosystem of this is is so broad but

00:46:47,380 --> 00:46:52,390
it's also at the same time super super

00:46:49,060 --> 00:46:54,400
interesting and yeah so I'm gonna wrap

00:46:52,390 --> 00:46:57,880
up and jump into questions just in case

00:46:54,400 --> 00:46:59,920
anyone has any questions on this or any

00:46:57,880 --> 00:47:02,800
other libraries but before that I'll

00:46:59,920 --> 00:47:05,560
just you know give a few words and this

00:47:02,800 --> 00:47:06,970
on the sort of stuff you know we covered

00:47:05,560 --> 00:47:09,370
you know three of the key

00:47:06,970 --> 00:47:11,890
areas that you know I've been focusing

00:47:09,370 --> 00:47:14,920
on these are orchestration explain

00:47:11,890 --> 00:47:17,050
ability and reproducibility but as I

00:47:14,920 --> 00:47:19,720
mentioned you know the content is you

00:47:17,050 --> 00:47:21,370
know insanely broad things that I

00:47:19,720 --> 00:47:23,770
actually haven't talked about which is

00:47:21,370 --> 00:47:26,920
also insanely interesting are things

00:47:23,770 --> 00:47:28,600
like adversarial robustness you know as

00:47:26,920 --> 00:47:31,330
you saw some of our explained ability

00:47:28,600 --> 00:47:35,740
techniques have an approach to explain

00:47:31,330 --> 00:47:38,290
through adversarial attacks kind of so

00:47:35,740 --> 00:47:40,840
it's also interesting to see how there

00:47:38,290 --> 00:47:43,930
is a lot of overlap across each of these

00:47:40,840 --> 00:47:46,750
areas and and also not only overlap but

00:47:43,930 --> 00:47:49,420
also different levels into which some

00:47:46,750 --> 00:47:51,520
fit in order of the categories right you

00:47:49,420 --> 00:47:53,740
know privacy is one that is super

00:47:51,520 --> 00:47:56,500
interesting that you know we haven't

00:47:53,740 --> 00:48:00,250
covered that dives into privacy privacy

00:47:56,500 --> 00:48:02,340
preserving machine learning which is an

00:48:00,250 --> 00:48:05,380
interesting area and it's self storage

00:48:02,340 --> 00:48:09,220
serialization function as a surveys etc

00:48:05,380 --> 00:48:11,320
etc so with that you know I have been

00:48:09,220 --> 00:48:13,300
able to give a high-level overview of

00:48:11,320 --> 00:48:16,600
the state of production machine learning

00:48:13,300 --> 00:48:19,870
in 2019 it was an exhaustive but you

00:48:16,600 --> 00:48:22,990
know it does feel like it was but yeah

00:48:19,870 --> 00:48:26,040
so if we have some questions I'm happy

00:48:22,990 --> 00:48:29,840
to cover them now or later at the pub

00:48:26,040 --> 00:48:35,659
thank you very much guys pleasure

00:48:29,840 --> 00:48:35,659
[Applause]

00:48:35,800 --> 00:48:39,740
thank you very much for your talk I'm

00:48:38,120 --> 00:48:41,810
actually chairing yellow session so do

00:48:39,740 --> 00:48:44,360
we have questions please come I had come

00:48:41,810 --> 00:48:49,090
to the microphones

00:48:44,360 --> 00:48:49,090
it's working for your questions please

00:48:50,500 --> 00:48:58,130
hi excellent talk thank you I was mostly

00:48:54,410 --> 00:49:00,680
inspired by this explain ability idea

00:48:58,130 --> 00:49:04,580
and have to question about it

00:49:00,680 --> 00:49:09,410
so first let's assume have a lot of

00:49:04,580 --> 00:49:12,920
features and they have like they

00:49:09,410 --> 00:49:17,150
produces a huge space of variants that

00:49:12,920 --> 00:49:20,450
can be huge special variants so it seems

00:49:17,150 --> 00:49:24,650
that when tried to explain this black

00:49:20,450 --> 00:49:26,870
box I need to iterate over all these

00:49:24,650 --> 00:49:29,210
features all variants of these features

00:49:26,870 --> 00:49:35,210
and it seems like performance issue here

00:49:29,210 --> 00:49:36,830
how can it be solved and yeah so that's

00:49:35,210 --> 00:49:37,480
the first question what second one and

00:49:36,830 --> 00:49:40,850
I'll repeat it

00:49:37,480 --> 00:49:48,020
okay it was first yeah and the second

00:49:40,850 --> 00:49:50,180
one that some models itself has some

00:49:48,020 --> 00:49:54,520
information about which important

00:49:50,180 --> 00:50:00,380
importance within it like this random

00:49:54,520 --> 00:50:02,960
forest no have you compared some results

00:50:00,380 --> 00:50:06,350
from this explainer with internal

00:50:02,960 --> 00:50:07,820
results of the model itself mmhmm yeah

00:50:06,350 --> 00:50:10,430
okay no that's that's that's two really

00:50:07,820 --> 00:50:13,490
good questions so the first one was

00:50:10,430 --> 00:50:16,220
basically you know you have a lot of

00:50:13,490 --> 00:50:18,350
features what the computational

00:50:16,220 --> 00:50:24,190
complexity around that and how you deal

00:50:18,350 --> 00:50:24,190
with that the second one is basically on

00:50:24,730 --> 00:50:29,360
what was the second one the second

00:50:26,930 --> 00:50:30,560
question was internal important in

00:50:29,360 --> 00:50:32,450
certain importance they're comparing

00:50:30,560 --> 00:50:34,400
internal importance to to the black box

00:50:32,450 --> 00:50:35,870
model explain ability so yeah yeah okay

00:50:34,400 --> 00:50:39,290
so let's dive first into into the

00:50:35,870 --> 00:50:40,820
computational challenges so that is that

00:50:39,290 --> 00:50:44,180
is a hundred percent correct and in

00:50:40,820 --> 00:50:46,520
terms of anchors as as a technique you

00:50:44,180 --> 00:50:47,869
know we are conscious that in order for

00:50:46,520 --> 00:50:50,450
you to explain

00:50:47,869 --> 00:50:54,170
black box motors as a whole it often

00:50:50,450 --> 00:50:55,819
becomes quite expensive the way that we

00:50:54,170 --> 00:50:58,069
have been able to tackle it is by

00:50:55,819 --> 00:51:01,099
separating the way that you actually

00:50:58,069 --> 00:51:02,779
request explanations and predictions so

00:51:01,099 --> 00:51:04,849
for explanations you may not want

00:51:02,779 --> 00:51:06,859
something that is like real time and for

00:51:04,849 --> 00:51:08,720
every single one of the the predictions

00:51:06,859 --> 00:51:11,930
that go through but instead is for

00:51:08,720 --> 00:51:13,910
actually diving deeper into one or a few

00:51:11,930 --> 00:51:16,099
of the inference predictions that you

00:51:13,910 --> 00:51:17,599
may have right so perhaps what if

00:51:16,099 --> 00:51:20,720
something went wrong you can use

00:51:17,599 --> 00:51:23,089
explanations to debug how it performed

00:51:20,720 --> 00:51:27,470
or if you know the threshold that you

00:51:23,089 --> 00:51:28,970
set for accuracy was 90% you know you

00:51:27,470 --> 00:51:30,740
would only request explanations for

00:51:28,970 --> 00:51:33,319
things that fall on there when you

00:51:30,740 --> 00:51:36,650
assess them so so so that is from one

00:51:33,319 --> 00:51:39,019
side in the other interestingly enough

00:51:36,650 --> 00:51:41,569
this week our data science team just

00:51:39,019 --> 00:51:46,069
published the paper that actually

00:51:41,569 --> 00:51:47,569
proposes a way to deal with the

00:51:46,069 --> 00:51:49,400
computational challenges with

00:51:47,569 --> 00:51:51,499
counterfactuals specifically and with

00:51:49,400 --> 00:51:55,730
contrast of explanations and that is

00:51:51,499 --> 00:51:59,960
basically using prototypes the concept

00:51:55,730 --> 00:52:01,730
of prototypes and this is with sort of

00:51:59,960 --> 00:52:03,200
like neural networks to reduce the

00:52:01,730 --> 00:52:06,589
dimensionality of your features

00:52:03,200 --> 00:52:07,970
themselves so so you know that papers in

00:52:06,589 --> 00:52:10,069
our curve and you can check it out but

00:52:07,970 --> 00:52:11,440
there is a lot of research in that space

00:52:10,069 --> 00:52:14,480
to actually make it more feasible

00:52:11,440 --> 00:52:16,460
without sacrificing the power-on

00:52:14,480 --> 00:52:19,220
explanations you know unfortunately

00:52:16,460 --> 00:52:21,640
there's no silver bullet so you know I

00:52:19,220 --> 00:52:24,380
do acknowledge that it is a challenge

00:52:21,640 --> 00:52:26,329
but then that is why there's the benefit

00:52:24,380 --> 00:52:29,059
of also leveraging white box model

00:52:26,329 --> 00:52:31,099
predictions in certain situations where

00:52:29,059 --> 00:52:32,569
you actually can and fall into your

00:52:31,099 --> 00:52:34,130
second question you can actually

00:52:32,569 --> 00:52:36,529
leverage some of the internal structures

00:52:34,130 --> 00:52:38,630
of the models like random forests or

00:52:36,529 --> 00:52:39,890
neural networks you know you're seeing

00:52:38,630 --> 00:52:43,069
sort of like the weights of the networks

00:52:39,890 --> 00:52:46,009
to actually explain much easier it was a

00:52:43,069 --> 00:52:48,109
worth mentioning that the explanations

00:52:46,009 --> 00:52:49,849
themselves the explainers some of them

00:52:48,109 --> 00:52:51,700
they're optimization problems so for

00:52:49,849 --> 00:52:54,109
example we use gradient descent to find

00:52:51,700 --> 00:52:57,920
some of the explanation techniques for

00:52:54,109 --> 00:52:59,180
the counterfactuals now for the second

00:52:57,920 --> 00:53:01,309
piece in terms of leveraging the

00:52:59,180 --> 00:53:01,790
internal stuff and also seeing how we

00:53:01,309 --> 00:53:03,650
perform

00:53:01,790 --> 00:53:05,960
against the black box models so we

00:53:03,650 --> 00:53:08,750
actually haven't done benchmarks of how

00:53:05,960 --> 00:53:09,620
it performs against but that's

00:53:08,750 --> 00:53:11,240
definitely something that we will be

00:53:09,620 --> 00:53:12,950
interested on if you're interested on

00:53:11,240 --> 00:53:15,740
that you know alibi is open source so we

00:53:12,950 --> 00:53:17,990
would love a pull request or an issue to

00:53:15,740 --> 00:53:20,090
our documentation on that but that's

00:53:17,990 --> 00:53:23,870
that's really good question yeah okay

00:53:20,090 --> 00:53:29,090
thank you thank you do we have more

00:53:23,870 --> 00:53:31,370
questions please go ahead I have two

00:53:29,090 --> 00:53:33,560
questions first is what are you views

00:53:31,370 --> 00:53:36,050
about setting up a kind of a feedback

00:53:33,560 --> 00:53:38,900
loop a pipeline for feedback loops

00:53:36,050 --> 00:53:41,660
saying that after your model has gone

00:53:38,900 --> 00:53:43,790
into production and you have a result at

00:53:41,660 --> 00:53:45,350
the end of the say day saying that hey

00:53:43,790 --> 00:53:46,970
you know what for these these days you

00:53:45,350 --> 00:53:49,310
had the correct predictions and for

00:53:46,970 --> 00:53:51,680
these number of records you had wrong

00:53:49,310 --> 00:53:53,720
predictions how do you go about get

00:53:51,680 --> 00:53:56,120
trading that retraining or incremental

00:53:53,720 --> 00:53:58,790
retraining your model but after it has

00:53:56,120 --> 00:54:00,140
gone out into production yeah that is an

00:53:58,790 --> 00:54:02,450
excellent question and and you know one

00:54:00,140 --> 00:54:05,420
of the that was one of the key things

00:54:02,450 --> 00:54:06,770
that I actually discussed in I guess

00:54:05,420 --> 00:54:08,650
they called it three eight three hour

00:54:06,770 --> 00:54:11,180
workshop I call it three hour rant

00:54:08,650 --> 00:54:13,610
because I was trying to push how

00:54:11,180 --> 00:54:15,170
important that that piece is and

00:54:13,610 --> 00:54:17,060
unfortunately again there's no silver

00:54:15,170 --> 00:54:18,530
bullet in terms of you know you can't

00:54:17,060 --> 00:54:21,260
just deploy a model and have that

00:54:18,530 --> 00:54:23,360
feedback loop out of the box because not

00:54:21,260 --> 00:54:25,280
always you actually have data that is

00:54:23,360 --> 00:54:27,950
relabeled in production right I'll give

00:54:25,280 --> 00:54:30,080
you a specific example if you're doing

00:54:27,950 --> 00:54:33,020
automation of support tickets routing

00:54:30,080 --> 00:54:36,950
then at the end the support tickets will

00:54:33,020 --> 00:54:38,660
be resolved at some point right so

00:54:36,950 --> 00:54:40,640
you're actually getting data that is

00:54:38,660 --> 00:54:42,710
being labeled in real time so you could

00:54:40,640 --> 00:54:45,350
actually get that feedback real-time

00:54:42,710 --> 00:54:47,870
other times where actually labeling of

00:54:45,350 --> 00:54:50,090
data is so expensive you may not have

00:54:47,870 --> 00:54:52,370
that benefit but you may still want to

00:54:50,090 --> 00:54:54,710
have that specific feedback loop and in

00:54:52,370 --> 00:54:56,900
that term you may actually require to

00:54:54,710 --> 00:54:59,690
establish that manually and what I would

00:54:56,900 --> 00:55:02,390
mean say would require every month or

00:54:59,690 --> 00:55:03,950
every week or every year once a year to

00:55:02,390 --> 00:55:07,130
evaluate the performance of the model by

00:55:03,950 --> 00:55:10,280
having a set of random data you know

00:55:07,130 --> 00:55:13,960
perhaps you know on a balanced set of

00:55:10,280 --> 00:55:15,589
classes that is labeled by hand and then

00:55:13,960 --> 00:55:17,180
compared

00:55:15,589 --> 00:55:20,180
what it should be and to see the

00:55:17,180 --> 00:55:22,430
performance so so that feedback loop

00:55:20,180 --> 00:55:24,380
should definitely be in place the way

00:55:22,430 --> 00:55:27,199
that it should be installed is different

00:55:24,380 --> 00:55:29,180
depending on the use cases there is also

00:55:27,199 --> 00:55:30,920
that sort of other part which is not

00:55:29,180 --> 00:55:33,319
feedback loop in terms of performance

00:55:30,920 --> 00:55:36,289
but it could be just feedback of real

00:55:33,319 --> 00:55:38,479
time performance of the metrics and

00:55:36,289 --> 00:55:41,180
actually for for one of the the things

00:55:38,479 --> 00:55:44,509
that I mentioned in the I think it was

00:55:41,180 --> 00:55:45,799
orchestration is you know you may you

00:55:44,509 --> 00:55:47,660
may have like three different models

00:55:45,799 --> 00:55:49,969
that in real time you may want to

00:55:47,660 --> 00:55:51,799
optimize the routing that also other

00:55:49,969 --> 00:55:53,630
type of feedback so in the API in the

00:55:51,799 --> 00:55:56,299
sdk that we build we actually have an

00:55:53,630 --> 00:55:59,089
endpoint called feedback that allows you

00:55:56,299 --> 00:56:01,249
to actually send you know stuff back but

00:55:59,089 --> 00:56:03,140
yeah the the the word feedback can mean

00:56:01,249 --> 00:56:06,650
so many things but on those two specific

00:56:03,140 --> 00:56:07,999
ones that would be my fault and just one

00:56:06,650 --> 00:56:10,880
thing more you mentioned about

00:56:07,999 --> 00:56:12,680
production monitoring yeah and when you

00:56:10,880 --> 00:56:14,209
said that data scientist has to maintain

00:56:12,680 --> 00:56:16,789
a certain number of models and

00:56:14,209 --> 00:56:19,789
production what what would actually

00:56:16,789 --> 00:56:21,559
trigger a manual action on that

00:56:19,789 --> 00:56:23,719
particular model what are the KPI is

00:56:21,559 --> 00:56:26,359
that you actually yeah the prediction

00:56:23,719 --> 00:56:28,309
accuracy is one of them but what

00:56:26,359 --> 00:56:29,719
actually would trigger that yes there is

00:56:28,309 --> 00:56:31,670
something wrong with the model and the

00:56:29,719 --> 00:56:33,529
data scientist needs to actually go and

00:56:31,670 --> 00:56:36,049
evaluate that model from the ground up

00:56:33,529 --> 00:56:38,119
mmm so I think it's not as explicit as

00:56:36,049 --> 00:56:41,420
you know the time the manual time is

00:56:38,119 --> 00:56:44,299
because things go wrong the manual time

00:56:41,420 --> 00:56:46,789
it actually goes all the way from the

00:56:44,299 --> 00:56:48,679
moment the data scientist goes like my

00:56:46,789 --> 00:56:50,839
model is ready I want to put it in

00:56:48,679 --> 00:56:53,539
production for business consumption from

00:56:50,839 --> 00:56:56,329
that moment the the data scientist has

00:56:53,539 --> 00:56:58,429
to think well maybe I need to expose a

00:56:56,329 --> 00:57:00,529
RESTful API so he needs to write he or

00:56:58,429 --> 00:57:03,979
she needs to write the code to actually

00:57:00,529 --> 00:57:06,140
you know wrap it on a flask server then

00:57:03,979 --> 00:57:08,029
it needs to expose the endpoints because

00:57:06,140 --> 00:57:10,249
the endpoints are quite custom are now

00:57:08,029 --> 00:57:11,929
not standardized across all all their

00:57:10,249 --> 00:57:14,059
models that other data scientists you

00:57:11,929 --> 00:57:15,439
know put in production you know he or

00:57:14,059 --> 00:57:18,999
she needs to actually like assess how

00:57:15,439 --> 00:57:21,109
it's performing if something goes wrong

00:57:18,999 --> 00:57:23,239
you know the data science needs to jump

00:57:21,109 --> 00:57:25,279
in and assess why it went wrong if it

00:57:23,239 --> 00:57:27,469
needs to be retrained again they design

00:57:25,279 --> 00:57:29,150
needs to retrain it so it's a lot of

00:57:27,469 --> 00:57:32,330
little things

00:57:29,150 --> 00:57:34,940
require that manual not just input but

00:57:32,330 --> 00:57:37,450
also continuous thinking around that

00:57:34,940 --> 00:57:39,830
because the responsibility of that model

00:57:37,450 --> 00:57:41,930
beyond its ready

00:57:39,830 --> 00:57:44,090
is it still falls within the data

00:57:41,930 --> 00:57:46,280
scientist so it's just be it's just

00:57:44,090 --> 00:57:48,950
pushing it towards that once a model is

00:57:46,280 --> 00:57:50,690
done it it should become similar to

00:57:48,950 --> 00:57:52,070
microservices to certain extent because

00:57:50,690 --> 00:57:54,080
you know as a software engineer you

00:57:52,070 --> 00:57:56,360
still have to jump in and debug it but

00:57:54,080 --> 00:57:56,780
to a certain extent once the model is

00:57:56,360 --> 00:57:59,990
ready

00:57:56,780 --> 00:58:02,270
it becomes a sysadmin or DevOps

00:57:59,990 --> 00:58:04,790
challenge right so then you can have

00:58:02,270 --> 00:58:07,070
hundreds under the same metrics so it's

00:58:04,790 --> 00:58:09,410
not just individual people assessing

00:58:07,070 --> 00:58:11,210
their own things in production and you

00:58:09,410 --> 00:58:12,860
have the same thing with with software

00:58:11,210 --> 00:58:14,360
engineering when you deploy micro

00:58:12,860 --> 00:58:20,270
services you want to avoid that and

00:58:14,360 --> 00:58:24,020
standardize it thank you we have four

00:58:20,270 --> 00:58:29,110
questions do we have more questions for

00:58:24,020 --> 00:58:32,870
our speaker today yes do you have a

00:58:29,110 --> 00:58:34,820
generic components to ensure that the

00:58:32,870 --> 00:58:36,530
confidence levels that are outputted by

00:58:34,820 --> 00:58:41,090
the models are calibrated in one way or

00:58:36,530 --> 00:58:44,480
another so we don't we don't we don't

00:58:41,090 --> 00:58:48,560
have a standardized sort of metric per

00:58:44,480 --> 00:58:51,680
se but you are able to expose custom

00:58:48,560 --> 00:58:53,780
metrics what a standardized is the way

00:58:51,680 --> 00:58:55,070
that these metrics are collected so

00:58:53,780 --> 00:58:57,590
they're collected through Prometheus

00:58:55,070 --> 00:58:59,720
well they're exposed through a metrics

00:58:57,590 --> 00:59:02,300
endpoint that then can be collected

00:58:59,720 --> 00:59:04,220
through Prometheus and then you know

00:59:02,300 --> 00:59:07,730
consumed by graph on ax then it's very

00:59:04,220 --> 00:59:10,760
easy to set thresholds to get notified

00:59:07,730 --> 00:59:12,760
so it is possible to just set thresholds

00:59:10,760 --> 00:59:16,280
for you know any of that standardized

00:59:12,760 --> 00:59:19,430
accuracy metric but then again when you

00:59:16,280 --> 00:59:21,560
say ninety percent accuracy that may

00:59:19,430 --> 00:59:24,770
vary from use case to use case and also

00:59:21,560 --> 00:59:26,900
accuracy is often irrelevant because

00:59:24,770 --> 00:59:28,220
sometimes you know false-positive may

00:59:26,900 --> 00:59:30,110
have more influence than a false

00:59:28,220 --> 00:59:33,440
negative so what we try to standardize

00:59:30,110 --> 00:59:35,720
is the metrics that come out and the way

00:59:33,440 --> 00:59:39,050
that they can be evaluated as opposed to

00:59:35,720 --> 00:59:40,910
the metrics that should be evaluated if

00:59:39,050 --> 00:59:42,360
that if that makes sense yeah

00:59:40,910 --> 00:59:45,210
my question was more

00:59:42,360 --> 00:59:48,750
Leon for instance video classification

00:59:45,210 --> 00:59:51,540
as the example that you gave the model

00:59:48,750 --> 00:59:56,130
can output i'm confidence that it's 80%

00:59:51,540 --> 01:00:01,080
chance negative but maybe it's actually

00:59:56,130 --> 01:00:02,820
not like if you take out of 100

01:00:01,080 --> 01:00:04,290
predictions and you've been the

01:00:02,820 --> 01:00:07,410
predictions by the confidence level you

01:00:04,290 --> 01:00:09,480
could see that the fraction of negatives

01:00:07,410 --> 01:00:12,210
in each bin are not actually reflected

01:00:09,480 --> 01:00:15,810
the the true confidence levels outputted

01:00:12,210 --> 01:00:17,370
by the model and depending on the models

01:00:15,810 --> 01:00:20,250
that you do you might have different

01:00:17,370 --> 01:00:23,220
calibration issues and I was wondering

01:00:20,250 --> 01:00:24,750
if calibration is something that is like

01:00:23,220 --> 01:00:26,790
a generic tool that you could put in

01:00:24,750 --> 01:00:29,250
your pipeline and is something that is

01:00:26,790 --> 01:00:32,190
requested by the users or how to

01:00:29,250 --> 01:00:34,710
leverage the calibration and or maybe

01:00:32,190 --> 01:00:37,230
it's not addressed yet that's it no no I

01:00:34,710 --> 01:00:39,750
think definitely calibration is is one

01:00:37,230 --> 01:00:42,990
of the important things I mean we do

01:00:39,750 --> 01:00:44,370
have some open source work that exposes

01:00:42,990 --> 01:00:46,560
not only the things like the multi-armed

01:00:44,370 --> 01:00:48,740
bandit but also techniques for things

01:00:46,560 --> 01:00:52,050
like outlier detection that you can use

01:00:48,740 --> 01:00:53,310
we don't have like a generic piece but

01:00:52,050 --> 01:00:56,130
that is not because there's no demand

01:00:53,310 --> 01:00:58,560
it's just because we don't have enough

01:00:56,130 --> 01:01:00,060
hands so we'd love that again you know

01:00:58,560 --> 01:01:03,120
it's open source you can open an issue

01:01:00,060 --> 01:01:05,850
if we get enough you know thumbs up then

01:01:03,120 --> 01:01:07,380
you know we definitely prioritize it and

01:01:05,850 --> 01:01:09,480
we actually have a bunch of examples

01:01:07,380 --> 01:01:11,580
we'd love to have just another jupiter

01:01:09,480 --> 01:01:14,250
notebook example showcasing how you

01:01:11,580 --> 01:01:15,510
would do that but that is that is

01:01:14,250 --> 01:01:18,500
definitely good point and it's very a

01:01:15,510 --> 01:01:20,270
very interesting area in this space yeah

01:01:18,500 --> 01:01:27,300
thank you

01:01:20,270 --> 01:01:28,980
we have done maybe for one lost okay if

01:01:27,300 --> 01:01:30,930
we don't have any further questions

01:01:28,980 --> 01:01:33,410
let's have a very warm applause for

01:01:30,930 --> 01:01:33,410
alejandro

01:01:34,890 --> 01:01:36,950

YouTube URL: https://www.youtube.com/watch?v=5ck1wObN65c


