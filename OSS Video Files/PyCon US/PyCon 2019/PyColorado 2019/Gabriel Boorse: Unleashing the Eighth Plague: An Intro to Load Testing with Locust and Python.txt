Title: Gabriel Boorse: Unleashing the Eighth Plague: An Intro to Load Testing with Locust and Python
Publication date: 2019-10-22
Playlist: PyColorado 2019
Description: 
	Puzzling over performance problems in production? Baffling backend bugs bending your brain? Unleash a plague of Locusts on your web app to devour performance problems, permanently! In this talk, you will learn how to leverage Locust for load testing RESTful services and more.
Captions: 
	00:00:00,370 --> 00:00:45,360
[Music]

00:00:42,649 --> 00:00:47,400
hey everybody my name is Gabriel

00:00:45,360 --> 00:00:49,559
greetings from Florida it's great to be

00:00:47,400 --> 00:00:52,680
here at Pike Colorado for the very first

00:00:49,559 --> 00:00:55,140
pie Colorado today I'm gonna be giving

00:00:52,680 --> 00:00:58,710
you an intro to load testing with locust

00:00:55,140 --> 00:01:00,059
and Python unfortunately I've only got

00:00:58,710 --> 00:01:01,710
about 30 minutes because I could go on

00:01:00,059 --> 00:01:04,290
and on about this topic for probably

00:01:01,710 --> 00:01:05,910
over an hour so I'm not going to be

00:01:04,290 --> 00:01:07,590
doing a deep dive into anything this is

00:01:05,910 --> 00:01:09,119
just getting our feet wet or we're doing

00:01:07,590 --> 00:01:10,530
an introduction right so we're gonna

00:01:09,119 --> 00:01:12,780
look at some of the major concepts of

00:01:10,530 --> 00:01:14,940
what load testing is as well some of the

00:01:12,780 --> 00:01:18,530
primary features of a really really cool

00:01:14,940 --> 00:01:21,509
Python library called locust all right

00:01:18,530 --> 00:01:23,700
so the question is what is load testing

00:01:21,509 --> 00:01:26,009
and most of us have a vague idea of this

00:01:23,700 --> 00:01:28,130
right we have this idea of maybe

00:01:26,009 --> 00:01:31,950
hammering a site with lots of traffic

00:01:28,130 --> 00:01:34,440
breaking things right but but there's

00:01:31,950 --> 00:01:36,090
actually a much more rigorous discipline

00:01:34,440 --> 00:01:37,679
of load testing that involves

00:01:36,090 --> 00:01:39,780
exploratory testing where you're

00:01:37,679 --> 00:01:42,690
evaluating the performance of your

00:01:39,780 --> 00:01:43,830
applications at scale and so while we're

00:01:42,690 --> 00:01:45,899
doing this we're asking important

00:01:43,830 --> 00:01:48,539
questions like how many concurrent users

00:01:45,899 --> 00:01:50,399
can my website handle and really what

00:01:48,539 --> 00:01:51,899
kind of quality of service am i

00:01:50,399 --> 00:01:54,270
providing when the site's under heavy

00:01:51,899 --> 00:01:55,709
load and that quality of the service

00:01:54,270 --> 00:01:57,569
term is going to come back later and

00:01:55,709 --> 00:01:58,560
this is really important load testing is

00:01:57,569 --> 00:02:00,780
really important because today

00:01:58,560 --> 00:02:04,020
everything's at scale right code we

00:02:00,780 --> 00:02:05,610
write runs everywhere all the time and

00:02:04,020 --> 00:02:08,310
sometimes sometimes that's really hard

00:02:05,610 --> 00:02:10,679
to sort of wrap your head around when

00:02:08,310 --> 00:02:12,030
you're thinking about it so before we go

00:02:10,679 --> 00:02:13,680
a little bit more into load testing I

00:02:12,030 --> 00:02:16,470
also want to give you some context for

00:02:13,680 --> 00:02:19,050
where load testing belongs in the sort

00:02:16,470 --> 00:02:20,310
of perspective of testing and what you

00:02:19,050 --> 00:02:22,440
might be doing as a part of your

00:02:20,310 --> 00:02:24,360
software development process right so

00:02:22,440 --> 00:02:26,340
this is maybe a familiar diagram from

00:02:24,360 --> 00:02:28,920
left to right where you've got your unit

00:02:26,340 --> 00:02:30,450
testing and unit testing is validating

00:02:28,920 --> 00:02:32,340
the the functionality of individual

00:02:30,450 --> 00:02:33,629
components integration testing is

00:02:32,340 --> 00:02:35,340
putting those components together and

00:02:33,629 --> 00:02:37,830
seeing how they behave and then UI

00:02:35,340 --> 00:02:39,720
testing is is looking at the the user

00:02:37,830 --> 00:02:41,370
interface may be a web application that

00:02:39,720 --> 00:02:43,890
you've built making sure that the page

00:02:41,370 --> 00:02:45,090
load times are correct and then all the

00:02:43,890 --> 00:02:47,160
way out there at the right is something

00:02:45,090 --> 00:02:48,690
that maybe a customer will handle is

00:02:47,160 --> 00:02:50,700
acceptance testing and that's validating

00:02:48,690 --> 00:02:52,140
that you're meeting your SLA s alright

00:02:50,700 --> 00:02:53,489
so this is a left to left to right

00:02:52,140 --> 00:02:55,829
diagram this is something that's maybe

00:02:53,489 --> 00:02:56,280
familiar to us and there's lots of other

00:02:55,829 --> 00:02:58,110
kinds of

00:02:56,280 --> 00:03:00,840
that you could put in here like smoke

00:02:58,110 --> 00:03:03,000
testing sanity testing security such you

00:03:00,840 --> 00:03:04,830
know some other ones but these these

00:03:03,000 --> 00:03:06,630
these four are the core ones that you're

00:03:04,830 --> 00:03:08,310
usually dealing with within a process

00:03:06,630 --> 00:03:11,760
and the question is where does load

00:03:08,310 --> 00:03:13,230
testing fit in on this graph and the

00:03:11,760 --> 00:03:15,120
answer to that is everywhere right you

00:03:13,230 --> 00:03:16,950
can use load testing to validate the

00:03:15,120 --> 00:03:19,440
performance of your application in any

00:03:16,950 --> 00:03:21,450
stage in this process so you can

00:03:19,440 --> 00:03:23,819
validate the performance of individual

00:03:21,450 --> 00:03:25,350
components it's sort of a unit test you

00:03:23,819 --> 00:03:27,660
can validate the performance of

00:03:25,350 --> 00:03:28,980
integration of those components as you

00:03:27,660 --> 00:03:30,780
put them together like an integration

00:03:28,980 --> 00:03:32,790
load test right you validate the

00:03:30,780 --> 00:03:35,700
performance of your UI like load times

00:03:32,790 --> 00:03:38,190
and you're validating the SLA is like I

00:03:35,700 --> 00:03:39,989
already mentioned so this load testing

00:03:38,190 --> 00:03:41,880
fits into our development process at

00:03:39,989 --> 00:03:43,260
every every part of the process right

00:03:41,880 --> 00:03:45,000
and it's valuable because our code is

00:03:43,260 --> 00:03:47,819
everywhere and so this is something we

00:03:45,000 --> 00:03:49,170
should be paying attention to so the

00:03:47,819 --> 00:03:53,819
questions were asking what we're load

00:03:49,170 --> 00:03:55,790
testing are what sort of metrics are we

00:03:53,819 --> 00:03:57,810
getting out when the site is

00:03:55,790 --> 00:03:59,010
experiencing heavy load right and so

00:03:57,810 --> 00:04:02,400
these are the three metrics that we're

00:03:59,010 --> 00:04:04,260
looking for throughput is a measure of

00:04:02,400 --> 00:04:05,459
how many simultaneous requests we can

00:04:04,260 --> 00:04:08,220
handle before something catastrophic

00:04:05,459 --> 00:04:10,560
happens right and a latency is how long

00:04:08,220 --> 00:04:12,060
do these requests take and then finally

00:04:10,560 --> 00:04:13,769
as we're experiencing throughput and

00:04:12,060 --> 00:04:15,630
latency what kind of braking points do

00:04:13,769 --> 00:04:17,280
we see you know the in these braking

00:04:15,630 --> 00:04:19,350
points are situations where the

00:04:17,280 --> 00:04:21,209
application just gives up and dies right

00:04:19,350 --> 00:04:23,310
and so an illustration of this would be

00:04:21,209 --> 00:04:25,110
like an e-commerce site that's expecting

00:04:23,310 --> 00:04:27,450
heavy load maybe before Christmas or

00:04:25,110 --> 00:04:29,280
Black Friday you've got a 70% off sale

00:04:27,450 --> 00:04:31,050
and you're expecting tens of thousands

00:04:29,280 --> 00:04:33,150
hundreds of thousands you know many many

00:04:31,050 --> 00:04:35,010
users hammering on your site you're

00:04:33,150 --> 00:04:36,450
asking yourself what goes wrong what

00:04:35,010 --> 00:04:38,370
breaks when does it break

00:04:36,450 --> 00:04:40,200
how many concurrent users can I handle

00:04:38,370 --> 00:04:41,970
will kind of throughput latency and

00:04:40,200 --> 00:04:44,490
braking points are we gonna see while

00:04:41,970 --> 00:04:45,810
that's occurring and that's the quality

00:04:44,490 --> 00:04:50,340
of service metrics that we're looking

00:04:45,810 --> 00:04:51,930
for when we're load testing right so I'm

00:04:50,340 --> 00:04:54,090
going to show you a secret to effective

00:04:51,930 --> 00:04:55,470
load testing and keep in mind here

00:04:54,090 --> 00:04:57,390
you're trying to break this code you're

00:04:55,470 --> 00:04:59,210
trying to take the code that you copied

00:04:57,390 --> 00:05:01,169
and pasted from Stack Overflow and

00:04:59,210 --> 00:05:03,450
you're gonna try and push it to its

00:05:01,169 --> 00:05:05,370
limits so the secret to load testing

00:05:03,450 --> 00:05:07,950
effectively is you don't want these

00:05:05,370 --> 00:05:10,499
tests to pass when you discover the

00:05:07,950 --> 00:05:12,240
limits of the code that you copied in

00:05:10,499 --> 00:05:13,499
you improve it and you find the limits

00:05:12,240 --> 00:05:15,990
of the new code and you keep iterating

00:05:13,499 --> 00:05:17,370
again and again on this theme where

00:05:15,990 --> 00:05:19,289
you're you're you're never really going

00:05:17,370 --> 00:05:20,849
to achieve an infinite scale of load

00:05:19,289 --> 00:05:23,999
testing you're never going to be able to

00:05:20,849 --> 00:05:25,889
simulate load at infinite scale to be

00:05:23,999 --> 00:05:28,439
able to test what happens at infinite

00:05:25,889 --> 00:05:30,360
scale so the best you can do is just

00:05:28,439 --> 00:05:32,520
keeping them keep pushing the limits of

00:05:30,360 --> 00:05:35,849
the current code and so another way to

00:05:32,520 --> 00:05:39,060
say this is design load tests that fail

00:05:35,849 --> 00:05:40,710
the purpose of load testing is to

00:05:39,060 --> 00:05:42,479
discover where are your limits right now

00:05:40,710 --> 00:05:44,039
and take it to the next level

00:05:42,479 --> 00:05:47,849
if you leave this talk with anything

00:05:44,039 --> 00:05:50,189
it's this slide alright this is a Python

00:05:47,849 --> 00:05:52,710
conference after all so let's look at

00:05:50,189 --> 00:05:54,120
some code so the library we're gonna be

00:05:52,710 --> 00:05:55,500
talking about it's called locus as I

00:05:54,120 --> 00:05:57,180
already mentioned and this is a pretty

00:05:55,500 --> 00:05:59,400
popular open source library for load

00:05:57,180 --> 00:06:01,500
testing and the real reason I'm talking

00:05:59,400 --> 00:06:03,509
about locus today is because I've used

00:06:01,500 --> 00:06:08,400
other tools in the past does anyone use

00:06:03,509 --> 00:06:11,009
jmeter here yes I see hands I feel your

00:06:08,400 --> 00:06:13,039
pain right so I'm talking about locus so

00:06:11,009 --> 00:06:16,409
you don't have to ever use jmeter again

00:06:13,039 --> 00:06:17,849
it's really easy to use this is the most

00:06:16,409 --> 00:06:22,680
basic load test you can write using

00:06:17,849 --> 00:06:24,419
locust nine lines right so remember that

00:06:22,680 --> 00:06:26,250
unit test from before where we're

00:06:24,419 --> 00:06:27,930
talking about validating the performance

00:06:26,250 --> 00:06:30,599
of a single component that's what this

00:06:27,930 --> 00:06:32,639
is doing we have two classes one's

00:06:30,599 --> 00:06:34,979
called my website user and one's called

00:06:32,639 --> 00:06:37,020
my tasks right my website user here

00:06:34,979 --> 00:06:39,240
there's a lot more configuration things

00:06:37,020 --> 00:06:41,639
you can do with your locust user class

00:06:39,240 --> 00:06:44,069
but for now and for the purposes of this

00:06:41,639 --> 00:06:46,110
of this talk we're just going to be

00:06:44,069 --> 00:06:48,270
doing the bare minimum and focusing on

00:06:46,110 --> 00:06:51,349
what tasks do so we've got a task set

00:06:48,270 --> 00:06:55,800
class here called my tasks right and

00:06:51,349 --> 00:06:58,740
what it's doing is the method annotated

00:06:55,800 --> 00:07:02,000
of that task is going to repeatedly for

00:06:58,740 --> 00:07:04,229
each user repeatedly load a user profile

00:07:02,000 --> 00:07:05,789
using you know self dot client talk yet

00:07:04,229 --> 00:07:07,529
and there's an endpoint that we're

00:07:05,789 --> 00:07:08,129
hitting right so this is great we've got

00:07:07,529 --> 00:07:10,020
a user

00:07:08,129 --> 00:07:11,729
we've got task a task that it can

00:07:10,020 --> 00:07:13,529
execute it's just going to repeatedly

00:07:11,729 --> 00:07:15,419
get this profile and that's you know the

00:07:13,529 --> 00:07:17,909
unit test where it's just validating the

00:07:15,419 --> 00:07:19,440
performance of one component all right

00:07:17,909 --> 00:07:20,870
so that's great so how do I run a load

00:07:19,440 --> 00:07:23,759
test

00:07:20,870 --> 00:07:25,499
you're gonna pip install the library

00:07:23,759 --> 00:07:27,419
pretty simple you could use pip install

00:07:25,499 --> 00:07:30,240
you can use a virtual end choose your

00:07:27,419 --> 00:07:31,650
poison and then there's two different

00:07:30,240 --> 00:07:33,900
ways of actually running the test one is

00:07:31,650 --> 00:07:36,719
with the web UI right and so that that

00:07:33,900 --> 00:07:38,699
allows us to see the load tests in your

00:07:36,719 --> 00:07:40,229
web browser as it's running or you can

00:07:38,699 --> 00:07:42,210
also run it headless Li and this can be

00:07:40,229 --> 00:07:44,249
useful in sort of a CI CD environment

00:07:42,210 --> 00:07:46,559
either way you're gonna see that we're

00:07:44,249 --> 00:07:48,360
passing in the locus file we're passing

00:07:46,559 --> 00:07:49,949
in a host parameter which says this is

00:07:48,360 --> 00:07:51,599
the host name of the website that I'm

00:07:49,949 --> 00:07:54,330
testing so this might be your QA site

00:07:51,599 --> 00:07:55,949
and then in the case of running without

00:07:54,330 --> 00:07:59,249
the web UI you're going to provide these

00:07:55,949 --> 00:08:01,110
- C and - R parameters and - C specifies

00:07:59,249 --> 00:08:02,729
the number of users and that was the my

00:08:01,110 --> 00:08:05,849
website user class that you saw earlier

00:08:02,729 --> 00:08:07,710
the number of users to spawn and - R is

00:08:05,849 --> 00:08:09,930
going to tell you how quickly to spawn

00:08:07,710 --> 00:08:11,129
them right and once those users are all

00:08:09,930 --> 00:08:13,020
spawned they're just gonna start

00:08:11,129 --> 00:08:15,839
hammering the site with the tasks that

00:08:13,020 --> 00:08:17,879
you've provided all right so you're

00:08:15,839 --> 00:08:20,550
running your load test and like I said

00:08:17,879 --> 00:08:22,499
there's a nice web UI that provides you

00:08:20,550 --> 00:08:23,969
the results where you can see the name

00:08:22,499 --> 00:08:25,889
of the requests that you're making how

00:08:23,969 --> 00:08:27,419
many requests are there how many times

00:08:25,889 --> 00:08:28,709
it's failed in this case I somehow I've

00:08:27,419 --> 00:08:30,330
got a perfect one and it never failed

00:08:28,709 --> 00:08:32,219
that's never gonna happen to you trust

00:08:30,330 --> 00:08:35,250
me you've also got median average

00:08:32,219 --> 00:08:36,959
minimum and maximum request times you

00:08:35,250 --> 00:08:39,209
can see all the way there at the maximum

00:08:36,959 --> 00:08:41,909
2.8 seconds that's so that's a little

00:08:39,209 --> 00:08:43,620
long so this is great I can write a load

00:08:41,909 --> 00:08:45,720
test that sends hundreds of thousands of

00:08:43,620 --> 00:08:48,000
requests to just hammer on my

00:08:45,720 --> 00:08:49,649
application but the problem is that this

00:08:48,000 --> 00:08:52,050
test is not much better than a cat

00:08:49,649 --> 00:08:53,430
pressing refresh on my laptop and I just

00:08:52,050 --> 00:08:56,550
wanted an excuse to put a cat gif in

00:08:53,430 --> 00:08:58,800
this talk so I have great news for you

00:08:56,550 --> 00:09:01,380
we've locust our test can become a lot

00:08:58,800 --> 00:09:03,569
more sophisticated so now we're looking

00:09:01,380 --> 00:09:05,250
at a different load test right we've

00:09:03,569 --> 00:09:07,769
still got the same my website user based

00:09:05,250 --> 00:09:10,199
on HTTP locust and now we've got two

00:09:07,769 --> 00:09:12,569
tasks and the parameter that we're

00:09:10,199 --> 00:09:14,940
passing to the at tasks decorator here

00:09:12,569 --> 00:09:18,300
two and three those are the weights for

00:09:14,940 --> 00:09:21,660
those tasks so now every five times this

00:09:18,300 --> 00:09:23,579
user is executing a task out of you know

00:09:21,660 --> 00:09:25,889
as it as it's running the load test two

00:09:23,579 --> 00:09:27,750
times out of five it's going to do you

00:09:25,889 --> 00:09:29,220
know hit the products carpets endpoint

00:09:27,750 --> 00:09:30,510
you know some other endpoint and then

00:09:29,220 --> 00:09:31,890
three times out of five it's going to

00:09:30,510 --> 00:09:34,010
hit a different endpoint and this allows

00:09:31,890 --> 00:09:36,420
us to sort of simulate maybe different

00:09:34,010 --> 00:09:37,260
randomization of requests that are

00:09:36,420 --> 00:09:39,840
coming in on

00:09:37,260 --> 00:09:42,450
on our site and something I want to draw

00:09:39,840 --> 00:09:43,890
attention to here I just want to point

00:09:42,450 --> 00:09:46,080
out that that's the weights something I

00:09:43,890 --> 00:09:48,060
want to draw attention to here is the

00:09:46,080 --> 00:09:50,610
the client object provided on the tasks

00:09:48,060 --> 00:09:52,230
set the client object is actually just a

00:09:50,610 --> 00:09:55,050
wrapper for a library that you probably

00:09:52,230 --> 00:09:57,930
used before which is requests right and

00:09:55,050 --> 00:09:59,790
so what locus does is it provides this

00:09:57,930 --> 00:10:02,190
client that when you make requests

00:09:59,790 --> 00:10:03,960
depending on the the status code that

00:10:02,190 --> 00:10:07,080
you get from that request it will

00:10:03,960 --> 00:10:09,150
register for success or failure within

00:10:07,080 --> 00:10:10,500
the state of locus so that at the end it

00:10:09,150 --> 00:10:14,370
can show you those results how many

00:10:10,500 --> 00:10:15,390
failed how many passed right all right

00:10:14,370 --> 00:10:17,040
so this is an improvement of the

00:10:15,390 --> 00:10:17,340
original one we're not just refreshing

00:10:17,040 --> 00:10:19,320
the page

00:10:17,340 --> 00:10:20,640
we're randomizing the requests a little

00:10:19,320 --> 00:10:22,050
bit but this doesn't seem like typical

00:10:20,640 --> 00:10:24,210
user behavior I'm not switching between

00:10:22,050 --> 00:10:27,810
tabs when I'm using website just

00:10:24,210 --> 00:10:30,810
refreshing so my observation is usually

00:10:27,810 --> 00:10:32,730
users will perform tasks within a

00:10:30,810 --> 00:10:35,550
sequence step by step and this is

00:10:32,730 --> 00:10:37,020
something that locus allows us to do so

00:10:35,550 --> 00:10:38,880
here's another example I've cut off the

00:10:37,020 --> 00:10:41,910
user because it's the same as in the

00:10:38,880 --> 00:10:43,950
other examples here we have three tasks

00:10:41,910 --> 00:10:46,950
and the first one I'm just illustrating

00:10:43,950 --> 00:10:48,420
here that you can do a post request you

00:10:46,950 --> 00:10:51,300
can do anything that you normally would

00:10:48,420 --> 00:10:54,570
with requests and you can see that we

00:10:51,300 --> 00:10:56,700
now have a sequence task decorator here

00:10:54,570 --> 00:10:58,800
which defines the order in which these

00:10:56,700 --> 00:11:00,870
tasks are going to get executed so now

00:10:58,800 --> 00:11:03,000
when we run our tests we spin up a

00:11:00,870 --> 00:11:06,060
thousand users and each one of these has

00:11:03,000 --> 00:11:08,550
the task sequence and then it's going to

00:11:06,060 --> 00:11:10,920
execute those tasks within that sequence

00:11:08,550 --> 00:11:12,720
so this is great right this is a pretty

00:11:10,920 --> 00:11:14,790
typical user flow there's a lot more

00:11:12,720 --> 00:11:19,020
complexity complexity you can do here

00:11:14,790 --> 00:11:21,140
but that's the general idea all right

00:11:19,020 --> 00:11:23,670
so maybe there are situations where

00:11:21,140 --> 00:11:25,230
having a status code of 200 isn't

00:11:23,670 --> 00:11:27,450
necessarily what we want to use to

00:11:25,230 --> 00:11:30,210
define successful failure so in this

00:11:27,450 --> 00:11:32,550
test here's another example right where

00:11:30,210 --> 00:11:34,500
you're gathering the response with a

00:11:32,550 --> 00:11:36,210
with a width statement and then you're

00:11:34,500 --> 00:11:38,640
checking if this the status code is a

00:11:36,210 --> 00:11:40,860
404 and if it's a 404 maybe that's

00:11:38,640 --> 00:11:42,600
successful in your load test right and

00:11:40,860 --> 00:11:44,100
the thing to keep in mind here is that

00:11:42,600 --> 00:11:46,500
the response object is a wrapper

00:11:44,100 --> 00:11:48,810
provided by locust where it has methods

00:11:46,500 --> 00:11:49,950
that you can use to define the success

00:11:48,810 --> 00:11:55,710
or failure of your

00:11:49,950 --> 00:11:57,390
Tess that's the wrapper method all right

00:11:55,710 --> 00:11:59,250
so now you've run your load tests and

00:11:57,390 --> 00:12:00,720
everything's broken you're seeing 500

00:11:59,250 --> 00:12:02,490
status codes you're seeing out of memory

00:12:00,720 --> 00:12:04,290
errors you're seeing lots of logs

00:12:02,490 --> 00:12:06,390
spitting out of your copied and pasted

00:12:04,290 --> 00:12:08,940
code from Stack Overflow my first piece

00:12:06,390 --> 00:12:10,500
of advice is don't panic and this is

00:12:08,940 --> 00:12:12,360
great right you're we're recognizing

00:12:10,500 --> 00:12:13,920
that we've reached the goal that we set

00:12:12,360 --> 00:12:16,170
out to achieve because we found the

00:12:13,920 --> 00:12:19,080
breaking point the goal in the beginning

00:12:16,170 --> 00:12:20,610
was to design tests that fail so this is

00:12:19,080 --> 00:12:23,700
a good thing this is a good reaction to

00:12:20,610 --> 00:12:25,680
have what we need to do next is get a

00:12:23,700 --> 00:12:27,660
get value from our load test results

00:12:25,680 --> 00:12:29,640
right and here are three ways that we

00:12:27,660 --> 00:12:31,740
can get the most value out of load tests

00:12:29,640 --> 00:12:33,540
the number one thing we need to do is

00:12:31,740 --> 00:12:34,680
measure everything right and look it's

00:12:33,540 --> 00:12:36,780
really helps you out with this as you

00:12:34,680 --> 00:12:38,220
saw in the UI view from earlier because

00:12:36,780 --> 00:12:40,080
it provides a number of requests that

00:12:38,220 --> 00:12:42,210
have passed or failed depending on how

00:12:40,080 --> 00:12:44,160
you define that and it provides the

00:12:42,210 --> 00:12:46,650
latency graphs it provides a

00:12:44,160 --> 00:12:48,180
distribution of requests with you know

00:12:46,650 --> 00:12:52,380
how many milliseconds it took to respond

00:12:48,180 --> 00:12:54,450
so locus kind of has this built in right

00:12:52,380 --> 00:12:57,300
but the other two maybe not so much

00:12:54,450 --> 00:12:59,040
because that's only giving us a very

00:12:57,300 --> 00:13:00,330
narrow-minded perspective from from the

00:12:59,040 --> 00:13:02,310
perspective of the client we don't know

00:13:00,330 --> 00:13:03,660
what's going on in the back end so what

00:13:02,310 --> 00:13:06,180
we also need to consider is that our

00:13:03,660 --> 00:13:07,410
systems are really complicated when

00:13:06,180 --> 00:13:08,910
you're doing load testing you need to

00:13:07,410 --> 00:13:10,680
think of your application as a beating

00:13:08,910 --> 00:13:12,330
heart where you need to identify a

00:13:10,680 --> 00:13:13,980
clogged artery you may have multiple

00:13:12,330 --> 00:13:15,600
different pieces that are all

00:13:13,980 --> 00:13:17,940
interacting with each other and more

00:13:15,600 --> 00:13:20,340
often than not your high loop your high

00:13:17,940 --> 00:13:21,960
latency and low throughput are caused by

00:13:20,340 --> 00:13:23,940
one part of the system causing other

00:13:21,960 --> 00:13:26,040
ones to wait for it right so you need to

00:13:23,940 --> 00:13:28,230
be asking yourself what database calls

00:13:26,040 --> 00:13:30,120
am i making what calls other services am

00:13:28,230 --> 00:13:32,040
i making and other performance issues

00:13:30,120 --> 00:13:35,010
related to i/o or something like that

00:13:32,040 --> 00:13:36,680
and then finally we also need to and

00:13:35,010 --> 00:13:39,870
this kind of summarizes up the other two

00:13:36,680 --> 00:13:41,850
we need to completely monitor the system

00:13:39,870 --> 00:13:43,680
under test right so we're measuring

00:13:41,850 --> 00:13:45,300
everything so we can find bottlenecks

00:13:43,680 --> 00:13:47,100
and the way that we achieve this is by

00:13:45,300 --> 00:13:49,800
monitoring the system of an under test

00:13:47,100 --> 00:13:51,750
and in my experience you can gather logs

00:13:49,800 --> 00:13:54,660
you can look at the memory usage CPU

00:13:51,750 --> 00:13:56,240
usage IO speeds but honestly the best

00:13:54,660 --> 00:13:59,490
way to do this is to use an APM's

00:13:56,240 --> 00:14:01,800
solution so this could be elastic APM it

00:13:59,490 --> 00:14:03,270
could be sacrified data dog-doo relic

00:14:01,800 --> 00:14:03,630
there's a lot of good options out there

00:14:03,270 --> 00:14:06,660
for

00:14:03,630 --> 00:14:08,970
location performance monitoring right

00:14:06,660 --> 00:14:11,100
and so this is useful like I said when

00:14:08,970 --> 00:14:14,550
you're looking for the clogged artery in

00:14:11,100 --> 00:14:17,190
a hole beating heart so we've identified

00:14:14,550 --> 00:14:19,140
where the problem is right we understand

00:14:17,190 --> 00:14:20,880
what piece of the system is causing

00:14:19,140 --> 00:14:22,410
others to wait for it maybe we

00:14:20,880 --> 00:14:24,600
understand why we're getting latency or

00:14:22,410 --> 00:14:27,510
breaking points so what we need to do

00:14:24,600 --> 00:14:29,820
now is take action and there's three

00:14:27,510 --> 00:14:31,080
progressively worse levels of this right

00:14:29,820 --> 00:14:32,490
so the first one is the one we like

00:14:31,080 --> 00:14:34,470
which is fixing the code and this is the

00:14:32,490 --> 00:14:36,060
best case scenario you have the time to

00:14:34,470 --> 00:14:37,800
do the load testing to understand what's

00:14:36,060 --> 00:14:40,980
going wrong and you actually get to fix

00:14:37,800 --> 00:14:43,110
the code another option here is to also

00:14:40,980 --> 00:14:45,270
scale up Hardware resources and this has

00:14:43,110 --> 00:14:46,950
become a little bit a little bit of a

00:14:45,270 --> 00:14:49,290
better option now that we can use things

00:14:46,950 --> 00:14:50,790
like AWS or Google cloud where we can

00:14:49,290 --> 00:14:54,510
really really easily scale up the

00:14:50,790 --> 00:14:56,010
resources but unfortunately a lot of the

00:14:54,510 --> 00:14:58,110
time you have to live with your findings

00:14:56,010 --> 00:14:59,820
because there's just not enough time to

00:14:58,110 --> 00:15:01,530
continue iterating and that's okay

00:14:59,820 --> 00:15:03,390
actually that's actually an OK thing to

00:15:01,530 --> 00:15:05,760
do because in a lot of situations you

00:15:03,390 --> 00:15:07,740
discover I can't handle ten thousand

00:15:05,760 --> 00:15:09,600
concurrent users right now but I only

00:15:07,740 --> 00:15:13,080
ever get one thousand so I don't need to

00:15:09,600 --> 00:15:14,820
solve a problem that I'm not at all

00:15:13,080 --> 00:15:16,890
right so that's the primary part of the

00:15:14,820 --> 00:15:18,300
talk what I want to go into now are two

00:15:16,890 --> 00:15:21,830
more advanced topics that you can

00:15:18,300 --> 00:15:24,720
encounter when you're doing load testing

00:15:21,830 --> 00:15:27,300
so the first of these is running locusts

00:15:24,720 --> 00:15:30,240
distributed and unfortunately the diet

00:15:27,300 --> 00:15:32,820
the the the terminology used in the

00:15:30,240 --> 00:15:34,440
locust documentation is master and slave

00:15:32,820 --> 00:15:36,780
but I've changed that to be agent and

00:15:34,440 --> 00:15:39,300
controller here what we want to be able

00:15:36,780 --> 00:15:41,130
to do is simulate load and sometimes

00:15:39,300 --> 00:15:42,810
maybe you're running your load tests on

00:15:41,130 --> 00:15:44,970
a single machine you're targeting

00:15:42,810 --> 00:15:46,800
another single machine that's just not

00:15:44,970 --> 00:15:48,900
enough to create the simulation of load

00:15:46,800 --> 00:15:51,420
that we need and so what we can do is

00:15:48,900 --> 00:15:54,180
have a single controller talking to

00:15:51,420 --> 00:15:56,430
agents and all of those agents will then

00:15:54,180 --> 00:15:58,800
load test the system that you're trying

00:15:56,430 --> 00:16:02,130
to break and this is actually pretty

00:15:58,800 --> 00:16:05,160
easy to do in locusts it's built in with

00:16:02,130 --> 00:16:06,750
the expect slaves parameter for the

00:16:05,160 --> 00:16:09,480
controller node and then you can mate

00:16:06,750 --> 00:16:12,870
may spin up multiple VMs potentially all

00:16:09,480 --> 00:16:14,670
of them have a slave argument here and

00:16:12,870 --> 00:16:16,209
then they point to the master and they

00:16:14,670 --> 00:16:18,279
communicate together and

00:16:16,209 --> 00:16:22,110
the controller will coordinate when the

00:16:18,279 --> 00:16:25,779
agents talk to the system under test and

00:16:22,110 --> 00:16:28,089
then finally we're able to also test non

00:16:25,779 --> 00:16:29,980
restful services and this is great

00:16:28,089 --> 00:16:32,649
because there are situations where your

00:16:29,980 --> 00:16:34,869
load testing systems that don't expose

00:16:32,649 --> 00:16:37,149
HTTP endpoints right we're not always

00:16:34,869 --> 00:16:39,519
dealing with REST API s sometimes we're

00:16:37,149 --> 00:16:41,319
using soap some kind of our XML RPC

00:16:39,519 --> 00:16:43,269
right we might be flooding message

00:16:41,319 --> 00:16:44,740
queues like Kafka

00:16:43,269 --> 00:16:47,350
for instance we might be making database

00:16:44,740 --> 00:16:49,959
calls and so the locus library exposes

00:16:47,350 --> 00:16:54,009
some api's for dealing with custom non

00:16:49,959 --> 00:16:56,920
HTTP requests that's a lot of code right

00:16:54,009 --> 00:17:00,550
so here we measure the time that it

00:16:56,920 --> 00:17:02,559
takes to make a my function call and and

00:17:00,550 --> 00:17:05,409
that could be anything right like I said

00:17:02,559 --> 00:17:07,480
it could be a request to a soap API it

00:17:05,409 --> 00:17:09,610
could be you know sending a message on a

00:17:07,480 --> 00:17:11,919
message queue we we measure the time

00:17:09,610 --> 00:17:15,569
that it takes to do that and that can be

00:17:11,919 --> 00:17:18,459
pretty much anything you want and then

00:17:15,569 --> 00:17:20,559
yeah we're saving the result sorry in

00:17:18,459 --> 00:17:23,319
the success variable there and then we

00:17:20,559 --> 00:17:25,510
register these events on locus itself

00:17:23,319 --> 00:17:29,080
and this is using G event which maybe

00:17:25,510 --> 00:17:30,370
some of you are familiar with and that's

00:17:29,080 --> 00:17:32,740
pretty straightforward you can do pretty

00:17:30,370 --> 00:17:34,929
much anything and the anecdote I have

00:17:32,740 --> 00:17:37,120
here is we had a system at a company I

00:17:34,929 --> 00:17:40,240
previously work for where the primary

00:17:37,120 --> 00:17:42,460
input to the system was a Java message

00:17:40,240 --> 00:17:44,440
message queue and so we used a locust

00:17:42,460 --> 00:17:46,299
tests to just flood that message queue

00:17:44,440 --> 00:17:48,010
with messages and then watch as all the

00:17:46,299 --> 00:17:50,110
services pulling off of that queue how

00:17:48,010 --> 00:17:54,279
they behaved how they skill and how they

00:17:50,110 --> 00:17:55,870
eventually broke that's all I have and

00:17:54,279 --> 00:17:58,630
I'm early which is great

00:17:55,870 --> 00:18:00,490
I'd rather be early than go too long so

00:17:58,630 --> 00:18:01,480
my hope is that you'll leave with a

00:18:00,490 --> 00:18:03,490
better understanding of what load

00:18:01,480 --> 00:18:05,350
testing is and what it can do for you

00:18:03,490 --> 00:18:08,049
and I hope you leave with a desire to go

00:18:05,350 --> 00:18:11,200
out and try locust for yourselves and

00:18:08,049 --> 00:18:12,520
also design load tests that fail thanks

00:18:11,200 --> 00:18:14,860
for your time and I think we can take

00:18:12,520 --> 00:18:17,590
questions we've got yeah if you how

00:18:14,860 --> 00:18:20,200
often do you recommend running the load

00:18:17,590 --> 00:18:23,289
test like if you take unit tests we run

00:18:20,200 --> 00:18:25,510
every PR merge integration test we'll

00:18:23,289 --> 00:18:28,950
run like every hour or so what is your

00:18:25,510 --> 00:18:30,340
recommendation for a load test that

00:18:28,950 --> 00:18:33,730
vastly did

00:18:30,340 --> 00:18:35,710
and upon what you're doing and who

00:18:33,730 --> 00:18:38,169
you're working for a lot of the time

00:18:35,710 --> 00:18:39,400
load testing is one of those types of

00:18:38,169 --> 00:18:40,929
testing that kind of falls by the

00:18:39,400 --> 00:18:43,620
wayside and you don't end up getting a

00:18:40,929 --> 00:18:46,090
time to do it but my recommendation

00:18:43,620 --> 00:18:47,950
honestly is that you take a look at the

00:18:46,090 --> 00:18:50,289
scale that you're seeing from your

00:18:47,950 --> 00:18:51,850
application right now and then gauge the

00:18:50,289 --> 00:18:53,679
amount of load testing you do based on

00:18:51,850 --> 00:18:56,049
that so you would look at your metrics

00:18:53,679 --> 00:18:57,909
for how many users you get a day or a

00:18:56,049 --> 00:19:00,039
month or whatever like that and then

00:18:57,909 --> 00:19:03,279
based on those metrics you then decide

00:19:00,039 --> 00:19:05,169
how often to do load testing so you have

00:19:03,279 --> 00:19:07,600
got two decorators over there one is

00:19:05,169 --> 00:19:09,460
tasks and another is sequence tasks and

00:19:07,600 --> 00:19:11,320
they both take two different parameters

00:19:09,460 --> 00:19:13,929
like one is the weight and another is

00:19:11,320 --> 00:19:16,929
the sequence correct what if I want to

00:19:13,929 --> 00:19:18,669
use both weight as well as the sequence

00:19:16,929 --> 00:19:20,950
yeah that's something I wasn't able to

00:19:18,669 --> 00:19:23,470
cover but you can specify multiple

00:19:20,950 --> 00:19:26,380
different tasks sequences or tasks sets

00:19:23,470 --> 00:19:27,549
to a user that's I think I mentioned at

00:19:26,380 --> 00:19:29,529
the beginning I wasn't gonna really

00:19:27,549 --> 00:19:31,210
cover more of the advanced ways that you

00:19:29,529 --> 00:19:32,529
can configure a user but you can

00:19:31,210 --> 00:19:34,750
actually provide it with multiple task

00:19:32,529 --> 00:19:36,730
sets and multiple task sequences and

00:19:34,750 --> 00:19:39,580
there ways you can sort of provide logic

00:19:36,730 --> 00:19:40,960
for when those get used that's something

00:19:39,580 --> 00:19:42,370
you could look at the days are possible

00:19:40,960 --> 00:19:44,770
absolutely thank you

00:19:42,370 --> 00:19:47,409
I'm in the really unfortunate position

00:19:44,770 --> 00:19:48,760
of having to talk a client into

00:19:47,409 --> 00:19:51,520
rewriting jmeter

00:19:48,760 --> 00:19:54,789
tests that are huge and nasty but they

00:19:51,520 --> 00:19:56,880
work is maintainability my best bet or

00:19:54,789 --> 00:20:03,279
what else can I add to that argument to

00:19:56,880 --> 00:20:05,080
hopefully get a rewrite and Locust you

00:20:03,279 --> 00:20:08,169
know that's that's sort of a battle that

00:20:05,080 --> 00:20:10,870
you're gonna have to choose your hell to

00:20:08,169 --> 00:20:13,929
die on honestly I think maintainability

00:20:10,870 --> 00:20:15,730
for Lucas tests is pretty high in my

00:20:13,929 --> 00:20:17,320
experience maintainability is one of the

00:20:15,730 --> 00:20:19,090
things that jmeter just does not have

00:20:17,320 --> 00:20:20,710
and so if you're talking with a client

00:20:19,090 --> 00:20:23,110
and they're asking what a benefit is

00:20:20,710 --> 00:20:25,330
maintain abilities one and

00:20:23,110 --> 00:20:26,919
customizability is one like jmeter is

00:20:25,330 --> 00:20:30,960
still limited on the things that it can

00:20:26,919 --> 00:20:30,960
do you can do anything in locust right

00:20:33,580 --> 00:20:36,240
yes

00:20:37,150 --> 00:20:56,519
[Applause]

00:20:43,220 --> 00:20:56,519

YouTube URL: https://www.youtube.com/watch?v=cRh-S8AA75k


