Title: Talk: Chris Seto - Big O No: Django ORM runtime complexity and how to avoid it using LATERAL JOINS
Publication date: 2021-05-05
Playlist: PyCon US 2020
Description: 
	Presented by:
Chris Seto

N+1 queries are as common as blog posts about how to solve them. What happens when you want to get a list of blog posts, the comments on them, and the comments’ respective authors? An exponential number of queries. The rise of GraphQL and REST APIs that provide “include” semantics make these situations increasingly common and painful. Clever use of prefetch_related and select_related may help in a pinch but never fully solve the problem. Learn how to identify these inefficient queries and optimize them using SQL aggregations and LATERAL JOINs.


Talk slides: https://docs.google.com/presentation/d/1JtlzTGAwcTiltbo_yvxLmm8fTydvhfK5i-wQ9YmS77I/edit?usp=sharing
Talk resources:
- Companion Repo: https://github.com/chrisseto/pycon2020-big-o-no
- Mentioned Library: https://github.com/chrisseto/django-include
Captions: 
	00:00:12,639 --> 00:00:16,720
hey everyone i'm chris cito

00:00:14,240 --> 00:00:18,560
and i'm a software reliability engineer

00:00:16,720 --> 00:00:20,240
over at cockroach labs i work on their

00:00:18,560 --> 00:00:21,439
database as a service platform

00:00:20,240 --> 00:00:26,080
and today we're going to be talking

00:00:21,439 --> 00:00:29,279
about django orm runtime complexity

00:00:26,080 --> 00:00:31,119
so the inspiration for this talk is a

00:00:29,279 --> 00:00:33,040
few years old at this point actually a

00:00:31,119 --> 00:00:34,880
company i previously worked for

00:00:33,040 --> 00:00:36,079
was having some performance issues with

00:00:34,880 --> 00:00:37,840
the rest endpoint

00:00:36,079 --> 00:00:39,600
and upon digging into it we realized

00:00:37,840 --> 00:00:41,040
that every single request to this

00:00:39,600 --> 00:00:43,520
endpoint resulted in

00:00:41,040 --> 00:00:44,079
a couple hundred sql queries being made

00:00:43,520 --> 00:00:46,800
and

00:00:44,079 --> 00:00:47,680
due to some unfortunate choices that we

00:00:46,800 --> 00:00:49,120
made

00:00:47,680 --> 00:00:51,199
we found that traditional mitigation

00:00:49,120 --> 00:00:53,840
tactics weren't

00:00:51,199 --> 00:00:56,320
quite effective enough so naturally we

00:00:53,840 --> 00:00:58,960
dropped down to raw sql

00:00:56,320 --> 00:00:59,840
technically we had a solution we were

00:00:58,960 --> 00:01:01,280
able to

00:00:59,840 --> 00:01:02,960
drop the number of queries made by to

00:01:01,280 --> 00:01:05,040
some point down to one

00:01:02,960 --> 00:01:06,560
and we were also able to pull a couple

00:01:05,040 --> 00:01:07,760
seconds off of this endpoints runtime

00:01:06,560 --> 00:01:09,840
because of that

00:01:07,760 --> 00:01:12,000
however we ended up with a query much

00:01:09,840 --> 00:01:15,520
like the one on the slide

00:01:12,000 --> 00:01:16,960
and we quickly found that queries like

00:01:15,520 --> 00:01:20,159
this become

00:01:16,960 --> 00:01:21,439
very unmaintainable it's pretty easy to

00:01:20,159 --> 00:01:23,439
catch typos because

00:01:21,439 --> 00:01:25,520
sql will validate that for you however

00:01:23,439 --> 00:01:28,080
if you accidentally filter in the wrong

00:01:25,520 --> 00:01:29,600
field or you join on the wrong columns

00:01:28,080 --> 00:01:31,200
things can look like they're working

00:01:29,600 --> 00:01:32,880
pretty well until

00:01:31,200 --> 00:01:35,119
you're in production you realize that

00:01:32,880 --> 00:01:38,479
you've accidentally missed a permissions

00:01:35,119 --> 00:01:41,280
check or something similar to that

00:01:38,479 --> 00:01:43,439
so we deemed this to be largely

00:01:41,280 --> 00:01:44,240
unacceptable on top of that we had to

00:01:43,439 --> 00:01:45,840
create this little

00:01:44,240 --> 00:01:47,840
corner of the code base that was

00:01:45,840 --> 00:01:49,600
incompatible with the rest of it because

00:01:47,840 --> 00:01:52,479
we had to work with the results of raw

00:01:49,600 --> 00:01:54,960
sql queries rather than django models

00:01:52,479 --> 00:01:56,880
so for all those reasons we're going to

00:01:54,960 --> 00:01:57,920
be working within the constraints of

00:01:56,880 --> 00:01:59,759
django's arm

00:01:57,920 --> 00:02:01,040
we want any solutions that we come up

00:01:59,759 --> 00:02:04,000
with

00:02:01,040 --> 00:02:04,640
to be maintainable and like easily

00:02:04,000 --> 00:02:08,000
parsable

00:02:04,640 --> 00:02:09,679
by the human eye not a robot and

00:02:08,000 --> 00:02:11,520
on top of that we want all of our

00:02:09,679 --> 00:02:15,200
solutions to be compatible with

00:02:11,520 --> 00:02:15,200
django's existing ecosystem

00:02:15,599 --> 00:02:19,200
back to the namesake of this talk we're

00:02:16,959 --> 00:02:22,080
going to do a quick overview of what

00:02:19,200 --> 00:02:24,560
big-o notation is

00:02:22,080 --> 00:02:25,840
big o is a way to describe the

00:02:24,560 --> 00:02:28,160
relationship between a

00:02:25,840 --> 00:02:29,040
certain characteristic of a function and

00:02:28,160 --> 00:02:32,239
some number

00:02:29,040 --> 00:02:34,400
n as n approaches infinity now

00:02:32,239 --> 00:02:35,360
generally speaking the characteristic

00:02:34,400 --> 00:02:38,000
we're going to be tracking

00:02:35,360 --> 00:02:39,760
is the runtime of a function and n is

00:02:38,000 --> 00:02:40,879
going to be a data set that is being

00:02:39,760 --> 00:02:42,959
operated on

00:02:40,879 --> 00:02:45,040
however this characteristic can also be

00:02:42,959 --> 00:02:46,080
the memory usage of a function as this

00:02:45,040 --> 00:02:48,080
data set grows

00:02:46,080 --> 00:02:50,720
or even the number of network requests

00:02:48,080 --> 00:02:52,560
that a function ends up making

00:02:50,720 --> 00:02:53,920
looking at our graph we'll see that o of

00:02:52,560 --> 00:02:56,000
one or o of

00:02:53,920 --> 00:02:58,319
any constant value for that matter

00:02:56,000 --> 00:02:59,920
indicates no relationship between this

00:02:58,319 --> 00:03:01,920
n value we're tracking and this

00:02:59,920 --> 00:03:02,560
characteristic we're tracking regardless

00:03:01,920 --> 00:03:05,200
of how

00:03:02,560 --> 00:03:06,159
large n grows our characteristic is

00:03:05,200 --> 00:03:09,920
going to remain

00:03:06,159 --> 00:03:11,680
constant o of n indicates that there is

00:03:09,920 --> 00:03:13,920
a linear relationship between this

00:03:11,680 --> 00:03:15,280
end value and our characteristic so if

00:03:13,920 --> 00:03:18,640
we are iterating over a

00:03:15,280 --> 00:03:19,680
list of n values the run time of that

00:03:18,640 --> 00:03:22,159
function is going to

00:03:19,680 --> 00:03:23,760
increase linearly with the length of

00:03:22,159 --> 00:03:25,440
this list

00:03:23,760 --> 00:03:27,599
o of n squared on the other hand

00:03:25,440 --> 00:03:30,879
indicates a slightly more

00:03:27,599 --> 00:03:32,640
explosive looking relationship between

00:03:30,879 --> 00:03:33,040
this n value and our characteristic

00:03:32,640 --> 00:03:36,000
you'll

00:03:33,040 --> 00:03:37,680
often see this in functions that have

00:03:36,000 --> 00:03:39,920
doubly nested loops

00:03:37,680 --> 00:03:41,120
and as long as we know what the upper

00:03:39,920 --> 00:03:43,280
bound of

00:03:41,120 --> 00:03:44,799
our n value is it's it's pretty okay to

00:03:43,280 --> 00:03:46,400
have characteristics like this we'll say

00:03:44,799 --> 00:03:48,560
that this is the

00:03:46,400 --> 00:03:50,720
maximum value that this characteristic

00:03:48,560 --> 00:03:53,200
can become and we're okay with that

00:03:50,720 --> 00:03:54,159
however if you're in a situation where

00:03:53,200 --> 00:03:56,480
the upper bounds of

00:03:54,159 --> 00:03:57,760
n is unknown this is when this type of

00:03:56,480 --> 00:04:00,799
characters can be

00:03:57,760 --> 00:04:03,840
scary as you aren't really sure how high

00:04:00,799 --> 00:04:06,959
you'll end up growing

00:04:03,840 --> 00:04:10,080
and finally we have our o log n

00:04:06,959 --> 00:04:11,519
o log n indicates that as n

00:04:10,080 --> 00:04:14,640
begins to approach infinity our

00:04:11,519 --> 00:04:17,199
characteristic is going to approach

00:04:14,640 --> 00:04:17,680
some upper bound here now this graph

00:04:17,199 --> 00:04:20,079
isn't

00:04:17,680 --> 00:04:21,440
fantastic i drew it myself but that's

00:04:20,079 --> 00:04:24,080
what we're going for

00:04:21,440 --> 00:04:26,240
and you'll often see this in functions

00:04:24,080 --> 00:04:26,880
that are taking their input and dividing

00:04:26,240 --> 00:04:28,240
in half

00:04:26,880 --> 00:04:30,880
over and over again until they finally

00:04:28,240 --> 00:04:34,320
get a result specifically binary search

00:04:30,880 --> 00:04:35,759
has this type of runtime complexity

00:04:34,320 --> 00:04:37,040
for the purposes of this talk the

00:04:35,759 --> 00:04:37,759
characteristic we're going to be

00:04:37,040 --> 00:04:39,840
tracking

00:04:37,759 --> 00:04:42,080
is the number of sql queries performed

00:04:39,840 --> 00:04:44,639
and our n value is going to be

00:04:42,080 --> 00:04:46,320
the size of our database or the number

00:04:44,639 --> 00:04:47,360
of rows and the number of relations in

00:04:46,320 --> 00:04:49,600
it

00:04:47,360 --> 00:04:52,000
it's important that we're not tracking

00:04:49,600 --> 00:04:55,520
the execution time of these queries

00:04:52,000 --> 00:04:57,440
just the number of queries itself

00:04:55,520 --> 00:04:59,199
why do we care about tracking the number

00:04:57,440 --> 00:05:01,280
of sql queries we're making

00:04:59,199 --> 00:05:02,400
rather than the total execution time of

00:05:01,280 --> 00:05:04,240
these queries

00:05:02,400 --> 00:05:06,240
this is because when we're making very

00:05:04,240 --> 00:05:08,000
very fast queries namely primary key

00:05:06,240 --> 00:05:09,440
lookups we'll find that the amount of

00:05:08,000 --> 00:05:11,120
overhead it takes to

00:05:09,440 --> 00:05:13,199
build the sql send it over to the

00:05:11,120 --> 00:05:15,199
database and get the results back

00:05:13,199 --> 00:05:16,479
often overshadows the amount of time it

00:05:15,199 --> 00:05:18,400
takes for the database to

00:05:16,479 --> 00:05:19,680
execute that query and we'll see that in

00:05:18,400 --> 00:05:21,440
our example here

00:05:19,680 --> 00:05:22,720
if we just load a sequential list of

00:05:21,440 --> 00:05:24,240
users

00:05:22,720 --> 00:05:26,000
this doesn't take very much time at all

00:05:24,240 --> 00:05:27,520
however if we were to load the same

00:05:26,000 --> 00:05:29,919
number of users by making

00:05:27,520 --> 00:05:31,360
n queries and loading them directly by

00:05:29,919 --> 00:05:33,680
the primary key

00:05:31,360 --> 00:05:34,800
it's about 100 times slower and we'll

00:05:33,680 --> 00:05:37,680
see that

00:05:34,800 --> 00:05:38,880
the time it takes to compile this sql

00:05:37,680 --> 00:05:42,160
and just

00:05:38,880 --> 00:05:44,160
get to the database and get back

00:05:42,160 --> 00:05:46,400
takes up a significant portion of this

00:05:44,160 --> 00:05:47,280
time so anything we can do to reduce the

00:05:46,400 --> 00:05:50,000
number of

00:05:47,280 --> 00:05:51,680
fast queries we're making will save us

00:05:50,000 --> 00:05:54,320
an enormous amount of time in our

00:05:51,680 --> 00:05:56,479
execution path let's pretend that we're

00:05:54,320 --> 00:05:58,000
building a blogging platform

00:05:56,479 --> 00:05:59,840
now whenever a user wants to get a

00:05:58,000 --> 00:06:02,160
specific post they'll give us the

00:05:59,840 --> 00:06:03,360
post id we'll look it up and send it

00:06:02,160 --> 00:06:05,039
back to them

00:06:03,360 --> 00:06:06,400
regardless of the number of posts being

00:06:05,039 --> 00:06:08,880
stored in our system

00:06:06,400 --> 00:06:11,440
this operation will always perform

00:06:08,880 --> 00:06:13,520
exactly one query

00:06:11,440 --> 00:06:16,080
this is an example of an of one

00:06:13,520 --> 00:06:17,840
operation

00:06:16,080 --> 00:06:20,000
every post in our system is going to

00:06:17,840 --> 00:06:22,240
have some number of comments attached to

00:06:20,000 --> 00:06:23,440
it and every comment is going to be made

00:06:22,240 --> 00:06:26,080
by an author

00:06:23,440 --> 00:06:27,759
when we go to display these list of

00:06:26,080 --> 00:06:29,919
comments to our users

00:06:27,759 --> 00:06:30,960
we want to also display the author that

00:06:29,919 --> 00:06:33,039
made them

00:06:30,960 --> 00:06:34,000
so as we loop over our list of comments

00:06:33,039 --> 00:06:36,240
we're going to be touching the

00:06:34,000 --> 00:06:37,680
author attribute this is going to result

00:06:36,240 --> 00:06:38,960
in us loading the author from the

00:06:37,680 --> 00:06:41,199
database

00:06:38,960 --> 00:06:42,720
and this is an example of an o of n

00:06:41,199 --> 00:06:45,039
operation

00:06:42,720 --> 00:06:46,319
colloquially this is known as the n plus

00:06:45,039 --> 00:06:47,120
one problem which we're going to be

00:06:46,319 --> 00:06:51,360
diving into

00:06:47,120 --> 00:06:53,680
more later o of n squared operations can

00:06:51,360 --> 00:06:55,680
often happen by accident in a previous

00:06:53,680 --> 00:06:58,080
example we were iterating over a list of

00:06:55,680 --> 00:07:00,080
comments and displaying the authors

00:06:58,080 --> 00:07:01,120
now if we decided to take a step back

00:07:00,080 --> 00:07:03,280
from that and

00:07:01,120 --> 00:07:04,960
iterate over first a list of posts and

00:07:03,280 --> 00:07:06,720
then for all those posts

00:07:04,960 --> 00:07:09,120
load the comments for those posts and

00:07:06,720 --> 00:07:11,360
then display them along with the authors

00:07:09,120 --> 00:07:13,120
this would be an of n squared operation

00:07:11,360 --> 00:07:14,800
as the number of posts grows and the

00:07:13,120 --> 00:07:16,319
number of comments on those posts grows

00:07:14,800 --> 00:07:16,960
the number of queries we end up making

00:07:16,319 --> 00:07:20,319
grows

00:07:16,960 --> 00:07:23,520
exponentially finally we have our

00:07:20,319 --> 00:07:24,479
o login operations now i don't think

00:07:23,520 --> 00:07:26,479
there are any

00:07:24,479 --> 00:07:27,840
practical applications that would result

00:07:26,479 --> 00:07:30,080
in a login

00:07:27,840 --> 00:07:31,360
amount of queries being generated so

00:07:30,080 --> 00:07:32,880
we're not going to cover this any

00:07:31,360 --> 00:07:34,479
further

00:07:32,880 --> 00:07:36,000
so let's talk about the n plus one

00:07:34,479 --> 00:07:37,759
problem

00:07:36,000 --> 00:07:39,599
jumping back to our example earlier of

00:07:37,759 --> 00:07:41,599
an o of n query

00:07:39,599 --> 00:07:43,440
we'll see that as we iterate over our

00:07:41,599 --> 00:07:45,759
comments here every time we touch an

00:07:43,440 --> 00:07:47,919
author it has to be loaded now this is

00:07:45,759 --> 00:07:49,759
the classic n plus one example and it

00:07:47,919 --> 00:07:52,080
can be easily solved by performing a

00:07:49,759 --> 00:07:53,919
join on our authors table conveniently

00:07:52,080 --> 00:07:56,800
for us django's

00:07:53,919 --> 00:07:58,560
select related function will perform

00:07:56,800 --> 00:08:00,720
this join for us and automatically

00:07:58,560 --> 00:08:02,639
populate our author attributes so

00:08:00,720 --> 00:08:04,639
we don't end up with any more additional

00:08:02,639 --> 00:08:05,360
queries we just get one query for this

00:08:04,639 --> 00:08:08,319
entire

00:08:05,360 --> 00:08:09,360
function the situation of having many

00:08:08,319 --> 00:08:11,759
related rows

00:08:09,360 --> 00:08:14,080
is a bit more complicated if we were to

00:08:11,759 --> 00:08:17,039
perform a sql join here we would either

00:08:14,080 --> 00:08:17,840
get a lot of duplicated posts or only

00:08:17,039 --> 00:08:19,440
one comment

00:08:17,840 --> 00:08:21,680
per post depending on what type of join

00:08:19,440 --> 00:08:22,800
we did so to solve this problem we're

00:08:21,680 --> 00:08:23,520
actually going to be looking towards

00:08:22,800 --> 00:08:25,759
django's

00:08:23,520 --> 00:08:27,520
pre-fetch related functionality now

00:08:25,759 --> 00:08:28,960
prefetch related will

00:08:27,520 --> 00:08:31,120
for all the posts that we pull that in

00:08:28,960 --> 00:08:32,719
our query it will find all the comments

00:08:31,120 --> 00:08:34,000
associated with them and then perform an

00:08:32,719 --> 00:08:36,959
in-memory join

00:08:34,000 --> 00:08:38,399
and populate a cache for us so whenever

00:08:36,959 --> 00:08:40,000
we touch our comment set

00:08:38,399 --> 00:08:41,680
attribute we won't actually be doing

00:08:40,000 --> 00:08:44,399
another query we'll just be touching

00:08:41,680 --> 00:08:45,040
this cache and this results in us only

00:08:44,399 --> 00:08:48,720
having to do

00:08:45,040 --> 00:08:50,640
two queries instead of oh within queries

00:08:48,720 --> 00:08:52,000
in real world situations you'll often

00:08:50,640 --> 00:08:53,680
find yourself spanning many

00:08:52,000 --> 00:08:54,000
relationships in order to stitch

00:08:53,680 --> 00:08:55,680
together

00:08:54,000 --> 00:08:58,240
some data that we can send back to our

00:08:55,680 --> 00:09:00,000
end users now we can still reach to

00:08:58,240 --> 00:09:02,240
prefetch related to stop barcode from

00:09:00,000 --> 00:09:03,839
making an explosive amount of queries

00:09:02,240 --> 00:09:05,440
however for every additional

00:09:03,839 --> 00:09:07,040
relationship we end up spanning

00:09:05,440 --> 00:09:09,200
prefetch related is going to have to

00:09:07,040 --> 00:09:10,800
make one additional query to load that

00:09:09,200 --> 00:09:13,760
relationship

00:09:10,800 --> 00:09:15,120
and if you happen to be spanning a very

00:09:13,760 --> 00:09:17,920
high number of relationships

00:09:15,120 --> 00:09:18,640
namely many of the many fields where the

00:09:17,920 --> 00:09:21,040
through table

00:09:18,640 --> 00:09:22,160
actually matters you may find yourself

00:09:21,040 --> 00:09:25,680
in search of

00:09:22,160 --> 00:09:27,440
alternative solutions conveniently we'll

00:09:25,680 --> 00:09:29,279
be talking about an alternative solution

00:09:27,440 --> 00:09:30,320
that gives us the same functionality as

00:09:29,279 --> 00:09:33,519
prefetch related

00:09:30,320 --> 00:09:35,040
but with a single query

00:09:33,519 --> 00:09:36,959
let's talk about some of my favorite and

00:09:35,040 --> 00:09:40,399
morally flexible sql features

00:09:36,959 --> 00:09:42,240
aggregations and lateral joins

00:09:40,399 --> 00:09:43,519
before we talk about sql aggregations

00:09:42,240 --> 00:09:45,760
we're actually going to take a look at

00:09:43,519 --> 00:09:47,760
the json build array function

00:09:45,760 --> 00:09:50,080
now what this function allows us to do

00:09:47,760 --> 00:09:52,000
is take a set of columns

00:09:50,080 --> 00:09:53,839
and roll it up and return it as if it

00:09:52,000 --> 00:09:55,519
were a single column

00:09:53,839 --> 00:09:58,000
now on its own this function isn't

00:09:55,519 --> 00:09:59,120
particularly useful but it forms a very

00:09:58,000 --> 00:10:02,480
important primitive for

00:09:59,120 --> 00:10:02,480
what we're going to be building up to

00:10:02,560 --> 00:10:06,959
sql aggregations are functions that run

00:10:04,959 --> 00:10:09,040
across a given set of rows

00:10:06,959 --> 00:10:10,800
if you've ever used a count query you've

00:10:09,040 --> 00:10:12,800
used a sql aggregation

00:10:10,800 --> 00:10:14,320
generally these are these types of

00:10:12,800 --> 00:10:15,920
functions are used to compute

00:10:14,320 --> 00:10:18,160
some type of statistic about a table

00:10:15,920 --> 00:10:20,320
namely the average sum

00:10:18,160 --> 00:10:21,519
minimum or maximum value of a given

00:10:20,320 --> 00:10:25,120
column

00:10:21,519 --> 00:10:26,480
now databases that support the json data

00:10:25,120 --> 00:10:28,720
type have this

00:10:26,480 --> 00:10:29,519
neat little aggregation called the json

00:10:28,720 --> 00:10:31,920
ag

00:10:29,519 --> 00:10:33,600
and what it allows us to do is rather

00:10:31,920 --> 00:10:36,079
than computing a statistic about a

00:10:33,600 --> 00:10:39,200
column it actually allows us to build up

00:10:36,079 --> 00:10:42,320
a json representation

00:10:39,200 --> 00:10:44,320
or just json object in general over the

00:10:42,320 --> 00:10:46,640
set of a given rows now when we can

00:10:44,320 --> 00:10:47,519
combine that with our json build array

00:10:46,640 --> 00:10:50,240
function

00:10:47,519 --> 00:10:50,880
what we get is the ability to take a set

00:10:50,240 --> 00:10:53,519
of rows

00:10:50,880 --> 00:10:54,720
and bundle it into the place of a single

00:10:53,519 --> 00:10:56,560
column

00:10:54,720 --> 00:10:58,320
now this would be particularly helpful

00:10:56,560 --> 00:11:01,360
if we had some way to

00:10:58,320 --> 00:11:03,360
say run aggregations

00:11:01,360 --> 00:11:05,440
for each row of a given query this would

00:11:03,360 --> 00:11:09,440
allow us to embed

00:11:05,440 --> 00:11:11,519
entire relationships into a single row

00:11:09,440 --> 00:11:13,279
lateral joints give us a way to execute

00:11:11,519 --> 00:11:16,240
effectively a for each loop

00:11:13,279 --> 00:11:17,279
inside a sql query now unfortunately it

00:11:16,240 --> 00:11:19,040
is

00:11:17,279 --> 00:11:21,279
fairly difficult to convince jenga's arm

00:11:19,040 --> 00:11:23,440
to generate anything besides a left or

00:11:21,279 --> 00:11:24,640
inner join so for the purpose of this

00:11:23,440 --> 00:11:26,720
talk we're actually going to be making

00:11:24,640 --> 00:11:27,360
use of what's called a correlated sub

00:11:26,720 --> 00:11:29,600
query

00:11:27,360 --> 00:11:30,800
and a correlated subquery runs on the

00:11:29,600 --> 00:11:33,360
same execution

00:11:30,800 --> 00:11:34,880
path as a lateral join and gives us the

00:11:33,360 --> 00:11:38,320
exact same style

00:11:34,880 --> 00:11:40,880
of for each loop but it is located

00:11:38,320 --> 00:11:42,240
in the select portion of a query rather

00:11:40,880 --> 00:11:44,000
than in the join portion

00:11:42,240 --> 00:11:47,040
and that just makes it a lot more easy

00:11:44,000 --> 00:11:48,560
for us to control in a generated style

00:11:47,040 --> 00:11:50,480
when we take all of these pieces and

00:11:48,560 --> 00:11:53,519
combine them together

00:11:50,480 --> 00:11:55,600
besides getting a very ugly query we

00:11:53,519 --> 00:11:58,399
also get the ability to

00:11:55,600 --> 00:11:59,600
for every row in a query find its

00:11:58,399 --> 00:12:02,320
related rows

00:11:59,600 --> 00:12:02,959
bundle them into a column and return

00:12:02,320 --> 00:12:05,360
that to

00:12:02,959 --> 00:12:06,800
django's orem now in this example here

00:12:05,360 --> 00:12:09,360
we've taken

00:12:06,800 --> 00:12:11,279
all posts in our system and we found all

00:12:09,360 --> 00:12:14,160
comments for those posts

00:12:11,279 --> 00:12:17,040
and squished them into a list of values

00:12:14,160 --> 00:12:19,920
and included that with our results

00:12:17,040 --> 00:12:20,639
now this would be extremely helpful if

00:12:19,920 --> 00:12:23,200
we had

00:12:20,639 --> 00:12:24,240
some way to take these values and turn

00:12:23,200 --> 00:12:26,639
them into

00:12:24,240 --> 00:12:29,680
fully fledged genus models and maybe

00:12:26,639 --> 00:12:31,760
just wedge them into the prefetch cache

00:12:29,680 --> 00:12:33,120
in this case we would get the exact same

00:12:31,760 --> 00:12:36,160
functionality as

00:12:33,120 --> 00:12:37,040
prefetch related gives us only we

00:12:36,160 --> 00:12:38,720
wouldn't have to make

00:12:37,040 --> 00:12:41,360
additional queries every time more

00:12:38,720 --> 00:12:43,120
relationships are spanned

00:12:41,360 --> 00:12:45,200
unfortunately loading the django

00:12:43,120 --> 00:12:46,320
prefetch cache and turning these json

00:12:45,200 --> 00:12:48,560
blobs into models

00:12:46,320 --> 00:12:50,240
is out of scope of this talk we want to

00:12:48,560 --> 00:12:52,560
stay mostly centered around

00:12:50,240 --> 00:12:54,000
how to reduce the overall number of sql

00:12:52,560 --> 00:12:56,399
queries we're making

00:12:54,000 --> 00:12:57,120
however if you are interested in how to

00:12:56,399 --> 00:12:59,360
do that

00:12:57,120 --> 00:13:01,040
i've bundled all of this into a library

00:12:59,360 --> 00:13:04,320
called django include

00:13:01,040 --> 00:13:05,440
more importantly this library provides a

00:13:04,320 --> 00:13:09,040
drop-in replacement

00:13:05,440 --> 00:13:10,959
for pre-fetch related

00:13:09,040 --> 00:13:12,160
you're likely asking yourself should i

00:13:10,959 --> 00:13:15,120
use this technique

00:13:12,160 --> 00:13:16,959
and the unfortunate answer is it depends

00:13:15,120 --> 00:13:18,320
can it help in certain situations

00:13:16,959 --> 00:13:20,480
certainly i've seen it take up to

00:13:18,320 --> 00:13:22,639
seconds off of certain rest end points

00:13:20,480 --> 00:13:24,480
on the other hand is it a silver bullet

00:13:22,639 --> 00:13:26,480
no there's plenty of situations where it

00:13:24,480 --> 00:13:28,000
may end up performing worse

00:13:26,480 --> 00:13:30,959
it's also important that you keep in

00:13:28,000 --> 00:13:32,720
mind what database you're using

00:13:30,959 --> 00:13:34,800
the queries that we're generating here

00:13:32,720 --> 00:13:38,399
are analytical style queries

00:13:34,800 --> 00:13:40,320
not all sql databases are optimized to

00:13:38,399 --> 00:13:41,920
serve analytical style queries

00:13:40,320 --> 00:13:45,040
and we'll also see that pop up and the

00:13:41,920 --> 00:13:47,120
benchmarks that we're about to look into

00:13:45,040 --> 00:13:48,079
before we jump into these quick

00:13:47,120 --> 00:13:51,440
disclaimer

00:13:48,079 --> 00:13:53,680
these are very simple benchmarks

00:13:51,440 --> 00:13:54,959
there are an incredible amount of

00:13:53,680 --> 00:13:56,959
variables that could affect the

00:13:54,959 --> 00:13:57,920
performance of these queries one way or

00:13:56,959 --> 00:13:59,600
the other

00:13:57,920 --> 00:14:00,959
to name a few there's the connection to

00:13:59,600 --> 00:14:03,199
the database there's the

00:14:00,959 --> 00:14:05,120
resources available to the database the

00:14:03,199 --> 00:14:07,519
schema that you're testing against

00:14:05,120 --> 00:14:08,880
and even the volume of the data in your

00:14:07,519 --> 00:14:10,639
schema

00:14:08,880 --> 00:14:12,320
so with that in mind it's important to

00:14:10,639 --> 00:14:14,560
take these with a grain of salt

00:14:12,320 --> 00:14:16,720
and make sure that you test against your

00:14:14,560 --> 00:14:18,639
own environment to determine what may be

00:14:16,720 --> 00:14:20,240
best for your situation

00:14:18,639 --> 00:14:21,760
so for most of these benchmarks we'll

00:14:20,240 --> 00:14:24,639
see that we're running

00:14:21,760 --> 00:14:26,320
effectively neck and neck with a

00:14:24,639 --> 00:14:28,480
prefetch related

00:14:26,320 --> 00:14:30,000
where generally within a few

00:14:28,480 --> 00:14:33,040
milliseconds one way or

00:14:30,000 --> 00:14:34,399
the other of its performance it's not

00:14:33,040 --> 00:14:37,600
until we start loading

00:14:34,399 --> 00:14:39,680
multiple top level rows that we see

00:14:37,600 --> 00:14:41,839
prefetch related starts to outperform

00:14:39,680 --> 00:14:43,120
the strategy

00:14:41,839 --> 00:14:45,279
when we run these benchmarks against

00:14:43,120 --> 00:14:47,199
cockroachdb we'll see effectively the

00:14:45,279 --> 00:14:48,959
same results most of the time

00:14:47,199 --> 00:14:51,519
we're going to be within a few

00:14:48,959 --> 00:14:54,959
milliseconds plus or minus

00:14:51,519 --> 00:14:56,160
of prefetch related however when we look

00:14:54,959 --> 00:14:58,560
at our

00:14:56,160 --> 00:15:00,320
tests of running loading multiple top

00:14:58,560 --> 00:15:02,800
level rows

00:15:00,320 --> 00:15:04,480
we'll see that we're getting absolutely

00:15:02,800 --> 00:15:05,360
blown out of the water by prefetch

00:15:04,480 --> 00:15:08,639
related

00:15:05,360 --> 00:15:10,240
and this is because cockroachdb is

00:15:08,639 --> 00:15:11,600
not optimized for running analytical

00:15:10,240 --> 00:15:13,839
queries it's optimized for earning

00:15:11,600 --> 00:15:15,279
transactions

00:15:13,839 --> 00:15:17,519
unfortunately we don't have a great way

00:15:15,279 --> 00:15:18,639
to ask and answer questions or handle

00:15:17,519 --> 00:15:20,480
comments

00:15:18,639 --> 00:15:22,800
but please feel free to hit me up on

00:15:20,480 --> 00:15:24,880
twitter at underscore ostriches or on

00:15:22,800 --> 00:15:25,199
github at cresceto if you're interested

00:15:24,880 --> 00:15:27,199
and

00:15:25,199 --> 00:15:28,720
how i got these benchmarks or anything

00:15:27,199 --> 00:15:30,079
else related to this talk i'm going to

00:15:28,720 --> 00:15:32,720
be dumping a lot of this

00:15:30,079 --> 00:15:33,600
information into a github repo pycon

00:15:32,720 --> 00:15:41,839
00:15:33,600 --> 00:15:41,839
big oh no thanks for watching

00:15:42,560 --> 00:15:44,639

YouTube URL: https://www.youtube.com/watch?v=GJUL3glrKvA


