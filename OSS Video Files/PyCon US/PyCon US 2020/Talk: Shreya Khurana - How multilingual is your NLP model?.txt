Title: Talk: Shreya Khurana - How multilingual is your NLP model?
Publication date: 2021-05-05
Playlist: PyCon US 2020
Description: 
	Presented by:
Shreya Khurana

Natural language is constantly evolving. With social media having its own language and interactions becoming more global, NLP models need more than just monolingual corpora to understand and make sense of all this data. Roughly, 50% of the world speaks two or more languages. This comes as a challenge to NL systems because conventional models are trained to understand one language or only translate from one to the other. In this talk, we’ll focus on Natural Language Understanding (NLU) for small multilingual texts.

A key step in building NLU systems is language identification. First, we’ll give an introduction to existing frameworks for this task in Python like cld3, langid, langdetect and will also have a short discussion on their shortcomings.

Another area of concern is transliterated and code-switched text, which consists a combination of two or more structurally different grammars and vocabulary. This type of data can be clearly seen in Tweets and comments on Facebook as well as product reviews. What makes this problem very challenging is the lack of annotated datasets and the added noise of having no “correct” grammar and spelling. We discuss the approaches to solve this using web crawlers and self-generated datasets.

The next section of this talk will be on using the multilingual BERT model released by Google, which is trained in 104 languages. We’ll see some examples of how this model performs when given text pieces in different languages. In the final section, we’ll discuss how to evaluate the model for different tasks.




Talk resources: https://github.com/ShreyaKhurana/pycon/
Captions: 
	00:00:13,810 --> 00:00:20,840
hello everyone and welcome to Pike on

00:00:17,000 --> 00:00:24,230
2020 this is my talk on how multilingual

00:00:20,840 --> 00:00:25,700
is your NLP model first of all I would

00:00:24,230 --> 00:00:27,770
just like to say that I would have very

00:00:25,700 --> 00:00:29,630
much like to meet you guys in person and

00:00:27,770 --> 00:00:31,370
Pittsburgh not only because I would have

00:00:29,630 --> 00:00:33,440
enjoyed it more but because you would

00:00:31,370 --> 00:00:35,239
have been a way better audience that my

00:00:33,440 --> 00:00:39,500
laundry bag and you clearly right in

00:00:35,239 --> 00:00:44,120
front of me all right so first a little

00:00:39,500 --> 00:00:46,100
bit about myself um I work as a data

00:00:44,120 --> 00:00:49,489
scientist at GoDaddy I've been working

00:00:46,100 --> 00:00:51,500
there since July last year before that I

00:00:49,489 --> 00:00:52,820
did my masters and statistics from the

00:00:51,500 --> 00:00:55,580
University of Illinois at

00:00:52,820 --> 00:00:57,620
urbana-champaign I work with

00:00:55,580 --> 00:00:59,870
unstructured language data and deep

00:00:57,620 --> 00:01:02,050
learning models before that I've also

00:00:59,870 --> 00:01:04,729
worked on patient hierarchical modeling

00:01:02,050 --> 00:01:06,799
if you have interested you can just give

00:01:04,729 --> 00:01:08,840
me a shout out I will be giving out my

00:01:06,799 --> 00:01:11,630
Linkedin contact and my github as well

00:01:08,840 --> 00:01:13,280
at the end now this presentation has a

00:01:11,630 --> 00:01:15,380
couple of notebooks so if you want to

00:01:13,280 --> 00:01:17,149
follow them you can just go to my github

00:01:15,380 --> 00:01:19,039
link right here and you can find

00:01:17,149 --> 00:01:24,159
everything you need to install and run

00:01:19,039 --> 00:01:26,950
the notebooks over there all right so

00:01:24,159 --> 00:01:29,539
here's how this talk is going to go I

00:01:26,950 --> 00:01:32,539
will be introducing what multilingual

00:01:29,539 --> 00:01:35,590
data is the challenges we see with

00:01:32,539 --> 00:01:38,180
code-switch data and transliteration

00:01:35,590 --> 00:01:41,960
what frameworks we have available for

00:01:38,180 --> 00:01:45,619
lack which identification and how do we

00:01:41,960 --> 00:01:48,380
go about combating those challenges then

00:01:45,619 --> 00:01:51,020
we will be moving to the deep learning

00:01:48,380 --> 00:01:52,850
model which is put and we'll be looking

00:01:51,020 --> 00:01:55,759
at a few examples of how both

00:01:52,850 --> 00:01:58,520
multilingual performs on code-switch

00:01:55,759 --> 00:02:01,159
transliterated data we will also be

00:01:58,520 --> 00:02:07,159
looking at how we can evaluate the bird

00:02:01,159 --> 00:02:09,649
multilingual model so why do we even

00:02:07,159 --> 00:02:12,200
care about multilingual data so right

00:02:09,649 --> 00:02:15,530
now on this earth we are about 7 billion

00:02:12,200 --> 00:02:18,140
people speaking 6800 languages and in

00:02:15,530 --> 00:02:21,440
point 93 countries that is a huge

00:02:18,140 --> 00:02:23,030
statistic around 1.6 billion people

00:02:21,440 --> 00:02:25,340
speak Mandarin

00:02:23,030 --> 00:02:27,410
500 million people eat speak English

00:02:25,340 --> 00:02:30,440
Spanish and Hindi which is my native

00:02:27,410 --> 00:02:32,090
language as well so you see with this

00:02:30,440 --> 00:02:34,280
huge statistic there is a need to

00:02:32,090 --> 00:02:38,030
actually evolve our natural language

00:02:34,280 --> 00:02:40,010
systems so we can incorporate all of the

00:02:38,030 --> 00:02:45,230
customers all of the people across the

00:02:40,010 --> 00:02:47,540
world and remove language barriers all

00:02:45,230 --> 00:02:49,910
right so whenever we work with language

00:02:47,540 --> 00:02:53,450
systems we have a few tasks associated

00:02:49,910 --> 00:02:55,400
with them the first and most basic is

00:02:53,450 --> 00:02:57,830
the tokenization where what we're trying

00:02:55,400 --> 00:02:59,300
to do is let's say we have an input

00:02:57,830 --> 00:03:01,100
sentence we're trying to break it down

00:02:59,300 --> 00:03:04,670
into words that are already present in

00:03:01,100 --> 00:03:06,800
our vocabulary POS targeting means that

00:03:04,670 --> 00:03:08,750
you have to assign all of those words

00:03:06,800 --> 00:03:12,220
certain tags like now an objective

00:03:08,750 --> 00:03:14,420
adverb so on named entity recognition

00:03:12,220 --> 00:03:17,209
where what you're trying to do is figure

00:03:14,420 --> 00:03:19,700
out which words in your input sequence

00:03:17,209 --> 00:03:23,180
are named entities like locations names

00:03:19,700 --> 00:03:24,950
of persons and so on language modeling

00:03:23,180 --> 00:03:27,410
this is by far the most interesting job

00:03:24,950 --> 00:03:29,180
according to me in a language system so

00:03:27,410 --> 00:03:31,160
what you're trying to do is you have an

00:03:29,180 --> 00:03:33,410
input sentence you basically try to

00:03:31,160 --> 00:03:35,209
predict what is the probability of that

00:03:33,410 --> 00:03:37,519
sentence what is the probability of that

00:03:35,209 --> 00:03:40,250
corpus what is the probability that this

00:03:37,519 --> 00:03:45,709
word will occur next given the first few

00:03:40,250 --> 00:03:47,780
words machine translation is as the name

00:03:45,709 --> 00:03:50,180
suggests it's translating from one

00:03:47,780 --> 00:03:52,670
language to the other and right now with

00:03:50,180 --> 00:03:54,980
the boom of noodle networks being used

00:03:52,670 --> 00:03:58,549
in NLP there's a huge research going on

00:03:54,980 --> 00:03:59,810
in this area sequence classification

00:03:58,549 --> 00:04:01,370
could be something like sentiment

00:03:59,810 --> 00:04:03,380
analysis where what you're trying to do

00:04:01,370 --> 00:04:05,120
is you have an input sequence and you're

00:04:03,380 --> 00:04:10,310
just trying to assign it to one or the

00:04:05,120 --> 00:04:12,590
other class now let's see some of the

00:04:10,310 --> 00:04:16,789
examples of this new sort of language

00:04:12,590 --> 00:04:18,140
data that we're seeing so tis which

00:04:16,789 --> 00:04:21,470
means that you will trying to mix

00:04:18,140 --> 00:04:23,750
between syntax or grammar of one

00:04:21,470 --> 00:04:25,550
language with the other and this often

00:04:23,750 --> 00:04:27,500
happens when we have multi lingual

00:04:25,550 --> 00:04:30,200
speakers and they sometimes miss

00:04:27,500 --> 00:04:33,320
elements of multiple languages together

00:04:30,200 --> 00:04:35,400
and you see a variety of phonology

00:04:33,320 --> 00:04:37,900
syntax mixing up

00:04:35,400 --> 00:04:39,939
so like here on the right side you see

00:04:37,900 --> 00:04:41,590
this example where the first two words

00:04:39,939 --> 00:04:43,990
are of English and the rest of the

00:04:41,590 --> 00:04:48,520
sentence is in male and you can often

00:04:43,990 --> 00:04:51,280
see them in conversations this is an

00:04:48,520 --> 00:04:53,530
example in Spanglish so it's a mixture

00:04:51,280 --> 00:04:58,930
of English the first few words and the

00:04:53,530 --> 00:05:00,759
rest ending is of Spanish okay so I took

00:04:58,930 --> 00:05:02,740
the liberty of actually going to my own

00:05:00,759 --> 00:05:04,330
Facebook Timeline and finding out

00:05:02,740 --> 00:05:07,120
examples of code swished and

00:05:04,330 --> 00:05:10,270
transliterated data so this first

00:05:07,120 --> 00:05:13,060
example here is a good switch because

00:05:10,270 --> 00:05:16,060
the first few words in the first example

00:05:13,060 --> 00:05:17,919
are in the transliterated text which

00:05:16,060 --> 00:05:19,840
means it's Hindi but it's actually

00:05:17,919 --> 00:05:22,030
converted to the English alphabet and

00:05:19,840 --> 00:05:23,620
the last three words let me celebrate

00:05:22,030 --> 00:05:28,029
you will be able to recognize they are

00:05:23,620 --> 00:05:30,460
English this example is unique because

00:05:28,029 --> 00:05:32,020
the first few words are in the Hindi

00:05:30,460 --> 00:05:35,379
they have knocked ray script which means

00:05:32,020 --> 00:05:37,930
it's in the native script the last of

00:05:35,379 --> 00:05:40,300
the few words are in English and there's

00:05:37,930 --> 00:05:44,740
also a couple of words which are in

00:05:40,300 --> 00:05:46,509
transliterated English text this is the

00:05:44,740 --> 00:05:48,159
example of a tweet where you would be

00:05:46,509 --> 00:05:50,050
able to recognize the first four words

00:05:48,159 --> 00:05:53,199
when your mom says they are in English

00:05:50,050 --> 00:05:56,020
but the rest of the words are in transit

00:05:53,199 --> 00:05:57,819
related English so these examples are

00:05:56,020 --> 00:06:02,379
pretty common if you look at YouTube

00:05:57,819 --> 00:06:04,990
comments or comments on Amazon tweets or

00:06:02,379 --> 00:06:07,270
on Facebook and this is because whenever

00:06:04,990 --> 00:06:09,099
multilingual speak they tend to mix

00:06:07,270 --> 00:06:15,460
languages and grammars of different

00:06:09,099 --> 00:06:17,080
types together so as part of this

00:06:15,460 --> 00:06:18,940
Facebook's initiative of actually

00:06:17,080 --> 00:06:20,800
breaking down barriers and allowing

00:06:18,940 --> 00:06:24,069
everyone to engage in their own content

00:06:20,800 --> 00:06:25,810
in their own language what they did was

00:06:24,069 --> 00:06:28,330
they started working with transliterated

00:06:25,810 --> 00:06:31,029
text and translating it into either the

00:06:28,330 --> 00:06:32,199
native script or the English script so

00:06:31,029 --> 00:06:34,210
the official definition of

00:06:32,199 --> 00:06:36,400
transliteration is that you convert

00:06:34,210 --> 00:06:40,000
words written in one alphabet to another

00:06:36,400 --> 00:06:42,729
alphabet and that often happens because

00:06:40,000 --> 00:06:46,240
you don't have support for different

00:06:42,729 --> 00:06:48,250
scripts either in your keyboard or if

00:06:46,240 --> 00:06:50,350
you're working on a phone so

00:06:48,250 --> 00:06:54,640
basically it's just easier to work with

00:06:50,350 --> 00:06:56,080
a single set of alphabet so on the left

00:06:54,640 --> 00:06:57,820
hand side of the screen shot you would

00:06:56,080 --> 00:07:00,700
be able to recognize there are different

00:06:57,820 --> 00:07:01,540
scripts there are words in English that

00:07:00,700 --> 00:07:04,240
you wouldn't be able to recognize

00:07:01,540 --> 00:07:06,370
probably um there are words in Spanish

00:07:04,240 --> 00:07:08,230
and so what Facebook did was they

00:07:06,370 --> 00:07:11,380
basically translated everything to

00:07:08,230 --> 00:07:14,110
English and so if you are a speaker who

00:07:11,380 --> 00:07:15,790
does not speak Spanish or other

00:07:14,110 --> 00:07:17,880
languages that are shown in the text

00:07:15,790 --> 00:07:20,350
then you will be able to recognize the

00:07:17,880 --> 00:07:26,740
screenshot on the right and read stuff

00:07:20,350 --> 00:07:29,590
in English all right now he switched

00:07:26,740 --> 00:07:32,740
over to a language identification now

00:07:29,590 --> 00:07:35,290
language identification is a very hard

00:07:32,740 --> 00:07:37,390
problem because there are certain

00:07:35,290 --> 00:07:40,360
vocabularies in many languages which are

00:07:37,390 --> 00:07:42,370
shared and the first framework were

00:07:40,360 --> 00:07:45,970
going to be covering right now is CL d3

00:07:42,370 --> 00:07:48,340
now CLA 3 was this Chrome extension that

00:07:45,970 --> 00:07:49,960
was released by Google and if you ever

00:07:48,340 --> 00:07:54,340
use Chrome you know that it detects

00:07:49,960 --> 00:07:58,450
language right so how it was built was

00:07:54,340 --> 00:08:00,130
using engrams so what they did was so

00:07:58,450 --> 00:08:03,100
let's say you have an input sequence

00:08:00,130 --> 00:08:04,450
they would extract unit grams and they

00:08:03,100 --> 00:08:07,150
would calculate the probability of each

00:08:04,450 --> 00:08:09,700
anagram so unigram in this case is just

00:08:07,150 --> 00:08:11,440
a simple character then they would go to

00:08:09,700 --> 00:08:12,610
buy grams and they would look at pairs

00:08:11,440 --> 00:08:13,930
of characters and what is the

00:08:12,610 --> 00:08:16,240
probability that they're seeing them in

00:08:13,930 --> 00:08:19,150
the input sequence and similarly for

00:08:16,240 --> 00:08:21,729
trigrams then basically they would embed

00:08:19,150 --> 00:08:23,950
all of these unigram probabilities in an

00:08:21,729 --> 00:08:27,160
embedding layer feed that to a hidden

00:08:23,950 --> 00:08:30,630
layer of certain neural neurons and

00:08:27,160 --> 00:08:32,680
basically feed that to a softmax there

00:08:30,630 --> 00:08:34,810
during the inference they would do

00:08:32,680 --> 00:08:36,700
something like extract these engrams

00:08:34,810 --> 00:08:40,240
from the input text calculate the

00:08:36,700 --> 00:08:42,280
probability then they would just go

00:08:40,240 --> 00:08:47,800
through this one forward pass of the

00:08:42,280 --> 00:08:50,650
whole neural network so let's see CL d3

00:08:47,800 --> 00:08:52,570
in practice if suppose C is a set of

00:08:50,650 --> 00:08:54,760
languages that are shown here and it

00:08:52,570 --> 00:08:57,130
also supports or the encircled ones

00:08:54,760 --> 00:08:59,500
which are the transliterated ones so you

00:08:57,130 --> 00:09:02,130
can see that it supports Chinese

00:08:59,500 --> 00:09:06,430
transliterated Russian

00:09:02,130 --> 00:09:09,220
creak which is a l.j a which is Japanese

00:09:06,430 --> 00:09:12,190
a chai which is Hindi and the latter

00:09:09,220 --> 00:09:14,980
prefix or suffix or just means that it's

00:09:12,190 --> 00:09:16,690
transliterated so CL III has this

00:09:14,980 --> 00:09:18,700
function called gate language wherein if

00:09:16,690 --> 00:09:21,279
you just give it the input sentence or

00:09:18,700 --> 00:09:24,880
just a sequence of characters it will

00:09:21,279 --> 00:09:26,769
recognize what language it's in so it

00:09:24,880 --> 00:09:30,070
gives the probability with which it's

00:09:26,769 --> 00:09:31,930
predicting that language then it'll also

00:09:30,070 --> 00:09:35,170
give the proportion of the text that it

00:09:31,930 --> 00:09:37,630
thinks it's in that language so over

00:09:35,170 --> 00:09:39,519
here in the first example we see we give

00:09:37,630 --> 00:09:43,149
it a mixture of French which is the

00:09:39,519 --> 00:09:45,490
issue of the first three words and we

00:09:43,149 --> 00:09:49,000
give it a URL but it's unable to

00:09:45,490 --> 00:09:50,680
recognize that French part of the

00:09:49,000 --> 00:09:53,399
sentence and that is because it gets

00:09:50,680 --> 00:09:55,779
confused to the URL which is in English

00:09:53,399 --> 00:09:58,630
now CL if she also has this another

00:09:55,779 --> 00:10:01,300
function where you can get more than one

00:09:58,630 --> 00:10:04,240
language as prediction and that is just

00:10:01,300 --> 00:10:06,190
get frequent languages so I try to do

00:10:04,240 --> 00:10:07,959
this I try to give it the same input

00:10:06,190 --> 00:10:09,550
sequence and what I would have expected

00:10:07,959 --> 00:10:11,829
was that it would be able to recognize

00:10:09,550 --> 00:10:14,350
that some proportion of it is in French

00:10:11,829 --> 00:10:17,610
some proportion of it is in English but

00:10:14,350 --> 00:10:17,610
it was unable to do that

00:10:19,860 --> 00:10:25,650
okay let's look at some other examples

00:10:22,190 --> 00:10:30,690
now this input text right here in this

00:10:25,650 --> 00:10:32,760
example is of Russian transliterated now

00:10:30,690 --> 00:10:36,390
as you can see it's able to recognize it

00:10:32,760 --> 00:10:38,670
P really well um and it has a really

00:10:36,390 --> 00:10:41,490
high probability it says it's reliable

00:10:38,670 --> 00:10:43,440
and the proportion of text that is in

00:10:41,490 --> 00:10:45,240
Russian Latin is 1 which is completely

00:10:43,440 --> 00:10:47,970
correct and that's because these are the

00:10:45,240 --> 00:10:49,230
languages that are supported oftentimes

00:10:47,970 --> 00:10:51,360
you will see that you will need to

00:10:49,230 --> 00:10:52,800
experiment with it to figure out how

00:10:51,360 --> 00:10:56,280
accurate this is for all your own

00:10:52,800 --> 00:10:58,620
language now I give it a piece of

00:10:56,280 --> 00:11:00,150
Russian in its own it script and it's

00:10:58,620 --> 00:11:04,980
able to recognize that with a pretty

00:11:00,150 --> 00:11:07,770
high probability as well let's see how

00:11:04,980 --> 00:11:11,270
it works on transliterated data so this

00:11:07,770 --> 00:11:14,130
is a piece of transliterated Hindi and

00:11:11,270 --> 00:11:16,500
as you can see there are some proper

00:11:14,130 --> 00:11:19,920
nouns which is being depicted by the

00:11:16,500 --> 00:11:21,180
capitalization here and all I wanted to

00:11:19,920 --> 00:11:24,050
see was whether it was able to protect

00:11:21,180 --> 00:11:27,990
because it does seem to be trained on

00:11:24,050 --> 00:11:30,480
Hindi transliterated data but here it's

00:11:27,990 --> 00:11:33,120
predicting finish and that's because it

00:11:30,480 --> 00:11:38,820
might have some common vocabulary with

00:11:33,120 --> 00:11:42,210
the Finnish language I gave it another

00:11:38,820 --> 00:11:44,010
example over here which is just Hindi

00:11:42,210 --> 00:11:47,010
for how are you I'm good it's a pretty

00:11:44,010 --> 00:11:49,770
common phrase again this is

00:11:47,010 --> 00:11:51,840
transliterated as you can see but it

00:11:49,770 --> 00:11:55,550
does not predict Hindi transliteration

00:11:51,840 --> 00:11:55,550
over here it predicts that it's Gaelic

00:11:57,020 --> 00:12:00,900
let's see how it does on code-switch

00:11:59,370 --> 00:12:04,440
data right code-switch data if you

00:12:00,900 --> 00:12:08,880
remember is just mixing two languages

00:12:04,440 --> 00:12:11,640
together in the single sequence so this

00:12:08,880 --> 00:12:12,870
is Spanish and English so a school kids

00:12:11,640 --> 00:12:17,250
are calling it these days it's like

00:12:12,870 --> 00:12:19,110
Spanglish now but uh it when you feed it

00:12:17,250 --> 00:12:21,540
to CRE tree it is not predicted to be

00:12:19,110 --> 00:12:26,670
Spanish or English it predicts to be

00:12:21,540 --> 00:12:29,220
Maori and I gave it some other phrases

00:12:26,670 --> 00:12:31,940
also this is again Spanglish this is um

00:12:29,220 --> 00:12:34,230
Franglais which is French English

00:12:31,940 --> 00:12:36,540
it's not equal to predict it really well

00:12:34,230 --> 00:12:38,730
again right it predicts something like

00:12:36,540 --> 00:12:40,440
Catalan which is a Western Romance

00:12:38,730 --> 00:12:47,459
language which was derived from Latin

00:12:40,440 --> 00:12:49,410
and it says the proportion is 1 now in

00:12:47,459 --> 00:12:51,390
the last slice you saw that CL III has

00:12:49,410 --> 00:12:54,180
its own challenges right it's not able

00:12:51,390 --> 00:12:56,820
to predict all languages with the very

00:12:54,180 --> 00:12:59,760
high probability we move over to a

00:12:56,820 --> 00:13:02,040
different framework which is lank ID now

00:12:59,760 --> 00:13:04,380
lambda was the standalone M language

00:13:02,040 --> 00:13:08,880
identification tool it's pre trained

00:13:04,380 --> 00:13:11,070
over 97 languages and it can be deployed

00:13:08,880 --> 00:13:13,649
as a web service but basically I have

00:13:11,070 --> 00:13:16,500
it's at its pace it's just a knife based

00:13:13,649 --> 00:13:18,329
classifier with a multinomial event

00:13:16,500 --> 00:13:23,519
model and what it does is it just looks

00:13:18,329 --> 00:13:26,850
at a mixture of bite and crumbs let's

00:13:23,519 --> 00:13:29,310
look at it in practice so right now what

00:13:26,850 --> 00:13:30,899
I did was you have each load the model

00:13:29,310 --> 00:13:32,730
over here you normalize the

00:13:30,899 --> 00:13:34,920
probabilities which means that you have

00:13:32,730 --> 00:13:36,450
the school and it will just normalize

00:13:34,920 --> 00:13:40,230
the probabilities for all the different

00:13:36,450 --> 00:13:42,720
languages so I set the language to be a

00:13:40,230 --> 00:13:46,560
particular set over here this is one

00:13:42,720 --> 00:13:48,690
very useful advantage of using this

00:13:46,560 --> 00:13:53,370
module that you can actually set it to

00:13:48,690 --> 00:13:55,649
be a particular language set so if

00:13:53,370 --> 00:13:57,990
you're sure that your training set only

00:13:55,649 --> 00:14:00,779
has about four languages you can give

00:13:57,990 --> 00:14:05,010
that to with identifier here and it will

00:14:00,779 --> 00:14:07,620
predict one of these four languages so

00:14:05,010 --> 00:14:10,130
let's see now that we've set our

00:14:07,620 --> 00:14:15,240
languages about Russian English Italian

00:14:10,130 --> 00:14:17,190
Slovakian we see that this is the piece

00:14:15,240 --> 00:14:20,130
of transliterated Russian that we gave

00:14:17,190 --> 00:14:22,230
it earlier also in cat3 it predicts has

00:14:20,130 --> 00:14:28,199
to be Slovakian with a probability of

00:14:22,230 --> 00:14:30,959
0.67 another example is of this Hindi

00:14:28,199 --> 00:14:33,180
transliteration where I give it a set of

00:14:30,959 --> 00:14:35,130
Hindi and English but because it does

00:14:33,180 --> 00:14:37,680
not support a saturated text at all it

00:14:35,130 --> 00:14:41,329
it just predicts it as English because

00:14:37,680 --> 00:14:41,329
it sees English characters over here

00:14:43,900 --> 00:14:50,089
another identification framework we have

00:14:46,790 --> 00:14:51,650
is lambda tech however one thing that

00:14:50,089 --> 00:14:54,380
you should know about blanked it is that

00:14:51,650 --> 00:14:56,660
it is undetermined istic which means

00:14:54,380 --> 00:14:59,270
that if you try and run solid text which

00:14:56,660 --> 00:15:01,180
is either too short or too ambiguous you

00:14:59,270 --> 00:15:03,140
might get different results every time

00:15:01,180 --> 00:15:05,420
again it's based on an eye base

00:15:03,140 --> 00:15:08,089
classifier and works with character

00:15:05,420 --> 00:15:11,540
based and grams however it's supposed

00:15:08,089 --> 00:15:13,490
only about 49 languages and those are

00:15:11,540 --> 00:15:17,180
also with about ninety-nine point eight

00:15:13,490 --> 00:15:18,890
percent precision it does not support

00:15:17,180 --> 00:15:22,880
any of the transliterated languages

00:15:18,890 --> 00:15:26,060
though and how it works is that basic it

00:15:22,880 --> 00:15:30,410
consists of computing features based on

00:15:26,060 --> 00:15:32,900
the language so like if you look at the

00:15:30,410 --> 00:15:35,029
accented e you can only see it and

00:15:32,900 --> 00:15:37,940
Spanish Italian but not so much in

00:15:35,029 --> 00:15:40,370
English right and it will look at

00:15:37,940 --> 00:15:42,260
features like how often the word that

00:15:40,370 --> 00:15:44,690
are starting with Z are using German

00:15:42,260 --> 00:15:47,180
versus how often they used in English

00:15:44,690 --> 00:15:49,880
and then it will compute the probability

00:15:47,180 --> 00:15:57,230
of those features given the input

00:15:49,880 --> 00:16:01,070
sequence in Python you can just import

00:15:57,230 --> 00:16:03,800
it as lambda tech and this has it has a

00:16:01,070 --> 00:16:05,270
function which is the tech longs again

00:16:03,800 --> 00:16:07,610
you can just go through the notebooks at

00:16:05,270 --> 00:16:09,740
your own pace play with it give it more

00:16:07,610 --> 00:16:12,880
examples get a feel of how it's

00:16:09,740 --> 00:16:16,190
performing on your preferred language

00:16:12,880 --> 00:16:17,930
now over here as you can see again

00:16:16,190 --> 00:16:21,050
because it does not support trust

00:16:17,930 --> 00:16:26,930
iterated data it Pro it just predicts is

00:16:21,050 --> 00:16:29,270
a Slovakian if you run it again because

00:16:26,930 --> 00:16:31,010
it's non-deterministic it will give you

00:16:29,270 --> 00:16:33,170
four different languages with four

00:16:31,010 --> 00:16:35,240
different probabilities like over here

00:16:33,170 --> 00:16:39,880
is protecting Slovakian Albanian heard

00:16:35,240 --> 00:16:39,880
Hungarian but none of them is Russian

00:16:41,670 --> 00:16:46,959
so in the past few slides we saw how all

00:16:45,519 --> 00:16:50,290
of these frameworks have their own

00:16:46,959 --> 00:16:51,850
limitations right we gave them text with

00:16:50,290 --> 00:16:54,009
romanized scripts in a different

00:16:51,850 --> 00:16:56,199
language but they had difficulty

00:16:54,009 --> 00:16:58,569
recognizing them if you have a very

00:16:56,199 --> 00:17:01,240
small text length that means just giving

00:16:58,569 --> 00:17:04,089
very less information to the model or

00:17:01,240 --> 00:17:06,399
any of these models that these

00:17:04,089 --> 00:17:08,459
frameworks have been trained on there

00:17:06,399 --> 00:17:10,870
are often borrowed words from different

00:17:08,459 --> 00:17:13,480
languages that you can see in any

00:17:10,870 --> 00:17:15,669
languages vocabulary right and that is

00:17:13,480 --> 00:17:19,419
why certain frameworks get confused

00:17:15,669 --> 00:17:20,829
between predicting either of them there

00:17:19,419 --> 00:17:24,610
are very different transliteration

00:17:20,829 --> 00:17:26,470
schemes so like how I write in Hindi

00:17:24,610 --> 00:17:27,909
transliterated is very different from my

00:17:26,470 --> 00:17:30,029
friend who lives in a different part of

00:17:27,909 --> 00:17:34,539
India and who writes in a different

00:17:30,029 --> 00:17:37,740
English script there are overlapping

00:17:34,539 --> 00:17:39,970
vocabulary items are certain

00:17:37,740 --> 00:17:41,500
vocabularies of different languages they

00:17:39,970 --> 00:17:43,390
have the same words but with different

00:17:41,500 --> 00:17:46,059
meanings which often confuses these

00:17:43,390 --> 00:17:48,580
models as well and as you can see with

00:17:46,059 --> 00:17:50,409
limited data which means that with all

00:17:48,580 --> 00:17:52,630
of these codes switched languages are

00:17:50,409 --> 00:17:54,399
examples and with these transliterated

00:17:52,630 --> 00:17:57,820
examples there's very little data to

00:17:54,399 --> 00:18:00,130
actually train your own model right so

00:17:57,820 --> 00:18:02,470
if you want your model to be able to

00:18:00,130 --> 00:18:05,440
recognize this you have to have

00:18:02,470 --> 00:18:07,870
something giving you as a very high

00:18:05,440 --> 00:18:11,200
probability that it is in fact a piece

00:18:07,870 --> 00:18:14,169
of transliterated text or or if it's in

00:18:11,200 --> 00:18:15,850
fact a piece of code switch text but the

00:18:14,169 --> 00:18:17,260
reason that these frameworks are not

00:18:15,850 --> 00:18:19,570
giving it is because they've been

00:18:17,260 --> 00:18:25,720
trained on very small data for these

00:18:19,570 --> 00:18:29,380
certain special cases so how do we go

00:18:25,720 --> 00:18:31,510
about solving this one of the approaches

00:18:29,380 --> 00:18:33,850
is that you actually augment your data

00:18:31,510 --> 00:18:36,520
sets with the data set that you pull

00:18:33,850 --> 00:18:38,020
yourself so often you will see that

00:18:36,520 --> 00:18:39,669
there is not enough data that is

00:18:38,020 --> 00:18:42,520
available in your language for example

00:18:39,669 --> 00:18:44,980
with Hindi I saw that interocitor ate a

00:18:42,520 --> 00:18:49,240
text I did not have a particular

00:18:44,980 --> 00:18:51,690
parallel corpus to work with so if I

00:18:49,240 --> 00:18:54,309
wanted to detect something as it was

00:18:51,690 --> 00:18:56,679
transliterated or if it was English

00:18:54,309 --> 00:18:59,320
there wasn't any model that was trained

00:18:56,679 --> 00:19:00,820
on a very large piece of data to

00:18:59,320 --> 00:19:03,520
actually give me this with a very high

00:19:00,820 --> 00:19:05,020
probability often you will see this

00:19:03,520 --> 00:19:07,780
off-the-shelf models also which are

00:19:05,020 --> 00:19:09,730
trained on multiple languages right but

00:19:07,780 --> 00:19:10,540
if they are trained on multiple

00:19:09,730 --> 00:19:13,270
languages

00:19:10,540 --> 00:19:16,270
just like we will see with pert you see

00:19:13,270 --> 00:19:18,820
that they have vocabularies spanning a

00:19:16,270 --> 00:19:20,710
lot other language is that what you want

00:19:18,820 --> 00:19:22,840
to be working with right and that just

00:19:20,710 --> 00:19:27,549
brings a noise from other languages to

00:19:22,840 --> 00:19:29,200
your model so how do we do with this so

00:19:27,549 --> 00:19:31,929
the first thing is that you have to

00:19:29,200 --> 00:19:34,059
identify one data source or multiple

00:19:31,929 --> 00:19:36,040
data sources in the language in any

00:19:34,059 --> 00:19:38,549
language that can be translated to yours

00:19:36,040 --> 00:19:42,130
either by Truls or by machine

00:19:38,549 --> 00:19:44,620
translation and then you use this

00:19:42,130 --> 00:19:47,860
machine generated data to augment for

00:19:44,620 --> 00:19:50,679
example right now let's say I was

00:19:47,860 --> 00:19:53,380
working with Hindi and I wanted to get

00:19:50,679 --> 00:19:56,230
much more data and transliterated form

00:19:53,380 --> 00:19:58,090
right so I have this dump of Hindi

00:19:56,230 --> 00:20:00,549
Wikipedia articles which is available

00:19:58,090 --> 00:20:03,790
readily online and I built my own

00:20:00,549 --> 00:20:05,740
translated later and this transliterated

00:20:03,790 --> 00:20:08,470
is based on rules so I define certain

00:20:05,740 --> 00:20:11,380
rules I give it to my transliterated

00:20:08,470 --> 00:20:13,540
class it just basically converts all of

00:20:11,380 --> 00:20:16,390
this dump of Health a Wikipedia articles

00:20:13,540 --> 00:20:19,120
into a new data set and once I have this

00:20:16,390 --> 00:20:21,250
new data set I can basically augment it

00:20:19,120 --> 00:20:25,150
with very small data set that I already

00:20:21,250 --> 00:20:27,580
had so this data set right here how this

00:20:25,150 --> 00:20:30,190
data set is the addition that we are

00:20:27,580 --> 00:20:33,340
providing to our pace data set to

00:20:30,190 --> 00:20:34,720
actually help it give more confidence to

00:20:33,340 --> 00:20:40,870
recognize that it's actually

00:20:34,720 --> 00:20:44,320
transliterated or not okay so let's look

00:20:40,870 --> 00:20:46,179
at how we go about solving this small

00:20:44,320 --> 00:20:48,070
example now this is a very simple

00:20:46,179 --> 00:20:49,840
transliterate ER in which what I have

00:20:48,070 --> 00:20:51,669
done is I have just defined my mappings

00:20:49,840 --> 00:20:54,370
of my Hindi as where to my English

00:20:51,669 --> 00:20:56,919
alphabet and basically I just read in a

00:20:54,370 --> 00:20:59,200
piece of text which might be in Hindi so

00:20:56,919 --> 00:21:00,760
so if I have an article of Wikipedia

00:20:59,200 --> 00:21:03,820
article basically I just read all

00:21:00,760 --> 00:21:06,310
sentences I use these mappings to

00:21:03,820 --> 00:21:08,920
convert them into English alphabet

00:21:06,310 --> 00:21:11,140
I defined certain other very simple

00:21:08,920 --> 00:21:14,230
rules as to what character can come

00:21:11,140 --> 00:21:16,690
before the other and then I just convert

00:21:14,230 --> 00:21:19,570
it to the English alphabet so like right

00:21:16,690 --> 00:21:22,570
here I it's I just convert this one

00:21:19,570 --> 00:21:25,780
single sentence which is from Hindi

00:21:22,570 --> 00:21:27,280
Wikipedia page for Python and it just

00:21:25,780 --> 00:21:30,370
converts it to English alphabet

00:21:27,280 --> 00:21:32,170
if you familiar with Hindi alphabet you

00:21:30,370 --> 00:21:33,820
will see that this is not a very good

00:21:32,170 --> 00:21:35,680
transliteration and that's because we're

00:21:33,820 --> 00:21:38,440
working with a very simple example right

00:21:35,680 --> 00:21:40,060
here and I just wanted to show that you

00:21:38,440 --> 00:21:41,530
can actually just build more

00:21:40,060 --> 00:21:44,770
sophisticated more complex

00:21:41,530 --> 00:21:49,780
transliterated cases based on your own

00:21:44,770 --> 00:21:52,690
custom task now we can either build our

00:21:49,780 --> 00:21:54,910
own transliterated systems or we can

00:21:52,690 --> 00:21:56,230
actually look at certain other examples

00:21:54,910 --> 00:21:59,770
that might exist in the literature

00:21:56,230 --> 00:22:01,930
already so for example if we I was

00:21:59,770 --> 00:22:04,000
working with the Indic languages and I

00:22:01,930 --> 00:22:06,250
found this really great library which is

00:22:04,000 --> 00:22:07,960
the CS and a lie and what it does is it

00:22:06,250 --> 00:22:10,300
already has a pre trained noodle machine

00:22:07,960 --> 00:22:14,140
translation model that converts the room

00:22:10,300 --> 00:22:16,420
into Hindi and basically it would give

00:22:14,140 --> 00:22:19,660
you something like this so if you give

00:22:16,420 --> 00:22:23,770
it a piece of text it would convert it

00:22:19,660 --> 00:22:25,960
to the Hindi script and basically if the

00:22:23,770 --> 00:22:29,110
probability of that conversion is really

00:22:25,960 --> 00:22:31,660
high it would assign it a Hindi tag so

00:22:29,110 --> 00:22:33,820
what I get with this is I get language

00:22:31,660 --> 00:22:36,430
identification that is not only sentence

00:22:33,820 --> 00:22:38,740
wide but that is token white so so that

00:22:36,430 --> 00:22:41,140
really helps in examples which might

00:22:38,740 --> 00:22:44,410
have code-switch data now this is only

00:22:41,140 --> 00:22:46,150
for Indic languages but there are tons

00:22:44,410 --> 00:22:53,110
of other open-source libraries that are

00:22:46,150 --> 00:22:55,030
available for other languages as well ok

00:22:53,110 --> 00:22:57,610
now that we've looked at all of these

00:22:55,030 --> 00:22:59,830
language identification frameworks and

00:22:57,610 --> 00:23:01,870
the challenges associated with them how

00:22:59,830 --> 00:23:03,730
do we go about solving them let's move

00:23:01,870 --> 00:23:06,010
on to certain off-the-shelf models that

00:23:03,730 --> 00:23:09,220
are readily available right so we have

00:23:06,010 --> 00:23:11,050
this really state-of-the-art model

00:23:09,220 --> 00:23:13,060
called the transformer and the

00:23:11,050 --> 00:23:14,770
transformer was actually very famous not

00:23:13,060 --> 00:23:16,600
because of what it brought to the table

00:23:14,770 --> 00:23:18,940
which was state-of-the-art at that time

00:23:16,600 --> 00:23:20,920
but because it led to

00:23:18,940 --> 00:23:24,100
so much of research being happening in

00:23:20,920 --> 00:23:27,040
the neural language community which

00:23:24,100 --> 00:23:28,120
meant that there were so many models so

00:23:27,040 --> 00:23:29,170
many research papers being published

00:23:28,120 --> 00:23:31,540
after this

00:23:29,170 --> 00:23:33,280
now the transformer was introduced in

00:23:31,540 --> 00:23:35,860
attention is all you need

00:23:33,280 --> 00:23:39,160
this was the paper by wasps Ronnie and

00:23:35,860 --> 00:23:41,500
others and basically it has a stack of

00:23:39,160 --> 00:23:44,260
encoders so this right here is an

00:23:41,500 --> 00:23:46,060
encoder each and Kudo has two layers

00:23:44,260 --> 00:23:49,120
which is the multi head attention and

00:23:46,060 --> 00:23:50,410
abnormal feed-forward layer we'll talk

00:23:49,120 --> 00:23:53,530
about multi height attention in the

00:23:50,410 --> 00:23:56,020
coming slide and it had a stack of six

00:23:53,530 --> 00:23:58,600
encoders and similarly a stack of sixty

00:23:56,020 --> 00:24:00,910
coders and each decoder had about three

00:23:58,600 --> 00:24:02,470
layers so again one was multi-head

00:24:00,910 --> 00:24:04,840
attention um

00:24:02,470 --> 00:24:11,380
again a multi had attention and then a

00:24:04,840 --> 00:24:13,270
feed-forward new network layer okay so

00:24:11,380 --> 00:24:15,910
we've been talking about multi has

00:24:13,270 --> 00:24:17,440
attention right multi-headed attention

00:24:15,910 --> 00:24:19,660
was this concept introduced by this

00:24:17,440 --> 00:24:23,430
paper which is why it was becoming very

00:24:19,660 --> 00:24:25,420
famous so attention was actually not

00:24:23,430 --> 00:24:28,110
introduced in this paper and it was

00:24:25,420 --> 00:24:30,490
introduced way back in 2014 and

00:24:28,110 --> 00:24:34,150
attention is when you're actually trying

00:24:30,490 --> 00:24:37,150
to figure out which word in the given

00:24:34,150 --> 00:24:40,720
sequence places how much of attention on

00:24:37,150 --> 00:24:42,730
the other words in the sequence and this

00:24:40,720 --> 00:24:44,560
could basically just mean that how many

00:24:42,730 --> 00:24:47,110
widths or how much of weight are you

00:24:44,560 --> 00:24:49,660
giving on each of these words in the

00:24:47,110 --> 00:24:52,570
sequence now multi-headed attention men

00:24:49,660 --> 00:24:54,640
that you're not even looking at just one

00:24:52,570 --> 00:24:56,650
sort of weights but you're looking at

00:24:54,640 --> 00:24:58,690
two different sets of weights or three

00:24:56,650 --> 00:25:00,670
different sets of weights in the paper

00:24:58,690 --> 00:25:02,680
they're using eight different matrices

00:25:00,670 --> 00:25:05,500
which means that they're looking at a

00:25:02,680 --> 00:25:07,930
different attention heads so as your

00:25:05,500 --> 00:25:09,490
sentence gets more complicated it needs

00:25:07,930 --> 00:25:12,130
to figure out different relations

00:25:09,490 --> 00:25:14,650
between the given word and the other

00:25:12,130 --> 00:25:17,500
words of the sequence so like right now

00:25:14,650 --> 00:25:20,140
if I have given no other context of all

00:25:17,500 --> 00:25:23,350
of these words before this would it

00:25:20,140 --> 00:25:25,450
I might just want to figure out what it

00:25:23,350 --> 00:25:27,430
is referring to so let's say if I'm not

00:25:25,450 --> 00:25:30,130
given any of this and I just have the

00:25:27,430 --> 00:25:32,590
sentence which is it was too tired my

00:25:30,130 --> 00:25:34,900
question might be um who is it

00:25:32,590 --> 00:25:36,820
good as a transfer to write who isn't

00:25:34,900 --> 00:25:39,070
too tired is it the street is it the

00:25:36,820 --> 00:25:42,570
animal and basically to answer this

00:25:39,070 --> 00:25:45,039
question is where attention is required

00:25:42,570 --> 00:25:47,860
so this was just one question that I'm

00:25:45,039 --> 00:25:49,960
answering but what if the other question

00:25:47,860 --> 00:25:51,419
that I'm answering is that why didn't

00:25:49,960 --> 00:25:54,190
the animal cross the street

00:25:51,419 --> 00:25:56,470
then the answer becomes because it was

00:25:54,190 --> 00:25:59,020
too tired so then that places a

00:25:56,470 --> 00:26:02,020
different sort of weight on different

00:25:59,020 --> 00:26:05,110
words and basically this is the problem

00:26:02,020 --> 00:26:07,570
that this model is trying to solve it's

00:26:05,110 --> 00:26:09,340
basically trying to see how you can

00:26:07,570 --> 00:26:11,470
answer various questions that are coming

00:26:09,340 --> 00:26:14,679
how you can assign different weights to

00:26:11,470 --> 00:26:19,990
different clauses based on just a single

00:26:14,679 --> 00:26:22,720
given foot now what was but now but

00:26:19,990 --> 00:26:25,659
again state-of-the-art soda everything

00:26:22,720 --> 00:26:28,690
now that you will see in this NLP

00:26:25,659 --> 00:26:32,140
community is that abby's soda right but

00:26:28,690 --> 00:26:34,990
burned again was a transformer at its

00:26:32,140 --> 00:26:38,409
base and when it was built literally

00:26:34,990 --> 00:26:40,750
every other model on that was just based

00:26:38,409 --> 00:26:42,399
on put so like we have Roberto we have

00:26:40,750 --> 00:26:45,370
to stir but we have to abort we have

00:26:42,399 --> 00:26:47,080
sent aboard I mean most of the models

00:26:45,370 --> 00:26:49,390
that we see right now or most of the

00:26:47,080 --> 00:26:51,340
national language community that you see

00:26:49,390 --> 00:26:53,470
right now is working on both working on

00:26:51,340 --> 00:26:56,760
its representations trying to improve

00:26:53,470 --> 00:27:01,870
we're trying to make it faster and so on

00:26:56,760 --> 00:27:04,299
so what is it why is it special and Bert

00:27:01,870 --> 00:27:07,600
is special because of the way it uses

00:27:04,299 --> 00:27:09,970
pre-training and find your name now but

00:27:07,600 --> 00:27:12,820
at its pre training stage for it it was

00:27:09,970 --> 00:27:15,789
it had all of this corpus and basically

00:27:12,820 --> 00:27:19,330
it trained on this unlabeled data it

00:27:15,789 --> 00:27:21,070
made two tasks the first task was about

00:27:19,330 --> 00:27:23,740
the next sentence prediction so if you

00:27:21,070 --> 00:27:27,640
have a corpus it would create a task

00:27:23,740 --> 00:27:31,360
that would have if one sentence is a

00:27:27,640 --> 00:27:32,890
next sentence of the previous one a 50%

00:27:31,360 --> 00:27:35,710
of the time and then they would create

00:27:32,890 --> 00:27:37,179
just a random sentence after another

00:27:35,710 --> 00:27:40,570
sentence and then that would be labeled

00:27:37,179 --> 00:27:42,280
as false another task that they use was

00:27:40,570 --> 00:27:46,059
the masked language model which will be

00:27:42,280 --> 00:27:48,369
coming in the coming slides

00:27:46,059 --> 00:27:50,379
and at the fine-tuning stage what it did

00:27:48,369 --> 00:27:52,719
was once you have all of these weights

00:27:50,379 --> 00:27:53,409
that I've been trained on these two

00:27:52,719 --> 00:27:55,479
tasks

00:27:53,409 --> 00:27:57,729
you basically just find you in this

00:27:55,479 --> 00:28:00,549
noodle Network for your particular task

00:27:57,729 --> 00:28:02,739
which could be sequence classification

00:28:00,549 --> 00:28:05,049
which could be question answering which

00:28:02,739 --> 00:28:07,269
is an you see which is what you see in

00:28:05,049 --> 00:28:09,039
reading comprehensions you could see if

00:28:07,269 --> 00:28:15,219
one sentence is a paraphrase of the

00:28:09,039 --> 00:28:17,859
other and so on so but model actually

00:28:15,219 --> 00:28:20,429
had this one pre-processing technique

00:28:17,859 --> 00:28:23,169
which is the word piece processing and

00:28:20,429 --> 00:28:25,659
the reason it has been proven so useful

00:28:23,169 --> 00:28:27,669
for multilingual systems is that you can

00:28:25,659 --> 00:28:30,009
actually share vocabulary across various

00:28:27,669 --> 00:28:32,499
languages so like the word vocabulary

00:28:30,009 --> 00:28:35,109
for this multilingual model is about 120

00:28:32,499 --> 00:28:37,659
thousand and it tokenized us on the

00:28:35,109 --> 00:28:41,399
basis of how likely our character

00:28:37,659 --> 00:28:44,049
sequences to be seen together so in this

00:28:41,399 --> 00:28:45,669
what piece pre-processing what we do is

00:28:44,049 --> 00:28:48,849
we basically start from the character

00:28:45,669 --> 00:28:51,190
level and for all of our languages which

00:28:48,849 --> 00:28:53,889
is 104 languages that the bird has been

00:28:51,190 --> 00:28:55,719
trained on we look at which characters

00:28:53,889 --> 00:28:58,509
are much more likely to be seen together

00:28:55,719 --> 00:29:01,059
than others and this is how we form

00:28:58,509 --> 00:29:04,299
these sub words so suppose our something

00:29:01,059 --> 00:29:06,639
in between a character and a word so in

00:29:04,299 --> 00:29:09,009
this example I'm using the hog face

00:29:06,639 --> 00:29:11,549
transformers and tokenize and slavery if

00:29:09,009 --> 00:29:13,809
you've ever worked with NLP you must be

00:29:11,549 --> 00:29:15,190
aware of this but if you're hearing

00:29:13,809 --> 00:29:17,649
about this for the first time definitely

00:29:15,190 --> 00:29:19,919
go check this out this library actually

00:29:17,649 --> 00:29:23,229
makes it very easy for us to train and

00:29:19,919 --> 00:29:26,229
evaluate transformers and it's a really

00:29:23,229 --> 00:29:29,409
good library for beginners so I just

00:29:26,229 --> 00:29:32,950
load the board multilingual model and I

00:29:29,409 --> 00:29:34,119
know the equivalent tokenizer then in

00:29:32,950 --> 00:29:37,239
line 5

00:29:34,119 --> 00:29:40,019
I basically tokenize a Spanish query and

00:29:37,239 --> 00:29:42,639
if you look at the pieces that we return

00:29:40,019 --> 00:29:45,249
we're getting in return you will be

00:29:42,639 --> 00:29:48,249
seeing that you don't get the same words

00:29:45,249 --> 00:29:51,639
as are separated by whitespace right and

00:29:48,249 --> 00:29:54,399
that is because those are supports and

00:29:51,639 --> 00:29:57,639
those are the word pieces so if you see

00:29:54,399 --> 00:29:59,710
a hash hash in the beginning of the

00:29:57,639 --> 00:30:01,720
support that's because that means that

00:29:59,710 --> 00:30:06,849
it was supposed to be appended to the

00:30:01,720 --> 00:30:10,149
previous one so as you can see Ola has

00:30:06,849 --> 00:30:12,159
been divided into two sub words Kiara

00:30:10,149 --> 00:30:14,859
has been divided into two sub words and

00:30:12,159 --> 00:30:17,950
so on in the next example in line six I

00:30:14,859 --> 00:30:20,409
tokenized the Hindi query where you see

00:30:17,950 --> 00:30:24,309
that the first word has been tokenized

00:30:20,409 --> 00:30:27,009
into three parts and in the last example

00:30:24,309 --> 00:30:30,879
if you're an office fan here's eros

00:30:27,009 --> 00:30:33,249
beats Battlestar Galactica so if you

00:30:30,879 --> 00:30:36,339
look at beats it has been again divided

00:30:33,249 --> 00:30:39,039
into two supports which is B and D s and

00:30:36,339 --> 00:30:41,019
again the hash is in bit in the

00:30:39,039 --> 00:30:44,549
beginning they just mean that the word

00:30:41,019 --> 00:30:44,549
has to be appended to the previous one

00:30:44,669 --> 00:30:49,899
so let us look at some statistics of

00:30:47,349 --> 00:30:53,379
languages and how the PERT actually

00:30:49,899 --> 00:30:56,440
leverages so many languages in just a

00:30:53,379 --> 00:30:58,419
single vocabulary right so let's look at

00:30:56,440 --> 00:30:59,919
the right hand side graph first the

00:30:58,419 --> 00:31:03,489
right hand side graph actually gives you

00:30:59,919 --> 00:31:05,259
fertility and fertility is a term that

00:31:03,489 --> 00:31:07,749
has been borrowed from statistical

00:31:05,259 --> 00:31:10,210
machine translation which and what it

00:31:07,749 --> 00:31:13,269
means is that what is the average number

00:31:10,210 --> 00:31:15,729
of birth word pieces corresponding to a

00:31:13,269 --> 00:31:18,789
single real token so in the last example

00:31:15,729 --> 00:31:20,799
we saw that ona was actually divided up

00:31:18,789 --> 00:31:22,629
into two word pieces right so if you're

00:31:20,799 --> 00:31:26,229
looking at the fertility of that word it

00:31:22,629 --> 00:31:27,639
just means it's two but for a particular

00:31:26,229 --> 00:31:30,609
language what we do is we calculate the

00:31:27,639 --> 00:31:33,519
average number of word pieces that each

00:31:30,609 --> 00:31:36,489
word in that language is divided into so

00:31:33,519 --> 00:31:38,200
on the left hand side of this graph

00:31:36,489 --> 00:31:40,899
where you see fertility versus the

00:31:38,200 --> 00:31:43,029
language you see that there are certain

00:31:40,899 --> 00:31:44,769
languages like Portuguese Hebrew English

00:31:43,029 --> 00:31:46,899
which have a fertility of around one

00:31:44,769 --> 00:31:49,899
which means that they are retaining

00:31:46,899 --> 00:31:51,909
their own original vocabulary so that

00:31:49,899 --> 00:31:54,729
means that most of the words in English

00:31:51,909 --> 00:31:57,729
actually have or have been divided into

00:31:54,729 --> 00:32:00,219
just one word which means that yeah it's

00:31:57,729 --> 00:32:01,869
just the original one on the right-hand

00:32:00,219 --> 00:32:05,169
side of this graph you see that there

00:32:01,869 --> 00:32:07,329
are thumb in Telugu Armenian Greek these

00:32:05,169 --> 00:32:09,849
languages right and that just means that

00:32:07,329 --> 00:32:12,640
these languages are broken up into more

00:32:09,849 --> 00:32:14,470
than two word pieces so

00:32:12,640 --> 00:32:16,870
an average word if you take in these

00:32:14,470 --> 00:32:21,640
languages it is more likely to be broken

00:32:16,870 --> 00:32:24,160
up into more number of word pieces so in

00:32:21,640 --> 00:32:26,410
the left-hand side of the graph the left

00:32:24,160 --> 00:32:29,049
graph if you see you are plotting

00:32:26,410 --> 00:32:30,790
frequency with respect to length in

00:32:29,049 --> 00:32:34,840
characters so this means that how many

00:32:30,790 --> 00:32:37,330
word pieces we see of how much length so

00:32:34,840 --> 00:32:39,549
again it's a very common graph because

00:32:37,330 --> 00:32:43,420
as the number of characters increases

00:32:39,549 --> 00:32:45,880
you see that the frequency decreases and

00:32:43,420 --> 00:32:47,380
that's very common because you're likely

00:32:45,880 --> 00:32:49,240
to break it down into smaller and

00:32:47,380 --> 00:32:55,870
smaller word pieces which actually have

00:32:49,240 --> 00:32:57,669
a much more likelihood of being seen so

00:32:55,870 --> 00:32:59,679
over here we talk about the bird masked

00:32:57,669 --> 00:33:01,660
language model now the special thing

00:32:59,679 --> 00:33:03,490
about this is that it was bi-directional

00:33:01,660 --> 00:33:05,559
which means that if you're looking to

00:33:03,490 --> 00:33:07,390
predict a word you basically look at the

00:33:05,559 --> 00:33:11,590
context from left to right as well as

00:33:07,390 --> 00:33:14,169
from right to left so a in bird what the

00:33:11,590 --> 00:33:16,390
authors did was the mass 15% of all the

00:33:14,169 --> 00:33:19,630
word piece tokens at random and they

00:33:16,390 --> 00:33:22,090
replaced this every 15 for every word of

00:33:19,630 --> 00:33:24,400
the 15 percent with the 80 percent

00:33:22,090 --> 00:33:26,230
probability that it would be a mask with

00:33:24,400 --> 00:33:28,270
a 10 percent probability that it would

00:33:26,230 --> 00:33:29,770
be a random token and with the 10

00:33:28,270 --> 00:33:32,140
percent probability that it would just

00:33:29,770 --> 00:33:33,610
remain the same original token and the

00:33:32,140 --> 00:33:36,669
way they would evaluate this language

00:33:33,610 --> 00:33:40,530
model is by just predicting how accurate

00:33:36,669 --> 00:33:40,530
your masked words are

00:33:42,370 --> 00:33:48,740
so here we define a function just to

00:33:45,580 --> 00:33:51,860
predict a given board in a given piece

00:33:48,740 --> 00:33:55,640
of sequence so here again I'm using the

00:33:51,860 --> 00:33:57,560
transformers library and pew just

00:33:55,640 --> 00:33:59,960
lowered the model which is port for mast

00:33:57,560 --> 00:34:01,460
LM and you know what the multilingual

00:33:59,960 --> 00:34:04,880
one because we are going to be looking

00:34:01,460 --> 00:34:06,530
at certain multilingual examples and in

00:34:04,880 --> 00:34:09,590
this function what we're doing is we

00:34:06,530 --> 00:34:12,200
take a piece of text we tokenize it then

00:34:09,590 --> 00:34:14,360
this is the second argument which is the

00:34:12,200 --> 00:34:17,929
word that you want to predict and you

00:34:14,360 --> 00:34:21,110
basically just give it a mask over here

00:34:17,929 --> 00:34:23,690
and you feed it to the model it predicts

00:34:21,110 --> 00:34:26,150
you take the Arg max of probability and

00:34:23,690 --> 00:34:28,250
then you see which one is the most

00:34:26,150 --> 00:34:30,940
likely word that is being predicted by

00:34:28,250 --> 00:34:34,850
the model you also look at certain other

00:34:30,940 --> 00:34:39,620
predictions just to see if your desired

00:34:34,850 --> 00:34:41,630
prediction is in the top K all right now

00:34:39,620 --> 00:34:43,429
that we've actually defined our function

00:34:41,630 --> 00:34:44,630
to predict the masked word let's

00:34:43,429 --> 00:34:49,130
actually do that for a couple of

00:34:44,630 --> 00:34:51,050
examples here the first example I give

00:34:49,130 --> 00:34:53,419
it a code switched piece of text where

00:34:51,050 --> 00:34:56,210
the first few words are in English the

00:34:53,419 --> 00:35:00,410
last few words are in Spanish which just

00:34:56,210 --> 00:35:02,120
means live and that live so basically

00:35:00,410 --> 00:35:07,370
what I want to do is I want to protect

00:35:02,120 --> 00:35:10,570
this masked word t-shirt now the model

00:35:07,370 --> 00:35:14,240
is actually able to predict a lot of the

00:35:10,570 --> 00:35:17,060
words that makes sense so if you look at

00:35:14,240 --> 00:35:20,270
a couple of them so low means just which

00:35:17,060 --> 00:35:23,690
means live and just live live and live

00:35:20,270 --> 00:35:25,700
well tambien also live and also live so

00:35:23,690 --> 00:35:28,940
all of them make sense and it's able to

00:35:25,700 --> 00:35:31,270
recognize the context of what we're

00:35:28,940 --> 00:35:36,620
talking about even though there's mixed

00:35:31,270 --> 00:35:39,080
language in this other example I give it

00:35:36,620 --> 00:35:42,560
the same piece of text but I want to

00:35:39,080 --> 00:35:44,750
protect viv you know now the good thing

00:35:42,560 --> 00:35:47,360
to notice over here is that if you look

00:35:44,750 --> 00:35:49,100
in the list of predicted tokens you will

00:35:47,360 --> 00:35:52,480
be able to see that you have Viva Viva

00:35:49,100 --> 00:35:55,089
which means live

00:35:52,480 --> 00:35:57,250
and again it's able to recognize context

00:35:55,089 --> 00:36:00,990
I think that's mainly because of another

00:35:57,250 --> 00:36:00,990
VV in the sentence

00:36:03,000 --> 00:36:07,030
now I also try to do this for in the

00:36:05,680 --> 00:36:11,079
example because I'm much more familiar

00:36:07,030 --> 00:36:13,210
with Hindi and basically what I saw was

00:36:11,079 --> 00:36:16,869
that when you give it a piece of text

00:36:13,210 --> 00:36:19,390
which is very small it's able to predict

00:36:16,869 --> 00:36:22,210
this word which is the actual word and

00:36:19,390 --> 00:36:24,520
it's top one accuracy is very high but

00:36:22,210 --> 00:36:26,589
all of these are the sentence

00:36:24,520 --> 00:36:31,990
predictions did not make sense at all

00:36:26,589 --> 00:36:33,849
given the input sequence so now let's

00:36:31,990 --> 00:36:36,910
look at another code switched example

00:36:33,849 --> 00:36:38,890
and this is a slightly longer example in

00:36:36,910 --> 00:36:42,430
which we have Hindi script as well as

00:36:38,890 --> 00:36:45,070
English interspersed in the middle so

00:36:42,430 --> 00:36:48,099
the first few words and the boxed words

00:36:45,070 --> 00:36:50,500
you can see are in Hindi script the

00:36:48,099 --> 00:36:52,660
remaining words are in English and you

00:36:50,500 --> 00:36:55,060
see these phrases that occur together a

00:36:52,660 --> 00:36:57,930
lot right like Hindi blogs Hindi

00:36:55,060 --> 00:37:00,760
bloggers popular Hindi blogs and so on

00:36:57,930 --> 00:37:02,589
so here's what I did I give it this

00:37:00,760 --> 00:37:05,560
piece of text and asked it to predict

00:37:02,589 --> 00:37:07,089
the word blog now in the predicted list

00:37:05,560 --> 00:37:09,040
of tokens you can see that it's actually

00:37:07,089 --> 00:37:12,250
recognizing this word as the first

00:37:09,040 --> 00:37:14,020
candidate itself and that is good in the

00:37:12,250 --> 00:37:16,750
other predictions you can see that it's

00:37:14,020 --> 00:37:19,119
giving you the capitalized log publish

00:37:16,750 --> 00:37:22,810
or forum which means that it's actually

00:37:19,119 --> 00:37:25,810
able to recognize the context of the

00:37:22,810 --> 00:37:29,410
given board and that's because it's

00:37:25,810 --> 00:37:31,569
appearing in multiple phrases right so

00:37:29,410 --> 00:37:33,970
you see in different phrases it's

00:37:31,569 --> 00:37:36,730
occurring as best hindi blogs popular

00:37:33,970 --> 00:37:38,950
hindi bloggers popular hindi blogs again

00:37:36,730 --> 00:37:41,710
so it the reason that it's able to

00:37:38,950 --> 00:37:43,930
recognize publish or blog or forum is

00:37:41,710 --> 00:37:44,890
because it's reading all of them time

00:37:43,930 --> 00:37:47,200
and again and because it's

00:37:44,890 --> 00:37:49,990
bi-directional so you will often see

00:37:47,200 --> 00:37:53,410
this so if you give Boyd a very long

00:37:49,990 --> 00:37:55,480
piece of text which has too much of

00:37:53,410 --> 00:37:58,740
contextual information it will be able

00:37:55,480 --> 00:38:01,329
to recognize the board pretty nicely

00:37:58,740 --> 00:38:04,890
irrespective of whether you have inter

00:38:01,329 --> 00:38:04,890
switched language in the middle

00:38:05,610 --> 00:38:10,680
another place where you see a lot of

00:38:07,320 --> 00:38:12,600
transliterated text is the lyrics so I'm

00:38:10,680 --> 00:38:14,070
a huge Polly would fan at any time I

00:38:12,600 --> 00:38:15,960
don't know the lyrics of a Bollywood

00:38:14,070 --> 00:38:18,600
song I'll just go to google and search

00:38:15,960 --> 00:38:20,700
it out the results will usually be in

00:38:18,600 --> 00:38:23,910
the English alphabet though which is why

00:38:20,700 --> 00:38:26,340
we get a lot of transliteration so now I

00:38:23,910 --> 00:38:29,610
give birth this huge piece of text which

00:38:26,340 --> 00:38:31,560
is lyrics of a song a popular song in

00:38:29,610 --> 00:38:34,590
Bollywood and I asked it to predict this

00:38:31,560 --> 00:38:38,640
word which is Mei Yin now if you notice

00:38:34,590 --> 00:38:40,860
the next word to Mei in is hei and it

00:38:38,640 --> 00:38:44,490
appears in another context again the

00:38:40,860 --> 00:38:47,130
next word is hei and again the next word

00:38:44,490 --> 00:38:49,110
is hei now if you look at the list of

00:38:47,130 --> 00:38:51,870
predicted tokens you will see that it is

00:38:49,110 --> 00:38:55,770
able to recognize that the targeted word

00:38:51,870 --> 00:38:58,290
was Mei N and if you look at some of the

00:38:55,770 --> 00:39:02,460
tokens over there most of them are just

00:38:58,290 --> 00:39:04,950
up endings and if you look at one token

00:39:02,460 --> 00:39:06,570
which is hei now that appears a lot in

00:39:04,950 --> 00:39:10,230
the text right in fact that is the next

00:39:06,570 --> 00:39:12,630
word to our masked word and the reason

00:39:10,230 --> 00:39:15,060
it's able to or it's giving us this

00:39:12,630 --> 00:39:17,400
prediction is because it's seeing that

00:39:15,060 --> 00:39:20,880
this word occurs a lot in the same

00:39:17,400 --> 00:39:23,550
context so if you give put a lot of

00:39:20,880 --> 00:39:25,620
information it will look at the right

00:39:23,550 --> 00:39:27,300
context at look at the left context and

00:39:25,620 --> 00:39:30,200
it will be able to recognize the masked

00:39:27,300 --> 00:39:33,410
word given that the same word appears

00:39:30,200 --> 00:39:33,410
multiple times

00:39:36,860 --> 00:39:41,340
okay so now that we've looked at how the

00:39:39,240 --> 00:39:43,470
mass language model performs let's look

00:39:41,340 --> 00:39:45,690
at how we can evaluate certain tasks

00:39:43,470 --> 00:39:47,760
that we perform with Bert right so let's

00:39:45,690 --> 00:39:50,280
say you have this multilingual psi and

00:39:47,760 --> 00:39:52,500
you are trying to give POS tax to every

00:39:50,280 --> 00:39:54,180
word piece the first thing that you want

00:39:52,500 --> 00:39:56,310
to do is you want to organize it because

00:39:54,180 --> 00:39:58,950
that is how board works you have to

00:39:56,310 --> 00:40:01,470
tokenize it into word pieces and the way

00:39:58,950 --> 00:40:03,570
you can assign them tags is by giving

00:40:01,470 --> 00:40:06,810
the first word piece of The Associated

00:40:03,570 --> 00:40:09,600
word a tag so which means that if you

00:40:06,810 --> 00:40:11,760
are looking at this sentence and Jim is

00:40:09,600 --> 00:40:14,220
one-world Henson is another world Henson

00:40:11,760 --> 00:40:16,410
is divided into hen and son world pieces

00:40:14,220 --> 00:40:18,510
she would basically give a tag to the

00:40:16,410 --> 00:40:21,660
first word piece hen and you would leave

00:40:18,510 --> 00:40:24,960
up the last word piece similarly over

00:40:21,660 --> 00:40:28,740
here if you are giving it a word piece

00:40:24,960 --> 00:40:31,050
of puppet and an ear you would leave out

00:40:28,740 --> 00:40:34,260
the last word piece and then just assign

00:40:31,050 --> 00:40:36,230
attack to the first one now there are

00:40:34,260 --> 00:40:39,480
various ways to do this you can either

00:40:36,230 --> 00:40:41,670
use the boat representations as input to

00:40:39,480 --> 00:40:48,650
another new network or you can find you

00:40:41,670 --> 00:40:50,730
input completely for generation our

00:40:48,650 --> 00:40:53,430
evaluation metrics actually look pretty

00:40:50,730 --> 00:40:56,160
similar to what they were to a normal

00:40:53,430 --> 00:40:57,630
noodle machine translation model you

00:40:56,160 --> 00:40:59,610
know if you're looking at the mast

00:40:57,630 --> 00:41:02,400
language model you would want to see

00:40:59,610 --> 00:41:04,530
with how much prediction or how much

00:41:02,400 --> 00:41:06,240
accuracy the bird model is actually

00:41:04,530 --> 00:41:08,310
predicting so you could look at the top

00:41:06,240 --> 00:41:12,150
ten accuracy or top three accuracy top

00:41:08,310 --> 00:41:13,470
five accuracy according to you now a lot

00:41:12,150 --> 00:41:15,570
of the metrics in your machine

00:41:13,470 --> 00:41:16,980
translation like beam search in blue are

00:41:15,570 --> 00:41:18,990
pretty useful for multilingual

00:41:16,980 --> 00:41:20,730
generation and that is because the

00:41:18,990 --> 00:41:24,150
multilingual generation and bird is

00:41:20,730 --> 00:41:25,590
based on board pieces right so in word

00:41:24,150 --> 00:41:27,960
pieces what we have is a common

00:41:25,590 --> 00:41:29,790
vocabulary across languages which means

00:41:27,960 --> 00:41:32,340
that you actually don't have to switch

00:41:29,790 --> 00:41:34,740
every time if you have a multilingual

00:41:32,340 --> 00:41:38,400
piece of data and figure out a language

00:41:34,740 --> 00:41:41,490
model for different languages you

00:41:38,400 --> 00:41:43,260
basically have this word pieces and you

00:41:41,490 --> 00:41:45,480
will just see which word piece is

00:41:43,260 --> 00:41:47,940
predicted after the other so in beam

00:41:45,480 --> 00:41:49,530
search what we do is we look at each

00:41:47,940 --> 00:41:52,230
time step and the

00:41:49,530 --> 00:41:54,630
few best candidates at that point we

00:41:52,230 --> 00:41:56,760
evaluate all paths that are arising from

00:41:54,630 --> 00:41:58,560
them so let's say at time step one we

00:41:56,760 --> 00:42:00,720
figured out that these are the 30 best

00:41:58,560 --> 00:42:03,360
candidates we would evaluate 30 best

00:42:00,720 --> 00:42:05,880
candidates at each again time step for

00:42:03,360 --> 00:42:07,710
all of them and then at the end we

00:42:05,880 --> 00:42:10,880
calculate the best possible candidate

00:42:07,710 --> 00:42:12,810
for our translation you can do this for

00:42:10,880 --> 00:42:16,620
transliteration you could do this for

00:42:12,810 --> 00:42:18,600
coats which piece of data anything now

00:42:16,620 --> 00:42:20,820
another way to actually evaluate how

00:42:18,600 --> 00:42:22,560
good your generation is is through the

00:42:20,820 --> 00:42:24,390
blue score and blue score is pretty

00:42:22,560 --> 00:42:26,070
widely used if you've ever worked with

00:42:24,390 --> 00:42:28,590
your machine translation you know about

00:42:26,070 --> 00:42:32,010
this but the main idea behind blue score

00:42:28,590 --> 00:42:34,770
is that you look at engrams so up to one

00:42:32,010 --> 00:42:37,650
gram to gram 3 gram for grams in the

00:42:34,770 --> 00:42:39,780
candidate sequence that you have and you

00:42:37,650 --> 00:42:42,890
compare it to the reference sequence and

00:42:39,780 --> 00:42:46,980
you figure out how similar they are

00:42:42,890 --> 00:42:49,860
and now just summarize what we've done

00:42:46,980 --> 00:42:52,410
till now if you want to make your model

00:42:49,860 --> 00:42:53,940
your NLP model more multilingual here's

00:42:52,410 --> 00:42:56,010
what you need to decide you need to

00:42:53,940 --> 00:42:57,990
decide if it's even required if what

00:42:56,010 --> 00:43:00,510
you're catering to actually needs a lot

00:42:57,990 --> 00:43:03,930
of languages which languages those are

00:43:00,510 --> 00:43:06,300
do you have enough data for them if not

00:43:03,930 --> 00:43:08,940
you need to add theta and this you can

00:43:06,300 --> 00:43:11,130
do by just converting with a rule-based

00:43:08,940 --> 00:43:13,260
rands translator rate or like I

00:43:11,130 --> 00:43:15,440
mentioned or if you have any neural

00:43:13,260 --> 00:43:17,910
machine models that are already trained

00:43:15,440 --> 00:43:21,540
you choose the multilingual pre trained

00:43:17,910 --> 00:43:23,550
model that you want to utilize and then

00:43:21,540 --> 00:43:26,220
you find eunuch ording to task let's say

00:43:23,550 --> 00:43:30,770
you want to do a classification task you

00:43:26,220 --> 00:43:33,270
do a soft max layer on top of poor and

00:43:30,770 --> 00:43:35,400
if you want regeneration tasks you

00:43:33,270 --> 00:43:38,760
customize accordingly and voila you have

00:43:35,400 --> 00:43:41,520
your multilingual model and with that we

00:43:38,760 --> 00:43:43,620
reach the end of the presentation so in

00:43:41,520 --> 00:43:45,390
this stop we've seen transliterated and

00:43:43,620 --> 00:43:46,890
code switch data and how they are

00:43:45,390 --> 00:43:50,310
extremely different grammars to

00:43:46,890 --> 00:43:51,870
monolingual corpuses or more normal

00:43:50,310 --> 00:43:54,720
languages that we've seen because they

00:43:51,870 --> 00:43:56,400
mix a variety of them we have seen some

00:43:54,720 --> 00:43:58,470
challenges that are associated with

00:43:56,400 --> 00:44:01,740
language identification with these kind

00:43:58,470 --> 00:44:03,360
of cases we have seen how we can

00:44:01,740 --> 00:44:06,690
actually augment data

00:44:03,360 --> 00:44:09,690
by building on our own and we can do

00:44:06,690 --> 00:44:12,240
that by either using a rule-based system

00:44:09,690 --> 00:44:16,230
or by using machine translation from a

00:44:12,240 --> 00:44:19,590
specific data source we have seen how

00:44:16,230 --> 00:44:21,930
multilingual board performs how it does

00:44:19,590 --> 00:44:24,240
on transliterated date on code switch

00:44:21,930 --> 00:44:28,830
data given enough length and given

00:44:24,240 --> 00:44:30,840
enough contexts and in the last we've

00:44:28,830 --> 00:44:33,710
seen that we can make a little people

00:44:30,840 --> 00:44:38,310
presentation without having a word cloud

00:44:33,710 --> 00:44:40,410
alright and with that we reached the end

00:44:38,310 --> 00:44:42,120
of this presentation if you have any

00:44:40,410 --> 00:44:45,030
questions feel free to leave them in the

00:44:42,120 --> 00:44:47,160
comment section below or you can find me

00:44:45,030 --> 00:44:49,590
on LinkedIn use it this QR code I'm also

00:44:47,160 --> 00:44:51,390
available on github or feel free to go

00:44:49,590 --> 00:44:53,880
through the notebooks and ask any

00:44:51,390 --> 00:44:56,070
questions that you have and I just like

00:44:53,880 --> 00:45:00,080
to thank PyCon and the Python Software

00:44:56,070 --> 00:45:00,080
Foundation for organizing this thank you

00:45:06,609 --> 00:45:08,670

YouTube URL: https://www.youtube.com/watch?v=hYZQaTeowHQ


