Title: Talk: Igor T. Ghisi - Write Less and Test More with Data Regression Testing
Publication date: 2021-05-05
Playlist: PyCon US 2020
Description: 
	Presented by:
Igor T. Ghisi

As data structures of a project increases in size and complexity, it becomes harder and harder to preserve test completeness. Testing objects with dozens of attributes and arrays with hundreds of values could turn into a laborious task. Often, programmers let these kind of data partially tested, especially if the required code coverage was already achieved.

In this talk we’ll show how to increase test completeness for data structures by applying data regression testing. We’ll be presenting pytest-regressions, a pytest plugin that helps to test datasets and objects by automatically serializing expected data on disk and later checking test results against it. We’ll also show how pytest-regressions make it easier to inspect test data and debug failing tests. The talk will demonstrate examples of data regression being applied to numerical algorithms, web APIs, Flask views and SQLAlchemy models.




Talk slides and resources: https://github.com/igortg/pycon2020-pytest-regressions
Captions: 
	00:00:14,150 --> 00:00:21,590
hello everyone my name is Egor gizzy

00:00:17,869 --> 00:00:23,990
this is PyCon 2020 and I will be giving

00:00:21,590 --> 00:00:27,130
the talk right less and test more with

00:00:23,990 --> 00:00:27,130
data regression testing

00:00:28,560 --> 00:00:31,350
but first a quick introduction about

00:00:30,450 --> 00:00:34,200
myself

00:00:31,350 --> 00:00:37,680
I live in florianópolis a small island

00:00:34,200 --> 00:00:39,480
in south of Brazil I hold a master's in

00:00:37,680 --> 00:00:42,570
computational mechanics from the

00:00:39,480 --> 00:00:47,540
University Federal University of Hilda

00:00:42,570 --> 00:00:51,360
Janeiro I started with Python around

00:00:47,540 --> 00:00:54,660
2004 and since that since then it's my

00:00:51,360 --> 00:01:00,590
language of preference I'm a technical

00:00:54,660 --> 00:01:03,270
leader at a trip OS @e type OS we build

00:01:00,590 --> 00:01:06,390
scientific soft software for scientific

00:01:03,270 --> 00:01:09,900
simulation most of the project involves

00:01:06,390 --> 00:01:11,810
some kind of fluid dynamics but we also

00:01:09,900 --> 00:01:14,369
have solutions in micro porosity

00:01:11,810 --> 00:01:16,979
characterization particles interaction

00:01:14,369 --> 00:01:20,340
and other disciplines that involve

00:01:16,979 --> 00:01:23,160
numerical simulation typically we build

00:01:20,340 --> 00:01:27,899
the numerical solvers using a mix of C++

00:01:23,160 --> 00:01:30,990
and Python and since 2003 we use Python

00:01:27,899 --> 00:01:33,600
to build application interface at the

00:01:30,990 --> 00:01:36,030
time very few people was using Python to

00:01:33,600 --> 00:01:38,790
create heavyweight desktop applications

00:01:36,030 --> 00:01:43,229
so I think I can say that we were very

00:01:38,790 --> 00:01:46,320
early adopters in that sense in 2018 we

00:01:43,229 --> 00:01:49,710
migrated our code base from Python 2 to

00:01:46,320 --> 00:01:52,080
3 and thanks to an extensive test

00:01:49,710 --> 00:01:55,920
coverage no bug related to the migration

00:01:52,080 --> 00:01:58,740
wench production it took us about 10

00:01:55,920 --> 00:02:01,799
months to finish the 2 to 3 migration

00:01:58,740 --> 00:02:04,200
and at the end we were so happy and so

00:02:01,799 --> 00:02:06,860
relieved that we made this piece of sure

00:02:04,200 --> 00:02:06,860
to celebrate

00:02:07,689 --> 00:02:12,069
for talking about concepts I want to

00:02:10,360 --> 00:02:14,910
give a quick list of the two will be

00:02:12,069 --> 00:02:14,910
showing here today

00:02:15,640 --> 00:02:21,310
let's say I have a class that stores car

00:02:18,370 --> 00:02:23,650
specifications here I made it a data

00:02:21,310 --> 00:02:26,740
class but it could be a standard by the

00:02:23,650 --> 00:02:29,320
class and I have a method create car

00:02:26,740 --> 00:02:33,840
from name that receives a car name and

00:02:29,320 --> 00:02:33,840
it returns an object of cars back

00:02:34,250 --> 00:02:38,690
a standard unit test for this method

00:02:36,200 --> 00:02:41,630
would be like this I call the method and

00:02:38,690 --> 00:02:45,500
check that each object attribute has the

00:02:41,630 --> 00:02:48,020
expected value well there's no problem

00:02:45,500 --> 00:02:52,100
with that but there is room for

00:02:48,020 --> 00:02:52,820
improvement first it's a very manual

00:02:52,100 --> 00:02:56,660
process

00:02:52,820 --> 00:02:58,970
I'm checking attributes one by one here

00:02:56,660 --> 00:03:00,860
a more sharp I would notice that I

00:02:58,970 --> 00:03:03,650
forgot to test the displacement

00:03:00,860 --> 00:03:08,630
attribute and this happens all the time

00:03:03,650 --> 00:03:10,520
in real situations also if I have an

00:03:08,630 --> 00:03:14,180
object with thousands and thousands of

00:03:10,520 --> 00:03:16,070
attributes or many nested objects the

00:03:14,180 --> 00:03:18,620
dets the test keeps getting bigger and

00:03:16,070 --> 00:03:22,940
harder to maintain so the solution

00:03:18,620 --> 00:03:27,110
scales very poorly so what I'll show you

00:03:22,940 --> 00:03:29,660
is how to replace all these asserts

00:03:27,110 --> 00:03:31,520
with this single line and did to make

00:03:29,660 --> 00:03:34,130
the test more complete more maintainable

00:03:31,520 --> 00:03:36,340
and easier to the big debug in case of

00:03:34,130 --> 00:03:36,340
failure

00:03:38,840 --> 00:03:44,030
before we dive into more examples I

00:03:41,230 --> 00:03:46,780
would like to properly define data

00:03:44,030 --> 00:03:46,780
regression test

00:03:46,950 --> 00:03:53,220
at first I thought in using just

00:03:49,600 --> 00:03:53,220
regression testing for this talk

00:03:53,420 --> 00:03:57,200
most definitions of aggression testing

00:03:55,520 --> 00:03:59,930
that I found were similar to this one

00:03:57,200 --> 00:04:01,610
that regression testing is done to

00:03:59,930 --> 00:04:05,300
ensure that a change in the code has not

00:04:01,610 --> 00:04:08,180
introduced any new defects well but this

00:04:05,300 --> 00:04:11,030
definition applies to 99% of my tests it

00:04:08,180 --> 00:04:14,270
almost all my tests are for preventing

00:04:11,030 --> 00:04:16,190
some kind of defect I'm him I'm Hef's

00:04:14,270 --> 00:04:18,859
I may have some other types of tests

00:04:16,190 --> 00:04:20,600
like to prevent that performance of the

00:04:18,859 --> 00:04:23,210
software to not do great deeds to a

00:04:20,600 --> 00:04:25,300
certain level or maybe doing some kind

00:04:23,210 --> 00:04:29,419
of exploratory testing with a tool like

00:04:25,300 --> 00:04:31,640
hypothesis I may be doing TDD so I'm not

00:04:29,419 --> 00:04:34,639
only preventing things to break but also

00:04:31,640 --> 00:04:36,590
driven the development of my code

00:04:34,639 --> 00:04:38,689
but at the end of the day the main

00:04:36,590 --> 00:04:42,710
objective of my test suite is to prevent

00:04:38,689 --> 00:04:45,110
software regression so in the search of

00:04:42,710 --> 00:04:47,840
a more specific definition for what I

00:04:45,110 --> 00:04:51,830
will be showing a ended up ended up with

00:04:47,840 --> 00:04:55,759
the term data regression test

00:04:51,830 --> 00:04:57,650
I couldn't find a definition for data

00:04:55,759 --> 00:05:00,050
regression testing in any of the

00:04:57,650 --> 00:05:03,470
classical literature of software quality

00:05:00,050 --> 00:05:06,860
and software testing books so I came up

00:05:03,470 --> 00:05:08,810
with this definition the aggression

00:05:06,860 --> 00:05:10,879
testing is used to prevent software

00:05:08,810 --> 00:05:13,759
aggression by comparing the output data

00:05:10,879 --> 00:05:15,979
of the code that I changed with the data

00:05:13,759 --> 00:05:18,220
generated by a previous version of this

00:05:15,979 --> 00:05:18,220
code

00:05:18,380 --> 00:05:24,830
as I said I found nothing on software

00:05:21,890 --> 00:05:26,810
testing books if anyone knows of some

00:05:24,830 --> 00:05:29,150
book that mentions that please send me a

00:05:26,810 --> 00:05:31,970
tweet but I found some clues that

00:05:29,150 --> 00:05:35,360
indicate the idea is already being used

00:05:31,970 --> 00:05:37,610
by many teams I found more than one blog

00:05:35,360 --> 00:05:40,490
post describing database regression

00:05:37,610 --> 00:05:42,350
testing where they compare databases

00:05:40,490 --> 00:05:45,050
populated by different branches of the

00:05:42,350 --> 00:05:49,670
code to detect regressions in the

00:05:45,050 --> 00:05:52,400
software and the well-known plot library

00:05:49,670 --> 00:05:55,370
matplotlib defines something called

00:05:52,400 --> 00:05:57,410
image comparison testing where they have

00:05:55,370 --> 00:05:59,690
tests that generate images from the

00:05:57,410 --> 00:06:02,210
Coolidge version of the code and compare

00:05:59,690 --> 00:06:04,520
them to a reference set of images if n

00:06:02,210 --> 00:06:08,210
difference is spotted between images the

00:06:04,520 --> 00:06:11,500
test suite fails so I'm not introducing

00:06:08,210 --> 00:06:11,500
anything new here

00:06:13,530 --> 00:06:18,900
each repo s the first helping to we

00:06:15,900 --> 00:06:21,930
created for data regression tested must

00:06:18,900 --> 00:06:26,120
aim to improve tests for 3d Henry

00:06:21,930 --> 00:06:29,310
algorithms similar to Madrid lib the to

00:06:26,120 --> 00:06:31,080
produce an image and compare it against

00:06:29,310 --> 00:06:34,110
the herons image save it in the hippo

00:06:31,080 --> 00:06:37,670
story at the time we were still using

00:06:34,110 --> 00:06:42,060
the Python standard unit test framework

00:06:37,670 --> 00:06:46,470
around 2013 we migrated to PI tests and

00:06:42,060 --> 00:06:48,680
this to evolve it to a by test plugin we

00:06:46,470 --> 00:06:51,600
added some more comparison functions and

00:06:48,680 --> 00:06:54,419
eventually we open sourced it in a

00:06:51,600 --> 00:06:57,200
separate in a separate library called by

00:06:54,419 --> 00:06:57,200
test figurations

00:06:57,520 --> 00:07:02,500
so I will be showing how we create data

00:06:59,949 --> 00:07:05,830
regression unit tests using PI test and

00:07:02,500 --> 00:07:08,020
pythons aggressions if you are using

00:07:05,830 --> 00:07:10,030
other test framework you see that the

00:07:08,020 --> 00:07:12,430
concepts are not that complicated and

00:07:10,030 --> 00:07:14,139
you may create your own tool for daily

00:07:12,430 --> 00:07:18,069
regression we use some of the ideas that

00:07:14,139 --> 00:07:20,169
I will be presenting here it would be

00:07:18,069 --> 00:07:22,660
good but not required if you know the

00:07:20,169 --> 00:07:24,970
basics of PI tests and how to use by

00:07:22,660 --> 00:07:28,319
test features to better understand the

00:07:24,970 --> 00:07:28,319
examples I will show next

00:07:28,349 --> 00:07:34,090
so PI test aggression is available on pi

00:07:31,389 --> 00:07:37,210
PI and also in Condor using the corner

00:07:34,090 --> 00:07:40,110
for channel and docks are available at

00:07:37,210 --> 00:07:40,110
Reedy docks

00:07:42,080 --> 00:07:47,080
after stalling by test regressions these

00:07:44,599 --> 00:07:51,770
four fixture would be available for use

00:07:47,080 --> 00:07:54,919
no regression for data aggression of

00:07:51,770 --> 00:07:57,500
numerical Hayes file aggression for

00:07:54,919 --> 00:07:59,810
generic texts needle aggression for

00:07:57,500 --> 00:08:02,599
basic Python types and image integration

00:07:59,810 --> 00:08:06,530
for images I will be showing each of

00:08:02,599 --> 00:08:10,909
them with examples so let's go with new

00:08:06,530 --> 00:08:13,430
hi Gresham first the example I will be

00:08:10,909 --> 00:08:15,229
showing here tries to mimic a situation

00:08:13,430 --> 00:08:18,139
that happens a lot in scientific

00:08:15,229 --> 00:08:21,680
development and the test first is not

00:08:18,139 --> 00:08:25,250
possible there is this concept of test

00:08:21,680 --> 00:08:27,440
first from test-driven development where

00:08:25,250 --> 00:08:30,440
you must write the test before any real

00:08:27,440 --> 00:08:32,209
code the test should be failing then you

00:08:30,440 --> 00:08:36,349
write the code to make it to make it

00:08:32,209 --> 00:08:39,500
pass or as Uncle Bob put it in the four

00:08:36,349 --> 00:08:41,269
most famous laws of TDD you are not

00:08:39,500 --> 00:08:43,579
allowed to write any production code

00:08:41,269 --> 00:08:48,110
unless its purpose is making a failing

00:08:43,579 --> 00:08:49,610
test pass but to do that you must know

00:08:48,110 --> 00:08:52,310
the result you are expecting from the

00:08:49,610 --> 00:08:54,050
code you write in before hints and there

00:08:52,310 --> 00:08:57,980
are many situations where this is not

00:08:54,050 --> 00:08:59,480
possible or it's very hard to do this

00:08:57,980 --> 00:09:01,250
happens all the time in numerical

00:08:59,480 --> 00:09:03,380
simulation where we can't know

00:09:01,250 --> 00:09:06,649
beforehand the result of complex systems

00:09:03,380 --> 00:09:09,019
of differential equations developers

00:09:06,649 --> 00:09:10,940
checks that their implementation is

00:09:09,019 --> 00:09:12,350
right typically by plotting the results

00:09:10,940 --> 00:09:15,079
in a graph or other kind of

00:09:12,350 --> 00:09:17,480
visualization and compare it with a

00:09:15,079 --> 00:09:20,959
real-world experiment or some benchmark

00:09:17,480 --> 00:09:22,490
published by other researchers there are

00:09:20,959 --> 00:09:27,290
other fields where this happens a lot

00:09:22,490 --> 00:09:29,839
like machine learning for example so for

00:09:27,290 --> 00:09:32,180
these kind of situations tests do not

00:09:29,839 --> 00:09:33,440
reap development they are mostly used to

00:09:32,180 --> 00:09:35,839
avoid high gresham after the

00:09:33,440 --> 00:09:38,570
implementation finish it and here's

00:09:35,839 --> 00:09:43,040
where data aggression to be the

00:09:38,570 --> 00:09:46,190
aggression becomes pretty handy so I

00:09:43,040 --> 00:09:48,500
will be using the BCA curve over it as

00:09:46,190 --> 00:09:51,649
an example of an average that I can know

00:09:48,500 --> 00:09:53,959
the results before hint the Bezier curve

00:09:51,649 --> 00:09:56,240
over it using many drawing software's

00:09:53,959 --> 00:09:59,540
they find a curve from three or more

00:09:56,240 --> 00:10:01,370
points called contra points the first

00:09:59,540 --> 00:10:04,220
and last points are always the end

00:10:01,370 --> 00:10:06,459
points of the curve and intermediate

00:10:04,220 --> 00:10:08,930
control points define curves inclination

00:10:06,459 --> 00:10:11,510
in this example I'm going to implement

00:10:08,930 --> 00:10:15,430
the quadratic Bezier to generate 100

00:10:11,510 --> 00:10:15,430
points curve from three control points

00:10:15,930 --> 00:10:21,280
if I would follow the best first

00:10:18,400 --> 00:10:23,380
approach this is how far I can get the

00:10:21,280 --> 00:10:25,330
only information that I have is that

00:10:23,380 --> 00:10:29,080
first and last control points are always

00:10:25,330 --> 00:10:30,850
the end points of the curve but drawing

00:10:29,080 --> 00:10:31,390
a straight line would make this test

00:10:30,850 --> 00:10:34,060
pass

00:10:31,390 --> 00:10:36,490
I can't know the intermediary points

00:10:34,060 --> 00:10:39,460
without solving the quadratic Bezier

00:10:36,490 --> 00:10:41,800
equation and although the equation is

00:10:39,460 --> 00:10:45,190
not that complicated I don't think in

00:10:41,800 --> 00:10:49,240
any reasonable person that would do this

00:10:45,190 --> 00:10:51,460
by hand for 100 points of course I could

00:10:49,240 --> 00:10:55,750
use another implementation of quadratic

00:10:51,460 --> 00:10:58,000
Bezier that I could trust but for the

00:10:55,750 --> 00:11:00,640
sake of this example let's say that the

00:10:58,000 --> 00:11:04,650
only reference I have are this drawing

00:11:00,640 --> 00:11:04,650
for all I got from Wikipedia

00:11:05,240 --> 00:11:09,720
so this is my quadratic a Bezier

00:11:08,759 --> 00:11:14,180
implementations

00:11:09,720 --> 00:11:14,180
let's visually see if I got it right

00:11:15,810 --> 00:11:26,899
run my code here and plot my result okay

00:11:22,500 --> 00:11:29,670
sins right the shape of the curve is

00:11:26,899 --> 00:11:33,480
it's almost the same that the image I

00:11:29,670 --> 00:11:38,959
have as her friends but my test isn't

00:11:33,480 --> 00:11:38,959
robust enough okay I'm testing only the

00:11:40,250 --> 00:11:45,740
in each oh and the end points what can I

00:11:43,700 --> 00:11:48,020
do

00:11:45,740 --> 00:11:51,460
well I can pick some intermediary points

00:11:48,020 --> 00:11:56,320
of the curve and other nacelle for it

00:11:51,460 --> 00:11:59,840
it's far from elegance but it works okay

00:11:56,320 --> 00:12:02,380
it will avoid most of regressions that

00:11:59,840 --> 00:12:02,380
could happen

00:12:03,370 --> 00:12:11,690
but how is the data regression approach

00:12:09,260 --> 00:12:13,760
as I showed in the first example I will

00:12:11,690 --> 00:12:15,410
replace all search to a single call and

00:12:13,760 --> 00:12:18,010
the test would become more complete and

00:12:15,410 --> 00:12:18,010
easier to maintain

00:12:18,970 --> 00:12:24,260
so I declare the PI test fixture

00:12:21,680 --> 00:12:25,520
non-aggression and use the method check

00:12:24,260 --> 00:12:28,220
passing a dict

00:12:25,520 --> 00:12:30,730
of the aJE's I want to test let's see

00:12:28,220 --> 00:12:30,730
what happens

00:12:31,370 --> 00:12:36,020
so here I have my test and

00:12:36,520 --> 00:12:40,530
let's run for the first time

00:12:41,900 --> 00:12:48,290
so my test failed with the message file

00:12:45,950 --> 00:12:51,740
not funding data directory created and

00:12:48,290 --> 00:12:53,900
we can see that the fixture created a

00:12:51,740 --> 00:12:56,559
directory with the same name of the of

00:12:53,900 --> 00:12:58,899
my test model

00:12:56,559 --> 00:13:00,579
inside of this directory we have a file

00:12:58,899 --> 00:13:04,140
with the same name of the test function

00:13:00,579 --> 00:13:08,220
a CSV file

00:13:04,140 --> 00:13:13,410
if I run my test again the dust baths

00:13:08,220 --> 00:13:17,900
and it will pass unless I have a high

00:13:13,410 --> 00:13:20,330
Gresham what I having this CSV file

00:13:17,900 --> 00:13:22,100
okay I have the contents of both I hey

00:13:20,330 --> 00:13:25,640
I'm testing the first line is the header

00:13:22,100 --> 00:13:29,690
using the dict keys and then I have all

00:13:25,640 --> 00:13:34,990
values of each a hey I can even plot

00:13:29,690 --> 00:13:41,480
this to the bug if my tests are correct

00:13:34,990 --> 00:13:45,220
so super easy to to the bug my my date

00:13:41,480 --> 00:13:45,220
at the data generated by the tests

00:13:48,160 --> 00:13:54,880
let's try to force a regression to see

00:13:51,100 --> 00:13:57,389
what happens okay so we will add a bug

00:13:54,880 --> 00:13:57,389
to my code here

00:13:57,740 --> 00:14:01,149
they will run my test again

00:14:02,390 --> 00:14:10,080
so the test fails and it show a diff of

00:14:07,340 --> 00:14:13,440
obtained and expected file

00:14:10,080 --> 00:14:17,220
he expected values are the content of

00:14:13,440 --> 00:14:19,320
the CSV and obtain it is the result from

00:14:17,220 --> 00:14:22,110
my quadratic Bezier well get

00:14:19,320 --> 00:14:24,270
implementation here they are calling

00:14:22,110 --> 00:14:26,630
with the absolute difference between

00:14:24,270 --> 00:14:26,630
values

00:14:27,589 --> 00:14:33,050
it's important to to to note that this

00:14:31,490 --> 00:14:37,329
file should be added to the repository

00:14:33,050 --> 00:14:39,949
so your Co your test would running the

00:14:37,329 --> 00:14:42,759
Kachinas integration or in the other

00:14:39,949 --> 00:14:42,759
developer machine

00:14:47,420 --> 00:14:53,270
I can also define a tolerance for for

00:14:50,780 --> 00:14:56,780
the new regression comparison so let's

00:14:53,270 --> 00:15:00,860
say for some reason my bezier code would

00:14:56,780 --> 00:15:06,230
run in some low memory equipment so to

00:15:00,860 --> 00:15:09,620
save some ran i would use two bytes

00:15:06,230 --> 00:15:12,340
float hey instead of float six instead

00:15:09,620 --> 00:15:12,340
of eight bytes

00:15:14,500 --> 00:15:23,960
okay my curves is too right still has

00:15:16,870 --> 00:15:26,990
the same shape but let's run tests

00:15:23,960 --> 00:15:32,060
the test fails because now my prestige

00:15:26,990 --> 00:15:37,640
very precision changed and so to fix

00:15:32,060 --> 00:15:40,130
that I can't set tolerance a within the

00:15:37,640 --> 00:15:45,740
option default tolerance and we will set

00:15:40,130 --> 00:15:47,870
the tolerance of power of ministry so if

00:15:45,740 --> 00:15:51,100
the difference between opportunity and I

00:15:47,870 --> 00:15:56,230
expected valid value would be less and

00:15:51,100 --> 00:15:56,230
the final tolerance the test will pass

00:15:56,320 --> 00:15:59,160
okay

00:16:01,370 --> 00:16:06,550
tolerance could also be set individually

00:16:03,319 --> 00:16:09,550
for each RA using the tolerance option

00:16:06,550 --> 00:16:09,550
so

00:16:10,540 --> 00:16:15,820
I need to give a dictionary with the

00:16:13,360 --> 00:16:21,370
keyword being there hey once you set the

00:16:15,820 --> 00:16:23,310
tolerance for and the tolerance use the

00:16:21,370 --> 00:16:26,500
new Pi standard for comparing values

00:16:23,310 --> 00:16:29,110
defines a parameter 804 absolute

00:16:26,500 --> 00:16:31,450
tolerance and art all for relative

00:16:29,110 --> 00:16:34,450
tolerance most of the time you can go

00:16:31,450 --> 00:16:37,300
with it all but when values has

00:16:34,450 --> 00:16:38,800
different magnitudes relative tolerance

00:16:37,300 --> 00:16:42,810
can use it to make sure you are

00:16:38,800 --> 00:16:42,810
correctly comparing very small values

00:16:43,000 --> 00:16:48,620
the next fixture I want to show is file

00:16:45,800 --> 00:16:52,490
aggression which the data aggression for

00:16:48,620 --> 00:16:54,170
generic text contents this example I

00:16:52,490 --> 00:16:59,450
will use a function that converts a

00:16:54,170 --> 00:17:02,090
piece of each HTML code to markdown to

00:16:59,450 --> 00:17:05,060
test this function we will use the file

00:17:02,090 --> 00:17:07,520
head ratio fixture I call check passing

00:17:05,060 --> 00:17:10,040
the generated string and use the extra

00:17:07,520 --> 00:17:12,920
parameter extension so the generated

00:17:10,040 --> 00:17:17,750
file has the appropriate extension the

00:17:12,920 --> 00:17:21,100
default one is dot text let's run the

00:17:17,750 --> 00:17:21,100
test to see what happens

00:17:22,510 --> 00:17:28,700
so in the first run

00:17:25,370 --> 00:17:33,040
test fails director is created and we

00:17:28,700 --> 00:17:33,040
have our generated markdown

00:17:33,560 --> 00:17:38,230
they run the test against the test to a

00:17:36,080 --> 00:17:43,850
pass

00:17:38,230 --> 00:17:45,910
let's force aggression to see what heads

00:17:43,850 --> 00:17:45,910
you

00:17:46,220 --> 00:17:53,420
so in case of regression Yajur mention

00:17:50,990 --> 00:17:56,150
message prints a nice stiff pointing the

00:17:53,420 --> 00:18:00,640
lines that are that will change it so

00:17:56,150 --> 00:18:00,640
it's pretty easy to to debug

00:18:02,920 --> 00:18:10,660
dear her message also prints a link for

00:18:07,750 --> 00:18:13,240
NGS to the fixture generates an HTML div

00:18:10,660 --> 00:18:16,290
and the links printed on the error

00:18:13,240 --> 00:18:19,360
message so if your CI console

00:18:16,290 --> 00:18:21,549
automatically bars links to files it

00:18:19,360 --> 00:18:24,809
becomes a great tool for for debugging

00:18:21,549 --> 00:18:24,809
failing tests on CI

00:18:25,410 --> 00:18:31,760
this is how the HTML diff looks like

00:18:32,900 --> 00:18:37,669
violent aggression fixture is also a

00:18:34,909 --> 00:18:40,700
good fit for testing web frameworks ting

00:18:37,669 --> 00:18:43,159
plate based views like we see in flask

00:18:40,700 --> 00:18:45,860
or jungle if you're not familiar with

00:18:43,159 --> 00:18:48,260
web frameworks a template based view is

00:18:45,860 --> 00:18:53,029
basically a web root that responds an

00:18:48,260 --> 00:18:54,919
HTML file render 800 at runtime the

00:18:53,029 --> 00:18:57,380
hinder ization could be parameterized by

00:18:54,919 --> 00:19:01,220
predefined 8 variables on the template

00:18:57,380 --> 00:19:04,880
file so here we have the template hello

00:19:01,220 --> 00:19:10,480
dot HTML that is handled by the root -

00:19:04,880 --> 00:19:10,480
hello using the string PyCon 2020

00:19:11,990 --> 00:19:17,850
here's a naive approach to test it just

00:19:15,360 --> 00:19:21,330
check if the response data contains the

00:19:17,850 --> 00:19:24,750
string I'm expecting there is no shame

00:19:21,330 --> 00:19:27,290
in that it works but it's far from from

00:19:24,750 --> 00:19:27,290
complete

00:19:28,090 --> 00:19:36,249
so I can use file hey Gresham to make

00:19:33,609 --> 00:19:39,539
sure that the there were no changes on

00:19:36,249 --> 00:19:39,539
the entire HTML file

00:19:43,410 --> 00:19:49,710
in the the previous example I use at a

00:19:47,010 --> 00:19:51,960
very short HTML so it would fit in these

00:19:49,710 --> 00:19:54,750
lights but if you already implemented

00:19:51,960 --> 00:19:57,240
dynamic web pages or web applications

00:19:54,750 --> 00:19:57,720
you know that HTML files are more like

00:19:57,240 --> 00:20:00,450
that

00:19:57,720 --> 00:20:03,929
there's parallels there are a lot of

00:20:00,450 --> 00:20:07,200
made that metadata JavaScript imports

00:20:03,929 --> 00:20:09,660
ties definition and probably if you do

00:20:07,200 --> 00:20:12,900
good separation between the view and the

00:20:09,660 --> 00:20:14,610
contents you don't want to change you

00:20:12,900 --> 00:20:18,390
don't want changes in this style to

00:20:14,610 --> 00:20:21,120
break your test so it's a good idea to

00:20:18,390 --> 00:20:24,840
use some HTML parser to do regression

00:20:21,120 --> 00:20:27,630
only the piece of HTML that matters here

00:20:24,840 --> 00:20:30,330
I'm using beautifulsoup to select only

00:20:27,630 --> 00:20:33,419
the body element of the HTML file for

00:20:30,330 --> 00:20:37,020
aggression it will also reduce the size

00:20:33,419 --> 00:20:39,679
of your regression file making make it

00:20:37,020 --> 00:20:39,679
easier to debug

00:20:42,300 --> 00:20:45,920
so let me show you here

00:20:46,980 --> 00:20:52,890
an example here is my HTML template it's

00:20:51,290 --> 00:20:56,970
it's a big one

00:20:52,890 --> 00:21:03,050
and in my test I'm using beautifulsoup

00:20:56,970 --> 00:21:03,050
to select only one on div element

00:21:03,280 --> 00:21:05,370
and

00:21:05,940 --> 00:21:14,090
so my aggression file instead of the

00:21:09,210 --> 00:21:17,760
whole HTML with a lot of clothes and

00:21:14,090 --> 00:21:20,480
styles definition has only the element

00:21:17,760 --> 00:21:20,480
that I'm testing for

00:21:24,940 --> 00:21:29,350
the third fixture is data aggression

00:21:27,430 --> 00:21:31,570
that could be used for basic battle

00:21:29,350 --> 00:21:33,600
types include clothing lists and

00:21:31,570 --> 00:21:33,600
dictionaries

00:21:34,600 --> 00:21:39,970
to show that let's get back to our first

00:21:37,240 --> 00:21:44,820
example the cars back class and they

00:21:39,970 --> 00:21:47,620
create car from a method here's our test

00:21:44,820 --> 00:21:49,840
the data regression check method

00:21:47,620 --> 00:21:53,649
receives any Python basic type including

00:21:49,840 --> 00:21:56,830
lists ticks and tuples so as we are

00:21:53,649 --> 00:21:59,080
testing an object it must be it must be

00:21:56,830 --> 00:22:02,380
possible to serialize it to a dict of

00:21:59,080 --> 00:22:06,370
basic types as we using a data class

00:22:02,380 --> 00:22:11,289
it's easy to serialize it using the SDK

00:22:06,370 --> 00:22:13,240
method the generated regression file is

00:22:11,289 --> 00:22:16,480
a yellow containing all the dictionary

00:22:13,240 --> 00:22:18,990
attributes including any any nested

00:22:16,480 --> 00:22:18,990
dictionary

00:22:19,049 --> 00:22:24,090
as in any other fixtures any regression

00:22:22,019 --> 00:22:27,679
will make the test fails and a nice diff

00:22:24,090 --> 00:22:27,679
will be shown in the error message

00:22:28,860 --> 00:22:34,390
the aggression is a very good fit for

00:22:31,510 --> 00:22:36,520
testing web api's let's say that this

00:22:34,390 --> 00:22:40,150
list of heroes is a collection that

00:22:36,520 --> 00:22:42,820
should be exposed through a REST API

00:22:40,150 --> 00:22:46,210
here I will be using flasks to expose

00:22:42,820 --> 00:22:48,309
this collection through HTTP methods the

00:22:46,210 --> 00:22:50,980
first route here exposes a single

00:22:48,309 --> 00:22:52,570
writing of the collection and the second

00:22:50,980 --> 00:22:57,360
route returns the entire collection of

00:22:52,570 --> 00:22:57,360
heroes both uses JSON as protocols

00:22:57,960 --> 00:23:03,299
I could use data aggression just like

00:22:59,999 --> 00:23:05,730
that to test both endpoints the client

00:23:03,299 --> 00:23:08,429
fixture simulates a browser HTTP GET

00:23:05,730 --> 00:23:11,730
request and returns a flask response

00:23:08,429 --> 00:23:13,919
object the object has a method get JSON

00:23:11,730 --> 00:23:18,690
that returns a JS about a JSON

00:23:13,919 --> 00:23:20,899
serializable digs the first test the

00:23:18,690 --> 00:23:23,220
response content is a single dictionary

00:23:20,899 --> 00:23:25,049
representing one item of the collection

00:23:23,220 --> 00:23:29,240
the regression file would contain a

00:23:25,049 --> 00:23:32,789
single writing as as the aslha like this

00:23:29,240 --> 00:23:34,860
in the second test method the response

00:23:32,789 --> 00:23:36,809
contain a list of dicts representing the

00:23:34,860 --> 00:23:40,019
collection so the generated file would

00:23:36,809 --> 00:23:42,379
contain the listing of items in ml

00:23:40,019 --> 00:23:42,379
format

00:23:43,700 --> 00:23:48,720
last but not least we have image

00:23:46,650 --> 00:23:51,030
regression that creates data regression

00:23:48,720 --> 00:23:53,980
for images

00:23:51,030 --> 00:23:56,620
so suppose we want to test this sample

00:23:53,980 --> 00:24:00,940
code that generates a 3d plot with metal

00:23:56,620 --> 00:24:03,640
clip we include the image regression

00:24:00,940 --> 00:24:08,160
fixture in our test and use the check

00:24:03,640 --> 00:24:08,160
method passing image content as bytes

00:24:08,260 --> 00:24:13,240
here we use it bytes IO object to trick

00:24:11,380 --> 00:24:15,790
the function to write the image contents

00:24:13,240 --> 00:24:17,710
in memory and then we pass the buffer

00:24:15,790 --> 00:24:20,500
contents to the image regression check

00:24:17,710 --> 00:24:22,270
method on the first run the image file

00:24:20,500 --> 00:24:24,880
would be created by the fixture in the

00:24:22,270 --> 00:24:27,010
test folder and following runs will

00:24:24,880 --> 00:24:31,000
compare images and fail you if any

00:24:27,010 --> 00:24:34,200
difference is Fault in the case of a

00:24:31,000 --> 00:24:37,720
high gresham the test message shows that

00:24:34,200 --> 00:24:39,580
error message shows a percentage that is

00:24:37,720 --> 00:24:45,580
calculated by checking the difference of

00:24:39,580 --> 00:24:47,860
each pixel RGB value you can set a

00:24:45,580 --> 00:24:50,290
threshold for to ignore a small

00:24:47,860 --> 00:24:53,830
difference in the image comparison using

00:24:50,290 --> 00:24:55,660
the diff threshold option a very common

00:24:53,830 --> 00:24:57,880
problem when using image regression

00:24:55,660 --> 00:25:00,160
testing is that some fonts are hindered

00:24:57,880 --> 00:25:02,490
with the small variations in different

00:25:00,160 --> 00:25:04,960
platforms like Windows and Linux

00:25:02,490 --> 00:25:07,140
increasing the D threshold may help with

00:25:04,960 --> 00:25:07,140
that

00:25:07,220 --> 00:25:13,790
and these are the four fixture of Pi

00:25:11,030 --> 00:25:15,980
desecrations the fou API can be found at

00:25:13,790 --> 00:25:18,770
the docks or read the docks

00:25:15,980 --> 00:25:24,740
I would add just some of final notes

00:25:18,770 --> 00:25:26,810
about the plug-in usage you can

00:25:24,740 --> 00:25:28,130
regenerate our regression data of your

00:25:26,810 --> 00:25:30,500
test suite

00:25:28,130 --> 00:25:32,600
using the fourth legend option this

00:25:30,500 --> 00:25:35,990
would run all the tests suite forcing

00:25:32,600 --> 00:25:38,600
regression files to be regenerated so

00:25:35,990 --> 00:25:41,120
consider our web framework view example

00:25:38,600 --> 00:25:44,480
where we use file regression to compare

00:25:41,120 --> 00:25:48,920
HTML files let's say we change a single

00:25:44,480 --> 00:25:51,560
CSS class and this is class name is used

00:25:48,920 --> 00:25:54,320
by all the application pages let me use

00:25:51,560 --> 00:25:58,120
force region to update all the HTML

00:25:54,320 --> 00:25:58,120
regression files without hassle

00:25:59,140 --> 00:26:04,030
about the plugin dependencies no

00:26:01,960 --> 00:26:06,850
regression depends on panda true true

00:26:04,030 --> 00:26:10,240
pandas to write CSV files and image

00:26:06,850 --> 00:26:13,540
aggressions depends on pill to do the

00:26:10,240 --> 00:26:15,550
image comparison by des aggressions do

00:26:13,540 --> 00:26:17,920
not test do not install these

00:26:15,550 --> 00:26:19,690
dependencies automatically to avoid

00:26:17,920 --> 00:26:23,530
increasing the size of your environment

00:26:19,690 --> 00:26:25,690
without needing it so you may have a

00:26:23,530 --> 00:26:27,850
project that only uses that regression

00:26:25,690 --> 00:26:31,360
for example and you probably don't want

00:26:27,850 --> 00:26:35,730
to stop wonders for that so blenders and

00:26:31,360 --> 00:26:35,730
pillow must be stolid manually

00:26:36,200 --> 00:26:40,529
before wrapping up I want to highlight

00:26:38,520 --> 00:26:43,500
two more libraries that we use when

00:26:40,529 --> 00:26:46,440
doing the aggression testing the first

00:26:43,500 --> 00:26:48,270
one is PI test data G it's a PI test

00:26:46,440 --> 00:26:51,620
plug-in that makes easier to restore

00:26:48,270 --> 00:26:51,620
support file for tests

00:26:51,780 --> 00:26:57,480
let's say you want to test a function

00:26:53,940 --> 00:27:00,030
that count lines of fire using PI test

00:26:57,480 --> 00:27:02,400
data G you can create a folder using the

00:27:00,030 --> 00:27:05,220
same name of the testing model and add

00:27:02,400 --> 00:27:06,900
any support file to it these files would

00:27:05,220 --> 00:27:09,570
become easily accessible through the

00:27:06,900 --> 00:27:13,440
data diary fixture which is a path Lib

00:27:09,570 --> 00:27:15,540
object here in the example and passing

00:27:13,440 --> 00:27:18,960
the support file dot txt to the count

00:27:15,540 --> 00:27:20,760
lines function contents of the data deer

00:27:18,960 --> 00:27:23,160
folder would be copied to a temporary

00:27:20,760 --> 00:27:24,720
directory so changes support file

00:27:23,160 --> 00:27:28,740
contents would not change the original

00:27:24,720 --> 00:27:31,260
file you can use you can also use data G

00:27:28,740 --> 00:27:33,090
to write files generated by your tests

00:27:31,260 --> 00:27:35,540
without worrying about remove them after

00:27:33,090 --> 00:27:35,540
the effect

00:27:36,980 --> 00:27:42,690
here we are testing a tab to space

00:27:40,320 --> 00:27:45,780
converter and writing the generated file

00:27:42,690 --> 00:27:49,460
using data G to then check that it

00:27:45,780 --> 00:27:49,460
doesn't have any type character

00:27:50,059 --> 00:27:54,979
my test aggressions used by test data

00:27:52,429 --> 00:27:59,889
behind the scenes and they can be use it

00:27:54,979 --> 00:28:02,690
together without problem so regarded the

00:27:59,889 --> 00:28:06,580
previous example instead of testing if

00:28:02,690 --> 00:28:09,289
space file dot text has no tab character

00:28:06,580 --> 00:28:10,969
we can use file regression to make the

00:28:09,289 --> 00:28:13,429
test way more effective in terms of

00:28:10,969 --> 00:28:15,870
preventing aggression so I'm testing the

00:28:13,429 --> 00:28:18,400
whole file

00:28:15,870 --> 00:28:21,820
another two we use a lot with spiders

00:28:18,400 --> 00:28:23,770
regressions is Sileo alchemy see the

00:28:21,820 --> 00:28:25,990
alchemy is a serialization library for

00:28:23,770 --> 00:28:28,900
psycho alchemy models psycho alchemy is

00:28:25,990 --> 00:28:30,940
the most used Python RM and we

00:28:28,900 --> 00:28:34,660
originally created this library to build

00:28:30,940 --> 00:28:36,460
web api for database models but it can

00:28:34,660 --> 00:28:38,230
be combined with data regression to

00:28:36,460 --> 00:28:40,520
greatly improve testing of psycho

00:28:38,230 --> 00:28:42,770
alchemy models

00:28:40,520 --> 00:28:47,110
here we have two very simple Seahawk

00:28:42,770 --> 00:28:51,230
models user and address and user has a

00:28:47,110 --> 00:28:53,120
wench one reference to address

00:28:51,230 --> 00:28:55,220
to test these models with deadly

00:28:53,120 --> 00:28:57,860
aggression I simply use city alchemy

00:28:55,220 --> 00:28:59,180
dump method to serialize my models two

00:28:57,860 --> 00:29:02,840
dictionaries containing only

00:28:59,180 --> 00:29:05,810
python-based types i set the option nest

00:29:02,840 --> 00:29:08,120
foreign key to true so my reference to

00:29:05,810 --> 00:29:11,480
others would be serialized as a nested

00:29:08,120 --> 00:29:17,450
dict instead of having the foreign key

00:29:11,480 --> 00:29:19,340
value here is the yellow generated by

00:29:17,450 --> 00:29:21,130
the fixture which would be my regression

00:29:19,340 --> 00:29:23,190
file

00:29:21,130 --> 00:29:23,190
you

00:29:23,750 --> 00:29:29,330
so wrapping up we defined the concept of

00:29:26,899 --> 00:29:31,429
data aggression testing we talked about

00:29:29,330 --> 00:29:33,289
potential Corrections by des protein

00:29:31,429 --> 00:29:35,840
that helps the creation of data

00:29:33,289 --> 00:29:38,330
regression testing we show it no

00:29:35,840 --> 00:29:41,960
regression which works with dictionaries

00:29:38,330 --> 00:29:44,120
of 1d non-p aJE's finally aggression to

00:29:41,960 --> 00:29:46,789
create data aggression for genetic tests

00:29:44,120 --> 00:29:49,240
beta aggression for based Python types

00:29:46,789 --> 00:29:52,279
and image regression for image binaries

00:29:49,240 --> 00:29:54,409
we show it by test data yield that helps

00:29:52,279 --> 00:29:56,120
the usage of support file for testing

00:29:54,409 --> 00:29:59,269
and silly alchemy that facilitates

00:29:56,120 --> 00:30:02,769
testing psycho alchemy models with the

00:29:59,269 --> 00:30:02,769
data aggressive fixture

00:30:04,390 --> 00:30:08,019
if you're still not into bite test and

00:30:06,370 --> 00:30:09,850
once you start the official

00:30:08,019 --> 00:30:14,799
documentation is a great starting point

00:30:09,850 --> 00:30:17,019
and not just for starters but for anyone

00:30:14,799 --> 00:30:19,120
that wants to get mod more out of Pi

00:30:17,019 --> 00:30:21,630
tests I would recommend the book pi test

00:30:19,120 --> 00:30:26,950
Quick Start Guide from paranoia Vader

00:30:21,630 --> 00:30:28,929
it's available on Amazon Bruno is one of

00:30:26,950 --> 00:30:32,590
the core developers off by tests and

00:30:28,929 --> 00:30:34,779
foods closure is my personal friend but

00:30:32,590 --> 00:30:36,940
it's a great book the QuickStart title

00:30:34,779 --> 00:30:39,789
may give the wrong impression that it

00:30:36,940 --> 00:30:41,799
comes with covers all the basics but the

00:30:39,789 --> 00:30:45,000
book explains in great detail the main

00:30:41,799 --> 00:30:45,000
features of PI tests

00:30:45,330 --> 00:30:50,700
so that South I hope it was of some use

00:30:47,999 --> 00:30:53,070
for all of you I would like to thanks oh

00:30:50,700 --> 00:30:55,379
and our coolant and former colleagues at

00:30:53,070 --> 00:30:57,600
a trip OS that in some way or another

00:30:55,379 --> 00:31:00,809
had collaborated to build the tools I

00:30:57,600 --> 00:31:03,509
showed here and I special thanks to

00:31:00,809 --> 00:31:05,989
micron organization they put so much

00:31:03,509 --> 00:31:08,460
effort to make this great conference and

00:31:05,989 --> 00:31:10,679
unfortunately this year it could it

00:31:08,460 --> 00:31:13,799
couldn't help it couldn't happen in the

00:31:10,679 --> 00:31:15,899
way we all desire we can reach me out

00:31:13,799 --> 00:31:17,820
through Twitter or you can leave me

00:31:15,899 --> 00:31:20,249
leave any question in the comment

00:31:17,820 --> 00:31:22,019
section of the video you can find these

00:31:20,249 --> 00:31:24,149
slides and the source code on my github

00:31:22,019 --> 00:31:29,539
I will bring the hippo story at the top

00:31:24,149 --> 00:31:29,539
of my profile so thanks again

00:31:34,290 --> 00:31:36,350

YouTube URL: https://www.youtube.com/watch?v=YBuVGx3EYSY


