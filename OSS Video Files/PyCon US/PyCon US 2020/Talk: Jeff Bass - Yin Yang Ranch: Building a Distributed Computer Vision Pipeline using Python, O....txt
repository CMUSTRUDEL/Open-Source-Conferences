Title: Talk: Jeff Bass - Yin Yang Ranch: Building a Distributed Computer Vision Pipeline using Python, O...
Publication date: 2021-05-05
Playlist: PyCon US 2020
Description: 
	Presented by:
Jeff Bass

I am building a small permaculture farm in Southern California. I have written computer vision programs in Python to read the water meter, optimize water use, track coyotes, rabbits, raccoons and bobcats, etc. The farm is set up like an ongoing science project. I am running Python on 20 Raspberry Pi computers with PiCameras and sensors. The RPi’s capture images, detect motion and select a subset of images. Did the water meter move? Was a coyote seen? If so, images are sent to a hub computer via PyZMQ. The hub computer uses Python and OpenCV to do more advanced processing like reading the water meter digits or keeping critter counts by season. This arrangement demonstrates ways that Python can be helpful in developing IOT networks with multiple cameras and sensors.

In this talk I will describe the hub and spoke design that distributes processing across a mix of RPi’s and larger computers. I’ll cover the pros and cons of PyZMQ messaging for image transfer. I’ll describe OpenCV techniques in Python that have been helpful on both the RPi’s and the hub computer. All the programs are pure Python, and they leverage fast libraries written in C, like OpenCV and ZMQ by using Python bindings. This is an open source project with all the Python source code available on GitHub. Hardware “how to’s” & photos are also on GitHub. Pictures of my farm and my favorite coyotes are also on GitHub…because why not?

Talks Slides: https://speakerdeck.com/jeffbass/yin-yang-ranch-building-a-distributed-computer-vision-pipeline-using-python-opencv-and-zmq-17024000-4389-4bae-9e4d-16302d20a5b6
Captions: 
	00:00:07,260 --> 00:00:12,880
welcome PyCon 2020 is being done a

00:00:11,020 --> 00:00:14,740
little differently this year we're doing

00:00:12,880 --> 00:00:16,630
it online and I haven't really done that

00:00:14,740 --> 00:00:19,480
before but I think it's gonna be fun so

00:00:16,630 --> 00:00:21,880
let's get started my presentation is the

00:00:19,480 --> 00:00:25,419
yin-yang ranch a distributed computer

00:00:21,880 --> 00:00:30,730
vision system using Python OpenCV and

00:00:25,419 --> 00:00:33,579
zmq what we're gonna cover today is a

00:00:30,730 --> 00:00:35,590
little bit about me my farm and my

00:00:33,579 --> 00:00:37,840
distributed computer vision pipeline a

00:00:35,590 --> 00:00:41,260
good bit about the overall project

00:00:37,840 --> 00:00:43,840
design I'm going to talk about the nodes

00:00:41,260 --> 00:00:48,190
portion of the design where raspberry

00:00:43,840 --> 00:00:51,100
PI's gather and select images talk about

00:00:48,190 --> 00:00:54,280
zmq and image zmq which transfer the

00:00:51,100 --> 00:00:56,560
images to hub computers or we'll talk

00:00:54,280 --> 00:00:59,470
about how they receive and process

00:00:56,560 --> 00:01:00,700
images and event messages and then we'll

00:00:59,470 --> 00:01:05,199
talk about how we can take questions

00:01:00,700 --> 00:01:07,299
even for this online kind of format so

00:01:05,199 --> 00:01:10,120
I'm building a small permaculture farm

00:01:07,299 --> 00:01:12,850
in suburbia permaculture is a collection

00:01:10,120 --> 00:01:14,920
of lots of practices but it's basically

00:01:12,850 --> 00:01:17,680
trying to be much more sustainable in

00:01:14,920 --> 00:01:20,970
how we build farms and how we grow

00:01:17,680 --> 00:01:23,740
things I'd like to read a quote for you

00:01:20,970 --> 00:01:26,530
remember how self-reliant a natural

00:01:23,740 --> 00:01:29,260
landscape is an ecosystem provides for

00:01:26,530 --> 00:01:31,720
itself no one brings in truckloads of

00:01:29,260 --> 00:01:32,860
fertilizer to a forest no one carries

00:01:31,720 --> 00:01:34,960
its waste to the dump

00:01:32,860 --> 00:01:36,850
the forest takes care of all that

00:01:34,960 --> 00:01:39,729
internally producing fertility and

00:01:36,850 --> 00:01:42,159
recycling litter and debris in other

00:01:39,729 --> 00:01:44,979
words the forest inputs and outputs are

00:01:42,159 --> 00:01:47,590
balanced leaving little waste and the

00:01:44,979 --> 00:01:50,170
work is powered by sunlight this is the

00:01:47,590 --> 00:01:52,299
model we strive to emulate that's a

00:01:50,170 --> 00:01:55,210
quote by toby hemenway in his book

00:01:52,299 --> 00:01:56,500
Gaia's garden so what I've been doing

00:01:55,210 --> 00:01:57,880
since I'm retired a few years back

00:01:56,500 --> 00:02:00,570
because I've been trying to convert my

00:01:57,880 --> 00:02:02,650
two acre suburban lot into a small

00:02:00,570 --> 00:02:05,110
permaculture farm we're calling a

00:02:02,650 --> 00:02:07,299
yin-yang ranch it's an evolving science

00:02:05,110 --> 00:02:09,459
project and it's a demonstration garden

00:02:07,299 --> 00:02:11,620
I do tours I do some instruction here

00:02:09,459 --> 00:02:13,659
and I'm also growing the plant

00:02:11,620 --> 00:02:14,079
polyculture we grow lots of different

00:02:13,659 --> 00:02:16,120
things

00:02:14,079 --> 00:02:18,430
figs pears pomegranates well and

00:02:16,120 --> 00:02:20,200
tomatoes and cucumbers but also a lot of

00:02:18,430 --> 00:02:22,900
native plants like coasts live oaks and

00:02:20,200 --> 00:02:25,569
sycamores I'm also growing a bumper crop

00:02:22,900 --> 00:02:28,180
of raspberry PI's that helps me use

00:02:25,569 --> 00:02:32,670
computer vision to help manage the farm

00:02:28,180 --> 00:02:35,500
a bit about me well I went to college

00:02:32,670 --> 00:02:37,750
starting to study EE and I got drafted

00:02:35,500 --> 00:02:39,909
so I learned about electronics and

00:02:37,750 --> 00:02:41,439
fixing electronics in the army when I

00:02:39,909 --> 00:02:42,159
got out I went to grad school on the GI

00:02:41,439 --> 00:02:45,040
Bill

00:02:42,159 --> 00:02:47,590
I did some dissertation research that

00:02:45,040 --> 00:02:49,810
ended up being computer science and then

00:02:47,590 --> 00:02:52,419
became a software company or actually

00:02:49,810 --> 00:02:54,189
wrote statistical language compilers at

00:02:52,419 --> 00:02:56,950
a time when PCs were actually a new

00:02:54,189 --> 00:02:59,290
thing I spent about 20 years after that

00:02:56,950 --> 00:03:02,230
doing statistics and big science big

00:02:59,290 --> 00:03:06,870
data science at big biotech and I've

00:03:02,230 --> 00:03:10,269
also been involved since I retired with

00:03:06,870 --> 00:03:13,090
making software building out the farm

00:03:10,269 --> 00:03:15,340
and trying to build computer vision

00:03:13,090 --> 00:03:18,060
pipelines I'm going to teach you a

00:03:15,340 --> 00:03:20,799
little bit more about that today

00:03:18,060 --> 00:03:22,959
so how computer vision helps manage my

00:03:20,799 --> 00:03:24,849
small permaculture farm well obviously

00:03:22,959 --> 00:03:27,099
it reads the water meter and helps me

00:03:24,849 --> 00:03:29,620
with water use it can count bees

00:03:27,099 --> 00:03:31,810
butterflies and pollinators it tracks

00:03:29,620 --> 00:03:33,400
coyotes rabbits raccoons and all kinds

00:03:31,810 --> 00:03:36,189
of critters behind my barn and elsewhere

00:03:33,400 --> 00:03:38,049
and it can monitor things that are more

00:03:36,189 --> 00:03:40,329
mundane like does the garage open or

00:03:38,049 --> 00:03:42,459
closed or is the driveway being blocked

00:03:40,329 --> 00:03:44,769
by a van that's delivering something I

00:03:42,459 --> 00:03:46,209
also track sunlight hours and light

00:03:44,769 --> 00:03:48,159
intensity so I can understand

00:03:46,209 --> 00:03:51,400
photosynthesis strength and availability

00:03:48,159 --> 00:03:54,220
and I monitor many non camera sensors I

00:03:51,400 --> 00:03:58,449
look at temperature humidity motion

00:03:54,220 --> 00:04:00,159
sensors and solar panel output so here's

00:03:58,449 --> 00:04:02,500
a drawing that I think helps illustrate

00:04:00,159 --> 00:04:05,859
what I mean by a computer vision

00:04:02,500 --> 00:04:08,590
pipeline raspberry PI's are used as

00:04:05,859 --> 00:04:11,290
nodes they have PI cameras that take

00:04:08,590 --> 00:04:14,379
pictures often 16 frames a second 24

00:04:11,290 --> 00:04:17,680
hours a day there's one or two cameras

00:04:14,379 --> 00:04:20,349
per Raspberry Pi and there's eight to 12

00:04:17,680 --> 00:04:23,770
raspberry PI's feeding a common image

00:04:20,349 --> 00:04:26,259
hub they each of them is gathering

00:04:23,770 --> 00:04:28,180
frames at 16 frames a second but because

00:04:26,259 --> 00:04:29,440
of the logic on the Raspberry Pi they

00:04:28,180 --> 00:04:33,130
don't send a lot of frame

00:04:29,440 --> 00:04:35,520
per day or per hour instead they send

00:04:33,130 --> 00:04:37,840
only frames that are important and we

00:04:35,520 --> 00:04:39,640
use detectors software I'll talk about

00:04:37,840 --> 00:04:42,610
in a moment to determine what's

00:04:39,640 --> 00:04:45,550
important enough to send for the frames

00:04:42,610 --> 00:04:48,130
to get from the Raspberry Pi to the

00:04:45,550 --> 00:04:49,720
image hub requires zmq messaging there's

00:04:48,130 --> 00:04:52,150
a lot of messaging services as it could

00:04:49,720 --> 00:04:54,310
be used we've chosen zmq and I've even

00:04:52,150 --> 00:04:58,270
written a package image the mq to make

00:04:54,310 --> 00:05:00,730
that easy and then once I have images in

00:04:58,270 --> 00:05:03,100
the hub they get stored they get filed

00:05:00,730 --> 00:05:05,320
and I have another program in the

00:05:03,100 --> 00:05:08,590
pipeline called a librarian and that

00:05:05,320 --> 00:05:12,790
librarian gathers as needed things from

00:05:08,590 --> 00:05:15,130
the hub images event messages processes

00:05:12,790 --> 00:05:17,680
those and answers queries for instance I

00:05:15,130 --> 00:05:22,300
can text the librarian and ask if the

00:05:17,680 --> 00:05:24,280
water's running so what do I mean by a

00:05:22,300 --> 00:05:26,830
distributed computer vision pipeline

00:05:24,280 --> 00:05:29,710
well computer vision is a whole bunch of

00:05:26,830 --> 00:05:32,500
techniques that capture images resize

00:05:29,710 --> 00:05:34,180
them perhaps transform them and their

00:05:32,500 --> 00:05:36,520
techniques that detect objects and

00:05:34,180 --> 00:05:39,610
images like is that a car a pedestrian

00:05:36,520 --> 00:05:41,350
can I read the road sign a computer

00:05:39,610 --> 00:05:43,600
vision pipeline is a sequence of

00:05:41,350 --> 00:05:45,430
computer vision programs different ones

00:05:43,600 --> 00:05:47,290
doing different things initialize a

00:05:45,430 --> 00:05:49,750
camera in one program take a picture

00:05:47,290 --> 00:05:51,550
resize the picture and then perhaps in

00:05:49,750 --> 00:05:53,800
another program receive the image and

00:05:51,550 --> 00:05:57,190
then use convolutional neural networks

00:05:53,800 --> 00:05:59,320
to recognize say a coyote a distributed

00:05:57,190 --> 00:06:03,360
computer vision program pipeline excuse

00:05:59,320 --> 00:06:05,970
me is a pipeline that runs on multiple

00:06:03,360 --> 00:06:08,440
distributed computers across the network

00:06:05,970 --> 00:06:10,510
that's what I'm doing here I have

00:06:08,440 --> 00:06:12,580
raspberry PI's communicating across a

00:06:10,510 --> 00:06:15,900
network to image hub computers in a

00:06:12,580 --> 00:06:18,070
different building and those in turn

00:06:15,900 --> 00:06:21,460
communicate with librarian computers

00:06:18,070 --> 00:06:23,530
some of which are in the Internet the

00:06:21,460 --> 00:06:26,800
tools I'm using for my computer vision

00:06:23,530 --> 00:06:29,020
work in Python is Python 3 plus well

00:06:26,800 --> 00:06:31,810
we're all doing that now right and then

00:06:29,020 --> 00:06:35,260
raspbian linux for twenty-plus raspberry

00:06:31,810 --> 00:06:38,050
PI's I used both Linux and Mac OS hubs

00:06:35,260 --> 00:06:39,130
and then I'm using numpy which for those

00:06:38,050 --> 00:06:40,810
of us that have been computing a long

00:06:39,130 --> 00:06:42,710
time that's my best friend ever since

00:06:40,810 --> 00:06:45,700
Fortran and working with array

00:06:42,710 --> 00:06:49,070
I use OpenCV which is a collection of

00:06:45,700 --> 00:06:50,690
2,500 tools for computer vision it's the

00:06:49,070 --> 00:06:53,690
backbone of most things we do with

00:06:50,690 --> 00:06:56,480
Python and computer vision I'm using zmq

00:06:53,690 --> 00:06:58,490
and it's bindings pi zmq to actually

00:06:56,480 --> 00:07:01,220
transfer images from computer to

00:06:58,490 --> 00:07:03,230
computer I'm using the PI camera which i

00:07:01,220 --> 00:07:05,630
think is an astonishing device not only

00:07:03,230 --> 00:07:07,400
for the hardware but the software the PI

00:07:05,630 --> 00:07:09,680
camera module has taught me a lot about

00:07:07,400 --> 00:07:12,350
how digital camera sensors actually work

00:07:09,680 --> 00:07:14,240
I'm also using the bunch of convenience

00:07:12,350 --> 00:07:16,430
libraries two functions one I'll mention

00:07:14,240 --> 00:07:18,830
here is I am utils you'll see it in some

00:07:16,430 --> 00:07:20,990
of my routines and then I'm using an

00:07:18,830 --> 00:07:23,270
array of electronics I'm using raspberry

00:07:20,990 --> 00:07:24,200
PI's as my main out there in the

00:07:23,270 --> 00:07:26,810
Internet of Things

00:07:24,200 --> 00:07:29,210
computers and I'm using MOSFETs and

00:07:26,810 --> 00:07:30,890
sensors and temperature sensors all

00:07:29,210 --> 00:07:33,350
kinds of electronics which I tie

00:07:30,890 --> 00:07:37,310
together mostly using the raspberry PI's

00:07:33,350 --> 00:07:40,520
GPIO boards so image computing the

00:07:37,310 --> 00:07:42,320
toolset OpenCV this is a big one if you

00:07:40,520 --> 00:07:44,120
haven't used open CV yet you should

00:07:42,320 --> 00:07:47,120
there's plenty of tutorials out there

00:07:44,120 --> 00:07:49,610
the Python bindings are great it's one

00:07:47,120 --> 00:07:51,470
line import CV - it's a bit tough to

00:07:49,610 --> 00:07:53,510
install it on some things like Raspberry

00:07:51,470 --> 00:07:55,670
Pi computers but there are tutorials out

00:07:53,510 --> 00:07:57,410
there for that as well it runs really

00:07:55,670 --> 00:08:01,520
well in Raspberry Pi computers actually

00:07:57,410 --> 00:08:03,620
and the open CV images you'll see them

00:08:01,520 --> 00:08:06,820
passed around some code a bit the open

00:08:03,620 --> 00:08:08,900
CV images are easily sent as Network

00:08:06,820 --> 00:08:12,500
messages because they're basically numpy

00:08:08,900 --> 00:08:15,590
arrays so let's talk about my pipeline a

00:08:12,500 --> 00:08:17,600
little bit things start at a Raspberry

00:08:15,590 --> 00:08:19,370
Pi I call that an image node they're

00:08:17,600 --> 00:08:22,010
passed over a network using a tool

00:08:19,370 --> 00:08:24,620
called image the mq and they arrive at

00:08:22,010 --> 00:08:26,540
the image however I'm not going to talk

00:08:24,620 --> 00:08:28,790
further than the image hub today because

00:08:26,540 --> 00:08:31,850
this is only a 30-minute talk and well

00:08:28,790 --> 00:08:33,560
that's gonna be blending so let's talk

00:08:31,850 --> 00:08:35,980
about the pseudocode for what happens on

00:08:33,560 --> 00:08:38,990
an image node it's a forever event loop

00:08:35,980 --> 00:08:41,720
grab the camera image you put the image

00:08:38,990 --> 00:08:44,540
in a queue you use some sort of detector

00:08:41,720 --> 00:08:47,030
software to analyze the queue decide if

00:08:44,540 --> 00:08:49,310
something happened and then if something

00:08:47,030 --> 00:08:52,640
happened / the detector you send the

00:08:49,310 --> 00:08:54,830
event message you send an imager 2 or 3

00:08:52,640 --> 00:08:56,430
and then you wait for the hub to respond

00:08:54,830 --> 00:09:00,290
and you process the hub response

00:08:56,430 --> 00:09:01,980
forever the other chub is doing

00:09:00,290 --> 00:09:04,320
something simpler

00:09:01,980 --> 00:09:06,240
it's just listening for raspberry PI's

00:09:04,320 --> 00:09:09,180
to send it messages it receives the

00:09:06,240 --> 00:09:10,920
messages stores the message stores the

00:09:09,180 --> 00:09:14,370
image and then sends an acknowledgement

00:09:10,920 --> 00:09:16,440
okay I got you the image hub can receive

00:09:14,370 --> 00:09:18,390
from multiple raspberry PI's at a time

00:09:16,440 --> 00:09:19,770
I've gone as high as fifteen I find that

00:09:18,390 --> 00:09:23,750
if I go much higher than eight things

00:09:19,770 --> 00:09:26,459
start to slow down but this is a mini in

00:09:23,750 --> 00:09:31,200
system where many raspberry PI's send

00:09:26,459 --> 00:09:36,330
messages and event images into the image

00:09:31,200 --> 00:09:39,600
shop let's talk a little bit about how

00:09:36,330 --> 00:09:41,760
that works in Python the upper half of

00:09:39,600 --> 00:09:43,770
the screen is the node code that runs on

00:09:41,760 --> 00:09:45,300
the Raspberry Pi the lower half of the

00:09:43,770 --> 00:09:46,529
screen is the hub code which in this

00:09:45,300 --> 00:09:51,720
case you happen to be running on a Mac

00:09:46,529 --> 00:09:54,000
so you import socket time typical Python

00:09:51,720 --> 00:09:56,510
standard library functions I'm using I

00:09:54,000 --> 00:09:59,730
am utils to import a video streaming

00:09:56,510 --> 00:10:03,720
function and then I import image zmq

00:09:59,730 --> 00:10:08,370
which is the software that makes image

00:10:03,720 --> 00:10:11,520
zmq makes zmq able to pass images so i

00:10:08,370 --> 00:10:14,339
instantiate a sender in image zmq giving

00:10:11,520 --> 00:10:16,770
it an address that I'm aiming at I set

00:10:14,339 --> 00:10:18,630
up the raspberry PI's name just using a

00:10:16,770 --> 00:10:20,760
socket function so but now I have some

00:10:18,630 --> 00:10:24,180
text to distinguish this Raspberry Pi

00:10:20,760 --> 00:10:26,130
from another one then I set up a PI

00:10:24,180 --> 00:10:28,980
camera by instantiating off a video

00:10:26,130 --> 00:10:32,160
stream and starting it and then I just

00:10:28,980 --> 00:10:38,000
loop grab an image send it grab an image

00:10:32,160 --> 00:10:43,140
send it forever on the hub side I import

00:10:38,000 --> 00:10:44,760
cv2 which is OpenCV I import image zmq

00:10:43,140 --> 00:10:46,800
because well that's how we're going to

00:10:44,760 --> 00:10:49,200
receive the images and then they

00:10:46,800 --> 00:10:52,529
instantiate from image the mq an image

00:10:49,200 --> 00:10:56,820
hub the same forever loop kind of

00:10:52,529 --> 00:11:01,320
happens again we grab the name and the

00:10:56,820 --> 00:11:04,170
image from the image hub we then use cv2

00:11:01,320 --> 00:11:06,450
to show the image on the screen and wait

00:11:04,170 --> 00:11:07,850
a few milliseconds and then send back

00:11:06,450 --> 00:11:09,160
the acknowledgement

00:11:07,850 --> 00:11:10,930
now the

00:11:09,160 --> 00:11:12,519
top half of the screen shows the program

00:11:10,930 --> 00:11:14,230
that's running continuously on eighth

00:11:12,519 --> 00:11:17,709
res berry pies for this particular

00:11:14,230 --> 00:11:20,290
example and the program at the bottom is

00:11:17,709 --> 00:11:22,209
running on a Mac which is receiving from

00:11:20,290 --> 00:11:25,170
those eight and then it's going to

00:11:22,209 --> 00:11:26,800
display what it's showing on the screen

00:11:25,170 --> 00:11:30,189
and there we go

00:11:26,800 --> 00:11:31,810
so eight raspberry pies are each running

00:11:30,189 --> 00:11:34,990
the program you saw at the top half of

00:11:31,810 --> 00:11:37,629
the screen and this isn't a screenshot

00:11:34,990 --> 00:11:40,089
from my Mac getting streams from all of

00:11:37,629 --> 00:11:43,319
those I was able to get with eight

00:11:40,089 --> 00:11:47,500
Raspberry Pi sending I think these were

00:11:43,319 --> 00:11:49,240
320 by 240 sending images continuously I

00:11:47,500 --> 00:11:52,959
was able to get about 10 to 12 frames a

00:11:49,240 --> 00:11:54,639
second if you loaded up higher than 8

00:11:52,959 --> 00:11:56,699
raspberry pies it might go lower than

00:11:54,639 --> 00:11:58,959
that but we'll talk about in a while

00:11:56,699 --> 00:12:04,149
there are a lot of ways to speed this up

00:11:58,959 --> 00:12:07,060
so let's use another distributed

00:12:04,149 --> 00:12:08,889
computer vision pipeline example this is

00:12:07,060 --> 00:12:10,360
one I've used to teach a lot of folks

00:12:08,889 --> 00:12:13,240
how to get started in this field it's

00:12:10,360 --> 00:12:15,459
reading my water meter so what does the

00:12:13,240 --> 00:12:17,529
Raspberry Pi do well it turns on the

00:12:15,459 --> 00:12:19,810
lights to light the meter the meters in

00:12:17,529 --> 00:12:22,420
the ground in a meter case it

00:12:19,810 --> 00:12:25,089
continuously grabs frames 16 frames a

00:12:22,420 --> 00:12:27,100
second just watching the meter it does

00:12:25,089 --> 00:12:31,019
ROI cropping converts the frames to

00:12:27,100 --> 00:12:31,019
grayscale it does threshold

00:12:32,339 --> 00:12:37,750
indistinguishable needle or the smaller

00:12:34,899 --> 00:12:40,060
needle link spinners in motion and if it

00:12:37,750 --> 00:12:42,519
is in motion it sends that navette

00:12:40,060 --> 00:12:46,269
message water flowing and sends four or

00:12:42,519 --> 00:12:48,610
five frames what the Mac does acting as

00:12:46,269 --> 00:12:51,430
a hub it receives it acknowledges those

00:12:48,610 --> 00:12:54,730
images it adds the event messages to an

00:12:51,430 --> 00:12:57,550
events log if stores and indexes the

00:12:54,730 --> 00:12:59,680
images and then a separate program the

00:12:57,550 --> 00:13:02,370
librarian extracts digits to read the

00:12:59,680 --> 00:13:07,329
meter and keeps history of events in

00:13:02,370 --> 00:13:10,329
response to queries about status so

00:13:07,329 --> 00:13:11,920
here's what it all looks like on the

00:13:10,329 --> 00:13:13,449
left is a daylight picture of what the

00:13:11,920 --> 00:13:15,930
water meter looks like this is what they

00:13:13,449 --> 00:13:18,819
look like in most parts of the world in

00:13:15,930 --> 00:13:21,399
the middle this is a full per frame

00:13:18,819 --> 00:13:23,080
capture from the Raspberry Pi camera

00:13:21,399 --> 00:13:26,530
it's lit with 20

00:13:23,080 --> 00:13:28,870
for low-power LEDs that way by spreading

00:13:26,530 --> 00:13:30,690
out the LEDs there's less glare on the

00:13:28,870 --> 00:13:33,670
glass screen at the meter

00:13:30,690 --> 00:13:37,660
once the Raspberry Pi has read the image

00:13:33,670 --> 00:13:40,360
it processes it actually crops out the

00:13:37,660 --> 00:13:42,700
part of the field it isn't needed and it

00:13:40,360 --> 00:13:45,550
picks an ROI the little square box in

00:13:42,700 --> 00:13:49,510
the second image from the right and if

00:13:45,550 --> 00:13:52,600
there's motion in that region of

00:13:49,510 --> 00:13:55,740
interest it actually triggers the

00:13:52,600 --> 00:13:58,870
flowing state and sends a few images and

00:13:55,740 --> 00:14:00,370
once the flowing state has been sent and

00:13:58,870 --> 00:14:02,080
it sent a few images it doesn't keep

00:14:00,370 --> 00:14:03,550
sending while the meter spinning there's

00:14:02,080 --> 00:14:05,290
really no benefit in that it's going to

00:14:03,550 --> 00:14:08,440
wait then until the meter stops spinning

00:14:05,290 --> 00:14:10,030
and take a reading at that time the

00:14:08,440 --> 00:14:12,820
advantage of that is we're sending

00:14:10,030 --> 00:14:15,910
relatively few images to get the job

00:14:12,820 --> 00:14:18,280
done and then on the Mac the four image

00:14:15,910 --> 00:14:21,640
on the right the Mac actually grabs out

00:14:18,280 --> 00:14:25,300
the digits mask is masked them out and

00:14:21,640 --> 00:14:26,890
then it uses image classification to

00:14:25,300 --> 00:14:30,490
pick out the digits and actually read

00:14:26,890 --> 00:14:32,620
the value so let me go back to the

00:14:30,490 --> 00:14:34,720
distributed computer vision pipeline and

00:14:32,620 --> 00:14:37,270
review a little bit about the things

00:14:34,720 --> 00:14:39,430
we've seen so far there's an image hug

00:14:37,270 --> 00:14:43,740
usually running on a laptop a Mac or

00:14:39,430 --> 00:14:46,300
Linux and it receives through image dmq

00:14:43,740 --> 00:14:50,170
images and event messages for eight to

00:14:46,300 --> 00:14:51,520
twelve raspberry PI's it depends on the

00:14:50,170 --> 00:14:54,490
fact that most of those won't be

00:14:51,520 --> 00:14:56,140
transmitting at the same time because it

00:14:54,490 --> 00:14:58,030
would be possible to overload both the

00:14:56,140 --> 00:15:00,010
hub and the network if all of them were

00:14:58,030 --> 00:15:02,020
continuously transmitting but that's not

00:15:00,010 --> 00:15:04,240
the kind of distributed computer vision

00:15:02,020 --> 00:15:06,670
pipeline am building I'm building one

00:15:04,240 --> 00:15:09,550
where events happen randomly around the

00:15:06,670 --> 00:15:11,050
farm and on average the network never

00:15:09,550 --> 00:15:13,630
gets overloaded in fact it never has

00:15:11,050 --> 00:15:16,030
better and then the librarian in the

00:15:13,630 --> 00:15:18,430
communication hose those use the data

00:15:16,030 --> 00:15:21,160
that's been gathered by the image hub to

00:15:18,430 --> 00:15:24,100
answer questions and queries either via

00:15:21,160 --> 00:15:29,620
web dashboard a texting system or an

00:15:24,100 --> 00:15:31,510
email agent so specialization is

00:15:29,620 --> 00:15:33,790
important and you want the right

00:15:31,510 --> 00:15:36,460
computer doing the right job well

00:15:33,790 --> 00:15:38,410
raspberry PI's are great at some things

00:15:36,460 --> 00:15:40,780
they're very cheap they're reliable

00:15:38,410 --> 00:15:43,060
they're families which is important and

00:15:40,780 --> 00:15:45,120
they're dust tolerant they're really

00:15:43,060 --> 00:15:48,430
small they're pi0 is even smaller

00:15:45,120 --> 00:15:50,140
they're very low-power they restart

00:15:48,430 --> 00:15:51,730
really quickly after power failures and

00:15:50,140 --> 00:15:54,370
the pie camera is great it has

00:15:51,730 --> 00:15:56,200
adjustable settings you can set the pie

00:15:54,370 --> 00:15:57,790
camera in many many different ways and

00:15:56,200 --> 00:16:01,510
it allows for a lot of experimentation

00:15:57,790 --> 00:16:04,630
frankly but do not confuse that little

00:16:01,510 --> 00:16:07,330
SD card in the Raspberry Pi with a desk

00:16:04,630 --> 00:16:09,820
it's not it's not reliable for writing

00:16:07,330 --> 00:16:11,980
large binary image files over and over

00:16:09,820 --> 00:16:14,860
and it writes really slowly I can write

00:16:11,980 --> 00:16:17,800
faster to the network and I can write to

00:16:14,860 --> 00:16:20,260
the card and you know the Raspberry Pi

00:16:17,800 --> 00:16:22,750
has fairly limited memory fairly limited

00:16:20,260 --> 00:16:25,840
processing capacity it has a slower USB

00:16:22,750 --> 00:16:27,280
bus Laurie threat the USB cameras don't

00:16:25,840 --> 00:16:30,040
work really well on a Raspberry Pi the

00:16:27,280 --> 00:16:32,650
PI cams work best but for the things it

00:16:30,040 --> 00:16:35,470
does it does them very well it's really

00:16:32,650 --> 00:16:37,660
good at being out by the barn running a

00:16:35,470 --> 00:16:39,400
camera and being sure to capture the

00:16:37,660 --> 00:16:43,300
images and send them off on the network

00:16:39,400 --> 00:16:45,610
quickly well Macs are greater Linux

00:16:43,300 --> 00:16:48,700
laptops are great for other things right

00:16:45,610 --> 00:16:52,450
they're great at Wi-Fi and Ethernet fast

00:16:48,700 --> 00:16:54,610
fast solid-state disk drives really pack

00:16:52,450 --> 00:16:56,830
a lot of information in great computing

00:16:54,610 --> 00:16:58,210
power they can do things like recognize

00:16:56,830 --> 00:17:00,220
the digits that are flipping in the

00:16:58,210 --> 00:17:03,040
meter much more effectively than a

00:17:00,220 --> 00:17:05,620
Raspberry Pi can but guess what one Mac

00:17:03,040 --> 00:17:07,660
uses as much power as 8 or 10 or 12

00:17:05,620 --> 00:17:09,190
raspberry PI's and they're expensive

00:17:07,660 --> 00:17:12,100
you're not going to put one out behind

00:17:09,190 --> 00:17:15,190
the barn to watch the coyotes by putting

00:17:12,100 --> 00:17:17,620
some of the jobs on the Raspberry Pi and

00:17:15,190 --> 00:17:19,839
putting other jobs on the Mac we're

00:17:17,620 --> 00:17:22,600
actually building a distributed computer

00:17:19,839 --> 00:17:24,700
vision pipeline where each computer in

00:17:22,600 --> 00:17:28,270
the pipeline does a thing for which it

00:17:24,700 --> 00:17:30,190
is best suited let's go over the water

00:17:28,270 --> 00:17:31,750
meter one more time this time showing a

00:17:30,190 --> 00:17:34,450
little bit about well what it looks like

00:17:31,750 --> 00:17:37,060
on the left you can see the cover for a

00:17:34,450 --> 00:17:39,760
typical water meter container in the

00:17:37,060 --> 00:17:41,380
ground and you can see the Raspberry Pi

00:17:39,760 --> 00:17:43,630
actually lives in a mason jar that's

00:17:41,380 --> 00:17:46,120
upside down a slots been cut on the top

00:17:43,630 --> 00:17:48,970
of the mason jar the LED lights are

00:17:46,120 --> 00:17:49,790
visible next to the unreturned water

00:17:48,970 --> 00:17:51,230
meter top

00:17:49,790 --> 00:17:55,460
when it's all assembled it looks like

00:17:51,230 --> 00:17:57,830
the water meter cover with a mason jar

00:17:55,460 --> 00:18:01,640
upside down you'll notice there was a 12

00:17:57,830 --> 00:18:04,340
volt plug I use 12 volts around a lot of

00:18:01,640 --> 00:18:06,590
my property because 12 volts travels

00:18:04,340 --> 00:18:09,140
better than five and then that simple

00:18:06,590 --> 00:18:11,720
car adapter same thing you'd plug into

00:18:09,140 --> 00:18:13,040
your car cigarette lighter to get five

00:18:11,720 --> 00:18:16,250
volts for your phone that's what I used

00:18:13,040 --> 00:18:18,140
to power the Raspberry Pi then the

00:18:16,250 --> 00:18:20,000
images from the Raspberry Pi are passed

00:18:18,140 --> 00:18:24,320
along a Wi-Fi network in this case

00:18:20,000 --> 00:18:28,550
there's a Wi-Fi on the PI through image

00:18:24,320 --> 00:18:30,380
zmq to the Linux laptop image hub that's

00:18:28,550 --> 00:18:33,320
receiving the images and text messages

00:18:30,380 --> 00:18:36,650
that's inside the house it's to probably

00:18:33,320 --> 00:18:38,810
to Wi-Fi hubs away and I can query the

00:18:36,650 --> 00:18:41,480
librarian program running on that and

00:18:38,810 --> 00:18:43,460
ask it well what about the water and

00:18:41,480 --> 00:18:46,220
I'll get a text back saying the water is

00:18:43,460 --> 00:18:48,830
flowing the last time off was at 921 m

00:18:46,220 --> 00:18:51,770
or the waters off the last time I was

00:18:48,830 --> 00:18:55,040
flowing was at 2 p.m. so that's a

00:18:51,770 --> 00:19:01,790
complete and end distributed computer

00:18:55,040 --> 00:19:03,380
vision pipeline for my water meter so

00:19:01,790 --> 00:19:05,870
let's look at the node code a little bit

00:19:03,380 --> 00:19:09,860
more detail here's an image code no

00:19:05,870 --> 00:19:11,420
image node code snippet and this is

00:19:09,860 --> 00:19:12,980
actually the main program of the image

00:19:11,420 --> 00:19:16,840
node code that runs on all the raspberry

00:19:12,980 --> 00:19:19,910
PI's I grabbed some settings I

00:19:16,840 --> 00:19:22,160
instantiate an image node which has a

00:19:19,910 --> 00:19:24,830
lot of methods and a lot of variables in

00:19:22,160 --> 00:19:26,030
it and then I could do a forever event

00:19:24,830 --> 00:19:29,420
loop just like the one we talked about

00:19:26,030 --> 00:19:31,760
before I grab sensor data which includes

00:19:29,420 --> 00:19:34,090
camera images and perhaps temperature

00:19:31,760 --> 00:19:37,130
sensor images temperature sensor data

00:19:34,090 --> 00:19:39,530
then I process the sensor data by

00:19:37,130 --> 00:19:41,510
detecting motion perhaps looking for

00:19:39,530 --> 00:19:43,610
light perhaps grabbing a temperature

00:19:41,510 --> 00:19:46,250
reading and I stick all that stuff in a

00:19:43,610 --> 00:19:47,570
queue the message queue and then if

00:19:46,250 --> 00:19:52,130
there's something in the mission's queue

00:19:47,570 --> 00:19:54,050
I send it off using image zmq you'll

00:19:52,130 --> 00:19:59,300
notice some code there with a try accept

00:19:54,050 --> 00:20:00,800
block to wait for a hub response if for

00:19:59,300 --> 00:20:02,390
some reason the hub doesn't respond

00:20:00,800 --> 00:20:03,380
immediately and it usually responds in

00:20:02,390 --> 00:20:04,669
milliseconds

00:20:03,380 --> 00:20:06,559
but if the hub doesn't respond

00:20:04,669 --> 00:20:08,799
immediately I actually try to fix the

00:20:06,559 --> 00:20:11,360
comlink and then restart the process

00:20:08,799 --> 00:20:15,980
actually I sure will code out of my

00:20:11,360 --> 00:20:17,750
image node repository on github the

00:20:15,980 --> 00:20:20,030
thing with this approach is you need to

00:20:17,750 --> 00:20:22,190
set all those computer vision settings

00:20:20,030 --> 00:20:24,470
and there's a lot of them I have to set

00:20:22,190 --> 00:20:26,480
view name I have to set detectors I have

00:20:24,470 --> 00:20:28,970
to set lights I have to turn on sensors

00:20:26,480 --> 00:20:31,700
I usually yamo files for that I find

00:20:28,970 --> 00:20:33,140
them to be very helpful you can they

00:20:31,700 --> 00:20:36,409
basically become a Python dictionary

00:20:33,140 --> 00:20:38,200
once you read them in so you can see

00:20:36,409 --> 00:20:41,000
when they lent Yemma files on the right

00:20:38,200 --> 00:20:44,750
it's really an effective way to put a

00:20:41,000 --> 00:20:48,080
lot of settings into an instantiation of

00:20:44,750 --> 00:20:49,669
an image node for each image that's

00:20:48,080 --> 00:20:51,650
captured image node does a lot of

00:20:49,669 --> 00:20:53,360
processing it applies transformations

00:20:51,650 --> 00:20:55,909
that might change the size of the image

00:20:53,360 --> 00:20:57,860
grayscale at threshold it and then it

00:20:55,909 --> 00:21:00,530
applies detectors in the case the water

00:20:57,860 --> 00:21:02,960
meter is detecting motion for each

00:21:00,530 --> 00:21:05,450
detector that's specified in the ml file

00:21:02,960 --> 00:21:07,580
you can specify more than one it sends

00:21:05,450 --> 00:21:10,429
images that meet that detector criteria

00:21:07,580 --> 00:21:13,159
and it sends event messages whenever the

00:21:10,429 --> 00:21:15,200
detector state changes the water media

00:21:13,159 --> 00:21:18,200
example water meter example is the most

00:21:15,200 --> 00:21:20,960
easy one to understand the two most

00:21:18,200 --> 00:21:23,059
important jobs for image node are to use

00:21:20,960 --> 00:21:25,970
detector methods to decide which images

00:21:23,059 --> 00:21:28,070
matter and send only the images that

00:21:25,970 --> 00:21:30,409
matter for instance when the water meter

00:21:28,070 --> 00:21:32,360
starts or stops I need a few frames or

00:21:30,409 --> 00:21:36,470
what the mean look like at the time it

00:21:32,360 --> 00:21:41,990
started or stopped so I can say a few

00:21:36,470 --> 00:21:44,659
more words about zmq zmq is a wonderful

00:21:41,990 --> 00:21:47,390
transport mechanism it does not need a

00:21:44,659 --> 00:21:50,150
broker or a server it's completely

00:21:47,390 --> 00:21:51,830
peer-to-peer and it is a great

00:21:50,150 --> 00:21:53,990
concurrency manager for multiple

00:21:51,830 --> 00:21:57,679
raspberry PI's using the request reply

00:21:53,990 --> 00:21:59,510
pattern and as a communications protocol

00:21:57,679 --> 00:22:01,580
it's very flexible but your messaging

00:21:59,510 --> 00:22:03,950
protocol has to be well designed it took

00:22:01,580 --> 00:22:06,490
me a while to work all that out I did

00:22:03,950 --> 00:22:11,330
look at alternatives to zero I'm Q

00:22:06,490 --> 00:22:14,270
RabbitMQ or OS mq p + QT d a number of

00:22:11,330 --> 00:22:15,559
them 0 mq really worked best for me

00:22:14,270 --> 00:22:16,880
although those others are well

00:22:15,559 --> 00:22:18,890
maintained libraries

00:22:16,880 --> 00:22:24,290
a lot of users they may work best for

00:22:18,890 --> 00:22:26,810
you I have taken image the MQ my Python

00:22:24,290 --> 00:22:28,880
eyes diversion of zmq and I've built a

00:22:26,810 --> 00:22:32,230
set of Python classes that allow you to

00:22:28,880 --> 00:22:35,720
move images from one computer to another

00:22:32,230 --> 00:22:38,000
I'm using the request reply pattern but

00:22:35,720 --> 00:22:39,680
you can use other patterns and it can

00:22:38,000 --> 00:22:42,260
send images it can send images

00:22:39,680 --> 00:22:44,000
compressed to JPEGs but the advantage of

00:22:42,260 --> 00:22:46,610
it is the images don't have to be

00:22:44,000 --> 00:22:49,700
encoded the actual numpy array that

00:22:46,610 --> 00:22:51,380
makes up an open CV image is sent

00:22:49,700 --> 00:22:55,010
without encoding it unless you choose to

00:22:51,380 --> 00:22:58,040
cook coda to JPEGs so I developed it for

00:22:55,010 --> 00:22:59,510
my yin-yang project it's been tested by

00:22:58,040 --> 00:23:02,540
myself and others for three years

00:22:59,510 --> 00:23:04,780
production release 1.0 one is out there

00:23:02,540 --> 00:23:06,970
and it's currently pip installable so

00:23:04,780 --> 00:23:11,000
install it give it a try

00:23:06,970 --> 00:23:13,970
if I look at the computer vision

00:23:11,000 --> 00:23:17,350
pipeline example I gave earlier here's

00:23:13,970 --> 00:23:21,320
the places that show the image cmq API

00:23:17,350 --> 00:23:23,930
we import it we instantiate a sender

00:23:21,320 --> 00:23:26,690
using an address from where you want to

00:23:23,930 --> 00:23:29,780
send to then on the hub computer we

00:23:26,690 --> 00:23:32,480
import it we instantiate hub generally

00:23:29,780 --> 00:23:36,560
that hub uses the local host as its

00:23:32,480 --> 00:23:38,840
address you don't keep one and then once

00:23:36,560 --> 00:23:42,740
having received an image you send a

00:23:38,840 --> 00:23:44,900
reply it's really that simple so what

00:23:42,740 --> 00:23:46,820
does the image hub code look like when

00:23:44,900 --> 00:23:49,370
it's all built out well this is the

00:23:46,820 --> 00:23:54,050
actual main program from the image hub

00:23:49,370 --> 00:23:57,550
github software I put up first you grab

00:23:54,050 --> 00:24:00,290
the settings then you instantiate a hub

00:23:57,550 --> 00:24:02,600
then you've got that same forever event

00:24:00,290 --> 00:24:04,670
loop again this time it's a little

00:24:02,600 --> 00:24:08,180
simpler we're gonna wait for a hub

00:24:04,670 --> 00:24:09,980
respond wait for a input and give a hub

00:24:08,180 --> 00:24:11,510
response if we haven't heard from any

00:24:09,980 --> 00:24:12,860
Raspberry Pi in a while it probably

00:24:11,510 --> 00:24:15,350
means something's wrong with the network

00:24:12,860 --> 00:24:17,000
so once we've set that patience

00:24:15,350 --> 00:24:19,370
parameter if we exceed it before we get

00:24:17,000 --> 00:24:20,690
an image we'll handle a timeout which

00:24:19,370 --> 00:24:22,880
usually sends me a text and says

00:24:20,690 --> 00:24:27,170
something broken and then we send a

00:24:22,880 --> 00:24:29,900
reply that loop receives image images

00:24:27,170 --> 00:24:34,940
from and responds to all the rest

00:24:29,900 --> 00:24:37,010
berry pies on the network so what does

00:24:34,940 --> 00:24:40,130
it do it perceives in-store images it

00:24:37,010 --> 00:24:42,830
immediately sends in ok stores the image

00:24:40,130 --> 00:24:46,070
stores the message and well that's it

00:24:42,830 --> 00:24:48,410
that's all that has to do the fact that

00:24:46,070 --> 00:24:49,850
the image hub software doesn't do much

00:24:48,410 --> 00:24:53,330
is the key to its success

00:24:49,850 --> 00:24:56,030
it handles images it sends me a message

00:24:53,330 --> 00:24:58,010
if it's broken and it runs I've had

00:24:56,030 --> 00:25:01,490
image hubs running on the property now

00:24:58,010 --> 00:25:06,860
for over two years and one or two

00:25:01,490 --> 00:25:09,380
restarts per year for each tuple that

00:25:06,860 --> 00:25:12,650
the image hub receives it sends it saves

00:25:09,380 --> 00:25:15,530
the image and the event message and then

00:25:12,650 --> 00:25:18,620
the image it receives can either be an

00:25:15,530 --> 00:25:21,020
open CV image which tends to be large or

00:25:18,620 --> 00:25:23,210
it can be a jpg encoded through from

00:25:21,020 --> 00:25:24,530
that image which is a lot smaller and

00:25:23,210 --> 00:25:28,370
you can actually see a couple of images

00:25:24,530 --> 00:25:33,140
and the text from the log file of an

00:25:28,370 --> 00:25:35,960
image hub on the right so let's take a

00:25:33,140 --> 00:25:38,960
look at one more example this is my barn

00:25:35,960 --> 00:25:40,820
I call it my coyote cam glass blocks

00:25:38,960 --> 00:25:42,530
infrared so I can't use a mason jar out

00:25:40,820 --> 00:25:45,410
here so I actually built a little cedar

00:25:42,530 --> 00:25:47,360
block cedar shake roof over the

00:25:45,410 --> 00:25:51,200
Raspberry Pi camera you can see on the

00:25:47,360 --> 00:25:53,210
right and here's what happened here's an

00:25:51,200 --> 00:25:55,460
example of a fully distributed computer

00:25:53,210 --> 00:25:56,900
vision pipeline the image node is

00:25:55,460 --> 00:25:59,300
running on the Raspberry Pi on the back

00:25:56,900 --> 00:26:02,060
of the barn the image hub is a Linux

00:25:59,300 --> 00:26:05,480
laptop in the house and then the object

00:26:02,060 --> 00:26:08,540
detection is done actually on a Mac and

00:26:05,480 --> 00:26:10,820
my detection in this case was let's see

00:26:08,540 --> 00:26:12,890
that coyote on the left was detected

00:26:10,820 --> 00:26:14,810
with the confidence of 63 percent the

00:26:12,890 --> 00:26:17,450
one on the right the confidence of forty

00:26:14,810 --> 00:26:19,100
seven percent and then the Bobcat much

00:26:17,450 --> 00:26:21,950
less at fourteen percent it's kind of

00:26:19,100 --> 00:26:23,660
fuzzy the images were taken with an

00:26:21,950 --> 00:26:26,000
image node Raspberry Pi that was using a

00:26:23,660 --> 00:26:29,390
pine waar infrared camera and a 12 volt

00:26:26,000 --> 00:26:31,700
8 watt infrared floodlight that

00:26:29,390 --> 00:26:35,360
Raspberry Pi captures a million images a

00:26:31,700 --> 00:26:36,530
day but on the three days shown here it

00:26:35,360 --> 00:26:38,870
only sent about three to five hundred

00:26:36,530 --> 00:26:40,490
frames a day that's an example of a

00:26:38,870 --> 00:26:42,860
distributed pipeline doing what it needs

00:26:40,490 --> 00:26:43,370
to do it's sending only the images that

00:26:42,860 --> 00:26:45,440
matter

00:26:43,370 --> 00:26:47,210
and not cluttering up the network with

00:26:45,440 --> 00:26:48,559
images that don't so some of the

00:26:47,210 --> 00:26:51,950
detection is done on the Raspberry Pi

00:26:48,559 --> 00:26:55,580
and further detection is done on the

00:26:51,950 --> 00:26:57,500
Linux and Mac repairs and finally I need

00:26:55,580 --> 00:26:59,660
to communicate with end-users so I've

00:26:57,500 --> 00:27:01,640
got a little texting routine and you

00:26:59,660 --> 00:27:04,190
know it sends messages like the water is

00:27:01,640 --> 00:27:07,070
off the last time it was flowing was at

00:27:04,190 --> 00:27:10,550
7:15 a.m. it was an animal detected

00:27:07,070 --> 00:27:12,830
behind the barn at 3:15 coyote maybe 47%

00:27:10,550 --> 00:27:14,600
confidence there's also other ways to

00:27:12,830 --> 00:27:17,270
communicate I've got a CLI text

00:27:14,600 --> 00:27:20,360
interface a texting interface and I'm

00:27:17,270 --> 00:27:22,940
building a web dashboard so I've learned

00:27:20,360 --> 00:27:24,950
some lessons so far experiment and

00:27:22,940 --> 00:27:27,950
observe before you optimize everybody

00:27:24,950 --> 00:27:30,290
talks about that you need to do it you

00:27:27,950 --> 00:27:31,910
can turn the image node computer vision

00:27:30,290 --> 00:27:34,010
parameters and you can spend a lot of

00:27:31,910 --> 00:27:36,860
time doing them tuning them because if

00:27:34,010 --> 00:27:39,110
you tuned them well the results are much

00:27:36,860 --> 00:27:41,270
better so I spend a lot of time tuning I

00:27:39,110 --> 00:27:43,370
also spend a lot of time optimizing

00:27:41,270 --> 00:27:44,870
Network load you want to send the

00:27:43,370 --> 00:27:45,440
smallest image size it'll get the job

00:27:44,870 --> 00:27:47,150
done

00:27:45,440 --> 00:27:50,270
remembering that most object detectors

00:27:47,150 --> 00:27:53,540
need 300 pixels or less in terms of

00:27:50,270 --> 00:27:55,820
image size and you can compress images

00:27:53,540 --> 00:27:57,410
to JPEGs that saved me a lot I tend to

00:27:55,820 --> 00:28:01,730
do that all the time around here and it

00:27:57,410 --> 00:28:04,100
looks like a Gaussian blur anyway here's

00:28:01,730 --> 00:28:05,660
some quick passes on hardware examples

00:28:04,100 --> 00:28:07,880
there's some infrared lights and other

00:28:05,660 --> 00:28:09,020
floodlights there's a mosfet that

00:28:07,880 --> 00:28:11,150
controls a floodlight

00:28:09,020 --> 00:28:13,940
get to know your MOSFETs that's the best

00:28:11,150 --> 00:28:15,770
friend you have to keep your GPIO board

00:28:13,940 --> 00:28:18,950
on your Raspberry Pi from getting burned

00:28:15,770 --> 00:28:21,080
out with too much current I also use

00:28:18,950 --> 00:28:22,370
light fixtures there's a Raspberry Pi

00:28:21,080 --> 00:28:25,309
and a temperature sensor in a light

00:28:22,370 --> 00:28:28,010
fixture on the back of the house fake

00:28:25,309 --> 00:28:31,450
security cams $5 little fake security

00:28:28,010 --> 00:28:33,290
cam holds a Raspberry Pi and a PI camera

00:28:31,450 --> 00:28:36,170
and I've learned a little bit about

00:28:33,290 --> 00:28:38,510
these tricks as well play games versus

00:28:36,170 --> 00:28:40,400
webcams no contest use the PI camera

00:28:38,510 --> 00:28:42,530
learn to use the PI camera module

00:28:40,400 --> 00:28:44,240
you won't regret the time spent there's

00:28:42,530 --> 00:28:47,210
all kinds of waterproof enclosures but

00:28:44,240 --> 00:28:50,560
my favorites are the mason jars and

00:28:47,210 --> 00:28:53,750
things like the old shingles on the barn

00:28:50,560 --> 00:28:56,090
infrared lighting it's kind of tricky I

00:28:53,750 --> 00:28:57,200
need to usually use two floodlights

00:28:56,090 --> 00:29:00,110
instead of one

00:28:57,200 --> 00:29:01,909
but it works out and power I use 12

00:29:00,110 --> 00:29:03,320
volts rather than 5 volts above running

00:29:01,909 --> 00:29:07,190
power any distance and then I use a

00:29:03,320 --> 00:29:08,990
cheap car lighter kind of plug like your

00:29:07,190 --> 00:29:12,049
cell phone to get the power down to 5

00:29:08,990 --> 00:29:13,370
volts so what am i doing next well I'm

00:29:12,049 --> 00:29:15,260
trying to write some deep learning

00:29:13,370 --> 00:29:18,830
software that looks at these image pairs

00:29:15,260 --> 00:29:21,380
and tells me that the garden needs water

00:29:18,830 --> 00:29:23,090
on the left you see a very wilted

00:29:21,380 --> 00:29:24,679
comfrey plant and a not welded

00:29:23,090 --> 00:29:27,679
conferring plant it's the same plant

00:29:24,679 --> 00:29:29,299
taken before and after watering so if I

00:29:27,679 --> 00:29:32,269
could use deep learning to recognize

00:29:29,299 --> 00:29:36,019
that change wow what a gift that would

00:29:32,269 --> 00:29:38,389
be to help manage my garden so all these

00:29:36,019 --> 00:29:40,549
projects are on open source and on

00:29:38,389 --> 00:29:44,389
github the addresses are all there for

00:29:40,549 --> 00:29:45,919
you and if you have questions about this

00:29:44,389 --> 00:29:47,779
talk I'm going to suggest something a

00:29:45,919 --> 00:29:50,690
little bit different I'm gonna suggest

00:29:47,779 --> 00:29:54,950
that you actually ask a question by

00:29:50,690 --> 00:29:57,409
posting a an issue on the yin-yang ranch

00:29:54,950 --> 00:30:01,010
github repository all the details are

00:29:57,409 --> 00:30:03,909
there and they're also in the deck some

00:30:01,010 --> 00:30:06,889
of their links for electronics cmq

00:30:03,909 --> 00:30:08,630
OpenCV computer vision tutorials in

00:30:06,889 --> 00:30:11,899
permaculture are shown on this screen

00:30:08,630 --> 00:30:13,669
and lastly I want to thank you

00:30:11,899 --> 00:30:15,590
especially I want to thank our PI con 20

00:30:13,669 --> 00:30:18,110
20 volunteers who have put in a lot of

00:30:15,590 --> 00:30:21,380
time to do this the hard way which is

00:30:18,110 --> 00:30:25,450
organizing all of us at home thank them

00:30:21,380 --> 00:30:25,450

YouTube URL: https://www.youtube.com/watch?v=76GGZGneJZ4


