Title: Larry Hastings   The Gilectomy How's It Going   PyCon 2017
Publication date: 2017-05-20
Playlist: PyCon 2017
Description: 
	"Speaker: Larry Hastings

One of the most interesting projects in Python today is Larry Hastings' ""Gilectomy"" project: the removal of Python's Global Interpreter Lock, or ""GIL"".  Come for an up-to-the-minute status report: what's been tried, what has and hasn't worked, and what performance is like now.

Slides can be found at: https://speakerdeck.com/pycon2017 and https://github.com/PyCon/2017-slides"
Captions: 
	00:00:00,000 --> 00:00:07,440
past so it's time for our last talk

00:00:04,470 --> 00:00:11,370
before lunch everyone so we really

00:00:07,440 --> 00:00:13,950
should make a start now our next speaker

00:00:11,370 --> 00:00:17,520
is here to talk about the gill ectomy

00:00:13,950 --> 00:00:30,029
and how it's going please make welcome

00:00:17,520 --> 00:00:31,650
Larry Hastings thank you uh my name is

00:00:30,029 --> 00:00:33,480
Larry Hastings ladies and gentlemen boys

00:00:31,650 --> 00:00:35,910
and girls children of all ages this is

00:00:33,480 --> 00:00:37,950
the Galactic how's it going hi Khan 2017

00:00:35,910 --> 00:00:40,290
edition I call the talk that because

00:00:37,950 --> 00:00:42,600
when I go to conferences now people walk

00:00:40,290 --> 00:00:43,829
up to me and say Oh Larry oh you think I

00:00:42,600 --> 00:00:46,140
work on the glass to me how's it going

00:00:43,829 --> 00:00:47,460
and I'm like ah I'm about to speak for

00:00:46,140 --> 00:00:49,649
40 minutes about how the Galacta me is

00:00:47,460 --> 00:00:51,360
going and it's I don't want to answer

00:00:49,649 --> 00:00:52,530
for 40 minutes every person walks out to

00:00:51,360 --> 00:00:54,149
me at a conference so I'm going to do it

00:00:52,530 --> 00:00:55,829
for everybody else once and now you

00:00:54,149 --> 00:00:58,230
don't have to ask that question you can

00:00:55,829 --> 00:01:00,300
ask a more specific question so about

00:00:58,230 --> 00:01:02,820
this talk I want to warn you just like

00:01:00,300 --> 00:01:04,049
last year I gave a talk about the

00:01:02,820 --> 00:01:06,630
Galacta me last year an introductory

00:01:04,049 --> 00:01:08,220
talk this is kinda the same preface

00:01:06,630 --> 00:01:10,080
slide this talk will be exceedingly

00:01:08,220 --> 00:01:11,880
technical and it's going to assume that

00:01:10,080 --> 00:01:13,890
everybody in here is comfortable about

00:01:11,880 --> 00:01:16,890
me talking about multi-threading issues

00:01:13,890 --> 00:01:19,350
and about cpython internals this year

00:01:16,890 --> 00:01:21,180
I'm kind of assuming that you're mildly

00:01:19,350 --> 00:01:23,070
familiar with maybe you might talk from

00:01:21,180 --> 00:01:24,330
last year so there's a lot of stuff that

00:01:23,070 --> 00:01:25,229
I'm not going to explain them just going

00:01:24,330 --> 00:01:28,860
to dive right into some of these

00:01:25,229 --> 00:01:30,930
concepts if you want to know more you

00:01:28,860 --> 00:01:33,450
can watch my talk from two years ago

00:01:30,930 --> 00:01:35,430
Python pythons infamous Gil where I

00:01:33,450 --> 00:01:37,079
explained the Gil itself and then last

00:01:35,430 --> 00:01:39,210
year's talk where I kinda got started

00:01:37,079 --> 00:01:43,590
they colectomy removing OOP typo

00:01:39,210 --> 00:01:45,390
removing Python skill so the Gil the

00:01:43,590 --> 00:01:48,600
goal of the colectomy is a Gil of the

00:01:45,390 --> 00:01:50,070
colectomy I want to run existing

00:01:48,600 --> 00:01:51,420
multi-threaded Python program so a

00:01:50,070 --> 00:01:53,579
Python program you could write today

00:01:51,420 --> 00:01:55,619
using the threading module I want to run

00:01:53,579 --> 00:01:58,320
it on multiple cores simultaneously I

00:01:55,619 --> 00:01:59,939
wanted to run it with as little C I want

00:01:58,320 --> 00:02:02,490
to implement this with this little C API

00:01:59,939 --> 00:02:04,469
breakage as possible it's impossible to

00:02:02,490 --> 00:02:05,670
not break the C API on there some

00:02:04,469 --> 00:02:08,489
guarantees the Gil gives you that I

00:02:05,670 --> 00:02:10,739
cannot guarantee anymore but with this

00:02:08,489 --> 00:02:12,780
little as breakage as possible and I

00:02:10,739 --> 00:02:14,110
want to run it faster than C Python does

00:02:12,780 --> 00:02:16,720
with a Gil

00:02:14,110 --> 00:02:18,190
by wall time so this is if you had a

00:02:16,720 --> 00:02:19,810
stopwatch and you started your program

00:02:18,190 --> 00:02:22,090
running when it finishes you hit it

00:02:19,810 --> 00:02:23,560
again if the program ran faster then I

00:02:22,090 --> 00:02:28,540
will declare the Galacta me a success

00:02:23,560 --> 00:02:30,550
which it has never done the approach

00:02:28,540 --> 00:02:33,340
that I'm taking and again this is this

00:02:30,550 --> 00:02:35,680
was most of the talk last year Python

00:02:33,340 --> 00:02:37,210
uses reference counting for tracking the

00:02:35,680 --> 00:02:38,860
lifetimes of objects and I switch that

00:02:37,210 --> 00:02:40,690
to atomic inker and decker that's

00:02:38,860 --> 00:02:43,960
something that your Intel CPU does for

00:02:40,690 --> 00:02:46,750
you where it will increment or decrement

00:02:43,960 --> 00:02:47,980
a number stored in memory in an atomic

00:02:46,750 --> 00:02:49,840
way such that there are no race

00:02:47,980 --> 00:02:50,890
conditions you're guaranteed that after

00:02:49,840 --> 00:02:52,900
you're done the number has been

00:02:50,890 --> 00:02:56,170
incremented by one and it was a done in

00:02:52,900 --> 00:02:57,820
a safe manner I used a bunch

00:02:56,170 --> 00:03:00,160
I added locks to all the internal data

00:02:57,820 --> 00:03:02,740
structures inside of Python objects that

00:03:00,160 --> 00:03:04,540
are mutable like Dix and lists so that

00:03:02,740 --> 00:03:07,270
those operations are safe if you append

00:03:04,540 --> 00:03:07,720
to a list or you add a set an item I

00:03:07,270 --> 00:03:09,130
dick

00:03:07,720 --> 00:03:11,200
that has to be an atomic operation it

00:03:09,130 --> 00:03:13,120
has to be safe and so those items those

00:03:11,200 --> 00:03:15,220
objects lock themselves internally I

00:03:13,120 --> 00:03:16,660
also added a bunch of locks around a

00:03:15,220 --> 00:03:18,850
bunch of internal C data structures to

00:03:16,660 --> 00:03:21,280
the users inside of C Python like free

00:03:18,850 --> 00:03:23,590
state but there's two in pretty fewer I

00:03:21,280 --> 00:03:25,720
want to call out automatic which is what

00:03:23,590 --> 00:03:27,820
we call the small block alligator this

00:03:25,720 --> 00:03:30,130
is used for memory allocation for small

00:03:27,820 --> 00:03:30,940
objects which is like under 256 bytes or

00:03:30,130 --> 00:03:32,800
something I don't remember what the

00:03:30,940 --> 00:03:34,690
cutoff point is but this is used for

00:03:32,800 --> 00:03:36,490
most of the objects that are allocated

00:03:34,690 --> 00:03:38,200
inside of C Python and this is very flat

00:03:36,490 --> 00:03:40,870
very finely tuned and it's super fast

00:03:38,200 --> 00:03:42,640
and C Python relies on it being fast and

00:03:40,870 --> 00:03:45,240
adding locking to that in order to make

00:03:42,640 --> 00:03:47,110
it safe has slowed it down a great deal

00:03:45,240 --> 00:03:47,950
also there are a bunch of free list

00:03:47,110 --> 00:03:49,840
inside of C Python

00:03:47,950 --> 00:03:53,500
it's very handy if you're using a bunch

00:03:49,840 --> 00:03:57,340
of say integers or frame objects if you

00:03:53,500 --> 00:03:58,900
if you allocate a fresh one every time

00:03:57,340 --> 00:04:00,310
that's a little slower than just say oh

00:03:58,900 --> 00:04:01,810
the last one that I use I'm gonna put it

00:04:00,310 --> 00:04:03,820
on the list and then reuse it next time

00:04:01,810 --> 00:04:05,110
I need a free list from object or an

00:04:03,820 --> 00:04:06,910
integer or something so there are a

00:04:05,110 --> 00:04:08,350
bunch of free lists internally of Python

00:04:06,910 --> 00:04:10,300
objects that get really used constantly

00:04:08,350 --> 00:04:11,950
and I of course had to put locks around

00:04:10,300 --> 00:04:14,770
those data structures or make them per

00:04:11,950 --> 00:04:17,080
thread I also disabled the garbage

00:04:14,770 --> 00:04:18,670
collector entirely I'm just not ready to

00:04:17,080 --> 00:04:21,040
deal with the garbage collection under

00:04:18,670 --> 00:04:22,900
the colectomy there there's a lot of

00:04:21,040 --> 00:04:25,180
research there are absolutely thread

00:04:22,900 --> 00:04:26,040
safe multi-threaded friendly garbage

00:04:25,180 --> 00:04:27,500
collection algorithms

00:04:26,040 --> 00:04:29,610
that's going to be a lot of work and

00:04:27,500 --> 00:04:31,170
that's not the thing that interests me

00:04:29,610 --> 00:04:32,700
what interests me is getting Python to

00:04:31,170 --> 00:04:36,210
be fast enough that this is useful for

00:04:32,700 --> 00:04:39,330
somebody ever so my general approach is

00:04:36,210 --> 00:04:42,000
I got it working and now I figure out

00:04:39,330 --> 00:04:43,620
what the slowest thing is and I run

00:04:42,000 --> 00:04:45,330
another a profiler I come up with

00:04:43,620 --> 00:04:46,680
thought experiments and I experiment I

00:04:45,330 --> 00:04:48,600
try something I see if I can make it go

00:04:46,680 --> 00:04:50,460
faster if I may go faster than I keep it

00:04:48,600 --> 00:04:51,900
then it doesn't go faster than I I don't

00:04:50,460 --> 00:04:53,340
throw it away I may like put it on the

00:04:51,900 --> 00:04:54,960
back burner and try it again later

00:04:53,340 --> 00:04:56,310
because sometimes you turn a corner and

00:04:54,960 --> 00:04:58,920
now this technology is going to work

00:04:56,310 --> 00:05:01,620
again just to give you an idea of how

00:04:58,920 --> 00:05:03,210
crappy this project is my official

00:05:01,620 --> 00:05:05,640
benchmark that this is literally all

00:05:03,210 --> 00:05:07,740
they ever run under the colectomy is a

00:05:05,640 --> 00:05:09,810
really bad fibonacci number generator

00:05:07,740 --> 00:05:12,420
it's a recursive Fibonacci so this is

00:05:09,810 --> 00:05:14,610
exercising a an if-statement it's

00:05:12,420 --> 00:05:16,230
exercising some math it's exercising

00:05:14,610 --> 00:05:17,730
recursive function calls and of course

00:05:16,230 --> 00:05:20,280
bytecode and a bunch of internal stuff

00:05:17,730 --> 00:05:22,260
inside of the Python engine but this is

00:05:20,280 --> 00:05:23,850
all I ever run so I'm running on this on

00:05:22,260 --> 00:05:27,630
multiple cores simultaneously inside of

00:05:23,850 --> 00:05:30,090
C Python so an overview of what's

00:05:27,630 --> 00:05:32,460
happened since last year when I gave the

00:05:30,090 --> 00:05:35,070
colectomy talk we start with what I'm

00:05:32,460 --> 00:05:38,340
going to call I'm Nikole last June's

00:05:35,070 --> 00:05:40,350
version of the Galactica the atomic

00:05:38,340 --> 00:05:41,820
version for using atomic ingrid decker i

00:05:40,350 --> 00:05:43,350
switch to something called buffered

00:05:41,820 --> 00:05:46,530
reference counts which was done by about

00:05:43,350 --> 00:05:48,540
october and then i did a bunch of work

00:05:46,530 --> 00:05:51,600
on off malloc and that was done in about

00:05:48,540 --> 00:05:53,790
April and then just this month I did

00:05:51,600 --> 00:05:55,590
some work that I'm calling no TLS TLS

00:05:53,790 --> 00:05:57,870
when I say TLS what I mean is

00:05:55,590 --> 00:05:59,430
thread-local storage this is data that

00:05:57,870 --> 00:06:01,050
you can store per thread so that each

00:05:59,430 --> 00:06:04,170
thread has its own version of something

00:06:01,050 --> 00:06:05,430
you need that in order to you can store

00:06:04,170 --> 00:06:06,630
something there and no other thread is

00:06:05,430 --> 00:06:08,150
going to examine it and so you don't

00:06:06,630 --> 00:06:10,170
have to lock it in order to talk to it

00:06:08,150 --> 00:06:12,840
so I'm going to go through each of these

00:06:10,170 --> 00:06:15,030
items and basically what it is and I'll

00:06:12,840 --> 00:06:16,470
show you how much it got faster but I

00:06:15,030 --> 00:06:18,090
want to talk for just a moment about how

00:06:16,470 --> 00:06:20,280
benchmarking is impossible on Marvin

00:06:18,090 --> 00:06:24,240
computers as Victor talked about in his

00:06:20,280 --> 00:06:27,090
talk this morning modern CPUs like an

00:06:24,240 --> 00:06:28,290
Intel CPU like a Xeon has a speedstep

00:06:27,090 --> 00:06:30,870
technology where it's constantly

00:06:28,290 --> 00:06:33,690
adjusting the run the speed of the cores

00:06:30,870 --> 00:06:35,940
inside of your CPU and so this I have a

00:06:33,690 --> 00:06:36,990
computer that literally has like 50 6

00:06:35,940 --> 00:06:38,370
cores it's enormous

00:06:36,990 --> 00:06:41,310
server

00:06:38,370 --> 00:06:42,870
and this is some of the cores at a

00:06:41,310 --> 00:06:44,910
particular moment in time how fast

00:06:42,870 --> 00:06:46,229
they're running so you can see I was

00:06:44,910 --> 00:06:47,520
running a benchmark at the time so the

00:06:46,229 --> 00:06:48,510
ones in the lower right of the fastest

00:06:47,520 --> 00:06:50,220
ones they're running at thirty one

00:06:48,510 --> 00:06:52,410
hundred megahertz the slowest ones are

00:06:50,220 --> 00:06:53,160
running at twelve hundred megahertz you

00:06:52,410 --> 00:06:54,810
really don't know

00:06:53,160 --> 00:06:56,160
from moment to moment how fast your CPU

00:06:54,810 --> 00:06:57,389
core is running and so it makes it

00:06:56,160 --> 00:06:59,610
almost impossible to do meaningful

00:06:57,389 --> 00:07:01,110
benchmarks in any meaningful way so this

00:06:59,610 --> 00:07:02,760
is just to give you an idea like already

00:07:01,110 --> 00:07:04,710
my benchmarking is crappy there even

00:07:02,760 --> 00:07:06,270
crappier because it is I haven't figured

00:07:04,710 --> 00:07:07,440
this one out yet a victor says oh yeah

00:07:06,270 --> 00:07:09,660
there's way you can turn it on for Linux

00:07:07,440 --> 00:07:11,940
we'll figure it out but that's just a

00:07:09,660 --> 00:07:13,139
pervy so to give you the sense of let's

00:07:11,940 --> 00:07:14,820
look at the benchmarks from a sort of a

00:07:13,139 --> 00:07:17,510
10,000 foot view let's not get concerned

00:07:14,820 --> 00:07:21,030
about like 5 percent this way or another

00:07:17,510 --> 00:07:21,510
so this is a graph of the speed of the

00:07:21,030 --> 00:07:24,330
galectins

00:07:21,510 --> 00:07:25,770
versus stock cpython and again this is

00:07:24,330 --> 00:07:27,000
I'm talking about different eras so I'm

00:07:25,770 --> 00:07:30,000
going to have update the graph every

00:07:27,000 --> 00:07:32,610
time I do a new thing so the red line at

00:07:30,000 --> 00:07:34,139
the bottom is a stock cpython

00:07:32,610 --> 00:07:35,669
which was the base revision that i

00:07:34,139 --> 00:07:38,490
started to collect me against which was

00:07:35,669 --> 00:07:40,770
last February it was trunk so it's what

00:07:38,490 --> 00:07:43,530
became 3 6 but oh there's a lot of work

00:07:40,770 --> 00:07:46,860
put in the 3 6 after I branched and then

00:07:43,530 --> 00:07:49,830
the blue line is the colectomy the

00:07:46,860 --> 00:07:51,479
bottom the x-axis is the number of cores

00:07:49,830 --> 00:07:53,039
I'm using because it's the number of

00:07:51,479 --> 00:07:55,020
threads that I'm running so cpython

00:07:53,039 --> 00:07:56,580
forces only is running multiple threads

00:07:55,020 --> 00:07:57,780
but it's only ever using one core at a

00:07:56,580 --> 00:08:00,030
time

00:07:57,780 --> 00:08:02,639
I really should relate with that threads

00:08:00,030 --> 00:08:04,320
not cores and then the the y-axis of

00:08:02,639 --> 00:08:07,260
course is the number of seconds that it

00:08:04,320 --> 00:08:11,970
took so just to drive home how bad this

00:08:07,260 --> 00:08:14,370
is on seven cores cpython runs in 4.4

00:08:11,970 --> 00:08:17,930
seconds and the Galecki is running in 80

00:08:14,370 --> 00:08:21,720
3.0 seconds it is 18.9 times slower as

00:08:17,930 --> 00:08:23,370
an aside this is why I got to say I

00:08:21,720 --> 00:08:24,419
haven't been terribly gracious like a

00:08:23,370 --> 00:08:25,380
lot of people like to talk to me and

00:08:24,419 --> 00:08:28,260
they say well have you heard about the

00:08:25,380 --> 00:08:30,210
super fast locking mechanism that's not

00:08:28,260 --> 00:08:32,550
where the war is going to be won the

00:08:30,210 --> 00:08:34,890
difference between 19 times slower is

00:08:32,550 --> 00:08:36,270
not oh you should use a slightly faster

00:08:34,890 --> 00:08:38,250
locking mechanism there are major

00:08:36,270 --> 00:08:39,360
battles to be won here once I get it

00:08:38,250 --> 00:08:41,400
down to the point where it's kind of

00:08:39,360 --> 00:08:42,839
within shooting range of cpython

00:08:41,400 --> 00:08:44,459
then I might be interested in more

00:08:42,839 --> 00:08:46,110
efficient locking mechanisms right now

00:08:44,459 --> 00:08:47,370
there are more fundamental structural

00:08:46,110 --> 00:08:48,810
problems inside the Galacta me

00:08:47,370 --> 00:08:50,760
the enormous nails that need to be

00:08:48,810 --> 00:08:52,050
hammered down and that's where my head

00:08:50,760 --> 00:08:54,089
is at so unless you're spend

00:08:52,050 --> 00:08:56,370
time doing analysis on the Galactic mean

00:08:54,089 --> 00:08:57,990
saying I found our super slow thing did

00:08:56,370 --> 00:08:59,190
you know about this Larry here's a way

00:08:57,990 --> 00:09:01,649
that you can make it faster that would

00:08:59,190 --> 00:09:03,480
be super interesting oh this is the way

00:09:01,649 --> 00:09:06,899
that Grand Central does logging not so

00:09:03,480 --> 00:09:11,399
interested so let's start with where we

00:09:06,899 --> 00:09:15,149
were in in the in last June like I

00:09:11,399 --> 00:09:17,250
mentioned cpython uses in creditor for

00:09:15,149 --> 00:09:18,959
reference counting and I was using

00:09:17,250 --> 00:09:20,850
atomic sinker and Dekker just to get the

00:09:18,959 --> 00:09:23,339
Galacta me working but this was 30

00:09:20,850 --> 00:09:24,839
percent slower off the top just using

00:09:23,339 --> 00:09:27,870
two threads and they get slower and

00:09:24,839 --> 00:09:30,810
slower each thread that you add is more

00:09:27,870 --> 00:09:32,100
than is more overhead than last I think

00:09:30,810 --> 00:09:33,660
what's going on here and I don't know

00:09:32,100 --> 00:09:35,310
for certain but what I believe is going

00:09:33,660 --> 00:09:36,959
on here is that the the course need to

00:09:35,310 --> 00:09:38,370
talk to each other there's an internal

00:09:36,959 --> 00:09:39,779
bus that they use to tell each other hey

00:09:38,370 --> 00:09:41,010
I'm doing an atomic increment on this

00:09:39,779 --> 00:09:41,370
thing you need to not look at it right

00:09:41,010 --> 00:09:42,600
now

00:09:41,370 --> 00:09:44,040
there's some internal bus that they're

00:09:42,600 --> 00:09:48,120
using to communicate with each other and

00:09:44,040 --> 00:09:49,920
the more ly automatics cubing the more

00:09:48,120 --> 00:09:52,380
atomic anchor and Decker that I'm doing

00:09:49,920 --> 00:09:53,820
the more traffic there is on that bus

00:09:52,380 --> 00:09:56,459
until we're starting to saturate the bus

00:09:53,820 --> 00:09:59,279
and people are having to wait so getting

00:09:56,459 --> 00:10:03,000
that work not to be atomic but would be

00:09:59,279 --> 00:10:04,020
a major win it turns out so first of all

00:10:03,000 --> 00:10:05,070
I spend a lot of time thinking about

00:10:04,020 --> 00:10:06,839
this problem cuz I knew this was my

00:10:05,070 --> 00:10:08,550
hardest problem to solve I actually came

00:10:06,839 --> 00:10:10,829
up with my own technique to solve it and

00:10:08,550 --> 00:10:12,240
then I felt terrible because I was like

00:10:10,829 --> 00:10:14,279
nobody invents anything new in computer

00:10:12,240 --> 00:10:15,420
science everything's been done you don't

00:10:14,279 --> 00:10:16,560
want to invent something new if you do

00:10:15,420 --> 00:10:18,120
that you've probably done something

00:10:16,560 --> 00:10:19,079
wrong because some all the good ideas

00:10:18,120 --> 00:10:20,370
have already been taken

00:10:19,079 --> 00:10:22,140
particularly in multi-core

00:10:20,370 --> 00:10:23,730
multi-threading that's all the work was

00:10:22,140 --> 00:10:25,380
done with million years ago so it turns

00:10:23,730 --> 00:10:26,910
out there's this book called the garbage

00:10:25,380 --> 00:10:28,320
collection handbook the second edition

00:10:26,910 --> 00:10:31,440
just updated in the last couple of years

00:10:28,320 --> 00:10:32,970
and they have it's mostly about garbage

00:10:31,440 --> 00:10:34,170
collection well what about technically

00:10:32,970 --> 00:10:36,089
it's called tracing garbage collection

00:10:34,170 --> 00:10:37,470
but reference counting also counts as

00:10:36,089 --> 00:10:39,060
garbage collection so they have a

00:10:37,470 --> 00:10:40,949
chapter in the beginning about reference

00:10:39,060 --> 00:10:43,230
counting and then turns out they have a

00:10:40,949 --> 00:10:45,449
chapter at the end about reference

00:10:43,230 --> 00:10:47,850
counting in multi-threaded programs and

00:10:45,449 --> 00:10:50,790
there are two things in this rather slim

00:10:47,850 --> 00:10:53,670
chapter one of them was exactly the

00:10:50,790 --> 00:10:54,779
thing that I invented on my own the

00:10:53,670 --> 00:10:56,130
other one is something that's very

00:10:54,779 --> 00:10:58,079
complicated that I don't think we can

00:10:56,130 --> 00:10:59,579
use called the recycler to be honest I

00:10:58,079 --> 00:11:01,199
don't understand how the recycler works

00:10:59,579 --> 00:11:03,810
internally I got to sit down and just

00:11:01,199 --> 00:11:05,250
read this book but I don't think we can

00:11:03,810 --> 00:11:05,680
use it I think it requires like compile

00:11:05,250 --> 00:11:08,080
time

00:11:05,680 --> 00:11:09,580
court but let's talk about this concept

00:11:08,080 --> 00:11:11,649
what the the technique is called

00:11:09,580 --> 00:11:13,360
buffered reference counting so let's

00:11:11,649 --> 00:11:15,460
examine our problem we have this object

00:11:13,360 --> 00:11:16,990
o at the top we have three threads that

00:11:15,460 --> 00:11:18,010
want to talk to object o and every time

00:11:16,990 --> 00:11:19,120
they want to talk to it they want to

00:11:18,010 --> 00:11:20,140
increment the reference count and when

00:11:19,120 --> 00:11:21,790
they're done talking to it they want to

00:11:20,140 --> 00:11:23,680
decrement the reference count so they're

00:11:21,790 --> 00:11:25,390
all trying to talk to the same area of

00:11:23,680 --> 00:11:27,040
memory and that's why I've used atomic

00:11:25,390 --> 00:11:28,870
anchoring decker we'd like to make it

00:11:27,040 --> 00:11:30,730
cheaper the way you make it cheaper is

00:11:28,870 --> 00:11:34,060
let's have only one person talking to

00:11:30,730 --> 00:11:35,950
the reference count at a time ever in a

00:11:34,060 --> 00:11:37,480
guaranteed way and then he doesn't have

00:11:35,950 --> 00:11:40,660
to use the atomic anchor or a Decker

00:11:37,480 --> 00:11:42,670
how do you do that well let's add a

00:11:40,660 --> 00:11:44,620
separate thread we're going to call the

00:11:42,670 --> 00:11:46,120
reference count committing log a

00:11:44,620 --> 00:11:47,709
committing thread we're going to make a

00:11:46,120 --> 00:11:49,240
big log what's just wave our hands to

00:11:47,709 --> 00:11:50,709
say this is a memory is this as big as

00:11:49,240 --> 00:11:51,730
we'll ever need it to be it's a

00:11:50,709 --> 00:11:52,930
reference count log it's like a

00:11:51,730 --> 00:11:55,120
transaction log for reference count

00:11:52,930 --> 00:11:56,740
changes so now the three threads talk to

00:11:55,120 --> 00:11:58,149
that instead every time they want to

00:11:56,740 --> 00:11:59,740
increment the reference count on o they

00:11:58,149 --> 00:12:01,180
write down o add one to the reference

00:11:59,740 --> 00:12:02,500
count every time they want to decrement

00:12:01,180 --> 00:12:04,450
they say o minus one to the reference

00:12:02,500 --> 00:12:05,920
count and then the separate thread sits

00:12:04,450 --> 00:12:07,209
there spinning watching the log and

00:12:05,920 --> 00:12:09,010
whenever there's work to do it goes to

00:12:07,209 --> 00:12:11,380
heaven does it since the reference count

00:12:09,010 --> 00:12:12,760
committing law thread the only thread

00:12:11,380 --> 00:12:14,080
that ever touches reference counts he

00:12:12,760 --> 00:12:15,610
doesn't have to use a tonic during

00:12:14,080 --> 00:12:17,350
Becker he can just modify the memory

00:12:15,610 --> 00:12:18,490
directly as a matter of fact it's a good

00:12:17,350 --> 00:12:20,260
idea if he's the only thread to ever

00:12:18,490 --> 00:12:22,029
looks at reference counts because one of

00:12:20,260 --> 00:12:23,320
the problems of this technique is going

00:12:22,029 --> 00:12:24,850
to be now reference counts don't happen

00:12:23,320 --> 00:12:25,839
in real time now reference counts you

00:12:24,850 --> 00:12:27,520
don't know whether they're accurate or

00:12:25,839 --> 00:12:28,870
not there could be reference count

00:12:27,520 --> 00:12:31,120
changes we're waiting in the logs that

00:12:28,870 --> 00:12:32,110
have been committed yet so this is going

00:12:31,120 --> 00:12:34,450
to cause some problems we'll talk about

00:12:32,110 --> 00:12:36,339
in a minute well let's move on this

00:12:34,450 --> 00:12:37,810
solves the problem of atomic occur and

00:12:36,339 --> 00:12:39,880
Decker but all we've really done is

00:12:37,810 --> 00:12:41,350
change it so that now we have contention

00:12:39,880 --> 00:12:43,720
around this ref count log where that has

00:12:41,350 --> 00:12:46,420
to be locked and unlocked for thread but

00:12:43,720 --> 00:12:48,940
we can solve that let's have one rest

00:12:46,420 --> 00:12:50,770
count log per thread so now each thread

00:12:48,940 --> 00:12:52,720
writes this reference count law changes

00:12:50,770 --> 00:12:54,490
to its own local log now there's no

00:12:52,720 --> 00:12:55,779
contingent over the logs they just need

00:12:54,490 --> 00:12:58,060
to lock a little bit between the commit

00:12:55,779 --> 00:12:59,500
log the committing thread and the

00:12:58,060 --> 00:13:00,760
individual threads but you just take the

00:12:59,500 --> 00:13:03,130
buffer and pass it off that's no big

00:13:00,760 --> 00:13:04,630
deal this solves all the contention

00:13:03,130 --> 00:13:08,050
problems but now we have an ordering

00:13:04,630 --> 00:13:10,630
problem so let's walk through that let's

00:13:08,050 --> 00:13:11,860
say that we have three threads or really

00:13:10,630 --> 00:13:13,660
only need two threads for this example

00:13:11,860 --> 00:13:16,180
and let's say for the sake of argument

00:13:13,660 --> 00:13:17,950
we have a list that's capital L and it

00:13:16,180 --> 00:13:18,980
has an object inside of it world I'm the

00:13:17,950 --> 00:13:22,940
collet Oh

00:13:18,980 --> 00:13:24,770
it's unnamed in this example and list L

00:13:22,940 --> 00:13:26,030
has the only reference to object oh

00:13:24,770 --> 00:13:28,250
that's the only reference it exists so

00:13:26,030 --> 00:13:29,570
always reference count is one and all of

00:13:28,250 --> 00:13:31,070
those changes happen a million years ago

00:13:29,570 --> 00:13:32,450
it's all the dust is all settled so it's

00:13:31,070 --> 00:13:34,700
nice and stable right now so currently

00:13:32,450 --> 00:13:36,860
Oh has a reference kind of one and that

00:13:34,700 --> 00:13:39,080
reference is being held by pal thread

00:13:36,860 --> 00:13:41,750
one comes along and says for XML print X

00:13:39,080 --> 00:13:44,240
that does an increment and decrement on

00:13:41,750 --> 00:13:45,950
object oh and then later thread zero

00:13:44,240 --> 00:13:48,560
comes along says l dot clear blows away

00:13:45,950 --> 00:13:50,570
everything inside of L that says o minus

00:13:48,560 --> 00:13:52,670
one that drops the reference to l to

00:13:50,570 --> 00:13:54,740
object o so that's going to kind of look

00:13:52,670 --> 00:13:55,850
like this the reference count log for

00:13:54,740 --> 00:13:57,830
thread one we're gonna have an O plus

00:13:55,850 --> 00:13:59,690
100 minus one and then later in

00:13:57,830 --> 00:14:01,280
reference count logs words thread zero

00:13:59,690 --> 00:14:02,900
we're going to have an O minus one the

00:14:01,280 --> 00:14:04,640
problem is what if we commit the

00:14:02,900 --> 00:14:05,960
reference count log four zero before we

00:14:04,640 --> 00:14:07,940
commit the reference count log for one

00:14:05,960 --> 00:14:10,250
we're going to drop the last reference

00:14:07,940 --> 00:14:12,920
to object o the object will be destroyed

00:14:10,250 --> 00:14:14,360
and then we're going to later commit the

00:14:12,920 --> 00:14:16,610
reference count region and thread one

00:14:14,360 --> 00:14:18,200
and we're going to say o a plus one and

00:14:16,610 --> 00:14:19,550
now your program is no longer correct

00:14:18,200 --> 00:14:22,490
because you're touching an object has

00:14:19,550 --> 00:14:24,200
been destroyed now you might say well

00:14:22,490 --> 00:14:25,880
just do those in the opposite order the

00:14:24,200 --> 00:14:26,960
first thing I would say to that is how

00:14:25,880 --> 00:14:28,490
do you know you were supposed to do them

00:14:26,960 --> 00:14:29,810
in the opposite order and the second

00:14:28,490 --> 00:14:33,020
thing I would say is what if I do this

00:14:29,810 --> 00:14:35,690
to you now we have two lists L L and L 2

00:14:33,020 --> 00:14:38,630
we have two objects o and O two we

00:14:35,690 --> 00:14:41,660
iterate over the list in one thread each

00:14:38,630 --> 00:14:44,480
and then we clear the other list there

00:14:41,660 --> 00:14:46,880
is no order that you can do process

00:14:44,480 --> 00:14:50,000
these logs in where your program will be

00:14:46,880 --> 00:14:53,210
correct now your program is inevitably

00:14:50,000 --> 00:14:55,400
incorrect so how do we solve that

00:14:53,210 --> 00:14:57,020
problem one way might be to write down a

00:14:55,400 --> 00:14:59,270
time stamp every time we write down a

00:14:57,020 --> 00:15:02,300
reference count change in the log that's

00:14:59,270 --> 00:15:05,750
expensive and it may not even be correct

00:15:02,300 --> 00:15:07,700
there's been bugs in the past with what

00:15:05,750 --> 00:15:11,690
I would use the are DTSC instruction on

00:15:07,700 --> 00:15:13,160
intel x86 where that gives you a time

00:15:11,690 --> 00:15:14,660
stamp counter that's internal the cpu

00:15:13,160 --> 00:15:16,520
that's very high precision which is what

00:15:14,660 --> 00:15:18,380
I would need for this but if you have

00:15:16,520 --> 00:15:20,540
actually two physical CPUs and your

00:15:18,380 --> 00:15:22,160
computer like I have sometimes they can

00:15:20,540 --> 00:15:24,350
drift so that the time stamp counters

00:15:22,160 --> 00:15:25,610
will be different and that would be

00:15:24,350 --> 00:15:27,350
problematic that would mean we would

00:15:25,610 --> 00:15:28,610
commit these things in out of order so

00:15:27,350 --> 00:15:30,810
it would also be it would be expensive

00:15:28,610 --> 00:15:33,360
and unsafe

00:15:30,810 --> 00:15:35,580
we can solve this problem on that it

00:15:33,360 --> 00:15:37,140
takes a stepping back and re-examining

00:15:35,580 --> 00:15:38,640
the problem itself because it turns out

00:15:37,140 --> 00:15:42,240
we don't actually need super-strong

00:15:38,640 --> 00:15:43,830
ordering of a reference count changes we

00:15:42,240 --> 00:15:45,210
can do something much weaker that is

00:15:43,830 --> 00:15:47,040
much cheaper and we can achieve that

00:15:45,210 --> 00:15:48,690
very easily so let's start with this

00:15:47,040 --> 00:15:51,390
observation let's talk about two objects

00:15:48,690 --> 00:15:53,400
our tubing I mean let me get this right

00:15:51,390 --> 00:15:55,980
let's talk about two reference count

00:15:53,400 --> 00:15:57,690
change events these are two events that

00:15:55,980 --> 00:15:59,160
we're going to write the blog though I'm

00:15:57,690 --> 00:16:01,260
going to talk about reference count

00:15:59,160 --> 00:16:02,850
change one and two and one might be an

00:16:01,260 --> 00:16:05,100
inker or a Decker and two might be an

00:16:02,850 --> 00:16:07,620
inker or Decker and the question is can

00:16:05,100 --> 00:16:09,810
I swap them in time is that harmless and

00:16:07,620 --> 00:16:11,610
it turns out three times out of four the

00:16:09,810 --> 00:16:13,680
answer is yes if you have an inker

00:16:11,610 --> 00:16:15,210
followed by an inker you can swap those

00:16:13,680 --> 00:16:17,010
that's harmless if you have a Decker

00:16:15,210 --> 00:16:18,780
fall owed by a Decker you can swap those

00:16:17,010 --> 00:16:20,730
that's harmless if you have a Decker

00:16:18,780 --> 00:16:22,080
followed by an inker you can swap that

00:16:20,730 --> 00:16:23,640
that's harmless because they can't be

00:16:22,080 --> 00:16:25,440
talking about the same object or if they

00:16:23,640 --> 00:16:27,210
are the object is obviously still alive

00:16:25,440 --> 00:16:29,190
because we did a Decker we assume the

00:16:27,210 --> 00:16:30,390
program is safe if we did a Decker and

00:16:29,190 --> 00:16:32,640
when we did an inker on the same object

00:16:30,390 --> 00:16:34,620
I assume that that was safe because the

00:16:32,640 --> 00:16:35,880
object is still alive the only one you

00:16:34,620 --> 00:16:37,590
have to make sure that you keep in the

00:16:35,880 --> 00:16:39,030
same order is if you have an inker

00:16:37,590 --> 00:16:40,530
followed by a Decker if those are tough

00:16:39,030 --> 00:16:42,030
without the same object and there was

00:16:40,530 --> 00:16:43,680
only one reference to the object and you

00:16:42,030 --> 00:16:44,910
did that anchor that keeps it alive when

00:16:43,680 --> 00:16:47,970
you do a decorator medially afterwards

00:16:44,910 --> 00:16:49,650
you cannot swap those but all this is

00:16:47,970 --> 00:16:52,770
telling us is we need to make sure that

00:16:49,650 --> 00:16:55,320
any Decker that happens after an inker

00:16:52,770 --> 00:16:57,180
in time has to happen afterwards when we

00:16:55,320 --> 00:17:00,360
commit it and that's a lot cheaper to

00:16:57,180 --> 00:17:03,250
achieve so here's what we do we have two

00:17:00,360 --> 00:17:06,789
separate logs per box for threat

00:17:03,250 --> 00:17:08,589
one for anchors one for Decker's and we

00:17:06,789 --> 00:17:10,630
all we need to do is cue them in such a

00:17:08,589 --> 00:17:13,150
way that any time we process a Decker

00:17:10,630 --> 00:17:15,130
log we ensure that all the incres that

00:17:13,150 --> 00:17:18,280
could have possibly happened before the

00:17:15,130 --> 00:17:20,980
time are committed first I got this

00:17:18,280 --> 00:17:22,870
working and then I iterated on the the

00:17:20,980 --> 00:17:24,730
algorithm and now I have a very safe

00:17:22,870 --> 00:17:26,860
queuing algorithm that is in constant

00:17:24,730 --> 00:17:31,360
time for everything so this is working

00:17:26,860 --> 00:17:33,070
really well as an aside right here this

00:17:31,360 --> 00:17:35,500
was an indispensable tool and working on

00:17:33,070 --> 00:17:38,020
the Galactica this is called undo DB

00:17:35,500 --> 00:17:40,450
that's undo debugger it is a reversible

00:17:38,020 --> 00:17:42,700
debugger where you can it behaves

00:17:40,450 --> 00:17:44,260
exactly like gdb and what you do is you

00:17:42,700 --> 00:17:45,400
set a breakpoint and you examine data

00:17:44,260 --> 00:17:47,559
and you're like how the hell did we get

00:17:45,400 --> 00:17:48,820
in this state and so you set a memory

00:17:47,559 --> 00:17:51,100
watch point and then you run your

00:17:48,820 --> 00:17:52,750
program backwards and you see when that

00:17:51,100 --> 00:17:54,159
triggers it's like oh that memory

00:17:52,750 --> 00:17:54,640
changed in this way well how did that

00:17:54,159 --> 00:17:56,049
get there

00:17:54,640 --> 00:17:57,429
and then you set another breakpoint or a

00:17:56,049 --> 00:17:58,770
memory watch point or something you run

00:17:57,429 --> 00:18:00,490
the program backwards some more

00:17:58,770 --> 00:18:02,020
indispensable for solving these problems

00:18:00,490 --> 00:18:03,700
because you can get in these situations

00:18:02,020 --> 00:18:05,080
where it's like I have no idea how the

00:18:03,700 --> 00:18:07,000
program got in the state now you can run

00:18:05,080 --> 00:18:08,740
it backwards and find out so I've been I

00:18:07,000 --> 00:18:11,950
used undo DB a lot in the development of

00:18:08,740 --> 00:18:13,630
the reference count manager but let's

00:18:11,950 --> 00:18:16,990
talk about how what has happened as a

00:18:13,630 --> 00:18:18,880
result so this is the old macro in C for

00:18:16,990 --> 00:18:20,500
performing an in craft this is what

00:18:18,880 --> 00:18:22,240
chains adds one to the reference counts

00:18:20,500 --> 00:18:23,860
very simple straightforward we take the

00:18:22,240 --> 00:18:26,320
object we find the reference count

00:18:23,860 --> 00:18:29,110
inside and we add one it's more

00:18:26,320 --> 00:18:31,510
complicated down so the first thing we

00:18:29,110 --> 00:18:33,130
do look at the bottom I say PI in craft

00:18:31,510 --> 00:18:35,679
at sync ref one in craft one what it

00:18:33,130 --> 00:18:37,929
does is it goes to thread-local storage

00:18:35,679 --> 00:18:38,860
and pulls out this ref log object which

00:18:37,929 --> 00:18:41,830
is where we're starting our reference

00:18:38,860 --> 00:18:45,010
counts per thread and it doesn't Inc rep

00:18:41,830 --> 00:18:47,770
2 on the object now so Inc ref - is

00:18:45,010 --> 00:18:49,090
implemented like this where we say is

00:18:47,770 --> 00:18:50,710
there space in the ref blog right now

00:18:49,090 --> 00:18:51,970
for me to write another pointer oh there

00:18:50,710 --> 00:18:54,250
is that I'm going to go ahead and write

00:18:51,970 --> 00:18:56,470
one oh there isn't then I need to rotate

00:18:54,250 --> 00:19:00,010
the logs out get fresh anchor and Decker

00:18:56,470 --> 00:19:02,559
buffers and now I write the log and then

00:19:00,010 --> 00:19:04,480
I have three which is unsafe which just

00:19:02,559 --> 00:19:05,950
writes the thing directly and the reason

00:19:04,480 --> 00:19:09,130
I have three of these is because you can

00:19:05,950 --> 00:19:12,010
use they get progressively faster this

00:19:09,130 --> 00:19:13,330
is the really slow version but I knew

00:19:12,010 --> 00:19:14,980
that it was going to be slow and so I

00:19:13,330 --> 00:19:16,730
have this macro it says PI rest cache

00:19:14,980 --> 00:19:18,770
you put that at the top of a funk

00:19:16,730 --> 00:19:20,870
and now it's cashed attached the ref log

00:19:18,770 --> 00:19:22,610
that's for your thread as a stack

00:19:20,870 --> 00:19:24,110
variable and now you can just refer that

00:19:22,610 --> 00:19:25,520
all the time so now you can change all

00:19:24,110 --> 00:19:27,590
your PI in graphs and pie deck graphs

00:19:25,520 --> 00:19:29,780
into PI Inc rep 2 and PI deck rep - and

00:19:27,590 --> 00:19:31,669
they're just faster for free if you want

00:19:29,780 --> 00:19:33,710
to work a little harder then you can

00:19:31,669 --> 00:19:35,150
sort of pre ensure that there's room in

00:19:33,710 --> 00:19:36,830
the ref log for all the thing you're

00:19:35,150 --> 00:19:38,240
about to do if you're about to do 5 deck

00:19:36,830 --> 00:19:39,679
reps in a row but you don't have to

00:19:38,240 --> 00:19:41,179
check each time as they're spaced you

00:19:39,679 --> 00:19:43,400
can say is there space for five do deck

00:19:41,179 --> 00:19:44,690
wraps and if there is then we just go

00:19:43,400 --> 00:19:47,360
and if there isn't then we do a right to

00:19:44,690 --> 00:19:49,160
rotate right then that's a little

00:19:47,360 --> 00:19:50,990
troublesome just because you can't you

00:19:49,160 --> 00:19:52,010
have to be right there it can't you

00:19:50,990 --> 00:19:53,210
can't recurse into the Python

00:19:52,010 --> 00:19:54,260
interpreter because that's going to do

00:19:53,210 --> 00:19:55,970
its own in grups indecorous

00:19:54,260 --> 00:19:57,620
so you need to make sure that this is

00:19:55,970 --> 00:19:58,940
very tightly coupled but you can

00:19:57,620 --> 00:20:01,220
occasionally use those pining crafts in

00:19:58,940 --> 00:20:02,630
pi vector3 by pre establishing you're

00:20:01,220 --> 00:20:04,100
going to have room in the logs this

00:20:02,630 --> 00:20:05,540
isn't actually it looks like a lot of

00:20:04,100 --> 00:20:06,740
code is actually pretty fast it's really

00:20:05,540 --> 00:20:08,660
not a big deal like these temporary

00:20:06,740 --> 00:20:10,760
rules go away all the pirate pad is

00:20:08,660 --> 00:20:12,650
really doing is doing a derrick view

00:20:10,760 --> 00:20:16,520
referencing a pointer storing to it and

00:20:12,650 --> 00:20:19,070
incrementing so the other thing that I

00:20:16,520 --> 00:20:20,870
caught that this resulted in the other

00:20:19,070 --> 00:20:22,280
problem with this cause apart from

00:20:20,870 --> 00:20:24,500
making incorrect and Decorah follow more

00:20:22,280 --> 00:20:26,630
complicated is that there are a couple

00:20:24,500 --> 00:20:28,370
of places there's one place I know of

00:20:26,630 --> 00:20:30,169
for certain we really need real-time

00:20:28,370 --> 00:20:32,419
reference counts on an object and that

00:20:30,169 --> 00:20:34,910
is we graphs the way that a week rep is

00:20:32,419 --> 00:20:37,100
implemented I'll remind you that you can

00:20:34,910 --> 00:20:39,770
have an object let's say object a and

00:20:37,100 --> 00:20:41,210
then you have a week rep object that's a

00:20:39,770 --> 00:20:43,250
separate object called we're going to

00:20:41,210 --> 00:20:46,130
call that B and B is a week reference to

00:20:43,250 --> 00:20:47,510
a you can say hey B give me a strong

00:20:46,130 --> 00:20:49,460
reference day it's like get weak

00:20:47,510 --> 00:20:51,530
reference on there get rep and it goes

00:20:49,460 --> 00:20:54,919
and gives you one and the way that's

00:20:51,530 --> 00:20:56,630
implemented inside a python is a knows

00:20:54,919 --> 00:20:59,660
that there are weak refs pointing to it

00:20:56,630 --> 00:21:01,880
and when a is destroyed it calls all of

00:20:59,660 --> 00:21:03,230
its weak reps in and tells it hey a is

00:21:01,880 --> 00:21:07,640
being destroyed you're not legal anymore

00:21:03,230 --> 00:21:10,429
and they say okay sorry but from a

00:21:07,640 --> 00:21:12,679
technical point of view B has a pointer

00:21:10,429 --> 00:21:15,049
to a but it does not have a reference to

00:21:12,679 --> 00:21:16,250
a it does not actually know at any

00:21:15,049 --> 00:21:17,929
particular time whether or not a is

00:21:16,250 --> 00:21:19,429
alive it's relying on the fact that

00:21:17,929 --> 00:21:22,040
we're running in the Gil and a is going

00:21:19,429 --> 00:21:23,809
to tell it oh I'm dead now to be safe

00:21:22,040 --> 00:21:25,190
but under the colectomy of course we

00:21:23,809 --> 00:21:27,320
don't have the Gil we don't have that

00:21:25,190 --> 00:21:28,610
safety and so I had no way because of

00:21:27,320 --> 00:21:30,000
these buffered reference counts I didn't

00:21:28,610 --> 00:21:32,250
know in real-time whether or not

00:21:30,000 --> 00:21:34,170
it was alive or not I what I wound up

00:21:32,250 --> 00:21:36,420
solving the problem with was a secondary

00:21:34,170 --> 00:21:37,680
reference count that is only used for

00:21:36,420 --> 00:21:40,230
weak reps in a couple of these other

00:21:37,680 --> 00:21:41,880
special examples which is atomically

00:21:40,230 --> 00:21:43,050
modified it's actually not incurred in

00:21:41,880 --> 00:21:45,300
Deckard the way that it works is you

00:21:43,050 --> 00:21:46,320
read the value if it's negative one the

00:21:45,300 --> 00:21:48,780
objects being destroyed and you're done

00:21:46,320 --> 00:21:50,370
if it's not negative one add 1 to the

00:21:48,780 --> 00:21:52,980
value you got and do an atomic test

00:21:50,370 --> 00:21:54,570
compare and swap if that succeeds then

00:21:52,980 --> 00:21:56,190
you've kept the optical alive and you

00:21:54,570 --> 00:21:59,100
have a reference in you're good if you

00:21:56,190 --> 00:22:00,150
get back a negative one then you know

00:21:59,100 --> 00:22:02,280
that the objects being destroyed and you

00:22:00,150 --> 00:22:03,510
can't modify it any more so that's all

00:22:02,280 --> 00:22:04,980
the problem for weak graphs I'm actually

00:22:03,510 --> 00:22:06,990
also using it for something called inter

00:22:04,980 --> 00:22:08,700
moral strings people have said Larry

00:22:06,990 --> 00:22:10,410
you're you're using too big a hammer

00:22:08,700 --> 00:22:11,670
here you can solve that another way I'm

00:22:10,410 --> 00:22:12,630
using it right now I haven't worried

00:22:11,670 --> 00:22:14,010
about it because it's kind of a minor

00:22:12,630 --> 00:22:16,290
implementation detail it's not a

00:22:14,010 --> 00:22:17,220
performance hit thing but I got internal

00:22:16,290 --> 00:22:18,590
moral strengths using the same

00:22:17,220 --> 00:22:20,910
technology I don't think I need to

00:22:18,590 --> 00:22:22,170
finally someone pointed out again I

00:22:20,910 --> 00:22:24,030
think she the same guy actually Mark

00:22:22,170 --> 00:22:25,350
Shannon pointed out I have a problem

00:22:24,030 --> 00:22:27,660
with resurrecting objects if you have a

00:22:25,350 --> 00:22:29,160
dunder del method that takes self and

00:22:27,660 --> 00:22:31,200
writes it to an external variable that's

00:22:29,160 --> 00:22:33,420
doing an inker and ink rest on the

00:22:31,200 --> 00:22:34,920
object and that's going to keep the

00:22:33,420 --> 00:22:36,210
object of lives well guess what I'm

00:22:34,920 --> 00:22:37,170
already I don't know that the objects

00:22:36,210 --> 00:22:38,370
being kept alive I don't have a

00:22:37,170 --> 00:22:40,410
real-time reference can I go ahead and

00:22:38,370 --> 00:22:42,360
delete it and other references deleted

00:22:40,410 --> 00:22:44,070
object I have no idea I'm going to solve

00:22:42,360 --> 00:22:44,490
that he says he has an idea I don't

00:22:44,070 --> 00:22:48,450
believe it

00:22:44,490 --> 00:22:49,830
so anyway my advice is don't resurrect

00:22:48,450 --> 00:22:51,390
objects inside of dunder del that's

00:22:49,830 --> 00:22:53,310
never been a good idea in Python and now

00:22:51,390 --> 00:22:55,620
it's an even worse or idea actually

00:22:53,310 --> 00:22:56,790
jaaye fun and ironpython had to solve a

00:22:55,620 --> 00:22:58,200
lot of these problems themselves so I

00:22:56,790 --> 00:23:00,240
can always talk to the ironpython and

00:22:58,200 --> 00:23:02,850
JSON guys and ask them they said they

00:23:00,240 --> 00:23:06,420
have a solution that is terrible but it

00:23:02,850 --> 00:23:08,040
works so let's look at the graph this is

00:23:06,420 --> 00:23:10,770
what happened as a result of making the

00:23:08,040 --> 00:23:12,510
reference account manager so again we

00:23:10,770 --> 00:23:14,310
have the same two lines red is always

00:23:12,510 --> 00:23:15,630
going to be see foxy Python blue is

00:23:14,310 --> 00:23:17,850
always going to be the atomic version as

00:23:15,630 --> 00:23:20,760
of June and this new green line that's

00:23:17,850 --> 00:23:24,600
what it was like as of October so it's

00:23:20,760 --> 00:23:26,400
getting faster so then the next thing

00:23:24,600 --> 00:23:28,230
that seemed to be slow was there the

00:23:26,400 --> 00:23:30,390
small black Alec Kreider what I'm going

00:23:28,230 --> 00:23:33,210
to call off malloc and what I originally

00:23:30,390 --> 00:23:34,740
did was I had one big lock for just all

00:23:33,210 --> 00:23:36,300
Volvo because like you grab that and you

00:23:34,740 --> 00:23:38,850
can allocate memory to drop it and that

00:23:36,300 --> 00:23:41,190
was super hot right away so internally

00:23:38,850 --> 00:23:43,100
odd malloc thinks of it calls these

00:23:41,190 --> 00:23:45,019
memory classes like

00:23:43,100 --> 00:23:46,610
it's a range of bytes v1 allocate if you

00:23:45,019 --> 00:23:48,049
want to Calicut zero bytes that's just

00:23:46,610 --> 00:23:50,720
illegal I think it just always gives you

00:23:48,049 --> 00:23:52,340
a pointer back this valid one to eight

00:23:50,720 --> 00:23:54,830
bytes is a class and then nine to

00:23:52,340 --> 00:23:56,539
sixteen bytes of the class and 17 to 24

00:23:54,830 --> 00:23:58,220
bytes is a class so it thinks of those

00:23:56,539 --> 00:24:00,350
internal ease being separate so what I

00:23:58,220 --> 00:24:02,269
did is I added per class locking and

00:24:00,350 --> 00:24:05,120
that made it faster but it still wasn't

00:24:02,269 --> 00:24:06,980
fast enough so I added to stage per

00:24:05,120 --> 00:24:09,200
class locking there was the fast lock

00:24:06,980 --> 00:24:10,370
which is for the super fast case of we

00:24:09,200 --> 00:24:12,350
have memory we just needed slice that

00:24:10,370 --> 00:24:13,940
off and hand it back and that's got its

00:24:12,350 --> 00:24:15,889
own super fast lock it's actually spin

00:24:13,940 --> 00:24:18,440
lock and then there's a slower heavier

00:24:15,889 --> 00:24:19,879
lock for oh I need to go and talk to an

00:24:18,440 --> 00:24:21,320
arena or I would need to actually go

00:24:19,879 --> 00:24:22,610
allocate memory or whatever anything

00:24:21,320 --> 00:24:24,590
that isn't the super fastest thing

00:24:22,610 --> 00:24:26,659
allocates a second heavier lock which

00:24:24,590 --> 00:24:27,590
doesn't prevent other threads from doing

00:24:26,659 --> 00:24:29,289
the faster thing if that actually

00:24:27,590 --> 00:24:33,860
happens to work for them at the time

00:24:29,289 --> 00:24:37,100
that sped things up I also added a per

00:24:33,860 --> 00:24:38,690
thread free list for generic allocated

00:24:37,100 --> 00:24:41,080
memory on this stored in thread-local

00:24:38,690 --> 00:24:44,000
storage and that sped things up again

00:24:41,080 --> 00:24:46,129
and finally around this time I also went

00:24:44,000 --> 00:24:47,179
through I gather a bunch of statistics

00:24:46,129 --> 00:24:48,919
when I'm doing debugging of the

00:24:47,179 --> 00:24:53,210
colectomy and I turn that on and that

00:24:48,919 --> 00:24:55,549
slows things down immensely and I did

00:24:53,210 --> 00:24:57,049
the conscientious job of making sure

00:24:55,549 --> 00:24:58,399
that there was absolutely no overhead

00:24:57,049 --> 00:25:00,019
from statistics when statistics were

00:24:58,399 --> 00:25:02,509
turned off because I was pretty sloppy

00:25:00,019 --> 00:25:04,309
about it before so as a result it did

00:25:02,509 --> 00:25:05,539
something to get faster the problem is

00:25:04,309 --> 00:25:08,050
that doesn't show up in the graph I

00:25:05,539 --> 00:25:10,720
don't know what happened here

00:25:08,050 --> 00:25:12,730
when I ran these benchmarks you can tell

00:25:10,720 --> 00:25:13,960
this is janky you can also tell it's

00:25:12,730 --> 00:25:16,750
above the green line that really should

00:25:13,960 --> 00:25:19,450
be below I guarantee you I swear it was

00:25:16,750 --> 00:25:21,040
faster when I was done but I don't have

00:25:19,450 --> 00:25:23,980
the data to show for it I'm sorry I

00:25:21,040 --> 00:25:25,240
don't know what I did but your get your

00:25:23,980 --> 00:25:26,140
get used to it you're gonna be staring

00:25:25,240 --> 00:25:32,890
that yellow line

00:25:26,140 --> 00:25:34,600
so that as of February I think yeah that

00:25:32,890 --> 00:25:36,520
size of April this year that's as far as

00:25:34,600 --> 00:25:37,780
I took it I took a break for a couple of

00:25:36,520 --> 00:25:39,520
months I was just tired of working on it

00:25:37,780 --> 00:25:41,980
but I came back to it and the next thing

00:25:39,520 --> 00:25:43,480
that seemed to be slowed was the

00:25:41,980 --> 00:25:44,920
physical act of pulling things out of

00:25:43,480 --> 00:25:46,510
thread-local storage so I'm going to

00:25:44,920 --> 00:25:47,980
show you a little bit of sweet Python

00:25:46,510 --> 00:25:49,780
internals here the function that

00:25:47,980 --> 00:25:52,420
actually runs byte code is this one

00:25:49,780 --> 00:25:55,030
gigantic function called PI eval

00:25:52,420 --> 00:25:57,490
underscore eval frame e^x that's the guy

00:25:55,030 --> 00:25:58,630
who literally runs pipe code so I needed

00:25:57,490 --> 00:26:00,160
to pull up my thread-local storage

00:25:58,630 --> 00:26:01,510
variable in order to look at stuff

00:26:00,160 --> 00:26:03,790
inside of that so at the top of the

00:26:01,510 --> 00:26:05,650
function I say PI thread state equals T

00:26:03,790 --> 00:26:06,820
say equals PI thread state yet that goes

00:26:05,650 --> 00:26:09,460
to thread-local storage pulls it out

00:26:06,820 --> 00:26:11,110
sixes in a stack variable then whenever

00:26:09,460 --> 00:26:12,910
you make a recursive function call it

00:26:11,110 --> 00:26:15,160
calls a function called call function

00:26:12,910 --> 00:26:16,600
call function needed that sea state so

00:26:15,160 --> 00:26:17,800
it pulled it out and then that

00:26:16,600 --> 00:26:20,410
recursively calls another function

00:26:17,800 --> 00:26:21,670
called fast function fast function needs

00:26:20,410 --> 00:26:24,130
that thread state thing and then that

00:26:21,670 --> 00:26:25,510
calls pie of alpha vol frame e^x these

00:26:24,130 --> 00:26:27,430
three functions get called every time

00:26:25,510 --> 00:26:30,100
you make a function call nc Python and

00:26:27,430 --> 00:26:32,550
the the Fibonacci benchmark is nothing

00:26:30,100 --> 00:26:34,480
but recursive so I'm making millions of

00:26:32,550 --> 00:26:36,640
recursive function call all over the

00:26:34,480 --> 00:26:39,250
place and every time I do it I'm looking

00:26:36,640 --> 00:26:41,560
in thread-local storage three times so I

00:26:39,250 --> 00:26:44,020
was making 370 million calls to P thread

00:26:41,560 --> 00:26:45,790
get specific which seemed to be at the

00:26:44,020 --> 00:26:48,670
top it wasn't dominating runtime but it

00:26:45,790 --> 00:26:51,310
was an enormous piece of runtime and I

00:26:48,670 --> 00:26:52,780
wanted to get rid of that that's pretty

00:26:51,310 --> 00:26:54,370
straightforward actually all I did is I

00:26:52,780 --> 00:26:56,140
sort of added an external membrane I

00:26:54,370 --> 00:26:58,240
took all the existing functions and I

00:26:56,140 --> 00:26:59,680
added two to the end again the Galacta

00:26:58,240 --> 00:27:01,270
me we're not going to merge this we're

00:26:59,680 --> 00:27:03,130
going to do a proper job if we ever if

00:27:01,270 --> 00:27:05,080
it makes it into c python but just to

00:27:03,130 --> 00:27:06,310
get it going I added a to the end of all

00:27:05,080 --> 00:27:08,770
these internal functions these three

00:27:06,310 --> 00:27:11,320
function calls and I made the the

00:27:08,770 --> 00:27:15,670
externally visible one eval frame e^x I

00:27:11,320 --> 00:27:17,080
made that so that it it looks up the

00:27:15,670 --> 00:27:19,240
thread local storage thing and passes it

00:27:17,080 --> 00:27:20,860
in as a parameter and now PI eval frame

00:27:19,240 --> 00:27:22,690
X two takes as a Fram

00:27:20,860 --> 00:27:24,370
call function two takes as a parameter

00:27:22,690 --> 00:27:26,289
fast function two takes as a parameter

00:27:24,370 --> 00:27:28,299
now we only look it up once and we can

00:27:26,289 --> 00:27:29,320
do eight million recursive function

00:27:28,299 --> 00:27:31,870
calls so we're fine

00:27:29,320 --> 00:27:32,769
that's sped things up again so this is

00:27:31,870 --> 00:27:34,809
where we are today

00:27:32,769 --> 00:27:36,460
this black line that's what I'm calling

00:27:34,809 --> 00:27:38,260
the no tlf line you'll notice that it is

00:27:36,460 --> 00:27:39,760
faster still than any of the previous

00:27:38,260 --> 00:27:41,799
lines it is getting faster and faster

00:27:39,760 --> 00:27:44,409
now I want to draw your attention the

00:27:41,799 --> 00:27:45,700
fact this is the CPU time graph so this

00:27:44,409 --> 00:27:47,710
is the collective amount of CPU time

00:27:45,700 --> 00:27:49,480
I've spent across all seven cores at the

00:27:47,710 --> 00:27:51,640
right side of the graph as opposed to

00:27:49,480 --> 00:27:53,289
cpython which is only using one core but

00:27:51,640 --> 00:27:54,700
what I said at the beginning was I'm

00:27:53,289 --> 00:27:56,649
actually interested in wall time I'm

00:27:54,700 --> 00:27:58,510
defining success or failure on this in

00:27:56,649 --> 00:28:03,220
terms of wall time so here's the wall

00:27:58,510 --> 00:28:04,659
time graph guess what the black line

00:28:03,220 --> 00:28:07,960
looks a lot better now doesn't that I'm

00:28:04,659 --> 00:28:10,720
pretty close again it's the benchmarking

00:28:07,960 --> 00:28:12,909
is so terrible and the and the CPU cores

00:28:10,720 --> 00:28:14,440
are changing frequency the ground is

00:28:12,909 --> 00:28:15,909
shifting out beneath my feet I don't

00:28:14,440 --> 00:28:18,010
know it could be that I'm actually

00:28:15,909 --> 00:28:20,409
faster probably not it could be that I'm

00:28:18,010 --> 00:28:22,659
slower than that that's more likely but

00:28:20,409 --> 00:28:24,880
I'm within striking distance and I feel

00:28:22,659 --> 00:28:27,010
like if I find another big thing that's

00:28:24,880 --> 00:28:28,630
a problem I may actually start to dip

00:28:27,010 --> 00:28:29,830
below it now and then which one I will

00:28:28,630 --> 00:28:31,960
say is I collect music success to

00:28:29,830 --> 00:28:35,019
everybody so the next thing I'm working

00:28:31,960 --> 00:28:36,639
on I'm working on autonomic again

00:28:35,019 --> 00:28:39,490
because I think it's still dominating

00:28:36,639 --> 00:28:41,529
run time at one point I switched mouth

00:28:39,490 --> 00:28:43,809
to using spin locks instead of my few

00:28:41,529 --> 00:28:47,889
text-based blocks and the few sex locks

00:28:43,809 --> 00:28:49,510
I ran under the profiler and allocate

00:28:47,889 --> 00:28:51,490
memory was 20 percent of run time and

00:28:49,510 --> 00:28:53,559
free memory was 20 percent of run time

00:28:51,490 --> 00:28:55,389
that doesn't show up when I use the few

00:28:53,559 --> 00:28:56,950
text space base locks for some reason I

00:28:55,389 --> 00:28:59,710
don't know maybe cache Brian doesn't

00:28:56,950 --> 00:29:01,000
like me but I'm like if I change that

00:28:59,710 --> 00:29:03,130
lock out the run time doesn't change

00:29:01,000 --> 00:29:05,919
significantly but the graph changes

00:29:03,130 --> 00:29:07,059
I suspect that maybe it's like I think

00:29:05,919 --> 00:29:09,220
it's still using the time it's just not

00:29:07,059 --> 00:29:11,740
showing up in the profiler so I want to

00:29:09,220 --> 00:29:13,630
rewrite automatic so that there's a

00:29:11,740 --> 00:29:15,669
central first data structure that's

00:29:13,630 --> 00:29:16,929
called used pools and that's global for

00:29:15,669 --> 00:29:18,820
the entire process I want to make that

00:29:16,929 --> 00:29:20,620
per thread and actually technically I

00:29:18,820 --> 00:29:22,299
did make it per thread and now it's not

00:29:20,620 --> 00:29:23,830
working properly and so I run my

00:29:22,299 --> 00:29:25,929
benchmark and instead of using 200

00:29:23,830 --> 00:29:28,330
megabytes it uses 10 gig before it's

00:29:25,929 --> 00:29:30,159
time before Sun and the physical act of

00:29:28,330 --> 00:29:31,330
allocating and freeing 10 gig worth of

00:29:30,159 --> 00:29:33,580
objects or whatever it is doing

00:29:31,330 --> 00:29:34,419
underneath itself is slow and so the

00:29:33,580 --> 00:29:36,159
whole program got

00:29:34,419 --> 00:29:38,830
slower once I figure out what that

00:29:36,159 --> 00:29:41,859
memory allocation problem is I can make

00:29:38,830 --> 00:29:44,980
that go away but I still have another

00:29:41,859 --> 00:29:46,840
experiment or two to try I have an idea

00:29:44,980 --> 00:29:48,730
I call private locking you start with

00:29:46,840 --> 00:29:50,769
the observation that all objects most

00:29:48,730 --> 00:29:55,149
objects when you never leave the thread

00:29:50,769 --> 00:29:57,730
they were created in and so so if we

00:29:55,149 --> 00:29:59,049
create a dict and it only lives in a

00:29:57,730 --> 00:30:00,999
single thread and then it's destroyed

00:29:59,049 --> 00:30:02,470
and never escapes that thread then why

00:30:00,999 --> 00:30:03,639
do we have to lock and release lock and

00:30:02,470 --> 00:30:05,679
release every time we talk to that dick

00:30:03,639 --> 00:30:07,330
it'd be cheaper to do something else

00:30:05,679 --> 00:30:09,009
where we knew that it was a per thread

00:30:07,330 --> 00:30:10,389
object and we didn't have to do all that

00:30:09,009 --> 00:30:12,909
locking so I have an idea that

00:30:10,389 --> 00:30:14,499
essentially uh Dickson lists and other

00:30:12,909 --> 00:30:18,039
objects like that are created in this

00:30:14,499 --> 00:30:19,239
sort of pre pre locked model where if

00:30:18,039 --> 00:30:20,590
another thread wants to talk to it has

00:30:19,239 --> 00:30:21,759
to say hey I actually want to talk to

00:30:20,590 --> 00:30:24,039
this you need to turn into a regular

00:30:21,759 --> 00:30:26,159
lockable object and before that locking

00:30:24,039 --> 00:30:30,659
and unlocking would be a simple local

00:30:26,159 --> 00:30:33,759
non none atomic increment and decrement

00:30:30,659 --> 00:30:35,769
I tried it once it made it slower but

00:30:33,759 --> 00:30:36,820
like I said I may turn the corner and I

00:30:35,769 --> 00:30:38,799
may think of something out maybe I

00:30:36,820 --> 00:30:40,690
botched it the first time if I try it

00:30:38,799 --> 00:30:42,820
again maybe I'll get it to be faster the

00:30:40,690 --> 00:30:45,129
other idea I have this was implemented

00:30:42,820 --> 00:30:47,649
for me actually by Thomas Wooters at the

00:30:45,129 --> 00:30:50,200
Sprint's last year he has he did

00:30:47,649 --> 00:30:52,179
something of where he was at work where

00:30:50,200 --> 00:30:54,580
they store the reference count outside

00:30:52,179 --> 00:30:55,690
of the object so right now the reference

00:30:54,580 --> 00:30:56,950
kind of sorted right at the top of the

00:30:55,690 --> 00:30:59,200
object and the reason that this might

00:30:56,950 --> 00:31:01,619
help the colectomy is because of cache

00:30:59,200 --> 00:31:04,480
lines every time that you change a

00:31:01,619 --> 00:31:05,859
memory that invalidates that cache line

00:31:04,480 --> 00:31:07,629
for all the other cores so if you have

00:31:05,859 --> 00:31:09,190
eight cores in your CPU all looking at

00:31:07,629 --> 00:31:10,869
the same cache line you change that

00:31:09,190 --> 00:31:12,249
memory suddenly it tells all the other

00:31:10,869 --> 00:31:14,230
cations hey you have to throw away your

00:31:12,249 --> 00:31:14,769
memory and get a fresh copy because it's

00:31:14,230 --> 00:31:16,149
changed

00:31:14,769 --> 00:31:17,200
and since we're storing the reference

00:31:16,149 --> 00:31:18,999
calm the object that means that we're

00:31:17,200 --> 00:31:21,249
changing the memory on every object in

00:31:18,999 --> 00:31:22,749
python anytime we examine it including

00:31:21,249 --> 00:31:25,600
objects that are otherwise immutable

00:31:22,749 --> 00:31:26,889
like say an integer or string so again

00:31:25,600 --> 00:31:29,830
the colectomy is doing nothing but

00:31:26,889 --> 00:31:31,600
integers and every time it examines the

00:31:29,830 --> 00:31:32,980
number zero or one or two its

00:31:31,600 --> 00:31:34,869
invalidating the cache lines for all the

00:31:32,980 --> 00:31:36,549
other cores if we could get it so that

00:31:34,869 --> 00:31:38,739
these objects were genuinely immutable

00:31:36,549 --> 00:31:40,119
then they wouldn't blow away those cache

00:31:38,739 --> 00:31:41,649
lines that would get rid of contention

00:31:40,119 --> 00:31:44,289
on this internal bus where those cores

00:31:41,649 --> 00:31:45,909
are talking to each other it would it

00:31:44,289 --> 00:31:47,300
seems like it would it would it actually

00:31:45,909 --> 00:31:48,650
would be better for copy on

00:31:47,300 --> 00:31:50,150
semantics for when you were doing what

00:31:48,650 --> 00:31:51,140
we process although again the Golda

00:31:50,150 --> 00:31:54,620
colectomy is make it so you don't have

00:31:51,140 --> 00:31:55,910
to go multi-process but storing the

00:31:54,620 --> 00:31:58,180
reference count outside of the object

00:31:55,910 --> 00:32:01,520
itself is overhead and it made it slower

00:31:58,180 --> 00:32:02,990
so but maybe in the future maybe we'll

00:32:01,520 --> 00:32:04,700
figure out a better way or maybe I just

00:32:02,990 --> 00:32:06,410
watched it and maybe it'll disaster in

00:32:04,700 --> 00:32:10,070
the future it certainly might help with

00:32:06,410 --> 00:32:12,860
copy-on-write semantics we'll see if all

00:32:10,070 --> 00:32:15,200
else fails I have one more huge thing

00:32:12,860 --> 00:32:17,240
that I can do this was suggested to me

00:32:15,200 --> 00:32:20,330
by multiple this wasn't my idea this was

00:32:17,240 --> 00:32:23,810
Marc Shanon Lukasz both suggested

00:32:20,330 --> 00:32:24,710
independently the idea is everybody

00:32:23,810 --> 00:32:26,810
knows that

00:32:24,710 --> 00:32:27,890
tracing garbage collection is faster

00:32:26,810 --> 00:32:29,180
than reference counting if you wanted to

00:32:27,890 --> 00:32:31,220
multi-threaded and that's what everybody

00:32:29,180 --> 00:32:33,980
does these days like Java is a reference

00:32:31,220 --> 00:32:36,650
garbage tracing garbage collection rust

00:32:33,980 --> 00:32:37,820
go everybody these days all the new

00:32:36,650 --> 00:32:40,160
languages are all tracing garbage

00:32:37,820 --> 00:32:41,480
collection so we switched cpython

00:32:40,160 --> 00:32:43,190
internal views tracing garbage

00:32:41,480 --> 00:32:44,630
collection this is a more difficult API

00:32:43,190 --> 00:32:48,860
to get right it's going to break the

00:32:44,630 --> 00:32:51,290
entire C API but there's a technology

00:32:48,860 --> 00:32:52,640
inside a pipe I called C PI X pi PI of

00:32:51,290 --> 00:32:55,610
course who knows the Python that's

00:32:52,640 --> 00:32:57,950
implemented in Python and it uses a JIT

00:32:55,610 --> 00:32:58,940
and it uses real traits and garbage

00:32:57,950 --> 00:33:01,070
collection it doesn't use a reference

00:32:58,940 --> 00:33:03,440
counts so their object model is very

00:33:01,070 --> 00:33:04,910
different from C Python but a classic

00:33:03,440 --> 00:33:07,070
problem for pi PI is that it doesn't run

00:33:04,910 --> 00:33:08,930
the extensions they had an idea where

00:33:07,070 --> 00:33:10,550
they could run C extensions unmodified

00:33:08,930 --> 00:33:13,040
like you literally could use a compiled

00:33:10,550 --> 00:33:15,830
shared library and just plug it into C

00:33:13,040 --> 00:33:19,070
Python to pi PI but but what they would

00:33:15,830 --> 00:33:20,960
do is simulate the C API and that

00:33:19,070 --> 00:33:22,250
involves simulating C pythons object

00:33:20,960 --> 00:33:25,580
model which involves simulating

00:33:22,250 --> 00:33:27,920
reference counts in a tracing garbage

00:33:25,580 --> 00:33:29,840
collection environment we don't have

00:33:27,920 --> 00:33:31,040
their problem of their internal

00:33:29,840 --> 00:33:32,210
representation of an object is very

00:33:31,040 --> 00:33:33,590
different so what they had that do

00:33:32,210 --> 00:33:35,750
eventually was they had two different

00:33:33,590 --> 00:33:37,580
objects there was the actual internal pi

00:33:35,750 --> 00:33:40,490
PI object of whatever it was and then

00:33:37,580 --> 00:33:42,050
this is C PI X X representation and they

00:33:40,490 --> 00:33:43,820
Honda had a problem keeping them in sync

00:33:42,050 --> 00:33:45,560
and stuff we don't have that problem we

00:33:43,820 --> 00:33:48,170
can just use the internal C Python

00:33:45,560 --> 00:33:50,510
object without the Gil and C PI

00:33:48,170 --> 00:33:51,950
extensions can talk to that and we would

00:33:50,510 --> 00:33:53,150
just simulate reference counts on top of

00:33:51,950 --> 00:33:55,340
it that'd be pretty harmless and so it

00:33:53,150 --> 00:33:56,330
would be a lot simple for us and all we

00:33:55,340 --> 00:33:57,320
need to do is some of the reference

00:33:56,330 --> 00:33:59,330
counts and we could probably get that

00:33:57,320 --> 00:34:01,309
working that probably pretty close again

00:33:59,330 --> 00:34:03,590
we can't guarantee no breakage

00:34:01,309 --> 00:34:04,759
on the capi but we can we could actually

00:34:03,590 --> 00:34:07,220
do some things to mitigate the

00:34:04,759 --> 00:34:08,480
multi-threaded nosov the Galacta me and

00:34:07,220 --> 00:34:10,099
we simulate reference counts and we

00:34:08,480 --> 00:34:13,010
could get away perhaps with running

00:34:10,099 --> 00:34:14,300
cpython extensions in this colectomy

00:34:13,010 --> 00:34:16,879
version with tracing garbage collection

00:34:14,300 --> 00:34:18,500
that'd be a lot of work I really don't

00:34:16,879 --> 00:34:20,720
want to do it so I'm going to try and

00:34:18,500 --> 00:34:22,429
push this existing approach as far as I

00:34:20,720 --> 00:34:25,639
can but if I really have to give up

00:34:22,429 --> 00:34:27,349
maybe I can start over and do this so

00:34:25,639 --> 00:34:29,270
the final thing I want to talk about is

00:34:27,349 --> 00:34:30,619
just this is what we want to see this is

00:34:29,270 --> 00:34:32,929
the graph we actually want to see right

00:34:30,619 --> 00:34:35,329
I just drew this purple line here the

00:34:32,929 --> 00:34:37,460
idea is you add threads to your program

00:34:35,329 --> 00:34:39,200
and it just uses multiple cores and

00:34:37,460 --> 00:34:41,240
doesn't care the program doesn't get any

00:34:39,200 --> 00:34:43,429
slower this is what we wish we had right

00:34:41,240 --> 00:34:49,760
actually we have that because that's guy

00:34:43,429 --> 00:34:51,770
fun and what I say is that JSON and

00:34:49,760 --> 00:34:53,020
ironpython are actually existence proofs

00:34:51,770 --> 00:34:55,970
that the Galacta me will work because

00:34:53,020 --> 00:34:58,520
consider let's let's just say that we

00:34:55,970 --> 00:35:00,460
have a whole pile of C code and it just

00:34:58,520 --> 00:35:03,410
happens that like one of the piles is a

00:35:00,460 --> 00:35:06,680
Python as a Java interpreter and the

00:35:03,410 --> 00:35:08,750
other one's a CLR runtime but it's a big

00:35:06,680 --> 00:35:09,740
pile of C code essentially and at the

00:35:08,750 --> 00:35:10,760
end of the day they have a Python

00:35:09,740 --> 00:35:12,650
interpreter this running will be

00:35:10,760 --> 00:35:14,390
threaded without a Gil this proves that

00:35:12,650 --> 00:35:17,089
you can write a multi-threaded Python

00:35:14,390 --> 00:35:20,450
interpreter in C without a Gil the

00:35:17,089 --> 00:35:22,790
question is not can we write one will it

00:35:20,450 --> 00:35:24,800
work the question is how much does the C

00:35:22,790 --> 00:35:29,619
API do I have to break before I can get

00:35:24,800 --> 00:35:29,619
the Python to work well out to go thank

00:35:34,560 --> 00:35:44,040
Larry Hastings ladies Midland by the way

00:35:40,290 --> 00:35:45,630
I have stickers who lunch is happening

00:35:44,040 --> 00:35:47,520
at the moment so if you are wanting to

00:35:45,630 --> 00:35:49,740
leave that can you please do so quietly

00:35:47,520 --> 00:35:51,540
if you have questions for Larry there

00:35:49,740 --> 00:35:54,450
are two microphones here in the aisles

00:35:51,540 --> 00:35:59,460
please line up and please be quiet if

00:35:54,450 --> 00:36:01,140
you're walking out what I say is you can

00:35:59,460 --> 00:36:02,910
have one of each design of the sticker

00:36:01,140 --> 00:36:11,220
okay we don't take more than one year on

00:36:02,910 --> 00:36:14,220
my right hai-yah Larry can hear you I

00:36:11,220 --> 00:36:15,810
can hear you go ahead so some of this

00:36:14,220 --> 00:36:19,020
sounded very Intel and

00:36:15,810 --> 00:36:21,090
architecture-specific is there when you

00:36:19,020 --> 00:36:22,200
think about arm CPUs or running Python

00:36:21,090 --> 00:36:24,240
and other environments do you expect

00:36:22,200 --> 00:36:25,950
with this approach with those places as

00:36:24,240 --> 00:36:27,480
well in the audience can you please be

00:36:25,950 --> 00:36:28,890
quiet there are questions and answers

00:36:27,480 --> 00:36:30,960
happening in people are still trying to

00:36:28,890 --> 00:36:33,390
listen okay I heard everything you said

00:36:30,960 --> 00:36:35,070
is that your whole question the question

00:36:33,390 --> 00:36:37,290
is is your approach to this going to be

00:36:35,070 --> 00:36:39,150
usable in other architectures like arm

00:36:37,290 --> 00:36:41,040
you talked about interspecific CPU

00:36:39,150 --> 00:36:43,200
instruction right so the answer is it

00:36:41,040 --> 00:36:45,360
should be right now it's not literally

00:36:43,200 --> 00:36:46,710
so like I said I discovered about a

00:36:45,360 --> 00:36:48,060
friend of mine told me about a week ago

00:36:46,710 --> 00:36:49,380
oh did you realize that your cores are

00:36:48,060 --> 00:36:53,070
changing speed on you I said oh my god

00:36:49,380 --> 00:36:55,110
no so I wanted to test on something that

00:36:53,070 --> 00:36:56,700
I had handy that I knew was multi-core

00:36:55,110 --> 00:36:58,260
and I guess was not going to be

00:36:56,700 --> 00:37:00,450
sophisticated enough to change the speed

00:36:58,260 --> 00:37:03,210
on me like that so I tried compiling the

00:37:00,450 --> 00:37:05,850
Galacta me on a Raspberry Pi 3 which is

00:37:03,210 --> 00:37:07,410
for core and arm and it didn't work

00:37:05,850 --> 00:37:08,610
because it's first of all I had one

00:37:07,410 --> 00:37:10,170
problem then I fixed it and I had

00:37:08,610 --> 00:37:14,280
another problem and then I said oh yeah

00:37:10,170 --> 00:37:16,170
I can't include this x86 internal header

00:37:14,280 --> 00:37:18,840
file there was something that GCC had

00:37:16,170 --> 00:37:22,260
given me and so I like ok I can't solve

00:37:18,840 --> 00:37:23,790
that but I all the atomic instructions

00:37:22,260 --> 00:37:25,740
that I'm using I talked about Intel

00:37:23,790 --> 00:37:27,300
specific things are DTS a of course is

00:37:25,740 --> 00:37:28,590
Intel specific I'm really only using

00:37:27,300 --> 00:37:30,270
that for statistics gathering I'm not

00:37:28,590 --> 00:37:32,700
using that as an implementation base of

00:37:30,270 --> 00:37:34,470
the colectomy every modern architecture

00:37:32,700 --> 00:37:35,970
does have atomic increment decrement

00:37:34,470 --> 00:37:37,800
every modern architecture has atomic

00:37:35,970 --> 00:37:39,510
test ins and Satre compare and swap

00:37:37,800 --> 00:37:40,200
instructions so all those things should

00:37:39,510 --> 00:37:42,720
be portable

00:37:40,200 --> 00:37:44,280
there will be more platform reliance in

00:37:42,720 --> 00:37:45,450
neglecting because we have to use those

00:37:44,280 --> 00:37:47,670
things and that's not part of the

00:37:45,450 --> 00:37:50,280
standard C API

00:37:47,670 --> 00:37:51,569
but they're all available and so we all

00:37:50,280 --> 00:37:53,369
we need to do is a little bit more

00:37:51,569 --> 00:37:57,480
platform hacking in order to get those

00:37:53,369 --> 00:38:00,650
to work next question okay so basically

00:37:57,480 --> 00:38:03,180
you said the benchmarking is really bad

00:38:00,650 --> 00:38:07,700
everyone knows it

00:38:03,180 --> 00:38:10,140
so how worried are you like that the FIB

00:38:07,700 --> 00:38:12,510
function isn't good enough I mean if you

00:38:10,140 --> 00:38:14,490
tried any different function or anything

00:38:12,510 --> 00:38:16,470
else that the results would be

00:38:14,490 --> 00:38:19,200
completely different like how worried

00:38:16,470 --> 00:38:21,630
are you about that I don't think it'd be

00:38:19,200 --> 00:38:24,809
a world of difference again it's so this

00:38:21,630 --> 00:38:26,819
is specifically exercising its I had a

00:38:24,809 --> 00:38:29,190
list all the things that's exercising so

00:38:26,819 --> 00:38:33,299
for example someone suggested an

00:38:29,190 --> 00:38:35,849
optimization to me they said you're the

00:38:33,299 --> 00:38:37,650
Fibonacci function itself looking up the

00:38:35,849 --> 00:38:40,950
Fibonacci function takes a lot of time

00:38:37,650 --> 00:38:43,380
because we have to do a lookup and

00:38:40,950 --> 00:38:45,450
actually have to look in the module so

00:38:43,380 --> 00:38:47,010
it's not cached locally so it needs to

00:38:45,450 --> 00:38:49,140
do it needs to lock and unlock a dict

00:38:47,010 --> 00:38:52,319
and that module addicted self was hot

00:38:49,140 --> 00:38:54,420
and so if we did a multiple reader

00:38:52,319 --> 00:38:56,220
single writer lock on the dict that

00:38:54,420 --> 00:38:58,380
would speed it up and I said well on the

00:38:56,220 --> 00:38:59,730
one hand I think that's optimizing for

00:38:58,380 --> 00:39:00,990
my particular benchmark let's not do

00:38:59,730 --> 00:39:03,030
that but on the other hand that's a

00:39:00,990 --> 00:39:04,890
generally purpose that's a helpful

00:39:03,030 --> 00:39:06,270
optimization for a lot of people and it

00:39:04,890 --> 00:39:07,650
really isn't all that's tailored to my

00:39:06,270 --> 00:39:10,290
code and it would work on all dicks and

00:39:07,650 --> 00:39:11,250
it'd be fine so I think ultimately we're

00:39:10,290 --> 00:39:13,799
going to merge that and make that

00:39:11,250 --> 00:39:14,730
benchmark faster of course we wouldn't

00:39:13,799 --> 00:39:16,410
see that if we went to a different

00:39:14,730 --> 00:39:19,230
benchmark like the one that David

00:39:16,410 --> 00:39:21,329
Beasley uses when he's timing things and

00:39:19,230 --> 00:39:23,040
playing with the Gil he uses countdown

00:39:21,329 --> 00:39:25,099
which is just a for loop over ten

00:39:23,040 --> 00:39:27,059
million times or something like that so

00:39:25,099 --> 00:39:28,680
at the end of the day I'm not all that

00:39:27,059 --> 00:39:30,210
worried because fundamentally I am

00:39:28,680 --> 00:39:32,849
exercising bytecode I'm exercising

00:39:30,210 --> 00:39:36,299
function calls I'm exercising dict and

00:39:32,849 --> 00:39:37,440
list lookups internally I'm exercising a

00:39:36,299 --> 00:39:41,760
little bit of boolean logic I'm

00:39:37,440 --> 00:39:42,869
exercising integers not strings but all

00:39:41,760 --> 00:39:44,339
the things that are implemented and see

00:39:42,869 --> 00:39:47,430
I'm not that worried about I'm worried

00:39:44,339 --> 00:39:48,839
about the internal core bytecode engine

00:39:47,430 --> 00:39:51,359
really of C Python is what I'm worried

00:39:48,839 --> 00:39:54,900
about and one function is as good as

00:39:51,359 --> 00:39:56,099
another at that point so once I'm more

00:39:54,900 --> 00:39:57,540
confident about the Galacta me in the

00:39:56,099 --> 00:39:59,280
approach then I'd be more interested in

00:39:57,540 --> 00:40:00,960
running more code through it anyway but

00:39:59,280 --> 00:40:01,450
right now I just have my head down it's

00:40:00,960 --> 00:40:03,579
like if

00:40:01,450 --> 00:40:05,829
I could make Fibonacci run faster than

00:40:03,579 --> 00:40:07,359
foxy Python then it becomes much easier

00:40:05,829 --> 00:40:09,490
to make other things on fast and see

00:40:07,359 --> 00:40:10,570
Potter so yes eventually I'll run other

00:40:09,490 --> 00:40:13,510
benchmarks but not now

00:40:10,570 --> 00:40:15,310
now the question so if I understand your

00:40:13,510 --> 00:40:17,470
ref count log implementation correctly

00:40:15,310 --> 00:40:19,270
it would actually truly make like dell

00:40:17,470 --> 00:40:21,190
in vacations like actually

00:40:19,270 --> 00:40:23,470
non-deterministic ivan fortunately seen

00:40:21,190 --> 00:40:25,089
a lot of Python code that kind of relies

00:40:23,470 --> 00:40:26,589
on reference counting even though that

00:40:25,089 --> 00:40:30,280
was never really guaranteed by the

00:40:26,589 --> 00:40:33,099
actual implementation per se but if you

00:40:30,280 --> 00:40:35,349
did go forward with this plan I could

00:40:33,099 --> 00:40:36,940
see code breaking because they relied on

00:40:35,349 --> 00:40:39,339
that reference counting implementation

00:40:36,940 --> 00:40:40,630
and I guess what is your like okay so

00:40:39,339 --> 00:40:42,099
you're talking about that how do you go

00:40:40,630 --> 00:40:45,640
forward with that you're talking about

00:40:42,099 --> 00:40:46,540
the fact that people rely on recipes

00:40:45,640 --> 00:40:47,619
you're not talking about reference

00:40:46,540 --> 00:40:49,869
counting per se you're talking about the

00:40:47,619 --> 00:40:51,550
people that rely on the fact that once

00:40:49,869 --> 00:40:53,200
the last reference to an object is

00:40:51,550 --> 00:40:55,859
dropped the object is freed immediately

00:40:53,200 --> 00:40:58,030
correct right the Python language spec

00:40:55,859 --> 00:40:59,829
specifically says you're not allowed to

00:40:58,030 --> 00:41:01,470
rely on that and none of the other

00:40:59,829 --> 00:41:03,970
implementations make it happen and

00:41:01,470 --> 00:41:06,490
that's just a fact of life that is a

00:41:03,970 --> 00:41:08,349
Python visible side effect of the

00:41:06,490 --> 00:41:10,030
implementation of the Gil and if we ever

00:41:08,349 --> 00:41:11,680
merged it and became official Python

00:41:10,030 --> 00:41:13,470
then yes it would go away and I'm sorry

00:41:11,680 --> 00:41:15,730
so that's why we have things like

00:41:13,470 --> 00:41:17,710
context managers they kind of manage

00:41:15,730 --> 00:41:19,599
explicitly therefore this sort of object

00:41:17,710 --> 00:41:20,770
like time management exactly yeah can't

00:41:19,599 --> 00:41:24,069
do anything about it sorry can't help

00:41:20,770 --> 00:41:24,940
you all right another question I thought

00:41:24,069 --> 00:41:26,560
you were going to bring up another topic

00:41:24,940 --> 00:41:28,660
which I didn't talk touch on really

00:41:26,560 --> 00:41:30,220
quickly one side effect the original

00:41:28,660 --> 00:41:31,990
implementation of the reference count

00:41:30,220 --> 00:41:33,490
manager of course I was doing the incres

00:41:31,990 --> 00:41:34,780
and deckers on this of the threat right

00:41:33,490 --> 00:41:36,430
which meant that the last dekker

00:41:34,780 --> 00:41:37,690
happened on other thread which meant

00:41:36,430 --> 00:41:39,930
that d alec happened on that other

00:41:37,690 --> 00:41:42,099
thread and so now that's two effects one

00:41:39,930 --> 00:41:44,859
d Alex happened on a different thread

00:41:42,099 --> 00:41:46,540
from where the object was originally

00:41:44,859 --> 00:41:48,579
like where it would have naturally

00:41:46,540 --> 00:41:51,400
happened and two that meant that the

00:41:48,579 --> 00:41:52,839
sialic thread the the commit thread had

00:41:51,400 --> 00:41:54,339
to work like a pit pony it turned out

00:41:52,839 --> 00:41:55,900
that that just swamped it it was

00:41:54,339 --> 00:41:57,460
spending all this time doing D Alex and

00:41:55,900 --> 00:41:59,079
it never got it fell behind immediately

00:41:57,460 --> 00:42:01,060
never caught up so what I wound up doing

00:41:59,079 --> 00:42:03,010
internally is when the object reaches

00:42:01,060 --> 00:42:04,660
and reference kind of zero I put it on

00:42:03,010 --> 00:42:06,970
another list and I pass it back to the

00:42:04,660 --> 00:42:09,130
last thread that did the last decra and

00:42:06,970 --> 00:42:11,349
then he notices that later and he

00:42:09,130 --> 00:42:13,300
commits it so there is a another delay

00:42:11,349 --> 00:42:14,289
built in before the object is destroyed

00:42:13,300 --> 00:42:18,759
so it's

00:42:14,289 --> 00:42:19,269
worse than you probably thought next

00:42:18,759 --> 00:42:20,469
question please

00:42:19,269 --> 00:42:22,569
just another quick question about

00:42:20,469 --> 00:42:23,919
benchmarking I don't have a quick

00:42:22,569 --> 00:42:24,849
question it's probably a long answering

00:42:23,919 --> 00:42:27,400
sorry

00:42:24,849 --> 00:42:29,079
I think this up well assuming that speed

00:42:27,400 --> 00:42:31,029
step is just for reducing power

00:42:29,079 --> 00:42:33,249
consumption is there not a like BIOS

00:42:31,029 --> 00:42:34,809
setting to turn it off yeah so I went

00:42:33,249 --> 00:42:36,489
through my BIOS and tried to turn off

00:42:34,809 --> 00:42:37,809
everything and I guess I maybe I had a

00:42:36,489 --> 00:42:39,489
lame by Oscar I was looking in the wrong

00:42:37,809 --> 00:42:42,219
spot but there was literally no big

00:42:39,489 --> 00:42:46,299
flashing set your CPU frequency here

00:42:42,219 --> 00:42:47,199
thing so I turned off a I turbo boost or

00:42:46,299 --> 00:42:48,669
something like that there were about

00:42:47,199 --> 00:42:49,929
three things that I turned off and it

00:42:48,669 --> 00:42:51,160
seemed to be a little bit more stable

00:42:49,929 --> 00:42:52,329
then and so these benchmarks are

00:42:51,160 --> 00:42:54,160
actually run with those settings turned

00:42:52,329 --> 00:42:56,199
on but apparently Victor said there's

00:42:54,160 --> 00:42:59,079
literally a Linux kernel setting where

00:42:56,199 --> 00:43:00,880
you can specify the max frequency and so

00:42:59,079 --> 00:43:02,679
if I said oh yeah your max frequency is

00:43:00,880 --> 00:43:03,910
a gigahertz and guess what everyone's

00:43:02,679 --> 00:43:06,219
gonna run the de gigahertz cuz that's

00:43:03,910 --> 00:43:08,499
like slower than it ever wants to be so

00:43:06,219 --> 00:43:09,939
I'm going to do that once I figure out

00:43:08,499 --> 00:43:11,169
what that setting is and once I get home

00:43:09,939 --> 00:43:13,959
and I'm sitting in front of the computer

00:43:11,169 --> 00:43:15,519
again but I mean I'm a guy I said I mean

00:43:13,959 --> 00:43:17,890
I'm only in so much of a hurry about it

00:43:15,519 --> 00:43:20,890
because I'm like I I'm in the I'm in the

00:43:17,890 --> 00:43:23,439
neighborhood a last question do you have

00:43:20,890 --> 00:43:26,259
an idea how much you can minimize the C

00:43:23,439 --> 00:43:27,519
API changes from this by the time how

00:43:26,259 --> 00:43:31,329
much I've what since we've gotten how

00:43:27,519 --> 00:43:33,669
much the C API changes will be - right

00:43:31,329 --> 00:43:37,209
okay so I kind of answered that question

00:43:33,669 --> 00:43:40,029
in my talk from last year the the answer

00:43:37,209 --> 00:43:43,299
is that so far I have essentially

00:43:40,029 --> 00:43:46,630
preserved the existing source code level

00:43:43,299 --> 00:43:48,549
C API so a recompile would get you using

00:43:46,630 --> 00:43:49,689
all the new technologies underneath you

00:43:48,549 --> 00:43:51,130
didn't have to touch a line of source

00:43:49,689 --> 00:43:52,630
code the problem is that there are

00:43:51,130 --> 00:43:54,400
semantic changes involved so there are

00:43:52,630 --> 00:43:58,569
guarantees that the Gil gives you that I

00:43:54,400 --> 00:44:00,009
don't give you like and there and there

00:43:58,569 --> 00:44:01,569
are other things happening like the what

00:44:00,009 --> 00:44:03,579
he alluded to which is the instantaneous

00:44:01,569 --> 00:44:04,989
objects going away being able to rely on

00:44:03,579 --> 00:44:06,159
that which you out which you don't have

00:44:04,989 --> 00:44:07,900
anymore because about for reference

00:44:06,159 --> 00:44:10,179
counting so another example of this

00:44:07,900 --> 00:44:11,979
which there's literally an example of

00:44:10,179 --> 00:44:14,529
this as a good approach to how to do

00:44:11,979 --> 00:44:17,199
things in the C Python extension

00:44:14,529 --> 00:44:19,390
documentation they say here's example

00:44:17,199 --> 00:44:21,309
code they say let's say you have an

00:44:19,390 --> 00:44:22,959
object you want to lazily instantiate

00:44:21,309 --> 00:44:25,900
because it's expensive you only want to

00:44:22,959 --> 00:44:26,980
do and it's needed so uhit's a static PI

00:44:25,900 --> 00:44:29,230
object star

00:44:26,980 --> 00:44:30,340
two equals null and then you say inside

00:44:29,230 --> 00:44:33,820
in the middle of your function you say

00:44:30,340 --> 00:44:35,260
if foo is null create foo and now we can

00:44:33,820 --> 00:44:36,640
use food and everybody's happy the

00:44:35,260 --> 00:44:39,550
problem is if you call that three times

00:44:36,640 --> 00:44:40,619
now you've got three races and probably

00:44:39,550 --> 00:44:42,760
you're going to allocate memory

00:44:40,619 --> 00:44:44,830
uselessly and you're going to stomp on

00:44:42,760 --> 00:44:46,030
that value and that's that used to be

00:44:44,830 --> 00:44:47,380
safe because it was protected by the

00:44:46,030 --> 00:44:49,780
guild literally nobody could interrupt

00:44:47,380 --> 00:44:51,550
you and and call into that again but

00:44:49,780 --> 00:44:54,040
without the Gil that's no longer safe

00:44:51,550 --> 00:44:55,869
and so I would say don't do that but

00:44:54,040 --> 00:44:57,850
there's lots of code that does that and

00:44:55,869 --> 00:44:59,950
it's a guarantee that the Gil gave you

00:44:57,850 --> 00:45:02,050
that I've taken away so that's a

00:44:59,950 --> 00:45:04,450
semantic change the API that isn't

00:45:02,050 --> 00:45:06,670
encoded in the actual like literal PI

00:45:04,450 --> 00:45:08,500
you know in craft PI deck ref those

00:45:06,670 --> 00:45:09,670
things haven't changed but the semantics

00:45:08,500 --> 00:45:11,710
around them those stuff you've been

00:45:09,670 --> 00:45:13,420
doing for years have changed and so

00:45:11,710 --> 00:45:14,770
that's why I say I know I'm going to

00:45:13,420 --> 00:45:16,630
break the extensions because these some

00:45:14,770 --> 00:45:18,700
axes have changed and I can't do

00:45:16,630 --> 00:45:20,500
anything about them I can the whole

00:45:18,700 --> 00:45:23,980
point was to break those sorts of things

00:45:20,500 --> 00:45:26,260
and I can't fix that as in terms of

00:45:23,980 --> 00:45:28,960
source code compatibility literally my

00:45:26,260 --> 00:45:30,580
goal is that you can recompile and you

00:45:28,960 --> 00:45:32,560
will produce like you you won't get any

00:45:30,580 --> 00:45:33,520
errors and there are no new API is that

00:45:32,560 --> 00:45:35,140
you were supposed to call that you

00:45:33,520 --> 00:45:36,850
didn't your code will continue to work

00:45:35,140 --> 00:45:40,240
and there are additional api's that will

00:45:36,850 --> 00:45:44,590
make things go faster but unchanged C

00:45:40,240 --> 00:45:45,830
API should physically compile Larry

00:45:44,590 --> 00:45:52,280
Hastings everyone

00:45:45,830 --> 00:45:52,280

YouTube URL: https://www.youtube.com/watch?v=pLqv11ScGsQ


