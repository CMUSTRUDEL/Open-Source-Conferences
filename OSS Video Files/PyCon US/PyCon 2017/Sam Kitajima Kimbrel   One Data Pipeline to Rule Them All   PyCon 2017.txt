Title: Sam Kitajima Kimbrel   One Data Pipeline to Rule Them All   PyCon 2017
Publication date: 2017-05-21
Playlist: PyCon 2017
Description: 
	"Speaker: Sam Kitajima-Kimbrel

There are myriad data storage systems available for every use case imaginable, but letting application teams choose storage engines independently can lead to duplicated efforts and wheel reinvention. This talk will explore how to build a reusable data pipeline based on Kafka to support multiple applications, datasets, and use cases including archival, warehousing and analytics, stream and batch processing, and low-latency ""hot"" storage.

Slides can be found at: https://speakerdeck.com/pycon2017 and https://github.com/PyCon/2017-slides"
Captions: 
	00:00:04,220 --> 00:00:08,069
if you just walked in the room can you

00:00:06,540 --> 00:00:12,200
please find a seat as soon as possible

00:00:08,069 --> 00:00:12,200
we'd like to kick off real soon now

00:00:14,960 --> 00:00:26,670
quick run run yes

00:00:23,779 --> 00:00:29,519
okay it's time for the second last of

00:00:26,670 --> 00:00:31,710
the session talks here at PyCon 2017 our

00:00:29,519 --> 00:00:33,510
presenter is Sam Kido jima Kimbrel who

00:00:31,710 --> 00:00:35,550
is going to tell us about one data

00:00:33,510 --> 00:00:44,700
pipeline to rule them all please make

00:00:35,550 --> 00:00:46,440
him welcome all right thank you Chris so

00:00:44,700 --> 00:00:48,210
I will start this with a poll of the

00:00:46,440 --> 00:00:51,870
audience so please put your hand up if

00:00:48,210 --> 00:00:53,820
you have data great for the video that

00:00:51,870 --> 00:00:55,680
was most of the room keep your hand up

00:00:53,820 --> 00:00:58,079
if you know all the data sets that you

00:00:55,680 --> 00:00:59,670
have how they're accessed how they

00:00:58,079 --> 00:01:01,859
arrive at all the storage systems they

00:00:59,670 --> 00:01:04,619
live in how to combine them to drive new

00:01:01,859 --> 00:01:06,990
data or analyses for the video there are

00:01:04,619 --> 00:01:08,220
approximately zero at one hand to three

00:01:06,990 --> 00:01:12,210
okay

00:01:08,220 --> 00:01:13,530
so hi I'm Sam I lead the data platform

00:01:12,210 --> 00:01:16,020
du bateau leo where we build and

00:01:13,530 --> 00:01:18,150
maintain a unified system for storing

00:01:16,020 --> 00:01:19,890
retrieving and doing computation on all

00:01:18,150 --> 00:01:22,950
the data generated by all of Toledo's

00:01:19,890 --> 00:01:25,770
product systems and I start with a story

00:01:22,950 --> 00:01:27,810
so let's make up a team a team is

00:01:25,770 --> 00:01:29,070
relational database they set it up to

00:01:27,810 --> 00:01:30,960
store some data that's generated by

00:01:29,070 --> 00:01:33,000
their application and it works great

00:01:30,960 --> 00:01:35,280
until the end of the quarter rolls

00:01:33,000 --> 00:01:37,020
around and GMA's product manager wants

00:01:35,280 --> 00:01:38,369
to run queries to figure out how much

00:01:37,020 --> 00:01:40,500
their usage grew over the last quarter

00:01:38,369 --> 00:01:42,360
and since this database was built for

00:01:40,500 --> 00:01:44,490
online processing a transaction

00:01:42,360 --> 00:01:46,320
processing single row transactions these

00:01:44,490 --> 00:01:48,570
giant queries summing up millions of

00:01:46,320 --> 00:01:50,070
rows are very slow the product manager

00:01:48,570 --> 00:01:52,920
says can we put the data somewhere else

00:01:50,070 --> 00:01:54,869
then would make this analysis faster and

00:01:52,920 --> 00:01:57,180
so now we have a data warehouse if you

00:01:54,869 --> 00:01:58,649
don't want ETL ET l stands for extract

00:01:57,180 --> 00:02:00,450
transform load and it's basically the

00:01:58,649 --> 00:02:02,390
pattern of picking up data from one

00:02:00,450 --> 00:02:04,350
system it's stored in one format and

00:02:02,390 --> 00:02:06,090
transforming it into another schema

00:02:04,350 --> 00:02:07,530
potentially or another storage format

00:02:06,090 --> 00:02:09,629
that's better for some other workload

00:02:07,530 --> 00:02:12,959
like running analytics queries so we

00:02:09,629 --> 00:02:13,680
wrote a Python script to do this ETL job

00:02:12,959 --> 00:02:15,120
and took

00:02:13,680 --> 00:02:16,769
an afternoon maybe are we have a

00:02:15,120 --> 00:02:18,269
columnstore warehouse it's great for

00:02:16,769 --> 00:02:19,640
running those giant roll-up queries and

00:02:18,269 --> 00:02:22,349
it works pretty well

00:02:19,640 --> 00:02:24,269
so team B comes along and says hey your

00:02:22,349 --> 00:02:26,069
data warehouse it looks really cool can

00:02:24,269 --> 00:02:29,040
we put some stuff in here and so they or

00:02:26,069 --> 00:02:30,290
you the newly appointed custodian of the

00:02:29,040 --> 00:02:33,299
data warehouse welcome to your new job

00:02:30,290 --> 00:02:35,099
right another cron job to run a slightly

00:02:33,299 --> 00:02:37,709
different Python ETL script and copy

00:02:35,099 --> 00:02:40,109
their data in as well and so we're doing

00:02:37,709 --> 00:02:42,060
okay but it's somebody on Team a decides

00:02:40,109 --> 00:02:44,099
to change some pieces of schema to

00:02:42,060 --> 00:02:45,810
support a new feature but every forgets

00:02:44,099 --> 00:02:47,879
about the day warehouse until one week

00:02:45,810 --> 00:02:49,230
later when somebody on the accounting

00:02:47,879 --> 00:02:51,750
team and oh by the way when did you

00:02:49,230 --> 00:02:54,090
start using this says hey why isn't the

00:02:51,750 --> 00:02:56,540
reporting warehouse updating well crud

00:02:54,090 --> 00:02:59,159
somebody updates it and life goes on

00:02:56,540 --> 00:03:00,269
team C says hey we've got this Cassandra

00:02:59,159 --> 00:03:03,060
cluster that we want to dump into the

00:03:00,269 --> 00:03:05,400
warehouse could you help us team do we

00:03:03,060 --> 00:03:06,959
want in real-time spam detection but run

00:03:05,400 --> 00:03:09,659
Knightly training jobs for our model

00:03:06,959 --> 00:03:12,480
over all the historical data a team e

00:03:09,659 --> 00:03:14,310
Ken has full text search and just like

00:03:12,480 --> 00:03:15,989
that or ETL flow it started out as a

00:03:14,310 --> 00:03:17,940
couple simple Python scripts is not

00:03:15,989 --> 00:03:19,799
quite so simple anymore we have a bunch

00:03:17,940 --> 00:03:20,729
of cron jobs there moving data into our

00:03:19,799 --> 00:03:23,159
warehouse from all these different

00:03:20,729 --> 00:03:24,900
systems something rigged onto the side

00:03:23,159 --> 00:03:26,519
to do real-time stream processing on the

00:03:24,900 --> 00:03:27,959
data we need to do that for and we're

00:03:26,519 --> 00:03:31,079
running flat out just to keep up with

00:03:27,959 --> 00:03:33,599
schema changes and then finally the

00:03:31,079 --> 00:03:36,180
accounting team comes back why don't

00:03:33,599 --> 00:03:38,129
these two systems agree on how many API

00:03:36,180 --> 00:03:43,199
calls or page views or whatever is it to

00:03:38,129 --> 00:03:45,780
be sold we did last month Wow okay so

00:03:43,199 --> 00:03:47,129
that story is pretty abstract 'add but

00:03:45,780 --> 00:03:48,629
pretty much all these things have

00:03:47,129 --> 00:03:50,519
happened to us over the years at folio

00:03:48,629 --> 00:03:51,989
where our data warehousing systems and I

00:03:50,519 --> 00:03:55,739
bet they're familiar to a couple of you

00:03:51,989 --> 00:03:57,750
too so what happened from a 10,000 foot

00:03:55,739 --> 00:03:58,909
view we had everything working more or

00:03:57,750 --> 00:04:01,470
less with our data warehousing systems

00:03:58,909 --> 00:04:03,870
but it was costing us a lot in developer

00:04:01,470 --> 00:04:05,639
time and machine time when you look back

00:04:03,870 --> 00:04:08,129
at our infrastructure kind of legacy

00:04:05,639 --> 00:04:11,009
systems we are able to identify a number

00:04:08,129 --> 00:04:13,079
of high-level problems with this so

00:04:11,009 --> 00:04:15,150
first up we had multiple systems to use

00:04:13,079 --> 00:04:17,449
as data sources we had multiple data

00:04:15,150 --> 00:04:19,829
sinks places we wanted to get to and

00:04:17,449 --> 00:04:21,359
there is some code reuse but every new

00:04:19,829 --> 00:04:23,940
type of system required major work to

00:04:21,359 --> 00:04:25,800
add and even new data system systems we

00:04:23,940 --> 00:04:27,360
knew about had we hand configured we

00:04:25,800 --> 00:04:29,129
weren't quite at the worst case but the

00:04:27,360 --> 00:04:31,379
Changez clear if you have independent

00:04:29,129 --> 00:04:33,979
systems to be connected one by one the

00:04:31,379 --> 00:04:35,969
connections grow with N squared

00:04:33,979 --> 00:04:38,400
additionally we had no single source of

00:04:35,969 --> 00:04:40,080
truth for data schemas so change even

00:04:38,400 --> 00:04:41,219
was risky and required manual work to

00:04:40,080 --> 00:04:44,069
verify that things are working correctly

00:04:41,219 --> 00:04:45,629
and finally we had no guarantee

00:04:44,069 --> 00:04:47,099
guarantee that all the data was correct

00:04:45,629 --> 00:04:49,110
and all the systems that was supposed to

00:04:47,099 --> 00:04:50,879
appear in network and host failures as

00:04:49,110 --> 00:04:52,319
well as programming errors could

00:04:50,879 --> 00:04:56,099
manifest as data being wrong and one

00:04:52,319 --> 00:04:58,919
system or another so with that as kind

00:04:56,099 --> 00:05:00,449
of our problem space what do we want our

00:04:58,919 --> 00:05:02,219
replacement architecture to look like

00:05:00,449 --> 00:05:04,259
we looked at what the industry giants

00:05:02,219 --> 00:05:05,819
like LinkedIn and Netflix were doing we

00:05:04,259 --> 00:05:07,139
looked at our own capabilities whenever

00:05:05,819 --> 00:05:09,300
people we had the amount of machine time

00:05:07,139 --> 00:05:11,279
we had and this is what we came up with

00:05:09,300 --> 00:05:13,159
to guide our architecture as we built

00:05:11,279 --> 00:05:17,460
rebuilt it for developer productivity

00:05:13,159 --> 00:05:18,810
scalability and correctness so first up

00:05:17,460 --> 00:05:21,479
we concluded that there should be one

00:05:18,810 --> 00:05:23,099
and only one way to publish data into

00:05:21,479 --> 00:05:25,680
the new platform from any application

00:05:23,099 --> 00:05:26,849
generating it a lot of our prior

00:05:25,680 --> 00:05:28,889
headaches were brought on by

00:05:26,849 --> 00:05:30,990
inconsistencies and how we move data

00:05:28,889 --> 00:05:32,159
between systems and having to duplicate

00:05:30,990 --> 00:05:34,139
effort across them when we made changes

00:05:32,159 --> 00:05:35,669
that had to go but we needed a single

00:05:34,139 --> 00:05:37,469
system to be the canonical path for

00:05:35,669 --> 00:05:38,969
records regardless of how many places

00:05:37,469 --> 00:05:42,300
they had rewritten to or how many they

00:05:38,969 --> 00:05:43,949
came from on the sub side given that we

00:05:42,300 --> 00:05:45,960
needed to put the same data in multiple

00:05:43,949 --> 00:05:48,509
storage systems support all the ways we

00:05:45,960 --> 00:05:50,159
want to access it we couldn't dictate a

00:05:48,509 --> 00:05:51,690
single method to get data into them but

00:05:50,159 --> 00:05:54,360
we did feel it was important to provide

00:05:51,690 --> 00:05:57,389
common libraries and tooling to share as

00:05:54,360 --> 00:05:58,949
much of that logic as possible we also

00:05:57,389 --> 00:06:00,180
want to come in schemas I'm going to go

00:05:58,949 --> 00:06:01,860
into a lot of detail on this later but

00:06:00,180 --> 00:06:03,900
for now I'm just going to say that it's

00:06:01,860 --> 00:06:05,129
really easy a lot easier to ensure that

00:06:03,900 --> 00:06:07,289
everything works well together when

00:06:05,129 --> 00:06:09,120
there's a single authoritative source of

00:06:07,289 --> 00:06:13,080
what constitutes a valid record for any

00:06:09,120 --> 00:06:14,669
given type of data and finally we wanted

00:06:13,080 --> 00:06:16,589
a way to make sure that all the systems

00:06:14,669 --> 00:06:19,020
that purport to contain a given data set

00:06:16,589 --> 00:06:21,389
have the same data if something a record

00:06:19,020 --> 00:06:22,949
is present and correct in one system it

00:06:21,389 --> 00:06:26,819
needs to be the same everywhere else

00:06:22,949 --> 00:06:28,439
that it's expected to appear so since

00:06:26,819 --> 00:06:29,879
the title of this talk includes words

00:06:28,439 --> 00:06:31,349
data pipeline of you might have guessed

00:06:29,879 --> 00:06:34,199
that we chose to build an event pipeline

00:06:31,349 --> 00:06:36,419
in architecture from 10,000 feet up it

00:06:34,199 --> 00:06:38,759
looks something like this in an event

00:06:36,419 --> 00:06:40,440
sourcing architecture all data is

00:06:38,759 --> 00:06:41,190
modeled as an ordered series of events

00:06:40,440 --> 00:06:43,440
that happen

00:06:41,190 --> 00:06:46,140
for log structured data so web requests

00:06:43,440 --> 00:06:48,330
ad clicks API calls this is a very

00:06:46,140 --> 00:06:50,450
natural model for data where records

00:06:48,330 --> 00:06:52,770
change over time so configuration data

00:06:50,450 --> 00:06:54,540
things that change State it requires

00:06:52,770 --> 00:06:56,070
viewing your records as an ordered

00:06:54,540 --> 00:06:58,050
sequence of change events to those

00:06:56,070 --> 00:06:59,730
underlying rows from which you can

00:06:58,050 --> 00:07:02,610
reconstruct the original data set at any

00:06:59,730 --> 00:07:03,870
point in time so we have some sorts of

00:07:02,610 --> 00:07:06,120
events let's call it a web server and

00:07:03,870 --> 00:07:08,250
it's handling user requests and it

00:07:06,120 --> 00:07:10,050
generates a log event every time a user

00:07:08,250 --> 00:07:11,220
views a page and for whatever reason

00:07:10,050 --> 00:07:13,050
were interested in storing those in

00:07:11,220 --> 00:07:15,030
keeping access keeping keeping them

00:07:13,050 --> 00:07:17,250
around so we can analyze them later that

00:07:15,030 --> 00:07:19,500
server emits a record on to a system

00:07:17,250 --> 00:07:20,820
that stores all the events in the order

00:07:19,500 --> 00:07:24,180
they were received as a first in first

00:07:20,820 --> 00:07:26,190
out queue and every system is interested

00:07:24,180 --> 00:07:28,320
in that type of data subscribes that

00:07:26,190 --> 00:07:30,170
single stream and consumes the events in

00:07:28,320 --> 00:07:31,980
the same order they were published

00:07:30,170 --> 00:07:33,630
important to note here is that the

00:07:31,980 --> 00:07:35,220
consumer systems and also the producing

00:07:33,630 --> 00:07:37,500
systems don't have to be the same type

00:07:35,220 --> 00:07:38,760
of system one consumer of the data

00:07:37,500 --> 00:07:40,470
stream could be a relational database

00:07:38,760 --> 00:07:42,750
for writing near real-time access to

00:07:40,470 --> 00:07:44,160
individual rows well others could be

00:07:42,750 --> 00:07:45,930
writing a permanent archive of the data

00:07:44,160 --> 00:07:48,060
and kind of bulk storage formats to cold

00:07:45,930 --> 00:07:49,590
storage systems you could do real-time

00:07:48,060 --> 00:07:53,490
computation on the stream of data to

00:07:49,590 --> 00:07:55,350
derive new data sets and so on and just

00:07:53,490 --> 00:07:57,090
like we have multiple systems at the far

00:07:55,350 --> 00:07:59,040
side of the queue we have multiple

00:07:57,090 --> 00:08:01,050
distinct systems sending different types

00:07:59,040 --> 00:08:02,850
of events to their own streams and we

00:08:01,050 --> 00:08:05,070
set up each consuming system to only

00:08:02,850 --> 00:08:09,090
read out the particulars types of events

00:08:05,070 --> 00:08:10,320
that interested in and so Apache Kafka

00:08:09,090 --> 00:08:13,470
is the backbone of this architecture

00:08:10,320 --> 00:08:15,450
Italia Kafka is a horizontally scalable

00:08:13,470 --> 00:08:17,820
fault tolerant and very high throughput

00:08:15,450 --> 00:08:19,470
streaming message platform if you're not

00:08:17,820 --> 00:08:21,060
familiar with it Kafka originally did it

00:08:19,470 --> 00:08:22,800
LinkedIn and they currently use it to

00:08:21,060 --> 00:08:25,410
move over a trillion trillion of the T

00:08:22,800 --> 00:08:27,330
events per day it's become wildly

00:08:25,410 --> 00:08:29,040
popular since going open-source and is

00:08:27,330 --> 00:08:30,750
used by companies ranging from Netflix

00:08:29,040 --> 00:08:32,219
to Goldman Sachs and since I'm here

00:08:30,750 --> 00:08:36,270
talking about it and I work at Trulia we

00:08:32,219 --> 00:08:38,039
use it Attilio a kafka deployment

00:08:36,270 --> 00:08:39,900
consists of a set of broker nodes that

00:08:38,039 --> 00:08:41,640
host topics and topics are just those

00:08:39,900 --> 00:08:43,620
streams of ordered events that I told

00:08:41,640 --> 00:08:45,110
you about earlier brokers accept rights

00:08:43,620 --> 00:08:47,310
to the topics from producer nodes

00:08:45,110 --> 00:08:48,960
persisting the producer events to disk

00:08:47,310 --> 00:08:51,110
and replicating amongst themselves for

00:08:48,960 --> 00:08:53,310
durability

00:08:51,110 --> 00:08:55,060
consumer processes connect to the broker

00:08:53,310 --> 00:08:57,100
nodes which deliver those event

00:08:55,060 --> 00:09:00,070
topics in the or they were produced and

00:08:57,100 --> 00:09:01,990
as they process events consumers send

00:09:00,070 --> 00:09:03,490
back acknowledgments of how far along in

00:09:01,990 --> 00:09:05,050
the stream they are basically this is

00:09:03,490 --> 00:09:06,820
the event offset you can think of as

00:09:05,050 --> 00:09:08,110
literally as a file that you're

00:09:06,820 --> 00:09:09,970
streaming and some producers are

00:09:08,110 --> 00:09:11,770
appending to the file and consumers are

00:09:09,970 --> 00:09:13,750
following bahang law following along

00:09:11,770 --> 00:09:16,000
behind them reading from the file as the

00:09:13,750 --> 00:09:18,940
consumers proceed through the stream

00:09:16,000 --> 00:09:20,740
they commit offsets back to Kafka so

00:09:18,940 --> 00:09:22,570
complan knows how far along they got so

00:09:20,740 --> 00:09:24,940
if you lose a consumer process that

00:09:22,570 --> 00:09:27,190
restarts or dies or it gets replaced it

00:09:24,940 --> 00:09:28,570
starts back up and whatever you replace

00:09:27,190 --> 00:09:30,520
it with starts back up from the last

00:09:28,570 --> 00:09:32,620
offset that Kafka had seen committed for

00:09:30,520 --> 00:09:34,720
it so in that way Kafka guarantees at

00:09:32,620 --> 00:09:36,550
least once delivery of every message

00:09:34,720 --> 00:09:40,330
sent to a topic to all register consumer

00:09:36,550 --> 00:09:41,620
groups read topic qapla is pretty

00:09:40,330 --> 00:09:44,110
straightforward to upgrade but if you're

00:09:41,620 --> 00:09:46,690
into managed services Haru has a Kafka

00:09:44,110 --> 00:09:49,029
add-on and Amazon's Kinesis service

00:09:46,690 --> 00:09:53,589
exposes similar API in context what

00:09:49,029 --> 00:09:55,839
Kafka does so to recap what we've done

00:09:53,589 --> 00:09:58,779
so far to use Kafka as a durable

00:09:55,839 --> 00:10:00,580
guaranteed delivery eventbus we treat

00:09:58,779 --> 00:10:02,230
every data set as a separate topic of

00:10:00,580 --> 00:10:04,240
events produced by the application

00:10:02,230 --> 00:10:06,040
system to generate them and we connect

00:10:04,240 --> 00:10:08,140
the consumer as needed for every storage

00:10:06,040 --> 00:10:11,830
or processing system that needs to read

00:10:08,140 --> 00:10:13,570
that data so so far this is pretty

00:10:11,830 --> 00:10:15,700
standard stuff you can find dozens of

00:10:13,570 --> 00:10:18,180
blog posts on this from LinkedIn Netflix

00:10:15,700 --> 00:10:20,440
confluent and a lot of other companies

00:10:18,180 --> 00:10:21,700
I'd like to go into the things that we

00:10:20,440 --> 00:10:24,850
learned along the way that are a little

00:10:21,700 --> 00:10:26,380
less obvious from the blog posts so

00:10:24,850 --> 00:10:28,600
first up and this is the strongest

00:10:26,380 --> 00:10:29,920
opinion in this talk so here goes you

00:10:28,600 --> 00:10:32,170
should absolutely by all means

00:10:29,920 --> 00:10:34,330
definitely use a strongly typed

00:10:32,170 --> 00:10:36,400
serialization format with a defined

00:10:34,330 --> 00:10:39,610
schema and validation library on both

00:10:36,400 --> 00:10:40,690
sides of your event bus so to the story

00:10:39,610 --> 00:10:42,700
here there are a lot of systems out

00:10:40,690 --> 00:10:44,350
there of like MongoDB for example they

00:10:42,700 --> 00:10:46,930
just let you chuck arbitrary documents

00:10:44,350 --> 00:10:47,920
at them and this is tempting you can get

00:10:46,930 --> 00:10:51,100
started really quickly with these

00:10:47,920 --> 00:10:53,110
systems but there's a cost to this your

00:10:51,100 --> 00:10:55,480
schemas and the afore enforcement of

00:10:53,110 --> 00:10:58,000
those schemas moves from a single place

00:10:55,480 --> 00:11:00,130
to many scattered places in application

00:10:58,000 --> 00:11:02,470
code this opens the possibility of

00:11:00,130 --> 00:11:04,240
sending data or storing it that you

00:11:02,470 --> 00:11:07,330
can't process later with different

00:11:04,240 --> 00:11:08,529
versions of the code so to give an

00:11:07,330 --> 00:11:10,119
example

00:11:08,529 --> 00:11:11,619
if we have an application writing data

00:11:10,119 --> 00:11:13,389
somewhere and a batch job written

00:11:11,619 --> 00:11:14,529
potentially in a different language it

00:11:13,389 --> 00:11:16,689
picks it up and does something with it

00:11:14,529 --> 00:11:18,339
let's say it generates a report if

00:11:16,689 --> 00:11:20,049
somebody makes a change and remove the

00:11:18,339 --> 00:11:21,249
field from the data in the producing

00:11:20,049 --> 00:11:23,559
application without telling the

00:11:21,249 --> 00:11:24,639
maintainer of the batch job and the

00:11:23,559 --> 00:11:27,219
batch depends on that field

00:11:24,639 --> 00:11:30,099
kaboom now somebody has to go pick up

00:11:27,219 --> 00:11:30,939
the pieces oh yes sorry this is this is

00:11:30,099 --> 00:11:35,189
a blank because I'm doing all the

00:11:30,939 --> 00:11:37,839
talking I have no new content for you um

00:11:35,189 --> 00:11:39,759
so yeah so we dropped a field in the

00:11:37,839 --> 00:11:40,989
producing side and we didn't bother to

00:11:39,759 --> 00:11:42,939
tell the person who writes the batch job

00:11:40,989 --> 00:11:44,469
that degenerates reports and so if

00:11:42,939 --> 00:11:45,969
Oliver somebody's to go pick up the

00:11:44,469 --> 00:11:48,489
pieces fix the code on the batch and

00:11:45,969 --> 00:11:50,469
rerun it and that's if you're lucky if

00:11:48,489 --> 00:11:52,089
you're unlucky you get a silent kaboom

00:11:50,469 --> 00:11:53,949
in the form of incorrect missing or

00:11:52,089 --> 00:11:55,539
corrupt data and let's really hope that

00:11:53,949 --> 00:11:59,079
that data isn't driving your revenue

00:11:55,539 --> 00:12:00,879
numbers so there are a lot of

00:11:59,079 --> 00:12:03,249
open-source libraries for a schema

00:12:00,879 --> 00:12:05,199
validation and serialization please pick

00:12:03,249 --> 00:12:09,699
one and use it everywhere that you

00:12:05,199 --> 00:12:11,169
transmit data between systems totally we

00:12:09,699 --> 00:12:12,899
ended up choosing Avro which is an

00:12:11,169 --> 00:12:15,939
Apache project for a number of reasons

00:12:12,899 --> 00:12:18,149
ever has official cross-platform support

00:12:15,939 --> 00:12:20,229
for both the JVM and for Python and

00:12:18,149 --> 00:12:21,579
community supported library for just

00:12:20,229 --> 00:12:25,749
about every other language in existence

00:12:21,579 --> 00:12:27,309
the PHP Ruby go anything you want the

00:12:25,749 --> 00:12:29,139
Java library if you happen to use Java

00:12:27,309 --> 00:12:30,849
offers both dynamic and Static types so

00:12:29,139 --> 00:12:32,409
you can just deserialize there chris to

00:12:30,849 --> 00:12:35,019
get a map or you can get actual code

00:12:32,409 --> 00:12:36,759
generated java objects which will give

00:12:35,019 --> 00:12:38,799
you static type guarantees if you're

00:12:36,759 --> 00:12:41,559
using java that service or thing on

00:12:38,799 --> 00:12:44,199
python basically you get a map all right

00:12:41,559 --> 00:12:45,939
excuse me when you're deserializing the

00:12:44,199 --> 00:12:47,859
library automatically converts between

00:12:45,939 --> 00:12:49,929
compatible versions of the same schema

00:12:47,859 --> 00:12:52,839
so if you have version 1 if you record

00:12:49,929 --> 00:12:54,729
schema and you add a field to it that

00:12:52,839 --> 00:12:56,169
has a default value or you remove a

00:12:54,729 --> 00:12:58,089
field that had default value in version

00:12:56,169 --> 00:12:59,859
2 it will automatically give you

00:12:58,089 --> 00:13:01,359
whichever version you want to consume as

00:12:59,859 --> 00:13:02,819
regardless of what was actually appended

00:13:01,359 --> 00:13:05,379
to you in the serialized format and

00:13:02,819 --> 00:13:06,969
finally it offers a compact binary

00:13:05,379 --> 00:13:08,499
serialization format that doesn't

00:13:06,969 --> 00:13:10,389
include a copy of the schema tag to

00:13:08,499 --> 00:13:12,369
every record other systems do this and

00:13:10,389 --> 00:13:14,019
so you kind of that bloat of every

00:13:12,369 --> 00:13:15,519
record you send done the pipe has the

00:13:14,019 --> 00:13:16,509
schema tagged onto it so you have to

00:13:15,519 --> 00:13:18,429
register your schemas and know about

00:13:16,509 --> 00:13:20,319
them ahead of time but the trade-off you

00:13:18,429 --> 00:13:21,990
get fred is a smaller representation on

00:13:20,319 --> 00:13:25,959
the wire

00:13:21,990 --> 00:13:27,519
so let's we're here enforce the schemas

00:13:25,959 --> 00:13:28,810
and validate them when records are

00:13:27,519 --> 00:13:31,050
produced from the applications that

00:13:28,810 --> 00:13:33,250
produce the records without exception

00:13:31,050 --> 00:13:35,860
doing this gives you an extremely

00:13:33,250 --> 00:13:37,839
powerful guarantee every record coming

00:13:35,860 --> 00:13:39,130
down a topic is going to be valid for

00:13:37,839 --> 00:13:41,500
any consumer of that record to

00:13:39,130 --> 00:13:43,240
deserialize it keeps the onus of data

00:13:41,500 --> 00:13:45,279
producing our sorry data validation on

00:13:43,240 --> 00:13:47,290
the producers where it's easier to test

00:13:45,279 --> 00:13:48,970
an update since most your data types are

00:13:47,290 --> 00:13:50,260
only going to come from one or a small

00:13:48,970 --> 00:13:53,110
number of code bases but might be

00:13:50,260 --> 00:13:54,310
consumed by many more within a single

00:13:53,110 --> 00:13:56,170
topic you should only make

00:13:54,310 --> 00:13:58,660
backwards-compatible changes to a schema

00:13:56,170 --> 00:14:00,850
if you need to break compatibility start

00:13:58,660 --> 00:14:02,139
a new topic for the new version let your

00:14:00,850 --> 00:14:04,720
consumers run off the end and then

00:14:02,139 --> 00:14:06,370
migrate them over so with those rules

00:14:04,720 --> 00:14:08,019
and guarantees in place the worst that

00:14:06,370 --> 00:14:09,730
can happen if you miss a schema update

00:14:08,019 --> 00:14:11,199
on the consumer side is that you've

00:14:09,730 --> 00:14:12,670
delayed how posts in the data is

00:14:11,199 --> 00:14:16,240
available you can't break your

00:14:12,670 --> 00:14:18,670
processing and you can't lose data so

00:14:16,240 --> 00:14:20,170
the record schema alone is not the only

00:14:18,670 --> 00:14:22,600
information that's useful to know about

00:14:20,170 --> 00:14:23,709
a topic and the records in it so one of

00:14:22,600 --> 00:14:25,690
the things you need to know is given a

00:14:23,709 --> 00:14:27,010
Kafka topic name well what schema

00:14:25,690 --> 00:14:28,480
applies to the records in it and what

00:14:27,010 --> 00:14:31,329
versions should we expect to see of that

00:14:28,480 --> 00:14:32,980
schema coming down the line we also

00:14:31,329 --> 00:14:35,230
might want to know because distributed

00:14:32,980 --> 00:14:36,639
systems are tricky how to resolve

00:14:35,230 --> 00:14:38,560
duplicates right so in the face of

00:14:36,639 --> 00:14:40,569
network partitions and host failures we

00:14:38,560 --> 00:14:42,250
aren't guaranteed that will produce a

00:14:40,569 --> 00:14:44,440
core consumer record only once and

00:14:42,250 --> 00:14:46,660
what's more even ordering records can be

00:14:44,440 --> 00:14:49,060
tricky Costco only knows about the order

00:14:46,660 --> 00:14:50,290
of it records arrived at the brokers so

00:14:49,060 --> 00:14:51,910
if you have multiple hosts hosts

00:14:50,290 --> 00:14:53,230
producing onto the topic in parallel

00:14:51,910 --> 00:14:56,889
you're going to have to support the

00:14:53,230 --> 00:14:58,899
ordering out when you consume to do that

00:14:56,889 --> 00:15:00,550
we need to do a couple things we need to

00:14:58,899 --> 00:15:02,560
know what uniquely identifies our record

00:15:00,550 --> 00:15:05,050
and then after that we have to know what

00:15:02,560 --> 00:15:06,639
logic we apply to choose a winner or

00:15:05,050 --> 00:15:09,339
merge conflicting versions of Records

00:15:06,639 --> 00:15:12,550
with the same ID so another tip here

00:15:09,339 --> 00:15:14,709
just for doing IDs and ordering um wall

00:15:12,550 --> 00:15:16,540
clocks if you haven't heard are not to

00:15:14,709 --> 00:15:17,889
be trusted again across multiple hosts

00:15:16,540 --> 00:15:20,410
so don't just use the latest physical

00:15:17,889 --> 00:15:21,610
timestamp there are things called vector

00:15:20,410 --> 00:15:23,740
clocks I unfortunately don't have a lot

00:15:21,610 --> 00:15:25,810
of time to get into them but those

00:15:23,740 --> 00:15:27,310
require some sort of serialization and

00:15:25,810 --> 00:15:28,540
locking for concurrent operations in the

00:15:27,310 --> 00:15:29,740
same object there's a lot of reading

00:15:28,540 --> 00:15:31,810
about those I'm happy to provide links

00:15:29,740 --> 00:15:34,389
to anybody who wants after

00:15:31,810 --> 00:15:36,069
and finally it's useful to know in

00:15:34,389 --> 00:15:38,259
addition to how we duplicate a data set

00:15:36,069 --> 00:15:40,810
um how do we verify that this data is

00:15:38,259 --> 00:15:42,490
complete and correct so we can reuse our

00:15:40,810 --> 00:15:45,160
source of uniqueness right the unique

00:15:42,490 --> 00:15:46,720
key we specified before on this topic

00:15:45,160 --> 00:15:48,730
for a first pass at reconciliation

00:15:46,720 --> 00:15:50,439
across different consumer systems right

00:15:48,730 --> 00:15:51,730
so count unique is always a good first

00:15:50,439 --> 00:15:53,139
step if you've got the same number of

00:15:51,730 --> 00:15:55,480
Records and same place you're likely to

00:15:53,139 --> 00:15:56,769
have the same set of Records if there

00:15:55,480 --> 00:15:58,180
are additional checks we can form right

00:15:56,769 --> 00:16:00,249
maybe you want to sum up the price of

00:15:58,180 --> 00:16:01,720
all the widgets you sold you can do that

00:16:00,249 --> 00:16:03,279
right so you can specify an aggregate

00:16:01,720 --> 00:16:05,139
operation to run over a data set and

00:16:03,279 --> 00:16:06,790
which feels to use it for and then just

00:16:05,139 --> 00:16:10,209
verify across all the places you store

00:16:06,790 --> 00:16:11,709
your data that that matches so armed

00:16:10,209 --> 00:16:13,360
with that I've covered what we started

00:16:11,709 --> 00:16:15,100
off with what we disliked about our

00:16:13,360 --> 00:16:16,899
original systems what we wanted out of

00:16:15,100 --> 00:16:18,639
our new architecture and the core

00:16:16,899 --> 00:16:20,709
abstractions that you've got in a casket

00:16:18,639 --> 00:16:23,529
based event I plane which is also

00:16:20,709 --> 00:16:24,910
referred to as a unified blog and next I

00:16:23,529 --> 00:16:26,769
want to go into some of the libraries

00:16:24,910 --> 00:16:28,180
and systems we built to augment our Casa

00:16:26,769 --> 00:16:32,199
cluster and connected to our data

00:16:28,180 --> 00:16:35,499
systems so first we have a metadata

00:16:32,199 --> 00:16:37,209
registry API so storing those record

00:16:35,499 --> 00:16:38,680
schemas that I mentioned and all of the

00:16:37,209 --> 00:16:40,720
additional metadata about uniqueness

00:16:38,680 --> 00:16:42,819
ordering and correctness in a registry

00:16:40,720 --> 00:16:44,439
gives us programmatic access to that

00:16:42,819 --> 00:16:46,689
data from any system that produces or

00:16:44,439 --> 00:16:48,309
consumed records so our metadata

00:16:46,689 --> 00:16:50,379
registry doesn't actually handle any

00:16:48,309 --> 00:16:52,059
data records itself it just says here's

00:16:50,379 --> 00:16:54,309
a schema for this type of record and

00:16:52,059 --> 00:16:56,199
that extra metadata about unique case

00:16:54,309 --> 00:16:58,809
and ordering validates that when you

00:16:56,199 --> 00:17:00,639
create a new version of a schema for a

00:16:58,809 --> 00:17:02,500
topic is elevates that the new version

00:17:00,639 --> 00:17:03,910
is compatible with the old ones and then

00:17:02,500 --> 00:17:06,069
just hands that metadata back out to any

00:17:03,910 --> 00:17:09,130
system that needs it so for example on

00:17:06,069 --> 00:17:10,270
the producer side you might want to say

00:17:09,130 --> 00:17:11,770
am I using the right schema for this

00:17:10,270 --> 00:17:13,809
topic so you can validate records before

00:17:11,770 --> 00:17:15,490
you send them koepcke comes with

00:17:13,809 --> 00:17:16,990
producer and consumer implementations

00:17:15,490 --> 00:17:19,659
for a lot of programming languages but

00:17:16,990 --> 00:17:21,250
like Kafka itself they work on the level

00:17:19,659 --> 00:17:22,510
of byte streams the Costco brokers don't

00:17:21,250 --> 00:17:24,370
know anything about our schemas they

00:17:22,510 --> 00:17:27,130
just you ever record as a chunk of mites

00:17:24,370 --> 00:17:28,960
so we built a wrapper around the Kafka

00:17:27,130 --> 00:17:31,419
libraries for systems that need to

00:17:28,960 --> 00:17:33,539
produce to handle that serialization and

00:17:31,419 --> 00:17:35,610
validation stuff so the producer library

00:17:33,539 --> 00:17:38,289
accepts the ever record objects

00:17:35,610 --> 00:17:39,399
validates that it conforms to the schema

00:17:38,289 --> 00:17:42,730
for the topic you're trying to put it

00:17:39,399 --> 00:17:44,110
onto and C realizes it for you the

00:17:42,730 --> 00:17:45,410
consumer library basically does this in

00:17:44,110 --> 00:17:47,660
Reverse right says uh-oh

00:17:45,410 --> 00:17:50,030
consuming this topic looks up the schema

00:17:47,660 --> 00:17:51,890
for that topic and then DC realizes the

00:17:50,030 --> 00:17:53,450
records using the appropriate schema and

00:17:51,890 --> 00:17:57,500
gives it back a native object or addicts

00:17:53,450 --> 00:17:58,850
for your application code Tulio has an

00:17:57,500 --> 00:18:01,070
extremely polyglot development

00:17:58,850 --> 00:18:03,230
environment we run a lot of Python a lot

00:18:01,070 --> 00:18:05,060
of Java and Scala some PHP and there's

00:18:03,230 --> 00:18:07,520
even a little bit of Ruby noting go

00:18:05,060 --> 00:18:09,140
floating around our data pipeline

00:18:07,520 --> 00:18:11,210
libraries so the official ones wrapped

00:18:09,140 --> 00:18:13,790
around the direct Kafka producer library

00:18:11,210 --> 00:18:15,380
we support Python and Java but porting

00:18:13,790 --> 00:18:16,370
the logic to four more platforms would

00:18:15,380 --> 00:18:17,240
have been a lot of effort for

00:18:16,370 --> 00:18:19,850
diminishing returns

00:18:17,240 --> 00:18:21,770
we also totally already have very well

00:18:19,850 --> 00:18:23,300
defined and well supported standards for

00:18:21,770 --> 00:18:25,640
internal rest api's with json

00:18:23,300 --> 00:18:27,980
serialization so we built a simple

00:18:25,640 --> 00:18:29,390
service that takes that act of producing

00:18:27,980 --> 00:18:31,850
to a cosmic topic and doing the

00:18:29,390 --> 00:18:33,350
validation before you do so and just put

00:18:31,850 --> 00:18:36,290
an HTTP interface on it and so anything

00:18:33,350 --> 00:18:38,210
that is not Python or Java can just go

00:18:36,290 --> 00:18:41,600
record that this producer API as JSON

00:18:38,210 --> 00:18:43,760
and they get the same guarantees so

00:18:41,600 --> 00:18:46,400
that's what we did for actually directly

00:18:43,760 --> 00:18:47,510
producing and consuming from Kafka

00:18:46,400 --> 00:18:49,340
what do we do with everything once

00:18:47,510 --> 00:18:51,710
you've got it the records into Kafka now

00:18:49,340 --> 00:18:53,990
for us this break down into roughly six

00:18:51,710 --> 00:18:56,060
types of system so first we can archive

00:18:53,990 --> 00:18:59,090
datasets to an expensive and scalable

00:18:56,060 --> 00:19:01,070
cold storage we this is s3 for us so we

00:18:59,090 --> 00:19:02,630
use this primary archive data to power

00:19:01,070 --> 00:19:04,760
through more use cases so we can load it

00:19:02,630 --> 00:19:06,890
into data warehouses for doing analysis

00:19:04,760 --> 00:19:08,750
on structured subsets of that data we

00:19:06,890 --> 00:19:10,160
can run batch processing jobs as part of

00:19:08,750 --> 00:19:12,050
our engineering workflow right to

00:19:10,160 --> 00:19:14,360
transform arbitrary large amounts of

00:19:12,050 --> 00:19:16,850
data into other datasets derived

00:19:14,360 --> 00:19:18,290
analysis and we can do ad hoc analysis

00:19:16,850 --> 00:19:20,870
of the archive data without needing to

00:19:18,290 --> 00:19:22,880
load it into a warehouse next we do

00:19:20,870 --> 00:19:24,740
stream processing since Kafka is high

00:19:22,880 --> 00:19:26,840
throughput and low latency as low

00:19:24,740 --> 00:19:28,250
latency is sub-second right 10

00:19:26,840 --> 00:19:30,320
milliseconds 50 milliseconds end-to-end

00:19:28,250 --> 00:19:32,360
you can connect stream applications

00:19:30,320 --> 00:19:34,880
directly to Kafka and process records in

00:19:32,360 --> 00:19:36,560
very close to real-time and finally we

00:19:34,880 --> 00:19:38,030
can connect traditional transaction

00:19:36,560 --> 00:19:40,010
processing databases like my sequel or

00:19:38,030 --> 00:19:42,380
elasticsearch to provide access to a

00:19:40,010 --> 00:19:44,150
limited amount of recent data with very

00:19:42,380 --> 00:19:46,520
low into n latency you know single row

00:19:44,150 --> 00:19:50,270
access limited amounts of search but for

00:19:46,520 --> 00:19:51,080
your kind of your online access so I'm

00:19:50,270 --> 00:19:54,170
going to go through these in more detail

00:19:51,080 --> 00:19:55,610
starting with archival so our primary

00:19:54,170 --> 00:19:56,120
data archive is something we call truly

00:19:55,610 --> 00:19:58,160
wellfest

00:19:56,120 --> 00:19:59,090
which is really a fancy name for some

00:19:58,160 --> 00:20:01,760
standards and made up about

00:19:59,090 --> 00:20:03,500
to organize data in s3 it's essentially

00:20:01,760 --> 00:20:05,210
a data Lake which is a term that some

00:20:03,500 --> 00:20:06,650
data architects made up to describe what

00:20:05,210 --> 00:20:08,090
happens when you dump all of your data

00:20:06,650 --> 00:20:10,130
into one place so that you can extract

00:20:08,090 --> 00:20:12,140
it for in chunks or for the processing

00:20:10,130 --> 00:20:14,600
or analysis and that looks something

00:20:12,140 --> 00:20:16,280
like this the incoming records from

00:20:14,600 --> 00:20:18,920
Kafka for a given topic are consumed by

00:20:16,280 --> 00:20:20,960
a system that we call copycat Kafka

00:20:18,920 --> 00:20:22,670
brokers being a finite set of machines

00:20:20,960 --> 00:20:24,380
you don't have infinite storage space

00:20:22,670 --> 00:20:27,620
and so only retain a fixed window of

00:20:24,380 --> 00:20:30,080
time for each topic for the data expires

00:20:27,620 --> 00:20:31,690
in this archive cough or sorry deleted

00:20:30,080 --> 00:20:34,910
from the casket brokers at the back end

00:20:31,690 --> 00:20:38,770
so copycat has one job to copy byte for

00:20:34,910 --> 00:20:41,240
byte entire Kafka topics into Amazon s3

00:20:38,770 --> 00:20:43,280
it's a Kafka connect application

00:20:41,240 --> 00:20:45,230
connected a framework is distributed

00:20:43,280 --> 00:20:47,300
with Kafka and it's designed for exactly

00:20:45,230 --> 00:20:49,100
this operation of consuming data from a

00:20:47,300 --> 00:20:50,630
Kafka topic and writing it somewhere

00:20:49,100 --> 00:20:52,160
else or reading data from another source

00:20:50,630 --> 00:20:54,800
system and producing it into account a

00:20:52,160 --> 00:20:56,600
topic and we use connect for pretty much

00:20:54,800 --> 00:20:58,940
all of our sink systems because it's

00:20:56,600 --> 00:21:01,490
just very easy to understand pattern a

00:20:58,940 --> 00:21:02,720
copycat output is organized by the topic

00:21:01,490 --> 00:21:04,280
and the partition so we might have

00:21:02,720 --> 00:21:06,170
widgets and then partition three of the

00:21:04,280 --> 00:21:08,510
widgets and then the date in the hour

00:21:06,170 --> 00:21:09,770
and then the highest offset in the Kafka

00:21:08,510 --> 00:21:11,840
batch so it's flush into that file

00:21:09,770 --> 00:21:13,160
most of our copy had consumer is

00:21:11,840 --> 00:21:15,650
basically a key nearly about five

00:21:13,160 --> 00:21:19,430
minutes of records in chunks and flush

00:21:15,650 --> 00:21:21,080
those and files to s3 before we've done

00:21:19,430 --> 00:21:22,310
anything else with this data a copycat

00:21:21,080 --> 00:21:24,770
has already given us a really neat

00:21:22,310 --> 00:21:26,210
capability since the output is a perfect

00:21:24,770 --> 00:21:28,070
copy by four bytes over the original

00:21:26,210 --> 00:21:30,710
Kafka topic we can actually just take

00:21:28,070 --> 00:21:32,720
any subset of that the time organized

00:21:30,710 --> 00:21:34,880
stream of data and replay it back in

00:21:32,720 --> 00:21:36,920
Kafka like we've gone back in time so

00:21:34,880 --> 00:21:38,570
this comes up if somebody finds a logic

00:21:36,920 --> 00:21:41,360
bug in their processing system for

00:21:38,570 --> 00:21:42,380
example they fix it and then they roll

00:21:41,360 --> 00:21:43,880
out the new version of that code and

00:21:42,380 --> 00:21:45,950
they say actually I want to reprocess

00:21:43,880 --> 00:21:48,470
three months so all we do is go into s3

00:21:45,950 --> 00:21:50,300
pull out those three months of copycat

00:21:48,470 --> 00:21:51,440
data and just dump it into a Kafka topic

00:21:50,300 --> 00:21:53,120
and they can reprocess everything

00:21:51,440 --> 00:21:57,230
without having to deal with going to

00:21:53,120 --> 00:21:59,420
find that data themselves but copycat is

00:21:57,230 --> 00:22:01,130
just the first step because its output

00:21:59,420 --> 00:22:02,720
is not guaranteed to be unique or in

00:22:01,130 --> 00:22:04,730
order since we've got producers running

00:22:02,720 --> 00:22:07,370
in parallel and as I said earlier it

00:22:04,730 --> 00:22:09,020
distributed systems we run a system

00:22:07,370 --> 00:22:10,850
called copy dogs to clean it up it's

00:22:09,020 --> 00:22:13,450
called copy dog because it chases the

00:22:10,850 --> 00:22:13,450
cat I don't know

00:22:13,800 --> 00:22:18,450
it's a spark job and it organizes the

00:22:16,350 --> 00:22:19,980
raw topic data that copycat since s3 and

00:22:18,450 --> 00:22:21,420
so this is the first place in our system

00:22:19,980 --> 00:22:23,190
where that topic metadata really comes

00:22:21,420 --> 00:22:25,470
into useful about deduplication and

00:22:23,190 --> 00:22:25,920
ordering as configuration for copy dog

00:22:25,470 --> 00:22:28,350
jobs

00:22:25,920 --> 00:22:30,570
so copy drive uses its knowledge of how

00:22:28,350 --> 00:22:32,550
to sort and merge records to mate a

00:22:30,570 --> 00:22:36,720
verified sorted and duplicated archives

00:22:32,550 --> 00:22:39,390
of each topic data also to s3 and so it

00:22:36,720 --> 00:22:42,390
actually has two inputs one of its input

00:22:39,390 --> 00:22:44,640
is the latest input file from copycat

00:22:42,390 --> 00:22:46,530
since last run and then the other one is

00:22:44,640 --> 00:22:47,190
the existing set of data in the clean

00:22:46,530 --> 00:22:49,890
output set

00:22:47,190 --> 00:22:51,960
so copy get sort of copy dog excuse me

00:22:49,890 --> 00:22:53,370
first takes a set of new records since

00:22:51,960 --> 00:22:54,900
the last run and source it using the

00:22:53,370 --> 00:22:57,630
sort key we configured as a metadata

00:22:54,900 --> 00:22:59,040
then identifies a set of date prefixes

00:22:57,630 --> 00:23:00,840
for which it found new records in the

00:22:59,040 --> 00:23:03,300
incoming batch reloads all of the

00:23:00,840 --> 00:23:04,980
existing records for those dates finds

00:23:03,300 --> 00:23:07,290
duplicates using the configured unique

00:23:04,980 --> 00:23:08,310
key on the metadata system and merges

00:23:07,290 --> 00:23:10,320
them appropriately according to the

00:23:08,310 --> 00:23:12,120
specified rules and then finally it

00:23:10,320 --> 00:23:15,570
writes out all the change date prefixes

00:23:12,120 --> 00:23:16,860
to s3 and since s3 is almost in HDFS but

00:23:15,570 --> 00:23:19,290
not quite and it doesn't have an atomic

00:23:16,860 --> 00:23:21,150
move operation there's actually a system

00:23:19,290 --> 00:23:22,350
of version file names and a metadata

00:23:21,150 --> 00:23:24,390
file that points to the current version

00:23:22,350 --> 00:23:26,250
which keeps other SPARC job as an other

00:23:24,390 --> 00:23:27,630
downstream consumers seeing inconsistent

00:23:26,250 --> 00:23:28,950
view of the data we don't update the

00:23:27,630 --> 00:23:32,610
version pointer until we finished

00:23:28,950 --> 00:23:34,230
flushing all the files back out so the

00:23:32,610 --> 00:23:36,750
output of this is actually our true data

00:23:34,230 --> 00:23:39,150
archive every record produced to every

00:23:36,750 --> 00:23:41,250
Kafka topic is in this s3 bucket exactly

00:23:39,150 --> 00:23:43,140
once in the latest state we've seen for

00:23:41,250 --> 00:23:44,970
Don Kafka and sorted accorded that the

00:23:43,140 --> 00:23:46,380
specified ordering for the data set in

00:23:44,970 --> 00:23:48,420
the pivotal element of both based

00:23:46,380 --> 00:23:50,790
systems in order to make the Data

00:23:48,420 --> 00:23:52,950
Platform group go fast if developers is

00:23:50,790 --> 00:23:55,140
that they're 100% configuration driven

00:23:52,950 --> 00:23:57,750
the logic is reusable across data types

00:23:55,140 --> 00:23:59,280
and the metadata API provides the

00:23:57,750 --> 00:24:01,680
configuration we need to specify the

00:23:59,280 --> 00:24:03,540
input and output directories the schemas

00:24:01,680 --> 00:24:05,400
and the story and merge strategies we

00:24:03,540 --> 00:24:07,470
can provision new copy-cat tasks with an

00:24:05,400 --> 00:24:09,780
API call to the Cal connect group and

00:24:07,470 --> 00:24:13,920
copy dog jobs just require pushing new

00:24:09,780 --> 00:24:15,660
configuration into our task scheduler so

00:24:13,920 --> 00:24:17,520
this archive of data is now usable for

00:24:15,660 --> 00:24:20,180
three things first we can load it into

00:24:17,520 --> 00:24:23,100
data warehouses for interactive querying

00:24:20,180 --> 00:24:25,330
so we use Amazon redshift as a warehouse

00:24:23,100 --> 00:24:27,730
engine a redshift is a managed to column

00:24:25,330 --> 00:24:30,190
a database that speaks Postgres so RBI

00:24:27,730 --> 00:24:32,200
analysts a little bit they just write

00:24:30,190 --> 00:24:34,210
sequel audit it's compatible with any

00:24:32,200 --> 00:24:36,520
visual bi dashboard system that speaks

00:24:34,210 --> 00:24:38,800
sequel and it's optimized for bulk

00:24:36,520 --> 00:24:40,240
loading of data from s3 we built a bunch

00:24:38,800 --> 00:24:41,740
of custom tooling around the management

00:24:40,240 --> 00:24:43,300
API so that it's easily provision

00:24:41,740 --> 00:24:45,460
multiple redshift clusters and generate

00:24:43,300 --> 00:24:47,080
schedules based on our metadata to load

00:24:45,460 --> 00:24:49,540
data from s3 into one or more of the

00:24:47,080 --> 00:24:51,100
warehouses every cluster has a different

00:24:49,540 --> 00:24:52,510
set of data based on who is using it so

00:24:51,100 --> 00:24:54,670
for example the finance team needs all

00:24:52,510 --> 00:24:55,660
the transaction data but engineering

00:24:54,670 --> 00:24:58,600
doesn't need to see that they probably

00:24:55,660 --> 00:25:00,130
shouldn't the ops team might want to

00:24:58,600 --> 00:25:04,270
know all the phone number configuration

00:25:00,130 --> 00:25:05,710
data and PM is probably want API logs so

00:25:04,270 --> 00:25:07,450
every cluster has a different subset of

00:25:05,710 --> 00:25:09,160
the data based on their needs and let's

00:25:07,450 --> 00:25:10,780
just let that this lets us keep those

00:25:09,160 --> 00:25:12,580
clusters small and performing optimally

00:25:10,780 --> 00:25:13,840
for those these cases and like I said

00:25:12,580 --> 00:25:15,250
keeps a sensitive financial information

00:25:13,840 --> 00:25:16,260
away from people who don't need to see

00:25:15,250 --> 00:25:18,970
it

00:25:16,260 --> 00:25:20,470
and we can also use our primary archives

00:25:18,970 --> 00:25:22,960
to drive batch processing for derive

00:25:20,470 --> 00:25:25,090
data and ad-hoc analysis so this was

00:25:22,960 --> 00:25:26,680
spark again spark has a very

00:25:25,090 --> 00:25:28,210
well-supported espree data driver and

00:25:26,680 --> 00:25:29,560
we've extended it support the

00:25:28,210 --> 00:25:31,900
organizational and schema metadata

00:25:29,560 --> 00:25:33,190
available to us engineering teams that

00:25:31,900 --> 00:25:35,500
need to process large amounts of data

00:25:33,190 --> 00:25:37,630
just write dedicated spark jobs and use

00:25:35,500 --> 00:25:40,600
the architecture to schedule them so at

00:25:37,630 --> 00:25:42,220
the manage platform that we provide we

00:25:40,600 --> 00:25:44,170
also use spark for ad-hoc processing so

00:25:42,220 --> 00:25:46,180
I'm guessing most people here are

00:25:44,170 --> 00:25:47,290
familiar with Jupiter in a book but if

00:25:46,180 --> 00:25:48,940
you're not that's an open source project

00:25:47,290 --> 00:25:51,340
for using and sharing interactive data

00:25:48,940 --> 00:25:53,050
in notebooks the plus engineers and PMS

00:25:51,340 --> 00:25:54,850
query large amounts of data from s3

00:25:53,050 --> 00:25:57,190
without having to load it into a

00:25:54,850 --> 00:25:59,230
warehouse a cluster first the tends to

00:25:57,190 --> 00:26:00,550
come up during outage response where we

00:25:59,230 --> 00:26:01,840
might find something and say oh well how

00:26:00,550 --> 00:26:03,790
long has this been broken for how many

00:26:01,840 --> 00:26:04,900
how many API call API calls are actually

00:26:03,790 --> 00:26:07,390
affected by this I mean go crunch

00:26:04,900 --> 00:26:09,070
through six a six month worth of logs so

00:26:07,390 --> 00:26:10,690
added response and if you're prototyping

00:26:09,070 --> 00:26:12,880
new batch jobs right so you can just

00:26:10,690 --> 00:26:13,960
write some spark sequel queries and fire

00:26:12,880 --> 00:26:15,490
them off and see if you get the right

00:26:13,960 --> 00:26:19,360
result before you go and code it into a

00:26:15,490 --> 00:26:20,530
full-on spark job and I'm going to sound

00:26:19,360 --> 00:26:22,090
like a broken record right now but we

00:26:20,530 --> 00:26:24,400
also use spark and streaming mode to do

00:26:22,090 --> 00:26:25,900
stream processing in real time so you

00:26:24,400 --> 00:26:27,870
can connect your spark tasks in

00:26:25,900 --> 00:26:29,830
streaming mode directly to a kafka topic

00:26:27,870 --> 00:26:31,390
processor data and real time animate

00:26:29,830 --> 00:26:33,160
results back into a new topic for

00:26:31,390 --> 00:26:35,770
storage elsewhere or you know real-time

00:26:33,160 --> 00:26:37,600
- boarding whatever you want and finally

00:26:35,770 --> 00:26:39,429
we can consume directly from kafka

00:26:37,600 --> 00:26:41,409
topics and write the data to online

00:26:39,429 --> 00:26:43,179
systems and this is about as simple as

00:26:41,409 --> 00:26:45,429
it sounds right so we run a copper

00:26:43,179 --> 00:26:47,409
connect service they copy data from a

00:26:45,429 --> 00:26:49,269
Kafka topic into a database like my

00:26:47,409 --> 00:26:51,580
sequel or Cassandra or Postgres or

00:26:49,269 --> 00:26:52,989
elasticsearch as it comes in and you can

00:26:51,580 --> 00:26:57,460
query it in real time from other systems

00:26:52,989 --> 00:26:59,049
to satisfy user requests okay so we have

00:26:57,460 --> 00:27:00,309
our data in our pipeline we've written

00:26:59,049 --> 00:27:02,499
it down as a bunch of places we've done

00:27:00,309 --> 00:27:03,700
some computation on it how do we know

00:27:02,499 --> 00:27:07,419
that the data is correct and all the

00:27:03,700 --> 00:27:09,159
places it has to be so first off as I

00:27:07,419 --> 00:27:11,289
mentioned earlier Kafka tracks consumer

00:27:09,159 --> 00:27:13,570
offsets so as the consumers are

00:27:11,289 --> 00:27:15,969
processing the topic they write back to

00:27:13,570 --> 00:27:20,109
Kafka and say I'm I'm good your offset 1

00:27:15,969 --> 00:27:22,389
2 3 4 5 6 7 8 9 0 and those offsets are

00:27:20,109 --> 00:27:24,429
themselves available as Kafka streams so

00:27:22,389 --> 00:27:25,899
we can build lightweight apps to consume

00:27:24,429 --> 00:27:27,700
the offset data as it's running through

00:27:25,899 --> 00:27:30,099
the system and monitor the progress of

00:27:27,700 --> 00:27:31,899
every consumer group so if a particular

00:27:30,099 --> 00:27:33,609
consumer system gets stuck or slows down

00:27:31,899 --> 00:27:35,080
we can set up an alert and say go

00:27:33,609 --> 00:27:37,479
provision some more capacity here go fix

00:27:35,080 --> 00:27:39,909
what happens for data correctness itself

00:27:37,479 --> 00:27:42,369
we use our topic metadata to do

00:27:39,909 --> 00:27:44,259
lightweight smoke testing so knowing how

00:27:42,369 --> 00:27:46,149
to unit identify unique records with our

00:27:44,259 --> 00:27:48,279
metadata means that we can ask your data

00:27:46,149 --> 00:27:50,139
stores to count them up and we can add

00:27:48,279 --> 00:27:51,669
additional checks for example you know

00:27:50,139 --> 00:27:53,799
how much did we make in widget sales

00:27:51,669 --> 00:27:56,139
yesterday or even you can just do a full

00:27:53,799 --> 00:27:59,259
root X sum its ensure that the different

00:27:56,139 --> 00:28:02,440
storage systems agree with each other so

00:27:59,259 --> 00:28:04,359
that's about it I'm a three boob so

00:28:02,440 --> 00:28:06,249
we've seen how an event oriented data

00:28:04,359 --> 00:28:08,289
pipeline architecture built around Kafka

00:28:06,249 --> 00:28:10,330
as reliable on high performance data bus

00:28:08,289 --> 00:28:12,339
gives us a strong foundation for

00:28:10,330 --> 00:28:13,599
reasoning about and planning data flows

00:28:12,339 --> 00:28:15,460
between systems that produce data

00:28:13,599 --> 00:28:17,950
systems that process and consume data

00:28:15,460 --> 00:28:20,289
and systems that store data we've talked

00:28:17,950 --> 00:28:21,820
about why strongly-typed data using Avro

00:28:20,289 --> 00:28:23,259
with a single source of screamo through

00:28:21,820 --> 00:28:25,899
single source of truth with schemas

00:28:23,259 --> 00:28:27,249
excuse me it's important and why your

00:28:25,899 --> 00:28:28,929
data processing systems will benefit

00:28:27,249 --> 00:28:30,070
from that and I briefly touched on how

00:28:28,929 --> 00:28:31,570
the properties of these systems both

00:28:30,070 --> 00:28:33,279
inherently guarantee that data is

00:28:31,570 --> 00:28:35,139
delivered everywhere that needs to be

00:28:33,279 --> 00:28:36,460
and how to build lightweight monitoring

00:28:35,139 --> 00:28:39,039
systems to verify that that's actually

00:28:36,460 --> 00:28:40,690
the case so let's go back to our story

00:28:39,039 --> 00:28:41,830
from beginning the talk instead of that

00:28:40,690 --> 00:28:43,679
growing web of connections between

00:28:41,830 --> 00:28:46,059
sources and sinks we have a single path

00:28:43,679 --> 00:28:47,889
data flows in terms of events through

00:28:46,059 --> 00:28:49,359
Kafka and every system that needs a

00:28:47,889 --> 00:28:51,519
particular type of data can connect and

00:28:49,359 --> 00:28:53,400
listen to it when you change the schema

00:28:51,519 --> 00:28:54,600
that system is connected to the data

00:28:53,400 --> 00:28:56,250
seemlessly converts data to the

00:28:54,600 --> 00:28:57,540
diversion they expect or they gracefully

00:28:56,250 --> 00:28:58,980
process to the end of the topic with the

00:28:57,540 --> 00:29:00,600
old version can be updated to pick up a

00:28:58,980 --> 00:29:02,220
new version the end of the year rolls

00:29:00,600 --> 00:29:04,140
around the PM's just request temporary

00:29:02,220 --> 00:29:07,560
redshift clusters to pull in their logs

00:29:04,140 --> 00:29:09,000
and do that numbers for a slide decks we

00:29:07,560 --> 00:29:10,320
try out new data stories all the time we

00:29:09,000 --> 00:29:12,840
drop them in as new flavors of data

00:29:10,320 --> 00:29:14,010
consumers and you've got that spam

00:29:12,840 --> 00:29:15,540
detection code that I mentioned in the

00:29:14,010 --> 00:29:17,250
story earlier runs a nightly so spark

00:29:15,540 --> 00:29:19,050
job and the same code loads up the new

00:29:17,250 --> 00:29:21,210
model and just processes the road in

00:29:19,050 --> 00:29:22,650
streaming mode on incoming messages we

00:29:21,210 --> 00:29:25,290
have elasticsearch and everything works

00:29:22,650 --> 00:29:27,120
great so that's it that's all I have

00:29:25,290 --> 00:29:31,950
thank you for listening and I hope that

00:29:27,120 --> 00:29:34,350
they heard thanks them we unfortunately

00:29:31,950 --> 00:29:35,670
don't have any time for questions but if

00:29:34,350 --> 00:29:37,620
you do want to have a chat with Sam

00:29:35,670 --> 00:29:38,970
about some of the stuff he's talked

00:29:37,620 --> 00:29:40,650
about he'll be hanging around here for a

00:29:38,970 --> 00:29:42,540
few minutes I imagine and you can come

00:29:40,650 --> 00:29:46,280
up and speak to him here I will be back

00:29:42,540 --> 00:29:46,280

YouTube URL: https://www.youtube.com/watch?v=N6riK1Xtyng


