Title: Sofia Heisler   No More Sad Pandas Optimizing Pandas Code for Speed and Efficiency   PyCon 2017
Publication date: 2017-05-21
Playlist: PyCon 2017
Description: 
	"Speaker: Sofia Heisler

When I first began working with the Python Pandas library, I was told by an experienced Python engineer: ""Pandas is fine for prototyping a bit of calculations, but it's too slow for any time-sensitive applications."" Over multiple years of working with the Pandas library, I have realized that this was only true if not enough care is put into identifying proper ways to optimize the code's performance. This talk will review some of the most common beginner pitfalls that can cause otherwise perfectly good Pandas code to grind to a screeching halt, and walk through a set of tips and tricks to avoid them. Using a series of examples, we will review the process for identifying the elements of the code that may be causing a slowdown, and discuss a series of optimizations, ranging from good practices of input data storage and reading, to the best methods for avoiding inefficient iterations, to using the power of vectorization to optimize functions for Pandas dataframes.


Slides can be found at: https://speakerdeck.com/pycon2017 and https://github.com/PyCon/2017-slides"
Captions: 
	00:00:07,390 --> 00:00:12,930
good afternoon everybody welcome to this

00:00:09,880 --> 00:00:15,850
Hampton afternoon session of icon 2017

00:00:12,930 --> 00:00:18,000
please be seated this ride will begin

00:00:15,850 --> 00:00:18,000
momentarily

00:00:25,570 --> 00:00:34,270
thank you so first things first if

00:00:31,960 --> 00:00:35,980
anyone has any noise noise making

00:00:34,270 --> 00:00:37,510
devices please make sure they do not

00:00:35,980 --> 00:00:40,809
make noise because when they make noise

00:00:37,510 --> 00:00:42,610
everyone stares at you with that said I

00:00:40,809 --> 00:00:44,650
would like to reduce our next speaker it

00:00:42,610 --> 00:00:46,989
is Sophia Heisler and she will be

00:00:44,650 --> 00:00:54,580
talking about optimizing pandas please

00:00:46,989 --> 00:00:57,460
make a feel welcome thank you everybody

00:00:54,580 --> 00:01:00,190
and welcome so my name is Sophia Heisler

00:00:57,460 --> 00:01:03,399
I am the lead data scientist at a

00:01:00,190 --> 00:01:05,229
startup called up side and today we're

00:01:03,399 --> 00:01:10,000
going to be talking about optimizing

00:01:05,229 --> 00:01:11,740
pandas code for speed and performance so

00:01:10,000 --> 00:01:13,630
all of the code that I'm going to be

00:01:11,740 --> 00:01:15,940
talking about is going to be up on the

00:01:13,630 --> 00:01:17,259
slides and I've done my best to make

00:01:15,940 --> 00:01:19,119
sure that it's going to be visible to

00:01:17,259 --> 00:01:22,509
everybody but if you do want to download

00:01:19,119 --> 00:01:23,979
the slides please go to this link and

00:01:22,509 --> 00:01:25,869
you should be able to grab the slide

00:01:23,979 --> 00:01:29,140
deck as well as the jupiter notebook

00:01:25,869 --> 00:01:30,430
that actually runs all of the code and

00:01:29,140 --> 00:01:34,060
the inputs that we're going to be

00:01:30,430 --> 00:01:35,920
talking about i've also put this link on

00:01:34,060 --> 00:01:37,960
the bottom right hand corner over here

00:01:35,920 --> 00:01:40,200
so if during the presentation you say

00:01:37,960 --> 00:01:42,759
you really want to download it because

00:01:40,200 --> 00:01:45,850
it gotten small you can't see anything

00:01:42,759 --> 00:01:49,479
please go ahead so first off how many

00:01:45,850 --> 00:01:51,700
people here actually use pandas almost

00:01:49,479 --> 00:01:54,549
everybody awesome so for those of you

00:01:51,700 --> 00:01:56,530
who is less familiar with the library

00:01:54,549 --> 00:01:59,590
pandas is an open source library that

00:01:56,530 --> 00:02:02,439
offers data structure support and a

00:01:59,590 --> 00:02:04,930
fantastic set of tools for data analysis

00:02:02,439 --> 00:02:07,840
in particular pandas is great for the

00:02:04,930 --> 00:02:09,850
analysis of tabular data in other in

00:02:07,840 --> 00:02:13,450
other words data that's arranged in rows

00:02:09,850 --> 00:02:15,850
and columns and pandas provides a lot of

00:02:13,450 --> 00:02:18,579
the functionality that until a few years

00:02:15,850 --> 00:02:22,019
ago was only available in more

00:02:18,579 --> 00:02:26,950
statistics oriented tools like R or

00:02:22,019 --> 00:02:30,430
Stata or Ceph or MATLAB for example so a

00:02:26,950 --> 00:02:32,200
lot of these tools pandas is now able to

00:02:30,430 --> 00:02:35,769
use the same function provide the same

00:02:32,200 --> 00:02:37,840
functionality within Python as a result

00:02:35,769 --> 00:02:39,370
pandas is used in just about everything

00:02:37,840 --> 00:02:43,599
from simple data manipulation

00:02:39,370 --> 00:02:46,239
- pretty complex machine learning so why

00:02:43,599 --> 00:02:47,500
do I care to optimize my code well that

00:02:46,239 --> 00:02:49,720
actually kind of depends on your use

00:02:47,500 --> 00:02:51,700
case and maybe if you're doing data

00:02:49,720 --> 00:02:54,010
science where your runtimes don't matter

00:02:51,700 --> 00:02:55,269
and your data isn't huge maybe it

00:02:54,010 --> 00:02:58,030
doesn't actually matter all that much

00:02:55,269 --> 00:03:00,579
whether your code is running in a few

00:02:58,030 --> 00:03:02,409
minutes or a few seconds whatever you'll

00:03:00,579 --> 00:03:04,599
go get a cup of coffee you come back and

00:03:02,409 --> 00:03:06,970
it's going to be done but the bottom

00:03:04,599 --> 00:03:09,819
line is that pandas is capable of

00:03:06,970 --> 00:03:11,769
providing a lot of efficiency because

00:03:09,819 --> 00:03:13,629
it's built on top of numpy and it has a

00:03:11,769 --> 00:03:16,359
lot of procedures built into it that are

00:03:13,629 --> 00:03:17,950
optimized incise on which means that it

00:03:16,359 --> 00:03:20,769
can be very fast when it's used

00:03:17,950 --> 00:03:22,660
correctly and those optimizations that

00:03:20,769 --> 00:03:24,879
you can put into it can make the

00:03:22,660 --> 00:03:27,159
difference between your code running in

00:03:24,879 --> 00:03:32,680
minutes or your code running in

00:03:27,159 --> 00:03:33,970
literally milliseconds so before we

00:03:32,680 --> 00:03:37,120
start talking about how we would

00:03:33,970 --> 00:03:40,780
actually optimize our code let's talk

00:03:37,120 --> 00:03:42,340
about how do I know whether my code is

00:03:40,780 --> 00:03:44,769
slow and how do I know whether I'm

00:03:42,340 --> 00:03:46,030
making it faster in other words we're

00:03:44,769 --> 00:03:49,090
going to talk a little bit about how you

00:03:46,030 --> 00:03:50,230
would do benchmarking so to start we're

00:03:49,090 --> 00:03:53,019
going to be looking at a bunch of

00:03:50,230 --> 00:03:54,849
examples that are based on a data set

00:03:53,019 --> 00:03:57,609
that I pulled down also of expedience

00:03:54,849 --> 00:03:59,319
developer website and it pretty much

00:03:57,609 --> 00:04:01,989
just contains all of the hotels in New

00:03:59,319 --> 00:04:04,840
York states that are sold by Expedia

00:04:01,989 --> 00:04:06,370
there's about 1600 of them turns out

00:04:04,840 --> 00:04:08,859
there's a lot of hotels in New York

00:04:06,370 --> 00:04:12,310
State and our data set is going to

00:04:08,859 --> 00:04:16,239
contain some information with one hotel

00:04:12,310 --> 00:04:19,690
per row an IV for each hotel a name and

00:04:16,239 --> 00:04:21,849
address a latitude and longitude and

00:04:19,690 --> 00:04:24,940
some information about the hotel such as

00:04:21,849 --> 00:04:26,770
the star rating and some high rates and

00:04:24,940 --> 00:04:30,099
low rates that are calculated by Expedia

00:04:26,770 --> 00:04:32,860
and the third we're just going to grab a

00:04:30,099 --> 00:04:34,539
function that we can benchmark from this

00:04:32,860 --> 00:04:36,280
is an example of a normalization

00:04:34,539 --> 00:04:39,160
function it's pretty straightforward

00:04:36,280 --> 00:04:41,050
what it's actually doing is not actually

00:04:39,160 --> 00:04:43,570
all of that relevant for our purposes

00:04:41,050 --> 00:04:45,370
other than it's taking some means and

00:04:43,570 --> 00:04:48,479
some standard deviations cutting off

00:04:45,370 --> 00:04:51,310
outliers and taking a log to normalize

00:04:48,479 --> 00:04:53,150
what we care about is how do we actually

00:04:51,310 --> 00:04:55,760
figure out how to time this

00:04:53,150 --> 00:04:58,280
and which parts of it are slower or

00:04:55,760 --> 00:05:00,889
faster than others so we're going to do

00:04:58,280 --> 00:05:03,440
that was something called magic commands

00:05:00,889 --> 00:05:07,070
so how many of you guys have used the

00:05:03,440 --> 00:05:09,740
magic commands in Jupiter great so a lot

00:05:07,070 --> 00:05:11,660
so magic commands are available through

00:05:09,740 --> 00:05:14,449
Jupiter notebooks to provide additional

00:05:11,660 --> 00:05:17,389
functionality on top of Python code that

00:05:14,449 --> 00:05:19,669
may running that code or doing other

00:05:17,389 --> 00:05:21,949
things with that code extra awesome and

00:05:19,669 --> 00:05:24,260
useful magic commands you'll see start

00:05:21,949 --> 00:05:26,000
with a percentage sign the single

00:05:24,260 --> 00:05:28,580
percent sign is just code that's

00:05:26,000 --> 00:05:30,500
executed on one line or double

00:05:28,580 --> 00:05:33,050
percentage that's executed on an entire

00:05:30,500 --> 00:05:34,910
cell and the first function that we're

00:05:33,050 --> 00:05:37,760
going to talk about is the time-it

00:05:34,910 --> 00:05:39,470
command so a time-it command just reruns

00:05:37,760 --> 00:05:41,630
a function over and over and over again

00:05:39,470 --> 00:05:44,300
and it shows the average and the

00:05:41,630 --> 00:05:48,260
standard deviation of the runtime that

00:05:44,300 --> 00:05:49,699
it obtained as a result what's the time

00:05:48,260 --> 00:05:51,530
that it calculates can serve as a

00:05:49,699 --> 00:05:54,289
benchmark for a bunch of further

00:05:51,530 --> 00:05:57,139
optimizations so let's look at an

00:05:54,289 --> 00:06:00,139
example so here we've done a payment of

00:05:57,139 --> 00:06:02,000
our normalized function I've said my

00:06:00,139 --> 00:06:05,810
normalized function the data frame that

00:06:02,000 --> 00:06:09,020
I created my set of hotels and I filled

00:06:05,810 --> 00:06:11,300
it to use the series higher rate in

00:06:09,020 --> 00:06:14,960
order to actually apply this function

00:06:11,300 --> 00:06:17,599
and I've assigned the results to a new

00:06:14,960 --> 00:06:19,310
series within the data frame have run

00:06:17,599 --> 00:06:22,370
the payment and it's letting me know

00:06:19,310 --> 00:06:26,599
that it the function on average took 2.8

00:06:22,370 --> 00:06:29,479
84 milliseconds and it ran it seven to

00:06:26,599 --> 00:06:31,970
seven runs of 100 loops each so now that

00:06:29,479 --> 00:06:34,400
provides a baseline from which I can go

00:06:31,970 --> 00:06:35,990
to figure out how to make this function

00:06:34,400 --> 00:06:37,639
run faster or slower and figure out

00:06:35,990 --> 00:06:40,490
whether I'm actually succeeding at what

00:06:37,639 --> 00:06:42,680
I'm doing so the next thing I'm going to

00:06:40,490 --> 00:06:45,020
do is I'm going to feed it through an

00:06:42,680 --> 00:06:48,800
extension called line profiler which

00:06:45,020 --> 00:06:52,520
gets abbreviated as % LP run as a magic

00:06:48,800 --> 00:06:55,300
function an align profiler will run

00:06:52,520 --> 00:06:57,650
through run my function line by line and

00:06:55,300 --> 00:07:00,110
give me a bunch of useful statistics

00:06:57,650 --> 00:07:02,810
about what it's doing and in particular

00:07:00,110 --> 00:07:05,599
it's going to tell me in that second

00:07:02,810 --> 00:07:06,680
column my hits it's going to tell me how

00:07:05,599 --> 00:07:10,220
many times my

00:07:06,680 --> 00:07:12,680
has been actually each line in my

00:07:10,220 --> 00:07:14,210
function has been rerun so if I'm

00:07:12,680 --> 00:07:16,570
running the function on a bunch of loop

00:07:14,210 --> 00:07:19,370
Celsius number greater than one here and

00:07:16,570 --> 00:07:21,169
in the next of the last column it's

00:07:19,370 --> 00:07:24,289
going to tell me what percentage of the

00:07:21,169 --> 00:07:27,169
time each line actually took so over

00:07:24,289 --> 00:07:28,880
here for example if you look we see I

00:07:27,169 --> 00:07:32,180
don't have my pointer here but if you

00:07:28,880 --> 00:07:35,680
look about four lines up from the bottom

00:07:32,180 --> 00:07:40,789
you'll see that my line 11 and 12

00:07:35,680 --> 00:07:42,860
actually took well close to 80% of the

00:07:40,789 --> 00:07:45,169
time that this function was running for

00:07:42,860 --> 00:07:47,210
which means that if I were going in and

00:07:45,169 --> 00:07:48,889
trying to optimize this function I would

00:07:47,210 --> 00:07:50,630
certainly look at those two lines and

00:07:48,889 --> 00:07:52,910
try to start there because I would get

00:07:50,630 --> 00:07:58,220
the biggest bang for my bum for my buck

00:07:52,910 --> 00:07:59,990
trying to optimize those steps so now

00:07:58,220 --> 00:08:02,090
that we sort of get the sense of how

00:07:59,990 --> 00:08:04,729
we're going to go about trying to

00:08:02,090 --> 00:08:11,150
optimize or trying to benchmark our

00:08:04,729 --> 00:08:13,099
functionality let's talk about some of

00:08:11,150 --> 00:08:16,340
the slower methodologies that I've seen

00:08:13,099 --> 00:08:19,280
used in pandas so we're going to start

00:08:16,340 --> 00:08:21,380
with a different practice function this

00:08:19,280 --> 00:08:23,780
is the hammer sign or Great Circle

00:08:21,380 --> 00:08:25,729
distance function all this is basically

00:08:23,780 --> 00:08:27,320
doing is taking in two sets of

00:08:25,729 --> 00:08:28,940
coordinates and is calculating a

00:08:27,320 --> 00:08:31,029
straight line distance between them

00:08:28,940 --> 00:08:33,620
taking in the curvature of the earth

00:08:31,029 --> 00:08:35,959
again the details of the implementation

00:08:33,620 --> 00:08:38,060
aren't actually all that important for

00:08:35,959 --> 00:08:40,099
our purposes other than to know that

00:08:38,060 --> 00:08:43,540
it's doing some addition some

00:08:40,099 --> 00:08:46,790
subtraction and it's doing a bunch of

00:08:43,540 --> 00:08:48,860
sines and cosines and other trig to

00:08:46,790 --> 00:08:51,350
actually calculate the distances and

00:08:48,860 --> 00:08:54,890
it's returning the actual number of

00:08:51,350 --> 00:08:56,480
miles between two coordinates so one

00:08:54,890 --> 00:08:58,700
thing that I see people do a lot

00:08:56,480 --> 00:09:01,790
actually as they start out in pandas is

00:08:58,700 --> 00:09:04,820
start iterating through all of the rows

00:09:01,790 --> 00:09:06,680
to apply a function which kind of makes

00:09:04,820 --> 00:09:08,630
sense right because you're working with

00:09:06,680 --> 00:09:10,370
a data frame that has a bunch of rows

00:09:08,630 --> 00:09:11,899
and a bunch of columns and why can't

00:09:10,370 --> 00:09:13,700
they just loop through all of my rows

00:09:11,899 --> 00:09:15,380
just the same way that I would loop

00:09:13,700 --> 00:09:17,690
through a list and actually figure out

00:09:15,380 --> 00:09:20,540
and actually apply the function to each

00:09:17,690 --> 00:09:23,120
item on that list this thing is

00:09:20,540 --> 00:09:25,730
is actually built on numpy which is

00:09:23,120 --> 00:09:27,200
designed for vector manipulation which

00:09:25,730 --> 00:09:28,220
means that loops are inherently

00:09:27,200 --> 00:09:30,800
inefficient

00:09:28,220 --> 00:09:33,500
that being said pandas will give you

00:09:30,800 --> 00:09:35,620
methods to loop through row by row if

00:09:33,500 --> 00:09:39,200
that's something you really want to do

00:09:35,620 --> 00:09:41,570
so for example it will provide you with

00:09:39,200 --> 00:09:44,510
an it arose method or inner tuples

00:09:41,570 --> 00:09:47,090
method which will give you essentially a

00:09:44,510 --> 00:09:50,210
set of things to loop through but it

00:09:47,090 --> 00:09:55,280
will be quite slow so over here I've

00:09:50,210 --> 00:10:01,190
basically created a blank new dictionary

00:09:55,280 --> 00:10:03,260
to feed our mileage into and I'm running

00:10:01,190 --> 00:10:06,020
through my rows within data frame it

00:10:03,260 --> 00:10:08,540
arose command and I'm just feeding it a

00:10:06,020 --> 00:10:10,670
set of coordinates and I'm running it

00:10:08,540 --> 00:10:12,890
calculating the distance between a

00:10:10,670 --> 00:10:15,740
particular set of coordinates and every

00:10:12,890 --> 00:10:17,660
single hotel and my data set if you're

00:10:15,740 --> 00:10:19,700
curious a particular set of coordinates

00:10:17,660 --> 00:10:21,500
happens to be the Brooklyn superhero

00:10:19,700 --> 00:10:26,030
supply in New York it's a fantastic

00:10:21,500 --> 00:10:28,160
place you should go there so now at this

00:10:26,030 --> 00:10:31,010
point we know that our function with it

00:10:28,160 --> 00:10:32,240
arose have taken 184 milliseconds we

00:10:31,010 --> 00:10:34,430
don't actually know whether that's slow

00:10:32,240 --> 00:10:35,720
or fast at this point right but all we

00:10:34,430 --> 00:10:40,940
know is that it took less than a second

00:10:35,720 --> 00:10:43,910
I guess that's good but we can try a

00:10:40,940 --> 00:10:45,230
different looping method a nicer way to

00:10:43,910 --> 00:10:47,540
have done this would have been to use

00:10:45,230 --> 00:10:50,600
apply which applies a function along a

00:10:47,540 --> 00:10:52,760
specified axis which is to say a set of

00:10:50,600 --> 00:10:54,710
rows or a set of columns and it's a lot

00:10:52,760 --> 00:10:56,210
more efficient than it arose it's much

00:10:54,710 --> 00:10:58,540
more optimized even though it's still

00:10:56,210 --> 00:11:00,980
looping through over and over again a

00:10:58,540 --> 00:11:03,110
platter is best used only when there is

00:11:00,980 --> 00:11:06,890
no good way to actually vectorize your

00:11:03,110 --> 00:11:08,810
function so let's try looking at that so

00:11:06,890 --> 00:11:10,750
over here I'm essentially having the

00:11:08,810 --> 00:11:14,600
function do the same saying it's

00:11:10,750 --> 00:11:17,060
applying the function to each individual

00:11:14,600 --> 00:11:19,190
row and it's comparing the distance from

00:11:17,060 --> 00:11:21,500
that hotel to a particular set of

00:11:19,190 --> 00:11:25,010
coordinates and it's running it through

00:11:21,500 --> 00:11:28,670
a row by row but just by swapping out

00:11:25,010 --> 00:11:32,450
apply for it arose I've gotten my run

00:11:28,670 --> 00:11:33,800
time down to 78 milliseconds by

00:11:32,450 --> 00:11:36,350
comparison

00:11:33,800 --> 00:11:37,850
to the 184 milliseconds that we saw

00:11:36,350 --> 00:11:39,800
before that's a two and a half times

00:11:37,850 --> 00:11:42,769
improvement for basically changing

00:11:39,800 --> 00:11:47,060
nothing about my function just changing

00:11:42,769 --> 00:11:49,310
the function that runs it and now if we

00:11:47,060 --> 00:11:52,070
look at the actual line profiler we can

00:11:49,310 --> 00:11:55,130
see what it's doing well uprize doing a

00:11:52,070 --> 00:12:00,200
lot of repetitive repetitive steps where

00:11:55,130 --> 00:12:02,089
you see that 100 1631 hits that's the

00:12:00,200 --> 00:12:04,430
apply function hitting the each

00:12:02,089 --> 00:12:07,070
individual row and doing the same set of

00:12:04,430 --> 00:12:09,019
things over and over and over again and

00:12:07,070 --> 00:12:11,570
if we could just get rid of that

00:12:09,019 --> 00:12:14,560
repetition we could make it run a lot

00:12:11,570 --> 00:12:20,060
faster and that's what vectorization

00:12:14,560 --> 00:12:22,519
actually does for our functions so what

00:12:20,060 --> 00:12:23,870
is vectorization well before we start

00:12:22,519 --> 00:12:26,000
talking about that let's take a step

00:12:23,870 --> 00:12:29,779
back and just talk about what it is that

00:12:26,000 --> 00:12:33,800
makes pandas so great the basic unit of

00:12:29,779 --> 00:12:35,690
pandas is an array so there's two sort

00:12:33,800 --> 00:12:38,209
of basic objects in pandas one is a

00:12:35,690 --> 00:12:41,720
series which is a one-dimensional array

00:12:38,209 --> 00:12:46,430
with axis labels so a series would be a

00:12:41,720 --> 00:12:49,100
column with a column with some labels on

00:12:46,430 --> 00:12:50,839
it for example or a data frame which is

00:12:49,100 --> 00:12:53,060
a two-dimensional array with labeled

00:12:50,839 --> 00:12:56,209
axes in other words that would be a

00:12:53,060 --> 00:12:58,279
table with column labels and row labels

00:12:56,209 --> 00:13:01,490
now vectorization is the process of

00:12:58,279 --> 00:13:04,910
performing operations on arrays instead

00:13:01,490 --> 00:13:06,860
of scalars in other words my vectorized

00:13:04,910 --> 00:13:09,950
operations are going to take my entire

00:13:06,860 --> 00:13:12,649
series and perform an operation on the

00:13:09,950 --> 00:13:14,959
entire saying simultaneously instead of

00:13:12,649 --> 00:13:18,800
running through it one single item at a

00:13:14,959 --> 00:13:22,130
time why would I want to do that well

00:13:18,800 --> 00:13:23,720
many pandas functions are actually built

00:13:22,130 --> 00:13:26,420
to operate that way they're built

00:13:23,720 --> 00:13:29,360
operate directly on a race so the

00:13:26,420 --> 00:13:32,089
built-in pandas some functions the

00:13:29,360 --> 00:13:34,250
string string processing they're all

00:13:32,089 --> 00:13:36,709
vectorize functions and they are

00:13:34,250 --> 00:13:39,829
inherently because of the inherent panda

00:13:36,709 --> 00:13:42,260
structure much faster than regular

00:13:39,829 --> 00:13:44,740
looping operations or trying to operate

00:13:42,260 --> 00:13:47,089
on one piece of the data frame at a time

00:13:44,740 --> 00:13:47,800
so let's look at how we would vectorize

00:13:47,089 --> 00:13:50,139
this function

00:13:47,800 --> 00:13:52,559
we actually don't need to do much all

00:13:50,139 --> 00:13:55,089
we've done is we've said we're going to

00:13:52,559 --> 00:13:56,889
grab our have a sine function we're

00:13:55,089 --> 00:14:00,040
still using the same set of coordinates

00:13:56,889 --> 00:14:02,829
but now instead of looping and applying

00:14:00,040 --> 00:14:05,439
the function on one row at a time

00:14:02,829 --> 00:14:07,509
we're going to feed it the entire vector

00:14:05,439 --> 00:14:09,910
latitude and longitude that we've

00:14:07,509 --> 00:14:12,629
grabbed from the data frame so at this

00:14:09,910 --> 00:14:14,709
point my DF latitude in DF longitude are

00:14:12,629 --> 00:14:18,369
individual arrays they're the contents

00:14:14,709 --> 00:14:20,799
of both of those columns whole and this

00:14:18,369 --> 00:14:24,879
brings our time down to actually 1.8

00:14:20,799 --> 00:14:26,980
milliseconds so if you recall in our

00:14:24,879 --> 00:14:29,499
previous in our previous swooping runs

00:14:26,980 --> 00:14:31,600
we got it down to something like 73 or

00:14:29,499 --> 00:14:34,959
something like that

00:14:31,600 --> 00:14:37,389
now we are down to a tiny fraction of

00:14:34,959 --> 00:14:40,029
that and in fact if we look at time it

00:14:37,389 --> 00:14:42,639
well the function is no longer looping

00:14:40,029 --> 00:14:45,100
it's doing exactly one hit to every

00:14:42,639 --> 00:14:47,709
single line that were in the function

00:14:45,100 --> 00:14:51,459
and that's what allows that huge

00:14:47,709 --> 00:14:53,049
increase in efficiency and so now just

00:14:51,459 --> 00:14:55,990
to summarize with it arose we were

00:14:53,049 --> 00:14:57,879
starting out at 184 milliseconds with a

00:14:55,990 --> 00:15:00,660
vectorized implementation of the exact

00:14:57,879 --> 00:15:04,240
same function we're down to 1.8

00:15:00,660 --> 00:15:07,980
milliseconds which is a 43 times

00:15:04,240 --> 00:15:11,230
improvement over even looping was apply

00:15:07,980 --> 00:15:14,350
so that's already pretty great but could

00:15:11,230 --> 00:15:16,629
we make it even better well the answer

00:15:14,350 --> 00:15:18,910
is actually yeah we can and we can do

00:15:16,629 --> 00:15:20,369
that by vectorizing with numpy arrays

00:15:18,910 --> 00:15:24,160
instead of series

00:15:20,369 --> 00:15:26,410
so why numpy you might ask well numpy

00:15:24,160 --> 00:15:29,740
calls itself a fundamental package for

00:15:26,410 --> 00:15:32,799
scientific computing in Python numpy

00:15:29,740 --> 00:15:36,389
operations are essentially executed an

00:15:32,799 --> 00:15:38,799
optimized pre compiled code and

00:15:36,389 --> 00:15:41,679
fundamental objects and numpy are also

00:15:38,799 --> 00:15:44,889
arrays are called NZ arrays and they are

00:15:41,679 --> 00:15:46,899
highly efficient and they skip out on a

00:15:44,889 --> 00:15:49,600
lot of the overhead that gets incurred

00:15:46,899 --> 00:15:52,419
by operations on pandas series and theis

00:15:49,600 --> 00:15:54,220
on pandas series are great for a lot of

00:15:52,419 --> 00:15:56,350
things they provide their own indexes

00:15:54,220 --> 00:15:59,049
there they have a lot of functionality

00:15:56,350 --> 00:16:01,570
but they do have a lot of extra overhead

00:15:59,049 --> 00:16:04,680
that numpy array skip

00:16:01,570 --> 00:16:08,259
and so what we can do is we can take

00:16:04,680 --> 00:16:10,690
again our old good old Harrison function

00:16:08,259 --> 00:16:15,610
and we're going to convert our pandas

00:16:10,690 --> 00:16:19,269
series back to numb 5mk erase by

00:16:15,610 --> 00:16:21,370
applying the dot values function to them

00:16:19,269 --> 00:16:25,480
this is just the built-in pandas method

00:16:21,370 --> 00:16:28,329
and now we are down to actually 370

00:16:25,480 --> 00:16:31,300
microseconds which is to say we've

00:16:28,329 --> 00:16:33,490
effectively gotten up to a 500 fold

00:16:31,300 --> 00:16:36,160
improvement from our original version of

00:16:33,490 --> 00:16:38,170
the function by not changing the

00:16:36,160 --> 00:16:44,430
function essentially just changing the

00:16:38,170 --> 00:16:47,199
way that our inputs are read in so that

00:16:44,430 --> 00:16:48,579
probably is pretty great for what we're

00:16:47,199 --> 00:16:51,910
trying to do and for that particular

00:16:48,579 --> 00:16:54,819
function but you might say what if I

00:16:51,910 --> 00:16:56,680
actually really wanted to use a loop and

00:16:54,819 --> 00:16:58,000
there might be a couple of reasons for

00:16:56,680 --> 00:16:59,620
why you might want to do that and then

00:16:58,000 --> 00:17:01,600
this hammer sign function might not

00:16:59,620 --> 00:17:04,000
actually be the best example for that

00:17:01,600 --> 00:17:05,470
but there are other reasons so for

00:17:04,000 --> 00:17:07,360
example maybe your function is really

00:17:05,470 --> 00:17:10,270
complex and it doesn't yield itself

00:17:07,360 --> 00:17:13,030
easily to vectorization maybe you're

00:17:10,270 --> 00:17:15,909
calling an API and there is no way to

00:17:13,030 --> 00:17:17,409
vectorize this process may be trying to

00:17:15,909 --> 00:17:19,809
vectorize your function would actually

00:17:17,409 --> 00:17:21,909
incur a lot of memory overhead for

00:17:19,809 --> 00:17:23,829
example your data frame is huge and it

00:17:21,909 --> 00:17:26,679
contains a lot of really complex float

00:17:23,829 --> 00:17:28,120
operations and it's too much for you to

00:17:26,679 --> 00:17:29,860
handle and so you're actually it's

00:17:28,120 --> 00:17:32,380
actually preferable for you to loop even

00:17:29,860 --> 00:17:34,679
though it would be slower or maybe

00:17:32,380 --> 00:17:37,780
you're just plain stubborn I don't know

00:17:34,679 --> 00:17:42,040
so one of the things that we could use

00:17:37,780 --> 00:17:44,080
to actually speed up loops is size on so

00:17:42,040 --> 00:17:46,059
say sign language is a superset of

00:17:44,080 --> 00:17:48,309
Python that additionally supports

00:17:46,059 --> 00:17:50,740
calling C functions and declaring C

00:17:48,309 --> 00:17:52,929
types and I think there is another slice

00:17:50,740 --> 00:17:54,429
on talk following directly after this

00:17:52,929 --> 00:17:57,760
I'm sure they will know a lot more than

00:17:54,429 --> 00:18:00,610
I do about it but this is my abbreviated

00:17:57,760 --> 00:18:03,549
version so any almost any piece of

00:18:00,610 --> 00:18:05,919
Python code is also valid seisonn code

00:18:03,549 --> 00:18:09,909
and the syphon compiler will effectively

00:18:05,919 --> 00:18:12,190
convert Python code into C code which

00:18:09,909 --> 00:18:15,320
will make equivalent calls to the Python

00:18:12,190 --> 00:18:18,350
and C API

00:18:15,320 --> 00:18:20,930
so we're still using jupiter notebooks

00:18:18,350 --> 00:18:23,150
and i've slip installed this ison

00:18:20,930 --> 00:18:26,090
extension I'm going to load my sights on

00:18:23,150 --> 00:18:28,160
extension and then I'm going to open a

00:18:26,090 --> 00:18:31,880
new site on sale I'm going to initialize

00:18:28,160 --> 00:18:34,700
it as running incise on and I'm going to

00:18:31,880 --> 00:18:37,130
grab my entire have a sine function and

00:18:34,700 --> 00:18:39,650
pretty much just run it through that

00:18:37,130 --> 00:18:42,050
slice on compiler I've not really made

00:18:39,650 --> 00:18:45,710
any real changes to it other than to

00:18:42,050 --> 00:18:48,140
define it in my death as a CP death

00:18:45,710 --> 00:18:49,730
which is a slice on Python function

00:18:48,140 --> 00:18:55,070
instead of just a straight Python

00:18:49,730 --> 00:18:56,840
function so let's time this once that's

00:18:55,070 --> 00:18:58,220
been done I can basically just run my

00:18:56,840 --> 00:19:02,840
function exactly the way I did before

00:18:58,220 --> 00:19:06,800
with an apply and I'm down to 76

00:19:02,840 --> 00:19:09,650
milliseconds well unfortunately that's

00:19:06,800 --> 00:19:11,360
actually not very good it's about the

00:19:09,650 --> 00:19:13,730
same thing we were getting with Python

00:19:11,360 --> 00:19:17,180
and that's a little bit disappointing

00:19:13,730 --> 00:19:18,920
because the sights on compiler was

00:19:17,180 --> 00:19:23,150
supposed to be doing a bunch of work in

00:19:18,920 --> 00:19:26,210
the background to convert our code to 2c

00:19:23,150 --> 00:19:28,580
or slice on and try to optimize it and

00:19:26,210 --> 00:19:32,840
make it run faster so what happened

00:19:28,580 --> 00:19:35,780
there well if I add the - a option to my

00:19:32,840 --> 00:19:38,180
sites on magic command the second

00:19:35,780 --> 00:19:39,740
compiler will actually show me how much

00:19:38,180 --> 00:19:43,160
of this function has been able to

00:19:39,740 --> 00:19:45,050
convert from Python to size on and those

00:19:43,160 --> 00:19:47,390
yellow bits is everything that it's

00:19:45,050 --> 00:19:50,060
still running in python that's a lot of

00:19:47,390 --> 00:19:52,370
yellow we did not do very well and

00:19:50,060 --> 00:19:55,100
that's exactly why we didn't cut any

00:19:52,370 --> 00:19:59,090
time off so let's see what we can

00:19:55,100 --> 00:20:01,640
actually do about that well for one

00:19:59,090 --> 00:20:04,040
thing we know that as long as slice on

00:20:01,640 --> 00:20:06,200
is still using Python we're not going to

00:20:04,040 --> 00:20:08,240
we're not going to improve the time much

00:20:06,200 --> 00:20:10,640
so we need to make the function more

00:20:08,240 --> 00:20:12,440
slice unfriendly and there's a bunch of

00:20:10,640 --> 00:20:14,960
ways to do that you know anything

00:20:12,440 --> 00:20:17,990
ranging from taking the real function to

00:20:14,960 --> 00:20:19,850
converting it to pure C but two of the

00:20:17,990 --> 00:20:23,750
things that we can do fairly easily is

00:20:19,850 --> 00:20:27,860
we can add explicit strict typing to the

00:20:23,750 --> 00:20:28,880
function or we can replace our wealth or

00:20:27,860 --> 00:20:31,700
and/or

00:20:28,880 --> 00:20:35,270
or we can replace our Python and numpy

00:20:31,700 --> 00:20:38,720
libraries with C specific math libraries

00:20:35,270 --> 00:20:41,390
so if you recall our function was using

00:20:38,720 --> 00:20:43,760
a whole bunch of numpy math to calculate

00:20:41,390 --> 00:20:45,020
a bunch of those trig formulas we're

00:20:43,760 --> 00:20:49,160
going to take those out and we're going

00:20:45,020 --> 00:20:52,010
to replace them with a actual C math

00:20:49,160 --> 00:20:55,580
library since this is what our converted

00:20:52,010 --> 00:20:58,130
function looks like now and you can see

00:20:55,580 --> 00:20:59,840
that I've basically taken all of the

00:20:58,130 --> 00:21:02,420
variables that are declared within the

00:20:59,840 --> 00:21:04,340
function and I've added strict typing to

00:21:02,420 --> 00:21:11,120
them they're all slopes it's easy enough

00:21:04,340 --> 00:21:12,350
and I've imported the Lib C math to

00:21:11,120 --> 00:21:14,120
bring in a bunch of sine and cosine

00:21:12,350 --> 00:21:18,260
functions that we're going to be using

00:21:14,120 --> 00:21:20,330
to replace the numpy library other than

00:21:18,260 --> 00:21:22,040
that the only thing I've really done is

00:21:20,330 --> 00:21:24,350
there was one function which was a

00:21:22,040 --> 00:21:26,420
degrees to radians conversion that

00:21:24,350 --> 00:21:28,280
exists in numpy but not in the original

00:21:26,420 --> 00:21:31,570
C library I've just taken it out and

00:21:28,280 --> 00:21:34,210
rewritten it and defined it as a

00:21:31,570 --> 00:21:39,140
function separate function within here

00:21:34,210 --> 00:21:41,750
so now let's try running that so we're

00:21:39,140 --> 00:21:45,950
going to time the sizin eyes function

00:21:41,750 --> 00:21:49,040
again the actual apply statement looks

00:21:45,950 --> 00:21:52,550
exactly the same as before and now we're

00:21:49,040 --> 00:21:55,190
actually down to 50 milliseconds which

00:21:52,550 --> 00:21:59,510
if you recall is not nearly as great as

00:21:55,190 --> 00:22:03,200
300 microseconds but you know it's an

00:21:59,510 --> 00:22:06,860
improvement we've gotten it up to 1.6

00:22:03,200 --> 00:22:10,460
times the previous version which was

00:22:06,860 --> 00:22:14,270
just running the Python function with

00:22:10,460 --> 00:22:17,720
apply or running the row wise function

00:22:14,270 --> 00:22:20,870
python function directly in the syphon

00:22:17,720 --> 00:22:23,570
compiler without doing anything and so

00:22:20,870 --> 00:22:26,000
at this point if you're really attached

00:22:23,570 --> 00:22:28,700
to loops you can go into a lot more

00:22:26,000 --> 00:22:31,250
probably seisonn optimizations but they

00:22:28,700 --> 00:22:32,870
will get a lot more complex or you can

00:22:31,250 --> 00:22:34,700
see if you can figure out a way to

00:22:32,870 --> 00:22:37,160
vectorize your function which will give

00:22:34,700 --> 00:22:42,820
you a huge boost and improvement in

00:22:37,160 --> 00:22:42,820
performance for very little work and

00:22:43,490 --> 00:22:49,280
one step if we actually look at our code

00:22:46,070 --> 00:22:51,530
at this point well we see that there's a

00:22:49,280 --> 00:22:55,040
hell of a lot more yield less yellow and

00:22:51,530 --> 00:22:57,140
more white on the screen so our changes

00:22:55,040 --> 00:22:59,360
that we made including the data typing

00:22:57,140 --> 00:23:01,880
and the conversion to a different

00:22:59,360 --> 00:23:04,640
library have actually done a lot to help

00:23:01,880 --> 00:23:10,940
the function convert to actual sites on

00:23:04,640 --> 00:23:13,460
code and run more efficiently alright so

00:23:10,940 --> 00:23:15,890
here we are let's sum it up so again

00:23:13,460 --> 00:23:18,470
this is our scoreboard we started out

00:23:15,890 --> 00:23:23,620
with 184 milliseconds we got it down to

00:23:18,470 --> 00:23:28,400
a point for my croissant 4 milliseconds

00:23:23,620 --> 00:23:30,470
overall about a 500 time improvement we

00:23:28,400 --> 00:23:32,620
started out looping with it arose which

00:23:30,470 --> 00:23:35,870
you should pretty much almost never do

00:23:32,620 --> 00:23:37,910
we moved to looping with a ply which is

00:23:35,870 --> 00:23:42,560
a fairly efficient way to loop through

00:23:37,910 --> 00:23:45,050
things we tried looping with a function

00:23:42,560 --> 00:23:47,480
that got converted to slice on which

00:23:45,050 --> 00:23:48,200
gave us some performance boost but not a

00:23:47,480 --> 00:23:50,240
whole lot

00:23:48,200 --> 00:23:52,580
and then we vectorize their function

00:23:50,240 --> 00:23:56,900
with pandas and with numpy arrays which

00:23:52,580 --> 00:23:59,930
gave huge boosts and performance so to

00:23:56,900 --> 00:24:02,720
summarize the general Zen of pandas

00:23:59,930 --> 00:24:05,600
optimization is one avoid loops if you

00:24:02,720 --> 00:24:08,420
can if you must move use apply not

00:24:05,600 --> 00:24:10,750
iteration functions if you must apply

00:24:08,420 --> 00:24:13,130
you slice on to make it faster

00:24:10,750 --> 00:24:17,240
vectorization is usually better than

00:24:13,130 --> 00:24:20,390
scalar operations and vector operations

00:24:17,240 --> 00:24:25,490
on numpy arrays are more efficient than

00:24:20,390 --> 00:24:27,770
a native pandas series and with that

00:24:25,490 --> 00:24:30,350
just a couple of words of warning to

00:24:27,770 --> 00:24:34,070
quote xkcd premature optimization is the

00:24:30,350 --> 00:24:36,260
root of all evil so before you start

00:24:34,070 --> 00:24:38,030
optimizing your function make sure that

00:24:36,260 --> 00:24:40,340
it is doing what you wanted to be doing

00:24:38,030 --> 00:24:42,590
otherwise you will find yourself having

00:24:40,340 --> 00:24:44,690
spent a week on trying to make it run a

00:24:42,590 --> 00:24:46,460
few minutes faster just to find that it

00:24:44,690 --> 00:24:48,740
actually wasn't running and doing things

00:24:46,460 --> 00:24:51,890
that you wanted it to do at all you will

00:24:48,740 --> 00:24:54,130
regret it another caveat that I should

00:24:51,890 --> 00:24:57,530
put in here all of this was done in

00:24:54,130 --> 00:25:02,960
Python 3.5 one

00:24:57,530 --> 00:25:05,540
panda's point 20 so anything any of

00:25:02,960 --> 00:25:07,580
these results will obviously vary

00:25:05,540 --> 00:25:09,650
depending on exactly how you're using

00:25:07,580 --> 00:25:11,900
your functions the system that you're

00:25:09,650 --> 00:25:15,230
running it on the size of the data frame

00:25:11,900 --> 00:25:18,110
the type of the functions that you're

00:25:15,230 --> 00:25:20,180
using and so take it with a grain of

00:25:18,110 --> 00:25:23,900
salt I can promise you the exact same

00:25:20,180 --> 00:25:25,400
performance performance boosts that we

00:25:23,900 --> 00:25:27,590
saw on this particular data frame in

00:25:25,400 --> 00:25:29,210
this particular function for every

00:25:27,590 --> 00:25:33,260
single thing that you might ever apply

00:25:29,210 --> 00:25:36,290
these methods to and that's pretty much

00:25:33,260 --> 00:25:38,990
it and since I have a few more seconds

00:25:36,290 --> 00:25:41,960
I'm going to give a bonus pitch we are

00:25:38,990 --> 00:25:45,710
hiring and check us out at upside comm

00:25:41,960 --> 00:25:48,350
we're a fantastic small travel startup

00:25:45,710 --> 00:25:50,510
located in Washington DC and if you're

00:25:48,350 --> 00:25:58,820
interested come talk to me thank you

00:25:50,510 --> 00:26:00,290
very much Thank You Sophia does anyone

00:25:58,820 --> 00:26:03,880
have any questions if you do there are

00:26:00,290 --> 00:26:03,880
microphones in the aisles

00:26:13,679 --> 00:26:20,200
so in your in your habits on Saipan

00:26:16,809 --> 00:26:23,889
example your last yellow line was uh

00:26:20,200 --> 00:26:27,340
you're using map and tuple unpacking and

00:26:23,889 --> 00:26:29,320
it seems like if you just put four lines

00:26:27,340 --> 00:26:31,029
of just do the computation you could

00:26:29,320 --> 00:26:33,730
have avoided a complete round trip into

00:26:31,029 --> 00:26:37,029
Python land you know that's a fair point

00:26:33,730 --> 00:26:38,830
I actually did try doing that and it

00:26:37,029 --> 00:26:41,409
actually does not improve performance

00:26:38,830 --> 00:26:42,669
but it was actually one one of the

00:26:41,409 --> 00:26:45,519
things that I was going to investigate

00:26:42,669 --> 00:26:46,989
was figuring out how to actually make

00:26:45,519 --> 00:26:50,830
that run faster because you're right it

00:26:46,989 --> 00:26:52,809
does run as a Python function but for

00:26:50,830 --> 00:26:53,950
the purposes of that function doing it

00:26:52,809 --> 00:26:55,929
one way or another didn't make a

00:26:53,950 --> 00:27:03,279
difference so I left it as it was thank

00:26:55,929 --> 00:27:05,739
you Oh for your improvement for your

00:27:03,279 --> 00:27:07,600
psyche on have a sine function did you

00:27:05,739 --> 00:27:12,549
test that with the vectorization to see

00:27:07,600 --> 00:27:16,179
if there was further improvement so not

00:27:12,549 --> 00:27:19,090
quite because once well so if you were

00:27:16,179 --> 00:27:21,220
to run it on vectors a lot of the actual

00:27:19,090 --> 00:27:23,649
benefits of sizin would basically just

00:27:21,220 --> 00:27:27,159
be the benefits that you get from the

00:27:23,649 --> 00:27:28,690
direct vectorization and so yes you

00:27:27,159 --> 00:27:31,559
could but at that point you might as

00:27:28,690 --> 00:27:34,299
well just run that function on vectors

00:27:31,559 --> 00:27:35,859
in its Python form and it will still be

00:27:34,299 --> 00:27:36,999
way fast there the combining the two

00:27:35,859 --> 00:27:39,159
doesn't actually give you much of a

00:27:36,999 --> 00:27:42,999
boost in performance in that case thank

00:27:39,159 --> 00:27:45,309
you so this isn't exactly related to I

00:27:42,999 --> 00:27:48,460
thought our pandas but you're using

00:27:45,309 --> 00:27:50,379
lambdas and I know I remember way back

00:27:48,460 --> 00:27:57,249
west McKinney's advice was not to use

00:27:50,379 --> 00:27:59,590
lambdas and apply has that changed or so

00:27:57,249 --> 00:28:02,529
that is a great question I don't know if

00:27:59,590 --> 00:28:05,289
I've ever heard not to use lambdas in

00:28:02,529 --> 00:28:07,929
apply the reason that we use lambdas in

00:28:05,289 --> 00:28:12,190
this particular use case is because

00:28:07,929 --> 00:28:14,080
we're trying to apply to a row and so

00:28:12,190 --> 00:28:17,139
we're trying to we need to give that

00:28:14,080 --> 00:28:19,389
object a particular name right if I were

00:28:17,139 --> 00:28:21,039
not applying it to a row if I were just

00:28:19,389 --> 00:28:21,580
doing it on a single series I could do

00:28:21,039 --> 00:28:26,320
without it

00:28:21,580 --> 00:28:28,930
you know if that's faster

00:28:26,320 --> 00:28:30,670
that's a great question I don't think it

00:28:28,930 --> 00:28:33,040
would be but I haven't tested it so I

00:28:30,670 --> 00:28:38,410
don't know all right thank you that's

00:28:33,040 --> 00:28:41,260
great Hoss question group by to group

00:28:38,410 --> 00:28:43,570
our regression models today and I found

00:28:41,260 --> 00:28:44,290
that if you do like over more than four

00:28:43,570 --> 00:28:48,670
columns

00:28:44,290 --> 00:28:51,730
it just is increasingly not performance

00:28:48,670 --> 00:28:53,440
at all do you have any suggestions of

00:28:51,730 --> 00:28:57,790
other ways to do that that would be more

00:28:53,440 --> 00:29:01,000
performant for specifically group bys

00:28:57,790 --> 00:29:03,400
it's you know off the top of my head I

00:29:01,000 --> 00:29:05,440
would guess that maybe dealing with some

00:29:03,400 --> 00:29:07,150
of the data types and looking at the way

00:29:05,440 --> 00:29:09,940
that your data types of the things that

00:29:07,150 --> 00:29:12,670
you're grouping by might affect it but

00:29:09,940 --> 00:29:18,010
be honest answer is no I don't actually

00:29:12,670 --> 00:29:20,580
know and so we had time for please again

00:29:18,010 --> 00:29:20,580
thank Sofia

00:29:23,780 --> 00:29:26,680

YouTube URL: https://www.youtube.com/watch?v=HN5d490_KKk


