Title: Alex Orlov   Cython as a Game Changer for Efficiency   PyCon 2017
Publication date: 2017-05-21
Playlist: PyCon 2017
Description: 
	"Speaker: Alex Orlov

Are you running a Web application? Do you suffer from CPU bottlenecks that slow down your growth? There's a tool that can easily fix all that, and then some. C++ knowledge not required.

Come learn how Instagram, the world's largest Django deployment with more than 600M active users, saved ~30% of global CPU by rewriting a handful of modules on the critical path in Cython. Learn to apply those techniques to your own projects with little effort and stop worrying about switching to other programming languages or rewriting stable components in C++.



Slides can be found at: https://speakerdeck.com/pycon2017 and https://github.com/PyCon/2017-slides"
Captions: 
	00:00:00,000 --> 00:00:04,740
lecture today we know Python is a great

00:00:02,340 --> 00:00:06,569
language for everything buzzspeed but

00:00:04,740 --> 00:00:09,030
how do we deal with it anyway we can

00:00:06,569 --> 00:00:10,620
solve this problem you will find the

00:00:09,030 --> 00:00:13,320
answer in the next talk let's welcome

00:00:10,620 --> 00:00:24,779
Alex for the title as a game changer for

00:00:13,320 --> 00:00:26,430
efficiency hello everybody thank you for

00:00:24,779 --> 00:00:28,470
coming today we're gonna talk about

00:00:26,430 --> 00:00:31,590
Python efficiency in general and more

00:00:28,470 --> 00:00:34,290
specifically we can talk about sytem so

00:00:31,590 --> 00:00:36,600
let's start with Python it's a great

00:00:34,290 --> 00:00:38,129
language that you probably love and you

00:00:36,600 --> 00:00:40,559
can probably name zillion of reasons why

00:00:38,129 --> 00:00:42,480
do you like it my favorite favorite is

00:00:40,559 --> 00:00:44,700
released adhere so it's speed of

00:00:42,480 --> 00:00:46,350
development code readability greater

00:00:44,700 --> 00:00:48,570
good system of libraries and of course

00:00:46,350 --> 00:00:50,180
community and actually I work with

00:00:48,570 --> 00:00:52,379
different programming languages but

00:00:50,180 --> 00:00:55,260
whenever I switch back to Python I

00:00:52,379 --> 00:00:57,390
always feel kind of relief and always

00:00:55,260 --> 00:01:01,379
getting surprised how fast and easy

00:00:57,390 --> 00:01:02,789
development is but let's admit that

00:01:01,379 --> 00:01:04,019
python is probably not the most

00:01:02,789 --> 00:01:06,330
efficient programming language in the

00:01:04,019 --> 00:01:08,820
world it's definitely quite efficient in

00:01:06,330 --> 00:01:10,560
terms of developer velocity but not that

00:01:08,820 --> 00:01:14,610
good in terms of CPU usage or memory

00:01:10,560 --> 00:01:17,220
usage but the real question here is how

00:01:14,610 --> 00:01:19,350
much do you care if your back-end

00:01:17,220 --> 00:01:21,600
engineer in typical web company and your

00:01:19,350 --> 00:01:23,130
company experiences growth it's quite

00:01:21,600 --> 00:01:25,259
likely that majority of your challenges

00:01:23,130 --> 00:01:26,970
will be somehow related to scaling

00:01:25,259 --> 00:01:29,070
issues of data bases or catch

00:01:26,970 --> 00:01:32,369
consistency or something like that

00:01:29,070 --> 00:01:34,020
but your web tier it's quite likely that

00:01:32,369 --> 00:01:36,150
the tool stays simple usually it's a

00:01:34,020 --> 00:01:37,890
stateless web server and all you need to

00:01:36,150 --> 00:01:40,890
do in order to scale is to add more

00:01:37,890 --> 00:01:42,659
boxes as simple as that but at some

00:01:40,890 --> 00:01:45,630
point number of machines that you edit

00:01:42,659 --> 00:01:47,520
might become insane or at least big

00:01:45,630 --> 00:01:49,500
enough for you to consider to save some

00:01:47,520 --> 00:01:53,460
money for your company and reduce number

00:01:49,500 --> 00:01:55,070
of boxes even then Python execution

00:01:53,460 --> 00:01:58,079
speed itself might not be a real concern

00:01:55,070 --> 00:02:00,420
your web tier can be CPU bound memory

00:01:58,079 --> 00:02:01,969
bound IO bound and all those are

00:02:00,420 --> 00:02:06,540
different type of issues although

00:02:01,969 --> 00:02:07,770
sometimes they're correlated but let's

00:02:06,540 --> 00:02:10,649
say that you're in the same boat as

00:02:07,770 --> 00:02:11,650
Instagram and you also have some CPU

00:02:10,649 --> 00:02:13,450
issues

00:02:11,650 --> 00:02:15,099
first things that you actually need to

00:02:13,450 --> 00:02:17,680
do is profiling

00:02:15,099 --> 00:02:20,110
according to Pareto principle 20% of

00:02:17,680 --> 00:02:22,720
work is responsible for 80% of results

00:02:20,110 --> 00:02:25,750
or in our case we should expect 20% of

00:02:22,720 --> 00:02:29,079
codebase to be responsible for 80% of 4

00:02:25,750 --> 00:02:31,540
of global cpu footprint and in our case

00:02:29,079 --> 00:02:34,150
that's actually true so try to avoid

00:02:31,540 --> 00:02:36,040
prematurity customizations and figure

00:02:34,150 --> 00:02:39,849
out what piece of code you really need

00:02:36,040 --> 00:02:42,220
to optimize so let's say you found

00:02:39,849 --> 00:02:46,329
critical code the next thing that you

00:02:42,220 --> 00:02:48,879
want to do is read your code so it's

00:02:46,329 --> 00:02:50,560
quite likely that it just performs

00:02:48,879 --> 00:02:53,019
unnecessary actions or there is some

00:02:50,560 --> 00:02:54,970
misuse of data structure or some Python

00:02:53,019 --> 00:02:58,060
specific stuff like imports and sidle

00:02:54,970 --> 00:02:59,829
functions for example here we have this

00:02:58,060 --> 00:03:02,230
comprehension that intentionally

00:02:59,829 --> 00:03:03,760
generates huge lists and then we have

00:03:02,230 --> 00:03:05,549
for loop and inside of the for loop we

00:03:03,760 --> 00:03:08,709
check if element is present in the list

00:03:05,549 --> 00:03:10,840
looks good looks like normal code but

00:03:08,709 --> 00:03:12,819
problem is that this data structure is

00:03:10,840 --> 00:03:15,549
not designed for this type of queries so

00:03:12,819 --> 00:03:19,780
we actually have n square algorithm here

00:03:15,549 --> 00:03:22,000
which is fine for many cases but if it's

00:03:19,780 --> 00:03:24,519
critical code paths then even for a

00:03:22,000 --> 00:03:27,549
relatively small n it might become an

00:03:24,519 --> 00:03:30,129
issue fortunately it's easy to fix if

00:03:27,549 --> 00:03:32,109
you change this comprehension to set

00:03:30,129 --> 00:03:35,889
comprehension you'll reduce complexity

00:03:32,109 --> 00:03:38,260
to linear and problem solve so my point

00:03:35,889 --> 00:03:41,500
is before applying any dramatic changes

00:03:38,260 --> 00:03:45,400
and optimizations try to read your code

00:03:41,500 --> 00:03:48,069
first and check your algorithm but let's

00:03:45,400 --> 00:03:51,940
say is that you did it and your code

00:03:48,069 --> 00:03:53,500
looks sane but it's still slow don't

00:03:51,940 --> 00:03:56,859
worry at this point you also have

00:03:53,500 --> 00:04:00,159
multiple options option a microservices

00:03:56,859 --> 00:04:01,989
so you can take your critical piece of

00:04:00,159 --> 00:04:03,639
code and if it's easy for you to

00:04:01,989 --> 00:04:05,919
decouple it from the rest of your app

00:04:03,639 --> 00:04:08,079
and if you're using service-oriented

00:04:05,919 --> 00:04:09,849
architecture you can probably create

00:04:08,079 --> 00:04:11,049
separate micro service to write it in

00:04:09,849 --> 00:04:12,879
any programming language that you

00:04:11,049 --> 00:04:17,650
consider to be more performant in Python

00:04:12,879 --> 00:04:20,859
and yeah so it should work but it has

00:04:17,650 --> 00:04:22,659
obvious downsides so first of all it

00:04:20,859 --> 00:04:25,030
sounds like non-trivial amount of work

00:04:22,659 --> 00:04:26,500
like to take a bunch of code and rewrite

00:04:25,030 --> 00:04:28,840
completely different programming

00:04:26,500 --> 00:04:30,370
language and also if you're not using

00:04:28,840 --> 00:04:32,020
service-oriented architecture it will

00:04:30,370 --> 00:04:34,210
add complexity to your system in terms

00:04:32,020 --> 00:04:37,680
of maintenance deployment capacity

00:04:34,210 --> 00:04:41,350
planning and whatnot so hold on

00:04:37,680 --> 00:04:43,390
option B a classic C extensions again

00:04:41,350 --> 00:04:48,130
you can take your code rewrite it in C

00:04:43,390 --> 00:04:49,900
or C++ and the great then just create as

00:04:48,130 --> 00:04:52,900
a separate library and then just create

00:04:49,900 --> 00:04:54,610
Python binding for it it works it works

00:04:52,900 --> 00:04:57,190
perfectly well and as a matter of fact

00:04:54,610 --> 00:05:00,310
that's how many libraries that we use

00:04:57,190 --> 00:05:02,050
are written but you'll have to write in

00:05:00,310 --> 00:05:04,450
C++ which is arguably not the most

00:05:02,050 --> 00:05:06,880
friendly language to write especially if

00:05:04,450 --> 00:05:09,240
your product engineer and if you don't

00:05:06,880 --> 00:05:11,940
have relevant experience

00:05:09,240 --> 00:05:14,770
option C you can change Python runtime

00:05:11,940 --> 00:05:16,870
so Python of the programming language is

00:05:14,770 --> 00:05:18,640
obstruction and C pythons that you

00:05:16,870 --> 00:05:20,560
probably use is concrete implementation

00:05:18,640 --> 00:05:24,160
of that abstraction but there are

00:05:20,560 --> 00:05:25,960
multiple of their multiple options so

00:05:24,160 --> 00:05:26,830
there is PI pi which is probably the

00:05:25,960 --> 00:05:29,200
most popular one

00:05:26,830 --> 00:05:31,470
there's by Stanford wrong box grandpa

00:05:29,200 --> 00:05:34,390
from Google so a lot of good stuff and

00:05:31,470 --> 00:05:37,300
the each of them has pros and cons on

00:05:34,390 --> 00:05:39,340
its own so we won't stop here but let's

00:05:37,300 --> 00:05:42,130
just say that switching Python runtime

00:05:39,340 --> 00:05:44,080
is not that easy as it sounds for

00:05:42,130 --> 00:05:47,140
example if you want to move to pi pi and

00:05:44,080 --> 00:05:48,580
you depend or code that you use depend

00:05:47,140 --> 00:05:50,890
on libraries that you use depends on

00:05:48,580 --> 00:05:55,450
multiple C extensions then migration

00:05:50,890 --> 00:05:58,600
might be tricky and one more options you

00:05:55,450 --> 00:06:01,150
can update Python so as you probably

00:05:58,600 --> 00:06:04,270
heard we migrated from Python 2 to

00:06:01,150 --> 00:06:07,210
Python 3 and it improved overall CPU

00:06:04,270 --> 00:06:10,390
usage of our system by 12%

00:06:07,210 --> 00:06:13,120
and so there's actual ongoing work

00:06:10,390 --> 00:06:14,830
related to performance and if it's

00:06:13,120 --> 00:06:19,750
feasible for you to update Python yeah

00:06:14,830 --> 00:06:24,760
why not just do it and finally you can

00:06:19,750 --> 00:06:25,500
use site on so what is site on according

00:06:24,760 --> 00:06:28,560
to the QPD

00:06:25,500 --> 00:06:30,760
site on is super ok I don't see it Oh

00:06:28,560 --> 00:06:32,140
site on a superset of the Python

00:06:30,760 --> 00:06:33,729
programming language designed to give C

00:06:32,140 --> 00:06:35,110
like performance with code which is

00:06:33,729 --> 00:06:37,990
mostly written in Python

00:06:35,110 --> 00:06:38,830
so in short sightedness programming

00:06:37,990 --> 00:06:40,480
language

00:06:38,830 --> 00:06:43,270
which is basically the same stuff as a

00:06:40,480 --> 00:06:46,570
Python but with optional extra syntax

00:06:43,270 --> 00:06:49,240
that you may or may not use up to you it

00:06:46,570 --> 00:06:50,800
compiles to C or C++ and it works

00:06:49,240 --> 00:06:53,830
perfectly well with your existing

00:06:50,800 --> 00:06:56,830
runtime so no changes in infrastructure

00:06:53,830 --> 00:06:59,110
are required at all let's consider the

00:06:56,830 --> 00:07:02,320
following example don't worry you don't

00:06:59,110 --> 00:07:04,270
have to read this code so that's Django

00:07:02,320 --> 00:07:06,430
URL dispatcher basically piece of Jenga

00:07:04,270 --> 00:07:09,310
it takes URL and figures out what view

00:07:06,430 --> 00:07:11,770
or controller it needs to execute so

00:07:09,310 --> 00:07:14,170
once we noticed that this module started

00:07:11,770 --> 00:07:16,990
consuming four percent of global CPU in

00:07:14,170 --> 00:07:20,530
our system and at the first step we just

00:07:16,990 --> 00:07:24,640
compile this vist item and this simple

00:07:20,530 --> 00:07:28,030
action gave us 3x performance boost for

00:07:24,640 --> 00:07:30,370
this model and reduced overall memory

00:07:28,030 --> 00:07:33,580
CPU consumption of this module from 4%

00:07:30,370 --> 00:07:34,150
to one each percent and if you think

00:07:33,580 --> 00:07:36,040
about it

00:07:34,150 --> 00:07:37,810
that's actually not bad because so far

00:07:36,040 --> 00:07:42,910
we still don't know what sytem is we

00:07:37,810 --> 00:07:45,190
didn't have to learn any syntax and we

00:07:42,910 --> 00:07:49,200
didn't have even we didn't even have to

00:07:45,190 --> 00:07:53,680
read Django source code so easy win

00:07:49,200 --> 00:07:56,400
so on this slide we we didn't change any

00:07:53,680 --> 00:07:58,390
line so sight on was able to apply some

00:07:56,400 --> 00:08:01,720
optimizations but it can do much better

00:07:58,390 --> 00:08:04,920
job if we somehow tell it what are we

00:08:01,720 --> 00:08:07,570
trying to do let's consider this example

00:08:04,920 --> 00:08:11,050
so here we have transformation functions

00:08:07,570 --> 00:08:13,540
that takes X and just squares it and a

00:08:11,050 --> 00:08:16,270
plier function which takes and and it

00:08:13,540 --> 00:08:18,340
has for loop and inside of the for loop

00:08:16,270 --> 00:08:20,350
it just accumulates results of

00:08:18,340 --> 00:08:24,190
transformation into sintel into local

00:08:20,350 --> 00:08:28,780
variable so if you compile this code it

00:08:24,190 --> 00:08:30,690
will run 2.5 X faster which is quite

00:08:28,780 --> 00:08:36,580
similar to what we experienced before

00:08:30,690 --> 00:08:38,920
but sytem allows us to add types ok so

00:08:36,580 --> 00:08:43,120
this code now looks slightly different

00:08:38,920 --> 00:08:44,530
from normal Python but actually what we

00:08:43,120 --> 00:08:46,810
change here we change the signature of

00:08:44,530 --> 00:08:50,290
functions for example now it's death of

00:08:46,810 --> 00:08:51,900
lier in M which means that our function

00:08:50,290 --> 00:08:55,200
only accepts into

00:08:51,900 --> 00:08:57,570
argue arguments and also we declared

00:08:55,200 --> 00:09:00,120
type of local variables inside of body

00:08:57,570 --> 00:09:03,450
of second function so if you compile

00:09:00,120 --> 00:09:07,920
this code for relatively large n like

00:09:03,450 --> 00:09:11,450
more than thousand it will run 200 X

00:09:07,920 --> 00:09:13,950
faster and all thanks to static typing

00:09:11,450 --> 00:09:15,839
to be fair there are multiple

00:09:13,950 --> 00:09:17,580
optimizations that you that seitan

00:09:15,839 --> 00:09:20,460
provides but if your goal is to optimize

00:09:17,580 --> 00:09:22,800
existing Python code then adding types

00:09:20,460 --> 00:09:26,910
is all you need to do in majority of

00:09:22,800 --> 00:09:29,250
cases so let's take a step back and take

00:09:26,910 --> 00:09:31,080
a brief dive into site and syntax that

00:09:29,250 --> 00:09:34,410
you probably should learn if you want to

00:09:31,080 --> 00:09:37,290
optimize existing Python code main

00:09:34,410 --> 00:09:39,060
keywords that site introduces is CDF

00:09:37,290 --> 00:09:41,370
it's used to declare type of variable

00:09:39,060 --> 00:09:44,310
for example here we have three variables

00:09:41,370 --> 00:09:48,029
integer variable I empty string s and

00:09:44,310 --> 00:09:51,260
empty list data okay it may look weird

00:09:48,029 --> 00:09:54,839
but should be quite simple to understand

00:09:51,260 --> 00:09:57,029
same applies to function signature you

00:09:54,839 --> 00:10:00,450
can specify a return type of function as

00:09:57,029 --> 00:10:02,580
well as type of arguments and when I say

00:10:00,450 --> 00:10:05,940
you can it means you can but you

00:10:02,580 --> 00:10:07,230
probably should but you don't have to if

00:10:05,940 --> 00:10:09,450
you don't specify particular some

00:10:07,230 --> 00:10:11,910
particular type it will default to the

00:10:09,450 --> 00:10:15,540
most generic types that Python has which

00:10:11,910 --> 00:10:17,250
is Python object type so syphon won't be

00:10:15,540 --> 00:10:21,380
able to apply some optimizations but

00:10:17,250 --> 00:10:24,480
your code will still be good to go

00:10:21,380 --> 00:10:26,610
another thing that I should mention is

00:10:24,480 --> 00:10:30,600
that there are three different ways to

00:10:26,610 --> 00:10:33,959
declare functions inside on dev CDs and

00:10:30,600 --> 00:10:35,959
CP def def functions are normal Python

00:10:33,959 --> 00:10:39,350
functions exactly what you can expect

00:10:35,959 --> 00:10:41,730
but there is also C def declaration

00:10:39,350 --> 00:10:45,270
basically site on will compile your code

00:10:41,730 --> 00:10:47,339
into native C function and as a result

00:10:45,270 --> 00:10:51,480
you won't be able to call it from normal

00:10:47,339 --> 00:10:54,990
Python code only in only from site on or

00:10:51,480 --> 00:10:57,560
from C but on a bright side it won't

00:10:54,990 --> 00:10:59,610
have any Python function call overhead

00:10:57,560 --> 00:11:01,890
for example it doesn't need to do

00:10:59,610 --> 00:11:05,130
marshalling from Python object type and

00:11:01,890 --> 00:11:06,780
to Python object type so close to those

00:11:05,130 --> 00:11:11,100
functions are considered to be much much

00:11:06,780 --> 00:11:13,170
cheaper and for functions in your basic

00:11:11,100 --> 00:11:13,800
modules in your system it might be quite

00:11:13,170 --> 00:11:16,320
critical

00:11:13,800 --> 00:11:19,410
and there's also see PDF declaration

00:11:16,320 --> 00:11:22,110
which is intersection of two worlds site

00:11:19,410 --> 00:11:24,690
and will generate native C function as

00:11:22,110 --> 00:11:26,220
that will be used inside of site on but

00:11:24,690 --> 00:11:29,550
you will still be able to call it from

00:11:26,220 --> 00:11:33,240
external Python code because setting

00:11:29,550 --> 00:11:36,150
will also generate scene rubber few

00:11:33,240 --> 00:11:39,000
words about type system Satan has

00:11:36,150 --> 00:11:45,000
support for all primitive C types such

00:11:39,000 --> 00:11:46,920
as int long float double char of course

00:11:45,000 --> 00:11:48,960
it has support for strings

00:11:46,920 --> 00:11:52,800
both byte strings and Unicode strings

00:11:48,960 --> 00:11:55,230
and by the way a site on works perfectly

00:11:52,800 --> 00:11:58,560
well with both Python 2 and Python 3 so

00:11:55,230 --> 00:12:01,800
for example is th TR type here will be

00:11:58,560 --> 00:12:05,580
unicode type in Python 3 and white

00:12:01,800 --> 00:12:07,230
string in Python 2 and also set and has

00:12:05,580 --> 00:12:09,300
support for all Python collections that

00:12:07,230 --> 00:12:12,720
we love such as least set dictionary

00:12:09,300 --> 00:12:14,580
tuple and again in majority of cases if

00:12:12,720 --> 00:12:18,200
you want to squeeze like performance

00:12:14,580 --> 00:12:21,030
like 2 X 5 X that's all you need to use

00:12:18,200 --> 00:12:23,790
but sometimes if you want to squeeze

00:12:21,030 --> 00:12:28,160
even more performance you can go deeper

00:12:23,790 --> 00:12:32,960
and start using low-level types so that

00:12:28,160 --> 00:12:37,200
that is scary but unnecessary slide so

00:12:32,960 --> 00:12:41,010
site only has support for such low level

00:12:37,200 --> 00:12:42,750
types as see arrays or row pointers you

00:12:41,010 --> 00:12:48,780
probably should be very careful with

00:12:42,750 --> 00:12:52,140
those also has support support of in

00:12:48,780 --> 00:12:53,700
arms see structures unions and for

00:12:52,140 --> 00:12:57,090
example if you're a big fan of C++

00:12:53,700 --> 00:12:59,640
standard template library as I am then

00:12:57,090 --> 00:13:01,860
and if you always wanted to use vector

00:12:59,640 --> 00:13:03,750
in your code or three based map now you

00:13:01,860 --> 00:13:06,420
have option to do that for example CDF

00:13:03,750 --> 00:13:10,140
vector in the data will declare empty

00:13:06,420 --> 00:13:13,410
vector of integers so it may look

00:13:10,140 --> 00:13:15,870
unusual and even slightly scary and but

00:13:13,410 --> 00:13:18,630
again there's those type of temptations

00:13:15,870 --> 00:13:21,870
you probably apply

00:13:18,630 --> 00:13:23,610
in rare cases another source of

00:13:21,870 --> 00:13:27,210
optimization that you probably should

00:13:23,610 --> 00:13:30,660
use our extension types they look quite

00:13:27,210 --> 00:13:32,400
similar to normal Python classes so for

00:13:30,660 --> 00:13:37,080
example here we defined by can speaker

00:13:32,400 --> 00:13:40,650
class it has three attributes name age

00:13:37,080 --> 00:13:43,470
biography and there is some constructor

00:13:40,650 --> 00:13:46,770
and there's some property so as you can

00:13:43,470 --> 00:13:49,080
see a quote here looks exactly almost

00:13:46,770 --> 00:13:51,110
the same as normal Python only one

00:13:49,080 --> 00:13:54,210
difference here is that we declared

00:13:51,110 --> 00:13:55,980
explicit see devlog and inside of the

00:13:54,210 --> 00:13:59,460
block we listed all attributes as well

00:13:55,980 --> 00:14:02,840
as their types so behind-the-scenes

00:13:59,460 --> 00:14:06,420
sytem will use the typed c structure

00:14:02,840 --> 00:14:10,230
instead of dynamic Python dictionary to

00:14:06,420 --> 00:14:12,840
store attributes of this class so as a

00:14:10,230 --> 00:14:16,260
result they consume much less memory

00:14:12,840 --> 00:14:18,620
they have faster attribute lookup they

00:14:16,260 --> 00:14:22,770
have faster method access you can

00:14:18,620 --> 00:14:24,480
declare some methods as CDF and what is

00:14:22,770 --> 00:14:26,660
most important they can be used as valid

00:14:24,480 --> 00:14:31,380
type for Satan static type system

00:14:26,660 --> 00:14:34,470
because foresight on any Python captain

00:14:31,380 --> 00:14:36,570
defined class is a black box because

00:14:34,470 --> 00:14:39,120
invite Python is the dynamic language

00:14:36,570 --> 00:14:41,640
and you can override everything so seven

00:14:39,120 --> 00:14:44,550
should be safe and it doesn't make any

00:14:41,640 --> 00:14:48,810
assumptions on internal structure of

00:14:44,550 --> 00:14:51,350
your objects and last but not least they

00:14:48,810 --> 00:14:55,140
work perfectly fine with your existing

00:14:51,350 --> 00:14:57,540
runtime you can create them and even

00:14:55,140 --> 00:15:00,470
more you can even create your new Python

00:14:57,540 --> 00:15:04,800
class and inherit it from sight on one

00:15:00,470 --> 00:15:06,180
so overall your optimization workflow

00:15:04,800 --> 00:15:08,460
with sytem should consist of of

00:15:06,180 --> 00:15:10,050
following steps first you detect

00:15:08,460 --> 00:15:12,360
critical modules and you compile it

00:15:10,050 --> 00:15:15,390
compare performance numbers if it's good

00:15:12,360 --> 00:15:18,150
enough you can stop there if not you

00:15:15,390 --> 00:15:20,610
will have to add some types then compile

00:15:18,150 --> 00:15:22,920
around performance comparison again then

00:15:20,610 --> 00:15:26,640
add even more types and so on and so on

00:15:22,920 --> 00:15:29,750
until you either get performance that

00:15:26,640 --> 00:15:31,950
you want or it's also possible that

00:15:29,750 --> 00:15:34,140
everything will be typed but you

00:15:31,950 --> 00:15:37,800
still want to get even more performance

00:15:34,140 --> 00:15:38,940
in this case probably you want you want

00:15:37,800 --> 00:15:41,340
to take a look into more low-level

00:15:38,940 --> 00:15:45,270
pictures of site on but that's a rare

00:15:41,340 --> 00:15:48,600
case for example you can replace Python

00:15:45,270 --> 00:15:49,710
data structures with like data

00:15:48,600 --> 00:15:55,820
structures or support positive

00:15:49,710 --> 00:15:58,320
structures so a few words about to link

00:15:55,820 --> 00:16:01,260
during compilation you have option to

00:15:58,320 --> 00:16:04,950
specify annotation flag it will generate

00:16:01,260 --> 00:16:07,140
such beautiful HTML here a yellow lines

00:16:04,950 --> 00:16:09,210
indicate interaction with Python virtual

00:16:07,140 --> 00:16:11,100
machine as you can see there are

00:16:09,210 --> 00:16:13,800
different shades of yellow so bold

00:16:11,100 --> 00:16:16,500
yellow indicates most expensive

00:16:13,800 --> 00:16:18,960
interaction this Python VM you can click

00:16:16,500 --> 00:16:22,380
on any particular line and you will get

00:16:18,960 --> 00:16:25,190
Yossi generated C code if you're not

00:16:22,380 --> 00:16:28,140
very comfortable with C or C++ probably

00:16:25,190 --> 00:16:30,630
this code will go on top of your head

00:16:28,140 --> 00:16:34,560
but at least you will figure out what

00:16:30,630 --> 00:16:39,990
parts of Python C API are considered to

00:16:34,560 --> 00:16:42,210
be expensive just want to share with you

00:16:39,990 --> 00:16:44,970
some Instagram results that we have so

00:16:42,210 --> 00:16:48,800
far so far we converted only 10-ish

00:16:44,970 --> 00:16:52,080
probably now it's closer to 15 modules

00:16:48,800 --> 00:16:56,070
2000 and when I say modules it actually

00:16:52,080 --> 00:16:58,860
means files so and it already reduce

00:16:56,070 --> 00:17:03,300
global CP like CPU consumption of our

00:16:58,860 --> 00:17:05,400
web stack by 30% and we just started so

00:17:03,300 --> 00:17:07,740
we still see a lot of opportunities and

00:17:05,400 --> 00:17:12,570
places in our code base that we can

00:17:07,740 --> 00:17:16,339
optimize and reclaim even more CPU funny

00:17:12,570 --> 00:17:21,240
fact is that when we first experienced

00:17:16,339 --> 00:17:24,089
experienced issues the CPU Titan wasn't

00:17:21,240 --> 00:17:27,390
obvious option and overall I had

00:17:24,089 --> 00:17:29,520
impression that Saturn is quite popular

00:17:27,390 --> 00:17:32,520
in open-source community but it's mainly

00:17:29,520 --> 00:17:36,240
used for following to use cases to wrap

00:17:32,520 --> 00:17:39,840
existing C code or to optimize projects

00:17:36,240 --> 00:17:41,970
but projects in data science space but

00:17:39,840 --> 00:17:43,630
as you can imagine Instagram is quite

00:17:41,970 --> 00:17:46,050
typical web service

00:17:43,630 --> 00:17:49,210
and as you can see we were able to

00:17:46,050 --> 00:17:53,860
reclaim a good chunk of CPU with a

00:17:49,210 --> 00:17:56,590
little effort okay to recap what we have

00:17:53,860 --> 00:17:59,380
so far first of all don't be concerned

00:17:56,590 --> 00:18:01,960
about Python execution speeds too early

00:17:59,380 --> 00:18:04,090
as you can see it took Instagram a while

00:18:01,960 --> 00:18:08,950
before it became an issue maybe a few

00:18:04,090 --> 00:18:12,220
hundreds millions users so the

00:18:08,950 --> 00:18:13,660
definitely good problem to have once you

00:18:12,220 --> 00:18:16,330
get there first thing that you want to

00:18:13,660 --> 00:18:19,540
do is profiling it might sound obvious

00:18:16,330 --> 00:18:24,340
but practice shows that developers tend

00:18:19,540 --> 00:18:26,290
to optimize everything I I think your

00:18:24,340 --> 00:18:27,820
code base should be similar to ours in a

00:18:26,290 --> 00:18:30,220
sense that you will be able to find some

00:18:27,820 --> 00:18:32,770
low-hanging fruits that you will be able

00:18:30,220 --> 00:18:35,950
to optimize and reclaim massive amount

00:18:32,770 --> 00:18:38,980
of CPU and for optimizations you can use

00:18:35,950 --> 00:18:42,070
multiple tools but we can recommend you

00:18:38,980 --> 00:18:44,920
to consider saikhan and the reason is it

00:18:42,070 --> 00:18:47,980
will help you to avoid massive code

00:18:44,920 --> 00:18:50,140
rewrite it also allows you to gradually

00:18:47,980 --> 00:18:52,750
optimize your code so you can start with

00:18:50,140 --> 00:18:56,560
compiling existing code then adding some

00:18:52,750 --> 00:18:59,740
types then adding even more types and so

00:18:56,560 --> 00:19:01,480
it will preserve Python syntax so you

00:18:59,740 --> 00:19:03,820
don't have to learn new language that's

00:19:01,480 --> 00:19:08,020
basically Python just with types and

00:19:03,820 --> 00:19:10,150
maybe a few more weird constructions and

00:19:08,020 --> 00:19:13,180
last but not least it will preserve

00:19:10,150 --> 00:19:16,090
existing runtime so you will be able to

00:19:13,180 --> 00:19:19,630
keep using C pythons and no changes in

00:19:16,090 --> 00:19:23,260
infrastructure are required okay that's

00:19:19,630 --> 00:19:25,540
probably it you can go to site and ozark

00:19:23,260 --> 00:19:29,050
and check the documentation it's pretty

00:19:25,540 --> 00:19:31,810
good and I'm not sure why I put

00:19:29,050 --> 00:19:34,560
Instagram reference here but go to

00:19:31,810 --> 00:19:37,560
Instagram let's go -

00:19:34,560 --> 00:19:37,560
yes

00:19:45,099 --> 00:19:50,899
questions yeah please

00:19:48,950 --> 00:19:53,899
so I went to an earlier talk about type

00:19:50,899 --> 00:19:56,749
annotations in cpython

00:19:53,899 --> 00:20:00,739
and I was wondering if there's anybody

00:19:56,749 --> 00:20:02,419
thinking about making it so that when

00:20:00,739 --> 00:20:04,460
you do that you automatically get these

00:20:02,419 --> 00:20:08,269
kinds of benefits they're new projects

00:20:04,460 --> 00:20:12,489
like that so first of all satin is a

00:20:08,269 --> 00:20:16,729
good citizen so as I as I mentioned it

00:20:12,489 --> 00:20:17,869
supports almost like all features it

00:20:16,729 --> 00:20:20,690
slightly behind with supports all

00:20:17,869 --> 00:20:22,940
features that the normal Python has it

00:20:20,690 --> 00:20:25,969
but now it will just ignore all type

00:20:22,940 --> 00:20:28,399
annotations that you provided so the

00:20:25,969 --> 00:20:32,359
reason it is that big is that two type

00:20:28,399 --> 00:20:33,769
systems my PI type system and sight on

00:20:32,359 --> 00:20:35,960
type systems they're not very compatible

00:20:33,769 --> 00:20:36,649
and they were designed for different

00:20:35,960 --> 00:20:39,109
reasons

00:20:36,649 --> 00:20:42,649
so sight on type system is designed more

00:20:39,109 --> 00:20:46,070
for optimization basically for workflow

00:20:42,649 --> 00:20:48,529
and to map to more primitive types while

00:20:46,070 --> 00:20:50,989
my PI type system is designed for

00:20:48,529 --> 00:20:54,619
different reason it's more for developer

00:20:50,989 --> 00:20:59,299
velocity and to keep you know better

00:20:54,619 --> 00:21:02,710
than me probably so and types that my PI

00:20:59,299 --> 00:21:05,299
system has right now they're not very

00:21:02,710 --> 00:21:07,909
convertible and there's not much that

00:21:05,299 --> 00:21:11,479
seitan can use from it for example list

00:21:07,909 --> 00:21:15,320
int of course we can safely assume that

00:21:11,479 --> 00:21:16,969
it's a list but we cannot take a lot of

00:21:15,320 --> 00:21:19,989
advantage that it's a list of integers

00:21:16,969 --> 00:21:22,099
or for example if you put iterable int

00:21:19,989 --> 00:21:23,749
site and doesn't actually need to do

00:21:22,099 --> 00:21:26,690
that like if you in your function

00:21:23,749 --> 00:21:29,479
iterate through that object so item can

00:21:26,690 --> 00:21:32,960
automatically understand that it's

00:21:29,479 --> 00:21:37,070
iterable without any type annotations so

00:21:32,960 --> 00:21:38,779
you can argue that you can use it for

00:21:37,070 --> 00:21:41,509
primitive types such as integers and

00:21:38,779 --> 00:21:45,559
strings but even then it's not quite

00:21:41,509 --> 00:21:48,830
safe to map Python into c int because

00:21:45,559 --> 00:21:51,229
you can I don't for example if input is

00:21:48,830 --> 00:21:53,149
more than 32-bit integer you'll probably

00:21:51,229 --> 00:21:56,059
have a bad time so right now I don't

00:21:53,149 --> 00:22:01,399
think there are plans to merge them

00:21:56,059 --> 00:22:05,059
okay thank you can can sight on release

00:22:01,399 --> 00:22:07,340
the Gil inside yes yes that's another

00:22:05,059 --> 00:22:10,909
feature you can actually have fair

00:22:07,340 --> 00:22:13,369
threads like like inside of sight on and

00:22:10,909 --> 00:22:16,429
you can release Gil and it actually

00:22:13,369 --> 00:22:20,179
takes scare like one trick there is that

00:22:16,429 --> 00:22:24,739
you cannot cannot work with any Python

00:22:20,179 --> 00:22:28,309
objects but actually flatten provides

00:22:24,739 --> 00:22:31,429
ways to keep you safe and to explicative

00:22:28,309 --> 00:22:34,549
like view that no you cannot mark you

00:22:31,429 --> 00:22:36,440
cannot release Gil here because we do

00:22:34,549 --> 00:22:41,839
some stuff with Python objects here so

00:22:36,440 --> 00:22:45,710
yeah it can it can really go does site

00:22:41,839 --> 00:22:48,339
on add steps to building you're

00:22:45,710 --> 00:22:49,820
distributing packages or to like a CI

00:22:48,339 --> 00:22:53,179
tool chain

00:22:49,820 --> 00:22:56,379
I'll just compile the code so when you

00:22:53,179 --> 00:22:59,899
compile code it will produce a so file

00:22:56,379 --> 00:23:02,809
that you will be able to use as a normal

00:22:59,899 --> 00:23:05,149
shared library or almost the same as it

00:23:02,809 --> 00:23:08,330
will be pi file right so and how you

00:23:05,149 --> 00:23:11,029
distribute yours like is that like all

00:23:08,330 --> 00:23:13,549
your like code base to production

00:23:11,029 --> 00:23:17,929
machines that's totally up to you so we

00:23:13,549 --> 00:23:20,659
it has nice tools to like that can

00:23:17,929 --> 00:23:25,669
simplify calculation but we for example

00:23:20,659 --> 00:23:27,349
we built our own like pipeline and then

00:23:25,669 --> 00:23:31,519
you just distribute the objects

00:23:27,349 --> 00:23:33,259
separately yeah yeah thank you okay so

00:23:31,519 --> 00:23:35,179
sort of slightly related was one of your

00:23:33,259 --> 00:23:36,859
examples was like about the Django

00:23:35,179 --> 00:23:38,330
writing system and like compiling that

00:23:36,859 --> 00:23:41,269
bit so like how do you deal with

00:23:38,330 --> 00:23:43,039
compiling just a tiny bit of one library

00:23:41,269 --> 00:23:45,950
and not the rest of it and like how do

00:23:43,039 --> 00:23:49,700
you ship that you can compile files so

00:23:45,950 --> 00:23:51,859
we just took one file that the inside of

00:23:49,700 --> 00:23:54,679
the file in the file contains all

00:23:51,859 --> 00:23:57,169
critical functions that work heavily

00:23:54,679 --> 00:23:59,779
that used heavily CPU like basically

00:23:57,169 --> 00:24:02,539
don't use the tip package for Django

00:23:59,779 --> 00:24:04,190
anymore you know no no yeah no we still

00:24:02,539 --> 00:24:06,830
use Django we just

00:24:04,190 --> 00:24:08,390
on import stage we just watch one

00:24:06,830 --> 00:24:09,290
particular file and that's it Oh

00:24:08,390 --> 00:24:12,320
interesting

00:24:09,290 --> 00:24:14,870
so we move to this file to our code base

00:24:12,320 --> 00:24:17,000
compiled it ends and just a lot yes that

00:24:14,870 --> 00:24:21,830
okay cool thank you we didn't compile

00:24:17,000 --> 00:24:23,330
whole jungle I've got a couple of

00:24:21,830 --> 00:24:25,460
questions first you know roughly how

00:24:23,330 --> 00:24:28,310
many in here areas you spend so far on

00:24:25,460 --> 00:24:34,760
converting things the site on much less

00:24:28,310 --> 00:24:36,860
than migration to poison tree so hello

00:24:34,760 --> 00:24:40,460
usually optimization on one particular

00:24:36,860 --> 00:24:41,360
module takes two hours yeah and then I

00:24:40,460 --> 00:24:43,370
was also wondering if you could talk a

00:24:41,360 --> 00:24:44,990
bit about what we did what we dig is

00:24:43,370 --> 00:24:48,440
problems you ran into we're when trying

00:24:44,990 --> 00:24:52,850
to convert a second like own stupidity

00:24:48,440 --> 00:24:56,120
that's int so sometimes I sometimes I

00:24:52,850 --> 00:24:58,760
assume that my function accepts a

00:24:56,120 --> 00:25:00,740
particular type of arguments but it

00:24:58,760 --> 00:25:02,690
doesn't says for example once assumes

00:25:00,740 --> 00:25:03,170
that it's integer but it's actually

00:25:02,690 --> 00:25:06,530
false

00:25:03,170 --> 00:25:11,750
and so I caused a bad situation with our

00:25:06,530 --> 00:25:13,250
website yeah rather than that well you

00:25:11,750 --> 00:25:15,530
should be careful with row pointers but

00:25:13,250 --> 00:25:18,170
as I said you should usually you don't

00:25:15,530 --> 00:25:21,760
actually use it I we actually used it

00:25:18,170 --> 00:25:26,930
only a few times maybe two times Thanks

00:25:21,760 --> 00:25:29,630
I thank you great doc I had a question

00:25:26,930 --> 00:25:33,200
about the kind of C extensions that it

00:25:29,630 --> 00:25:36,760
creates is it the C types based the

00:25:33,200 --> 00:25:39,320
extension or can you also have csfi

00:25:36,760 --> 00:25:42,710
based extension that works with other

00:25:39,320 --> 00:25:44,480
virtual machines so I'm not sure that

00:25:42,710 --> 00:25:46,760
I'm very capable to answer this question

00:25:44,480 --> 00:25:51,650
but site on it by itself is a tool to

00:25:46,760 --> 00:25:53,480
write extensions so can for example can

00:25:51,650 --> 00:25:55,340
do the extension to work with pipe I for

00:25:53,480 --> 00:25:57,470
example oh for Paiva yeah it's a support

00:25:55,340 --> 00:25:59,570
for Python yeah okay okay but it

00:25:57,470 --> 00:26:05,960
explicitly added the support it's not

00:25:59,570 --> 00:26:08,390
like I think it has I'm curious why if

00:26:05,960 --> 00:26:10,100
you get a 3x improvement on the

00:26:08,390 --> 00:26:12,770
dispatcher why would you just run it on

00:26:10,100 --> 00:26:14,270
all of Jenga what's the cherlene some

00:26:12,770 --> 00:26:15,980
downside what sir

00:26:14,270 --> 00:26:17,750
why aren't you why don't you run all of

00:26:15,980 --> 00:26:20,600
Jenga through site on it

00:26:17,750 --> 00:26:24,110
just one module get to it is there some

00:26:20,600 --> 00:26:26,480
downside to doing all of it or yeah

00:26:24,110 --> 00:26:29,390
that's a really long topic if you want

00:26:26,480 --> 00:26:31,850
we can share the flying but first of all

00:26:29,390 --> 00:26:33,860
compilation takes a lot of time so we

00:26:31,850 --> 00:26:37,550
usually recompile everything on every

00:26:33,860 --> 00:26:40,340
Ally curl out and and to answer your

00:26:37,550 --> 00:26:42,500
question we didn't have to Jango doesn't

00:26:40,340 --> 00:26:45,230
consume much CPU on our machines right

00:26:42,500 --> 00:26:48,590
now so it was one particular modules

00:26:45,230 --> 00:26:52,850
that consumed a lot so just yeah we just

00:26:48,590 --> 00:26:54,710
compiled that one and so one thing you

00:26:52,850 --> 00:26:57,260
didn't talk about that I know exists

00:26:54,710 --> 00:27:00,350
they're a bunch of essentially compiler

00:26:57,260 --> 00:27:01,940
flags that you can put in are you making

00:27:00,350 --> 00:27:03,260
use of any of those things I'm going to

00:27:01,940 --> 00:27:05,320
remember there you could like turn off

00:27:03,260 --> 00:27:09,830
type checking and various things and

00:27:05,320 --> 00:27:11,780
maybe even see like and we provided the

00:27:09,830 --> 00:27:16,480
trick codes I know I don't remember

00:27:11,780 --> 00:27:20,330
probably probably few again we can fold

00:27:16,480 --> 00:27:22,750
okay it's just okay thanks for this very

00:27:20,330 --> 00:27:29,829
heat discussion that thanks Alex again

00:27:22,750 --> 00:27:29,829

YouTube URL: https://www.youtube.com/watch?v=_1MSX7V28Po


