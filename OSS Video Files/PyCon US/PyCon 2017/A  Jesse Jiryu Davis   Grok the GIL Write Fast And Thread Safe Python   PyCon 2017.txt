Title: A  Jesse Jiryu Davis   Grok the GIL Write Fast And Thread Safe Python   PyCon 2017
Publication date: 2017-05-20
Playlist: PyCon 2017
Description: 
	"Speaker: A. Jesse Jiryu Davis

I wrote Python for years while holding mistaken notions about the Global Interpreter Lock, and I've met others in the same boat. The GIL's effect is simply this: only one thread can execute Python code at a time, while N other threads sleep or await network I/O. Let's read CPython interpreter source and try some examples to grok the GIL, and learn to write fast and thread-safe Python.

Slides can be found at: https://speakerdeck.com/pycon2017 and https://github.com/PyCon/2017-slides"
Captions: 
	00:01:15,450 --> 00:01:17,509
you

00:02:29,930 --> 00:02:34,310
all right everyone we're going to get

00:02:31,909 --> 00:02:38,769
started I'd like to introduce a Jesse

00:02:34,310 --> 00:02:38,769
jury Davis we are going to grok the Gil

00:02:39,490 --> 00:02:45,809
[Applause]

00:02:46,420 --> 00:02:53,689
I'd been programming Python for a number

00:02:50,269 --> 00:02:56,920
of years and kind of thought that I

00:02:53,689 --> 00:02:59,359
understood how multitasking worked I

00:02:56,920 --> 00:03:02,480
understood how it worked in Java and C

00:02:59,359 --> 00:03:04,310
and I kind of lazily expected that the

00:03:02,480 --> 00:03:07,510
same principles were applicable to

00:03:04,310 --> 00:03:10,060
Python I didn't really understand how

00:03:07,510 --> 00:03:13,099
multi-threading worked in Python

00:03:10,060 --> 00:03:16,340
particularly until I started working for

00:03:13,099 --> 00:03:18,980
MongoDB and once I got there we were

00:03:16,340 --> 00:03:21,829
writing the kind of complicated

00:03:18,980 --> 00:03:25,489
high-performance Python that required me

00:03:21,829 --> 00:03:29,000
to really understand how multi-threaded

00:03:25,489 --> 00:03:31,939
Python specifically works and in order

00:03:29,000 --> 00:03:36,829
to do that I finally really had to

00:03:31,939 --> 00:03:38,989
understand the Gil so who here has heard

00:03:36,829 --> 00:03:40,879
of the global interpreter lock please

00:03:38,989 --> 00:03:44,989
yeah

00:03:40,879 --> 00:03:50,840
who here has seen the global interpreter

00:03:44,989 --> 00:03:55,069
lock so almost everybody here is in the

00:03:50,840 --> 00:04:01,099
same position that I was in then let's

00:03:55,069 --> 00:04:04,129
be curious let's look at it so I've got

00:04:01,099 --> 00:04:08,930
Python 2.7 checked out of github here in

00:04:04,129 --> 00:04:11,180
my editor I'm using Python 2 rather than

00:04:08,930 --> 00:04:13,939
3 because the code that we want to look

00:04:11,180 --> 00:04:14,900
at is simpler in Python 2 but everything

00:04:13,939 --> 00:04:18,340
that we're going to talk about today

00:04:14,900 --> 00:04:21,169
will be equally applicable to Python 3

00:04:18,340 --> 00:04:27,919
let's go find the Gil it's going to be

00:04:21,169 --> 00:04:30,470
in a file called C eval dot C and what

00:04:27,919 --> 00:04:32,630
this file contains is all of the logic

00:04:30,470 --> 00:04:36,409
that's at the core of the interpreter

00:04:32,630 --> 00:04:40,550
where it actually as Guido says execute

00:04:36,409 --> 00:04:42,950
compiled code and like any respectable

00:04:40,550 --> 00:04:43,790
old software project it's also got a 20

00:04:42,950 --> 00:04:45,980
year old to do with

00:04:43,790 --> 00:04:50,870
the top which has long since been done

00:04:45,980 --> 00:04:53,210
but we forgot to delete the comment the

00:04:50,870 --> 00:05:02,030
gill is in here somewhere so let's find

00:04:53,210 --> 00:05:04,640
it once the gill was famous guido added

00:05:02,030 --> 00:05:06,470
this helpful comment around 2003 but the

00:05:04,640 --> 00:05:09,430
gill has been here since the early 1990s

00:05:06,470 --> 00:05:13,970
since he first wrote a multi-threaded

00:05:09,430 --> 00:05:16,100
Python interpreter the global

00:05:13,970 --> 00:05:19,610
interpreter lock locks name is

00:05:16,100 --> 00:05:22,700
interpreter lock it's type is PI thread

00:05:19,610 --> 00:05:25,340
type lock and that's just an alias for

00:05:22,700 --> 00:05:30,140
whatever is the most basic lock on your

00:05:25,340 --> 00:05:34,070
system on UNIX this is a mutex a mutual

00:05:30,140 --> 00:05:37,370
exclusion lock it means that when one

00:05:34,070 --> 00:05:39,050
thread grabs it no other thread can have

00:05:37,370 --> 00:05:43,220
it until the thread that is holding it

00:05:39,050 --> 00:05:45,590
drops it on Windows it's something else

00:05:43,220 --> 00:05:47,570
with the same behavior we can see that

00:05:45,590 --> 00:05:49,430
it's static which means that there is

00:05:47,570 --> 00:05:53,350
only one of them for the entire trip

00:05:49,430 --> 00:05:55,550
interpreter process it is truly global

00:05:53,350 --> 00:06:00,440
the other thing that we can see here is

00:05:55,550 --> 00:06:02,480
that it's initialized at the very

00:06:00,440 --> 00:06:04,370
beginning of the interpreters startup

00:06:02,480 --> 00:06:08,630
the main thread calls this function PI

00:06:04,370 --> 00:06:11,510
eval and it threads allocates some loc

00:06:08,630 --> 00:06:14,090
it's going to be a mutex on UNIX on

00:06:11,510 --> 00:06:15,950
Windows of something else and the other

00:06:14,090 --> 00:06:18,560
interesting thing to see here is that as

00:06:15,950 --> 00:06:22,340
soon as the main thread has created the

00:06:18,560 --> 00:06:27,710
gill it locks it the gill is born locked

00:06:22,340 --> 00:06:30,380
but a main thread the mutex is a lock

00:06:27,710 --> 00:06:34,670
that threads have to hold whenever they

00:06:30,380 --> 00:06:38,690
are executing Python code and this leads

00:06:34,670 --> 00:06:40,760
us to a principle about how the gill

00:06:38,690 --> 00:06:43,010
affects our multi-threaded programs

00:06:40,760 --> 00:06:48,740
that's simple enough that you could read

00:06:43,010 --> 00:06:52,430
it on one hand one thread runs Python

00:06:48,740 --> 00:06:53,930
will end others sleep or oh wait io and

00:06:52,430 --> 00:06:57,460
if that's a little hard to read like

00:06:53,930 --> 00:06:57,460
that then we can see like this again

00:06:57,620 --> 00:07:02,700
you can have a truly multi-threaded

00:07:00,660 --> 00:07:04,860
Python program all of your other threads

00:07:02,700 --> 00:07:07,680
can be doing other things they can sleep

00:07:04,860 --> 00:07:09,900
they can establish network connections

00:07:07,680 --> 00:07:17,550
the only thing that two threads can't do

00:07:09,900 --> 00:07:19,020
it once in Python is run Python now this

00:07:17,550 --> 00:07:20,970
principle is simple enough to write on

00:07:19,020 --> 00:07:23,840
your hand but it might take a little bit

00:07:20,970 --> 00:07:26,790
of work to really wrap your head around

00:07:23,840 --> 00:07:29,340
what this means for your programs I like

00:07:26,790 --> 00:07:35,100
to think of my Python programs like an

00:07:29,340 --> 00:07:37,530
old mainframe computer this is a PDP 6

00:07:35,100 --> 00:07:40,200
it's a mainframe from the late 1960s is

00:07:37,530 --> 00:07:43,830
one of the first to implement this idea

00:07:40,200 --> 00:07:46,380
at the time slicing even though this

00:07:43,830 --> 00:07:50,880
mainframe only has one processor it

00:07:46,380 --> 00:07:54,950
could simulate parallel execution by

00:07:50,880 --> 00:07:58,230
rapidly swapping off among various tasks

00:07:54,950 --> 00:08:00,000
so even though it only does one thing at

00:07:58,230 --> 00:08:03,300
a time it appears to be doing multiple

00:08:00,000 --> 00:08:07,760
things at a time your Python programs

00:08:03,300 --> 00:08:10,140
running in C Python act the same way and

00:08:07,760 --> 00:08:11,850
over the years there have been many

00:08:10,140 --> 00:08:13,500
attempts like why did Wed agree to

00:08:11,850 --> 00:08:17,220
implement it this way

00:08:13,500 --> 00:08:19,440
first of all is simple and it's very

00:08:17,220 --> 00:08:22,020
fast for single threaded execution and

00:08:19,440 --> 00:08:25,220
in the early 1990s multi-core computers

00:08:22,020 --> 00:08:27,480
were less widespread than they are now

00:08:25,220 --> 00:08:31,260
there have been many attempts in the

00:08:27,480 --> 00:08:36,270
years since to work around this to get

00:08:31,260 --> 00:08:38,400
truly parallel Python there's JSON which

00:08:36,270 --> 00:08:40,500
is based on the JVM it's free threaded

00:08:38,400 --> 00:08:45,240
but it's got a lot of incompatibilities

00:08:40,500 --> 00:08:47,730
with C Python there's a experiment a

00:08:45,240 --> 00:08:51,690
research project in pi pi to remove the

00:08:47,730 --> 00:08:53,670
Gil from pi PI and over in the next room

00:08:51,690 --> 00:08:56,880
Larry Hastings is giving us an update on

00:08:53,670 --> 00:09:01,770
his a Gil ectomy his surgical removal of

00:08:56,880 --> 00:09:03,360
the Gil from standard C Python and so

00:09:01,770 --> 00:09:05,930
over in that room are a bunch of

00:09:03,360 --> 00:09:05,930
idealists

00:09:08,300 --> 00:09:15,530
people who want to know what the future

00:09:11,430 --> 00:09:20,040
might look like and you and I are

00:09:15,530 --> 00:09:21,570
practical we want to know how do we

00:09:20,040 --> 00:09:29,460
write fast and thread-safe

00:09:21,570 --> 00:09:32,400
Python with C Python today now

00:09:29,460 --> 00:09:33,260
Python has two kinds of multitasking in

00:09:32,400 --> 00:09:37,230
it

00:09:33,260 --> 00:09:40,040
cooperative and pre-emptive cooperative

00:09:37,230 --> 00:09:42,480
multitasking is where a thread is

00:09:40,040 --> 00:09:44,010
running long executing Python and at

00:09:42,480 --> 00:09:46,170
some point it does something that it

00:09:44,010 --> 00:09:49,290
knows might take a while like establish

00:09:46,170 --> 00:09:51,570
a connection since it doesn't need to

00:09:49,290 --> 00:09:54,780
run anymore Python for a little while it

00:09:51,570 --> 00:09:56,280
drops the Gil voluntarily so that other

00:09:54,780 --> 00:10:01,500
threads can run Python

00:09:56,280 --> 00:10:04,710
well this thread does something else the

00:10:01,500 --> 00:10:06,960
other kind of multitasking which is also

00:10:04,710 --> 00:10:09,630
implemented in c python is pre-emptive

00:10:06,960 --> 00:10:11,730
multitasking that happens when a threads

00:10:09,630 --> 00:10:14,610
been running and using the Gil for a

00:10:11,730 --> 00:10:16,560
certain period of time and the

00:10:14,610 --> 00:10:18,480
interpreter decides that it's had the

00:10:16,560 --> 00:10:21,210
Gil long enough and it grabs the Gil

00:10:18,480 --> 00:10:22,830
away from the thread and forces it to

00:10:21,210 --> 00:10:26,460
drop ago so that some of the thread can

00:10:22,830 --> 00:10:29,340
run Python instead this is like what I

00:10:26,460 --> 00:10:32,670
hope you learned in and when you were a

00:10:29,340 --> 00:10:34,590
toddler that if you're sitting on the

00:10:32,670 --> 00:10:37,200
swing and then you're done swinging you

00:10:34,590 --> 00:10:39,060
don't just kind of sit grumpily on that

00:10:37,200 --> 00:10:41,910
swing for the rest of recess so no other

00:10:39,060 --> 00:10:44,010
kids can use it you get up and you go do

00:10:41,910 --> 00:10:47,400
something else and other kids can use

00:10:44,010 --> 00:10:49,110
the swing sets so a cooperative

00:10:47,400 --> 00:10:51,450
multitasking is when you get up and you

00:10:49,110 --> 00:10:53,550
leave the swing set behind this little

00:10:51,450 --> 00:10:55,760
girl is ripe for pre-emptive

00:10:53,550 --> 00:10:57,780
multitasking which is that the

00:10:55,760 --> 00:11:00,300
interpreter is going to take the Gil

00:10:57,780 --> 00:11:02,940
away from her after she's used it

00:11:00,300 --> 00:11:05,970
this happens every thousand byte codes

00:11:02,940 --> 00:11:07,740
in Python to ended in Python 3 and 20

00:11:05,970 --> 00:11:11,340
true rewrote the whole thing to be much

00:11:07,740 --> 00:11:12,600
better and now 15 milliseconds but you

00:11:11,340 --> 00:11:13,920
don't really have to worry about that

00:11:12,600 --> 00:11:18,240
distinction when you're writing your

00:11:13,920 --> 00:11:19,699
code we're going to look at examples of

00:11:18,240 --> 00:11:21,829
both of these

00:11:19,699 --> 00:11:25,489
first we're going to look at an example

00:11:21,829 --> 00:11:27,139
of cooperative multitasking where I'm

00:11:25,489 --> 00:11:28,489
going to start two threads and on each

00:11:27,139 --> 00:11:30,799
of those threads I'll establish a

00:11:28,489 --> 00:11:33,049
network connection and we're going to

00:11:30,799 --> 00:11:36,439
see that because cooperative

00:11:33,049 --> 00:11:39,919
multitasking works each of them can wait

00:11:36,439 --> 00:11:41,569
at the same time for that connection to

00:11:39,919 --> 00:11:48,230
be established and then they'll both

00:11:41,569 --> 00:11:50,559
resume once that's happened so I've

00:11:48,230 --> 00:11:52,730
written you a little program here and

00:11:50,559 --> 00:11:54,889
since we're going to do Network stuff

00:11:52,730 --> 00:11:56,419
with threads we import socket and

00:11:54,889 --> 00:11:59,119
threading and then I'm going to make a

00:11:56,419 --> 00:12:02,839
list of messages here where I'll just

00:11:59,119 --> 00:12:06,319
use this to record what the program does

00:12:02,839 --> 00:12:10,220
at every step then I've got a function

00:12:06,319 --> 00:12:15,230
here called do connect which creates a

00:12:10,220 --> 00:12:19,160
socket and it records that it started to

00:12:15,230 --> 00:12:22,759
connect and then it connects to python

00:12:19,160 --> 00:12:26,079
org on port 80 and then it's going to

00:12:22,759 --> 00:12:26,079
write that it has finished connecting

00:12:26,230 --> 00:12:31,100
now we're going to start two threads and

00:12:29,269 --> 00:12:34,579
each of them will execute this do

00:12:31,100 --> 00:12:36,769
connect function we start both threads

00:12:34,579 --> 00:12:39,169
and that we call join on both threads

00:12:36,769 --> 00:12:41,209
which makes the main thread wait until

00:12:39,169 --> 00:12:45,230
both threads have finished and then

00:12:41,209 --> 00:12:46,939
we're going to print out the list of

00:12:45,230 --> 00:12:48,589
messages that they've recorded so the

00:12:46,939 --> 00:12:51,649
question here is are we going to see

00:12:48,589 --> 00:12:53,419
that one thread completes all of its

00:12:51,649 --> 00:12:54,739
work before the other thread can start

00:12:53,419 --> 00:12:56,629
or are we going to see some sort of

00:12:54,739 --> 00:13:04,429
interleaving some cooperation between

00:12:56,629 --> 00:13:06,799
them let's find out so that's

00:13:04,429 --> 00:13:08,929
interesting right we see connecting

00:13:06,799 --> 00:13:11,929
connecting connected connected what does

00:13:08,929 --> 00:13:14,839
that tell you that tells you that when

00:13:11,929 --> 00:13:17,809
the first thread reached this spot it

00:13:14,839 --> 00:13:20,299
dropped the Gil and that allowed the

00:13:17,809 --> 00:13:22,399
other thread to also start up execute

00:13:20,299 --> 00:13:25,100
enough Python to also reach that spot

00:13:22,399 --> 00:13:27,499
and then also drop the Gil and then they

00:13:25,100 --> 00:13:30,949
complete it in some order or another so

00:13:27,499 --> 00:13:33,620
how is this actually possible how does

00:13:30,949 --> 00:13:41,240
the interpreter allow threads to

00:13:33,620 --> 00:13:44,270
operate in this way let's take a look so

00:13:41,240 --> 00:13:46,400
when you call import socket the logic

00:13:44,270 --> 00:13:51,200
that you are bringing into your program

00:13:46,400 --> 00:13:53,810
is all implemented in C in a file here

00:13:51,200 --> 00:13:54,950
called socket module C and the

00:13:53,810 --> 00:13:57,020
particular function that we're

00:13:54,950 --> 00:13:59,870
interested in here is socket connect

00:13:57,020 --> 00:14:03,650
which is the socket connect function in

00:13:59,870 --> 00:14:05,839
Python and this is all in C and it takes

00:14:03,650 --> 00:14:08,450
a couple of arguments the the socket

00:14:05,839 --> 00:14:10,460
object which is like self and the

00:14:08,450 --> 00:14:12,890
address that it's going to connect to

00:14:10,460 --> 00:14:16,880
and it needs to do a little bit of work

00:14:12,890 --> 00:14:22,760
to convert that Python tuple into a

00:14:16,880 --> 00:14:26,270
standard C address thing and if that

00:14:22,760 --> 00:14:31,070
works then it does these three lines and

00:14:26,270 --> 00:14:33,920
this is really important that I begin

00:14:31,070 --> 00:14:37,640
allows threads macro that's where this

00:14:33,920 --> 00:14:39,529
thread drops the Gil because on the next

00:14:37,640 --> 00:14:42,350
line it's going to call internal connect

00:14:39,529 --> 00:14:45,470
and that'll do something or other but

00:14:42,350 --> 00:14:47,870
it's all purely in C it establishes that

00:14:45,470 --> 00:14:51,339
connection using pure thread safe C and

00:14:47,870 --> 00:14:53,990
does not touch the interpreter at all

00:14:51,339 --> 00:14:56,660
then once that work is completed calls

00:14:53,990 --> 00:14:58,580
PI and allows threads and reacquires the

00:14:56,660 --> 00:15:02,570
guild before it touches the interpreter

00:14:58,580 --> 00:15:05,959
again now if there are no other threads

00:15:02,570 --> 00:15:07,820
competing for the guild then PI and

00:15:05,959 --> 00:15:10,940
allow threads will allow to immediately

00:15:07,820 --> 00:15:13,700
reacquire the Gil and continue if there

00:15:10,940 --> 00:15:15,110
are other threads that are competing for

00:15:13,700 --> 00:15:17,330
the Gil like say some other thread is

00:15:15,110 --> 00:15:20,029
holding the Gil by this point then this

00:15:17,330 --> 00:15:21,920
thread will have to block there until it

00:15:20,029 --> 00:15:24,800
gets a chance to lock the global

00:15:21,920 --> 00:15:26,630
interpreter lock again but one way or

00:15:24,800 --> 00:15:29,390
another by the time it gets down here

00:15:26,630 --> 00:15:32,660
it's holding the lock and so it can do

00:15:29,390 --> 00:15:35,000
python e things again like if there was

00:15:32,660 --> 00:15:37,610
an error it can call high error set

00:15:35,000 --> 00:15:42,050
string which is the way to raise a

00:15:37,610 --> 00:15:44,880
Python exception from C or if everything

00:15:42,050 --> 00:15:48,870
went okay then it returns none

00:15:44,880 --> 00:15:54,449
and if this.c function returns none then

00:15:48,870 --> 00:15:57,149
it pops back out here and because it's

00:15:54,449 --> 00:16:00,389
holding the Gil it can run the rest of

00:15:57,149 --> 00:16:03,240
the Python on this thread and finish up

00:16:00,389 --> 00:16:06,420
so that's why we're able to see these

00:16:03,240 --> 00:16:07,680
two threads sharing the Gil while

00:16:06,420 --> 00:16:13,980
they're doing cooperative multitasking

00:16:07,680 --> 00:16:17,790
like network operations but what about

00:16:13,980 --> 00:16:20,250
pre-emptive I'm going to show you

00:16:17,790 --> 00:16:22,800
another little Python program here which

00:16:20,250 --> 00:16:24,990
will not do any sockets stuff so we'll

00:16:22,800 --> 00:16:26,940
never deliberately drop the global

00:16:24,990 --> 00:16:30,569
interpreter lock we're just going to do

00:16:26,940 --> 00:16:32,720
pure calculation I'm going to do a big

00:16:30,569 --> 00:16:35,370
loop on two threads at the same time and

00:16:32,720 --> 00:16:41,519
we'll see whether these threads share

00:16:35,370 --> 00:16:43,680
the Gil or not so that's over here now I

00:16:41,519 --> 00:16:46,829
don't need socket anymore so just import

00:16:43,680 --> 00:16:50,699
threading and my calculation heavy

00:16:46,829 --> 00:16:52,740
function here is called run and it has

00:16:50,699 --> 00:16:54,930
an outer loop that goes 5 4 3 times in

00:16:52,740 --> 00:16:57,720
every outer iteration it also does an

00:16:54,930 --> 00:16:59,370
inner loop 500 times every time it

00:16:57,720 --> 00:17:01,649
finishes one of the outer iterations it

00:16:59,370 --> 00:17:05,660
will print its name or rather it will

00:17:01,649 --> 00:17:05,660
append its name to the list of messages

00:17:05,809 --> 00:17:09,659
besides that the rest of the code is

00:17:07,949 --> 00:17:13,679
pretty much the same we're going to

00:17:09,659 --> 00:17:17,370
start two threads their arguments will

00:17:13,679 --> 00:17:19,289
be their names 0 & 1 we wait for them

00:17:17,370 --> 00:17:21,390
both to finish and then we print out the

00:17:19,289 --> 00:17:23,699
messages that they wrote the question

00:17:21,390 --> 00:17:27,990
here is going to be are we going to see

00:17:23,699 --> 00:17:29,850
just the first thread write 0 0 0 until

00:17:27,990 --> 00:17:32,909
it's done and then the other thread

00:17:29,850 --> 00:17:36,590
write 1 1 1 until it's done or are they

00:17:32,909 --> 00:17:43,110
going to be able to share the Gil like

00:17:36,590 --> 00:17:44,880
well-trained toddlers alright so a lot

00:17:43,110 --> 00:17:49,350
of output let's kind of scroll up to the

00:17:44,880 --> 00:17:52,260
top here alright so we see thread 0

00:17:49,350 --> 00:17:55,380
runs for a bunch of iterations and then

00:17:52,260 --> 00:17:58,630
thread 1 runs for a bunch of iterations

00:17:55,380 --> 00:18:01,810
as well and then 0

00:17:58,630 --> 00:18:03,220
and then one so they're able to somehow

00:18:01,810 --> 00:18:05,200
trade off the Gil

00:18:03,220 --> 00:18:07,060
even though they're never calling any

00:18:05,200 --> 00:18:10,210
socket operations that would voluntarily

00:18:07,060 --> 00:18:14,290
drop it how is this actually implemented

00:18:10,210 --> 00:18:15,850
in the interpreter in order to find that

00:18:14,290 --> 00:18:19,480
code we're going to have to go back to

00:18:15,850 --> 00:18:21,190
that file see eval dot C that is the

00:18:19,480 --> 00:18:23,110
kind of L like beating heart of the

00:18:21,190 --> 00:18:27,040
interpreter the place that it actually

00:18:23,110 --> 00:18:28,420
executes spy code and let's let's

00:18:27,040 --> 00:18:33,400
actually take a step back here for a

00:18:28,420 --> 00:18:36,880
second your Python code is executed kind

00:18:33,400 --> 00:18:40,420
of in two phases the Python text that

00:18:36,880 --> 00:18:45,730
you type is first compiled into byte

00:18:40,420 --> 00:18:47,710
code which is a simple binary list of

00:18:45,730 --> 00:18:50,620
very simple primitive instructions and

00:18:47,710 --> 00:18:52,510
then that byte code is interpreted by

00:18:50,620 --> 00:18:54,370
the interpreter which kind of executes

00:18:52,510 --> 00:18:56,200
like a little virtual machine that

00:18:54,370 --> 00:18:59,740
executes those instructions one after

00:18:56,200 --> 00:19:02,920
another and that stuff that's over in C

00:18:59,740 --> 00:19:06,040
of L dot C and the place that we're

00:19:02,920 --> 00:19:09,550
going to look for we're pre-emptive

00:19:06,040 --> 00:19:12,640
multitasking is implemented is down here

00:19:09,550 --> 00:19:15,870
where Guido has nicely signposted us

00:19:12,640 --> 00:19:19,390
that this is the interpreter main loop

00:19:15,870 --> 00:19:22,990
as the interpreter main loop is a

00:19:19,390 --> 00:19:28,270
function with with this a beautiful

00:19:22,990 --> 00:19:30,580
title PI eval eval frame X and we can

00:19:28,270 --> 00:19:34,180
read it we can actually understand to

00:19:30,580 --> 00:19:36,430
some extent what we're looking at so it

00:19:34,180 --> 00:19:38,400
takes a frame object that contains all

00:19:36,430 --> 00:19:40,810
the code that it's going to execute and

00:19:38,400 --> 00:19:42,280
it kind of creates a little virtual

00:19:40,810 --> 00:19:44,290
machine here with things like a stack

00:19:42,280 --> 00:19:48,100
pointer and appointed to the next

00:19:44,290 --> 00:19:51,070
instruction it's going to execute we can

00:19:48,100 --> 00:19:53,050
scroll down a little bit I don't really

00:19:51,070 --> 00:19:57,010
know what all this stuff is about to be

00:19:53,050 --> 00:19:59,230
honest but things get sort of

00:19:57,010 --> 00:20:03,900
interesting over here who here has used

00:19:59,230 --> 00:20:06,940
a debugger like like gdb or like pycharm

00:20:03,900 --> 00:20:09,250
good almost all of you great if you

00:20:06,940 --> 00:20:10,630
haven't that is absolutely the next

00:20:09,250 --> 00:20:11,340
thing you should do to level up your

00:20:10,630 --> 00:20:15,630
ears

00:20:11,340 --> 00:20:17,070
bills and debuggers are sort of magical

00:20:15,630 --> 00:20:18,750
they can hit break points whenever you

00:20:17,070 --> 00:20:21,840
tell them to this is how they actually

00:20:18,750 --> 00:20:23,850
work they register a thing called a

00:20:21,840 --> 00:20:25,950
trace function which is a callback that

00:20:23,850 --> 00:20:28,320
the interpreter executes every time it

00:20:25,950 --> 00:20:30,510
starts a function call and this is where

00:20:28,320 --> 00:20:32,970
it tells the debugger I've started a

00:20:30,510 --> 00:20:37,790
function call if you need to do anything

00:20:32,970 --> 00:20:41,070
in this moment here's your opportunity

00:20:37,790 --> 00:20:44,070
similar with profilers like C profile or

00:20:41,070 --> 00:20:47,220
yappi they execute they register

00:20:44,070 --> 00:20:49,080
callbacks also and that's how they know

00:20:47,220 --> 00:20:51,960
when a function call begins and ends is

00:20:49,080 --> 00:20:53,520
this profile func so that's kind of cool

00:20:51,960 --> 00:20:55,560
we're looking at the heart of the

00:20:53,520 --> 00:20:57,630
interpreter and we sort of understand

00:20:55,560 --> 00:20:59,190
what we're looking at but we haven't

00:20:57,630 --> 00:21:02,130
found what we're really searching for

00:20:59,190 --> 00:21:05,700
yet which is where does the interpreter

00:21:02,130 --> 00:21:07,460
grab the Gil preemptively from a thread

00:21:05,700 --> 00:21:12,510
that's been holding the Gil for too long

00:21:07,460 --> 00:21:14,940
so let's keep looking all right there's

00:21:12,510 --> 00:21:17,310
like a bunch of setup here there appear

00:21:14,940 --> 00:21:24,540
to be in jokes that I don't get y equals

00:21:17,310 --> 00:21:26,340
y not and then this is interesting right

00:21:24,540 --> 00:21:29,700
whenever you see an infinite loop you

00:21:26,340 --> 00:21:32,430
should probably stop and think this is

00:21:29,700 --> 00:21:34,530
where this function executes syou're

00:21:32,430 --> 00:21:36,900
byte codes one after another after

00:21:34,530 --> 00:21:38,520
another until one of them either returns

00:21:36,900 --> 00:21:42,600
from this function or throws an

00:21:38,520 --> 00:21:46,080
exception and right at the top here

00:21:42,600 --> 00:21:47,310
Guido says do periodic things doing this

00:21:46,080 --> 00:21:49,200
every time through the loop would add

00:21:47,310 --> 00:21:53,310
too much overhead so we do it only every

00:21:49,200 --> 00:21:57,330
nth instruction and n here is 1,000 by

00:21:53,310 --> 00:21:59,160
default that's the check interval so now

00:21:57,330 --> 00:22:02,070
the code does just what Guido said it

00:21:59,160 --> 00:22:05,700
would which is it decrement some Tigger

00:22:02,070 --> 00:22:10,800
and if it goes below zero then it resets

00:22:05,700 --> 00:22:15,200
the ticker to a thousand and then look

00:22:10,800 --> 00:22:15,200
at this give another thread a chance

00:22:15,800 --> 00:22:21,260
the interpreter releases the lock the

00:22:18,920 --> 00:22:24,380
thread has no control over this right

00:22:21,260 --> 00:22:26,470
your Python code didn't agree to drop

00:22:24,380 --> 00:22:30,110
the lock the interpreter took it and

00:22:26,470 --> 00:22:31,820
other threads can run now and this

00:22:30,110 --> 00:22:33,920
thread immediately tries to get the lock

00:22:31,820 --> 00:22:35,600
back so if there's competition for the

00:22:33,920 --> 00:22:37,190
guild then you'll block here for a while

00:22:35,600 --> 00:22:38,720
waiting for some other thread to drop

00:22:37,190 --> 00:22:41,360
the Gil and for this thread to have a

00:22:38,720 --> 00:22:43,340
chance to grab it back if this is a

00:22:41,360 --> 00:22:45,470
single-threaded program or if all the

00:22:43,340 --> 00:22:48,380
other threads are asleep or awaiting i/o

00:22:45,470 --> 00:22:50,000
then all that will happen is every

00:22:48,380 --> 00:22:51,770
thousandth I've codes your thread will

00:22:50,000 --> 00:22:54,050
just drop the Gil and reacquire it

00:22:51,770 --> 00:23:01,720
immediately so it's very quick check

00:22:54,050 --> 00:23:04,460
here so now we've seen it we saw we're

00:23:01,720 --> 00:23:08,870
cooperative and pre-emptive multitasking

00:23:04,460 --> 00:23:11,830
are actually implemented is it time yet

00:23:08,870 --> 00:23:16,850
to start using what we've learned to

00:23:11,830 --> 00:23:20,960
write fast code first actually let me

00:23:16,850 --> 00:23:23,210
let me ask the question why does Python

00:23:20,960 --> 00:23:25,130
have multitasking at all like if it

00:23:23,210 --> 00:23:26,990
can't really run two threads in parallel

00:23:25,130 --> 00:23:29,200
at the same time then why does it have

00:23:26,990 --> 00:23:33,020
cooperative and pre-emptive multitasking

00:23:29,200 --> 00:23:37,370
the purpose of cooperative multitasking

00:23:33,020 --> 00:23:41,180
is to finish jobs faster if those jobs

00:23:37,370 --> 00:23:43,400
are primarily awaiting i/o the purpose

00:23:41,180 --> 00:23:45,350
of pre-emptive multitasking is not to go

00:23:43,400 --> 00:23:47,540
faster the purpose of pre-emptive

00:23:45,350 --> 00:23:50,360
multitasking is to simulate parallelism

00:23:47,540 --> 00:23:52,070
so instead of one thread running all the

00:23:50,360 --> 00:23:55,460
way to the end instead many threads

00:23:52,070 --> 00:23:58,340
appear to run in parallel but slowly all

00:23:55,460 --> 00:24:02,000
right but this kind of raises the

00:23:58,340 --> 00:24:05,510
question of of what about safety all

00:24:02,000 --> 00:24:07,070
right if you have a global interpreter

00:24:05,510 --> 00:24:10,790
lock do you need to worry about thread

00:24:07,070 --> 00:24:12,440
safety in Python like in a language like

00:24:10,790 --> 00:24:15,200
Java or C that's completely free

00:24:12,440 --> 00:24:19,010
threaded there's a basic principle that

00:24:15,200 --> 00:24:21,440
if multiple threads could read or write

00:24:19,010 --> 00:24:23,090
the same data at the same time then

00:24:21,440 --> 00:24:24,800
that's bad that can cause race

00:24:23,090 --> 00:24:27,410
conditions and so you should prevent

00:24:24,800 --> 00:24:28,940
that with locks right the basic

00:24:27,410 --> 00:24:29,510
principle is that you should lock around

00:24:28,940 --> 00:24:35,060
ax

00:24:29,510 --> 00:24:36,260
two shared mutable state I think that

00:24:35,060 --> 00:24:38,300
we'd better figure out whether this

00:24:36,260 --> 00:24:40,880
principle applies to Python two because

00:24:38,300 --> 00:24:43,340
going fast is great but going fast and

00:24:40,880 --> 00:24:46,430
being unsafe can lead to unfortunate

00:24:43,340 --> 00:24:48,770
consequences let's take a look at a

00:24:46,430 --> 00:24:52,640
program that's going to test this for us

00:24:48,770 --> 00:24:55,640
I'm just going to set some global

00:24:52,640 --> 00:24:57,620
variable n to 0 and try to increment it

00:24:55,640 --> 00:25:01,790
by one with a thousand threads at the

00:24:57,620 --> 00:25:05,030
same time and if the correct output of

00:25:01,790 --> 00:25:10,570
1,000 is what we get then we're probably

00:25:05,030 --> 00:25:10,570
thread safe so let's try the experiment

00:25:11,320 --> 00:25:17,990
all right we're going to import

00:25:13,550 --> 00:25:20,420
threading and sis and remember that the

00:25:17,990 --> 00:25:22,580
default check interval in Python 2 is

00:25:20,420 --> 00:25:25,190
every thousand byte codes I'm going to

00:25:22,580 --> 00:25:28,940
turn the knob down to 1 this is going to

00:25:25,190 --> 00:25:33,020
slow my code down and it allows a thread

00:25:28,940 --> 00:25:34,970
to lose the Gil at any moment and it

00:25:33,020 --> 00:25:39,650
makes race conditions much easier to

00:25:34,970 --> 00:25:42,890
manifest then I create global variable n

00:25:39,650 --> 00:25:45,410
equals 0 foo here is going to increment

00:25:42,890 --> 00:25:49,430
it by 1 and we're going to do this in a

00:25:45,410 --> 00:25:52,220
thousand threads simultaneously and once

00:25:49,430 --> 00:25:53,900
all have finished we'll print out the

00:25:52,220 --> 00:25:55,850
result so the question is are we going

00:25:53,900 --> 00:26:02,500
to get a thousand every time or is

00:25:55,850 --> 00:26:05,170
something going to go wrong here huh

00:26:02,500 --> 00:26:07,940
let's try it again

00:26:05,170 --> 00:26:12,110
all right sometimes a thousand sometimes

00:26:07,940 --> 00:26:14,710
a 999 sometimes 998 what is going wrong

00:26:12,110 --> 00:26:14,710
here

00:26:16,330 --> 00:26:24,040
we can actually uh see what the problem

00:26:22,060 --> 00:26:27,430
is with this function through by

00:26:24,040 --> 00:26:29,320
disassembling it we can use the Python

00:26:27,430 --> 00:26:31,690
standard libraries disk module to

00:26:29,320 --> 00:26:35,380
disassemble it and see the bytecode that

00:26:31,690 --> 00:26:38,140
it compiles to so let's simplify this

00:26:35,380 --> 00:26:39,760
program down so it's just foo we'll

00:26:38,140 --> 00:26:43,300
import this and we'll print the

00:26:39,760 --> 00:26:47,680
disassembly that this function compiles

00:26:43,300 --> 00:26:50,980
to him and this makes this rather nice

00:26:47,680 --> 00:26:55,030
print out here and we can see that even

00:26:50,980 --> 00:26:59,350
though a foo really only has one line of

00:26:55,030 --> 00:27:03,850
actual code it compiles to six byte

00:26:59,350 --> 00:27:06,780
codes these first four this is the

00:27:03,850 --> 00:27:11,620
implementation of n plus equals one

00:27:06,780 --> 00:27:14,230
first you load the value of the global

00:27:11,620 --> 00:27:16,810
variable N and that's the first thing on

00:27:14,230 --> 00:27:19,600
the stack and then you load one also on

00:27:16,810 --> 00:27:21,430
to the stack you add the two things that

00:27:19,600 --> 00:27:24,220
are at the top of the stack right now

00:27:21,430 --> 00:27:28,060
and then you store the result to a

00:27:24,220 --> 00:27:32,290
global variable and then the final two

00:27:28,060 --> 00:27:35,620
are just loading none onto the stack and

00:27:32,290 --> 00:27:37,990
then returning that as well every Python

00:27:35,620 --> 00:27:39,460
function has a return statement if you

00:27:37,990 --> 00:27:41,250
don't write it yourself the compiler

00:27:39,460 --> 00:27:45,580
will insert it so that's what that is

00:27:41,250 --> 00:27:49,030
the important thing is that that one

00:27:45,580 --> 00:27:52,030
line n plus equals one compiles to four

00:27:49,030 --> 00:27:56,380
byte codes and that gives us three

00:27:52,030 --> 00:27:59,230
possibilities to be interrupted so you

00:27:56,380 --> 00:28:03,100
can kind of see how this would go wrong

00:27:59,230 --> 00:28:05,530
if one thread loads the global value of

00:28:03,100 --> 00:28:07,360
n as let's say zero it's the first one

00:28:05,530 --> 00:28:09,250
that's started and then it adds one to

00:28:07,360 --> 00:28:12,060
it and right before it's about to store

00:28:09,250 --> 00:28:14,410
that result one back to the global value

00:28:12,060 --> 00:28:17,980
another thread starts up and interrupts

00:28:14,410 --> 00:28:21,340
it also loads zero as the global value

00:28:17,980 --> 00:28:24,180
of n also adds one to it stores its

00:28:21,340 --> 00:28:26,260
result one back to the global value and

00:28:24,180 --> 00:28:29,740
finishes and then the first thread we

00:28:26,260 --> 00:28:32,170
are talking about also stores one two

00:28:29,740 --> 00:28:35,020
global value so now two threads have

00:28:32,170 --> 00:28:36,940
completed incrementing n by one but the

00:28:35,020 --> 00:28:38,830
result is only one and if that happens a

00:28:36,940 --> 00:28:40,240
couple of times you'll end up with this

00:28:38,830 --> 00:28:43,840
result of 998

00:28:40,240 --> 00:28:45,370
when you're expecting a thousand so that

00:28:43,840 --> 00:28:47,020
means that the same principle applies

00:28:45,370 --> 00:28:49,120
even in Python even with a global

00:28:47,020 --> 00:28:52,179
interpreter lock that you have to lock

00:28:49,120 --> 00:28:55,630
around shared mutable state so let's do

00:28:52,179 --> 00:28:59,620
this here's the code before the unsafe

00:28:55,630 --> 00:29:03,040
code and then here's after right before

00:28:59,620 --> 00:29:05,890
after all we have to do is create a

00:29:03,040 --> 00:29:07,240
global lock of our own right nothing to

00:29:05,890 --> 00:29:11,470
do with the global interpreter lock and

00:29:07,240 --> 00:29:14,140
then before we increment n acquire it

00:29:11,470 --> 00:29:17,640
and after we're done we release it and

00:29:14,140 --> 00:29:28,420
if we run this a couple of times

00:29:17,640 --> 00:29:30,040
tada it's a thousand every time so it's

00:29:28,420 --> 00:29:33,850
smooth sailing from this point forward

00:29:30,040 --> 00:29:36,429
and we can finally talk about what you

00:29:33,850 --> 00:29:42,660
really came here for which is how to

00:29:36,429 --> 00:29:47,590
make code go fast there's two kinds of

00:29:42,660 --> 00:29:49,540
jobs that benefit from from multitasking

00:29:47,590 --> 00:29:56,020
and they're called concurrency and

00:29:49,540 --> 00:29:57,760
parallelism now I want us all to admit

00:29:56,020 --> 00:30:00,280
something to each other this is you know

00:29:57,760 --> 00:30:04,720
small group of friends concurrency and

00:30:00,280 --> 00:30:06,630
parallelism are the same word if you

00:30:04,720 --> 00:30:09,010
look it up in an English dictionary

00:30:06,630 --> 00:30:12,580
they're going to have the same

00:30:09,010 --> 00:30:15,600
definition but among computer scientists

00:30:12,580 --> 00:30:19,600
we make this very sharp distinction that

00:30:15,600 --> 00:30:22,059
concurrency is when a job finishes

00:30:19,600 --> 00:30:25,890
faster by waiting for multiple i/o

00:30:22,059 --> 00:30:28,540
operations at the same time and

00:30:25,890 --> 00:30:31,690
parallelism is when a job finishes

00:30:28,540 --> 00:30:34,660
faster when multiple threads do things

00:30:31,690 --> 00:30:37,720
at the same time people often use sort

00:30:34,660 --> 00:30:40,210
of a cooking analogy for this that if I

00:30:37,720 --> 00:30:42,370
put potatoes in the microwave and while

00:30:40,210 --> 00:30:43,149
they're cooking I also start some water

00:30:42,370 --> 00:30:44,830
on the stove

00:30:43,149 --> 00:30:47,499
I'm waiting for multiple things at the

00:30:44,830 --> 00:30:49,479
same time that's concurrency if I'm

00:30:47,499 --> 00:30:51,359
doing multiple things at the same time

00:30:49,479 --> 00:30:53,859
like whisking eggs with one hand while

00:30:51,359 --> 00:30:55,029
flipping pancakes with the other which I

00:30:53,859 --> 00:30:56,649
think probably only Adrienne could

00:30:55,029 --> 00:31:00,580
actually do

00:30:56,649 --> 00:31:04,269
that's parallelism and Python threads

00:31:00,580 --> 00:31:09,219
can't do that so we're going to finish

00:31:04,269 --> 00:31:10,899
with two code examples one of them is

00:31:09,219 --> 00:31:13,929
going to show how to use threads to make

00:31:10,899 --> 00:31:15,249
a concurrent task go faster and then the

00:31:13,929 --> 00:31:17,409
other one is going to show you how you

00:31:15,249 --> 00:31:20,200
can accomplish parallelism despite the

00:31:17,409 --> 00:31:24,969
guilt so we'll do the concurrency one

00:31:20,200 --> 00:31:28,119
first now a really kind of classic

00:31:24,969 --> 00:31:30,279
application of concurrency is when you

00:31:28,119 --> 00:31:32,349
want to fetch a whole bunch of URLs at

00:31:30,279 --> 00:31:34,839
the same time but you don't actually do

00:31:32,349 --> 00:31:36,609
anything with the results so almost all

00:31:34,839 --> 00:31:39,039
of your programs time is spent waiting

00:31:36,609 --> 00:31:42,249
for i/o and that's something that

00:31:39,039 --> 00:31:48,460
threads are really good at so let's say

00:31:42,249 --> 00:31:52,509
that I wanted to download the websites

00:31:48,460 --> 00:31:56,169
of all of the great sponsors who made

00:31:52,509 --> 00:32:00,609
PyCon possible like continuum is

00:31:56,169 --> 00:32:03,490
everybody from continuum here no well

00:32:00,609 --> 00:32:09,090
great guys

00:32:03,490 --> 00:32:13,630
at other talks maybe they're idealists

00:32:09,090 --> 00:32:16,510
so that's over a hundred URLs here and I

00:32:13,630 --> 00:32:20,230
want to download them all as fast as I

00:32:16,510 --> 00:32:22,750
can so I've written a worker function

00:32:20,230 --> 00:32:24,940
here that's just going to keep trying to

00:32:22,750 --> 00:32:26,860
pop a URL off of the list

00:32:24,940 --> 00:32:28,210
and then fetch it with requests and then

00:32:26,860 --> 00:32:30,760
it's just it's not going to do anything

00:32:28,210 --> 00:32:35,320
with it at all it'll just print that

00:32:30,760 --> 00:32:37,900
it's downloaded it will write down the

00:32:35,320 --> 00:32:40,950
start time let's start with ten threads

00:32:37,900 --> 00:32:43,330
let's see how well that performs and

00:32:40,950 --> 00:32:45,580
once they've all finished will print out

00:32:43,330 --> 00:32:51,970
how long that took so let's let's see

00:32:45,580 --> 00:32:54,010
how this goes this is 101 URLs and the

00:32:51,970 --> 00:32:57,940
good news is that the the conference

00:32:54,010 --> 00:33:03,940
website is working at all but the bad

00:32:57,940 --> 00:33:06,130
news is that that I'm bored okay so that

00:33:03,940 --> 00:33:08,400
took 16 and a quarter seconds and the

00:33:06,130 --> 00:33:11,020
question is can we make this go faster

00:33:08,400 --> 00:33:12,910
despite the global interpreter lock by

00:33:11,020 --> 00:33:15,370
adding more threads so let's just go

00:33:12,910 --> 00:33:17,440
straight for the win let's go to a

00:33:15,370 --> 00:33:19,410
hundred thread so we are practically

00:33:17,440 --> 00:33:22,270
downloading all of them simultaneously

00:33:19,410 --> 00:33:25,570
let's see how that performs so 16 and a

00:33:22,270 --> 00:33:30,790
quarter seconds before that looks better

00:33:25,570 --> 00:33:34,570
ooh and we got down to something like an

00:33:30,790 --> 00:33:36,730
eighth of the run time by multiplying

00:33:34,570 --> 00:33:38,590
the number of threads by ten so it's not

00:33:36,730 --> 00:33:42,010
perfect scaling but it's it's really

00:33:38,590 --> 00:33:43,990
darn good and this is the kind of thing

00:33:42,010 --> 00:33:47,170
that you need to keep in mind that if

00:33:43,990 --> 00:33:51,400
your problem is concurrency then a good

00:33:47,170 --> 00:33:53,730
answer in Python is threads but what

00:33:51,400 --> 00:33:56,890
about the other one what about

00:33:53,730 --> 00:34:01,270
parallelism what if you actually need to

00:33:56,890 --> 00:34:04,440
do multiple things at the same time for

00:34:01,270 --> 00:34:08,350
that we're going to need processes a

00:34:04,440 --> 00:34:10,990
process so a thread is a independent

00:34:08,350 --> 00:34:13,330
sort of sequence of instructions

00:34:10,990 --> 00:34:15,950
executed within one process so threads

00:34:13,330 --> 00:34:18,169
share memory it means that they can

00:34:15,950 --> 00:34:21,049
share information by like updating

00:34:18,169 --> 00:34:23,139
global variables and so on processes on

00:34:21,049 --> 00:34:26,629
the other hand are completely distinct

00:34:23,139 --> 00:34:28,579
they do not share any memory at all and

00:34:26,629 --> 00:34:31,069
this means that multiple Python

00:34:28,579 --> 00:34:32,599
processes have independent global

00:34:31,069 --> 00:34:35,690
interpreter lock and they can actually

00:34:32,599 --> 00:34:38,450
run simultaneously on a multi-core

00:34:35,690 --> 00:34:40,369
laptop like this one you can run a dozen

00:34:38,450 --> 00:34:43,760
of them and take advantage of the

00:34:40,369 --> 00:34:46,129
multiple cores but since they don't

00:34:43,760 --> 00:34:48,619
share anything at all communicating

00:34:46,129 --> 00:34:52,909
among processes is much more complex

00:34:48,619 --> 00:34:54,950
than among threads so that's the final

00:34:52,909 --> 00:34:57,020
code example we're going to see is how

00:34:54,950 --> 00:34:58,730
do we fork off a bunch of child

00:34:57,020 --> 00:35:06,319
processes and then use things called

00:34:58,730 --> 00:35:12,230
pipes to communicate among them all

00:35:06,319 --> 00:35:16,160
right so the task that I've set up here

00:35:12,230 --> 00:35:18,710
is sort of deliberately dumb I want to

00:35:16,160 --> 00:35:20,900
take 10 million numbers and sum them and

00:35:18,710 --> 00:35:24,200
for simplicity all of the numbers are

00:35:20,900 --> 00:35:25,819
going to be 1 so the sum obviously ought

00:35:24,200 --> 00:35:29,210
to be 10 billion and we're going to see

00:35:25,819 --> 00:35:30,980
if we can speed up this by by doing it

00:35:29,210 --> 00:35:32,720
on more processes at the same time so

00:35:30,980 --> 00:35:38,059
let's just begin by saying that we're

00:35:32,720 --> 00:35:40,190
only going to use one child now we'll

00:35:38,059 --> 00:35:42,200
write down the start time and now we're

00:35:40,190 --> 00:35:45,020
going to start chunking this list of ten

00:35:42,200 --> 00:35:47,089
million numbers into a chunk per child

00:35:45,020 --> 00:35:52,220
so at first we're only going to have one

00:35:47,089 --> 00:35:55,309
child so let's create the chunk it's a

00:35:52,220 --> 00:36:00,609
list of ones that's ten million elements

00:35:55,309 --> 00:36:03,619
long and now we need to prepare to

00:36:00,609 --> 00:36:05,990
communicate with a child and this is

00:36:03,619 --> 00:36:08,150
much more complex than with threads we

00:36:05,990 --> 00:36:11,660
need to create a thing called a pipe and

00:36:08,150 --> 00:36:13,730
when we call pipe we get two ends of the

00:36:11,660 --> 00:36:17,750
pipe or read and and a right to end

00:36:13,730 --> 00:36:20,770
these are two file descriptors and then

00:36:17,750 --> 00:36:24,829
we call fork there's probably the most

00:36:20,770 --> 00:36:27,290
mind-blowing of all functions because it

00:36:24,829 --> 00:36:29,600
clones the current process and then it

00:36:27,290 --> 00:36:34,340
returns in both the parent

00:36:29,600 --> 00:36:36,830
and the child simultaneously it's kind

00:36:34,340 --> 00:36:39,230
of like if you went to sleep knowing you

00:36:36,830 --> 00:36:41,150
were going to be cloned in your sleep

00:36:39,230 --> 00:36:44,260
and then you wake up in your bedroom and

00:36:41,150 --> 00:36:44,260
you don't know if you're the original

00:36:45,610 --> 00:36:53,420
everything looks the same the only way

00:36:51,380 --> 00:36:55,670
for this process to know whether it's

00:36:53,420 --> 00:37:01,100
the original where the child is the

00:36:55,670 --> 00:37:02,690
return value of fork so if fork returns

00:37:01,100 --> 00:37:06,320
of the parent then the parent gets the

00:37:02,690 --> 00:37:08,210
child's process ID and so it knows it's

00:37:06,320 --> 00:37:10,550
the original and all it needs to do is

00:37:08,210 --> 00:37:13,190
store away the read end of the pipe that

00:37:10,550 --> 00:37:15,890
it made it's going to receive a sub

00:37:13,190 --> 00:37:19,790
total from the child once the child's

00:37:15,890 --> 00:37:22,520
done and then the parent just keeps

00:37:19,790 --> 00:37:27,470
looping forking off children one per

00:37:22,520 --> 00:37:29,570
chunk until it's done now the child on

00:37:27,470 --> 00:37:32,810
the other hand it knows it's the child

00:37:29,570 --> 00:37:35,990
because fork in the child returns zero

00:37:32,810 --> 00:37:40,640
and so the child's job is going to be to

00:37:35,990 --> 00:37:42,710
sum up its chunk of numbers so it does

00:37:40,640 --> 00:37:46,100
that here sort of intentionally stupidly

00:37:42,710 --> 00:37:48,410
and then it's going to print that

00:37:46,100 --> 00:37:51,460
subtotal and then it needs to write the

00:37:48,410 --> 00:37:56,420
subtotal to the parent so it does that

00:37:51,460 --> 00:37:57,980
by you can only write bytes to pipes so

00:37:56,420 --> 00:38:01,490
you can't just send the number there you

00:37:57,980 --> 00:38:03,470
need to string a Phi it encode it as

00:38:01,490 --> 00:38:06,730
bytes and then write it to the pipe and

00:38:03,470 --> 00:38:10,370
then the child's life is over into Texas

00:38:06,730 --> 00:38:12,010
the parent meanwhile it gets down here

00:38:10,370 --> 00:38:16,040
after it started all of the child

00:38:12,010 --> 00:38:18,440
processes and so its job is to read

00:38:16,040 --> 00:38:22,460
those numbers off the read ends of the

00:38:18,440 --> 00:38:26,180
pipes so it does the reverse it needs to

00:38:22,460 --> 00:38:29,000
decode the bytes and turn them back into

00:38:26,180 --> 00:38:32,240
integers and then sum them up to a grand

00:38:29,000 --> 00:38:36,110
total finally it prints out the grand

00:38:32,240 --> 00:38:39,980
total and how long it took so with just

00:38:36,110 --> 00:38:42,640
one a child process let's see how long

00:38:39,980 --> 00:38:42,640
this one takes

00:38:42,809 --> 00:38:48,579
all right computers are fast these days

00:38:45,609 --> 00:38:53,289
I can sum 10,000,000 ones in 1.2 seconds

00:38:48,579 --> 00:38:57,519
and now what about parallelism what if

00:38:53,289 --> 00:39:04,559
we go to 10 children instead we were 1.2

00:38:57,519 --> 00:39:06,819
seconds before and now 0.4 seconds so

00:39:04,559 --> 00:39:09,759
multiplying the number of processes by

00:39:06,819 --> 00:39:13,420
10 let us finish in what is that about

00:39:09,759 --> 00:39:16,839
three times as fast each of the children

00:39:13,420 --> 00:39:18,549
summed up its chunk more or less in

00:39:16,839 --> 00:39:21,160
parallel with all the other ones because

00:39:18,549 --> 00:39:23,979
it has an independent global lock and

00:39:21,160 --> 00:39:29,289
then the parent could wait at the end

00:39:23,979 --> 00:39:32,009
and sum them all up and that's it you've

00:39:29,289 --> 00:39:32,009
got to the gill

00:39:38,610 --> 00:39:44,430
the principle that you just learned is

00:39:41,970 --> 00:39:46,770
also short enough probably to write on

00:39:44,430 --> 00:39:48,660
the back of your hand which is that you

00:39:46,770 --> 00:39:52,260
can use threads for concurrency and

00:39:48,660 --> 00:39:53,640
processes for parallelism and so if

00:39:52,260 --> 00:39:55,290
you've got two hands you can learn

00:39:53,640 --> 00:40:00,090
everything you need to know about Python

00:39:55,290 --> 00:40:01,920
multi-threading on one of them you write

00:40:00,090 --> 00:40:04,500
the effect of the Gil on your code one

00:40:01,920 --> 00:40:06,780
thread runs Python well and others sleep

00:40:04,500 --> 00:40:08,520
or wait i/o and then on your other hand

00:40:06,780 --> 00:40:10,110
you can write the new thing you're just

00:40:08,520 --> 00:40:12,930
learned which is that you can make your

00:40:10,110 --> 00:40:14,160
code go faster by using threads for

00:40:12,930 --> 00:40:18,840
concurrency and processes for

00:40:14,160 --> 00:40:21,540
parallelism now if you want to read like

00:40:18,840 --> 00:40:25,860
an article form of this talk you could

00:40:21,540 --> 00:40:27,840
go to bitly slash croc the Gil and that

00:40:25,860 --> 00:40:30,000
will show you all of these code examples

00:40:27,840 --> 00:40:32,610
and lets you go through this at your own

00:40:30,000 --> 00:40:38,580
pace it includes the two principles I

00:40:32,610 --> 00:40:41,940
described beyond uh these two principles

00:40:38,580 --> 00:40:44,670
though here's what I really want you to

00:40:41,940 --> 00:40:46,950
take out of this talk which is that be

00:40:44,670 --> 00:40:50,700
curious if there's something you want to

00:40:46,950 --> 00:40:52,830
know about how Python works you can open

00:40:50,700 --> 00:40:54,870
up the interpreter code read it for

00:40:52,830 --> 00:40:56,790
yourself and sort of understand what

00:40:54,870 --> 00:40:59,340
you're looking at you can find out how

00:40:56,790 --> 00:41:02,430
Python works by reading the C Python

00:40:59,340 --> 00:41:04,680
source code that's what I did and it

00:41:02,430 --> 00:41:06,270
made me a better Python programmer thank

00:41:04,680 --> 00:41:15,230
you very much

00:41:06,270 --> 00:41:15,230
[Applause]

00:41:17,110 --> 00:41:22,060
all right thanks everyone we're breaking

00:41:19,490 --> 00:41:22,060

YouTube URL: https://www.youtube.com/watch?v=7SSYhuk5hmc


