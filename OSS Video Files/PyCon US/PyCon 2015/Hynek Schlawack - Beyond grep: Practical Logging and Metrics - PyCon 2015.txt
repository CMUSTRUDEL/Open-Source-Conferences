Title: Hynek Schlawack - Beyond grep: Practical Logging and Metrics - PyCon 2015
Publication date: 2015-04-12
Playlist: PyCon 2015
Description: 
	"Speaker: Hynek Schlawack

Your Python server applications are running but you’re wondering what they are doing?  Your only clue about their current state is the server load?  Let’s have stroll through the landscape of logging and metrics so you’ll find the perfect fit for your use cases!

Slides can be found at: https://speakerdeck.com/pycon2015 and https://github.com/PyCon/2015-slides"
Captions: 
	00:00:04,670 --> 00:00:10,019
it's great to be back

00:00:06,870 --> 00:00:11,790
so I'm Henoch from the internet I've

00:00:10,019 --> 00:00:14,460
worked for small web hosting company

00:00:11,790 --> 00:00:16,830
called viral media we were big enough to

00:00:14,460 --> 00:00:18,840
need proper metrics and logging but we

00:00:16,830 --> 00:00:21,359
are small enough such that we don't have

00:00:18,840 --> 00:00:23,100
an own dedicated team for it so that's

00:00:21,359 --> 00:00:25,769
why I believe that my experiences are

00:00:23,100 --> 00:00:27,510
relatable to most of you and since I

00:00:25,769 --> 00:00:29,550
have really little time that's all I'm

00:00:27,510 --> 00:00:31,890
gonna tell you about myself and I'm

00:00:29,550 --> 00:00:33,540
gonna start right away so for the same

00:00:31,890 --> 00:00:35,850
reason there will be no questions at the

00:00:33,540 --> 00:00:37,890
end but I'm believe I will be here

00:00:35,850 --> 00:00:40,910
through hope icons so if you have any

00:00:37,890 --> 00:00:44,850
questions just walk up to me and talk

00:00:40,910 --> 00:00:47,940
what I will be talking about is three

00:00:44,850 --> 00:00:51,329
things about errors and how to get

00:00:47,940 --> 00:00:54,149
properly notified about metrics and how

00:00:51,329 --> 00:00:55,829
to know what's going on without SS aging

00:00:54,149 --> 00:00:58,620
in your servers or touch your servers in

00:00:55,829 --> 00:00:59,910
the first place and finally I will be

00:00:58,620 --> 00:01:03,570
talking about logging and how to

00:00:59,910 --> 00:01:07,439
centralize it so let's start with eros

00:01:03,570 --> 00:01:10,710
right away they happen you have to deal

00:01:07,439 --> 00:01:13,080
with them and they're all sort of

00:01:10,710 --> 00:01:14,430
quickest wins here to make so I will

00:01:13,080 --> 00:01:19,439
start with them while you still wide

00:01:14,430 --> 00:01:23,220
awake and I have three requirements when

00:01:19,439 --> 00:01:26,909
it comes to error logging I want fast

00:01:23,220 --> 00:01:28,920
notifies and I want only one modify

00:01:26,909 --> 00:01:32,880
because I don't want this to happen to

00:01:28,920 --> 00:01:35,520
me so hands up who ever had like 500

00:01:32,880 --> 00:01:37,979
unread emails because of some exception

00:01:35,520 --> 00:01:41,850
to log yeah I don't have to finish the

00:01:37,979 --> 00:01:45,509
sentence and I also want to have some

00:01:41,850 --> 00:01:49,110
useful context around with my my errors

00:01:45,509 --> 00:01:51,570
because this is not helpful to find out

00:01:49,110 --> 00:01:52,860
what the hell is going on and it can be

00:01:51,570 --> 00:01:56,310
anything that can be a network problem

00:01:52,860 --> 00:01:58,799
it I want to know only about errors that

00:01:56,310 --> 00:02:00,840
are within my app and obviously this is

00:01:58,799 --> 00:02:04,140
a pretty common problem it people want

00:02:00,840 --> 00:02:05,939
to solve they're also pretty many

00:02:04,140 --> 00:02:09,869
solutions to it but I will talk only

00:02:05,939 --> 00:02:12,180
about one which is century center is

00:02:09,869 --> 00:02:13,590
pretty cool because David crema bought

00:02:12,180 --> 00:02:16,180
me a burrito once

00:02:13,590 --> 00:02:17,920
it was a great burrito in the middle of

00:02:16,180 --> 00:02:21,670
nowhere in Poland and I really

00:02:17,920 --> 00:02:23,980
appreciate that but it's also cool

00:02:21,670 --> 00:02:26,650
because it's a Python application using

00:02:23,980 --> 00:02:29,770
Jenga that means you probably already

00:02:26,650 --> 00:02:31,000
know how to deploy it and if you do not

00:02:29,770 --> 00:02:33,610
want to deploy it

00:02:31,000 --> 00:02:36,550
there are affordable paid options

00:02:33,610 --> 00:02:39,310
directly from the makers of century

00:02:36,550 --> 00:02:42,400
including a free one so you can be up

00:02:39,310 --> 00:02:44,350
and running for free within seconds also

00:02:42,400 --> 00:02:47,950
if you look into your swag bag I've been

00:02:44,350 --> 00:02:50,410
told there's a $100 coupon there for

00:02:47,950 --> 00:02:53,830
their service so there's no excuse to at

00:02:50,410 --> 00:02:57,070
least try it so these people standing

00:02:53,830 --> 00:02:58,930
back there there's a plenty free seat

00:02:57,070 --> 00:03:04,090
over there so you don't really don't

00:02:58,930 --> 00:03:06,280
have to stand just over there so what do

00:03:04,090 --> 00:03:09,130
you get from sentry first of all you get

00:03:06,280 --> 00:03:10,600
useful notifications like email or slack

00:03:09,130 --> 00:03:13,150
or whatever you want because there's a

00:03:10,600 --> 00:03:15,820
whole plugin system that will allow you

00:03:13,150 --> 00:03:17,020
for whatever you want it already

00:03:15,820 --> 00:03:20,709
contains to stacktrace

00:03:17,020 --> 00:03:22,990
plus some useful metadata but

00:03:20,709 --> 00:03:25,600
interesting but of course is the view on

00:03:22,990 --> 00:03:28,840
century which will bring you directly to

00:03:25,600 --> 00:03:32,470
the web view this is just very very much

00:03:28,840 --> 00:03:34,270
cropped excerpt of it and I'd like to

00:03:32,470 --> 00:03:35,860
direct your attention to this little

00:03:34,270 --> 00:03:38,200
button up here this button is saying

00:03:35,860 --> 00:03:41,250
I've saved you 100 emails in your

00:03:38,200 --> 00:03:43,600
mailbox I like that

00:03:41,250 --> 00:03:46,000
once you've fixed your back or your

00:03:43,600 --> 00:03:49,900
thing you fixed it you mark it as

00:03:46,000 --> 00:03:52,150
resolved and if the error happens again

00:03:49,900 --> 00:03:55,150
it will be marked as a regression and

00:03:52,150 --> 00:03:56,620
you get your notification again so it's

00:03:55,150 --> 00:03:59,800
exactly what you would expect exactly

00:03:56,620 --> 00:04:02,290
what you want great once more it was a

00:03:59,800 --> 00:04:05,380
small crop you get a lot of info you get

00:04:02,290 --> 00:04:07,840
metadata just think of it as the Django

00:04:05,380 --> 00:04:11,410
stack trace except it's sort of to you

00:04:07,840 --> 00:04:14,500
and not to your customers so how do you

00:04:11,410 --> 00:04:17,770
get data into it the short answer is

00:04:14,500 --> 00:04:19,540
JSON over HTTP which means you can use

00:04:17,770 --> 00:04:21,580
it with any language any framework any

00:04:19,540 --> 00:04:23,800
technology of course there are nicer

00:04:21,580 --> 00:04:26,440
clients for basically every popular

00:04:23,800 --> 00:04:27,080
platform out there the Python one is

00:04:26,440 --> 00:04:30,919
called

00:04:27,080 --> 00:04:33,289
- and it supported both multiple

00:04:30,919 --> 00:04:36,379
transports which is how the data is

00:04:33,289 --> 00:04:38,710
getting into century so G event twisted

00:04:36,379 --> 00:04:42,139
request and also what's more interesting

00:04:38,710 --> 00:04:44,689
integrations now integrations is how all

00:04:42,139 --> 00:04:45,770
the data is gathered for example there's

00:04:44,689 --> 00:04:49,159
the logging integration which is a

00:04:45,770 --> 00:04:51,530
logging Handler and whenever exception

00:04:49,159 --> 00:04:54,139
lands at this handler it will be

00:04:51,530 --> 00:04:57,979
forwarded to century simple Django as

00:04:54,139 --> 00:04:59,449
site center itself is a Django app so

00:04:57,979 --> 00:05:01,580
the authors know a thing or two about

00:04:59,449 --> 00:05:04,879
Django so the integration is pretty

00:05:01,580 --> 00:05:09,110
great there's direct support for generic

00:05:04,879 --> 00:05:12,110
whiskey and nine other thing nine other

00:05:09,110 --> 00:05:14,539
ways that document how to integrate it

00:05:12,110 --> 00:05:16,879
so if you do not want to use

00:05:14,539 --> 00:05:19,099
integrations it's still very easy you

00:05:16,879 --> 00:05:23,569
import a client you instantiate it with

00:05:19,099 --> 00:05:25,669
the URL of your of your century and API

00:05:23,569 --> 00:05:27,259
token then you just capture exception

00:05:25,669 --> 00:05:29,120
there's nothing more to it with

00:05:27,259 --> 00:05:32,270
integrations of course it's even easier

00:05:29,120 --> 00:05:34,419
you just add one line now this one line

00:05:32,270 --> 00:05:37,430
will give you reports on uncalled errors

00:05:34,419 --> 00:05:39,490
you can import the client which is then

00:05:37,430 --> 00:05:42,500
already configured for you from anywhere

00:05:39,490 --> 00:05:44,210
this is really great and which also

00:05:42,500 --> 00:05:46,669
means that we've solved our first

00:05:44,210 --> 00:05:48,770
problem deploy sentry or give David a

00:05:46,669 --> 00:05:50,479
few bucks in store even add a few lines

00:05:48,770 --> 00:05:52,550
to your project and you have error

00:05:50,479 --> 00:05:54,680
reporting and I would like to reinforce

00:05:52,550 --> 00:05:56,839
this if you do not have error reporting

00:05:54,680 --> 00:05:58,849
today you are definitely missing errors

00:05:56,839 --> 00:06:01,039
and your customers are not missing they

00:05:58,849 --> 00:06:04,009
are seeing them so don't be embarrassing

00:06:01,039 --> 00:06:06,080
get error reporting there are still a

00:06:04,009 --> 00:06:11,300
lot of free spaces over there you really

00:06:06,080 --> 00:06:14,659
don't have to stand next up metrics or

00:06:11,300 --> 00:06:17,000
our metrics metrics are just numbers you

00:06:14,659 --> 00:06:19,900
save in a database it's numbers over

00:06:17,000 --> 00:06:22,039
time that makes it time series data and

00:06:19,900 --> 00:06:25,580
they basically make the difference

00:06:22,039 --> 00:06:27,319
between guessing and knowing because if

00:06:25,580 --> 00:06:29,900
you want to make decisions about the

00:06:27,319 --> 00:06:32,930
direction of your development you need

00:06:29,900 --> 00:06:35,389
to have facts and metrics are those

00:06:32,930 --> 00:06:37,339
facts otherwise you might just spend

00:06:35,389 --> 00:06:38,990
multiple weeks a month working on

00:06:37,339 --> 00:06:40,150
something that doesn't solve a problem

00:06:38,990 --> 00:06:44,199
you actually have

00:06:40,150 --> 00:06:47,710
so let's give them a quick roll I would

00:06:44,199 --> 00:06:49,840
um I would distinguish between two types

00:06:47,710 --> 00:06:51,760
of metric on system metrics which is

00:06:49,840 --> 00:06:54,460
something you observed on a server like

00:06:51,760 --> 00:06:56,710
the load Network throughput stuff like

00:06:54,460 --> 00:06:59,889
that what I'm concentrating in this talk

00:06:56,710 --> 00:07:02,169
on our ad metrics which are things you a

00:06:59,889 --> 00:07:03,910
measure within your own app so for

00:07:02,169 --> 00:07:06,070
example counters whenever something

00:07:03,910 --> 00:07:08,560
happens no matter what you you increase

00:07:06,070 --> 00:07:13,330
a number that's pretty fast even in

00:07:08,560 --> 00:07:15,639
Python or timers you want to know how

00:07:13,330 --> 00:07:16,210
long your database queries take well now

00:07:15,639 --> 00:07:19,720
you know

00:07:16,210 --> 00:07:21,910
and finally gauges which I find are a

00:07:19,720 --> 00:07:24,160
bit underappreciated because there are

00:07:21,910 --> 00:07:26,139
numbers you want to keep track of so it

00:07:24,160 --> 00:07:27,430
can be a number of active clients or a

00:07:26,139 --> 00:07:29,169
number of active connections in a

00:07:27,430 --> 00:07:30,850
connection pool and if you have them you

00:07:29,169 --> 00:07:33,370
have a great insight into your app

00:07:30,850 --> 00:07:36,520
without touching it it's a

00:07:33,370 --> 00:07:38,650
representation of your state so there

00:07:36,520 --> 00:07:42,880
are a lot more I usually use just the

00:07:38,650 --> 00:07:44,710
three so concentrate on them so we've

00:07:42,880 --> 00:07:47,080
said metrics our time series of data so

00:07:44,710 --> 00:07:50,410
you can plot them and that gives you a

00:07:47,080 --> 00:07:53,229
view on the development over time so for

00:07:50,410 --> 00:07:57,460
example you see whether you are at 99%

00:07:53,229 --> 00:08:01,240
capacity at 12:00 p.m. and also you see

00:07:57,460 --> 00:08:03,039
trends so you can you can you can make

00:08:01,240 --> 00:08:04,810
educated guesses about when you will

00:08:03,039 --> 00:08:07,030
probably need to scale out your servers

00:08:04,810 --> 00:08:09,250
and now that you have plotted your

00:08:07,030 --> 00:08:12,849
values you can of course correlate them

00:08:09,250 --> 00:08:15,460
and so one really popular and useful

00:08:12,849 --> 00:08:18,460
metric is to correlate a graph of

00:08:15,460 --> 00:08:20,289
requests per second versus latencies so

00:08:18,460 --> 00:08:21,970
you get an idea again when do you have

00:08:20,289 --> 00:08:24,729
to scale out because the latency becomes

00:08:21,970 --> 00:08:29,229
unbearable and since they are just

00:08:24,729 --> 00:08:30,550
numbers you can do math on them so so

00:08:29,229 --> 00:08:32,229
for example if you have a graph of a

00:08:30,550 --> 00:08:34,659
counter it's not very useful because

00:08:32,229 --> 00:08:36,459
it's just rising what what can you do

00:08:34,659 --> 00:08:41,529
you can do a derivation and then you

00:08:36,459 --> 00:08:44,130
have to the rate or how about what is

00:08:41,529 --> 00:08:48,820
the average request time for slowest

00:08:44,130 --> 00:08:51,900
0.01 point per sentence because what if

00:08:48,820 --> 00:08:54,130
every 1000th request takes one minute

00:08:51,900 --> 00:08:59,050
you will not know because it's

00:08:54,130 --> 00:09:00,790
out by the other 999 values but your

00:08:59,050 --> 00:09:02,010
clients will probably not be very happy

00:09:00,790 --> 00:09:08,860
about that

00:09:02,010 --> 00:09:11,020
so finally math is hard the average

00:09:08,860 --> 00:09:15,070
human has one ovary and one testicle

00:09:11,020 --> 00:09:19,690
this is a true fact but it's not a very

00:09:15,070 --> 00:09:21,790
useful information to have and so be

00:09:19,690 --> 00:09:25,360
careful that you do not some math and

00:09:21,790 --> 00:09:28,050
get a similarly useful information about

00:09:25,360 --> 00:09:30,400
your systems so unless you know what

00:09:28,050 --> 00:09:33,540
exponentially decaying reservoirs are

00:09:30,400 --> 00:09:37,510
use tools by those who know what it is

00:09:33,540 --> 00:09:40,390
so what you can also do is apply

00:09:37,510 --> 00:09:42,250
monitoring to your metrics for example

00:09:40,390 --> 00:09:45,100
you can set a hard limit on your

00:09:42,250 --> 00:09:47,740
acceptable agency and notify yourself if

00:09:45,100 --> 00:09:51,040
you just exceeded you can monitor your

00:09:47,740 --> 00:09:54,730
error rate because even if benign errors

00:09:51,040 --> 00:09:56,230
like 401 or for 404 s-- are getting out

00:09:54,730 --> 00:09:59,080
of whack there's probably something

00:09:56,230 --> 00:10:01,540
going on you want to look into all just

00:09:59,080 --> 00:10:03,400
anomalies in general if some value

00:10:01,540 --> 00:10:05,320
starts behaving very differently

00:10:03,400 --> 00:10:06,490
suddenly there's probably again

00:10:05,320 --> 00:10:08,620
something you want to have a look into

00:10:06,490 --> 00:10:10,660
them there's a whole stack called kale

00:10:08,620 --> 00:10:13,180
which will help you with that

00:10:10,660 --> 00:10:17,020
so the question now is where do those

00:10:13,180 --> 00:10:20,050
metrics live I say database but I

00:10:17,020 --> 00:10:21,850
probably didn't mean a sequel I'd what

00:10:20,050 --> 00:10:24,490
you are looking for is a so called time

00:10:21,850 --> 00:10:26,950
series database and they have various

00:10:24,490 --> 00:10:28,810
features specific to the problem domain

00:10:26,950 --> 00:10:30,310
one of the most important one is

00:10:28,810 --> 00:10:33,850
probably the roll-up where you get a

00:10:30,310 --> 00:10:35,890
various resolution depending on how old

00:10:33,850 --> 00:10:37,740
your data is because in a current hour

00:10:35,890 --> 00:10:40,930
you maybe want a one-second resolution

00:10:37,740 --> 00:10:44,470
but the values from a month ago maybe

00:10:40,930 --> 00:10:46,360
our average is enough because if you

00:10:44,470 --> 00:10:49,330
collect a lot of metrics which you

00:10:46,360 --> 00:10:51,940
should the data can really pile up

00:10:49,330 --> 00:10:55,060
quickly so I'm gonna introduce you to

00:10:51,940 --> 00:10:57,790
three ones and we will start with

00:10:55,060 --> 00:10:59,500
libretto metrics it's a paid one it's a

00:10:57,790 --> 00:11:01,240
hosted one and you can get started

00:10:59,500 --> 00:11:04,480
super fast you can just curve a use

00:11:01,240 --> 00:11:06,580
against it so you can build a graph of

00:11:04,480 --> 00:11:07,440
your server load using curl that's

00:11:06,580 --> 00:11:10,980
really

00:11:07,440 --> 00:11:13,620
cool if you don't want to do that

00:11:10,980 --> 00:11:15,870
the current still standard is graphite

00:11:13,620 --> 00:11:18,720
which is has been popularized by Etsy

00:11:15,870 --> 00:11:22,170
and is actually a Python application the

00:11:18,720 --> 00:11:23,940
front-end is a jungle app and the

00:11:22,170 --> 00:11:27,360
networking back-end that takes the data

00:11:23,940 --> 00:11:31,590
is a twisted app called carbon which is

00:11:27,360 --> 00:11:34,380
also that the stand then the protocol

00:11:31,590 --> 00:11:36,330
name that is used the good news is it's

00:11:34,380 --> 00:11:37,920
finally part of Trustee so you can just

00:11:36,330 --> 00:11:41,370
install it using aptitude which was not

00:11:37,920 --> 00:11:43,790
possible before and it's basically a de

00:11:41,370 --> 00:11:47,550
facto standard for saving metrics data

00:11:43,790 --> 00:11:54,420
so other competing products support it

00:11:47,550 --> 00:11:57,840
too on the bad side the storage

00:11:54,420 --> 00:12:00,420
configuration is a bit finicky and it's

00:11:57,840 --> 00:12:02,520
not really pretty it's XJS that's what

00:12:00,420 --> 00:12:06,960
happens when programmers build

00:12:02,520 --> 00:12:11,370
interfaces but that's a solvable problem

00:12:06,960 --> 00:12:14,700
using Rivanna which was only purpose is

00:12:11,370 --> 00:12:17,580
to give you pretty dashboards from data

00:12:14,700 --> 00:12:19,620
it fetches itself from graphite and the

00:12:17,580 --> 00:12:22,080
netting is also supports the new kid on

00:12:19,620 --> 00:12:23,670
the block which is in flux DB it's

00:12:22,080 --> 00:12:25,440
basically the next generation x years

00:12:23,670 --> 00:12:28,710
database written in go because it is

00:12:25,440 --> 00:12:30,690
apparently what you do nowadays there's

00:12:28,710 --> 00:12:32,760
a company behind its selling hosting so

00:12:30,690 --> 00:12:36,600
let's hope they do not pull a foundation

00:12:32,760 --> 00:12:38,610
DB and it's used by Heroku so it's not

00:12:36,600 --> 00:12:41,550
some obscure nerd toy

00:12:38,610 --> 00:12:44,400
this is production-ready it has easier

00:12:41,550 --> 00:12:46,470
to manageable storage you can tag values

00:12:44,400 --> 00:12:48,330
which anyone was ever put server names

00:12:46,470 --> 00:12:50,970
into their metrics will appreciate and

00:12:48,330 --> 00:12:55,380
it offers a sicko like query language

00:12:50,970 --> 00:12:57,330
and it offers a graphite front-end so in

00:12:55,380 --> 00:12:59,610
theory you can just point all your old

00:12:57,330 --> 00:13:01,950
tools you've been pointing to graphite

00:12:59,610 --> 00:13:03,839
to in Flex DB and it should keep working

00:13:01,950 --> 00:13:08,280
that's it I say should because it's

00:13:03,839 --> 00:13:10,350
software so so if you're setting up a

00:13:08,280 --> 00:13:12,210
metric system today I would recommend to

00:13:10,350 --> 00:13:15,150
look at in Flex DB first but there's no

00:13:12,210 --> 00:13:17,790
real reason to jump ship and abandon

00:13:15,150 --> 00:13:20,070
graphite if you're happy with it so we

00:13:17,790 --> 00:13:20,620
have a database how do we get data into

00:13:20,070 --> 00:13:24,220
it

00:13:20,620 --> 00:13:26,560
there are basically two approaches that

00:13:24,220 --> 00:13:28,330
are common one is that you do external

00:13:26,560 --> 00:13:29,860
aggregation that means whenever

00:13:28,330 --> 00:13:31,410
something happens or you measure

00:13:29,860 --> 00:13:33,670
something you just send it to an

00:13:31,410 --> 00:13:36,130
third-party server and it survived it

00:13:33,670 --> 00:13:36,610
will do the math and make sure that it's

00:13:36,130 --> 00:13:39,700
safe

00:13:36,610 --> 00:13:42,760
you do not care at all the most famous

00:13:39,700 --> 00:13:44,680
one is stats D from Etsy slightly less

00:13:42,760 --> 00:13:46,870
popular one is Riemann which is pretty

00:13:44,680 --> 00:13:51,340
complex to set up the configuration is

00:13:46,870 --> 00:13:53,650
using closure so it depends on how much

00:13:51,340 --> 00:13:55,750
you like parents whether you will like

00:13:53,650 --> 00:13:56,950
it or not the nice thing about riemann

00:13:55,750 --> 00:14:00,750
is it will give you a real-time

00:13:56,950 --> 00:14:00,750
dashboard which states you will not

00:14:00,870 --> 00:14:06,400
upside is there's no state in your app

00:14:04,060 --> 00:14:07,800
you just send out values and don't care

00:14:06,400 --> 00:14:10,120
it's super simple

00:14:07,800 --> 00:14:13,140
the downside is you have no direct

00:14:10,120 --> 00:14:16,630
introspection about your metrics without

00:14:13,140 --> 00:14:19,420
another server or two in a case of stats

00:14:16,630 --> 00:14:22,300
D which it's kind of not so nice

00:14:19,420 --> 00:14:23,800
the second approach of that and it is

00:14:22,300 --> 00:14:26,530
there is you aggregate your metrics

00:14:23,800 --> 00:14:28,270
within your own app and then push it to

00:14:26,530 --> 00:14:30,850
a database this approach has been

00:14:28,270 --> 00:14:32,470
popularized by CUDA Hale and his talk

00:14:30,850 --> 00:14:34,240
metrics metrics everywhere which you

00:14:32,470 --> 00:14:36,180
should totally watch because it explains

00:14:34,240 --> 00:14:39,070
everything I had absolutely no time here

00:14:36,180 --> 00:14:40,900
and this approach gives you immediate

00:14:39,070 --> 00:14:45,130
insight into your application which is

00:14:40,900 --> 00:14:47,820
especially useful with weather with

00:14:45,130 --> 00:14:52,480
gauges because you get a real-time

00:14:47,820 --> 00:14:54,100
introspection feature the downside is

00:14:52,480 --> 00:14:57,580
that you have stayed within your app and

00:14:54,100 --> 00:15:01,360
state is bad and it's also global state

00:14:57,580 --> 00:15:03,100
because it's a quite right I personally

00:15:01,360 --> 00:15:04,690
prefer a second approach for what it's

00:15:03,100 --> 00:15:09,430
worth so how do you do this in Python

00:15:04,690 --> 00:15:12,910
for stats D there's a dozen of clients

00:15:09,430 --> 00:15:14,860
on pi PI they seem to work all fine pick

00:15:12,910 --> 00:15:16,390
your poison yourself the usage is always

00:15:14,860 --> 00:15:18,520
the same you just instantiate some

00:15:16,390 --> 00:15:21,310
client with a host name and then you

00:15:18,520 --> 00:15:24,490
start incrementing numbers or sending

00:15:21,310 --> 00:15:25,750
timing data and you don't care about the

00:15:24,490 --> 00:15:29,560
return values you don't care about

00:15:25,750 --> 00:15:30,660
anything it's UDP anyway so it's gonna

00:15:29,560 --> 00:15:32,980
be okay

00:15:30,660 --> 00:15:35,470
for the second approach

00:15:32,980 --> 00:15:37,959
as far as I know the only really Riley

00:15:35,470 --> 00:15:41,139
used of standard scales and as you see

00:15:37,959 --> 00:15:44,250
you have more setting up to do and this

00:15:41,139 --> 00:15:47,800
is even not containing the configuration

00:15:44,250 --> 00:15:49,480
I've edited to metrics I use most which

00:15:47,800 --> 00:15:52,990
is a meter stat which is kind of like a

00:15:49,480 --> 00:15:56,769
counter but it contains already features

00:15:52,990 --> 00:15:59,199
to give you metering metering data like

00:15:56,769 --> 00:16:01,750
home how often something happens per

00:15:59,199 --> 00:16:04,769
second the second one is a simple timer

00:16:01,750 --> 00:16:08,230
how do you use them this is how you

00:16:04,769 --> 00:16:10,899
measure metering and the timer give you

00:16:08,230 --> 00:16:13,089
gives you a context manager and will

00:16:10,899 --> 00:16:14,860
measure at a time that's all the cool

00:16:13,089 --> 00:16:17,380
thing is now you get a bad view of your

00:16:14,860 --> 00:16:20,320
data straight from your app this is from

00:16:17,380 --> 00:16:22,180
a meter and this is from a timer and as

00:16:20,320 --> 00:16:25,750
you see you'll get your percentiles for

00:16:22,180 --> 00:16:28,630
free they are already there and what's

00:16:25,750 --> 00:16:30,970
also cool you get the same data as Jason

00:16:28,630 --> 00:16:33,010
so you can recruit it and you can

00:16:30,970 --> 00:16:36,839
collect it for example collect D or

00:16:33,010 --> 00:16:39,910
something if you do not want to do that

00:16:36,839 --> 00:16:42,399
scales also contains a graphite pusher

00:16:39,910 --> 00:16:47,339
pusher which will push it in a

00:16:42,399 --> 00:16:49,510
configurable intervals to graphite done

00:16:47,339 --> 00:16:51,660
we come to our last topic which is

00:16:49,510 --> 00:16:54,730
logging

00:16:51,660 --> 00:16:56,170
errors we've had metrics but probably

00:16:54,730 --> 00:16:58,930
you still need some kind of bookkeeping

00:16:56,170 --> 00:17:01,300
like when did a user log in when the

00:16:58,930 --> 00:17:02,920
user log out and those information is

00:17:01,300 --> 00:17:05,500
usually interesting not to you but for

00:17:02,920 --> 00:17:08,500
example support staff and you don't

00:17:05,500 --> 00:17:11,620
necessarily want to hand out SSH keys to

00:17:08,500 --> 00:17:13,480
the servers to those people and you also

00:17:11,620 --> 00:17:15,730
don't want them to search on multiple

00:17:13,480 --> 00:17:19,870
servers so you want your logs accessible

00:17:15,730 --> 00:17:21,790
in one place and I can't talk about lock

00:17:19,870 --> 00:17:24,100
management of dimensions blank please

00:17:21,790 --> 00:17:26,620
notice that I added more money bags next

00:17:24,100 --> 00:17:28,660
to the name because this is enterprise

00:17:26,620 --> 00:17:31,530
software it's not just one web interface

00:17:28,660 --> 00:17:34,240
they have literally an app store and

00:17:31,530 --> 00:17:36,190
they work both on-premise and cloud it's

00:17:34,240 --> 00:17:37,720
great when you can afford it but it's

00:17:36,190 --> 00:17:39,730
still enterprise software so the home

00:17:37,720 --> 00:17:41,590
page is full of PDF ID papers case

00:17:39,730 --> 00:17:44,909
studies and it will be very happy to

00:17:41,590 --> 00:17:44,909
invite you to our next webinar

00:17:45,940 --> 00:17:51,399
a more down-to-earth alternatives

00:17:48,279 --> 00:17:54,279
include paper trail or log li um I've

00:17:51,399 --> 00:17:55,980
heard great stuff about both a effort

00:17:54,279 --> 00:17:58,269
not so great stuff about both I

00:17:55,980 --> 00:18:02,049
personally would not wouldn't use either

00:17:58,269 --> 00:18:03,480
because I don't like sending any kind of

00:18:02,049 --> 00:18:05,799
customer data to a third party

00:18:03,480 --> 00:18:10,090
especially if the third party is on a

00:18:05,799 --> 00:18:11,889
different continent but they take you by

00:18:10,090 --> 00:18:14,830
the hand help you with integrating and

00:18:11,889 --> 00:18:17,169
you get something for your money if you

00:18:14,830 --> 00:18:19,629
do not want that you've probably already

00:18:17,169 --> 00:18:23,409
heard about ELQ which is a stack of

00:18:19,629 --> 00:18:25,690
three pieces of software log stash is a

00:18:23,409 --> 00:18:28,860
parser that will take your log entries

00:18:25,690 --> 00:18:32,049
and give them meaning elasticsearch

00:18:28,860 --> 00:18:34,500
stores this data and allows for searches

00:18:32,049 --> 00:18:37,779
and Cabana final is what you see here

00:18:34,500 --> 00:18:41,500
will allows for search and view the data

00:18:37,779 --> 00:18:43,240
a symbol product is gray log it has

00:18:41,500 --> 00:18:46,840
similar architecture particularly it

00:18:43,240 --> 00:18:49,710
also uses elastic search and while Alex

00:18:46,840 --> 00:18:52,120
Cabana is just a view on elastic search

00:18:49,710 --> 00:18:53,860
Greylock server does a lot more big

00:18:52,120 --> 00:18:55,529
house and I'm quoting here elastic

00:18:53,860 --> 00:18:57,580
search is not a lock management system

00:18:55,529 --> 00:19:01,240
so they try to be overall more

00:18:57,580 --> 00:19:03,909
integrated I'm personally not fond of

00:19:01,240 --> 00:19:07,120
the fact that I'd have to include a Mac

00:19:03,909 --> 00:19:09,549
vendor into my infrastructure but if you

00:19:07,120 --> 00:19:11,080
don't have such problems like I do you

00:19:09,549 --> 00:19:13,690
should maybe you should try it in any

00:19:11,080 --> 00:19:15,549
case it seems to me that ELQ has won and

00:19:13,690 --> 00:19:18,610
I've personally didn't find any striking

00:19:15,549 --> 00:19:22,750
reasons to try to change switch to gray

00:19:18,610 --> 00:19:25,570
lock in any case elastic the company

00:19:22,750 --> 00:19:28,539
behind ELQ was here so I guess there's

00:19:25,570 --> 00:19:32,950
the people are still here Hansa crowd

00:19:28,539 --> 00:19:34,539
the author of the Python library for for

00:19:32,950 --> 00:19:36,580
elastic search is definitely still here

00:19:34,539 --> 00:19:41,350
so if you have any questions or problems

00:19:36,580 --> 00:19:44,409
you should chat them up so Python time

00:19:41,350 --> 00:19:46,870
again how do we produce data properly I

00:19:44,409 --> 00:19:49,179
think this should be the goal a

00:19:46,870 --> 00:19:51,399
timestamp and a machine readable event

00:19:49,179 --> 00:19:52,990
with its context because that makes

00:19:51,399 --> 00:19:55,149
configuration really simple you just

00:19:52,990 --> 00:19:57,159
tell for example elasticsearch that the

00:19:55,149 --> 00:19:58,429
first part it's a timestamp and the rest

00:19:57,159 --> 00:20:01,700
is Jason and it's

00:19:58,429 --> 00:20:03,980
all in practice that's just one line of

00:20:01,700 --> 00:20:07,039
course so how do we get there

00:20:03,980 --> 00:20:09,679
and I'm arguing it's about context and

00:20:07,039 --> 00:20:12,049
format you want to look out everything

00:20:09,679 --> 00:20:14,539
that's important formatted in a

00:20:12,049 --> 00:20:16,399
machine-readable way and this is for

00:20:14,539 --> 00:20:17,950
everyone would try that pretty tedious

00:20:16,399 --> 00:20:21,409
with standard tools

00:20:17,950 --> 00:20:23,960
hence Everett something on my own strut

00:20:21,409 --> 00:20:28,970
lock hands up who has heard of

00:20:23,960 --> 00:20:32,210
star-struck lock okay that's far too few

00:20:28,970 --> 00:20:34,759
hands so let's change that so one

00:20:32,210 --> 00:20:36,409
important note struck lock is not a

00:20:34,759 --> 00:20:39,230
logging system and it's not a

00:20:36,409 --> 00:20:41,480
replacement for log book or standard

00:20:39,230 --> 00:20:44,600
libraries logging instead it gives you a

00:20:41,480 --> 00:20:47,330
bound logger which wraps your original

00:20:44,600 --> 00:20:51,259
logger your original logger still locks

00:20:47,330 --> 00:20:53,690
all the data that's doing the i/o but

00:20:51,259 --> 00:20:56,119
also keeps a context dictionary which

00:20:53,690 --> 00:21:00,730
you can bind key value pairs to it and

00:20:56,119 --> 00:21:03,559
once you decide to lock out data the the

00:21:00,730 --> 00:21:06,499
logging dictionary will be combined with

00:21:03,559 --> 00:21:09,769
the context to one event dictionary and

00:21:06,499 --> 00:21:13,690
it's run through a chain of processors

00:21:09,769 --> 00:21:16,700
and these processors are just callable

00:21:13,690 --> 00:21:19,369
they get the Aventa canary in and return

00:21:16,700 --> 00:21:21,139
a new event dictionary which will be

00:21:19,369 --> 00:21:24,110
passed into the next one and you can do

00:21:21,139 --> 00:21:28,759
anything here so you can you can just

00:21:24,110 --> 00:21:31,700
send errors along with the context to

00:21:28,759 --> 00:21:33,080
century or you can pull out metrics out

00:21:31,700 --> 00:21:37,159
of your entries and send them to

00:21:33,080 --> 00:21:38,899
graphite or whatever and at the very end

00:21:37,159 --> 00:21:40,999
the original logger is called with the

00:21:38,899 --> 00:21:43,429
result of the last processor so it's

00:21:40,999 --> 00:21:47,119
kind of a formatter so the last

00:21:43,429 --> 00:21:50,029
processors should in a usual set ups

00:21:47,119 --> 00:21:52,399
probably return a string like Jason so

00:21:50,029 --> 00:21:56,809
this handles both context and format and

00:21:52,399 --> 00:21:59,389
processors add flexibility so I guess

00:21:56,809 --> 00:22:00,019
some of you expected some login code so

00:21:59,389 --> 00:22:04,220
here it is

00:22:00,019 --> 00:22:07,129
I say ignore most login features lock to

00:22:04,220 --> 00:22:08,809
standard out handle locks outside UNIX

00:22:07,129 --> 00:22:10,249
had over 40 years to develop solid

00:22:08,809 --> 00:22:11,440
logging tools there's no reason

00:22:10,249 --> 00:22:14,470
whatsoever for us

00:22:11,440 --> 00:22:17,409
people patting people to reinvent lock

00:22:14,470 --> 00:22:19,210
rotation or date stamping so especially

00:22:17,409 --> 00:22:21,190
in an age of containers it's super

00:22:19,210 --> 00:22:25,059
annoying when an app insists on writing

00:22:21,190 --> 00:22:26,200
to files to actual files or to even do

00:22:25,059 --> 00:22:28,149
lock rotation on itself

00:22:26,200 --> 00:22:32,679
don't do it also I've heard that logging

00:22:28,149 --> 00:22:36,940
is rather painful to use but maybe

00:22:32,679 --> 00:22:38,950
you're like pain so we have structured

00:22:36,940 --> 00:22:40,750
data on standard out what do we do we

00:22:38,950 --> 00:22:42,940
capture it and we pipe it somewhere for

00:22:40,750 --> 00:22:44,769
example in files you can send it to the

00:22:42,940 --> 00:22:48,000
slot which is a nightstand er a nice

00:22:44,769 --> 00:22:50,769
standard with terrible default settings

00:22:48,000 --> 00:22:53,019
or directly into a queue like calf:cow

00:22:50,769 --> 00:22:55,299
rabbit or we pipe it directly into a

00:22:53,019 --> 00:22:57,909
forwarder that sends it directly to log

00:22:55,299 --> 00:23:00,549
stash and I will and I want to give you

00:22:57,909 --> 00:23:03,220
an example how concretely I do logging

00:23:00,549 --> 00:23:06,929
so maybe you have a starting point so I

00:23:03,220 --> 00:23:11,259
of course you strike look and I log out

00:23:06,929 --> 00:23:13,600
something struck log creates a JSON

00:23:11,259 --> 00:23:15,909
string and passes it on to logging which

00:23:13,600 --> 00:23:18,639
sends to start out on standard out it's

00:23:15,909 --> 00:23:23,730
caught by run it but run it's logging

00:23:18,639 --> 00:23:27,100
demon run it is just just a way to start

00:23:23,730 --> 00:23:28,929
server processes on unix it works just

00:23:27,100 --> 00:23:31,919
as well as supervisor or something like

00:23:28,929 --> 00:23:36,490
that and now it's saved into a file arm

00:23:31,919 --> 00:23:40,629
so I find personally that important

00:23:36,490 --> 00:23:41,980
because I don't want to look to lose log

00:23:40,629 --> 00:23:44,200
entries just because there's a network

00:23:41,980 --> 00:23:46,929
partition and someone also asked me what

00:23:44,200 --> 00:23:50,230
if I want to use grep to that my answer

00:23:46,929 --> 00:23:51,850
is I want to because grep is awesome I

00:23:50,230 --> 00:23:56,289
just don't want it to be my default or

00:23:51,850 --> 00:23:58,480
even only way of acquiring data from a

00:23:56,289 --> 00:24:00,519
log file now this file is watched by

00:23:58,480 --> 00:24:02,379
locks a forwarder Center to log stash

00:24:00,519 --> 00:24:08,830
locks - saves it to elastic search and

00:24:02,379 --> 00:24:15,250
we're done oh we're done early let's get

00:24:08,830 --> 00:24:17,169
some protein there not anyone who ever

00:24:15,250 --> 00:24:20,950
heard me talking they'll know that I'm

00:24:17,169 --> 00:24:23,259
never done early so we have three

00:24:20,950 --> 00:24:24,730
components but how do we put them

00:24:23,259 --> 00:24:27,280
together because this is the

00:24:24,730 --> 00:24:31,020
Matic part actually so do you want to

00:24:27,280 --> 00:24:33,940
your coat look like this because I don't

00:24:31,020 --> 00:24:37,600
it's hard to even find the logic hidden

00:24:33,940 --> 00:24:41,679
under all the login capturing measuring

00:24:37,600 --> 00:24:44,410
and whatnot I want this something

00:24:41,679 --> 00:24:47,230
happens I send it to my logging systems

00:24:44,410 --> 00:24:50,160
and I'm done of course it's not always

00:24:47,230 --> 00:24:54,669
possible but let's try anyway so errors

00:24:50,160 --> 00:24:57,250
use logging integration you I said you

00:24:54,669 --> 00:24:59,470
just sent an exception to your logging

00:24:57,250 --> 00:25:02,410
and the Sentry handler would pick it up

00:24:59,470 --> 00:25:04,690
and send it to sentry or do it like me

00:25:02,410 --> 00:25:07,179
strut log I've wrote a little handler

00:25:04,690 --> 00:25:09,520
that will add the context of the logger

00:25:07,179 --> 00:25:11,799
to the exception and send it to century

00:25:09,520 --> 00:25:16,750
even better or if you're writing that

00:25:11,799 --> 00:25:18,730
apps use error views each that into each

00:25:16,750 --> 00:25:20,950
that framework has some kind of error

00:25:18,730 --> 00:25:22,870
views this isn't permitted example you

00:25:20,950 --> 00:25:25,179
get accept you get requests so you can

00:25:22,870 --> 00:25:26,350
gather some metadata from it and the

00:25:25,179 --> 00:25:29,830
nice thing is that this capture

00:25:26,350 --> 00:25:33,250
exception method will return an error ID

00:25:29,830 --> 00:25:35,290
which you can serve vector to the to

00:25:33,250 --> 00:25:37,840
your client and then when your client is

00:25:35,290 --> 00:25:40,960
yellow yelling at you over telephone I

00:25:37,840 --> 00:25:45,419
can ask them for the ID and look up

00:25:40,960 --> 00:25:48,940
their concrete error which is nice so

00:25:45,419 --> 00:25:50,230
attrex most metrics can be observed from

00:25:48,940 --> 00:25:52,450
the outside and that's what you should

00:25:50,230 --> 00:25:54,730
try to do so outside can mean outside

00:25:52,450 --> 00:25:56,950
your views outside of your app or even

00:25:54,730 --> 00:25:58,799
outside of your server for example

00:25:56,950 --> 00:26:01,330
whiskey servers the two major ones

00:25:58,799 --> 00:26:04,620
support both metrics to a certain degree

00:26:01,330 --> 00:26:08,049
so it unicorn has stats tea built in and

00:26:04,620 --> 00:26:11,650
micro risky as usual goes much farther

00:26:08,049 --> 00:26:13,660
it of course supports stats d2 but it

00:26:11,650 --> 00:26:16,690
also supports writing directly to

00:26:13,660 --> 00:26:20,290
graphite and it has a whole metric

00:26:16,690 --> 00:26:22,950
subsystem and also supports SNMP don't

00:26:20,290 --> 00:26:28,150
look it up if you don't know what it is

00:26:22,950 --> 00:26:30,429
you will sleep better so basically your

00:26:28,150 --> 00:26:32,169
one argument away from getting useful

00:26:30,429 --> 00:26:33,970
metrics about your app without doing

00:26:32,169 --> 00:26:36,070
anything about it it gives you a big

00:26:33,970 --> 00:26:38,850
picture about what's going on so now you

00:26:36,070 --> 00:26:41,040
want to dig in you can use things like

00:26:38,850 --> 00:26:43,490
middle there so for example for pyramid

00:26:41,040 --> 00:26:47,760
here's a queen which is a awkward

00:26:43,490 --> 00:26:49,800
contraction of between and this little

00:26:47,760 --> 00:26:51,000
function is called on each request so

00:26:49,800 --> 00:26:52,890
you have two requests you have all the

00:26:51,000 --> 00:26:56,130
request data you want you can start

00:26:52,890 --> 00:26:57,600
breaking down your timing so and that

00:26:56,130 --> 00:26:59,550
chances you don't even have to do that

00:26:57,600 --> 00:27:01,260
so for example for pyramid there's a

00:26:59,550 --> 00:27:03,770
package called pyramids that's D which

00:27:01,260 --> 00:27:09,240
will do just that

00:27:03,770 --> 00:27:12,480
yeah finally not finally sorry you can

00:27:09,240 --> 00:27:14,070
extract your metrics from log files

00:27:12,480 --> 00:27:17,370
because if you look something out you

00:27:14,070 --> 00:27:20,280
don't have to additionally count it in

00:27:17,370 --> 00:27:22,860
your app so log stash will help you with

00:27:20,280 --> 00:27:26,670
that it supports all kinds of metrics

00:27:22,860 --> 00:27:28,140
back ends the back and the problem is

00:27:26,670 --> 00:27:30,000
that you have to change the

00:27:28,140 --> 00:27:31,770
configuration of log stash which may or

00:27:30,000 --> 00:27:33,450
may not add some friction which you are

00:27:31,770 --> 00:27:35,430
may or may not be comfortable it I

00:27:33,450 --> 00:27:36,840
personally prefer my approach with

00:27:35,430 --> 00:27:38,520
struck luck we have wrote a processor

00:27:36,840 --> 00:27:41,870
that will look at the events that come

00:27:38,520 --> 00:27:46,050
in and generate metrics from that

00:27:41,870 --> 00:27:49,070
finally now it's really finally you

00:27:46,050 --> 00:27:53,370
surely have monitoring in place right

00:27:49,070 --> 00:27:55,920
right you can measure execution time and

00:27:53,370 --> 00:27:58,860
save it modules directly support metrics

00:27:55,920 --> 00:28:00,990
numbers from checkers so this gives you

00:27:58,860 --> 00:28:03,180
an external view which may be a bit

00:28:00,990 --> 00:28:07,440
imprecise but it's still information you

00:28:03,180 --> 00:28:09,000
can use and what's left what do you have

00:28:07,440 --> 00:28:12,210
still to measure yourself and pollute

00:28:09,000 --> 00:28:14,130
your own code with so for one if you

00:28:12,210 --> 00:28:16,530
want to know the timing of certain code

00:28:14,130 --> 00:28:19,580
paths for example database queries or

00:28:16,530 --> 00:28:22,650
major use cases like you have a view

00:28:19,580 --> 00:28:24,960
which sometimes just serves completely

00:28:22,650 --> 00:28:26,700
out of cache and sometimes uses the

00:28:24,960 --> 00:28:30,120
database it does not make a lot of sense

00:28:26,700 --> 00:28:31,440
to average those two values together so

00:28:30,120 --> 00:28:34,200
you may want to split them up

00:28:31,440 --> 00:28:36,390
and of course I've already said I'm a

00:28:34,200 --> 00:28:38,730
fan of gauges you have to do them by

00:28:36,390 --> 00:28:42,330
hand there's no way around that if you

00:28:38,730 --> 00:28:44,790
want to keep keep track of a number but

00:28:42,330 --> 00:28:47,460
I feel it's still much less boilerplate

00:28:44,790 --> 00:28:51,690
then you may an update with few just

00:28:47,460 --> 00:28:55,590
went in go into it and do it naively

00:28:51,690 --> 00:28:58,080
and what did we learn

00:28:55,590 --> 00:28:59,970
we learned that proper error logging is

00:28:58,080 --> 00:29:02,700
important centuries awesome

00:28:59,970 --> 00:29:05,870
you learned metrics are also important

00:29:02,700 --> 00:29:08,039
and in Flex DB is probably the future

00:29:05,870 --> 00:29:10,230
we've learnt of centralized logging

00:29:08,039 --> 00:29:10,889
saves you a lot of pain and it will have

00:29:10,230 --> 00:29:15,299
your back

00:29:10,889 --> 00:29:19,019
so we'll Greylock depends on concrete

00:29:15,299 --> 00:29:20,789
requirements and you know how to use all

00:29:19,019 --> 00:29:23,580
of them without gross code duplication

00:29:20,789 --> 00:29:26,220
in your Python code so I hope there was

00:29:23,580 --> 00:29:28,559
something for everyone and go forth and

00:29:26,220 --> 00:29:31,019
measure study the top page which I've

00:29:28,559 --> 00:29:32,639
again assembled follow me on Twitter and

00:29:31,019 --> 00:29:36,200
tell your german-speaking friends to get

00:29:32,639 --> 00:29:36,200
their domains from vero media thank you

00:29:42,040 --> 00:29:45,460
oh and if you want oh we have time for

00:29:44,920 --> 00:29:50,170
questions

00:29:45,460 --> 00:29:51,370
oh my god that's new okay quick do you

00:29:50,170 --> 00:29:53,260
have any more thoughts on alerting

00:29:51,370 --> 00:29:55,570
coming up alerting

00:29:53,260 --> 00:29:58,060
so you're monitoring all the stuff but

00:29:55,570 --> 00:29:59,650
when something happens that is bad or

00:29:58,060 --> 00:30:01,650
your numbers you know your request times

00:29:59,650 --> 00:30:04,300
too high or whatever how do you

00:30:01,650 --> 00:30:07,030
proactively tell somebody without them

00:30:04,300 --> 00:30:10,930
having to go to Griffin or asking me if

00:30:07,030 --> 00:30:12,670
I have monitoring on top of metrics how

00:30:10,930 --> 00:30:14,410
are you telling your developers when

00:30:12,670 --> 00:30:16,690
something bad happens without them

00:30:14,410 --> 00:30:19,840
having to go to their Cabana dashboard

00:30:16,690 --> 00:30:22,060
or something oh I see I'm I'm afraid I

00:30:19,840 --> 00:30:25,180
don't have this problem we are we are

00:30:22,060 --> 00:30:27,070
too small for that to have to to be this

00:30:25,180 --> 00:30:29,310
a problem we have to solve so I can't

00:30:27,070 --> 00:30:31,660
help you there okay thanks sorry

00:30:29,310 --> 00:30:35,100
Thank You Nick sadly we don't have more

00:30:31,660 --> 00:30:35,100

YouTube URL: https://www.youtube.com/watch?v=gqmAwK0wNyw


