Title: TALK   Jonathan Striebel   Using Declarative Configs for Maintainable Reproducible Code
Publication date: 2021-05-30
Playlist: PyCon US 2021
Description: 
	Wondering how to keep your application config from getting outdated? Looking for a way to future-proof it in a backwards-compatible manner, keeping previous versions reproducible? Join this talk, we’ll share how declarative configs can be leveraged to make your code maintainable and reproducible at the same time.

Therefore, an overview across the application config landscape is given – from inputs as cli-args, env-vars, and config-files, to their representations in code, covering serialization & deserialization, type-safety with config-schemas and evolutions. We’ll recommend cherries to pick for a maintainable and expressive declarative config system.

All code examples are available at
https://github.com/jstriebel/declarative-configs

00:18 *Introduction & Problem Domain*
       https://scalableminds.com
       https://webknossos.org
       https://twitter.com/jostriebel

03:02 *Goals: Maintainability & Reproducability*

*Declarative Configurations and their Pythonic Representations*
04:16 Toy Experiment
05:07 Declarative Configuration Exctraction
06:08 Input Formats, Representations & Deserialization
       https://typer.tiangolo.com
       https://www.attrs.org
       https://cattrs.readthedocs.io
08:49 Landscape Overview
       Blog Post comparing attrs, dataclasses & pydantic:
       https://stefan.sofa-rockers.org/2020/05/29/attrs-dataclasses-pydantic

*Code Examples*
10:10 Toy Example
11:08 Split Configuration
13:46 Type Checking
       https://mypy.readthedocs.io/
       https://nbqa.readthedocs.io
15:15 Complex Example with Nested Configurations
18:45 Evolution of Old Configurations

*Recap & Summary*
20:15 Schema Versions & Evolutions
21:04 Experiment Tracking
21:34 Summary

Slides: https://speakerdeck.com/jstriebel/declarative-configs-for-maintainable-reproducible-code
Captions: 
	00:00:04,170 --> 00:00:11,869
[Music]

00:00:15,040 --> 00:00:18,400
hello everyone

00:00:16,320 --> 00:00:20,240
i'm very happy to welcome you to my talk

00:00:18,400 --> 00:00:21,039
about declarative configs for

00:00:20,240 --> 00:00:24,560
maintainable

00:00:21,039 --> 00:00:26,320
reproducible code my name is jonathan

00:00:24,560 --> 00:00:27,680
and you can write me an email or follow

00:00:26,320 --> 00:00:30,320
me on twitter

00:00:27,680 --> 00:00:31,920
i'm working for scalable a software

00:00:30,320 --> 00:00:34,079
company in potsdam germany

00:00:31,920 --> 00:00:35,920
we're working on image analysis tools

00:00:34,079 --> 00:00:38,480
and services

00:00:35,920 --> 00:00:39,520
before diving into the topic in detail

00:00:38,480 --> 00:00:41,600
i'd like to give you an

00:00:39,520 --> 00:00:44,000
overview of the domain i'm working in

00:00:41,600 --> 00:00:46,239
and the problems we are facing at

00:00:44,000 --> 00:00:48,399
scalable minds we've built webnozzles

00:00:46,239 --> 00:00:49,840
an open source online tool that allows

00:00:48,399 --> 00:00:52,559
you to view and annotate

00:00:49,840 --> 00:00:53,120
3d volumetric image data what you see

00:00:52,559 --> 00:00:55,120
here

00:00:53,120 --> 00:00:56,399
is a 3d scan of brain tissue from a

00:00:55,120 --> 00:00:58,160
microscope

00:00:56,399 --> 00:01:00,239
the different cells are segmented as

00:00:58,160 --> 00:01:01,840
shown by the color and one cell is

00:01:00,239 --> 00:01:04,000
rendered in 3d at the bottom

00:01:01,840 --> 00:01:05,040
center if you want to try it for

00:01:04,000 --> 00:01:09,439
yourself you could

00:01:05,040 --> 00:01:11,840
go to webnozzles.org or use this qr code

00:01:09,439 --> 00:01:12,720
we are also automating the annotation of

00:01:11,840 --> 00:01:14,960
such cells

00:01:12,720 --> 00:01:16,880
which is what i'm working on most of the

00:01:14,960 --> 00:01:20,080
time

00:01:16,880 --> 00:01:20,640
for that we're running experiments it

00:01:20,080 --> 00:01:23,040
starts

00:01:20,640 --> 00:01:24,240
with multiple terabytes of grayscale

00:01:23,040 --> 00:01:26,159
image data

00:01:24,240 --> 00:01:28,159
on that we train machine learning

00:01:26,159 --> 00:01:29,520
systems to detect where the cell

00:01:28,159 --> 00:01:31,360
boundaries are

00:01:29,520 --> 00:01:33,439
therefore we manage the training data in

00:01:31,360 --> 00:01:36,320
the valuation data which was acquired

00:01:33,439 --> 00:01:39,520
manually via web nozzles before

00:01:36,320 --> 00:01:41,759
the training usually takes up two weeks

00:01:39,520 --> 00:01:44,159
afterwards we are running segmentation

00:01:41,759 --> 00:01:46,479
and agglomeration algorithms

00:01:44,159 --> 00:01:48,320
the result is then a dense 3d

00:01:46,479 --> 00:01:48,960
reconstruction of all neurons in the

00:01:48,320 --> 00:01:50,880
data

00:01:48,960 --> 00:01:52,960
which is then used for biological

00:01:50,880 --> 00:01:55,040
analysis by our clients

00:01:52,960 --> 00:01:56,960
since we were working with massive data

00:01:55,040 --> 00:01:58,960
and computation heavy algorithms

00:01:56,960 --> 00:02:01,280
we run this pipeline parallelized in

00:01:58,960 --> 00:02:03,040
high performance computing clusters

00:02:01,280 --> 00:02:04,799
this is just an overview of a single

00:02:03,040 --> 00:02:07,040
experiment since

00:02:04,799 --> 00:02:09,520
the domain is very much research driven

00:02:07,040 --> 00:02:11,520
we constantly iterate on our pipeline

00:02:09,520 --> 00:02:13,599
we might run an experiment with data set

00:02:11,520 --> 00:02:17,360
1 and develop a feature a

00:02:13,599 --> 00:02:19,920
to improve the results additionally

00:02:17,360 --> 00:02:22,800
we start with data set 2. on the first

00:02:19,920 --> 00:02:24,720
data set we add feature b and figure out

00:02:22,800 --> 00:02:27,280
that we should replace feature a with

00:02:24,720 --> 00:02:30,239
feature c after some time

00:02:27,280 --> 00:02:31,120
also we apply feature b and a new

00:02:30,239 --> 00:02:33,280
feature d

00:02:31,120 --> 00:02:34,400
on the second data set and afterwards

00:02:33,280 --> 00:02:38,080
also use d

00:02:34,400 --> 00:02:39,440
on data set 1. this happens with many

00:02:38,080 --> 00:02:41,760
more in between steps

00:02:39,440 --> 00:02:43,920
on a time scale of months and years and

00:02:41,760 --> 00:02:46,160
might give you an idea of the problems

00:02:43,920 --> 00:02:48,319
we ran into we needed to keep an

00:02:46,160 --> 00:02:50,800
overview of the features we use for each

00:02:48,319 --> 00:02:52,319
data set and experiment and be able to

00:02:50,800 --> 00:02:54,560
rerun an experiment

00:02:52,319 --> 00:02:55,680
maybe a year later but with the

00:02:54,560 --> 00:02:57,200
up-to-date pipeline

00:02:55,680 --> 00:02:58,879
so that we can simply switch on the

00:02:57,200 --> 00:03:02,480
feature that we just developed

00:02:58,879 --> 00:03:05,120
yesterday those challenges

00:03:02,480 --> 00:03:06,080
motivate this talk we need to keep our

00:03:05,120 --> 00:03:08,480
application

00:03:06,080 --> 00:03:11,200
hierarchy maintainable and at the same

00:03:08,480 --> 00:03:13,599
time reproducible

00:03:11,200 --> 00:03:15,519
reproducible not only in the sense of

00:03:13,599 --> 00:03:17,040
pinning the code and the packages of a

00:03:15,519 --> 00:03:19,599
specific experiment

00:03:17,040 --> 00:03:20,480
but being able to rerun that old

00:03:19,599 --> 00:03:23,519
experiment

00:03:20,480 --> 00:03:23,840
with the current code base therefore we

00:03:23,519 --> 00:03:25,840
have

00:03:23,840 --> 00:03:28,000
four main points that helped us to

00:03:25,840 --> 00:03:30,640
accomplish this

00:03:28,000 --> 00:03:33,040
first we separate our feature flags and

00:03:30,640 --> 00:03:35,840
parameters the configuration

00:03:33,040 --> 00:03:37,920
from the rest of the code this splits

00:03:35,840 --> 00:03:40,560
the structure of the experiments

00:03:37,920 --> 00:03:42,640
and the evolving pipeline and give us

00:03:40,560 --> 00:03:44,959
the notion of the experiment hierarchy

00:03:42,640 --> 00:03:46,879
i've just shown before

00:03:44,959 --> 00:03:49,120
second we want to verify the

00:03:46,879 --> 00:03:50,640
configuration of an experiment against

00:03:49,120 --> 00:03:53,439
the available features

00:03:50,640 --> 00:03:55,120
but also the other way around verifying

00:03:53,439 --> 00:03:58,159
that the code only uses available

00:03:55,120 --> 00:04:00,959
configuration parameters

00:03:58,159 --> 00:04:02,400
finally since the configurations might

00:04:00,959 --> 00:04:04,879
change over time

00:04:02,400 --> 00:04:07,200
we want to have automatic migrations or

00:04:04,879 --> 00:04:09,519
evolutions in place

00:04:07,200 --> 00:04:11,360
first i'd like to give you an overview

00:04:09,519 --> 00:04:14,879
about the options to implement this

00:04:11,360 --> 00:04:16,880
before then diving into the actual code

00:04:14,879 --> 00:04:18,959
for this talk i've prepared a toy

00:04:16,880 --> 00:04:20,560
example that is much more simple than

00:04:18,959 --> 00:04:22,400
our usual experiments

00:04:20,560 --> 00:04:23,759
but the mechanisms are basically the

00:04:22,400 --> 00:04:25,759
same

00:04:23,759 --> 00:04:27,840
in the example we load a data set in

00:04:25,759 --> 00:04:29,199
this case the linear root dataset about

00:04:27,840 --> 00:04:31,280
sport exercises

00:04:29,199 --> 00:04:33,600
you can see different sport exercises

00:04:31,280 --> 00:04:34,639
and the numbers of repetitions that a

00:04:33,600 --> 00:04:38,560
person could do

00:04:34,639 --> 00:04:39,600
in the different rows we perform outlier

00:04:38,560 --> 00:04:42,080
detection on it

00:04:39,600 --> 00:04:43,919
and then plot the data where an outlier

00:04:42,080 --> 00:04:45,600
here is marked in orange

00:04:43,919 --> 00:04:47,280
for the plot we have to select two of

00:04:45,600 --> 00:04:47,919
the available columns for the different

00:04:47,280 --> 00:04:50,479
axes

00:04:47,919 --> 00:04:52,400
in this case we have chins situps and

00:04:50,479 --> 00:04:55,680
jumps available in the data set

00:04:52,400 --> 00:04:57,600
and plot the jumps and the chins

00:04:55,680 --> 00:04:58,720
here you can see that one person can do

00:04:57,600 --> 00:05:01,280
much more jumps

00:04:58,720 --> 00:05:04,720
than the others and therefore is marked

00:05:01,280 --> 00:05:04,720
as an outlier here in the top

00:05:05,440 --> 00:05:08,639
the code for this experiment would look

00:05:07,520 --> 00:05:11,440
roughly like this

00:05:08,639 --> 00:05:12,720
we load the data from some path find the

00:05:11,440 --> 00:05:14,800
outliers

00:05:12,720 --> 00:05:16,639
where we might have to specify a

00:05:14,800 --> 00:05:18,720
threshold in this case 10

00:05:16,639 --> 00:05:20,479
and plot the data using two specific

00:05:18,720 --> 00:05:23,280
axes

00:05:20,479 --> 00:05:24,080
now when we extract the configuration we

00:05:23,280 --> 00:05:26,800
have to extract

00:05:24,080 --> 00:05:29,120
in this case the path the threshold and

00:05:26,800 --> 00:05:30,960
the two axis for the plot

00:05:29,120 --> 00:05:32,720
you could of course simply write a

00:05:30,960 --> 00:05:34,639
function with four parameters

00:05:32,720 --> 00:05:36,400
but instead i recommend to keep this

00:05:34,639 --> 00:05:38,880
completely separate of your code

00:05:36,400 --> 00:05:41,280
using a declarative configuration

00:05:38,880 --> 00:05:42,240
declarative means that only data can be

00:05:41,280 --> 00:05:44,400
specified here

00:05:42,240 --> 00:05:46,479
in contrast to imperative con

00:05:44,400 --> 00:05:47,680
programming such as with a python

00:05:46,479 --> 00:05:51,280
programming language

00:05:47,680 --> 00:05:54,000
which can use if clauses or for loops

00:05:51,280 --> 00:05:56,080
the benefit of separating this and using

00:05:54,000 --> 00:05:58,639
a declarative config

00:05:56,080 --> 00:05:59,680
that this forces you to keep a simple

00:05:58,639 --> 00:06:01,840
configuration

00:05:59,680 --> 00:06:03,280
and it cannot contain any logic that

00:06:01,840 --> 00:06:06,800
instead must be specified

00:06:03,280 --> 00:06:09,039
in your application

00:06:06,800 --> 00:06:10,800
so we need a declarative input format

00:06:09,039 --> 00:06:13,199
for the configuration

00:06:10,800 --> 00:06:14,560
then this needs to be represented in our

00:06:13,199 --> 00:06:17,440
code base

00:06:14,560 --> 00:06:18,639
and to turn this input format into the

00:06:17,440 --> 00:06:21,199
representation

00:06:18,639 --> 00:06:22,560
we need some sort of deserialization in

00:06:21,199 --> 00:06:24,160
between

00:06:22,560 --> 00:06:26,000
let's have a look what our options for

00:06:24,160 --> 00:06:28,240
those are

00:06:26,000 --> 00:06:30,160
for the input format a typical choice is

00:06:28,240 --> 00:06:31,680
to use arguments for a command line

00:06:30,160 --> 00:06:33,680
interface

00:06:31,680 --> 00:06:35,199
therefore all configuration must be

00:06:33,680 --> 00:06:36,880
supplied on the command line which

00:06:35,199 --> 00:06:39,440
doesn't work too well if you have a lot

00:06:36,880 --> 00:06:41,360
of parameters

00:06:39,440 --> 00:06:43,520
it's great for a few parameters though

00:06:41,360 --> 00:06:46,319
the usual choice is to use the python

00:06:43,520 --> 00:06:47,919
built in arc parse to load the arguments

00:06:46,319 --> 00:06:49,440
but here nothing prevents you from

00:06:47,919 --> 00:06:50,479
accessing a wrong key of your

00:06:49,440 --> 00:06:52,240
configuration

00:06:50,479 --> 00:06:53,520
which would result then in a runtime

00:06:52,240 --> 00:06:55,759
error

00:06:53,520 --> 00:06:56,880
therefore i prefer to use the external

00:06:55,759 --> 00:06:59,039
package typer

00:06:56,880 --> 00:07:00,800
which allows you to specify the expected

00:06:59,039 --> 00:07:03,120
parameters and data types

00:07:00,800 --> 00:07:04,960
as function arguments which then can

00:07:03,120 --> 00:07:07,280
also be type checked more about that in

00:07:04,960 --> 00:07:09,120
a second

00:07:07,280 --> 00:07:10,880
another alternative is to use

00:07:09,120 --> 00:07:13,599
environment variables for the input

00:07:10,880 --> 00:07:15,120
which can be accessed via os dot environ

00:07:13,599 --> 00:07:18,160
in python

00:07:15,120 --> 00:07:18,960
what i prefer for large configs is to

00:07:18,160 --> 00:07:21,680
extract them

00:07:18,960 --> 00:07:22,880
into a separate file internally we use

00:07:21,680 --> 00:07:25,360
yaml for that

00:07:22,880 --> 00:07:27,360
but there's many other choices like json

00:07:25,360 --> 00:07:28,960
tommel or any

00:07:27,360 --> 00:07:31,360
to load a yama file you need a

00:07:28,960 --> 00:07:32,639
third-party library such as payamal

00:07:31,360 --> 00:07:35,120
which gives you a pythonic

00:07:32,639 --> 00:07:37,520
representation of that file

00:07:35,120 --> 00:07:39,120
this representation consists of the

00:07:37,520 --> 00:07:44,400
basic python types

00:07:39,120 --> 00:07:46,240
such as dictionaries lists integers etc

00:07:44,400 --> 00:07:47,840
the problem here is again that we could

00:07:46,240 --> 00:07:50,160
access the wrong key

00:07:47,840 --> 00:07:51,120
which would result in a runtime error

00:07:50,160 --> 00:07:53,360
since our

00:07:51,120 --> 00:07:54,479
experiments run for days this needs to

00:07:53,360 --> 00:07:57,440
be catched earlier

00:07:54,479 --> 00:07:58,080
for example in tests an additional

00:07:57,440 --> 00:08:00,800
possibility

00:07:58,080 --> 00:08:02,639
that we use is to turn the configuration

00:08:00,800 --> 00:08:04,240
into a class

00:08:02,639 --> 00:08:05,919
the class then defines the different

00:08:04,240 --> 00:08:09,120
parameters and their types

00:08:05,919 --> 00:08:09,680
as their attributes to get the init

00:08:09,120 --> 00:08:12,400
method

00:08:09,680 --> 00:08:14,240
and other helper methods we use the

00:08:12,400 --> 00:08:16,240
uterus library which adds them

00:08:14,240 --> 00:08:18,160
automatically

00:08:16,240 --> 00:08:21,120
now we access the parameters of the

00:08:18,160 --> 00:08:22,879
config object as usual attributes

00:08:21,120 --> 00:08:24,240
this allows us to use a type checker

00:08:22,879 --> 00:08:27,280
before running the code

00:08:24,240 --> 00:08:30,639
which catches the wrong usage

00:08:27,280 --> 00:08:31,520
beforehand since loading a yama file

00:08:30,639 --> 00:08:33,440
into python

00:08:31,520 --> 00:08:34,959
gives us the basic python structure we

00:08:33,440 --> 00:08:37,200
have on the left

00:08:34,959 --> 00:08:39,360
we need a tool to convert this into the

00:08:37,200 --> 00:08:41,200
object of the class on the right

00:08:39,360 --> 00:08:42,959
for this we can directly use the c

00:08:41,200 --> 00:08:44,880
address library which provides

00:08:42,959 --> 00:08:46,720
converters for many data types

00:08:44,880 --> 00:08:49,120
and can also be adapted with custom

00:08:46,720 --> 00:08:50,959
converters

00:08:49,120 --> 00:08:52,800
before diving into the code let's have a

00:08:50,959 --> 00:08:54,000
look at the landscape of possibilities

00:08:52,800 --> 00:08:56,640
you have if you want

00:08:54,000 --> 00:08:58,000
to implement a similar system i've shown

00:08:56,640 --> 00:08:59,760
three different options how you can

00:08:58,000 --> 00:09:00,959
supply your config data to your

00:08:59,760 --> 00:09:02,720
application

00:09:00,959 --> 00:09:04,399
then this needs to be represented in

00:09:02,720 --> 00:09:05,120
your code for which you have many

00:09:04,399 --> 00:09:07,360
options

00:09:05,120 --> 00:09:08,560
if you want to add type information to a

00:09:07,360 --> 00:09:11,680
plain dictionary

00:09:08,560 --> 00:09:13,360
there is typing.typedict we rather using

00:09:11,680 --> 00:09:14,160
objects of custom classes as shown

00:09:13,360 --> 00:09:17,440
before

00:09:14,160 --> 00:09:18,720
to automate the special methods of those

00:09:17,440 --> 00:09:20,880
classes you can use

00:09:18,720 --> 00:09:22,240
named tuples or data classes which are

00:09:20,880 --> 00:09:24,720
part of python

00:09:22,240 --> 00:09:26,480
if you have more complex scenarios you

00:09:24,720 --> 00:09:29,120
might want to use a third party

00:09:26,480 --> 00:09:29,600
party library such as pedentic which is

00:09:29,120 --> 00:09:33,040
great

00:09:29,600 --> 00:09:34,560
or in our case utters i'm not providing

00:09:33,040 --> 00:09:36,560
a detailed comparison here

00:09:34,560 --> 00:09:38,240
this would be just too much for this

00:09:36,560 --> 00:09:40,240
talk

00:09:38,240 --> 00:09:41,920
to create an object of such a class you

00:09:40,240 --> 00:09:44,720
also need a converter

00:09:41,920 --> 00:09:45,920
type load is a popular library design is

00:09:44,720 --> 00:09:48,399
specifically for

00:09:45,920 --> 00:09:50,399
data classes pedantic comes with

00:09:48,399 --> 00:09:52,880
built-in converters for its classes

00:09:50,399 --> 00:09:53,839
and then there's c adders which i prefer

00:09:52,880 --> 00:09:56,480
because you can

00:09:53,839 --> 00:09:58,480
write custom structures for your own

00:09:56,480 --> 00:10:00,320
classes

00:09:58,480 --> 00:10:02,240
finally i'd recommend to use a type

00:10:00,320 --> 00:10:04,079
checker to validate the usage of the

00:10:02,240 --> 00:10:07,440
config objects in your code

00:10:04,079 --> 00:10:10,720
such as my pi or pi type so let's see

00:10:07,440 --> 00:10:12,399
how this would look like in code

00:10:10,720 --> 00:10:14,640
here i've prepared the example i've

00:10:12,399 --> 00:10:16,560
shown you before in the tubebudder

00:10:14,640 --> 00:10:18,399
two-parter notebook

00:10:16,560 --> 00:10:20,399
in this case we're loading another data

00:10:18,399 --> 00:10:21,839
set the iris data set which is about

00:10:20,399 --> 00:10:24,160
flowers

00:10:21,839 --> 00:10:24,880
we also perform outlier detection this

00:10:24,160 --> 00:10:28,320
time with a

00:10:24,880 --> 00:10:31,040
slightly different threshold and

00:10:28,320 --> 00:10:31,839
then plot the data where we choose two

00:10:31,040 --> 00:10:34,160
axes

00:10:31,839 --> 00:10:35,279
in this case the data consists of four

00:10:34,160 --> 00:10:38,560
columns

00:10:35,279 --> 00:10:40,079
with different attributes about sizes of

00:10:38,560 --> 00:10:42,240
the flowers

00:10:40,079 --> 00:10:46,079
also we have specified here already

00:10:42,240 --> 00:10:48,160
which of the rows is an outlier or not

00:10:46,079 --> 00:10:49,440
we see the result for the two different

00:10:48,160 --> 00:10:52,640
axes

00:10:49,440 --> 00:10:53,279
in the plot below also i have another

00:10:52,640 --> 00:10:55,360
example

00:10:53,279 --> 00:10:57,040
the one i've just shown before with the

00:10:55,360 --> 00:11:00,480
linen root data set

00:10:57,040 --> 00:11:03,760
and another outlier factor here

00:11:00,480 --> 00:11:06,320
of 10 and we use of course

00:11:03,760 --> 00:11:07,360
two different axes to plot again the

00:11:06,320 --> 00:11:09,040
chins and the jumps

00:11:07,360 --> 00:11:11,200
and this results in just the plot you've

00:11:09,040 --> 00:11:15,040
seen before

00:11:11,200 --> 00:11:18,720
so when we want to convert this code

00:11:15,040 --> 00:11:22,240
into a code where we supply

00:11:18,720 --> 00:11:24,880
a split configuration can start by

00:11:22,240 --> 00:11:25,680
just writing this config file so in this

00:11:24,880 --> 00:11:28,959
case

00:11:25,680 --> 00:11:32,079
for the first example we would specify

00:11:28,959 --> 00:11:36,560
the data set iris in this case

00:11:32,079 --> 00:11:40,880
we specify 50 for the outlier factor

00:11:36,560 --> 00:11:40,880
and the two different axes for the plot

00:11:41,360 --> 00:11:45,680
we can do the same for the other example

00:11:44,079 --> 00:11:48,240
where we have another config

00:11:45,680 --> 00:11:50,480
this time with the linear route data set

00:11:48,240 --> 00:11:52,880
another parameter and two other axis for

00:11:50,480 --> 00:11:56,320
the plot

00:11:52,880 --> 00:11:58,880
now if we want to use this in our

00:11:56,320 --> 00:12:00,560
two-parter notebook here we have to

00:11:58,880 --> 00:12:03,120
specify a class

00:12:00,560 --> 00:12:05,440
as i have shown before so in this case

00:12:03,120 --> 00:12:08,160
it's the config schema class

00:12:05,440 --> 00:12:10,399
where we have a data set we look into

00:12:08,160 --> 00:12:12,800
the data set type in a second

00:12:10,399 --> 00:12:13,680
and the outlier number which is an

00:12:12,800 --> 00:12:16,560
integer

00:12:13,680 --> 00:12:18,079
and the two axis parameters that are

00:12:16,560 --> 00:12:22,000
strings

00:12:18,079 --> 00:12:23,440
so the dataset parameter here is an enum

00:12:22,000 --> 00:12:25,440
in this case we can just have two

00:12:23,440 --> 00:12:27,839
options for this enum liner root and

00:12:25,440 --> 00:12:27,839
iris

00:12:28,720 --> 00:12:31,920
so to load now this configuration into

00:12:31,200 --> 00:12:35,200
an object

00:12:31,920 --> 00:12:35,760
of this config schema class we have to

00:12:35,200 --> 00:12:38,079
first

00:12:35,760 --> 00:12:39,279
load the file when we have opened the

00:12:38,079 --> 00:12:42,800
file here

00:12:39,279 --> 00:12:45,440
we load it with yaml load which gives

00:12:42,800 --> 00:12:47,040
us a dictionary with just the structure

00:12:45,440 --> 00:12:49,360
of the file

00:12:47,040 --> 00:12:50,480
then we can use c utters which i've

00:12:49,360 --> 00:12:53,680
presented before

00:12:50,480 --> 00:12:55,519
to structure this dictionary into

00:12:53,680 --> 00:12:57,920
an object of this class the config

00:12:55,519 --> 00:13:00,480
schema so in the end

00:12:57,920 --> 00:13:02,079
the result is the config here below with

00:13:00,480 --> 00:13:04,480
just the data we've supplied in our

00:13:02,079 --> 00:13:06,639
config file

00:13:04,480 --> 00:13:08,079
this now can be used to adapt the code

00:13:06,639 --> 00:13:11,279
that we've seen before

00:13:08,079 --> 00:13:14,959
we just check which of the two data sets

00:13:11,279 --> 00:13:16,000
we have then we use the parameter from

00:13:14,959 --> 00:13:18,560
the configuration

00:13:16,000 --> 00:13:21,839
for the outlier detection and also the

00:13:18,560 --> 00:13:21,839
two axes we've supplied

00:13:21,920 --> 00:13:25,839
now instead of having the two

00:13:24,639 --> 00:13:28,639
experiments

00:13:25,839 --> 00:13:30,000
in the notebook we can simply use the

00:13:28,639 --> 00:13:33,519
different

00:13:30,000 --> 00:13:37,519
configuration now

00:13:33,519 --> 00:13:40,959
this is now for the configuration

00:13:37,519 --> 00:13:43,920
with the linear data set we load

00:13:40,959 --> 00:13:43,920
this configuration

00:13:44,079 --> 00:13:51,040
and rerun this part and generate

00:13:47,600 --> 00:13:51,839
the fitting plot here now if you've made

00:13:51,040 --> 00:13:54,880
a mistake

00:13:51,839 --> 00:13:58,320
and you supplied here instead of plot y

00:13:54,880 --> 00:14:01,440
plot z um you can check this

00:13:58,320 --> 00:14:03,360
ahead of running this using my pi the

00:14:01,440 --> 00:14:06,880
step a static type checker

00:14:03,360 --> 00:14:08,560
in this case using nvqa which can run

00:14:06,880 --> 00:14:13,680
this on notebooks

00:14:08,560 --> 00:14:13,680
we start my pi using this notebook

00:14:15,680 --> 00:14:19,279
and we have to save it before obviously

00:14:21,360 --> 00:14:27,120
and can now see that we have an error

00:14:24,959 --> 00:14:28,639
because we can't use plot z which isn't

00:14:27,120 --> 00:14:32,480
part of our schema

00:14:28,639 --> 00:14:36,000
but instead have to use y or

00:14:32,480 --> 00:14:40,000
x so if we fix this again

00:14:36,000 --> 00:14:43,760
we're back to no error

00:14:40,000 --> 00:14:46,079
so what you've seen now

00:14:43,760 --> 00:14:46,959
is that we can separate our config

00:14:46,079 --> 00:14:50,079
encode

00:14:46,959 --> 00:14:54,000
using a declarative yaml config in this

00:14:50,079 --> 00:14:56,880
case we can verify our configuration

00:14:54,000 --> 00:14:59,040
since we load it into our defined schema

00:14:56,880 --> 00:15:03,120
class

00:14:59,040 --> 00:15:05,440
using c utters and we can verify then

00:15:03,120 --> 00:15:08,639
the usage of this configuration in our

00:15:05,440 --> 00:15:08,639
code using mypi

00:15:08,720 --> 00:15:15,120
let's have a look how this would be in

00:15:11,839 --> 00:15:15,120
a more complex use case

00:15:17,440 --> 00:15:23,600
in this case we are not only

00:15:20,880 --> 00:15:24,560
plotting a simple scatter plot of the

00:15:23,600 --> 00:15:26,399
data

00:15:24,560 --> 00:15:28,560
but we want to add more possibilities

00:15:26,399 --> 00:15:31,920
for plotting

00:15:28,560 --> 00:15:35,920
so if we have a plot now instead of

00:15:31,920 --> 00:15:38,320
only using x and y we also define

00:15:35,920 --> 00:15:42,639
the c attribute which is optional since

00:15:38,320 --> 00:15:42,639
we still can do 2d plots

00:15:42,800 --> 00:15:47,040
another alternative to have instead of

00:15:46,000 --> 00:15:50,160
the scatter plot

00:15:47,040 --> 00:15:54,079
is now a heat map plot which just uses x

00:15:50,160 --> 00:15:56,720
and y

00:15:54,079 --> 00:15:58,320
since we can only supply one of the two

00:15:56,720 --> 00:16:01,120
plotting possibilities

00:15:58,320 --> 00:16:01,920
we just define a union of those which

00:16:01,120 --> 00:16:05,279
basically

00:16:01,920 --> 00:16:08,320
means that an object of the

00:16:05,279 --> 00:16:09,680
union of the plot schema is either a

00:16:08,320 --> 00:16:12,720
scatter plot schema

00:16:09,680 --> 00:16:15,759
or a heat map schema

00:16:12,720 --> 00:16:19,600
and you can see which of

00:16:15,759 --> 00:16:21,920
those it is by looking at the kind which

00:16:19,600 --> 00:16:23,680
either is sketcher in this case it just

00:16:21,920 --> 00:16:26,560
can be the scatter string

00:16:23,680 --> 00:16:26,560
or heat map

00:16:27,519 --> 00:16:32,480
then just as before we can use this in

00:16:30,480 --> 00:16:34,880
our config schema

00:16:32,480 --> 00:16:36,959
so we have a nested schema here in our

00:16:34,880 --> 00:16:39,120
config schema just for the plot

00:16:36,959 --> 00:16:40,800
the data set is just the same as before

00:16:39,120 --> 00:16:43,440
we have an enum here

00:16:40,800 --> 00:16:44,560
and we have the integer for the outliers

00:16:43,440 --> 00:16:47,600
but this now

00:16:44,560 --> 00:16:51,839
is the union of the two

00:16:47,600 --> 00:16:51,839
schemata we defined here above

00:16:52,079 --> 00:16:55,759
so now we have to adapt our

00:16:54,079 --> 00:16:57,920
configuration

00:16:55,759 --> 00:16:59,519
in this case we still take the linear

00:16:57,920 --> 00:17:02,720
data set

00:16:59,519 --> 00:17:04,400
we use still the same number for the

00:17:02,720 --> 00:17:06,959
outlier detection

00:17:04,400 --> 00:17:08,480
we do a scatter plot and then if we just

00:17:06,959 --> 00:17:10,480
supply chins and sit ups

00:17:08,480 --> 00:17:13,360
this results in exactly the same as

00:17:10,480 --> 00:17:16,160
before the code is a bit more complex

00:17:13,360 --> 00:17:17,120
now since we have if clauses for the

00:17:16,160 --> 00:17:20,079
different plotting

00:17:17,120 --> 00:17:23,520
possibilities so here we just have the

00:17:20,079 --> 00:17:23,520
same scatter plot as before

00:17:24,000 --> 00:17:30,960
now we can also add

00:17:27,039 --> 00:17:35,840
the optional z parameter

00:17:30,960 --> 00:17:35,840
and we reload this

00:17:36,559 --> 00:17:42,000
and see in the end now we have the 3d

00:17:40,160 --> 00:17:43,440
version of the plot how does this work

00:17:42,000 --> 00:17:47,600
in detail again

00:17:43,440 --> 00:17:50,559
so because here we are using the

00:17:47,600 --> 00:17:50,960
scatterplot schema we this time supplied

00:17:50,559 --> 00:17:55,280
the

00:17:50,960 --> 00:17:58,400
set attribute and in

00:17:55,280 --> 00:18:01,760
the if part here below we find out if

00:17:58,400 --> 00:18:04,480
z is defined or not and

00:18:01,760 --> 00:18:06,480
since it is defined we are doing now a

00:18:04,480 --> 00:18:10,160
scatter plot

00:18:06,480 --> 00:18:14,320
so let's say okay we want to do

00:18:10,160 --> 00:18:16,960
the heat map this time so again we just

00:18:14,320 --> 00:18:20,160
use the heatmap parameter from here

00:18:16,960 --> 00:18:23,440
supply it in the config reload the

00:18:20,160 --> 00:18:26,640
config and run our code

00:18:23,440 --> 00:18:28,799
and now we get an error because

00:18:26,640 --> 00:18:29,679
we couldn't parse this configuration

00:18:28,799 --> 00:18:32,880
since

00:18:29,679 --> 00:18:35,840
c was defined since c

00:18:32,880 --> 00:18:38,000
is not part of the 2d heat map we have

00:18:35,840 --> 00:18:41,760
to remove it

00:18:38,000 --> 00:18:43,200
and can rerun this and simply verifying

00:18:41,760 --> 00:18:46,480
this config can also be

00:18:43,200 --> 00:18:46,960
done easily ahead of time so in this

00:18:46,480 --> 00:18:50,240
time

00:18:46,960 --> 00:18:53,840
we just get a heat map now

00:18:50,240 --> 00:18:57,120
we've adapted the configuration for b

00:18:53,840 --> 00:18:59,039
manually but instead of

00:18:57,120 --> 00:19:00,559
adapting this manually every time we

00:18:59,039 --> 00:19:03,440
just want to have an evolution

00:19:00,559 --> 00:19:03,919
so we still have the configuration of a

00:19:03,440 --> 00:19:05,919
and

00:19:03,919 --> 00:19:07,520
we want to run this old configuration

00:19:05,919 --> 00:19:12,000
now also

00:19:07,520 --> 00:19:14,000
with a so for this i've prepared here

00:19:12,000 --> 00:19:15,520
an evolution it could look simply like

00:19:14,000 --> 00:19:17,840
this we load

00:19:15,520 --> 00:19:19,760
the dictionary of the config called a

00:19:17,840 --> 00:19:21,360
draw config in this case

00:19:19,760 --> 00:19:23,520
then we look if there's a version

00:19:21,360 --> 00:19:28,080
defined so here

00:19:23,520 --> 00:19:31,520
you'd have to say okay the new config

00:19:28,080 --> 00:19:34,400
also has a version key

00:19:31,520 --> 00:19:35,440
this would be two in this case and the

00:19:34,400 --> 00:19:37,919
default version

00:19:35,440 --> 00:19:39,280
for our old version is our old version

00:19:37,919 --> 00:19:42,480
configs are simply

00:19:39,280 --> 00:19:44,880
one and if we have an old config

00:19:42,480 --> 00:19:45,840
we just run our evolution which then

00:19:44,880 --> 00:19:47,840
transforms

00:19:45,840 --> 00:19:51,200
those two plots into the plotting

00:19:47,840 --> 00:19:54,000
possibilities that we have now

00:19:51,200 --> 00:19:56,320
so now instead of loading the new

00:19:54,000 --> 00:19:58,480
configuration

00:19:56,320 --> 00:20:02,240
below here we start with the old

00:19:58,480 --> 00:20:02,240
configuration and run evolution

00:20:02,320 --> 00:20:09,360
and can now use just the old experiment

00:20:06,159 --> 00:20:12,720
with the updated code where

00:20:09,360 --> 00:20:15,360
the configuration is migrated

00:20:12,720 --> 00:20:18,159
automatically

00:20:15,360 --> 00:20:19,600
so what we have are the config files

00:20:18,159 --> 00:20:20,880
that are transferred into the

00:20:19,600 --> 00:20:22,640
dictionaries

00:20:20,880 --> 00:20:24,320
which are then transferred into the

00:20:22,640 --> 00:20:26,320
objects so

00:20:24,320 --> 00:20:28,799
we always have an up-to-date schema

00:20:26,320 --> 00:20:32,080
class for our newest code

00:20:28,799 --> 00:20:35,840
and now what i've just shown before is

00:20:32,080 --> 00:20:38,000
to use an evolution where we have

00:20:35,840 --> 00:20:38,960
version config files and do the

00:20:38,000 --> 00:20:42,080
evolutions

00:20:38,960 --> 00:20:45,440
on the dictionaries so

00:20:42,080 --> 00:20:47,840
we need only the simple schema class of

00:20:45,440 --> 00:20:50,000
the current code

00:20:47,840 --> 00:20:50,880
alternative you can also do the

00:20:50,000 --> 00:20:53,520
evolutions

00:20:50,880 --> 00:20:55,039
on your structured objects but then you

00:20:53,520 --> 00:20:57,360
also need to keep all

00:20:55,039 --> 00:21:02,159
the old schema classes that you had

00:20:57,360 --> 00:21:04,240
defined before

00:21:02,159 --> 00:21:06,320
so i've shown you this overview before

00:21:04,240 --> 00:21:07,120
you might miss some more libraries here

00:21:06,320 --> 00:21:10,320
which are built

00:21:07,120 --> 00:21:13,360
to track experiments um

00:21:10,320 --> 00:21:16,159
those are sacred for example ml flow or

00:21:13,360 --> 00:21:17,120
guild and they are great to tag your

00:21:16,159 --> 00:21:18,320
experiments

00:21:17,120 --> 00:21:20,240
and can be combined with the

00:21:18,320 --> 00:21:20,960
configuration mechanisms i've described

00:21:20,240 --> 00:21:22,720
here

00:21:20,960 --> 00:21:24,480
but they don't have the same

00:21:22,720 --> 00:21:27,200
possibilities on their own

00:21:24,480 --> 00:21:28,559
such as type checking or evolutions they

00:21:27,200 --> 00:21:32,960
are especially useful

00:21:28,559 --> 00:21:32,960
to track metrics across your experiments

00:21:34,400 --> 00:21:39,120
so to summarize i've also now shown you

00:21:38,400 --> 00:21:42,240
two ways

00:21:39,120 --> 00:21:44,400
to evolve your configs so that you can

00:21:42,240 --> 00:21:48,080
run and migrate old experiments

00:21:44,400 --> 00:21:50,080
with a backwards-compatible application

00:21:48,080 --> 00:21:52,320
let's have a look at our goals again

00:21:50,080 --> 00:21:54,880
first the maintainability

00:21:52,320 --> 00:21:57,039
the separation of the declarative config

00:21:54,880 --> 00:21:59,039
helps us to keep an overview of our

00:21:57,039 --> 00:22:00,640
experiments and the config and code

00:21:59,039 --> 00:22:03,360
verification helps us

00:22:00,640 --> 00:22:04,960
that those work as expected in our

00:22:03,360 --> 00:22:07,520
pipeline

00:22:04,960 --> 00:22:08,799
also this verification together with a

00:22:07,520 --> 00:22:11,039
migration system

00:22:08,799 --> 00:22:12,240
also ensures that old experiments are

00:22:11,039 --> 00:22:16,159
reproducible

00:22:12,240 --> 00:22:16,159
with our ever evolving pipeline

00:22:17,280 --> 00:22:20,480
so feel free to contact me if you have

00:22:19,600 --> 00:22:22,480
any questions

00:22:20,480 --> 00:22:24,640
and i'm very happy to discuss any of

00:22:22,480 --> 00:22:26,880
those topics in detail

00:22:24,640 --> 00:22:29,520
i hope that this gave you some useful

00:22:26,880 --> 00:22:30,799
input for maintainable and reproducible

00:22:29,520 --> 00:22:41,840
applications

00:22:30,799 --> 00:22:41,840
thank you very much

00:23:34,640 --> 00:23:36,720

YouTube URL: https://www.youtube.com/watch?v=omhJrT90lXU


