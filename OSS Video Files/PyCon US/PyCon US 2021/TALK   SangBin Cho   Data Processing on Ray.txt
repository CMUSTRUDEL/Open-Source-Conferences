Title: TALK   SangBin Cho   Data Processing on Ray
Publication date: 2021-05-29
Playlist: PyCon US 2021
Description: 
	Machine learning and data processing applications continue to drive the need to develop scalable Python applications. Ray is a distributed execution engine that enables programmers to scale up their Python applications.

This talk will cover some of the challenges we faced and key architectural changes we made to Ray over the past year to support a new set of large scale data processing workloads.

Slides: https://docs.google.com/presentation/d/15a6-6Smdu9FldWU8S21925i7wV5Y625QXduXlxBBscw/edit?usp=sharing
Captions: 
	00:00:04,170 --> 00:00:11,869
[Music]

00:00:16,640 --> 00:00:19,600
hello i'm sang bin i'm a software

00:00:18,160 --> 00:00:21,039
engineer at nscl

00:00:19,600 --> 00:00:23,199
today i'm going to present data

00:00:21,039 --> 00:00:25,279
processing on ray

00:00:23,199 --> 00:00:27,439
oh what does this talk about the talk is

00:00:25,279 --> 00:00:30,640
primarily about ray and how it evolves

00:00:27,439 --> 00:00:32,079
over time to support data processing

00:00:30,640 --> 00:00:33,680
i'm going to go through why data

00:00:32,079 --> 00:00:36,399
processing support is important

00:00:33,680 --> 00:00:38,160
for general purpose systems like ray as

00:00:36,399 --> 00:00:40,000
well as what kind of architectural

00:00:38,160 --> 00:00:41,040
changes we've made over time to support

00:00:40,000 --> 00:00:43,440
them

00:00:41,040 --> 00:00:44,079
let me then introduce myself first i'm a

00:00:43,440 --> 00:00:45,840
soft engineer

00:00:44,079 --> 00:00:48,160
at any scale which is the company dutch

00:00:45,840 --> 00:00:50,000
packing raid i'm also a ray committer

00:00:48,160 --> 00:00:51,520
and have been working on ray over the

00:00:50,000 --> 00:00:53,760
past year

00:00:51,520 --> 00:00:55,600
i have primarily worked on raycore to

00:00:53,760 --> 00:00:59,600
support data processing lately

00:00:55,600 --> 00:01:01,440
and which is why i'm having a talk today

00:00:59,600 --> 00:01:03,120
well then let's start from why we need a

00:01:01,440 --> 00:01:05,600
general purpose system for data

00:01:03,120 --> 00:01:07,840
processing

00:01:05,600 --> 00:01:09,360
uh in the motor and ml infrastructure

00:01:07,840 --> 00:01:10,080
there are lots of complexities in

00:01:09,360 --> 00:01:11,920
composing

00:01:10,080 --> 00:01:14,320
different types of workload in different

00:01:11,920 --> 00:01:15,920
systems for example this is the one i

00:01:14,320 --> 00:01:18,479
actually have seen in the industry

00:01:15,920 --> 00:01:20,960
um first it needs to do run etl type of

00:01:18,479 --> 00:01:22,159
jobs using the spark cluster for

00:01:20,960 --> 00:01:24,799
feature processing or some

00:01:22,159 --> 00:01:27,439
pre-processing uh load and shuffle the

00:01:24,799 --> 00:01:28,320
data that's written to parklet into the

00:01:27,439 --> 00:01:31,920
training cluster

00:01:28,320 --> 00:01:34,079
like in this example or it uses hormone

00:01:31,920 --> 00:01:35,520
and after the training it needs to do

00:01:34,079 --> 00:01:36,400
the hyperparameter tuning in the

00:01:35,520 --> 00:01:38,560
different of

00:01:36,400 --> 00:01:40,240
different systems in this case is ray

00:01:38,560 --> 00:01:42,880
and also the ray chin

00:01:40,240 --> 00:01:44,079
um there are also many cases where um

00:01:42,880 --> 00:01:45,600
those training

00:01:44,079 --> 00:01:47,600
during the training job you sometimes

00:01:45,600 --> 00:01:49,600
need to run some another

00:01:47,600 --> 00:01:51,680
preprocessing or shuffling workload back

00:01:49,600 --> 00:01:53,680
into the spark cluster

00:01:51,680 --> 00:01:54,799
which all which can actually add a lot

00:01:53,680 --> 00:01:57,040
of complexities

00:01:54,799 --> 00:01:57,840
uh when this sort of um different

00:01:57,040 --> 00:02:01,840
composition

00:01:57,840 --> 00:02:01,840
increases in the industry example

00:02:01,920 --> 00:02:05,840
then what are the problems firstly job

00:02:04,159 --> 00:02:07,920
composition across multiple

00:02:05,840 --> 00:02:09,440
different systems can actually increase

00:02:07,920 --> 00:02:10,959
the complexity a lot

00:02:09,440 --> 00:02:13,200
because it requires to maintain the

00:02:10,959 --> 00:02:16,160
multiple systems organizing

00:02:13,200 --> 00:02:17,120
um workflow of different jobs and

00:02:16,160 --> 00:02:18,959
scheduling them

00:02:17,120 --> 00:02:21,120
and also taking care of these job

00:02:18,959 --> 00:02:22,640
dependencies and failures that happen

00:02:21,120 --> 00:02:24,640
among them

00:02:22,640 --> 00:02:26,080
at the same time managing multiple

00:02:24,640 --> 00:02:28,640
different systems can be

00:02:26,080 --> 00:02:29,520
uh incurring really high maintenance

00:02:28,640 --> 00:02:31,519
costs

00:02:29,520 --> 00:02:33,440
uh because there needs to be team that

00:02:31,519 --> 00:02:35,440
maintain different systems and each of

00:02:33,440 --> 00:02:37,120
team needs to understand how it works

00:02:35,440 --> 00:02:39,920
how it operates how to debug

00:02:37,120 --> 00:02:41,840
and things like that and usually when

00:02:39,920 --> 00:02:44,000
you com when you want to make

00:02:41,840 --> 00:02:45,840
multiple systems to communicate it's

00:02:44,000 --> 00:02:48,160
usually not efficient because you always

00:02:45,840 --> 00:02:51,360
need to pass intermediate layers like

00:02:48,160 --> 00:02:53,040
some files parker files like uh um

00:02:51,360 --> 00:02:54,720
distributed file systems and things like

00:02:53,040 --> 00:02:56,640
that

00:02:54,720 --> 00:02:58,560
and this can be very inefficient if you

00:02:56,640 --> 00:03:00,239
can actually solve all the problem like

00:02:58,560 --> 00:03:02,480
pre-processing training

00:03:00,239 --> 00:03:03,920
and things like that in the same cluster

00:03:02,480 --> 00:03:05,040
all within memory when you have enough

00:03:03,920 --> 00:03:08,159
memory capacity

00:03:05,040 --> 00:03:11,840
in your in your training cluster or

00:03:08,159 --> 00:03:13,840
data processing cluster oh then what if

00:03:11,840 --> 00:03:16,000
you have a general purpose system

00:03:13,840 --> 00:03:17,040
uh if a single system can run different

00:03:16,000 --> 00:03:18,720
type of workload

00:03:17,040 --> 00:03:21,360
it can actually remove a lot of

00:03:18,720 --> 00:03:23,840
complexity we just go through

00:03:21,360 --> 00:03:24,480
for example instead of actually grouping

00:03:23,840 --> 00:03:26,159
the job

00:03:24,480 --> 00:03:28,000
depending on what type of workload it

00:03:26,159 --> 00:03:28,640
has which needs to be run in different

00:03:28,000 --> 00:03:31,280
systems

00:03:28,640 --> 00:03:32,959
we can more logically group job through

00:03:31,280 --> 00:03:35,280
the job so that we can simplify the

00:03:32,959 --> 00:03:39,200
dependencies between jobs

00:03:35,280 --> 00:03:40,959
um it's also if you can run multiple

00:03:39,200 --> 00:03:43,440
different workloads within a single

00:03:40,959 --> 00:03:45,200
general purpose system uh there is gonna

00:03:43,440 --> 00:03:46,879
be less maintenance burden because you

00:03:45,200 --> 00:03:48,959
just need to understand one system

00:03:46,879 --> 00:03:50,799
operate one system and also debug one

00:03:48,959 --> 00:03:51,519
system that means you just need to learn

00:03:50,799 --> 00:03:54,959
one system

00:03:51,519 --> 00:03:56,720
in this case and as i mentioned the

00:03:54,959 --> 00:03:59,200
optimization is easier because

00:03:56,720 --> 00:04:00,799
if your data processing workload and

00:03:59,200 --> 00:04:02,319
also the training workload

00:04:00,799 --> 00:04:04,080
if all of the results from the data

00:04:02,319 --> 00:04:05,680
processing can be cached in memory

00:04:04,080 --> 00:04:07,360
there's no reason to actually test the

00:04:05,680 --> 00:04:10,159
intermediate layer and we can just

00:04:07,360 --> 00:04:12,480
directly pass data using the memory

00:04:10,159 --> 00:04:14,319
which is a lot faster

00:04:12,480 --> 00:04:16,320
also as you can see this type of system

00:04:14,319 --> 00:04:18,079
composition could become like

00:04:16,320 --> 00:04:19,759
this with a single general purpose

00:04:18,079 --> 00:04:21,519
system and you can run different

00:04:19,759 --> 00:04:23,280
libraries like etl library

00:04:21,519 --> 00:04:24,960
load and shop library training library

00:04:23,280 --> 00:04:26,960
and ginning library all on the same

00:04:24,960 --> 00:04:28,560
systems

00:04:26,960 --> 00:04:30,160
now what could be a good general purpose

00:04:28,560 --> 00:04:32,320
system candidates here uh

00:04:30,160 --> 00:04:33,759
i'd like to introduce ray as a solution

00:04:32,320 --> 00:04:35,440
for this problem

00:04:33,759 --> 00:04:37,759
um let me actually briefly introduce

00:04:35,440 --> 00:04:39,120
what ray is already is a simple library

00:04:37,759 --> 00:04:41,040
for distributed computing

00:04:39,120 --> 00:04:42,160
it's also general purpose which is why

00:04:41,040 --> 00:04:44,560
we'd like to

00:04:42,160 --> 00:04:46,400
use this as a solution it also has a

00:04:44,560 --> 00:04:48,080
great ecosystem of libraries which

00:04:46,400 --> 00:04:48,800
enable all the workload that we just

00:04:48,080 --> 00:04:50,880
described

00:04:48,800 --> 00:04:52,479
and it's also written in very high

00:04:50,880 --> 00:04:54,400
performance way

00:04:52,479 --> 00:04:56,320
if you're very interested in deep

00:04:54,400 --> 00:04:58,160
details about rey you can also

00:04:56,320 --> 00:04:59,759
check out the last year's type of talk

00:04:58,160 --> 00:05:02,639
but i'm also going to introduce

00:04:59,759 --> 00:05:04,240
more about writing this talk okay then

00:05:02,639 --> 00:05:05,280
let's actually i'll learn a little bit

00:05:04,240 --> 00:05:08,320
more about

00:05:05,280 --> 00:05:11,280
um what the ray is about

00:05:08,320 --> 00:05:14,160
well firstly ray provides um simple apis

00:05:11,280 --> 00:05:15,840
to write distributed applications

00:05:14,160 --> 00:05:17,759
so normal python programs usually

00:05:15,840 --> 00:05:19,840
consist of function and classes

00:05:17,759 --> 00:05:21,120
and in this case you have two functions

00:05:19,840 --> 00:05:23,840
reading array from the file

00:05:21,120 --> 00:05:25,680
and also add that arrays together and

00:05:23,840 --> 00:05:27,039
this is another class example you have a

00:05:25,680 --> 00:05:28,800
counter class which

00:05:27,039 --> 00:05:30,639
you just define it and you can increment

00:05:28,800 --> 00:05:33,919
the internal

00:05:30,639 --> 00:05:35,600
attributes using the increment method

00:05:33,919 --> 00:05:37,039
this is very simple programming model

00:05:35,600 --> 00:05:37,759
and everyone understands if you're

00:05:37,039 --> 00:05:39,440
writing code

00:05:37,759 --> 00:05:41,280
but if you actually want to run them in

00:05:39,440 --> 00:05:42,320
parallel in distributed systems how

00:05:41,280 --> 00:05:45,120
would you do that this

00:05:42,320 --> 00:05:46,800
becomes a much more complicated problems

00:05:45,120 --> 00:05:48,720
fortunately ray provides really

00:05:46,800 --> 00:05:50,960
intuitive apis to support this

00:05:48,720 --> 00:05:52,479
so in ray functions becoming task and

00:05:50,960 --> 00:05:54,160
class becoming actor

00:05:52,479 --> 00:05:55,600
just by adding a decorator called

00:05:54,160 --> 00:05:57,440
ray.remote

00:05:55,600 --> 00:05:59,520
and once you decorate your functions you

00:05:57,440 --> 00:06:01,840
can invoke them by calling

00:05:59,520 --> 00:06:02,720
dot remote for each function in class

00:06:01,840 --> 00:06:04,880
and

00:06:02,720 --> 00:06:06,000
these functions are basically executed

00:06:04,880 --> 00:06:09,440
somewhere in your

00:06:06,000 --> 00:06:11,919
distributed systems in parallel and

00:06:09,440 --> 00:06:12,800
it's returning the future and later you

00:06:11,919 --> 00:06:15,199
can actually

00:06:12,800 --> 00:06:17,360
obtaining the results by calling an api

00:06:15,199 --> 00:06:19,919
called ray.get

00:06:17,360 --> 00:06:21,680
on top of the feature that is returned

00:06:19,919 --> 00:06:23,520
and the same thing applies to the class

00:06:21,680 --> 00:06:25,600
the class once they are decorated by a

00:06:23,520 --> 00:06:27,280
red remote they becoming an actor

00:06:25,600 --> 00:06:29,360
and this means this class is standing

00:06:27,280 --> 00:06:30,720
somewhere in your distributed systems

00:06:29,360 --> 00:06:34,319
and you can communicate with that

00:06:30,720 --> 00:06:36,240
through the function.remote

00:06:34,319 --> 00:06:38,800
um secondly raise the general purpose

00:06:36,240 --> 00:06:40,880
systems it supports both stateless and

00:06:38,800 --> 00:06:42,800
stateful computation which are basically

00:06:40,880 --> 00:06:44,720
the primitive operations for

00:06:42,800 --> 00:06:48,240
building operating uh building the

00:06:44,720 --> 00:06:49,599
distributed systems applications

00:06:48,240 --> 00:06:51,520
for example using the stateless

00:06:49,599 --> 00:06:53,360
computation like tasks you can easily

00:06:51,520 --> 00:06:56,240
build on distributed

00:06:53,360 --> 00:06:58,000
um data processing library that is doing

00:06:56,240 --> 00:07:00,240
some etl type of workload

00:06:58,000 --> 00:07:02,400
or it's also possible to build some

00:07:00,240 --> 00:07:05,440
scientific or parallel computing

00:07:02,400 --> 00:07:07,599
workload if you use actor it's also

00:07:05,440 --> 00:07:09,280
possible to even further optimize your

00:07:07,599 --> 00:07:11,520
applications like for exam

00:07:09,280 --> 00:07:12,880
in some cases if you need stage for your

00:07:11,520 --> 00:07:14,800
distributed applications

00:07:12,880 --> 00:07:16,000
you can implement using actors for

00:07:14,800 --> 00:07:19,360
example ray tune

00:07:16,000 --> 00:07:21,440
is primarily written with actors and it

00:07:19,360 --> 00:07:22,479
basically uses a this is a parameter

00:07:21,440 --> 00:07:25,280
server that is

00:07:22,479 --> 00:07:26,960
done written done using actors and also

00:07:25,280 --> 00:07:28,880
things like microservices type of

00:07:26,960 --> 00:07:31,280
applications can be written as

00:07:28,880 --> 00:07:33,360
actor for example race serve is written

00:07:31,280 --> 00:07:36,880
primarily by actors and there are also

00:07:33,360 --> 00:07:41,199
many other actor frameworks like akka or

00:07:36,880 --> 00:07:42,319
dapper so third ray is an ecosystem of

00:07:41,199 --> 00:07:44,240
libraries

00:07:42,319 --> 00:07:46,160
so ray is a framework for distributed

00:07:44,240 --> 00:07:48,000
computing and it provides

00:07:46,160 --> 00:07:49,840
uh the primitives for distributed

00:07:48,000 --> 00:07:51,840
computing and took care of scheduling

00:07:49,840 --> 00:07:53,599
fault tolerance and arbuses for the

00:07:51,840 --> 00:07:55,280
libraries

00:07:53,599 --> 00:07:57,680
which allows you to write distributed

00:07:55,280 --> 00:07:59,440
applications of machine learning um life

00:07:57,680 --> 00:08:00,800
cycle end-to-end for example we have

00:07:59,440 --> 00:08:02,720
like a native libraries

00:08:00,800 --> 00:08:04,639
or some of our critical machine learning

00:08:02,720 --> 00:08:07,280
workloads and also many other

00:08:04,639 --> 00:08:10,400
third-party integrations all run while

00:08:07,280 --> 00:08:13,120
running a scale on top array

00:08:10,400 --> 00:08:14,000
already is also a highly performant

00:08:13,120 --> 00:08:16,639
system

00:08:14,000 --> 00:08:18,160
and it's written it's very scalable uh

00:08:16,639 --> 00:08:20,240
it's basically written

00:08:18,160 --> 00:08:21,599
uh it's python native but the core part

00:08:20,240 --> 00:08:24,240
is written in cyto

00:08:21,599 --> 00:08:25,360
as well as c plus plus so all the

00:08:24,240 --> 00:08:28,400
critical path is

00:08:25,360 --> 00:08:28,720
uh very fast and it's not um restricted

00:08:28,400 --> 00:08:31,120
by

00:08:28,720 --> 00:08:32,880
the global interpreter lock and it also

00:08:31,120 --> 00:08:35,839
has fast scheduling architecture

00:08:32,880 --> 00:08:36,320
so it has decentralized scheduler which

00:08:35,839 --> 00:08:38,399
means

00:08:36,320 --> 00:08:39,440
your scheduling performance is not going

00:08:38,399 --> 00:08:41,839
to be

00:08:39,440 --> 00:08:44,240
slow when you actually scale up it also

00:08:41,839 --> 00:08:46,080
has built-in distributed object store

00:08:44,240 --> 00:08:48,000
which has the shared memory and zero

00:08:46,080 --> 00:08:50,959
copyright optimization which means

00:08:48,000 --> 00:08:52,839
you can have much efficient memory usage

00:08:50,959 --> 00:08:55,120
when you're using

00:08:52,839 --> 00:08:56,640
raid well all these features

00:08:55,120 --> 00:08:59,120
clearly indicate ray can be a great

00:08:56,640 --> 00:08:59,440
solution as a general purpose system for

00:08:59,120 --> 00:09:02,399
this

00:08:59,440 --> 00:09:03,440
end-to-end ml life cycle so this is the

00:09:02,399 --> 00:09:06,160
same example but

00:09:03,440 --> 00:09:06,800
on top of ray so you can run ray and you

00:09:06,160 --> 00:09:09,360
can do

00:09:06,800 --> 00:09:10,800
um the etl job using spark on ray and

00:09:09,360 --> 00:09:13,519
you load and shuffle the

00:09:10,800 --> 00:09:13,920
data using ray ml data set apis and also

00:09:13,519 --> 00:09:15,920
you can

00:09:13,920 --> 00:09:17,440
training or you can train in using

00:09:15,920 --> 00:09:21,040
horror button ray and you can

00:09:17,440 --> 00:09:23,279
um tune the machine learning model using

00:09:21,040 --> 00:09:25,839
ray chin

00:09:23,279 --> 00:09:27,760
array was originally very ml focused but

00:09:25,839 --> 00:09:30,800
we've had drastic improvements

00:09:27,760 --> 00:09:32,560
over the over the last year and that's

00:09:30,800 --> 00:09:34,640
something i'm going to talk very soon

00:09:32,560 --> 00:09:36,560
but as a result we've been able to

00:09:34,640 --> 00:09:37,519
support many data processing third-party

00:09:36,560 --> 00:09:40,240
integrations

00:09:37,519 --> 00:09:41,279
on top of ray such as modin which is the

00:09:40,240 --> 00:09:43,440
um

00:09:41,279 --> 00:09:46,480
which is a distributed pandas and also

00:09:43,440 --> 00:09:48,720
desk on ray which is very useful for

00:09:46,480 --> 00:09:50,640
anyone who's using numpy and pandas and

00:09:48,720 --> 00:09:52,720
for other um

00:09:50,640 --> 00:09:55,680
famous data processing libraries like

00:09:52,720 --> 00:09:58,640
mars or spark

00:09:55,680 --> 00:10:00,320
so this is a typical example of you use

00:09:58,640 --> 00:10:04,160
all of the workload at the same place

00:10:00,320 --> 00:10:04,959
so in this case it uses spark on ray as

00:10:04,160 --> 00:10:07,600
well as the

00:10:04,959 --> 00:10:09,920
um twitch estimator so you can actually

00:10:07,600 --> 00:10:10,560
use the spark data create a spark data

00:10:09,920 --> 00:10:12,480
frame here

00:10:10,560 --> 00:10:13,839
and you can pass them to estimator and

00:10:12,480 --> 00:10:16,320
train here

00:10:13,839 --> 00:10:17,839
so this is a example of um running like

00:10:16,320 --> 00:10:19,680
a data processing workload and machine

00:10:17,839 --> 00:10:23,200
learning workflow with the same cluster

00:10:19,680 --> 00:10:24,959
yeah it's the same job uh before going

00:10:23,200 --> 00:10:26,079
to the next section let me explain how

00:10:24,959 --> 00:10:28,320
ray was last year

00:10:26,079 --> 00:10:29,279
ray was very ml focused and although he

00:10:28,320 --> 00:10:31,600
was really good at

00:10:29,279 --> 00:10:33,200
running ml workload um the data

00:10:31,600 --> 00:10:36,399
processing support wasn't

00:10:33,200 --> 00:10:38,640
robust enough because

00:10:36,399 --> 00:10:40,320
ray wasn't supporting some of important

00:10:38,640 --> 00:10:42,480
features to the

00:10:40,320 --> 00:10:43,839
great and robust data processing backend

00:10:42,480 --> 00:10:45,519
and this is something i'm going to cover

00:10:43,839 --> 00:10:49,440
from now on

00:10:45,519 --> 00:10:50,959
okay so let me first go through what

00:10:49,440 --> 00:10:53,040
types of data processing

00:10:50,959 --> 00:10:54,640
is out there uh firstly the most common

00:10:53,040 --> 00:10:56,880
data persisting workload is

00:10:54,640 --> 00:10:58,480
etl type of workload which basically

00:10:56,880 --> 00:11:00,480
extract information from

00:10:58,480 --> 00:11:01,519
some files and transform the data into

00:11:00,480 --> 00:11:04,560
different formats

00:11:01,519 --> 00:11:06,480
and load them into different files

00:11:04,560 --> 00:11:08,000
usually people write jobs that run over

00:11:06,480 --> 00:11:10,720
hours

00:11:08,000 --> 00:11:12,480
for etl type of workload another type of

00:11:10,720 --> 00:11:14,000
workload is the data in this type of

00:11:12,480 --> 00:11:16,000
workload so if you finish your

00:11:14,000 --> 00:11:17,760
etl job the result is written into some

00:11:16,000 --> 00:11:18,240
files and you need to ingest the data

00:11:17,760 --> 00:11:21,040
into

00:11:18,240 --> 00:11:22,320
ml clusters in order to train or do

00:11:21,040 --> 00:11:23,760
something else

00:11:22,320 --> 00:11:25,600
and there are also analytics type of

00:11:23,760 --> 00:11:28,240
data processing which is uh

00:11:25,600 --> 00:11:29,760
which heavily uses things like sql and

00:11:28,240 --> 00:11:32,000
it's usually used by

00:11:29,760 --> 00:11:33,839
people like data scientists and with

00:11:32,000 --> 00:11:35,600
things like jupiter notebook

00:11:33,839 --> 00:11:37,600
and there's also streaming processing

00:11:35,600 --> 00:11:40,079
which has pretty unique requirements

00:11:37,600 --> 00:11:40,800
and system specialized systems like

00:11:40,079 --> 00:11:44,399
flink

00:11:40,800 --> 00:11:44,399
is supporting streaming processing

00:11:44,720 --> 00:11:48,800
for ray we'd like to uh make sure they

00:11:47,200 --> 00:11:51,120
be the best choice for the

00:11:48,800 --> 00:11:52,720
end-to-end ml life cycle right now so in

00:11:51,120 --> 00:11:54,560
the short term we're going to focus on

00:11:52,720 --> 00:11:57,519
the top two workloads etl

00:11:54,560 --> 00:11:58,560
and also the data ingest which is uh

00:11:57,519 --> 00:12:00,880
pretty important for

00:11:58,560 --> 00:12:04,240
the ml life cycle as we as i described

00:12:00,880 --> 00:12:04,240
in the beginning of the presentation

00:12:04,560 --> 00:12:08,639
okay then let's actually think about

00:12:07,040 --> 00:12:11,200
what are important features data

00:12:08,639 --> 00:12:12,959
processing backend should have

00:12:11,200 --> 00:12:14,639
firstly it should support seminars

00:12:12,959 --> 00:12:16,480
distributed execution

00:12:14,639 --> 00:12:18,160
for example we should be able to run

00:12:16,480 --> 00:12:18,720
stateless functions in the distributed

00:12:18,160 --> 00:12:20,240
systems

00:12:18,720 --> 00:12:21,920
and it should handle what distributed

00:12:20,240 --> 00:12:23,600
systems should do

00:12:21,920 --> 00:12:25,760
for example issue scale should be

00:12:23,600 --> 00:12:28,000
faltering in component failures

00:12:25,760 --> 00:12:28,959
handling network operation as well as

00:12:28,000 --> 00:12:31,519
object transfer

00:12:28,959 --> 00:12:33,440
across machines or secondly it should

00:12:31,519 --> 00:12:34,240
support robust distributed memory

00:12:33,440 --> 00:12:36,480
management

00:12:34,240 --> 00:12:37,440
so it's not going to crash when you have

00:12:36,480 --> 00:12:39,680
all really

00:12:37,440 --> 00:12:41,360
large memory usage that is even bigger

00:12:39,680 --> 00:12:43,279
than the capacity of memory that your

00:12:41,360 --> 00:12:45,120
cluster has

00:12:43,279 --> 00:12:47,040
well then how did ray look like before

00:12:45,120 --> 00:12:50,000
uh it satisfied the first requirements

00:12:47,040 --> 00:12:52,720
but not the second one very well

00:12:50,000 --> 00:12:54,480
the ray is designed to be a very highly

00:12:52,720 --> 00:12:56,240
performant and general purpose

00:12:54,480 --> 00:12:57,920
and all of this thinness distributed

00:12:56,240 --> 00:13:00,320
execution as i explained before it

00:12:57,920 --> 00:13:02,240
supported very well

00:13:00,320 --> 00:13:03,680
whereas the robot's distributed memory

00:13:02,240 --> 00:13:05,600
management wasn't really not well

00:13:03,680 --> 00:13:06,240
sprayed for example the out of core

00:13:05,600 --> 00:13:08,800
processing

00:13:06,240 --> 00:13:10,480
wasn't possible previously and the

00:13:08,800 --> 00:13:11,200
scheduling didn't really respect the

00:13:10,480 --> 00:13:13,600
memory

00:13:11,200 --> 00:13:15,279
usage of each machine and it doesn't

00:13:13,600 --> 00:13:15,839
really do the locality or scheduling as

00:13:15,279 --> 00:13:17,680
well

00:13:15,839 --> 00:13:18,880
and there was no admission control

00:13:17,680 --> 00:13:22,639
respecting the hard

00:13:18,880 --> 00:13:22,639
memory limit for each machine

00:13:22,720 --> 00:13:26,320
well to make sure ray supports data

00:13:24,240 --> 00:13:28,000
processing uh we will need to make sure

00:13:26,320 --> 00:13:29,200
it has robust distributed memory

00:13:28,000 --> 00:13:30,560
management

00:13:29,200 --> 00:13:32,240
then i'm going to explain how we

00:13:30,560 --> 00:13:35,360
actually achieved it from now on

00:13:32,240 --> 00:13:37,200
so firstly what we try to do is to make

00:13:35,360 --> 00:13:40,800
sure the distributed shuffle

00:13:37,200 --> 00:13:42,480
works really well on top of braid

00:13:40,800 --> 00:13:44,240
well before we go dive into what we've

00:13:42,480 --> 00:13:45,680
done let me actually explain what is

00:13:44,240 --> 00:13:48,320
distributed shuffle

00:13:45,680 --> 00:13:49,680
um usually in distributed systems data

00:13:48,320 --> 00:13:51,600
set is partitioned

00:13:49,680 --> 00:13:53,680
or data set is usually stored in

00:13:51,600 --> 00:13:55,040
partitions with each partition holding a

00:13:53,680 --> 00:13:57,440
group of rows

00:13:55,040 --> 00:13:58,320
shuffle is basically the operation over

00:13:57,440 --> 00:14:00,399
the data set

00:13:58,320 --> 00:14:01,440
that redistributed data across these

00:14:00,399 --> 00:14:04,480
partitions

00:14:01,440 --> 00:14:06,160
it's pretty important operation for data

00:14:04,480 --> 00:14:08,399
processing because it is uh

00:14:06,160 --> 00:14:10,639
quite commonly used for many different

00:14:08,399 --> 00:14:12,639
distributed data processing algorithms

00:14:10,639 --> 00:14:14,880
like for example when you're running

00:14:12,639 --> 00:14:16,639
sort like distributed sort

00:14:14,880 --> 00:14:18,480
it requires you to run shuffle under the

00:14:16,639 --> 00:14:21,199
boot

00:14:18,480 --> 00:14:21,600
so this is a i this is this demonstrate

00:14:21,199 --> 00:14:23,519
uh

00:14:21,600 --> 00:14:25,680
actually how this works so usually it

00:14:23,519 --> 00:14:26,399
has two phase the map phase and reduce

00:14:25,680 --> 00:14:30,160
space

00:14:26,399 --> 00:14:31,360
and usually map phase create objects as

00:14:30,160 --> 00:14:32,880
you can see they are creating four

00:14:31,360 --> 00:14:34,320
different objects oh by the way you can

00:14:32,880 --> 00:14:37,519
think circle is a task

00:14:34,320 --> 00:14:38,480
ray test and square of square or ray

00:14:37,519 --> 00:14:40,639
objects

00:14:38,480 --> 00:14:42,079
and you can see each of the first object

00:14:40,639 --> 00:14:44,240
is going to the first produce

00:14:42,079 --> 00:14:45,440
the first object in this format goes to

00:14:44,240 --> 00:14:47,680
the first reduce

00:14:45,440 --> 00:14:48,720
and which means the objects are now

00:14:47,680 --> 00:14:51,120
redistributed

00:14:48,720 --> 00:14:52,399
in the reduced task so you can do some

00:14:51,120 --> 00:14:55,360
um different operation

00:14:52,399 --> 00:14:55,360
with the shuffle data

00:14:56,240 --> 00:14:59,680
so then why are we focused on supporting

00:14:58,320 --> 00:15:01,680
distributed shuffle

00:14:59,680 --> 00:15:04,560
yeah uh it is because distributed

00:15:01,680 --> 00:15:07,040
shuffle stresses data processing systems

00:15:04,560 --> 00:15:09,120
memory management layer very hard

00:15:07,040 --> 00:15:10,000
because it's because it requires a lot

00:15:09,120 --> 00:15:12,800
of transfer of

00:15:10,000 --> 00:15:14,480
objects between task desectors as you

00:15:12,800 --> 00:15:16,000
can see every object has to be

00:15:14,480 --> 00:15:16,560
transferred to different reducers

00:15:16,000 --> 00:15:18,240
meaning

00:15:16,560 --> 00:15:20,480
there's going to be a lot of object

00:15:18,240 --> 00:15:23,360
transfer

00:15:20,480 --> 00:15:23,920
and usually the size of data is a way

00:15:23,360 --> 00:15:26,320
larger

00:15:23,920 --> 00:15:27,040
than the memory capacity of your cluster

00:15:26,320 --> 00:15:28,720
meaning

00:15:27,040 --> 00:15:30,160
you have to support auto core data

00:15:28,720 --> 00:15:32,800
processing to support

00:15:30,160 --> 00:15:34,639
a distributed shuffle robustly it's also

00:15:32,800 --> 00:15:35,360
very easy to test because we can easily

00:15:34,639 --> 00:15:37,519
scale it up

00:15:35,360 --> 00:15:39,279
for example we can try from like one

00:15:37,519 --> 00:15:42,000
gigabyte 10 gigabyte with

00:15:39,279 --> 00:15:44,639
a less number of partitions but in this

00:15:42,000 --> 00:15:48,000
case there are four partitions

00:15:44,639 --> 00:15:50,480
uh and you can easily scale up to like

00:15:48,000 --> 00:15:52,720
one terabyte ten terabyte hundred tribe

00:15:50,480 --> 00:15:54,240
with thousands of partitions later to

00:15:52,720 --> 00:15:58,240
actually stress your system

00:15:54,240 --> 00:15:59,279
to the end so last year ray couldn't

00:15:58,240 --> 00:16:02,399
really handle heavy

00:15:59,279 --> 00:16:04,480
distribution shuffle workload and

00:16:02,399 --> 00:16:05,680
but we have made a lot of improvements

00:16:04,480 --> 00:16:06,959
over the year

00:16:05,680 --> 00:16:08,800
and that's something i'm going to

00:16:06,959 --> 00:16:10,959
explain from now on

00:16:08,800 --> 00:16:13,440
um the first improvement we've made over

00:16:10,959 --> 00:16:15,920
the year is the scheduling improvement

00:16:13,440 --> 00:16:18,079
so previously ray didn't have locality

00:16:15,920 --> 00:16:22,720
over scheduling as well as memory or

00:16:18,079 --> 00:16:24,720
scheduling so previously um

00:16:22,720 --> 00:16:25,839
ray didn't really respect memory usage

00:16:24,720 --> 00:16:29,040
at each machine

00:16:25,839 --> 00:16:30,720
but now what it happens is it basically

00:16:29,040 --> 00:16:33,120
knows how much memory is used per

00:16:30,720 --> 00:16:35,360
machine and it basically prefers to be

00:16:33,120 --> 00:16:38,720
scheduled to the machine that uses low

00:16:35,360 --> 00:16:39,040
memory another optimization we've made

00:16:38,720 --> 00:16:40,720
is

00:16:39,040 --> 00:16:42,399
called locality or scheduling so

00:16:40,720 --> 00:16:43,600
locality simply means when you're

00:16:42,399 --> 00:16:45,440
scheduling raid tasks

00:16:43,600 --> 00:16:47,040
you want to schedule on the machine that

00:16:45,440 --> 00:16:49,839
already has the objects

00:16:47,040 --> 00:16:51,759
that are needed for tasks and previously

00:16:49,839 --> 00:16:52,639
we don't do that and if we don't do that

00:16:51,759 --> 00:16:56,079
the problem is

00:16:52,639 --> 00:16:57,759
all of these objects have to be

00:16:56,079 --> 00:16:58,240
transferred and copied to the machines

00:16:57,759 --> 00:17:00,480
that

00:16:58,240 --> 00:17:01,440
schedule tests and this was very

00:17:00,480 --> 00:17:04,240
inefficient

00:17:01,440 --> 00:17:06,079
so now every task basically knows what

00:17:04,240 --> 00:17:06,720
kind of objects it requires and where

00:17:06,079 --> 00:17:09,120
they are

00:17:06,720 --> 00:17:10,959
so you can um actually do locality aware

00:17:09,120 --> 00:17:12,799
scheduling and schedule on the machines

00:17:10,959 --> 00:17:15,839
they already have the best number

00:17:12,799 --> 00:17:18,720
the largest number of um object size

00:17:15,839 --> 00:17:19,360
for the task and this will eventually

00:17:18,720 --> 00:17:22,400
minimize

00:17:19,360 --> 00:17:25,679
objects or copied across the

00:17:22,400 --> 00:17:27,760
different machines well the second

00:17:25,679 --> 00:17:30,799
improvement we've made is

00:17:27,760 --> 00:17:32,720
to enable out of core processing

00:17:30,799 --> 00:17:34,799
oh so we basically implemented something

00:17:32,720 --> 00:17:37,200
called object spelling which spills ray

00:17:34,799 --> 00:17:39,200
objects from object store raise built-in

00:17:37,200 --> 00:17:42,480
object store to external storage

00:17:39,200 --> 00:17:44,480
like disks or s3

00:17:42,480 --> 00:17:46,400
this is very critical for supporting

00:17:44,480 --> 00:17:49,039
distributed software cloud because

00:17:46,400 --> 00:17:50,400
distributed shuffle usually has uh more

00:17:49,039 --> 00:17:52,559
data size than the

00:17:50,400 --> 00:17:55,360
maximum capacity of memory so we usually

00:17:52,559 --> 00:17:57,520
have to rely on external storages

00:17:55,360 --> 00:18:00,400
oh and i'm going to explain how object

00:17:57,520 --> 00:18:02,240
spilling works on top of ray from now on

00:18:00,400 --> 00:18:04,400
so this is an example where software is

00:18:02,240 --> 00:18:07,760
running without object spilling

00:18:04,400 --> 00:18:09,840
so let's see from the map phase first

00:18:07,760 --> 00:18:12,160
so in the map phase basically this

00:18:09,840 --> 00:18:14,880
square big square is a worker

00:18:12,160 --> 00:18:16,480
and this circle is a task so these two

00:18:14,880 --> 00:18:18,880
map tasks are scheduled

00:18:16,480 --> 00:18:19,679
and they're creating objects for like

00:18:18,880 --> 00:18:22,720
this to the

00:18:19,679 --> 00:18:24,480
uh object store

00:18:22,720 --> 00:18:25,919
and in the reduced phase you basically

00:18:24,480 --> 00:18:28,160
want to redistribute

00:18:25,919 --> 00:18:28,960
so this reduced tasks are scheduled and

00:18:28,160 --> 00:18:31,280
you can see

00:18:28,960 --> 00:18:33,039
the first square in the first snap test

00:18:31,280 --> 00:18:33,600
and the first pair in the second map

00:18:33,039 --> 00:18:36,799
test

00:18:33,600 --> 00:18:38,400
is going to be um gotten by the first

00:18:36,799 --> 00:18:40,880
reduce test you can see

00:18:38,400 --> 00:18:43,200
this light blue and light purple is

00:18:40,880 --> 00:18:44,559
obtained by this reduced test meaning

00:18:43,200 --> 00:18:48,240
now this reduced task

00:18:44,559 --> 00:18:49,760
can do some operation with shuffle data

00:18:48,240 --> 00:18:52,720
oh then how they work when object

00:18:49,760 --> 00:18:55,760
splitting is required

00:18:52,720 --> 00:18:57,440
let me start from the map phase

00:18:55,760 --> 00:18:59,039
note that this is the same as this

00:18:57,440 --> 00:19:01,360
progress

00:18:59,039 --> 00:19:02,559
but it requires object spelling as well

00:19:01,360 --> 00:19:05,840
as other more map

00:19:02,559 --> 00:19:08,000
tasks so the difference is we have

00:19:05,840 --> 00:19:09,679
external storage here

00:19:08,000 --> 00:19:12,799
so now these two tasks are scheduled

00:19:09,679 --> 00:19:14,799
first and they create objects

00:19:12,799 --> 00:19:17,280
and now new task has to be scheduled and

00:19:14,799 --> 00:19:18,880
you just realize this needs to create a

00:19:17,280 --> 00:19:21,679
more object but there's no

00:19:18,880 --> 00:19:24,000
capacity in memory so what ray is doing

00:19:21,679 --> 00:19:26,960
is it smartly chooses objective spill

00:19:24,000 --> 00:19:28,799
and it spills them to the external

00:19:26,960 --> 00:19:30,640
storage so it's going to make space to

00:19:28,799 --> 00:19:33,440
create objects for

00:19:30,640 --> 00:19:36,400
this task and it just repeats until

00:19:33,440 --> 00:19:37,679
every objects are created

00:19:36,400 --> 00:19:40,160
oh then what's going to happen in the

00:19:37,679 --> 00:19:41,120
radio space note this is the same

00:19:40,160 --> 00:19:44,320
process as

00:19:41,120 --> 00:19:48,160
this reduce phase and we just

00:19:44,320 --> 00:19:51,039
same we have more tasks here

00:19:48,160 --> 00:19:51,520
so first um this is the state after all

00:19:51,039 --> 00:19:54,320
the

00:19:51,520 --> 00:19:56,480
mapper map phase is done so now to

00:19:54,320 --> 00:19:58,000
reduce tester schedule and you realize

00:19:56,480 --> 00:20:01,039
this needs speeds for

00:19:58,000 --> 00:20:03,600
objects and this black task needs these

00:20:01,039 --> 00:20:04,720
like a thick four color objects that are

00:20:03,600 --> 00:20:07,039
shuffled

00:20:04,720 --> 00:20:08,799
so the first thing is it has to restore

00:20:07,039 --> 00:20:09,760
the object from the external storage

00:20:08,799 --> 00:20:13,039
into memory

00:20:09,760 --> 00:20:15,039
so this test can access so ray smartly

00:20:13,039 --> 00:20:16,400
chooses which objects are not needed

00:20:15,039 --> 00:20:18,320
anymore from

00:20:16,400 --> 00:20:19,440
the shared memory object store and it

00:20:18,320 --> 00:20:22,640
spills to the

00:20:19,440 --> 00:20:25,919
disk first and now

00:20:22,640 --> 00:20:28,159
in the um in the empty slot it basically

00:20:25,919 --> 00:20:30,559
restores the objects properly

00:20:28,159 --> 00:20:31,440
so that you can actually schedule tasks

00:20:30,559 --> 00:20:34,320
um

00:20:31,440 --> 00:20:35,520
better in the external storage so you

00:20:34,320 --> 00:20:38,880
can't you just realize

00:20:35,520 --> 00:20:40,720
all of the objects are ready here and

00:20:38,880 --> 00:20:42,960
basically repeat until every tasks are

00:20:40,720 --> 00:20:42,960
done

00:20:43,120 --> 00:20:47,679
so the last improvement i'll demonstrate

00:20:45,440 --> 00:20:48,720
is how we improved our memory management

00:20:47,679 --> 00:20:52,640
layer

00:20:48,720 --> 00:20:55,120
um in summary ray respects a hard limit

00:20:52,640 --> 00:20:55,840
for the distributed object store so what

00:20:55,120 --> 00:20:58,799
does that mean

00:20:55,840 --> 00:20:59,840
there are three things that basically we

00:20:58,799 --> 00:21:01,840
implemented

00:20:59,840 --> 00:21:04,080
oh the first thing is it detects when

00:21:01,840 --> 00:21:06,640
there is the memory pressure

00:21:04,080 --> 00:21:08,640
and also it guarantees the progress when

00:21:06,640 --> 00:21:11,280
applications run out of memory

00:21:08,640 --> 00:21:13,360
by taking the proper actions for example

00:21:11,280 --> 00:21:14,640
oh the test has to be scheduled and it

00:21:13,360 --> 00:21:17,600
needs to

00:21:14,640 --> 00:21:19,360
have some number of objects that are uh

00:21:17,600 --> 00:21:21,600
they have to fit into the memory

00:21:19,360 --> 00:21:22,400
then it properly affects unnecessary

00:21:21,600 --> 00:21:24,559
objects

00:21:22,400 --> 00:21:26,320
or spelling objects with the right

00:21:24,559 --> 00:21:29,360
priority so it's going to make

00:21:26,320 --> 00:21:31,440
space always so that all the tasks

00:21:29,360 --> 00:21:33,360
uh in the system can actually be in

00:21:31,440 --> 00:21:36,400
progress

00:21:33,360 --> 00:21:38,159
and lastly it also we also implemented

00:21:36,400 --> 00:21:40,480
admission control when scheduling

00:21:38,159 --> 00:21:41,200
tasks so that it actually um respects

00:21:40,480 --> 00:21:44,880
the total

00:21:41,200 --> 00:21:45,679
uh limit but so to limit the total

00:21:44,880 --> 00:21:47,679
memory used

00:21:45,679 --> 00:21:50,320
so it doesn't schedule a task if you

00:21:47,679 --> 00:21:53,760
realize if the test uses more memory

00:21:50,320 --> 00:21:56,320
uh than the capacity of the memory

00:21:53,760 --> 00:21:58,799
and i'm going to demonstrate on how the

00:21:56,320 --> 00:22:00,960
last part is working

00:21:58,799 --> 00:22:03,440
so this is the state after the map phase

00:22:00,960 --> 00:22:06,400
is done and as you can see these two

00:22:03,440 --> 00:22:06,880
reduce task is going to be scheduled

00:22:06,400 --> 00:22:08,720
notes

00:22:06,880 --> 00:22:11,360
so it has enough cpus you know as you

00:22:08,720 --> 00:22:15,280
can see um these two tests are now cute

00:22:11,360 --> 00:22:15,280
and this top and bottom is now scheduled

00:22:16,880 --> 00:22:22,159
um so we can we know these eight objects

00:22:21,440 --> 00:22:25,679
are

00:22:22,159 --> 00:22:28,240
on an object needs to be restored into

00:22:25,679 --> 00:22:29,360
the objects but you notice that there

00:22:28,240 --> 00:22:31,440
are only six slots

00:22:29,360 --> 00:22:33,120
so there are eight objects only six

00:22:31,440 --> 00:22:33,679
slots meaning you're not able to

00:22:33,120 --> 00:22:36,080
actually

00:22:33,679 --> 00:22:37,280
uh fit all of the object to the memory

00:22:36,080 --> 00:22:38,320
well let's see what's going to happen in

00:22:37,280 --> 00:22:40,480
this case

00:22:38,320 --> 00:22:42,720
we're trying to retrieve object for each

00:22:40,480 --> 00:22:44,880
task repeat repeat

00:22:42,720 --> 00:22:46,000
and you realize the last object that is

00:22:44,880 --> 00:22:48,640
required for each task

00:22:46,000 --> 00:22:50,080
is cannot be fit into the memory meaning

00:22:48,640 --> 00:22:53,600
both subtests cannot

00:22:50,080 --> 00:22:56,159
be in progress but there's that one

00:22:53,600 --> 00:22:57,360
and another problem that this kind of

00:22:56,159 --> 00:23:00,559
workload can have

00:22:57,360 --> 00:23:01,840
is if you uh for example spill this two

00:23:00,559 --> 00:23:04,000
green again

00:23:01,840 --> 00:23:05,679
and restore these two orange again

00:23:04,000 --> 00:23:09,200
you're still not in progress

00:23:05,679 --> 00:23:11,120
because each task needs four objects

00:23:09,200 --> 00:23:12,960
that are needed for each task to be in

00:23:11,120 --> 00:23:15,600
memory but it never been there

00:23:12,960 --> 00:23:17,600
so use this happens again and again so

00:23:15,600 --> 00:23:19,280
it basically spills again restore again

00:23:17,600 --> 00:23:21,360
spills again restores again

00:23:19,280 --> 00:23:23,520
until there happen to be four objects

00:23:21,360 --> 00:23:24,480
for this task to be available in this

00:23:23,520 --> 00:23:27,600
memory and

00:23:24,480 --> 00:23:29,440
that's very inefficient so how did you

00:23:27,600 --> 00:23:31,919
solve the problem

00:23:29,440 --> 00:23:33,600
now ray has decentralized schedule ray

00:23:31,919 --> 00:23:37,039
decentralized scheduler is also

00:23:33,600 --> 00:23:39,039
decentralized memory manager

00:23:37,039 --> 00:23:41,120
and ray doesn't schedule tasks if the

00:23:39,039 --> 00:23:42,799
task input requires more memory than its

00:23:41,120 --> 00:23:44,880
capacity after it's scheduled

00:23:42,799 --> 00:23:46,000
so let's see what that means with real

00:23:44,880 --> 00:23:48,159
example so

00:23:46,000 --> 00:23:49,919
previously we just trying to restore

00:23:48,159 --> 00:23:51,120
objects for each task but now ray

00:23:49,919 --> 00:23:54,159
smartly knows that

00:23:51,120 --> 00:23:55,679
um you can if they put objects for both

00:23:54,159 --> 00:23:56,640
tests at the same time it's going to be

00:23:55,679 --> 00:23:58,320
out of capacity

00:23:56,640 --> 00:24:01,360
so basically trying to restore object

00:23:58,320 --> 00:24:03,200
for the first task first

00:24:01,360 --> 00:24:05,440
and then the first test is done and it

00:24:03,200 --> 00:24:08,080
knows that on the second task

00:24:05,440 --> 00:24:09,600
means these four objects and the first

00:24:08,080 --> 00:24:11,200
newly scheduled task

00:24:09,600 --> 00:24:13,360
cannot have objects at the same time

00:24:11,200 --> 00:24:15,760
because it also requires four objects

00:24:13,360 --> 00:24:19,840
so it only restore object for the second

00:24:15,760 --> 00:24:19,840
task and repeat

00:24:20,080 --> 00:24:24,320
yeah so for more detailed information so

00:24:22,320 --> 00:24:26,159
we didn't we didn't cover

00:24:24,320 --> 00:24:27,679
every detail about how this is

00:24:26,159 --> 00:24:29,279
implemented so if you're

00:24:27,679 --> 00:24:31,039
interested in more detailed um

00:24:29,279 --> 00:24:34,240
implementation information

00:24:31,039 --> 00:24:36,559
check out our white paper

00:24:34,240 --> 00:24:38,480
so after this improvement now ray is

00:24:36,559 --> 00:24:40,080
supporting both requirements to be a

00:24:38,480 --> 00:24:42,080
robust data processing backend the

00:24:40,080 --> 00:24:44,320
simplest distributed execution as well

00:24:42,080 --> 00:24:46,880
as robust distributed memory management

00:24:44,320 --> 00:24:49,200
as a result we could support uh many

00:24:46,880 --> 00:24:51,279
third-party integration very well and we

00:24:49,200 --> 00:24:53,600
we've actually seen many positive uh

00:24:51,279 --> 00:24:55,440
benchmark results from these libraries

00:24:53,600 --> 00:24:57,679
and also we recently succeeded to run

00:24:55,440 --> 00:24:58,720
900 tribe distribution of workload on

00:24:57,679 --> 00:25:00,080
top of break

00:24:58,720 --> 00:25:02,320
and we are also going to further

00:25:00,080 --> 00:25:04,240
investigate to improve the performance

00:25:02,320 --> 00:25:04,720
as well as reliability of systems when

00:25:04,240 --> 00:25:07,679
running

00:25:04,720 --> 00:25:09,360
a very stressful software workload okay

00:25:07,679 --> 00:25:11,200
thank you so much it was a real pleasure

00:25:09,360 --> 00:25:13,520
having a chance to present pycon

00:25:11,200 --> 00:25:15,760
uh if you're interested in ray please

00:25:13,520 --> 00:25:17,840
visit our github page and give a star or

00:25:15,760 --> 00:25:18,720
visit the raid discourse for asking

00:25:17,840 --> 00:25:20,159
questions

00:25:18,720 --> 00:25:21,919
and also there's going to be race coming

00:25:20,159 --> 00:25:23,679
next month which is free

00:25:21,919 --> 00:25:25,120
so please join resume if you're

00:25:23,679 --> 00:25:26,880
interested in ray

00:25:25,120 --> 00:25:28,480
and if you're interested in any scale

00:25:26,880 --> 00:25:30,000
which is the company that's backing ray

00:25:28,480 --> 00:25:43,840
we are hiring right now

00:25:30,000 --> 00:25:43,840
okay thank you so much

00:26:36,559 --> 00:26:38,640

YouTube URL: https://www.youtube.com/watch?v=DNLqvdov_J4


