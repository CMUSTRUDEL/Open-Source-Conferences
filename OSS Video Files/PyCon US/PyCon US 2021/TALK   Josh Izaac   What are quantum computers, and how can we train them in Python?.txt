Title: TALK   Josh Izaac   What are quantum computers, and how can we train them in Python?
Publication date: 2021-05-30
Playlist: PyCon US 2021
Description: 
	“Let me just go run this on my quantum computer.”

Quantum computers aren’t what-ifs anymore — they are available now, and publicly accessible over the internet. And Python is rapidly becoming the language of choice for accessing and programming quantum computers, with Python SDKs available from Google (Cirq), IBM (Qiskit), and others. However, early quantum computers are small, noisy, and error prone. Simultaneously, it has never been easier to perform differentiable programming in Python; simply swap out NumPy for TensorFlow, PyTorch, or JAX, and you have the ability to differentiate and train the program itself.

So what would happen if we attempted to combine the two?

Using a mixture of real Python examples and illustrated diagrams, we show how to not only evaluate, but also differentiate small quantum programs directly on quantum hardware. By extracting the gradients, we can integrate these quantum programs directly into larger differentiable programs in Python, and train/optimize the full (hybrid quantum-classical!) program. Over the course of this talk, quantum-curious Python developers will see first-hand how quantum programming looks in Python, and get an idea of how (and when) it makes sense to take advantage of these novel hardware devices.

Slides: https://iza.ac/pdf/pycon2021.pdf
Captions: 
	00:00:04,170 --> 00:00:11,869
[Music]

00:00:15,599 --> 00:00:19,680
hello pycon 2021

00:00:17,520 --> 00:00:21,199
my name is josh and today i'm going to

00:00:19,680 --> 00:00:23,119
talk about quantum computing from a

00:00:21,199 --> 00:00:25,199
python perspective

00:00:23,119 --> 00:00:26,560
quantum computers aren't hypothetical

00:00:25,199 --> 00:00:28,720
and they aren't spooky

00:00:26,560 --> 00:00:31,519
they're available today in various forms

00:00:28,720 --> 00:00:33,680
and easily accessible via python

00:00:31,519 --> 00:00:35,360
now i'm really really lucky in that

00:00:33,680 --> 00:00:36,000
quantum computing in python is my day

00:00:35,360 --> 00:00:38,000
job

00:00:36,000 --> 00:00:39,920
i work at xanadu a canadian based

00:00:38,000 --> 00:00:41,440
quantum computing hardware company

00:00:39,920 --> 00:00:43,680
where i help to build open source

00:00:41,440 --> 00:00:45,920
quantum software including the open

00:00:43,680 --> 00:00:47,360
source quantum framework and event

00:00:45,920 --> 00:00:49,120
if you want to stay in touch after this

00:00:47,360 --> 00:00:51,199
talk i'm active on twitter

00:00:49,120 --> 00:00:52,559
my twitter account is third quantization

00:00:51,199 --> 00:00:55,120
feel free to send through any questions

00:00:52,559 --> 00:00:55,120
you might have

00:00:55,280 --> 00:00:58,160
in this talk i want to do something a

00:00:56,960 --> 00:00:59,520
little different to most talks on

00:00:58,160 --> 00:01:01,120
quantum computing

00:00:59,520 --> 00:01:03,359
rather than delve deeply into what

00:01:01,120 --> 00:01:04,879
quantum key views are and how they work

00:01:03,359 --> 00:01:06,400
let's go straight into the code and see

00:01:04,879 --> 00:01:08,159
what it looks like

00:01:06,400 --> 00:01:09,600
so hopefully by the end of this talk

00:01:08,159 --> 00:01:11,439
you'll have an idea

00:01:09,600 --> 00:01:13,119
of what quantum programming means and

00:01:11,439 --> 00:01:14,159
what quantum programming looks like in

00:01:13,119 --> 00:01:16,000
python

00:01:14,159 --> 00:01:18,080
the current states of quantum hardware

00:01:16,000 --> 00:01:20,000
and when it makes sense to use them

00:01:18,080 --> 00:01:21,280
and finally how we can train quantum

00:01:20,000 --> 00:01:27,840
hardware using the rich

00:01:21,280 --> 00:01:27,840
python machine learning ecosystem

00:01:28,799 --> 00:01:33,600
firstly what are quantum computers now

00:01:32,079 --> 00:01:35,520
i know i said we would go straight into

00:01:33,600 --> 00:01:37,520
the code but with quantum compute

00:01:35,520 --> 00:01:39,520
currently holding such a mystical or

00:01:37,520 --> 00:01:41,920
there is no avoiding briefly mentioning

00:01:39,520 --> 00:01:43,759
what quantum computers are

00:01:41,920 --> 00:01:45,360
so quantum computers are programmable

00:01:43,759 --> 00:01:47,119
computers that harness subatomic

00:01:45,360 --> 00:01:49,759
particles to store data and perform

00:01:47,119 --> 00:01:51,040
computations

00:01:49,759 --> 00:01:52,479
and i just want to emphasize that there

00:01:51,040 --> 00:01:53,439
is no one way to build a quantum

00:01:52,479 --> 00:01:54,960
computer

00:01:53,439 --> 00:01:56,799
quantum computers have been built using

00:01:54,960 --> 00:02:00,000
superconducting electric circuits

00:01:56,799 --> 00:02:02,399
lasers photonics molecules atoms

00:02:00,000 --> 00:02:04,240
and various other approaches any

00:02:02,399 --> 00:02:04,880
subatomic system where you can control

00:02:04,240 --> 00:02:06,479
the energy

00:02:04,880 --> 00:02:09,840
and perform measurement readout is

00:02:06,479 --> 00:02:09,840
potentially suitable

00:02:10,560 --> 00:02:14,239
now compared to classical computers

00:02:12,879 --> 00:02:15,840
quantum computers are able to take

00:02:14,239 --> 00:02:17,520
advantage of quantum properties such as

00:02:15,840 --> 00:02:19,599
entanglement and superposition

00:02:17,520 --> 00:02:23,840
to allow computation in an exceptionally

00:02:19,599 --> 00:02:23,840
large computational space

00:02:24,160 --> 00:02:28,080
and the quantum computers that are

00:02:26,160 --> 00:02:28,640
available today are near-term quantum

00:02:28,080 --> 00:02:32,239
computers

00:02:28,640 --> 00:02:33,920
and these are very specialized devices

00:02:32,239 --> 00:02:36,800
in particular the near-term quantum

00:02:33,920 --> 00:02:38,400
devices that we have are small

00:02:36,800 --> 00:02:41,040
they have a small number of qubits which

00:02:38,400 --> 00:02:43,680
are the quantum resource equivalent to

00:02:41,040 --> 00:02:44,879
classical bits and in addition to that

00:02:43,680 --> 00:02:47,280
they're quite noisy

00:02:44,879 --> 00:02:50,560
so errors tend to propagate throughout

00:02:47,280 --> 00:02:51,840
the computation

00:02:50,560 --> 00:02:53,360
now there is a lot of hype and

00:02:51,840 --> 00:02:54,319
misinformation surrounding quantum

00:02:53,360 --> 00:02:55,920
computing

00:02:54,319 --> 00:02:57,440
such as the misconception that quantum

00:02:55,920 --> 00:02:58,720
computers automatically perform

00:02:57,440 --> 00:03:00,400
parallelization

00:02:58,720 --> 00:03:02,239
or that they enable a speed up in all

00:03:00,400 --> 00:03:04,080
cases

00:03:02,239 --> 00:03:05,360
in fact quantum computers are highly

00:03:04,080 --> 00:03:07,280
specialized devices

00:03:05,360 --> 00:03:08,400
and will likely not replace cpus and

00:03:07,280 --> 00:03:11,920
gpus anytime

00:03:08,400 --> 00:03:14,000
soon you can almost think of near-term

00:03:11,920 --> 00:03:16,560
quantum computers as accelerators

00:03:14,000 --> 00:03:19,360
akin to gpus for specific tasks rather

00:03:16,560 --> 00:03:21,040
than general purpose computing devices

00:03:19,360 --> 00:03:22,640
it is very difficult to harness quantum

00:03:21,040 --> 00:03:25,280
superposition and entanglement to

00:03:22,640 --> 00:03:27,680
achieve speedups for all applications

00:03:25,280 --> 00:03:29,120
instead there are specific algorithms

00:03:27,680 --> 00:03:30,159
that are exceptionally hard to do

00:03:29,120 --> 00:03:32,560
classified

00:03:30,159 --> 00:03:36,159
like factoring integers that we can do

00:03:32,560 --> 00:03:38,159
exponentially faster on quantum devices

00:03:36,159 --> 00:03:40,480
so almost in the way that you use gpus

00:03:38,159 --> 00:03:42,000
today we know that gpus are very very

00:03:40,480 --> 00:03:45,440
good for parallelizing

00:03:42,000 --> 00:03:47,440
lots of small matrix multiplications

00:03:45,440 --> 00:03:49,760
so we harness gpus for that specific

00:03:47,440 --> 00:03:52,640
task and continue to use cpus for other

00:03:49,760 --> 00:03:52,640
more general tasks

00:03:52,720 --> 00:03:56,400
so instead of focusing on superposition

00:03:54,959 --> 00:03:58,159
and entanglement

00:03:56,400 --> 00:04:02,000
it is more useful to think of dear term

00:03:58,159 --> 00:04:05,120
quantum devices oh mrs black boxes

00:04:02,000 --> 00:04:07,280
and these black boxes are very very good

00:04:05,120 --> 00:04:08,640
at performing matrix multiplication in

00:04:07,280 --> 00:04:11,760
an exponentially large

00:04:08,640 --> 00:04:13,280
vector space so given the same amount of

00:04:11,760 --> 00:04:15,120
resources we might have on the small

00:04:13,280 --> 00:04:17,519
quantum device as compared to a

00:04:15,120 --> 00:04:18,959
classical device the size of the matrix

00:04:17,519 --> 00:04:23,040
multiplication we can perform on the

00:04:18,959 --> 00:04:23,040
quantum device is exponentially larger

00:04:26,160 --> 00:04:29,600
however we can't access this high

00:04:28,720 --> 00:04:31,280
dimensional

00:04:29,600 --> 00:04:32,639
vector space where this large matrix

00:04:31,280 --> 00:04:34,560
multiplication is taking place

00:04:32,639 --> 00:04:35,919
so that's one of the drawbacks that many

00:04:34,560 --> 00:04:38,240
people aren't aware of when it comes to

00:04:35,919 --> 00:04:39,759
quantum computing

00:04:38,240 --> 00:04:43,520
while we are performing these high

00:04:39,759 --> 00:04:45,600
dimensional matrix multiplications

00:04:43,520 --> 00:04:47,199
the best we can do is we can sample from

00:04:45,600 --> 00:04:48,800
this high dimensional space and we can

00:04:47,199 --> 00:04:50,080
extract measurement statistics from the

00:04:48,800 --> 00:04:51,680
space

00:04:50,080 --> 00:04:53,120
so that's what we do with these near

00:04:51,680 --> 00:04:54,880
term quantum devices

00:04:53,120 --> 00:04:56,800
we perform measurements and we extract

00:04:54,880 --> 00:04:58,880
classical data from the black box

00:04:56,800 --> 00:05:02,080
and essentially our sampling from these

00:04:58,880 --> 00:05:02,080
very large vector spaces

00:05:03,120 --> 00:05:06,160
before we move on i just want to quickly

00:05:04,800 --> 00:05:06,639
elaborate on something i mentioned

00:05:06,160 --> 00:05:08,479
earlier

00:05:06,639 --> 00:05:10,880
about quantum computers being available

00:05:08,479 --> 00:05:12,720
now and being publicly accessible

00:05:10,880 --> 00:05:14,320
so over the past five to ten years

00:05:12,720 --> 00:05:14,800
there's been a huge amount of progress

00:05:14,320 --> 00:05:17,600
in both

00:05:14,800 --> 00:05:18,639
academic research groups and companies

00:05:17,600 --> 00:05:21,199
in building out

00:05:18,639 --> 00:05:22,800
quantum devices while the progress has

00:05:21,199 --> 00:05:25,280
been staggering there's still a large

00:05:22,800 --> 00:05:27,360
amount of operational restrictions

00:05:25,280 --> 00:05:29,039
so for instance devices that use

00:05:27,360 --> 00:05:30,080
superconducting electric circuits for

00:05:29,039 --> 00:05:32,000
their computation

00:05:30,080 --> 00:05:33,680
require ultra-low temperatures to

00:05:32,000 --> 00:05:35,360
operate

00:05:33,680 --> 00:05:36,800
so while it's not currently feasible to

00:05:35,360 --> 00:05:37,520
have a quantum computer installed in

00:05:36,800 --> 00:05:40,000
your home

00:05:37,520 --> 00:05:40,800
or your office these quantum computers

00:05:40,000 --> 00:05:42,240
are available

00:05:40,800 --> 00:05:43,840
and they're available and accessible

00:05:42,240 --> 00:05:46,000
over the internet

00:05:43,840 --> 00:05:48,479
so anyone working on their laptop or

00:05:46,000 --> 00:05:50,560
computer or mobile phone even

00:05:48,479 --> 00:05:51,840
can submit quantum algorithms to be run

00:05:50,560 --> 00:05:54,639
on these quantum devices and have the

00:05:51,840 --> 00:05:56,240
results returned to them over the cloud

00:05:54,639 --> 00:05:57,919
a cool side effect of this is that

00:05:56,240 --> 00:05:59,039
there's been an explosion in open source

00:05:57,919 --> 00:06:01,199
quantum software

00:05:59,039 --> 00:06:02,240
and python has really become the home of

00:06:01,199 --> 00:06:05,360
quantum computation

00:06:02,240 --> 00:06:07,280
in 2021 so

00:06:05,360 --> 00:06:09,199
alongside these quantum devices open

00:06:07,280 --> 00:06:10,080
source quantum frameworks available in

00:06:09,199 --> 00:06:13,840
python

00:06:10,080 --> 00:06:17,680
include penny lane

00:06:13,840 --> 00:06:21,840
kiskit by ibm amazon bracket

00:06:17,680 --> 00:06:21,840
and google circ amongst many others

00:06:24,639 --> 00:06:28,080
now that we know these quantum devices

00:06:26,400 --> 00:06:29,919
are accessible by python

00:06:28,080 --> 00:06:31,840
and in a very abstract sense we can

00:06:29,919 --> 00:06:34,080
treat these near-term quantum devices as

00:06:31,840 --> 00:06:36,479
black box matrix multiplication machines

00:06:34,080 --> 00:06:38,720
the new strategy starts to become clear

00:06:36,479 --> 00:06:41,120
let's build a quantum function in python

00:06:38,720 --> 00:06:42,639
that does the following three things so

00:06:41,120 --> 00:06:43,280
firstly it accepts floating point

00:06:42,639 --> 00:06:45,039
parameters

00:06:43,280 --> 00:06:46,800
and these can be manually inputted to

00:06:45,039 --> 00:06:48,400
the function or they could be the

00:06:46,800 --> 00:06:50,720
outputs of some previous computational

00:06:48,400 --> 00:06:50,720
step

00:06:52,080 --> 00:06:55,520
internally this quantum function will

00:06:53,759 --> 00:06:57,840
contain quantum instructions

00:06:55,520 --> 00:07:00,240
dependent on these input parameters that

00:06:57,840 --> 00:07:00,720
are executed on either a remote hardware

00:07:00,240 --> 00:07:04,400
device

00:07:00,720 --> 00:07:04,400
or perhaps a local simulator

00:07:04,479 --> 00:07:08,479
finally this quantum function will

00:07:06,080 --> 00:07:11,919
return measurement statistics

00:07:08,479 --> 00:07:15,120
so this quantum device will be measured

00:07:11,919 --> 00:07:16,960
providing some insight to the

00:07:15,120 --> 00:07:20,319
probability distribution of this large

00:07:16,960 --> 00:07:22,400
vector space and this will be returned

00:07:20,319 --> 00:07:24,479
so crucially this quantum function

00:07:22,400 --> 00:07:26,720
accepts floating point data

00:07:24,479 --> 00:07:28,720
and outputs floating point data this

00:07:26,720 --> 00:07:30,400
function is completely deterministic

00:07:28,720 --> 00:07:32,400
the output is fully determined by the

00:07:30,400 --> 00:07:33,919
input however internally

00:07:32,400 --> 00:07:36,240
we're able to take advantage of this

00:07:33,919 --> 00:07:40,000
very very large computational space

00:07:36,240 --> 00:07:42,720
accessible by these quantum devices

00:07:40,000 --> 00:07:44,479
and finally and this is my most uh the i

00:07:42,720 --> 00:07:46,000
find most exciting is that because we've

00:07:44,479 --> 00:07:47,360
chosen a function abstraction

00:07:46,000 --> 00:07:49,360
this quantum function is fully

00:07:47,360 --> 00:07:51,280
composable within any python pipeline

00:07:49,360 --> 00:07:52,479
so it integrates very very well with the

00:07:51,280 --> 00:07:58,160
very rich

00:07:52,479 --> 00:07:59,919
scientific piping ecosystem

00:07:58,160 --> 00:08:01,759
so now let's jump into the code and see

00:07:59,919 --> 00:08:05,280
what this parameterized quantum function

00:08:01,759 --> 00:08:06,800
looks like in practice in python

00:08:05,280 --> 00:08:09,039
so i'm going to drop into my terminal

00:08:06,800 --> 00:08:10,720
now and i'm going to be using the

00:08:09,039 --> 00:08:12,080
quantum framework penny lane to

00:08:10,720 --> 00:08:16,080
demonstrate this

00:08:12,080 --> 00:08:20,000
so to begin with import pennylane as qfl

00:08:16,080 --> 00:08:21,440
and we also want to import numpy as np

00:08:20,000 --> 00:08:27,440
so the first thing we want to do is we

00:08:21,440 --> 00:08:29,199
want to provision a quantum device

00:08:27,440 --> 00:08:30,639
so just two things to note here the

00:08:29,199 --> 00:08:31,520
first is that i'm provisioning a device

00:08:30,639 --> 00:08:35,599
that has

00:08:31,520 --> 00:08:37,519
two wires or two qubits this is just

00:08:35,599 --> 00:08:38,640
the size of the device that we're

00:08:37,519 --> 00:08:39,839
creating

00:08:38,640 --> 00:08:41,360
the other thing to note is that i'm

00:08:39,839 --> 00:08:43,200
using a default cuber which is a

00:08:41,360 --> 00:08:44,640
built-in simulator that comes along with

00:08:43,200 --> 00:08:46,240
penny lane and it's useful for rapid

00:08:44,640 --> 00:08:47,600
prototyping

00:08:46,240 --> 00:08:49,519
if you're following along and you'd like

00:08:47,600 --> 00:08:51,760
to use a real hardware device then

00:08:49,519 --> 00:08:52,640
uh definitely give it a go you just need

00:08:51,760 --> 00:08:54,320
to change this line

00:08:52,640 --> 00:08:56,399
instead of provisioning default keyword

00:08:54,320 --> 00:08:57,519
provision something from ibm queue and

00:08:56,399 --> 00:08:59,519
there's more information in the planning

00:08:57,519 --> 00:09:01,120
documentation

00:08:59,519 --> 00:09:03,519
so now we want to create our quantum

00:09:01,120 --> 00:09:04,000
function so to do that in any lane we

00:09:03,519 --> 00:09:06,480
use the

00:09:04,000 --> 00:09:08,240
qr.cuno decorator and this essentially

00:09:06,480 --> 00:09:10,000
says the following function is a quantum

00:09:08,240 --> 00:09:12,240
function that will be executed on this

00:09:10,000 --> 00:09:14,240
particular device

00:09:12,240 --> 00:09:16,959
and then the quantum function is just

00:09:14,240 --> 00:09:18,399
created like any other python function

00:09:16,959 --> 00:09:20,240
so i'll call it q func and it'll take

00:09:18,399 --> 00:09:21,839
some input analysis

00:09:20,240 --> 00:09:23,839
so within the quantum function this is

00:09:21,839 --> 00:09:25,519
where our quantum instructions come

00:09:23,839 --> 00:09:27,040
so i'll start off with my first quantum

00:09:25,519 --> 00:09:28,880
instruction which is

00:09:27,040 --> 00:09:30,800
uh well not to go into too much detail

00:09:28,880 --> 00:09:32,240
but just a rotation that's applied on

00:09:30,800 --> 00:09:34,080
the quantum device within this high

00:09:32,240 --> 00:09:36,720
dimensional subspace

00:09:34,080 --> 00:09:37,519
so this rotation will be dependent on

00:09:36,720 --> 00:09:39,600
the first

00:09:37,519 --> 00:09:41,120
element of my parenthesis and it will be

00:09:39,600 --> 00:09:43,440
applied to the first wire the first

00:09:41,120 --> 00:09:43,440
qubit

00:09:43,519 --> 00:09:48,560
i'll do another rotation this time using

00:09:46,240 --> 00:09:52,800
second parameter in our bronze array

00:09:48,560 --> 00:09:54,800
and finally i want to apply this is a

00:09:52,800 --> 00:09:56,720
non-parametrized quantum instruction

00:09:54,800 --> 00:09:59,360
uh what essentially does is it entangles

00:09:56,720 --> 00:10:00,560
our two qubits together

00:09:59,360 --> 00:10:02,160
so i've got a couple of quantum

00:10:00,560 --> 00:10:02,880
instructions now and what i want to do

00:10:02,160 --> 00:10:04,640
is i want to

00:10:02,880 --> 00:10:06,320
perform some measurement statistic on

00:10:04,640 --> 00:10:07,920
the quantum device to be able to extract

00:10:06,320 --> 00:10:09,360
some information as outputs of our

00:10:07,920 --> 00:10:12,640
quantum function

00:10:09,360 --> 00:10:14,480
so i will return in this particular case

00:10:12,640 --> 00:10:16,480
i'll return the probability of the

00:10:14,480 --> 00:10:19,519
quantum device

00:10:16,480 --> 00:10:20,959
over both wires

00:10:19,519 --> 00:10:23,760
and there we go that's our quantum

00:10:20,959 --> 00:10:24,720
function so let's create some initial

00:10:23,760 --> 00:10:28,880
parameters

00:10:24,720 --> 00:10:28,880
to evaluate its quantum function with

00:10:30,839 --> 00:10:36,240
and it's evaluating

00:10:34,480 --> 00:10:39,120
there you go we've got a function that

00:10:36,240 --> 00:10:41,040
takes a numpy array of size two

00:10:39,120 --> 00:10:43,120
and it outputs another array of size

00:10:41,040 --> 00:10:44,959
four and these are the probabilities

00:10:43,120 --> 00:10:46,880
of our qubit system of our cube of our

00:10:44,959 --> 00:10:49,680
quantum device after we applied these

00:10:46,880 --> 00:10:52,480
parametrized quantum instructions

00:10:49,680 --> 00:10:53,680
awesome so as i mentioned uh the cool

00:10:52,480 --> 00:10:55,120
thing about parameterized quantum

00:10:53,680 --> 00:10:56,560
functions is that they're composable and

00:10:55,120 --> 00:10:57,120
they're very flexible we can include

00:10:56,560 --> 00:10:59,680
them

00:10:57,120 --> 00:11:01,600
within other scientific piping packages

00:10:59,680 --> 00:11:03,600
so we've created a parameterized quantum

00:11:01,600 --> 00:11:05,360
function here

00:11:03,600 --> 00:11:07,839
let's try to optimize this function or

00:11:05,360 --> 00:11:11,200
minimize it so that we're training it

00:11:07,839 --> 00:11:13,519
to outper a certain value

00:11:11,200 --> 00:11:15,279
so we can use scipy files for those

00:11:13,519 --> 00:11:16,399
familiar with sci-fi sci-fi has an

00:11:15,279 --> 00:11:20,320
optimization

00:11:16,399 --> 00:11:23,680
sub-module with a minimize function

00:11:20,320 --> 00:11:24,959
so let's import that and

00:11:23,680 --> 00:11:26,560
before we can do anything we need to

00:11:24,959 --> 00:11:27,519
construct our cost function so this is

00:11:26,560 --> 00:11:29,839
the

00:11:27,519 --> 00:11:30,800
this is where encoding the function that

00:11:29,839 --> 00:11:34,079
we want to minimize

00:11:30,800 --> 00:11:35,839
to solve a particular problem

00:11:34,079 --> 00:11:38,720
so let's create a cost function this

00:11:35,839 --> 00:11:38,720
takes our premises

00:11:38,800 --> 00:11:44,560
and within this cost function let's do a

00:11:42,720 --> 00:11:48,320
mix of classical processing and

00:11:44,560 --> 00:11:51,920
quantum processing so let's take

00:11:48,320 --> 00:11:52,720
the sine and within here and let's let's

00:11:51,920 --> 00:11:57,279
create another

00:11:52,720 --> 00:11:58,720
array or four values

00:11:57,279 --> 00:12:00,560
and since this numpy array has four

00:11:58,720 --> 00:12:02,399
values and the output of our quantum

00:12:00,560 --> 00:12:03,760
function also has four values

00:12:02,399 --> 00:12:06,639
we can take the dot product between

00:12:03,760 --> 00:12:08,320
these two so let's reevaluate our

00:12:06,639 --> 00:12:09,279
quantum function with the cost function

00:12:08,320 --> 00:12:12,160
parameters

00:12:09,279 --> 00:12:13,600
and take the dot product between that

00:12:12,160 --> 00:12:15,279
numpy array and the output of our

00:12:13,600 --> 00:12:18,399
quantum function

00:12:15,279 --> 00:12:20,720
and there we go that's a classical

00:12:18,399 --> 00:12:21,600
quantum cost function and it involves a

00:12:20,720 --> 00:12:23,279
mix

00:12:21,600 --> 00:12:25,040
of classical processing for instance the

00:12:23,279 --> 00:12:28,079
sine the dot product

00:12:25,040 --> 00:12:30,399
and quantum processing by represented by

00:12:28,079 --> 00:12:33,200
evaluating our quantum function

00:12:30,399 --> 00:12:35,040
so we can test out this cost function

00:12:33,200 --> 00:12:36,079
let's evaluate it with our initial

00:12:35,040 --> 00:12:37,680
parameters

00:12:36,079 --> 00:12:39,360
there we go so we evaluate with our

00:12:37,680 --> 00:12:41,600
initial parameters and we get a scalar

00:12:39,360 --> 00:12:43,839
output of 0.81

00:12:41,600 --> 00:12:45,279
perfect so we have a cost function now

00:12:43,839 --> 00:12:46,639
it mixes classical processing and

00:12:45,279 --> 00:12:48,480
quantum processing

00:12:46,639 --> 00:12:50,399
let's use scipy to minimize this cost

00:12:48,480 --> 00:12:51,200
function so we'll use scipy to find the

00:12:50,399 --> 00:12:52,959
value of the

00:12:51,200 --> 00:12:56,320
input parameters that result in the

00:12:52,959 --> 00:12:56,320
minimal value of the output

00:12:58,000 --> 00:13:01,600
so we call the minimize function we pass

00:13:00,000 --> 00:13:04,160
the function we want to minimize

00:13:01,600 --> 00:13:06,480
as well as the initial parameters that

00:13:04,160 --> 00:13:08,320
we're starting off with in our problem

00:13:06,480 --> 00:13:11,120
there we go let's see how this

00:13:08,320 --> 00:13:11,120
optimization went

00:13:11,519 --> 00:13:16,079
amazing so the optimization was a

00:13:13,680 --> 00:13:16,079
success

00:13:16,399 --> 00:13:21,360
uh it required two iterations and i

00:13:20,160 --> 00:13:23,680
believe it required

00:13:21,360 --> 00:13:24,959
32 evaluations of the quantum function i

00:13:23,680 --> 00:13:27,040
i might have to double check with the

00:13:24,959 --> 00:13:29,200
sci-fi documentation

00:13:27,040 --> 00:13:30,720
uh and it's also provided us our optimal

00:13:29,200 --> 00:13:31,600
values of the parameters which minimize

00:13:30,720 --> 00:13:34,000
that cost function

00:13:31,600 --> 00:13:36,720
so let's test that out so here are

00:13:34,000 --> 00:13:39,360
minimal parameter values

00:13:36,720 --> 00:13:41,120
and let's evaluate our cost function

00:13:39,360 --> 00:13:44,079
with those minimum values

00:13:41,120 --> 00:13:45,760
there we go we're comparing that again

00:13:44,079 --> 00:13:49,040
so the cost function would be initial

00:13:45,760 --> 00:13:50,560
parameters we can see that the optimized

00:13:49,040 --> 00:13:52,480
parameters results in their cost value

00:13:50,560 --> 00:13:54,000
of minus 0.84

00:13:52,480 --> 00:13:58,399
compared to our initial value which is

00:13:54,000 --> 00:13:58,399
0.81 so a really really nice result

00:14:00,240 --> 00:14:03,839
having composable quantum functions that

00:14:01,920 --> 00:14:05,440
can be used arbitrarily within python is

00:14:03,839 --> 00:14:07,199
already an awesome addition

00:14:05,440 --> 00:14:09,199
we easily provide this function to scipy

00:14:07,199 --> 00:14:10,480
for optimization without sci-fi knowing

00:14:09,199 --> 00:14:12,240
any better if it was optimizing a

00:14:10,480 --> 00:14:14,000
quantum device

00:14:12,240 --> 00:14:16,160
i just want to quickly emphasize exactly

00:14:14,000 --> 00:14:17,360
what we did here we used python to train

00:14:16,160 --> 00:14:18,480
the quantum device to achieve a

00:14:17,360 --> 00:14:19,839
particular outcome

00:14:18,480 --> 00:14:22,240
by varying the parameters of this

00:14:19,839 --> 00:14:23,600
quantum device phrased in this way does

00:14:22,240 --> 00:14:25,199
it sound familiar

00:14:23,600 --> 00:14:26,720
this is exactly what we do with neural

00:14:25,199 --> 00:14:28,320
networks and machine learning using

00:14:26,720 --> 00:14:30,320
workhorse algorithms such as gradient

00:14:28,320 --> 00:14:32,480
descent and back propagation

00:14:30,320 --> 00:14:33,760
in fact python has a rich ecosystem in

00:14:32,480 --> 00:14:36,480
machine learning frameworks

00:14:33,760 --> 00:14:37,760
including tensorflow pi torch can we

00:14:36,480 --> 00:14:39,279
integrate our quantum function with

00:14:37,760 --> 00:14:40,639
these machine learning frameworks

00:14:39,279 --> 00:14:43,760
and use the tools developed for deep

00:14:40,639 --> 00:14:45,760
learning to train quantum devices

00:14:43,760 --> 00:14:47,120
we quickly run into an issue though if

00:14:45,760 --> 00:14:48,079
we want to integrate our quantum

00:14:47,120 --> 00:14:48,800
function with machine learning

00:14:48,079 --> 00:14:50,160
frameworks

00:14:48,800 --> 00:14:52,000
we need more information about our

00:14:50,160 --> 00:14:52,880
quantum function we also need the

00:14:52,000 --> 00:14:54,560
gradient

00:14:52,880 --> 00:14:56,160
and preferably we want to be able to

00:14:54,560 --> 00:14:56,800
extract the gradient via another quantum

00:14:56,160 --> 00:14:58,320
function

00:14:56,800 --> 00:14:59,839
since quantum gradients are quantum

00:14:58,320 --> 00:15:02,959
computations themselves

00:14:59,839 --> 00:15:04,320
and cannot be easily computed on cpus

00:15:02,959 --> 00:15:06,000
luckily there is an approach for

00:15:04,320 --> 00:15:08,240
computing quantum gradients

00:15:06,000 --> 00:15:09,839
on quantum devices and this is the

00:15:08,240 --> 00:15:11,360
so-called parameter shift rule

00:15:09,839 --> 00:15:13,199
which allows us to reuse the same

00:15:11,360 --> 00:15:14,399
quantum function just evaluate the

00:15:13,199 --> 00:15:16,880
different parameter values

00:15:14,399 --> 00:15:19,680
to compute the quantum gradient so let's

00:15:16,880 --> 00:15:19,680
have a look at that now

00:15:19,760 --> 00:15:23,600
so again i'm just going to create a

00:15:21,680 --> 00:15:24,800
quantum device i'll use the local

00:15:23,600 --> 00:15:27,760
simulator with two

00:15:24,800 --> 00:15:29,279
wires or two qubits and i'll create a

00:15:27,760 --> 00:15:30,959
slightly more complicated quantum

00:15:29,279 --> 00:15:32,399
function in this case

00:15:30,959 --> 00:15:34,079
so you can see now that i have three

00:15:32,399 --> 00:15:35,040
rotation instructions on the quantum

00:15:34,079 --> 00:15:38,079
device

00:15:35,040 --> 00:15:40,399
so three parameters

00:15:38,079 --> 00:15:42,560
i have two entangling gates or

00:15:40,399 --> 00:15:44,480
entangling instructions

00:15:42,560 --> 00:15:46,160
and rather than returning a measurement

00:15:44,480 --> 00:15:47,759
statistic which is a probability

00:15:46,160 --> 00:15:50,800
this time i'm returning an expectation

00:15:47,759 --> 00:15:54,079
value of the quantum device

00:15:50,800 --> 00:15:56,959
so we'll create some parameters

00:15:54,079 --> 00:15:58,399
let's evaluate this quantum function so

00:15:56,959 --> 00:16:00,519
you can see that it has three input

00:15:58,399 --> 00:16:02,560
parameters and it outputs a scalar

00:16:00,519 --> 00:16:04,399
0.0289

00:16:02,560 --> 00:16:06,000
so now let's find the derivative of this

00:16:04,399 --> 00:16:08,560
quantum function with respect to the

00:16:06,000 --> 00:16:11,199
second parameter 0.2

00:16:08,560 --> 00:16:12,160
so what we'll do is we'll shift it we'll

00:16:11,199 --> 00:16:14,639
create a shift vector

00:16:12,160 --> 00:16:15,839
and the shifter vector will result in no

00:16:14,639 --> 00:16:16,480
change to the first and the third

00:16:15,839 --> 00:16:18,240
parameter

00:16:16,480 --> 00:16:20,480
but it will shift the second parameter

00:16:18,240 --> 00:16:22,079
by pi r2

00:16:20,480 --> 00:16:24,000
so what we'll do is we'll evaluate this

00:16:22,079 --> 00:16:25,360
quantum function twice the first time

00:16:24,000 --> 00:16:27,519
with the parameters with the second

00:16:25,360 --> 00:16:29,199
parameter shifted forward by pan two

00:16:27,519 --> 00:16:30,480
and the second time by the quantum

00:16:29,199 --> 00:16:32,160
parameter by the second parameter

00:16:30,480 --> 00:16:34,639
shifted backwards by pi of two

00:16:32,160 --> 00:16:36,399
and we'll divide that by two and that's

00:16:34,639 --> 00:16:38,480
the gradient of the quantum function

00:16:36,399 --> 00:16:40,560
with respect to the second parameter

00:16:38,480 --> 00:16:42,160
as a quick sanity check let's compare

00:16:40,560 --> 00:16:45,360
this to penny lane's built-in

00:16:42,160 --> 00:16:46,639
gradient computation so any lane has a

00:16:45,360 --> 00:16:48,839
function keynote.grad

00:16:46,639 --> 00:16:50,560
to compute the gradient of quantum

00:16:48,839 --> 00:16:52,399
functions so

00:16:50,560 --> 00:16:54,000
in this case this is the gradient with

00:16:52,399 --> 00:16:56,240
respect to all parameters

00:16:54,000 --> 00:16:57,839
but we in particular calculate the

00:16:56,240 --> 00:16:59,440
gradient respect to the second parameter

00:16:57,839 --> 00:17:05,839
and we can see that we have a

00:16:59,440 --> 00:17:05,839
exact correspondence this is great

00:17:06,400 --> 00:17:09,679
so so far we've seen how to construct a

00:17:08,160 --> 00:17:10,959
quantum function in python and we've

00:17:09,679 --> 00:17:12,559
also explored how to compute the

00:17:10,959 --> 00:17:14,160
gradient of that quantum function by

00:17:12,559 --> 00:17:16,319
evaluating that same quantum function

00:17:14,160 --> 00:17:18,959
just with shifted parameter values

00:17:16,319 --> 00:17:20,640
so this is all we need in order to

00:17:18,959 --> 00:17:22,000
integrate our quantum function with a

00:17:20,640 --> 00:17:24,959
machine learning library

00:17:22,000 --> 00:17:26,400
to manage the optimization pipeline so a

00:17:24,959 --> 00:17:27,839
neat feature of many machine learning

00:17:26,400 --> 00:17:29,679
packages for python is that they enable

00:17:27,839 --> 00:17:30,960
you to explicitly provide the custom

00:17:29,679 --> 00:17:32,559
gradient of a function

00:17:30,960 --> 00:17:35,120
allowing it to seamlessly integrate into

00:17:32,559 --> 00:17:36,960
the machine learning framework

00:17:35,120 --> 00:17:39,200
so this is common to a lot of the

00:17:36,960 --> 00:17:41,280
frameworks in this particular example

00:17:39,200 --> 00:17:42,720
we'll use pytorch and this is just a

00:17:41,280 --> 00:17:44,320
page from the pytorch documentation

00:17:42,720 --> 00:17:45,280
that's showing how you make something a

00:17:44,320 --> 00:17:47,679
particular function

00:17:45,280 --> 00:17:49,520
pi torch compatible and you really only

00:17:47,679 --> 00:17:49,840
need to do two things you need to create

00:17:49,520 --> 00:17:52,320
a

00:17:49,840 --> 00:17:53,840
pi torch autograd function object and

00:17:52,320 --> 00:17:54,880
define the forward pass

00:17:53,840 --> 00:17:56,880
and this is what happens when you

00:17:54,880 --> 00:17:59,360
evaluate the function

00:17:56,880 --> 00:18:01,520
and the backwards pass and this is the

00:17:59,360 --> 00:18:04,320
gradient computation

00:18:01,520 --> 00:18:07,120
of your particular custom function so

00:18:04,320 --> 00:18:07,120
let's do this now

00:18:07,840 --> 00:18:14,240
first things first let's import i torch

00:18:12,240 --> 00:18:17,440
and we can start off by creating our pie

00:18:14,240 --> 00:18:20,640
torch comparable quantum function

00:18:17,440 --> 00:18:22,520
so we create a

00:18:20,640 --> 00:18:25,440
hue func that inherits from

00:18:22,520 --> 00:18:26,640
autograd.function

00:18:25,440 --> 00:18:28,320
and the first thing we need to do is

00:18:26,640 --> 00:18:30,160
define the forward method and this is

00:18:28,320 --> 00:18:32,240
just a static method

00:18:30,160 --> 00:18:35,120
that takes in the environment context

00:18:32,240 --> 00:18:36,480
and the input torch parameters

00:18:35,120 --> 00:18:38,480
so we need to save these input

00:18:36,480 --> 00:18:41,200
parameters for the

00:18:38,480 --> 00:18:42,720
back propagation and if you want any

00:18:41,200 --> 00:18:44,160
more details about how back propagation

00:18:42,720 --> 00:18:46,160
works i encourage you to read up

00:18:44,160 --> 00:18:47,760
on the pi swatch website it provides a

00:18:46,160 --> 00:18:50,480
lot more details in that extending

00:18:47,760 --> 00:18:52,000
python page

00:18:50,480 --> 00:18:53,760
um now the issue is that these

00:18:52,000 --> 00:18:56,000
parameters are pi torch tensors and our

00:18:53,760 --> 00:18:57,440
quantum function takes numpy arrays so

00:18:56,000 --> 00:18:59,200
what we want to do is we want to take

00:18:57,440 --> 00:19:00,880
these parameters we want to detach them

00:18:59,200 --> 00:19:02,640
from the back propagation

00:19:00,880 --> 00:19:04,320
and convert them into nonpirates and

00:19:02,640 --> 00:19:05,120
this gives us a form that we can use to

00:19:04,320 --> 00:19:11,840
evaluate

00:19:05,120 --> 00:19:11,840
our q function

00:19:12,559 --> 00:19:16,799
so we've now evaluated our q func and

00:19:14,720 --> 00:19:19,919
all we need to return is we need to

00:19:16,799 --> 00:19:20,960
convert this into a back into a torch

00:19:19,919 --> 00:19:23,200
tensor

00:19:20,960 --> 00:19:24,480
there we go that's our forward method so

00:19:23,200 --> 00:19:27,679
now let's define

00:19:24,480 --> 00:19:27,679
our backwards method

00:19:29,600 --> 00:19:32,799
so this takes the environment context it

00:19:31,440 --> 00:19:34,559
also takes

00:19:32,799 --> 00:19:36,799
what's called the gradient output so

00:19:34,559 --> 00:19:39,039
back propagation works in reverse

00:19:36,799 --> 00:19:40,400
we're going from the output of the

00:19:39,039 --> 00:19:41,600
computation and we're going backwards

00:19:40,400 --> 00:19:43,039
through to compute the gradient so

00:19:41,600 --> 00:19:45,360
that's why we pass in the gradient

00:19:43,039 --> 00:19:45,360
output

00:19:45,840 --> 00:19:49,280
so what pytorch wants in this particular

00:19:47,600 --> 00:19:50,720
method is it wants the vector jacobian

00:19:49,280 --> 00:19:53,840
product

00:19:50,720 --> 00:19:53,840
and this is a

00:19:54,240 --> 00:19:58,000
array with the same shape as the input

00:19:56,559 --> 00:19:59,440
premises

00:19:58,000 --> 00:20:03,120
and now we can apply the parameter shift

00:19:59,440 --> 00:20:03,120
rule so we can actually loop

00:20:05,360 --> 00:20:11,440
over every parameter to our keynote

00:20:08,400 --> 00:20:11,440
to our quantum function

00:20:15,039 --> 00:20:20,240
you can make a copy of the parameter

00:20:18,840 --> 00:20:22,080
array

00:20:20,240 --> 00:20:24,159
what we want to do is we want to shift

00:20:22,080 --> 00:20:28,159
this particular index in that parameter

00:20:24,159 --> 00:20:28,159
array by that shift value

00:20:28,720 --> 00:20:31,840
and then we can evaluate

00:20:33,039 --> 00:20:36,720
the forward shift of our quantum

00:20:34,799 --> 00:20:38,480
function

00:20:36,720 --> 00:20:40,799
now we do something similar we shift

00:20:38,480 --> 00:20:42,799
that same index

00:20:40,799 --> 00:20:44,320
backwards by pi so in fact we're now

00:20:42,799 --> 00:20:47,280
shifting backwards from the original

00:20:44,320 --> 00:20:47,280
value by pi on two

00:20:47,360 --> 00:20:50,880
and we evaluate the backward value

00:20:53,760 --> 00:20:57,039
and finally as you saw before our

00:20:55,600 --> 00:21:00,080
gradient is simply

00:20:57,039 --> 00:21:02,400
forward take backward

00:21:00,080 --> 00:21:03,840
divide by two now i mentioned here that

00:21:02,400 --> 00:21:04,480
we want to return the vector jacobian

00:21:03,840 --> 00:21:07,200
product

00:21:04,480 --> 00:21:08,559
so it's slightly more than just the

00:21:07,200 --> 00:21:10,400
gradient we want to return we want to

00:21:08,559 --> 00:21:10,799
return the gradient multiplied by this

00:21:10,400 --> 00:21:13,440
grad

00:21:10,799 --> 00:21:13,440
output value

00:21:13,840 --> 00:21:20,000
and this is the idx index

00:21:16,880 --> 00:21:21,039
of our jp vector

00:21:20,000 --> 00:21:23,039
and that's it we've applied the

00:21:21,039 --> 00:21:23,840
parameter shift rule in a for loop over

00:21:23,039 --> 00:21:25,840
each index

00:21:23,840 --> 00:21:28,559
in our initial parameters so this

00:21:25,840 --> 00:21:31,200
returns the full vector jacobian product

00:21:28,559 --> 00:21:34,880
now we simply want to convert it back

00:21:31,200 --> 00:21:37,280
into a tensor so that python percentage

00:21:34,880 --> 00:21:39,200
and there we go we've made our quantum

00:21:37,280 --> 00:21:40,480
function pi torch comparable by defining

00:21:39,200 --> 00:21:41,440
what happens when we evaluate the

00:21:40,480 --> 00:21:45,360
quantum function

00:21:41,440 --> 00:21:46,880
for pi torch and also defining what the

00:21:45,360 --> 00:21:49,600
gradient of this quantum function is

00:21:46,880 --> 00:21:52,640
here so the final step

00:21:49,600 --> 00:21:55,360
is just to create a

00:21:52,640 --> 00:21:56,799
function that is aliased to the apply

00:21:55,360 --> 00:21:59,120
method of this class

00:21:56,799 --> 00:22:00,720
and that's it so let's test this out now

00:21:59,120 --> 00:22:02,000
we'll do the forward pass first so we'll

00:22:00,720 --> 00:22:04,960
create some

00:22:02,000 --> 00:22:05,960
initial parameters and again we're just

00:22:04,960 --> 00:22:08,480
doing

00:22:05,960 --> 00:22:09,039
0.10.20.3 we're creating a torch sensor

00:22:08,480 --> 00:22:10,640
because

00:22:09,039 --> 00:22:12,640
we need to provide parameters that pi

00:22:10,640 --> 00:22:14,320
torque understands

00:22:12,640 --> 00:22:16,320
and let's construct our cross function

00:22:14,320 --> 00:22:17,840
so let's do some arbitrary mix of

00:22:16,320 --> 00:22:20,320
classical processing quantum

00:22:17,840 --> 00:22:22,880
processing just because we can so let's

00:22:20,320 --> 00:22:26,480
take the sine

00:22:22,880 --> 00:22:28,799
pi switching variable quantum function

00:22:26,480 --> 00:22:30,559
and let's take the cube of that because

00:22:28,799 --> 00:22:32,559
why not

00:22:30,559 --> 00:22:35,120
there you go that's our value oh pretty

00:22:32,559 --> 00:22:38,320
small let's do a bit more

00:22:35,120 --> 00:22:40,320
we'll let's compute the quantum function

00:22:38,320 --> 00:22:42,400
again and add that onto that value

00:22:40,320 --> 00:22:45,200
this time with the square root of the

00:22:42,400 --> 00:22:45,200
initial transfers

00:22:45,760 --> 00:22:50,000
nice slightly larger value so here comes

00:22:49,120 --> 00:22:52,640
the

00:22:50,000 --> 00:22:54,480
fun part let's perform back propagation

00:22:52,640 --> 00:22:56,240
through this hybrid mix

00:22:54,480 --> 00:22:58,640
of both classical processing and quantum

00:22:56,240 --> 00:23:00,159
processing

00:22:58,640 --> 00:23:02,799
everything seems to have worked out fine

00:23:00,159 --> 00:23:04,480
so let's have a look

00:23:02,799 --> 00:23:07,679
there we go and that's our gradient so

00:23:04,480 --> 00:23:09,600
we've incorporated our quantum function

00:23:07,679 --> 00:23:11,360
into pi torch we've created a pi torch

00:23:09,600 --> 00:23:13,520
version of this quantum function

00:23:11,360 --> 00:23:15,360
that pytorch natively understands and

00:23:13,520 --> 00:23:16,960
not only does it natively understand

00:23:15,360 --> 00:23:18,720
it's able to back propagate through this

00:23:16,960 --> 00:23:20,320
entire structure so if you have a look

00:23:18,720 --> 00:23:22,320
back at that initial slide we've created

00:23:20,320 --> 00:23:24,400
something almost like this here the

00:23:22,320 --> 00:23:26,000
green are quantum functions

00:23:24,400 --> 00:23:27,520
potentially on the same device maybe

00:23:26,000 --> 00:23:30,400
even on different devices

00:23:27,520 --> 00:23:31,520
and we've seamlessly integrated it with

00:23:30,400 --> 00:23:34,840
classical processing

00:23:31,520 --> 00:23:37,840
indicated by the yellow nodes in the

00:23:34,840 --> 00:23:37,840
graph

00:23:41,919 --> 00:23:45,760
so as you can see we have the ability to

00:23:43,840 --> 00:23:47,520
integrate quantum computing seamlessly

00:23:45,760 --> 00:23:48,880
into python and its myriad of deep

00:23:47,520 --> 00:23:50,159
learning roblox

00:23:48,880 --> 00:23:52,000
the tools that we have developed for

00:23:50,159 --> 00:23:53,919
deep learning over the past decades we

00:23:52,000 --> 00:23:56,080
can harness to optimize and train these

00:23:53,919 --> 00:23:57,679
near-term quantum devices

00:23:56,080 --> 00:23:59,360
open-source python software such as

00:23:57,679 --> 00:24:00,880
penulane which we use today

00:23:59,360 --> 00:24:02,840
and tensorflow quantum automate this

00:24:00,880 --> 00:24:04,000
integration allowing for rapid

00:24:02,840 --> 00:24:06,320
prototyping

00:24:04,000 --> 00:24:07,679
a word of caution though i mentioned

00:24:06,320 --> 00:24:08,960
earlier that many misconceptions

00:24:07,679 --> 00:24:10,720
surround quantum computing and

00:24:08,960 --> 00:24:12,240
especially quantum machine learning

00:24:10,720 --> 00:24:14,000
i want to emphasize that this field is

00:24:12,240 --> 00:24:15,840
still very young and definitely still

00:24:14,000 --> 00:24:17,520
has an exploratory stage

00:24:15,840 --> 00:24:19,039
replacing your neural networks with

00:24:17,520 --> 00:24:19,919
quantum functions typically won't lead

00:24:19,039 --> 00:24:22,559
to a speed up

00:24:19,919 --> 00:24:24,240
or even better results however these

00:24:22,559 --> 00:24:26,080
devices have shown an early promise for

00:24:24,240 --> 00:24:28,799
quantum machine learning specifically

00:24:26,080 --> 00:24:29,679
on quantum data sets so for example this

00:24:28,799 --> 00:24:31,440
is very

00:24:29,679 --> 00:24:32,720
common in quantum chemistry where you

00:24:31,440 --> 00:24:35,200
might want to find the ground state

00:24:32,720 --> 00:24:36,960
energy of a molecule

00:24:35,200 --> 00:24:38,640
having said that i hope that this talk

00:24:36,960 --> 00:24:39,200
has shown how easy it is to play around

00:24:38,640 --> 00:24:40,640
have fun

00:24:39,200 --> 00:24:42,480
and just explore what's possible with

00:24:40,640 --> 00:24:44,960
quantum computing in python

00:24:42,480 --> 00:24:46,000
the python ecosystem is so rich and with

00:24:44,960 --> 00:24:48,240
machine learning we have seen

00:24:46,000 --> 00:24:49,520
this rich ecosystem and ability to

00:24:48,240 --> 00:24:51,279
rapidly prototype

00:24:49,520 --> 00:24:52,640
lead to new theoretical results and

00:24:51,279 --> 00:24:54,159
understanding

00:24:52,640 --> 00:24:56,000
perhaps the same can be true of quantum

00:24:54,159 --> 00:24:57,520
computing

00:24:56,000 --> 00:24:59,200
i know this talk was short but if i have

00:24:57,520 --> 00:25:01,039
wasted your appetite please check out

00:24:59,200 --> 00:25:03,279
the following resources

00:25:01,039 --> 00:25:04,880
so a shout out to the unitary fund a

00:25:03,279 --> 00:25:06,559
non-profit organization that provides

00:25:04,880 --> 00:25:08,159
micro grants to work on open quantum

00:25:06,559 --> 00:25:09,840
software

00:25:08,159 --> 00:25:12,000
the quantum open source foundation

00:25:09,840 --> 00:25:13,840
similarly helps support the development

00:25:12,000 --> 00:25:16,640
and standardization of open tools for

00:25:13,840 --> 00:25:18,400
quantum computing

00:25:16,640 --> 00:25:19,840
if you're interested the quantum open

00:25:18,400 --> 00:25:21,279
source foundation maintains a list of

00:25:19,840 --> 00:25:22,799
active open source quantum computing

00:25:21,279 --> 00:25:24,320
projects so i encourage you to check

00:25:22,799 --> 00:25:25,600
them out or even contribute to a few of

00:25:24,320 --> 00:25:27,520
them

00:25:25,600 --> 00:25:29,120
finally check out the penulene website

00:25:27,520 --> 00:25:30,559
for further explanations and tutorials

00:25:29,120 --> 00:25:43,840
on quantum machine learning

00:25:30,559 --> 00:25:43,840
thank you everyone

00:26:39,679 --> 00:26:41,760

YouTube URL: https://www.youtube.com/watch?v=o377m0doD6M


