Title: TALK   Anthony Shaw   Restarting Pyjion, a general purpose JIT for Python- is it worth it?
Publication date: 2021-05-29
Playlist: PyCon US 2021
Description: 
	In this talk you'll see an update to the Pyjion project, a JIT compiler for CPython byte-code. This project was started 5 years ago but stopped after making no gains in performance. Recent changes to CPython have made optimisations more viable, so now it has been restarted and is showing big performance gains vs. standard CPython with 100% compatibility. Many attempts have been made to build a general purpose JIT for Python and few have succeeded. Is it worth it and what are the gains to be made? This talk will cover the design ideas of a JIT for CPython, optimisations, and future potential.

Website: https://pyjion.readthedocs.io
Source code: https://GitHub.com/tonybaloney/pyjion
Book: https://realpython.com/products/cpython-internals-book/
Captions: 
	00:00:04,170 --> 00:00:11,869
[Music]

00:00:15,920 --> 00:00:18,080
hi everyone i hope you're really

00:00:17,359 --> 00:00:22,000
enjoying

00:00:18,080 --> 00:00:23,760
pycon us 2021 so far i'm really excited

00:00:22,000 --> 00:00:24,560
to be here to present something to you

00:00:23,760 --> 00:00:26,160
today

00:00:24,560 --> 00:00:27,920
called pidgin which is a project that

00:00:26,160 --> 00:00:31,359
i've been working on for the last

00:00:27,920 --> 00:00:32,880
nine months and um yeah i want to say a

00:00:31,359 --> 00:00:34,399
big hello to all the international

00:00:32,880 --> 00:00:36,160
pythonistas out there

00:00:34,399 --> 00:00:38,320
and so pleased that everyone can make it

00:00:36,160 --> 00:00:39,520
this year virtually and really look

00:00:38,320 --> 00:00:43,120
forward to seeing you

00:00:39,520 --> 00:00:45,039
in the future face to face in this talk

00:00:43,120 --> 00:00:46,719
we're going to cover five main topics in

00:00:45,039 --> 00:00:48,559
a short space of time

00:00:46,719 --> 00:00:51,760
some of these topics especially the jit

00:00:48,559 --> 00:00:53,360
compiler are very niche technology areas

00:00:51,760 --> 00:00:55,440
i'm not assuming that everyone watching

00:00:53,360 --> 00:00:57,120
this talk is a compiler expert

00:00:55,440 --> 00:00:59,039
but i'll really try my best to break

00:00:57,120 --> 00:01:01,440
down some of the topics

00:00:59,039 --> 00:01:03,039
we don't have that much time if you find

00:01:01,440 --> 00:01:04,320
yourself wanting to learn more by the

00:01:03,039 --> 00:01:05,600
end of the talk there are plenty of

00:01:04,320 --> 00:01:08,240
links to follow up with

00:01:05,600 --> 00:01:10,560
or you can reach out to me directly so

00:01:08,240 --> 00:01:13,920
first off let's recap from my pycon us

00:01:10,560 --> 00:01:15,680
2020 talk why is python slow

00:01:13,920 --> 00:01:17,360
i strongly recommend you watch that talk

00:01:15,680 --> 00:01:19,200
because it gives some context

00:01:17,360 --> 00:01:21,680
for why i'm looking at a jit to solve

00:01:19,200 --> 00:01:23,840
some of python's performance challenges

00:01:21,680 --> 00:01:24,880
in that talk i talked about a particular

00:01:23,840 --> 00:01:27,759
benchmark

00:01:24,880 --> 00:01:29,920
called the n-body algorithm the n-body

00:01:27,759 --> 00:01:31,600
algorithm is a mathematical formula

00:01:29,920 --> 00:01:34,079
that can calculate the orbits of the

00:01:31,600 --> 00:01:37,200
jovian planets which are jupiter

00:01:34,079 --> 00:01:39,119
saturn uranus and neptune i picked nbody

00:01:37,200 --> 00:01:41,280
because the python implementation

00:01:39,119 --> 00:01:44,399
suffers from an extreme case of some of

00:01:41,280 --> 00:01:47,439
the causes of its general slowness

00:01:44,399 --> 00:01:49,680
if you compare c and c python 3.9

00:01:47,439 --> 00:01:51,840
which is written in c the execution

00:01:49,680 --> 00:01:54,880
times are not even in the same galaxy

00:01:51,840 --> 00:01:55,520
let alone the same planet even ruby php

00:01:54,880 --> 00:01:57,360
and perl

00:01:55,520 --> 00:01:58,880
put python to shame on this algorithm

00:01:57,360 --> 00:02:00,560
when it comes to speed

00:01:58,880 --> 00:02:03,040
but it's not those languages i'd like to

00:02:00,560 --> 00:02:05,520
compare python against it's javascript

00:02:03,040 --> 00:02:06,560
javascript is equally dynamic it has a

00:02:05,520 --> 00:02:09,039
gc

00:02:06,560 --> 00:02:10,560
and it kind of even has a gill as well

00:02:09,039 --> 00:02:13,120
so how is node.js

00:02:10,560 --> 00:02:15,760
which runs javascript so much faster

00:02:13,120 --> 00:02:15,760
than python

00:02:17,440 --> 00:02:21,120
this is the guts of the python n-body

00:02:19,440 --> 00:02:23,280
implementation

00:02:21,120 --> 00:02:25,200
to summarize what's happening here it's

00:02:23,280 --> 00:02:26,800
looping over a list of tuples

00:02:25,200 --> 00:02:28,560
unpacking them and then performing a

00:02:26,800 --> 00:02:30,640
number of calculations and floating

00:02:28,560 --> 00:02:32,160
point numbers

00:02:30,640 --> 00:02:33,760
i've highlighted the core integral of

00:02:32,160 --> 00:02:35,200
the algorithm here

00:02:33,760 --> 00:02:37,840
all of the highlighted variables are

00:02:35,200 --> 00:02:39,599
floats something that's important

00:02:37,840 --> 00:02:41,040
is that python won't do anything clever

00:02:39,599 --> 00:02:42,480
with the operators

00:02:41,040 --> 00:02:44,319
the compiler knows the order of

00:02:42,480 --> 00:02:46,160
operations and emits the bytecodes in

00:02:44,319 --> 00:02:47,920
the correct sequence

00:02:46,160 --> 00:02:50,000
it uses a mnemonic that maybe you

00:02:47,920 --> 00:02:53,519
learned at high school like bodmap

00:02:50,000 --> 00:02:54,640
or pemdas the achilles heel of this

00:02:53,519 --> 00:02:55,760
calculation

00:02:54,640 --> 00:02:58,560
is that the result of each

00:02:55,760 --> 00:03:01,280
multiplication addition subtraction

00:02:58,560 --> 00:03:02,879
is a new floating point object which

00:03:01,280 --> 00:03:05,519
then gets dereferenced in the next

00:03:02,879 --> 00:03:07,680
operation

00:03:05,519 --> 00:03:09,280
let's expand line 74 and i'll show you

00:03:07,680 --> 00:03:11,360
what i mean

00:03:09,280 --> 00:03:13,200
in this equation python will run four

00:03:11,360 --> 00:03:15,680
multiplication operations

00:03:13,200 --> 00:03:16,800
two addition operations and one power

00:03:15,680 --> 00:03:18,400
operation

00:03:16,800 --> 00:03:20,400
the resulting floating point numbers

00:03:18,400 --> 00:03:22,400
have to be allocated in memory

00:03:20,400 --> 00:03:24,159
the native c float has to be converted

00:03:22,400 --> 00:03:26,239
to a pi float object

00:03:24,159 --> 00:03:29,040
and then in the very next operation it

00:03:26,239 --> 00:03:31,200
gets converted back into a c float

00:03:29,040 --> 00:03:33,040
the reference count becomes zero and so

00:03:31,200 --> 00:03:35,440
the memory is freed

00:03:33,040 --> 00:03:37,519
you might think that memory is fast but

00:03:35,440 --> 00:03:40,159
the floating point numbers

00:03:37,519 --> 00:03:41,680
in steps one to six in this diagram are

00:03:40,159 --> 00:03:43,120
all temporary objects

00:03:41,680 --> 00:03:46,159
so they get allocated and then

00:03:43,120 --> 00:03:47,599
deallocated almost instantaneously

00:03:46,159 --> 00:03:50,080
so if you think of the time it takes to

00:03:47,599 --> 00:03:52,080
do that multiply that by

00:03:50,080 --> 00:03:53,200
the half a million iterations this loop

00:03:52,080 --> 00:03:54,720
executes

00:03:53,200 --> 00:03:56,400
and then again for each planet and then

00:03:54,720 --> 00:03:58,400
again for each step

00:03:56,400 --> 00:04:00,000
it's actually over a billion operations

00:03:58,400 --> 00:04:02,000
of this particular line

00:04:00,000 --> 00:04:04,640
so when you add all that up it adds up

00:04:02,000 --> 00:04:06,239
to a lot of execution time

00:04:04,640 --> 00:04:08,480
if you were to convert this function to

00:04:06,239 --> 00:04:10,319
a siphon module and annotate all of

00:04:08,480 --> 00:04:12,000
those variables as doubles

00:04:10,319 --> 00:04:13,920
it would bypass the temporary object

00:04:12,000 --> 00:04:15,840
allocations and syphon would compile

00:04:13,920 --> 00:04:18,320
that down to execute about eight times

00:04:15,840 --> 00:04:19,120
faster it does this because a floating

00:04:18,320 --> 00:04:22,320
point number

00:04:19,120 --> 00:04:24,720
still fits within 64 bits so

00:04:22,320 --> 00:04:26,160
the cpu can keep that on the register

00:04:24,720 --> 00:04:27,919
and it doesn't have to allocate and

00:04:26,160 --> 00:04:30,000
de-allocate memory from the heap to do

00:04:27,919 --> 00:04:32,000
the calculation

00:04:30,000 --> 00:04:33,520
if you were to run n-body using another

00:04:32,000 --> 00:04:35,280
jet pipe

00:04:33,520 --> 00:04:37,199
it has its own mechanism for removing

00:04:35,280 --> 00:04:39,759
the allocation and the allocation of

00:04:37,199 --> 00:04:42,000
these temporary objects

00:04:39,759 --> 00:04:43,199
the pie pie approach is super efficient

00:04:42,000 --> 00:04:45,840
on the cpu

00:04:43,199 --> 00:04:47,600
but it does consume more memory this is

00:04:45,840 --> 00:04:49,680
a common issue with jits to have high

00:04:47,600 --> 00:04:51,919
memory usage at the expense of reduced

00:04:49,680 --> 00:04:54,160
execution times

00:04:51,919 --> 00:04:56,160
so let's recap the conclusion of why is

00:04:54,160 --> 00:04:59,120
python slow

00:04:56,160 --> 00:05:01,840
there's a temporary object problem

00:04:59,120 --> 00:05:04,639
there's the evaluation loop of c python

00:05:01,840 --> 00:05:07,840
and the big overhead that that has so

00:05:04,639 --> 00:05:09,120
tight loops and cycles are really slow

00:05:07,840 --> 00:05:11,039
most attempts at improving the

00:05:09,120 --> 00:05:12,960
performance of python come with major

00:05:11,039 --> 00:05:14,960
drawbacks to either compatibility or

00:05:12,960 --> 00:05:17,039
platform support

00:05:14,960 --> 00:05:18,639
and so having a truly compatible

00:05:17,039 --> 00:05:21,280
optimizer for python

00:05:18,639 --> 00:05:23,840
is actually pretty tricky the garbage

00:05:21,280 --> 00:05:25,440
collector is a stop everything collector

00:05:23,840 --> 00:05:28,880
unlike node.js which does a

00:05:25,440 --> 00:05:28,880
multi-threaded mark process

00:05:29,039 --> 00:05:32,240
and lastly the theory is that a

00:05:31,199 --> 00:05:35,680
specialized jit

00:05:32,240 --> 00:05:35,680
could help in some scenarios

00:05:36,080 --> 00:05:40,240
there are plenty of projects which add a

00:05:37,919 --> 00:05:42,960
jit compilation to your python code

00:05:40,240 --> 00:05:44,639
depending on the domain for data science

00:05:42,960 --> 00:05:46,800
and in particular for numpy

00:05:44,639 --> 00:05:48,400
there's the number project number is a

00:05:46,800 --> 00:05:49,520
decorator that you wrap on certain

00:05:48,400 --> 00:05:51,360
functions

00:05:49,520 --> 00:05:53,039
with annotations on which underlying

00:05:51,360 --> 00:05:54,960
types are used

00:05:53,039 --> 00:05:57,520
it will then jit compile parts of the

00:05:54,960 --> 00:05:59,280
function to benefit numpy calls

00:05:57,520 --> 00:06:01,600
if you're already using numpy this is

00:05:59,280 --> 00:06:02,720
great but if you're just writing general

00:06:01,600 --> 00:06:04,400
python code

00:06:02,720 --> 00:06:07,759
it likely won't make any difference at

00:06:04,400 --> 00:06:09,919
all it might even make the code slower

00:06:07,759 --> 00:06:12,160
next there's the piston project which is

00:06:09,919 --> 00:06:13,840
a fork of c python that includes a jet

00:06:12,160 --> 00:06:16,960
for some operations

00:06:13,840 --> 00:06:19,199
using the llvm jit engine number claims

00:06:16,960 --> 00:06:22,880
performance gains of 10 to 20 percent

00:06:19,199 --> 00:06:25,120
compared to c python 3.9 however

00:06:22,880 --> 00:06:26,479
the drawbacks is that it's a closed

00:06:25,120 --> 00:06:28,479
source project

00:06:26,479 --> 00:06:31,120
and that it's a runtime that you have to

00:06:28,479 --> 00:06:33,520
deploy install and support as well

00:06:31,120 --> 00:06:35,199
and lastly the pi pi project a python

00:06:33,520 --> 00:06:36,800
interpreter written in python

00:06:35,199 --> 00:06:38,720
which has a mature date that will

00:06:36,800 --> 00:06:40,080
deliver massive performance gains in

00:06:38,720 --> 00:06:42,400
many scenarios

00:06:40,080 --> 00:06:44,639
the drawbacks with pi pi is that in some

00:06:42,400 --> 00:06:45,520
cases is significantly slower than c

00:06:44,639 --> 00:06:47,520
python

00:06:45,520 --> 00:06:50,080
and also it lacks a lot of compatibility

00:06:47,520 --> 00:06:51,520
with c extensions

00:06:50,080 --> 00:06:53,360
i think there's still a gap here for a

00:06:51,520 --> 00:06:54,560
general purpose jet that focuses on

00:06:53,360 --> 00:06:56,479
compatibility

00:06:54,560 --> 00:06:58,720
and delivers performance gains to plug

00:06:56,479 --> 00:07:00,319
some of the pitfalls in c python's eval

00:06:58,720 --> 00:07:02,639
loop

00:07:00,319 --> 00:07:03,840
this is where pidgin comes in pidgin is

00:07:02,639 --> 00:07:06,560
a jit compiler for c

00:07:03,840 --> 00:07:06,960
python byte code you can pip install it

00:07:06,560 --> 00:07:11,520
from pi

00:07:06,960 --> 00:07:14,160
pi and it's compatible with c python 3.9

00:07:11,520 --> 00:07:15,280
pidgin is compiled for linux mac os and

00:07:14,160 --> 00:07:17,520
windows

00:07:15,280 --> 00:07:18,880
it supports 64-bit intel cpu

00:07:17,520 --> 00:07:21,520
architectures

00:07:18,880 --> 00:07:23,599
and i'll work on arm support if somebody

00:07:21,520 --> 00:07:25,759
can buy me an m1

00:07:23,599 --> 00:07:27,199
something i want to make super clear

00:07:25,759 --> 00:07:30,560
pidgin is not

00:07:27,199 --> 00:07:34,240
another python interpreter it works

00:07:30,560 --> 00:07:36,479
inside c python 3.9

00:07:34,240 --> 00:07:39,440
pigeon is not a new project either it

00:07:36,479 --> 00:07:42,400
was originally presented at pycon 2016

00:07:39,440 --> 00:07:45,840
by brett cannon and de la villand it was

00:07:42,400 --> 00:07:48,479
written against the python 3.6 bytecode

00:07:45,840 --> 00:07:50,720
it also only worked on windows and it

00:07:48,479 --> 00:07:54,000
required a custom build of python

00:07:50,720 --> 00:07:56,080
because it required pep523 which

00:07:54,000 --> 00:07:58,560
wasn't yet merged and then was later

00:07:56,080 --> 00:08:01,280
introduced in python 3.7

00:07:58,560 --> 00:08:01,919
it was also written for a jet compiler

00:08:01,280 --> 00:08:05,280
based on

00:08:01,919 --> 00:08:08,560
net core 1.0 beta which

00:08:05,280 --> 00:08:10,879
is long since passed so i have

00:08:08,560 --> 00:08:12,000
all intents and purposes rewritten the

00:08:10,879 --> 00:08:14,319
original project

00:08:12,000 --> 00:08:16,319
over the last nine months the design of

00:08:14,319 --> 00:08:18,000
it is very similar but there's some

00:08:16,319 --> 00:08:19,440
fundamental changes which i want to talk

00:08:18,000 --> 00:08:21,199
about

00:08:19,440 --> 00:08:23,120
i know the original project was seeking

00:08:21,199 --> 00:08:25,919
optimizations through the use of

00:08:23,120 --> 00:08:27,919
unboxing integers and floats but i've

00:08:25,919 --> 00:08:30,400
largely abandoned that idea

00:08:27,919 --> 00:08:31,599
i don't think the effort is worth reward

00:08:30,400 --> 00:08:32,560
and there are better options of

00:08:31,599 --> 00:08:35,680
functions which use

00:08:32,560 --> 00:08:38,800
lots of floats and integers

00:08:35,680 --> 00:08:40,080
pigeon focuses on compatibility if it

00:08:38,800 --> 00:08:43,519
runs and see python

00:08:40,080 --> 00:08:44,640
it should run in pidgin legit startup

00:08:43,519 --> 00:08:47,519
overhead

00:08:44,640 --> 00:08:49,600
should be minimal especially if sub

00:08:47,519 --> 00:08:51,519
interpreters are widely adopted beyond

00:08:49,600 --> 00:08:53,920
python 3.10

00:08:51,519 --> 00:08:56,560
this can't be like waiting for a big vm

00:08:53,920 --> 00:08:58,640
to boot like the java vm

00:08:56,560 --> 00:09:01,120
beyond enabling the jet pigeon should

00:08:58,640 --> 00:09:03,040
not require any changes to the code

00:09:01,120 --> 00:09:04,720
it shouldn't require type annotations or

00:09:03,040 --> 00:09:06,320
wrapper functions

00:09:04,720 --> 00:09:08,160
i'm assuming that people want to use a

00:09:06,320 --> 00:09:10,080
general purpose jet for code

00:09:08,160 --> 00:09:11,360
that they don't control they don't want

00:09:10,080 --> 00:09:13,920
to change

00:09:11,360 --> 00:09:15,600
they really just want to enable legit in

00:09:13,920 --> 00:09:17,680
already working code and have it

00:09:15,600 --> 00:09:19,600
optimized where possible

00:09:17,680 --> 00:09:21,279
and lastly i want this to be able to be

00:09:19,600 --> 00:09:23,040
deployed anywhere

00:09:21,279 --> 00:09:24,480
so if you're using a cloud environment

00:09:23,040 --> 00:09:25,760
where you don't control the python

00:09:24,480 --> 00:09:27,360
that's installed

00:09:25,760 --> 00:09:28,800
you should be able to pip install and

00:09:27,360 --> 00:09:30,560
import pidgin

00:09:28,800 --> 00:09:32,480
this opens up opportunities for all

00:09:30,560 --> 00:09:34,959
sorts of past platforms

00:09:32,480 --> 00:09:35,600
where you can add this to optimize your

00:09:34,959 --> 00:09:40,000
existing

00:09:35,600 --> 00:09:41,519
code to understand how pigeon works

00:09:40,000 --> 00:09:43,519
let's look briefly at the components

00:09:41,519 --> 00:09:46,640
that make up c python's compiler

00:09:43,519 --> 00:09:48,080
and execution process so first you have

00:09:46,640 --> 00:09:51,200
your python code

00:09:48,080 --> 00:09:53,120
this is parsed in python 3.9 using the

00:09:51,200 --> 00:09:54,640
shiny new peg parser

00:09:53,120 --> 00:09:56,640
the parser will read your code and

00:09:54,640 --> 00:09:58,320
understand how and where you've used the

00:09:56,640 --> 00:10:00,399
python syntax

00:09:58,320 --> 00:10:02,320
it will also throw up things like syntax

00:10:00,399 --> 00:10:04,720
errors when you make mistakes

00:10:02,320 --> 00:10:05,440
that couldn't even be parsed the parsed

00:10:04,720 --> 00:10:07,760
code

00:10:05,440 --> 00:10:09,120
is emitted as an abstract syntax tree or

00:10:07,760 --> 00:10:11,519
ast

00:10:09,120 --> 00:10:13,440
asts are very useful representations for

00:10:11,519 --> 00:10:15,440
the python compiler

00:10:13,440 --> 00:10:17,200
the python compiler compiles down each

00:10:15,440 --> 00:10:20,079
function into small sequential

00:10:17,200 --> 00:10:21,920
atomic commands called bytecodes these

00:10:20,079 --> 00:10:24,560
bytecodes are cached on disk

00:10:21,920 --> 00:10:26,560
in your dunder pi cache folder and each

00:10:24,560 --> 00:10:28,399
time python executes your code

00:10:26,560 --> 00:10:30,240
it will loop through the bytecodes and

00:10:28,399 --> 00:10:32,000
call the corresponding apis

00:10:30,240 --> 00:10:33,440
within cpython to bring your code to

00:10:32,000 --> 00:10:35,360
life

00:10:33,440 --> 00:10:36,720
it also does the work of interconnecting

00:10:35,360 --> 00:10:38,640
with c extensions

00:10:36,720 --> 00:10:39,839
handling memory allocation threading

00:10:38,640 --> 00:10:43,360
garbage collector

00:10:39,839 --> 00:10:45,120
and quite a lot else so pigeon inserts

00:10:43,360 --> 00:10:47,200
itself between the compiler and the

00:10:45,120 --> 00:10:50,160
evaluation stages

00:10:47,200 --> 00:10:52,399
it will recompile the python byte code

00:10:50,160 --> 00:10:54,079
into native machine code

00:10:52,399 --> 00:10:56,480
and it does this at run time which is

00:10:54,079 --> 00:10:58,240
what makes it a jit compiler

00:10:56,480 --> 00:11:00,560
pidgin will kick in when a function is

00:10:58,240 --> 00:11:02,640
run a certain number of times

00:11:00,560 --> 00:11:04,000
it compiles the python byte code into an

00:11:02,640 --> 00:11:07,120
intermediary language

00:11:04,000 --> 00:11:09,120
called ecmasil ecmascell is used by

00:11:07,120 --> 00:11:12,079
the.net compiler

00:11:09,120 --> 00:11:14,480
this is the.net 5 compiler not to be

00:11:12,079 --> 00:11:17,200
confused with i guess the older.net

00:11:14,480 --> 00:11:18,800
the use of the net 5 jit is really an

00:11:17,200 --> 00:11:20,320
implementation detail

00:11:18,800 --> 00:11:22,399
and in no way it helps you doing

00:11:20,320 --> 00:11:24,160
anything.net related or working with any

00:11:22,399 --> 00:11:27,200
dotnet apis

00:11:24,160 --> 00:11:29,680
it was selected because the sill

00:11:27,200 --> 00:11:31,120
is a good cross-platform low-level il

00:11:29,680 --> 00:11:33,519
and net5's

00:11:31,120 --> 00:11:35,440
ryujip compiler is a mature

00:11:33,519 --> 00:11:38,480
well-supported jit compiler

00:11:35,440 --> 00:11:41,680
that it supports intel cpu x64

00:11:38,480 --> 00:11:44,720
and arm so the compiled code is

00:11:41,680 --> 00:11:45,600
assembly well actually it's machine code

00:11:44,720 --> 00:11:48,720
but it's

00:11:45,600 --> 00:11:50,800
a compile binary kept in memory

00:11:48,720 --> 00:11:53,360
so pigeon compiles each of your python

00:11:50,800 --> 00:11:55,519
functions into executable symbols and it

00:11:53,360 --> 00:11:57,920
caches them in ram

00:11:55,519 --> 00:12:01,440
all of this is really theoretical and a

00:11:57,920 --> 00:12:01,440
lot easier to explain with a demo

00:12:03,120 --> 00:12:07,200
pidgin is pip installable so you start

00:12:05,440 --> 00:12:08,800
off with the python 3.9 virtual

00:12:07,200 --> 00:12:11,839
environment

00:12:08,800 --> 00:12:11,839
pip install pigeon

00:12:12,240 --> 00:12:19,040
start up a python 3.9 repel and we can

00:12:15,680 --> 00:12:19,040
see the compiler in action

00:12:19,920 --> 00:12:25,680
let's define a crude python function

00:12:22,399 --> 00:12:28,160
that divides numbers in half

00:12:25,680 --> 00:12:28,880
so we'll take an input of x and we'll

00:12:28,160 --> 00:12:31,920
return

00:12:28,880 --> 00:12:33,600
x divided by 2.

00:12:31,920 --> 00:12:35,760
so once you declare this function on the

00:12:33,600 --> 00:12:38,399
ripple c python will have compiled it

00:12:35,760 --> 00:12:41,440
and stored the code object in the dunder

00:12:38,399 --> 00:12:43,360
code attribute of the function object

00:12:41,440 --> 00:12:44,800
you can disassemble the function into c

00:12:43,360 --> 00:12:49,200
python bytecode

00:12:44,800 --> 00:12:49,200
using this method in the disk module

00:12:49,360 --> 00:12:54,240
if you use pidgin you first need to

00:12:51,600 --> 00:12:56,010
import the pigeon package

00:12:54,240 --> 00:12:57,920
and then enable the jit compiler

00:12:56,010 --> 00:13:00,800
[Music]

00:12:57,920 --> 00:13:01,760
if you execute the half function the jit

00:13:00,800 --> 00:13:04,000
will kick in

00:13:01,760 --> 00:13:06,560
and compile those python byte codes into

00:13:04,000 --> 00:13:08,480
machine code

00:13:06,560 --> 00:13:10,480
pidgin uses a hidden field in the code

00:13:08,480 --> 00:13:12,480
object called co extra

00:13:10,480 --> 00:13:14,880
to store a dictionary of attributes of

00:13:12,480 --> 00:13:16,639
its jit compiled state

00:13:14,880 --> 00:13:18,720
this includes the binary instructions

00:13:16,639 --> 00:13:20,560
for the compiled function

00:13:18,720 --> 00:13:24,560
you can see the status of this by using

00:13:20,560 --> 00:13:26,160
the info function in the pigeon module

00:13:24,560 --> 00:13:27,680
this result tells us that it has

00:13:26,160 --> 00:13:31,839
compiled the function

00:13:27,680 --> 00:13:35,360
it's executed once and the pgc status is

00:13:31,839 --> 00:13:37,120
one which i'll come to later i've also

00:13:35,360 --> 00:13:40,399
included a disassembler

00:13:37,120 --> 00:13:42,639
into pigeon so you can see both the

00:13:40,399 --> 00:13:45,040
ecmasil instructions as well as the

00:13:42,639 --> 00:13:46,560
assembly you can seal the still

00:13:45,040 --> 00:13:49,519
instructions by using the

00:13:46,560 --> 00:13:51,199
pigeon.disk module and then calling the

00:13:49,519 --> 00:13:53,279
dysfunction and passing it the function

00:13:51,199 --> 00:13:55,440
object

00:13:53,279 --> 00:13:57,040
the method calls in il are referencing

00:13:55,440 --> 00:13:59,199
python c api

00:13:57,040 --> 00:14:00,880
so pidgin will use your operating

00:13:59,199 --> 00:14:03,199
system's abi

00:14:00,880 --> 00:14:05,440
to call the python 3.9 c api where

00:14:03,199 --> 00:14:07,360
required

00:14:05,440 --> 00:14:08,959
in the case of this half function it

00:14:07,360 --> 00:14:09,760
will call the pi number underscore

00:14:08,959 --> 00:14:12,320
divide

00:14:09,760 --> 00:14:14,320
which is part of the c api because it

00:14:12,320 --> 00:14:16,480
has no idea what x is

00:14:14,320 --> 00:14:17,920
so it's just going to say right i assume

00:14:16,480 --> 00:14:20,560
it's a number and i'll just do the

00:14:17,920 --> 00:14:21,760
division operator

00:14:20,560 --> 00:14:24,079
you can go a level deeper and

00:14:21,760 --> 00:14:27,199
disassemble the compiled machine code

00:14:24,079 --> 00:14:28,480
into x86 using this underscore native

00:14:27,199 --> 00:14:29,760
function

00:14:28,480 --> 00:14:32,160
if you want to use an external

00:14:29,760 --> 00:14:34,959
disassembler you can dump the compiled

00:14:32,160 --> 00:14:35,760
binary code using pidgin.dump native to

00:14:34,959 --> 00:14:37,680
disk

00:14:35,760 --> 00:14:40,959
and then load it directly using a tool

00:14:37,680 --> 00:14:40,959
like hopper for example

00:14:41,680 --> 00:14:45,920
so a function that divides numbers in

00:14:43,839 --> 00:14:47,839
half is pretty unimpressive

00:14:45,920 --> 00:14:50,399
um so let's try something a bit more

00:14:47,839 --> 00:14:50,399
interesting

00:14:50,880 --> 00:14:57,199
this is a dead simple flask application

00:14:54,160 --> 00:14:58,480
and i've bundled a whiskey middleware

00:14:57,199 --> 00:15:00,560
with pigeon

00:14:58,480 --> 00:15:02,639
that all it really does is when it

00:15:00,560 --> 00:15:05,519
initializes it enables the

00:15:02,639 --> 00:15:07,120
jits so you can use it with frameworks

00:15:05,519 --> 00:15:09,600
like flask and django

00:15:07,120 --> 00:15:11,600
and if you've deployed it with a web

00:15:09,600 --> 00:15:14,639
worker a whiskey worker

00:15:11,600 --> 00:15:16,720
like g unicorn for example it'll enable

00:15:14,639 --> 00:15:18,480
the jet compiler on your whiskey workers

00:15:16,720 --> 00:15:19,920
so that your web application

00:15:18,480 --> 00:15:22,560
your routes your functions and

00:15:19,920 --> 00:15:24,160
everything will all be jet compiled

00:15:22,560 --> 00:15:26,720
so once you've added this whiskey

00:15:24,160 --> 00:15:30,000
middleware just use flask as normal

00:15:26,720 --> 00:15:30,000
so if we start up that script

00:15:30,720 --> 00:15:34,800
right and we can see that's running and

00:15:32,320 --> 00:15:37,680
listening on the port

00:15:34,800 --> 00:15:39,759
and flask is working as normal so this

00:15:37,680 --> 00:15:41,360
required absolutely no change just the

00:15:39,759 --> 00:15:42,800
existing code

00:15:41,360 --> 00:15:44,639
other than obviously to import the

00:15:42,800 --> 00:15:46,320
whiskey module but that can be done once

00:15:44,639 --> 00:15:48,079
at the application level

00:15:46,320 --> 00:15:50,160
you don't need to decorate any functions

00:15:48,079 --> 00:15:52,160
you don't need to change any functions

00:15:50,160 --> 00:15:53,680
your existing application should just

00:15:52,160 --> 00:15:56,959
work

00:15:53,680 --> 00:15:59,040
so in this demo i skimmed over a couple

00:15:56,959 --> 00:16:01,360
of things

00:15:59,040 --> 00:16:03,199
pidgin works by attaching a special jit

00:16:01,360 --> 00:16:06,639
object to code objects

00:16:03,199 --> 00:16:08,240
this is actually permitted per pep 523

00:16:06,639 --> 00:16:10,240
this isn't a hacky thing that we've come

00:16:08,240 --> 00:16:12,160
up with

00:16:10,240 --> 00:16:14,079
this special object contains the

00:16:12,160 --> 00:16:16,800
compiled binary for your function

00:16:14,079 --> 00:16:19,040
as well as some other handy data c

00:16:16,800 --> 00:16:20,399
python is still the thing that parses

00:16:19,040 --> 00:16:21,519
the code

00:16:20,399 --> 00:16:23,519
you don't need to worry about whether

00:16:21,519 --> 00:16:26,079
the syntax will be compatible

00:16:23,519 --> 00:16:27,920
pidgin never reads the code it works at

00:16:26,079 --> 00:16:29,839
a bytecode level

00:16:27,920 --> 00:16:32,959
pidgin compiles the bytecode from python

00:16:29,839 --> 00:16:35,519
3.9 into machine code

00:16:32,959 --> 00:16:39,839
when you enable pidgin it tells c python

00:16:35,519 --> 00:16:39,839
that pigeon will now evaluate frames

00:16:40,399 --> 00:16:45,360
so after pigeon has been enabled

00:16:43,440 --> 00:16:46,800
pigeon will now evaluate all frames

00:16:45,360 --> 00:16:48,639
regardless of whether or not they have

00:16:46,800 --> 00:16:50,639
been jit compiled

00:16:48,639 --> 00:16:51,920
if it detects that the function hasn't

00:16:50,639 --> 00:16:55,199
yet been compiled

00:16:51,920 --> 00:16:55,199
it will compile it in line

00:16:55,600 --> 00:16:59,120
so this sounds pretty awesome you saw

00:16:57,120 --> 00:17:02,880
that assembly code in the screen

00:16:59,120 --> 00:17:06,079
so this must be ridiculously fast right

00:17:02,880 --> 00:17:08,160
sadly no at least not yet the

00:17:06,079 --> 00:17:10,480
jitters code you saw is still calling

00:17:08,160 --> 00:17:13,199
the c python c api

00:17:10,480 --> 00:17:14,480
and the c of l loop is also compiled

00:17:13,199 --> 00:17:16,480
code so

00:17:14,480 --> 00:17:18,240
the c compiler does probably a much

00:17:16,480 --> 00:17:20,000
better job actually of writing assembly

00:17:18,240 --> 00:17:22,480
than i would

00:17:20,000 --> 00:17:23,360
so in terms of performance it doesn't

00:17:22,480 --> 00:17:25,760
make a difference

00:17:23,360 --> 00:17:28,240
just to call the same api and have it

00:17:25,760 --> 00:17:28,240
compiled

00:17:28,960 --> 00:17:34,640
jit compilers are faster only when they

00:17:32,000 --> 00:17:37,280
can make optimizations

00:17:34,640 --> 00:17:38,400
so far pigeon has 15 optimizations i've

00:17:37,280 --> 00:17:40,400
written

00:17:38,400 --> 00:17:42,160
and i think when it's really pushing the

00:17:40,400 --> 00:17:43,679
boundaries that numbers can be more like

00:17:42,160 --> 00:17:45,679
a hundred

00:17:43,679 --> 00:17:48,559
all of these optimizations are patterns

00:17:45,679 --> 00:17:51,360
that can be observed with a code object

00:17:48,559 --> 00:17:53,280
when it's compiling so pidgin uses them

00:17:51,360 --> 00:17:55,280
to emit faster code which is still

00:17:53,280 --> 00:17:56,720
compatible with the equivalent c python

00:17:55,280 --> 00:17:58,880
code

00:17:56,720 --> 00:18:02,160
so as an example let's roll back to end

00:17:58,880 --> 00:18:04,559
body i'll show you two optimizations

00:18:02,160 --> 00:18:06,320
that make a dent on the execution time

00:18:04,559 --> 00:18:08,640
when you use pigeon

00:18:06,320 --> 00:18:10,559
the first is really simple pigeon will

00:18:08,640 --> 00:18:11,840
notice that when you access an item in a

00:18:10,559 --> 00:18:14,400
list or tuple

00:18:11,840 --> 00:18:16,480
using a constant index like here the

00:18:14,400 --> 00:18:18,640
number zero one

00:18:16,480 --> 00:18:19,760
instead of using the pi long object for

00:18:18,640 --> 00:18:22,640
the index

00:18:19,760 --> 00:18:25,280
it uses the much faster capi method for

00:18:22,640 --> 00:18:28,559
getting an item out of a list or tuple

00:18:25,280 --> 00:18:30,160
using a c integer the second

00:18:28,559 --> 00:18:31,360
optimization is one i talked about at

00:18:30,160 --> 00:18:33,280
the beginning

00:18:31,360 --> 00:18:34,880
when pidgin notices that a statement

00:18:33,280 --> 00:18:37,120
uses two sequential

00:18:34,880 --> 00:18:38,000
mathematical operations on a float or

00:18:37,120 --> 00:18:40,160
long

00:18:38,000 --> 00:18:41,280
it will keep the carryover value in its

00:18:40,160 --> 00:18:44,799
native type

00:18:41,280 --> 00:18:46,400
instead of constructing a new pi object

00:18:44,799 --> 00:18:48,000
this takes effect for in-place

00:18:46,400 --> 00:18:49,520
operations as well

00:18:48,000 --> 00:18:51,520
like these in-place additions and

00:18:49,520 --> 00:18:53,280
subtractions

00:18:51,520 --> 00:18:55,360
the result of the right-hand side of the

00:18:53,280 --> 00:18:57,120
statement is kept as a native c

00:18:55,360 --> 00:18:59,520
float and the additional pi object is

00:18:57,120 --> 00:19:01,919
never allocated

00:18:59,520 --> 00:19:03,679
so these aren't massive improvements but

00:19:01,919 --> 00:19:05,440
they're patterns which i've observed in

00:19:03,679 --> 00:19:07,840
a lot of other python code as well

00:19:05,440 --> 00:19:10,000
so they don't just apply to anybody they

00:19:07,840 --> 00:19:11,679
can be used

00:19:10,000 --> 00:19:13,679
for a number of different scenarios and

00:19:11,679 --> 00:19:16,320
actually work really nicely in a general

00:19:13,679 --> 00:19:16,320
purpose jit

00:19:16,559 --> 00:19:20,080
so one of the biggest challenges any

00:19:18,400 --> 00:19:21,919
python optimization

00:19:20,080 --> 00:19:24,000
is going to have is trying to establish

00:19:21,919 --> 00:19:25,360
what type things are

00:19:24,000 --> 00:19:27,520
so i'm working on a feature at the

00:19:25,360 --> 00:19:29,280
moment called profile guided compilation

00:19:27,520 --> 00:19:32,160
or pgc

00:19:29,280 --> 00:19:33,200
the concept is that python is really

00:19:32,160 --> 00:19:35,200
dynamic

00:19:33,200 --> 00:19:36,480
it's very hard to determine the types of

00:19:35,200 --> 00:19:39,360
variables

00:19:36,480 --> 00:19:41,440
however the types at particular opcode

00:19:39,360 --> 00:19:41,919
positions don't tend to change much

00:19:41,440 --> 00:19:45,520
between

00:19:41,919 --> 00:19:46,240
executions of a function if you execute

00:19:45,520 --> 00:19:48,559
a function

00:19:46,240 --> 00:19:49,679
thousand times and every single time you

00:19:48,559 --> 00:19:52,160
send it a string

00:19:49,679 --> 00:19:54,400
and it works with strings let's optimize

00:19:52,160 --> 00:19:56,720
it for strings

00:19:54,400 --> 00:19:58,799
pgc doesn't interpret the ast like other

00:19:56,720 --> 00:20:00,559
typing tools it's a profiler

00:19:58,799 --> 00:20:02,640
so when you run the jitted function the

00:20:00,559 --> 00:20:04,400
first time it can pass some probes into

00:20:02,640 --> 00:20:06,320
the machine code

00:20:04,400 --> 00:20:08,400
these capture any types that pigeon is

00:20:06,320 --> 00:20:10,480
particularly interested in

00:20:08,400 --> 00:20:12,320
when you run the function again it will

00:20:10,480 --> 00:20:14,400
use the profile

00:20:12,320 --> 00:20:17,360
and then start to make some assumptions

00:20:14,400 --> 00:20:20,720
about what it can and can't optimize

00:20:17,360 --> 00:20:21,200
the pgc state is either uncompiled which

00:20:20,720 --> 00:20:22,720
means

00:20:21,200 --> 00:20:25,520
the jet compiler has never seen it

00:20:22,720 --> 00:20:28,159
before the second stage is to compile it

00:20:25,520 --> 00:20:30,640
as a generic function with probes

00:20:28,159 --> 00:20:31,760
which then basically emits the profile

00:20:30,640 --> 00:20:33,679
data

00:20:31,760 --> 00:20:35,280
and then when the function is executed

00:20:33,679 --> 00:20:37,120
again it will see

00:20:35,280 --> 00:20:38,799
that it has the profile data and it will

00:20:37,120 --> 00:20:40,640
recompile the function

00:20:38,799 --> 00:20:42,159
and then include any optimizations that

00:20:40,640 --> 00:20:43,760
it can make

00:20:42,159 --> 00:20:45,440
you can see which stage it's at using

00:20:43,760 --> 00:20:48,640
the pidgin.info function

00:20:45,440 --> 00:20:50,480
that i demoed earlier

00:20:48,640 --> 00:20:52,640
so let's take another example this is a

00:20:50,480 --> 00:20:54,799
simple function in the django source

00:20:52,640 --> 00:20:57,600
code for listing static files for a

00:20:54,799 --> 00:21:01,400
particular storage location

00:20:57,600 --> 00:21:05,039
the first time it runs ptc says hey

00:21:01,400 --> 00:21:06,960
self.locations is a list self.storages

00:21:05,039 --> 00:21:09,440
is a dictionary

00:21:06,960 --> 00:21:12,400
and then when it recompiles the function

00:21:09,440 --> 00:21:15,120
with the pgc profile data it says

00:21:12,400 --> 00:21:16,400
okay let's optimize that in case the

00:21:15,120 --> 00:21:19,919
types do change

00:21:16,400 --> 00:21:20,640
it compiles a type guard to inspect the

00:21:19,919 --> 00:21:23,360
value

00:21:20,640 --> 00:21:25,360
at runtime and if it isn't what it was

00:21:23,360 --> 00:21:28,559
expecting based on the profile data

00:21:25,360 --> 00:21:31,520
it will default back to the generic path

00:21:28,559 --> 00:21:32,880
so coming back to the end body algorithm

00:21:31,520 --> 00:21:34,480
i'm actually currently getting about a

00:21:32,880 --> 00:21:38,080
third of the execution time

00:21:34,480 --> 00:21:40,640
in pidgin compared to c python 3.9

00:21:38,080 --> 00:21:42,080
other benchmarks are showing promise are

00:21:40,640 --> 00:21:45,039
the fancook

00:21:42,080 --> 00:21:46,240
and the float benchmarks which have

00:21:45,039 --> 00:21:48,799
around 20

00:21:46,240 --> 00:21:51,200
speed improvement at the moment my

00:21:48,799 --> 00:21:54,080
philosophy is that anything below 20

00:21:51,200 --> 00:21:55,280
isn't worth the effort so i'm looking

00:21:54,080 --> 00:21:57,520
really

00:21:55,280 --> 00:21:59,280
much higher than that um looking to see

00:21:57,520 --> 00:22:01,520
if we can get multiples of performance

00:21:59,280 --> 00:22:03,760
off this

00:22:01,520 --> 00:22:04,799
so in conclusion i'd love some help on

00:22:03,760 --> 00:22:07,200
this

00:22:04,799 --> 00:22:08,320
jig compilers are really fun to work on

00:22:07,200 --> 00:22:09,919
and

00:22:08,320 --> 00:22:11,440
there are at this stage thousands of

00:22:09,919 --> 00:22:13,280
tests so you can see all sorts of

00:22:11,440 --> 00:22:15,120
different scenarios and how this can be

00:22:13,280 --> 00:22:17,120
worked and used

00:22:15,120 --> 00:22:19,120
i think the idea has a lot of potential

00:22:17,120 --> 00:22:22,000
as a drop-in module to optimize c

00:22:19,120 --> 00:22:23,919
python and optimize code which would

00:22:22,000 --> 00:22:25,840
really benefit from a jit

00:22:23,919 --> 00:22:27,919
and then have a transparent effect on

00:22:25,840 --> 00:22:30,400
code which doesn't

00:22:27,919 --> 00:22:32,320
and lastly the more i look into this i'm

00:22:30,400 --> 00:22:34,240
finding problems that the piper project

00:22:32,320 --> 00:22:37,039
has already solved

00:22:34,240 --> 00:22:38,480
so check out pi pi and see whether your

00:22:37,039 --> 00:22:40,400
code works with pi pi i think they've

00:22:38,480 --> 00:22:42,240
done a brilliant job already

00:22:40,400 --> 00:22:43,760
there's a lot of brilliant science and

00:22:42,240 --> 00:22:45,039
research that's gone into pie pie and

00:22:43,760 --> 00:22:46,640
legit

00:22:45,039 --> 00:22:50,000
and it can make a drastic difference to

00:22:46,640 --> 00:22:52,080
the performance of your code already

00:22:50,000 --> 00:22:54,720
so the documentation for this project is

00:22:52,080 --> 00:22:56,080
up at pidgin.readthedocs.i

00:22:54,720 --> 00:22:58,400
and the source is on my github

00:22:56,080 --> 00:23:01,520
repository at github.com

00:22:58,400 --> 00:23:03,039
tony baloney slash pidgin if you want to

00:23:01,520 --> 00:23:03,840
understand more about c python's

00:23:03,039 --> 00:23:06,480
compiler

00:23:03,840 --> 00:23:08,240
the eval loop memory management i cover

00:23:06,480 --> 00:23:09,200
all of this in my c python internals

00:23:08,240 --> 00:23:12,000
book

00:23:09,200 --> 00:23:13,679
and you can follow my blog on my website

00:23:12,000 --> 00:23:15,200
for the latest on what i'm working on or

00:23:13,679 --> 00:23:23,840
follow me on twitter

00:23:15,200 --> 00:23:23,840
thank you and enjoy the rest of pycon

00:24:24,960 --> 00:24:27,039

YouTube URL: https://www.youtube.com/watch?v=YFeUUdKBrJ8


