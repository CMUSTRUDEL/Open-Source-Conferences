Title: Matthew Rocklin - Democratizing Distributed Computing with Dask and JupyterHub - PyCon 2018
Publication date: 2018-08-06
Playlist: Talks
Description: 
	Speaker: Matthew Rocklin

We use JupyterHub, XArray, Dask, and Kubernetes to build a cloud-based system to enable scientists to analyze and manage large datasets.  We use this in practice to serve a broad community of atmospheric and climate scientists.

Atmospheric and climate scientists analyze large volumes of observational and simulated data to better understand our planet.  They have historically used tools like NumPy and SciPy along with Jupyter notebooks to combine efficient computation with accessibility.  However, as datasets increase in size and collaboration extends to new populations of scientists these tools begin to feel their age.  In this talk we use more recent libraries to build a modern deployment for academic scientists.  In particular we use the following tools:

- **Dask:** to parallelize and scale NumPy computations
- **XArray**: as a self-discribing data model and tool kit for labeled and index arrays
- **JupyterLab:** to enable more APIs for users beyond the classic notebook
- **JupyterHub:** to manage users and maintain environments for a new population of cloud-friendly users
- **Kubernetes:** to manage everything and deploy easily on cloud hardware

This talk will focus less on how these libraries work and will instead be a case study of using them together in an operational setting.  During the talk we will build up and deploy a running system that the audience can then use to access distributed computing resources.


Slides can be found at: https://speakerdeck.com/pycon2018 and https://github.com/PyCon/2018-slides
Captions: 
	00:00:00,319 --> 00:00:06,629
okay we're gonna get okay we're gonna

00:00:03,750 --> 00:00:11,120
get started I'd like to welcome Matthew

00:00:06,629 --> 00:00:11,120
Rocklin from anaconda for the next talk

00:00:11,720 --> 00:00:17,070
[Applause]

00:00:15,049 --> 00:00:19,260
great thank you Peter thank you so much

00:00:17,070 --> 00:00:20,580
for having me here so my name is Matthew

00:00:19,260 --> 00:00:23,070
Rocklin I'm an open source software

00:00:20,580 --> 00:00:25,410
developer at anaconda anicon is a

00:00:23,070 --> 00:00:27,180
for-profit company inside the Moors for

00:00:25,410 --> 00:00:28,949
the data science oriented part of Python

00:00:27,180 --> 00:00:30,570
sure if you're familiar with libraries

00:00:28,949 --> 00:00:33,450
like numpy or pandas or scikit-learn

00:00:30,570 --> 00:00:36,660
this for the space of tools that we sort

00:00:33,450 --> 00:00:38,219
of care about my job is to improve the

00:00:36,660 --> 00:00:40,290
performance of those tools so I operate

00:00:38,219 --> 00:00:41,640
and Charlie the open source I mostly

00:00:40,290 --> 00:00:43,350
care about parallel and scalable

00:00:41,640 --> 00:00:46,829
computing mostly with a library called

00:00:43,350 --> 00:00:48,960
desk and most talks that have are about

00:00:46,829 --> 00:00:50,010
desk this talks to me a little bit

00:00:48,960 --> 00:00:51,600
different to be a little bit more

00:00:50,010 --> 00:00:54,329
high-level a little less technical and

00:00:51,600 --> 00:00:56,460
we talk about collaboration I've had the

00:00:54,329 --> 00:00:59,340
privilege to being a part of with tools

00:00:56,460 --> 00:01:01,050
like x-ray and Jupiter hub to help a lot

00:00:59,340 --> 00:01:04,019
of I'm a spheric scientists and

00:01:01,050 --> 00:01:06,450
oceanographic scientists interact with

00:01:04,019 --> 00:01:07,619
large-scale data sets on the cloud that

00:01:06,450 --> 00:01:09,750
collaboration goes under the name pan

00:01:07,619 --> 00:01:13,380
geo it's welcome to any people who might

00:01:09,750 --> 00:01:14,729
be the audience I mostly talked to

00:01:13,380 --> 00:01:16,770
scientists and mostly talk people who

00:01:14,729 --> 00:01:18,840
understand hard core numerical computing

00:01:16,770 --> 00:01:20,220
this group is I think different there's

00:01:18,840 --> 00:01:22,979
more mix which I really was right I

00:01:20,220 --> 00:01:25,020
really like coming to Python so my goals

00:01:22,979 --> 00:01:27,259
are a bit a little bit different here so

00:01:25,020 --> 00:01:29,250
we're talking about a few Python tools

00:01:27,259 --> 00:01:31,170
once it is mentioned and a couple others

00:01:29,250 --> 00:01:32,880
to do atmospheric and oceanographic

00:01:31,170 --> 00:01:36,689
science I'm assuming people here don't

00:01:32,880 --> 00:01:39,420
do these Sciences any oceanographers or

00:01:36,689 --> 00:01:41,869
amateur scientists in the room there's

00:01:39,420 --> 00:01:45,869
Filipe and a couple person I don't know

00:01:41,869 --> 00:01:47,520
yeah so it's it's it's a fun topic so

00:01:45,869 --> 00:01:49,259
our goals here to provide some context

00:01:47,520 --> 00:01:50,970
for scientific Python who who aren't

00:01:49,259 --> 00:01:53,100
familiar with numpy understand how it

00:01:50,970 --> 00:01:54,990
gets used I want to sort maybe attract

00:01:53,100 --> 00:01:56,430
some other scientific groups to this

00:01:54,990 --> 00:01:57,869
collaboration it's been a really

00:01:56,430 --> 00:02:00,509
fruitful things so far I think we could

00:01:57,869 --> 00:02:02,909
expand and I also want to encourage some

00:02:00,509 --> 00:02:04,409
non science people to help out so it

00:02:02,909 --> 00:02:07,229
turns out that doing science requires a

00:02:04,409 --> 00:02:08,759
lot of non and science skills many

00:02:07,229 --> 00:02:10,590
skills that I think are in the room so

00:02:08,759 --> 00:02:12,780
please come and help I feel like this

00:02:10,590 --> 00:02:13,380
has been the my effort to reduce carbon

00:02:12,780 --> 00:02:15,870
in the world

00:02:13,380 --> 00:02:17,940
has been maximized by this effort so

00:02:15,870 --> 00:02:21,860
please come on body and also learn a

00:02:17,940 --> 00:02:27,480
little bit about your associates so

00:02:21,860 --> 00:02:31,890
great slides are available on Matthew

00:02:27,480 --> 00:02:36,810
Rocklin comm slash slides /pi con 2018

00:02:31,890 --> 00:02:40,470
HTML for just a moment also tweet these

00:02:36,810 --> 00:02:43,950
slides in a moment so we live here and

00:02:40,470 --> 00:02:47,010
we measure the earth quite a bit we have

00:02:43,950 --> 00:02:48,420
cameras in space we also that gives of

00:02:47,010 --> 00:02:50,550
other things in space things like radar

00:02:48,420 --> 00:02:52,050
and lidar systems that do a variety of

00:02:50,550 --> 00:02:53,730
interesting scientific instruments that

00:02:52,050 --> 00:02:55,230
look down on us we have ground-based

00:02:53,730 --> 00:02:58,350
observations you have lots of things we

00:02:55,230 --> 00:03:00,230
measure we also do simulations so I'm

00:02:58,350 --> 00:03:03,000
gonna switch to a video for a moment

00:03:00,230 --> 00:03:07,230
this is a simulation of the Earth's

00:03:03,000 --> 00:03:09,690
oceans at some resolution some high

00:03:07,230 --> 00:03:11,250
resolution of his run it's not an

00:03:09,690 --> 00:03:13,290
observation this is a simulation that

00:03:11,250 --> 00:03:14,670
runs in a giant supercomputer this

00:03:13,290 --> 00:03:17,460
generates I think something like 2

00:03:14,670 --> 00:03:18,870
petabytes of data every time it runs and

00:03:17,460 --> 00:03:20,850
this helps us understand how the oceans

00:03:18,870 --> 00:03:23,520
in the atmosphere exchange heat amongst

00:03:20,850 --> 00:03:25,590
each other in fun fun waves so you can

00:03:23,520 --> 00:03:27,930
see things here like a nice a nice sort

00:03:25,590 --> 00:03:28,860
of stream coming off of Japan I think if

00:03:27,930 --> 00:03:32,910
we sort of move forward a little bit

00:03:28,860 --> 00:03:34,230
we'll see the Gulf Stream so there's a

00:03:32,910 --> 00:03:35,430
lot of structure here and understanding

00:03:34,230 --> 00:03:37,410
this structure is very important to

00:03:35,430 --> 00:03:39,860
understanding how we hope you can need

00:03:37,410 --> 00:03:39,860
to live on this planet

00:03:41,060 --> 00:03:45,480
so first we measure the earth either

00:03:43,980 --> 00:03:47,070
with observations or a simulation and

00:03:45,480 --> 00:03:48,810
then scientists do a lot of analysis

00:03:47,070 --> 00:03:50,190
they typically do this analysis in

00:03:48,810 --> 00:03:54,120
Python Python is becoming the standard

00:03:50,190 --> 00:03:56,250
language to do this sort of work so I'm

00:03:54,120 --> 00:03:58,170
going to do a quick demonstration of how

00:03:56,250 --> 00:04:03,180
people use Python to analyze this sort

00:03:58,170 --> 00:04:06,780
of data I'm gonna use a tool called

00:04:03,180 --> 00:04:09,330
x-ray in a jupiter notebook so I'm gonna

00:04:06,780 --> 00:04:10,140
assume some exposure light exposure to

00:04:09,330 --> 00:04:12,209
jupiter notebooks

00:04:10,140 --> 00:04:14,760
that's a webpage I go to is running on

00:04:12,209 --> 00:04:19,739
my personal computer I'm gonna load some

00:04:14,760 --> 00:04:21,570
data with x-ray so I'm reading some data

00:04:19,739 --> 00:04:24,270
in the netcdf format this is a great

00:04:21,570 --> 00:04:26,640
file format to look at a lot of gridded

00:04:24,270 --> 00:04:27,540
data so a lot of this data isn't like a

00:04:26,640 --> 00:04:29,280
sequel database

00:04:27,540 --> 00:04:31,110
a bunch of records so much of gridded

00:04:29,280 --> 00:04:32,670
data structures so you might have for

00:04:31,110 --> 00:04:34,770
example the temperature and every point

00:04:32,670 --> 00:04:35,940
on the earth at every elevation over

00:04:34,770 --> 00:04:37,980
time and that may be maybe a

00:04:35,940 --> 00:04:39,450
four-dimensional data structure but also

00:04:37,980 --> 00:04:41,310
the temperature and the pressure and the

00:04:39,450 --> 00:04:42,480
wind speed and the humidity many

00:04:41,310 --> 00:04:44,340
different arrays that are related to

00:04:42,480 --> 00:04:47,310
each other so this may be like images

00:04:44,340 --> 00:04:49,020
but maybe maybe more more complex so

00:04:47,310 --> 00:04:52,080
this is a relatively small data set and

00:04:49,020 --> 00:04:53,580
it has the sea surface temperature which

00:04:52,080 --> 00:04:57,720
has dimensions of latitude longitude and

00:04:53,580 --> 00:04:59,880
time so I might like with pandas cut out

00:04:57,720 --> 00:05:02,430
the time coordinate and look at it we

00:04:59,880 --> 00:05:05,400
can see that it's going from 1960 to 19

00:05:02,430 --> 00:05:07,860
2016 I might do some small operation

00:05:05,400 --> 00:05:12,390
like min and see the earliest the status

00:05:07,860 --> 00:05:15,300
that goes back is 1960 so but again this

00:05:12,390 --> 00:05:18,120
is not necessarily pandas data this is n

00:05:15,300 --> 00:05:20,430
dimensional data so here is the average

00:05:18,120 --> 00:05:22,110
of that temperature over time we can see

00:05:20,430 --> 00:05:23,810
that it's it's hotter in the oceans near

00:05:22,110 --> 00:05:26,370
the equator which is not a big surprise

00:05:23,810 --> 00:05:28,950
but it's able to to query that and do

00:05:26,370 --> 00:05:30,630
that reduction relatively easily and so

00:05:28,950 --> 00:05:32,190
I'm doing sort of a high-level analysis

00:05:30,630 --> 00:05:33,810
but using libraries like numpy and

00:05:32,190 --> 00:05:38,930
pandas to do relatively efficient code

00:05:33,810 --> 00:05:41,610
underneath I do something else we might

00:05:38,930 --> 00:05:43,830
select a time range maybe since the

00:05:41,610 --> 00:05:45,480
Millennium we might take an average of a

00:05:43,830 --> 00:05:47,430
longitude sort of look at a latitude in

00:05:45,480 --> 00:05:49,860
time then we're gonna subtract off the

00:05:47,430 --> 00:05:53,700
average over time and this shows us the

00:05:49,860 --> 00:05:55,860
the temperature of the ocean normalized

00:05:53,700 --> 00:05:56,940
on the northern and southern hemisphere

00:05:55,860 --> 00:05:58,980
and you can see things sort of switch

00:05:56,940 --> 00:06:02,040
depending where you are in the summers

00:05:58,980 --> 00:06:04,800
so this is a sort of a modestly complex

00:06:02,040 --> 00:06:06,210
visualization we achieved by relatively

00:06:04,800 --> 00:06:09,360
small lines of literally small what

00:06:06,210 --> 00:06:11,400
lines of code underneath the hood this

00:06:09,360 --> 00:06:13,170
is still just using numpy so numpy is a

00:06:11,400 --> 00:06:15,210
library to deal with gridded data

00:06:13,170 --> 00:06:17,330
structures so does you might find images

00:06:15,210 --> 00:06:21,270
or these hard dimensional structures

00:06:17,330 --> 00:06:23,100
okay so people people like numpy they're

00:06:21,270 --> 00:06:24,390
like x-ray they've been doing this for a

00:06:23,100 --> 00:06:26,880
while

00:06:24,390 --> 00:06:31,200
and so what as well as we saw we saw

00:06:26,880 --> 00:06:33,780
jupiter notebooks we saw netcdf a file

00:06:31,200 --> 00:06:35,310
format an x-ray a computational engine

00:06:33,780 --> 00:06:37,200
that uses numpy and pandas

00:06:35,310 --> 00:06:38,760
to do some queries on that these are

00:06:37,200 --> 00:06:46,860
very common tools in that space

00:06:38,760 --> 00:06:48,570
I'm gonna set a quick timer here so we

00:06:46,860 --> 00:06:50,490
use numpy and pandas to do efficient

00:06:48,570 --> 00:06:52,470
in-memory computation this is using

00:06:50,490 --> 00:06:53,250
Python code to drive C code to run

00:06:52,470 --> 00:06:55,230
quickly

00:06:53,250 --> 00:06:56,940
you'll sees mount pop lab to visualize

00:06:55,230 --> 00:06:58,650
results and this has been going on for a

00:06:56,940 --> 00:07:00,990
long time sort of familiar roughly with

00:06:58,650 --> 00:07:02,310
the scientific Python stack these are

00:07:00,990 --> 00:07:05,250
sort of normal tools that you might be

00:07:02,310 --> 00:07:06,870
familiar with x-ray optionally uses desk

00:07:05,250 --> 00:07:08,430
clever I work on so this works up to

00:07:06,870 --> 00:07:10,590
sort of that 10 gigabyte 200 gigabyte

00:07:08,430 --> 00:07:13,260
scale on a single machine and that's

00:07:10,590 --> 00:07:14,520
again sort of commonly done today we're

00:07:13,260 --> 00:07:16,140
now gonna step forward a little bit and

00:07:14,520 --> 00:07:18,750
see how well we can scale it out to

00:07:16,140 --> 00:07:21,150
larger data sets because remember this

00:07:18,750 --> 00:07:23,490
video with all the swirl eNOS and

00:07:21,150 --> 00:07:25,440
intricate detail in it comes in at

00:07:23,490 --> 00:07:28,110
petabytes so that's no megabytes

00:07:25,440 --> 00:07:29,640
gigabytes terabytes petabytes so you got

00:07:28,110 --> 00:07:36,390
quite a ways to go till we get to

00:07:29,640 --> 00:07:38,430
something like this ok so we used to

00:07:36,390 --> 00:07:40,170
penor notebooks because scientists like

00:07:38,430 --> 00:07:41,340
to code interactively they don't have a

00:07:40,170 --> 00:07:42,600
particular end goal that they're

00:07:41,340 --> 00:07:44,220
shooting towards they need to iterate

00:07:42,600 --> 00:07:45,870
very quickly as they're searching

00:07:44,220 --> 00:07:47,610
they're searching for whatever might be

00:07:45,870 --> 00:07:48,780
interesting in that data set they can't

00:07:47,610 --> 00:07:50,580
write tests and then write to those

00:07:48,780 --> 00:07:54,570
tests it's much more a much more

00:07:50,580 --> 00:07:57,000
interactive flow it also runs in a

00:07:54,570 --> 00:07:58,770
browser and and more or less this is not

00:07:57,000 --> 00:08:01,200
particularly exciting for most people on

00:07:58,770 --> 00:08:02,550
their laptops it's sort of a I created

00:08:01,200 --> 00:08:04,320
server I log in to that server

00:08:02,550 --> 00:08:05,220
everything's running locally it could

00:08:04,320 --> 00:08:06,420
just as well have been a rich client

00:08:05,220 --> 00:08:08,100
application they wouldn't have carried

00:08:06,420 --> 00:08:09,510
we'll see that this is going to be very

00:08:08,100 --> 00:08:11,280
important when we switch to more

00:08:09,510 --> 00:08:12,960
distributed systems when we create

00:08:11,280 --> 00:08:14,730
remote systems for them to work with so

00:08:12,960 --> 00:08:16,440
running in a browser ends up being very

00:08:14,730 --> 00:08:17,970
important that's one reason why we we

00:08:16,440 --> 00:08:18,980
really liked you better as we move

00:08:17,970 --> 00:08:21,660
forward

00:08:18,980 --> 00:08:25,100
so let's look briefly at netcdf in X

00:08:21,660 --> 00:08:28,470
array so again these libraries manage

00:08:25,100 --> 00:08:31,620
collections of regularly gridded

00:08:28,470 --> 00:08:33,599
immodestly typed data like numpy but

00:08:31,620 --> 00:08:35,370
have many different arrays so you might

00:08:33,599 --> 00:08:36,750
have a few arrays like the temperature

00:08:35,370 --> 00:08:38,190
and the pressure might be

00:08:36,750 --> 00:08:39,570
three-dimensional we have an other

00:08:38,190 --> 00:08:41,520
arrays like the land cover or the

00:08:39,570 --> 00:08:44,130
elevation might be two-dimensional you

00:08:41,520 --> 00:08:47,070
might have indexes and an axis like

00:08:44,130 --> 00:08:48,690
longitude intime and these libraries

00:08:47,070 --> 00:08:50,880
collect all of these different arrays

00:08:48,690 --> 00:08:52,170
into one cohesive unit so you can do

00:08:50,880 --> 00:08:53,670
things like take

00:08:52,170 --> 00:08:56,070
average over time and it will average

00:08:53,670 --> 00:08:57,810
everything appropriately you might also

00:08:56,070 --> 00:09:00,029
if you outside of the space think about

00:08:57,810 --> 00:09:01,139
maybe movies a movie might be a

00:09:00,029 --> 00:09:03,630
three-dimensional array of all the

00:09:01,139 --> 00:09:06,060
frames of the film with a time axis and

00:09:03,630 --> 00:09:07,860
two spatial axis ease and then maybe an

00:09:06,060 --> 00:09:09,959
audio track also with sharing the same

00:09:07,860 --> 00:09:12,149
time axis but having maybe a channel

00:09:09,959 --> 00:09:13,470
access their audio tracks so there's

00:09:12,149 --> 00:09:16,760
general technology but happen to be very

00:09:13,470 --> 00:09:19,410
useful in this in the scientific domain

00:09:16,760 --> 00:09:22,820
x-ray uses numpy for competition on the

00:09:19,410 --> 00:09:25,740
individual rays and uses pandas for the

00:09:22,820 --> 00:09:30,480
indexes on a quickly done quickly say

00:09:25,740 --> 00:09:32,639
here that this pandas tabular model only

00:09:30,480 --> 00:09:33,870
really works well for the the

00:09:32,639 --> 00:09:35,430
coordinates on the sides it doesn't work

00:09:33,870 --> 00:09:37,260
well for the actual gridded data inside

00:09:35,430 --> 00:09:39,089
because that that is regularly strided

00:09:37,260 --> 00:09:42,769
it's more gridded it's hard to fit that

00:09:39,089 --> 00:09:42,769
into sort of a classic data based model

00:09:42,889 --> 00:09:48,959
so these tools allow scientists to

00:09:45,899 --> 00:09:50,610
analyze critical data quickly what is we

00:09:48,959 --> 00:09:52,649
like because they are actively fighting

00:09:50,610 --> 00:09:54,389
to keep the planet alive so we should we

00:09:52,649 --> 00:09:56,850
should support them there's some

00:09:54,389 --> 00:09:57,449
challenges datasets are increasing

00:09:56,850 --> 00:09:59,399
rapidly

00:09:57,449 --> 00:10:01,230
NASA is putting in satellites and many

00:09:59,399 --> 00:10:03,300
other agencies international governments

00:10:01,230 --> 00:10:04,350
for-profit companies are putting a bunch

00:10:03,300 --> 00:10:07,440
of satellites into space right now

00:10:04,350 --> 00:10:08,760
they're putting amazing they're trying

00:10:07,440 --> 00:10:10,019
to generate amazing amounts of satellite

00:10:08,760 --> 00:10:12,899
imagery which can really change how we

00:10:10,019 --> 00:10:14,910
understand our planet at the same time

00:10:12,899 --> 00:10:17,040
the average human user is becoming less

00:10:14,910 --> 00:10:19,140
sophisticated we're getting far more

00:10:17,040 --> 00:10:21,209
students who are using these tools with

00:10:19,140 --> 00:10:23,760
far less training also not just students

00:10:21,209 --> 00:10:25,740
but also you know emeritus faculty who

00:10:23,760 --> 00:10:27,529
have far less training in using Python

00:10:25,740 --> 00:10:30,839
we need to lower the barrier to adoption

00:10:27,529 --> 00:10:32,940
they're not able to spin up clusters

00:10:30,839 --> 00:10:34,769
right MPI code that's at the challenge

00:10:32,940 --> 00:10:37,050
so I'm going to show you a thing that

00:10:34,769 --> 00:10:38,519
we've been working on recently if the

00:10:37,050 --> 00:10:41,730
internet works hopefully got a live demo

00:10:38,519 --> 00:10:44,990
if not we'll switch to video so I'm

00:10:41,730 --> 00:10:47,670
running let's restart this for a moment

00:10:44,990 --> 00:10:51,000
so I'm gonna show you a website Pangaea

00:10:47,670 --> 00:10:53,069
org and you can log into this will get

00:10:51,000 --> 00:10:55,519
up credentials and I'm gonna do a much

00:10:53,069 --> 00:10:59,399
larger analysis now thank you

00:10:55,519 --> 00:11:02,670
this is using x-ray again I put on some

00:10:59,399 --> 00:11:04,620
larger data here I'm going to connect it

00:11:02,670 --> 00:11:05,580
to some data stored in the cloud I think

00:11:04,620 --> 00:11:07,200
in total this is a few

00:11:05,580 --> 00:11:08,670
under gigabytes it's not huge but it's

00:11:07,200 --> 00:11:12,630
bigger than I want to work on my laptop

00:11:08,670 --> 00:11:14,550
and we've Reds just some metadata and so

00:11:12,630 --> 00:11:16,200
this data set is like the data set we

00:11:14,550 --> 00:11:19,590
saw before about sea surface temperature

00:11:16,200 --> 00:11:20,940
but it now has many variables we're

00:11:19,590 --> 00:11:24,030
gonna look particularly at the sea level

00:11:20,940 --> 00:11:25,890
altitude which is larger than what we

00:11:24,030 --> 00:11:29,040
had before it's sort of a 10,000 by

00:11:25,890 --> 00:11:32,370
1,000 by 1,000 array and this is the the

00:11:29,040 --> 00:11:35,970
sea level from a high-resolution over

00:11:32,370 --> 00:11:37,740
very long time so this data set is going

00:11:35,970 --> 00:11:39,360
to be somewhat large so we're not going

00:11:37,740 --> 00:11:40,980
to be able to work on it with our single

00:11:39,360 --> 00:11:41,970
machine we're gonna connect to

00:11:40,980 --> 00:11:43,380
kubernetes we'll talk about that a

00:11:41,970 --> 00:11:45,150
little bit we'll talk about this more a

00:11:43,380 --> 00:11:48,240
little bit in the future and we'll ask

00:11:45,150 --> 00:11:50,010
for maybe three workers and this is

00:11:48,240 --> 00:11:52,560
using tasks which again we'll talk about

00:11:50,010 --> 00:11:55,500
a little bit in the future so we've got

00:11:52,560 --> 00:11:57,240
some workers connect to that cluster now

00:11:55,500 --> 00:12:00,060
we're going to do something simple we're

00:11:57,240 --> 00:12:06,300
just going to look for one day of that

00:12:00,060 --> 00:12:11,010
data and and plot the results so this is

00:12:06,300 --> 00:12:12,690
the sea level altitude so again this is

00:12:11,010 --> 00:12:14,550
sort of how maybe how high the tides are

00:12:12,690 --> 00:12:16,230
or how high the ocean is relative to the

00:12:14,550 --> 00:12:19,200
land and we see some interesting

00:12:16,230 --> 00:12:21,540
structure we see in the equator it's so

00:12:19,200 --> 00:12:23,540
red as higher blue is lower in the

00:12:21,540 --> 00:12:25,620
equator it's relatively common uniform

00:12:23,540 --> 00:12:28,440
maybe you know on the sort of on the

00:12:25,620 --> 00:12:29,880
windward side or on on the east side of

00:12:28,440 --> 00:12:33,840
most land masses we see a lot more

00:12:29,880 --> 00:12:36,300
variability around the Cape here there's

00:12:33,840 --> 00:12:38,040
a lot of a lot of turn so there's just

00:12:36,300 --> 00:12:40,760
one day of data and we have you know

00:12:38,040 --> 00:12:44,460
10,000 and such such days or time points

00:12:40,760 --> 00:12:46,140
so this particular array is around 70 70

00:12:44,460 --> 00:12:47,370
gigabytes in RAM again this is not large

00:12:46,140 --> 00:12:48,780
people deal with larger things in this

00:12:47,370 --> 00:12:50,190
but it's sort of something I can work

00:12:48,780 --> 00:12:52,590
with interactively for a conference talk

00:12:50,190 --> 00:12:53,820
so let's do some more computation before

00:12:52,590 --> 00:12:55,380
I do that I want to open up the

00:12:53,820 --> 00:12:57,150
dashboard which will help us understand

00:12:55,380 --> 00:13:00,660
how things are going I'm gonna scroll up

00:12:57,150 --> 00:13:02,070
here a little bit I also give us a nice

00:13:00,660 --> 00:13:03,660
sort of visual view of what's happening

00:13:02,070 --> 00:13:05,190
on our cluster as we do some more

00:13:03,660 --> 00:13:09,360
serious computations I'm gonna scroll

00:13:05,190 --> 00:13:10,440
back down to where we were before I'm

00:13:09,360 --> 00:13:11,910
going to do some more complex

00:13:10,440 --> 00:13:14,220
computations we take the average across

00:13:11,910 --> 00:13:16,020
spacial dimensions together just across

00:13:14,220 --> 00:13:17,290
longitude and then look at the variance

00:13:16,020 --> 00:13:19,720
over time

00:13:17,290 --> 00:13:21,700
and well that's going to do that's gonna

00:13:19,720 --> 00:13:23,590
break up our computation into thousands

00:13:21,700 --> 00:13:25,630
of little small pieces that we can then

00:13:23,590 --> 00:13:26,860
run across a cluster so on the right

00:13:25,630 --> 00:13:30,430
side of the screen you're seeing the

00:13:26,860 --> 00:13:33,280
activity of those 80 cores every line

00:13:30,430 --> 00:13:35,430
here corresponds to the trace of one

00:13:33,280 --> 00:13:38,650
core as it loads some data

00:13:35,430 --> 00:13:40,810
compute some some averages etc those are

00:13:38,650 --> 00:13:42,040
taking you know 100 millisecond Python

00:13:40,810 --> 00:13:44,410
functions that are running on various

00:13:42,040 --> 00:13:45,610
machines and ask is just coordinating

00:13:44,410 --> 00:13:48,790
all those machines to give us what we

00:13:45,610 --> 00:13:52,470
what we need so this is showing us the

00:13:48,790 --> 00:13:55,630
activity of our cluster over time and

00:13:52,470 --> 00:13:57,340
with us doing is that that's by doing

00:13:55,630 --> 00:13:59,410
all these very small number small

00:13:57,340 --> 00:14:00,700
Pandits computations it is completing

00:13:59,410 --> 00:14:03,400
for us a much larger aggregate

00:14:00,700 --> 00:14:05,170
computation this averaging over various

00:14:03,400 --> 00:14:08,350
dimensions that we asked for so now

00:14:05,170 --> 00:14:10,000
that's done took around 30 seconds we

00:14:08,350 --> 00:14:10,680
can start doing some more and look at

00:14:10,000 --> 00:14:12,910
those results

00:14:10,680 --> 00:14:16,750
I'm gonna go fullscreen on left here

00:14:12,910 --> 00:14:19,270
just the images can be a bit larger so

00:14:16,750 --> 00:14:20,620
let's look at the we're gonna we average

00:14:19,270 --> 00:14:24,510
over the spatial dimensions so we're

00:14:20,620 --> 00:14:27,850
just looking at the result over time and

00:14:24,510 --> 00:14:30,550
here we can see the the c-level average

00:14:27,850 --> 00:14:33,030
over the earth over time and so you can

00:14:30,550 --> 00:14:34,990
see the the cyclic variability just

00:14:33,030 --> 00:14:37,750
winter and summer there's there some

00:14:34,990 --> 00:14:40,390
earth sort of breeze a little bit you

00:14:37,750 --> 00:14:43,210
can also see a market increase over time

00:14:40,390 --> 00:14:45,400
so the sea level is rising and this is

00:14:43,210 --> 00:14:46,870
interesting right because we didn't have

00:14:45,400 --> 00:14:49,510
to look up at an agency to find out this

00:14:46,870 --> 00:14:51,760
information we just got to log into a

00:14:49,510 --> 00:14:53,770
website look at the real data analyze

00:14:51,760 --> 00:14:55,780
that data and come to a conclusion

00:14:53,770 --> 00:14:57,340
there's this sort of takes out any sort

00:14:55,780 --> 00:14:58,890
of politics in the discussion something

00:14:57,340 --> 00:15:01,480
that we can immediately go towards

00:14:58,890 --> 00:15:03,870
directly look at some more in more

00:15:01,480 --> 00:15:03,870
analyses

00:15:08,310 --> 00:15:11,639
the thing that takes a long time here is

00:15:10,199 --> 00:15:17,339
actually plotting the results the

00:15:11,639 --> 00:15:18,810
computation is all done there we go so

00:15:17,339 --> 00:15:20,430
this is the same analysis but we've

00:15:18,810 --> 00:15:22,199
included latitude so you can see how the

00:15:20,430 --> 00:15:25,139
sea level rise will change with southern

00:15:22,199 --> 00:15:26,309
or northern latitudes I think you see

00:15:25,139 --> 00:15:27,329
that you know things change a little bit

00:15:26,309 --> 00:15:28,829
it looks like there's some fine

00:15:27,329 --> 00:15:32,939
structure here around you know maybe

00:15:28,829 --> 00:15:33,930
latitude 38 or 37 if things still can be

00:15:32,939 --> 00:15:36,569
a little bit different the north and the

00:15:33,930 --> 00:15:40,199
south you might then also look at the

00:15:36,569 --> 00:15:44,160
the variability of sea level over over

00:15:40,199 --> 00:15:46,649
time and we can see that you know on the

00:15:44,160 --> 00:15:49,920
eastern coasts of most continents we

00:15:46,649 --> 00:15:50,999
actually see more of more variation it

00:15:49,920 --> 00:15:53,249
might be you know the east coast of your

00:15:50,999 --> 00:15:54,839
continent has higher and lower tides in

00:15:53,249 --> 00:15:56,220
the west coast of your continent and I

00:15:54,839 --> 00:15:58,230
don't know why this is just ask an

00:15:56,220 --> 00:16:00,389
oceanographer maybe it's the winds or

00:15:58,230 --> 00:16:03,660
something like that so again we're doing

00:16:00,389 --> 00:16:04,829
you know science here and we didn't

00:16:03,660 --> 00:16:07,079
really have to think that much about

00:16:04,829 --> 00:16:09,329
should be computing or scale it was all

00:16:07,079 --> 00:16:11,189
relatively intuitive if you're familiar

00:16:09,329 --> 00:16:15,089
with x-ray which many of you scientists

00:16:11,189 --> 00:16:18,149
are okay so you can do this too this

00:16:15,089 --> 00:16:20,399
legal one Pangea dot pi dot org which is

00:16:18,149 --> 00:16:22,079
a Jupiter hub deployment has open access

00:16:20,399 --> 00:16:24,089
currently with github please don't mind

00:16:22,079 --> 00:16:26,430
Bitcoin when you might start mining a

00:16:24,089 --> 00:16:30,329
Bitcoin we have to start putting in

00:16:26,430 --> 00:16:31,829
access controls but try it out the Wi-Fi

00:16:30,329 --> 00:16:33,480
here is not necessarily the greatest but

00:16:31,829 --> 00:16:35,970
you should shred out by taking whole

00:16:33,480 --> 00:16:37,470
minutes for things to spin up so you

00:16:35,970 --> 00:16:39,269
knew the exact analysis I just did is

00:16:37,470 --> 00:16:41,970
available to you you can do exactly that

00:16:39,269 --> 00:16:43,439
thing if you log in so we use Jupiter

00:16:41,970 --> 00:16:46,410
lab we use Jupiter hub but we used ask

00:16:43,439 --> 00:16:48,120
we use kubernetes so these tools or

00:16:46,410 --> 00:16:49,889
maybe a little bit newer than the ones

00:16:48,120 --> 00:16:51,559
we saw before and we're gonna see a

00:16:49,889 --> 00:16:56,459
little bit about why those those matter

00:16:51,559 --> 00:16:58,709
talk about Jupiter lab first so here we

00:16:56,459 --> 00:17:02,339
have the classic Jupiter notebook here

00:16:58,709 --> 00:17:03,929
we had Jupiter lab I think the Styles a

00:17:02,339 --> 00:17:06,000
little bit nicer I also like the

00:17:03,929 --> 00:17:09,059
keyboard shortcuts I can restart and

00:17:06,000 --> 00:17:11,730
clear my notebook without ever really

00:17:09,059 --> 00:17:14,880
touching a mouse some other nice things

00:17:11,730 --> 00:17:17,100
I've got a file browser I'm gonna look

00:17:14,880 --> 00:17:20,000
around I can look at examples these

00:17:17,100 --> 00:17:22,410
different things I also have a terminal

00:17:20,000 --> 00:17:25,860
so Jupiter lab is a much more fully

00:17:22,410 --> 00:17:27,420
featured development environment much

00:17:25,860 --> 00:17:28,530
more so than classic notebook this

00:17:27,420 --> 00:17:29,850
didn't matter when I was on a single

00:17:28,530 --> 00:17:31,650
machine but it really matters when I'm

00:17:29,850 --> 00:17:32,910
on a cluster and I want to manage my

00:17:31,650 --> 00:17:34,940
software environments only manage lots

00:17:32,910 --> 00:17:38,610
of things

00:17:34,940 --> 00:17:40,680
second Jupiter hub so Jupiter hub is one

00:17:38,610 --> 00:17:43,170
way to give many different users their

00:17:40,680 --> 00:17:44,670
own Jupiter server so I'm stealing this

00:17:43,170 --> 00:17:47,100
these slides from Carroll winneth

00:17:44,670 --> 00:17:50,340
willing who was generous enough to

00:17:47,100 --> 00:17:51,720
donate them to me so Jupiter hub is a

00:17:50,340 --> 00:17:55,590
way to give many people a Jupiter server

00:17:51,720 --> 00:17:56,910
so a notebook is a document software

00:17:55,590 --> 00:18:00,390
environment that's all served through

00:17:56,910 --> 00:18:02,340
web application so a user looks at their

00:18:00,390 --> 00:18:04,470
monitor that goes to their browser and

00:18:02,340 --> 00:18:05,760
that goes to some HTTP server almost

00:18:04,470 --> 00:18:07,320
always this is running on the local

00:18:05,760 --> 00:18:10,050
machine there doesn't have to it can run

00:18:07,320 --> 00:18:11,610
somewhere else what I would like to do

00:18:10,050 --> 00:18:13,290
though is I like to give a jupiter

00:18:11,610 --> 00:18:16,740
server to many people everyone who logs

00:18:13,290 --> 00:18:18,720
in to Pangea org gets their own jupiter

00:18:16,740 --> 00:18:20,220
notebook server that's independent for

00:18:18,720 --> 00:18:21,060
everyone else at their own software

00:18:20,220 --> 00:18:26,820
environment their own home directory

00:18:21,060 --> 00:18:28,260
jupiter hub handles all that for me so

00:18:26,820 --> 00:18:29,790
i've got many users look at their

00:18:28,260 --> 00:18:32,460
laptops they go through nation to p

00:18:29,790 --> 00:18:33,900
proxy they talk to the hub the hub spins

00:18:32,460 --> 00:18:38,610
up at gpnotebook server on kubernetes

00:18:33,900 --> 00:18:42,270
and gives them access to that server we

00:18:38,610 --> 00:18:43,650
also saw a desk so task is a library

00:18:42,270 --> 00:18:44,790
peril computing this is what I work on

00:18:43,650 --> 00:18:47,130
is my sort of small piece of this

00:18:44,790 --> 00:18:49,830
collaboration so this is designed to

00:18:47,130 --> 00:18:51,420
scale the existing Python data science

00:18:49,830 --> 00:18:53,370
libraries like numpy pandas or

00:18:51,420 --> 00:18:56,130
scikit-learn works in a variety of other

00:18:53,370 --> 00:18:58,110
contexts I give a much broader topic a

00:18:56,130 --> 00:19:00,090
bunch of otter talk about this topic a

00:18:58,110 --> 00:19:01,890
pike on last year if you care about

00:19:00,090 --> 00:19:03,600
parallel computing or scalable computing

00:19:01,890 --> 00:19:05,370
you might want to watch that

00:19:03,600 --> 00:19:08,070
but generally speaking we're just using

00:19:05,370 --> 00:19:11,250
one part of tasks task array which

00:19:08,070 --> 00:19:13,560
scales numpy x-ray who recall used numpy

00:19:11,250 --> 00:19:16,710
for computation dasker ray can scale

00:19:13,560 --> 00:19:19,020
numpy low no pike computations it takes

00:19:16,710 --> 00:19:20,940
many small numpy arrays that might be

00:19:19,020 --> 00:19:23,820
tribute across a cluster and coordinates

00:19:20,940 --> 00:19:25,740
them to create a one logical array that

00:19:23,820 --> 00:19:27,420
creates a task graph which tasks in the

00:19:25,740 --> 00:19:29,220
next few time parallel hardware that's

00:19:27,420 --> 00:19:32,310
like the 30 second explanation of task

00:19:29,220 --> 00:19:33,960
probably no one got that that's fine but

00:19:32,310 --> 00:19:37,440
- leaves you some parallel computing

00:19:33,960 --> 00:19:39,180
with a lot of Python code we also use

00:19:37,440 --> 00:19:42,240
kubernetes to manage both Jupiter hub

00:19:39,180 --> 00:19:43,890
and ask so kubernetes is a system you

00:19:42,240 --> 00:19:45,570
can run on a cluster allows many

00:19:43,890 --> 00:19:48,210
distributed systems to share that

00:19:45,570 --> 00:19:51,930
cluster so Jupiter hub and asked both

00:19:48,210 --> 00:19:53,460
want to create a bunch of machines a

00:19:51,930 --> 00:19:55,230
bunch of processes running on my cluster

00:19:53,460 --> 00:19:57,930
and kubernetes is the thing that makes

00:19:55,230 --> 00:19:59,940
them share nicely so what actually

00:19:57,930 --> 00:20:01,530
happens with this deployment that we

00:19:59,940 --> 00:20:03,480
have which is very similar you can make

00:20:01,530 --> 00:20:05,880
these things - there's one example of

00:20:03,480 --> 00:20:08,700
what we built so I have a bunch of

00:20:05,880 --> 00:20:09,690
machines these are these blue boxes and

00:20:08,700 --> 00:20:13,140
one of those machines are morning

00:20:09,690 --> 00:20:14,520
jupiter hub a user shows up toxic butter

00:20:13,140 --> 00:20:16,080
hop and jupiter hub gives them a jupiter

00:20:14,520 --> 00:20:18,110
notebook server maybe on the same

00:20:16,080 --> 00:20:21,390
machine maybe on a different one that

00:20:18,110 --> 00:20:23,310
user then talks to the notebook they in

00:20:21,390 --> 00:20:25,890
they import tasks they ask for some task

00:20:23,310 --> 00:20:27,540
workers and kubernetes gives them some

00:20:25,890 --> 00:20:29,040
tasks workers as well so now they're

00:20:27,540 --> 00:20:30,210
using the same cluster - both to have

00:20:29,040 --> 00:20:32,220
their notebook running in a single

00:20:30,210 --> 00:20:34,470
machine and many many task workers at

00:20:32,220 --> 00:20:36,180
the same time another user might show up

00:20:34,470 --> 00:20:39,350
might ask for another jupiter notebook

00:20:36,180 --> 00:20:41,940
and they might ask for even more workers

00:20:39,350 --> 00:20:43,590
here kubernetes gonna talk now to our

00:20:41,940 --> 00:20:45,330
cloud provider we happen to be using

00:20:43,590 --> 00:20:47,250
google who's generously donated a bunch

00:20:45,330 --> 00:20:49,440
of money for us to run on their hardware

00:20:47,250 --> 00:20:51,390
and kubernetes will apply pressure

00:20:49,440 --> 00:20:53,370
upstream and Google will now give us

00:20:51,390 --> 00:20:55,400
more machines to work with we can then

00:20:53,370 --> 00:20:58,230
launch more tasks cluster das workers

00:20:55,400 --> 00:21:00,420
the first user might go away Schubert

00:20:58,230 --> 00:21:03,150
hub will nicely clean up things and the

00:21:00,420 --> 00:21:04,140
cluster can scale down so this is how

00:21:03,150 --> 00:21:05,820
we're using Jupiter hub and asked

00:21:04,140 --> 00:21:08,940
together with kubernetes on the cloud

00:21:05,820 --> 00:21:10,260
it's been very effective so far so we've

00:21:08,940 --> 00:21:11,490
run the service continuously for a few

00:21:10,260 --> 00:21:13,920
months it showed up first and around

00:21:11,490 --> 00:21:15,420
January to a very small group of people

00:21:13,920 --> 00:21:18,360
we've been increasingly expanding the

00:21:15,420 --> 00:21:20,190
service and science users frequently

00:21:18,360 --> 00:21:22,620
scale up to sort of thousand core

00:21:20,190 --> 00:21:24,420
clusters and things can scale up in that

00:21:22,620 --> 00:21:26,250
nice horizontal way and they can come

00:21:24,420 --> 00:21:28,650
back down as long as the size users are

00:21:26,250 --> 00:21:30,150
sort of judicious about cleaning things

00:21:28,650 --> 00:21:32,550
up when they go away and we have various

00:21:30,150 --> 00:21:34,620
tools help do that we've been able to

00:21:32,550 --> 00:21:36,900
keep down costs so it's cost a sort of

00:21:34,620 --> 00:21:38,940
thousands of dollars which may be a lot

00:21:36,900 --> 00:21:41,370
to some of us but is very very low

00:21:38,940 --> 00:21:44,340
relative to your average distributed

00:21:41,370 --> 00:21:47,460
system running in some government lab

00:21:44,340 --> 00:21:48,660
there's no dedicated support staff so we

00:21:47,460 --> 00:21:52,170
don't have to hire anyone to manage this

00:21:48,660 --> 00:21:53,700
it seems to all work more or less so a

00:21:52,170 --> 00:21:55,890
few a few thoughts a few comments about

00:21:53,700 --> 00:21:59,190
impact and community this started with

00:21:55,890 --> 00:22:00,960
an NSF grant between some of the x-ray

00:21:59,190 --> 00:22:03,030
developers that were working at Columbia

00:22:00,960 --> 00:22:04,910
University and NCAR the National Center

00:22:03,030 --> 00:22:06,420
graphics our atmospheric research

00:22:04,910 --> 00:22:08,250
scientists at both of those

00:22:06,420 --> 00:22:09,810
organizations and also anaconda where I

00:22:08,250 --> 00:22:11,940
work a bunch of open-source software

00:22:09,810 --> 00:22:13,800
developers to make this sort of system

00:22:11,940 --> 00:22:14,790
it's been a really good collaboration

00:22:13,800 --> 00:22:16,350
and really nice having professional

00:22:14,790 --> 00:22:18,900
software developers working hand-in-hand

00:22:16,350 --> 00:22:21,090
with scientists funded for government

00:22:18,900 --> 00:22:23,310
public need this has been very popular

00:22:21,090 --> 00:22:25,590
with many other government agencies if

00:22:23,310 --> 00:22:27,180
you go to Pangea org there's you'll see

00:22:25,590 --> 00:22:29,130
a lot of information about other groups

00:22:27,180 --> 00:22:30,570
that have come on including other

00:22:29,130 --> 00:22:32,010
government labs I particularly want to

00:22:30,570 --> 00:22:35,160
thank the UK Met Office who's done a lot

00:22:32,010 --> 00:22:38,010
of work also groups like NASA USGS other

00:22:35,160 --> 00:22:40,080
various government organizations and

00:22:38,010 --> 00:22:42,870
people bring the log in and do work

00:22:40,080 --> 00:22:47,640
let's let's go ahead and see if someone

00:22:42,870 --> 00:22:48,840
is doing work the system by the way is

00:22:47,640 --> 00:22:52,110
completely insecure don't put anything

00:22:48,840 --> 00:22:54,810
up there it can go down any time there's

00:22:52,110 --> 00:22:57,930
very about access controls so here's

00:22:54,810 --> 00:22:59,700
people who have logged in so far some of

00:22:57,930 --> 00:23:01,920
these I recognized as being scientists

00:22:59,700 --> 00:23:05,190
ok pack some of these I imagine people

00:23:01,920 --> 00:23:06,630
from the audience it looks like a kayak

00:23:05,190 --> 00:23:11,580
is also learning a lot of fun of task

00:23:06,630 --> 00:23:13,350
workers we've also this is actually my

00:23:11,580 --> 00:23:14,820
favorite thing we've gotten scientists

00:23:13,350 --> 00:23:16,950
to talk about science not talking about

00:23:14,820 --> 00:23:18,630
scale so the example I showed you was

00:23:16,950 --> 00:23:20,670
was incorrect and if someone showed up

00:23:18,630 --> 00:23:22,500
and said hey you're actually not

00:23:20,670 --> 00:23:24,000
accounting for the fact that the the

00:23:22,500 --> 00:23:26,250
poles are a little bit different from

00:23:24,000 --> 00:23:27,870
the equator you're not doing a spatial

00:23:26,250 --> 00:23:29,520
average incorrectly if you if you do

00:23:27,870 --> 00:23:31,530
that spatial averaging you'll find that

00:23:29,520 --> 00:23:33,110
a sea-level rise has actually been a bit

00:23:31,530 --> 00:23:35,250
but larger and you're dissipating

00:23:33,110 --> 00:23:36,630
there's a long conversation where

00:23:35,250 --> 00:23:37,740
scientists talk about the various merits

00:23:36,630 --> 00:23:40,200
of various weighted averaging schemes

00:23:37,740 --> 00:23:42,660
that I don't understand but never ever

00:23:40,200 --> 00:23:44,040
do they mention scale or data size

00:23:42,660 --> 00:23:45,870
problems this person is also a

00:23:44,040 --> 00:23:47,310
first-time contributor which also nice I

00:23:45,870 --> 00:23:50,220
have no idea who this person is they

00:23:47,310 --> 00:23:51,840
just showed up so it's really a win for

00:23:50,220 --> 00:23:53,910
people just generally talking about

00:23:51,840 --> 00:23:55,700
science once science is available for

00:23:53,910 --> 00:23:59,330
everyone to talk about interact with

00:23:55,700 --> 00:24:01,309
directly successors no full-time staff I

00:23:59,330 --> 00:24:03,200
mean some of us like tweak things from

00:24:01,309 --> 00:24:04,250
time to time sometimes things break but

00:24:03,200 --> 00:24:07,100
no one's really paid to do this

00:24:04,250 --> 00:24:08,360
full-time I think's Jupiter hub and

00:24:07,100 --> 00:24:12,350
people who work on Jupiter hub for

00:24:08,360 --> 00:24:13,100
making this very easy other domains is

00:24:12,350 --> 00:24:16,220
are taking this on

00:24:13,100 --> 00:24:18,470
so microscopy is genomic genetics people

00:24:16,220 --> 00:24:21,320
astronomers full start looking at the

00:24:18,470 --> 00:24:24,559
same technology stack it's really

00:24:21,320 --> 00:24:25,820
independent of atmospheric science can

00:24:24,559 --> 00:24:29,210
we were used in a variety of different

00:24:25,820 --> 00:24:31,429
situations so to sort of finish there's

00:24:29,210 --> 00:24:33,320
some challenges and opportunities there

00:24:31,429 --> 00:24:35,480
are too many scientists and not enough

00:24:33,320 --> 00:24:38,269
non scientists so again my call to

00:24:35,480 --> 00:24:39,950
action to all of you please check out we

00:24:38,269 --> 00:24:41,480
have an issue tracker it's very open and

00:24:39,950 --> 00:24:43,279
welcoming people show up every day

00:24:41,480 --> 00:24:45,110
saying hey I'm this person I have these

00:24:43,279 --> 00:24:47,600
skills I have these needs how can I fit

00:24:45,110 --> 00:24:49,820
in there's a be link at the end if you

00:24:47,600 --> 00:24:53,090
have some interesting thoughts design

00:24:49,820 --> 00:24:54,710
skills ability to make websites we're

00:24:53,090 --> 00:24:56,450
really lacking on those we can write

00:24:54,710 --> 00:25:00,200
Fortran code and do science that's kind

00:24:56,450 --> 00:25:01,399
of it some other challenges are

00:25:00,200 --> 00:25:03,289
interesting managing software

00:25:01,399 --> 00:25:05,630
environments and user permissions has

00:25:03,289 --> 00:25:08,090
been a tricky challenge a cloud of data

00:25:05,630 --> 00:25:09,529
storage for scientific data formats so

00:25:08,090 --> 00:25:10,940
the interesting question there's a lot

00:25:09,529 --> 00:25:13,010
of support in the open-source community

00:25:10,940 --> 00:25:16,100
for business intelligence cases you know

00:25:13,010 --> 00:25:17,210
park' file formats sequel databases not

00:25:16,100 --> 00:25:21,250
a whole lot that handles this sort of

00:25:17,210 --> 00:25:25,120
other need of a large raster data sense

00:25:21,250 --> 00:25:28,490
and that's it great thank you so much

00:25:25,120 --> 00:25:28,490
[Applause]

00:25:30,200 --> 00:25:34,700
I think we're about five minutes for

00:25:33,080 --> 00:25:36,740
questions if you want to stand up behind

00:25:34,700 --> 00:25:50,000
the mic in the center how to take

00:25:36,740 --> 00:25:52,130
questions come on somebody yes thank you

00:25:50,000 --> 00:25:53,270
thank you for your great and inspiring

00:25:52,130 --> 00:25:55,730
talk

00:25:53,270 --> 00:25:57,860
I was wondering so you were mentioning

00:25:55,730 --> 00:26:02,030
that there are petabytes of data being

00:25:57,860 --> 00:26:04,640
published on Geoscience and you are

00:26:02,030 --> 00:26:07,730
basically crawling these these websites

00:26:04,640 --> 00:26:10,460
or perhaps squaring this data are there

00:26:07,730 --> 00:26:12,740
tools that you think will be able to

00:26:10,460 --> 00:26:15,350
make it easier to share this data for

00:26:12,740 --> 00:26:17,660
example I found in in science and

00:26:15,350 --> 00:26:20,630
academia usually when a paper is

00:26:17,660 --> 00:26:22,970
published the the data that accompanies

00:26:20,630 --> 00:26:25,220
this paper is not always shared or it is

00:26:22,970 --> 00:26:27,800
shared but in a very difficult to access

00:26:25,220 --> 00:26:29,030
platform yeah so the really nice thing

00:26:27,800 --> 00:26:29,750
about a lot of these data sources that

00:26:29,030 --> 00:26:31,040
they're coming from government

00:26:29,750 --> 00:26:32,870
organizations and actually have a

00:26:31,040 --> 00:26:34,460
mandate to share the data so

00:26:32,870 --> 00:26:36,560
historically if you look back a few

00:26:34,460 --> 00:26:38,870
years all of us data was on either

00:26:36,560 --> 00:26:40,250
supercomputing centers that anyone could

00:26:38,870 --> 00:26:42,200
hypothetically you get an AK account to

00:26:40,250 --> 00:26:45,560
and do some work on or they were served

00:26:42,200 --> 00:26:47,810
in national data centers which had some

00:26:45,560 --> 00:26:48,890
sort of difficult to access API what

00:26:47,810 --> 00:26:51,380
we're seeing is a lot of government

00:26:48,890 --> 00:26:53,090
government agencies like NASA JPL are

00:26:51,380 --> 00:26:55,880
now pushing data on to the cloud they're

00:26:53,090 --> 00:26:57,770
just dumping data onto AWS in sort of

00:26:55,880 --> 00:27:00,680
public access buckets I think AWS is

00:26:57,770 --> 00:27:01,970
funding the storage and this is great

00:27:00,680 --> 00:27:04,010
except that we don't have really good

00:27:01,970 --> 00:27:06,830
computational mechanism to to query and

00:27:04,010 --> 00:27:08,510
access that data or we don't we can

00:27:06,830 --> 00:27:11,360
access the data if you can use s3 or

00:27:08,510 --> 00:27:12,410
another cloud storage format but we're

00:27:11,360 --> 00:27:15,890
sort of trying to build a computational

00:27:12,410 --> 00:27:17,750
complement to s3 to do that analysis so

00:27:15,890 --> 00:27:19,580
I would say it's actually fairly the

00:27:17,750 --> 00:27:21,710
data is becoming very public and very

00:27:19,580 --> 00:27:23,330
easy to access there are data catalogs

00:27:21,710 --> 00:27:25,310
you can look at on a few different

00:27:23,330 --> 00:27:27,950
government agencies that will have this

00:27:25,310 --> 00:27:32,930
access to a bunch of kinds of data thank

00:27:27,950 --> 00:27:34,310
you so I've started trying to play

00:27:32,930 --> 00:27:35,810
around with Jupiter hub at my company

00:27:34,310 --> 00:27:37,070
for some of our researchers to use and

00:27:35,810 --> 00:27:38,900
one of the things I kind of ran into

00:27:37,070 --> 00:27:40,220
right away was it was a lot more

00:27:38,900 --> 00:27:41,480
difficult for people to kind of share

00:27:40,220 --> 00:27:42,770
notebooks they had with each other

00:27:41,480 --> 00:27:43,940
because you can't like you know copy and

00:27:42,770 --> 00:27:46,009
paste the link and send it off

00:27:43,940 --> 00:27:47,090
is that something you've run into with

00:27:46,009 --> 00:27:48,710
like the scientists working on this

00:27:47,090 --> 00:27:49,490
platform and how are you thinking to

00:27:48,710 --> 00:27:50,870
address that problem

00:27:49,490 --> 00:27:52,820
absolutely it's definitely been a

00:27:50,870 --> 00:27:54,529
problem people have analyses they want

00:27:52,820 --> 00:27:56,210
to share them they used to email their

00:27:54,529 --> 00:27:57,559
notebooks back and forth that's sort of

00:27:56,210 --> 00:27:58,940
not the right way to do things

00:27:57,559 --> 00:28:01,820
what's the right way we don't have a

00:27:58,940 --> 00:28:03,559
good answer so no that's a pending

00:28:01,820 --> 00:28:05,000
question we're trying to address so

00:28:03,559 --> 00:28:06,679
interestingly so I'm gonna take off my

00:28:05,000 --> 00:28:10,370
open-source hat on put on my anaconda

00:28:06,679 --> 00:28:11,750
evil Enterprise I never understood

00:28:10,370 --> 00:28:13,820
enterprise software that anaconda was

00:28:11,750 --> 00:28:15,110
building until I worked on this and it

00:28:13,820 --> 00:28:17,090
you know handles managing sharing

00:28:15,110 --> 00:28:19,519
notebooks handles environments and

00:28:17,090 --> 00:28:21,500
building software systems it's like all

00:28:19,519 --> 00:28:23,809
the problems that I now have I now want

00:28:21,500 --> 00:28:24,799
to buy enterprise software for so one

00:28:23,809 --> 00:28:27,230
answer is pay a lot of money to a

00:28:24,799 --> 00:28:29,090
company and anakata as many competitors

00:28:27,230 --> 00:28:30,440
in this space but it's an active problem

00:28:29,090 --> 00:28:32,120
that many companies are trying to

00:28:30,440 --> 00:28:36,019
address and now we're trying to rest in

00:28:32,120 --> 00:28:41,559
open science as well thank you I'm gonna

00:28:36,019 --> 00:28:41,559
take off the enterprise hat I'm not

00:28:41,740 --> 00:28:48,679
research scientist and these all sound

00:28:45,950 --> 00:28:51,259
like really wonderful tools and NASA is

00:28:48,679 --> 00:28:55,970
pretty good at making its data available

00:28:51,259 --> 00:28:59,450
for other people but internally allowing

00:28:55,970 --> 00:29:01,340
our researchers to do research on the

00:28:59,450 --> 00:29:04,580
cloud or someplace else is very

00:29:01,340 --> 00:29:07,029
challenging for all of the security

00:29:04,580 --> 00:29:12,970
reasons that make our lives difficult

00:29:07,029 --> 00:29:16,279
and my question is have you already

00:29:12,970 --> 00:29:20,029
established installation of these on

00:29:16,279 --> 00:29:22,129
government hardware for internal

00:29:20,029 --> 00:29:24,110
government use yeah definitely okay so

00:29:22,129 --> 00:29:25,789
dasa has been around for a while and

00:29:24,110 --> 00:29:27,919
it's very popular in more traditional

00:29:25,789 --> 00:29:29,299
high-performance computing clusters okay

00:29:27,919 --> 00:29:33,049
if you're interested I recommend looking

00:29:29,299 --> 00:29:35,539
at a project called let's see - job

00:29:33,049 --> 00:29:37,460
queue which is a nice way to set up

00:29:35,539 --> 00:29:39,799
tasks on a variety of more traditional

00:29:37,460 --> 00:29:42,080
job schedulers like sge your slurm or

00:29:39,799 --> 00:29:45,350
tour for LSF if those one of those sound

00:29:42,080 --> 00:29:47,090
familiar to you okay yeah that makes my

00:29:45,350 --> 00:29:49,490
life easier someone else is already done

00:29:47,090 --> 00:29:51,679
yeah and you should also go onto the pan

00:29:49,490 --> 00:29:53,179
geo good hub tracker right put a link

00:29:51,679 --> 00:29:54,710
back here and you'll find that many

00:29:53,179 --> 00:29:56,960
people are running on a variety of

00:29:54,710 --> 00:29:57,430
different clusters maybe already the one

00:29:56,960 --> 00:30:04,180
that you're

00:29:57,430 --> 00:30:06,190
okay great thank you yeah I met you so I

00:30:04,180 --> 00:30:09,340
found a lot of documentation for tasks

00:30:06,190 --> 00:30:13,200
on how to use it and all all the power

00:30:09,340 --> 00:30:16,420
it has where I'm having difficulty is

00:30:13,200 --> 00:30:17,860
knowing how to set it up for my company

00:30:16,420 --> 00:30:19,570
like what is the proper way to set it up

00:30:17,860 --> 00:30:21,970
and I don't find much documentation

00:30:19,570 --> 00:30:24,610
either can you point me to some

00:30:21,970 --> 00:30:26,890
resources for that yeah so if we do add

00:30:24,610 --> 00:30:29,950
ask documentation the top there is a

00:30:26,890 --> 00:30:31,780
deploy link so take you to the the main

00:30:29,950 --> 00:30:33,220
deploy documentation has a variety of

00:30:31,780 --> 00:30:35,170
different options based on running on a

00:30:33,220 --> 00:30:38,140
single machine - works very well in your

00:30:35,170 --> 00:30:39,760
laptop first out of core data work or

00:30:38,140 --> 00:30:41,200
maybe more complex things like ice SH

00:30:39,760 --> 00:30:44,500
for high-performance computers like with

00:30:41,200 --> 00:30:46,480
a NASA person or kubernetes or other

00:30:44,500 --> 00:30:48,850
sort of other sort of options so this is

00:30:46,480 --> 00:30:50,190
where I would recommend starting most

00:30:48,850 --> 00:30:52,930
documentation rigid asses at

00:30:50,190 --> 00:30:54,340
da-da-da-da-da org I'm also at the

00:30:52,930 --> 00:30:55,570
Anaconda booth the fair amount today if

00:30:54,340 --> 00:30:57,280
you have other questions and want a chat

00:30:55,570 --> 00:31:00,340
oh good thank you

00:30:57,280 --> 00:31:03,370
I think if I have one more question and

00:31:00,340 --> 00:31:05,140
I should probably yield the floor really

00:31:03,370 --> 00:31:07,390
quick for those of us setting up desk

00:31:05,140 --> 00:31:08,890
deployments on premise at a company

00:31:07,390 --> 00:31:10,480
it sounds like kubernetes is just like

00:31:08,890 --> 00:31:12,460
the right Orchestrator or like the

00:31:10,480 --> 00:31:14,710
pervert Orchestrator is there like a

00:31:12,460 --> 00:31:16,390
preferred data source like a database or

00:31:14,710 --> 00:31:19,330
a file format with which tasks works

00:31:16,390 --> 00:31:21,610
best yeah so communities not necessarily

00:31:19,330 --> 00:31:23,410
preferred I like it but usually will

00:31:21,610 --> 00:31:26,140
already have a system set up and look at

00:31:23,410 --> 00:31:27,370
tasks usually works with that system so

00:31:26,140 --> 00:31:30,700
there's a variety of ways to set up

00:31:27,370 --> 00:31:32,500
tasks depending on your needs terms of

00:31:30,700 --> 00:31:34,210
data source I say depends a lot on the

00:31:32,500 --> 00:31:36,460
kind of ways you're planning to use desk

00:31:34,210 --> 00:31:38,680
using task data frame the sort of

00:31:36,460 --> 00:31:41,290
scalable big panda's data frame you

00:31:38,680 --> 00:31:43,840
might use park' or orc format if you're

00:31:41,290 --> 00:31:45,820
using das Garre you might choose hdf5 or

00:31:43,840 --> 00:31:48,520
something else but ask is also used with

00:31:45,820 --> 00:31:51,880
a variety of other more custom systems I

00:31:48,520 --> 00:31:53,440
think maybe - main attraction for a lot

00:31:51,880 --> 00:31:54,820
of companies is its flexibility its

00:31:53,440 --> 00:31:57,130
ability to work with a variety of

00:31:54,820 --> 00:31:59,470
different more custom in-house systems

00:31:57,130 --> 00:32:01,020
so thank you great thank you all so much

00:31:59,470 --> 00:32:03,080
for your time

00:32:01,020 --> 00:32:03,080

YouTube URL: https://www.youtube.com/watch?v=Iq72dt1gO9c


