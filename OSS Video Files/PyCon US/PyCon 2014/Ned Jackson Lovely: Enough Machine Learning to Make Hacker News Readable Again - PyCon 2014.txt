Title: Ned Jackson Lovely: Enough Machine Learning to Make Hacker News Readable Again - PyCon 2014
Publication date: 2014-04-12
Playlist: PyCon 2014
Description: 
	Speaker: Ned Jackson Lovely

It's inevitable that online communities will change, and that we'll remember the community with a fondness that likely doesn't accurately reflect the former reality. We'll explore how we can take a set of articles from an online community and winnow out the stuff we feel is unworthy. We'll explore some of the machine learning tools that are just a "pip install" away, such as scikit-learn and nltk.

Slides can be found at: https://speakerdeck.com/pycon2014 and https://github.com/PyCon/2014-slides
Captions: 
	00:00:09,950 --> 00:00:19,470
jackets on boo and the mics on hi we

00:00:14,969 --> 00:00:22,080
have a Ned Ludd Jackson again here that

00:00:19,470 --> 00:00:23,460
lovely Jackson on stage and he's going

00:00:22,080 --> 00:00:32,219
to talk to us about machine lighting

00:00:23,460 --> 00:00:35,070
please welcome hi everyone how y'all

00:00:32,219 --> 00:00:36,420
doing so my name my talk is enough

00:00:35,070 --> 00:00:38,340
machine learning to make hacker news

00:00:36,420 --> 00:00:41,879
readable again yes that's a little

00:00:38,340 --> 00:00:45,120
snarky I'm sorry so what I want to talk

00:00:41,879 --> 00:00:48,059
about sort of focus to this should

00:00:45,120 --> 00:00:55,800
introduce myself to shouldn't I and plug

00:00:48,059 --> 00:00:57,120
in my pointer all right so this is me oh

00:00:55,800 --> 00:01:01,559
by the way the slides are up on my

00:00:57,120 --> 00:01:03,420
website and jus net jl on the twitters

00:01:01,559 --> 00:01:05,790
things you can email at me and jay len

00:01:03,420 --> 00:01:07,409
in jail us too I don't know ask me

00:01:05,790 --> 00:01:09,240
questions or yell at me or whatever so

00:01:07,409 --> 00:01:11,610
what try to do here is a simple

00:01:09,240 --> 00:01:13,350
achievable project something that is

00:01:11,610 --> 00:01:15,390
machine learning related but I think all

00:01:13,350 --> 00:01:17,040
of us are capable of which is a

00:01:15,390 --> 00:01:18,990
personalized filter for hacker news

00:01:17,040 --> 00:01:20,130
taking hacker news inserting the

00:01:18,990 --> 00:01:23,280
articles into what I'm going to call

00:01:20,130 --> 00:01:25,830
dreck and not direct and then you read

00:01:23,280 --> 00:01:30,180
the not dreck and you feel much better

00:01:25,830 --> 00:01:32,159
about the world in general so the whole

00:01:30,180 --> 00:01:35,009
point of my talk is I can machine learn

00:01:32,159 --> 00:01:36,900
and you can too machine learning like

00:01:35,009 --> 00:01:39,030
has this crazy name like it feels like

00:01:36,900 --> 00:01:42,150
artificial intelligence like the machine

00:01:39,030 --> 00:01:44,070
is learning man and that's a lot of

00:01:42,150 --> 00:01:45,119
intimidation there is a lot of science

00:01:44,070 --> 00:01:46,649
involved there's a lot of terminology

00:01:45,119 --> 00:01:48,390
you're going to spend a lot of time

00:01:46,649 --> 00:01:51,000
googling going to spend a lot of time

00:01:48,390 --> 00:01:52,920
reading Wikipedia articles and survey

00:01:51,000 --> 00:01:55,649
overviews stuff but the essence of

00:01:52,920 --> 00:01:57,119
machine learning is actually start an

00:01:55,649 --> 00:01:59,520
approach engineering it started approach

00:01:57,119 --> 00:02:01,619
tools you can use I'm machine learning

00:01:59,520 --> 00:02:04,380
is just applying statistics to big piles

00:02:01,619 --> 00:02:06,360
of data that's really all it is so we've

00:02:04,380 --> 00:02:08,039
gave it this wonderful name but when you

00:02:06,360 --> 00:02:09,899
get down to it you're building

00:02:08,039 --> 00:02:12,090
statistical models of a bunch of input

00:02:09,899 --> 00:02:13,410
data and you're using it to understand

00:02:12,090 --> 00:02:15,000
that data better

00:02:13,410 --> 00:02:17,760
or to make predictions or to better or

00:02:15,000 --> 00:02:19,560
to sort of go further with the data so

00:02:17,760 --> 00:02:21,030
yeah there's terminology but we're going

00:02:19,560 --> 00:02:24,000
to I'm going to give you a bunch of it

00:02:21,030 --> 00:02:26,160
and then try to set you loose so here's

00:02:24,000 --> 00:02:28,170
sort of the workflow when you're doing

00:02:26,160 --> 00:02:30,900
machine learning you have to get the

00:02:28,170 --> 00:02:33,360
data which is usually not as easy as you

00:02:30,900 --> 00:02:35,940
think you need to engineer the data

00:02:33,360 --> 00:02:38,490
which means you need to take this messy

00:02:35,940 --> 00:02:40,200
real world stuff that you scraped off

00:02:38,490 --> 00:02:42,240
the web or gut out of some database and

00:02:40,200 --> 00:02:44,250
turn it into nice little numpy arrays

00:02:42,240 --> 00:02:46,500
with well you know with well-formed

00:02:44,250 --> 00:02:48,090
values and then you need to train and

00:02:46,500 --> 00:02:50,100
tune the model this is the science part

00:02:48,090 --> 00:02:53,190
that training and tuning the model but

00:02:50,100 --> 00:02:54,450
yeah other people have written libraries

00:02:53,190 --> 00:02:56,220
you can just use their libraries it's

00:02:54,450 --> 00:02:58,020
great and then applying the model to new

00:02:56,220 --> 00:03:00,000
data once again you just use the

00:02:58,020 --> 00:03:01,470
libraries if you talk to folks who do

00:03:00,000 --> 00:03:02,610
this for a living who have doctorates

00:03:01,470 --> 00:03:04,350
who spent a lot of time working on

00:03:02,610 --> 00:03:06,090
machine learning they spent all their

00:03:04,350 --> 00:03:08,760
time getting the data in engineering the

00:03:06,090 --> 00:03:10,410
data they burn a lot of CPU cycles but

00:03:08,760 --> 00:03:13,350
not a lot of time training and tuning

00:03:10,410 --> 00:03:16,740
models and then you know just applying

00:03:13,350 --> 00:03:19,260
it is very straightforward so I'm gonna

00:03:16,740 --> 00:03:20,670
be talking mostly about scikit-learn the

00:03:19,260 --> 00:03:23,700
documentation for socket learn is

00:03:20,670 --> 00:03:26,070
fantastic a couple pip installs away

00:03:23,700 --> 00:03:27,600
from having a fully functioning awesome

00:03:26,070 --> 00:03:29,880
machine learning library sitting on your

00:03:27,600 --> 00:03:32,670
machine the hardest part is installed

00:03:29,880 --> 00:03:35,190
installing them installing syfy so

00:03:32,670 --> 00:03:38,280
you've got a tutorial user guides api

00:03:35,190 --> 00:03:40,920
docs in this flowchart this flowchart is

00:03:38,280 --> 00:03:42,540
one of the coolest things ever so the

00:03:40,920 --> 00:03:44,730
hard part with machine learning is

00:03:42,540 --> 00:03:46,860
there's too much terminology there are

00:03:44,730 --> 00:03:49,200
too many things you can do there are too

00:03:46,860 --> 00:03:50,730
many options there are people will say

00:03:49,200 --> 00:03:52,020
oh you support vector machines for

00:03:50,730 --> 00:03:54,420
everything and they're probably right

00:03:52,020 --> 00:03:56,000
but who knows like maybe you're trying

00:03:54,420 --> 00:03:58,470
to do something else so what this does

00:03:56,000 --> 00:04:00,840
this chart gives you some steps you can

00:03:58,470 --> 00:04:04,320
go through to figure out what you want

00:04:00,840 --> 00:04:06,450
to start googling all right it's really

00:04:04,320 --> 00:04:09,060
that straightforward you say oh I've got

00:04:06,450 --> 00:04:10,290
less than 50 samples of never mind right

00:04:09,060 --> 00:04:11,610
and so you kind of step your way through

00:04:10,290 --> 00:04:13,290
this flow chart try to figure out what

00:04:11,610 --> 00:04:15,000
you're trying to do their data and you

00:04:13,290 --> 00:04:16,620
can start figuring out what parts of

00:04:15,000 --> 00:04:18,870
socket learned you need to research more

00:04:16,620 --> 00:04:20,730
what you need to find a couple papers on

00:04:18,870 --> 00:04:21,810
there's lots of good papers that kind of

00:04:20,730 --> 00:04:23,789
give you an overview of the field

00:04:21,810 --> 00:04:25,440
without bogging you down too much and

00:04:23,789 --> 00:04:27,210
when you don't understand the math go

00:04:25,440 --> 00:04:30,960
blah blah blah and keep reading

00:04:27,210 --> 00:04:32,400
that's my advice so something that we

00:04:30,960 --> 00:04:33,300
hear a lot about in machine learning and

00:04:32,400 --> 00:04:34,650
I think it's worth talking about

00:04:33,300 --> 00:04:37,139
bringing up and just making people aware

00:04:34,650 --> 00:04:39,720
of is a concept of supervised versus

00:04:37,139 --> 00:04:43,319
unsupervised so supervised learning is

00:04:39,720 --> 00:04:46,080
when you have input data and then

00:04:43,319 --> 00:04:47,910
there's some output value so for me this

00:04:46,080 --> 00:04:49,710
was the input data was a bunch of stuff

00:04:47,910 --> 00:04:51,180
I scraped off a hacker news and sliced

00:04:49,710 --> 00:04:53,310
at link to hacker news that was the

00:04:51,180 --> 00:04:56,220
input data and then the output was is

00:04:53,310 --> 00:04:58,410
this crap or not right so a boolean

00:04:56,220 --> 00:05:00,180
value true or false true something I

00:04:58,410 --> 00:05:03,020
want to read false something I wish

00:05:00,180 --> 00:05:04,770
didn't exist right and so that's

00:05:03,020 --> 00:05:06,930
classification that's supervised

00:05:04,770 --> 00:05:09,210
learning where you go and you have a

00:05:06,930 --> 00:05:11,729
bunch of labels and output values and

00:05:09,210 --> 00:05:13,490
you try to turn input data into those

00:05:11,729 --> 00:05:15,900
labels or output values that's

00:05:13,490 --> 00:05:17,250
supervised learning unsupervised

00:05:15,900 --> 00:05:21,919
learning is more about understanding

00:05:17,250 --> 00:05:24,740
your data that would be I have you know

00:05:21,919 --> 00:05:27,150
thousands of hacker news articles can I

00:05:24,740 --> 00:05:29,190
visualize them somehow can I group them

00:05:27,150 --> 00:05:30,780
by subjects and I don't know how many

00:05:29,190 --> 00:05:32,580
subjects there are but can I find

00:05:30,780 --> 00:05:34,440
subjects and group them so that's kind

00:05:32,580 --> 00:05:35,580
of unsupervised sort of trying to

00:05:34,440 --> 00:05:37,500
understand the date a little bit better

00:05:35,580 --> 00:05:39,599
a lot of power to it a lot of

00:05:37,500 --> 00:05:40,919
interesting bits there but I'm going to

00:05:39,599 --> 00:05:41,789
set that aside for this talk and I'm

00:05:40,919 --> 00:05:43,860
pretty much when we talking about

00:05:41,789 --> 00:05:45,380
supervised learning there are a lot of

00:05:43,860 --> 00:05:47,580
really accessible books on the topic

00:05:45,380 --> 00:05:48,690
natural language processing with Python

00:05:47,580 --> 00:05:50,520
and programming collective intelligence

00:05:48,690 --> 00:05:53,340
the o'reilly books aren't directly

00:05:50,520 --> 00:05:54,780
dealing with the topic of this talk but

00:05:53,340 --> 00:05:56,789
they do a really good job of getting you

00:05:54,780 --> 00:05:59,520
thinking about dealing with big piles of

00:05:56,789 --> 00:06:01,110
text as data which is a kind of like a

00:05:59,520 --> 00:06:04,199
little bit of a thing to stretch your

00:06:01,110 --> 00:06:05,729
mind to say you know what it's text but

00:06:04,199 --> 00:06:07,650
i can turn into numbers and how do i go

00:06:05,729 --> 00:06:09,150
about turning two numbers the books from

00:06:07,650 --> 00:06:10,440
packed building machine learning systems

00:06:09,150 --> 00:06:12,630
with python and learning scikit-learn

00:06:10,440 --> 00:06:14,460
are both really good books that step you

00:06:12,630 --> 00:06:15,659
through a step-by-step but they tend to

00:06:14,460 --> 00:06:18,599
kind of walk you through a little bit

00:06:15,659 --> 00:06:21,479
contrived examples and can hide you from

00:06:18,599 --> 00:06:22,560
a little bit of the real world so enough

00:06:21,479 --> 00:06:24,360
about this let's talk about this socket

00:06:22,560 --> 00:06:25,409
learn thing and some patterns and stuff

00:06:24,360 --> 00:06:27,060
you're going to see over and over again

00:06:25,409 --> 00:06:28,590
as you're writing scikit-learn code and

00:06:27,060 --> 00:06:30,870
things to look out for and be aware of

00:06:28,590 --> 00:06:34,349
so first things first they love them

00:06:30,870 --> 00:06:35,580
some parallel arrays X is the input so

00:06:34,349 --> 00:06:37,740
in my case this is an array of

00:06:35,580 --> 00:06:40,710
dictionaries with lots of random junk

00:06:37,740 --> 00:06:42,540
from hacker news why is

00:06:40,710 --> 00:06:44,760
the value you're trying to get out so X

00:06:42,540 --> 00:06:46,500
is the input data in my case why would

00:06:44,760 --> 00:06:50,040
be a boolean true I want to read it

00:06:46,500 --> 00:06:51,660
false I don't first thing you want to do

00:06:50,040 --> 00:06:54,360
with machine learning and this is this

00:06:51,660 --> 00:06:56,760
is one of those hard-won things that the

00:06:54,360 --> 00:06:58,560
community has finally come to is you

00:06:56,760 --> 00:07:01,020
want to set aside what's called a

00:06:58,560 --> 00:07:03,210
validation set you're trying to train

00:07:01,020 --> 00:07:06,120
the computer to notice patterns and to

00:07:03,210 --> 00:07:09,540
pick up on things on data it has never

00:07:06,120 --> 00:07:11,700
seen before right so it would be trivial

00:07:09,540 --> 00:07:14,270
to write something which saved all of

00:07:11,700 --> 00:07:17,210
the input values that saw exactly and

00:07:14,270 --> 00:07:19,770
then spit out the output values again

00:07:17,210 --> 00:07:21,120
when it saw those same input values and

00:07:19,770 --> 00:07:22,530
it would look like it was perfect you'd

00:07:21,120 --> 00:07:24,480
say hey look I put it in it comes right

00:07:22,530 --> 00:07:26,460
out but what you're curious about what

00:07:24,480 --> 00:07:28,320
you want to learn about is new we're

00:07:26,460 --> 00:07:31,050
different interesting stuff your machine

00:07:28,320 --> 00:07:32,580
hasn't seen it all so what the idea of a

00:07:31,050 --> 00:07:34,290
validation set is is you take about

00:07:32,580 --> 00:07:35,880
twenty five percent of your data and you

00:07:34,290 --> 00:07:37,680
set it aside totally you're not allowed

00:07:35,880 --> 00:07:39,600
to touch it you're not allowed to look

00:07:37,680 --> 00:07:41,190
at it at the very end you're done with

00:07:39,600 --> 00:07:43,200
everything and you use the validation

00:07:41,190 --> 00:07:45,720
set to figure out if you did a good

00:07:43,200 --> 00:07:47,190
enough job or not for me i marked them

00:07:45,720 --> 00:07:48,870
all in the database and then when i was

00:07:47,190 --> 00:07:50,670
pulling and messing with the data my

00:07:48,870 --> 00:07:51,990
validation set didn't show up at all and

00:07:50,670 --> 00:07:53,580
then finally at the end i use the

00:07:51,990 --> 00:07:56,850
validation set to figure out how good my

00:07:53,580 --> 00:07:58,700
results were so how do you work what do

00:07:56,850 --> 00:08:01,020
you do you're going to build pipelines

00:07:58,700 --> 00:08:02,400
so sequences of things that operate on

00:08:01,020 --> 00:08:04,020
data and you're going to optimize

00:08:02,400 --> 00:08:05,340
parameters you're going to be tweaking

00:08:04,020 --> 00:08:07,530
how these things are operating on the

00:08:05,340 --> 00:08:10,620
data pipeline just a sequence of

00:08:07,530 --> 00:08:12,390
operations that's all it is they are

00:08:10,620 --> 00:08:15,060
this amazing wonderful thing that allows

00:08:12,390 --> 00:08:16,830
you to put together a bunch of

00:08:15,060 --> 00:08:19,200
potentially really complex steps and

00:08:16,830 --> 00:08:21,060
then optimize this entire series of

00:08:19,200 --> 00:08:25,200
complex steps to get the best possible

00:08:21,060 --> 00:08:26,250
results so what I have right here I'm

00:08:25,200 --> 00:08:29,250
going over here so I kind of heights in

00:08:26,250 --> 00:08:32,820
code I'm just importing the pipeline I'm

00:08:29,250 --> 00:08:36,390
getting this text package and a linear

00:08:32,820 --> 00:08:37,740
support vector classifier so I create

00:08:36,390 --> 00:08:40,620
the pipeline I just give each one of

00:08:37,740 --> 00:08:42,510
them a name and basically this will take

00:08:40,620 --> 00:08:44,850
input blobs of text and turn them into

00:08:42,510 --> 00:08:46,710
nice numerical numpy arrays and this

00:08:44,850 --> 00:08:49,590
will attempt to learn from that

00:08:46,710 --> 00:08:51,870
input.text this is you know very

00:08:49,590 --> 00:08:54,390
straightforward and that's an almost

00:08:51,870 --> 00:08:56,910
complete reasonable way for

00:08:54,390 --> 00:08:59,190
step to understand some text and to make

00:08:56,910 --> 00:09:01,770
some predictions about text really all

00:08:59,190 --> 00:09:06,810
you need but there's these things called

00:09:01,770 --> 00:09:08,910
hyper parameters so there are amazing

00:09:06,810 --> 00:09:11,880
amounts of wonderful tweakable little

00:09:08,910 --> 00:09:14,220
bits of math going on inside all of

00:09:11,880 --> 00:09:16,950
these these gigantic statistical methods

00:09:14,220 --> 00:09:19,080
and if you look you're like oh there's

00:09:16,950 --> 00:09:21,990
this thing called C and I want to set it

00:09:19,080 --> 00:09:23,310
to some power of 2 and whatever you

00:09:21,990 --> 00:09:24,990
google that you figure it out you get

00:09:23,310 --> 00:09:27,660
some vague idea of what's going on and

00:09:24,990 --> 00:09:28,860
then you use these things called up well

00:09:27,660 --> 00:09:30,390
they get a couple different kinds of

00:09:28,860 --> 00:09:33,810
ways to do this but the grid search is

00:09:30,390 --> 00:09:36,420
amazing so you basically say there are I

00:09:33,810 --> 00:09:37,950
don't know for different values for C

00:09:36,420 --> 00:09:39,630
that seem reasonable there's two

00:09:37,950 --> 00:09:41,760
different values for the loss function I

00:09:39,630 --> 00:09:44,850
want to try two different values for the

00:09:41,760 --> 00:09:47,010
Ngram thing and then the grid search I

00:09:44,850 --> 00:09:49,380
set the number of jobs to negative 1

00:09:47,010 --> 00:09:51,090
which means use all my CPUs I put

00:09:49,380 --> 00:09:52,260
verbose equals 2 which means print a lot

00:09:51,090 --> 00:09:54,570
of stuff to the output so that I feel

00:09:52,260 --> 00:09:56,640
like things are happening and then I

00:09:54,570 --> 00:10:00,030
look at H top and all of my all of my

00:09:56,640 --> 00:10:03,720
CPOs are pegged read the fans go on it

00:10:00,030 --> 00:10:05,190
just crunches I actually had one that

00:10:03,720 --> 00:10:07,200
took four hours because i was doing

00:10:05,190 --> 00:10:08,460
multiple pipelines in parallel and just

00:10:07,200 --> 00:10:10,470
testing them all out and trying to find

00:10:08,460 --> 00:10:12,420
the best one so you just try out all

00:10:10,470 --> 00:10:14,520
these possible combinations and it finds

00:10:12,420 --> 00:10:16,710
out which one is best at predicting your

00:10:14,520 --> 00:10:18,210
data for you it does cross validation

00:10:16,710 --> 00:10:20,130
all these other things before you behind

00:10:18,210 --> 00:10:22,350
the scenes but you just try a bunch of

00:10:20,130 --> 00:10:25,200
values and it tries all the values it

00:10:22,350 --> 00:10:27,720
tries all the combinations and will spit

00:10:25,200 --> 00:10:29,700
out an object at the end that is the

00:10:27,720 --> 00:10:33,810
most effective and efficient and an

00:10:29,700 --> 00:10:35,400
accurate trained model very straight

00:10:33,810 --> 00:10:36,620
forward so that fit function is

00:10:35,400 --> 00:10:38,760
something you're going to see a lot of

00:10:36,620 --> 00:10:41,550
there are three functions in particular

00:10:38,760 --> 00:10:42,810
that are interesting transform and fit

00:10:41,550 --> 00:10:45,360
are both ones you might have to write

00:10:42,810 --> 00:10:47,160
yourself and predict is where the

00:10:45,360 --> 00:10:49,290
awesome statistics people have done the

00:10:47,160 --> 00:10:52,110
magic for you that's that's where the

00:10:49,290 --> 00:10:55,590
science is is in predicts and fits so

00:10:52,110 --> 00:10:57,060
this is a transform the hashing vector

00:10:55,590 --> 00:11:00,900
Iser you saw a little bit earlier to

00:10:57,060 --> 00:11:03,570
turn blobs of text into nice little rays

00:11:00,900 --> 00:11:06,270
so all this one does I threw in two

00:11:03,570 --> 00:11:08,370
parts of import this and it turns it

00:11:06,270 --> 00:11:10,529
into a sparse matrix of

00:11:08,370 --> 00:11:12,330
floats with 10 story elements so it just

00:11:10,529 --> 00:11:15,930
takes this text this array of text and

00:11:12,330 --> 00:11:17,640
actually for each column is a word not

00:11:15,930 --> 00:11:20,490
precisely but close enough each column

00:11:17,640 --> 00:11:22,320
is a word each row is a some input text

00:11:20,490 --> 00:11:25,230
and it will set those values based on

00:11:22,320 --> 00:11:27,150
this input.text really really handy way

00:11:25,230 --> 00:11:29,790
to turn text into something you can

00:11:27,150 --> 00:11:33,120
operate on as if it was numbers the next

00:11:29,790 --> 00:11:34,800
step is fit so this is this is where the

00:11:33,120 --> 00:11:37,050
magic happens I think that's that's the

00:11:34,800 --> 00:11:39,120
line so right in here you say hey here's

00:11:37,050 --> 00:11:41,850
a bunch input data and here's what the

00:11:39,120 --> 00:11:43,020
results should be for that right results

00:11:41,850 --> 00:11:45,450
should be that's what the output data

00:11:43,020 --> 00:11:48,060
should be is this why it matches up the

00:11:45,450 --> 00:11:50,790
X and the y it does lots of math and

00:11:48,060 --> 00:11:52,680
statistics and it figures out what the

00:11:50,790 --> 00:11:53,850
value you know it figures out what it

00:11:52,680 --> 00:11:54,960
needs to store internally in order to be

00:11:53,850 --> 00:11:56,670
able to make predictions in the future

00:11:54,960 --> 00:11:59,010
predictions in the future is just this

00:11:56,670 --> 00:12:00,839
predict thing you pass an array of

00:11:59,010 --> 00:12:04,320
things to make predictions on it spits

00:12:00,839 --> 00:12:07,800
out an array of guesses basically very

00:12:04,320 --> 00:12:10,080
straightforward so that's kind of it

00:12:07,800 --> 00:12:12,450
like that's that's the real essence of

00:12:10,080 --> 00:12:15,990
this there's lots of engineering though

00:12:12,450 --> 00:12:18,360
the real world messy scary you got to

00:12:15,990 --> 00:12:22,770
get the data right how do you get the

00:12:18,360 --> 00:12:24,510
data requests in lxml so I've got a

00:12:22,770 --> 00:12:26,010
something that scrapes the front two

00:12:24,510 --> 00:12:28,380
pages of hacker news every four or five

00:12:26,010 --> 00:12:31,110
minutes parse it with lxml I pull out

00:12:28,380 --> 00:12:33,060
the links i crawl the links if I haven't

00:12:31,110 --> 00:12:34,860
seen them before and I just basically go

00:12:33,060 --> 00:12:36,810
through and try to grab all the data

00:12:34,860 --> 00:12:39,420
possible that i can from from hacker

00:12:36,810 --> 00:12:41,339
news so i have this raw data but what I

00:12:39,420 --> 00:12:43,529
need to know is I need to know what's

00:12:41,339 --> 00:12:46,260
good and what's not good so I wrote

00:12:43,529 --> 00:12:48,089
myself a web app I to classify direct

00:12:46,260 --> 00:12:49,950
and non dreck you can't see the big red

00:12:48,089 --> 00:12:53,880
buttons for bad they got cut off in the

00:12:49,950 --> 00:12:56,490
slide and so the course of about six

00:12:53,880 --> 00:12:58,589
weeks I think I classified a five

00:12:56,490 --> 00:12:59,580
thousand articles and found about twenty

00:12:58,589 --> 00:13:03,120
percent of them were things I was

00:12:59,580 --> 00:13:06,900
willing to read it was it was pretty

00:13:03,120 --> 00:13:08,580
epic for a while there I came up with

00:13:06,900 --> 00:13:15,510
lots of tricks to make this faster so i

00:13:08,580 --> 00:13:17,100
controlled f4 coin or NSA or San

00:13:15,510 --> 00:13:19,110
Francisco or a bunch of other things and

00:13:17,100 --> 00:13:21,480
and just try to get rid of world news

00:13:19,110 --> 00:13:22,829
and business hacks

00:13:21,480 --> 00:13:24,839
and I don't even know stuff I just I

00:13:22,829 --> 00:13:26,880
want to read and so I would and this is

00:13:24,839 --> 00:13:29,370
all my opinion so anyway I go through

00:13:26,880 --> 00:13:32,010
when i clicked bad bad bad bad bad this

00:13:29,370 --> 00:13:33,630
bring the pain button would show me site

00:13:32,010 --> 00:13:35,940
after site in the iframe with big

00:13:33,630 --> 00:13:37,290
buttons at the top for good and bad so

00:13:35,940 --> 00:13:39,510
there was a period there where I read

00:13:37,290 --> 00:13:42,959
everything that made the front two pages

00:13:39,510 --> 00:13:45,120
of hacker news almost so yeah this was

00:13:42,959 --> 00:13:46,589
that this was the hard part right this

00:13:45,120 --> 00:13:47,699
was actually the hardest most involved

00:13:46,589 --> 00:13:49,860
part in the entire thing was getting

00:13:47,699 --> 00:13:52,440
this data that I could then feed into my

00:13:49,860 --> 00:13:54,120
models so what data did I have I had the

00:13:52,440 --> 00:13:56,610
the title that it was submitted with I

00:13:54,120 --> 00:14:00,120
had a title if it changed I had the URL

00:13:56,610 --> 00:14:02,310
who submitted it what was there how

00:14:00,120 --> 00:14:03,540
whats max rank was how many votes that

00:14:02,310 --> 00:14:06,300
got how many comments what time of day

00:14:03,540 --> 00:14:08,550
and most importantly and most painfully

00:14:06,300 --> 00:14:11,459
arrived at whether I found it to be

00:14:08,550 --> 00:14:14,310
Drecker or not so when you turn this

00:14:11,459 --> 00:14:17,370
messy data into normalized happy healthy

00:14:14,310 --> 00:14:20,730
fun numpy arrays there's a lot of

00:14:17,370 --> 00:14:21,930
techniques for turning words into

00:14:20,730 --> 00:14:23,730
numbers and I kind of want to give a

00:14:21,930 --> 00:14:25,500
brief overview of some of them so that

00:14:23,730 --> 00:14:28,800
you've seen them and once again you know

00:14:25,500 --> 00:14:30,810
what to Google first up bag of words so

00:14:28,800 --> 00:14:33,540
we have the phrase time flies like an

00:14:30,810 --> 00:14:35,660
arrow fruit flies like bananas and this

00:14:33,540 --> 00:14:38,760
is an incredibly grammatically correct

00:14:35,660 --> 00:14:42,050
grammatically complicated in deep phrase

00:14:38,760 --> 00:14:45,690
right like flies is a verb in one and

00:14:42,050 --> 00:14:47,519
it's once a simile I don't this is this

00:14:45,690 --> 00:14:51,180
is hard for a human being to fully parse

00:14:47,519 --> 00:14:53,160
right so forget grammar who needs it

00:14:51,180 --> 00:14:55,170
we're going to treat these words as if

00:14:53,160 --> 00:14:56,730
they were just a bag of words and we're

00:14:55,170 --> 00:14:58,709
going to say Oh flies like time and

00:14:56,730 --> 00:15:00,690
arrow fruit bananas good they're all in

00:14:58,709 --> 00:15:01,980
there may be some some techniques to

00:15:00,690 --> 00:15:03,779
count them some it's bullying you say

00:15:01,980 --> 00:15:05,610
whether the word is there or not and

00:15:03,779 --> 00:15:08,550
also implicitly this doesn't mention

00:15:05,610 --> 00:15:09,810
Bitcoin so bitcoin is zero so we just

00:15:08,550 --> 00:15:11,459
kind of count up what's their treat it

00:15:09,810 --> 00:15:12,779
like it's a bag of words and just

00:15:11,459 --> 00:15:15,540
totally ignore this grammar stuff

00:15:12,779 --> 00:15:17,130
because grammar is hard so if you want a

00:15:15,540 --> 00:15:18,569
hint of the grammar though there's this

00:15:17,130 --> 00:15:20,130
thing called n-grams and people always

00:15:18,569 --> 00:15:21,750
talk about n grams and yoona grams and

00:15:20,130 --> 00:15:23,339
by grams and trigrams and i don't know

00:15:21,750 --> 00:15:25,589
what would it be quad grams I don't know

00:15:23,339 --> 00:15:27,300
people to say four grams so you just get

00:15:25,589 --> 00:15:28,680
chunks of words and you think of these

00:15:27,300 --> 00:15:31,019
chunks of words as if they were

00:15:28,680 --> 00:15:33,959
themselves words so instead of time

00:15:31,019 --> 00:15:35,459
flies being two words you think of it as

00:15:33,959 --> 00:15:37,949
time flies

00:15:35,459 --> 00:15:39,720
you think of flies like and you look at

00:15:37,949 --> 00:15:41,519
just pairs of words or groups of three

00:15:39,720 --> 00:15:42,839
or four however much input data you have

00:15:41,519 --> 00:15:45,389
and how much memory you're willing to

00:15:42,839 --> 00:15:48,420
burn and you just kind of start building

00:15:45,389 --> 00:15:50,249
this higher level understanding of it

00:15:48,420 --> 00:15:53,339
that includes just that little hint to

00:15:50,249 --> 00:15:55,499
the grammar it's also this concept

00:15:53,339 --> 00:15:56,790
called normalization so there's you

00:15:55,499 --> 00:16:00,569
sometimes hear stemming and limit

00:15:56,790 --> 00:16:02,129
ization and stemming is generally a hack

00:16:00,569 --> 00:16:04,230
and limited ation means looking it up in

00:16:02,129 --> 00:16:06,629
a dictionary this is a really

00:16:04,230 --> 00:16:09,119
interesting thing so there's this thing

00:16:06,629 --> 00:16:10,589
called the snowball stemmer and in NLT k

00:16:09,119 --> 00:16:12,029
which is the natural language toolkit

00:16:10,589 --> 00:16:14,069
and has lots of fun things to play with

00:16:12,029 --> 00:16:17,790
text in it and you can grab this stemmer

00:16:14,069 --> 00:16:20,279
and feed it just English language text

00:16:17,790 --> 00:16:22,379
and it tries to normalize it so does it

00:16:20,279 --> 00:16:25,110
really matter if you say flies or flied

00:16:22,379 --> 00:16:26,309
or flying or anyone of another couple

00:16:25,110 --> 00:16:27,329
different parts of speech it doesn't

00:16:26,309 --> 00:16:30,329
really matter they're all kind of the

00:16:27,329 --> 00:16:32,189
same thing so when he fly he liked to

00:16:30,329 --> 00:16:34,439
fly upon early flight so it just

00:16:32,189 --> 00:16:37,110
normalizes the words so that it kind of

00:16:34,439 --> 00:16:38,759
hides a little bit of tenses or plural

00:16:37,110 --> 00:16:41,519
versus singular I think it does a great

00:16:38,759 --> 00:16:44,220
job and finally there's this concept

00:16:41,519 --> 00:16:46,049
called stop words up not the final one

00:16:44,220 --> 00:16:47,579
this is concept called stop words and

00:16:46,049 --> 00:16:49,949
the idea what stop words is there are

00:16:47,579 --> 00:16:51,689
words which are just useless they don't

00:16:49,949 --> 00:16:53,639
give you any information about what's

00:16:51,689 --> 00:16:56,339
actually going on if you know that and

00:16:53,639 --> 00:16:59,339
are that a that's linked to from hacker

00:16:56,339 --> 00:17:00,269
news uses the word voix that doesn't

00:16:59,339 --> 00:17:03,089
give you any additional information

00:17:00,269 --> 00:17:05,220
right who cares all right it's it's just

00:17:03,089 --> 00:17:06,720
it's sort of the fluff that we use in

00:17:05,220 --> 00:17:09,270
normal English grammar to glue stuff

00:17:06,720 --> 00:17:10,529
together there's a set of stop words for

00:17:09,270 --> 00:17:13,740
English that are included in

00:17:10,529 --> 00:17:15,329
scikit-learn and you can just set an

00:17:13,740 --> 00:17:17,730
option on a bunch of different things to

00:17:15,329 --> 00:17:21,480
ignore stop words which can be you know

00:17:17,730 --> 00:17:23,250
pretty a pretty big boost this is this

00:17:21,480 --> 00:17:26,189
is the last thing here term frequency

00:17:23,250 --> 00:17:30,240
inverse document frequency so the idea

00:17:26,189 --> 00:17:33,690
is if you have a word like bitcoin and

00:17:30,240 --> 00:17:36,570
bitcoin shows up 12 times in this

00:17:33,690 --> 00:17:40,169
article whereas on average it only shows

00:17:36,570 --> 00:17:42,419
up one in every four articles this

00:17:40,169 --> 00:17:44,700
article is clearly very strongly about

00:17:42,419 --> 00:17:47,760
bitcoin it has much more Bitcoin in it

00:17:44,700 --> 00:17:49,290
than any other article so let's give the

00:17:47,760 --> 00:17:54,120
word Bitcoin a little

00:17:49,290 --> 00:17:55,950
bit of a boost and let's give the word

00:17:54,120 --> 00:18:00,360
Bitcoin a little bit of a boost here

00:17:55,950 --> 00:18:03,000
tell it to kind of you know get rid of

00:18:00,360 --> 00:18:05,130
it so other stuff here about engineering

00:18:03,000 --> 00:18:07,980
features so this is some some code i

00:18:05,130 --> 00:18:10,260
I've actually used in my my attempts

00:18:07,980 --> 00:18:12,410
here so we can pull out relevant text

00:18:10,260 --> 00:18:16,920
there's something called readability and

00:18:12,410 --> 00:18:18,510
readability lxml is a python we

00:18:16,920 --> 00:18:20,400
implement ation of this browser plugin

00:18:18,510 --> 00:18:22,400
that tries to get rid of all the junk

00:18:20,400 --> 00:18:25,410
around the outside of a webpage so

00:18:22,400 --> 00:18:27,870
recommended links that you know a menu

00:18:25,410 --> 00:18:29,880
at the top ads all sorts of other stuff

00:18:27,870 --> 00:18:31,770
that don't directly relate to the main

00:18:29,880 --> 00:18:34,110
content of the article it tries to pull

00:18:31,770 --> 00:18:37,560
them all out with heuristics and so with

00:18:34,110 --> 00:18:40,890
readability XML I take it I grab that

00:18:37,560 --> 00:18:43,230
summary i parse the thing with lxml

00:18:40,890 --> 00:18:45,150
again i try to pull out all the text and

00:18:43,230 --> 00:18:47,250
then I return the text so I'm cleaning

00:18:45,150 --> 00:18:49,230
out all of the HTML tags I'm cleaning

00:18:47,250 --> 00:18:52,530
out everything I'm trying to get just to

00:18:49,230 --> 00:18:56,630
what is the relevant actual real text

00:18:52,530 --> 00:19:00,780
for this particular for this particular

00:18:56,630 --> 00:19:02,490
HTML page right you can also roll your

00:19:00,780 --> 00:19:05,370
own features so I had a theory that I

00:19:02,490 --> 00:19:07,650
liked long-form content so what this

00:19:05,370 --> 00:19:10,850
does is right here in the transform

00:19:07,650 --> 00:19:13,500
function it takes an array of text and

00:19:10,850 --> 00:19:15,090
it just counts how long each one is and

00:19:13,500 --> 00:19:18,360
returns that back as a nice

00:19:15,090 --> 00:19:20,070
two-dimensional array and so you feed it

00:19:18,360 --> 00:19:21,990
text and you get back out numbers

00:19:20,070 --> 00:19:25,380
between I don't know zero and probably

00:19:21,990 --> 00:19:28,020
tens of thousands all these things want

00:19:25,380 --> 00:19:29,880
the numbers to be like centered on 0 and

00:19:28,020 --> 00:19:32,040
usually like standard deviation to

00:19:29,880 --> 00:19:35,370
either side of one to negative 1 and

00:19:32,040 --> 00:19:37,830
this standard scalar thing which is out

00:19:35,370 --> 00:19:39,990
of the box takes these random crazy

00:19:37,830 --> 00:19:41,880
length numbers and centers them on 0 and

00:19:39,990 --> 00:19:44,690
makes them a nice little even

00:19:41,880 --> 00:19:47,040
distribution around 0 so I could then

00:19:44,690 --> 00:19:48,990
have this additional feature that I

00:19:47,040 --> 00:19:51,450
created from scratch where I kind of

00:19:48,990 --> 00:19:53,430
inferred something from that source

00:19:51,450 --> 00:19:57,270
material that wasn't immediately obvious

00:19:53,430 --> 00:19:58,650
in it length you can also combine

00:19:57,270 --> 00:20:00,720
features with this thing called feature

00:19:58,650 --> 00:20:02,759
Union and basically what this does is

00:20:00,720 --> 00:20:04,229
this takes two

00:20:02,759 --> 00:20:05,579
numpy are raised and kind of

00:20:04,229 --> 00:20:07,289
concatenates them and sticks them right

00:20:05,579 --> 00:20:09,599
next to each other so that you can feed

00:20:07,289 --> 00:20:11,489
in multiple signals and stick them

00:20:09,599 --> 00:20:13,499
together with this feature Union and you

00:20:11,489 --> 00:20:16,649
also notice I stuck this length pipeline

00:20:13,499 --> 00:20:18,539
in as if it were yet another thing so I

00:20:16,649 --> 00:20:21,269
i have like pipelines and side pipelines

00:20:18,539 --> 00:20:22,679
and side pipelines to sort of massage

00:20:21,269 --> 00:20:27,449
together different features that then

00:20:22,679 --> 00:20:29,070
get exposed all the way up but my data

00:20:27,449 --> 00:20:30,359
starts his dictionary so I'm just

00:20:29,070 --> 00:20:34,499
pulling this out of a database

00:20:30,359 --> 00:20:36,749
because I'm lazy and this little thing

00:20:34,499 --> 00:20:39,690
here is a transformer that will pull

00:20:36,749 --> 00:20:42,839
values out of a dictionary and return

00:20:39,690 --> 00:20:44,729
those values so the way I use this is I

00:20:42,839 --> 00:20:46,919
got this idea that maybe host names are

00:20:44,729 --> 00:20:49,049
relevant right there are places that

00:20:46,919 --> 00:20:51,209
seem to post good content there's places

00:20:49,049 --> 00:20:53,219
that post awful content and that should

00:20:51,209 --> 00:20:55,379
be a signal that might should go into

00:20:53,219 --> 00:21:00,659
this machine learning bit right so what

00:20:55,379 --> 00:21:03,929
I do is I use URL parse to pull out the

00:21:00,659 --> 00:21:06,509
host name for a URL and then I just

00:21:03,929 --> 00:21:09,839
return that and then I build a pipeline

00:21:06,509 --> 00:21:11,969
once again I build a pipeline so I feed

00:21:09,839 --> 00:21:16,529
this in the raw manga results from my

00:21:11,969 --> 00:21:19,229
database it extracts the URL from that

00:21:16,529 --> 00:21:23,219
and turns it into an array of strings I

00:21:19,229 --> 00:21:25,379
then extract the host name from that URL

00:21:23,219 --> 00:21:27,449
and I pass it through this vector

00:21:25,379 --> 00:21:29,519
Iser thing which then turns it into a

00:21:27,449 --> 00:21:31,079
nice numerical numpy array which is

00:21:29,519 --> 00:21:33,559
pretty much always the goal is to turn

00:21:31,079 --> 00:21:36,359
it into this nice little numpy array so

00:21:33,559 --> 00:21:37,949
what is the actual application look like

00:21:36,359 --> 00:21:40,789
how do you actually use this stuff to do

00:21:37,949 --> 00:21:45,119
new predictions you do this sorry Alex

00:21:40,789 --> 00:21:48,149
anyway say savior save your input data

00:21:45,119 --> 00:21:49,769
so you can recreate it later I know of

00:21:48,149 --> 00:21:52,049
production systems which cannot be

00:21:49,769 --> 00:21:54,449
upgraded on penalty of death because

00:21:52,049 --> 00:21:56,159
there's some pickle from like seven

00:21:54,449 --> 00:21:59,940
years ago that we can't recreate and

00:21:56,159 --> 00:22:01,529
like don't touch it right so anyway keep

00:21:59,940 --> 00:22:03,539
your sample keep your source data so you

00:22:01,529 --> 00:22:05,729
can recreate it but you just take that

00:22:03,539 --> 00:22:07,979
thing you pick like mine is I think it's

00:22:05,729 --> 00:22:10,409
like gzipped the pickle that does the

00:22:07,979 --> 00:22:12,149
predictions is like five megs and I've

00:22:10,409 --> 00:22:14,929
got an ansible script that pulls it down

00:22:12,149 --> 00:22:16,200
from s3 and throws it on the right place

00:22:14,929 --> 00:22:18,179
then you

00:22:16,200 --> 00:22:19,919
pass in input data in the same format

00:22:18,179 --> 00:22:23,490
that it got the input data when you were

00:22:19,919 --> 00:22:26,580
training it and it magically works so I

00:22:23,490 --> 00:22:28,409
built this thing and there's a bunch of

00:22:26,580 --> 00:22:30,450
different colors most of them having to

00:22:28,409 --> 00:22:32,039
do with what data I can grab but red

00:22:30,450 --> 00:22:34,110
basically means stuff at things I

00:22:32,039 --> 00:22:36,059
shouldn't read and green is stuff I

00:22:34,110 --> 00:22:39,360
think it should read and I put it up at

00:22:36,059 --> 00:22:40,980
hnn jailed at us and I like this morning

00:22:39,360 --> 00:22:42,659
when oh boy probably better turn cashing

00:22:40,980 --> 00:22:46,470
on for that so hopefully I did that

00:22:42,659 --> 00:22:48,630
right and if you have all this data

00:22:46,470 --> 00:22:49,710
right so you can build this app to sort

00:22:48,630 --> 00:22:51,059
stuff but if you have a date you can do

00:22:49,710 --> 00:22:53,549
lots of other things so I mentioned

00:22:51,059 --> 00:22:54,929
unsupervised learning can you look at it

00:22:53,549 --> 00:22:56,669
and figure out are there other

00:22:54,929 --> 00:22:59,370
interesting things I can do here are

00:22:56,669 --> 00:23:02,460
there other is there can I cluster it

00:22:59,370 --> 00:23:05,279
like I said can I find clusters maybe

00:23:02,460 --> 00:23:06,389
you could predict article scores which

00:23:05,279 --> 00:23:07,620
would then be really interesting

00:23:06,389 --> 00:23:09,659
combined with something that watched an

00:23:07,620 --> 00:23:13,289
RSS feed and maybe Otto submitted I'm

00:23:09,659 --> 00:23:14,490
just saying and the real point of my

00:23:13,289 --> 00:23:15,840
talk the thing that I really want to

00:23:14,490 --> 00:23:18,630
stress is that machine learning is

00:23:15,840 --> 00:23:20,370
becoming engineering this is starting to

00:23:18,630 --> 00:23:21,630
move out of the range of science where

00:23:20,370 --> 00:23:23,010
nobody really understands what it does

00:23:21,630 --> 00:23:25,139
and you have to read a million articles

00:23:23,010 --> 00:23:26,639
and get a doctorate in this stuff in

00:23:25,139 --> 00:23:28,500
order to be able to actually apply it to

00:23:26,639 --> 00:23:30,210
the real world there are libraries out

00:23:28,500 --> 00:23:31,549
there that you can use that you can

00:23:30,210 --> 00:23:34,289
start to understand the properties of

00:23:31,549 --> 00:23:35,669
you know 20 years ago if you wanted to

00:23:34,289 --> 00:23:38,010
use a red black tree you pretty much had

00:23:35,669 --> 00:23:39,929
to write it yourself right and now we

00:23:38,010 --> 00:23:41,159
just accept that these fancy things are

00:23:39,929 --> 00:23:42,630
in libraries and I think machine

00:23:41,159 --> 00:23:43,769
learning is going the same way these are

00:23:42,630 --> 00:23:44,669
going to be awesome statistical

00:23:43,769 --> 00:23:46,440
techniques you're going to need to know

00:23:44,669 --> 00:23:47,669
a lot about the characteristics of but

00:23:46,440 --> 00:23:49,200
they're going to be in libraries they

00:23:47,669 --> 00:23:51,059
are in libraries you can just go use

00:23:49,200 --> 00:23:55,279
them so go use them and do interesting

00:23:51,059 --> 00:23:55,279
things thank you

00:24:07,370 --> 00:24:12,540
she thanked me for the talk and say we

00:24:09,630 --> 00:24:16,230
have how long for Q&A four minutes for

00:24:12,540 --> 00:24:17,490
Q&A do we have any questions do we don't

00:24:16,230 --> 00:24:21,260
have the microphone work go ahead and I

00:24:17,490 --> 00:24:21,260
saw you go talk loud so I can hear you

00:24:26,600 --> 00:24:34,680
that when I was gathering data did I

00:24:28,740 --> 00:24:37,560
look at a search engine oh yeah no that

00:24:34,680 --> 00:24:40,440
was that was older that I I did this I

00:24:37,560 --> 00:24:43,440
did this um I think I did this a couple

00:24:40,440 --> 00:24:44,880
months before the new search engine yeah

00:24:43,440 --> 00:24:46,860
so I don't look at that I you know

00:24:44,880 --> 00:24:48,810
frankly I just need to grab to

00:24:46,860 --> 00:24:51,120
essentially static web pages every five

00:24:48,810 --> 00:24:53,850
minutes I wasn't really interested in

00:24:51,120 --> 00:24:56,070
doing in-depth mining of the data there

00:24:53,850 --> 00:24:58,290
was enough scary dangerous dangerousness

00:24:56,070 --> 00:24:59,580
and crawling random URLs off of hacker

00:24:58,290 --> 00:25:02,130
news and putting them in a database to

00:24:59,580 --> 00:25:05,850
keep me occupied any other questions yes

00:25:02,130 --> 00:25:07,020
over there yeah but if we could try to

00:25:05,850 --> 00:25:10,140
get in line for the mic is it working

00:25:07,020 --> 00:25:11,490
now yeah awesome I feel like I should

00:25:10,140 --> 00:25:19,050
just have you shot your question rather

00:25:11,490 --> 00:25:21,240
than get line so so he's wondering about

00:25:19,050 --> 00:25:23,550
my accuracy with the features i picked i

00:25:21,240 --> 00:25:25,950
found the fancier i got the worst my

00:25:23,550 --> 00:25:28,410
accuracy gut it's around ninety percent

00:25:25,950 --> 00:25:30,600
accurate and all of the failures except

00:25:28,410 --> 00:25:31,860
for one because i looked at each one

00:25:30,600 --> 00:25:33,120
because i was like what's going on so

00:25:31,860 --> 00:25:34,650
it's ninety percent accurate which i'm

00:25:33,120 --> 00:25:36,930
proud of because anybody can get eighty

00:25:34,650 --> 00:25:38,610
percent this but it's naughty percent

00:25:36,930 --> 00:25:40,650
accurate and all the failures are things

00:25:38,610 --> 00:25:43,620
that thinks i shouldn't read that i

00:25:40,650 --> 00:25:44,850
marked as i would read and i went back

00:25:43,620 --> 00:25:47,670
and looked at them and they were usually

00:25:44,850 --> 00:25:50,700
things where i said oh i would like to

00:25:47,670 --> 00:25:52,980
read the first article about the NSA and

00:25:50,700 --> 00:25:55,590
then the rest of them i was like no no

00:25:52,980 --> 00:25:56,790
I'm done now so a lot of my failures

00:25:55,590 --> 00:26:00,690
were things that I had marked as

00:25:56,790 --> 00:26:04,620
readable and then changed my mind any

00:26:00,690 --> 00:26:06,540
other questions we do have a mic we

00:26:04,620 --> 00:26:10,370
should probably be lining up for do we

00:26:06,540 --> 00:26:10,370
want Wow good somebody back there

00:26:19,150 --> 00:26:25,700
yeah so so basically you do something

00:26:22,400 --> 00:26:27,530
called cross validation where you hold

00:26:25,700 --> 00:26:29,870
out a portion of your data as if it's

00:26:27,530 --> 00:26:31,610
you know cross validation and you train

00:26:29,870 --> 00:26:33,050
the other eighty percent and then you

00:26:31,610 --> 00:26:35,150
see how it's good is it predicting the

00:26:33,050 --> 00:26:37,340
twenty percent and so you try a bunch of

00:26:35,150 --> 00:26:39,200
different methods and you try and I

00:26:37,340 --> 00:26:41,300
actually built this thing that put like

00:26:39,200 --> 00:26:42,860
many pipelines in parallel and then

00:26:41,300 --> 00:26:45,410
optimized every one of these pipelines

00:26:42,860 --> 00:26:46,730
and then pick the best pipeline and then

00:26:45,410 --> 00:26:48,230
spit out what that was for me and then

00:26:46,730 --> 00:26:51,320
retrain the data so that my pickle was

00:26:48,230 --> 00:26:54,140
only 25 megabytes raw instead of like

00:26:51,320 --> 00:26:59,330
500 megabytes raw so yeah you can you

00:26:54,140 --> 00:27:00,860
can you just try out all the options

00:26:59,330 --> 00:27:03,050
like there's all these switches and you

00:27:00,860 --> 00:27:04,400
just flip all the switches and you have

00:27:03,050 --> 00:27:06,140
the computer flip all the switches for

00:27:04,400 --> 00:27:08,180
you the next thing you know you know

00:27:06,140 --> 00:27:09,290
your laptop is very very hot and you

00:27:08,180 --> 00:27:10,550
have something that can predict if

00:27:09,290 --> 00:27:12,830
hacker news articles are crap or not

00:27:10,550 --> 00:27:17,030
it's amazing yes question so can you

00:27:12,830 --> 00:27:19,340
train as you use your Katrina's use it

00:27:17,030 --> 00:27:22,820
yeah this this whole thing about you

00:27:19,340 --> 00:27:26,200
know feedback loops and taking a model

00:27:22,820 --> 00:27:28,190
and updating the model there's lots of

00:27:26,200 --> 00:27:30,020
complicated stuff there that I'm happy

00:27:28,190 --> 00:27:32,240
to say is sort of starts being out of my

00:27:30,020 --> 00:27:33,920
realm of real understanding but I do

00:27:32,240 --> 00:27:35,810
have some stuff in place where i go

00:27:33,920 --> 00:27:37,460
through every once in a while and i will

00:27:35,810 --> 00:27:39,890
flag a bunch of articles as this one is

00:27:37,460 --> 00:27:41,210
bad if this one is good and i will use

00:27:39,890 --> 00:27:42,470
the fact that it's already been sorted

00:27:41,210 --> 00:27:44,540
for me to kind of like help me go

00:27:42,470 --> 00:27:47,600
through them faster there are techniques

00:27:44,540 --> 00:27:49,840
for like you know updating your model

00:27:47,600 --> 00:27:53,240
and stuff but frankly i'm scared of them

00:27:49,840 --> 00:27:56,300
yes you said that you needed about five

00:27:53,240 --> 00:27:57,890
thousand articles yep what would be the

00:27:56,300 --> 00:28:00,230
minimum number actually to be able to

00:27:57,890 --> 00:28:01,280
have anything so i did five thousand

00:28:00,230 --> 00:28:02,510
articles what would be the minimum

00:28:01,280 --> 00:28:06,020
number of articles be able to do this

00:28:02,510 --> 00:28:07,370
sort of thing that's a good question you

00:28:06,020 --> 00:28:08,720
know if you look at the nice little flow

00:28:07,370 --> 00:28:10,220
chart it says oh do you have at least 50

00:28:08,720 --> 00:28:12,830
things okay then you can start doing

00:28:10,220 --> 00:28:14,600
stuff but the real sort of weird thing

00:28:12,830 --> 00:28:17,390
that the way this works is you want your

00:28:14,600 --> 00:28:20,060
number of samples so you want kind of

00:28:17,390 --> 00:28:23,290
the number of rows to be to be much more

00:28:20,060 --> 00:28:25,150
than the number of columns

00:28:23,290 --> 00:28:26,710
I think we're done you want the number

00:28:25,150 --> 00:28:29,050
of rows to be more than the number of

00:28:26,710 --> 00:28:31,600
columns and so if you're going to be

00:28:29,050 --> 00:28:32,710
feeding in text which by the nature of

00:28:31,600 --> 00:28:34,180
having all these different words is

00:28:32,710 --> 00:28:36,880
going to have in many different columns

00:28:34,180 --> 00:28:40,770
you kind of need to have a lot of rows

00:28:36,880 --> 00:28:43,630
right so 5,000 might not even be enough

00:28:40,770 --> 00:28:47,440
but again who knows maybe a thousand and

00:28:43,630 --> 00:28:50,670
work and anybody else all right thank

00:28:47,440 --> 00:28:50,670

YouTube URL: https://www.youtube.com/watch?v=O7IezJT9uSI


