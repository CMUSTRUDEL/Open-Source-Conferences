Title: Craig Kerstiens: Postgres Performance for Humans - PyCon 2014
Publication date: 2014-04-24
Playlist: PyCon 2014
Description: 
	Speaker: Craig Kerstiens

To many developers the database is a black box. You expect to be able to put data into your database, have it to stay there, and get it out when you query it... hopefully in a performant manner. When its not performant enough the two options are usually add some indexes or throw some hardware at it. We'll walk through a bit of a clearer guide of how you can understand and manage DB performance.

Slides can be found at: https://speakerdeck.com/pycon2014 and https://github.com/PyCon/2014-slides
Captions: 
	00:00:05,420 --> 00:00:10,889
okay good afternoon hike on I hope you

00:00:08,519 --> 00:00:12,870
enjoyed your lunch and the poster

00:00:10,889 --> 00:00:14,429
session there and the jobs fair I am

00:00:12,870 --> 00:00:16,590
just a couple of announcements before we

00:00:14,429 --> 00:00:18,210
get started here and I would just like

00:00:16,590 --> 00:00:21,390
to remind all the auction winners to

00:00:18,210 --> 00:00:23,279
pick up their winnings if you want an

00:00:21,390 --> 00:00:25,410
item at the auction last night please go

00:00:23,279 --> 00:00:27,390
down to the registration desk right now

00:00:25,410 --> 00:00:31,080
to pick it up it will be closing soon

00:00:27,390 --> 00:00:33,390
and secondly I'd like to mention the

00:00:31,080 --> 00:00:35,399
Sprint's after the conference ends will

00:00:33,390 --> 00:00:36,960
be holding development Sprint's Sprint's

00:00:35,399 --> 00:00:38,760
or a great chance to get your first

00:00:36,960 --> 00:00:40,950
patch accepted to your favorite library

00:00:38,760 --> 00:00:43,200
and meet the authors and get introduced

00:00:40,950 --> 00:00:44,910
the open source contribution so stick

00:00:43,200 --> 00:00:47,070
around after the closing messages for an

00:00:44,910 --> 00:00:49,170
introduction to the sprint or just show

00:00:47,070 --> 00:00:51,000
up here on Monday and if you want to

00:00:49,170 --> 00:00:52,620
lead a sprint please prepare a two

00:00:51,000 --> 00:00:56,640
minute description to get people excited

00:00:52,620 --> 00:00:57,899
about sprinting on your project it's our

00:00:56,640 --> 00:01:01,379
okay well it says two minutes on you

00:00:57,899 --> 00:01:02,820
okay it is now 20 seconds okay I am to

00:01:01,379 --> 00:01:04,589
get people excited about sprinting on

00:01:02,820 --> 00:01:08,729
your project you'll be able to present

00:01:04,589 --> 00:01:11,159
that after the lightning talks okay I am

00:01:08,729 --> 00:01:12,780
so next up we have Craig kirstens and

00:01:11,159 --> 00:01:15,600
he's going to be telling us about

00:01:12,780 --> 00:01:17,630
postgres performance for humans take it

00:01:15,600 --> 00:01:17,630
away

00:01:22,980 --> 00:01:28,420
Thanks hi everyone so I'm Craig car

00:01:25,900 --> 00:01:30,310
scenes I work at Heroku I run product

00:01:28,420 --> 00:01:32,560
for a couple of teams for our data team

00:01:30,310 --> 00:01:35,680
which runs Heroku postgres and our

00:01:32,560 --> 00:01:36,970
languages team I basically have the job

00:01:35,680 --> 00:01:40,300
of doing whatever the engineers don't

00:01:36,970 --> 00:01:43,000
want to do is the way I describe it so

00:01:40,300 --> 00:01:45,040
really quickly to start off some some

00:01:43,000 --> 00:01:46,180
quick and shameless plugs and throughout

00:01:45,040 --> 00:01:47,260
this talk it's gonna be a little bit of

00:01:46,180 --> 00:01:49,330
a shotgun approach i'm going to throw

00:01:47,260 --> 00:01:51,760
kind of a lot of various information at

00:01:49,330 --> 00:01:53,440
you a lot to get through so it'll kind

00:01:51,760 --> 00:01:55,840
of be a little bit disparate at times

00:01:53,440 --> 00:01:57,250
but some shameless plugs i curate an

00:01:55,840 --> 00:01:59,260
email newsletter called post for us

00:01:57,250 --> 00:02:01,210
weekly if you're an end user an app

00:01:59,260 --> 00:02:04,030
developer and use postgres hopefully it

00:02:01,210 --> 00:02:06,510
has useful content i blogged a good bit

00:02:04,030 --> 00:02:09,250
postgres guide is kind of a guide for

00:02:06,510 --> 00:02:11,740
you know getting started up to some

00:02:09,250 --> 00:02:14,760
interesting cool things in Postgres if

00:02:11,740 --> 00:02:18,130
you're on a map Mac use postgres top

00:02:14,760 --> 00:02:19,959
don't use macports or homebrew if you've

00:02:18,130 --> 00:02:22,000
already got it great keep using it but

00:02:19,959 --> 00:02:25,090
if you run into problems with it which

00:02:22,000 --> 00:02:26,800
you will give postgres tap a try and

00:02:25,090 --> 00:02:32,170
then I work at Heroku we run a lot of

00:02:26,800 --> 00:02:34,300
postgres so usually when I give quite a

00:02:32,170 --> 00:02:36,160
few talks and usually when i talk about

00:02:34,300 --> 00:02:38,200
you know postgres and why it's great i

00:02:36,160 --> 00:02:41,290
put up a slide that looks kind of like

00:02:38,200 --> 00:02:42,370
this this is all the awesome features in

00:02:41,290 --> 00:02:45,190
Postgres if you don't know about

00:02:42,370 --> 00:02:46,239
something on the slide google it every

00:02:45,190 --> 00:02:48,700
single thing here you should probably

00:02:46,239 --> 00:02:51,400
know about and use or have the ability

00:02:48,700 --> 00:02:54,880
to use it sometime to make this easy for

00:02:51,400 --> 00:02:57,790
for twitter this is a quote by a

00:02:54,880 --> 00:02:59,350
co-worker basically post-crisis becoming

00:02:57,790 --> 00:03:01,660
more and more of a data platform then it

00:02:59,350 --> 00:03:04,420
is just a relational database there's

00:03:01,660 --> 00:03:05,620
full-text search there she is there's

00:03:04,420 --> 00:03:07,930
about everything you could want to do in

00:03:05,620 --> 00:03:11,350
there and it's really becoming a much

00:03:07,930 --> 00:03:12,820
more flexible platform overall so kind

00:03:11,350 --> 00:03:15,250
of getting into a little bit more of the

00:03:12,820 --> 00:03:16,540
the meat when you think about database

00:03:15,250 --> 00:03:20,850
works loads there's kind of two ways

00:03:16,540 --> 00:03:24,790
there's a lap and a little teepee so

00:03:20,850 --> 00:03:27,850
oltp is essentially web apps that's you

00:03:24,790 --> 00:03:30,810
know web applications Shango flask small

00:03:27,850 --> 00:03:34,329
writes and reads transactional workload

00:03:30,810 --> 00:03:34,900
olap is business reporting bi large

00:03:34,329 --> 00:03:38,110
report

00:03:34,900 --> 00:03:40,629
over a lot of data you're looking at MPP

00:03:38,110 --> 00:03:42,909
type solutions here and I'm essentially

00:03:40,629 --> 00:03:45,099
not going to talk about any of this

00:03:42,909 --> 00:03:47,560
really in the talk so if you're looking

00:03:45,099 --> 00:03:50,709
at this a you know to get kind of advice

00:03:47,560 --> 00:03:52,599
on data warehousing stuff happy to shot

00:03:50,709 --> 00:03:53,920
afterwards but hopefully most of the

00:03:52,599 --> 00:03:55,420
people in this room where our web app

00:03:53,920 --> 00:03:56,379
developers actually it's show hands

00:03:55,420 --> 00:04:00,189
inside the case for most people

00:03:56,379 --> 00:04:04,470
developing web apps ok cool so right off

00:04:00,189 --> 00:04:06,430
against things good on setup and config

00:04:04,470 --> 00:04:07,690
I'm not going to spend a whole lot of

00:04:06,430 --> 00:04:11,470
time here since you only have to do it

00:04:07,690 --> 00:04:15,579
once another short of it is if you're on

00:04:11,470 --> 00:04:17,260
Amazon use Heroku or go check out this

00:04:15,579 --> 00:04:19,090
talk last year I think from Pike on um

00:04:17,260 --> 00:04:20,769
it's definitely been giving it a lot of

00:04:19,090 --> 00:04:22,660
Jenga conferences postgresql when it's

00:04:20,769 --> 00:04:24,490
not your day job by Christophe Pettis

00:04:22,660 --> 00:04:26,169
it's a great talk basically there's

00:04:24,490 --> 00:04:29,560
about 30 configs you need to set up once

00:04:26,169 --> 00:04:31,389
once you do it you're done so start

00:04:29,560 --> 00:04:35,979
there and essentially don't worry about

00:04:31,389 --> 00:04:37,630
it because amazon is sort of virtualized

00:04:35,979 --> 00:04:39,729
infrastructure on top of virtualized

00:04:37,630 --> 00:04:41,800
infrastructure on top of more

00:04:39,729 --> 00:04:44,320
virtualization it's a little different

00:04:41,800 --> 00:04:45,669
if you're on any other cloud a lot of

00:04:44,320 --> 00:04:47,229
them are a good bit different you get a

00:04:45,669 --> 00:04:49,900
little bit more predictability and disk

00:04:47,229 --> 00:04:51,849
and that kind of thing the best bet is

00:04:49,900 --> 00:04:52,930
postgresql when it's not your day job so

00:04:51,849 --> 00:04:55,389
you're setting a bunch of configs

00:04:52,930 --> 00:04:57,000
they're a little different it'll

00:04:55,389 --> 00:05:00,220
basically get you up and running and

00:04:57,000 --> 00:05:01,840
then if you're on real hardware high

00:05:00,220 --> 00:05:04,530
performance postgresql this looks a

00:05:01,840 --> 00:05:09,280
little old now it's based on postgres 90

00:05:04,530 --> 00:05:11,380
but if you've got SSDs fusion-io really

00:05:09,280 --> 00:05:12,669
kind of any real hardware this is still

00:05:11,380 --> 00:05:16,599
really applicable I think it's being

00:05:12,669 --> 00:05:19,630
upgraded for updated 493 but essentially

00:05:16,599 --> 00:05:24,520
this is where you want to start and

00:05:19,630 --> 00:05:28,900
there's a link to the slides as well so

00:05:24,520 --> 00:05:31,090
um any time I come and look at a new

00:05:28,900 --> 00:05:33,699
database the first thing I want to do is

00:05:31,090 --> 00:05:37,000
like take the 30,000 foot view of how is

00:05:33,699 --> 00:05:39,669
this doing doesn't need more hardware is

00:05:37,000 --> 00:05:42,400
it just screwed how about are we doing

00:05:39,669 --> 00:05:45,130
and the number one thing that any web

00:05:42,400 --> 00:05:47,500
app should care about is the the cash so

00:05:45,130 --> 00:05:48,610
postgres is really good at keeping

00:05:47,500 --> 00:05:50,800
frequently accessed

00:05:48,610 --> 00:05:52,120
data in memory I know you think you're

00:05:50,800 --> 00:05:55,689
going to be better at cashing your data

00:05:52,120 --> 00:05:59,430
than postgres will you won't go ahead

00:05:55,689 --> 00:06:01,150
and try it's really good at this so

00:05:59,430 --> 00:06:02,289
essentially you're going to aim for a

00:06:01,150 --> 00:06:03,909
pretty high like ninety-nine percent

00:06:02,289 --> 00:06:05,710
cache hit ratio that means it's serving

00:06:03,909 --> 00:06:07,030
data out of memory ninety-nine percent

00:06:05,710 --> 00:06:09,849
of the time and one percent attending

00:06:07,030 --> 00:06:13,060
disk to get that you run this super

00:06:09,849 --> 00:06:16,539
simple query and it's going to give you

00:06:13,060 --> 00:06:18,789
something that looks like this basically

00:06:16,539 --> 00:06:20,020
don't try to memorize the query you

00:06:18,789 --> 00:06:21,610
figure out what it's doing it's crazy

00:06:20,020 --> 00:06:23,860
internal post-press stuff some of the

00:06:21,610 --> 00:06:24,879
columns actually don't make sense but

00:06:23,860 --> 00:06:29,020
that's going to give you you know the

00:06:24,879 --> 00:06:30,340
cache hit ratio and like I said

00:06:29,020 --> 00:06:32,770
ninety-nine percent or higher is what

00:06:30,340 --> 00:06:34,599
you're aiming for if you don't have that

00:06:32,770 --> 00:06:37,180
you probably want to throw more memory

00:06:34,599 --> 00:06:40,900
at the box that's the easiest way to

00:06:37,180 --> 00:06:43,389
start scaling your database so index hit

00:06:40,900 --> 00:06:45,189
is another one how often are you using

00:06:43,389 --> 00:06:46,779
indexes for not so this is definitely

00:06:45,189 --> 00:06:49,120
important for web applications if you're

00:06:46,779 --> 00:06:51,969
talking about bi and reporting

00:06:49,120 --> 00:06:53,440
applications it's less common but what I

00:06:51,969 --> 00:06:55,740
want to see is you know heavy index

00:06:53,440 --> 00:06:58,990
usage I want things served from index

00:06:55,740 --> 00:07:01,779
frequently so that queries going to give

00:06:58,990 --> 00:07:03,539
me something like this and from here I

00:07:01,779 --> 00:07:06,520
can actually start digging in and saying

00:07:03,539 --> 00:07:10,240
all right where do I need to add indexes

00:07:06,520 --> 00:07:12,550
and some rough guidelines so cache hit

00:07:10,240 --> 00:07:14,469
ratio ninety-nine percent are higher as

00:07:12,550 --> 00:07:16,599
soon as you drop below ninety nine

00:07:14,469 --> 00:07:19,779
percent down to like 95 you're going to

00:07:16,599 --> 00:07:21,879
see performance significantly tank index

00:07:19,779 --> 00:07:23,919
hit ratio greater than ninety five

00:07:21,879 --> 00:07:26,020
percent I actually have a tweet

00:07:23,919 --> 00:07:28,449
somewhere in my history that will add an

00:07:26,020 --> 00:07:30,550
index on every column and every table in

00:07:28,449 --> 00:07:31,750
your database I don't know that I'd

00:07:30,550 --> 00:07:34,870
encourage it but you could definitely do

00:07:31,750 --> 00:07:35,979
it if you're using a table that's you've

00:07:34,870 --> 00:07:37,389
got a table and you've got queries

00:07:35,979 --> 00:07:39,189
against it that are never using an index

00:07:37,389 --> 00:07:40,270
start adding you like it should be

00:07:39,189 --> 00:07:42,699
pretty straightforward on how you're

00:07:40,270 --> 00:07:46,389
using the table if it's a really small

00:07:42,699 --> 00:07:49,120
table you can get away without it so a

00:07:46,389 --> 00:07:51,810
really handy shortcut how many people

00:07:49,120 --> 00:07:56,050
here use like a bash our CEO of mr see

00:07:51,810 --> 00:07:57,940
how many people here use a pc QRC i'm

00:07:56,050 --> 00:08:00,729
actually impressed that there's like ten

00:07:57,940 --> 00:08:02,259
hands in the room so PC klar see is

00:08:00,729 --> 00:08:02,540
awesome it doesn't mean it's the same

00:08:02,259 --> 00:08:05,180
thing

00:08:02,540 --> 00:08:07,310
right you can set a lot of commands the

00:08:05,180 --> 00:08:08,660
really nice thing is that you can set

00:08:07,310 --> 00:08:10,880
some shortcuts here so I can name

00:08:08,660 --> 00:08:13,610
queries so I can have that cache hit

00:08:10,880 --> 00:08:15,080
query saved and just run cache hit on

00:08:13,610 --> 00:08:17,480
any database i connect to and it's going

00:08:15,080 --> 00:08:18,740
to run that query for me so really handy

00:08:17,480 --> 00:08:23,210
for frequently used queries across

00:08:18,740 --> 00:08:25,400
different systems you're working with so

00:08:23,210 --> 00:08:27,710
a bit of a quick detour on how data is

00:08:25,400 --> 00:08:30,920
retrieved hopefully this is really

00:08:27,710 --> 00:08:32,150
boring in 101 but if it's not I figure

00:08:30,920 --> 00:08:37,190
it's a good baseline for everyone to

00:08:32,150 --> 00:08:38,720
kind of have so when you interact with

00:08:37,190 --> 00:08:40,880
your database and you're retrieving data

00:08:38,720 --> 00:08:42,919
from it really basically it's going to

00:08:40,880 --> 00:08:45,290
come down to consuming data one of two

00:08:42,919 --> 00:08:48,170
ways a sequential scan so all the data

00:08:45,290 --> 00:08:50,030
is simply sitting on disk and if you

00:08:48,170 --> 00:08:51,320
have a query select star where this

00:08:50,030 --> 00:08:54,470
condition is true it's going to start

00:08:51,320 --> 00:08:56,570
iterating on disk and looking for data

00:08:54,470 --> 00:08:58,610
that meets that condition and the only

00:08:56,570 --> 00:09:00,200
way it's going to stop scanning that

00:08:58,610 --> 00:09:01,610
table is when it's you've got a limit on

00:09:00,200 --> 00:09:03,290
it so if you've got a limit of one it's

00:09:01,610 --> 00:09:05,990
going to find the first row until it

00:09:03,290 --> 00:09:10,010
meets that condition reading disc is

00:09:05,990 --> 00:09:12,830
obviously slow in contrast is an index

00:09:10,010 --> 00:09:14,750
right so here's a really dumb down

00:09:12,830 --> 00:09:16,580
version of a b-tree index where it's

00:09:14,750 --> 00:09:18,740
going to know based on this initial

00:09:16,580 --> 00:09:20,480
value I'm going to go to this set of

00:09:18,740 --> 00:09:24,130
records and I'm going to keep traversing

00:09:20,480 --> 00:09:26,870
down until I have this record indexes

00:09:24,130 --> 00:09:29,150
postgres 92 and before always had to hit

00:09:26,870 --> 00:09:31,580
disk so post Christ under the covers is

00:09:29,150 --> 00:09:33,140
a really giant append only long it just

00:09:31,580 --> 00:09:34,640
keeps writing data writing data writing

00:09:33,140 --> 00:09:37,190
data when you delete data it actually

00:09:34,640 --> 00:09:38,630
writes data so an index that's in memory

00:09:37,190 --> 00:09:40,910
may not know that the data has been

00:09:38,630 --> 00:09:44,780
removed so it always has to hit disk if

00:09:40,910 --> 00:09:47,390
it's hitting an index and postgres 92

00:09:44,780 --> 00:09:49,430
and up there is something an index only

00:09:47,390 --> 00:09:51,560
scan that if it can use it it's great

00:09:49,430 --> 00:09:54,800
it's kind of magic when it does and

00:09:51,560 --> 00:09:56,180
doesn't there's not great advice fairly

00:09:54,800 --> 00:09:58,220
troubleshooting when it should be using

00:09:56,180 --> 00:10:00,320
one or doesn't but most of the time if

00:09:58,220 --> 00:10:02,330
it can use it it will so I know that's

00:10:00,320 --> 00:10:05,380
not super helpful but if you're on 92 93

00:10:02,330 --> 00:10:07,790
you can get some performance gains there

00:10:05,380 --> 00:10:09,170
so rule of thumb when are sequential

00:10:07,790 --> 00:10:10,460
scans okay they're not always bad

00:10:09,170 --> 00:10:14,020
they're good for large reports when

00:10:10,460 --> 00:10:16,070
you've got a query over a ton of data

00:10:14,020 --> 00:10:17,180
index scans

00:10:16,070 --> 00:10:20,600
applications this is where you should

00:10:17,180 --> 00:10:21,890
mostly see index scans being used it's

00:10:20,600 --> 00:10:27,530
for the most common queries in your app

00:10:21,890 --> 00:10:29,060
that's what you should expect so how do

00:10:27,530 --> 00:10:32,950
you understand a specific query

00:10:29,060 --> 00:10:35,300
performance given a really basic query

00:10:32,950 --> 00:10:38,780
what we can do is put an explain in

00:10:35,300 --> 00:10:41,990
front of it postgres for every query

00:10:38,780 --> 00:10:43,400
that's run has a query plan and putting

00:10:41,990 --> 00:10:45,110
explain i'll show you what that query

00:10:43,400 --> 00:10:47,060
plane is going to be and how long it

00:10:45,110 --> 00:10:48,950
thinks it's going to take and you're

00:10:47,060 --> 00:10:51,110
going to get this kind of cryptic output

00:10:48,950 --> 00:10:53,420
that's super straightforward to anyone

00:10:51,110 --> 00:10:55,520
the first time they look at it it's

00:10:53,420 --> 00:10:57,890
really not too bad so there's three

00:10:55,520 --> 00:10:59,120
values right there the startup time

00:10:57,890 --> 00:11:01,730
which is how long it takes to kind of

00:10:59,120 --> 00:11:03,530
start that process the max time it

00:11:01,730 --> 00:11:07,120
thinks it's going to take and then how

00:11:03,530 --> 00:11:07,120
many roses thinks it's going to return

00:11:07,420 --> 00:11:11,030
running explain analyze you're going to

00:11:09,830 --> 00:11:12,710
get what it thinks it's going to do

00:11:11,030 --> 00:11:15,860
which is great out there above and then

00:11:12,710 --> 00:11:17,090
the actual time so what the real thing

00:11:15,860 --> 00:11:19,610
you want to look out there is that max

00:11:17,090 --> 00:11:23,030
time of each step of where is it taking

00:11:19,610 --> 00:11:25,760
a ton of time jumping ahead kind of

00:11:23,030 --> 00:11:28,550
rough guide lines of queries and in web

00:11:25,760 --> 00:11:30,050
applications aiming for a page response

00:11:28,550 --> 00:11:32,360
time of less than 100 milliseconds is

00:11:30,050 --> 00:11:34,400
kind of nice common queries should be

00:11:32,360 --> 00:11:35,990
less than 10 milliseconds and I really

00:11:34,400 --> 00:11:37,610
aim for around one I can't always get

00:11:35,990 --> 00:11:42,350
below one millisecond but I can usually

00:11:37,610 --> 00:11:45,200
get to 1.5 2 milliseconds pretty

00:11:42,350 --> 00:11:46,910
consistently on any query a run and then

00:11:45,200 --> 00:11:50,330
more rare queries less than 100

00:11:46,910 --> 00:11:53,090
milliseconds so coming back here if

00:11:50,330 --> 00:11:55,310
you've got a page that's slow you can

00:11:53,090 --> 00:11:57,590
basically run the explain on it explain

00:11:55,310 --> 00:12:00,920
analyze which actually execute the query

00:11:57,590 --> 00:12:04,190
as well see how long it takes and say

00:12:00,920 --> 00:12:07,280
okay this is crap let's uh let's start

00:12:04,190 --> 00:12:09,710
to optimize it so basically pretty

00:12:07,280 --> 00:12:11,660
straightforward i had a filter on salary

00:12:09,710 --> 00:12:14,720
i'm just going to end at an index on

00:12:11,660 --> 00:12:16,220
salary i'm going to see that slop from

00:12:14,720 --> 00:12:18,140
using a sequential scan over to an index

00:12:16,220 --> 00:12:20,680
scan now and my times about where I

00:12:18,140 --> 00:12:20,680
expected

00:12:22,640 --> 00:12:28,670
so this is great if I have a page that I

00:12:25,310 --> 00:12:30,050
want to optimize and some queries some

00:12:28,670 --> 00:12:31,880
people start there but for a lot of

00:12:30,050 --> 00:12:33,680
people it's like hey how do I look at my

00:12:31,880 --> 00:12:37,370
database in an aggregate and say I

00:12:33,680 --> 00:12:39,500
wanted to start optimizing queries PG

00:12:37,370 --> 00:12:41,300
stat statement is probably the least our

00:12:39,500 --> 00:12:44,480
most underused visibility tool directly

00:12:41,300 --> 00:12:46,550
in Postgres so what it does is normalize

00:12:44,480 --> 00:12:48,680
every single query against your database

00:12:46,550 --> 00:12:52,040
so where I've got email equal question

00:12:48,680 --> 00:12:53,540
right there it's like I ran in that with

00:12:52,040 --> 00:12:55,120
where email equals Craig at Heroku and

00:12:53,540 --> 00:12:58,220
they just swapped out Craig at Heroku

00:12:55,120 --> 00:13:00,590
for that parameter and what this is

00:12:58,220 --> 00:13:01,820
going to do when you turn it on for your

00:13:00,590 --> 00:13:03,680
database by just running create

00:13:01,820 --> 00:13:05,200
extension PG stat statement it's going

00:13:03,680 --> 00:13:08,420
to record every single query that's run

00:13:05,200 --> 00:13:11,090
the average time it takes and how many

00:13:08,420 --> 00:13:14,390
times it's run so i can run something

00:13:11,090 --> 00:13:16,160
like this now which will give me the

00:13:14,390 --> 00:13:17,600
total number of time' queries been run

00:13:16,160 --> 00:13:21,920
against my system the average number of

00:13:17,600 --> 00:13:23,270
time and the query itself so from here I

00:13:21,920 --> 00:13:24,950
can say what are the most expensive

00:13:23,270 --> 00:13:27,380
queries in aggregate on my system and

00:13:24,950 --> 00:13:29,300
where can i optimize so coming back to

00:13:27,380 --> 00:13:31,400
this knowing i can get each of these

00:13:29,300 --> 00:13:32,600
probably down to one millisecond i can

00:13:31,400 --> 00:13:34,010
say all right i can get two orders of

00:13:32,600 --> 00:13:35,270
magnitude back on the second one and

00:13:34,010 --> 00:13:41,530
give it a lot of time back to my system

00:13:35,270 --> 00:13:45,410
pretty pretty quickly so indexes

00:13:41,530 --> 00:13:47,240
postgres has quite a few if you're like

00:13:45,410 --> 00:13:52,400
me when you even when you read the docs

00:13:47,240 --> 00:13:54,890
the general reaction is this the dots

00:13:52,400 --> 00:13:56,210
don't help a ton they explain kind of

00:13:54,890 --> 00:13:58,580
what they are under the covers but not

00:13:56,210 --> 00:14:00,740
when you use them really dumb down

00:13:58,580 --> 00:14:02,630
versions beating when you say create

00:14:00,740 --> 00:14:03,950
index this is what you get this is

00:14:02,630 --> 00:14:06,680
usually what you want you usually don't

00:14:03,950 --> 00:14:08,660
have to think too much about it if

00:14:06,680 --> 00:14:11,810
you're doing anything interesting like

00:14:08,660 --> 00:14:13,310
post GIS or full text search or some of

00:14:11,810 --> 00:14:14,720
the more unique data types like H store

00:14:13,310 --> 00:14:17,420
or array you may want some of these

00:14:14,720 --> 00:14:20,810
others so generalized inverted index is

00:14:17,420 --> 00:14:22,640
a gin index rule of thumb if you've got

00:14:20,810 --> 00:14:25,810
multiple values in a single column this

00:14:22,640 --> 00:14:29,960
is what you want so eight Shore

00:14:25,810 --> 00:14:31,640
eventually JSON arrays rule of thumb

00:14:29,960 --> 00:14:33,290
just put this on there in some cases

00:14:31,640 --> 00:14:36,200
just will be a little better but I

00:14:33,290 --> 00:14:38,720
wouldn't worry too much about it

00:14:36,200 --> 00:14:40,820
just rough rule of thumb is full text

00:14:38,720 --> 00:14:42,980
search or shapes so if you're doing GIS

00:14:40,820 --> 00:14:46,780
stuff you're going to be using a lot of

00:14:42,980 --> 00:14:52,280
just indexes speeding through the others

00:14:46,780 --> 00:14:54,440
KN n is for similarity SP just I've had

00:14:52,280 --> 00:14:56,960
this explained to me about 50 times by a

00:14:54,440 --> 00:15:03,200
lot of postgres people and all I know is

00:14:56,960 --> 00:15:04,850
it's good for phone numbers so I yeah if

00:15:03,200 --> 00:15:09,980
you have a straightforward explanation I

00:15:04,850 --> 00:15:11,450
would love to hear it vodka so almost

00:15:09,980 --> 00:15:13,360
all these index types come out of the

00:15:11,450 --> 00:15:15,940
group of the post Crest Community

00:15:13,360 --> 00:15:18,620
finally refers to as the Russians

00:15:15,940 --> 00:15:20,750
they're a bunch of professors over in

00:15:18,620 --> 00:15:22,340
University of Moscow I think one's a

00:15:20,750 --> 00:15:24,590
professor of astrophysics and just hacks

00:15:22,340 --> 00:15:26,090
on postgres for fun they come up with

00:15:24,590 --> 00:15:29,900
crazy ideas for indexes and

00:15:26,090 --> 00:15:31,910
optimizations and vodka I believe is one

00:15:29,900 --> 00:15:35,360
that's up and coming it's a space

00:15:31,910 --> 00:15:38,570
partition gin index and because they're

00:15:35,360 --> 00:15:40,370
Russian they they thought we had gin and

00:15:38,570 --> 00:15:41,930
we needed vodka in there this is the

00:15:40,370 --> 00:15:43,670
working name I hope it doesn't make it

00:15:41,930 --> 00:15:48,800
in this this I don't know if we'll win

00:15:43,670 --> 00:15:50,720
that battle yeah so more indexes I'll

00:15:48,800 --> 00:15:51,800
speed through these pretty quickly you

00:15:50,720 --> 00:15:55,460
also have like conditional and

00:15:51,800 --> 00:15:56,540
functional indexes conditional hopefully

00:15:55,460 --> 00:15:59,240
it's pretty straightforward if I'm

00:15:56,540 --> 00:16:02,090
selecting start from places and I say I

00:15:59,240 --> 00:16:04,220
only want big cities right maybe that's

00:16:02,090 --> 00:16:06,380
a common thing in my application a good

00:16:04,220 --> 00:16:07,790
example is this is where current address

00:16:06,380 --> 00:16:09,080
is true right if you've got a history of

00:16:07,790 --> 00:16:11,150
where everyone's lives and you only care

00:16:09,080 --> 00:16:14,090
about the recent one mostly you could

00:16:11,150 --> 00:16:15,050
index on that and pretty straightforward

00:16:14,090 --> 00:16:16,910
so you're just going to add the

00:16:15,050 --> 00:16:18,950
condition on the index just like you

00:16:16,910 --> 00:16:20,930
would in the query so if you've got a

00:16:18,950 --> 00:16:23,720
ton of data but you only want to index

00:16:20,930 --> 00:16:28,700
some of it for efficiency you can do

00:16:23,720 --> 00:16:32,050
this pretty easily also functional

00:16:28,700 --> 00:16:35,740
indexes so you can index on a function

00:16:32,050 --> 00:16:38,030
so in this case I've got some JSON data

00:16:35,740 --> 00:16:40,580
Jace town in Postgres is marginally

00:16:38,030 --> 00:16:42,160
useful right now you have to write a

00:16:40,580 --> 00:16:46,250
bunch of functions to make them useful

00:16:42,160 --> 00:16:48,680
but I can basically say give me this key

00:16:46,250 --> 00:16:50,089
back population and I want to find where

00:16:48,680 --> 00:16:53,329
populations greater than

00:16:50,089 --> 00:16:55,550
ten thousand so I can actually add an

00:16:53,329 --> 00:16:58,189
index on that function so any function

00:16:55,550 --> 00:17:02,120
in Postgres any user-defined function

00:16:58,189 --> 00:17:04,520
you can add an index on one important

00:17:02,120 --> 00:17:06,470
thing about functional indexes and

00:17:04,520 --> 00:17:07,970
hopefully this sounds a little weird and

00:17:06,470 --> 00:17:10,880
counterintuitive because it did to me at

00:17:07,970 --> 00:17:14,150
first if the same input to the function

00:17:10,880 --> 00:17:16,010
returns the same output you want

00:17:14,150 --> 00:17:17,329
immutable on it so basically if you

00:17:16,010 --> 00:17:19,459
don't have random things happening in

00:17:17,329 --> 00:17:20,689
the function you want a mutable on it

00:17:19,459 --> 00:17:22,159
and post crest streets this differently

00:17:20,689 --> 00:17:23,449
and knows that hey it's always going to

00:17:22,159 --> 00:17:25,939
return the same result given the same

00:17:23,449 --> 00:17:31,399
input and it does very very different

00:17:25,939 --> 00:17:33,559
things for performance so conditional

00:17:31,399 --> 00:17:35,000
and functional hopefully no surprise

00:17:33,559 --> 00:17:36,200
here you can combine these so you can

00:17:35,000 --> 00:17:41,809
say you know the output of this function

00:17:36,200 --> 00:17:44,179
is greater than some value so another

00:17:41,809 --> 00:17:46,399
thing create index concurrently if

00:17:44,179 --> 00:17:47,570
you're running any production system

00:17:46,399 --> 00:17:49,880
this is probably what you want to be

00:17:47,570 --> 00:17:51,289
using when you run create index it's

00:17:49,880 --> 00:17:53,690
going to hold a lock on the table while

00:17:51,289 --> 00:17:55,309
is rewriting that index in certain other

00:17:53,690 --> 00:17:58,070
databases this is the only choice you

00:17:55,309 --> 00:17:59,510
have postgres at least gives you another

00:17:58,070 --> 00:18:00,679
option where create an index and

00:17:59,510 --> 00:18:02,630
currently is going to build this index

00:18:00,679 --> 00:18:04,130
up in the background when I say it

00:18:02,630 --> 00:18:06,110
doesn't hold a lock that's only half

00:18:04,130 --> 00:18:07,909
true it holds a lot for a couple of

00:18:06,110 --> 00:18:09,049
milliseconds so for a couple of

00:18:07,909 --> 00:18:12,880
milliseconds you can't write to your

00:18:09,049 --> 00:18:15,649
data a database but it's pretty trivial

00:18:12,880 --> 00:18:16,700
it's going to be slower but it's just

00:18:15,649 --> 00:18:21,980
going to work it's not gonna bring down

00:18:16,700 --> 00:18:26,240
production everyone's happier is anyone

00:18:21,980 --> 00:18:31,970
here using H door in Postgres okay has

00:18:26,240 --> 00:18:33,830
anyone here using JSON ok a few hands H

00:18:31,970 --> 00:18:35,779
stores awesome people should use it if

00:18:33,830 --> 00:18:38,179
you're unfamiliar with it here's kind of

00:18:35,779 --> 00:18:40,399
a quick run-through so H store is a key

00:18:38,179 --> 00:18:42,350
value store inside your database so it's

00:18:40,399 --> 00:18:45,110
just another data type you enable it by

00:18:42,350 --> 00:18:46,700
running create extension H store and

00:18:45,110 --> 00:18:49,490
then you have this H store data type

00:18:46,700 --> 00:18:51,020
down here i usually get some flak for

00:18:49,490 --> 00:18:52,279
calling this data but i think it's fair

00:18:51,020 --> 00:18:54,580
because it's just random data i'm

00:18:52,279 --> 00:18:57,620
throwing in there is a key value store

00:18:54,580 --> 00:19:00,320
but you can do things like this so i can

00:18:57,620 --> 00:19:02,690
insert you know genders male state is

00:19:00,320 --> 00:19:03,650
california here i can answer all sorts

00:19:02,690 --> 00:19:06,350
of new keys

00:19:03,650 --> 00:19:08,420
I can search filter on those just like

00:19:06,350 --> 00:19:16,010
you'd expect just like any other key

00:19:08,420 --> 00:19:18,530
value store JSON got into postgres in 92

00:19:16,010 --> 00:19:22,610
I believe and 93 it became a little more

00:19:18,530 --> 00:19:25,570
useful it's still marginally useful JSON

00:19:22,610 --> 00:19:28,130
is really just validation on text today

00:19:25,570 --> 00:19:30,130
there's no big optimizations around it

00:19:28,130 --> 00:19:32,870
it just validates the text is valid JSON

00:19:30,130 --> 00:19:35,170
there are some functions for helping

00:19:32,870 --> 00:19:38,170
with searching on it now that came in 93

00:19:35,170 --> 00:19:41,420
but overall it's kind of a marginal use

00:19:38,170 --> 00:19:44,540
if you're using these eight stores kind

00:19:41,420 --> 00:19:46,310
of the way i would go today indexes work

00:19:44,540 --> 00:19:48,230
with its oj man just indexed you can

00:19:46,310 --> 00:19:50,750
just add a gin index and it's going to

00:19:48,230 --> 00:19:52,520
index every key and every value inside

00:19:50,750 --> 00:19:54,230
your database there's a talk at fosston

00:19:52,520 --> 00:19:58,430
this year if you search for performance

00:19:54,230 --> 00:20:00,380
of a postgres first MongoDB it actually

00:19:58,430 --> 00:20:02,000
holds up and compares pretty well in

00:20:00,380 --> 00:20:04,040
some cases it's faster in some cases

00:20:02,000 --> 00:20:06,080
it's slower in some cases it's bigger on

00:20:04,040 --> 00:20:08,630
disk in some cases it's smaller but it's

00:20:06,080 --> 00:20:10,190
really comparable overall it's not a

00:20:08,630 --> 00:20:12,920
full document store though which is what

00:20:10,190 --> 00:20:15,140
a lot of people want so JSON you know

00:20:12,920 --> 00:20:18,170
works for that it is a full JSON

00:20:15,140 --> 00:20:19,850
document store inside postgres but

00:20:18,170 --> 00:20:21,290
functional indexes or what you have to

00:20:19,850 --> 00:20:22,760
do to get good performance there unless

00:20:21,290 --> 00:20:24,860
you're just shoving in a document and

00:20:22,760 --> 00:20:26,300
pulling it out so have fun with that

00:20:24,860 --> 00:20:29,930
it's going to be a lot of work getting

00:20:26,300 --> 00:20:31,310
good performance postgres 94 is around

00:20:29,930 --> 00:20:34,100
the corner and json be just got

00:20:31,310 --> 00:20:37,040
committed so json b is a binary

00:20:34,100 --> 00:20:39,140
representation of json on disk and this

00:20:37,040 --> 00:20:41,360
was actually a claw operation with a lot

00:20:39,140 --> 00:20:44,420
of people with Engine Yard Heroku PG

00:20:41,360 --> 00:20:48,470
experts and the Russians of course they

00:20:44,420 --> 00:20:51,680
were involved in something crazy so this

00:20:48,470 --> 00:20:53,870
is what was H door to with Jason on top

00:20:51,680 --> 00:20:56,000
of it with Jin index is working so kind

00:20:53,870 --> 00:20:57,770
of the best of all worlds finally to to

00:20:56,000 --> 00:21:03,590
postgres and i believe the plan is this

00:20:57,770 --> 00:21:07,130
to be I n native data type so connection

00:21:03,590 --> 00:21:10,010
pooling is another big area if you're on

00:21:07,130 --> 00:21:12,410
Jango 15 or earlier please tell me

00:21:10,010 --> 00:21:15,920
you're using a connection polar Django

00:21:12,410 --> 00:21:17,170
16 I got persistent connections and the

00:21:15,920 --> 00:21:19,810
ability to have a polar

00:21:17,170 --> 00:21:21,190
it makes life a lot better if you're

00:21:19,810 --> 00:21:23,110
running your database with ssl you

00:21:21,190 --> 00:21:27,100
should expect a connection on Jango 15

00:21:23,110 --> 00:21:28,480
to be around 30 to 40 seconds 30 to 40

00:21:27,100 --> 00:21:30,370
milliseconds for just getting a

00:21:28,480 --> 00:21:32,050
connection so you've got maybe a one or

00:21:30,370 --> 00:21:34,180
two second query every millisecond query

00:21:32,050 --> 00:21:35,110
but you're spending you know 30 times

00:21:34,180 --> 00:21:37,990
that actually just getting the

00:21:35,110 --> 00:21:40,600
connection to your database sequel

00:21:37,990 --> 00:21:41,770
alchemy is already pretty good here but

00:21:40,600 --> 00:21:42,880
in short you kind of got a couple of

00:21:41,770 --> 00:21:44,710
options you got the application

00:21:42,880 --> 00:21:46,930
framework handling this for you which

00:21:44,710 --> 00:21:48,600
dingos gotten a lot better in recent

00:21:46,930 --> 00:21:50,740
releases sequel alchemy does this well

00:21:48,600 --> 00:21:53,230
and then you've also got the option of a

00:21:50,740 --> 00:21:56,200
standalone demon so even with a

00:21:53,230 --> 00:21:59,500
connection polar in your framework you

00:21:56,200 --> 00:22:02,520
may want to run a server side or

00:21:59,500 --> 00:22:05,650
application side connection polar

00:22:02,520 --> 00:22:07,150
postgres does well up to 100 200

00:22:05,650 --> 00:22:10,360
connections and then after that you need

00:22:07,150 --> 00:22:11,620
to kind of consider another option on

00:22:10,360 --> 00:22:15,760
the post crest options there's really

00:22:11,620 --> 00:22:17,140
two a PG bouncer and PG pool I won't go

00:22:15,760 --> 00:22:18,970
into the details of them I'd encourage

00:22:17,140 --> 00:22:20,560
the use of PG bouncer I don't know that

00:22:18,970 --> 00:22:22,840
I'd encourage the use of PG pool it

00:22:20,560 --> 00:22:25,240
takes the strategy of doing a whole lot

00:22:22,840 --> 00:22:26,620
of things ok and PG bouncer does one

00:22:25,240 --> 00:22:32,080
thing really well which is connection

00:22:26,620 --> 00:22:34,390
pooling so when it comes to scaling as I

00:22:32,080 --> 00:22:36,390
mentioned the easiest way of scaling

00:22:34,390 --> 00:22:38,410
when you need more memory is scale up

00:22:36,390 --> 00:22:40,900
but as a certain point that's not

00:22:38,410 --> 00:22:43,810
possible for databases so you can also

00:22:40,900 --> 00:22:45,400
scale that out postgres when you have a

00:22:43,810 --> 00:22:46,870
replica and you start sending queries to

00:22:45,400 --> 00:22:48,700
it it's going to keep that cash

00:22:46,870 --> 00:22:51,040
completely separate so it's going to

00:22:48,700 --> 00:22:52,180
have all the same data but its cache and

00:22:51,040 --> 00:22:53,830
what's in memory is going to be

00:22:52,180 --> 00:22:56,710
different so you can do things like

00:22:53,830 --> 00:22:59,080
sending you know read-only queries for a

00:22:56,710 --> 00:23:00,910
certain model to one database and it's

00:22:59,080 --> 00:23:02,170
going to keep all that data in memory so

00:23:00,910 --> 00:23:03,760
you can start to scale out pretty easily

00:23:02,170 --> 00:23:07,330
that way without a heavy sharding

00:23:03,760 --> 00:23:09,030
architecture to set that up you're gonna

00:23:07,330 --> 00:23:12,490
want to have some kind of replication

00:23:09,030 --> 00:23:14,200
Heroku we make it easy with followers a

00:23:12,490 --> 00:23:15,790
lot of service providers provide

00:23:14,200 --> 00:23:17,910
different things there if you're running

00:23:15,790 --> 00:23:19,750
it yourself there's a several options

00:23:17,910 --> 00:23:21,880
some of these have been around for a

00:23:19,750 --> 00:23:24,010
really long time and then there's some

00:23:21,880 --> 00:23:28,120
more recent ones so postgres got a

00:23:24,010 --> 00:23:30,330
synchronous replication around now I

00:23:28,120 --> 00:23:33,539
forget it's either 90 or 91

00:23:30,330 --> 00:23:35,210
it's gotten a lot more useful it's okay

00:23:33,539 --> 00:23:37,620
to set up on your own without any help

00:23:35,210 --> 00:23:39,480
but these tools to tools down here at

00:23:37,620 --> 00:23:41,850
the bottom make it a lot easier so Wally

00:23:39,480 --> 00:23:45,000
is something we've open sourced it runs

00:23:41,850 --> 00:23:47,700
powers all Heroku databases for our fork

00:23:45,000 --> 00:23:50,309
and Paolo stuff bar man is something out

00:23:47,700 --> 00:23:52,440
of second quadrant Wally is Python it's

00:23:50,309 --> 00:23:53,820
basically just a pretty straightforward

00:23:52,440 --> 00:24:00,269
Python script that gives you a lot of

00:23:53,820 --> 00:24:04,440
utilities to make this easier backups so

00:24:00,269 --> 00:24:05,490
there's two types of backups in Postgres

00:24:04,440 --> 00:24:07,380
most people when they think about

00:24:05,490 --> 00:24:09,210
backups they only think about logical

00:24:07,380 --> 00:24:11,700
backups so this is what happens when you

00:24:09,210 --> 00:24:12,990
run PG dump on your database this is

00:24:11,700 --> 00:24:15,360
what most people think of as backups

00:24:12,990 --> 00:24:18,600
it's human readable it's portable it's

00:24:15,360 --> 00:24:20,940
what people start with the other is a

00:24:18,600 --> 00:24:24,029
physical backup or also known as a base

00:24:20,940 --> 00:24:25,409
backup if you set up replication you had

00:24:24,029 --> 00:24:27,659
to do this at some point this is kind of

00:24:25,409 --> 00:24:30,419
what powers that this is the physical

00:24:27,659 --> 00:24:32,480
bites on disk this is not cross cross

00:24:30,419 --> 00:24:36,750
platform or cross architecture dependent

00:24:32,480 --> 00:24:38,370
it it's not promised to be it maybe is

00:24:36,750 --> 00:24:40,590
some people have said it is some of said

00:24:38,370 --> 00:24:41,970
it isn't don't rely on this it will

00:24:40,590 --> 00:24:44,820
break at some point that's pretty much a

00:24:41,970 --> 00:24:49,230
guarantee a little bit of comparison

00:24:44,820 --> 00:24:51,720
between the two logical backups are good

00:24:49,230 --> 00:24:53,940
for you know moving something from your

00:24:51,720 --> 00:24:55,230
production environment down locally if

00:24:53,940 --> 00:24:58,110
you've got you know developing on a Mac

00:24:55,230 --> 00:25:00,659
versus running on a boon too good for

00:24:58,110 --> 00:25:02,519
portability but it has load on the

00:25:00,659 --> 00:25:04,080
database when you fire this off it's

00:25:02,519 --> 00:25:07,470
going to have load on your database and

00:25:04,080 --> 00:25:09,059
impact performance it works early on but

00:25:07,470 --> 00:25:11,789
it stops working at a certain point

00:25:09,059 --> 00:25:15,330
especially if your database has load so

00:25:11,789 --> 00:25:17,039
if you're you know serving traffic it'll

00:25:15,330 --> 00:25:19,919
have an impact there and it stops

00:25:17,039 --> 00:25:21,870
working at a certain point generally the

00:25:19,919 --> 00:25:24,090
community starts to encourage once

00:25:21,870 --> 00:25:26,130
you're a big database you move strictly

00:25:24,090 --> 00:25:28,740
to physical backups there's a little

00:25:26,130 --> 00:25:31,549
more initial setup but there's limited

00:25:28,740 --> 00:25:34,200
to no load on the system and its scales

00:25:31,549 --> 00:25:38,100
essentially everyone its large scale as

00:25:34,200 --> 00:25:43,860
using this so kind of a really quick

00:25:38,100 --> 00:25:45,120
recap OLAP is a whole other talk

00:25:43,860 --> 00:25:47,250
when you're looking at all applications

00:25:45,120 --> 00:25:50,400
just how this guy o is really important

00:25:47,250 --> 00:25:52,799
so you're looking at SSDs in fusion-io

00:25:50,400 --> 00:25:55,740
and real Hardware the order on disk is

00:25:52,799 --> 00:25:58,410
helpful and important PG reorg is a

00:25:55,740 --> 00:25:59,610
crazy thing out of NTT that reordered

00:25:58,410 --> 00:26:01,530
Speights on disk while they're sitting

00:25:59,610 --> 00:26:03,600
there in your your databases live in

00:26:01,530 --> 00:26:04,830
production it works really well as long

00:26:03,600 --> 00:26:10,230
as you don't do anything wrong and

00:26:04,830 --> 00:26:12,780
possibly wipe all your data parts of

00:26:10,230 --> 00:26:15,120
that are being examined for contributed

00:26:12,780 --> 00:26:17,520
back to postgres but it's a it's a ways

00:26:15,120 --> 00:26:19,290
to go to make that safe and then there's

00:26:17,520 --> 00:26:21,630
a lot of MPP solutions on top of

00:26:19,290 --> 00:26:25,470
postgres a lot of data warehousing

00:26:21,630 --> 00:26:26,790
projects start out on postgres so

00:26:25,470 --> 00:26:28,080
there's postgres bits him in there I

00:26:26,790 --> 00:26:30,870
think I mean if you look at redshift

00:26:28,080 --> 00:26:33,210
it's even I a long long long ago

00:26:30,870 --> 00:26:36,330
postgres at some point they start to

00:26:33,210 --> 00:26:38,390
deviate pretty far from that and then

00:26:36,330 --> 00:26:40,580
for the bulk of this oltp web apps

00:26:38,390 --> 00:26:43,500
ensure the bulk of your data is in cash

00:26:40,580 --> 00:26:46,140
and that you have a good high cache hit

00:26:43,500 --> 00:26:48,900
rate optimize your overall query load

00:26:46,140 --> 00:26:50,400
with PG stat statements check your

00:26:48,900 --> 00:26:52,590
indexes and then you know when cash

00:26:50,400 --> 00:26:53,880
sucks throw more at it it really is an

00:26:52,590 --> 00:26:56,520
easy way to solve your database problems

00:26:53,880 --> 00:26:58,230
I wouldn't be overly wasteful but

00:26:56,520 --> 00:27:01,799
scaling up more memory it definitely

00:26:58,230 --> 00:27:04,340
helps if you're low on cash thanks and

00:27:01,799 --> 00:27:04,340
I'll take a few questions

00:27:18,030 --> 00:27:23,350
hi Craig nice talk thanks um I was just

00:27:21,760 --> 00:27:27,100
wondering if you could talk a little

00:27:23,350 --> 00:27:32,350
about whether Heroku uses the vacuum

00:27:27,100 --> 00:27:34,740
statement vacuum analyze yeah so um we

00:27:32,350 --> 00:27:37,320
we have auto vacuum on on all databases

00:27:34,740 --> 00:27:39,900
we don't manually configure it too much

00:27:37,320 --> 00:27:44,080
vacuum used to be horrible in Postgres

00:27:39,900 --> 00:27:45,550
now it's just bad it's actually gotten a

00:27:44,080 --> 00:27:47,050
lot better a lot of that comes pretty

00:27:45,550 --> 00:27:51,280
good unless you have a database with

00:27:47,050 --> 00:27:54,400
super super high load so auto vacuum

00:27:51,280 --> 00:27:56,050
should keep up if you look at one of our

00:27:54,400 --> 00:27:59,650
tools PG extras if you search for that

00:27:56,050 --> 00:28:00,820
on Heroku there's a command-line plug-in

00:27:59,650 --> 00:28:02,620
that shows you a lot of queries so

00:28:00,820 --> 00:28:04,840
there's like cache hit index hit there's

00:28:02,620 --> 00:28:06,400
also one for bloat and looking at

00:28:04,840 --> 00:28:10,270
database bloat is kind of the way up do

00:28:06,400 --> 00:28:12,010
you need to tune auto vacuum or not so I

00:28:10,270 --> 00:28:15,430
just go instill that query or if you're

00:28:12,010 --> 00:28:17,290
on Heroku look at your PG extras and say

00:28:15,430 --> 00:28:19,450
you know is bloat high and there's a

00:28:17,290 --> 00:28:22,030
bloke factor usually I'd say something

00:28:19,450 --> 00:28:24,990
about 5 to 10 X is when okay vacuum is

00:28:22,030 --> 00:28:30,640
not doing its job how can you tweak it

00:28:24,990 --> 00:28:32,440
thank you hey thanks for the talk you

00:28:30,640 --> 00:28:34,540
talked a lot about optimizing the

00:28:32,440 --> 00:28:37,210
database for a heavy read load do you

00:28:34,540 --> 00:28:38,980
have any advice for either what

00:28:37,210 --> 00:28:41,310
performance metrics to look at or how to

00:28:38,980 --> 00:28:43,960
optimize database for heavy right load

00:28:41,310 --> 00:28:46,750
yeah so having you right load I mean

00:28:43,960 --> 00:28:48,490
it's rare to see heavy right load you

00:28:46,750 --> 00:28:50,440
can do a variety of things it depends on

00:28:48,490 --> 00:28:53,800
how much you care about your data you

00:28:50,440 --> 00:28:55,720
can run postgres with unlogged tables

00:28:53,800 --> 00:28:57,070
which I consider mode where

00:28:55,720 --> 00:28:58,630
basically yeah your data is going to

00:28:57,070 --> 00:29:03,700
write really fast but it may or may not

00:28:58,630 --> 00:29:05,320
stay there every index you have is going

00:29:03,700 --> 00:29:07,690
to slow that down I mean that's the

00:29:05,320 --> 00:29:09,100
biggest thing is overuse of indexes you

00:29:07,690 --> 00:29:10,870
can get away a lot of that on a heavy

00:29:09,100 --> 00:29:15,060
read load just because you don't need

00:29:10,870 --> 00:29:17,650
high throughput there's unlogged indexes

00:29:15,060 --> 00:29:19,900
there's a variety of postgres configs I

00:29:17,650 --> 00:29:21,480
might look at a that talk postgresql

00:29:19,900 --> 00:29:23,070
when it's not your day job

00:29:21,480 --> 00:29:24,330
it gets a little more down into postgres

00:29:23,070 --> 00:29:26,549
configs I don't think there's anything

00:29:24,330 --> 00:29:28,559
super high kind of app developer level

00:29:26,549 --> 00:29:36,750
other than don't over use indexes really

00:29:28,559 --> 00:29:39,210
when it's high right load I'm sorry I

00:29:36,750 --> 00:29:41,130
didn't hear you mentioned analyze and

00:29:39,210 --> 00:29:42,750
I've had some pretty big surprise at

00:29:41,130 --> 00:29:44,340
some point with some database that were

00:29:42,750 --> 00:29:46,980
nothing eyes then they returned some

00:29:44,340 --> 00:29:48,900
horrific queries so is this still the

00:29:46,980 --> 00:29:51,840
needed with the latest version of a

00:29:48,900 --> 00:29:54,240
postage scale yeah so um so around

00:29:51,840 --> 00:29:57,150
analyze the thing is you need to run it

00:29:54,240 --> 00:29:58,440
after doing a big bulk load once if

00:29:57,150 --> 00:29:59,970
you're kind of running a production

00:29:58,440 --> 00:30:02,429
website and you know you're not doing a

00:29:59,970 --> 00:30:06,390
lot of bulk loads and dump restores type

00:30:02,429 --> 00:30:07,830
things then you're fine Annalise it's

00:30:06,390 --> 00:30:09,510
actually really important to do after

00:30:07,830 --> 00:30:12,059
that bulk load so that postgres knows

00:30:09,510 --> 00:30:14,130
the layout of your data but on a

00:30:12,059 --> 00:30:15,510
production site it's not to worrying

00:30:14,130 --> 00:30:18,000
because postgres is constantly

00:30:15,510 --> 00:30:19,230
monitoring and watching this so yeah

00:30:18,000 --> 00:30:21,299
it's it's definitely something to

00:30:19,230 --> 00:30:23,850
consider if you're like doing ETL

00:30:21,299 --> 00:30:25,350
processes and all with a lot of data but

00:30:23,850 --> 00:30:27,270
for average production site I wouldn't

00:30:25,350 --> 00:30:33,720
worry about it so it really depends on

00:30:27,270 --> 00:30:35,730
your use case okay thank you yep you

00:30:33,720 --> 00:30:37,799
mentioned it great wide open in Atlanta

00:30:35,730 --> 00:30:40,620
just a few weeks ago some of the work

00:30:37,799 --> 00:30:43,100
that's being done for pluggable storage

00:30:40,620 --> 00:30:45,390
type applicable storage engines and

00:30:43,100 --> 00:30:47,190
potentially columnar stores and stuff

00:30:45,390 --> 00:30:48,900
like that you elaborate a little bit on

00:30:47,190 --> 00:30:53,040
the future of that and postgres over the

00:30:48,900 --> 00:30:54,929
next few releases so uh a pluggable

00:30:53,040 --> 00:30:56,549
storage engine is definitely speculative

00:30:54,929 --> 00:30:57,299
there's people want it there's people

00:30:56,549 --> 00:31:01,080
they don't think it could be done in

00:30:57,299 --> 00:31:02,820
core there was a calmer store released

00:31:01,080 --> 00:31:05,730
as a foreign data wrapper by situs data

00:31:02,820 --> 00:31:09,690
I think last week which is really

00:31:05,730 --> 00:31:11,940
awesome I think we're going to see a lot

00:31:09,690 --> 00:31:14,220
of FTW support some of this and in time

00:31:11,940 --> 00:31:15,720
we'll see more of a pluggable storage

00:31:14,220 --> 00:31:17,040
engine I know some companies that they

00:31:15,720 --> 00:31:20,280
can't talk about that have some interest

00:31:17,040 --> 00:31:21,450
in it so there's some potential for it

00:31:20,280 --> 00:31:24,240
but I think we're definitely looking at

00:31:21,450 --> 00:31:25,610
least a year and a half off probably two

00:31:24,240 --> 00:31:29,660
and a half years before we have a

00:31:25,610 --> 00:31:29,660
completely pluggable storage layer

00:31:29,870 --> 00:31:36,000
so I'm really interested in in H store

00:31:32,850 --> 00:31:38,159
so when you say key value store I often

00:31:36,000 --> 00:31:40,770
think about memcache lettuce but if you

00:31:38,159 --> 00:31:43,110
have a ninety-nine percent cache hit

00:31:40,770 --> 00:31:44,760
rate and your cash is in memory it seems

00:31:43,110 --> 00:31:47,190
like this could be a really cool way to

00:31:44,760 --> 00:31:48,630
not have to spin up like a memcache or

00:31:47,190 --> 00:31:51,450
etis instance and do everything in

00:31:48,630 --> 00:31:53,220
Postgres so is that kind of the goal

00:31:51,450 --> 00:31:54,929
like how do you see people actually

00:31:53,220 --> 00:31:58,020
using H door and is this kind of like

00:31:54,929 --> 00:31:59,549
where that's going or am I totally off I

00:31:58,020 --> 00:32:01,590
mean it definitely can I don't think

00:31:59,549 --> 00:32:03,270
that's the big top primary use case I

00:32:01,590 --> 00:32:06,240
think it's more of that schema list

00:32:03,270 --> 00:32:07,890
flexibility so like for us we use it in

00:32:06,240 --> 00:32:10,559
one of our huge production systems that

00:32:07,890 --> 00:32:12,840
runs a check on every database every 30

00:32:10,559 --> 00:32:15,360
seconds and we observe all sorts of

00:32:12,840 --> 00:32:16,650
things and every week we want to say hey

00:32:15,360 --> 00:32:18,270
we want to measure something new and

00:32:16,650 --> 00:32:20,100
instead of running a migration and

00:32:18,270 --> 00:32:21,450
adding some columns and maybe throwing

00:32:20,100 --> 00:32:24,030
out a way a month later we just add it

00:32:21,450 --> 00:32:25,620
to our age store column and start

00:32:24,030 --> 00:32:27,929
observing that theta and it's already

00:32:25,620 --> 00:32:30,659
index we can see if it's useful in it so

00:32:27,929 --> 00:32:31,919
we can refactor it out but generally we

00:32:30,659 --> 00:32:34,080
just leave it there just because it

00:32:31,919 --> 00:32:36,390
works it's performant it gives us a lot

00:32:34,080 --> 00:32:38,370
of that schema less flexibility there's

00:32:36,390 --> 00:32:41,429
a lot of stuff for a user account I may

00:32:38,370 --> 00:32:43,890
eventually want to track that I can just

00:32:41,429 --> 00:32:46,020
throw in there I'm already know I'm I

00:32:43,890 --> 00:32:47,280
mean email and password but I may I have

00:32:46,020 --> 00:32:49,770
no idea what else I want to track for a

00:32:47,280 --> 00:32:51,299
user you can get some of the

00:32:49,770 --> 00:32:53,280
functionality out of that you would use

00:32:51,299 --> 00:32:56,850
a red Redis remem cash and I might start

00:32:53,280 --> 00:32:59,220
there I don't know that I'd go to too

00:32:56,850 --> 00:33:01,500
far with it like another good use cases

00:32:59,220 --> 00:33:02,940
feature flags right do you need to rule

00:33:01,500 --> 00:33:04,710
out feature flags for every single new

00:33:02,940 --> 00:33:05,970
feature or can you just have a bucket of

00:33:04,710 --> 00:33:08,490
feature flags of what someone's flagged

00:33:05,970 --> 00:33:12,000
into and a lot of people will look at a

00:33:08,490 --> 00:33:13,620
register memcache sometimes they're so

00:33:12,000 --> 00:33:15,600
it depends i would start with h store

00:33:13,620 --> 00:33:21,960
and then as you outgrow it which you

00:33:15,600 --> 00:33:23,400
will write us from M&T helpful there ok

00:33:21,960 --> 00:33:25,610
that's all we have time for Thank You

00:33:23,400 --> 00:33:25,610

YouTube URL: https://www.youtube.com/watch?v=MpH8W5hce9I


