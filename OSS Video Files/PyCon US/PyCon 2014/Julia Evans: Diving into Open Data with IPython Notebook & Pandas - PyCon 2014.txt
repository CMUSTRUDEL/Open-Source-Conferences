Title: Julia Evans: Diving into Open Data with IPython Notebook & Pandas - PyCon 2014
Publication date: 2014-04-24
Playlist: PyCon 2014
Description: 
	Speaker: Julia Evans

I'll walk you through Python's best tools for getting a grip on data: IPython Notebook and pandas. I'll show you how to read in data, clean it up, graph it, and draw some conclusions, using some open data about the number of cyclists on MontrÃ©al's bike paths as an example.

Slides can be found at: https://speakerdeck.com/pycon2014 and https://github.com/PyCon/2014-slides
Captions: 
	00:00:04,420 --> 00:00:08,809
okay thank you everyone for coming along

00:00:06,890 --> 00:00:11,509
to this first after lunch session at

00:00:08,809 --> 00:00:14,000
PyCon 2014 here in Montreal we've got

00:00:11,509 --> 00:00:16,400
three really excellent speeches all

00:00:14,000 --> 00:00:18,470
lined up for you our first presenter is

00:00:16,400 --> 00:00:21,410
a programmer and data scientist based

00:00:18,470 --> 00:00:24,050
here in Montreal she works on stripes

00:00:21,410 --> 00:00:25,940
data team and is a co-organizer of Pi

00:00:24,050 --> 00:00:29,090
ladies Montreal and the Montreal

00:00:25,940 --> 00:00:31,520
all-girl hack night to speak to us today

00:00:29,090 --> 00:00:33,530
about diving into open data with ipython

00:00:31,520 --> 00:00:45,170
notebook and panders please welcome

00:00:33,530 --> 00:00:47,780
Julia Evans alright um so today what I

00:00:45,170 --> 00:00:49,460
want to talk to you about um I work on a

00:00:47,780 --> 00:00:51,860
data team um which means they work with

00:00:49,460 --> 00:00:54,800
data um and I have a bunch of different

00:00:51,860 --> 00:00:57,170
tools that I use right sometimes I dupe

00:00:54,800 --> 00:00:58,190
um sometimes I use Python sometimes like

00:00:57,170 --> 00:01:02,690
I use R once

00:00:58,190 --> 00:01:04,519
um and my favorite tools to use like the

00:01:02,690 --> 00:01:07,310
things that I enjoy using the most our

00:01:04,519 --> 00:01:09,350
Python tools I enjoy using ipython

00:01:07,310 --> 00:01:11,359
notebook and pandas together to answer

00:01:09,350 --> 00:01:13,549
questions about my data and what I want

00:01:11,359 --> 00:01:15,950
to explain this talk is why they're my

00:01:13,549 --> 00:01:17,840
favorite um and why they could maybe be

00:01:15,950 --> 00:01:23,479
your favorite if you don't use them

00:01:17,840 --> 00:01:26,840
already so um the way this talk is

00:01:23,479 --> 00:01:29,240
structured um it's kind of small not

00:01:26,840 --> 00:01:31,579
gonna get better apparently um is step

00:01:29,240 --> 00:01:33,709
one what our ipython notebook and pandas

00:01:31,579 --> 00:01:35,029
like what do those words mean um you may

00:01:33,709 --> 00:01:36,979
know a little bit already if you watch

00:01:35,029 --> 00:01:39,469
run on reprises excellent keynote this

00:01:36,979 --> 00:01:41,630
morning um most of my time is going to

00:01:39,469 --> 00:01:43,759
be spent on practical examples of how to

00:01:41,630 --> 00:01:45,529
use these to answer questions about your

00:01:43,759 --> 00:01:47,119
data and then I'll end with like a

00:01:45,529 --> 00:01:50,709
little bit of advice about like where to

00:01:47,119 --> 00:01:54,229
go next if you want to learn more so

00:01:50,709 --> 00:01:56,539
first question is like what are a Python

00:01:54,229 --> 00:01:59,060
notebook and pandas and like numpy um

00:01:56,539 --> 00:02:02,209
and like how do these like scientific

00:01:59,060 --> 00:02:03,439
computing tools work together so the

00:02:02,209 --> 00:02:06,409
first thing I want to talk about is

00:02:03,439 --> 00:02:08,539
ipython notebook so I thought that

00:02:06,409 --> 00:02:10,099
notebook is like a web-based user

00:02:08,539 --> 00:02:12,019
interface for Python and you may think

00:02:10,099 --> 00:02:15,049
like why would I want that right like

00:02:12,019 --> 00:02:17,600
you can already write Python maybe um

00:02:15,049 --> 00:02:19,580
and why would you want to be on the

00:02:17,600 --> 00:02:23,270
it right like why would you want it to

00:02:19,580 --> 00:02:25,040
be in a webpage so um the way if I

00:02:23,270 --> 00:02:28,250
thought notebook works um is it runs as

00:02:25,040 --> 00:02:30,200
a server on your machine um and then you

00:02:28,250 --> 00:02:31,010
will open a new new notebook right and

00:02:30,200 --> 00:02:32,600
I'm going to give you a really short

00:02:31,010 --> 00:02:36,320
demo instead of listing a bunch of

00:02:32,600 --> 00:02:38,690
features so um the most important thing

00:02:36,320 --> 00:02:41,360
that isn't always obvious is it when you

00:02:38,690 --> 00:02:42,950
use ipython notebook you can run like

00:02:41,360 --> 00:02:44,150
write any Python code that you would

00:02:42,950 --> 00:02:45,500
normally write like it's not like a

00:02:44,150 --> 00:02:47,270
limited environment where there are only

00:02:45,500 --> 00:02:49,310
certain things you can do um it's just

00:02:47,270 --> 00:02:50,540
Python like you can do any Python things

00:02:49,310 --> 00:02:52,640
that you would otherwise do like you

00:02:50,540 --> 00:02:56,780
could connect to databases and you can

00:02:52,640 --> 00:02:59,180
like you can do everything right um so

00:02:56,780 --> 00:03:01,220
one thing that I really like about it is

00:02:59,180 --> 00:03:03,680
like let's say I import something and

00:03:01,220 --> 00:03:05,810
then I do like string dot split and I

00:03:03,680 --> 00:03:07,610
want to know how it works right normally

00:03:05,810 --> 00:03:09,380
you would look up the documentation here

00:03:07,610 --> 00:03:11,150
it sees that I've hesitated and it's

00:03:09,380 --> 00:03:13,790
like would you like some documentation

00:03:11,150 --> 00:03:15,380
and then I press tab again and like oh

00:03:13,790 --> 00:03:16,700
would you like even more and then I

00:03:15,380 --> 00:03:18,740
first have again because I'm kind of

00:03:16,700 --> 00:03:20,510
frustrated and it pops has all of the

00:03:18,740 --> 00:03:22,520
documentation at the bottom explaining a

00:03:20,510 --> 00:03:24,740
split works for me and I can like resize

00:03:22,520 --> 00:03:27,080
it and I didn't have to leave right and

00:03:24,740 --> 00:03:30,590
I didn't have to even know it just like

00:03:27,080 --> 00:03:32,150
came up for me um so I find it a really

00:03:30,590 --> 00:03:33,920
useful interactive tool for doing like

00:03:32,150 --> 00:03:41,240
exploratory work like I can do like

00:03:33,920 --> 00:03:42,920
string got split right like this um two

00:03:41,240 --> 00:03:44,270
three and then feel like oh that wasn't

00:03:42,920 --> 00:03:46,790
what I wanted maybe I need to tell it to

00:03:44,270 --> 00:03:48,140
split on a comma oh I see right so my

00:03:46,790 --> 00:03:50,270
work flow around this is often I'll do

00:03:48,140 --> 00:03:51,980
something do it wrong as we do

00:03:50,270 --> 00:03:54,920
um and then change it and I can iterate

00:03:51,980 --> 00:03:57,890
really quickly so that's it if I thought

00:03:54,920 --> 00:04:01,310
notebook um the next thing I want to

00:03:57,890 --> 00:04:03,380
talk about is pandas um so often I will

00:04:01,310 --> 00:04:05,570
do some kind of data analysis like I'll

00:04:03,380 --> 00:04:08,740
have a dataset with every complaint call

00:04:05,570 --> 00:04:11,270
ever made in New York right for fun and

00:04:08,740 --> 00:04:13,100
then I want to know like let's say I

00:04:11,270 --> 00:04:16,120
want to know like every hour

00:04:13,100 --> 00:04:18,140
how many noise complaints were made um

00:04:16,120 --> 00:04:21,980
except like I would like to split it out

00:04:18,140 --> 00:04:23,450
by borough and also maybe like I only

00:04:21,980 --> 00:04:25,460
care about the period in like September

00:04:23,450 --> 00:04:28,160
and December um so I want to do like a

00:04:25,460 --> 00:04:29,570
lot of filtering and aggregating and you

00:04:28,160 --> 00:04:31,460
might think that you might have to write

00:04:29,570 --> 00:04:33,080
a loop like if you're writing it for

00:04:31,460 --> 00:04:35,330
Graham that would be like something that

00:04:33,080 --> 00:04:39,229
could happen um with pendous you don't

00:04:35,330 --> 00:04:41,389
have to write loops and also like doing

00:04:39,229 --> 00:04:42,530
something like I read all the noise

00:04:41,389 --> 00:04:44,180
complaints and filter out things you

00:04:42,530 --> 00:04:46,250
don't want and then graph it except like

00:04:44,180 --> 00:04:48,710
um and then graph the number each hour

00:04:46,250 --> 00:04:51,849
is like five lines of code like so it's

00:04:48,710 --> 00:04:54,080
really compact it's really easy um and

00:04:51,849 --> 00:04:55,400
but it's not like oh it's super obvious

00:04:54,080 --> 00:04:57,349
how to get started so that's what I'm

00:04:55,400 --> 00:04:58,460
going to explain but pandas is kind of

00:04:57,349 --> 00:05:02,930
the tool that lets you do all this

00:04:58,460 --> 00:05:05,539
filtering um and parsing so pandas is

00:05:02,930 --> 00:05:07,039
built on top of numpy what is numpy if

00:05:05,539 --> 00:05:08,509
you went to Brendan Rose this talk

00:05:07,039 --> 00:05:10,729
yesterday about Python data structures

00:05:08,509 --> 00:05:12,620
you will know that if you have a Python

00:05:10,729 --> 00:05:14,300
list with like five million things if

00:05:12,620 --> 00:05:16,280
you iterate through that list you have

00:05:14,300 --> 00:05:19,240
to make five million objects which takes

00:05:16,280 --> 00:05:21,949
time even though computers are fast so I

00:05:19,240 --> 00:05:25,669
but like sing like number is faster it's

00:05:21,949 --> 00:05:28,009
kind of a like it's it's not it's not a

00:05:25,669 --> 00:05:30,110
specific enough right so I wanted to do

00:05:28,009 --> 00:05:31,610
an example and the example was like I'll

00:05:30,110 --> 00:05:34,099
take a whole bunch of numbers right and

00:05:31,610 --> 00:05:35,599
then find the sum of the squares so I

00:05:34,099 --> 00:05:37,639
did it in Python right I wrote it like

00:05:35,599 --> 00:05:39,830
pretty simple is pretty simple example I

00:05:37,639 --> 00:05:41,690
took 1.2 seconds to add up all those

00:05:39,830 --> 00:05:43,310
numbers squared which is pretty good

00:05:41,690 --> 00:05:45,409
right like computers are fast that that

00:05:43,310 --> 00:05:47,330
was a big number um but if I do it at

00:05:45,409 --> 00:05:50,509
numpy it takes like 83 milliseconds

00:05:47,330 --> 00:05:51,680
which is like like 15 times faster um so

00:05:50,509 --> 00:05:53,360
when I say now pi is faster

00:05:51,680 --> 00:05:54,800
I mean um pi is like 15 times faster

00:05:53,360 --> 00:06:00,380
like that's what you should be thinking

00:05:54,800 --> 00:06:01,849
about or more right um so and the reason

00:06:00,380 --> 00:06:03,530
it's faster is because it implements all

00:06:01,849 --> 00:06:06,650
the operations like it stores your um

00:06:03,530 --> 00:06:10,099
data structures is like series um and

00:06:06,650 --> 00:06:11,750
then like when you operate on numpy

00:06:10,099 --> 00:06:13,940
arrays you do it all at once so instead

00:06:11,750 --> 00:06:16,039
of being like writing a for loop you'll

00:06:13,940 --> 00:06:18,199
be like just sum all these things right

00:06:16,039 --> 00:06:19,669
and you just like call numpy functions

00:06:18,199 --> 00:06:22,219
and numpy takes care of everything for

00:06:19,669 --> 00:06:24,169
you and some as well pandas is built on

00:06:22,219 --> 00:06:25,430
top of numpy and you'll have pandas

00:06:24,169 --> 00:06:30,680
functions which are built on top of not

00:06:25,430 --> 00:06:32,750
by functions so um I use pandas inside

00:06:30,680 --> 00:06:36,139
ipython notebook and numpy makes pandas

00:06:32,750 --> 00:06:37,969
fast okay um

00:06:36,139 --> 00:06:40,070
quick note how did it install these

00:06:37,969 --> 00:06:43,010
tools don't use the like Ubuntu packages

00:06:40,070 --> 00:06:44,659
install things using pip or there's a

00:06:43,010 --> 00:06:45,830
tool called there's a distribution of

00:06:44,659 --> 00:06:47,660
anaconda which I

00:06:45,830 --> 00:06:50,960
find super easy to use and I use a lot

00:06:47,660 --> 00:06:52,250
um but yeah never use packages like

00:06:50,960 --> 00:06:53,660
these these things are evolving super

00:06:52,250 --> 00:06:56,750
fast the ipython community is doing

00:06:53,660 --> 00:06:58,460
amazing work um and you should use the

00:06:56,750 --> 00:06:58,970
latest versions um because they're

00:06:58,460 --> 00:07:02,060
amazing

00:06:58,970 --> 00:07:09,290
so um and you can run ipython notebook

00:07:02,060 --> 00:07:11,330
by typing ipython notebook it's good not

00:07:09,290 --> 00:07:12,680
super hard um and then when you run a

00:07:11,330 --> 00:07:14,680
Python hoping you get this like it'll

00:07:12,680 --> 00:07:17,840
pop up something in your browser and

00:07:14,680 --> 00:07:19,400
then you can get started so now I want

00:07:17,840 --> 00:07:24,290
to talk about some practical examples as

00:07:19,400 --> 00:07:25,310
I promised um so the first thing I want

00:07:24,290 --> 00:07:25,880
to talk about is the data set we're

00:07:25,310 --> 00:07:29,060
going to be using

00:07:25,880 --> 00:07:30,800
we're in Montreal people it's a bit cold

00:07:29,060 --> 00:07:32,960
right now it was much colder a few weeks

00:07:30,800 --> 00:07:35,900
ago even when it's very cold people go

00:07:32,960 --> 00:07:38,090
biking right so we have bike paths here

00:07:35,900 --> 00:07:39,860
um there are sensors on these bike paths

00:07:38,090 --> 00:07:41,960
which meant meant measure the number of

00:07:39,860 --> 00:07:44,570
cyclists who are going past that sensor

00:07:41,960 --> 00:07:46,970
every day um and that data is published

00:07:44,570 --> 00:07:48,710
online so we can play with it and find

00:07:46,970 --> 00:07:50,900
out things about when people go biking

00:07:48,710 --> 00:07:55,250
for example do people go biking when is

00:07:50,900 --> 00:07:57,890
a minus 20 No ah except people do

00:07:55,250 --> 00:07:59,630
actually which is what we're gonna get

00:07:57,890 --> 00:08:00,500
there um so this is the data set we're

00:07:59,630 --> 00:08:03,140
going to be talking about so I

00:08:00,500 --> 00:08:05,840
downloaded it um this is not big data

00:08:03,140 --> 00:08:09,500
right this is like one data point for

00:08:05,840 --> 00:08:11,660
each day of the year um so um I

00:08:09,500 --> 00:08:13,730
downloaded this CSV and this is what it

00:08:11,660 --> 00:08:16,520
looked like when I started right uh-huh

00:08:13,730 --> 00:08:18,290
if you've parsed CSDs before you may be

00:08:16,520 --> 00:08:21,950
familiar with things that can go wrong

00:08:18,290 --> 00:08:23,780
um so what this is is it's one row for

00:08:21,950 --> 00:08:26,630
each day of the year and has the date

00:08:23,780 --> 00:08:28,250
and the number of cyclists on each on

00:08:26,630 --> 00:08:29,960
each bike path and there are some names

00:08:28,250 --> 00:08:31,850
different bike paths so you'll notice

00:08:29,960 --> 00:08:33,260
they're encoding problems the separator

00:08:31,850 --> 00:08:35,450
it thought it was a comma and it wasn't

00:08:33,260 --> 00:08:37,910
comma right and you may not be impressed

00:08:35,450 --> 00:08:40,700
with pandas right now um so the reason

00:08:37,910 --> 00:08:43,370
you should be impressed is you can also

00:08:40,700 --> 00:08:44,480
there's a lot of text here but um I gave

00:08:43,370 --> 00:08:46,250
it a whole bunch of options and I was

00:08:44,480 --> 00:08:47,390
like read the CSV probably be encoding

00:08:46,250 --> 00:08:49,100
this Latin one to the separators a

00:08:47,390 --> 00:08:50,630
semicolon I you should index by date you

00:08:49,100 --> 00:08:51,950
should parse the dates I need you to

00:08:50,630 --> 00:08:55,130
parse the day first because we're not

00:08:51,950 --> 00:08:57,290
American um and we write dates like

00:08:55,130 --> 00:08:59,510
Canadians um and it has all these all

00:08:57,290 --> 00:09:01,610
these options and there are more options

00:08:59,510 --> 00:09:04,220
you have an even weirder CSV and like

00:09:01,610 --> 00:09:05,870
the like the people who wrote pandas

00:09:04,220 --> 00:09:07,340
have bought about this right and they

00:09:05,870 --> 00:09:09,140
know that maybe they're like twelve

00:09:07,340 --> 00:09:11,480
lines at the top of your CSD which are

00:09:09,140 --> 00:09:13,520
irrelevant to your CSV so there's a skip

00:09:11,480 --> 00:09:15,230
option where you can skip the first 20

00:09:13,520 --> 00:09:16,670
rows because that happened when I was

00:09:15,230 --> 00:09:17,600
downloading weather data from weather

00:09:16,670 --> 00:09:19,820
DCCA

00:09:17,600 --> 00:09:21,500
and then it was there and I didn't need

00:09:19,820 --> 00:09:24,170
to write code because it was just like

00:09:21,500 --> 00:09:26,660
an option to this VT SV method um and

00:09:24,170 --> 00:09:29,720
there's also like read Excel um I had a

00:09:26,660 --> 00:09:31,100
client at some point well they like sent

00:09:29,720 --> 00:09:32,720
us a whole bunch of Excel files and it

00:09:31,100 --> 00:09:41,030
was fine because pandas can read Excel

00:09:32,720 --> 00:09:43,040
ah it's great um so so the first thing I

00:09:41,030 --> 00:09:45,890
do um so now you'll notice that this is

00:09:43,040 --> 00:09:47,240
beautiful right um I would like to stop

00:09:45,890 --> 00:09:49,190
for a minute and talk about what we're

00:09:47,240 --> 00:09:51,380
looking at right like I said bike data

00:09:49,190 --> 00:09:54,500
is this variable what is it

00:09:51,380 --> 00:09:57,860
um so bike data is a data frame who's

00:09:54,500 --> 00:09:59,660
used R before a few of you um a

00:09:57,860 --> 00:10:01,970
dataframe pandas based on a data frame

00:09:59,660 --> 00:10:05,660
it are your intuitions are correct um

00:10:01,970 --> 00:10:07,370
who here has used sequel more of you um

00:10:05,660 --> 00:10:09,380
a data frame is a little bit like a

00:10:07,370 --> 00:10:11,780
database table right there rows there

00:10:09,380 --> 00:10:14,600
are columns um there's an index which is

00:10:11,780 --> 00:10:18,530
a little bit like your primary key um so

00:10:14,600 --> 00:10:20,660
here the data is the index and um the

00:10:18,530 --> 00:10:22,760
way this is stored like the way kind of

00:10:20,660 --> 00:10:24,620
like kind of thinks about this is it's a

00:10:22,760 --> 00:10:27,530
bunch of numpy arrays which are the

00:10:24,620 --> 00:10:29,540
which are the columns I'm so stored as a

00:10:27,530 --> 00:10:31,340
bunch of columns but it's displayed to

00:10:29,540 --> 00:10:33,320
you as like a table all together like an

00:10:31,340 --> 00:10:37,220
Excel spreadsheet kind of except awesome

00:10:33,320 --> 00:10:39,230
um because it's not an Excel spreadsheet

00:10:37,220 --> 00:10:43,190
and it's much easier to use as a

00:10:39,230 --> 00:10:46,130
programmer so um so we have our data

00:10:43,190 --> 00:10:47,780
frame um the first operation I want to

00:10:46,130 --> 00:10:50,350
show you is you can take the first three

00:10:47,780 --> 00:10:55,580
rows you can take a layout row slice um

00:10:50,350 --> 00:10:57,080
um so that's great um and let's say we

00:10:55,580 --> 00:10:58,550
wanted to plot it you might think that

00:10:57,080 --> 00:10:59,750
you have to learn how to use matplotlib

00:10:58,550 --> 00:11:01,910
and learn how to use the plotting

00:10:59,750 --> 00:11:06,320
library that's not true you just do dot

00:11:01,910 --> 00:11:07,400
plot and then we see like we look at

00:11:06,320 --> 00:11:10,940
this um

00:11:07,400 --> 00:11:13,490
and we're like okay um in the winter

00:11:10,940 --> 00:11:15,860
until March it's really cold outside

00:11:13,490 --> 00:11:17,149
and no one really goes biking and then

00:11:15,860 --> 00:11:19,970
in the summer people are like it's

00:11:17,149 --> 00:11:22,490
summer this is the best everything is

00:11:19,970 --> 00:11:25,699
amazing everyone is happy so this is not

00:11:22,490 --> 00:11:27,170
a huge surprise right so the way if I

00:11:25,699 --> 00:11:30,980
should explain this graph for a minute

00:11:27,170 --> 00:11:33,019
um the x-axis is time and the y-axis is

00:11:30,980 --> 00:11:35,209
like the number of people biking on each

00:11:33,019 --> 00:11:37,040
day and then the different lines are

00:11:35,209 --> 00:11:39,139
different bike paths I'm so like berry

00:11:37,040 --> 00:11:40,459
the blue one is right near my house and

00:11:39,139 --> 00:11:42,439
it's really popular bike path you can go

00:11:40,459 --> 00:11:45,230
really fast this is super steep hill um

00:11:42,439 --> 00:11:51,319
and it's really fun I like a little bit

00:11:45,230 --> 00:11:53,240
dangerous um it's very popular um so

00:11:51,319 --> 00:11:55,699
let's say like I said that berry was the

00:11:53,240 --> 00:11:57,559
most popular right um but if I wanted to

00:11:55,699 --> 00:11:59,749
like quantify that and I was sending a

00:11:57,559 --> 00:12:02,569
report to like my boss in charge of bike

00:11:59,749 --> 00:12:04,040
paths right I would like to and I would

00:12:02,569 --> 00:12:05,749
like to like give him the median right

00:12:04,040 --> 00:12:09,499
on the way you do that is you're like a

00:12:05,749 --> 00:12:11,389
dot median and there are a lot of is

00:12:09,499 --> 00:12:13,009
like super helpful funk like methods

00:12:11,389 --> 00:12:15,079
that pandas gives you on data frames um

00:12:13,009 --> 00:12:18,529
for like finding out statistics about

00:12:15,079 --> 00:12:20,089
your data um so and let's say I didn't

00:12:18,529 --> 00:12:22,369
want it to plot the medians and have

00:12:20,089 --> 00:12:24,439
like a bar chart cuz everyone loves bar

00:12:22,369 --> 00:12:27,040
charts then I could be like bike data

00:12:24,439 --> 00:12:30,230
dot median dot plot

00:12:27,040 --> 00:12:32,499
um and then it gave me some weird air

00:12:30,230 --> 00:12:35,269
pretend that errors in there uh-huh

00:12:32,499 --> 00:12:36,920
that was some kind of fun thing um and

00:12:35,269 --> 00:12:38,480
then you can see that that like berry is

00:12:36,920 --> 00:12:39,889
the biggest right and then I feel like

00:12:38,480 --> 00:12:41,209
this is the best buy crap we should kill

00:12:39,889 --> 00:12:42,799
all the others I don't know like

00:12:41,209 --> 00:12:43,850
whatever track kind of conclusion you

00:12:42,799 --> 00:12:45,139
were trying to convince the people in

00:12:43,850 --> 00:12:49,519
your board with your board meeting chill

00:12:45,139 --> 00:12:51,559
in this graph okay um a few other things

00:12:49,519 --> 00:12:53,839
I want to talk about um you can take a

00:12:51,559 --> 00:12:55,999
column slice so like let's say sometimes

00:12:53,839 --> 00:12:58,670
I have like CSVs which have like two

00:12:55,999 --> 00:13:00,949
billion rows or like 50 and I only

00:12:58,670 --> 00:13:04,129
really care about three um you can give

00:13:00,949 --> 00:13:06,230
a list of roses as an index and just

00:13:04,129 --> 00:13:09,199
restrict your attention to that and then

00:13:06,230 --> 00:13:10,639
you can also like say to take the first

00:13:09,199 --> 00:13:11,959
three rows and you can switch those

00:13:10,639 --> 00:13:13,399
around you can be like give me the first

00:13:11,959 --> 00:13:15,139
three rows and then only these columns

00:13:13,399 --> 00:13:19,699
it doesn't care what order you do it in

00:13:15,139 --> 00:13:22,129
pandas is nice to you okay um the last

00:13:19,699 --> 00:13:24,499
kind of like basic pen like numpy pandas

00:13:22,129 --> 00:13:26,540
feature I want you to talk about um is

00:13:24,499 --> 00:13:27,080
my favorite one of my favorites I have

00:13:26,540 --> 00:13:31,490
many favored

00:13:27,080 --> 00:13:33,560
sorry um so I talked about doing

00:13:31,490 --> 00:13:35,360
operations all at once right so let's

00:13:33,560 --> 00:13:37,610
say I wanted to find all of the days

00:13:35,360 --> 00:13:39,140
where they're less than 75 people biking

00:13:37,610 --> 00:13:41,530
on the berry bike path near my house

00:13:39,140 --> 00:13:44,960
right because like 75 isn't a lot um

00:13:41,530 --> 00:13:47,450
it's a pretty popular bike path I'm so

00:13:44,960 --> 00:13:49,760
what I can do is I can say when is this

00:13:47,450 --> 00:13:52,010
less than 75 and it gives me this long

00:13:49,760 --> 00:13:54,980
Bachelor of trues and falses right and

00:13:52,010 --> 00:13:58,010
then what I can do with that is I can

00:13:54,980 --> 00:14:00,020
put that into like I can index with it

00:13:58,010 --> 00:14:02,060
and it will give me all of the rows that

00:14:00,020 --> 00:14:04,250
satisfy that condition and I can combine

00:14:02,060 --> 00:14:06,230
conditions and that can use arbitrarily

00:14:04,250 --> 00:14:08,480
complicated conditions so it's like a

00:14:06,230 --> 00:14:10,790
sequel query if you've used that except

00:14:08,480 --> 00:14:12,530
you can write Python code right um and

00:14:10,790 --> 00:14:13,910
you can't just like do whatever sequel

00:14:12,530 --> 00:14:15,860
might allow you to do you can do

00:14:13,910 --> 00:14:18,590
anything you want and do kind of like

00:14:15,860 --> 00:14:20,060
arbitrary queries um and we can see here

00:14:18,590 --> 00:14:21,800
that like the days with less than 700

00:14:20,060 --> 00:14:23,360
people are all days in January and

00:14:21,800 --> 00:14:27,020
February because January and February

00:14:23,360 --> 00:14:30,800
are so cold right it's like not a huge

00:14:27,020 --> 00:14:33,830
surprise so um that's super powerful and

00:14:30,800 --> 00:14:38,930
I use it all the time okay so the next

00:14:33,830 --> 00:14:40,670
question I had um is I wanted to know

00:14:38,930 --> 00:14:42,260
like what all of this variation was

00:14:40,670 --> 00:14:45,140
about right like there's this graph and

00:14:42,260 --> 00:14:47,000
it's like number of cyclists and I want

00:14:45,140 --> 00:14:48,950
to know like is this because of weekends

00:14:47,000 --> 00:14:50,540
like is the variation because more

00:14:48,950 --> 00:14:52,250
people bike on weekdays or on weekends

00:14:50,540 --> 00:14:54,380
so here's a here's a question like who

00:14:52,250 --> 00:14:55,970
thinks that in Montreal we're a city of

00:14:54,380 --> 00:14:58,730
commuter cyclist having mostly bike

00:14:55,970 --> 00:15:02,810
because we're going to work some people

00:14:58,730 --> 00:15:05,180
who thinks it's we bike for fun there's

00:15:02,810 --> 00:15:07,730
disagreement we can solve this with data

00:15:05,180 --> 00:15:11,240
this is the best we're gonna find out

00:15:07,730 --> 00:15:13,790
who's right so the first thing I'm going

00:15:11,240 --> 00:15:15,410
to do is I have a data frame I'm gonna

00:15:13,790 --> 00:15:16,910
add a new column the way you add a new

00:15:15,410 --> 00:15:18,940
column is like adding a new key to a

00:15:16,910 --> 00:15:22,040
dictionary um because everything is nice

00:15:18,940 --> 00:15:26,810
and like these interfaces work kind of

00:15:22,040 --> 00:15:28,340
like you might expect um so um pandas is

00:15:26,810 --> 00:15:31,010
really good with time series a time

00:15:28,340 --> 00:15:33,740
series is a fancy word for a bunch of

00:15:31,010 --> 00:15:35,870
numbers which are indexed by like a date

00:15:33,740 --> 00:15:37,790
so like stocks right um it was

00:15:35,870 --> 00:15:40,970
originally built by by people who are

00:15:37,790 --> 00:15:44,900
doing like financial data analysis um

00:15:40,970 --> 00:15:48,500
um so I had a weekday column and like

00:15:44,900 --> 00:15:50,800
index alt weekday and then it gives me a

00:15:48,500 --> 00:15:53,240
number right for each day of the year

00:15:50,800 --> 00:15:57,020
and then what I want to do with this is

00:15:53,240 --> 00:15:58,400
I want to UM collect all of all of the

00:15:57,020 --> 00:15:59,720
entries with like the same weekday so

00:15:58,400 --> 00:16:01,190
like say like everything with weekday

00:15:59,720 --> 00:16:02,930
6:00 I would like to add all those up

00:16:01,190 --> 00:16:04,460
and then everything with weekday zero I

00:16:02,930 --> 00:16:05,540
would like to add all those up and then

00:16:04,460 --> 00:16:07,160
every day this week a day one I'll add

00:16:05,540 --> 00:16:10,960
all those up and then we'll figure out

00:16:07,160 --> 00:16:13,610
what six and zero actually means um and

00:16:10,960 --> 00:16:19,640
then we'll draw a pretty graph and show

00:16:13,610 --> 00:16:22,790
it to our board meeting right so um once

00:16:19,640 --> 00:16:25,700
I do that um if you've done who seems

00:16:22,790 --> 00:16:27,800
like a sequel group by this is like that

00:16:25,700 --> 00:16:29,990
um if you haven't used a sequel group by

00:16:27,800 --> 00:16:33,790
it's what I said right um you have like

00:16:29,990 --> 00:16:36,350
all of the zeros and you add them up um

00:16:33,790 --> 00:16:38,030
but like you should think of a pandas

00:16:36,350 --> 00:16:41,330
group I like a sequel group I that's why

00:16:38,030 --> 00:16:43,610
it's called that um so we say group by

00:16:41,330 --> 00:16:46,010
week day and then aggregate all of those

00:16:43,610 --> 00:16:48,140
groups by taking the sum you can use any

00:16:46,010 --> 00:16:49,700
function you want here you don't just

00:16:48,140 --> 00:16:51,560
have to use built-in functions you can

00:16:49,700 --> 00:16:53,120
write your own functions you can use any

00:16:51,560 --> 00:16:54,530
function that you find in the wild you

00:16:53,120 --> 00:16:57,470
can use someone else's you know you can

00:16:54,530 --> 00:16:59,660
you can just use any function um so I do

00:16:57,470 --> 00:17:01,670
this and then I get a new data frame

00:16:59,660 --> 00:17:04,010
which has all of the weekdays as the

00:17:01,670 --> 00:17:05,780
index and then for each column is added

00:17:04,010 --> 00:17:07,460
them all up and it did all the work for

00:17:05,780 --> 00:17:09,740
me and I didn't have to write a loop

00:17:07,460 --> 00:17:12,020
because loops are work and we don't like

00:17:09,740 --> 00:17:15,020
doing work we like other people to do

00:17:12,020 --> 00:17:18,590
our work for us or at least I do um

00:17:15,020 --> 00:17:22,010
right um but like numbers like who likes

00:17:18,590 --> 00:17:26,510
reading tables of a lot of numbers some

00:17:22,010 --> 00:17:29,930
of you um I I feel you I like members

00:17:26,510 --> 00:17:31,700
however I prefer graphs right um so what

00:17:29,930 --> 00:17:33,620
I did was I changed my index by hand I

00:17:31,700 --> 00:17:35,390
just looked up like I find a jape that

00:17:33,620 --> 00:17:37,820
was zero and then looked up in my

00:17:35,390 --> 00:17:39,110
calendar to find out what day of the

00:17:37,820 --> 00:17:40,160
week it was and I found out that it was

00:17:39,110 --> 00:17:44,300
Monday um

00:17:40,160 --> 00:17:45,740
because I I wanted to do it fast um if

00:17:44,300 --> 00:17:47,270
you were like doing it the right way you

00:17:45,740 --> 00:17:47,990
would probably find out some way to do

00:17:47,270 --> 00:17:50,560
it programmatically

00:17:47,990 --> 00:17:50,560
I didn't do that

00:17:51,190 --> 00:17:55,510
I changed the index view right and it

00:17:53,830 --> 00:17:57,310
turns out that Thursday is the most

00:17:55,510 --> 00:17:58,870
popular day the days of the week are

00:17:57,310 --> 00:18:00,730
more popular than the weekends and it

00:17:58,870 --> 00:18:08,980
looks like we're commuters it looks like

00:18:00,730 --> 00:18:10,990
we bike to work um so that's cool um and

00:18:08,980 --> 00:18:13,510
then I drew a bar graph you'll note that

00:18:10,990 --> 00:18:16,360
like if you want to plot a bar graph

00:18:13,510 --> 00:18:18,220
you're like plot kind equals bar um

00:18:16,360 --> 00:18:22,330
that's like one of the main kinds of

00:18:18,220 --> 00:18:23,470
graphs I draw a lot um so that that's

00:18:22,330 --> 00:18:25,240
good right

00:18:23,470 --> 00:18:27,070
and you'll notice that we didn't have to

00:18:25,240 --> 00:18:28,390
write loops to do that right like if it

00:18:27,070 --> 00:18:32,560
was just like a few lines of code

00:18:28,390 --> 00:18:34,510
all right so but if we look at that this

00:18:32,560 --> 00:18:36,400
chart again like there was a little bit

00:18:34,510 --> 00:18:37,960
of variation by day of the week but

00:18:36,400 --> 00:18:39,610
that's definitely not like all that's

00:18:37,960 --> 00:18:44,320
causing this like huge spike throughout

00:18:39,610 --> 00:18:46,440
the year right um so I'd like to do like

00:18:44,320 --> 00:18:48,760
a better investigation into this um

00:18:46,440 --> 00:18:52,690
because we're like data scientists or

00:18:48,760 --> 00:18:53,920
whatever I don't know so the next thing

00:18:52,690 --> 00:18:56,320
I wanted to do is look at the

00:18:53,920 --> 00:19:00,370
temperature right like it's cold it's

00:18:56,320 --> 00:19:03,430
don't need to be like amazing uh data

00:19:00,370 --> 00:19:05,110
statistics magic people to like know

00:19:03,430 --> 00:19:07,750
that people don't like going biking when

00:19:05,110 --> 00:19:09,160
it's cold um so I remembered this

00:19:07,750 --> 00:19:11,890
function don't look at this function

00:19:09,160 --> 00:19:14,110
it's kind of big um but basically what I

00:19:11,890 --> 00:19:16,740
was doing was like I went to climate dot

00:19:14,110 --> 00:19:20,200
weather DC top CA and like I found some

00:19:16,740 --> 00:19:22,510
like place where I could put in things

00:19:20,200 --> 00:19:24,400
into the URL and it would give me a CSV

00:19:22,510 --> 00:19:26,650
kind of and I could put it together

00:19:24,400 --> 00:19:27,850
anyway it wasn't a lot of work it's kind

00:19:26,650 --> 00:19:29,080
of what I'm trying to say here like you

00:19:27,850 --> 00:19:33,370
can imagine you could have written this

00:19:29,080 --> 00:19:35,350
um and then I got my weather data and I

00:19:33,370 --> 00:19:37,480
looked at it and it gave me the

00:19:35,350 --> 00:19:39,910
temperature every hour and I was like

00:19:37,480 --> 00:19:41,470
that's good um the main problem with

00:19:39,910 --> 00:19:43,300
this is I didn't want the temperature

00:19:41,470 --> 00:19:45,970
every hour and wanted the temperature

00:19:43,300 --> 00:19:50,290
every day right because we only have the

00:19:45,970 --> 00:19:53,680
bike data every day um so I decided to

00:19:50,290 --> 00:19:55,350
take the average temperature um and the

00:19:53,680 --> 00:19:58,510
way you take the average temperature is

00:19:55,350 --> 00:19:59,950
you resample which is apparently

00:19:58,510 --> 00:20:01,510
something people do when analyzing like

00:19:59,950 --> 00:20:03,250
financial stock data because they're

00:20:01,510 --> 00:20:04,990
like I have my stock prices ever you're

00:20:03,250 --> 00:20:06,400
like two millisecond

00:20:04,990 --> 00:20:08,740
and I only need them every like 10

00:20:06,400 --> 00:20:12,250
milliseconds I don't know about hyper

00:20:08,740 --> 00:20:16,660
egusi stock analysis too much but when I

00:20:12,250 --> 00:20:19,330
did it I resampled so um so we're

00:20:16,660 --> 00:20:21,790
example resampling is great you do dot

00:20:19,330 --> 00:20:23,350
resample and then you give it the time

00:20:21,790 --> 00:20:25,510
period you want you can write it in like

00:20:23,350 --> 00:20:27,429
you write D if you want to days your

00:20:25,510 --> 00:20:31,450
right to D if you want three hours you

00:20:27,429 --> 00:20:33,610
write 3h it's pretty simple um and then

00:20:31,450 --> 00:20:34,900
you say how and you can either say

00:20:33,610 --> 00:20:36,850
something like mean or you can give it a

00:20:34,900 --> 00:20:38,700
function because you can all basically

00:20:36,850 --> 00:20:42,640
like all the skip n distinct functions

00:20:38,700 --> 00:20:44,230
um so once I've done that I get them the

00:20:42,640 --> 00:20:45,700
average temperature every day right and

00:20:44,230 --> 00:20:46,929
we could argue for like hours about

00:20:45,700 --> 00:20:48,429
whether or not this is a useful thing

00:20:46,929 --> 00:20:52,900
like this is like the best way to

00:20:48,429 --> 00:20:54,640
resample um but we won't you can

00:20:52,900 --> 00:20:57,820
download this afterwards and do a better

00:20:54,640 --> 00:21:01,270
job than me that is what I would like so

00:20:57,820 --> 00:21:03,910
um we can see like on January 3rd that

00:21:01,270 --> 00:21:05,650
it was like - 14 Celsius which is pretty

00:21:03,910 --> 00:21:12,850
cold I think it's like a zero Fahrenheit

00:21:05,650 --> 00:21:14,590
um if you're American um so I drew I

00:21:12,850 --> 00:21:16,179
drew a little graph up like bikes per

00:21:14,590 --> 00:21:17,950
day in temperature and you'll see like

00:21:16,179 --> 00:21:19,390
this I'm gonna go over there really

00:21:17,950 --> 00:21:21,760
quickly um because this was really

00:21:19,390 --> 00:21:21,970
exciting to me oh no but I'm not tall

00:21:21,760 --> 00:21:24,280
enough

00:21:21,970 --> 00:21:27,070
okay this spike here this was in March

00:21:24,280 --> 00:21:30,220
and it went up to 18 degrees and it was

00:21:27,070 --> 00:21:32,080
beautiful and I missed it and all of my

00:21:30,220 --> 00:21:33,670
friends were like oh it was so nice and

00:21:32,080 --> 00:21:35,910
I was outside and I was wearing a tank

00:21:33,670 --> 00:21:37,570
top and it was a March and I was like

00:21:35,910 --> 00:21:39,580
why did I miss it

00:21:37,570 --> 00:21:41,380
um anyway this was like kind of unheard

00:21:39,580 --> 00:21:43,030
of but like if the temperature went up

00:21:41,380 --> 00:21:44,590
super high and everyone went up biking

00:21:43,030 --> 00:21:45,580
and everyone was so excited and then it

00:21:44,590 --> 00:21:46,300
went down again everyone's like

00:21:45,580 --> 00:21:48,040
nevermind

00:21:46,300 --> 00:21:50,530
and they put their bike away again right

00:21:48,040 --> 00:21:52,179
like um so you can see that like they're

00:21:50,530 --> 00:21:53,890
there's like a real correlation here

00:21:52,179 --> 00:21:56,679
right but the rest of it I don't know

00:21:53,890 --> 00:21:58,630
like I'm I'm not like as sold on like

00:21:56,679 --> 00:22:01,390
the other spikes in this graph just kind

00:21:58,630 --> 00:22:05,290
of that one in March over there um but

00:22:01,390 --> 00:22:06,760
that's cool we've done science and by

00:22:05,290 --> 00:22:11,100
which I mean looking at graphs and

00:22:06,760 --> 00:22:14,260
points I'm not a real scientist so um

00:22:11,100 --> 00:22:16,470
right so now the next question was like

00:22:14,260 --> 00:22:18,309
there's more variation here right like

00:22:16,470 --> 00:22:18,940
so maybe let's look at whether it's

00:22:18,309 --> 00:22:22,900
raining

00:22:18,940 --> 00:22:25,300
let's look at some precipitation so I

00:22:22,900 --> 00:22:27,310
wanted to know like what percentage of

00:22:25,300 --> 00:22:29,260
each day was it raining right and here

00:22:27,310 --> 00:22:31,420
you might again think and we if we look

00:22:29,260 --> 00:22:34,270
at our original um data

00:22:31,420 --> 00:22:36,430
weather data frame here it doesn't give

00:22:34,270 --> 00:22:38,350
us like a rain this quotient it says

00:22:36,430 --> 00:22:40,330
like a string which is the weather right

00:22:38,350 --> 00:22:43,650
um so you might think you would have to

00:22:40,330 --> 00:22:47,740
do work here and you'd be wrong because

00:22:43,650 --> 00:22:50,020
pandas knows everything so panthis is

00:22:47,740 --> 00:22:51,580
all these magical string functions so

00:22:50,020 --> 00:22:54,340
what you say is like look at the weather

00:22:51,580 --> 00:22:56,170
and then go to like the bunch of string

00:22:54,340 --> 00:22:57,790
functions and say like does this contain

00:22:56,170 --> 00:22:59,650
rain and then it gives you a 1 or a 0

00:22:57,790 --> 00:23:01,180
depending on whether or not it contains

00:22:59,650 --> 00:23:05,920
the string rain and it just does

00:23:01,180 --> 00:23:07,990
everything for you um so and then you

00:23:05,920 --> 00:23:09,550
resample that again every day um so we

00:23:07,990 --> 00:23:11,440
get like the percentage of hours of the

00:23:09,550 --> 00:23:12,640
day when it was raining right and like

00:23:11,440 --> 00:23:16,060
whether or not that's the right thing I

00:23:12,640 --> 00:23:17,740
don't know right maybe um and then we

00:23:16,060 --> 00:23:19,960
get this other graph I'm like this graph

00:23:17,740 --> 00:23:23,610
is a lot less clear to me um there's

00:23:19,960 --> 00:23:28,810
some spikes over here where like like

00:23:23,610 --> 00:23:30,580
this one and over here like maybe that

00:23:28,810 --> 00:23:32,950
correlates with like a spike downwards I

00:23:30,580 --> 00:23:35,590
can kind of see it like like like like

00:23:32,950 --> 00:23:39,100
this and--but but like also like

00:23:35,590 --> 00:23:40,810
pointing at uh spikes in graphs is like

00:23:39,100 --> 00:23:42,340
a really dangerous thing to do in

00:23:40,810 --> 00:23:44,230
analyzing data this is not a good

00:23:42,340 --> 00:23:46,240
practice and because you like you can

00:23:44,230 --> 00:23:47,530
just like over fate with your brain a

00:23:46,240 --> 00:23:48,940
lot because we're really good at

00:23:47,530 --> 00:23:50,890
detecting patterns that aren't there um

00:23:48,940 --> 00:23:52,720
so it would be better to look at like a

00:23:50,890 --> 00:23:55,210
correlation um which you could also do

00:23:52,720 --> 00:23:57,970
but we're not going to do um because

00:23:55,210 --> 00:23:59,440
this is all I have to say but don't

00:23:57,970 --> 00:24:00,550
applaud yet I have more to say but this

00:23:59,440 --> 00:24:02,620
is all I've saved at our practical

00:24:00,550 --> 00:24:04,960
example right um

00:24:02,620 --> 00:24:07,840
this wasn't a lot of code is the main

00:24:04,960 --> 00:24:08,890
point I want to make right um except for

00:24:07,840 --> 00:24:10,600
the weather thing which was like a

00:24:08,890 --> 00:24:13,420
disaster but like pretend that didn't

00:24:10,600 --> 00:24:15,790
happen um and there were no loops right

00:24:13,420 --> 00:24:17,560
like we made these graphs and like we

00:24:15,790 --> 00:24:20,200
found out if it contained rain and we

00:24:17,560 --> 00:24:21,580
like resampled and we did all this kind

00:24:20,200 --> 00:24:22,810
of cool stuff and we didn't have to

00:24:21,580 --> 00:24:25,450
write loops we had to write like up to

00:24:22,810 --> 00:24:26,260
like six lines of code right including

00:24:25,450 --> 00:24:29,830
reading in the data

00:24:26,260 --> 00:24:32,440
I was super easy um and it's very easy

00:24:29,830 --> 00:24:33,850
to experiment so

00:24:32,440 --> 00:24:36,600
have a little bit of advice for you um

00:24:33,850 --> 00:24:38,860
if you want to be using these tools I

00:24:36,600 --> 00:24:40,510
find it super useful to read some the

00:24:38,860 --> 00:24:44,080
documentation um there's a ton of

00:24:40,510 --> 00:24:45,340
documentation um and what I often find

00:24:44,080 --> 00:24:46,960
is I'll read like a tutorial and I'll

00:24:45,340 --> 00:24:48,040
learn a little bit and then let go look

00:24:46,960 --> 00:24:49,780
at the documentation I'll find something

00:24:48,040 --> 00:24:51,430
which is like totally helps me I'm like

00:24:49,780 --> 00:24:51,940
I wish I knew about that like six months

00:24:51,430 --> 00:24:53,320
ago

00:24:51,940 --> 00:24:55,540
um so it's good to go look at a little

00:24:53,320 --> 00:24:56,740
bit at from time to time I'm brush up um

00:24:55,540 --> 00:24:59,020
once you've learned some of the basics

00:24:56,740 --> 00:25:01,300
I'm just like this huge PDF and really

00:24:59,020 --> 00:25:03,040
good API documentation I really enjoy it

00:25:01,300 --> 00:25:04,750
um husband Kenny wrote a book called

00:25:03,040 --> 00:25:06,090
Python for data analysis which I enjoy

00:25:04,750 --> 00:25:10,120
and has a lot of really great examples

00:25:06,090 --> 00:25:12,220
um one of the main most important things

00:25:10,120 --> 00:25:13,600
is like always try to use like these

00:25:12,220 --> 00:25:16,300
built-in operations right like don't

00:25:13,600 --> 00:25:18,520
resample or like um things that have

00:25:16,300 --> 00:25:21,760
been built things that are built in um

00:25:18,520 --> 00:25:23,560
because writing your own loops is a lot

00:25:21,760 --> 00:25:25,120
of like it's more of your work um it

00:25:23,560 --> 00:25:27,340
means that will be really slow it'll be

00:25:25,120 --> 00:25:28,410
like 20 times slower um as we saw before

00:25:27,340 --> 00:25:30,700
right

00:25:28,410 --> 00:25:32,050
um and it's like it doesn't matter for

00:25:30,700 --> 00:25:34,360
taking a second but if you're doing like

00:25:32,050 --> 00:25:38,470
real big computations it's a big problem

00:25:34,360 --> 00:25:40,180
um and though you can if you really need

00:25:38,470 --> 00:25:43,090
to do some custom computation you can

00:25:40,180 --> 00:25:44,650
use tools like scythe on um to like

00:25:43,090 --> 00:25:46,140
write things that are compiled to see

00:25:44,650 --> 00:25:48,190
and actually run quickly and that's

00:25:46,140 --> 00:25:49,360
pretty approachable like I've done it

00:25:48,190 --> 00:25:50,950
before I kind of like googled some

00:25:49,360 --> 00:25:52,030
examples and dived into the Penta source

00:25:50,950 --> 00:25:54,010
code and pulled something out and copy

00:25:52,030 --> 00:25:55,620
didn't messed with it and it worked um

00:25:54,010 --> 00:25:58,090
it's like pretty approachable to do that

00:25:55,620 --> 00:25:59,200
but it's easier to avoid doing that and

00:25:58,090 --> 00:26:01,360
just use built in functions whenever

00:25:59,200 --> 00:26:04,390
possible and often more things are built

00:26:01,360 --> 00:26:07,060
in that you think um one thing that I

00:26:04,390 --> 00:26:08,860
did is I made a pandas cookbook if you

00:26:07,060 --> 00:26:10,780
want to get started so I have this

00:26:08,860 --> 00:26:12,700
github repository and there's like ten

00:26:10,780 --> 00:26:15,070
chapters which are like different like

00:26:12,700 --> 00:26:17,110
small examples of things that you can do

00:26:15,070 --> 00:26:18,880
with pandas together with like practical

00:26:17,110 --> 00:26:20,290
examples so this is a seis data set

00:26:18,880 --> 00:26:21,870
there's some other data sets that I use

00:26:20,290 --> 00:26:25,720
to kind of show off some kind of

00:26:21,870 --> 00:26:26,980
capabilities um and so if you want to

00:26:25,720 --> 00:26:29,200
take a look at that you could contribute

00:26:26,980 --> 00:26:30,760
to it also um they're examples of how to

00:26:29,200 --> 00:26:35,080
use it with like sequel databases

00:26:30,760 --> 00:26:39,180
um and that might be a place to get

00:26:35,080 --> 00:26:39,180
started and that's it

00:26:42,549 --> 00:26:46,299
hence cooler that was fantastic

00:26:46,690 --> 00:26:51,429
so if there are any questions for Julia

00:26:49,360 --> 00:26:53,440
come and line up at this microphone that

00:26:51,429 --> 00:26:56,080
we've cleverly placed here at the front

00:26:53,440 --> 00:27:00,970
of the room I will just give a few

00:26:56,080 --> 00:27:03,129
moments for our cue to form great first

00:27:00,970 --> 00:27:05,830
question thank you it seems like going

00:27:03,129 --> 00:27:08,230
from fundamentally based programming to

00:27:05,830 --> 00:27:10,509
this sort of vector base model require a

00:27:08,230 --> 00:27:12,009
fairly different set of thinking so is

00:27:10,509 --> 00:27:13,870
there any particular tips for people who

00:27:12,009 --> 00:27:15,970
are not as familiar with operating on

00:27:13,870 --> 00:27:17,919
vectors that you found were helpful in

00:27:15,970 --> 00:27:19,899
getting started that's a really good

00:27:17,919 --> 00:27:21,820
question I guess I think of them as a

00:27:19,899 --> 00:27:23,470
little bit like database queries I'm so

00:27:21,820 --> 00:27:25,179
if you if you think of database queries

00:27:23,470 --> 00:27:27,820
that's like a very group based way of

00:27:25,179 --> 00:27:31,389
thinking of things um and if you're not

00:27:27,820 --> 00:27:32,980
I find the like the more I practice it

00:27:31,389 --> 00:27:33,700
the better it gets that's like a not a

00:27:32,980 --> 00:27:39,370
very good answer

00:27:33,700 --> 00:27:41,230
ah hi where does something like

00:27:39,370 --> 00:27:45,970
scikit-learn Fidan do this

00:27:41,230 --> 00:27:47,919
the slides that's it the scikit-learn

00:27:45,970 --> 00:27:49,299
another thing I've heard some talks

00:27:47,919 --> 00:27:52,200
about oh yeah I talked about

00:27:49,299 --> 00:27:55,059
scikit-learn in my abstract um so like

00:27:52,200 --> 00:27:57,610
numpy integrates really well ii learn so

00:27:55,059 --> 00:27:59,259
anytime you want to use like if you want

00:27:57,610 --> 00:28:02,110
to do machine on your pandas dataframes

00:27:59,259 --> 00:28:04,330
that'll just work um so can it be for

00:28:02,110 --> 00:28:06,129
like data analysis and for secular

00:28:04,330 --> 00:28:07,330
before modelling yes I could learn for

00:28:06,129 --> 00:28:08,950
modeling yeah so if you want to make a

00:28:07,330 --> 00:28:10,899
map model you can like send like a

00:28:08,950 --> 00:28:12,820
panda's data frame as input and that

00:28:10,899 --> 00:28:17,559
will work seamlessly that's something

00:28:12,820 --> 00:28:19,090
that I do yeah um so first off this

00:28:17,559 --> 00:28:20,620
looks like a lot of fun cuz my city's

00:28:19,090 --> 00:28:24,340
been releasing a lot of open data lately

00:28:20,620 --> 00:28:26,919
um but Kenneth can this do geographical

00:28:24,340 --> 00:28:28,600
stuff graphical stuff or Geographic

00:28:26,919 --> 00:28:31,029
geographical stuff that's a good

00:28:28,600 --> 00:28:34,690
question I don't think that pandas does

00:28:31,029 --> 00:28:36,970
geographical stuff by itself I don't

00:28:34,690 --> 00:28:40,690
know if that's true not that I know of

00:28:36,970 --> 00:28:43,600
um but there are really good tools that

00:28:40,690 --> 00:28:48,309
I've seen okay yeah I can I can show you

00:28:43,600 --> 00:28:50,950
something later okay thanks Julie

00:28:48,309 --> 00:28:53,980
appreciate the talk quick question on

00:28:50,950 --> 00:28:56,710
customizing ipython notebooks I've seen

00:28:53,980 --> 00:28:58,600
a lot of different customizations of the

00:28:56,710 --> 00:29:00,880
interface for ipython notebooks

00:28:58,600 --> 00:29:03,520
why I was wondering if you had any any

00:29:00,880 --> 00:29:04,809
if you customized ipython notebook at

00:29:03,520 --> 00:29:07,419
all and if so do you have any

00:29:04,809 --> 00:29:09,490
recommended resources so do you mean

00:29:07,419 --> 00:29:12,400
like customizing people slides no

00:29:09,490 --> 00:29:14,799
customizing the actual interfaces I know

00:29:12,400 --> 00:29:18,220
that you can kind of as I understand it

00:29:14,799 --> 00:29:20,919
you can customize it so that certain

00:29:18,220 --> 00:29:23,590
commands do certain different things in

00:29:20,919 --> 00:29:24,789
ipython notebook okay you like some

00:29:23,590 --> 00:29:28,179
people do like interactive JavaScript

00:29:24,789 --> 00:29:29,169
things and ipython notebook got a lot of

00:29:28,179 --> 00:29:32,350
different options

00:29:29,169 --> 00:29:33,460
oh so the answer is I don't know I think

00:29:32,350 --> 00:29:36,070
the answer is I don't know but I would

00:29:33,460 --> 00:29:40,870
love to see yeah you know I don't do

00:29:36,070 --> 00:29:42,669
that Julia how do you make sure that the

00:29:40,870 --> 00:29:46,600
conclusions you make are real and not

00:29:42,669 --> 00:29:50,799
just like because the I think the answer

00:29:46,600 --> 00:29:54,059
to that is like learn statistics and

00:29:50,799 --> 00:29:59,110
acquire friends who know statistics um

00:29:54,059 --> 00:30:00,190
yeah um I don't want to say too much

00:29:59,110 --> 00:30:03,820
about this because I feel like I'll

00:30:00,190 --> 00:30:07,360
embarrass myself but um one thing you

00:30:03,820 --> 00:30:09,820
can do is be really careful about what

00:30:07,360 --> 00:30:11,890
data you look at so like so for example

00:30:09,820 --> 00:30:14,110
you don't want to like look at data and

00:30:11,890 --> 00:30:15,370
then like take out points that you think

00:30:14,110 --> 00:30:16,480
are interesting like I was doing like

00:30:15,370 --> 00:30:19,210
what I was doing was a terrible thing to

00:30:16,480 --> 00:30:20,500
do right you shouldn't do that um what

00:30:19,210 --> 00:30:21,700
you can do is like think about the

00:30:20,500 --> 00:30:24,280
questions that you're asking carefully

00:30:21,700 --> 00:30:26,500
before you look at the data um and I

00:30:24,280 --> 00:30:27,820
think that's a good way yeah like I like

00:30:26,500 --> 00:30:29,770
asking the question after you look at

00:30:27,820 --> 00:30:31,299
the data is a bad choice because then

00:30:29,770 --> 00:30:32,770
like you'd like made up a question right

00:30:31,299 --> 00:30:34,840
um but if you ask question before you

00:30:32,770 --> 00:30:39,190
look at the data then you have a better

00:30:34,840 --> 00:30:41,559
chance of like doing a good job by

00:30:39,190 --> 00:30:42,580
hearing your experience enthusiasm for

00:30:41,559 --> 00:30:44,320
this this topic

00:30:42,580 --> 00:30:46,500
everybody please like Julia Evans for a

00:30:44,320 --> 00:30:46,500
talk

00:30:53,389 --> 00:30:56,600

YouTube URL: https://www.youtube.com/watch?v=rEalbu8UGeo


