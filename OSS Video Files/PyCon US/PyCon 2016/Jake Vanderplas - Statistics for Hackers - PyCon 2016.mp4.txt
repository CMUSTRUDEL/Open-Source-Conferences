Title: Jake Vanderplas - Statistics for Hackers - PyCon 2016.mp4
Publication date: 2016-06-17
Playlist: PyCon 2016
Description: 
	Speaker: Jake Vanderplas

Statistics has the reputation of being difficult to understand, but using some simple Python skills it can be made much more intuitive. This talk will cover several sampling-based approaches to solving statistical problems, and show you that if you can write a for-loop, you can do statistics.

Slides can be found at: https://speakerdeck.com/pycon2016 and https://github.com/PyCon/2016-slides
Captions: 
	00:00:00,399 --> 00:00:04,670
Our next speaker is an astronomer from the University of Washington.

00:00:04,670 --> 00:00:07,580
Please help me welcome Jake Vanderplas.

00:00:07,580 --> 00:00:12,040
[applause]

00:00:13,280 --> 00:00:15,920
All right, well thanks very much, it's great to be here.

00:00:15,920 --> 00:00:19,640
I always love my experiences at PyCon.

00:00:19,640 --> 00:00:23,740
Today I want to talk to you a little bit about statistics for hackers --

00:00:23,740 --> 00:00:27,330
and just real quick so you know who you're hearing this from --

00:00:27,330 --> 00:00:28,699
I’m an astronomer by training.

00:00:28,699 --> 00:00:32,880
I like to say I’m a statistician by accident because in astronomy

00:00:32,880 --> 00:00:36,520
we work with data and anyone who works with data ends up by default

00:00:36,520 --> 00:00:40,430
working in statistics, which is a little bit crazy

00:00:40,430 --> 00:00:44,260
because often many of us who spend our lives working with data

00:00:44,260 --> 00:00:47,800
haven't had much training in statistics, right?

00:00:47,800 --> 00:00:52,160
So we end up kind of going along and learning things on the way.

00:00:52,160 --> 00:00:56,330
So I’m active in the Python science and open source;

00:00:56,330 --> 00:00:59,320
I contribute a lot to scikit-learn and SciPy and stuff like that

00:00:59,320 --> 00:01:02,980
and I really find a lot of enjoyment in that.

00:01:02,980 --> 00:01:05,970
And you can find me as jakevdp on Twitter and GitHub.

00:01:05,970 --> 00:01:11,760
But back to the talk at hand, the topic at hand, statistics for hackers.

00:01:11,760 --> 00:01:14,800
I've noticed this has caused a little bit of confusion when I’ve told people

00:01:14,800 --> 00:01:18,390
about this, because people think of "hacker" as a person trying

00:01:18,390 --> 00:01:20,930
to steal your grandma's bank password or something like that.

00:01:20,930 --> 00:01:23,340
But I’m not using hacker in that sort of sense.

00:01:23,340 --> 00:01:27,730
I’m using hacker in the sense of probably what a lot of you are in this room,

00:01:27,730 --> 00:01:32,980
someone whose natural approach to solving problems includes writing code

00:01:32,980 --> 00:01:36,500
or understanding the world through writing code.

00:01:36,500 --> 00:01:40,880
And what I found -- it's really interesting --

00:01:40,880 --> 00:01:42,960
is that statistics is hard,

00:01:42,960 --> 00:01:48,360
but if you apply some of those skills that each of you have in this room

00:01:48,370 --> 00:01:51,880
and use those programming skills, the statistics can be easy,

00:01:51,880 --> 00:01:54,110
or at least much easier.

00:01:54,110 --> 00:01:58,310
And the trick in statistics really comes down to, well --

00:01:58,310 --> 00:02:00,920
first, I should say my thesis for today is

00:02:00,920 --> 00:02:04,260
that if you can write a for loop, you can do statistics.

00:02:04,260 --> 00:02:06,890
And I want to come back to that later.

00:02:06,890 --> 00:02:09,609
But what statistics really comes down to

00:02:09,609 --> 00:02:12,540
is asking the right question about your data.

00:02:12,540 --> 00:02:15,249
And when I work with students or I work with other folks

00:02:15,249 --> 00:02:19,900
who are trying to learn how to apply statistics well,

00:02:19,900 --> 00:02:22,120
it comes down to this, to asking this right question.

00:02:22,120 --> 00:02:26,600
I came across this excellent Dr. Seuss quote a little while ago.

00:02:26,600 --> 00:02:30,969
He said, "Sometimes the questions are complicated and the answers are simple."

00:02:30,969 --> 00:02:34,689
And I think this encapsulates the field of statistics.

00:02:34,689 --> 00:02:39,150
The hard part is asking the questions correctly.

00:02:39,150 --> 00:02:42,510
And once you've figured out how to ask those questions well,

00:02:42,510 --> 00:02:47,370
the answers sort of come on on their own.

00:02:47,370 --> 00:02:54,400
So, as with any statistics talk or lecture or course,

00:02:54,400 --> 00:02:56,799
we always like to start with a warmup.

00:02:56,799 --> 00:02:59,719
And the warmup usually involves flipping a coin because it's something

00:02:59,719 --> 00:03:01,260
that we can all wrap our minds around.

00:03:01,260 --> 00:03:03,769
So let's think about flipping a coin.

00:03:03,769 --> 00:03:09,779
Let's say you toss a coin 30 times and you see that it lands heads 22 times.

00:03:09,779 --> 00:03:13,559
And the question you want to answer is, "Is this a fair coin?"

00:03:13,559 --> 00:03:16,200
And now you could have an argument about this.

00:03:16,200 --> 00:03:20,319
You might say, you know, a fair coin should show 15 or so heads

00:03:20,319 --> 00:03:22,319
so this coin is probably not fair, right?

00:03:22,319 --> 00:03:25,540
But then your friend comes along and says, "Ah, but even a fair coin

00:03:25,540 --> 00:03:27,959
"could show 22 heads every once in a while."

00:03:27,959 --> 00:03:32,290
So how do you answer this question?

00:03:32,290 --> 00:03:33,870
This person on the left saying

00:03:33,870 --> 00:03:38,299
the fair coin should show 15 heads, we’ll call them the advocate

00:03:38,299 --> 00:03:42,299
and on the right, this person saying, it could be a fair coin

00:03:42,299 --> 00:03:45,489
and just show this by accident, we’ll call them the skeptic.

00:03:45,489 --> 00:03:53,559
And basically the way we proceed here in statistics is to assume,

00:03:53,559 --> 00:03:56,159
in this sort of test, assume the skeptic is correct.

00:03:56,159 --> 00:03:59,790
We’re going to test what's called the null hypothesis.

00:03:59,790 --> 00:04:01,709
And we'll ask, "What is the probability

00:04:01,709 --> 00:04:06,430
"of a fair coin showing 22 heads just by chance?"

00:04:06,430 --> 00:04:10,409
And so going back to your undergrad or your high school days,

00:04:10,409 --> 00:04:15,969
you probably learned about, you know, the probability of a coin toss is 50%

00:04:15,969 --> 00:04:21,949
and the probability of two heads in a row would be 50% squared so you square ½.

00:04:21,949 --> 00:04:28,789
The probability of two heads followed by a tail would be 50% to the 3, 50% cubed.

00:04:28,789 --> 00:04:32,160
But then if you're talking about, like, two heads and a tail in any order,

00:04:32,160 --> 00:04:36,440
you have to multiply that by the number of possibilities, the number of arrangements.

00:04:36,440 --> 00:04:41,310
And then eventually from this simple thought process,

00:04:41,310 --> 00:04:43,889
you end up with a formula that looks something like this.

00:04:43,889 --> 00:04:48,650
It’s the number of arrangements of your heads and tails times

00:04:48,650 --> 00:04:52,290
the probability of heads to the n times probability of tails to the n, right?

00:04:52,290 --> 00:04:56,379
And this, this is a nice thing; this is called the binomial distribution.

00:04:56,379 --> 00:05:01,330
And if you plot it out, you see that this gives you a plot

00:05:01,330 --> 00:05:05,139
of the number of heads you can get as --

00:05:05,139 --> 00:05:10,349
it's a histogram of the number of heads you get in 20 tosses, or in 30 tosses.

00:05:10,349 --> 00:05:13,560
And what we can look at here is, where are 22 hits--

00:05:13,560 --> 00:05:17,240
right there-- and ask, "What percentage

00:05:17,240 --> 00:05:21,520
"of these tosses would be that big or bigger?"

00:05:21,520 --> 00:05:26,259
And we get here for the binomial distribution that it’s .8%, right?

00:05:26,259 --> 00:05:27,780
And this, actually, if you've heard of

00:05:27,780 --> 00:05:30,479
these p-value things, this is actually a p-value.

00:05:30,479 --> 00:05:34,530
We have a p of .008 for the data that we’ve looked at.

00:05:34,530 --> 00:05:38,770
That says that, assuming the null hypothesis is true,

00:05:38,770 --> 00:05:41,680
assuming there's no effects that we’re interested in,

00:05:41,680 --> 00:05:46,479
the probability of getting our data just by chance is .8%.

00:05:46,479 --> 00:05:50,120
And we can say, "This is less than .05 which is the arbitrary bound

00:05:50,120 --> 00:05:53,250
"that someone long ago decided was the right bound to set."

00:05:53,250 --> 00:05:57,610
And therefore our coin is not a fair coin.

00:05:57,610 --> 00:06:01,990
Now this is nice and this works for a lot of people.

00:06:01,990 --> 00:06:06,250
But I find that many people who think in code,

00:06:06,250 --> 00:06:08,569
who think about the world procedurally

00:06:08,569 --> 00:06:12,949
from the standpoint of writing Python code,

00:06:12,949 --> 00:06:15,009
there are other approaches that might be more helpful.

00:06:15,009 --> 00:06:19,280
So for example, why deal with all that binomial distribution thing

00:06:19,280 --> 00:06:20,860
when you can just simulate it, right?

00:06:20,860 --> 00:06:26,719
We can do a loop of 100,000 -- we can do a loop of 100,000 repetitions.

00:06:26,719 --> 00:06:30,190
We can draw in a random integer, 0 or 1.

00:06:30,190 --> 00:06:32,199
We can ask what the sum is,

00:06:32,199 --> 00:06:35,680
and if it's greater than or equal to 22, we add 1 to the result.

00:06:35,680 --> 00:06:42,360
And we find that .8% of the time, .008,

00:06:42,360 --> 00:06:45,790
we get this result of 22 heads or more, right?

00:06:45,790 --> 00:06:48,879
So we've just done in five lines of Python code

00:06:48,879 --> 00:06:52,849
what we did previously in a few slides of mathematics.

00:06:52,849 --> 00:06:58,689
And the point I want to make here is that you all have a way

00:06:58,689 --> 00:07:02,190
of looking at the world as hackers, right?

00:07:02,190 --> 00:07:05,009
And you can express some of these statistical ideas

00:07:05,009 --> 00:07:08,759
in this language that makes intuitive sense to you.

00:07:08,759 --> 00:07:10,409
The other way works well, right?

00:07:10,409 --> 00:07:11,539
The other way works as well.

00:07:11,539 --> 00:07:13,949
But for many people who think about the world in code,

00:07:13,949 --> 00:07:17,620
I think this is a really good way to solve this problem.

00:07:17,620 --> 00:07:21,600
All right, so in general, computing the sampling distribution --

00:07:21,610 --> 00:07:26,150
that's this binomial curve that I showed you -- is a difficult thing to do.

00:07:26,150 --> 00:07:31,460
But also in general, simulating the sampling distribution can be very easy.

00:07:31,460 --> 00:07:35,340
So what I want to do today is I want to show you a few recipes

00:07:35,340 --> 00:07:38,280
for doing this sort of simulation of the sampling distribution

00:07:38,280 --> 00:07:41,060
so you can answer statistical questions

00:07:41,060 --> 00:07:44,990
appealing to the types of coding intuition that you have.

00:07:44,990 --> 00:07:47,530
So this first one, direct stimulation, we just saw.

00:07:47,530 --> 00:07:51,570
That works well when you have some a priori model of the world,

00:07:51,570 --> 00:07:53,889
like you know that a coin toss is going to

00:07:53,889 --> 00:07:57,120
land 50% of the time and you can simulate that.

00:07:57,120 --> 00:08:00,599
But even in cases, as we’ll see, even in cases where you can't get

00:08:00,599 --> 00:08:04,129
an a priori estimate of what the outcome will be,

00:08:04,129 --> 00:08:07,240
we can still do some sampling approaches.

00:08:07,240 --> 00:08:10,240
So the next one I want to talk to you about is shuffling.

00:08:10,240 --> 00:08:14,560
And sticking with the Dr. Seuss theme -- I don't know -- does anyone know

00:08:14,560 --> 00:08:16,210
who these guys are right here?

00:08:16,210 --> 00:08:20,069
These are the -- one of my favorite Dr. Seuss stories, The Sneetches.

00:08:20,069 --> 00:08:23,110
So the Sneetches were this group of creatures

00:08:23,110 --> 00:08:28,270
and half of them or so had stars on their bellies and the other half didn't.

00:08:28,270 --> 00:08:31,600
And, you know, over time, those with stars on their belly

00:08:31,600 --> 00:08:33,570
started to think they were pretty special

00:08:33,570 --> 00:08:38,060
and lorded it over the rest of those Sneetches without stars upon thars, right?

00:08:38,060 --> 00:08:42,130
So let's say you are a researcher and you want to go in and answer

00:08:42,130 --> 00:08:45,540
whether the Star-Belly Sneetches really are better than

00:08:45,540 --> 00:08:48,250
those without stars upon thars.

00:08:48,250 --> 00:08:51,370
You might go in and administer some sort of test, right?

00:08:51,370 --> 00:08:53,020
So here's a distribution of test scores

00:08:53,020 --> 00:08:56,170
you give to the Sneetches out of 100 points.

00:08:56,170 --> 00:08:58,390
And the Sneetches with stars have a certain number;

00:08:58,390 --> 00:09:00,190
without stars have a certain number.

00:09:00,190 --> 00:09:02,960
You compute the means of those and you find that the Star-Bellied Sneetches

00:09:02,960 --> 00:09:11,360
have a 73.5% average and the non-star Sneetches have a 66.9 average.

00:09:11,360 --> 00:09:13,830
So, obviously, 73 is higher than 66.

00:09:13,830 --> 00:09:17,450
But the question you should be asking is, "Is this significant?"

00:09:17,450 --> 00:09:20,700
Could it just happen by chance, right?

00:09:20,700 --> 00:09:23,580
And I want to say this section I’m going through here is drawn

00:09:23,580 --> 00:09:25,640
from an excellent talk by John Rauser

00:09:25,640 --> 00:09:29,310
that he gave a couple years ago at an O’Reilly conference.

00:09:29,310 --> 00:09:32,910
He didn't do the Sneetches but he did something very similar.

00:09:32,910 --> 00:09:35,090
So is this significant?

00:09:35,090 --> 00:09:37,150
And you can do this the classical way.

00:09:37,150 --> 00:09:40,690
If you go back to your Stats 101 and kind of read the table of contents,

00:09:40,690 --> 00:09:43,430
you’ll remember that there's this thing called a t-test.

00:09:43,430 --> 00:09:45,720
And what you do is you subtract the means

00:09:45,720 --> 00:09:49,140
and then you divide by some weighted sum of the standard deviations.

00:09:49,140 --> 00:09:53,180
So we can do that; we can plug in our numbers and we get .93, right?

00:09:53,180 --> 00:09:55,880
All right, so what does this mean?

00:09:55,880 --> 00:09:58,850
You know, you go read a little further in your Stats 101 text

00:09:58,850 --> 00:10:02,970
and you see that this t-statistic should be distributed this way, right?

00:10:02,970 --> 00:10:06,710
And that upside-down L-shape there is a gamma function

00:10:06,710 --> 00:10:08,400
and the little V-shaped thing,

00:10:08,400 --> 00:10:11,990
that's a Greek letter nu, which means degrees of freedom.

00:10:11,990 --> 00:10:14,000
And you scratch your head

00:10:14,000 --> 00:10:16,200
and you try to remember what degrees of freedom are.

00:10:16,210 --> 00:10:20,230
And you go to Wikipedia and it says, "The number of independent ways by which

00:10:20,230 --> 00:10:24,690
"a dynamic system can move without violating any constraint imposed on it."

00:10:24,690 --> 00:10:26,370
And you're like OK, um…

00:10:26,370 --> 00:10:27,840
[laughter]

00:10:27,840 --> 00:10:31,520
So but then you dig a little further and down the Wikipedia page they say

00:10:31,530 --> 00:10:37,410
that this Welch-Satterthwaite’s equation can, you know, can get you there.

00:10:37,410 --> 00:10:41,560
So, you know, you know how to plug numbers into a formula and you get 10.7.

00:10:41,560 --> 00:10:43,400
So that's your degrees of freedom.

00:10:43,400 --> 00:10:48,100
And then you go to a chart like this and you look up 11ish degrees of freedom

00:10:48,100 --> 00:10:52,710
for a .05 and you find that the t-statistic is 1.79

00:10:52,710 --> 00:10:55,220
and you have to ask if your t-value is greater than that.

00:10:55,220 --> 00:10:59,180
And remember we computed a t-value way back; it was like .9, right?

00:10:59,180 --> 00:11:00,930
And this is not true.

00:11:00,930 --> 00:11:03,413
So the difference -- it would be 6.6 --

00:11:03,413 --> 00:11:07,420
is not significant at the p equals .05 level, right?

00:11:07,420 --> 00:11:08,420
Excellent.

00:11:08,420 --> 00:11:10,940
And you sit back and you’re like, I did it.

00:11:10,940 --> 00:11:13,180
[laughter]

00:11:13,180 --> 00:11:15,340
But -- so the problem here

00:11:15,350 --> 00:11:19,470
is we’ve entirely lost track of what question we’re answering, right?

00:11:19,470 --> 00:11:23,000
I know there are probably a few statisticians in this room

00:11:23,000 --> 00:11:28,370
for whom that logic makes sense and helps you understand the problem;

00:11:28,370 --> 00:11:29,370
I’m not one of them.

00:11:29,370 --> 00:11:32,380
I don't know -- you may not be one of them either.

00:11:32,380 --> 00:11:36,600
So what we can do -- some people would say, well,

00:11:36,600 --> 00:11:39,520
why are you going through all that mumbo jumbo when you can just do this?

00:11:39,520 --> 00:11:44,120
You just import t-test in from statsmodels and plug in the right, you know,

00:11:44,120 --> 00:11:49,200
form of the variance and the right form of everything else.

00:11:49,210 --> 00:11:50,950
And, you know, you get out a p-value.

00:11:50,950 --> 00:11:56,350
But again, this might be the right level of abstraction for some people.

00:11:56,350 --> 00:11:59,030
It's not the right level of abstraction for me.

00:11:59,030 --> 00:12:00,720
And I’d guess for a lot of folks in this room,

00:12:00,720 --> 00:12:03,430
this is not a helpful level of abstraction

00:12:03,430 --> 00:12:08,160
for writing the question cause the problem is, what question is this answering?

00:12:08,160 --> 00:12:11,730
If you're four years into a statistics degree, you might be able

00:12:11,730 --> 00:12:16,090
to answer that off the tip of your tongue, but I certainly can't right now.

00:12:16,090 --> 00:12:18,970
So stepping back, we go back to this.

00:12:18,970 --> 00:12:21,780
This is the real key of this problem,

00:12:21,780 --> 00:12:25,380
this sampling distribution, this student's t-distribution.

00:12:25,380 --> 00:12:28,770
And it's very similar to what we did before with the binomial distribution

00:12:28,770 --> 00:12:34,390
where we’re asking, how often do we get 22 heads with a fair coin?

00:12:34,390 --> 00:12:36,870
Here what we're doing is we're drawing a different type of distribution

00:12:36,870 --> 00:12:41,060
and we're asking for the cutoff and trying to integrate everything above the cutoff.

00:12:41,060 --> 00:12:43,730
So why don't we use a sampling method instead,

00:12:43,730 --> 00:12:47,140
something that you and I can wrap our minds around?

00:12:47,140 --> 00:12:50,370
Well the problem is, unlike coin flipping, we don't have a theoretical model.

00:12:50,370 --> 00:12:52,850
We can't simulate a Sneetch, right?

00:12:52,850 --> 00:12:54,370
All we have are these test scores.

00:12:54,370 --> 00:12:59,830
So we need some way for those test scores to be the simulation themselves.

00:12:59,830 --> 00:13:03,360
And what we can do in this situation is something called shuffling.

00:13:03,360 --> 00:13:07,310
So the idea here with the shuffling is that we're going to simulate

00:13:07,310 --> 00:13:12,620
the distribution of possible test scores by shuffling these labels around.

00:13:12,620 --> 00:13:15,990
And the motivation is that, in the null hypothesis,

00:13:15,990 --> 00:13:20,110
if Star-Bellied Sneetches and regular Sneetches are really the same,

00:13:20,110 --> 00:13:23,240
it shouldn't matter what the labels of these numbers are.

00:13:23,240 --> 00:13:25,700
So we can label them however we want.

00:13:25,700 --> 00:13:26,980
So this is what we do.

00:13:26,980 --> 00:13:28,300
We first -- we shuffle the labels.

00:13:28,300 --> 00:13:29,660
We've kept the numbers in the same place

00:13:29,660 --> 00:13:33,130
and just shuffled around the red and green squares.

00:13:33,130 --> 00:13:37,370
We rearrange them, take the mean and the difference.

00:13:37,370 --> 00:13:39,030
And we can plot it on our little graph there.

00:13:39,030 --> 00:13:42,060
We got a difference of 4.8.

00:13:42,060 --> 00:13:45,370
Then we do it again; we shuffle the samples, we rearrange, and we plot a mean.

00:13:45,370 --> 00:13:49,860
We shuffle the samples, we rearrange; we plot the means, shuffle the samples.

00:13:49,860 --> 00:13:51,600
And in this way, we can build up

00:13:51,600 --> 00:13:57,690
this sort of sampled proxy to the real sampling distribution.

00:13:57,690 --> 00:14:02,750
And we get an idea there of, in a very intuitive manner,

00:14:02,750 --> 00:14:07,220
of what we can expect these differences and test scores to be.

00:14:07,220 --> 00:14:11,990
And of course we draw the line where our measured data lies, at around 6,

00:14:11,990 --> 00:14:13,680
and we compute that something like

00:14:13,680 --> 00:14:18,870
16% of samples show a score difference greater than 6.

00:14:18,870 --> 00:14:23,140
So if you're keeping track, this .16 is not less than .05, right?

00:14:23,140 --> 00:14:29,310
So in the classical statistical sense of looking for p of .05,

00:14:29,310 --> 00:14:31,350
we're going to say that this is not significant.

00:14:31,350 --> 00:14:33,910
So you go in and you perform this study.

00:14:33,910 --> 00:14:37,190
And there's hugs all around; all the Sneetches are reunited

00:14:37,190 --> 00:14:44,280
with their long-lost brothers and sisters and you've done your good in the world.

00:14:44,280 --> 00:14:47,520
But so the key is that this shuffling approach works

00:14:47,520 --> 00:14:52,440
when the null hypothesis assumes that the two groups are entirely equivalent.

00:14:52,440 --> 00:14:55,440
So I’m sure you can imagine situations where this comes up.

00:14:55,440 --> 00:15:01,060
The classical thing is testing whether a drug works or doesn't, you know?

00:15:01,060 --> 00:15:04,090
You look at the drug's effects, you look at the placebo effects,

00:15:04,090 --> 00:15:08,420
and you can do these shuffling things to figure out whether the drug is effective.

00:15:08,420 --> 00:15:12,050
I should say a little caveat; like all methods, this is only going to work

00:15:12,050 --> 00:15:14,320
if your samples are representative, you know?

00:15:14,320 --> 00:15:16,420
If you have a data-gathering problem,

00:15:16,420 --> 00:15:18,200
that's something completely different.

00:15:18,200 --> 00:15:21,250
And you also need care for independent trials,

00:15:21,250 --> 00:15:24,140
like if you're -- let's say you're measuring

00:15:24,140 --> 00:15:28,650
the different test scores of the same Sneetch over and over.

00:15:28,650 --> 00:15:31,340
You might expect them to improve with time.

00:15:31,340 --> 00:15:35,290
So there's sort of a dependence there of the data on previous data.

00:15:35,290 --> 00:15:39,320
And in that case, you have to be a little more careful with shuffling.

00:15:39,320 --> 00:15:40,760
If you want to read more about this,

00:15:40,760 --> 00:15:44,770
there’s this Simon's Resampling: The New Statistics.

00:15:44,770 --> 00:15:46,970
It's a book that you can go and look into

00:15:46,970 --> 00:15:50,760
that kind of goes into this in a little more detail.

00:15:50,760 --> 00:15:54,820
But anyway, so shuffling is a nice way to use this sampling approach

00:15:54,820 --> 00:16:00,380
when you don't actually have an a priori model of the data that you're looking at.

00:16:00,380 --> 00:16:05,120
Another very similar approach is something known as bootstrapping.

00:16:05,120 --> 00:16:06,850
And that's what I’m going to talk about next.

00:16:06,850 --> 00:16:09,710
So if you remember your Dr. Seuss,

00:16:09,710 --> 00:16:13,620
there was just this king of the turtle pond named Yertle.

00:16:13,620 --> 00:16:14,660
And Yertle the Turtle wanted

00:16:14,660 --> 00:16:18,070
to be the most powerful, tallest, richest turtle in the world.

00:16:18,070 --> 00:16:24,000
So he decided to get on the back of his fellow turtles and make them stack higher

00:16:24,000 --> 00:16:27,730
and higher and stand on the back so he could be the tallest turtle in the world.

00:16:27,730 --> 00:16:32,570
Now you as a turtle researcher go out to this pond.

00:16:32,570 --> 00:16:35,540
And you're observing these every day and you see that Yertle has

00:16:35,540 --> 00:16:39,460
a distribution of turtle heights that he gets to each day.

00:16:39,460 --> 00:16:43,910
And you want to know in the long run, if you were to observe Yertle for an infinite

00:16:43,910 --> 00:16:50,020
amount of time, what would be the average height of turtles that he gets to?

00:16:50,020 --> 00:16:52,000
And what would be the spread of that, you know?

00:16:52,000 --> 00:16:57,960
How can you characterize this distribution of Yertle’s turtle heights?

00:16:57,960 --> 00:17:02,340
And so one way we can address this is to use the classic method,

00:17:02,340 --> 00:17:04,511
which is to compute the sample mean,

00:17:04,511 --> 00:17:06,420
and you've probably seen things like this before.

00:17:06,420 --> 00:17:10,280
You can compute the standard error of the mean and you get some numbers

00:17:10,280 --> 00:17:14,329
and you find that it's 28.9 plus or minus 3.

00:17:14,329 --> 00:17:19,620
And again, this works and is fairly intuitive for many people.

00:17:19,620 --> 00:17:25,050
But I imagine it's probably not intuitive for a lot of folks in this room.

00:17:25,050 --> 00:17:27,740
In particular, you may not know what assumptions

00:17:27,740 --> 00:17:30,780
go into these formula that you're using.

00:17:30,780 --> 00:17:33,930
And you might wonder, can we use some sort of sampling approach instead

00:17:33,930 --> 00:17:37,000
where we can wrap our mind around what's going on?

00:17:37,000 --> 00:17:39,930
And like before, we don't have a generating model.

00:17:39,930 --> 00:17:42,390
And unlike before, we're not comparing two different groups

00:17:42,390 --> 00:17:45,190
so we can't just do the shuffling approach.

00:17:45,190 --> 00:17:49,160
But there is this interesting solution called bootstrap resampling.

00:17:49,160 --> 00:17:52,780
And what bootstrap resampling is is you take this data

00:17:52,780 --> 00:17:58,070
and you basically treat the data as a measurement of its own distribution.

00:17:58,070 --> 00:18:02,060
And what that looks like in practice is you sample from this data set

00:18:02,060 --> 00:18:05,810
with replacement to generate new samples.

00:18:05,810 --> 00:18:09,280
So we're going to draw random numbers from this data set.

00:18:09,280 --> 00:18:11,480
And you'll see already that there are some repeats.

00:18:11,480 --> 00:18:13,790
We've hit 41 twice, right?

00:18:13,790 --> 00:18:16,580
That's what you want to happen in bootstrap resampling.

00:18:16,580 --> 00:18:19,710
You’re resampling with replacement.

00:18:19,710 --> 00:18:22,980
And you continue on and you get some other repeats in there.

00:18:22,980 --> 00:18:27,270
And you end up with a subsample or a resampled version

00:18:27,270 --> 00:18:31,180
of your data that has a mean of 31.05.

00:18:31,180 --> 00:18:34,240
All right, so we can repeat this several thousand times

00:18:34,240 --> 00:18:37,150
and we end up with the distribution of these mean values.

00:18:37,150 --> 00:18:42,510
And it turns out that almost magically, this distribution is very close

00:18:42,510 --> 00:18:46,650
to the analytic result that we computed earlier.

00:18:46,650 --> 00:18:48,490
And we can do this as a simple for loop, right?

00:18:48,490 --> 00:18:54,140
We go for i in range 10,000, we pick 20 random points from the sample.

00:18:54,140 --> 00:18:57,270
This is a way to do it using the NumPy package.

00:18:57,270 --> 00:19:01,720
And we can say that the mean is -- the ith mean is the mean of the sample.

00:19:01,720 --> 00:19:03,500
And then we look at the mean of all the means

00:19:03,500 --> 00:19:05,150
and the standard deviation of all the means

00:19:05,150 --> 00:19:08,950
and we find something that describes our data.

00:19:08,950 --> 00:19:13,110
Now this is a little bit simplistic but the nice thing about bootstrapping

00:19:13,110 --> 00:19:16,180
is you can apply it to even more complicated statistics.

00:19:16,180 --> 00:19:18,530
Like let's say we go out and we measure

00:19:18,530 --> 00:19:23,370
not only the height of Yertle’s towers but we also measure the wind speed.

00:19:23,370 --> 00:19:31,510
And we want to know how the wind speed relates to the tower height.

00:19:31,510 --> 00:19:35,600
And we can plot this line on the data and we can measure the slope and intercept.

00:19:35,600 --> 00:19:38,030
And it turns out if you do the bootstrap resampling here

00:19:38,030 --> 00:19:42,600
and you compute the slope and intercept on the resample data,

00:19:42,600 --> 00:19:49,650
you get a nice estimate of what that confidence interval might be.

00:19:49,650 --> 00:19:54,680
So this gives us a general idea of what range of slopes and intercepts

00:19:54,680 --> 00:19:59,180
we can expect from the small sample that we looked at.

00:19:59,180 --> 00:20:03,400
And the cool thing about bootstrapping is that it's actually really, really

00:20:03,400 --> 00:20:06,550
well studied in the statistics community.

00:20:06,550 --> 00:20:07,680
You know, I don’t want to give the impression

00:20:07,680 --> 00:20:12,300
that I’m giving you, like, these recipes that statisticians don't know about.

00:20:12,300 --> 00:20:14,410
They know about all of this stuff.

00:20:14,410 --> 00:20:16,900
And bootstrapping in particular is something that's been studied

00:20:16,900 --> 00:20:20,560
for a long, long time within the statistics community.

00:20:20,560 --> 00:20:24,500
There are a couple caveats to it that you can read in other places.

00:20:24,500 --> 00:20:28,320
For example, it doesn't work very well for rank-based statistics.

00:20:28,320 --> 00:20:31,520
Like if you do the bootstrap of the maximum value,

00:20:31,520 --> 00:20:34,030
it's not going to give you very good results.

00:20:34,030 --> 00:20:36,470
It works poorly if you have very few samples.

00:20:36,470 --> 00:20:40,330
And there are rules of thumb that you can read about in different books

00:20:40,330 --> 00:20:42,130
about how to apply this

00:20:42,130 --> 00:20:44,770
if you're going to really dig into this stuff.

00:20:44,770 --> 00:20:47,340
And as with the other stuff, as the previous ones,

00:20:47,340 --> 00:20:49,060
I want to warn you to be careful

00:20:49,060 --> 00:20:54,100
about selection of biases in your data and non-independent data and things like this.

00:20:54,100 --> 00:20:55,950
You have to think about it a little bit.

00:20:55,950 --> 00:21:01,770
But the point is that you have this procedure whereby you can reason through

00:21:01,770 --> 00:21:03,660
what you're doing to your data

00:21:03,660 --> 00:21:06,280
and wrap your mind around what the answer is saying.

00:21:06,280 --> 00:21:12,860
And you can keep the question in mind the whole time that you're writing code.

00:21:12,860 --> 00:21:18,380
Now the last recipe for hacking statistics that I really like is cross-validation.

00:21:18,380 --> 00:21:22,520
And this is something, if any of you have been working in machine learning,

00:21:22,520 --> 00:21:25,370
you'll be familiar with cross-validation.

00:21:25,370 --> 00:21:31,010
Basically, cross-validation is a way to determine how well a model is fitting data

00:21:31,010 --> 00:21:34,800
when you don't have some a priori description of the data.

00:21:34,800 --> 00:21:37,570
And statisticians have worked long and hard

00:21:37,570 --> 00:21:41,940
to learn how well a line fits data, right?

00:21:41,940 --> 00:21:43,480
And lines are relatively simple.

00:21:43,480 --> 00:21:47,460
And you can even bring that along to even more complicated models.

00:21:47,460 --> 00:21:53,140
But when you start talking about something like a neural net with 16 hidden layers,

00:21:53,140 --> 00:21:54,830
there's no statistician in the world

00:21:54,830 --> 00:22:00,720
that can write out the analytic statistics of how that model fits the data.

00:22:00,720 --> 00:22:04,860
I know someone's gonna raise their hand and say, "But I did that."

00:22:04,860 --> 00:22:07,659
If you've done that, tell me; I'd be interested to hear about it.

00:22:07,659 --> 00:22:09,240
So cross-validation is interesting.

00:22:09,240 --> 00:22:12,300
And I don't know if any of you have read The Lorax.

00:22:12,300 --> 00:22:16,150
The book is way better than the movie, by the way.

00:22:16,150 --> 00:22:19,970
You know, The Lorax is about this faceless beast

00:22:19,970 --> 00:22:24,370
who goes out into the Truffula tree forest and starts making Thneeds.

00:22:24,370 --> 00:22:28,630
And Thneeds are, of course, fine somethings that all people need.

00:22:28,630 --> 00:22:30,100
And the Lorax gets rather angry.

00:22:30,100 --> 00:22:35,550
But let's say you are a data scientist who’s hired by Onceler Industries.

00:22:35,550 --> 00:22:38,970
And Onceler Industries wants you to project Thneed sales

00:22:38,970 --> 00:22:43,230
so that you can help them more efficiently do their business

00:22:43,230 --> 00:22:46,670
and hack the Truffula tree forest to bits.

00:22:46,670 --> 00:22:48,940
And you notice combing through their data that there seems

00:22:48,940 --> 00:22:53,640
to be this relationship between temperature and Thneed sales, right?

00:22:53,640 --> 00:22:55,270
And now that's an interesting relationship.

00:22:55,270 --> 00:22:58,390
And you'd like to predict based on the temperature

00:22:58,390 --> 00:23:02,440
what you think the Thneed sales are going to be for any given day, right?

00:23:02,440 --> 00:23:06,050
So the question is, what model better fits the data?

00:23:06,050 --> 00:23:09,200
You might have a linear model, this blue line, or you might have

00:23:09,200 --> 00:23:11,760
a quadratic model, this red line.

00:23:11,760 --> 00:23:15,530
And both of those by eye sort of seem plausible.

00:23:15,530 --> 00:23:21,140
But how do you choose which is the better model for actually fitting your data?

00:23:21,140 --> 00:23:24,270
And you might think, I’ll just measure how close

00:23:24,270 --> 00:23:26,380
the points are to each of those models, right?

00:23:26,380 --> 00:23:30,550
You compute the root mean square error about the model and you find

00:23:30,550 --> 00:23:34,270
that for the blue points it’s 63 and for the red points it’s 51.

00:23:34,270 --> 00:23:37,160
But this is something you have to be careful about.

00:23:37,160 --> 00:23:38,920
The red model is more complicated.

00:23:38,920 --> 00:23:43,850
And a more complicated model will nearly always fit the data better, right?

00:23:43,850 --> 00:23:46,100
If we start doing -- instead of a linear model

00:23:46,100 --> 00:23:51,440
or a quadratic model, if we do cubic or a quartic or an even higher model,

00:23:51,440 --> 00:23:55,070
as we add more terms to that equation, the RMS error gets better

00:23:55,070 --> 00:23:57,700
and better and better, forever, basically,

00:23:57,700 --> 00:24:00,240
until we have as many terms as we have data points.

00:24:00,240 --> 00:24:02,150
And then you're fitting the data perfectly.

00:24:02,150 --> 00:24:06,260
And these higher-order models actually look pretty silly, right?

00:24:06,260 --> 00:24:10,400
If you were gonna use this blue line here to predict Thneed sales

00:24:10,400 --> 00:24:12,750
and you say that at -- what am I looking at here? --

00:24:12,750 --> 00:24:16,560
at 20 degrees, you have 0 because that's what the model says.

00:24:16,560 --> 00:24:17,800
This is a silly model.

00:24:17,800 --> 00:24:20,580
You don't want to use that one to project your Thneed sales.

00:24:20,580 --> 00:24:23,100
So, you know, statistics has this figured out.

00:24:23,110 --> 00:24:27,460
What we can do with these sorts of models is we can look it up in the book

00:24:27,460 --> 00:24:30,900
and we see that the difference in mean squared errors

00:24:30,900 --> 00:24:33,300
follows a chi-square distribution.

00:24:33,300 --> 00:24:35,260
You can estimate the degrees of freedom

00:24:35,260 --> 00:24:38,840
because these are nested models and you can get these degrees of freedom.

00:24:38,840 --> 00:24:40,540
And you start plugging in your numbers

00:24:40,540 --> 00:24:43,440
and pretty soon you're in the same situation as before.

00:24:43,440 --> 00:24:48,460
You're thinking, what question were we trying to answer?

00:24:48,460 --> 00:24:53,760
And one way I find that I can keep my eye on that question a little more

00:24:53,760 --> 00:24:56,990
is by doing this cross-validation approach.

00:24:56,990 --> 00:25:01,679
So what we do in cross validation is we take the data set

00:25:01,679 --> 00:25:08,270
and we essentially split it randomly and separate those two parts.

00:25:08,270 --> 00:25:14,930
And then for each of those sections of the data, we fit our best model.

00:25:14,930 --> 00:25:20,340
And once we have those best model fits, we then flip-flop the data and we ask,

00:25:20,340 --> 00:25:23,300
"How well does the red model fit the blue data

00:25:23,300 --> 00:25:26,900
"and how well does the blue model fit the red data?"

00:25:26,900 --> 00:25:29,780
And this will protect against what's known as overfitting, right?

00:25:29,780 --> 00:25:33,690
If we have a model that's really drawn to that top left point

00:25:33,690 --> 00:25:37,170
and really highly influenced by that top left point,

00:25:37,170 --> 00:25:42,470
then testing the model on a data set that doesn't include that top left point

00:25:42,470 --> 00:25:48,640
is a better and more robust way to see how well the model is doing.

00:25:48,640 --> 00:25:50,660
All right, so then once we've done that,

00:25:50,660 --> 00:25:54,660
we can compute the RMS error for each model.

00:25:54,660 --> 00:25:58,620
And we repeat this for as long as we have patience to repeat.

00:25:58,630 --> 00:26:02,059
Fortunately you can write a for loop and you can do this as many times

00:26:02,059 --> 00:26:04,530
as you want in basically a split second.

00:26:04,530 --> 00:26:07,590
And then we can compare this cross-validated root mean square.

00:26:07,590 --> 00:26:10,350
So here this blue curve is what we saw before.

00:26:10,350 --> 00:26:12,809
As we make the model more complex,

00:26:12,809 --> 00:26:15,950
it just fits the data better and better and better.

00:26:15,950 --> 00:26:17,880
But the red curve is a cross-validated error

00:26:17,880 --> 00:26:21,340
where we’re controlling for this overfitting phenomenon.

00:26:21,340 --> 00:26:24,950
And as we make the model more complex, it hits a minimum

00:26:24,950 --> 00:26:27,850
where it fits the data well

00:26:27,850 --> 00:26:31,150
and then we go on and on and we're basically to the point

00:26:31,150 --> 00:26:33,870
where the model is influenced

00:26:33,870 --> 00:26:37,160
by the noise in the data more than the data itself.

00:26:37,160 --> 00:26:40,400
So doing that, we can fit this second-order model to our data

00:26:40,400 --> 00:26:46,370
and we can be sure that we have a solid model for the data that we're looking at,

00:26:46,370 --> 00:26:49,750
so one that minimizes the cross-validated error.

00:26:49,750 --> 00:26:55,410
And then, of course, we've done our job and now Onceler Industries can go on

00:26:55,410 --> 00:26:57,840
and take over the world and ship their Thneeds

00:26:57,840 --> 00:27:01,450
to the southeast and the west and the north.

00:27:01,450 --> 00:27:04,500
Maybe I should’ve used a different example.

00:27:04,500 --> 00:27:06,250
Anyway, so the cross-validation --

00:27:06,250 --> 00:27:08,679
this was known as a two-fold cross-validation.

00:27:08,679 --> 00:27:12,270
It's because we split the data set into two folds

00:27:12,270 --> 00:27:15,290
and then we fit across each of those.

00:27:15,290 --> 00:27:16,940
There's also different ones.

00:27:16,940 --> 00:27:20,140
There’s things like k-fold cross-validation where you take --

00:27:20,140 --> 00:27:24,620
you split the data into k different sets and you fit on the first -- let's say

00:27:24,620 --> 00:27:28,910
you split it into 10 sets and you fit on 9 and then test with 1.

00:27:28,910 --> 00:27:32,450
And then you shuffle them again and fit on 9 and test with 1.

00:27:32,450 --> 00:27:36,130
There are other cross-validation routines we can use.

00:27:36,130 --> 00:27:39,560
And if you look in the scikit-learn package documentation

00:27:39,560 --> 00:27:42,060
there's a pretty good description of how to use those

00:27:42,060 --> 00:27:45,560
and why you might use one over another.

00:27:45,560 --> 00:27:46,860
I mentioned this before,

00:27:46,860 --> 00:27:50,440
but cross-validation is really the go-to method for machine learning.

00:27:50,440 --> 00:27:55,240
And this is because often in machine learning, we're working with models

00:27:55,240 --> 00:28:00,440
that you can't really do the analytic statistical distribution of the results.

00:28:00,440 --> 00:28:01,870
It's not like fitting a line to data

00:28:01,870 --> 00:28:05,120
where you can write down the sampling distribution.

00:28:05,120 --> 00:28:10,850
If you're doing something like a random forest or a neural net,

00:28:10,850 --> 00:28:15,799
it's not something that you can compute analytically very easily.

00:28:15,799 --> 00:28:18,429
And then again, I want to put in the caveats

00:28:18,429 --> 00:28:22,670
about selection bias and data independence and things like this.

00:28:22,670 --> 00:28:26,730
So these were the four hacking statistics recipes

00:28:26,730 --> 00:28:28,330
that I wanted to present to you guys.

00:28:28,330 --> 00:28:32,100
Number one, the direct simulation.

00:28:32,100 --> 00:28:37,929
This is where you have an a priori model of your data generation process

00:28:37,929 --> 00:28:40,950
and you can actually simulate the whole thing end to end.

00:28:40,950 --> 00:28:44,650
There’s shuffling where you're trying to decide whether one group is different

00:28:44,650 --> 00:28:47,830
than another group and you can shuffle the results to generate

00:28:47,830 --> 00:28:51,840
that sampling distribution or to mimic the sampling distribution.

00:28:51,840 --> 00:28:56,000
You can do bootstrapping, where you're drawing with replacement

00:28:56,000 --> 00:28:59,730
and computing a statistic, computing distribution of those statistics.

00:28:59,730 --> 00:29:03,270
And then cross-validation for comparing models where you don't have

00:29:03,270 --> 00:29:10,560
an a priori statistical way of looking at those model comparisons.

00:29:10,560 --> 00:29:15,210
Now I should just do one aside.

00:29:15,210 --> 00:29:20,309
I think direct simulation out of all these is probably the most appealing one.

00:29:20,309 --> 00:29:23,230
And you'd be surprised how far you can take direct simulation.

00:29:23,230 --> 00:29:26,740
Like for example in astronomy,

00:29:26,740 --> 00:29:30,490
there's this project called the Large Synoptic Survey Telescope.

00:29:30,490 --> 00:29:34,090
And one thing that they're doing with that -- essentially

00:29:34,090 --> 00:29:37,510
this telescope is going to start in a few years and it's going

00:29:37,510 --> 00:29:41,820
to take an image of the entire night sky a couple times a week

00:29:41,820 --> 00:29:45,760
over the course of 10 years and give you huge, huge amounts of data.

00:29:45,760 --> 00:29:47,160
And we as astronomers are going

00:29:47,160 --> 00:29:52,820
to want to ask statistical questions about this data.

00:29:52,820 --> 00:29:57,120
And one thing that the group at University of Washington is doing

00:29:57,120 --> 00:30:01,341
is they're bringing this direct simulation approach almost to its logical end.

00:30:01,341 --> 00:30:07,049
And they’re simulating from the ground up the entire survey, from the photons

00:30:07,049 --> 00:30:10,000
leaving the stars, going through the atmosphere, going through

00:30:10,000 --> 00:30:15,549
the telescope optics, landing on the CCD, displacing an electron, the electron going

00:30:15,549 --> 00:30:21,940
across to the detector, and basically their goal is to be able to apply

00:30:21,940 --> 00:30:28,740
this direct simulation method to something that's extremely, extremely complicated.

00:30:28,740 --> 00:30:30,330
So if you have the computational power,

00:30:30,330 --> 00:30:35,120
you can really do some interesting things with this type of sampling.

00:30:35,120 --> 00:30:39,440
So, anyway, to wrap up, I just want to tell you that sampling methods are --

00:30:39,440 --> 00:30:40,760
I want to leave you with this.

00:30:40,760 --> 00:30:44,820
Sampling methods allow you to use these intuitive computational approaches

00:30:44,820 --> 00:30:49,360
in place of often non-intuitive statistical rules.

00:30:49,360 --> 00:30:51,150
And I do want to hedge a little bit before

00:30:51,150 --> 00:30:54,460
cause I've gotten in trouble for saying things a little too strongly.

00:30:54,460 --> 00:31:00,150
I’m not saying that classical statistics is wrong or that it produces bad results

00:31:00,150 --> 00:31:03,600
or even that it's a bad way to look at the world.

00:31:03,600 --> 00:31:07,120
What I’m saying is that I think for a lot of people in this room,

00:31:07,120 --> 00:31:11,900
the computational approaches will be more intuitive and will allow you to keep

00:31:11,900 --> 00:31:16,600
the question that you're answering in your mind while you're working with your data.

00:31:16,600 --> 00:31:19,740
And that in statistics is the most important thing,

00:31:19,740 --> 00:31:22,620
that you keep this question in your mind, because sometimes

00:31:22,620 --> 00:31:26,780
the questions are complicated and the answers are simple.

00:31:26,780 --> 00:31:29,280
So a couple of things I didn't have time for.

00:31:29,280 --> 00:31:32,030
I actually talked fast 'cause I would have had time for some of these.

00:31:32,030 --> 00:31:38,700
But Bayesian methods are a really interesting way to move forward if --

00:31:38,700 --> 00:31:41,430
there's a lot of sampling that goes on in Bayesian methods.

00:31:41,430 --> 00:31:43,460
So one thing you can look at for this, you might look at

00:31:43,460 --> 00:31:47,010
Bayesian Methods for Hackers by Cam Davidson-Pilon.

00:31:47,010 --> 00:31:49,070
It's a kind of all-online book

00:31:49,070 --> 00:31:52,840
that he wrote several years ago that’s pretty good.

00:31:52,840 --> 00:31:58,110
This idea of selection bias, of, you know, worrying about how your data is gathered

00:31:58,110 --> 00:32:01,700
and whether you're really looking at the data set you think you're looking at,

00:32:01,700 --> 00:32:06,740
there’s a phenomenal talk from last summer by Chris Fonnesbeck, who’s a professor

00:32:06,740 --> 00:32:10,280
out of Nashville, called Statistical Thinking for Data Science.

00:32:10,280 --> 00:32:14,480
You can find that, the video of that talk, online and I’d highly recommend it.

00:32:14,480 --> 00:32:18,690
And then detailed considerations of these sampling, shuffling, and bootstrapping

00:32:18,690 --> 00:32:22,590
approaches, there are a couple books out there that are interesting.

00:32:22,590 --> 00:32:26,700
I’d recommend taking a look at Statistics is Easy by Shasha and Wilson

00:32:26,700 --> 00:32:31,790
and also Resampling: The New Statistics, by Julian Simon.

00:32:31,790 --> 00:32:34,890
And they're excellent ways to dig into a little more of the meat of

00:32:34,890 --> 00:32:40,660
these approaches, because there are some subtleties that you have to worry about.

00:32:40,660 --> 00:32:43,070
OK and with that, I’m finished.

00:32:43,070 --> 00:32:48,410
If you want to look at these slides online, I just tweeted the link.

00:32:48,410 --> 00:32:51,100
And I’m @jakevdp right there.

00:32:51,100 --> 00:32:53,880
So, thanks very much; it was a pleasure to be here.

00:32:53,880 --> 00:32:55,940
And we'll have some questions.

00:32:55,940 --> 00:33:02,020
[applause]

00:33:07,160 --> 00:33:09,080
(moderator) Yeah, we have time for some questions,

00:33:09,080 --> 00:33:12,680
if you could please queue up at the microphones.

00:33:12,680 --> 00:33:17,260
And please remember to keep your questions, a question; thank you.

00:33:25,600 --> 00:33:27,160
(audience member 1) Uh, can I ask now

00:33:27,160 --> 00:33:28,260
or do I have to wait?

00:33:28,260 --> 00:33:29,740
(Jake) Yeah, go ahead.

00:33:29,740 --> 00:33:32,500
(audience member 1) OK, um, sorry.

00:33:32,500 --> 00:33:36,940
So when you're getting sort of a new sample that looks like

00:33:36,940 --> 00:33:42,520
the sample you already have, is there -- is it convenient to use something

00:33:42,520 --> 00:33:46,330
like importance sampling, where you don't need to know the exact distribution

00:33:46,330 --> 00:33:48,950
that the thing is coming from, you have another distribution

00:33:48,950 --> 00:33:51,490
that kind of looks like it and you know how to sort of apply

00:33:51,490 --> 00:33:55,110
a correction factor or like a weighting factor,

00:33:55,110 --> 00:33:59,030
does that ever -- is that useful for making it easier

00:33:59,030 --> 00:34:01,840
to kind of see how well your model’s doing?

00:34:01,840 --> 00:34:03,300
(Jake) Yeah, that's a good question.

00:34:03,300 --> 00:34:05,260
The question was about importance sampling, so you're essentially

00:34:05,270 --> 00:34:10,259
using other information that you have in order to drive the samples.

00:34:10,259 --> 00:34:16,229
And yeah, that can be useful; I think it's a more advanced technique

00:34:16,229 --> 00:34:21,080
and I'd be sure to read up and make sure you're doing it correctly.

00:34:21,080 --> 00:34:25,140
I don't think I have much more to say than that.

00:34:26,300 --> 00:34:29,260
(audience member 2) Thank you for your talk, Jake.

00:34:29,260 --> 00:34:34,060
This is a approach that very much speaks to how I think, I guess.

00:34:34,060 --> 00:34:36,240
And so I’m wondering, when doesn't it work?

00:34:36,240 --> 00:34:39,640
Like, what should I be on the lookout for when this is not gonna -- ?

00:34:39,640 --> 00:34:41,240
(Jake) Yeah, when does this not work?

00:34:41,240 --> 00:34:43,120
So I tried to give some of those caveats in there.

00:34:43,129 --> 00:34:49,750
But especially when you have -- all of this basically assumes independence

00:34:49,750 --> 00:34:53,710
and then identically distributed data, that sort of thing, where I gave

00:34:53,710 --> 00:34:59,509
the example before of, you know, maybe a Sneetch is taking the test

00:34:59,509 --> 00:35:03,560
and they're not passing their notes off to the next Sneetch, right?

00:35:03,560 --> 00:35:08,100
The next data point does not depend on the original data point.

00:35:08,109 --> 00:35:12,309
In that case, if you start to do shuffling tricks,

00:35:12,309 --> 00:35:14,880
you'll end up with results that are completely off.

00:35:14,880 --> 00:35:16,860
So you have to be very careful about that.

00:35:16,860 --> 00:35:20,700
And sometimes that non-independence in your data can be really, really subtle.

00:35:20,700 --> 00:35:24,589
So I'd watch that talk by Chris Fonnesbeck

00:35:24,589 --> 00:35:27,040
that I referenced for some of those situations.

00:35:27,040 --> 00:35:30,130
He has some great examples of things

00:35:30,130 --> 00:35:35,190
that have happened in the real world where these sorts of subtleties come up.

00:35:35,190 --> 00:35:39,200
The other thing is if you have very very few samples, you know, if you have

00:35:39,200 --> 00:35:41,970
three samples and you start shuffling them, you're not going to get

00:35:41,970 --> 00:35:46,790
a very good proxy for your sampling distribution.

00:35:46,790 --> 00:35:50,529
And then there's some other, more detailed considerations

00:35:50,529 --> 00:35:56,140
that you can look at in those books that I mentioned.

00:35:58,220 --> 00:35:59,900
(audience member 3) So is there anything --

00:35:59,900 --> 00:36:01,600
one of the implicit assumptions here is that you're --

00:36:01,600 --> 00:36:03,340
when you're writing code like this,

00:36:03,340 --> 00:36:06,220
is that the random number generator is actually a random number generator.

00:36:06,229 --> 00:36:08,720
Is there like, do you have any advice specifically about Python, about

00:36:08,720 --> 00:36:13,460
like, are there any caveats about the random number generator there, any advice?

00:36:13,460 --> 00:36:15,340
(Jake) Yeah, that's a great point.

00:36:15,340 --> 00:36:17,500
So this, like you said, this all depends

00:36:17,510 --> 00:36:23,029
on your random number generator actually being sort of random.

00:36:23,029 --> 00:36:25,930
And one thing about random number generators is none of them,

00:36:25,930 --> 00:36:27,710
almost none of ‘em, are actually random, right?

00:36:27,710 --> 00:36:29,640
They’re all deterministic, heh.

00:36:29,640 --> 00:36:34,819
Even one -- if you import the random module in Python, you give it a seed

00:36:34,819 --> 00:36:38,400
and it creates a deterministic stream of random numbers.

00:36:38,400 --> 00:36:43,089
Now those numbers have properties of randomness and they sort of reflect

00:36:43,089 --> 00:36:47,520
what you would expect random numbers to look like, but this distinction

00:36:47,520 --> 00:36:54,020
of pseudo-random versus random is really subtle and really important here.

00:36:54,020 --> 00:36:58,349
So if you use a very unsophisticated random number generator, one with like,

00:36:58,349 --> 00:37:03,259
a very low mode or something, these sort of approaches can fail.

00:37:03,259 --> 00:37:05,779
And they can fail in ways that are hard to detect.

00:37:05,779 --> 00:37:09,960
But the good news for us in Python is that we have a built-in random number

00:37:09,960 --> 00:37:15,099
generator based on some pretty sophisticated methods.

00:37:15,099 --> 00:37:19,200
The same random number generator is also built into NumPy.

00:37:19,200 --> 00:37:23,220
And for all intents and purposes, you can treat the Python random number --

00:37:23,220 --> 00:37:27,329
random module as producing real random numbers.

00:37:27,329 --> 00:37:30,470
But as hackers, you all know the difference between pseudo-random

00:37:30,470 --> 00:37:33,250
and random number generators, so you can

00:37:33,250 --> 00:37:38,640
keep that in mind as you're answering these sorts of questions.

00:37:40,600 --> 00:37:42,140
(audience member 4) Jake, thank you very much;

00:37:42,140 --> 00:37:44,400
excellent presentation.

00:37:44,400 --> 00:37:48,100
I am also a budding statistician.

00:37:48,100 --> 00:37:51,040
And I know it's not the right Python function call --

00:37:51,040 --> 00:37:52,500
I think it's a gamma distribution, I’m not sure --

00:37:52,500 --> 00:37:53,720
but what you can say -- ?

00:37:53,720 --> 00:37:54,920
(Jake) Which distribution?

00:37:54,920 --> 00:37:56,640
(audience member 4) The gamma distribution,

00:37:56,640 --> 00:37:59,640
where you can specify the mean and the standard deviation

00:37:59,640 --> 00:38:03,800
of your sample set and it can create however much you want.

00:38:03,800 --> 00:38:05,480
Is there a reason why you didn't use that

00:38:05,480 --> 00:38:09,380
for generating more sample data in your examples here?

00:38:09,380 --> 00:38:11,620
(Jake) Yeah, yeah, so I guess the question is

00:38:11,620 --> 00:38:14,720
if you know your data is coming

00:38:14,720 --> 00:38:19,700
from a gamma distribution or a normal distribution, that's completely valid.

00:38:19,710 --> 00:38:21,650
But you know, the normal distribution is

00:38:21,650 --> 00:38:25,999
only really, in most cases, is only really an approximation.

00:38:25,999 --> 00:38:30,420
So you're -- if you use, say, a normal distribution and you generate

00:38:30,420 --> 00:38:33,809
more data from that distribution, what you're learning about

00:38:33,809 --> 00:38:37,519
is the normal distribution that you've assumed fits your data.

00:38:37,519 --> 00:38:40,489
And what we want to do in these methods is we want to not make

00:38:40,489 --> 00:38:42,589
those assumptions about what the distribution is,

00:38:42,589 --> 00:38:47,119
but rather kind of let the data speak for themselves in terms of the distribution.

00:38:47,119 --> 00:38:49,640
And that's why we don't do these things.

00:38:49,640 --> 00:38:54,259
So it's a great solution if you actually know that your data is

00:38:54,259 --> 00:38:57,680
normally distributed with a certain mean and a certain standard deviation.

00:38:57,680 --> 00:38:58,820
(audience member 4) Thank you very much.

00:38:58,820 --> 00:38:59,820
(Jake) Yeah.

00:39:00,440 --> 00:39:03,500
(audience member 5) I just wanted to confirm on the example

00:39:03,500 --> 00:39:09,320
where you had the points plotted and then you split it into two graphs.

00:39:09,320 --> 00:39:12,880
Did you just randomly pick the values, depending on which graph

00:39:12,880 --> 00:39:14,720
it was going to go on, they were randomly --?

00:39:14,720 --> 00:39:16,680
(Jake) Yeah, so that’s --

00:39:16,680 --> 00:39:20,340
the key to this cross-validation is that it's a random split.

00:39:20,340 --> 00:39:23,580
Especially, you know, you might have a data process that's kind of biased

00:39:23,599 --> 00:39:27,359
where the first half is slightly different than the second half.

00:39:27,359 --> 00:39:31,869
And then if you do a split down the middle, you would run into problems.

00:39:31,869 --> 00:39:37,239
So for packages like scikit-learn, they'll automatically do the right kind

00:39:37,240 --> 00:39:41,240
of random split to make sure that you're getting the right answer on your data.

00:39:41,240 --> 00:39:42,420
(audience member 5) Thank you.

00:39:42,420 --> 00:39:44,140
(Jake) Yep.

00:39:44,140 --> 00:39:45,620
Maybe one last question.

00:39:45,620 --> 00:39:47,120
(audience member 6) Sure, when you talk about

00:39:47,120 --> 00:39:50,860
cross-validation and it's not a good idea for smaller --

00:39:50,860 --> 00:39:53,520
like if you only have 20 points or something like that --

00:39:53,520 --> 00:39:55,320
what do you do when you --?

00:39:55,320 --> 00:39:56,900
(Jake) Yeah, that's a good question.

00:39:56,900 --> 00:39:58,320
(audience member 6) -- you don't have a ton of points

00:39:58,320 --> 00:40:01,320
but you still don’t wanna overfit or -- ?

00:40:01,320 --> 00:40:04,900
(Jake) There are a couple things --

00:40:04,900 --> 00:40:06,440
(audience member 6) Even if you can just give me words

00:40:06,440 --> 00:40:07,600
I can look it up on the internet.

00:40:07,600 --> 00:40:09,320
(Jake) There are a couple of things you can do.

00:40:09,320 --> 00:40:13,220
So one, you could do something like a leave-one-out validation.

00:40:13,220 --> 00:40:17,759
So rather than splitting your data in two, you just hold out one data point

00:40:17,760 --> 00:40:21,580
and you fit it on the other nine and then ask how well it fits that one.

00:40:21,580 --> 00:40:25,040
So that gets you a little closer to having the full data set.

00:40:25,040 --> 00:40:27,880
But I think the broader answer is that

00:40:27,880 --> 00:40:31,060
if you're doing machine learning on 10 data points, you have bigger problems.

00:40:31,060 --> 00:40:33,920
(audience member 6) Sure, OK, thanks.

00:40:33,920 --> 00:40:35,760
(moderator) Well let's all thank Jake for his great talk.

00:40:35,760 --> 00:40:40,120

YouTube URL: https://www.youtube.com/watch?v=Iq9DzN6mvYA


