Title: Van Lindberg   Structured Data from Unstructured Text   PyCon 2016
Publication date: 2016-06-20
Playlist: PyCon 2016
Description: 
	"Speaker: Van Lindberg

Ever wonder how if you google “When was Python created?” Google just has the answer in a box at the top for you?  In this talk we’ll investigate how information extraction systems work, implement one using scikit-learn and NLTK, and learn about natural language processing along the way.

Slides can be found at: https://speakerdeck.com/pycon2016 and https://github.com/PyCon/2016-slides"
Captions: 
	00:00:00,100 --> 00:00:01,860
(moderator) Hello.

00:00:01,860 --> 00:00:04,280
This is Structured Data from Unstructured Text.

00:00:04,280 --> 00:00:08,300
I'd like to introduce our speaker, Van Lindberg.

00:00:08,300 --> 00:00:15,760
[applause]

00:00:18,040 --> 00:00:20,260
(Van Lindberg) Hello everyone. Wow!

00:00:20,700 --> 00:00:23,600
That's quite a bit louder than I expected.

00:00:24,320 --> 00:00:27,660
I am happy to be here today.

00:00:27,660 --> 00:00:30,740
I hope that you are happy about it, because a number of you

00:00:30,740 --> 00:00:34,190
were probably coming expecting to see Smitha Milli.

00:00:34,190 --> 00:00:37,769
Smitha had an issue that --

00:00:37,769 --> 00:00:41,140
a travel issue, I believe, and wasn't able to make it.

00:00:41,140 --> 00:00:44,620
And so, I saw her abstract and I saw her title,

00:00:44,620 --> 00:00:47,360
and this was something that I have been passionate about

00:00:47,360 --> 00:00:50,920
for a long time, and I said, "Well, I'll give that talk.

00:00:50,920 --> 00:00:54,180
"I don't have her slides but I'll write something."

00:00:54,180 --> 00:00:57,700
And they said, "Okay."

00:00:57,700 --> 00:01:01,760
And so, I saddled myself with a talk 24 hours ago.

00:01:01,760 --> 00:01:05,080
But this is something that I love.

00:01:05,080 --> 00:01:07,180
But I tell you, I will not be offended

00:01:07,180 --> 00:01:09,320
if any of you walk out right now.

00:01:10,940 --> 00:01:12,680
Still here?

00:01:12,680 --> 00:01:14,960
Good. Okay.

00:01:14,960 --> 00:01:16,960
So why are we here?

00:01:16,960 --> 00:01:20,520
Why do we care about getting unstructured --

00:01:20,520 --> 00:01:23,920
getting structured data from unstructured text?

00:01:24,820 --> 00:01:29,700
Well, I think it's because we are creatures of language.

00:01:29,700 --> 00:01:33,740
We have -- we are surrounded by masses of text.

00:01:33,740 --> 00:01:37,340
You know, there is an explosion of publicly available information

00:01:37,340 --> 00:01:41,780
right now, and most of it is in text format.

00:01:42,420 --> 00:01:45,820
And we want to use that text, we are being who we are,

00:01:45,820 --> 00:01:47,860
as input to a function.

00:01:47,860 --> 00:01:49,730
You know, this is very trendy right now.

00:01:49,730 --> 00:01:54,380
Half of the startups out there are about applying machine learning

00:01:54,380 --> 00:01:57,420
to some sort of text database or some sort of images,

00:01:57,420 --> 00:02:00,280
and people are throwing money at them.

00:02:00,280 --> 00:02:03,820
We want to make our processes more efficient.

00:02:04,620 --> 00:02:07,780
But I think it's about a little bit more than that.

00:02:07,780 --> 00:02:10,740
As Dr. Barba said in her keynote yesterday,

00:02:10,740 --> 00:02:13,500
we are creatures of language.

00:02:13,500 --> 00:02:15,940
We act through language.

00:02:15,940 --> 00:02:19,980
If we can teach computers to take all of this text

00:02:19,980 --> 00:02:23,420
that surrounds us and turn it into information

00:02:23,420 --> 00:02:26,620
that we can use in various ways, then we have done something

00:02:26,620 --> 00:02:28,560
that is actually very profound.

00:02:28,560 --> 00:02:34,220
We have taught computers to read for us, to understand,

00:02:34,220 --> 00:02:37,080
and to teach us back the things that they understood.

00:02:37,080 --> 00:02:41,020
We have made computers a little more human.

00:02:41,460 --> 00:02:44,460
That is a pretty profound thing.

00:02:45,060 --> 00:02:49,780
So, I think as soon as we start talking about generating...

00:02:51,780 --> 00:02:55,460
Ah, I'm not even keeping up with my slides.

00:02:55,460 --> 00:02:57,780
As soon as we start talking generating structured data

00:02:57,780 --> 00:03:02,320
from unstructured text, I think that we need a couple definitions.

00:03:02,320 --> 00:03:05,640
These are not dictionary definitions, these are my definitions.

00:03:05,640 --> 00:03:08,860
And I'm not going to read them to you, but I want to highlight

00:03:08,860 --> 00:03:14,520
one thing about them, and that is: it is all about ambiguity.

00:03:14,520 --> 00:03:19,320
As humans, we have the capability of -- we have lots of context

00:03:19,320 --> 00:03:23,540
and we have lots of things that we use for clues in order to reduce

00:03:23,540 --> 00:03:28,820
the ambiguity in English sentences or other natural languages

00:03:28,820 --> 00:03:33,940
and come up with something approaching what we think that other person meant.

00:03:33,940 --> 00:03:41,100
But computers don't have that same advantage.

00:03:41,100 --> 00:03:44,871
And so, we -- what we are trying to do

00:03:44,871 --> 00:03:49,200
when we're generating structured data is we're trying to reduce the --

00:03:49,200 --> 00:03:53,700
use the structure of the language, all the clues that we have,

00:03:53,700 --> 00:03:57,500
and teach a computer to reduce the ambiguity so that we are able

00:03:57,500 --> 00:03:59,900
to then compute about it.

00:04:00,660 --> 00:04:03,960
So, to start with, we need some data.

00:04:03,960 --> 00:04:07,140
Now, I'm going to switch over to a Jupyter notebook

00:04:07,140 --> 00:04:12,500
and may the demo gods all be with us today.

00:04:13,720 --> 00:04:18,020
And I have a CSV -- oops, wrong way.

00:04:18,020 --> 00:04:22,440
I have a CSV that we exported actually from the PyCon site

00:04:22,440 --> 00:04:26,960
that has tutorial names and -- talk and tutorial names and abstracts,

00:04:26,960 --> 00:04:31,740
and as far as possible I'm going to be using that for some of the data today.

00:04:31,740 --> 00:04:33,780
Now, this is unstructured text.

00:04:33,780 --> 00:04:36,520
I can show it to you right here.

00:04:37,640 --> 00:04:40,920
And you can see it's just in a CSV file.

00:04:41,600 --> 00:04:44,160
It's not very interesting.

00:04:44,160 --> 00:04:46,360
But even -- this is unstructured text,

00:04:46,360 --> 00:04:48,800
but I have to warn you that I am cheating,

00:04:48,800 --> 00:04:52,960
because already, I have it in a machine-parsible format.

00:04:52,960 --> 00:04:55,030
I have it in a CSV.

00:04:55,030 --> 00:04:58,580
Really, this information comes from a database dump,

00:04:58,580 --> 00:05:03,800
or even you can get it off the HTML by scraping the PyCon website.

00:05:03,800 --> 00:05:09,580
A lot of times, the data that you get is going to come in a messy format

00:05:09,580 --> 00:05:14,639
embedded in some sort of document, and half of machine learning is about

00:05:14,640 --> 00:05:18,540
the pipes that move the data around and cleaning the data.

00:05:18,540 --> 00:05:21,520
And so, I'm going to start

00:05:21,520 --> 00:05:25,520
by getting the data, and I'll run this here.

00:05:25,520 --> 00:05:29,560
And if you look at it, I just -- I went over this once.

00:05:29,560 --> 00:05:33,840
I removed all the -- it's in UTF-8 but I removed all the characters

00:05:33,840 --> 00:05:36,360
that have an ordinal number higher than 128

00:05:36,360 --> 00:05:38,540
because I really only needed the ASCII data.

00:05:38,540 --> 00:05:41,400
I had some messy stuff, but you'll see I didn't actually do it

00:05:41,400 --> 00:05:45,060
very carefully because I've got a bunch of spurious newlines in there.

00:05:45,060 --> 00:05:50,480
So I'm going to actually clean it a little bit more,

00:05:50,480 --> 00:05:53,479
and I'm going to replace some of these newlines.

00:05:53,480 --> 00:05:57,560
And I'm going to also just make a little index that I'm going to use

00:05:57,560 --> 00:06:01,040
to save and I can refer back to these documents later.

00:06:01,040 --> 00:06:05,820
So, you can see the -- you saw these newlines and everything.

00:06:05,820 --> 00:06:08,580
Let's make it look just a little bit nicer here.

00:06:10,300 --> 00:06:14,900
And, well, it is...

00:06:15,680 --> 00:06:18,620
It's harder to tell on this resolution; however, those --

00:06:18,620 --> 00:06:21,920
the spurious newlines are gone.

00:06:24,340 --> 00:06:26,080
But...

00:06:26,800 --> 00:06:28,800
You may think that we are ready to go,

00:06:28,800 --> 00:06:32,200
but we actually have one more important step,

00:06:32,200 --> 00:06:35,400
and that is: we need to tokenize.

00:06:35,400 --> 00:06:39,680
We need to decide what we actually mean by

00:06:39,680 --> 00:06:44,100
"We have something that we're ready to compute about. We have data."

00:06:44,100 --> 00:06:50,060
Now, when you're thinking about words and language, you may think,

00:06:50,060 --> 00:06:53,000
"Well, obviously you would split along the words."

00:06:53,000 --> 00:06:57,200
But that is not nearly as obvious as it might seem.

00:06:57,200 --> 00:06:59,560
The reason why is because there are lots

00:06:59,560 --> 00:07:02,680
of interesting things that you can do --

00:07:02,680 --> 00:07:05,740
for example, splitting along every character line.

00:07:05,740 --> 00:07:08,580
How many of you have heard of neural network,

00:07:08,590 --> 00:07:12,380
in particular, recurrent neural networks?

00:07:12,380 --> 00:07:15,500
A lot of people. There was a great demo the other day --

00:07:15,500 --> 00:07:17,700
that came around a little while ago,

00:07:17,700 --> 00:07:21,060
where they decided, "We're going to generate text

00:07:21,060 --> 00:07:23,440
"and we're going to have a bunch of words

00:07:23,440 --> 00:07:25,460
"but we're not going to look at them as words.

00:07:25,460 --> 00:07:29,060
"Instead we're going to look at them on a character-by-character basis

00:07:29,060 --> 00:07:32,660
"and we're going to figure out what is the most likely character,

00:07:32,660 --> 00:07:35,180
"after looking at all this stuff,

00:07:35,180 --> 00:07:38,480
"based upon the inputs that we've had so far."

00:07:38,480 --> 00:07:43,860
And so I've got -- you know, "Python is..."

00:07:43,860 --> 00:07:47,680
Snd how many characters? I thought obviously we should do 42.

00:07:53,320 --> 00:07:57,240
"Python is the legend of John Newton at Storm. Sit."

00:07:57,240 --> 00:07:58,800
[laughter]

00:07:58,800 --> 00:08:02,660
And so, the amazing thing, when you think about it,

00:08:02,660 --> 00:08:05,220
this was generated character by character.

00:08:05,220 --> 00:08:09,940
It had no idea that it was generating English words.

00:08:09,940 --> 00:08:13,860
It was computing on this idea of one piece of text

00:08:13,860 --> 00:08:16,480
anticipates the next, anticipates the next.

00:08:16,480 --> 00:08:19,180
And we can actually redo this over and over

00:08:19,180 --> 00:08:26,060
and get new funny -- new funny things.

00:08:26,060 --> 00:08:28,720
We'll give it a few more.

00:08:30,360 --> 00:08:34,320
"Python is locked panel: The current De Zoli (GSR) Cit."

00:08:37,240 --> 00:08:42,140
The point is that you may want to think about, is a word really

00:08:42,149 --> 00:08:45,089
the smallest piece of information that you need?

00:08:45,089 --> 00:08:48,220
Going the other way, you may want to also look at things

00:08:48,220 --> 00:08:51,260
that are bigger than one single word.

00:08:51,260 --> 00:08:55,160
For example, bigrams are sequences of two words.

00:08:55,160 --> 00:08:59,460
You would have those in cases where you have --

00:08:59,460 --> 00:09:04,020
especially for something like a proper noun -- where "the queen"

00:09:04,020 --> 00:09:09,100
has a very separate and distinct meaning from just the word "queen."

00:09:09,100 --> 00:09:13,620
And by throwing away the word "the", the fact -- the information

00:09:13,620 --> 00:09:15,600
that it was next to the word "queen",

00:09:15,600 --> 00:09:19,440
you actually throw away a lot of information.

00:09:21,560 --> 00:09:23,460
In fact, language models --

00:09:23,460 --> 00:09:25,400
I don't know how many of you know Doug Napoleone.

00:09:25,400 --> 00:09:28,660
He works for Nuance, who does a lot of cutting-edge

00:09:28,660 --> 00:09:31,580
language research and work.

00:09:31,580 --> 00:09:36,180
And he said that they have a six-way model --

00:09:36,180 --> 00:09:42,280
6 ngram is what they call it -- for predicting the next part of speech.

00:09:42,280 --> 00:09:44,560
But we are going to be completely boring

00:09:44,560 --> 00:09:47,540
and we are going to tokenize just upon words.

00:09:47,540 --> 00:09:50,400
And one of the things that we have in Python

00:09:50,400 --> 00:09:54,900
is something called NLTK. it's the Natural Language Toolkit.

00:09:54,900 --> 00:09:57,240
I'm going to be using a lot of NLTK today

00:09:57,240 --> 00:09:59,460
and I'm going to be using something called gensim.

00:09:59,460 --> 00:10:06,360
These are excellent, almost jack of all trades

00:10:06,360 --> 00:10:11,420
in terms of doing a lot of things with natural language processing.

00:10:12,100 --> 00:10:14,120
There are a few others that we'll talk about.

00:10:14,120 --> 00:10:18,560
Also, all of this, just as an aside, is running in Python 3.51

00:10:18,560 --> 00:10:22,340
and so everything here is available in Python 3.

00:10:23,500 --> 00:10:28,220
So, we're going to import NLTK and we're going to tokenize our words.

00:10:28,220 --> 00:10:31,000
And so, let's see what -- I took a random sentence

00:10:31,000 --> 00:10:35,820
from one of our inputss. Let's see what we've got.

00:10:35,820 --> 00:10:37,640
So let's run this.

00:10:39,560 --> 00:10:42,400
So, "The syntax in many programming languages is complicated

00:10:42,400 --> 00:10:45,060
"and they use many characters rarely found in written English",

00:10:45,060 --> 00:10:49,680
was the sentence, and you can see the way in which it tokenized it.

00:10:49,680 --> 00:10:56,700
It broke it out mostly by white space, and you'll notice it also separated out

00:10:56,700 --> 00:10:59,529
the period as a separate character at the end,

00:10:59,529 --> 00:11:03,330
because it changes the -- it changes what it is

00:11:03,330 --> 00:11:06,520
that you are thinking about. It changes the meaning

00:11:06,520 --> 00:11:10,380
of both the word before and the word after.

00:11:11,500 --> 00:11:16,120
Now, now that we have our --

00:11:16,120 --> 00:11:20,820
now that we have our various tokens,

00:11:20,820 --> 00:11:22,800
the first place that you might think about

00:11:22,800 --> 00:11:25,620
looking for ways to reduce the ambiguity,

00:11:25,620 --> 00:11:28,400
to get information out of these sentences,

00:11:28,400 --> 00:11:34,040
is by examining the structure of the sentence itself.

00:11:34,040 --> 00:11:40,240
I don't know how many of you ever had to do this.

00:11:40,720 --> 00:11:43,120
Did any of you ever have to do these?

00:11:43,120 --> 00:11:45,340
They were pain, weren't they?

00:11:46,100 --> 00:11:49,140
This is a sentence diagram,

00:11:49,140 --> 00:11:51,800
where the different parts of speech and the relationships

00:11:51,800 --> 00:11:54,870
between the different words are represented

00:11:54,870 --> 00:11:58,980
by the types of lines and the connections between them.

00:11:58,980 --> 00:12:04,120
This is something that we can also do with computers, and in fact,

00:12:04,120 --> 00:12:07,720
Google just released something called SyntaxNet

00:12:07,720 --> 00:12:14,680
where they use their TensorFlow system in order to do

00:12:14,680 --> 00:12:19,700
very high quality parsing, tagging, tokenization.

00:12:19,700 --> 00:12:23,960
And it uses both a rule-based system and a probabilistic-based system

00:12:23,960 --> 00:12:29,760
based upon learning many, many sentences across the entire Internet.

00:12:29,760 --> 00:12:33,320
This pre-trained model that they provide

00:12:33,320 --> 00:12:38,500
for parsing English sentences is called Parsey McParseface.

00:12:38,500 --> 00:12:42,420
And you can look it up.

00:12:42,420 --> 00:12:48,040
And they have a command line interface to it,

00:12:48,040 --> 00:12:51,100
and so you can see that it generates the same sort of tree.

00:12:51,100 --> 00:12:53,920
Not exactly the same, but you can see the similarities.

00:12:53,920 --> 00:13:01,900
And you can also see it allocating parts of speech tags

00:13:01,900 --> 00:13:09,600
to the various words: verbs, nouns, subjects, direct objects, etc.

00:13:10,680 --> 00:13:18,040
So this is very useful for certain types of information extraction,

00:13:18,040 --> 00:13:21,740
particularly if you want to know about the relationships between --

00:13:21,740 --> 00:13:23,780
within the sentence.

00:13:23,780 --> 00:13:26,600
But personally, having done a lot of this,

00:13:26,600 --> 00:13:30,560
I found that it hasn't quite lived up to my expectations.

00:13:30,560 --> 00:13:34,640
It hasn't been as useful as I would have expected.

00:13:34,640 --> 00:13:39,899
And the reason why is because it tells you

00:13:39,900 --> 00:13:44,000
a lot of things about the structure of the sentence,

00:13:44,000 --> 00:13:50,860
but then it doesn't tell you about anything relative to other sentences.

00:13:50,860 --> 00:13:56,240
It doesn't tell you about information and how it relates to other symbols

00:13:56,240 --> 00:13:58,780
that represent things in the real world.

00:13:58,780 --> 00:14:04,760
For example -- for example, it is a lot more useful to know

00:14:04,760 --> 00:14:09,100
that Queen Elizabeth is closely associated with England

00:14:09,100 --> 00:14:14,800
than that "Queen Elizabeth" is a compound noun phrase.

00:14:16,080 --> 00:14:20,560
One ties two concrete facts together,

00:14:20,560 --> 00:14:23,620
the other ties a fact to an abstract concept.

00:14:23,620 --> 00:14:26,460
Useful, but not always.

00:14:26,780 --> 00:14:31,840
The other thing is that Parsey McParseface is state of the art.

00:14:31,840 --> 00:14:36,580
It can correctly diagram and tag about 94% of sentences.

00:14:36,580 --> 00:14:38,500
I believe that that is either at the best

00:14:38,500 --> 00:14:41,120
or near the best that has been done.

00:14:41,800 --> 00:14:45,880
This is actually just a hair below what a trained human linguist

00:14:45,880 --> 00:14:48,820
could do, which is about 97%.

00:14:48,820 --> 00:14:52,480
But you'll notice there is still a lot of ambiguity in there.

00:14:52,480 --> 00:14:56,680
The thing that strikes me is, 97% of sentences,

00:14:56,680 --> 00:15:02,540
even a trained linguist still gets wrong 3% of those sentences.

00:15:02,540 --> 00:15:04,680
So what are we to do?

00:15:04,680 --> 00:15:06,980
Turns out that the answer,

00:15:06,980 --> 00:15:10,900
as so frequently is the case these days, is data.

00:15:10,900 --> 00:15:12,760
More and more data.

00:15:12,760 --> 00:15:15,040
And this is something that has really been pioneered

00:15:15,040 --> 00:15:16,980
by Google, and their --

00:15:16,980 --> 00:15:21,280
they had an interesting thing many years ago where they said --

00:15:21,280 --> 00:15:24,540
they talked about the unreasonable effectiveness of data.

00:15:24,540 --> 00:15:27,200
And so, let's start again then with our tokenized sentence

00:15:27,209 --> 00:15:29,700
and see if there's another way we can work with them.

00:15:29,700 --> 00:15:34,100
And that's by thinking of them as a collection of features.

00:15:34,100 --> 00:15:37,860
Now a feature is anything that a computer can recognize.

00:15:39,780 --> 00:15:41,780
In this case...

00:15:43,580 --> 00:15:45,420
In this case, what we're going to do --

00:15:45,420 --> 00:15:47,280
let me switch back here.

00:15:48,000 --> 00:15:50,820
Oh, by the way,

00:15:50,820 --> 00:15:52,780
NLTK -- oops.

00:15:53,400 --> 00:15:55,760
Nope, that's not what I want to do.

00:15:56,360 --> 00:15:58,560
NLTK can also do that.

00:16:01,120 --> 00:16:05,280
Hmm. All right. So, moving on.

00:16:05,280 --> 00:16:07,300
[laughter]

00:16:10,440 --> 00:16:12,740
So, the...

00:16:14,460 --> 00:16:16,300
Ee're going to look at a series of features.

00:16:16,300 --> 00:16:20,010
And when we're looking at language, the thing that we're going to say is,

00:16:20,010 --> 00:16:22,870
a feature is the presence, at least at the start,

00:16:22,870 --> 00:16:26,860
is the presence or the absence of the word in a certain context.

00:16:26,860 --> 00:16:29,860
Now this throws away a whole lot of context --

00:16:29,860 --> 00:16:31,740
so much that you would be really surprised.

00:16:31,740 --> 00:16:33,720
They call it a bag of words.

00:16:33,720 --> 00:16:38,480
And the image is actually rather apt of you pour everything into a bag

00:16:38,480 --> 00:16:40,899
and you jumble it and that is your set of features

00:16:40,900 --> 00:16:44,740
and that completely characterizes your document.

00:16:44,740 --> 00:16:48,800
And so, we're going to prepare -- take our documents, our texts here,

00:16:48,800 --> 00:16:51,200
and we're going to prepare a bag of words with them

00:16:51,200 --> 00:16:53,180
by removing some of the most common ones.

00:16:53,180 --> 00:16:56,040
We'll use our tokenizer here. You can see the text.

00:16:56,040 --> 00:17:00,100
And we're going to throw out the ones that only appear once.

00:17:00,100 --> 00:17:05,620
And then we're going to create a series of texts.

00:17:05,620 --> 00:17:07,500
So let's run this.

00:17:11,260 --> 00:17:13,380
It looks like I have...

00:17:14,020 --> 00:17:15,800
I need to...

00:17:17,240 --> 00:17:20,380
Let me run all the ones above this.

00:17:29,460 --> 00:17:32,120
[laughter]

00:17:33,360 --> 00:17:35,600
[laughter]

00:17:39,200 --> 00:17:42,380
Huh. It worked. Okay, there we go.

00:17:42,380 --> 00:17:45,920
And so, now we're going to create a dictionary and a corpus.

00:17:45,920 --> 00:17:48,380
And a dictionary is something -- a corpus is simply

00:17:48,380 --> 00:17:51,340
a collection of documents, and then a dictionary is something

00:17:51,340 --> 00:17:57,220
that maps a particular position in this vector to a particular word.

00:17:57,220 --> 00:18:02,620
Now the nice thing about a vector is it's a long, one-dimensional matrix.

00:18:03,460 --> 00:18:08,679
It's a 1-by-n matrix where the number -- the n

00:18:08,680 --> 00:18:10,960
is the number of different features that you have,

00:18:10,960 --> 00:18:13,700
and the 1 is the presence or the absence of that feature,

00:18:13,700 --> 00:18:15,680
at least in the bag words model.

00:18:15,680 --> 00:18:20,380
And the thing that you -- and then you can create things later

00:18:20,380 --> 00:18:24,320
that use different representations in that spot.

00:18:24,320 --> 00:18:26,220
But as long as you have that,

00:18:26,220 --> 00:18:29,200
you can do a lot of really nifty matrix math on it,

00:18:29,200 --> 00:18:32,580
and that allows you to extract some of the meaning from it.

00:18:33,060 --> 00:18:36,520
So we're going to use gensim here.

00:18:36,520 --> 00:18:39,400
You'll notice I've moved to gensim in the text.

00:18:39,400 --> 00:18:41,600
And we are going to...

00:18:49,400 --> 00:18:51,120
Oops.

00:18:52,760 --> 00:18:54,560
Oh, dead kernel.

00:18:56,760 --> 00:18:59,080
[audience member inaudible]

00:18:59,080 --> 00:19:03,580
[laughter]

00:19:04,820 --> 00:19:06,600
Okay.

00:19:06,600 --> 00:19:08,600
[audience member inaudible]

00:19:12,960 --> 00:19:15,040
(audience member) "Kernel" in the toolbar.

00:19:15,040 --> 00:19:17,560
(Van Lindberg) Kernel in the toolbar.

00:19:17,560 --> 00:19:19,300
Restart.

00:19:20,700 --> 00:19:23,480
[applause]

00:19:23,480 --> 00:19:25,420
Thank you.

00:19:27,860 --> 00:19:33,640
And then we'll Run All Above.

00:19:42,880 --> 00:19:46,160
And let's see if we can.

00:19:53,580 --> 00:19:55,840
Do I have a dead kernel again?

00:19:55,840 --> 00:19:57,840
[audience member inaudible]

00:19:59,360 --> 00:20:02,160
Okay. So while we're waiting for this,

00:20:02,160 --> 00:20:04,580
I'm going to tell you about what it's doing.

00:20:06,100 --> 00:20:08,440
So, we have this "bag of words" model,

00:20:08,440 --> 00:20:11,940
and frankly it's not that useful except as a starting place.

00:20:11,940 --> 00:20:15,620
But the thing that we can start to do is we can start to talk

00:20:15,620 --> 00:20:21,620
about extracting information by doing math on this vector.

00:20:21,620 --> 00:20:23,520
And the first thing that we're going to do

00:20:23,520 --> 00:20:25,440
is we're going to look at something called tf-idf

00:20:25,440 --> 00:20:30,500
which stands for "term frequency over inverse document frequency."

00:20:30,500 --> 00:20:35,140
What this does is it looks at the total frequency of each feature,

00:20:35,140 --> 00:20:37,080
in this case each word,

00:20:37,080 --> 00:20:42,700
and it scales that by the number of times

00:20:42,700 --> 00:20:47,420
that that particular feature appears across all documents.

00:20:48,120 --> 00:20:50,120
If you think about it, this actually becomes

00:20:50,120 --> 00:20:55,960
a pretty intuitive way of identifying things

00:20:55,960 --> 00:20:59,240
that are important in a particular document.

00:20:59,240 --> 00:21:03,980
For example, the word "and" is going to appear all over the place,

00:21:03,980 --> 00:21:09,020
but because it has a high divisor it appears in lots of --

00:21:09,029 --> 00:21:11,989
it has a high document frequency,

00:21:11,989 --> 00:21:16,360
well, we're going to -- it ends up not being very important.

00:21:16,360 --> 00:21:19,640
Whereas if you have something like "docker,"

00:21:19,640 --> 00:21:22,920
well, "docker" is going to show up quite a quite a bit.

00:21:25,080 --> 00:21:26,800
Assuming that...

00:21:31,560 --> 00:21:33,300
You know what?

00:21:53,060 --> 00:21:55,380
I actually have all the text.

00:21:59,700 --> 00:22:02,460
So let's see if we can...

00:22:10,980 --> 00:22:12,980
No, not that one.

00:22:17,380 --> 00:22:20,120
Okay. This is not working.

00:22:21,560 --> 00:22:24,640
So, what we're going to do is...

00:22:26,640 --> 00:22:28,420
Man! Okay.

00:22:29,820 --> 00:22:32,220
So, after we look at term frequency

00:22:32,220 --> 00:22:36,629
over inverse document frequency, what we have is a series of floats

00:22:36,629 --> 00:22:40,160
in each of those spaces that talk about the relative importance

00:22:40,160 --> 00:22:44,880
of each of those features in each document.

00:22:45,640 --> 00:22:52,900
And after -- and once we have that, we have what is called a sparse vector.

00:22:52,900 --> 00:22:55,680
Most of those things are going to be either zeros

00:22:55,680 --> 00:22:58,220
or very, very low probabilities.

00:22:58,220 --> 00:23:05,280
It's just, think about if you had a long, long matrix that had a 1

00:23:05,280 --> 00:23:07,620
for every single word that was in a document.

00:23:07,620 --> 00:23:12,320
Now a document may have a lot of words, but if the length of the vector

00:23:12,320 --> 00:23:17,330
is the number of all words in English, or all the words in all the documents

00:23:17,330 --> 00:23:21,500
that you have, most of the time that is going to be 0.

00:23:21,500 --> 00:23:23,740
Those are not going to exist at all.

00:23:23,740 --> 00:23:27,460
And so as a result, what happens

00:23:27,460 --> 00:23:32,880
is that you have very, very high dimensional spaces.

00:23:32,880 --> 00:23:39,780
Typical models will use anywhere from 300 to 500 as sort of a golden range

00:23:39,780 --> 00:23:42,760
and can go up to thousands or even millions

00:23:42,760 --> 00:23:47,000
of different features in their vector space.

00:23:47,000 --> 00:23:52,200
This is simply too many for us to meaningfully reason about.

00:23:52,200 --> 00:23:56,860
So one of the things that we do is we take a look at ways in which

00:23:56,860 --> 00:24:01,360
we can do meaningful dimensionality reduction,

00:24:01,360 --> 00:24:05,300
which means that we say, "What are the most important pieces

00:24:05,300 --> 00:24:11,140
"of this vector? What are the things that most correctly characterize it?"

00:24:11,140 --> 00:24:15,740
And we use those because that ends up being

00:24:15,740 --> 00:24:20,340
a much more compact representation of what is the essence

00:24:20,340 --> 00:24:22,360
of this particular document.

00:24:22,920 --> 00:24:27,880
So, how many of you have heard of principal component analysis?

00:24:28,520 --> 00:24:30,560
Good.

00:24:30,560 --> 00:24:34,280
The first thing that came out -- this was either the late '90s

00:24:34,280 --> 00:24:39,740
or the 2000s -- was the use of LSI, or latent semantic indexing,

00:24:39,740 --> 00:24:46,060
in order to identify what a document is about,

00:24:46,060 --> 00:24:50,029
what other things are about, by doing principal component analysis

00:24:50,029 --> 00:24:55,080
across the different vectors associated with a particular document.

00:24:56,820 --> 00:24:59,600
Turns out that they were able to find that certain things

00:24:59,600 --> 00:25:02,560
were very closely aligned in various ways,

00:25:02,560 --> 00:25:06,680
and other things were not nearly -- were less closely aligned.

00:25:06,680 --> 00:25:08,620
And as a result...

00:25:10,580 --> 00:25:13,380
And as a result, they...

00:25:22,260 --> 00:25:26,920
As a result, they were able to say, well, if you have a word that looks like --

00:25:26,920 --> 00:25:30,080
if you have a word "Queen Elizabeth" or a term "Queen Elizabeth,"

00:25:30,080 --> 00:25:33,620
that tends to be highly associated with ships,

00:25:33,620 --> 00:25:36,900
with England, with the Crown, with things like that.

00:25:36,900 --> 00:25:40,160
And because those things all tended to cluster together,

00:25:40,160 --> 00:25:45,440
you were able to not only be able to have them together

00:25:45,440 --> 00:25:47,720
but also to be able to...

00:25:48,600 --> 00:25:50,500
You know what? We are out of time.

00:25:50,500 --> 00:25:52,380
(unidentified speaker) I was just going to say,

00:25:52,380 --> 00:25:54,420
do you want a quick hand fixing that up?

00:25:54,420 --> 00:25:56,360
(Van Lindberg) I talked for too long.

00:25:59,780 --> 00:26:02,060
(unidentified speaker) Do you want a quick hand fixing that up?

00:26:02,060 --> 00:26:04,080
(Van Lindberg) Sure, please fix that up.

00:26:04,080 --> 00:26:06,080
In the meantime...

00:26:06,960 --> 00:26:09,420
In the meantime, I'll tell you basically

00:26:09,420 --> 00:26:11,400
there are different ways in which you could --

00:26:11,400 --> 00:26:15,420
the latent semantic indexing was --

00:26:15,420 --> 00:26:18,300
and then you had something called latent Dirichlet allocation --

00:26:18,300 --> 00:26:20,900
I'm not even sure I'm saying that right -- LDA,

00:26:20,900 --> 00:26:24,680
in which case it allocated a series of topics

00:26:24,680 --> 00:26:27,100
across a particular document.

00:26:29,340 --> 00:26:31,660
A series of topics across the document.

00:26:31,660 --> 00:26:35,060
The most interesting things that have happened recently

00:26:35,060 --> 00:26:39,140
are the creation of two things called word2vec and lda2vec.

00:26:39,140 --> 00:26:41,680
And what this is is it's a conditional --

00:26:41,680 --> 00:26:44,359
the evaluation of a conditional probability

00:26:44,360 --> 00:26:46,860
of a word, given the other words around it.

00:26:46,860 --> 00:26:49,940
And the interesting thing about this is that it operates

00:26:49,940 --> 00:26:56,260
in the vector space, similar -- and allows you to do math on words.

00:26:56,260 --> 00:27:02,220
For example, if you say "king, minus man, plus woman," what do you get?

00:27:03,060 --> 00:27:04,580
Queen.

00:27:04,580 --> 00:27:10,580
And if you think about your vectors, when you add them in different ways,

00:27:10,580 --> 00:27:13,880
turns out that with word2vec you end up with the same way.

00:27:13,880 --> 00:27:17,560
Lda2vec does the same thing for topics.

00:27:17,560 --> 00:27:20,100
And with that, I hope you haven't been too disappointed.

00:27:20,100 --> 00:27:24,320
But thank you for listening and I'll take any questions

00:27:24,320 --> 00:27:26,220
as we go down. Thank you.

00:27:26,220 --> 00:27:35,200

YouTube URL: https://www.youtube.com/watch?v=-K-XtxSyyvU


