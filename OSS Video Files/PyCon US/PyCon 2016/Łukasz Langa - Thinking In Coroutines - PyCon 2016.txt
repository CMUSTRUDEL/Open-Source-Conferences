Title: Łukasz Langa - Thinking In Coroutines - PyCon 2016
Publication date: 2016-05-30
Playlist: PyCon 2016
Description: 
	Speaker: Łukasz Langa

The wait for the killer feature of Python 3 is over! Come learn about asyncio and the beauty of event loops, coroutines, futures, executors and the mighty async/await. Practical examples. Bad puns. Pretty pictures. No prior asyncore, Twisted or Node.js experience required.

Slides can be found at: https://speakerdeck.com/pycon2016 and https://github.com/PyCon/2016-slides
Captions: 
	00:00:00,740 --> 00:00:02,740
(presenter) Good morning everyone.

00:00:02,740 --> 00:00:04,780
(audience members) Good morning!

00:00:07,660 --> 00:00:09,840
(presenter) 2-5-1 confirms we are OK.

00:00:10,360 --> 00:00:12,360
Good morning everyone.

00:00:12,360 --> 00:00:15,340
We are running a little bit late, so a short introduction.

00:00:15,340 --> 00:00:17,340
This is Łukasz Langa.

00:00:17,340 --> 00:00:21,699
He's talking about coroutine's asyncio framework in Python.

00:00:21,699 --> 00:00:24,339
Please give a big hand and applause to Łukasz.

00:00:24,340 --> 00:00:30,340
[applause]

00:00:32,160 --> 00:00:33,900
(Łukasz Langa) Good morning everyone.

00:00:33,900 --> 00:00:35,760
This is Thinking in Coroutines.

00:00:35,760 --> 00:00:37,500
My name is Łukasz Langa, I'm from the Internet.

00:00:37,500 --> 00:00:39,360
You can find me in lots of places.

00:00:39,360 --> 00:00:41,120
[laughter]

00:00:41,120 --> 00:00:44,220
In my free time, I'm helping Facebook run Python.

00:00:44,220 --> 00:00:46,800
Specifically, our mission for 2016

00:00:46,810 --> 00:00:50,140
is get as many projects as possible on Python 3.

00:00:50,140 --> 00:00:52,380
We are doing pretty well.

00:00:52,390 --> 00:00:55,750
You can check how far along are we on our booth.

00:00:55,750 --> 00:00:57,780
I invite you to do that.

00:00:57,780 --> 00:01:00,180
Specifically, it's very popular at Facebook

00:01:00,190 --> 00:01:02,640
because Facebook loves async.

00:01:02,640 --> 00:01:05,280
There's a lot of things about asynchronous programming

00:01:05,289 --> 00:01:07,889
that just clicks with our minds for some reason.

00:01:07,889 --> 00:01:10,860
As you can see, the PHP variant that we're using

00:01:10,869 --> 00:01:14,740
is both typed faster and has async 08.

00:01:14,740 --> 00:01:16,979
The C++ libraries that we're using

00:01:16,979 --> 00:01:22,999
to actually use as much CPU power as we have on our servers

00:01:23,000 --> 00:01:25,180
are also asynchronous in their nature.

00:01:25,180 --> 00:01:30,640
So is the RocksDB database layer that we also open sourced.

00:01:30,640 --> 00:01:32,900
It sort of clicks with people at Facebook.

00:01:32,909 --> 00:01:34,929
They understand what it means.

00:01:34,929 --> 00:01:38,009
They understand why it's cool, but why?

00:01:38,009 --> 00:01:41,949
What does async mean for a programmer?

00:01:41,949 --> 00:01:46,169
The easiest example is two variants of the same thing.

00:01:46,169 --> 00:01:52,589
We want to serve a response to a user requesting a webpage.

00:01:52,589 --> 00:01:58,599
If we are able to fan out the requests to data sources,

00:01:58,599 --> 00:02:01,019
the response time is going to arrive sooner.

00:02:01,020 --> 00:02:03,280
So, the latency is going to be better for the user.

00:02:03,280 --> 00:02:06,260
Everybody is happy.

00:02:06,260 --> 00:02:08,319
One of the things that I learned at Facebook

00:02:08,319 --> 00:02:11,680
is that it's the latency that drives the experience,

00:02:11,680 --> 00:02:15,000
not necessarily the time that takes to complete an operation.

00:02:15,000 --> 00:02:19,980
So, responsiveness an important thing, also in UI or mobile, especially.

00:02:19,980 --> 00:02:23,000
On Python, we didn't have a great story about this.

00:02:23,000 --> 00:02:25,060
And very often people would just say,

00:02:25,060 --> 00:02:27,140
"Come on, like, you can just spawn threads."

00:02:27,140 --> 00:02:28,940
"It's going to be awesome."

00:02:28,940 --> 00:02:30,720
In fact, it's far from awesome.

00:02:30,720 --> 00:02:32,560
[laughter]

00:02:32,560 --> 00:02:34,700
The problems with programming with threads

00:02:34,700 --> 00:02:39,360
is that it's very, very hard to see the global state of your program.

00:02:39,360 --> 00:02:42,640
So, not only is it hard to debug problems,

00:02:42,640 --> 00:02:46,200
it's also hard and complex to think about shared state.

00:02:46,200 --> 00:02:49,260
And obviously, we need locks.

00:02:49,260 --> 00:02:54,280
Speaking of locks, this also means that your threaded application

00:02:54,290 --> 00:02:58,040
might not behave as well as you would hope.

00:02:58,040 --> 00:03:01,370
The reason for it is, obviously, the global interpreter lock

00:03:01,370 --> 00:03:08,410
which we still have until Larry actually does the gilectomy

00:03:08,410 --> 00:03:12,250
that he just started and announced on the language summit.

00:03:12,250 --> 00:03:18,690
So, I have my hopes up, but currently the state is this.

00:03:18,690 --> 00:03:21,660
This is an actual slide from an internal talk I have given

00:03:21,660 --> 00:03:25,340
about global interpreter lock problem.

00:03:25,340 --> 00:03:28,620
We were observing that the blue thread operations

00:03:28,630 --> 00:03:31,140
are just executed increasingly rarely,

00:03:31,140 --> 00:03:33,140
and we didn't know why.

00:03:33,140 --> 00:03:35,480
It wasn't that they were actually doing more work

00:03:35,490 --> 00:03:37,890
or we had anything that we were blocked on,

00:03:37,890 --> 00:03:42,440
but for some reason, basically, we had some CPU leak,

00:03:42,440 --> 00:03:44,660
and that was, like, the strangest thing ever.

00:03:44,660 --> 00:03:48,920
What it actually turned out to be is that our red thread

00:03:48,930 --> 00:03:52,160
that was absolutely uninvolved with anything interesting --

00:03:52,160 --> 00:03:55,830
just set up by somebody to just do some logging

00:03:55,830 --> 00:03:58,150
of what is happening in the application - -

00:03:58,150 --> 00:04:00,860
had a bug in it, and just grew a collection

00:04:00,860 --> 00:04:05,790
over which it was repeatedly iterating on,

00:04:05,790 --> 00:04:09,530
which means it spent increasing amounts of time

00:04:09,530 --> 00:04:11,310
doing the same thing.

00:04:11,310 --> 00:04:14,030
And because of the global interpreter lock,

00:04:14,030 --> 00:04:17,770
everybody else had less time to do their actual work.

00:04:18,800 --> 00:04:23,780
So, my talk here is basically to say that you don't need all this.

00:04:23,780 --> 00:04:29,180
You can use asyncio, and that solves some of the problems.

00:04:29,180 --> 00:04:34,220
Actually, this is not a new problem, and this is not a new solution.

00:04:35,540 --> 00:04:37,520
Back in the early 2000s,

00:04:37,520 --> 00:04:40,260
before Guido was even in the United States,

00:04:40,270 --> 00:04:43,050
and before we had PEP 8,

00:04:43,050 --> 00:04:46,080
there was a project started by Glyph called Twisted,

00:04:46,080 --> 00:04:49,920
and Twisted was, at the heart of it, the same thing.

00:04:51,820 --> 00:04:56,640
But it was only after Greg Ewing added "yield-from" to the language

00:04:56,650 --> 00:05:01,160
where suddenly it became apparent that we can have a really nice syntax

00:05:01,160 --> 00:05:05,530
to express what Twisted has been doing for all those years.

00:05:05,530 --> 00:05:08,670
Twisted was, at the time, sort of like PyPi is now.

00:05:08,670 --> 00:05:10,670
Everybody was talking about it,

00:05:10,670 --> 00:05:15,200
but people were really afraid to take the leap and start using it.

00:05:15,200 --> 00:05:17,720
So, the hope was that with better syntax,

00:05:17,720 --> 00:05:23,160
with a simpler way of thinking about it,

00:05:23,160 --> 00:05:29,660
we might actually be able to at least start writing simple programs in it.

00:05:29,660 --> 00:05:31,880
So since "yield-from,"

00:05:31,880 --> 00:05:35,980
Guido has been really excited about adding this functionality to Python.

00:05:35,980 --> 00:05:39,500
And with Glyph's help, we arrived at asyncio.

00:05:39,500 --> 00:05:41,560
So, what is it?

00:05:42,000 --> 00:05:45,300
This is it; that's asyncio in its very core.

00:05:45,300 --> 00:05:48,860
It is an event loop that calls callbacks.

00:05:48,860 --> 00:05:52,200
That's the most important slide in this talk,

00:05:52,200 --> 00:05:55,220
so, really internalize that there's no magic,

00:05:55,220 --> 00:05:59,080
no complex things about asyncio.

00:05:59,080 --> 00:06:01,419
The real thing that you need to understand is

00:06:01,419 --> 00:06:05,159
there is one event loop calling callbacks.

00:06:05,160 --> 00:06:08,700
What this means is this is a framework

00:06:08,710 --> 00:06:12,889
that can maximize the use of a single thread.

00:06:12,889 --> 00:06:16,800
We can't achieve, inherently, any parallelism with it.

00:06:16,800 --> 00:06:20,320
It is more for concurrency if we get to coroutines.

00:06:20,320 --> 00:06:22,600
But this is basically what it does.

00:06:22,600 --> 00:06:24,640
But this sounds magical,

00:06:24,640 --> 00:06:28,640
so let me actually dive inside the code that does it

00:06:28,640 --> 00:06:30,980
to show you that it's true.

00:06:30,980 --> 00:06:33,680
When we use asyncio we would do this thing.

00:06:33,690 --> 00:06:36,300
We would just say, "asyncio, get event loop,"

00:06:36,300 --> 00:06:38,420
which gets the event loop for the current thread,

00:06:38,420 --> 00:06:40,680
and we say, "Run forever."

00:06:40,680 --> 00:06:45,240
And if you actually do this, what happens internally is

00:06:45,240 --> 00:06:48,160
we are actually running a loop.

00:06:48,160 --> 00:06:50,640
That's the code of asyncio right there.

00:06:50,650 --> 00:06:53,250
You can check it, it's open source.

00:06:53,250 --> 00:06:56,670
So, I invite you to do that.

00:06:56,670 --> 00:06:59,300
But that example was a little annoying

00:06:59,310 --> 00:07:01,950
because it was just running nothing forever.

00:07:01,950 --> 00:07:05,250
So, what does the loop call?

00:07:05,250 --> 00:07:08,540
What it calls is, whatever you want, right?

00:07:08,540 --> 00:07:12,740
If we have any simple function that we would like to invoke,

00:07:12,740 --> 00:07:16,160
you can just tell the loop, "Please call it soon."

00:07:16,160 --> 00:07:19,540
The terminology, "calling soon," comes from the fact

00:07:19,540 --> 00:07:23,760
that it might already have something that it is running currently.

00:07:23,760 --> 00:07:27,080
So, "As soon as you're free, please call the thing."

00:07:27,080 --> 00:07:29,060
We are calling "3"

00:07:29,060 --> 00:07:33,780
any things with different arguments on that very slide,

00:07:33,780 --> 00:07:38,100
and we are calling "later," at least after two seconds,

00:07:38,110 --> 00:07:40,140
a call to loop.stop.

00:07:40,140 --> 00:07:41,960
So, this is what actually happens.

00:07:41,960 --> 00:07:43,940
Everybody is happy, and it looks like, yeah,

00:07:43,940 --> 00:07:46,900
we achieved pretty much with a little code.

00:07:47,980 --> 00:07:51,540
So, this is awesome, and as I was saying,

00:07:51,540 --> 00:07:55,560
this is exactly what is executed on the event loop:

00:07:55,570 --> 00:07:57,340
a loop calling callbacks.

00:07:57,340 --> 00:07:59,140
No magic here.

00:07:59,140 --> 00:08:02,640
Obviously, the call to stop the loop after two seconds

00:08:02,650 --> 00:08:04,900
isn't busy looping, waiting for the two seconds.

00:08:04,900 --> 00:08:09,139
Actually, the loop takes -- uses a selector

00:08:09,139 --> 00:08:11,419
provided by your operating system

00:08:11,419 --> 00:08:15,310
to be smart about what callback should be called next.

00:08:15,310 --> 00:08:18,350
It's not a first-in, first-out loop.

00:08:18,350 --> 00:08:20,390
But it doesn't really matter, right?

00:08:20,390 --> 00:08:22,330
That's a technical detail.

00:08:22,330 --> 00:08:26,320
The thing is, it just executes callbacks one after the other.

00:08:26,320 --> 00:08:28,320
So, that sounds all great,

00:08:28,320 --> 00:08:31,700
but what if any of those callbacks were really slow.

00:08:31,700 --> 00:08:33,700
As I told you, it's just one thread.

00:08:33,710 --> 00:08:35,589
It's very simple.

00:08:35,589 --> 00:08:37,589
If any of those callbacks is slow,

00:08:37,589 --> 00:08:40,329
everything else coming after it is going to be slow.

00:08:40,329 --> 00:08:43,479
We can simulate that very easily by calling some operation

00:08:43,479 --> 00:08:45,659
that is going to just wait for a long time.

00:08:45,660 --> 00:08:47,820
That might have been a URL call.

00:08:47,820 --> 00:08:51,140
That might have been a database call, like, anything of the sort.

00:08:51,140 --> 00:08:53,180
If we do this, then actually

00:08:53,180 --> 00:08:57,080
what we're going to see executing the same code here --

00:08:57,080 --> 00:09:01,680
that everything else is waiting increasingly long and long and long,

00:09:01,680 --> 00:09:03,760
basically breaking the assumption

00:09:03,760 --> 00:09:07,640
that asyncio helps us with concurrency in any way.

00:09:07,640 --> 00:09:10,760
Fortunately, asyncio is helpful in the regard that

00:09:10,760 --> 00:09:14,190
if you tell it, "pythonasynciodebug=1,"

00:09:14,190 --> 00:09:16,520
when you run your program, it will yell at you

00:09:16,520 --> 00:09:22,160
for having callbacks that are very slow to run.

00:09:22,160 --> 00:09:26,560
So at least we can be warned about a situation like this that's bad.

00:09:26,560 --> 00:09:28,540
How can we solve it?

00:09:28,540 --> 00:09:30,560
How can we split work in a way

00:09:30,570 --> 00:09:34,010
where we are still executing this great amount of work

00:09:34,010 --> 00:09:36,800
but in a way where we are not stopping anything else

00:09:36,800 --> 00:09:38,860
from being executed in the meantime?

00:09:38,860 --> 00:09:41,100
Well, obviously, the answer is coroutines.

00:09:41,100 --> 00:09:44,990
So, instead of just creating a plain old function,

00:09:44,990 --> 00:09:47,490
like we were in that previous example,

00:09:47,490 --> 00:09:51,120
what we're doing instead is, we're creating a coroutine function.

00:09:51,120 --> 00:09:53,220
So basically we're saying "async def,"

00:09:53,220 --> 00:09:57,260
and instead of just assuming some operation is going to be slow,

00:09:57,260 --> 00:10:00,520
we are explicitly awaiting on it.

00:10:00,520 --> 00:10:03,860
One distinction that I like to make is this:

00:10:03,860 --> 00:10:06,279
When we're saying "coroutine function,"

00:10:06,279 --> 00:10:08,760
we're saying this is the function that we have defined

00:10:08,760 --> 00:10:10,700
that creates coroutines.

00:10:10,700 --> 00:10:13,779
A coroutine is already an instantiated call

00:10:13,779 --> 00:10:15,739
to a coroutine function.

00:10:15,740 --> 00:10:18,440
The reason why it's important is that that coroutine has a state

00:10:18,440 --> 00:10:21,560
and it's going to take a while until it's complete.

00:10:21,560 --> 00:10:23,540
So, whenever I say "coroutine function,"

00:10:23,540 --> 00:10:25,820
I mean the thing that we put in the code.

00:10:25,820 --> 00:10:27,860
Whenever I say "coroutine,"

00:10:27,860 --> 00:10:30,300
we mean the thing that's already instantiated.

00:10:30,300 --> 00:10:34,459
By the way, asyncio.sleep is a coroutine function,

00:10:34,459 --> 00:10:37,739
and its instantiation is already a coroutine, right?

00:10:37,740 --> 00:10:39,700
So this is it:

00:10:39,700 --> 00:10:42,500
How can we invoke coroutines with asyncio?

00:10:42,500 --> 00:10:44,360
It's also easy.

00:10:44,360 --> 00:10:46,540
We just create tasks on loops basically saying,

00:10:46,540 --> 00:10:49,960
"Please just execute this asyncronousy."

00:10:49,960 --> 00:10:53,480
Create a task and it's going to execute pretty well.

00:10:53,490 --> 00:10:56,150
If we do this, if we execute this code,

00:10:56,150 --> 00:10:59,589
we're back in concurrent land, everybody is happy.

00:10:59,589 --> 00:11:01,560
We can go home, right?

00:11:01,560 --> 00:11:04,300
Specifically, what happens when we create a task is,

00:11:04,300 --> 00:11:06,340
really, asyncio is going to create

00:11:06,340 --> 00:11:10,060
an instance of a class called "task."

00:11:10,060 --> 00:11:13,320
So let's look inside, like, how does this work?

00:11:13,320 --> 00:11:15,340
It's actually pretty easy.

00:11:15,340 --> 00:11:20,040
Tasks instantiate a few boring things, hence the ellipsis.

00:11:20,040 --> 00:11:24,340
But what it does at the end of its init method is,

00:11:24,340 --> 00:11:26,340
it says, "Oh, an event loop.

00:11:26,340 --> 00:11:31,700
"By the way, please call soon one step of me, just one."

00:11:31,700 --> 00:11:33,900
So what does it mean it has steps?

00:11:33,910 --> 00:11:36,260
What does it mean tasks have steps?

00:11:36,260 --> 00:11:41,560
A step might be one draw from my generator,

00:11:41,560 --> 00:11:44,240
because coroutines are based on generators.

00:11:44,240 --> 00:11:47,120
But that also might mean we already have our result,

00:11:47,120 --> 00:11:49,820
in which case we're just going to set the result on ourselves

00:11:49,820 --> 00:11:51,620
or maybe there was an exception,

00:11:51,620 --> 00:11:53,440
so we're going to set an exception on ourselves.

00:11:53,440 --> 00:11:56,080
If not, we're just going to keep on drawing,

00:11:56,080 --> 00:11:58,040
but how do we do this?

00:11:58,040 --> 00:12:01,880
We're going to do this by saying, "And by the way, I'm done now.

00:12:01,880 --> 00:12:03,660
"Call me soon."

00:12:03,660 --> 00:12:05,480
So, you can actually imagine

00:12:05,480 --> 00:12:09,410
that the execution in practice looks like this.

00:12:09,410 --> 00:12:13,070
We're just calling steps on all the coroutines that we have,

00:12:13,070 --> 00:12:15,000
one after the other,

00:12:15,000 --> 00:12:17,920
assuming that each of them is going to take a little time.

00:12:17,930 --> 00:12:22,070
Hence, we're actually maximizing the usage of a single thread.

00:12:22,070 --> 00:12:24,430
We're not going to wait on external I/O,

00:12:24,430 --> 00:12:27,750
but instead, we're going to keep our CPUs busy.

00:12:28,900 --> 00:12:32,100
So, that's the model on which an asyncio is built.

00:12:32,100 --> 00:12:35,360
Having that trampoline of the tasks,

00:12:35,370 --> 00:12:39,170
just casual, simple steps, one after the other.

00:12:39,170 --> 00:12:42,970
But everybody lies, and I did lie to you, too.

00:12:42,970 --> 00:12:45,740
There is one single thing that we forgot to do

00:12:45,750 --> 00:12:48,210
in our primitive example.

00:12:49,160 --> 00:12:52,060
Specifically, when I said, "Please call later.

00:12:52,070 --> 00:12:55,529
"After two seconds, just stop the loop," or whatnot,

00:12:55,529 --> 00:12:57,750
there's a little conflict between the coroutines

00:12:57,750 --> 00:12:59,839
that are already scheduled to be executed

00:12:59,839 --> 00:13:03,100
that are going to take more than two seconds,

00:13:03,100 --> 00:13:06,340
and our will to just stop the loop after two seconds.

00:13:07,060 --> 00:13:08,820
Fortunately, as I said,

00:13:08,820 --> 00:13:10,620
I think I was friendly to the programmer

00:13:10,620 --> 00:13:12,940
that just, you know, comes to asyncio for the first time

00:13:12,940 --> 00:13:16,060
and doesn't really expect those situations to happen.

00:13:16,060 --> 00:13:19,250
If you use "pythonasynciodebug," what is going to happen,

00:13:19,250 --> 00:13:21,570
it's going to tell you that, "I'm closing the loop,

00:13:21,570 --> 00:13:23,380
"but there is still work to do.

00:13:23,380 --> 00:13:25,100
"What are we doing?"

00:13:25,100 --> 00:13:29,120
So instead, maybe there is a way to say to the loop,

00:13:29,120 --> 00:13:31,860
"Please execute this for as long as it takes

00:13:31,860 --> 00:13:33,680
"until it completes."

00:13:33,680 --> 00:13:35,220
And actually, there is

00:13:35,220 --> 00:13:37,080
and it's called exactly as you would expect:

00:13:37,080 --> 00:13:38,840
"run until complete."

00:13:38,840 --> 00:13:42,180
That's true for a single coroutine, but what if we have many of them?

00:13:42,180 --> 00:13:46,880
And this is where the composability of coroutines comes in.

00:13:47,680 --> 00:13:51,340
Asyncio provides many of them, and one of them is "wait."

00:13:51,340 --> 00:13:54,620
You can create multiple tasks and tell the loop,

00:13:54,620 --> 00:13:57,080
"Please wait on all of them."

00:13:57,080 --> 00:13:59,080
This is how you would express this.

00:13:59,090 --> 00:14:02,310
"Run until complete," we're now actually

00:14:02,310 --> 00:14:05,680
going to execute everything as you would expect.

00:14:05,680 --> 00:14:07,600
No lies here anymore.

00:14:07,600 --> 00:14:09,980
This is how it runs.

00:14:09,980 --> 00:14:12,740
So, that's all great, but very often

00:14:12,750 --> 00:14:16,260
we would like those coroutines to actually return a thing for us,

00:14:16,260 --> 00:14:20,260
and the example didn't really have this before.

00:14:20,260 --> 00:14:22,860
But returning, as you would expect,

00:14:22,860 --> 00:14:25,500
in blocking programming from top to bottom,

00:14:25,980 --> 00:14:29,140
works exactly simple, right?

00:14:29,140 --> 00:14:31,480
You just return a thing.

00:14:31,480 --> 00:14:34,220
If you have many tasks, all of the results

00:14:34,230 --> 00:14:37,330
are stored on the consecutive tasks object,

00:14:37,330 --> 00:14:39,160
so you can actually print them out.

00:14:39,160 --> 00:14:40,980
If we do this, you can see

00:14:40,980 --> 00:14:44,820
that we are actually executing the functions at first,

00:14:44,820 --> 00:14:48,070
and then we are gathering the results and printing out the results,

00:14:48,070 --> 00:14:50,860
in which case we are seeing that, yes, actually some of the coroutines

00:14:50,860 --> 00:14:53,519
took pretty long to execute.

00:14:53,519 --> 00:14:59,260
But concurrently, we were able to start them all, sort of, at the same time.

00:14:59,260 --> 00:15:01,020
You understand, it's not parallel,

00:15:01,020 --> 00:15:04,440
but it is by means of steps which means it's pretty fast anyhow.

00:15:05,520 --> 00:15:08,140
If we only had one coroutine,

00:15:08,149 --> 00:15:12,169
the result can be simply taken right from "run until complete."

00:15:13,320 --> 00:15:17,060
The same thing is true for exception handling.

00:15:17,070 --> 00:15:20,269
It's done exactly as if you would expect it.

00:15:20,269 --> 00:15:22,470
So, if there's any exceptions,

00:15:22,470 --> 00:15:26,710
you can get to them by looking at the task's exception method.

00:15:27,520 --> 00:15:29,840
In this case, if we do this,

00:15:29,850 --> 00:15:32,810
we're going to see there is an exception type error:

00:15:32,810 --> 00:15:36,780
asyncio.sleep can't really tell how many seconds

00:15:36,790 --> 00:15:39,610
we want it to sleep here.

00:15:39,610 --> 00:15:45,149
If we wouldn't want this exception to bubble up to our code somewhere else

00:15:45,149 --> 00:15:47,790
but just to handle it internally in the coroutine,

00:15:47,790 --> 00:15:51,899
you would do it exactly as you expected already knowing Python.

00:15:51,899 --> 00:15:55,739
You just wrap it on "try-except," and it does the right thing,

00:15:56,540 --> 00:15:59,040
in which case no longer any type errors.

00:15:59,040 --> 00:16:01,040
It does the correct thing.

00:16:01,040 --> 00:16:03,120
So, just to summarize this --

00:16:03,120 --> 00:16:05,779
and I mean, really, you now understand asyncio

00:16:05,779 --> 00:16:09,959
and you can go forth and spread the gospel.

00:16:09,960 --> 00:16:14,000
From the blocking world, you invoke coroutines

00:16:14,010 --> 00:16:16,210
by either creating tasks on the loop and saying,

00:16:16,210 --> 00:16:18,040
"Hey, when you're running,

00:16:18,040 --> 00:16:20,060
these are the things that you have to handle,"

00:16:20,060 --> 00:16:22,200
or you can simply say to the loop,

00:16:22,200 --> 00:16:24,780
"I'm going to wait as long as it takes.

00:16:24,780 --> 00:16:26,720
"Run until complete."

00:16:26,720 --> 00:16:29,900
If you're inside a coroutine, again, you can create tasks.

00:16:29,900 --> 00:16:34,120
So you can say, "I don't care when this is going to be executed,

00:16:34,130 --> 00:16:36,440
"but just handle it,"

00:16:36,440 --> 00:16:38,420
or you can await, which means,

00:16:38,420 --> 00:16:40,420
"I'm going to wait as long as it takes

00:16:40,420 --> 00:16:44,019
"and only continue my execution afterwards."

00:16:44,019 --> 00:16:47,650
This is really important, because what it does is,

00:16:47,650 --> 00:16:51,580
it makes all the switch points in your applications explicit.

00:16:51,580 --> 00:16:53,600
What that means is,

00:16:53,600 --> 00:16:56,140
you can really reason about the shared state

00:16:56,149 --> 00:16:59,130
knowing that in between await calls,

00:16:59,130 --> 00:17:02,230
nobody else is going to modify your shared state,

00:17:02,230 --> 00:17:06,339
but any await call might be actually execute some different coroutine

00:17:06,339 --> 00:17:08,539
that might touch your shared state.

00:17:08,540 --> 00:17:10,560
This is much easier to reason about

00:17:10,569 --> 00:17:14,129
than a threading situation where everything is implicit.

00:17:14,880 --> 00:17:17,140
So, that's the summary.

00:17:17,140 --> 00:17:20,240
The good thing about asyncio

00:17:20,250 --> 00:17:23,360
is that there's already a lot included for you already.

00:17:23,360 --> 00:17:27,060
You can find all sorts of goodies in the docs already.

00:17:27,060 --> 00:17:29,000
So obviously, you can create connections

00:17:29,010 --> 00:17:31,180
that supports SSL as well, that supports IPv6.

00:17:31,180 --> 00:17:33,300
We use it, so I know.

00:17:33,300 --> 00:17:36,280
There's TCP, UDP, Unix sockets, you name it.

00:17:36,290 --> 00:17:38,040
You can do this.

00:17:38,040 --> 00:17:41,440
You can also write clients with it just as easily.

00:17:41,440 --> 00:17:43,240
Again, it supports SSL.

00:17:43,240 --> 00:17:47,060
It supports UDP by using the same datagram endpoint.

00:17:47,060 --> 00:17:49,060
You can watch file descriptors

00:17:49,060 --> 00:17:53,880
which is sort of the same thing but for local dealing with changes.

00:17:53,880 --> 00:17:56,520
You can also invoke subprocesses.

00:17:56,520 --> 00:17:58,560
These days, I find myself using asyncio

00:17:58,560 --> 00:18:00,520
even if I don't do any networking,

00:18:00,530 --> 00:18:02,860
because just, you know, fanning out a hundred subprocesses

00:18:02,860 --> 00:18:04,820
is much easier with asyncio

00:18:04,820 --> 00:18:07,420
than doing the same thing with the blocking subprocessing module.

00:18:08,620 --> 00:18:10,620
So, yes, this is it.

00:18:10,620 --> 00:18:13,600
And I was obviously making fun of logs and whatnot

00:18:13,600 --> 00:18:16,370
and saying, "Hey, we basically can mostly get away with it,"

00:18:16,370 --> 00:18:18,300
but if you really want data logs, you can still have them, right?

00:18:18,300 --> 00:18:19,810
[laughter]

00:18:19,810 --> 00:18:21,670
You can still use those sorts of primitives.

00:18:21,670 --> 00:18:23,430
Obviously, I'm kidding.

00:18:23,430 --> 00:18:25,230
Sometimes they are needed,

00:18:25,230 --> 00:18:28,760
but before you get and try to use them, there's queues.

00:18:28,760 --> 00:18:30,720
Queues solve a lot of problems really nicely,

00:18:30,730 --> 00:18:34,010
so maybe this is actually a thing that you would like to use instead.

00:18:34,010 --> 00:18:36,040
This is what asyncio provides.

00:18:36,040 --> 00:18:38,920
Obviously it would be like, "Hey, where's my Django?"

00:18:38,929 --> 00:18:41,010
There's no Django, but there's aiohttp

00:18:41,010 --> 00:18:44,320
which is pretty high level -- actually achieves a lot.

00:18:44,320 --> 00:18:46,840
So, I recommend you looking at the documentation of it.

00:18:46,841 --> 00:18:49,809
It is actually pretty powerful.

00:18:49,809 --> 00:18:53,880
If you want a database, Postgres is there, MySQL is there.

00:18:53,880 --> 00:18:55,880
Actually, it's pretty awesome,

00:18:55,880 --> 00:18:59,940
because it also supports the core API of SQLAlchemy.

00:18:59,940 --> 00:19:01,960
Obviously, not the ORM,

00:19:01,960 --> 00:19:05,640
because SQLAlchemy does things implicitly for you,

00:19:05,640 --> 00:19:09,870
and that doesn't work, with the summary of OS

00:19:09,870 --> 00:19:12,270
being really explicit about switch points, right?

00:19:12,270 --> 00:19:16,490
But the core session handling and whatnot is the same, same API.

00:19:17,360 --> 00:19:20,260
If you want speed, then you can also have UV loops.

00:19:20,260 --> 00:19:23,360
A UV loop is a new implementation of the event loop.

00:19:23,370 --> 00:19:26,630
You can just drop in the reference implementation

00:19:26,630 --> 00:19:30,100
and have it run at least twice as fast in Prod.

00:19:30,100 --> 00:19:32,690
So, asyncio is pretty popular these days.

00:19:32,690 --> 00:19:36,670
There's a lot of things happening, so I recommend you look at it.

00:19:36,670 --> 00:19:41,179
But if you really want speed, you will inevitably find yourself

00:19:41,179 --> 00:19:44,619
dealing with already existing blocking APIs,

00:19:44,620 --> 00:19:46,620
and that makes you really sad,

00:19:46,620 --> 00:19:49,940
because you can't do anything about it... or can you?

00:19:49,940 --> 00:19:51,720
Yes, you can.

00:19:51,720 --> 00:19:55,260
There is a concept of executors in asyncio, which basically means

00:19:55,260 --> 00:19:58,920
if you really have a terrible function coming from a third party library

00:19:58,920 --> 00:20:00,980
and we can't do anything about it --

00:20:00,980 --> 00:20:03,260
it was just implemented to wait forever for something --

00:20:03,270 --> 00:20:06,679
we can just say, "Hey, I'm going to use a pool of threads

00:20:06,679 --> 00:20:11,699
and just go forth and run those slow things in those threads."

00:20:11,700 --> 00:20:16,720
For stuff like sleeping I/O, with networking or whatnot,

00:20:16,720 --> 00:20:19,560
threads actually deal pretty well in Python,

00:20:19,570 --> 00:20:22,760
so you're going to see that this thing might be slower

00:20:22,760 --> 00:20:26,360
than using the asyncio equivalent, but it's pretty fast, too,

00:20:26,360 --> 00:20:28,400
so executors are nice.

00:20:28,400 --> 00:20:30,700
But as I said, the GIL is a thing,

00:20:30,700 --> 00:20:35,210
so if there is a CPU-intensive computation that you're doing,

00:20:35,210 --> 00:20:38,970
I would recommend you use the ProcessPoolExecutor instead.

00:20:38,970 --> 00:20:41,570
So, asyncio provides both, right?

00:20:41,570 --> 00:20:45,450
Thread pools are easier, process pools are more robust,

00:20:45,450 --> 00:20:47,480
but you pay the price

00:20:47,480 --> 00:20:50,840
for picking and unpicking arguments to your process pool.

00:20:50,850 --> 00:20:55,320
So, these are basically the good and bad sides of using either.

00:20:56,240 --> 00:21:00,840
Now, let me spend a few minutes on, sort of like,

00:21:00,840 --> 00:21:03,060
how this is already used in production.

00:21:05,220 --> 00:21:11,240
So, at Facebook, we are already 100,000 lines of code in --

00:21:11,240 --> 00:21:14,320
services that are on asyncio -- and growing daily.

00:21:14,320 --> 00:21:16,320
I'm pretty sure you know, by the end of the year,

00:21:16,320 --> 00:21:18,520
that number is going to be meaningless,

00:21:18,520 --> 00:21:20,560
but this is actually from this morning,

00:21:20,560 --> 00:21:22,760
so you're the first to hear about this.

00:21:22,770 --> 00:21:26,730
Instagram is already pretty heavily invested in asyncio as well.

00:21:26,730 --> 00:21:31,130
Again, we hope to be even better at the end of the year.

00:21:32,800 --> 00:21:36,020
Facebook uses Thrift very heavily, internally.

00:21:36,020 --> 00:21:39,250
If you want suddenly to create clients and servers

00:21:39,250 --> 00:21:42,750
that are asyncio enabled, you can do this like this.

00:21:42,750 --> 00:21:45,470
You just create a new namespace and the Thrift compiler

00:21:45,470 --> 00:21:48,100
is going to do the correct thing.

00:21:48,100 --> 00:21:51,400
When it does it, you can just import your service

00:21:51,400 --> 00:21:53,970
and then start implementing your methods

00:21:53,970 --> 00:21:56,550
that are going to create responses for you,

00:21:56,550 --> 00:21:58,350
which is pretty easy.

00:21:58,350 --> 00:22:00,150
If you want to create a connection,

00:22:00,150 --> 00:22:01,990
you're using the exact thing that you would expect.

00:22:01,990 --> 00:22:05,160
You just create a server factory,

00:22:05,160 --> 00:22:09,040
and then you just create connections if you are on the client's side.

00:22:10,260 --> 00:22:12,260
If you already have a connection,

00:22:12,260 --> 00:22:16,400
then you simply simply await on calls to the service that you're using.

00:22:16,400 --> 00:22:18,240
There's no magic here.

00:22:18,240 --> 00:22:20,620
You simply do the same thing as you would do in the blocking world,

00:22:20,620 --> 00:22:22,880
just prepend it with asyncio.

00:22:22,880 --> 00:22:24,840
Same thing with calling subprocesses.

00:22:24,840 --> 00:22:26,800
We do it quite often.

00:22:26,800 --> 00:22:29,220
The API is pretty obvious here.

00:22:29,220 --> 00:22:34,880
What I very often like to point out to people is this thing:

00:22:34,880 --> 00:22:37,880
You should be letting know that your subprocesses

00:22:37,880 --> 00:22:40,660
should die with the parent.

00:22:40,660 --> 00:22:42,620
You do it like this.

00:22:42,620 --> 00:22:45,400
It's just a few magic lines in ctypes.

00:22:45,410 --> 00:22:49,040
But actually, it tells the kernel, "If you're using Linux, OK,

00:22:49,040 --> 00:22:51,580
"if the parent dies, the children die with it."

00:22:51,580 --> 00:22:53,720
That's useful for production.

00:22:54,520 --> 00:22:56,560
Speaking of signal handling,

00:22:56,560 --> 00:22:59,080
obviously asyncio support setting signal handlers

00:22:59,080 --> 00:23:01,490
for all of the things -- use it.

00:23:01,490 --> 00:23:06,080
So, actually using asyncio for quite a while now,

00:23:06,080 --> 00:23:10,560
I think it's going to be a year in two weeks

00:23:10,570 --> 00:23:14,230
since we deployed our first service on asyncio.

00:23:15,100 --> 00:23:17,120
Let me tell you this:

00:23:17,120 --> 00:23:21,120
Just using Python 3.5 is much nicer to use with asyncio

00:23:21,120 --> 00:23:23,140
and much nicer in general,

00:23:23,140 --> 00:23:27,020
so don't bother with 3.3, don't bother with 3.4.

00:23:27,030 --> 00:23:30,700
It's more complicated for you and the syntax is horrific,

00:23:30,700 --> 00:23:34,880
and there's less opportunities for nice debugging.

00:23:34,880 --> 00:23:37,640
Garbage collection, specifically, is better.

00:23:37,640 --> 00:23:40,740
So, that's one of the recommendations.

00:23:40,750 --> 00:23:43,010
The other recommendation is obvious, right?

00:23:43,010 --> 00:23:45,690
Everybody knows it, and nobody does it... at least enough.

00:23:45,690 --> 00:23:47,620
[laughter]

00:23:47,630 --> 00:23:50,770
But really, with asyncio, suddenly you realize that,

00:23:50,770 --> 00:23:53,880
"My threaded application that had, like, this massive state

00:23:53,880 --> 00:23:56,549
"and I didn't know what it's doing,"

00:23:56,549 --> 00:23:58,580
suddenly you just have a few coroutines,

00:23:58,580 --> 00:24:01,429
and you can just tell to the loop, "Just execute this guy."

00:24:01,429 --> 00:24:03,560
And at the end of that execution, you can check,

00:24:03,560 --> 00:24:05,520
"Hey are there any other coroutines

00:24:05,520 --> 00:24:08,320
that end up being there for some reason?"

00:24:08,320 --> 00:24:10,680
So, it's much easier to write a unit test for asyncio

00:24:10,690 --> 00:24:12,690
than there would be for a threaded application.

00:24:12,690 --> 00:24:14,640
You can mock out coroutines easily.

00:24:14,640 --> 00:24:16,620
You can just tell to the loop,

00:24:16,620 --> 00:24:18,480
"Just run this one thing until complete,"

00:24:18,480 --> 00:24:20,260
so, there's just no excuse.

00:24:20,260 --> 00:24:22,200
For some reason, I find that very often

00:24:22,200 --> 00:24:24,320
people would be terrified about the prospect

00:24:24,320 --> 00:24:27,040
of opening a new empty file and writing class,

00:24:27,040 --> 00:24:29,039
you know, or whatever test case.

00:24:29,039 --> 00:24:33,799
For some reason, that's considered a massive psychological block.

00:24:33,800 --> 00:24:35,680
But it only takes a minute.

00:24:35,680 --> 00:24:37,460
There's no excuse; do it.

00:24:37,460 --> 00:24:39,220
Set up debugging.

00:24:39,220 --> 00:24:41,900
As I said, asyncio is very, very friendly,

00:24:41,900 --> 00:24:44,590
explaining what you're doing wrong if you let it.

00:24:44,590 --> 00:24:46,550
So, a few things that you can do.

00:24:46,550 --> 00:24:48,590
Set up logging if you need it.

00:24:48,590 --> 00:24:50,550
It's very verbose, but you can do that.

00:24:50,550 --> 00:24:52,380
Set up the GC debugging

00:24:52,380 --> 00:24:54,160
in which case, you're going to see, like,

00:24:54,160 --> 00:24:55,960
"Hey, I did something horribly wrong

00:24:55,960 --> 00:24:58,500
"and suddenly I have a lot of uncollectable items,"

00:24:58,500 --> 00:25:01,460
and at the end, you can just set the loop to debug

00:25:01,470 --> 00:25:04,770
which is the equivalent of "pythonasynciodebug=1,"

00:25:04,770 --> 00:25:06,870
in which case, it's going to start telling you all those things

00:25:06,870 --> 00:25:10,120
about coroutines being left when you're shutting down

00:25:10,120 --> 00:25:11,920
and stuff like this.

00:25:11,920 --> 00:25:13,940
So again, this sort of thing.

00:25:13,940 --> 00:25:15,780
One particular example

00:25:15,780 --> 00:25:17,540
that I found a little frustrating at first,

00:25:17,540 --> 00:25:20,529
was just instantiating a coroutine function to a coroutine

00:25:20,529 --> 00:25:23,009
but not awaiting on it, really.

00:25:23,009 --> 00:25:24,880
Again, asyncio is really friendly.

00:25:24,880 --> 00:25:27,000
It's going to tell you,

00:25:27,000 --> 00:25:29,020
"Hey, you had instantiated some coroutines,

00:25:29,020 --> 00:25:30,940
"and never awaited on them.

00:25:30,950 --> 00:25:33,020
"Is that OK?"

00:25:33,020 --> 00:25:35,280
It's not, but you're going to know about this.

00:25:35,720 --> 00:25:40,220
So again, Coroutines are based internally on generators.

00:25:40,220 --> 00:25:43,080
You don't have to know about this now, but they are.

00:25:43,080 --> 00:25:46,280
So, stop using StopIteration.

00:25:46,280 --> 00:25:48,040
This is wrong.

00:25:48,040 --> 00:25:49,880
This is going to cause trouble for you.

00:25:49,880 --> 00:25:53,160
But in Python 3, as I said, there's many nice things about it.

00:25:53,169 --> 00:25:55,309
It can just return from a generator.

00:25:55,309 --> 00:25:57,549
It's awesome; do it -- it does the right thing.

00:25:58,440 --> 00:26:00,220
I like to prefer ProcessPool executors

00:26:00,220 --> 00:26:02,890
even though they have inherent costs to start with,

00:26:02,890 --> 00:26:04,640
but at least they're known

00:26:04,640 --> 00:26:06,460
and there's no surprises with the GIL.

00:26:06,470 --> 00:26:08,210
Those GIL surprises are the worst,

00:26:08,210 --> 00:26:10,430
because it takes a while to debug those.

00:26:11,140 --> 00:26:14,340
I hope that I convinced you to just read the docs

00:26:14,340 --> 00:26:17,169
and read the source, because it's pretty clear.

00:26:17,169 --> 00:26:22,849
There is a reason why Guido named asyncio a reference implementation.

00:26:22,849 --> 00:26:24,849
So do it.

00:26:24,849 --> 00:26:26,680
One last thought:

00:26:26,690 --> 00:26:29,789
In Python 3.4, when asyncio was introduced,

00:26:29,789 --> 00:26:32,789
you had coroutines expressed as a decorator,

00:26:32,789 --> 00:26:34,729
and you had to use "yield-from."

00:26:34,729 --> 00:26:37,549
No longer; now you have this nice syntax.

00:26:37,549 --> 00:26:40,160
But you still might experience some code

00:26:40,160 --> 00:26:43,840
that is using coroutines and "yield-from."

00:26:43,840 --> 00:26:46,720
OK, I used images.

00:26:46,720 --> 00:26:48,520
My name is Łukasz Langa.

00:26:48,520 --> 00:26:50,300
That was Thinking in Coroutines.

00:26:50,300 --> 00:26:52,160
Thank you very much.

00:26:52,160 --> 00:26:58,100
[applause]

00:26:59,340 --> 00:27:01,220
(presenter) Thank you Łukasz.

00:27:01,220 --> 00:27:03,760
We have no time for Q and A on this session,

00:27:03,760 --> 00:27:05,900
but Łukasz said you just go and talk to him

00:27:05,900 --> 00:27:07,860
if you have any questions.

00:27:07,860 --> 00:27:10,920
And the next session is going to start at 11:30 sharp.

00:27:10,920 --> 00:27:12,780
Thank you, and thank you again Łukasz.

00:27:12,780 --> 00:27:14,540

YouTube URL: https://www.youtube.com/watch?v=l4Nn-y9ktd4


