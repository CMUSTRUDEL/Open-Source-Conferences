Title: Nina Zakharenko - Memory Management in Python - The Basics - PyCon 2016
Publication date: 2016-05-31
Playlist: PyCon 2016
Description: 
	Speaker: Nina Zakharenko

As a new python developer, do you find memory management in Python confusing? Come to this talk to learn about the basics of how Memory Management works in Python. We'll cover the concepts of reference counting, garbage collection, weak references, __slots__, and the Global Interpreter Lock.

Slides can be found at: https://speakerdeck.com/pycon2016 and https://github.com/PyCon/2016-slides
Captions: 
	00:00:00,690 --> 00:00:02,650
(moderator) Hello everybody.

00:00:02,650 --> 00:00:04,780
Our next session is about memory management in Python.

00:00:04,790 --> 00:00:07,710
Please welcome Nina Zakharenko.

00:00:07,710 --> 00:00:14,310
[applause]

00:00:15,940 --> 00:00:18,260
(Nina Zakharenko) Hi everyone, thank you so much

00:00:18,270 --> 00:00:19,850
for coming to this talk.

00:00:19,850 --> 00:00:22,770
My name is Nina and I've been programming professionally

00:00:22,770 --> 00:00:24,650
for about 10 years now

00:00:24,650 --> 00:00:27,870
in a variety of different programming languages.

00:00:27,870 --> 00:00:29,540
When I’m not writing code

00:00:29,540 --> 00:00:32,619
you'll probably find me snowboarding or mountain biking.

00:00:32,619 --> 00:00:35,269
But let's go ahead and deep dive into the basics

00:00:35,269 --> 00:00:37,309
of memory management in Python.

00:00:38,420 --> 00:00:42,339
So, first off, why should you care?

00:00:42,339 --> 00:00:45,829
Well, knowing about memory management is going to help you write

00:00:45,829 --> 00:00:47,979
more efficient code

00:00:47,979 --> 00:00:51,190
and that knowledge is going to help you solve problems

00:00:51,190 --> 00:00:52,760
with slow programs.

00:00:52,760 --> 00:00:56,280
It's going to help you troubleshoot, and it's really going to help you debug.

00:00:56,280 --> 00:00:58,760
Sometimes you really want to answer this question:

00:00:58,760 --> 00:01:01,500
why is my program taking up so much memory?

00:01:01,500 --> 00:01:04,980
And why is that memory usage increasing over time?

00:01:04,980 --> 00:01:08,220
I’m going to give you the tools to help you answer that question,

00:01:08,220 --> 00:01:11,440
and as a bonus, writing more efficient programs

00:01:11,440 --> 00:01:13,900
makes you look pretty darn smart.

00:01:15,580 --> 00:01:17,990
So what are you going to get today?

00:01:17,990 --> 00:01:20,480
We're going to get a vocabulary.

00:01:20,480 --> 00:01:22,260
You want to know more about the topic

00:01:22,260 --> 00:01:24,660
but it can be easy to get overwhelmed.

00:01:24,670 --> 00:01:27,440
Sometimes you're just faced with too much information

00:01:27,440 --> 00:01:30,830
and too much new terminology so we're going to cover

00:01:30,830 --> 00:01:32,730
the basic concepts.

00:01:34,320 --> 00:01:37,080
My goal is to make this topic more understandable,

00:01:37,080 --> 00:01:39,450
even if you're just starting out,

00:01:39,450 --> 00:01:41,770
and I’m going to do that by giving you a foundation.

00:01:43,320 --> 00:01:45,900
What are you not going to get?

00:01:45,900 --> 00:01:49,220
Well, you're not going to be an expert at the end of this talk.

00:01:49,220 --> 00:01:51,980
That's the downside of the thousand-foot overview

00:01:51,980 --> 00:01:53,540
and that's okay.

00:01:53,540 --> 00:01:56,470
For the experts in this room, though, a quick disclaimer:

00:01:56,470 --> 00:01:58,650
My talk applies to CPython only.

00:02:00,560 --> 00:02:04,170
So in order to really understand memory management in Python,

00:02:04,170 --> 00:02:07,110
we need to get a little bit philosophical and ask ourselves,

00:02:07,110 --> 00:02:08,780
what is a variable?

00:02:08,789 --> 00:02:12,250
A variable is a container that can store different variables --

00:02:12,250 --> 00:02:14,960
or different values.

00:02:14,960 --> 00:02:17,690
So in this example we have a C-style variable.

00:02:17,690 --> 00:02:20,120
It’s a very simplified example.

00:02:20,120 --> 00:02:23,200
So here, we need to declare the type of that variable

00:02:23,200 --> 00:02:25,040
before its assignment.

00:02:25,040 --> 00:02:30,000
And that's because these variables live in memory like this.

00:02:32,400 --> 00:02:35,700
They live in a fixed-sized bucket.

00:02:35,700 --> 00:02:38,730
And that bucket can only hold the same-sized value

00:02:38,730 --> 00:02:40,730
or an overflow can occur.

00:02:41,640 --> 00:02:47,640
When we change our C-style variable, so later on we say a=6,

00:02:47,650 --> 00:02:50,709
what's happening is that the data in that memory location

00:02:50,709 --> 00:02:52,740
gets overwritten.

00:02:52,740 --> 00:02:57,880
So now it's 6 and our old value is blown away.

00:02:59,080 --> 00:03:01,260
Now here's a big idea.

00:03:01,260 --> 00:03:04,880
Python has names, not variables.

00:03:06,680 --> 00:03:09,820
How are Python objects stored in memory?

00:03:09,820 --> 00:03:14,000
Well, we have names, we have references,

00:03:14,010 --> 00:03:16,760
and we have objects.

00:03:16,760 --> 00:03:20,490
And name is just a label for an object.

00:03:20,490 --> 00:03:24,290
And each object can have lots of names.

00:03:24,290 --> 00:03:26,810
Those names reference that object.

00:03:28,600 --> 00:03:31,640
We have two different types of objects.

00:03:31,640 --> 00:03:35,080
We have simple objects like numbers and strings.

00:03:35,080 --> 00:03:37,020
Those simple objects are just that;

00:03:37,020 --> 00:03:39,400
they store their own value.

00:03:39,400 --> 00:03:42,780
Each simple object is generally stored in memory once.

00:03:44,050 --> 00:03:47,600
We also have container objects like dictionaries, lists,

00:03:47,600 --> 00:03:49,090
and user-defined classes.

00:03:49,090 --> 00:03:51,800
Those container objects store references

00:03:51,800 --> 00:03:55,240
to either simple objects or other containers.

00:03:56,500 --> 00:03:58,300
So what's a reference?

00:03:58,300 --> 00:04:01,599
A reference is a name or a container object

00:04:01,599 --> 00:04:04,779
that points at another object.

00:04:04,780 --> 00:04:06,660
What's a reference count?

00:04:06,670 --> 00:04:09,330
It's the number of references that you have.

00:04:11,600 --> 00:04:13,680
How do we increase the reference count?

00:04:13,700 --> 00:04:17,580
In this example, we're setting the name x to be 300.

00:04:18,800 --> 00:04:22,120
That increases the number of references by 1.

00:04:23,380 --> 00:04:27,100
Later on, we say y = 300.

00:04:27,120 --> 00:04:30,830
Instead of creating a new slot in memory for that 300,

00:04:30,830 --> 00:04:33,199
we're just adding another reference to it.

00:04:33,199 --> 00:04:35,739
So now our reference count is 2.

00:04:37,850 --> 00:04:42,000
In this example we have z, a list, a container object

00:04:42,000 --> 00:04:48,180
that has 2 more references to 300, so now our reference count is 4.

00:04:50,740 --> 00:04:53,400
How do we decrease the reference count?

00:04:53,400 --> 00:04:57,340
One way is with using the del statement.

00:04:57,340 --> 00:05:01,720
So, in this example, we’ve removed the reference

00:05:01,721 --> 00:05:03,540
from x to 300.

00:05:03,540 --> 00:05:05,540
Now we have the one from y.

00:05:06,580 --> 00:05:09,910
What exactly does the del statement do?

00:05:09,910 --> 00:05:13,550
Well, it does not delete objects.

00:05:13,550 --> 00:05:18,050
It, instead, will remove that name as a reference

00:05:18,050 --> 00:05:20,290
to that object.

00:05:20,290 --> 00:05:22,400
And what does that do?

00:05:22,400 --> 00:05:24,420
Reduces the reference count by 1.

00:05:27,860 --> 00:05:30,320
Another way that we can decrease the reference count

00:05:30,330 --> 00:05:33,030
is by changing the reference.

00:05:33,030 --> 00:05:36,880
So in this example, if I set y to none,

00:05:36,880 --> 00:05:39,360
I’m going to remove that reference.

00:05:39,370 --> 00:05:43,490
Now the reference count of 300 is potentially 0.

00:05:43,490 --> 00:05:45,560
Once there are no more references,

00:05:45,560 --> 00:05:48,790
we don't really care if that object still exists.

00:05:48,790 --> 00:05:51,150
It can be safely removed from memory later on.

00:05:52,820 --> 00:05:54,919
So put it in the trash.

00:05:54,919 --> 00:05:57,860
One more way of decreasing reference counts

00:05:57,860 --> 00:05:59,919
is going out of scope.

00:05:59,919 --> 00:06:03,740
So if I have this really simple program

00:06:03,740 --> 00:06:07,199
and I run it, as that --

00:06:07,199 --> 00:06:09,350
if I have the simple function and I run it,

00:06:09,350 --> 00:06:12,790
as this function is running, inside of that function

00:06:12,790 --> 00:06:16,000
the reference count of the word 'seven'

00:06:16,000 --> 00:06:18,370
increases by one.

00:06:18,370 --> 00:06:22,650
After that function has exited, that word 'seven'

00:06:22,650 --> 00:06:25,479
is now out of scope, so the reference count

00:06:25,479 --> 00:06:27,539
goes down by one.

00:06:27,540 --> 00:06:29,520
The final way that a reference count

00:06:29,520 --> 00:06:31,930
can go down is when the program exits.

00:06:31,930 --> 00:06:34,450
We have no more references.

00:06:35,450 --> 00:06:39,419
So local vs. global namespace.

00:06:39,419 --> 00:06:41,610
If that reference count is going to decrease

00:06:41,610 --> 00:06:45,570
when an object goes out of scope, what can happen with objects

00:06:45,570 --> 00:06:47,740
in a global namespace?

00:06:47,740 --> 00:06:51,310
Well, they might never go out of scope

00:06:51,310 --> 00:06:54,190
and their reference count might never be zero.

00:06:55,430 --> 00:06:58,930
So the trick here is to avoid putting larger complex objects

00:06:58,930 --> 00:07:00,710
in that global namespace.

00:07:00,710 --> 00:07:03,180
And if you do, make sure you clean them up,

00:07:03,180 --> 00:07:07,560
either by changing the reference or by calling a del on them.

00:07:11,080 --> 00:07:16,120
Internally, every Python object holds three things:

00:07:16,120 --> 00:07:21,120
its type, its value, and its reference count.

00:07:23,360 --> 00:07:30,300
So in our previous example, we had two names: x and y.

00:07:30,300 --> 00:07:33,280
That gives us two references

00:07:35,480 --> 00:07:38,120
to one object.

00:07:39,990 --> 00:07:42,729
So we have a object here,

00:07:42,729 --> 00:07:46,160
it's -- it knows its type, it knows it's an integer,

00:07:46,160 --> 00:07:50,580
it knows that its refcount is 2 and it knows that its value is 300.

00:07:51,860 --> 00:07:54,020
Let's take a little bit of a peek under the hood.

00:07:54,030 --> 00:07:56,919
And as a warning, don't try this example

00:07:56,919 --> 00:08:00,579
in the interactive environment or the REPL.

00:08:02,100 --> 00:08:06,410
So if I have my x and y equal to 300,

00:08:06,410 --> 00:08:10,569
we can take a peek and see what memory location

00:08:10,569 --> 00:08:14,629
the object lives at by using the identity function, ID.

00:08:16,020 --> 00:08:20,320
If we compare the memory location of x and y,

00:08:20,320 --> 00:08:22,860
we’ll see that it's the same.

00:08:24,610 --> 00:08:28,729
I can also ask Python, "Does this object live

00:08:28,729 --> 00:08:32,640
"in the same memory location?" by using the is keyword.

00:08:32,640 --> 00:08:39,040
So if I ask Python, "Is x y?" I'll see that it's true.

00:08:40,430 --> 00:08:43,669
So now we can talk about garbage collection.

00:08:43,669 --> 00:08:46,540
What is garbage collection?

00:08:46,540 --> 00:08:48,779
You can think of it as a way for your program

00:08:48,779 --> 00:08:53,670
to automatically release memory when the object that's taking up

00:08:53,670 --> 00:08:57,660
that memory is no longer in use.

00:08:57,660 --> 00:09:01,000
Back in the day programmers had to allocate and deallocate

00:09:01,000 --> 00:09:02,820
their memory manually,

00:09:02,820 --> 00:09:05,260
and, spoiler alert, it really kind of sucked.

00:09:05,260 --> 00:09:08,970
If you forgot to free your memory, it can cause memory leaks.

00:09:08,970 --> 00:09:11,570
If you accidentally overwrote your memory,

00:09:11,570 --> 00:09:14,330
your program could totally crash.

00:09:14,330 --> 00:09:17,520
Garbage collection came in to the rescue.

00:09:17,520 --> 00:09:22,740
I like to think of garbage collection as memory recycling.

00:09:22,740 --> 00:09:26,000
There are two main types of garbage collection,

00:09:26,010 --> 00:09:31,180
the first being reference counting, the second being tracing.

00:09:31,180 --> 00:09:33,720
In a way, Python uses both.

00:09:33,720 --> 00:09:37,180
So how does reference counting garbage collection work?

00:09:37,180 --> 00:09:39,980
Well, we add and remove references.

00:09:39,980 --> 00:09:42,900
That refcount is increased with every assignment.

00:09:42,900 --> 00:09:46,660
Refcount is decreased when that reference is removed.

00:09:47,940 --> 00:09:50,980
When the refcount reaches zero, we can go ahead

00:09:50,980 --> 00:09:53,600
and just immediately delete that object.

00:09:53,600 --> 00:09:55,660
We know that we have no use for it.

00:09:56,780 --> 00:10:00,600
And that causes an interesting cascading effect

00:10:00,610 --> 00:10:05,630
because when you do decrease the refcount of any objects

00:10:05,630 --> 00:10:09,350
that that deleted object was pointing to,

00:10:09,350 --> 00:10:12,990
if their refcount reaches zero, you can delete them as well.

00:10:12,990 --> 00:10:16,290
So one refcount reaching zero can mean lots of objects

00:10:16,290 --> 00:10:18,030
being deleted from memory.

00:10:20,060 --> 00:10:21,620
So the good thing

00:10:21,620 --> 00:10:23,519
about reference counting garbage collection

00:10:23,519 --> 00:10:29,490
is that it's pretty easy to implement, and when that refcount is zero,

00:10:29,490 --> 00:10:32,260
those objects are immediately deleted.

00:10:32,260 --> 00:10:34,500
But it has some downsides.

00:10:36,780 --> 00:10:39,459
There's a lot of space overhead involved, right?

00:10:39,459 --> 00:10:42,779
So when your reference count is stored for every object,

00:10:44,040 --> 00:10:50,400
that data has to live somewhere, and there's execution overhead too,

00:10:50,410 --> 00:10:54,250
because that reference count is changed on every assignment.

00:10:55,960 --> 00:10:58,500
And unfortunately, there's a pretty ugly side

00:10:58,510 --> 00:11:00,620
to reference counting as well.

00:11:00,620 --> 00:11:03,990
It's not generally thread safe,

00:11:03,990 --> 00:11:09,750
and reference counting garbage collection does not detect cyclical references.

00:11:13,350 --> 00:11:16,269
So what is a cyclical reference?

00:11:16,269 --> 00:11:18,529
Let's talk about it by example.

00:11:18,529 --> 00:11:23,440
Here we have a node class and it contains a value

00:11:23,440 --> 00:11:26,200
and a reference to the next node.

00:11:28,820 --> 00:11:34,440
We declare a root node, a left node, and a right node.

00:11:34,450 --> 00:11:38,120
Then we point our root node at left,

00:11:38,120 --> 00:11:40,610
we point our left node at right,

00:11:40,610 --> 00:11:43,920
and we point our right node back at left.

00:11:43,920 --> 00:11:45,840
What does that look like?

00:11:47,440 --> 00:11:52,060
The reference count of root is 1, it’s referred to by the name root.

00:11:52,060 --> 00:11:54,370
The reference count of left is 3,

00:11:54,370 --> 00:11:58,350
it's referred to by its name, the root, and the right node.

00:11:58,350 --> 00:12:00,829
And the reference count of right is 2,

00:12:00,829 --> 00:12:05,260
it's referred to by its name and by the left node.

00:12:05,260 --> 00:12:08,829
So a cycle occurs when we have two objects that point

00:12:08,829 --> 00:12:11,509
or refer to each other.

00:12:16,230 --> 00:12:20,769
What happens when we remove the names as references

00:12:20,769 --> 00:12:22,769
to these nodes?

00:12:23,960 --> 00:12:29,000
Well, we removed the names but the internal references,

00:12:29,010 --> 00:12:33,589
that next, is still there, so the reference count of root

00:12:33,589 --> 00:12:38,680
is 0, but the reference count of left and right remains 1

00:12:38,680 --> 00:12:42,140
because those two nodes refer to each other.

00:12:45,640 --> 00:12:49,620
Reference counting alone does not garbage collect objects

00:12:49,630 --> 00:12:51,530
with cyclical references.

00:12:52,360 --> 00:12:57,720
And early Python implementation was only refcount-based

00:12:57,730 --> 00:13:02,040
and that caused lots of problems because many types of objects

00:13:02,040 --> 00:13:07,390
can have cyclical references, like graphs or doubly-linked lists.

00:13:07,390 --> 00:13:09,880
And early on we realized that we really needed

00:13:09,880 --> 00:13:11,480
something else.

00:13:12,880 --> 00:13:15,870
So there are two main types of garbage collection.

00:13:15,870 --> 00:13:17,760
We talked about reference counting.

00:13:17,760 --> 00:13:21,500
The second type is a strategy called tracing.

00:13:21,500 --> 00:13:26,100
Tracing generally uses an algorithm called mark and sweep.

00:13:27,540 --> 00:13:34,019
The first step is marking any objects that are reachable.

00:13:34,019 --> 00:13:39,579
So we start at a root node and then we follow

00:13:39,579 --> 00:13:45,060
all the references and we mark the live ones.

00:13:45,060 --> 00:13:48,339
This algorithm gets run when the number of objects in memory

00:13:48,339 --> 00:13:50,559
is greater than a certain threshold.

00:13:51,950 --> 00:13:54,079
The next step is sweep.

00:13:54,079 --> 00:13:56,680
So when marking is done,

00:13:56,680 --> 00:14:00,140
the sweep phase will remove the dead objects.

00:14:00,140 --> 00:14:03,860
Cyclical references get deleted with this algorithm too.

00:14:04,940 --> 00:14:07,000
Which one does Python use?

00:14:07,000 --> 00:14:09,100
We know it uses reference counting,

00:14:09,100 --> 00:14:13,100
but it also uses a strategy called generational.

00:14:13,100 --> 00:14:16,760
Generational is a type of tracing garbage collection.

00:14:16,760 --> 00:14:19,180
And, remember, we need another strategy

00:14:19,180 --> 00:14:21,110
because reference counting doesn't clean up

00:14:21,110 --> 00:14:23,430
those dangling cyclical references.

00:14:25,180 --> 00:14:29,260
Generational garbage collection is based on this theory

00:14:29,269 --> 00:14:33,989
that most objects die young, and really, how tragic.

00:14:35,700 --> 00:14:39,600
Frequently we create objects to store temporary values

00:14:39,610 --> 00:14:44,990
or they're used in one function call and never really get used again.

00:14:44,990 --> 00:14:47,870
So how does generational garbage collection work?

00:14:47,870 --> 00:14:52,200
Well, Python will maintain a list of every object created

00:14:52,200 --> 00:14:54,240
as a program is run.

00:14:54,240 --> 00:14:58,330
Actually, it goes ahead and creates three lists.

00:14:58,330 --> 00:15:02,750
They're called generation 0, 1, and 2.

00:15:02,750 --> 00:15:05,320
Newly created objects are going to be stored

00:15:05,320 --> 00:15:07,850
in generation 0.

00:15:07,850 --> 00:15:11,240
Each object is only stored in one generation,

00:15:11,240 --> 00:15:15,310
and we optimize by collecting young objects in generation 0

00:15:15,310 --> 00:15:17,670
more frequently than the old.

00:15:17,670 --> 00:15:22,529
Now remember that only container objects with a reference count greater than zero

00:15:22,529 --> 00:15:25,150
are stored in these generational lists.

00:15:25,150 --> 00:15:28,350
So, similar to mark and sweep, but instead of keeping

00:15:28,350 --> 00:15:31,899
a list of all the objects, we only keep the ones

00:15:31,899 --> 00:15:34,100
with those active references.

00:15:34,100 --> 00:15:37,000
That means that fewer objects are tracked and scanned.

00:15:38,500 --> 00:15:40,800
When the number of objects in a generation

00:15:40,800 --> 00:15:44,550
reaches a particular threshold, Python will run

00:15:44,550 --> 00:15:47,060
a generational garbage collection algorithm

00:15:47,060 --> 00:15:49,820
on that generation and any generations

00:15:49,820 --> 00:15:51,139
younger than it.

00:15:51,139 --> 00:15:53,950
So when we run on generation 2, we're actually collecting

00:15:53,950 --> 00:15:57,050
on generation 0, 1, and 2.

00:15:58,440 --> 00:16:03,839
During that garbage collection cycle, Python makes a list of objects to discard.

00:16:03,839 --> 00:16:07,410
It runs an algorithm, that is out of scope for this talk,

00:16:07,410 --> 00:16:09,600
to detect those cyclical references.

00:16:09,600 --> 00:16:12,400
Then, if an object has no outside references,

00:16:12,410 --> 00:16:13,980
it's put on a discard list.

00:16:13,980 --> 00:16:17,380
And, when that cycle is done, it's going to free up the objects

00:16:17,380 --> 00:16:19,320
on that discard list.

00:16:22,440 --> 00:16:26,180
After our garbage collection cycle, objects that survived

00:16:26,190 --> 00:16:29,170
will be promoted to the next generation.

00:16:31,050 --> 00:16:33,930
So objects that are in the last generation,

00:16:33,930 --> 00:16:36,620
generation 2, are those that are going to stay there

00:16:36,630 --> 00:16:38,870
as the program executes.

00:16:42,230 --> 00:16:45,810
A big idea here is that, when the refcount reaches zero,

00:16:45,810 --> 00:16:48,400
we get an immediate cleanup.

00:16:48,400 --> 00:16:52,420
But if we have objects with cycles,

00:16:52,420 --> 00:16:56,400
we are going to need for garbage collection to run,

00:16:56,410 --> 00:16:58,870
and in order to do that, we have to wait.

00:17:00,260 --> 00:17:03,460
So if you have those cyclical references,

00:17:03,460 --> 00:17:06,539
it could potentially slow your program down.

00:17:06,539 --> 00:17:08,679
They could really be a culprit.

00:17:10,400 --> 00:17:13,840
So, some reference counting gotchas.

00:17:17,440 --> 00:17:21,320
Reference counting is not generally thread safe.

00:17:21,329 --> 00:17:25,640
And we're going to see why that's a big deal later on,

00:17:25,640 --> 00:17:30,489
because what happens if two threads try to increase

00:17:30,489 --> 00:17:37,100
and decrease the reference count of one object at the same time?

00:17:37,100 --> 00:17:39,960
We might end up with a pretty big problem.

00:17:42,560 --> 00:17:47,460
If we remember our reference cycle from before,

00:17:47,460 --> 00:17:50,490
we had a node left and a node right.

00:17:50,490 --> 00:17:54,659
They retain their reference counts of 1.

00:17:54,659 --> 00:17:57,639
Those cyclical references are going to get cleaned up

00:17:57,639 --> 00:18:00,379
by generational garbage collection.

00:18:02,920 --> 00:18:12,139
Except in Python 2, if your class declares --

00:18:12,139 --> 00:18:15,359
or has a dunder del method --

00:18:16,700 --> 00:18:18,360
Gotcha!

00:18:18,360 --> 00:18:24,000
Thankfully this is fixed as of Python 3.4.

00:18:24,009 --> 00:18:27,829
Now what is the dunder del magic method?

00:18:29,060 --> 00:18:31,700
Sometimes it's called a destructor.

00:18:33,300 --> 00:18:36,580
It is not the del statement.

00:18:36,590 --> 00:18:42,529
So del x does not call the magic method dunder del.

00:18:42,529 --> 00:18:46,700
The del statement decrements the reference count of x --

00:18:46,700 --> 00:18:49,840
er, your object by 1.

00:18:49,840 --> 00:18:56,440
And the dunder del magic method is only called

00:18:56,440 --> 00:19:02,929
when the reference count of that object reaches zero.

00:19:02,929 --> 00:19:06,989
So we run it before an object is removed from memory.

00:19:08,419 --> 00:19:12,149
If you're using Python 2, this is a pretty big gotcha.

00:19:12,149 --> 00:19:15,409
You can end up with lots of crud in memory.

00:19:16,840 --> 00:19:19,240
So keep a watchful eye out.

00:19:24,600 --> 00:19:30,179
One strategy that we can use to improve our memory usage

00:19:30,179 --> 00:19:32,450
is called slots.

00:19:32,450 --> 00:19:34,530
So what are slots?

00:19:39,210 --> 00:19:42,859
We know that every Python instance contains a dictionary

00:19:42,860 --> 00:19:44,920
of its names and values.

00:19:47,160 --> 00:19:52,659
So if I print the dunder dict of my dog class here,

00:19:52,659 --> 00:19:57,899
we’ll see that it has a key name and a value, buddy.

00:19:57,900 --> 00:20:01,100
Slots turn the internals of an object

00:20:01,109 --> 00:20:04,279
from a dictionary to a tuple.

00:20:04,279 --> 00:20:07,239
What's important about tuples?

00:20:07,239 --> 00:20:12,099
Tuples are immutable, meaning that they can't be changed.

00:20:15,040 --> 00:20:20,760
So slots prevent us from setting names on instances willy-nilly.

00:20:20,760 --> 00:20:24,940
And some of us have probably -- well, I’m gonna say all of us

00:20:24,950 --> 00:20:27,809
have definitely seen this exception before.

00:20:27,809 --> 00:20:32,779
What happens if we try to set a name on the string, Pug?

00:20:32,779 --> 00:20:35,820
What exception are we going to get?

00:20:35,820 --> 00:20:37,680
It's going to be an attribute error.

00:20:37,680 --> 00:20:39,600
Python is going to complain at us and say,

00:20:39,600 --> 00:20:43,540
"Well, this string object doesn't have an attribute name."

00:20:43,549 --> 00:20:45,609
Makes sense, right?

00:20:46,889 --> 00:20:49,629
We can use slots to emulate this behavior

00:20:49,629 --> 00:20:51,609
in our own classes.

00:20:52,680 --> 00:20:55,380
So, I have this class Point.

00:20:55,380 --> 00:20:58,560
I declare the slots to be x and y.

00:20:59,840 --> 00:21:02,160
What is the type of slots?

00:21:03,480 --> 00:21:05,240
A tuple.

00:21:06,250 --> 00:21:09,720
The only attributes we can set on this class

00:21:09,720 --> 00:21:11,760
are those that we define in slots.

00:21:13,710 --> 00:21:18,570
So I can set my x and y on an instance of point,

00:21:18,570 --> 00:21:24,020
but what happens if I try to assign a name to my point?

00:21:24,020 --> 00:21:27,940
I’m going to see one of those attribute errors, right?

00:21:27,940 --> 00:21:30,900
My point doesn't have an internal dictionary.

00:21:34,260 --> 00:21:37,440
Now, why is this important?

00:21:37,450 --> 00:21:42,309
Well, let's take a look of the size in memory

00:21:42,309 --> 00:21:45,019
of a dictionary versus a tuple.

00:21:45,019 --> 00:21:50,789
We can use the getsizeof function to return the size in bytes

00:21:50,789 --> 00:21:52,909
for built-in types.

00:21:54,499 --> 00:21:58,889
So the size of a dictionary in bytes is,

00:21:58,889 --> 00:22:02,299
in my implementation of Python, 288 bytes.

00:22:02,299 --> 00:22:05,840
But the size of a tuple is 48 bytes.

00:22:05,840 --> 00:22:12,009
Now that's not a huge difference for one instance, right?

00:22:12,009 --> 00:22:15,650
But it really adds up when there are lots of instances.

00:22:15,650 --> 00:22:18,279
So when would we want to use slots?

00:22:18,279 --> 00:22:23,539
Well, if we're going to be creating lots of instances of a class,

00:22:23,539 --> 00:22:26,999
they might be worthwhile, and if we know in advance

00:22:26,999 --> 00:22:30,059
what properties that class should have.

00:22:32,529 --> 00:22:35,919
Now let's talk about the elephant in the room,

00:22:35,919 --> 00:22:38,699
or in this case, the shark.

00:22:38,700 --> 00:22:40,500
What’s a GIL?

00:22:44,520 --> 00:22:48,120
A GIL is a Global Interpreter Lock.

00:22:48,120 --> 00:22:51,580
A global interpreter lock prevents multiple Python threads

00:22:51,590 --> 00:22:55,259
from executing Python code at the same time.

00:22:55,259 --> 00:22:59,279
So there's one GIL for each interpreter.

00:22:59,279 --> 00:23:01,539
In other words, two Python programs

00:23:01,539 --> 00:23:04,399
running on one machine don't share a GIL.

00:23:05,540 --> 00:23:10,159
So one thread can run in their interpreter at a time.

00:23:10,159 --> 00:23:13,409
Why does Python need this interpreter lock?

00:23:13,409 --> 00:23:15,580
We need to prevent reference counts

00:23:15,580 --> 00:23:18,450
from being changed concurrently.

00:23:18,450 --> 00:23:20,919
What happens if two threads try to increase

00:23:20,919 --> 00:23:25,129
and decrease the reference count of an object at the same time?

00:23:25,129 --> 00:23:29,209
Those operations might not happen in order,

00:23:29,209 --> 00:23:31,709
and that's a big problem.

00:23:31,710 --> 00:23:33,979
The advantages and disadvantages of the GIL?

00:23:33,979 --> 00:23:36,269
Well, the upside is that we get

00:23:36,269 --> 00:23:39,210
a fast and simple garbage collection algorithm,

00:23:39,210 --> 00:23:41,919
but the downside is a Python program,

00:23:41,919 --> 00:23:45,820
no matter how many threads exist in that Python program,

00:23:45,820 --> 00:23:49,559
only one thread will be executed at a time.

00:23:49,559 --> 00:23:52,759
So if we want to take advantage of multiple CPUs,

00:23:52,759 --> 00:23:56,950
we want to use multi-processing instead of multi-threading.

00:23:56,950 --> 00:23:59,349
Each process will have its own GIL.

00:23:59,349 --> 00:24:02,239
And it's on the developer to figure out the best way

00:24:02,239 --> 00:24:05,639
to share information between those processes.

00:24:08,279 --> 00:24:10,739
So if the GIL limits us in this way,

00:24:10,740 --> 00:24:12,779
can't we just remove it?

00:24:12,779 --> 00:24:16,850
Well, the GIL is a bag of snakes.

00:24:16,850 --> 00:24:19,389
It's caused a lot of infighting in the Python community,

00:24:19,389 --> 00:24:21,759
as you may or may not be aware.

00:24:21,759 --> 00:24:26,549
In an early version of Python, about 1.5, a patch was submitted

00:24:26,549 --> 00:24:28,040
that removed the GIL.

00:24:28,040 --> 00:24:30,920
And, spoiler alert, it didn't really go well.

00:24:30,929 --> 00:24:36,540
It sped up multithreaded application and that's a good thing, right?

00:24:36,540 --> 00:24:40,279
Well, it also slowed down single-threaded applications

00:24:40,279 --> 00:24:43,179
by about 50%.

00:24:43,180 --> 00:24:46,599
So, for better or for worse, the GIL is here to stay.

00:24:46,599 --> 00:24:49,369
In the meantime, the Python code base has become

00:24:49,369 --> 00:24:53,729
significantly more complex since that patch was introduced.

00:24:53,729 --> 00:24:57,519
Just be aware that not all Python implementations have a GIL.

00:24:57,519 --> 00:25:00,619
For example, Jython and IronPython.

00:25:02,620 --> 00:25:04,700
Sorry guys, deal with it.

00:25:06,220 --> 00:25:08,600
So what did we learn today?

00:25:09,920 --> 00:25:13,040
Garbage collection is pretty good, right?

00:25:13,049 --> 00:25:15,489
It's way better than doing it manually in C.

00:25:15,489 --> 00:25:17,509
But it's not a magic wand.

00:25:17,509 --> 00:25:21,549
It adds overhead in terms of execution time and space

00:25:21,549 --> 00:25:25,700
and it still doesn't prevent us from being inefficient.

00:25:25,700 --> 00:25:29,409
So now you know how memory is managed in Python.

00:25:29,409 --> 00:25:31,389
You're familiar with the concepts.

00:25:31,389 --> 00:25:33,870
Please keep learning and exploring.

00:25:33,870 --> 00:25:37,590
It'll help you write better, faster, more efficient code.

00:25:37,590 --> 00:25:39,800
There's a lot that I didn't cover

00:25:39,809 --> 00:25:43,149
so I added a bonus section in my slides with links

00:25:43,149 --> 00:25:44,880
to additional resources.

00:25:44,880 --> 00:25:46,620
I'll give you a link to the slides

00:25:46,620 --> 00:25:49,020
at the end of my talk.

00:25:49,020 --> 00:25:51,140
Consider Python 3.

00:25:51,660 --> 00:25:53,280
It's better.

00:25:53,289 --> 00:25:55,020
It's an active development.

00:25:55,020 --> 00:25:59,679
There is a better GIL implementation that's more efficient.

00:25:59,679 --> 00:26:02,509
And remember that problem that we had with destructors?

00:26:02,509 --> 00:26:08,559
Well, Python 3 can call those destructors on objects with cyclical references.

00:26:08,559 --> 00:26:10,659
And these are just some of the many reasons

00:26:10,659 --> 00:26:12,499
to make the switch.

00:26:13,560 --> 00:26:19,040
Or for scientific applications, consider NumPy and Pandas.

00:26:19,049 --> 00:26:21,159
These packages are optimized to work

00:26:21,159 --> 00:26:23,249
with large numeric data structures

00:26:23,249 --> 00:26:25,739
and don't suffer from some of the same problems

00:26:25,739 --> 00:26:27,859
that we saw here.

00:26:27,860 --> 00:26:30,100
Thank you guys so much for your time.

00:26:30,100 --> 00:26:38,580
[applause]

00:26:38,580 --> 00:26:40,580
(moderator) Thank you, Nina.

00:26:40,580 --> 00:26:43,220
We have time for one question only.

00:26:43,220 --> 00:26:45,520
Please raise your hand, be brave.

00:26:49,440 --> 00:26:51,980
Ah, it’s great to see everybody’s totally an expert

00:26:51,980 --> 00:26:53,700
on memory management now.

00:26:53,700 --> 00:26:55,380
Thank you, Nina.

00:26:55,380 --> 00:26:59,480

YouTube URL: https://www.youtube.com/watch?v=F6u5rhUQ6dU


