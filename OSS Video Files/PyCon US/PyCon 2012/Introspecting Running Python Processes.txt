Title: Introspecting Running Python Processes
Publication date: 2012-04-29
Playlist: PyCon 2012
Description: 
	Adam Lowry
Understanding the internal state of a running system can be vital to maintaining a high performance, stable system, but conventional approaches such as logging and error handling only expose so much. This talk will touch on how to instrume
Captions: 
	00:00:00,000 --> 00:00:06,089
our next stroke is a soda minute stroke

00:00:02,159 --> 00:00:07,830
including questions and Adam Lowry will

00:00:06,089 --> 00:00:10,500
tell us about introspecting running

00:00:07,830 --> 00:00:11,790
pison processes Adam borrower is with

00:00:10,500 --> 00:00:17,340
the startup maybe you can say something

00:00:11,790 --> 00:00:19,529
about himself thank you so my name is

00:00:17,340 --> 00:00:21,660
Adam Lowry i'm a co-founder and

00:00:19,529 --> 00:00:23,640
developer at urban airship we provide

00:00:21,660 --> 00:00:26,510
services for mobile application

00:00:23,640 --> 00:00:28,050
developers my colleague Michael shorter

00:00:26,510 --> 00:00:29,609
Schmeichel as you might know

00:00:28,050 --> 00:00:31,170
unfortunately couldn't be here with me

00:00:29,609 --> 00:00:33,239
but you worked on this talk with me and

00:00:31,170 --> 00:00:37,440
you can trust him because just look at

00:00:33,239 --> 00:00:39,390
that beard and here is a picture of my

00:00:37,440 --> 00:00:42,239
goal in a Colombian drug runners

00:00:39,390 --> 00:00:43,500
submarine so just to get that going so

00:00:42,239 --> 00:00:46,770
what I want to talk to you about today

00:00:43,500 --> 00:00:48,719
is what is your application doing what

00:00:46,770 --> 00:00:53,579
is your service doing right now while

00:00:48,719 --> 00:00:55,410
you're in this talk do you know within

00:00:53,579 --> 00:00:57,390
the application but especially with

00:00:55,410 --> 00:00:59,550
high-performance applications you need

00:00:57,390 --> 00:01:01,500
to know what's going on so how do you

00:00:59,550 --> 00:01:03,359
know that say your web application is

00:01:01,500 --> 00:01:05,880
behaving as you expect you might have a

00:01:03,359 --> 00:01:09,020
monitor the hits at once a minute you

00:01:05,880 --> 00:01:12,630
have logs you have error e-mail or

00:01:09,020 --> 00:01:15,450
another set of error structures but you

00:01:12,630 --> 00:01:17,490
are sort of estimating based on other

00:01:15,450 --> 00:01:19,110
knowledge if everything ground to a halt

00:01:17,490 --> 00:01:21,509
without any change you made could you

00:01:19,110 --> 00:01:23,159
identify the problem and that's very

00:01:21,509 --> 00:01:25,259
difficult unless you instrument and

00:01:23,159 --> 00:01:27,450
expose the internal data of your

00:01:25,259 --> 00:01:32,549
application all you can do is guess

00:01:27,450 --> 00:01:34,170
about the causes of the event so to

00:01:32,549 --> 00:01:35,430
start out to get a little bit of

00:01:34,170 --> 00:01:38,340
background we can talk about logging

00:01:35,430 --> 00:01:40,500
which you can consider your applications

00:01:38,340 --> 00:01:42,299
diary you have an extreme of expected

00:01:40,500 --> 00:01:43,740
events and you're you're throwing

00:01:42,299 --> 00:01:46,229
everything to disk everything is being

00:01:43,740 --> 00:01:50,610
persisted in the new processes search as

00:01:46,229 --> 00:01:53,270
as needed but logging does have some

00:01:50,610 --> 00:01:58,710
downsides when you get into extremes

00:01:53,270 --> 00:02:00,360
verbosity if you have a slow request can

00:01:58,710 --> 00:02:02,579
you tell why it was slow if you had a

00:02:00,360 --> 00:02:04,680
traceback or a 500 do you have enough of

00:02:02,579 --> 00:02:07,500
the local state in order to reproduce it

00:02:04,680 --> 00:02:09,450
or to tell what's going on and the

00:02:07,500 --> 00:02:12,870
operational burden can be extremely

00:02:09,450 --> 00:02:13,890
large even though there are certainly

00:02:12,870 --> 00:02:16,890
ways to

00:02:13,890 --> 00:02:19,860
work around that actually did have one

00:02:16,890 --> 00:02:24,060
case where a syslog d was the bottleneck

00:02:19,860 --> 00:02:25,770
in an application so it can happen but

00:02:24,060 --> 00:02:27,450
this logging is still vital for auditing

00:02:25,770 --> 00:02:28,910
and reference and a bunch of other uses

00:02:27,450 --> 00:02:32,310
so you want to keep all what you've got

00:02:28,910 --> 00:02:34,230
there are some ways you could call

00:02:32,310 --> 00:02:36,690
breaking in through the back door and

00:02:34,230 --> 00:02:39,060
this is digging into your application in

00:02:36,690 --> 00:02:41,640
some way that may not be entirely safe

00:02:39,060 --> 00:02:44,340
or entirely appropriate there was an

00:02:41,640 --> 00:02:46,560
awesome talk here I think was last year

00:02:44,340 --> 00:02:49,410
on gdb heap digging into memory itself

00:02:46,560 --> 00:02:51,209
there are back door modules where you

00:02:49,410 --> 00:02:53,790
can attach a rebel to a running process

00:02:51,209 --> 00:02:56,070
or well that you have the capability

00:02:53,790 --> 00:02:57,330
built into it then lid has one so it

00:02:56,070 --> 00:02:58,800
spawns a green thread and you can

00:02:57,330 --> 00:03:02,100
actually poke your python process around

00:02:58,800 --> 00:03:04,680
or poke around in an interpreter and the

00:03:02,100 --> 00:03:06,420
what actually the bugger is is a great

00:03:04,680 --> 00:03:09,239
example of what you could do when you

00:03:06,420 --> 00:03:11,280
have that power it you in development

00:03:09,239 --> 00:03:12,780
you have a 500 page or something you can

00:03:11,280 --> 00:03:16,230
poke around at every level the stack and

00:03:12,780 --> 00:03:18,060
even use the repple to to investigate

00:03:16,230 --> 00:03:19,860
what's going on but all these things

00:03:18,060 --> 00:03:21,350
they have trade-offs and in general you

00:03:19,860 --> 00:03:24,209
wouldn't say they're for production use

00:03:21,350 --> 00:03:25,950
so just take a little step back I want

00:03:24,209 --> 00:03:28,590
to look at what we're missing when we

00:03:25,950 --> 00:03:30,480
use a python applications it

00:03:28,590 --> 00:03:31,860
particularly want to look at the JVM

00:03:30,480 --> 00:03:34,079
that's what I'm most familiar with

00:03:31,860 --> 00:03:36,540
outside of Python it's also what a lot

00:03:34,079 --> 00:03:39,120
of people that are writing services are

00:03:36,540 --> 00:03:42,150
using these days so take a look at the

00:03:39,120 --> 00:03:43,739
Java management extensions any library

00:03:42,150 --> 00:03:47,370
application can expose a set of

00:03:43,739 --> 00:03:50,070
interfaces reading is not language

00:03:47,370 --> 00:03:52,410
agnostic but you can expose this data

00:03:50,070 --> 00:03:54,450
via HTTP and Jason and that is a

00:03:52,410 --> 00:03:57,150
terrible screenshots kind of blurry I'm

00:03:54,450 --> 00:04:00,320
sorry what you see on the right on the

00:03:57,150 --> 00:04:02,579
left is a hierarchy of of packages there

00:04:00,320 --> 00:04:04,200
have information that you can pull out

00:04:02,579 --> 00:04:07,470
and on the right as attributes and

00:04:04,200 --> 00:04:09,329
values and any class or library can

00:04:07,470 --> 00:04:11,010
expose these values the communication is

00:04:09,329 --> 00:04:14,280
actually two way you can put information

00:04:11,010 --> 00:04:16,859
back in or call methods but this is sort

00:04:14,280 --> 00:04:18,239
of you get this for free with the JVM

00:04:16,859 --> 00:04:20,940
and it's traditionally used for

00:04:18,239 --> 00:04:22,710
resources consumption or system

00:04:20,940 --> 00:04:25,260
monitoring but anything can make use of

00:04:22,710 --> 00:04:27,420
it in this program that we're looking at

00:04:25,260 --> 00:04:30,990
jconsole is a GUI to can

00:04:27,420 --> 00:04:34,020
to a running JVM and see what is going

00:04:30,990 --> 00:04:37,590
on and so we were poking around at jmx

00:04:34,020 --> 00:04:39,300
attributes before but this is the is

00:04:37,590 --> 00:04:41,490
just looking at some system information

00:04:39,300 --> 00:04:43,830
there's the the heat memory usage you

00:04:41,490 --> 00:04:46,170
got that nice happy sawtooth graph and

00:04:43,830 --> 00:04:47,700
so this machine is pretty good but this

00:04:46,170 --> 00:04:49,470
can be incredibly useful when you have a

00:04:47,700 --> 00:04:51,360
machine that's behaving somewhat badly

00:04:49,470 --> 00:04:53,250
you could point this at it and see

00:04:51,360 --> 00:04:54,630
what's going on without knowing ahead of

00:04:53,250 --> 00:04:56,460
time what you're looking for you have

00:04:54,630 --> 00:04:59,130
all this instrumentation available to

00:04:56,460 --> 00:05:02,430
you the third one doesn't look as nice

00:04:59,130 --> 00:05:04,980
but a J stack it really is just a

00:05:02,430 --> 00:05:06,900
sending a signal to the JVM and then it

00:05:04,980 --> 00:05:08,820
dumps out the output of every running

00:05:06,900 --> 00:05:11,610
thread right now so that you can look at

00:05:08,820 --> 00:05:14,250
exactly what each thread is doing as

00:05:11,610 --> 00:05:18,750
it's going and this is probably the most

00:05:14,250 --> 00:05:21,000
boring stack trace in the world but you

00:05:18,750 --> 00:05:23,070
get the idea when something bad is going

00:05:21,000 --> 00:05:24,780
on this can give you a huge amount of

00:05:23,070 --> 00:05:27,180
information and it's what is being

00:05:24,780 --> 00:05:29,040
processed right at that moment not what

00:05:27,180 --> 00:05:31,290
activities have finished and have been

00:05:29,040 --> 00:05:34,500
logged and this is built into the

00:05:31,290 --> 00:05:37,200
runtime the last thing is not really

00:05:34,500 --> 00:05:39,120
something that is built into the JVM but

00:05:37,200 --> 00:05:41,190
it's it's a more of a cultural thing

00:05:39,120 --> 00:05:43,080
because these tools for retrieving

00:05:41,190 --> 00:05:45,540
information is good but you have to have

00:05:43,080 --> 00:05:47,670
good instrumentation in order to expose

00:05:45,540 --> 00:05:50,220
the right data and metrics is a library

00:05:47,670 --> 00:05:52,620
for instrument in your application all

00:05:50,220 --> 00:05:55,890
data data is exposed by jmx or

00:05:52,620 --> 00:05:59,130
optionally with HTTP and but it's not

00:05:55,890 --> 00:06:01,380
just the tools it's a there's a mindset

00:05:59,130 --> 00:06:02,550
that knowledge about what is going on

00:06:01,380 --> 00:06:05,820
inside the application is crucial to

00:06:02,550 --> 00:06:08,160
operations and that mindset gives you a

00:06:05,820 --> 00:06:09,300
lot more power when there is when our

00:06:08,160 --> 00:06:11,840
events are when you doing capacity

00:06:09,300 --> 00:06:14,420
planning or other things of that nature

00:06:11,840 --> 00:06:16,830
so I highly recommend there's this

00:06:14,420 --> 00:06:19,200
presentation there a coda Hales of

00:06:16,830 --> 00:06:20,460
metrics echoed conf and it's an

00:06:19,200 --> 00:06:22,710
extremely good presentation you haven't

00:06:20,460 --> 00:06:24,540
already seen it no matter that a jmx day

00:06:22,710 --> 00:06:27,300
that we looked at before these are this

00:06:24,540 --> 00:06:31,320
is actually a metrics exposed a bit of

00:06:27,300 --> 00:06:32,520
data on a running system so these are

00:06:31,320 --> 00:06:35,310
measurements that are collected by it

00:06:32,520 --> 00:06:37,860
and this is reporting a particular set

00:06:35,310 --> 00:06:40,980
of calls and how long in the taking like

00:06:37,860 --> 00:06:42,420
the 50 percentile through 99th is taking

00:06:40,980 --> 00:06:44,700
one millisecond so that's pretty good

00:06:42,420 --> 00:06:47,220
and it's only at the 999 that it bumps

00:06:44,700 --> 00:06:49,890
up so we can be confident that this

00:06:47,220 --> 00:06:51,780
machine is running pretty well with a

00:06:49,890 --> 00:06:53,130
variety of instruments with a variety of

00:06:51,780 --> 00:06:54,920
measurements you get up more confidence

00:06:53,130 --> 00:06:58,680
that your system is behaving as you

00:06:54,920 --> 00:07:01,080
wanted to oh and here's one more bit of

00:06:58,680 --> 00:07:03,630
jconsole connected to jmx my colleague

00:07:01,080 --> 00:07:05,250
lucky wanted you to see this one minute

00:07:03,630 --> 00:07:07,080
graph down the bottom so there's the one

00:07:05,250 --> 00:07:09,120
minute rate of activity and you just

00:07:07,080 --> 00:07:10,740
clicked on that and then it started

00:07:09,120 --> 00:07:12,390
graphing from that point so you can see

00:07:10,740 --> 00:07:15,990
the change while you're watching it

00:07:12,390 --> 00:07:18,240
right then so given that they have these

00:07:15,990 --> 00:07:20,220
different capabilities what do we have

00:07:18,240 --> 00:07:21,600
available to us and a couple of

00:07:20,220 --> 00:07:22,980
approaches that that some people are

00:07:21,600 --> 00:07:24,750
working on is one is a new relic of

00:07:22,980 --> 00:07:26,700
course which they there's a lot of the

00:07:24,750 --> 00:07:28,890
guys here and they have a fantastic

00:07:26,700 --> 00:07:31,230
system for doing a web app hosted web

00:07:28,890 --> 00:07:32,910
application monitoring and because

00:07:31,230 --> 00:07:34,710
they're here in I think they're in expo

00:07:32,910 --> 00:07:37,650
hall you should go get a demo from them

00:07:34,710 --> 00:07:40,110
and see what they can do in graphite I

00:07:37,650 --> 00:07:43,050
know a lot of people are using these

00:07:40,110 --> 00:07:45,270
days it's a scalable graphing system for

00:07:43,050 --> 00:07:47,400
time series data so you poke data at it

00:07:45,270 --> 00:07:50,100
and it gives you some graphs of of

00:07:47,400 --> 00:07:51,420
what's going on and as a nice python

00:07:50,100 --> 00:07:54,330
library for sending data to it from

00:07:51,420 --> 00:07:55,770
inside your application what I'd like to

00:07:54,330 --> 00:07:57,120
do that now though is talk about a few

00:07:55,770 --> 00:08:00,390
ways Michael and I've been working to

00:07:57,120 --> 00:08:02,820
instrument our Python processes the

00:08:00,390 --> 00:08:05,610
first is a socket console which is a

00:08:02,820 --> 00:08:07,920
terrible name and I apologize what I

00:08:05,610 --> 00:08:09,810
wanted was Jay stack and I wanted for

00:08:07,920 --> 00:08:11,310
for Python I talked to a bunch of people

00:08:09,810 --> 00:08:12,720
and a lot of and a lot of people I talk

00:08:11,310 --> 00:08:16,260
to you they had done this before but it

00:08:12,720 --> 00:08:17,820
hadn't been they hadn't codified

00:08:16,260 --> 00:08:20,430
codified and there were some trouble

00:08:17,820 --> 00:08:22,770
with it we have a mix of web services

00:08:20,430 --> 00:08:24,240
and non web services running Python I

00:08:22,770 --> 00:08:26,070
wanted something to work the same on on

00:08:24,240 --> 00:08:28,080
all of them and I wanted something that

00:08:26,070 --> 00:08:30,210
didn't require a fighting or too much

00:08:28,080 --> 00:08:32,820
configuration so what soccer council

00:08:30,210 --> 00:08:35,099
does is it you launch it inside your

00:08:32,820 --> 00:08:36,150
application creates a eunuch socket so

00:08:35,099 --> 00:08:38,940
that way you don't have to fight over

00:08:36,150 --> 00:08:40,680
HTTP ports or anything and then you can

00:08:38,940 --> 00:08:43,349
read when you read from that socket you

00:08:40,680 --> 00:08:44,850
pull down the stack trace so the goals

00:08:43,349 --> 00:08:46,620
of this when I came into it is I want to

00:08:44,850 --> 00:08:49,740
work a multi-process and multi-threaded

00:08:46,620 --> 00:08:51,360
apps no configuration pretty much heb

00:08:49,740 --> 00:08:53,300
ports as I mentioned that can be a real

00:08:51,360 --> 00:08:55,519
pain to manage if each process

00:08:53,300 --> 00:08:57,920
is going to have its own HTTP port then

00:08:55,519 --> 00:08:59,630
if you got 90 some processes or you have

00:08:57,920 --> 00:09:02,630
a dynamic ones like a really difficult

00:08:59,630 --> 00:09:04,370
to keep that all together and also

00:09:02,630 --> 00:09:05,839
didn't want to use any unix signals just

00:09:04,370 --> 00:09:07,580
because I didn't want trust that every

00:09:05,839 --> 00:09:09,560
application or library that I was

00:09:07,580 --> 00:09:13,310
instrumenting handled interruptions

00:09:09,560 --> 00:09:17,000
correctly so quick little demo what this

00:09:13,310 --> 00:09:19,160
one does or example this is a very silly

00:09:17,000 --> 00:09:21,709
little script it starts up four threads

00:09:19,160 --> 00:09:24,170
and in the main thread it calls this

00:09:21,709 --> 00:09:27,800
waiter and the waiter calculates a

00:09:24,170 --> 00:09:30,769
random value and sleeps forever or 500

00:09:27,800 --> 00:09:34,220
seconds and the socket console launches

00:09:30,769 --> 00:09:36,680
what kicks that off kicks off the sorry

00:09:34,220 --> 00:09:40,339
the thread that is going to do the it

00:09:36,680 --> 00:09:42,980
exposes the stack trace information if

00:09:40,339 --> 00:09:44,570
this was a web app like the the main

00:09:42,980 --> 00:09:47,959
whiskey startup would be a good place to

00:09:44,570 --> 00:09:49,579
do that so here's the output socket

00:09:47,959 --> 00:09:50,870
reader is a shortcut for communicating

00:09:49,579 --> 00:09:55,339
with each of those socket process

00:09:50,870 --> 00:09:57,529
there's socket files so we pull down the

00:09:55,339 --> 00:09:59,420
stack trace I edited the paths just for

00:09:57,529 --> 00:10:04,459
clarity but you can see that both of

00:09:59,420 --> 00:10:05,930
those threads are are sleeping and you

00:10:04,459 --> 00:10:08,690
can see the local values that are there

00:10:05,930 --> 00:10:10,310
currently now this is because this is

00:10:08,690 --> 00:10:11,959
such a contrived example I don't think

00:10:10,310 --> 00:10:13,459
it really gets to how useful that can be

00:10:11,959 --> 00:10:15,730
so here's one that does a little bit

00:10:13,459 --> 00:10:17,899
more work it's just a tiny script that

00:10:15,730 --> 00:10:20,899
connects via sequel alchemy to a

00:10:17,899 --> 00:10:23,570
postgres test test database and execute

00:10:20,899 --> 00:10:26,480
PG sleep which is just sleep for 15

00:10:23,570 --> 00:10:30,890
seconds and that's just long enough for

00:10:26,480 --> 00:10:32,600
me to run the the socket reader now the

00:10:30,890 --> 00:10:34,520
stack trace on this is not very useful

00:10:32,600 --> 00:10:36,020
we know what it's doing because of the

00:10:34,520 --> 00:10:39,410
size of the script but the locals are

00:10:36,020 --> 00:10:42,020
pretty neat because it just has so

00:10:39,410 --> 00:10:43,790
happened that the statement is in a

00:10:42,020 --> 00:10:46,670
local variable we know the exact

00:10:43,790 --> 00:10:48,470
statement that is running and we've seen

00:10:46,670 --> 00:10:49,820
this happen for free where we just think

00:10:48,470 --> 00:10:53,269
on this servers being a little slow

00:10:49,820 --> 00:10:55,519
let's poke this at it and oh a lot of

00:10:53,269 --> 00:10:58,430
these are doing this this query let's go

00:10:55,519 --> 00:11:02,209
see on the database if that is backing

00:10:58,430 --> 00:11:03,860
up there both of these examples are

00:11:02,209 --> 00:11:05,590
basically frozen threads but it works

00:11:03,860 --> 00:11:06,850
even when there's a lot of churn and

00:11:05,590 --> 00:11:11,710
lot of activity not just when it's

00:11:06,850 --> 00:11:14,080
totally stopped up next is a library

00:11:11,710 --> 00:11:17,050
written by Michael shorter the colleague

00:11:14,080 --> 00:11:18,550
Imogen before called in stats or mm

00:11:17,050 --> 00:11:22,660
stats he hasn't decided how to pronounce

00:11:18,550 --> 00:11:24,490
it it to provide a subset of what jmx

00:11:22,660 --> 00:11:28,060
can be used for to pull information out

00:11:24,490 --> 00:11:29,950
and we've bouncing around some ideas for

00:11:28,060 --> 00:11:31,690
for taglines the proc file system for

00:11:29,950 --> 00:11:34,630
your application is kind of the best one

00:11:31,690 --> 00:11:36,700
for the the Linux heads we want to

00:11:34,630 --> 00:11:38,920
expose any data that we can calculate in

00:11:36,700 --> 00:11:40,360
a way that's easy to consume we didn't

00:11:38,920 --> 00:11:42,190
want the writing depend on any framework

00:11:40,360 --> 00:11:43,450
or any particular library in Python and

00:11:42,190 --> 00:11:46,690
we want the reading to be able to be

00:11:43,450 --> 00:11:49,690
done from any language whatsoever so

00:11:46,690 --> 00:11:53,050
what it does is it a it exposes a memory

00:11:49,690 --> 00:11:55,360
mapped file for each for each in general

00:11:53,050 --> 00:11:57,340
each thread a as long as there's one

00:11:55,360 --> 00:11:58,630
writer and in the memory map file

00:11:57,340 --> 00:12:00,640
there's a language-independent data

00:11:58,630 --> 00:12:02,860
structure you've got a series of fields

00:12:00,640 --> 00:12:06,790
of whatever kind you want and exposed in

00:12:02,860 --> 00:12:09,840
Python as a model class his goals behind

00:12:06,790 --> 00:12:12,100
this was trying to make a simple API and

00:12:09,840 --> 00:12:14,230
very importantly having a predictable

00:12:12,100 --> 00:12:16,870
and mostly minimal or minimal

00:12:14,230 --> 00:12:18,220
performance impact because you don't

00:12:16,870 --> 00:12:20,290
want your monitoring system or your

00:12:18,220 --> 00:12:21,610
instrumentation to be to actually become

00:12:20,290 --> 00:12:23,650
a bottleneck in your application and

00:12:21,610 --> 00:12:24,940
then to separate the writing and reading

00:12:23,650 --> 00:12:27,340
which is useful in a heterogeneous

00:12:24,940 --> 00:12:29,020
architecture and our environment and

00:12:27,340 --> 00:12:30,340
when you have an ops team that is very

00:12:29,020 --> 00:12:33,700
good at their jobs they want to use

00:12:30,340 --> 00:12:36,120
whatever they can use so as I said

00:12:33,700 --> 00:12:38,560
before it's a single rider multi reader

00:12:36,120 --> 00:12:40,870
which helps us bypass some needs for

00:12:38,560 --> 00:12:43,990
locks when you're updating fields

00:12:40,870 --> 00:12:45,640
there's no system calls so even that is

00:12:43,990 --> 00:12:47,740
a little bit more predictable it stays

00:12:45,640 --> 00:12:49,210
in the user space and a reading doesn't

00:12:47,740 --> 00:12:55,990
have any impact on what the writers are

00:12:49,210 --> 00:12:57,610
doing let's just see an example NC

00:12:55,990 --> 00:13:01,720
window so here is another stupid script

00:12:57,610 --> 00:13:03,880
I excel at those the it increments up to

00:13:01,720 --> 00:13:05,560
a thousand in updates encounter and I

00:13:03,880 --> 00:13:08,140
guess it sleeps for a random amount of

00:13:05,560 --> 00:13:09,910
time and I'm keating ahold of some stats

00:13:08,140 --> 00:13:13,810
while I do this Hank are maintained uh

00:13:09,910 --> 00:13:15,160
counters and that's about it so I have

00:13:13,810 --> 00:13:16,480
this data is now exposed in this memory

00:13:15,160 --> 00:13:17,980
mapped file what are some of the ways I

00:13:16,480 --> 00:13:24,400
could pull out

00:13:17,980 --> 00:13:27,190
data these two tools are the simplest

00:13:24,400 --> 00:13:29,440
ways to work with it one is slurp stats

00:13:27,190 --> 00:13:32,080
which just pulls from a list of memory

00:13:29,440 --> 00:13:34,630
mapped files which would look which

00:13:32,080 --> 00:13:36,100
would be any number of writers there any

00:13:34,630 --> 00:13:37,870
number of threads or process or whatever

00:13:36,100 --> 00:13:39,610
you're doing and just dumps all the

00:13:37,870 --> 00:13:41,590
metrics it can find we just use that for

00:13:39,610 --> 00:13:44,170
testing sometimes but we have put that

00:13:41,590 --> 00:13:47,260
into a watch command just to see it go

00:13:44,170 --> 00:13:50,770
over time and then pull stats is really

00:13:47,260 --> 00:13:52,300
really simple it just till shows you the

00:13:50,770 --> 00:13:55,450
difference between counters once a

00:13:52,300 --> 00:13:59,020
second and no nothing's going to win any

00:13:55,450 --> 00:14:01,270
beauty awards with it but it uh it does

00:13:59,020 --> 00:14:03,160
have its own use and these simple ones

00:14:01,270 --> 00:14:05,560
especially can be useful for one-off

00:14:03,160 --> 00:14:06,610
scripts I mean doing some data migration

00:14:05,560 --> 00:14:08,170
or something it's going to run for a

00:14:06,610 --> 00:14:10,360
couple hours but if you can just take

00:14:08,170 --> 00:14:12,190
some time and expose the metrics ahead

00:14:10,360 --> 00:14:13,420
of time then you don't have to worry

00:14:12,190 --> 00:14:15,550
whether you got your print statements

00:14:13,420 --> 00:14:19,570
correct like every 10,000 operations you

00:14:15,550 --> 00:14:21,040
printed a dot or whatnot but to go to

00:14:19,570 --> 00:14:27,430
another reader that's a little bit more

00:14:21,040 --> 00:14:30,130
useful in mash is just a it is a web

00:14:27,430 --> 00:14:32,950
server that you give it a settings file

00:14:30,130 --> 00:14:35,470
of where any applications might be that

00:14:32,950 --> 00:14:37,930
are exposing this data it goes and finds

00:14:35,470 --> 00:14:39,940
them exposes all of the the counters

00:14:37,930 --> 00:14:42,730
there are all the the metrics that

00:14:39,940 --> 00:14:46,180
you've created so the first two on the

00:14:42,730 --> 00:14:47,920
top there the the counter or the the

00:14:46,180 --> 00:14:49,810
localhost just shows from that counter

00:14:47,920 --> 00:14:52,690
application what's going on and I can

00:14:49,810 --> 00:14:53,950
dig into the counter but the two on the

00:14:52,690 --> 00:14:55,570
bottom are a little more interesting

00:14:53,950 --> 00:14:59,200
that's from one of our running systems

00:14:55,570 --> 00:15:01,540
where the we have a I don't know like

00:14:59,200 --> 00:15:03,010
two dozen processes on this one machine

00:15:01,540 --> 00:15:05,320
maybe three dozen and they're all

00:15:03,010 --> 00:15:08,320
reporting how many jobs they're

00:15:05,320 --> 00:15:10,630
processing at any one time and so I can

00:15:08,320 --> 00:15:15,190
view them all individually or sum them

00:15:10,630 --> 00:15:16,990
up with a simple aggregator now at this

00:15:15,190 --> 00:15:19,840
point we've we've been able to expose

00:15:16,990 --> 00:15:21,940
data in a pretty easy way and we're

00:15:19,840 --> 00:15:24,820
confident in the way that it that are

00:15:21,940 --> 00:15:27,940
that we can write that data out but it's

00:15:24,820 --> 00:15:28,810
only useful now if we go and look at it

00:15:27,940 --> 00:15:31,610
so

00:15:28,810 --> 00:15:34,190
talking with the ops team and how we we

00:15:31,610 --> 00:15:37,340
do it we want to integrate this with the

00:15:34,190 --> 00:15:40,940
rest of our operations system so we use

00:15:37,340 --> 00:15:42,980
a single and the nagios fork for

00:15:40,940 --> 00:15:45,710
monitoring and p and people now give us

00:15:42,980 --> 00:15:47,420
to graph a lot of that data so this is a

00:15:45,710 --> 00:15:50,000
check that pulls on that aggregated data

00:15:47,420 --> 00:15:51,440
about successes we saw last time and so

00:15:50,000 --> 00:15:53,120
we have a nice graph and because this

00:15:51,440 --> 00:15:55,070
goes because it's a sort of agnostic

00:15:53,120 --> 00:15:57,740
format nagios is reading all that in we

00:15:55,070 --> 00:16:01,940
can perform checks on any of the the

00:15:57,740 --> 00:16:04,550
metrics or they either the the data that

00:16:01,940 --> 00:16:06,950
we're pulling out and it goes next to

00:16:04,550 --> 00:16:08,060
all of the graphs that were graphs in

00:16:06,950 --> 00:16:12,200
checks that were doing for every other

00:16:08,060 --> 00:16:14,750
part of our system and because our ops

00:16:12,200 --> 00:16:17,000
team is so great anyways they using

00:16:14,750 --> 00:16:18,350
whatever tools they like and here they

00:16:17,000 --> 00:16:20,690
have a graph where they've pulled

00:16:18,350 --> 00:16:22,970
multiple hosts exposing that same sort

00:16:20,690 --> 00:16:25,280
of data and put all together and at this

00:16:22,970 --> 00:16:27,800
point because they have a heterogeneous

00:16:25,280 --> 00:16:28,910
architecture they earn we have a

00:16:27,800 --> 00:16:31,010
monitoring system that works across

00:16:28,910 --> 00:16:33,350
heterogeneous architecture they can make

00:16:31,010 --> 00:16:35,990
a dashboard with this data and related

00:16:33,350 --> 00:16:37,670
servers and related data stores and

00:16:35,990 --> 00:16:40,010
other things so we get a holistic view

00:16:37,670 --> 00:16:43,690
of what's going on right now with the

00:16:40,010 --> 00:16:43,690
related set of services and applications

00:16:43,900 --> 00:16:55,580
so with within stats and a socket

00:16:51,140 --> 00:16:57,760
console where this is very early in

00:16:55,580 --> 00:16:59,660
their lifetime because this is sort of a

00:16:57,760 --> 00:17:02,120
practical problem we're approaching

00:16:59,660 --> 00:17:04,160
we're looking for practical solutions we

00:17:02,120 --> 00:17:05,450
talked to everybody that's that we meet

00:17:04,160 --> 00:17:07,630
about how they're approaching these

00:17:05,450 --> 00:17:09,620
problems and everyone sort of got

00:17:07,630 --> 00:17:11,420
different approaches in different

00:17:09,620 --> 00:17:12,710
different tools and so one of the

00:17:11,420 --> 00:17:14,960
greatest things we've been doing is

00:17:12,710 --> 00:17:16,850
talking if people in learning about what

00:17:14,960 --> 00:17:19,760
can we put together to make this more

00:17:16,850 --> 00:17:21,260
easily or make this more make it

00:17:19,760 --> 00:17:23,570
applications easier to instrument and

00:17:21,260 --> 00:17:25,520
make them more useful to pull out data

00:17:23,570 --> 00:17:27,350
so they're more field to do more

00:17:25,520 --> 00:17:28,610
measurement styles especially some of

00:17:27,350 --> 00:17:33,110
the more advanced ones that are in the

00:17:28,610 --> 00:17:34,760
metrics library and more readers and

00:17:33,110 --> 00:17:36,410
examples and plug-ins for common

00:17:34,760 --> 00:17:39,320
libraries so that we could just drop

00:17:36,410 --> 00:17:41,390
these into existing services without too

00:17:39,320 --> 00:17:42,720
much configuration the unified web

00:17:41,390 --> 00:17:46,150
interface idea is that

00:17:42,720 --> 00:17:47,710
if we have a web service that takes an

00:17:46,150 --> 00:17:49,150
easy configuration file we pointed the

00:17:47,710 --> 00:17:50,650
various applications then you've got a

00:17:49,150 --> 00:17:52,960
dashboard for all of your Python

00:17:50,650 --> 00:17:55,180
processes on one machine and that can be

00:17:52,960 --> 00:17:56,950
pretty useful and now I want to talk

00:17:55,180 --> 00:17:58,750
especially about a couple efforts that

00:17:56,950 --> 00:18:00,670
have been going on in parallel that are

00:17:58,750 --> 00:18:04,210
public and open source one is scales

00:18:00,670 --> 00:18:06,460
which is a parallel to a lot of things

00:18:04,210 --> 00:18:08,920
we're doing with emm stats it's come a

00:18:06,460 --> 00:18:11,380
long way since in the last few months it

00:18:08,920 --> 00:18:12,910
supports a variety of metrics you answer

00:18:11,380 --> 00:18:14,950
made your Python applications and data

00:18:12,910 --> 00:18:17,590
is exported either by an in-process web

00:18:14,950 --> 00:18:19,810
server or periodically by pushing the

00:18:17,590 --> 00:18:22,630
graphite and I'd say the primary

00:18:19,810 --> 00:18:25,180
difference in philosophy under is under

00:18:22,630 --> 00:18:27,430
the hood not in the external where it

00:18:25,180 --> 00:18:30,250
does require locking and the thread port

00:18:27,430 --> 00:18:31,900
/ process but I highly recommend

00:18:30,250 --> 00:18:33,580
checking it out and there's a lot to

00:18:31,900 --> 00:18:36,040
learn there in your own projects as well

00:18:33,580 --> 00:18:38,710
and then one other that I just learned

00:18:36,040 --> 00:18:40,600
about today when someone a send me a

00:18:38,710 --> 00:18:46,360
message on Twitter is PI stock which is

00:18:40,600 --> 00:18:48,910
very much like socket console and the it

00:18:46,360 --> 00:18:51,130
uses the web server embedded web server

00:18:48,910 --> 00:18:53,440
idea so you give a port to your

00:18:51,130 --> 00:18:55,870
application and it has that same data

00:18:53,440 --> 00:18:58,180
and I think he's he's got a better

00:18:55,870 --> 00:19:04,780
reader than mine her better command line

00:18:58,180 --> 00:19:06,190
tool this as I said is a practical

00:19:04,780 --> 00:19:09,760
problem many of us have sold it in

00:19:06,190 --> 00:19:11,500
different ways and I'd like us to be

00:19:09,760 --> 00:19:13,870
able to learn from each other as we're

00:19:11,500 --> 00:19:17,470
managing all these services and building

00:19:13,870 --> 00:19:20,920
new ones and find a set of tools and

00:19:17,470 --> 00:19:22,420
practices that make these solutions

00:19:20,920 --> 00:19:25,570
straightforward and easy to integrate

00:19:22,420 --> 00:19:27,460
this should be the the default when we

00:19:25,570 --> 00:19:29,020
deploy Python services that we have all

00:19:27,460 --> 00:19:31,120
this information about it and that it

00:19:29,020 --> 00:19:34,030
takes less and less time to integrate

00:19:31,120 --> 00:19:37,060
and to apply them to each one and with

00:19:34,030 --> 00:19:39,190
that in mind we we set up a new mailing

00:19:37,060 --> 00:19:42,700
list to discuss these projects and other

00:19:39,190 --> 00:19:44,110
ones and will be sprinting on monday and

00:19:42,700 --> 00:19:46,030
tuesday i'll be here on Monday or

00:19:44,110 --> 00:19:51,550
Tuesday and Michael will be sprinting

00:19:46,030 --> 00:19:53,110
remotely from Portland on Monday I think

00:19:51,550 --> 00:19:55,879
we all need this and it's within our

00:19:53,110 --> 00:19:58,190
reach these are all solvable problems

00:19:55,879 --> 00:20:01,309
here's a couple of the projects that we

00:19:58,190 --> 00:20:05,929
were talking about and happy to show a

00:20:01,309 --> 00:20:09,289
little bit more thank you very much this

00:20:05,929 --> 00:20:11,029
is my contact information and Michael's

00:20:09,289 --> 00:20:13,609
there's the mailing list and urban

00:20:11,029 --> 00:20:15,949
airship is hiring a both in Portland and

00:20:13,609 --> 00:20:20,029
San Francisco in case that's interesting

00:20:15,949 --> 00:20:23,649
to you and if there are any questions

00:20:20,029 --> 00:20:23,649
I'd love to hear them or comments

00:20:35,520 --> 00:20:50,050
all that n curson we have time just hop

00:20:39,310 --> 00:20:53,710
up here hi I wanted to know how do the

00:20:50,050 --> 00:20:57,160
tools or what's planned with the tools

00:20:53,710 --> 00:20:59,440
that you're developing and how well do

00:20:57,160 --> 00:21:01,690
they play with for example the java

00:20:59,440 --> 00:21:04,480
console and the monitoring tools that

00:21:01,690 --> 00:21:09,280
already exist for example when using Jai

00:21:04,480 --> 00:21:12,610
thon or when using a JVM launched from a

00:21:09,280 --> 00:21:14,890
Python script a problem oat so the

00:21:12,610 --> 00:21:17,560
question was how well though these tools

00:21:14,890 --> 00:21:20,860
will play with existing Java tools or

00:21:17,560 --> 00:21:22,060
with in places where Python and Java are

00:21:20,860 --> 00:21:25,900
working together and the answer is

00:21:22,060 --> 00:21:29,490
probably very little the Java tools the

00:21:25,900 --> 00:21:32,230
way jmx works is is quite specific

00:21:29,490 --> 00:21:34,150
however if you take sort of the next

00:21:32,230 --> 00:21:36,160
layer up in the services that generally

00:21:34,150 --> 00:21:37,750
consumed this data like the wrong date

00:21:36,160 --> 00:21:40,090
like the monitoring services and other

00:21:37,750 --> 00:21:43,600
things then that's the part where they

00:21:40,090 --> 00:21:45,160
can work together very well and we this

00:21:43,600 --> 00:21:46,930
is all both of those projects particular

00:21:45,160 --> 00:21:49,150
unit specific they won't work on my

00:21:46,930 --> 00:21:52,000
windows well ok they might work on

00:21:49,150 --> 00:21:57,280
windows I haven't tried that but I ipod

00:21:52,000 --> 00:21:58,840
isn't an honorary at all ok thanks do

00:21:57,280 --> 00:22:00,820
you think that things like pie pie we

00:21:58,840 --> 00:22:02,260
have kind of more of the vm layer would

00:22:00,820 --> 00:22:04,360
help with kind of monitoring tools plain

00:22:02,260 --> 00:22:06,250
ODI matches more at the virtual machine

00:22:04,360 --> 00:22:08,890
layer not so much it's not a Java thing

00:22:06,250 --> 00:22:10,120
specifically so is it a lot harder than

00:22:08,890 --> 00:22:12,430
Python just because you don't have that

00:22:10,120 --> 00:22:14,560
kind of bottom layer to instrument the

00:22:12,430 --> 00:22:17,080
tools apart from the language or that's

00:22:14,560 --> 00:22:18,310
a good question so so right so that I

00:22:17,080 --> 00:22:21,160
mean a lot of the Java tools they are

00:22:18,310 --> 00:22:23,490
built into the JVM or they make use of

00:22:21,160 --> 00:22:26,350
systems that are built into the JVM and

00:22:23,490 --> 00:22:28,360
an effort like pipe I definitely could

00:22:26,350 --> 00:22:31,660
expose a lot more or make it easier to

00:22:28,360 --> 00:22:33,130
expose them the the idea of just

00:22:31,660 --> 00:22:34,810
grabbing the stack trace that's

00:22:33,130 --> 00:22:38,170
something that a lot of systems do at

00:22:34,810 --> 00:22:42,000
the the vm or runtime layer like I know

00:22:38,170 --> 00:22:45,450
go just integrate or just a

00:22:42,000 --> 00:22:46,650
resolved Michael's feature request which

00:22:45,450 --> 00:22:50,580
was to be able to give the strat

00:22:46,650 --> 00:22:52,800
sectaries at any one time and I can see

00:22:50,580 --> 00:22:55,110
a point where it would make more sense

00:22:52,800 --> 00:22:56,970
to push that up to the interpreter level

00:22:55,110 --> 00:23:00,210
but I don't think that we know enough

00:22:56,970 --> 00:23:03,060
about what exactly we want we want the

00:23:00,210 --> 00:23:05,040
use cases from the JVM but not

00:23:03,060 --> 00:23:08,520
necessarily the way they've approached

00:23:05,040 --> 00:23:11,070
it that said the the tracing stuff that

00:23:08,520 --> 00:23:13,320
they're working on in in pi PI is really

00:23:11,070 --> 00:23:15,870
cool and that is the kind of data that

00:23:13,320 --> 00:23:21,690
I'd like to see exposed as well as this

00:23:15,870 --> 00:23:27,530
sort of application specific data can

00:23:21,690 --> 00:23:30,270
you comment some on a pie MX project as

00:23:27,530 --> 00:23:32,640
as it relates to what you're working on

00:23:30,270 --> 00:23:35,070
I the last time I looked at that it

00:23:32,640 --> 00:23:36,480
hadn't I hadn't seen any updates in a

00:23:35,070 --> 00:23:38,760
very long time I don't think it's

00:23:36,480 --> 00:23:42,240
maintained I if I'm wrong then I

00:23:38,760 --> 00:23:44,160
definitely should look and I I don't

00:23:42,240 --> 00:23:45,870
know that their what their goals were

00:23:44,160 --> 00:23:48,180
weather was to make this exact same

00:23:45,870 --> 00:23:50,160
thing or whether to just pull out the

00:23:48,180 --> 00:23:54,540
data they needed in order to help their

00:23:50,160 --> 00:23:57,270
operations but I think focusing on the

00:23:54,540 --> 00:23:59,340
the practical aspects as opposed to the

00:23:57,270 --> 00:24:01,650
the encompass envision is going to be

00:23:59,340 --> 00:24:03,630
the best way forward to to being able to

00:24:01,650 --> 00:24:05,960
make the most out of our applications

00:24:03,630 --> 00:24:05,960
data

00:24:10,520 --> 00:24:18,120
any more questions I also would like to

00:24:15,210 --> 00:24:19,290
point out if they are some somebody more

00:24:18,120 --> 00:24:21,390
interest in this topic there's some

00:24:19,290 --> 00:24:23,250
space for open space so if you like to

00:24:21,390 --> 00:24:25,500
can organize or open space and people

00:24:23,250 --> 00:24:27,420
can talk about it it's a good idea it

00:24:25,500 --> 00:24:28,860
does not any more questions then thank

00:24:27,420 --> 00:24:31,040
you very much for your very interesting

00:24:28,860 --> 00:24:31,040

YouTube URL: https://www.youtube.com/watch?v=YdnBK5yO4zU


