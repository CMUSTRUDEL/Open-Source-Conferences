Title: Build reliable, traceable, distributed systems with ZeroMQ
Publication date: 2012-04-29
Playlist: PyCon 2012
Description: 
	Jérôme Petazzoni
We will show how to build simple yet powerful RPC code with ZeroMQ, with very few (if any!) modification to existing code. We will build fan-in and fan-out topologies with ZeroMQ special socket types to implement PUB/SUB patterns and
Captions: 
	00:00:00,030 --> 00:00:06,930
okay so I will quickly explain who we

00:00:04,319 --> 00:00:09,769
are and why we did all this then I will

00:00:06,930 --> 00:00:14,040
give a quick tour of the zero RPC or

00:00:09,769 --> 00:00:16,650
framework to do RPC with 0 mq so picture

00:00:14,040 --> 00:00:20,570
of the features and then I will give

00:00:16,650 --> 00:00:25,529
some details about how we implemented it

00:00:20,570 --> 00:00:28,470
so why did we implement a full-blown RPC

00:00:25,529 --> 00:00:31,230
layer on top of 0 mq well because we're

00:00:28,470 --> 00:00:33,600
running a pass so we deploy a monitor of

00:00:31,230 --> 00:00:37,320
scale and all that jazz apps in the

00:00:33,600 --> 00:00:39,950
cloud and this involves many moving

00:00:37,320 --> 00:00:43,829
parts many components load balancers

00:00:39,950 --> 00:00:46,500
code stores and on a very large

00:00:43,829 --> 00:00:48,530
distributed cluster just to give you a

00:00:46,500 --> 00:00:50,969
really rough overview this is

00:00:48,530 --> 00:00:53,579
approximately what the platform looks

00:00:50,969 --> 00:00:56,789
like so all the grey boxes are different

00:00:53,579 --> 00:01:00,809
services talking to each other and the

00:00:56,789 --> 00:01:03,870
red boxes are servers that are actually

00:01:00,809 --> 00:01:05,700
present in hundreds of instances for the

00:01:03,870 --> 00:01:09,990
nodes on the right and tens of instances

00:01:05,700 --> 00:01:12,869
for those on the left so or requirements

00:01:09,990 --> 00:01:15,299
were basically what we wanted to be able

00:01:12,869 --> 00:01:18,270
to expose Python code running somewhere

00:01:15,299 --> 00:01:20,820
and to call it from somewhere else so

00:01:18,270 --> 00:01:22,650
this is pretty basic but we wanted to

00:01:20,820 --> 00:01:25,439
avoid to have any modification to

00:01:22,650 --> 00:01:28,350
existing code so I want to be able if I

00:01:25,439 --> 00:01:30,450
have a Python module foo and I import it

00:01:28,350 --> 00:01:33,329
and I can call a function I want to be

00:01:30,450 --> 00:01:36,090
able to do the same thing transparently

00:01:33,329 --> 00:01:38,490
if the code is running remotely so far

00:01:36,090 --> 00:01:41,610
it's pretty basic we wanted to have

00:01:38,490 --> 00:01:44,220
something that would document by itself

00:01:41,610 --> 00:01:46,290
if possible because we didn't want to

00:01:44,220 --> 00:01:48,299
maintain a separate documentation while

00:01:46,290 --> 00:01:50,850
not only because we are just a bunch of

00:01:48,299 --> 00:01:52,950
lazy Forks but also because manual

00:01:50,850 --> 00:01:55,470
documentation tends to be out of date

00:01:52,950 --> 00:01:57,450
all the time and if you can't trust the

00:01:55,470 --> 00:02:00,570
doc because you're wondering if it's out

00:01:57,450 --> 00:02:02,729
of date or maybe not well then it's it's

00:02:00,570 --> 00:02:05,369
better to just not have any dog at all

00:02:02,729 --> 00:02:07,590
so really we wanted something that would

00:02:05,369 --> 00:02:11,009
be able to use the dog strings and the

00:02:07,590 --> 00:02:13,800
introspection features of Python we had

00:02:11,009 --> 00:02:16,140
a couple of more difficult requirements

00:02:13,800 --> 00:02:18,780
we wanted to be able to propagate

00:02:16,140 --> 00:02:21,750
exceptions so if I'm cooling remote code

00:02:18,780 --> 00:02:24,090
and it's throwing some exception I want

00:02:21,750 --> 00:02:27,000
to see that exception and not some

00:02:24,090 --> 00:02:29,730
obscure remote exception that make no

00:02:27,000 --> 00:02:33,990
sense we wanted to be language agnostic

00:02:29,730 --> 00:02:36,360
because even if we have mostly Python

00:02:33,990 --> 00:02:39,180
code base we wanted to be able at some

00:02:36,360 --> 00:02:43,410
point to plug some maybe not GS ruby or

00:02:39,180 --> 00:02:45,540
java stuff who knows we wanted to have

00:02:43,410 --> 00:02:48,210
the ability to be broker less highly

00:02:45,540 --> 00:02:49,830
available fast and to support exotic

00:02:48,210 --> 00:02:52,620
topologies so what does that mean

00:02:49,830 --> 00:02:56,430
broccolis means that we don't want to

00:02:52,620 --> 00:02:58,980
have to fire up some special server each

00:02:56,430 --> 00:03:01,530
time we want just to have a small RPC

00:02:58,980 --> 00:03:04,080
call running highly available well with

00:03:01,530 --> 00:03:06,900
just one thing to not break if just one

00:03:04,080 --> 00:03:10,080
process or server goes down fast because

00:03:06,900 --> 00:03:13,250
we want to use that for logging and for

00:03:10,080 --> 00:03:15,210
matrix with which both have like

00:03:13,250 --> 00:03:17,940
thousands or tens of thousands of

00:03:15,210 --> 00:03:20,070
message per second and finding in phenom

00:03:17,940 --> 00:03:22,350
topologies means for instance when we

00:03:20,070 --> 00:03:24,570
update some HTTP via Traverse

00:03:22,350 --> 00:03:28,590
configuration it has to propagate to a

00:03:24,570 --> 00:03:30,480
large number of load balancers but we

00:03:28,590 --> 00:03:32,610
don't necessarily want to have all those

00:03:30,480 --> 00:03:36,420
features at the same time so for

00:03:32,610 --> 00:03:38,970
instance it's okay to have to require a

00:03:36,420 --> 00:03:40,590
broker when you want to be both fast and

00:03:38,970 --> 00:03:42,870
have fun even fan-out we don't want to

00:03:40,590 --> 00:03:45,540
have everything for this for the same

00:03:42,870 --> 00:03:48,030
service so it's okay if not all those

00:03:45,540 --> 00:03:50,190
requirements can be met together also we

00:03:48,030 --> 00:03:52,560
want it to be able to trace and profile

00:03:50,190 --> 00:03:54,300
nested calls so if I have a service

00:03:52,560 --> 00:03:58,200
calling another one calling a third one

00:03:54,300 --> 00:03:59,850
calling yet another if something takes a

00:03:58,200 --> 00:04:01,920
long time or if there is an exception I

00:03:59,850 --> 00:04:06,510
want to know where is the exception and

00:04:01,920 --> 00:04:10,709
I want to know what is taking so long so

00:04:06,510 --> 00:04:13,560
why did we not use something else so we

00:04:10,709 --> 00:04:17,220
considered using HTTP and also some mqp

00:04:13,560 --> 00:04:19,410
based solutions like rabbitmq but both

00:04:17,220 --> 00:04:22,229
had the problem of having a significant

00:04:19,410 --> 00:04:23,940
overheads for some of our use cases like

00:04:22,229 --> 00:04:26,990
the matrix with thousands of message per

00:04:23,940 --> 00:04:29,870
second and also when using HTTP

00:04:26,990 --> 00:04:33,530
a lot of those use cases require some

00:04:29,870 --> 00:04:35,599
extra work so for instance all the

00:04:33,530 --> 00:04:39,319
problems with real-time streaming

00:04:35,599 --> 00:04:41,210
updates can be solved with HTTP and

00:04:39,319 --> 00:04:41,960
WebSockets but when you're doing

00:04:41,210 --> 00:04:44,090
WebSockets

00:04:41,960 --> 00:04:47,090
you could as well be doing plenty CP and

00:04:44,090 --> 00:04:50,590
there is way no point of with using HTTP

00:04:47,090 --> 00:04:55,490
in the first place so we decided to

00:04:50,590 --> 00:04:58,430
reinvent our own wheel and we named it

00:04:55,490 --> 00:05:01,550
zero PC because it's our PC based on 0

00:04:58,430 --> 00:05:04,819
mq so we use the remm cue we decided to

00:05:01,550 --> 00:05:07,610
use massage pack for salvation it

00:05:04,819 --> 00:05:09,460
supports everything we needed so if all

00:05:07,610 --> 00:05:12,830
those requirements sound good to you

00:05:09,460 --> 00:05:14,690
please use it and we came up with

00:05:12,830 --> 00:05:17,539
multiple implementations we started with

00:05:14,690 --> 00:05:19,639
something simple in the beginning which

00:05:17,539 --> 00:05:23,449
became more and more involved with time

00:05:19,639 --> 00:05:26,180
and so it's in Python and at some point

00:05:23,449 --> 00:05:28,190
we came up with a new implementation

00:05:26,180 --> 00:05:33,199
from the ground up and this new

00:05:28,190 --> 00:05:35,690
implementation is now on github and open

00:05:33,199 --> 00:05:38,990
source and we encourage people to use

00:05:35,690 --> 00:05:40,669
and abuse it we also have an OG

00:05:38,990 --> 00:05:43,520
implementation but it's only if you put

00:05:40,669 --> 00:05:47,479
a partial set of the features so it's

00:05:43,520 --> 00:05:50,570
not really for public use yet so quick

00:05:47,479 --> 00:05:53,120
tour of what we can do with the OPC we

00:05:50,570 --> 00:05:56,330
can expose any Python code without

00:05:53,120 --> 00:05:58,340
modifying it so for instance here we're

00:05:56,330 --> 00:06:00,940
exposing the bridge with a little tool

00:05:58,340 --> 00:06:04,340
provided with the OPC the row PC client

00:06:00,940 --> 00:06:06,860
that allows to start client servers and

00:06:04,340 --> 00:06:10,580
all kind of stuff so here we expose the

00:06:06,860 --> 00:06:12,680
URL Lib standard Python module and this

00:06:10,580 --> 00:06:15,650
just this command will make it listen on

00:06:12,680 --> 00:06:18,440
port TCP 1 2 3 4 then we can call it

00:06:15,650 --> 00:06:20,900
with the command-line client which is

00:06:18,440 --> 00:06:23,659
mainly used for debugging and poking

00:06:20,900 --> 00:06:26,509
proposals and we can call it from Python

00:06:23,659 --> 00:06:28,849
code just like we premised so we connect

00:06:26,509 --> 00:06:30,949
and once we are connected we have an

00:06:28,849 --> 00:06:34,580
object just behave which behaves just

00:06:30,949 --> 00:06:37,760
like the normal or believe module it can

00:06:34,580 --> 00:06:39,350
expose modules classes anything which

00:06:37,760 --> 00:06:41,660
has a list of calibers

00:06:39,350 --> 00:06:44,450
we can do introspection so we can list

00:06:41,660 --> 00:06:46,160
the methods we can see the signatures so

00:06:44,450 --> 00:06:51,200
arguments and argument names and

00:06:46,160 --> 00:06:53,780
docstrings we can see exceptions so if I

00:06:51,200 --> 00:06:55,850
try to call the quote plus function

00:06:53,780 --> 00:06:58,820
without supplying the argument I will

00:06:55,850 --> 00:07:01,670
get a trust but a traceback with while a

00:06:58,820 --> 00:07:04,790
bunch of stuff but at the end I can see

00:07:01,670 --> 00:07:08,290
my normal plain old type error reminding

00:07:04,790 --> 00:07:12,200
me that I forgot to add one argument

00:07:08,290 --> 00:07:14,180
it has load balancing so the load

00:07:12,200 --> 00:07:18,620
balancing actually requires a tiny

00:07:14,180 --> 00:07:21,620
broker so we name that a hub so you fire

00:07:18,620 --> 00:07:25,430
up the hub which is it just requires a

00:07:21,620 --> 00:07:27,380
three lines of yeah Mel and then you

00:07:25,430 --> 00:07:28,670
connect some workers to the hub and then

00:07:27,380 --> 00:07:31,310
you connect to the hub to make your

00:07:28,670 --> 00:07:35,000
queries and that's about it if you need

00:07:31,310 --> 00:07:38,060
high availability we will again use a

00:07:35,000 --> 00:07:40,820
tiny broker which is this time HZ proxy

00:07:38,060 --> 00:07:43,630
so which a proxy is a well-known load

00:07:40,820 --> 00:07:46,280
balancer mainly for TCP and HTTP and

00:07:43,630 --> 00:07:48,910
with the really super simple

00:07:46,280 --> 00:07:50,840
configuration shown here we have

00:07:48,910 --> 00:07:54,260
something to provide high availability

00:07:50,840 --> 00:07:56,390
for RPC services there is nothing to do

00:07:54,260 --> 00:07:58,910
in the code actually there is nothing to

00:07:56,390 --> 00:08:01,040
do in our code neither because 0nq

00:07:58,910 --> 00:08:04,610
handles everything for us we connection

00:08:01,040 --> 00:08:06,860
and all that stuff now a non-example

00:08:04,610 --> 00:08:08,840
so an example things that we did in the

00:08:06,860 --> 00:08:11,720
beginning and then we realized we were

00:08:08,840 --> 00:08:16,760
all wrong so I would advise you not to

00:08:11,720 --> 00:08:18,890
try that so 0 mq has support for pub sub

00:08:16,760 --> 00:08:21,050
topologies so to broadcast information

00:08:18,890 --> 00:08:25,610
or to collect information to a central

00:08:21,050 --> 00:08:27,170
place but it has issues not with the

00:08:25,610 --> 00:08:29,180
room view itself just because in the

00:08:27,170 --> 00:08:31,970
beginning we completely missed the point

00:08:29,180 --> 00:08:33,820
of pub sub pub sub is not for reliable

00:08:31,970 --> 00:08:36,919
streaming of the front of of information

00:08:33,820 --> 00:08:39,140
if you disconnect and reconnect to the

00:08:36,919 --> 00:08:40,280
thing that is publishing information you

00:08:39,140 --> 00:08:43,010
will lose some updates

00:08:40,280 --> 00:08:45,530
so sometimes it's fine for instance if

00:08:43,010 --> 00:08:48,380
it's some metrics if you send every 10

00:08:45,530 --> 00:08:51,030
seconds the RAM of CPU usage you don't

00:08:48,380 --> 00:08:53,790
care if you miss a few data points now

00:08:51,030 --> 00:08:55,770
if it's some logs or some RPC call if

00:08:53,790 --> 00:09:02,070
you lose it

00:08:55,770 --> 00:09:04,770
consequences can be worse so instead of

00:09:02,070 --> 00:09:07,260
using pub/sub we ended up implementing

00:09:04,770 --> 00:09:08,940
something special with the ROI PC call

00:09:07,260 --> 00:09:09,570
streaming and I will give some details

00:09:08,940 --> 00:09:12,980
about that

00:09:09,570 --> 00:09:15,840
so streaming that's when you need to

00:09:12,980 --> 00:09:18,450
send for instance a big bunch of data

00:09:15,840 --> 00:09:21,690
for instance in the when we need to

00:09:18,450 --> 00:09:24,690
retrieve all the CPU usage for a given

00:09:21,690 --> 00:09:26,460
application over the last week this can

00:09:24,690 --> 00:09:30,360
be a lot of data because with a lot of

00:09:26,460 --> 00:09:32,190
data points and initially the first

00:09:30,360 --> 00:09:35,850
implementation was really bad it was

00:09:32,190 --> 00:09:38,250
building a huge list of data points

00:09:35,850 --> 00:09:40,740
it was converting them with message back

00:09:38,250 --> 00:09:43,080
sending them over the wire as one big

00:09:40,740 --> 00:09:44,840
bulk of data and at the other end you

00:09:43,080 --> 00:09:48,390
would have to do everything in Reverse

00:09:44,840 --> 00:09:51,240
so the streaming mode that we

00:09:48,390 --> 00:09:53,130
implemented allows you in your code to

00:09:51,240 --> 00:09:55,350
return an iterator and then the

00:09:53,130 --> 00:09:58,110
client-side when invoking the function

00:09:55,350 --> 00:09:59,970
will get an iterator as well and when

00:09:58,110 --> 00:10:02,280
you fetch the data from the literature

00:09:59,970 --> 00:10:05,700
it automatically behind the scenes

00:10:02,280 --> 00:10:08,400
fetches data from the server so that's

00:10:05,700 --> 00:10:10,890
good for all kind of applications so big

00:10:08,400 --> 00:10:13,530
messages or constant stream of smaller

00:10:10,890 --> 00:10:14,940
messages and also long polling so when

00:10:13,530 --> 00:10:19,400
you want to get amplification when

00:10:14,940 --> 00:10:21,930
something happens we have tracing so

00:10:19,400 --> 00:10:23,310
this unfortunately is not yet in the

00:10:21,930 --> 00:10:25,560
public repository because your

00:10:23,310 --> 00:10:27,240
implementation is tied with a lot of

00:10:25,560 --> 00:10:29,220
four internal components but we are

00:10:27,240 --> 00:10:32,010
working on this to open source it as

00:10:29,220 --> 00:10:34,650
well so what does it mean tracing this

00:10:32,010 --> 00:10:38,130
is an example when someone has an app on

00:10:34,650 --> 00:10:40,770
that cloud and he is adding a domain

00:10:38,130 --> 00:10:45,300
name to it so there is a comment line it

00:10:40,770 --> 00:10:48,210
does that cloud alias add my app and

00:10:45,300 --> 00:10:51,180
then the domain name so we can see that

00:10:48,210 --> 00:10:54,510
this is actually an HTTP call going over

00:10:51,180 --> 00:10:57,480
an HTTP endpoint so the trace begins at

00:10:54,510 --> 00:11:00,720
some new whiskey worker then it goes to

00:10:57,480 --> 00:11:02,939
a 0 worker there is some tracking to

00:11:00,720 --> 00:11:05,519
to register what the users are doing for

00:11:02,939 --> 00:11:07,379
statistical purposes and then it goes

00:11:05,519 --> 00:11:09,509
through all the components of our

00:11:07,379 --> 00:11:13,500
platform and we can see the timing

00:11:09,509 --> 00:11:16,319
information so we can if this call takes

00:11:13,500 --> 00:11:21,000
too long we can see exactly which part

00:11:16,319 --> 00:11:25,199
of the call took so long so let's see

00:11:21,000 --> 00:11:26,790
how we implemented all that stuff so the

00:11:25,199 --> 00:11:29,370
following part will be useful if you

00:11:26,790 --> 00:11:32,790
want to use your PC and wonder what's

00:11:29,370 --> 00:11:35,370
under the hood or if you excited about

00:11:32,790 --> 00:11:37,589
the idea of forking this on github and

00:11:35,370 --> 00:11:40,529
doing some cool stuff with it or if you

00:11:37,589 --> 00:11:42,889
want to reinvent your own wheel because

00:11:40,529 --> 00:11:45,000
you have different requirements but you

00:11:42,889 --> 00:11:47,600
preferably wants to avoid shooting

00:11:45,000 --> 00:11:49,680
yourselves in the foot just like we did

00:11:47,600 --> 00:11:52,889
or just if you're curious about

00:11:49,680 --> 00:11:56,250
distributed systems so why did we use

00:11:52,889 --> 00:11:59,220
the remm cube because 0 mq is just like

00:11:56,250 --> 00:12:02,819
playing all the TCP and UDP sockets but

00:11:59,220 --> 00:12:05,069
much better so for instance it handles

00:12:02,819 --> 00:12:08,399
connections for us normally if you have

00:12:05,069 --> 00:12:10,350
a TCP server and you connect to it if

00:12:08,399 --> 00:12:12,240
the server is actually not running the

00:12:10,350 --> 00:12:16,139
client will get the connection refused a

00:12:12,240 --> 00:12:21,209
row with 0 mq the client will just wait

00:12:16,139 --> 00:12:24,120
patiently for the servers to show up 0

00:12:21,209 --> 00:12:26,189
mq is able to use well there are plenty

00:12:24,120 --> 00:12:29,069
of other cool features in 0 mq not just

00:12:26,189 --> 00:12:32,550
that one so the room Q can work over

00:12:29,069 --> 00:12:34,529
regular TCP so there is no low-level

00:12:32,550 --> 00:12:37,439
custom Network protocol or something

00:12:34,529 --> 00:12:40,680
like that but if you need it for really

00:12:37,439 --> 00:12:42,990
high performance applications so that's

00:12:40,680 --> 00:12:46,829
like tens or hundreds of millions of

00:12:42,990 --> 00:12:48,689
message per seconds there are IPC and in

00:12:46,829 --> 00:12:50,490
proc transports which are respectively

00:12:48,689 --> 00:12:52,470
local to the machine and local to the

00:12:50,490 --> 00:12:55,189
process and it supports different

00:12:52,470 --> 00:12:58,889
topologies or request/response pub/sub

00:12:55,189 --> 00:13:01,769
push-pull to some load balancing and the

00:12:58,889 --> 00:13:05,639
good thing is if you want to start

00:13:01,769 --> 00:13:08,220
hacking with 0 mq even if you're not

00:13:05,639 --> 00:13:11,040
interested by the RPC you can just pick

00:13:08,220 --> 00:13:13,310
install by the democratic and it will

00:13:11,040 --> 00:13:16,639
take care of everything it will

00:13:13,310 --> 00:13:19,579
install the the 0eq libraries and some

00:13:16,639 --> 00:13:21,800
of its dependencies and it will work

00:13:19,579 --> 00:13:24,230
big thanks to Brandon Craig Rhodes who

00:13:21,800 --> 00:13:28,339
make the pies Adam Q static package

00:13:24,230 --> 00:13:32,990
because this saved us countless batches

00:13:28,339 --> 00:13:35,600
so cyclisation we use message back

00:13:32,990 --> 00:13:39,199
so why message back and why not Jason

00:13:35,600 --> 00:13:42,949
based on XML UML just because we did

00:13:39,199 --> 00:13:45,680
some really simple tests and we found

00:13:42,949 --> 00:13:49,249
that message pack was faster and more

00:13:45,680 --> 00:13:51,800
efficient space wise so depending of the

00:13:49,249 --> 00:13:54,470
test it could be between 20 and 50 times

00:13:51,800 --> 00:13:57,709
faster and sometimes even better and the

00:13:54,470 --> 00:14:01,819
output the the byte stream was at least

00:13:57,709 --> 00:14:03,499
twice smaller same thing if you want to

00:14:01,819 --> 00:14:07,160
if you are looking for something to

00:14:03,499 --> 00:14:09,230
sterilize stuff well you can pip install

00:14:07,160 --> 00:14:14,980
message back Python and play with it as

00:14:09,230 --> 00:14:18,559
well so the wire format so what does

00:14:14,980 --> 00:14:21,800
request and response look like with zero

00:14:18,559 --> 00:14:23,930
RPC we decided that it would be

00:14:21,800 --> 00:14:26,120
something like this with some headers

00:14:23,930 --> 00:14:27,829
the name of the method that you want to

00:14:26,120 --> 00:14:30,139
call and the list of arguments

00:14:27,829 --> 00:14:33,189
nothing will even see the headers is

00:14:30,139 --> 00:14:36,259
completely optional in the beginning we

00:14:33,189 --> 00:14:38,300
didn't even have the errors and then we

00:14:36,259 --> 00:14:40,279
felt Oh what about protocol extensions

00:14:38,300 --> 00:14:43,730
hmm let's put some headers were there

00:14:40,279 --> 00:14:45,769
and we use it in our in-house

00:14:43,730 --> 00:14:49,610
implementation project for the tracing

00:14:45,769 --> 00:14:52,189
stuff the arcs are just well the list of

00:14:49,610 --> 00:14:55,970
arguments we don't support keyword

00:14:52,189 --> 00:14:58,129
arguments because we wanted to have

00:14:55,970 --> 00:14:59,839
something that would work with languages

00:14:58,129 --> 00:15:03,620
that would not support keywords

00:14:59,839 --> 00:15:06,379
arguments so that's the only reason why

00:15:03,620 --> 00:15:08,720
and the response messages are exactly

00:15:06,379 --> 00:15:12,529
the same except that the method name is

00:15:08,720 --> 00:15:15,410
just something saying if the call went

00:15:12,529 --> 00:15:17,779
well if it was an error or if it's a

00:15:15,410 --> 00:15:19,939
stream then there is more data coming

00:15:17,779 --> 00:15:22,779
after that and the return value it takes

00:15:19,939 --> 00:15:27,290
the place of the arguments

00:15:22,779 --> 00:15:29,660
time outs some of you might have noticed

00:15:27,290 --> 00:15:32,179
that I mentioned that if you connect

00:15:29,660 --> 00:15:35,089
with a client with 0 mq and the server

00:15:32,179 --> 00:15:38,329
is not there the client will wait

00:15:35,089 --> 00:15:41,540
forever which in some cases might not be

00:15:38,329 --> 00:15:43,790
what you want so we implemented timeouts

00:15:41,540 --> 00:15:46,939
so if you send a request and nothing

00:15:43,790 --> 00:15:49,970
happens after like 30 seconds you just

00:15:46,939 --> 00:15:51,589
decide that the request is dead but in

00:15:49,970 --> 00:15:53,660
some cases it's wrong

00:15:51,589 --> 00:15:57,109
sometimes it's just that you're doing a

00:15:53,660 --> 00:16:00,199
color that needs more than 30 seconds so

00:15:57,109 --> 00:16:02,899
the improved implementation that the one

00:16:00,199 --> 00:16:05,089
that isn't on github has something

00:16:02,899 --> 00:16:08,749
better because the server will send

00:16:05,089 --> 00:16:12,499
heartbeats so the client we know ok the

00:16:08,749 --> 00:16:16,459
server is still working on that and the

00:16:12,499 --> 00:16:20,119
client will wait introspection this was

00:16:16,459 --> 00:16:22,970
actually quite easy we just when you

00:16:20,119 --> 00:16:24,739
expose something like the URL Lib module

00:16:22,970 --> 00:16:27,980
as shown in the example in the beginning

00:16:24,739 --> 00:16:33,350
we add a few extra functions there are

00:16:27,980 --> 00:16:35,329
PC list name help args that will peek

00:16:33,350 --> 00:16:38,209
inside the module and give you the list

00:16:35,329 --> 00:16:40,489
of functions and the arguments and

00:16:38,209 --> 00:16:43,629
docstrings of the functions that was

00:16:40,489 --> 00:16:47,389
quite easy and that was super useful

00:16:43,629 --> 00:16:49,220
when we have a new hire and we just drop

00:16:47,389 --> 00:16:51,919
in in front of the keyboard and we give

00:16:49,220 --> 00:16:55,129
him the keys to the zero PC stuff and

00:16:51,919 --> 00:16:57,470
we'd say I'm ok no poke around look at

00:16:55,129 --> 00:17:01,459
the list of services look at the method

00:16:57,470 --> 00:17:03,649
in them look at the dog strings and we

00:17:01,459 --> 00:17:07,519
found out that it was really easy to

00:17:03,649 --> 00:17:11,149
find your way in very large distributed

00:17:07,519 --> 00:17:14,929
systems with something like that naming

00:17:11,149 --> 00:17:17,240
so right now in the version that we have

00:17:14,929 --> 00:17:19,100
published on github you have to specify

00:17:17,240 --> 00:17:23,839
the host and port that you want to

00:17:19,100 --> 00:17:26,449
connect to which is not so great in

00:17:23,839 --> 00:17:29,299
house we have something using just a

00:17:26,449 --> 00:17:31,370
flat ml file but we were ashamed of this

00:17:29,299 --> 00:17:32,720
so we didn't want to publish it on

00:17:31,370 --> 00:17:35,570
github

00:17:32,720 --> 00:17:38,360
but we are considering to have something

00:17:35,570 --> 00:17:41,690
like DNS lookups using a combination of

00:17:38,360 --> 00:17:44,210
maybe a Surrey and takes T records we

00:17:41,690 --> 00:17:46,160
didn't decide yet exactly what we want

00:17:44,210 --> 00:17:48,350
to use because internally we will

00:17:46,160 --> 00:17:51,860
probably still be using this flat file

00:17:48,350 --> 00:17:54,950
because even if it's a shame at least it

00:17:51,860 --> 00:17:58,370
doesn't rely or on anything external so

00:17:54,950 --> 00:18:03,890
even if the DNS goes down the zero RPC

00:17:58,370 --> 00:18:05,870
calls will go on security well bad news

00:18:03,890 --> 00:18:09,050
there is absolutely no security in that

00:18:05,870 --> 00:18:12,140
stuff because 0 mq assumes that you're

00:18:09,050 --> 00:18:17,240
running on trusted internal private

00:18:12,140 --> 00:18:20,630
network since this is not always true we

00:18:17,240 --> 00:18:23,720
have a few recipes to run that in the

00:18:20,630 --> 00:18:29,090
wild on public TCP ports the easiest

00:18:23,720 --> 00:18:31,520
solution is to add ssl with estrin l so

00:18:29,090 --> 00:18:34,730
it's maybe a five or six configuration

00:18:31,520 --> 00:18:37,850
file for estrin l just to wrap the 0 mq

00:18:34,730 --> 00:18:40,720
connections within ssl we have a

00:18:37,850 --> 00:18:46,670
prototype for authentication that adds

00:18:40,720 --> 00:18:49,760
md5 or sha-1 responses to make sure that

00:18:46,670 --> 00:18:52,490
they are not tampered with in flight and

00:18:49,760 --> 00:18:55,220
to make sure that only authorized people

00:18:52,490 --> 00:18:58,940
can actually make RPC calls but it's not

00:18:55,220 --> 00:19:04,940
completely ready for production yet also

00:18:58,940 --> 00:19:07,040
we have HTTP 0 PC gateway that or API

00:19:04,940 --> 00:19:09,260
actually uses so as I mentioned when

00:19:07,040 --> 00:19:11,930
someone does that cloud command the

00:19:09,260 --> 00:19:14,690
command line will actually do some HTTP

00:19:11,930 --> 00:19:17,600
requests and those HTTP requests are

00:19:14,690 --> 00:19:20,990
immediately translated into RPC calls

00:19:17,600 --> 00:19:23,360
well after an authorization run trip but

00:19:20,990 --> 00:19:27,590
then there is a clean mapping of the

00:19:23,360 --> 00:19:30,350
calls between the RPC and HTTP tracing

00:19:27,590 --> 00:19:32,960
so the tracing is not published yet

00:19:30,350 --> 00:19:35,810
because it uses a lot of internal

00:19:32,960 --> 00:19:37,910
libraries and stuff so when we started

00:19:35,810 --> 00:19:40,880
to pull it out to include it into the

00:19:37,910 --> 00:19:43,340
public repository we ended up pulling or

00:19:40,880 --> 00:19:44,269
entire code base but we are currently

00:19:43,340 --> 00:19:46,669
working on

00:19:44,269 --> 00:19:50,509
something to open-source the tracing

00:19:46,669 --> 00:19:52,700
system so the tracing system the

00:19:50,509 --> 00:19:55,190
interesting stuff is that it actually

00:19:52,700 --> 00:19:57,950
only took one day for one of our

00:19:55,190 --> 00:20:02,809
engineers to craft the tracing system

00:19:57,950 --> 00:20:05,019
with what we already had and he had he

00:20:02,809 --> 00:20:09,559
added a lot of cool features like

00:20:05,019 --> 00:20:12,589
real-time graphs of latency the ability

00:20:09,559 --> 00:20:15,639
to take that boring line per line trace

00:20:12,589 --> 00:20:18,499
and do a nice graph with it because

00:20:15,639 --> 00:20:21,320
sometimes some calls will fan out so you

00:20:18,499 --> 00:20:23,389
do one call to multiple machines and one

00:20:21,320 --> 00:20:25,039
of them will respond so in that case it

00:20:23,389 --> 00:20:28,820
makes sense to have a real graph instead

00:20:25,039 --> 00:20:32,950
of just a traceback line by line and

00:20:28,820 --> 00:20:36,679
also the the tracer can send exceptions

00:20:32,950 --> 00:20:38,539
to airbrakes entry or services like that

00:20:36,679 --> 00:20:42,829
so when you have an exception in your

00:20:38,539 --> 00:20:47,479
zero RPC stuff you get alerts on your

00:20:42,829 --> 00:20:48,529
favorite exception monitoring tool so

00:20:47,479 --> 00:20:52,729
how does it work

00:20:48,529 --> 00:20:55,399
the grand plan is that each time there

00:20:52,729 --> 00:20:58,309
is a call or response we send some

00:20:55,399 --> 00:21:01,219
information to a central place and we

00:20:58,309 --> 00:21:04,849
index it with a trace ID and then we can

00:21:01,219 --> 00:21:08,389
retrieve all those small trace elements

00:21:04,849 --> 00:21:10,940
let's name that trace let's and we can

00:21:08,389 --> 00:21:14,059
see all the the course that were

00:21:10,940 --> 00:21:17,029
involved in in one complex call so this

00:21:14,059 --> 00:21:19,820
trace ID each color has a trace ID

00:21:17,029 --> 00:21:21,829
because when you're doing a call if you

00:21:19,820 --> 00:21:24,440
don't have yet to trace ID you make one

00:21:21,829 --> 00:21:26,149
up and if you're within a call already

00:21:24,440 --> 00:21:28,549
and you make a sub call to different

00:21:26,149 --> 00:21:31,190
service you will reuse the same trace ID

00:21:28,549 --> 00:21:35,450
and it's thrown in local context a bit

00:21:31,190 --> 00:21:39,019
like a thread local storage and so the

00:21:35,450 --> 00:21:42,249
tray size D will go along with the call

00:21:39,019 --> 00:21:47,419
during the whole lifetime of the call

00:21:42,249 --> 00:21:50,509
then those small trace elements those

00:21:47,419 --> 00:21:53,299
will contain some trace ID the cool name

00:21:50,509 --> 00:21:55,789
so just a function name the name of the

00:21:53,299 --> 00:21:56,580
current process so is this the V host

00:21:55,789 --> 00:22:00,330
service or

00:21:56,580 --> 00:22:02,730
if this some net service or something

00:22:00,330 --> 00:22:04,919
else it also contains the hostname so

00:22:02,730 --> 00:22:08,039
you can know where the thing is running

00:22:04,919 --> 00:22:11,039
and a timestamp and it will send all

00:22:08,039 --> 00:22:13,710
that stuff to a central place this

00:22:11,039 --> 00:22:17,010
central place is actually a ready key

00:22:13,710 --> 00:22:19,260
value store so it keeps everything in

00:22:17,010 --> 00:22:21,269
RAM because it has to be fast because

00:22:19,260 --> 00:22:23,610
it's receiving a constant stream of

00:22:21,269 --> 00:22:26,340
tresses all the time

00:22:23,610 --> 00:22:29,340
it's in RAM so it's not persistent but

00:22:26,340 --> 00:22:32,159
we don't care because this is mostly for

00:22:29,340 --> 00:22:36,419
debugging stuff so we really don't mind

00:22:32,159 --> 00:22:40,799
losing the trace of the course that we

00:22:36,419 --> 00:22:43,200
did last week we just for information

00:22:40,799 --> 00:22:46,710
the whole platform is generating about

00:22:43,200 --> 00:22:49,740
16 gigs of trace every day so we could

00:22:46,710 --> 00:22:55,620
keep that but we decided not to because

00:22:49,740 --> 00:22:57,539
we really don't need them so we use some

00:22:55,620 --> 00:23:00,260
release features to to make this

00:22:57,539 --> 00:23:05,100
component really fast efficient and

00:23:00,260 --> 00:23:08,880
everything is like Big O of 1 so weight

00:23:05,100 --> 00:23:11,730
stuff actually we don't talk directly to

00:23:08,880 --> 00:23:13,620
Redis we talk to a service that itself

00:23:11,730 --> 00:23:18,090
stocks to Redis and that service in the

00:23:13,620 --> 00:23:22,139
middle will trigger air brake or century

00:23:18,090 --> 00:23:23,850
and that kind of specification so the

00:23:22,139 --> 00:23:27,210
first implementation that we did was

00:23:23,850 --> 00:23:30,179
synchronous this means that if you have

00:23:27,210 --> 00:23:32,820
a call that takes a very long time the

00:23:30,179 --> 00:23:37,110
whole service will block so for instance

00:23:32,820 --> 00:23:40,830
we had a call to spin up new servers new

00:23:37,110 --> 00:23:43,320
ec2 instances and sometimes this takes a

00:23:40,830 --> 00:23:45,149
while so when you would be spinning up a

00:23:43,320 --> 00:23:49,320
server you wouldn't be able to do

00:23:45,149 --> 00:23:52,769
something else with the or ec2 bridge

00:23:49,320 --> 00:23:55,500
during the same time so the first

00:23:52,769 --> 00:23:57,419
solution was well let's let's do some

00:23:55,500 --> 00:23:59,159
load balancing as explained in the

00:23:57,419 --> 00:24:01,049
beginning so we put this hub we have

00:23:59,159 --> 00:24:03,179
multiple workers and we dispatched

00:24:01,049 --> 00:24:04,980
requesting the workers the problem is

00:24:03,179 --> 00:24:07,800
when you have really really really long

00:24:04,980 --> 00:24:13,410
calls eventually you will run out of

00:24:07,800 --> 00:24:15,510
workers so this is not a problem

00:24:13,410 --> 00:24:18,900
specific to your PC whether this the

00:24:15,510 --> 00:24:20,550
same time with web apps using where

00:24:18,900 --> 00:24:22,590
whiskey web apps at the same problem you

00:24:20,550 --> 00:24:24,870
have to spin up multiple whiskey workers

00:24:22,590 --> 00:24:28,620
and if all your whiskey workers are busy

00:24:24,870 --> 00:24:31,980
well the app just stopped responding so

00:24:28,620 --> 00:24:34,440
at first we think we thought well let's

00:24:31,980 --> 00:24:37,800
do just like not GS let's have some

00:24:34,440 --> 00:24:40,470
asynchronous event all over the place so

00:24:37,800 --> 00:24:42,720
when you need to do something you send a

00:24:40,470 --> 00:24:45,240
request and you tell ok once the request

00:24:42,720 --> 00:24:48,600
is done send me the results to some

00:24:45,240 --> 00:24:50,340
other place so just like callbacks in no

00:24:48,600 --> 00:24:53,550
GS or in a synchronous loops like

00:24:50,340 --> 00:24:56,790
twisted in order like we tried the

00:24:53,550 --> 00:25:00,540
result wasn't pretty and we learned that

00:24:56,790 --> 00:25:04,440
while trying to do that it can work but

00:25:00,540 --> 00:25:08,670
it requires a lot of care to make sure

00:25:04,440 --> 00:25:10,260
that notably one of the big problems

00:25:08,670 --> 00:25:12,330
were the problem of tree falling in the

00:25:10,260 --> 00:25:14,790
forest with no one to hear them which

00:25:12,330 --> 00:25:17,010
means you're doing a call and you're

00:25:14,790 --> 00:25:19,800
telling well once you have the result of

00:25:17,010 --> 00:25:22,860
this call please call this other

00:25:19,800 --> 00:25:26,330
function if something goes wrong the

00:25:22,860 --> 00:25:28,650
function is not called and the whole

00:25:26,330 --> 00:25:31,140
workflow that we are following just

00:25:28,650 --> 00:25:34,730
stops because at some point someone

00:25:31,140 --> 00:25:38,340
didn't call the next thing to do so

00:25:34,730 --> 00:25:41,640
maybe it could have worked if we had

00:25:38,340 --> 00:25:44,490
been careful programmers or if we had

00:25:41,640 --> 00:25:46,770
some better features or maybe actually

00:25:44,490 --> 00:25:51,540
from a theoretical point of view if we

00:25:46,770 --> 00:25:53,340
had some kind of something to make sure

00:25:51,540 --> 00:25:55,140
that we don't lose the state of those

00:25:53,340 --> 00:25:57,780
scores so when we would start a call it

00:25:55,140 --> 00:25:59,700
would monitor them and if they happen to

00:25:57,780 --> 00:26:04,050
be lost in space it would start them

00:25:59,700 --> 00:26:08,940
again but this was too complicated so we

00:26:04,050 --> 00:26:12,960
decided to use G event which is a really

00:26:08,940 --> 00:26:15,120
cool a synchronous framework using

00:26:12,960 --> 00:26:17,040
routines so you're still writing

00:26:15,120 --> 00:26:18,800
synchronous code you're not sending

00:26:17,040 --> 00:26:22,640
callbacks and even

00:26:18,800 --> 00:26:24,650
stuff like that and it works

00:26:22,640 --> 00:26:27,590
the code won't have to fork it won't

00:26:24,650 --> 00:26:29,180
have to use threads and well I'm not

00:26:27,590 --> 00:26:33,620
saying that you won't have any problem

00:26:29,180 --> 00:26:37,490
but it was way better than what we had

00:26:33,620 --> 00:26:40,190
before so G evens turns your whole

00:26:37,490 --> 00:26:42,770
codebase into something fully a

00:26:40,190 --> 00:26:45,410
synchronous it achieves this by

00:26:42,770 --> 00:26:46,760
replacing every blocking call in the

00:26:45,410 --> 00:26:49,580
standard Python library with a

00:26:46,760 --> 00:26:51,740
non-blocking version but I think there

00:26:49,580 --> 00:26:54,010
is a talk about deviance just after mind

00:26:51,740 --> 00:26:58,820
so you will certainly have some details

00:26:54,010 --> 00:27:01,760
and this was the real solution to a

00:26:58,820 --> 00:27:03,470
problem and the good news is that the

00:27:01,760 --> 00:27:07,780
version that we have in github has this

00:27:03,470 --> 00:27:10,940
jeevan's stuff in it so you can expose

00:27:07,780 --> 00:27:14,420
one some Python code that takes time to

00:27:10,940 --> 00:27:17,530
run and each won't block just because

00:27:14,420 --> 00:27:22,790
there is one long function call running

00:27:17,530 --> 00:27:25,280
so the code we published the repository

00:27:22,790 --> 00:27:29,690
just did morning after like late

00:27:25,280 --> 00:27:33,680
adjustments and everything it works we

00:27:29,690 --> 00:27:36,950
use it in production and it can normally

00:27:33,680 --> 00:27:39,320
be installed just by beeping story pip

00:27:36,950 --> 00:27:44,770
installing it directly from github it

00:27:39,320 --> 00:27:46,160
will probably be on pi PI shortly and

00:27:44,770 --> 00:27:48,080
that's about it

00:27:46,160 --> 00:27:49,460
so it has the zero PC module I was

00:27:48,080 --> 00:27:52,820
talking about it has this small

00:27:49,460 --> 00:27:55,670
command-line tool to expose modules and

00:27:52,820 --> 00:27:57,500
to see what they are doing it propagates

00:27:55,670 --> 00:28:02,770
exceptions it has an integration with

00:27:57,500 --> 00:28:08,810
Jevons but now what it doesn't have is

00:28:02,770 --> 00:28:10,330
tracing naming stuff to make nice pubsub

00:28:08,810 --> 00:28:13,490
and push pull integration and

00:28:10,330 --> 00:28:15,740
authentication but the good news is that

00:28:13,490 --> 00:28:19,690
we have implementations for all those

00:28:15,740 --> 00:28:22,160
patterns in your code base and we are

00:28:19,690 --> 00:28:26,560
willing to open serve them progressively

00:28:22,160 --> 00:28:30,850
so expect to see more in that area

00:28:26,560 --> 00:28:30,850
that's it you have any questions

00:28:35,900 --> 00:28:46,730
I have a few questions I've got a couple

00:28:44,840 --> 00:28:49,580
so tell me to get off the stage if I'm

00:28:46,730 --> 00:28:54,530
taking up too much time so what do you

00:28:49,580 --> 00:28:57,440
do if the function signature changes on

00:28:54,530 --> 00:28:59,870
a remote host how do you deal with with

00:28:57,440 --> 00:29:02,060
those changes if you change doing it so

00:28:59,870 --> 00:29:05,270
if a function signature on the server

00:29:02,060 --> 00:29:07,640
changes if it's changed during the goal

00:29:05,270 --> 00:29:09,170
or if at some point you release a new

00:29:07,640 --> 00:29:12,500
version of the service with a different

00:29:09,170 --> 00:29:15,320
signature so the thing is that it's

00:29:12,500 --> 00:29:18,290
completely dynamic so if you make a

00:29:15,320 --> 00:29:20,150
client code with let's say two arguments

00:29:18,290 --> 00:29:22,040
but actually the new implementation has

00:29:20,150 --> 00:29:23,360
three arguments you will get an

00:29:22,040 --> 00:29:25,460
exception telling you that you don't

00:29:23,360 --> 00:29:27,890
have any arguments well just like when

00:29:25,460 --> 00:29:30,230
you change some normal Python code and

00:29:27,890 --> 00:29:32,480
in the library and you don't you change

00:29:30,230 --> 00:29:33,740
the code using the library do you have

00:29:32,480 --> 00:29:35,180
any have you developed any best

00:29:33,740 --> 00:29:38,570
practices internally for dealing with

00:29:35,180 --> 00:29:41,570
that so do we have best practice to deal

00:29:38,570 --> 00:29:45,500
with changes in api's we are working on

00:29:41,570 --> 00:29:48,530
that from now or guidelines are don't

00:29:45,500 --> 00:29:51,140
make any incompatible changes so if you

00:29:48,530 --> 00:29:53,930
extend the call add optional arguments

00:29:51,140 --> 00:29:56,270
with sensible defaults and if it's

00:29:53,930 --> 00:29:58,040
something different just add a call so

00:29:56,270 --> 00:30:00,590
that's why some of our services have

00:29:58,040 --> 00:30:03,860
like six or seven calls that looked like

00:30:00,590 --> 00:30:05,870
the same but each has a really different

00:30:03,860 --> 00:30:08,540
slightly different behavior it sounds

00:30:05,870 --> 00:30:11,390
like the way to go to zero I'm kids

00:30:08,540 --> 00:30:13,670
still throw asserts when the unexpected

00:30:11,390 --> 00:30:18,830
happens those the room cue still sorry

00:30:13,670 --> 00:30:21,230
this gmq have assertions in the library

00:30:18,830 --> 00:30:22,460
that caused the program to crash still

00:30:21,230 --> 00:30:25,940
because I know there was a problem

00:30:22,460 --> 00:30:30,340
earlier um if it has a sorry I didn't

00:30:25,940 --> 00:30:30,340
understand no okay

00:30:30,820 --> 00:30:36,800
thank you

00:30:33,200 --> 00:30:39,410
one last question what do you do if pool

00:30:36,800 --> 00:30:42,290
membership changes I you add a server to

00:30:39,410 --> 00:30:44,840
the the RPC pool do you have to update

00:30:42,290 --> 00:30:47,960
the a proxy configured if some sort of

00:30:44,840 --> 00:30:50,990
autumn so if so what do we do if we add

00:30:47,960 --> 00:30:54,320
or remove workers in a hav BT setup so

00:30:50,990 --> 00:30:57,290
actually the the infrastructure looks

00:30:54,320 --> 00:30:59,150
like hubs workers connect to hubs so we

00:30:57,290 --> 00:31:01,160
can add and remove workers without

00:30:59,150 --> 00:31:03,710
reconfiguring anything and the only

00:31:01,160 --> 00:31:09,310
thing that's hard coded in within H a

00:31:03,710 --> 00:31:09,310
proxy the location of two hubs thank you

00:31:09,820 --> 00:31:14,840
hi first of all I just want to say thank

00:31:13,070 --> 00:31:16,370
you for making this open-source and

00:31:14,840 --> 00:31:18,590
releasing this as open source because

00:31:16,370 --> 00:31:21,290
it's tools like this that make Python so

00:31:18,590 --> 00:31:24,280
great right so I guess thank you on

00:31:21,290 --> 00:31:24,280
behalf of Python

00:31:25,280 --> 00:31:31,430
I guess my question is how do you

00:31:28,910 --> 00:31:32,930
determine worker utilization so you have

00:31:31,430 --> 00:31:34,070
all these different workers doing things

00:31:32,930 --> 00:31:36,830
that are kind of doing the same sort of

00:31:34,070 --> 00:31:39,290
class how do you how do you figure out

00:31:36,830 --> 00:31:42,020
worker utilization so how do we figure

00:31:39,290 --> 00:31:42,590
out how many workers are required on

00:31:42,020 --> 00:31:46,190
that kind of stuff

00:31:42,590 --> 00:31:49,900
so um back in the days before the

00:31:46,190 --> 00:31:52,580
jeevan's implementation we had a kind of

00:31:49,900 --> 00:31:55,610
dynamic work of q a little bit like the

00:31:52,580 --> 00:32:00,800
apache mechanism that spins up and down

00:31:55,610 --> 00:32:03,470
workers it worked so and so and it could

00:32:00,800 --> 00:32:05,720
also examine the queue length and stuff

00:32:03,470 --> 00:32:06,440
like that but you didn't solve

00:32:05,720 --> 00:32:08,150
everything

00:32:06,440 --> 00:32:11,630
because at some point you would just end

00:32:08,150 --> 00:32:14,740
up with hundreds of workers and all busy

00:32:11,630 --> 00:32:16,910
within something so the jeevan's

00:32:14,740 --> 00:32:18,860
implementation completely removed the

00:32:16,910 --> 00:32:21,290
worker issue actually there is some

00:32:18,860 --> 00:32:23,090
cases where we were we would be using

00:32:21,290 --> 00:32:24,980
some library that would be compatible

00:32:23,090 --> 00:32:28,930
with jeevan's so in that case we'd be

00:32:24,980 --> 00:32:31,580
back to the plain old workers but it's a

00:32:28,930 --> 00:32:34,430
there are not too many of them so we

00:32:31,580 --> 00:32:35,990
were able to figure it out I was just

00:32:34,430 --> 00:32:37,970
wondering what kind of overlap there is

00:32:35,990 --> 00:32:39,680
with a project like twisted because it

00:32:37,970 --> 00:32:41,720
seems like this solves some similar

00:32:39,680 --> 00:32:44,240
issues in terms of asynchronous and

00:32:41,720 --> 00:32:46,070
distributing things over a network so

00:32:44,240 --> 00:32:49,400
the relationship between this and

00:32:46,070 --> 00:32:51,560
twisted um for instance I think instead

00:32:49,400 --> 00:32:55,520
of using je viens we probably could have

00:32:51,560 --> 00:32:57,290
used twisted but we were completely

00:32:55,520 --> 00:33:00,680
excited about je viens because it would

00:32:57,290 --> 00:33:03,770
allow us to continue to write normal

00:33:00,680 --> 00:33:06,050
code like synchronous code without

00:33:03,770 --> 00:33:10,460
twisting or mine around a synchronous

00:33:06,050 --> 00:33:13,220
patterns I think it would it would

00:33:10,460 --> 00:33:17,570
totally make sense to have well just

00:33:13,220 --> 00:33:21,140
like there is Z mqg events to have zmq

00:33:17,570 --> 00:33:24,590
twisted and then to have Z RPC twisted -

00:33:21,140 --> 00:33:29,030
to plug our bicycles with in a twisted

00:33:24,590 --> 00:33:32,690
event loop oh I have a question about

00:33:29,030 --> 00:33:34,730
exceptions how are exceptions handled in

00:33:32,690 --> 00:33:35,990
a cross language manner so how do you

00:33:34,730 --> 00:33:37,640
get properties off an exception object

00:33:35,990 --> 00:33:40,790
and what do they look like over the wire

00:33:37,640 --> 00:33:42,650
so how do we handle exceptions across

00:33:40,790 --> 00:33:45,140
language barriers and how do we send

00:33:42,650 --> 00:33:48,770
them on the wire so across language

00:33:45,140 --> 00:33:50,390
barriers we don't actually the as I said

00:33:48,770 --> 00:33:52,130
we have a preliminary energy s

00:33:50,390 --> 00:33:54,830
implementation that only has a partial

00:33:52,130 --> 00:33:58,910
subset and it doesn't deal with

00:33:54,830 --> 00:34:03,470
exceptions very well we tried to

00:33:58,910 --> 00:34:07,400
convince some Java shops to use zero RPC

00:34:03,470 --> 00:34:12,550
and to see where it would lead us but so

00:34:07,400 --> 00:34:15,950
far or attempts were unsuccessful but we

00:34:12,550 --> 00:34:19,760
that's completely up an issue the way so

00:34:15,950 --> 00:34:22,910
how we send them over the wire right now

00:34:19,760 --> 00:34:25,730
it's I think it's semi structured so

00:34:22,910 --> 00:34:28,100
it's like it's not we're not trying to

00:34:25,730 --> 00:34:30,110
pickle exceptions and do any fancy stuff

00:34:28,100 --> 00:34:32,720
like that at the beginning it was just a

00:34:30,110 --> 00:34:34,190
big bunch of text and right now I think

00:34:32,720 --> 00:34:38,260
it's a little bit better because it's a

00:34:34,190 --> 00:34:41,030
list or with the trace back but um it's

00:34:38,260 --> 00:34:44,560
it's it's something like a hack for now

00:34:41,030 --> 00:34:47,740
so we think that

00:34:44,560 --> 00:34:50,800
the first other people to use this with

00:34:47,740 --> 00:34:54,120
a different programming language we'll

00:34:50,800 --> 00:34:56,830
probably have to figure this out for us

00:34:54,120 --> 00:34:59,410
but yeah I will probably at some point

00:34:56,830 --> 00:35:02,370
write some kind of premium spec to to

00:34:59,410 --> 00:35:02,370
help other implementations

00:35:03,570 --> 00:35:08,590
how do you do offline development and

00:35:06,580 --> 00:35:11,290
how are you test against your remote

00:35:08,590 --> 00:35:14,500
servers so how do we do offline

00:35:11,290 --> 00:35:15,610
development so like like you're on a

00:35:14,500 --> 00:35:17,170
plane and you're adding a new feature

00:35:15,610 --> 00:35:18,910
but you can't talk to any of your

00:35:17,170 --> 00:35:22,990
service oh so if I'm on the painting I

00:35:18,910 --> 00:35:25,270
want to work on this well we in our

00:35:22,990 --> 00:35:27,070
specific case we just happen to have a

00:35:25,270 --> 00:35:28,480
virtual machine with a staging version

00:35:27,070 --> 00:35:33,070
of the whole platform with all the

00:35:28,480 --> 00:35:35,890
services running in it and actually in

00:35:33,070 --> 00:35:40,860
that case 0 RPC helped a little bit

00:35:35,890 --> 00:35:45,550
because the naming system that we had

00:35:40,860 --> 00:35:47,050
this ugly ml file of shame helped us to

00:35:45,550 --> 00:35:49,600
to have those different versions

00:35:47,050 --> 00:35:53,560
production staging development little

00:35:49,600 --> 00:35:57,100
machine but we don't have anything to so

00:35:53,560 --> 00:35:59,050
you can make calls and have some magic

00:35:57,100 --> 00:36:01,690
happen well actually if you make your PC

00:35:59,050 --> 00:36:03,430
calls since its room cue as soon as you

00:36:01,690 --> 00:36:05,110
have network connectivity again the call

00:36:03,430 --> 00:36:09,910
will make it to the server and you will

00:36:05,110 --> 00:36:11,680
get the reply but there is nothing else

00:36:09,910 --> 00:36:13,600
than just well you can have mock-ups for

00:36:11,680 --> 00:36:18,700
your services and stuff like that but we

00:36:13,600 --> 00:36:20,760
really don't try to address that thank

00:36:18,700 --> 00:36:20,760

YouTube URL: https://www.youtube.com/watch?v=9G6-GksU7Ko


