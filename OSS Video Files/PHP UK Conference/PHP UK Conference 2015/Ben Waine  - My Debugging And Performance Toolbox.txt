Title: Ben Waine  - My Debugging And Performance Toolbox
Publication date: 2015-04-02
Playlist: PHP UK Conference 2015
Description: 
	In addition to PHP I use a number of tools on a day to day basis to debug and QA my work. This talk is an opinionated overview and live demo of these tools, what they do and how they fit together. The tools I'll be demoing are: Charles Proxy, XDebug, Xhprof and JMeter. I will also demo integrating these with Behat and PHPUnit. The aim of the talk is to show that by using testing, a proxy and Xdebug an engineer can get to the bottom of most PHP problems very quickly. Building on this approach using testing, Xhprof and JMeter it's possible to understand the performance characteristics of your code at scale.
Captions: 
	00:00:00,000 --> 00:00:02,060
you

00:00:05,300 --> 00:00:11,540
um well thank you very much for coming

00:00:07,940 --> 00:00:14,000
to the talk my debugging and performance

00:00:11,540 --> 00:00:16,520
tool box for those of you that haven't

00:00:14,000 --> 00:00:17,900
met me before my name is Ben Wayne and

00:00:16,520 --> 00:00:21,050
I've worked with PHP for about five

00:00:17,900 --> 00:00:23,750
years I'm and I am a software engineer

00:00:21,050 --> 00:00:25,790
at Sainsbury's one of the sponsors of

00:00:23,750 --> 00:00:27,020
the conference we're hiring for all

00:00:25,790 --> 00:00:28,430
different types of roles at the moment

00:00:27,020 --> 00:00:30,349
so if you're interested any of the stuff

00:00:28,430 --> 00:00:32,180
I've talked about either yesterday or

00:00:30,349 --> 00:00:35,270
today then make sure you come and see me

00:00:32,180 --> 00:00:38,239
we'll talk about it occasionally I

00:00:35,270 --> 00:00:39,710
dabble in a double in DevOps much to the

00:00:38,239 --> 00:00:42,980
consternation of the people who actually

00:00:39,710 --> 00:00:44,600
have that role in our organization and a

00:00:42,980 --> 00:00:46,160
lot of the stuff I'm going to talk about

00:00:44,600 --> 00:00:50,589
today is is a little bit dev ops ii in

00:00:46,160 --> 00:00:53,210
nature I'm this is the link to the

00:00:50,589 --> 00:00:55,070
joined in page where you can review the

00:00:53,210 --> 00:00:59,629
talk afterwards give me some positive

00:00:55,070 --> 00:01:03,050
for some negative feedback so when I

00:00:59,629 --> 00:01:04,879
started making this talk um I was trying

00:01:03,050 --> 00:01:07,970
to think of a pity way to sum it up and

00:01:04,879 --> 00:01:09,950
what I got to was what I'm about to show

00:01:07,970 --> 00:01:11,690
you is a very opinionated view about how

00:01:09,950 --> 00:01:14,570
to connect a range of different tools

00:01:11,690 --> 00:01:17,150
together for the purposes of isolating

00:01:14,570 --> 00:01:20,560
errors quickly in development and also

00:01:17,150 --> 00:01:24,110
as they appear in staging and production

00:01:20,560 --> 00:01:26,810
I'm the other thing to say is that as a

00:01:24,110 --> 00:01:29,120
contractor I often come into a new code

00:01:26,810 --> 00:01:30,560
base every six to nine months and the

00:01:29,120 --> 00:01:32,990
tools that I'm wiring together today

00:01:30,560 --> 00:01:35,720
help me get to the core of issues really

00:01:32,990 --> 00:01:37,460
quickly in a new code base and that's

00:01:35,720 --> 00:01:40,460
why I've put a lot of time into kind of

00:01:37,460 --> 00:01:42,740
connecting them together I'm equally

00:01:40,460 --> 00:01:45,320
when I then go to another developers

00:01:42,740 --> 00:01:46,490
desk to help them with a problem I'll

00:01:45,320 --> 00:01:48,320
reach out for one of these tools and

00:01:46,490 --> 00:01:50,120
they they just are there and I feel a

00:01:48,320 --> 00:01:53,660
bit like i'm debugging naked or

00:01:50,120 --> 00:01:55,010
something I'm so I then have this

00:01:53,660 --> 00:01:59,840
conversation which I've put into

00:01:55,010 --> 00:02:01,610
presentation form um most of this is a

00:01:59,840 --> 00:02:03,410
live demo so there aren't many slides

00:02:01,610 --> 00:02:05,540
I'm just going to switch screens in a

00:02:03,410 --> 00:02:07,670
minute and demonstrate a few of the

00:02:05,540 --> 00:02:10,099
tools so if you'll all join me in a

00:02:07,670 --> 00:02:15,500
moment of silence of prayer for the demo

00:02:10,099 --> 00:02:17,540
gods I'm what am I going to talk about

00:02:15,500 --> 00:02:19,010
some of these tools you may have already

00:02:17,540 --> 00:02:23,989
used or perhaps or

00:02:19,010 --> 00:02:26,840
I'm the first one is Charles proxy it is

00:02:23,989 --> 00:02:29,269
a HTTP proxy it sits between you and it

00:02:26,840 --> 00:02:30,980
and say in the browser or as an API

00:02:29,269 --> 00:02:33,200
client and then the server that you're

00:02:30,980 --> 00:02:35,000
calling to I'm it's really useful

00:02:33,200 --> 00:02:37,489
because it takes it makes a log of all

00:02:35,000 --> 00:02:40,159
that traffic and then exposes that too

00:02:37,489 --> 00:02:42,319
so you can look for patterns in the data

00:02:40,159 --> 00:02:44,420
that might reveal an error that you have

00:02:42,319 --> 00:02:46,159
maybe a field that you're expecting to

00:02:44,420 --> 00:02:50,720
be true is false and this provides you

00:02:46,159 --> 00:02:52,069
with a quick look at that the next tool

00:02:50,720 --> 00:02:54,280
and probably one of the more interesting

00:02:52,069 --> 00:02:56,629
ones I'm going to talk about is X debug

00:02:54,280 --> 00:02:58,760
it has a range of different features but

00:02:56,629 --> 00:03:00,859
the crown jewels for me is remote

00:02:58,760 --> 00:03:03,889
debugging which allows you to put a

00:03:00,859 --> 00:03:06,260
breakpoint in the code and and then as

00:03:03,889 --> 00:03:08,359
you execute the code stop at that break

00:03:06,260 --> 00:03:11,930
point and see what's going on so things

00:03:08,359 --> 00:03:14,720
like variable state and and the path the

00:03:11,930 --> 00:03:17,269
code takes through the path the request

00:03:14,720 --> 00:03:21,010
takes to the code it's really really

00:03:17,269 --> 00:03:23,900
interesting so moving away from

00:03:21,010 --> 00:03:26,000
development and debugging and kind of

00:03:23,900 --> 00:03:30,430
into the development staging and

00:03:26,000 --> 00:03:34,609
production area is X 8 prov x8 prof is a

00:03:30,430 --> 00:03:37,010
hierarchical PHP profiler and you can

00:03:34,609 --> 00:03:38,449
sum this up as a system which shows you

00:03:37,010 --> 00:03:41,540
a list of all the function calls that

00:03:38,449 --> 00:03:45,139
were used to service a request and it

00:03:41,540 --> 00:03:47,690
shows you how long you spend in the CPU

00:03:45,139 --> 00:03:49,699
how much time each function took how

00:03:47,690 --> 00:03:51,260
many times it was called so really

00:03:49,699 --> 00:03:53,500
useful information to figure out where

00:03:51,260 --> 00:03:56,000
the bottlenecks in your system are and

00:03:53,500 --> 00:03:58,940
then finally in the kind of staging and

00:03:56,000 --> 00:04:01,340
production area you've got jmeter so

00:03:58,940 --> 00:04:03,199
jmeter takes a user journey through your

00:04:01,340 --> 00:04:07,120
site but allows you two times the load

00:04:03,199 --> 00:04:10,280
by X number of users and as we all know

00:04:07,120 --> 00:04:12,530
in development code will perform one way

00:04:10,280 --> 00:04:14,750
in production with access to bigger data

00:04:12,530 --> 00:04:17,030
or more users it performs a very

00:04:14,750 --> 00:04:19,070
different way so we really need to

00:04:17,030 --> 00:04:20,570
figure out a way to simulate that before

00:04:19,070 --> 00:04:24,050
he goes into production and that's what

00:04:20,570 --> 00:04:26,780
jay meters for so for testing i'm using

00:04:24,050 --> 00:04:29,120
behat and phpunit but this isn't a

00:04:26,780 --> 00:04:31,550
testing talk really it's a talk on how

00:04:29,120 --> 00:04:34,450
to integrate all of the above with those

00:04:31,550 --> 00:04:34,450
two testing two

00:04:34,690 --> 00:04:39,310
so for the purposes of this talk have

00:04:37,010 --> 00:04:42,560
produced a very simple demo application

00:04:39,310 --> 00:04:45,230
it's got two end points the first one

00:04:42,560 --> 00:04:47,090
creates a uuid which is just a big

00:04:45,230 --> 00:04:49,550
string and then stores it in a file and

00:04:47,090 --> 00:04:51,980
then the second one lets you get a list

00:04:49,550 --> 00:04:53,360
of those uu IDs it's about five lines of

00:04:51,980 --> 00:04:55,670
code in each one of those methods but

00:04:53,360 --> 00:04:57,230
it's just enough to demonstrate and the

00:04:55,670 --> 00:05:01,940
debugging and performance profiling

00:04:57,230 --> 00:05:05,860
tools I'm and all of the code is here

00:05:01,940 --> 00:05:09,680
I'm love software / toolbox demo a

00:05:05,860 --> 00:05:11,630
github so hopefully the screen will be

00:05:09,680 --> 00:05:12,470
big enough I have tested it but if you

00:05:11,630 --> 00:05:19,420
want to follow along when you're on

00:05:12,470 --> 00:05:19,420
laptop please go to that address now so

00:05:20,140 --> 00:05:26,690
those are all the slides I have so this

00:05:24,710 --> 00:05:28,280
is the this is the code base that I'm

00:05:26,690 --> 00:05:29,690
going to demo today the first thing to

00:05:28,280 --> 00:05:32,210
point out is that it's got a vagrant

00:05:29,690 --> 00:05:34,940
file so if later on you want to try this

00:05:32,210 --> 00:05:38,480
at home check out the repository I do a

00:05:34,940 --> 00:05:41,450
vagrant up and and at the end of this

00:05:38,480 --> 00:05:43,160
file is it is this line here which will

00:05:41,450 --> 00:05:45,350
tell it to run a provisioning script

00:05:43,160 --> 00:05:47,990
that provisioning script is up in this

00:05:45,350 --> 00:05:49,760
build directory and it sets up all the

00:05:47,990 --> 00:05:53,030
tools that I'm going to talk about today

00:05:49,760 --> 00:05:55,340
so it sets up XD bug it sets up XH prof

00:05:53,030 --> 00:05:58,250
and it also sets up the demo web

00:05:55,340 --> 00:06:03,230
application so that you can really get

00:05:58,250 --> 00:06:05,450
into these tools straight away okay so I

00:06:03,230 --> 00:06:08,690
suppose I best show you the actual code

00:06:05,450 --> 00:06:11,540
and as I said this is very simple it's a

00:06:08,690 --> 00:06:14,360
cylex application silex is a routing

00:06:11,540 --> 00:06:18,980
framework and it allows you to map

00:06:14,360 --> 00:06:20,810
lambda functions to bits of code so here

00:06:18,980 --> 00:06:24,890
you can see their foes to post to the

00:06:20,810 --> 00:06:27,560
uuid endpoint then I would create a uuid

00:06:24,890 --> 00:06:29,330
string at persist it using a bit of code

00:06:27,560 --> 00:06:31,670
that I've written and then in the

00:06:29,330 --> 00:06:35,030
response I'd return adjacent encoded

00:06:31,670 --> 00:06:41,840
version of that uuid so really simple

00:06:35,030 --> 00:06:44,600
and then correspondingly for the get you

00:06:41,840 --> 00:06:46,220
you IDs and this will get all the UU IDs

00:06:44,600 --> 00:06:48,560
that have been created

00:06:46,220 --> 00:06:51,320
then Jason encode them and return them

00:06:48,560 --> 00:06:52,670
to the client and that's all the code

00:06:51,320 --> 00:06:56,000
really that we're going to that we're

00:06:52,670 --> 00:06:59,660
going to touch on today so let's take a

00:06:56,000 --> 00:07:02,000
look at this in the browser see what it

00:06:59,660 --> 00:07:03,260
does this is the kind of get you ids bit

00:07:02,000 --> 00:07:05,960
you can see I've been playing with it

00:07:03,260 --> 00:07:11,180
today lots and lots of you you IDs on a

00:07:05,960 --> 00:07:13,670
string I'm okay so the first thing i

00:07:11,180 --> 00:07:16,790
want to show you is Charles so I'm there

00:07:13,670 --> 00:07:19,360
a number of tools you could use to do

00:07:16,790 --> 00:07:21,650
this Windows users might use fiddler

00:07:19,360 --> 00:07:29,660
linux users there's a version of Charles

00:07:21,650 --> 00:07:39,200
for you as well it's it's small okay let

00:07:29,660 --> 00:07:41,030
me see I'm not sure I can zoom it this

00:07:39,200 --> 00:07:43,100
is quite a small part all the other bits

00:07:41,030 --> 00:07:45,530
like anything that's in a browser I can

00:07:43,100 --> 00:07:53,900
blow up for you this I don't think I can

00:07:45,530 --> 00:07:56,180
I'm actually check that so I go back to

00:07:53,900 --> 00:08:01,280
the browser and i refresh this youyou

00:07:56,180 --> 00:08:02,900
IDs I'm section here then in the proxy

00:08:01,280 --> 00:08:05,270
you get a list of all the requests which

00:08:02,900 --> 00:08:13,160
being made as they happen you can see

00:08:05,270 --> 00:08:16,930
them coming in I'm and then in the for

00:08:13,160 --> 00:08:19,550
each of them you can see an overview I'm

00:08:16,930 --> 00:08:21,680
or not actually you know what I'm just

00:08:19,550 --> 00:08:23,840
going to take two seconds just to change

00:08:21,680 --> 00:08:32,750
the display a little bit let's see if

00:08:23,840 --> 00:08:34,760
that works absolutely not no okay I'll

00:08:32,750 --> 00:08:36,860
talk you do these things I tell you what

00:08:34,760 --> 00:08:40,520
you go for that I will talk about what's

00:08:36,860 --> 00:08:42,409
on the screen so you can see a list of

00:08:40,520 --> 00:08:45,650
requests which are made from the browser

00:08:42,409 --> 00:08:49,520
and to the end point that i discussed

00:08:45,650 --> 00:08:50,810
I'm and in the bottom window Charles is

00:08:49,520 --> 00:08:52,520
gathering and exposing loads of

00:08:50,810 --> 00:08:55,280
information to you so things like the

00:08:52,520 --> 00:08:57,800
request time the URL that you hit the

00:08:55,280 --> 00:08:59,240
response time and it will also show you

00:08:57,800 --> 00:08:59,660
all the headers that came back from the

00:08:59,240 --> 00:09:05,590
server

00:08:59,660 --> 00:09:08,720
and the content itself so this is useful

00:09:05,590 --> 00:09:11,150
but it's not really revolutionary you

00:09:08,720 --> 00:09:12,800
can do that in chrome by popping out the

00:09:11,150 --> 00:09:14,210
console and having a look you've

00:09:12,800 --> 00:09:17,570
probably all done this when your ton of

00:09:14,210 --> 00:09:19,310
debugging Ajax requests what's really

00:09:17,570 --> 00:09:22,160
useful is if you could integrate this

00:09:19,310 --> 00:09:25,450
into your testing tool I'm I reckon

00:09:22,160 --> 00:09:25,450
that's as close as we'll get thank you

00:09:25,540 --> 00:09:30,410
and if you could integrate this into

00:09:28,940 --> 00:09:32,120
your testing tool and if you imagine

00:09:30,410 --> 00:09:34,130
that you're developing an API which I

00:09:32,120 --> 00:09:37,430
often am and you're writing a client for

00:09:34,130 --> 00:09:39,230
that and then if we could send all the

00:09:37,430 --> 00:09:41,480
traffic from the test client through to

00:09:39,230 --> 00:09:43,430
the API then we could use this Charles

00:09:41,480 --> 00:09:46,040
proxy to isolate errors really quickly

00:09:43,430 --> 00:09:48,530
when something fails in a test suite so

00:09:46,040 --> 00:09:51,380
let's tell this to go away and let's

00:09:48,530 --> 00:09:54,410
look at how that might be done so here

00:09:51,380 --> 00:09:59,750
this I can zoom in for us and it's clear

00:09:54,410 --> 00:10:02,300
it I'm here I've got a test suite with B

00:09:59,750 --> 00:10:07,580
hat and if I go and show you what that

00:10:02,300 --> 00:10:09,110
looks like in the test folder um you

00:10:07,580 --> 00:10:11,930
basically right features like this in

00:10:09,110 --> 00:10:13,040
behat you have a scenario which

00:10:11,930 --> 00:10:15,440
describes something you want to achieve

00:10:13,040 --> 00:10:17,930
and then you have a number of steps and

00:10:15,440 --> 00:10:20,930
those steps a map to pieces of PHP code

00:10:17,930 --> 00:10:23,360
which go off and do things so here I'm

00:10:20,930 --> 00:10:26,140
creating a UID which is analogous to

00:10:23,360 --> 00:10:28,700
making an HTTP request to that service

00:10:26,140 --> 00:10:31,280
and then I'm checking that the response

00:10:28,700 --> 00:10:33,890
should contain a UID and this is really

00:10:31,280 --> 00:10:39,920
good it kind of covers the business case

00:10:33,890 --> 00:10:43,390
for this API and there they are there

00:10:39,920 --> 00:10:45,980
they are running now the way that I have

00:10:43,390 --> 00:10:51,140
mapped that textual string saying

00:10:45,980 --> 00:10:54,740
request is by using a HTTP library and

00:10:51,140 --> 00:10:57,950
that HTTP library respects this HTTP

00:10:54,740 --> 00:11:01,220
proxy environment variable so Charles is

00:10:57,950 --> 00:11:04,550
on the host machine listening on 8888

00:11:01,220 --> 00:11:06,620
and if I go over there now and I wipe

00:11:04,550 --> 00:11:11,450
all of the information from it run the

00:11:06,620 --> 00:11:13,400
tests again you can see that each one of

00:11:11,450 --> 00:11:15,200
those web service calls in the test

00:11:13,400 --> 00:11:19,070
now available to look at through Charles

00:11:15,200 --> 00:11:21,440
now before i was saying this really

00:11:19,070 --> 00:11:24,590
helps with some fault isolation so if i

00:11:21,440 --> 00:11:26,810
go back to the index and I look at my

00:11:24,590 --> 00:11:29,630
get you you IDs and if I just uncomment

00:11:26,810 --> 00:11:32,090
this response variable you can see that

00:11:29,630 --> 00:11:34,700
I'm over writing the list of you IDs

00:11:32,090 --> 00:11:42,110
with just an empty array now so the test

00:11:34,700 --> 00:11:45,470
should fail like so no you IDs in the

00:11:42,110 --> 00:11:47,450
response so why is that well we can now

00:11:45,470 --> 00:11:49,580
go into Charles we can look at the

00:11:47,450 --> 00:11:51,020
response look at the Jason that was

00:11:49,580 --> 00:11:53,600
returned and we can see the desert

00:11:51,020 --> 00:11:55,490
there's an empty array if we go back to

00:11:53,600 --> 00:11:57,080
one of the previous successful ones we

00:11:55,490 --> 00:12:00,380
can see there's an array full of those

00:11:57,080 --> 00:12:03,620
uuid strings so if you can imagine

00:12:00,380 --> 00:12:04,730
during development and you can have

00:12:03,620 --> 00:12:06,140
Charles running in the background all

00:12:04,730 --> 00:12:08,120
the time you can send all of your test

00:12:06,140 --> 00:12:09,770
data through it and you can quickly get

00:12:08,120 --> 00:12:21,290
an insight into the traffic between

00:12:09,770 --> 00:12:24,230
client and server okay so that's okay

00:12:21,290 --> 00:12:26,150
but if you can't immediately figure out

00:12:24,230 --> 00:12:28,220
what's going on from the kind of outside

00:12:26,150 --> 00:12:32,990
looking in we need to dive into the code

00:12:28,220 --> 00:12:36,260
and to do that we can use X debug so XD

00:12:32,990 --> 00:12:38,740
book provides this facility for remote

00:12:36,260 --> 00:12:42,650
debugging and it's activated using a

00:12:38,740 --> 00:12:44,300
cookie header so wouldn't it be great if

00:12:42,650 --> 00:12:46,550
we could get our proxy which is already

00:12:44,300 --> 00:12:48,800
plugged in to the test suite to drop

00:12:46,550 --> 00:12:51,920
that head of fours and then start a

00:12:48,800 --> 00:12:55,040
debugging session so luckily Charles

00:12:51,920 --> 00:12:59,000
does that I'm hopefully in a way that we

00:12:55,040 --> 00:13:01,520
can see yes so in this kind of rewrite

00:12:59,000 --> 00:13:04,700
section here we can set up a rewrite

00:13:01,520 --> 00:13:07,910
rule so for all of the requests that

00:13:04,700 --> 00:13:11,930
come through append this little X debug

00:13:07,910 --> 00:13:13,460
session cookie to them so that when that

00:13:11,930 --> 00:13:17,630
hits the server it will start a

00:13:13,460 --> 00:13:24,370
debugging session for us so let's go

00:13:17,630 --> 00:13:24,370
over to my debugger go to index dot PHP

00:13:24,929 --> 00:13:33,399
I'm set a breakpoint next to the first

00:13:29,230 --> 00:13:37,230
line in that function and then run the

00:13:33,399 --> 00:13:41,199
tests again and here you can see that

00:13:37,230 --> 00:13:42,579
it's broken at that point so the journey

00:13:41,199 --> 00:13:44,799
we've been on so far is we've kind of

00:13:42,579 --> 00:13:46,600
had a look in our HTTP proxy didn't

00:13:44,799 --> 00:13:48,369
really find what we want so we're now

00:13:46,600 --> 00:13:51,249
going one step deeper and actually line

00:13:48,369 --> 00:13:53,410
by line debugging the code again now

00:13:51,249 --> 00:13:56,649
when you're in that kind of mindset you

00:13:53,410 --> 00:13:58,540
can step 12 and then we see the response

00:13:56,649 --> 00:14:02,079
has been overwritten so we can fix that

00:13:58,540 --> 00:14:03,639
bug but this is all happening while your

00:14:02,079 --> 00:14:06,309
test suite is actually running so if we

00:14:03,639 --> 00:14:08,319
want to kind of do that again run the

00:14:06,309 --> 00:14:13,089
tests over and over again until we find

00:14:08,319 --> 00:14:15,549
the the outcome that we want for me that

00:14:13,089 --> 00:14:23,379
provides a and then obviously go and fix

00:14:15,549 --> 00:14:26,290
the bug like so for me that provides a

00:14:23,379 --> 00:14:30,879
really tight development cycle by

00:14:26,290 --> 00:14:34,709
powering XD bug from your tests now XD

00:14:30,879 --> 00:14:37,029
bug does a number of brilliant things um

00:14:34,709 --> 00:14:39,040
if anybody is used to working with

00:14:37,029 --> 00:14:45,220
legacy code you've probably seen code

00:14:39,040 --> 00:14:47,679
like this so the f open command here if

00:14:45,220 --> 00:14:51,189
that file doesn't exist then it causes a

00:14:47,679 --> 00:14:52,480
notice to appear and there's nothing you

00:14:51,189 --> 00:14:54,999
can do to catch that or stop it

00:14:52,480 --> 00:14:58,209
displaying really it just happens so

00:14:54,999 --> 00:15:00,549
quite often people have done this and

00:14:58,209 --> 00:15:02,919
put an add operator in front of it this

00:15:00,549 --> 00:15:04,660
happens in kind of legacy code bit code

00:15:02,919 --> 00:15:06,399
bases like wordpress drupal all the time

00:15:04,660 --> 00:15:09,220
it can be really difficult to track that

00:15:06,399 --> 00:15:11,529
down so let's take a look at it so we've

00:15:09,220 --> 00:15:13,350
got our errors displayed on and then

00:15:11,529 --> 00:15:15,939
we're trying to open a non existing file

00:15:13,350 --> 00:15:20,949
so if we go to their kind of x debug

00:15:15,939 --> 00:15:24,519
endpoint that i made like that then you

00:15:20,949 --> 00:15:26,999
get this kind of huge error so let's try

00:15:24,519 --> 00:15:30,910
and hide that are using the add operator

00:15:26,999 --> 00:15:32,289
yeah it's gone away but when you're

00:15:30,910 --> 00:15:34,779
actually trying to debug a problem which

00:15:32,289 --> 00:15:36,759
is hidden in a function which has been

00:15:34,779 --> 00:15:37,690
suppressed like that you can literally

00:15:36,759 --> 00:15:39,190
kind of

00:15:37,690 --> 00:15:42,690
not round the code base for hours trying

00:15:39,190 --> 00:15:46,180
to find it so XD book allows you to

00:15:42,690 --> 00:15:48,550
override that and even if the operator

00:15:46,180 --> 00:15:50,890
is on skreet the scream setting will

00:15:48,550 --> 00:15:53,560
insist that that error turns up on the

00:15:50,890 --> 00:15:55,390
screen and in your logs as well so

00:15:53,560 --> 00:15:58,030
really nice way to when you're debugging

00:15:55,390 --> 00:16:00,430
legacy code bases to figure out

00:15:58,030 --> 00:16:03,070
potential problems so let's turn both of

00:16:00,430 --> 00:16:05,170
those off at the moment should have

00:16:03,070 --> 00:16:11,590
purchased some sublime licensing before

00:16:05,170 --> 00:16:14,980
this talk sorry sublime guys okay so by

00:16:11,590 --> 00:16:18,340
default em the HTML errors flag is

00:16:14,980 --> 00:16:21,610
turned on in PHP when it's turned on an

00:16:18,340 --> 00:16:23,410
ex debug is installed XD bug will

00:16:21,610 --> 00:16:27,070
override the bottom and do some nice

00:16:23,410 --> 00:16:29,770
pretty printing so this is what Ave Adam

00:16:27,070 --> 00:16:33,220
normally looks like and then if we

00:16:29,770 --> 00:16:36,940
return to the default settings of HTML

00:16:33,220 --> 00:16:40,480
errors being on refresh this is what a

00:16:36,940 --> 00:16:42,340
Varden looks like now now something I

00:16:40,480 --> 00:16:45,190
say in the office all the time is that

00:16:42,340 --> 00:16:47,260
friends don't let friends VAR dump in

00:16:45,190 --> 00:16:48,820
order to debug I think it's really

00:16:47,260 --> 00:16:50,590
terrible practice because occasionally

00:16:48,820 --> 00:16:52,660
one of those vadims ends up in

00:16:50,590 --> 00:16:55,210
production code everybody gets really

00:16:52,660 --> 00:16:57,400
embarrassed it's much much better to do

00:16:55,210 --> 00:16:58,960
remote debugging work possible but

00:16:57,400 --> 00:17:00,280
equally sometimes you have a huge data

00:16:58,960 --> 00:17:03,340
structure which you want to be on screen

00:17:00,280 --> 00:17:14,740
and in that case I'd recommend doing

00:17:03,340 --> 00:17:17,920
this so that's the kind of X debug

00:17:14,740 --> 00:17:21,220
aspect to this talk I'm going to talk

00:17:17,920 --> 00:17:25,810
about XH prof now I'm the hierarchical

00:17:21,220 --> 00:17:29,230
PHP tool i mentioned so if we look at

00:17:25,810 --> 00:17:33,420
the the top of this code base here i'm

00:17:29,230 --> 00:17:37,390
including a script which starts XH prof

00:17:33,420 --> 00:17:41,110
and at the bottom i'm including a script

00:17:37,390 --> 00:17:45,730
which stops XH prof so if I take a look

00:17:41,110 --> 00:17:50,890
at those scripts look at the pre one

00:17:45,730 --> 00:17:51,640
first I'm requiring some XH prof library

00:17:50,890 --> 00:17:55,280
code

00:17:51,640 --> 00:17:58,010
I'm and I'm turning on XH prof. for the

00:17:55,280 --> 00:18:00,050
duration of this request and then I'm

00:17:58,010 --> 00:18:01,190
picking a name for the session that this

00:18:00,050 --> 00:18:04,100
is going to generate that we're going to

00:18:01,190 --> 00:18:09,260
look after and then I'm sending that

00:18:04,100 --> 00:18:12,590
name back as a header and then after all

00:18:09,260 --> 00:18:17,990
the code is executed I'm saving that run

00:18:12,590 --> 00:18:20,540
I'm for kind of viewing later on so if

00:18:17,990 --> 00:18:22,100
we go back to pre why am I generating

00:18:20,540 --> 00:18:24,290
the session name before the things been

00:18:22,100 --> 00:18:26,360
saved well the reason for that is if I

00:18:24,290 --> 00:18:31,400
send it back as a header I can use

00:18:26,360 --> 00:18:33,710
Charles to then map individual requests

00:18:31,400 --> 00:18:36,350
to X age proffer ins for analysis later

00:18:33,710 --> 00:18:38,690
on and this is really useful during

00:18:36,350 --> 00:18:40,220
development but it's really useful when

00:18:38,690 --> 00:18:42,470
you're doing load testing because what

00:18:40,220 --> 00:18:43,910
you want to do is pick the kind of 10

00:18:42,470 --> 00:18:46,580
requests that failed in that high

00:18:43,910 --> 00:18:52,010
throughput load test and then go back

00:18:46,580 --> 00:18:57,790
and have a look at their XH prof runs so

00:18:52,010 --> 00:18:59,870
let's take a look at go back to Charles

00:18:57,790 --> 00:19:02,810
and we take a look at some of the

00:18:59,870 --> 00:19:05,180
headers which have been generated in the

00:19:02,810 --> 00:19:07,940
kind of tests which we've just run so

00:19:05,180 --> 00:19:11,240
you can see the guys in the front row

00:19:07,940 --> 00:19:15,400
can see that there is an X H prof run ID

00:19:11,240 --> 00:19:19,000
there so that uniquely identifies a run

00:19:15,400 --> 00:19:21,860
which was generated by one of our tests

00:19:19,000 --> 00:19:26,270
which we can then go and have a look at

00:19:21,860 --> 00:19:29,420
so let's do it so this is all in the

00:19:26,270 --> 00:19:33,710
kind of vagrant file and in the readme

00:19:29,420 --> 00:19:37,610
see you can do this yourself later on if

00:19:33,710 --> 00:19:40,490
i go to / x h prof and and look at the

00:19:37,610 --> 00:19:42,980
HTML endpoint that it provides and then

00:19:40,490 --> 00:19:44,720
i do a search I can see in this big long

00:19:42,980 --> 00:19:46,760
list of ex age proffer ins that I've

00:19:44,720 --> 00:19:49,010
generated that this is the one I'm

00:19:46,760 --> 00:19:52,780
interested in so if I click through to

00:19:49,010 --> 00:19:57,770
it and zoom out a little bit I think

00:19:52,780 --> 00:20:00,470
okay I'm then I get to see a wealth of

00:19:57,770 --> 00:20:03,070
information about a test run which was

00:20:00,470 --> 00:20:07,299
generated by one of my behavioral tests

00:20:03,070 --> 00:20:10,230
I'm so having a look at the information

00:20:07,299 --> 00:20:15,549
that's available I'm in the top box

00:20:10,230 --> 00:20:19,960
should I just magnify in the top box you

00:20:15,549 --> 00:20:21,850
can see wall time and cpu time memory

00:20:19,960 --> 00:20:23,950
usage peak memory usage and then the

00:20:21,850 --> 00:20:26,169
number of function calls which went into

00:20:23,950 --> 00:20:28,529
generating that request so looking at

00:20:26,169 --> 00:20:31,299
some of those metrics individually

00:20:28,529 --> 00:20:35,320
inclusive of all time is how long it

00:20:31,299 --> 00:20:37,659
took including everything CPU time was

00:20:35,320 --> 00:20:42,820
how long it's been in the cpu processing

00:20:37,659 --> 00:20:45,220
I'm memory use was the total amount of

00:20:42,820 --> 00:20:48,279
memory used and then there's peak memory

00:20:45,220 --> 00:20:51,509
usage which is how i went up to and then

00:20:48,279 --> 00:20:53,919
there's number of function calls taken

00:20:51,509 --> 00:20:56,559
so they provide you with some nice top

00:20:53,919 --> 00:20:58,539
level information about what's going on

00:20:56,559 --> 00:21:00,429
note at this point in order just to

00:20:58,539 --> 00:21:04,690
produce that simple example I seem to

00:21:00,429 --> 00:21:05,980
have called 2116 functions really bad

00:21:04,690 --> 00:21:10,600
and we're going to address that in a

00:21:05,980 --> 00:21:14,139
minute and then you see below that a

00:21:10,600 --> 00:21:16,779
list of all the function calls so if I

00:21:14,139 --> 00:21:20,860
sort them by this metric here exclusive

00:21:16,779 --> 00:21:23,320
wall time and all of these are clickable

00:21:20,860 --> 00:21:25,809
and so you can sort the whole run in a

00:21:23,320 --> 00:21:27,759
number of different ways exclusive wall

00:21:25,809 --> 00:21:29,919
time is the amount of time spent in a

00:21:27,759 --> 00:21:32,470
function excluding the amount of time

00:21:29,919 --> 00:21:35,500
spent in any functions that that

00:21:32,470 --> 00:21:37,899
function calls so in this case file

00:21:35,500 --> 00:21:39,850
exists is right at the top here so we

00:21:37,899 --> 00:21:43,389
must be doing a lot of work with the

00:21:39,850 --> 00:21:45,850
file system I'm so that seems a little

00:21:43,389 --> 00:21:49,750
bit odd and we'll come back to that in a

00:21:45,850 --> 00:21:54,100
moment I'm you can also sort things by a

00:21:49,750 --> 00:21:56,259
number of calls made so loads of string

00:21:54,100 --> 00:21:59,799
functions string-- pause string string

00:21:56,259 --> 00:22:02,019
substring I'm you know they look a

00:21:59,799 --> 00:22:04,629
little bit suspicious as well we're only

00:22:02,019 --> 00:22:05,980
returning some roni returning a little

00:22:04,629 --> 00:22:07,450
bit of data why are we calling them all

00:22:05,980 --> 00:22:10,860
these are all questions you can ask

00:22:07,450 --> 00:22:10,860
yourself because we're seeing this data

00:22:12,480 --> 00:22:15,850
so the next thing I'm going to show you

00:22:14,440 --> 00:22:17,350
I'm

00:22:15,850 --> 00:22:22,140
at first glance it looks a little bit

00:22:17,350 --> 00:22:22,140
mind-boggling which is the call graph

00:22:23,190 --> 00:22:32,200
there it is so this is a call graph

00:22:29,740 --> 00:22:33,789
which represents all the different

00:22:32,200 --> 00:22:36,700
functions which were called in the order

00:22:33,789 --> 00:22:38,410
that they were called it's really big at

00:22:36,700 --> 00:22:41,230
the moment but let's just zoom in at the

00:22:38,410 --> 00:22:44,710
top where we should see some things that

00:22:41,230 --> 00:22:45,940
were we expect to see autoloading that

00:22:44,710 --> 00:22:49,330
normally happens at the start of a

00:22:45,940 --> 00:22:54,190
request um and you can see we go down a

00:22:49,330 --> 00:22:57,760
path of autoloading here and pimple

00:22:54,190 --> 00:23:00,039
offset get that is part of the pimple

00:22:57,760 --> 00:23:03,400
dependency injection container so we're

00:23:00,039 --> 00:23:05,440
seeing on this graph things that we

00:23:03,400 --> 00:23:07,299
would expect to see based on our

00:23:05,440 --> 00:23:09,100
knowledge of the code base so if i zoom

00:23:07,299 --> 00:23:12,190
out a little bit and then zoom in on

00:23:09,100 --> 00:23:13,990
this big red box this is file exists so

00:23:12,190 --> 00:23:16,360
this is where we're spending all of our

00:23:13,990 --> 00:23:22,150
time and it's right at the bottom of a

00:23:16,360 --> 00:23:25,299
big chain of function calls so I wonder

00:23:22,150 --> 00:23:28,620
why dye is actually I've didn't think to

00:23:25,299 --> 00:23:28,620
ask this does anybody know why that is

00:23:29,429 --> 00:23:37,539
sorry class loading exactly so this has

00:23:35,620 --> 00:23:39,730
pulled up the fact that our autoloader

00:23:37,539 --> 00:23:41,950
is being created in a strange way every

00:23:39,730 --> 00:23:43,600
single time we make the request there's

00:23:41,950 --> 00:23:50,710
a very easy way to solve that which is

00:23:43,600 --> 00:23:52,929
to optimize the autoloader which I

00:23:50,710 --> 00:23:57,990
thought was in my class history never

00:23:52,929 --> 00:24:02,140
mind and so PHP compose it up bar

00:23:57,990 --> 00:24:07,150
install and I think mine is minus

00:24:02,140 --> 00:24:12,640
optimized Optima with a Z optimized

00:24:07,150 --> 00:24:14,890
autoloader okay

00:24:12,640 --> 00:24:16,210
so it's taking a little bit more time

00:24:14,890 --> 00:24:18,160
than it normally would but it's

00:24:16,210 --> 00:24:20,050
generating optimized autoloader which

00:24:18,160 --> 00:24:22,240
will then use again so what I'm going to

00:24:20,050 --> 00:24:24,460
show you now is the difference between 1

00:24:22,240 --> 00:24:27,160
x.x agecroft run and then the next one

00:24:24,460 --> 00:24:29,040
and you can think of this as a bit of a

00:24:27,160 --> 00:24:32,500
thought exercise as to the process of

00:24:29,040 --> 00:24:35,920
optimizing and then looking for change

00:24:32,500 --> 00:24:38,050
in each subsequent run so we've

00:24:35,920 --> 00:24:39,550
optimized the autoloader all we have to

00:24:38,050 --> 00:24:44,200
do to generate more information is run

00:24:39,550 --> 00:24:47,140
our tests again so run the tests turn

00:24:44,200 --> 00:24:52,720
this off excuse the results run the test

00:24:47,140 --> 00:24:54,790
and then go back to Charles go to the

00:24:52,720 --> 00:24:56,080
bottom of the list and then look at the

00:24:54,790 --> 00:24:59,910
headers in the response we've got a

00:24:56,080 --> 00:25:05,200
unique identifier again in Charles and

00:24:59,910 --> 00:25:11,340
and then let's go back back again back

00:25:05,200 --> 00:25:16,390
again refresh and here is the the run

00:25:11,340 --> 00:25:17,770
click through to it so I'm already just

00:25:16,390 --> 00:25:21,220
in the top level information there's a

00:25:17,770 --> 00:25:23,320
kind of market difference between what

00:25:21,220 --> 00:25:25,570
we did previously which is over 2,000

00:25:23,320 --> 00:25:29,350
function calls and what we got now which

00:25:25,570 --> 00:25:32,050
is around 1400 function calls so really

00:25:29,350 --> 00:25:33,400
quick difference in a quick win and if

00:25:32,050 --> 00:25:39,070
we view the call graph I think there's

00:25:33,400 --> 00:25:40,600
going to be a huge difference so if you

00:25:39,070 --> 00:25:43,390
think about the size of the previous one

00:25:40,600 --> 00:25:44,920
this one's a lot smaller and now we're

00:25:43,390 --> 00:25:49,540
spending a lot of time in a different

00:25:44,920 --> 00:25:52,090
area of the application so if I sort by

00:25:49,540 --> 00:25:55,480
exclusive wall time again now we're

00:25:52,090 --> 00:25:59,920
spending a lot of our time in autoload

00:25:55,480 --> 00:26:02,950
class map I'm but significantly less

00:25:59,920 --> 00:26:06,550
than seventy nine percent of the time in

00:26:02,950 --> 00:26:09,520
file exists I'm another thing that you

00:26:06,550 --> 00:26:14,920
can do is compare one run with another

00:26:09,520 --> 00:26:18,730
run so um if I go back to this page this

00:26:14,920 --> 00:26:21,000
is the ID of the first one that we

00:26:18,730 --> 00:26:21,000
called

00:26:22,929 --> 00:26:31,460
oh discipline okay yes you're right I'm

00:26:28,720 --> 00:26:33,650
so you have to do a bit of trickery here

00:26:31,460 --> 00:26:36,500
you have to go run one and then you have

00:26:33,650 --> 00:26:41,270
to put in the ID and then you have to do

00:26:36,500 --> 00:26:45,980
run to you n 2 equals you have to go

00:26:41,270 --> 00:26:52,610
back and find the other ID like so place

00:26:45,980 --> 00:26:55,730
then I am but after that you get a

00:26:52,610 --> 00:26:58,429
comparison between the two runs so now

00:26:55,730 --> 00:27:00,110
we can see I'm the second run which was

00:26:58,429 --> 00:27:03,170
run with the optimized autoloader is

00:27:00,110 --> 00:27:06,460
significantly more performant in terms

00:27:03,170 --> 00:27:09,500
of actual time inclusive of all time and

00:27:06,460 --> 00:27:11,840
the CPU and the number of function calls

00:27:09,500 --> 00:27:14,210
but it doesn't perform as well in memory

00:27:11,840 --> 00:27:16,750
so that brings me on to the point there

00:27:14,210 --> 00:27:19,100
and when you're trying to optimize

00:27:16,750 --> 00:27:23,270
optimize one thing at a time it's very

00:27:19,100 --> 00:27:25,550
easy to get lost by kind of optimizing

00:27:23,270 --> 00:27:27,170
for cpu for 10 minutes and then going

00:27:25,550 --> 00:27:30,679
for memory it should take a really

00:27:27,170 --> 00:27:33,850
rigorous approach and I've got an

00:27:30,679 --> 00:27:37,429
article in the readme file this one I

00:27:33,850 --> 00:27:40,790
saw a talk by Lorenzo alberton about XH

00:27:37,429 --> 00:27:42,410
prof ages ago and the Renzo is really

00:27:40,790 --> 00:27:45,650
rigorous person anyway all of his

00:27:42,410 --> 00:27:47,210
writing is absolutely brilliant but he

00:27:45,650 --> 00:27:50,150
shows you how to get started with XH

00:27:47,210 --> 00:27:53,990
prof there I'm and if you like me you're

00:27:50,150 --> 00:27:56,870
probably thinking pasting IDs into

00:27:53,990 --> 00:27:59,809
strings in order to do comparisons is

00:27:56,870 --> 00:28:02,780
really it's a pain so underneath that

00:27:59,809 --> 00:28:05,380
there's an article by lorna talking

00:28:02,780 --> 00:28:09,620
about how to start with X H prof GUI and

00:28:05,380 --> 00:28:11,510
that's a step up in terms of you I but

00:28:09,620 --> 00:28:15,020
it's also more complex to install so I

00:28:11,510 --> 00:28:18,230
didn't do it for this demo and then

00:28:15,020 --> 00:28:20,960
worth a mention is a sin CEO of have

00:28:18,230 --> 00:28:23,210
produced a kind of next generation x h

00:28:20,960 --> 00:28:25,790
prof like tool which apparently has a

00:28:23,210 --> 00:28:26,900
really good UI I've not had time to test

00:28:25,790 --> 00:28:29,480
it personally but I think it's

00:28:26,900 --> 00:28:31,130
definitely worth a mention i think it's

00:28:29,480 --> 00:28:34,399
called black fire i oh so if you're

00:28:31,130 --> 00:28:43,789
interested make sure you check it out

00:28:34,399 --> 00:28:46,589
so we've now got a sequencer like a

00:28:43,789 --> 00:28:49,229
development pipeline as it were you are

00:28:46,589 --> 00:28:52,049
writing behavioral tests or unit tests

00:28:49,229 --> 00:28:54,389
you're capable of debugging those both

00:28:52,049 --> 00:28:56,579
on the kind of you can debug the test

00:28:54,389 --> 00:28:59,429
and you can also debug the API call it

00:28:56,579 --> 00:29:01,440
that test generates all the while and

00:28:59,429 --> 00:29:03,149
when you're developing those features

00:29:01,440 --> 00:29:05,999
you should be thinking about performance

00:29:03,149 --> 00:29:08,609
and every time you run those tests you

00:29:05,999 --> 00:29:11,429
can harvest the XH prof run IDs and then

00:29:08,609 --> 00:29:13,349
do comparisons like one run versus

00:29:11,429 --> 00:29:15,059
another run you can do that in

00:29:13,349 --> 00:29:17,279
development but you can also do that on

00:29:15,059 --> 00:29:19,859
kind of live like in a live like

00:29:17,279 --> 00:29:21,719
environment and it's worth mentioning

00:29:19,859 --> 00:29:24,239
that XH prof can be running production

00:29:21,719 --> 00:29:27,059
with certain settings disabled so i

00:29:24,239 --> 00:29:28,979
think that the cpu flag which tells you

00:29:27,059 --> 00:29:30,479
how long you spent at the cpu apparently

00:29:28,979 --> 00:29:34,440
that is expensive to an in production

00:29:30,479 --> 00:29:36,209
but if you omit that flag and it's okay

00:29:34,440 --> 00:29:39,209
to have X 8 prov running like one in

00:29:36,209 --> 00:29:41,279
every 1,000 requests and then gathering

00:29:39,209 --> 00:29:43,229
that data from your live servers and

00:29:41,279 --> 00:29:46,799
then using it to figure out if there any

00:29:43,229 --> 00:29:48,359
bottlenecks in production but before we

00:29:46,799 --> 00:29:51,329
get to production there should be

00:29:48,359 --> 00:29:53,190
another step which is simulating

00:29:51,329 --> 00:29:54,899
production like load on a known

00:29:53,190 --> 00:29:57,359
environment and applying all the

00:29:54,899 --> 00:29:59,279
techniques we've learned so far and in

00:29:57,359 --> 00:30:03,239
order to get some learning as to how the

00:29:59,279 --> 00:30:05,190
thing is going to perform in prod so to

00:30:03,239 --> 00:30:08,669
do that is the kind of next tool in the

00:30:05,190 --> 00:30:10,289
toolbox which is jmeter I jmeter gets a

00:30:08,669 --> 00:30:13,950
really bad rap and people say that it's

00:30:10,289 --> 00:30:15,839
a really complex but actually I think it

00:30:13,950 --> 00:30:17,009
I think it's very simple I'm so

00:30:15,839 --> 00:30:21,479
confident that I'm going to try and

00:30:17,009 --> 00:30:23,579
build a Jamie to test plan right now so

00:30:21,479 --> 00:30:25,919
the first thing we're going to do is add

00:30:23,579 --> 00:30:28,320
a thread group so you can think of a

00:30:25,919 --> 00:30:29,609
thread group as a way of controlling how

00:30:28,320 --> 00:30:31,440
many users are going to do the journey

00:30:29,609 --> 00:30:34,499
that were about to plan out how many

00:30:31,440 --> 00:30:36,809
times that journey is going to occur and

00:30:34,499 --> 00:30:38,909
also maybe you want to ramp up the

00:30:36,809 --> 00:30:41,459
number of users over time is it's no

00:30:38,909 --> 00:30:43,289
good saying I want a thousand users to

00:30:41,459 --> 00:30:44,729
all visit the site right away because

00:30:43,289 --> 00:30:45,090
that's not really how production traffic

00:30:44,729 --> 00:30:46,980
work

00:30:45,090 --> 00:30:49,050
or it might be that might be your

00:30:46,980 --> 00:30:50,580
business but for me normally there's a

00:30:49,050 --> 00:30:54,030
bit of a ramp up in which we might have

00:30:50,580 --> 00:30:57,270
50 users 100 200 and scaling your test

00:30:54,030 --> 00:31:02,310
like that and enables you to learn were

00:30:57,270 --> 00:31:06,350
where the break point is so in a thread

00:31:02,310 --> 00:31:08,640
group we can do some config and so the

00:31:06,350 --> 00:31:11,400
request defaults is something that you

00:31:08,640 --> 00:31:13,500
pretty much always put in I'm and in the

00:31:11,400 --> 00:31:20,330
request default you put the URL of this

00:31:13,500 --> 00:31:22,230
server that you're going to hit like so

00:31:20,330 --> 00:31:24,230
that's pretty much the only thing you

00:31:22,230 --> 00:31:28,440
need to put in and then you can add a

00:31:24,230 --> 00:31:30,360
sampler to the thread group a sampler in

00:31:28,440 --> 00:31:35,370
our case is just a means of making an

00:31:30,360 --> 00:31:38,390
HTTP request says open this out a little

00:31:35,370 --> 00:31:41,700
bit and to do that you need to specify

00:31:38,390 --> 00:31:44,970
the verb so get and post and then the

00:31:41,700 --> 00:31:48,090
path so we're looking for you you IDs

00:31:44,970 --> 00:31:49,620
and we're going to get them we don't

00:31:48,090 --> 00:31:51,720
have to fill any of this in because it's

00:31:49,620 --> 00:31:54,750
taken care of by this request default

00:31:51,720 --> 00:31:59,240
section I'm I will probably give it a

00:31:54,750 --> 00:32:03,210
name like get you you IDs like so and

00:31:59,240 --> 00:32:08,150
then let's put another one in which to

00:32:03,210 --> 00:32:11,400
do the post and so sampler HTTP requests

00:32:08,150 --> 00:32:17,910
/eu IDs but this time let's talk about

00:32:11,400 --> 00:32:21,390
the post and we'll call it post youyou

00:32:17,910 --> 00:32:22,620
IDs like so so the only thing wrong

00:32:21,390 --> 00:32:24,690
while the two things wrong with this

00:32:22,620 --> 00:32:26,280
test at the moment one is that there if

00:32:24,690 --> 00:32:27,810
we set the journey to loop it would just

00:32:26,280 --> 00:32:29,670
hammer the server without putting any

00:32:27,810 --> 00:32:31,050
kind of gap in there and what we're

00:32:29,670 --> 00:32:33,690
really trying to simulate is a user

00:32:31,050 --> 00:32:36,150
journey where we can then multiply that

00:32:33,690 --> 00:32:38,700
journey by 100 users so if you think

00:32:36,150 --> 00:32:41,070
about the journey of a shopping cart you

00:32:38,700 --> 00:32:43,320
might create a car browse to a product

00:32:41,070 --> 00:32:45,240
page look at that product page 43

00:32:43,320 --> 00:32:47,820
seconds and then add something to your

00:32:45,240 --> 00:32:50,310
basket or it may take it may take you

00:32:47,820 --> 00:32:53,180
kind of three product page lookups

00:32:50,310 --> 00:32:56,910
before you put something in your cart so

00:32:53,180 --> 00:32:58,119
let's put a timer in there it's constant

00:32:56,910 --> 00:33:00,939
timer and what

00:32:58,119 --> 00:33:09,909
300 milliseconds delay in forget you IDs

00:33:00,939 --> 00:33:11,739
and add another timer for the same like

00:33:09,909 --> 00:33:13,509
so so that's going to wait three hundred

00:33:11,739 --> 00:33:14,679
milliseconds for our case thats could be

00:33:13,509 --> 00:33:15,879
enough it's just going to throttle it a

00:33:14,679 --> 00:33:19,299
little bit so we're not just going to

00:33:15,879 --> 00:33:21,459
hammer that little test server I'm for

00:33:19,299 --> 00:33:22,809
your case you should you should do

00:33:21,459 --> 00:33:24,909
something to figure out what those

00:33:22,809 --> 00:33:26,739
timings are sometimes you can get them

00:33:24,909 --> 00:33:31,659
from access logs of an existing server

00:33:26,739 --> 00:33:34,179
and we've also had instances where we

00:33:31,659 --> 00:33:36,159
have a user who is sitting in front of

00:33:34,179 --> 00:33:37,839
the UI interacting with it at kind of

00:33:36,159 --> 00:33:39,969
their leisure and then figure out the

00:33:37,839 --> 00:33:42,429
timings for the request based on that

00:33:39,969 --> 00:33:45,149
kind of direct user input it's really

00:33:42,429 --> 00:33:47,679
important for this to be realistic and

00:33:45,149 --> 00:33:50,229
then we need a way of viewing all the

00:33:47,679 --> 00:33:53,099
results so there's loads of listeners

00:33:50,229 --> 00:33:56,349
which you can use the most useful our

00:33:53,099 --> 00:33:57,519
view results in a tree in a table which

00:33:56,349 --> 00:34:04,419
was just show you a table of all the

00:33:57,519 --> 00:34:06,279
requests I'm and then view results in a

00:34:04,419 --> 00:34:10,019
tree which will allow you to inspect an

00:34:06,279 --> 00:34:18,519
individual request if you want to and

00:34:10,019 --> 00:34:22,779
then the summary graph response time

00:34:18,519 --> 00:34:24,519
graph and because management love graphs

00:34:22,779 --> 00:34:27,579
so you're gonna have to show them

00:34:24,519 --> 00:34:33,970
something I'm and then let's just run

00:34:27,579 --> 00:34:40,749
this once as a test I won't save it okay

00:34:33,970 --> 00:34:44,739
so that didn't work uid okay let's have

00:34:40,749 --> 00:34:51,609
a look here posts pasted that into the

00:34:44,739 --> 00:34:55,839
wrong box okay let's try it again still

00:34:51,609 --> 00:34:56,950
did not work okay something's wrong

00:34:55,839 --> 00:34:59,520
there but luckily I've got something

00:34:56,950 --> 00:35:05,250
that I made earlier Blue Peter style

00:34:59,520 --> 00:35:16,180
okay let me fix that aah in there oh

00:35:05,250 --> 00:35:18,640
yeah good man okay so now we've got a

00:35:16,180 --> 00:35:20,890
test which is working so if we go to

00:35:18,640 --> 00:35:23,920
this get you you IDs we can see the

00:35:20,890 --> 00:35:25,570
result which importantly contains the X

00:35:23,920 --> 00:35:28,720
HBO for an ID because we're going to put

00:35:25,570 --> 00:35:30,370
those things together in a minute and if

00:35:28,720 --> 00:35:33,130
we go to the review results in the table

00:35:30,370 --> 00:35:35,380
we can see these failed ones and then we

00:35:33,130 --> 00:35:38,050
can also see the successful ones so

00:35:35,380 --> 00:35:40,360
let's ramp this up a little bit by going

00:35:38,050 --> 00:35:43,450
to the thread group and saying let's run

00:35:40,360 --> 00:35:44,590
it forever just with one user still but

00:35:43,450 --> 00:35:50,530
that should just generate some

00:35:44,590 --> 00:35:53,740
interesting traffic like so I'm so now

00:35:50,530 --> 00:35:58,180
if I go and kind of pick one of these at

00:35:53,740 --> 00:36:00,130
random and back to jmeter either results

00:35:58,180 --> 00:36:04,530
in a tree let's have a look at this one

00:36:00,130 --> 00:36:07,420
XA to proffer an ID go back to the UI

00:36:04,530 --> 00:36:10,240
refresh and then look for it and it's

00:36:07,420 --> 00:36:11,800
it's there so you can imagine if you

00:36:10,240 --> 00:36:14,440
were running a load test and you had a

00:36:11,800 --> 00:36:16,060
lot of these on a lot of different

00:36:14,440 --> 00:36:19,540
instances you could ship them somewhere

00:36:16,060 --> 00:36:23,740
to a common webroot maybe you dumped

00:36:19,540 --> 00:36:26,020
them all in s3 I'm and then a later date

00:36:23,740 --> 00:36:29,080
you just go through a non-anomalous kind

00:36:26,020 --> 00:36:31,530
of results from jmeter and pick out the

00:36:29,080 --> 00:36:36,700
interesting ones and then perform that

00:36:31,530 --> 00:36:38,290
analysis on them so let me just check my

00:36:36,700 --> 00:36:39,910
list and check that I've covered

00:36:38,290 --> 00:36:41,740
everything I wanted to say oh yeah

00:36:39,910 --> 00:36:44,680
there's a few other things that jmeter

00:36:41,740 --> 00:36:47,260
does and one is it to allow the to allow

00:36:44,680 --> 00:36:49,390
you to verify the success of a request

00:36:47,260 --> 00:36:50,860
based on its content that is a little

00:36:49,390 --> 00:36:53,680
bit more complicated i'm not going to

00:36:50,860 --> 00:36:55,690
display it today but a common technique

00:36:53,680 --> 00:36:57,370
there would be if you're doing this on

00:36:55,690 --> 00:36:59,230
your website rather than your API and

00:36:57,370 --> 00:37:00,940
look for the footer and the text which

00:36:59,230 --> 00:37:05,230
should be in the footer that will show

00:37:00,940 --> 00:37:08,260
all the that war show that the page at

00:37:05,230 --> 00:37:10,030
least rendered correctly and then the

00:37:08,260 --> 00:37:12,320
other thing that i should say is that

00:37:10,030 --> 00:37:15,650
jmeter is also producing

00:37:12,320 --> 00:37:18,590
some interesting metrics and I'll

00:37:15,650 --> 00:37:20,570
explain what they are and this one on

00:37:18,590 --> 00:37:24,260
the right is one of the more important

00:37:20,570 --> 00:37:28,070
ones which is latency so this is the

00:37:24,260 --> 00:37:32,060
time that it took to return the first

00:37:28,070 --> 00:37:35,510
bite of that request I'm whereas the

00:37:32,060 --> 00:37:37,460
other thing which is sample time is the

00:37:35,510 --> 00:37:40,790
amount that it took to receive the whole

00:37:37,460 --> 00:37:42,710
request so I was working at a company

00:37:40,790 --> 00:37:44,930
while ago and we were moving

00:37:42,710 --> 00:37:47,950
infrastructure from a dedicated

00:37:44,930 --> 00:37:50,720
environment to a cloud environment and

00:37:47,950 --> 00:37:52,160
moving from Apache to engine X so we're

00:37:50,720 --> 00:37:55,310
doing a lot of things new for the first

00:37:52,160 --> 00:37:57,110
time and this kind of latency number

00:37:55,310 --> 00:37:58,940
would be fine up until about 50 users

00:37:57,110 --> 00:38:02,510
and then all of a sudden latency would

00:37:58,940 --> 00:38:04,880
go through the roof and the read and

00:38:02,510 --> 00:38:06,410
that came up doing this type of testing

00:38:04,880 --> 00:38:08,300
and the reason was that we hadn't

00:38:06,410 --> 00:38:12,830
configured our engine X pools correctly

00:38:08,300 --> 00:38:14,540
and so the HTTP requests were stacking

00:38:12,830 --> 00:38:17,450
up and waiting for in genetics to deal

00:38:14,540 --> 00:38:20,000
with them and that is a classic example

00:38:17,450 --> 00:38:23,320
of the kind of thing that you find out

00:38:20,000 --> 00:38:27,710
when you're doing this kind of testing

00:38:23,320 --> 00:38:30,320
so oh I should also demonstrate the

00:38:27,710 --> 00:38:37,030
response time graph display the graph

00:38:30,320 --> 00:38:40,430
there so these are the two requests I'm

00:38:37,030 --> 00:38:42,380
over time these graphs can be pretty

00:38:40,430 --> 00:38:45,260
interesting when you've got non-trivial

00:38:42,380 --> 00:38:46,730
examples one of the graphs which is

00:38:45,260 --> 00:38:49,400
particularly interesting is if you've

00:38:46,730 --> 00:38:52,190
got a login area of your website and

00:38:49,400 --> 00:38:54,050
you're using bcrypt you'll notice like a

00:38:52,190 --> 00:38:55,760
increase in the amount of time that it

00:38:54,050 --> 00:38:57,410
takes to do that initial login call

00:38:55,760 --> 00:38:59,480
that's normal because you're decrypting

00:38:57,410 --> 00:39:01,430
something so that not that kind of

00:38:59,480 --> 00:39:07,340
request normally sits a lot higher than

00:39:01,430 --> 00:39:12,560
the rest of your requests I'm and this

00:39:07,340 --> 00:39:14,510
kind of test design phase is interesting

00:39:12,560 --> 00:39:18,230
and it can be informed by user testing

00:39:14,510 --> 00:39:20,780
but you can also hook in your your user

00:39:18,230 --> 00:39:22,850
test because presumably as a stakeholder

00:39:20,780 --> 00:39:25,130
you will have defined the journey so

00:39:22,850 --> 00:39:27,619
like given given I go to the homepage

00:39:25,130 --> 00:39:29,359
and I create a basket and I put product

00:39:27,619 --> 00:39:30,829
in the basket you've defined a bunch of

00:39:29,359 --> 00:39:33,950
steps that you want your customer to

00:39:30,829 --> 00:39:36,019
make so wouldn't it be great if we could

00:39:33,950 --> 00:39:37,730
feed that into jmeter and somehow it

00:39:36,019 --> 00:39:39,769
would make a test out of it and then we

00:39:37,730 --> 00:39:43,700
could just ramped up the amount of

00:39:39,769 --> 00:39:47,690
traffic on that journey luckily using

00:39:43,700 --> 00:39:52,210
HTTP proxies we can do exactly that so

00:39:47,690 --> 00:39:57,079
if i stop this test now create a new one

00:39:52,210 --> 00:39:59,779
nope and so this workbench area under

00:39:57,079 --> 00:40:02,329
here and you can just kind of put

00:39:59,779 --> 00:40:06,650
samplers and tests in just to just to

00:40:02,329 --> 00:40:09,440
test them one of those is the HTTP test

00:40:06,650 --> 00:40:12,319
script recorder I'm which is for all

00:40:09,440 --> 00:40:15,380
intensive purposes is just a proxy that

00:40:12,319 --> 00:40:20,049
you send traffic to and then on top of

00:40:15,380 --> 00:40:23,690
that you can put a recording controller

00:40:20,049 --> 00:40:30,410
so I go to this https test quick

00:40:23,690 --> 00:40:32,509
recorder I'm until tell it to start ask

00:40:30,410 --> 00:40:37,250
you to install an ssl certificate which

00:40:32,509 --> 00:40:40,250
you do and then go back to your tests so

00:40:37,250 --> 00:40:41,839
previously the proxy was located on 8888

00:40:40,250 --> 00:40:43,789
and that's the address and the port the

00:40:41,839 --> 00:40:46,430
charles is using now we've got a new

00:40:43,789 --> 00:40:49,279
proxy which jmeter is exposing and that

00:40:46,430 --> 00:40:53,750
is on 80 80 or another port of your

00:40:49,279 --> 00:40:58,309
choice run the tests which pass but they

00:40:53,750 --> 00:41:01,279
also if we expand this section I'm put

00:40:58,309 --> 00:41:04,339
the HTTP requests into this recording

00:41:01,279 --> 00:41:07,400
controller and now if I were to add a

00:41:04,339 --> 00:41:11,569
thread group I can then drag and drop

00:41:07,400 --> 00:41:15,640
these samplers into the thread group and

00:41:11,569 --> 00:41:15,640
if I were to run that test now once I

00:41:15,880 --> 00:41:23,750
I'd also have to add of course something

00:41:18,619 --> 00:41:26,589
to view listener few results in a tree

00:41:23,750 --> 00:41:26,589
play it

00:41:27,780 --> 00:41:32,430
and you can see that that's caught

00:41:30,900 --> 00:41:35,280
that's basically mimicked the user

00:41:32,430 --> 00:41:38,370
journey that was defined in that

00:41:35,280 --> 00:41:41,640
behavioral tests and then if you imagine

00:41:38,370 --> 00:41:43,410
that we wanted to test that we could put

00:41:41,640 --> 00:41:44,730
some appropriate timings in place and

00:41:43,410 --> 00:41:48,000
then we could multiply the number of

00:41:44,730 --> 00:41:52,580
threads by a million and do some kind of

00:41:48,000 --> 00:41:55,170
load testing with that so I think that

00:41:52,580 --> 00:41:57,810
demonstrates that all of these things

00:41:55,170 --> 00:41:59,730
connected from a development standpoint

00:41:57,810 --> 00:42:01,350
and all the way through to staging and

00:41:59,730 --> 00:42:03,780
production it's a really valuable

00:42:01,350 --> 00:42:07,770
process to do that and to be constantly

00:42:03,780 --> 00:42:10,500
aware of not just the story requirements

00:42:07,770 --> 00:42:12,900
but also the non-functional requirements

00:42:10,500 --> 00:42:16,500
as well it's really what that tool chain

00:42:12,900 --> 00:42:18,150
is all about I'm one last thing to say

00:42:16,500 --> 00:42:19,710
is that you can do jmeter as a service

00:42:18,150 --> 00:42:21,600
so if you don't want to generate the

00:42:19,710 --> 00:42:23,670
load yourself you can farm that out to

00:42:21,600 --> 00:42:25,950
another company and they will provide

00:42:23,670 --> 00:42:30,360
the load for you based on your test

00:42:25,950 --> 00:42:34,470
plans so I think that's all the demoing

00:42:30,360 --> 00:42:35,730
that I've got to do today I am so I

00:42:34,470 --> 00:42:44,880
guess are there any questions in the

00:42:35,730 --> 00:42:48,090
room about any of this stuff like you me

00:42:44,880 --> 00:42:50,970
and can use run through the be her again

00:42:48,090 --> 00:42:53,070
so you typed I mean I saw you tired yeah

00:42:50,970 --> 00:42:56,340
sure how that related to actual test

00:42:53,070 --> 00:42:57,630
yeah so if I missed all know I met them

00:42:56,340 --> 00:42:58,920
may have done a little bit of kind of a

00:42:57,630 --> 00:43:00,780
smoke and mirrors gamer I didn't show

00:42:58,920 --> 00:43:02,040
you exactly how that worked but we've

00:43:00,780 --> 00:43:06,960
got a little bit of time so let's dig

00:43:02,040 --> 00:43:09,770
into that um so in the the client that I

00:43:06,960 --> 00:43:11,910
mentioned this HTTP client which is

00:43:09,770 --> 00:43:14,300
performing requests against the API

00:43:11,910 --> 00:43:18,240
that's called guzzle which is a fairly

00:43:14,300 --> 00:43:19,710
popular client google has made a service

00:43:18,240 --> 00:43:21,960
description or I made a service

00:43:19,710 --> 00:43:25,410
description here which basically lets

00:43:21,960 --> 00:43:29,880
you map methods to end points of your

00:43:25,410 --> 00:43:31,680
rest api and call them now without any

00:43:29,880 --> 00:43:35,880
kind of interference it would just make

00:43:31,680 --> 00:43:38,990
a direct kind of web request over HTTP

00:43:35,880 --> 00:43:41,160
but because goes will respects this

00:43:38,990 --> 00:43:45,420
environment variable which I'm passing

00:43:41,160 --> 00:43:47,220
into the PHP script it will tell guzzle

00:43:45,420 --> 00:43:49,829
to use a proxy rather than going

00:43:47,220 --> 00:43:53,329
directly to the source and it's at that

00:43:49,829 --> 00:43:56,069
point you hook in and then you can also

00:43:53,329 --> 00:43:58,260
i'm demonstrating this for api's but you

00:43:56,069 --> 00:44:01,140
can also do this for mink which is the

00:43:58,260 --> 00:44:02,880
UI testing bit of behalf so if you're

00:44:01,140 --> 00:44:06,180
using mink to drive a lot of

00:44:02,880 --> 00:44:08,460
interactions you can also use a proxy

00:44:06,180 --> 00:44:13,710
capture those interactions and do your

00:44:08,460 --> 00:44:22,440
UI test journeys as well this gentleman

00:44:13,710 --> 00:44:25,010
here hi I'm curious that you seem to be

00:44:22,440 --> 00:44:28,650
combining load testing with profiling

00:44:25,010 --> 00:44:31,170
yes profiling will normally slow down

00:44:28,650 --> 00:44:33,980
your application significantly so you're

00:44:31,170 --> 00:44:37,710
not really load testing are you well I'm

00:44:33,980 --> 00:44:39,960
that's a good question so I'm apparently

00:44:37,710 --> 00:44:43,109
I'm you can relax a tip-off in

00:44:39,960 --> 00:44:46,079
production I'm providing that you don't

00:44:43,109 --> 00:44:48,329
run the CPU flags it's supposed to be a

00:44:46,079 --> 00:44:50,549
very light kind of church where is

00:44:48,329 --> 00:44:54,960
something like k cash grind adds a

00:44:50,549 --> 00:44:57,809
significant overhead to to your requests

00:44:54,960 --> 00:45:00,150
I'm your next question is probably have

00:44:57,809 --> 00:45:02,940
you measured that overhead or similar

00:45:00,150 --> 00:45:05,579
and I'm afraid I haven't this is just an

00:45:02,940 --> 00:45:08,309
approach that I use probably without

00:45:05,579 --> 00:45:12,359
thinking I enough but it the other thing

00:45:08,309 --> 00:45:14,099
that you can do actually is to do say

00:45:12,359 --> 00:45:17,579
one in a thousand requests so say you're

00:45:14,099 --> 00:45:21,180
doing a thousand users you can use the J

00:45:17,579 --> 00:45:23,010
meter data which will be mostly unpro

00:45:21,180 --> 00:45:26,599
filed to get the kind of broad themes

00:45:23,010 --> 00:45:30,329
and then you could use the XH prof ID to

00:45:26,599 --> 00:45:32,190
extract a profiling run at while the

00:45:30,329 --> 00:45:34,140
system is under load and it's that I'm

00:45:32,190 --> 00:45:35,819
trying to capture really it's what

00:45:34,140 --> 00:45:39,720
happens when you're using a prod data

00:45:35,819 --> 00:45:41,309
set and at prod amount of users but but

00:45:39,720 --> 00:45:45,450
if you actually did want a load test

00:45:41,309 --> 00:45:47,760
yeah you wouldn't do that yes I guess no

00:45:45,450 --> 00:45:50,819
I'm that this is I guess this is

00:45:47,760 --> 00:45:53,130
something that I'm doing pre prod in

00:45:50,819 --> 00:45:54,210
order to get insight and yeah I think I

00:45:53,130 --> 00:45:55,980
would probably turn XH

00:45:54,210 --> 00:45:58,800
off off if we were doing the kind of

00:45:55,980 --> 00:46:02,609
final load test before prod that's a

00:45:58,800 --> 00:46:08,970
good point thank you gentleman at the

00:46:02,609 --> 00:46:10,740
back hi are there any other load testing

00:46:08,970 --> 00:46:14,730
applications or services that you

00:46:10,740 --> 00:46:16,410
recommend so I've heard talk of like

00:46:14,730 --> 00:46:19,050
Apache bench which is the classic one

00:46:16,410 --> 00:46:21,930
which lets you throw loss of traffic at

00:46:19,050 --> 00:46:23,640
something I'm really jmeter was just the

00:46:21,930 --> 00:46:27,810
first tool that I picked up and was able

00:46:23,640 --> 00:46:30,150
to get working correctly and also the

00:46:27,810 --> 00:46:31,710
kind of jmeter as a service stuff

00:46:30,150 --> 00:46:33,990
provided by blaze meter and the other

00:46:31,710 --> 00:46:37,230
companies really works for me so I don't

00:46:33,990 --> 00:46:38,940
want to figure out how to create a load

00:46:37,230 --> 00:46:40,680
testing infrastructure I just want to

00:46:38,940 --> 00:46:43,349
design it and pass it off to somebody

00:46:40,680 --> 00:46:45,119
that can generate the load for me but

00:46:43,349 --> 00:46:50,310
yeah there are there are others apache

00:46:45,119 --> 00:46:52,770
bench is one thank you are there any

00:46:50,310 --> 00:47:00,119
questions in the other room no any

00:46:52,770 --> 00:47:01,980
questions here is it possible to oppose

00:47:00,119 --> 00:47:04,349
a result in chi meter I mean consider

00:47:01,980 --> 00:47:06,420
the first request will be login that

00:47:04,349 --> 00:47:08,630
generates a random token and that's

00:47:06,420 --> 00:47:11,520
request is a logo that uses that token

00:47:08,630 --> 00:47:13,609
yes that is as possible and I've really

00:47:11,520 --> 00:47:16,859
only showed like the bare minimum of

00:47:13,609 --> 00:47:19,170
functionality jmeter offers today you

00:47:16,859 --> 00:47:21,060
can do journeys in which for example you

00:47:19,170 --> 00:47:23,040
harvest the session token from a log on

00:47:21,060 --> 00:47:26,369
request and then you use that session

00:47:23,040 --> 00:47:29,220
token to make subsequent requests and

00:47:26,369 --> 00:47:31,410
you can also do that so say you have a

00:47:29,220 --> 00:47:32,940
thousand threads you can have them do

00:47:31,410 --> 00:47:36,060
that journey and there will be a

00:47:32,940 --> 00:47:37,410
thousand unique tokens created so you're

00:47:36,060 --> 00:47:40,470
not kind of trampling on the same

00:47:37,410 --> 00:47:42,359
session which might have different

00:47:40,470 --> 00:47:43,650
performance characteristics and if you

00:47:42,359 --> 00:47:49,250
had a thousand separate users on the

00:47:43,650 --> 00:47:52,230
site so yeah really haven't demonstrated

00:47:49,250 --> 00:47:55,680
the breadth of jmeter you can do kind of

00:47:52,230 --> 00:47:58,349
if this responds like this then do that

00:47:55,680 --> 00:48:03,330
you can do loops it's a really diverse

00:47:58,349 --> 00:48:06,330
tool and actually I link on the readme

00:48:03,330 --> 00:48:08,069
notes to this talk and this kind of

00:48:06,330 --> 00:48:10,170
introduction to jamie to video

00:48:08,069 --> 00:48:12,779
which is done by blaze meter and there's

00:48:10,170 --> 00:48:14,819
kind of five videos which show you the

00:48:12,779 --> 00:48:18,479
most basic example which is probably the

00:48:14,819 --> 00:48:20,190
one I've done today versus like a actual

00:48:18,479 --> 00:48:24,599
customer journey across a site and how

00:48:20,190 --> 00:48:28,969
to capture all the things involved any

00:48:24,599 --> 00:48:31,410
more questions I have one if you want

00:48:28,969 --> 00:48:33,599
you have wonderfully if you've mentioned

00:48:31,410 --> 00:48:36,779
a couple of alternatives to the various

00:48:33,599 --> 00:48:38,430
components except for the proxies yeah I

00:48:36,779 --> 00:48:40,289
have a few mind myself but do you have

00:48:38,430 --> 00:48:43,079
any opinions on the alternates and so

00:48:40,289 --> 00:48:46,559
I've used fiddler before I'm also worth

00:48:43,079 --> 00:48:49,229
noting it's not a proxy but Wireshark if

00:48:46,559 --> 00:48:51,420
is really good if you need more

00:48:49,229 --> 00:48:54,599
information lower down than the kind of

00:48:51,420 --> 00:48:56,459
HTTP layer you can you can apply the

00:48:54,599 --> 00:48:59,670
same kind of approaches that you do with

00:48:56,459 --> 00:49:03,299
Charles send traffic to it do deeper

00:48:59,670 --> 00:49:05,099
analysis you have some yeah sure you got

00:49:03,299 --> 00:49:08,009
web scarab which is a java web app on

00:49:05,099 --> 00:49:09,449
and you've also gasps mid-end proxy

00:49:08,009 --> 00:49:12,900
which is great because you can scale the

00:49:09,449 --> 00:49:16,130
text for presentations you've been

00:49:12,900 --> 00:49:16,130
waiting a long time to say that how many

00:49:17,119 --> 00:49:20,969
there's a couple other cell so the thing

00:49:19,559 --> 00:49:23,430
is Charles is also paid so the other

00:49:20,969 --> 00:49:25,920
ones movie serves straight vantage yep

00:49:23,430 --> 00:49:27,569
that is true I've got a lucky enough to

00:49:25,920 --> 00:49:28,979
have access to a site license so I

00:49:27,569 --> 00:49:30,209
haven't had to pay myself but yeah

00:49:28,979 --> 00:49:33,900
that's worth noting you do have to pay

00:49:30,209 --> 00:49:38,309
fifty dollars if you want to use it any

00:49:33,900 --> 00:49:41,599
any more questions okay thank you very

00:49:38,309 --> 00:49:41,599

YouTube URL: https://www.youtube.com/watch?v=_JIFvGYsyxo


