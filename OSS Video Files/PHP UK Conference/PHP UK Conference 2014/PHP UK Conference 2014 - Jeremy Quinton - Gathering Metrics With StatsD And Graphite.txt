Title: PHP UK Conference 2014 - Jeremy Quinton - Gathering Metrics With StatsD And Graphite
Publication date: 2014-03-21
Playlist: PHP UK Conference 2014
Description: 
	Application metrics are extremely important but are often hard to gather as our PHP Applications differ significantly. Using StatsD and Graphite we can gather metrics from our applications no matter what their shape or form. In this talk I will discuss how you can use Statsd to send various metrics of your PHP applications to Graphite. StatsD is a simple NodeJS daemon for easy stats aggregation and makes it simple to plot application metrics on a graph in Graphite. Using the metrics that are gathered its possible to get an overview of what is happening with our applications in near realtime which is extremely useful. Graphite additionally allows us to produce easy understandable graphs and dashboards which once analysed can be used to improve our PHP applications. My talk will cover everything from setting up Statsd and Graphite to how you gather the metrics from within your PHP applications. After the talk developers should be confident enough to go away and implement these technologies in their applications.
Captions: 
	00:00:04,130 --> 00:00:09,269
my name's Jeremy Quinton I'm originally

00:00:06,600 --> 00:00:12,889
from South Africa I've been living in

00:00:09,269 --> 00:00:15,420
the UK for about the last seven years

00:00:12,889 --> 00:00:17,940
and I thought of a story on the this

00:00:15,420 --> 00:00:20,210
morning on the way yeah I got in the

00:00:17,940 --> 00:00:22,680
Northern Line and I took the wrong

00:00:20,210 --> 00:00:24,060
branch of the of the Northern Line and I

00:00:22,680 --> 00:00:25,619
ended up in Charing Cross and I should

00:00:24,060 --> 00:00:27,300
have been on the other branch which is

00:00:25,619 --> 00:00:31,109
quite funny because my first PHP

00:00:27,300 --> 00:00:34,649
conference eight years ago and I got on

00:00:31,109 --> 00:00:36,000
a bus and I ended up in a village and so

00:00:34,649 --> 00:00:38,760
I missed the first two talks of that

00:00:36,000 --> 00:00:40,440
conference so I've been yeah and you

00:00:38,760 --> 00:00:44,760
know seven years and I slow kanji is the

00:00:40,440 --> 00:00:46,440
public transport and so just a bit about

00:00:44,760 --> 00:00:50,550
me I've been working with PHP since

00:00:46,440 --> 00:00:51,539
about 2003 a lot of PHP applications and

00:00:50,550 --> 00:00:53,430
what so really interested in

00:00:51,539 --> 00:00:57,539
infrastructure and application

00:00:53,430 --> 00:01:01,079
architectures i mentioned that i came to

00:00:57,539 --> 00:01:02,399
the PHP conference in 2007 what's really

00:01:01,079 --> 00:01:06,330
awesome is the first conference that i

00:01:02,399 --> 00:01:09,390
came to had about 50 to 100 people was

00:01:06,330 --> 00:01:11,430
in a university we had one sort of

00:01:09,390 --> 00:01:15,090
lecture room had one track with five

00:01:11,430 --> 00:01:16,950
talks today we've got three tracks the

00:01:15,090 --> 00:01:18,810
conference is over two days and that

00:01:16,950 --> 00:01:20,520
about 600 attendees so to see that

00:01:18,810 --> 00:01:22,320
growth in these PHP conferences is

00:01:20,520 --> 00:01:25,619
pretty awesome I think it's you know it

00:01:22,320 --> 00:01:27,960
says a lot about PHP as a language I'm

00:01:25,619 --> 00:01:29,610
an open source enthusiast everything I'm

00:01:27,960 --> 00:01:31,770
talking about today is open source but

00:01:29,610 --> 00:01:34,530
all the projects and most the work I do

00:01:31,770 --> 00:01:36,240
involves open source software and I'm

00:01:34,530 --> 00:01:41,430
also a really big fan of the DevOps

00:01:36,240 --> 00:01:43,380
culture and professional movement and so

00:01:41,430 --> 00:01:44,399
that brings me to my next slide how many

00:01:43,380 --> 00:01:48,030
guys in the audience have heard of

00:01:44,399 --> 00:01:50,189
DevOps right pretty pretty much everyone

00:01:48,030 --> 00:01:53,520
right DevOps is a lot of different

00:01:50,189 --> 00:01:55,170
things to you know different people the

00:01:53,520 --> 00:01:58,350
DevOps is actually broken up into sort

00:01:55,170 --> 00:02:00,020
of four tiers so its culture it's about

00:01:58,350 --> 00:02:02,460
the culture of your organization

00:02:00,020 --> 00:02:03,390
automation so you know automating your

00:02:02,460 --> 00:02:05,460
infrastructure with things like

00:02:03,390 --> 00:02:08,520
configuration management tools in the

00:02:05,460 --> 00:02:09,569
cloud it's about measurement and the

00:02:08,520 --> 00:02:11,340
measurement we also have things like

00:02:09,569 --> 00:02:15,450
monitoring tools

00:02:11,340 --> 00:02:16,920
and sharing I can't talk about you know

00:02:15,450 --> 00:02:18,690
any of these today maybe over beer we

00:02:16,920 --> 00:02:19,950
can discuss DevOps if you want but I

00:02:18,690 --> 00:02:23,099
wanted to tell you a story about

00:02:19,950 --> 00:02:25,980
measurements how came to realize that

00:02:23,099 --> 00:02:29,849
measurement is important why you should

00:02:25,980 --> 00:02:31,080
measure gather application matrix and to

00:02:29,849 --> 00:02:32,760
tell you that story i'll tell you about

00:02:31,080 --> 00:02:35,459
about a web application i was working on

00:02:32,760 --> 00:02:37,319
this time last year so it was pretty

00:02:35,459 --> 00:02:40,319
much in the firing line i was working on

00:02:37,319 --> 00:02:41,640
a PHP application but the PHP

00:02:40,319 --> 00:02:43,500
application was really different because

00:02:41,640 --> 00:02:47,250
it only had to scale for three months of

00:02:43,500 --> 00:02:49,110
the year so we had this sort of lead

00:02:47,250 --> 00:02:53,040
time where we would you know build this

00:02:49,110 --> 00:02:55,650
app in a series of sprints and then at

00:02:53,040 --> 00:02:57,000
some point we go live to production so

00:02:55,650 --> 00:02:58,470
that period was probably about six or

00:02:57,000 --> 00:03:01,290
seven months with bull bull bull bull

00:02:58,470 --> 00:03:03,120
and then we push the appt to production

00:03:01,290 --> 00:03:04,739
and then we had a short period where we

00:03:03,120 --> 00:03:06,030
could do some load testing now as

00:03:04,739 --> 00:03:08,220
developers we really good at breaking

00:03:06,030 --> 00:03:10,349
things so this was our opportunity to

00:03:08,220 --> 00:03:11,760
stick some load on the app and you know

00:03:10,349 --> 00:03:13,410
get the wheels to come off and really

00:03:11,760 --> 00:03:14,849
break it and we're really good at that

00:03:13,410 --> 00:03:16,440
you know during the load testing no

00:03:14,849 --> 00:03:18,510
problem we could break that and then we

00:03:16,440 --> 00:03:21,480
have the spike and this is the scary

00:03:18,510 --> 00:03:22,650
bird right actually lost like a lot of

00:03:21,480 --> 00:03:24,780
sleep in these three months but we never

00:03:22,650 --> 00:03:26,790
actually knew you know how much traffic

00:03:24,780 --> 00:03:28,109
we're going to get so just to give a bit

00:03:26,790 --> 00:03:29,370
of history around this application at

00:03:28,109 --> 00:03:33,239
the time I was working for comic relief

00:03:29,370 --> 00:03:36,150
so comic relief or a big UK charity one

00:03:33,239 --> 00:03:37,500
year they have an event which is sport

00:03:36,150 --> 00:03:39,919
relief and then the next year they have

00:03:37,500 --> 00:03:42,269
red nose day so we could have a

00:03:39,919 --> 00:03:44,849
celebrity with you know two million

00:03:42,269 --> 00:03:47,519
followers pop out a tweet and you know

00:03:44,849 --> 00:03:51,569
bring things done but I didn't realize

00:03:47,519 --> 00:03:53,549
it at the time but we had no application

00:03:51,569 --> 00:03:55,500
metrics sorry also in this period we had

00:03:53,549 --> 00:03:58,319
you know multiple deployments with

00:03:55,500 --> 00:03:59,400
frequent changes so the thing is our

00:03:58,319 --> 00:04:01,109
requirements were changing all the time

00:03:59,400 --> 00:04:03,540
so we didn't know the knock-on effect of

00:04:01,109 --> 00:04:04,889
those changes but we had no application

00:04:03,540 --> 00:04:08,519
metrics and I didn't realize it at the

00:04:04,889 --> 00:04:10,709
time and I was at PHP UK last year and

00:04:08,519 --> 00:04:12,269
Joe did a really good talk where he

00:04:10,709 --> 00:04:14,310
spoke about you can't optimize what you

00:04:12,269 --> 00:04:16,320
can't measure and at the time it really

00:04:14,310 --> 00:04:17,549
hit a chord with me because what he

00:04:16,320 --> 00:04:20,459
spoke about that day and what I'm

00:04:17,549 --> 00:04:23,250
speaking about today and you know is

00:04:20,459 --> 00:04:25,200
what I actually needed and the subject

00:04:23,250 --> 00:04:26,700
of what Joe spoke about last time

00:04:25,200 --> 00:04:30,030
what I spoke about was the subject of

00:04:26,700 --> 00:04:32,220
these two blog posts so the first blog

00:04:30,030 --> 00:04:34,020
post is about Flickr from Flickr they

00:04:32,220 --> 00:04:36,090
talked about to application metric tax

00:04:34,020 --> 00:04:38,610
which is counting and timing and the

00:04:36,090 --> 00:04:39,720
second blog posts by etsy they talk

00:04:38,610 --> 00:04:42,300
about measure anything measure

00:04:39,720 --> 00:04:47,610
everything and they're really honing on

00:04:42,300 --> 00:04:48,900
why measurement is important it seats go

00:04:47,610 --> 00:04:51,750
on to talk about measuring at three

00:04:48,900 --> 00:04:53,190
different levels the first level is the

00:04:51,750 --> 00:04:54,990
network level and the second level is

00:04:53,190 --> 00:04:56,910
the machine level and we had both these

00:04:54,990 --> 00:04:58,710
measurements in place this time last

00:04:56,910 --> 00:05:00,750
year so we could see how much traffic

00:04:58,710 --> 00:05:02,250
was coming in you know right down them

00:05:00,750 --> 00:05:04,920
to the network level at the Machine

00:05:02,250 --> 00:05:06,450
level we could see how much CPU are you

00:05:04,920 --> 00:05:08,610
know web tier was consuming how much

00:05:06,450 --> 00:05:10,950
memory and stuff but we didn't have

00:05:08,610 --> 00:05:13,140
application metrics and I didn't realize

00:05:10,950 --> 00:05:15,540
at the time but application matrix are

00:05:13,140 --> 00:05:17,220
actually the third type of metric but

00:05:15,540 --> 00:05:18,750
they really hold together and the reason

00:05:17,220 --> 00:05:20,640
they're really hard together is because

00:05:18,750 --> 00:05:23,400
application metrics are specific to your

00:05:20,640 --> 00:05:25,410
business and your business requirements

00:05:23,400 --> 00:05:28,260
and as your business requirements change

00:05:25,410 --> 00:05:33,000
so you need to gather you know different

00:05:28,260 --> 00:05:34,620
application matrix so why is measurement

00:05:33,000 --> 00:05:38,490
important it might seem really obvious

00:05:34,620 --> 00:05:40,350
but it helps us to understand things and

00:05:38,490 --> 00:05:41,790
once we can and things in the census our

00:05:40,350 --> 00:05:44,910
web applications but once we better

00:05:41,790 --> 00:05:47,790
understand things we can go about

00:05:44,910 --> 00:05:49,380
improving them and I think improving

00:05:47,790 --> 00:05:51,150
things is a big part of what we do as

00:05:49,380 --> 00:05:52,620
developers you know how many times have

00:05:51,150 --> 00:05:54,810
you written code like six months ago and

00:05:52,620 --> 00:05:56,640
say was that was that I write that code

00:05:54,810 --> 00:05:58,260
was that me and you check sort of you

00:05:56,640 --> 00:06:00,840
know the commit history and you know it

00:05:58,260 --> 00:06:02,250
was you but you know we want to go about

00:06:00,840 --> 00:06:05,070
improving things so to be able to

00:06:02,250 --> 00:06:08,400
improve things we need to and you know

00:06:05,070 --> 00:06:09,990
first understand them so a really good

00:06:08,400 --> 00:06:11,250
quote about measurement and this is

00:06:09,990 --> 00:06:12,570
pretty much where I was last year but

00:06:11,250 --> 00:06:14,640
measurement is the first step that leads

00:06:12,570 --> 00:06:16,230
to control and eventually to improvement

00:06:14,640 --> 00:06:17,220
if you can't measure something you can't

00:06:16,230 --> 00:06:19,290
understand it and if you can't

00:06:17,220 --> 00:06:20,910
understand it you can't control it if

00:06:19,290 --> 00:06:28,170
you can't control it you can't improve

00:06:20,910 --> 00:06:30,000
it so to get some measurement of our web

00:06:28,170 --> 00:06:33,690
applications in this case our PHP web

00:06:30,000 --> 00:06:35,850
applications we need some metrics so a

00:06:33,690 --> 00:06:37,150
metric a definition I took from the

00:06:35,850 --> 00:06:39,070
dictionary you simply assist

00:06:37,150 --> 00:06:41,400
or a standard of measurement all right

00:06:39,070 --> 00:06:45,400
so we need to put a system in place to

00:06:41,400 --> 00:06:48,370
gather some metrics so the system I'm

00:06:45,400 --> 00:06:53,500
talking about today is something that

00:06:48,370 --> 00:06:55,150
was put together by STATS d Joe

00:06:53,500 --> 00:06:56,500
mentioned in his keynote but about

00:06:55,150 --> 00:06:58,030
taking different technologies and

00:06:56,500 --> 00:06:59,560
putting them together and when you put

00:06:58,030 --> 00:07:01,900
these technologies together you can do

00:06:59,560 --> 00:07:04,450
some really cool stuff so at a very

00:07:01,900 --> 00:07:06,280
higher level this is a system overview

00:07:04,450 --> 00:07:07,870
what I'm going to do is I will going to

00:07:06,280 --> 00:07:10,090
detail on each of these but we have our

00:07:07,870 --> 00:07:12,460
application so our application in this

00:07:10,090 --> 00:07:15,430
sense can be a PHP application but it's

00:07:12,460 --> 00:07:17,770
anything that can send a UDP packet to

00:07:15,430 --> 00:07:20,620
STATS d stats these sitting there stats

00:07:17,770 --> 00:07:22,510
teaser nodejs a demon it's event-driven

00:07:20,620 --> 00:07:25,240
it's got fast input and outputs and

00:07:22,510 --> 00:07:26,740
that's sending the metrics to to

00:07:25,240 --> 00:07:28,630
graphite right so Graphite's got three

00:07:26,740 --> 00:07:30,280
ports it's got carbon it's got a web app

00:07:28,630 --> 00:07:31,930
and it's got whisper and I'll talk about

00:07:30,280 --> 00:07:34,870
each of these in a bit more deeper

00:07:31,930 --> 00:07:36,130
detail so what I want to do is I want to

00:07:34,870 --> 00:07:38,050
take you through the system and how to

00:07:36,130 --> 00:07:41,110
gather application matrix using the

00:07:38,050 --> 00:07:45,850
system so we've got different types of

00:07:41,110 --> 00:07:48,100
application matrix the first type of

00:07:45,850 --> 00:07:50,410
application metric you have is counting

00:07:48,100 --> 00:07:56,220
and counting is really useful just to

00:07:50,410 --> 00:07:58,630
Canton event in our web application so

00:07:56,220 --> 00:08:00,670
counting answers you know simple things

00:07:58,630 --> 00:08:02,380
like how many emails did we send over

00:08:00,670 --> 00:08:04,870
the last 10 minutes within our web

00:08:02,380 --> 00:08:07,810
application how many users logging into

00:08:04,870 --> 00:08:08,860
the system in the last five minutes how

00:08:07,810 --> 00:08:10,960
many calls have been made to a

00:08:08,860 --> 00:08:13,060
particular API so it's really just

00:08:10,960 --> 00:08:15,070
counting events knowing how many things

00:08:13,060 --> 00:08:16,300
are happening simultaneously so when I

00:08:15,070 --> 00:08:18,460
showed you the example earlier when we

00:08:16,300 --> 00:08:19,570
were doing load testing we you know we'd

00:08:18,460 --> 00:08:21,070
know that would bottle out the

00:08:19,570 --> 00:08:23,770
application when we got loads of you

00:08:21,070 --> 00:08:25,960
know 500 errors we saturated the network

00:08:23,770 --> 00:08:27,130
so the thing is if we had the metric at

00:08:25,960 --> 00:08:28,630
that point in time we would know that

00:08:27,130 --> 00:08:31,090
you know we're sending extra money

00:08:28,630 --> 00:08:32,830
emails you know how many users logging

00:08:31,090 --> 00:08:34,270
in you know that kind of thing and we

00:08:32,830 --> 00:08:35,380
would know at what point that we're

00:08:34,270 --> 00:08:38,590
broke it and then when we got the

00:08:35,380 --> 00:08:40,750
three-month traffic spike we could then

00:08:38,590 --> 00:08:43,480
know that when our application was

00:08:40,750 --> 00:08:45,030
getting to breaking points so how do we

00:08:43,480 --> 00:08:47,830
go about gathering accounting metric

00:08:45,030 --> 00:08:50,480
using the system so first off you need a

00:08:47,830 --> 00:08:54,139
stats the PHP client library

00:08:50,480 --> 00:08:57,740
I've just a no basic search on unpack

00:08:54,139 --> 00:09:01,190
adjust my examples today are using the

00:08:57,740 --> 00:09:03,199
first library there there's quite a few

00:09:01,190 --> 00:09:05,899
other libraries but actually you'll see

00:09:03,199 --> 00:09:07,160
that what the PHP client library does is

00:09:05,899 --> 00:09:08,750
very simple so if you really were

00:09:07,160 --> 00:09:11,510
ambitious if you wanted to you could you

00:09:08,750 --> 00:09:14,510
could write your own stats d client

00:09:11,510 --> 00:09:16,430
library and so an example cantering

00:09:14,510 --> 00:09:19,250
metric in PHP code looks something like

00:09:16,430 --> 00:09:22,279
this so basically I'm creating a

00:09:19,250 --> 00:09:26,540
connection here a UDP connection to

00:09:22,279 --> 00:09:28,490
stats D and then I'm instantiating an

00:09:26,540 --> 00:09:30,680
object as a stats the client object i'm

00:09:28,490 --> 00:09:34,399
dropping that connection in and away we

00:09:30,680 --> 00:09:36,500
go so to do simple counts of any event

00:09:34,399 --> 00:09:38,870
in our application it's just simply

00:09:36,500 --> 00:09:42,260
stats the increment and the metric name

00:09:38,870 --> 00:09:43,670
and this metric name will appear as a

00:09:42,260 --> 00:09:48,579
bucket in graphite and i'll show you

00:09:43,670 --> 00:09:51,079
that a bit later over the wire from the

00:09:48,579 --> 00:09:52,970
PHP client library to stats d it's

00:09:51,079 --> 00:09:55,610
actually really simple it's just a

00:09:52,970 --> 00:09:59,089
little packet that has this as the name

00:09:55,610 --> 00:10:01,490
this over here is is one which is the

00:09:59,089 --> 00:10:04,040
value for that metric and the C means

00:10:01,490 --> 00:10:06,680
that it's a counter metric so if you

00:10:04,040 --> 00:10:08,420
were sorry i forgot the spread so we've

00:10:06,680 --> 00:10:12,139
got we got the metric name the current

00:10:08,420 --> 00:10:15,279
value and the metric type so if you

00:10:12,139 --> 00:10:17,630
wanted to if you've got stats d set up

00:10:15,279 --> 00:10:19,910
on the bash on the command line you

00:10:17,630 --> 00:10:21,800
could just echo packet to net card and

00:10:19,910 --> 00:10:23,899
send that to stats d if you're just

00:10:21,800 --> 00:10:26,029
playing around and testing so all the

00:10:23,899 --> 00:10:27,589
PHP client library is doing is making a

00:10:26,029 --> 00:10:28,430
UDP connection and sending a packet that

00:10:27,589 --> 00:10:32,810
looks like that so it's really

00:10:28,430 --> 00:10:34,459
straightforward ok but that packet gets

00:10:32,810 --> 00:10:37,339
sent to status t so just a bit about

00:10:34,459 --> 00:10:38,810
stats d so stats t is built by HC i'm

00:10:37,339 --> 00:10:40,670
not sure if it one's a familiar with a

00:10:38,810 --> 00:10:43,399
cheap at Etsy or a vintage online

00:10:40,670 --> 00:10:48,829
marketplace in America where you can buy

00:10:43,399 --> 00:10:51,529
all sorts of crazy stuff and steady as a

00:10:48,829 --> 00:10:53,389
brief briefly mention is a network demon

00:10:51,529 --> 00:10:56,149
that get your gathers and flashes and

00:10:53,389 --> 00:10:57,649
metrics to a back end it's important to

00:10:56,149 --> 00:10:59,689
also understand that stat see does do

00:10:57,649 --> 00:11:02,329
some aggregation on the matrix for us

00:10:59,689 --> 00:11:03,949
and I'll show an example of that but

00:11:02,329 --> 00:11:04,430
later on the other thing that's really

00:11:03,949 --> 00:11:05,899
important

00:11:04,430 --> 00:11:07,190
stand about stats d and this is

00:11:05,899 --> 00:11:09,230
configurable is that it has a flash

00:11:07,190 --> 00:11:10,880
interval so you've got this nodejs demon

00:11:09,230 --> 00:11:12,529
it's aggregating the metrics and then it

00:11:10,880 --> 00:11:15,710
flashes them out to our back-end at a

00:11:12,529 --> 00:11:17,240
ten second in the fall and this is

00:11:15,710 --> 00:11:18,680
probably the most important thing and

00:11:17,240 --> 00:11:22,070
the most frequent thing that people will

00:11:18,680 --> 00:11:24,950
ask but stats d uses your the UDP

00:11:22,070 --> 00:11:27,560
protocol so the UDP protocol is TCPS

00:11:24,950 --> 00:11:29,690
ugly kid brother what it means is when

00:11:27,560 --> 00:11:31,040
you send it to UDP packet you're not

00:11:29,690 --> 00:11:32,360
guarantee that that pack is going to get

00:11:31,040 --> 00:11:34,220
delivered or in the order that that

00:11:32,360 --> 00:11:36,470
packet is going to go what that means is

00:11:34,220 --> 00:11:39,260
is that you can send the packets a lot

00:11:36,470 --> 00:11:41,120
faster and it's a lot more performance

00:11:39,260 --> 00:11:43,700
so if you're gathering metrics and you

00:11:41,120 --> 00:11:45,770
lose some packets you know it's not the

00:11:43,700 --> 00:11:48,380
end of the world because you can use

00:11:45,770 --> 00:11:50,060
netstat to see if a if any of your

00:11:48,380 --> 00:11:51,589
service you could monitor you know have

00:11:50,060 --> 00:11:54,950
we lost UDP packets and you know that

00:11:51,589 --> 00:11:56,839
that's affected your metrics but you

00:11:54,950 --> 00:11:58,550
know the key concept is is that you know

00:11:56,839 --> 00:11:59,720
we're measuring our application so we

00:11:58,550 --> 00:12:01,820
don't want to affect the performance of

00:11:59,720 --> 00:12:05,270
the applications with our you know

00:12:01,820 --> 00:12:10,580
measuring system so another way to think

00:12:05,270 --> 00:12:13,580
of stats d is Sonic the Hedgehog on on

00:12:10,580 --> 00:12:14,900
steroids kind of thing but it's an event

00:12:13,580 --> 00:12:18,320
driven framework and it's got a lot of

00:12:14,900 --> 00:12:20,120
you know you know I oh so basically it's

00:12:18,320 --> 00:12:21,800
sitting there and it's gathering packets

00:12:20,120 --> 00:12:23,240
and then pumping them art it's doing

00:12:21,800 --> 00:12:26,510
some aggregation and then send them and

00:12:23,240 --> 00:12:29,360
their Mahr to a back-end so stats d is

00:12:26,510 --> 00:12:31,430
actually really simple if you want to

00:12:29,360 --> 00:12:33,650
have a look later the I've looked at the

00:12:31,430 --> 00:12:35,510
source code for stats t and the main

00:12:33,650 --> 00:12:37,100
library part is only like almost four

00:12:35,510 --> 00:12:38,390
hundred lines of JavaScript so it's not

00:12:37,100 --> 00:12:40,550
too difficult to understand what it's

00:12:38,390 --> 00:12:42,320
doing which is nice if you maybe want to

00:12:40,550 --> 00:12:43,700
contribute to that library or something

00:12:42,320 --> 00:12:44,839
like that so I just had a look at the

00:12:43,700 --> 00:12:47,390
source code just to get a better

00:12:44,839 --> 00:12:49,550
understanding for myself so you can

00:12:47,390 --> 00:12:52,670
clone it you then need to create a

00:12:49,550 --> 00:12:54,770
configuration file for stats d so you

00:12:52,670 --> 00:12:56,660
copy example the example configuration

00:12:54,770 --> 00:13:01,370
file some we just put it somewhere and

00:12:56,660 --> 00:13:03,920
then you can start up the node.js demon

00:13:01,370 --> 00:13:05,660
with you just type node status and the

00:13:03,920 --> 00:13:07,040
path to your configuration what I

00:13:05,660 --> 00:13:09,230
haven't shown you is how to install

00:13:07,040 --> 00:13:12,440
nodejs on your server but you can do

00:13:09,230 --> 00:13:15,170
that by using a package manager

00:13:12,440 --> 00:13:17,649
configuration management tool so just a

00:13:15,170 --> 00:13:19,509
basic sample stats d

00:13:17,649 --> 00:13:22,839
duration so what I'm saying is is that

00:13:19,509 --> 00:13:24,939
stats d is listening on port 80 125 it's

00:13:22,839 --> 00:13:28,300
using a graphite as a back end and then

00:13:24,939 --> 00:13:31,779
graphites listening on port 2300 on the

00:13:28,300 --> 00:13:36,749
local host in this instance debug it was

00:13:31,779 --> 00:13:40,029
true the reason I showed that is because

00:13:36,749 --> 00:13:41,829
when you getting started our stats d you

00:13:40,029 --> 00:13:42,939
can get some debug information so when

00:13:41,829 --> 00:13:45,819
you're first starting to play with it

00:13:42,939 --> 00:13:47,470
it'll actually output data onto the

00:13:45,819 --> 00:13:49,149
screen so if you send it a cantor metric

00:13:47,470 --> 00:13:50,589
it'll say I'm not tracking that metric

00:13:49,149 --> 00:13:53,199
and that kind of thing it just it just

00:13:50,589 --> 00:13:55,600
helps you get started ready and legacy

00:13:53,199 --> 00:14:00,459
names but equals false came in I think

00:13:55,600 --> 00:14:02,410
its version 0.5 or 1.5 of stats DN up so

00:14:00,459 --> 00:14:03,550
stats t also does some name spacing on

00:14:02,410 --> 00:14:07,089
your metrics and I'll give you an

00:14:03,550 --> 00:14:08,259
example shortly but if you just getting

00:14:07,089 --> 00:14:10,689
thought our status t I would recommend

00:14:08,259 --> 00:14:12,639
putting a legacy namespace onto false

00:14:10,689 --> 00:14:14,439
because you get really nice buckets for

00:14:12,639 --> 00:14:15,699
your different metric types if you don't

00:14:14,439 --> 00:14:17,079
there is a bit of confusion and there's

00:14:15,699 --> 00:14:19,059
a lot of issues in a raised in the

00:14:17,079 --> 00:14:21,639
projects so just in the simple JSON

00:14:19,059 --> 00:14:24,490
configuration just stick legacy

00:14:21,639 --> 00:14:26,649
namespace equals false okay so we've got

00:14:24,490 --> 00:14:29,110
half a system so I've taken us through

00:14:26,649 --> 00:14:32,050
some code yeah so that's what the code

00:14:29,110 --> 00:14:34,209
looks like to track an event in our

00:14:32,050 --> 00:14:37,379
system to get a simple counting metric a

00:14:34,209 --> 00:14:39,759
UDP packet goes over the wire to stats d

00:14:37,379 --> 00:14:43,199
stats these sitting there it's doing

00:14:39,759 --> 00:14:45,730
some aggregation and then it's flushing

00:14:43,199 --> 00:14:47,889
the metrics are to the back in every 10

00:14:45,730 --> 00:14:50,499
seconds so just something else that's

00:14:47,889 --> 00:14:51,970
important to understand is that stats t

00:14:50,499 --> 00:14:54,009
also does some name spacing on our

00:14:51,970 --> 00:14:55,779
metrics so you can see my metric name is

00:14:54,009 --> 00:14:59,800
account sort of indication that logins

00:14:55,779 --> 00:15:02,199
that attempted but stats t add some

00:14:59,800 --> 00:15:04,449
extra namespaces so for counter metrics

00:15:02,199 --> 00:15:06,730
with stats the little namespace at stats

00:15:04,449 --> 00:15:08,949
counters and it's my matric name and

00:15:06,730 --> 00:15:10,629
actually i'm only sending one value to

00:15:08,949 --> 00:15:13,209
staff see but it's actually sending two

00:15:10,629 --> 00:15:16,059
buckets are to graphite the first one is

00:15:13,209 --> 00:15:18,309
the actual current value so in a 10

00:15:16,059 --> 00:15:20,470
second period if i call this piece of

00:15:18,309 --> 00:15:24,670
code 23 times the value that gets

00:15:20,470 --> 00:15:26,410
flushed out to graphite is 23 but then

00:15:24,670 --> 00:15:30,410
also for there are events that happen in

00:15:26,410 --> 00:15:32,910
our applications very frequently so

00:15:30,410 --> 00:15:34,470
stats t also does a normalization and

00:15:32,910 --> 00:15:37,440
gives you the per second rate of that

00:15:34,470 --> 00:15:39,570
event so perhaps you are you know

00:15:37,440 --> 00:15:40,980
sending our tons and tons of emails you

00:15:39,570 --> 00:15:45,090
might want to see the per second rate

00:15:40,980 --> 00:15:47,760
that that's happening ok so just a bit

00:15:45,090 --> 00:15:49,910
on namespacing metrics so you know

00:15:47,760 --> 00:15:52,020
there's not a perfect sort of you know

00:15:49,910 --> 00:15:53,850
answer to this question I've put some

00:15:52,020 --> 00:15:56,040
blog posts at the bottom here I don't

00:15:53,850 --> 00:15:57,510
know if they say legible but my slides

00:15:56,040 --> 00:15:59,970
will be online later you can go have a

00:15:57,510 --> 00:16:02,070
look but in this instance I've got the

00:15:59,970 --> 00:16:03,570
namespace so I've got accounts I've got

00:16:02,070 --> 00:16:05,970
the instrumented section which is

00:16:03,570 --> 00:16:07,770
authentication I then got a target Nam

00:16:05,970 --> 00:16:09,810
which is login and then I'm postings

00:16:07,770 --> 00:16:11,670
verb which is attempted succeeded login

00:16:09,810 --> 00:16:15,750
so when you actually view these metrics

00:16:11,670 --> 00:16:18,900
in a graph you know the actual metric

00:16:15,750 --> 00:16:20,880
name makes sense so when you thinking of

00:16:18,900 --> 00:16:22,620
naming your metrics upfront give it a

00:16:20,880 --> 00:16:24,300
bit of thought maybe read the blog post

00:16:22,620 --> 00:16:26,460
but it is something to consider another

00:16:24,300 --> 00:16:29,130
another way to name metrics that I have

00:16:26,460 --> 00:16:32,070
seen and used a bit is you might want to

00:16:29,130 --> 00:16:33,690
have a matrix / environment and so my

00:16:32,070 --> 00:16:37,620
example in my load testing environment

00:16:33,690 --> 00:16:38,970
you know perhaps wonders in a metric to

00:16:37,620 --> 00:16:40,920
actually say what environment that is

00:16:38,970 --> 00:16:43,830
you know that's the product name the sub

00:16:40,920 --> 00:16:45,570
component is the API and this metric

00:16:43,830 --> 00:16:47,970
type which is a timing metric which I'll

00:16:45,570 --> 00:16:50,339
give you examples of is send email

00:16:47,970 --> 00:16:52,140
response time so you know there's no

00:16:50,339 --> 00:16:53,520
hard and fast rules but you know give it

00:16:52,140 --> 00:16:56,040
some you know thought upfront and then

00:16:53,520 --> 00:16:58,589
these buckets these are actual metric

00:16:56,040 --> 00:17:01,830
names then appear in graphite and you

00:16:58,589 --> 00:17:03,390
can get graphs from those metrics ok so

00:17:01,830 --> 00:17:06,329
graphites the third piece of the puzzle

00:17:03,390 --> 00:17:08,339
for the system it's written in Python

00:17:06,329 --> 00:17:10,260
graphite essentially what graphite does

00:17:08,339 --> 00:17:13,560
is it stores a numeric time series data

00:17:10,260 --> 00:17:15,390
it's just a nice way of saying that you

00:17:13,560 --> 00:17:16,680
know it collects the metrics and you can

00:17:15,390 --> 00:17:21,510
view those metrics and nice pretty

00:17:16,680 --> 00:17:23,130
graphs you can render graphs of this

00:17:21,510 --> 00:17:24,870
data under mine so what that means if

00:17:23,130 --> 00:17:28,470
you got metrics for a week you could go

00:17:24,870 --> 00:17:30,540
back to last week Tuesday or two weeks

00:17:28,470 --> 00:17:32,760
later last week tuesday between two and

00:17:30,540 --> 00:17:34,800
four and view that particular matrix and

00:17:32,760 --> 00:17:37,470
you can render the graphs on demand

00:17:34,800 --> 00:17:39,630
which is really quite powerful and also

00:17:37,470 --> 00:17:42,390
as graphite has a really powerful

00:17:39,630 --> 00:17:43,500
function library so you can apply

00:17:42,390 --> 00:17:46,050
functions

00:17:43,500 --> 00:17:47,760
to your metric types and do some really

00:17:46,050 --> 00:17:52,470
cool crazy stuff I give a couple of

00:17:47,760 --> 00:17:54,450
examples later on okay so I'm going to

00:17:52,470 --> 00:17:56,070
go a little bit deep into how to

00:17:54,450 --> 00:17:57,870
configure graphite because there were

00:17:56,070 --> 00:17:59,610
some pinch points for me and things I've

00:17:57,870 --> 00:18:00,810
got confused about so i thought those

00:17:59,610 --> 00:18:02,610
worth mentioning so if you want to

00:18:00,810 --> 00:18:04,350
implement the system when you go well

00:18:02,610 --> 00:18:05,970
off this talk you can maybe use the

00:18:04,350 --> 00:18:08,640
slides as a reference so the first thing

00:18:05,970 --> 00:18:12,000
in graphite is carbon so carbon is a

00:18:08,640 --> 00:18:15,060
network demon it uses the twisted event

00:18:12,000 --> 00:18:16,980
at io framework of a Python and but it's

00:18:15,060 --> 00:18:18,960
configured using carbon comp and it acts

00:18:16,980 --> 00:18:20,280
as like this buffer so stats these

00:18:18,960 --> 00:18:22,620
pumping out these metrics every 10

00:18:20,280 --> 00:18:24,330
second and this buffer Falls up and and

00:18:22,620 --> 00:18:25,260
because if you've got lots of metrics

00:18:24,330 --> 00:18:27,630
you don't want to bring the whole system

00:18:25,260 --> 00:18:30,690
to a halt when the buffer falls up it'll

00:18:27,630 --> 00:18:32,520
write that down to disk the important

00:18:30,690 --> 00:18:33,810
thing is is that if you do get to a

00:18:32,520 --> 00:18:35,700
point where you're sending tons and tons

00:18:33,810 --> 00:18:38,670
of matrix the first pinch point is

00:18:35,700 --> 00:18:40,590
probably going to be carbon because you

00:18:38,670 --> 00:18:42,120
know if the buffer gets full really

00:18:40,590 --> 00:18:44,490
quickly and then all of a sudden is

00:18:42,120 --> 00:18:47,340
doing a lot of Sikhs on the disk you

00:18:44,490 --> 00:18:49,560
know you might need to you know take a

00:18:47,340 --> 00:18:51,960
look at that the configuration file is

00:18:49,560 --> 00:18:53,850
quite well-documented got some really

00:18:51,960 --> 00:18:54,900
good comments in it but out the box if

00:18:53,850 --> 00:18:56,610
you're just getting sorted out you

00:18:54,900 --> 00:18:59,670
probably don't need to do touch anything

00:18:56,610 --> 00:19:03,060
in carbon conf and then we have whisper

00:18:59,670 --> 00:19:09,150
and whisper has two configuration files

00:19:03,060 --> 00:19:11,340
so storage scheme is calm and storage

00:19:09,150 --> 00:19:13,320
aggregation conf and I'll take you

00:19:11,340 --> 00:19:14,520
through those short key so the other

00:19:13,320 --> 00:19:16,590
thing to understand about whisper is

00:19:14,520 --> 00:19:19,800
that it's storing a numeric time series

00:19:16,590 --> 00:19:22,440
data so your database is fixed in size

00:19:19,800 --> 00:19:26,930
of pollen creation and it's similar to

00:19:22,440 --> 00:19:29,430
design a indesign to run Robin database

00:19:26,930 --> 00:19:31,710
so what we have is we have a timestamp

00:19:29,430 --> 00:19:32,760
every 10 seconds and actually the data

00:19:31,710 --> 00:19:34,500
would look something like this so you

00:19:32,760 --> 00:19:36,690
have the timestamp and then a count

00:19:34,500 --> 00:19:38,370
value then you'd have a timestamp 10

00:19:36,690 --> 00:19:40,320
seconds later with another count value

00:19:38,370 --> 00:19:42,180
so that's how you know it's at a higher

00:19:40,320 --> 00:19:47,250
level but that's to understand how

00:19:42,180 --> 00:19:49,860
whispers storing the data and you also

00:19:47,250 --> 00:19:51,929
then have this notion of archive so the

00:19:49,860 --> 00:19:53,680
whisper file format has some metadata so

00:19:51,929 --> 00:19:56,860
its data about the data and then

00:19:53,680 --> 00:19:58,420
you have different archives so I've got

00:19:56,860 --> 00:20:00,700
archive Enya because you can have as

00:19:58,420 --> 00:20:03,760
many archives as your life three is

00:20:00,700 --> 00:20:04,990
generally enough or you could go with

00:20:03,760 --> 00:20:11,950
one but on the next slide of the

00:20:04,990 --> 00:20:16,210
archives make a bit more sense so in the

00:20:11,950 --> 00:20:17,710
storage schemers file the thing to

00:20:16,210 --> 00:20:21,430
understand is that the metric will come

00:20:17,710 --> 00:20:22,900
into graphite like this but this

00:20:21,430 --> 00:20:24,100
configuration file has different

00:20:22,900 --> 00:20:27,400
sections so you can have multiple

00:20:24,100 --> 00:20:28,690
patterns in the configuration file but

00:20:27,400 --> 00:20:30,700
all it's saying is and this is a really

00:20:28,690 --> 00:20:35,560
simple a regular expression is catch

00:20:30,700 --> 00:20:38,380
this metric and it's prefixed with you

00:20:35,560 --> 00:20:42,040
know stats so any metric that's you know

00:20:38,380 --> 00:20:43,330
sent across the wire to graphite that

00:20:42,040 --> 00:20:44,590
starts with stats that's going to be

00:20:43,330 --> 00:20:46,810
called so this kind of acts as a

00:20:44,590 --> 00:20:48,700
catch-all bucket if you gettin started

00:20:46,810 --> 00:20:49,960
out you can do this but if you didn't

00:20:48,700 --> 00:20:51,550
want to use the catch-all approach you

00:20:49,960 --> 00:20:53,560
can have multiple sections in this file

00:20:51,550 --> 00:20:55,210
and it's read from top to bottom so the

00:20:53,560 --> 00:20:57,430
regulates the first regular expression

00:20:55,210 --> 00:20:59,260
that matches is the one that'll be used

00:20:57,430 --> 00:21:02,550
but the most important thing about this

00:20:59,260 --> 00:21:05,620
file is configuring your attentions so

00:21:02,550 --> 00:21:06,880
I'm saying I want to store the frequency

00:21:05,620 --> 00:21:08,620
of my data that's coming in his

00:21:06,880 --> 00:21:12,070
10-second data and I want to store that

00:21:08,620 --> 00:21:14,890
data for six hours and so my first

00:21:12,070 --> 00:21:16,900
archive will have ten second data for

00:21:14,890 --> 00:21:20,200
six hours and then we have multiple

00:21:16,900 --> 00:21:22,840
archives so then the next archive is one

00:21:20,200 --> 00:21:25,360
minute data for seven hours and then the

00:21:22,840 --> 00:21:27,700
third archive is 10 minute data for five

00:21:25,360 --> 00:21:29,040
years so you need to kind of thing okay

00:21:27,700 --> 00:21:31,150
well how long for this particular

00:21:29,040 --> 00:21:35,530
contour metric how long do I want to

00:21:31,150 --> 00:21:38,530
store some values another pain point is

00:21:35,530 --> 00:21:41,770
that your lowest retention excuse me

00:21:38,530 --> 00:21:44,110
your lowest retention of 10 seconds

00:21:41,770 --> 00:21:46,360
should match the defaults that's the

00:21:44,110 --> 00:21:48,850
flash interval if you don't you're going

00:21:46,360 --> 00:21:51,130
to end up with some weird stuff going on

00:21:48,850 --> 00:21:53,080
in graphite missing data and whatever so

00:21:51,130 --> 00:21:54,970
if you change the flush interval in

00:21:53,080 --> 00:21:58,210
status d which you can do you want to up

00:21:54,970 --> 00:22:00,220
your retention value sure but the other

00:21:58,210 --> 00:22:02,280
really important thing is that because

00:22:00,220 --> 00:22:05,080
we're using a round robin type database

00:22:02,280 --> 00:22:07,080
when data moves from one archive to the

00:22:05,080 --> 00:22:11,020
next

00:22:07,080 --> 00:22:12,669
data gets aggregated right so when so

00:22:11,020 --> 00:22:14,440
when we've got six hours of ten second

00:22:12,669 --> 00:22:17,290
data data starts getting overwritten

00:22:14,440 --> 00:22:19,330
again and gets rolled up into archive

00:22:17,290 --> 00:22:21,040
too and in archive to we've got one

00:22:19,330 --> 00:22:23,380
minute data right so for one minute data

00:22:21,040 --> 00:22:26,200
will have six data points of ten second

00:22:23,380 --> 00:22:27,820
data so you configure the storage

00:22:26,200 --> 00:22:30,700
aggregation using the storage

00:22:27,820 --> 00:22:33,220
aggregation conf and again the files got

00:22:30,700 --> 00:22:35,110
a similar similar sort of format so it's

00:22:33,220 --> 00:22:39,160
read from top to bottom so we're saying

00:22:35,110 --> 00:22:43,090
the pattern that ends in you know dot

00:22:39,160 --> 00:22:45,190
can't I want the aggregation method to

00:22:43,090 --> 00:22:46,809
be some so what that means is when it

00:22:45,190 --> 00:22:48,309
rolls the data up from one archive to

00:22:46,809 --> 00:22:50,880
the other you want to you want to sum

00:22:48,309 --> 00:22:54,160
the values because by default whisper

00:22:50,880 --> 00:22:55,929
users averaging and so if you averaged

00:22:54,160 --> 00:22:57,520
art a counter metric it's going to lose

00:22:55,929 --> 00:22:59,049
its actual meaning the data is going to

00:22:57,520 --> 00:23:01,809
lose it a minute when i show you timing

00:22:59,049 --> 00:23:04,360
matrix it's ok to average lows art over

00:23:01,809 --> 00:23:05,679
time but with cancer values that's

00:23:04,360 --> 00:23:09,340
another pinch point so you'll actually

00:23:05,679 --> 00:23:11,350
lose the meaning of your data and it's

00:23:09,340 --> 00:23:12,940
also a thing called x-files factor which

00:23:11,350 --> 00:23:14,770
you configure this file has a couple of

00:23:12,940 --> 00:23:16,179
other configuration options again there

00:23:14,770 --> 00:23:19,780
are pretty well-documented it's a link

00:23:16,179 --> 00:23:22,179
to the doc share but when you go from 10

00:23:19,780 --> 00:23:25,750
second data for six hours to one minute

00:23:22,179 --> 00:23:27,250
data for seven days you know you only

00:23:25,750 --> 00:23:29,200
want the data to be rolled up for

00:23:27,250 --> 00:23:31,270
certain metric types if you have you

00:23:29,200 --> 00:23:33,130
know values at each specific point so

00:23:31,270 --> 00:23:34,750
it's not a real good name for a

00:23:33,130 --> 00:23:40,179
configuration option because it's X

00:23:34,750 --> 00:23:44,470
Files factor but if I had no 10 second

00:23:40,179 --> 00:23:47,380
data over a month period so if I didn't

00:23:44,470 --> 00:23:51,580
have the six data points it's fine that

00:23:47,380 --> 00:23:53,590
data will still get rolled up to one

00:23:51,580 --> 00:23:54,940
minute data but the value would be 0 but

00:23:53,590 --> 00:23:56,410
perhaps you've got a timing metric and

00:23:54,940 --> 00:24:01,559
you don't want to do that so you can

00:23:56,410 --> 00:24:04,120
configure that with X Files factor ok so

00:24:01,559 --> 00:24:07,419
we have other aggregation methods to we

00:24:04,120 --> 00:24:10,540
have averaged some min and Max depending

00:24:07,419 --> 00:24:12,640
on the metric types and min and Max are

00:24:10,540 --> 00:24:14,559
used for timing metrics and it'll make a

00:24:12,640 --> 00:24:16,960
bit more sense when I show you some

00:24:14,559 --> 00:24:19,160
slides further on but we've taken quite

00:24:16,960 --> 00:24:23,870
a bit of a sort of a deep dive here

00:24:19,160 --> 00:24:26,020
so this is our application metric system

00:24:23,870 --> 00:24:30,530
to you know gather some measurements

00:24:26,020 --> 00:24:32,540
we're doing a canting metric so we're

00:24:30,530 --> 00:24:35,210
incrementing a counter over the wire

00:24:32,540 --> 00:24:37,010
that's what the UDP packet looks like we

00:24:35,210 --> 00:24:38,450
then have stats d stats is doing a job

00:24:37,010 --> 00:24:40,220
for us it's doing some aggregation

00:24:38,450 --> 00:24:42,050
flushes the metrics are two carbon

00:24:40,220 --> 00:24:43,700
carbon since their gathers and metrics

00:24:42,050 --> 00:24:45,710
and flushes it to disk and then those

00:24:43,700 --> 00:24:50,270
metrics of store based on our attentions

00:24:45,710 --> 00:24:55,700
and then they rolled up through the you

00:24:50,270 --> 00:25:02,930
know in their attentions in with the

00:24:55,700 --> 00:25:04,750
aggregation file okay so the real

00:25:02,930 --> 00:25:08,150
important thing to understand is that

00:25:04,750 --> 00:25:10,880
etsy wanted to have a system in place

00:25:08,150 --> 00:25:12,290
that they can you know go from not

00:25:10,880 --> 00:25:14,090
knowing the answer to a question to

00:25:12,290 --> 00:25:15,680
knowing that answer really quickly so

00:25:14,090 --> 00:25:17,750
like where I said how many emails have

00:25:15,680 --> 00:25:19,520
we sent or you know how many times is

00:25:17,750 --> 00:25:20,960
the system doing this we can get that

00:25:19,520 --> 00:25:23,120
answer really quickly so once you've

00:25:20,960 --> 00:25:24,470
implemented the system you might have to

00:25:23,120 --> 00:25:26,390
come back and make some changes to it

00:25:24,470 --> 00:25:29,290
but from then on upwards we can just

00:25:26,390 --> 00:25:31,460
start gathering application metrics so

00:25:29,290 --> 00:25:33,380
that's really nice we can just you know

00:25:31,460 --> 00:25:36,190
put in some code and once we deploy our

00:25:33,380 --> 00:25:38,570
application we get some metrics about it

00:25:36,190 --> 00:25:40,280
so the cancer matrix continued so

00:25:38,570 --> 00:25:42,230
there's another code sample it's really

00:25:40,280 --> 00:25:43,940
some pseudocode I haven't sort of flesh

00:25:42,230 --> 00:25:47,090
this out but I've got an authentication

00:25:43,940 --> 00:25:49,220
method I don't even have the class

00:25:47,090 --> 00:25:52,310
declarations or any notice that now when

00:25:49,220 --> 00:25:53,750
it's nice big and but I'm basically

00:25:52,310 --> 00:25:56,780
gathering how many logins have been

00:25:53,750 --> 00:25:59,720
attempted these are successful logins

00:25:56,780 --> 00:26:02,240
else you know failed logins so in

00:25:59,720 --> 00:26:03,980
graphite what you have is you have three

00:26:02,240 --> 00:26:06,080
different buckets for these simple

00:26:03,980 --> 00:26:08,060
cancer matrix right and if you click on

00:26:06,080 --> 00:26:11,900
a bucket you get a nice graph of those

00:26:08,060 --> 00:26:15,860
metrics so we can see on the left that's

00:26:11,900 --> 00:26:18,080
logins attempted so the logins that have

00:26:15,860 --> 00:26:19,280
been successful or in green and it's I

00:26:18,080 --> 00:26:20,780
don't know how legible that is but

00:26:19,280 --> 00:26:22,610
there's a red line there with the failed

00:26:20,780 --> 00:26:24,590
logins but graphite has a really

00:26:22,610 --> 00:26:26,330
powerful feature where you can correlate

00:26:24,590 --> 00:26:28,010
data really easy so you can just take

00:26:26,330 --> 00:26:30,140
one of these graphs and just drop it on

00:26:28,010 --> 00:26:31,640
another one and then view metrics

00:26:30,140 --> 00:26:32,419
against one another so when you do that

00:26:31,640 --> 00:26:34,129
you get a graph

00:26:32,419 --> 00:26:36,980
look something like this so what we have

00:26:34,129 --> 00:26:39,919
is Logan's attempted login succeed ins

00:26:36,980 --> 00:26:41,659
and logins failed so you know really you

00:26:39,919 --> 00:26:42,859
know i mean i'm using logins an example

00:26:41,659 --> 00:26:44,779
but any events that happen in your

00:26:42,859 --> 00:26:47,720
system you can correlate them to one

00:26:44,779 --> 00:26:52,659
another really easily the you know kinds

00:26:47,720 --> 00:26:54,679
of metrics in this example and but

00:26:52,659 --> 00:26:56,119
something that you know the problem that

00:26:54,679 --> 00:26:57,559
i had last year was you know we were

00:26:56,119 --> 00:27:02,389
deploying our application quite a bit

00:26:57,559 --> 00:27:04,070
and so you know the knock-on effect of

00:27:02,389 --> 00:27:06,109
deployment application you sometimes

00:27:04,070 --> 00:27:08,899
want to know have you broken something

00:27:06,109 --> 00:27:13,129
in your application so another thing you

00:27:08,899 --> 00:27:15,619
can do with stats d is you can draw

00:27:13,129 --> 00:27:17,570
lines on graphs right so what i'm doing

00:27:15,619 --> 00:27:19,340
over here isn't what you can see if this

00:27:17,570 --> 00:27:21,320
graph makes sense is that everyone was

00:27:19,340 --> 00:27:22,970
logging into the system fine we had a

00:27:21,320 --> 00:27:24,769
couple of failed logins and all of a

00:27:22,970 --> 00:27:26,330
sudden we've got a deployment right

00:27:24,769 --> 00:27:27,679
which is the yellow line and all of a

00:27:26,330 --> 00:27:30,499
sudden nobody can log into the system

00:27:27,679 --> 00:27:32,450
right so that's so if you making a big

00:27:30,499 --> 00:27:34,039
feature change and you tracking that

00:27:32,450 --> 00:27:35,929
kinds of feature if you correlate it to

00:27:34,039 --> 00:27:38,269
deployments you can see straight away

00:27:35,929 --> 00:27:40,070
you know what effect you've had on it

00:27:38,269 --> 00:27:41,690
and you can see ya there was a period of

00:27:40,070 --> 00:27:44,690
time where you know things were broken

00:27:41,690 --> 00:27:46,600
I've deployed again all of a sudden you

00:27:44,690 --> 00:27:48,470
know everyone's able to login again and

00:27:46,600 --> 00:27:49,940
you know there's a couple of failed

00:27:48,470 --> 00:27:51,470
logins but it's gone back down to the

00:27:49,940 --> 00:27:53,869
norm so you've got this really like

00:27:51,470 --> 00:27:55,840
visual graphs of what's going on in your

00:27:53,869 --> 00:27:58,879
in your application is really powerful

00:27:55,840 --> 00:28:01,129
so the trick to track every release is

00:27:58,879 --> 00:28:03,649
something that took me a while to work

00:28:01,129 --> 00:28:05,269
out but is to use the draw as in finite

00:28:03,649 --> 00:28:06,649
function in graphite so if you right

00:28:05,269 --> 00:28:11,239
click on one of those graphs you get a

00:28:06,649 --> 00:28:13,279
list of functions and you can say it

00:28:11,239 --> 00:28:14,749
draws in finance if a long as the

00:28:13,279 --> 00:28:16,309
counter value is larger than one you'll

00:28:14,749 --> 00:28:17,600
get a straight line in the graph so it

00:28:16,309 --> 00:28:19,940
doesn't only have to be deployments

00:28:17,600 --> 00:28:21,259
that's any other vent that happens that

00:28:19,940 --> 00:28:24,070
you want to track like that you can draw

00:28:21,259 --> 00:28:26,119
it as a straight line and so I'm just

00:28:24,070 --> 00:28:27,950
incrementing account here that if that's

00:28:26,119 --> 00:28:29,119
for deploys but obviously you know if

00:28:27,950 --> 00:28:30,080
you were tracking this event you would

00:28:29,119 --> 00:28:31,519
probably want to do it from your

00:28:30,080 --> 00:28:33,529
deployment system so say using

00:28:31,519 --> 00:28:35,720
Capistrano or fing or something like

00:28:33,529 --> 00:28:39,710
that every time you deploy you could do

00:28:35,720 --> 00:28:41,840
that with a simple and bash command I

00:28:39,710 --> 00:28:43,940
think they are some deployment systems

00:28:41,840 --> 00:28:45,340
actually have a plug-in that does this

00:28:43,940 --> 00:28:50,050
for you but that's actually

00:28:45,340 --> 00:28:52,330
is happening at the lower level okay so

00:28:50,050 --> 00:28:53,500
I've taken you through the system and

00:28:52,330 --> 00:28:55,180
I've taken you through how to gather

00:28:53,500 --> 00:28:57,850
canter matrix but there are other metric

00:28:55,180 --> 00:29:00,430
types the other metric types is timing

00:28:57,850 --> 00:29:04,390
so we can time any piece of our PHP

00:29:00,430 --> 00:29:08,860
application we can do gorges so guards

00:29:04,390 --> 00:29:12,460
or get gauges gauges and it's basically

00:29:08,860 --> 00:29:14,110
to track a arbitrary value you know at a

00:29:12,460 --> 00:29:15,580
certain point in time kind of like a

00:29:14,110 --> 00:29:17,350
petrol gauge if you look at your petrol

00:29:15,580 --> 00:29:19,980
gauge now and then you look at it in an

00:29:17,350 --> 00:29:22,300
hour's time you know would have moved so

00:29:19,980 --> 00:29:26,080
that's another metric type you can use

00:29:22,300 --> 00:29:28,540
sets so set started out as a pull

00:29:26,080 --> 00:29:31,690
request to STATS d haven't you sets much

00:29:28,540 --> 00:29:33,760
myself but sets or to get the unique

00:29:31,690 --> 00:29:38,710
items in a group so if you wanted to see

00:29:33,760 --> 00:29:41,050
something like how many unique users are

00:29:38,710 --> 00:29:42,580
on your site you could use sets the

00:29:41,050 --> 00:29:44,320
important thing about sets is to make

00:29:42,580 --> 00:29:46,150
sure that your stats d client library

00:29:44,320 --> 00:29:49,360
support sets because the library i

00:29:46,150 --> 00:29:50,710
showed you you doesn't but again you

00:29:49,360 --> 00:29:52,780
could probably get what that metric

00:29:50,710 --> 00:29:56,050
looks like over the wire and do the

00:29:52,780 --> 00:29:57,370
implementation yourself which is

00:29:56,050 --> 00:29:59,050
actually not a bad idea for a pull

00:29:57,370 --> 00:30:01,060
request on I just thought of that now

00:29:59,050 --> 00:30:03,220
for that library because that currently

00:30:01,060 --> 00:30:07,150
doesn't have sets but sets are a fairly

00:30:03,220 --> 00:30:09,130
new metric type ok so let's do some

00:30:07,150 --> 00:30:10,780
timing matrix right so how do we do a

00:30:09,130 --> 00:30:14,260
timing metric well that's really simple

00:30:10,780 --> 00:30:16,900
on the stats the object i'm just calling

00:30:14,260 --> 00:30:19,510
the start timing method so via the

00:30:16,900 --> 00:30:21,220
metric that i'm tracking is a send email

00:30:19,510 --> 00:30:23,080
response time so for a hypothetical

00:30:21,220 --> 00:30:26,200
example let's say using a third-party

00:30:23,080 --> 00:30:29,770
api to trigger off a transaction email

00:30:26,200 --> 00:30:31,900
you can go start timing then we have

00:30:29,770 --> 00:30:34,780
some code which connects to that api and

00:30:31,900 --> 00:30:36,040
sends that email and then n timing right

00:30:34,780 --> 00:30:38,980
and that will actually send a

00:30:36,040 --> 00:30:40,390
millisecond value as a timing metric the

00:30:38,980 --> 00:30:42,490
other way to do it with this library i'm

00:30:40,390 --> 00:30:43,750
using is you can just go timing and so

00:30:42,490 --> 00:30:48,030
basically you would give it the metric

00:30:43,750 --> 00:30:50,470
name and this value is in milliseconds

00:30:48,030 --> 00:30:52,180
and again over the wire what does the

00:30:50,470 --> 00:30:56,560
metric look like so we've got the metric

00:30:52,180 --> 00:30:58,700
name the value and the metric type is ms

00:30:56,560 --> 00:31:01,730
which is milliseconds but it's a timing

00:30:58,700 --> 00:31:04,220
trick so timing matrix under the hood is

00:31:01,730 --> 00:31:08,360
the most complicated metric type in

00:31:04,220 --> 00:31:09,590
stats d but it's important to understand

00:31:08,360 --> 00:31:11,540
that stat see does a lot of aggregate

00:31:09,590 --> 00:31:16,840
vacation for us so we send one timing

00:31:11,540 --> 00:31:19,880
metric to stats d but stats d produces

00:31:16,840 --> 00:31:21,860
nine data buckets and those nine data

00:31:19,880 --> 00:31:23,240
buckets look something like this so we

00:31:21,860 --> 00:31:24,860
have stat start timers we have the

00:31:23,240 --> 00:31:27,170
metric name and then we've got a whole

00:31:24,860 --> 00:31:29,330
bunch of sort of a statistical thing so

00:31:27,170 --> 00:31:33,820
we have the mean we've got the lower the

00:31:29,330 --> 00:31:35,990
upper and we've got standard deviation

00:31:33,820 --> 00:31:38,210
we've got the mean of the 90th

00:31:35,990 --> 00:31:42,500
percentile so the mean of ninety percent

00:31:38,210 --> 00:31:43,340
of the values and I think someone raised

00:31:42,500 --> 00:31:45,230
the issue that you know you don't

00:31:43,340 --> 00:31:46,610
actually need all of these values so at

00:31:45,230 --> 00:31:48,110
some point there might be configurable

00:31:46,610 --> 00:31:49,700
so you can switch some of them off and

00:31:48,110 --> 00:31:52,160
only you know use the ones that you need

00:31:49,700 --> 00:31:54,380
but I mean just to understand you know

00:31:52,160 --> 00:31:56,210
the timing metrics so if a set of data

00:31:54,380 --> 00:31:58,490
for a 10 second period say these were

00:31:56,210 --> 00:32:00,380
millisecond values the mean that it

00:31:58,490 --> 00:32:01,700
calculates for you automatically stats d

00:32:00,380 --> 00:32:03,800
would be to our nine so it's just the

00:32:01,700 --> 00:32:05,900
sum of the values like my math is right

00:32:03,800 --> 00:32:08,300
they divided by the number of values and

00:32:05,900 --> 00:32:10,160
and then we get the lower value so in

00:32:08,300 --> 00:32:12,970
the set of data for a 10 second period

00:32:10,160 --> 00:32:17,930
the lower value would be 200 and the

00:32:12,970 --> 00:32:22,670
upper value would be to 17 so what does

00:32:17,930 --> 00:32:26,890
this look like on a graph looks really

00:32:22,670 --> 00:32:31,100
nice so what we have here is we can see

00:32:26,890 --> 00:32:34,330
that making a call to this API on

00:32:31,100 --> 00:32:36,830
average over time takes 250 milliseconds

00:32:34,330 --> 00:32:38,960
the Arthur limits the upper limits it's

00:32:36,830 --> 00:32:42,200
close to 300 milliseconds and the lower

00:32:38,960 --> 00:32:43,940
limits is 200 milliseconds right so

00:32:42,200 --> 00:32:49,130
that's really useful so I've actually

00:32:43,940 --> 00:32:50,600
produced a a graph like this so each of

00:32:49,130 --> 00:32:52,460
those nine metric types that I show you

00:32:50,600 --> 00:32:54,080
to be nine different graphs and I've

00:32:52,460 --> 00:32:55,670
just dropped these three on on top of

00:32:54,080 --> 00:32:57,790
one of another but if you wanted to you

00:32:55,670 --> 00:33:01,310
could put all nine matrix together and

00:32:57,790 --> 00:33:03,680
if you really wanted to do that but this

00:33:01,310 --> 00:33:06,080
is where timing metrics become really

00:33:03,680 --> 00:33:09,620
important ok so something's going wrong

00:33:06,080 --> 00:33:12,080
and you fix that slide but essentially

00:33:09,620 --> 00:33:14,899
we can see that you know calling this AP

00:33:12,080 --> 00:33:17,390
I took 250 milliseconds but then all of

00:33:14,899 --> 00:33:19,640
a sudden there's a massive jump and it's

00:33:17,390 --> 00:33:22,340
not taking 400 milliseconds right you

00:33:19,640 --> 00:33:23,299
know what the hell happened you know so

00:33:22,340 --> 00:33:25,399
you probably want to get on the phone

00:33:23,299 --> 00:33:28,039
and start you know speaking to you and

00:33:25,399 --> 00:33:30,320
your third party supply and say hey you

00:33:28,039 --> 00:33:32,390
know your API sort of a sudden you know

00:33:30,320 --> 00:33:33,980
taking really long to respond but this

00:33:32,390 --> 00:33:35,570
was so probably you know this is an

00:33:33,980 --> 00:33:37,190
example of sending an email but if you

00:33:35,570 --> 00:33:39,230
were timing a piece of code and you are

00:33:37,190 --> 00:33:42,019
dependent on a third-party API and all

00:33:39,230 --> 00:33:44,149
of a sudden you know the timing spikes

00:33:42,019 --> 00:33:45,470
you probably want to know about that and

00:33:44,149 --> 00:33:47,000
you want to maybe question them on that

00:33:45,470 --> 00:33:48,769
because you know they've probably made a

00:33:47,000 --> 00:33:49,940
change or you know it might be something

00:33:48,769 --> 00:33:53,960
on the network there's so many different

00:33:49,940 --> 00:33:56,059
possibilities but in reality as you know

00:33:53,960 --> 00:33:57,710
developers we know we are all quite busy

00:33:56,059 --> 00:33:59,659
we're not going to sit there staring you

00:33:57,710 --> 00:34:01,399
know and watch it and graph and waiting

00:33:59,659 --> 00:34:02,450
for something to happen well you know

00:34:01,399 --> 00:34:05,779
maybe if you've got time on your hands

00:34:02,450 --> 00:34:07,580
you can do that but you know it would be

00:34:05,779 --> 00:34:09,649
nice to be notified automatically if

00:34:07,580 --> 00:34:12,200
something like this happen so graphite

00:34:09,649 --> 00:34:15,440
does have a really powerful API aranda

00:34:12,200 --> 00:34:18,800
API so you can actually export data in a

00:34:15,440 --> 00:34:21,230
JSON format so you can call the graphite

00:34:18,800 --> 00:34:23,629
API get the data art and then obviously

00:34:21,230 --> 00:34:25,790
do some calculations and so if you saw

00:34:23,629 --> 00:34:28,280
that in you know the previous slide if

00:34:25,790 --> 00:34:30,020
you sort of a sudden I mean in this case

00:34:28,280 --> 00:34:32,149
we will probably set our threshold right

00:34:30,020 --> 00:34:35,450
so we can see I can average is roughly

00:34:32,149 --> 00:34:39,099
250 milliseconds if the average goes say

00:34:35,450 --> 00:34:41,720
up to you know 325 milliseconds you know

00:34:39,099 --> 00:34:43,280
because that's you know above the the

00:34:41,720 --> 00:34:46,339
art of sort of limit let me know about

00:34:43,280 --> 00:34:52,879
that so we get the data out of graphite

00:34:46,339 --> 00:34:55,159
using the render API so the render a

00:34:52,879 --> 00:34:57,920
plain graphite is quite powerful so it

00:34:55,159 --> 00:34:59,420
basically splits outer image and in some

00:34:57,920 --> 00:35:03,109
examples if you change the format to

00:34:59,420 --> 00:35:07,160
JSON you get a nice simple sort of bit

00:35:03,109 --> 00:35:09,530
of data in JSON format and then on the

00:35:07,160 --> 00:35:12,140
back of this we could do some anomaly

00:35:09,530 --> 00:35:15,619
detection so in the example where we

00:35:12,140 --> 00:35:17,210
have that spike in the timing these are

00:35:15,619 --> 00:35:18,530
two examples of anomaly detection you

00:35:17,210 --> 00:35:20,180
can do you could write your own anomaly

00:35:18,530 --> 00:35:24,140
detection because you've got the data in

00:35:20,180 --> 00:35:25,310
that format but nagios is a simple check

00:35:24,140 --> 00:35:26,570
that you can use of guitar

00:35:25,310 --> 00:35:28,250
so you can say you know this is a

00:35:26,570 --> 00:35:30,920
threshold for this metric if it goes

00:35:28,250 --> 00:35:34,190
above this threshold you know send me a

00:35:30,920 --> 00:35:35,540
warning you know nagios has different I

00:35:34,190 --> 00:35:36,950
don't not sure how much people know

00:35:35,540 --> 00:35:38,600
about Nagas it has different alerting

00:35:36,950 --> 00:35:42,470
levels so you can have warning critical

00:35:38,600 --> 00:35:45,640
but you know so maybe warning at 325 or

00:35:42,470 --> 00:35:48,590
critical at it at a certain level and

00:35:45,640 --> 00:35:52,610
another tool to do not only detection is

00:35:48,590 --> 00:35:54,800
a a wider system called kale that was

00:35:52,610 --> 00:35:56,570
open source by HC the middle of last

00:35:54,800 --> 00:35:57,980
year I think it's a really good blog

00:35:56,570 --> 00:36:00,440
place you can go read and part of that

00:35:57,980 --> 00:36:01,640
kale system is skyline write the blog

00:36:00,440 --> 00:36:03,470
post is really interesting because he

00:36:01,640 --> 00:36:04,460
talks about the amount of application

00:36:03,470 --> 00:36:05,990
metrics that I have and it's something

00:36:04,460 --> 00:36:07,820
like I think because think he says a

00:36:05,990 --> 00:36:10,580
quarter of a million so you can imagine

00:36:07,820 --> 00:36:13,760
you've got a quarter million matrix you

00:36:10,580 --> 00:36:16,070
know I think it says something like 250

00:36:13,760 --> 00:36:18,680
software engineers so you know that's a

00:36:16,070 --> 00:36:20,330
thousand metrics / engineer you assume

00:36:18,680 --> 00:36:22,220
means we can't certain you know monitor

00:36:20,330 --> 00:36:24,290
these metrics so this is a system that

00:36:22,220 --> 00:36:25,850
they built and that they've open source

00:36:24,290 --> 00:36:27,710
they can actually do the anomaly

00:36:25,850 --> 00:36:30,370
detection for you and there's another

00:36:27,710 --> 00:36:33,860
part of the scale system called oculus

00:36:30,370 --> 00:36:35,420
which then does you know if there's a I

00:36:33,860 --> 00:36:37,700
think from the way under standard I

00:36:35,420 --> 00:36:39,590
haven't used skyline but if there's a

00:36:37,700 --> 00:36:41,840
problem with this metric correlated to

00:36:39,590 --> 00:36:43,430
this metric and this metric and then you

00:36:41,840 --> 00:36:45,470
know if you know there's a pattern then

00:36:43,430 --> 00:36:46,490
you know semi alerts it's quite complex

00:36:45,470 --> 00:36:49,220
I haven't worked that I don't have that

00:36:46,490 --> 00:36:52,910
many metrics so but it is if you've got

00:36:49,220 --> 00:36:56,780
a that you start to track that might be

00:36:52,910 --> 00:36:59,750
something you want to look at okay so

00:36:56,780 --> 00:37:01,070
I've taken you through you know using

00:36:59,750 --> 00:37:03,140
the stats declined library getting

00:37:01,070 --> 00:37:05,420
cancer metrics timing matrix told you

00:37:03,140 --> 00:37:06,710
about the other metric types but the

00:37:05,420 --> 00:37:08,300
other cool thing that we can do with the

00:37:06,710 --> 00:37:12,380
system is we can get metrics from our

00:37:08,300 --> 00:37:13,700
log files okay so there's two tools to

00:37:12,380 --> 00:37:16,640
do this so the first tool that we can

00:37:13,700 --> 00:37:19,460
use is lobster which again you guessed

00:37:16,640 --> 00:37:21,260
it is by HC so it allows you to pass a

00:37:19,460 --> 00:37:23,300
configuration file and put some metrics

00:37:21,260 --> 00:37:25,310
into logs but the other tool is a log

00:37:23,300 --> 00:37:27,080
stash I think develop developers are

00:37:25,310 --> 00:37:29,300
fairly familiar i'm not sure how many

00:37:27,080 --> 00:37:32,690
guards are using log stash but log stash

00:37:29,300 --> 00:37:34,460
is the other tool that you can use so

00:37:32,690 --> 00:37:35,790
you pass log files and you send some

00:37:34,460 --> 00:37:37,230
data to

00:37:35,790 --> 00:37:38,820
stats d so I'm going to give you an

00:37:37,230 --> 00:37:41,790
example of how to do that with log stash

00:37:38,820 --> 00:37:45,210
so log stash has this notion of inputs

00:37:41,790 --> 00:37:47,610
with filters so over yeah my input is my

00:37:45,210 --> 00:37:49,890
Apache access log so Apache access logs

00:37:47,610 --> 00:37:52,440
you know are quite configurable in terms

00:37:49,890 --> 00:37:53,760
of what you can put in them in a fairly

00:37:52,440 --> 00:37:55,500
configurable but you can get things like

00:37:53,760 --> 00:37:58,770
you know number of bytes same for

00:37:55,500 --> 00:38:00,930
request response codes you know all

00:37:58,770 --> 00:38:02,220
different types of things then with log

00:38:00,930 --> 00:38:04,860
stash we have the input then we have a

00:38:02,220 --> 00:38:09,060
filter so this is using croc pattern

00:38:04,860 --> 00:38:11,820
matching so croc matches some operatory

00:38:09,060 --> 00:38:13,470
text you know to pattern i kind of like

00:38:11,820 --> 00:38:18,300
to think of in PHP terms like preg match

00:38:13,470 --> 00:38:20,550
so you get your matches so it outputs a

00:38:18,300 --> 00:38:22,470
bunch of patterns and then my output is

00:38:20,550 --> 00:38:25,140
to stats d so what I'm saying is for

00:38:22,470 --> 00:38:27,750
every response code increments a cancer

00:38:25,140 --> 00:38:32,280
based on the particular response code

00:38:27,750 --> 00:38:34,950
right so what does that look like in a

00:38:32,280 --> 00:38:36,980
graph so a graphite graph of HTTP

00:38:34,950 --> 00:38:39,330
response code right so we can see

00:38:36,980 --> 00:38:41,820
essentially we've got a you know a nice

00:38:39,330 --> 00:38:43,830
graph using cancers we've got the number

00:38:41,820 --> 00:38:46,110
of response codes so if all of a sudden

00:38:43,830 --> 00:38:48,840
we've got a lot of 500 response codes or

00:38:46,110 --> 00:38:51,120
400 for that matter or maybe a load of

00:38:48,840 --> 00:38:53,310
redirects you know we can start to do

00:38:51,120 --> 00:38:54,450
some anomaly detection on this but the

00:38:53,310 --> 00:38:58,320
point that I'm really trying to make

00:38:54,450 --> 00:39:01,350
here is that you know we've got so many

00:38:58,320 --> 00:39:04,020
different you know log files you know in

00:39:01,350 --> 00:39:06,030
a simple you know web application so

00:39:04,020 --> 00:39:08,310
you've got you know my sequel logs if

00:39:06,030 --> 00:39:10,290
they switched on you know any tool using

00:39:08,310 --> 00:39:11,580
varnish if that's logging so there's

00:39:10,290 --> 00:39:13,800
loads of different data in your log

00:39:11,580 --> 00:39:15,900
files that you can then a great and set

00:39:13,800 --> 00:39:18,330
on to stats t and get some nice sort of

00:39:15,900 --> 00:39:20,430
you know idea of what's going on also

00:39:18,330 --> 00:39:22,380
you know if using monologue you could

00:39:20,430 --> 00:39:24,900
potentially log something particular to

00:39:22,380 --> 00:39:27,450
a file and then grow fat art into a nice

00:39:24,900 --> 00:39:30,210
graph and viewing your your your log

00:39:27,450 --> 00:39:32,220
files as graphs it kind of gives you

00:39:30,210 --> 00:39:34,230
kind of a sort of a better understanding

00:39:32,220 --> 00:39:36,810
of things so this is an example that I

00:39:34,230 --> 00:39:39,630
took from the 80 blog post but they're

00:39:36,810 --> 00:39:41,820
tracking the number of PHP warnings so

00:39:39,630 --> 00:39:43,560
it's clear to see that you know at about

00:39:41,820 --> 00:39:44,869
four o'clock something happened all of a

00:39:43,560 --> 00:39:48,230
sudden there was a low

00:39:44,869 --> 00:39:50,390
of warnings and then all of a sudden

00:39:48,230 --> 00:39:52,240
they came down it sort of didn't quite

00:39:50,390 --> 00:39:54,859
correct itself and then from now onwards

00:39:52,240 --> 00:39:56,749
everything was okay if you correlate

00:39:54,859 --> 00:39:58,940
those two deployments it's kind of clear

00:39:56,749 --> 00:40:00,710
to see what happened so somebody broke

00:39:58,940 --> 00:40:04,249
something or did something stupid like

00:40:00,710 --> 00:40:08,539
we do and someone came along and fixed

00:40:04,249 --> 00:40:11,630
it things dropped off there was a bit of

00:40:08,539 --> 00:40:13,309
sort of you know you know stuff going on

00:40:11,630 --> 00:40:14,809
yeah and then you know another

00:40:13,309 --> 00:40:17,029
deployment could have kind of fixed it

00:40:14,809 --> 00:40:18,829
so we can correlate deployments do

00:40:17,029 --> 00:40:20,359
things in our log files and you know

00:40:18,829 --> 00:40:22,670
start to develop sort of patterns and

00:40:20,359 --> 00:40:24,950
things that way but really no metric

00:40:22,670 --> 00:40:27,559
from our log files log files contain all

00:40:24,950 --> 00:40:33,619
types of data so they are there are many

00:40:27,559 --> 00:40:36,170
possibilities the two tools i showed you

00:40:33,619 --> 00:40:37,759
are fairly well documented so using logs

00:40:36,170 --> 00:40:39,410
differs log stash I mean I've just given

00:40:37,759 --> 00:40:40,700
you some options which ever you sort of

00:40:39,410 --> 00:40:45,140
you know read and feel comfortable with

00:40:40,700 --> 00:40:47,059
using now go with that so another thing

00:40:45,140 --> 00:40:49,880
that's really cool about graphite is it

00:40:47,059 --> 00:40:51,980
has this render API and so you can click

00:40:49,880 --> 00:40:54,349
on a glove graph and you can go you're

00:40:51,980 --> 00:40:58,249
right click and you can say as get image

00:40:54,349 --> 00:40:59,900
URL and basically this actually outputs

00:40:58,249 --> 00:41:01,819
an image so you can see I'm saying give

00:40:59,900 --> 00:41:07,999
me the data for the last two hours until

00:41:01,819 --> 00:41:10,400
now make the graph 800 x 600 my target

00:41:07,999 --> 00:41:12,380
is my metric type and they're not just a

00:41:10,400 --> 00:41:16,789
title for the graph but this is really

00:41:12,380 --> 00:41:18,680
useful for building dashboards so you

00:41:16,789 --> 00:41:21,170
know you can drop that you're all into

00:41:18,680 --> 00:41:23,269
image source tag and build really nice

00:41:21,170 --> 00:41:24,710
dashboards or say for example you want

00:41:23,269 --> 00:41:26,630
to brag to you know one of your

00:41:24,710 --> 00:41:29,059
co-workers you've made something really

00:41:26,630 --> 00:41:30,499
fast you can send them a link and say

00:41:29,059 --> 00:41:31,819
you know check out check out much faster

00:41:30,499 --> 00:41:33,440
I made something and you you know

00:41:31,819 --> 00:41:35,749
actually get that graph and then see I

00:41:33,440 --> 00:41:37,099
even you know improve things but you

00:41:35,749 --> 00:41:39,799
know you can build really powerful

00:41:37,099 --> 00:41:41,089
dashboards and you know and that's

00:41:39,799 --> 00:41:43,339
something that's a key thing about

00:41:41,089 --> 00:41:45,140
DevOps is in measurement you know

00:41:43,339 --> 00:41:46,549
building these dashboards and you know

00:41:45,140 --> 00:41:48,079
dashboards that not only us as

00:41:46,549 --> 00:41:50,420
developers see but the wider business

00:41:48,079 --> 00:41:51,670
can see you know so you know how many

00:41:50,420 --> 00:41:53,559
orders you know

00:41:51,670 --> 00:41:54,790
have we got in today you know maybe

00:41:53,559 --> 00:41:56,559
you've got a line going up of that all

00:41:54,790 --> 00:41:57,730
or anything like that you know it's so

00:41:56,559 --> 00:42:00,400
you can build some really powerful

00:41:57,730 --> 00:42:03,970
dashboards so graphite also has this

00:42:00,400 --> 00:42:05,710
function library so a couple of

00:42:03,970 --> 00:42:07,569
functions yeah so the first is Timeship

00:42:05,710 --> 00:42:09,670
so you can use time shift to compare

00:42:07,569 --> 00:42:11,980
today's quantitative logins verse last

00:42:09,670 --> 00:42:14,049
week or maybe you're a startup and you

00:42:11,980 --> 00:42:16,270
want to compare you know the growth rate

00:42:14,049 --> 00:42:18,059
of a particular metric to the week

00:42:16,270 --> 00:42:20,920
before you can use time shift to do that

00:42:18,059 --> 00:42:22,540
as a percentage you can compare one

00:42:20,920 --> 00:42:25,299
metric as a percent of another so I've

00:42:22,540 --> 00:42:27,819
got failed logins over you know tempted

00:42:25,299 --> 00:42:29,170
logins and the graphite does have a

00:42:27,819 --> 00:42:30,549
powerful function library if I'm

00:42:29,170 --> 00:42:33,190
completely honest I haven't used all the

00:42:30,549 --> 00:42:36,339
functions but if you want to view or

00:42:33,190 --> 00:42:39,190
visualize your data in some way you

00:42:36,339 --> 00:42:41,500
probably could go about you know work in

00:42:39,190 --> 00:42:44,160
that art and it is also open source

00:42:41,500 --> 00:42:47,109
written in Python so if you wanted to

00:42:44,160 --> 00:42:48,250
hack a feature in there I haven't really

00:42:47,109 --> 00:42:50,220
looked at the source code but if you

00:42:48,250 --> 00:42:52,960
wanted to I guess you probably could and

00:42:50,220 --> 00:42:55,000
the graph ads you know the web pot and

00:42:52,960 --> 00:42:57,430
so you've kind of got these graphs that

00:42:55,000 --> 00:42:58,990
you can get on demand so the other

00:42:57,430 --> 00:43:01,839
important thing about stats d is that

00:42:58,990 --> 00:43:03,640
it's a pluggable system so most of these

00:43:01,839 --> 00:43:06,670
have literally cut and paste this from

00:43:03,640 --> 00:43:09,910
this link but it's got this a pluggable

00:43:06,670 --> 00:43:16,809
system which actually uses as noted NPM

00:43:09,910 --> 00:43:20,470
which is to plug in a module so I mean

00:43:16,809 --> 00:43:21,970
some examples of these one that Joe

00:43:20,470 --> 00:43:23,440
spoke bad knees talk last year was data

00:43:21,970 --> 00:43:25,420
dog so data dogs actually like

00:43:23,440 --> 00:43:26,920
monitoring as a service so if you didn't

00:43:25,420 --> 00:43:27,910
want to send your stuff to graphite and

00:43:26,920 --> 00:43:29,619
you wanted to use monitoring as a

00:43:27,910 --> 00:43:31,690
service you'd still your stats d but

00:43:29,619 --> 00:43:34,030
that would send you your your metrics to

00:43:31,690 --> 00:43:35,890
data dog and from what I've read of data

00:43:34,030 --> 00:43:38,290
dog is really powerful you can really

00:43:35,890 --> 00:43:39,730
build some you know nice dashboards and

00:43:38,290 --> 00:43:43,359
do some really cool things and you can

00:43:39,730 --> 00:43:44,890
also set up alerts inside data dog but

00:43:43,359 --> 00:43:46,299
you've got so many options here I mean

00:43:44,890 --> 00:43:49,599
you've also got stats Diaz of back-end

00:43:46,299 --> 00:43:52,329
because the actual figures for stats di

00:43:49,599 --> 00:43:57,339
think it can do something like it

00:43:52,329 --> 00:44:00,549
bottles out at about 42 to 45,000 matrix

00:43:57,339 --> 00:44:02,770
a second in the latest version but if

00:44:00,549 --> 00:44:04,119
you got a system you know and you're

00:44:02,770 --> 00:44:05,650
doing lots of matrix you might want to

00:44:04,119 --> 00:44:07,059
scale out

00:44:05,650 --> 00:44:09,190
stats d so what you'd have is you'd have

00:44:07,059 --> 00:44:11,380
a stats the instance and then you relay

00:44:09,190 --> 00:44:12,730
to other stats d instances but also I

00:44:11,380 --> 00:44:16,180
think that's the the plug-in that you

00:44:12,730 --> 00:44:17,559
use when you plug it into skyline might

00:44:16,180 --> 00:44:20,170
be able to correct me on that but

00:44:17,559 --> 00:44:22,420
libretto and ganglia or other graphing

00:44:20,170 --> 00:44:25,059
tools I think I haven't used those much

00:44:22,420 --> 00:44:26,440
but if you know you're using that system

00:44:25,059 --> 00:44:28,000
already in your company then you can

00:44:26,440 --> 00:44:31,839
maybe just plug stesti into that instead

00:44:28,000 --> 00:44:37,569
of graphite if it's got MongoDB there

00:44:31,839 --> 00:44:40,660
might see also quite a few options okay

00:44:37,569 --> 00:44:42,910
so that's it basically so I've taken you

00:44:40,660 --> 00:44:44,650
through using stats d and graphite

00:44:42,910 --> 00:44:47,650
gathering metrics the different metric

00:44:44,650 --> 00:44:49,599
types so just in Russia wrapping up you

00:44:47,650 --> 00:44:51,099
know measure all the things I think you

00:44:49,599 --> 00:44:53,470
know this time last year wasn't using

00:44:51,099 --> 00:44:55,630
application matrix and like I said you

00:44:53,470 --> 00:44:57,609
know once you use stats do to collect

00:44:55,630 --> 00:44:58,569
data and you Crawford with graphite you

00:44:57,609 --> 00:45:00,819
really will get a better understanding

00:44:58,569 --> 00:45:02,619
of your applications and once you've got

00:45:00,819 --> 00:45:08,500
that better understanding you can go

00:45:02,619 --> 00:45:11,559
about improving your applications ok so

00:45:08,500 --> 00:45:15,490
the next slide didn't come up the next

00:45:11,559 --> 00:45:18,490
slide had questions on it or just a

00:45:15,490 --> 00:45:21,910
slight but I think we've got some time

00:45:18,490 --> 00:45:23,559
for questions now nothing I wanted to

00:45:21,910 --> 00:45:26,849
mention i haven't done many conference

00:45:23,559 --> 00:45:29,710
talks so appreciate any feedback on

00:45:26,849 --> 00:45:33,309
joined in good or bad don't be too harsh

00:45:29,710 --> 00:45:37,980
and but but yeah I think that's it let

00:45:33,309 --> 00:45:37,980
me forget any questions and from anyone

00:45:38,460 --> 00:45:42,180
it's a question over there

00:45:43,970 --> 00:45:57,410
there's a question is it go over there

00:45:46,900 --> 00:46:00,920
get some of this water do you have a cup

00:45:57,410 --> 00:46:03,140
of estimated idea of when and when not

00:46:00,920 --> 00:46:05,150
to use it and if you clutter the whole

00:46:03,140 --> 00:46:07,190
ice code basically you can abstract it

00:46:05,150 --> 00:46:08,900
to a certain degree but if you're

00:46:07,190 --> 00:46:10,940
collecting too much information it does

00:46:08,900 --> 00:46:15,500
it make the application slow i

00:46:10,940 --> 00:46:19,640
appreciate asynchronous yeah it's a good

00:46:15,500 --> 00:46:22,430
question i guess it's just you get a

00:46:19,640 --> 00:46:24,200
feel for that over time really so if you

00:46:22,430 --> 00:46:26,480
do have a lot of code that's in making

00:46:24,200 --> 00:46:27,770
other code unreadable you could probably

00:46:26,480 --> 00:46:29,540
think about using something like that

00:46:27,770 --> 00:46:32,180
observer pattern to fire off the metrics

00:46:29,540 --> 00:46:34,369
so like an event-driven things so you

00:46:32,180 --> 00:46:37,880
don't have too much code clutter in

00:46:34,369 --> 00:46:40,369
terms of collecting too many metrics and

00:46:37,880 --> 00:46:44,869
the performance you know that that has

00:46:40,369 --> 00:46:48,080
on the system one performance tip is

00:46:44,869 --> 00:46:52,310
that when you connect to stats d don't

00:46:48,080 --> 00:46:54,980
connect to it by using the hostname use

00:46:52,310 --> 00:46:58,130
the IP address so then you save some

00:46:54,980 --> 00:47:00,200
time on a DNS lookup so that's one thing

00:46:58,130 --> 00:47:01,700
but if you're making this quick UDP

00:47:00,200 --> 00:47:04,220
connection if you think about the PHP

00:47:01,700 --> 00:47:06,589
you know model you know it's just

00:47:04,220 --> 00:47:08,930
executing from top like sort of Dan so

00:47:06,589 --> 00:47:10,099
if you make you know one quick quick

00:47:08,930 --> 00:47:11,570
connection then you fire off a whole

00:47:10,099 --> 00:47:16,070
bunch of packets I think the effect on

00:47:11,570 --> 00:47:17,240
your application is not that big yeah i

00:47:16,070 --> 00:47:18,530
think the benefit that you're going to

00:47:17,240 --> 00:47:20,720
get from this if there was a small

00:47:18,530 --> 00:47:22,430
knock-on effect you'd probably wouldn't

00:47:20,720 --> 00:47:24,530
want to worry about that too much but

00:47:22,430 --> 00:47:26,330
obviously you know this is the thing it

00:47:24,530 --> 00:47:27,380
depends on the application really

00:47:26,330 --> 00:47:31,609
because all the applications are

00:47:27,380 --> 00:47:35,359
different so the other thing you can do

00:47:31,609 --> 00:47:36,890
is you can do a sampling which I haven't

00:47:35,359 --> 00:47:38,930
given example of the library that the

00:47:36,890 --> 00:47:40,880
PHP client library I showed you doesn't

00:47:38,930 --> 00:47:44,690
support that but you can actually sample

00:47:40,880 --> 00:47:46,580
matrix so you can say only send ten

00:47:44,690 --> 00:47:48,710
percent of the data that I send only

00:47:46,580 --> 00:47:50,599
sent ten percent of it ten percent of it

00:47:48,710 --> 00:47:52,820
just adds d and if it's something that

00:47:50,599 --> 00:47:54,770
you can't really frequently you can say

00:47:52,820 --> 00:47:55,870
send more point not one percent of the

00:47:54,770 --> 00:47:58,220
data

00:47:55,870 --> 00:48:02,390
so does that aren't you a question yes

00:47:58,220 --> 00:48:08,690
thank you any more questions another

00:48:02,390 --> 00:48:11,650
question than the mall hello okay that's

00:48:08,690 --> 00:48:14,090
better we were talking about how you

00:48:11,650 --> 00:48:16,910
started out looking at metrics a year

00:48:14,090 --> 00:48:20,930
ago so one of the things I'm asking is

00:48:16,910 --> 00:48:22,610
that a lot of devs think that adding

00:48:20,930 --> 00:48:24,200
metrics sounds like a nice idea but we

00:48:22,610 --> 00:48:26,120
don't really have the time so just to

00:48:24,200 --> 00:48:27,920
really sell it was there anything you

00:48:26,120 --> 00:48:29,540
spotted as soon as you start tracking

00:48:27,920 --> 00:48:31,430
metrics that you wouldn't have figured

00:48:29,540 --> 00:48:34,030
out otherwise or at least you feel you

00:48:31,430 --> 00:48:37,490
wouldn't have figured out otherwise I

00:48:34,030 --> 00:48:39,020
guess to answer the question really

00:48:37,490 --> 00:48:41,060
simple is that you just feel sort of

00:48:39,020 --> 00:48:42,620
more in control you've got a better

00:48:41,060 --> 00:48:44,570
understanding straightaway of what's

00:48:42,620 --> 00:48:47,360
going on because i'm using the example

00:48:44,570 --> 00:48:51,740
of where was last year we we had lots of

00:48:47,360 --> 00:48:53,510
traffic and you know i did actually lose

00:48:51,740 --> 00:48:56,780
some sleep i was on a call for the

00:48:53,510 --> 00:48:58,610
application and you know once you've got

00:48:56,780 --> 00:49:00,020
metrics in place you just get a better

00:48:58,610 --> 00:49:02,210
understanding fulfilled so when you do a

00:49:00,020 --> 00:49:04,340
deployment you can see ok so in our

00:49:02,210 --> 00:49:08,020
application we had things like donations

00:49:04,340 --> 00:49:11,000
and you know lots of people registering

00:49:08,020 --> 00:49:13,940
so as long as people can still donate on

00:49:11,000 --> 00:49:16,160
the site as long as you know i can

00:49:13,940 --> 00:49:17,300
correlate that to and i can see what's

00:49:16,160 --> 00:49:19,670
going on with the payment providers you

00:49:17,300 --> 00:49:21,260
just gotta sort of better feeling an

00:49:19,670 --> 00:49:23,540
understanding i mean it's it's kind of

00:49:21,260 --> 00:49:26,030
hard to put into words but once you

00:49:23,540 --> 00:49:27,020
start doing it you definitely just feel

00:49:26,030 --> 00:49:28,160
more in control you've got a better

00:49:27,020 --> 00:49:31,460
understand you can go about improving

00:49:28,160 --> 00:49:33,140
things and con really explain splendid

00:49:31,460 --> 00:49:35,180
better really but i would say do it if

00:49:33,140 --> 00:49:36,740
you can i mean you know this is i spoke

00:49:35,180 --> 00:49:40,160
a bit about DevOps the professional

00:49:36,740 --> 00:49:41,720
culture and movement but you know any

00:49:40,160 --> 00:49:43,430
question you can ask like you know how

00:49:41,720 --> 00:49:44,720
many emails have we sent or you know how

00:49:43,430 --> 00:49:46,070
many times did something happen you know

00:49:44,720 --> 00:49:47,960
if someone's got a business question you

00:49:46,070 --> 00:49:49,130
can answer it really quickly won a lot

00:49:47,960 --> 00:49:51,260
of code you can count it or you can

00:49:49,130 --> 00:49:53,180
start timing something so you know we

00:49:51,260 --> 00:49:54,860
also had things where you know we had

00:49:53,180 --> 00:49:56,960
payment providers we had bullpen will

00:49:54,860 --> 00:49:58,430
pay and I don't know how much you guys

00:49:56,960 --> 00:50:00,620
have work with payment providers but you

00:49:58,430 --> 00:50:03,590
know generally with a payment provider

00:50:00,620 --> 00:50:04,850
you have a AP and call back so you send

00:50:03,590 --> 00:50:06,200
someone to like the payment provider

00:50:04,850 --> 00:50:07,610
that make the payment and then that

00:50:06,200 --> 00:50:09,530
payment provider makes a call back to

00:50:07,610 --> 00:50:11,060
your system so you can start

00:50:09,530 --> 00:50:12,920
correlate like how many people that I

00:50:11,060 --> 00:50:15,680
sent the payment provider and how many

00:50:12,920 --> 00:50:17,270
people you know came back because only

00:50:15,680 --> 00:50:20,270
one someone's paid is it like a auto

00:50:17,270 --> 00:50:21,920
complete and in our instance we actually

00:50:20,270 --> 00:50:24,200
had an issue where it actually turned

00:50:21,920 --> 00:50:25,820
out to be a network issue but the

00:50:24,200 --> 00:50:27,830
problem was is that if we didn't get

00:50:25,820 --> 00:50:29,690
that I pain call back successfully the

00:50:27,830 --> 00:50:31,100
order didn't get completed which means

00:50:29,690 --> 00:50:32,900
people didn't get like a registration

00:50:31,100 --> 00:50:35,300
pack and it caused quite a bit of issues

00:50:32,900 --> 00:50:37,130
and you know because it was service

00:50:35,300 --> 00:50:40,610
orientated architecture we had all these

00:50:37,130 --> 00:50:42,140
different birds but actually you know

00:50:40,610 --> 00:50:44,270
getting that art and graph and it was

00:50:42,140 --> 00:50:46,810
you know fairly simple and you just just

00:50:44,270 --> 00:50:53,090
feel but you know woman fuzzy inside sir

00:50:46,810 --> 00:50:55,510
cool okay cool there's some question

00:50:53,090 --> 00:50:55,510
over there

00:51:05,780 --> 00:51:13,200
there's another microvia how much I

00:51:10,200 --> 00:51:17,070
think we've got a bad I think we got

00:51:13,200 --> 00:51:19,550
about five minutes left so see if I

00:51:17,070 --> 00:51:24,090
would yeah okay that definitely works

00:51:19,550 --> 00:51:25,890
right either of the box or via some

00:51:24,090 --> 00:51:30,090
plug-in is there any way stats that you

00:51:25,890 --> 00:51:32,730
can take system Lord stats and you know

00:51:30,090 --> 00:51:35,040
CPU memory because too to be honest to

00:51:32,730 --> 00:51:37,440
be all to be able to overlay that with

00:51:35,040 --> 00:51:40,290
metrics that we you know we have record

00:51:37,440 --> 00:51:42,990
will be massively massively powerful to

00:51:40,290 --> 00:51:45,240
see whether the bottleneck would be into

00:51:42,990 --> 00:51:46,860
show capacity and you know to be able to

00:51:45,240 --> 00:51:48,930
explain to your boss how much you know

00:51:46,860 --> 00:51:51,360
yeah sure yeah so much you'd have to

00:51:48,930 --> 00:51:53,370
invest to satisfy so many users like

00:51:51,360 --> 00:51:55,380
kind of thing yeah you can't you can do

00:51:53,370 --> 00:51:57,960
that I don't know how many people have

00:51:55,380 --> 00:52:02,390
used sensor as a monitoring system but

00:51:57,960 --> 00:52:05,640
sends you by default users graphite and

00:52:02,390 --> 00:52:09,960
you can write your own custom checks but

00:52:05,640 --> 00:52:11,940
you were with Sen su you can output data

00:52:09,960 --> 00:52:15,090
it actually upwards data to graphite so

00:52:11,940 --> 00:52:16,770
you'd be able to correlate cpu to you

00:52:15,090 --> 00:52:21,450
know certain things within your system

00:52:16,770 --> 00:52:26,400
so you does it on to your question set

00:52:21,450 --> 00:52:29,100
sensor yeah so since use the monitoring

00:52:26,400 --> 00:52:32,880
package and so since we will put your

00:52:29,100 --> 00:52:34,740
your data like memory usage cpu usage

00:52:32,880 --> 00:52:38,280
and those kind of things into graphite

00:52:34,740 --> 00:52:39,870
graphs and then you can use that same

00:52:38,280 --> 00:52:41,070
graphite instance to get metrics from

00:52:39,870 --> 00:52:43,170
status t and then you could correlate

00:52:41,070 --> 00:52:47,130
them to one another so that is possible

00:52:43,170 --> 00:52:53,070
it does it on to your question I st.

00:52:47,130 --> 00:52:57,150
suace en su it's also open source yeah

00:52:53,070 --> 00:52:58,140
it's written in Ruby though but I think

00:52:57,150 --> 00:52:59,700
you can't actually you can write custom

00:52:58,140 --> 00:53:03,810
checks that you can write custom checks

00:52:59,700 --> 00:53:07,050
in PHP I think one of to another

00:53:03,810 --> 00:53:09,210
question yeah other in your examples

00:53:07,050 --> 00:53:10,609
everything was so being logged to a

00:53:09,210 --> 00:53:13,880
local

00:53:10,609 --> 00:53:16,400
server how how exactly do you get that

00:53:13,880 --> 00:53:20,630
data away from your servers sort of like

00:53:16,400 --> 00:53:22,160
to your office or something do you know

00:53:20,630 --> 00:53:25,339
I mean I'm not exactly sure what you

00:53:22,160 --> 00:53:29,690
mean so in your example you're logging

00:53:25,339 --> 00:53:32,089
everything to localhost yeah and say for

00:53:29,690 --> 00:53:33,739
example I've got server farm and like

00:53:32,089 --> 00:53:35,749
five service or something yeah or

00:53:33,739 --> 00:53:38,599
logging to localhost how does how does

00:53:35,749 --> 00:53:41,420
all that data then get back to to me

00:53:38,599 --> 00:53:46,039
yeah sure so my examples are using a

00:53:41,420 --> 00:53:47,960
local host but their stats d so let's go

00:53:46,039 --> 00:53:51,619
back first estas t so the stats d

00:53:47,960 --> 00:53:53,569
configuration file when you make a

00:53:51,619 --> 00:53:55,009
connection from the stats d PHP client

00:53:53,569 --> 00:53:56,720
library you can connect to any IP

00:53:55,009 --> 00:54:00,019
address so that IP address could be in

00:53:56,720 --> 00:54:02,630
amazon or whatever and then from stats d

00:54:00,019 --> 00:54:03,650
to that goes to graphite that could be

00:54:02,630 --> 00:54:06,980
in another house and that's also

00:54:03,650 --> 00:54:08,630
configurable by IP address does it want

00:54:06,980 --> 00:54:10,369
you a question yet yeah okay so that

00:54:08,630 --> 00:54:13,970
brings me on to my next question okay

00:54:10,369 --> 00:54:15,710
which is that that's fine but what about

00:54:13,970 --> 00:54:20,180
authentication because obviously using

00:54:15,710 --> 00:54:25,099
UDP so yeah that's a good point yeah and

00:54:20,180 --> 00:54:27,230
I don't want to be sending all this data

00:54:25,099 --> 00:54:30,380
some yeah of course awning unencrypted

00:54:27,230 --> 00:54:33,589
so let's take an example of AWS for

00:54:30,380 --> 00:54:37,730
example so in AWS you can set up a

00:54:33,589 --> 00:54:39,650
virtual private cloud so you could set

00:54:37,730 --> 00:54:41,239
up that sort of stats d and graphite

00:54:39,650 --> 00:54:44,119
instance in that virtual private cloud

00:54:41,239 --> 00:54:46,009
and then you know that traffic would

00:54:44,119 --> 00:54:47,150
still only be going over that black sort

00:54:46,009 --> 00:54:51,529
of network if you needed that for

00:54:47,150 --> 00:54:52,730
security reasons and so you know I mean

00:54:51,529 --> 00:54:54,950
you can go read up on I mean that's an

00:54:52,730 --> 00:54:56,119
example there it does so you could you

00:54:54,950 --> 00:54:58,339
could secure it like that so you're not

00:54:56,119 --> 00:55:01,150
actually sending it out over sort of a

00:54:58,339 --> 00:55:03,829
wider area because v pcs are quite I

00:55:01,150 --> 00:55:05,480
mean you can go read the security white

00:55:03,829 --> 00:55:07,279
paper from amazon it's quite clear I

00:55:05,480 --> 00:55:09,230
think you've actually got a segregated

00:55:07,279 --> 00:55:11,960
part of their network so nobody else can

00:55:09,230 --> 00:55:17,269
actually snuff the packets that's cool

00:55:11,960 --> 00:55:18,769
thanks okay I mean that was that was an

00:55:17,269 --> 00:55:20,509
example various I guess you could get

00:55:18,769 --> 00:55:22,030
that in other hosting providers sort of

00:55:20,509 --> 00:55:27,890
your virtual sort of

00:55:22,030 --> 00:55:29,990
area another question I think you put it

00:55:27,890 --> 00:55:32,150
on this slide but and there was a slide

00:55:29,990 --> 00:55:33,470
where you've got the steps going up and

00:55:32,150 --> 00:55:35,240
down and then you've got some vertical

00:55:33,470 --> 00:55:37,329
lines showing the deploys and I'm

00:55:35,240 --> 00:55:39,740
guessing you've put that on to show us

00:55:37,329 --> 00:55:41,720
is there a way to automatically put

00:55:39,740 --> 00:55:44,119
those on like with your deployment

00:55:41,720 --> 00:55:46,880
script could you make a line go into the

00:55:44,119 --> 00:55:49,130
stairs yes I did give an example so some

00:55:46,880 --> 00:55:50,930
deployment tools have a plug-in but for

00:55:49,130 --> 00:55:53,599
a counter metric in graphite you use the

00:55:50,930 --> 00:55:55,849
drawers in finite function and it's just

00:55:53,599 --> 00:55:58,549
a simple bash command that'll actually

00:55:55,849 --> 00:56:00,079
then put the line like in a graph but

00:55:58,549 --> 00:56:02,299
then you need to correlate that graph to

00:56:00,079 --> 00:56:04,910
the other metric so it was the function

00:56:02,299 --> 00:56:06,260
code it's troy as in finite my slides

00:56:04,910 --> 00:56:07,460
will be online later so we can chat

00:56:06,260 --> 00:56:09,020
about it off it's too but it's the

00:56:07,460 --> 00:56:11,450
functioning in graph our destroyers in

00:56:09,020 --> 00:56:13,400
finite and then you need a counter

00:56:11,450 --> 00:56:14,720
matric to count that event and then you

00:56:13,400 --> 00:56:17,540
control those vertical lines but you

00:56:14,720 --> 00:56:18,890
could draw any counter metric you can

00:56:17,540 --> 00:56:21,410
draws that vertical line so you could

00:56:18,890 --> 00:56:25,609
sort of track any event perfect thank

00:56:21,410 --> 00:56:28,280
you ok sure that other think we I'm not

00:56:25,609 --> 00:56:29,450
sure one more question ok sure I think

00:56:28,280 --> 00:56:34,280
we've got a bit of a break off there so

00:56:29,450 --> 00:56:35,900
if we run over it's not hi um you

00:56:34,280 --> 00:56:37,339
certainly won't have any problems

00:56:35,900 --> 00:56:39,200
selling it to me I mean the overall idea

00:56:37,339 --> 00:56:41,720
is great the only question i'm thinking

00:56:39,200 --> 00:56:43,940
is a do you have you come across any

00:56:41,720 --> 00:56:45,859
obstacles implementing it I mean

00:56:43,940 --> 00:56:47,540
obviously in a new application that

00:56:45,859 --> 00:56:49,670
won't be an issue but in existing

00:56:47,540 --> 00:56:51,829
applications like did you come across

00:56:49,670 --> 00:56:54,170
anything there was a pitfall or anything

00:56:51,829 --> 00:56:55,640
like that or was it just easy yeah I

00:56:54,170 --> 00:56:56,599
mean I think it's you know some of the

00:56:55,640 --> 00:56:59,180
things that's why I shuttle the

00:56:56,599 --> 00:57:02,359
configuration files so things to think

00:56:59,180 --> 00:57:03,950
about if you just starting art like i

00:57:02,359 --> 00:57:07,940
showed the storage schemas with three

00:57:03,950 --> 00:57:09,440
retention rates it is a bit weird when

00:57:07,940 --> 00:57:10,640
you first look at the graphs like there

00:57:09,440 --> 00:57:12,349
is a bit of a learning curve there so

00:57:10,640 --> 00:57:14,589
what you could potentially do is in your

00:57:12,349 --> 00:57:17,510
storage configuration you could say

00:57:14,589 --> 00:57:19,250
store just one minute data for seven

00:57:17,510 --> 00:57:20,990
days for example and then change your

00:57:19,250 --> 00:57:24,490
flush interval and graphite to 60

00:57:20,990 --> 00:57:26,359
seconds so you have one minute data I

00:57:24,490 --> 00:57:27,920
mean there's a learning curve with it

00:57:26,359 --> 00:57:29,750
within anything a couple of years ago

00:57:27,920 --> 00:57:31,490
like three or four years ago someone

00:57:29,750 --> 00:57:33,230
chucked me onto a Drupal project and

00:57:31,490 --> 00:57:35,220
I've been doing PHP for like five or six

00:57:33,230 --> 00:57:37,320
years matalan Drupal

00:57:35,220 --> 00:57:39,119
was like what the whole you know so I

00:57:37,320 --> 00:57:40,500
think you know the learning curve of

00:57:39,119 --> 00:57:42,060
Drupal is quite steep not maybe such a

00:57:40,500 --> 00:57:44,010
great example but there is a bit of a

00:57:42,060 --> 00:57:46,109
learning curve and you know there are

00:57:44,010 --> 00:57:48,180
some obstacles i think my slides give

00:57:46,109 --> 00:57:49,580
some basic examples so for me it's all

00:57:48,180 --> 00:57:51,900
about you know get it up and running

00:57:49,580 --> 00:57:54,180
maybe in a vagrant sort of like

00:57:51,900 --> 00:57:56,099
environment you know mess around with

00:57:54,180 --> 00:57:58,580
and then sort of you know prototype it

00:57:56,099 --> 00:58:00,869
and then sort of take it further I mean

00:57:58,580 --> 00:58:03,780
the idea that I like about this is that

00:58:00,869 --> 00:58:05,599
you know if you think of like Zen

00:58:03,780 --> 00:58:07,920
framework or Symphony framework

00:58:05,599 --> 00:58:09,180
wordpress drupal whatever your PHP

00:58:07,920 --> 00:58:11,190
application you could get a metric on

00:58:09,180 --> 00:58:13,020
just about anything in any applications

00:58:11,190 --> 00:58:14,520
i think you know like the question

00:58:13,020 --> 00:58:16,470
earlier is you know all of a sudden you

00:58:14,520 --> 00:58:17,580
might see a lot of like timing sort of

00:58:16,470 --> 00:58:19,800
thing so you might want to do something

00:58:17,580 --> 00:58:22,560
like the reserve a pattern or something

00:58:19,800 --> 00:58:24,119
like that but nothing i can think of now

00:58:22,560 --> 00:58:26,010
but if i come up with something maybe

00:58:24,119 --> 00:58:30,570
chat about it but i want you a question

00:58:26,010 --> 00:58:33,900
I think yeah cool okay so we're at a

00:58:30,570 --> 00:58:35,250
time so I Mia the rest of the day hang

00:58:33,900 --> 00:58:36,270
around for a bureau to tonight and I me

00:58:35,250 --> 00:58:38,849
out tomorrow so if you have any

00:58:36,270 --> 00:58:41,160
questions or anything you want to run by

00:58:38,849 --> 00:58:44,390
me please do and any feedback and joined

00:58:41,160 --> 00:58:44,390

YouTube URL: https://www.youtube.com/watch?v=parmTnIr3gE


