Title: PHP UK Conference 2013 - Kenny Gryp - Resolving MySQL Problems Quickly
Publication date: 2013-05-15
Playlist: PHP UK Conference 2013
Description: 
	Troubleshooting MySQL doesn't need to involve trial-and-error, and it doesn't need to take a long time. You need only two things: a good process and good tools. This session will show you an approach that the speaker has used to solve many frustrating problems quickly, and open source tools that assist this process. The tools especially include key tools from Percona Toolkit.
Captions: 
	00:00:07,140 --> 00:00:12,969
okay good afternoon um first one when

00:00:11,650 --> 00:00:15,430
you're coming down I put some stickers

00:00:12,969 --> 00:00:17,260
there so feel free to take them I've got

00:00:15,430 --> 00:00:20,200
plenty of stuff to share with everybody

00:00:17,260 --> 00:00:23,760
so please ask questions and then you get

00:00:20,200 --> 00:00:27,100
a t-shirt or maybe a book I don't know

00:00:23,760 --> 00:00:29,740
okay so I can hear myself it's kind of

00:00:27,100 --> 00:00:32,129
strange anyway um expert troubleshooting

00:00:29,740 --> 00:00:35,590
so I'm going to talk about some things

00:00:32,129 --> 00:00:38,290
on troubleshooting with MySQL this is

00:00:35,590 --> 00:00:40,239
like the table of contents so I'll talk

00:00:38,290 --> 00:00:41,949
a little bit about problems for types of

00:00:40,239 --> 00:00:44,760
problems and what the problem is with

00:00:41,949 --> 00:00:46,720
problems I'll talk a little bit about

00:00:44,760 --> 00:00:49,360
instrumentation different ways of

00:00:46,720 --> 00:00:50,890
instrumenting for my squirrel but also a

00:00:49,360 --> 00:00:52,900
little bit more general about different

00:00:50,890 --> 00:00:56,199
aspects like response time capacity

00:00:52,900 --> 00:00:57,909
things like that then I'll go into tree

00:00:56,199 --> 00:01:00,610
different types of troubleshooting that

00:00:57,909 --> 00:01:02,890
we often have to do in pro kona as part

00:01:00,610 --> 00:01:05,470
of our consulting business is individual

00:01:02,890 --> 00:01:07,270
slow query troubleshooting seeing how we

00:01:05,470 --> 00:01:09,400
can optimize individual queries and

00:01:07,270 --> 00:01:12,820
global performance problems sometimes

00:01:09,400 --> 00:01:15,369
you have just the slow server because of

00:01:12,820 --> 00:01:17,140
some reason and a very interesting one

00:01:15,369 --> 00:01:19,210
is the intermittent performance problems

00:01:17,140 --> 00:01:21,070
so performance problems that happen at

00:01:19,210 --> 00:01:23,469
very random times for a very brief

00:01:21,070 --> 00:01:26,229
amount of time sometimes that's really a

00:01:23,469 --> 00:01:27,909
problem for some applications costs a

00:01:26,229 --> 00:01:29,590
lot of money so there's a it's difficult

00:01:27,909 --> 00:01:32,380
to troubleshoot but i'll show you some

00:01:29,590 --> 00:01:33,969
tools on how you can actually yeah get

00:01:32,380 --> 00:01:36,960
more insight in that and try to find a

00:01:33,969 --> 00:01:44,499
solution for it i'll use this thing here

00:01:36,960 --> 00:01:46,210
okay so the problem so the thing i see a

00:01:44,499 --> 00:01:48,460
lot is is when when some of our

00:01:46,210 --> 00:01:50,289
customers come to us they say I hey I've

00:01:48,460 --> 00:01:53,619
got a problem what what's the problem

00:01:50,289 --> 00:01:55,329
here so usually we say like we hear

00:01:53,619 --> 00:01:57,399
things like hate the website is down or

00:01:55,329 --> 00:01:59,560
the database doesn't work anymore and

00:01:57,399 --> 00:02:03,310
then it's like sometimes it's like

00:01:59,560 --> 00:02:06,729
really what what's wrong I mean what's

00:02:03,310 --> 00:02:08,920
really going on here and and and usually

00:02:06,729 --> 00:02:12,460
the information that we get from people

00:02:08,920 --> 00:02:15,400
is kinda yeah scarce or maybe not really

00:02:12,460 --> 00:02:17,230
what the real problem is so if the most

00:02:15,400 --> 00:02:19,910
important thing here is is it's hard to

00:02:17,230 --> 00:02:22,340
find out what really the problem is and

00:02:19,910 --> 00:02:24,110
in this case yeah I can't login that's

00:02:22,340 --> 00:02:26,620
that's one example and go and I'll show

00:02:24,110 --> 00:02:29,300
you some more about it a little later on

00:02:26,620 --> 00:02:32,020
another one is we hear is like Tom

00:02:29,300 --> 00:02:35,510
doesn't respond anymore how do you know

00:02:32,020 --> 00:02:37,610
I've had several discussions with some

00:02:35,510 --> 00:02:38,780
of my friends on IRC like they have some

00:02:37,610 --> 00:02:41,200
problems and then we try to troubleshoot

00:02:38,780 --> 00:02:43,790
it just for fun and we try to help them

00:02:41,200 --> 00:02:45,050
and and then it's like okay how do you

00:02:43,790 --> 00:02:47,690
know that Tom car doesn't work anymore

00:02:45,050 --> 00:02:50,090
because I don't know did you check the

00:02:47,690 --> 00:02:53,300
error logs I didn't did you have so many

00:02:50,090 --> 00:02:54,470
money drinks nope so there's a lot of

00:02:53,300 --> 00:02:56,420
times we don't have the right

00:02:54,470 --> 00:02:58,370
instrumentation the right tools that

00:02:56,420 --> 00:03:00,590
right data to actually find out what is

00:02:58,370 --> 00:03:03,290
really going on is there something going

00:03:00,590 --> 00:03:05,030
on is there any change of behavior with

00:03:03,290 --> 00:03:07,640
compared to things that were happening

00:03:05,030 --> 00:03:11,930
and yeah just before the problem happens

00:03:07,640 --> 00:03:14,630
things like that also another problem is

00:03:11,930 --> 00:03:16,580
is guessing sometimes they say okay

00:03:14,630 --> 00:03:19,130
we're this is a tomcat example here I

00:03:16,580 --> 00:03:20,630
like to use Tomcat as an example it's

00:03:19,130 --> 00:03:25,850
probably something to do with the

00:03:20,630 --> 00:03:29,840
connection pool okay why kind of a

00:03:25,850 --> 00:03:32,300
problem so the thing is is finding out

00:03:29,840 --> 00:03:37,400
the real problem it's hard what's really

00:03:32,300 --> 00:03:39,920
going on the problem with those

00:03:37,400 --> 00:03:42,470
definitions about these things is that

00:03:39,920 --> 00:03:44,300
we kind of limit ourselves when we talk

00:03:42,470 --> 00:03:49,520
about some problem with a customer we

00:03:44,300 --> 00:03:51,500
try to yet not try to listen to what

00:03:49,520 --> 00:03:53,810
they actually already think is going on

00:03:51,500 --> 00:03:56,030
when they say hey it's probably tomcat

00:03:53,810 --> 00:03:58,790
connection pooling we try to say hey

00:03:56,030 --> 00:04:00,650
that's not not not something that we

00:03:58,790 --> 00:04:01,850
want to hear we want to know what do you

00:04:00,650 --> 00:04:05,209
see what do you what is the application

00:04:01,850 --> 00:04:07,700
how is it behaving because otherwise we

00:04:05,209 --> 00:04:09,290
kind of limit and we our area focus we

00:04:07,700 --> 00:04:10,940
kind of narrow down the vision that we

00:04:09,290 --> 00:04:12,950
have and we kind of only focus on

00:04:10,940 --> 00:04:14,209
connection pooling then but there's like

00:04:12,950 --> 00:04:15,500
no real indication that there's

00:04:14,209 --> 00:04:19,520
something going wrong with connection

00:04:15,500 --> 00:04:21,410
pooling so the lesson number one is

00:04:19,520 --> 00:04:24,890
don't trust anybody including yourself

00:04:21,410 --> 00:04:27,050
and guessing is also kind of lying to

00:04:24,890 --> 00:04:28,360
yourself so that that's an important

00:04:27,050 --> 00:04:32,830
lesson that I've heard

00:04:28,360 --> 00:04:34,629
over the last couple of years so we're

00:04:32,830 --> 00:04:37,060
talking all about measuring an

00:04:34,629 --> 00:04:40,569
instrumentation here so you've got to

00:04:37,060 --> 00:04:42,490
measure like a boss so instrumentation

00:04:40,569 --> 00:04:45,629
very important there were some talks

00:04:42,490 --> 00:04:47,500
yesterday about instrumentation as well

00:04:45,629 --> 00:04:50,979
sorry about that I need to drink

00:04:47,500 --> 00:04:52,750
sometimes so it's the branch of

00:04:50,979 --> 00:04:55,449
mechanical engineering that deals with

00:04:52,750 --> 00:04:57,310
measurement and control so one famous

00:04:55,449 --> 00:04:59,469
quote here is you can't control what you

00:04:57,310 --> 00:05:00,789
can't measure so that's a very important

00:04:59,469 --> 00:05:03,129
thing we need to measure we need to have

00:05:00,789 --> 00:05:05,259
the metrics we need to know all kinds of

00:05:03,129 --> 00:05:09,069
things the example here is try to use

00:05:05,259 --> 00:05:13,180
this can you see that the laser not

00:05:09,069 --> 00:05:15,550
really okay so if we look at a car we

00:05:13,180 --> 00:05:19,900
all know how fast is our car going how

00:05:15,550 --> 00:05:22,539
far did I go since I last got some new

00:05:19,900 --> 00:05:24,490
gas how much fuel am I consuming these

00:05:22,539 --> 00:05:26,259
are all kinds of metrics that we have

00:05:24,490 --> 00:05:27,909
and we should have that any our

00:05:26,259 --> 00:05:30,610
application as well but also in our

00:05:27,909 --> 00:05:35,259
database and very important to be able

00:05:30,610 --> 00:05:37,870
to understand the real problem so why do

00:05:35,259 --> 00:05:41,620
we need to instrument in a lot of cases

00:05:37,870 --> 00:05:43,210
there's a a guess and that guest I said

00:05:41,620 --> 00:05:45,879
you're kind of lying to yourself but in

00:05:43,210 --> 00:05:48,580
many ways you're right you probably are

00:05:45,879 --> 00:05:51,129
experienced in that area so you might

00:05:48,580 --> 00:05:53,469
think that this is the problem and maybe

00:05:51,129 --> 00:05:56,259
you're right most of the time the

00:05:53,469 --> 00:05:59,319
example of like logging is slow so we've

00:05:56,259 --> 00:06:00,879
got logging on a website takes 15

00:05:59,319 --> 00:06:03,539
seconds so we've gots a bunch of web

00:06:00,879 --> 00:06:06,250
service and we've got a mysql database

00:06:03,539 --> 00:06:09,460
okay so where do you think the problem

00:06:06,250 --> 00:06:11,770
would be the first guess always is its

00:06:09,460 --> 00:06:13,360
mysql there's only my one my SQL box so

00:06:11,770 --> 00:06:14,770
can't be the web servers you know

00:06:13,360 --> 00:06:17,889
there's many of them it scales and

00:06:14,770 --> 00:06:21,039
everything so okay you're thinking the

00:06:17,889 --> 00:06:22,990
database probably right there's a lot of

00:06:21,039 --> 00:06:27,939
challenges with databases compared to

00:06:22,990 --> 00:06:29,319
applications so yeah we're good but we

00:06:27,939 --> 00:06:35,180
kind of need to know what's going on

00:06:29,319 --> 00:06:37,610
here so proving important thing that

00:06:35,180 --> 00:06:39,949
we don't often see in applications is

00:06:37,610 --> 00:06:42,380
that you try to need to monitor

00:06:39,949 --> 00:06:43,970
instrument what your application is

00:06:42,380 --> 00:06:46,100
doing how much time it is spending at

00:06:43,970 --> 00:06:48,110
various types of tasks i think it's

00:06:46,100 --> 00:06:51,740
doing and one way to represent this is

00:06:48,110 --> 00:06:53,750
for showing afro like this so where you

00:06:51,740 --> 00:06:55,729
got submitted a login form and that's

00:06:53,750 --> 00:06:58,039
the amount of time that it takes so it's

00:06:55,729 --> 00:06:59,660
a sequence diagram so this only takes a

00:06:58,039 --> 00:07:02,539
small part so checking if the user

00:06:59,660 --> 00:07:04,520
exists goes really fast but somehow we

00:07:02,539 --> 00:07:06,080
kind of update the last login date of a

00:07:04,520 --> 00:07:09,229
user and that seems to take a lot of

00:07:06,080 --> 00:07:11,900
time so by having some kind of

00:07:09,229 --> 00:07:13,280
instrumentation like this it's I don't

00:07:11,900 --> 00:07:15,410
know it's not easy to make something

00:07:13,280 --> 00:07:18,400
like this in your application server but

00:07:15,410 --> 00:07:20,060
at least knowing at which stages of your

00:07:18,400 --> 00:07:21,949
application or your complete

00:07:20,060 --> 00:07:24,770
architecture it is spending time on how

00:07:21,949 --> 00:07:26,720
much time you kind of can figure out ok

00:07:24,770 --> 00:07:28,490
we spent most time here so if we want to

00:07:26,720 --> 00:07:29,900
make things faster or if you want to fix

00:07:28,490 --> 00:07:33,110
our solution it's probably something to

00:07:29,900 --> 00:07:35,780
do with updating the last login date ok

00:07:33,110 --> 00:07:38,440
so that takes a lot of time so why are

00:07:35,780 --> 00:07:40,970
why is law it why is this taking so long

00:07:38,440 --> 00:07:44,300
so this is the query that's being used

00:07:40,970 --> 00:07:46,940
so we're updating users and we said the

00:07:44,300 --> 00:07:50,599
last login date to now where ID so user

00:07:46,940 --> 00:07:53,000
ID so a very simple thing yeah probably

00:07:50,599 --> 00:07:55,699
very easy one ID is probably primary key

00:07:53,000 --> 00:07:59,960
so there should not be a table scan here

00:07:55,699 --> 00:08:01,250
so it should be pretty fast schema is

00:07:59,960 --> 00:08:03,470
also very very simple very

00:08:01,250 --> 00:08:05,449
straightforward so we've got ID primary

00:08:03,470 --> 00:08:07,150
key a lot of cons and we've got last

00:08:05,449 --> 00:08:09,770
login date which is one of the columns

00:08:07,150 --> 00:08:12,139
now if you do show full process list

00:08:09,770 --> 00:08:14,990
what we see is an it's a little hard to

00:08:12,139 --> 00:08:17,150
actually read but we can see that the

00:08:14,990 --> 00:08:19,159
second query is the one that is updating

00:08:17,150 --> 00:08:21,590
the users and setting a last login date

00:08:19,159 --> 00:08:23,240
for one particular users and all the

00:08:21,590 --> 00:08:25,729
other users are actually locked they're

00:08:23,240 --> 00:08:28,220
waiting waiting until the other one

00:08:25,729 --> 00:08:30,169
completes so in this case it's using my

00:08:28,220 --> 00:08:33,740
eyes m and my isaam has stable level

00:08:30,169 --> 00:08:35,479
locking and you can only write one one

00:08:33,740 --> 00:08:37,909
query at the same time so only one right

00:08:35,479 --> 00:08:40,159
can happen at the same time so that kind

00:08:37,909 --> 00:08:42,529
of yeah is a kind of a problem but you

00:08:40,159 --> 00:08:43,760
can see that this takes two seconds so

00:08:42,529 --> 00:08:45,829
this is the time that the query is

00:08:43,760 --> 00:08:47,720
running so two seconds is quite a lot to

00:08:45,829 --> 00:08:53,000
just update that small column

00:08:47,720 --> 00:08:55,610
why is that so here we understand that

00:08:53,000 --> 00:08:59,870
we can see by running show process list

00:08:55,610 --> 00:09:02,209
that this is causing a problem if we

00:08:59,870 --> 00:09:04,939
would like just look at general metrics

00:09:02,209 --> 00:09:07,970
like uptime load cpu usage we could see

00:09:04,939 --> 00:09:10,129
like okay load is 0 dot 88 it doesn't

00:09:07,970 --> 00:09:11,509
mean that even though there's a lot of

00:09:10,129 --> 00:09:13,550
things going on here and a lot of

00:09:11,509 --> 00:09:15,769
locking and I love waiting here doesn't

00:09:13,550 --> 00:09:18,800
mean that cpu must be like one hundred

00:09:15,769 --> 00:09:20,810
percent use Lotus very low here so by

00:09:18,800 --> 00:09:23,540
looking at global metrics you don't

00:09:20,810 --> 00:09:25,250
always get the information you need or

00:09:23,540 --> 00:09:27,050
you don't always see that yeah the

00:09:25,250 --> 00:09:28,879
problem is not in the database because

00:09:27,050 --> 00:09:31,990
there's no cpu load that does not always

00:09:28,879 --> 00:09:34,850
true in many cases is it it is not

00:09:31,990 --> 00:09:37,009
another thing we could do is we could do

00:09:34,850 --> 00:09:38,569
show global status like slow query see

00:09:37,009 --> 00:09:40,430
how many slow queries we had over a

00:09:38,569 --> 00:09:42,019
certain amount of time and we can see

00:09:40,430 --> 00:09:44,120
that there were only three slow queries

00:09:42,019 --> 00:09:48,259
since that was since the start of the

00:09:44,120 --> 00:09:50,720
mysql database however slow queries by

00:09:48,259 --> 00:09:53,420
itself we're configured long query time

00:09:50,720 --> 00:09:55,220
set to one second so you could assume

00:09:53,420 --> 00:09:57,980
that if it takes longer than one second

00:09:55,220 --> 00:10:00,079
it should be a slow query but that's not

00:09:57,980 --> 00:10:01,939
true because lock time as we can see

00:10:00,079 --> 00:10:03,740
here they're all locked that time

00:10:01,939 --> 00:10:06,620
doesn't count for this long query time

00:10:03,740 --> 00:10:09,709
so another problem another thing that

00:10:06,620 --> 00:10:13,639
you have to know about how mysql looks

00:10:09,709 --> 00:10:17,209
at that okay so some problems Duncan

00:10:13,639 --> 00:10:19,910
went come with load so utilization rate

00:10:17,209 --> 00:10:23,449
CPU disk i/o that doesn't always show

00:10:19,910 --> 00:10:25,730
you what the real problem is so just

00:10:23,449 --> 00:10:27,649
don't guess I'll third time I said it

00:10:25,730 --> 00:10:30,470
I'll keep on saying it don't guess try

00:10:27,649 --> 00:10:33,290
to prove it very important it actually

00:10:30,470 --> 00:10:35,329
makes if I can prove something it makes

00:10:33,290 --> 00:10:37,009
me feel good you know and if I can fix

00:10:35,329 --> 00:10:38,689
things and I didn't prove it I feel bad

00:10:37,009 --> 00:10:40,309
because I don't know why I fixed it or

00:10:38,689 --> 00:10:44,059
how i fix it or if that even was the

00:10:40,309 --> 00:10:46,910
problem so yeah now some concepts about

00:10:44,059 --> 00:10:49,399
instrumentation and yeah response time

00:10:46,910 --> 00:10:52,490
to put so load is how much work is

00:10:49,399 --> 00:10:55,519
currently coming in utilization how much

00:10:52,490 --> 00:10:58,540
of our resources we currently use are

00:10:55,519 --> 00:10:59,870
being used at this moment scalability is

00:10:58,540 --> 00:11:02,029
what is

00:10:59,870 --> 00:11:06,050
relationship between utilization and our

00:11:02,029 --> 00:11:08,930
our means response time so throughput is

00:11:06,050 --> 00:11:11,660
how many tasks can we do in a certain

00:11:08,930 --> 00:11:13,160
amount of time concurrency is how many

00:11:11,660 --> 00:11:16,850
tasks can we do at the same time and

00:11:13,160 --> 00:11:19,940
capacity is how big can X so the troop

00:11:16,850 --> 00:11:22,100
would go without making other things

00:11:19,940 --> 00:11:24,800
unacceptable like response time so

00:11:22,100 --> 00:11:26,990
there's like a lot of connection between

00:11:24,800 --> 00:11:28,790
those things and one of the some of the

00:11:26,990 --> 00:11:31,279
most important things its response time

00:11:28,790 --> 00:11:33,710
is how much time does it take to do a

00:11:31,279 --> 00:11:36,380
certain amount of tasks how much time it

00:11:33,710 --> 00:11:39,800
does it takes to do one certain task and

00:11:36,380 --> 00:11:41,839
true put X is how many tasks can I do at

00:11:39,800 --> 00:11:43,430
a certain amount of time so often we

00:11:41,839 --> 00:11:45,230
look at true put we can see hey we're

00:11:43,430 --> 00:11:47,300
doing thousand two thousand transactions

00:11:45,230 --> 00:11:50,410
per second that looks good but your

00:11:47,300 --> 00:11:53,540
response time might be very very bad so

00:11:50,410 --> 00:11:55,400
true put is not performance it's the

00:11:53,540 --> 00:11:57,440
relationship between all these things

00:11:55,400 --> 00:12:01,940
throughput utilization response time and

00:11:57,440 --> 00:12:03,710
capacity so are so response time I have

00:12:01,940 --> 00:12:05,959
to say it's the combination of both the

00:12:03,710 --> 00:12:08,060
service time so the time it takes to do

00:12:05,959 --> 00:12:10,520
a certain task and the queuing that has

00:12:08,060 --> 00:12:15,290
been involved in that so we need to take

00:12:10,520 --> 00:12:17,480
that into account now about MySQL where

00:12:15,290 --> 00:12:19,310
do I need to look in my scroll so the

00:12:17,480 --> 00:12:21,020
common ones that we do is we know the

00:12:19,310 --> 00:12:22,700
error log is something going on is it

00:12:21,020 --> 00:12:25,310
crushing do I have a crush table things

00:12:22,700 --> 00:12:27,440
like that show global status shows us a

00:12:25,310 --> 00:12:30,110
lot of status counters very interesting

00:12:27,440 --> 00:12:32,480
but yeah running show global status by

00:12:30,110 --> 00:12:33,920
itself doesn't really give you much of

00:12:32,480 --> 00:12:35,690
an answer for some types of problems

00:12:33,920 --> 00:12:38,720
I'll show you some more examples on that

00:12:35,690 --> 00:12:42,110
later show engine I know TV status shows

00:12:38,720 --> 00:12:44,120
you I know DB specific information so I

00:12:42,110 --> 00:12:46,760
know DB is a transactional storage

00:12:44,120 --> 00:12:48,920
engine for MySQL you've got the

00:12:46,760 --> 00:12:54,440
operating system metrics so CPU memory

00:12:48,920 --> 00:12:58,760
disk network whatever so measuring

00:12:54,440 --> 00:13:00,500
performance we often recommend look at

00:12:58,760 --> 00:13:01,970
performance do it in your application

00:13:00,500 --> 00:13:04,190
because your application is doing the

00:13:01,970 --> 00:13:05,930
database requests so you're making the

00:13:04,190 --> 00:13:08,150
application usually so you have the

00:13:05,930 --> 00:13:10,550
control and adding that metrics to your

00:13:08,150 --> 00:13:12,500
application so you can add response time

00:13:10,550 --> 00:13:12,980
in your application or in your web

00:13:12,500 --> 00:13:17,810
server

00:13:12,980 --> 00:13:19,850
whatever you want mysql by itself gives

00:13:17,810 --> 00:13:21,560
you a lot of troubleshooting and i'll

00:13:19,850 --> 00:13:23,300
show you some more on on how to identify

00:13:21,560 --> 00:13:25,010
those things but if you have it in your

00:13:23,300 --> 00:13:29,420
application you can have it real time so

00:13:25,010 --> 00:13:32,000
one example we have here is from a ph

00:13:29,420 --> 00:13:33,529
instrumentation for PHP it's a small PHP

00:13:32,000 --> 00:13:35,899
class that actually gives you the

00:13:33,529 --> 00:13:38,000
following information for every request

00:13:35,899 --> 00:13:39,649
or every certain percentage of requests

00:13:38,000 --> 00:13:41,720
and important is that we can actually

00:13:39,649 --> 00:13:43,850
use this to make some powerful metrics

00:13:41,720 --> 00:13:46,220
we can see how much time it took in

00:13:43,850 --> 00:13:49,190
mysql and you can see that this was only

00:13:46,220 --> 00:13:51,470
4 milliseconds sphinx time so Sphinx is

00:13:49,190 --> 00:13:53,209
a full-text search engine often used in

00:13:51,470 --> 00:13:58,040
color a collaboration with mysql is

00:13:53,209 --> 00:14:00,769
about 83 milliseconds the total time it

00:13:58,040 --> 00:14:02,839
takes so user time is 129 milliseconds

00:14:00,769 --> 00:14:06,680
so if you look at that we can say okay

00:14:02,839 --> 00:14:09,079
Sphinx is taking up most time so if you

00:14:06,680 --> 00:14:11,209
want to optimize it and make this page

00:14:09,079 --> 00:14:13,519
faster we just need to optimize things

00:14:11,209 --> 00:14:17,180
because optimizing MySQL will only gain

00:14:13,519 --> 00:14:20,329
you four milliseconds out of 129 so you

00:14:17,180 --> 00:14:23,779
have to focus on what is most beneficial

00:14:20,329 --> 00:14:26,060
to you other important things as you can

00:14:23,779 --> 00:14:27,740
see how many queries were doing this is

00:14:26,060 --> 00:14:29,870
an example and many applications have

00:14:27,740 --> 00:14:31,760
much more information but a very

00:14:29,870 --> 00:14:34,579
important is is a page type and maybe

00:14:31,760 --> 00:14:37,970
the page request itself which is on top

00:14:34,579 --> 00:14:40,550
page so we can actually with this

00:14:37,970 --> 00:14:42,800
information we can make a look at

00:14:40,550 --> 00:14:45,589
response time we can look at how much

00:14:42,800 --> 00:14:47,690
time at it it takes to do a certain type

00:14:45,589 --> 00:14:49,610
of page or look at the different types

00:14:47,690 --> 00:14:51,380
of requests that we have and what the

00:14:49,610 --> 00:14:53,180
response time is for that we have the

00:14:51,380 --> 00:14:55,339
time when it was locked so we can see is

00:14:53,180 --> 00:14:57,560
it happening over the the whole amount

00:14:55,339 --> 00:14:59,959
of time throughout the day or throughout

00:14:57,560 --> 00:15:02,839
the week is it is it busier is response

00:14:59,959 --> 00:15:05,329
time higher at peak times I'd like 7-8

00:15:02,839 --> 00:15:08,240
p.m. is it is it more busy on wednesday

00:15:05,329 --> 00:15:10,250
afternoon is it is it more idle that

00:15:08,240 --> 00:15:13,730
allows you to make some queries look at

00:15:10,250 --> 00:15:16,190
95 percentiles 90 percentile and and

00:15:13,730 --> 00:15:20,110
really see when the load is actually

00:15:16,190 --> 00:15:23,360
higher how it affects your response time

00:15:20,110 --> 00:15:25,279
so that was a instrumentation for ph

00:15:23,360 --> 00:15:26,810
peets so that's so just a small open

00:15:25,279 --> 00:15:29,120
source project here

00:15:26,810 --> 00:15:30,590
yeah you've got a new relic that's

00:15:29,120 --> 00:15:32,210
application performance monitoring

00:15:30,590 --> 00:15:35,120
there's there's many other solutions new

00:15:32,210 --> 00:15:37,220
relic is the one I know best they do

00:15:35,120 --> 00:15:39,140
similar kinds of things and much more

00:15:37,220 --> 00:15:40,700
I'm so very useful if you have that

00:15:39,140 --> 00:15:45,800
don't have that yet I recommend looking

00:15:40,700 --> 00:15:47,330
at that about MySQL itself um we do have

00:15:45,800 --> 00:15:49,460
something called precone are monitoring

00:15:47,330 --> 00:15:51,710
tools and it's a set of scripts that

00:15:49,460 --> 00:15:54,140
plug into nodules and cacti I know it's

00:15:51,710 --> 00:15:55,730
a little yeah cacti has been there for a

00:15:54,140 --> 00:15:58,520
long time but we have those graphs for a

00:15:55,730 --> 00:15:59,990
long time already but it's quite often

00:15:58,520 --> 00:16:02,060
used because we have some nice graphs

00:15:59,990 --> 00:16:08,870
for cacti for my skull and I'll show you

00:16:02,060 --> 00:16:13,760
some later on okay now individual slow

00:16:08,870 --> 00:16:16,070
query so in this case we try to look at

00:16:13,760 --> 00:16:18,170
a certain single query see how we can

00:16:16,070 --> 00:16:21,050
make it faster I'm not going to explain

00:16:18,170 --> 00:16:23,060
you how to make it fast or I'll tell you

00:16:21,050 --> 00:16:24,890
how to optimize it at the Nexus things

00:16:23,060 --> 00:16:27,529
like that but I'll just show you which

00:16:24,890 --> 00:16:29,120
things you can use in MySQL to get more

00:16:27,529 --> 00:16:34,040
information about it and learn more

00:16:29,120 --> 00:16:36,770
about it so we've got explain show

00:16:34,040 --> 00:16:38,480
session status you've got show global

00:16:36,770 --> 00:16:41,420
status as well but in this case we're

00:16:38,480 --> 00:16:44,120
looking at the session status so when we

00:16:41,420 --> 00:16:46,970
run the query we can see in that session

00:16:44,120 --> 00:16:48,950
how many things it did I'll show you

00:16:46,970 --> 00:16:52,070
some examples how many rows at read how

00:16:48,950 --> 00:16:53,810
many sorts it did things like that show

00:16:52,070 --> 00:16:57,200
profiles it shows you some profiling

00:16:53,810 --> 00:17:00,050
information where it actually was in

00:16:57,200 --> 00:17:02,720
what kind of stage internally in MySQL

00:17:00,050 --> 00:17:04,280
was the query taking most time so

00:17:02,720 --> 00:17:06,800
sometimes it really reveals some

00:17:04,280 --> 00:17:09,160
information but not quite often used and

00:17:06,800 --> 00:17:13,880
one feature we have in percona server

00:17:09,160 --> 00:17:16,459
and is also in Moorea DB is slow query

00:17:13,880 --> 00:17:18,470
log extended statistics so we have a lot

00:17:16,459 --> 00:17:20,630
of added extend statistics to the slow

00:17:18,470 --> 00:17:23,420
query log if you look at Oracle MySQL

00:17:20,630 --> 00:17:26,329
and they have rose red rose examined

00:17:23,420 --> 00:17:28,069
rows returned and the time it took but

00:17:26,329 --> 00:17:30,530
we have so much more information about

00:17:28,069 --> 00:17:33,320
all those specific session status

00:17:30,530 --> 00:17:35,510
variables how much much more

00:17:33,320 --> 00:17:36,980
fine-grained detail on on what it was

00:17:35,510 --> 00:17:38,570
actually doing so it helps you better

00:17:36,980 --> 00:17:40,390
understand and helps you up how to

00:17:38,570 --> 00:17:43,490
optimize those queries

00:17:40,390 --> 00:17:45,920
more examples later on so we've got some

00:17:43,490 --> 00:17:49,970
kind of a query so it's a select

00:17:45,920 --> 00:17:51,860
straight joint count from cast info join

00:17:49,970 --> 00:17:54,140
title so this is from the IMDb database

00:17:51,860 --> 00:17:58,190
which can freely download from their ftp

00:17:54,140 --> 00:18:00,200
servers on IMDb com so if we explain it

00:17:58,190 --> 00:18:04,040
we can see how my squirrel will actually

00:18:00,200 --> 00:18:09,440
execute this so um I yeah as I said I

00:18:04,040 --> 00:18:10,970
won't go into many specific yeah explain

00:18:09,440 --> 00:18:13,220
you how how what is wrong with it or how

00:18:10,970 --> 00:18:15,980
to optimize it but we can see that it's

00:18:13,220 --> 00:18:18,590
a join between two tables and it starts

00:18:15,980 --> 00:18:22,190
with the first table called cost info

00:18:18,590 --> 00:18:25,580
and it is actually using an index named

00:18:22,190 --> 00:18:28,190
person ID to execute that it is doing a

00:18:25,580 --> 00:18:30,470
table scan it is using a temporary table

00:18:28,190 --> 00:18:33,350
and it is doing a file sort so it could

00:18:30,470 --> 00:18:35,270
not use an index to do any sorting so

00:18:33,350 --> 00:18:39,560
for every matching row it has here it

00:18:35,270 --> 00:18:41,900
will actually join with the title table

00:18:39,560 --> 00:18:44,990
and it will use the primary key to

00:18:41,900 --> 00:18:47,930
actually find it so here you can see

00:18:44,990 --> 00:18:51,070
that this kind of yeah shows you how it

00:18:47,930 --> 00:18:53,780
is being executed how the optimizer will

00:18:51,070 --> 00:18:57,410
execute that curry so we've got explain

00:18:53,780 --> 00:18:59,600
in 55 and before you could only explain

00:18:57,410 --> 00:19:02,330
select since five not six which has been

00:18:59,600 --> 00:19:05,000
become generally available in the last a

00:19:02,330 --> 00:19:09,140
couple of weeks you can explain updates

00:19:05,000 --> 00:19:11,120
and inserts and deletes as well so this

00:19:09,140 --> 00:19:14,180
gives you information so if you change

00:19:11,120 --> 00:19:15,830
some like remove the straight join maybe

00:19:14,180 --> 00:19:17,720
it will execute differently if you add

00:19:15,830 --> 00:19:19,520
an index see how it behaves on that

00:19:17,720 --> 00:19:21,500
maybe you can set some optimizer

00:19:19,520 --> 00:19:23,480
settings on a session basis it might

00:19:21,500 --> 00:19:24,980
execute differently as well but while

00:19:23,480 --> 00:19:27,410
you can see there's an estimate on how

00:19:24,980 --> 00:19:30,320
many rows it needs to read so it guesses

00:19:27,410 --> 00:19:32,270
so based on some metrics about the index

00:19:30,320 --> 00:19:34,310
at the table and everything it does some

00:19:32,270 --> 00:19:36,680
cost based optimizing and it thinks it

00:19:34,310 --> 00:19:38,660
will read about eight rows on the first

00:19:36,680 --> 00:19:42,290
table and for every matching row it will

00:19:38,660 --> 00:19:44,210
reach maximum of one row so that should

00:19:42,290 --> 00:19:46,730
be very fast curry it's not always the

00:19:44,210 --> 00:19:48,590
case there are bugs it is a guess it's

00:19:46,730 --> 00:19:50,960
an estimate especially with I know DV

00:19:48,590 --> 00:19:53,030
those statistics are estimates based on

00:19:50,960 --> 00:19:53,750
our own some random pages that it takes

00:19:53,030 --> 00:19:56,120
so

00:19:53,750 --> 00:19:58,280
might not always be perfect but it shows

00:19:56,120 --> 00:20:00,350
you the intention my Skrill has and

00:19:58,280 --> 00:20:02,990
that's it a little bit of a problem it's

00:20:00,350 --> 00:20:05,210
not what my squirrel did and many other

00:20:02,990 --> 00:20:07,790
databases have that information easily

00:20:05,210 --> 00:20:10,790
available in MySQL explain does not show

00:20:07,790 --> 00:20:13,490
you that however show session status

00:20:10,790 --> 00:20:16,100
shows you that information it's not that

00:20:13,490 --> 00:20:18,860
easy especially with this kind of curry

00:20:16,100 --> 00:20:21,410
you were thinking it was upwards working

00:20:18,860 --> 00:20:23,630
really fast but it wasn't so what we do

00:20:21,410 --> 00:20:25,280
is we flush the status so on top we

00:20:23,630 --> 00:20:27,980
remove the session status we put

00:20:25,280 --> 00:20:30,140
everything we can on 0 we run the query

00:20:27,980 --> 00:20:33,800
and then we do show session status like

00:20:30,140 --> 00:20:35,690
a chase o-h a handler show me everything

00:20:33,800 --> 00:20:37,610
that starts with handler and the handler

00:20:35,690 --> 00:20:40,130
interface is the API between the MySQL

00:20:37,610 --> 00:20:42,440
core and its storage engine so it kind

00:20:40,130 --> 00:20:44,060
of mysql core tells like the storage

00:20:42,440 --> 00:20:47,510
engine give me the next row of that

00:20:44,060 --> 00:20:51,350
table give me the next row right some

00:20:47,510 --> 00:20:53,720
row read some index so that the

00:20:51,350 --> 00:20:55,490
statistics between and in that interface

00:20:53,720 --> 00:20:57,230
actually show you a lot of information

00:20:55,490 --> 00:20:59,330
so what we can see here and then i'll

00:20:57,230 --> 00:21:01,550
show you some important once we've got

00:20:59,330 --> 00:21:03,860
handler read first handlery key and

00:21:01,550 --> 00:21:07,640
handler eat next so first is like read

00:21:03,860 --> 00:21:10,910
the first index entry of that yeah

00:21:07,640 --> 00:21:12,800
indexed so leads the first row has I

00:21:10,910 --> 00:21:15,020
read next is read the next one so you

00:21:12,800 --> 00:21:17,150
can see that this happened for 14

00:21:15,020 --> 00:21:18,650
million times read the next row read the

00:21:17,150 --> 00:21:20,330
next stroke can you hear me coming and

00:21:18,650 --> 00:21:22,430
it's not going to be very fast at curry

00:21:20,330 --> 00:21:25,820
so 14 million times for that specific

00:21:22,430 --> 00:21:28,880
query handler read key means read a

00:21:25,820 --> 00:21:31,910
specific index entry so the namings are

00:21:28,880 --> 00:21:34,580
not really clear but yeah it's

00:21:31,910 --> 00:21:38,060
documented on the depth of my skull calm

00:21:34,580 --> 00:21:40,100
website so it read about 13 million

00:21:38,060 --> 00:21:42,470
eight hundred ninety thousand times read

00:21:40,100 --> 00:21:45,500
that specific index entry read that

00:21:42,470 --> 00:21:48,770
specific index entry we've got handle

00:21:45,500 --> 00:21:50,810
read our indian handler reed rd next R&D

00:21:48,770 --> 00:21:52,940
does not mean random it just this is

00:21:50,810 --> 00:21:56,480
about reading an index this is about

00:21:52,940 --> 00:21:59,870
reading a row so we can see that this is

00:21:56,480 --> 00:22:02,690
give me the next row read the next row

00:21:59,870 --> 00:22:04,340
so what this is actually a table scan so

00:22:02,690 --> 00:22:06,740
this is an index can give me the next

00:22:04,340 --> 00:22:06,980
index entry this is a table scan give me

00:22:06,740 --> 00:22:08,990
the

00:22:06,980 --> 00:22:11,210
next row give me the next row this

00:22:08,990 --> 00:22:14,179
happens for only two hundred two million

00:22:11,210 --> 00:22:16,520
four hundred and seven thousand another

00:22:14,179 --> 00:22:18,860
interesting thing and that's where it

00:22:16,520 --> 00:22:19,880
kind of lacks good insight on what it

00:22:18,860 --> 00:22:21,950
really doesn't kind of need to

00:22:19,880 --> 00:22:23,480
understand it is that was just to select

00:22:21,950 --> 00:22:27,559
but what we see is that it does about

00:22:23,480 --> 00:22:29,690
two dot 4 million rights so to this

00:22:27,559 --> 00:22:31,850
actually comes from reading from a

00:22:29,690 --> 00:22:33,890
temporary writing to a temporary table

00:22:31,850 --> 00:22:36,799
so as you see here it was mentioned it

00:22:33,890 --> 00:22:42,740
creates a temporary table to do some

00:22:36,799 --> 00:22:44,299
sorting or or yes similar so what you

00:22:42,740 --> 00:22:46,370
can see is the temporary table is

00:22:44,299 --> 00:22:49,580
actually two million rows big so that's

00:22:46,370 --> 00:22:51,320
quite large already and we can see that

00:22:49,580 --> 00:22:52,880
this kind of matches with handle read

00:22:51,320 --> 00:22:54,799
are in the next so when a temporary

00:22:52,880 --> 00:22:58,160
table is being created there's no index

00:22:54,799 --> 00:22:59,660
on that temporary table and the results

00:22:58,160 --> 00:23:01,370
will have to be read to be further

00:22:59,660 --> 00:23:03,140
processed so you can see that it read

00:23:01,370 --> 00:23:05,750
that whole temporary table again to

00:23:03,140 --> 00:23:08,059
return the results somehow so very

00:23:05,750 --> 00:23:10,340
interesting one so if you understand a

00:23:08,059 --> 00:23:13,220
little bit those things and and see like

00:23:10,340 --> 00:23:16,429
temporary table file sort so what we can

00:23:13,220 --> 00:23:19,970
see is this this was an index scan so

00:23:16,429 --> 00:23:24,070
those metrics came from the first table

00:23:19,970 --> 00:23:27,770
and the join waited here was actually

00:23:24,070 --> 00:23:29,870
handle read key so it was read a certain

00:23:27,770 --> 00:23:32,600
primary key read that entry for every

00:23:29,870 --> 00:23:35,059
matching row here read that entry so we

00:23:32,600 --> 00:23:37,130
can see here that it did that for about

00:23:35,059 --> 00:23:40,580
30 million times and this is the size of

00:23:37,130 --> 00:23:41,960
a temporary table so it gives it takes a

00:23:40,580 --> 00:23:44,690
little bit of experience to get familiar

00:23:41,960 --> 00:23:48,559
with it but very useful post execution

00:23:44,690 --> 00:23:51,230
analysis of this very good now profiling

00:23:48,559 --> 00:23:53,270
not quite often used but this is how you

00:23:51,230 --> 00:23:55,490
enable it set profiling equals one on

00:23:53,270 --> 00:23:58,309
your session run the query do show

00:23:55,490 --> 00:24:00,679
profiles the query that we ran comes up

00:23:58,309 --> 00:24:03,380
and we can see the profiling by doing

00:24:00,679 --> 00:24:05,630
show profile for query one and this is

00:24:03,380 --> 00:24:08,330
what is being output it so you can see

00:24:05,630 --> 00:24:11,330
the different states that it goes

00:24:08,330 --> 00:24:15,230
through in my scroll and we can see that

00:24:11,330 --> 00:24:18,110
most time this is not really yeah

00:24:15,230 --> 00:24:20,260
perfect numbers but they show you a good

00:24:18,110 --> 00:24:23,590
indication especially here is we copy

00:24:20,260 --> 00:24:26,290
temp table was 113 seconds copying to

00:24:23,590 --> 00:24:28,450
temp table on disk so sometimes MySQL

00:24:26,290 --> 00:24:30,130
converts at them table when it becomes

00:24:28,450 --> 00:24:32,260
too large in memory it makes it in my

00:24:30,130 --> 00:24:34,570
eyes on table on the temporary on a

00:24:32,260 --> 00:24:37,090
temporary directory and the file system

00:24:34,570 --> 00:24:39,820
so you can see that this took 96 seconds

00:24:37,090 --> 00:24:42,100
so there's some room for optimization on

00:24:39,820 --> 00:24:44,890
that I would recommend to just fix the

00:24:42,100 --> 00:24:47,050
curry by itself instead of putting the

00:24:44,890 --> 00:24:50,680
temporary table directory on a shared

00:24:47,050 --> 00:24:52,990
file I on a memory file system but it

00:24:50,680 --> 00:24:57,390
does work in some cases so here we see

00:24:52,990 --> 00:24:59,920
that this time is spent on that state

00:24:57,390 --> 00:25:02,470
not quite frequently used at least not

00:24:59,920 --> 00:25:04,480
in my case now does it extend that slow

00:25:02,470 --> 00:25:06,460
log statistics give you similar

00:25:04,480 --> 00:25:09,820
information so like the show session

00:25:06,460 --> 00:25:11,650
status and it's a little bit I think

00:25:09,820 --> 00:25:13,450
it's very easy to read and very easy to

00:25:11,650 --> 00:25:16,270
understand and good for logging as it

00:25:13,450 --> 00:25:19,480
becomes logged in the slow log so set

00:25:16,270 --> 00:25:21,130
global lon qui x 0 we log every query

00:25:19,480 --> 00:25:23,800
that is going to be run on the database

00:25:21,130 --> 00:25:25,570
from now on and we set the verbosity to

00:25:23,800 --> 00:25:27,700
full so this means because it give us

00:25:25,570 --> 00:25:30,220
all the metrics you can give us and this

00:25:27,700 --> 00:25:32,500
is all the output from one certain query

00:25:30,220 --> 00:25:35,130
from that query this is all the metrics

00:25:32,500 --> 00:25:38,740
that we get out of it so what do we see

00:25:35,130 --> 00:25:41,470
there was a lot of I know dbio reads so

00:25:38,740 --> 00:25:44,590
this read a lot of bites was it a foul

00:25:41,470 --> 00:25:46,690
sort yes was it a query cache hit how

00:25:44,590 --> 00:25:48,670
many discs temporary tables were created

00:25:46,690 --> 00:25:52,540
how big was the temporary table very

00:25:48,670 --> 00:25:55,240
nice very nice yeah everything that you

00:25:52,540 --> 00:25:56,950
can imagine is in there so that's really

00:25:55,240 --> 00:25:59,710
good especially if you can log it to the

00:25:56,950 --> 00:26:02,470
table log it to a file and then analyze

00:25:59,710 --> 00:26:05,860
it with some tools which is something

00:26:02,470 --> 00:26:07,360
I'll show you next any questions so far

00:26:05,860 --> 00:26:09,450
I still have a lot of t-shirts and

00:26:07,360 --> 00:26:12,660
otherwise I'll just throw them away yes

00:26:09,450 --> 00:26:12,660
here you go

00:26:17,520 --> 00:26:28,210
yeah perfect if you wait a little bit I

00:26:26,350 --> 00:26:30,970
have a perfect example that shows you

00:26:28,210 --> 00:26:33,340
how to analyze that it's a pretty common

00:26:30,970 --> 00:26:35,700
problem indeed I'll show you if i have

00:26:33,340 --> 00:26:38,170
time i but yeah definitely get there um

00:26:35,700 --> 00:26:48,540
any other questions I've got seven or

00:26:38,170 --> 00:26:51,640
eight of them no oh yeah sure oh sorry

00:26:48,540 --> 00:26:54,550
so I don't know if I named DB uses it

00:26:51,640 --> 00:26:56,080
but they have csv files on an ftp server

00:26:54,550 --> 00:26:57,850
which you can download and there's an

00:26:56,080 --> 00:27:00,310
open source project on sourceforge that

00:26:57,850 --> 00:27:02,530
actually adapted to be imported in my

00:27:00,310 --> 00:27:04,630
eyes mi no DB or postgres tables or

00:27:02,530 --> 00:27:08,950
oracle so it's kind of a tool that is

00:27:04,630 --> 00:27:17,280
written around it and to be used so yeah

00:27:08,950 --> 00:27:17,280
indeed I don't know probably yeah yes

00:27:23,940 --> 00:27:33,279
why is it doing that exactly sorry k

00:27:27,880 --> 00:27:36,399
repeat hi yeah why doesn't get pudding

00:27:33,279 --> 00:27:40,809
mixes I'm it's temporary tables that

00:27:36,399 --> 00:27:42,100
previous query yeah um yeah why is it

00:27:40,809 --> 00:27:44,080
creating a temperature that's a good

00:27:42,100 --> 00:27:47,320
question i need to check out why doesn't

00:27:44,080 --> 00:27:49,779
it use an index on it probably because

00:27:47,320 --> 00:27:55,090
there's some index missing so we it it

00:27:49,779 --> 00:27:56,919
had to do some kind of sorting and no

00:27:55,090 --> 00:27:59,470
sorry if there's a group by here very

00:27:56,919 --> 00:28:01,539
easy and it couldn't use an index to do

00:27:59,470 --> 00:28:03,519
grew by and in order to do the group by

00:28:01,539 --> 00:28:05,679
it creates a temporary table to do that

00:28:03,519 --> 00:28:07,870
so we can adapt indexing maybe add some

00:28:05,679 --> 00:28:09,039
composite indexes to actually make sure

00:28:07,870 --> 00:28:10,899
we don't need to create a temporary

00:28:09,039 --> 00:28:12,850
table in that case and then it would be

00:28:10,899 --> 00:28:14,289
resolved although there's a lot of

00:28:12,850 --> 00:28:15,940
limitations around indexing and

00:28:14,289 --> 00:28:18,429
everything so i can't really go into

00:28:15,940 --> 00:28:20,139
specifics on how to optimize this

00:28:18,429 --> 00:28:23,799
particular case but i can show you

00:28:20,139 --> 00:28:26,440
afterwards on how to yeah leverage that

00:28:23,799 --> 00:28:29,620
after the talk is okay well actually I

00:28:26,440 --> 00:28:33,100
meant you say it makes a temporary table

00:28:29,620 --> 00:28:35,919
without an index yeah so okay sorry I

00:28:33,100 --> 00:28:37,570
misunderstood so it doesn't a temporary

00:28:35,919 --> 00:28:41,950
table by itself is called a memory

00:28:37,570 --> 00:28:43,330
engine so it doesn't make any indexes

00:28:41,950 --> 00:28:45,850
because you don't do create temporary

00:28:43,330 --> 00:28:47,559
table which is also possible it makes it

00:28:45,850 --> 00:28:49,659
automatically and it doesn't create an

00:28:47,559 --> 00:28:51,940
index my squirrel just says okay I need

00:28:49,659 --> 00:28:53,440
a temporary table I don't know which my

00:28:51,940 --> 00:28:55,450
skull doesn't know which indexes to

00:28:53,440 --> 00:28:57,429
create so it doesn't it just makes it

00:28:55,450 --> 00:28:59,110
able to dump the data in and then

00:28:57,429 --> 00:29:04,690
retrieves and does a full table scan on

00:28:59,110 --> 00:29:06,009
that okay perfect okay global

00:29:04,690 --> 00:29:10,830
performance problems that we took the

00:29:06,009 --> 00:29:14,620
time really quickly ok I'll go fast okay

00:29:10,830 --> 00:29:16,570
example problem 95 percentile of the

00:29:14,620 --> 00:29:19,149
response time has been increased from 40

00:29:16,570 --> 00:29:21,009
milliseconds to 200 milliseconds so

00:29:19,149 --> 00:29:23,679
what's going on how do we get more

00:29:21,009 --> 00:29:26,409
insight in that case how do we know

00:29:23,679 --> 00:29:29,620
what's going on so I recommend to use

00:29:26,409 --> 00:29:31,980
trending graphs whatever you use I'll go

00:29:29,620 --> 00:29:34,840
show some all very old cacti graphs but

00:29:31,980 --> 00:29:36,340
there's a lot of variance about it so if

00:29:34,840 --> 00:29:39,789
you got pro kona ganglia

00:29:36,340 --> 00:29:42,580
plugins there's grass for zabbix for

00:29:39,789 --> 00:29:44,770
everything pretty much everything a lot

00:29:42,580 --> 00:29:46,750
of other graphing engines actually use

00:29:44,770 --> 00:29:48,400
our graphs as a basis because they are

00:29:46,750 --> 00:29:51,340
really useful graphs they show you some

00:29:48,400 --> 00:29:53,919
really useful information so we want to

00:29:51,340 --> 00:29:56,529
look at more granular data like really

00:29:53,919 --> 00:29:58,779
rose red on the database that really

00:29:56,529 --> 00:30:00,760
shows you more than just a query how

00:29:58,779 --> 00:30:04,150
many queries per second I can show you

00:30:00,760 --> 00:30:06,070
some graphs other tools that we can use

00:30:04,150 --> 00:30:09,520
as cysts that I all-star and pstat

00:30:06,070 --> 00:30:11,080
vmstat PT maxed ptd sets IO profile PMP

00:30:09,520 --> 00:30:12,730
and pity card digests I'll go through

00:30:11,080 --> 00:30:15,070
all of them but I'll skip some of them

00:30:12,730 --> 00:30:18,130
that are less important so systat is

00:30:15,070 --> 00:30:21,460
probably well known iostat mp7 vmstat so

00:30:18,130 --> 00:30:24,039
look at i/o statistics CPU statistics

00:30:21,460 --> 00:30:26,860
and virtual memory up yeah or more

00:30:24,039 --> 00:30:29,740
global statistics this is part of the

00:30:26,860 --> 00:30:31,779
pro kona toolkit and i'll show you some

00:30:29,740 --> 00:30:36,250
of them really quickly but first some

00:30:31,779 --> 00:30:37,809
graphs having trending i won't go and

00:30:36,250 --> 00:30:40,029
say what the problem is but trending

00:30:37,809 --> 00:30:41,679
allows you to see what patterns changed

00:30:40,029 --> 00:30:43,360
over a certain amount of time and the

00:30:41,679 --> 00:30:44,950
power of the graphs that i think about

00:30:43,360 --> 00:30:46,840
the graphs we have here is we don't see

00:30:44,950 --> 00:30:49,059
one metric and how it evolves but we

00:30:46,840 --> 00:30:50,350
look at some some metrics that are like

00:30:49,059 --> 00:30:52,539
connected to each other in this case

00:30:50,350 --> 00:30:54,549
it's about connection so we see here the

00:30:52,539 --> 00:30:58,090
amount of connections created the amount

00:30:54,549 --> 00:30:59,799
of treads that were connected so we can

00:30:58,090 --> 00:31:01,240
see that there was a slight spike here

00:30:59,799 --> 00:31:03,610
so it might be a good thing to

00:31:01,240 --> 00:31:05,710
investigate that if necessary or to

00:31:03,610 --> 00:31:08,799
understand why this happens so it's all

00:31:05,710 --> 00:31:11,710
about understanding about replication we

00:31:08,799 --> 00:31:13,720
can see that replication is lagging from

00:31:11,710 --> 00:31:15,490
time to time up to the ten ten thousand

00:31:13,720 --> 00:31:17,620
seconds but it kind of catches up like

00:31:15,490 --> 00:31:19,570
during the night but at some point there

00:31:17,620 --> 00:31:21,760
was like a big delay and replication

00:31:19,570 --> 00:31:23,710
never caught up through like more than a

00:31:21,760 --> 00:31:25,840
week so there was kind of a problem

00:31:23,710 --> 00:31:27,370
there so we can see that if there was an

00:31:25,840 --> 00:31:30,130
application problem do you have some

00:31:27,370 --> 00:31:32,140
stale data returned on one of your safes

00:31:30,130 --> 00:31:33,549
that's probably causing it what is

00:31:32,140 --> 00:31:36,610
causing it yeah that's something else

00:31:33,549 --> 00:31:39,070
you have to investigate same about

00:31:36,610 --> 00:31:40,809
temporary tables how much are created

00:31:39,070 --> 00:31:43,059
what we can see here this is a pretty

00:31:40,809 --> 00:31:44,710
strict pattern probably some cron job

00:31:43,059 --> 00:31:46,659
running on every hour so you can see

00:31:44,710 --> 00:31:48,730
that this increases a little bit the

00:31:46,659 --> 00:31:49,159
temp tables being created so that's a

00:31:48,730 --> 00:31:51,349
good one

00:31:49,159 --> 00:31:53,450
there was a slight spike in the one here

00:31:51,349 --> 00:31:55,159
but yeah if there's no real problem

00:31:53,450 --> 00:31:56,869
don't go and find out but if there's a

00:31:55,159 --> 00:31:59,419
problem it helps you to understand what

00:31:56,869 --> 00:32:02,119
the MySQL did differently another useful

00:31:59,419 --> 00:32:03,919
one is I know DB buffer pool what's

00:32:02,119 --> 00:32:05,450
empty we just restarted the database

00:32:03,919 --> 00:32:07,039
here and you can see it takes a lot of

00:32:05,450 --> 00:32:08,659
time before memory is becoming full

00:32:07,039 --> 00:32:11,359
again so you can see that this kind of

00:32:08,659 --> 00:32:13,509
effects checkpointing so writing the

00:32:11,359 --> 00:32:16,099
changes to the table spaces itself in

00:32:13,509 --> 00:32:18,679
mysql so you can see that there was a

00:32:16,099 --> 00:32:21,200
lot of Rights having to happen because

00:32:18,679 --> 00:32:24,379
the memory because this guy all was

00:32:21,200 --> 00:32:26,090
actually yeah heavily utilized because

00:32:24,379 --> 00:32:30,739
of the wreaths because of memory not

00:32:26,090 --> 00:32:34,059
being yeah completely leveraged got some

00:32:30,739 --> 00:32:37,309
more graphs some more fine-grained one

00:32:34,059 --> 00:32:40,340
row operations how many rows read io

00:32:37,309 --> 00:32:41,690
operations and buffer pool activity so

00:32:40,340 --> 00:32:43,609
we can actually look at them together

00:32:41,690 --> 00:32:46,220
see what actually happened you can see

00:32:43,609 --> 00:32:48,710
some of the spikes match with each other

00:32:46,220 --> 00:32:50,779
sometimes they don't so you can see ya

00:32:48,710 --> 00:32:53,419
try to understand what's going on here

00:32:50,779 --> 00:32:55,249
another useful one in pre-owned of

00:32:53,419 --> 00:33:00,229
server is the response time distribution

00:32:55,249 --> 00:33:01,789
and the thing we see here is is that it

00:33:00,229 --> 00:33:03,470
just gallons the amount of queries that

00:33:01,789 --> 00:33:07,190
took a certain amount of time and it

00:33:03,470 --> 00:33:09,679
adds up the total response time in here

00:33:07,190 --> 00:33:11,509
so what we can see is this is a query

00:33:09,679 --> 00:33:14,479
that takes less than one micro second

00:33:11,509 --> 00:33:16,940
there were zero a query that takes yeah

00:33:14,479 --> 00:33:19,940
between 1 and 10 microseconds 17 of them

00:33:16,940 --> 00:33:21,979
and so forth so from 100 milliseconds up

00:33:19,940 --> 00:33:23,869
to a second 8,000 of them and that was a

00:33:21,979 --> 00:33:25,940
total response time of four hundred

00:33:23,869 --> 00:33:27,950
seconds so it doesn't seem to look that

00:33:25,940 --> 00:33:29,749
interesting but if you look it over time

00:33:27,950 --> 00:33:33,679
you can actually graph it and you can

00:33:29,749 --> 00:33:36,259
see that that there were more queries

00:33:33,679 --> 00:33:38,029
you can maybe you can see it's shift I

00:33:36,259 --> 00:33:39,889
can actually show it better here that

00:33:38,029 --> 00:33:43,599
curry is actually when there's more load

00:33:39,889 --> 00:33:45,679
more throughput that average the global

00:33:43,599 --> 00:33:47,450
response time actually becomes slower

00:33:45,679 --> 00:33:50,029
and those counters start to increase

00:33:47,450 --> 00:33:51,799
more so if you can make it faster if to

00:33:50,029 --> 00:33:53,570
put is less probably everything becomes

00:33:51,799 --> 00:33:57,229
a little bit football faster so it's a

00:33:53,570 --> 00:33:59,419
good thing to look at it over time PT

00:33:57,229 --> 00:34:01,999
mixed so I mentioned show global status

00:33:59,419 --> 00:34:03,160
shows you global status counters since

00:34:01,999 --> 00:34:05,590
mysql start

00:34:03,160 --> 00:34:08,470
for most of them so PT max actually

00:34:05,590 --> 00:34:10,240
shows you that over a certain between a

00:34:08,470 --> 00:34:13,360
certain period of time so we can see

00:34:10,240 --> 00:34:15,120
here we look at my SQL admin next so

00:34:13,360 --> 00:34:17,440
that's show global status a command line

00:34:15,120 --> 00:34:19,330
with an interval of ten seconds and we

00:34:17,440 --> 00:34:21,370
do it three times so PT max just

00:34:19,330 --> 00:34:23,740
analyzes the data just generates like a

00:34:21,370 --> 00:34:26,320
table here and shows you the value it

00:34:23,740 --> 00:34:28,570
was the first time and the difference in

00:34:26,320 --> 00:34:31,240
the second run so we can see how many

00:34:28,570 --> 00:34:34,720
inserts were there in those second at

00:34:31,240 --> 00:34:36,340
ten seconds so 1500 inserts so if we

00:34:34,720 --> 00:34:38,169
have a certain problem or we want to

00:34:36,340 --> 00:34:40,240
look during peak we want to use this not

00:34:38,169 --> 00:34:42,460
global counter since the start two years

00:34:40,240 --> 00:34:44,710
ago of the database so we look at

00:34:42,460 --> 00:34:46,900
certain small times and we can see that

00:34:44,710 --> 00:34:50,740
10 seconds later we did the double

00:34:46,900 --> 00:34:52,210
amount of inserts so very interesting we

00:34:50,740 --> 00:34:56,140
can see that a lot of temp tables were

00:34:52,210 --> 00:34:57,760
created here about 181 per second so

00:34:56,140 --> 00:34:59,350
there's more here and we've got the

00:34:57,760 --> 00:35:01,240
handler statistics again but these are

00:34:59,350 --> 00:35:04,780
global now so you can see the database

00:35:01,240 --> 00:35:08,950
wasn't too busy that's about 3492 times

00:35:04,780 --> 00:35:12,070
read a certain row that's a read a

00:35:08,950 --> 00:35:14,010
certain index that's pretty good if it's

00:35:12,070 --> 00:35:17,170
eight million i'm even not too impressed

00:35:14,010 --> 00:35:19,960
so the box is probably not doing that

00:35:17,170 --> 00:35:22,000
much here but you can see so much more

00:35:19,960 --> 00:35:25,000
about corey cash how many threads were

00:35:22,000 --> 00:35:26,520
running so we've got five running five

00:35:25,000 --> 00:35:29,710
queries running at the same time and

00:35:26,520 --> 00:35:31,750
three mine a treeless at that specific

00:35:29,710 --> 00:35:34,120
moment in time not in those 10 seconds

00:35:31,750 --> 00:35:35,770
so some counters are like select it now

00:35:34,120 --> 00:35:37,390
that many treads are running so two

00:35:35,770 --> 00:35:40,330
threads were running when we did it

00:35:37,390 --> 00:35:43,810
again and then zero very important for

00:35:40,330 --> 00:35:45,400
next chapter so BTW mext allows us to

00:35:43,810 --> 00:35:47,740
investigate what's going on at the

00:35:45,400 --> 00:35:50,260
certain period of time we often do this

00:35:47,740 --> 00:35:52,960
for our performance audits for customers

00:35:50,260 --> 00:35:54,880
we ask them when its peak time okay

00:35:52,960 --> 00:35:56,680
that's that day we just collect the data

00:35:54,880 --> 00:35:59,380
when its peak down because that

00:35:56,680 --> 00:36:00,880
represents the actual workload that we

00:35:59,380 --> 00:36:02,170
need to investigate we don't want to

00:36:00,880 --> 00:36:05,440
know what happened over the course of

00:36:02,170 --> 00:36:08,050
one day doesn't give us any clue some of

00:36:05,440 --> 00:36:10,930
the tools available like bicycle tuner

00:36:08,050 --> 00:36:12,190
and others look at global counters and

00:36:10,930 --> 00:36:15,670
give you advice on how to tune your

00:36:12,190 --> 00:36:18,560
database that that doesn't work

00:36:15,670 --> 00:36:21,740
disk subsystem we've got iOS that pretty

00:36:18,560 --> 00:36:24,470
common important things we can see here

00:36:21,740 --> 00:36:26,930
sdb had an average weight of 420

00:36:24,470 --> 00:36:30,170
milliseconds and a service time of 2002

00:36:26,930 --> 00:36:33,160
94 milliseconds so this means this guy

00:36:30,170 --> 00:36:37,580
was pretty stressed here we had about

00:36:33,160 --> 00:36:40,520
338 rights and 19 0 dot 99 reads per

00:36:37,580 --> 00:36:41,570
second so that's not that much there's

00:36:40,520 --> 00:36:43,810
something going on with the disk

00:36:41,570 --> 00:36:47,150
subsystem never look at utilization

00:36:43,810 --> 00:36:49,400
utilization shows you how many time like

00:36:47,150 --> 00:36:51,530
if we do it like in one second over the

00:36:49,400 --> 00:36:54,860
course of one second in that last second

00:36:51,530 --> 00:36:57,080
how much percent of the that second was

00:36:54,860 --> 00:36:59,030
in at least one request and if you have

00:36:57,080 --> 00:37:01,100
one disk it makes sense but if you have

00:36:59,030 --> 00:37:03,290
a large disk subsystem or you have

00:37:01,100 --> 00:37:05,360
flushed based storage that can handle

00:37:03,290 --> 00:37:07,790
multiple requests at the same time then

00:37:05,360 --> 00:37:10,670
yeah that doesn't matter anymore 100%

00:37:07,790 --> 00:37:13,820
might mean nothing now the problem with

00:37:10,670 --> 00:37:15,710
IO started is that it shows you a newer

00:37:13,820 --> 00:37:17,720
version actually newer versions actually

00:37:15,710 --> 00:37:19,460
fixed it is that this is combined reads

00:37:17,720 --> 00:37:21,800
and writes for response time so we've

00:37:19,460 --> 00:37:26,660
got a tool PT disk stats that looks at

00:37:21,800 --> 00:37:28,730
proc disk stats and you can see read

00:37:26,660 --> 00:37:31,760
response time over right response time

00:37:28,730 --> 00:37:35,240
so similar data similar data that you

00:37:31,760 --> 00:37:37,370
can see here there's a lot more but i

00:37:35,240 --> 00:37:40,670
won't go into details here okay

00:37:37,370 --> 00:37:43,430
optimizing crows so when response time

00:37:40,670 --> 00:37:46,940
goes up you look at PT mext you can see

00:37:43,430 --> 00:37:48,950
there is about yet 86 million here maybe

00:37:46,940 --> 00:37:50,960
over 10 seconds so we're doing full

00:37:48,950 --> 00:37:53,390
table scans because it's handle read RND

00:37:50,960 --> 00:37:54,950
next so we kind of need to find out

00:37:53,390 --> 00:37:56,930
which query is causing this you can do

00:37:54,950 --> 00:37:59,210
show process list until you find it but

00:37:56,930 --> 00:38:00,470
yeah you might not catch it so we can

00:37:59,210 --> 00:38:03,620
look at the slow query log that I

00:38:00,470 --> 00:38:05,750
mentioned so I showed it you this before

00:38:03,620 --> 00:38:09,950
all the metrics but we've got a tool

00:38:05,750 --> 00:38:12,500
called PT query digest that shows you

00:38:09,950 --> 00:38:15,260
that analyzes that log and can show you

00:38:12,500 --> 00:38:16,850
a good report about it so what we see

00:38:15,260 --> 00:38:20,990
here is we can run it there's a lot of

00:38:16,850 --> 00:38:23,660
features about filtering out yeah a lot

00:38:20,990 --> 00:38:25,760
of features but what I want to show is

00:38:23,660 --> 00:38:27,320
that it analyzes the different types of

00:38:25,760 --> 00:38:28,910
queries doesn't look at the actual data

00:38:27,320 --> 00:38:30,320
just the type of query

00:38:28,910 --> 00:38:33,170
and summarizes and gives you some

00:38:30,320 --> 00:38:35,030
percentiles averages and you can see

00:38:33,170 --> 00:38:38,000
what the average execution time is if

00:38:35,030 --> 00:38:40,040
the average and the 95 percentile are

00:38:38,000 --> 00:38:43,130
quite similar here so that's good but

00:38:40,040 --> 00:38:48,350
maybe yeah there's a lot of variance

00:38:43,130 --> 00:38:51,380
between it so this is the first query

00:38:48,350 --> 00:38:53,420
some distribution time so fifty percent

00:38:51,380 --> 00:38:55,790
of the time it runs between 100

00:38:53,420 --> 00:38:57,800
milliseconds and one second and other

00:38:55,790 --> 00:39:00,290
times it takes between 10 and 100

00:38:57,800 --> 00:39:02,060
microseconds this could be this base

00:39:00,290 --> 00:39:04,610
reads memory-based reads very

00:39:02,060 --> 00:39:06,980
interesting to know there's a lot of

00:39:04,610 --> 00:39:08,390
other metrics about it if you use the

00:39:06,980 --> 00:39:11,600
slow query log from pro-communist server

00:39:08,390 --> 00:39:14,600
you've got I no debe ir reads and writes

00:39:11,600 --> 00:39:16,430
and things like that all the added

00:39:14,600 --> 00:39:21,680
extras if you just use Oracle MySQL

00:39:16,430 --> 00:39:24,620
you've got only dos yeah dos and then it

00:39:21,680 --> 00:39:28,130
stops okay intermittent performance

00:39:24,620 --> 00:39:29,690
problems now we looked at global

00:39:28,130 --> 00:39:32,360
performance problems but sometimes they

00:39:29,690 --> 00:39:35,720
happen problems happen really really

00:39:32,360 --> 00:39:38,810
like briefly we've got ya if you have

00:39:35,720 --> 00:39:41,540
like social games then you really want

00:39:38,810 --> 00:39:43,940
to have a good response time if it's

00:39:41,540 --> 00:39:45,650
becoming a little slower users notice

00:39:43,940 --> 00:39:47,960
immediately so you cannot afford to have

00:39:45,650 --> 00:39:49,880
that so how do we investigate this we

00:39:47,960 --> 00:39:54,050
got two tools called PT stock and PT

00:39:49,880 --> 00:39:56,270
sift BTW sog it stalks something until

00:39:54,050 --> 00:39:58,880
some kind of condition becomes true it's

00:39:56,270 --> 00:40:03,350
like by default it does let me show you

00:39:58,880 --> 00:40:05,750
skip you a little bit so by default it

00:40:03,350 --> 00:40:07,490
actually looks at treads running Saudi

00:40:05,750 --> 00:40:09,560
here's a metric of treads running over a

00:40:07,490 --> 00:40:12,740
certain amount of time like usually it's

00:40:09,560 --> 00:40:14,270
seven but then it actually goes up to 24

00:40:12,740 --> 00:40:16,160
so there's some kind of locking going on

00:40:14,270 --> 00:40:17,660
there's something going on so PT style

00:40:16,160 --> 00:40:19,970
can can be can be configured to do

00:40:17,660 --> 00:40:21,500
anything it can look at treads running

00:40:19,970 --> 00:40:24,020
it you can make your own scripts your

00:40:21,500 --> 00:40:26,420
own triggers for it like check various

00:40:24,020 --> 00:40:28,520
whatever application metrics and as soon

00:40:26,420 --> 00:40:30,460
as that condition becomes true it starts

00:40:28,520 --> 00:40:33,350
to collect data but I mean a lot of data

00:40:30,460 --> 00:40:36,250
you can do gdb back traces of MySQL

00:40:33,350 --> 00:40:38,660
Oprah falling s tracing tcpdump data

00:40:36,250 --> 00:40:42,070
collection in order to see what kind of

00:40:38,660 --> 00:40:44,170
traffic was going on but yeah

00:40:42,070 --> 00:40:45,580
maybe not the first thing you want to

00:40:44,170 --> 00:40:48,060
look at but all the other things are

00:40:45,580 --> 00:40:50,340
there like operating system information

00:40:48,060 --> 00:40:53,500
memory information I always that

00:40:50,340 --> 00:40:55,390
interrupts I know DB status all kinds of

00:40:53,500 --> 00:40:59,230
information it just happens when you run

00:40:55,390 --> 00:41:00,490
it it just starts collecting all that so

00:40:59,230 --> 00:41:02,440
you can analyze it with the tool called

00:41:00,490 --> 00:41:04,540
PT sift or you can just read the files

00:41:02,440 --> 00:41:06,040
and it shows you some supper summary so

00:41:04,540 --> 00:41:08,050
you can see what kind of things were

00:41:06,040 --> 00:41:09,610
going on and actually helps us in our

00:41:08,050 --> 00:41:11,320
consulting business when we have of

00:41:09,610 --> 00:41:13,960
customer says hey that problem happens

00:41:11,320 --> 00:41:16,600
we don't go log in and monitor 24 7 we

00:41:13,960 --> 00:41:18,130
just say ok we'll configure it and it

00:41:16,600 --> 00:41:19,750
sends an email to us as soon as

00:41:18,130 --> 00:41:22,780
something is collected and then we go

00:41:19,750 --> 00:41:24,460
and analyze that data so very easy we

00:41:22,780 --> 00:41:27,930
usually find out what's going on pretty

00:41:24,460 --> 00:41:30,550
easily so what's usually going on here

00:41:27,930 --> 00:41:34,240
full table scans queries locking each

00:41:30,550 --> 00:41:36,640
other up long transactions as mentioned

00:41:34,240 --> 00:41:38,230
here causing others to be blocked and

00:41:36,640 --> 00:41:40,750
yeah causing a lot of performance

00:41:38,230 --> 00:41:42,640
degradation maybe there were some

00:41:40,750 --> 00:41:44,500
caching issues some mem cache server

00:41:42,640 --> 00:41:46,240
crashed causing more queries to come to

00:41:44,500 --> 00:41:47,860
the database layer which kind of

00:41:46,240 --> 00:41:50,980
overloads the database so there's a lot

00:41:47,860 --> 00:41:56,080
of stuff that comes a usually as being

00:41:50,980 --> 00:41:58,750
being seen now I've got some examples

00:41:56,080 --> 00:42:02,380
but I'll take you the most interesting

00:41:58,750 --> 00:42:04,590
one the transaction locking ok that's

00:42:02,380 --> 00:42:06,730
the one that I wanted to show like

00:42:04,590 --> 00:42:08,770
there's a lot of lock weights between

00:42:06,730 --> 00:42:11,290
each other we could see that in show

00:42:08,770 --> 00:42:13,450
global status with PT mixed there's some

00:42:11,290 --> 00:42:14,980
counters about that but we don't know

00:42:13,450 --> 00:42:16,390
what it comes from where it comes from

00:42:14,980 --> 00:42:18,700
you want to know which car is actually

00:42:16,390 --> 00:42:20,200
causing this so with the extended slow

00:42:18,700 --> 00:42:22,090
logging we can actually log all that

00:42:20,200 --> 00:42:25,150
information and you can see which

00:42:22,090 --> 00:42:26,860
transactions were locking each other but

00:42:25,150 --> 00:42:28,930
it doesn't show you which one was

00:42:26,860 --> 00:42:31,420
causing the other ones to wait it's a

00:42:28,930 --> 00:42:33,940
lot of data that you need to analyze so

00:42:31,420 --> 00:42:36,130
what we will do is we configure PT stock

00:42:33,940 --> 00:42:38,080
we write the script that looks at

00:42:36,130 --> 00:42:40,030
transaction lock weights and show ng 90

00:42:38,080 --> 00:42:43,000
DB status and as soon as their

00:42:40,030 --> 00:42:45,760
long-running transaction we captured TP

00:42:43,000 --> 00:42:47,950
TCP dump data which we can then use to

00:42:45,760 --> 00:42:49,380
actually transform into the queries and

00:42:47,950 --> 00:42:52,960
the results that were actually returned

00:42:49,380 --> 00:42:55,380
now we convert it using PT query digest

00:42:52,960 --> 00:42:57,420
so it reads the royalty freedom data

00:42:55,380 --> 00:43:00,180
and then show you some information so

00:42:57,420 --> 00:43:02,460
show engine I know TV status shows you

00:43:00,180 --> 00:43:04,500
there's an active transaction for 14

00:43:02,460 --> 00:43:06,480
seconds active but it's not doing any

00:43:04,500 --> 00:43:09,119
query so it's doing nothing sleep state

00:43:06,480 --> 00:43:11,779
and show process lists so it's not doing

00:43:09,119 --> 00:43:15,119
anything but it's having looks so it has

00:43:11,779 --> 00:43:18,299
50 lock structures and have some undo

00:43:15,119 --> 00:43:20,309
log entries so other transactions are

00:43:18,299 --> 00:43:22,259
actually waiting on that transaction to

00:43:20,309 --> 00:43:25,049
be committed but it's not happening and

00:43:22,259 --> 00:43:27,210
how can we know which transaction is

00:43:25,049 --> 00:43:29,519
actually causing that where and my code

00:43:27,210 --> 00:43:31,799
is there like a transaction being idle

00:43:29,519 --> 00:43:34,470
for a certain amount of time so because

00:43:31,799 --> 00:43:38,430
we have that TCP dump data we can filter

00:43:34,470 --> 00:43:40,619
out based on hostname and port tcp port

00:43:38,430 --> 00:43:43,109
so we can use the tread ID and the IP

00:43:40,619 --> 00:43:45,509
which show process list which will all

00:43:43,109 --> 00:43:47,309
be in the PT stall data and find out ok

00:43:45,509 --> 00:43:49,230
that was that particular port and as

00:43:47,309 --> 00:43:51,690
soon as we have that particular port we

00:43:49,230 --> 00:43:53,970
can use the TCP dump data or we can tune

00:43:51,690 --> 00:43:57,420
in with pcp dump and PT query digest and

00:43:53,970 --> 00:43:59,849
find out what was that transaction doing

00:43:57,420 --> 00:44:02,190
is it still doing something and in that

00:43:59,849 --> 00:44:04,200
case there was a loop in the transaction

00:44:02,190 --> 00:44:06,269
and in the application that was doing

00:44:04,200 --> 00:44:07,769
the same thing over and over again so it

00:44:06,269 --> 00:44:10,140
was waiting a couple of seconds maybe

00:44:07,769 --> 00:44:13,319
doing some processing in the application

00:44:10,140 --> 00:44:15,089
and then it was actually doing some

00:44:13,319 --> 00:44:17,039
queries but always the same query so

00:44:15,089 --> 00:44:19,829
that kind of helps us investigate those

00:44:17,039 --> 00:44:21,750
specific issues sorry I have to go a

00:44:19,829 --> 00:44:24,329
little fast here I usually I give this

00:44:21,750 --> 00:44:26,190
talk in an hour and a half so I managed

00:44:24,329 --> 00:44:30,890
to remove two slides in total because I

00:44:26,190 --> 00:44:33,769
couldn't cope with it so that helped us

00:44:30,890 --> 00:44:39,140
and I'm I don't know I've got one minute

00:44:33,769 --> 00:44:39,140
perfect I can show you one other example

00:44:39,349 --> 00:44:44,369
sometimes Craig pileups happens but we

00:44:42,660 --> 00:44:45,839
don't know we actually investigated for

00:44:44,369 --> 00:44:48,029
hours and we couldn't see anything

00:44:45,839 --> 00:44:49,859
suddenly I all went up but my squirrel

00:44:48,029 --> 00:44:51,269
didn't do anything my skull was like I

00:44:49,859 --> 00:44:54,299
didn't do any I oh I didn't want to do

00:44:51,269 --> 00:44:56,130
any i/o so what we did PT stock treads

00:44:54,299 --> 00:44:59,009
running bigger and 10 started collecting

00:44:56,130 --> 00:45:01,019
data because things were locking up this

00:44:59,009 --> 00:45:03,029
guy o becomes slow queries are growing

00:45:01,019 --> 00:45:05,160
slower multiple queries are running at

00:45:03,029 --> 00:45:07,650
the same time the whole thing comes to a

00:45:05,160 --> 00:45:08,990
like a normal stop but in the mem info

00:45:07,650 --> 00:45:11,550
we could actually see that

00:45:08,990 --> 00:45:13,530
ma'am info it contains multiple

00:45:11,550 --> 00:45:14,670
collections of the mem info command and

00:45:13,530 --> 00:45:17,160
we could see that right back was

00:45:14,670 --> 00:45:19,380
actually dropping 20 and then increasing

00:45:17,160 --> 00:45:21,090
again so it's a very specific problem

00:45:19,380 --> 00:45:23,970
but it really helps us understand okay

00:45:21,090 --> 00:45:26,430
there's something going on after a while

00:45:23,970 --> 00:45:28,830
we noticed that okay every time that a

00:45:26,430 --> 00:45:31,110
trigger happens so every time PT staub

00:45:28,830 --> 00:45:32,670
decided to like collect data because

00:45:31,110 --> 00:45:34,830
that treads running became bigger than

00:45:32,670 --> 00:45:36,450
10 we notice that a new binary log was

00:45:34,830 --> 00:45:39,510
being created at exactly the same time

00:45:36,450 --> 00:45:42,420
so not a coincidence right nope it

00:45:39,510 --> 00:45:47,550
wasn't binary log uses the file system

00:45:42,420 --> 00:45:51,840
cache to buffer rights ok good when a

00:45:47,550 --> 00:45:53,460
binary log is being rotated it looks at

00:45:51,840 --> 00:45:56,340
expire log days and remove some all

00:45:53,460 --> 00:45:59,550
binary locks right so they have to be

00:45:56,340 --> 00:46:01,710
deleted the customer is using extended

00:45:59,550 --> 00:46:04,350
tree file system which is really slow in

00:46:01,710 --> 00:46:06,570
deleting files so we had a binary log

00:46:04,350 --> 00:46:08,640
size of one gigabyte so deleting that

00:46:06,570 --> 00:46:10,440
file took seconds and because there was

00:46:08,640 --> 00:46:14,100
like an internal log it's called the

00:46:10,440 --> 00:46:16,380
lock lock mutex in my skull 51 in this

00:46:14,100 --> 00:46:19,620
case it was other transactions were

00:46:16,380 --> 00:46:21,990
being blocked by it so one solution is

00:46:19,620 --> 00:46:23,940
good go to XFS it's super fast in li

00:46:21,990 --> 00:46:26,480
ting it's usually best much better than

00:46:23,940 --> 00:46:29,190
extended tree as has less issues with

00:46:26,480 --> 00:46:31,410
database operations and another solution

00:46:29,190 --> 00:46:33,420
was actually let's shrink the size of

00:46:31,410 --> 00:46:36,360
viral log 250 megabytes and create more

00:46:33,420 --> 00:46:38,310
binary logs so that actually resolved

00:46:36,360 --> 00:46:39,870
despites it only had to remove 50

00:46:38,310 --> 00:46:42,540
megabytes extended free which is much

00:46:39,870 --> 00:46:44,220
much faster it did remove more but it

00:46:42,540 --> 00:46:45,930
was just smaller so that's another way

00:46:44,220 --> 00:46:48,240
that we kind of investigated how

00:46:45,930 --> 00:46:50,130
something yeah what's wrong and how we

00:46:48,240 --> 00:46:51,630
optimize this I have more examples but I

00:46:50,130 --> 00:46:53,670
can't go anymore I think I'm over time

00:46:51,630 --> 00:46:59,720
so any questions I've got more t-shirts

00:46:53,670 --> 00:46:59,720
yes ok wait for the microphone

00:47:02,610 --> 00:47:10,570
okay in order to do some reporting I

00:47:08,350 --> 00:47:12,760
have to copy probably several hundred

00:47:10,570 --> 00:47:16,390
thousand rolls from an unindexed table

00:47:12,760 --> 00:47:19,690
mm-hmm so I can join against it in in

00:47:16,390 --> 00:47:21,730
real time but I've noticed if I copy the

00:47:19,690 --> 00:47:23,620
data and then add the indexes it's much

00:47:21,730 --> 00:47:25,030
faster than if i create the table adding

00:47:23,620 --> 00:47:28,240
the indexes and then copy the data

00:47:25,030 --> 00:47:30,820
center why would that be um the reason

00:47:28,240 --> 00:47:32,560
why is that depends on how which data

00:47:30,820 --> 00:47:35,770
you insert do you insert it in order or

00:47:32,560 --> 00:47:37,930
not so you have a primary key and if you

00:47:35,770 --> 00:47:40,360
insert it in order it's easy to actually

00:47:37,930 --> 00:47:42,640
add yeah the index entries but if you

00:47:40,360 --> 00:47:44,320
have multiple indexes those indexes need

00:47:42,640 --> 00:47:46,600
to be fragmented because your it needs

00:47:44,320 --> 00:47:48,850
to update the b-tree at several

00:47:46,600 --> 00:47:51,310
different places so it becomes slower so

00:47:48,850 --> 00:47:53,710
it is a good optimization to create just

00:47:51,310 --> 00:47:56,650
the primary key insert the data and then

00:47:53,710 --> 00:47:58,060
add the indexes because then what it

00:47:56,650 --> 00:47:59,770
actually does it does read the whole

00:47:58,060 --> 00:48:02,140
table it sorts it and then creates the

00:47:59,770 --> 00:48:03,790
index so it kind of it's a longer step

00:48:02,140 --> 00:48:05,590
but it is a much more performing step

00:48:03,790 --> 00:48:10,930
actually it's a good question because

00:48:05,590 --> 00:48:12,310
our MySQL yeah our our MySQL dump has a

00:48:10,930 --> 00:48:14,260
feature in procurement server that

00:48:12,310 --> 00:48:16,000
actually does that operation and create

00:48:14,260 --> 00:48:17,980
stable without the secondary in nexus

00:48:16,000 --> 00:48:23,350
and then adds them afterwards just to

00:48:17,980 --> 00:48:25,570
make that step a much faster good here

00:48:23,350 --> 00:48:28,860
you go they're small sizes sorry about

00:48:25,570 --> 00:48:28,860
that yes question

00:48:31,590 --> 00:48:39,580
I was wondering if basically on my

00:48:35,530 --> 00:48:41,410
secret on ours RDS you can choose what

00:48:39,580 --> 00:48:43,450
Mexico distribution we want so you can

00:48:41,410 --> 00:48:45,820
install you cannot install Parker no

00:48:43,450 --> 00:48:47,740
server or Margot be and you cannot even

00:48:45,820 --> 00:48:50,380
ssh into the server so i was wondering

00:48:47,740 --> 00:48:52,930
if you have any recommendations like the

00:48:50,380 --> 00:48:55,000
b stock example what we recommend fire

00:48:52,930 --> 00:48:58,390
up another linux machine and you can

00:48:55,000 --> 00:49:00,910
configure it so it the the iOS that the

00:48:58,390 --> 00:49:02,650
like the operating system statistics it

00:49:00,910 --> 00:49:04,240
will create from that linux server but

00:49:02,650 --> 00:49:06,700
we configure my skull to connect to the

00:49:04,240 --> 00:49:09,730
RDS instance we have less metrics but we

00:49:06,700 --> 00:49:12,250
can still do all those met mysql related

00:49:09,730 --> 00:49:13,600
operations there is also the slow lock

00:49:12,250 --> 00:49:16,780
you don't have that available in our

00:49:13,600 --> 00:49:19,180
amazon RDS but you do have a log table

00:49:16,780 --> 00:49:20,830
slow lock table which is a csv table and

00:49:19,180 --> 00:49:23,230
we can easily convert that we have some

00:49:20,830 --> 00:49:25,660
scripts on our block bicycle performance

00:49:23,230 --> 00:49:27,400
blog com that actually convert that in a

00:49:25,660 --> 00:49:35,760
slow log so you can use it with PT query

00:49:27,400 --> 00:49:35,760
digest yeah thank you ok t-shirt

00:49:37,290 --> 00:49:49,420
yeah one more sure oh yeah okay see whoa

00:49:46,600 --> 00:49:52,060
why is it so much slower if you do and

00:49:49,420 --> 00:49:56,020
in on a table rather than having a

00:49:52,060 --> 00:49:58,510
couple of the same amount of items it

00:49:56,020 --> 00:50:01,210
depends it does not always mean that an

00:49:58,510 --> 00:50:03,280
in on it yeah we're in where something

00:50:01,210 --> 00:50:05,980
in and then a couple of values yeah is

00:50:03,280 --> 00:50:07,750
sometimes fast sometimes it's not

00:50:05,980 --> 00:50:10,090
depends on the optimizer it might choose

00:50:07,750 --> 00:50:12,100
to just decide okay I need to read a lot

00:50:10,090 --> 00:50:14,560
of rows any Rachel I'll just read a full

00:50:12,100 --> 00:50:16,660
table scan because i think it going it's

00:50:14,560 --> 00:50:18,400
going to be faster but in reality it is

00:50:16,660 --> 00:50:20,530
not it's it's the optimizer that made a

00:50:18,400 --> 00:50:26,410
bad decision in that case optimizer is

00:50:20,530 --> 00:50:28,120
not perfect all right okay okay yeah

00:50:26,410 --> 00:50:29,650
i'll be running around somewhere

00:50:28,120 --> 00:50:32,020
downstairs so if you want to talk to me

00:50:29,650 --> 00:50:34,180
i even have a book to give away so i can

00:50:32,020 --> 00:50:42,340
see one more question coming up is that

00:50:34,180 --> 00:50:46,060
allowed sure no question no we're done I

00:50:42,340 --> 00:50:49,210
can't give the book away then its

00:50:46,060 --> 00:50:50,800
high-performance mysql 3rd edition ok a

00:50:49,210 --> 00:50:55,060
lot of questions come to me outside

00:50:50,800 --> 00:50:57,180
because i'm getting throwed out thank

00:50:55,060 --> 00:50:57,180
you

00:51:06,650 --> 00:51:08,710

YouTube URL: https://www.youtube.com/watch?v=I7fsZB1HC8I


