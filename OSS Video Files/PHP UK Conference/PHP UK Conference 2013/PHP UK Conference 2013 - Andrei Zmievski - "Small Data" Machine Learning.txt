Title: PHP UK Conference 2013 - Andrei Zmievski - "Small Data" Machine Learning
Publication date: 2013-04-16
Playlist: PHP UK Conference 2013
Description: 
	What do you do if you have a single letter Twitter handle and your reply stream is useless due to people misusing and abusing the @ sign, like "I'm @a bar"? Machine learning to the rescue! I will explain how I used ML and a couple of other tricks to build a program that sanitizes my Twitter mentions and will hopefully inspire you to use ML in your own projects.

Slides: https://speakerdeck.com/andreiz/small-data-machine-learning
Captions: 
	00:00:08,050 --> 00:00:16,689
I work at a company called AB dynamics

00:00:10,840 --> 00:00:18,369
and we just briefly work on we have a

00:00:16,689 --> 00:00:19,810
product that as production level

00:00:18,369 --> 00:00:21,310
monitoring and troubleshooting of like

00:00:19,810 --> 00:00:23,500
mission critical business apps and

00:00:21,310 --> 00:00:25,060
that's why the picture hoop superhero

00:00:23,500 --> 00:00:27,820
there because customers consider us

00:00:25,060 --> 00:00:29,169
superheroes we're working on a PHP

00:00:27,820 --> 00:00:31,540
version of our product right now which

00:00:29,169 --> 00:00:33,190
is a PHP extension you drop into

00:00:31,540 --> 00:00:34,600
production environment and it starts

00:00:33,190 --> 00:00:36,640
collecting analyzing a source of data

00:00:34,600 --> 00:00:38,920
but your app and helping you instrument

00:00:36,640 --> 00:00:40,420
and troubleshoot and get to the root

00:00:38,920 --> 00:00:41,649
cause of the problems really quickly so

00:00:40,420 --> 00:00:45,160
if you're interested in that come talk

00:00:41,649 --> 00:00:46,390
to me afterwards but we're not here to

00:00:45,160 --> 00:00:50,829
talk about that we're here to talk about

00:00:46,390 --> 00:00:55,120
math so these slides will contain some

00:00:50,829 --> 00:00:58,600
math but don't be afraid of it because

00:00:55,120 --> 00:01:02,289
it's awesome math unless you do some

00:00:58,600 --> 00:01:06,070
really cool stuff this is my Twitter and

00:01:02,289 --> 00:01:09,580
handle for those of you who don't know

00:01:06,070 --> 00:01:14,680
already and this is both very cool and

00:01:09,580 --> 00:01:15,730
very horrible thing i got it in october

00:01:14,680 --> 00:01:17,140
two thousand eight I used to have a

00:01:15,730 --> 00:01:19,030
different one before but then through

00:01:17,140 --> 00:01:23,290
various shenanigans I was able to

00:01:19,030 --> 00:01:25,780
acquire this one and I didn't have the

00:01:23,290 --> 00:01:28,720
foresight to see what was going to come

00:01:25,780 --> 00:01:31,930
next and I know a bunch of other single

00:01:28,720 --> 00:01:34,000
letter Twitter people one of whom is

00:01:31,930 --> 00:01:38,410
here helgi if you know him he is at h

00:01:34,000 --> 00:01:39,640
but i know a bunch of others and so the

00:01:38,410 --> 00:01:43,960
advantage of heaven single twitter

00:01:39,640 --> 00:01:45,760
handle is fame apparently you people

00:01:43,960 --> 00:01:48,160
like to do saal sorts of profiles on

00:01:45,760 --> 00:01:52,000
single letter twitter handles like from

00:01:48,160 --> 00:01:53,710
A to Z the Atlantic did that Wall Street

00:01:52,000 --> 00:01:55,300
Journal came and did an article and like

00:01:53,710 --> 00:01:56,590
photographs and stuff like that unlike

00:01:55,300 --> 00:02:01,150
what wall street journal is interested

00:01:56,590 --> 00:02:03,160
in this stuff seriously followers I've

00:02:01,150 --> 00:02:04,960
like fifty-three fifty-four thousand

00:02:03,160 --> 00:02:07,510
followers right now I have no idea who

00:02:04,960 --> 00:02:11,680
they are I mean I know like a couple of

00:02:07,510 --> 00:02:13,629
hundred maybe but that's it but another

00:02:11,680 --> 00:02:15,129
advantage is maximum reply space right

00:02:13,629 --> 00:02:17,200
hundred forty characters monitor the

00:02:15,129 --> 00:02:20,020
length of AD sign a in space gives

00:02:17,200 --> 00:02:23,790
friends and other people 137 to reply

00:02:20,020 --> 00:02:26,410
back to me I feel like I'm doing them

00:02:23,790 --> 00:02:28,840
the cons are this is what my reply

00:02:26,410 --> 00:02:31,540
stream looks like most of the time it is

00:02:28,840 --> 00:02:36,280
just full of garbage and if you look at

00:02:31,540 --> 00:02:38,080
the at the times here they are all very

00:02:36,280 --> 00:02:40,209
closely spaced together so it's pretty

00:02:38,080 --> 00:02:45,310
much impossible to filter anything

00:02:40,209 --> 00:02:46,870
visually and I thought for a while about

00:02:45,310 --> 00:02:48,850
how to solve this thing it's like well

00:02:46,870 --> 00:02:50,980
maybe I'll write some sort of list of

00:02:48,850 --> 00:02:52,660
rules by which to reject or accept some

00:02:50,980 --> 00:02:54,700
of these and so on but it's really hard

00:02:52,660 --> 00:02:57,850
to do any sort of hard code the system

00:02:54,700 --> 00:02:59,560
is not going to able to adapt so I

00:02:57,850 --> 00:03:01,000
decided to use machine learning because

00:02:59,560 --> 00:03:02,560
I'm interested in that stuff and the

00:03:01,000 --> 00:03:10,060
best way to learn something is to apply

00:03:02,560 --> 00:03:11,560
it and do some sort of hack so after I

00:03:10,060 --> 00:03:13,810
wrote this little tool called replied

00:03:11,560 --> 00:03:16,300
cleaner this may not look that much

00:03:13,810 --> 00:03:18,580
different to you but in my estimate it's

00:03:16,300 --> 00:03:21,510
like eighty percent better already first

00:03:18,580 --> 00:03:24,580
of all because there is a there much

00:03:21,510 --> 00:03:26,200
less closely spaced together so I can

00:03:24,580 --> 00:03:28,600
actually visually filter through them

00:03:26,200 --> 00:03:31,299
just scroll on my phone and so on and in

00:03:28,600 --> 00:03:33,459
actual quality is improved and the way

00:03:31,299 --> 00:03:35,160
this thing works is that it uses a

00:03:33,459 --> 00:03:38,110
trained model based on a number of

00:03:35,160 --> 00:03:39,850
tweets that I've collected to classify

00:03:38,110 --> 00:03:41,560
them into good and bad ones and for bad

00:03:39,850 --> 00:03:44,350
ones it just blocks the user say like

00:03:41,560 --> 00:03:45,820
disappear from my view completely and

00:03:44,350 --> 00:03:47,920
that's because Twitter doesn't really

00:03:45,820 --> 00:03:49,780
give you a way to individually like

00:03:47,920 --> 00:03:53,350
exclude single tweets from your replies

00:03:49,780 --> 00:03:55,329
from your reply stream and so it looks

00:03:53,350 --> 00:03:56,950
much cleaner like this is an example on

00:03:55,329 --> 00:03:59,440
my phone where somebody replied to me

00:03:56,950 --> 00:04:02,709
and I was actually able to look at it

00:03:59,440 --> 00:04:04,840
even though I don't follow them and have

00:04:02,709 --> 00:04:07,060
a conversation with the person but if

00:04:04,840 --> 00:04:08,620
you look at this like there's still some

00:04:07,060 --> 00:04:11,680
even though it's readable but it's still

00:04:08,620 --> 00:04:16,209
some junk there know why people use a

00:04:11,680 --> 00:04:18,430
day and very random ways and then yeah I

00:04:16,209 --> 00:04:20,640
can you know filters are in fine stuff

00:04:18,430 --> 00:04:20,640
like that

00:04:21,600 --> 00:04:27,730
people don't believe that they are

00:04:23,410 --> 00:04:29,410
single letters exist or this stuff how

00:04:27,730 --> 00:04:31,540
can people like a day and Dixie who is

00:04:29,410 --> 00:04:36,940
the CEO of Twitter will have a million

00:04:31,540 --> 00:04:41,200
less followers so conclusion i still

00:04:36,940 --> 00:04:43,720
hate humanity just a little bit less so

00:04:41,200 --> 00:04:45,690
a machine learning machine learning is

00:04:43,720 --> 00:04:47,919
branch of artificial intelligence

00:04:45,690 --> 00:04:50,110
there's no really widely accepted

00:04:47,919 --> 00:04:51,760
definition of what it is but I kind of

00:04:50,110 --> 00:04:54,639
like this one which was given by Arthur

00:04:51,760 --> 00:04:56,350
Samuel in 1959 machine learning is a

00:04:54,639 --> 00:04:57,850
field of study that gives computer is

00:04:56,350 --> 00:05:00,310
the ability to learn without being

00:04:57,850 --> 00:05:03,010
explicitly programmed they learn based

00:05:00,310 --> 00:05:05,979
on the data that you feed them based on

00:05:03,010 --> 00:05:09,210
the experience so to say and it's used

00:05:05,979 --> 00:05:12,310
in a variety of different industries and

00:05:09,210 --> 00:05:15,520
especially the proliferation of data

00:05:12,310 --> 00:05:17,200
based like big data and data-driven

00:05:15,520 --> 00:05:19,330
analytics and everything like that for

00:05:17,200 --> 00:05:20,919
things like spam filtering which is very

00:05:19,330 --> 00:05:23,770
helpful because nobody wants to read

00:05:20,919 --> 00:05:27,310
spams this is like just a screenshot of

00:05:23,770 --> 00:05:30,030
what ends up in my spam folder I'm very

00:05:27,310 --> 00:05:32,289
thankful to gmail for that things like

00:05:30,030 --> 00:05:35,320
recommendations based on what you buy

00:05:32,289 --> 00:05:37,000
and what merchants like Amazon think you

00:05:35,320 --> 00:05:42,250
owe more on to buy based on your

00:05:37,000 --> 00:05:44,560
patterns machine translation google

00:05:42,250 --> 00:05:46,090
translate is actually a statistic uses

00:05:44,560 --> 00:05:48,820
statistical machine translation it's not

00:05:46,090 --> 00:05:51,520
rule based or example based so they have

00:05:48,820 --> 00:05:53,050
a big body of examples of source

00:05:51,520 --> 00:05:54,610
language and a target language and I do

00:05:53,050 --> 00:05:56,620
a whole bunch of analysis and machine

00:05:54,610 --> 00:05:58,600
learning of that in order to use

00:05:56,620 --> 00:06:02,919
whatever 58 languages that they support

00:05:58,600 --> 00:06:05,560
right now things like clustering this is

00:06:02,919 --> 00:06:07,000
google news example where it looks at

00:06:05,560 --> 00:06:09,030
the incoming news stories and then

00:06:07,000 --> 00:06:11,020
figures out what topics that belong to

00:06:09,030 --> 00:06:16,030
automatically and then clusters them

00:06:11,020 --> 00:06:18,190
around those topics so this is all like

00:06:16,030 --> 00:06:21,789
very cool stuff and related to big data

00:06:18,190 --> 00:06:24,130
and one of the fundamental things to

00:06:21,789 --> 00:06:26,530
understand machine learning is that one

00:06:24,130 --> 00:06:30,099
it's based on the concept of features

00:06:26,530 --> 00:06:31,960
and a feature is an individual property

00:06:30,099 --> 00:06:32,920
of something that you are observing a

00:06:31,960 --> 00:06:35,840
measuring

00:06:32,920 --> 00:06:38,660
the really easy way to explain this is

00:06:35,840 --> 00:06:41,120
if you look at the like a label

00:06:38,660 --> 00:06:45,590
nutritional facts on some type of food

00:06:41,120 --> 00:06:48,500
you can see things like you know fats

00:06:45,590 --> 00:06:49,940
cholesterol sodium carbohydrates and

00:06:48,500 --> 00:06:51,680
they all have numeric values next to

00:06:49,940 --> 00:06:53,270
them you can think of these as features

00:06:51,680 --> 00:06:56,840
that describe that particular type of

00:06:53,270 --> 00:06:59,180
food and if we take all of those and put

00:06:56,840 --> 00:07:01,040
them in an array then we get what's

00:06:59,180 --> 00:07:02,210
called a feature vector it's basically a

00:07:01,040 --> 00:07:07,160
set of features for a certain

00:07:02,210 --> 00:07:10,910
observation so as an example if we were

00:07:07,160 --> 00:07:13,220
trying to do a model that predicts house

00:07:10,910 --> 00:07:15,800
prices based on some parameters or

00:07:13,220 --> 00:07:17,750
features of the house we may come up

00:07:15,800 --> 00:07:19,850
with things like how many rooms does it

00:07:17,750 --> 00:07:22,100
have what's the square footage of the

00:07:19,850 --> 00:07:27,590
house how old is it doesn't have a yard

00:07:22,100 --> 00:07:30,710
and so on and for each one when we can

00:07:27,590 --> 00:07:32,840
when we have that feature vector if we

00:07:30,710 --> 00:07:37,730
also derive some sort of weights that

00:07:32,840 --> 00:07:41,360
apply to each feature so let's say these

00:07:37,730 --> 00:07:43,700
weights are priced based on like

00:07:41,360 --> 00:07:46,070
hundreds of hundred thousand dollars so

00:07:43,700 --> 00:07:47,180
if if each room gives you approximately

00:07:46,070 --> 00:07:48,680
one hundred and two thousand dollars

00:07:47,180 --> 00:07:52,400
increases the price of a house by that

00:07:48,680 --> 00:07:55,730
or each year of the house age decreases

00:07:52,400 --> 00:07:57,920
by ten thousand and so on so you take

00:07:55,730 --> 00:07:59,360
the features in the weights but before

00:07:57,920 --> 00:08:01,070
you do that there's one more thing that

00:07:59,360 --> 00:08:05,710
the usually is usually done is that you

00:08:01,070 --> 00:08:07,760
pad them and for you basically add one

00:08:05,710 --> 00:08:10,130
prepend one to the feature vector

00:08:07,760 --> 00:08:14,780
because that corresponds to this sort of

00:08:10,130 --> 00:08:18,950
offset wait it's a it's starting weight

00:08:14,780 --> 00:08:21,170
and then you use dot product to multiply

00:08:18,950 --> 00:08:23,060
them and you get your prediction now

00:08:21,170 --> 00:08:25,100
here's where a little bit of math comes

00:08:23,060 --> 00:08:26,420
in is the first slide for those of you

00:08:25,100 --> 00:08:29,480
who don't remember what the dot product

00:08:26,420 --> 00:08:33,080
is it looks something like this right we

00:08:29,480 --> 00:08:35,660
have our input array of various features

00:08:33,080 --> 00:08:37,430
with the one in front and theta is

00:08:35,660 --> 00:08:38,960
usually denotes the weights for those

00:08:37,430 --> 00:08:41,660
features they're also called parameters

00:08:38,960 --> 00:08:43,969
and it's actually really easy all it is

00:08:41,660 --> 00:08:47,110
is you take the pairs of those you

00:08:43,969 --> 00:08:47,110
multiply them together and you

00:08:47,910 --> 00:08:57,930
that's it that's a dot product with me

00:08:53,200 --> 00:09:00,310
so far okay good i see nodding heads now

00:08:57,930 --> 00:09:03,880
the goal of what you want to do is to

00:09:00,310 --> 00:09:08,380
take a body of some training data that

00:09:03,880 --> 00:09:10,210
you already have examples of so things

00:09:08,380 --> 00:09:11,860
like if you're trying to do spam

00:09:10,210 --> 00:09:13,930
filtering it would be a whole bunch of

00:09:11,860 --> 00:09:15,910
emails and then to sort of label that

00:09:13,930 --> 00:09:20,410
says whether it's a good or bad email

00:09:15,910 --> 00:09:21,970
and you so you feed that into some sort

00:09:20,410 --> 00:09:23,740
of learning algorithm and their various

00:09:21,970 --> 00:09:25,570
types of learning algorithms will will

00:09:23,740 --> 00:09:27,550
mention just one in this one like one of

00:09:25,570 --> 00:09:29,080
the simplest ones but what comes out of

00:09:27,550 --> 00:09:31,960
the learning algorithm is what's called

00:09:29,080 --> 00:09:35,050
a hypothesis or it's also called

00:09:31,960 --> 00:09:37,000
decision function sometimes and the

00:09:35,050 --> 00:09:40,150
hypothesis represents what the system

00:09:37,000 --> 00:09:41,650
has learned so far and then once you

00:09:40,150 --> 00:09:43,570
have your hypothesis you can take it and

00:09:41,650 --> 00:09:47,230
apply to new data and make predictions

00:09:43,570 --> 00:09:49,690
based based on this train model if you

00:09:47,230 --> 00:09:51,880
feed it new data you can classify it to

00:09:49,690 --> 00:09:59,680
you know whatever number of categories

00:09:51,880 --> 00:10:03,690
you decide so hypothesis is usually it's

00:09:59,680 --> 00:10:06,760
usually written as a function age-based

00:10:03,690 --> 00:10:09,190
with the input X and parameterize by

00:10:06,760 --> 00:10:11,770
this theta so this is the input data

00:10:09,190 --> 00:10:14,710
this is our feature vectors and or

00:10:11,770 --> 00:10:17,680
training data these are the parameters

00:10:14,710 --> 00:10:21,400
those weights and what comes out here is

00:10:17,680 --> 00:10:24,490
the prediction why now the task of our

00:10:21,400 --> 00:10:27,490
algorithm that we want to do we want to

00:10:24,490 --> 00:10:29,050
apply to this is to determine the best

00:10:27,490 --> 00:10:34,470
parameters to give us the best

00:10:29,050 --> 00:10:36,910
prediction there are a couple of

00:10:34,470 --> 00:10:38,560
learning algorithms this is probably the

00:10:36,910 --> 00:10:40,090
simplest one called linear regression

00:10:38,560 --> 00:10:42,400
and it applies when you have a

00:10:40,090 --> 00:10:45,730
relationship of some sort between one or

00:10:42,400 --> 00:10:47,830
more input variables and an output

00:10:45,730 --> 00:10:49,600
variable and in the simplest case you

00:10:47,830 --> 00:10:51,040
just have one input and one output so in

00:10:49,600 --> 00:10:53,710
this case let's say I have some sort of

00:10:51,040 --> 00:10:56,290
training data i looked at my collection

00:10:53,710 --> 00:10:57,820
of whiskeys and so on right and i see ok

00:10:56,290 --> 00:10:59,710
on the horizontal i'm going to have my

00:10:57,820 --> 00:11:02,170
whiskey age which is the input and on

00:10:59,710 --> 00:11:05,290
the vertical I have a whiskey price in

00:11:02,170 --> 00:11:09,550
dollars and so I just mapped them and

00:11:05,290 --> 00:11:12,070
now I want to fit a line through this

00:11:09,550 --> 00:11:16,120
that no Fitz it in the best light

00:11:12,070 --> 00:11:17,350
possible to minimize the errors so if we

00:11:16,120 --> 00:11:19,690
fit the line it might look something

00:11:17,350 --> 00:11:21,720
like this and now that we have this line

00:11:19,690 --> 00:11:24,240
that a certain slope certain inclination

00:11:21,720 --> 00:11:26,650
we can use it to make predictions about

00:11:24,240 --> 00:11:28,330
whiskey's I don't have yet so for

00:11:26,650 --> 00:11:31,090
example I don't have any data for 25

00:11:28,330 --> 00:11:35,500
year old whiskey's right but now that we

00:11:31,090 --> 00:11:36,790
have this line we can trace it and see

00:11:35,500 --> 00:11:40,390
that it comes out to be about one

00:11:36,790 --> 00:11:42,760
hundred forty dollars or so you know it

00:11:40,390 --> 00:11:44,770
may not be entirely accurate but this is

00:11:42,760 --> 00:11:48,490
what it is based on the data that I fed

00:11:44,770 --> 00:11:50,530
through this model now the problem is

00:11:48,490 --> 00:11:54,070
that linear regression works pretty well

00:11:50,530 --> 00:11:57,280
for numeric cases where you have some

00:11:54,070 --> 00:11:58,840
server out put like price or temperature

00:11:57,280 --> 00:12:00,970
or whatever but it doesn't work railway

00:11:58,840 --> 00:12:02,590
want to classify things like into good

00:12:00,970 --> 00:12:05,560
or bad and so on and the problem is that

00:12:02,590 --> 00:12:08,500
the output of linear regression it's

00:12:05,560 --> 00:12:10,810
unbounded it's just a domain of the

00:12:08,500 --> 00:12:14,410
whole like real numbers right what we

00:12:10,810 --> 00:12:16,120
want is just 0 1 mostly and you can

00:12:14,410 --> 00:12:18,040
threshold it let's say okay if it's

00:12:16,120 --> 00:12:19,540
above 80 then I'm going to consider that

00:12:18,040 --> 00:12:21,430
good or if it's below 80 I'm going to

00:12:19,540 --> 00:12:25,000
consider that bad but it doesn't work

00:12:21,430 --> 00:12:29,130
very well in practice so there's another

00:12:25,000 --> 00:12:31,810
algorithm called logistic regression and

00:12:29,130 --> 00:12:34,350
it uses this special function called

00:12:31,810 --> 00:12:36,460
sigmoid function or logistic function

00:12:34,350 --> 00:12:43,410
because it looks sort of like letter s

00:12:36,460 --> 00:12:46,000
and it's very useful for us because it

00:12:43,410 --> 00:12:48,460
transforms its input to be contained

00:12:46,000 --> 00:12:51,760
between 0 and 1 and so if you look at

00:12:48,460 --> 00:12:54,100
like its approaches 1 as the greater the

00:12:51,760 --> 00:12:59,710
Z becomes and approaches 0 the less than

00:12:54,100 --> 00:13:02,170
C becomes and that way once you apply

00:12:59,710 --> 00:13:04,180
some sort of input to this and get a

00:13:02,170 --> 00:13:08,140
number number between 0 1 you can

00:13:04,180 --> 00:13:12,610
threshold it on whatever value you want

00:13:08,140 --> 00:13:14,260
and in this case what is Z that's just

00:13:12,610 --> 00:13:20,050
our dog product that prediction that

00:13:14,260 --> 00:13:22,720
we're making so if we just substitute

00:13:20,050 --> 00:13:24,580
that back in this is our hypothesis this

00:13:22,720 --> 00:13:26,830
is our decision function that we're

00:13:24,580 --> 00:13:28,330
going to use and so if you want to think

00:13:26,830 --> 00:13:32,110
about it more intuitively what it gives

00:13:28,330 --> 00:13:34,120
you is the probability that let's say y

00:13:32,110 --> 00:13:36,940
equals 1 so something is it good and

00:13:34,120 --> 00:13:40,390
then our good class for a certain input

00:13:36,940 --> 00:13:42,250
X and that's this is called logistic

00:13:40,390 --> 00:13:44,530
regression so for example if your

00:13:42,250 --> 00:13:47,350
hypothesis is this email spam or not and

00:13:44,530 --> 00:13:48,760
it gives you 0.7 output that means there

00:13:47,350 --> 00:13:50,920
are seventy percent chances this is a

00:13:48,760 --> 00:13:53,050
spam and it's up to you to decide okay

00:13:50,920 --> 00:13:54,970
do actually what's my threshold is it

00:13:53,050 --> 00:13:56,680
seventy percent is it fifty percent and

00:13:54,970 --> 00:13:58,630
so on depending on how many false

00:13:56,680 --> 00:14:03,040
positives or negatives you want to

00:13:58,630 --> 00:14:06,790
exclude so building actual tool what

00:14:03,040 --> 00:14:08,770
goes into that well we want the training

00:14:06,790 --> 00:14:11,200
data or what's called the corpus that we

00:14:08,770 --> 00:14:14,380
want to try now log algorithm on and

00:14:11,200 --> 00:14:18,120
corpus is a collection of data use for

00:14:14,380 --> 00:14:18,120
training and testing the model as well

00:14:18,330 --> 00:14:22,900
since this is not big data I don't need

00:14:21,460 --> 00:14:24,910
a whole lot of it I don't need like

00:14:22,900 --> 00:14:27,100
millions and billions of various

00:14:24,910 --> 00:14:30,990
training examples so what I did I use

00:14:27,100 --> 00:14:33,340
the library called fire hose which is

00:14:30,990 --> 00:14:36,490
can be used to hook into Twitter's

00:14:33,340 --> 00:14:38,260
streaming API and so with a little thing

00:14:36,490 --> 00:14:41,140
that SAT there and just download with my

00:14:38,260 --> 00:14:42,610
reply stream into MongoDB which is

00:14:41,140 --> 00:14:44,710
really useful because it just works with

00:14:42,610 --> 00:14:49,930
JSON data and Twitter sending json data

00:14:44,710 --> 00:14:51,700
back so i got about 8,500 tweets from my

00:14:49,930 --> 00:14:54,100
reply stream took a little bit of time

00:14:51,700 --> 00:14:56,140
maybe a couple of weeks or so because

00:14:54,100 --> 00:14:58,060
even with all the garbage that comes

00:14:56,140 --> 00:15:02,650
into it it's not actually that prolific

00:14:58,060 --> 00:15:05,100
right so now that i had this I needed to

00:15:02,650 --> 00:15:09,910
derive my features all my training

00:15:05,100 --> 00:15:11,560
training points from that and when you

00:15:09,910 --> 00:15:12,940
when you try to figure out what sort of

00:15:11,560 --> 00:15:14,830
features you can extract from your

00:15:12,940 --> 00:15:16,769
training data you want to make them

00:15:14,830 --> 00:15:19,709
independent and discriminant

00:15:16,769 --> 00:15:21,360
we're running by that well independent

00:15:19,709 --> 00:15:23,970
means that it feature a should not

00:15:21,360 --> 00:15:27,149
co-occur with feature be too frequently

00:15:23,970 --> 00:15:29,429
it shouldn't be correlated with that so

00:15:27,149 --> 00:15:31,709
and thus criminal means that each

00:15:29,429 --> 00:15:35,579
particular feature should give you some

00:15:31,709 --> 00:15:38,100
sort of valuable data about the whole

00:15:35,579 --> 00:15:40,739
observation and should give you some

00:15:38,100 --> 00:15:43,259
uniquely classifiable thing so for

00:15:40,739 --> 00:15:46,529
example if the if you decide to have a

00:15:43,259 --> 00:15:49,350
feature is make a feature out of the

00:15:46,529 --> 00:15:51,509
first letter of the tweet like that's

00:15:49,350 --> 00:15:53,549
not actually discriminant because it

00:15:51,509 --> 00:15:55,199
doesn't give you you know classifiable

00:15:53,549 --> 00:15:56,519
data you can't say that just because the

00:15:55,199 --> 00:15:58,739
tweet starts with the letter B it's

00:15:56,519 --> 00:16:00,660
going to be bad or good you want to have

00:15:58,739 --> 00:16:04,949
something that actually helps you make a

00:16:00,660 --> 00:16:07,949
decision here are some of the possible

00:16:04,949 --> 00:16:09,989
features that came up after sort of

00:16:07,949 --> 00:16:11,759
looking visually and analyzing which

00:16:09,989 --> 00:16:16,170
tweets were good which were bad I

00:16:11,759 --> 00:16:18,360
noticed that for the bad ones a lot of

00:16:16,170 --> 00:16:20,220
times that a was at the very end of the

00:16:18,360 --> 00:16:23,569
tweet or if it was followed by three

00:16:20,220 --> 00:16:26,579
dots it was sometimes it was very short

00:16:23,569 --> 00:16:28,920
or had a lot of user mentions in the

00:16:26,579 --> 00:16:30,389
Tweed a lot of hashtags language was

00:16:28,920 --> 00:16:32,850
very important like what language tweet

00:16:30,389 --> 00:16:34,379
was written in and a bunch of others

00:16:32,850 --> 00:16:36,899
them not sharing here but these were

00:16:34,379 --> 00:16:39,389
mine sort of sample space with features

00:16:36,899 --> 00:16:41,759
i wanted to consider so once i had these

00:16:39,389 --> 00:16:44,879
then i just throw talo function that I

00:16:41,759 --> 00:16:46,350
give you the tweet and it it extracts

00:16:44,879 --> 00:16:49,259
this feature using back some sort of

00:16:46,350 --> 00:16:51,149
numeric value and you can pretty much

00:16:49,259 --> 00:16:54,509
transform anything into a number right

00:16:51,149 --> 00:16:57,230
whether it's a boolean or even a string

00:16:54,509 --> 00:16:59,699
you can make a number out of it and

00:16:57,230 --> 00:17:04,470
that's good usually one floating point

00:16:59,699 --> 00:17:06,089
values for this stuff and then you take

00:17:04,470 --> 00:17:08,549
your corpus you run and throw these

00:17:06,089 --> 00:17:10,770
extractors for features and you get back

00:17:08,549 --> 00:17:14,069
a whole number of feature vectors so

00:17:10,770 --> 00:17:16,500
basically if a big array of smaller

00:17:14,069 --> 00:17:19,289
arrays one for each of the observation

00:17:16,500 --> 00:17:24,270
so I had 8500 of these for each tweet

00:17:19,289 --> 00:17:27,240
and just save it to database mentioned

00:17:24,270 --> 00:17:29,480
language and that's that was the one of

00:17:27,240 --> 00:17:35,150
the most important features actually to

00:17:29,480 --> 00:17:37,370
get right because for example if I see

00:17:35,150 --> 00:17:40,690
that Indonesian 02 gala language it's

00:17:37,370 --> 00:17:43,700
probably garbage I ran a little bit of

00:17:40,690 --> 00:17:46,400
just analysis on the older 8500 tweets

00:17:43,700 --> 00:17:49,940
and if you if you look at it you'll see

00:17:46,400 --> 00:17:53,030
that Indonesian is like there are more

00:17:49,940 --> 00:17:57,380
tweets in that event in English and or

00:17:53,030 --> 00:17:58,640
like Somalian or Swahili I guarantee you

00:17:57,380 --> 00:18:01,280
nobody's really tweeting at me in

00:17:58,640 --> 00:18:04,280
Swahili or Somalia like nobody's

00:18:01,280 --> 00:18:07,910
actually saying hey at a la blah blah

00:18:04,280 --> 00:18:10,669
blah so I eat it like this was this was

00:18:07,910 --> 00:18:17,090
useful data to use in classifying tweets

00:18:10,669 --> 00:18:19,400
now Twitter doesn't really give you a

00:18:17,090 --> 00:18:20,780
way to know what the language tweeted

00:18:19,400 --> 00:18:24,620
the tweet is written so you have to do

00:18:20,780 --> 00:18:26,270
some sort of language detection you

00:18:24,620 --> 00:18:28,700
can't trust the language field in the

00:18:26,270 --> 00:18:30,169
users profile there's a field that says

00:18:28,700 --> 00:18:31,270
like what language they speak or

00:18:30,169 --> 00:18:33,650
whatever which country they're from

00:18:31,270 --> 00:18:35,150
because there's many examples where it

00:18:33,650 --> 00:18:36,950
was just said English and they were

00:18:35,150 --> 00:18:40,780
actually using you know Indonesian or

00:18:36,950 --> 00:18:43,730
something so you have to use tools like

00:18:40,780 --> 00:18:45,140
impair this text language detect or in

00:18:43,730 --> 00:18:51,919
Pekel there's a new extension called

00:18:45,140 --> 00:18:54,200
text cat which uses trigram analysis and

00:18:51,919 --> 00:18:56,390
tries to figure out with some

00:18:54,200 --> 00:18:58,490
probability what it would a text a

00:18:56,390 --> 00:19:02,540
certain what languages certain piece of

00:18:58,490 --> 00:19:03,980
text is written in and this took a

00:19:02,540 --> 00:19:07,790
little bit of time to get right because

00:19:03,980 --> 00:19:10,160
it's not like it's not certain that this

00:19:07,790 --> 00:19:11,660
is the right language so I and sometimes

00:19:10,160 --> 00:19:12,890
you says oh I give up I don't know what

00:19:11,660 --> 00:19:16,790
this is and then you have to make some

00:19:12,890 --> 00:19:18,710
sort of decision based on that but once

00:19:16,790 --> 00:19:20,809
once I got through that then I actually

00:19:18,710 --> 00:19:22,669
had to do this manual classification I

00:19:20,809 --> 00:19:24,559
have to go through pretty much all of

00:19:22,669 --> 00:19:26,630
those tweets and say are these good or

00:19:24,559 --> 00:19:28,429
bad well thankfully only a certain

00:19:26,630 --> 00:19:30,830
number of their own the small number

00:19:28,429 --> 00:19:33,410
we're good so I told this little tool

00:19:30,830 --> 00:19:36,950
using Twitter what's called bootstrap

00:19:33,410 --> 00:19:38,570
yeah which lets people like me who don't

00:19:36,950 --> 00:19:41,870
want to do any sort of visual design to

00:19:38,570 --> 00:19:43,070
just make something work so this just

00:19:41,870 --> 00:19:45,649
throws up tweets from

00:19:43,070 --> 00:19:47,570
database and I can quickly scan and see

00:19:45,649 --> 00:19:50,299
okay this is actually a good one lesbian

00:19:47,570 --> 00:19:51,649
or we tweeted me saying a visiting any

00:19:50,299 --> 00:19:53,929
of the trappist breweries monasteries

00:19:51,649 --> 00:19:56,029
like okay this is a good one go to the

00:19:53,929 --> 00:19:59,000
next page next page and so on so this

00:19:56,029 --> 00:20:01,970
was tedious tedious work for about one

00:19:59,000 --> 00:20:04,580
of several hours but once I was done

00:20:01,970 --> 00:20:06,320
with this I had my inputs which were the

00:20:04,580 --> 00:20:09,559
feature vectors that I extracted from

00:20:06,320 --> 00:20:11,440
the training data and I had my labels

00:20:09,559 --> 00:20:16,700
are they good or bad that's my output

00:20:11,440 --> 00:20:19,299
now that I had this I was almost ready

00:20:16,700 --> 00:20:21,860
and I say almost because there is a

00:20:19,299 --> 00:20:24,470
fairly big problem with the training

00:20:21,860 --> 00:20:29,600
data that I collected and that's the

00:20:24,470 --> 00:20:32,629
problem is that it was very biased the

00:20:29,600 --> 00:20:34,690
number of the bad tweets far outweighed

00:20:32,629 --> 00:20:37,220
the number of the good ones it was like

00:20:34,690 --> 00:20:41,059
one or two percent only were good and

00:20:37,220 --> 00:20:42,799
the rest were bad so if you just fed

00:20:41,059 --> 00:20:44,360
this into the learning algorithm as is

00:20:42,799 --> 00:20:47,419
it would actually not give you very good

00:20:44,360 --> 00:20:50,509
outputs because it's so biased so we

00:20:47,419 --> 00:20:56,179
need to adjust this bias so that they're

00:20:50,509 --> 00:20:58,250
approximately equal now there are two

00:20:56,179 --> 00:21:02,509
ways of doing that one is called over

00:20:58,250 --> 00:21:04,820
sampling and this is where you take the

00:21:02,509 --> 00:21:07,879
smaller subset and you multiply it and

00:21:04,820 --> 00:21:09,679
make multiple copies of it until it's

00:21:07,879 --> 00:21:12,440
you know about equal in size to the

00:21:09,679 --> 00:21:14,539
other class the problem with this is

00:21:12,440 --> 00:21:16,610
that the bias was so high that if I took

00:21:14,539 --> 00:21:18,289
those hundred of 200 to eat so whatever

00:21:16,610 --> 00:21:20,120
and just copy them around that it would

00:21:18,289 --> 00:21:23,330
also not give you a whole lot of good

00:21:20,120 --> 00:21:26,690
data it wouldn't contribute a lot of

00:21:23,330 --> 00:21:29,860
variance to the to the classes and the

00:21:26,690 --> 00:21:32,690
other one is called under sampling and

00:21:29,860 --> 00:21:35,419
this is sort of the opposite you look at

00:21:32,690 --> 00:21:38,120
the large class and you drop most of

00:21:35,419 --> 00:21:40,039
that data so that the remaining

00:21:38,120 --> 00:21:43,129
remainder is kind of equal to the other

00:21:40,039 --> 00:21:45,799
class the problem with this is that if I

00:21:43,129 --> 00:21:47,539
did that my total corpus would end up

00:21:45,799 --> 00:21:49,070
being like three or four hundred tweets

00:21:47,539 --> 00:21:51,429
and that's not small data that's tiny

00:21:49,070 --> 00:21:51,429
data

00:21:51,590 --> 00:21:56,900
so a solution was to use something

00:21:54,470 --> 00:21:59,120
called synthetic over sampling and this

00:21:56,900 --> 00:22:02,559
is where instead of just blindly taking

00:21:59,120 --> 00:22:05,299
the small class and multiplying it I

00:22:02,559 --> 00:22:08,330
synthesized like I basically make up

00:22:05,299 --> 00:22:11,240
feature vectors by sort of predicting

00:22:08,330 --> 00:22:13,610
what constitutes a good tweet right so

00:22:11,240 --> 00:22:15,620
you can I can with some variance is some

00:22:13,610 --> 00:22:17,390
random randomness throw in so i can say

00:22:15,620 --> 00:22:19,070
that ninety percent of the time a good

00:22:17,390 --> 00:22:22,250
tweet you'll be in one of these

00:22:19,070 --> 00:22:24,860
languages that I understand and or it's

00:22:22,250 --> 00:22:26,659
two percent of the time it's the good

00:22:24,860 --> 00:22:29,240
sweet actually does have at a at the end

00:22:26,659 --> 00:22:33,350
and so on and so I basically I make up

00:22:29,240 --> 00:22:36,320
these feature vectors and add them to my

00:22:33,350 --> 00:22:41,710
good class and that way I have enough

00:22:36,320 --> 00:22:41,710
variance to help the learning algorithm

00:22:43,659 --> 00:22:49,399
so now that we have the inputs the

00:22:46,850 --> 00:22:52,640
outputs and the bias correction is done

00:22:49,399 --> 00:22:54,279
there approximately equal in size we

00:22:52,640 --> 00:22:56,899
need to do they actually train the model

00:22:54,279 --> 00:23:00,890
so how do we actually determine these

00:22:56,899 --> 00:23:02,330
weights for each feature well the first

00:23:00,890 --> 00:23:05,600
thing we need to look at is something

00:23:02,330 --> 00:23:07,730
called a cost function and this measures

00:23:05,600 --> 00:23:10,730
how far the prediction of the system is

00:23:07,730 --> 00:23:12,620
from reality so it will give you some of

00:23:10,730 --> 00:23:14,990
our output and then you need to measure

00:23:12,620 --> 00:23:17,720
how far does it actually correspond to

00:23:14,990 --> 00:23:21,080
what you said it in the first place and

00:23:17,720 --> 00:23:25,370
the cost depends on the parameters of

00:23:21,080 --> 00:23:29,230
your of your model the less the cost the

00:23:25,370 --> 00:23:29,230
closer way out to the ideal parameters

00:23:29,860 --> 00:23:39,919
more math this is just sort of analyst

00:23:36,559 --> 00:23:42,350
tration that says the cost function you

00:23:39,919 --> 00:23:44,240
give it the hypothesis what what the

00:23:42,350 --> 00:23:47,480
model has learned and the actual data

00:23:44,240 --> 00:23:49,669
which is why the labels and you just go

00:23:47,480 --> 00:23:51,470
through all your training examples and

00:23:49,669 --> 00:23:53,630
sum them up and average them out and

00:23:51,470 --> 00:23:59,539
that's your cost averaged over all the

00:23:53,630 --> 00:24:00,980
training examples and for logistic

00:23:59,539 --> 00:24:03,799
function the cost turns out to be

00:24:00,980 --> 00:24:04,640
something like this if the if the class

00:24:03,799 --> 00:24:07,820
is zero

00:24:04,640 --> 00:24:11,180
then it's that function and the classes

00:24:07,820 --> 00:24:13,880
one it's that function question like why

00:24:11,180 --> 00:24:16,160
is it specifically this well if you

00:24:13,880 --> 00:24:20,030
graph them out they'll look something

00:24:16,160 --> 00:24:21,500
like this and the idea here is that if

00:24:20,030 --> 00:24:23,240
for the correct guess when a system

00:24:21,500 --> 00:24:26,090
guesses correctly the cost that should

00:24:23,240 --> 00:24:29,840
be 0 but when it guesses incorrectly the

00:24:26,090 --> 00:24:32,720
cost should be huge and these functions

00:24:29,840 --> 00:24:34,670
if you look at them if the if the

00:24:32,720 --> 00:24:36,920
correct prediction is 0 and it guesses

00:24:34,670 --> 00:24:38,450
correctly cost is zero but if I guess is

00:24:36,920 --> 00:24:41,090
incorrectly that's like asymptotically

00:24:38,450 --> 00:24:44,350
infinity basically it's a huge cost so

00:24:41,090 --> 00:24:47,390
we penalize it for incorrect guesses

00:24:44,350 --> 00:24:55,310
same for the other example but you know

00:24:47,390 --> 00:24:58,370
in bird so the goal of our algorithm is

00:24:55,310 --> 00:25:00,500
to minimize this cost over this over

00:24:58,370 --> 00:25:02,780
these parameters or weights we want to

00:25:00,500 --> 00:25:06,740
find the best values of theta that

00:25:02,780 --> 00:25:09,800
minimize this cost and the algorithm

00:25:06,740 --> 00:25:15,770
that is one of the simpler ones to use

00:25:09,800 --> 00:25:17,840
is called gradient descent and it to

00:25:15,770 --> 00:25:20,240
think about it intuitively imagine you

00:25:17,840 --> 00:25:22,370
have like a hilly surface of some sort

00:25:20,240 --> 00:25:24,020
and you're standing in certain point of

00:25:22,370 --> 00:25:26,420
that surface and you want to get down to

00:25:24,020 --> 00:25:28,580
the lowest point so what you do is you

00:25:26,420 --> 00:25:31,010
sort of look around and find the

00:25:28,580 --> 00:25:33,650
steepest decline and you take a step in

00:25:31,010 --> 00:25:35,810
that direction and then you repeat that

00:25:33,650 --> 00:25:37,670
you look around again and you like okay

00:25:35,810 --> 00:25:39,980
so this is the sepa direct direction now

00:25:37,670 --> 00:25:42,110
and you take another step and eventually

00:25:39,980 --> 00:25:44,360
if your repeated enough times you'll end

00:25:42,110 --> 00:25:46,580
up at some low point and I'm not so

00:25:44,360 --> 00:25:49,090
you'll nap at the lowest point because

00:25:46,580 --> 00:25:51,890
it's not a global minimum necessarily

00:25:49,090 --> 00:25:54,290
but you'll end up at a lowest point

00:25:51,890 --> 00:25:56,750
possible for your starting point notice

00:25:54,290 --> 00:25:57,950
that in this example we have two

00:25:56,750 --> 00:26:00,470
different starting points and they'd

00:25:57,950 --> 00:26:04,100
lead us to two different minimums and

00:26:00,470 --> 00:26:05,930
that's okay I mean it's not much we can

00:26:04,100 --> 00:26:08,540
do here if we with this specific

00:26:05,930 --> 00:26:12,620
algorithm but it is one of the simplest

00:26:08,540 --> 00:26:15,230
ones to explain and the general equation

00:26:12,620 --> 00:26:17,120
for how this algorithm works

00:26:15,230 --> 00:26:19,340
is something like this which I'll

00:26:17,120 --> 00:26:22,340
explain in pieces so these are the

00:26:19,340 --> 00:26:25,210
parameters is each each parameter

00:26:22,340 --> 00:26:31,120
depending on how many features we have

00:26:25,210 --> 00:26:34,910
we update it this is the learning rate

00:26:31,120 --> 00:26:36,799
for our system and this controls how big

00:26:34,910 --> 00:26:41,450
of a step to take you can take a big

00:26:36,799 --> 00:26:43,340
step you can take a small step and if

00:26:41,450 --> 00:26:45,350
the learning rate is big you have

00:26:43,340 --> 00:26:48,770
aggressive descent but you may sort of

00:26:45,350 --> 00:26:50,570
overshoot the minimum and dub kind of

00:26:48,770 --> 00:26:54,020
bouncing back and forth or even like out

00:26:50,570 --> 00:26:55,940
of the valley completely and if it's too

00:26:54,020 --> 00:26:57,710
small it might take too long because

00:26:55,940 --> 00:26:59,330
they have tiny steps you take tiny steps

00:26:57,710 --> 00:27:03,740
and you know you have to do hundred

00:26:59,330 --> 00:27:05,059
thousand or more and this is just just

00:27:03,740 --> 00:27:08,360
says this is the slow this is the

00:27:05,059 --> 00:27:09,830
incline or decline if you want of at

00:27:08,360 --> 00:27:13,540
this at the current point for this

00:27:09,830 --> 00:27:16,850
particular feature so this is our slope

00:27:13,540 --> 00:27:19,610
how steep it is and in what direction so

00:27:16,850 --> 00:27:22,400
this could take this and you keep doing

00:27:19,610 --> 00:27:25,160
this for a number of iterations or until

00:27:22,400 --> 00:27:27,860
your cost is different for each step is

00:27:25,160 --> 00:27:31,880
below a threshold of some sort so it

00:27:27,860 --> 00:27:34,700
converges another way to sort of monitor

00:27:31,880 --> 00:27:36,650
your progress is used you graph out your

00:27:34,700 --> 00:27:37,850
cost function and if if it starts

00:27:36,650 --> 00:27:40,730
approaching zero and even you know

00:27:37,850 --> 00:27:44,210
you're in the you getting you're going

00:27:40,730 --> 00:27:45,830
in the right direction so this is the

00:27:44,210 --> 00:27:50,240
final update algorithm right it looks

00:27:45,830 --> 00:27:52,100
how complicated but this is this is it

00:27:50,240 --> 00:27:55,490
for logistic function we're basically

00:27:52,100 --> 00:27:57,770
for each parameter we subtract this

00:27:55,490 --> 00:28:05,690
learning rate multiplied by this number

00:27:57,770 --> 00:28:08,570
which is basically our car our slope

00:28:05,690 --> 00:28:14,900
that we calculate over all the training

00:28:08,570 --> 00:28:16,820
samples and so let's just take it a

00:28:14,900 --> 00:28:18,679
small a quick example let's say we only

00:28:16,820 --> 00:28:21,049
have one feature so this is these are

00:28:18,679 --> 00:28:23,540
our and we only have two samples in our

00:28:21,049 --> 00:28:25,130
set so we have one with number 12 and

00:28:23,540 --> 00:28:26,960
minus 3 and a half

00:28:25,130 --> 00:28:30,620
we pad those with ones at the beginning

00:28:26,960 --> 00:28:33,520
rate and the first time will consider

00:28:30,620 --> 00:28:36,680
good and the other one will consider bad

00:28:33,520 --> 00:28:38,630
so and we'll just randomly start with

00:28:36,680 --> 00:28:42,080
the weights being point 1 and point one

00:28:38,630 --> 00:28:46,700
for each one and let's say learning rate

00:28:42,080 --> 00:28:48,830
is point zero five right so we calculate

00:28:46,700 --> 00:28:52,220
the hypothesis for the first one that's

00:28:48,830 --> 00:28:54,010
that sigmoid logistic function would do

00:28:52,220 --> 00:28:56,330
the dot product and then put it in and

00:28:54,010 --> 00:28:59,090
it comes out to be like point seven

00:28:56,330 --> 00:29:03,830
eight six and this is for the other for

00:28:59,090 --> 00:29:05,330
the second sample point for 38 and this

00:29:03,830 --> 00:29:07,670
is our temporary value that we're going

00:29:05,330 --> 00:29:09,890
to save the calculation into because we

00:29:07,670 --> 00:29:12,590
don't we don't want to update our theta

00:29:09,890 --> 00:29:16,940
array yet because we're still using it

00:29:12,590 --> 00:29:20,480
in calculating the hypothesis so that's

00:29:16,940 --> 00:29:23,000
that previous slides example equation

00:29:20,480 --> 00:29:25,490
just what substituted stuff ends so our

00:29:23,000 --> 00:29:27,410
current one minus point zero five which

00:29:25,490 --> 00:29:32,420
is the learning rate and then this is

00:29:27,410 --> 00:29:36,110
the sum over the both of the ones and if

00:29:32,420 --> 00:29:37,640
you just plug the numbers in it comes

00:29:36,110 --> 00:29:40,280
out to be point zero at a that's our

00:29:37,640 --> 00:29:46,580
next iteration for the first parameter

00:29:40,280 --> 00:29:49,010
and for the second one it's point 305 so

00:29:46,580 --> 00:29:53,380
now that we have those we plug them back

00:29:49,010 --> 00:29:55,940
back into our theta array and keep going

00:29:53,380 --> 00:29:58,340
so instead of point 1 point 1 now we

00:29:55,940 --> 00:30:00,080
have these values and if you keep doing

00:29:58,340 --> 00:30:03,800
it long enough eventually you'll get to

00:30:00,080 --> 00:30:05,000
the right answer it it's for logistic

00:30:03,800 --> 00:30:09,470
regression it's pretty much guaranteed

00:30:05,000 --> 00:30:11,540
that you'll get to the minimum so

00:30:09,470 --> 00:30:15,220
somebody asks in it when I give this

00:30:11,540 --> 00:30:15,220
talk the first time somebody asks for a

00:30:15,310 --> 00:30:22,550
sample code you wanted to see sample

00:30:19,460 --> 00:30:28,930
code I'm like okay let's do sample code

00:30:22,550 --> 00:30:28,930
so can everybody see that or larger font

00:30:31,330 --> 00:30:35,990
so let's say we have three features and

00:30:33,650 --> 00:30:39,020
my data set is like I want to live

00:30:35,990 --> 00:30:42,070
somewhere around the world where average

00:30:39,020 --> 00:30:44,660
winter temperature is not too low where

00:30:42,070 --> 00:30:47,330
city population is fairly big I like big

00:30:44,660 --> 00:30:49,370
cities and it has the airport I can fly

00:30:47,330 --> 00:30:50,690
to from USA directly so I kind of went

00:30:49,370 --> 00:30:53,180
through several cities I had in mind

00:30:50,690 --> 00:30:55,370
collected data for them like the first

00:30:53,180 --> 00:30:58,940
column shows the average winter

00:30:55,370 --> 00:31:02,060
temperature in Celsius the second one is

00:30:58,940 --> 00:31:03,710
population and millions and the third

00:31:02,060 --> 00:31:05,900
column is doesn't have that airport or

00:31:03,710 --> 00:31:10,280
not that's my those my feature vectors

00:31:05,900 --> 00:31:13,160
and I also label them do I want to live

00:31:10,280 --> 00:31:14,300
there or not so I have zero in 110 is

00:31:13,160 --> 00:31:17,840
using floating point numbers for

00:31:14,300 --> 00:31:19,660
everything goes to simplify stuff and

00:31:17,840 --> 00:31:22,190
then i have this hypothesis function

00:31:19,660 --> 00:31:25,400
that's just calculates the dot product

00:31:22,190 --> 00:31:27,980
and plugs it into that plug that into

00:31:25,400 --> 00:31:33,440
the equation and that gives you back

00:31:27,980 --> 00:31:38,720
that output between zero and one so what

00:31:33,440 --> 00:31:43,700
do we do here i initialize the weights

00:31:38,720 --> 00:31:45,680
just random starting parameters and then

00:31:43,700 --> 00:31:47,150
my learning rate is point zero five and

00:31:45,680 --> 00:31:49,400
i'm going to take about twenty thousand

00:31:47,150 --> 00:31:54,170
iteration of this to see where we get

00:31:49,400 --> 00:31:55,400
and this is the guts of it which not

00:31:54,170 --> 00:31:57,830
going to look at it too closely it's

00:31:55,400 --> 00:31:59,300
basically the same idea you go for all

00:31:57,830 --> 00:32:02,830
your parameters and then throw all the

00:31:59,300 --> 00:32:05,390
samples you calculate the hypothesis and

00:32:02,830 --> 00:32:09,530
update the parameter just like on the

00:32:05,390 --> 00:32:11,480
slide we I link to this at the end and

00:32:09,530 --> 00:32:14,290
the resources so you can check it out to

00:32:11,480 --> 00:32:17,060
your heart's content but then we have

00:32:14,290 --> 00:32:20,360
the our weights determined that we can

00:32:17,060 --> 00:32:22,070
do predictions so we can take we can

00:32:20,360 --> 00:32:25,070
test our model feed it some new data and

00:32:22,070 --> 00:32:28,940
see what are the outputs and so if i run

00:32:25,070 --> 00:32:32,270
this works for a little bit and then it

00:32:28,940 --> 00:32:34,730
gives me something like this so 20,000

00:32:32,270 --> 00:32:38,180
steps these are the weights that are

00:32:34,730 --> 00:32:40,070
determined and now i want to validate it

00:32:38,180 --> 00:32:42,650
right i want to go through my training

00:32:40,070 --> 00:32:45,470
data that I fed it and see

00:32:42,650 --> 00:32:47,330
if it tries to predict the prediction

00:32:45,470 --> 00:32:49,820
does actually correspond to they like to

00:32:47,330 --> 00:32:52,460
manual labels I gave it and in this case

00:32:49,820 --> 00:32:54,440
it predicted fairly well but it misses

00:32:52,460 --> 00:32:58,070
two so my correctness is eighty percent

00:32:54,440 --> 00:33:00,530
for this for these weights which is not

00:32:58,070 --> 00:33:01,940
too bad and then I can test the model I

00:33:00,530 --> 00:33:03,530
can feed it some new data saying like

00:33:01,940 --> 00:33:06,230
okay well what if there is a city that's

00:33:03,530 --> 00:33:08,270
about zero degrees in the winter on

00:33:06,230 --> 00:33:10,640
average and it's a 1.1 million and

00:33:08,270 --> 00:33:12,530
there's an airport that I can fly to

00:33:10,640 --> 00:33:15,620
from USA directly and it says yeah you

00:33:12,530 --> 00:33:17,690
likely you want to live there well what

00:33:15,620 --> 00:33:19,700
if there's one that's minus 14 on the

00:33:17,690 --> 00:33:21,740
winter it's still a big city and there's

00:33:19,700 --> 00:33:22,970
an airport it's likely no probably i'll

00:33:21,740 --> 00:33:24,680
live there because you know the

00:33:22,970 --> 00:33:27,380
temperature or whatever but i didn't

00:33:24,680 --> 00:33:28,820
tell it like what is more important

00:33:27,380 --> 00:33:30,200
which of the features is more important

00:33:28,820 --> 00:33:34,550
right it kind of figured it out on its

00:33:30,200 --> 00:33:41,360
own if you look at the weights so that's

00:33:34,550 --> 00:33:43,040
an example of this algorithm so putting

00:33:41,360 --> 00:33:46,910
it all together how to finish building

00:33:43,040 --> 00:33:48,770
this tool basically i once i have the

00:33:46,910 --> 00:33:49,910
model train I just loaded from database

00:33:48,770 --> 00:33:53,210
or whatever these are basically the

00:33:49,910 --> 00:33:55,490
weights we calculated I have some hard

00:33:53,210 --> 00:33:56,900
coded rules to skip things that it shy

00:33:55,490 --> 00:34:00,920
should him and try to run the algorithm

00:33:56,900 --> 00:34:04,280
on like I think in my case it was some

00:34:00,920 --> 00:34:05,600
weird truncated retweets if my friends

00:34:04,280 --> 00:34:06,980
tweeted me I don't want to really run

00:34:05,600 --> 00:34:09,290
through our algorithm that's clear that

00:34:06,980 --> 00:34:12,830
I want to see those all the time tweets

00:34:09,290 --> 00:34:14,390
from amit twins mentioning my friends

00:34:12,830 --> 00:34:17,200
and things like that so we just skip

00:34:14,390 --> 00:34:21,520
those and then we do the classification

00:34:17,200 --> 00:34:21,520
into good and bad

00:34:23,649 --> 00:34:31,879
with my remote cut out here let's see so

00:34:29,570 --> 00:34:34,010
and how do you do prediction it's the

00:34:31,879 --> 00:34:35,570
same hypothesis function like it's the

00:34:34,010 --> 00:34:37,760
same function with a dog product and

00:34:35,570 --> 00:34:41,080
everything but now instead of feeding at

00:34:37,760 --> 00:34:43,639
the training data with feed it new data

00:34:41,080 --> 00:34:45,290
so we take that and we sort of

00:34:43,639 --> 00:34:49,490
substitute that in and you end up with

00:34:45,290 --> 00:34:52,310
this kind of big looking thing but it's

00:34:49,490 --> 00:34:53,929
it's gives you the output like this is

00:34:52,310 --> 00:34:56,659
the dog product that's the function and

00:34:53,929 --> 00:34:58,010
if you calculate it and it gives you a

00:34:56,659 --> 00:35:00,230
number between zero and one that gives

00:34:58,010 --> 00:35:03,170
you the probability that this is in that

00:35:00,230 --> 00:35:05,300
class that you're trying to determine so

00:35:03,170 --> 00:35:07,940
in my example is if it's greater than

00:35:05,300 --> 00:35:09,740
0.5 I consider it that otherwise I

00:35:07,940 --> 00:35:11,780
consider it good when I can adjust that

00:35:09,740 --> 00:35:14,780
threshold like in my case I wanted to be

00:35:11,780 --> 00:35:17,150
fairly cautious that I don't necessarily

00:35:14,780 --> 00:35:19,310
end up with a whole lot of false

00:35:17,150 --> 00:35:21,260
positives and I like block the person

00:35:19,310 --> 00:35:22,610
and never see their tweets again because

00:35:21,260 --> 00:35:24,770
what if it was like somebody actually

00:35:22,610 --> 00:35:30,550
had a valid tweet but I just

00:35:24,770 --> 00:35:32,510
misclassified them so the threshold is

00:35:30,550 --> 00:35:33,940
figuring out what the threshold should

00:35:32,510 --> 00:35:39,200
be a little bit is a little bit of an

00:35:33,940 --> 00:35:42,950
art but then the general flow is that

00:35:39,200 --> 00:35:44,660
you for each tweet that comes in I run

00:35:42,950 --> 00:35:46,760
the same feature extractors to extract

00:35:44,660 --> 00:35:50,900
the features giving my array of features

00:35:46,760 --> 00:35:54,440
then I run the model and act on the

00:35:50,900 --> 00:35:56,950
result and so if it's determines that

00:35:54,440 --> 00:35:59,990
it's a bad tweet it blocks the user

00:35:56,950 --> 00:36:02,359
through the twitter api and i never see

00:35:59,990 --> 00:36:07,010
from them again if they and i don't see

00:36:02,359 --> 00:36:09,109
that tweet either and they kind of cool

00:36:07,010 --> 00:36:12,920
thing about this approach is that I

00:36:09,109 --> 00:36:14,330
don't need to have a proxy that's

00:36:12,920 --> 00:36:15,920
sitting in front of Twitter and I

00:36:14,330 --> 00:36:17,750
connect our proxy from all my clients

00:36:15,920 --> 00:36:19,550
like I actually all my client devices

00:36:17,750 --> 00:36:21,140
the phone and the web they work with

00:36:19,550 --> 00:36:23,210
Twitter directly just the user is

00:36:21,140 --> 00:36:26,330
blocked and kind of never appears my

00:36:23,210 --> 00:36:29,380
reply stream anymore so some of the

00:36:26,330 --> 00:36:29,380
lessons learned from this

00:36:30,260 --> 00:36:36,840
Twitter API on is big pain in the ass

00:36:34,400 --> 00:36:39,180
who here has work with Twitter API

00:36:36,840 --> 00:36:44,790
especially a streaming one do you like

00:36:39,180 --> 00:36:50,280
it yeah I can't like forget the

00:36:44,790 --> 00:36:51,780
documentation which is okay the number

00:36:50,280 --> 00:36:54,090
of times that I have rented the things

00:36:51,780 --> 00:36:56,310
were undocumented like the error codes

00:36:54,090 --> 00:37:00,150
they weren't really explained or just

00:36:56,310 --> 00:37:02,900
random like bad things happening is too

00:37:00,150 --> 00:37:05,520
high to mention I really wish they

00:37:02,900 --> 00:37:09,230
concentrate a little more on on their

00:37:05,520 --> 00:37:09,230
API rather than pissing off developers

00:37:09,770 --> 00:37:16,500
blocking is the only option in my case

00:37:12,600 --> 00:37:18,210
and it's pretty final like if I

00:37:16,500 --> 00:37:20,430
misclassify somebody and I block them

00:37:18,210 --> 00:37:21,960
like i said i'll never see them trying

00:37:20,430 --> 00:37:23,670
to say hey what did you block me and so

00:37:21,960 --> 00:37:25,620
on right like that the only way of for

00:37:23,670 --> 00:37:27,420
them to use to get hold of me is to have

00:37:25,620 --> 00:37:32,910
somebody else contact me or email me or

00:37:27,420 --> 00:37:34,800
whatever right i also found out that the

00:37:32,910 --> 00:37:37,590
streaming API delivery is incomplete

00:37:34,800 --> 00:37:40,080
there would be cases where I would go

00:37:37,590 --> 00:37:43,020
into my reply stream on Twitter website

00:37:40,080 --> 00:37:44,940
and I would see a tweet there that that

00:37:43,020 --> 00:37:47,040
was not delivered to my street to the

00:37:44,940 --> 00:37:49,470
streaming API like I don't know why that

00:37:47,040 --> 00:37:53,790
happens it's just another example of

00:37:49,470 --> 00:37:56,250
Twitter being very inconsistent I judge

00:37:53,790 --> 00:37:58,080
the the tool to me about eighty percent

00:37:56,250 --> 00:38:01,760
effective I'm still going to keep

00:37:58,080 --> 00:38:04,200
working on it but it's already big help

00:38:01,760 --> 00:38:07,230
also one of the PHP sucks at math ii

00:38:04,200 --> 00:38:10,230
stuff it doesn't really have tools for

00:38:07,230 --> 00:38:13,560
doing anything besides I don't know

00:38:10,230 --> 00:38:16,980
simple arithmetic stuff and maybe I

00:38:13,560 --> 00:38:19,710
don't know square roots and exponents

00:38:16,980 --> 00:38:22,380
and things like that but you really want

00:38:19,710 --> 00:38:27,630
some of that to have to do really cool

00:38:22,380 --> 00:38:30,840
algorithms so some of the next steps

00:38:27,630 --> 00:38:35,580
that I can take with this I can do more

00:38:30,840 --> 00:38:37,920
of a real-time feedback loop so as build

00:38:35,580 --> 00:38:39,960
something where as the new things as a

00:38:37,920 --> 00:38:41,760
new tweets come in and I'm like oh this

00:38:39,960 --> 00:38:42,760
actually is a bad one but you missed it

00:38:41,760 --> 00:38:44,260
I would just click

00:38:42,760 --> 00:38:45,760
somewhere and I would go and add it to

00:38:44,260 --> 00:38:47,470
the model and you know update the

00:38:45,760 --> 00:38:49,810
weights and so on so some sort of real

00:38:47,470 --> 00:38:52,000
real time feedback I could look at more

00:38:49,810 --> 00:38:56,440
features to see what else might be fed

00:38:52,000 --> 00:39:01,660
into the model do I could do some like

00:38:56,440 --> 00:39:04,420
grammar analysis to for first for some

00:39:01,660 --> 00:39:06,400
tweets that ends up being that it's

00:39:04,420 --> 00:39:09,570
English and it's actually valid English

00:39:06,400 --> 00:39:11,950
but people say stuff like I am at a bar

00:39:09,570 --> 00:39:14,350
which I don't understand why they do

00:39:11,950 --> 00:39:17,610
that but I could try to determine those

00:39:14,350 --> 00:39:19,990
cases and add it to the hard-coded rules

00:39:17,610 --> 00:39:21,310
another thing to look at is a different

00:39:19,990 --> 00:39:24,400
learning algorithm called support

00:39:21,310 --> 00:39:26,170
support vector machines which deals much

00:39:24,400 --> 00:39:28,990
better with the biased cases so I

00:39:26,170 --> 00:39:31,960
wouldn't have to do that synthetic over

00:39:28,990 --> 00:39:34,780
sampling that much I can use and there's

00:39:31,960 --> 00:39:37,510
actually a PHP extension called SVM that

00:39:34,780 --> 00:39:40,090
I think Ian wrote so there could be

00:39:37,510 --> 00:39:41,980
another thing to load look at Twitter

00:39:40,090 --> 00:39:44,700
recently released something called

00:39:41,980 --> 00:39:48,420
clockwork Raven have you heard of that

00:39:44,700 --> 00:39:53,490
it's it's like a library and an app to

00:39:48,420 --> 00:39:57,040
help you submit data to mechanical turk

00:39:53,490 --> 00:39:58,630
and work with that an easier way so that

00:39:57,040 --> 00:40:00,640
could be useful if I wanted to redo that

00:39:58,630 --> 00:40:03,250
manual classification like if I ever

00:40:00,640 --> 00:40:05,080
need to retrain them and we label the

00:40:03,250 --> 00:40:07,240
model I could use that and have somebody

00:40:05,080 --> 00:40:09,040
actually sit there and say this is good

00:40:07,240 --> 00:40:12,130
this is bad rather than e doing that for

00:40:09,040 --> 00:40:15,130
a bunch bunch of hours other

00:40:12,130 --> 00:40:17,290
minimization algorithms like the FGS or

00:40:15,130 --> 00:40:19,480
conjugate gradient gradient descent is

00:40:17,290 --> 00:40:20,800
simple but it has you know like a

00:40:19,480 --> 00:40:22,930
censored nations doesn't give you the

00:40:20,800 --> 00:40:24,220
global minimum you have to figure out

00:40:22,930 --> 00:40:26,830
what the learning rate should be and

00:40:24,220 --> 00:40:29,830
these algorithms are more complex but

00:40:26,830 --> 00:40:32,140
they don't suffer from that no and I

00:40:29,830 --> 00:40:33,820
really want something like python has

00:40:32,140 --> 00:40:35,500
this thing called scikit-learn which is

00:40:33,820 --> 00:40:37,420
a whole big library that has awesome

00:40:35,500 --> 00:40:39,400
machine learning stuff so you can write

00:40:37,420 --> 00:40:41,740
actual apps and tools based on that and

00:40:39,400 --> 00:40:46,780
we wish there was something like that in

00:40:41,740 --> 00:40:50,890
Pekel for PHP so some of the tools used

00:40:46,780 --> 00:40:54,360
our MongoDB already mentioned the text

00:40:50,890 --> 00:40:54,360
language detect library in pair

00:40:54,400 --> 00:40:59,440
it's the underlined ones a link so if

00:40:57,520 --> 00:41:01,569
you see the slides later just click on

00:40:59,440 --> 00:41:03,700
them and go there english vocabulary

00:41:01,569 --> 00:41:05,650
corpus which has like a million english

00:41:03,700 --> 00:41:08,260
words and i use that to clean up some of

00:41:05,650 --> 00:41:12,789
the language detection stuff is you can

00:41:08,260 --> 00:41:16,900
see in the slide notes later so as parts

00:41:12,789 --> 00:41:19,420
of speech tagging system SPL fixed array

00:41:16,900 --> 00:41:22,720
is a part of the SPL extension and it

00:41:19,420 --> 00:41:24,760
basically gives you a simpler and more

00:41:22,720 --> 00:41:26,260
memory efficient arrays rather than what

00:41:24,760 --> 00:41:29,380
the PHP has which are not really arrays

00:41:26,260 --> 00:41:31,089
they're like ordered maps basically

00:41:29,380 --> 00:41:33,010
because you can throw anything in them

00:41:31,089 --> 00:41:35,109
and this is just like okay I'm going to

00:41:33,010 --> 00:41:39,339
have ten entries of numbers and that's

00:41:35,109 --> 00:41:42,099
it and it helps you with some speed and

00:41:39,339 --> 00:41:44,410
memory efficiency fire hose and that's

00:41:42,099 --> 00:41:46,779
the tool library that hooks onto Twitter

00:41:44,410 --> 00:41:49,170
streaming API and actually use Python

00:41:46,779 --> 00:41:52,089
scikit-learn for to validate the results

00:41:49,170 --> 00:41:57,039
which was useful and linked to the code

00:41:52,089 --> 00:41:59,170
sample as well so I think we're set of

00:41:57,039 --> 00:42:03,660
like time for a few questions if you

00:41:59,170 --> 00:42:03,660
have them anybody

00:42:07,990 --> 00:42:14,390
yes it is worth to have its short

00:42:12,410 --> 00:42:16,099
twitter name did you see the fame the

00:42:14,390 --> 00:42:20,930
followers the fortune and stuff like

00:42:16,099 --> 00:42:24,349
that no it's worth it and even just as a

00:42:20,930 --> 00:42:34,460
conversation starter if nothing else who

00:42:24,349 --> 00:42:37,609
else okay in the red but well Mike how

00:42:34,460 --> 00:42:39,319
many uses have you bend I'm sorry can

00:42:37,609 --> 00:42:41,359
you how do how many people have you

00:42:39,319 --> 00:42:45,710
bound on Twitter how many but how are

00:42:41,359 --> 00:42:47,150
you bill did that ban um so for each

00:42:45,710 --> 00:42:50,509
block tweet I also save it to the

00:42:47,150 --> 00:42:52,250
database just because because in case I

00:42:50,509 --> 00:42:55,880
wanted to run some analysis or later or

00:42:52,250 --> 00:43:00,859
whatever and I think it's in the

00:42:55,880 --> 00:43:03,920
hundreds of thousands now I I don't know

00:43:00,859 --> 00:43:10,450
if I'm the number one blocker on Twitter

00:43:03,920 --> 00:43:10,450
or not but I might be yeah behind

00:43:11,920 --> 00:43:16,809
compare how they compare in terms of

00:43:14,720 --> 00:43:20,690
accuracy and efficiency to

00:43:16,809 --> 00:43:24,259
classification your network how does it

00:43:20,690 --> 00:43:29,869
compare classification system how does

00:43:24,259 --> 00:43:33,640
it compare in terms of accuracy well

00:43:29,869 --> 00:43:36,349
it's a very simple algorithm right and I

00:43:33,640 --> 00:43:38,150
kind of use it because I sort of thought

00:43:36,349 --> 00:43:39,410
I might give this talk and it easier to

00:43:38,150 --> 00:43:42,559
explain that something like support

00:43:39,410 --> 00:43:46,069
vector machines or so it could it could

00:43:42,559 --> 00:43:47,569
be better is what I'm saying but this

00:43:46,069 --> 00:43:52,420
way it's I think a little more

00:43:47,569 --> 00:43:52,420
transparent about what's going on yeah

00:43:58,670 --> 00:44:01,270
yes

00:44:05,660 --> 00:44:08,260
kind of invasion

00:44:11,230 --> 00:44:16,190
have I had any feedback from Twitter

00:44:14,030 --> 00:44:19,820
about this or interaction with them not

00:44:16,190 --> 00:44:22,550
really I mean I i know people some

00:44:19,820 --> 00:44:25,070
people who work at twitter like somebody

00:44:22,550 --> 00:44:27,500
on their API team and so on and i

00:44:25,070 --> 00:44:29,599
complained about this stuff but there's

00:44:27,500 --> 00:44:33,020
not much that they can actually do right

00:44:29,599 --> 00:44:35,390
and they're not going to run something

00:44:33,020 --> 00:44:39,950
like this and automatically block people

00:44:35,390 --> 00:44:43,070
from me so it's sort of I mean it comes

00:44:39,950 --> 00:44:44,780
with a territory apparently and if you

00:44:43,070 --> 00:44:48,410
think Twitter result is just what you

00:44:44,780 --> 00:44:50,960
see and they sort of your reply stream

00:44:48,410 --> 00:44:53,930
like there's a whole big dark Twitter

00:44:50,960 --> 00:44:56,599
out there that's just horrible stuff you

00:44:53,930 --> 00:44:58,010
know I as I was like looking at if you

00:44:56,599 --> 00:44:59,840
just hook it at the streaming API and

00:44:58,010 --> 00:45:01,849
there's a sampling one that just shows

00:44:59,840 --> 00:45:03,500
you like ten percent of what's actually

00:45:01,849 --> 00:45:05,630
going into Twitter and just look at it

00:45:03,500 --> 00:45:08,330
for a while you will be horrified like

00:45:05,630 --> 00:45:12,230
just the abuses of the language for

00:45:08,330 --> 00:45:13,670
example that go on so it comes with

00:45:12,230 --> 00:45:15,050
territory and that's why I kind of had

00:45:13,670 --> 00:45:17,750
to take this into my own hands and do

00:45:15,050 --> 00:45:20,330
stuff feedback about the actual Twitter

00:45:17,750 --> 00:45:23,060
API sucking that's nothing new you know

00:45:20,330 --> 00:45:26,480
then I don't know if they're motivated

00:45:23,060 --> 00:45:28,660
to fix that or not necessarily anybody

00:45:26,480 --> 00:45:28,660
else

00:45:34,369 --> 00:45:39,359
this is working yeah and I was just

00:45:37,650 --> 00:45:41,309
curious is that how much you knew about

00:45:39,359 --> 00:45:44,329
the tools and the maps behind all this

00:45:41,309 --> 00:45:46,619
stuff before you kind of inherited a

00:45:44,329 --> 00:45:49,799
what you just really hate spam and have

00:45:46,619 --> 00:45:54,140
to learn it all how much of this did

00:45:49,799 --> 00:45:56,489
they know did I learn before yeah and

00:45:54,140 --> 00:45:58,079
I've always been sort of interested in

00:45:56,489 --> 00:46:01,589
kind of machine learning and in

00:45:58,079 --> 00:46:04,380
artificial intelligence but I haven't no

00:46:01,589 --> 00:46:06,269
I hadn't had a had a motivation to apply

00:46:04,380 --> 00:46:11,489
it to something like a real project

00:46:06,269 --> 00:46:13,109
until this but there there are a lot of

00:46:11,489 --> 00:46:17,549
different ways you can use machine

00:46:13,109 --> 00:46:21,150
learning even for simpler stuff and I

00:46:17,549 --> 00:46:23,549
think Google is actually has a new thing

00:46:21,150 --> 00:46:25,170
where you can basically it's a predictor

00:46:23,549 --> 00:46:26,609
system you feed a training data it

00:46:25,170 --> 00:46:27,900
figures out the model parameters and

00:46:26,609 --> 00:46:30,329
then you've peated new stuff and give us

00:46:27,900 --> 00:46:32,009
the output through an API I haven't

00:46:30,329 --> 00:46:34,079
taken a look at that but that might be

00:46:32,009 --> 00:46:35,999
another thing for me to consider you

00:46:34,079 --> 00:46:37,829
know maybe because then I don't have to

00:46:35,999 --> 00:46:39,539
really to do anything I like Google do

00:46:37,829 --> 00:46:40,739
all the cool algorithmic stuff but on

00:46:39,539 --> 00:46:42,539
the other hand like it's just kind of

00:46:40,739 --> 00:46:45,680
neat that I just know who wrote this

00:46:42,539 --> 00:46:54,779
myself and there's it's actually working

00:46:45,680 --> 00:46:56,400
yeah just to go ahead sorry which you're

00:46:54,779 --> 00:46:58,200
doing language processing how do you

00:46:56,400 --> 00:46:59,670
tackle the problem of stop words and

00:46:58,200 --> 00:47:02,430
stemming so for example having

00:46:59,670 --> 00:47:04,799
multi-currency right so right so the

00:47:02,430 --> 00:47:06,180
question is the language detection how

00:47:04,799 --> 00:47:07,559
do you deal with standing and stop words

00:47:06,180 --> 00:47:09,509
and all that stuff there is a whole

00:47:07,559 --> 00:47:12,539
slide that I omitted but i'll include in

00:47:09,509 --> 00:47:14,940
the one as i upload where when it gives

00:47:12,539 --> 00:47:18,239
you back data and says this is English

00:47:14,940 --> 00:47:20,489
it may not be English for example right

00:47:18,239 --> 00:47:23,609
so I ran through a whole number of other

00:47:20,489 --> 00:47:25,470
steps to clean it up where like I check

00:47:23,609 --> 00:47:27,809
whether it's an English vocabulary or

00:47:25,470 --> 00:47:29,730
not first of all if it's not there then

00:47:27,809 --> 00:47:31,230
I run parts parts of speech analysis on

00:47:29,730 --> 00:47:32,730
it and if it's one of three classes like

00:47:31,230 --> 00:47:35,069
if it's a third person singular or

00:47:32,730 --> 00:47:38,220
something or a verb in the past tense

00:47:35,069 --> 00:47:39,180
then I then I do stemming on that and

00:47:38,220 --> 00:47:41,960
then I check if it's an English

00:47:39,180 --> 00:47:41,960
vocabulary again

00:47:43,330 --> 00:47:53,000
sorry not soundex know there's a there's

00:47:50,360 --> 00:47:55,000
a porter standing algorithm I think

00:47:53,000 --> 00:47:57,560
there is a library for that in PHP t

00:47:55,000 --> 00:48:02,410
which is works pretty well for that but

00:47:57,560 --> 00:48:02,410
yeah language detection is a messy thing

00:48:02,710 --> 00:48:06,530
thanks a lot for coming to the talk

00:48:04,820 --> 00:48:08,240
you've been super audience thanks for

00:48:06,530 --> 00:48:10,550
the questions as well if you could go to

00:48:08,240 --> 00:48:12,620
this joined in link later on and leave

00:48:10,550 --> 00:48:14,480
you feedback the slides will be linked

00:48:12,620 --> 00:48:18,170
from there as well in about an hour or

00:48:14,480 --> 00:48:19,820
so or within an hour and if you want to

00:48:18,170 --> 00:48:21,770
chat about this stuff again I'm going to

00:48:19,820 --> 00:48:24,890
be all night here at the social and so

00:48:21,770 --> 00:48:27,070
on so just come into common Chet thanks

00:48:24,890 --> 00:48:27,070
a lot

00:48:37,040 --> 00:48:39,100

YouTube URL: https://www.youtube.com/watch?v=pCl223SUT14


