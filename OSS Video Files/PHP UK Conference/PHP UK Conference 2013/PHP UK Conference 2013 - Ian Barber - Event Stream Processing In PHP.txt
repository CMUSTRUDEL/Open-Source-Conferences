Title: PHP UK Conference 2013 - Ian Barber - Event Stream Processing In PHP
Publication date: 2013-04-16
Playlist: PHP UK Conference 2013
Description: 
	Complex event processing is at the cutting edge of reactive systems in business and finance, where early detection of patterns is used to get just ahead of the curve. In this talk we will see how by using react PHP and a few simple functions we can build reactive systems that can give use much of the power of commercial CEP but at a fraction of the complexity.

Slides: https://speakerdeck.com/ianbarber/event-stream-processing-in-php
Captions: 
	00:00:06,670 --> 00:00:11,780
alright so hi everyone my name is Ian I

00:00:09,530 --> 00:00:14,240
I work for Google I work at Google Plus

00:00:11,780 --> 00:00:16,280
on google plus I've been doing that for

00:00:14,240 --> 00:00:20,270
about eight months now so it's still

00:00:16,280 --> 00:00:22,700
slightly confusing and weird this talk

00:00:20,270 --> 00:00:24,410
is about event stream processing as you

00:00:22,700 --> 00:00:26,780
can guess from the title it has quite a

00:00:24,410 --> 00:00:30,170
bit of code in it and that's all up on

00:00:26,780 --> 00:00:32,599
that github link that's the joint didn't

00:00:30,170 --> 00:00:34,010
URL please do go and comment on there

00:00:32,599 --> 00:00:35,300
not just for me but for all the

00:00:34,010 --> 00:00:38,780
speaker's you see it's really useful

00:00:35,300 --> 00:00:40,100
fast because it tells us what we did

00:00:38,780 --> 00:00:41,809
right what we did wrong and it's also

00:00:40,100 --> 00:00:44,449
really useful for the organizers because

00:00:41,809 --> 00:00:45,649
it lets them say who really connected

00:00:44,449 --> 00:00:47,030
with the audience the kind of things

00:00:45,649 --> 00:00:48,679
they should look out for next year the

00:00:47,030 --> 00:00:51,229
kind of problems they should look out

00:00:48,679 --> 00:00:53,449
for and if you want to ping me mba

00:00:51,229 --> 00:00:59,749
php.net will get to me or grab me on +

00:00:53,449 --> 00:01:01,699
or on twitter so one small plug before

00:00:59,749 --> 00:01:03,379
we start if you're interested in things

00:01:01,699 --> 00:01:05,000
like event stream processing you may

00:01:03,379 --> 00:01:08,330
also be interested in messaging and i

00:01:05,000 --> 00:01:11,900
wrote a kind of essay tiny ebook thing

00:01:08,330 --> 00:01:14,510
if I about 80 pages over Christmas last

00:01:11,900 --> 00:01:16,370
year and it's on lean pub you can get it

00:01:14,510 --> 00:01:20,000
from that URL just search for the title

00:01:16,370 --> 00:01:21,320
and it's free I would love for anyone

00:01:20,000 --> 00:01:22,490
that is interested in messaging or

00:01:21,320 --> 00:01:23,990
things they might be to take a look at

00:01:22,490 --> 00:01:25,190
it give me some feedback I've already

00:01:23,990 --> 00:01:28,390
had a lot of great stuff and I'll be

00:01:25,190 --> 00:01:31,570
updating it soon so it's one small plug

00:01:28,390 --> 00:01:34,820
so what I wanted to talk about was

00:01:31,570 --> 00:01:40,030
really a lot of things that have been of

00:01:34,820 --> 00:01:43,600
interest to me over the last few years

00:01:40,030 --> 00:01:46,580
I've been looking at how you can do

00:01:43,600 --> 00:01:48,350
prediction from the point of view of

00:01:46,580 --> 00:01:50,060
machine learning and support vector

00:01:48,350 --> 00:01:52,790
machines document classification things

00:01:50,060 --> 00:01:55,040
like that so build a model and then make

00:01:52,790 --> 00:01:56,780
a prediction based on it and I started

00:01:55,040 --> 00:01:58,670
looking at messaging systems I started

00:01:56,780 --> 00:02:00,950
looking at fire hoses and event based

00:01:58,670 --> 00:02:05,090
systems and looking at how you could

00:02:00,950 --> 00:02:06,620
make decisions now and what I got

00:02:05,090 --> 00:02:09,500
interested in was this concept of maybe

00:02:06,620 --> 00:02:11,870
combining the two in some way trying to

00:02:09,500 --> 00:02:13,670
make those kind of decisions in near

00:02:11,870 --> 00:02:15,590
real time based on data as it was moving

00:02:13,670 --> 00:02:18,230
rather than data kind of in a bucket

00:02:15,590 --> 00:02:19,610
we're really good at analyzing data this

00:02:18,230 --> 00:02:22,250
in a bucket we've got

00:02:19,610 --> 00:02:23,540
bases where you can do I mean incredibly

00:02:22,250 --> 00:02:26,960
complex queries and you can do them very

00:02:23,540 --> 00:02:28,700
very fast even a traditional relational

00:02:26,960 --> 00:02:30,710
database your mysql and your post

00:02:28,700 --> 00:02:33,080
grocers and all the commercial ones you

00:02:30,710 --> 00:02:34,580
can you know whack a bunch of SSDs and a

00:02:33,080 --> 00:02:36,770
lot of ram in a machine and you can do

00:02:34,580 --> 00:02:38,240
huge queries really quickly if your

00:02:36,770 --> 00:02:40,280
curries are two huge you can use Hadoop

00:02:38,240 --> 00:02:41,720
and things like big query and all these

00:02:40,280 --> 00:02:44,330
kind of amazing big data tools we have

00:02:41,720 --> 00:02:45,890
and you can process some seriously large

00:02:44,330 --> 00:02:49,010
volumes of data and you could do that

00:02:45,890 --> 00:02:51,110
relatively fast but it still takes time

00:02:49,010 --> 00:02:53,510
it's still you put the data into a

00:02:51,110 --> 00:02:55,190
bucket you do some analysis and you look

00:02:53,510 --> 00:02:56,480
at him and then when you look at it what

00:02:55,190 --> 00:02:57,709
you're almost always doing is trying to

00:02:56,480 --> 00:02:58,790
decide what you should do next you're

00:02:57,709 --> 00:03:02,090
trying to make a prediction about how

00:02:58,790 --> 00:03:03,680
things are going to happen so I wondered

00:03:02,090 --> 00:03:07,630
could we take this stuff that we have

00:03:03,680 --> 00:03:10,820
with messaging systems with cues with

00:03:07,630 --> 00:03:12,770
real-time systems can we do some of our

00:03:10,820 --> 00:03:15,830
analysis as it's going along and that's

00:03:12,770 --> 00:03:19,160
the kind of idea that I wanted to look

00:03:15,830 --> 00:03:22,370
at on the kind of basis for for looking

00:03:19,160 --> 00:03:25,430
at this talk I think you can I think we

00:03:22,370 --> 00:03:27,049
have to think about data in motion and

00:03:25,430 --> 00:03:29,450
we have to think about that motion in

00:03:27,049 --> 00:03:31,840
terms of the movement of events an event

00:03:29,450 --> 00:03:33,980
is real simple it's just a programmatic

00:03:31,840 --> 00:03:37,820
representation of an occurrence out in

00:03:33,980 --> 00:03:40,400
the real world or in another system it's

00:03:37,820 --> 00:03:42,290
a thing that has changed and from my

00:03:40,400 --> 00:03:44,750
point of view all an event is is a tuple

00:03:42,290 --> 00:03:47,269
it's a list it is a list with some

00:03:44,750 --> 00:03:51,380
elements in it ABC that's fine it could

00:03:47,269 --> 00:03:52,600
be a complex object it could be a string

00:03:51,380 --> 00:03:55,340
it could be whatever but it's

00:03:52,600 --> 00:03:56,750
effectively a list that's all we need to

00:03:55,340 --> 00:03:58,670
know about it to actually start doing

00:03:56,750 --> 00:04:00,860
things with it but an event on its own

00:03:58,670 --> 00:04:02,060
is not interesting it's like a it's a

00:04:00,860 --> 00:04:04,459
single record of a database table

00:04:02,060 --> 00:04:05,840
there's not enough of it where we start

00:04:04,459 --> 00:04:08,180
getting interesting is when we think

00:04:05,840 --> 00:04:11,570
about an event stream and red stream is

00:04:08,180 --> 00:04:12,950
just a series of related events now they

00:04:11,570 --> 00:04:15,799
don't have to be related you could have

00:04:12,950 --> 00:04:18,799
a sort of non-homogeneous of industry

00:04:15,799 --> 00:04:21,950
mother it's not so common and it's not

00:04:18,799 --> 00:04:24,610
what we're really focusing on here so an

00:04:21,950 --> 00:04:27,200
event stream is the same kind of event a

00:04:24,610 --> 00:04:30,229
series of them that has occurred over

00:04:27,200 --> 00:04:32,510
time with some kind of ordering like a

00:04:30,229 --> 00:04:35,540
stock market price so that would be the

00:04:32,510 --> 00:04:37,700
the code for excellent and that's their

00:04:35,540 --> 00:04:39,740
price at various points you can see that

00:04:37,700 --> 00:04:41,420
over time it doesn't say anything about

00:04:39,740 --> 00:04:42,590
what that time is it doesn't say

00:04:41,420 --> 00:04:45,760
anything about how that's been generated

00:04:42,590 --> 00:04:48,410
just that there is a stream of events

00:04:45,760 --> 00:04:51,050
when you have multiple streams of events

00:04:48,410 --> 00:04:56,420
that are related in some way you have an

00:04:51,050 --> 00:04:59,180
event cloud an event cloud is not just a

00:04:56,420 --> 00:05:00,320
set of streams but a set of streams

00:04:59,180 --> 00:05:03,860
where there is some connection between

00:05:00,320 --> 00:05:07,150
them so a stock market itself is an

00:05:03,860 --> 00:05:10,010
event cloud we think of something like a

00:05:07,150 --> 00:05:13,340
index so like this is the price for the

00:05:10,010 --> 00:05:16,400
footsie 100 what that represents is a

00:05:13,340 --> 00:05:19,250
series of streams of the prices of

00:05:16,400 --> 00:05:22,100
different stocks are there independent

00:05:19,250 --> 00:05:23,690
you know if one company goes out and

00:05:22,100 --> 00:05:25,100
does something amazing there may be

00:05:23,690 --> 00:05:27,140
their price will go up if they do same

00:05:25,100 --> 00:05:30,650
bad maybe their price will go down but

00:05:27,140 --> 00:05:32,900
changes can affect all of the stocks in

00:05:30,650 --> 00:05:34,220
an index some of them it can cause some

00:05:32,900 --> 00:05:35,930
to go up and others to go down and

00:05:34,220 --> 00:05:37,400
there's a correlation as a relation

00:05:35,930 --> 00:05:40,700
between them so there's certain things

00:05:37,400 --> 00:05:42,140
you can extract like if you have a bad

00:05:40,700 --> 00:05:45,500
economic outlook maybe everyone goes

00:05:42,140 --> 00:05:49,430
down if you have a index tracker then

00:05:45,500 --> 00:05:51,920
how they work is by investing in stocks

00:05:49,430 --> 00:05:54,620
in rough proportion to how much of an

00:05:51,920 --> 00:05:56,300
index they make up so if i stop becomes

00:05:54,620 --> 00:05:58,160
less valuable makes up less of an index

00:05:56,300 --> 00:06:00,110
then maybe that index tracker will sell

00:05:58,160 --> 00:06:01,550
it and buy other ones and that causes a

00:06:00,110 --> 00:06:04,070
change it causes a rippling change

00:06:01,550 --> 00:06:05,990
outwards and analyzing these things is

00:06:04,070 --> 00:06:08,420
therefore pretty complicated if you have

00:06:05,990 --> 00:06:10,160
a cloud of events trying to extract

00:06:08,420 --> 00:06:13,070
useful things from them it's hard which

00:06:10,160 --> 00:06:15,560
is why a field called complex event

00:06:13,070 --> 00:06:18,560
processing developed complex event

00:06:15,560 --> 00:06:20,960
processing is a world of kind of big

00:06:18,560 --> 00:06:22,820
chunky services some are open sources

00:06:20,960 --> 00:06:26,060
Esper which is an excellent open source

00:06:22,820 --> 00:06:29,720
project you should check it out designed

00:06:26,060 --> 00:06:33,230
to do clever queries across a series of

00:06:29,720 --> 00:06:38,030
events dreams so you could do something

00:06:33,230 --> 00:06:40,130
like look for instances where a item has

00:06:38,030 --> 00:06:42,400
been placed onto a shelf so it's been

00:06:40,130 --> 00:06:44,480
scanned on a shelf in a shop it's been

00:06:42,400 --> 00:06:46,220
it's gone out the door which you've

00:06:44,480 --> 00:06:47,780
tracked with an RFID going

00:06:46,220 --> 00:06:49,190
the door sensors but it hasn't gone

00:06:47,780 --> 00:06:52,010
through a check out so it's been nicked

00:06:49,190 --> 00:06:53,360
that you can do as a query and you write

00:06:52,010 --> 00:06:55,400
that in either a kind of sequel light

00:06:53,360 --> 00:06:57,710
language or a lot of cep systems you

00:06:55,400 --> 00:06:59,090
have a visual query builder because

00:06:57,710 --> 00:07:01,430
they're just complicated they're too

00:06:59,090 --> 00:07:03,650
hard for humans to reason about to kind

00:07:01,430 --> 00:07:04,460
of easily code those kind of things up

00:07:03,650 --> 00:07:06,680
will do them in a more straightforward

00:07:04,460 --> 00:07:08,090
actually needs a dragon so you can see

00:07:06,680 --> 00:07:12,200
the flow of events to actually build

00:07:08,090 --> 00:07:13,670
queries so these are no big generally

00:07:12,200 --> 00:07:16,460
expensive systems from people like

00:07:13,670 --> 00:07:19,370
informatica and tibco and huge names

00:07:16,460 --> 00:07:21,530
like that and one of those systems was a

00:07:19,370 --> 00:07:23,840
chemical stream basin this chap dark NS

00:07:21,530 --> 00:07:26,330
were there and if you know the London

00:07:23,840 --> 00:07:28,130
Erlang or Java or these days node

00:07:26,330 --> 00:07:29,420
communities or many others you may have

00:07:28,130 --> 00:07:33,230
encountered that it's a really really

00:07:29,420 --> 00:07:36,260
smart guy really nice guy and he when he

00:07:33,230 --> 00:07:38,480
left string bass started looking at the

00:07:36,260 --> 00:07:40,700
idea of a vent process and in complex

00:07:38,480 --> 00:07:42,620
event processing and realized that for

00:07:40,700 --> 00:07:45,350
all the complexity in there there's a

00:07:42,620 --> 00:07:47,840
good amount you can do with just a tiny

00:07:45,350 --> 00:07:49,520
bit of the work you can kind of do a

00:07:47,840 --> 00:07:51,500
Pareto principle thing and say I can get

00:07:49,520 --> 00:07:52,910
eighty percent of the ability to look at

00:07:51,500 --> 00:07:56,210
all these streams and do something with

00:07:52,910 --> 00:07:58,220
just twenty percent the work so he did

00:07:56,210 --> 00:08:01,550
that and he built a little library on

00:07:58,220 --> 00:08:06,229
nodejs called EEP embeddable event

00:08:01,550 --> 00:08:09,770
processing and what this was was looking

00:08:06,229 --> 00:08:11,810
at all the parts of a CEP system of an

00:08:09,770 --> 00:08:14,120
event processing system and identified

00:08:11,810 --> 00:08:16,520
what bits are straightforward to

00:08:14,120 --> 00:08:18,710
implement and therefore what bits can we

00:08:16,520 --> 00:08:21,919
do really fast because one of things

00:08:18,710 --> 00:08:23,990
node is good at is asynchronous callback

00:08:21,919 --> 00:08:26,270
based event driven applications it can

00:08:23,990 --> 00:08:28,729
do those really quickly and he figured

00:08:26,270 --> 00:08:31,250
if you can do something very very fast

00:08:28,729 --> 00:08:34,490
that's almost as good has been very very

00:08:31,250 --> 00:08:37,370
smart simple things fast give you an

00:08:34,490 --> 00:08:38,690
awful lot of flexibility so the things

00:08:37,370 --> 00:08:41,570
that he looked at were these stream

00:08:38,690 --> 00:08:44,180
operations these basic things these

00:08:41,570 --> 00:08:47,300
basic building blocks which we can use

00:08:44,180 --> 00:08:50,150
to start processing event and those are

00:08:47,300 --> 00:08:51,650
pipes the ability to move events from

00:08:50,150 --> 00:08:54,740
one place to another move a stream of

00:08:51,650 --> 00:08:56,240
events over their Maps so that's a

00:08:54,740 --> 00:08:58,019
one-way transformation or a

00:08:56,240 --> 00:09:01,800
one-at-a-time transformations

00:08:58,019 --> 00:09:03,300
if you are taking a input value you map

00:09:01,800 --> 00:09:05,309
it to something else maybe you oughta

00:09:03,300 --> 00:09:07,439
meant it maybe you transform it and then

00:09:05,309 --> 00:09:10,009
your output it so it's one event comes

00:09:07,439 --> 00:09:12,509
in one event goes out there's windows

00:09:10,009 --> 00:09:14,249
these windows give you a view over a

00:09:12,509 --> 00:09:16,290
series of events and allow you to have

00:09:14,249 --> 00:09:19,559
some kind of calculation for more than

00:09:16,290 --> 00:09:21,449
one event at a time and those windows

00:09:19,559 --> 00:09:23,850
those calculations those are either

00:09:21,449 --> 00:09:24,929
aggregate functions which it's easiest

00:09:23,850 --> 00:09:26,999
to think of this kind of online

00:09:24,929 --> 00:09:30,329
functions functions that update as they

00:09:26,999 --> 00:09:32,040
get new events and sort of memory based

00:09:30,329 --> 00:09:34,199
functions things we're looking at data

00:09:32,040 --> 00:09:39,209
that's been stored which can be a thing

00:09:34,199 --> 00:09:40,799
like a join so I I really like this

00:09:39,209 --> 00:09:42,179
library i thought was fun and I thought

00:09:40,799 --> 00:09:43,079
I I want to understand it better and

00:09:42,179 --> 00:09:44,639
I've got two ways of understanding

00:09:43,079 --> 00:09:45,989
something that work for me and one of

00:09:44,639 --> 00:09:49,529
them is going and given a talk about it

00:09:45,989 --> 00:09:52,470
so this is that the other way is writing

00:09:49,529 --> 00:09:56,339
it actually writing code so i ported EP

00:09:52,470 --> 00:09:57,779
to react PHP in a weekend this is not I

00:09:56,339 --> 00:09:59,489
mean this is not a complex code base and

00:09:57,779 --> 00:10:01,290
you'll see this and react is a really

00:09:59,489 --> 00:10:05,759
really good project it sir it's

00:10:01,290 --> 00:10:09,389
basically an oj s style invented call

00:10:05,759 --> 00:10:10,740
back base system written in PHP so you

00:10:09,389 --> 00:10:13,319
get to use pretty much the same program

00:10:10,740 --> 00:10:15,689
model and importantly for me it had the

00:10:13,319 --> 00:10:17,850
pipes system which node has and I think

00:10:15,689 --> 00:10:19,980
we actually is not necessarily that

00:10:17,850 --> 00:10:22,439
well-known so I just wanted to quickly

00:10:19,980 --> 00:10:27,269
show you what it's like to knock

00:10:22,439 --> 00:10:29,369
something up with that so react is

00:10:27,269 --> 00:10:31,259
actually installed via composer and if

00:10:29,369 --> 00:10:32,699
you haven't used composer do it's a

00:10:31,259 --> 00:10:37,470
wonderful little package management

00:10:32,699 --> 00:10:43,369
system dependency management system so

00:10:37,470 --> 00:10:43,369
what I'm going to do is just all dear

00:10:43,549 --> 00:10:47,119
let's call it server

00:10:47,220 --> 00:10:56,050
so what I'm going to do is just quickly

00:10:50,430 --> 00:10:57,670
knock up a little react scrape that just

00:10:56,050 --> 00:11:00,820
shows the basics of what it is because

00:10:57,670 --> 00:11:03,760
it works slightly differently from how

00:11:00,820 --> 00:11:04,810
you normally implement our PHP process

00:11:03,760 --> 00:11:07,209
so you normally would have some kind of

00:11:04,810 --> 00:11:10,029
web server calling out to even running

00:11:07,209 --> 00:11:12,250
PHP process or far CGI or you know

00:11:10,029 --> 00:11:13,720
Apache and so on but react actually is

00:11:12,250 --> 00:11:16,209
the web server it's going to handle the

00:11:13,720 --> 00:11:18,190
connection for you and its base react

00:11:16,209 --> 00:11:19,870
has an event loop this is kind of the

00:11:18,190 --> 00:11:23,500
bit that you get for free if you use

00:11:19,870 --> 00:11:26,560
node node really is an event loop but

00:11:23,500 --> 00:11:28,810
with react we have to build one so we

00:11:26,560 --> 00:11:30,070
just create a loop like that I mean this

00:11:28,810 --> 00:11:34,290
is assuming I don't make any typos

00:11:30,070 --> 00:11:38,589
through this process which is low chance

00:11:34,290 --> 00:11:41,500
and then we create a server for a socket

00:11:38,589 --> 00:11:43,750
like that now at this point we could

00:11:41,500 --> 00:11:45,579
plug that server entire sign else like

00:11:43,750 --> 00:11:47,529
we could plug it into an HTTP client and

00:11:45,579 --> 00:11:49,449
turn into a web server sorry an HTTP

00:11:47,529 --> 00:11:53,230
seven turn into web server we could not

00:11:49,449 --> 00:11:55,750
do a regular socket so that is TCP but

00:11:53,230 --> 00:11:57,880
we can't is easily do 0 and Q or another

00:11:55,750 --> 00:12:01,120
messaging system if we had a binding for

00:11:57,880 --> 00:12:03,760
that to actually make it do stuff we

00:12:01,120 --> 00:12:05,110
just say socket listen so this is a TCP

00:12:03,760 --> 00:12:08,290
socket it's just going to bind itself in

00:12:05,110 --> 00:12:11,709
port 4000 and you run and that just

00:12:08,290 --> 00:12:16,140
kicks off the actual process so so you

00:12:11,709 --> 00:12:16,140
mean I haven't messed anything up good

00:12:17,310 --> 00:12:22,870
so we can tell that to it and we can

00:12:20,470 --> 00:12:24,430
send stuff but it doesn't do anything

00:12:22,870 --> 00:12:25,829
right all is doing is sitting there

00:12:24,430 --> 00:12:29,560
listening accepting collections and

00:12:25,829 --> 00:12:31,329
being boring but the really cool thing

00:12:29,560 --> 00:12:33,730
and the reason reacted is excellent for

00:12:31,329 --> 00:12:37,630
this kind of work is we have the ability

00:12:33,730 --> 00:12:39,640
to pipe events and streams through so

00:12:37,630 --> 00:12:41,050
this is just like unix pipe you know

00:12:39,640 --> 00:12:42,370
when you use the pipe character in UNIX

00:12:41,050 --> 00:12:43,899
and you can send all the output from one

00:12:42,370 --> 00:12:46,000
app to another one it's a really

00:12:43,899 --> 00:12:48,730
effective it's really simple and it lets

00:12:46,000 --> 00:12:50,170
you decompose a big program into lots of

00:12:48,730 --> 00:12:53,610
individual components with piping

00:12:50,170 --> 00:12:57,040
between them so what we can do is do

00:12:53,610 --> 00:12:59,620
socket on connection because we actors

00:12:57,040 --> 00:13:00,910
all call that based on event-based we

00:12:59,620 --> 00:13:02,680
register kind of a list

00:13:00,910 --> 00:13:04,180
for an event so this is saying there's a

00:13:02,680 --> 00:13:05,410
connection event coming in that means

00:13:04,180 --> 00:13:10,240
there's a new connection that's happened

00:13:05,410 --> 00:13:14,290
and then we implement a callback which

00:13:10,240 --> 00:13:17,560
accepts a connection argument and we can

00:13:14,290 --> 00:13:23,380
just do khan pipe and we can send it

00:13:17,560 --> 00:13:25,840
where we want like straight back out see

00:13:23,380 --> 00:13:28,600
how that works so they mean do hello

00:13:25,840 --> 00:13:30,280
world and it occurs it back so just

00:13:28,600 --> 00:13:32,140
piped the input straight back to the

00:13:30,280 --> 00:13:34,420
output which is fine that's useful and

00:13:32,140 --> 00:13:37,240
that's happening very cheaply if we were

00:13:34,420 --> 00:13:39,370
sending a hundred makefile through this

00:13:37,240 --> 00:13:40,840
it's not going to like buffer it all and

00:13:39,370 --> 00:13:42,880
then send it on to the next step as a

00:13:40,840 --> 00:13:44,860
chunk comes in it'll send it through

00:13:42,880 --> 00:13:48,850
it's just doing the kind of minimal work

00:13:44,860 --> 00:13:52,000
required to actually do that and that

00:13:48,850 --> 00:13:55,570
means we can implement maps so a map

00:13:52,000 --> 00:13:58,630
might be done as a function or is a new

00:13:55,570 --> 00:14:00,990
kind of stream type so if I do something

00:13:58,630 --> 00:14:00,990
like this

00:14:08,709 --> 00:14:12,820
then the through stream is something

00:14:11,240 --> 00:14:18,649
that has both an input and output filter

00:14:12,820 --> 00:14:20,300
pipe and we can connect them and they go

00:14:18,649 --> 00:14:22,670
through the filter function so we get

00:14:20,300 --> 00:14:25,130
some data and we send it out again so we

00:14:22,670 --> 00:14:27,500
can just return something like string to

00:14:25,130 --> 00:14:29,899
our power data so all this is going to

00:14:27,500 --> 00:14:32,290
do is take whatever it gets in string to

00:14:29,899 --> 00:14:34,910
operate and send it out of its out pipe

00:14:32,290 --> 00:14:46,579
and we can do so no filter equals new

00:14:34,910 --> 00:14:48,320
upper stream use that and instead of

00:14:46,579 --> 00:14:50,089
doing it straight to the pipe we can

00:14:48,320 --> 00:14:52,610
pipe it to filter and because pipe

00:14:50,089 --> 00:14:55,160
returns the last thing the destination

00:14:52,610 --> 00:14:57,200
we can then pipe that back out to the

00:14:55,160 --> 00:14:59,269
connection so we could do that kind of

00:14:57,200 --> 00:15:01,700
infinitely we can pipe as many other

00:14:59,269 --> 00:15:03,380
things through here on this upper stream

00:15:01,700 --> 00:15:05,149
here knows nothing about where that data

00:15:03,380 --> 00:15:07,399
is coming from if that's a 0 and Q

00:15:05,149 --> 00:15:09,649
message coming in and being piped out to

00:15:07,399 --> 00:15:11,269
an HTTP connection completely fine so

00:15:09,649 --> 00:15:13,010
you don't have to worry about the kind

00:15:11,269 --> 00:15:15,290
of plumbing of your application when

00:15:13,010 --> 00:15:17,180
you're writing things like maps and I'm

00:15:15,290 --> 00:15:19,640
not going to show it for every other

00:15:17,180 --> 00:15:22,130
example but this kind of structure

00:15:19,640 --> 00:15:24,380
surrounds everything that we could do we

00:15:22,130 --> 00:15:26,990
always have this flexibility to send

00:15:24,380 --> 00:15:33,440
data off where we need it assuming this

00:15:26,990 --> 00:15:37,670
works good so far so now it should be a

00:15:33,440 --> 00:15:39,860
sheltie hello world yeah so that is just

00:15:37,670 --> 00:15:41,570
happening as the data comes through its

00:15:39,860 --> 00:15:43,850
processing in that function and sending

00:15:41,570 --> 00:15:45,860
it back out again straightforward so

00:15:43,850 --> 00:15:48,920
react is very cool and react is exactly

00:15:45,860 --> 00:15:53,180
what you wanted to use and that handles

00:15:48,920 --> 00:15:54,829
because it's got pipes in it streams in

00:15:53,180 --> 00:15:56,600
it and the pipes and it handles the

00:15:54,829 --> 00:15:58,310
piping handles the ability to move data

00:15:56,600 --> 00:16:00,470
about so one of the five things we need

00:15:58,310 --> 00:16:02,870
is ticked off mapping functions well

00:16:00,470 --> 00:16:05,000
we've got all of PHP it's a generic

00:16:02,870 --> 00:16:06,769
general-purpose programming language so

00:16:05,000 --> 00:16:08,329
there's almost nothing we can't do we

00:16:06,769 --> 00:16:10,579
can go and look up in a database or we

00:16:08,329 --> 00:16:12,920
can go and transform it in some way we

00:16:10,579 --> 00:16:14,510
can do almost anything so we don't need

00:16:12,920 --> 00:16:16,760
to be clever about the mapping functions

00:16:14,510 --> 00:16:21,640
so they get taken away as well so what

00:16:16,760 --> 00:16:21,640
we're left with is the windows

00:16:22,420 --> 00:16:31,070
and that's roughly what eep actually

00:16:25,970 --> 00:16:32,150
provides so the first kind of window

00:16:31,070 --> 00:16:35,720
that's worth been aware of and we'll

00:16:32,150 --> 00:16:38,930
look at three is a tumbling window and

00:16:35,720 --> 00:16:40,490
this is really really common use case so

00:16:38,930 --> 00:16:42,620
you have events coming in we have this

00:16:40,490 --> 00:16:46,220
stream of events of the top one to nine

00:16:42,620 --> 00:16:48,890
then back down we have a window size of

00:16:46,220 --> 00:16:51,770
four as events come in they go into the

00:16:48,890 --> 00:16:55,010
window once it hits its limit it emits

00:16:51,770 --> 00:16:57,170
and it closes the window and opens a new

00:16:55,010 --> 00:16:58,880
one so the window tumbles and then we

00:16:57,170 --> 00:17:00,620
get a new one once that fills up gets to

00:16:58,880 --> 00:17:03,080
for its limit it emits and opens a new

00:17:00,620 --> 00:17:04,699
one and the emit just means it's calling

00:17:03,080 --> 00:17:07,339
the function underneath it's calling

00:17:04,699 --> 00:17:10,040
this aggregator it's calling its memory

00:17:07,339 --> 00:17:12,760
function whatever it is so the kind of

00:17:10,040 --> 00:17:17,449
thing you could do with that would be

00:17:12,760 --> 00:17:19,699
say something like our server monitor so

00:17:17,449 --> 00:17:21,560
you might want to take a stream of

00:17:19,699 --> 00:17:23,959
events from your server that are showing

00:17:21,560 --> 00:17:26,360
the latency how long it's taken to serve

00:17:23,959 --> 00:17:30,080
a particular page and you might want to

00:17:26,360 --> 00:17:31,520
use that as a alerting system you want

00:17:30,080 --> 00:17:34,540
to say hey my my servers going a bit

00:17:31,520 --> 00:17:38,300
wonky this is not a wonderful situation

00:17:34,540 --> 00:17:40,160
so we can bring in auto load and then we

00:17:38,300 --> 00:17:41,750
create a mean function the mean is an

00:17:40,160 --> 00:17:43,360
aggregate function which is just going

00:17:41,750 --> 00:17:46,520
to calculate the average over the window

00:17:43,360 --> 00:17:51,830
we create a new tumbling window with a

00:17:46,520 --> 00:17:54,980
size of 100 and we set up a call back in

00:17:51,830 --> 00:17:56,330
the emit event that says you know just

00:17:54,980 --> 00:17:57,980
take that average let's come back from

00:17:56,330 --> 00:17:59,870
the main function if it's over 290

00:17:57,980 --> 00:18:02,240
you'll know server's not doing the right

00:17:59,870 --> 00:18:03,800
thing we'd better signal a lot just

00:18:02,240 --> 00:18:05,000
going to print it out and down here we

00:18:03,800 --> 00:18:08,540
actually pump data and of course we're

00:18:05,000 --> 00:18:10,190
just making up data so it's a win in

00:18:08,540 --> 00:18:12,770
queue and in queue just says push that

00:18:10,190 --> 00:18:14,300
event in so what that looks like we run

00:18:12,770 --> 00:18:18,050
it is what kind of you know what you'd

00:18:14,300 --> 00:18:20,570
expect expect it's a PHP he's so on

00:18:18,050 --> 00:18:23,360
Paul's server mom it prints out a bunch

00:18:20,570 --> 00:18:26,020
of alerts so we pushed 50,000 events

00:18:23,360 --> 00:18:29,600
through it and you know by chance so no

00:18:26,020 --> 00:18:31,430
50 were over that limit 50 of them were

00:18:29,600 --> 00:18:33,380
events that would have triggered a lot

00:18:31,430 --> 00:18:35,060
so we can handle quite a few events with

00:18:33,380 --> 00:18:36,650
us the speed is quite good and one the

00:18:35,060 --> 00:18:40,880
reasons the speed is quite good is that

00:18:36,650 --> 00:18:42,620
these things don't keep a lot of data

00:18:40,880 --> 00:18:45,890
around so if you look at the mean

00:18:42,620 --> 00:18:48,950
function this is what's in it it's that

00:18:45,890 --> 00:18:51,950
big it's not complicated but we're not

00:18:48,950 --> 00:18:56,180
keeping the whole window and going count

00:18:51,950 --> 00:18:59,030
it all up divide it we're creating a

00:18:56,180 --> 00:19:01,550
running count and just as that count

00:18:59,030 --> 00:19:03,530
goes when we're told to omit it we just

00:19:01,550 --> 00:19:06,020
omit whatever the mean is at that point

00:19:03,530 --> 00:19:08,450
and when we're told to initialize we

00:19:06,020 --> 00:19:10,940
just reset everything 20 and the window

00:19:08,450 --> 00:19:13,160
actually manages it the window doesn't

00:19:10,940 --> 00:19:15,320
keep that data around either so what

00:19:13,160 --> 00:19:17,840
it's doing in this case is setting up a

00:19:15,320 --> 00:19:19,280
limit and as events come in it sends

00:19:17,840 --> 00:19:22,130
them through to the accumulator and

00:19:19,280 --> 00:19:24,050
forgets about them when it's had as many

00:19:22,130 --> 00:19:27,410
as it needs so when the index hits the

00:19:24,050 --> 00:19:29,540
size it just tells the aggregate to omit

00:19:27,410 --> 00:19:33,830
it just says tell me what the current

00:19:29,540 --> 00:19:35,690
value is and then resets it there's very

00:19:33,830 --> 00:19:37,880
little complexity in it and that's one

00:19:35,690 --> 00:19:41,240
of the things the examples here are in

00:19:37,880 --> 00:19:42,740
this eep dot PHP but you could do them

00:19:41,240 --> 00:19:44,510
in almost anything almost any stream

00:19:42,740 --> 00:19:46,190
system almost anything where you can

00:19:44,510 --> 00:19:50,210
just write code you can knock up this

00:19:46,190 --> 00:19:52,580
literally it's a weekend's work so you

00:19:50,210 --> 00:19:56,090
can build something like that but if you

00:19:52,580 --> 00:19:57,440
look at this the average of something

00:19:56,090 --> 00:19:59,720
like detecting latency it's not very

00:19:57,440 --> 00:20:01,670
powerful right because i think it's

00:19:59,720 --> 00:20:03,380
morgan taka the nice to say if you look

00:20:01,670 --> 00:20:05,630
at the average temperature of people in

00:20:03,380 --> 00:20:07,340
a hospital they look fine you can't tell

00:20:05,630 --> 00:20:08,510
that some of them are overheating and

00:20:07,340 --> 00:20:12,080
dying and some of them are too cold and

00:20:08,510 --> 00:20:13,100
I so we can calculate more statistics so

00:20:12,080 --> 00:20:15,320
what we've got down here is just the

00:20:13,100 --> 00:20:17,030
same thing I mean exactly the same thing

00:20:15,320 --> 00:20:19,460
except we use in a slightly different

00:20:17,030 --> 00:20:21,080
stats function all we can calculate a

00:20:19,460 --> 00:20:22,910
whole bunch of different statistics at

00:20:21,080 --> 00:20:24,920
the same time and all it costs us is

00:20:22,910 --> 00:20:26,000
kind of like a few extra variables so we

00:20:24,920 --> 00:20:28,010
can calculate the standard deviation

00:20:26,000 --> 00:20:29,870
which is how widely spread apart the

00:20:28,010 --> 00:20:32,330
values are we can calculate the average

00:20:29,870 --> 00:20:34,280
them in the max we can count up how many

00:20:32,330 --> 00:20:36,590
values we've seen all of that kind of

00:20:34,280 --> 00:20:39,140
thing so that means we can do a much

00:20:36,590 --> 00:20:40,640
more complex detector we can say hey if

00:20:39,140 --> 00:20:42,470
the standard deviation is over this

00:20:40,640 --> 00:20:42,909
level and the mean is over this level

00:20:42,470 --> 00:20:45,159
and the

00:20:42,909 --> 00:20:46,869
this is over this level then something

00:20:45,159 --> 00:20:51,759
really is going wrong it's not just

00:20:46,869 --> 00:20:52,899
chance and so we run that and we get all

00:20:51,759 --> 00:20:55,599
the others we did have and then have

00:20:52,899 --> 00:20:58,179
actually saved the file then we get many

00:20:55,599 --> 00:20:59,619
less for the combined events so the

00:20:58,179 --> 00:21:02,049
combined event is a much more sensitive

00:20:59,619 --> 00:21:04,179
discriminator so we can easily start

00:21:02,049 --> 00:21:05,710
making more and more useful

00:21:04,179 --> 00:21:07,029
discriminators without having to change

00:21:05,710 --> 00:21:09,099
the data we don't have to go back and

00:21:07,029 --> 00:21:10,269
omit anything new we don't really have

00:21:09,099 --> 00:21:12,190
to care about going back and

00:21:10,269 --> 00:21:13,690
reprocessing all data because we don't

00:21:12,190 --> 00:21:15,970
care about all data we care about things

00:21:13,690 --> 00:21:18,399
that are going to change now so we can

00:21:15,970 --> 00:21:20,080
just update our detector we can update

00:21:18,399 --> 00:21:24,129
our aggregate function and we can do

00:21:20,080 --> 00:21:26,379
more interesting things with it so the

00:21:24,129 --> 00:21:28,929
next type of window is a periodic window

00:21:26,379 --> 00:21:30,639
and this is really really important one

00:21:28,929 --> 00:21:33,009
as well but also slightly tricky to use

00:21:30,639 --> 00:21:35,710
so a periodic window has another concept

00:21:33,009 --> 00:21:38,049
that concept is the time and a periodic

00:21:35,710 --> 00:21:39,820
window says every the window length is

00:21:38,049 --> 00:21:42,159
not to find a number of events but in

00:21:39,820 --> 00:21:43,509
the time over those events which means

00:21:42,159 --> 00:21:45,729
it's very varied of how many events

00:21:43,509 --> 00:21:47,679
might be in there you could have in this

00:21:45,729 --> 00:21:49,029
case we've got five minute window we've

00:21:47,679 --> 00:21:50,859
got five events in the first window

00:21:49,029 --> 00:21:52,119
three events in the second window

00:21:50,859 --> 00:21:55,299
because they just weren't as many the

00:21:52,119 --> 00:21:56,499
same time past but with less events one

00:21:55,299 --> 00:21:57,879
of the things that actually happens with

00:21:56,499 --> 00:21:59,759
these kind of systems is you can find a

00:21:57,879 --> 00:22:02,950
lot of cases where it'll actually be

00:21:59,759 --> 00:22:04,989
order of magnitude more events in some

00:22:02,950 --> 00:22:06,519
windows than other because a lot of

00:22:04,989 --> 00:22:08,320
stuff is in fact spiky is in fact

00:22:06,519 --> 00:22:09,909
bursting so it can change how your

00:22:08,320 --> 00:22:12,669
processing that's why it's so important

00:22:09,909 --> 00:22:13,840
to keep as little data as you need

00:22:12,669 --> 00:22:15,639
because it gives you the most

00:22:13,840 --> 00:22:17,830
flexibility as the data is moving

00:22:15,639 --> 00:22:20,379
through you'll also notice i say wall

00:22:17,830 --> 00:22:22,299
clock not a wall clock I mean literally

00:22:20,379 --> 00:22:25,470
the clock on the wall the time that is

00:22:22,299 --> 00:22:27,549
on your watch on your phone that time is

00:22:25,470 --> 00:22:28,899
inconsistent anyone that's tried to deal

00:22:27,549 --> 00:22:31,149
with a bunch of servers and had to deal

00:22:28,899 --> 00:22:33,190
with ntp issues there are times when

00:22:31,149 --> 00:22:34,869
your server goes back in time because

00:22:33,190 --> 00:22:37,899
it's got it wrong and it has the correct

00:22:34,869 --> 00:22:40,029
from ntp so it doesn't mean that if the

00:22:37,899 --> 00:22:42,009
time now is this that in a second the

00:22:40,029 --> 00:22:44,080
time will be one second greater these

00:22:42,009 --> 00:22:45,399
things change so you might not want to

00:22:44,080 --> 00:22:47,559
use the wall clock you might want to use

00:22:45,399 --> 00:22:49,960
a monotonic clock which is just a

00:22:47,559 --> 00:22:52,299
counter you might want to use a vector

00:22:49,960 --> 00:22:54,899
clock like dynamo based databases like

00:22:52,299 --> 00:22:56,410
react to use these kind of things are

00:22:54,899 --> 00:22:59,140
alternate ways

00:22:56,410 --> 00:23:01,330
of kind of measuring progress or some

00:22:59,140 --> 00:23:03,640
other factor which you will use to

00:23:01,330 --> 00:23:06,270
determine window size and you can use

00:23:03,640 --> 00:23:09,550
them in a pretty straightforward way so

00:23:06,270 --> 00:23:10,750
similar sort of monitoring situation

00:23:09,550 --> 00:23:12,700
maybe you don't want to monitor your

00:23:10,750 --> 00:23:15,280
server you want to monitor the

00:23:12,700 --> 00:23:16,840
effectiveness of your site so let's say

00:23:15,280 --> 00:23:19,450
that you have sign ups or you have

00:23:16,840 --> 00:23:21,730
purchases and you want to look at if I

00:23:19,450 --> 00:23:24,220
have less than a certain number in a

00:23:21,730 --> 00:23:25,900
certain time period there's a problem I

00:23:24,220 --> 00:23:27,310
don't it doesn't even have to be with my

00:23:25,900 --> 00:23:29,200
site it might be the my upstream

00:23:27,310 --> 00:23:31,810
bandwidth provide as a problem it might

00:23:29,200 --> 00:23:33,550
be that my customers can't get to me for

00:23:31,810 --> 00:23:35,110
whatever reason and but it indicates

00:23:33,550 --> 00:23:38,020
that I'm not getting the usual traffic

00:23:35,110 --> 00:23:40,840
the thing I expect and the point of this

00:23:38,020 --> 00:23:43,690
is that all we're doing to do that is to

00:23:40,840 --> 00:23:46,330
account over a window of time so what

00:23:43,690 --> 00:23:49,180
the events are kind of doesn't matter if

00:23:46,330 --> 00:23:51,670
I'm pushing through a someone's bought

00:23:49,180 --> 00:23:53,470
this item event it doesn't matter what's

00:23:51,670 --> 00:23:55,240
in that event for this particular window

00:23:53,470 --> 00:23:57,490
so I can be pushing that for other

00:23:55,240 --> 00:24:00,030
reasons to do other analysis on and

00:23:57,490 --> 00:24:03,760
still make use of it to detect low rates

00:24:00,030 --> 00:24:05,170
so doing this from a utilization point

00:24:03,760 --> 00:24:07,090
of view same thing we have an aggregate

00:24:05,170 --> 00:24:08,170
function which is the count all that's

00:24:07,090 --> 00:24:09,850
going to do is count up it's pretty

00:24:08,170 --> 00:24:12,550
straightforward and we have the periodic

00:24:09,850 --> 00:24:15,490
window which has a size of five seconds

00:24:12,550 --> 00:24:17,260
so five thousand milliseconds and again

00:24:15,490 --> 00:24:19,480
we have an emit and that callback

00:24:17,260 --> 00:24:21,280
function that just looks at the count

00:24:19,480 --> 00:24:25,960
and say hey is it low is this low rate

00:24:21,280 --> 00:24:27,940
so when we we do that we can do examples

00:24:25,960 --> 00:24:30,250
low rate and that's just going to sit

00:24:27,940 --> 00:24:32,590
there for five seconds now we aren't

00:24:30,250 --> 00:24:33,730
having that we aren't having a clock go

00:24:32,590 --> 00:24:35,710
in the background we're not having a

00:24:33,730 --> 00:24:37,390
kind of JavaScript style set time out to

00:24:35,710 --> 00:24:38,860
say this is going to happen we tick the

00:24:37,390 --> 00:24:41,050
clock when we want because the clock

00:24:38,860 --> 00:24:42,430
isn't necessarily a wall clock we could

00:24:41,050 --> 00:24:44,080
hook it up if we wanted to hook it up to

00:24:42,430 --> 00:24:46,750
a set timeout and tick the clock every

00:24:44,080 --> 00:24:48,730
second we could but it's our decision

00:24:46,750 --> 00:24:50,800
it's not something that the the window

00:24:48,730 --> 00:24:53,400
decides so you see that we had we had 21

00:24:50,800 --> 00:24:55,990
low rate come in so we signaled a lot

00:24:53,400 --> 00:25:00,610
what the clock looks like is just a

00:24:55,990 --> 00:25:02,110
thing that takes on tops so if we drop

00:25:00,610 --> 00:25:04,260
so to match you make this a little bit

00:25:02,110 --> 00:25:04,260
bigger

00:25:05,520 --> 00:25:13,900
so a the clock has a couple of just

00:25:12,040 --> 00:25:15,640
simple functions in it it just measures

00:25:13,900 --> 00:25:17,920
the time when it starts it knows the

00:25:15,640 --> 00:25:20,350
interval that it has to take over and

00:25:17,920 --> 00:25:23,500
all it does when you you check is just

00:25:20,350 --> 00:25:25,660
say has the current time passed the

00:25:23,500 --> 00:25:27,010
interval and that's it that's what it

00:25:25,660 --> 00:25:29,470
needs to do it doesn't need to know

00:25:27,010 --> 00:25:30,730
exactly how long has passed it just

00:25:29,470 --> 00:25:32,230
needs to know is it past the last

00:25:30,730 --> 00:25:34,480
interval because if it has the window

00:25:32,230 --> 00:25:37,290
should close so all the window has to do

00:25:34,480 --> 00:25:40,440
is ticket so if we look at the actual

00:25:37,290 --> 00:25:42,310
periodic window it just extends the

00:25:40,440 --> 00:25:44,350
monotonic window because they're roughly

00:25:42,310 --> 00:25:46,270
the same and all the monotonic window

00:25:44,350 --> 00:25:49,060
does is when you take it just says has

00:25:46,270 --> 00:25:51,970
time passed tick if it hasn't carryall

00:25:49,060 --> 00:25:54,340
if it has enough time has passed for a

00:25:51,970 --> 00:25:56,800
window to close then we talk it which

00:25:54,340 --> 00:26:00,610
closes the window we emit an event and

00:25:56,800 --> 00:26:02,860
we start a new one so periodic windows

00:26:00,610 --> 00:26:06,520
are really useful whenever you need to

00:26:02,860 --> 00:26:08,290
consider time as a factor for the window

00:26:06,520 --> 00:26:10,300
size not necessary times a factor of a

00:26:08,290 --> 00:26:11,860
data that's unrelated but when you need

00:26:10,300 --> 00:26:16,600
to consider it for the actual window

00:26:11,860 --> 00:26:18,160
itself the final kind of window that we

00:26:16,600 --> 00:26:20,050
come here now there's loads of windows

00:26:18,160 --> 00:26:22,300
that kind of cep systems and event

00:26:20,050 --> 00:26:23,680
processing systems used but so these are

00:26:22,300 --> 00:26:25,990
thought of the three most useful and the

00:26:23,680 --> 00:26:27,430
final kind is sliding windows so sliding

00:26:25,990 --> 00:26:29,590
window starts like a tumbling window

00:26:27,430 --> 00:26:33,340
events go into it when it hits the size

00:26:29,590 --> 00:26:35,530
admits but once it's hit the size it

00:26:33,340 --> 00:26:38,200
doesn't drop everything and start again

00:26:35,530 --> 00:26:40,330
it just drops the first and adds the

00:26:38,200 --> 00:26:42,610
next event so it slides along with the

00:26:40,330 --> 00:26:45,250
event stream so once it hits its size

00:26:42,610 --> 00:26:48,780
that every new event causes an admit

00:26:45,250 --> 00:26:51,370
every new an event causes a window to

00:26:48,780 --> 00:26:53,380
causes the window to move on so a

00:26:51,370 --> 00:26:55,540
sliding windows you can kind of do

00:26:53,380 --> 00:26:57,400
something that happens on every event so

00:26:55,540 --> 00:26:59,920
you look you're basically at this point

00:26:57,400 --> 00:27:03,640
in time I look back my window size and I

00:26:59,920 --> 00:27:06,880
do some kind of calculation so most of

00:27:03,640 --> 00:27:08,920
the examples thus far have been data

00:27:06,880 --> 00:27:10,840
numeric data that we can do kind of

00:27:08,920 --> 00:27:12,430
statistical computation on which is

00:27:10,840 --> 00:27:13,520
interesting but there's lots of stuff

00:27:12,430 --> 00:27:16,020
that doesn't fit that

00:27:13,520 --> 00:27:18,420
so we might want to do pattern matching

00:27:16,020 --> 00:27:23,400
and all pattern matching tends to come

00:27:18,420 --> 00:27:25,110
down to finite state machines so this is

00:27:23,400 --> 00:27:27,390
an example of a custom aggregate

00:27:25,110 --> 00:27:30,120
function so this is not one less or

00:27:27,390 --> 00:27:32,040
standard ones this is one that defines a

00:27:30,120 --> 00:27:34,080
specific pattern and that pattern is

00:27:32,040 --> 00:27:35,130
looking for is a kind of stock market

00:27:34,080 --> 00:27:37,470
patterns there's something that you

00:27:35,130 --> 00:27:39,270
might use if you are well viewers

00:27:37,470 --> 00:27:42,720
several years ago and not a very good

00:27:39,270 --> 00:27:46,170
trader and the pattern is you have a

00:27:42,720 --> 00:27:48,600
price you see the price job and then you

00:27:46,170 --> 00:27:51,780
see it go higher if you see that happen

00:27:48,600 --> 00:27:53,790
then if in a short time you see a price

00:27:51,780 --> 00:27:55,050
and a drop again you think it's going to

00:27:53,790 --> 00:27:58,350
do the same thing it's going to do high

00:27:55,050 --> 00:27:59,970
so if you see that tick that's a pattern

00:27:58,350 --> 00:28:01,500
matched and then you wait for a trigger

00:27:59,970 --> 00:28:03,240
of a drop and then you know how I should

00:28:01,500 --> 00:28:04,620
buy that price and it'll go higher and i

00:28:03,240 --> 00:28:06,600
can sell it then i can make a little bit

00:28:04,620 --> 00:28:07,860
of money so we can do that with a

00:28:06,600 --> 00:28:09,690
sliding window because we want to look

00:28:07,860 --> 00:28:11,430
back we just want the recent history has

00:28:09,690 --> 00:28:13,350
there been a tick in it has there been a

00:28:11,430 --> 00:28:16,340
tick and the trigger if there has either

00:28:13,350 --> 00:28:18,690
a if not i should move on and i should

00:28:16,340 --> 00:28:20,370
wait until there's the right conditions

00:28:18,690 --> 00:28:23,220
for the trade and that could be easily

00:28:20,370 --> 00:28:25,530
modeled as a state machine so we go from

00:28:23,220 --> 00:28:27,600
the state of not having anything to

00:28:25,530 --> 00:28:30,270
having a first price then we see if it

00:28:27,600 --> 00:28:31,830
drops if it drops great then we wait to

00:28:30,270 --> 00:28:33,840
see it go higher than the original if it

00:28:31,830 --> 00:28:36,090
goes higher great if not at any point we

00:28:33,840 --> 00:28:39,270
reset and that's exactly what we do here

00:28:36,090 --> 00:28:41,520
so as we accumulate as new items get

00:28:39,270 --> 00:28:44,130
pushed into the queue we just check the

00:28:41,520 --> 00:28:46,440
state which state situation are in and

00:28:44,130 --> 00:28:48,300
we take the appropriate action so if

00:28:46,440 --> 00:28:51,150
we've not seen any data over in the

00:28:48,300 --> 00:28:52,950
initial state we just add a data item if

00:28:51,150 --> 00:28:54,900
we've got that we look for a job if we

00:28:52,950 --> 00:28:57,960
don't get the drop we reset and each

00:28:54,900 --> 00:28:59,910
state processes like this simple

00:28:57,960 --> 00:29:03,960
straightforward code there's no real

00:28:59,910 --> 00:29:05,340
data to hold there's no real archive to

00:29:03,960 --> 00:29:07,290
look back we don't have to physically

00:29:05,340 --> 00:29:09,390
look back across the window we don't

00:29:07,290 --> 00:29:12,330
have to go back when we emit we just

00:29:09,390 --> 00:29:15,660
have to update the state of our object

00:29:12,330 --> 00:29:18,980
as we go so the tick detector can then

00:29:15,660 --> 00:29:22,260
just simply move through the states and

00:29:18,980 --> 00:29:24,450
when the examples leave so when the

00:29:22,260 --> 00:29:24,750
sliding window moves on all it has the

00:29:24,450 --> 00:29:28,230
care

00:29:24,750 --> 00:29:30,600
about was did the text art before this

00:29:28,230 --> 00:29:33,240
window so is the event that dropped the

00:29:30,600 --> 00:29:34,710
start of the tech if it is then we need

00:29:33,240 --> 00:29:36,330
to be set because it's too long now

00:29:34,710 --> 00:29:38,970
we've been waiting too long it's no

00:29:36,330 --> 00:29:41,070
longer a valid thing so we can run that

00:29:38,970 --> 00:29:43,410
just on some some simple data and we

00:29:41,070 --> 00:29:44,820
just use a sliding window with size of 7

00:29:43,410 --> 00:29:51,540
and we're going to run it across this

00:29:44,820 --> 00:29:53,940
data with that tick function so okay it

00:29:51,540 --> 00:29:55,830
just goes and it finds a tech and it's

00:29:53,940 --> 00:29:59,310
not clear from that that it's actually

00:29:55,830 --> 00:30:05,700
doing something on every window entry so

00:29:59,310 --> 00:30:07,380
if we just put in just a doll so we see

00:30:05,700 --> 00:30:09,270
that those dots are just being emitted

00:30:07,380 --> 00:30:11,160
as the window closes so it's a window of

00:30:09,270 --> 00:30:13,530
slide 7 moving across in this case just

00:30:11,160 --> 00:30:15,840
12 data items and each time it moves

00:30:13,530 --> 00:30:18,300
it's doing this test it's seen hey are

00:30:15,840 --> 00:30:19,620
we in the right state and only when it

00:30:18,300 --> 00:30:21,720
is in the right state does it emit the

00:30:19,620 --> 00:30:23,040
rest of the time it it just bounces

00:30:21,720 --> 00:30:24,570
around the situations of the state

00:30:23,040 --> 00:30:26,310
machine again not storing very much data

00:30:24,570 --> 00:30:28,110
not doing very much calculation so you

00:30:26,310 --> 00:30:30,650
can many of these at the same time you

00:30:28,110 --> 00:30:33,120
can process a lot of events very quickly

00:30:30,650 --> 00:30:36,690
you can also do data that kind of is

00:30:33,120 --> 00:30:38,760
non-numeric at all so this is again more

00:30:36,690 --> 00:30:40,560
numbers that we're processing with some

00:30:38,760 --> 00:30:42,060
rules around those numbers but we can do

00:30:40,560 --> 00:30:43,530
the same thing with with it with

00:30:42,060 --> 00:30:47,910
anything really one of the examples

00:30:43,530 --> 00:30:51,300
Derek included in EP j s that i ported

00:30:47,910 --> 00:30:53,520
over was tim braised wide finder so Tim

00:30:51,300 --> 00:30:54,750
Bray he's our he works on identity at

00:30:53,520 --> 00:30:56,730
Google now but he was formerly of

00:30:54,750 --> 00:30:59,130
Sunland one of the main guys behind XML

00:30:56,730 --> 00:31:01,890
he was interested in looking at online

00:30:59,130 --> 00:31:04,020
processing of log files so as new

00:31:01,890 --> 00:31:05,430
entries come into his log he wants to

00:31:04,020 --> 00:31:08,520
calculate what's the most popular stuff

00:31:05,430 --> 00:31:10,350
on my site so as stuff comes in that

00:31:08,520 --> 00:31:12,270
just gets updated in a sensible way and

00:31:10,350 --> 00:31:14,310
that's a perfect kind of problem for

00:31:12,270 --> 00:31:16,260
Windows and streaming systems we don't

00:31:14,310 --> 00:31:18,660
want to look at the whole log file we

00:31:16,260 --> 00:31:20,400
just want to look at it as it comes so

00:31:18,660 --> 00:31:22,560
we can set that up again with a custom

00:31:20,400 --> 00:31:25,950
aggregate function what we have here is

00:31:22,560 --> 00:31:27,810
a tumbling window of a size of thousand

00:31:25,950 --> 00:31:30,060
and we have that custom aggregate

00:31:27,810 --> 00:31:31,920
function for white finder and what those

00:31:30,060 --> 00:31:33,330
thousand entries look like is like a

00:31:31,920 --> 00:31:35,850
standard Apache log file you know

00:31:33,330 --> 00:31:37,059
they're going to say the the URL that

00:31:35,850 --> 00:31:38,970
was being addressed and

00:31:37,059 --> 00:31:41,620
I came from and all that kind of stuff

00:31:38,970 --> 00:31:44,440
so what we actually do in the custom

00:31:41,620 --> 00:31:46,330
function is use that regular expression

00:31:44,440 --> 00:31:49,330
to just pass out the URL and then just

00:31:46,330 --> 00:31:52,059
keep a count of matches so we're doing

00:31:49,330 --> 00:31:54,100
is keeping an array and we make the URL

00:31:52,059 --> 00:31:57,820
the key into that array and keep account

00:31:54,100 --> 00:32:00,399
free GRL we see and then at the end we

00:31:57,820 --> 00:32:03,129
are met and we omit that whole thing so

00:32:00,399 --> 00:32:05,379
we see down in the callback all it's

00:32:03,129 --> 00:32:07,179
doing is doing in a very slice taking

00:32:05,379 --> 00:32:09,549
the top 10 of them that have been sorted

00:32:07,179 --> 00:32:11,409
by the number of hits so we can keep a

00:32:09,549 --> 00:32:13,450
running total of what's hot on the

00:32:11,409 --> 00:32:14,619
website right now and that's very much

00:32:13,450 --> 00:32:16,029
what you do if you had a kind of

00:32:14,619 --> 00:32:17,619
e-commerce setup and you wanted to know

00:32:16,029 --> 00:32:18,940
what the what's the hot item right now

00:32:17,619 --> 00:32:20,919
what's the interesting thing that's

00:32:18,940 --> 00:32:22,690
selling you can keep a fairly limited

00:32:20,919 --> 00:32:25,990
amount of data in memory and still

00:32:22,690 --> 00:32:28,990
process events very very quickly so in

00:32:25,990 --> 00:32:31,210
this case we have a as a test the log

00:32:28,990 --> 00:32:36,610
file from Tim site that we put up to

00:32:31,210 --> 00:32:40,090
accompany the post about this and it is

00:32:36,610 --> 00:32:41,619
10,000 10,000 log entries and we've just

00:32:40,090 --> 00:32:44,379
patched them up into windows of a

00:32:41,619 --> 00:32:46,360
thousand so it goes through them like

00:32:44,379 --> 00:32:49,450
this and you can see Oh in the earliest

00:32:46,360 --> 00:32:51,129
one dynamic idea was top and then atomic

00:32:49,450 --> 00:32:52,840
RSS was next and in the most recent

00:32:51,129 --> 00:32:54,610
violent garden you still top and them

00:32:52,840 --> 00:32:56,769
than something else so you could see a

00:32:54,610 --> 00:32:59,529
current total of what things are going

00:32:56,769 --> 00:33:01,720
and while this is hitting a file we

00:32:59,529 --> 00:33:03,039
could do the same thing against you know

00:33:01,720 --> 00:33:04,360
an actual log file that had data

00:33:03,039 --> 00:33:05,950
streaming into it or just a pipe

00:33:04,360 --> 00:33:12,129
straight out of Apache or whichever

00:33:05,950 --> 00:33:16,419
looks over we were using so that's kind

00:33:12,129 --> 00:33:17,950
of the ability to look at numeric data

00:33:16,419 --> 00:33:19,899
and textual data and a lot of things we

00:33:17,950 --> 00:33:23,289
can process events that make sense to us

00:33:19,899 --> 00:33:25,090
but we can also consider joining between

00:33:23,289 --> 00:33:26,860
different streams and actually looking

00:33:25,090 --> 00:33:29,590
at some of this more complex interaction

00:33:26,860 --> 00:33:31,179
between streams and that again doesn't

00:33:29,590 --> 00:33:33,700
have to involve a lot of memory it

00:33:31,179 --> 00:33:37,210
doesn't have to involve a lot of time so

00:33:33,700 --> 00:33:40,360
this is a semi join across two streams

00:33:37,210 --> 00:33:43,409
and this could be used for example if

00:33:40,360 --> 00:33:47,980
you're in a situation where you have a

00:33:43,409 --> 00:33:49,840
stream of auction auction items so

00:33:47,980 --> 00:33:50,860
here's where items are listed and a

00:33:49,840 --> 00:33:52,660
stream of closed

00:33:50,860 --> 00:33:54,730
so here's where the auctions ended and

00:33:52,660 --> 00:33:56,290
you might want to look for the kind of

00:33:54,730 --> 00:33:58,299
items the people are just hitting buy it

00:33:56,290 --> 00:33:59,710
now right away on like is there

00:33:58,299 --> 00:34:03,220
something about them I just want to

00:33:59,710 --> 00:34:05,650
stream the within a window an item has

00:34:03,220 --> 00:34:08,200
been added and ball so they've gone

00:34:05,650 --> 00:34:09,609
really quickly fast moving items I can

00:34:08,200 --> 00:34:11,379
then look at them and say oh is it a

00:34:09,609 --> 00:34:13,540
certain category should I be promoting

00:34:11,379 --> 00:34:15,100
this whatever I want to do that kind of

00:34:13,540 --> 00:34:16,629
decision involves looking at these two

00:34:15,100 --> 00:34:18,820
different streams and doing so in a

00:34:16,629 --> 00:34:21,730
quick way but we don't need to care too

00:34:18,820 --> 00:34:24,129
much about the item so a semi join is

00:34:21,730 --> 00:34:27,190
like well a full database join would be

00:34:24,129 --> 00:34:30,520
like you have speaker ID and talk type

00:34:27,190 --> 00:34:32,800
or and speaker name and audience member

00:34:30,520 --> 00:34:34,929
and audience member name and speaker ID

00:34:32,800 --> 00:34:37,359
and if you join those two together you

00:34:34,929 --> 00:34:40,570
get all of those columns let me do a

00:34:37,359 --> 00:34:42,760
semi join for audience member 2 speaker

00:34:40,570 --> 00:34:45,010
then all you'd get is the columns in

00:34:42,760 --> 00:34:47,020
audience member you would only get them

00:34:45,010 --> 00:34:48,909
if there was a match in speaker but you

00:34:47,020 --> 00:34:50,679
wouldn't get any of the extra data from

00:34:48,909 --> 00:34:52,419
the speaker and that's exactly what we

00:34:50,679 --> 00:34:54,909
need here we don't care about the data

00:34:52,419 --> 00:34:57,070
that was with the list auction event we

00:34:54,909 --> 00:34:59,140
just care that it was there within this

00:34:57,070 --> 00:35:02,020
window so we can use a very similar

00:34:59,140 --> 00:35:04,000
technique to the wide finder here we

00:35:02,020 --> 00:35:07,150
just share an aggregate function between

00:35:04,000 --> 00:35:09,100
two sliding windows s'ok we create our

00:35:07,150 --> 00:35:11,260
semi join function and we create two

00:35:09,100 --> 00:35:13,420
sliding windows and we have the same

00:35:11,260 --> 00:35:16,720
function shared in order to make that

00:35:13,420 --> 00:35:19,840
work we actually wrap the events in a

00:35:16,720 --> 00:35:22,270
muxed type and all that does is just

00:35:19,840 --> 00:35:24,520
take the value and add a stream ID to it

00:35:22,270 --> 00:35:25,750
so it's stream 0 extreme one that

00:35:24,520 --> 00:35:27,369
literally is it there's nothing else

00:35:25,750 --> 00:35:28,869
going on there and that's just so the

00:35:27,369 --> 00:35:32,980
function can tell whether data came from

00:35:28,869 --> 00:35:36,400
and then in the semi join all we're

00:35:32,980 --> 00:35:37,510
doing is keeping two arrays 14 stream 11

00:35:36,400 --> 00:35:38,830
for stream two loves you could

00:35:37,510 --> 00:35:41,440
generalize this to as many streams as

00:35:38,830 --> 00:35:44,500
you wanted and that allows us to see

00:35:41,440 --> 00:35:48,670
which ids have been passed so in the

00:35:44,500 --> 00:35:51,940
accumulate we just check is there an

00:35:48,670 --> 00:35:55,330
entry in the current array that says

00:35:51,940 --> 00:35:57,340
this item has been in there if there is

00:35:55,330 --> 00:35:58,960
we just increment it because the same

00:35:57,340 --> 00:36:00,950
item might come up more than once for

00:35:58,960 --> 00:36:05,030
whatever reason

00:36:00,950 --> 00:36:06,740
and then we check the opposite array so

00:36:05,030 --> 00:36:09,530
down here we're just eggs or in to get

00:36:06,740 --> 00:36:13,250
the other stream ID and we just check is

00:36:09,530 --> 00:36:16,520
there the same ID in the other window if

00:36:13,250 --> 00:36:20,420
there is we set last value and last

00:36:16,520 --> 00:36:22,220
value is emitted on every step so if

00:36:20,420 --> 00:36:24,890
it's a match last value gets set to

00:36:22,220 --> 00:36:29,060
something if not last value stays null

00:36:24,890 --> 00:36:30,470
so we only get a mitad event if there

00:36:29,060 --> 00:36:32,810
was a match between these two streams

00:36:30,470 --> 00:36:34,220
but we don't care what happened in the

00:36:32,810 --> 00:36:35,810
other stream we don't care about what

00:36:34,220 --> 00:36:38,210
the data was we just care there was a

00:36:35,810 --> 00:36:39,619
match and the compensate function is

00:36:38,210 --> 00:36:43,099
really easy because we're keeping a

00:36:39,619 --> 00:36:45,140
count of what how many times we've seen

00:36:43,099 --> 00:36:47,089
a given ID where you can just decrement

00:36:45,140 --> 00:36:48,859
that cat once it goes to 0 we know it's

00:36:47,089 --> 00:36:50,150
no longer within this window and get rid

00:36:48,859 --> 00:36:52,940
of it so we're not storing a lot of data

00:36:50,150 --> 00:36:56,329
just storing IDs and a count of how many

00:36:52,940 --> 00:36:59,359
times we've seen them and we can run

00:36:56,329 --> 00:37:05,690
that and we can put a bunch of her data

00:36:59,359 --> 00:37:07,280
through okay so those yeah i just put

00:37:05,690 --> 00:37:09,349
50,000 events through and a whole bunch

00:37:07,280 --> 00:37:10,970
of categories came up that matched

00:37:09,349 --> 00:37:13,190
between these two things so there's a

00:37:10,970 --> 00:37:15,770
simple way of joining those two streams

00:37:13,190 --> 00:37:17,839
and getting some results out so finally

00:37:15,770 --> 00:37:19,730
I just wanted to show kind of where you

00:37:17,839 --> 00:37:21,460
could go with this though you won't

00:37:19,730 --> 00:37:24,020
better code than this this is really

00:37:21,460 --> 00:37:26,060
sort of a thought experiment in code

00:37:24,020 --> 00:37:29,119
rather than a particularly finished idea

00:37:26,060 --> 00:37:30,800
and that was it would be nice to predict

00:37:29,119 --> 00:37:33,290
the future right we'd like to be able to

00:37:30,800 --> 00:37:34,849
do predictions and at the moment that's

00:37:33,290 --> 00:37:36,980
difficult everything we've done is gives

00:37:34,849 --> 00:37:38,540
us analysis and we could make a decision

00:37:36,980 --> 00:37:41,180
based on it or making a prediction is

00:37:38,540 --> 00:37:43,550
hard but what we can do by looking at

00:37:41,180 --> 00:37:46,250
multiple streams is attempt to find a

00:37:43,550 --> 00:37:48,319
correlation and if we can find a

00:37:46,250 --> 00:37:50,569
correlation over time we can determine a

00:37:48,319 --> 00:37:53,000
leader so imagine a situation where we

00:37:50,569 --> 00:37:54,710
had the Layton sees from a database and

00:37:53,000 --> 00:37:57,369
from a reddit server and from a web

00:37:54,710 --> 00:37:59,690
server if we could look at that and see

00:37:57,369 --> 00:38:02,150
when we see a spike in the database

00:37:59,690 --> 00:38:04,700
server we see a spike in the web server

00:38:02,150 --> 00:38:06,980
two seconds later then we could know if

00:38:04,700 --> 00:38:09,589
we see that spike we should immediately

00:38:06,980 --> 00:38:11,150
you know do some swimlane inor or turn

00:38:09,589 --> 00:38:12,970
offs and features or do something to

00:38:11,150 --> 00:38:14,859
protect our user experience

00:38:12,970 --> 00:38:16,270
so users never see the problem so we can

00:38:14,859 --> 00:38:18,880
actually get ahead of the problem before

00:38:16,270 --> 00:38:21,280
it's visible to users but we can do that

00:38:18,880 --> 00:38:23,260
without having to hard-code yes this

00:38:21,280 --> 00:38:25,270
thing if we see it here first then here

00:38:23,260 --> 00:38:27,609
we can actually continually watch the

00:38:25,270 --> 00:38:28,810
streams watch the events and detect

00:38:27,609 --> 00:38:30,849
whether there is a leadership

00:38:28,810 --> 00:38:33,400
relationship there and all we need to do

00:38:30,849 --> 00:38:37,510
that is to correlate so this really

00:38:33,400 --> 00:38:39,369
hacky class actually is a window kind of

00:38:37,510 --> 00:38:42,400
with aggregate functions in it so what

00:38:39,369 --> 00:38:45,040
it does is create one window across two

00:38:42,400 --> 00:38:47,200
streams and it divides it into sub

00:38:45,040 --> 00:38:48,970
windows so in this case in the example

00:38:47,200 --> 00:38:52,180
it divides it into four sub windows and

00:38:48,970 --> 00:38:55,119
then it compares each sub window and it

00:38:52,180 --> 00:38:56,920
compares them using a standard pearson

00:38:55,119 --> 00:38:58,660
correlations this is just like if you

00:38:56,920 --> 00:39:00,849
google correlate the wikipedia entry

00:38:58,660 --> 00:39:02,320
that the first thing in it is this

00:39:00,849 --> 00:39:04,810
formula it's very very simple

00:39:02,320 --> 00:39:06,250
correlation and it's just saying if it

00:39:04,810 --> 00:39:08,020
goes up in one does it go up in the

00:39:06,250 --> 00:39:09,640
other or if it goes up in one does it go

00:39:08,020 --> 00:39:11,500
down in the other either way does one

00:39:09,640 --> 00:39:14,170
influence the other and what we're

00:39:11,500 --> 00:39:17,770
looking for is a correlation between one

00:39:14,170 --> 00:39:19,270
in the past and one in the future if we

00:39:17,770 --> 00:39:20,530
see that correlation we know we've

00:39:19,270 --> 00:39:22,930
detected a leader and we can do

00:39:20,530 --> 00:39:24,730
something about it so here we have some

00:39:22,930 --> 00:39:27,400
data that is there's clearly bit of

00:39:24,730 --> 00:39:28,839
correlation in that we again use the

00:39:27,400 --> 00:39:31,180
muxing because we're putting two

00:39:28,839 --> 00:39:35,890
different streams together and when we

00:39:31,180 --> 00:39:37,869
run it we can see initially it wasn't

00:39:35,890 --> 00:39:40,119
sure initially it was a balanced table

00:39:37,869 --> 00:39:42,220
but then as the stream stabilized we

00:39:40,119 --> 00:39:45,310
could see the we've clearly detected the

00:39:42,220 --> 00:39:46,960
stream 0 does lead stream 1 and that

00:39:45,310 --> 00:39:49,869
means we can make a decision about that

00:39:46,960 --> 00:39:52,240
we could use stream 0 to predict the

00:39:49,869 --> 00:39:54,430
behavior in the future of stream 1 and

00:39:52,240 --> 00:39:56,740
that's really powerful and if we didn't

00:39:54,430 --> 00:39:58,270
know you know is this database versus

00:39:56,740 --> 00:40:00,310
red its database first we could just run

00:39:58,270 --> 00:40:02,230
the combinations we have multiple of

00:40:00,310 --> 00:40:05,260
these running on different processes

00:40:02,230 --> 00:40:09,280
different processes that allow us to

00:40:05,260 --> 00:40:10,839
handle this sort of volume of data so i

00:40:09,280 --> 00:40:12,910
hope that gives you kind of an idea of

00:40:10,839 --> 00:40:17,800
some of the things that you can do with

00:40:12,910 --> 00:40:20,800
just some simple functions i wanted to

00:40:17,800 --> 00:40:23,230
leave it with with two quick points one

00:40:20,800 --> 00:40:25,300
warning that you can process tens of

00:40:23,230 --> 00:40:27,490
thousands a second with with

00:40:25,300 --> 00:40:29,230
not decode that's on github right now

00:40:27,490 --> 00:40:31,120
this will easily do 50 thousand events

00:40:29,230 --> 00:40:34,000
per second that's not a problem that's

00:40:31,120 --> 00:40:37,150
not that big a number if you are doing

00:40:34,000 --> 00:40:38,740
the same thing in say directs node

00:40:37,150 --> 00:40:40,750
version you can probably process

00:40:38,740 --> 00:40:43,090
millions of events per second now the

00:40:40,750 --> 00:40:45,280
reason for that is the most of these

00:40:43,090 --> 00:40:47,230
examples don't do very much work and if

00:40:45,280 --> 00:40:49,270
you're not doing very much work you can

00:40:47,230 --> 00:40:51,130
do that faster in node the new cam PHP

00:40:49,270 --> 00:40:52,900
if we're doing quite a lot of work per

00:40:51,130 --> 00:40:54,700
event it doesn't make any difference but

00:40:52,900 --> 00:40:57,100
certain languages are faster add doing

00:40:54,700 --> 00:40:58,300
nothing than others and it's it's

00:40:57,100 --> 00:40:59,620
important to be aware of it because

00:40:58,300 --> 00:41:02,080
sometimes you actually want to be able

00:40:59,620 --> 00:41:03,700
to do nothing really fast so if you're

00:41:02,080 --> 00:41:05,050
doing this I would imagine you can all

00:41:03,700 --> 00:41:06,970
get started right now with whatever

00:41:05,050 --> 00:41:08,740
you're using it's just going to work but

00:41:06,970 --> 00:41:10,480
if you really do get to a state where

00:41:08,740 --> 00:41:12,070
you're pushing hundreds of thousands or

00:41:10,480 --> 00:41:14,200
millions event for a single process

00:41:12,070 --> 00:41:16,000
might not through multiple where it's a

00:41:14,200 --> 00:41:17,890
different issue but for a single process

00:41:16,000 --> 00:41:20,170
you may need to consider which language

00:41:17,890 --> 00:41:21,640
you're doing in and I haven't tried this

00:41:20,170 --> 00:41:26,140
on hip hop but I would imagine it'll be

00:41:21,640 --> 00:41:29,290
a lot faster if you did so thank you I

00:41:26,140 --> 00:41:30,700
think we're pretty much done on time so

00:41:29,290 --> 00:41:33,190
I will be around if anyone has any

00:41:30,700 --> 00:41:34,680
questions please do come up and talk to

00:41:33,190 --> 00:41:36,850
me or pick me on any of those venues

00:41:34,680 --> 00:41:39,760
please leave some feedback on joined in

00:41:36,850 --> 00:41:42,700
and all the code from this is here and

00:41:39,760 --> 00:41:44,410
all the code from derek's no Jess

00:41:42,700 --> 00:41:45,970
implementation is here and apparently

00:41:44,410 --> 00:41:47,350
he's working on Erlang and someone's

00:41:45,970 --> 00:41:48,940
working on the closure version so there

00:41:47,350 --> 00:41:50,320
should be many many language

00:41:48,940 --> 00:41:53,940
implementations of these same kind of

00:41:50,320 --> 00:41:53,940
ideas to look at thank

00:42:03,830 --> 00:42:05,890

YouTube URL: https://www.youtube.com/watch?v=js0zEArFVz8


