Title: Nader Dabit - The future of Real-time offline data
Publication date: 2020-02-22
Playlist: AgentConf 2020
Description: 
	The future of Real-time/offline/data
Captions: 
	00:00:00,030 --> 00:00:05,400
I just feel like it's a very community

00:00:03,300 --> 00:00:08,910
driven conference it also is a lot of

00:00:05,400 --> 00:00:10,769
quality and people are just nice hi my

00:00:08,910 --> 00:00:11,730
name's Sarah and this is agent comp in

00:00:10,769 --> 00:00:15,420
Dortmund

00:00:11,730 --> 00:00:18,099
[Music]

00:00:15,420 --> 00:00:20,500
amazing venue Austria is beautiful

00:00:18,099 --> 00:00:25,300
meeting all the people in the community

00:00:20,500 --> 00:00:33,040
and getting to go and hang out and ski

00:00:25,300 --> 00:00:33,040
[Music]

00:00:35,640 --> 00:00:41,290
all right as she mentioned building

00:00:38,199 --> 00:00:42,640
offline firsts apps are not easy and I'm

00:00:41,290 --> 00:00:44,350
gonna be really talking about two things

00:00:42,640 --> 00:00:46,659
the first is building offline first

00:00:44,350 --> 00:00:48,610
applications and I think before we talk

00:00:46,659 --> 00:00:52,119
about actually doing this we should talk

00:00:48,610 --> 00:00:53,830
about what this actually means so I kind

00:00:52,119 --> 00:00:56,140
of picked up three definitions off of a

00:00:53,830 --> 00:00:59,260
combination of the Internet and kind of

00:00:56,140 --> 00:01:01,000
my own ideas so the first is this the

00:00:59,260 --> 00:01:02,860
core features should function with or

00:01:01,000 --> 00:01:05,409
without an internet connection you know

00:01:02,860 --> 00:01:07,090
that's pretty obvious that doesn't mean

00:01:05,409 --> 00:01:08,950
the entire app has to function without

00:01:07,090 --> 00:01:11,470
an internet connection it just basically

00:01:08,950 --> 00:01:13,119
means that we have a core subset of

00:01:11,470 --> 00:01:15,759
features we have a core subset of

00:01:13,119 --> 00:01:17,440
functionality we want this to work we

00:01:15,759 --> 00:01:18,610
also don't want the app to crash we

00:01:17,440 --> 00:01:21,850
don't want things to break when we're

00:01:18,610 --> 00:01:24,580
not connected to the Internet the second

00:01:21,850 --> 00:01:26,350
is this we'd like to have this idea of

00:01:24,580 --> 00:01:30,220
where we're riding our data locally and

00:01:26,350 --> 00:01:32,530
then once the and the end users device

00:01:30,220 --> 00:01:34,840
then periodically up uploads and

00:01:32,530 --> 00:01:37,390
replicates the data to the cloud or to

00:01:34,840 --> 00:01:40,420
whatever database that we have you know

00:01:37,390 --> 00:01:42,250
connected to our app and when you start

00:01:40,420 --> 00:01:44,620
taking this idea are these

00:01:42,250 --> 00:01:45,940
considerations into consideration you

00:01:44,620 --> 00:01:47,590
kind of start thinking about building

00:01:45,940 --> 00:01:49,120
these types of applications is in

00:01:47,590 --> 00:01:53,290
building more of like a distributed

00:01:49,120 --> 00:01:56,080
system the third thing that this

00:01:53,290 --> 00:01:57,280
basically means is that we you know if

00:01:56,080 --> 00:01:59,950
you're building an offline first

00:01:57,280 --> 00:02:02,290
application you end up wanting to

00:01:59,950 --> 00:02:04,600
provide end-users with a consistent user

00:02:02,290 --> 00:02:06,970
experience of course regardless of

00:02:04,600 --> 00:02:09,610
whether they're connected or not but

00:02:06,970 --> 00:02:11,560
also they might have a slow internet

00:02:09,610 --> 00:02:13,510
connection and they might then have a

00:02:11,560 --> 00:02:15,069
fast internet connection they might then

00:02:13,510 --> 00:02:17,080
have no internet connection so kind of

00:02:15,069 --> 00:02:18,430
taking all the different variables of

00:02:17,080 --> 00:02:20,290
like while they're connected while

00:02:18,430 --> 00:02:22,510
they're not connected as their internet

00:02:20,290 --> 00:02:23,709
connection gets better and worse and at

00:02:22,510 --> 00:02:25,480
the end of the day most of the time

00:02:23,709 --> 00:02:26,500
these offline first apps are going to

00:02:25,480 --> 00:02:27,940
provide a

00:02:26,500 --> 00:02:29,920
user experience or a better user

00:02:27,940 --> 00:02:32,080
experience than applications that are

00:02:29,920 --> 00:02:34,510
kind of not optimized for being offline

00:02:32,080 --> 00:02:35,830
first and then the second idea I want to

00:02:34,510 --> 00:02:38,650
talk about is building real-time

00:02:35,830 --> 00:02:41,560
applications so a couple of definitions

00:02:38,650 --> 00:02:43,209
here the first is that a real-time

00:02:41,560 --> 00:02:45,100
application what does it mean

00:02:43,209 --> 00:02:46,840
it basically means an application that

00:02:45,100 --> 00:02:49,709
functions within a time frame that the

00:02:46,840 --> 00:02:52,450
user senses as immediate or close to it

00:02:49,709 --> 00:02:53,650
when you think about this type of

00:02:52,450 --> 00:02:55,750
application you might think about

00:02:53,650 --> 00:02:57,610
something like a chat application where

00:02:55,750 --> 00:02:59,920
you're talking to someone you send a

00:02:57,610 --> 00:03:01,780
message that next response basically

00:02:59,920 --> 00:03:03,160
comes through you're not having to

00:03:01,780 --> 00:03:05,020
refresh the app you don't have to kind

00:03:03,160 --> 00:03:06,730
of go back and forth to retrieve new

00:03:05,020 --> 00:03:08,950
data the data kind of like comes through

00:03:06,730 --> 00:03:11,140
directly you also might think of

00:03:08,950 --> 00:03:12,459
something like Google Docs Google Docs

00:03:11,140 --> 00:03:14,560
you may be collaborating on a

00:03:12,459 --> 00:03:16,090
spreadsheet with someone you're typing

00:03:14,560 --> 00:03:18,250
in this cell they're typing in this cell

00:03:16,090 --> 00:03:20,140
you might have even a half-dozen users

00:03:18,250 --> 00:03:22,840
in the same document they're all typing

00:03:20,140 --> 00:03:24,160
at once you don't have any errors you're

00:03:22,840 --> 00:03:27,190
kind of seeing the movement as it

00:03:24,160 --> 00:03:28,810
happens and then the second is when

00:03:27,190 --> 00:03:31,150
you're building a real-time application

00:03:28,810 --> 00:03:33,280
you're not really thinking of building

00:03:31,150 --> 00:03:35,019
your app in a traditional way you're

00:03:33,280 --> 00:03:37,989
kind of in my opinion thinking of it

00:03:35,019 --> 00:03:40,000
more as a cohesive system where data is

00:03:37,989 --> 00:03:43,060
in sync across all the connected devices

00:03:40,000 --> 00:03:45,130
so you might have dozens or hundreds or

00:03:43,060 --> 00:03:47,530
even thousands or tens of thousands of

00:03:45,130 --> 00:03:49,690
connected devices and you want to make

00:03:47,530 --> 00:03:52,150
sure that the data that you have on your

00:03:49,690 --> 00:03:53,620
device ends up being propagated to all

00:03:52,150 --> 00:04:00,040
the different devices that are also

00:03:53,620 --> 00:04:02,560
connected to the same system so what my

00:04:00,040 --> 00:04:03,790
talk is really about is in my opinion

00:04:02,560 --> 00:04:04,959
when you're building real-time

00:04:03,790 --> 00:04:07,510
applications and we were building

00:04:04,959 --> 00:04:08,680
offline first applications okay just

00:04:07,510 --> 00:04:11,290
want to make sure my animations are

00:04:08,680 --> 00:04:13,120
working there when you're thinking about

00:04:11,290 --> 00:04:14,380
building these two types of applications

00:04:13,120 --> 00:04:15,760
there's a lot of overlap and the

00:04:14,380 --> 00:04:18,190
functionality and there's a lot of

00:04:15,760 --> 00:04:19,750
overlap in the considerations and I

00:04:18,190 --> 00:04:21,609
think when you're building you know this

00:04:19,750 --> 00:04:23,919
type of application either real-time or

00:04:21,609 --> 00:04:26,500
offline first if you can kind of merge

00:04:23,919 --> 00:04:28,270
the two into something that works really

00:04:26,500 --> 00:04:29,860
great you end up kind of with what I

00:04:28,270 --> 00:04:32,080
thought what I kind of consider modern

00:04:29,860 --> 00:04:33,610
application development so you know

00:04:32,080 --> 00:04:36,840
welcome to my talk this is the future of

00:04:33,610 --> 00:04:36,840
real time offline data

00:04:38,770 --> 00:04:42,530
hi my name is NAT or David this is my

00:04:41,120 --> 00:04:45,409
avatar on Twitter if you've seen me

00:04:42,530 --> 00:04:46,969
there and I do a lot of stuff the main

00:04:45,409 --> 00:04:50,000
thing I'm kind of working on I'm pretty

00:04:46,969 --> 00:04:52,069
happy about and want to talk about today

00:04:50,000 --> 00:04:54,259
I guess is my book full stack server

00:04:52,069 --> 00:04:56,240
lists from O'Reilly publications this

00:04:54,259 --> 00:04:58,250
book is about building you know full

00:04:56,240 --> 00:05:02,930
full stack apps on the cloud using griot

00:04:58,250 --> 00:05:04,280
graph QL react in AWS so before we talk

00:05:02,930 --> 00:05:06,409
about how to do this let's talk about

00:05:04,280 --> 00:05:07,879
why we want to do this so why would you

00:05:06,409 --> 00:05:11,210
want to build a real-time and offline

00:05:07,879 --> 00:05:13,219
first application well the first thing

00:05:11,210 --> 00:05:14,780
like I mentioned before is this idea of

00:05:13,219 --> 00:05:16,370
modern application development and what

00:05:14,780 --> 00:05:18,469
you know what does modern application

00:05:16,370 --> 00:05:19,729
development really mean well a lot of

00:05:18,469 --> 00:05:21,259
the apps that we're building today kind

00:05:19,729 --> 00:05:23,000
of fall into this category so you might

00:05:21,259 --> 00:05:24,889
not even call it modern application

00:05:23,000 --> 00:05:26,479
development it might just be application

00:05:24,889 --> 00:05:27,590
development these might just be the

00:05:26,479 --> 00:05:29,319
types of apps that you're kind of

00:05:27,590 --> 00:05:32,060
building on your day to day basis anyway

00:05:29,319 --> 00:05:33,409
and I think the number one category that

00:05:32,060 --> 00:05:36,349
you kind of see here that falls into

00:05:33,409 --> 00:05:38,810
this is collaborative apps so the more

00:05:36,349 --> 00:05:40,610
that we have better tools that are

00:05:38,810 --> 00:05:42,469
available for us to build these types of

00:05:40,610 --> 00:05:43,759
applications the more features that

00:05:42,469 --> 00:05:45,349
people are adding and the more that you

00:05:43,759 --> 00:05:47,960
see these types of collaborative apps

00:05:45,349 --> 00:05:49,430
coming into the wild again another

00:05:47,960 --> 00:05:50,930
reason you might want to do this is that

00:05:49,430 --> 00:05:52,669
you want to build an application that is

00:05:50,930 --> 00:05:54,379
available to everyone in every part of

00:05:52,669 --> 00:05:56,870
the world you want to be able to deploy

00:05:54,379 --> 00:05:58,069
not only here in Europe or in America

00:05:56,870 --> 00:06:00,229
where we have a really you know pretty

00:05:58,069 --> 00:06:01,879
good internet connections in general but

00:06:00,229 --> 00:06:03,440
you might also want your app to work in

00:06:01,879 --> 00:06:04,639
parts of the world where they don't have

00:06:03,440 --> 00:06:06,949
a good internet connection

00:06:04,639 --> 00:06:08,330
they also might have really slow devices

00:06:06,949 --> 00:06:09,860
and you might have to take you know all

00:06:08,330 --> 00:06:11,719
this stuff into consideration and you

00:06:09,860 --> 00:06:13,460
want to provide some way for your app

00:06:11,719 --> 00:06:14,930
not only to work there but you also

00:06:13,460 --> 00:06:16,699
might want to provide a decent user

00:06:14,930 --> 00:06:21,199
experience if not a great user

00:06:16,699 --> 00:06:23,449
experience and the last thing is user

00:06:21,199 --> 00:06:24,860
experience so again when you're building

00:06:23,449 --> 00:06:26,629
these types of applications a lot of

00:06:24,860 --> 00:06:29,419
times one of the things that you're

00:06:26,629 --> 00:06:31,370
really doing is doing this idea of an

00:06:29,419 --> 00:06:33,979
optimistic response and optimistic user

00:06:31,370 --> 00:06:35,300
interface optimistic UI's so when you're

00:06:33,979 --> 00:06:37,310
building these apps when you create a

00:06:35,300 --> 00:06:39,830
mutation when you create an update you

00:06:37,310 --> 00:06:41,539
see the update happen immediately and it

00:06:39,830 --> 00:06:44,389
just feels really snappy it feels really

00:06:41,539 --> 00:06:45,770
fast now when you do this once if you're

00:06:44,389 --> 00:06:47,569
just building like to do app or

00:06:45,770 --> 00:06:48,620
something basic it's pretty easy but

00:06:47,569 --> 00:06:50,419
when you start building something

00:06:48,620 --> 00:06:51,050
sophisticated when you start having to

00:06:50,419 --> 00:06:52,220
take an

00:06:51,050 --> 00:06:54,110
all the considerations that you

00:06:52,220 --> 00:06:55,909
typically do authentication and

00:06:54,110 --> 00:06:57,349
authorization you have to take into

00:06:55,909 --> 00:06:58,870
consideration all the different pieces

00:06:57,349 --> 00:07:02,180
of your application this starts becoming

00:06:58,870 --> 00:07:04,190
pretty complex so the idea here that I

00:07:02,180 --> 00:07:06,289
want to talk about is some of the things

00:07:04,190 --> 00:07:09,379
that we've done in my company to kind of

00:07:06,289 --> 00:07:11,000
make this easier and share some of the

00:07:09,379 --> 00:07:13,909
ideas that we've had and hopefully that

00:07:11,000 --> 00:07:15,560
you know listening to these ideas that

00:07:13,909 --> 00:07:17,240
people can kind of take some of the

00:07:15,560 --> 00:07:19,370
ideas that we've learned and maybe apply

00:07:17,240 --> 00:07:20,449
those and create something similar to

00:07:19,370 --> 00:07:23,469
the thing that I'm gonna be talking

00:07:20,449 --> 00:07:27,800
about today so what are some

00:07:23,469 --> 00:07:29,860
considerations technically when you're

00:07:27,800 --> 00:07:33,379
building these types of applications

00:07:29,860 --> 00:07:35,900
well one of the first and the hardest

00:07:33,379 --> 00:07:37,340
and the thing that we're really we're

00:07:35,900 --> 00:07:41,240
gonna focus a lot really on today is

00:07:37,340 --> 00:07:42,919
caching and this idea of caching and I

00:07:41,240 --> 00:07:45,860
guess not only caching but local

00:07:42,919 --> 00:07:48,500
persistence in general you may have

00:07:45,860 --> 00:07:50,240
heard this quote there are only two hard

00:07:48,500 --> 00:07:54,349
things computer science cache

00:07:50,240 --> 00:07:56,389
invalidation and naming things yeah Dan

00:07:54,349 --> 00:08:01,400
Abramov he didn't say that but you know

00:07:56,389 --> 00:08:02,690
we can attribute it to him and when

00:08:01,400 --> 00:08:03,889
we're talking about caching we're not

00:08:02,690 --> 00:08:05,180
talking about caching on the server

00:08:03,889 --> 00:08:07,400
we're talking about caching on the

00:08:05,180 --> 00:08:10,360
client and there's a couple of pieces

00:08:07,400 --> 00:08:10,360
that come into play here

00:08:10,630 --> 00:08:16,699
the first is data synchronization when

00:08:14,210 --> 00:08:18,680
you have different actors in different

00:08:16,699 --> 00:08:21,169
parts of the world and we're all

00:08:18,680 --> 00:08:22,639
operating against the same system what

00:08:21,169 --> 00:08:24,259
we're gonna end up happening is we're

00:08:22,639 --> 00:08:26,449
gonna have data conflicts we're gonna

00:08:24,259 --> 00:08:28,370
have inconsistencies we're gonna have

00:08:26,449 --> 00:08:29,990
people again going offline coming back

00:08:28,370 --> 00:08:32,300
online and what we're gonna need to do

00:08:29,990 --> 00:08:35,390
is find some way to synchronize all this

00:08:32,300 --> 00:08:37,610
data and do it in a very consistent way

00:08:35,390 --> 00:08:40,880
across all the devices connected to the

00:08:37,610 --> 00:08:44,209
system we also want to have complex

00:08:40,880 --> 00:08:47,149
query when you think about caches you

00:08:44,209 --> 00:08:49,699
typically think of having some type of

00:08:47,149 --> 00:08:52,279
local data either in memory or some type

00:08:49,699 --> 00:08:54,920
of local storage where you're you know

00:08:52,279 --> 00:08:56,120
have maybe some initial subsets of data

00:08:54,920 --> 00:08:57,980
that you've queried against you've

00:08:56,120 --> 00:09:00,170
stored locally and then you might need

00:08:57,980 --> 00:09:03,680
to get additional subsets of that data

00:09:00,170 --> 00:09:04,220
as your application continues to evolve

00:09:03,680 --> 00:09:06,620
you end

00:09:04,220 --> 00:09:08,480
updating this data people might be

00:09:06,620 --> 00:09:10,370
making changes elsewhere you're updating

00:09:08,480 --> 00:09:13,070
that cache and then you want to then

00:09:10,370 --> 00:09:14,900
take other subsets of that data for your

00:09:13,070 --> 00:09:17,570
own application and you might want to

00:09:14,900 --> 00:09:21,340
query against it you might want to do

00:09:17,570 --> 00:09:23,330
things like get additional or maybe

00:09:21,340 --> 00:09:24,680
remove parameters that you're not

00:09:23,330 --> 00:09:27,020
actually rendering in your app things

00:09:24,680 --> 00:09:28,460
like that and this this starts to become

00:09:27,020 --> 00:09:31,250
pretty complex when you're working with

00:09:28,460 --> 00:09:32,840
the cache and then when you're actually

00:09:31,250 --> 00:09:35,120
implementing all this stuff what you end

00:09:32,840 --> 00:09:36,680
up with if you're doing it yourself and

00:09:35,120 --> 00:09:38,420
you haven't created a good abstraction

00:09:36,680 --> 00:09:40,100
is you have a ton of additional

00:09:38,420 --> 00:09:42,050
complexity in your code you're writing

00:09:40,100 --> 00:09:43,460
caching mechanisms you're reading and

00:09:42,050 --> 00:09:45,530
you're writing to the cache all over the

00:09:43,460 --> 00:09:47,270
place and then you need to re-render and

00:09:45,530 --> 00:09:49,030
read and send updates to any parts of

00:09:47,270 --> 00:09:51,410
the app that are also using this data

00:09:49,030 --> 00:09:52,940
and I think one of the things that we

00:09:51,410 --> 00:09:55,750
end up doing is we start treating our

00:09:52,940 --> 00:09:58,610
cache as a database or as a datastore

00:09:55,750 --> 00:10:00,140
caches weren't really created to be that

00:09:58,610 --> 00:10:02,510
they're just created to have whatever

00:10:00,140 --> 00:10:04,370
data that we'd like to then retrieve

00:10:02,510 --> 00:10:06,530
quickly have it available but we're not

00:10:04,370 --> 00:10:08,030
actually it's not we don't have all the

00:10:06,530 --> 00:10:10,870
different query mechanisms that we

00:10:08,030 --> 00:10:14,540
typically would on a typical database

00:10:10,870 --> 00:10:17,720
the next idea is again synchronization I

00:10:14,540 --> 00:10:19,850
talked about this a moment ago when not

00:10:17,720 --> 00:10:21,350
only do you have all these people doing

00:10:19,850 --> 00:10:23,150
different things in your app you also

00:10:21,350 --> 00:10:25,220
want to make sure that when these

00:10:23,150 --> 00:10:27,410
updates happen you're only sending the

00:10:25,220 --> 00:10:29,450
data to the right devices that actually

00:10:27,410 --> 00:10:31,310
need the data so in a real-time

00:10:29,450 --> 00:10:32,810
application this might be something like

00:10:31,310 --> 00:10:36,170
a chat app where you're in a chat room

00:10:32,810 --> 00:10:37,490
and you have another person in the chat

00:10:36,170 --> 00:10:39,050
room and they're sending a message you

00:10:37,490 --> 00:10:41,990
want to be able to filter that data and

00:10:39,050 --> 00:10:43,940
only send this this new data to this to

00:10:41,990 --> 00:10:45,470
the clients that are subscribed to those

00:10:43,940 --> 00:10:46,850
changes if you're thinking about

00:10:45,470 --> 00:10:49,040
something like Google Docs you have

00:10:46,850 --> 00:10:51,200
authentication and authorization things

00:10:49,040 --> 00:10:53,030
that are that are concerned so if you

00:10:51,200 --> 00:10:54,590
might go in a document and there might

00:10:53,030 --> 00:10:56,420
only be a half-dozen people that are

00:10:54,590 --> 00:10:57,470
authorized to see those changes you need

00:10:56,420 --> 00:11:00,650
to actually take all that into

00:10:57,470 --> 00:11:02,900
consideration and only send updates to

00:11:00,650 --> 00:11:04,670
the people that can that are supposed to

00:11:02,900 --> 00:11:06,590
see these updates and you also don't

00:11:04,670 --> 00:11:10,520
want to send updates where they're not

00:11:06,590 --> 00:11:12,770
needed and you just save bandwidth and

00:11:10,520 --> 00:11:14,720
then one of the big pieces about

00:11:12,770 --> 00:11:16,640
building these types of applications is

00:11:14,720 --> 00:11:17,750
this idea of conflict detection so if

00:11:16,640 --> 00:11:19,760
you have to

00:11:17,750 --> 00:11:21,440
people sending data either at the same

00:11:19,760 --> 00:11:23,480
time or you might have someone that

00:11:21,440 --> 00:11:26,440
creates a mutation while they're all

00:11:23,480 --> 00:11:29,570
flan someone else creates an additional

00:11:26,440 --> 00:11:31,700
mutation in the future they're online

00:11:29,570 --> 00:11:32,990
when the when the other user comes back

00:11:31,700 --> 00:11:35,750
online you're going to end up having

00:11:32,990 --> 00:11:37,460
some type of conflict how do you detect

00:11:35,750 --> 00:11:39,710
these conflicts and then conflict

00:11:37,460 --> 00:11:41,570
resolution is how do you resolve this

00:11:39,710 --> 00:11:43,430
conflict and how do you do this again in

00:11:41,570 --> 00:11:45,380
a consistent manner you need to make

00:11:43,430 --> 00:11:47,480
sure that you know over the course of

00:11:45,380 --> 00:11:50,930
your application you're not having any

00:11:47,480 --> 00:11:53,060
errors you know having to do with

00:11:50,930 --> 00:11:56,890
ordering and things like that and this

00:11:53,060 --> 00:11:56,890
is a very very hard problem to solve

00:11:58,480 --> 00:12:03,410
another consideration or the idea of

00:12:01,370 --> 00:12:06,770
multiple platforms if you've ever used

00:12:03,410 --> 00:12:08,930
Google Docs you've probably been able to

00:12:06,770 --> 00:12:11,750
edit your document from your computer

00:12:08,930 --> 00:12:14,720
you can even use your app on your mobile

00:12:11,750 --> 00:12:16,130
phone or a tablet and you're able to do

00:12:14,720 --> 00:12:18,530
this from all these different clients

00:12:16,130 --> 00:12:21,170
doing this is not really easy again

00:12:18,530 --> 00:12:23,060
because if you have a native iOS app a

00:12:21,170 --> 00:12:25,040
native Android app you have a web app

00:12:23,060 --> 00:12:27,770
and maybe and maybe whatever else maybe

00:12:25,040 --> 00:12:29,360
react native you end up rewriting all of

00:12:27,770 --> 00:12:32,089
these caching mechanisms all of this

00:12:29,360 --> 00:12:33,680
logic locally multiple times because you

00:12:32,089 --> 00:12:35,750
need it to work consistently across all

00:12:33,680 --> 00:12:39,130
these devices so you're bringing even

00:12:35,750 --> 00:12:41,360
more complexity there and then finally

00:12:39,130 --> 00:12:43,130
scalability so when you're building

00:12:41,360 --> 00:12:45,500
something simple you might have a half

00:12:43,130 --> 00:12:46,940
dozen or so connected devices you know

00:12:45,500 --> 00:12:49,400
this is pretty easy but when you start

00:12:46,940 --> 00:12:51,530
building you know complex systems you

00:12:49,400 --> 00:12:53,030
start thinking about scale you start

00:12:51,530 --> 00:12:55,160
thinking about what if we end up having

00:12:53,030 --> 00:12:57,080
tens or hundreds of thousands of

00:12:55,160 --> 00:12:59,300
connected devices how can we actually

00:12:57,080 --> 00:13:01,550
scale this a lot of the companies that

00:12:59,300 --> 00:13:03,110
we work with have these problems and

00:13:01,550 --> 00:13:04,520
we've really taken these into

00:13:03,110 --> 00:13:06,170
consideration around some of the things

00:13:04,520 --> 00:13:08,750
that I'm going to talk about today we've

00:13:06,170 --> 00:13:10,130
worked with just with this system I'm

00:13:08,750 --> 00:13:13,310
going to talk about today with companies

00:13:10,130 --> 00:13:14,960
like Ticketmaster Aldo BMW where they

00:13:13,310 --> 00:13:16,640
have you know literally millions of

00:13:14,960 --> 00:13:18,680
connected devices and we have to make

00:13:16,640 --> 00:13:21,770
sure that none of their applications

00:13:18,680 --> 00:13:23,000
break and nothing is leaked we have you

00:13:21,770 --> 00:13:24,710
know we have to make sure all their data

00:13:23,000 --> 00:13:28,430
is secure so how can we actually

00:13:24,710 --> 00:13:29,600
accomplish scalability as well so now

00:13:28,430 --> 00:13:31,160
that we've talked about the

00:13:29,600 --> 00:13:31,610
considerations let's talk about some of

00:13:31,160 --> 00:13:35,630
the solutions

00:13:31,610 --> 00:13:38,329
that I'm gonna propose today the first

00:13:35,630 --> 00:13:40,250
again about caching we talked about this

00:13:38,329 --> 00:13:41,510
a moment ago so we talked about the

00:13:40,250 --> 00:13:42,490
problems let's talk about some of the

00:13:41,510 --> 00:13:44,899
solutions

00:13:42,490 --> 00:13:46,760
if you've ever written a cash-in graph

00:13:44,899 --> 00:13:47,209
QL you might have seen something like

00:13:46,760 --> 00:13:50,779
this

00:13:47,209 --> 00:13:54,500
in this example here we're creating a

00:13:50,779 --> 00:13:58,550
mutation we're saying we want to create

00:13:54,500 --> 00:14:00,709
a new comment we then want to create an

00:13:58,550 --> 00:14:04,370
optimistic response so we then create

00:14:00,709 --> 00:14:05,660
another separate little function or an

00:14:04,370 --> 00:14:07,279
object where we're kind of describing

00:14:05,660 --> 00:14:10,490
the data that we would like to see in

00:14:07,279 --> 00:14:13,399
this optimistic response we then need to

00:14:10,490 --> 00:14:15,350
write to the cache so we then we first

00:14:13,399 --> 00:14:17,839
read from the cache we then write to the

00:14:15,350 --> 00:14:19,519
cache and we write or we write to that

00:14:17,839 --> 00:14:21,709
copy of the cache and then we rewrite to

00:14:19,519 --> 00:14:23,480
rewrite to the cache so we're creating a

00:14:21,709 --> 00:14:27,709
lot of complexity here just for a fairly

00:14:23,480 --> 00:14:30,709
simple operation so what we're basically

00:14:27,709 --> 00:14:33,019
doing is duplicating you know our logic

00:14:30,709 --> 00:14:36,230
we are saying we want to create an item

00:14:33,019 --> 00:14:37,910
and we now need to to make sure that

00:14:36,230 --> 00:14:40,190
this operation happens in two different

00:14:37,910 --> 00:14:42,380
places we want to write to our system

00:14:40,190 --> 00:14:44,930
which would be the cloud or wherever our

00:14:42,380 --> 00:14:46,459
database is located and we also want to

00:14:44,930 --> 00:14:50,209
write locally and we want to keep these

00:14:46,459 --> 00:14:52,040
things things in sync and that's that

00:14:50,209 --> 00:14:54,170
those are rights but what about reads we

00:14:52,040 --> 00:14:56,510
want to be able to query again from our

00:14:54,170 --> 00:14:59,810
local database or our our local cache

00:14:56,510 --> 00:15:01,730
whatever that is and once you create

00:14:59,810 --> 00:15:04,070
this initial query from your database

00:15:01,730 --> 00:15:06,380
you store locally you are stuck with

00:15:04,070 --> 00:15:10,180
that basic subset of whatever that data

00:15:06,380 --> 00:15:12,440
is let's say you now want to create an

00:15:10,180 --> 00:15:14,329
additional query where you only want to

00:15:12,440 --> 00:15:16,910
filter against something you might want

00:15:14,329 --> 00:15:19,120
to say okay I have all this data I want

00:15:16,910 --> 00:15:22,070
to then just create another graph QL

00:15:19,120 --> 00:15:24,380
query against what we already have here

00:15:22,070 --> 00:15:26,630
this just isn't gonna work what you

00:15:24,380 --> 00:15:28,220
could do I guess is you could take all

00:15:26,630 --> 00:15:30,709
of that data that we've already queried

00:15:28,220 --> 00:15:32,360
locally and then maybe take that and

00:15:30,709 --> 00:15:34,100
then filter it and then and then use

00:15:32,360 --> 00:15:36,320
that in a place that you'd like to use

00:15:34,100 --> 00:15:38,329
it or whatever else that you'd like to

00:15:36,320 --> 00:15:41,180
do but really you're basically stuck

00:15:38,329 --> 00:15:43,850
within this this initial query that you

00:15:41,180 --> 00:15:44,360
have this initial subset of data is kind

00:15:43,850 --> 00:15:48,199
of what you were

00:15:44,360 --> 00:15:49,579
with now the same thing happens when

00:15:48,199 --> 00:15:52,790
you're talking about subscriptions so

00:15:49,579 --> 00:15:55,129
with with mutations your your your

00:15:52,790 --> 00:15:57,829
created a mutation your creating the

00:15:55,129 --> 00:15:59,299
cashed or the optimistic response and

00:15:57,829 --> 00:16:00,619
your writing into the cache with

00:15:59,299 --> 00:16:01,910
subscriptions or with when you're

00:16:00,619 --> 00:16:04,129
dealing with real-time you have this

00:16:01,910 --> 00:16:06,470
listener you have the data come through

00:16:04,129 --> 00:16:08,779
you then have to write again to the

00:16:06,470 --> 00:16:10,730
cache and this twenty lines or so of

00:16:08,779 --> 00:16:12,350
code here is just a traditional or

00:16:10,730 --> 00:16:14,929
typical thing you might see done if

00:16:12,350 --> 00:16:17,629
you're working you know with graph QL so

00:16:14,929 --> 00:16:20,319
I think the answer to this is what if we

00:16:17,629 --> 00:16:24,290
don't need a cache in the first place

00:16:20,319 --> 00:16:28,519
maybe maybe what we need is actually a

00:16:24,290 --> 00:16:31,129
store so instead of thinking of the

00:16:28,519 --> 00:16:35,569
cache we we do need to think about this

00:16:31,129 --> 00:16:37,939
a little bit in a more sophisticated

00:16:35,569 --> 00:16:40,759
manner and what we need to do is think

00:16:37,939 --> 00:16:44,920
about this as a store and at the most

00:16:40,759 --> 00:16:48,290
basic level to me working with data

00:16:44,920 --> 00:16:51,199
locally is a very simple mental model if

00:16:48,290 --> 00:16:53,929
you've ever taken a react tutorial or a

00:16:51,199 --> 00:16:55,759
view tutorial or any tutorial the first

00:16:53,929 --> 00:16:58,459
thing that they're gonna do is create

00:16:55,759 --> 00:16:59,899
some local state in memory and you're

00:16:58,459 --> 00:17:02,119
just gonna be writing and reading from

00:16:59,899 --> 00:17:03,860
this local state this is pretty simple

00:17:02,119 --> 00:17:06,769
because all you're doing is creating

00:17:03,860 --> 00:17:08,299
updates you're you're rendering this

00:17:06,769 --> 00:17:10,339
data and you're not really having to

00:17:08,299 --> 00:17:11,899
think about anything else this is a very

00:17:10,339 --> 00:17:14,389
great user experience and it's the

00:17:11,899 --> 00:17:17,209
reason that we use this idea whenever

00:17:14,389 --> 00:17:18,829
we're creating tutorials and we're

00:17:17,209 --> 00:17:20,480
getting people started because we want

00:17:18,829 --> 00:17:23,480
to start them off in the most simple way

00:17:20,480 --> 00:17:25,069
as possible right what if we took this

00:17:23,480 --> 00:17:26,929
mental model and applied it to a

00:17:25,069 --> 00:17:28,309
distributed system and we applied it to

00:17:26,929 --> 00:17:30,590
building real time and all Flom

00:17:28,309 --> 00:17:32,720
applications well that's basically what

00:17:30,590 --> 00:17:34,100
we've done we decided this is the best

00:17:32,720 --> 00:17:35,510
programming model that we would like to

00:17:34,100 --> 00:17:40,100
work with and we want to make this work

00:17:35,510 --> 00:17:42,110
in a distributed fashion what we've done

00:17:40,100 --> 00:17:45,980
over the last two years and we released

00:17:42,110 --> 00:17:47,600
this in December it reinvents and i'm

00:17:45,980 --> 00:17:50,059
gonna talk about how we built this and

00:17:47,600 --> 00:17:51,470
hopefully not only will you learn you

00:17:50,059 --> 00:17:53,690
know some of the stuff that we've done

00:17:51,470 --> 00:17:56,270
but we also would love to see other

00:17:53,690 --> 00:17:57,799
things in this category people building

00:17:56,270 --> 00:17:59,869
similar solutions

00:17:57,799 --> 00:18:02,269
so what we've built this epified

00:17:59,869 --> 00:18:04,460
datastore it's a multi-platform own

00:18:02,269 --> 00:18:06,710
device persistent storage engine that

00:18:04,460 --> 00:18:09,019
automatically synchronizes data between

00:18:06,710 --> 00:18:10,999
mobile and web applications and the

00:18:09,019 --> 00:18:16,159
cloud and we use graph QL to make this

00:18:10,999 --> 00:18:18,440
work so the way that this works is this

00:18:16,159 --> 00:18:21,230
it all kind of revolves around this

00:18:18,440 --> 00:18:23,149
programming concept of dealing with your

00:18:21,230 --> 00:18:25,700
data model just just like I talked about

00:18:23,149 --> 00:18:28,820
a moment ago and we kind of decided that

00:18:25,700 --> 00:18:30,980
graph QL schema definition language is

00:18:28,820 --> 00:18:32,809
the perfect way for developers to do the

00:18:30,980 --> 00:18:34,580
data modeling in their apps and it's

00:18:32,809 --> 00:18:38,149
also kind of the perfect way to solve

00:18:34,580 --> 00:18:40,549
this problem of real-time and offline

00:18:38,149 --> 00:18:44,570
you know application development in a

00:18:40,549 --> 00:18:46,700
cross-platform manner so the idea is

00:18:44,570 --> 00:18:48,559
that developers or you will define your

00:18:46,700 --> 00:18:50,929
data model we then translate these

00:18:48,559 --> 00:18:53,419
models and to what's needed at both the

00:18:50,929 --> 00:18:55,970
local storage repository level as well

00:18:53,419 --> 00:18:58,429
as the backend for interacting with the

00:18:55,970 --> 00:19:00,649
system and in our case the system would

00:18:58,429 --> 00:19:05,330
be AWS absent which is a managed graph

00:19:00,649 --> 00:19:08,419
QL service so we'll walk through this in

00:19:05,330 --> 00:19:11,989
detail so you as a developer want to

00:19:08,419 --> 00:19:15,080
create an application you first you

00:19:11,989 --> 00:19:16,700
author your your graph QL schema so

00:19:15,080 --> 00:19:18,409
let's say we want to create like a

00:19:16,700 --> 00:19:20,960
blogging application you create a post

00:19:18,409 --> 00:19:24,470
type you give it a couple of fields an

00:19:20,960 --> 00:19:27,019
ID a title and a description once your

00:19:24,470 --> 00:19:30,529
data model has been defined you run a

00:19:27,019 --> 00:19:32,389
build now depending on which platform

00:19:30,529 --> 00:19:35,090
you're on this could be an NPM script it

00:19:32,389 --> 00:19:36,830
could be a Gradle task on Android or if

00:19:35,090 --> 00:19:41,509
you're building an iOS app it would be

00:19:36,830 --> 00:19:43,009
something like in Xcode build phase out

00:19:41,509 --> 00:19:45,109
of the build we then generate models

00:19:43,009 --> 00:19:47,779
with the language construct of choice so

00:19:45,109 --> 00:19:49,879
for JavaScript or typescript this would

00:19:47,779 --> 00:19:52,909
be a class if you're working with Java

00:19:49,879 --> 00:19:54,409
would be a cocoa cooker JavaScript

00:19:52,909 --> 00:19:57,559
Coco's if you're working on Swift this

00:19:54,409 --> 00:20:01,359
would be a class now you as a developer

00:19:57,559 --> 00:20:03,379
are going to be interacting with these

00:20:01,359 --> 00:20:04,639
models that you've created and you're no

00:20:03,379 --> 00:20:07,309
longer going to be having to deal with

00:20:04,639 --> 00:20:10,039
or program against graph QL instead

00:20:07,309 --> 00:20:12,080
you're operating on what we have as the

00:20:10,039 --> 00:20:15,330
data store API

00:20:12,080 --> 00:20:18,240
the data store API offers this idea of a

00:20:15,330 --> 00:20:20,460
fluent interface so what we're gonna do

00:20:18,240 --> 00:20:22,740
is we're gonna import this this store

00:20:20,460 --> 00:20:26,790
API and we're gonna then be able to

00:20:22,740 --> 00:20:29,310
create updates mutations queries against

00:20:26,790 --> 00:20:30,870
the store so let's say we want to save

00:20:29,310 --> 00:20:33,180
an item to the store we say store dot

00:20:30,870 --> 00:20:36,900
save we just pass in the properties we'd

00:20:33,180 --> 00:20:39,420
like to save we can also query against

00:20:36,900 --> 00:20:42,600
the store so we want to query all the

00:20:39,420 --> 00:20:44,070
posts we can then just query store that

00:20:42,600 --> 00:20:47,580
query passing in the model that we'd

00:20:44,070 --> 00:20:49,700
like to query for if we'd like to have

00:20:47,580 --> 00:20:52,380
conditional logic we can use predicates

00:20:49,700 --> 00:20:54,810
so say we want to query only the posts

00:20:52,380 --> 00:20:57,600
where someone has written form accruals

00:20:54,810 --> 00:20:59,580
as the title we can do that where we're

00:20:57,600 --> 00:21:02,730
just passing in the query is the first

00:20:59,580 --> 00:21:05,340
argument and predicate as a predicate

00:21:02,730 --> 00:21:07,920
function as a second argument we can

00:21:05,340 --> 00:21:10,830
also change its so let's say we want to

00:21:07,920 --> 00:21:13,440
query our store where posts title equals

00:21:10,830 --> 00:21:15,060
a for make is awesome and this post

00:21:13,440 --> 00:21:18,420
status is published we can do that as

00:21:15,060 --> 00:21:21,810
well and we can also create updates of

00:21:18,420 --> 00:21:23,760
course we want to create deletes or you

00:21:21,810 --> 00:21:26,040
know updates but the cool thing about

00:21:23,760 --> 00:21:28,350
this is we can actually apply predicates

00:21:26,040 --> 00:21:30,720
to the updates so we might want to say

00:21:28,350 --> 00:21:32,820
we only wanted to delete an item based

00:21:30,720 --> 00:21:34,530
on this predicate or we might only want

00:21:32,820 --> 00:21:36,390
to update night item based on that

00:21:34,530 --> 00:21:38,940
predicate so here we're basically saying

00:21:36,390 --> 00:21:41,220
we only want to delete the post where

00:21:38,940 --> 00:21:45,060
the post status equals published or

00:21:41,220 --> 00:21:46,920
whatever so let's take a look at the

00:21:45,060 --> 00:21:50,670
vertical slice of this architecture and

00:21:46,920 --> 00:21:52,200
how it works I showed you this a moment

00:21:50,670 --> 00:21:56,100
ago but we're gonna look at it a little

00:21:52,200 --> 00:21:58,380
more in-depth now so after you create a

00:21:56,100 --> 00:22:00,480
model instance the library basically

00:21:58,380 --> 00:22:02,790
decomposes that model instance and

00:22:00,480 --> 00:22:07,320
creates and what we call a storage

00:22:02,790 --> 00:22:09,300
engine component a model registry the

00:22:07,320 --> 00:22:12,960
model registry is basically a registry

00:22:09,300 --> 00:22:18,780
containing all of your models and you

00:22:12,960 --> 00:22:20,670
know we then have a adapter a storage

00:22:18,780 --> 00:22:22,800
adapter in the storage adapter is using

00:22:20,670 --> 00:22:24,750
a classic repository pattern and we

00:22:22,800 --> 00:22:25,470
convert this into the persistence layer

00:22:24,750 --> 00:22:27,659
of choice

00:22:25,470 --> 00:22:31,080
so if you're working with the web we'll

00:22:27,659 --> 00:22:32,909
be indexeddb if you're on native iOS or

00:22:31,080 --> 00:22:36,179
Android we sequel lights and then we're

00:22:32,909 --> 00:22:38,400
also working and will soon have a react

00:22:36,179 --> 00:22:40,890
native version of this which will be

00:22:38,400 --> 00:22:44,400
either using async storage or a bridge

00:22:40,890 --> 00:22:46,950
to sequel I'd doing this you can

00:22:44,400 --> 00:22:50,400
actually use you can use this without an

00:22:46,950 --> 00:22:52,559
AWS account if you only want to use the

00:22:50,400 --> 00:22:55,169
offline storage piece and a nice way to

00:22:52,559 --> 00:22:56,970
do data modeling and programming against

00:22:55,169 --> 00:22:59,159
all these filters you know you can do

00:22:56,970 --> 00:23:00,600
that without an AWS back-end because

00:22:59,159 --> 00:23:06,600
again this is all just a local

00:23:00,600 --> 00:23:09,240
persistence layer but if you want to

00:23:06,600 --> 00:23:11,580
then sync this with your app sync back

00:23:09,240 --> 00:23:16,200
in all you need to do is update a flag

00:23:11,580 --> 00:23:17,970
in your build script and what's going to

00:23:16,200 --> 00:23:20,220
happen is you'll then be connected to

00:23:17,970 --> 00:23:22,799
the system and you'll be working against

00:23:20,220 --> 00:23:25,020
the storage engine with the datastore

00:23:22,799 --> 00:23:28,140
API which in itself is working with this

00:23:25,020 --> 00:23:29,820
this idea of a sync engine you're

00:23:28,140 --> 00:23:32,520
basically going to be creating writes to

00:23:29,820 --> 00:23:33,990
the sync engine the the sync engine is

00:23:32,520 --> 00:23:35,549
then going to basically take these

00:23:33,990 --> 00:23:37,740
rights and create graph to all

00:23:35,549 --> 00:23:41,010
statements so queries and mutations will

00:23:37,740 --> 00:23:43,860
go against the actual the graph QL API

00:23:41,010 --> 00:23:45,600
and then we'll also be observing data

00:23:43,860 --> 00:23:47,220
and then under the hood this is going to

00:23:45,600 --> 00:23:49,049
be working with graphical subscriptions

00:23:47,220 --> 00:23:51,150
and any responses are basically

00:23:49,049 --> 00:23:53,070
converted back to the model from graph

00:23:51,150 --> 00:23:56,340
QL and then written to the storage

00:23:53,070 --> 00:24:00,210
engine so that's the offline piece let's

00:23:56,340 --> 00:24:01,289
talk about the real-time piece so what

00:24:00,210 --> 00:24:05,159
are some options for real-time

00:24:01,289 --> 00:24:07,110
applications first of all there's long

00:24:05,159 --> 00:24:09,179
polling this is probably the most basic

00:24:07,110 --> 00:24:12,780
way that you can do this and it sounds

00:24:09,179 --> 00:24:15,900
just like it is you have a some type of

00:24:12,780 --> 00:24:17,400
it some type of time interval where

00:24:15,900 --> 00:24:19,320
you're gonna say I want to hit this API

00:24:17,400 --> 00:24:21,720
every 5 minutes every 10 minutes every

00:24:19,320 --> 00:24:23,940
one hour or maybe every 1 second and we

00:24:21,720 --> 00:24:26,070
wanted to just get data and check and

00:24:23,940 --> 00:24:28,320
see you know if the data has changed or

00:24:26,070 --> 00:24:30,030
not this isn't very efficient because

00:24:28,320 --> 00:24:32,970
let's say you have a change every one

00:24:30,030 --> 00:24:34,620
hour but you only are querying every day

00:24:32,970 --> 00:24:36,630
or you might have a change every second

00:24:34,620 --> 00:24:38,190
but you're only querying every hour so

00:24:36,630 --> 00:24:39,240
you end up over fetching or under

00:24:38,190 --> 00:24:43,130
fetching in some way there's

00:24:39,240 --> 00:24:43,130
there's no way no other way around it

00:24:43,550 --> 00:24:50,130
another option is service and events so

00:24:47,280 --> 00:24:51,660
server-sent events basically have a

00:24:50,130 --> 00:24:53,790
couple of characteristics they only

00:24:51,660 --> 00:24:55,590
allow communication to the server from

00:24:53,790 --> 00:24:56,990
the server to the client there's no

00:24:55,590 --> 00:24:59,880
protocol from the client to the server

00:24:56,990 --> 00:25:01,679
you're limited to utf-8 so you can't

00:24:59,880 --> 00:25:03,630
actually send any binary data with

00:25:01,679 --> 00:25:07,920
server sent events and you also have a

00:25:03,630 --> 00:25:09,809
limit of six of event can event sorts of

00:25:07,920 --> 00:25:10,920
connections at a time and this is like a

00:25:09,809 --> 00:25:12,510
hard limit they're not they're never

00:25:10,920 --> 00:25:15,300
going to change this based on some

00:25:12,510 --> 00:25:18,990
conversations that I've seen online it

00:25:15,300 --> 00:25:20,670
is part of the native browser event

00:25:18,990 --> 00:25:22,260
source API so it's part of the native

00:25:20,670 --> 00:25:25,890
local API and it's actually a pretty

00:25:22,260 --> 00:25:28,260
simple API to work with but it's not

00:25:25,890 --> 00:25:29,940
that well supported as at least as much

00:25:28,260 --> 00:25:33,740
as something like WebSockets is a

00:25:29,940 --> 00:25:35,640
concern so let's talk about WebSockets

00:25:33,740 --> 00:25:38,640
WebSockets are another way to deal with

00:25:35,640 --> 00:25:40,559
this this protocol does allow data to go

00:25:38,640 --> 00:25:43,290
both from the client to the server and

00:25:40,559 --> 00:25:44,730
from the server to the client and using

00:25:43,290 --> 00:25:48,390
WebSockets you can you know work with

00:25:44,730 --> 00:25:50,610
both binary and utf-8 there's more

00:25:48,390 --> 00:25:53,309
robust browser support than server sent

00:25:50,610 --> 00:25:56,220
events but the API is a little more

00:25:53,309 --> 00:25:57,630
complex but because there's a lot bigger

00:25:56,220 --> 00:25:59,730
of an ecosystem there's a lot of good

00:25:57,630 --> 00:26:03,150
abstraction around WebSockets these days

00:25:59,730 --> 00:26:06,660
and then finally the other mechanism

00:26:03,150 --> 00:26:08,730
that we use is graph QL subscriptions so

00:26:06,660 --> 00:26:11,670
graph QL subscriptions or a real-time

00:26:08,730 --> 00:26:13,200
event based way to send data from the

00:26:11,670 --> 00:26:16,650
client to the server server to the

00:26:13,200 --> 00:26:18,990
client in real time their event based

00:26:16,650 --> 00:26:20,370
and typically the events or based on

00:26:18,990 --> 00:26:22,890
some type of update or some type of

00:26:20,370 --> 00:26:25,200
mutation so you might say on create on

00:26:22,890 --> 00:26:28,080
update or on delete I want to then send

00:26:25,200 --> 00:26:30,929
this updated data down to whatever

00:26:28,080 --> 00:26:33,600
clients are subscribed and you can even

00:26:30,929 --> 00:26:36,540
filter these subscriptions based on some

00:26:33,600 --> 00:26:39,120
types of arguments and these are

00:26:36,540 --> 00:26:41,460
initialized on the client typically what

00:26:39,120 --> 00:26:43,590
this is done via WebSockets but the

00:26:41,460 --> 00:26:46,679
actual implementation is up to you this

00:26:43,590 --> 00:26:49,830
is only kind of a it's not an actual

00:26:46,679 --> 00:26:51,090
implementation detail graph QL is more

00:26:49,830 --> 00:26:52,500
of a spec so you can kind of do this

00:26:51,090 --> 00:26:54,580
whatever way you like

00:26:52,500 --> 00:26:56,980
and then when the event happens the

00:26:54,580 --> 00:26:58,690
server then uses this open connection to

00:26:56,980 --> 00:27:02,980
send the event data down to the

00:26:58,690 --> 00:27:05,590
subscribe clients so how did we deal

00:27:02,980 --> 00:27:07,360
with this idea of real-time these these

00:27:05,590 --> 00:27:10,150
real-time graph growth subscriptions

00:27:07,360 --> 00:27:12,910
what type of abstraction do we have well

00:27:10,150 --> 00:27:14,440
we we have this idea of observe so we

00:27:12,910 --> 00:27:17,410
basically can call a data store not

00:27:14,440 --> 00:27:19,270
observe we pass in the operation or the

00:27:17,410 --> 00:27:21,130
the class that we'd like to observe and

00:27:19,270 --> 00:27:23,260
then we can basically subscribe and we

00:27:21,130 --> 00:27:24,820
can see the event and we have

00:27:23,260 --> 00:27:26,680
information about the event so we can

00:27:24,820 --> 00:27:28,870
look at the operation type the model and

00:27:26,680 --> 00:27:30,850
the element you can also pass different

00:27:28,870 --> 00:27:32,980
arguments into this subscription to

00:27:30,850 --> 00:27:35,880
basically filter based on whatever

00:27:32,980 --> 00:27:38,800
arguments that you like now this is

00:27:35,880 --> 00:27:40,060
basic this is just like a basic idea in

00:27:38,800 --> 00:27:42,460
general but what does this actually give

00:27:40,060 --> 00:27:44,140
you well this actually does away with a

00:27:42,460 --> 00:27:46,000
lot of that boilerplate that we looked

00:27:44,140 --> 00:27:47,440
at before and what this basically will

00:27:46,000 --> 00:27:49,960
end up giving you is this idea of a

00:27:47,440 --> 00:27:51,760
single rehydrate query you don't need to

00:27:49,960 --> 00:27:54,130
and again you don't need to then

00:27:51,760 --> 00:27:56,260
continue working when worried about

00:27:54,130 --> 00:27:57,970
working with updating your local store

00:27:56,260 --> 00:28:01,450
all of this is handled for you by the

00:27:57,970 --> 00:28:02,950
system itself so let's take a look again

00:28:01,450 --> 00:28:04,810
at what we used to write for graph field

00:28:02,950 --> 00:28:07,330
subscriptions and let's see what we can

00:28:04,810 --> 00:28:10,270
do now to kind of update this using this

00:28:07,330 --> 00:28:15,100
idea of a single rehydrate query instead

00:28:10,270 --> 00:28:17,290
of creating the actual cash update

00:28:15,100 --> 00:28:19,390
ourselves where instead we're just going

00:28:17,290 --> 00:28:22,750
to listen to any subscription on any

00:28:19,390 --> 00:28:24,820
subscription event that comes through

00:28:22,750 --> 00:28:26,920
and anytime that that happens we're just

00:28:24,820 --> 00:28:28,810
gonna refetch our posts because the

00:28:26,920 --> 00:28:30,400
local datastore has already been updated

00:28:28,810 --> 00:28:32,290
by the system itself so we don't

00:28:30,400 --> 00:28:34,510
actually have to worry about going and

00:28:32,290 --> 00:28:36,730
caching all updating the cache because

00:28:34,510 --> 00:28:39,100
the store has already been located all

00:28:36,730 --> 00:28:40,510
we're basically doing is refetch in that

00:28:39,100 --> 00:28:42,400
data and rendering it in our app

00:28:40,510 --> 00:28:44,050
wherever we need it so this could be at

00:28:42,400 --> 00:28:46,360
the local level or you cannot actually

00:28:44,050 --> 00:28:48,790
move this up you know and react up to

00:28:46,360 --> 00:28:51,550
some type of other store or something

00:28:48,790 --> 00:28:53,110
like context or mob X or whatever and

00:28:51,550 --> 00:28:54,370
then your entire app is going to

00:28:53,110 --> 00:28:57,640
re-render but you don't actually have to

00:28:54,370 --> 00:28:58,900
write any of that logic yourself the

00:28:57,640 --> 00:29:00,430
next thing I want to talk about is

00:28:58,900 --> 00:29:04,610
conflict detection and conflict

00:29:00,430 --> 00:29:06,230
resolution so what is

00:29:04,610 --> 00:29:08,150
conflict what yeah its conflict

00:29:06,230 --> 00:29:09,770
detection conflict resolution well

00:29:08,150 --> 00:29:13,059
basically what you want to do is provide

00:29:09,770 --> 00:29:16,070
a way to merge concurrent modifications

00:29:13,059 --> 00:29:18,020
always and in any order without any you

00:29:16,070 --> 00:29:19,790
know without any errors and very

00:29:18,020 --> 00:29:23,330
consistently so what does this actually

00:29:19,790 --> 00:29:24,350
mean well let's take a basic system that

00:29:23,330 --> 00:29:26,780
looks something like this where we have

00:29:24,350 --> 00:29:29,420
three clients that are all working along

00:29:26,780 --> 00:29:33,140
the same application let's say we have

00:29:29,420 --> 00:29:35,150
one user creates an update and in an

00:29:33,140 --> 00:29:37,700
offline first application this might be

00:29:35,150 --> 00:29:39,440
an update to our local storage engine

00:29:37,700 --> 00:29:41,960
and then we're going to then replicate

00:29:39,440 --> 00:29:46,010
this to all the connected nodes so this

00:29:41,960 --> 00:29:47,809
might be an operation to a half-dozen

00:29:46,010 --> 00:29:51,410
connected devices or it might be you

00:29:47,809 --> 00:29:53,630
know a thousand connected devices so

00:29:51,410 --> 00:29:55,970
then user becomes online they make an

00:29:53,630 --> 00:29:58,669
update these updates go to all of the

00:29:55,970 --> 00:30:00,710
connected devices as well this is pretty

00:29:58,669 --> 00:30:03,049
simple because you know all we're doing

00:30:00,710 --> 00:30:06,200
is you know because these things are

00:30:03,049 --> 00:30:07,910
happening along a Thom continuum we're

00:30:06,200 --> 00:30:12,559
not having any conflicts but what

00:30:07,910 --> 00:30:14,210
happens when a single moment in time

00:30:12,559 --> 00:30:18,830
gets to operations that happen at the

00:30:14,210 --> 00:30:21,380
same time what we end up having is some

00:30:18,830 --> 00:30:23,059
type of conflict because we have two

00:30:21,380 --> 00:30:25,549
users that are writing at the same time

00:30:23,059 --> 00:30:27,320
and their rights might be different so

00:30:25,549 --> 00:30:29,240
this user might be updating the age and

00:30:27,320 --> 00:30:30,620
this other user might be updating at the

00:30:29,240 --> 00:30:33,260
age at the same time so how do we

00:30:30,620 --> 00:30:35,030
resolve this and this even gets harder

00:30:33,260 --> 00:30:38,330
when you're working with a more complex

00:30:35,030 --> 00:30:39,799
system so say we have a half-dozen or a

00:30:38,330 --> 00:30:41,960
thousand or tens of thousands of

00:30:39,799 --> 00:30:44,030
connected devices this again becomes a

00:30:41,960 --> 00:30:45,799
really tough problem to solve and what

00:30:44,030 --> 00:30:50,000
this really comes down to is this and

00:30:45,799 --> 00:30:51,650
how do you resolve this the basic idea

00:30:50,000 --> 00:30:54,260
is that we want to tag objects with some

00:30:51,650 --> 00:30:57,440
type of metadata that's unique and we

00:30:54,260 --> 00:30:59,840
want to be able to figure out based on

00:30:57,440 --> 00:31:02,570
this tag metadata and what order do we

00:30:59,840 --> 00:31:04,790
need to update our system and in what

00:31:02,570 --> 00:31:07,640
order has have these things come through

00:31:04,790 --> 00:31:10,040
and which one is the winner and who

00:31:07,640 --> 00:31:13,309
should we actually trust their their

00:31:10,040 --> 00:31:14,690
operation to be the most current and if

00:31:13,309 --> 00:31:16,220
you've ever looked at any so yeah

00:31:14,690 --> 00:31:17,710
synchronization protocol is it really

00:31:16,220 --> 00:31:20,740
just come downs - tag

00:31:17,710 --> 00:31:22,059
these objects with metadata there's two

00:31:20,740 --> 00:31:23,700
main schools of thought that you

00:31:22,059 --> 00:31:26,380
typically see in this discussion

00:31:23,700 --> 00:31:28,360
the first is operational transforms it's

00:31:26,380 --> 00:31:30,520
kind of an older idea but Google Docs

00:31:28,360 --> 00:31:31,630
still uses it in Microsoft Office online

00:31:30,520 --> 00:31:33,039
these are kind of the two biggest

00:31:31,630 --> 00:31:35,020
applications that I found that actually

00:31:33,039 --> 00:31:37,320
still use this and then there's this

00:31:35,020 --> 00:31:40,240
idea of CR DTS which are conflict-free

00:31:37,320 --> 00:31:41,799
replicated data types Redis Facebook

00:31:40,240 --> 00:31:43,480
cosmos DB those were the biggest

00:31:41,799 --> 00:31:45,250
companies that I could find that

00:31:43,480 --> 00:31:48,100
actually publicly have papers and stuff

00:31:45,250 --> 00:31:50,620
written about this stuff now this this

00:31:48,100 --> 00:31:51,850
stuff really is gets pretty academic if

00:31:50,620 --> 00:31:53,649
you start reading some of the papers and

00:31:51,850 --> 00:31:57,220
stuff but really what it comes down to

00:31:53,649 --> 00:31:59,590
is having a clock that's associated with

00:31:57,220 --> 00:32:02,110
the update that's happening a clock is

00:31:59,590 --> 00:32:03,909
basically some type of unique identifier

00:32:02,110 --> 00:32:05,770
that's going to be giving some type of

00:32:03,909 --> 00:32:07,419
associative tom and this could be an

00:32:05,770 --> 00:32:08,799
actual Tom stamp but it could be

00:32:07,419 --> 00:32:11,049
something that is actually more

00:32:08,799 --> 00:32:12,700
mathematical like a vector clock or a

00:32:11,049 --> 00:32:18,309
monotonic counter which is what we use

00:32:12,700 --> 00:32:20,440
without sync in datastore so again now

00:32:18,309 --> 00:32:22,870
let's look at what these clocks are

00:32:20,440 --> 00:32:26,080
actually solving so let's take a look at

00:32:22,870 --> 00:32:31,029
a piece of data we have a person with

00:32:26,080 --> 00:32:33,159
two properties a name and an age we now

00:32:31,029 --> 00:32:35,200
have two clients that come online at the

00:32:33,159 --> 00:32:38,409
same time and make an operation at the

00:32:35,200 --> 00:32:41,440
same time client a updates the title to

00:32:38,409 --> 00:32:43,450
engineer and client B updates the

00:32:41,440 --> 00:32:45,610
location to Nebraska but these

00:32:43,450 --> 00:32:47,500
operations happen at the same time if we

00:32:45,610 --> 00:32:50,770
had a naive approach to this we might

00:32:47,500 --> 00:32:52,450
update client a or client B first

00:32:50,770 --> 00:32:55,720
whichever one really you know comes in

00:32:52,450 --> 00:32:57,640
exactly first and then the next right

00:32:55,720 --> 00:33:00,880
would override that object because

00:32:57,640 --> 00:33:02,590
instead of creating a merge between

00:33:00,880 --> 00:33:07,390
these two objects but we end up doing is

00:33:02,590 --> 00:33:10,450
overriding one with the other what we

00:33:07,390 --> 00:33:12,640
would like to have is a union between

00:33:10,450 --> 00:33:15,580
these two data sets we'd like to have

00:33:12,640 --> 00:33:17,740
the title updated and the location

00:33:15,580 --> 00:33:19,299
updated as well right now what about

00:33:17,740 --> 00:33:22,059
with lists this becomes even more

00:33:19,299 --> 00:33:24,399
complicated I think because let's say we

00:33:22,059 --> 00:33:27,100
have two connected clients they both

00:33:24,399 --> 00:33:28,630
send an operation and we want to add an

00:33:27,100 --> 00:33:30,320
additional item to the array of data

00:33:28,630 --> 00:33:32,760
here

00:33:30,320 --> 00:33:35,370
ideally what we'd like to have is

00:33:32,760 --> 00:33:37,590
something like this where we end up not

00:33:35,370 --> 00:33:39,090
overriding one person's piece of data

00:33:37,590 --> 00:33:42,090
with the other we would like to have a

00:33:39,090 --> 00:33:45,360
union between the results of the hobbies

00:33:42,090 --> 00:33:47,010
array which is you know is ideally you

00:33:45,360 --> 00:33:49,680
know what you what you were probably

00:33:47,010 --> 00:33:51,540
wanting in a situation like this so how

00:33:49,680 --> 00:33:55,980
do we deal with this conflict detection

00:33:51,540 --> 00:33:57,300
and conflict resolution well we have a

00:33:55,980 --> 00:33:59,160
couple of things that we do to make this

00:33:57,300 --> 00:34:01,470
work first of all we use this idea of

00:33:59,160 --> 00:34:02,910
monotonic counters it sounds complex

00:34:01,470 --> 00:34:05,490
it's really pretty basic I'm going to

00:34:02,910 --> 00:34:08,850
walk through in just a moment the

00:34:05,490 --> 00:34:10,200
counters and also any other versioning

00:34:08,850 --> 00:34:12,180
that we're doing is all controlled by

00:34:10,200 --> 00:34:13,560
the system itself so this is all

00:34:12,180 --> 00:34:15,750
controlled by app sync in a couple of

00:34:13,560 --> 00:34:18,300
different ways and the way that we make

00:34:15,750 --> 00:34:20,670
this work is we use graph QL types that

00:34:18,300 --> 00:34:23,400
have versions that are used for merge or

00:34:20,670 --> 00:34:25,980
reject decisions and all this all this

00:34:23,400 --> 00:34:29,100
metadata is stored both locally and in

00:34:25,980 --> 00:34:32,220
the system and then we have two tables

00:34:29,100 --> 00:34:34,740
for every table we have an additional

00:34:32,220 --> 00:34:36,120
change table or change journal where we

00:34:34,740 --> 00:34:39,630
keep up with all the different updates

00:34:36,120 --> 00:34:41,940
and in the base table and in the change

00:34:39,630 --> 00:34:45,270
journal we have this idea of time to

00:34:41,940 --> 00:34:46,980
live and we also only up operate with

00:34:45,270 --> 00:34:48,660
self deletes so with that bit whatis

00:34:46,980 --> 00:34:50,460
obsolete is is instead of actually

00:34:48,660 --> 00:34:52,140
deleting the audit from the database we

00:34:50,460 --> 00:34:53,970
add a flag that says whether or not this

00:34:52,140 --> 00:34:55,440
item has been deleted and we'll talk

00:34:53,970 --> 00:34:58,050
about that more in just a moment how

00:34:55,440 --> 00:35:00,510
that works so what is a monotonic

00:34:58,050 --> 00:35:01,920
counter they might want to make it sound

00:35:00,510 --> 00:35:03,360
like it's complicated it's really not

00:35:01,920 --> 00:35:05,010
that complicated after I started digging

00:35:03,360 --> 00:35:06,930
into this and after we actually

00:35:05,010 --> 00:35:08,640
implemented this all this basically is

00:35:06,930 --> 00:35:10,800
is we want to have some type of counter

00:35:08,640 --> 00:35:13,170
that increments only in one direction in

00:35:10,800 --> 00:35:15,870
our case we only want it to increment up

00:35:13,170 --> 00:35:17,790
we want to make sure that if we have an

00:35:15,870 --> 00:35:20,610
item stored that's version one it's

00:35:17,790 --> 00:35:22,050
never overwritten by version zero we

00:35:20,610 --> 00:35:23,580
never were one to overwrite version

00:35:22,050 --> 00:35:25,170
three by version two the only time you

00:35:23,580 --> 00:35:28,980
can override an item is by increment by

00:35:25,170 --> 00:35:30,270
an incremental change so what this might

00:35:28,980 --> 00:35:33,750
look like in your table is something

00:35:30,270 --> 00:35:35,550
like this we have IDs we have metadata

00:35:33,750 --> 00:35:37,440
and then we have an underscore version

00:35:35,550 --> 00:35:40,200
in each item in the database has a

00:35:37,440 --> 00:35:42,960
version that's the base table what about

00:35:40,200 --> 00:35:44,160
the change table to change journal

00:35:42,960 --> 00:35:46,070
change table whatever you like to call

00:35:44,160 --> 00:35:48,810
this this keeps up with every single

00:35:46,070 --> 00:35:53,310
mutation that happens ever in your

00:35:48,810 --> 00:35:56,700
application now this has a way for us to

00:35:53,310 --> 00:35:58,710
keep up with the unique identifiers and

00:35:56,700 --> 00:36:00,390
one and and and and a couple of

00:35:58,710 --> 00:36:02,040
different well in one way actually and

00:36:00,390 --> 00:36:05,609
what we basically do is use a

00:36:02,040 --> 00:36:07,800
combination of our primary key in our

00:36:05,609 --> 00:36:10,050
short key the primary key is a

00:36:07,800 --> 00:36:12,180
concatenation of the type name the

00:36:10,050 --> 00:36:15,470
graphic you'll type name a UUID and in

00:36:12,180 --> 00:36:18,240
the date and the sort key is a

00:36:15,470 --> 00:36:20,250
combination of the timestamp the UUID in

00:36:18,240 --> 00:36:24,320
the version and using these two keys

00:36:20,250 --> 00:36:24,320
together we can have a unique identifier

00:36:24,710 --> 00:36:31,410
and the way that we the the main way

00:36:29,490 --> 00:36:34,920
that we kind of are handling conflicts

00:36:31,410 --> 00:36:37,920
is this idea of Auto merge so let's take

00:36:34,920 --> 00:36:40,619
another look at a system that we might

00:36:37,920 --> 00:36:44,820
want to identify and find the solution

00:36:40,619 --> 00:36:49,260
to so we have two connected clients user

00:36:44,820 --> 00:36:54,900
B makes a mutation she changes the age

00:36:49,260 --> 00:36:57,900
from 32 to 33 user a then gets this

00:36:54,900 --> 00:37:01,470
update so now we've incremented the

00:36:57,900 --> 00:37:03,140
version from version to to version 3 I'm

00:37:01,470 --> 00:37:08,849
sorry from version one to version two

00:37:03,140 --> 00:37:10,980
now user B goes offline user B then

00:37:08,849 --> 00:37:12,869
makes an OP makes an update has an

00:37:10,980 --> 00:37:14,730
optimistic response on their on their UI

00:37:12,869 --> 00:37:16,500
so to them everything looks great

00:37:14,730 --> 00:37:18,000
they're not back online yet though so

00:37:16,500 --> 00:37:22,320
the operation hasn't actually gone

00:37:18,000 --> 00:37:23,880
through now user a comes back and they

00:37:22,320 --> 00:37:27,359
actually are still online and they make

00:37:23,880 --> 00:37:31,050
another update so person user B's update

00:37:27,359 --> 00:37:32,910
is changing the data to have an

00:37:31,050 --> 00:37:37,050
additional item called location and

00:37:32,910 --> 00:37:39,990
they're also changing the age to 34 user

00:37:37,050 --> 00:37:42,240
a is not adding any additional metadata

00:37:39,990 --> 00:37:45,599
they're only changing the age from 33 to

00:37:42,240 --> 00:37:50,670
35 so we have a conflict here person B

00:37:45,599 --> 00:37:52,770
is updating the age person a is updating

00:37:50,670 --> 00:37:53,790
the age so we have two different things

00:37:52,770 --> 00:37:58,350
that are going on here

00:37:53,790 --> 00:38:01,410
now user becomes back online what's

00:37:58,350 --> 00:38:04,740
gonna happen well what's gonna happen is

00:38:01,410 --> 00:38:07,140
what would we like to happen is with

00:38:04,740 --> 00:38:08,940
without emerge this is actually what

00:38:07,140 --> 00:38:11,160
happens is we're going to basically take

00:38:08,940 --> 00:38:13,920
these two result sets and create a union

00:38:11,160 --> 00:38:16,470
and what we're gonna see is that when

00:38:13,920 --> 00:38:19,920
this person created this mutation of age

00:38:16,470 --> 00:38:22,410
34 it was prior to when this other

00:38:19,920 --> 00:38:25,170
person created the age of 35 so we want

00:38:22,410 --> 00:38:27,420
to keep the location field but when I

00:38:25,170 --> 00:38:30,660
discard the age field and what we end up

00:38:27,420 --> 00:38:32,850
with is this result set where the person

00:38:30,660 --> 00:38:34,800
now has age of 35 the location of

00:38:32,850 --> 00:38:38,450
Seattle and we increment the version to

00:38:34,800 --> 00:38:42,450
4 and the way that we kind of do this is

00:38:38,450 --> 00:38:45,600
we use this change table the base table

00:38:42,450 --> 00:38:47,970
and graph QL types with versions to deal

00:38:45,600 --> 00:38:51,630
with the merge conflicts and reject

00:38:47,970 --> 00:38:56,820
decisions and we use graph QL resolvers

00:38:51,630 --> 00:38:59,310
that we call sync enabled resolvers so

00:38:56,820 --> 00:39:01,710
our marriage is kind of the base the

00:38:59,310 --> 00:39:03,630
main form of conflict resolution that we

00:39:01,710 --> 00:39:05,280
by default would recommend but we also

00:39:03,630 --> 00:39:07,470
offer a couple of different ways to do

00:39:05,280 --> 00:39:08,820
conflict resolution as well because auto

00:39:07,470 --> 00:39:11,130
marriage does not might not be what you

00:39:08,820 --> 00:39:14,340
want for every single operation you can

00:39:11,130 --> 00:39:17,430
kind of choose the type of conflict

00:39:14,340 --> 00:39:20,640
resolution that you like based on each

00:39:17,430 --> 00:39:22,770
each operation so the other options that

00:39:20,640 --> 00:39:25,320
we have or optimistic concurrency which

00:39:22,770 --> 00:39:26,610
basically is last rider wins and then if

00:39:25,320 --> 00:39:28,290
you want to have something custom you

00:39:26,610 --> 00:39:31,950
can write it in a lambda function which

00:39:28,290 --> 00:39:33,780
is pretty easy to configure as well so

00:39:31,950 --> 00:39:38,820
let's talk about now the synchronization

00:39:33,780 --> 00:39:41,370
piece of this if you think of a basic

00:39:38,820 --> 00:39:43,830
approach to synchronization you might

00:39:41,370 --> 00:39:45,810
have something like this your app user

00:39:43,830 --> 00:39:51,660
comes online we fetch data from the

00:39:45,810 --> 00:39:54,110
database and we might have two users

00:39:51,660 --> 00:39:56,220
that now that are in our system

00:39:54,110 --> 00:39:59,880
they're both online at the same time

00:39:56,220 --> 00:40:02,790
user one goes offline user two sends a

00:39:59,880 --> 00:40:05,670
delete so now we have an inconsistent

00:40:02,790 --> 00:40:06,779
data between our first and our second

00:40:05,670 --> 00:40:08,939
client

00:40:06,779 --> 00:40:12,329
now when user one comes back online a

00:40:08,939 --> 00:40:14,969
naive approach might be to go back and

00:40:12,329 --> 00:40:18,630
fetch the entire data set from our table

00:40:14,969 --> 00:40:22,079
now this is okay in some circumstances

00:40:18,630 --> 00:40:24,929
but but really optimally if we're

00:40:22,079 --> 00:40:27,059
dealing with large data sets if we're

00:40:24,929 --> 00:40:29,339
dealing with applications that are

00:40:27,059 --> 00:40:31,140
working with a lot of interactions going

00:40:29,339 --> 00:40:33,479
on on the client so single threaded apps

00:40:31,140 --> 00:40:35,189
like Java Script ops but this also comes

00:40:33,479 --> 00:40:37,769
up in native ios and android development

00:40:35,189 --> 00:40:39,719
as well ideally what we want is only to

00:40:37,769 --> 00:40:41,849
get the change set from the last time

00:40:39,719 --> 00:40:43,619
that that person was online and the way

00:40:41,849 --> 00:40:46,199
that we do this is this idea of Delta

00:40:43,619 --> 00:40:48,299
sync and Delta is the change you know

00:40:46,199 --> 00:40:50,429
between when the user was online laughs

00:40:48,299 --> 00:40:53,130
and the user was on comes back online

00:40:50,429 --> 00:40:56,819
and the way that we kind of do this is

00:40:53,130 --> 00:40:59,400
by using this change table so let's look

00:40:56,819 --> 00:41:04,409
at this again using a delta sync user

00:40:59,400 --> 00:41:07,859
one comes online they fetch their data

00:41:04,409 --> 00:41:09,989
they then go off on someone comes in

00:41:07,859 --> 00:41:13,529
creates another item in the database

00:41:09,989 --> 00:41:15,150
table but think about this maybe in its

00:41:13,529 --> 00:41:20,339
scale this might be hundreds or

00:41:15,150 --> 00:41:23,519
thousands of items right what we can now

00:41:20,339 --> 00:41:26,339
do is in the graph QL query we can pass

00:41:23,519 --> 00:41:27,809
in an argument this is going to specify

00:41:26,339 --> 00:41:32,669
the last time that we sync with the

00:41:27,809 --> 00:41:35,429
database using this last sync argument

00:41:32,669 --> 00:41:36,900
we can now create a query and we can say

00:41:35,429 --> 00:41:39,209
we only want to get the changes that

00:41:36,900 --> 00:41:41,159
have happened since this last time we

00:41:39,209 --> 00:41:43,739
synced up so now we're only going to

00:41:41,159 --> 00:41:45,419
create a query fetching the changed

00:41:43,739 --> 00:41:47,339
items bringing those back to our device

00:41:45,419 --> 00:41:50,419
therefore we're saving a lot of

00:41:47,339 --> 00:41:52,650
bandwidth and a lot of network you know

00:41:50,419 --> 00:41:55,289
activity but also locally we're not

00:41:52,650 --> 00:41:56,669
having to do as much work as well the

00:41:55,289 --> 00:41:58,039
last thing that this gives us is this

00:41:56,669 --> 00:42:01,519
idea of tomtravel

00:41:58,039 --> 00:42:04,679
because we have an entire ledger both of

00:42:01,519 --> 00:42:05,939
the current table where as well as all

00:42:04,679 --> 00:42:07,949
the different operations that have

00:42:05,939 --> 00:42:09,809
happened in the past we can actually go

00:42:07,949 --> 00:42:10,919
through our change table and see

00:42:09,809 --> 00:42:13,650
everything that's happened so if

00:42:10,919 --> 00:42:15,209
something happens wrong we can catch it

00:42:13,650 --> 00:42:17,119
in time before our time to live is

00:42:15,209 --> 00:42:19,709
expired and maybe see what happened

00:42:17,119 --> 00:42:20,460
speaking of time to live this also gives

00:42:19,709 --> 00:42:22,890
you more

00:42:20,460 --> 00:42:25,560
optimisations around your database so

00:42:22,890 --> 00:42:27,210
using this time to live you can set for

00:42:25,560 --> 00:42:32,400
how long you want your change journal to

00:42:27,210 --> 00:42:34,230
live so this might be 30 minutes it

00:42:32,400 --> 00:42:35,310
might be 30 days might be a year

00:42:34,230 --> 00:42:37,530
whatever you like

00:42:35,310 --> 00:42:39,300
after this time to live expires the

00:42:37,530 --> 00:42:41,760
items will automatically be deleted from

00:42:39,300 --> 00:42:46,020
your database so you don't have to pay

00:42:41,760 --> 00:42:47,750
for that additional storage as far as

00:42:46,020 --> 00:42:50,760
the platforms are concerned you know

00:42:47,750 --> 00:42:52,830
right now as it's been for a while

00:42:50,760 --> 00:42:54,540
the main platforms are native iOS native

00:42:52,830 --> 00:42:57,810
Android and web so we support all those

00:42:54,540 --> 00:42:59,580
and we think that optimally and we're

00:42:57,810 --> 00:43:02,280
seeing this a lot with our customers

00:42:59,580 --> 00:43:04,950
people are building applications across

00:43:02,280 --> 00:43:07,320
all platforms react native is huge

00:43:04,950 --> 00:43:10,050
between startups that work with Amazon

00:43:07,320 --> 00:43:11,940
but also within Amazon where I work we

00:43:10,050 --> 00:43:13,080
have tons of apps being built using

00:43:11,940 --> 00:43:16,020
react native we have our own react

00:43:13,080 --> 00:43:17,820
native conference we even have like

00:43:16,020 --> 00:43:20,369
rewrites being done entirely and react

00:43:17,820 --> 00:43:21,920
native because we want to deliver

00:43:20,369 --> 00:43:25,020
experiences across all these platforms

00:43:21,920 --> 00:43:26,640
now react native isn't always the answer

00:43:25,020 --> 00:43:29,070
but it is a lot of the times but but

00:43:26,640 --> 00:43:31,410
bottom line is developers want to ship

00:43:29,070 --> 00:43:34,109
to iOS Android and web and that's kind

00:43:31,410 --> 00:43:36,060
of what we we want to deliver so if you

00:43:34,109 --> 00:43:38,970
want to learn more about datastore you

00:43:36,060 --> 00:43:40,800
can just go to the docs and also have

00:43:38,970 --> 00:43:43,859
maybe a couple of starter projects on my

00:43:40,800 --> 00:43:50,819
github comm slash tab at 3:00 and that's

00:43:43,859 --> 00:43:55,819
it thank you oh yeah

00:43:50,819 --> 00:43:55,819
questions does anyone have any questions

00:44:06,739 --> 00:44:12,569
thanks for you talk I basically have two

00:44:09,749 --> 00:44:14,999
questions is this based on local time of

00:44:12,569 --> 00:44:17,489
the device it's my first question and

00:44:14,999 --> 00:44:20,309
the second one is do you handle schema

00:44:17,489 --> 00:44:23,660
changes over time we are we do handle

00:44:20,309 --> 00:44:25,619
schema migrations there is an actual

00:44:23,660 --> 00:44:28,199
utility that we have that actually will

00:44:25,619 --> 00:44:29,849
deal with the migrations as far as the

00:44:28,199 --> 00:44:31,650
the time that's a good question because

00:44:29,849 --> 00:44:34,439
we actually don't we don't rely on any

00:44:31,650 --> 00:44:36,869
local device time we're using this idea

00:44:34,439 --> 00:44:39,209
of monotonic counters and the counters

00:44:36,869 --> 00:44:42,029
are incremented based on the actual

00:44:39,209 --> 00:44:44,699
system itself so we don't rule out any

00:44:42,029 --> 00:44:47,219
local local reference to Tom that is

00:44:44,699 --> 00:44:49,589
created on the device itself we're

00:44:47,219 --> 00:44:52,349
basically taking a reference from the

00:44:49,589 --> 00:44:53,969
time that the device comes online versus

00:44:52,349 --> 00:44:55,890
the next time of the update so instead

00:44:53,969 --> 00:45:01,259
of it actually being a real time stamp

00:44:55,890 --> 00:45:03,829
it's more of like a number yeah anyone

00:45:01,259 --> 00:45:03,829
else have any questions

00:45:13,920 --> 00:45:19,540
hi thanks for your talk I've got a

00:45:17,140 --> 00:45:22,510
question about autumn urge you the case

00:45:19,540 --> 00:45:24,820
you showed pretty much allowed to do the

00:45:22,510 --> 00:45:29,320
merge without using the change table at

00:45:24,820 --> 00:45:31,780
all because you could infer from the two

00:45:29,320 --> 00:45:36,250
objects that you were merging I mean

00:45:31,780 --> 00:45:38,800
both both change properties were scalar

00:45:36,250 --> 00:45:41,140
so you could just merge it together how

00:45:38,800 --> 00:45:44,890
do you do it for more complex data types

00:45:41,140 --> 00:45:46,770
like lists for example I figure you you

00:45:44,890 --> 00:45:50,320
kind of need to use the change table and

00:45:46,770 --> 00:45:52,030
if yes what do you do if an update comes

00:45:50,320 --> 00:45:56,040
in and you no longer have the necessary

00:45:52,030 --> 00:45:59,710
change protocol so we we do we deal with

00:45:56,040 --> 00:46:02,050
we deal with lesson sets you know

00:45:59,710 --> 00:46:03,880
basically you can have you have a couple

00:46:02,050 --> 00:46:05,740
of options that when you're actually

00:46:03,880 --> 00:46:08,590
creating the operation itself

00:46:05,740 --> 00:46:10,420
you can do a pin or you can do overwrite

00:46:08,590 --> 00:46:11,830
and if you do a pin we basically are

00:46:10,420 --> 00:46:13,930
going to handle that in the graphic in

00:46:11,830 --> 00:46:17,620
the resolver itself and what we're going

00:46:13,930 --> 00:46:19,450
to basically do is basically say we're

00:46:17,620 --> 00:46:20,860
gonna have an associative tom stamp I

00:46:19,450 --> 00:46:22,120
guess you would say it's not really a

00:46:20,860 --> 00:46:24,010
time stamp but it's something like that

00:46:22,120 --> 00:46:26,800
associated with every item and then

00:46:24,010 --> 00:46:29,500
based on whether or not we feel if it's

00:46:26,800 --> 00:46:30,670
appropriate to either overwrite an item

00:46:29,500 --> 00:46:33,240
that's already there or we'll just

00:46:30,670 --> 00:46:39,700
append to the list that's already there

00:46:33,240 --> 00:46:41,650
Thanks we also have a big write-up slash

00:46:39,700 --> 00:46:43,930
piece of documentation going into a

00:46:41,650 --> 00:46:45,610
little more depth around our conflict

00:46:43,930 --> 00:46:47,110
resolution strategy and our

00:46:45,610 --> 00:46:50,980
documentation so you might want to check

00:46:47,110 --> 00:46:55,180
that out does anyone have any other

00:46:50,980 --> 00:47:01,220
questions we have time for one more okay

00:46:55,180 --> 00:47:05,440
three do one okay thank you

00:47:01,220 --> 00:47:05,440

YouTube URL: https://www.youtube.com/watch?v=kTiLTGbOwQA


