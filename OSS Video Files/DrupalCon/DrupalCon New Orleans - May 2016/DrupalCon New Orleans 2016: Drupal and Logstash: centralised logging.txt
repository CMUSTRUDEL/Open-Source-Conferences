Title: DrupalCon New Orleans 2016: Drupal and Logstash: centralised logging
Publication date: 2016-05-10
Playlist: DrupalCon New Orleans - May 2016
Description: 
	Have you heard about Logstash and always wanted to test it out? This is your perfect chance to start!

The ELK stack – Elasticsearch, Logstash and Kibana – is a popular combination for aggregating, filtering and visualising data from multiple log streams. This presentation will demonstrate how to use ELK with Drupal. You will see data being filtered on the fly with lots of pretty graphs.

The focus of this presentation will be on how easy it is to start. We will cover how to run the ELK stack on your development machine with just a few commands - using the power of docker - and analyse your apache, Drupal and php logs.

Then we will have a look at real production installation, recieving logs from different sources, where we will analyse a problem and visualise trends.

The objective of this session is to:

get you excited about Logstash, understand what it is,
get you motivated enough to start using it, even to set it up yourself,
teach you how to create graphs on the fly, visualise your data,
realise the power of a centralised logging solution.
About the presenter

Marji is a co-founder and the chief systems administrator for Morpht, specialising in DevOps, Ansible, Logstash / ELK, Puppet, Jenkins, server configuration and developer workflow – with Drupal being the centre of his attention.
Captions: 
	00:00:00,410 --> 00:00:07,710
before I start I would like to point out

00:00:05,009 --> 00:00:10,320
that this presentation was prepared for

00:00:07,710 --> 00:00:11,969
beginner audience in mind so if you guys

00:00:10,320 --> 00:00:13,559
have been doing dr. running in

00:00:11,969 --> 00:00:16,770
production for a while it's probably not

00:00:13,559 --> 00:00:18,150
for you so please feel free leave me any

00:00:16,770 --> 00:00:21,900
time I will not take it personally if

00:00:18,150 --> 00:00:25,350
you always wanted to try run a log stash

00:00:21,900 --> 00:00:27,869
sorry I said dr. Locke stage and give

00:00:25,350 --> 00:00:33,059
this a try but didn't know how you're in

00:00:27,869 --> 00:00:35,760
the right room okay let me introduce

00:00:33,059 --> 00:00:37,920
myself my name is Margie I'm a systems

00:00:35,760 --> 00:00:40,500
engineer working for a small Drupal

00:00:37,920 --> 00:00:44,520
company in Australia based in Sydney

00:00:40,500 --> 00:00:46,550
called morphed it's small but we were

00:00:44,520 --> 00:00:48,510
lucky enough to have a few enterprise

00:00:46,550 --> 00:00:52,850
customers from the publishing industry

00:00:48,510 --> 00:00:56,250
pharma industry and local and government

00:00:52,850 --> 00:00:58,440
australian government so that gives us

00:00:56,250 --> 00:01:00,840
good opportunity to do a lot of DevOps

00:00:58,440 --> 00:01:03,180
at big projects which is really good fun

00:01:00,840 --> 00:01:06,600
I have been fun of DevOps following

00:01:03,180 --> 00:01:09,590
DevOps for last five six years I would

00:01:06,600 --> 00:01:12,720
say and I think I became a sysadmin in

00:01:09,590 --> 00:01:15,659
1999 when my colleague at a web

00:01:12,720 --> 00:01:17,970
development company left us and I was

00:01:15,659 --> 00:01:20,729
suddenly the only responsible for the

00:01:17,970 --> 00:01:23,250
production web server running actually

00:01:20,729 --> 00:01:25,080
web pages of a political party which was

00:01:23,250 --> 00:01:26,970
in the government at the time so that

00:01:25,080 --> 00:01:33,780
was really good start of my sis admin

00:01:26,970 --> 00:01:36,000
career Matt it was fun okie dokie so to

00:01:33,780 --> 00:01:38,369
give you get you an idea I used to work

00:01:36,000 --> 00:01:40,439
for a couple of ISPs in Australia as

00:01:38,369 --> 00:01:42,659
well if you are wondering is this

00:01:40,439 --> 00:01:44,369
Australian accent it is not of course

00:01:42,659 --> 00:01:46,280
not i'm originally from the czech

00:01:44,369 --> 00:01:52,020
republic i have lived in Australia for

00:01:46,280 --> 00:01:53,909
12 years so I've worked for a few big

00:01:52,020 --> 00:01:56,700
ice piece in Australia and you get at

00:01:53,909 --> 00:01:59,040
the kid which says customer says they

00:01:56,700 --> 00:02:00,299
get randomly redirected while browsing

00:01:59,040 --> 00:02:02,100
your website there is no more

00:02:00,299 --> 00:02:05,009
information so what what can i do right

00:02:02,100 --> 00:02:08,220
so this is way back so what do you do

00:02:05,009 --> 00:02:10,500
you login to the web server and start

00:02:08,220 --> 00:02:11,160
dripping logs right so this is an Apache

00:02:10,500 --> 00:02:14,550
so

00:02:11,160 --> 00:02:16,500
see like gripping 430 EX in apache logs

00:02:14,550 --> 00:02:17,880
i'm trying to filter out the lines which

00:02:16,500 --> 00:02:20,700
I don't want to see so I'll get rid of

00:02:17,880 --> 00:02:24,270
Google board and you know this is a mess

00:02:20,700 --> 00:02:26,580
right this is how it used to be it can

00:02:24,270 --> 00:02:28,500
be even worse if you happen to have more

00:02:26,580 --> 00:02:30,390
than one web server like behind a load

00:02:28,500 --> 00:02:32,760
balancer you might need to jump on all

00:02:30,390 --> 00:02:35,400
of them and decision on each of them or

00:02:32,760 --> 00:02:37,530
maybe download the logs on your machine

00:02:35,400 --> 00:02:40,020
and do their I actually do remember

00:02:37,530 --> 00:02:43,140
working for a big telco in Australia

00:02:40,020 --> 00:02:45,540
that we had a colleague of mine wrote a

00:02:43,140 --> 00:02:48,930
little robot which was theoretically are

00:02:45,540 --> 00:02:53,370
sinking apache logs or tomcat logs from

00:02:48,930 --> 00:02:56,610
24 production web heads to like a big

00:02:53,370 --> 00:02:59,010
thumper thumper storage box just to be

00:02:56,610 --> 00:03:00,420
able to have it locally and parse it you

00:02:59,010 --> 00:03:02,670
know like that was that spread butter

00:03:00,420 --> 00:03:04,350
that's how people used to do it so what

00:03:02,670 --> 00:03:07,320
if there was a new way what if you just

00:03:04,350 --> 00:03:10,170
go to a console and type in hey give me

00:03:07,320 --> 00:03:12,600
locked up apache and it belongs to this

00:03:10,170 --> 00:03:15,600
side and the server response was between

00:03:12,600 --> 00:03:19,050
301 and three or four well there is such

00:03:15,600 --> 00:03:23,420
a thing it's called cabana and you can

00:03:19,050 --> 00:03:26,820
see that here is the query line and

00:03:23,420 --> 00:03:30,720
after hitting enter their you get 12

00:03:26,820 --> 00:03:32,630
hits back over the last 15 minutes if

00:03:30,720 --> 00:03:35,370
you can see it in the right top corner

00:03:32,630 --> 00:03:37,050
which basically are exactly what they

00:03:35,370 --> 00:03:39,959
are looking for and you can start going

00:03:37,050 --> 00:03:43,220
into and you can see these fields on the

00:03:39,959 --> 00:03:45,120
left which are extracted from the lines

00:03:43,220 --> 00:03:48,360
then you can go and create a

00:03:45,120 --> 00:03:52,170
visualization a little chart with all

00:03:48,360 --> 00:03:54,420
the response codes over the time on

00:03:52,170 --> 00:03:55,620
maybe even better like a date histogram

00:03:54,420 --> 00:03:56,970
which shows you more what what's

00:03:55,620 --> 00:03:59,970
happening about what course you are

00:03:56,970 --> 00:04:02,760
getting so what is it we have just seen

00:03:59,970 --> 00:04:05,760
so this was cabana I will explain what

00:04:02,760 --> 00:04:09,330
Gibby on is and we just as you could see

00:04:05,760 --> 00:04:13,530
we just executed one query and create it

00:04:09,330 --> 00:04:15,600
to visualization to help us look at the

00:04:13,530 --> 00:04:17,190
data but what's under the hood and

00:04:15,600 --> 00:04:20,100
learns the log stash I'm supposed to

00:04:17,190 --> 00:04:21,690
talk about well para ladies and

00:04:20,100 --> 00:04:24,180
gentlemen let me introduce you to the

00:04:21,690 --> 00:04:27,640
elk stack

00:04:24,180 --> 00:04:30,670
Alec stands for elasticsearch log stash

00:04:27,640 --> 00:04:32,710
& Gabbana these are three open source

00:04:30,670 --> 00:04:34,980
projects maintained by a company called

00:04:32,710 --> 00:04:40,390
elastic which has had quarter in

00:04:34,980 --> 00:04:42,820
Amsterdam and I go regularly to their

00:04:40,390 --> 00:04:45,370
meetups because this is really you know

00:04:42,820 --> 00:04:49,620
everybody but many companies these days

00:04:45,370 --> 00:04:53,830
use elastic search for storing documents

00:04:49,620 --> 00:04:57,670
searching so I go to their meetups so a

00:04:53,830 --> 00:05:00,460
little bit of a interesting development

00:04:57,670 --> 00:05:02,560
on the elk name so I think early this

00:05:00,460 --> 00:05:04,930
year they realize it's not al anymore

00:05:02,560 --> 00:05:07,360
maybe you know like there it's like a

00:05:04,930 --> 00:05:09,670
bee and elec together you can see that

00:05:07,360 --> 00:05:12,760
they tried that's because there is a new

00:05:09,670 --> 00:05:15,790
component which came to the stag it's

00:05:12,760 --> 00:05:18,210
called beats so we can call it bulk it's

00:05:15,790 --> 00:05:20,940
probably the accurate name for today and

00:05:18,210 --> 00:05:23,440
also i think the elastic announced that

00:05:20,940 --> 00:05:25,210
at least since the new version like

00:05:23,440 --> 00:05:26,860
there is a version 5 of all these four

00:05:25,210 --> 00:05:29,230
components coming within a month or two

00:05:26,860 --> 00:05:32,470
they will call it elastic stag so that's

00:05:29,230 --> 00:05:34,990
actually the name the next marketing

00:05:32,470 --> 00:05:38,320
name of the LX tag so elastic stack is

00:05:34,990 --> 00:05:40,530
the old Alex tag and this these are are

00:05:38,320 --> 00:05:45,060
there like a new logos of the project

00:05:40,530 --> 00:05:50,140
products so what's what's the goal of

00:05:45,060 --> 00:05:52,320
the stag it's basically designed to take

00:05:50,140 --> 00:05:55,210
that up from any source in any format

00:05:52,320 --> 00:06:00,210
process it transform it and enrich it

00:05:55,210 --> 00:06:03,250
and then store it so you can search

00:06:00,210 --> 00:06:05,230
analyze and visualize it in real time so

00:06:03,250 --> 00:06:10,690
that's what the stack is supposed to

00:06:05,230 --> 00:06:13,030
provide you as I said well we can look

00:06:10,690 --> 00:06:14,350
at it as like it has four components at

00:06:13,030 --> 00:06:17,590
the moment so I will just walk you

00:06:14,350 --> 00:06:20,050
through this briefly elasticsearch is

00:06:17,590 --> 00:06:22,530
where the data is stored in the Alex tag

00:06:20,050 --> 00:06:25,750
it's actually a full text search

00:06:22,530 --> 00:06:28,090
analytic engine you might be similar

00:06:25,750 --> 00:06:30,130
with Apache Solr they actually share the

00:06:28,090 --> 00:06:33,820
same codebase both of them were forked

00:06:30,130 --> 00:06:36,380
from apache Lucene but this one has like

00:06:33,820 --> 00:06:38,230
a high availability high availability

00:06:36,380 --> 00:06:41,450
I built in and have horizontal

00:06:38,230 --> 00:06:45,140
scalability as well you know you have a

00:06:41,450 --> 00:06:47,330
cluster of several elasticsearch notes

00:06:45,140 --> 00:06:49,400
we are running out of space you just add

00:06:47,330 --> 00:06:50,990
another elasticsearch know it

00:06:49,400 --> 00:06:53,240
automatically joins the cluster

00:06:50,990 --> 00:06:56,300
rebalances data you know tries to

00:06:53,240 --> 00:06:58,490
basically rebalance itself so it's

00:06:56,300 --> 00:07:02,150
designed for high availability and

00:06:58,490 --> 00:07:04,700
scalability the next tool is log stash

00:07:02,150 --> 00:07:08,900
that's the tool which collects process

00:07:04,700 --> 00:07:10,340
and forwards events and basically for

00:07:08,900 --> 00:07:13,130
data collection and Richmond and

00:07:10,340 --> 00:07:16,700
transformation it has many input outputs

00:07:13,130 --> 00:07:19,160
and plugins and this actually shows you

00:07:16,700 --> 00:07:21,770
a little bit more this is the old log

00:07:19,160 --> 00:07:24,110
stash logo before the new one was

00:07:21,770 --> 00:07:25,490
reduced which kind of you can see here

00:07:24,110 --> 00:07:28,520
what's happening you have a lot of data

00:07:25,490 --> 00:07:30,740
sources coming in size log stash you can

00:07:28,520 --> 00:07:33,590
even pull doesn't have to be pushed and

00:07:30,740 --> 00:07:35,260
then you process it somehow and then you

00:07:33,590 --> 00:07:41,420
can output it to different endpoints

00:07:35,260 --> 00:07:43,400
whatever you need to just to say a

00:07:41,420 --> 00:07:45,440
little bit with log stash so as I said

00:07:43,400 --> 00:07:48,710
there are input plugins out plugins and

00:07:45,440 --> 00:07:50,570
filter plugins so for inputs just a few

00:07:48,710 --> 00:07:52,630
like it can be file like a log file you

00:07:50,570 --> 00:07:55,640
can read from the disk it can be a

00:07:52,630 --> 00:07:57,650
socket to TCP UDP or WebSocket can read

00:07:55,640 --> 00:08:00,440
from syslog you can read from message

00:07:57,650 --> 00:08:03,080
queue from Microsoft Windows Event log

00:08:00,440 --> 00:08:05,000
also from Drupal DB log as I said you

00:08:03,080 --> 00:08:07,550
don't have to only you know like receive

00:08:05,000 --> 00:08:09,560
something you can actually pull so if I

00:08:07,550 --> 00:08:13,490
was reading from Drupal DB look I would

00:08:09,560 --> 00:08:15,920
be pulling from from mysql database and

00:08:13,490 --> 00:08:18,980
the beats i put the beads on the first

00:08:15,920 --> 00:08:22,160
that's the new thing so you will learn

00:08:18,980 --> 00:08:24,440
in a minute there are also dozens of

00:08:22,160 --> 00:08:26,510
output plugins so after you process the

00:08:24,440 --> 00:08:28,460
data in log stash you can store it

00:08:26,510 --> 00:08:29,810
somewhere else in a file again maybe you

00:08:28,460 --> 00:08:32,390
just pre-processed it change the

00:08:29,810 --> 00:08:35,150
structure you can send it somewhere else

00:08:32,390 --> 00:08:37,190
why up tcp UDP WebSocket storage and

00:08:35,150 --> 00:08:40,219
syslog put it in a message queue send it

00:08:37,190 --> 00:08:41,719
to your matrix storage system or you

00:08:40,219 --> 00:08:45,230
know create a ticket in zero read mine

00:08:41,719 --> 00:08:48,110
you know create a twitter tweet store it

00:08:45,230 --> 00:08:51,920
in s3 all or store it in elastic search

00:08:48,110 --> 00:08:56,540
what else the Alex tech does and there

00:08:51,920 --> 00:08:58,850
are a few filters logstash uses for

00:08:56,540 --> 00:09:01,760
manipulating and reaching the data which

00:08:58,850 --> 00:09:04,579
we will cover later as well cabana this

00:09:01,760 --> 00:09:08,269
is that's the interface I use your

00:09:04,579 --> 00:09:10,220
browser to run cabana and that's open

00:09:08,269 --> 00:09:11,959
source data visualization platform which

00:09:10,220 --> 00:09:13,610
allows you to interact with data through

00:09:11,959 --> 00:09:15,560
powerful graphics I'm reading dude this

00:09:13,610 --> 00:09:17,269
is really nice bring the data to life

00:09:15,560 --> 00:09:19,990
with visualization I like that

00:09:17,269 --> 00:09:22,190
definition that's what gabbana is and

00:09:19,990 --> 00:09:25,450
the last edition that's the fourth

00:09:22,190 --> 00:09:27,709
component that's what Alec became bulk

00:09:25,450 --> 00:09:30,430
elastic game a primitive concept of

00:09:27,709 --> 00:09:34,220
beads which are kind of like lightweight

00:09:30,430 --> 00:09:37,070
data shippers so think of it as

00:09:34,220 --> 00:09:38,750
something you can install on your cell

00:09:37,070 --> 00:09:42,740
regarded locks are so maybe you have

00:09:38,750 --> 00:09:46,250
like a few Apache servers so you can

00:09:42,740 --> 00:09:48,620
just put a little a file beat they're

00:09:46,250 --> 00:09:52,010
tailing the Apache log and sending it to

00:09:48,620 --> 00:09:53,899
log stash or you can install I think

00:09:52,010 --> 00:09:56,240
it's called top beat or packet beat

00:09:53,899 --> 00:09:58,480
sniffing packets sending it to log stash

00:09:56,240 --> 00:10:02,089
so these are but like a lock collectors

00:09:58,480 --> 00:10:04,000
designed to be lightweight so that's the

00:10:02,089 --> 00:10:07,790
and there are more and more of them

00:10:04,000 --> 00:10:09,500
getting developed to show you the flow

00:10:07,790 --> 00:10:13,209
in the belk stack so we said that there

00:10:09,500 --> 00:10:15,860
is elastic search when we are storing

00:10:13,209 --> 00:10:18,470
I'm going to store the data the process

00:10:15,860 --> 00:10:22,070
logs Qabbani connects to elasticsearch

00:10:18,470 --> 00:10:23,690
and gives you the visualization do you

00:10:22,070 --> 00:10:28,010
know like to be able to query it

00:10:23,690 --> 00:10:30,740
visualize it analyzed it then you have

00:10:28,010 --> 00:10:34,370
the many data sources that's the input

00:10:30,740 --> 00:10:35,750
you know somehow needs to get get the

00:10:34,370 --> 00:10:37,370
logs from the data source into

00:10:35,750 --> 00:10:39,410
elasticsearch so that's the locks that

00:10:37,370 --> 00:10:43,190
look stitch does that and as you can see

00:10:39,410 --> 00:10:47,000
I one data source might use a beat to

00:10:43,190 --> 00:10:49,339
get data to the log stash and our data

00:10:47,000 --> 00:10:52,880
source maybe uses a different different

00:10:49,339 --> 00:10:54,420
path maybe it's actually running locally

00:10:52,880 --> 00:10:56,459
on the log stash server so

00:10:54,420 --> 00:10:58,709
it's the log stash might use just like a

00:10:56,459 --> 00:11:02,940
file input there is no need for any

00:10:58,709 --> 00:11:05,070
transmission and maybe as I said the new

00:11:02,940 --> 00:11:06,360
beats kind of support because they are

00:11:05,070 --> 00:11:08,430
lightweight they might do some kind of

00:11:06,360 --> 00:11:10,560
pre-processing as well and maybe they

00:11:08,430 --> 00:11:11,910
are capable of sending the logs straight

00:11:10,560 --> 00:11:15,449
to the elastic search because there is

00:11:11,910 --> 00:11:17,160
no processing needed anymore you have

00:11:15,449 --> 00:11:20,310
done the little of processing you need

00:11:17,160 --> 00:11:22,769
on the source side and then you can just

00:11:20,310 --> 00:11:25,740
store it straight away no need to go

00:11:22,769 --> 00:11:29,850
through the whole pipeline this is just

00:11:25,740 --> 00:11:35,250
to show you the input output and filter

00:11:29,850 --> 00:11:36,839
plug-in which logstash consists of so

00:11:35,250 --> 00:11:40,110
before I show you how to run that I

00:11:36,839 --> 00:11:41,699
would like to say a few words about dr.

00:11:40,110 --> 00:11:43,470
I don't think I have to introduce it too

00:11:41,699 --> 00:11:46,230
much because this has been such a

00:11:43,470 --> 00:11:49,889
popular tool over last at least one but

00:11:46,230 --> 00:11:51,870
maybe two years when like basically

00:11:49,889 --> 00:11:55,889
developers these days run dr. on their

00:11:51,870 --> 00:11:59,399
machines just to be able to run stacks

00:11:55,889 --> 00:12:02,399
very quickly I noticed enterprises even

00:11:59,399 --> 00:12:05,790
like old style like telco enterprises

00:12:02,399 --> 00:12:08,760
had dr. in production these days so it

00:12:05,790 --> 00:12:10,680
was really breaking technology me as I

00:12:08,760 --> 00:12:12,660
said man I saw at these two three years

00:12:10,680 --> 00:12:14,699
ago when it came as a lightweight

00:12:12,660 --> 00:12:16,980
virtualization platform a way of

00:12:14,699 --> 00:12:21,449
virtualizing things but actually that's

00:12:16,980 --> 00:12:23,190
not how the doctor developers salad they

00:12:21,449 --> 00:12:25,380
say that doctor is an open source

00:12:23,190 --> 00:12:28,740
platform for developers and sis admins

00:12:25,380 --> 00:12:30,449
to build and run distributed

00:12:28,740 --> 00:12:32,820
application so they kind of look at it

00:12:30,449 --> 00:12:34,949
as a packaging system you somehow build

00:12:32,820 --> 00:12:37,050
your application inside you create a

00:12:34,949 --> 00:12:39,480
docker image then you can ship it you

00:12:37,050 --> 00:12:41,220
store the image somewhere and then when

00:12:39,480 --> 00:12:43,440
you need to run it and could be on your

00:12:41,220 --> 00:12:45,089
notebook it might be in production might

00:12:43,440 --> 00:12:47,610
be in staging might be on different

00:12:45,089 --> 00:12:49,230
operating system you just get copy of

00:12:47,610 --> 00:12:51,630
that image it's already built it's a

00:12:49,230 --> 00:12:54,769
package and you execute it that's a

00:12:51,630 --> 00:12:57,329
beautiful way of thinking of application

00:12:54,769 --> 00:12:59,910
packaging system which my drive anywhere

00:12:57,329 --> 00:13:01,889
this is a kind of younger definition

00:12:59,910 --> 00:13:04,140
doctor is tool that can package an

00:13:01,889 --> 00:13:04,640
application and its dependencies in a

00:13:04,140 --> 00:13:06,950
virtual

00:13:04,640 --> 00:13:09,260
Tanner that can run on any Linux server

00:13:06,950 --> 00:13:11,630
there is a dependence on linux server

00:13:09,260 --> 00:13:14,180
but you probably know if you run it on

00:13:11,630 --> 00:13:16,010
your laptops that you know that was

00:13:14,180 --> 00:13:19,550
booted to dr. than was a newer version

00:13:16,010 --> 00:13:21,800
when it kind of installs virtual machine

00:13:19,550 --> 00:13:27,170
virtual box for you so you can run it on

00:13:21,800 --> 00:13:30,770
Windows or Mac I think dr. was it last

00:13:27,170 --> 00:13:32,930
month released a beta of what they call

00:13:30,770 --> 00:13:38,180
dr. for mac and dr. for windows and

00:13:32,930 --> 00:13:43,820
they've cut off the need for virtual box

00:13:38,180 --> 00:13:45,950
by using the native hypervisor so under

00:13:43,820 --> 00:13:47,840
make it uses the hypervisor which is

00:13:45,950 --> 00:13:49,850
built in Mac on Windows it uses

00:13:47,840 --> 00:13:53,360
hypervisor switches in windows so there

00:13:49,850 --> 00:13:55,280
is no more it still runs linux kernel on

00:13:53,360 --> 00:13:57,890
that hypervisor but it does not use the

00:13:55,280 --> 00:14:02,390
heavy lift it like over VirtualBox to

00:13:57,890 --> 00:14:06,260
provide it so it's even closer you can

00:14:02,390 --> 00:14:07,970
think of it as a native tool so I want

00:14:06,260 --> 00:14:12,520
to just show you quickly how I run a

00:14:07,970 --> 00:14:19,430
hello world logstash by one line command

00:14:12,520 --> 00:14:22,820
so I'm going to a darker run a log stash

00:14:19,430 --> 00:14:24,740
2.3 image why 2.3 because I know that

00:14:22,820 --> 00:14:26,600
version 5 is going to be released this

00:14:24,740 --> 00:14:28,010
month or next month and if you don't

00:14:26,600 --> 00:14:31,490
specify the number is it tries to

00:14:28,010 --> 00:14:35,120
download the latest so I'm I'm locking

00:14:31,490 --> 00:14:37,640
the number here and i'm configuring that

00:14:35,120 --> 00:14:40,880
it runs logstash program within the

00:14:37,640 --> 00:14:43,580
container and this input and output

00:14:40,880 --> 00:14:45,230
plugin so input plugin will be standard

00:14:43,580 --> 00:14:49,190
input and output will be standard output

00:14:45,230 --> 00:14:52,850
using the rabbit debug codec so let's

00:14:49,190 --> 00:14:59,860
see how that looks like i have a little

00:14:52,850 --> 00:14:59,860
cheat file so my hello world is here

00:15:02,570 --> 00:15:11,780
it's starting so it's one liner if I say

00:15:08,300 --> 00:15:14,780
hello hold that's the standard input

00:15:11,780 --> 00:15:17,180
it's waiting for I'm getting the same

00:15:14,780 --> 00:15:19,910
thing back but it's structured you can

00:15:17,180 --> 00:15:22,130
see I got like a Jason the message is

00:15:19,910 --> 00:15:24,740
hello world it added a version it

00:15:22,130 --> 00:15:26,240
timestamp it added the host name of the

00:15:24,740 --> 00:15:27,680
server it was process that's actually

00:15:26,240 --> 00:15:30,260
the name of the docker container is

00:15:27,680 --> 00:15:33,500
running right now so you see this is

00:15:30,260 --> 00:15:35,390
just reading standard input processing

00:15:33,500 --> 00:15:38,300
it so that was my hello world

00:15:35,390 --> 00:15:40,700
application so I just ran logstash by

00:15:38,300 --> 00:15:42,410
running one command what I need to do I

00:15:40,700 --> 00:15:44,210
just need to have dr. in my machine I

00:15:42,410 --> 00:15:50,870
just showed you how to run a low world

00:15:44,210 --> 00:15:52,490
in in poker logstash so I kill that

00:15:50,870 --> 00:15:56,990
container so I have no containers

00:15:52,490 --> 00:16:01,340
running our container is stopped sorry

00:15:56,990 --> 00:16:05,000
so there's nothing and we can go and do

00:16:01,340 --> 00:16:07,550
the same test but this time we also add

00:16:05,000 --> 00:16:10,130
our filter plugin so we had standard

00:16:07,550 --> 00:16:14,510
input before and standard output but now

00:16:10,130 --> 00:16:17,660
we are also define a filter using the

00:16:14,510 --> 00:16:20,120
groc plug in and saying try to match the

00:16:17,660 --> 00:16:22,670
message you are getting in using the

00:16:20,120 --> 00:16:24,680
combine apache lock pattern you can see

00:16:22,670 --> 00:16:28,520
here in the middle so that's a pattern

00:16:24,680 --> 00:16:31,220
it's like regex it's defined and it will

00:16:28,520 --> 00:16:34,040
basically try to parse the line and and

00:16:31,220 --> 00:16:36,260
break it based on the definition of the

00:16:34,040 --> 00:16:39,410
combined Apache lock which is a standard

00:16:36,260 --> 00:16:40,970
and i will pass a patchy line to the

00:16:39,410 --> 00:16:46,130
standard input and let's see what we

00:16:40,970 --> 00:16:49,190
will get just much file again so

00:16:46,130 --> 00:16:52,700
I'm running darker version 2.3 sorry

00:16:49,190 --> 00:16:55,750
logstash 2.3 in darker and i'm

00:16:52,700 --> 00:16:59,210
configuring it from common line

00:16:55,750 --> 00:17:01,990
providing input plugging filter plug in

00:16:59,210 --> 00:17:01,990
and out plug in

00:17:02,550 --> 00:17:05,550
starting

00:17:06,970 --> 00:17:11,199
and now i take this Apache line and

00:17:09,069 --> 00:17:17,010
paste it to standard input we know it

00:17:11,199 --> 00:17:20,020
and it used the combined Apache log

00:17:17,010 --> 00:17:23,199
definition pattern definition and parse

00:17:20,020 --> 00:17:26,829
this line i pasted in on input so you

00:17:23,199 --> 00:17:30,820
can see that this get got here in the

00:17:26,829 --> 00:17:35,650
verb field this 200 goes to response

00:17:30,820 --> 00:17:41,140
field this IP address got here into

00:17:35,650 --> 00:17:45,370
client IP so this is how I ply clock

00:17:41,140 --> 00:17:49,299
stash parsed and apache long time so

00:17:45,370 --> 00:17:52,059
that was just a little play I will stop

00:17:49,299 --> 00:17:56,530
this log stash is no doctor running I

00:17:52,059 --> 00:17:59,440
can go back so let's try to run this

00:17:56,530 --> 00:18:01,450
this is something you can run in

00:17:59,440 --> 00:18:04,179
production it's not how available but it

00:18:01,450 --> 00:18:08,679
can actually do that on your little

00:18:04,179 --> 00:18:10,270
server so as you can see we have three

00:18:08,679 --> 00:18:13,150
components here elasticsearch when the

00:18:10,270 --> 00:18:15,400
data will be stored gabbana this is how

00:18:13,150 --> 00:18:17,380
we will look at the data log stash is

00:18:15,400 --> 00:18:21,250
what will process the data and we need

00:18:17,380 --> 00:18:23,620
some kind of source so i will run three

00:18:21,250 --> 00:18:27,429
containers elasticsearch with this line

00:18:23,620 --> 00:18:30,510
and i will run kabana linking to the

00:18:27,429 --> 00:18:33,970
elastic search and then i will run

00:18:30,510 --> 00:18:36,669
logstash giving giving it a

00:18:33,970 --> 00:18:40,240
configuration file in this directory

00:18:36,669 --> 00:18:42,309
unmounting and giving it a Apache log

00:18:40,240 --> 00:18:45,549
file which I download it downloaded from

00:18:42,309 --> 00:18:48,000
a production server last line i'll show

00:18:45,549 --> 00:18:48,000
you what it is

00:18:49,540 --> 00:18:59,960
so let's start elasticsearch and once

00:18:57,530 --> 00:19:02,950
again if you have dr. installed and you

00:18:59,960 --> 00:19:05,750
execute this command you are running

00:19:02,950 --> 00:19:09,740
elasticsearch right now this is how easy

00:19:05,750 --> 00:19:13,309
it is to use docker so Alice texture is

00:19:09,740 --> 00:19:17,690
running you can see the it's registered

00:19:13,309 --> 00:19:22,340
here now I start gabbana saying run

00:19:17,690 --> 00:19:24,590
Qabbani 4.5 exposed port 5601 which is

00:19:22,340 --> 00:19:27,710
standard port given a license to so

00:19:24,590 --> 00:19:30,160
instead of one of this five six or five

00:19:27,710 --> 00:19:33,559
six I want to be available on all my

00:19:30,160 --> 00:19:36,470
interfaces on my local machine link it

00:19:33,559 --> 00:19:40,070
to the elastic search and name it ik

00:19:36,470 --> 00:19:44,929
bond so I started I'm running

00:19:40,070 --> 00:19:50,770
elasticsearch & Gabbana so if this works

00:19:44,929 --> 00:19:54,770
I should be able to go to localhost 5601

00:19:50,770 --> 00:19:56,690
it's loading cabana and it's asking you

00:19:54,770 --> 00:19:59,650
to configure index and it's telling me

00:19:56,690 --> 00:20:02,750
that there is unable to fetch mapping

00:19:59,650 --> 00:20:04,670
well that's because holistic 30 is empty

00:20:02,750 --> 00:20:07,190
it's expected try it so let's let's give

00:20:04,670 --> 00:20:13,040
it some data so the last thing we need

00:20:07,190 --> 00:20:14,390
to run is the log stash and i will show

00:20:13,040 --> 00:20:16,490
you what I'm giving it so I have a lock

00:20:14,390 --> 00:20:18,890
stage directory just the time not

00:20:16,490 --> 00:20:22,460
cheating you see that i have one config

00:20:18,890 --> 00:20:24,260
file and one apache access so this will

00:20:22,460 --> 00:20:29,570
i will pass this as a convict and I will

00:20:24,260 --> 00:20:31,220
pass this in as as locked file let's

00:20:29,570 --> 00:20:36,520
just have a look at the load file so it

00:20:31,220 --> 00:20:36,520
has 34 thousand lines

00:20:37,940 --> 00:20:44,659
and you can see its upper to log and

00:20:40,760 --> 00:20:44,659
let's look at a config

00:20:48,519 --> 00:20:54,580
I will cover that but as you say there

00:20:51,849 --> 00:20:56,799
is input file that will be a patchy we

00:20:54,580 --> 00:20:58,659
are passing in we will be using grog

00:20:56,799 --> 00:21:01,019
filter for combined Apache look again

00:20:58,659 --> 00:21:04,739
and we will write this to elasticsearch

00:21:01,019 --> 00:21:04,739
so that's exactly that

00:21:12,240 --> 00:21:18,480
and starting these who are closer to me

00:21:16,110 --> 00:21:21,960
can probably hear my fan just started

00:21:18,480 --> 00:21:26,850
spinning that's because it's processing

00:21:21,960 --> 00:21:31,970
these thirty thousand lines should take

00:21:26,850 --> 00:21:34,500
only a few seconds so now when I go back

00:21:31,970 --> 00:21:37,980
I'm running three docker containers

00:21:34,500 --> 00:21:40,440
plastic surg gabbana I'm looking at and

00:21:37,980 --> 00:21:42,480
the log stash which just processed the

00:21:40,440 --> 00:21:47,850
log file and stored it in elasticsearch

00:21:42,480 --> 00:21:50,280
so if i refresh this page it should see

00:21:47,850 --> 00:21:52,380
some data so I'm saying hey I can see

00:21:50,280 --> 00:21:56,850
time stem field should i use it as index

00:21:52,380 --> 00:22:00,390
nokia please so now it analyzed data and

00:21:56,850 --> 00:22:02,520
found this data inside the log file like

00:22:00,390 --> 00:22:08,370
these fields inside the log file so we

00:22:02,520 --> 00:22:10,440
can look at it oh there is no data why

00:22:08,370 --> 00:22:12,390
is that well because this is last 15

00:22:10,440 --> 00:22:14,900
minute in the right top corner that's

00:22:12,390 --> 00:22:17,820
the default in log stash it actually

00:22:14,900 --> 00:22:19,920
hurt me at least twice when I phone

00:22:17,820 --> 00:22:22,110
something's broken and like just don't

00:22:19,920 --> 00:22:24,300
have any data for last 15 mins this file

00:22:22,110 --> 00:22:28,670
is from the last night so I need to go

00:22:24,300 --> 00:22:28,670
back and say show me maybe past 24 hours

00:22:29,870 --> 00:22:36,960
and you see I'm getting something here

00:22:31,980 --> 00:22:39,360
and these are hope these are Apache

00:22:36,960 --> 00:22:40,920
lines but a little bit enriched as I

00:22:39,360 --> 00:22:44,460
said it's not you know like because you

00:22:40,920 --> 00:22:46,440
can see I have geoip Czech Republic I

00:22:44,460 --> 00:22:48,330
took it from a check server because I'm

00:22:46,440 --> 00:22:54,030
not afraid of the customer being angry

00:22:48,330 --> 00:22:59,300
at me it's a it's a Drupal bishop I

00:22:54,030 --> 00:23:02,240
built years back so I know I can do this

00:22:59,300 --> 00:23:05,940
so we've got enriched by geoip fields

00:23:02,240 --> 00:23:13,610
but it's still the Apache log you know

00:23:05,940 --> 00:23:17,540
the agent the client IP the HTTP version

00:23:13,610 --> 00:23:19,309
request and server response so usually

00:23:17,540 --> 00:23:24,280
Cabana looks like this unfortunately

00:23:19,309 --> 00:23:27,590
this resolution is very low so if I go

00:23:24,280 --> 00:23:29,570
you usually see this field on the left

00:23:27,590 --> 00:23:31,190
and you can kind of filter through that

00:23:29,570 --> 00:23:34,820
so you can see if I generally just a

00:23:31,190 --> 00:23:37,100
gent so now I'm I'm just highlighting

00:23:34,820 --> 00:23:42,049
age and or you can see I don't want to

00:23:37,100 --> 00:23:43,700
see agent I want to see a client IP so

00:23:42,049 --> 00:23:49,130
that's each line but I highlighting you

00:23:43,700 --> 00:23:50,990
did a client IP and HTTP version for a

00:23:49,130 --> 00:23:52,790
couple so this is how we can do your

00:23:50,990 --> 00:23:55,850
data so but let's go and do a little bit

00:23:52,790 --> 00:23:57,710
of a investigation so we were talking

00:23:55,850 --> 00:24:00,230
about response code so let's let's

00:23:57,710 --> 00:24:04,070
create a few visualization so let's

00:24:00,230 --> 00:24:08,510
start with the most ketchup on so we

00:24:04,070 --> 00:24:13,250
create a new visualization from Henry

00:24:08,510 --> 00:24:16,700
tell it to use terms which terms well

00:24:13,250 --> 00:24:24,120
let's let's use the response codes so if

00:24:16,700 --> 00:24:30,880
I can see it here field and use

00:24:24,120 --> 00:24:32,560
respawns row so I'm looking at last 24

00:24:30,880 --> 00:24:37,270
hours of locks and this was my

00:24:32,560 --> 00:24:44,310
distribution of status codes so i will

00:24:37,270 --> 00:24:50,620
save this quality Rollag so this is PI

00:24:44,310 --> 00:24:54,070
response I create a little bit graph

00:24:50,620 --> 00:24:55,990
which is more despair with me I need to

00:24:54,070 --> 00:24:58,060
create for to show three to show you

00:24:55,990 --> 00:25:03,790
something so I'll create this vertical

00:24:58,060 --> 00:25:10,540
bar chart it's a good one to go so it

00:25:03,790 --> 00:25:12,600
will be no sorry start again when you

00:25:10,540 --> 00:25:20,700
search

00:25:12,600 --> 00:25:24,830
and it will be date Instagram and split

00:25:20,700 --> 00:25:31,590
bars and head the terms and use the

00:25:24,830 --> 00:25:35,070
field response oh the same thing but

00:25:31,590 --> 00:25:44,220
shows us as it was so i will save that

00:25:35,070 --> 00:25:47,340
as well and this one is called maybe and

00:25:44,220 --> 00:25:55,770
the last one geoip that's always very

00:25:47,340 --> 00:25:57,300
funny very good topic and it geo

00:25:55,770 --> 00:26:01,310
coordinates it will automatically or

00:25:57,300 --> 00:26:04,800
from geoip location and you can see

00:26:01,310 --> 00:26:07,640
where i'm getting most traffic thrown so

00:26:04,800 --> 00:26:07,640
i will save that one as well

00:26:13,710 --> 00:26:18,120
okay that's good and let I want to show

00:26:17,010 --> 00:26:20,309
you something that's really cool now

00:26:18,120 --> 00:26:22,020
when I have like three safe I have safe

00:26:20,309 --> 00:26:25,830
visualization I can create a dashboard

00:26:22,020 --> 00:26:29,429
so I go to dashboard and I say okay so i

00:26:25,830 --> 00:26:32,130
have this pie responds with power

00:26:29,429 --> 00:26:33,990
responds and I know geoip and I put them

00:26:32,130 --> 00:26:37,320
somehow it's really difficult on this

00:26:33,990 --> 00:26:41,970
resolution but I'm trying my best so I

00:26:37,320 --> 00:26:44,659
will resize them to see them hopefully

00:26:41,970 --> 00:26:44,659
at the same time

00:26:50,720 --> 00:26:53,620
and two

00:26:58,419 --> 00:27:06,260
challenging but I will good so and now I

00:27:03,200 --> 00:27:11,270
can do things like oh maybe I wanna look

00:27:06,260 --> 00:27:16,280
for the last seven days instead and then

00:27:11,270 --> 00:27:18,559
when i go and zoom in you see that all

00:27:16,280 --> 00:27:26,350
the visualization are changing at the

00:27:18,559 --> 00:27:26,350
same time so if i if i click on 200 here

00:27:26,650 --> 00:27:36,049
and i can reverse the 200 so i invert it

00:27:32,510 --> 00:27:39,470
so this is everything but 200 the five

00:27:36,049 --> 00:27:42,710
most frequently seen response codes I

00:27:39,470 --> 00:27:44,660
can pin that and I can star

00:27:42,710 --> 00:27:47,780
investigation and I can maybe zoom in as

00:27:44,660 --> 00:27:50,390
you see I'm zooming in it's changing all

00:27:47,780 --> 00:27:52,610
the graphs the geoip is changing so I

00:27:50,390 --> 00:27:53,990
have like awesome correlation without

00:27:52,610 --> 00:27:55,309
actually just playing with the data I

00:27:53,990 --> 00:27:59,179
haven't saved anything I'm just clearing

00:27:55,309 --> 00:28:02,480
elastic search by a cabana just like go

00:27:59,179 --> 00:28:06,440
back so I don't get lost laws let's have

00:28:02,480 --> 00:28:10,429
a look at the last 24 hours and maybe

00:28:06,440 --> 00:28:13,429
try to I have a few minutes left maybe

00:28:10,429 --> 00:28:16,130
try to so when i'm looking at the

00:28:13,429 --> 00:28:18,679
visualization here and I paint this

00:28:16,130 --> 00:28:20,990
response code not being 200 I can go to

00:28:18,679 --> 00:28:24,200
discover and I'm looking at the lines

00:28:20,990 --> 00:28:26,690
which are what i can see in the crops so

00:28:24,200 --> 00:28:28,940
i can i can go and go it's a bit more

00:28:26,690 --> 00:28:31,490
but hey we were sink so what's actually

00:28:28,940 --> 00:28:33,260
interesting here it's like theres 404 a

00:28:31,490 --> 00:28:36,580
lot maybe you have a look what's what's

00:28:33,260 --> 00:28:40,640
actually causing it also I can lock 404

00:28:36,580 --> 00:28:43,190
and it's going mostly from one IP

00:28:40,640 --> 00:28:49,570
address like hey mom like how about I I

00:28:43,190 --> 00:28:49,570
look at this I pin it as well

00:28:55,000 --> 00:29:00,360
and

00:28:56,760 --> 00:29:04,890
here I maybe want to see the client IP

00:29:00,360 --> 00:29:09,680
but the agent I realized that all of

00:29:04,890 --> 00:29:17,120
these are crawl requests by doing this

00:29:09,680 --> 00:29:17,120
and I can see that it's actually me

00:29:17,840 --> 00:29:23,310
preparing for previous I presented the

00:29:20,730 --> 00:29:25,590
short version of this at a different

00:29:23,310 --> 00:29:28,050
meet up at a meet up and I was just

00:29:25,590 --> 00:29:29,610
trying to find some other create some

00:29:28,050 --> 00:29:31,650
anomalies in the log so this for all

00:29:29,610 --> 00:29:34,160
four were caused by me but you can see I

00:29:31,650 --> 00:29:36,090
just noticed just by going through crabs

00:29:34,160 --> 00:29:41,490
so I don't want to waste too much time

00:29:36,090 --> 00:29:44,310
here because time's flying so it was so

00:29:41,490 --> 00:29:46,800
what we have just seen so we had log

00:29:44,310 --> 00:29:52,320
stash breeding input lines from an

00:29:46,800 --> 00:29:53,700
Apache look 33,000 we used the refill

00:29:52,320 --> 00:29:55,740
turret using the combine a bachelor

00:29:53,700 --> 00:29:59,040
pattern we store it in elastic search

00:29:55,740 --> 00:30:00,660
and then we use cabana to basically go

00:29:59,040 --> 00:30:03,210
through the data located and trying to

00:30:00,660 --> 00:30:04,830
look we could see use geoip as well I

00:30:03,210 --> 00:30:06,960
could spend an hour here I have to admit

00:30:04,830 --> 00:30:09,630
I'm not a cabana expert i'm interested

00:30:06,960 --> 00:30:11,160
in getting the data in storing and

00:30:09,630 --> 00:30:13,410
reaching them and then somebody else a

00:30:11,160 --> 00:30:15,990
developer can go and you know like go

00:30:13,410 --> 00:30:18,450
crazy i'm not that gifted in nevada but

00:30:15,990 --> 00:30:22,920
i'm just trying to show you how it can

00:30:18,450 --> 00:30:24,690
help you as a developer and i used

00:30:22,920 --> 00:30:26,310
basically as you could see I didn't my

00:30:24,690 --> 00:30:29,490
config file wasn't a bit I just like

00:30:26,310 --> 00:30:32,340
said like hey use a source access log

00:30:29,490 --> 00:30:33,870
you know start from beginning why do

00:30:32,340 --> 00:30:36,540
need to start from beginning because

00:30:33,870 --> 00:30:38,460
lockstitch just reads from the point it

00:30:36,540 --> 00:30:39,750
started so if there is an old father

00:30:38,460 --> 00:30:42,180
wouldn't touch it so you actually have

00:30:39,750 --> 00:30:43,200
to force it to reread it from the

00:30:42,180 --> 00:30:45,030
beginning because it was from yesterday

00:30:43,200 --> 00:30:47,610
otherwise it'd be waiting for the file

00:30:45,030 --> 00:30:50,850
to to get new lines and only these will

00:30:47,610 --> 00:30:56,460
will get processed store the output in

00:30:50,850 --> 00:30:59,160
elasticsearch and the filter like so if

00:30:56,460 --> 00:31:02,610
type is Apache and we sorry and we set

00:30:59,160 --> 00:31:04,080
the type here in this reading this file

00:31:02,610 --> 00:31:06,330
we said the type is a patch is just like

00:31:04,080 --> 00:31:08,640
a Mikey or types Apache I set up

00:31:06,330 --> 00:31:10,919
keyboard to type is Apache so if type is

00:31:08,640 --> 00:31:16,019
Apache use this Grug pattern and match

00:31:10,919 --> 00:31:18,750
it for a combined Apache log and that

00:31:16,019 --> 00:31:21,120
was the croc plugin filter filter plugin

00:31:18,750 --> 00:31:23,190
also apply geoip on the client IP

00:31:21,120 --> 00:31:25,679
declined IP I get client IP from the

00:31:23,190 --> 00:31:27,990
previous grok match from the combine

00:31:25,679 --> 00:31:31,769
Apache log client IP is one of its field

00:31:27,990 --> 00:31:34,679
so then i applied geoip plugin it gave

00:31:31,769 --> 00:31:36,510
me the so i can show you the map too

00:31:34,679 --> 00:31:39,360
happy map and also do something with

00:31:36,510 --> 00:31:42,659
date like because if I did not tell

00:31:39,360 --> 00:31:44,669
logstash what to do with the date every

00:31:42,659 --> 00:31:47,880
single log in log stash would have the

00:31:44,669 --> 00:31:51,179
timestamp of the time it was processed

00:31:47,880 --> 00:31:53,190
by log stash so if i'm importing 30,000

00:31:51,179 --> 00:31:55,409
log lines they would have time stamp now

00:31:53,190 --> 00:31:58,380
so that's what i'm saying hey actually

00:31:55,409 --> 00:32:01,590
there is a time stamp filled with this

00:31:58,380 --> 00:32:07,470
regular pattern on or debt for the date

00:32:01,590 --> 00:32:10,769
of the event so log stash comes with a

00:32:07,470 --> 00:32:12,779
lot of patterns we used combine apache

00:32:10,769 --> 00:32:16,010
olivares also like username as you can

00:32:12,779 --> 00:32:19,740
see letters and numbers positive integer

00:32:16,010 --> 00:32:21,559
syslog so it's and this is how combined

00:32:19,740 --> 00:32:25,380
apache lock looks like so it's always

00:32:21,559 --> 00:32:28,200
IPO its type IP host storage as client

00:32:25,380 --> 00:32:34,769
client IP pattern user story this tight

00:32:28,200 --> 00:32:36,409
end pattern nap number stories as HTTP

00:32:34,769 --> 00:32:42,210
version so it's a regular expression

00:32:36,409 --> 00:32:46,559
definition of of the so here is actually

00:32:42,210 --> 00:32:49,710
example of apache log so this first IP

00:32:46,559 --> 00:32:52,889
address will get stored in client IP if

00:32:49,710 --> 00:32:56,070
the match is successful of course so

00:32:52,889 --> 00:32:59,880
there are we i described the components

00:32:56,070 --> 00:33:01,860
the bulk stack uses i have run a local

00:32:59,880 --> 00:33:05,820
instance of the stack by running three

00:33:01,860 --> 00:33:08,880
commands we processed and stored

00:33:05,820 --> 00:33:11,850
analyzed reprocessed stored and analyzed

00:33:08,880 --> 00:33:14,630
the apache lock and found an awkward for

00:33:11,850 --> 00:33:17,360
for all four just by using component

00:33:14,630 --> 00:33:18,950
that and i hope that eat at you each of

00:33:17,360 --> 00:33:22,910
you could do the same you don't need to

00:33:18,950 --> 00:33:24,710
do much to start before i jump to the

00:33:22,910 --> 00:33:26,630
last part of the presentation i would

00:33:24,710 --> 00:33:28,250
like to go if you have your tablet or

00:33:26,630 --> 00:33:30,350
phone can you please go to this address

00:33:28,250 --> 00:33:33,530
and pick your poison it's just a little

00:33:30,350 --> 00:33:36,680
little live demo let's see whether this

00:33:33,530 --> 00:33:39,290
will fail or not I will go there as well

00:33:36,680 --> 00:33:48,970
just to prove that's not nothing to be

00:33:39,290 --> 00:33:51,650
ashamed of bulk dot hyphen showcase.com

00:33:48,970 --> 00:33:57,440
just that I didn't have any better

00:33:51,650 --> 00:34:01,990
remain neutral domain to to use so if i

00:33:57,440 --> 00:34:01,990
go to bulk sides of the case to come

00:34:05,260 --> 00:34:14,790
it's a little Drupal 8 side i put

00:34:07,630 --> 00:34:18,399
together runs on ugly up in sydney and

00:34:14,790 --> 00:34:21,790
beings a system in thus if you can pick

00:34:18,399 --> 00:34:28,889
one of the poison for me which talks to

00:34:21,790 --> 00:34:28,889
you so i'll pick pencil

00:34:32,820 --> 00:34:37,850
okay so let's go back to the

00:34:35,040 --> 00:34:40,230
presentation I hope I got a few clicks

00:34:37,850 --> 00:34:41,790
it's just to mention central logging I

00:34:40,230 --> 00:34:43,830
thought I was done with my presentation

00:34:41,790 --> 00:34:45,510
then I reread my description and say oh

00:34:43,830 --> 00:34:50,730
there is one more paragraph I have to

00:34:45,510 --> 00:34:52,380
cover so like I did that centralized

00:34:50,730 --> 00:34:54,990
logging why do you need centralized

00:34:52,380 --> 00:34:56,640
login I tried to demonstrate it by the

00:34:54,990 --> 00:34:59,280
example in the beginning it's basically

00:34:56,640 --> 00:35:04,200
to get logs to one space so you can one

00:34:59,280 --> 00:35:06,450
place so you can you can analyze it you

00:35:04,200 --> 00:35:09,090
can do whatever you want you can it just

00:35:06,450 --> 00:35:11,010
it's convenient I put sick here in the

00:35:09,090 --> 00:35:13,590
brackets here because it has security

00:35:11,010 --> 00:35:15,410
implications of course if you have all

00:35:13,590 --> 00:35:18,360
your applications and production servers

00:35:15,410 --> 00:35:21,150
pumping locks to one central place and

00:35:18,360 --> 00:35:23,100
somebody compromises that server you

00:35:21,150 --> 00:35:25,170
know like they have perfectly very good

00:35:23,100 --> 00:35:29,580
view of your infrastructure and it's

00:35:25,170 --> 00:35:31,320
like a security security risk bridge so

00:35:29,580 --> 00:35:33,590
be careful if you do something like that

00:35:31,320 --> 00:35:36,480
to think about security definitely first

00:35:33,590 --> 00:35:38,790
it is not a new thing I remember rsyslog

00:35:36,480 --> 00:35:41,730
reading like trying to configure our

00:35:38,790 --> 00:35:45,150
syslog to stream sis logs from several

00:35:41,730 --> 00:35:47,130
servers to one central syslog server at

00:35:45,150 --> 00:35:49,080
least 15 years ago so i'm pretty sure

00:35:47,130 --> 00:35:52,560
that already 15 years ago syslog could

00:35:49,080 --> 00:35:55,770
strain remotely by a TCP or UDP beauty p

00:35:52,560 --> 00:35:57,090
prefers probability CP maybe after the

00:35:55,770 --> 00:35:58,800
most of us you have the more you need

00:35:57,090 --> 00:36:00,660
this you know like if you run cluster

00:35:58,800 --> 00:36:02,550
with you know like one web server ven y

00:36:00,660 --> 00:36:04,770
scale that's probably all right to jump

00:36:02,550 --> 00:36:08,250
and and see on the common level setting

00:36:04,770 --> 00:36:11,070
on but if you have it high available you

00:36:08,250 --> 00:36:16,050
need it you might also need to archive

00:36:11,070 --> 00:36:18,390
that for audits and if you have auto

00:36:16,050 --> 00:36:20,460
scaling environment say these days you

00:36:18,390 --> 00:36:24,000
we have like a load balancer with auto

00:36:20,460 --> 00:36:25,980
scaled auto scale the farm of web

00:36:24,000 --> 00:36:29,010
servers to be ready for your commercial

00:36:25,980 --> 00:36:31,440
running in the TV tomorrow when a lot of

00:36:29,010 --> 00:36:32,850
customers hate your side you

00:36:31,440 --> 00:36:35,490
automatically provision more servers

00:36:32,850 --> 00:36:37,800
then this is called peak is gone you

00:36:35,490 --> 00:36:39,570
destroy them and the day after there is

00:36:37,800 --> 00:36:42,330
no server to download your logs from so

00:36:39,570 --> 00:36:44,620
you actually have to stream them to the

00:36:42,330 --> 00:36:46,800
locks or if you want to have any visit

00:36:44,620 --> 00:36:49,540
lately what was happening yesterday

00:36:46,800 --> 00:36:52,780
there are many options Greylock has been

00:36:49,540 --> 00:36:54,370
around for a while elastic stag alch has

00:36:52,780 --> 00:36:57,850
been popular for last two years Splunk

00:36:54,370 --> 00:37:02,470
is a commercial version that was that

00:36:57,850 --> 00:37:04,480
they had a lot of popularity 65 years

00:37:02,470 --> 00:37:07,620
ago I remember working for a telco

00:37:04,480 --> 00:37:12,640
company expensive but very very good and

00:37:07,620 --> 00:37:15,100
elastic elastic kind of tried to do

00:37:12,640 --> 00:37:19,150
something similar in open-source pay and

00:37:15,100 --> 00:37:21,070
she proved a there are many hosted

00:37:19,150 --> 00:37:23,440
solutions like dialogue is very popular

00:37:21,070 --> 00:37:25,060
like many companies these days m1 or to

00:37:23,440 --> 00:37:26,950
see said means they cannot you know hire

00:37:25,060 --> 00:37:29,890
somebody full time to develop them a

00:37:26,950 --> 00:37:32,830
centralized clock solution you can just

00:37:29,890 --> 00:37:35,530
open up an account with any of this you

00:37:32,830 --> 00:37:37,180
trust it's always like a whom do you

00:37:35,530 --> 00:37:39,370
trust like do you are you comfortable

00:37:37,180 --> 00:37:41,860
with your logs being with a third-party

00:37:39,370 --> 00:37:44,770
data log very popular lovely new relic

00:37:41,860 --> 00:37:47,560
we probably know it similar chiq splunk

00:37:44,770 --> 00:37:52,840
and elastic cloud offers some kind of

00:37:47,560 --> 00:37:54,520
hosting a hosted solution as well my

00:37:52,840 --> 00:37:58,690
choice is this one we have seen it

00:37:54,520 --> 00:38:02,440
before I would actually this is just a

00:37:58,690 --> 00:38:04,270
little detour but doing this I would

00:38:02,440 --> 00:38:06,640
make it high available because here as

00:38:04,270 --> 00:38:09,250
you can see you are getting all your

00:38:06,640 --> 00:38:11,320
locks into one log stash instance what

00:38:09,250 --> 00:38:13,030
if there is a lot of processing being

00:38:11,320 --> 00:38:15,390
done you know like your CPU is running

00:38:13,030 --> 00:38:18,280
one at one hundred percent you cannot

00:38:15,390 --> 00:38:21,220
cope with traffic you start losing your

00:38:18,280 --> 00:38:24,340
data so you need to kind of split it in

00:38:21,220 --> 00:38:27,190
two I need to use a message queue so I

00:38:24,340 --> 00:38:30,160
would just use a load balancer and put

00:38:27,190 --> 00:38:32,530
at least two log stash behind it logged

00:38:30,160 --> 00:38:34,180
will answer and this log stash i call

00:38:32,530 --> 00:38:35,920
them shippers I think it's official

00:38:34,180 --> 00:38:37,420
terminology they are shippers because

00:38:35,920 --> 00:38:41,470
they don't really process anything they

00:38:37,420 --> 00:38:44,050
are just there to to store the data in a

00:38:41,470 --> 00:38:46,300
message queue if you remember that log

00:38:44,050 --> 00:38:48,280
stash picture in the beginning like take

00:38:46,300 --> 00:38:49,500
data from one side storage summer so

00:38:48,280 --> 00:38:54,190
this is what it's doing it's just

00:38:49,500 --> 00:38:56,420
receiving the your locks whatever

00:38:54,190 --> 00:39:00,410
channel you want us

00:38:56,420 --> 00:39:03,440
get it into and outputs it to message

00:39:00,410 --> 00:39:04,730
queue maybe it's amazon sks because you

00:39:03,440 --> 00:39:07,070
don't know how to do that yourself how

00:39:04,730 --> 00:39:08,990
do you store your locks you know like so

00:39:07,070 --> 00:39:11,360
that's a beauty but this life locks the

00:39:08,990 --> 00:39:14,960
shipper is very lightweight it's just

00:39:11,360 --> 00:39:17,720
there to you might need like really not

00:39:14,960 --> 00:39:20,690
beef instance very slow cpu just just

00:39:17,720 --> 00:39:22,790
just to put in queue and i have to so if

00:39:20,690 --> 00:39:24,140
i'm creating one of these or i need to

00:39:22,790 --> 00:39:26,810
reboot it because there is a several

00:39:24,140 --> 00:39:28,730
colonel patch you know like i never have

00:39:26,810 --> 00:39:31,520
a downtown so that's why i have to and

00:39:28,730 --> 00:39:35,120
then this is the rest we have seen

00:39:31,520 --> 00:39:38,090
before but this time I have more log

00:39:35,120 --> 00:39:39,980
star servers like pulling the messages

00:39:38,090 --> 00:39:42,770
debating messages from the message queue

00:39:39,980 --> 00:39:45,230
and I keep reading how long the message

00:39:42,770 --> 00:39:47,570
queue is I happened it happened to me

00:39:45,230 --> 00:39:50,590
that I had like two millions of

00:39:47,570 --> 00:39:53,390
unprocessed locks in message queue

00:39:50,590 --> 00:39:56,360
because I didn't have alerted logstash

00:39:53,390 --> 00:39:58,100
being it down so ideally you have the

00:39:56,360 --> 00:39:59,840
message queue being monitored and if it

00:39:58,100 --> 00:40:03,470
becomes too long key provision another

00:39:59,840 --> 00:40:05,420
log stash just to get get get it

00:40:03,470 --> 00:40:07,280
processed and then you can destroy it

00:40:05,420 --> 00:40:11,480
again and if you store it again to

00:40:07,280 --> 00:40:14,320
elasticsearch and you skip annum so i

00:40:11,480 --> 00:40:19,010
just created lasting watching time yeah

00:40:14,320 --> 00:40:24,320
just created one little elk demo this

00:40:19,010 --> 00:40:26,660
time I put it on US House linode it's

00:40:24,320 --> 00:40:29,540
very similar it runs like a few Dockers

00:40:26,660 --> 00:40:33,680
the same way we just run them here on my

00:40:29,540 --> 00:40:39,190
local machine but it actually gets locks

00:40:33,680 --> 00:40:43,490
from few sources it's getting a lamp

00:40:39,190 --> 00:40:47,510
locks from japan-based linode it's

00:40:43,490 --> 00:40:49,420
getting a lamp locks by apizza from

00:40:47,510 --> 00:40:53,990
germany-based linode that's where the

00:40:49,420 --> 00:40:56,870
little shop is hosted book shop from

00:40:53,990 --> 00:40:58,640
Australia AWS instance as well and from

00:40:56,870 --> 00:41:01,130
australia-based aqueous subscriptions

00:40:58,640 --> 00:41:03,730
just like to show you the variety you

00:41:01,130 --> 00:41:07,010
know like I have central lock / solution

00:41:03,730 --> 00:41:09,920
just to play with but I can get box from

00:41:07,010 --> 00:41:11,780
all around the world and by using

00:41:09,920 --> 00:41:14,329
beads which are designed to ship that

00:41:11,780 --> 00:41:16,130
I'd maybe the line is not reliable all

00:41:14,329 --> 00:41:20,329
the time but that's the pizzas about it

00:41:16,130 --> 00:41:22,599
just tries to deliver it i'm going to

00:41:20,329 --> 00:41:26,180
show you so i will just quickly show you

00:41:22,599 --> 00:41:28,849
how triple watched our clocks look like

00:41:26,180 --> 00:41:30,710
in cabana maybe we will look at the

00:41:28,849 --> 00:41:33,890
varnish lock then I have a little teaser

00:41:30,710 --> 00:41:36,849
house you can use several metrics and

00:41:33,890 --> 00:41:41,079
there will be maybe something else so

00:41:36,849 --> 00:41:44,410
let's have a quick look where this works

00:41:41,079 --> 00:41:49,579
this is the local instance we don't want

00:41:44,410 --> 00:41:53,450
so this is my so did I sell the shoes

00:41:49,579 --> 00:41:58,640
first yeah let's look at drupal watchdog

00:41:53,450 --> 00:42:01,490
so i am looking for lock tie and it will

00:41:58,640 --> 00:42:02,990
be here a little bit the fields you use

00:42:01,490 --> 00:42:04,910
often usually end up here at the

00:42:02,990 --> 00:42:07,460
beginning so I'm saying that I want a

00:42:04,910 --> 00:42:09,079
lock type and if you see that it's just

00:42:07,460 --> 00:42:11,180
a quick analysis there is locked at

00:42:09,079 --> 00:42:13,579
varnish look type Apache love the lock

00:42:11,180 --> 00:42:15,200
type and your next look that much smoke

00:42:13,579 --> 00:42:17,930
and I can pin it from here son saying

00:42:15,200 --> 00:42:20,569
click I want to see only lock type boy

00:42:17,930 --> 00:42:22,420
stock and this is what i sent it already

00:42:20,569 --> 00:42:25,220
got filtered so now i'm just looking at

00:42:22,420 --> 00:42:29,200
drupal watchdog messages over the last

00:42:25,220 --> 00:42:32,540
one hour you can see what it looks like

00:42:29,200 --> 00:42:36,109
so this is the message which came in and

00:42:32,540 --> 00:42:39,049
then you got parse the drupal action was

00:42:36,109 --> 00:42:41,930
page not found and drupal request URL

00:42:39,049 --> 00:42:44,450
how's this one drupal message was this

00:42:41,930 --> 00:42:50,319
one so this is applying like a triple

00:42:44,450 --> 00:42:53,059
filter on on total watchdog messages

00:42:50,319 --> 00:42:55,960
then maybe we want to see varnish so i

00:42:53,059 --> 00:42:55,960
remove this

00:42:59,670 --> 00:43:04,200
so I come to lock type is varnished

00:43:17,700 --> 00:43:22,250
varnish looks very similar to Apache I

00:43:23,120 --> 00:43:33,720
can see that this one came from Aria Joe

00:43:30,330 --> 00:43:37,830
IP got applied on that as well and the

00:43:33,720 --> 00:43:41,820
last one there is remind myself what it

00:43:37,830 --> 00:43:46,320
was yeah I have a beat on one server

00:43:41,820 --> 00:43:50,480
which is called top beat and when you

00:43:46,320 --> 00:43:50,480
love a new load top beat into your

00:43:50,960 --> 00:43:55,260
Cabana install top bead on your server

00:43:53,460 --> 00:44:06,720
it gives you this dashboard which I just

00:43:55,260 --> 00:44:12,110
load in second the B dash board and this

00:44:06,720 --> 00:44:15,330
is metrics from one of the web servers

00:44:12,110 --> 00:44:18,380
over the last 15 minutes so I can see

00:44:15,330 --> 00:44:22,880
this time was spent on java mysql PHP

00:44:18,380 --> 00:44:26,070
top bead itself processes cpu usage

00:44:22,880 --> 00:44:28,560
average memory you can have more service

00:44:26,070 --> 00:44:34,530
like that so it gives you some matrix

00:44:28,560 --> 00:44:38,790
very cheaply as well so how did I get

00:44:34,530 --> 00:44:41,190
the locks inside the central lock palak

00:44:38,790 --> 00:44:44,990
instance i just used install file bid

00:44:41,190 --> 00:44:49,350
package its RPM instead i configured it

00:44:44,990 --> 00:44:51,270
just by saying hey stream these paths to

00:44:49,350 --> 00:44:53,850
this locks touch that's how is it is of

00:44:51,270 --> 00:44:56,900
course i would also use TLS certificates

00:44:53,850 --> 00:44:59,880
but this is just to show you how quickly

00:44:56,900 --> 00:45:02,700
it's possible install file beat and

00:44:59,880 --> 00:45:07,500
stream the log from these three files to

00:45:02,700 --> 00:45:11,390
the lockstate server also i showed you

00:45:07,500 --> 00:45:15,810
some Drupal locks the production way of

00:45:11,390 --> 00:45:20,060
storing locks is using the core syslog

00:45:15,810 --> 00:45:23,430
modules pitch basically stores the

00:45:20,060 --> 00:45:26,310
watchdog events on the local server

00:45:23,430 --> 00:45:29,900
syslog facility which you can configure

00:45:26,310 --> 00:45:35,630
like here I did I said hey I create

00:45:29,900 --> 00:45:38,090
config file and said store these events

00:45:35,630 --> 00:45:42,620
into VAR log grip lock so I'm just using

00:45:38,090 --> 00:45:45,320
syslog module friday to antislip rights

00:45:42,620 --> 00:45:47,750
to our dedicated file and then as we

00:45:45,320 --> 00:45:50,870
could see here in the previous slide I'm

00:45:47,750 --> 00:45:53,810
just streaming this route to lock file

00:45:50,870 --> 00:45:56,090
by the file beat so it's a nice way out

00:45:53,810 --> 00:45:58,640
to how to get it to log stash save it

00:45:56,090 --> 00:46:02,690
refers to syslog this looks saves it as

00:45:58,640 --> 00:46:05,450
a file and then and then follow bit

00:46:02,690 --> 00:46:08,060
streams each to send roses look you can

00:46:05,450 --> 00:46:10,190
also use the Drupal DB log input plug in

00:46:08,060 --> 00:46:12,050
is more for development or when you run

00:46:10,190 --> 00:46:13,700
it locally which you actually can see

00:46:12,050 --> 00:46:16,160
how you configure the input you have to

00:46:13,700 --> 00:46:18,110
tell it like this is my database this is

00:46:16,160 --> 00:46:20,480
my credentials and pull it every one

00:46:18,110 --> 00:46:22,820
minute it s only minute it doesn't do it

00:46:20,480 --> 00:46:24,590
faster so it's like pulling every minute

00:46:22,820 --> 00:46:27,940
from straight from the database it's

00:46:24,590 --> 00:46:31,550
another option button for production and

00:46:27,940 --> 00:46:33,980
aquia streams Acquia has this nice if

00:46:31,550 --> 00:46:36,950
you guys have seen Acquia subscriptions

00:46:33,980 --> 00:46:38,870
they have their login done really nice

00:46:36,950 --> 00:46:42,140
you can kind of say I want to watch PHP

00:46:38,870 --> 00:46:45,560
log varnish lock and it keeps streaming

00:46:42,140 --> 00:46:47,570
you they also created a lock stream gem

00:46:45,560 --> 00:46:49,550
which is publicly available if you just

00:46:47,570 --> 00:46:51,170
search for log stream gem we can see

00:46:49,550 --> 00:46:54,050
that it's like in the gen repository I

00:46:51,170 --> 00:46:57,140
don't understand Ruby but I took the gem

00:46:54,050 --> 00:46:58,850
rubbed it in docker container and then I

00:46:57,140 --> 00:47:00,590
start the docker container and you can

00:46:58,850 --> 00:47:04,250
see what it does it just runs the lock

00:47:00,590 --> 00:47:07,550
stream jam towards my aqueous absque

00:47:04,250 --> 00:47:09,500
ription and saves it to a file and then

00:47:07,550 --> 00:47:13,610
again i just a log stash now read from

00:47:09,500 --> 00:47:17,420
this file so I'm actually getting 30

00:47:13,610 --> 00:47:20,500
close to real time data from aquia into

00:47:17,420 --> 00:47:23,030
my log stash I talk to pantheon and

00:47:20,500 --> 00:47:25,040
thoughtful message this morning they

00:47:23,030 --> 00:47:29,810
apparently have some way of exposing

00:47:25,040 --> 00:47:31,760
their looks remotely in the roadmap they

00:47:29,810 --> 00:47:33,980
said you can ssh to the server and get

00:47:31,760 --> 00:47:35,650
it or are seeing it but there is no way

00:47:33,980 --> 00:47:38,470
how to stream it at the moment

00:47:35,650 --> 00:47:42,220
but something they know about and

00:47:38,470 --> 00:47:44,470
working on so the last thing last two

00:47:42,220 --> 00:47:51,820
minutes let's see whether we have got

00:47:44,470 --> 00:47:58,630
anything of your clicks at the Showcase

00:47:51,820 --> 00:48:06,250
so so you can say look for everything

00:47:58,630 --> 00:48:08,710
which is request page for the last 15

00:48:06,250 --> 00:48:10,660
minute looking for everything which is

00:48:08,710 --> 00:48:14,770
solve puppet and little chef in tracker

00:48:10,660 --> 00:48:17,860
so there are some and look at the

00:48:14,770 --> 00:48:21,090
request page and can you see what's

00:48:17,860 --> 00:48:24,430
happening here like a this line is full

00:48:21,090 --> 00:48:26,500
fully qualified a URL and this is just

00:48:24,430 --> 00:48:29,680
the path like just the pup just do what

00:48:26,500 --> 00:48:34,870
happened here like so but let me show

00:48:29,680 --> 00:48:37,450
you log log died so this is varnished

00:48:34,870 --> 00:48:39,670
apache varnish apache ha so that means

00:48:37,450 --> 00:48:41,620
that you know like i haven't put the

00:48:39,670 --> 00:48:43,270
right word not normalized but i didn't

00:48:41,620 --> 00:48:46,210
process the log file in the same way so

00:48:43,270 --> 00:48:48,700
what what's what's request patient

00:48:46,210 --> 00:48:51,070
garnish it actually comes in the lock

00:48:48,700 --> 00:48:54,700
message as a full URL while from apache

00:48:51,070 --> 00:48:57,400
look I have only the path and it's up to

00:48:54,700 --> 00:48:58,840
me to do the processing if I want to

00:48:57,400 --> 00:49:02,080
store it in the same fuel I didn't hear

00:48:58,840 --> 00:49:03,880
but haha knowing that everything which

00:49:02,080 --> 00:49:08,830
hit Apache must have gone through

00:49:03,880 --> 00:49:11,430
varnish I can say and lock type his

00:49:08,830 --> 00:49:11,430
varnish

00:49:16,600 --> 00:49:19,110
and

00:49:19,280 --> 00:49:29,210
the last thing I will create a graph out

00:49:21,740 --> 00:49:32,120
of this I think I have a typo here so

00:49:29,210 --> 00:49:34,190
class with Elijah be slightly yes infra

00:49:32,120 --> 00:49:36,410
code ann sablan seven siblings available

00:49:34,190 --> 00:49:40,820
I haven't set up any script which / do

00:49:36,410 --> 00:49:44,840
this and so let's visualize that so i

00:49:40,820 --> 00:49:50,410
will create a little pie chart from a

00:49:44,840 --> 00:49:50,410
saved search hand

00:49:53,970 --> 00:49:59,090
the term is request to you guys remember

00:49:59,330 --> 00:50:16,910
term and field was I think read my stage

00:50:03,980 --> 00:50:16,910
server string request page yep bum

00:50:17,370 --> 00:50:29,430
ansible 2071 percent sold 15 infra

00:50:25,290 --> 00:50:33,390
structure as a code 11 so I think and

00:50:29,430 --> 00:50:35,940
super has one thank you very much so

00:50:33,390 --> 00:50:38,700
wrapping act I show you how to run the

00:50:35,940 --> 00:50:42,120
Alex stack locally running 3dr commands

00:50:38,700 --> 00:50:44,910
please don't do try come to me I will

00:50:42,120 --> 00:50:48,000
happy to help if you need to help i will

00:50:44,910 --> 00:50:50,700
also a bridle blog post and follow up on

00:50:48,000 --> 00:50:53,460
this we process an Apache log file

00:50:50,700 --> 00:50:57,270
storage I hope it was seized him we

00:50:53,460 --> 00:50:59,400
examine it we visualized it and we

00:50:57,270 --> 00:51:01,440
looked a little central logging solution

00:50:59,400 --> 00:51:03,840
which I put together head hawk but I

00:51:01,440 --> 00:51:06,570
wanted to show you that I can get data

00:51:03,840 --> 00:51:09,120
from four different occasions three

00:51:06,570 --> 00:51:12,060
different server types and still have

00:51:09,120 --> 00:51:13,920
all of their there are some links there

00:51:12,060 --> 00:51:17,970
is a very good book on lock stash from

00:51:13,920 --> 00:51:21,060
James Turnbull there's the URL of the

00:51:17,970 --> 00:51:24,540
blog post i'm going to write docker

00:51:21,060 --> 00:51:27,510
every time we run dr run log stash it

00:51:24,540 --> 00:51:30,420
actually runs the official image so

00:51:27,510 --> 00:51:32,790
these are the project pages of the lock

00:51:30,420 --> 00:51:33,930
socialists fish and Cabana docker images

00:51:32,790 --> 00:51:36,150
you don't need to know it when you run

00:51:33,930 --> 00:51:38,100
docker run Cabana does download it for

00:51:36,150 --> 00:51:40,830
you but it's just good to know was doing

00:51:38,100 --> 00:51:43,410
any question please come and ask me

00:51:40,830 --> 00:51:45,690
maybe we have time and please before you

00:51:43,410 --> 00:51:49,560
leave do rate my if you if you liked my

00:51:45,690 --> 00:51:51,540
presentation please do rate my my talk I

00:51:49,560 --> 00:51:53,690
will be very grateful thank you very

00:51:51,540 --> 00:51:53,690
much

00:51:57,829 --> 00:52:04,740
guys I have some stickers being at the

00:52:01,529 --> 00:52:06,480
meetup I have Beats logstash a coupon if

00:52:04,740 --> 00:52:08,250
you like this stuff I just brought it

00:52:06,480 --> 00:52:11,940
that's not my cup of tea but please

00:52:08,250 --> 00:52:14,690
please have it if you like any question

00:52:11,940 --> 00:52:14,690

YouTube URL: https://www.youtube.com/watch?v=hnLiVUQtpvE


