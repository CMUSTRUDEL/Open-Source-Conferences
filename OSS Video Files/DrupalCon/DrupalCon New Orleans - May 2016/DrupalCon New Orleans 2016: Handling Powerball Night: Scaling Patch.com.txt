Title: DrupalCon New Orleans 2016: Handling Powerball Night: Scaling Patch.com
Publication date: 2016-05-10
Playlist: DrupalCon New Orleans - May 2016
Description: 
	Patch.com had a problem many would like to have after the first Powerball drawing: the Google juice was flowing so fast that standard datacenter links (~2gbps) were saturating. And, because links were maxing out, we couldn't even know just how much more capacity we needed for the next drawing. We had a couple days to prepare -- on a site that requires nearly instant invalidation to keep its content fresh.

There weren't many options we could turn around so quickly, so we talked to CDN providers and investigated other traffic-management options. It wasn't just an issue of getting a solution set up but also configuring, testing, and transitioning over with time to spare. This is the 48-hour story of surviving Google's catapult into the top 100 sites.

In this presentation, we will cover:

Services and configurations you can deploy on short notice for site scaling, including costs and time-to-availability
Running HTTPS at scale (and avoiding man-in-the-middle attacks when communicating with the origin)
Configuring different cache lifetimes along the stack to allow precise invalidation control -- while still handling spikes elegantly
Origin shields: balancing geographic proximity with hitting the cache
How HTTP-standard Surrogate-Control headers manage differing cache lifetimes along the stack
Using Varnish's grace mode (in this case via Fastly) as a Plan B if the origin experiences issues
At each stage, making this all work well with Drupal's own cache invalidation hooks and header system
Captions: 
	00:00:00,000 --> 00:00:07,440
okay welcome to handling power of all

00:00:03,510 --> 00:00:10,920
night with patch and in a way also with

00:00:07,440 --> 00:00:14,219
Pantheon and fastly and tonight we're

00:00:10,920 --> 00:00:15,990
going to be talking about a extreme

00:00:14,219 --> 00:00:17,400
traffic spike that happened four patch

00:00:15,990 --> 00:00:20,550
column which is one of the largest

00:00:17,400 --> 00:00:24,180
Drupal sites in the world and how we

00:00:20,550 --> 00:00:26,789
worked to to build infrastructure over

00:00:24,180 --> 00:00:29,070
the course of a couple days that would

00:00:26,789 --> 00:00:30,949
be able to handle the next spike despite

00:00:29,070 --> 00:00:35,010
not knowing exactly how big it would be

00:00:30,949 --> 00:00:38,370
so today we can introduce the two

00:00:35,010 --> 00:00:40,620
prisoners I'll go ahead and start i am

00:00:38,370 --> 00:00:44,070
david strauss i'm a CTO and co-founder

00:00:40,620 --> 00:00:46,230
at Pantheon we run Drupal infrastructure

00:00:44,070 --> 00:00:50,430
for development testing and deployment

00:00:46,230 --> 00:00:53,760
of projects including patch com and this

00:00:50,430 --> 00:00:55,500
is a Brewster who is the sea the CTO at

00:00:53,760 --> 00:00:57,390
patch would you mind introducing

00:00:55,500 --> 00:01:01,620
yourself sure those microphones work as

00:00:57,390 --> 00:01:04,260
well oh and used those i I'm just this

00:01:01,620 --> 00:01:06,360
is my first drupalcon ever i've been

00:01:04,260 --> 00:01:09,330
working in drupal for about six or eight

00:01:06,360 --> 00:01:11,400
years but under the radar and it may

00:01:09,330 --> 00:01:17,189
well be my last if this talk goes poorly

00:01:11,400 --> 00:01:19,259
but but anyway I'm let me know when you

00:01:17,189 --> 00:01:20,610
want me to just start talking yeah we

00:01:19,259 --> 00:01:23,729
should actually we should just bring you

00:01:20,610 --> 00:01:31,470
up here right to kick things on so I've

00:01:23,729 --> 00:01:34,710
actually paper notes yeah so you don't

00:01:31,470 --> 00:01:35,909
know me and if you do know patch you're

00:01:34,710 --> 00:01:39,180
probably know patch is one of the more

00:01:35,909 --> 00:01:42,240
colossal failures on the internet and I

00:01:39,180 --> 00:01:47,460
want to take one moment to say rumors of

00:01:42,240 --> 00:01:50,850
our death are exaggerated and second of

00:01:47,460 --> 00:01:54,119
all to sort of introduce you to the

00:01:50,850 --> 00:01:57,149
problems of patch which and articulate

00:01:54,119 --> 00:01:59,460
them to sort of create the foundation

00:01:57,149 --> 00:02:01,340
for the story of these four days but

00:01:59,460 --> 00:02:04,680
we're going to we're going to talk about

00:02:01,340 --> 00:02:06,270
I'm under no illusions as to who you

00:02:04,680 --> 00:02:08,700
want to hear from it's this guy over

00:02:06,270 --> 00:02:10,950
here so I to keep my my remarks as quick

00:02:08,700 --> 00:02:13,010
as possible and then hand it back to

00:02:10,950 --> 00:02:17,599
David

00:02:13,010 --> 00:02:19,430
but so patch is a hyperlocal news

00:02:17,599 --> 00:02:24,739
platform serving about a thousand towns

00:02:19,430 --> 00:02:28,280
across the country it was originally

00:02:24,739 --> 00:02:30,349
owned by AOL spun off under shareholder

00:02:28,280 --> 00:02:34,220
pressure in 2014 has been running on its

00:02:30,349 --> 00:02:35,900
own steam since it was moved to very

00:02:34,220 --> 00:02:39,170
quickly move through the architecture

00:02:35,900 --> 00:02:41,720
change it was moved off of aol's

00:02:39,170 --> 00:02:43,400
infrastructure at three hundred thousand

00:02:41,720 --> 00:02:46,310
dollars a month infrastructure spend on

00:02:43,400 --> 00:02:49,340
thirty thousand on AWS partially thanks

00:02:46,310 --> 00:02:51,859
to mac right there yeah who worked on it

00:02:49,340 --> 00:02:55,569
in calgary with the hell global team and

00:02:51,859 --> 00:02:58,069
then we moved it over onto pantheon and

00:02:55,569 --> 00:03:00,799
we walked straight into the hyperlocal

00:02:58,069 --> 00:03:05,590
paradox is what we call it a patch and i

00:03:00,799 --> 00:03:07,670
just have to hit a button so these are

00:03:05,590 --> 00:03:10,000
typical stories you might see on patch

00:03:07,670 --> 00:03:14,359
which illustrate this paradox which is

00:03:10,000 --> 00:03:18,500
the if i were to smell smoke in this

00:03:14,359 --> 00:03:19,970
room right now and i yelled fire right

00:03:18,500 --> 00:03:21,769
that would be extremely valuable

00:03:19,970 --> 00:03:25,310
information to everybody in this room

00:03:21,769 --> 00:03:27,609
right and then probably pretty

00:03:25,310 --> 00:03:30,980
invaluable to people down the hall and

00:03:27,609 --> 00:03:33,079
not too valuable for people down the

00:03:30,980 --> 00:03:36,680
street right and that's the problem with

00:03:33,079 --> 00:03:38,629
patch we have information like this you

00:03:36,680 --> 00:03:40,970
know you were returned a chihuahua to

00:03:38,629 --> 00:03:42,560
their owner that is extremely valuable

00:03:40,970 --> 00:03:46,180
information to that group of people

00:03:42,560 --> 00:03:49,129
right whether the schools are closed in

00:03:46,180 --> 00:03:51,410
ridgefield is irrelevant to the people

00:03:49,129 --> 00:03:55,099
in westbourne but so we have with

00:03:51,410 --> 00:03:58,750
decreasing traffic richfield west board

00:03:55,099 --> 00:04:00,919
60 blue onde estÃ¡ wahwah right we have

00:03:58,750 --> 00:04:02,359
increasing value of our information so

00:04:00,919 --> 00:04:05,720
what that means that we have to do is

00:04:02,359 --> 00:04:08,930
serve an enormous histogram of content

00:04:05,720 --> 00:04:12,590
daily across our network so we serve on

00:04:08,930 --> 00:04:17,120
the order of i think i've been nixed i

00:04:12,590 --> 00:04:18,299
have to define how big we are but i just

00:04:17,120 --> 00:04:21,269
hit the wrong button

00:04:18,299 --> 00:04:24,389
I'm hitting buttons David there that's

00:04:21,269 --> 00:04:26,909
that's today so we're running at 7600

00:04:24,389 --> 00:04:31,110
concurrence but on chart be there about

00:04:26,909 --> 00:04:33,629
200 pages of URLs being served at any

00:04:31,110 --> 00:04:36,030
given moment on patch com it's got an

00:04:33,629 --> 00:04:38,430
enormous footprint that has to serve at

00:04:36,030 --> 00:04:41,129
very high availability and our database

00:04:38,430 --> 00:04:44,400
is big as Matt knows and is David knows

00:04:41,129 --> 00:04:47,819
all too well we have about 15 million

00:04:44,400 --> 00:04:50,550
stories articles nodes in our database

00:04:47,819 --> 00:04:53,610
six million users 44 million images

00:04:50,550 --> 00:04:56,009
something like that that we are keeping

00:04:53,610 --> 00:04:58,469
track of and serving at any given time

00:04:56,009 --> 00:05:00,000
and at very high availability and so we

00:04:58,469 --> 00:05:02,099
built this architecture the sort of what

00:05:00,000 --> 00:05:05,509
Jesse at Pantheon called decapitated

00:05:02,099 --> 00:05:07,440
Drupal architecture which means we have

00:05:05,509 --> 00:05:09,780
Drupal on the front and rupal on the

00:05:07,440 --> 00:05:11,969
back and so the service layer separating

00:05:09,780 --> 00:05:13,319
them but it allows our front-end to do a

00:05:11,969 --> 00:05:15,030
lot of the sort of processing and

00:05:13,319 --> 00:05:17,099
minimally sentient stuff that we needed

00:05:15,030 --> 00:05:18,930
to do while serving stuff that is cached

00:05:17,099 --> 00:05:20,400
in large scale across the varnish

00:05:18,930 --> 00:05:24,120
infrastructure in between the front in

00:05:20,400 --> 00:05:29,729
the back so what this is allowed path to

00:05:24,120 --> 00:05:32,009
do is if I get the right button start

00:05:29,729 --> 00:05:34,349
jumping the fence in certain cases to

00:05:32,009 --> 00:05:36,719
serve stories of national import and

00:05:34,349 --> 00:05:38,370
it's this is not just the only one we've

00:05:36,719 --> 00:05:41,370
do we do really well on election night

00:05:38,370 --> 00:05:44,430
we do all sorts of things I mean last

00:05:41,370 --> 00:05:45,599
two nights ago Listeria shot us to

00:05:44,430 --> 00:05:47,460
thirteen or fourteen thousand

00:05:45,599 --> 00:05:49,770
concurrence we had no idea that was

00:05:47,460 --> 00:05:52,190
coming and we have the hardest-working

00:05:49,770 --> 00:05:54,569
editorial group in show business really

00:05:52,190 --> 00:05:57,360
deploying all these articles across and

00:05:54,569 --> 00:06:03,090
hyper localizing them across our entire

00:05:57,360 --> 00:06:06,719
network of sites but excuse me in

00:06:03,090 --> 00:06:11,279
picking up these national news stories

00:06:06,719 --> 00:06:12,599
that comes with a price which is that

00:06:11,279 --> 00:06:17,699
you start running into scale problems

00:06:12,599 --> 00:06:21,120
pretty quickly and so this is this is

00:06:17,699 --> 00:06:23,129
the thirteenth story but on january

00:06:21,120 --> 00:06:25,440
ninth it was a Saturday night like any

00:06:23,129 --> 00:06:27,750
other saturday night i was sort of

00:06:25,440 --> 00:06:30,000
hanging out having dinner whatever and i

00:06:27,750 --> 00:06:30,780
got a ping from one of our QA people

00:06:30,000 --> 00:06:34,400
saying

00:06:30,780 --> 00:06:36,600
oh by the way we're running a little hot

00:06:34,400 --> 00:06:38,070
and I said why the heck are we running

00:06:36,600 --> 00:06:39,300
hot is what we're running at 10,000

00:06:38,070 --> 00:06:41,630
concurrence on a Saturday night that's

00:06:39,300 --> 00:06:47,100
not that doesn't make any sense to us I

00:06:41,630 --> 00:06:49,860
said okay that's so we are and I watched

00:06:47,100 --> 00:06:53,190
and I watched and suddenly it was 15,000

00:06:49,860 --> 00:06:55,020
and then it was 20,000 and it was 30,000

00:06:53,190 --> 00:06:59,669
it was so real it was going up like mad

00:06:55,020 --> 00:07:02,310
and you know and at 40,000 this is over

00:06:59,669 --> 00:07:04,260
the course of like 15 minutes and you

00:07:02,310 --> 00:07:06,090
know 50,000 concurrence we're all like

00:07:04,260 --> 00:07:11,240
giving each other high-fives you know

00:07:06,090 --> 00:07:14,070
excellent and then batch went dark and

00:07:11,240 --> 00:07:17,370
David was the recipient and I think re

00:07:14,070 --> 00:07:19,130
of one of those arms length bug reports

00:07:17,370 --> 00:07:24,660
from me which no one really likes to get

00:07:19,130 --> 00:07:27,240
but we recovered 20 minutes later that's

00:07:24,660 --> 00:07:32,070
the last surviving screenshot from that

00:07:27,240 --> 00:07:40,380
night so you you may notice that the the

00:07:32,070 --> 00:07:42,000
meter has gone around which was yeah we

00:07:40,380 --> 00:07:43,110
didn't know there were certain points in

00:07:42,000 --> 00:07:44,190
the night actually when chart beats

00:07:43,110 --> 00:07:48,840
going like this and all of a sudden it

00:07:44,190 --> 00:07:50,100
just drops yes thank you shark meat

00:07:48,840 --> 00:07:51,390
would just vanish and then it would come

00:07:50,100 --> 00:07:54,560
back as it didn't know it had to

00:07:51,390 --> 00:07:57,570
reallocate service to us and so we

00:07:54,560 --> 00:08:01,970
started dealing with I didn't know how

00:07:57,570 --> 00:08:04,350
did this was new realm I would like the

00:08:01,970 --> 00:08:07,080
transaction there's 150 milliseconds

00:08:04,350 --> 00:08:10,210
normally and so we're coming out of

00:08:07,080 --> 00:08:12,789
their normal speed we bootstraps in it

00:08:10,210 --> 00:08:14,740
millisecond our servers are fine

00:08:12,789 --> 00:08:18,370
everything's fine except for our crew

00:08:14,740 --> 00:08:19,720
foot goes to nowhere right and so we

00:08:18,370 --> 00:08:24,669
didn't know quite how to interpret this

00:08:19,720 --> 00:08:30,340
I we had our we had two clues okay thank

00:08:24,669 --> 00:08:31,870
you to clue of one was that well and the

00:08:30,340 --> 00:08:33,729
other is that in our infrastructure in

00:08:31,870 --> 00:08:35,740
this decapitated structure we have our

00:08:33,729 --> 00:08:37,300
main service box and it talks to our

00:08:35,740 --> 00:08:40,409
front end to help it clear its own

00:08:37,300 --> 00:08:42,700
varnish cash very programmatically and

00:08:40,409 --> 00:08:44,470
and very granularly because we can't

00:08:42,700 --> 00:08:46,300
just blow the entire cash for

00:08:44,470 --> 00:08:47,680
Connecticut when a new Snicket story

00:08:46,300 --> 00:08:52,060
comes up we have to be very careful

00:08:47,680 --> 00:08:53,950
about where we do it and so so it was

00:08:52,060 --> 00:08:55,720
having no it was having no trouble

00:08:53,950 --> 00:08:57,580
talking to sail through and other

00:08:55,720 --> 00:08:59,740
providers but it couldn't reach the

00:08:57,580 --> 00:09:01,120
front end at all and all the time outs

00:08:59,740 --> 00:09:02,890
were at four hundred ninety nine

00:09:01,120 --> 00:09:05,410
milliseconds which is our time to

00:09:02,890 --> 00:09:07,570
connect so we got some sense that guess

00:09:05,410 --> 00:09:09,670
what we couldn't get to the front end

00:09:07,570 --> 00:09:11,459
you couldn't even get there it wasn't

00:09:09,670 --> 00:09:15,130
that the front end couldn't serve it and

00:09:11,459 --> 00:09:16,720
that was basically the one fact that I

00:09:15,130 --> 00:09:20,620
managed to get into my bug report to

00:09:16,720 --> 00:09:25,540
david the other fact or two was that no

00:09:20,620 --> 00:09:28,839
one won powerball and and it was

00:09:25,540 --> 00:09:31,240
happening to assurity the next wednesday

00:09:28,839 --> 00:09:33,100
or thursday night right so we were

00:09:31,240 --> 00:09:36,399
basically on the clock and i think this

00:09:33,100 --> 00:09:38,290
is probably where I end and the person

00:09:36,399 --> 00:09:41,880
you want to hear starts talking so

00:09:38,290 --> 00:09:41,880
anyway David

00:09:44,940 --> 00:09:52,180
so so when you build at a site you

00:09:50,080 --> 00:09:53,980
typically start by having a basic

00:09:52,180 --> 00:09:55,630
architecture where you have browsers

00:09:53,980 --> 00:09:58,420
connecting to the application server and

00:09:55,630 --> 00:10:00,100
then when you're ready to scale out for

00:09:58,420 --> 00:10:02,590
bigger amounts of traffic you added a

00:10:00,100 --> 00:10:05,020
load balancer that then balances your

00:10:02,590 --> 00:10:07,630
requests between multiple application

00:10:05,020 --> 00:10:09,760
servers multiple backends this is now

00:10:07,630 --> 00:10:12,460
allowing you to you to evenly distribute

00:10:09,760 --> 00:10:16,540
the traffic to those bottlenecks boxes

00:10:12,460 --> 00:10:18,010
and you do it with something that has a

00:10:16,540 --> 00:10:19,480
very light touch like a load balancer

00:10:18,010 --> 00:10:20,770
where it doesn't have to do much with

00:10:19,480 --> 00:10:23,530
the traffic other than centers the right

00:10:20,770 --> 00:10:25,600
back end the problem is is that this can

00:10:23,530 --> 00:10:27,100
be a bottleneck in itself and if you're

00:10:25,600 --> 00:10:28,960
processing enough traffic like a

00:10:27,100 --> 00:10:31,180
national news story adding a load

00:10:28,960 --> 00:10:34,170
balancer isn't enough to actually scale

00:10:31,180 --> 00:10:38,470
your traffic up for that sort of

00:10:34,170 --> 00:10:40,750
environment and indeed when we started

00:10:38,470 --> 00:10:43,090
looking at the actual logs of where

00:10:40,750 --> 00:10:44,610
things had actually peaked out it wasn't

00:10:43,090 --> 00:10:48,070
the application servers that had gotten

00:10:44,610 --> 00:10:51,340
that we're falling over we saw network

00:10:48,070 --> 00:10:54,070
traffic basically spike up and then sort

00:10:51,340 --> 00:10:55,810
of hover around this jittery edge that

00:10:54,070 --> 00:10:57,820
you start seeing when you're working

00:10:55,810 --> 00:11:00,790
with TCP traffic and you've maxed out

00:10:57,820 --> 00:11:03,040
the connection and even if you have a

00:11:00,790 --> 00:11:04,990
gigabit or two gigabit connections for

00:11:03,040 --> 00:11:08,290
stuff eventually it maxes out and that's

00:11:04,990 --> 00:11:09,550
sort of the story of that night that

00:11:08,290 --> 00:11:12,250
once you start having that kind of

00:11:09,550 --> 00:11:13,510
national news story you really can max

00:11:12,250 --> 00:11:17,620
out that sort of connection and then a

00:11:13,510 --> 00:11:20,890
load balancers done enough so this is

00:11:17,620 --> 00:11:23,320
what happened at as we were working on

00:11:20,890 --> 00:11:25,510
that Abe already told you about the

00:11:23,320 --> 00:11:28,960
downtime once they reached about 50,000

00:11:25,510 --> 00:11:31,780
concurrence which is about 10 are not 10

00:11:28,960 --> 00:11:33,430
about five times a sort of baseline

00:11:31,780 --> 00:11:38,410
traffic that would be typically expected

00:11:33,430 --> 00:11:42,520
to to reach and then around sunday is

00:11:38,410 --> 00:11:43,839
when he filed the report with us and

00:11:42,520 --> 00:11:45,700
when he's his arms length he doesn't

00:11:43,839 --> 00:11:50,530
mean like a separation he means like the

00:11:45,700 --> 00:11:52,720
text was the hot and then once we

00:11:50,530 --> 00:11:53,980
actually got back to the office I think

00:11:52,720 --> 00:11:55,329
was it I don't know if as a holiday

00:11:53,980 --> 00:11:57,579
monday or whatever reason

00:11:55,329 --> 00:12:00,069
but we started really diving into the

00:11:57,579 --> 00:12:01,509
technical issue on Tuesday finding out

00:12:00,069 --> 00:12:05,739
that it was a load balancer bottleneck

00:12:01,509 --> 00:12:07,689
and looking at her options and then we

00:12:05,739 --> 00:12:10,360
knew that we actually had to implement

00:12:07,689 --> 00:12:15,670
something by Wednesday because Thursday

00:12:10,360 --> 00:12:18,459
was the next powerball drawing so and

00:12:15,670 --> 00:12:19,989
also i want to emphasize here that we

00:12:18,459 --> 00:12:21,279
had an unknown expected number of

00:12:19,989 --> 00:12:23,949
concurrence because just because the

00:12:21,279 --> 00:12:27,069
infrastructure died at 50,000 doesn't

00:12:23,949 --> 00:12:30,910
mean that you actually can say well if i

00:12:27,069 --> 00:12:33,279
do double that it's going to be fine so

00:12:30,910 --> 00:12:36,579
eventually you have to take paths to

00:12:33,279 --> 00:12:37,720
even more scale web scale I don't know

00:12:36,579 --> 00:12:42,910
how many people have seen this cartoon

00:12:37,720 --> 00:12:44,499
okay great this is for those who haven't

00:12:42,910 --> 00:12:47,110
seen it it's a cartoon mocking the term

00:12:44,499 --> 00:12:50,709
web scale because of how a lot of people

00:12:47,110 --> 00:12:54,189
put it in place when it's premature or

00:12:50,709 --> 00:12:56,040
they're using not very reliable

00:12:54,189 --> 00:12:58,600
technologies that just run really fast

00:12:56,040 --> 00:13:01,509
but this is actually an incident of

00:12:58,600 --> 00:13:02,739
actually requiring web scale for

00:13:01,509 --> 00:13:05,429
delivering this sort of infrastructure

00:13:02,739 --> 00:13:09,040
and we went through a bunch of options

00:13:05,429 --> 00:13:11,169
internally at Pantheon the first option

00:13:09,040 --> 00:13:12,759
we considered that we could graft on top

00:13:11,169 --> 00:13:15,279
of our existing infrastructure was

00:13:12,759 --> 00:13:17,619
something like round robin DNS where we

00:13:15,279 --> 00:13:20,860
deploy a few more load balancers we put

00:13:17,619 --> 00:13:24,579
all those things into DNS upstream our

00:13:20,860 --> 00:13:26,230
DNS will will send out a fresh IP in the

00:13:24,579 --> 00:13:27,970
rotation each time a new request comes

00:13:26,230 --> 00:13:29,259
in but there's a problem with this

00:13:27,970 --> 00:13:31,689
approach because you don't have any

00:13:29,259 --> 00:13:34,899
guaranteed balance even if you have all

00:13:31,689 --> 00:13:36,549
those ip's rotating some service

00:13:34,899 --> 00:13:39,100
provider like Comcast could very well

00:13:36,549 --> 00:13:41,290
get one result from you cash it and not

00:13:39,100 --> 00:13:43,899
necessarily follow the same structure

00:13:41,290 --> 00:13:47,860
for rotating it causing everyone from a

00:13:43,899 --> 00:13:51,209
major ISP or origin to be accessing the

00:13:47,860 --> 00:13:54,220
same load balancer all the same time and

00:13:51,209 --> 00:13:56,919
given that it's off the dns caching is

00:13:54,220 --> 00:14:00,129
often provider by provider that lumping

00:13:56,919 --> 00:14:02,589
can be really really onion afore so we

00:14:00,129 --> 00:14:04,929
we decided against hacking this approach

00:14:02,589 --> 00:14:05,800
into place it's not an approach that we

00:14:04,929 --> 00:14:07,360
even really

00:14:05,800 --> 00:14:08,649
support on the platform anyway we would

00:14:07,360 --> 00:14:12,130
have had to kind of go on the side to

00:14:08,649 --> 00:14:14,589
implement it the next option would be

00:14:12,130 --> 00:14:16,720
trying to pick up the red phone to our

00:14:14,589 --> 00:14:19,089
service provider and say let's buy a

00:14:16,720 --> 00:14:22,540
gigantic load balancer like well do you

00:14:19,089 --> 00:14:25,720
have any do you have any 10 gigabit f5s

00:14:22,540 --> 00:14:28,089
lying around and the answer is usually

00:14:25,720 --> 00:14:29,860
no by the way because 10 gigabit f5s

00:14:28,089 --> 00:14:30,940
start at thirty thousand dollars apiece

00:14:29,860 --> 00:14:33,670
and if you want to implement them

00:14:30,940 --> 00:14:35,350
redundant ly you need at least two so

00:14:33,670 --> 00:14:39,519
they don't typically just sit on the

00:14:35,350 --> 00:14:41,200
shelves too much and often I mean red

00:14:39,519 --> 00:14:43,630
phone notwithstanding they often take

00:14:41,200 --> 00:14:44,920
weeks to deploy if you wanted to call up

00:14:43,630 --> 00:14:47,800
our service provider have them put

00:14:44,920 --> 00:14:50,440
together a proposal and then you you end

00:14:47,800 --> 00:14:51,790
up with it in a rack of hardware and

00:14:50,440 --> 00:14:54,250
then there's the whole time for

00:14:51,790 --> 00:14:55,870
configuring it and questions about how

00:14:54,250 --> 00:14:59,740
well it'll handle other load profiles

00:14:55,870 --> 00:15:01,930
like HTTPS termination and ultimately it

00:14:59,740 --> 00:15:05,260
still concentrates the traffic all into

00:15:01,930 --> 00:15:07,839
one data center which has its own kind

00:15:05,260 --> 00:15:11,620
of issues with being able to scale out

00:15:07,839 --> 00:15:14,050
the traffic and performance the third

00:15:11,620 --> 00:15:15,279
option we looked at was I'm skipping the

00:15:14,050 --> 00:15:18,310
load balancer and going right to

00:15:15,279 --> 00:15:21,399
pantheons edge because we deploy varnish

00:15:18,310 --> 00:15:25,209
nodes on Pantheon we're on the Pantheon

00:15:21,399 --> 00:15:28,120
edge for every site it comes with a set

00:15:25,209 --> 00:15:29,770
of three nodes that both handle varnish

00:15:28,120 --> 00:15:33,730
and then route back to back in

00:15:29,770 --> 00:15:36,070
containers and then what we do is unless

00:15:33,730 --> 00:15:38,980
someone's implemented HTTPS we typically

00:15:36,070 --> 00:15:41,410
send the traffic directly there each of

00:15:38,980 --> 00:15:44,410
those boxes has a multi-gigabit capacity

00:15:41,410 --> 00:15:46,779
but at the same time it could be lumpy

00:15:44,410 --> 00:15:48,370
with the distribution and ultimately

00:15:46,779 --> 00:15:50,410
this wasn't going to get us through more

00:15:48,370 --> 00:15:53,010
than just Powerball night because while

00:15:50,410 --> 00:15:56,199
patch com currently is http-based

00:15:53,010 --> 00:15:58,089
they've been deploying more HTTPS things

00:15:56,199 --> 00:16:00,940
and eventually we'll need to go more and

00:15:58,089 --> 00:16:02,649
more HTTPS so a solution here that

00:16:00,940 --> 00:16:06,010
doesn't actually account for the next

00:16:02,649 --> 00:16:07,750
few months of roadmap and can only be

00:16:06,010 --> 00:16:09,430
used in the sort of emergency

00:16:07,750 --> 00:16:12,370
circumstance is not a very appealing

00:16:09,430 --> 00:16:13,320
option and it would have even been in a

00:16:12,370 --> 00:16:15,720
regression for

00:16:13,320 --> 00:16:18,300
that night because even today patch

00:16:15,720 --> 00:16:20,010
column can be accessed over HTTPS it

00:16:18,300 --> 00:16:21,420
just redirects you and we wouldn't have

00:16:20,010 --> 00:16:24,390
been able to even handle the redirects

00:16:21,420 --> 00:16:27,120
with this sort of use case so we sort of

00:16:24,390 --> 00:16:31,380
ruled that out too so now we're heading

00:16:27,120 --> 00:16:34,440
to CDN territory the initial kind of CDN

00:16:31,380 --> 00:16:36,930
look that the initial CDN architecture

00:16:34,440 --> 00:16:39,420
that we looked at was the standard one

00:16:36,930 --> 00:16:41,670
which is where user agents get routed to

00:16:39,420 --> 00:16:43,470
a point of presence that is

00:16:41,670 --> 00:16:45,600
geographically local to them and if that

00:16:43,470 --> 00:16:48,870
point of presence misses its cash then

00:16:45,600 --> 00:16:50,790
it hits back to the Pantheon origin this

00:16:48,870 --> 00:16:52,700
would meet the use case and I would have

00:16:50,790 --> 00:16:55,340
been perfectly happy implementing this

00:16:52,700 --> 00:16:58,290
but it isn't as good as you can get

00:16:55,340 --> 00:17:00,810
because you can also add in an origin

00:16:58,290 --> 00:17:02,790
shield and this is supported by many

00:17:00,810 --> 00:17:05,820
major CD ends including CloudFlare and

00:17:02,790 --> 00:17:09,030
fastly and what this basically does is

00:17:05,820 --> 00:17:10,530
now we have a few layers of caching we

00:17:09,030 --> 00:17:13,290
have the local point of presence which

00:17:10,530 --> 00:17:15,150
stores it geographically local to a user

00:17:13,290 --> 00:17:17,010
who's accessing the content then you

00:17:15,150 --> 00:17:21,180
have an origin shield which basically

00:17:17,010 --> 00:17:23,040
forms a bat forms as a backstop right

00:17:21,180 --> 00:17:25,230
before the CDN actually connects to the

00:17:23,040 --> 00:17:27,839
origin systems and what this does is it

00:17:25,230 --> 00:17:29,100
aggregates all the misses from all the

00:17:27,839 --> 00:17:31,380
different points of presents around the

00:17:29,100 --> 00:17:33,120
world into this origin shield and then

00:17:31,380 --> 00:17:35,370
if the origin shield has it according to

00:17:33,120 --> 00:17:36,780
the rules of the CDN that means that it

00:17:35,370 --> 00:17:39,030
doesn't have to reach the origin at all

00:17:36,780 --> 00:17:41,510
and the great thing about this is that

00:17:39,030 --> 00:17:43,950
you typically can configure the caching

00:17:41,510 --> 00:17:45,840
lifetimes and other configuration

00:17:43,950 --> 00:17:47,730
consistently across the whole CDN

00:17:45,840 --> 00:17:49,590
including the origin shield and points

00:17:47,730 --> 00:17:53,130
of presence without a lot of extra

00:17:49,590 --> 00:17:55,920
effort so you almost get it you almost

00:17:53,130 --> 00:17:57,390
get this additional cash hit for free it

00:17:55,920 --> 00:17:58,710
would have been probably fine to send

00:17:57,390 --> 00:18:01,770
all the points of presence to the origin

00:17:58,710 --> 00:18:03,090
but with the national news story you're

00:18:01,770 --> 00:18:04,410
working with quite a few points of

00:18:03,090 --> 00:18:06,870
presence that are going to be getting

00:18:04,410 --> 00:18:08,210
traffic coming in and so each one would

00:18:06,870 --> 00:18:11,310
have to miss on each piece of content

00:18:08,210 --> 00:18:12,930
before they would be locally cached I'd

00:18:11,310 --> 00:18:14,400
like to add just one thing can you use

00:18:12,930 --> 00:18:16,560
website I'd like to add just one thing

00:18:14,400 --> 00:18:19,620
to this too is that you know at eleven

00:18:16,560 --> 00:18:21,060
o'clock the numbers are announced so you

00:18:19,620 --> 00:18:21,680
have to be able to purge these kinds of

00:18:21,060 --> 00:18:22,850
things

00:18:21,680 --> 00:18:24,710
it's not that they're just going to sit

00:18:22,850 --> 00:18:26,030
out there and the other four thousand

00:18:24,710 --> 00:18:27,860
stories on patch or three thousand

00:18:26,030 --> 00:18:30,350
stories on patch of the day we had about

00:18:27,860 --> 00:18:32,480
1,500 new ones in a day are all being

00:18:30,350 --> 00:18:35,230
updated at the same time as well so it's

00:18:32,480 --> 00:18:40,760
everything is volatile in this situation

00:18:35,230 --> 00:18:42,260
yeah and so this we did we needed to

00:18:40,760 --> 00:18:44,810
accommodate that particular thing into

00:18:42,260 --> 00:18:47,300
the architecture as well so we went into

00:18:44,810 --> 00:18:48,380
sort of looking at CDN selection and our

00:18:47,300 --> 00:18:50,990
priorities for this sort of

00:18:48,380 --> 00:18:53,210
implementation now if you have much more

00:18:50,990 --> 00:18:56,330
lead time your priorities might be a

00:18:53,210 --> 00:18:58,130
little different but in our case we

00:18:56,330 --> 00:19:00,650
needed to find a CDN that's ready to

00:18:58,130 --> 00:19:02,480
handle top 100 levels of traffic there

00:19:00,650 --> 00:19:04,370
are some really interesting cdns out

00:19:02,480 --> 00:19:06,470
there that are kind of new newer on the

00:19:04,370 --> 00:19:08,420
scene like key CDN that have a nice

00:19:06,470 --> 00:19:10,400
feature set but I don't know if I would

00:19:08,420 --> 00:19:14,780
want to throw a top 100 website at them

00:19:10,400 --> 00:19:16,130
overnight they probably wouldn't be that

00:19:14,780 --> 00:19:19,730
would probably blow their capacity

00:19:16,130 --> 00:19:21,050
planning we needed Drupal compatibility

00:19:19,730 --> 00:19:22,730
in the sense that we needed to be able

00:19:21,050 --> 00:19:24,680
to specify the rules that Drupal needs

00:19:22,730 --> 00:19:26,540
to operate properly across the CDN and

00:19:24,680 --> 00:19:28,610
we needed to be able to do this in a

00:19:26,540 --> 00:19:30,140
reasonable amount of time and this mean

00:19:28,610 --> 00:19:31,580
i say reasonable amount of time because

00:19:30,140 --> 00:19:35,930
when you work with a provider like say

00:19:31,580 --> 00:19:39,200
Akamai which which has a very fast CDN

00:19:35,930 --> 00:19:40,880
and great coverage their rule sets

00:19:39,200 --> 00:19:43,640
basically require that you work through

00:19:40,880 --> 00:19:44,600
them to implement updated rules and that

00:19:43,640 --> 00:19:45,920
makes it very hard to implement

00:19:44,600 --> 00:19:47,570
something like drupal that has

00:19:45,920 --> 00:19:50,630
complicated cash management rules

00:19:47,570 --> 00:19:52,310
because of the round trip through their

00:19:50,630 --> 00:19:53,780
sort of professional services team to

00:19:52,310 --> 00:19:55,940
implementing rules and refining the

00:19:53,780 --> 00:19:57,610
rules means the minimum implementation

00:19:55,940 --> 00:20:03,350
for that sort of thing would be weeks

00:19:57,610 --> 00:20:05,960
and we didn't have leaks we needed to

00:20:03,350 --> 00:20:08,480
have HTTPS support all the way for

00:20:05,960 --> 00:20:09,980
running on the apex domain and apex

00:20:08,480 --> 00:20:13,670
domains means something like X

00:20:09,980 --> 00:20:17,090
example.com whereas a third level domain

00:20:13,670 --> 00:20:21,020
would be dub dub dub example calm and

00:20:17,090 --> 00:20:22,760
some CD ins only offer HTTPS for the

00:20:21,020 --> 00:20:25,790
third-level domains because you can do

00:20:22,760 --> 00:20:27,290
things with see names with them and then

00:20:25,790 --> 00:20:29,930
different cdns have different approaches

00:20:27,290 --> 00:20:32,180
for supporting the apex domain and

00:20:29,930 --> 00:20:32,809
because patch com literally runs as

00:20:32,180 --> 00:20:36,440
Patrick

00:20:32,809 --> 00:20:37,850
not dub-dub-dub patch com this was

00:20:36,440 --> 00:20:39,470
something that we wanted to have going

00:20:37,850 --> 00:20:41,570
forward so that we could not only select

00:20:39,470 --> 00:20:45,649
a CDN for the next couple of weeks but

00:20:41,570 --> 00:20:47,899
ideally for the next few years the 24

00:20:45,649 --> 00:20:50,179
hour turnaround is a big deal so I

00:20:47,899 --> 00:20:51,379
mentioned a bit on that how that impacts

00:20:50,179 --> 00:20:54,769
things like drupal compatibility or

00:20:51,379 --> 00:20:56,960
capacity planning but we didn't want to

00:20:54,769 --> 00:20:59,600
be the biggest customer of the CDN we

00:20:56,960 --> 00:21:04,309
were taking on we wanted to be another

00:20:59,600 --> 00:21:06,139
customer and we also wanted to have an

00:21:04,309 --> 00:21:08,119
eye toward the future for cash tagging

00:21:06,139 --> 00:21:10,899
and validation how many of you are

00:21:08,119 --> 00:21:14,269
building sites on Drupal 8 at this point

00:21:10,899 --> 00:21:17,600
that's like twenty percent I mean that

00:21:14,269 --> 00:21:20,499
will continue to grow but Drupal 8 can

00:21:17,600 --> 00:21:23,600
now tag content where rather than

00:21:20,499 --> 00:21:26,899
invalidating by URL patterns you can

00:21:23,600 --> 00:21:29,600
send surrogate surrogate keys down to

00:21:26,899 --> 00:21:32,539
your edge cash and then generally an

00:21:29,600 --> 00:21:34,789
edge cash the ability to invoke clearing

00:21:32,539 --> 00:21:38,990
a specific key and what that means is

00:21:34,789 --> 00:21:41,480
that every time say a note appears as

00:21:38,990 --> 00:21:43,610
the node view or in a block on a page or

00:21:41,480 --> 00:21:45,379
on a listing on a page you can do

00:21:43,610 --> 00:21:47,539
something like tag it with that note ID

00:21:45,379 --> 00:21:49,309
and then whenever you update the node

00:21:47,539 --> 00:21:51,019
you can invalidate every page that has

00:21:49,309 --> 00:21:53,029
anything that was derived from that node

00:21:51,019 --> 00:21:55,369
and it allows very precise cache

00:21:53,029 --> 00:21:58,129
invalidation and it doesn't it doesn't

00:21:55,369 --> 00:21:59,869
mean you put one tag on a page if we you

00:21:58,129 --> 00:22:02,179
include five nodes on a page you would

00:21:59,869 --> 00:22:03,679
put five tags on the page so that if any

00:22:02,179 --> 00:22:07,879
of those nodes are invalidated you can

00:22:03,679 --> 00:22:10,220
invalidate the edge content and also we

00:22:07,879 --> 00:22:12,169
wanted as additional insurance and in

00:22:10,220 --> 00:22:14,330
terms of I've talked about security from

00:22:12,169 --> 00:22:15,860
defense in depth and I think there's

00:22:14,330 --> 00:22:17,929
such a thing from a reliability

00:22:15,860 --> 00:22:20,419
perspective of engineering in depth and

00:22:17,929 --> 00:22:22,580
what that means is don't just have a

00:22:20,419 --> 00:22:24,499
plan a for your engineering in terms of

00:22:22,580 --> 00:22:30,200
your customer experience have a plan B

00:22:24,499 --> 00:22:32,059
as well and so on cdns including fastly

00:22:30,200 --> 00:22:35,210
and cloudflare they have options for

00:22:32,059 --> 00:22:38,240
fall back to their stale or cached

00:22:35,210 --> 00:22:40,399
content if the origin or backbone is

00:22:38,240 --> 00:22:42,950
non-responsive and what that means is

00:22:40,399 --> 00:22:44,869
that you can retain a copy of it on the

00:22:42,950 --> 00:22:45,170
CD in for a considerably longer amount

00:22:44,869 --> 00:22:47,090
of

00:22:45,170 --> 00:22:50,120
I'm the nude you would have it served

00:22:47,090 --> 00:22:53,960
normally and then rather than giving

00:22:50,120 --> 00:22:56,210
your users an error or a blank page or

00:22:53,960 --> 00:22:58,940
something worse you end up serving them

00:22:56,210 --> 00:23:00,890
at worst stale content and that's a much

00:22:58,940 --> 00:23:08,240
much better thing for your traffic ad

00:23:00,890 --> 00:23:11,090
revenue and brand so what we ended up

00:23:08,240 --> 00:23:13,700
doing was kind of a sort of clever

00:23:11,090 --> 00:23:15,140
approach to minimize the amount of

00:23:13,700 --> 00:23:19,570
integration we would have to do deeply

00:23:15,140 --> 00:23:22,790
with the CDN initially so what we did is

00:23:19,570 --> 00:23:25,370
rather than try and move all kind of

00:23:22,790 --> 00:23:27,890
cash and validation logic today to the

00:23:25,370 --> 00:23:29,120
CDN or by today I mean when we were

00:23:27,890 --> 00:23:31,790
implementing this in this short period

00:23:29,120 --> 00:23:34,130
of time what we did is we kept the long

00:23:31,790 --> 00:23:36,650
TTL zanden validation on pantheons edge

00:23:34,130 --> 00:23:40,280
with its varnish cluster and then what

00:23:36,650 --> 00:23:43,010
we did on on fastly is we implemented a

00:23:40,280 --> 00:23:45,350
15-second TTL for the content but we

00:23:43,010 --> 00:23:48,470
told it to retain it for a full day just

00:23:45,350 --> 00:23:50,300
in case so what this meant is that if we

00:23:48,470 --> 00:23:53,870
invalidated something at Pantheon zedge

00:23:50,300 --> 00:23:57,170
then it would be fresh to CDN users

00:23:53,870 --> 00:23:59,870
within 15 seconds and that was a small

00:23:57,170 --> 00:24:01,670
enough window of time that even updating

00:23:59,870 --> 00:24:03,170
things like a Powerball result results

00:24:01,670 --> 00:24:06,260
story we're not going to be that

00:24:03,170 --> 00:24:07,820
dramatically affected and then the one

00:24:06,260 --> 00:24:10,370
day retention meant that even if there

00:24:07,820 --> 00:24:11,900
were say an hour or two of inability to

00:24:10,370 --> 00:24:14,420
access the origin or a backbone

00:24:11,900 --> 00:24:17,300
connection the it would be able to use

00:24:14,420 --> 00:24:19,130
its extra copy of the content and then

00:24:17,300 --> 00:24:22,250
serve that up so that the users would

00:24:19,130 --> 00:24:23,630
still see something fortunately we

00:24:22,250 --> 00:24:31,310
didn't have to fall back on that but

00:24:23,630 --> 00:24:33,080
it's nice to have that there so um how

00:24:31,310 --> 00:24:36,730
do you move to a CDN especially when you

00:24:33,080 --> 00:24:36,730
have a really limited amount of time uh

00:24:36,850 --> 00:24:42,140
so in our case one of the first things I

00:24:39,170 --> 00:24:44,120
did is work to get the CDN to terminate

00:24:42,140 --> 00:24:46,430
HTTPS because we wanted to make sure we

00:24:44,120 --> 00:24:49,010
can handle the redirect and would be

00:24:46,430 --> 00:24:51,200
ready for that future traffic later it

00:24:49,010 --> 00:24:53,330
tends to be kind of hard to throw HTTPS

00:24:51,200 --> 00:24:54,940
into the mix if you don't account for it

00:24:53,330 --> 00:24:56,800
a little early in the process because

00:24:54,940 --> 00:24:58,870
sometimes

00:24:56,800 --> 00:25:01,810
you end up with aliased pages for the

00:24:58,870 --> 00:25:03,160
HTTP versus https versions and it's

00:25:01,810 --> 00:25:04,930
really just better to get kind of get

00:25:03,160 --> 00:25:06,580
the handling in there even if the only

00:25:04,930 --> 00:25:09,250
purpose of that handling is to redirect

00:25:06,580 --> 00:25:12,430
to the non-encrypted copy the reverse is

00:25:09,250 --> 00:25:14,710
true if you go HTTPS only it makes sense

00:25:12,430 --> 00:25:17,860
to handle both cases and make sure the

00:25:14,710 --> 00:25:19,690
right things are in place early and then

00:25:17,860 --> 00:25:21,550
we made rules to properly handle Drupal

00:25:19,690 --> 00:25:23,230
this typically handled things like

00:25:21,550 --> 00:25:25,240
passed through for active sessions if

00:25:23,230 --> 00:25:27,670
you've ever looked at a varnish vcl file

00:25:25,240 --> 00:25:30,250
you see things like if there's a session

00:25:27,670 --> 00:25:33,190
cookie then do pass rather than fri to

00:25:30,250 --> 00:25:34,480
hit the cash that's pretty much required

00:25:33,190 --> 00:25:38,800
for any sort of content management

00:25:34,480 --> 00:25:41,470
system and keying on HTTP versus HTTPS

00:25:38,800 --> 00:25:43,120
which means that when we return a

00:25:41,470 --> 00:25:45,070
different response for one versus the

00:25:43,120 --> 00:25:47,290
other that it doesn't aliased like you

00:25:45,070 --> 00:25:49,870
can get into a redirect loop if you

00:25:47,290 --> 00:25:51,280
don't distinguish when you cash because

00:25:49,870 --> 00:25:54,610
if you're redirecting from one to the

00:25:51,280 --> 00:25:56,500
other or back you definitely don't want

00:25:54,610 --> 00:25:58,360
to do something where you load the HTTP

00:25:56,500 --> 00:26:00,340
page and then you send a redirect to the

00:25:58,360 --> 00:26:03,250
HTTP page that's cached from the last

00:26:00,340 --> 00:26:04,840
time you handle the HTTPS response now

00:26:03,250 --> 00:26:06,520
so those were sort of table stakes for

00:26:04,840 --> 00:26:09,460
just getting it to work and not be

00:26:06,520 --> 00:26:12,430
broken and then we created a test domain

00:26:09,460 --> 00:26:13,780
that routes through the CDN like on the

00:26:12,430 --> 00:26:15,160
surface like Pantheon you sort of just

00:26:13,780 --> 00:26:17,440
kind of add an extra domain on the

00:26:15,160 --> 00:26:20,320
dashboard and then if it's a subdomain

00:26:17,440 --> 00:26:22,960
you just tell us your cv and about it

00:26:20,320 --> 00:26:25,180
and what that does is it now allows you

00:26:22,960 --> 00:26:26,860
to inform other people from the

00:26:25,180 --> 00:26:29,650
organization here hey here's something

00:26:26,860 --> 00:26:31,150
to hammer on and this should work for

00:26:29,650 --> 00:26:34,150
you and they can do things like login

00:26:31,150 --> 00:26:36,490
logout view pages make sure the cash you

00:26:34,150 --> 00:26:41,770
can make sure that retention times are

00:26:36,490 --> 00:26:43,930
working properly and you can also make

00:26:41,770 --> 00:26:46,360
sure that all the kind of interactive

00:26:43,930 --> 00:26:48,670
things for once you're logged in and say

00:26:46,360 --> 00:26:50,170
editing content and then viewing it it

00:26:48,670 --> 00:26:51,940
that all the past through happens right

00:26:50,170 --> 00:26:54,790
and then also if you're doing redirects

00:26:51,940 --> 00:26:57,340
between HTTP and HTTPS making sure that

00:26:54,790 --> 00:27:01,660
all works correctly and that you don't

00:26:57,340 --> 00:27:03,040
catch aliasing and that's that's sort of

00:27:01,660 --> 00:27:04,450
what I just mentioned in terms of

00:27:03,040 --> 00:27:07,330
validating all of that through your test

00:27:04,450 --> 00:27:08,950
domain and patches case there's a lot of

00:27:07,330 --> 00:27:10,450
custom infrastructure in terms of the

00:27:08,950 --> 00:27:11,740
Headless Drupal

00:27:10,450 --> 00:27:15,130
various other services implemented

00:27:11,740 --> 00:27:17,710
through Drupal and those all interact

00:27:15,130 --> 00:27:20,140
even through varnish themselves not

00:27:17,710 --> 00:27:21,640
though not through the CDN so we wanted

00:27:20,140 --> 00:27:25,690
to validate that all of that was still

00:27:21,640 --> 00:27:27,430
working to and then really it's cut

00:27:25,690 --> 00:27:31,300
overtime once everything looks great and

00:27:27,430 --> 00:27:32,800
the best way to cut over because DNS can

00:27:31,300 --> 00:27:35,530
be finicky especially with long cash

00:27:32,800 --> 00:27:38,770
times is you want to drive that TTL way

00:27:35,530 --> 00:27:41,260
way down I know that a lot of DNS

00:27:38,770 --> 00:27:44,050
systems charge by the number of requests

00:27:41,260 --> 00:27:46,720
and when the T tails dropped you pay of

00:27:44,050 --> 00:27:48,580
pain proportional amount more but for

00:27:46,720 --> 00:27:51,550
the transition time it's totally worth

00:27:48,580 --> 00:27:54,280
it so you reduce it like maybe you had a

00:27:51,550 --> 00:27:57,250
15 minute TTL before really reduce it to

00:27:54,280 --> 00:27:59,020
like 15 seconds something where the

00:27:57,250 --> 00:28:02,830
cutover can be pretty reliable pretty

00:27:59,020 --> 00:28:05,110
quick not everyone running a recursive

00:28:02,830 --> 00:28:06,820
resolver downstream is going to totally

00:28:05,110 --> 00:28:09,730
honor your cash times but they tend to

00:28:06,820 --> 00:28:11,920
be close and then you want to wait out

00:28:09,730 --> 00:28:15,520
the old TTL in fact you can start this

00:28:11,920 --> 00:28:16,780
process well before you're ready to

00:28:15,520 --> 00:28:19,360
actually cut over because this doesn't

00:28:16,780 --> 00:28:21,700
actually cut over it may reduce

00:28:19,360 --> 00:28:24,190
performance a tiny tiny bit for hit

00:28:21,700 --> 00:28:26,770
rates to DNS caches but so if you have a

00:28:24,190 --> 00:28:28,930
15 minute TTL you do this change at

00:28:26,770 --> 00:28:30,430
least 15 minutes before you're ready to

00:28:28,930 --> 00:28:32,140
actually cut over because you want all

00:28:30,430 --> 00:28:33,790
the downstream caches to be flushed

00:28:32,140 --> 00:28:37,690
everyone to have those little short

00:28:33,790 --> 00:28:39,220
copies of that DNS and then once it's a

00:28:37,690 --> 00:28:42,370
super short time you can actually

00:28:39,220 --> 00:28:46,390
retarget to the CDN or alternative

00:28:42,370 --> 00:28:48,580
infrastructure and the that should

00:28:46,390 --> 00:28:50,530
implement that should roll out really

00:28:48,580 --> 00:28:53,110
quickly because if you have say a 15

00:28:50,530 --> 00:28:55,420
second time out on our TTL on your DNS

00:28:53,110 --> 00:28:57,100
records then it should only take 15 to

00:28:55,420 --> 00:28:58,600
30 seconds after making the change

00:28:57,100 --> 00:29:03,610
before you start seeing the traffic

00:28:58,600 --> 00:29:06,820
really flow into the the new the new IPs

00:29:03,610 --> 00:29:09,430
and then once you're actually happy with

00:29:06,820 --> 00:29:11,050
all of that then you can actually

00:29:09,430 --> 00:29:13,630
validate the production functionality

00:29:11,050 --> 00:29:16,030
and return DNS the original TTL the

00:29:13,630 --> 00:29:18,570
other purpose to the short TTL is that

00:29:16,030 --> 00:29:20,590
it also makes a mistake less costly that

00:29:18,570 --> 00:29:22,420
let's say you've got the configuration

00:29:20,590 --> 00:29:23,960
wrong or something was not set up

00:29:22,420 --> 00:29:25,370
properly in the CDM

00:29:23,960 --> 00:29:28,430
and you need to go back to your original

00:29:25,370 --> 00:29:30,140
origin then you can just toggle it back

00:29:28,430 --> 00:29:32,060
and there's just as little time the

00:29:30,140 --> 00:29:33,260
toggle things back at like you really

00:29:32,060 --> 00:29:35,030
don't want to be having a high-traffic

00:29:33,260 --> 00:29:36,770
site and then get the configuration

00:29:35,030 --> 00:29:40,400
wrong and have to wait 15 minutes before

00:29:36,770 --> 00:29:42,170
you can possibly fix it but then once

00:29:40,400 --> 00:29:44,630
it's validated you can bump the TTL back

00:29:42,170 --> 00:29:47,480
up in this sort of structure you've only

00:29:44,630 --> 00:29:49,820
spent an hour or two at the low TTL and

00:29:47,480 --> 00:29:51,350
then your performance return performance

00:29:49,820 --> 00:29:53,060
and cost return to exactly where they

00:29:51,350 --> 00:29:57,560
were before but you've mitigated the

00:29:53,060 --> 00:29:59,750
rest of risk of the transition um so I

00:29:57,560 --> 00:30:02,450
will hand this back to able to talk

00:29:59,750 --> 00:30:04,160
about what it was like after we did all

00:30:02,450 --> 00:30:14,240
of this and then we were in the next

00:30:04,160 --> 00:30:16,130
powerball drawing night I'd be remiss

00:30:14,240 --> 00:30:17,480
not to thank again the Pantheon crew for

00:30:16,130 --> 00:30:19,400
everything they did in those two days I

00:30:17,480 --> 00:30:21,350
mean my bug reports notwithstanding we

00:30:19,400 --> 00:30:24,590
all put in some long hours those days to

00:30:21,350 --> 00:30:27,500
get this right because patch in a

00:30:24,590 --> 00:30:29,870
hyperlocal sense is edge cases upon edge

00:30:27,500 --> 00:30:31,310
cases upon edge cases because if we're

00:30:29,870 --> 00:30:32,690
in Joliet Illinois and we're in

00:30:31,310 --> 00:30:34,400
Greenwich Connecticut those things are

00:30:32,690 --> 00:30:37,580
about as similar as chalk and cheese you

00:30:34,400 --> 00:30:39,680
know and so we just try to keep we have

00:30:37,580 --> 00:30:41,210
everything can't be a one-size-fits-all

00:30:39,680 --> 00:30:45,020
solution so we have these things that

00:30:41,210 --> 00:30:48,200
pantheon helped us out with so so 1045

00:30:45,020 --> 00:30:49,820
we're running at about 19,000

00:30:48,200 --> 00:30:51,410
concurrence which was warm but we were

00:30:49,820 --> 00:30:56,090
sort of saying well what what happened

00:30:51,410 --> 00:30:57,500
maybe you know was that what if they had

00:30:56,090 --> 00:30:59,360
a war nobody came what have we had a

00:30:57,500 --> 00:31:01,100
Powerball night and nobody came to batch

00:30:59,360 --> 00:31:03,920
right maybe the Google Jesus week that

00:31:01,100 --> 00:31:07,640
night exactly exactly so you're sort of

00:31:03,920 --> 00:31:10,460
sitting there this is at 1045 watching

00:31:07,640 --> 00:31:12,740
watching watching that's at eleven so

00:31:10,460 --> 00:31:14,330
that's jumped to 51 so we broke the

00:31:12,740 --> 00:31:18,790
previous one and you can see that now we

00:31:14,330 --> 00:31:21,650
broke the needles off the scale at 1101

00:31:18,790 --> 00:31:23,060
that's 1104 that's three minutes later

00:31:21,650 --> 00:31:25,730
that we jumped another 20,000

00:31:23,060 --> 00:31:27,350
concurrence and by the way we're in

00:31:25,730 --> 00:31:29,510
validating stories all over the place

00:31:27,350 --> 00:31:30,890
still I mean people are invalidating

00:31:29,510 --> 00:31:32,630
we're sending out breaking news alerts

00:31:30,890 --> 00:31:34,370
which when a breaking news alert goes

00:31:32,630 --> 00:31:35,059
out of patch say we send one to

00:31:34,370 --> 00:31:37,159
Ridgefield Connecticut

00:31:35,059 --> 00:31:38,840
it it puts a breaking news story on the

00:31:37,159 --> 00:31:40,429
front Fiat front page of Ridgefield

00:31:38,840 --> 00:31:42,649
Connecticut so it invalidates that page

00:31:40,429 --> 00:31:44,960
so every single time we're doing this

00:31:42,649 --> 00:31:46,999
we're in validating across a thousand

00:31:44,960 --> 00:31:52,940
different domain sites there's sort of

00:31:46,999 --> 00:31:54,710
URLs at all through this period that's

00:31:52,940 --> 00:31:56,830
1105 that's one minute later we've

00:31:54,710 --> 00:32:01,309
jumped another 20,000 concurrence

00:31:56,830 --> 00:32:06,169
there's 1106 which is a hundred and ten

00:32:01,309 --> 00:32:09,139
thousand concurrent this is what we saw

00:32:06,169 --> 00:32:10,309
on fastly by the way which is the faster

00:32:09,139 --> 00:32:13,580
was taking eighty-one percent of our

00:32:10,309 --> 00:32:16,039
traffic and that still means that we

00:32:13,580 --> 00:32:18,679
were seeing five or six thousand hits

00:32:16,039 --> 00:32:20,659
coming right through vastly through the

00:32:18,679 --> 00:32:21,919
Pantheon edge and that's what our

00:32:20,659 --> 00:32:24,230
throughput is at the time about five

00:32:21,919 --> 00:32:25,460
thousand right that's right to the metal

00:32:24,230 --> 00:32:27,289
on the front end this actually

00:32:25,460 --> 00:32:29,690
understates the fast they hit rate a bit

00:32:27,289 --> 00:32:32,269
because the way that the origin shield

00:32:29,690 --> 00:32:34,429
works is that if you missed the point of

00:32:32,269 --> 00:32:36,230
presence and then you hit the origin

00:32:34,429 --> 00:32:40,100
shield then it counts as one hit and one

00:32:36,230 --> 00:32:45,409
mess because each hit and miss on each

00:32:40,100 --> 00:32:49,129
area is is accumulated independently and

00:32:45,409 --> 00:32:51,529
then all rolled up so in I think we were

00:32:49,129 --> 00:32:54,499
probably in excess of ninety percent of

00:32:51,529 --> 00:32:56,570
traffic really actually being absorbed

00:32:54,499 --> 00:33:00,590
by fastly right that would make sense

00:32:56,570 --> 00:33:04,190
though and that's the screenshot of

00:33:00,590 --> 00:33:07,399
record that we have which is GA saying

00:33:04,190 --> 00:33:08,570
we had 250,000 and chart be saying we

00:33:07,399 --> 00:33:11,840
had a hundred and seventeen thousand it

00:33:08,570 --> 00:33:14,600
went higher but we didn't catch it and I

00:33:11,840 --> 00:33:16,249
think that's is that our I don't know if

00:33:14,600 --> 00:33:21,019
that's our last slide or not David but

00:33:16,249 --> 00:33:23,090
uh to just check can't be so times last

00:33:21,019 --> 00:33:26,230
night so we made it thanks to these guys

00:33:23,090 --> 00:33:30,409
and thanks to the engineers at patch to

00:33:26,230 --> 00:33:32,299
all six of them and the FAFSA team for

00:33:30,409 --> 00:33:34,410
like churning this out and put faster

00:33:32,299 --> 00:33:41,230
and faster

00:33:34,410 --> 00:33:43,300
the and so it also shows um why it

00:33:41,230 --> 00:33:45,070
matters not necessarily assuming that

00:33:43,300 --> 00:33:46,540
hey this is where we maxed out before

00:33:45,070 --> 00:33:47,890
let's implement double the

00:33:46,540 --> 00:33:49,840
infrastructure and hope things work out

00:33:47,890 --> 00:33:51,970
because we would have had to implement

00:33:49,840 --> 00:33:54,220
triple the infrastructure and had good

00:33:51,970 --> 00:33:56,890
balancing between it in order to sustain

00:33:54,220 --> 00:34:05,080
this traffic with the architectures we

00:33:56,890 --> 00:34:06,610
were using before great yeah we can

00:34:05,080 --> 00:34:08,230
opener questions yeah questions and

00:34:06,610 --> 00:34:11,560
there may be one more slide there but

00:34:08,230 --> 00:34:14,050
it's it's just the oh so yeah brought

00:34:11,560 --> 00:34:16,720
back in there please so this is for

00:34:14,050 --> 00:34:19,090
patch how did you guys get ranked number

00:34:16,720 --> 00:34:20,980
one was that just happenstance Google

00:34:19,090 --> 00:34:25,960
blesses you and what it giveth it take

00:34:20,980 --> 00:34:27,760
us away and uh first for some reason one

00:34:25,960 --> 00:34:30,490
of the nice things is the patches local

00:34:27,760 --> 00:34:32,440
we are hyper local in a thousand towns

00:34:30,490 --> 00:34:34,899
across the country and when a the

00:34:32,440 --> 00:34:37,050
winners in a patch town goes we're going

00:34:34,899 --> 00:34:39,429
to have the story probably first anyway

00:34:37,050 --> 00:34:42,669
and Google's going to privilege that

00:34:39,429 --> 00:34:44,380
story over a lot of these things we do

00:34:42,669 --> 00:34:46,300
have a pretty decent SEO on the site we

00:34:44,380 --> 00:34:50,230
are still doing spectacular numbers of

00:34:46,300 --> 00:34:54,100
things wrong and which gives us a lot of

00:34:50,230 --> 00:34:55,600
room to improve but uh we we get blessed

00:34:54,100 --> 00:34:57,580
here and there we've got blessed on a

00:34:55,600 --> 00:35:00,010
couple of the primaries and you just

00:34:57,580 --> 00:35:02,230
never know why it happens sometimes but

00:35:00,010 --> 00:35:03,910
a lot of it has to do with being out of

00:35:02,230 --> 00:35:05,770
the gate early with the story that's a

00:35:03,910 --> 00:35:08,170
good story and one of the nice things

00:35:05,770 --> 00:35:10,810
about patch stories is that they are

00:35:08,170 --> 00:35:12,390
generally if they're really a local

00:35:10,810 --> 00:35:15,340
story there really a good story and

00:35:12,390 --> 00:35:19,810
their unique so that that gives us the

00:35:15,340 --> 00:35:21,400
edge there thanks Tricia this question

00:35:19,810 --> 00:35:22,870
is for Pantheon first that's an

00:35:21,400 --> 00:35:26,050
impressive piece of engineering and

00:35:22,870 --> 00:35:28,600
incredibly short timeframe my site is

00:35:26,050 --> 00:35:30,280
slightly different in that I don't know

00:35:28,600 --> 00:35:33,040
when that massive traffic spike is

00:35:30,280 --> 00:35:35,950
coming what would you do differently or

00:35:33,040 --> 00:35:39,760
with the same application architectures

00:35:35,950 --> 00:35:42,220
to work well II if you're worried about

00:35:39,760 --> 00:35:44,240
the traffic spike they need to be

00:35:42,220 --> 00:35:47,270
thinking about exactly how far up

00:35:44,240 --> 00:35:50,000
could go part of what we do at Pantheon

00:35:47,270 --> 00:35:52,850
is by putting a cluster of varnish boxes

00:35:50,000 --> 00:35:55,340
in front of every single site we can

00:35:52,850 --> 00:35:57,770
actually handle like top 100 sites style

00:35:55,340 --> 00:36:00,860
traffic on a typical day without any

00:35:57,770 --> 00:36:02,840
issues and pop 100 style site traffic on

00:36:00,860 --> 00:36:08,590
a typical day is an enormous amount of

00:36:02,840 --> 00:36:11,060
traffic for our normal site the and I

00:36:08,590 --> 00:36:13,280
would also recommend looking at your

00:36:11,060 --> 00:36:15,290
options at throwing a CD enter front you

00:36:13,280 --> 00:36:18,260
want to look at the costs of the

00:36:15,290 --> 00:36:20,750
implementation times some CD ends like

00:36:18,260 --> 00:36:22,010
CloudFlare start free and you can

00:36:20,750 --> 00:36:24,010
actually get a lot of their benefits

00:36:22,010 --> 00:36:27,560
without having to even spend anything

00:36:24,010 --> 00:36:29,540
vastly starts at paid rates but offers

00:36:27,560 --> 00:36:32,180
some more customization of the caching

00:36:29,540 --> 00:36:33,680
layer okay I would also add we never

00:36:32,180 --> 00:36:36,470
know when we're going to get a spike

00:36:33,680 --> 00:36:38,090
either last night I had to roll out code

00:36:36,470 --> 00:36:40,100
I had a window of about an hour to roll

00:36:38,090 --> 00:36:42,710
out some code and suddenly the northern

00:36:40,100 --> 00:36:44,810
lights were visible in Connecticut and I

00:36:42,710 --> 00:36:47,300
was rolled out coat on Pantheon with

00:36:44,810 --> 00:36:51,770
8,000 concurrence on our site just at

00:36:47,300 --> 00:36:53,930
note choice okay thank you but oh to

00:36:51,770 --> 00:36:55,670
that point I opened in the fast what

00:36:53,930 --> 00:36:57,890
helped there was having fastly in play

00:36:55,670 --> 00:36:59,869
because I could then open up their TTL

00:36:57,890 --> 00:37:01,520
for another minute or two just to give

00:36:59,869 --> 00:37:03,140
myself the breathing room I needed to

00:37:01,520 --> 00:37:06,470
get the code out the door and then close

00:37:03,140 --> 00:37:08,000
it again I think that's yeah sort of the

00:37:06,470 --> 00:37:09,800
other benefits that CD ends will give

00:37:08,000 --> 00:37:11,540
you our like if you've got five hundreds

00:37:09,800 --> 00:37:13,640
on your site that'll be serving traffic

00:37:11,540 --> 00:37:15,400
you know could pull that traffic you

00:37:13,640 --> 00:37:16,970
know so you're not serving those 500s

00:37:15,400 --> 00:37:19,330
but another thing i want to mention

00:37:16,970 --> 00:37:21,859
really quick was the we saw at sony

00:37:19,330 --> 00:37:23,240
where we had a lot of hyperlocal you

00:37:21,859 --> 00:37:25,760
know sort of hyperlocal on the global

00:37:23,240 --> 00:37:27,859
stage was that these CD ends really

00:37:25,760 --> 00:37:30,109
helped serve traffic much faster because

00:37:27,859 --> 00:37:33,320
they're pulling from you know Germany or

00:37:30,109 --> 00:37:36,650
Austria or you know Japan we saw a big

00:37:33,320 --> 00:37:38,210
boost actually even in organic search

00:37:36,650 --> 00:37:40,280
because our site was delivering a lot

00:37:38,210 --> 00:37:42,350
faster just by having content coming

00:37:40,280 --> 00:37:45,080
from closer points of presence and that

00:37:42,350 --> 00:37:46,340
you can use a you know some VPNs out

00:37:45,080 --> 00:37:48,230
there that you can sort of subscribe to

00:37:46,340 --> 00:37:49,760
and you can proxy your traffic through

00:37:48,230 --> 00:37:51,020
to these other you know what is around

00:37:49,760 --> 00:37:54,210
the country to sort of test these things

00:37:51,020 --> 00:37:57,690
out before you go live with them too

00:37:54,210 --> 00:38:01,880
I am I think on one of the slides you

00:37:57,690 --> 00:38:05,160
said you have a very long TTL at origin

00:38:01,880 --> 00:38:07,619
it's not that long okay so five minutes

00:38:05,160 --> 00:38:09,599
hi okay and then he said you're in

00:38:07,619 --> 00:38:12,540
validating all the time are you is this

00:38:09,599 --> 00:38:15,390
we blow the five minutes our editors are

00:38:12,540 --> 00:38:16,710
very impatient right skills so if they

00:38:15,390 --> 00:38:20,940
make a change they want to see it

00:38:16,710 --> 00:38:23,940
immediately so it's only a long TTL

00:38:20,940 --> 00:38:26,820
compared to the 15 seconds and fastly we

00:38:23,940 --> 00:38:31,200
also do we stagger our TTLs too so we

00:38:26,820 --> 00:38:33,119
don't just set a global TTL we start and

00:38:31,200 --> 00:38:36,270
in Drupal speak we start with a global

00:38:33,119 --> 00:38:38,070
TTL and then anybody who's dealing with

00:38:36,270 --> 00:38:41,820
content anywhere down the execution

00:38:38,070 --> 00:38:43,770
chain can can change that TTL as its as

00:38:41,820 --> 00:38:46,410
it's running out the door so if we get a

00:38:43,770 --> 00:38:49,260
404 we set that TTL to something very

00:38:46,410 --> 00:38:53,580
long we don't want to start that 40 40

00:38:49,260 --> 00:38:55,230
gamut or if we see certain cases if you

00:38:53,580 --> 00:38:56,820
go to patch calm and go to connect patch

00:38:55,230 --> 00:39:00,210
icon Connecticut Greenwich or whatever

00:38:56,820 --> 00:39:02,820
there are 300 pages of content on patch

00:39:00,210 --> 00:39:06,810
com / Connecticut / granted page to page

00:39:02,820 --> 00:39:10,140
3 page 300 but we put a much longer TTL

00:39:06,810 --> 00:39:12,990
on pages 3 through ex things like that I

00:39:10,140 --> 00:39:14,580
also sorry is there are using is that

00:39:12,990 --> 00:39:16,200
within Drupal do you have like some kind

00:39:14,580 --> 00:39:18,570
of module where you're setting custom

00:39:16,200 --> 00:39:20,790
TTLs by path where are you doing this oh

00:39:18,570 --> 00:39:22,380
it's generally procedural and yes and we

00:39:20,790 --> 00:39:25,380
set the global TTL and then I'm hook

00:39:22,380 --> 00:39:27,000
exit we set that into the headers the

00:39:25,380 --> 00:39:30,690
other thing I wanted to mention here is

00:39:27,000 --> 00:39:34,290
that these short TTLs can be amazing for

00:39:30,690 --> 00:39:36,599
vacuuming up traffic because even even a

00:39:34,290 --> 00:39:37,650
one-second TTL on say a varnish box if

00:39:36,599 --> 00:39:39,390
you're able to handle the traffic

00:39:37,650 --> 00:39:41,490
through there is the difference between

00:39:39,390 --> 00:39:43,950
capping it at 60 requests per second

00:39:41,490 --> 00:39:46,260
versus a completely unlimited cap and so

00:39:43,950 --> 00:39:48,300
at 15 seconds we were getting at most

00:39:46,260 --> 00:39:50,970
four requests for any given thing from

00:39:48,300 --> 00:39:52,950
the origin shield for a specific URL

00:39:50,970 --> 00:39:55,680
that could hit the cash and that makes

00:39:52,950 --> 00:39:59,070
all the difference in the world and even

00:39:55,680 --> 00:40:00,450
that tiny amount of caching just I think

00:39:59,070 --> 00:40:02,310
at the peak it was hitting something

00:40:00,450 --> 00:40:03,660
like a ninety-six percent hit rate and

00:40:02,310 --> 00:40:05,780
fastly maybe even ninety-eight percent

00:40:03,660 --> 00:40:07,079
that's and that's even including the

00:40:05,780 --> 00:40:08,910
caveat that

00:40:07,079 --> 00:40:10,499
said before about if it misses the local

00:40:08,910 --> 00:40:12,420
point of presence and then hits the

00:40:10,499 --> 00:40:14,400
origin shield that accounts as a hit nms

00:40:12,420 --> 00:40:15,900
it was hitting points of presence of

00:40:14,400 --> 00:40:17,670
that rate just because everyone was

00:40:15,900 --> 00:40:19,289
viewing the same thing so if your

00:40:17,670 --> 00:40:21,839
traffic spikes happen to be

00:40:19,289 --> 00:40:24,509
laser-focused on particular assets on

00:40:21,839 --> 00:40:27,690
the site a short cash time can do

00:40:24,509 --> 00:40:29,579
wonders I think also we found it patch

00:40:27,690 --> 00:40:31,589
that if you really need to get traffic

00:40:29,579 --> 00:40:33,359
to your site what you do is you bury a

00:40:31,589 --> 00:40:35,880
billion dollars somewhere in the country

00:40:33,359 --> 00:40:39,989
and then you tell everyone that they

00:40:35,880 --> 00:40:41,880
wasted their time trying and last

00:40:39,989 --> 00:40:43,829
question as far as the invalidation goes

00:40:41,880 --> 00:40:45,569
are you doing any sort of integration

00:40:43,829 --> 00:40:47,549
between Drupal and varnish and fastly

00:40:45,569 --> 00:40:49,979
there's integration between drupal and

00:40:47,549 --> 00:40:51,359
pantheons varnish edge we have an API on

00:40:49,979 --> 00:40:54,420
the platform for doing in validations

00:40:51,359 --> 00:40:56,309
there isn't any integration with fastly

00:40:54,420 --> 00:40:58,739
right now and that's part of the story

00:40:56,309 --> 00:41:01,229
of why we chose a super short cash

00:40:58,739 --> 00:41:03,719
lifetime because even a really impatient

00:41:01,229 --> 00:41:07,739
editor can generally wait 15 seconds for

00:41:03,719 --> 00:41:09,690
something to actually get fresh and do

00:41:07,739 --> 00:41:12,119
the actual work to do an integration to

00:41:09,690 --> 00:41:14,299
fastly should happen eventually and like

00:41:12,119 --> 00:41:16,680
I've certainly recommended it to patch

00:41:14,299 --> 00:41:19,829
especially because the cash Keys support

00:41:16,680 --> 00:41:22,249
but as a stopgap especially if you're in

00:41:19,829 --> 00:41:25,109
a rush a really short cash lifetime

00:41:22,249 --> 00:41:26,459
deployed in a very robust way can do

00:41:25,109 --> 00:41:30,359
wonders first sight without you having

00:41:26,459 --> 00:41:35,670
to worry too much about steal items an

00:41:30,359 --> 00:41:37,859
explicit and validation thank you not

00:41:35,670 --> 00:41:40,349
that I'm prefer one over other but what

00:41:37,859 --> 00:41:43,619
were your reasons do choose vastly over

00:41:40,349 --> 00:41:46,019
cloud fair as obvious well there was

00:41:43,619 --> 00:41:47,999
definitely a difference between how it

00:41:46,019 --> 00:41:50,569
could handle the case of any issue

00:41:47,999 --> 00:41:53,910
connecting to origin / or / a backbone

00:41:50,569 --> 00:41:56,430
because when fastly goes into grace mode

00:41:53,910 --> 00:41:58,829
it's very transparent to end-users even

00:41:56,430 --> 00:42:01,469
though it shows up in the Irate results

00:41:58,829 --> 00:42:02,910
in fast days dashboard and logs so we

00:42:01,469 --> 00:42:05,519
can know what's happening even if site

00:42:02,910 --> 00:42:08,729
visitors don't which is really nice from

00:42:05,519 --> 00:42:10,979
a brand perspective cloudflare can keep

00:42:08,729 --> 00:42:12,900
the site online but they put branding on

00:42:10,979 --> 00:42:14,130
the page that says that basically

00:42:12,900 --> 00:42:16,910
cloudflare is keeping the site online

00:42:14,130 --> 00:42:20,450
which was a little less desirable

00:42:16,910 --> 00:42:22,760
and also in terms of really granular

00:42:20,450 --> 00:42:26,120
cache invalidation and cache key

00:42:22,760 --> 00:42:28,400
management fastly has been in that game

00:42:26,120 --> 00:42:30,440
for a long time there are some newer

00:42:28,400 --> 00:42:32,660
cache invalidation features on

00:42:30,440 --> 00:42:34,070
cloudflare that have launched I think in

00:42:32,660 --> 00:42:35,830
the last six months we actually have a

00:42:34,070 --> 00:42:44,380
cloud flower person here in the audience

00:42:35,830 --> 00:42:48,110
but the okay p and x panthi or to the

00:42:44,380 --> 00:42:51,110
and so there's they're starting to be

00:42:48,110 --> 00:42:53,330
more parity between the two surfaces

00:42:51,110 --> 00:42:55,370
like fastly is gaining the things that

00:42:53,330 --> 00:42:58,070
cloud Fleur once had is as very as

00:42:55,370 --> 00:42:59,330
fairly unique attributes and cloud

00:42:58,070 --> 00:43:00,820
fleurs gaining the things the

00:42:59,330 --> 00:43:02,990
distinctions that fast they had

00:43:00,820 --> 00:43:04,310
sometimes it comes down to exactly how

00:43:02,990 --> 00:43:06,320
much granularity you need because you

00:43:04,310 --> 00:43:09,320
certainly can't inject vcl into

00:43:06,320 --> 00:43:11,240
cloudflare second question we're

00:43:09,320 --> 00:43:13,520
currently using Akamai can we achieve

00:43:11,240 --> 00:43:16,670
the same results with a low TTL on

00:43:13,520 --> 00:43:19,100
Akamai that you got from say fastly I

00:43:16,670 --> 00:43:20,630
mean you can there's nothing you really

00:43:19,100 --> 00:43:26,480
can't do with akamai if you throw enough

00:43:20,630 --> 00:43:28,250
money and time at them thank you but the

00:43:26,480 --> 00:43:31,190
one thing I would caution is that I see

00:43:28,250 --> 00:43:32,570
some people aspirationally use Akamai

00:43:31,190 --> 00:43:35,630
when they're sort of a middle tier

00:43:32,570 --> 00:43:37,310
customer and you just get the dredges of

00:43:35,630 --> 00:43:39,080
the resources from Akamai like you will

00:43:37,310 --> 00:43:41,800
work with their worst engineers and

00:43:39,080 --> 00:43:44,120
their worst implementation people

00:43:41,800 --> 00:43:45,890
because like unless you're throwing a

00:43:44,120 --> 00:43:47,420
lot of money at Akamai you don't really

00:43:45,890 --> 00:43:50,120
matter to them very much how do you

00:43:47,420 --> 00:43:53,090
really feel how do you really feel about

00:43:50,120 --> 00:43:55,220
that so like I think they're a great

00:43:53,090 --> 00:43:56,870
product at the very high end but they I

00:43:55,220 --> 00:43:59,900
think that choosing them the middle tier

00:43:56,870 --> 00:44:02,420
gives you less value unfortunately we

00:43:59,900 --> 00:44:04,520
are video shop so that web bucket is a

00:44:02,420 --> 00:44:12,980
very small portion of the whole contract

00:44:04,520 --> 00:44:15,290
so okay thank you so assuming the vastly

00:44:12,980 --> 00:44:17,130
integration and Drupal work together is

00:44:15,290 --> 00:44:20,009
there any reason to keep the voyage

00:44:17,130 --> 00:44:22,740
the infrastructure and that's a good

00:44:20,009 --> 00:44:24,960
question well the answer right now is

00:44:22,740 --> 00:44:27,900
that only a handful of sites on Pantheon

00:44:24,960 --> 00:44:30,480
are going through fastly or any other

00:44:27,900 --> 00:44:33,930
CDN and most sites are relying on the

00:44:30,480 --> 00:44:36,150
Pantheon edge for their scaling and most

00:44:33,930 --> 00:44:39,660
sites can rely on that actually and it's

00:44:36,150 --> 00:44:42,269
fine for them and their it's patches

00:44:39,660 --> 00:44:44,759
actually the first case and to date the

00:44:42,269 --> 00:44:47,190
only case of someone actually saturating

00:44:44,759 --> 00:44:48,990
the bandwidth and edge resources of

00:44:47,190 --> 00:44:51,480
pantheon yeah we didn't mention that

00:44:48,990 --> 00:44:54,779
Powerball went down during that time and

00:44:51,480 --> 00:44:56,250
we feel I would also say that we are

00:44:54,779 --> 00:44:58,799
actually already doing that in certain

00:44:56,250 --> 00:45:00,839
cases we are invalidating we have a lot

00:44:58,799 --> 00:45:02,250
of internal sort of micro service

00:45:00,839 --> 00:45:04,890
architecture now so we have three or

00:45:02,250 --> 00:45:08,089
four sites sitting behind our front and

00:45:04,890 --> 00:45:10,950
some of them are using pantheons edge

00:45:08,089 --> 00:45:13,769
and some of them and and then the same

00:45:10,950 --> 00:45:15,779
thing is using fast Lee's edge and

00:45:13,769 --> 00:45:18,390
invalidating fastly and invalidating

00:45:15,779 --> 00:45:21,329
Pantheon in two different cases so we do

00:45:18,390 --> 00:45:23,279
some sort of tricky stuff there do you

00:45:21,329 --> 00:45:24,990
have this is the question to pantheon do

00:45:23,279 --> 00:45:27,539
you have this option available that's

00:45:24,990 --> 00:45:29,220
customers can turn off varnish do you

00:45:27,539 --> 00:45:31,319
have such customers you can always send

00:45:29,220 --> 00:45:34,730
headers to pantheons edge that cause it

00:45:31,319 --> 00:45:38,279
to not cash and then rely exclusive go

00:45:34,730 --> 00:45:39,930
upstream 2cd amisom yes and then general

00:45:38,279 --> 00:45:41,910
generally you can configure CD ins in

00:45:39,930 --> 00:45:44,130
various ways where you configure how

00:45:41,910 --> 00:45:46,559
they choose their caching decisions and

00:45:44,130 --> 00:45:48,029
choose a way where you can indicate the

00:45:46,559 --> 00:45:50,700
CDN that you want to cash even though

00:45:48,029 --> 00:45:53,670
you don't tell Pantheon akin cash we

00:45:50,700 --> 00:45:55,829
actually have one huge website that I

00:45:53,670 --> 00:45:57,539
don't want to name that is doing that

00:45:55,829 --> 00:45:59,609
exact model on Pantheon where they

00:45:57,539 --> 00:46:02,910
basically tell pantheons edge just pass

00:45:59,609 --> 00:46:04,529
it through and then they use a CDN for

00:46:02,910 --> 00:46:06,359
their real caching and then they do deep

00:46:04,529 --> 00:46:08,640
integration with the CDN for

00:46:06,359 --> 00:46:10,319
invalidation and what is the reason that

00:46:08,640 --> 00:46:13,589
they chose it this way like you

00:46:10,319 --> 00:46:16,170
completely skip I think if you could so

00:46:13,589 --> 00:46:17,700
I think if you're willing to do all the

00:46:16,170 --> 00:46:19,920
deep integration with the CDN to handle

00:46:17,700 --> 00:46:22,140
your invalidation there and you're

00:46:19,920 --> 00:46:24,750
willing to pay for a CDN and you have

00:46:22,140 --> 00:46:27,180
access to that and people qualified to

00:46:24,750 --> 00:46:28,950
configure it then

00:46:27,180 --> 00:46:32,700
it's technically a more scalable

00:46:28,950 --> 00:46:34,170
solution and if you're I wouldn't

00:46:32,700 --> 00:46:36,900
recommend trying to deeply integrate

00:46:34,170 --> 00:46:38,550
with both pantheons cash and a CDN cash

00:46:36,900 --> 00:46:40,619
you should probably pick one of the

00:46:38,550 --> 00:46:42,900
other you should either do a patch does

00:46:40,619 --> 00:46:46,290
right now which is like CDN only for

00:46:42,900 --> 00:46:48,390
very short periods of time or do what

00:46:46,290 --> 00:46:50,309
that other site does and pantheons edge

00:46:48,390 --> 00:46:52,920
either for very short periods of time or

00:46:50,309 --> 00:46:55,650
nothing and then control the cash in the

00:46:52,920 --> 00:46:57,990
CDN and one last question do you guys

00:46:55,650 --> 00:47:00,480
all for custom varnish configurations we

00:46:57,990 --> 00:47:02,309
don't our typical approach is actually

00:47:00,480 --> 00:47:03,480
very similar to the direction that fast

00:47:02,309 --> 00:47:06,180
Lee's been moving with configuration

00:47:03,480 --> 00:47:08,790
which is putting more of it as

00:47:06,180 --> 00:47:11,579
standardized in band headers where

00:47:08,790 --> 00:47:13,920
basically you specify as much as

00:47:11,579 --> 00:47:17,099
possible using standard HTTP spec and

00:47:13,920 --> 00:47:20,609
then from there with some extensions to

00:47:17,099 --> 00:47:23,369
what standard HTTP specs specifies and

00:47:20,609 --> 00:47:26,220
then on the page you can inform the cash

00:47:23,369 --> 00:47:28,530
how to behave so for example in pantheon

00:47:26,220 --> 00:47:30,480
you can tell the edge cash to keep

00:47:28,530 --> 00:47:32,730
Ursa's various cookies for that content

00:47:30,480 --> 00:47:34,230
and then the cash will know that you

00:47:32,730 --> 00:47:35,849
will deliver different pieces of content

00:47:34,230 --> 00:47:38,339
depending on the cookie that the person

00:47:35,849 --> 00:47:40,950
comes in with but that's all handled in

00:47:38,339 --> 00:47:42,569
band and then for people who come to us

00:47:40,950 --> 00:47:44,880
and ask how do I do how can I handle

00:47:42,569 --> 00:47:46,589
this custom vcl case we sort of roll

00:47:44,880 --> 00:47:48,690
back and say well what are you trying to

00:47:46,589 --> 00:47:51,059
actually accomplish in terms of your

00:47:48,690 --> 00:47:52,710
caching strategy and we will see if we

00:47:51,059 --> 00:47:55,950
can map that to what we have already and

00:47:52,710 --> 00:47:57,599
if not we will consider is there a way

00:47:55,950 --> 00:48:00,030
we can allow customers to configure this

00:47:57,599 --> 00:48:02,940
in band to satisfy this use case without

00:48:00,030 --> 00:48:04,619
introducing custom vcl then again if you

00:48:02,940 --> 00:48:07,049
need custom vcl that's something that

00:48:04,619 --> 00:48:08,880
fastly provides so that would be the

00:48:07,049 --> 00:48:11,460
other kind of extended advice we would

00:48:08,880 --> 00:48:13,710
have is you can always disable any

00:48:11,460 --> 00:48:15,270
caching of pat pantheons edge and then

00:48:13,710 --> 00:48:18,450
implement something like fastly and then

00:48:15,270 --> 00:48:19,980
throw whatever vcl you want and i would

00:48:18,450 --> 00:48:21,240
add to that to that this is a good

00:48:19,980 --> 00:48:23,099
example of what you talked about with

00:48:21,240 --> 00:48:25,200
the engineering and depth too because

00:48:23,099 --> 00:48:27,780
even if you put a five-second TTL on

00:48:25,200 --> 00:48:30,540
pantheons edge you'd have a you'd have a

00:48:27,780 --> 00:48:35,430
fallback if something went askew on the

00:48:30,540 --> 00:48:36,220
outside end so so I where the best part

00:48:35,430 --> 00:48:38,290
of this

00:48:36,220 --> 00:48:40,890
so you were talking about how might take

00:48:38,290 --> 00:48:44,080
a long time to like get your

00:48:40,890 --> 00:48:46,150
configuration up to the CDN to allow

00:48:44,080 --> 00:48:48,160
certain past we on cash or like to

00:48:46,150 --> 00:48:50,320
configure SSL though if you going

00:48:48,160 --> 00:48:52,750
through something like Akamai how were

00:48:50,320 --> 00:48:57,490
you able to do this in two days if

00:48:52,750 --> 00:48:59,260
that's the case well with so you could

00:48:57,490 --> 00:49:02,290
do it self service with CloudFlare in

00:48:59,260 --> 00:49:03,940
two days and then with fastly you

00:49:02,290 --> 00:49:06,310
basically just email or call them and

00:49:03,940 --> 00:49:09,730
say I have to turn this out really

00:49:06,310 --> 00:49:12,420
quickly and they have people ready to do

00:49:09,730 --> 00:49:15,400
things like deploying certificates and

00:49:12,420 --> 00:49:17,770
readying their infrastructure ok and

00:49:15,400 --> 00:49:18,970
then how would the solution change if

00:49:17,770 --> 00:49:21,609
you were doing with something like

00:49:18,970 --> 00:49:23,230
e-commerce but the contents always going

00:49:21,609 --> 00:49:26,619
out there that are you doing with

00:49:23,230 --> 00:49:28,780
checkout process on my black friday well

00:49:26,619 --> 00:49:32,410
for most ecommerce sites with a checkout

00:49:28,780 --> 00:49:33,880
process its various i'll hit one unique

00:49:32,410 --> 00:49:35,530
thing for a e-commerce in a moment but

00:49:33,880 --> 00:49:37,030
mostly it's the same as the logged in

00:49:35,530 --> 00:49:38,890
user case where you still want to be

00:49:37,030 --> 00:49:43,060
cashing all these static assets like

00:49:38,890 --> 00:49:45,730
javascript CSS images etc and then only

00:49:43,060 --> 00:49:49,810
generating the actual page content on

00:49:45,730 --> 00:49:51,790
demand the Drupal 8.1 has introduced

00:49:49,810 --> 00:49:54,099
some things like big pipe that allow you

00:49:51,790 --> 00:49:55,450
to progressively render and deliver the

00:49:54,099 --> 00:49:58,830
page of the browser to speed up

00:49:55,450 --> 00:50:04,060
rendering for authenticated user cases

00:49:58,830 --> 00:50:05,080
which would be relevant to that the the

00:50:04,060 --> 00:50:07,570
other thing that I'll mentioned for

00:50:05,080 --> 00:50:08,800
e-commerce is when you implement a CDN

00:50:07,570 --> 00:50:10,720
you're basically implementing a man in

00:50:08,800 --> 00:50:12,670
the middle and you need to make sure

00:50:10,720 --> 00:50:14,320
that you don't miss any kind of

00:50:12,670 --> 00:50:16,570
compliance goals that you have where

00:50:14,320 --> 00:50:17,830
let's say you need to meet PCI if you're

00:50:16,570 --> 00:50:20,320
sending the credit card over that

00:50:17,830 --> 00:50:22,180
website and submitting it to your

00:50:20,320 --> 00:50:23,770
application that will go in the clear

00:50:22,180 --> 00:50:25,660
over the CDN because they have to

00:50:23,770 --> 00:50:27,780
terminate the encryption to do their

00:50:25,660 --> 00:50:29,920
caching and then re-encrypt back to you

00:50:27,780 --> 00:50:31,810
and you need to make sure they're rien

00:50:29,920 --> 00:50:34,980
Krypton back to you and that the CD in

00:50:31,810 --> 00:50:37,420
you're using is actually PCI compliant

00:50:34,980 --> 00:50:39,390
which both cloudflare and fast they are

00:50:37,420 --> 00:50:41,919
by the way

00:50:39,390 --> 00:50:44,739
my question was related to that as well

00:50:41,919 --> 00:50:46,749
how does the HTTPS termination work what

00:50:44,739 --> 00:50:49,119
does it happen it happens it happens at

00:50:46,749 --> 00:50:52,749
the CDN at the point of presence so the

00:50:49,119 --> 00:50:55,630
communication between the CDN and it is

00:50:52,749 --> 00:50:57,819
encrypted both both CloudFlare and

00:50:55,630 --> 00:51:06,729
fastly allow you to encrypt to the

00:50:57,819 --> 00:51:11,049
origin the it can it uses TLS okay well

00:51:06,729 --> 00:51:15,579
anymore microphone please just for

00:51:11,049 --> 00:51:17,410
recording purposes this does handle very

00:51:15,579 --> 00:51:18,549
well the anonymous user case but what

00:51:17,410 --> 00:51:20,140
percentage of your traffic is

00:51:18,549 --> 00:51:24,339
authenticated and what are your plans

00:51:20,140 --> 00:51:26,130
for scaling that on the front end of

00:51:24,339 --> 00:51:30,609
patch there is no authenticated traffic

00:51:26,130 --> 00:51:32,559
we have an authoring box where we do

00:51:30,609 --> 00:51:34,900
deal with our authenticated traffic and

00:51:32,559 --> 00:51:37,929
on a completely different architecture

00:51:34,900 --> 00:51:39,999
so that's the short answer to that

00:51:37,929 --> 00:51:45,189
question so is it just like your editors

00:51:39,999 --> 00:51:47,109
that are authenticated and oh words are

00:51:45,189 --> 00:51:48,640
different instants don't they are they

00:51:47,109 --> 00:51:50,079
connected back in Drupal right they

00:51:48,640 --> 00:51:51,849
guess they can electrically and they

00:51:50,079 --> 00:51:54,069
connect to the backend services box

00:51:51,849 --> 00:51:57,249
never through the front and they're

00:51:54,069 --> 00:52:01,919
about 40,000 active users currently

00:51:57,249 --> 00:52:04,509
authoring stuff 400,000 that we consider

00:52:01,919 --> 00:52:08,349
unsuspicious out of our six million

00:52:04,509 --> 00:52:11,529
total user objects the one thing also

00:52:08,349 --> 00:52:12,999
say is even cases that might seem to

00:52:11,529 --> 00:52:15,400
require authenticated users you can

00:52:12,999 --> 00:52:17,199
certainly play games where as far as

00:52:15,400 --> 00:52:18,969
Drupal and the CDN are concerned it's

00:52:17,199 --> 00:52:20,829
it's anonymous like if you just want to

00:52:18,969 --> 00:52:22,089
offer commenting on your website and you

00:52:20,829 --> 00:52:23,799
implement something like facebook

00:52:22,089 --> 00:52:25,359
comments disqus or something similar

00:52:23,799 --> 00:52:27,729
that doesn't require them to be

00:52:25,359 --> 00:52:29,679
authenticated to Drupal and so you can

00:52:27,729 --> 00:52:32,429
still hit all these edges while still

00:52:29,679 --> 00:52:36,579
providing some community interaction

00:52:32,429 --> 00:52:39,419
thank you okay I think we'll wrap it up

00:52:36,579 --> 00:52:39,419
thanks for coming

00:52:40,440 --> 00:52:46,240
just just the last question or would it

00:52:44,050 --> 00:52:49,390
be possible in the architecture like

00:52:46,240 --> 00:52:52,450
this so there's this authenticated users

00:52:49,390 --> 00:52:55,360
cash case is driving me to this question

00:52:52,450 --> 00:52:57,550
will be possible to configure weight

00:52:55,360 --> 00:52:59,920
through the CDN and the Pantheon edge to

00:52:57,550 --> 00:53:02,140
another caching instance like for

00:52:59,920 --> 00:53:05,560
example of cash or something like that

00:53:02,140 --> 00:53:09,670
possible cash accuses sorry what cashing

00:53:05,560 --> 00:53:12,070
off cash alt cash or off cash yeah yeah

00:53:09,670 --> 00:53:13,840
you that gizem gets into some pretty

00:53:12,070 --> 00:53:15,130
complicated use cases and you can do

00:53:13,840 --> 00:53:17,530
things the foreigners like edge site

00:53:15,130 --> 00:53:19,780
includes where you can integrate some

00:53:17,530 --> 00:53:23,470
cached pieces of content into an overall

00:53:19,780 --> 00:53:26,350
uncashed page I haven't worked it off

00:53:23,470 --> 00:53:28,630
cash in a while and I'll say why because

00:53:26,350 --> 00:53:30,190
I haven't found that many cases where

00:53:28,630 --> 00:53:31,720
it's really solved the problem and it

00:53:30,190 --> 00:53:34,390
definitely complicates the architecture

00:53:31,720 --> 00:53:36,820
of the site no question it's complicated

00:53:34,390 --> 00:53:40,600
or not but just if it's possible to

00:53:36,820 --> 00:53:43,600
configure a real separate way to catch

00:53:40,600 --> 00:53:46,270
autÃ³k authenticated traffic separated

00:53:43,600 --> 00:53:47,610
from the analytic oh I mean you can set

00:53:46,270 --> 00:53:50,170
cash rules to catch whatever you want

00:53:47,610 --> 00:53:51,640
but like authenticated traffic would be

00:53:50,170 --> 00:53:54,100
distinguished by at least the session

00:53:51,640 --> 00:53:56,050
and there's often not a lot of benefit

00:53:54,100 --> 00:53:57,580
and caching that is keyed by the session

00:53:56,050 --> 00:54:02,130
because you typically get low cash rates

00:53:57,580 --> 00:54:02,130
cache hit rates okay thank you

00:54:09,050 --> 00:54:15,579
thank you

00:54:11,569 --> 00:54:15,579

YouTube URL: https://www.youtube.com/watch?v=h1zmA0aqVLE


