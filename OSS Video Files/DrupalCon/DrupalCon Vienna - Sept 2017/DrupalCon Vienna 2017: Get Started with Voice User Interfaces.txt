Title: DrupalCon Vienna 2017: Get Started with Voice User Interfaces
Publication date: 2017-09-26
Playlist: DrupalCon Vienna - Sept 2017
Description: 
	From personal assistants to chatbots, to conversational devices in the home, voice user interfaces that make tasks easier, faster, or more fun are quickly finding ways into our daily lives. New Developer APIs and SDKs for voice-enabled services are being released more and more frequently, providing new opportunities for developers to learn new skills and companies to find new ways for customers to interact with their products and services. But these technologies are very much a new horizon in human-computer interaction and there is a lot to learn.

In this session, we’ll survey the current state of voice and conversational interface APIs, with an eye toward global language support. We’ll look at services such as Alexa, Google, and Cortana and look at their distinct features, the devices, platforms, and interactions they support, as well as what spoken languages they support. 

Then, we’ll dive into the voice design process, with questions you’ll want to consider as you think about how to add voice to an application. We’ll also look at important concepts and terminology in voice user interaction that you’ll need to understand in order to successfully build a custom voice “skill”.

Next, we’ll demonstrate a custom skill built for Alexa and how we integrated data from a Drupal site into it.

Finally, we’ll take a look at API.AI and how you can use this service to build a voice user interface and export it to a number of different conversational AI services.

By the end of this session, you will:

have a better understanding of the voice and conversational interface services landscape
get ideas for how to approach the voice user interface design process
understand concepts and terminology related to voice interaction
know how to get started exploring and developing custom voice interactions for existing and up-and-coming APIs
Captions: 
	00:00:00,030 --> 00:00:06,200
hello this is get started with voice

00:00:02,399 --> 00:00:08,970
user interfaces my name is amber Matz

00:00:06,200 --> 00:00:11,550
I'm the production manager and a trainer

00:00:08,970 --> 00:00:13,710
at gerbil ëismí and you can find me on

00:00:11,550 --> 00:00:18,990
Twitter especially if you're nice at

00:00:13,710 --> 00:00:21,000
amber Himes mass at replace me we

00:00:18,990 --> 00:00:23,699
provide online tutorials on both written

00:00:21,000 --> 00:00:25,769
and video formats our goal is to be the

00:00:23,699 --> 00:00:27,449
number one source of Drupal 8 training

00:00:25,769 --> 00:00:29,220
anywhere I just want to give a little

00:00:27,449 --> 00:00:32,599
plug because they're the reason that I'm

00:00:29,220 --> 00:00:32,599
able to come to events like this

00:00:34,610 --> 00:00:40,170
in today's episode first I'm going to

00:00:38,040 --> 00:00:42,090
start out with a survey of several voice

00:00:40,170 --> 00:00:44,670
UI platforms which should give you a

00:00:42,090 --> 00:00:47,039
good idea of what opportunities exist

00:00:44,670 --> 00:00:48,600
for you as a developer and which

00:00:47,039 --> 00:00:51,570
platform you might want to start out

00:00:48,600 --> 00:00:53,460
learning next I'll present some ideas

00:00:51,570 --> 00:00:57,780
you want to consider as you go through

00:00:53,460 --> 00:00:59,629
the voice UI design process and even

00:00:57,780 --> 00:01:02,250
though there are multiple voice UI

00:00:59,629 --> 00:01:05,640
platforms out there they share common

00:01:02,250 --> 00:01:08,960
concepts in their api's specifically

00:01:05,640 --> 00:01:11,340
taking from API AI and Alexa's

00:01:08,960 --> 00:01:13,860
implementations we'll look at concepts

00:01:11,340 --> 00:01:17,630
and terminology in voice UI development

00:01:13,860 --> 00:01:19,979
that you'll want to know and understand

00:01:17,630 --> 00:01:22,350
then I'll talk about end point

00:01:19,979 --> 00:01:24,570
fulfillment with a lean toward Drupal

00:01:22,350 --> 00:01:28,320
integration since we are at Drupal con

00:01:24,570 --> 00:01:30,180
and finally I've got a few quick fun

00:01:28,320 --> 00:01:33,600
demos to show you and then we should

00:01:30,180 --> 00:01:35,250
have time for questions by the end of

00:01:33,600 --> 00:01:39,150
this session you should have some

00:01:35,250 --> 00:01:41,430
direction on which UI voice platform you

00:01:39,150 --> 00:01:43,290
want to start learning and you'll have a

00:01:41,430 --> 00:01:46,979
head start on understanding the overall

00:01:43,290 --> 00:01:48,960
process and important concepts basically

00:01:46,979 --> 00:01:50,820
getting over that hump when you are

00:01:48,960 --> 00:01:53,729
looking into documentation and tutorials

00:01:50,820 --> 00:01:55,530
in relay okay what is this and you know

00:01:53,729 --> 00:01:57,659
just getting over that initial kind of

00:01:55,530 --> 00:02:02,060
knowledge and understanding so that you

00:01:57,659 --> 00:02:04,770
can just dive right in so you'll get a

00:02:02,060 --> 00:02:07,079
head start on the major concepts and

00:02:04,770 --> 00:02:08,849
process of voice UI implementation no

00:02:07,079 --> 00:02:10,470
matter which platform you decide to

00:02:08,849 --> 00:02:12,900
learn

00:02:10,470 --> 00:02:15,390
this talk is geared toward developers

00:02:12,900 --> 00:02:17,730
who want to know how to add voice to

00:02:15,390 --> 00:02:20,610
their applications the actual

00:02:17,730 --> 00:02:23,580
implementation of a voice UI requires an

00:02:20,610 --> 00:02:25,530
intermediate web or app developer

00:02:23,580 --> 00:02:28,680
background which here means the ability

00:02:25,530 --> 00:02:31,230
to copy and paste example code and

00:02:28,680 --> 00:02:35,010
modify it to your needs and follow

00:02:31,230 --> 00:02:37,710
directions in a tutorial so it's not too

00:02:35,010 --> 00:02:41,130
hard to get started basically in essence

00:02:37,710 --> 00:02:44,520
you are standard nerds so welcome and

00:02:41,130 --> 00:02:46,200
thank you for coming the voice UI

00:02:44,520 --> 00:02:48,540
development is really quite an

00:02:46,200 --> 00:02:50,580
accessible process and the companies

00:02:48,540 --> 00:02:52,890
that are involved with this are eager to

00:02:50,580 --> 00:02:56,070
make it relatively easy for developers

00:02:52,890 --> 00:02:58,050
to add voice to their projects so let's

00:02:56,070 --> 00:03:01,350
get started I've got a lot to tell you

00:02:58,050 --> 00:03:06,150
about today the emerging players in this

00:03:01,350 --> 00:03:08,730
space are Alexa Google API AI Cortana

00:03:06,150 --> 00:03:12,209
and Siri but that's not all of them

00:03:08,730 --> 00:03:15,989
those are just the major ones let's

00:03:12,209 --> 00:03:18,840
start out with Alexa the purpose of

00:03:15,989 --> 00:03:21,480
Alexa it lets you build custom voice

00:03:18,840 --> 00:03:25,590
skills that's their word for Alexa

00:03:21,480 --> 00:03:27,989
enabled devices or integrate Alexa into

00:03:25,590 --> 00:03:30,810
your connected product the company

00:03:27,989 --> 00:03:33,959
behind it is Amazon and the hosting

00:03:30,810 --> 00:03:38,489
options include AWS lambda or any

00:03:33,959 --> 00:03:41,519
internet accessible endpoint the devices

00:03:38,489 --> 00:03:44,070
that Alexa skills support are any device

00:03:41,519 --> 00:03:47,610
in the echo family the Kindle Fire is

00:03:44,070 --> 00:03:50,400
coming with Alexa enabled and any other

00:03:47,610 --> 00:03:52,019
Alexa enable connected device so one

00:03:50,400 --> 00:03:55,680
that you might build yourself or any

00:03:52,019 --> 00:03:58,049
other one you get the custom skilled app

00:03:55,680 --> 00:04:01,440
distribution happens in the Alexus store

00:03:58,049 --> 00:04:03,360
the end user installs it via the Alexa

00:04:01,440 --> 00:04:06,299
app so it's something that the end user

00:04:03,360 --> 00:04:12,180
needs to install and enable for their

00:04:06,299 --> 00:04:15,930
device localization and language support

00:04:12,180 --> 00:04:20,160
includes there are only three region and

00:04:15,930 --> 00:04:21,510
language combinations that are supported

00:04:20,160 --> 00:04:24,090
with Alexa and

00:04:21,510 --> 00:04:30,150
it's English in the US English in the UK

00:04:24,090 --> 00:04:32,340
or German in Germany the state of

00:04:30,150 --> 00:04:35,720
developers support as I've experienced

00:04:32,340 --> 00:04:40,500
it there's a very nice skill building UI

00:04:35,720 --> 00:04:43,620
there are docs code samples there's an

00:04:40,500 --> 00:04:46,410
Alexa github account an API reference

00:04:43,620 --> 00:04:49,920
there are videos that will walk you

00:04:46,410 --> 00:04:53,010
through step by step how to use the UI

00:04:49,920 --> 00:04:56,550
as well as concepts that you should know

00:04:53,010 --> 00:04:58,850
about there's a variety of SDKs in a

00:04:56,550 --> 00:05:01,260
variety of different languages and

00:04:58,850 --> 00:05:05,520
overall I felt like it was a positive

00:05:01,260 --> 00:05:07,320
testing and publishing experience you

00:05:05,520 --> 00:05:10,860
can find out more about building an

00:05:07,320 --> 00:05:13,590
Alexis skill at developer.samsung.com

00:05:10,860 --> 00:05:15,900
slash Alexa there's also a new thing

00:05:13,590 --> 00:05:18,390
called the Alexa voice service and so

00:05:15,900 --> 00:05:20,490
you can see the URL there if you want to

00:05:18,390 --> 00:05:23,160
learn more about Alexa's voice service

00:05:20,490 --> 00:05:25,800
and that's adding Alexa to your

00:05:23,160 --> 00:05:31,200
connected device so more it's a

00:05:25,800 --> 00:05:33,420
different type of implementation next we

00:05:31,200 --> 00:05:36,180
have the Google assistant and actions on

00:05:33,420 --> 00:05:38,820
Google which are related in that Google

00:05:36,180 --> 00:05:41,430
actions let you build apps for the

00:05:38,820 --> 00:05:43,980
Google assistant so the Google assistant

00:05:41,430 --> 00:05:47,100
is going to hear the request from the

00:05:43,980 --> 00:05:49,920
user and if the user requests to hear

00:05:47,100 --> 00:05:54,270
from a specific UI they're gonna pass

00:05:49,920 --> 00:05:56,520
that request to your app and then you'll

00:05:54,270 --> 00:05:59,100
your app will handle the conversation

00:05:56,520 --> 00:06:03,420
until they're done and it passes it back

00:05:59,100 --> 00:06:06,380
to the Google assistant obviously the

00:06:03,420 --> 00:06:09,210
company behind it is Google the hosting

00:06:06,380 --> 00:06:12,390
options are cloud functions for firebase

00:06:09,210 --> 00:06:15,030
which these first two the Google cloud

00:06:12,390 --> 00:06:16,770
and the and the firebase are both kind

00:06:15,030 --> 00:06:18,510
of the easiest path to get started

00:06:16,770 --> 00:06:20,820
that's what's included in the tutorials

00:06:18,510 --> 00:06:22,290
but any internet accessible endpoint

00:06:20,820 --> 00:06:25,520
you'll see that is a common theme

00:06:22,290 --> 00:06:25,520
throughout all of these platforms

00:06:25,580 --> 00:06:31,170
these these apps will work with the

00:06:28,980 --> 00:06:33,570
google home device and any google

00:06:31,170 --> 00:06:35,460
assistant enabled device so any device

00:06:33,570 --> 00:06:39,000
that has google assistant on it

00:06:35,460 --> 00:06:42,000
will your app will potentially be

00:06:39,000 --> 00:06:47,330
available on it depending on language

00:06:42,000 --> 00:06:50,340
and region configurations of the user

00:06:47,330 --> 00:06:53,790
the app distribution is different than

00:06:50,340 --> 00:06:56,370
Alexis it's automatically distributed to

00:06:53,790 --> 00:07:00,120
Google assistant and enabled devices the

00:06:56,370 --> 00:07:02,160
user doesn't have to install or doesn't

00:07:00,120 --> 00:07:05,910
even isn't even given the option of

00:07:02,160 --> 00:07:07,950
installing or enabling a specific app so

00:07:05,910 --> 00:07:12,630
it's just automatically pushed out to

00:07:07,950 --> 00:07:15,930
any relevant user the localization and

00:07:12,630 --> 00:07:18,510
language support is kind of hard to pin

00:07:15,930 --> 00:07:21,000
down it's really dependent on the user's

00:07:18,510 --> 00:07:22,880
regional settings there's a lot of

00:07:21,000 --> 00:07:25,860
complaining in the in the forums about

00:07:22,880 --> 00:07:28,590
not being able to use Google assistant

00:07:25,860 --> 00:07:31,740
in more than one language and/or region

00:07:28,590 --> 00:07:34,920
so there's that kind of muddy water but

00:07:31,740 --> 00:07:36,690
if you use API AI to build your agent

00:07:34,920 --> 00:07:41,520
then there are fifteen languages

00:07:36,690 --> 00:07:43,800
supported which are these listed here so

00:07:41,520 --> 00:07:46,050
this is a lot potentially a lot broader

00:07:43,800 --> 00:07:50,970
support than what you might have with

00:07:46,050 --> 00:07:53,430
Alexa the state of developer support

00:07:50,970 --> 00:07:56,370
they are eager to get developers on

00:07:53,430 --> 00:07:58,110
board with them seeing with Amazon they

00:07:56,370 --> 00:08:01,080
have an agent building UI

00:07:58,110 --> 00:08:04,320
which is through API dot AI which I will

00:08:01,080 --> 00:08:07,950
get to in a minute an API ai's console

00:08:04,320 --> 00:08:10,680
is excellent as you might expect they

00:08:07,950 --> 00:08:13,620
have Doc's code samples they also have a

00:08:10,680 --> 00:08:16,110
github account with code examples for

00:08:13,620 --> 00:08:20,040
your endpoint development links to API

00:08:16,110 --> 00:08:24,160
references and plenty of SDKs there are

00:08:20,040 --> 00:08:26,470
video walkthroughs and concept tutorials

00:08:24,160 --> 00:08:29,440
and like I said a variety of des decays

00:08:26,470 --> 00:08:34,210
tools for building out your voice UI and

00:08:29,440 --> 00:08:37,539
hosting options and via the API dot a i

00:08:34,210 --> 00:08:40,240
console there are there is in-app as you

00:08:37,539 --> 00:08:45,130
go testing which is really nice as well

00:08:40,240 --> 00:08:46,030
as in point fulfillment testing so you

00:08:45,130 --> 00:08:49,330
can find out more at

00:08:46,030 --> 00:08:50,710
developers.google.com slash actions

00:08:49,330 --> 00:08:53,800
which is where i would recommend that

00:08:50,710 --> 00:08:58,650
you start and you can find out more

00:08:53,800 --> 00:09:00,940
about the google assistant sdk SDKs at

00:08:58,650 --> 00:09:03,340
developers.google.com/plus tint slash

00:09:00,940 --> 00:09:07,420
sdk but I would start with actions on

00:09:03,340 --> 00:09:09,460
Google which looks like that right now

00:09:07,420 --> 00:09:14,680
today the other day when I made that

00:09:09,460 --> 00:09:18,130
screenshot all right API dot AI its

00:09:14,680 --> 00:09:21,370
purpose is to build a unified API and UI

00:09:18,130 --> 00:09:25,210
to build conversational voice or chat

00:09:21,370 --> 00:09:28,660
bot apps and deploy to deploy that to

00:09:25,210 --> 00:09:31,360
one or many platforms so they want to

00:09:28,660 --> 00:09:32,770
solve this problem of okay that this

00:09:31,360 --> 00:09:34,960
space is emerging there's lots of

00:09:32,770 --> 00:09:39,280
companies jumping in let's build a

00:09:34,960 --> 00:09:42,820
unified API that people can use build

00:09:39,280 --> 00:09:45,330
their UI their agent as their term is

00:09:42,820 --> 00:09:49,600
once and then you could deploy that to

00:09:45,330 --> 00:09:54,010
any number of platforms google recently

00:09:49,600 --> 00:09:56,140
acquired them in 2016 so they're the

00:09:54,010 --> 00:09:59,110
tutorials on actions on Google are going

00:09:56,140 --> 00:10:01,270
to reference API AI and vice versa so

00:09:59,110 --> 00:10:04,000
you're gonna find the easiest path to

00:10:01,270 --> 00:10:07,990
get started with actions on Google or

00:10:04,000 --> 00:10:09,700
API AI is to use those two platforms in

00:10:07,990 --> 00:10:12,970
tandem but you're not limited to that

00:10:09,700 --> 00:10:14,560
that's a good way to get started I would

00:10:12,970 --> 00:10:17,890
say it's just as easy to get started

00:10:14,560 --> 00:10:19,270
with actions on Google and API AI as it

00:10:17,890 --> 00:10:22,750
is to get started with building an

00:10:19,270 --> 00:10:26,380
Alexis skill same kind of level of UI

00:10:22,750 --> 00:10:28,210
and tools and documentation I would say

00:10:26,380 --> 00:10:31,210
it's if you want to get started start

00:10:28,210 --> 00:10:33,190
with one of those two the hosting an app

00:10:31,210 --> 00:10:35,310
distribution depends on the integration

00:10:33,190 --> 00:10:37,260
like what your final point

00:10:35,310 --> 00:10:40,410
is where you're going to push that out

00:10:37,260 --> 00:10:43,410
too and the integrations are many there

00:10:40,410 --> 00:10:47,730
is actions on Google facebook Messenger

00:10:43,410 --> 00:10:51,360
kick line Skype slack Cisco spark

00:10:47,730 --> 00:10:53,700
telegram Cisco troppo Twilio Twilio IP

00:10:51,360 --> 00:10:56,370
Twitter and viber half of these I've

00:10:53,700 --> 00:10:58,650
never even heard of before so there are

00:10:56,370 --> 00:11:04,950
lots of options not just voice but also

00:10:58,650 --> 00:11:08,040
chat bot API AI says in their Docs

00:11:04,950 --> 00:11:10,680
voice interface is cross-platform your

00:11:08,040 --> 00:11:12,720
agent will understand your users no

00:11:10,680 --> 00:11:15,089
matter what device you're using you

00:11:12,720 --> 00:11:18,510
design the interaction scenarios just

00:11:15,089 --> 00:11:21,360
once currently we have SDKs for all most

00:11:18,510 --> 00:11:22,620
popular platforms and more to come so

00:11:21,360 --> 00:11:25,500
they're really looking to become the

00:11:22,620 --> 00:11:28,890
leader in voice UI development and

00:11:25,500 --> 00:11:31,950
really simplify the process of whether

00:11:28,890 --> 00:11:33,720
you're doing a chatbot implementation or

00:11:31,950 --> 00:11:36,240
you want to add voice to that they're

00:11:33,720 --> 00:11:40,230
trying to make that a simpler process

00:11:36,240 --> 00:11:42,089
more streamlined and the localization

00:11:40,230 --> 00:11:44,160
and language support depends on your

00:11:42,089 --> 00:11:46,260
integration but like I mentioned before

00:11:44,160 --> 00:11:49,470
on the actions on Google 15 languages

00:11:46,260 --> 00:11:52,170
are supported and when you first create

00:11:49,470 --> 00:11:54,300
your agent you'll select a language so

00:11:52,170 --> 00:11:56,940
you will need to create an agent for

00:11:54,300 --> 00:12:00,210
each language you want to support so

00:11:56,940 --> 00:12:02,460
which is a you know it makes sense

00:12:00,210 --> 00:12:06,030
because if you had a multilingual site

00:12:02,460 --> 00:12:08,040
for example you can set up endpoints at

00:12:06,030 --> 00:12:09,870
the different languages that you're

00:12:08,040 --> 00:12:12,420
supporting for each of your agents so

00:12:09,870 --> 00:12:15,330
all else being equal and you can also

00:12:12,420 --> 00:12:17,990
set up responses that are particular to

00:12:15,330 --> 00:12:20,660
a certain language so there are 15

00:12:17,990 --> 00:12:23,339
languages supported at this time and

00:12:20,660 --> 00:12:26,610
from what I read like this is one of the

00:12:23,339 --> 00:12:29,430
areas multilingual support in voice it's

00:12:26,610 --> 00:12:30,959
it's a really like of course there needs

00:12:29,430 --> 00:12:33,300
to be multilingual support we're talking

00:12:30,959 --> 00:12:35,100
about conversational interfaces and

00:12:33,300 --> 00:12:37,830
people speak in many many different

00:12:35,100 --> 00:12:40,980
languages certainly not limited to these

00:12:37,830 --> 00:12:43,980
15 and so this is just what the state is

00:12:40,980 --> 00:12:46,579
right now and I think we can look to see

00:12:43,980 --> 00:12:50,149
this bro over the you know

00:12:46,579 --> 00:12:52,790
the coming years here the state of

00:12:50,149 --> 00:12:55,279
developer support there is a very good

00:12:52,790 --> 00:12:59,179
agent building you I I even like it

00:12:55,279 --> 00:13:01,699
better than the Alexa you I the there's

00:12:59,179 --> 00:13:04,220
Docs samples and API reference sometimes

00:13:01,699 --> 00:13:06,619
that takes back to the actions on Google

00:13:04,220 --> 00:13:08,569
but they still have a good set of

00:13:06,619 --> 00:13:11,209
documentation just on their own and an

00:13:08,569 --> 00:13:13,670
excellent API reference and there are

00:13:11,209 --> 00:13:17,420
videos but that's again via Google

00:13:13,670 --> 00:13:19,009
actions and a variety of SDKs supporting

00:13:17,420 --> 00:13:22,189
a number of languages so you don't need

00:13:19,009 --> 00:13:25,759
to be a node expert you there's even a

00:13:22,189 --> 00:13:28,850
PHP SDK which I'll talk about later and

00:13:25,759 --> 00:13:31,639
as I mentioned the in-app and testing is

00:13:28,850 --> 00:13:34,879
really nice to have because you don't

00:13:31,639 --> 00:13:36,259
have to finish everything and then you

00:13:34,879 --> 00:13:38,209
know and wait until you're pretty much

00:13:36,259 --> 00:13:41,239
done before testing you can test as you

00:13:38,209 --> 00:13:43,279
go and really that's an encouragement to

00:13:41,239 --> 00:13:45,709
do that and they show you how to do that

00:13:43,279 --> 00:13:48,649
in the tutorials so just makes the

00:13:45,709 --> 00:13:50,179
process a lot easier and it helps you as

00:13:48,649 --> 00:13:52,699
you're testing understand what it is

00:13:50,179 --> 00:13:55,160
that you're actually doing because a lot

00:13:52,699 --> 00:13:56,600
of us haven't done voice UI building

00:13:55,160 --> 00:13:59,029
before ends like what am I doing here

00:13:56,600 --> 00:14:02,230
how is this gonna work so the testing in

00:13:59,029 --> 00:14:05,899
in the in the interface is really nice

00:14:02,230 --> 00:14:09,679
so you can find out more at API ji and

00:14:05,899 --> 00:14:12,350
go to slash Doc's slash SDKs to see

00:14:09,679 --> 00:14:15,439
which software is is currently supported

00:14:12,350 --> 00:14:17,629
and then you'll notice that there is

00:14:15,439 --> 00:14:19,939
this relationship this tight

00:14:17,629 --> 00:14:22,369
relationship between Google actions and

00:14:19,939 --> 00:14:25,279
so you can also find tutorials on the

00:14:22,369 --> 00:14:32,720
actions on Google site that walk through

00:14:25,279 --> 00:14:37,669
the API ji user interface I wanted to

00:14:32,720 --> 00:14:42,439
also mention Cortana Cortana purpose is

00:14:37,669 --> 00:14:47,149
to add voice ie Cortana whoa stop

00:14:42,439 --> 00:14:51,470
so we're oh that is why I'm not buying

00:14:47,149 --> 00:14:54,199
their service add voice Cortana and

00:14:51,470 --> 00:14:56,779
cognitive intelligence - and this is the

00:14:54,199 --> 00:14:59,990
catch an existing bot built on the

00:14:56,779 --> 00:15:01,970
Microsoft bot framework is anyone here

00:14:59,990 --> 00:15:04,459
building bots on the Microsoft bot

00:15:01,970 --> 00:15:05,750
framework I didn't think so

00:15:04,459 --> 00:15:08,390
which is why we're just gonna keep

00:15:05,750 --> 00:15:12,050
moving on here hosting options are

00:15:08,390 --> 00:15:13,040
either or if you're really fancy Azur I

00:15:12,050 --> 00:15:16,310
don't really know how they're saying

00:15:13,040 --> 00:15:18,830
that or any internet accessible endpoint

00:15:16,310 --> 00:15:22,600
and the device is supported our Windows

00:15:18,830 --> 00:15:26,810
10 Android iOS and this new fancy thing

00:15:22,600 --> 00:15:28,640
called the Harman Kardon invoke so

00:15:26,810 --> 00:15:30,980
that's a new thing that's like coming

00:15:28,640 --> 00:15:33,950
out like now I guess so it's another

00:15:30,980 --> 00:15:37,700
headless device and so that's gonna be

00:15:33,950 --> 00:15:40,370
the cortana one app distribution is via

00:15:37,700 --> 00:15:43,640
Bing I'm just gonna leave it at that

00:15:40,370 --> 00:15:46,220
and the localization and language

00:15:43,640 --> 00:15:48,170
support they say Cortana's optimize for

00:15:46,220 --> 00:15:50,330
specific language and market pairings

00:15:48,170 --> 00:15:52,100
she works best when you're region and

00:15:50,330 --> 00:15:56,810
language settings are aligned obviously

00:15:52,100 --> 00:15:59,149
but I will say that there are there's a

00:15:56,810 --> 00:16:02,870
nice combination of language and regions

00:15:59,149 --> 00:16:04,010
supported here and there's some outliers

00:16:02,870 --> 00:16:06,290
you know there's some differences

00:16:04,010 --> 00:16:09,860
between what's supported with API AI

00:16:06,290 --> 00:16:13,250
even so I think that you know there

00:16:09,860 --> 00:16:16,220
might be a use case here if your client

00:16:13,250 --> 00:16:18,740
you know is in a certain market and you

00:16:16,220 --> 00:16:20,450
need to support Windows then I feel like

00:16:18,740 --> 00:16:21,920
it's a valid thing however I will tell

00:16:20,450 --> 00:16:24,130
you that right now the state of

00:16:21,920 --> 00:16:27,680
developer support it's in public preview

00:16:24,130 --> 00:16:31,040
so which means it's very limited and

00:16:27,680 --> 00:16:33,290
it's limited to adding voice to a bot

00:16:31,040 --> 00:16:35,870
built on Microsoft's bot framework so

00:16:33,290 --> 00:16:38,240
there's kind of yeah I'm just gonna

00:16:35,870 --> 00:16:41,060
leave it at that so that's just an FYI

00:16:38,240 --> 00:16:47,420
for you and you can find out more on the

00:16:41,060 --> 00:16:49,579
developer Microsoft site finally Siri I

00:16:47,420 --> 00:16:52,430
just want to let you know about Siri

00:16:49,579 --> 00:16:54,620
there's sirikit which enables your iOS

00:16:52,430 --> 00:16:57,470
apps and watch OS apps to work with Siri

00:16:54,620 --> 00:17:01,040
and then there's home kit because voice

00:16:57,470 --> 00:17:03,230
is really applicable especially to you

00:17:01,040 --> 00:17:05,270
know in the home right it's the whole

00:17:03,230 --> 00:17:07,100
the whole problem of someone is sitting

00:17:05,270 --> 00:17:08,630
on their couch and they don't want to

00:17:07,100 --> 00:17:12,390
get up and do something they want to

00:17:08,630 --> 00:17:15,120
like boss around this device and so

00:17:12,390 --> 00:17:18,630
really the homekit stuff is is relevant

00:17:15,120 --> 00:17:20,040
for that obviously it's about apples

00:17:18,630 --> 00:17:21,569
behind it and there and the reason why

00:17:20,040 --> 00:17:23,699
I'm mentioning it to you today just

00:17:21,569 --> 00:17:26,640
briefly is that they've recently

00:17:23,699 --> 00:17:29,520
announced home pod which is there

00:17:26,640 --> 00:17:32,429
headless device so home pod will have

00:17:29,520 --> 00:17:33,929
more people query theory okay so if you

00:17:32,429 --> 00:17:36,179
want to get in if you are an apple

00:17:33,929 --> 00:17:38,630
developer or if you are thinking about

00:17:36,179 --> 00:17:41,670
getting into that sort of thing just

00:17:38,630 --> 00:17:43,500
just know that there is Siri kit and

00:17:41,670 --> 00:17:45,030
home kit and there's going to be this

00:17:43,500 --> 00:17:47,429
home pod device so there might be some

00:17:45,030 --> 00:17:50,040
opportunities there I don't really know

00:17:47,429 --> 00:17:52,200
the extent of the localization and

00:17:50,040 --> 00:17:55,580
language support although I did find out

00:17:52,200 --> 00:17:59,250
that the home pod is only supported in

00:17:55,580 --> 00:18:01,890
English in the US UK on Australia so

00:17:59,250 --> 00:18:05,340
there you go if you want to find out

00:18:01,890 --> 00:18:07,440
more you can go there there are some

00:18:05,340 --> 00:18:09,620
open source options and perhaps I'm

00:18:07,440 --> 00:18:12,000
remiss and not talking more about them

00:18:09,620 --> 00:18:14,750
Mycroft and Jasper's sound like really

00:18:12,000 --> 00:18:16,919
interesting things to talk about and

00:18:14,750 --> 00:18:18,600
they sound like great topics for a

00:18:16,919 --> 00:18:22,830
future presentation but I'm not going to

00:18:18,600 --> 00:18:25,110
cover them today designing a voice user

00:18:22,830 --> 00:18:27,960
interface or a conversational app is a

00:18:25,110 --> 00:18:29,460
new experience for many of us so first

00:18:27,960 --> 00:18:31,890
let's take a look at what we can learn

00:18:29,460 --> 00:18:36,210
about normal human conversations with

00:18:31,890 --> 00:18:39,120
some conversation basics we take turns

00:18:36,210 --> 00:18:41,429
and conversations based on subtle cues

00:18:39,120 --> 00:18:44,299
that often include nonverbal

00:18:41,429 --> 00:18:46,919
conversation so how can we design

00:18:44,299 --> 00:18:50,580
human-computer conversation that makes

00:18:46,919 --> 00:18:55,860
it clear whose turn it is to talk like

00:18:50,580 --> 00:19:00,090
how do we program no you go you know how

00:18:55,860 --> 00:19:03,210
do we do that as we converse we keep

00:19:00,090 --> 00:19:05,540
track and we weave together all elements

00:19:03,210 --> 00:19:08,549
of a conversation including the context

00:19:05,540 --> 00:19:10,520
taking words and phrases out of context

00:19:08,549 --> 00:19:13,440
is a classic way to introduce

00:19:10,520 --> 00:19:15,630
misunderstanding so how do we design a

00:19:13,440 --> 00:19:18,120
conversation that will keep track of

00:19:15,630 --> 00:19:20,220
what's being said without getting lost

00:19:18,120 --> 00:19:22,169
and without it can people feel like

00:19:20,220 --> 00:19:24,350
what's being said is just over their

00:19:22,169 --> 00:19:26,880
head

00:19:24,350 --> 00:19:29,040
human conversation is naturally

00:19:26,880 --> 00:19:31,350
efficient we often read between the

00:19:29,040 --> 00:19:34,530
lines and leave certain things unspoken

00:19:31,350 --> 00:19:36,390
this is often dependent on trust and the

00:19:34,530 --> 00:19:39,330
nature of the relationship between the

00:19:36,390 --> 00:19:41,430
people talking how do we compensate for

00:19:39,330 --> 00:19:47,850
our human tendency to leave things

00:19:41,430 --> 00:19:50,190
unspoken in code we use different

00:19:47,850 --> 00:19:52,740
phrases to mean the same thing all of

00:19:50,190 --> 00:19:54,960
the time the context and state of the

00:19:52,740 --> 00:19:57,690
conversation often influences our

00:19:54,960 --> 00:19:59,940
response if we're talking to a person in

00:19:57,690 --> 00:20:02,010
authority and we're in trouble we might

00:19:59,940 --> 00:20:05,460
give an affirmative response using more

00:20:02,010 --> 00:20:07,980
formal language such as yes sir whereas

00:20:05,460 --> 00:20:09,690
if a co-worker asked us in slack if we

00:20:07,980 --> 00:20:10,980
can do something or do a favor for them

00:20:09,690 --> 00:20:13,710
we might reply you bet

00:20:10,980 --> 00:20:15,210
and there were saying the same thing but

00:20:13,710 --> 00:20:18,210
we're saying it completely differently

00:20:15,210 --> 00:20:20,340
so how can our app learn about all the

00:20:18,210 --> 00:20:23,360
different ways our user might respond

00:20:20,340 --> 00:20:23,360
without getting confused

00:20:24,620 --> 00:20:29,520
humans can usually spot and repair

00:20:27,300 --> 00:20:31,890
mistakes or misunderstanding in a

00:20:29,520 --> 00:20:35,130
conversation so how can we allow for

00:20:31,890 --> 00:20:37,260
that and I'll allow for an program for

00:20:35,130 --> 00:20:40,170
correction and conversation repair

00:20:37,260 --> 00:20:43,530
without returning a lazy invalid

00:20:40,170 --> 00:20:45,900
response or other an graceful error how

00:20:43,530 --> 00:20:48,660
can we design conversations that can get

00:20:45,900 --> 00:20:53,190
back on track is there in any way

00:20:48,660 --> 00:20:55,590
function a voice user interface should

00:20:53,190 --> 00:20:57,660
try and follow the rules of cooperative

00:20:55,590 --> 00:20:59,820
conversation a set of principles

00:20:57,660 --> 00:21:02,550
popularized by linguistics professor

00:20:59,820 --> 00:21:06,840
Paul Grice and should try to follow

00:21:02,550 --> 00:21:10,470
these basic rules be truthful be

00:21:06,840 --> 00:21:14,490
informative be relevant be as clear as

00:21:10,470 --> 00:21:20,520
possible ensure develop a killer voice

00:21:14,490 --> 00:21:22,530
UI just not literally well it's fine to

00:21:20,520 --> 00:21:24,300
start out with a few contrived examples

00:21:22,530 --> 00:21:26,760
to learn the process which I certainly

00:21:24,300 --> 00:21:29,070
have done to become a really excellent

00:21:26,760 --> 00:21:31,800
voice UI designer you want to choose

00:21:29,070 --> 00:21:33,290
projects where adding voice will make

00:21:31,800 --> 00:21:37,640
the task

00:21:33,290 --> 00:21:39,440
faster easier or more fun we're not here

00:21:37,640 --> 00:21:43,130
to make people's lives more cumbersome

00:21:39,440 --> 00:21:45,530
tedious or downright miserable are we so

00:21:43,130 --> 00:21:47,480
what's faster setting a timer by walking

00:21:45,530 --> 00:21:50,000
over to the microwave and setting it or

00:21:47,480 --> 00:21:52,600
saying Alexa set a timer for three

00:21:50,000 --> 00:21:55,100
minutes from anywhere in the room

00:21:52,600 --> 00:21:57,650
thinking about making a task easier

00:21:55,100 --> 00:21:59,270
think about how someone might usually

00:21:57,650 --> 00:22:01,670
perform a task with their hands and

00:21:59,270 --> 00:22:04,220
needing to view a screen how might that

00:22:01,670 --> 00:22:08,000
task be made easier through a hands-free

00:22:04,220 --> 00:22:09,830
eyes-free voice request maybe even think

00:22:08,000 --> 00:22:12,980
in terms of how to make a task more

00:22:09,830 --> 00:22:14,900
accessible for example is it easier to

00:22:12,980 --> 00:22:17,390
control playback of a song with a voice

00:22:14,900 --> 00:22:19,960
command or is it easier to play a song

00:22:17,390 --> 00:22:24,590
via screens and buttons and through apps

00:22:19,960 --> 00:22:27,350
that's debatable what's called single

00:22:24,590 --> 00:22:29,870
turn dialogue is also an example of easy

00:22:27,350 --> 00:22:31,400
interaction for example asking for the

00:22:29,870 --> 00:22:34,010
weather or for a joke

00:22:31,400 --> 00:22:36,050
the user makes a request the agent

00:22:34,010 --> 00:22:38,680
returns a response and the interaction

00:22:36,050 --> 00:22:41,840
is over that's theoretically easy if

00:22:38,680 --> 00:22:44,780
you're using multiple turn dialogue it

00:22:41,840 --> 00:22:46,850
still needs to be easy this requires

00:22:44,780 --> 00:22:49,340
more design work and you'll need to

00:22:46,850 --> 00:22:53,720
explore interaction that can flow in

00:22:49,340 --> 00:22:56,450
various ways when designing for fun you

00:22:53,720 --> 00:22:58,070
also want to make it easy but you don't

00:22:56,450 --> 00:23:01,130
want to make it so easy that it's boring

00:22:58,070 --> 00:23:03,740
in lame games for example it can be

00:23:01,130 --> 00:23:05,870
interesting to design because in order

00:23:03,740 --> 00:23:08,810
for a game to be fun it needs to present

00:23:05,870 --> 00:23:12,080
a challenge games that are easier boring

00:23:08,810 --> 00:23:14,410
so you want to design your game to be

00:23:12,080 --> 00:23:17,210
fun by making it easy to play but

00:23:14,410 --> 00:23:20,630
challenging at an appropriate level to

00:23:17,210 --> 00:23:23,540
win you can also look for ways in your

00:23:20,630 --> 00:23:26,870
app to incorporate humor surprise or

00:23:23,540 --> 00:23:30,340
delight and finally think about how do

00:23:26,870 --> 00:23:32,840
you want your users to feel during and

00:23:30,340 --> 00:23:34,790
after interaction with your voice skill

00:23:32,840 --> 00:23:38,840
how many times have you been on the

00:23:34,790 --> 00:23:41,660
phone with an automated voice machine

00:23:38,840 --> 00:23:43,580
and you're know press 1 for this and

00:23:41,660 --> 00:23:46,160
press 2 for that or say your number and

00:23:43,580 --> 00:23:47,870
it just leaves you frustrated and your

00:23:46,160 --> 00:23:50,420
swearing and you know they actually have

00:23:47,870 --> 00:23:53,120
like people you know listening to

00:23:50,420 --> 00:23:55,190
cursing and you know if if you reach a

00:23:53,120 --> 00:23:56,960
critical mass of cursing then they get

00:23:55,190 --> 00:24:00,470
an operator on the phone to help you out

00:23:56,960 --> 00:24:02,390
it's like how often are we so frustrated

00:24:00,470 --> 00:24:05,180
dealing with voice you eyes that it just

00:24:02,390 --> 00:24:06,950
leaves us just fuming mad that's not how

00:24:05,180 --> 00:24:11,650
you want your users to feel when they're

00:24:06,950 --> 00:24:15,770
interacting with your app so be choosy

00:24:11,650 --> 00:24:17,900
be choosy be particular about what ask

00:24:15,770 --> 00:24:20,180
aspects of your platform you want to

00:24:17,900 --> 00:24:22,610
expose to voice interaction you don't

00:24:20,180 --> 00:24:25,010
have to do it all you can pick a certain

00:24:22,610 --> 00:24:28,850
aspect of your platform to expose to

00:24:25,010 --> 00:24:32,150
voice ask yourself will adding voice

00:24:28,850 --> 00:24:35,540
interaction make a certain task faster

00:24:32,150 --> 00:24:37,850
easier or more fun for your user if the

00:24:35,540 --> 00:24:39,980
answer is a resounding no to all of

00:24:37,850 --> 00:24:44,060
those you probably want to rethink your

00:24:39,980 --> 00:24:46,670
project idea one of the first challenges

00:24:44,060 --> 00:24:50,780
is deciding what type of project is a

00:24:46,670 --> 00:24:52,910
good fit for voice interaction spend

00:24:50,780 --> 00:24:54,260
some time describing some scenarios in

00:24:52,910 --> 00:24:57,350
which people would find your skill

00:24:54,260 --> 00:25:00,310
useful or desirable think about why

00:24:57,350 --> 00:25:03,170
would people want to use your voice UI

00:25:00,310 --> 00:25:06,440
maybe think about what a person will be

00:25:03,170 --> 00:25:08,330
doing before during or after interacting

00:25:06,440 --> 00:25:10,460
with your skill and that might help you

00:25:08,330 --> 00:25:12,740
envision the context in which a person

00:25:10,460 --> 00:25:13,370
using your skill when when that makes

00:25:12,740 --> 00:25:17,210
sense

00:25:13,370 --> 00:25:19,280
and also think about what someone would

00:25:17,210 --> 00:25:23,750
get from their skill that they can't get

00:25:19,280 --> 00:25:26,810
any other way next create a persona

00:25:23,750 --> 00:25:29,330
we're talking about voice tears so think

00:25:26,810 --> 00:25:31,250
about what is your you eyes personality

00:25:29,330 --> 00:25:33,470
what kinds of things or phrases would

00:25:31,250 --> 00:25:35,330
they say are its expressions and

00:25:33,470 --> 00:25:37,580
responses in line with your brand's

00:25:35,330 --> 00:25:41,150
values or is it just coming out of your

00:25:37,580 --> 00:25:44,180
own head once you've picked out your

00:25:41,150 --> 00:25:45,830
project idea or have decided which part

00:25:44,180 --> 00:25:47,990
of your application you want to expose

00:25:45,830 --> 00:25:50,330
to a voice UI and you've thought about

00:25:47,990 --> 00:25:53,060
your voice you eyes persona it's time to

00:25:50,330 --> 00:25:55,370
write out some scripts start out with a

00:25:53,060 --> 00:25:56,090
simple script between the UI and the

00:25:55,370 --> 00:25:59,120
user

00:25:56,090 --> 00:26:01,820
and at first focus on the happy path

00:25:59,120 --> 00:26:04,040
where everything goes well in the

00:26:01,820 --> 00:26:06,350
process thinking think about whether or

00:26:04,040 --> 00:26:08,540
not the dialog is flowing naturally and

00:26:06,350 --> 00:26:10,760
the variations of dialogue that could

00:26:08,540 --> 00:26:13,550
result in the same outcome maybe

00:26:10,760 --> 00:26:15,050
practice with someone and see what kind

00:26:13,550 --> 00:26:18,460
of different phrases after you practice

00:26:15,050 --> 00:26:21,830
it over and over again get brought up

00:26:18,460 --> 00:26:24,230
keep the interactions brief and right

00:26:21,830 --> 00:26:28,220
for people how people talk not how they

00:26:24,230 --> 00:26:31,760
write indicate when the user needs to

00:26:28,220 --> 00:26:35,360
provide info and ask for one piece of

00:26:31,760 --> 00:26:37,760
information at a time next we want to

00:26:35,360 --> 00:26:41,330
represent our example dial dialog with a

00:26:37,760 --> 00:26:43,940
flow diagram so reference the happy path

00:26:41,330 --> 00:26:46,180
script and map out all of the places

00:26:43,940 --> 00:26:48,590
where input is needed from the user

00:26:46,180 --> 00:26:51,200
after you have diagram the flow for the

00:26:48,590 --> 00:26:53,900
happy path start branching out cover

00:26:51,200 --> 00:26:55,850
additional logic and things where things

00:26:53,900 --> 00:26:58,190
don't go well and remember keep this

00:26:55,850 --> 00:27:00,500
maximum in your head that you you want

00:26:58,190 --> 00:27:02,510
to you don't want to say to the user

00:27:00,500 --> 00:27:04,430
that they've made an error so think

00:27:02,510 --> 00:27:06,140
about how you can reroute and get the

00:27:04,430 --> 00:27:10,940
conversation back on track to have a

00:27:06,140 --> 00:27:13,520
successful conversation so here's an

00:27:10,940 --> 00:27:14,870
example of a script and this is one of

00:27:13,520 --> 00:27:17,720
the examples that you can work through

00:27:14,870 --> 00:27:20,930
on the developer Google site for Google

00:27:17,720 --> 00:27:22,850
actions on Google welcome and I want you

00:27:20,930 --> 00:27:25,160
to think about as I'm reading this the

00:27:22,850 --> 00:27:27,170
different ways the different phrases

00:27:25,160 --> 00:27:28,520
that both the user and the UI are using

00:27:27,170 --> 00:27:31,160
even though they're basically saying the

00:27:28,520 --> 00:27:33,440
same thing welcome to number Jeannie I'm

00:27:31,160 --> 00:27:35,810
thinking of a number between 0 and 100

00:27:33,440 --> 00:27:38,140
what's your first guest 50 it's slower

00:27:35,810 --> 00:27:39,320
than 50 next guess how about 9

00:27:38,140 --> 00:27:43,610
piping-hot

00:27:39,320 --> 00:27:46,160
go lower okay is it 8 keep going 7 yes

00:27:43,610 --> 00:27:48,650
it's 7 how about another round no thanks

00:27:46,160 --> 00:27:51,380
all right talk to you later then so

00:27:48,650 --> 00:27:53,330
basically the UI is just saying no you

00:27:51,380 --> 00:27:54,740
didn't get a write a bunch of different

00:27:53,330 --> 00:27:56,150
times but they're saying at different

00:27:54,740 --> 00:27:59,300
ways and they're saying it in a certain

00:27:56,150 --> 00:28:01,490
way that makes you think yeah this thing

00:27:59,300 --> 00:28:03,200
has personality and it's not just a

00:28:01,490 --> 00:28:04,730
machine it's you know it's a little bit

00:28:03,200 --> 00:28:05,700
more than that even though it is just a

00:28:04,730 --> 00:28:08,200
machine

00:28:05,700 --> 00:28:10,180
the final step in the voice design

00:28:08,200 --> 00:28:12,670
process is to create and configure the

00:28:10,180 --> 00:28:14,920
interaction model this is an actual

00:28:12,670 --> 00:28:17,110
implementation step and a key part of

00:28:14,920 --> 00:28:19,930
the process for creating a custom skill

00:28:17,110 --> 00:28:22,450
in this step you want to take your flow

00:28:19,930 --> 00:28:24,760
diagram and ascertain what are the

00:28:22,450 --> 00:28:27,490
concrete things that can happen in this

00:28:24,760 --> 00:28:27,970
interaction so these concrete things are

00:28:27,490 --> 00:28:31,720
called

00:28:27,970 --> 00:28:35,020
intense what are the specific phrases

00:28:31,720 --> 00:28:38,200
that can be said to invoke these intense

00:28:35,020 --> 00:28:42,880
these are our utterances or what the

00:28:38,200 --> 00:28:45,490
quote user says and what data does your

00:28:42,880 --> 00:28:49,210
app need to fulfill the request these

00:28:45,490 --> 00:28:52,690
are your slots or your entities you can

00:28:49,210 --> 00:28:55,540
find out more about these concepts at on

00:28:52,690 --> 00:28:57,400
these URLs and I'll have these slides

00:28:55,540 --> 00:29:01,710
available on the session node and you

00:28:57,400 --> 00:29:04,270
can so you don't have to worry about

00:29:01,710 --> 00:29:07,030
capturing these now you can go back to

00:29:04,270 --> 00:29:10,030
the slides later but these are all

00:29:07,030 --> 00:29:13,240
resources that I took from in putting

00:29:10,030 --> 00:29:16,360
together these tips let's talk more

00:29:13,240 --> 00:29:19,030
about key concepts in voice UI creation

00:29:16,360 --> 00:29:22,570
so how does this start conversations

00:29:19,030 --> 00:29:25,000
start with activation so this is a wake

00:29:22,570 --> 00:29:27,730
word or a phrase that activates the

00:29:25,000 --> 00:29:30,070
platform AI sometimes this is a physical

00:29:27,730 --> 00:29:33,010
button or other audible trigger like

00:29:30,070 --> 00:29:35,860
hand clapping so this could be hey Siri

00:29:33,010 --> 00:29:41,800
Alexa or okay Google or pressing a

00:29:35,860 --> 00:29:45,040
button on the device invocation is what

00:29:41,800 --> 00:29:48,040
tells the platform which voice UI you

00:29:45,040 --> 00:29:50,080
want to talk to so there's thousands of

00:29:48,040 --> 00:29:53,290
developers developing thousands of apps

00:29:50,080 --> 00:29:55,330
how does whatever the AI that you're

00:29:53,290 --> 00:30:00,130
talking to how does it know which skill

00:29:55,330 --> 00:30:02,200
to talk to this is invocation so think

00:30:00,130 --> 00:30:03,670
of it like an operator like Alexa or

00:30:02,200 --> 00:30:05,290
Google is the operator and you're

00:30:03,670 --> 00:30:07,480
telling the operator who you want to

00:30:05,290 --> 00:30:11,230
talk to so let's say the name of our

00:30:07,480 --> 00:30:13,930
voice UI is fish jokes with Alexa you do

00:30:11,230 --> 00:30:17,200
this with a specific set of invocation

00:30:13,930 --> 00:30:20,110
keywords like ask open or

00:30:17,200 --> 00:30:23,200
and then the name of the skill so I

00:30:20,110 --> 00:30:26,649
could say open fish jokes or launch fish

00:30:23,200 --> 00:30:29,049
jokes or ask fish jokes with Google it's

00:30:26,649 --> 00:30:31,929
a bit more natural for example let me

00:30:29,049 --> 00:30:34,510
talk to fish jokes so Alexa tends to be

00:30:31,929 --> 00:30:37,330
more command oriented and Google tends

00:30:34,510 --> 00:30:41,139
to be more kind of naturally conversing

00:30:37,330 --> 00:30:43,149
and that brings up other issues that I'm

00:30:41,139 --> 00:30:46,630
not going to talk about today but these

00:30:43,149 --> 00:30:48,159
devices are in the home and they're

00:30:46,630 --> 00:30:49,750
being done you know in the context of

00:30:48,159 --> 00:30:51,370
families and with young children and

00:30:49,750 --> 00:30:53,320
I've had conversations with people who

00:30:51,370 --> 00:30:55,720
are like yeah I don't really like how

00:30:53,320 --> 00:30:57,669
Alexa so command oriented because it's

00:30:55,720 --> 00:31:00,610
kind of teaching my toddler how to boss

00:30:57,669 --> 00:31:02,769
around this device called Alexa so they

00:31:00,610 --> 00:31:04,630
you know so there's just it's it's

00:31:02,769 --> 00:31:06,669
interesting how what kinds of things

00:31:04,630 --> 00:31:08,559
this is bringing into our societies so I

00:31:06,669 --> 00:31:10,840
kind of like actually how the Google

00:31:08,559 --> 00:31:17,889
implementation is more conversant and it

00:31:10,840 --> 00:31:20,649
allows for more natural dialog intense

00:31:17,889 --> 00:31:23,380
are what map what the user says to

00:31:20,649 --> 00:31:26,590
specific functionality or actions of

00:31:23,380 --> 00:31:28,840
your UI and these are there are built-in

00:31:26,590 --> 00:31:30,460
intense that your port that your

00:31:28,840 --> 00:31:32,350
platform provides that can make it

00:31:30,460 --> 00:31:35,559
easier for you to implement default

00:31:32,350 --> 00:31:38,260
welcome responses or help or ending the

00:31:35,559 --> 00:31:39,820
conversation so each platform has some

00:31:38,260 --> 00:31:41,260
built in intense that can make you like

00:31:39,820 --> 00:31:45,429
your life easier you're not gonna have

00:31:41,260 --> 00:31:47,799
to reinvent those wheels and and so

00:31:45,429 --> 00:31:50,230
those kinds of built-in intents can help

00:31:47,799 --> 00:31:52,779
you with specific responses depending on

00:31:50,230 --> 00:31:55,149
context and then there's custom intents

00:31:52,779 --> 00:31:58,210
which are your voice you eyes special

00:31:55,149 --> 00:31:59,889
sauce so that's really about the direct

00:31:58,210 --> 00:32:03,190
functionality that you want to provide

00:31:59,889 --> 00:32:05,919
but you also need to throw in help and

00:32:03,190 --> 00:32:09,130
how do you how does a user quit your UI

00:32:05,919 --> 00:32:12,779
and things like that so and you'll need

00:32:09,130 --> 00:32:16,029
to have those to pass the QA process

00:32:12,779 --> 00:32:18,990
user says or utterances and I'm using

00:32:16,029 --> 00:32:22,360
these two different phrases because in

00:32:18,990 --> 00:32:24,309
Alexa it's called utterances and API AI

00:32:22,360 --> 00:32:27,220
it's called user says so that's why I've

00:32:24,309 --> 00:32:29,080
got both terms on there and these are

00:32:27,220 --> 00:32:29,720
the phrases or words that your app

00:32:29,080 --> 00:32:32,480
record

00:32:29,720 --> 00:32:34,460
Isis so you also want to think about

00:32:32,480 --> 00:32:36,680
context because you want to have

00:32:34,460 --> 00:32:39,500
different sets of phrases for different

00:32:36,680 --> 00:32:42,050
intents and those intents in different

00:32:39,500 --> 00:32:44,870
contexts so these phrases can contain

00:32:42,050 --> 00:32:47,950
slots or entities will ultimately feed

00:32:44,870 --> 00:32:50,810
arguments or parameters to your endpoint

00:32:47,950 --> 00:32:52,910
you want to add as many variations as

00:32:50,810 --> 00:32:54,560
possible you want to think about that

00:32:52,910 --> 00:32:56,750
context when someone after a

00:32:54,560 --> 00:32:58,490
conversation is started people respond

00:32:56,750 --> 00:33:00,140
differently because they know what has

00:32:58,490 --> 00:33:01,850
been set already and so your apps should

00:33:00,140 --> 00:33:06,380
know what has been said already - and

00:33:01,850 --> 00:33:09,080
take that into consideration so for

00:33:06,380 --> 00:33:12,410
example here's an API a I screen and

00:33:09,080 --> 00:33:16,520
we've got a list of phrases that user

00:33:12,410 --> 00:33:17,810
says and we want to build out as many as

00:33:16,520 --> 00:33:20,810
possible and the machine learning

00:33:17,810 --> 00:33:23,990
algorithm of the API dot a I will take

00:33:20,810 --> 00:33:26,720
that and learn from that and eventually

00:33:23,990 --> 00:33:28,610
your app will recognize even more

00:33:26,720 --> 00:33:30,650
phrases kind of based on what you've fed

00:33:28,610 --> 00:33:32,570
it already but you still want to feed it

00:33:30,650 --> 00:33:37,850
as many variations as possible to help

00:33:32,570 --> 00:33:40,850
that machine learning process in Alexis

00:33:37,850 --> 00:33:42,500
beta interaction model UI so as you go

00:33:40,850 --> 00:33:44,690
through the screens and they'll and

00:33:42,500 --> 00:33:47,330
building your Alexis screen you'll get

00:33:44,690 --> 00:33:48,800
to the interaction model and it'll say

00:33:47,330 --> 00:33:51,020
do you want to try out the beta

00:33:48,800 --> 00:33:53,330
interaction model and your answer should

00:33:51,020 --> 00:33:55,640
be yes I do because is so much better

00:33:53,330 --> 00:33:59,230
than the first iteration that they have

00:33:55,640 --> 00:34:03,320
so you add sample utterances here and

00:33:59,230 --> 00:34:04,910
and this is in your intent slots or

00:34:03,320 --> 00:34:08,060
entities which I've mentioned are

00:34:04,910 --> 00:34:10,280
optional arguments you define a type and

00:34:08,060 --> 00:34:11,900
then populate it with valid terms so you

00:34:10,280 --> 00:34:14,780
might want to things think in terms of

00:34:11,900 --> 00:34:17,090
you define a vocabulary and then you

00:34:14,780 --> 00:34:20,390
give that vocabulary terms it's a

00:34:17,090 --> 00:34:23,810
similar sort of thing you you'll then

00:34:20,390 --> 00:34:26,860
put these slots or entities into your

00:34:23,810 --> 00:34:28,010
sample phrases or your user says in your

00:34:26,860 --> 00:34:31,250
intent

00:34:28,010 --> 00:34:34,670
so as you're saying like well they might

00:34:31,250 --> 00:34:36,860
ask for fish jokes that are silly and so

00:34:34,670 --> 00:34:38,810
silly is going to be your slot and silly

00:34:36,860 --> 00:34:40,520
is going to be your taxonomy term on

00:34:38,810 --> 00:34:41,750
your Drupal site that's going to get the

00:34:40,520 --> 00:34:45,470
silly joke return

00:34:41,750 --> 00:34:48,290
back to the user for example in this

00:34:45,470 --> 00:34:51,409
phrase I want to hear about Google's

00:34:48,290 --> 00:34:54,320
history so Google's history or history

00:34:51,409 --> 00:34:55,399
and I want to hear about history or I

00:34:54,320 --> 00:34:58,550
want to hear about Google's history

00:34:55,399 --> 00:35:01,520
that's highlighted and it's mapped to

00:34:58,550 --> 00:35:05,480
the fact category entity then we

00:35:01,520 --> 00:35:09,320
configure the parameter down below which

00:35:05,480 --> 00:35:11,390
will be passed on to our endpoint so we

00:35:09,320 --> 00:35:13,280
can even make that a required thing so

00:35:11,390 --> 00:35:16,160
we're gonna keep prompting the user for

00:35:13,280 --> 00:35:18,140
this information but until they give it

00:35:16,160 --> 00:35:23,330
to us so that we can return an

00:35:18,140 --> 00:35:25,850
appropriate response the valid entity

00:35:23,330 --> 00:35:27,620
terms in this example our history or

00:35:25,850 --> 00:35:30,350
headquarters so here's where I'm

00:35:27,620 --> 00:35:32,300
defining my entity so I've got two terms

00:35:30,350 --> 00:35:33,860
history or headquarters those are the

00:35:32,300 --> 00:35:36,530
two types of facts that I'm going to

00:35:33,860 --> 00:35:39,590
return and I can also set a number of

00:35:36,530 --> 00:35:42,800
synonyms there which is really nice in

00:35:39,590 --> 00:35:46,120
the Alexa interaction model UI you

00:35:42,800 --> 00:35:48,470
create a slot type and then slot values

00:35:46,120 --> 00:35:50,750
including any variations of the term

00:35:48,470 --> 00:35:53,690
so you're just going to list those all

00:35:50,750 --> 00:35:56,240
out and it's a different sort of way

00:35:53,690 --> 00:35:57,710
that you do that instead of doing

00:35:56,240 --> 00:35:59,930
synonyms you're just going to list out

00:35:57,710 --> 00:36:03,590
all of the different terms that will be

00:35:59,930 --> 00:36:06,800
valid responses and the user says

00:36:03,590 --> 00:36:09,380
phrases you map certain words to entity

00:36:06,800 --> 00:36:12,110
parameters if you configure your

00:36:09,380 --> 00:36:14,270
entities and terms before your user says

00:36:12,110 --> 00:36:16,310
phrases these words will be

00:36:14,270 --> 00:36:17,990
automatically mapped for you so if I

00:36:16,310 --> 00:36:20,120
setup my entity already and set up my

00:36:17,990 --> 00:36:22,730
terms as I'm typing out the user says

00:36:20,120 --> 00:36:24,290
and if I use one of those terms that

00:36:22,730 --> 00:36:26,570
I've already added to my entity it's

00:36:24,290 --> 00:36:30,200
gonna highlight it already it's gonna

00:36:26,570 --> 00:36:32,090
highlight automatically and otherwise if

00:36:30,200 --> 00:36:33,860
you haven't done that step already you

00:36:32,090 --> 00:36:36,560
can highlight the word that you know is

00:36:33,860 --> 00:36:40,490
going to be your entity and then you can

00:36:36,560 --> 00:36:43,400
map it to either a built in or a custom

00:36:40,490 --> 00:36:46,280
entity type so you can kind of build

00:36:43,400 --> 00:36:48,230
this out as you go and you can go back

00:36:46,280 --> 00:36:52,360
and forth between your entities and your

00:36:48,230 --> 00:36:55,690
intent to 2-iron all about those details

00:36:52,360 --> 00:36:57,760
and it's a similar thing with Alexis

00:36:55,690 --> 00:36:59,620
beta UI for the interaction model you

00:36:57,760 --> 00:37:01,870
can active you activate a slot though

00:36:59,620 --> 00:37:03,670
instead of with just highlighting a word

00:37:01,870 --> 00:37:05,200
you have to use a curly you open a curly

00:37:03,670 --> 00:37:09,010
brace and it's like oh I know you want

00:37:05,200 --> 00:37:11,920
it in an intense slot so which type do

00:37:09,010 --> 00:37:14,680
you want okay I want category and so in

00:37:11,920 --> 00:37:17,620
in your utterances it's going to have

00:37:14,680 --> 00:37:20,020
curly brace category instead of like the

00:37:17,620 --> 00:37:23,980
actual word like the actual synonym or

00:37:20,020 --> 00:37:25,870
term so you can stub out slot names in

00:37:23,980 --> 00:37:27,520
your sample utterances and then you can

00:37:25,870 --> 00:37:32,800
create your slot type and add the terms

00:37:27,520 --> 00:37:34,840
later so an API dot AI entities are

00:37:32,800 --> 00:37:38,860
highlighted and user says phrases for

00:37:34,840 --> 00:37:41,890
your intent so just enter given that the

00:37:38,860 --> 00:37:44,110
user is going to use one of these entity

00:37:41,890 --> 00:37:48,910
terms or synonyms enter a variety of

00:37:44,110 --> 00:37:50,710
phrases that make sense once you've

00:37:48,910 --> 00:37:52,450
started to figure out your interaction

00:37:50,710 --> 00:37:54,520
model you need to think about where the

00:37:52,450 --> 00:37:59,410
data will come from that will make up

00:37:54,520 --> 00:38:02,050
your you eyes response on the ape in

00:37:59,410 --> 00:38:04,660
Apia I ate on the fulfilment

00:38:02,050 --> 00:38:07,120
configuration screen you configure a web

00:38:04,660 --> 00:38:09,490
hook with the URL you can also include

00:38:07,120 --> 00:38:13,030
any basic authorization or additional

00:38:09,490 --> 00:38:15,160
headers the URL is the endpoint and the

00:38:13,030 --> 00:38:17,830
process is much the same for Alexa

00:38:15,160 --> 00:38:20,170
you're going to enter in a URL that is

00:38:17,830 --> 00:38:24,370
the endpoint that's going to return the

00:38:20,170 --> 00:38:26,740
JSON for your response so let's talk

00:38:24,370 --> 00:38:29,470
about some possibilities for those

00:38:26,740 --> 00:38:30,310
endpoints and there are many but I'm

00:38:29,470 --> 00:38:33,520
going to talk about several

00:38:30,310 --> 00:38:34,900
possibilities here the easiest path that

00:38:33,520 --> 00:38:37,480
you'll probably want to start out with

00:38:34,900 --> 00:38:41,380
is to provide response values and a

00:38:37,480 --> 00:38:43,930
hard-coded array both Alexa and actions

00:38:41,380 --> 00:38:46,750
on Google have github repos with example

00:38:43,930 --> 00:38:48,400
code that uses static erase so with just

00:38:46,750 --> 00:38:50,440
a bit of JavaScript knowledge it's

00:38:48,400 --> 00:38:52,810
relatively easy to tweak out these

00:38:50,440 --> 00:38:54,990
blueprints with custom response values

00:38:52,810 --> 00:38:57,670
this is the method that you'll likely

00:38:54,990 --> 00:38:59,440
use when you're setting out to learn a

00:38:57,670 --> 00:39:01,780
platform and you're going through the

00:38:59,440 --> 00:39:03,670
getting started tutorials but to add

00:39:01,780 --> 00:39:05,710
more values

00:39:03,670 --> 00:39:08,680
your responses after your app has been

00:39:05,710 --> 00:39:11,319
published you'll have to resubmit a new

00:39:08,680 --> 00:39:13,119
version of your app so that's kind of

00:39:11,319 --> 00:39:15,520
cumbersome that's fine for learning

00:39:13,119 --> 00:39:18,400
that's fine for once but how is that

00:39:15,520 --> 00:39:23,319
sustainable in the real world it's not

00:39:18,400 --> 00:39:24,940
very so we can use the same hosting and

00:39:23,319 --> 00:39:27,490
endpoint configuration so in that first

00:39:24,940 --> 00:39:32,290
example with the static array you'll

00:39:27,490 --> 00:39:35,770
host it on AWS lambda or firebase or

00:39:32,290 --> 00:39:38,890
Google Cloud and we can still do that we

00:39:35,770 --> 00:39:41,500
can have like a node script or some kind

00:39:38,890 --> 00:39:45,180
of Java Script that has our static array

00:39:41,500 --> 00:39:48,250
and instead of that static array we can

00:39:45,180 --> 00:39:51,010
make a web services call to an external

00:39:48,250 --> 00:39:53,349
endpoint and so for example if that

00:39:51,010 --> 00:39:55,809
endpoint was on a Drupal site we can

00:39:53,349 --> 00:39:58,119
configure for example a view using the

00:39:55,809 --> 00:40:00,280
REST export display which returns JSON

00:39:58,119 --> 00:40:02,880
at a certain path and this is something

00:40:00,280 --> 00:40:05,500
that we did with our custom alexis skill

00:40:02,880 --> 00:40:07,720
so in this example we're using a JSON

00:40:05,500 --> 00:40:10,210
endpoint provided by Drupal to draw from

00:40:07,720 --> 00:40:11,829
a larger library of material so any

00:40:10,210 --> 00:40:14,170
Content that we add to our Drupal site

00:40:11,829 --> 00:40:15,700
is now available in the response we

00:40:14,170 --> 00:40:17,619
don't have to resubmit our app we just

00:40:15,700 --> 00:40:20,950
have to update our Drupal site with new

00:40:17,619 --> 00:40:22,780
content so this means that we can add

00:40:20,950 --> 00:40:26,170
possible responses without the need to

00:40:22,780 --> 00:40:29,980
resubmit our app a third possibility is

00:40:26,170 --> 00:40:32,079
to get rid of the the lambda or the

00:40:29,980 --> 00:40:34,930
Google Cloud or firebase dependency

00:40:32,079 --> 00:40:38,319
entirely and have the voice UI service

00:40:34,930 --> 00:40:41,549
talk directly to a Drupal site but if

00:40:38,319 --> 00:40:45,910
we're tasked with parsing JSON that

00:40:41,549 --> 00:40:48,730
Alexa API AI or Google actions sends to

00:40:45,910 --> 00:40:52,089
our Drupal site that would be no easy

00:40:48,730 --> 00:40:55,839
task but thankfully there are some

00:40:52,089 --> 00:40:58,299
modules for that the modules that I've

00:40:55,839 --> 00:41:02,020
personally used to create endpoints for

00:40:58,299 --> 00:41:05,079
voice UI requests are listed here so we

00:41:02,020 --> 00:41:08,380
have a rest export views display the

00:41:05,079 --> 00:41:12,100
Alexa project the chat bot API project

00:41:08,380 --> 00:41:16,150
in conjunction with the API

00:41:12,100 --> 00:41:19,950
i webhook project which requires the PHP

00:41:16,150 --> 00:41:23,740
SDK for API AI

00:41:19,950 --> 00:41:25,690
so first the views rest export in the

00:41:23,740 --> 00:41:28,630
case where we make a web services call

00:41:25,690 --> 00:41:31,300
from a JavaScript hosted with a platform

00:41:28,630 --> 00:41:34,750
cloud service like firebase or AWS

00:41:31,300 --> 00:41:37,540
lambda we called an endpoint created by

00:41:34,750 --> 00:41:39,760
this rest export views display this

00:41:37,540 --> 00:41:44,170
functionality ships with Drupal 8 core

00:41:39,760 --> 00:41:46,420
no extra modules are required if you're

00:41:44,170 --> 00:41:48,640
building a custom alexis skill and you

00:41:46,420 --> 00:41:51,700
want to use data from your Drupal site

00:41:48,640 --> 00:41:55,780
in the response take a look at the alexa

00:41:51,700 --> 00:41:57,850
module there we had to add some custom

00:41:55,780 --> 00:42:00,040
functionality to get a card view to

00:41:57,850 --> 00:42:02,920
display but it's pretty great

00:42:00,040 --> 00:42:06,280
out-of-the-box this module also

00:42:02,920 --> 00:42:09,340
optionally integrates with chatbot api

00:42:06,280 --> 00:42:11,620
project this project serves as a common

00:42:09,340 --> 00:42:15,040
layer to send data to a number of voice

00:42:11,620 --> 00:42:17,140
and chat BOTS UI services it uses

00:42:15,040 --> 00:42:20,170
several different systems in Drupal

00:42:17,140 --> 00:42:22,180
including the plug-in system views and

00:42:20,170 --> 00:42:27,820
it provides a way to export Drupal

00:42:22,180 --> 00:42:30,190
content to API AI entities chatbot api

00:42:27,820 --> 00:42:32,770
provides a base plugin for chat bot

00:42:30,190 --> 00:42:34,720
intense you create a mod a plug-in in

00:42:32,770 --> 00:42:37,360
your module that extends the intent

00:42:34,720 --> 00:42:39,730
plug-in base and the annotation you

00:42:37,360 --> 00:42:43,360
provide an ID that's equal to the name

00:42:39,730 --> 00:42:45,400
of your intent in API AI for example you

00:42:43,360 --> 00:42:47,650
can actually use Drupal console to

00:42:45,400 --> 00:42:49,780
generate this type of plugin or you can

00:42:47,650 --> 00:42:51,820
copy and paste the example provided in

00:42:49,780 --> 00:42:54,240
the module and then modify it to fit

00:42:51,820 --> 00:42:56,650
your intent and your class name the

00:42:54,240 --> 00:42:59,230
process method in this class is

00:42:56,650 --> 00:43:02,980
automatically called and is where all of

00:42:59,230 --> 00:43:05,140
your logic goes through the response but

00:43:02,980 --> 00:43:07,570
there's also a views display provided by

00:43:05,140 --> 00:43:10,210
the module this is the chat bots intent

00:43:07,570 --> 00:43:12,730
display which will show up for you if

00:43:10,210 --> 00:43:14,950
you have the module enabled the intent

00:43:12,730 --> 00:43:18,460
name should be the name of your intent

00:43:14,950 --> 00:43:21,040
in your platform UI the implementation

00:43:18,460 --> 00:43:23,990
is still ongoing but on a basic level it

00:43:21,040 --> 00:43:25,700
works I've tested it with API AI

00:43:23,990 --> 00:43:30,290
agents integrating with actions on

00:43:25,700 --> 00:43:32,690
Google you can also use API AI webhook

00:43:30,290 --> 00:43:34,730
project with chat bot API instead of the

00:43:32,690 --> 00:43:38,480
plug-in system it uses the event system

00:43:34,730 --> 00:43:40,700
it handles requests from API AI agents

00:43:38,480 --> 00:43:42,740
to the web hook on your Drupal site and

00:43:40,700 --> 00:43:45,470
it triggers a symphony event which

00:43:42,740 --> 00:43:46,460
modules can subscribe to in order to add

00:43:45,470 --> 00:43:51,560
their logic

00:43:46,460 --> 00:43:53,180
it requires the API a ap PHP SDK which

00:43:51,560 --> 00:43:57,350
is in progress but it's got a great

00:43:53,180 --> 00:43:59,240
start these are all great modules and

00:43:57,350 --> 00:44:01,010
projects to look into and I encourage

00:43:59,240 --> 00:44:03,440
you if you're a developer to see how you

00:44:01,010 --> 00:44:05,260
can help and support the maintain the

00:44:03,440 --> 00:44:10,040
maintainer z' of these modules and their

00:44:05,260 --> 00:44:13,369
respective issue is chic use so here

00:44:10,040 --> 00:44:15,400
they are one last time so check out

00:44:13,369 --> 00:44:18,710
those project pages and see how you can

00:44:15,400 --> 00:44:20,780
test them out give them feedback and if

00:44:18,710 --> 00:44:22,580
you're a developer help contribute

00:44:20,780 --> 00:44:24,440
because I think these all have a great

00:44:22,580 --> 00:44:28,130
start and they can make the process that

00:44:24,440 --> 00:44:31,270
much easier finally let's talk about

00:44:28,130 --> 00:44:34,550
testing and publication of your voice UI

00:44:31,270 --> 00:44:36,800
both Alexa and actions on Google provide

00:44:34,550 --> 00:44:38,619
in browser testing simulator so you

00:44:36,800 --> 00:44:42,260
don't need to go out and buy a device

00:44:38,619 --> 00:44:43,940
necessarily to do this and to even go

00:44:42,260 --> 00:44:46,670
through the entire process of even

00:44:43,940 --> 00:44:48,020
developing testing and publishing it you

00:44:46,670 --> 00:44:51,590
don't need to go out and buy all these

00:44:48,020 --> 00:44:53,960
devices it's fun to have them around but

00:44:51,590 --> 00:44:56,330
you can you don't need them they they

00:44:53,960 --> 00:44:59,119
have a simulator you can test both the

00:44:56,330 --> 00:45:01,550
headless audio responses as well as rich

00:44:59,119 --> 00:45:04,570
responses containing images and links by

00:45:01,550 --> 00:45:08,300
selecting a surface option as in this

00:45:04,570 --> 00:45:11,630
snippet of a screen so here this is the

00:45:08,300 --> 00:45:14,720
surface so the Google home device is

00:45:11,630 --> 00:45:17,150
highlighted so it's going to return just

00:45:14,720 --> 00:45:19,760
what the voice you I would say and if

00:45:17,150 --> 00:45:21,920
you have the you know speakers on on

00:45:19,760 --> 00:45:23,780
your on your computer then you can hear

00:45:21,920 --> 00:45:25,910
what it would say but you can also just

00:45:23,780 --> 00:45:28,280
test it out with the keyboard so you

00:45:25,910 --> 00:45:30,290
don't necessarily have to you know hole

00:45:28,280 --> 00:45:32,270
up somewhere where you you know it

00:45:30,290 --> 00:45:35,269
doesn't you can test it just with

00:45:32,270 --> 00:45:37,519
keyboard but if you switch to the screen

00:45:35,269 --> 00:45:38,989
then it'll return a rich response and

00:45:37,519 --> 00:45:41,390
that's part of the development process

00:45:38,989 --> 00:45:42,859
is making sure that you're providing a

00:45:41,390 --> 00:45:46,339
rich response as well as a voice

00:45:42,859 --> 00:45:48,409
response for the Google assistant tester

00:45:46,339 --> 00:45:51,679
you just say you just type in talk to my

00:45:48,409 --> 00:45:55,519
test stop and you'll be able to test it

00:45:51,679 --> 00:45:57,739
out after you've tested your app and

00:45:55,519 --> 00:46:00,049
entered in the appropriate metadata

00:45:57,739 --> 00:46:03,049
phoria like name description logo etc

00:46:00,049 --> 00:46:05,809
you can submit it for publication

00:46:03,049 --> 00:46:08,140
it'll be thoroughly tested and you can

00:46:05,809 --> 00:46:11,869
expect feedback within one to two days

00:46:08,140 --> 00:46:13,839
make sure your you watch for that email

00:46:11,869 --> 00:46:16,909
it'll go to your developer account

00:46:13,839 --> 00:46:18,559
something that I didn't mention is a big

00:46:16,909 --> 00:46:20,419
part of this process is signing up for

00:46:18,559 --> 00:46:21,739
all these developer accounts so you

00:46:20,419 --> 00:46:24,349
might want to make that different than

00:46:21,739 --> 00:46:27,890
your normal personal account especially

00:46:24,349 --> 00:46:29,659
since you're gonna need to turn off a

00:46:27,890 --> 00:46:31,249
lot of privacy settings and data

00:46:29,659 --> 00:46:33,529
collection settings that you may not be

00:46:31,249 --> 00:46:36,979
comfortable with on your personal

00:46:33,529 --> 00:46:39,289
account so I set up a separate email and

00:46:36,979 --> 00:46:40,999
a separate account for all my developer

00:46:39,289 --> 00:46:43,399
accounts especially when we're talking

00:46:40,999 --> 00:46:46,880
about all of the data that is collected

00:46:43,399 --> 00:46:49,099
there so just consider that address the

00:46:46,880 --> 00:46:49,729
feedback that they give you sometimes

00:46:49,099 --> 00:46:51,319
they're wrong

00:46:49,729 --> 00:46:52,880
so I've encountered that they were wrong

00:46:51,319 --> 00:46:56,539
and I told them they were wrong and why

00:46:52,880 --> 00:46:58,279
and in a polite way and and they they

00:46:56,539 --> 00:47:00,709
see your point or they don't or you're

00:46:58,279 --> 00:47:03,079
wrong and just a you know address the

00:47:00,709 --> 00:47:04,729
feedback and resubmit and once approved

00:47:03,079 --> 00:47:06,619
there's no extra step if they it's

00:47:04,729 --> 00:47:08,149
published it's out there so for Google

00:47:06,619 --> 00:47:09,499
that means automatically pushing it out

00:47:08,149 --> 00:47:11,869
and for Alexa that means it's going to

00:47:09,499 --> 00:47:16,099
show up in the Alexa store of that users

00:47:11,869 --> 00:47:17,599
can browse through and enable finally I

00:47:16,099 --> 00:47:19,699
just have a couple of demos to show you

00:47:17,599 --> 00:47:23,049
just for fun and these are some projects

00:47:19,699 --> 00:47:28,219
that I've done so this is an example of

00:47:23,049 --> 00:47:31,159
Alexa I like to tinker with hardware and

00:47:28,219 --> 00:47:33,439
so I decided like having an echo dot is

00:47:31,159 --> 00:47:38,239
okay I guess but it's like way more fun

00:47:33,439 --> 00:47:41,869
to take apart the motor and solder the

00:47:38,239 --> 00:47:44,089
input into an Arduino and write a little

00:47:41,869 --> 00:47:45,840
or do we know script and have this

00:47:44,089 --> 00:47:52,770
animatronic fish

00:47:45,840 --> 00:47:55,070
instead of a codon so Alexa open fish

00:47:52,770 --> 00:47:58,410
jokes

00:47:55,070 --> 00:48:03,930
why don't fish play a basketball because

00:47:58,410 --> 00:48:05,490
they're afraid of the net art these are

00:48:03,930 --> 00:48:07,160
like the worst jokes out of her but

00:48:05,490 --> 00:48:13,940
they're great

00:48:07,160 --> 00:48:16,320
Alexa asked fish jokes for a nerd joke

00:48:13,940 --> 00:48:22,620
what Drupal module do you use to

00:48:16,320 --> 00:48:25,770
organize schools of fish organic yeah no

00:48:22,620 --> 00:48:28,950
so in that example we had the slot so

00:48:25,770 --> 00:48:31,320
ask fish jokes for a nerd joke so on the

00:48:28,950 --> 00:48:33,540
Drupal site we have a bunch of jokes and

00:48:31,320 --> 00:48:37,350
they're tagged with the term nerd and so

00:48:33,540 --> 00:48:38,940
it returns a joke that is tagged with

00:48:37,350 --> 00:48:42,150
that term so that's how that works

00:48:38,940 --> 00:48:44,550
together and then finally um this is

00:48:42,150 --> 00:48:47,100
like totally different this is not an

00:48:44,550 --> 00:48:50,040
action on Google but this is you can

00:48:47,100 --> 00:48:54,300
actually embed the Google assistant into

00:48:50,040 --> 00:48:56,430
a DIY device Google promoted this

00:48:54,300 --> 00:48:59,340
through providing this like cardboard

00:48:56,430 --> 00:49:02,220
build all you needed was a Raspberry Pi

00:48:59,340 --> 00:49:04,350
3 and it had a special voice hat a

00:49:02,220 --> 00:49:06,840
little speaker and microphone so I built

00:49:04,350 --> 00:49:09,060
this built this little DIY Google home

00:49:06,840 --> 00:49:12,510
device and I embedded Google assistant

00:49:09,060 --> 00:49:14,550
on it so this was a terrible 'ti of this

00:49:12,510 --> 00:49:16,830
video is not great but you can kind of

00:49:14,550 --> 00:49:20,160
see how you could do that there's a

00:49:16,830 --> 00:49:22,800
terminal that's gonna pop up and so I'm

00:49:20,160 --> 00:49:24,750
activating the service I actually turned

00:49:22,800 --> 00:49:26,370
this on automatically so that I'm typing

00:49:24,750 --> 00:49:31,560
this with one hand and filming with the

00:49:26,370 --> 00:49:35,780
other so it's really shaky so the

00:49:31,560 --> 00:49:35,780
service is happening I press the button

00:49:37,190 --> 00:49:41,870
what is the weather in Portland Oregon

00:49:49,519 --> 00:49:55,499
so the SDK for Google assistant it it's

00:49:53,400 --> 00:49:58,079
all open source so you can and if you

00:49:55,499 --> 00:50:01,769
have a Linux if you have an embedded

00:49:58,079 --> 00:50:03,809
system that uses Linux you can embed the

00:50:01,769 --> 00:50:06,630
Google assistant into your device and

00:50:03,809 --> 00:50:10,140
you can also build actions on Google to

00:50:06,630 --> 00:50:13,710
extend that so you could use Ashlyn

00:50:10,140 --> 00:50:15,690
access on Google to create a an app that

00:50:13,710 --> 00:50:18,089
could like turn on lights or you know

00:50:15,690 --> 00:50:20,069
you can hack you know certain things so

00:50:18,089 --> 00:50:22,049
if you're into that sort of thing then

00:50:20,069 --> 00:50:23,700
you can there's also some possibilities

00:50:22,049 --> 00:50:25,589
there I will say you can also do this

00:50:23,700 --> 00:50:27,359
with Alexa but that was just me

00:50:25,589 --> 00:50:31,170
experimenting with Google assistant

00:50:27,359 --> 00:50:33,150
so to recap we I gave you an overview of

00:50:31,170 --> 00:50:34,920
the voice platforms and some of the

00:50:33,150 --> 00:50:37,740
opportunities that are available to you

00:50:34,920 --> 00:50:40,470
as a developer we talked about designing

00:50:37,740 --> 00:50:42,990
a voice interface and some voice UI

00:50:40,470 --> 00:50:45,660
concepts that are common across the

00:50:42,990 --> 00:50:47,640
board and finally we talked about some

00:50:45,660 --> 00:50:50,400
endpoint possibilities and how you might

00:50:47,640 --> 00:50:52,109
be able to integrate with Drupal and

00:50:50,400 --> 00:50:53,759
certainly there's probably other ways

00:50:52,109 --> 00:50:56,099
that you can do that too especially if

00:50:53,759 --> 00:50:57,989
you're like really into decoupling an

00:50:56,099 --> 00:50:59,460
API first and that sort of thing you

00:50:57,989 --> 00:51:01,529
probably can think of a lot of different

00:50:59,460 --> 00:51:06,059
ideas but those are what are designed

00:51:01,529 --> 00:51:07,799
for a voicing and chatbot this session

00:51:06,059 --> 00:51:09,930
was called get started with voice user

00:51:07,799 --> 00:51:12,299
interfaces so you can go to the Drupal

00:51:09,930 --> 00:51:14,670
con Vienna site and go to the session

00:51:12,299 --> 00:51:16,440
node and you'll find a link to an

00:51:14,670 --> 00:51:18,390
evaluation survey on the page for the

00:51:16,440 --> 00:51:21,509
session and I would love to have your

00:51:18,390 --> 00:51:23,249
feedback I'm happy to answer any

00:51:21,509 --> 00:51:25,650
questions or you can find me in the

00:51:23,249 --> 00:51:27,690
hallway afterward or you can find me on

00:51:25,650 --> 00:51:30,059
Twitter so if there's any questions

00:51:27,690 --> 00:51:33,230
please feel free to use the the mic in

00:51:30,059 --> 00:51:36,969
the center and thank you

00:51:33,230 --> 00:51:36,969
[Applause]

00:51:39,479 --> 00:51:45,880
hi I was just wondering you mentioned

00:51:42,400 --> 00:51:48,460
the testing which was useful information

00:51:45,880 --> 00:51:51,450
to see that have you done any automated

00:51:48,460 --> 00:51:55,450
testing with any of the voice assistants

00:51:51,450 --> 00:51:59,410
no have you considered it and are you

00:51:55,450 --> 00:52:01,479
intending to no no I just do this for

00:51:59,410 --> 00:52:04,599
fun this is like my evening and weekend

00:52:01,479 --> 00:52:09,009
thing to keep me sane from doing Drupal

00:52:04,599 --> 00:52:12,130
yeah so I mean I'm pretty much dabbling

00:52:09,009 --> 00:52:14,200
just with the home assistant project if

00:52:12,130 --> 00:52:17,470
that one before so I've just recently

00:52:14,200 --> 00:52:20,229
integrated that so I can now use Google

00:52:17,470 --> 00:52:23,410
Google's assistant to talk to my home

00:52:20,229 --> 00:52:25,569
assistant to turn my lights on or open

00:52:23,410 --> 00:52:27,160
the garage and so on or just if I

00:52:25,569 --> 00:52:29,470
continue going down that route I

00:52:27,160 --> 00:52:31,930
probably get to a stage where I want the

00:52:29,470 --> 00:52:33,849
automated testing so that sounds like a

00:52:31,930 --> 00:52:36,609
really good idea yeah you know if the

00:52:33,849 --> 00:52:38,979
testing tool has an API Yui just I don't

00:52:36,609 --> 00:52:40,059
know no thank you for your questioning

00:52:38,979 --> 00:52:42,809
because that's a good thing to consider

00:52:40,059 --> 00:52:44,619
thanks for bringing that up

00:52:42,809 --> 00:52:47,529
any other questions

00:52:44,619 --> 00:52:49,239
all right thank you very much and if

00:52:47,529 --> 00:52:52,170
something comes to mind please come and

00:52:49,239 --> 00:52:52,170

YouTube URL: https://www.youtube.com/watch?v=zczMUU-Ct0M


