Title: A Year with Apache Aurora - Rick Mangi, Chartbeat
Publication date: 2017-10-31
Playlist: MesosCon Europe 2017
Description: 
	A Year with Apache Aurora - Rick Mangi, Chartbeat

Chartbeat, a real time web publishing analytics platform made the decision last year to migrate the bulk of our workload from puppet managed AWS EC2 instances to Aurora. Today, the majority of our migration is done and this talk will focus on what we learned and the decisions made along the way, including what not to migrate to Aurora. We chose to adopt Aurora for a variety of reasons: cost savings from better resource utilization, consistent deployments and monitoring of services, streamlining of the development workflow and the ability to approach scaling our platform holistically. Aurora has helped us to reign in server sprawl and get a much better handle on our footprint. We don't claim to have done everything "right", but it works for us and that's all that matters.

About Rick Mangi
Head of Platform Engineering and DevOps (Platopus) at Chartbeat, Rick is a 20 year industry veteran focused on startups in the publishing and media space. At Chartbeat, he has been focused on bringing a successful startup to the next level of efficiency and reliability with apache aurora, kafka, and a whole lot of aws. Previously, he has only spoken at meetups but feels like he has enough gray hair to be worth listening to.
Captions: 
	00:00:00,030 --> 00:00:06,870
hey everybody how many people before you

00:00:04,770 --> 00:00:10,050
saw the schedule had ever heard of chart

00:00:06,870 --> 00:00:13,740
beat and I imagine no one excellent as I

00:00:10,050 --> 00:00:16,500
expected before I get started I'll warn

00:00:13,740 --> 00:00:18,240
you I'm from New York I talk fast I'm

00:00:16,500 --> 00:00:21,539
gonna try to slow down a little bit I

00:00:18,240 --> 00:00:23,820
might say some funny things but you know

00:00:21,539 --> 00:00:26,640
that's that is what it is so let's get

00:00:23,820 --> 00:00:30,119
started so yeah the topic of this talk

00:00:26,640 --> 00:00:31,710
is a year with the patchy Aurora I put a

00:00:30,119 --> 00:00:33,149
little asterisk there because it's

00:00:31,710 --> 00:00:34,920
actually been almost two years at this

00:00:33,149 --> 00:00:38,070
point since I submitted this started

00:00:34,920 --> 00:00:44,570
submitting the talk and maybe 18 months

00:00:38,070 --> 00:00:44,570
we've actively been using Aurora so see

00:00:48,660 --> 00:00:52,110
there we go okay so here's what we're

00:00:50,520 --> 00:00:53,370
gonna talk about today first who is

00:00:52,110 --> 00:00:55,650
chart beat because as we've established

00:00:53,370 --> 00:00:58,890
no one has ever heard of us what our

00:00:55,650 --> 00:01:01,980
architecture looks like how or why we

00:00:58,890 --> 00:01:03,870
adopted mesas and and Aurora how we

00:01:01,980 --> 00:01:05,129
active actually use Aurora and then

00:01:03,870 --> 00:01:06,510
we're gonna take a deeper look into some

00:01:05,129 --> 00:01:09,900
of the interesting features that we

00:01:06,510 --> 00:01:12,300
found so about chart beat we're 75

00:01:09,900 --> 00:01:15,270
employees we're eight years-old venture

00:01:12,300 --> 00:01:17,310
capital back startup in New York City we

00:01:15,270 --> 00:01:19,770
have somewhere north of 20 engineers

00:01:17,310 --> 00:01:21,509
that includes front-end engineers data

00:01:19,770 --> 00:01:24,420
scientists and a bunch of back-end

00:01:21,509 --> 00:01:25,860
engineers and my team which is five of

00:01:24,420 --> 00:01:28,369
us and we're the platform and devops

00:01:25,860 --> 00:01:31,200
came we call ourselves the platypus team

00:01:28,369 --> 00:01:33,990
and that five includes myself and also

00:01:31,200 --> 00:01:36,240
our CTO who unfortunately is usually in

00:01:33,990 --> 00:01:37,729
meetings so but he's a really good

00:01:36,240 --> 00:01:40,860
programmer so we like it when we get him

00:01:37,729 --> 00:01:42,240
we're in New York City where if you know

00:01:40,860 --> 00:01:44,250
New York we're just south of Union

00:01:42,240 --> 00:01:46,740
Square above the Strand bookstore it's

00:01:44,250 --> 00:01:50,130
an awesome location and we're entirely

00:01:46,740 --> 00:01:53,009
hosted on AWS and every engineer at our

00:01:50,130 --> 00:01:55,619
organization pushes code all the time so

00:01:53,009 --> 00:01:57,450
who what do we do so this is the

00:01:55,619 --> 00:01:59,759
marketing slide you know they gave me a

00:01:57,450 --> 00:02:01,709
couple I had to put in here and our

00:01:59,759 --> 00:02:03,229
mission statement is we are the content

00:02:01,709 --> 00:02:05,640
intelligence platform that empowers

00:02:03,229 --> 00:02:07,229
storytellers audience builders and

00:02:05,640 --> 00:02:10,830
analysts to drive the stories that

00:02:07,229 --> 00:02:13,319
change the world and our customers are

00:02:10,830 --> 00:02:16,170
the press so we work for most of the

00:02:13,319 --> 00:02:18,660
large news news agencies online

00:02:16,170 --> 00:02:22,380
magazines big blogs everyone from the

00:02:18,660 --> 00:02:27,209
New York Times Washington Post BBC a lot

00:02:22,380 --> 00:02:30,989
of the press in Europe and we get a lot

00:02:27,209 --> 00:02:32,370
of traffic so basically the short story

00:02:30,989 --> 00:02:34,290
is we put a little JavaScript on

00:02:32,370 --> 00:02:36,300
everyone's page and that pings us all

00:02:34,290 --> 00:02:37,920
the time and we can measure how far our

00:02:36,300 --> 00:02:40,230
user went how long they spent reading a

00:02:37,920 --> 00:02:42,989
page and all that and it turns out to be

00:02:40,230 --> 00:02:45,530
about 300,000 requests a second coming

00:02:42,989 --> 00:02:48,480
in just with those JavaScript pings

00:02:45,530 --> 00:02:50,879
we're on 50,000 over 50,000 websites

00:02:48,480 --> 00:02:55,819
around the world and we track about 50

00:02:50,879 --> 00:02:55,819
billion site page visits a month

00:02:56,069 --> 00:03:02,560
so okay this is what it looks like so we

00:03:00,220 --> 00:03:07,330
have whoa I just went too far

00:03:02,560 --> 00:03:10,690
trying to get the laser pointer here

00:03:07,330 --> 00:03:13,810
okay so I forgot laser pointer so we

00:03:10,690 --> 00:03:16,239
have dashboards real-time historic and

00:03:13,810 --> 00:03:18,370
video dashboards and when our customers

00:03:16,239 --> 00:03:20,440
log in they get a pretty view in real

00:03:18,370 --> 00:03:24,640
time of how people are using their page

00:03:20,440 --> 00:03:25,840
so you this is a PRI a public radio

00:03:24,640 --> 00:03:27,310
international they're one of the

00:03:25,840 --> 00:03:30,730
customers that lets us use their their

00:03:27,310 --> 00:03:32,709
data and they currently have 494 people

00:03:30,730 --> 00:03:34,840
on there I believe this is probably

00:03:32,709 --> 00:03:37,420
their homepage I did this early in the

00:03:34,840 --> 00:03:39,670
morning so you know the traffic picks up

00:03:37,420 --> 00:03:42,099
and the average time someone spends on

00:03:39,670 --> 00:03:43,840
this page is 45 seconds you can drill

00:03:42,099 --> 00:03:45,700
into all the different pages you can

00:03:43,840 --> 00:03:48,879
pivot on author and section and all that

00:03:45,700 --> 00:03:50,019
cool stuff and we also do optimization

00:03:48,879 --> 00:03:51,790
so we have something we call the heads

00:03:50,019 --> 00:03:56,319
up display when you go on to your

00:03:51,790 --> 00:03:59,980
website and this is NRC NL you can see

00:03:56,319 --> 00:04:01,660
these these bars that show what how each

00:03:59,980 --> 00:04:03,430
of the click throughs is behaving on

00:04:01,660 --> 00:04:05,290
every page on your site so they use this

00:04:03,430 --> 00:04:08,230
to decide hey you know that story down

00:04:05,290 --> 00:04:10,569
there about Obama is doing really well

00:04:08,230 --> 00:04:11,200
let's keep it on the homepage this the

00:04:10,569 --> 00:04:13,239
one next to it

00:04:11,200 --> 00:04:14,980
something about Quebec sorry don't be

00:04:13,239 --> 00:04:16,359
Dutch isn't doing that well they might

00:04:14,980 --> 00:04:16,900
want to push that down or do something

00:04:16,359 --> 00:04:18,489
else with it

00:04:16,900 --> 00:04:19,660
or move it up if they want to put it in

00:04:18,489 --> 00:04:21,549
a better position so maybe they want to

00:04:19,660 --> 00:04:24,820
swap that and get more traffic going to

00:04:21,549 --> 00:04:25,930
that story if they want so I think it's

00:04:24,820 --> 00:04:27,250
really important in any talk like this

00:04:25,930 --> 00:04:28,990
to understand what the or how the

00:04:27,250 --> 00:04:30,880
organization approaches software

00:04:28,990 --> 00:04:32,260
engineering I don't think we're quite

00:04:30,880 --> 00:04:34,300
unique but we definitely have our own

00:04:32,260 --> 00:04:36,400
way of doing things so this is my

00:04:34,300 --> 00:04:38,260
favorite quote I try to use it anytime I

00:04:36,400 --> 00:04:39,820
give a talk it's really old it's one of

00:04:38,260 --> 00:04:41,889
the quotes that inspired me when I was

00:04:39,820 --> 00:04:44,410
like 22 years old right out of college

00:04:41,889 --> 00:04:47,169
engineering and it's by Larry wall who

00:04:44,410 --> 00:04:49,630
wrote Perl and he said in the first

00:04:47,169 --> 00:04:51,220
edition of the programming Perl book we

00:04:49,630 --> 00:04:53,710
will encourage you to develop the three

00:04:51,220 --> 00:04:56,650
great virtues of a programmer laziness

00:04:53,710 --> 00:04:58,690
impatience and hubris and he got some

00:04:56,650 --> 00:05:00,669
pushback on this and so in follow-up

00:04:58,690 --> 00:05:02,199
editions they expanded on what they

00:05:00,669 --> 00:05:04,000
really meant and they don't mean I

00:05:02,199 --> 00:05:06,550
should be lazy they mean that I should

00:05:04,000 --> 00:05:08,890
be actively writing code to allow myself

00:05:06,550 --> 00:05:09,160
to be lazy right I shouldn't be lazy I

00:05:08,890 --> 00:05:10,480
should

00:05:09,160 --> 00:05:12,580
lazy because the computer is not

00:05:10,480 --> 00:05:13,960
programming fast enough for me it's not

00:05:12,580 --> 00:05:15,850
giving me back my response so I'm gonna

00:05:13,960 --> 00:05:18,880
write code to make it do things faster

00:05:15,850 --> 00:05:21,190
and if you don't have a lot of hubris

00:05:18,880 --> 00:05:22,570
you can't be an engineer because you

00:05:21,190 --> 00:05:24,490
have to believe that you can do anything

00:05:22,570 --> 00:05:27,670
and make that computer do what you want

00:05:24,490 --> 00:05:31,210
so how does this translate into truck

00:05:27,670 --> 00:05:32,620
beats engineering standards so the

00:05:31,210 --> 00:05:35,680
platform team wrote a mission statement

00:05:32,620 --> 00:05:38,860
because they told us we had to with some

00:05:35,680 --> 00:05:40,810
sort of okay our KPI thing and we came

00:05:38,860 --> 00:05:42,940
up with this that our mission is to

00:05:40,810 --> 00:05:45,190
build an effective efficient platform

00:05:42,940 --> 00:05:47,200
and secure development platform for

00:05:45,190 --> 00:05:48,160
chart beat engineers because we believe

00:05:47,200 --> 00:05:50,320
that an efficient and effective

00:05:48,160 --> 00:05:55,840
development platform leads to fast

00:05:50,320 --> 00:05:57,460
execution so how do we operate in a day

00:05:55,840 --> 00:05:59,620
to day basis and like I said I don't

00:05:57,460 --> 00:06:02,380
think this is unique it's definitely

00:05:59,620 --> 00:06:06,910
unique compared to engineering 25 years

00:06:02,380 --> 00:06:08,260
ago when I started when we had CVS so

00:06:06,910 --> 00:06:09,610
git is the source of truth for

00:06:08,260 --> 00:06:11,380
everything right we store our

00:06:09,610 --> 00:06:13,660
configurations for our entire Amazon

00:06:11,380 --> 00:06:16,300
infrastructure and get so we can always

00:06:13,660 --> 00:06:18,190
reproduce it anytime we want everything

00:06:16,300 --> 00:06:18,670
that gets deployed is deployed by a GUID

00:06:18,190 --> 00:06:21,430
hash

00:06:18,670 --> 00:06:23,830
except for Java stuff we use semantic

00:06:21,430 --> 00:06:27,130
versioning for that we might be able to

00:06:23,830 --> 00:06:29,140
fix that later but engineers run the

00:06:27,130 --> 00:06:30,100
code on the laptop they brought in a dev

00:06:29,140 --> 00:06:31,690
environment they've run it in a

00:06:30,100 --> 00:06:33,130
production environment we prefer the

00:06:31,690 --> 00:06:33,850
command line everyone likes to do things

00:06:33,130 --> 00:06:36,340
from the command line

00:06:33,850 --> 00:06:38,290
I'm probably one of the few that

00:06:36,340 --> 00:06:39,820
actually uses an IDE because I'm old and

00:06:38,290 --> 00:06:42,280
I like IDs because they didn't exist

00:06:39,820 --> 00:06:44,310
when I was a kid but other people just

00:06:42,280 --> 00:06:46,900
use them or whatever

00:06:44,310 --> 00:06:49,660
we prefer writing scripts to memorizing

00:06:46,900 --> 00:06:51,160
commands right because my brain is full

00:06:49,660 --> 00:06:53,650
of other things other than an esoteric

00:06:51,160 --> 00:06:55,690
commands and we don't reinvent things at

00:06:53,650 --> 00:06:58,060
work we're small we make templates and

00:06:55,690 --> 00:07:00,040
we write scripts to automate things as

00:06:58,060 --> 00:07:03,160
far as programming we are almost

00:07:00,040 --> 00:07:04,419
exclusively Python and closure with the

00:07:03,160 --> 00:07:06,820
exception JavaScript for the front end

00:07:04,419 --> 00:07:07,710
but I don't understand that I don't use

00:07:06,820 --> 00:07:12,340
it

00:07:07,710 --> 00:07:15,700
so why maysa why now we're eight years

00:07:12,340 --> 00:07:16,990
old were by you know everyone seems to

00:07:15,700 --> 00:07:19,630
think we're very successful company in

00:07:16,990 --> 00:07:20,860
our industry so why would we make such a

00:07:19,630 --> 00:07:23,350
big switch

00:07:20,860 --> 00:07:25,060
so I feel like the freedom to innovate

00:07:23,350 --> 00:07:26,470
is the result of a successful product

00:07:25,060 --> 00:07:27,490
right we want to set ourselves up for

00:07:26,470 --> 00:07:29,320
the next five years

00:07:27,490 --> 00:07:30,880
you know chart beats gotten to this

00:07:29,320 --> 00:07:32,710
great point we have a lot of customers

00:07:30,880 --> 00:07:34,570
and you know we're we have good revenue

00:07:32,710 --> 00:07:36,010
where do we want to be five years from

00:07:34,570 --> 00:07:38,680
now so that's what this project was

00:07:36,010 --> 00:07:41,200
about we wanted to reduce our server

00:07:38,680 --> 00:07:43,720
footprint to save money as a lot of

00:07:41,200 --> 00:07:45,220
folks have mentioned here we want to

00:07:43,720 --> 00:07:47,800
provide faster and more reliable service

00:07:45,220 --> 00:07:50,100
to our customers we wanted to migrate

00:07:47,800 --> 00:07:53,470
all of our jobs in one year to whatever

00:07:50,100 --> 00:07:54,730
system we decided to use and while we're

00:07:53,470 --> 00:07:56,470
doing that we want to pay off tech debt

00:07:54,730 --> 00:07:58,420
right because you're gonna take the

00:07:56,470 --> 00:08:00,430
effort to move a bunch of jobs over to a

00:07:58,420 --> 00:08:02,230
new system you should probably address

00:08:00,430 --> 00:08:04,030
you know hey does this job really need

00:08:02,230 --> 00:08:05,620
to be here anymore should we spend a

00:08:04,030 --> 00:08:07,690
couple days tighten it up doing whatever

00:08:05,620 --> 00:08:09,370
and you got stuff running that yeah oh

00:08:07,690 --> 00:08:11,560
my god that's still running it's been up

00:08:09,370 --> 00:08:15,640
for five years and no one knew so let's

00:08:11,560 --> 00:08:16,990
not move that most importantly we wanted

00:08:15,640 --> 00:08:21,970
to make life better for our engineers

00:08:16,990 --> 00:08:24,610
right we wanted happy engineers so come

00:08:21,970 --> 00:08:25,720
to today we have a moderate-sized

00:08:24,610 --> 00:08:28,750
cluster compared to what I've heard

00:08:25,720 --> 00:08:30,970
around here we have 300 1,350 cores in

00:08:28,750 --> 00:08:32,940
our in our cluster and almost everything

00:08:30,970 --> 00:08:36,970
that we run is now in Mesa

00:08:32,940 --> 00:08:38,170
ok so what's a happy engineer so happy

00:08:36,970 --> 00:08:39,340
engineers are productive engineers

00:08:38,170 --> 00:08:40,810
because engineers want to be productive

00:08:39,340 --> 00:08:42,310
right you got into this industry because

00:08:40,810 --> 00:08:45,010
you're curious you want to build stuff

00:08:42,310 --> 00:08:47,560
and if you can't build that you're gonna

00:08:45,010 --> 00:08:49,270
get frustrated so they like uneventful

00:08:47,560 --> 00:08:50,920
on-call rotations like a lot of

00:08:49,270 --> 00:08:52,990
companies our size every engineers on

00:08:50,920 --> 00:08:54,370
call right it's a one-week on call with

00:08:52,990 --> 00:08:55,870
a backup person you could woken up in

00:08:54,370 --> 00:08:57,880
the middle of the night if you're like

00:08:55,870 --> 00:09:00,760
dude I just got woken up this sucks

00:08:57,880 --> 00:09:02,800
right so they don't want to have to do

00:09:00,760 --> 00:09:04,240
anything when they're on call they want

00:09:02,800 --> 00:09:05,320
to push things quickly you know they

00:09:04,240 --> 00:09:07,420
don't want to have to jump through hoops

00:09:05,320 --> 00:09:09,130
to get their code into production they

00:09:07,420 --> 00:09:11,320
want to be able to monitor and debug

00:09:09,130 --> 00:09:13,350
their applications easily they want to

00:09:11,320 --> 00:09:16,360
be able to scale their applications

00:09:13,350 --> 00:09:17,320
really they want to when I should say we

00:09:16,360 --> 00:09:18,730
don't talk about engineers now I'm

00:09:17,320 --> 00:09:21,280
talking about our product engineers the

00:09:18,730 --> 00:09:22,480
guys who we work for they want to write

00:09:21,280 --> 00:09:23,770
product code right they want to write

00:09:22,480 --> 00:09:25,390
JavaScript they want to write Python API

00:09:23,770 --> 00:09:27,610
so they don't want to mess with DevOps

00:09:25,390 --> 00:09:28,780
so they want self-service DevOps that's

00:09:27,610 --> 00:09:31,480
easy to use and that's where we would

00:09:28,780 --> 00:09:33,940
set out to build so what do we do first

00:09:31,480 --> 00:09:34,690
so before may sews we had a lot of

00:09:33,940 --> 00:09:37,240
puppet

00:09:34,690 --> 00:09:39,550
right we had Huayra rolls and puppet

00:09:37,240 --> 00:09:42,459
that map to Amazon AWS tags for the

00:09:39,550 --> 00:09:44,529
instances we built virtually Envy's into

00:09:42,459 --> 00:09:46,680
Debian's for our Python code so that we

00:09:44,529 --> 00:09:50,110
could capture all the dependencies

00:09:46,680 --> 00:09:52,930
mostly we had single purpose servers we

00:09:50,110 --> 00:09:54,939
use fabric to go in and restart jobs and

00:09:52,930 --> 00:09:56,620
stuff like that it is flexible

00:09:54,939 --> 00:09:58,360
I mean puppets great it's very flexible

00:09:56,620 --> 00:10:01,300
but it's really complicated right you

00:09:58,360 --> 00:10:03,759
got Ruby and you've got Huayra and it's

00:10:01,300 --> 00:10:06,490
it's it's it's really complicated so say

00:10:03,759 --> 00:10:09,129
you have this project foo right foo had

00:10:06,490 --> 00:10:10,930
an api service a Kafka consumer some

00:10:09,129 --> 00:10:13,569
cron job workers that go and do some

00:10:10,930 --> 00:10:16,389
database roll-ups and stuff and you you

00:10:13,569 --> 00:10:21,009
basically build out through API o 1 o 2

00:10:16,389 --> 00:10:24,069
o 3 or 4 or 5 foo Kafka consumer 1 2 3 4

00:10:21,009 --> 00:10:25,420
5 6 7 8 9 10 16 right and then all these

00:10:24,069 --> 00:10:27,129
workers so you have all you basically

00:10:25,420 --> 00:10:30,310
just scale out horizontally with your

00:10:27,129 --> 00:10:33,250
single app so what happens when we've

00:10:30,310 --> 00:10:34,930
got a whole bunch of apps you know all

00:10:33,250 --> 00:10:36,399
of a sudden foo has a whole bunch of

00:10:34,930 --> 00:10:38,470
servers bar has a whole bunch of servers

00:10:36,399 --> 00:10:41,850
there's a whole bunch of servers we

00:10:38,470 --> 00:10:44,439
found ourselves with 773 ec2 instances

00:10:41,850 --> 00:10:48,819
you know for a company with 25 people

00:10:44,439 --> 00:10:50,560
that's 25 engineers that's a lot during

00:10:48,819 --> 00:10:52,000
the u.s. election last year we broke a

00:10:50,560 --> 00:10:54,009
thousand instances and we were like

00:10:52,000 --> 00:10:57,970
that's a lot

00:10:54,009 --> 00:11:00,279
we are 125 different roles in puppet it

00:10:57,970 --> 00:11:01,959
was really hard on DevOps is confusing

00:11:00,279 --> 00:11:04,870
for the product engineers we've wasted

00:11:01,959 --> 00:11:06,069
resources it was really hard to scale so

00:11:04,870 --> 00:11:08,680
we started looking at it and we say you

00:11:06,069 --> 00:11:11,170
know we're wasting something like 40 50

00:11:08,680 --> 00:11:15,399
percent of our CPU and RAM and that's

00:11:11,170 --> 00:11:17,470
just not really cool so we decided that

00:11:15,399 --> 00:11:18,970
whenever we built had to allow us to

00:11:17,470 --> 00:11:22,029
solve the Python dependency management

00:11:18,970 --> 00:11:23,380
solution problem for once and for all it

00:11:22,029 --> 00:11:24,610
had to play nicely with our current work

00:11:23,380 --> 00:11:25,779
for we didn't want to tell all of our

00:11:24,610 --> 00:11:27,130
engineers on now you have to do it all

00:11:25,779 --> 00:11:29,259
this way right because they're used to

00:11:27,130 --> 00:11:30,430
doing things their way so it had to be

00:11:29,259 --> 00:11:32,769
hackable so that we can kind of

00:11:30,430 --> 00:11:34,269
customize and tweak it it had to be open

00:11:32,769 --> 00:11:36,519
source we only use open source software

00:11:34,269 --> 00:11:39,339
with the exception of some amazon

00:11:36,519 --> 00:11:40,930
databases it had to be supported by an

00:11:39,339 --> 00:11:44,110
active community that's actually using

00:11:40,930 --> 00:11:45,790
the stuff in the real world it had to

00:11:44,110 --> 00:11:47,529
allow us to slow do this migration over

00:11:45,790 --> 00:11:48,290
time right and it had to make our

00:11:47,529 --> 00:11:52,860
engineers have

00:11:48,290 --> 00:11:54,690
so we chose Aurora I'm not gonna get

00:11:52,860 --> 00:11:55,740
into why we chose Aurora happy to have a

00:11:54,690 --> 00:11:57,930
beer later if you want to talk about

00:11:55,740 --> 00:11:59,220
that compared to and I've also by the

00:11:57,930 --> 00:12:00,330
way written a couple blog posts about

00:11:59,220 --> 00:12:02,339
this where I get into some of the

00:12:00,330 --> 00:12:06,810
details of why we chose Aurora versus

00:12:02,339 --> 00:12:08,580
Marathon so what is arrived if you

00:12:06,810 --> 00:12:10,560
haven't used the rora it's a maze host

00:12:08,580 --> 00:12:13,170
framework for long-running processes and

00:12:10,560 --> 00:12:14,850
cron jobs it was built by Twitter I was

00:12:13,170 --> 00:12:17,880
based on Borg they had an engineer who

00:12:14,850 --> 00:12:20,040
had previously worked on Borg they they

00:12:17,880 --> 00:12:22,560
launched it at Twitter in 2010 and it

00:12:20,040 --> 00:12:23,550
joined the Apache Incubator in 2013 I'm

00:12:22,560 --> 00:12:24,899
not quite sure when it became a

00:12:23,550 --> 00:12:27,420
top-level project but I'm sure someone

00:12:24,899 --> 00:12:28,230
here knows they're currently on released

00:12:27,420 --> 00:12:29,970
0:18

00:12:28,230 --> 00:12:31,290
and about every six months they roll a

00:12:29,970 --> 00:12:34,050
new release a new releases always

00:12:31,290 --> 00:12:35,730
support the latest maysa version it's

00:12:34,050 --> 00:12:40,740
got a very active user community and

00:12:35,730 --> 00:12:43,800
it's written in Java and Python so

00:12:40,740 --> 00:12:46,410
basically this is Aurora you know over

00:12:43,800 --> 00:12:48,180
on the left side you have a framework

00:12:46,410 --> 00:12:50,339
that's registered in May so's there's an

00:12:48,180 --> 00:12:53,100
agent that runs on each of your servers

00:12:50,339 --> 00:12:56,700
that receives the the instructions to go

00:12:53,100 --> 00:12:59,370
ahead and launch a new job everything in

00:12:56,700 --> 00:13:01,529
Aurora runs inside a sandbox container

00:12:59,370 --> 00:13:04,200
right so you get a directory it's a true

00:13:01,529 --> 00:13:05,760
and in there all your stuff goes and

00:13:04,200 --> 00:13:09,270
your whatever user you launch the job as

00:13:05,760 --> 00:13:12,000
as has permissions for that tree they

00:13:09,270 --> 00:13:14,520
have an observer which basically lets

00:13:12,000 --> 00:13:16,709
you through a UI come in and look at

00:13:14,520 --> 00:13:19,140
your jobs you can look at the log files

00:13:16,709 --> 00:13:20,730
and that sort of stuff and they have an

00:13:19,140 --> 00:13:24,000
executor that monitors the life of the

00:13:20,730 --> 00:13:26,520
job so they define things as jobs so a

00:13:24,000 --> 00:13:29,820
job might be an API server and I'd say I

00:13:26,520 --> 00:13:31,980
want 42 of them right so yeah that's 42

00:13:29,820 --> 00:13:35,610
tasks and masers goes ahead and

00:13:31,980 --> 00:13:39,350
schedules them inside thermos is the the

00:13:35,610 --> 00:13:41,910
executor inside thermos you get

00:13:39,350 --> 00:13:45,120
processes so you can run multiple things

00:13:41,910 --> 00:13:47,490
in in parallel in pipelines something

00:13:45,120 --> 00:13:48,810
can install a job then run a job health

00:13:47,490 --> 00:13:52,230
check there's that sort of things those

00:13:48,810 --> 00:13:53,610
are all processes so some of the

00:13:52,230 --> 00:13:56,220
features of Aurora that we've found

00:13:53,610 --> 00:13:57,930
useful so all the job templating is in

00:13:56,220 --> 00:13:59,550
Python which means you can do anything

00:13:57,930 --> 00:14:01,630
right and everyone loves Python these

00:13:59,550 --> 00:14:04,750
days

00:14:01,630 --> 00:14:06,670
one problem we had with with puppet

00:14:04,750 --> 00:14:08,590
instances is when something died it

00:14:06,670 --> 00:14:09,790
where it got wedged which is a very

00:14:08,590 --> 00:14:11,860
technical term that we like to use

00:14:09,790 --> 00:14:13,810
someone had to actually log in in the

00:14:11,860 --> 00:14:16,960
machine we started figure out what's

00:14:13,810 --> 00:14:19,330
going on now if if a process gets wedged

00:14:16,960 --> 00:14:21,640
a health checker in Aurora will say hey

00:14:19,330 --> 00:14:23,800
that that thing's not doing whatever you

00:14:21,640 --> 00:14:25,180
said the health check was like it's I

00:14:23,800 --> 00:14:27,040
don't see anything in the log file I

00:14:25,180 --> 00:14:29,500
can't hit this port it kills it

00:14:27,040 --> 00:14:31,330
rescheduled it no one cares that no one

00:14:29,500 --> 00:14:34,180
even knows I mean we obviously do know

00:14:31,330 --> 00:14:36,100
but no one has to do anything it's it

00:14:34,180 --> 00:14:39,370
has a very hackable CLI which I'm going

00:14:36,100 --> 00:14:42,580
to get into it does service discovery

00:14:39,370 --> 00:14:44,440
using finagle through zookeeper you can

00:14:42,580 --> 00:14:47,200
map ports obviously all around it has a

00:14:44,440 --> 00:14:49,270
good API and something that I actually

00:14:47,200 --> 00:14:51,580
found really cool that I initially

00:14:49,270 --> 00:14:56,310
thought was kind of weird was the way

00:14:51,580 --> 00:14:58,510
they named jobs by cluster organization

00:14:56,310 --> 00:15:00,250
environment and then the job name which

00:14:58,510 --> 00:15:04,000
helps in zookeeper and in all of our

00:15:00,250 --> 00:15:07,390
metrics for knowing what's what so this

00:15:04,000 --> 00:15:10,870
is how what would they call a dot Aurora

00:15:07,390 --> 00:15:13,120
file looks that this is where you define

00:15:10,870 --> 00:15:16,270
your job description in Aurora so every

00:15:13,120 --> 00:15:18,840
job in in basic or you have an Aurora

00:15:16,270 --> 00:15:22,900
file which can define multiple jobs

00:15:18,840 --> 00:15:24,430
there Python as I said and the processes

00:15:22,900 --> 00:15:26,110
are basically any kind of UNIX thing

00:15:24,430 --> 00:15:27,850
that you can do so in this case we

00:15:26,110 --> 00:15:29,620
define the path to some this is the

00:15:27,850 --> 00:15:31,000
hello world from the Aurora website by

00:15:29,620 --> 00:15:34,180
the way I took a couple things out

00:15:31,000 --> 00:15:35,440
because they were esoteric so you define

00:15:34,180 --> 00:15:37,120
the name of the script you want to run

00:15:35,440 --> 00:15:39,280
you have a process which is you're gonna

00:15:37,120 --> 00:15:41,320
call installer you're gonna name it

00:15:39,280 --> 00:15:42,880
fetch package and it's gonna go and copy

00:15:41,320 --> 00:15:45,370
the thing from this directory slash

00:15:42,880 --> 00:15:47,530
vagrant into your local sandbox it's

00:15:45,370 --> 00:15:49,120
gonna print something saying here I did

00:15:47,530 --> 00:15:53,710
this and then it's gonna make it

00:15:49,120 --> 00:15:55,450
executable and run it I'm sorry

00:15:53,710 --> 00:15:57,070
make it executable the next process runs

00:15:55,450 --> 00:15:59,110
it right so I had one that installed it

00:15:57,070 --> 00:16:00,640
now this one's gonna run it so because

00:15:59,110 --> 00:16:02,020
the head and just calls Python it's just

00:16:00,640 --> 00:16:04,570
you know obviously does a UNIX

00:16:02,020 --> 00:16:06,700
command-line statement so then I go

00:16:04,570 --> 00:16:08,410
ahead and I link those two things

00:16:06,700 --> 00:16:10,540
together so I'm gonna do an install and

00:16:08,410 --> 00:16:13,690
then I'm gonna run hello world and I

00:16:10,540 --> 00:16:14,510
need one CPU mega RAM and eight Meg's of

00:16:13,690 --> 00:16:18,260
disk to

00:16:14,510 --> 00:16:20,240
so and I call that HelloWorld tasks so

00:16:18,260 --> 00:16:22,850
then I go ahead and define my top level

00:16:20,240 --> 00:16:24,890
job and I say it's going to run on the

00:16:22,850 --> 00:16:27,770
dev cluster it's going to run as the

00:16:24,890 --> 00:16:29,600
user devel I'm sorry in the environment

00:16:27,770 --> 00:16:32,300
devel there's develop rod and test

00:16:29,600 --> 00:16:36,040
environments I'm gonna run it using the

00:16:32,300 --> 00:16:39,920
dug up data user call it hello world and

00:16:36,040 --> 00:16:41,870
go ahead and it runs it so you know I

00:16:39,920 --> 00:16:44,720
find that DevOps is a balance between

00:16:41,870 --> 00:16:46,850
flexibility and reliability right you

00:16:44,720 --> 00:16:49,100
want to let your your users do what they

00:16:46,850 --> 00:16:50,390
want to do but you need to be safe all

00:16:49,100 --> 00:16:52,100
right you want to protect them from

00:16:50,390 --> 00:16:53,810
doing silly things and at the same time

00:16:52,100 --> 00:16:56,210
make your job as a DevOps engineer

00:16:53,810 --> 00:16:58,070
easier because if you know how things

00:16:56,210 --> 00:17:00,380
are running if you have control over it

00:16:58,070 --> 00:17:01,850
you can manage it if you let your users

00:17:00,380 --> 00:17:03,920
kind of do whatever they want that's

00:17:01,850 --> 00:17:06,680
great until it becomes a nightmare for

00:17:03,920 --> 00:17:10,730
you so we wanted to make this much more

00:17:06,680 --> 00:17:12,740
kind of more structured and the reason

00:17:10,730 --> 00:17:15,380
is because when we looked at the work

00:17:12,740 --> 00:17:17,300
that we do almost everything we do falls

00:17:15,380 --> 00:17:19,579
into three categories right we have

00:17:17,300 --> 00:17:22,250
Kafka consumers that read off a Kafka

00:17:19,579 --> 00:17:25,280
right to a database or to another Kafka

00:17:22,250 --> 00:17:27,320
topic we have workers that listen to a

00:17:25,280 --> 00:17:29,270
rabbit queue and get work and then they

00:17:27,320 --> 00:17:31,430
go and most of them doing something like

00:17:29,270 --> 00:17:32,840
taking hours worth of data from this

00:17:31,430 --> 00:17:34,430
database and turn it into a five-minute

00:17:32,840 --> 00:17:36,890
roll-up or a copy of some stuff from

00:17:34,430 --> 00:17:39,890
here to there and then we have api's

00:17:36,890 --> 00:17:41,780
right so we have closure consumers Kafka

00:17:39,890 --> 00:17:44,060
consumers we have Python workers and we

00:17:41,780 --> 00:17:49,190
have Python API servers that's pretty

00:17:44,060 --> 00:17:51,980
much like 95% of the stuff we do so big

00:17:49,190 --> 00:17:53,870
decision time what do we want to do so

00:17:51,980 --> 00:17:56,330
we decided we're going to adopt pants

00:17:53,870 --> 00:17:58,730
obviously adopt a roar that's the the

00:17:56,330 --> 00:18:00,020
one I already let you know we're gonna

00:17:58,730 --> 00:18:02,180
dot pants I'll talk about pants in a

00:18:00,020 --> 00:18:03,680
second we're gonna wrap this Aurora

00:18:02,180 --> 00:18:06,440
command-line interface with our own

00:18:03,680 --> 00:18:09,050
client that we can add some more kind of

00:18:06,440 --> 00:18:11,000
control around and I'll talk about that

00:18:09,050 --> 00:18:13,400
in a sec I'm going to create a library

00:18:11,000 --> 00:18:15,710
of Aurora templates that make it easy to

00:18:13,400 --> 00:18:17,810
do repetitive things like pull an

00:18:15,710 --> 00:18:21,530
artifact from s3 drop it in here make it

00:18:17,810 --> 00:18:23,630
executable and run it we're gonna just

00:18:21,530 --> 00:18:25,700
let it do its thing we've always had

00:18:23,630 --> 00:18:26,930
issues with log file management it's

00:18:25,700 --> 00:18:27,920
like one of these old the oldest

00:18:26,930 --> 00:18:30,350
problems in the book is

00:18:27,920 --> 00:18:32,630
you know I'll file handles damn it you

00:18:30,350 --> 00:18:36,050
know just filling up and so we said you

00:18:32,630 --> 00:18:38,090
know Aurora it has a disk quota so when

00:18:36,050 --> 00:18:39,740
a job is hits that quota it kills the

00:18:38,090 --> 00:18:40,940
job it restarts it and then it goes

00:18:39,740 --> 00:18:45,320
through periodically and cleans out all

00:18:40,940 --> 00:18:47,570
the sand boxes so let it do that and

00:18:45,320 --> 00:18:49,670
we're gonna not even bother with

00:18:47,570 --> 00:18:51,770
containers so at the point we'd made

00:18:49,670 --> 00:18:53,690
this decision that there was no docker

00:18:51,770 --> 00:18:55,640
support in Aurora and we don't use

00:18:53,690 --> 00:18:56,240
docker we use it a little bit but not

00:18:55,640 --> 00:18:58,310
very much

00:18:56,240 --> 00:18:59,570
so we didn't really care about that we

00:18:58,310 --> 00:19:03,140
said we're just gonna go with these sand

00:18:59,570 --> 00:19:05,800
boxes that sounds fine to us so how do

00:19:03,140 --> 00:19:11,330
we make a brewer fit into our workflow

00:19:05,800 --> 00:19:13,160
so the Aurora file is very powerful you

00:19:11,330 --> 00:19:15,410
can really do anything you can define a

00:19:13,160 --> 00:19:17,060
whole bunch of jobs and go ahead and run

00:19:15,410 --> 00:19:19,010
them but that gets very confusing

00:19:17,060 --> 00:19:21,680
because he as a DevOps engineer you no

00:19:19,010 --> 00:19:22,730
longer know what's running everywhere so

00:19:21,680 --> 00:19:25,220
we decided we're gonna take all the

00:19:22,730 --> 00:19:28,670
common config options out of the Aurora

00:19:25,220 --> 00:19:30,320
file and put them in a Yama file things

00:19:28,670 --> 00:19:32,270
like how many CPUs do you need how much

00:19:30,320 --> 00:19:34,310
RAM do you need that sort of stuff

00:19:32,270 --> 00:19:36,170
flags that that you might want to pass

00:19:34,310 --> 00:19:39,410
the command-line and then the Aurora

00:19:36,170 --> 00:19:41,360
files become much more simple we decided

00:19:39,410 --> 00:19:43,160
that we're gonna require you know

00:19:41,360 --> 00:19:46,550
version artifacts built by our server

00:19:43,160 --> 00:19:48,260
which is what we did before but we

00:19:46,550 --> 00:19:50,810
actually tie that into the client so if

00:19:48,260 --> 00:19:52,220
you you have to specify the get hash in

00:19:50,810 --> 00:19:54,230
our Yama file for what you want to

00:19:52,220 --> 00:19:55,460
deploy and our client actually checks to

00:19:54,230 --> 00:19:57,020
make sure that thing exists before you

00:19:55,460 --> 00:19:58,990
try to launch it so we put in some

00:19:57,020 --> 00:20:01,250
safety nets for our product engineers

00:19:58,990 --> 00:20:02,510
you also have to be on master if you

00:20:01,250 --> 00:20:05,860
want to push something to the production

00:20:02,510 --> 00:20:08,120
the production environment because

00:20:05,860 --> 00:20:10,900
people do silly things especially 2:00

00:20:08,120 --> 00:20:14,900
in the morning when they get woken up so

00:20:10,900 --> 00:20:17,300
we also decided that every Yama file

00:20:14,900 --> 00:20:22,780
specifies one job that job could be

00:20:17,300 --> 00:20:25,100
running develop rod whatever but one

00:20:22,780 --> 00:20:27,500
multiple Yama files can actually point

00:20:25,100 --> 00:20:29,930
to the same Aurora file which has the

00:20:27,500 --> 00:20:31,190
definitions of how the job runs and I'll

00:20:29,930 --> 00:20:35,750
talk about that in a sec it gets very

00:20:31,190 --> 00:20:37,580
interesting all of our configs I

00:20:35,750 --> 00:20:39,140
mentioned already live in the repo which

00:20:37,580 --> 00:20:41,120
makes it really easy to find jobs so we

00:20:39,140 --> 00:20:42,950
have one directory where all of the job

00:20:41,120 --> 00:20:45,320
figurations are you can go and grep and

00:20:42,950 --> 00:20:47,660
you know replace stuff and it's very

00:20:45,320 --> 00:20:50,090
easy to make major changes or to figure

00:20:47,660 --> 00:20:51,410
out what's running where and then we

00:20:50,090 --> 00:20:53,540
also added some additional functionality

00:20:51,410 --> 00:20:57,020
for things like tallying log files as

00:20:53,540 --> 00:21:00,290
they're running so what's the difference

00:20:57,020 --> 00:21:03,230
so on the top this is a what it takes to

00:21:00,290 --> 00:21:05,840
run foo server Arora on the top is the

00:21:03,230 --> 00:21:07,640
basic Arora command line to do it

00:21:05,840 --> 00:21:10,910
they say Arora create there's also a

00:21:07,640 --> 00:21:13,130
rora update which will do a rolling up

00:21:10,910 --> 00:21:16,010
update you can do a restart you can do a

00:21:13,130 --> 00:21:17,630
kill and then you name the job so

00:21:16,010 --> 00:21:19,730
remember I said these they have these

00:21:17,630 --> 00:21:22,550
funny names so it's a a is the cluster

00:21:19,730 --> 00:21:23,480
name we have a and B because one of our

00:21:22,550 --> 00:21:25,760
guys used to work at Google and

00:21:23,480 --> 00:21:27,440
apparently that's what they do a a and

00:21:25,760 --> 00:21:29,690
then CB ops is the name of the user and

00:21:27,440 --> 00:21:32,360
then it's running production called foo

00:21:29,690 --> 00:21:34,010
server and a path to the Aurora file so

00:21:32,360 --> 00:21:36,590
the way we do it we have the saguaro

00:21:34,010 --> 00:21:40,820
managed command it mimics all of the

00:21:36,590 --> 00:21:42,080
commands but it maps to that Yama file

00:21:40,820 --> 00:21:43,670
and it pulls out all the stuff that

00:21:42,080 --> 00:21:45,200
you're not going to remember like the

00:21:43,670 --> 00:21:46,400
name of the user that it's running on

00:21:45,200 --> 00:21:48,170
there because if someone launches this

00:21:46,400 --> 00:21:51,830
job with a different user that could

00:21:48,170 --> 00:21:53,750
cause havoc right and we have to specify

00:21:51,830 --> 00:21:56,120
whether we want it to run endeavor prog

00:21:53,750 --> 00:21:57,980
because engineers launch things they

00:21:56,120 --> 00:22:01,850
miss type it and they launch things in

00:21:57,980 --> 00:22:04,790
the wrong place so it's about a safety

00:22:01,850 --> 00:22:08,240
net so this Yama file that we've

00:22:04,790 --> 00:22:10,190
designed at the top has information

00:22:08,240 --> 00:22:12,020
about the job so this is for a thing

00:22:10,190 --> 00:22:16,010
called eight-ball that does one of our

00:22:12,020 --> 00:22:19,700
one of our dials on our dashboard it

00:22:16,010 --> 00:22:21,260
runs a so you specify the the file is

00:22:19,700 --> 00:22:24,350
the Aurora file that's gonna run the

00:22:21,260 --> 00:22:25,880
user it's running at CDE the build name

00:22:24,350 --> 00:22:27,679
refers to an artifact that's gonna be

00:22:25,880 --> 00:22:30,110
found in s3 and in this case is called

00:22:27,679 --> 00:22:31,820
eight-ball we're launching this by git

00:22:30,110 --> 00:22:34,190
so we also allow versions for Java

00:22:31,820 --> 00:22:36,140
things we have a static type for things

00:22:34,190 --> 00:22:38,330
like third-party things like Ravana that

00:22:36,140 --> 00:22:39,830
you know we just kind of build once and

00:22:38,330 --> 00:22:41,120
deploy and then all of your

00:22:39,830 --> 00:22:42,410
configuration so these are the things

00:22:41,120 --> 00:22:45,530
that most people are going to want to

00:22:42,410 --> 00:22:47,929
change frequently and then we allow you

00:22:45,530 --> 00:22:50,030
to specify things that you're gonna use

00:22:47,929 --> 00:22:52,100
in an in a way that we've defined in

00:22:50,030 --> 00:22:54,140
your Aurora file like arguments

00:22:52,100 --> 00:22:55,610
command-line arguments to your

00:22:54,140 --> 00:22:57,950
whatever your the thing that you're

00:22:55,610 --> 00:22:59,179
running is and we allow you to override

00:22:57,950 --> 00:23:01,340
this for different stages

00:22:59,179 --> 00:23:03,230
it's very common you know in in Devon

00:23:01,340 --> 00:23:04,880
want two of them and then prod I want 56

00:23:03,230 --> 00:23:06,410
of them you know when Deb I want these

00:23:04,880 --> 00:23:08,120
command-line arguments and prod about

00:23:06,410 --> 00:23:10,490
these command-line arguments so we

00:23:08,120 --> 00:23:12,679
specify we've broken it out so you can

00:23:10,490 --> 00:23:18,880
override them and you always have to

00:23:12,679 --> 00:23:22,520
specify agate hash so pants pants is

00:23:18,880 --> 00:23:23,960
here's my one slide on what pants is we

00:23:22,520 --> 00:23:26,690
discovered pants because they use it to

00:23:23,960 --> 00:23:28,880
build Aurora it's also from Twitter you

00:23:26,690 --> 00:23:30,820
can find it on pants build I oh so it's

00:23:28,880 --> 00:23:33,320
a build system for Big Ma no repos

00:23:30,820 --> 00:23:35,210
especially Python ones they do support

00:23:33,320 --> 00:23:36,710
other things but as far as I know what

00:23:35,210 --> 00:23:40,400
I've never seen anyone use anything but

00:23:36,710 --> 00:23:42,290
Python and it's it's awesome so if you

00:23:40,400 --> 00:23:44,900
are familiar with maven it's essentially

00:23:42,290 --> 00:23:46,730
maven for Python and it creates x-files

00:23:44,900 --> 00:23:48,890
packs files are executable Python

00:23:46,730 --> 00:23:50,720
directories so basically what it does is

00:23:48,890 --> 00:23:52,520
it takes all of your dependencies so you

00:23:50,720 --> 00:23:55,429
know you need PI llamo and you want

00:23:52,520 --> 00:23:56,480
requests 2.3 and all this stuff which is

00:23:55,429 --> 00:23:58,130
a problem when you're trying to deploy

00:23:56,480 --> 00:24:00,980
multiple things on one server right

00:23:58,130 --> 00:24:02,090
because it's all at the top level so

00:24:00,980 --> 00:24:03,620
instead of a virtual environment it

00:24:02,090 --> 00:24:05,179
basically builds a directory with all of

00:24:03,620 --> 00:24:07,910
your dependencies all of your code any

00:24:05,179 --> 00:24:09,770
extra resources like yamo files or other

00:24:07,910 --> 00:24:11,870
config files and it puts them all in a

00:24:09,770 --> 00:24:13,520
zip file and it makes it executable so

00:24:11,870 --> 00:24:15,650
you now have one artifact with all of

00:24:13,520 --> 00:24:17,600
your Python stuff in one place and we

00:24:15,650 --> 00:24:19,610
tag that tag them with agate hash we

00:24:17,600 --> 00:24:21,530
named it for whether it's built up for

00:24:19,610 --> 00:24:23,570
trustee or precise or whatever and we

00:24:21,530 --> 00:24:27,830
upload it to s3 from our from our

00:24:23,570 --> 00:24:32,059
Jenkins so it has directory level build

00:24:27,830 --> 00:24:33,740
files which is kind of it's a lot of

00:24:32,059 --> 00:24:36,620
files but it's actually very very

00:24:33,740 --> 00:24:38,330
flexible and it the reason for this is

00:24:36,620 --> 00:24:40,460
it does incremental builds for mono repo

00:24:38,330 --> 00:24:42,200
so if you make a change in some Python

00:24:40,460 --> 00:24:44,270
code here you don't want to kick off a

00:24:42,200 --> 00:24:46,160
build of everything it can figure out

00:24:44,270 --> 00:24:50,870
what else in your repo depends on that

00:24:46,160 --> 00:24:53,120
file change and just build that right so

00:24:50,870 --> 00:24:54,799
we have no more repo level dependency

00:24:53,120 --> 00:24:57,650
conflicts you can even specify different

00:24:54,799 --> 00:24:59,840
versions of third party stuff it was

00:24:57,650 --> 00:25:01,910
this was a big migration so we decided

00:24:59,840 --> 00:25:03,919
early everything's going to Aurora and

00:25:01,910 --> 00:25:06,740
by the way it has to get pants before it

00:25:03,919 --> 00:25:07,830
goes to Aurora you know we obviously

00:25:06,740 --> 00:25:09,570
helped our product

00:25:07,830 --> 00:25:12,299
to do this and it was a great way of

00:25:09,570 --> 00:25:14,370
getting rid of some tech debt so what

00:25:12,299 --> 00:25:16,380
pants look like this is a pants build

00:25:14,370 --> 00:25:17,580
file for the Fidler server that's

00:25:16,380 --> 00:25:21,000
another one if that's one of our API

00:25:17,580 --> 00:25:22,380
servers so you basically specify the

00:25:21,000 --> 00:25:24,299
entry point into your code and

00:25:22,380 --> 00:25:26,760
dependencies which are either relative

00:25:24,299 --> 00:25:29,159
to your code or there are somewhere else

00:25:26,760 --> 00:25:31,200
in your repo or the third party so this

00:25:29,159 --> 00:25:34,380
will include PI llamo it'll include a

00:25:31,200 --> 00:25:37,490
handlers directory some of our in-house

00:25:34,380 --> 00:25:40,500
login details and memcache utils

00:25:37,490 --> 00:25:43,440
sharknado 3 which is our API server

00:25:40,500 --> 00:25:46,019
because people love naming things and

00:25:43,440 --> 00:25:48,000
the sharknado 3g event plugin which we

00:25:46,019 --> 00:25:49,590
use and there's also some constants yamo

00:25:48,000 --> 00:25:51,470
file that needs to get included in there

00:25:49,590 --> 00:25:54,380
all this gets put in one directory

00:25:51,470 --> 00:25:57,149
tarter zipped up and made executable

00:25:54,380 --> 00:25:58,740
it's like magic and this will build

00:25:57,149 --> 00:26:04,070
fiddler server

00:25:58,740 --> 00:26:07,049
- get hash - trusty and x86 64 dot packs

00:26:04,070 --> 00:26:08,580
so the next thing we did was write a

00:26:07,049 --> 00:26:16,649
bunch of templates for doing common

00:26:08,580 --> 00:26:18,299
things all right so we wrote since the

00:26:16,649 --> 00:26:20,429
Aurora file is just Python we wrote a

00:26:18,299 --> 00:26:22,320
whole bunch of templates to automate the

00:26:20,429 --> 00:26:23,909
common things people wanted to do like

00:26:22,320 --> 00:26:27,570
installers so we have installers to

00:26:23,909 --> 00:26:30,019
install jars tars text files gzip

00:26:27,570 --> 00:26:32,700
whatever that are found in various s3

00:26:30,019 --> 00:26:34,080
directories pull them in and drop them

00:26:32,700 --> 00:26:36,590
right no one needs to know how to do

00:26:34,080 --> 00:26:40,679
that it's it's like someone did it once

00:26:36,590 --> 00:26:43,200
JJ VM and jmx configuration options all

00:26:40,679 --> 00:26:45,120
sorts of environments stuff if you have

00:26:43,200 --> 00:26:47,159
to create a config file based on some

00:26:45,120 --> 00:26:48,840
inputs and drop that into your your

00:26:47,159 --> 00:26:52,799
troop before your thing runs we support

00:26:48,840 --> 00:26:54,090
that very easy access credentials we

00:26:52,799 --> 00:26:56,370
install all these with puppet on the

00:26:54,090 --> 00:26:58,980
machines but they're all you know

00:26:56,370 --> 00:27:01,200
they're there they're hidden and stuff

00:26:58,980 --> 00:27:03,269
like that and so we have ways to get to

00:27:01,200 --> 00:27:04,529
that we also have shared resources you

00:27:03,269 --> 00:27:06,000
know here's here's the list of all the

00:27:04,529 --> 00:27:08,159
databases here's all the Kafka brokers

00:27:06,000 --> 00:27:11,549
here's all the the zookeepers and all

00:27:08,159 --> 00:27:14,610
that sort of stuff and then supporting

00:27:11,549 --> 00:27:16,230
actors in this in this world so we have

00:27:14,610 --> 00:27:18,210
this thing called off proxy that every

00:27:16,230 --> 00:27:20,370
API has to run that authenticates users

00:27:18,210 --> 00:27:21,630
against the database for four different

00:27:20,370 --> 00:27:23,220
api's

00:27:21,630 --> 00:27:24,950
someone wrote that once we just have a

00:27:23,220 --> 00:27:27,450
one line or two drop it in and use it

00:27:24,950 --> 00:27:28,830
Aurora uses these all these health

00:27:27,450 --> 00:27:31,260
checkers they have an HTTP health

00:27:28,830 --> 00:27:33,990
checker and we wrote ones that tell log

00:27:31,260 --> 00:27:35,790
files proxy and other service to see if

00:27:33,990 --> 00:27:39,080
it's up and someone just said I want to

00:27:35,790 --> 00:27:42,270
use that health check no problem alright

00:27:39,080 --> 00:27:45,330
so this is what one of our Aurora files

00:27:42,270 --> 00:27:47,670
looks like for 8-ball so Aurora makes

00:27:45,330 --> 00:27:52,200
heavy use of this thing called pistachio

00:27:47,670 --> 00:27:54,990
and that's it's it's it's a type safe

00:27:52,200 --> 00:27:57,300
dict in Python it's almost like a struct

00:27:54,990 --> 00:28:00,240
and it allows mustache templates to

00:27:57,300 --> 00:28:01,830
replace things either at at the time

00:28:00,240 --> 00:28:03,570
when you define the job or once it's

00:28:01,830 --> 00:28:05,910
been assigned to a server right so

00:28:03,570 --> 00:28:07,230
something like the port HTTP port you

00:28:05,910 --> 00:28:09,720
don't know until it's been assigned to a

00:28:07,230 --> 00:28:11,730
server something like the name of my my

00:28:09,720 --> 00:28:13,650
my sequel database I know up front when

00:28:11,730 --> 00:28:15,600
I want to run it so it allows for

00:28:13,650 --> 00:28:19,140
different evaluation times so things can

00:28:15,600 --> 00:28:20,910
be added in so Aurora exposes pistachio

00:28:19,140 --> 00:28:24,450
templates for the port mappings and that

00:28:20,910 --> 00:28:26,520
sort of thing then the instance ID the

00:28:24,450 --> 00:28:29,100
name of the server and we wrote our own

00:28:26,520 --> 00:28:31,860
for doing things that we need to do so

00:28:29,100 --> 00:28:34,890
it works by adding all these these these

00:28:31,860 --> 00:28:36,300
profiles so we have we define a bunch of

00:28:34,890 --> 00:28:39,510
profiles up top that we're going to bind

00:28:36,300 --> 00:28:41,010
later on you can see in this ops thing

00:28:39,510 --> 00:28:42,840
someone's defining command line

00:28:41,010 --> 00:28:45,360
arguments for the API server that's

00:28:42,840 --> 00:28:48,030
gonna run so here's our memcache servers

00:28:45,360 --> 00:28:52,020
they're in the services struck the port

00:28:48,030 --> 00:28:54,510
is is defined by thermos executors and

00:28:52,020 --> 00:28:57,480
it allows you to just if you give any

00:28:54,510 --> 00:28:58,920
string into this this port stick it will

00:28:57,480 --> 00:29:02,040
assign a port with that name and then

00:28:58,920 --> 00:29:04,320
you can use it later we use private it's

00:29:02,040 --> 00:29:08,370
a private public you know the gem export

00:29:04,320 --> 00:29:11,130
all these ports are signed down here you

00:29:08,370 --> 00:29:13,110
say I need to run 8ball here's a command

00:29:11,130 --> 00:29:15,630
line you want to run the pecks file that

00:29:13,110 --> 00:29:17,790
I put in that struct up there and the

00:29:15,630 --> 00:29:21,210
options from that thing over there and

00:29:17,790 --> 00:29:24,030
it creates a command line then I want to

00:29:21,210 --> 00:29:25,530
add in off proxies so it's just one

00:29:24,030 --> 00:29:28,170
liner I want off proxy I want this

00:29:25,530 --> 00:29:30,020
health check that is going to check my

00:29:28,170 --> 00:29:32,580
API server at this URL

00:29:30,020 --> 00:29:34,950
with this port that is going to be

00:29:32,580 --> 00:29:37,019
assigned later and then

00:29:34,950 --> 00:29:38,940
I want to run these first two things I

00:29:37,019 --> 00:29:41,820
need to install eight ball and run eight

00:29:38,940 --> 00:29:44,460
ball but then don't stop let that keep

00:29:41,820 --> 00:29:46,289
going and then go ahead and install this

00:29:44,460 --> 00:29:48,899
off proxy in this health check process

00:29:46,289 --> 00:29:50,940
so we've kind of defined these pipelines

00:29:48,899 --> 00:29:53,399
that you can use to define how your

00:29:50,940 --> 00:29:57,450
things are going to run and then finally

00:29:53,399 --> 00:29:59,850
you define the job and you go ahead and

00:29:57,450 --> 00:30:04,350
you bind all these profiles and Aurora

00:29:59,850 --> 00:30:06,450
runs it so we've taken this kind of this

00:30:04,350 --> 00:30:11,730
idea of our custom templates a step

00:30:06,450 --> 00:30:13,470
further we have 104 workers that are

00:30:11,730 --> 00:30:15,299
doing basically the same thing they

00:30:13,470 --> 00:30:17,100
listen to a rabbit queue and they run

00:30:15,299 --> 00:30:18,840
some stuff and it's actually you know we

00:30:17,100 --> 00:30:20,490
have this thing called Igor which is our

00:30:18,840 --> 00:30:22,559
work of framework and the difference

00:30:20,490 --> 00:30:24,480
between one worker job and another

00:30:22,559 --> 00:30:26,220
worker job is what are they listening to

00:30:24,480 --> 00:30:28,649
and some imports write some Python

00:30:26,220 --> 00:30:30,779
imports because you don't want to import

00:30:28,649 --> 00:30:33,779
the giant data science library for

00:30:30,779 --> 00:30:35,669
something that's not using it so we

00:30:33,779 --> 00:30:37,830
decided to this remember I said that you

00:30:35,669 --> 00:30:39,480
can have multiple yeah mul job

00:30:37,830 --> 00:30:41,970
definitions pointing to the same Aurora

00:30:39,480 --> 00:30:43,799
config so we said alright let's have one

00:30:41,970 --> 00:30:45,659
or or a config for all of our workers

00:30:43,799 --> 00:30:47,370
and then just define llamo for all the

00:30:45,659 --> 00:30:48,720
different ones so now if someone wants

00:30:47,370 --> 00:30:50,909
to add a worker they just have to write

00:30:48,720 --> 00:30:53,100
a little bit of llamo and say use this

00:30:50,909 --> 00:30:55,409
you know this is the the rabbit cue you

00:30:53,100 --> 00:30:57,779
want to listen to and this is some

00:30:55,409 --> 00:31:00,240
command line arguments so right now in

00:30:57,779 --> 00:31:02,700
our Aurora config directory where we

00:31:00,240 --> 00:31:04,620
store everything and we have 104 of

00:31:02,700 --> 00:31:06,620
these defined and you can see some of

00:31:04,620 --> 00:31:11,149
the different different ones so

00:31:06,620 --> 00:31:11,149
elasticsearch indexing is a big one so

00:31:11,840 --> 00:31:17,149
then we took it a step further and we

00:31:14,669 --> 00:31:19,200
create an ETL pipeline called deep water

00:31:17,149 --> 00:31:20,519
because someone who may or may not be

00:31:19,200 --> 00:31:25,139
sitting in the front row wanted to name

00:31:20,519 --> 00:31:28,799
something after an oil spill but deep

00:31:25,139 --> 00:31:31,649
water actually lets you define a whole

00:31:28,799 --> 00:31:33,840
workflow that runs and Aurora jobs so

00:31:31,649 --> 00:31:36,480
you can define these your steps as

00:31:33,840 --> 00:31:38,730
Python classes and then each step in the

00:31:36,480 --> 00:31:40,230
pipeline gets its own Aurora job and you

00:31:38,730 --> 00:31:41,309
can give different requirements

00:31:40,230 --> 00:31:43,559
different resource requirements to

00:31:41,309 --> 00:31:44,880
different steps in the job you can scale

00:31:43,559 --> 00:31:46,500
them out

00:31:44,880 --> 00:31:48,300
however you want but it also uses

00:31:46,500 --> 00:31:49,770
Postgres for consistency so if a job

00:31:48,300 --> 00:31:56,160
failed its marked and Postgres and we

00:31:49,770 --> 00:31:59,160
know so that's only part of the story so

00:31:56,160 --> 00:32:01,230
before deploying anything we had to

00:31:59,160 --> 00:32:02,280
figure out the right you know we want to

00:32:01,230 --> 00:32:04,140
use Aurora okay

00:32:02,280 --> 00:32:06,180
now how do we solve every other problem

00:32:04,140 --> 00:32:08,450
with this migration right so here's some

00:32:06,180 --> 00:32:11,400
things that we had to deal with so

00:32:08,450 --> 00:32:13,950
request routing metrics and monitoring

00:32:11,400 --> 00:32:16,530
log file collection configuration

00:32:13,950 --> 00:32:20,010
management and a bunch of other stuff

00:32:16,530 --> 00:32:24,900
right so how did we do this so the first

00:32:20,010 --> 00:32:27,030
one is routing right so how do you route

00:32:24,900 --> 00:32:29,010
traffic as jobs move around the cluster

00:32:27,030 --> 00:32:32,250
so we used to do this where you know we

00:32:29,010 --> 00:32:34,440
a job was running on phu api o1 and it

00:32:32,250 --> 00:32:36,600
was always going to run on fufu api l1

00:32:34,440 --> 00:32:39,000
and you know what if who api a one

00:32:36,600 --> 00:32:41,610
crashes because it's amazon we're going

00:32:39,000 --> 00:32:43,590
to launch another foo api l1 right and

00:32:41,610 --> 00:32:46,590
it's always going to be you know port

00:32:43,590 --> 00:32:51,060
9000 for this 9001 for that this is

00:32:46,590 --> 00:32:53,870
obviously changing so we introduced a

00:32:51,060 --> 00:32:56,090
tree proxy and synapse so synapse

00:32:53,870 --> 00:33:00,810
everyone knows what - a proxy is right

00:32:56,090 --> 00:33:06,390
synapse well for so this is kind of how

00:33:00,810 --> 00:33:08,760
it it works all of our jobs have our API

00:33:06,390 --> 00:33:10,620
servers have auth proxy they have the

00:33:08,760 --> 00:33:13,050
API server themselves and then they have

00:33:10,620 --> 00:33:16,080
a health check right and we bind off

00:33:13,050 --> 00:33:18,660
proxy to the public HTTP port and we

00:33:16,080 --> 00:33:20,550
bind the API server to the private port

00:33:18,660 --> 00:33:22,530
so internally if someone needs to make a

00:33:20,550 --> 00:33:24,300
request to that API server because you

00:33:22,530 --> 00:33:26,100
know it's a batch job that needs to read

00:33:24,300 --> 00:33:27,390
that data they go right to the private

00:33:26,100 --> 00:33:30,390
port someone coming in from the outside

00:33:27,390 --> 00:33:33,870
world gets sent to auth proxy and then

00:33:30,390 --> 00:33:35,400
that proxies them to the API server the

00:33:33,870 --> 00:33:37,350
health proxy never needs to talk to a

00:33:35,400 --> 00:33:39,600
proxy because that's running in the same

00:33:37,350 --> 00:33:42,540
Mesa server right next to it so requests

00:33:39,600 --> 00:33:45,210
coming in for get hot API scroll depth

00:33:42,540 --> 00:33:47,910
or private hut-hut API scroll death goes

00:33:45,210 --> 00:33:50,730
H a proxy into the mesas cluster so the

00:33:47,910 --> 00:33:54,170
way synapse helps us out here and

00:33:50,730 --> 00:33:54,170
synapse was written by

00:33:55,639 --> 00:34:01,019
Airbnb thank you

00:33:57,929 --> 00:34:03,240
written by Airbnb and it's the configure

00:34:01,019 --> 00:34:07,110
is Yama land so superset of the H a

00:34:03,240 --> 00:34:09,389
proxy config right so Aurora when a job

00:34:07,110 --> 00:34:12,030
is launched in Aurora it announces into

00:34:09,389 --> 00:34:14,339
zookeeper that you know hey this hut API

00:34:12,030 --> 00:34:16,200
is running you've got three instances of

00:34:14,339 --> 00:34:18,929
it and here's the reports that are

00:34:16,200 --> 00:34:20,399
defined H a proxy is polling zookeeper

00:34:18,929 --> 00:34:21,869
or person apps rather as polling

00:34:20,399 --> 00:34:24,359
zookeeper and when it detects a change

00:34:21,869 --> 00:34:27,359
it generates a new age a proxy config

00:34:24,359 --> 00:34:31,770
and bounces H a proxy this happens

00:34:27,359 --> 00:34:33,179
pretty quickly and I know that earlier

00:34:31,770 --> 00:34:34,740
someone was talking about how there's

00:34:33,179 --> 00:34:36,300
actually an update to AJ proxy which

00:34:34,740 --> 00:34:38,069
makes it so you don't lose any

00:34:36,300 --> 00:34:40,290
connections but when it bounces we

00:34:38,069 --> 00:34:42,300
probably lose a couple all of these

00:34:40,290 --> 00:34:43,889
api's are being accessed from JavaScript

00:34:42,300 --> 00:34:45,450
that's just going to retry the request

00:34:43,889 --> 00:34:47,970
so it's not a big deal you know it takes

00:34:45,450 --> 00:34:52,230
like 200 milliseconds to restarted or

00:34:47,970 --> 00:34:54,059
something we use puppet to manage the H

00:34:52,230 --> 00:34:55,800
a proxy config and the synaptic config

00:34:54,059 --> 00:34:58,440
so if a user needs to add a new route

00:34:55,800 --> 00:35:00,660
they'll add it to puppet and push that

00:34:58,440 --> 00:35:04,230
out and it'll get picked up on our AJ

00:35:00,660 --> 00:35:09,089
proxies our heo proxies are all running

00:35:04,230 --> 00:35:11,130
in in ELB okay so question number two

00:35:09,089 --> 00:35:13,470
metrics collection right metric

00:35:11,130 --> 00:35:15,329
collection is really important and we

00:35:13,470 --> 00:35:16,650
wanted to make it easy right we had

00:35:15,329 --> 00:35:20,220
several different ways people were doing

00:35:16,650 --> 00:35:24,240
this before they were using you know

00:35:20,220 --> 00:35:27,299
everything from TS DB to all sorts of

00:35:24,240 --> 00:35:28,950
different ways of collecting stuff so we

00:35:27,299 --> 00:35:35,730
decided to consolidate everything on

00:35:28,950 --> 00:35:38,280
open TS DB and go fauna open KS DB was

00:35:35,730 --> 00:35:40,079
written by Etsy I think most people are

00:35:38,280 --> 00:35:42,270
familiar with go fauna it's a great

00:35:40,079 --> 00:35:43,740
dashboard for visualizing this stuff so

00:35:42,270 --> 00:35:47,970
our flow is open to s DB

00:35:43,740 --> 00:35:50,760
Integra fauna Nagios is polling Griffon

00:35:47,970 --> 00:35:52,799
and also tiers to be directly and seeing

00:35:50,760 --> 00:35:54,839
if something is wonky and then we use

00:35:52,799 --> 00:35:56,339
page of duty for alerting the cool thing

00:35:54,839 --> 00:35:58,079
about the naming of all these things in

00:35:56,339 --> 00:36:02,220
Aurora is that it's very easy for us to

00:35:58,079 --> 00:36:04,200
say you know figure out the the tag TS

00:36:02,220 --> 00:36:05,970
DB works with tags so you have its time

00:36:04,200 --> 00:36:07,460
series database you have a time series

00:36:05,970 --> 00:36:09,860
you get a point in time

00:36:07,460 --> 00:36:11,900
has a bunch of tags so one tag is the

00:36:09,860 --> 00:36:13,580
name of the job one tag is which

00:36:11,900 --> 00:36:15,800
environment is running in one tag is

00:36:13,580 --> 00:36:17,360
what user is it running as so that gets

00:36:15,800 --> 00:36:19,130
very easy to say well let me look at the

00:36:17,360 --> 00:36:21,230
Hut API dev now let me look at how to

00:36:19,130 --> 00:36:22,820
API prod because everything is

00:36:21,230 --> 00:36:25,310
consistently named we're able to

00:36:22,820 --> 00:36:27,770
actually write tools that easily let

00:36:25,310 --> 00:36:29,210
engineers put this data in and also

00:36:27,770 --> 00:36:31,280
scrape all the data that's coming out of

00:36:29,210 --> 00:36:33,320
arora for the jobs running so we can

00:36:31,280 --> 00:36:35,360
generate dashboards for any job showing

00:36:33,320 --> 00:36:38,990
how much CPU is it using how much RAM is

00:36:35,360 --> 00:36:42,110
it using all of our JMX metrics also get

00:36:38,990 --> 00:36:43,430
this data so we can graph things very

00:36:42,110 --> 00:36:45,380
easily everyone knows where to look for

00:36:43,430 --> 00:36:48,080
any job that's running so we've written

00:36:45,380 --> 00:36:49,700
libraries in Python and closure that do

00:36:48,080 --> 00:36:53,690
all this kind of auto tagging based on

00:36:49,700 --> 00:36:57,440
the Aurora names and we wrote a what we

00:36:53,690 --> 00:36:59,570
call the JMX collector which actually

00:36:57,440 --> 00:37:01,640
pulls any job that's running in Aurora

00:36:59,570 --> 00:37:03,860
and just pulls out the JMX metrics if

00:37:01,640 --> 00:37:08,000
there's a gem export to find and stores

00:37:03,860 --> 00:37:10,880
them in TS DB and refine our dashboards

00:37:08,000 --> 00:37:13,460
for everything so you know engineers

00:37:10,880 --> 00:37:16,520
love pretty graphs so here's our generic

00:37:13,460 --> 00:37:19,400
mesas job graph up on the top you can

00:37:16,520 --> 00:37:20,930
see CPU used by tasks you can the red

00:37:19,400 --> 00:37:24,170
line is the limit that's been assigned

00:37:20,930 --> 00:37:26,840
this job is nice and it peaked a little

00:37:24,170 --> 00:37:29,990
bit but not too bad which is how we like

00:37:26,840 --> 00:37:32,090
it right and you can see if any any

00:37:29,990 --> 00:37:35,000
specific tasks are using more CPU than

00:37:32,090 --> 00:37:37,520
others which is actually happens a lot

00:37:35,000 --> 00:37:40,730
in Kafka consumers it especially if you

00:37:37,520 --> 00:37:43,490
have an unbalanced topic right so we can

00:37:40,730 --> 00:37:45,350
say oh this task is is using way more

00:37:43,490 --> 00:37:48,680
one thing we haven't quite figured out

00:37:45,350 --> 00:37:50,900
how to solve is a way to give certain

00:37:48,680 --> 00:37:52,940
tasks more CPU but I think that's

00:37:50,900 --> 00:37:54,290
probably a pipe dream much better just

00:37:52,940 --> 00:37:58,460
figure out how to balance the topic

00:37:54,290 --> 00:38:00,170
better so log file analysis this was

00:37:58,460 --> 00:38:03,380
actually a really big one for our users

00:38:00,170 --> 00:38:07,430
I think mostly because log file analysis

00:38:03,380 --> 00:38:09,530
has always been kind of tough when we

00:38:07,430 --> 00:38:12,080
told users they couldn't just easily SSH

00:38:09,530 --> 00:38:13,880
in and use poly SH to tell all their

00:38:12,080 --> 00:38:16,190
logs they were like no this is horrible

00:38:13,880 --> 00:38:19,780
so we tried to pull everything into

00:38:16,190 --> 00:38:22,600
elasticsearch with Kabana

00:38:19,780 --> 00:38:24,610
I know some people love it I hate it it

00:38:22,600 --> 00:38:27,390
was it was really messy and incredibly

00:38:24,610 --> 00:38:31,300
expensive so we chose to use flume

00:38:27,390 --> 00:38:33,550
Athena which is an Amazon product it's

00:38:31,300 --> 00:38:36,430
it's presto running in Amazon and

00:38:33,550 --> 00:38:39,760
something called tale LLL because we

00:38:36,430 --> 00:38:40,450
already had at LLL so what a what do

00:38:39,760 --> 00:38:42,700
those look like

00:38:40,450 --> 00:38:44,320
so I mentioned users wanna Polly if

00:38:42,700 --> 00:38:46,120
you're not familiar with Polly SH it's a

00:38:44,320 --> 00:38:48,310
little Python program lets you like

00:38:46,120 --> 00:38:49,870
shell into ten servers run the same

00:38:48,310 --> 00:38:52,330
command and see all the output nicely

00:38:49,870 --> 00:38:55,720
separated even with colors it's really

00:38:52,330 --> 00:38:59,590
cool so we wrote this addition to our

00:38:55,720 --> 00:39:02,440
Aurora client called Aurora managed klll

00:38:59,590 --> 00:39:03,640
and a job name so since we have we know

00:39:02,440 --> 00:39:05,410
where everything's running from the

00:39:03,640 --> 00:39:08,890
Aurora client you can say hey I want to

00:39:05,410 --> 00:39:10,630
tell this job and it will say hey where

00:39:08,890 --> 00:39:12,850
are these jobs running I'll log in to

00:39:10,630 --> 00:39:15,450
all of them and and and pull back all of

00:39:12,850 --> 00:39:19,000
your log files and just print them out

00:39:15,450 --> 00:39:20,650
the there is an Aurora web UI to just

00:39:19,000 --> 00:39:23,320
kind of click on a job and look at the

00:39:20,650 --> 00:39:24,280
log file just like in Macy's but that

00:39:23,320 --> 00:39:26,080
doesn't help with a cron job that

00:39:24,280 --> 00:39:29,380
already stopped running or if it got

00:39:26,080 --> 00:39:33,010
cleaned up so we suck all of our log

00:39:29,380 --> 00:39:34,900
files in to Athena through floom Athena

00:39:33,010 --> 00:39:37,690
just lets you do ad hoc sequel like

00:39:34,900 --> 00:39:39,310
queries across s3 buckets so you know if

00:39:37,690 --> 00:39:41,290
you want to do kind of historical

00:39:39,310 --> 00:39:42,010
forensic on why did this thing die

00:39:41,290 --> 00:39:44,860
yesterday

00:39:42,010 --> 00:39:47,350
you can just go into Athena and look at

00:39:44,860 --> 00:39:49,060
the logs and we have a lot of stuff

00:39:47,350 --> 00:39:50,620
that's not running in May so so so all

00:39:49,060 --> 00:39:53,350
of those logs go there as well like our

00:39:50,620 --> 00:39:54,990
Kafka brokers our databases I didn't

00:39:53,350 --> 00:40:02,770
mention we don't put databases in Aurora

00:39:54,990 --> 00:40:06,130
yeah I don't think we go so two years

00:40:02,770 --> 00:40:09,060
later and we're really psyched we've

00:40:06,130 --> 00:40:12,580
reduced our on-call events dramatically

00:40:09,060 --> 00:40:14,800
we've cut our ec2 instance cost by about

00:40:12,580 --> 00:40:16,240
thirty three percent and at the same

00:40:14,800 --> 00:40:19,150
time we've built new stuff it's not like

00:40:16,240 --> 00:40:20,530
we didn't build new stuff we actually

00:40:19,150 --> 00:40:22,330
recently did an engineering survey

00:40:20,530 --> 00:40:25,450
because we couldn't figure out any other

00:40:22,330 --> 00:40:27,190
way to really measure our KPIs so we

00:40:25,450 --> 00:40:28,510
thought let's let's do a Google survey

00:40:27,190 --> 00:40:30,790
and ask our engineers what they think

00:40:28,510 --> 00:40:32,980
and we asked a bunch of somewhat leading

00:40:30,790 --> 00:40:33,609
questions maybe but they said that they

00:40:32,980 --> 00:40:35,200
rarely extry

00:40:33,609 --> 00:40:38,230
blockers deploying stuff which is great

00:40:35,200 --> 00:40:42,279
and it's honestly changed our entire

00:40:38,230 --> 00:40:45,069
approach to DevOps one of the most

00:40:42,279 --> 00:40:48,400
telling examples is how we use the pecks

00:40:45,069 --> 00:40:49,989
files you know we actually build pecks

00:40:48,400 --> 00:40:53,319
files for all of our command line tools

00:40:49,989 --> 00:40:56,470
now so we have a text file that runs s3

00:40:53,319 --> 00:40:59,499
command we have text files that run you

00:40:56,470 --> 00:41:01,420
know all of our our we have command-line

00:40:59,499 --> 00:41:03,489
tools to launch instances and stuff like

00:41:01,420 --> 00:41:07,950
that and we just wrote we do them as a

00:41:03,489 --> 00:41:11,470
pecks file now we wrote a thing called

00:41:07,950 --> 00:41:13,210
Tex Runner which we deploy on all of our

00:41:11,470 --> 00:41:14,619
machines which you can say pecks run and

00:41:13,210 --> 00:41:16,599
give it the name of a job and agate hash

00:41:14,619 --> 00:41:19,150
and it'll just downloaded from s3 cache

00:41:16,599 --> 00:41:21,489
it locally which we do on our Mesa

00:41:19,150 --> 00:41:22,749
servers as well so this text you want

00:41:21,489 --> 00:41:25,119
this get oh I already have it I don't

00:41:22,749 --> 00:41:26,460
have to go and get it from s3 and that's

00:41:25,119 --> 00:41:29,470
really changed the way that we approach

00:41:26,460 --> 00:41:33,640
bundling our Python stuff so that's been

00:41:29,470 --> 00:41:37,569
great so that's it I want to leave time

00:41:33,640 --> 00:41:41,200
for questions and I have so awesome any

00:41:37,569 --> 00:41:43,119
questions I should say that's our

00:41:41,200 --> 00:41:46,089
engineering blog and there's posts about

00:41:43,119 --> 00:41:48,640
this that get into some more detail i'm

00:41:46,089 --> 00:41:50,589
on twitter at our mangie and github at

00:41:48,640 --> 00:41:52,660
our mangie and everywhere else pretty

00:41:50,589 --> 00:41:56,700
much at our mangie except at work where

00:41:52,660 --> 00:42:01,280
i'm rick so that's it thank you

00:41:56,700 --> 00:42:01,280

YouTube URL: https://www.youtube.com/watch?v=2XWQfnJXh3s


