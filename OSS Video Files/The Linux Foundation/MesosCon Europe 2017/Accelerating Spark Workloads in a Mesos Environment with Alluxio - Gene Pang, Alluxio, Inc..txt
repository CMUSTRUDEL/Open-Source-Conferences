Title: Accelerating Spark Workloads in a Mesos Environment with Alluxio - Gene Pang, Alluxio, Inc.
Publication date: 2017-10-31
Playlist: MesosCon Europe 2017
Description: 
	Accelerating Spark Workloads in a Mesos Environment with Alluxio - Gene Pang, Alluxio, Inc.

Organizations Mesos and Apache Spark together to gain insight from large amounts of data. It is common for Spark to process data stored in disparate public cloud storage, such as Amazon S3, Microsoft Azure Blob Storage, or Google Cloud Storage as well as on-premise data on HDFS, Ceph or ECS. This architecture results in sub-optimal performance as data and compute are not co-located.

Using Alluxio, a memory speed virtual distributed storage system, deployed on Mesos enables connecting any compute framework, such as Apache Spark, to storage systems via a unified namespace. Alluxio enables applications to interact with any data at memory speed. Alluxio can eliminate the pains of ETL and data duplication, and enable new workloads across all data. Gene will discuss the architecture of Mesos, Spark and Alluxio to achieve an optimal architecture for enterprises.

About Gene Pang
Gene Pang is one of PMCs and maintainers of the Alluxio open source project and a founding member at Alluxio, Inc. He recently graduated with a Ph.D. from the AMPLab at UC Berkeley, working on distributed database systems. Before starting at Berkeley, he worked at Google and has an M.S. from Stanford University, and B.S. from Cornell University.
Captions: 
	00:00:00,000 --> 00:00:04,770
hi everyone thank you for coming to this

00:00:02,220 --> 00:00:06,899
talk my name is jean pang and i'll be

00:00:04,770 --> 00:00:09,000
talking about accelerating spark

00:00:06,899 --> 00:00:12,690
workloads in a maysa environment with

00:00:09,000 --> 00:00:15,059
the Luxio so here's a little bit about

00:00:12,690 --> 00:00:17,609
myself before we get started my name is

00:00:15,059 --> 00:00:20,970
jean pang and i'm a software engineer at

00:00:17,609 --> 00:00:23,970
a Luxio and I'm also a PMC member of the

00:00:20,970 --> 00:00:27,420
Alexia open source project before I

00:00:23,970 --> 00:00:29,760
started a Luxio I got my PhD from UC

00:00:27,420 --> 00:00:31,800
Berkeley from the amp lab which also

00:00:29,760 --> 00:00:35,309
produced you know software like mesos

00:00:31,800 --> 00:00:37,260
and before that I was working at Google

00:00:35,309 --> 00:00:40,320
with distributed databases and systems

00:00:37,260 --> 00:00:45,110
and here you can find my Twitter and

00:00:40,320 --> 00:00:48,480
github handle so here's a brief overview

00:00:45,110 --> 00:00:50,100
of what I'll be talking about today I'll

00:00:48,480 --> 00:00:53,579
first go into an introduction in an

00:00:50,100 --> 00:00:57,420
overview of a Luxio and then I will go

00:00:53,579 --> 00:01:00,660
into some use cases that some some users

00:00:57,420 --> 00:01:04,049
are using with Luxio and and spark and

00:01:00,660 --> 00:01:06,060
Mayo's together and also I will sort of

00:01:04,049 --> 00:01:09,030
describe how you can use spark and

00:01:06,060 --> 00:01:11,939
Alexia together and then and then I'll

00:01:09,030 --> 00:01:14,430
go into some you know how does this get

00:01:11,939 --> 00:01:21,450
deployed in my source and then finally

00:01:14,430 --> 00:01:23,430
go through a demo of this on on TCOs so

00:01:21,450 --> 00:01:25,770
first let's talk about sort of the this

00:01:23,430 --> 00:01:27,840
this big data ecosystem you know back in

00:01:25,770 --> 00:01:31,110
the day say 10 15 years ago it was

00:01:27,840 --> 00:01:33,810
actually pretty simple I would say if

00:01:31,110 --> 00:01:35,100
they there was there was like basically

00:01:33,810 --> 00:01:37,110
one framework there was the Hadoop

00:01:35,100 --> 00:01:39,210
framework where we had Hadoop MapReduce

00:01:37,110 --> 00:01:41,610
we also had a Hadoop HDFS for the

00:01:39,210 --> 00:01:44,070
storage and it was actually very simple

00:01:41,610 --> 00:01:45,170
there was basically one a one-to-one

00:01:44,070 --> 00:01:48,240
mapping

00:01:45,170 --> 00:01:50,340
however you know as time involved the

00:01:48,240 --> 00:01:52,439
ecosystem evolved as well and today

00:01:50,340 --> 00:01:54,509
there are lots of different types of

00:01:52,439 --> 00:01:56,189
frameworks for computation and there's

00:01:54,509 --> 00:01:57,540
lots of there are a lot of different

00:01:56,189 --> 00:02:00,180
types of storage systems that people

00:01:57,540 --> 00:02:02,460
like to use so for example here you know

00:02:00,180 --> 00:02:03,600
you know HDFS is still here but there

00:02:02,460 --> 00:02:04,979
are a lot of new ones that people are

00:02:03,600 --> 00:02:08,130
people want to use like the cloud

00:02:04,979 --> 00:02:10,200
storage at s3 the Google one

00:02:08,130 --> 00:02:13,890
Microsoft Azure and then there's also

00:02:10,200 --> 00:02:14,940
lots of storage appliances as well so

00:02:13,890 --> 00:02:18,030
there's a lot of storage and then

00:02:14,940 --> 00:02:20,220
there's also a lot of computation

00:02:18,030 --> 00:02:22,080
application frameworks like HDR like

00:02:20,220 --> 00:02:23,850
Hadoop MapReduce but there's also a

00:02:22,080 --> 00:02:26,820
spark which is a big one there's also

00:02:23,850 --> 00:02:28,620
fling presto you name it there's a lot

00:02:26,820 --> 00:02:31,080
of different types of application

00:02:28,620 --> 00:02:33,540
frameworks and so this can actually get

00:02:31,080 --> 00:02:36,110
pretty messy just in terms of writing

00:02:33,540 --> 00:02:39,780
applications managing the storage and

00:02:36,110 --> 00:02:47,400
just adding new ones removing old ones

00:02:39,780 --> 00:02:49,890
just is quite difficult also because the

00:02:47,400 --> 00:02:52,470
the compute and storage is there's just

00:02:49,890 --> 00:02:54,480
such a wide variety of them now it's

00:02:52,470 --> 00:02:57,030
harder to get sort of the optimal IO

00:02:54,480 --> 00:02:59,930
performance from the app from the

00:02:57,030 --> 00:03:03,240
storage to the application so this is

00:02:59,930 --> 00:03:06,360
where a Luxio wants to help things

00:03:03,240 --> 00:03:08,730
Alexio is a new layer in between storage

00:03:06,360 --> 00:03:10,890
and computation and here you can see

00:03:08,730 --> 00:03:12,840
that it sits in between the application

00:03:10,890 --> 00:03:15,350
frameworks and it's and above the

00:03:12,840 --> 00:03:17,310
storage systems and it actually

00:03:15,350 --> 00:03:20,370
abstracts away the storage systems and

00:03:17,310 --> 00:03:22,140
provides a single unified and global

00:03:20,370 --> 00:03:24,810
namespace across all the different

00:03:22,140 --> 00:03:27,660
storage systems and so applications

00:03:24,810 --> 00:03:29,880
really only need to talk to just a Luxio

00:03:27,660 --> 00:03:32,280
with just different paths and they can

00:03:29,880 --> 00:03:35,070
access their different data that

00:03:32,280 --> 00:03:38,340
happened to be happen to be stored in

00:03:35,070 --> 00:03:40,560
separate storage systems in addition to

00:03:38,340 --> 00:03:43,320
that alexei was actually a distributed

00:03:40,560 --> 00:03:45,480
system so what typically this is

00:03:43,320 --> 00:03:47,790
deployed close to the computation and

00:03:45,480 --> 00:03:50,310
what looks you can do is actually cache

00:03:47,790 --> 00:03:53,220
and store data closer to the application

00:03:50,310 --> 00:03:56,070
also in memory so what this allows is

00:03:53,220 --> 00:03:59,100
that it can actually enable in memory

00:03:56,070 --> 00:04:01,200
access to data for applications and this

00:03:59,100 --> 00:04:04,080
is actually very powerful applications

00:04:01,200 --> 00:04:07,440
really only need to talk to one API one

00:04:04,080 --> 00:04:10,620
namespace and they can get almost local

00:04:07,440 --> 00:04:12,450
memory speed type of i/o from their data

00:04:10,620 --> 00:04:14,370
even though the data can be all over the

00:04:12,450 --> 00:04:17,340
place in different storage systems and

00:04:14,370 --> 00:04:19,260
this ultimately enables decoupling being

00:04:17,340 --> 00:04:21,600
able to decouple computation and storage

00:04:19,260 --> 00:04:23,430
and that's actually very powerful

00:04:21,600 --> 00:04:26,160
you can scale each independently and

00:04:23,430 --> 00:04:30,990
it's actually a very very scalable way

00:04:26,160 --> 00:04:34,370
to operate things so with a Luxio in the

00:04:30,990 --> 00:04:36,720
picture now you know the the analytics

00:04:34,370 --> 00:04:38,130
it can power a lot of different types of

00:04:36,720 --> 00:04:41,910
analytics and a lot of different types

00:04:38,130 --> 00:04:43,740
of ecosystems and scenarios so we've

00:04:41,910 --> 00:04:47,100
seen examples of big data

00:04:43,740 --> 00:04:49,140
IOT we've seen AI machine learning so

00:04:47,100 --> 00:04:52,770
there's a lot of different use cases

00:04:49,140 --> 00:04:55,730
that people use unlocks yeoman also you

00:04:52,770 --> 00:04:58,830
can deploy them in very in a diverse

00:04:55,730 --> 00:05:01,290
environment so you can you can deploy

00:04:58,830 --> 00:05:04,020
them on premise you can deploy them on

00:05:01,290 --> 00:05:06,090
the cloud across different clouds and so

00:05:04,020 --> 00:05:08,580
we've actually seen you know especially

00:05:06,090 --> 00:05:11,310
using mesas we've seen Alexia being

00:05:08,580 --> 00:05:14,670
deployed across clouds and also a cloud

00:05:11,310 --> 00:05:17,040
on-premise simply you know also using

00:05:14,670 --> 00:05:20,250
besos simply by deploying these along

00:05:17,040 --> 00:05:22,560
co-workers to different locations so

00:05:20,250 --> 00:05:26,250
there's it's a very flexible way to to

00:05:22,560 --> 00:05:29,040
operate so just to sort of summarize

00:05:26,250 --> 00:05:31,800
what Alexa can provide ultimately it can

00:05:29,040 --> 00:05:34,080
unify your data and it provides this one

00:05:31,800 --> 00:05:36,660
single API and single namespace for your

00:05:34,080 --> 00:05:39,330
data regardless of where the data

00:05:36,660 --> 00:05:41,670
actually lives underneath it there's

00:05:39,330 --> 00:05:43,680
also a lot of flexibility with Alexio

00:05:41,670 --> 00:05:46,920
you can since you get to decouple your

00:05:43,680 --> 00:05:48,630
computation and storage you can scale

00:05:46,920 --> 00:05:50,220
them independently you can use you can

00:05:48,630 --> 00:05:51,950
mix and match different computation you

00:05:50,220 --> 00:05:55,290
can mix and match different storage and

00:05:51,950 --> 00:05:56,670
it's still a Luxio allows you to do that

00:05:55,290 --> 00:06:00,180
and it enables that to make it much

00:05:56,670 --> 00:06:02,520
easier and lastly a Luxio

00:06:00,180 --> 00:06:04,680
since it can store data closer to the

00:06:02,520 --> 00:06:09,150
application and in memory can greatly

00:06:04,680 --> 00:06:12,120
improve the i/o performance so look see

00:06:09,150 --> 00:06:13,260
how it's a Luxio is an open source

00:06:12,120 --> 00:06:14,280
project and it's actually one of the

00:06:13,260 --> 00:06:16,620
fastest growing ones

00:06:14,280 --> 00:06:19,080
Luxio has been open source for about

00:06:16,620 --> 00:06:21,450
four years now so yeah about four years

00:06:19,080 --> 00:06:24,150
and this is actually a graph of the

00:06:21,450 --> 00:06:26,640
number of could have contributors to the

00:06:24,150 --> 00:06:29,040
project over the first four years of the

00:06:26,640 --> 00:06:30,960
project and the top line is a Luxio and

00:06:29,040 --> 00:06:33,180
this this graph is actually a little bit

00:06:30,960 --> 00:06:34,639
stale but if you I think if we go onto

00:06:33,180 --> 00:06:37,909
github today

00:06:34,639 --> 00:06:39,050
I think there's over 600 contributors in

00:06:37,909 --> 00:06:41,479
there Luxio projects so it's actually

00:06:39,050 --> 00:06:42,979
been really exciting and and fun to be a

00:06:41,479 --> 00:06:45,499
part of that community and sort of see

00:06:42,979 --> 00:06:49,580
how different people are using elección

00:06:45,499 --> 00:06:52,909
in different ways so next I'll talk

00:06:49,580 --> 00:06:58,310
about some Luxio spark and mesos use

00:06:52,909 --> 00:07:01,039
cases out there so this first one is is

00:06:58,310 --> 00:07:06,169
from june are there you know a big

00:07:01,039 --> 00:07:08,210
travel website in in in china and here

00:07:06,169 --> 00:07:10,310
they have an interesting use case where

00:07:08,210 --> 00:07:12,080
they actually have multiple computation

00:07:10,310 --> 00:07:13,939
frameworks they have spark and flink and

00:07:12,080 --> 00:07:15,919
they want to do both streaming they want

00:07:13,939 --> 00:07:17,479
to do both batch and there's a lot of

00:07:15,919 --> 00:07:18,949
sort of mixing and matching between the

00:07:17,479 --> 00:07:20,930
two computation frameworks but they also

00:07:18,949 --> 00:07:23,090
have multiple storage systems that

00:07:20,930 --> 00:07:25,009
they're storing data and they have HDFS

00:07:23,090 --> 00:07:28,159
and they're also use also using SEF so

00:07:25,009 --> 00:07:29,979
there's you know multiple computation

00:07:28,159 --> 00:07:32,449
and multiple storage and it was actually

00:07:29,979 --> 00:07:34,460
you know becoming sort of a headache to

00:07:32,449 --> 00:07:35,599
manage all that as well as they're not

00:07:34,460 --> 00:07:38,240
getting the best performance that they

00:07:35,599 --> 00:07:40,039
wanted so they added a Luxio

00:07:38,240 --> 00:07:42,409
in addition so they added mesos and they

00:07:40,039 --> 00:07:44,900
added a Luxio to the picture and by

00:07:42,409 --> 00:07:47,120
doing this they could actually abstract

00:07:44,900 --> 00:07:49,279
away the the different storage systems

00:07:47,120 --> 00:07:52,009
that they actually have and they can get

00:07:49,279 --> 00:07:53,810
some of the higher performance io that

00:07:52,009 --> 00:07:55,490
they were looking for as well as being

00:07:53,810 --> 00:07:57,770
able to share a lot of that data between

00:07:55,490 --> 00:07:59,719
the two computation frameworks through

00:07:57,770 --> 00:08:02,210
the memory and so this actually sped up

00:07:59,719 --> 00:08:05,300
a lot of their jobs and especially in

00:08:02,210 --> 00:08:07,250
some really bad peak times some of their

00:08:05,300 --> 00:08:10,099
queries actually completed 300 times

00:08:07,250 --> 00:08:11,719
faster with this new environment so they

00:08:10,099 --> 00:08:17,810
actually found a lot of value from a

00:08:11,719 --> 00:08:21,319
Luxio this next example is from guardant

00:08:17,810 --> 00:08:24,860
health and they do a lot of genomics and

00:08:21,319 --> 00:08:27,529
cancer research and here they had a

00:08:24,860 --> 00:08:30,399
spark before they had the spark HT of

00:08:27,529 --> 00:08:32,779
his environment but they it wasn't

00:08:30,399 --> 00:08:34,459
scaling up as much as they could have

00:08:32,779 --> 00:08:36,050
and they were looking for actually they

00:08:34,459 --> 00:08:37,250
have a lot of data and they want to they

00:08:36,050 --> 00:08:40,339
need to scale out more so they actually

00:08:37,250 --> 00:08:43,250
moved to something they moved to Mineo

00:08:40,339 --> 00:08:45,230
which is like a cloud like auto store

00:08:43,250 --> 00:08:47,810
where they could scale out the data of

00:08:45,230 --> 00:08:48,680
far greater than HDFS and so once they

00:08:47,810 --> 00:08:52,190
did that though

00:08:48,680 --> 00:08:54,680
the data was actually it was remote and

00:08:52,190 --> 00:08:56,839
slower so they were they wanted sort of

00:08:54,680 --> 00:08:59,930
the performance back from when they had

00:08:56,839 --> 00:09:01,910
sort of the local data so they added um

00:08:59,930 --> 00:09:03,740
you know a Luxio to the picture along

00:09:01,910 --> 00:09:06,830
with mesos to this to be able to scale

00:09:03,740 --> 00:09:10,400
out and they you know ran spike spark on

00:09:06,830 --> 00:09:11,950
a Luxio over Mineo and that actually

00:09:10,400 --> 00:09:14,810
sped up a lot of the access as well as

00:09:11,950 --> 00:09:17,360
being able to access even their HDFS

00:09:14,810 --> 00:09:19,610
data as well so this this sort of gave

00:09:17,360 --> 00:09:22,400
them the flexibility to use different

00:09:19,610 --> 00:09:25,839
storage underneath their application and

00:09:22,400 --> 00:09:25,839
be able to scale out to their needs

00:09:26,020 --> 00:09:35,320
so next I'll talk about how spark and

00:09:28,880 --> 00:09:37,520
Alexio can be used so one one class of

00:09:35,320 --> 00:09:39,650
benefits that Alexa can provide is

00:09:37,520 --> 00:09:42,350
actually being able to share data via

00:09:39,650 --> 00:09:47,060
the memory and the Luxio can enable that

00:09:42,350 --> 00:09:50,390
so with so if you were to just run some

00:09:47,060 --> 00:09:52,010
spark jobs on mesas on some storage and

00:09:50,390 --> 00:09:55,250
if they wanted to catch their own data

00:09:52,010 --> 00:09:57,170
they would actually be each of the SPARC

00:09:55,250 --> 00:10:00,500
context will be cashing their own data

00:09:57,170 --> 00:10:02,870
and that essentially would duplicate the

00:10:00,500 --> 00:10:04,820
data that that you have in memory and

00:10:02,870 --> 00:10:06,650
that could actually waste some space so

00:10:04,820 --> 00:10:09,680
here we have an example where you know

00:10:06,650 --> 00:10:13,330
both blocks one and three are stored by

00:10:09,680 --> 00:10:15,380
these two spark computation contexts but

00:10:13,330 --> 00:10:16,520
you know that's that's somewhat

00:10:15,380 --> 00:10:20,209
unnecessary especially if they're on the

00:10:16,520 --> 00:10:23,630
same machine so if you have if you use a

00:10:20,209 --> 00:10:25,760
Luxio instead you can actually store

00:10:23,630 --> 00:10:28,070
that data in a Luxio and spark wouldn't

00:10:25,760 --> 00:10:29,510
have to store that data internally and

00:10:28,070 --> 00:10:31,760
so if spark doesn't have to store that

00:10:29,510 --> 00:10:34,670
internally the Luxio can essentially

00:10:31,760 --> 00:10:36,890
manage caching and storing that data in

00:10:34,670 --> 00:10:39,770
memory for the spark applications and

00:10:36,890 --> 00:10:42,890
they spark cannot have direct access to

00:10:39,770 --> 00:10:47,540
that memory data and be able to not have

00:10:42,890 --> 00:10:50,270
to duplicate duplicate the the memory

00:10:47,540 --> 00:10:56,750
memory usage as well as have memory

00:10:50,270 --> 00:10:58,820
speed io to that data another so even if

00:10:56,750 --> 00:11:00,470
there's only one spark context there's a

00:10:58,820 --> 00:11:03,640
lot of benefit as well

00:11:00,470 --> 00:11:06,350
you can share that data across different

00:11:03,640 --> 00:11:09,350
invocations of that context so here so

00:11:06,350 --> 00:11:11,660
here we are the spark context on running

00:11:09,350 --> 00:11:15,410
on some data but you know if for some

00:11:11,660 --> 00:11:17,120
reason that spark context crashes or you

00:11:15,410 --> 00:11:19,490
know has to be restarted or another one

00:11:17,120 --> 00:11:21,710
gets to be started all that sort of

00:11:19,490 --> 00:11:23,870
useful data gets lost and you'd have to

00:11:21,710 --> 00:11:25,520
reread it so if you reread it from

00:11:23,870 --> 00:11:28,610
something that's slow it would actually

00:11:25,520 --> 00:11:32,630
take a long time to to restart that

00:11:28,610 --> 00:11:35,720
spark job so instead you can store it in

00:11:32,630 --> 00:11:38,060
a Luxio and even if the spark

00:11:35,720 --> 00:11:40,580
application has to restart or has or

00:11:38,060 --> 00:11:43,160
crashes the data is still resident in

00:11:40,580 --> 00:11:46,310
the memory in the Luxio worker and so

00:11:43,160 --> 00:11:47,990
because of that the application can when

00:11:46,310 --> 00:11:51,410
it gets restarted it can directly read

00:11:47,990 --> 00:11:53,600
from the memory the data from memory and

00:11:51,410 --> 00:11:59,720
thus greatly increase the i/o

00:11:53,600 --> 00:12:02,000
performance there so here is a

00:11:59,720 --> 00:12:03,530
high-level overview of what the Luxio

00:12:02,000 --> 00:12:05,360
architecture looks like Luxio

00:12:03,530 --> 00:12:07,250
essentially has three major components

00:12:05,360 --> 00:12:08,930
there's a Luxio client

00:12:07,250 --> 00:12:12,950
there's a Luxio master unlock co worker

00:12:08,930 --> 00:12:15,620
so the Luxio client is living in the

00:12:12,950 --> 00:12:17,210
application and that is what the

00:12:15,620 --> 00:12:19,850
application uses to communicate with the

00:12:17,210 --> 00:12:21,800
Luxio and then there is the Luxio master

00:12:19,850 --> 00:12:24,890
and workers which I'll speak more about

00:12:21,800 --> 00:12:27,290
in detail later but they do most of the

00:12:24,890 --> 00:12:30,080
interaction with the storage and the

00:12:27,290 --> 00:12:35,600
storage is over here on the on the right

00:12:30,080 --> 00:12:37,280
and so the applications only really need

00:12:35,600 --> 00:12:39,590
to talk to a Luxio and allow co-workers

00:12:37,280 --> 00:12:41,480
Luxio masters and then the workers and

00:12:39,590 --> 00:12:44,210
masters will interact with under the

00:12:41,480 --> 00:12:46,840
backing underlying storage for the data

00:12:44,210 --> 00:12:46,840
and metadata

00:12:47,200 --> 00:12:52,880
so the Luxio client is the main way that

00:12:50,290 --> 00:12:54,740
applications interact with the Luxio and

00:12:52,880 --> 00:12:57,860
there are actually a few different ways

00:12:54,740 --> 00:13:01,190
to interact with Alexio a different API

00:12:57,860 --> 00:13:04,040
so there's the there's the native Java

00:13:01,190 --> 00:13:06,710
Luxio file system client which has a lot

00:13:04,040 --> 00:13:08,240
of the allow students specific

00:13:06,710 --> 00:13:10,510
operations such as pinning and unpinning

00:13:08,240 --> 00:13:12,850
there's mounting unmounting

00:13:10,510 --> 00:13:15,370
you know setting TTL things like that

00:13:12,850 --> 00:13:17,890
then there is the hdfs compatible file

00:13:15,370 --> 00:13:20,620
system client and this is this enables

00:13:17,890 --> 00:13:21,850
applications do not have to modify their

00:13:20,620 --> 00:13:23,920
code if they're already writing reading

00:13:21,850 --> 00:13:25,600
and writing from HDFS it'll look

00:13:23,920 --> 00:13:28,540
alexia will look just like an HDFS

00:13:25,600 --> 00:13:30,820
client and thus it'll interact with

00:13:28,540 --> 00:13:33,550
Alexia while the applications thinks

00:13:30,820 --> 00:13:35,950
it's talking the HDFS and then also a

00:13:33,550 --> 00:13:39,220
new a new API that was recently added

00:13:35,950 --> 00:13:42,160
like a few weeks ago was the s3 API so

00:13:39,220 --> 00:13:46,840
when applications are written talking to

00:13:42,160 --> 00:13:49,750
s3 a Luxio can also you know talk the s3

00:13:46,840 --> 00:13:51,820
api so applications can just point it to

00:13:49,750 --> 00:13:54,940
to a Luxio instead so these are the

00:13:51,820 --> 00:13:59,860
three major ways that you can use to

00:13:54,940 --> 00:14:01,210
interact with Alexio there's also the

00:13:59,860 --> 00:14:05,020
Luxio master component and this

00:14:01,210 --> 00:14:06,520
component is primarily used for managing

00:14:05,020 --> 00:14:09,640
the metadata and there's there's two

00:14:06,520 --> 00:14:11,200
major there's there's a few major you

00:14:09,640 --> 00:14:13,210
know classes of metadata there's the

00:14:11,200 --> 00:14:14,770
file system namespace metadata which

00:14:13,210 --> 00:14:17,830
handles all the file system namespace

00:14:14,770 --> 00:14:19,810
and there's the metadata for all the

00:14:17,830 --> 00:14:22,000
blocks of the data and as well as the

00:14:19,810 --> 00:14:24,400
workers in the system so these are the

00:14:22,000 --> 00:14:28,750
main pieces of metadata that exist in

00:14:24,400 --> 00:14:30,490
the system and the the the primary

00:14:28,750 --> 00:14:32,290
master also writes to a journal so all

00:14:30,490 --> 00:14:34,540
the actions are durable and the

00:14:32,290 --> 00:14:38,950
secondary masters will essentially tail

00:14:34,540 --> 00:14:41,770
tail that journal to keep up-to-date and

00:14:38,950 --> 00:14:44,530
the workers are the there are the

00:14:41,770 --> 00:14:47,140
primary components for storing the

00:14:44,530 --> 00:14:48,550
actual data and so they they store the

00:14:47,140 --> 00:14:50,860
data they serve the data they read the

00:14:48,550 --> 00:14:53,160
data and they also they can store it

00:14:50,860 --> 00:14:55,930
actually in different storage media

00:14:53,160 --> 00:14:58,420
there it's called the feature is called

00:14:55,930 --> 00:15:01,690
tiered storage but essentially allows

00:14:58,420 --> 00:15:04,000
you can can use hard drives SSDs and

00:15:01,690 --> 00:15:06,460
memory for storing this type of data and

00:15:04,000 --> 00:15:09,670
there are sort of eviction policies and

00:15:06,460 --> 00:15:12,310
and promotion policies built-in that you

00:15:09,670 --> 00:15:14,980
can configure to get the type of

00:15:12,310 --> 00:15:17,050
behavior that you want and also workers

00:15:14,980 --> 00:15:20,320
are the main components that read and

00:15:17,050 --> 00:15:22,500
write read and write the data to and

00:15:20,320 --> 00:15:22,500
from

00:15:26,189 --> 00:15:32,499
so next I'll briefly talk about how

00:15:29,860 --> 00:15:36,220
Luxio can be deployed on missiles and a

00:15:32,499 --> 00:15:41,649
Luxio is part of the TCOs the universe

00:15:36,220 --> 00:15:45,089
and so as you can see here over here you

00:15:41,649 --> 00:15:48,610
can see Alexia is a package on the DCOs

00:15:45,089 --> 00:15:51,220
universe and you know it's like I

00:15:48,610 --> 00:15:53,709
mentioned before Luxio you know can

00:15:51,220 --> 00:15:55,119
provide this unified view of the data

00:15:53,709 --> 00:15:58,089
that you have in different storage

00:15:55,119 --> 00:16:01,779
systems and also can give you higher

00:15:58,089 --> 00:16:04,179
performance io2 that data and TCL TCOs

00:16:01,779 --> 00:16:07,420
actually makes makes deployment very

00:16:04,179 --> 00:16:10,199
very easy and scalable and it's just

00:16:07,420 --> 00:16:12,309
it's a very useful tool in terms of

00:16:10,199 --> 00:16:14,549
dealing with the infrastructure so

00:16:12,309 --> 00:16:17,399
together it's actually really really

00:16:14,549 --> 00:16:21,040
convenient to have a lock cont see what

00:16:17,399 --> 00:16:24,339
implemented for TCOs so that you can

00:16:21,040 --> 00:16:27,639
have much faster deployments for your

00:16:24,339 --> 00:16:30,879
applications as well as deploying a

00:16:27,639 --> 00:16:35,850
Luxio as well in the same framework and

00:16:30,879 --> 00:16:39,279
so this also enables being able to have

00:16:35,850 --> 00:16:42,160
you know applications in the TCOs in the

00:16:39,279 --> 00:16:45,040
maze world that want to access data sort

00:16:42,160 --> 00:16:46,449
of outside that may cells the maze world

00:16:45,040 --> 00:16:49,119
and so along who can help bridge that

00:16:46,449 --> 00:16:53,799
gap and continue to provide high

00:16:49,119 --> 00:16:58,089
performance to that data so next I will

00:16:53,799 --> 00:17:01,569
show a short short video demo on sort of

00:16:58,089 --> 00:17:05,500
how it looks like deploying a Luxio on

00:17:01,569 --> 00:17:07,839
DCOs and a short demo with spark and so

00:17:05,500 --> 00:17:10,329
for this demo this is it's very simple

00:17:07,839 --> 00:17:12,909
setup we have we have a you know mesos

00:17:10,329 --> 00:17:15,029
front we have DC West running and we are

00:17:12,909 --> 00:17:18,039
going to install spark and mesos

00:17:15,029 --> 00:17:20,740
together and we'll be running a few

00:17:18,039 --> 00:17:23,159
simple spark commands and being able to

00:17:20,740 --> 00:17:26,470
show how it interacts with the Luxio and

00:17:23,159 --> 00:17:31,210
we also will be interacting with some

00:17:26,470 --> 00:17:33,309
data in Amazon s3 so in terms of the

00:17:31,210 --> 00:17:34,150
demo setup we're using this these

00:17:33,309 --> 00:17:38,370
versions of the software

00:17:34,150 --> 00:17:42,750
and we're using an Amazon ec2 instance

00:17:38,370 --> 00:17:42,750
m3x large type of instance

00:17:54,720 --> 00:18:02,800
so in this in the setup we have HDFS

00:17:59,320 --> 00:18:04,810
setup and in HDFS this is the the UI

00:18:02,800 --> 00:18:06,580
that shows the files in HDFS and here

00:18:04,810 --> 00:18:09,100
you can see there's one file called

00:18:06,580 --> 00:18:13,090
license and so there's one file in HDFS

00:18:09,100 --> 00:18:13,660
and then we also have an s3 bucket for

00:18:13,090 --> 00:18:16,180
this demo

00:18:13,660 --> 00:18:18,880
and in this s3 bucket here we're showing

00:18:16,180 --> 00:18:23,170
the listing of the bucket and we have

00:18:18,880 --> 00:18:26,410
two files we have the readme file and a

00:18:23,170 --> 00:18:28,330
sample 1g file and so these are the two

00:18:26,410 --> 00:18:33,670
storage systems that you know will be

00:18:28,330 --> 00:18:38,080
interacting with today and so if we go

00:18:33,670 --> 00:18:41,140
back to the CCOs we also have a darker

00:18:38,080 --> 00:18:43,270
registry that will store you know some

00:18:41,140 --> 00:18:44,920
of our darker darker images for spark

00:18:43,270 --> 00:18:48,340
and a lock co and things like that and

00:18:44,920 --> 00:18:50,350
so to install Luxio it's it's an it's in

00:18:48,340 --> 00:18:53,260
the universe and so you can look for Doc

00:18:50,350 --> 00:18:55,990
Co you can try it and you can install it

00:18:53,260 --> 00:18:59,020
through that so there are two main

00:18:55,990 --> 00:19:01,810
things you have to you have to configure

00:18:59,020 --> 00:19:06,160
for the installation one is the license

00:19:01,810 --> 00:19:09,610
and so this the license has to be sort

00:19:06,160 --> 00:19:11,260
of base64 encoded and and this is what

00:19:09,610 --> 00:19:14,080
this is doing right now but it's gonna

00:19:11,260 --> 00:19:16,530
base 64 encode the license and that'll

00:19:14,080 --> 00:19:20,070
be sort of pasted into the configuration

00:19:16,530 --> 00:19:23,050
and then another thing that you have to

00:19:20,070 --> 00:19:25,480
configure is the ufs address and this is

00:19:23,050 --> 00:19:27,790
something we call the under under FS

00:19:25,480 --> 00:19:32,290
under file system address and this is

00:19:27,790 --> 00:19:34,000
where we are essentially mounting some

00:19:32,290 --> 00:19:36,490
storage system through the root of

00:19:34,000 --> 00:19:39,190
Alexio so something there needs to be

00:19:36,490 --> 00:19:41,320
some connection Luxio needs to have some

00:19:39,190 --> 00:19:44,590
sort of something backing the file

00:19:41,320 --> 00:19:48,640
system so here we're gonna be using the

00:19:44,590 --> 00:19:51,190
HDFS location we're using the HDFS that

00:19:48,640 --> 00:19:54,430
I showed earlier to be the under FS for

00:19:51,190 --> 00:19:56,230
alexia for the root of Luxio and so once

00:19:54,430 --> 00:20:04,200
we've configured those to two major

00:19:56,230 --> 00:20:04,200
points we're going to install it yeah

00:20:06,950 --> 00:20:12,320
and then once that's once that starts

00:20:09,440 --> 00:20:15,109
you will be able to see a lot of the

00:20:12,320 --> 00:20:18,139
processes start up for a Luxio running

00:20:15,109 --> 00:20:20,960
on mesos and so here I think we will be

00:20:18,139 --> 00:20:22,940
showing some some tasks here that are

00:20:20,960 --> 00:20:25,309
starting up and some of the tasks that

00:20:22,940 --> 00:20:28,489
start up are the workers some of them

00:20:25,309 --> 00:20:29,899
are the master and those with so yeah

00:20:28,489 --> 00:20:31,789
those are the main the main components

00:20:29,899 --> 00:20:34,759
that I think I'd start up start it up

00:20:31,789 --> 00:20:38,989
and so once a Luxio

00:20:34,759 --> 00:20:40,669
looks like a Luxio is started next what

00:20:38,989 --> 00:20:42,590
we'll do is we'll actually log in to the

00:20:40,669 --> 00:20:46,039
master and then start doing a few

00:20:42,590 --> 00:20:48,379
commands with the Luxio shell commands

00:20:46,039 --> 00:20:53,749
so since Alexio does provide a file

00:20:48,379 --> 00:20:57,249
system type of a namespace and interface

00:20:53,749 --> 00:21:00,590
and you can do simple file system like

00:20:57,249 --> 00:21:03,980
operations so we'll log in to the master

00:21:00,590 --> 00:21:09,950
will you know start up we'll start up a

00:21:03,980 --> 00:21:11,090
docker container yeah I think we're just

00:21:09,950 --> 00:21:17,690
looking at some of the Alessio

00:21:11,090 --> 00:21:19,999
configuration here and yeah the first

00:21:17,690 --> 00:21:22,399
command we'll do is a basic LS command

00:21:19,999 --> 00:21:24,529
and so here it's a little bit cut off

00:21:22,399 --> 00:21:28,429
but it'll it's basically doing a Luxio

00:21:24,529 --> 00:21:30,619
FS LS / the root and so here you can see

00:21:28,429 --> 00:21:32,149
it's listing one file already so we

00:21:30,619 --> 00:21:33,200
didn't do anything with Luxio yet but

00:21:32,149 --> 00:21:35,749
there's already a file there and that's

00:21:33,200 --> 00:21:38,659
because we mounted that HDFS I showed

00:21:35,749 --> 00:21:41,570
earlier into a Luxio and so since HDFS

00:21:38,659 --> 00:21:47,629
had that license file that I showed

00:21:41,570 --> 00:21:49,460
earlier now we can see it in a Luxio so

00:21:47,629 --> 00:21:52,609
when we do the LS we can see the license

00:21:49,460 --> 00:21:54,259
file there also you can see that it says

00:21:52,609 --> 00:21:57,259
not in memory that means it hasn't been

00:21:54,259 --> 00:22:00,169
loaded into a Luxio yet so it's still in

00:21:57,259 --> 00:22:02,600
HDFS the metadata is in a lock Co but

00:22:00,169 --> 00:22:05,239
not the data is not in a Luxio yet and

00:22:02,600 --> 00:22:07,220
so this next command here we're actually

00:22:05,239 --> 00:22:09,080
going to mount another storage system

00:22:07,220 --> 00:22:10,279
into into the locks United space since a

00:22:09,080 --> 00:22:11,989
lock so you can combine different

00:22:10,279 --> 00:22:13,909
storage systems in the same namespace

00:22:11,989 --> 00:22:15,950
this is what we're doing here we're

00:22:13,909 --> 00:22:18,200
actually going to mount the s3 bucket I

00:22:15,950 --> 00:22:18,739
showed earlier into the name space of a

00:22:18,200 --> 00:22:20,250
Luxio

00:22:18,739 --> 00:22:21,810
and so here

00:22:20,250 --> 00:22:26,760
towards the end of the command and we're

00:22:21,810 --> 00:22:29,220
mounting the DCOs demo s3 bucket into /s

00:22:26,760 --> 00:22:32,040
3a and so the path in the Luxio will be

00:22:29,220 --> 00:22:40,920
/s 3a and we're mounting that s3 bucket

00:22:32,040 --> 00:22:47,490
in and so now if we list that location

00:22:40,920 --> 00:22:48,960
in a Luxio / s3 a what we'll see we will

00:22:47,490 --> 00:22:51,720
actually see those two files that I

00:22:48,960 --> 00:22:54,450
showed earlier and so here you can see

00:22:51,720 --> 00:22:56,970
two files s3 a you can see the readme

00:22:54,450 --> 00:23:01,680
file and the sample file that was

00:22:56,970 --> 00:23:03,150
already existing in the s3 bucket and so

00:23:01,680 --> 00:23:05,310
the melody has been pulled into Alexio

00:23:03,150 --> 00:23:07,680
but if the data the contents of the data

00:23:05,310 --> 00:23:11,790
has has not been pulled in yet since

00:23:07,680 --> 00:23:13,470
nothing has read that data yet and so

00:23:11,790 --> 00:23:18,750
the next thing we're gonna do is we're

00:23:13,470 --> 00:23:21,630
going to start up a spark shell and do a

00:23:18,750 --> 00:23:25,140
few commands with spark on top of

00:23:21,630 --> 00:23:27,150
running on top of a Luxio so here we're

00:23:25,140 --> 00:23:29,570
logging in we're going to start a docker

00:23:27,150 --> 00:23:29,570
container

00:23:42,800 --> 00:23:47,330
and so as yeah so we're starting with

00:23:45,320 --> 00:23:49,970
spark shell so it'll start up with the

00:23:47,330 --> 00:23:52,070
executors and we are going to run

00:23:49,970 --> 00:23:55,760
basically a simple command that will

00:23:52,070 --> 00:23:58,190
count the data in that s3 bucket in that

00:23:55,760 --> 00:24:00,320
sample 1g file and so first what we're

00:23:58,190 --> 00:24:02,000
going to do is we're going to set the

00:24:00,320 --> 00:24:03,920
log level to info so you can see some of

00:24:02,000 --> 00:24:07,240
the timing information so that's what

00:24:03,920 --> 00:24:07,240
we'll be doing here

00:24:13,260 --> 00:24:18,120
and then what we're gonna do is we're

00:24:15,780 --> 00:24:20,610
gonna read the sample 1g file from

00:24:18,120 --> 00:24:24,150
Alexio so here you can see the command

00:24:20,610 --> 00:24:25,980
we're recruiting an RDD from the sample

00:24:24,150 --> 00:24:28,770
once you file of a Luxio so the path

00:24:25,980 --> 00:24:31,650
that we're passing in here is it starts

00:24:28,770 --> 00:24:34,380
with the Luxio Luxio scheme and then we

00:24:31,650 --> 00:24:35,730
have you know the the hostname and

00:24:34,380 --> 00:24:39,809
things like that and then we have the

00:24:35,730 --> 00:24:41,760
path s3 a sample sample 1g and so that's

00:24:39,809 --> 00:24:45,990
the file that we're creating this artery

00:24:41,760 --> 00:24:48,929
RTD from and then we want to essentially

00:24:45,990 --> 00:24:52,230
read that RTD and so we're gonna do a

00:24:48,929 --> 00:24:53,669
simple count on that and so it'll it'll

00:24:52,230 --> 00:24:55,679
process that data and actually at this

00:24:53,669 --> 00:24:59,669
point it'll read it in from s3 since it

00:24:55,679 --> 00:25:00,780
hasn't been read in before yet so if you

00:24:59,669 --> 00:25:03,900
take a look at the time

00:25:00,780 --> 00:25:06,480
it took about 30 seconds to read all

00:25:03,900 --> 00:25:08,580
that data and to read or read all that

00:25:06,480 --> 00:25:12,960
data and in that process actually it

00:25:08,580 --> 00:25:15,480
will have though we will have saved it

00:25:12,960 --> 00:25:18,660
in a Luxio space as well so if we if you

00:25:15,480 --> 00:25:22,260
look up here we do the same listing on

00:25:18,660 --> 00:25:26,190
the s3 a path in the Luxio and now the

00:25:22,260 --> 00:25:28,559
sample 1g file says in memory and that's

00:25:26,190 --> 00:25:30,990
because since an application has read

00:25:28,559 --> 00:25:33,720
that file it pulled it in from s3 and

00:25:30,990 --> 00:25:35,549
stored it in a Luxio now and so the next

00:25:33,720 --> 00:25:38,520
time that you want to read it it'll

00:25:35,549 --> 00:25:39,990
actually be in memory now so we're

00:25:38,520 --> 00:25:43,950
actually gonna start a new spark shell a

00:25:39,990 --> 00:25:46,440
separate spark shell and we're gonna run

00:25:43,950 --> 00:25:48,600
sort of the same command we're gonna you

00:25:46,440 --> 00:25:51,570
know create an already RTD from that

00:25:48,600 --> 00:25:53,580
Alexio file and we're gonna we're going

00:25:51,570 --> 00:25:57,030
to read that data so we set the log

00:25:53,580 --> 00:25:59,580
level we you know create that RTD the

00:25:57,030 --> 00:26:03,809
same RTD from the same file and then

00:25:59,580 --> 00:26:07,710
we're gonna run the count and so here

00:26:03,809 --> 00:26:10,770
you can notice that there's there's an

00:26:07,710 --> 00:26:13,049
old local locality level for these tasks

00:26:10,770 --> 00:26:15,120
and that's because it's now loaded into

00:26:13,049 --> 00:26:18,750
Alexios so a spark can actually find it

00:26:15,120 --> 00:26:20,790
it can schedule tasks local to the data

00:26:18,750 --> 00:26:23,520
and it's actually in their media that in

00:26:20,790 --> 00:26:25,860
this case and so it'll actually greatly

00:26:23,520 --> 00:26:27,629
speed up the processing so

00:26:25,860 --> 00:26:29,100
if you take a look at the time now it

00:26:27,629 --> 00:26:32,249
took about three and a half seconds so

00:26:29,100 --> 00:26:35,669
you know almost ten times you know

00:26:32,249 --> 00:26:38,659
faster to read that data again and to

00:26:35,669 --> 00:26:43,549
process that data again because it was

00:26:38,659 --> 00:26:48,049
it was red from the Luxio memory so that

00:26:43,549 --> 00:26:48,049
is the end of the demo

00:26:52,470 --> 00:26:57,630
so here are just some of the results

00:26:54,900 --> 00:26:59,700
from the simple demo we have this is

00:26:57,630 --> 00:27:01,710
sort of the the duration in seconds of

00:26:59,700 --> 00:27:04,680
that of that processing that that our DD

00:27:01,710 --> 00:27:06,870
count and with the Luxio this so the

00:27:04,680 --> 00:27:09,150
light blue the top lines of each section

00:27:06,870 --> 00:27:11,010
is the first time we ran the count and

00:27:09,150 --> 00:27:13,560
the second line is the second time we

00:27:11,010 --> 00:27:16,170
ran the count and you know if you run

00:27:13,560 --> 00:27:19,080
directly on s3 it'll actually which is

00:27:16,170 --> 00:27:20,850
the bottom two lines here it will take

00:27:19,080 --> 00:27:22,650
the same amount of time to read the data

00:27:20,850 --> 00:27:25,650
again because you because you're just

00:27:22,650 --> 00:27:27,450
gonna access s3 again but we still Luxio

00:27:25,650 --> 00:27:29,610
the second time you the second time you

00:27:27,450 --> 00:27:31,380
read it it'll actually read it from

00:27:29,610 --> 00:27:33,450
Luxio memory it's already it's already

00:27:31,380 --> 00:27:36,390
been cached and Luxio so it actually

00:27:33,450 --> 00:27:38,240
will have much faster IO because it's

00:27:36,390 --> 00:27:41,850
already in memory and so the application

00:27:38,240 --> 00:27:43,980
you know will essentially be a so in

00:27:41,850 --> 00:27:50,250
this example eight times faster because

00:27:43,980 --> 00:27:53,850
the data is already in a Luxio so in

00:27:50,250 --> 00:27:57,180
conclusion I showed how easy it is to

00:27:53,850 --> 00:27:59,520
use Alexio and spark on the Miss in the

00:27:57,180 --> 00:28:01,200
mesas environment I also described sort

00:27:59,520 --> 00:28:03,300
of the overview of a Luxio and how can

00:28:01,200 --> 00:28:07,800
benefit a lot of different scenarios a

00:28:03,300 --> 00:28:10,800
Luxio can also provide a lot of i/o

00:28:07,800 --> 00:28:12,930
performance because we can store a Luxio

00:28:10,800 --> 00:28:16,620
can Alexa can store data closer to the

00:28:12,930 --> 00:28:18,750
application and in memory and I've also

00:28:16,620 --> 00:28:21,180
shown that also can connect different

00:28:18,750 --> 00:28:25,470
storage systems easily into a single

00:28:21,180 --> 00:28:28,550
unified namespace so that is the end of

00:28:25,470 --> 00:28:28,550
my talk thank you very much

00:28:34,180 --> 00:28:42,700
[Music]

00:28:38,789 --> 00:28:45,250
hello thanks for the presentation it's

00:28:42,700 --> 00:28:46,720
really cool just question so if I

00:28:45,250 --> 00:28:48,250
understand correctly Alexia is like

00:28:46,720 --> 00:28:49,809
distributed memory transaction or

00:28:48,250 --> 00:28:53,559
distributed memory across multiple

00:28:49,809 --> 00:28:56,380
machines and it read the data from the

00:28:53,559 --> 00:28:58,509
memory on different machines right yes

00:28:56,380 --> 00:28:59,950
you can you can't read memory from other

00:28:58,509 --> 00:29:01,870
machines yes some different machine like

00:28:59,950 --> 00:29:03,789
this the cache basically in the memory

00:29:01,870 --> 00:29:05,679
is actually multiple machines and they

00:29:03,789 --> 00:29:08,049
do distributed memory so what about

00:29:05,679 --> 00:29:10,059
cache invalidations and it's constancy

00:29:08,049 --> 00:29:12,700
yeah that's a good question

00:29:10,059 --> 00:29:14,649
primarily a Luxio works in in the

00:29:12,700 --> 00:29:16,929
environment where the data is immutable

00:29:14,649 --> 00:29:20,049
so if when the data is immutable that is

00:29:16,929 --> 00:29:21,129
no longer an issue so once you write a

00:29:20,049 --> 00:29:22,509
file in a Luxio

00:29:21,129 --> 00:29:24,960
you'd have to delete it if you wanted to

00:29:22,509 --> 00:29:24,960
update it

00:29:33,610 --> 00:29:39,010
it's a little bit of a similar question

00:29:35,650 --> 00:29:42,490
so if I have a datasets that's larger

00:29:39,010 --> 00:29:44,230
than any one of my servers can hold

00:29:42,490 --> 00:29:46,600
itself I mean it needs to be striped

00:29:44,230 --> 00:29:48,640
across multiple servers how does a Luxio

00:29:46,600 --> 00:29:51,070
deal with failure modes so if I have I

00:29:48,640 --> 00:29:52,870
don't know say a terabyte of data and I

00:29:51,070 --> 00:29:54,880
lose a note in my cluster with a part of

00:29:52,870 --> 00:29:56,440
that data will I reap will I pull in

00:29:54,880 --> 00:29:58,030
just that part or will I have to pull in

00:29:56,440 --> 00:30:01,270
the entire data set again yeah that's a

00:29:58,030 --> 00:30:04,660
good question so in in the Luxio world

00:30:01,270 --> 00:30:07,870
there's a concept of files and blocks

00:30:04,660 --> 00:30:09,700
and so most people have to reread blocks

00:30:07,870 --> 00:30:11,260
of data but not the entire files so if

00:30:09,700 --> 00:30:12,730
the file has like ten blocks and you

00:30:11,260 --> 00:30:13,150
lose a machine that had two of those

00:30:12,730 --> 00:30:15,220
blocks

00:30:13,150 --> 00:30:17,410
you would have to reread two of those

00:30:15,220 --> 00:30:19,390
blocks from that DeLange store or from

00:30:17,410 --> 00:30:21,220
if it's on a different machine you can

00:30:19,390 --> 00:30:32,410
even read it from another Luxio machine

00:30:21,220 --> 00:30:34,210
so it's it's on a block level so you

00:30:32,410 --> 00:30:37,600
mentioned about sparse locality data

00:30:34,210 --> 00:30:40,570
locality and so I'm confused in this

00:30:37,600 --> 00:30:42,970
case so the data is on Alexio and we

00:30:40,570 --> 00:30:45,309
have like there will be spark workers

00:30:42,970 --> 00:30:52,150
running but they are actually they might

00:30:45,309 --> 00:30:53,770
be different machines so right like the

00:30:52,150 --> 00:30:56,650
spark jobs are running maybe on

00:30:53,770 --> 00:30:59,140
different nodes then Alexio nodes where

00:30:56,650 --> 00:31:00,730
yeah that's that's possible yeah and

00:30:59,140 --> 00:31:02,980
then in this case what locality means

00:31:00,730 --> 00:31:04,300
yeah so if they're if they're not on the

00:31:02,980 --> 00:31:08,050
same machine that you can't get okatee

00:31:04,300 --> 00:31:09,850
if if if the spark workers are on the

00:31:08,050 --> 00:31:13,420
same machine as the LOC co-workers and

00:31:09,850 --> 00:31:16,090
that's when you get locality okay but

00:31:13,420 --> 00:31:18,990
like even if like let's say if we have

00:31:16,090 --> 00:31:22,150
one spark node and - Alex you nodes and

00:31:18,990 --> 00:31:25,840
data is charted between the memory is in

00:31:22,150 --> 00:31:28,300
between - these two nodes then they look

00:31:25,840 --> 00:31:30,130
then the spark worker will see a local

00:31:28,300 --> 00:31:31,900
data because it's it knows one note but

00:31:30,130 --> 00:31:33,400
actually the other half of the data is

00:31:31,900 --> 00:31:36,070
one another not right yes

00:31:33,400 --> 00:31:38,860
so if yeah if you only had one spark

00:31:36,070 --> 00:31:41,080
worker then for hot like half of those

00:31:38,860 --> 00:31:43,900
jobs it will not be local data because

00:31:41,080 --> 00:31:46,980
it'll be on a different machine right

00:31:43,900 --> 00:31:46,980
okay thank you

00:31:47,880 --> 00:31:56,220
hi I have rewritten Geoscience you are

00:31:52,660 --> 00:31:59,740
tachyon before next year

00:31:56,220 --> 00:32:03,820
and I have always the one question I

00:31:59,740 --> 00:32:07,480
read about Kitaen office of keep mode

00:32:03,820 --> 00:32:08,200
that is reading for tachyon was

00:32:07,480 --> 00:32:11,560
agonizing

00:32:08,200 --> 00:32:14,950
Luxio conceit but they never need to

00:32:11,560 --> 00:32:17,620
understand why we want to cut our duty

00:32:14,950 --> 00:32:21,100
if we want if we cool safe in a lecture

00:32:17,620 --> 00:32:23,200
it's not the same or I don't know I

00:32:21,100 --> 00:32:27,640
talked about cashing spark cashing

00:32:23,200 --> 00:32:30,460
versus Knoxville cash in in in in memory

00:32:27,640 --> 00:32:34,300
level that is not a memories of heap

00:32:30,460 --> 00:32:38,260
that I think is only really relate with

00:32:34,300 --> 00:32:40,630
we see if I understand well so spark has

00:32:38,260 --> 00:32:42,670
many different levels of caching one of

00:32:40,630 --> 00:32:47,670
them is like the memory caching layer

00:32:42,670 --> 00:32:50,740
level so that is that's not a Luxio but

00:32:47,670 --> 00:32:53,290
I guess there's a few distinctions here

00:32:50,740 --> 00:32:55,720
but one of the major ones is that that

00:32:53,290 --> 00:32:57,550
when spark caches that when spark caches

00:32:55,720 --> 00:32:59,920
itself in its own internal memory it

00:32:57,550 --> 00:33:02,710
sort of lives before that one spark

00:32:59,920 --> 00:33:04,060
context or spark job so if you store it

00:33:02,710 --> 00:33:06,340
in a low if you store it in that one

00:33:04,060 --> 00:33:09,430
spark context another spark context

00:33:06,340 --> 00:33:11,350
cannot read that data because it's in a

00:33:09,430 --> 00:33:14,860
different context so if you have it in a

00:33:11,350 --> 00:33:16,090
Luxio both or any spark context can

00:33:14,860 --> 00:33:17,890
actually read that data from memory

00:33:16,090 --> 00:33:20,920
actually it doesn't have to be spark it

00:33:17,890 --> 00:33:22,570
could be like blink or whatever so on

00:33:20,920 --> 00:33:24,460
any application can be different memory

00:33:22,570 --> 00:33:26,950
so it's just essentially you're pulling

00:33:24,460 --> 00:33:32,100
some of the caching duties out of spark

00:33:26,950 --> 00:33:32,100
and into some external external system

00:33:33,660 --> 00:33:41,800
and another question and you use you say

00:33:37,660 --> 00:33:43,860
that you have several file system from

00:33:41,800 --> 00:33:48,310
the other line file system support it

00:33:43,860 --> 00:33:50,710
how can you say how much or I only see

00:33:48,310 --> 00:33:53,830
Gloucester and HDFS

00:33:50,710 --> 00:33:55,270
well there's HDFS there's a there's you

00:33:53,830 --> 00:33:57,430
know there's a cluster ones I think

00:33:55,270 --> 00:34:03,280
that's also talks to HDFS there

00:33:57,430 --> 00:34:07,270
s3 there is like NFS type of systems as

00:34:03,280 --> 00:34:10,000
well yeah so a lot of different I think

00:34:07,270 --> 00:34:11,350
we support many of the files there some

00:34:10,000 --> 00:34:14,080
there one that you're particularly

00:34:11,350 --> 00:34:15,430
interested in my case it was in their

00:34:14,080 --> 00:34:18,040
face so yes

00:34:15,430 --> 00:34:22,380
yeah so I think we do have people using

00:34:18,040 --> 00:34:22,380
it with NFS as well okay thanks

00:34:32,100 --> 00:34:35,660
any more questions

00:34:37,190 --> 00:34:41,749
thank you

00:34:38,460 --> 00:34:41,749

YouTube URL: https://www.youtube.com/watch?v=SAPycsD4u08


