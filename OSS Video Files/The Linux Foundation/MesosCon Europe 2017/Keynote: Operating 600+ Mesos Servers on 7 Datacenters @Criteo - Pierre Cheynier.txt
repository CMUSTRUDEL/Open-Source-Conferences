Title: Keynote: Operating 600+ Mesos Servers on 7 Datacenters @Criteo - Pierre Cheynier
Publication date: 2017-10-31
Playlist: MesosCon Europe 2017
Description: 
	Keynote: Operating 600+ Mesos Servers on 7 Datacenters @Criteo - Pierre Cheynier, Operations Engineer, Criteo

Given the nature of its business, Criteo has a tremendous need for scalability. Historically based on bare-metal infrastructure and serving billions of user requests per day with the lowest latencies, we will present how Mesos became a first-class citizen on our platform.

In this talk, we will describe how we deploy and operate 600+ Mesos agents, hosting hundreds of applications and handling up to 200K requests per second, with up to 40Gbps of outgoing traffic. 
We'll mostly focus on net/dev/ops concerns, like how we dealt with configuration management, app secrets, logging, service discovery, networking, metrology and SLAs, tests, etc.

The aim of this presentation is to share what we have learnt during this long journey of setting up a production-grade Mesos infrastructure from scratch and what we expect from it in a near future.

About Pierre Cheynier
Pierre Cheynier is an Operations Engineer at Criteo, a world leader in performance advertising. As a SRE since 2015, he mainly focuses on automating deployment, troubleshooting and providing support to developers on Mesos clusters and a very large legacy Windows / C# infrastructure. Prior to working at Criteo, Pierre worked in the IPTV field for a French ISP, where he also introduced and deployed Mesos.
Captions: 
	00:00:00,000 --> 00:00:05,310
okay thank you you're so yeah a

00:00:03,060 --> 00:00:07,770
disclaimer you will immediately notice

00:00:05,310 --> 00:00:11,160
that I have a French accent so this

00:00:07,770 --> 00:00:13,080
would be a single tour this morning okay

00:00:11,160 --> 00:00:15,299
so I'm Jeff Jenni I'm working at an

00:00:13,080 --> 00:00:19,140
operation engineer in yes a division of

00:00:15,299 --> 00:00:22,279
Chris Hill and in this talk I will try

00:00:19,140 --> 00:00:25,230
to share with you some insight into our

00:00:22,279 --> 00:00:28,769
deployment and operation regarding our

00:00:25,230 --> 00:00:31,170
missiles infrastructure so we I will be

00:00:28,769 --> 00:00:32,820
quite fast because now a lot of

00:00:31,170 --> 00:00:36,270
interesting and technical content in

00:00:32,820 --> 00:00:38,809
this talk but I will share the slides

00:00:36,270 --> 00:00:44,670
just after and you can come by our booth

00:00:38,809 --> 00:00:47,719
if you want to add some details so first

00:00:44,670 --> 00:00:52,230
a bit of context regarding our company

00:00:47,719 --> 00:00:53,940
so at Crito our business or we we are

00:00:52,230 --> 00:00:56,250
approaching the attack industry and our

00:00:53,940 --> 00:00:58,590
business is basically to predict the

00:00:56,250 --> 00:01:03,600
most relevant ad for the right choice at

00:00:58,590 --> 00:01:06,650
the right moment and since for the last

00:01:03,600 --> 00:01:10,560
12 years with managed to do that pretty

00:01:06,650 --> 00:01:12,299
efficiently and right now we are able to

00:01:10,560 --> 00:01:16,770
present some interesting metrics

00:01:12,299 --> 00:01:17,610
reckoning that like we have 30 offices

00:01:16,770 --> 00:01:20,159
around the world

00:01:17,610 --> 00:01:23,729
we reach every month 1.2 billion

00:01:20,159 --> 00:01:26,040
distinct use on internet we operate in

00:01:23,729 --> 00:01:29,400
seven different the data center around

00:01:26,040 --> 00:01:32,880
the wall and we are asking more than

00:01:29,400 --> 00:01:37,350
20,000 physical servers in these data

00:01:32,880 --> 00:01:39,450
centers we also constrained because of

00:01:37,350 --> 00:01:41,850
our business since we are doing

00:01:39,450 --> 00:01:44,820
performance marketing we have some

00:01:41,850 --> 00:01:46,799
services that have to respond under 10

00:01:44,820 --> 00:01:49,619
milliseconds and this is quite a

00:01:46,799 --> 00:01:54,390
challenge to operate such an

00:01:49,619 --> 00:01:56,119
infrastructure so critical like in many

00:01:54,390 --> 00:01:59,100
other companies we are always

00:01:56,119 --> 00:02:02,969
transitioning and from a necessary

00:01:59,100 --> 00:02:06,270
perspective transitioning means four

00:02:02,969 --> 00:02:09,390
different things at that time the first

00:02:06,270 --> 00:02:12,390
thing is hardware we try in the long run

00:02:09,390 --> 00:02:14,520
to improve our CEO Oregon in Hardware

00:02:12,390 --> 00:02:17,430
meaning that we

00:02:14,520 --> 00:02:20,400
see the resiliency more at a data

00:02:17,430 --> 00:02:25,100
central level rather than at the several

00:02:20,400 --> 00:02:29,700
level we're gonna need the OS stack we

00:02:25,100 --> 00:02:31,910
starting we started a big switch is

00:02:29,700 --> 00:02:34,710
historically from windows-based

00:02:31,910 --> 00:02:39,420
infrastructure to something more Linux

00:02:34,710 --> 00:02:42,030
oriented Rini runtime we've introduced a

00:02:39,420 --> 00:02:48,120
bit more diversity we are strictly based

00:02:42,030 --> 00:02:50,570
on the dotnet ecosystem and last but not

00:02:48,120 --> 00:02:53,450
least we on our platform we aim to

00:02:50,570 --> 00:02:57,000
improve our ability to deliver all self

00:02:53,450 --> 00:03:01,440
self service to our end user which are

00:02:57,000 --> 00:03:02,550
basically internal users and well what

00:03:01,440 --> 00:03:06,600
we've learned so far

00:03:02,550 --> 00:03:08,820
at doing this transition is that to get

00:03:06,600 --> 00:03:12,150
a stable and maintainable service you

00:03:08,820 --> 00:03:15,570
have to make its component simple and

00:03:12,150 --> 00:03:19,110
highly modular and this is why we chose

00:03:15,570 --> 00:03:20,970
methods initially so I won't detail on

00:03:19,110 --> 00:03:23,040
the why methods is simple and Madeira

00:03:20,970 --> 00:03:24,780
because there are a lot of interesting

00:03:23,040 --> 00:03:27,390
tools training these aspects in this

00:03:24,780 --> 00:03:30,480
conference but I could also mention that

00:03:27,390 --> 00:03:33,480
it's highly self-sufficient in the sense

00:03:30,480 --> 00:03:38,040
that you can run containers in many

00:03:33,480 --> 00:03:39,780
different ways so just think about it in

00:03:38,040 --> 00:03:42,300
our case we are running continental

00:03:39,780 --> 00:03:45,770
imageless containers meaning that we

00:03:42,300 --> 00:03:48,390
don't fully rely on the image based

00:03:45,770 --> 00:03:50,390
hydration but you can do it if you want

00:03:48,390 --> 00:03:52,920
we can also use different runtimes and

00:03:50,390 --> 00:03:55,740
we've learned yesterday that we will

00:03:52,920 --> 00:03:59,580
soon be able to maybe run VMs on top of

00:03:55,740 --> 00:04:03,060
missiles so that's really amazing so

00:03:59,580 --> 00:04:05,340
where are we at creature right now we've

00:04:03,060 --> 00:04:11,160
started a small PLC almost two years ago

00:04:05,340 --> 00:04:13,470
and right now we asked 600 agent on our

00:04:11,160 --> 00:04:15,630
seven datacenters we are running on a

00:04:13,470 --> 00:04:18,750
wonder and fifty production application

00:04:15,630 --> 00:04:21,090
and these thanks to the two to generate

00:04:18,750 --> 00:04:24,300
framework which are Merson and apache

00:04:21,090 --> 00:04:26,639
aurora and we will try in a near future

00:04:24,300 --> 00:04:30,270
to introduce machine learning or

00:04:26,639 --> 00:04:32,550
warp load and to move really huge blocks

00:04:30,270 --> 00:04:37,830
from our legacy infrastructure to the

00:04:32,550 --> 00:04:42,810
new methods infrastructure so what does

00:04:37,830 --> 00:04:47,490
this imply from a personal point of view

00:04:42,810 --> 00:04:50,009
I mean yes a revision here I wanted to

00:04:47,490 --> 00:04:53,129
highlight a few points which are really

00:04:50,009 --> 00:04:55,439
important if you want to move from like

00:04:53,129 --> 00:05:00,180
weeded from a small POC to something a

00:04:55,439 --> 00:05:02,580
bit more production grade so the first

00:05:00,180 --> 00:05:06,419
thing is that you have to automate

00:05:02,580 --> 00:05:08,639
everything in our case we are operating

00:05:06,419 --> 00:05:12,270
a huge legacy infrastructure which is

00:05:08,639 --> 00:05:16,259
composed of more than one sorry

00:05:12,270 --> 00:05:20,099
Hill 11,000 of Windows machine plus the

00:05:16,259 --> 00:05:24,270
Missis infrastructure so it's absolutely

00:05:20,099 --> 00:05:27,120
impossible if we don't automatically

00:05:24,270 --> 00:05:28,919
make something work so in our case we

00:05:27,120 --> 00:05:34,319
are using chef to do that as a config

00:05:28,919 --> 00:05:36,419
management tool so okay with config

00:05:34,319 --> 00:05:39,120
management you can deploy sing etcetera

00:05:36,419 --> 00:05:41,930
but it's not the only thing we are doing

00:05:39,120 --> 00:05:45,900
actually we perform also complex

00:05:41,930 --> 00:05:47,699
operation using these tools like if we

00:05:45,900 --> 00:05:50,430
want to reboot a machine if we want to

00:05:47,699 --> 00:05:53,610
fix a reboot the machine if we want to

00:05:50,430 --> 00:05:56,849
upgrade an OS if we want to upgrade our

00:05:53,610 --> 00:05:59,520
message cluster like we do here from 103

00:05:56,849 --> 00:06:02,729
to 104 if I want to scale up my

00:05:59,520 --> 00:06:03,360
infrastructure we do all of that using a

00:06:02,729 --> 00:06:09,479
chef

00:06:03,360 --> 00:06:12,839
thanks to internal development so second

00:06:09,479 --> 00:06:15,839
aspect is you have to configure your

00:06:12,839 --> 00:06:22,229
infrastructure and defensively for

00:06:15,839 --> 00:06:25,889
predictability so the first task for an

00:06:22,229 --> 00:06:28,379
operator to do that is to basically do a

00:06:25,889 --> 00:06:32,310
map identify your fault domains and

00:06:28,379 --> 00:06:36,139
these are mostly related to your network

00:06:32,310 --> 00:06:36,139
topology in your different data centers

00:06:36,150 --> 00:06:43,110
a second aspect is that you have to

00:06:38,100 --> 00:06:44,730
enforce limits for your task I won't

00:06:43,110 --> 00:06:47,010
detail on CPU and memory because there

00:06:44,730 --> 00:06:49,980
have been some interesting blog posts

00:06:47,010 --> 00:06:53,160
around that but do you care about your

00:06:49,980 --> 00:06:54,900
disk and about your the UNIX user that

00:06:53,160 --> 00:06:57,110
makes you all task running on your

00:06:54,900 --> 00:06:59,820
missus infrastructure if not you should

00:06:57,110 --> 00:07:01,260
because that's also part of the

00:06:59,820 --> 00:07:04,200
predictability of your infrastructure

00:07:01,260 --> 00:07:06,510
and last but not least you should

00:07:04,200 --> 00:07:09,540
perform backup and also try to wrestle

00:07:06,510 --> 00:07:12,780
them you don't want like me to be in

00:07:09,540 --> 00:07:15,450
this situation understand a afternoon

00:07:12,780 --> 00:07:17,940
when you on call being called by someone

00:07:15,450 --> 00:07:19,320
your company saying hey we had an

00:07:17,940 --> 00:07:22,170
incident you have to restore everything

00:07:19,320 --> 00:07:26,310
and you end up with this kind of a world

00:07:22,170 --> 00:07:29,460
so please try to do backup and to

00:07:26,310 --> 00:07:31,080
restore them and thanks to this us we

00:07:29,460 --> 00:07:33,810
will have apparently amazing primitive

00:07:31,080 --> 00:07:39,600
are coming for doing that automatically

00:07:33,810 --> 00:07:44,400
a third aspect in our case was our

00:07:39,600 --> 00:07:45,990
ability to move smoothly from a service

00:07:44,400 --> 00:07:49,350
from the legacy infrastructure to the

00:07:45,990 --> 00:07:52,200
messers cursor and to do that we've

00:07:49,350 --> 00:07:55,470
introduced service discovery component

00:07:52,200 --> 00:07:57,870
using console on every single machine in

00:07:55,470 --> 00:07:59,970
our data centers so that we are able to

00:07:57,870 --> 00:08:03,630
perform smooth transition from the

00:07:59,970 --> 00:08:05,070
legacy to the new infrastructure that

00:08:03,630 --> 00:08:08,460
will service discovery components you

00:08:05,070 --> 00:08:10,620
can do a lot more we are using that also

00:08:08,460 --> 00:08:13,590
to for example provision load burn so

00:08:10,620 --> 00:08:16,380
etc so this clearly a key component if

00:08:13,590 --> 00:08:21,150
you want to envisage transitioning from

00:08:16,380 --> 00:08:25,860
a legacy to a new system the first

00:08:21,150 --> 00:08:28,940
aspect is about observability don't

00:08:25,860 --> 00:08:31,080
forget that transitioning from a legacy

00:08:28,940 --> 00:08:34,440
infrastructure which is statically

00:08:31,080 --> 00:08:38,550
partitioned purely outward based to

00:08:34,440 --> 00:08:40,310
something really on containers it's

00:08:38,550 --> 00:08:43,800
something completely new for you on user

00:08:40,310 --> 00:08:46,310
if they use to run under such old

00:08:43,800 --> 00:08:46,310
systems

00:08:46,329 --> 00:08:52,190
why because historic historically their

00:08:49,970 --> 00:08:52,970
instance where a completely static they

00:08:52,190 --> 00:08:56,360
didn't move

00:08:52,970 --> 00:09:00,500
they had monitoring that well was maybe

00:08:56,360 --> 00:09:03,500
depend on the company but our statically

00:09:00,500 --> 00:09:05,990
configured but now apps move

00:09:03,500 --> 00:09:08,320
continuously instances are related

00:09:05,990 --> 00:09:13,220
because of operator of doing something

00:09:08,320 --> 00:09:16,760
are being resorted etcetera etcetera so

00:09:13,220 --> 00:09:19,279
you have to get some insight from your

00:09:16,760 --> 00:09:22,389
platform and here I wanted to highlight

00:09:19,279 --> 00:09:26,800
some very interesting components and

00:09:22,389 --> 00:09:26,800
metric that are available in the missus

00:09:28,120 --> 00:09:35,810
using different business components so

00:09:33,470 --> 00:09:38,899
for example a few metrics we are

00:09:35,810 --> 00:09:40,820
networking these caios there isn't

00:09:38,899 --> 00:09:46,100
another aspect which is important is

00:09:40,820 --> 00:09:50,240
it's tracing for some purpose you may

00:09:46,100 --> 00:09:55,029
want to be able to debug you up and have

00:09:50,240 --> 00:09:59,240
the lowest possible level of insight and

00:09:55,029 --> 00:10:02,329
to do that you can perform tracing in

00:09:59,240 --> 00:10:04,610
measures you have a lot of Awesome

00:10:02,329 --> 00:10:09,850
components and one of them is the curve

00:10:04,610 --> 00:10:12,709
either a toe using that you can you can

00:10:09,850 --> 00:10:16,190
retrieve some traces and these are

00:10:12,709 --> 00:10:20,269
awesome if you want to perform low-level

00:10:16,190 --> 00:10:22,550
investigations in our case we're also

00:10:20,269 --> 00:10:25,300
working to introduce algae TNG as a

00:10:22,550 --> 00:10:28,640
tracing solution and for those of you

00:10:25,300 --> 00:10:31,459
were able to attend to the tracing

00:10:28,640 --> 00:10:38,120
summit there are some of our curries we

00:10:31,459 --> 00:10:40,209
will present this integration so the

00:10:38,120 --> 00:10:43,790
rest aspect I wanted to mention is

00:10:40,209 --> 00:10:48,860
networking networking in our case was a

00:10:43,790 --> 00:10:52,370
really complex aspect so our first

00:10:48,860 --> 00:10:54,829
intent was to provide services around

00:10:52,370 --> 00:10:57,649
networking like automatic DNS

00:10:54,829 --> 00:10:59,190
provisioning timeout profile ABG to

00:10:57,649 --> 00:11:03,180
manage Tiki cookies

00:10:59,190 --> 00:11:09,000
potentially automatic GLS configuration

00:11:03,180 --> 00:11:11,820
etc but we faced two categories of

00:11:09,000 --> 00:11:15,360
issues the first one was about our load

00:11:11,820 --> 00:11:18,660
balancing stack so we are using a cheap

00:11:15,360 --> 00:11:20,580
proxy which is an awesome product these

00:11:18,660 --> 00:11:23,070
communities are bringing a lot of

00:11:20,580 --> 00:11:24,980
addition in the product and so you are

00:11:23,070 --> 00:11:31,530
able to perform almost everything at the

00:11:24,980 --> 00:11:35,100
layer seven Rhian HTTP but the reloads

00:11:31,530 --> 00:11:38,670
while we are not that stable in our case

00:11:35,100 --> 00:11:43,580
we were either in a situation in which

00:11:38,670 --> 00:11:48,600
we introduced reset at the TCP level or

00:11:43,580 --> 00:11:50,850
purely latency spikes so I encourage

00:11:48,600 --> 00:11:53,130
those of you who are using a chip Roxie

00:11:50,850 --> 00:11:55,590
to upgrade to the latest version because

00:11:53,130 --> 00:11:57,350
this community has done a lot of

00:11:55,590 --> 00:12:02,420
interesting work and so that these

00:11:57,350 --> 00:12:04,470
issues are now fixed another aspect is

00:12:02,420 --> 00:12:09,870
regarding predictability

00:12:04,470 --> 00:12:14,250
again we've noticed that we were quite

00:12:09,870 --> 00:12:16,800
frequently subject to the noisy neighbor

00:12:14,250 --> 00:12:22,110
issue which is quite common when you're

00:12:16,800 --> 00:12:24,030
doing our container based systems and so

00:12:22,110 --> 00:12:26,060
we did a lot of Investigation regaining

00:12:24,030 --> 00:12:28,950
that and in our case we ended up

00:12:26,060 --> 00:12:33,750
implementing something around net TLS

00:12:28,950 --> 00:12:35,970
which is something interesting from the

00:12:33,750 --> 00:12:38,160
the kernel which is managed using C

00:12:35,970 --> 00:12:40,500
Group and which allow you to basically

00:12:38,160 --> 00:12:43,820
classify your different flows and to

00:12:40,500 --> 00:12:43,820
apply QoS rule on it

00:12:47,720 --> 00:12:54,480
okay so here it was supposed to be the

00:12:50,580 --> 00:12:57,440
fun side of the talk like a few incident

00:12:54,480 --> 00:13:03,750
we had during the last months

00:12:57,440 --> 00:13:06,000
so first one regarding DC hostages so it

00:13:03,750 --> 00:13:08,790
was called by someone again on Sunday

00:13:06,000 --> 00:13:11,640
afternoon I don't know why always in

00:13:08,790 --> 00:13:15,750
sorry afternoon July was sunny etc and

00:13:11,640 --> 00:13:18,560
okay someone told me hey yeah so we have

00:13:15,750 --> 00:13:21,540
1 DC starting to burn

00:13:18,560 --> 00:13:26,400
so basically errors every sarah has been

00:13:21,540 --> 00:13:29,970
shut down and you have to help us to

00:13:26,400 --> 00:13:33,780
resolve the wall infrastructure and what

00:13:29,970 --> 00:13:36,930
I can tell you is that it was really

00:13:33,780 --> 00:13:38,880
eager to restart something measures base

00:13:36,930 --> 00:13:42,380
and container-based compared to our

00:13:38,880 --> 00:13:46,410
legacy trust me we spent a lot of time

00:13:42,380 --> 00:13:50,850
performing that so clearly dis revealed

00:13:46,410 --> 00:13:56,100
that a missiles based solution bring a

00:13:50,850 --> 00:13:57,870
lot to company like arrow I also wanted

00:13:56,100 --> 00:14:00,660
to mention some disaster recovery

00:13:57,870 --> 00:14:03,720
scenarios such as a mercenary

00:14:00,660 --> 00:14:07,500
occasionally eg worldwide so we had one

00:14:03,720 --> 00:14:10,200
of our user which basically was

00:14:07,500 --> 00:14:12,780
privileged for some reason try to call

00:14:10,200 --> 00:14:15,930
some api's and ended up in destroying

00:14:12,780 --> 00:14:24,330
every application on our infrastructure

00:14:15,930 --> 00:14:29,390
except his home so this is this was an

00:14:24,330 --> 00:14:29,390
HCl concern and so I encourage you to be

00:14:30,080 --> 00:14:37,370
careful about these problematics you

00:14:34,020 --> 00:14:40,890
should either perform multi-tenancy or

00:14:37,370 --> 00:14:48,660
be really careful about isolating your

00:14:40,890 --> 00:14:50,590
different api path so for us what's left

00:14:48,660 --> 00:14:53,130
to answer

00:14:50,590 --> 00:14:58,500
[Music]

00:14:53,130 --> 00:15:03,150
so the our first concern in the is

00:14:58,500 --> 00:15:06,060
regarding adoration clearly we we aim to

00:15:03,150 --> 00:15:11,610
improve our isolation regarding network

00:15:06,060 --> 00:15:14,930
and iOS aspect with this chaos since we

00:15:11,610 --> 00:15:17,970
will also try to move complex and

00:15:14,930 --> 00:15:20,760
latency driven components we also

00:15:17,970 --> 00:15:23,340
looking in using CPU sets potentially to

00:15:20,760 --> 00:15:27,540
have more predictability in our on our

00:15:23,340 --> 00:15:30,210
components there is also something that

00:15:27,540 --> 00:15:33,900
will require a lot of investment from

00:15:30,210 --> 00:15:38,070
from us and this is basically described

00:15:33,900 --> 00:15:41,490
by the graph here you can notice that

00:15:38,070 --> 00:15:43,680
the usage versus reservation between the

00:15:41,490 --> 00:15:47,880
usage and the reservation there is quite

00:15:43,680 --> 00:15:51,510
a gap and so in the long run we've we

00:15:47,880 --> 00:15:53,790
will probably have to invest into the

00:15:51,510 --> 00:15:56,990
notion of revocability oversubscription

00:15:53,790 --> 00:15:59,700
and why not potentially bin packing

00:15:56,990 --> 00:16:03,900
because using bin packing you cannot

00:15:59,700 --> 00:16:05,280
only reclaim our wear but potentially if

00:16:03,900 --> 00:16:07,440
you are able to do it

00:16:05,280 --> 00:16:10,500
you can also reclaim electrical power

00:16:07,440 --> 00:16:13,350
just imagine if you are able to

00:16:10,500 --> 00:16:18,300
defragment your cluster by packing the

00:16:13,350 --> 00:16:20,880
tasks you can envisage completely

00:16:18,300 --> 00:16:24,000
stopping some of your servers they are

00:16:20,880 --> 00:16:26,100
doing nothing so if you have a correct

00:16:24,000 --> 00:16:28,770
deal with your energy supply on your

00:16:26,100 --> 00:16:33,570
data center you can potentially save

00:16:28,770 --> 00:16:36,930
some resources a last aspect is about

00:16:33,570 --> 00:16:39,660
maintenance primitives as you may have

00:16:36,930 --> 00:16:42,210
understood we are doing some complex

00:16:39,660 --> 00:16:44,460
operation with our IT automation tool

00:16:42,210 --> 00:16:47,370
like reboots etc and we would like to

00:16:44,460 --> 00:16:50,280
anticipate more dissipation by

00:16:47,370 --> 00:16:51,900
reclaiming resources and inform the

00:16:50,280 --> 00:16:53,760
different frameworks that we will do

00:16:51,900 --> 00:16:57,320
something and at some point they have to

00:16:53,760 --> 00:16:57,320
move their tasks

00:17:04,780 --> 00:17:09,819
okay so this slide was about

00:17:06,640 --> 00:17:12,520
collaboration the company and Trust to

00:17:09,819 --> 00:17:13,810
mention that if you provide a good level

00:17:12,520 --> 00:17:16,689
services and a good level of

00:17:13,810 --> 00:17:19,480
collaboration between essary teams and

00:17:16,689 --> 00:17:21,819
software department in your company you

00:17:19,480 --> 00:17:25,540
get you can get awesome contribution and

00:17:21,819 --> 00:17:28,390
this is one of the good example because

00:17:25,540 --> 00:17:33,130
one of our ingenious software Department

00:17:28,390 --> 00:17:36,190
noticed that by trying to move a dotnet

00:17:33,130 --> 00:17:36,970
based application on top of lessers he

00:17:36,190 --> 00:17:42,190
observed

00:17:36,970 --> 00:17:46,030
weird behaviors regarding the sizing of

00:17:42,190 --> 00:17:48,610
its thread pools and basically this guy

00:17:46,030 --> 00:17:50,860
managed to introduce the support of CPU

00:17:48,610 --> 00:17:52,840
shares and ZFS into the dotnet here are

00:17:50,860 --> 00:18:00,190
which is basically the equivalent of the

00:17:52,840 --> 00:18:02,620
JDK the JDK in the.net ecosystem so

00:18:00,190 --> 00:18:05,230
clearly collaboration inside the company

00:18:02,620 --> 00:18:07,660
gives you a lot of value and exchanging

00:18:05,230 --> 00:18:15,700
around this aspect with your developers

00:18:07,660 --> 00:18:17,770
can bring you a lot of added value okay

00:18:15,700 --> 00:18:19,690
so that's all if you want to know more

00:18:17,770 --> 00:18:24,570
because this was a bit technical and I

00:18:19,690 --> 00:18:28,240
was quite fast faster that was expected

00:18:24,570 --> 00:18:31,390
feel free to come by our booth we can

00:18:28,240 --> 00:18:33,130
detail a lot run that and also I want to

00:18:31,390 --> 00:18:36,760
mention that we are hiring so if you

00:18:33,130 --> 00:18:39,670
want to work in an amazing R&D

00:18:36,760 --> 00:18:43,770
department in either of Paris on the US

00:18:39,670 --> 00:18:48,020
feel free thank you very much

00:18:43,770 --> 00:18:48,020

YouTube URL: https://www.youtube.com/watch?v=8jlxp3g8_D0


