Title: What Building Multiple Scalable DC OS Deployments Taught Me About Running Stateful Services on DC OS
Publication date: 2017-10-31
Playlist: MesosCon Europe 2017
Description: 
	What Building Multiple Scalable DC/OS Deployments Taught Me About Running Stateful Services on DC/OS - Nathan Shimek, New Context

As a systems integrator specializing in cloud transformation projects, New Context has helped customers run mission-critical applications on DCOS. As part of that work, we’ve overcome a host of challenges that pop up when running stateful services like databases, queues, and key-value stores on top of DC/OS.

DC/OS supports local and external volumes for stateful applications, but there are a number of documented “caveats” that must be overcome like volumes being pinned to hosts, inability to dynamically provision volumes at run time, resource requirements being fixed at task launch, and being limited to one task per volume.

This talk will provide background on the main gotchas of running stateful services on Marathon and DCOS, and will discuss how to overcome them based on real-world projects conducted alongside some of the largest container users in the world.

About Nathan Shimek
Nathan serves as VP of Client Solutions for New Context. He has over 13 years of experience leading high performing operations and development organizations for companies like LifeLock and Saba Software.
Captions: 
	00:00:00,269 --> 00:00:06,150
good afternoon I'm Nathan shamak vice

00:00:04,830 --> 00:00:07,940
president of client solutions at new

00:00:06,150 --> 00:00:10,230
context we are a SAN francisco-based

00:00:07,940 --> 00:00:13,230
systems integrator that specializes in

00:00:10,230 --> 00:00:15,990
the container implementations I'm joined

00:00:13,230 --> 00:00:18,630
today by Dinesh Asrani senior software

00:00:15,990 --> 00:00:20,789
engineer at port works and today we're

00:00:18,630 --> 00:00:23,100
here to talk to you about what building

00:00:20,789 --> 00:00:25,350
multiple scalable DCOs deployments has

00:00:23,100 --> 00:00:26,060
taught us about running staple services

00:00:25,350 --> 00:00:28,500
on DCOs

00:00:26,060 --> 00:00:29,760
I'd like to take a moment and thank the

00:00:28,500 --> 00:00:32,250
Linux Foundation for hosting the

00:00:29,760 --> 00:00:34,040
conference Mesa sphere for developing a

00:00:32,250 --> 00:00:36,510
great product for us to build on top of

00:00:34,040 --> 00:00:39,540
sponsors and all of you for showing up

00:00:36,510 --> 00:00:43,399
at a five o'clock on Friday so without

00:00:39,540 --> 00:00:46,620
further ado let's dive right in

00:00:43,399 --> 00:00:48,530
the containerization expand space as it

00:00:46,620 --> 00:00:51,750
exists today has a myriad of challenges

00:00:48,530 --> 00:00:54,210
first start it's relatively new so the

00:00:51,750 --> 00:00:56,760
teams that are today being tasked to

00:00:54,210 --> 00:00:58,969
build and maintain platforms often just

00:00:56,760 --> 00:01:02,010
don't have a huge amount of experience

00:00:58,969 --> 00:01:04,890
similar to the you know adoption of

00:01:02,010 --> 00:01:06,229
cloud technologies there's a real ramp

00:01:04,890 --> 00:01:08,390
that comes into learning and

00:01:06,229 --> 00:01:12,270
successfully building all these things

00:01:08,390 --> 00:01:13,770
as such sufficient skills and experience

00:01:12,270 --> 00:01:16,970
are one of the things that you should

00:01:13,770 --> 00:01:19,470
really look forward as you go forward

00:01:16,970 --> 00:01:21,720
there are areas where traditional skills

00:01:19,470 --> 00:01:23,670
don't necessarily directly translate but

00:01:21,720 --> 00:01:25,110
need to be built upon for example in the

00:01:23,670 --> 00:01:28,640
networking arena you know the recent

00:01:25,110 --> 00:01:30,990
edition of C&I Sdn network overlays etc

00:01:28,640 --> 00:01:33,720
further complicate an already complex

00:01:30,990 --> 00:01:35,280
picture so if it's your expectation

00:01:33,720 --> 00:01:37,740
they're gonna go from zero to production

00:01:35,280 --> 00:01:39,600
with a small team and a couple months

00:01:37,740 --> 00:01:40,530
that doesn't have a domain experience

00:01:39,600 --> 00:01:43,140
it's probably gonna be pretty

00:01:40,530 --> 00:01:45,479
challenging that said there is hope

00:01:43,140 --> 00:01:47,490
things are improving very rapidly and

00:01:45,479 --> 00:01:48,990
the patterns for success and the space

00:01:47,490 --> 00:01:52,259
are quickly emerging in the community is

00:01:48,990 --> 00:01:54,149
doing a lot to bring those forward so

00:01:52,259 --> 00:01:55,939
today we'll talk about four high level

00:01:54,149 --> 00:01:58,710
areas and then dive a little bit deeper

00:01:55,939 --> 00:02:00,810
first we'll look at platform

00:01:58,710 --> 00:02:02,280
availability of role and some of the key

00:02:00,810 --> 00:02:03,990
design decisions you should be thinking

00:02:02,280 --> 00:02:06,869
about to ensure your DCOs implementation

00:02:03,990 --> 00:02:08,369
is resilient against failure next we

00:02:06,869 --> 00:02:10,890
will look at some of the stickier points

00:02:08,369 --> 00:02:13,470
we both experienced within and outside

00:02:10,890 --> 00:02:15,870
the cluster and finally we'll review how

00:02:13,470 --> 00:02:18,420
organizations respond to these

00:02:15,870 --> 00:02:20,490
challenges and what has enabled them to

00:02:18,420 --> 00:02:21,720
find success for State running stateful

00:02:20,490 --> 00:02:23,850
services and DCOs

00:02:21,720 --> 00:02:28,590
so let's take a look at platform

00:02:23,850 --> 00:02:31,050
availability you'll see that there's a

00:02:28,590 --> 00:02:33,540
huge list of things that can be

00:02:31,050 --> 00:02:34,590
considered failure domains don't

00:02:33,540 --> 00:02:36,810
consider these specific to

00:02:34,590 --> 00:02:38,340
containerization or dcs by any means

00:02:36,810 --> 00:02:41,630
these are failure domains that you've

00:02:38,340 --> 00:02:43,680
probably seen in Amazon environment

00:02:41,630 --> 00:02:44,880
maybe your virtualized infrastructure

00:02:43,680 --> 00:02:47,250
and certainly could be possible in your

00:02:44,880 --> 00:02:48,480
bare metal infrastructure in our

00:02:47,250 --> 00:02:50,340
experience these are scenarios that

00:02:48,480 --> 00:02:52,920
given sufficient time number of users

00:02:50,340 --> 00:02:55,170
you're likely to see at some point in

00:02:52,920 --> 00:02:57,090
your environment so failures have fallen

00:02:55,170 --> 00:02:59,040
all the time it's about how we design

00:02:57,090 --> 00:03:02,370
around those and to mitigate those risks

00:02:59,040 --> 00:03:04,470
that matter at the end of the day it's

00:03:02,370 --> 00:03:12,120
our job to mitigate the impact of these

00:03:04,470 --> 00:03:13,550
outages and be able so when we get

00:03:12,120 --> 00:03:16,500
things wrong and we do get things wrong

00:03:13,550 --> 00:03:18,450
they can be dangerous and costly that's

00:03:16,500 --> 00:03:19,800
it don't lose hope yeah these are

00:03:18,450 --> 00:03:22,350
certainly not insurmountable challenges

00:03:19,800 --> 00:03:23,520
it's been something we've really focused

00:03:22,350 --> 00:03:25,950
on over the last couple years and

00:03:23,520 --> 00:03:27,330
improving in the space when you do have

00:03:25,950 --> 00:03:28,890
an issue get in the habit of holding a

00:03:27,330 --> 00:03:30,450
blameless post mortem then be sure to

00:03:28,890 --> 00:03:32,190
include how one could have identified a

00:03:30,450 --> 00:03:35,640
service interruption through monitoring

00:03:32,190 --> 00:03:38,280
your metrics and we include that as part

00:03:35,640 --> 00:03:40,130
of discussion didn't actually test or

00:03:38,280 --> 00:03:42,630
setup and test the appropriate monitors

00:03:40,130 --> 00:03:44,310
and ensure that they behave expected is

00:03:42,630 --> 00:03:45,959
expected if you're unfamiliar with the

00:03:44,310 --> 00:03:49,110
concept blame puts mortems let's have a

00:03:45,959 --> 00:03:51,090
quick conversation after this actually

00:03:49,110 --> 00:03:53,760
diving into how to build a resilient

00:03:51,090 --> 00:03:55,709
platform or of the opinion that you

00:03:53,760 --> 00:03:57,120
should design for production quality

00:03:55,709 --> 00:03:58,739
from the start that doesn't mean that

00:03:57,120 --> 00:04:01,739
you have to build a production level

00:03:58,739 --> 00:04:04,410
implementation during your POC days but

00:04:01,739 --> 00:04:06,690
keeping that goalpost further down is

00:04:04,410 --> 00:04:08,010
going to be really important it's our

00:04:06,690 --> 00:04:09,810
experience that the difference in effort

00:04:08,010 --> 00:04:11,820
is compared ly small when you look at

00:04:09,810 --> 00:04:13,320
the challenges companies face when a POC

00:04:11,820 --> 00:04:15,480
implementation gets traction and

00:04:13,320 --> 00:04:17,269
suddenly you're hosting

00:04:15,480 --> 00:04:20,430
revenue-generating systems on top of

00:04:17,269 --> 00:04:22,979
unstable or essentially just small-scale

00:04:20,430 --> 00:04:24,780
infrastructure and variably when that

00:04:22,979 --> 00:04:27,150
happens platform stability issues emerge

00:04:24,780 --> 00:04:28,320
as it happens just platforms

00:04:27,150 --> 00:04:30,870
just being asked to do things that's not

00:04:28,320 --> 00:04:34,139
really designed to do and users have bad

00:04:30,870 --> 00:04:35,820
experiences additionally when you design

00:04:34,139 --> 00:04:37,620
from the start with production scale

00:04:35,820 --> 00:04:39,240
infrastructure in mind you inform

00:04:37,620 --> 00:04:41,699
decisions that you'll make it a little

00:04:39,240 --> 00:04:43,740
time as you have a specific lens to work

00:04:41,699 --> 00:04:45,750
with your automation and told choices

00:04:43,740 --> 00:04:47,639
are very heavily impacted by the design

00:04:45,750 --> 00:04:49,520
and over the medium term you should

00:04:47,639 --> 00:04:51,539
actually be able to get further ahead as

00:04:49,520 --> 00:04:54,840
your investment in automation from the

00:04:51,539 --> 00:04:56,250
start around the ability to build and

00:04:54,840 --> 00:04:59,789
rebuild clusters easily with minimal

00:04:56,250 --> 00:05:01,380
impact it will greatly reduce your time

00:04:59,789 --> 00:05:04,949
and upgrade and allow you to rapidly

00:05:01,380 --> 00:05:06,630
iterate on your DCOs infrastructure it's

00:05:04,949 --> 00:05:07,770
our again our experience that on small

00:05:06,630 --> 00:05:08,970
scale implementation so you can

00:05:07,770 --> 00:05:10,979
experience more talent in time with

00:05:08,970 --> 00:05:12,660
cluster rebuilds then a much larger one

00:05:10,979 --> 00:05:14,699
do the typical approach of manual

00:05:12,660 --> 00:05:16,110
intervention in a POC environment and

00:05:14,699 --> 00:05:19,460
small scale environment versus a heavy

00:05:16,110 --> 00:05:22,260
focus on automation when you go to scale

00:05:19,460 --> 00:05:25,440
some key points and to think about from

00:05:22,260 --> 00:05:26,849
your automation efforts are your

00:05:25,440 --> 00:05:28,860
operators safe to terminate at least one

00:05:26,849 --> 00:05:30,900
node without any measurable impact yes

00:05:28,860 --> 00:05:32,910
that's great what happens with three

00:05:30,900 --> 00:05:35,010
notes go down what if you answered no to

00:05:32,910 --> 00:05:37,080
that what happens when you lose a node

00:05:35,010 --> 00:05:41,849
and we're sitting at a talk at mrs. Kahn

00:05:37,080 --> 00:05:43,169
at 1706 on a Friday well did your

00:05:41,849 --> 00:05:44,669
monitoring a metrics collection pick it

00:05:43,169 --> 00:05:46,229
up and automatically resolve that and

00:05:44,669 --> 00:05:49,380
just open up a ticket to let you know

00:05:46,229 --> 00:05:51,690
something happened or did a developer

00:05:49,380 --> 00:05:53,250
who's relying upon services provided on

00:05:51,690 --> 00:05:55,409
top of DCOs have to open a ticket

00:05:53,250 --> 00:05:58,349
internally or even worse yet some

00:05:55,409 --> 00:05:59,760
end-user wait 25 minutes experiencing an

00:05:58,349 --> 00:06:01,380
outage open up a ticket with your

00:05:59,760 --> 00:06:04,800
company and then you know you have SL

00:06:01,380 --> 00:06:06,300
impacts all these things can by and

00:06:04,800 --> 00:06:08,990
large we mitigated with a proper design

00:06:06,300 --> 00:06:11,310
and implementation from the start

00:06:08,990 --> 00:06:13,260
continue down that scenario so now we've

00:06:11,310 --> 00:06:16,139
got some notes down a customer's called

00:06:13,260 --> 00:06:18,120
in and after 25 or so customers called

00:06:16,139 --> 00:06:19,740
in after 25 minutes you've been paged

00:06:18,120 --> 00:06:21,419
out and now you've got to open up your

00:06:19,740 --> 00:06:23,699
laptop connect remotely and take a look

00:06:21,419 --> 00:06:25,380
at what's going on do you have the

00:06:23,699 --> 00:06:27,449
ability to bring back the failed notes

00:06:25,380 --> 00:06:29,010
with a single command easily executed or

00:06:27,449 --> 00:06:31,199
do you have to actually dig in and do

00:06:29,010 --> 00:06:33,960
some manual intervention again now we're

00:06:31,199 --> 00:06:36,300
adding time all these things are

00:06:33,960 --> 00:06:38,880
relatively easily addressed especially

00:06:36,300 --> 00:06:40,810
if that skill sets required to really

00:06:38,880 --> 00:06:43,300
take on the challenges associated

00:06:40,810 --> 00:06:45,880
containers and stateful services within

00:06:43,300 --> 00:06:48,040
them now I'll hand it over to Dinesh to

00:06:45,880 --> 00:06:52,500
talk about the staples services on

00:06:48,040 --> 00:06:56,310
storage thanks Nate

00:06:52,500 --> 00:06:58,240
so in this new age of their ups words

00:06:56,310 --> 00:07:00,520
typically everything needs to be

00:06:58,240 --> 00:07:02,620
automated because no one's really got

00:07:00,520 --> 00:07:06,190
the time to log in and manually recover

00:07:02,620 --> 00:07:08,710
from failures also this is not really

00:07:06,190 --> 00:07:10,930
possible at large scale because you

00:07:08,710 --> 00:07:13,720
don't want one of your DevOps folks to

00:07:10,930 --> 00:07:16,570
basically be up at like nature that 5:00

00:07:13,720 --> 00:07:18,010
p.m. on a on a Friday to basically try

00:07:16,570 --> 00:07:20,820
to bring up thousand nodes that went

00:07:18,010 --> 00:07:23,080
down and and try to recover your data

00:07:20,820 --> 00:07:24,970
you want to make sure that the storage

00:07:23,080 --> 00:07:26,830
solution you choose has good integration

00:07:24,970 --> 00:07:28,450
with cellulose and if you're using

00:07:26,830 --> 00:07:31,210
multiple schedulers you want to make

00:07:28,450 --> 00:07:32,889
sure that they work they work across

00:07:31,210 --> 00:07:37,000
multiple sherrilyn so you don't need to

00:07:32,889 --> 00:07:38,440
use multiple solutions with them for

00:07:37,000 --> 00:07:39,850
example you also want to make sure that

00:07:38,440 --> 00:07:43,150
you are able to efficiently schedule

00:07:39,850 --> 00:07:44,830
pots to be co-located with your data so

00:07:43,150 --> 00:07:49,510
that you get good performance for your

00:07:44,830 --> 00:07:52,510
pots or containers and don't spend a lot

00:07:49,510 --> 00:07:57,490
of network bandwidth just doing data or

00:07:52,510 --> 00:07:58,900
just sending data across your nodes on a

00:07:57,490 --> 00:08:00,669
large scale you also don't want to

00:07:58,900 --> 00:08:02,380
manually provision volumes every time a

00:08:00,669 --> 00:08:04,240
customer whether its internal or

00:08:02,380 --> 00:08:06,070
external needs to spin up new services

00:08:04,240 --> 00:08:08,979
because that is just adding another

00:08:06,070 --> 00:08:11,139
layer of manual intervention which is

00:08:08,979 --> 00:08:15,490
just not acceptable in this day of

00:08:11,139 --> 00:08:16,990
automation so one of the things is you

00:08:15,490 --> 00:08:18,940
also want to make sure that you test

00:08:16,990 --> 00:08:21,490
various failure scenarios and how

00:08:18,940 --> 00:08:23,620
schedulers deal with them with regards

00:08:21,490 --> 00:08:27,820
to storage you know in order to avoid

00:08:23,620 --> 00:08:29,410
nasty surprises in productions soviet

00:08:27,820 --> 00:08:31,240
port works are actually working towards

00:08:29,410 --> 00:08:33,250
an open-source framework called torpedo

00:08:31,240 --> 00:08:35,919
which will help you validate these via

00:08:33,250 --> 00:08:39,339
various failures in areas to avoid just

00:08:35,919 --> 00:08:41,890
that the next thing that you should look

00:08:39,339 --> 00:08:44,589
at is how easy you are able to basically

00:08:41,890 --> 00:08:46,900
add or replace storage nodes and perform

00:08:44,589 --> 00:08:48,310
maintenance operations because these are

00:08:46,900 --> 00:08:50,470
the kind of operations that could

00:08:48,310 --> 00:08:52,570
basically result in downtime for your

00:08:50,470 --> 00:08:53,980
services so you want to make sure that

00:08:52,570 --> 00:08:56,949
any storage solution that you

00:08:53,980 --> 00:09:02,290
use minimizes or eliminates this kind of

00:08:56,949 --> 00:09:05,440
downtime so for example if you're using

00:09:02,290 --> 00:09:07,060
auto scaling groups with Amazon you you

00:09:05,440 --> 00:09:09,430
need to figure out how that would affect

00:09:07,060 --> 00:09:11,139
you with the storage from your old nodes

00:09:09,430 --> 00:09:13,630
automatically be available to your new

00:09:11,139 --> 00:09:15,490
nodes and if you wanted to add capacity

00:09:13,630 --> 00:09:17,050
capacity to your storage solution are

00:09:15,490 --> 00:09:19,570
you able to scale up your current nodes

00:09:17,050 --> 00:09:21,670
or would you basically be able to add

00:09:19,570 --> 00:09:25,449
new nodes to scale up your cluster

00:09:21,670 --> 00:09:27,519
either another thing to keep in mind is

00:09:25,449 --> 00:09:30,430
how your services would work in hybrid

00:09:27,519 --> 00:09:32,110
cloud deployments because you don't want

00:09:30,430 --> 00:09:34,420
to be building tools and automation

00:09:32,110 --> 00:09:36,250
across four different types of

00:09:34,420 --> 00:09:38,380
environments that you have you want to

00:09:36,250 --> 00:09:43,779
have one way of doing things across

00:09:38,380 --> 00:09:45,790
multiple environments so for that you

00:09:43,779 --> 00:09:47,889
basically would be you basically want to

00:09:45,790 --> 00:09:50,560
use a cloud native storage solution like

00:09:47,889 --> 00:09:53,050
port works to make sure that it is easy

00:09:50,560 --> 00:09:57,579
to easy to manage and deploy your

00:09:53,050 --> 00:09:59,670
stories in one way you don't have to

00:09:57,579 --> 00:10:01,959
have multiple automation frameworks and

00:09:59,670 --> 00:10:04,750
tools to manage the different

00:10:01,959 --> 00:10:09,790
deployments in that field like Nathan

00:10:04,750 --> 00:10:11,680
pointed out also you are you want to aim

00:10:09,790 --> 00:10:14,230
for highly available data as Nathan

00:10:11,680 --> 00:10:15,850
pointed out earlier because you don't

00:10:14,230 --> 00:10:18,010
want to run into production and then

00:10:15,850 --> 00:10:19,199
figure out that oh you lost the node and

00:10:18,010 --> 00:10:21,819
then you are not able to bring that

00:10:19,199 --> 00:10:26,980
bring the same services up because you

00:10:21,819 --> 00:10:28,360
fail to replicate your data another

00:10:26,980 --> 00:10:30,910
thing that you want to make sure is that

00:10:28,360 --> 00:10:33,399
your storage solution is automatically

00:10:30,910 --> 00:10:35,290
able to place replicas across failure

00:10:33,399 --> 00:10:36,250
domains so that you're always able to

00:10:35,290 --> 00:10:39,850
bring up your service

00:10:36,250 --> 00:10:41,079
even if an entire rack goes down so this

00:10:39,850 --> 00:10:43,149
will actually require a storage solution

00:10:41,079 --> 00:10:45,910
to be intelligent enough to figure out

00:10:43,149 --> 00:10:49,089
where they are located and automatically

00:10:45,910 --> 00:10:53,110
place data on in different availability

00:10:49,089 --> 00:10:54,399
zones when they are provisioned finally

00:10:53,110 --> 00:10:55,779
you want to make sure that when the time

00:10:54,399 --> 00:10:57,519
does come to update your software

00:10:55,779 --> 00:10:59,769
solution you don't have to bring down

00:10:57,519 --> 00:11:01,660
your entire cluster you want to make

00:10:59,769 --> 00:11:03,670
sure that there is a way to perform in

00:11:01,660 --> 00:11:06,939
place rolling upgrades to minimize

00:11:03,670 --> 00:11:07,950
disruptions again this sometimes

00:11:06,939 --> 00:11:10,279
requires integral

00:11:07,950 --> 00:11:14,040
with schedulers to let them know that

00:11:10,279 --> 00:11:16,350
your storage is going to be down on on a

00:11:14,040 --> 00:11:19,050
particular node so that it should not

00:11:16,350 --> 00:11:22,950
schedule any containers on to that node

00:11:19,050 --> 00:11:24,870
while the upgrade is no process so I'm

00:11:22,950 --> 00:11:27,029
gonna hand it back to Nathan now to talk

00:11:24,870 --> 00:11:30,420
about the test for the field failure

00:11:27,029 --> 00:11:36,959
scenarios that I alluded to thanks the

00:11:30,420 --> 00:11:39,120
national testing is key in our world

00:11:36,959 --> 00:11:41,639
today there are a number of companies

00:11:39,120 --> 00:11:43,980
like port works with torpedo and Netflix

00:11:41,639 --> 00:11:46,019
with chaos monkey that are building an

00:11:43,980 --> 00:11:49,050
open sourcing tools which allow you to

00:11:46,019 --> 00:11:52,440
simulate railroad outages for various

00:11:49,050 --> 00:11:54,060
services ideally you would eventually

00:11:52,440 --> 00:11:55,410
mature that's actually running in your

00:11:54,060 --> 00:11:55,920
production environment but on the path

00:11:55,410 --> 00:11:57,480
there

00:11:55,920 --> 00:11:59,040
I would suggest building a production

00:11:57,480 --> 00:12:00,990
like environment so a minimal scale

00:11:59,040 --> 00:12:02,910
implementation that follows the same

00:12:00,990 --> 00:12:04,260
color string topology network topology

00:12:02,910 --> 00:12:06,180
etc as your actual production

00:12:04,260 --> 00:12:08,550
infrastructure and run it there

00:12:06,180 --> 00:12:12,300
doing so will likely expose gaps and

00:12:08,550 --> 00:12:15,060
monitoring responses times any number of

00:12:12,300 --> 00:12:16,529
areas that you are going to hit in

00:12:15,060 --> 00:12:19,130
production this would just be a less

00:12:16,529 --> 00:12:22,079
costly way to find it and patch that up

00:12:19,130 --> 00:12:23,490
so again develop metrics and monitoring

00:12:22,079 --> 00:12:24,750
that align to the failure scenarios that

00:12:23,490 --> 00:12:26,940
you see most commonly and are most

00:12:24,750 --> 00:12:28,980
impactful in the world today it's

00:12:26,940 --> 00:12:30,750
incredibly easy to implement the tool

00:12:28,980 --> 00:12:33,089
check a bunch of check boxes and just

00:12:30,750 --> 00:12:34,470
get totally inundated with the data

00:12:33,089 --> 00:12:37,110
that's deliver it's unit becomes uh

00:12:34,470 --> 00:12:40,790
national really focus on what impacts

00:12:37,110 --> 00:12:40,790
you and how to respond to that

00:12:41,269 --> 00:12:45,930
additionally when things break and they

00:12:43,500 --> 00:12:47,970
will it's really important to limit the

00:12:45,930 --> 00:12:49,769
blast radius last thing you want to have

00:12:47,970 --> 00:12:51,510
happen as a cascading failure which

00:12:49,769 --> 00:12:56,100
takes significant downtime and effort to

00:12:51,510 --> 00:12:58,050
recover from if we started with a H a

00:12:56,100 --> 00:12:59,430
design and implementation have focused

00:12:58,050 --> 00:13:02,250
on automation we've already taken

00:12:59,430 --> 00:13:05,310
significant steps to reduce the impact

00:13:02,250 --> 00:13:07,500
of single zone outages and we can

00:13:05,310 --> 00:13:09,389
further contain the likelihood of that

00:13:07,500 --> 00:13:11,279
happening by isolating user applications

00:13:09,389 --> 00:13:13,319
from each other platform services from

00:13:11,279 --> 00:13:16,230
users and platform services from each

00:13:13,319 --> 00:13:17,670
other for example if a platform service

00:13:16,230 --> 00:13:19,709
needs zookeeper then the zookeeper

00:13:17,670 --> 00:13:21,269
instance of the service that is linked

00:13:19,709 --> 00:13:22,150
to should not be accessible from the

00:13:21,269 --> 00:13:23,770
platform

00:13:22,150 --> 00:13:25,180
isolating platform services from the

00:13:23,770 --> 00:13:26,620
user space will help ensure platform

00:13:25,180 --> 00:13:27,100
resiliency in the face of application

00:13:26,620 --> 00:13:29,050
issues

00:13:27,100 --> 00:13:31,330
additionally sandboxing platform

00:13:29,050 --> 00:13:32,650
services will help avoid everything from

00:13:31,330 --> 00:13:35,520
noisy neighbor problems and resource

00:13:32,650 --> 00:13:38,050
consumption issues to cascading failures

00:13:35,520 --> 00:13:40,330
at the end of the day infrastructure is

00:13:38,050 --> 00:13:42,520
multidisciplinary and cross-functional

00:13:40,330 --> 00:13:44,940
and DC OS is no different you really

00:13:42,520 --> 00:13:47,320
need expertise and security compliance

00:13:44,940 --> 00:13:50,320
containers specifically compute storage

00:13:47,320 --> 00:13:50,620
networking automation CI on and on and

00:13:50,320 --> 00:13:52,870
on

00:13:50,620 --> 00:13:54,940
we're not yet to the point where we

00:13:52,870 --> 00:13:56,680
fully converged those skill sets so find

00:13:54,940 --> 00:13:59,830
people with experience in the MIT space

00:13:56,680 --> 00:14:01,990
and bring them in the the days of having

00:13:59,830 --> 00:14:04,600
a compute team and a network team and a

00:14:01,990 --> 00:14:06,430
storage team don't really align what the

00:14:04,600 --> 00:14:07,780
model of DC OS and nor do they align and

00:14:06,430 --> 00:14:08,350
really modern operation models in

00:14:07,780 --> 00:14:10,450
general

00:14:08,350 --> 00:14:12,040
DevOps has pretty fundamentally changed

00:14:10,450 --> 00:14:14,350
a space and you should look to a lot of

00:14:12,040 --> 00:14:16,030
the learnings from there so now let's

00:14:14,350 --> 00:14:17,890
take a look at what's happening within

00:14:16,030 --> 00:14:24,070
the cluster I'll hand it back to the

00:14:17,890 --> 00:14:25,810
mission so once you have your cluster up

00:14:24,070 --> 00:14:28,240
and running you will realize that your

00:14:25,810 --> 00:14:30,790
needs needs will change over time either

00:14:28,240 --> 00:14:33,130
because the apps that you use will

00:14:30,790 --> 00:14:34,540
change the scale that you run them at

00:14:33,130 --> 00:14:36,070
will change or it's just the

00:14:34,540 --> 00:14:39,400
ever-evolving tech that you're involved

00:14:36,070 --> 00:14:41,110
with so in such scenarios you don't want

00:14:39,400 --> 00:14:42,760
to tear down your volumes or cluster and

00:14:41,110 --> 00:14:44,650
reinstall everything to be able to deal

00:14:42,760 --> 00:14:47,290
with your new requirements for example

00:14:44,650 --> 00:14:49,780
if you provisioned 100 GB volume with

00:14:47,290 --> 00:14:51,160
your foreign application but the demand

00:14:49,780 --> 00:14:54,520
and use for that application far

00:14:51,160 --> 00:14:56,890
exceeded your expectation and you now

00:14:54,520 --> 00:14:58,330
need to allocate more space to it do you

00:14:56,890 --> 00:15:02,530
want to provision another volume and

00:14:58,330 --> 00:15:05,920
move data over from the old volume you

00:15:02,530 --> 00:15:08,470
you don't the ideal way you would want

00:15:05,920 --> 00:15:10,560
to do this is do it in real time without

00:15:08,470 --> 00:15:13,510
having any downtime for your services

00:15:10,560 --> 00:15:15,370
and you will eventually hit a point

00:15:13,510 --> 00:15:19,120
where you will need to add more storage

00:15:15,370 --> 00:15:20,800
to your storage solution again you would

00:15:19,120 --> 00:15:23,080
want to make sure that the solution that

00:15:20,800 --> 00:15:25,270
you have chosen allows you to do this

00:15:23,080 --> 00:15:27,670
seamlessly by either adding disks to

00:15:25,270 --> 00:15:31,360
nodes or adding new nodes as I had

00:15:27,670 --> 00:15:32,980
mentioned earlier you also want to make

00:15:31,360 --> 00:15:35,020
sure that you understand your customers

00:15:32,980 --> 00:15:35,690
needs with regards to backups and

00:15:35,020 --> 00:15:37,970
archive

00:15:35,690 --> 00:15:39,560
data for example you want to set up

00:15:37,970 --> 00:15:41,810
schedules to take regular snapshots

00:15:39,560 --> 00:15:44,390
automatically and also archive your data

00:15:41,810 --> 00:15:46,400
outside your cluster in terms of in

00:15:44,390 --> 00:15:50,720
cases of disaster so that you can

00:15:46,400 --> 00:15:51,920
basically recover from that for example

00:15:50,720 --> 00:15:53,960
with port works you can do this by

00:15:51,920 --> 00:15:56,840
setting up snapshots scheduled at a

00:15:53,960 --> 00:15:58,400
continued granular level and also take

00:15:56,840 --> 00:16:01,010
cloud snaps which can backup your data

00:15:58,400 --> 00:16:04,490
to either s3 or your blob or a good

00:16:01,010 --> 00:16:06,200
cloud storage so in a case of disaster

00:16:04,490 --> 00:16:07,850
all you would need to do is basically

00:16:06,200 --> 00:16:09,530
show from that cloud snap and

00:16:07,850 --> 00:16:13,190
reconfigure your apps and you will be up

00:16:09,530 --> 00:16:14,780
and running with your service you also

00:16:13,190 --> 00:16:17,510
need to understand your security needs

00:16:14,780 --> 00:16:19,430
based on the service you are running for

00:16:17,510 --> 00:16:23,960
example how is your data stored on rest

00:16:19,430 --> 00:16:25,820
as well as in transit depending on the

00:16:23,960 --> 00:16:27,650
industry you are in there might be

00:16:25,820 --> 00:16:29,690
regulations and you want to make sure

00:16:27,650 --> 00:16:33,800
that you can enable encryption ssin

00:16:29,690 --> 00:16:35,330
for both these cases lastly you also

00:16:33,800 --> 00:16:36,860
want to make sure that you can monitor

00:16:35,330 --> 00:16:39,140
the health of your storage solution and

00:16:36,860 --> 00:16:40,790
receive alerts in case of pending doom

00:16:39,140 --> 00:16:43,700
so that you can proactively take

00:16:40,790 --> 00:16:45,740
measures to avoid downtime and today

00:16:43,700 --> 00:16:47,750
with our tools like Prometheus and graph

00:16:45,740 --> 00:16:50,030
on ax there is really no X no excuse for

00:16:47,750 --> 00:16:53,300
storage solutions not to provide such

00:16:50,030 --> 00:16:54,950
integrations so I'm going to hand it

00:16:53,300 --> 00:16:57,050
back over to Nathan to talk about some

00:16:54,950 --> 00:17:02,420
of the platform security stuff that you

00:16:57,050 --> 00:17:04,310
can security within the containerization

00:17:02,420 --> 00:17:06,050
realm and security in general is a much

00:17:04,310 --> 00:17:07,520
broader and deeper topic then we'll have

00:17:06,050 --> 00:17:10,329
time to really go into today but I

00:17:07,520 --> 00:17:12,650
figured we'd just do a couple quick hits

00:17:10,329 --> 00:17:14,810
platforms there are patterns for both

00:17:12,650 --> 00:17:17,209
attacking and defending containers or

00:17:14,810 --> 00:17:19,310
evolving rapidly there are several open

00:17:17,209 --> 00:17:20,780
source software initiatives creating

00:17:19,310 --> 00:17:22,610
patterns to attempt to address the space

00:17:20,780 --> 00:17:25,220
that the bulk of the progress really has

00:17:22,610 --> 00:17:27,890
been made in the enterprise software

00:17:25,220 --> 00:17:29,750
realm there are a few things you can do

00:17:27,890 --> 00:17:31,700
today probably with relatively low cost

00:17:29,750 --> 00:17:33,860
by either deploying new tools or

00:17:31,700 --> 00:17:35,090
tweaking existing tools to take

00:17:33,860 --> 00:17:38,060
advantage of some of the security

00:17:35,090 --> 00:17:39,260
improvements we're probably most people

00:17:38,060 --> 00:17:41,270
here probably where the CI stalker

00:17:39,260 --> 00:17:42,290
benchmark I think it provides value it's

00:17:41,270 --> 00:17:44,350
one of the things that we integrate as

00:17:42,290 --> 00:17:46,310
part of CI on a very very regular basis

00:17:44,350 --> 00:17:48,650
additionally you can look at container

00:17:46,310 --> 00:17:49,470
image signing build time vulnerability

00:17:48,650 --> 00:17:52,380
scanning

00:17:49,470 --> 00:17:54,299
and compliance control enforcement and

00:17:52,380 --> 00:17:56,789
monitoring through something like in

00:17:54,299 --> 00:17:58,230
spec and test-driven development again

00:17:56,789 --> 00:18:00,030
I'm happy to talk about all these things

00:17:58,230 --> 00:18:01,830
over beers afterwards but each one of

00:18:00,030 --> 00:18:03,600
these things warrants a probably a

00:18:01,830 --> 00:18:07,320
multi-day track so we'll to skip through

00:18:03,600 --> 00:18:11,220
that a little bit quickly now to the fun

00:18:07,320 --> 00:18:12,539
part really operationalizing things at

00:18:11,220 --> 00:18:14,640
the end of the day you will always need

00:18:12,539 --> 00:18:17,760
to maintain what you build maintenance

00:18:14,640 --> 00:18:19,559
isn't compasses you know version of

00:18:17,760 --> 00:18:22,400
version upgrades major upgrades

00:18:19,559 --> 00:18:24,450
accommodating breaking changes etc

00:18:22,400 --> 00:18:27,299
cluster maintenance and upgrades have

00:18:24,450 --> 00:18:30,240
become significantly easier in the DCOs

00:18:27,299 --> 00:18:32,309
world if you've you've been using it for

00:18:30,240 --> 00:18:34,890
you know 18 months or more

00:18:32,309 --> 00:18:36,030
you know this and based off of my kind

00:18:34,890 --> 00:18:38,370
of rough understanding of the product

00:18:36,030 --> 00:18:40,470
roadmap for DCs there are some

00:18:38,370 --> 00:18:42,120
significant improvements and a 1.11 I'm

00:18:40,470 --> 00:18:44,010
sure that the people at the mesosphere

00:18:42,120 --> 00:18:48,750
booth would be happy to run you through

00:18:44,010 --> 00:18:50,909
the product roadmap on that front even

00:18:48,750 --> 00:18:52,020
with good controls and training users

00:18:50,909 --> 00:18:54,539
will still find a way to break things

00:18:52,020 --> 00:18:56,520
clock up resources and otherwise just

00:18:54,539 --> 00:18:58,710
cause havoc and cluster you know

00:18:56,520 --> 00:19:00,720
occasional jobs runaway ups and orphan

00:18:58,710 --> 00:19:02,659
tasks just happen it's the name of the

00:19:00,720 --> 00:19:06,350
game planning ahead for these issues

00:19:02,659 --> 00:19:09,450
will really make your life much easier

00:19:06,350 --> 00:19:10,799
now let's take a look at how we handle

00:19:09,450 --> 00:19:13,620
some of the challenges with

00:19:10,799 --> 00:19:17,520
externalizing services which are built

00:19:13,620 --> 00:19:20,190
and running in eCos as I kind of alluded

00:19:17,520 --> 00:19:22,770
to earlier networking is one of the more

00:19:20,190 --> 00:19:25,590
tricky areas given the additional

00:19:22,770 --> 00:19:29,159
complexity is added by network overlays

00:19:25,590 --> 00:19:30,210
see an ISDN etc clusters today are

00:19:29,159 --> 00:19:31,620
really well designed for internal

00:19:30,210 --> 00:19:34,740
traffic apps talking to apps than the

00:19:31,620 --> 00:19:36,950
cluster is a highly reliable well

00:19:34,740 --> 00:19:39,210
understood and overall pretty trivial

00:19:36,950 --> 00:19:42,090
the real challenges on our experience

00:19:39,210 --> 00:19:44,400
come from when you need to wire in to

00:19:42,090 --> 00:19:46,860
existing infrastructure and externalize

00:19:44,400 --> 00:19:48,000
the service for example do you have a

00:19:46,860 --> 00:19:52,220
knife am tool in place today in your

00:19:48,000 --> 00:19:56,730
company does it provide an API as both

00:19:52,220 --> 00:19:57,990
is easy to automate against if not do

00:19:56,730 --> 00:19:59,820
you have to adopt a new tool for your

00:19:57,990 --> 00:20:02,850
company to do IP address management or

00:19:59,820 --> 00:20:03,270
do you carve out some subset just for

00:20:02,850 --> 00:20:05,580
your

00:20:03,270 --> 00:20:07,500
containerization environment start

00:20:05,580 --> 00:20:09,540
Avenue start ad and things like IP for

00:20:07,500 --> 00:20:13,530
container this conversation becomes much

00:20:09,540 --> 00:20:14,550
more complex so in this realm as well as

00:20:13,530 --> 00:20:16,950
with service discovery and load

00:20:14,550 --> 00:20:19,770
balancing what you have in place today

00:20:16,950 --> 00:20:22,560
is going to largely inform what you do

00:20:19,770 --> 00:20:24,180
with your dcs implementation you know

00:20:22,560 --> 00:20:25,260
I'm sure we all have opinions on what

00:20:24,180 --> 00:20:27,480
you would want to do in a brown or a

00:20:25,260 --> 00:20:30,240
green field environment when it comes to

00:20:27,480 --> 00:20:33,120
load balancing service discovery etc

00:20:30,240 --> 00:20:34,710
it's my experience that I haven't been

00:20:33,120 --> 00:20:37,080
particularly lucky as a consultant and

00:20:34,710 --> 00:20:38,610
the ability to just start from a green

00:20:37,080 --> 00:20:40,050
field if you have those projects going

00:20:38,610 --> 00:20:41,910
that's really cool they'd love to talk

00:20:40,050 --> 00:20:44,730
to you about those and hear what your

00:20:41,910 --> 00:20:46,080
thoughts are but again for me the name

00:20:44,730 --> 00:20:48,540
of the game here is really how do we

00:20:46,080 --> 00:20:51,150
integrate into existing environments and

00:20:48,540 --> 00:20:53,400
then move stateful services that are

00:20:51,150 --> 00:20:55,680
today running on either bare metal or in

00:20:53,400 --> 00:20:59,220
a virtualized environment into

00:20:55,680 --> 00:21:00,900
containers so last but certainly not

00:20:59,220 --> 00:21:03,930
least let's talk about organizational

00:21:00,900 --> 00:21:05,520
and as I've alluded to I actually

00:21:03,930 --> 00:21:06,810
believe that this is kind of the the

00:21:05,520 --> 00:21:08,580
chief metric on whether or not you're

00:21:06,810 --> 00:21:10,370
going to be successful in your DCOs

00:21:08,580 --> 00:21:13,950
implementation and I would say

00:21:10,370 --> 00:21:15,510
containerization in general the team who

00:21:13,950 --> 00:21:17,430
leads the internal container initiative

00:21:15,510 --> 00:21:20,640
really will define its success or lack

00:21:17,430 --> 00:21:22,440
thereof they it's our experience that

00:21:20,640 --> 00:21:24,720
they need to bring themselves their

00:21:22,440 --> 00:21:27,120
peers in in the internal developer

00:21:24,720 --> 00:21:29,640
community up to speed on all these new

00:21:27,120 --> 00:21:30,840
technologies patterns etc I'm pretty

00:21:29,640 --> 00:21:36,300
much in parallel and that's a pretty

00:21:30,840 --> 00:21:38,880
difficult task as such one of the ways

00:21:36,300 --> 00:21:41,100
to kind of ease the burden here is to

00:21:38,880 --> 00:21:43,500
engage people early probably your

00:21:41,100 --> 00:21:44,670
developer community first off and really

00:21:43,500 --> 00:21:46,710
get to understand what their

00:21:44,670 --> 00:21:48,330
requirements are at the end of the day

00:21:46,710 --> 00:21:50,460
you're building a platform for services

00:21:48,330 --> 00:21:52,350
and if you're not providing services

00:21:50,460 --> 00:21:53,490
which are consumable or of interest to

00:21:52,350 --> 00:21:56,610
the people whole building software on

00:21:53,490 --> 00:21:58,200
top of that what are you doing it for so

00:21:56,610 --> 00:21:59,400
I'm a strong proponent of kind of

00:21:58,200 --> 00:22:00,540
thinking of this as a software project

00:21:59,400 --> 00:22:03,540
more so than a traditional

00:22:00,540 --> 00:22:05,220
infrastructure project I always handle

00:22:03,540 --> 00:22:07,380
this in an agile fashion do some

00:22:05,220 --> 00:22:09,270
requirements gathering work very rapidly

00:22:07,380 --> 00:22:12,690
and iteratively to provide value as

00:22:09,270 --> 00:22:14,700
quickly as possible that way assuming

00:22:12,690 --> 00:22:16,680
they have a good experience assuming the

00:22:14,700 --> 00:22:17,080
platform's available and resilient and

00:22:16,680 --> 00:22:18,580
provides

00:22:17,080 --> 00:22:20,440
services that people are interested in

00:22:18,580 --> 00:22:22,450
their typical to use it and then once

00:22:20,440 --> 00:22:24,700
you have adoption hopefully you can turn

00:22:22,450 --> 00:22:28,060
those people into evangelists to turn

00:22:24,700 --> 00:22:30,990
other people into your community on to

00:22:28,060 --> 00:22:34,510
the platform you're now providing it's

00:22:30,990 --> 00:22:36,940
too often I certainly see a small-scale

00:22:34,510 --> 00:22:38,590
implementation that doesn't really look

00:22:36,940 --> 00:22:40,290
at what they're trying to service and

00:22:38,590 --> 00:22:42,760
they don't get adoption and wonder why

00:22:40,290 --> 00:22:43,960
you know it's not one of the things that

00:22:42,760 --> 00:22:45,850
if you build it they will come

00:22:43,960 --> 00:22:49,030
it's if you make it easy to use and

00:22:45,850 --> 00:22:50,530
attractive they might use it but

00:22:49,030 --> 00:22:52,420
certainly if you just make it difficult

00:22:50,530 --> 00:22:57,330
to use or are not providing any value

00:22:52,420 --> 00:22:59,830
they're not going to engage with you as

00:22:57,330 --> 00:23:01,710
the nest touched on there are a number

00:22:59,830 --> 00:23:04,270
of guardrails that do need to be built

00:23:01,710 --> 00:23:08,020
especially when it comes to reasoning

00:23:04,270 --> 00:23:10,810
about data services guardrails in

00:23:08,020 --> 00:23:12,640
general at the end of the day there are

00:23:10,810 --> 00:23:13,960
Dave data sovereignty laws which can be

00:23:12,640 --> 00:23:15,430
as granular as a local level but

00:23:13,960 --> 00:23:20,320
certainly at a state and national level

00:23:15,430 --> 00:23:22,930
exists as Dinesh pointed out that can be

00:23:20,320 --> 00:23:25,330
something as simple as encryption or if

00:23:22,930 --> 00:23:27,910
you are in a multi region implementation

00:23:25,330 --> 00:23:30,160
and accidentally decide or purposefully

00:23:27,910 --> 00:23:32,050
decide to replicate personally

00:23:30,160 --> 00:23:33,190
identifiable information for example out

00:23:32,050 --> 00:23:34,630
of the European Union to the United

00:23:33,190 --> 00:23:37,930
States or vice versa

00:23:34,630 --> 00:23:39,850
you have now really gone off the rails

00:23:37,930 --> 00:23:41,410
and your internal controls and clients

00:23:39,850 --> 00:23:43,960
organization is not going to be happy

00:23:41,410 --> 00:23:45,040
with you unfortunately it's kind of

00:23:43,960 --> 00:23:46,630
trivially easy to do that from a

00:23:45,040 --> 00:23:49,570
technology perspective and it can have

00:23:46,630 --> 00:23:51,820
huge ramifications on your company from

00:23:49,570 --> 00:23:53,110
a legal perspective it's not not a great

00:23:51,820 --> 00:23:55,690
conversation anyone wants to have with

00:23:53,110 --> 00:23:59,320
your CIO or your internal legal general

00:23:55,690 --> 00:24:01,300
counsel so look at internal controls on

00:23:59,320 --> 00:24:03,550
how engage with your internal controls

00:24:01,300 --> 00:24:06,550
group to see what you can do what you

00:24:03,550 --> 00:24:08,470
should be doing additionally be mindful

00:24:06,550 --> 00:24:09,760
of any industry specific controls right

00:24:08,470 --> 00:24:12,820
in the United States we have HIPPA

00:24:09,760 --> 00:24:14,680
for health care we have saw a number of

00:24:12,820 --> 00:24:16,360
things and they reason about what we

00:24:14,680 --> 00:24:18,670
need to do what our responsibilities are

00:24:16,360 --> 00:24:20,770
and regardless of the platform that

00:24:18,670 --> 00:24:21,820
we're delivering our services upon it is

00:24:20,770 --> 00:24:24,910
our responsibility to do that

00:24:21,820 --> 00:24:27,400
so at the end of the day have some

00:24:24,910 --> 00:24:30,640
conversations stay in compliance

00:24:27,400 --> 00:24:33,740
make everybody's lives easier

00:24:30,640 --> 00:24:35,690
on the skill set area there are some

00:24:33,740 --> 00:24:38,240
ways to just engender growth in adoption

00:24:35,690 --> 00:24:40,220
right first and foremost

00:24:38,240 --> 00:24:41,539
hopefully if you have to do some

00:24:40,220 --> 00:24:43,039
external recruiting find some

00:24:41,539 --> 00:24:44,210
experienced engineers who have you know

00:24:43,039 --> 00:24:46,250
run through this or worked in the

00:24:44,210 --> 00:24:48,110
platform they will be a great asset to

00:24:46,250 --> 00:24:49,760
you if you don't have that not a problem

00:24:48,110 --> 00:24:52,429
there's a wide community right there's

00:24:49,760 --> 00:24:53,750
slot channels and github and a million

00:24:52,429 --> 00:24:55,730
places conferences like your right now

00:24:53,750 --> 00:24:57,549
to really find people engage with and

00:24:55,730 --> 00:25:00,320
learn from them

00:24:57,549 --> 00:25:01,640
additionally especially early on I'm a

00:25:00,320 --> 00:25:03,740
big fan of creating an operational

00:25:01,640 --> 00:25:05,000
playground both for the platform

00:25:03,740 --> 00:25:07,280
engineering side as well as the

00:25:05,000 --> 00:25:09,770
developer side it's my experience that I

00:25:07,280 --> 00:25:12,789
need to be able to figure out a break

00:25:09,770 --> 00:25:15,530
cluster great clusters unintentionally

00:25:12,789 --> 00:25:17,179
rapidly iterate on automation to rebuild

00:25:15,530 --> 00:25:18,950
things and if I'm doing that while

00:25:17,179 --> 00:25:19,760
developers are attempting to learn how

00:25:18,950 --> 00:25:21,679
to use the platform

00:25:19,760 --> 00:25:24,200
I'm negatively impacting their

00:25:21,679 --> 00:25:26,690
experience so if you have enough compute

00:25:24,200 --> 00:25:28,730
resources available just give yourself

00:25:26,690 --> 00:25:29,870
your own playground give dev their own

00:25:28,730 --> 00:25:30,980
playground and eventually you can

00:25:29,870 --> 00:25:32,360
probably get to the point where you're

00:25:30,980 --> 00:25:33,919
mature enough that you can consolidate

00:25:32,360 --> 00:25:34,870
those things but off the break I would

00:25:33,919 --> 00:25:39,380
definitely start there

00:25:34,870 --> 00:25:40,909
additionally just general notes from

00:25:39,380 --> 00:25:42,530
agile write fail fast and fail often

00:25:40,909 --> 00:25:45,110
it's totally okay right we this is a

00:25:42,530 --> 00:25:47,120
learning experience for many of us and

00:25:45,110 --> 00:25:48,350
finally if you want to make this more

00:25:47,120 --> 00:25:50,390
attractive and you know drive some

00:25:48,350 --> 00:25:52,549
internal adoption set up a half-day

00:25:50,390 --> 00:25:56,990
figure out what makes sense what

00:25:52,549 --> 00:26:01,909
problems are you trying to face so now

00:25:56,990 --> 00:26:03,110
you have a great way to help on a great

00:26:01,909 --> 00:26:05,600
way to help on all these fronts is to

00:26:03,110 --> 00:26:07,490
focus on training after you've found

00:26:05,600 --> 00:26:09,679
some internal advocates and Vangelis who

00:26:07,490 --> 00:26:11,720
are familiar and can drive excitement

00:26:09,679 --> 00:26:13,820
within your organization and once you

00:26:11,720 --> 00:26:15,919
have a base level engagement couple with

00:26:13,820 --> 00:26:17,090
providing developers and in developers

00:26:15,919 --> 00:26:18,710
and engineers with environments where

00:26:17,090 --> 00:26:20,179
they can learn you should be able to

00:26:18,710 --> 00:26:22,909
rapidly iterate an experiment to drive

00:26:20,179 --> 00:26:24,440
adoption around somewhere in this point

00:26:22,909 --> 00:26:26,030
I would suggest investing in formalized

00:26:24,440 --> 00:26:27,320
training and then use that experience of

00:26:26,030 --> 00:26:29,990
formalized training to build training

00:26:27,320 --> 00:26:33,200
that actually matters to you at the end

00:26:29,990 --> 00:26:35,030
of the day stateful services is a very

00:26:33,200 --> 00:26:36,289
expanding field so what makes sense for

00:26:35,030 --> 00:26:38,150
a company looking at implementing

00:26:36,289 --> 00:26:39,950
Cassandra versus something else might

00:26:38,150 --> 00:26:41,840
not be the same really fine fine what

00:26:39,950 --> 00:26:43,690
the how to bring up the skill sets that

00:26:41,840 --> 00:26:46,519
are applicable to your organization

00:26:43,690 --> 00:26:47,929
at the end of the day running stateful

00:26:46,519 --> 00:26:49,519
services and containers is not trivial

00:26:47,929 --> 00:26:51,559
DCOs import works are making it

00:26:49,519 --> 00:26:53,330
significantly easier but it still

00:26:51,559 --> 00:26:55,730
requires expertise and a wide range of

00:26:53,330 --> 00:26:57,769
areas successfully do that and finding

00:26:55,730 --> 00:26:59,360
experienced advocates and evangelists

00:26:57,769 --> 00:27:01,100
and your organization will really help

00:26:59,360 --> 00:27:02,690
so by pulling all these things together

00:27:01,100 --> 00:27:04,190
you should find that you're fostering

00:27:02,690 --> 00:27:07,039
the right skills to make your platform

00:27:04,190 --> 00:27:08,840
attractive and available and eventually

00:27:07,039 --> 00:27:12,379
or hopefully soon getting to production

00:27:08,840 --> 00:27:22,970
level services so with that we're pretty

00:27:12,379 --> 00:27:23,640
much done any questions ok thank you

00:27:22,970 --> 00:27:27,359
very much

00:27:23,640 --> 00:27:27,359

YouTube URL: https://www.youtube.com/watch?v=kxh2FJ6aTAM


