Title: DataStax Enterprise on DC OS - Yes, It’s Possible; Customer Case Studies - Ravi Yadav
Publication date: 2017-10-27
Playlist: MesosCon Europe 2017
Description: 
	DataStax Enterprise on DC/OS - Yes, It’s Possible; Customer Case Studies - Ravi Yadav, Mesosphere, Inc. & Chris Splinter, Datastax

Migrating a database to a containerized infrastructure brings with it a whole host of challenging new issues. Concerns range from persistence management, availability requirements, and complicated recovery semantics. If you’re considering migrating a database to containers in the future, this talk should enlighten the path.

We will walk you through the current state of the DataStax Enterprise framework. We'll explore the details of the integration between DSE and DC/OS and cover tradeoffs between different deployment options. We’ll tell the real story of the evolution of this framework. In doing so we’ll discuss how our initial design decisions conflicted with customer expectations and how we worked through these and other engineering feats to get to the offering we have today. We'll then tell a few customer deployment stories and conclude with a demo of DSE on DC/OS.

About Chris Splinter
Chris Splinter has been with DataStax for 4 years. He currently works on the Partner Engineering team but also works closely improving QA processes with guidance from some of our most important customers. Chris is a sports enthusiast who played football at Harvard while dabbling in Computer Science during his spare time.

About Ravi Yadav
Ravi Yadav is responsible for platform partnerships and ecosystem development at Mesosphere. Prior to this, he was a Developer Advocate at IBM and worked on IBM Watson partnerships and advocacy. In his past life, he worked on developing drivers for medical devices.
Captions: 
	00:00:00,060 --> 00:00:04,110
it's good to see you guys and it's good

00:00:01,829 --> 00:00:06,960
to be here in frog I'm coming all the

00:00:04,110 --> 00:00:11,040
way from Chicago so a bit of a long

00:00:06,960 --> 00:00:12,900
flight but it's good to be here my name

00:00:11,040 --> 00:00:16,770
is Chris winter and I'm a product

00:00:12,900 --> 00:00:20,430
manager at data stacks yeah guys just

00:00:16,770 --> 00:00:21,779
come on in and today I'm going to be

00:00:20,430 --> 00:00:23,990
talking a bit about the data sacks

00:00:21,779 --> 00:00:27,210
enterprise integration on DCOs

00:00:23,990 --> 00:00:30,510
and specifically we're going to talk

00:00:27,210 --> 00:00:33,090
about why production quality stateful

00:00:30,510 --> 00:00:35,130
services are hard we're going to talk a

00:00:33,090 --> 00:00:37,559
bit about the evolution of the framework

00:00:35,130 --> 00:00:40,379
how we went from Ground Zero to where

00:00:37,559 --> 00:00:43,110
we're at today and then I'll go through

00:00:40,379 --> 00:00:44,610
the current state of the project show

00:00:43,110 --> 00:00:48,210
you the couple tiles that we have on the

00:00:44,610 --> 00:00:50,250
DC OS universe today and then we'll talk

00:00:48,210 --> 00:00:52,590
about some custard customer deployments

00:00:50,250 --> 00:00:55,260
how they're getting bit real business

00:00:52,590 --> 00:00:57,329
value out of this service and then

00:00:55,260 --> 00:01:01,199
finally we will conclude with a couple

00:00:57,329 --> 00:01:05,040
demos just to show you guys how this

00:01:01,199 --> 00:01:06,630
integration is working today so I want

00:01:05,040 --> 00:01:09,990
to start off real quick just by giving

00:01:06,630 --> 00:01:11,580
an overview of what data stacks is to

00:01:09,990 --> 00:01:16,340
try to provide some context for the

00:01:11,580 --> 00:01:20,640
integration and so it's a peer-to-peer

00:01:16,340 --> 00:01:23,280
no SQL database at the core is Cassandra

00:01:20,640 --> 00:01:25,740
and we build in enterprise features such

00:01:23,280 --> 00:01:28,490
as search graph analytics and we add

00:01:25,740 --> 00:01:31,259
some security on top of it as well

00:01:28,490 --> 00:01:33,509
we see a lot of personalization customer

00:01:31,259 --> 00:01:37,290
360 apps built with it

00:01:33,509 --> 00:01:41,640
messaging programs we get a lot of

00:01:37,290 --> 00:01:43,079
sensor data IOT stuff and then fraud

00:01:41,640 --> 00:01:45,390
detection is a big thing with our

00:01:43,079 --> 00:01:46,950
analytics and graph features and then

00:01:45,390 --> 00:01:52,140
interestingly enough we see it being

00:01:46,950 --> 00:01:54,869
used for playlists as well so now I'm

00:01:52,140 --> 00:01:56,729
going to go into really what goes into

00:01:54,869 --> 00:01:58,920
developing these production quality

00:01:56,729 --> 00:02:00,719
stateful services and some of the

00:01:58,920 --> 00:02:06,180
technical challenges behind just the

00:02:00,719 --> 00:02:07,500
complexities that are involved so first

00:02:06,180 --> 00:02:09,989
I'm going to start with some terminology

00:02:07,500 --> 00:02:12,050
and this is specific to Cassandra and

00:02:09,989 --> 00:02:14,390
David Sachs Enterprise

00:02:12,050 --> 00:02:18,020
a node is a single instance so a single

00:02:14,390 --> 00:02:20,720
unit of DSE and these are these make up

00:02:18,020 --> 00:02:23,300
data centers and the data centers can be

00:02:20,720 --> 00:02:26,120
either logical data centers or physical

00:02:23,300 --> 00:02:28,370
data centers in Cassandra the way it

00:02:26,120 --> 00:02:31,160
works is it replicates your data based

00:02:28,370 --> 00:02:32,600
upon a snitch and you can configure how

00:02:31,160 --> 00:02:35,450
many replicas you want in each one of

00:02:32,600 --> 00:02:38,270
your data centers and the largest unit

00:02:35,450 --> 00:02:41,270
of work is a cluster and the data

00:02:38,270 --> 00:02:42,830
centers add up to this larger cluster

00:02:41,270 --> 00:02:45,350
and you can have several data centers in

00:02:42,830 --> 00:02:47,810
a single cluster and in a world where

00:02:45,350 --> 00:02:49,930
data autonomy is becoming more and more

00:02:47,810 --> 00:02:52,640
important it's important to be able to

00:02:49,930 --> 00:02:55,790
deploy these clusters either on-premise

00:02:52,640 --> 00:02:57,470
or in the cloud and this is going to be

00:02:55,790 --> 00:03:02,090
a big piece of our DC OS integration

00:02:57,470 --> 00:03:04,220
that I'll go into a bit more later so

00:03:02,090 --> 00:03:05,930
the next thing is the gossip protocol

00:03:04,220 --> 00:03:08,900
and this is kind of what makes it all

00:03:05,930 --> 00:03:10,100
work it's a this is what makes it

00:03:08,900 --> 00:03:12,260
peer-to-peer and these nodes are

00:03:10,100 --> 00:03:15,290
constantly talking and they exchange

00:03:12,260 --> 00:03:17,709
these messages every second and in these

00:03:15,290 --> 00:03:20,570
messages are the health of the nodes

00:03:17,709 --> 00:03:22,190
whether they're up or down where they're

00:03:20,570 --> 00:03:23,860
located and this is really how the

00:03:22,190 --> 00:03:26,120
different nodes learn about each other

00:03:23,860 --> 00:03:27,530
and they're all communicating to each

00:03:26,120 --> 00:03:30,410
other it's not just a one-to-one

00:03:27,530 --> 00:03:32,870
relationship and based upon this

00:03:30,410 --> 00:03:35,390
communication this is how the different

00:03:32,870 --> 00:03:37,940
requests are routed so if all of a

00:03:35,390 --> 00:03:39,470
sudden one node gets very slow the

00:03:37,940 --> 00:03:42,110
cluster knows that it'll start steering

00:03:39,470 --> 00:03:44,810
a request around that slow node in order

00:03:42,110 --> 00:03:50,420
to keep the different SL A's and Layton

00:03:44,810 --> 00:03:52,330
sees in a good state the next thing I

00:03:50,420 --> 00:03:55,340
want to touch on here is the right path

00:03:52,330 --> 00:03:57,620
so when a request comes in its first

00:03:55,340 --> 00:04:02,690
written to a commit log which is just a

00:03:57,620 --> 00:04:06,170
sequential log based format on disk and

00:04:02,690 --> 00:04:08,930
then it goes to the mem table where it's

00:04:06,170 --> 00:04:12,500
stored in memory and once this mem table

00:04:08,930 --> 00:04:15,920
fills up it'll be flush to disk and when

00:04:12,500 --> 00:04:17,950
it's on disk compaction runs and this

00:04:15,920 --> 00:04:21,049
will load the data back up into memory

00:04:17,950 --> 00:04:23,900
sort it and then write it back into disk

00:04:21,049 --> 00:04:25,520
in these immutable SS tables and this is

00:04:23,900 --> 00:04:27,949
all important because

00:04:25,520 --> 00:04:29,720
the integration with DCOs one of the

00:04:27,949 --> 00:04:32,090
features that we'll provide is node

00:04:29,720 --> 00:04:34,370
recovery so it's very important for

00:04:32,090 --> 00:04:35,990
these different data directories to be

00:04:34,370 --> 00:04:37,699
able to be stored locally with the

00:04:35,990 --> 00:04:43,400
possibility of them being attached later

00:04:37,699 --> 00:04:46,479
on so the next thing I'm gonna touch on

00:04:43,400 --> 00:04:49,840
is the configuration management there's

00:04:46,479 --> 00:04:53,300
more than 30 configuration files in DSC

00:04:49,840 --> 00:04:55,909
so there's a lot to keep track of if

00:04:53,300 --> 00:04:58,370
you're trying to do this all by hand and

00:04:55,909 --> 00:05:01,389
depending on your workload you can have

00:04:58,370 --> 00:05:03,470
upwards of a thousand different settings

00:05:01,389 --> 00:05:06,139
and especially when you're making

00:05:03,470 --> 00:05:09,680
changes in production which changes are

00:05:06,139 --> 00:05:10,819
likely it can be very hard to keep track

00:05:09,680 --> 00:05:14,090
of if you're trying to do that all

00:05:10,819 --> 00:05:15,979
manually and specifically here in the

00:05:14,090 --> 00:05:18,319
Cassandra yamo file there's more than

00:05:15,979 --> 00:05:23,840
1,000 settings and then the DSC amyl

00:05:18,319 --> 00:05:25,370
there's a comparable amount as well so I

00:05:23,840 --> 00:05:28,009
described all these things to get to the

00:05:25,370 --> 00:05:31,580
point that stateful services are hard

00:05:28,009 --> 00:05:34,250
and managing deploying configuring

00:05:31,580 --> 00:05:37,310
stateful services are hard as well but

00:05:34,250 --> 00:05:40,479
this is where the DC OS SDK really comes

00:05:37,310 --> 00:05:45,440
in and adds value to the data stacks

00:05:40,479 --> 00:05:46,610
deployment it can do things like manage

00:05:45,440 --> 00:05:50,150
your deployment like I said before

00:05:46,610 --> 00:05:51,919
either on-premise or in the cloud it can

00:05:50,150 --> 00:05:53,810
perform maintenance for these stateful

00:05:51,919 --> 00:05:56,199
services automatically if a node goes

00:05:53,810 --> 00:05:58,039
down we can try to bring it back up

00:05:56,199 --> 00:06:00,289
automatically up to a certain point

00:05:58,039 --> 00:06:03,919
until we deem it down and that it will

00:06:00,289 --> 00:06:05,750
need manual intervention it can also do

00:06:03,919 --> 00:06:08,990
things like packet restore configuration

00:06:05,750 --> 00:06:12,349
in it each one of these pieces we

00:06:08,990 --> 00:06:15,139
configure the data stack scheduler to do

00:06:12,349 --> 00:06:19,969
it specific to the DSC tasks that I just

00:06:15,139 --> 00:06:24,259
described so the core this is DCOs

00:06:19,969 --> 00:06:27,380
commons it's the open source library to

00:06:24,259 --> 00:06:31,759
manage these sorts of deployment and

00:06:27,380 --> 00:06:33,710
configuration strategies and it makes

00:06:31,759 --> 00:06:35,479
things really convenient when you're

00:06:33,710 --> 00:06:37,729
operating in this distributed

00:06:35,479 --> 00:06:39,000
environment or you want to deploy micro

00:06:37,729 --> 00:06:41,280
services in a unified

00:06:39,000 --> 00:06:45,390
in fashion and makes this sort of thing

00:06:41,280 --> 00:06:49,140
very very easy and more doable than

00:06:45,390 --> 00:06:50,520
having to do it all manually and it

00:06:49,140 --> 00:06:52,980
accomplishes these tasks to a

00:06:50,520 --> 00:06:56,850
declarative goal-oriented approach and

00:06:52,980 --> 00:06:59,250
to show you a little example of that I

00:06:56,850 --> 00:07:00,420
have this goal oriented design here

00:06:59,250 --> 00:07:02,250
where it's really operating with two

00:07:00,420 --> 00:07:05,670
states the current state and the target

00:07:02,250 --> 00:07:08,640
state so in this example if we're

00:07:05,670 --> 00:07:12,030
starting with CPU two and memory for

00:07:08,640 --> 00:07:15,120
gigs and we want to get to having CPU 1

00:07:12,030 --> 00:07:18,780
and memory 8 gigs first a scheduler

00:07:15,120 --> 00:07:21,360
knows to unreserve 1 CPU and reserve an

00:07:18,780 --> 00:07:23,669
additional an additional 4 gigs of

00:07:21,360 --> 00:07:26,160
memory and then it will communicate with

00:07:23,669 --> 00:07:29,370
the DAC scheduler to launch a new node

00:07:26,160 --> 00:07:32,850
with the configuration value specific to

00:07:29,370 --> 00:07:38,190
DSC that will achieve this target goal

00:07:32,850 --> 00:07:40,110
here so now I want to talk more

00:07:38,190 --> 00:07:42,560
specifically about the integration of

00:07:40,110 --> 00:07:46,850
these two things and how we went from

00:07:42,560 --> 00:07:51,470
having nothing to where we're at today

00:07:46,850 --> 00:07:53,760
so as I'm sure you guys may know

00:07:51,470 --> 00:07:56,340
engineering resources can be strapped

00:07:53,760 --> 00:07:57,900
sometimes and the number of customers

00:07:56,340 --> 00:08:00,810
that you need to serve and the needs

00:07:57,900 --> 00:08:02,100
that you need to serve outnumber that of

00:08:00,810 --> 00:08:05,070
what you have so you need to be smart

00:08:02,100 --> 00:08:07,890
with your design so in version 1 we were

00:08:05,070 --> 00:08:09,390
really looking to go low touch and make

00:08:07,890 --> 00:08:14,150
something that would be easy to develop

00:08:09,390 --> 00:08:16,710
and easy to customize and expand upon

00:08:14,150 --> 00:08:21,180
and we wanted all this to be just in a

00:08:16,710 --> 00:08:23,010
single universe package on DCOs and the

00:08:21,180 --> 00:08:24,990
outcome of this though we thought hey

00:08:23,010 --> 00:08:26,760
this is great like we can give it to

00:08:24,990 --> 00:08:28,830
anybody and anybody can use it how they

00:08:26,760 --> 00:08:32,520
want we found out that customers

00:08:28,830 --> 00:08:34,320
actually wanted it all in front for them

00:08:32,520 --> 00:08:40,169
and they didn't necessarily want to just

00:08:34,320 --> 00:08:43,229
build it up and extend it themselves so

00:08:40,169 --> 00:08:46,950
that brought us to version 2 and I have

00:08:43,229 --> 00:08:49,260
this they give them the plain phrase up

00:08:46,950 --> 00:08:51,240
there because DC can really be like a

00:08:49,260 --> 00:08:52,920
control panel of a plane where there's a

00:08:51,240 --> 00:08:55,230
million different knobs and switches

00:08:52,920 --> 00:08:58,560
that you want to turn and these

00:08:55,230 --> 00:09:01,350
customers wanted the ability to turn all

00:08:58,560 --> 00:09:04,050
of them from this interface on DCOs

00:09:01,350 --> 00:09:06,149
and we really just needed a tighter

00:09:04,050 --> 00:09:09,839
integration than what we had in version

00:09:06,149 --> 00:09:11,670
one so the first step was to dedicate a

00:09:09,839 --> 00:09:14,100
data stacks engineering team to this

00:09:11,670 --> 00:09:17,220
effort where we can provide the data

00:09:14,100 --> 00:09:20,070
stacks expertise needed to make the

00:09:17,220 --> 00:09:23,850
integration flow much more naturally and

00:09:20,070 --> 00:09:26,339
to build DC specific resilient factors

00:09:23,850 --> 00:09:30,060
into the platform and into the

00:09:26,339 --> 00:09:32,610
integration so we were working hand in

00:09:30,060 --> 00:09:34,310
hand with mesosphere on this and at

00:09:32,610 --> 00:09:37,440
first we were meeting every single day

00:09:34,310 --> 00:09:39,600
and then that eventually turned into a

00:09:37,440 --> 00:09:41,250
few times a week and now it's pretty

00:09:39,600 --> 00:09:43,079
much just as needed now that the

00:09:41,250 --> 00:09:47,220
integration is more stable and the

00:09:43,079 --> 00:09:50,430
foundation is there we really baited the

00:09:47,220 --> 00:09:53,699
heck out of this thing I think we went

00:09:50,430 --> 00:09:56,550
through five different betas before we

00:09:53,699 --> 00:09:58,140
went to GA so we had a pretty tight

00:09:56,550 --> 00:10:01,199
feedback loop with the customers that

00:09:58,140 --> 00:10:04,380
were trying this out so they really let

00:10:01,199 --> 00:10:05,970
us know exactly what they wanted and it

00:10:04,380 --> 00:10:09,029
tailored our design and we were able to

00:10:05,970 --> 00:10:13,170
fulfill those requests for them

00:10:09,029 --> 00:10:16,440
and finally the joint support agreements

00:10:13,170 --> 00:10:19,230
was something that was definitely needed

00:10:16,440 --> 00:10:21,570
because with a platform like this when

00:10:19,230 --> 00:10:23,130
the integration is so tight you don't

00:10:21,570 --> 00:10:25,019
necessarily know as a customer okay I

00:10:23,130 --> 00:10:27,779
just have this error but you don't know

00:10:25,019 --> 00:10:30,149
whether it's coming from DSC or whether

00:10:27,779 --> 00:10:31,320
it's coming from DC OS so we had to set

00:10:30,149 --> 00:10:33,300
up a system where customers could

00:10:31,320 --> 00:10:36,269
contact us and go through either channel

00:10:33,300 --> 00:10:38,279
and then we would then take that request

00:10:36,269 --> 00:10:40,949
and go from there based upon whether it

00:10:38,279 --> 00:10:45,149
was a DC OS bug or whether it was

00:10:40,949 --> 00:10:47,010
specific to data stacks enterprise and

00:10:45,149 --> 00:10:50,160
the outcome of this version two was that

00:10:47,010 --> 00:10:51,500
we were definitely better together like

00:10:50,160 --> 00:10:53,910
I said before with all these

00:10:51,500 --> 00:10:56,220
configuration files and all these

00:10:53,910 --> 00:10:59,790
different knobs to turn that's a that's

00:10:56,220 --> 00:11:03,240
a very difficult task to do manually so

00:10:59,790 --> 00:11:05,459
DC OS gives us the ability to have all

00:11:03,240 --> 00:11:07,590
these things in a standard format we you

00:11:05,459 --> 00:11:10,680
can fill it out as I'll show you

00:11:07,590 --> 00:11:14,360
in the GUI itself and check off boxes

00:11:10,680 --> 00:11:17,190
for what you want to deploy in a big

00:11:14,360 --> 00:11:19,620
advantage of this too is that it you can

00:11:17,190 --> 00:11:23,790
roll back these changes so let's say

00:11:19,620 --> 00:11:25,920
that you are a retail company and Black

00:11:23,790 --> 00:11:28,700
Friday is coming up and you know that

00:11:25,920 --> 00:11:31,200
you have your certain performance

00:11:28,700 --> 00:11:34,290
configuration for these increased

00:11:31,200 --> 00:11:36,000
traffic times DCOs makes it very

00:11:34,290 --> 00:11:39,029
convenient to be able to roll out these

00:11:36,000 --> 00:11:41,880
changes for these higher traffic times

00:11:39,029 --> 00:11:46,470
which is a very very useful feature of

00:11:41,880 --> 00:11:48,570
the integration and the next bullet I

00:11:46,470 --> 00:11:52,589
have here is the automated vertical and

00:11:48,570 --> 00:11:55,110
horizontal horizontal scaling users of

00:11:52,589 --> 00:11:58,890
Cassandra and DSC are very used to this

00:11:55,110 --> 00:12:00,450
ability to scale horizontally if you

00:11:58,890 --> 00:12:02,810
need more throughput you can just add

00:12:00,450 --> 00:12:05,940
more nodes and it will scale linearly

00:12:02,810 --> 00:12:08,339
but DCOs gives us the ability to also

00:12:05,940 --> 00:12:10,980
scale vertically so in the cases where

00:12:08,339 --> 00:12:14,070
you might be restricted to the number of

00:12:10,980 --> 00:12:16,470
nodes you have but they might have the

00:12:14,070 --> 00:12:18,839
ability to use more resources DCOs can

00:12:16,470 --> 00:12:20,580
allocate those for you so now with this

00:12:18,839 --> 00:12:25,880
integration you can scale both

00:12:20,580 --> 00:12:28,320
vertically and horizontally and finally

00:12:25,880 --> 00:12:31,770
the other big advantage that we've seen

00:12:28,320 --> 00:12:35,310
is the uniform deployment of these

00:12:31,770 --> 00:12:37,770
enterprise applications we have a few

00:12:35,310 --> 00:12:40,200
customers who are using this to do

00:12:37,770 --> 00:12:42,570
things like platform as a service and

00:12:40,200 --> 00:12:45,650
also micro services so when you need to

00:12:42,570 --> 00:12:49,350
deploy things uniformly and efficiently

00:12:45,650 --> 00:12:53,030
having the click of a button in DCOs has

00:12:49,350 --> 00:12:53,030
been a real advantage those customers

00:12:53,180 --> 00:12:58,020
all right so now we'll touch on the

00:12:56,490 --> 00:13:00,150
current state of the project and what it

00:12:58,020 --> 00:13:04,650
actually looks like in the DC OS

00:13:00,150 --> 00:13:07,560
universe we have these two tiles the

00:13:04,650 --> 00:13:13,070
first is data stacks DSC and data stacks

00:13:07,560 --> 00:13:18,120
ops the data stacks DSC tile is the

00:13:13,070 --> 00:13:20,670
actual data stack server so through this

00:13:18,120 --> 00:13:22,500
panel here you can just click config

00:13:20,670 --> 00:13:23,970
you configure everything that you want

00:13:22,500 --> 00:13:26,450
and then hit deploy and I'll go through

00:13:23,970 --> 00:13:29,070
an example of that in a bit here and

00:13:26,450 --> 00:13:32,580
then the second panel is data stacks ops

00:13:29,070 --> 00:13:36,420
and that is our ops center product which

00:13:32,580 --> 00:13:39,000
provides the ability to get more of a

00:13:36,420 --> 00:13:42,120
view towards the JMX metrics that DSC

00:13:39,000 --> 00:13:44,940
produces as well as it lets you do

00:13:42,120 --> 00:13:47,370
things like backup and restore scheduled

00:13:44,940 --> 00:13:50,490
repair services and things like that so

00:13:47,370 --> 00:13:56,790
we provide both of these products on the

00:13:50,490 --> 00:14:00,180
DC OS universe so in this most recent

00:13:56,790 --> 00:14:02,310
version we have full platform support so

00:14:00,180 --> 00:14:03,870
that means that we support the data

00:14:02,310 --> 00:14:08,640
center price features like advanced

00:14:03,870 --> 00:14:10,110
replication search graph analytics as

00:14:08,640 --> 00:14:15,240
well as some of our advanced security

00:14:10,110 --> 00:14:17,880
features we have no placement and no

00:14:15,240 --> 00:14:19,530
task failure recovery I touched on this

00:14:17,880 --> 00:14:23,280
briefly before but essentially what that

00:14:19,530 --> 00:14:25,500
means is if DCOs senses that this node

00:14:23,280 --> 00:14:28,440
has gone down it will try to start it

00:14:25,500 --> 00:14:30,030
back up automatically until it'll will

00:14:28,440 --> 00:14:32,850
eventually give up because sometimes it

00:14:30,030 --> 00:14:34,560
does require manual intervention but

00:14:32,850 --> 00:14:37,680
this is good because it does add some

00:14:34,560 --> 00:14:40,740
resiliency to these distributed systems

00:14:37,680 --> 00:14:44,040
where the failures can happen really all

00:14:40,740 --> 00:14:45,660
over the place the next thing that we

00:14:44,040 --> 00:14:49,310
support is strict mode support this

00:14:45,660 --> 00:14:52,320
allows you to run on air-gap networks

00:14:49,310 --> 00:14:56,780
multi-tenancy which means that you can

00:14:52,320 --> 00:15:00,450
have multiple DSC nodes on the same

00:14:56,780 --> 00:15:02,520
physical host this is good to just if if

00:15:00,450 --> 00:15:05,970
you have beefy boxes you can build

00:15:02,520 --> 00:15:08,250
denser and denser nodes but there are

00:15:05,970 --> 00:15:10,500
some replication considerations to take

00:15:08,250 --> 00:15:12,860
into play there and then the next one

00:15:10,500 --> 00:15:16,110
here is pod replaced with local storage

00:15:12,860 --> 00:15:17,850
if you have a pod failure and you have

00:15:16,110 --> 00:15:19,980
your local storage backed up there's the

00:15:17,850 --> 00:15:21,570
capability to reattach that to launch a

00:15:19,980 --> 00:15:24,390
new pod and we attach that to the new

00:15:21,570 --> 00:15:26,820
pod which again just builds more

00:15:24,390 --> 00:15:31,050
resiliency into the platform itself and

00:15:26,820 --> 00:15:32,910
then the network management and CNI this

00:15:31,050 --> 00:15:34,410
also comes into play for the dense node

00:15:32,910 --> 00:15:38,850
support where you can have multiple

00:15:34,410 --> 00:15:40,259
DSC nodes on the same host and it's just

00:15:38,850 --> 00:15:43,560
really important for all that stuff to

00:15:40,259 --> 00:15:45,899
be working well or if the gossip

00:15:43,560 --> 00:15:48,660
protocol that I mentioned before isn't

00:15:45,899 --> 00:15:51,740
able to function your server is going to

00:15:48,660 --> 00:15:54,290
be a mess and then finally we have

00:15:51,740 --> 00:15:57,480
expanded monitoring where you can see

00:15:54,290 --> 00:15:59,990
some of the errors and some of the DSC

00:15:57,480 --> 00:16:05,550
statistics actually in the DCOs

00:15:59,990 --> 00:16:08,639
UI so that's where we're at today and

00:16:05,550 --> 00:16:12,689
then I touched on these briefly before

00:16:08,639 --> 00:16:14,250
but I'll just go over them again we have

00:16:12,689 --> 00:16:16,519
a couple customer deployments are a

00:16:14,250 --> 00:16:20,009
couple patterns and customer deployments

00:16:16,519 --> 00:16:23,399
the first one is for a large travel

00:16:20,009 --> 00:16:25,410
company they're using it to deploy these

00:16:23,399 --> 00:16:29,069
micro services in a very efficient

00:16:25,410 --> 00:16:30,329
manner they don't have a lot of typical

00:16:29,069 --> 00:16:32,910
II don't have a lot of time to deploy

00:16:30,329 --> 00:16:34,769
these services so being able to just hit

00:16:32,910 --> 00:16:37,620
a button in DCOs and have these things

00:16:34,769 --> 00:16:40,949
fire up has been a real value ad for

00:16:37,620 --> 00:16:42,329
them and it really comes back to just

00:16:40,949 --> 00:16:44,930
being able to have a repeatable

00:16:42,329 --> 00:16:47,130
consistent consistent deployment where

00:16:44,930 --> 00:16:49,649
when they have a configuration that's

00:16:47,130 --> 00:16:51,769
working in dev they can take it directly

00:16:49,649 --> 00:16:55,050
to test and then directly to production

00:16:51,769 --> 00:16:57,870
knowing that it's exactly the same and

00:16:55,050 --> 00:17:00,750
without having to do any manual porting

00:16:57,870 --> 00:17:02,009
there and then the second one I

00:17:00,750 --> 00:17:05,309
mentioned here is a platform as a

00:17:02,009 --> 00:17:07,439
service this is similar to the first but

00:17:05,309 --> 00:17:09,480
it's also very important for them to be

00:17:07,439 --> 00:17:13,110
able to have this uniform deployment

00:17:09,480 --> 00:17:16,500
such that when they need more resources

00:17:13,110 --> 00:17:18,929
or more endpoints to meet their internal

00:17:16,500 --> 00:17:21,030
on Prem cloud they can just go ahead and

00:17:18,929 --> 00:17:26,069
fire those up through the D cos and DSC

00:17:21,030 --> 00:17:29,730
integration all right now I'm gonna get

00:17:26,069 --> 00:17:31,740
to a couple demos they're pre-recorded I

00:17:29,730 --> 00:17:33,179
couldn't do them live I tried last night

00:17:31,740 --> 00:17:37,200
and it didn't work so I ended up having

00:17:33,179 --> 00:17:40,700
somebody else send me some videos so the

00:17:37,200 --> 00:17:44,539
first one here I'll show you how to

00:17:40,700 --> 00:17:47,539
install the database through the DC OS

00:17:44,539 --> 00:17:47,539
catalog

00:17:52,900 --> 00:17:58,580
so here if we go to the catalog section

00:17:56,330 --> 00:18:08,570
we can see the couple panels that I

00:17:58,580 --> 00:18:11,000
mentioned before let's try that again

00:18:08,570 --> 00:18:12,650
so we'll go to the catalog and you'll

00:18:11,000 --> 00:18:16,580
see the couple panels that I mentioned

00:18:12,650 --> 00:18:19,130
before and if you go ahead and click

00:18:16,580 --> 00:18:23,420
configure here you can see the different

00:18:19,130 --> 00:18:25,940
options for enabling any of our full

00:18:23,420 --> 00:18:28,130
platform support and as well as select a

00:18:25,940 --> 00:18:29,630
number of nodes and the different

00:18:28,130 --> 00:18:32,900
options that you would see in the

00:18:29,630 --> 00:18:34,400
Cassandra and DSC amell's here as you

00:18:32,900 --> 00:18:38,990
can kind of tell from this there's a lot

00:18:34,400 --> 00:18:40,730
of options so a big piece of this is

00:18:38,990 --> 00:18:43,670
when you're setting all these things

00:18:40,730 --> 00:18:47,300
afterwards you can just download that

00:18:43,670 --> 00:18:53,900
configuration file and save it so that

00:18:47,300 --> 00:18:55,760
you can roll back later on I'll continue

00:18:53,900 --> 00:18:57,230
just it continues to flip through some

00:18:55,760 --> 00:19:04,460
of the configuration options to take

00:18:57,230 --> 00:19:06,200
away here is that there's a lot so after

00:19:04,460 --> 00:19:07,580
you set all these things you can also

00:19:06,200 --> 00:19:08,840
deploy option which is the GUI

00:19:07,580 --> 00:19:10,400
management after you set all these

00:19:08,840 --> 00:19:12,590
things you can go ahead and review and

00:19:10,400 --> 00:19:15,350
like I said download the configuration

00:19:12,590 --> 00:19:18,350
and then deploy it so this will take you

00:19:15,350 --> 00:19:20,650
to the service panel where you can start

00:19:18,350 --> 00:19:25,580
to see these lot these nodes being

00:19:20,650 --> 00:19:29,120
launched and in our lab it takes usually

00:19:25,580 --> 00:19:32,450
about 10 minutes or so so this is sped

00:19:29,120 --> 00:19:36,530
up a bit to just make a clear point here

00:19:32,450 --> 00:19:38,660
but in this case it's a three node DSC

00:19:36,530 --> 00:19:40,550
cluster and on each one of those nodes

00:19:38,660 --> 00:19:44,720
there's an agent as well as the DSC

00:19:40,550 --> 00:19:47,120
service running and like I said this is

00:19:44,720 --> 00:19:48,650
sped up just a little bit to just make

00:19:47,120 --> 00:19:51,860
the point that you can see the resources

00:19:48,650 --> 00:19:56,170
that each one of the machines has

00:19:51,860 --> 00:19:59,240
allocated towards it so that's

00:19:56,170 --> 00:20:00,830
installing DSC and now we'll go through

00:19:59,240 --> 00:20:05,649
a quick one for installing

00:20:00,830 --> 00:20:05,649
Center which is the management GUI

00:20:12,080 --> 00:20:19,649
so a separate panel here the data stacks

00:20:16,769 --> 00:20:21,029
ops panel but same sort of a thing where

00:20:19,649 --> 00:20:23,610
you can figure it and there's much less

00:20:21,029 --> 00:20:26,249
options here for this service then the

00:20:23,610 --> 00:20:28,169
DSC service and one of the caveats here

00:20:26,249 --> 00:20:30,570
is that right now the ops center service

00:20:28,169 --> 00:20:31,799
is running on a single node where in the

00:20:30,570 --> 00:20:34,230
future we're going to have that be

00:20:31,799 --> 00:20:36,960
running on multiple nodes that that's

00:20:34,230 --> 00:20:41,190
actually using a distributed storage

00:20:36,960 --> 00:20:43,259
system as well so same sort of system

00:20:41,190 --> 00:20:47,399
here it's just launching that ops center

00:20:43,259 --> 00:20:49,499
node which is going to give you a view

00:20:47,399 --> 00:20:50,909
into your DSC cluster and be able to

00:20:49,499 --> 00:20:55,279
manage things like backup and restore

00:20:50,909 --> 00:20:58,259
and repair and now I'll go over to the

00:20:55,279 --> 00:21:00,570
command line interface to show how you

00:20:58,259 --> 00:21:04,409
can pull up that GUI and get the

00:21:00,570 --> 00:21:05,970
endpoint that it launched at and my name

00:21:04,409 --> 00:21:08,720
is not Katherine Erickson but she was

00:21:05,970 --> 00:21:11,489
the one who provided these demos for me

00:21:08,720 --> 00:21:14,220
so you use this DCOs command and you

00:21:11,489 --> 00:21:17,669
have to install the Clive for the data

00:21:14,220 --> 00:21:20,999
stacks ops and our service first so you

00:21:17,669 --> 00:21:23,340
see that going on here and then we'll

00:21:20,999 --> 00:21:25,169
use this endpoints command to grab the

00:21:23,340 --> 00:21:29,549
endpoint which we can then throw in the

00:21:25,169 --> 00:21:36,450
browser to get to this GUI management

00:21:29,549 --> 00:21:43,049
service so we're just grabbing the

00:21:36,450 --> 00:21:47,429
endpoint here now you can see the

00:21:43,049 --> 00:21:52,489
address right there so we take that and

00:21:47,429 --> 00:21:52,489
we can put that into the browser

00:21:58,850 --> 00:22:04,549
and this brings up the the ops center

00:22:01,309 --> 00:22:06,440
panel that gives you just another set of

00:22:04,549 --> 00:22:08,139
visibility into your cluster so here you

00:22:06,440 --> 00:22:11,029
can see that we have this three node

00:22:08,139 --> 00:22:13,419
data sacks enterprise cluster standing

00:22:11,029 --> 00:22:19,789
which we just launched through the DCOs

00:22:13,419 --> 00:22:23,240
catalog so the final thing I want to

00:22:19,789 --> 00:22:25,490
show you is the most recent command-line

00:22:23,240 --> 00:22:27,559
interface I don't know if any of you

00:22:25,490 --> 00:22:29,179
have used this in the past but there's

00:22:27,559 --> 00:22:34,490
been a lot of improvements here to make

00:22:29,179 --> 00:22:43,490
it more usable and just overall more

00:22:34,490 --> 00:22:45,049
enjoyable so we see our DSC nodes here

00:22:43,490 --> 00:22:47,990
again and now we can click on this

00:22:45,049 --> 00:22:53,080
install cly and it gives us the commands

00:22:47,990 --> 00:22:56,299
that we need to install this interface

00:22:53,080 --> 00:22:58,669
and I didn't she have to use sudo for

00:22:56,299 --> 00:23:03,860
her curl command here so luckily her

00:22:58,669 --> 00:23:08,779
password is hidden go ahead and install

00:23:03,860 --> 00:23:10,340
that and really what this command-line

00:23:08,779 --> 00:23:12,590
interface does is it just gives you some

00:23:10,340 --> 00:23:15,350
more some different touch points for

00:23:12,590 --> 00:23:17,360
your cluster if you want to essentially

00:23:15,350 --> 00:23:20,330
SSH directly in you can do that through

00:23:17,360 --> 00:23:23,870
this command line interface but again we

00:23:20,330 --> 00:23:32,840
see this install for the OP Center

00:23:23,870 --> 00:23:34,669
command line interface and we also

00:23:32,840 --> 00:23:36,080
installed the DS so you have to do a

00:23:34,669 --> 00:23:38,960
separate command line interface for each

00:23:36,080 --> 00:23:41,509
one of the packages for DSC and for op

00:23:38,960 --> 00:23:44,360
center and now we'll go ahead and look

00:23:41,509 --> 00:23:46,669
at our DSC endpoints here and the one

00:23:44,360 --> 00:23:50,289
that we're interested is and interested

00:23:46,669 --> 00:23:52,490
in is the Native Client which is the

00:23:50,289 --> 00:23:56,149
communication port the port that you

00:23:52,490 --> 00:24:01,909
would write to just regular queries for

00:23:56,149 --> 00:24:03,860
data stacks so we grab the we grab the

00:24:01,909 --> 00:24:06,379
IP addresses and the ports here and then

00:24:03,860 --> 00:24:10,760
we can go ahead and just open up a shell

00:24:06,379 --> 00:24:12,700
on that first node where now we'll go

00:24:10,760 --> 00:24:14,470
into cql SH and we'll show that we

00:24:12,700 --> 00:24:18,100
can just execute queries directly on

00:24:14,470 --> 00:24:19,780
this node and CQ LSH is just the the

00:24:18,100 --> 00:24:25,780
shell that is used to interact with

00:24:19,780 --> 00:24:26,980
cassandra to issue requests so we'll go

00:24:25,780 --> 00:24:30,070
ahead and here and just create a key

00:24:26,980 --> 00:24:34,000
space which is essentially just the bin

00:24:30,070 --> 00:24:40,720
for the data stacks schema we'll create

00:24:34,000 --> 00:24:42,970
a table called customer sales and then

00:24:40,720 --> 00:24:45,610
we'll just go ahead and insert a couple

00:24:42,970 --> 00:24:48,010
rows and then do a quick query there

00:24:45,610 --> 00:24:49,720
just to show how this has been much

00:24:48,010 --> 00:24:56,080
improved I don't know if you guys did

00:24:49,720 --> 00:24:58,600
use it before but this is like great so

00:24:56,080 --> 00:25:01,330
just a normal select query there based

00:24:58,600 --> 00:25:04,300
upon the rows that were marked with a

00:25:01,330 --> 00:25:13,090
different timestamp above that one and

00:25:04,300 --> 00:25:16,390
that's the command-line interface so

00:25:13,090 --> 00:25:19,210
next I'll show some of the value and how

00:25:16,390 --> 00:25:21,450
easy it is to add a node into scale

00:25:19,210 --> 00:25:21,450
horizontally

00:25:26,270 --> 00:25:30,830
and this is really great because

00:25:28,130 --> 00:25:33,110
typically if you are deploying Cassandra

00:25:30,830 --> 00:25:35,420
or data stacks Enterprise you'd have to

00:25:33,110 --> 00:25:37,340
do all this stuff manually and now it's

00:25:35,420 --> 00:25:42,050
literally you can see the configuration

00:25:37,340 --> 00:25:43,429
files over here and then on this side is

00:25:42,050 --> 00:25:45,800
all the environment variables that you

00:25:43,429 --> 00:25:47,990
can singer configure and now all you

00:25:45,800 --> 00:25:52,429
have to do is add this pod count to four

00:25:47,990 --> 00:25:54,020
and it will go ahead and like we said

00:25:52,429 --> 00:25:56,540
before with the configuration it takes

00:25:54,020 --> 00:25:58,700
this new request it will reserve these

00:25:56,540 --> 00:26:01,429
new resources and then go ahead and

00:25:58,700 --> 00:26:03,860
launch that new node for you here so we

00:26:01,429 --> 00:26:07,220
can go from our three node cluster to

00:26:03,860 --> 00:26:09,980
our four node cluster through a UI with

00:26:07,220 --> 00:26:12,110
a configuration that we know is working

00:26:09,980 --> 00:26:14,809
and that exists and is managed in a

00:26:12,110 --> 00:26:19,130
single place and we go ahead and just

00:26:14,809 --> 00:26:20,929
hit deploy and now the DCOs service is

00:26:19,130 --> 00:26:24,830
launching this node with the with the

00:26:20,929 --> 00:26:28,040
same resource allocation that was on the

00:26:24,830 --> 00:26:30,140
previous three nodes that we had so it

00:26:28,040 --> 00:26:33,340
makes it really easy to score scale

00:26:30,140 --> 00:26:33,340
horizontally for you

00:26:34,809 --> 00:26:39,220
so we'll go ahead and here and just do

00:26:37,070 --> 00:26:42,890
the endpoints command again to show that

00:26:39,220 --> 00:26:45,130
one was added to the previous three node

00:26:42,890 --> 00:26:45,130
cluster

00:27:02,640 --> 00:27:07,480
so just like that now we have these four

00:27:05,350 --> 00:27:11,140
house here and our cluster was just

00:27:07,480 --> 00:27:14,890
scaled horizontally and that's really

00:27:11,140 --> 00:27:19,720
what I want to show here with this added

00:27:14,890 --> 00:27:20,919
node demo but this is the sort of thing

00:27:19,720 --> 00:27:23,770
that when you are deploying these

00:27:20,919 --> 00:27:25,600
platforms as a service that if you do

00:27:23,770 --> 00:27:27,250
need more resources or if you do need

00:27:25,600 --> 00:27:29,650
more endpoints it's as easy as a few

00:27:27,250 --> 00:27:31,510
clicks of the button and now we'll go to

00:27:29,650 --> 00:27:34,059
the ops center again just to show that

00:27:31,510 --> 00:27:37,020
the same change was reflected in the ops

00:27:34,059 --> 00:27:37,020
center GUI as well

00:27:46,610 --> 00:27:54,399
so we load up op center and now we have

00:27:50,720 --> 00:27:54,399
four nodes in our DSC cluster

00:28:01,660 --> 00:28:11,110
I put this up here in I'll go ahead

00:28:07,600 --> 00:28:12,670
so on this meso Schoen link here we have

00:28:11,110 --> 00:28:15,280
a bunch of examples if you want to try

00:28:12,670 --> 00:28:17,470
this for yourself to go through some of

00:28:15,280 --> 00:28:20,320
the exact things that we just ran this

00:28:17,470 --> 00:28:22,990
demo so these slide decks are on the

00:28:20,320 --> 00:28:24,700
mesos con europe website so i'd

00:28:22,990 --> 00:28:27,460
recommend if you guys are interested to

00:28:24,700 --> 00:28:29,520
go to this link here and take it for a

00:28:27,460 --> 00:28:29,520
spin

00:28:30,750 --> 00:28:36,850
alright and that's it

00:28:34,450 --> 00:28:39,280
do you guys have any questions about the

00:28:36,850 --> 00:28:40,270
platform or about anything that we've

00:28:39,280 --> 00:28:49,230
built here or anything that was

00:28:40,270 --> 00:28:52,330
presented today it's a great talk

00:28:49,230 --> 00:28:54,970
how couple questions so the framework

00:28:52,330 --> 00:28:58,630
the masses framework that data stack is

00:28:54,970 --> 00:29:00,700
built it's tied to DCOs right so if I

00:28:58,630 --> 00:29:03,340
want to run on a vanilla missus that

00:29:00,700 --> 00:29:07,300
will be like the flag is ring correct

00:29:03,340 --> 00:29:08,950
it's built on G cos it requires D cos so

00:29:07,300 --> 00:29:12,070
you'd need that service to be able to

00:29:08,950 --> 00:29:15,370
run it and the second question is you

00:29:12,070 --> 00:29:17,920
mentioned that the the way you work with

00:29:15,370 --> 00:29:20,350
local disks allows the replication and

00:29:17,920 --> 00:29:22,360
fast moving of the container to another

00:29:20,350 --> 00:29:27,580
node can you elaborate a little bit on

00:29:22,360 --> 00:29:30,670
this sure so when you persist when you

00:29:27,580 --> 00:29:32,800
persist the volume it gets stored to an

00:29:30,670 --> 00:29:35,440
underlying host and with this pod

00:29:32,800 --> 00:29:37,750
replace mechanism that data doesn't

00:29:35,440 --> 00:29:41,110
actually go anywhere but the previous

00:29:37,750 --> 00:29:42,850
pod that you had before will go down but

00:29:41,110 --> 00:29:44,830
then a new pod will be launched and you

00:29:42,850 --> 00:29:46,480
can tell it to map that local storage

00:29:44,830 --> 00:29:49,420
that was there the whole time

00:29:46,480 --> 00:29:51,640
to this new volume so that are to a new

00:29:49,420 --> 00:29:54,700
volume in this new pod so then you can

00:29:51,640 --> 00:29:56,880
access that same data there okay so so

00:29:54,700 --> 00:30:01,000
there is no rebuild associated when we

00:29:56,880 --> 00:30:04,360
create the pod on the same note correct

00:30:01,000 --> 00:30:09,520
and do you work with external storages

00:30:04,360 --> 00:30:11,470
there as well I don't know honestly I'm

00:30:09,520 --> 00:30:14,790
more just add more no just so I know

00:30:11,470 --> 00:30:16,260
more about the data sack side of things

00:30:14,790 --> 00:30:17,700
so I don't know exactly but we can

00:30:16,260 --> 00:30:22,410
follow up later if you want to get an

00:30:17,700 --> 00:30:25,320
answer though thanks just one note for

00:30:22,410 --> 00:30:27,420
that though the ops center management

00:30:25,320 --> 00:30:29,970
GUI that I mentioned before it does

00:30:27,420 --> 00:30:32,490
provide the ability to backup to s3 or

00:30:29,970 --> 00:30:36,059
any external storage that you have I'm

00:30:32,490 --> 00:30:40,490
just not positive about the DCOs side of

00:30:36,059 --> 00:30:40,490
things working with external storage

00:30:41,300 --> 00:30:46,770
thank you for the nice presentation a

00:30:43,980 --> 00:30:49,580
question when you add nodes how does it

00:30:46,770 --> 00:30:52,590
handle tokens underneath the covers yep

00:30:49,580 --> 00:30:56,150
so that's going to depend on whether you

00:30:52,590 --> 00:30:59,809
are using single tokens or V nodes in

00:30:56,150 --> 00:31:03,059
Cassandra if you're using virtual nodes

00:30:59,809 --> 00:31:06,300
that allocation algorithm works

00:31:03,059 --> 00:31:09,600
automatically so if you if let's say you

00:31:06,300 --> 00:31:12,900
have 256 tokens per node and you

00:31:09,600 --> 00:31:15,450
launched a new node the way that the

00:31:12,900 --> 00:31:18,420
token allocation works is that it will

00:31:15,450 --> 00:31:21,990
automatically select the tokens that

00:31:18,420 --> 00:31:24,720
would best balance your existing cluster

00:31:21,990 --> 00:31:27,480
so all that is done through DSC and

00:31:24,720 --> 00:31:30,240
cassandra automatically but if you're

00:31:27,480 --> 00:31:34,410
using single tokens then you would have

00:31:30,240 --> 00:31:36,540
to configure that yourself for the best

00:31:34,410 --> 00:31:38,760
token allocation for your single token

00:31:36,540 --> 00:31:41,460
architecture okay so you'd put that into

00:31:38,760 --> 00:31:42,690
I guess the configuration and then when

00:31:41,460 --> 00:31:45,059
you're done you just have to clean up

00:31:42,690 --> 00:31:48,600
yeah you still have to clean up if

00:31:45,059 --> 00:31:51,809
you're doing single tokens thank you and

00:31:48,600 --> 00:31:53,670
you would just do that via the cly you

00:31:51,809 --> 00:31:56,340
can go into each node into the clean up

00:31:53,670 --> 00:31:57,840
command there was that running

00:31:56,340 --> 00:32:01,790
containers or was that actually running

00:31:57,840 --> 00:32:01,790
now so it's running containers

00:32:06,100 --> 00:32:09,510
any other questions

00:32:12,930 --> 00:32:20,479
all right thanks guys

00:32:16,410 --> 00:32:20,479

YouTube URL: https://www.youtube.com/watch?v=J8T8Br__UD0


