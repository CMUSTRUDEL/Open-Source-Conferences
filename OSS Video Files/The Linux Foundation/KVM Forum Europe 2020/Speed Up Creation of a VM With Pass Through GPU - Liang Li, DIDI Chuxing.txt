Title: Speed Up Creation of a VM With Pass Through GPU - Liang Li, DIDI Chuxing
Publication date: 2020-11-10
Playlist: KVM Forum Europe 2020
Description: 
	Speed Up Creation of a VM With Pass Through GPU - Liang Li, DIDI Chuxing
Captions: 
	00:00:06,960 --> 00:00:11,040
hello everyone

00:00:08,320 --> 00:00:12,320
my name is leon and i'm from the

00:00:11,040 --> 00:00:17,920
infrastructure team

00:00:12,320 --> 00:00:17,920
of td tuition let's get started

00:00:18,000 --> 00:00:22,480
with the rapid development of artificial

00:00:20,320 --> 00:00:25,680
intelligence in these years

00:00:22,480 --> 00:00:28,720
gpu plays a very important role

00:00:25,680 --> 00:00:31,199
and is widely used

00:00:28,720 --> 00:00:32,960
it has usually provided as a form of

00:00:31,199 --> 00:00:36,000
virtual machine instance by cloud

00:00:32,960 --> 00:00:36,000
service providers

00:00:36,160 --> 00:00:39,680
for some technical reasons creating

00:00:38,800 --> 00:00:44,399
virtual machine

00:00:39,680 --> 00:00:46,960
with a password field card is very slow

00:00:44,399 --> 00:00:50,480
which is a common issue faced by all's

00:00:46,960 --> 00:00:53,360
cloud service providers

00:00:50,480 --> 00:00:53,680
today i will share you with a practice

00:00:53,360 --> 00:00:59,840
that

00:00:53,680 --> 00:00:59,840
how dd serves this issue

00:01:04,640 --> 00:01:08,799
the agenda of my presentation contains

00:01:06,799 --> 00:01:12,320
the following parts

00:01:08,799 --> 00:01:13,760
the first part is a background and the

00:01:12,320 --> 00:01:16,159
second part

00:01:13,760 --> 00:01:16,960
we release the main issues slow down the

00:01:16,159 --> 00:01:19,439
creation

00:01:16,960 --> 00:01:21,280
of a virtual machine with a pass-through

00:01:19,439 --> 00:01:22,960
gpu card

00:01:21,280 --> 00:01:26,240
the third part will give you some

00:01:22,960 --> 00:01:29,520
details of the solutions and

00:01:26,240 --> 00:01:32,799
then the fact of the optimization

00:01:29,520 --> 00:01:40,240
will be shown the next part

00:01:32,799 --> 00:01:43,040
is the conclusion

00:01:40,240 --> 00:01:44,399
in this topic i will call a virtual

00:01:43,040 --> 00:01:47,759
machine without

00:01:44,399 --> 00:01:49,680
or pass through pci device as a cpu

00:01:47,759 --> 00:01:52,240
virtual machine

00:01:49,680 --> 00:01:54,159
and the virtual machine with one or more

00:01:52,240 --> 00:01:57,600
password gpu cars

00:01:54,159 --> 00:01:57,600
as a gpu virtual machine

00:01:57,840 --> 00:02:01,759
creating ocp world machine instance is

00:02:00,399 --> 00:02:05,200
fast

00:02:01,759 --> 00:02:08,000
it usually takes several seconds

00:02:05,200 --> 00:02:08,879
while creating a gp virtual machine

00:02:08,000 --> 00:02:11,440
instance

00:02:08,879 --> 00:02:12,800
with the same resource configuration is

00:02:11,440 --> 00:02:16,080
slow

00:02:12,800 --> 00:02:17,599
it may take several minutes if the

00:02:16,080 --> 00:02:21,680
virtual machine has a lot of

00:02:17,599 --> 00:02:23,840
ram in most case

00:02:21,680 --> 00:02:25,840
virtual machine creation time is not

00:02:23,840 --> 00:02:28,959
critical

00:02:25,840 --> 00:02:30,959
but in some interactivity scenario a

00:02:28,959 --> 00:02:31,599
long watch machine instance creation

00:02:30,959 --> 00:02:34,879
time

00:02:31,599 --> 00:02:37,840
means poor user experience and computing

00:02:34,879 --> 00:02:37,840
resource waste

00:02:45,920 --> 00:02:50,400
virtual machine creation time is defined

00:02:48,400 --> 00:02:53,200
as a time interval

00:02:50,400 --> 00:02:56,879
between cumula process start to execute

00:02:53,200 --> 00:02:56,879
and its guest colors start to run

00:02:57,360 --> 00:03:01,120
it's divided into two parts the first

00:03:00,560 --> 00:03:04,480
part

00:03:01,120 --> 00:03:07,200
is virtual machine initialization time

00:03:04,480 --> 00:03:08,720
which is defined as a time interval

00:03:07,200 --> 00:03:11,840
between cumulative process

00:03:08,720 --> 00:03:14,000
start execute and the way cpu start to

00:03:11,840 --> 00:03:14,000
run

00:03:14,319 --> 00:03:20,959
the second part is bios execution time

00:03:18,319 --> 00:03:22,879
which is defined as the time interval

00:03:20,959 --> 00:03:24,959
between which cpu start run

00:03:22,879 --> 00:03:27,440
and the first guest current log is

00:03:24,959 --> 00:03:29,920
printed

00:03:27,440 --> 00:03:30,799
the chart in the right shows the

00:03:29,920 --> 00:03:32,640
creation time

00:03:30,799 --> 00:03:36,000
of different virtual machine instance

00:03:32,640 --> 00:03:36,000
before optimization

00:03:36,080 --> 00:03:39,760
some factors like virtual machine ram

00:03:38,799 --> 00:03:43,280
size

00:03:39,760 --> 00:03:46,159
the type or gpu card and the count

00:03:43,280 --> 00:03:48,959
or gpu cards will affect virtual machine

00:03:46,159 --> 00:03:48,959
creation time

00:03:54,400 --> 00:03:57,760
you will be curious about the reason for

00:03:56,799 --> 00:04:00,959
the long time

00:03:57,760 --> 00:04:03,519
it takes when creating a gpu virtual

00:04:00,959 --> 00:04:07,840
machine instance

00:04:03,519 --> 00:04:10,959
what slow down the creation process

00:04:07,840 --> 00:04:11,280
to find out reason we can use perth to

00:04:10,959 --> 00:04:13,439
get

00:04:11,280 --> 00:04:15,519
the hot spot functions of cumulative

00:04:13,439 --> 00:04:17,919
process

00:04:15,519 --> 00:04:18,799
the flame graph in this page shows the

00:04:17,919 --> 00:04:21,600
hotspot

00:04:18,799 --> 00:04:22,880
is in the code chain or call function

00:04:21,600 --> 00:04:29,840
wii fio

00:04:22,880 --> 00:04:29,840
pin page remote

00:04:31,680 --> 00:04:38,400
this page lists the main factors

00:04:35,120 --> 00:04:41,919
slow down the virtual machine creation

00:04:38,400 --> 00:04:43,759
the key factors is a function with fio

00:04:41,919 --> 00:04:46,320
pinpage remote

00:04:43,759 --> 00:04:46,320
is slow

00:04:47,600 --> 00:04:52,080
by debug you will find some repeated

00:04:50,360 --> 00:04:56,400
vi5odma map

00:04:52,080 --> 00:04:59,680
and unmap for the same ioa

00:04:56,400 --> 00:05:03,600
which makes sense worse

00:04:59,680 --> 00:05:07,600
besides that psi device reset

00:05:03,600 --> 00:05:10,240
management metadata initialization in qm

00:05:07,600 --> 00:05:12,160
and other is seniors configuration will

00:05:10,240 --> 00:05:14,720
slow down virtual machine instance

00:05:12,160 --> 00:05:14,720
creation

00:05:14,800 --> 00:05:25,840
i will describe these factors in detail

00:05:26,400 --> 00:05:33,440
for wii file pin page remote

00:05:29,520 --> 00:05:36,400
there are two main issues make it slow

00:05:33,440 --> 00:05:38,720
the first one is zero out operation

00:05:36,400 --> 00:05:41,600
which is required when allocating pages

00:05:38,720 --> 00:05:44,479
for user space

00:05:41,600 --> 00:05:45,840
server also page content will make sure

00:05:44,479 --> 00:05:49,199
sensitive information

00:05:45,840 --> 00:05:51,520
invisible to user space

00:05:49,199 --> 00:05:53,360
because page allocated may have been

00:05:51,520 --> 00:05:56,880
used by other process

00:05:53,360 --> 00:06:00,000
of the kernel and has sensitive

00:05:56,880 --> 00:06:00,000
information retained

00:06:00,319 --> 00:06:04,560
as a solution we introduced a new

00:06:03,120 --> 00:06:07,840
feature called

00:06:04,560 --> 00:06:13,440
pre-zero out free page to speed up

00:06:07,840 --> 00:06:17,199
page allocation the idea is simple

00:06:13,440 --> 00:06:20,319
there are three pages in other ones

00:06:17,199 --> 00:06:23,520
some when allocating pages page

00:06:20,319 --> 00:06:23,520
zero out can be skipped

00:06:25,759 --> 00:06:32,400
the second issue is the wii fio dma map

00:06:29,360 --> 00:06:34,720
p memory in a page by page way

00:06:32,400 --> 00:06:37,600
this result in two-man page table

00:06:34,720 --> 00:06:37,600
entries access

00:06:38,400 --> 00:06:49,840
as a solution pin memory embark is used

00:06:41,919 --> 00:06:49,840
to reduce the cost

00:06:50,800 --> 00:06:57,120
for pre-zero out free page it is based

00:06:54,240 --> 00:06:59,759
on three page reporting

00:06:57,120 --> 00:07:01,840
paste out operation is down in your code

00:06:59,759 --> 00:07:05,599
works

00:07:01,840 --> 00:07:06,080
after page is zeroed out cells page zero

00:07:05,599 --> 00:07:09,280
flag

00:07:06,080 --> 00:07:13,680
is corresponding page slide

00:07:09,280 --> 00:07:17,199
one page allocated list to be zeroed out

00:07:13,680 --> 00:07:22,720
check page zero flag first

00:07:17,199 --> 00:07:22,720
if is set zero operation can be skipped

00:07:24,000 --> 00:07:27,520
when pages are free peggy sterling flag

00:07:26,720 --> 00:07:33,199
is cleared

00:07:27,520 --> 00:07:33,199
and the zero out worker will be woken up

00:07:35,120 --> 00:07:41,520
i have sent the rfc pipestat to upstream

00:07:38,479 --> 00:07:44,960
you can find the implementation details

00:07:41,520 --> 00:07:45,520
with link in this page i will not talk

00:07:44,960 --> 00:07:47,680
more about

00:07:45,520 --> 00:07:47,680
it

00:07:54,639 --> 00:07:58,400
to make weak file dma map p memory

00:07:57,360 --> 00:08:01,840
embark

00:07:58,400 --> 00:08:04,879
we add two functions in kernel they are

00:08:01,840 --> 00:08:09,280
get user city page and get users

00:08:04,879 --> 00:08:12,319
page long term they are corresponding to

00:08:09,280 --> 00:08:14,639
get user page and get user page long

00:08:12,319 --> 00:08:14,639
term

00:08:14,879 --> 00:08:20,400
ct here means physical continuous

00:08:18,000 --> 00:08:21,840
the new function will try to pin memory

00:08:20,400 --> 00:08:24,840
and get the information

00:08:21,840 --> 00:08:27,840
about opark or physical continuous

00:08:24,840 --> 00:08:27,840
memory

00:08:28,000 --> 00:08:32,000
the chart on the right shows the

00:08:29,919 --> 00:08:35,200
different behavior of the new function

00:08:32,000 --> 00:08:35,200
and the original one

00:08:36,479 --> 00:08:40,080
the new function will be friendlier to

00:08:39,039 --> 00:08:43,200
function

00:08:40,080 --> 00:08:47,519
we order get pfn and make

00:08:43,200 --> 00:08:47,519
its life easier to pin memory embark

00:08:48,720 --> 00:08:55,839
to take more benefits huge page should

00:08:51,360 --> 00:08:55,839
be used

00:09:00,399 --> 00:09:08,399
we fio dma map is inefficient

00:09:04,399 --> 00:09:09,519
there are two reasons for this the first

00:09:08,399 --> 00:09:13,920
one is the same

00:09:09,519 --> 00:09:18,880
ioa map experienced as a map

00:09:13,920 --> 00:09:22,560
on map and then remap precision

00:09:18,880 --> 00:09:25,600
it's unreasonable

00:09:22,560 --> 00:09:29,760
to solve this issue the mapped

00:09:25,600 --> 00:09:32,959
ioe area information are retained in qmu

00:09:29,760 --> 00:09:36,080
to avoid unnecessary wii fio dma map

00:09:32,959 --> 00:09:39,279
and unmap operation

00:09:36,080 --> 00:09:42,320
for the horse's work we fio

00:09:39,279 --> 00:09:47,200
iomu on mapdma our control is all

00:09:42,320 --> 00:09:50,160
called with map of conflict ioa area

00:09:47,200 --> 00:09:51,120
conflict here means a new added airway

00:09:50,160 --> 00:09:53,440
area

00:09:51,120 --> 00:09:54,880
which is intersected with an already

00:09:53,440 --> 00:09:59,440
mapped ioa

00:09:54,880 --> 00:09:59,440
area but not equals to it

00:10:02,480 --> 00:10:09,600
the second issue is inefficient iowa

00:10:05,519 --> 00:10:12,079
aerial mapping update for example

00:10:09,600 --> 00:10:15,200
to change or tribute our subregion or

00:10:12,079 --> 00:10:18,000
when io area which is already mapped

00:10:15,200 --> 00:10:18,720
the whole iowa area is to be unmapped

00:10:18,000 --> 00:10:22,240
first

00:10:18,720 --> 00:10:24,959
and then be mapped again

00:10:22,240 --> 00:10:26,720
this will happen for an ioa area

00:10:24,959 --> 00:10:29,680
contains the address

00:10:26,720 --> 00:10:29,680
of one mega

00:10:30,160 --> 00:10:37,279
as a solution the ioa error

00:10:33,200 --> 00:10:37,279
is split into two parts

00:10:38,480 --> 00:10:44,839
one part is below

00:10:41,600 --> 00:10:46,160
one mega and the last part is about my

00:10:44,839 --> 00:10:49,600
mega

00:10:46,160 --> 00:10:52,720
it can it can prevent high part

00:10:49,600 --> 00:10:54,079
iowa error from being unmapped for

00:10:52,720 --> 00:11:01,839
modifications

00:10:54,079 --> 00:11:01,839
to slow part

00:11:03,360 --> 00:11:08,640
for pci device reset one reset takes

00:11:06,800 --> 00:11:11,839
about one second

00:11:08,640 --> 00:11:14,959
so it's a slow operation

00:11:11,839 --> 00:11:17,200
there are two issues in qmu the first

00:11:14,959 --> 00:11:17,200
one

00:11:17,440 --> 00:11:20,640
a device was reset price during virtual

00:11:20,160 --> 00:11:23,200
machine

00:11:20,640 --> 00:11:23,200
creation

00:11:24,079 --> 00:11:31,519
one eating function qmo system reset

00:11:28,240 --> 00:11:34,800
and another one in wii file group

00:11:31,519 --> 00:11:37,920
get device fd io control

00:11:34,800 --> 00:11:42,959
reset ties is redundant

00:11:37,920 --> 00:11:45,360
one of them can be removed

00:11:42,959 --> 00:11:46,079
the second issue is psi device reset

00:11:45,360 --> 00:11:51,200
operation

00:11:46,079 --> 00:11:51,200
are specifying a 0 are serialized

00:11:52,160 --> 00:11:56,000
if a virtual machine has more than 1 gpu

00:11:54,959 --> 00:11:58,399
cards

00:11:56,000 --> 00:12:00,800
it will take more time to reset the

00:11:58,399 --> 00:12:00,800
device

00:12:01,760 --> 00:12:05,440
do the pci device reset in parallel will

00:12:04,880 --> 00:12:08,800
be more

00:12:05,440 --> 00:12:11,120
scalable and furthermore

00:12:08,800 --> 00:12:13,920
make the pci device reset in parallel

00:12:11,120 --> 00:12:24,399
with vfio dma map

00:12:13,920 --> 00:12:28,160
can maximizing the benefits

00:12:24,399 --> 00:12:30,320
for qm column model there are some time

00:12:28,160 --> 00:12:33,600
consuming operations which can

00:12:30,320 --> 00:12:38,160
be optimized third page

00:12:33,600 --> 00:12:40,639
bitmap initialization is one of them

00:12:38,160 --> 00:12:41,920
virtual machine with a pass-through gpu

00:12:40,639 --> 00:12:44,959
does not support

00:12:41,920 --> 00:12:47,120
level migration currently so third-party

00:12:44,959 --> 00:12:50,480
login for a pci bar

00:12:47,120 --> 00:12:53,839
specified mmi

00:12:50,480 --> 00:12:57,519
mm-io range is a useless

00:12:53,839 --> 00:13:01,040
which can be skipped when pml

00:12:57,519 --> 00:13:05,040
is enabled instead if he enters dbit

00:13:01,040 --> 00:13:05,040
is a last time consuming operation

00:13:05,200 --> 00:13:10,320
it uses reverse map to get the ept

00:13:08,880 --> 00:13:12,639
entries for setting the

00:13:10,320 --> 00:13:12,639
db

00:13:14,800 --> 00:13:20,480
closing all the reverse map entries

00:13:18,240 --> 00:13:23,680
are time consuming if the virtual

00:13:20,480 --> 00:13:23,680
machine has a large ram

00:13:24,399 --> 00:13:28,320
during the virtual machine creation most

00:13:26,800 --> 00:13:32,160
of the ep entries

00:13:28,320 --> 00:13:35,360
are empty so croatian or the

00:13:32,160 --> 00:13:36,720
reverse map to find a few or effective

00:13:35,360 --> 00:13:40,320
ep entries

00:13:36,720 --> 00:13:41,519
is lot worse this can be improved by

00:13:40,320 --> 00:13:45,440
making the reverse

00:13:41,519 --> 00:13:47,760
map closer more efficient for example

00:13:45,440 --> 00:13:49,600
we can introduce a sparse bitmap

00:13:47,760 --> 00:13:53,199
merchandising

00:13:49,600 --> 00:13:54,399
like http map used in queue to skip the

00:13:53,199 --> 00:13:58,560
empty reverse map

00:13:54,399 --> 00:14:00,959
entries in our environment

00:13:58,560 --> 00:14:04,160
we use a lot of simple way to serve this

00:14:00,959 --> 00:14:07,360
issue by counting the effective

00:14:04,160 --> 00:14:07,360
rewards map entries

00:14:07,680 --> 00:14:15,199
silver's map entrance for memory slot

00:14:10,800 --> 00:14:19,279
can be skipped if we so factor

00:14:15,199 --> 00:14:19,279
reverse map entries count is zero

00:14:20,000 --> 00:14:25,839
this is not an ideal solution but

00:14:23,120 --> 00:14:28,639
it is a balance between benefits and the

00:14:25,839 --> 00:14:28,639
development

00:14:28,839 --> 00:14:31,839
complexity

00:14:36,800 --> 00:14:42,560
there are some configurations which will

00:14:39,040 --> 00:14:46,800
affect the virtual machine creation time

00:14:42,560 --> 00:14:50,720
see at least listed listed about

00:14:46,800 --> 00:14:53,600
c bios with mario has 2.5 seconds of

00:14:50,720 --> 00:14:56,720
timeout by default

00:14:53,600 --> 00:14:59,839
if put manual is unnecessary please

00:14:56,720 --> 00:14:59,839
disable it

00:15:00,720 --> 00:15:05,440
if linux guest is used the graph may

00:15:03,519 --> 00:15:08,160
configure a timeout for selecting

00:15:05,440 --> 00:15:08,160
different color

00:15:08,240 --> 00:15:13,839
if it's unnecessary please change it to

00:15:11,199 --> 00:15:13,839
zero

00:15:14,880 --> 00:15:18,959
new memory parcel will affect the speed

00:15:17,680 --> 00:15:22,079
of page allocation

00:15:18,959 --> 00:15:23,440
when some of the loads have memory

00:15:22,079 --> 00:15:27,839
pressure

00:15:23,440 --> 00:15:27,839
so be careful with it

00:15:32,959 --> 00:15:36,480
this page shows the cumulative process

00:15:35,279 --> 00:15:39,440
flame graph

00:15:36,480 --> 00:15:40,160
of the optimization you can find the

00:15:39,440 --> 00:15:44,320
hotspot

00:15:40,160 --> 00:15:44,320
we saw before has disappeared

00:15:51,040 --> 00:15:57,279
and this page shows a accumulated time

00:15:53,920 --> 00:16:00,720
takes by some make human functions

00:15:57,279 --> 00:16:09,120
as you see the time is reduced greatly

00:16:00,720 --> 00:16:12,079
after implementation

00:16:09,120 --> 00:16:13,199
this page shows the gpu virtual machine

00:16:12,079 --> 00:16:14,959
instance

00:16:13,199 --> 00:16:17,839
creation time when different

00:16:14,959 --> 00:16:20,079
optimization method is used

00:16:17,839 --> 00:16:21,120
compared with cpu virtual machine

00:16:20,079 --> 00:16:24,320
instance

00:16:21,120 --> 00:16:24,320
it takes a little longer

00:16:31,279 --> 00:16:35,360
and this page shows the creation time of

00:16:34,000 --> 00:16:39,759
a gpu watch machine

00:16:35,360 --> 00:16:43,600
instance with one gpu card and

00:16:39,759 --> 00:16:46,959
48 giga byte ram

00:16:43,600 --> 00:16:48,560
before optimization it takes about 38

00:16:46,959 --> 00:16:52,240
seconds

00:16:48,560 --> 00:16:54,480
after optimization it only takes 3.3

00:16:52,240 --> 00:16:57,519
seconds

00:16:54,480 --> 00:17:00,959
the creation time is reduced

00:16:57,519 --> 00:17:00,959
by more than light percent

00:17:02,160 --> 00:17:05,760
for gpu virtual machine instance with

00:17:04,319 --> 00:17:09,360
4gpu cards

00:17:05,760 --> 00:17:13,439
and 192 giga ram

00:17:09,360 --> 00:17:16,959
it is is reduced from about 2 minutes

00:17:13,439 --> 00:17:20,319
to 4.4 seconds

00:17:16,959 --> 00:17:32,080
which is which is reduced by

00:17:20,319 --> 00:17:36,080
more than 95 percent

00:17:32,080 --> 00:17:39,520
the conclusion part i have to point out

00:17:36,080 --> 00:17:43,679
words of optimizations are not limited

00:17:39,520 --> 00:17:45,840
to gpu virtual machine instance

00:17:43,679 --> 00:17:47,520
they apply to virtual machine instance

00:17:45,840 --> 00:17:52,240
with other pci

00:17:47,520 --> 00:17:57,039
pass-through device and some of them

00:17:52,240 --> 00:17:57,039
applying to cpu virtual machine instance

00:17:58,400 --> 00:18:04,000
about pre-zero or free page it has some

00:18:01,280 --> 00:18:04,000
limitations

00:18:04,480 --> 00:18:08,559
its current implementation is load

00:18:06,720 --> 00:18:11,840
friendly to huge trb

00:18:08,559 --> 00:18:14,000
file systems extra work is needed for

00:18:11,840 --> 00:18:16,799
this case

00:18:14,000 --> 00:18:17,280
and there is a core case if the free

00:18:16,799 --> 00:18:20,559
page

00:18:17,280 --> 00:18:24,080
a lot zeroed out in time

00:18:20,559 --> 00:18:25,520
it may lose the fact of boosting sends

00:18:24,080 --> 00:18:30,240
up

00:18:25,520 --> 00:18:30,240
so it's far from perfect

00:18:33,919 --> 00:18:38,400
our solutions has some pros the first

00:18:37,440 --> 00:18:41,440
point

00:18:38,400 --> 00:18:42,320
is transparent to guest nothing needs to

00:18:41,440 --> 00:18:45,360
be changed

00:18:42,320 --> 00:18:48,480
for guests so it's more appropriate

00:18:45,360 --> 00:18:51,600
for public cloud environment

00:18:48,480 --> 00:18:54,720
the second point dma operation in

00:18:51,600 --> 00:18:56,720
biostate can be handled correctly

00:18:54,720 --> 00:18:59,360
other solutions based on parallel

00:18:56,720 --> 00:19:03,200
virtualization need some workaround

00:18:59,360 --> 00:19:10,559
to forbid the dma operations in valve's

00:19:03,200 --> 00:19:12,720
execution state

00:19:10,559 --> 00:19:13,679
about the gpu virtual machine creation

00:19:12,720 --> 00:19:17,280
time

00:19:13,679 --> 00:19:20,320
there is some some room some room for

00:19:17,280 --> 00:19:21,520
further improvement we find the linux

00:19:20,320 --> 00:19:24,320
memory match

00:19:21,520 --> 00:19:27,120
memory management seems inefficient in

00:19:24,320 --> 00:19:30,080
device pass-through scenario

00:19:27,120 --> 00:19:31,360
for example all the features for page

00:19:30,080 --> 00:19:34,559
migration

00:19:31,360 --> 00:19:39,200
and memory archimedes

00:19:34,559 --> 00:19:41,679
are useless in this case

00:19:39,200 --> 00:19:44,240
so it's possible to make sense simpler

00:19:41,679 --> 00:19:47,840
and more efficient

00:19:44,240 --> 00:19:47,840
is in our future play

00:19:49,200 --> 00:19:52,480
one more thing we will contribute our

00:19:52,080 --> 00:19:55,360
work

00:19:52,480 --> 00:19:55,360
to upstream

00:20:00,640 --> 00:20:07,200
that's all for my presentation and

00:20:03,840 --> 00:20:09,280
this is my email if you have a question

00:20:07,200 --> 00:20:14,240
which i can't answer online

00:20:09,280 --> 00:20:14,240
you can send email to me thanks

00:20:18,840 --> 00:20:21,840
bye

00:20:24,400 --> 00:20:26,480

YouTube URL: https://www.youtube.com/watch?v=6wJwV7Q8FcY


