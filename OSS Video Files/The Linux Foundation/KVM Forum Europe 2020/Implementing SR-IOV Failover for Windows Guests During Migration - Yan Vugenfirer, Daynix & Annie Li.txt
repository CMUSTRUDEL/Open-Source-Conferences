Title: ImplementingÂ SR-IOV Failover for Windows Guests During Migration - Yan Vugenfirer, Daynix & Annie Li
Publication date: 2020-11-10
Playlist: KVM Forum Europe 2020
Description: 
	ImplementingÂ SR-IOV Failover for Windows Guests During Migration - Yan Vugenfirer, Daynix & Annie Li, Oracle
Captions: 
	00:00:07,839 --> 00:00:11,360
hello

00:00:08,639 --> 00:00:12,240
my name is jan vegan fear and i'm a ceo

00:00:11,360 --> 00:00:15,040
at denix

00:00:12,240 --> 00:00:16,800
and a contractor at red hat here with me

00:00:15,040 --> 00:00:18,160
is annie lee principal software engineer

00:00:16,800 --> 00:00:19,760
at oracle

00:00:18,160 --> 00:00:21,760
together we are going to talk about

00:00:19,760 --> 00:00:24,560
implementing srv failover

00:00:21,760 --> 00:00:26,560
for windows gas during the migration so

00:00:24,560 --> 00:00:27,680
during our presentation we are going to

00:00:26,560 --> 00:00:29,359
discuss

00:00:27,680 --> 00:00:30,880
real-time wind drivers in general and

00:00:29,359 --> 00:00:34,079
give you some

00:00:30,880 --> 00:00:36,079
overview on the virtual drive drivers

00:00:34,079 --> 00:00:37,760
we will talk about some windows gas

00:00:36,079 --> 00:00:38,879
terminology for the people that are less

00:00:37,760 --> 00:00:41,200
aware of that

00:00:38,879 --> 00:00:42,800
discuss the problem with the srv

00:00:41,200 --> 00:00:45,440
migration

00:00:42,800 --> 00:00:45,920
go about a little bit overview about

00:00:45,440 --> 00:00:48,399
different

00:00:45,920 --> 00:00:49,760
solutions and then we will discuss our

00:00:48,399 --> 00:00:51,520
solution

00:00:49,760 --> 00:00:54,160
so let's talk about retirement drivers

00:00:51,520 --> 00:00:56,559
first so here we have a link

00:00:54,160 --> 00:00:58,399
to the github uh where there is our

00:00:56,559 --> 00:01:00,320
option repository

00:00:58,399 --> 00:01:01,440
and this repository can find all the

00:01:00,320 --> 00:01:03,359
major drivers

00:01:01,440 --> 00:01:04,799
uh all the major retail drivers we have

00:01:03,359 --> 00:01:07,920
a retail network a

00:01:04,799 --> 00:01:09,840
block with a scasi and other drivers

00:01:07,920 --> 00:01:11,840
uh in this directory as well there are

00:01:09,840 --> 00:01:14,400
some other guest drivers that are not

00:01:11,840 --> 00:01:17,280
related to retail like panic driver

00:01:14,400 --> 00:01:20,080
and firmware complete and also some inf

00:01:17,280 --> 00:01:23,520
files that help us to define

00:01:20,080 --> 00:01:27,840
the system for example sm biasing for a

00:01:23,520 --> 00:01:27,840
q35 chipset or pci serial

00:01:28,560 --> 00:01:32,079
so what are those drivers and how they

00:01:31,119 --> 00:01:34,079
are built

00:01:32,079 --> 00:01:35,680
so the network and the storage driver

00:01:34,079 --> 00:01:38,079
they are built in architecture microsoft

00:01:35,680 --> 00:01:40,880
architecture called miniport drivers

00:01:38,079 --> 00:01:41,920
so each and their uh respected driver

00:01:40,880 --> 00:01:44,320
technology

00:01:41,920 --> 00:01:46,880
uh for network it's endius and for

00:01:44,320 --> 00:01:49,840
storage store port or sky support

00:01:46,880 --> 00:01:51,600
and other drivers are wdf drivers so

00:01:49,840 --> 00:01:53,680
it's a microsoft framework

00:01:51,600 --> 00:01:55,520
that allows you to easily write kernel

00:01:53,680 --> 00:01:57,840
drivers

00:01:55,520 --> 00:01:59,680
what are the supported oasis so we

00:01:57,840 --> 00:02:00,560
support all the oss starting from

00:01:59,680 --> 00:02:03,200
windows xp

00:02:00,560 --> 00:02:04,640
up to windows 10 and same with windows

00:02:03,200 --> 00:02:08,319
servers 2003

00:02:04,640 --> 00:02:11,039
to 2019 from the windows

00:02:08,319 --> 00:02:12,319
for windows 10 we also support support

00:02:11,039 --> 00:02:16,560
arm 64

00:02:12,319 --> 00:02:20,319
platform how can you contribute

00:02:16,560 --> 00:02:22,160
so please sign pull request uh the code

00:02:20,319 --> 00:02:23,440
changes should pass microsoft

00:02:22,160 --> 00:02:26,000
certifications

00:02:23,440 --> 00:02:27,040
but don't worry we are running ci on the

00:02:26,000 --> 00:02:30,239
upstream

00:02:27,040 --> 00:02:31,920
so you are covered for that and who are

00:02:30,239 --> 00:02:32,800
the contributors for the project during

00:02:31,920 --> 00:02:35,120
the years

00:02:32,800 --> 00:02:37,680
so main contributors are coming from red

00:02:35,120 --> 00:02:38,560
hat but we had also contributions from

00:02:37,680 --> 00:02:42,319
duty ozo

00:02:38,560 --> 00:02:46,400
oracle google microsoft aws

00:02:42,319 --> 00:02:49,519
and others so now let's talk about

00:02:46,400 --> 00:02:52,319
uh windows terms and then

00:02:49,519 --> 00:02:52,800
how the network driver architecture

00:02:52,319 --> 00:02:55,680
looks

00:02:52,800 --> 00:02:57,040
like in windows so you'll hear a lot

00:02:55,680 --> 00:02:59,280
during this presentation

00:02:57,040 --> 00:03:01,280
and just so what is andi's network

00:02:59,280 --> 00:03:04,879
driver interface specification

00:03:01,280 --> 00:03:07,280
it's also api for network drivers

00:03:04,879 --> 00:03:08,720
it's also the architecture of the

00:03:07,280 --> 00:03:10,640
network drivers and camera

00:03:08,720 --> 00:03:11,920
and there is andis.cs which is a

00:03:10,640 --> 00:03:14,239
microsoft driver

00:03:11,920 --> 00:03:15,120
that you can see in windows kernel and

00:03:14,239 --> 00:03:17,680
it implements

00:03:15,120 --> 00:03:19,120
part of the in this functionality so if

00:03:17,680 --> 00:03:21,680
you will go from

00:03:19,120 --> 00:03:23,200
bottom to top uh in the bottom you will

00:03:21,680 --> 00:03:24,959
see hardware devices

00:03:23,200 --> 00:03:27,280
and on top of them there is a mini port

00:03:24,959 --> 00:03:27,840
driver that usually supplied by the

00:03:27,280 --> 00:03:29,840
vendor

00:03:27,840 --> 00:03:31,120
and this driver drives the specific

00:03:29,840 --> 00:03:34,239
device

00:03:31,120 --> 00:03:36,080
in the simple case that you can see from

00:03:34,239 --> 00:03:38,400
the right side

00:03:36,080 --> 00:03:40,239
there are binded protocol drivers just

00:03:38,400 --> 00:03:42,159
on top of the mini core driver

00:03:40,239 --> 00:03:44,480
the more complicated case is when we

00:03:42,159 --> 00:03:45,920
have also intermediate driver

00:03:44,480 --> 00:03:47,840
and then the protocol drivers are

00:03:45,920 --> 00:03:50,400
binding to the intermediate driver

00:03:47,840 --> 00:03:51,519
so intermediate drivers towards the mini

00:03:50,400 --> 00:03:53,920
port driver has

00:03:51,519 --> 00:03:55,360
api of the protocol drivers so

00:03:53,920 --> 00:03:56,640
meaningful things that could stock the

00:03:55,360 --> 00:03:58,400
protocol driver

00:03:56,640 --> 00:04:00,080
and towards the protocol driver it has a

00:03:58,400 --> 00:04:02,159
mini port api so

00:04:00,080 --> 00:04:03,439
protocol drivers think that they talk to

00:04:02,159 --> 00:04:05,840
mini for driver

00:04:03,439 --> 00:04:07,439
why do we need such a thing so one of

00:04:05,840 --> 00:04:09,519
the example is the moves driver

00:04:07,439 --> 00:04:11,120
that can sit on top of several miniport

00:04:09,519 --> 00:04:15,439
drivers and present

00:04:11,120 --> 00:04:17,359
one virtual nic to the top layers

00:04:15,439 --> 00:04:19,759
also in the user space we have notify

00:04:17,359 --> 00:04:21,840
object notify object can get

00:04:19,759 --> 00:04:23,040
callbacks from the network configuration

00:04:21,840 --> 00:04:26,840
subsystem

00:04:23,040 --> 00:04:29,919
and act on on those callbacks

00:04:26,840 --> 00:04:34,560
by changing network configuration

00:04:29,919 --> 00:04:37,199
removing drivers installing drivers etc

00:04:34,560 --> 00:04:38,560
so how the util network net kvm driver

00:04:37,199 --> 00:04:40,800
for windows looks like

00:04:38,560 --> 00:04:42,160
so it's nds minifor driver as we

00:04:40,800 --> 00:04:44,240
mentioned before

00:04:42,160 --> 00:04:46,320
and the basic driver project package

00:04:44,240 --> 00:04:48,240
looks like you have the imf file

00:04:46,320 --> 00:04:49,440
which is an installation descriptor you

00:04:48,240 --> 00:04:51,759
have a sys file

00:04:49,440 --> 00:04:52,560
which is a driver binary you have a pdf

00:04:51,759 --> 00:04:54,960
file

00:04:52,560 --> 00:04:56,479
those are symbols for debugging and cut

00:04:54,960 --> 00:05:00,800
file which is the package

00:04:56,479 --> 00:05:03,840
digital signature so now let's discuss

00:05:00,800 --> 00:05:05,360
the problem why we even needed to do

00:05:03,840 --> 00:05:06,800
something

00:05:05,360 --> 00:05:08,880
so when we are talking about power

00:05:06,800 --> 00:05:12,240
utilized devices

00:05:08,880 --> 00:05:14,960
and drivers and all fully emulated

00:05:12,240 --> 00:05:15,759
devices all the code is resides inside

00:05:14,960 --> 00:05:18,800
of qmu

00:05:15,759 --> 00:05:19,440
and qmu also controls the data path so

00:05:18,800 --> 00:05:22,000
when we

00:05:19,440 --> 00:05:23,680
want to migrate such device it's just

00:05:22,000 --> 00:05:24,080
migrated with virtual machine all the

00:05:23,680 --> 00:05:27,360
device

00:05:24,080 --> 00:05:27,840
that is migrated fully controls the data

00:05:27,360 --> 00:05:30,880
path

00:05:27,840 --> 00:05:32,639
etc but when we have uh external

00:05:30,880 --> 00:05:34,800
hardware device when qmu does not

00:05:32,639 --> 00:05:35,600
control the data path the dma continues

00:05:34,800 --> 00:05:38,880
to run

00:05:35,600 --> 00:05:39,919
we need somehow to migrate the hardware

00:05:38,880 --> 00:05:41,360
state

00:05:39,919 --> 00:05:43,440
and therefore there are several

00:05:41,360 --> 00:05:44,080
solutions that were proposed over the

00:05:43,440 --> 00:05:46,320
years

00:05:44,080 --> 00:05:47,759
so we will have small overview about

00:05:46,320 --> 00:05:50,160
them

00:05:47,759 --> 00:05:51,120
somewhere more vendor specific we'll

00:05:50,160 --> 00:05:54,639
talk about

00:05:51,120 --> 00:05:56,960
uh what microsoft did in hyper-v and

00:05:54,639 --> 00:06:00,240
there's a solution in linux with three

00:05:56,960 --> 00:06:00,240
not that model

00:06:00,639 --> 00:06:04,960
so regarding previous effort i think

00:06:02,479 --> 00:06:05,600
almost every year on the kvm forum we

00:06:04,960 --> 00:06:07,600
have

00:06:05,600 --> 00:06:10,240
at least one presentation about slv

00:06:07,600 --> 00:06:13,440
migration so they are ranging between

00:06:10,240 --> 00:06:16,400
very vendor-specific or device-specific

00:06:13,440 --> 00:06:21,440
solutions to just now there's a parallel

00:06:16,400 --> 00:06:24,400
session about more generic solutions

00:06:21,440 --> 00:06:25,120
and now i am passing the presentation to

00:06:24,400 --> 00:06:27,199
annie

00:06:25,120 --> 00:06:29,199
and she's going to give the overview

00:06:27,199 --> 00:06:35,840
about the solutions that microsoft did

00:06:29,199 --> 00:06:35,840
and about our solution

00:06:40,720 --> 00:06:46,639
thanks yan hi everyone this is ani

00:06:44,000 --> 00:06:49,199
from oracle today i'm going to talk

00:06:46,639 --> 00:06:53,919
about the software solutions

00:06:49,199 --> 00:06:57,280
of srlv migration in windows

00:06:53,919 --> 00:06:58,479
so the these solutions focus on

00:06:57,280 --> 00:07:01,599
switching data paths

00:06:58,479 --> 00:07:03,280
seamlessly between vf network and the

00:07:01,599 --> 00:07:06,800
word out network

00:07:03,280 --> 00:07:07,520
before initiating the migration the vf

00:07:06,800 --> 00:07:10,400
network

00:07:07,520 --> 00:07:11,680
adapter will be hard to remove and all

00:07:10,400 --> 00:07:14,080
network traffic

00:07:11,680 --> 00:07:16,000
will be redirected to the vertical

00:07:14,080 --> 00:07:19,120
network data path

00:07:16,000 --> 00:07:22,080
after the migration is done the vf

00:07:19,120 --> 00:07:22,960
network adapter will be hard added under

00:07:22,080 --> 00:07:25,680
target

00:07:22,960 --> 00:07:26,240
so all the network data will go through

00:07:25,680 --> 00:07:30,720
the

00:07:26,240 --> 00:07:32,000
vf network path today i will talk about

00:07:30,720 --> 00:07:35,520
the

00:07:32,000 --> 00:07:38,240
existing solutions first there are the

00:07:35,520 --> 00:07:39,039
windows nick teaming windows max

00:07:38,240 --> 00:07:42,080
intermediate

00:07:39,039 --> 00:07:45,280
driver and hyper-v solution after that

00:07:42,080 --> 00:07:49,199
i will talk about the tonight down model

00:07:45,280 --> 00:07:49,199
in windows virtual driver

00:07:50,720 --> 00:07:57,520
so the windows snake teaming is built in

00:07:54,080 --> 00:08:00,720
windows since windows server 2012.

00:07:57,520 --> 00:08:03,199
it is similar to the boundary in linux

00:08:00,720 --> 00:08:05,360
and the windows snake teaming provides

00:08:03,199 --> 00:08:09,120
the fair lower capability

00:08:05,360 --> 00:08:12,319
user can put divert our network and the

00:08:09,120 --> 00:08:15,840
vf network into one team and

00:08:12,319 --> 00:08:19,360
configure the virtual network as standby

00:08:15,840 --> 00:08:22,400
so when the vf adapter is hard to remove

00:08:19,360 --> 00:08:24,560
the windows neck teaming will set the

00:08:22,400 --> 00:08:28,400
vertical adapter as

00:08:24,560 --> 00:08:31,440
active and switch the data path to the

00:08:28,400 --> 00:08:35,760
world at all after the

00:08:31,440 --> 00:08:39,200
vf adapter is hard added

00:08:35,760 --> 00:08:42,640
the windows negative will set the

00:08:39,200 --> 00:08:44,399
adapter as standby and then the data

00:08:42,640 --> 00:08:47,440
pathway goes through wf

00:08:44,399 --> 00:08:48,320
adapter so the windows nic teaming can

00:08:47,440 --> 00:08:50,880
be configured

00:08:48,320 --> 00:08:52,000
to through gui or the partial in the

00:08:50,880 --> 00:08:55,360
user space

00:08:52,000 --> 00:08:57,440
however we prefer the solution in kernel

00:08:55,360 --> 00:09:00,399
space to switch the data path

00:08:57,440 --> 00:09:00,959
automatically and the user doesn't need

00:09:00,399 --> 00:09:05,680
to spend

00:09:00,959 --> 00:09:09,040
time or effort in configuring user space

00:09:05,680 --> 00:09:10,800
the windows max intermediate driver is a

00:09:09,040 --> 00:09:13,680
kernel solution

00:09:10,800 --> 00:09:15,040
it is supposed to one or more virtual

00:09:13,680 --> 00:09:17,519
adapters

00:09:15,040 --> 00:09:18,880
based on the relationship between the

00:09:17,519 --> 00:09:22,320
virtual adapter and

00:09:18,880 --> 00:09:25,519
underlying network adapter it has

00:09:22,320 --> 00:09:28,640
the various models today i only

00:09:25,519 --> 00:09:32,399
introduced the 122 gel model for the

00:09:28,640 --> 00:09:35,040
srlv lamp migration this model

00:09:32,399 --> 00:09:36,720
is similar to the nic teaming in

00:09:35,040 --> 00:09:40,560
failover mode

00:09:36,720 --> 00:09:44,560
its architecture is also similar to the

00:09:40,560 --> 00:09:44,560
three network model in linux

00:09:45,440 --> 00:09:48,880
so this slide shows the architecture of

00:09:48,560 --> 00:09:52,399
the

00:09:48,880 --> 00:09:55,440
one to two max java model as you can see

00:09:52,399 --> 00:09:56,080
the bottom are the vertical network and

00:09:55,440 --> 00:09:58,399
the vf

00:09:56,080 --> 00:10:00,720
function network they have their own

00:09:58,399 --> 00:10:01,040
mini product drivers serve them that's a

00:10:00,720 --> 00:10:04,480
net

00:10:01,040 --> 00:10:07,360
qvm driver and a vf minipaw driver

00:10:04,480 --> 00:10:09,279
on top of them that's the one to two max

00:10:07,360 --> 00:10:12,160
intermediate driver

00:10:09,279 --> 00:10:13,760
this max driver exposed the protocol

00:10:12,160 --> 00:10:17,760
driver as a lower edge

00:10:13,760 --> 00:10:21,200
to bend to the underlying minipod driver

00:10:17,760 --> 00:10:21,519
also it's exposed the mini power driver

00:10:21,200 --> 00:10:24,720
as

00:10:21,519 --> 00:10:28,320
upper add to bend to the tcp

00:10:24,720 --> 00:10:29,279
and other protocols inside the max

00:10:28,320 --> 00:10:33,200
driver

00:10:29,279 --> 00:10:36,320
the mini pod virtual adapter

00:10:33,200 --> 00:10:39,680
band to the its own protocol driver

00:10:36,320 --> 00:10:41,440
internally so the ndc isn't aware of

00:10:39,680 --> 00:10:44,000
this bending

00:10:41,440 --> 00:10:44,560
the mass driver has full control on the

00:10:44,000 --> 00:10:48,240
network

00:10:44,560 --> 00:10:51,600
data here so it can switch the data path

00:10:48,240 --> 00:10:53,040
between the net qvm and we have mini

00:10:51,600 --> 00:10:56,880
power driver

00:10:53,040 --> 00:10:58,640
the uh the thing is one the underlying

00:10:56,880 --> 00:11:00,640
meaning project driver

00:10:58,640 --> 00:11:02,240
is supposed post and this file banning

00:11:00,640 --> 00:11:04,320
interface

00:11:02,240 --> 00:11:07,519
to avoid the confusion between the

00:11:04,320 --> 00:11:11,040
banning interface and this file with the

00:11:07,519 --> 00:11:12,079
in this version so i will only use the

00:11:11,040 --> 00:11:15,279
term end is

00:11:12,079 --> 00:11:16,560
here as you can see the protocol driver

00:11:15,279 --> 00:11:19,120
in mass driver

00:11:16,560 --> 00:11:20,959
is supposed under expanding interface as

00:11:19,120 --> 00:11:24,079
well as the tcp

00:11:20,959 --> 00:11:26,839
and other protocols this means this

00:11:24,079 --> 00:11:28,320
underlying meaning procedural bind into

00:11:26,839 --> 00:11:31,200
the

00:11:28,320 --> 00:11:33,040
max java protocol also bend to the up

00:11:31,200 --> 00:11:35,680
layer protocol

00:11:33,040 --> 00:11:36,800
however the mass driver only wants to

00:11:35,680 --> 00:11:40,320
use expose the

00:11:36,800 --> 00:11:43,440
virtual adapter here not the underlying

00:11:40,320 --> 00:11:43,760
mini power driver so a notified object

00:11:43,440 --> 00:11:47,519
is

00:11:43,760 --> 00:11:49,839
involved here to unbend the

00:11:47,519 --> 00:11:51,600
upper layer protocol driver from the

00:11:49,839 --> 00:11:55,279
underlying net qvm

00:11:51,600 --> 00:11:58,399
and we have manipulator here i will skip

00:11:55,279 --> 00:12:01,440
the details about the notify object

00:11:58,399 --> 00:12:03,920
and i will go into more depth on it

00:12:01,440 --> 00:12:03,920
later

00:12:04,720 --> 00:12:09,040
so this snapshot shows the binding

00:12:07,279 --> 00:12:12,480
details

00:12:09,040 --> 00:12:15,760
nick of our max driver so the

00:12:12,480 --> 00:12:16,880
they see they show their similar venue

00:12:15,760 --> 00:12:20,639
so i only paste

00:12:16,880 --> 00:12:21,519
one for both so the ethernet 14 and the

00:12:20,639 --> 00:12:25,200
ethernet

00:12:21,519 --> 00:12:28,079
file are the vf and the virtual network

00:12:25,200 --> 00:12:28,720
adapter connection they're only banned

00:12:28,079 --> 00:12:32,639
to the

00:12:28,720 --> 00:12:35,680
network adapter multiplexer protocol

00:12:32,639 --> 00:12:38,399
and srov network connection is

00:12:35,680 --> 00:12:39,839
generated by the link teaming of the max

00:12:38,399 --> 00:12:42,959
java model

00:12:39,839 --> 00:12:43,760
it blended to all necessary app layer

00:12:42,959 --> 00:12:47,120
protocols

00:12:43,760 --> 00:12:49,360
but it doesn't bend into the its own

00:12:47,120 --> 00:12:52,639
protocol driver

00:12:49,360 --> 00:12:54,639
so as we know that hyper-v supported the

00:12:52,639 --> 00:12:57,600
srl vlan migration

00:12:54,639 --> 00:12:58,800
so let's see how hyper-v works the

00:12:57,600 --> 00:13:01,920
important

00:12:58,800 --> 00:13:04,959
part of the vm network is the

00:13:01,920 --> 00:13:07,440
network virtual service client that's

00:13:04,959 --> 00:13:10,480
the net vic

00:13:07,440 --> 00:13:11,120
native aic can also communicate with the

00:13:10,480 --> 00:13:14,800
network

00:13:11,120 --> 00:13:15,200
virtual service provider through the vm

00:13:14,800 --> 00:13:17,839
bus

00:13:15,200 --> 00:13:20,880
in parent partition so that's the

00:13:17,839 --> 00:13:23,839
synthetic data path

00:13:20,880 --> 00:13:26,079
the network sc driver also communicates

00:13:23,839 --> 00:13:29,519
with the vf municipal driver

00:13:26,079 --> 00:13:32,560
for the srlv lab migration

00:13:29,519 --> 00:13:35,600
and the network also provides

00:13:32,560 --> 00:13:38,800
two installation files one is for

00:13:35,600 --> 00:13:41,199
installing the nano sd mini power driver

00:13:38,800 --> 00:13:42,399
another for installing the nano sc

00:13:41,199 --> 00:13:44,639
protocol driver

00:13:42,399 --> 00:13:46,079
both the two drivers share the same

00:13:44,639 --> 00:13:48,480
driver binary

00:13:46,079 --> 00:13:50,160
normally they are tagged their names are

00:13:48,480 --> 00:13:55,920
tagged with the

00:13:50,160 --> 00:13:55,920
in this version for example network c63

00:13:57,199 --> 00:14:02,959
so let's see the architectural hyper-v

00:14:00,199 --> 00:14:07,440
srvbrf failover

00:14:02,959 --> 00:14:11,279
so as you can see the vf miniport driver

00:14:07,440 --> 00:14:14,320
in hyperv exposed the bending interface

00:14:11,279 --> 00:14:17,120
operand as the ndcvf

00:14:14,320 --> 00:14:18,800
and the network c protocol driver is the

00:14:17,120 --> 00:14:22,639
only in protocol driver that

00:14:18,800 --> 00:14:24,800
is post and is a vf binding interface

00:14:22,639 --> 00:14:26,160
so this means that these two drivers can

00:14:24,800 --> 00:14:29,360
bend together

00:14:26,160 --> 00:14:32,560
it's cl exclusively and there's

00:14:29,360 --> 00:14:35,920
no notify object involved

00:14:32,560 --> 00:14:39,760
neither no new virtual adapter

00:14:35,920 --> 00:14:43,920
is generated also there's no band or

00:14:39,760 --> 00:14:45,760
teaming involved so the network protocol

00:14:43,920 --> 00:14:48,720
driver sitting in the same

00:14:45,760 --> 00:14:49,839
java binary as the network c mini power

00:14:48,720 --> 00:14:53,600
driver

00:14:49,839 --> 00:14:56,240
so as you can see because of this

00:14:53,600 --> 00:14:59,279
it is possible for the protocol driver

00:14:56,240 --> 00:15:00,959
to access the network data from network

00:14:59,279 --> 00:15:04,560
c mini power driver

00:15:00,959 --> 00:15:06,959
and forward them to the vf manipulator

00:15:04,560 --> 00:15:07,680
finally reach the virtual function

00:15:06,959 --> 00:15:10,800
device

00:15:07,680 --> 00:15:10,800
and the west versa

00:15:10,880 --> 00:15:15,760
so here is the network binding of

00:15:14,079 --> 00:15:19,120
hyper-v

00:15:15,760 --> 00:15:22,800
the hyper the ethernet file is the

00:15:19,120 --> 00:15:24,639
vf network connection it only bound into

00:15:22,800 --> 00:15:28,480
the network sd field over

00:15:24,639 --> 00:15:29,199
vs protocol driver the ethernet 4 is the

00:15:28,480 --> 00:15:32,000
hyper-v

00:15:29,199 --> 00:15:32,320
virtual adapter connection it abandoned

00:15:32,000 --> 00:15:35,440
to

00:15:32,320 --> 00:15:39,279
the tcp and other protocols

00:15:35,440 --> 00:15:42,560
but the hyper-v failover vf protocol

00:15:39,279 --> 00:15:44,959
driver is hidden to it

00:15:42,560 --> 00:15:46,560
so as we can see the mass driver model

00:15:44,959 --> 00:15:49,600
is complicated

00:15:46,560 --> 00:15:52,720
a new virtual adapter is generated

00:15:49,600 --> 00:15:54,480
this requires deployment of the new

00:15:52,720 --> 00:15:57,360
virtual miniport driver

00:15:54,480 --> 00:15:58,720
and the offload have to be restored in

00:15:57,360 --> 00:16:02,079
the max driver

00:15:58,720 --> 00:16:05,199
and also the notify object in the max

00:16:02,079 --> 00:16:06,800
model is complicated the installation

00:16:05,199 --> 00:16:10,399
involves installing the

00:16:06,800 --> 00:16:13,759
virtual adapter meaning how driver also

00:16:10,399 --> 00:16:14,720
upload the protocol driver so this means

00:16:13,759 --> 00:16:17,680
more efforts

00:16:14,720 --> 00:16:19,040
are required for the deployment of the

00:16:17,680 --> 00:16:22,639
max drive model

00:16:19,040 --> 00:16:26,240
the hyper-v model is simplified

00:16:22,639 --> 00:16:30,560
but it is only appropriate for hyper-v

00:16:26,240 --> 00:16:34,160
in linux the mailbox mechanism

00:16:30,560 --> 00:16:37,279
is implemented for the vf and pf

00:16:34,160 --> 00:16:41,120
communication however different

00:16:37,279 --> 00:16:44,959
mechanism is implemented for the hyper-v

00:16:41,120 --> 00:16:48,079
in windows as a result same device

00:16:44,959 --> 00:16:51,680
vf device are advertised by different

00:16:48,079 --> 00:16:54,440
device id and the windows vf

00:16:51,680 --> 00:16:55,600
mini project end up with the different

00:16:54,440 --> 00:16:58,959
implementations

00:16:55,600 --> 00:17:02,720
too as well as the banning interface

00:16:58,959 --> 00:17:04,760
are exposed differently this means we

00:17:02,720 --> 00:17:08,959
cannot use the hyper-v

00:17:04,760 --> 00:17:11,760
implementation directly in kvm

00:17:08,959 --> 00:17:12,480
so here the question comes what should

00:17:11,760 --> 00:17:16,480
we do

00:17:12,480 --> 00:17:17,039
for the srv lab migration human those

00:17:16,480 --> 00:17:21,600
guests

00:17:17,039 --> 00:17:24,319
in qvm the idea here is combine the

00:17:21,600 --> 00:17:25,360
maxjob mod and have a remodel solution

00:17:24,319 --> 00:17:28,079
together

00:17:25,360 --> 00:17:29,600
and that's the tornado dev model in

00:17:28,079 --> 00:17:32,880
windows

00:17:29,600 --> 00:17:35,919
so let's at first let's take a look

00:17:32,880 --> 00:17:38,240
at the regular network and

00:17:35,919 --> 00:17:39,840
virtual network and the virg virtual

00:17:38,240 --> 00:17:43,120
function network

00:17:39,840 --> 00:17:45,600
they have their own miniport driver to

00:17:43,120 --> 00:17:46,320
driver to serve them that's the net qvm

00:17:45,600 --> 00:17:49,919
and we are

00:17:46,320 --> 00:17:53,919
in project this drivers bend to the

00:17:49,919 --> 00:17:53,919
uplayer protocol directly

00:17:54,320 --> 00:17:57,880
let's see what's new in the two network

00:17:56,799 --> 00:18:02,400
model for the

00:17:57,880 --> 00:18:03,520
srlv lamp migration so a new virtual io

00:18:02,400 --> 00:18:06,799
protocol driver

00:18:03,520 --> 00:18:07,440
is implemented here it shares the same

00:18:06,799 --> 00:18:11,120
battery

00:18:07,440 --> 00:18:13,679
binary as the net qvm input driver

00:18:11,120 --> 00:18:16,640
so that's you that's very convenient for

00:18:13,679 --> 00:18:20,160
them to share the data between them

00:18:16,640 --> 00:18:22,080
also the vf miniport driver is post the

00:18:20,160 --> 00:18:25,200
banning interface and is

00:18:22,080 --> 00:18:26,799
here as you can see the word our

00:18:25,200 --> 00:18:30,240
protocol driver

00:18:26,799 --> 00:18:33,360
and the up layer tcp other protocol also

00:18:30,240 --> 00:18:36,960
expose the nd spanning interface

00:18:33,360 --> 00:18:39,360
that means the vertical meaning

00:18:36,960 --> 00:18:39,360
we have

00:18:41,280 --> 00:18:48,160
bend manipulated the tcp other particles

00:18:44,880 --> 00:18:50,559
so a notify object is implemented

00:18:48,160 --> 00:18:52,000
here to guarantee the binding between

00:18:50,559 --> 00:18:54,880
word l particle

00:18:52,000 --> 00:18:56,160
and we have mini powder i in one to one

00:18:54,880 --> 00:19:00,160
mode

00:18:56,160 --> 00:19:03,440
so in the notify object is a com object

00:19:00,160 --> 00:19:05,679
that sits in the dynamic link library

00:19:03,440 --> 00:19:07,360
when the word out protocol driver is

00:19:05,679 --> 00:19:10,799
being installed

00:19:07,360 --> 00:19:12,000
the network transport class installer

00:19:10,799 --> 00:19:14,880
will register

00:19:12,000 --> 00:19:16,640
a notified object for this what our

00:19:14,880 --> 00:19:19,760
protocol driver

00:19:16,640 --> 00:19:23,280
so when the vf device is

00:19:19,760 --> 00:19:26,640
hard added any new bending generated

00:19:23,280 --> 00:19:28,000
to the over our protocol driver although

00:19:26,640 --> 00:19:31,360
we have main project

00:19:28,000 --> 00:19:33,679
will be detected so if the bending is

00:19:31,360 --> 00:19:37,200
between the vertical protocol

00:19:33,679 --> 00:19:39,679
and we have mini port it will be allowed

00:19:37,200 --> 00:19:42,720
any other buildings bended to them will

00:19:39,679 --> 00:19:42,720
be disabled

00:19:43,679 --> 00:19:48,080
so this guaranteed the the banding

00:19:46,000 --> 00:19:50,080
between the vertical protocol driver and

00:19:48,080 --> 00:19:53,840
the vf meaningful driver

00:19:50,080 --> 00:19:53,840
are exclusive

00:19:54,000 --> 00:19:59,760
so the protocol driver is the important

00:19:57,440 --> 00:20:02,320
part in the two net dev models

00:19:59,760 --> 00:20:03,360
i will talk about it in more details

00:20:02,320 --> 00:20:05,840
here

00:20:03,360 --> 00:20:08,080
at first the protocol driver behave like

00:20:05,840 --> 00:20:10,640
a bridge between the

00:20:08,080 --> 00:20:14,000
mini port driver whatever mini power

00:20:10,640 --> 00:20:16,799
driver and the vf mini pro driver

00:20:14,000 --> 00:20:19,280
and also internet down model the vf

00:20:16,799 --> 00:20:20,320
adapter is coupled to the vertical

00:20:19,280 --> 00:20:23,919
adapter

00:20:20,320 --> 00:20:27,039
with the same mac address when the vf

00:20:23,919 --> 00:20:28,320
adapter is hard added the protocol

00:20:27,039 --> 00:20:31,280
driver will search

00:20:28,320 --> 00:20:34,320
for the matched mac address among all

00:20:31,280 --> 00:20:37,120
users to invert our network devices

00:20:34,320 --> 00:20:38,000
if there's matched one the protocol

00:20:37,120 --> 00:20:41,280
driver will

00:20:38,000 --> 00:20:44,320
bend it to the vf minipod driver

00:20:41,280 --> 00:20:47,120
and switch the datapath to it

00:20:44,320 --> 00:20:48,240
so when the vf network adapter is had

00:20:47,120 --> 00:20:50,320
removed

00:20:48,240 --> 00:20:51,280
the protocol driver will shut down

00:20:50,320 --> 00:20:54,240
expanding

00:20:51,280 --> 00:20:56,240
and switch the datapath back to the

00:20:54,240 --> 00:20:59,440
vertical

00:20:56,240 --> 00:21:02,159
for the ts network data the protocol

00:20:59,440 --> 00:21:05,280
driver will set the source handle of the

00:21:02,159 --> 00:21:08,080
net buffer list as the vf

00:21:05,280 --> 00:21:11,039
meaning part bending handle and forward

00:21:08,080 --> 00:21:11,760
the network data to the vf mini part

00:21:11,039 --> 00:21:15,039
through this

00:21:11,760 --> 00:21:18,559
handle for the rx network

00:21:15,039 --> 00:21:21,679
data the protocol driver will indicate

00:21:18,559 --> 00:21:24,400
all the network data from vf mean

00:21:21,679 --> 00:21:26,240
part to the app layer protocol through

00:21:24,400 --> 00:21:30,320
the vertical mini part

00:21:26,240 --> 00:21:30,799
handle the object identifiers are

00:21:30,320 --> 00:21:34,720
wrapped

00:21:30,799 --> 00:21:37,840
and forwarded offload are propagated

00:21:34,720 --> 00:21:41,760
in this same way and the work

00:21:37,840 --> 00:21:44,640
of the propagation in this case

00:21:41,760 --> 00:21:48,080
is much less than the restoring offload

00:21:44,640 --> 00:21:48,080
working in max driver

00:21:48,240 --> 00:21:55,360
so here is the bending details of the

00:21:52,240 --> 00:21:59,120
vertel srlv the

00:21:55,360 --> 00:22:01,600
ethernet file is the vf network

00:21:59,120 --> 00:22:03,520
it's only been to the red harvard outnet

00:22:01,600 --> 00:22:06,720
qm protocol driver

00:22:03,520 --> 00:22:10,000
it doesn't bend to any other drivers

00:22:06,720 --> 00:22:13,200
ethernet 11 is the vertical

00:22:10,000 --> 00:22:15,840
connection event to the tcp ip

00:22:13,200 --> 00:22:16,480
other particle but it doesn't bend to

00:22:15,840 --> 00:22:20,240
the

00:22:16,480 --> 00:22:20,240
its own protocol driver

00:22:20,559 --> 00:22:26,320
so you can see that's now that

00:22:23,600 --> 00:22:27,919
you know how the internet that model

00:22:26,320 --> 00:22:30,799
works in the

00:22:27,919 --> 00:22:33,039
windows vert l driver so i will hand it

00:22:30,799 --> 00:22:35,600
over to yen to talk about the current

00:22:33,039 --> 00:22:41,840
status of the two network module

00:22:35,600 --> 00:22:41,840
yeah please take it over thank you

00:22:45,280 --> 00:22:50,159
thank you very much amy so let's talk

00:22:48,640 --> 00:22:53,280
about the status and the

00:22:50,159 --> 00:22:55,120
known issues so the code for this

00:22:53,280 --> 00:22:56,799
solution is already upstream and you can

00:22:55,120 --> 00:22:59,039
use it

00:22:56,799 --> 00:23:00,159
and the known issues that we have is are

00:22:59,039 --> 00:23:02,320
the followings

00:23:00,159 --> 00:23:04,799
so first of all uh the support is only

00:23:02,320 --> 00:23:07,440
for the newer operating systems

00:23:04,799 --> 00:23:09,120
uh second the statistics for the vf is

00:23:07,440 --> 00:23:11,840
missing because they are not propagated

00:23:09,120 --> 00:23:14,000
to the net kvm driver

00:23:11,840 --> 00:23:15,280
we have some issues that are related on

00:23:14,000 --> 00:23:17,760
the order

00:23:15,280 --> 00:23:20,960
of starting of the devices so one of

00:23:17,760 --> 00:23:24,000
them is a dhtp issue that we might have

00:23:20,960 --> 00:23:25,600
and another thing that you should know

00:23:24,000 --> 00:23:27,600
is that

00:23:25,600 --> 00:23:28,720
if you want the solution to work on the

00:23:27,600 --> 00:23:30,960
specific

00:23:28,720 --> 00:23:31,760
vf you need to add the plug-and-play id

00:23:30,960 --> 00:23:35,679
of the cf

00:23:31,760 --> 00:23:39,679
either to the notification object code

00:23:35,679 --> 00:23:42,799
or to the registry

00:23:39,679 --> 00:23:43,120
uh regarding the current solution with

00:23:42,799 --> 00:23:46,159
the

00:23:43,120 --> 00:23:48,720
virtual netspec and net fs standby

00:23:46,159 --> 00:23:50,000
so we are not using this capability

00:23:48,720 --> 00:23:51,679
right now because there

00:23:50,000 --> 00:23:54,960
we are relying on the notification

00:23:51,679 --> 00:23:56,640
object to notify us about the appearance

00:23:54,960 --> 00:23:57,600
and disappearance of the devices in the

00:23:56,640 --> 00:24:00,960
system

00:23:57,600 --> 00:24:04,000
in the future we might use it

00:24:00,960 --> 00:24:07,120
some changes in the installation so

00:24:04,000 --> 00:24:09,760
first of all what we had before we had

00:24:07,120 --> 00:24:12,320
one inf file for the miniport driver

00:24:09,760 --> 00:24:13,039
and after those changes we have one inf

00:24:12,320 --> 00:24:15,200
file

00:24:13,039 --> 00:24:16,559
for the mini port driver and we have

00:24:15,200 --> 00:24:18,559
another inf

00:24:16,559 --> 00:24:20,080
for the protocol driver definition and

00:24:18,559 --> 00:24:24,240
for the notify object

00:24:20,080 --> 00:24:27,520
so this kind of a dual installation here

00:24:24,240 --> 00:24:29,360
regarding the hkl certification

00:24:27,520 --> 00:24:32,000
before we were certifying the miniport

00:24:29,360 --> 00:24:35,039
driver and the microsoft automatically

00:24:32,000 --> 00:24:36,960
review the test package and currently

00:24:35,039 --> 00:24:39,600
it's a two-step certification so first

00:24:36,960 --> 00:24:41,679
we need to verify the miniport driver

00:24:39,600 --> 00:24:43,760
and there is automatic review for that

00:24:41,679 --> 00:24:47,120
and then we should certify verify

00:24:43,760 --> 00:24:50,240
the whole solution and

00:24:47,120 --> 00:24:54,799
submit the test results and

00:24:50,240 --> 00:24:54,799
it's a manual review for the second time

00:24:55,120 --> 00:24:58,720
uh let's take a look at the performance

00:24:57,360 --> 00:25:03,440
numbers

00:24:58,720 --> 00:25:06,080
and here's the performance number on 100

00:25:03,440 --> 00:25:06,640
gigabit per second card uh between the

00:25:06,080 --> 00:25:09,520
hosts

00:25:06,640 --> 00:25:11,200
and uh you can see it a vm to remote

00:25:09,520 --> 00:25:13,279
host traffic

00:25:11,200 --> 00:25:15,679
uh so there are several things so first

00:25:13,279 --> 00:25:19,760
of all what we wanted to see is there's

00:25:15,679 --> 00:25:22,480
almost no degradation between

00:25:19,760 --> 00:25:23,919
the usage of the vf and the usage of the

00:25:22,480 --> 00:25:26,400
two network model

00:25:23,919 --> 00:25:27,039
in our solution and you can see it's

00:25:26,400 --> 00:25:29,360
here

00:25:27,039 --> 00:25:31,279
and in order to achieve it uh what we

00:25:29,360 --> 00:25:34,640
have to do is of course to

00:25:31,279 --> 00:25:36,799
uh propagate the oids correctly

00:25:34,640 --> 00:25:38,559
in order to ensure that that the offload

00:25:36,799 --> 00:25:40,480
is propagated correctly from

00:25:38,559 --> 00:25:42,400
offloads offload settings are correctly

00:25:40,480 --> 00:25:45,840
propagated from the vf

00:25:42,400 --> 00:25:48,960
to the protocol driver and um

00:25:45,840 --> 00:25:50,159
also ensure the correct settings of the

00:25:48,960 --> 00:25:54,000
jumbo frames

00:25:50,159 --> 00:25:57,039
so you see here use a 9000

00:25:54,000 --> 00:25:59,840
this is the data for a remote host

00:25:57,039 --> 00:26:02,480
vm as well you can see that the

00:25:59,840 --> 00:26:05,520
performance here is almost not

00:26:02,480 --> 00:26:07,279
diminished uh when we are using our

00:26:05,520 --> 00:26:11,440
solution

00:26:07,279 --> 00:26:14,799
and another results are vm to vm

00:26:11,440 --> 00:26:17,760
that are running on the remote costs

00:26:14,799 --> 00:26:18,799
so thank you very much uh if you have

00:26:17,760 --> 00:26:21,360
more questions

00:26:18,799 --> 00:26:22,080
please ask us in the chat or send us

00:26:21,360 --> 00:26:23,600
emails

00:26:22,080 --> 00:26:25,120
with questions and comments we'll be

00:26:23,600 --> 00:26:38,480
happy to answer them

00:26:25,120 --> 00:26:40,559
thank you very much

00:26:38,480 --> 00:26:40,559

YouTube URL: https://www.youtube.com/watch?v=X4tBkFvqB8s


