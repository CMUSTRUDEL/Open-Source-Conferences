Title: KVM Dirty Ring - A New Approach to Logging - Peter Xu, Red Hat
Publication date: 2020-11-12
Playlist: KVM Forum Europe 2020
Description: 
	KVM Dirty Ring - A New Approach to Logging - Peter Xu, Red Hat
Captions: 
	00:00:05,759 --> 00:00:10,080
uh hello everyone i'm peter schue from

00:00:07,759 --> 00:00:13,200
red hat virtualization team

00:00:10,080 --> 00:00:16,320
so today my session is going to be about

00:00:13,200 --> 00:00:20,400
kvm 30 interface which is a new

00:00:16,320 --> 00:00:20,400
interface for kvm 30 tracking

00:00:22,160 --> 00:00:25,439
so i'll start with some background

00:00:23,600 --> 00:00:29,119
information on migration

00:00:25,439 --> 00:00:30,240
and dirty tracking on and especially on

00:00:29,119 --> 00:00:32,719
the existing

00:00:30,240 --> 00:00:34,399
kvm category log and what we have done

00:00:32,719 --> 00:00:36,000
to improve it

00:00:34,399 --> 00:00:38,320
uh then we will try to i'll try to

00:00:36,000 --> 00:00:41,200
introduce kvm 30 ring

00:00:38,320 --> 00:00:42,000
and how it was implemented at last i'll

00:00:41,200 --> 00:00:44,320
share with

00:00:42,000 --> 00:00:47,840
with you some conclusions and future

00:00:44,320 --> 00:00:47,840
work that we might be able to do

00:00:50,879 --> 00:00:56,800
so this uh this

00:00:54,800 --> 00:00:59,920
workflow this is a workflow of the

00:00:56,800 --> 00:01:02,800
general vm live migration

00:00:59,920 --> 00:01:04,000
as we know that each my each migration

00:01:02,800 --> 00:01:06,240
will contain

00:01:04,000 --> 00:01:08,159
quite a few iterations the first

00:01:06,240 --> 00:01:10,159
iteration will be very special that we

00:01:08,159 --> 00:01:11,920
will migrate all the guests to pages

00:01:10,159 --> 00:01:14,240
because on the destination mode there is

00:01:11,920 --> 00:01:16,640
nothing yet

00:01:14,240 --> 00:01:17,520
starting from the second iteration we

00:01:16,640 --> 00:01:20,560
will need

00:01:17,520 --> 00:01:25,680
to synchronize 30 track information

00:01:20,560 --> 00:01:29,040
because since the migration is live

00:01:25,680 --> 00:01:30,240
the gaster is running concurrently when

00:01:29,040 --> 00:01:32,159
we migrate

00:01:30,240 --> 00:01:34,400
in the first round so there will be some

00:01:32,159 --> 00:01:37,280
new dirted pages

00:01:34,400 --> 00:01:37,920
we need to update these pages to latest

00:01:37,280 --> 00:01:40,960
on the

00:01:37,920 --> 00:01:44,720
destination node so that we it will

00:01:40,960 --> 00:01:44,720
always contain the latest information

00:01:44,799 --> 00:01:48,159
the synchronization of dirty track

00:01:47,040 --> 00:01:50,560
information

00:01:48,159 --> 00:01:53,840
is done previously by an actor called

00:01:50,560 --> 00:01:56,960
kvm gap30 log

00:01:53,840 --> 00:01:59,680
this arc tool majorly copies a 30-bit

00:01:56,960 --> 00:02:01,840
map from the kernel to user space

00:01:59,680 --> 00:02:03,040
for each of the bit it represents a

00:02:01,840 --> 00:02:06,079
guest page

00:02:03,040 --> 00:02:07,040
tells us whether that page is started in

00:02:06,079 --> 00:02:09,840
previous

00:02:07,040 --> 00:02:09,840
iteration

00:02:10,959 --> 00:02:17,840
so kvm 30 logging

00:02:14,800 --> 00:02:20,800
is not really ideal it was

00:02:17,840 --> 00:02:22,640
very it was very good initially when the

00:02:20,800 --> 00:02:26,319
vm is small

00:02:22,640 --> 00:02:30,160
but since the vm gets bigger

00:02:26,319 --> 00:02:33,360
the octal can get slower

00:02:30,160 --> 00:02:36,720
if we look slightly deep into the octal

00:02:33,360 --> 00:02:39,440
it materially does two things firstly

00:02:36,720 --> 00:02:41,840
it copy a dirty bitmap from the user

00:02:39,440 --> 00:02:44,959
from the kernel to user space

00:02:41,840 --> 00:02:46,480
the 30-bit map size is linear to guess

00:02:44,959 --> 00:02:50,080
the memory size

00:02:46,480 --> 00:02:53,360
so for a huge memory this copy procedure

00:02:50,080 --> 00:02:55,599
can take some time

00:02:53,360 --> 00:02:56,480
and there is also another step called

00:02:55,599 --> 00:03:00,239
step two

00:02:56,480 --> 00:03:02,319
which is to reset page protections

00:03:00,239 --> 00:03:03,599
for example uh if we use write

00:03:02,319 --> 00:03:06,720
protection

00:03:03,599 --> 00:03:09,200
to track uh guess the rights

00:03:06,720 --> 00:03:10,400
thing means you need to re regret

00:03:09,200 --> 00:03:14,000
protect all the guest

00:03:10,400 --> 00:03:16,959
pages this

00:03:14,000 --> 00:03:18,400
process can take a long time and what's

00:03:16,959 --> 00:03:21,440
worse is that

00:03:18,400 --> 00:03:24,480
step two will scan the whole bitmap

00:03:21,440 --> 00:03:27,200
with mmu logout trying to reprotect all

00:03:24,480 --> 00:03:27,200
those pages

00:03:27,360 --> 00:03:31,760
the thing is uh mmu lock is very

00:03:30,319 --> 00:03:35,840
expensive

00:03:31,760 --> 00:03:38,879
it plays a similar role to mm semper

00:03:35,840 --> 00:03:42,000
in general linux process

00:03:38,879 --> 00:03:43,680
because whatever we do like a normal

00:03:42,000 --> 00:03:45,920
page vote

00:03:43,680 --> 00:03:47,519
may take this lock to resolve the page

00:03:45,920 --> 00:03:52,080
vote

00:03:47,519 --> 00:03:54,720
so if kvm category log thread

00:03:52,080 --> 00:03:56,799
took this log for a long time it means

00:03:54,720 --> 00:03:58,840
all the rest of the vcpu thread can

00:03:56,799 --> 00:04:00,159
hang for a long time trying to take this

00:03:58,840 --> 00:04:02,159
log

00:04:00,159 --> 00:04:04,319
and after some measurement we can see

00:04:02,159 --> 00:04:07,840
that on some big systems

00:04:04,319 --> 00:04:09,120
with a huge memory this step can take a

00:04:07,840 --> 00:04:12,239
few seconds or more

00:04:09,120 --> 00:04:16,400
it means the vcpu can harm without

00:04:12,239 --> 00:04:19,680
responding to user interactions

00:04:16,400 --> 00:04:21,600
and and the workload can't stop that is

00:04:19,680 --> 00:04:26,160
not good

00:04:21,600 --> 00:04:28,880
so so

00:04:26,160 --> 00:04:29,919
the community tried to improve this

00:04:28,880 --> 00:04:33,040
condition

00:04:29,919 --> 00:04:34,880
by introducing more capabilities into

00:04:33,040 --> 00:04:38,560
kvm-30 logging

00:04:34,880 --> 00:04:41,280
i called it a few variances

00:04:38,560 --> 00:04:45,759
the first variance is a new capability

00:04:41,280 --> 00:04:49,360
called kvm cap manual dirty lock protect

00:04:45,759 --> 00:04:52,960
this capability uh tries to solve

00:04:49,360 --> 00:04:54,720
two things firstly it separates the

00:04:52,960 --> 00:04:57,600
steps

00:04:54,720 --> 00:04:58,639
as we know we have two steps in kvm 30

00:04:57,600 --> 00:05:03,039
log

00:04:58,639 --> 00:05:05,600
with this new capability we are able to

00:05:03,039 --> 00:05:07,039
separate these two steps into two

00:05:05,600 --> 00:05:09,759
outputs

00:05:07,039 --> 00:05:11,039
so the kvm get 30 lock will only collect

00:05:09,759 --> 00:05:16,320
30-bit map

00:05:11,039 --> 00:05:19,759
but we will keep the pages readable

00:05:16,320 --> 00:05:21,440
and we introduce a new actor called kvm

00:05:19,759 --> 00:05:23,680
clear dirty log

00:05:21,440 --> 00:05:26,160
and this actual will be responsible for

00:05:23,680 --> 00:05:29,360
reset page protections

00:05:26,160 --> 00:05:29,840
what's better is that we since this is a

00:05:29,360 --> 00:05:34,000
new

00:05:29,840 --> 00:05:37,360
interface we can try to

00:05:34,000 --> 00:05:40,320
let it take an extra range parameter

00:05:37,360 --> 00:05:42,960
so that we don't need to reset the page

00:05:40,320 --> 00:05:46,320
protection for the whole kvm slot

00:05:42,960 --> 00:05:48,000
uh we can we can reset it in a finer

00:05:46,320 --> 00:05:50,560
with the final granularity

00:05:48,000 --> 00:05:53,759
so that we only reset a subset of guest

00:05:50,560 --> 00:05:56,000
pages in the slot

00:05:53,759 --> 00:05:58,000
this new capability greatly improved the

00:05:56,000 --> 00:06:02,400
vm responsiveness

00:05:58,000 --> 00:06:06,000
and and is

00:06:02,400 --> 00:06:09,199
it's a vastly used i believe in

00:06:06,000 --> 00:06:14,240
in some in major new kernels

00:06:09,199 --> 00:06:17,680
however even with the variance 1

00:06:14,240 --> 00:06:20,560
we later on noticed the fact that even

00:06:17,680 --> 00:06:22,800
the enabling of kvm 30 logging is slow

00:06:20,560 --> 00:06:22,800
too

00:06:22,960 --> 00:06:26,800
it's because when we tries to apply the

00:06:26,080 --> 00:06:29,520
kvm

00:06:26,800 --> 00:06:30,639
log 30 pages onto the memory slot that's

00:06:29,520 --> 00:06:34,160
basically

00:06:30,639 --> 00:06:36,720
how we enable the 30 logging

00:06:34,160 --> 00:06:38,080
this step requires an initial reset of

00:06:36,720 --> 00:06:41,360
page protections

00:06:38,080 --> 00:06:42,720
on all guest rams for example all the

00:06:41,360 --> 00:06:44,560
rams were writable

00:06:42,720 --> 00:06:46,800
and when we start dirty logging we need

00:06:44,560 --> 00:06:49,520
to write protect all the pages

00:06:46,800 --> 00:06:51,759
and that process can take a long time as

00:06:49,520 --> 00:06:55,120
well

00:06:51,759 --> 00:06:57,520
uh so uh to solve this

00:06:55,120 --> 00:06:59,520
problem we introduced another new bit

00:06:57,520 --> 00:07:03,280
called kvm 30 login

00:06:59,520 --> 00:07:04,560
initially set this bit is very

00:07:03,280 --> 00:07:07,919
interesting because

00:07:04,560 --> 00:07:09,840
it sounds very simple but it really

00:07:07,919 --> 00:07:12,880
solves some problem

00:07:09,840 --> 00:07:13,199
the idea is very simple which is if this

00:07:12,880 --> 00:07:16,080
bit

00:07:13,199 --> 00:07:16,720
set we initialize all the 30-bit map

00:07:16,080 --> 00:07:19,919
with

00:07:16,720 --> 00:07:22,160
once which means

00:07:19,919 --> 00:07:23,599
uh we assume all the pages were dirty

00:07:22,160 --> 00:07:27,120
initially

00:07:23,599 --> 00:07:30,720
that's uh that's that actually won't

00:07:27,120 --> 00:07:34,240
affect major user space applications

00:07:30,720 --> 00:07:36,400
since for migration uh all the dirty

00:07:34,240 --> 00:07:39,199
bitmap will be set to one

00:07:36,400 --> 00:07:41,440
uh anyways in the user space so it won't

00:07:39,199 --> 00:07:44,639
affect the user space

00:07:41,440 --> 00:07:47,280
uh on my migrations

00:07:44,639 --> 00:07:48,319
but for kvm it is of it is a game

00:07:47,280 --> 00:07:50,800
because

00:07:48,319 --> 00:07:52,960
if all the dirty bit map is set it means

00:07:50,800 --> 00:07:56,319
we we don't need to write protect it

00:07:52,960 --> 00:07:58,160
when we enable this feature so we

00:07:56,319 --> 00:08:00,879
skip page protections in the first

00:07:58,160 --> 00:08:02,879
iteration which is quite interesting

00:08:00,879 --> 00:08:04,960
and after some measurement it was

00:08:02,879 --> 00:08:08,080
reported that migration starts

00:08:04,960 --> 00:08:09,840
even 10 times faster than previously uh

00:08:08,080 --> 00:08:13,120
without this beat

00:08:09,840 --> 00:08:16,080
for a gas store with a 128

00:08:13,120 --> 00:08:16,080
gigabyte memory

00:08:17,759 --> 00:08:24,720
so we can see that what we have we did

00:08:21,199 --> 00:08:27,919
uh try to evolve a kvmc

00:08:24,720 --> 00:08:31,599
30 log to make it better and

00:08:27,919 --> 00:08:35,760
to be more suitable for huge vms

00:08:31,599 --> 00:08:39,360
but we can see that 30b map is

00:08:35,760 --> 00:08:42,240
both the good and the evo it's good is

00:08:39,360 --> 00:08:43,599
in that it is an ideal structure for

00:08:42,240 --> 00:08:46,480
many reasons

00:08:43,599 --> 00:08:48,000
firstly it is very efficient because we

00:08:46,480 --> 00:08:50,320
used a single beat

00:08:48,000 --> 00:08:52,320
to represent a guest small page which is

00:08:50,320 --> 00:08:54,640
ideal

00:08:52,320 --> 00:08:56,800
and probably the most efficient way to

00:08:54,640 --> 00:08:58,240
store this data structure

00:08:56,800 --> 00:09:00,480
if we are going to cover the whole

00:08:58,240 --> 00:09:03,200
gastro memory

00:09:00,480 --> 00:09:06,160
and it's uh very easy to be serialized

00:09:03,200 --> 00:09:08,080
using atomic operations as well

00:09:06,160 --> 00:09:09,600
because basically we are playing with

00:09:08,080 --> 00:09:13,040
the bits

00:09:09,600 --> 00:09:16,399
uh however vms are getting bigger

00:09:13,040 --> 00:09:18,959
so as so are the dirty bit maps

00:09:16,399 --> 00:09:21,040
which means i like uh collecting 30

00:09:18,959 --> 00:09:25,120
bitmap will always be slower because we

00:09:21,040 --> 00:09:28,399
can't we always need to collect it

00:09:25,120 --> 00:09:30,800
per vm so it will be always a huge work

00:09:28,399 --> 00:09:33,279
and a huge overhead

00:09:30,800 --> 00:09:34,000
it will definitely take time and

00:09:33,279 --> 00:09:37,200
sometimes

00:09:34,000 --> 00:09:39,920
we need to sync 30-bit map somehow

00:09:37,200 --> 00:09:41,839
between source and destination like

00:09:39,920 --> 00:09:43,839
for post copy we need to discard 30

00:09:41,839 --> 00:09:46,640
bitmap and

00:09:43,839 --> 00:09:47,519
for like post copy recovery we also need

00:09:46,640 --> 00:09:51,360
to synchronize

00:09:47,519 --> 00:09:52,720
this such information so fundamentally

00:09:51,360 --> 00:09:56,240
the 30-bit map

00:09:52,720 --> 00:09:56,240
structure is hard to scale

00:09:57,839 --> 00:10:04,160
that's also

00:10:00,880 --> 00:10:06,480
the reason that maybe

00:10:04,160 --> 00:10:07,200
we can try to change this fundamental

00:10:06,480 --> 00:10:11,760
structure

00:10:07,200 --> 00:10:11,760
and think about something something else

00:10:11,839 --> 00:10:15,440
which is friendly to huge virtual

00:10:13,279 --> 00:10:19,839
machines

00:10:15,440 --> 00:10:19,839
uh here comes the kvm 30 ring

00:10:19,920 --> 00:10:25,839
this work uh was originated from

00:10:23,279 --> 00:10:28,160
late hal into a one seven or even

00:10:25,839 --> 00:10:31,360
earlier that i'm not aware of

00:10:28,160 --> 00:10:34,720
and later on paulo took it over

00:10:31,360 --> 00:10:37,440
and me so

00:10:34,720 --> 00:10:39,360
i i believe it was initially designed

00:10:37,440 --> 00:10:41,680
for colo

00:10:39,360 --> 00:10:42,640
which is the the so-called high

00:10:41,680 --> 00:10:45,680
availability

00:10:42,640 --> 00:10:48,160
infrastructure for

00:10:45,680 --> 00:10:48,160
kvm

00:10:49,040 --> 00:10:54,800
the design is quite straightforward but

00:10:52,320 --> 00:10:56,079
we can see that it's totally different

00:10:54,800 --> 00:10:59,279
because

00:10:56,079 --> 00:11:00,000
the 30-bit map is gone we used instead

00:10:59,279 --> 00:11:02,800
of the bitmap

00:11:00,000 --> 00:11:04,720
you use previous cpu rings to store

00:11:02,800 --> 00:11:08,000
dirty pfns

00:11:04,720 --> 00:11:11,040
uh pfn stands for page frame number

00:11:08,000 --> 00:11:13,519
or whatever we think just it's just a

00:11:11,040 --> 00:11:16,000
page index

00:11:13,519 --> 00:11:18,160
and the the most important thing is we

00:11:16,000 --> 00:11:21,600
use permissible rings

00:11:18,160 --> 00:11:22,560
this is funny because um it means the

00:11:21,600 --> 00:11:25,760
data structure

00:11:22,560 --> 00:11:29,440
is uh it's not global anymore

00:11:25,760 --> 00:11:31,519
and also this string can be configurable

00:11:29,440 --> 00:11:34,480
it's not linear to guest memory size at

00:11:31,519 --> 00:11:37,600
all it can be very small like 4k

00:11:34,480 --> 00:11:40,959
maybe 64k um

00:11:37,600 --> 00:11:42,800
so the second thing is we we

00:11:40,959 --> 00:11:45,600
start from the beginning we separate

00:11:42,800 --> 00:11:48,079
collection and page protection

00:11:45,600 --> 00:11:50,720
so we separate the step one and step two

00:11:48,079 --> 00:11:52,639
it can be done separately

00:11:50,720 --> 00:11:54,079
and since we are going to introduce this

00:11:52,639 --> 00:11:56,639
new structure

00:11:54,079 --> 00:11:59,519
we make it a shared data structure

00:11:56,639 --> 00:12:03,040
between the user space and the kernel

00:11:59,519 --> 00:12:06,079
by using mmap to map the same page

00:12:03,040 --> 00:12:08,800
in the kernel and in the user space

00:12:06,079 --> 00:12:10,880
so there is no extra copy when we fetch

00:12:08,800 --> 00:12:13,360
the information the user space adjuster

00:12:10,880 --> 00:12:16,720
needs to read the sum of the memory

00:12:13,360 --> 00:12:20,160
address to fetch this information

00:12:16,720 --> 00:12:25,839
and it was very thread friendly

00:12:20,160 --> 00:12:25,839
because we use the thread local buffers

00:12:26,639 --> 00:12:30,240
so this is how a kvm dirty ring looks

00:12:29,360 --> 00:12:32,079
like

00:12:30,240 --> 00:12:33,519
as we have already mentioned for each of

00:12:32,079 --> 00:12:37,360
these this view

00:12:33,519 --> 00:12:40,320
there will be 130 ring that bound to it

00:12:37,360 --> 00:12:43,200
for history of the ring there will be a

00:12:40,320 --> 00:12:43,200
multiple of

00:12:43,440 --> 00:12:49,760
small page frame number entries

00:12:47,040 --> 00:12:52,060
that will we can configure when we start

00:12:49,760 --> 00:12:53,120
the virtual machine

00:12:52,060 --> 00:12:55,839
[Music]

00:12:53,120 --> 00:12:57,279
we use the two extra bits in each of the

00:12:55,839 --> 00:13:00,320
pfn

00:12:57,279 --> 00:13:02,240
to keep the status of this entry

00:13:00,320 --> 00:13:04,480
so we'll talk about it later because

00:13:02,240 --> 00:13:08,560
each of the

00:13:04,480 --> 00:13:11,360
the page index can be either 30

00:13:08,560 --> 00:13:12,560
a dirty address or it can be something

00:13:11,360 --> 00:13:15,600
to be reset

00:13:12,560 --> 00:13:20,399
there is a state machine

00:13:15,600 --> 00:13:23,120
then we need to run

00:13:20,399 --> 00:13:24,240
about the state machine it is actually

00:13:23,120 --> 00:13:27,600
quite simple

00:13:24,240 --> 00:13:30,880
so for each of the entry it initializes

00:13:27,600 --> 00:13:32,839
with empty state which means it is free

00:13:30,880 --> 00:13:35,920
to use

00:13:32,839 --> 00:13:39,680
so uh when the kernel or when

00:13:35,920 --> 00:13:40,880
some vcpu tries to write a page and we

00:13:39,680 --> 00:13:43,920
trapped it

00:13:40,880 --> 00:13:48,000
we will try to insert a new 30 entry

00:13:43,920 --> 00:13:52,320
into the dirty ring of of this vcpu

00:13:48,000 --> 00:13:55,120
this is done by kvm of course and

00:13:52,320 --> 00:13:55,680
we will mark this entry as 30 along with

00:13:55,120 --> 00:13:59,120
the

00:13:55,680 --> 00:14:02,639
page index so after that

00:13:59,120 --> 00:14:06,560
the user will be able to

00:14:02,639 --> 00:14:09,440
see this newly dirtied page

00:14:06,560 --> 00:14:10,959
so it can try to collect this dirty pfn

00:14:09,440 --> 00:14:14,000
uh after that

00:14:10,959 --> 00:14:16,160
set the status bit to collect it

00:14:14,000 --> 00:14:17,680
which tells the kernel that okay i

00:14:16,160 --> 00:14:21,199
finished using this address

00:14:17,680 --> 00:14:21,600
you can try to recycle it so the last

00:14:21,199 --> 00:14:24,880
step

00:14:21,600 --> 00:14:28,000
is done by the kernel again we just try

00:14:24,880 --> 00:14:31,279
to read this pfn again

00:14:28,000 --> 00:14:34,639
so we know that this pfn has been used

00:14:31,279 --> 00:14:37,920
and consumed we reset this

00:14:34,639 --> 00:14:41,040
page that the pfm points to and

00:14:37,920 --> 00:14:44,320
we clear the entry go back

00:14:41,040 --> 00:14:45,920
which go back to the empty state so it's

00:14:44,320 --> 00:14:49,199
a quite simple state machine

00:14:45,920 --> 00:14:52,800
but i drew the this is how we

00:14:49,199 --> 00:14:56,560
generally uh split the steps

00:14:52,800 --> 00:14:59,839
of step one and step two as we

00:14:56,560 --> 00:14:59,839
talked previously

00:15:00,079 --> 00:15:03,680
this is a closer look but due to time

00:15:02,399 --> 00:15:06,800
reason i don't

00:15:03,680 --> 00:15:06,800
plan to dig into it

00:15:09,040 --> 00:15:13,279
and this is a comparison between the old

00:15:12,000 --> 00:15:15,670
dirty locking

00:15:13,279 --> 00:15:17,760
and the dirty ring

00:15:15,670 --> 00:15:20,240
[Music]

00:15:17,760 --> 00:15:21,199
anyone can feel free to reference these

00:15:20,240 --> 00:15:24,079
two

00:15:21,199 --> 00:15:24,720
so i'll skip it as well we can see that

00:15:24,079 --> 00:15:27,199
we have

00:15:24,720 --> 00:15:30,000
quite a lot of differences between the

00:15:27,199 --> 00:15:30,000
two interfaces

00:15:31,600 --> 00:15:36,720
so this is some interesting part because

00:15:34,800 --> 00:15:37,839
dirty ring is a totally totally new

00:15:36,720 --> 00:15:40,959
structure

00:15:37,839 --> 00:15:44,320
and it brings something

00:15:40,959 --> 00:15:47,279
new as well like

00:15:44,320 --> 00:15:49,600
the full event because we know 30 ring

00:15:47,279 --> 00:15:51,040
uh 30-bit map won't be able to get a

00:15:49,600 --> 00:15:53,519
full event because

00:15:51,040 --> 00:15:54,639
30-bit map was designed for whole gaster

00:15:53,519 --> 00:15:57,759
memory

00:15:54,639 --> 00:15:57,759
so it won't get full

00:15:58,560 --> 00:16:05,279
30 ring is different because it is a

00:16:01,759 --> 00:16:06,480
configured size the ring so it can get

00:16:05,279 --> 00:16:10,240
full

00:16:06,480 --> 00:16:10,639
as the cpu continuously to dirty the

00:16:10,240 --> 00:16:12,959
page

00:16:10,639 --> 00:16:13,920
uh and as long as we don't collect it

00:16:12,959 --> 00:16:17,440
fast enough

00:16:13,920 --> 00:16:21,759
it can get full and when it happens

00:16:17,440 --> 00:16:22,000
uh actually uh well what we do right now

00:16:21,759 --> 00:16:25,519
is

00:16:22,000 --> 00:16:30,079
to interrupt the right instruction

00:16:25,519 --> 00:16:33,440
uh so instead of continuing this vcpu

00:16:30,079 --> 00:16:36,399
we will do a vm exit and actually a user

00:16:33,440 --> 00:16:39,199
space access with reason kvm access

00:16:36,399 --> 00:16:40,880
dirty ring full this is a new uh newly

00:16:39,199 --> 00:16:44,240
introduced uh

00:16:40,880 --> 00:16:45,360
exit reason so that the user space will

00:16:44,240 --> 00:16:48,560
know that okay

00:16:45,360 --> 00:16:51,839
this vcpu got its ring full and

00:16:48,560 --> 00:16:53,600
is starting the ram quite a bit we will

00:16:51,839 --> 00:16:56,720
try to rip the dirty ring

00:16:53,600 --> 00:16:59,519
to at least the freezer move the slots

00:16:56,720 --> 00:17:00,000
send a new icon called kvm receptor t

00:16:59,519 --> 00:17:03,120
rings

00:17:00,000 --> 00:17:07,919
so that the kernel will recycle those

00:17:03,120 --> 00:17:10,720
dirty slots and continue the visit view

00:17:07,919 --> 00:17:11,839
and the vcpu will retry the previously

00:17:10,720 --> 00:17:15,120
interrupted

00:17:11,839 --> 00:17:18,240
instruction again so this

00:17:15,120 --> 00:17:21,520
is um the

00:17:18,240 --> 00:17:24,559
the whole process uh should be like

00:17:21,520 --> 00:17:26,240
quite natural right but uh what's funny

00:17:24,559 --> 00:17:29,600
is that

00:17:26,240 --> 00:17:32,880
we um accidentally introduced

00:17:29,600 --> 00:17:33,600
such a way that we can synchronously

00:17:32,880 --> 00:17:36,000
handle

00:17:33,600 --> 00:17:37,120
dirty tracking which leads to at least

00:17:36,000 --> 00:17:39,360
to another

00:17:37,120 --> 00:17:41,760
interesting fact about the side effect

00:17:39,360 --> 00:17:44,880
on auto converge maybe

00:17:41,760 --> 00:17:45,280
because this is not something we have

00:17:44,880 --> 00:17:48,799
with

00:17:45,280 --> 00:17:49,440
kvm30 logging because uh 30 logging

00:17:48,799 --> 00:17:51,679
cannot

00:17:49,440 --> 00:17:53,280
it's always asynchronous we cannot stop

00:17:51,679 --> 00:17:56,720
the vcpu

00:17:53,280 --> 00:18:00,720
but with km30 ring we can

00:17:56,720 --> 00:18:01,840
which means um unlike dirty logging 30

00:18:00,720 --> 00:18:05,120
ring tracking can

00:18:01,840 --> 00:18:07,520
blocks with pu and it will

00:18:05,120 --> 00:18:08,880
provide other converge with like a final

00:18:07,520 --> 00:18:12,080
granularity

00:18:08,880 --> 00:18:14,960
of what to throttle so

00:18:12,080 --> 00:18:15,840
auto converge was trying to throttle the

00:18:14,960 --> 00:18:19,520
whole system

00:18:15,840 --> 00:18:23,200
always for example we have a throttle

00:18:19,520 --> 00:18:26,640
parameter decides

00:18:23,200 --> 00:18:26,960
how many clock cycles this vcpu can use

00:18:26,640 --> 00:18:28,960
but

00:18:26,960 --> 00:18:30,400
this parameter is applied to all the

00:18:28,960 --> 00:18:35,039
vcpus

00:18:30,400 --> 00:18:37,200
this brings a problem so that if

00:18:35,039 --> 00:18:38,320
let's assume there are two threads one

00:18:37,200 --> 00:18:40,960
is a worker thread

00:18:38,320 --> 00:18:42,160
one is a gui thread the user is using

00:18:40,960 --> 00:18:45,200
the gui

00:18:42,160 --> 00:18:46,960
and if the workers run 30s the gas the

00:18:45,200 --> 00:18:50,559
memory too often

00:18:46,960 --> 00:18:53,840
or too heavy it will greatly

00:18:50,559 --> 00:18:57,280
uh that the

00:18:53,840 --> 00:19:01,520
auto converge throttle will be greatly

00:18:57,280 --> 00:19:04,720
increased boosted so the gui will start

00:19:01,520 --> 00:19:07,919
this is not good what we really want is

00:19:04,720 --> 00:19:09,440
we we make this worker thread slower and

00:19:07,919 --> 00:19:13,919
we keep the gui running

00:19:09,440 --> 00:19:13,919
so the user can still be responsive

00:19:14,160 --> 00:19:19,520
um so this is uh

00:19:17,520 --> 00:19:21,360
something that we can probably improve

00:19:19,520 --> 00:19:23,360
in the future for other converge with

00:19:21,360 --> 00:19:26,080
kvm dirty ring because we now

00:19:23,360 --> 00:19:27,840
have the ability to identify which vcpu

00:19:26,080 --> 00:19:30,080
is starting too fast

00:19:27,840 --> 00:19:31,120
also we have better responsiveness as

00:19:30,080 --> 00:19:34,799
well on the

00:19:31,120 --> 00:19:37,679
so-called trap points because previously

00:19:34,799 --> 00:19:38,880
when we do the other converged logic it

00:19:37,679 --> 00:19:42,640
is only done

00:19:38,880 --> 00:19:46,160
during dirty sync but dirty sync

00:19:42,640 --> 00:19:48,400
is very rare it only happens at

00:19:46,160 --> 00:19:50,000
the start of each iteration if you if we

00:19:48,400 --> 00:19:53,360
still remember the previous uh

00:19:50,000 --> 00:19:56,000
workflow of live migration but uh

00:19:53,360 --> 00:19:57,120
kvm dirty ring provides us a way that we

00:19:56,000 --> 00:20:00,320
can track the

00:19:57,120 --> 00:20:02,720
nearly every ram right of the vcpu

00:20:00,320 --> 00:20:04,799
not really literally but uh because

00:20:02,720 --> 00:20:08,480
every right can trigger a rainfall

00:20:04,799 --> 00:20:12,240
so it can be really responsive on

00:20:08,480 --> 00:20:14,240
evaluating which vcpu is heavily dirty

00:20:12,240 --> 00:20:16,960
in the ram

00:20:14,240 --> 00:20:17,520
so with kvm dirty ring a better auto

00:20:16,960 --> 00:20:20,159
converge

00:20:17,520 --> 00:20:23,520
can be really possible maybe we can have

00:20:20,159 --> 00:20:23,520
a version 2.0

00:20:23,760 --> 00:20:27,360
so that's something we can probably

00:20:26,159 --> 00:20:29,440
consider later

00:20:27,360 --> 00:20:32,080
because it will be a work totally in the

00:20:29,440 --> 00:20:32,080
user space

00:20:32,840 --> 00:20:37,360
um some quick conclusions

00:20:35,520 --> 00:20:38,720
so we know that we have quite a few

00:20:37,360 --> 00:20:42,400
benefits by

00:20:38,720 --> 00:20:45,760
introducing kvm dirty ring and it can be

00:20:42,400 --> 00:20:48,720
something more than we have because uh

00:20:45,760 --> 00:20:49,440
like as i said it was i believe it was

00:20:48,720 --> 00:20:51,760
in

00:20:49,440 --> 00:20:52,880
initially introduced by colo but maybe

00:20:51,760 --> 00:20:55,440
we can find some

00:20:52,880 --> 00:20:56,159
new uh new scenarios that we can use

00:20:55,440 --> 00:21:00,080
dirty ring

00:20:56,159 --> 00:21:02,080
that we haven't imagined before

00:21:00,080 --> 00:21:03,280
it definitely has reduced the memory

00:21:02,080 --> 00:21:06,080
footprint

00:21:03,280 --> 00:21:07,760
on the dirty tracking data structure so

00:21:06,080 --> 00:21:09,120
the synchronization is cheaper as well

00:21:07,760 --> 00:21:09,760
because it can run the background

00:21:09,120 --> 00:21:12,880
background

00:21:09,760 --> 00:21:16,640
reading some memory just to read some

00:21:12,880 --> 00:21:18,799
memory rather than some heavy alcohols

00:21:16,640 --> 00:21:21,440
and it is definitely much more friendly

00:21:18,799 --> 00:21:24,400
to huge vms

00:21:21,440 --> 00:21:26,000
so possible scenarios scenarios uh not

00:21:24,400 --> 00:21:26,640
not only the major thing should be

00:21:26,000 --> 00:21:28,880
called but

00:21:26,640 --> 00:21:30,320
uh there can be a lot of things that i

00:21:28,880 --> 00:21:33,039
already mentioned

00:21:30,320 --> 00:21:33,039
or even more

00:21:34,559 --> 00:21:39,919
uh there can be some future works about

00:21:37,600 --> 00:21:42,880
the cavem30 ring firstly i will

00:21:39,919 --> 00:21:44,720
i will try to move it forward on the

00:21:42,880 --> 00:21:48,720
review process and have it merged

00:21:44,720 --> 00:21:51,120
because it's still uh ongoing review

00:21:48,720 --> 00:21:53,919
uh also i would really like to uh

00:21:51,120 --> 00:21:56,960
probably after it's merged because uh

00:21:53,919 --> 00:21:59,919
um so anyway uh

00:21:56,960 --> 00:22:03,360
probably we we can try with more real

00:21:59,919 --> 00:22:05,840
world runs with the dirty ring

00:22:03,360 --> 00:22:07,120
so that we can see what's still missing

00:22:05,840 --> 00:22:10,559
what we can

00:22:07,120 --> 00:22:12,080
make it better so the

00:22:10,559 --> 00:22:13,840
the first thing i'm thinking about is

00:22:12,080 --> 00:22:16,720
whether we can support the non

00:22:13,840 --> 00:22:17,679
x86 because right now it only supports

00:22:16,720 --> 00:22:19,600
x86

00:22:17,679 --> 00:22:21,760
uh but we can think about other

00:22:19,600 --> 00:22:23,679
architectures um

00:22:21,760 --> 00:22:27,360
also we can have a paris appeal ring

00:22:23,679 --> 00:22:29,840
reset currently it was a kind of global

00:22:27,360 --> 00:22:30,640
that's another story but uh definitely

00:22:29,840 --> 00:22:33,760
not

00:22:30,640 --> 00:22:36,559
going to be covered in this talk but uh

00:22:33,760 --> 00:22:38,159
we can just think about something better

00:22:36,559 --> 00:22:41,039
probably after we have some

00:22:38,159 --> 00:22:43,280
real more real world runs to see what's

00:22:41,039 --> 00:22:45,280
the bottleneck

00:22:43,280 --> 00:22:47,039
for qmill there can be quite a few

00:22:45,280 --> 00:22:49,559
things to do firstly

00:22:47,039 --> 00:22:51,120
we can support the new interface in

00:22:49,559 --> 00:22:53,760
kvml.c

00:22:51,120 --> 00:22:54,400
that's something i have already done in

00:22:53,760 --> 00:22:57,200
my test

00:22:54,400 --> 00:22:59,200
branch so after the kernel series i'll

00:22:57,200 --> 00:23:02,559
try to move forward this one as well

00:22:59,200 --> 00:23:04,000
so it's a tick the the next ones will be

00:23:02,559 --> 00:23:05,679
question mark because i

00:23:04,000 --> 00:23:07,360
uh it's just something i was thinking

00:23:05,679 --> 00:23:10,559
about so

00:23:07,360 --> 00:23:12,880
if we know uh if we are familiar with

00:23:10,559 --> 00:23:15,679
cumula migration infrastructure

00:23:12,880 --> 00:23:17,200
we will see that not only the kvm layer

00:23:15,679 --> 00:23:19,440
there is a dirty bitmap

00:23:17,200 --> 00:23:20,880
we have 30 bitmap in quite a few other

00:23:19,440 --> 00:23:23,039
layers as well

00:23:20,880 --> 00:23:26,000
including the red block layer including

00:23:23,039 --> 00:23:26,000
the migration layer

00:23:26,080 --> 00:23:31,280
so uh how about we remove all these

00:23:29,520 --> 00:23:36,000
dirty bit maps

00:23:31,280 --> 00:23:37,600
so it's a it's a bigger work

00:23:36,000 --> 00:23:39,520
comparing to the first one because the

00:23:37,600 --> 00:23:41,760
interface is easy

00:23:39,520 --> 00:23:43,600
however if we want to replace all the

00:23:41,760 --> 00:23:45,520
dirty bit maps in the upper layers we

00:23:43,600 --> 00:23:49,039
probably need to think more

00:23:45,520 --> 00:23:52,559
at least on how it affects tc uh

00:23:49,039 --> 00:23:55,600
tcg uh not tcg um

00:23:52,559 --> 00:23:57,760
vga and other users we need to make sure

00:23:55,600 --> 00:23:59,679
they won't be affected but i believe

00:23:57,760 --> 00:24:01,760
migration should be the major one

00:23:59,679 --> 00:24:05,200
and also we need to think about

00:24:01,760 --> 00:24:07,840
something that we might have missed

00:24:05,200 --> 00:24:09,360
and the with all these things removed

00:24:07,840 --> 00:24:13,279
maybe pre-copy

00:24:09,360 --> 00:24:17,360
can be able to read 30 pages and kills

00:24:13,279 --> 00:24:20,240
so it will look more like postcopy but

00:24:17,360 --> 00:24:22,240
as a side effect of this all the

00:24:20,240 --> 00:24:25,120
converge will be on by default

00:24:22,240 --> 00:24:26,880
since rings can get full right as we

00:24:25,120 --> 00:24:27,840
have already mentioned the 30 bitmaps

00:24:26,880 --> 00:24:30,559
won't get full

00:24:27,840 --> 00:24:32,080
but rinse can so all the conversion will

00:24:30,559 --> 00:24:34,559
be a must

00:24:32,080 --> 00:24:35,440
if we remove all the dirty bitmap and

00:24:34,559 --> 00:24:39,360
use queues

00:24:35,440 --> 00:24:43,919
like ideally permissible kills

00:24:39,360 --> 00:24:46,720
to to cache the 30 pages

00:24:43,919 --> 00:24:48,400
so it can really looks look something

00:24:46,720 --> 00:24:52,960
like this but

00:24:48,400 --> 00:24:55,919
again this is uh imaginary world

00:24:52,960 --> 00:24:56,640
so we can have other solutions basically

00:24:55,919 --> 00:25:00,159
this is

00:24:56,640 --> 00:25:02,640
something we we may think about uh

00:25:00,159 --> 00:25:03,679
that can be really friendly to huge vms

00:25:02,640 --> 00:25:06,559
uh assuming

00:25:03,679 --> 00:25:07,679
it is coming like uh more people will be

00:25:06,559 --> 00:25:09,600
using huge vms and

00:25:07,679 --> 00:25:11,039
this seems to be a one solution

00:25:09,600 --> 00:25:14,640
comparing to the other one

00:25:11,039 --> 00:25:16,880
which uses post copy and

00:25:14,640 --> 00:25:18,559
even some more enhancements there to

00:25:16,880 --> 00:25:20,960
make post copy better

00:25:18,559 --> 00:25:23,200
and more suitable more responsive for

00:25:20,960 --> 00:25:26,480
huge vms and this one can be

00:25:23,200 --> 00:25:28,159
something as well that we try to

00:25:26,480 --> 00:25:30,640
throttle the source

00:25:28,159 --> 00:25:31,760
with cpu 30 rate but at the meantime the

00:25:30,640 --> 00:25:35,120
most important thing

00:25:31,760 --> 00:25:38,240
is to keep the host responsiveness

00:25:35,120 --> 00:25:41,360
by a smart logic

00:25:38,240 --> 00:25:42,400
on how to manipulate the dirty rings to

00:25:41,360 --> 00:25:47,360
control

00:25:42,400 --> 00:25:50,559
how the cpu runs so if with a very nice

00:25:47,360 --> 00:25:52,000
control maybe we can have very good

00:25:50,559 --> 00:25:55,279
responsiveness

00:25:52,000 --> 00:25:58,480
to control the vcpu but at the same time

00:25:55,279 --> 00:25:58,480
keeps the responsiveness

00:25:59,279 --> 00:26:02,640
so the last page is about uh some photo

00:26:01,760 --> 00:26:06,080
references

00:26:02,640 --> 00:26:08,000
uh anyone can check the latest version

00:26:06,080 --> 00:26:10,960
of kevin durant here in the first

00:26:08,000 --> 00:26:11,760
link and i also pasted the repos for

00:26:10,960 --> 00:26:14,640
testing just

00:26:11,760 --> 00:26:17,600
in case anyone is interested for both

00:26:14,640 --> 00:26:17,600
colonel and qmeo

00:26:17,840 --> 00:26:27,039
so that's all thank you very much

00:26:24,960 --> 00:26:27,039

YouTube URL: https://www.youtube.com/watch?v=9huThHYGJFI


