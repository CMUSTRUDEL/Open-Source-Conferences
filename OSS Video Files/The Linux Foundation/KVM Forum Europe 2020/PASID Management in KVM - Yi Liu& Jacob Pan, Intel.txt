Title: PASID Management in KVM - Yi Liu& Jacob Pan, Intel
Publication date: 2020-11-10
Playlist: KVM Forum Europe 2020
Description: 
	PASID Management in KVM - Yi Liu& Jacob Pan, Intel
Captions: 
	00:00:09,679 --> 00:00:12,880
hello everyone

00:00:10,800 --> 00:00:13,920
thanks for joining this session my name

00:00:12,880 --> 00:00:16,720
is elio from

00:00:13,920 --> 00:00:18,320
intel corporation today i'm going to

00:00:16,720 --> 00:00:21,279
share the pessimism management

00:00:18,320 --> 00:00:23,039
in kvm together with my colleague jacob

00:00:21,279 --> 00:00:25,359
pam

00:00:23,039 --> 00:00:26,960
this is the agenda for the session i

00:00:25,359 --> 00:00:30,080
will do a passive recap

00:00:26,960 --> 00:00:32,719
first and then review the past usage in

00:00:30,080 --> 00:00:34,239
shared virtual addressing and intel

00:00:32,719 --> 00:00:37,040
scalable aoe

00:00:34,239 --> 00:00:39,440
after that jacob would introduce more

00:00:37,040 --> 00:00:43,520
details on the passive management

00:00:39,440 --> 00:00:45,920
from software site passive stance for

00:00:43,520 --> 00:00:46,879
process address space id with the

00:00:45,920 --> 00:00:49,680
introduction of

00:00:46,879 --> 00:00:50,160
it dma remapping happens at the request

00:00:49,680 --> 00:00:53,280
id

00:00:50,160 --> 00:00:56,000
and passive governarity

00:00:53,280 --> 00:00:57,120
to achieve such isolation coronarity

00:00:56,000 --> 00:00:59,760
platform vendors

00:00:57,120 --> 00:01:00,559
should also support a new president

00:00:59,760 --> 00:01:03,039
table

00:01:00,559 --> 00:01:03,760
it is a part device table by hardware

00:01:03,039 --> 00:01:06,159
design

00:01:03,760 --> 00:01:07,200
and its storage in virtualization

00:01:06,159 --> 00:01:10,159
environment

00:01:07,200 --> 00:01:12,000
differs across wonders like intel

00:01:10,159 --> 00:01:15,200
virtualization technology for

00:01:12,000 --> 00:01:17,759
directed i o is maintained by host

00:01:15,200 --> 00:01:19,840
and the imminent translation but the

00:01:17,759 --> 00:01:23,600
forearm system memory management

00:01:19,840 --> 00:01:26,560
unit version 3 and mdimu

00:01:23,600 --> 00:01:27,600
is maintained by guests under lesser

00:01:26,560 --> 00:01:30,320
translation

00:01:27,600 --> 00:01:30,799
this difference results in different

00:01:30,320 --> 00:01:34,079
ways

00:01:30,799 --> 00:01:34,960
to set up for immunized translation for

00:01:34,079 --> 00:01:37,200
guests

00:01:34,960 --> 00:01:38,000
one is to bind against the person to

00:01:37,200 --> 00:01:41,119
host

00:01:38,000 --> 00:01:44,799
one by one allows it to bind the whole

00:01:41,119 --> 00:01:44,799
guest replacer table to host

00:01:44,880 --> 00:01:49,520
okay let's see the best usage in shadow

00:01:48,240 --> 00:01:52,479
water addressing

00:01:49,520 --> 00:01:54,000
the diagram in the left shows the steps

00:01:52,479 --> 00:01:57,520
to set up as we use

00:01:54,000 --> 00:01:59,280
it in native application will issue bind

00:01:57,520 --> 00:02:02,399
a reprocess

00:01:59,280 --> 00:02:05,520
request which goes into device driver

00:02:02,399 --> 00:02:08,879
and then will close into ime driver

00:02:05,520 --> 00:02:12,239
mdr will allocate a passive

00:02:08,879 --> 00:02:12,879
and bind the password with the cpu page

00:02:12,239 --> 00:02:16,000
table

00:02:12,879 --> 00:02:18,560
of the current process by creating a

00:02:16,000 --> 00:02:21,040
password entry in the password table

00:02:18,560 --> 00:02:22,000
then password is programmed to hardware

00:02:21,040 --> 00:02:25,200
device

00:02:22,000 --> 00:02:27,760
after that device is able to research

00:02:25,200 --> 00:02:29,760
the process virtual address space with

00:02:27,760 --> 00:02:32,879
the password

00:02:29,760 --> 00:02:36,560
when it comes to virtualization guest

00:02:32,879 --> 00:02:39,440
follows the same steps to set up for sva

00:02:36,560 --> 00:02:40,560
however hypervisor needs to travel

00:02:39,440 --> 00:02:43,840
guests

00:02:40,560 --> 00:02:44,239
specific operations in order to set up

00:02:43,840 --> 00:02:48,000
for

00:02:44,239 --> 00:02:50,160
nest translation for sova

00:02:48,000 --> 00:02:51,519
for example internationalization

00:02:50,160 --> 00:02:55,040
technology for

00:02:51,519 --> 00:02:57,360
directed i o requires to trap guests to

00:02:55,040 --> 00:02:58,319
pass the location and pass the cache

00:02:57,360 --> 00:03:01,519
flash

00:02:58,319 --> 00:03:02,640
to set up iomu nasty translation for

00:03:01,519 --> 00:03:06,239
each passage

00:03:02,640 --> 00:03:09,200
in host site for wonders which allows

00:03:06,239 --> 00:03:10,879
guests to maintain get past the table

00:03:09,200 --> 00:03:14,080
under net translation

00:03:10,879 --> 00:03:16,959
it needs it needs to trap the

00:03:14,080 --> 00:03:17,519
guest capacity table initialization to

00:03:16,959 --> 00:03:20,720
bind

00:03:17,519 --> 00:03:24,319
the whole guest surpassing table to host

00:03:20,720 --> 00:03:25,840
after set up for guest sov device would

00:03:24,319 --> 00:03:28,560
be able to access

00:03:25,840 --> 00:03:29,519
the virtual address space of the guest

00:03:28,560 --> 00:03:32,959
application

00:03:29,519 --> 00:03:36,720
with the password

00:03:32,959 --> 00:03:40,000
passed is also the foundation of

00:03:36,720 --> 00:03:42,879
intel scale of iov each assignable

00:03:40,000 --> 00:03:44,319
device interface will be associated with

00:03:42,879 --> 00:03:47,440
a whole surprises

00:03:44,319 --> 00:03:50,000
this association happens when its parent

00:03:47,440 --> 00:03:50,879
device is attached to a domain in

00:03:50,000 --> 00:03:54,159
auxiliary

00:03:50,879 --> 00:03:57,040
manner imu driver will allocate a

00:03:54,159 --> 00:03:59,760
default password for exterior domains

00:03:57,040 --> 00:04:00,959
with the default password available

00:03:59,760 --> 00:04:03,680
device interface

00:04:00,959 --> 00:04:04,560
accessories to the virtual virtual

00:04:03,680 --> 00:04:08,799
machine's

00:04:04,560 --> 00:04:11,280
guest physical address space as of now

00:04:08,799 --> 00:04:11,840
passive is no longer just taking a

00:04:11,280 --> 00:04:14,400
process

00:04:11,840 --> 00:04:16,239
address space it can also tag against

00:04:14,400 --> 00:04:20,400
the physical address space

00:04:16,239 --> 00:04:23,440
so it's actually i o address space id

00:04:20,400 --> 00:04:26,400
instead of just process address based id

00:04:23,440 --> 00:04:27,199
this is also the base of passive

00:04:26,400 --> 00:04:30,960
management

00:04:27,199 --> 00:04:34,080
in software since sva and the slv

00:04:30,960 --> 00:04:38,560
are both based on acid

00:04:34,080 --> 00:04:41,520
can they coexist the answer is yes

00:04:38,560 --> 00:04:43,120
since they are a second node o

00:04:41,520 --> 00:04:46,160
technologies

00:04:43,120 --> 00:04:46,479
for example we can set up for guest sva

00:04:46,160 --> 00:04:50,639
on

00:04:46,479 --> 00:04:52,400
assign the adis guest adjuster needs to

00:04:50,639 --> 00:04:56,000
follow the normal steps

00:04:52,400 --> 00:04:58,720
for sva set up however there is still a

00:04:56,000 --> 00:05:02,320
difference on the opacity program

00:04:58,720 --> 00:05:05,600
between physical functions and adis

00:05:02,320 --> 00:05:08,240
for physical functions passes from guest

00:05:05,600 --> 00:05:09,759
are programmed to hardware directory

00:05:08,240 --> 00:05:12,320
while for adis

00:05:09,759 --> 00:05:13,280
pass the program should be mediated by a

00:05:12,320 --> 00:05:15,919
host

00:05:13,280 --> 00:05:18,400
which means passage from guests should

00:05:15,919 --> 00:05:21,440
be converted to host passive

00:05:18,400 --> 00:05:24,400
first and then program to hardware

00:05:21,440 --> 00:05:25,280
my colleague how just talked about

00:05:24,400 --> 00:05:29,120
interesting

00:05:25,280 --> 00:05:33,039
command for this guest passage to host

00:05:29,120 --> 00:05:35,759
passive translation when it comes to

00:05:33,039 --> 00:05:37,039
the example in the diagram if we have

00:05:35,759 --> 00:05:40,240
zero programs

00:05:37,039 --> 00:05:43,440
guess the passing to device a and

00:05:40,240 --> 00:05:47,520
to divide it to retail zero

00:05:43,440 --> 00:05:51,039
for device a it will get a guess opacity

00:05:47,520 --> 00:05:52,880
while for three dell zero it will get a

00:05:51,039 --> 00:05:55,520
host passing them

00:05:52,880 --> 00:05:56,639
considering the host support for nasa

00:05:55,520 --> 00:05:59,759
translation

00:05:56,639 --> 00:06:03,360
and the i o page page

00:05:59,759 --> 00:06:04,319
request from device hoster will have

00:06:03,360 --> 00:06:07,360
both guest

00:06:04,319 --> 00:06:09,039
passed on the whole capacitor similar

00:06:07,360 --> 00:06:11,759
tenuously

00:06:09,039 --> 00:06:13,280
this may have potential conflict so we

00:06:11,759 --> 00:06:16,400
needed to get a proper

00:06:13,280 --> 00:06:18,880
passive management in hostel site this

00:06:16,400 --> 00:06:21,120
would be introduced by jacob

00:06:18,880 --> 00:06:24,160
hi to club i think you can take over it

00:06:21,120 --> 00:06:24,160
now thanks

00:06:25,759 --> 00:06:30,639
hi thanks e for the introduction again

00:06:28,639 --> 00:06:33,120
my name is jacob penn

00:06:30,639 --> 00:06:35,440
i will continue to talk about iosit and

00:06:33,120 --> 00:06:38,400
passat management

00:06:35,440 --> 00:06:39,520
this is a generic library we introduced

00:06:38,400 --> 00:06:42,479
since kernel

00:06:39,520 --> 00:06:43,759
version 505 but ever since we have been

00:06:42,479 --> 00:06:46,800
continuously

00:06:43,759 --> 00:06:50,560
improving it to meet against svm

00:06:46,800 --> 00:06:54,160
iova use cases so in the next few

00:06:50,560 --> 00:06:56,560
slides i will touch upon four aspects

00:06:54,160 --> 00:06:57,840
of the passive management the first one

00:06:56,560 --> 00:07:01,039
is gas to host

00:06:57,840 --> 00:07:05,440
passive mapping and then

00:07:01,039 --> 00:07:08,160
because ioasit is a system-wide resource

00:07:05,440 --> 00:07:11,520
we'll talk about the partitioning and

00:07:08,160 --> 00:07:14,960
namespaces we support

00:07:11,520 --> 00:07:18,240
and also io acid is just not a single

00:07:14,960 --> 00:07:19,759
simple number it's uh it has multiple

00:07:18,240 --> 00:07:22,479
users with hardware

00:07:19,759 --> 00:07:23,919
contacts associated with it so we'll

00:07:22,479 --> 00:07:27,280
talk about how

00:07:23,919 --> 00:07:30,639
to synchronize the oasis states

00:07:27,280 --> 00:07:33,280
when things change in the end

00:07:30,639 --> 00:07:34,800
we walk through a typical life cycle of

00:07:33,280 --> 00:07:37,280
io acid

00:07:34,800 --> 00:07:38,639
in the normal flow well we probably

00:07:37,280 --> 00:07:41,680
don't have time to talk about

00:07:38,639 --> 00:07:41,680
exception cases

00:07:41,840 --> 00:07:45,919
now we move on to a gas and host passive

00:07:43,919 --> 00:07:48,879
mapping so far there are two

00:07:45,919 --> 00:07:50,160
main approaches to support gas pass it

00:07:48,879 --> 00:07:52,000
the first one being

00:07:50,160 --> 00:07:54,400
shadow the gas capacity table this is

00:07:52,000 --> 00:07:56,160
used by vtd scalable mode

00:07:54,400 --> 00:07:59,280
the second is to bind the gas passage

00:07:56,160 --> 00:08:02,319
table and this is used by

00:07:59,280 --> 00:08:05,919
arms as mmbu version 3.

00:08:02,319 --> 00:08:06,479
so now looking from io acid point of

00:08:05,919 --> 00:08:09,599
view

00:08:06,479 --> 00:08:12,720
what are requirements because io acid

00:08:09,599 --> 00:08:14,879
is a generic infrastructure

00:08:12,720 --> 00:08:17,360
so if you look at a shadowed approach it

00:08:14,879 --> 00:08:20,479
requires a gas host passive transmission

00:08:17,360 --> 00:08:24,080
because gas opacity may not be equal

00:08:20,479 --> 00:08:27,360
to the host passage it also requires

00:08:24,080 --> 00:08:29,680
every single guest passive has a host

00:08:27,360 --> 00:08:33,360
passive backing

00:08:29,680 --> 00:08:35,760
because on scalable mode we support

00:08:33,360 --> 00:08:37,120
so-called shared work queue meaning a

00:08:35,760 --> 00:08:39,839
share a work you

00:08:37,120 --> 00:08:41,919
single work you can be assigned to

00:08:39,839 --> 00:08:44,880
multiple vms

00:08:41,919 --> 00:08:45,600
therefore in order to identify two dma

00:08:44,880 --> 00:08:49,120
streams

00:08:45,600 --> 00:08:52,399
with which passes

00:08:49,120 --> 00:08:55,760
the passive value must be unique

00:08:52,399 --> 00:08:56,959
that's why the passive value the passion

00:08:55,760 --> 00:09:00,800
has to be

00:08:56,959 --> 00:09:01,360
system-wide so there's also a little bit

00:09:00,800 --> 00:09:04,480
caveat

00:09:01,360 --> 00:09:07,519
when it comes down to pf assignment

00:09:04,480 --> 00:09:09,440
when you assign a pf to the guest the

00:09:07,519 --> 00:09:12,399
gas can directly program

00:09:09,440 --> 00:09:13,839
pass it onto the onto the physical

00:09:12,399 --> 00:09:16,560
device

00:09:13,839 --> 00:09:19,120
which is not mediated this is fine when

00:09:16,560 --> 00:09:22,000
you don't have any other devices

00:09:19,120 --> 00:09:23,120
to allocate passage from the host but

00:09:22,000 --> 00:09:26,240
when it comes to

00:09:23,120 --> 00:09:28,959
a mix with assignable device interfaces

00:09:26,240 --> 00:09:31,200
which is mediated device and they

00:09:28,959 --> 00:09:33,760
allocate surpass it from the host

00:09:31,200 --> 00:09:35,120
so they may create a conflict therefore

00:09:33,760 --> 00:09:39,760
some sort of enforcement

00:09:35,120 --> 00:09:39,760
must be done to prevent this conflict

00:09:40,080 --> 00:09:43,200
and if you look at the second approach

00:09:42,080 --> 00:09:46,800
bind basically

00:09:43,200 --> 00:09:49,040
bind as pass a table it's much simpler

00:09:46,800 --> 00:09:50,560
because the gas simply owns the capacity

00:09:49,040 --> 00:09:54,480
table and the host

00:09:50,560 --> 00:09:57,680
simply don't care so in terms of

00:09:54,480 --> 00:10:00,959
requirements for i o acid number one

00:09:57,680 --> 00:10:00,959
it says superset

00:10:02,399 --> 00:10:06,399
so io acid is a limited system-wide

00:10:05,360 --> 00:10:09,440
resource

00:10:06,399 --> 00:10:12,560
in the pcie spec pass it is 20 bits

00:10:09,440 --> 00:10:15,600
so we must partition them into groups

00:10:12,560 --> 00:10:19,040
in order to support multiple users

00:10:15,600 --> 00:10:22,079
in this example we have three ioc

00:10:19,040 --> 00:10:25,120
groups we call ioc sets

00:10:22,079 --> 00:10:28,640
set zero is used for host use

00:10:25,120 --> 00:10:32,480
usage such as native svm or native

00:10:28,640 --> 00:10:35,920
iova and i always say set one and two

00:10:32,480 --> 00:10:39,120
were given to the two vms we have here

00:10:35,920 --> 00:10:42,000
in terms of namespaces we do not support

00:10:39,120 --> 00:10:42,880
multiple namespaces each native

00:10:42,000 --> 00:10:47,600
environment has

00:10:42,880 --> 00:10:50,640
only one single space for the io acid

00:10:47,600 --> 00:10:54,240
so in this example the gas pass

00:10:50,640 --> 00:10:56,480
the vm1 could have ioc number one and

00:10:54,240 --> 00:10:59,519
vm2 can also have ios in

00:10:56,480 --> 00:11:02,959
number one but the backing io assets

00:10:59,519 --> 00:11:04,160
are different the host is 101 and 102

00:11:02,959 --> 00:11:07,200
respectively

00:11:04,160 --> 00:11:08,240
they must be unique to identify the dma

00:11:07,200 --> 00:11:11,600
streams that match

00:11:08,240 --> 00:11:14,880
different page tables

00:11:11,600 --> 00:11:17,040
so in terms of sizes we illustrate here

00:11:14,880 --> 00:11:20,480
the vm2 has a smaller

00:11:17,040 --> 00:11:23,519
quota for the ios set because

00:11:20,480 --> 00:11:25,040
the system administrator may give less

00:11:23,519 --> 00:11:28,320
resource to vm2 or

00:11:25,040 --> 00:11:28,800
vm1 that could be depending on how many

00:11:28,320 --> 00:11:33,440
assigned

00:11:28,800 --> 00:11:33,440
devices they have or other use cases

00:11:35,360 --> 00:11:41,360
so io acid is not a simple number

00:11:38,560 --> 00:11:42,480
on a real system it has many users and

00:11:41,360 --> 00:11:45,200
each user may have

00:11:42,480 --> 00:11:47,760
hardware context associated with it in

00:11:45,200 --> 00:11:50,480
this particular example

00:11:47,760 --> 00:11:51,279
we'll use intel's vtd scalable iov

00:11:50,480 --> 00:11:53,920
platform

00:11:51,279 --> 00:11:55,120
on this platform we could have five

00:11:53,920 --> 00:11:59,600
potential users

00:11:55,120 --> 00:12:03,839
of the io acid so

00:11:59,600 --> 00:12:06,959
for cpu it has a passive msr

00:12:03,839 --> 00:12:10,160
this is used for enqueue command

00:12:06,959 --> 00:12:12,880
they must be propagated or set up

00:12:10,160 --> 00:12:14,079
before inquid command can be used the

00:12:12,880 --> 00:12:17,839
vfio

00:12:14,079 --> 00:12:20,959
is a pure software construct however

00:12:17,839 --> 00:12:22,880
hypervisor must use vfio to

00:12:20,959 --> 00:12:24,000
communicate with the kernel for

00:12:22,880 --> 00:12:28,480
allocation

00:12:24,000 --> 00:12:32,000
free by numbing of the passive

00:12:28,480 --> 00:12:35,360
iomu of course stores the passive table

00:12:32,000 --> 00:12:36,720
and the context it performs the actual

00:12:35,360 --> 00:12:40,079
binombind

00:12:36,720 --> 00:12:43,519
of the guest page table

00:12:40,079 --> 00:12:45,920
and the pass it the kpm maintains

00:12:43,519 --> 00:12:47,839
a passive translation table that

00:12:45,920 --> 00:12:50,800
performs the guest to host passively

00:12:47,839 --> 00:12:50,800
passive translation

00:12:50,959 --> 00:12:56,880
device driver such as media device

00:12:54,480 --> 00:12:57,680
they program the actual password onto

00:12:56,880 --> 00:13:00,160
the device

00:12:57,680 --> 00:13:02,320
in order to generate dma request with

00:13:00,160 --> 00:13:05,279
passive stream

00:13:02,320 --> 00:13:06,240
so in order to synchronize all these

00:13:05,279 --> 00:13:09,200
users

00:13:06,240 --> 00:13:10,639
when passive state changes such as being

00:13:09,200 --> 00:13:13,920
unbind

00:13:10,639 --> 00:13:17,519
we must get some sort of a notification

00:13:13,920 --> 00:13:18,160
uh here we proposed a ios notification

00:13:17,519 --> 00:13:22,480
chain

00:13:18,160 --> 00:13:24,880
for each uh each vm for each ios is set

00:13:22,480 --> 00:13:25,680
uh for example when the password is

00:13:24,880 --> 00:13:29,440
unbind

00:13:25,680 --> 00:13:32,320
kvm will receive a buy notification

00:13:29,440 --> 00:13:32,880
event and then it will tear down its

00:13:32,320 --> 00:13:35,680
entry

00:13:32,880 --> 00:13:36,959
in the passive translation table there

00:13:35,680 --> 00:13:39,920
is also

00:13:36,959 --> 00:13:41,279
notification uh priorities and other

00:13:39,920 --> 00:13:44,639
things we will talk about

00:13:41,279 --> 00:13:44,639
in the upcoming slide

00:13:45,279 --> 00:13:48,800
so now let's talk about passes live

00:13:47,120 --> 00:13:50,959
hopefully it's a little more interesting

00:13:48,800 --> 00:13:53,920
than a bug's life

00:13:50,959 --> 00:13:55,040
on a typical usage it consists of five

00:13:53,920 --> 00:13:58,240
steps

00:13:55,040 --> 00:14:01,680
the first is initialization this is done

00:13:58,240 --> 00:14:03,040
on a per vm basis but on a per passive

00:14:01,680 --> 00:14:06,480
base it really has just

00:14:03,040 --> 00:14:07,120
four steps allocation deposit bind with

00:14:06,480 --> 00:14:10,800
a

00:14:07,120 --> 00:14:14,079
page table guest space table an unbind

00:14:10,800 --> 00:14:18,079
and a free the dma can start

00:14:14,079 --> 00:14:19,279
after step three so now let's walk

00:14:18,079 --> 00:14:22,560
through this example

00:14:19,279 --> 00:14:23,760
we use uh intel vtd scalable mode as an

00:14:22,560 --> 00:14:27,680
example

00:14:23,760 --> 00:14:30,000
here it so started with a vm issues

00:14:27,680 --> 00:14:31,120
allocation of the password once the pass

00:14:30,000 --> 00:14:33,760
is allocated

00:14:31,120 --> 00:14:34,959
it can be passed down to the vfi or to

00:14:33,760 --> 00:14:38,160
vfl interface

00:14:34,959 --> 00:14:41,519
through a bind or bind by optos

00:14:38,160 --> 00:14:44,320
this gets propagated to the iomu driver

00:14:41,519 --> 00:14:46,000
to performs the bind they basically set

00:14:44,320 --> 00:14:48,639
up to pass it

00:14:46,000 --> 00:14:49,440
in the passive table and also the nested

00:14:48,639 --> 00:14:52,800
translation

00:14:49,440 --> 00:14:56,160
is enabled once the passage is

00:14:52,800 --> 00:14:58,959
bound to a guest page table

00:14:56,160 --> 00:15:00,320
our new driver and the key image can

00:14:58,959 --> 00:15:03,120
notify

00:15:00,320 --> 00:15:03,600
the rest of the users of the status

00:15:03,120 --> 00:15:05,839
change

00:15:03,600 --> 00:15:08,160
so the passive is ready to go for all

00:15:05,839 --> 00:15:10,639
the users such as kvm

00:15:08,160 --> 00:15:11,279
so cpu can issue eq command or device

00:15:10,639 --> 00:15:13,839
driver

00:15:11,279 --> 00:15:15,279
can do can start doing dna on their

00:15:13,839 --> 00:15:18,399
passive

00:15:15,279 --> 00:15:21,199
so the notification can reach

00:15:18,399 --> 00:15:22,320
the other users such as kvn and device

00:15:21,199 --> 00:15:24,880
drivers

00:15:22,320 --> 00:15:25,519
of course during the initialization time

00:15:24,880 --> 00:15:28,160
kvm

00:15:25,519 --> 00:15:29,600
and device drivers must register

00:15:28,160 --> 00:15:32,720
notification

00:15:29,600 --> 00:15:35,920
those are are on the per vm

00:15:32,720 --> 00:15:38,240
or process and then basis we have a

00:15:35,920 --> 00:15:41,519
mechanism to identify

00:15:38,240 --> 00:15:44,240
the common token between users of the

00:15:41,519 --> 00:15:44,240
same process

00:15:46,160 --> 00:15:50,160
so the teardown is just a reverse

00:15:47,920 --> 00:15:51,199
process initiated from the vm to do

00:15:50,160 --> 00:15:53,360
unbind

00:15:51,199 --> 00:15:54,800
and pass under ibm driver performed

00:15:53,360 --> 00:15:58,079
onbind

00:15:54,800 --> 00:15:59,120
and then notified the kvm or device

00:15:58,079 --> 00:16:01,680
driver

00:15:59,120 --> 00:16:02,399
for example when kvm gets notified it

00:16:01,680 --> 00:16:05,600
will clear

00:16:02,399 --> 00:16:07,199
its passing table entry for that

00:16:05,600 --> 00:16:09,519
particular passage

00:16:07,199 --> 00:16:10,720
and we also implement the wrap counting

00:16:09,519 --> 00:16:13,920
mechanism to

00:16:10,720 --> 00:16:17,759
to make sure the passive life cycles are

00:16:13,920 --> 00:16:20,240
clearly aligned meaning not until

00:16:17,759 --> 00:16:21,120
the last user drops references after

00:16:20,240 --> 00:16:23,199
passive

00:16:21,120 --> 00:16:25,839
the pass will not be returned to the

00:16:23,199 --> 00:16:28,320
pool for reallocation

00:16:25,839 --> 00:16:30,320
so now that's that is update so our team

00:16:28,320 --> 00:16:32,480
has been working on scalable iov

00:16:30,320 --> 00:16:34,320
enabling shared virtual memory for the

00:16:32,480 --> 00:16:36,399
past two three years

00:16:34,320 --> 00:16:38,399
so we have made a lot of progress in our

00:16:36,399 --> 00:16:42,079
new driver vtd driver

00:16:38,399 --> 00:16:42,399
and user apis so here we listed a couple

00:16:42,079 --> 00:16:45,680
of

00:16:42,399 --> 00:16:48,839
related patches related to passive

00:16:45,680 --> 00:16:51,199
ios it core enhancements and vfile

00:16:48,839 --> 00:16:51,839
interfaces we also have we also have

00:16:51,199 --> 00:16:54,320
some

00:16:51,839 --> 00:16:55,680
opens we want to discuss in this forum

00:16:54,320 --> 00:16:58,560
the first one is

00:16:55,680 --> 00:17:00,240
should i oasi allocation exclusively

00:16:58,560 --> 00:17:03,519
being done so via file

00:17:00,240 --> 00:17:06,959
as we have today or we can have

00:17:03,519 --> 00:17:08,000
a standalone user api it has many

00:17:06,959 --> 00:17:11,439
implications

00:17:08,000 --> 00:17:15,120
for complexity and

00:17:11,439 --> 00:17:17,280
lifecycle management also

00:17:15,120 --> 00:17:18,559
how can we use it how can a user manage

00:17:17,280 --> 00:17:22,160
iosc quota

00:17:18,559 --> 00:17:24,799
from using from a system admin

00:17:22,160 --> 00:17:24,799
perspective

00:17:25,439 --> 00:17:31,520
so we have done some research on using

00:17:28,559 --> 00:17:32,160
our limit or c group but those seems to

00:17:31,520 --> 00:17:34,799
be

00:17:32,160 --> 00:17:35,440
too heavy-handed for a simple passing

00:17:34,799 --> 00:17:39,360
allocation

00:17:35,440 --> 00:17:41,520
quota management so finally let's

00:17:39,360 --> 00:17:43,600
summarize what we covered today

00:17:41,520 --> 00:17:44,799
so we talked about dma request please

00:17:43,600 --> 00:17:47,679
pass it with

00:17:44,799 --> 00:17:50,000
remapping this is done at the request id

00:17:47,679 --> 00:17:53,039
and the passive granularity

00:17:50,000 --> 00:17:56,880
pass it in linux is managed by io acid

00:17:53,039 --> 00:18:00,160
core we don't support

00:17:56,880 --> 00:18:01,280
multiple namespace for passing on on the

00:18:00,160 --> 00:18:03,679
host

00:18:01,280 --> 00:18:05,120
the cases also has its own passive name

00:18:03,679 --> 00:18:07,600
space

00:18:05,120 --> 00:18:08,320
passes could have multiple users each

00:18:07,600 --> 00:18:11,120
with

00:18:08,320 --> 00:18:12,559
hardware contacts association so we must

00:18:11,120 --> 00:18:15,600
synchronize them

00:18:12,559 --> 00:18:17,840
during setup and teardown

00:18:15,600 --> 00:18:20,799
so we use notification and rev counting

00:18:17,840 --> 00:18:22,640
to manage the life cycles

00:18:20,799 --> 00:18:24,559
i want to thank you for your attention

00:18:22,640 --> 00:18:27,120
and you i are ready

00:18:24,559 --> 00:18:28,559
for questions and more discussions on

00:18:27,120 --> 00:18:40,799
the two opens we have

00:18:28,559 --> 00:18:40,799

YouTube URL: https://www.youtube.com/watch?v=myzqu2ldEoM


