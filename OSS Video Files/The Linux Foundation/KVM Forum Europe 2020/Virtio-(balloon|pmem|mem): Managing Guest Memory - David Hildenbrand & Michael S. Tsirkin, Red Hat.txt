Title: Virtio-(balloon|pmem|mem): Managing Guest Memory - David Hildenbrand & Michael S. Tsirkin, Red Hat
Publication date: 2020-11-10
Playlist: KVM Forum Europe 2020
Description: 
	Virtio-(balloon|pmem|mem): Managing Guest Memory - David Hildenbrand & Michael S. Tsirkin, Red Hat
Captions: 
	00:00:08,880 --> 00:00:12,240
hi everybody

00:00:09,920 --> 00:00:13,360
welcome to this kvm forum 2020

00:00:12,240 --> 00:00:16,240
presentation

00:00:13,360 --> 00:00:18,080
about managing guest memory using rudio

00:00:16,240 --> 00:00:19,920
my name is david hillenbrand and today

00:00:18,080 --> 00:00:21,920
with me i'm giving this talk with my

00:00:19,920 --> 00:00:23,119
good surgeon

00:00:21,920 --> 00:00:26,880
hi i'm michael turkey and i'm

00:00:23,119 --> 00:00:26,880
distinguished engineer at redhat

00:00:27,359 --> 00:00:30,720
okay so let's get started what do we

00:00:29,840 --> 00:00:34,160
actually mean

00:00:30,720 --> 00:00:37,280
when we talk about managing guest memory

00:00:34,160 --> 00:00:40,079
so uh usually there are uh

00:00:37,280 --> 00:00:41,360
four different things we want to achieve

00:00:40,079 --> 00:00:44,879
with our virtual

00:00:41,360 --> 00:00:47,360
uh memory of our guests first of all

00:00:44,879 --> 00:00:48,879
we often want to speed up migration so

00:00:47,360 --> 00:00:50,640
if you take a look at the virtual

00:00:48,879 --> 00:00:51,360
machine from the hypervisor point of

00:00:50,640 --> 00:00:54,879
view

00:00:51,360 --> 00:00:57,280
any memory is possibly worth migrating

00:00:54,879 --> 00:00:59,840
because it might contain important data

00:00:57,280 --> 00:01:00,800
but in reality there is often quite some

00:00:59,840 --> 00:01:03,039
memory sitting

00:01:00,800 --> 00:01:04,400
inside virtual machines that is actually

00:01:03,039 --> 00:01:08,400
not worth migrating

00:01:04,400 --> 00:01:11,280
for example if it's simply free memory

00:01:08,400 --> 00:01:12,000
of course it's not that easy to identify

00:01:11,280 --> 00:01:15,280
that memory

00:01:12,000 --> 00:01:16,799
from the hypervisor and be sure that you

00:01:15,280 --> 00:01:19,439
don't lose any important data when

00:01:16,799 --> 00:01:22,640
migrating so you need some kind of

00:01:19,439 --> 00:01:25,600
handshake with your guest

00:01:22,640 --> 00:01:26,000
the second item is that we often have

00:01:25,600 --> 00:01:29,360
over

00:01:26,000 --> 00:01:32,560
commitment of memory and we want to

00:01:29,360 --> 00:01:34,320
avoid host swapping by any means that

00:01:32,560 --> 00:01:36,159
means whenever our hypervisor

00:01:34,320 --> 00:01:37,680
is running out of memory instead of

00:01:36,159 --> 00:01:40,479
going to swap we

00:01:37,680 --> 00:01:42,640
much rather want to temporarily steal

00:01:40,479 --> 00:01:44,720
unused memory from virtual machines

00:01:42,640 --> 00:01:46,479
because in practice it happens quite

00:01:44,720 --> 00:01:48,640
often that some virtual machines have

00:01:46,479 --> 00:01:49,280
quite some unused or free memory lying

00:01:48,640 --> 00:01:52,880
around

00:01:49,280 --> 00:01:56,000
that we can use instead of swapping

00:01:52,880 --> 00:01:56,719
the third item is that we often want to

00:01:56,000 --> 00:01:58,640
control

00:01:56,719 --> 00:02:03,040
or shrink the page cache in the virtual

00:01:58,640 --> 00:02:05,200
machine and also sometimes other caches

00:02:03,040 --> 00:02:06,159
the nature of a modern operating system

00:02:05,200 --> 00:02:08,560
is that

00:02:06,159 --> 00:02:09,920
it will try to make best use of all

00:02:08,560 --> 00:02:13,360
available memory

00:02:09,920 --> 00:02:15,599
um and that implies using it for caches

00:02:13,360 --> 00:02:17,760
in linux this is for example done by the

00:02:15,599 --> 00:02:18,560
page cache which will essentially over

00:02:17,760 --> 00:02:21,120
time

00:02:18,560 --> 00:02:23,200
consume most of your main memory but of

00:02:21,120 --> 00:02:26,160
course some data and caches can be

00:02:23,200 --> 00:02:28,560
dropped without affecting any workload

00:02:26,160 --> 00:02:30,000
but from a hypervisor point of view it's

00:02:28,560 --> 00:02:33,200
absolutely not clear

00:02:30,000 --> 00:02:35,519
which memory that might be

00:02:33,200 --> 00:02:38,000
used for cache inside a virtual machine

00:02:35,519 --> 00:02:40,640
can actually be dropped and there's also

00:02:38,000 --> 00:02:42,560
like no real interface to drop these

00:02:40,640 --> 00:02:45,280
caches

00:02:42,560 --> 00:02:47,360
and last uh but not least we often want

00:02:45,280 --> 00:02:48,160
to dynamically resize virtual machine

00:02:47,360 --> 00:02:50,959
memory

00:02:48,160 --> 00:02:51,840
that means we want to hot plug or hot

00:02:50,959 --> 00:02:53,599
unplug memory

00:02:51,840 --> 00:02:55,040
from virtual machines either

00:02:53,599 --> 00:02:57,120
automatically um

00:02:55,040 --> 00:02:58,159
for example if our virtual machine runs

00:02:57,120 --> 00:03:00,800
out of memory

00:02:58,159 --> 00:03:03,120
or manually by user request and this

00:03:00,800 --> 00:03:06,000
also needs some kind of collaboration

00:03:03,120 --> 00:03:08,239
with the guests corporation to make it

00:03:06,000 --> 00:03:08,239
work

00:03:10,000 --> 00:03:16,480
now the traditional mechanism to

00:03:13,440 --> 00:03:17,680
do all of these things is memory

00:03:16,480 --> 00:03:21,760
ballooning

00:03:17,680 --> 00:03:23,680
and just to give you a recap of what

00:03:21,760 --> 00:03:25,840
memory ballooning actually is

00:03:23,680 --> 00:03:27,440
it can be summarized as relocating

00:03:25,840 --> 00:03:29,280
physical memory between a virtual

00:03:27,440 --> 00:03:31,599
machine and its hypervisor

00:03:29,280 --> 00:03:33,599
and the idea is actually pretty simple

00:03:31,599 --> 00:03:35,840
inside your virtual machine memory

00:03:33,599 --> 00:03:38,879
you have something called the balloon

00:03:35,840 --> 00:03:41,280
and the balloon can inflate or deflate

00:03:38,879 --> 00:03:42,400
and all memory that's currently inflated

00:03:41,280 --> 00:03:44,720
inside of the balloon

00:03:42,400 --> 00:03:47,280
is not actually usable by the virtual

00:03:44,720 --> 00:03:49,760
machine but by the hypervisor instead

00:03:47,280 --> 00:03:50,560
that means when we inflate the balloon

00:03:49,760 --> 00:03:52,560
we give

00:03:50,560 --> 00:03:54,640
more memory back to the hypervisor and

00:03:52,560 --> 00:03:56,480
take it from the virtual machine

00:03:54,640 --> 00:03:58,480
and implement implementation in the

00:03:56,480 --> 00:03:59,200
operating system is actually also pretty

00:03:58,480 --> 00:04:01,439
simple

00:03:59,200 --> 00:04:03,040
so there is a driver running in the

00:04:01,439 --> 00:04:05,840
virtual machine in the guest operating

00:04:03,040 --> 00:04:08,560
system which simply allocates memory

00:04:05,840 --> 00:04:10,159
coordinates with the hypervisor and when

00:04:08,560 --> 00:04:13,439
it wants to

00:04:10,159 --> 00:04:15,519
get some memory back for uh deflation it

00:04:13,439 --> 00:04:16,239
simply freeze previously allocated

00:04:15,519 --> 00:04:18,880
memory

00:04:16,239 --> 00:04:20,560
after coordinating with the hypervisor

00:04:18,880 --> 00:04:22,320
and the whole mechanism so the size of

00:04:20,560 --> 00:04:24,000
the balloon is controlled by a so-called

00:04:22,320 --> 00:04:26,560
target balloon size

00:04:24,000 --> 00:04:29,040
which corresponds to a request from the

00:04:26,560 --> 00:04:31,520
hypervisor towards the virtual machine

00:04:29,040 --> 00:04:33,199
to change the size of the balloon now

00:04:31,520 --> 00:04:36,639
this idea is pretty neat

00:04:33,199 --> 00:04:39,199
and it has been used for decades already

00:04:36,639 --> 00:04:43,840
and this is also why it has been used

00:04:39,199 --> 00:04:43,840
for all of the use cases we just saw

00:04:44,160 --> 00:04:49,360
so for example when you want to

00:04:47,520 --> 00:04:51,520
dynamically resize the virtual machine

00:04:49,360 --> 00:04:53,440
memory you could dynamically inflate or

00:04:51,520 --> 00:04:57,040
deflate the balloon

00:04:53,440 --> 00:04:59,040
and also for all of the other um items i

00:04:57,040 --> 00:05:00,880
mentioned you you you might be able to

00:04:59,040 --> 00:05:03,680
use it to some extent

00:05:00,880 --> 00:05:06,080
uh i'm not going to go into detail here

00:05:03,680 --> 00:05:07,919
because uh there isn't a sufficient time

00:05:06,080 --> 00:05:09,280
to cover all of the details but there

00:05:07,919 --> 00:05:12,240
are a lot of issues

00:05:09,280 --> 00:05:12,720
and michael will talk about at least one

00:05:12,240 --> 00:05:15,759
issue

00:05:12,720 --> 00:05:15,759
regarding migration

00:05:17,759 --> 00:05:23,680
so what do we want to do instead

00:05:20,880 --> 00:05:24,160
of course this is not optimal so what we

00:05:23,680 --> 00:05:27,039
see

00:05:24,160 --> 00:05:28,880
are uh a plenty of extensions or new

00:05:27,039 --> 00:05:30,320
mechanism to hold make the whole thing

00:05:28,880 --> 00:05:34,080
work

00:05:30,320 --> 00:05:37,280
and uh one uh

00:05:34,080 --> 00:05:38,000
one part is extensions to existing water

00:05:37,280 --> 00:05:39,919
balloon giving

00:05:38,000 --> 00:05:41,680
it more interfaces or better suited

00:05:39,919 --> 00:05:43,759
interfaces to get the job done and

00:05:41,680 --> 00:05:47,199
michael will talk about these

00:05:43,759 --> 00:05:50,000
the other part is new

00:05:47,199 --> 00:05:52,000
mechanisms neo4j devices and one-handed

00:05:50,000 --> 00:05:54,479
pm on the other hand buddha mem

00:05:52,000 --> 00:06:07,840
which i will talk about after michael

00:05:54,479 --> 00:06:07,840
discussed widow balloon extensions

00:06:08,800 --> 00:06:16,080
so let's try to migrate a guest

00:06:13,199 --> 00:06:16,960
consider an example in this slide we

00:06:16,080 --> 00:06:19,280
start with an

00:06:16,960 --> 00:06:21,360
eight gigabyte virtual machine and when

00:06:19,280 --> 00:06:24,479
migrating it we inflate a balloon

00:06:21,360 --> 00:06:27,280
to four gigabytes and as a result only

00:06:24,479 --> 00:06:31,440
four gigabytes need to be migrated

00:06:27,280 --> 00:06:31,440
now after migration balloon is deflated

00:06:31,759 --> 00:06:36,479
here we immediately encounter problems

00:06:33,680 --> 00:06:38,080
how is the balloon size determined

00:06:36,479 --> 00:06:40,160
if you inflate it too much guests will

00:06:38,080 --> 00:06:42,160
slow down

00:06:40,160 --> 00:06:45,759
and if we inflate it too little then

00:06:42,160 --> 00:06:45,759
migration will take longer

00:06:47,120 --> 00:06:50,240
to address this issue we can give guests

00:06:49,440 --> 00:06:52,960
more control

00:06:50,240 --> 00:06:54,240
over the balloon and several ideas have

00:06:52,960 --> 00:06:57,440
to come together

00:06:54,240 --> 00:07:00,880
to result in our current solution

00:06:57,440 --> 00:07:04,319
first to inflate balloon

00:07:00,880 --> 00:07:06,960
we can make it as big as possible

00:07:04,319 --> 00:07:10,160
to fill up all of free memory naturally

00:07:06,960 --> 00:07:12,400
guest needs to change so

00:07:10,160 --> 00:07:16,240
a second idea is to let gas deflate at

00:07:12,400 --> 00:07:18,080
any time if that happens

00:07:16,240 --> 00:07:19,919
third idea is that the first thing guest

00:07:18,080 --> 00:07:21,599
does with a free page is to write some

00:07:19,919 --> 00:07:23,360
data into it

00:07:21,599 --> 00:07:24,960
because it's free so it has nothing in

00:07:23,360 --> 00:07:26,720
it so far

00:07:24,960 --> 00:07:28,560
and this is actually easy for the host

00:07:26,720 --> 00:07:31,599
to detect so we can do away with an

00:07:28,560 --> 00:07:33,520
explicit deflate operation

00:07:31,599 --> 00:07:34,720
the last idea is that we do not care

00:07:33,520 --> 00:07:37,120
about reporting

00:07:34,720 --> 00:07:38,639
small 4 kilobyte chunks of free ram

00:07:37,120 --> 00:07:39,440
which has spread all over the guest

00:07:38,639 --> 00:07:41,919
memory

00:07:39,440 --> 00:07:43,360
modern guests have compaction mechanisms

00:07:41,919 --> 00:07:46,479
which can with time

00:07:43,360 --> 00:07:48,479
help create large free pages

00:07:46,479 --> 00:07:49,840
an order of multiple megabytes let's

00:07:48,479 --> 00:07:51,280
only inflate

00:07:49,840 --> 00:07:53,120
with the largest possible chunk of

00:07:51,280 --> 00:07:57,120
memory that is still tracked by the

00:07:53,120 --> 00:08:00,160
guest memory management now combining

00:07:57,120 --> 00:08:02,240
these ideas we get a couple of features

00:08:00,160 --> 00:08:04,560
which are called free page hinting and

00:08:02,240 --> 00:08:08,160
three page reporting

00:08:04,560 --> 00:08:08,160
let's look at them in a bit more detail

00:08:10,160 --> 00:08:14,000
preparation is an older one of the

00:08:11,840 --> 00:08:15,680
features it was contributed by intel

00:08:14,000 --> 00:08:17,599
several years ago

00:08:15,680 --> 00:08:20,400
it was designed specifically to speed up

00:08:17,599 --> 00:08:22,160
migration here's how it works

00:08:20,400 --> 00:08:23,840
well it all starts by host right

00:08:22,160 --> 00:08:27,520
protecting all of its memory

00:08:23,840 --> 00:08:29,280
that's normal for migration host then

00:08:27,520 --> 00:08:31,520
sends the request to start three page

00:08:29,280 --> 00:08:33,360
hinting to the guest

00:08:31,520 --> 00:08:37,360
at this point guests will take all three

00:08:33,360 --> 00:08:39,279
pages and add them all to the balloon

00:08:37,360 --> 00:08:40,640
and host will start processing the pages

00:08:39,279 --> 00:08:42,159
sent to it i can

00:08:40,640 --> 00:08:43,760
marking them up so they won't be

00:08:42,159 --> 00:08:45,680
migrated

00:08:43,760 --> 00:08:47,920
and also write protecting them if not

00:08:45,680 --> 00:08:49,440
already protected

00:08:47,920 --> 00:08:51,920
meanwhile should guests need some free

00:08:49,440 --> 00:08:54,080
pages this simply starts using them

00:08:51,920 --> 00:08:56,160
even as host processing them at the same

00:08:54,080 --> 00:08:57,760
time

00:08:56,160 --> 00:09:00,000
now since the first thing that guest

00:08:57,760 --> 00:09:00,800
does when using a page is right into the

00:09:00,000 --> 00:09:02,880
page

00:09:00,800 --> 00:09:04,800
and this page is right protected this

00:09:02,880 --> 00:09:06,839
will cause a fault

00:09:04,800 --> 00:09:09,839
and host will mark page for migration

00:09:06,839 --> 00:09:09,839
again

00:09:11,040 --> 00:09:15,279
now unsurprisingly this feature is a

00:09:13,680 --> 00:09:17,839
good fit for migration

00:09:15,279 --> 00:09:18,720
it has no overhead unless requested

00:09:17,839 --> 00:09:21,040
hypervisor

00:09:18,720 --> 00:09:23,040
tracking is used for migration anyway so

00:09:21,040 --> 00:09:24,640
it's easy to reuse

00:09:23,040 --> 00:09:26,240
balloon can shrink without waiting for

00:09:24,640 --> 00:09:29,040
horse to make progress

00:09:26,240 --> 00:09:30,560
so guest is not slowing down on the

00:09:29,040 --> 00:09:32,720
other hand this lesson ideal is a

00:09:30,560 --> 00:09:34,959
solution for memory over commit

00:09:32,720 --> 00:09:36,640
hostnet needs to request it and it's not

00:09:34,959 --> 00:09:38,800
clear when is a good time to do it

00:09:36,640 --> 00:09:40,399
outside migration

00:09:38,800 --> 00:09:43,519
inflating all the free memory can get

00:09:40,399 --> 00:09:45,279
expensive should we do it often

00:09:43,519 --> 00:09:51,279
right tracking adds overhead to all

00:09:45,279 --> 00:09:53,360
guest rights even to non-free memory

00:09:51,279 --> 00:09:55,200
to solve some of these issues you have

00:09:53,360 --> 00:09:57,519
free page reporting which is a newer

00:09:55,200 --> 00:10:01,040
feature also from intel

00:09:57,519 --> 00:10:03,440
it's designed to solve the disadvantages

00:10:01,040 --> 00:10:05,200
of the hinting

00:10:03,440 --> 00:10:06,800
free page reporting is initiated by

00:10:05,200 --> 00:10:08,399
guest which takes action when a

00:10:06,800 --> 00:10:10,560
significant number of new free pages

00:10:08,399 --> 00:10:12,880
accumulates at this point

00:10:10,560 --> 00:10:14,959
just take some of these pages by default

00:10:12,880 --> 00:10:18,399
about 1 16 of the three pages

00:10:14,959 --> 00:10:20,079
and add them to the balloon processes

00:10:18,399 --> 00:10:21,600
the pages by marking them as free

00:10:20,079 --> 00:10:23,519
and then reports that page has been

00:10:21,600 --> 00:10:25,440
processed to the guest

00:10:23,519 --> 00:10:27,120
now unlike with painting guests then

00:10:25,440 --> 00:10:27,680
waits for host to process the reported

00:10:27,120 --> 00:10:30,160
pages

00:10:27,680 --> 00:10:31,040
before taking them out of the balloon

00:10:30,160 --> 00:10:34,560
and again

00:10:31,040 --> 00:10:36,480
when page is reused it is first of all

00:10:34,560 --> 00:10:39,760
written to and this causes a fault and

00:10:36,480 --> 00:10:39,760
memory allocation on the host

00:10:40,880 --> 00:10:44,399
now this reporting is a good piece for

00:10:43,040 --> 00:10:46,720
our commit

00:10:44,399 --> 00:10:48,880
because guest activates it the memory

00:10:46,720 --> 00:10:50,959
becomes free

00:10:48,880 --> 00:10:52,399
host implementation is also simple

00:10:50,959 --> 00:10:55,600
there's no need to play with right

00:10:52,399 --> 00:10:59,360
tracking which is easy to get wrong

00:10:55,600 --> 00:11:00,000
and we also do not need to track guest

00:10:59,360 --> 00:11:01,680
rights to use

00:11:00,000 --> 00:11:03,680
pages which is often most of guest

00:11:01,680 --> 00:11:05,200
memory rights

00:11:03,680 --> 00:11:06,800
on the other hand this feature has

00:11:05,200 --> 00:11:09,519
overhead to memory intensive workloads

00:11:06,800 --> 00:11:12,240
at all times not just during migration

00:11:09,519 --> 00:11:13,760
and also shrinking must wait for the

00:11:12,240 --> 00:11:15,760
host which can be blocked by host

00:11:13,760 --> 00:11:18,480
scheduler so it's less of a good feed

00:11:15,760 --> 00:11:18,480
for migration

00:11:19,360 --> 00:11:23,200
so these are the two hinting features

00:11:21,519 --> 00:11:25,360
that we have

00:11:23,200 --> 00:11:27,200
before we move on i just wanted to

00:11:25,360 --> 00:11:30,160
mention a sundry list

00:11:27,200 --> 00:11:30,959
of all the balloon related to the items

00:11:30,160 --> 00:11:34,800
that we have

00:11:30,959 --> 00:11:37,120
and some of them we have had for years

00:11:34,800 --> 00:11:39,519
first of all guest repage solutions do

00:11:37,120 --> 00:11:43,440
not have a way to shrink guest caches

00:11:39,519 --> 00:11:45,680
like regular inflate does

00:11:43,440 --> 00:11:47,600
so we can just bypass the page cache and

00:11:45,680 --> 00:11:50,639
this is virtio premium which david is

00:11:47,600 --> 00:11:52,560
going to talk about a little bit later

00:11:50,639 --> 00:11:54,839
that's one solution but what exactly

00:11:52,560 --> 00:11:56,959
about for example application page

00:11:54,839 --> 00:12:00,160
caches

00:11:56,959 --> 00:12:01,839
also balloon still doesn't really

00:12:00,160 --> 00:12:04,720
support

00:12:01,839 --> 00:12:06,320
a device pass through with the fio

00:12:04,720 --> 00:12:07,920
supporting that is not easy

00:12:06,320 --> 00:12:11,839
it needs some someone who's ready to

00:12:07,920 --> 00:12:11,839
hack host side the menu the imb drivers

00:12:11,920 --> 00:12:15,600
there's also a slew of old balloon

00:12:13,519 --> 00:12:17,040
interface bugs that no one seems to want

00:12:15,600 --> 00:12:20,720
to fix

00:12:17,040 --> 00:12:24,480
for example virtual machine memory size

00:12:20,720 --> 00:12:26,240
with inflate and deflate is very limited

00:12:24,480 --> 00:12:28,079
cast and host page size is assumed to

00:12:26,240 --> 00:12:30,639
always be four kilobytes

00:12:28,079 --> 00:12:32,000
which is not always the case out of

00:12:30,639 --> 00:12:34,000
memory handling

00:12:32,000 --> 00:12:35,200
is present in linux but is

00:12:34,000 --> 00:12:37,360
underspecified

00:12:35,200 --> 00:12:40,160
and contributions would be most

00:12:37,360 --> 00:12:40,160
importantly welcome

00:12:41,279 --> 00:12:47,120
okay let's talk about virto piano next

00:12:44,720 --> 00:12:48,560
so the basic idea of virtual pmm is

00:12:47,120 --> 00:12:51,600
actually pretty simple

00:12:48,560 --> 00:12:53,519
instead of exposing your disk image via

00:12:51,600 --> 00:12:54,720
brutal blocker similar towards your

00:12:53,519 --> 00:12:57,760
virtual machine

00:12:54,720 --> 00:12:59,839
instead you map the file directly into a

00:12:57,760 --> 00:13:02,480
guest physical address space

00:12:59,839 --> 00:13:03,920
and make the guest access that disk

00:13:02,480 --> 00:13:06,959
image similar to an

00:13:03,920 --> 00:13:09,680
nvdimm so a persistent memory or also

00:13:06,959 --> 00:13:11,120
sometimes referred as decks like direct

00:13:09,680 --> 00:13:14,079
access

00:13:11,120 --> 00:13:15,279
however in contrast to uh real emulated

00:13:14,079 --> 00:13:18,560
nvidia

00:13:15,279 --> 00:13:21,200
we get the benefit of flushes or

00:13:18,560 --> 00:13:23,040
flushing rights to this to actually work

00:13:21,200 --> 00:13:25,519
properly and we're gonna talk about that

00:13:23,040 --> 00:13:25,519
in a sec

00:13:27,200 --> 00:13:31,680
so if we take a look at our um guest

00:13:30,240 --> 00:13:34,160
physical address space

00:13:31,680 --> 00:13:36,399
then uh with virtual pmem we would have

00:13:34,160 --> 00:13:39,360
our dex device meaning our

00:13:36,399 --> 00:13:40,160
file directly mapped into this address

00:13:39,360 --> 00:13:42,880
space

00:13:40,160 --> 00:13:44,000
and if we compare that to an nvdim it's

00:13:42,880 --> 00:13:46,880
actually

00:13:44,000 --> 00:13:48,320
pretty similar so the main difference

00:13:46,880 --> 00:13:52,000
here is that

00:13:48,320 --> 00:13:53,120
whenever we emulate an nvdimm using a

00:13:52,000 --> 00:13:56,240
real nvidim

00:13:53,120 --> 00:13:57,920
there is absolutely no issue but at the

00:13:56,240 --> 00:14:00,720
point where we would start to

00:13:57,920 --> 00:14:01,440
emulate an nvdm for our guest using a

00:14:00,720 --> 00:14:03,760
file

00:14:01,440 --> 00:14:05,440
we would run into issues when wanting to

00:14:03,760 --> 00:14:08,800
flush

00:14:05,440 --> 00:14:11,839
rights to disk the nature of

00:14:08,800 --> 00:14:13,680
nvidia's work by using only memory flush

00:14:11,839 --> 00:14:15,279
instructions so to for example flash

00:14:13,680 --> 00:14:16,399
cache lines and memory fence

00:14:15,279 --> 00:14:18,079
instructions

00:14:16,399 --> 00:14:20,320
and once these instructions were

00:14:18,079 --> 00:14:23,920
executed the guests can be sure that

00:14:20,320 --> 00:14:26,560
everything is persistent but if we map a

00:14:23,920 --> 00:14:28,480
file into our vm physical address base

00:14:26,560 --> 00:14:30,720
this is no longer the case

00:14:28,480 --> 00:14:32,480
so instead we really have to intercept

00:14:30,720 --> 00:14:35,760
any kinds of flushes

00:14:32,480 --> 00:14:37,040
um to cream qmu and in qmu we have then

00:14:35,760 --> 00:14:40,079
go ahead and

00:14:37,040 --> 00:14:41,600
do an fsync and only after the f sync

00:14:40,079 --> 00:14:43,279
happens we can be sure that it's

00:14:41,600 --> 00:14:45,680
actually persistent

00:14:43,279 --> 00:14:47,279
and this is very important in case our

00:14:45,680 --> 00:14:49,680
virtual machine would crash

00:14:47,279 --> 00:14:51,120
because if stuff would not be persistent

00:14:49,680 --> 00:14:54,639
on something that's supposed to be

00:14:51,120 --> 00:14:57,680
persistent memory then we're in trouble

00:14:54,639 --> 00:15:00,320
so um the big idea is to have a power

00:14:57,680 --> 00:15:02,399
virtualized mechanism to perform flushes

00:15:00,320 --> 00:15:03,360
and this is exactly what rudolph piment

00:15:02,399 --> 00:15:05,600
does

00:15:03,360 --> 00:15:07,199
and we get on by doing that we get the

00:15:05,600 --> 00:15:10,000
benefit of

00:15:07,199 --> 00:15:11,360
dex devices meaning we can bypass the

00:15:10,000 --> 00:15:14,399
page cache in our

00:15:11,360 --> 00:15:16,320
guest completely and instead let

00:15:14,399 --> 00:15:20,160
the page cache for that file be

00:15:16,320 --> 00:15:20,160
completely managed in the hypervisor

00:15:20,560 --> 00:15:25,120
so what are the advantages of rudolph of

00:15:23,680 --> 00:15:26,720
course

00:15:25,120 --> 00:15:29,040
we move this page cache handling from

00:15:26,720 --> 00:15:30,880
the guest to the hypervisor

00:15:29,040 --> 00:15:32,880
we free up the guest page cache so the

00:15:30,880 --> 00:15:34,800
hypervisor can make decisions of

00:15:32,880 --> 00:15:36,560
when to shrink the page cache just

00:15:34,800 --> 00:15:38,720
easily for example when it's about to

00:15:36,560 --> 00:15:41,440
run out of memory

00:15:38,720 --> 00:15:42,079
also it's a safe fireback emulated in

00:15:41,440 --> 00:15:44,639
vdim

00:15:42,079 --> 00:15:45,440
because rights work properly in contrast

00:15:44,639 --> 00:15:48,560
to

00:15:45,440 --> 00:15:52,079
using a real emulated and vdim

00:15:48,560 --> 00:15:54,800
backed by a file as i mentioned also

00:15:52,079 --> 00:15:55,680
uh interestingly as it's a rodeo device

00:15:54,800 --> 00:15:58,160
it's actually an

00:15:55,680 --> 00:16:00,000
nvidium-like mechanism a dex mechanism

00:15:58,160 --> 00:16:00,399
even for architectures that don't even

00:16:00,000 --> 00:16:04,160
have

00:16:00,399 --> 00:16:05,040
hardware nvidians or architectures that

00:16:04,160 --> 00:16:08,320
don't even have

00:16:05,040 --> 00:16:10,720
acpi so for example s390x might be

00:16:08,320 --> 00:16:13,600
feasible in the future

00:16:10,720 --> 00:16:14,240
but also there are some disadvantages uh

00:16:13,600 --> 00:16:16,480
because we

00:16:14,240 --> 00:16:18,480
mapped this disk image directly into our

00:16:16,480 --> 00:16:20,959
vm fiscal address base

00:16:18,480 --> 00:16:23,920
um we really only support raw disks for

00:16:20,959 --> 00:16:26,079
now so no qco2 or similar

00:16:23,920 --> 00:16:28,639
also because we're using the hypervisor

00:16:26,079 --> 00:16:29,440
page cache now um with multiple virtual

00:16:28,639 --> 00:16:31,360
machines

00:16:29,440 --> 00:16:32,560
there are quite some security but also

00:16:31,360 --> 00:16:37,040
fairness concerns

00:16:32,560 --> 00:16:40,320
that at least users have to be aware of

00:16:37,040 --> 00:16:41,839
similar to real nv dimms booting is not

00:16:40,320 --> 00:16:44,639
supported and requires an

00:16:41,839 --> 00:16:46,880
external coroner or another disk image

00:16:44,639 --> 00:16:49,040
which could for example be read-only or

00:16:46,880 --> 00:16:51,120
similar

00:16:49,040 --> 00:16:53,120
also it's worthwhile to mention that

00:16:51,120 --> 00:16:54,399
with a pmem is not applicable in all

00:16:53,120 --> 00:16:56,720
setups

00:16:54,399 --> 00:16:58,720
so for example there are environments

00:16:56,720 --> 00:17:00,000
where the hypervisor page cache is not

00:16:58,720 --> 00:17:02,800
involved at all

00:17:00,000 --> 00:17:04,559
imagine passing through a disk directly

00:17:02,800 --> 00:17:07,520
from your hypervisor to your guest

00:17:04,559 --> 00:17:09,919
or accessing the disk using some other

00:17:07,520 --> 00:17:12,480
mediated devices

00:17:09,919 --> 00:17:15,679
also as soon as we have fairly big disks

00:17:12,480 --> 00:17:15,679
this could become an issue

00:17:16,559 --> 00:17:20,559
also there are still some open items to

00:17:18,720 --> 00:17:23,039
be sorted out

00:17:20,559 --> 00:17:24,480
on the one hand uh we want to eventually

00:17:23,039 --> 00:17:26,480
support other

00:17:24,480 --> 00:17:27,760
architectures but also other guest

00:17:26,480 --> 00:17:29,840
operating systems

00:17:27,760 --> 00:17:32,320
as far as i know currently there is only

00:17:29,840 --> 00:17:34,320
really linux support for it

00:17:32,320 --> 00:17:36,160
also in the long term we want to support

00:17:34,320 --> 00:17:38,320
other disk image types

00:17:36,160 --> 00:17:40,880
and we could actually support something

00:17:38,320 --> 00:17:43,280
like uco 2 or similar by using some neat

00:17:40,880 --> 00:17:45,039
use of old fd triggery

00:17:43,280 --> 00:17:47,360
but of course this is stuff for the

00:17:45,039 --> 00:17:49,280
future and might require more work to

00:17:47,360 --> 00:17:50,960
figure out how exactly it's gonna be

00:17:49,280 --> 00:17:53,039
done

00:17:50,960 --> 00:17:54,799
there's still uh one remaining bug

00:17:53,039 --> 00:17:57,520
that's to be solved um

00:17:54,799 --> 00:17:58,160
which involves pre-flashing asynchronous

00:17:57,520 --> 00:18:01,200
flashes

00:17:58,160 --> 00:18:03,600
in linux stuff like that long story

00:18:01,200 --> 00:18:05,679
short it's work in progress but

00:18:03,600 --> 00:18:07,840
as long as that's not upstream there is

00:18:05,679 --> 00:18:11,120
some cases where

00:18:07,840 --> 00:18:13,200
flashes might not actually be persistent

00:18:11,120 --> 00:18:15,600
yet

00:18:13,200 --> 00:18:16,960
also uh we want to see in the future

00:18:15,600 --> 00:18:19,360
liberty integration

00:18:16,960 --> 00:18:20,320
live migration support hot unblock

00:18:19,360 --> 00:18:23,200
support and

00:18:20,320 --> 00:18:24,640
a bunch of optimizations but until then

00:18:23,200 --> 00:18:27,520
rudolph pmem can be

00:18:24,640 --> 00:18:30,799
used um just fine keeping in mind a

00:18:27,520 --> 00:18:30,799
couple of things i mentioned

00:18:31,200 --> 00:18:37,440
now let's talk about voodoo map

00:18:34,720 --> 00:18:39,520
the veteran can be summarized as a fine

00:18:37,440 --> 00:18:41,919
grain umavera memory hot unblock

00:18:39,520 --> 00:18:43,120
mechanism to dynamically resize virtual

00:18:41,919 --> 00:18:45,039
machines

00:18:43,120 --> 00:18:46,240
and the idea is actually pretty simple

00:18:45,039 --> 00:18:48,799
so if you take a

00:18:46,240 --> 00:18:50,720
look at your memory uh the memory your

00:18:48,799 --> 00:18:52,559
virtual machine has available

00:18:50,720 --> 00:18:54,320
then you usually have some kind of

00:18:52,559 --> 00:18:56,480
initial or boot memory

00:18:54,320 --> 00:18:58,160
and you can extend that memory using

00:18:56,480 --> 00:19:00,640
various measurements

00:18:58,160 --> 00:19:01,679
so for example you could you could use

00:19:00,640 --> 00:19:04,000
dims to

00:19:01,679 --> 00:19:04,720
add more memory to your virtual machine

00:19:04,000 --> 00:19:08,000
um

00:19:04,720 --> 00:19:09,120
or remove dims again by hot unplugging

00:19:08,000 --> 00:19:11,039
them

00:19:09,120 --> 00:19:12,480
but dims have their own set of issues

00:19:11,039 --> 00:19:15,520
that i'm not gonna

00:19:12,480 --> 00:19:17,200
uh go into detail here um buddha mmm is

00:19:15,520 --> 00:19:20,799
similar so viral mem can

00:19:17,200 --> 00:19:24,320
extend then your initial vm size

00:19:20,799 --> 00:19:26,240
uh on a per node level and it works by

00:19:24,320 --> 00:19:28,240
each with a man device providing a

00:19:26,240 --> 00:19:30,400
flexible amount of memory towards a

00:19:28,240 --> 00:19:33,039
virtual machine

00:19:30,400 --> 00:19:33,919
internally this is implemented by a

00:19:33,039 --> 00:19:36,960
device

00:19:33,919 --> 00:19:40,240
managing a dedicated region in guest

00:19:36,960 --> 00:19:42,480
physical address space it can be thought

00:19:40,240 --> 00:19:43,039
of something like a resizable dim but

00:19:42,480 --> 00:19:46,320
it's

00:19:43,039 --> 00:19:49,360
more complicated than that

00:19:46,320 --> 00:19:50,880
one interesting fact is that root of man

00:19:49,360 --> 00:19:52,960
devices

00:19:50,880 --> 00:19:54,960
are not discovered if you're running an

00:19:52,960 --> 00:19:56,480
unmodified operating system meaning an

00:19:54,960 --> 00:19:59,120
operating system that

00:19:56,480 --> 00:20:01,200
uh is not aware of rodeo map because

00:19:59,120 --> 00:20:03,919
that allows us to always

00:20:01,200 --> 00:20:04,559
know which memory uh a guest is allowed

00:20:03,919 --> 00:20:06,880
to touch

00:20:04,559 --> 00:20:08,159
and for example later detect malicious

00:20:06,880 --> 00:20:10,000
gas that might

00:20:08,159 --> 00:20:12,799
try to make use of more memory than they

00:20:10,000 --> 00:20:14,640
are actually allowed to

00:20:12,799 --> 00:20:16,880
internally voter membranes in the

00:20:14,640 --> 00:20:18,320
granularity of blocks for example two

00:20:16,880 --> 00:20:20,240
megabyte blocks but they can be

00:20:18,320 --> 00:20:23,679
significantly bigger

00:20:20,240 --> 00:20:26,320
and a worderman device itself has

00:20:23,679 --> 00:20:28,799
three main properties on one hand it has

00:20:26,320 --> 00:20:30,799
a size which corresponds to the amount

00:20:28,799 --> 00:20:33,280
of memory a rudderman device currently

00:20:30,799 --> 00:20:36,080
provides towards a virtual machine

00:20:33,280 --> 00:20:38,080
it has also has a maximum size and the

00:20:36,080 --> 00:20:39,840
maximum size corresponds to the maximum

00:20:38,080 --> 00:20:42,000
amount of memory uh

00:20:39,840 --> 00:20:44,400
that could be provided via a rudiment

00:20:42,000 --> 00:20:46,320
device towards the virtual machine

00:20:44,400 --> 00:20:48,640
last but not least there is a requested

00:20:46,320 --> 00:20:50,720
size which corresponds to a crest

00:20:48,640 --> 00:20:52,480
request from the hypervisor towards the

00:20:50,720 --> 00:20:54,640
guest to uh

00:20:52,480 --> 00:20:57,200
change the amount of memory that is

00:20:54,640 --> 00:21:00,320
consumed for your roder memory device

00:20:57,200 --> 00:21:03,760
and this mechanism allows you to resize

00:21:00,320 --> 00:21:06,559
a guest in fairly fine crane steps uh

00:21:03,760 --> 00:21:06,559
numa there

00:21:07,120 --> 00:21:10,320
and using it is actually not too hard

00:21:09,360 --> 00:21:12,480
right now so

00:21:10,320 --> 00:21:14,559
first of all you have to prepare your uh

00:21:12,480 --> 00:21:15,679
virtual machine for memory devices just

00:21:14,559 --> 00:21:19,760
as you would have to

00:21:15,679 --> 00:21:22,400
for dims and vdins but also voter keyman

00:21:19,760 --> 00:21:23,200
after that you create a memory backend

00:21:22,400 --> 00:21:26,640
which

00:21:23,200 --> 00:21:28,840
is later used to

00:21:26,640 --> 00:21:31,360
host your router man device in your

00:21:28,840 --> 00:21:35,120
hypervisor and the size you specify

00:21:31,360 --> 00:21:37,039
actually corresponds to the maximum size

00:21:35,120 --> 00:21:38,320
then you create your actual ruler mem

00:21:37,039 --> 00:21:39,840
device

00:21:38,320 --> 00:21:41,760
you can assign it to a node and you

00:21:39,840 --> 00:21:45,280
connect the memory back end

00:21:41,760 --> 00:21:45,760
and as a default if you would start your

00:21:45,280 --> 00:21:47,919
vm

00:21:45,760 --> 00:21:49,840
your uh guest would not consume any

00:21:47,919 --> 00:21:52,159
additional memory via disregardment

00:21:49,840 --> 00:21:54,480
device

00:21:52,159 --> 00:21:55,440
it will start in consuming more memory

00:21:54,480 --> 00:21:57,520
as soon as you

00:21:55,440 --> 00:21:59,120
actually request it so you can request

00:21:57,520 --> 00:22:03,200
it for example via

00:21:59,120 --> 00:22:04,720
qmp or hmp in qmu using a chrome set and

00:22:03,200 --> 00:22:07,360
corbin get mechanism

00:22:04,720 --> 00:22:09,360
so you could request to um consume for

00:22:07,360 --> 00:22:11,520
example four gigabytes via that device

00:22:09,360 --> 00:22:14,559
and the guest will try to make

00:22:11,520 --> 00:22:15,360
make make it possible and you can always

00:22:14,559 --> 00:22:17,840
then also

00:22:15,360 --> 00:22:19,520
observe how much memory the guest is

00:22:17,840 --> 00:22:23,120
actually consuming via device by

00:22:19,520 --> 00:22:23,120
clearing its current size

00:22:24,080 --> 00:22:29,039
so what are advantages and disadvantages

00:22:26,640 --> 00:22:31,360
advantages are obviously that you can re

00:22:29,039 --> 00:22:32,159
resize a virtual machine in fairly small

00:22:31,360 --> 00:22:36,159
increments

00:22:32,159 --> 00:22:37,840
so right now with uh linux gas on x86 64

00:22:36,159 --> 00:22:39,840
you can resize in four megabyte

00:22:37,840 --> 00:22:42,080
criminality

00:22:39,840 --> 00:22:44,159
also it's significantly more flexible

00:22:42,080 --> 00:22:45,919
than dims and also significantly more

00:22:44,159 --> 00:22:47,679
flexible than memory ballooning

00:22:45,919 --> 00:22:50,960
for example memory ballooning does not

00:22:47,679 --> 00:22:54,559
support pneuma and with dimms you have

00:22:50,960 --> 00:22:57,200
quite some granularity restrictions

00:22:54,559 --> 00:22:59,440
also butterman is able to manage vm size

00:22:57,200 --> 00:23:01,360
changes completely insecure you

00:22:59,440 --> 00:23:03,039
so you don't have to mess with any dims

00:23:01,360 --> 00:23:03,840
or anything else all you do is you

00:23:03,039 --> 00:23:05,760
request

00:23:03,840 --> 00:23:09,120
changes to the size of a ruler mem

00:23:05,760 --> 00:23:11,919
device and see what happens

00:23:09,120 --> 00:23:13,679
interestingly verdamm being over the old

00:23:11,919 --> 00:23:15,360
device is also architectured

00:23:13,679 --> 00:23:17,120
independent so for example it does not

00:23:15,360 --> 00:23:18,799
require acpi

00:23:17,120 --> 00:23:21,280
so it's also applicable to other

00:23:18,799 --> 00:23:24,080
architectures

00:23:21,280 --> 00:23:25,520
disadvantage are um for example that

00:23:24,080 --> 00:23:27,600
it's not production ready yet

00:23:25,520 --> 00:23:30,159
so we have some basic versions upstream

00:23:27,600 --> 00:23:32,320
and linux jmu and cloud hypervisor

00:23:30,159 --> 00:23:33,520
but there are still some things that at

00:23:32,320 --> 00:23:36,720
least i want to see

00:23:33,520 --> 00:23:38,799
uh implemented and fixed uh before we

00:23:36,720 --> 00:23:41,520
can consider this production ready and i

00:23:38,799 --> 00:23:44,240
can sleep good at night

00:23:41,520 --> 00:23:46,320
also it's slower than memory ballooning

00:23:44,240 --> 00:23:47,679
and it cannot unplug as much memory as

00:23:46,320 --> 00:23:49,279
memory balloon

00:23:47,679 --> 00:23:51,520
the thing is that memory ballooning

00:23:49,279 --> 00:23:54,240
works on the whole virtual machine and

00:23:51,520 --> 00:23:56,400
not just on restricted uh physical

00:23:54,240 --> 00:23:58,559
memory regions inside your virtual

00:23:56,400 --> 00:24:00,480
machine and memory ballooning works on

00:23:58,559 --> 00:24:03,039
4k granularity usually

00:24:00,480 --> 00:24:05,200
while brutal mem works on 4 megabyte

00:24:03,039 --> 00:24:07,440
triangularity

00:24:05,200 --> 00:24:09,200
also currently it's incompatible with

00:24:07,440 --> 00:24:10,960
hibernation and suspension

00:24:09,200 --> 00:24:12,880
meaning as soon as you have roderman

00:24:10,960 --> 00:24:14,640
running with linux gas you won't be able

00:24:12,880 --> 00:24:15,360
to hibernate or suspend your guests

00:24:14,640 --> 00:24:16,880
anymore

00:24:15,360 --> 00:24:20,400
this might change in the future but

00:24:16,880 --> 00:24:20,400
might requires quite some work

00:24:20,559 --> 00:24:24,480
open items are just as with wood or pmem

00:24:23,200 --> 00:24:25,360
for example support for other

00:24:24,480 --> 00:24:29,440
architectures

00:24:25,360 --> 00:24:31,200
um arm64 and s390x i have prototypes for

00:24:29,440 --> 00:24:33,600
but of course other ones

00:24:31,200 --> 00:24:36,240
might also be interesting guest

00:24:33,600 --> 00:24:38,799
operating support

00:24:36,240 --> 00:24:40,799
will also be challenging and interesting

00:24:38,799 --> 00:24:42,480
for example to get windows running with

00:24:40,799 --> 00:24:44,159
it

00:24:42,480 --> 00:24:46,080
there's still quite some open items in

00:24:44,159 --> 00:24:48,320
the linux driver for example

00:24:46,080 --> 00:24:49,840
um how much memory you can actually

00:24:48,320 --> 00:24:53,120
unplug later on um

00:24:49,840 --> 00:24:55,520
is not guaranteed yet but it is work a

00:24:53,120 --> 00:24:57,360
work in progress in inquiry there are

00:24:55,520 --> 00:24:59,760
various things that have to be tackled

00:24:57,360 --> 00:25:01,840
for example vfo support just as for

00:24:59,760 --> 00:25:06,559
voter balloon meaning that you can

00:25:01,840 --> 00:25:08,720
pass through devices and still have this

00:25:06,559 --> 00:25:10,080
mechanism to resize the virtual machines

00:25:08,720 --> 00:25:13,120
this way

00:25:10,080 --> 00:25:17,360
also other gmu future work would be

00:25:13,120 --> 00:25:19,360
protecting a guest memory from

00:25:17,360 --> 00:25:20,559
being accessed again meaning that a

00:25:19,360 --> 00:25:22,320
malicious guest

00:25:20,559 --> 00:25:25,840
does not consume more memory than

00:25:22,320 --> 00:25:27,919
actually requested via a rudiment device

00:25:25,840 --> 00:25:29,679
also just as forwarded pmem library

00:25:27,919 --> 00:25:30,880
integration would be great to see in the

00:25:29,679 --> 00:25:32,720
future

00:25:30,880 --> 00:25:35,520
especially once it's officially

00:25:32,720 --> 00:25:35,520
production ready

00:25:37,200 --> 00:25:42,640
so to summarize what we see

00:25:40,400 --> 00:25:43,600
is we see more specialized mechanisms to

00:25:42,640 --> 00:25:46,000
manage custom

00:25:43,600 --> 00:25:47,919
memory so for example we talked about

00:25:46,000 --> 00:25:50,080
the router balloon extensions

00:25:47,919 --> 00:25:52,400
to speed up migration or to optimize

00:25:50,080 --> 00:25:54,640
memory over commit in the hypervisor

00:25:52,400 --> 00:25:57,039
we talked about voter pmaem to move the

00:25:54,640 --> 00:25:59,520
page cache handling to the hypervisor

00:25:57,039 --> 00:26:00,480
and we talked about voodoo mmm to resize

00:25:59,520 --> 00:26:03,520
your gas

00:26:00,480 --> 00:26:03,520
fine grained in muma

00:26:03,679 --> 00:26:08,000
but it's worth to note that traditional

00:26:06,000 --> 00:26:11,039
balloon inflation and deflation

00:26:08,000 --> 00:26:13,039
still remains important for example the

00:26:11,039 --> 00:26:14,080
new mechanisms we see still have to

00:26:13,039 --> 00:26:15,840
mature

00:26:14,080 --> 00:26:17,760
for example rudermann is still not

00:26:15,840 --> 00:26:21,520
production ready

00:26:17,760 --> 00:26:26,720
also um the the more

00:26:21,520 --> 00:26:29,760
um yeah memory management

00:26:26,720 --> 00:26:31,760
intensive things we develop the deeper

00:26:29,760 --> 00:26:32,159
the memory management integration in our

00:26:31,760 --> 00:26:34,960
guest

00:26:32,159 --> 00:26:36,880
actually is so for example riding a

00:26:34,960 --> 00:26:38,559
balloon driver is pretty simple all you

00:26:36,880 --> 00:26:39,120
have to do is allocate memory and free

00:26:38,559 --> 00:26:42,240
memory

00:26:39,120 --> 00:26:43,760
essentially but having winrar support

00:26:42,240 --> 00:26:46,480
for all of the other features we talked

00:26:43,760 --> 00:26:48,799
about today will be much more difficult

00:26:46,480 --> 00:26:50,400
and so it is with all closed source

00:26:48,799 --> 00:26:52,720
operating systems where we

00:26:50,400 --> 00:26:54,159
as open source developer cannot really

00:26:52,720 --> 00:26:57,279
influence

00:26:54,159 --> 00:26:59,520
core memory management

00:26:57,279 --> 00:27:01,279
also in general there is still a lot to

00:26:59,520 --> 00:27:04,080
optimize

00:27:01,279 --> 00:27:05,279
as michael already mentioned the page

00:27:04,080 --> 00:27:07,760
guest page cache

00:27:05,279 --> 00:27:10,080
still remains challenging uh so are

00:27:07,760 --> 00:27:10,720
other caches like the application cache

00:27:10,080 --> 00:27:13,279
uh

00:27:10,720 --> 00:27:14,720
if you imagine something like that um

00:27:13,279 --> 00:27:17,760
for example

00:27:14,720 --> 00:27:18,080
pmem isn't always applicable um and then

00:27:17,760 --> 00:27:19,919
you

00:27:18,080 --> 00:27:22,000
essentially are back to the same issue

00:27:19,919 --> 00:27:24,080
with the guests

00:27:22,000 --> 00:27:26,159
maybe consume all of its main memory

00:27:24,080 --> 00:27:28,080
just for the page cache

00:27:26,159 --> 00:27:29,440
also encrypted virtual machines remain

00:27:28,080 --> 00:27:31,279
challenging

00:27:29,440 --> 00:27:33,200
i think this item hasn't really been

00:27:31,279 --> 00:27:34,240
tackled yet but it's certainly stuff for

00:27:33,200 --> 00:27:35,760
the future

00:27:34,240 --> 00:27:37,840
because the hypervisor isn't really

00:27:35,760 --> 00:27:40,799
allowed to modify um

00:27:37,840 --> 00:27:41,279
content of your virtual machine um so

00:27:40,799 --> 00:27:43,840
what

00:27:41,279 --> 00:27:45,679
most of our mechanisms do is they

00:27:43,840 --> 00:27:48,399
discard for example memory

00:27:45,679 --> 00:27:50,000
um to optimize and that is not possible

00:27:48,399 --> 00:27:52,480
so it requires some kind of

00:27:50,000 --> 00:27:53,520
coordination with the guest or with the

00:27:52,480 --> 00:27:56,640
encrypted vm

00:27:53,520 --> 00:27:58,080
setup um i think that router balloon

00:27:56,640 --> 00:27:58,720
inflation and deflation should be

00:27:58,080 --> 00:28:01,200
feasible

00:27:58,720 --> 00:28:03,600
voter mem should be feasible i'm not so

00:28:01,200 --> 00:28:05,520
sure about rudolph pman because

00:28:03,600 --> 00:28:06,720
we're mapping some content into our

00:28:05,520 --> 00:28:08,640
guest which

00:28:06,720 --> 00:28:10,399
is unencrypted and that might be an

00:28:08,640 --> 00:28:13,440
issue

00:28:10,399 --> 00:28:14,840
also vfo and internal pci path through

00:28:13,440 --> 00:28:17,279
our other path through remains

00:28:14,840 --> 00:28:19,120
challenging because the issue with vfr

00:28:17,279 --> 00:28:19,919
is that it essentially pins all guest

00:28:19,120 --> 00:28:22,000
memory

00:28:19,919 --> 00:28:23,200
and forcing it to remain in hypervisor

00:28:22,000 --> 00:28:25,600
memory so

00:28:23,200 --> 00:28:27,120
um even if you would have riddler pmm

00:28:25,600 --> 00:28:28,799
this would mean that your whole router

00:28:27,120 --> 00:28:30,320
and pmem device would be pinned in

00:28:28,799 --> 00:28:32,080
hypervisor memory

00:28:30,320 --> 00:28:33,600
which is not really an improvement to

00:28:32,080 --> 00:28:36,000
what we have right now

00:28:33,600 --> 00:28:37,120
and the same goes for all of the other

00:28:36,000 --> 00:28:39,279
items

00:28:37,120 --> 00:28:41,039
we do have a prototype for router mem

00:28:39,279 --> 00:28:44,080
that makes it work

00:28:41,039 --> 00:28:44,640
but i guess a clean solution will still

00:28:44,080 --> 00:28:47,600
have to

00:28:44,640 --> 00:28:49,200
require some discussions in the future

00:28:47,600 --> 00:28:51,360
and that's basically it

00:28:49,200 --> 00:28:53,440
for this talk thank you a lot for

00:28:51,360 --> 00:28:54,559
attending if there are any questions

00:28:53,440 --> 00:28:56,240
feel free to

00:28:54,559 --> 00:28:58,000
ask them in the chat or reach out to

00:28:56,240 --> 00:29:01,039
either me or michael

00:28:58,000 --> 00:29:03,120
and i'll leave you with that

00:29:01,039 --> 00:29:05,440
here are some resources in case you want

00:29:03,120 --> 00:29:09,679
to learn more

00:29:05,440 --> 00:29:12,080
look up stuff and this is it

00:29:09,679 --> 00:29:25,279
i hope you'll have a great time enjoying

00:29:12,080 --> 00:29:25,279

YouTube URL: https://www.youtube.com/watch?v=GU7bEblD1f4


