Title: Webinar: Privacy Tech in A.I. Model Building, sponsored by doc.ai
Publication date: 2020-08-20
Playlist: LF Live Webinars
Description: 
	The pandemic has accelerated the adoption of A.I. across sectors from finance to healthcare. How can we use the richness of datasets, while protecting the individuals and communities they belong to?
Captions: 
	00:00:00,000 --> 00:00:02,399
london

00:00:08,720 --> 00:00:13,200
great so

00:00:11,840 --> 00:00:17,039
i'd like to welcome everyone to the

00:00:13,200 --> 00:00:20,160
privacy and tech and ai model building

00:00:17,039 --> 00:00:21,439
so a little bit of additional

00:00:20,160 --> 00:00:24,960
information

00:00:21,439 --> 00:00:26,400
so before we get started so i work over

00:00:24,960 --> 00:00:27,920
at doc ai i'm the head of edge

00:00:26,400 --> 00:00:30,480
infrastructure

00:00:27,920 --> 00:00:31,599
dock ai is a silicon valley-based

00:00:30,480 --> 00:00:34,800
digital health company

00:00:31,599 --> 00:00:38,160
we we build mobile health products

00:00:34,800 --> 00:00:39,760
that have a that they work with ai

00:00:38,160 --> 00:00:41,760
technologies and algorithms privacy

00:00:39,760 --> 00:00:45,920
preserving infrastructure

00:00:41,760 --> 00:00:50,160
we work with with a variety of

00:00:45,920 --> 00:00:53,840
organizations across the board

00:00:50,160 --> 00:00:57,120
and including very large healthcare

00:00:53,840 --> 00:00:58,800
organizations for me

00:00:57,120 --> 00:01:00,399
part of what i part of what i've done

00:00:58,800 --> 00:01:02,879
over at doc ai is i started the

00:01:00,399 --> 00:01:04,799
federated learning and ai privacy teams

00:01:02,879 --> 00:01:06,080
uh built up the initial teams around

00:01:04,799 --> 00:01:08,560
them i also

00:01:06,080 --> 00:01:09,360
focus on infrastructure related things

00:01:08,560 --> 00:01:10,880
to

00:01:09,360 --> 00:01:13,360
help health care companies adopt zero

00:01:10,880 --> 00:01:15,040
trust and cloud native environments

00:01:13,360 --> 00:01:16,799
i also do a lot of work in the open

00:01:15,040 --> 00:01:19,439
source space so i do a lot of work with

00:01:16,799 --> 00:01:22,640
network service mesh which is a

00:01:19,439 --> 00:01:26,159
cncf sandbox project

00:01:22,640 --> 00:01:27,040
and is helping with with lower level

00:01:26,159 --> 00:01:30,960
networking

00:01:27,040 --> 00:01:32,640
and zero trust uh networking and policy

00:01:30,960 --> 00:01:35,280
and we're seeing early adoption in both

00:01:32,640 --> 00:01:36,640
telecom and and enterprise

00:01:35,280 --> 00:01:38,640
i've also worked in a variety of

00:01:36,640 --> 00:01:42,079
different areas across the board

00:01:38,640 --> 00:01:44,399
throughout infrastructure so let's get

00:01:42,079 --> 00:01:44,399
started

00:01:46,000 --> 00:01:49,439
so the the agenda is uh we're going to

00:01:48,479 --> 00:01:50,880
run through a survey

00:01:49,439 --> 00:01:53,040
and this survey is going to start off

00:01:50,880 --> 00:01:54,640
with some ai model building technologies

00:01:53,040 --> 00:01:56,240
and then we're going to look at survey

00:01:54,640 --> 00:01:58,640
infrastructure technologies

00:01:56,240 --> 00:01:59,360
after that and then we'll finish it up

00:01:58,640 --> 00:02:01,680
with a

00:01:59,360 --> 00:02:04,560
with a short example that uses some of

00:02:01,680 --> 00:02:04,560
these technologies

00:02:04,719 --> 00:02:09,920
so the problem statement the

00:02:08,560 --> 00:02:12,000
so when you start looking at what

00:02:09,920 --> 00:02:15,360
artificial intelligence is specifically

00:02:12,000 --> 00:02:17,040
uh how neural networks work they

00:02:15,360 --> 00:02:19,280
they learn to predict their outputs

00:02:17,040 --> 00:02:20,720
based on their input features

00:02:19,280 --> 00:02:22,239
and so you have a set if you look at the

00:02:20,720 --> 00:02:23,520
graph on the right you have a set of

00:02:22,239 --> 00:02:26,879
input features that come in

00:02:23,520 --> 00:02:29,360
they run through some set of of network

00:02:26,879 --> 00:02:30,959
that network will learn things about the

00:02:29,360 --> 00:02:32,800
about the input dimensions

00:02:30,959 --> 00:02:35,200
and then we'll try to make predictions

00:02:32,800 --> 00:02:36,000
in the output so this is generally a

00:02:35,200 --> 00:02:38,239
good property

00:02:36,000 --> 00:02:39,680
and that as you learn information about

00:02:38,239 --> 00:02:41,360
the input then you can make better

00:02:39,680 --> 00:02:42,239
decisions about what the output should

00:02:41,360 --> 00:02:45,120
be

00:02:42,239 --> 00:02:46,239
but this also has an impact on privacy

00:02:45,120 --> 00:02:47,760
and the reason why

00:02:46,239 --> 00:02:49,920
is because you're you're literally

00:02:47,760 --> 00:02:52,000
learning to identify features about your

00:02:49,920 --> 00:02:54,560
inputs to predict your output

00:02:52,000 --> 00:02:56,400
so if you're training a model that has

00:02:54,560 --> 00:03:01,280
access to sensitive data

00:02:56,400 --> 00:03:01,280
or you are training a model which

00:03:01,680 --> 00:03:05,120
what you're effectively doing is you're

00:03:02,959 --> 00:03:06,480
training the model to recognize the

00:03:05,120 --> 00:03:08,000
training set

00:03:06,480 --> 00:03:10,640
to recognize properties about the

00:03:08,000 --> 00:03:13,680
training set

00:03:10,640 --> 00:03:17,599
so the reason that this

00:03:13,680 --> 00:03:20,720
the reason this happens is there's a

00:03:17,599 --> 00:03:21,360
there's an effect that is called uh that

00:03:20,720 --> 00:03:23,440
is called

00:03:21,360 --> 00:03:24,640
overfitting that uh that happens within

00:03:23,440 --> 00:03:28,239
neural networks

00:03:24,640 --> 00:03:31,680
so when you have a given input it's

00:03:28,239 --> 00:03:32,319
the system is not uh immediately capable

00:03:31,680 --> 00:03:34,159
of of

00:03:32,319 --> 00:03:35,360
generalizing right up front and there

00:03:34,159 --> 00:03:36,959
are techniques you can use to help with

00:03:35,360 --> 00:03:39,040
that generalization

00:03:36,959 --> 00:03:40,159
but uh what ends up happening is

00:03:39,040 --> 00:03:42,000
whatever input you

00:03:40,159 --> 00:03:43,680
send it's is going to be what it would

00:03:42,000 --> 00:03:45,440
identify so if you're doing a bunch of

00:03:43,680 --> 00:03:47,519
inputs like you're making an animal

00:03:45,440 --> 00:03:49,040
detector and all you put in is cats

00:03:47,519 --> 00:03:50,879
you're probably not going to be able to

00:03:49,040 --> 00:03:52,799
to detect dogs with it

00:03:50,879 --> 00:03:55,200
and this particular technique is a form

00:03:52,799 --> 00:03:57,280
of bias it's a form of overfitting

00:03:55,200 --> 00:03:58,879
and to make matters even worse

00:03:57,280 --> 00:04:00,400
overfitted models learn too much

00:03:58,879 --> 00:04:02,799
information about

00:04:00,400 --> 00:04:04,640
the individual inputs themselves what

00:04:02,799 --> 00:04:08,480
this means is that if a

00:04:04,640 --> 00:04:10,400
if a model were to escape your

00:04:08,480 --> 00:04:11,519
your environment and end up in the black

00:04:10,400 --> 00:04:14,560
market

00:04:11,519 --> 00:04:15,439
then you don't have a way to remove that

00:04:14,560 --> 00:04:17,199
model off of there

00:04:15,439 --> 00:04:19,680
and people can analyze the model you

00:04:17,199 --> 00:04:22,160
have and and make

00:04:19,680 --> 00:04:23,120
and discover information about the

00:04:22,160 --> 00:04:25,120
inputs which

00:04:23,120 --> 00:04:27,040
could be very sensitive could be very

00:04:25,120 --> 00:04:30,240
sensitive data

00:04:27,040 --> 00:04:32,720
so to give you a visual example

00:04:30,240 --> 00:04:34,960
if that we the we have two lines in the

00:04:32,720 --> 00:04:38,240
center and each of these represent

00:04:34,960 --> 00:04:39,600
two very simple models so we have the

00:04:38,240 --> 00:04:42,000
straight line which is a more

00:04:39,600 --> 00:04:44,320
generalized predictor and then we have

00:04:42,000 --> 00:04:45,440
the dotted line and the dotted line is

00:04:44,320 --> 00:04:47,759
something that has been over

00:04:45,440 --> 00:04:49,040
trained and so the question then is

00:04:47,759 --> 00:04:51,840
predict where the blue

00:04:49,040 --> 00:04:53,040
and red sorry where the blue and uh

00:04:51,840 --> 00:04:54,160
where are the squares and where are the

00:04:53,040 --> 00:04:57,199
circles

00:04:54,160 --> 00:04:58,160
so if so if you look you can see who has

00:04:57,199 --> 00:05:01,120
it had the line

00:04:58,160 --> 00:05:01,600
uh squiggles around you can you can see

00:05:01,120 --> 00:05:05,280
where

00:05:01,600 --> 00:05:06,880
it where it reaches out to encompass a

00:05:05,280 --> 00:05:08,560
circle you can see where it reaches out

00:05:06,880 --> 00:05:12,000
to encompass a square

00:05:08,560 --> 00:05:13,680
and if we were to populate this with the

00:05:12,000 --> 00:05:14,720
initial training set you can actually

00:05:13,680 --> 00:05:16,639
see how

00:05:14,720 --> 00:05:19,360
this particular model has over trained

00:05:16,639 --> 00:05:22,479
and in this scenario you can see the

00:05:19,360 --> 00:05:23,360
the linear the line version the solid

00:05:22,479 --> 00:05:25,039
version

00:05:23,360 --> 00:05:26,960
is still predicting it's still giving

00:05:25,039 --> 00:05:27,440
you information about the overall data

00:05:26,960 --> 00:05:29,120
set

00:05:27,440 --> 00:05:33,120
and but is also giving you less

00:05:29,120 --> 00:05:33,120
information about any individual

00:05:34,800 --> 00:05:38,000
so this means that the very first thing

00:05:37,039 --> 00:05:40,720
you should do

00:05:38,000 --> 00:05:41,840
in terms of protecting your your

00:05:40,720 --> 00:05:44,479
information

00:05:41,840 --> 00:05:45,919
is you should reduce your overfitting

00:05:44,479 --> 00:05:47,840
and so there are several techniques we

00:05:45,919 --> 00:05:48,560
can which you can use this is not a full

00:05:47,840 --> 00:05:51,840
survey of

00:05:48,560 --> 00:05:53,120
of how to reduce that that form uh of

00:05:51,840 --> 00:05:55,039
bias but

00:05:53,120 --> 00:05:56,560
there are tools that are very well used

00:05:55,039 --> 00:05:58,479
throughout throughout the industry that

00:05:56,560 --> 00:06:00,720
can help you get started so

00:05:58,479 --> 00:06:03,199
the very first thing to realize is that

00:06:00,720 --> 00:06:06,080
smaller networks learn less information

00:06:03,199 --> 00:06:07,840
a network that has 10 nodes or 100 nodes

00:06:06,080 --> 00:06:09,520
is going to learn a lot less information

00:06:07,840 --> 00:06:12,720
than a network that has

00:06:09,520 --> 00:06:15,199
a million nodes or 10 million nodes

00:06:12,720 --> 00:06:16,800
and so so the first thing you should do

00:06:15,199 --> 00:06:18,960
is try to work out what's the smallest

00:06:16,800 --> 00:06:23,120
network that i can provide

00:06:18,960 --> 00:06:25,120
that still gets me a good prediction but

00:06:23,120 --> 00:06:26,800
but isn't too isn't too large so that

00:06:25,120 --> 00:06:28,240
you're not learning too much information

00:06:26,800 --> 00:06:30,319
about the

00:06:28,240 --> 00:06:31,520
about the specific entries within your

00:06:30,319 --> 00:06:32,720
your data set

00:06:31,520 --> 00:06:35,039
there's other techniques such as drop

00:06:32,720 --> 00:06:37,280
dropout that

00:06:35,039 --> 00:06:38,639
will shut off random nodes within your

00:06:37,280 --> 00:06:41,120
graph so that

00:06:38,639 --> 00:06:42,800
that node will will learn less

00:06:41,120 --> 00:06:44,720
information and will generalize a little

00:06:42,800 --> 00:06:46,800
a little bit better you can also train

00:06:44,720 --> 00:06:48,160
on more data so if you train on a small

00:06:46,800 --> 00:06:49,919
data set you'll learn

00:06:48,160 --> 00:06:51,360
details about that small detail that

00:06:49,919 --> 00:06:52,560
small data set when you train on a large

00:06:51,360 --> 00:06:54,400
data set you

00:06:52,560 --> 00:06:55,599
depending on the bias within the data of

00:06:54,400 --> 00:06:57,520
course you learn

00:06:55,599 --> 00:06:58,960
generally learn less information about

00:06:57,520 --> 00:07:02,240
any single

00:06:58,960 --> 00:07:04,240
about any single entry there's regular

00:07:02,240 --> 00:07:05,680
regularization techniques that you can

00:07:04,240 --> 00:07:08,479
add in that help

00:07:05,680 --> 00:07:09,280
suppress some of some of these over

00:07:08,479 --> 00:07:10,880
training

00:07:09,280 --> 00:07:12,960
and of course you also have things like

00:07:10,880 --> 00:07:14,960
data augmentation the ability to add

00:07:12,960 --> 00:07:17,759
additional noise into the system

00:07:14,960 --> 00:07:19,120
in order to help reduce some of the bias

00:07:17,759 --> 00:07:20,800
now these are not the only things you

00:07:19,120 --> 00:07:25,280
should do and we'll get into

00:07:20,800 --> 00:07:25,280
more rigorous techniques shortly

00:07:26,960 --> 00:07:31,039
so another problem that that we have as

00:07:30,639 --> 00:07:34,560
well

00:07:31,039 --> 00:07:36,639
is sensitive access to data so

00:07:34,560 --> 00:07:38,880
most models are developed on centralized

00:07:36,639 --> 00:07:42,160
data sets so

00:07:38,880 --> 00:07:45,520
imagine you're creating a model to

00:07:42,160 --> 00:07:47,039
try to detect some form of cancer so

00:07:45,520 --> 00:07:48,560
the way that it typically works is

00:07:47,039 --> 00:07:50,400
people will gain access

00:07:48,560 --> 00:07:52,080
through could be through hospitals could

00:07:50,400 --> 00:07:53,919
be through research

00:07:52,080 --> 00:07:56,319
organizations that have collected this

00:07:53,919 --> 00:07:58,000
information and they'll centralize all

00:07:56,319 --> 00:08:01,680
that information into a central

00:07:58,000 --> 00:08:02,319
repository and that central repository

00:08:01,680 --> 00:08:04,319
which

00:08:02,319 --> 00:08:05,599
this is uh which could have sensitive

00:08:04,319 --> 00:08:08,639
information is

00:08:05,599 --> 00:08:10,720
uh is then provided to a small group of

00:08:08,639 --> 00:08:12,080
researchers who then can run their ai

00:08:10,720 --> 00:08:13,680
model training loop

00:08:12,080 --> 00:08:15,599
and so you can see in the the

00:08:13,680 --> 00:08:18,400
environment on the right

00:08:15,599 --> 00:08:20,240
that decentralized data and the ai model

00:08:18,400 --> 00:08:24,080
training loop are both coupled closely

00:08:20,240 --> 00:08:27,520
together within the training environment

00:08:24,080 --> 00:08:28,639
so one of the questions that that comes

00:08:27,520 --> 00:08:31,120
up is

00:08:28,639 --> 00:08:32,719
what if the parties who own the data do

00:08:31,120 --> 00:08:34,479
not want to share the information

00:08:32,719 --> 00:08:36,640
to the central group or to the central

00:08:34,479 --> 00:08:39,680
authority

00:08:36,640 --> 00:08:41,440
so one technique that we have to

00:08:39,680 --> 00:08:43,279
to work with this is to use something

00:08:41,440 --> 00:08:46,480
called federated learning

00:08:43,279 --> 00:08:47,839
and federated learning allows you to

00:08:46,480 --> 00:08:51,200
develop a model

00:08:47,839 --> 00:08:52,880
without having access to the model

00:08:51,200 --> 00:08:54,800
directly but instead you

00:08:52,880 --> 00:08:57,200
work and coordinate with lots of other

00:08:54,800 --> 00:08:57,920
agents so that they each train a small

00:08:57,200 --> 00:08:59,519
part of the

00:08:57,920 --> 00:09:00,959
network and then they send you back

00:08:59,519 --> 00:09:02,640
updates

00:09:00,959 --> 00:09:04,959
so if you look in the graph on the right

00:09:02,640 --> 00:09:06,160
we have three three stages we have the

00:09:04,959 --> 00:09:08,640
first one is the

00:09:06,160 --> 00:09:10,080
model we have a central model that has

00:09:08,640 --> 00:09:13,839
some initial predictor

00:09:10,080 --> 00:09:15,839
that gets pushed out to a remote set of

00:09:13,839 --> 00:09:17,360
of agents those agents have some data

00:09:15,839 --> 00:09:19,120
that they can train on

00:09:17,360 --> 00:09:21,440
each of them does their local training

00:09:19,120 --> 00:09:24,160
loop and produces a

00:09:21,440 --> 00:09:25,600
produce as a new model those the updates

00:09:24,160 --> 00:09:28,959
to those new models

00:09:25,600 --> 00:09:32,480
get sent back to the original

00:09:28,959 --> 00:09:34,399
to your repository and that

00:09:32,480 --> 00:09:34,810
those models then become aggregated they

00:09:34,399 --> 00:09:36,240
become

00:09:34,810 --> 00:09:38,640
[Music]

00:09:36,240 --> 00:09:39,920
they can be ensemble together they could

00:09:38,640 --> 00:09:41,519
also be

00:09:39,920 --> 00:09:43,040
averaged out there's various techniques

00:09:41,519 --> 00:09:43,519
you can use to work out how do you want

00:09:43,040 --> 00:09:45,519
to

00:09:43,519 --> 00:09:46,560
join them but what ends up happening is

00:09:45,519 --> 00:09:48,640
that there's a way that they

00:09:46,560 --> 00:09:50,080
these models can get joined together to

00:09:48,640 --> 00:09:52,800
produce a a

00:09:50,080 --> 00:09:54,080
single a single model or a single set of

00:09:52,800 --> 00:09:57,440
models

00:09:54,080 --> 00:09:58,959
so this helps this helps with the

00:09:57,440 --> 00:10:00,560
with the issue where you might have

00:09:58,959 --> 00:10:02,240
sensitive data that

00:10:00,560 --> 00:10:04,240
multiple organizations don't want to

00:10:02,240 --> 00:10:06,959
share directly with another organization

00:10:04,240 --> 00:10:08,480
for a variety of reasons and so it still

00:10:06,959 --> 00:10:09,680
allows you to gain access to train on

00:10:08,480 --> 00:10:12,480
these models

00:10:09,680 --> 00:10:14,160
across multiple organizations without

00:10:12,480 --> 00:10:17,200
owning the data itself without ever

00:10:14,160 --> 00:10:19,600
having access to that original data

00:10:17,200 --> 00:10:20,399
but even then that's still not uh not

00:10:19,600 --> 00:10:23,680
enough

00:10:20,399 --> 00:10:26,160
so can we what

00:10:23,680 --> 00:10:27,680
one of the things is this in in this uh

00:10:26,160 --> 00:10:30,240
problem is that

00:10:27,680 --> 00:10:31,920
can we model population without modeling

00:10:30,240 --> 00:10:33,680
without modeling the individuals in the

00:10:31,920 --> 00:10:36,240
population because

00:10:33,680 --> 00:10:36,959
if you recall you still have this

00:10:36,240 --> 00:10:38,959
problem

00:10:36,959 --> 00:10:40,000
that that exists you still have this

00:10:38,959 --> 00:10:41,440
line that

00:10:40,000 --> 00:10:43,120
uh that can get created that still

00:10:41,440 --> 00:10:45,440
exposes information

00:10:43,120 --> 00:10:47,279
and federated learning by itself doesn't

00:10:45,440 --> 00:10:47,680
solve that although it is a piece of the

00:10:47,279 --> 00:10:50,480
step

00:10:47,680 --> 00:10:51,839
towards removing access and preserving

00:10:50,480 --> 00:10:54,880
privacy

00:10:51,839 --> 00:10:56,399
so um so again

00:10:54,880 --> 00:10:58,000
phrasing the question again can we model

00:10:56,399 --> 00:10:59,040
a population without modeling the

00:10:58,000 --> 00:11:00,800
individuals of the pop

00:10:59,040 --> 00:11:02,880
of the population so if you have a

00:11:00,800 --> 00:11:04,480
sensitive question a sensitive question

00:11:02,880 --> 00:11:06,880
could be something like do you have any

00:11:04,480 --> 00:11:08,959
history of mental illness in your family

00:11:06,880 --> 00:11:11,040
you get a complex answer because there

00:11:08,959 --> 00:11:11,680
may be legal and social implications the

00:11:11,040 --> 00:11:14,000
same

00:11:11,680 --> 00:11:14,880
may be about drug use in the in the past

00:11:14,000 --> 00:11:19,200
or

00:11:14,880 --> 00:11:22,160
um or criminal history or

00:11:19,200 --> 00:11:23,600
so on so these type of sense pieces of

00:11:22,160 --> 00:11:26,839
sensitive information if you

00:11:23,600 --> 00:11:28,160
if you ask this question to a person you

00:11:26,839 --> 00:11:30,480
me

00:11:28,160 --> 00:11:31,200
they may choose not to answer it and you

00:11:30,480 --> 00:11:33,360
get bias

00:11:31,200 --> 00:11:35,120
from people who who are more comfortable

00:11:33,360 --> 00:11:37,200
answering or they just may

00:11:35,120 --> 00:11:38,800
they may lie about it because they want

00:11:37,200 --> 00:11:40,000
to participate and being seen not to

00:11:38,800 --> 00:11:41,600
participate

00:11:40,000 --> 00:11:42,959
they feel can give can give away

00:11:41,600 --> 00:11:44,480
information about themselves so they

00:11:42,959 --> 00:11:46,399
would opt to lie instead and

00:11:44,480 --> 00:11:48,160
adds in additional bias into you into

00:11:46,399 --> 00:11:50,959
your system

00:11:48,160 --> 00:11:51,920
so one of the techniques we can use to

00:11:50,959 --> 00:11:53,600
help with this

00:11:51,920 --> 00:11:55,120
is a technique called differential

00:11:53,600 --> 00:11:57,200
privacy so

00:11:55,120 --> 00:11:58,480
differential privacy can be used without

00:11:57,200 --> 00:12:01,920
machine learning

00:11:58,480 --> 00:12:04,079
and what what we do is we add noise to

00:12:01,920 --> 00:12:06,000
both the inputs and the outputs and so i

00:12:04,079 --> 00:12:08,399
have a very simple example let's take

00:12:06,000 --> 00:12:10,880
that same question that we had before

00:12:08,399 --> 00:12:12,079
and about whether you have a whether you

00:12:10,880 --> 00:12:14,079
have a history of

00:12:12,079 --> 00:12:15,760
mental illness illness in your family

00:12:14,079 --> 00:12:17,040
and you were to ask this as part of a

00:12:15,760 --> 00:12:19,760
survey

00:12:17,040 --> 00:12:21,600
just a like a written survey and if you

00:12:19,760 --> 00:12:23,680
just ask the question you'll get bias

00:12:21,600 --> 00:12:24,959
so what we can do is we can put a person

00:12:23,680 --> 00:12:27,680
into into a

00:12:24,959 --> 00:12:28,560
private room and there is a non-biased

00:12:27,680 --> 00:12:31,200
coin

00:12:28,560 --> 00:12:32,800
that uh that that is there maybe the

00:12:31,200 --> 00:12:34,720
user even provides the coin themselves

00:12:32,800 --> 00:12:36,079
so they know that it's not a tab it has

00:12:34,720 --> 00:12:38,160
not been tampered with

00:12:36,079 --> 00:12:40,399
and so what they do is they start the

00:12:38,160 --> 00:12:43,200
instructions say you toss the coin

00:12:40,399 --> 00:12:45,279
if it's heads you toss the coin again

00:12:43,200 --> 00:12:48,160
which erases the initial answer

00:12:45,279 --> 00:12:48,560
and then you answer the question if the

00:12:48,160 --> 00:12:51,839
first

00:12:48,560 --> 00:12:52,240
coin toss was tails you toss the coin

00:12:51,839 --> 00:12:54,800
again

00:12:52,240 --> 00:12:56,639
if it's heads you answer yes if it's

00:12:54,800 --> 00:13:00,399
tails you answer no

00:12:56,639 --> 00:13:02,560
what this allows the what this allows

00:13:00,399 --> 00:13:03,600
us to do is it adds plausible

00:13:02,560 --> 00:13:05,680
deniability

00:13:03,600 --> 00:13:07,920
into the answers by plausible

00:13:05,680 --> 00:13:09,680
deniability what this means is

00:13:07,920 --> 00:13:11,120
if you ask the person who filled out the

00:13:09,680 --> 00:13:14,399
survey hey

00:13:11,120 --> 00:13:17,839
you answered yes do you do um

00:13:14,399 --> 00:13:19,519
to this do you do that means you have

00:13:17,839 --> 00:13:20,000
this particular condition or you have

00:13:19,519 --> 00:13:22,560
this this

00:13:20,000 --> 00:13:23,920
history the person can say oh no i

00:13:22,560 --> 00:13:26,720
answered the coin toss

00:13:23,920 --> 00:13:28,079
so it gives them the ability to to not

00:13:26,720 --> 00:13:30,720
provide information about

00:13:28,079 --> 00:13:32,480
themselves directly but ins but still

00:13:30,720 --> 00:13:33,920
gives you the ability to

00:13:32,480 --> 00:13:35,279
to find something about the overall

00:13:33,920 --> 00:13:36,639
population because you know the

00:13:35,279 --> 00:13:39,680
probability of the twin

00:13:36,639 --> 00:13:42,240
of the coin toss and and you're able to

00:13:39,680 --> 00:13:44,320
then model that into into your system

00:13:42,240 --> 00:13:45,680
so it turns out that this technique you

00:13:44,320 --> 00:13:48,240
can also apply into

00:13:45,680 --> 00:13:49,839
into machine learning you can apply

00:13:48,240 --> 00:13:52,000
noise to the input

00:13:49,839 --> 00:13:53,839
you can apply noise to the output you

00:13:52,000 --> 00:13:55,519
can cap the

00:13:53,839 --> 00:13:58,000
learning rates so that you don't learn

00:13:55,519 --> 00:14:00,720
too much information on a single pass

00:13:58,000 --> 00:14:02,560
and you're able to then quantify how

00:14:00,720 --> 00:14:05,040
much information is is

00:14:02,560 --> 00:14:06,560
been encoded into the system and this

00:14:05,040 --> 00:14:09,120
this actually turns out to

00:14:06,560 --> 00:14:09,920
also help generalize your model it's a

00:14:09,120 --> 00:14:11,440
it

00:14:09,920 --> 00:14:14,480
because you're not learning about

00:14:11,440 --> 00:14:16,880
information about an individual

00:14:14,480 --> 00:14:17,600
an individual user in in the same in the

00:14:16,880 --> 00:14:20,639
same

00:14:17,600 --> 00:14:24,240
level so

00:14:20,639 --> 00:14:26,639
another technique that we use as well to

00:14:24,240 --> 00:14:29,600
that is that is related is secure

00:14:26,639 --> 00:14:32,480
multi-party compute

00:14:29,600 --> 00:14:32,959
so secure multi-party compute is where

00:14:32,480 --> 00:14:34,959
you have

00:14:32,959 --> 00:14:37,120
two parties who want to collaborate but

00:14:34,959 --> 00:14:40,399
do not want to share information

00:14:37,120 --> 00:14:41,760
so what happens is the data is converted

00:14:40,399 --> 00:14:44,240
into multiple

00:14:41,760 --> 00:14:45,760
component spaces so in other words a

00:14:44,240 --> 00:14:49,040
gets turned into a1

00:14:45,760 --> 00:14:52,959
a2 b gets turned into b1

00:14:49,040 --> 00:14:55,120
b2 and b3 and in this graph on the right

00:14:52,959 --> 00:14:57,279
we have three separate organizations we

00:14:55,120 --> 00:14:58,399
have the one organization that owns all

00:14:57,279 --> 00:14:59,920
the circles

00:14:58,399 --> 00:15:01,760
one organization that owns all the

00:14:59,920 --> 00:15:03,760
squares and a third

00:15:01,760 --> 00:15:05,680
come and a third company which is a

00:15:03,760 --> 00:15:08,720
trusted third party

00:15:05,680 --> 00:15:12,480
is a is the diamond so

00:15:08,720 --> 00:15:14,880
what happens is that the the components

00:15:12,480 --> 00:15:15,760
these component spaces these a1 a2 and

00:15:14,880 --> 00:15:18,800
a3

00:15:15,760 --> 00:15:22,000
uh are produced from a and they get sent

00:15:18,800 --> 00:15:24,880
to each piece gets sent to to each

00:15:22,000 --> 00:15:26,240
party respectively um the same occurs

00:15:24,880 --> 00:15:27,680
with uh with b

00:15:26,240 --> 00:15:30,240
and they all perform the same

00:15:27,680 --> 00:15:33,199
computation on the data

00:15:30,240 --> 00:15:34,160
and but which is and what happens is

00:15:33,199 --> 00:15:36,880
that

00:15:34,160 --> 00:15:38,320
the the sent the center graphs uh the

00:15:36,880 --> 00:15:40,720
center parts like the one that's perf

00:15:38,320 --> 00:15:41,759
that's performing that function f is not

00:15:40,720 --> 00:15:44,079
able to

00:15:41,759 --> 00:15:45,920
to reason about like what is what is

00:15:44,079 --> 00:15:48,880
what is a from a1 what is b

00:15:45,920 --> 00:15:51,040
from b1 the same is true with uh with

00:15:48,880 --> 00:15:52,320
the square and the same is true for

00:15:51,040 --> 00:15:54,639
for the diamond but then once you

00:15:52,320 --> 00:15:57,279
combine the information back together

00:15:54,639 --> 00:15:58,959
then you can get the result of the of

00:15:57,279 --> 00:16:01,120
the process without having

00:15:58,959 --> 00:16:03,279
shared the original information itself

00:16:01,120 --> 00:16:04,639
now there are some limitations to this

00:16:03,279 --> 00:16:07,199
technique

00:16:04,639 --> 00:16:08,240
in short if you have any form and this

00:16:07,199 --> 00:16:10,160
this is for

00:16:08,240 --> 00:16:12,000
more for some of the mathematicians in

00:16:10,160 --> 00:16:15,120
in the room if you have

00:16:12,000 --> 00:16:16,880
if you have anything that is uh

00:16:15,120 --> 00:16:18,240
that is non-linear then you need to be

00:16:16,880 --> 00:16:20,320
very careful with this technique

00:16:18,240 --> 00:16:22,000
it tends to break what this means is

00:16:20,320 --> 00:16:25,040
that in a from an ai

00:16:22,000 --> 00:16:27,360
perspective you're able to

00:16:25,040 --> 00:16:28,880
you're able to perform the initial the

00:16:27,360 --> 00:16:29,519
initial work on the on the graph you're

00:16:28,880 --> 00:16:31,040
able to

00:16:29,519 --> 00:16:32,800
to do the multiplication and the

00:16:31,040 --> 00:16:36,160
addition but if you

00:16:32,800 --> 00:16:39,360
tie in something like a tangent then uh

00:16:36,160 --> 00:16:40,560
you your output is likely to to break in

00:16:39,360 --> 00:16:43,279
that scenario

00:16:40,560 --> 00:16:44,959
but branch predictions still work so

00:16:43,279 --> 00:16:45,680
this means that you're able to perform

00:16:44,959 --> 00:16:48,160
your

00:16:45,680 --> 00:16:49,839
your predictions as long as you stick to

00:16:48,160 --> 00:16:51,839
things that are that are linear so this

00:16:49,839 --> 00:16:53,040
does limit some techniques

00:16:51,839 --> 00:16:55,279
that you can use but it's still a

00:16:53,040 --> 00:16:59,279
powerful technique that when you're

00:16:55,279 --> 00:17:01,920
when when your problem fits this this

00:16:59,279 --> 00:17:05,839
this space then it is a tool in your box

00:17:01,920 --> 00:17:05,839
that you can reach for and use

00:17:06,319 --> 00:17:10,000
so going on to some of the

00:17:08,000 --> 00:17:13,120
infrastructure work

00:17:10,000 --> 00:17:14,640
there is a environment called a trusted

00:17:13,120 --> 00:17:17,679
execution environment

00:17:14,640 --> 00:17:19,160
and so what what this is is

00:17:17,679 --> 00:17:22,079
if you look at traditional

00:17:19,160 --> 00:17:24,720
containerization techniques you have

00:17:22,079 --> 00:17:26,160
virtual machines you have containers

00:17:24,720 --> 00:17:26,959
linux containers that have that have

00:17:26,160 --> 00:17:28,880
come up

00:17:26,959 --> 00:17:31,120
and all of these are centered around

00:17:28,880 --> 00:17:34,960
protecting the host

00:17:31,120 --> 00:17:38,640
the host operating system from the guest

00:17:34,960 --> 00:17:41,280
and so that guest one

00:17:38,640 --> 00:17:43,440
would would in most scenarios would

00:17:41,280 --> 00:17:44,400
would have limited to no capability to

00:17:43,440 --> 00:17:47,840
influence guest

00:17:44,400 --> 00:17:50,880
2 or or the host in

00:17:47,840 --> 00:17:52,880
a trusted execution environment it's

00:17:50,880 --> 00:17:54,480
it's about the the op protecting in the

00:17:52,880 --> 00:17:58,840
opposite path it's about protecting

00:17:54,480 --> 00:18:01,919
the guest from a from a host

00:17:58,840 --> 00:18:03,600
so so effectively trusted execution

00:18:01,919 --> 00:18:06,080
environments are containers which

00:18:03,600 --> 00:18:07,039
protect the guest from from snooping

00:18:06,080 --> 00:18:09,440
from the host

00:18:07,039 --> 00:18:10,240
the way that this works is that there is

00:18:09,440 --> 00:18:11,679
a hardware

00:18:10,240 --> 00:18:14,320
there's some new hardware that's gone

00:18:11,679 --> 00:18:17,840
into the the latest set of uh

00:18:14,320 --> 00:18:20,480
of chips so you have intel and amd and

00:18:17,840 --> 00:18:21,919
an arm and so on have they have a way to

00:18:20,480 --> 00:18:25,280
encrypt them the memory

00:18:21,919 --> 00:18:26,720
of the of the process

00:18:25,280 --> 00:18:28,480
so you're able to create what's called a

00:18:26,720 --> 00:18:30,559
secure enclave

00:18:28,480 --> 00:18:32,559
and the secure enclave you can then

00:18:30,559 --> 00:18:35,440
deploy software into

00:18:32,559 --> 00:18:37,039
in and say keep it separate from the

00:18:35,440 --> 00:18:38,480
host because the host and each of the

00:18:37,039 --> 00:18:39,679
guests are all encrypted with a

00:18:38,480 --> 00:18:42,799
different key

00:18:39,679 --> 00:18:45,760
and it minimizes the performance impact

00:18:42,799 --> 00:18:47,039
because you're you're not you're not

00:18:45,760 --> 00:18:50,320
doing the

00:18:47,039 --> 00:18:51,039
uh the computation on an expensive on an

00:18:50,320 --> 00:18:53,300
expensive

00:18:51,039 --> 00:18:54,480
key and it's hardware accelerated in

00:18:53,300 --> 00:18:57,600
[Music]

00:18:54,480 --> 00:19:00,640
in its uh encryption and decryption path

00:18:57,600 --> 00:19:04,000
and the keys are typically stored in the

00:19:00,640 --> 00:19:06,080
in in the processor itself or in a

00:19:04,000 --> 00:19:07,360
trusted chip that's that's alongside the

00:19:06,080 --> 00:19:11,039
the processor

00:19:07,360 --> 00:19:14,160
so what this allows us to do is that

00:19:11,039 --> 00:19:15,840
assuming you can attest the uh the

00:19:14,160 --> 00:19:17,679
the guess that you're deploying to and

00:19:15,840 --> 00:19:19,679
guarantee that it is in fact running in

00:19:17,679 --> 00:19:22,480
a trusted execution environment

00:19:19,679 --> 00:19:23,600
it means that you can ship a sensitive

00:19:22,480 --> 00:19:26,480
workload

00:19:23,600 --> 00:19:28,240
to a cloud environment and have some

00:19:26,480 --> 00:19:29,200
protection from the host being able to

00:19:28,240 --> 00:19:32,559
inspect what's

00:19:29,200 --> 00:19:32,559
uh what's inside of them

00:19:35,919 --> 00:19:41,600
there is also a um another technique

00:19:39,280 --> 00:19:45,360
that's uh that's coming around

00:19:41,600 --> 00:19:48,559
so there and if you look at how

00:19:45,360 --> 00:19:51,840
systems are defended against today in

00:19:48,559 --> 00:19:52,880
your security model you have uh you tend

00:19:51,840 --> 00:19:53,600
to have something called perimeter

00:19:52,880 --> 00:19:55,280
defense

00:19:53,600 --> 00:19:57,840
the idea behind a perimeter defense is

00:19:55,280 --> 00:20:00,640
if you look at the top graphic

00:19:57,840 --> 00:20:03,120
you have a trusted network with a

00:20:00,640 --> 00:20:06,320
workload inside of it

00:20:03,120 --> 00:20:08,080
this trusted workload is

00:20:06,320 --> 00:20:10,320
it needs to communicate with a second

00:20:08,080 --> 00:20:13,360
workload that's in a different network

00:20:10,320 --> 00:20:15,679
so what ends up happening is typically

00:20:13,360 --> 00:20:16,880
these there'll be a secure connection

00:20:15,679 --> 00:20:18,000
between the two networks that's

00:20:16,880 --> 00:20:21,280
established

00:20:18,000 --> 00:20:24,159
and that that connection will be

00:20:21,280 --> 00:20:25,440
defended by putting a firewall between

00:20:24,159 --> 00:20:28,720
the two networks

00:20:25,440 --> 00:20:30,480
or they may have a vpn that

00:20:28,720 --> 00:20:32,159
that allows one network to communicate

00:20:30,480 --> 00:20:34,799
with another network

00:20:32,159 --> 00:20:36,000
so one of the problems is if the

00:20:34,799 --> 00:20:39,039
attacker enters

00:20:36,000 --> 00:20:41,600
the trusted network then

00:20:39,039 --> 00:20:43,360
they're typically able to access systems

00:20:41,600 --> 00:20:47,760
within that trusted network

00:20:43,360 --> 00:20:50,480
with um with very few limitations

00:20:47,760 --> 00:20:52,240
and so we see these types of uh of

00:20:50,480 --> 00:20:55,120
attacks go on quite uh

00:20:52,240 --> 00:20:56,799
quite often and there's some very famous

00:20:55,120 --> 00:21:00,559
attacks that have occurred where

00:20:56,799 --> 00:21:04,000
a user is where the operator

00:21:00,559 --> 00:21:05,360
has had some uh some

00:21:04,000 --> 00:21:07,280
web service that's exposed to the

00:21:05,360 --> 00:21:09,919
internet and uh attacker will

00:21:07,280 --> 00:21:10,880
will end up uh breaking into that web

00:21:09,919 --> 00:21:12,400
web service

00:21:10,880 --> 00:21:14,400
and once they have access to that web

00:21:12,400 --> 00:21:16,320
service then that web service straddles

00:21:14,400 --> 00:21:17,280
both the internally and the external

00:21:16,320 --> 00:21:19,440
network

00:21:17,280 --> 00:21:20,480
so they can then scan the internal

00:21:19,440 --> 00:21:22,320
network and find

00:21:20,480 --> 00:21:23,600
databases that exist within that and

00:21:22,320 --> 00:21:26,000
start asking

00:21:23,600 --> 00:21:28,000
start to extract information and there's

00:21:26,000 --> 00:21:29,280
a very high profile and won't give names

00:21:28,000 --> 00:21:30,640
in a scenario with some very high

00:21:29,280 --> 00:21:33,760
profile attacks that had

00:21:30,640 --> 00:21:36,559
this particular profile that have led to

00:21:33,760 --> 00:21:38,080
very significant breaches throughout uh

00:21:36,559 --> 00:21:38,720
throughout the industry both within

00:21:38,080 --> 00:21:42,480
healthcare

00:21:38,720 --> 00:21:45,520
and and out of healthcare

00:21:42,480 --> 00:21:48,159
so what zero trust does

00:21:45,520 --> 00:21:50,080
is it's a different way of thinking of

00:21:48,159 --> 00:21:53,760
of how to perform security

00:21:50,080 --> 00:21:57,520
where the idea is to minimize

00:21:53,760 --> 00:21:59,360
your your overall

00:21:57,520 --> 00:22:00,960
perimeter to the smallest thing possible

00:21:59,360 --> 00:22:02,640
for a given set of workloads so we're

00:22:00,960 --> 00:22:03,919
not saying there's two trusted networks

00:22:02,640 --> 00:22:05,520
instead we're saying

00:22:03,919 --> 00:22:07,280
i have one workload that needs to talk

00:22:05,520 --> 00:22:09,120
to another workload let's

00:22:07,280 --> 00:22:10,480
limit the communication to those

00:22:09,120 --> 00:22:12,320
workloads that are

00:22:10,480 --> 00:22:13,919
that are involved regardless as to what

00:22:12,320 --> 00:22:16,640
network that they're in

00:22:13,919 --> 00:22:18,240
and so the first company to implement

00:22:16,640 --> 00:22:21,520
this at scale

00:22:18,240 --> 00:22:23,520
was uh google's after they were if i

00:22:21,520 --> 00:22:24,640
recall properly after they were attacked

00:22:23,520 --> 00:22:27,200
by a

00:22:24,640 --> 00:22:29,840
advanced persistent threat they decided

00:22:27,200 --> 00:22:31,360
to move over to this uh this approach

00:22:29,840 --> 00:22:33,280
and the way that this particular

00:22:31,360 --> 00:22:36,480
approach tends to work

00:22:33,280 --> 00:22:38,080
is every workload receives some form of

00:22:36,480 --> 00:22:40,080
cryptographic identity

00:22:38,080 --> 00:22:41,679
it's uh you can think of it like a

00:22:40,080 --> 00:22:42,559
certificate in a web server when you

00:22:41,679 --> 00:22:44,880
visit your

00:22:42,559 --> 00:22:46,240
your bank uh it has a cryptographic

00:22:44,880 --> 00:22:48,320
identity so it's the same

00:22:46,240 --> 00:22:50,799
type of cryptographic identity but

00:22:48,320 --> 00:22:52,799
assigned to an internal workload

00:22:50,799 --> 00:22:54,000
and when two workloads communicate with

00:22:52,799 --> 00:22:57,120
each other they have to

00:22:54,000 --> 00:22:59,600
prove to each other by showing their

00:22:57,120 --> 00:23:00,880
their certificates who they are before

00:22:59,600 --> 00:23:04,159
that secure connection

00:23:00,880 --> 00:23:06,000
can occur once that secures

00:23:04,159 --> 00:23:07,280
connection is established we can then

00:23:06,000 --> 00:23:09,840
control

00:23:07,280 --> 00:23:11,200
the communication between them using

00:23:09,840 --> 00:23:12,960
declarative policy

00:23:11,200 --> 00:23:14,720
and declarative policy is basically

00:23:12,960 --> 00:23:16,320
describing what workloads can talk with

00:23:14,720 --> 00:23:16,799
other workloads what messages can you

00:23:16,320 --> 00:23:19,520
send

00:23:16,799 --> 00:23:21,200
across across the wire as opposed to a

00:23:19,520 --> 00:23:23,120
more imperative approach which say

00:23:21,200 --> 00:23:25,039
these ip addresses can talk to these ip

00:23:23,120 --> 00:23:28,000
addresses over this part

00:23:25,039 --> 00:23:29,120
which which becomes uh difficult to

00:23:28,000 --> 00:23:30,720
manage at scale

00:23:29,120 --> 00:23:33,280
and it is how people do it today but

00:23:30,720 --> 00:23:35,440
it's a it's a very hard problem to

00:23:33,280 --> 00:23:37,120
to scale up in when you're dealing only

00:23:35,440 --> 00:23:40,080
with ips because there's not an

00:23:37,120 --> 00:23:40,960
implicit relationship between an ip or

00:23:40,080 --> 00:23:42,720
rather there is an

00:23:40,960 --> 00:23:44,159
implicit relationship between an ip and

00:23:42,720 --> 00:23:47,440
an identity

00:23:44,159 --> 00:23:50,480
rather than an explicit uh

00:23:47,440 --> 00:23:51,279
relationship so this allows us to

00:23:50,480 --> 00:23:53,120
decouple and it

00:23:51,279 --> 00:23:55,120
allows us to work in more edge

00:23:53,120 --> 00:23:58,159
environments cloud native environments

00:23:55,120 --> 00:24:00,240
groups groups like like kubernetes

00:23:58,159 --> 00:24:02,320
where your workloads can spin up and

00:24:00,240 --> 00:24:03,279
spin down quite quickly the ips they

00:24:02,320 --> 00:24:06,080
receive

00:24:03,279 --> 00:24:06,480
change on a on a regular basis and they

00:24:06,080 --> 00:24:08,080
get

00:24:06,480 --> 00:24:11,039
they get rotated amongst different

00:24:08,080 --> 00:24:14,000
workloads and so this allows you to

00:24:11,039 --> 00:24:14,720
to focus on creating your identity based

00:24:14,000 --> 00:24:16,799
upon what to

00:24:14,720 --> 00:24:18,799
what the workload actually is rather

00:24:16,799 --> 00:24:22,159
than on an underlying

00:24:18,799 --> 00:24:26,240
detail so

00:24:22,159 --> 00:24:26,240
preserving privacy itself

00:24:26,799 --> 00:24:30,000
part of the reason why this is important

00:24:28,240 --> 00:24:32,640
is because we have a whole chain

00:24:30,000 --> 00:24:34,480
of things that need to to occur we have

00:24:32,640 --> 00:24:38,159
when you when you're building out a

00:24:34,480 --> 00:24:40,159
ai we or you're building out a model

00:24:38,159 --> 00:24:41,440
you need to know is where i'm grabbing

00:24:40,159 --> 00:24:44,000
the data from

00:24:41,440 --> 00:24:45,679
a trusted environment am i applying the

00:24:44,000 --> 00:24:49,120
right type of

00:24:45,679 --> 00:24:50,799
of of privacy into it am i adding things

00:24:49,120 --> 00:24:52,720
like differential privacy

00:24:50,799 --> 00:24:54,080
uh what type of communication can i have

00:24:52,720 --> 00:24:55,440
if it's like a federated learning

00:24:54,080 --> 00:24:57,120
example how do i

00:24:55,440 --> 00:24:58,480
how do i know that i'm talking to an

00:24:57,120 --> 00:25:01,840
entity that i that i

00:24:58,480 --> 00:25:03,840
trust who's remote so these type of uh

00:25:01,840 --> 00:25:04,880
these type of models you can't just

00:25:03,840 --> 00:25:06,640
focus on on

00:25:04,880 --> 00:25:08,159
one layer you have to focus on all of

00:25:06,640 --> 00:25:11,120
the layers down from

00:25:08,159 --> 00:25:12,640
the hardware and and what's running all

00:25:11,120 --> 00:25:14,720
the way up to

00:25:12,640 --> 00:25:15,679
the actual process themselves and what's

00:25:14,720 --> 00:25:18,320
uh and what's running

00:25:15,679 --> 00:25:19,679
and what's running on top of them so uh

00:25:18,320 --> 00:25:21,120
this means that you have to have

00:25:19,679 --> 00:25:22,720
cooperation from your

00:25:21,120 --> 00:25:24,640
from your data modelers you have to have

00:25:22,720 --> 00:25:26,640
cooperation from your

00:25:24,640 --> 00:25:29,440
from your infrastructure team the people

00:25:26,640 --> 00:25:31,679
who are building out the pipelines

00:25:29,440 --> 00:25:33,440
and the vendors who are selling you the

00:25:31,679 --> 00:25:37,360
uh the hardware that this stuff

00:25:33,440 --> 00:25:40,960
that this stuff runs on so

00:25:37,360 --> 00:25:43,600
uh in terms of in terms of privacy

00:25:40,960 --> 00:25:44,720
we've applied these particular uh

00:25:43,600 --> 00:25:46,559
systems to

00:25:44,720 --> 00:25:49,039
several of our of our products that we

00:25:46,559 --> 00:25:51,120
have but we want to focus specifically

00:25:49,039 --> 00:25:54,880
in this example on the bottom left with

00:25:51,120 --> 00:25:57,760
uh with passport so

00:25:54,880 --> 00:25:58,880
password itself is a secure application

00:25:57,760 --> 00:26:01,760
that is designed

00:25:58,880 --> 00:26:03,440
to allow to have an employee dashboard

00:26:01,760 --> 00:26:07,039
that is designed to help teams get

00:26:03,440 --> 00:26:08,880
back to a shared physical space

00:26:07,039 --> 00:26:11,840
while simultaneously preserving their

00:26:08,880 --> 00:26:14,240
privacy so

00:26:11,840 --> 00:26:16,000
the way that it ends up working is that

00:26:14,240 --> 00:26:20,640
there's a series of questions that are

00:26:16,000 --> 00:26:23,279
that are asked that that are sensitive

00:26:20,640 --> 00:26:24,720
but are necessary in order to protect

00:26:23,279 --> 00:26:27,200
the population

00:26:24,720 --> 00:26:29,120
and what we do is these questions get

00:26:27,200 --> 00:26:30,720
pushed to the phone in the same way

00:26:29,120 --> 00:26:33,039
use the same heuristic set a set of

00:26:30,720 --> 00:26:33,520
heuristics the questions get pushed to

00:26:33,039 --> 00:26:37,840
the

00:26:33,520 --> 00:26:39,600
to the phone and we we then work on that

00:26:37,840 --> 00:26:41,200
on those set of questions we never send

00:26:39,600 --> 00:26:44,159
the the information

00:26:41,200 --> 00:26:45,120
the the result of any given question to

00:26:44,159 --> 00:26:47,520
the

00:26:45,120 --> 00:26:49,039
back to the central location so the the

00:26:47,520 --> 00:26:52,400
sensitive information stays on

00:26:49,039 --> 00:26:54,000
on the phone and and if they've if

00:26:52,400 --> 00:26:55,039
they've answered all the questions in a

00:26:54,000 --> 00:26:58,799
particular

00:26:55,039 --> 00:27:02,480
way uh that demonstrates that they are

00:26:58,799 --> 00:27:05,120
a safe candidate to come back in then

00:27:02,480 --> 00:27:06,159
they report back saying that that

00:27:05,120 --> 00:27:09,279
they've

00:27:06,159 --> 00:27:12,159
replied uh successfully

00:27:09,279 --> 00:27:12,720
with to each of the questions in a way

00:27:12,159 --> 00:27:15,840
that is

00:27:12,720 --> 00:27:18,960
that determines that they are safe and

00:27:15,840 --> 00:27:20,480
or low risk i should say rather than say

00:27:18,960 --> 00:27:24,000
that they're low risk

00:27:20,480 --> 00:27:26,320
and so we have this gives us the um just

00:27:24,000 --> 00:27:28,159
enough information to report back to the

00:27:26,320 --> 00:27:32,000
employer and to approve the

00:27:28,159 --> 00:27:34,000
the person while simultaneously not

00:27:32,000 --> 00:27:35,679
giving the employer any detailed

00:27:34,000 --> 00:27:38,080
information about what goes in so it's

00:27:35,679 --> 00:27:38,799
sharing a minimum quantity of data back

00:27:38,080 --> 00:27:40,720
sensitive

00:27:38,799 --> 00:27:41,840
sensitive information itself is not

00:27:40,720 --> 00:27:43,440
transmitted

00:27:41,840 --> 00:27:45,760
and the end result is a

00:27:43,440 --> 00:27:48,240
cryptographically signed qr code that

00:27:45,760 --> 00:27:50,159
exists on the phone that they can then

00:27:48,240 --> 00:27:52,720
show and scan it says basically

00:27:50,159 --> 00:27:54,480
effectively says yes i answered this

00:27:52,720 --> 00:27:57,279
i answered these set of questions and

00:27:54,480 --> 00:28:01,440
have and i've attested that

00:27:57,279 --> 00:28:05,360
that the person is low risk

00:28:01,440 --> 00:28:08,399
so on the back end we also make use of

00:28:05,360 --> 00:28:10,159
uh of a zero trust environment and so

00:28:08,399 --> 00:28:12,320
each each of these connections in the

00:28:10,159 --> 00:28:15,520
internal system are

00:28:12,320 --> 00:28:17,360
uh based upon uh are based upon spiffy

00:28:15,520 --> 00:28:21,120
and spire so spiffy

00:28:17,360 --> 00:28:24,000
is a cncf project that describes a

00:28:21,120 --> 00:28:25,679
set of like how do you give out these

00:28:24,000 --> 00:28:26,880
identities how do you rotate these

00:28:25,679 --> 00:28:28,840
identities

00:28:26,880 --> 00:28:30,320
and uh spire is the reference

00:28:28,840 --> 00:28:33,120
implementation of

00:28:30,320 --> 00:28:34,960
the speedy spiffy protocol and so it's

00:28:33,120 --> 00:28:37,919
these both of these are cncf

00:28:34,960 --> 00:28:38,799
projects which is the this which is part

00:28:37,919 --> 00:28:40,720
the same

00:28:38,799 --> 00:28:42,080
organization which also manages

00:28:40,720 --> 00:28:43,760
kubernetes

00:28:42,080 --> 00:28:45,840
so they're they're both they're all

00:28:43,760 --> 00:28:48,320
sibling projects to each other

00:28:45,840 --> 00:28:49,600
and so aspire does the actual work of

00:28:48,320 --> 00:28:50,559
handing out the identities to the

00:28:49,600 --> 00:28:52,080
workloads

00:28:50,559 --> 00:28:54,320
verifying information about the

00:28:52,080 --> 00:28:56,240
workloads what images they're running

00:28:54,320 --> 00:28:58,000
what systems are they running on and

00:28:56,240 --> 00:29:01,279
then open policy agent

00:28:58,000 --> 00:29:02,720
is a system which you can write

00:29:01,279 --> 00:29:05,279
declarative policy

00:29:02,720 --> 00:29:07,039
and that declarative policy is human

00:29:05,279 --> 00:29:10,240
readable and machine readable

00:29:07,039 --> 00:29:11,679
so you can say this workload is this

00:29:10,240 --> 00:29:12,880
application is allowed to talk to this

00:29:11,679 --> 00:29:14,960
database

00:29:12,880 --> 00:29:16,960
and i want them to prove who they are

00:29:14,960 --> 00:29:18,480
using the identities i received from

00:29:16,960 --> 00:29:20,640
spire and they're allowed to send these

00:29:18,480 --> 00:29:22,799
messages and so you can specify the

00:29:20,640 --> 00:29:24,640
interactions using open policy agent an

00:29:22,799 --> 00:29:28,480
open policy agent will then

00:29:24,640 --> 00:29:30,559
read the the input from the request

00:29:28,480 --> 00:29:32,320
and then we'll give you a decision like

00:29:30,559 --> 00:29:33,039
yes this i want to allow this or no i'm

00:29:32,320 --> 00:29:34,799
not going to allow

00:29:33,039 --> 00:29:36,399
this and here's why and it gives you

00:29:34,799 --> 00:29:39,600
that explainability

00:29:36,399 --> 00:29:41,279
and finally these the information that

00:29:39,600 --> 00:29:41,919
is necessary to report back to the

00:29:41,279 --> 00:29:45,200
employer

00:29:41,919 --> 00:29:46,799
is then sent back to a uh to a metrics

00:29:45,200 --> 00:29:48,080
and logging infrastructure where the

00:29:46,799 --> 00:29:51,440
employer can then look in a

00:29:48,080 --> 00:29:52,640
in a dashboard so as an example uh it's

00:29:51,440 --> 00:29:54,080
trying to reduce the

00:29:52,640 --> 00:29:57,200
the total amount of information it's

00:29:54,080 --> 00:30:00,320
sent it uh tries to separate out

00:29:57,200 --> 00:30:00,720
components the the policy is separate

00:30:00,320 --> 00:30:02,640
from

00:30:00,720 --> 00:30:04,399
from the application itself and is

00:30:02,640 --> 00:30:08,559
applied and is

00:30:04,399 --> 00:30:11,840
it is applied as a as a as a

00:30:08,559 --> 00:30:14,960
uniform thing that you can control with

00:30:11,840 --> 00:30:16,880
uh that aspire giving

00:30:14,960 --> 00:30:18,480
giving out the the identities themselves

00:30:16,880 --> 00:30:20,640
like the application cannot ask

00:30:18,480 --> 00:30:22,480
for a specific identity it gets assigned

00:30:20,640 --> 00:30:24,960
an identity based upon based on its

00:30:22,480 --> 00:30:24,960
properties

00:30:25,679 --> 00:30:31,279
with that as a recap

00:30:29,200 --> 00:30:33,120
we want to make sure that we collect

00:30:31,279 --> 00:30:35,440
less data overall

00:30:33,120 --> 00:30:37,200
so when you're building out an ai system

00:30:35,440 --> 00:30:38,799
or any other system that is collecting

00:30:37,200 --> 00:30:39,760
sensitive data it doesn't have to be

00:30:38,799 --> 00:30:42,799
mlai these

00:30:39,760 --> 00:30:45,600
these type of techniques also work in

00:30:42,799 --> 00:30:47,039
other environments or not with other

00:30:45,600 --> 00:30:49,279
with other approaches

00:30:47,039 --> 00:30:51,039
so you want to collect less data overall

00:30:49,279 --> 00:30:53,120
try to collect less sensitive data if

00:30:51,039 --> 00:30:55,360
you can

00:30:53,120 --> 00:30:56,640
exercise good processes for data that

00:30:55,360 --> 00:30:59,760
was collected

00:30:56,640 --> 00:31:01,279
in fact part of this is not just about

00:30:59,760 --> 00:31:02,159
the technology it's also about your

00:31:01,279 --> 00:31:04,000
internal

00:31:02,159 --> 00:31:05,360
processes if you have internally if you

00:31:04,000 --> 00:31:08,240
have if you have

00:31:05,360 --> 00:31:08,799
good discipline within your processes

00:31:08,240 --> 00:31:10,960
then

00:31:08,799 --> 00:31:12,240
this discipline will reflect in your

00:31:10,960 --> 00:31:14,640
technology and in your

00:31:12,240 --> 00:31:16,640
in your choices and will help you

00:31:14,640 --> 00:31:18,159
identify

00:31:16,640 --> 00:31:21,919
clean lines of ownership and clean

00:31:18,159 --> 00:31:21,919
contracts and all of this ends up

00:31:22,080 --> 00:31:25,600
applying good software engineering

00:31:23,440 --> 00:31:27,519
techniques will will help you in this

00:31:25,600 --> 00:31:29,360
path and make sure that you

00:31:27,519 --> 00:31:31,120
the same way that you have your features

00:31:29,360 --> 00:31:32,880
consider privacy as a feature

00:31:31,120 --> 00:31:34,559
don't consider it has a secondary

00:31:32,880 --> 00:31:36,320
bolt-on thing that you've added it is a

00:31:34,559 --> 00:31:39,120
feature in itself

00:31:36,320 --> 00:31:41,120
and it's something that is cross-cutting

00:31:39,120 --> 00:31:43,600
other features

00:31:41,120 --> 00:31:46,720
design that design and prioritize that

00:31:43,600 --> 00:31:49,440
privacy in your architecture

00:31:46,720 --> 00:31:51,600
and importantly do not assume that the

00:31:49,440 --> 00:31:52,559
ai models or the data that you could

00:31:51,600 --> 00:31:55,039
that you trained

00:31:52,559 --> 00:31:56,080
on sensitive data is inherently privacy

00:31:55,039 --> 00:31:58,880
preserving

00:31:56,080 --> 00:32:00,559
so one really famous example of this is

00:31:58,880 --> 00:32:01,360
if you look at the uh the netflix study

00:32:00,559 --> 00:32:04,320
that was done

00:32:01,360 --> 00:32:04,880
in um it was a neck there was a netflix

00:32:04,320 --> 00:32:07,840
prize

00:32:04,880 --> 00:32:09,039
that was released and people came up

00:32:07,840 --> 00:32:10,799
with some pretty

00:32:09,039 --> 00:32:12,159
the idea was to provide enough

00:32:10,799 --> 00:32:15,360
information about

00:32:12,159 --> 00:32:17,760
what movie a user has watched and

00:32:15,360 --> 00:32:20,159
in order to provide better predictions

00:32:17,760 --> 00:32:22,880
it turns out that this data set

00:32:20,159 --> 00:32:23,919
when you pick by itself uh was

00:32:22,880 --> 00:32:26,000
de-identified

00:32:23,919 --> 00:32:27,120
and by itself it was it was pretty

00:32:26,000 --> 00:32:29,360
innocuous but

00:32:27,120 --> 00:32:30,960
when you paired it with information from

00:32:29,360 --> 00:32:34,000
twitter from facebook

00:32:30,960 --> 00:32:36,480
from other social media platforms

00:32:34,000 --> 00:32:37,760
then it turns out that there was enough

00:32:36,480 --> 00:32:39,760
information in there

00:32:37,760 --> 00:32:41,679
that you could then start to personally

00:32:39,760 --> 00:32:43,519
identify people and what movies they

00:32:41,679 --> 00:32:45,200
watch like persons might say i watched a

00:32:43,519 --> 00:32:46,880
movie tonight and i watched this or this

00:32:45,200 --> 00:32:48,159
is my favorite movie and how they rated

00:32:46,880 --> 00:32:49,760
it

00:32:48,159 --> 00:32:51,600
all of this information can be paired

00:32:49,760 --> 00:32:53,360
with other with other things and so if a

00:32:51,600 --> 00:32:56,000
day if a model

00:32:53,360 --> 00:32:57,279
is that is supposed to be private is

00:32:56,000 --> 00:32:59,840
extracted and is

00:32:57,279 --> 00:33:00,720
and is leaked um make the assumption

00:32:59,840 --> 00:33:02,559
that people are going to

00:33:00,720 --> 00:33:04,559
try to pair this up with other data sets

00:33:02,559 --> 00:33:07,200
to try to reduce the um

00:33:04,559 --> 00:33:08,799
to try to reduce the overall privacy the

00:33:07,200 --> 00:33:10,559
differential privacy that we discussed

00:33:08,799 --> 00:33:12,640
earlier helps a lot in this particular

00:33:10,559 --> 00:33:15,440
space because

00:33:12,640 --> 00:33:15,440
it turns out the

00:33:15,919 --> 00:33:19,600
because you because you you have that

00:33:17,600 --> 00:33:20,240
plausible deniability that's built into

00:33:19,600 --> 00:33:22,159
it

00:33:20,240 --> 00:33:25,039
it makes it very difficult to work out

00:33:22,159 --> 00:33:28,480
whether some whether some spike in your

00:33:25,039 --> 00:33:31,919
in your data is real or not it reduces

00:33:28,480 --> 00:33:35,600
it reduces that that

00:33:31,919 --> 00:33:37,120
privacy leak through that uh property

00:33:35,600 --> 00:33:38,640
and think about privacy across your

00:33:37,120 --> 00:33:38,960
whole chain you have the models you have

00:33:38,640 --> 00:33:40,640
your

00:33:38,960 --> 00:33:42,559
pipelines you build you have in the

00:33:40,640 --> 00:33:43,840
infrastructure people tend to

00:33:42,559 --> 00:33:46,000
to separate their infrastructure into

00:33:43,840 --> 00:33:47,600
three parts you have compute you have

00:33:46,000 --> 00:33:50,080
the transport the network and the

00:33:47,600 --> 00:33:52,080
storage all of them have to be designed

00:33:50,080 --> 00:33:53,919
to work with each other they're not

00:33:52,080 --> 00:33:56,000
isolated they're all part of

00:33:53,919 --> 00:33:58,080
a of a solution they're all part of a

00:33:56,000 --> 00:33:58,720
chain make sure that things are designed

00:33:58,080 --> 00:34:00,399
so that

00:33:58,720 --> 00:34:01,840
they have clean interactions with each

00:34:00,399 --> 00:34:03,200
other and can help each other it can

00:34:01,840 --> 00:34:04,960
help

00:34:03,200 --> 00:34:06,559
they can help defend against each other

00:34:04,960 --> 00:34:08,560
like on the compute side

00:34:06,559 --> 00:34:10,480
you you may have a secure storage and a

00:34:08,560 --> 00:34:13,599
secure transport but if you have

00:34:10,480 --> 00:34:14,720
a if you have a bug in your compute and

00:34:13,599 --> 00:34:16,320
the actual hardware

00:34:14,720 --> 00:34:18,159
maybe there's some information that can

00:34:16,320 --> 00:34:19,520
get trans that can be

00:34:18,159 --> 00:34:22,159
transferred to the side things like

00:34:19,520 --> 00:34:25,200
heartbleed or or similar techniques that

00:34:22,159 --> 00:34:26,639
that may come out in the future and so

00:34:25,200 --> 00:34:28,159
how do you how do you defend against

00:34:26,639 --> 00:34:29,280
compute well maybe what you do is you

00:34:28,159 --> 00:34:32,159
only run

00:34:29,280 --> 00:34:34,159
processes from a specific user on a

00:34:32,159 --> 00:34:36,000
specific processor that's been dedicated

00:34:34,159 --> 00:34:36,320
to them for a specific period of time

00:34:36,000 --> 00:34:39,760
and

00:34:36,320 --> 00:34:41,520
uh and you don't co-mingle

00:34:39,760 --> 00:34:43,599
certain types of processes and so like

00:34:41,520 --> 00:34:44,879
think of these type of problems

00:34:43,599 --> 00:34:47,599
if you're working on data that's not

00:34:44,879 --> 00:34:49,200
sensitive it doesn't matter as much

00:34:47,599 --> 00:34:50,879
but if you're working on very sensitive

00:34:49,200 --> 00:34:52,320
data start asking these type of

00:34:50,879 --> 00:34:53,839
questions as to like what can go wrong

00:34:52,320 --> 00:34:54,560
in my computer what can go wrong in my

00:34:53,839 --> 00:34:56,560
model

00:34:54,560 --> 00:34:57,599
how can they how can they defend each

00:34:56,560 --> 00:34:59,680
other and

00:34:57,599 --> 00:35:00,800
cover each other's weaknesses and

00:34:59,680 --> 00:35:03,040
finally

00:35:00,800 --> 00:35:04,640
i strongly recommend that you engage

00:35:03,040 --> 00:35:06,160
with open source communities who are

00:35:04,640 --> 00:35:08,640
focusing on privacy

00:35:06,160 --> 00:35:10,640
in in this area so there are certainly

00:35:08,640 --> 00:35:12,640
multiple organizations within

00:35:10,640 --> 00:35:14,160
the machine learning and ai space that

00:35:12,640 --> 00:35:16,800
are starting to have a focus on this and

00:35:14,160 --> 00:35:19,839
this is the tip of the spear

00:35:16,800 --> 00:35:20,480
i'm also hoping that uh that linux

00:35:19,839 --> 00:35:23,440
foundation

00:35:20,480 --> 00:35:25,520
ieee and other similar groups start to

00:35:23,440 --> 00:35:26,880
also invest heavily on not just the

00:35:25,520 --> 00:35:28,640
security side like there's a new

00:35:26,880 --> 00:35:30,480
security organization within linux

00:35:28,640 --> 00:35:32,320
foundation but also focus on

00:35:30,480 --> 00:35:34,160
on privacy because security and privacy

00:35:32,320 --> 00:35:36,240
are even though they're related are not

00:35:34,160 --> 00:35:38,880
the same thing

00:35:36,240 --> 00:35:39,520
private security is very often focused

00:35:38,880 --> 00:35:41,680
around

00:35:39,520 --> 00:35:43,119
who's doing what how do i make sure that

00:35:41,680 --> 00:35:44,720
only i unauthorized

00:35:43,119 --> 00:35:46,240
that i can authenticate and authorize a

00:35:44,720 --> 00:35:49,599
user and

00:35:46,240 --> 00:35:50,640
defend and defend things privacy is

00:35:49,599 --> 00:35:52,720
about how do i

00:35:50,640 --> 00:35:54,560
not learn or how do i not share

00:35:52,720 --> 00:35:57,119
sensitive information they're both

00:35:54,560 --> 00:35:57,599
tightly coupled with each other but

00:35:57,119 --> 00:35:59,520
they're

00:35:57,599 --> 00:36:01,680
they're two side they're they're they're

00:35:59,520 --> 00:36:04,480
two separate orthogonal

00:36:01,680 --> 00:36:06,960
things that that do have some

00:36:04,480 --> 00:36:08,640
implications with each other

00:36:06,960 --> 00:36:10,640
and with that i want to thank everyone

00:36:08,640 --> 00:36:13,040
for joining and listening in and if you

00:36:10,640 --> 00:36:14,960
have any questions

00:36:13,040 --> 00:36:16,079
feel free to ask here in the webinar

00:36:14,960 --> 00:36:18,880
while it's on

00:36:16,079 --> 00:36:19,680
you can also reach out to me i have my

00:36:18,880 --> 00:36:22,560
name here

00:36:19,680 --> 00:36:23,040
on the cncf slack if you're not on cncf

00:36:22,560 --> 00:36:24,320
slack

00:36:23,040 --> 00:36:26,079
there's a link there on how to gain

00:36:24,320 --> 00:36:29,040
access for information

00:36:26,079 --> 00:36:29,760
about doc ai and its products and what

00:36:29,040 --> 00:36:32,800
we're doing

00:36:29,760 --> 00:36:35,599
or if you want to join us in

00:36:32,800 --> 00:36:36,079
in producing or building some of this

00:36:35,599 --> 00:36:38,160
stuff

00:36:36,079 --> 00:36:41,040
you can send us an email at info dockyi

00:36:38,160 --> 00:36:42,720
as well and we'll be happy to answer any

00:36:41,040 --> 00:36:55,839
questions

00:36:42,720 --> 00:36:55,839
thank you very much

00:37:04,160 --> 00:37:08,560
okay thanks everyone for joining us um

00:37:07,119 --> 00:37:10,480
going to go ahead and

00:37:08,560 --> 00:37:23,839
have frederick answer a few questions

00:37:10,480 --> 00:37:23,839
here i'm going to share my screen

00:37:42,400 --> 00:37:49,119
great so in terms of uh

00:37:45,599 --> 00:37:51,920
questions so let me

00:37:49,119 --> 00:37:54,000
i'll go ahead and um and uh read some of

00:37:51,920 --> 00:37:54,000
them

00:37:54,400 --> 00:37:58,320
so one of the questions is what do you

00:37:56,560 --> 00:38:00,480
do to recommend to assure compliance of

00:37:58,320 --> 00:38:04,560
ai models with privacy regulations

00:38:00,480 --> 00:38:07,599
like the gdp gdpr in europe

00:38:04,560 --> 00:38:10,880
so gdpr is uh

00:38:07,599 --> 00:38:15,440
is a very interesting um

00:38:10,880 --> 00:38:17,920
scenario so i'm not an expert in gdpr so

00:38:15,440 --> 00:38:20,160
i want to be a little bit careful please

00:38:17,920 --> 00:38:21,280
take a take in mind with take my answer

00:38:20,160 --> 00:38:24,000
a little bit of grain of salt and get

00:38:21,280 --> 00:38:26,880
some expert advice in this area

00:38:24,000 --> 00:38:28,800
my understanding with this from uh from

00:38:26,880 --> 00:38:30,960
the privacy side is that

00:38:28,800 --> 00:38:32,720
if you have data that is uh that

00:38:30,960 --> 00:38:34,079
originates from a user you have to be

00:38:32,720 --> 00:38:35,920
able to track

00:38:34,079 --> 00:38:38,079
uh and be able to delete information

00:38:35,920 --> 00:38:39,760
from that user in specific ways and

00:38:38,079 --> 00:38:42,720
there's rules on

00:38:39,760 --> 00:38:43,520
uh on who can perform actions as a as a

00:38:42,720 --> 00:38:47,200
processor

00:38:43,520 --> 00:38:51,520
of that of that data and so

00:38:47,200 --> 00:38:54,079
in some ways there are some some similar

00:38:51,520 --> 00:38:55,040
uh there are there are some similarities

00:38:54,079 --> 00:38:57,040
with how

00:38:55,040 --> 00:38:58,560
hipaa tends to work within the united

00:38:57,040 --> 00:39:00,800
states so

00:38:58,560 --> 00:39:02,240
like in with hipaa if you want to work

00:39:00,800 --> 00:39:02,880
if you want to share some sensitive

00:39:02,240 --> 00:39:05,359
information

00:39:02,880 --> 00:39:06,320
to have some processing done or you you

00:39:05,359 --> 00:39:09,359
want someone to

00:39:06,320 --> 00:39:11,280
work in uh in a specific way

00:39:09,359 --> 00:39:12,960
on some sensitive data you generally

00:39:11,280 --> 00:39:15,200
have to

00:39:12,960 --> 00:39:16,720
you you have to get them under a what's

00:39:15,200 --> 00:39:18,160
called a baa

00:39:16,720 --> 00:39:20,079
i believe it stands for business

00:39:18,160 --> 00:39:22,320
associate agreement and

00:39:20,079 --> 00:39:23,680
this means that you can audit you may

00:39:22,320 --> 00:39:26,240
have to audit

00:39:23,680 --> 00:39:27,280
the the organization in some scenarios

00:39:26,240 --> 00:39:29,839
you have certain

00:39:27,280 --> 00:39:30,880
requirements in terms of how the data is

00:39:29,839 --> 00:39:33,920
passed

00:39:30,880 --> 00:39:35,440
and there's a a legal infrastructure

00:39:33,920 --> 00:39:38,400
that gets established between

00:39:35,440 --> 00:39:38,800
between the companies and i think that

00:39:38,400 --> 00:39:42,320
if

00:39:38,800 --> 00:39:44,079
that with gdpr if you want to

00:39:42,320 --> 00:39:45,920
play it safely it's not just about the

00:39:44,079 --> 00:39:48,400
technology it's also about the people so

00:39:45,920 --> 00:39:50,400
we want to make sure that

00:39:48,400 --> 00:39:51,599
that you establish those same type of

00:39:50,400 --> 00:39:53,839
things say like hey

00:39:51,599 --> 00:39:55,599
i have some sensitive data and i'm going

00:39:53,839 --> 00:39:58,640
to provide you with that sensitive data

00:39:55,599 --> 00:40:02,000
so you can provide a service

00:39:58,640 --> 00:40:04,480
set up that legal infrastructure so that

00:40:02,000 --> 00:40:06,000
you can ensure that they protect the

00:40:04,480 --> 00:40:09,200
data as well

00:40:06,000 --> 00:40:10,240
and also that if they breach the the

00:40:09,200 --> 00:40:12,960
agreement

00:40:10,240 --> 00:40:13,920
that they take responsibility for for it

00:40:12,960 --> 00:40:15,680
as well that they

00:40:13,920 --> 00:40:17,040
they don't just palm it off back on you

00:40:15,680 --> 00:40:19,040
and saying oh we were just the

00:40:17,040 --> 00:40:20,240
we were just the processor never mind

00:40:19,040 --> 00:40:22,960
you know that the

00:40:20,240 --> 00:40:25,119
techniques that they used were were not

00:40:22,960 --> 00:40:29,200
particularly

00:40:25,119 --> 00:40:32,560
particularly good in that scenario

00:40:29,200 --> 00:40:35,599
so i hope that answers the question

00:40:32,560 --> 00:40:37,359
properly in terms of

00:40:35,599 --> 00:40:38,880
another question have we experimented

00:40:37,359 --> 00:40:40,720
with homomorphic encryption

00:40:38,880 --> 00:40:42,880
so that was a that's a fantastic

00:40:40,720 --> 00:40:45,520
question um i have

00:40:42,880 --> 00:40:46,319
experimented with homomorphic encryption

00:40:45,520 --> 00:40:49,040
one of the things

00:40:46,319 --> 00:40:50,480
that i'm a little bothered with in terms

00:40:49,040 --> 00:40:53,040
of homomorphic encryption

00:40:50,480 --> 00:40:54,880
is when you start to do things at scale

00:40:53,040 --> 00:40:58,240
that it tends to have

00:40:54,880 --> 00:40:58,560
significant slowdowns uh as far as i

00:40:58,240 --> 00:41:01,440
know

00:40:58,560 --> 00:41:01,920
this is not really a assault problem

00:41:01,440 --> 00:41:03,839
there are

00:41:01,920 --> 00:41:05,359
some excellent use cases for homomorphic

00:41:03,839 --> 00:41:06,480
encryption when you have smaller

00:41:05,359 --> 00:41:09,040
quantities of data

00:41:06,480 --> 00:41:10,000
and uh i would recommend that you make

00:41:09,040 --> 00:41:12,640
use of those

00:41:10,000 --> 00:41:13,920
when when you can if the problem fits

00:41:12,640 --> 00:41:15,119
but when you start training on very

00:41:13,920 --> 00:41:17,839
large quantities of data then

00:41:15,119 --> 00:41:20,160
homomorphic encryption starts to

00:41:17,839 --> 00:41:22,319
starts to have some some problems there

00:41:20,160 --> 00:41:24,880
and so

00:41:22,319 --> 00:41:25,520
my hope is that we in in the future we

00:41:24,880 --> 00:41:28,400
have some

00:41:25,520 --> 00:41:30,400
advances in the industry that helps make

00:41:28,400 --> 00:41:33,920
makes this a more

00:41:30,400 --> 00:41:36,880
a more tractable technology

00:41:33,920 --> 00:41:37,520
that being said there there are

00:41:36,880 --> 00:41:40,480
certainly

00:41:37,520 --> 00:41:41,599
areas where it can where it can work out

00:41:40,480 --> 00:41:44,400
and so

00:41:41,599 --> 00:41:44,960
if if you experiment with it and you see

00:41:44,400 --> 00:41:47,440
that

00:41:44,960 --> 00:41:48,640
that it fits your your problem then by

00:41:47,440 --> 00:41:51,359
all means definitely

00:41:48,640 --> 00:41:51,359
definitely use it

00:41:53,359 --> 00:41:57,280
there's another question about insecure

00:41:55,280 --> 00:41:57,839
multi-party compute why is the function

00:41:57,280 --> 00:42:00,960
f not

00:41:57,839 --> 00:42:02,079
labeled f1 f2 and f3 thank you for for

00:42:00,960 --> 00:42:05,680
asking a question fantastic

00:42:02,079 --> 00:42:08,480
question so what we want is we want

00:42:05,680 --> 00:42:09,359
every fun we want to run the exact same

00:42:08,480 --> 00:42:11,119
function

00:42:09,359 --> 00:42:12,400
across all three data sets so we're not

00:42:11,119 --> 00:42:15,839
deviating the function

00:42:12,400 --> 00:42:16,640
we're deviating the data that is sent to

00:42:15,839 --> 00:42:19,839
the function

00:42:16,640 --> 00:42:21,280
across the three organizations so

00:42:19,839 --> 00:42:23,440
uh there's this actually a really

00:42:21,280 --> 00:42:25,119
important point because it turns out

00:42:23,440 --> 00:42:26,720
that

00:42:25,119 --> 00:42:28,160
you have sensitivity in the data most

00:42:26,720 --> 00:42:30,880
people focus on sensitive

00:42:28,160 --> 00:42:32,400
sensitivity of the data but what if the

00:42:30,880 --> 00:42:35,680
algorithm itself

00:42:32,400 --> 00:42:37,119
is sensitive and can give away

00:42:35,680 --> 00:42:38,000
information about what you're trying to

00:42:37,119 --> 00:42:41,280
do

00:42:38,000 --> 00:42:42,319
then in that scenario a secure

00:42:41,280 --> 00:42:43,920
multi-party compute

00:42:42,319 --> 00:42:45,359
may not be the right choice for you

00:42:43,920 --> 00:42:46,800
because you're effectively giving your

00:42:45,359 --> 00:42:49,280
algorithm to two or three

00:42:46,800 --> 00:42:50,720
other organizations and in that scenario

00:42:49,280 --> 00:42:52,560
you'll probably want to focus on a

00:42:50,720 --> 00:42:53,200
trusted execution environment where you

00:42:52,560 --> 00:42:56,240
can

00:42:53,200 --> 00:42:59,440
where you can send a workload

00:42:56,240 --> 00:43:01,359
to to uh to a secure enclave

00:42:59,440 --> 00:43:02,960
and then you bootstrap it from there

00:43:01,359 --> 00:43:06,160
pull your algorithm using a

00:43:02,960 --> 00:43:07,119
uh using uh your pki or your public key

00:43:06,160 --> 00:43:09,599
infrastructure

00:43:07,119 --> 00:43:10,640
and then run it in in that uh trusted

00:43:09,599 --> 00:43:13,839
environment

00:43:10,640 --> 00:43:15,839
so and and that can that can give you

00:43:13,839 --> 00:43:17,440
that that will allow you to deviate the

00:43:15,839 --> 00:43:20,560
function itself

00:43:17,440 --> 00:43:21,040
thank you for that question uh in terms

00:43:20,560 --> 00:43:24,720
of this

00:43:21,040 --> 00:43:26,640
uh in terms of the slides uh yes we can

00:43:24,720 --> 00:43:27,760
we can post the slides i'll make sure

00:43:26,640 --> 00:43:28,880
the linux foundation

00:43:27,760 --> 00:43:30,240
actually they do have access to the

00:43:28,880 --> 00:43:31,839
slide so we'll make sure they get posted

00:43:30,240 --> 00:43:37,200
out

00:43:31,839 --> 00:43:37,200
um let's see there is a

00:43:37,680 --> 00:43:43,520
there is a question about

00:43:40,800 --> 00:43:43,520
passport

00:43:44,960 --> 00:43:51,200
melissa or marina maybe maybe you want

00:43:47,760 --> 00:43:51,200
to answer this particular one on

00:43:52,839 --> 00:43:58,720
passport

00:43:55,680 --> 00:44:00,160
um basically the question is about

00:43:58,720 --> 00:44:01,200
what would the information the employer

00:44:00,160 --> 00:44:02,960
would be able to gather from the

00:44:01,200 --> 00:44:06,079
employee's responses

00:44:02,960 --> 00:44:09,839
would it be anonymous is it uh uh

00:44:06,079 --> 00:44:09,839
of the house

00:44:19,280 --> 00:44:22,880
what gets sent back my recommendation is

00:44:22,480 --> 00:44:26,000
to

00:44:22,880 --> 00:44:28,079
ask send an email to info docket i

00:44:26,000 --> 00:44:29,839
and get you an accurate response because

00:44:28,079 --> 00:44:31,440
i'm not able to properly answer that

00:44:29,839 --> 00:44:37,839
specific question

00:44:31,440 --> 00:44:37,839
thank you thank you for posting that

00:44:38,160 --> 00:44:41,680
um with that i think that answers all of

00:44:41,040 --> 00:44:43,200
the uh

00:44:41,680 --> 00:44:45,280
the questions other than i don't know

00:44:43,200 --> 00:44:47,359
when the webinar will be will be posted

00:44:45,280 --> 00:44:49,200
i'll work with the linux foundation to

00:44:47,359 --> 00:44:50,960
to get that out and we'll put a message

00:44:49,200 --> 00:44:52,319
on our twitter when it gets posted as

00:44:50,960 --> 00:44:55,440
well

00:44:52,319 --> 00:44:56,319
i can jump in here frederick um yes so

00:44:55,440 --> 00:44:58,400
the slides

00:44:56,319 --> 00:45:00,560
and the presentation will be posted to

00:44:58,400 --> 00:45:01,200
the linux foundation youtube page and

00:45:00,560 --> 00:45:05,839
you can look

00:45:01,200 --> 00:45:05,839
for that in the next week

00:45:09,680 --> 00:45:14,000
okay and i'm actually gonna switch um

00:45:12,000 --> 00:45:14,880
the host over to marina she's gonna

00:45:14,000 --> 00:45:19,200
answer

00:45:14,880 --> 00:45:22,400
on the passport question

00:45:19,200 --> 00:45:24,480
uh oh as i was just saying um that

00:45:22,400 --> 00:45:26,480
question probably would be best answer

00:45:24,480 --> 00:45:27,520
answered by email we can follow up in a

00:45:26,480 --> 00:45:30,560
bit more detail

00:45:27,520 --> 00:45:33,599
on passport specifically so the

00:45:30,560 --> 00:45:36,880
the email to contact us

00:45:33,599 --> 00:45:39,599
at is info doc

00:45:36,880 --> 00:45:39,599
dot ai

00:45:45,119 --> 00:46:01,839
okay great

00:45:49,599 --> 00:46:01,839
is there any other questions

00:46:22,640 --> 00:46:28,640
okay if we have no more questions uh

00:46:25,760 --> 00:46:31,440
we will close out for today last call

00:46:28,640 --> 00:46:31,440
for questions

00:46:36,079 --> 00:46:41,280
okay thanks everybody for joining us and

00:46:39,440 --> 00:46:43,839
we look forward to seeing you next time

00:46:41,280 --> 00:46:43,839

YouTube URL: https://www.youtube.com/watch?v=FAV6Wb7jqYQ


