Title: Tune Your Microservices by Learning from Traces - Zhang Wentao & Yang Yang, IBM
Publication date: 2019-07-10
Playlist: Shanghai '19: KubeCon + CloudNativeCon + Open Source Summit
Description: 
	Tune Your Microservices by Learning from Traces - Zhang Wentao & Yang Yang, IBM 

Tracing plays a more and more important role in the world of microservices, to help with trouble shooting and bottle neck analysis. But within huge amount of traces generated everyday, what can we learn from them, and make full use of these valuable amount of data? In this session, we will discuss how to use Kubeflow to train tracing data generated by Istio, to reveal the patterns you may never discovered by naked eyes, like seasonality performance downgrade, biggest influencer of system failure, correlation between microservices, etc.. It will help with root cause analysis, and eventually tune your microservices with optimized performance.Â   

https://sched.co/Nrne
Captions: 
	00:00:00,030 --> 00:00:06,359
maybe this Sunday she has already been

00:00:02,600 --> 00:00:08,280
appeared for many times for from the

00:00:06,359 --> 00:00:13,799
presentations even by different speakers

00:00:08,280 --> 00:00:14,969
the Cooper flow can help us to making

00:00:13,799 --> 00:00:17,340
deployment of the machine learning

00:00:14,969 --> 00:00:19,560
workflow and kusanagi simple port bow

00:00:17,340 --> 00:00:21,539
and elbow from the name you can tell

00:00:19,560 --> 00:00:25,099
that at the very beginning it will do

00:00:21,539 --> 00:00:28,949
the tensile load and if you already

00:00:25,099 --> 00:00:32,399
attend the previous session of this the

00:00:28,949 --> 00:00:34,770
tank flow and Cooper flow has or it

00:00:32,399 --> 00:00:37,500
means elaborate everything detail

00:00:34,770 --> 00:00:40,739
without fruit flow if we only have the

00:00:37,500 --> 00:00:43,800
sense of flow we'll have the machine

00:00:40,739 --> 00:00:45,390
learning job which is communicated first

00:00:43,800 --> 00:00:48,450
I need to understand that principle

00:00:45,390 --> 00:00:50,039
event 10 machines intend knows I need to

00:00:48,450 --> 00:00:52,289
know their words I need to know their

00:00:50,039 --> 00:00:54,809
resources and when I submit a new

00:00:52,289 --> 00:00:57,809
disability which has the PS no and which

00:00:54,809 --> 00:01:00,059
one is no oneno so for the good flow it

00:00:57,809 --> 00:01:02,550
is like picture on the right hand side

00:01:00,059 --> 00:01:05,159
and it can also help us to show the

00:01:02,550 --> 00:01:07,890
sonicated complexity of the environments

00:01:05,159 --> 00:01:11,790
free summer in a motor survey as well as

00:01:07,890 --> 00:01:14,130
in the monitoring it provided behind the

00:01:11,790 --> 00:01:17,430
parking tools to show this memory

00:01:14,130 --> 00:01:21,259
capacity sold us to help people focus on

00:01:17,430 --> 00:01:21,259
the key machine learning code

00:01:23,290 --> 00:01:29,060
in our midst and today we use that in

00:01:26,540 --> 00:01:32,120
the flow without a gap huge and each

00:01:29,060 --> 00:01:37,580
year we'll collect a lot of traces the

00:01:32,120 --> 00:01:39,350
amount is about 700,000 each day and

00:01:37,580 --> 00:01:42,200
later I would like to share with you

00:01:39,350 --> 00:01:45,440
architecture of our topic on the

00:01:42,200 --> 00:01:51,410
left-hand side on the blue it is a

00:01:45,440 --> 00:01:56,540
kinetic question in first it is the

00:01:51,410 --> 00:01:59,480
space it is nice pace and another once

00:01:56,540 --> 00:02:02,210
it has the appointment of the micro

00:01:59,480 --> 00:02:08,869
surveys in the East Hill so on each of

00:02:02,210 --> 00:02:11,030
all there's we have the steel they also

00:02:08,869 --> 00:02:15,890
have the eager and elastic moving in

00:02:11,030 --> 00:02:20,180
space but we do use the steel people

00:02:15,890 --> 00:02:22,130
eager because it is all in one and it

00:02:20,180 --> 00:02:24,970
doesn't it cannot store a lot of cell

00:02:22,130 --> 00:02:28,250
traces they cannot support a lot of

00:02:24,970 --> 00:02:35,150
paralyzation so that's why does you need

00:02:28,250 --> 00:02:37,940
to introduce a architecture which can

00:02:35,150 --> 00:02:42,980
support a large amount of the foundation

00:02:37,940 --> 00:02:50,530
but that is done we can trace the trace

00:02:42,980 --> 00:02:50,530
both the sanctuary eco-fashion in the we

00:02:53,410 --> 00:02:58,570
Concentra a lot research and finally we

00:02:56,330 --> 00:02:58,570
chose

00:02:58,989 --> 00:03:09,319
in that last exert it will be stored in

00:03:03,800 --> 00:03:11,000
the cement part would be the right-hand

00:03:09,319 --> 00:03:14,030
side which is for the machine learning

00:03:11,000 --> 00:03:16,250
we have the data preparation and during

00:03:14,030 --> 00:03:19,819
this tab the data will be pulled from

00:03:16,250 --> 00:03:22,910
the es and then we'll use the data for

00:03:19,819 --> 00:03:25,190
planning because when we class these

00:03:22,910 --> 00:03:27,290
chemical traces they can be buried in

00:03:25,190 --> 00:03:29,420
different layers so that's why we

00:03:27,290 --> 00:03:32,180
prepare some data is here and we only

00:03:29,420 --> 00:03:35,239
slash the build that we pay attention to

00:03:32,180 --> 00:03:37,489
and then generate a document and put it

00:03:35,239 --> 00:03:39,650
into the service and all this kind of

00:03:37,489 --> 00:03:42,080
the file will be consumed by the follow

00:03:39,650 --> 00:03:45,500
and train via a motive after iterations

00:03:42,080 --> 00:03:55,340
the model will be stored in the object

00:03:45,500 --> 00:03:59,450
storage by the Koopa flow run on the

00:03:55,340 --> 00:04:01,340
banana cluster this is the overview of

00:03:59,450 --> 00:04:03,380
the architecture and now I'd like to

00:04:01,340 --> 00:04:05,950
give the floor to my coworker mr.

00:04:03,380 --> 00:04:05,950
junkman pal

00:04:11,330 --> 00:04:18,680
and thank you and later I would like to

00:04:15,020 --> 00:04:24,860
share with you the machine learning in

00:04:18,680 --> 00:04:26,960
our case and just now I just introduced

00:04:24,860 --> 00:04:32,320
that in the trays there are a lot of

00:04:26,960 --> 00:04:32,320
information among them there are some

00:04:32,870 --> 00:04:38,240
[Music]

00:04:34,210 --> 00:04:41,060
others like that in each phrase I know

00:04:38,240 --> 00:04:46,280
that which service name it is from and

00:04:41,060 --> 00:05:05,840
where it goes to the source the origin

00:04:46,280 --> 00:05:29,210
and the address and in the service how

00:05:05,840 --> 00:05:33,740
can we use these days and today as the

00:05:29,210 --> 00:05:38,570
target of the machine learning the first

00:05:33,740 --> 00:05:41,090
stop is ETA in PDA it is a concept on

00:05:38,570 --> 00:05:43,130
the statistic oh that I dedicate which

00:05:41,090 --> 00:05:46,900
means that in order to process the data

00:05:43,130 --> 00:05:46,900
you need to perceive the seder

00:05:50,700 --> 00:05:57,120
the futures of the data in different

00:05:52,550 --> 00:06:00,300
degrees and different I mentioned after

00:05:57,120 --> 00:06:03,980
we have a perception of the data we can

00:06:00,300 --> 00:06:03,980
decide what kind of the model which

00:06:04,760 --> 00:06:13,830
example we use the service duration as

00:06:09,330 --> 00:06:16,500
the object of the data process and we

00:06:13,830 --> 00:06:19,110
can observe it from different time range

00:06:16,500 --> 00:06:22,950
in time break because in different time

00:06:19,110 --> 00:06:26,610
frame we can see that the features the

00:06:22,950 --> 00:06:32,940
data show our friends so let's have a

00:06:26,610 --> 00:06:36,450
look at the picture he's not a diagram

00:06:32,940 --> 00:06:38,700
here so each frame lasts for about 30

00:06:36,450 --> 00:06:41,970
minutes and we can see that within the

00:06:38,700 --> 00:06:46,370
lifecycle of the 30 minutes the duration

00:06:41,970 --> 00:06:51,360
watch wait back and forth so the

00:06:46,370 --> 00:06:54,960
requesting time is much waiting and in

00:06:51,360 --> 00:06:57,840
this way we can know that it is related

00:06:54,960 --> 00:07:00,000
to the total of the requests people we

00:06:57,840 --> 00:07:03,060
don't need to analyse that what are the

00:07:00,000 --> 00:07:12,270
most of the fluctuation and let's have

00:07:03,060 --> 00:07:16,620
another dimension change the future has

00:07:12,270 --> 00:07:19,920
already been which means that within the

00:07:16,620 --> 00:07:23,460
range of the 30 minutes the fluctuation

00:07:19,920 --> 00:07:25,530
of the duration is really violence but

00:07:23,460 --> 00:07:29,760
when the expanded range

00:07:25,530 --> 00:07:34,640
12 hours is still 40 and also show an

00:07:29,760 --> 00:07:34,640
features just like the EDR

00:07:41,270 --> 00:07:44,350
[Music]

00:08:03,700 --> 00:08:06,769
[Music]

00:08:24,689 --> 00:08:37,229
we can see that there is because

00:08:40,589 --> 00:08:48,190
differently right and I like this mo

00:08:44,050 --> 00:08:58,810
doing a D time welcome is south

00:08:48,190 --> 00:09:10,480
more requests any show perception data

00:08:58,810 --> 00:09:15,389
for machining the duration is a time

00:09:10,480 --> 00:09:15,389
serial data so we're going to pick

00:09:16,439 --> 00:09:37,569
treatment so here we use ohdf because i

00:09:23,319 --> 00:09:41,220
staff its traditional art in Cameron

00:09:37,569 --> 00:09:41,220
arias takes time Weiss

00:09:42,670 --> 00:09:47,850
example there is periodic graduation

00:09:49,320 --> 00:10:06,220
transmitted then the network can learn

00:09:52,300 --> 00:10:10,420
this character is a structure maybe the

00:10:06,220 --> 00:10:15,580
layers are may disappear then is DM can

00:10:10,420 --> 00:10:17,710
come to play because units for control

00:10:15,580 --> 00:10:20,310
it will have us to decide whether these

00:10:17,710 --> 00:10:33,340
features should be carried forward or

00:10:20,310 --> 00:10:38,230
neglected we use process language crispy

00:10:33,340 --> 00:10:42,190
we will use natto to generate Nero

00:10:38,230 --> 00:10:52,450
sequence based on existing sample we do

00:10:42,190 --> 00:10:55,650
with language maybe to speak for us in

00:10:52,450 --> 00:11:00,040
our case based on the previous example

00:10:55,650 --> 00:11:02,760
then we will predict the upcoming

00:11:00,040 --> 00:11:02,760
generation

00:11:38,380 --> 00:11:46,690
in terms of tracing the machining let me

00:11:41,390 --> 00:11:46,690
use Tracy before of nominee detection

00:11:47,500 --> 00:11:53,300
time sequence prediction based on the

00:11:51,530 --> 00:11:57,500
previous time sequence I can generate

00:11:53,300 --> 00:12:00,890
for future time sequence and I will use

00:11:57,500 --> 00:12:03,710
this estimate days I will compare these

00:12:00,890 --> 00:12:07,220
estimated sequence with the previous one

00:12:03,710 --> 00:12:19,720
if there is a tolerance an aviation and

00:12:07,220 --> 00:12:24,640
I can tell whether this is in we have

00:12:19,720 --> 00:12:24,640
1990 data points in the test dataset

00:12:30,250 --> 00:12:39,400
1996 dealer morning

00:12:32,260 --> 00:12:40,990
which I ain't no money in which is

00:12:39,400 --> 00:12:44,530
indicated in the report

00:12:40,990 --> 00:12:48,730
so how can we tell whether it is anomaly

00:12:44,530 --> 00:12:50,740
or not so we have used some specific

00:12:48,730 --> 00:13:09,820
algorithm and also based on our

00:12:50,740 --> 00:13:16,210
experience if we use different time

00:13:09,820 --> 00:13:19,170
frames characteristics are different the

00:13:16,210 --> 00:13:22,290
value is the same the number is the same

00:13:19,170 --> 00:13:27,700
every States displayed are different

00:13:22,290 --> 00:13:32,050
it's like a no story in China blind for

00:13:27,700 --> 00:13:34,300
blind people touch T touched anything it

00:13:32,050 --> 00:13:37,870
when they reach to reach to laugh

00:13:34,300 --> 00:13:41,140
elephants at lag they say it's a and

00:13:37,870 --> 00:13:43,540
when they touch anybody

00:13:41,140 --> 00:13:45,760
it says it's our own so what is the

00:13:43,540 --> 00:13:48,990
animal actually add the elements

00:13:45,760 --> 00:13:48,990
elephant that has the

00:13:52,779 --> 00:14:02,480
so we're trying to get these ideas in

00:13:58,129 --> 00:14:13,040
order to do so when you picture in a

00:14:02,480 --> 00:14:18,170
bigger picture this is if we view the

00:14:13,040 --> 00:14:22,850
data in short time frame you see huge

00:14:18,170 --> 00:14:26,600
penetration in duration unacceptable

00:14:22,850 --> 00:14:30,110
which will be defined as anomaly but if

00:14:26,600 --> 00:14:35,779
we extend the time frame the fluctuation

00:14:30,110 --> 00:14:38,689
is still there however less abrupt then

00:14:35,779 --> 00:14:46,689
the motor will define it as a normal

00:14:38,689 --> 00:14:46,689
phenomena it has trained for a while and

00:14:48,819 --> 00:14:56,569
so for us we want the model to capture

00:14:53,240 --> 00:15:03,079
to capture these a nominal anomaly in

00:14:56,569 --> 00:15:07,579
the short duration we also hope its

00:15:03,079 --> 00:15:10,540
mortal won't mistreat a nominal anomaly

00:15:07,579 --> 00:15:10,540
as a

00:15:21,330 --> 00:15:35,350
we train the model we can't just put it

00:15:25,390 --> 00:15:53,620
aside bro the purpose is an API then the

00:15:35,350 --> 00:15:55,840
application example is this time

00:15:53,620 --> 00:15:59,050
reference we can use this this 10 points

00:15:55,840 --> 00:16:03,240
to estimate future time sequence our

00:15:59,050 --> 00:16:16,960
time window we can estimate is to

00:16:03,240 --> 00:16:22,440
duration prediction example I use the

00:16:16,960 --> 00:16:22,440
real time to read to do the institutions

00:16:22,590 --> 00:16:27,680
relies on completed sequence example

00:16:28,250 --> 00:16:36,420
future time sequence these are the

00:16:33,210 --> 00:16:51,270
previously so the first approach is more

00:16:36,420 --> 00:16:54,990
accurate we need we need real time or

00:16:51,270 --> 00:16:58,380
accuracy then or estimation true if you

00:16:54,990 --> 00:17:01,260
just want to know the answer then the

00:16:58,380 --> 00:17:03,500
time sequence based approach would be

00:17:01,260 --> 00:17:03,500
better

00:17:20,030 --> 00:17:23,990
three minutes or one hour

00:17:29,669 --> 00:17:37,090
you go if I use this as the input or

00:17:34,539 --> 00:17:43,019
kaboom but then I will get a small

00:17:37,090 --> 00:17:46,590
timeframe which we call it 401

00:17:43,019 --> 00:17:51,840
okay with this morning I can estimate

00:17:46,590 --> 00:17:55,299
what happens in the last 30 minutes is

00:17:51,840 --> 00:17:58,330
normal for the last 30 minutes but if we

00:17:55,299 --> 00:18:04,799
can also extend the timeframe then we'll

00:17:58,330 --> 00:18:29,470
get a break their motto identify

00:18:04,799 --> 00:18:36,970
characteristics a refuge over the last 7

00:18:29,470 --> 00:18:43,409
days that would indicate that it's a

00:18:36,970 --> 00:18:43,409
result the duration frequent

00:18:48,960 --> 00:18:53,669
predict that over the long term

00:18:58,750 --> 00:20:10,390
we can increase down what our training

00:20:07,910 --> 00:20:10,390
and deployment

00:20:12,009 --> 00:20:23,440
he is the con job we need bigger

00:20:20,769 --> 00:20:26,889
timeframe we need more your data set

00:20:23,440 --> 00:20:29,409
that was a longer training but or it's

00:20:26,889 --> 00:20:33,029
more training are more like 30 minute

00:20:29,409 --> 00:20:37,360
model don't be smart

00:20:33,029 --> 00:20:45,070
the training very short time that means

00:20:37,360 --> 00:20:51,730
we get iterates the model we use the is

00:20:45,070 --> 00:21:05,769
do it's to help us to do publishing in

00:20:51,730 --> 00:21:11,259
different version Tracy Tracy is younger

00:21:05,769 --> 00:21:15,940
and do the kill flow model and to

00:21:11,259 --> 00:21:18,100
identify the anomaly services the

00:21:15,940 --> 00:21:24,059
anomaly is not a girl they can notify

00:21:18,100 --> 00:21:24,059
the operation team for information

00:21:27,470 --> 00:21:36,870
do some skating micro-services can

00:21:33,710 --> 00:21:39,060
provide one service so this is what we

00:21:36,870 --> 00:21:42,390
want to share it if you have any

00:21:39,060 --> 00:21:44,960
questions there is your hand please use

00:21:42,390 --> 00:21:44,960
the microphone

00:21:54,990 --> 00:22:05,490
so when you do when you do the anomaly

00:21:58,530 --> 00:22:14,520
detection are you mentioned upon the

00:22:05,490 --> 00:22:21,510
classification reoccurrence so here in

00:22:14,520 --> 00:22:24,510
this time for any a fluctuating if I

00:22:21,510 --> 00:22:27,720
just use the long term tomorrow it will

00:22:24,510 --> 00:22:31,530
treat these value as normal because it

00:22:27,720 --> 00:22:35,190
predicts characteristics will happen

00:22:31,530 --> 00:22:37,950
here after learning it will treat it as

00:22:35,190 --> 00:22:39,830
a normal phenomenon in this case I will

00:22:37,950 --> 00:22:46,980
use the cluster every certain to

00:22:39,830 --> 00:22:52,080
identify the points for there was a

00:22:46,980 --> 00:23:01,590
normal point before it why don't you use

00:22:52,080 --> 00:23:04,380
some Engineer use some traditional

00:23:01,590 --> 00:23:06,750
machine learning like characteristic

00:23:04,380 --> 00:23:10,440
engineering to identify and

00:23:06,750 --> 00:23:12,870
characteristics first wouldn't have be

00:23:10,440 --> 00:23:15,720
better maybe here we will think about

00:23:12,870 --> 00:23:17,900
out we will give it a try first question

00:23:15,720 --> 00:23:17,900
is that

00:23:19,330 --> 00:23:27,370
well you try to use this in truth

00:23:22,480 --> 00:23:30,640
together with the scheduler yes because

00:23:27,370 --> 00:23:41,230
this will involve the distributed motor

00:23:30,640 --> 00:23:42,150
training a virtual dimension that's a

00:23:41,230 --> 00:23:45,940
good job

00:23:42,150 --> 00:23:50,190
to train the data afterwards this can be

00:23:45,940 --> 00:23:55,840
traumatic therefore we have a lot of job

00:23:50,190 --> 00:24:00,130
submitted was one to use that you say

00:23:55,840 --> 00:24:07,450
it's distributed approach traditionally

00:24:00,130 --> 00:24:10,510
scheduler has faced some challenges when

00:24:07,450 --> 00:24:12,460
it comes to a paralyzing but later we'll

00:24:10,510 --> 00:24:16,419
think about use a cube edge as a

00:24:12,460 --> 00:24:19,300
scheduler my proposal asking this

00:24:16,419 --> 00:24:26,640
question class if you try

00:24:19,300 --> 00:24:29,800
I would like to know that girdle and the

00:24:26,640 --> 00:24:35,860
others which one who are fast the

00:24:29,800 --> 00:24:38,080
usability so we deploy it needs time at

00:24:35,860 --> 00:24:40,480
the time cannot be pasted it depends on

00:24:38,080 --> 00:24:42,490
the time and a network for test and why

00:24:40,480 --> 00:24:46,480
I hope that I can use that as soon as

00:24:42,490 --> 00:24:48,880
possible right so it requires the the

00:24:46,480 --> 00:24:50,920
good performance so I would like to know

00:24:48,880 --> 00:24:55,500
that is there an imbalance between these

00:24:50,920 --> 00:24:55,500
two episode as it can be I can be used

00:24:56,010 --> 00:25:03,520
so when you before the model can you

00:25:00,010 --> 00:25:06,310
still use the theory and another kind of

00:25:03,520 --> 00:25:09,220
the model of the optimization method

00:25:06,310 --> 00:25:13,690
well so far we have encountered this

00:25:09,220 --> 00:25:15,750
kind of problems so far all right thank

00:25:13,690 --> 00:25:15,750
you

00:25:21,650 --> 00:25:35,180
I have a question and how can I ensure

00:25:29,450 --> 00:25:37,970
that what I train is the one I will re

00:25:35,180 --> 00:25:39,800
use in practice so in other words do you

00:25:37,970 --> 00:25:43,730
think that the training is only

00:25:39,800 --> 00:25:45,170
available in a campus in one areas or it

00:25:43,730 --> 00:25:47,180
is incomparable

00:25:45,170 --> 00:25:48,620
well actually what we train it is the

00:25:47,180 --> 00:25:52,490
best service you can understand that

00:25:48,620 --> 00:25:54,830
it's a related note ok so after I train

00:25:52,490 --> 00:25:57,380
it I can only use it in one service

00:25:54,830 --> 00:26:01,520
right here this right is not a common

00:25:57,380 --> 00:26:04,490
model and in the final it will have the

00:26:01,520 --> 00:26:09,320
autos going right yes so I would like to

00:26:04,490 --> 00:26:12,080
know the auto Scully and I'd like to

00:26:09,320 --> 00:26:14,810
know that when it is decided to scale um

00:26:12,080 --> 00:26:21,440
and what if will decide to scale down

00:26:14,810 --> 00:26:33,320
and what are the criteria but I would

00:26:21,440 --> 00:26:36,890
like to for example and actually I can I

00:26:33,320 --> 00:26:40,190
need a tea requires Menagerie I can only

00:26:36,890 --> 00:26:42,410
small it's 50 requests but if it is go

00:26:40,190 --> 00:26:44,480
up from them teach 80 and it will fill

00:26:42,410 --> 00:26:47,990
in a 52 and what would happen and we'll

00:26:44,480 --> 00:26:50,480
try to do well Ashley in our case we

00:26:47,990 --> 00:26:52,730
don't have such a large amount of

00:26:50,480 --> 00:26:57,230
requests yes this part of the problems

00:26:52,730 --> 00:27:00,410
but may happen but we won't go from the

00:26:57,230 --> 00:27:04,670
extreme like your own as you described

00:27:00,410 --> 00:27:08,290
well Ashley is there and possibly

00:27:04,670 --> 00:27:08,290
doesn't when you dude

00:27:10,980 --> 00:27:16,919
yes the auscultation can be happen so

00:27:15,150 --> 00:27:18,960
how can you ensure that this kind of

00:27:16,919 --> 00:27:21,570
information can be avoided

00:27:18,960 --> 00:27:24,480
well actually so these kind of the

00:27:21,570 --> 00:27:27,150
auscultation with a scale up and the

00:27:24,480 --> 00:27:29,460
number will be increased so the process

00:27:27,150 --> 00:27:31,620
ability ability increase in this way the

00:27:29,460 --> 00:27:33,179
duration will be reduced right yes

00:27:31,620 --> 00:27:39,720
that's right so that's why that's if we

00:27:33,179 --> 00:27:42,270
have to use at least two models for the

00:27:39,720 --> 00:27:45,380
or discovery I use it for the long term

00:27:42,270 --> 00:27:52,160
model so in this way I can avoid that

00:27:45,380 --> 00:27:52,160
and will notice the violent graduation

00:27:52,880 --> 00:28:01,830
and that would help

00:27:54,960 --> 00:28:04,590
what does that mean I don't know another

00:28:01,830 --> 00:28:06,840
model is responsible for judging not the

00:28:04,590 --> 00:28:09,179
same service right now so this one is

00:28:06,840 --> 00:28:12,080
for compensation right yes then this one

00:28:09,179 --> 00:28:12,080
is for compensation

00:28:12,650 --> 00:28:18,000
all right down to the notation thank you

00:28:16,320 --> 00:28:19,740
very much for your attention

00:28:18,000 --> 00:28:24,860
and if you still have any questions

00:28:19,740 --> 00:28:24,860

YouTube URL: https://www.youtube.com/watch?v=-8cKz8mPr1c


