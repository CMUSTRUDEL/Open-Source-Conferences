Title: Simulating Our Apache Mesos Framework for Fun and Profit and...
Publication date: 2017-09-18
Playlist: MesosCon North America 2017
Description: 
	Simulating Our Apache Mesos Framework for Fun and Profit and... - Wil Yegelwel, TwoSigma

At Two Sigma, we use Cook, our open source batch scheduling mesos framework, to run millions of compute-hours of work for hundreds of users every day. This year, we are working on changing the scheduler optimization algorithm, but we want some confidence that it will actually improve utilization and the user experience (latency). Therefore, we built a mesos simulator which lets us test algorithm changes, without running the whole distributed system, and in doing so, found some subtle bugs and performance bottlenecks, and highlighted areas needing better test coverage.

In this talk, Wil will describe how we built the simulator for cook, some of the challenges in building it, and share the insights we learned by running our historical job traces through it. We will highlight the value and practicality of simulation testing for real, production systems.

Wil Yegelwel
Software Developer, TwoSigma
I'm a developer at Two Sigma Investments working on Distributed System and Analysis tools. Previously, I was a student at Brown University studying Computer Science and Applied Math.
Captions: 
	00:00:00,000 --> 00:00:03,570
hi everyone my name is will and today I

00:00:02,190 --> 00:00:06,540
want to talk to you about simulating our

00:00:03,570 --> 00:00:08,309
mesos framework cook my plan for this

00:00:06,540 --> 00:00:11,130
talks first tell you what simulation

00:00:08,309 --> 00:00:13,290
testing is in general and give you a

00:00:11,130 --> 00:00:15,960
sense of why you might want to do it and

00:00:13,290 --> 00:00:17,880
then tell you a bit about cook our open

00:00:15,960 --> 00:00:19,050
source batch scheduler that's really

00:00:17,880 --> 00:00:20,789
designed for the case when you have a

00:00:19,050 --> 00:00:23,670
lot more resource requests and you have

00:00:20,789 --> 00:00:25,740
capacity to fulfill it tell you why we

00:00:23,670 --> 00:00:26,580
built cook in the first place and then

00:00:25,740 --> 00:00:28,769
tell you some of the more recent

00:00:26,580 --> 00:00:33,090
challenges that cause us to consider

00:00:28,769 --> 00:00:34,170
building a simulator and then tell you a

00:00:33,090 --> 00:00:35,790
little bit about how we built the

00:00:34,170 --> 00:00:38,070
simulator and the trade-offs we made and

00:00:35,790 --> 00:00:41,760
go over one of the cases in which we use

00:00:38,070 --> 00:00:44,010
a simulator to improve the system and so

00:00:41,760 --> 00:00:45,570
to start it helps to have kind of an

00:00:44,010 --> 00:00:48,989
example system in mind when thinking

00:00:45,570 --> 00:00:52,079
about simulating a system and this is

00:00:48,989 --> 00:00:54,000
kind of a generic like generic system

00:00:52,079 --> 00:00:55,199
that you might have your own company it

00:00:54,000 --> 00:00:56,460
doesn't actually matter what it's really

00:00:55,199 --> 00:00:58,500
doing you know we have some clients

00:00:56,460 --> 00:01:00,539
sending to a service service put some

00:00:58,500 --> 00:01:02,250
data on a queue workers pull off the

00:01:00,539 --> 00:01:04,650
queue do some processing put it back on

00:01:02,250 --> 00:01:06,510
the queue the service either writes to a

00:01:04,650 --> 00:01:08,010
database sends it back to the clients

00:01:06,510 --> 00:01:14,040
maybe puts it back on the queue I mean

00:01:08,010 --> 00:01:18,630
you know a generic service and the point

00:01:14,040 --> 00:01:20,610
here is that it's even even this is

00:01:18,630 --> 00:01:21,450
pretty complex like there's no way that

00:01:20,610 --> 00:01:23,430
we're going to be able to just

00:01:21,450 --> 00:01:26,960
understand by looking at this or even by

00:01:23,430 --> 00:01:29,790
inspecting some metrics what it's doing

00:01:26,960 --> 00:01:31,860
holistically and if we make any changes

00:01:29,790 --> 00:01:32,909
what those changes are going to do we

00:01:31,860 --> 00:01:35,189
might have a sense of you know we'll

00:01:32,909 --> 00:01:36,450
have mental models for the system we

00:01:35,189 --> 00:01:38,009
kind of have a sense that like if we add

00:01:36,450 --> 00:01:43,530
more workers they'll probably scale out

00:01:38,009 --> 00:01:47,009
linearly hopefully but we don't really

00:01:43,530 --> 00:01:51,119
know and so if we wanted to start

00:01:47,009 --> 00:01:53,880
answering these questions one way we

00:01:51,119 --> 00:01:55,560
could do it would be to just make the

00:01:53,880 --> 00:01:59,939
change in production and you know just

00:01:55,560 --> 00:02:01,979
see what happens but that's probably you

00:01:59,939 --> 00:02:03,840
know that might be fine but oftentimes

00:02:01,979 --> 00:02:06,329
it's not really what you want to do you

00:02:03,840 --> 00:02:08,459
can't even ask you can't even really ask

00:02:06,329 --> 00:02:09,479
the opposite question which is what

00:02:08,459 --> 00:02:10,649
would have happened if I didn't make

00:02:09,479 --> 00:02:13,110
this change you can't ask the

00:02:10,649 --> 00:02:15,420
counterfactual and so

00:02:13,110 --> 00:02:17,610
you know we have this case where we want

00:02:15,420 --> 00:02:18,960
we want to test a hypothesis that's

00:02:17,610 --> 00:02:23,190
really what these questions boil down to

00:02:18,960 --> 00:02:25,200
is you know if I add more workers my

00:02:23,190 --> 00:02:28,350
hypothesis is that I know I'll be able

00:02:25,200 --> 00:02:30,360
to scale out linearly but we don't have

00:02:28,350 --> 00:02:32,100
a way to experiment with our system you

00:02:30,360 --> 00:02:34,110
know we can put it in production but our

00:02:32,100 --> 00:02:36,260
a production system isn't really a

00:02:34,110 --> 00:02:39,480
controlled environment so what I mean by

00:02:36,260 --> 00:02:42,390
experiment is a scientific process to

00:02:39,480 --> 00:02:44,459
test a hypothesis and so you know we can

00:02:42,390 --> 00:02:46,050
have a hypothesis and we could test it

00:02:44,459 --> 00:02:48,870
in production but it's not really

00:02:46,050 --> 00:02:51,810
scientific you know there are lots of

00:02:48,870 --> 00:02:53,910
things changing besides whatever change

00:02:51,810 --> 00:02:56,070
we made to test our hypothesis the

00:02:53,910 --> 00:02:58,709
workloads are going to change as we run

00:02:56,070 --> 00:03:00,360
our experiment we might have an

00:02:58,709 --> 00:03:02,310
automated process or somebody that's

00:03:00,360 --> 00:03:04,230
logging into those servers and like

00:03:02,310 --> 00:03:05,760
updating things and then what if that

00:03:04,230 --> 00:03:07,860
process fails or that person goes to

00:03:05,760 --> 00:03:12,180
lunch and now like your systems in this

00:03:07,860 --> 00:03:13,230
weird half state and you know this is

00:03:12,180 --> 00:03:15,270
not this is not the controlled

00:03:13,230 --> 00:03:17,720
environment you want to run you want to

00:03:15,270 --> 00:03:19,980
be running experiments and if we were a

00:03:17,720 --> 00:03:22,410
physical scientist looking at a physical

00:03:19,980 --> 00:03:25,070
system like that would definitely get

00:03:22,410 --> 00:03:28,950
thrown out in an academic review process

00:03:25,070 --> 00:03:30,750
so you know can we get closer can we get

00:03:28,950 --> 00:03:33,120
closer to running real experiments in a

00:03:30,750 --> 00:03:35,040
scientific manner and so this really

00:03:33,120 --> 00:03:37,560
boils down to can we control the

00:03:35,040 --> 00:03:40,290
environment of art that our system runs

00:03:37,560 --> 00:03:42,000
in and well half of the answer to that

00:03:40,290 --> 00:03:43,860
is well yeah I mean we could just stand

00:03:42,000 --> 00:03:47,340
up another copy of our production system

00:03:43,860 --> 00:03:48,360
and just don't tell anybody about it if

00:03:47,340 --> 00:03:50,700
no one's touching it

00:03:48,360 --> 00:03:51,930
then it's pretty much controlled you

00:03:50,700 --> 00:03:53,700
know nothing's really happening that

00:03:51,930 --> 00:03:57,540
doesn't happen from just the system's

00:03:53,700 --> 00:03:59,790
own processes but this isn't a really

00:03:57,540 --> 00:04:02,220
interesting system there's nothing

00:03:59,790 --> 00:04:04,260
happening but if we just send a

00:04:02,220 --> 00:04:06,660
production traffic we're back to what we

00:04:04,260 --> 00:04:09,000
had in production right we've now lost

00:04:06,660 --> 00:04:09,840
any control we had so what we can do is

00:04:09,000 --> 00:04:12,090
we can stand up

00:04:09,840 --> 00:04:15,090
synthetic clients and now now we control

00:04:12,090 --> 00:04:16,590
the entire the entire environment and

00:04:15,090 --> 00:04:20,280
what this means now is we can change any

00:04:16,590 --> 00:04:22,860
one piece and run a real experiment now

00:04:20,280 --> 00:04:24,120
I should say that this isn't this still

00:04:22,860 --> 00:04:25,530
isn't fully controlled right like

00:04:24,120 --> 00:04:26,699
servers can still fail they could still

00:04:25,530 --> 00:04:28,530
be networked partition

00:04:26,699 --> 00:04:32,130
but it's way better than what we have in

00:04:28,530 --> 00:04:35,250
production and so you know let's say we

00:04:32,130 --> 00:04:36,419
change this this this lead service you

00:04:35,250 --> 00:04:39,240
know we can start looking at what

00:04:36,419 --> 00:04:40,919
happens when we upgrade our service you

00:04:39,240 --> 00:04:44,310
know hypotheses like does it remain

00:04:40,919 --> 00:04:47,610
correct or what if we changed our

00:04:44,310 --> 00:04:49,440
workload what if we what if we get twice

00:04:47,610 --> 00:04:50,970
as many requests as we normally do or we

00:04:49,440 --> 00:04:54,060
switch from a read workload to a write

00:04:50,970 --> 00:04:56,610
workload or you know what if something

00:04:54,060 --> 00:04:58,020
fails you know now we could start to ask

00:04:56,610 --> 00:05:01,889
these questions and run these

00:04:58,020 --> 00:05:05,490
experiments and really do this in a

00:05:01,889 --> 00:05:07,440
scientific manner and so this is kind of

00:05:05,490 --> 00:05:10,259
the heart of simulation of simulating a

00:05:07,440 --> 00:05:13,110
system is putting yourself putting your

00:05:10,259 --> 00:05:15,690
system into a place where it's a fully

00:05:13,110 --> 00:05:19,849
controlled and this gives you a way to

00:05:15,690 --> 00:05:22,410
principally experiment on your system

00:05:19,849 --> 00:05:25,380
this is probably a good time to point

00:05:22,410 --> 00:05:27,479
out that when you do this your

00:05:25,380 --> 00:05:29,340
experiments might not always match what

00:05:27,479 --> 00:05:31,590
happens in production so you might run

00:05:29,340 --> 00:05:34,830
your simulation get some great results

00:05:31,590 --> 00:05:36,419
that say you know if if you scale out

00:05:34,830 --> 00:05:37,680
workers it scales out linearly and

00:05:36,419 --> 00:05:39,360
you're like really happy and you do it

00:05:37,680 --> 00:05:43,169
in production and it doesn't scale

00:05:39,360 --> 00:05:47,190
linearly and this is because no matter

00:05:43,169 --> 00:05:50,190
how close you get to a clean environment

00:05:47,190 --> 00:05:52,940
that that's controlled but still like

00:05:50,190 --> 00:05:55,889
production it will never be production

00:05:52,940 --> 00:05:57,690
but I think that's still okay you know

00:05:55,889 --> 00:06:03,900
even if a model is not perfect it can

00:05:57,690 --> 00:06:05,639
still be extremely useful and so we can

00:06:03,900 --> 00:06:07,289
now start looking at this our controlled

00:06:05,639 --> 00:06:09,240
environment our simulation where we have

00:06:07,289 --> 00:06:10,590
our system and we have these requests

00:06:09,240 --> 00:06:13,349
and we start having them flow through

00:06:10,590 --> 00:06:16,710
and then we change something and this is

00:06:13,349 --> 00:06:17,970
our way of experimenting but you know so

00:06:16,710 --> 00:06:20,580
far we've talked about our system as

00:06:17,970 --> 00:06:21,930
just a copy of production but you

00:06:20,580 --> 00:06:24,090
actually have choice here and it's

00:06:21,930 --> 00:06:27,960
really on a spectrum from high fidelity

00:06:24,090 --> 00:06:30,690
and high cost to low fidelity but also

00:06:27,960 --> 00:06:32,130
lower cost and so the high fidelity side

00:06:30,690 --> 00:06:34,110
is you just take a copy of a production

00:06:32,130 --> 00:06:35,520
system you know the results you're going

00:06:34,110 --> 00:06:36,930
to get from these experiments should

00:06:35,520 --> 00:06:38,760
match well to what happens in production

00:06:36,930 --> 00:06:39,350
because well I mean you're looking at

00:06:38,760 --> 00:06:41,990
effective

00:06:39,350 --> 00:06:44,660
your production system but this is gonna

00:06:41,990 --> 00:06:46,760
be expensive both in terms of dollars

00:06:44,660 --> 00:06:48,140
but also in terms of time so the dollar

00:06:46,760 --> 00:06:50,960
side probably makes sense right

00:06:48,140 --> 00:06:54,980
you need boxes to run your entire system

00:06:50,960 --> 00:06:56,240
a second time and you need you know

00:06:54,980 --> 00:06:57,980
these fake clients and if you have a

00:06:56,240 --> 00:07:01,370
very large system that's taking tons of

00:06:57,980 --> 00:07:04,210
requests you're going to need a lot of

00:07:01,370 --> 00:07:06,350
boxes to be able to simulate this I

00:07:04,210 --> 00:07:08,510
think the time part is a little more

00:07:06,350 --> 00:07:10,250
subtle though since you're doing actual

00:07:08,510 --> 00:07:13,370
Network requests actual disk writes

00:07:10,250 --> 00:07:14,750
actual database reads you can only run

00:07:13,370 --> 00:07:17,090
this real time so if you want to

00:07:14,750 --> 00:07:18,890
simulate over seven days of data it's

00:07:17,090 --> 00:07:21,140
going to take seven days to run your

00:07:18,890 --> 00:07:25,940
experiment and this means you either

00:07:21,140 --> 00:07:27,380
have to run very few experiments or you

00:07:25,940 --> 00:07:29,060
have to run very short experiments and

00:07:27,380 --> 00:07:30,740
both aren't great I mean on the one hand

00:07:29,060 --> 00:07:33,290
you don't get to get that many results

00:07:30,740 --> 00:07:34,820
on the other your results have to have

00:07:33,290 --> 00:07:38,240
this additional caveat that you know

00:07:34,820 --> 00:07:39,800
here these results but they only they

00:07:38,240 --> 00:07:41,390
only account for 30 minutes of data

00:07:39,800 --> 00:07:43,760
let's say and so they might not

00:07:41,390 --> 00:07:46,940
generalize to a longer running in

00:07:43,760 --> 00:07:50,450
production on the other side of the

00:07:46,940 --> 00:07:52,190
spectrum is building a model of your

00:07:50,450 --> 00:07:54,530
system either a mathematical model or

00:07:52,190 --> 00:07:56,270
you can you know write some code that

00:07:54,530 --> 00:07:58,220
approximates how your system works and

00:07:56,270 --> 00:08:00,110
this can be much cheaper you can often

00:07:58,220 --> 00:08:03,080
run in a single box on a single process

00:08:00,110 --> 00:08:06,260
and you can often run it way faster than

00:08:03,080 --> 00:08:10,970
your production system you know in this

00:08:06,260 --> 00:08:13,070
case you know you're not making any any

00:08:10,970 --> 00:08:15,200
network requests any disk writes no

00:08:13,070 --> 00:08:17,480
database reads I mean that this you can

00:08:15,200 --> 00:08:19,400
run way faster and so you can run either

00:08:17,480 --> 00:08:23,000
much more experiments or much longer

00:08:19,400 --> 00:08:24,410
experiments and so in that regard you

00:08:23,000 --> 00:08:27,800
know you could feel more confident about

00:08:24,410 --> 00:08:29,510
your results the problem is that you

00:08:27,800 --> 00:08:32,510
know you're now taking approximations of

00:08:29,510 --> 00:08:34,430
your system and so you might miss entire

00:08:32,510 --> 00:08:36,620
classes of behavior of your of your

00:08:34,430 --> 00:08:38,090
actual system so that when once you have

00:08:36,620 --> 00:08:38,960
your results and you try to apply them

00:08:38,090 --> 00:08:40,910
to production

00:08:38,960 --> 00:08:43,550
they don't actually they don't actually

00:08:40,910 --> 00:08:44,960
apply and so you know you now have the

00:08:43,550 --> 00:08:48,320
caveat that you were working with a

00:08:44,960 --> 00:08:51,170
model of your system and so your results

00:08:48,320 --> 00:08:52,750
might not generalize but again a not

00:08:51,170 --> 00:08:55,970
perfect model can still be used

00:08:52,750 --> 00:08:58,520
and there's really a full spectrum here

00:08:55,970 --> 00:09:01,490
where you can make models of small

00:08:58,520 --> 00:09:04,670
pieces of your system to get somewhere

00:09:01,490 --> 00:09:06,620
between these two extremes and the the

00:09:04,670 --> 00:09:08,240
choice we made with cook was to take the

00:09:06,620 --> 00:09:09,590
part of our code that does this that

00:09:08,240 --> 00:09:12,800
handles scheduling the part that's like

00:09:09,590 --> 00:09:15,680
the actual maysa framework and use that

00:09:12,800 --> 00:09:17,660
code but then mock everything else so we

00:09:15,680 --> 00:09:19,880
run all of our databases in memory and

00:09:17,660 --> 00:09:21,560
we built a mock of maysa so that we

00:09:19,880 --> 00:09:24,290
could run our system much faster in a

00:09:21,560 --> 00:09:26,960
single box and so we'll see that in a

00:09:24,290 --> 00:09:29,840
little bit but now now given that we

00:09:26,960 --> 00:09:31,430
have this set up you know we can start

00:09:29,840 --> 00:09:33,470
to ask we can start to run these

00:09:31,430 --> 00:09:35,570
experiments with certain hypotheses so I

00:09:33,470 --> 00:09:38,320
mean I think one of the most basic ones

00:09:35,570 --> 00:09:40,670
is basically the foundation of testing

00:09:38,320 --> 00:09:43,010
if I upgrade from version one to version

00:09:40,670 --> 00:09:44,570
two my hypothesis is that my system

00:09:43,010 --> 00:09:47,330
remains correct and we could just test

00:09:44,570 --> 00:09:49,070
this we could either generate traffic

00:09:47,330 --> 00:09:50,450
that looks like production traffic or we

00:09:49,070 --> 00:09:52,460
can just take a trace of production

00:09:50,450 --> 00:09:54,440
traffic you know maybe look at what what

00:09:52,460 --> 00:09:57,050
happened last week and apply it to this

00:09:54,440 --> 00:10:00,230
week and apply it sorry apply it to your

00:09:57,050 --> 00:10:02,210
upgraded system and now if your system

00:10:00,230 --> 00:10:04,040
remains correct either because you you

00:10:02,210 --> 00:10:05,930
have properties that you would assert or

00:10:04,040 --> 00:10:08,690
you just check that it behaves the same

00:10:05,930 --> 00:10:10,160
way it did last week well now you could

00:10:08,690 --> 00:10:11,840
be confident that or you could be at

00:10:10,160 --> 00:10:13,220
least more confident that your system is

00:10:11,840 --> 00:10:16,730
going to be correct when you deploy to

00:10:13,220 --> 00:10:18,860
production with this upgrade you might

00:10:16,730 --> 00:10:21,230
have another hypothesis that if request

00:10:18,860 --> 00:10:23,180
rates double your latency stays about

00:10:21,230 --> 00:10:26,540
the same that you know your system

00:10:23,180 --> 00:10:27,980
scales well or that the doubling of

00:10:26,540 --> 00:10:30,470
request rate isn't going to hit a knee

00:10:27,980 --> 00:10:35,540
in performance where you know you jump

00:10:30,470 --> 00:10:37,280
to a new latency for all requests or you

00:10:35,540 --> 00:10:40,160
might look at apophysis around server

00:10:37,280 --> 00:10:41,660
failures so you know maybe if a server

00:10:40,160 --> 00:10:45,190
fails your hypothesis is that your

00:10:41,660 --> 00:10:47,930
system doesn't fall over and you know

00:10:45,190 --> 00:10:51,020
when we look at real-world examples of

00:10:47,930 --> 00:10:53,180
people actually doing this you know this

00:10:51,020 --> 00:10:55,810
is a pretty common thing to look at and

00:10:53,180 --> 00:10:58,400
so probably the most famous example of

00:10:55,810 --> 00:11:01,070
using simulation testing to test your

00:10:58,400 --> 00:11:03,650
system and I suspect specifically to

00:11:01,070 --> 00:11:05,180
look at faults is Kyle Kingsbury's work

00:11:03,650 --> 00:11:07,310
or a fir you may have known him

00:11:05,180 --> 00:11:08,930
you know him as with Jepson and so the

00:11:07,310 --> 00:11:11,510
idea of Jepsen is it stands up a

00:11:08,930 --> 00:11:13,040
distributed system and sends it requests

00:11:11,510 --> 00:11:15,500
and then injects faults either network

00:11:13,040 --> 00:11:16,520
partitions or server failures and checks

00:11:15,500 --> 00:11:19,580
that the properties of system

00:11:16,520 --> 00:11:24,110
advertisers actually apply to the system

00:11:19,580 --> 00:11:26,390
in the in the face of faults and if you

00:11:24,110 --> 00:11:28,420
haven't seen his work before I recommend

00:11:26,390 --> 00:11:31,040
you you go look at these posts they're

00:11:28,420 --> 00:11:33,740
amazing they're a lot of fun to read and

00:11:31,040 --> 00:11:35,570
also like really terrifying when you

00:11:33,740 --> 00:11:38,150
realize that lots of systems that we

00:11:35,570 --> 00:11:41,900
depend on every day have some serious

00:11:38,150 --> 00:11:43,400
problems and so I I'm pretty thankful

00:11:41,900 --> 00:11:45,800
that Kyle's going through and finding

00:11:43,400 --> 00:11:49,690
these problems and helping us get more

00:11:45,800 --> 00:11:52,070
robust systems on the academic side

00:11:49,690 --> 00:11:54,320
there's this paper lineage driven fault

00:11:52,070 --> 00:11:57,980
injection where they take a model of

00:11:54,320 --> 00:11:59,720
your system and have a correct request

00:11:57,980 --> 00:12:02,390
flow and then they have this tool that

00:11:59,720 --> 00:12:04,040
will look at this request flow and try

00:12:02,390 --> 00:12:07,400
to find places where if they inject

00:12:04,040 --> 00:12:11,690
faults they can make the request flow

00:12:07,400 --> 00:12:13,730
incorrect and once this tool runs what

00:12:11,690 --> 00:12:15,980
you get back is one of two things either

00:12:13,730 --> 00:12:17,390
you get a case where your system doesn't

00:12:15,980 --> 00:12:19,280
have the properties it says it does and

00:12:17,390 --> 00:12:22,220
you get this nice Lamport diagram

00:12:19,280 --> 00:12:24,590
showing where things went wrong or you

00:12:22,220 --> 00:12:27,140
get a gold star that says for this

00:12:24,590 --> 00:12:29,750
particular request flow your system is

00:12:27,140 --> 00:12:30,680
robust to some level of faults and so

00:12:29,750 --> 00:12:32,570
like you know if you kill all the

00:12:30,680 --> 00:12:35,210
servers your systems probably not robust

00:12:32,570 --> 00:12:38,030
to that but given some level of faults

00:12:35,210 --> 00:12:40,520
your system will be robust and I mean

00:12:38,030 --> 00:12:43,850
that's a really powerful guarantee you

00:12:40,520 --> 00:12:47,960
know this is the kind of thing that I

00:12:43,850 --> 00:12:50,540
hope we get to see more of a different

00:12:47,960 --> 00:12:52,190
type of example that's testing that it's

00:12:50,540 --> 00:12:54,110
not testing for faults but instead

00:12:52,190 --> 00:12:56,360
testing to see if we can optimize our

00:12:54,110 --> 00:12:58,010
system is this boat paper and so what

00:12:56,360 --> 00:12:59,510
they did was they look to see if if you

00:12:58,010 --> 00:13:04,190
change configuration settings on

00:12:59,510 --> 00:13:06,200
Cassandra could you reduce latency and

00:13:04,190 --> 00:13:07,970
sure enough they were able to find

00:13:06,200 --> 00:13:09,950
settings that reduce latency by about

00:13:07,970 --> 00:13:13,820
three acts and this is by changing just

00:13:09,950 --> 00:13:15,020
configuration no code was changed the

00:13:13,820 --> 00:13:16,760
way they did this was they just stood up

00:13:15,020 --> 00:13:19,010
a Cassandra cluster and ran through some

00:13:16,760 --> 00:13:21,170
workloads change a configuration

00:13:19,010 --> 00:13:24,079
the same thing and found Settings and

00:13:21,170 --> 00:13:29,779
found these improved settings I mean

00:13:24,079 --> 00:13:31,459
this is this is really powerful so you

00:13:29,779 --> 00:13:32,600
know we've looked at simulation testing

00:13:31,459 --> 00:13:34,339
in general and now I'm gonna tell you a

00:13:32,600 --> 00:13:36,410
little bit about Cooke and so I

00:13:34,339 --> 00:13:39,199
mentioned before Cooke is an open source

00:13:36,410 --> 00:13:40,730
distributed a distributed job scheduler

00:13:39,199 --> 00:13:42,589
and it's really built for the case when

00:13:40,730 --> 00:13:45,529
you have a lot more requests than you

00:13:42,589 --> 00:13:47,779
have capacity to run and the reason we

00:13:45,529 --> 00:13:48,769
built Cooke was a few years ago this is

00:13:47,779 --> 00:13:50,660
kind of what it looked like at two

00:13:48,769 --> 00:13:52,370
segments it still looks like this we're

00:13:50,660 --> 00:13:55,610
a bunch of users that want lots of

00:13:52,370 --> 00:13:57,980
compute I'm often during the work day at

00:13:55,610 --> 00:13:59,720
least the requests are for way more

00:13:57,980 --> 00:14:01,940
compute than we really want to keep on

00:13:59,720 --> 00:14:05,269
hand and so we know we need to share it

00:14:01,940 --> 00:14:07,399
fairly and so Cook has two mechanisms to

00:14:05,269 --> 00:14:09,320
do this the first one is that we order

00:14:07,399 --> 00:14:12,079
jobs based on DRF the same algorithm

00:14:09,320 --> 00:14:14,690
maysa is using to decide what framework

00:14:12,079 --> 00:14:17,329
to give resources to next and then we

00:14:14,690 --> 00:14:21,620
schedule so that users that have low

00:14:17,329 --> 00:14:23,899
share get scheduled sooner and this

00:14:21,620 --> 00:14:25,519
works well when we have an empty cluster

00:14:23,899 --> 00:14:27,889
and a bunch of users show up and we were

00:14:25,519 --> 00:14:29,180
able to provide them all compute but

00:14:27,889 --> 00:14:30,319
what can happen is if it like two

00:14:29,180 --> 00:14:32,690
o'clock in the morning there's only a

00:14:30,319 --> 00:14:34,279
few users that want compute we're happy

00:14:32,690 --> 00:14:36,170
to give all of them large shares of the

00:14:34,279 --> 00:14:39,410
cluster whereas the work day comes

00:14:36,170 --> 00:14:41,360
around more users want compute and then

00:14:39,410 --> 00:14:43,040
we have this problem where if users that

00:14:41,360 --> 00:14:44,810
are already running their their jobs are

00:14:43,040 --> 00:14:45,980
going to take a long time so the users

00:14:44,810 --> 00:14:47,660
that are waiting will have to wait a

00:14:45,980 --> 00:14:50,540
long time before they can get their fair

00:14:47,660 --> 00:14:51,860
share and so we have another component

00:14:50,540 --> 00:14:53,269
that will rebalance the cluster we'll

00:14:51,860 --> 00:14:55,250
preempt jobs from users that have a lot

00:14:53,269 --> 00:14:57,709
of resources and give them to users that

00:14:55,250 --> 00:15:00,079
have only a little bit and so between

00:14:57,709 --> 00:15:02,269
these two mechanisms we were able to

00:15:00,079 --> 00:15:04,220
provide an environment where users could

00:15:02,269 --> 00:15:05,720
request resources and then be able to

00:15:04,220 --> 00:15:07,610
run their jobs and be confident that

00:15:05,720 --> 00:15:10,550
they'll complete in a reasonable amount

00:15:07,610 --> 00:15:12,290
of time but recently we started

00:15:10,550 --> 00:15:14,329
leveraging the public cloud and with it

00:15:12,290 --> 00:15:17,029
has come a lot of capabilities and with

00:15:14,329 --> 00:15:19,519
it challenges and so the first challenge

00:15:17,029 --> 00:15:20,569
is around heterogeneous clusters now in

00:15:19,519 --> 00:15:22,100
the public cloud you can purchase

00:15:20,569 --> 00:15:24,680
machines that are memory optimized or

00:15:22,100 --> 00:15:26,600
compute optimized and then the choice of

00:15:24,680 --> 00:15:29,899
what job to run on what machine actually

00:15:26,600 --> 00:15:31,399
matters you know they might they might

00:15:29,899 --> 00:15:32,640
have better performance on a memory

00:15:31,399 --> 00:15:35,550
optimized machine but it might

00:15:32,640 --> 00:15:38,160
cost more and so being able to trade off

00:15:35,550 --> 00:15:40,380
the cost for performance would be I

00:15:38,160 --> 00:15:42,660
think really powerful but at the moment

00:15:40,380 --> 00:15:44,850
our scheduling algorithm will just get

00:15:42,660 --> 00:15:49,140
we'll just schedule the job on any box

00:15:44,850 --> 00:15:52,140
where they it will fit another challenge

00:15:49,140 --> 00:15:53,310
we've had is around scaling in the

00:15:52,140 --> 00:15:56,130
public clouds I mean that that's one of

00:15:53,310 --> 00:15:57,570
the most powerful components of the

00:15:56,130 --> 00:15:59,160
cloud is that you know when you need to

00:15:57,570 --> 00:16:00,450
burst you can and then when you no

00:15:59,160 --> 00:16:03,990
longer need the compute you just scale

00:16:00,450 --> 00:16:06,660
down but this really begs the question

00:16:03,990 --> 00:16:08,280
well when should you scale and right now

00:16:06,660 --> 00:16:10,200
we have some heuristics to do the

00:16:08,280 --> 00:16:12,570
scaling but we really wanted something

00:16:10,200 --> 00:16:14,610
that's more integrated with with our

00:16:12,570 --> 00:16:15,840
scheduling algorithms and so earlier

00:16:14,610 --> 00:16:18,240
this year we decided we wanted to

00:16:15,840 --> 00:16:21,270
revisit some of the algorithms we used

00:16:18,240 --> 00:16:22,500
to schedule but we know we had this

00:16:21,270 --> 00:16:24,870
problem that it's the same problem that

00:16:22,500 --> 00:16:26,790
we saw earlier where you know we we want

00:16:24,870 --> 00:16:29,160
to run the experiment of if we change

00:16:26,790 --> 00:16:30,750
our scheduling algorithm are we able to

00:16:29,160 --> 00:16:33,450
take advantage of these things and and

00:16:30,750 --> 00:16:36,690
either improve performance or reduced

00:16:33,450 --> 00:16:38,280
cost but we don't you know if we do it

00:16:36,690 --> 00:16:40,170
in production we have all these

00:16:38,280 --> 00:16:42,990
confounding variables prices change

00:16:40,170 --> 00:16:44,460
workloads change we won't we can't be

00:16:42,990 --> 00:16:46,680
really confident that our changes

00:16:44,460 --> 00:16:48,690
actually have the effect we want them to

00:16:46,680 --> 00:16:51,690
and so you know we set out to build this

00:16:48,690 --> 00:16:53,130
simulator and so now I'm gonna tell you

00:16:51,690 --> 00:16:56,160
a little bit about how the simulators

00:16:53,130 --> 00:16:58,590
built how it's designed and to do this

00:16:56,160 --> 00:17:00,840
first it helps to look at how Cooke is

00:16:58,590 --> 00:17:02,370
architected both from an external view

00:17:00,840 --> 00:17:04,560
and then internally and then revisit

00:17:02,370 --> 00:17:06,709
what meso Sook's like so this is kind of

00:17:04,560 --> 00:17:09,240
how we run cooking production we have

00:17:06,709 --> 00:17:11,610
three cook servers for high availability

00:17:09,240 --> 00:17:13,770
zookeeper for leader election day Tomic

00:17:11,610 --> 00:17:16,800
as our data store and then may sauce of

00:17:13,770 --> 00:17:19,050
course for resources internally there's

00:17:16,800 --> 00:17:22,800
a bunch of components but the three

00:17:19,050 --> 00:17:24,870
biggest components are a component to

00:17:22,800 --> 00:17:27,030
take the jobs that are waiting and rank

00:17:24,870 --> 00:17:28,620
them based on DRF and then send this

00:17:27,030 --> 00:17:30,780
ranking to a component that handles

00:17:28,620 --> 00:17:35,520
scheduling it also takes in new offers

00:17:30,780 --> 00:17:39,180
and then and then once we have these

00:17:35,520 --> 00:17:41,040
matches well send we'll call launch

00:17:39,180 --> 00:17:43,710
tasks on the scheduler dry on the

00:17:41,040 --> 00:17:45,670
message driver to actually send those

00:17:43,710 --> 00:17:47,680
requests to mesas

00:17:45,670 --> 00:17:49,150
we have a second component that handles

00:17:47,680 --> 00:17:51,190
rebalancing of the cluster so this is

00:17:49,150 --> 00:17:52,990
the the component that preempts from

00:17:51,190 --> 00:17:55,930
users with lots of share and gives it to

00:17:52,990 --> 00:17:57,820
users with little share and this is also

00:17:55,930 --> 00:17:59,500
taking in both the view of the entire

00:17:57,820 --> 00:18:02,310
cluster and the ranking of all the jobs

00:17:59,500 --> 00:18:04,630
we want to run and what once it finds

00:18:02,310 --> 00:18:06,700
tasks we want to preempt in favor of

00:18:04,630 --> 00:18:11,200
others it will call kill tasks on mesas

00:18:06,700 --> 00:18:12,910
to free up those resources so now on the

00:18:11,200 --> 00:18:15,430
meso side I mean you've probably seen

00:18:12,910 --> 00:18:17,560
this effective diagram where we have a

00:18:15,430 --> 00:18:19,840
few maysa masters for high availability

00:18:17,560 --> 00:18:22,150
so you keep it for some state and to

00:18:19,840 --> 00:18:23,500
handle leader election the mesas agents

00:18:22,150 --> 00:18:25,930
for resources and then on the framework

00:18:23,500 --> 00:18:28,930
side we have some client library the

00:18:25,930 --> 00:18:30,460
massage driver that handles the

00:18:28,930 --> 00:18:36,520
communication between the framework and

00:18:30,460 --> 00:18:39,520
and may sews and so I mentioned earlier

00:18:36,520 --> 00:18:41,170
that what we chose to do was take take

00:18:39,520 --> 00:18:42,700
cook and then mock all of its

00:18:41,170 --> 00:18:47,230
dependencies and so what this means is

00:18:42,700 --> 00:18:49,180
that we'll end up mocking both the mesas

00:18:47,230 --> 00:18:51,220
master in the Mesa driver and then

00:18:49,180 --> 00:18:53,560
bringing our databases in memory

00:18:51,220 --> 00:18:56,440
thankfully both of them have a testing

00:18:53,560 --> 00:18:59,470
in memory version and so when you build

00:18:56,440 --> 00:19:01,210
a simulator there's some high-level

00:18:59,470 --> 00:19:02,740
properties you need to think about that

00:19:01,210 --> 00:19:04,750
are going to affect your entire design

00:19:02,740 --> 00:19:07,180
as well as how you even interact with

00:19:04,750 --> 00:19:08,050
the simulator and those two are whether

00:19:07,180 --> 00:19:10,420
it'll have you simulator be

00:19:08,050 --> 00:19:12,430
deterministic or non-deterministic and

00:19:10,420 --> 00:19:14,820
whether to have it be real-time or

00:19:12,430 --> 00:19:18,010
faster than real-time and so looking at

00:19:14,820 --> 00:19:19,750
determinism having a be deterministic is

00:19:18,010 --> 00:19:22,510
has some really nice properties it means

00:19:19,750 --> 00:19:24,880
that you can be more confident in the

00:19:22,510 --> 00:19:26,800
simulation itself so if the simulation

00:19:24,880 --> 00:19:29,770
runs and you run the same simulation

00:19:26,800 --> 00:19:30,670
twice so you make no changes the result

00:19:29,770 --> 00:19:32,170
should be the same and if they're not

00:19:30,670 --> 00:19:33,550
you know there's a problem you know

00:19:32,170 --> 00:19:36,610
there's some bug in the simulation

00:19:33,550 --> 00:19:39,120
itself this also means that if you do

00:19:36,610 --> 00:19:41,320
make a change between two simulations

00:19:39,120 --> 00:19:43,030
the results that you see the difference

00:19:41,320 --> 00:19:44,890
in those results is strictly from the

00:19:43,030 --> 00:19:50,200
change you made and not from any noise

00:19:44,890 --> 00:19:51,550
from the non determinism the problem

00:19:50,200 --> 00:19:53,290
with having your simulator be

00:19:51,550 --> 00:19:55,420
deterministic is that your distributed

00:19:53,290 --> 00:19:59,030
system is definitely not deterministic

00:19:55,420 --> 00:20:01,130
and so by forcing your

00:19:59,030 --> 00:20:03,740
simulator and because of this your

00:20:01,130 --> 00:20:05,120
actual system to be deterministic it

00:20:03,740 --> 00:20:06,680
means that you're missing a class of

00:20:05,120 --> 00:20:09,080
behavior that stems from the non

00:20:06,680 --> 00:20:11,770
determinism and so again you have to add

00:20:09,080 --> 00:20:14,840
this caveat with your experiments that

00:20:11,770 --> 00:20:16,600
you know this assumes that there is no

00:20:14,840 --> 00:20:18,380
non determinism which may or may not

00:20:16,600 --> 00:20:22,340
drastically affect how you would

00:20:18,380 --> 00:20:23,780
interpret the results another choice you

00:20:22,340 --> 00:20:25,430
have you have to make is between having

00:20:23,780 --> 00:20:27,020
the system be real time versus faster

00:20:25,430 --> 00:20:28,820
than real time and earlier we said that

00:20:27,020 --> 00:20:30,980
if if you have your production system

00:20:28,820 --> 00:20:32,360
and just make a copy of it it you're

00:20:30,980 --> 00:20:34,430
forced to have it be real time and so

00:20:32,360 --> 00:20:38,900
this is really talking about what you

00:20:34,430 --> 00:20:40,040
decide your system means and so if you

00:20:38,900 --> 00:20:42,740
make it faster than real time you're

00:20:40,040 --> 00:20:44,420
able to run more experiments and so what

00:20:42,740 --> 00:20:47,170
we chose to do is make our system be

00:20:44,420 --> 00:20:50,210
deterministic and faster than real time

00:20:47,170 --> 00:20:52,040
and so at the highest level this is what

00:20:50,210 --> 00:20:55,160
our simulator looks like we have cooked

00:20:52,040 --> 00:20:56,360
in our mock of mazes that are talking to

00:20:55,160 --> 00:20:58,280
each other and we have the simulation

00:20:56,360 --> 00:21:00,500
driver that's going to instantiate both

00:20:58,280 --> 00:21:03,200
wire them up and then drive the

00:21:00,500 --> 00:21:04,520
simulation forward and so we'll look at

00:21:03,200 --> 00:21:08,210
each component individually starting

00:21:04,520 --> 00:21:10,550
with the mock of maysa and so we

00:21:08,210 --> 00:21:12,890
implemented this we needed to mock both

00:21:10,550 --> 00:21:14,240
the driver and the master and so on the

00:21:12,890 --> 00:21:16,700
driver side we needed to provide

00:21:14,240 --> 00:21:19,340
implementations for launch tasks kill

00:21:16,700 --> 00:21:20,810
tasks decline offer I mean if you've

00:21:19,340 --> 00:21:23,810
built a framework before I'm sure you've

00:21:20,810 --> 00:21:25,040
seen this sort of stuff and then the

00:21:23,810 --> 00:21:27,590
mock of Maysles needs to be able to

00:21:25,040 --> 00:21:29,840
handle these these calls as well as be

00:21:27,590 --> 00:21:31,640
able to call into calling to cook and

00:21:29,840 --> 00:21:33,200
provide resource offers let it know when

00:21:31,640 --> 00:21:37,010
it's been registered and provide

00:21:33,200 --> 00:21:40,880
information when tasks move from move to

00:21:37,010 --> 00:21:42,650
running and to completed and you know

00:21:40,880 --> 00:21:43,910
this was a lot of fun to implement but

00:21:42,650 --> 00:21:46,280
we don't really have time to go into it

00:21:43,910 --> 00:21:49,460
ask me afterwards I'm happy to talk

00:21:46,280 --> 00:21:51,890
about it on cook side we made a really

00:21:49,460 --> 00:21:54,350
strong decision to try to change as

00:21:51,890 --> 00:21:57,770
little as possible and this is for two

00:21:54,350 --> 00:21:59,570
reasons one is the less you change from

00:21:57,770 --> 00:22:01,880
simulation to production the more

00:21:59,570 --> 00:22:03,800
confident you can be in your results but

00:22:01,880 --> 00:22:05,690
the other thing is is more from a

00:22:03,800 --> 00:22:07,610
software perspective the more changes

00:22:05,690 --> 00:22:09,890
you need to make to yours to accommodate

00:22:07,610 --> 00:22:11,940
the simulator the harder is going to be

00:22:09,890 --> 00:22:14,400
to keep your simulator and your code in

00:22:11,940 --> 00:22:16,530
and so by making us few change as

00:22:14,400 --> 00:22:19,320
possible it reduces how much effort you

00:22:16,530 --> 00:22:21,720
need to do you need to do to maintain

00:22:19,320 --> 00:22:23,250
your simulator and so the only thing we

00:22:21,720 --> 00:22:26,430
really did was provide a way to trigger

00:22:23,250 --> 00:22:28,200
each of these components instead of

00:22:26,430 --> 00:22:31,740
having them all be event based or

00:22:28,200 --> 00:22:33,660
time-based and so this allows our

00:22:31,740 --> 00:22:36,000
simulation driver once it's instant

00:22:33,660 --> 00:22:38,040
she'd and wired everything to trigger

00:22:36,000 --> 00:22:40,440
each of each component individually and

00:22:38,040 --> 00:22:43,560
this allows us to have the simulation be

00:22:40,440 --> 00:22:46,140
deterministic and so first it on each

00:22:43,560 --> 00:22:48,360
cycle it submits new jobs it triggers

00:22:46,140 --> 00:22:51,210
may suppose to send it triggers our maka

00:22:48,360 --> 00:22:53,220
may so send new offers and sends status

00:22:51,210 --> 00:22:54,480
updates triggers cooked a rank triggers

00:22:53,220 --> 00:22:56,370
cooked a schedule triggers cook to

00:22:54,480 --> 00:22:58,110
rebalance and between each of these

00:22:56,370 --> 00:23:02,460
stages stages it's incrementing

00:22:58,110 --> 00:23:03,720
simulation time and handling time when

00:23:02,460 --> 00:23:05,700
you want your simulation to be

00:23:03,720 --> 00:23:08,850
deterministic is actually tricky and you

00:23:05,700 --> 00:23:10,170
need to think about it you know time is

00:23:08,850 --> 00:23:12,920
one of those things that's going to make

00:23:10,170 --> 00:23:16,410
your system be non-deterministic and so

00:23:12,920 --> 00:23:17,790
one way to handle this is between each

00:23:16,410 --> 00:23:20,730
of these events to keep track of the

00:23:17,790 --> 00:23:24,510
wall clock time that maps to what the

00:23:20,730 --> 00:23:25,440
simulation time was and then in addition

00:23:24,510 --> 00:23:26,880
to doing that you also need to keep

00:23:25,440 --> 00:23:30,870
track of the inputs and outputs so you

00:23:26,880 --> 00:23:32,430
know between this simulation time this

00:23:30,870 --> 00:23:34,080
component got these inputs and got these

00:23:32,430 --> 00:23:35,790
outputs that when you go to look back at

00:23:34,080 --> 00:23:40,110
your at the results of your simulation

00:23:35,790 --> 00:23:41,190
you can see how everything flowed the

00:23:40,110 --> 00:23:43,340
problem with doing this is that you end

00:23:41,190 --> 00:23:45,990
up keeping track of a lot of data both

00:23:43,340 --> 00:23:47,370
what wall clock times map to simulation

00:23:45,990 --> 00:23:49,200
time but also all the data that's

00:23:47,370 --> 00:23:51,990
flowing and you also need to have ways

00:23:49,200 --> 00:23:52,890
of getting that data so right now

00:23:51,990 --> 00:23:55,200
because of the way we're doing the

00:23:52,890 --> 00:23:57,390
triggering all the data flow is still

00:23:55,200 --> 00:24:01,320
handled by the normal code that we use

00:23:57,390 --> 00:24:02,640
in production if we wanted to be able to

00:24:01,320 --> 00:24:04,800
get that data out we'd have to add

00:24:02,640 --> 00:24:06,240
deeper hooks into all of our components

00:24:04,800 --> 00:24:10,560
which like I said we didn't we don't

00:24:06,240 --> 00:24:12,810
want to do and so we did something I'm

00:24:10,560 --> 00:24:16,080
not entirely proud of but it did it does

00:24:12,810 --> 00:24:17,460
work which is just stop time so we're

00:24:16,080 --> 00:24:19,740
running on the JVM we're used joda-time

00:24:17,460 --> 00:24:21,990
and deep in the bowels of joda-time that

00:24:19,740 --> 00:24:23,550
I hope nobody knows exists is a function

00:24:21,990 --> 00:24:24,930
that can you can set current time

00:24:23,550 --> 00:24:26,970
Milly's so any

00:24:24,930 --> 00:24:31,410
to get time now gives the back the same

00:24:26,970 --> 00:24:33,960
instant until you reset it and so we use

00:24:31,410 --> 00:24:36,090
this so that all of our components when

00:24:33,960 --> 00:24:37,590
they get time all have the same all at

00:24:36,090 --> 00:24:40,050
the same time it's now just simulation

00:24:37,590 --> 00:24:41,700
time so any time stamps that are written

00:24:40,050 --> 00:24:43,800
to the database also have simulation

00:24:41,700 --> 00:24:45,900
time and what this means is that we

00:24:43,800 --> 00:24:46,950
didn't have to make any changes to get

00:24:45,900 --> 00:24:48,690
any of this data and we didn't have to

00:24:46,950 --> 00:24:51,120
keep track of what simulation time was

00:24:48,690 --> 00:24:52,650
what we had to do was change current

00:24:51,120 --> 00:24:55,830
time Milly's throughout the running of

00:24:52,650 --> 00:24:59,730
the simulation and so like I said this

00:24:55,830 --> 00:25:01,320
is this is a little sketchy but it means

00:24:59,730 --> 00:25:03,060
that we didn't have to make these deep

00:25:01,320 --> 00:25:04,680
changes we didn't want to make and it

00:25:03,060 --> 00:25:07,370
also means that if we look at our the

00:25:04,680 --> 00:25:10,050
actual database of two simulations that

00:25:07,370 --> 00:25:11,640
that have no changes between them they

00:25:10,050 --> 00:25:13,740
will be at it will be identical as well

00:25:11,640 --> 00:25:15,420
which is kind of a nice property when

00:25:13,740 --> 00:25:17,630
you want to look at the individual

00:25:15,420 --> 00:25:19,920
events that occurred in the system and

00:25:17,630 --> 00:25:21,090
so I mean there's a lot more details

00:25:19,920 --> 00:25:22,920
about the simulator but this kind of

00:25:21,090 --> 00:25:24,930
gives you a nice feel for how it works

00:25:22,920 --> 00:25:28,560
and so now I want to tell you about how

00:25:24,930 --> 00:25:29,910
we used it what we did was kind of

00:25:28,560 --> 00:25:32,310
similar to what that boat paper did

00:25:29,910 --> 00:25:34,800
where we we looked at if we could change

00:25:32,310 --> 00:25:37,230
configuration settings to improve how we

00:25:34,800 --> 00:25:39,060
do rebalancing and what I mean by

00:25:37,230 --> 00:25:40,740
improve in this case is could we reduce

00:25:39,060 --> 00:25:42,930
the number of preemptions and reduce the

00:25:40,740 --> 00:25:45,030
waste that stems from those preemptions

00:25:42,930 --> 00:25:47,580
while still keeping fairness about the

00:25:45,030 --> 00:25:49,470
same and so I mean I mentioned it before

00:25:47,580 --> 00:25:51,180
basically the idea of how the preemption

00:25:49,470 --> 00:25:53,490
works is if we have some users that have

00:25:51,180 --> 00:25:55,230
a lot a large share of the cluster we

00:25:53,490 --> 00:25:57,420
have users that have a very small share

00:25:55,230 --> 00:26:00,660
and they're not getting more resources

00:25:57,420 --> 00:26:02,010
at a quick enough pace will rebalance

00:26:00,660 --> 00:26:03,300
the cluster will preamp from users that

00:26:02,010 --> 00:26:07,290
have a lot and give to users and have a

00:26:03,300 --> 00:26:08,880
little and but what we're really

00:26:07,290 --> 00:26:10,410
changing here is just configuration

00:26:08,880 --> 00:26:12,570
settings and the two knobs we had at our

00:26:10,410 --> 00:26:14,880
disposal where the number of tasks to

00:26:12,570 --> 00:26:16,920
preempt at any cycle and how selective

00:26:14,880 --> 00:26:19,020
to be when we choose to make preemptions

00:26:16,920 --> 00:26:20,820
and so this is how unfair the allocation

00:26:19,020 --> 00:26:23,970
needs to be before we're willing to

00:26:20,820 --> 00:26:26,370
preempt tasks and we set up our

00:26:23,970 --> 00:26:30,240
experiment to look at data between May

00:26:26,370 --> 00:26:31,830
1st and May 6 and what we chose to do is

00:26:30,240 --> 00:26:33,870
we look at reducing the number of

00:26:31,830 --> 00:26:36,600
preemptions and increased in increasing

00:26:33,870 --> 00:26:38,670
the selectivity and we had a feeling

00:26:36,600 --> 00:26:40,200
this would work well because

00:26:38,670 --> 00:26:42,210
previously I had run a simulation that

00:26:40,200 --> 00:26:44,790
didn't touch any of these preemption

00:26:42,210 --> 00:26:46,620
settings but I had misconfigured it and

00:26:44,790 --> 00:26:47,940
it had it so that it it didn't have the

00:26:46,620 --> 00:26:51,810
settings that the production system was

00:26:47,940 --> 00:26:52,860
using and it the results from it when I

00:26:51,810 --> 00:26:57,090
was looking at I was like wow this is

00:26:52,860 --> 00:26:58,830
really weird showed that this

00:26:57,090 --> 00:27:01,590
combination of reducing preemptions and

00:26:58,830 --> 00:27:03,000
increasing selectivity would let us

00:27:01,590 --> 00:27:04,020
reduce the number of preemptions and

00:27:03,000 --> 00:27:07,380
reduce waste

00:27:04,020 --> 00:27:10,050
whereas doing just one would one of them

00:27:07,380 --> 00:27:11,250
wouldn't why either waste would increase

00:27:10,050 --> 00:27:12,840
or the number of preemptions would

00:27:11,250 --> 00:27:14,640
increase and so this was kind of this

00:27:12,840 --> 00:27:17,580
non-intuitive result that kind of popped

00:27:14,640 --> 00:27:20,190
out just from well a mistake but you

00:27:17,580 --> 00:27:23,540
know lots of good things come from from

00:27:20,190 --> 00:27:27,300
like miss configurations and mistakes so

00:27:23,540 --> 00:27:28,890
we have this experiment and the results

00:27:27,300 --> 00:27:31,260
we were looking for in simulation was

00:27:28,890 --> 00:27:33,960
that fairness and just total resources

00:27:31,260 --> 00:27:36,090
that we used over time stayed about flat

00:27:33,960 --> 00:27:38,730
or decreased only ever so slightly but

00:27:36,090 --> 00:27:40,310
waste decreased significantly and so

00:27:38,730 --> 00:27:42,750
that that's exactly we ended up seeing

00:27:40,310 --> 00:27:44,790
total resource use stayed about the same

00:27:42,750 --> 00:27:46,050
fairness dropped by only a little bit

00:27:44,790 --> 00:27:50,070
and so we'll look at that in a moment

00:27:46,050 --> 00:27:51,150
and then waste dropped by about 15% so

00:27:50,070 --> 00:27:53,190
we you know we were really happy with

00:27:51,150 --> 00:27:56,940
this and then looking at the simulation

00:27:53,190 --> 00:27:58,890
results for fairness we looked at what

00:27:56,940 --> 00:28:00,990
we call starvation overtime and what I

00:27:58,890 --> 00:28:02,700
mean by starvation is if you look at how

00:28:00,990 --> 00:28:05,940
much resources a user would get if we

00:28:02,700 --> 00:28:07,530
just evenly partition the cluster per

00:28:05,940 --> 00:28:10,370
user and then looked at how much

00:28:07,530 --> 00:28:13,080
resources they got allocated by cook

00:28:10,370 --> 00:28:15,270
anything under that fare out anything

00:28:13,080 --> 00:28:18,720
under that even allocation we considered

00:28:15,270 --> 00:28:22,110
them being starved and so when we look

00:28:18,720 --> 00:28:24,720
at this graph up is bad and what we'll

00:28:22,110 --> 00:28:26,220
see is that our our old production

00:28:24,720 --> 00:28:28,620
settings and the new settings that we

00:28:26,220 --> 00:28:31,170
went to the new settings were always

00:28:28,620 --> 00:28:33,420
higher but they tracked very closely and

00:28:31,170 --> 00:28:36,120
so you know we were we were pretty happy

00:28:33,420 --> 00:28:38,790
to trade off this slight increase in

00:28:36,120 --> 00:28:43,290
unfairness for that large drop in waste

00:28:38,790 --> 00:28:44,760
and so once we'd finished our analysis

00:28:43,290 --> 00:28:48,090
we were we were happy to go to

00:28:44,760 --> 00:28:49,650
production and what you'll see is we're

00:28:48,090 --> 00:28:52,169
looking at waste over time now and

00:28:49,650 --> 00:28:53,639
there'll be a line showing when when the

00:28:52,169 --> 00:28:56,580
change went in and after the change went

00:28:53,639 --> 00:28:58,649
in waste drops and then stays down and

00:28:56,580 --> 00:29:01,409
so you know we were happy with these

00:28:58,649 --> 00:29:04,710
results right we were able to have a

00:29:01,409 --> 00:29:06,359
hypothesis tested in our simulation find

00:29:04,710 --> 00:29:08,340
results that we were happy with and then

00:29:06,359 --> 00:29:11,249
apply them to production and get to see

00:29:08,340 --> 00:29:12,830
that that they matched pretty well with

00:29:11,249 --> 00:29:14,609
what what have we saw in our simulations

00:29:12,830 --> 00:29:16,200
you know this was really powerful

00:29:14,609 --> 00:29:18,059
there's no way we would have been able

00:29:16,200 --> 00:29:19,919
to just guess around and poke at these

00:29:18,059 --> 00:29:23,070
settings in production right we'd have

00:29:19,919 --> 00:29:24,779
to wait a few days to see to see whether

00:29:23,070 --> 00:29:27,149
what the effect of these settings were

00:29:24,779 --> 00:29:28,799
and we'd like go back and reset them you

00:29:27,149 --> 00:29:31,080
know this would be really painful to

00:29:28,799 --> 00:29:36,029
find without something like a simulator

00:29:31,080 --> 00:29:39,179
and so you know we've so we've looked at

00:29:36,029 --> 00:29:42,239
what it means to to simulate a system in

00:29:39,179 --> 00:29:43,679
general we looked at we looked at what

00:29:42,239 --> 00:29:45,799
cookie is and what it mean what it meant

00:29:43,679 --> 00:29:48,929
to simulate cook and saw a case in which

00:29:45,799 --> 00:29:51,029
using the simulator helped us find how

00:29:48,929 --> 00:29:53,580
helped us improve the system I should

00:29:51,029 --> 00:29:55,559
say aside from just just this case we

00:29:53,580 --> 00:29:57,899
also use it to improve testing in our

00:29:55,559 --> 00:29:59,730
systems so while building it and while

00:29:57,899 --> 00:30:02,009
while starting using our simulator we

00:29:59,730 --> 00:30:04,169
found - like really nasty bugs and cook

00:30:02,009 --> 00:30:05,850
that had been there for years and then

00:30:04,169 --> 00:30:08,249
once we started applying it to our

00:30:05,850 --> 00:30:11,190
continuous integration we've caught a

00:30:08,249 --> 00:30:12,629
few bugs now that that we didn't catch

00:30:11,190 --> 00:30:14,369
from any of our other testing it would

00:30:12,629 --> 00:30:16,739
have made it further into our process of

00:30:14,369 --> 00:30:19,409
QA and and release before we would have

00:30:16,739 --> 00:30:23,369
hid the bug in it probably in production

00:30:19,409 --> 00:30:25,109
and so before I wrap up I want to leave

00:30:23,369 --> 00:30:27,450
you with just one this one idea which is

00:30:25,109 --> 00:30:29,190
simulation testing helps us understand

00:30:27,450 --> 00:30:31,409
our system more deeply being able to

00:30:29,190 --> 00:30:33,179
experiment with our system and being

00:30:31,409 --> 00:30:36,840
able to do it in a principled and

00:30:33,179 --> 00:30:38,940
scientific way helps us understand not

00:30:36,840 --> 00:30:42,840
only whether our system is robust and

00:30:38,940 --> 00:30:45,359
how to improve it but also lets us poke

00:30:42,840 --> 00:30:49,529
at you know these complex interactions

00:30:45,359 --> 00:30:50,970
between these components and any any

00:30:49,529 --> 00:30:52,649
tool you can have that can help us

00:30:50,970 --> 00:30:54,989
understand these complex distributed

00:30:52,649 --> 00:30:57,029
systems more I think is is really useful

00:30:54,989 --> 00:30:59,690
and so with that I'm happy to answer any

00:30:57,029 --> 00:30:59,690
questions you might have

00:31:02,590 --> 00:31:05,590
microphone

00:31:12,630 --> 00:31:16,740
I said you're mocking me sauce how

00:31:15,420 --> 00:31:21,180
general-purpose is it are you planning

00:31:16,740 --> 00:31:23,520
to open source it yeah so it's pretty

00:31:21,180 --> 00:31:25,710
general-purpose it's in Java well so

00:31:23,520 --> 00:31:29,610
it's in the JVM cook is written in

00:31:25,710 --> 00:31:32,310
closure so it's in closure so it would

00:31:29,610 --> 00:31:36,060
be a little bit of work to make it able

00:31:32,310 --> 00:31:38,940
to use for general JVM users if you're

00:31:36,060 --> 00:31:41,070
in closure yeah you it is open source

00:31:38,940 --> 00:31:44,910
right now you can take a look at it in

00:31:41,070 --> 00:31:46,560
the cook github project if there's an

00:31:44,910 --> 00:31:56,970
interest that well we could talk about

00:31:46,560 --> 00:31:59,040
it after how did you know when to stop

00:31:56,970 --> 00:32:01,080
right so you have this ability to go

00:31:59,040 --> 00:32:02,760
quickly change configuration and it

00:32:01,080 --> 00:32:05,100
seems like you could spend forever

00:32:02,760 --> 00:32:07,080
trying to find an optimal stipulation so

00:32:05,100 --> 00:32:09,060
what what criteria did you use to say

00:32:07,080 --> 00:32:11,580
this is good enough I'm gonna now go to

00:32:09,060 --> 00:32:16,920
production with the change yeah that's a

00:32:11,580 --> 00:32:19,440
really good question so in this

00:32:16,920 --> 00:32:20,700
particular case this was the first this

00:32:19,440 --> 00:32:23,940
was the first case in which we use the

00:32:20,700 --> 00:32:24,990
simulate the simulator to find to change

00:32:23,940 --> 00:32:27,750
something and then apply it to

00:32:24,990 --> 00:32:30,240
production and so I actually tried only

00:32:27,750 --> 00:32:33,150
a few settings I already said I had a

00:32:30,240 --> 00:32:35,700
sense of what what type what direction

00:32:33,150 --> 00:32:38,070
that the changes should go in order to

00:32:35,700 --> 00:32:40,290
get the results we wanted so I tried

00:32:38,070 --> 00:32:42,210
that those configuration settings and

00:32:40,290 --> 00:32:44,940
two others to make sure that my

00:32:42,210 --> 00:32:46,770
understanding of how what of how

00:32:44,940 --> 00:32:49,830
changing those values will affect the

00:32:46,770 --> 00:32:53,010
system in in general but I was really

00:32:49,830 --> 00:32:55,380
only looking at those my concern was if

00:32:53,010 --> 00:32:57,420
I tried a lot of different settings I

00:32:55,380 --> 00:32:58,980
might over fit to something that doesn't

00:32:57,420 --> 00:33:01,740
that wasn't going to match production

00:32:58,980 --> 00:33:04,050
well and so I had I was still kind of

00:33:01,740 --> 00:33:06,690
using a mental model that I had checked

00:33:04,050 --> 00:33:08,040
to see that it it looked right in in

00:33:06,690 --> 00:33:09,740
simulation and then went right to

00:33:08,040 --> 00:33:12,300
production because I didn't want to

00:33:09,740 --> 00:33:15,720
overfit to something that I still wasn't

00:33:12,300 --> 00:33:17,460
confident in I think as you build more

00:33:15,720 --> 00:33:19,860
confidence in this in your simulation

00:33:17,460 --> 00:33:22,200
environment you can start to run more

00:33:19,860 --> 00:33:23,850
simulations and really hone in on the

00:33:22,200 --> 00:33:25,910
right settings and so like the batboat

00:33:23,850 --> 00:33:27,470
paper

00:33:25,910 --> 00:33:28,940
they're standing up an actual Cassandra

00:33:27,470 --> 00:33:30,880
cluster and sending an actual request

00:33:28,940 --> 00:33:35,450
and so they can be more confident in the

00:33:30,880 --> 00:33:37,390
in the simulation you know in the

00:33:35,450 --> 00:33:42,050
simulator and so they they can they can

00:33:37,390 --> 00:33:43,550
hone in more on the right settings so it

00:33:42,050 --> 00:33:45,440
really depends on how much you can trust

00:33:43,550 --> 00:33:51,560
your simulator I guess is the answer to

00:33:45,440 --> 00:33:52,540
your question Thanks all right thank you

00:33:51,560 --> 00:33:56,990
thank you

00:33:52,540 --> 00:33:56,990

YouTube URL: https://www.youtube.com/watch?v=4qAVHYqCLlc


