Title: Building Your First Stateful DC OS Service
Publication date: 2017-09-18
Playlist: MesosCon North America 2017
Description: 
	Building Your First Stateful DC/OS Service - Ben Wood, Mesosphere (limited spots, pre-registration suggested)

Apache Mesos and DC/OS are powerful orchestration tools. But, building stateful application on top of DC/OS requires understanding Apache Mesos primitives and DC/OS components, and writing complex scheduler code. 

From a birdâ€™s eye view, most stateful systems look similar. Apache Kafka, Apache Cassandra, and other stateful systems have their own concerns, but they all need to provision storage, scale capacity, be discoverable by clients, be manageable by operators, and be resilient to failure (which is complicated for databases). 

In this talk, Ben will demonstrate by example how the DC/OS SDK enables you to build stateful applications which satisfy these common requirements. Particular attention will be paid to how the abstractions of the DC/OS SDK free developers from focusing on interfacing with Apache Mesos and DC/OS and instead concentrate on building a robust stateful service.

About

Ben Wood
Ben is a software engineer on the DC/OS SDK team at Mesosphere. Prior to Mesosphere, Ben was a software and infrastructure engineer at Autodesk. He has also been an engineer and technical owner of distributed performance measurement systems at Neumob and SOASTA.
Captions: 
	00:00:00,030 --> 00:00:04,319
all right good afternoon and welcome to

00:00:02,370 --> 00:00:07,500
our last Mises University session

00:00:04,319 --> 00:00:11,550
actually today and for this mrs. Khan so

00:00:07,500 --> 00:00:13,080
Ben Ben is a software engineer at mrs.

00:00:11,550 --> 00:00:14,730
fear and he's gonna tell us all about

00:00:13,080 --> 00:00:18,029
what it takes to build like our first

00:00:14,730 --> 00:00:21,180
stateful dcs service and in particular

00:00:18,029 --> 00:00:22,830
this is gonna utilize the SDK so this is

00:00:21,180 --> 00:00:24,119
the underpinning for all the great

00:00:22,830 --> 00:00:27,240
services you might have heard today

00:00:24,119 --> 00:00:29,039
about in the keynote so all this max

00:00:27,240 --> 00:00:31,949
tech services are basically based on the

00:00:29,039 --> 00:00:34,950
SDK and today it's up to you to learn

00:00:31,949 --> 00:00:41,809
and write your first also stateful dcs

00:00:34,950 --> 00:00:47,820
service enjoy okay microphone working

00:00:41,809 --> 00:00:50,789
yes sweet yeah so I am wood I work on

00:00:47,820 --> 00:00:53,399
the SDK team the SDK team SDK will be

00:00:50,789 --> 00:00:54,600
you keep saying SDK I'll explain a bit

00:00:53,399 --> 00:00:55,670
more about like what does that actually

00:00:54,600 --> 00:00:58,260
mean

00:00:55,670 --> 00:01:02,280
cool so first things first you should go

00:00:58,260 --> 00:01:04,049
to bit ly / first stateful every single

00:01:02,280 --> 00:01:05,970
command you see up here is in there like

00:01:04,049 --> 00:01:07,890
with section titles and things so you'll

00:01:05,970 --> 00:01:11,760
be able to follow along without trying

00:01:07,890 --> 00:01:15,409
to hand type incredibly arcane commands

00:01:11,760 --> 00:01:18,840
as well as a bunch of gamal after that

00:01:15,409 --> 00:01:21,799
you're gonna want to do so first an

00:01:18,840 --> 00:01:23,820
order of business there's a lot of you

00:01:21,799 --> 00:01:25,470
we don't have clusters for every single

00:01:23,820 --> 00:01:27,810
one of you so we're gonna do pairs or

00:01:25,470 --> 00:01:29,790
maybe triples so basically like if

00:01:27,810 --> 00:01:31,110
you're sitting by yourself you're doing

00:01:29,790 --> 00:01:32,939
it wrong you should sit next to someone

00:01:31,110 --> 00:01:35,009
and then when we hand out clusters

00:01:32,939 --> 00:01:36,630
you'll pair up with somebody but you can

00:01:35,009 --> 00:01:38,759
definitely like follow along and type

00:01:36,630 --> 00:01:40,590
all the code on your own personal box

00:01:38,759 --> 00:01:42,450
but yeah so you basically wanna do the

00:01:40,590 --> 00:01:45,750
doctor pull mesosphere d service commons

00:01:42,450 --> 00:01:47,250
latest that's also in if you went to the

00:01:45,750 --> 00:01:48,659
bit though I think first you will see

00:01:47,250 --> 00:01:50,820
that and you can just copy and paste

00:01:48,659 --> 00:01:52,560
it's just cuz our docker image it's a

00:01:50,820 --> 00:01:54,299
little bit big but this is actually the

00:01:52,560 --> 00:01:58,399
image that all of our engineers and our

00:01:54,299 --> 00:01:58,399
CI system use for working with the SDK

00:01:59,210 --> 00:02:07,340
alright so everybody on board

00:02:02,549 --> 00:02:09,989
bit that ly first a full docker good

00:02:07,340 --> 00:02:12,260
vague vague acknowledgement great

00:02:09,989 --> 00:02:13,909
alright so our agenda is

00:02:12,260 --> 00:02:15,739
I'm gonna go over an intro like what is

00:02:13,909 --> 00:02:17,959
the SDK what is the motivation behind it

00:02:15,739 --> 00:02:20,480
how does it go about accomplishing what

00:02:17,959 --> 00:02:22,760
it sets out to do then we'll do a bit of

00:02:20,480 --> 00:02:24,680
developer setup basically get at least

00:02:22,760 --> 00:02:26,720
one laptop for every couple of people a

00:02:24,680 --> 00:02:27,769
few people hooked up to a cluster so

00:02:26,720 --> 00:02:29,569
you'll actually build it employ it and

00:02:27,769 --> 00:02:31,519
you do a little bit of debugging and

00:02:29,569 --> 00:02:34,370
then also just have you setup in general

00:02:31,519 --> 00:02:36,819
to write the code on your own machine

00:02:34,370 --> 00:02:39,200
then we'll do a very simple hello world

00:02:36,819 --> 00:02:42,409
sort of introduce you to the development

00:02:39,200 --> 00:02:44,720
cycle with the SDK and then we'll do

00:02:42,409 --> 00:02:46,430
memcache you're kept saying stateful he

00:02:44,720 --> 00:02:48,530
said it so many times

00:02:46,430 --> 00:02:50,239
memcache is not technically stateful

00:02:48,530 --> 00:02:55,609
right like it is a it is an ephemeral

00:02:50,239 --> 00:02:59,180
cache however I know that's fair

00:02:55,609 --> 00:03:02,000
so however however you would you would

00:02:59,180 --> 00:03:03,409
have a very unfortunate time trying to

00:03:02,000 --> 00:03:05,959
do what we're going to do with memcache

00:03:03,409 --> 00:03:07,340
on marathon and we will use like

00:03:05,959 --> 00:03:10,099
leverage things like persistent volumes

00:03:07,340 --> 00:03:11,540
a little bit there's some element of my

00:03:10,099 --> 00:03:13,639
colleagues and I have stolen all the

00:03:11,540 --> 00:03:15,170
low-hanging fruit for like implementing

00:03:13,639 --> 00:03:19,510
stateful distributed services like we

00:03:15,170 --> 00:03:19,510
already did Kafka Cassandra cockroach

00:03:19,540 --> 00:03:24,919
elastic HDFS and and it's sort of like

00:03:22,480 --> 00:03:26,389
those ones you know I'll probably show a

00:03:24,919 --> 00:03:29,209
few of those at the end in terms of like

00:03:26,389 --> 00:03:31,239
what those real productionize camels and

00:03:29,209 --> 00:03:33,769
and a little bit of Java look like but

00:03:31,239 --> 00:03:35,930
so basically well we'll do configuration

00:03:33,769 --> 00:03:38,720
templates and sidecar plans those are

00:03:35,930 --> 00:03:42,349
sort of two of the more useful in terms

00:03:38,720 --> 00:03:43,910
of making a robust framework features of

00:03:42,349 --> 00:03:45,530
the SDK and then we'll sort of go over

00:03:43,910 --> 00:03:47,449
what you can't do which is mostly gonna

00:03:45,530 --> 00:03:49,519
be me telling you everything that the

00:03:47,449 --> 00:03:53,329
SDK can do and then a little bit of

00:03:49,519 --> 00:03:56,389
where we're kind of going with it okay

00:03:53,329 --> 00:03:58,549
the intro nice Who am I I am a software

00:03:56,389 --> 00:04:02,060
engineer at mesosphere I work on the SDK

00:03:58,549 --> 00:04:05,389
team there are about 12 of us Gabriel

00:04:02,060 --> 00:04:07,549
Hartman who gave a talk earlier today he

00:04:05,389 --> 00:04:10,489
is sort of the original author and then

00:04:07,549 --> 00:04:13,459
one of the tech leads I'm the co tech

00:04:10,489 --> 00:04:14,930
lead I focus a lot on like process and

00:04:13,459 --> 00:04:17,840
how the the team can ship like a

00:04:14,930 --> 00:04:20,269
really high quality SDK and like a bit

00:04:17,840 --> 00:04:22,639
more on taking the SDK and building

00:04:20,269 --> 00:04:24,530
really robust data services with it my

00:04:22,639 --> 00:04:25,850
background is a basically real-time

00:04:24,530 --> 00:04:27,860
performance monitoring so I

00:04:25,850 --> 00:04:30,470
a couple of companies where we suck in a

00:04:27,860 --> 00:04:32,620
bunch of data from users around

00:04:30,470 --> 00:04:36,100
performance like website performance and

00:04:32,620 --> 00:04:38,810
provide value to Fortune 2000 companies

00:04:36,100 --> 00:04:43,340
and then also in doing that did a lot of

00:04:38,810 --> 00:04:45,740
infrastructure automation and so the SDK

00:04:43,340 --> 00:04:48,050
what does the SDK mean the SDK is

00:04:45,740 --> 00:04:51,290
fundamentally a github project under

00:04:48,050 --> 00:04:54,650
mesosphere org called DCOs staff Commons

00:04:51,290 --> 00:04:56,630
I don't know sometimes we're like what

00:04:54,650 --> 00:04:58,820
we'll call it if you see us - SDK but

00:04:56,630 --> 00:05:00,890
hey it has the name it has right so

00:04:58,820 --> 00:05:03,560
let's walk through a little bit okay

00:05:00,890 --> 00:05:06,230
like why the SDK just remediate systems

00:05:03,560 --> 00:05:09,590
are hard mezzos is a pretty good

00:05:06,230 --> 00:05:12,700
approach to you know abstracting the

00:05:09,590 --> 00:05:16,300
hardware of a distributed infrastructure

00:05:12,700 --> 00:05:20,810
who here is written the Mazur scheduler

00:05:16,300 --> 00:05:22,820
it's really hard right like right like

00:05:20,810 --> 00:05:24,080
an onboarding task at mesosphere if you

00:05:22,820 --> 00:05:25,940
are a mesosphere employee one of your

00:05:24,080 --> 00:05:28,640
onboarding tasks engineer we do not make

00:05:25,940 --> 00:05:30,740
the accountants do this is you write a

00:05:28,640 --> 00:05:32,810
maze those framework and it's like neat

00:05:30,740 --> 00:05:34,790
with a person who most recently joined

00:05:32,810 --> 00:05:36,350
our team he was like oh yeah I made this

00:05:34,790 --> 00:05:38,300
cool batch scheduler it only took me

00:05:36,350 --> 00:05:40,160
like a few hours and I'm gonna try

00:05:38,300 --> 00:05:42,050
persistent volumes and we all kind of

00:05:40,160 --> 00:05:45,500
just like snickered and we're like okay

00:05:42,050 --> 00:05:48,800
and then two days later Evans like and

00:05:45,500 --> 00:05:51,500
we're like yeah we did that already so

00:05:48,800 --> 00:05:54,500
right like like mezzos is a fantastic

00:05:51,500 --> 00:05:56,660
hardware abstraction but it is wily like

00:05:54,500 --> 00:05:58,580
you got a really deal with a lot of

00:05:56,660 --> 00:05:59,630
weird edge cases and I think right like

00:05:58,580 --> 00:06:02,600
we've seen it like there there are only

00:05:59,630 --> 00:06:05,120
a few truly successful schedulers what I

00:06:02,600 --> 00:06:07,220
think we've seen is people trying to do

00:06:05,120 --> 00:06:09,830
specific data services like a Rango DB

00:06:07,220 --> 00:06:11,780
has made a pretty good framework but

00:06:09,830 --> 00:06:14,540
they have written tens of thousands of

00:06:11,780 --> 00:06:17,380
lines of C++ to do it right and no one

00:06:14,540 --> 00:06:21,620
should have to write more than like zero

00:06:17,380 --> 00:06:24,740
of C++ so additionally you know the the

00:06:21,620 --> 00:06:26,840
SDK essentially targets DCOs and DCOs is

00:06:24,740 --> 00:06:27,950
a very powerful system it has like you

00:06:26,840 --> 00:06:30,470
know right you can think of it as its

00:06:27,950 --> 00:06:33,979
its mais au s-- + marathon plus a bunch

00:06:30,470 --> 00:06:36,860
of really fantastic orchestration and

00:06:33,979 --> 00:06:38,570
sort of you know service discovery all

00:06:36,860 --> 00:06:39,510
these wonderful things but it also is

00:06:38,570 --> 00:06:41,310
kind of hard to leverage

00:06:39,510 --> 00:06:42,600
right like you leverage it in Marathon

00:06:41,310 --> 00:06:46,350
but like if you want to do it yourself

00:06:42,600 --> 00:06:48,330
kind of tricky and then also so like

00:06:46,350 --> 00:06:50,880
right like how can we try to solve this

00:06:48,330 --> 00:06:52,650
with like an actual platform with an SDK

00:06:50,880 --> 00:06:55,320
and Ray might say like well Cassandra is

00:06:52,650 --> 00:06:57,390
pretty different from HDFS and like it's

00:06:55,320 --> 00:06:59,880
like yeah but like if you squint at most

00:06:57,390 --> 00:07:01,470
distributed systems right if you sort of

00:06:59,880 --> 00:07:04,620
blur your vision it's like they start to

00:07:01,470 --> 00:07:06,630
look really similar right like it's it's

00:07:04,620 --> 00:07:08,550
like 90% similarity they all care about

00:07:06,630 --> 00:07:10,530
deployment they care about how do you

00:07:08,550 --> 00:07:12,630
recover when any given node type goes

00:07:10,530 --> 00:07:14,550
down they care about upgrades they need

00:07:12,630 --> 00:07:16,650
service discovery you want to have

00:07:14,550 --> 00:07:18,150
performance metrics there's all this

00:07:16,650 --> 00:07:21,720
stuff right and you can sort of see like

00:07:18,150 --> 00:07:23,370
DCOs and mezzos have the primitives of

00:07:21,720 --> 00:07:26,520
all of that right and we want to just

00:07:23,370 --> 00:07:28,710
very easily sort of provide you a clean

00:07:26,520 --> 00:07:32,880
abstraction for combining all that

00:07:28,710 --> 00:07:34,410
together so what is the SDK it is a

00:07:32,880 --> 00:07:37,080
declarative orchestration abstraction

00:07:34,410 --> 00:07:39,210
for Apache Mesa so VCOs fundamentally it

00:07:37,080 --> 00:07:42,300
is an Apache means a scheduler factory

00:07:39,210 --> 00:07:44,970
right you give it some input in the form

00:07:42,300 --> 00:07:46,620
of the amyl or a bit of Java and what do

00:07:44,970 --> 00:07:50,280
you get on the other side you basically

00:07:46,620 --> 00:07:53,580
get a jar that jar knows how to deploy

00:07:50,280 --> 00:07:55,950
your service very well all right so in

00:07:53,580 --> 00:07:57,030
terms of where does it live so if you

00:07:55,950 --> 00:07:58,470
want to look at the docs which is

00:07:57,030 --> 00:08:01,950
probably the best entry point to it

00:07:58,470 --> 00:08:04,440
there's actually a link at the bitly

00:08:01,950 --> 00:08:07,260
link the first staple and that gist so

00:08:04,440 --> 00:08:09,750
there's there are Doc's upon Doc's upon

00:08:07,260 --> 00:08:11,220
Doc's of all the features I'll probably

00:08:09,750 --> 00:08:13,650
if we have a bit of time at the end I'll

00:08:11,220 --> 00:08:16,200
sort of take us through those where you

00:08:13,650 --> 00:08:18,240
can sort of pull out the key value so

00:08:16,200 --> 00:08:19,230
what do you get if you use the sdk right

00:08:18,240 --> 00:08:21,810
because you might think like well I

00:08:19,230 --> 00:08:23,070
could just write up mazes scheduler it's

00:08:21,810 --> 00:08:24,270
pretty simple the thing I'm doing it's

00:08:23,070 --> 00:08:25,950
like yeah sure

00:08:24,270 --> 00:08:28,050
we probably right there's there's a

00:08:25,950 --> 00:08:31,170
handful of very good Apache mezzo

00:08:28,050 --> 00:08:34,440
schedulers out there in the world but

00:08:31,170 --> 00:08:36,270
like Aurora and marathon and like Apple

00:08:34,440 --> 00:08:37,830
is never gonna open-source Jarvis not

00:08:36,270 --> 00:08:39,510
well maybe Never Say Never

00:08:37,830 --> 00:08:41,550
but right like they're they're very

00:08:39,510 --> 00:08:43,380
specific and primarily like the two

00:08:41,550 --> 00:08:45,360
particularly good ones Aurora and

00:08:43,380 --> 00:08:46,740
marathon are these sort of mono

00:08:45,360 --> 00:08:49,290
schedulers right and they're they're

00:08:46,740 --> 00:08:50,880
kind of hard to customize hard to extend

00:08:49,290 --> 00:08:52,540
if you want to like I have had you look

00:08:50,880 --> 00:08:55,209
at the marathon codebase it is

00:08:52,540 --> 00:08:59,019
a good powerful piece of software but so

00:08:55,209 --> 00:09:02,070
much Scala so we've built an incredibly

00:08:59,019 --> 00:09:05,649
good default scheduler right like it is

00:09:02,070 --> 00:09:08,139
we've we've written six services on top

00:09:05,649 --> 00:09:10,899
of it that we're you know selling to

00:09:08,139 --> 00:09:12,819
folks to run their data solutions on top

00:09:10,899 --> 00:09:14,889
of right like we we've gotten very good

00:09:12,819 --> 00:09:17,410
at building staple new services with

00:09:14,889 --> 00:09:19,180
this SDK so covers you know deployment

00:09:17,410 --> 00:09:20,920
updates recovery you can do powerful

00:09:19,180 --> 00:09:22,720
custom orchestration and then

00:09:20,920 --> 00:09:23,440
additionally it does tightly coupled

00:09:22,720 --> 00:09:26,800
with DCOs

00:09:23,440 --> 00:09:28,449
in terms of security networking service

00:09:26,800 --> 00:09:29,649
discovery right like sort of

00:09:28,449 --> 00:09:32,050
fundamentally like it would more or less

00:09:29,649 --> 00:09:34,029
work out of the box on top of just raw

00:09:32,050 --> 00:09:36,610
apache mezzos except that raw apache

00:09:34,029 --> 00:09:38,350
mezzos doesn't force you to have dns

00:09:36,610 --> 00:09:40,029
right like that's sort of the

00:09:38,350 --> 00:09:42,730
fundamental thing that's missing if

00:09:40,029 --> 00:09:46,180
you've had maze of DNS or so DTS has

00:09:42,730 --> 00:09:48,730
Spartan which is the fancy the fancier

00:09:46,180 --> 00:09:51,579
DNS we've recently added additionally

00:09:48,730 --> 00:09:54,130
there is so the VCOs CLI has a sort of

00:09:51,579 --> 00:09:55,690
concept of modules so every service gets

00:09:54,130 --> 00:09:58,149
auto-generated sort of an operator

00:09:55,690 --> 00:10:00,100
module for interacting with it and then

00:09:58,149 --> 00:10:01,660
additionally that what is that doing

00:10:00,100 --> 00:10:04,829
it's basically just talking to a REST

00:10:01,660 --> 00:10:06,519
API that is served by the scheduler

00:10:04,829 --> 00:10:08,110
talked about powerful custom

00:10:06,519 --> 00:10:09,940
orchestration so there's this sort of

00:10:08,110 --> 00:10:11,980
plans logic will go into but

00:10:09,940 --> 00:10:14,319
additionally you can extend scheduler

00:10:11,980 --> 00:10:18,310
behavior very deeply by writing a bit of

00:10:14,319 --> 00:10:21,190
Java we have nice we have okay hooks for

00:10:18,310 --> 00:10:23,410
diving into the sort of actual Java that

00:10:21,190 --> 00:10:26,250
is you know interpreting the declarative

00:10:23,410 --> 00:10:28,029
API and turning it into orchestration

00:10:26,250 --> 00:10:29,050
additionally there are twelve people

00:10:28,029 --> 00:10:31,440
that work on this full-time

00:10:29,050 --> 00:10:33,760
right like we are every time like

00:10:31,440 --> 00:10:35,709
something lands and patching bezos and

00:10:33,760 --> 00:10:37,569
then as soon as like gcos can like

00:10:35,709 --> 00:10:39,189
supply it to us and then like boom we

00:10:37,569 --> 00:10:41,079
implement it right like we have a very

00:10:39,189 --> 00:10:43,750
tight relationship with apache bezos for

00:10:41,079 --> 00:10:45,160
obvious reasons work at mesosphere we

00:10:43,750 --> 00:10:47,439
want all those new features we're also

00:10:45,160 --> 00:10:49,990
pushing like a lot of the things that

00:10:47,439 --> 00:10:51,790
have come out from ASOS and 4d cos are

00:10:49,990 --> 00:10:54,550
pushed forward by the drive towards like

00:10:51,790 --> 00:10:56,110
can we do these big stateful complicated

00:10:54,550 --> 00:11:01,300
systems on top of these platforms

00:10:56,110 --> 00:11:05,800
so there's a very benefit there's a good

00:11:01,300 --> 00:11:06,430
cycle words escape me okay so what is

00:11:05,800 --> 00:11:08,740
the SDK

00:11:06,430 --> 00:11:12,250
so essentially the the SDK has three

00:11:08,740 --> 00:11:13,570
core interfaces like what the the SDK is

00:11:12,250 --> 00:11:16,930
driven towards so essentially there is

00:11:13,570 --> 00:11:18,490
two programming time interfaces the

00:11:16,930 --> 00:11:21,610
declarative API and the programmatic API

00:11:18,490 --> 00:11:24,040
declarative API is enamel / Matic API is

00:11:21,610 --> 00:11:25,990
in Java and then at runtime you have the

00:11:24,040 --> 00:11:29,470
REST API for interacting with the

00:11:25,990 --> 00:11:32,110
service so 2/3 of API what does it look

00:11:29,470 --> 00:11:35,650
like so you have a service named neat

00:11:32,110 --> 00:11:39,220
you then have pods and plants right so

00:11:35,650 --> 00:11:41,140
pods are what are you going to run plans

00:11:39,220 --> 00:11:43,450
are how are you going to run it when are

00:11:41,140 --> 00:11:48,280
you gonna run it what should it do right

00:11:43,450 --> 00:11:48,970
so pods in terms of this - I have there

00:11:48,280 --> 00:11:52,500
we go

00:11:48,970 --> 00:11:55,720
so pods right so here's some kind of

00:11:52,500 --> 00:11:58,840
fake pods that I made up but essentially

00:11:55,720 --> 00:12:01,120
a pod is a set of tasks translated into

00:11:58,840 --> 00:12:03,760
mezzos land a pod is amazing executor

00:12:01,120 --> 00:12:06,130
and a task is a maze those task group

00:12:03,760 --> 00:12:07,840
the reason for that is essentially made

00:12:06,130 --> 00:12:09,820
those task groups are atomic units

00:12:07,840 --> 00:12:11,380
everything in a task group has to fail

00:12:09,820 --> 00:12:13,210
together we don't want you to do that if

00:12:11,380 --> 00:12:15,040
we're running your database right we

00:12:13,210 --> 00:12:16,960
want like the database tasks to be

00:12:15,040 --> 00:12:18,850
separate from the maintenance tasks so

00:12:16,960 --> 00:12:22,450
that they can be turned on and off

00:12:18,850 --> 00:12:23,800
separately fail separately etc so as you

00:12:22,450 --> 00:12:25,660
can see here we basically have two

00:12:23,800 --> 00:12:27,970
different pods you can define a count

00:12:25,660 --> 00:12:30,790
there are dozens and dozens of different

00:12:27,970 --> 00:12:33,010
parameters in the amyl all documented in

00:12:30,790 --> 00:12:34,570
the documentation I linked you to but

00:12:33,010 --> 00:12:36,520
essentially you can do all the obvious

00:12:34,570 --> 00:12:38,380
basics you can define a command you can

00:12:36,520 --> 00:12:40,000
set CPUs you can set memory it's not

00:12:38,380 --> 00:12:42,730
shown here we'll see it in this tutorial

00:12:40,000 --> 00:12:44,350
you can set a docker image we don't do

00:12:42,730 --> 00:12:46,540
this standard like a lot of work space

00:12:44,350 --> 00:12:48,310
in systems they're just like docker and

00:12:46,540 --> 00:12:49,540
then they run whatever the docker thing

00:12:48,310 --> 00:12:51,520
is supposed to run we don't do that

00:12:49,540 --> 00:12:54,850
right we basically use docker as a file

00:12:51,520 --> 00:12:55,990
format to present you know bundle

00:12:54,850 --> 00:12:57,820
dependencies and then we launch

00:12:55,990 --> 00:13:00,630
everything with the universal container

00:12:57,820 --> 00:13:03,250
runtime we don't touch docker at all

00:13:00,630 --> 00:13:04,780
okay so that's the declarative API in

00:13:03,250 --> 00:13:08,610
terms of pods right so again this is

00:13:04,780 --> 00:13:12,730
like what do we want to run now plans

00:13:08,610 --> 00:13:16,600
are pretty powerful and they allow us to

00:13:12,730 --> 00:13:18,070
define both deployment so there's sort

00:13:16,600 --> 00:13:19,570
of a there is a built-in like if you

00:13:18,070 --> 00:13:21,490
define no plans

00:13:19,570 --> 00:13:24,070
what would happen if I install this like

00:13:21,490 --> 00:13:27,010
well what's gonna happen is when our

00:13:24,070 --> 00:13:28,900
scheduler parses this it just sees oh I

00:13:27,010 --> 00:13:32,170
have two things that have a goal state

00:13:28,900 --> 00:13:33,910
of running I want five of pot B and I

00:13:32,170 --> 00:13:35,910
want one of pot a it's getting like well

00:13:33,910 --> 00:13:38,590
I'm gonna see really launch one pot a

00:13:35,910 --> 00:13:40,180
but I'm only going to turn on task a one

00:13:38,590 --> 00:13:41,410
because it has a goal state of running I

00:13:40,180 --> 00:13:44,050
don't know what to do with the task

00:13:41,410 --> 00:13:45,160
that's finished and then pot B it's

00:13:44,050 --> 00:13:47,050
gonna be like well I'm gonna see really

00:13:45,160 --> 00:13:49,660
launch five of these right and it's like

00:13:47,050 --> 00:13:51,310
obviously that that is trivial that is

00:13:49,660 --> 00:13:53,800
like the naive case that that doesn't

00:13:51,310 --> 00:13:55,060
none of our services right like none of

00:13:53,800 --> 00:13:57,370
them the naive case is actually correct

00:13:55,060 --> 00:14:00,580
but it's like it's good to have a

00:13:57,370 --> 00:14:03,340
default so plans cover a number of

00:14:00,580 --> 00:14:06,190
things right so they cover deployment we

00:14:03,340 --> 00:14:08,800
also have a separate update plan we'll

00:14:06,190 --> 00:14:10,660
have in the future the ability to do

00:14:08,800 --> 00:14:12,760
relatively complex upgrade plans for

00:14:10,660 --> 00:14:15,340
things like database migrations file

00:14:12,760 --> 00:14:16,570
format conversions stuff like that and

00:14:15,340 --> 00:14:18,910
additionally you can define something

00:14:16,570 --> 00:14:21,580
called sidecar plans so sidecars are

00:14:18,910 --> 00:14:24,220
essentially auxilary tasks within a pod

00:14:21,580 --> 00:14:26,140
right so if we look back here tasks a

00:14:24,220 --> 00:14:27,490
two will be considered a sidecar right

00:14:26,140 --> 00:14:29,890
like it has this goal state of finished

00:14:27,490 --> 00:14:31,060
right well not necessarily a sidecar but

00:14:29,890 --> 00:14:32,470
it has a goal state of finished race

00:14:31,060 --> 00:14:34,500
there's two possible goal states there's

00:14:32,470 --> 00:14:37,570
running and finished running means

00:14:34,500 --> 00:14:40,960
always make sure I am on if I fail bring

00:14:37,570 --> 00:14:44,200
me back finished means keep trying until

00:14:40,960 --> 00:14:46,630
I succeed and then stop do not bring me

00:14:44,200 --> 00:14:49,990
back right now there's a series of

00:14:46,630 --> 00:14:51,370
different interactions you can do some

00:14:49,990 --> 00:14:53,080
cool stuff like obviously you can have a

00:14:51,370 --> 00:14:55,060
bootstrapping task a great example is if

00:14:53,080 --> 00:14:57,640
you look at our HDFS framework we

00:14:55,060 --> 00:14:59,710
basically do some we like format the

00:14:57,640 --> 00:15:02,410
name nodes those are essentially tasks

00:14:59,710 --> 00:15:03,730
with a finished goal state then after

00:15:02,410 --> 00:15:06,010
that we actually start the name node

00:15:03,730 --> 00:15:07,870
server right additionally you can do

00:15:06,010 --> 00:15:10,270
sidecars where you might define a plan

00:15:07,870 --> 00:15:11,770
where an operator is gonna run it a

00:15:10,270 --> 00:15:13,090
grady's we're gonna go over one today

00:15:11,770 --> 00:15:14,860
we're basically gonna we're gonna do

00:15:13,090 --> 00:15:16,330
memcache as I said one of the things

00:15:14,860 --> 00:15:18,790
we're gonna do is define a sidecar that

00:15:16,330 --> 00:15:20,830
flushes the cache right so you can even

00:15:18,790 --> 00:15:22,420
tell memcache individual instances like

00:15:20,830 --> 00:15:24,820
hey flush your cache we're gonna define

00:15:22,420 --> 00:15:26,710
a sidecar that is allows an operator say

00:15:24,820 --> 00:15:28,840
hey flush the entire cache of everything

00:15:26,710 --> 00:15:30,250
it'll just either serially or in

00:15:28,840 --> 00:15:32,500
parallel go through and flush the cache

00:15:30,250 --> 00:15:33,480
for everything so plans are basically

00:15:32,500 --> 00:15:36,480
built up of so

00:15:33,480 --> 00:15:38,399
here deploy is the plan it has an

00:15:36,480 --> 00:15:40,529
overall strategy of serial which I see

00:15:38,399 --> 00:15:43,740
means for all of my phases go through

00:15:40,529 --> 00:15:45,540
them see really within a phase so here

00:15:43,740 --> 00:15:47,910
we have pod a phase you can also again

00:15:45,540 --> 00:15:50,760
have a strategy a phase operates against

00:15:47,910 --> 00:15:52,560
a pod a step but you don't actually see

00:15:50,760 --> 00:15:55,110
any here but you'll see them later a

00:15:52,560 --> 00:15:57,170
step is essentially what should happen

00:15:55,110 --> 00:15:59,430
for an individual pod instance right

00:15:57,170 --> 00:16:01,920
excuse me so you can have you know

00:15:59,430 --> 00:16:03,269
different configurations of this sort of

00:16:01,920 --> 00:16:04,260
thing if you look at our elastic

00:16:03,269 --> 00:16:06,089
framework is actually a really good

00:16:04,260 --> 00:16:08,430
example of different deploy and update

00:16:06,089 --> 00:16:11,699
plans for deployment elastic doesn't

00:16:08,430 --> 00:16:14,850
care just like throw all the nodes out

00:16:11,699 --> 00:16:16,529
there right and then for update you do

00:16:14,850 --> 00:16:18,540
care for all sorts of reasons

00:16:16,529 --> 00:16:19,949
availability things like that so then it

00:16:18,540 --> 00:16:21,720
has a separate update plan that is much

00:16:19,949 --> 00:16:26,040
more careful about sequencing of how

00:16:21,720 --> 00:16:28,709
it's rolling out new binaries all right

00:16:26,040 --> 00:16:29,940
programmatic API I'm not really gonna

00:16:28,709 --> 00:16:31,490
show you an example is if we have time

00:16:29,940 --> 00:16:34,410
at the end I'll go over a couple

00:16:31,490 --> 00:16:36,029
basically if you look at anything but

00:16:34,410 --> 00:16:37,170
elastic they all have custom recovery

00:16:36,029 --> 00:16:38,459
I'll show you I'll at least show you

00:16:37,170 --> 00:16:40,800
where to look so you can look at the

00:16:38,459 --> 00:16:42,329
examples so essentially the scheduler

00:16:40,800 --> 00:16:44,279
can be extended by writing Java to add

00:16:42,329 --> 00:16:47,100
custom recovery so that's things a great

00:16:44,279 --> 00:16:49,410
example is Cassandra Cassandra when you

00:16:47,100 --> 00:16:51,360
replace a node you need to somehow

00:16:49,410 --> 00:16:54,060
communicate to the ring this node is

00:16:51,360 --> 00:16:55,560
going away right because with and by so

00:16:54,060 --> 00:16:57,769
there's a distinction between restarting

00:16:55,560 --> 00:17:01,589
and replacing restarting a node means

00:16:57,769 --> 00:17:03,300
cycle it in place replace means throw it

00:17:01,589 --> 00:17:04,530
away unreserve the resources find

00:17:03,300 --> 00:17:08,400
somewhere new to put it right like

00:17:04,530 --> 00:17:10,589
replace is the rack broke or we're

00:17:08,400 --> 00:17:13,290
taking that rack away so all of those

00:17:10,589 --> 00:17:15,390
instances need to go away so replace you

00:17:13,290 --> 00:17:16,890
have to do a little bit of custom logic

00:17:15,390 --> 00:17:19,140
to check that like oh this is a

00:17:16,890 --> 00:17:22,350
permanent replacement okay I need to go

00:17:19,140 --> 00:17:26,760
and tell the ring hey this one's going

00:17:22,350 --> 00:17:28,260
away yeah and then additionally a good

00:17:26,760 --> 00:17:31,520
example of this is our own agile B

00:17:28,260 --> 00:17:33,330
framework they have to sort of

00:17:31,520 --> 00:17:35,220
oftentimes the things you will do in

00:17:33,330 --> 00:17:36,990
Java you're essentially either hacking

00:17:35,220 --> 00:17:38,669
around the fact that word that that the

00:17:36,990 --> 00:17:40,980
SDK does not plan to support something

00:17:38,669 --> 00:17:42,480
or it's like in our future right it

00:17:40,980 --> 00:17:44,040
might be like I need to iterate over a

00:17:42,480 --> 00:17:46,110
list and it's like neat you can write

00:17:44,040 --> 00:17:47,070
some Java to do that so essentially the

00:17:46,110 --> 00:17:48,900
service pack

00:17:47,070 --> 00:17:51,330
is the in Java representation of the

00:17:48,900 --> 00:17:53,310
yeah Mille and you can then you know

00:17:51,330 --> 00:17:56,430
take that service back and you might

00:17:53,310 --> 00:17:57,690
have an N var that is a big list and

00:17:56,430 --> 00:17:59,370
you're like great I actually need an ad

00:17:57,690 --> 00:18:04,170
a port for every single one of those

00:17:59,370 --> 00:18:05,250
things things like that the rest api at

00:18:04,170 --> 00:18:07,200
endpoints you actually really care about

00:18:05,250 --> 00:18:08,790
so endpoints which is all about telling

00:18:07,200 --> 00:18:09,840
you how to connect your services we'll

00:18:08,790 --> 00:18:12,330
see an example of that

00:18:09,840 --> 00:18:14,430
memcache right like neat I deployed a

00:18:12,330 --> 00:18:16,920
service but I actually really care about

00:18:14,430 --> 00:18:19,320
talking to it the endpoints API is all

00:18:16,920 --> 00:18:21,270
about revealing to you the user how do I

00:18:19,320 --> 00:18:22,950
actually talk to it right you can you

00:18:21,270 --> 00:18:24,510
can very carefully curate like what does

00:18:22,950 --> 00:18:26,790
and doesn't get revealed it's not sort

00:18:24,510 --> 00:18:29,490
of just a barf of like here's every port

00:18:26,790 --> 00:18:32,130
an IP address this has ever used plans

00:18:29,490 --> 00:18:33,600
so plans are all about receiving

00:18:32,130 --> 00:18:36,210
information about the individual plans

00:18:33,600 --> 00:18:38,340
deploy recovery deploy recovery other to

00:18:36,210 --> 00:18:41,610
built-ins deploy is how does it bring

00:18:38,340 --> 00:18:44,250
stuff up recovery is is a reactive plan

00:18:41,610 --> 00:18:46,320
that's basically looking for failed or

00:18:44,250 --> 00:18:49,500
yeah based are looking for failed tasks

00:18:46,320 --> 00:18:51,180
and then any cycler plans you can also

00:18:49,500 --> 00:18:54,540
perform offer like a number of different

00:18:51,180 --> 00:18:56,760
operations on any given plan and pod is

00:18:54,540 --> 00:18:58,710
just a way to look at pod and task state

00:18:56,760 --> 00:19:00,330
you can also perform operations on the

00:18:58,710 --> 00:19:00,690
pod so I alluded to you can restart a

00:19:00,330 --> 00:19:02,670
pod

00:19:00,690 --> 00:19:04,650
it basically means restart it in place

00:19:02,670 --> 00:19:07,110
bring up any tasks it should be running

00:19:04,650 --> 00:19:09,750
according to the current plans and then

00:19:07,110 --> 00:19:12,060
there is replace which is throw it all

00:19:09,750 --> 00:19:15,000
away unreserve the resources destroy the

00:19:12,060 --> 00:19:19,080
data and move it somewhere else you

00:19:15,000 --> 00:19:20,400
shouldn't do replace ever or often at

00:19:19,080 --> 00:19:21,660
least there are cases where you might

00:19:20,400 --> 00:19:23,220
want to do a replace you should test

00:19:21,660 --> 00:19:25,350
replace when you write a framework like

00:19:23,220 --> 00:19:27,060
full you really should test it it is a

00:19:25,350 --> 00:19:31,260
great test of is my recovery actually

00:19:27,060 --> 00:19:33,210
good okay so how do I seek a services

00:19:31,260 --> 00:19:35,780
like actually run and VCOs right like

00:19:33,210 --> 00:19:38,670
what is what is the true output of the

00:19:35,780 --> 00:19:43,170
SDK so fundamentally what you care about

00:19:38,670 --> 00:19:46,980
is unibit install it right so the the

00:19:43,170 --> 00:19:50,790
true output of the SDK like a truly

00:19:46,980 --> 00:19:52,830
fully compiled output is a DCOs package

00:19:50,790 --> 00:19:55,290
so what is the VCOs package these 2's

00:19:52,830 --> 00:19:57,780
package is a set of instructions which

00:19:55,290 --> 00:20:00,300
are basically some package metadata some

00:19:57,780 --> 00:20:00,960
resources that that package will utilize

00:20:00,300 --> 00:20:03,929
like

00:20:00,960 --> 00:20:06,360
they say you are eyes and an options

00:20:03,929 --> 00:20:08,130
file that essentially defines all the

00:20:06,360 --> 00:20:11,730
parameters of the service and a

00:20:08,130 --> 00:20:14,100
templated marathon app cosmos is the

00:20:11,730 --> 00:20:15,990
package manager for DC OS so cosmos

00:20:14,100 --> 00:20:19,200
knows how to translate those first three

00:20:15,990 --> 00:20:22,559
files and that marathon app definition

00:20:19,200 --> 00:20:24,630
into a launched marathon app right so

00:20:22,559 --> 00:20:29,490
fundamentally what we spit out is a jar

00:20:24,630 --> 00:20:31,890
and a package definition that when we

00:20:29,490 --> 00:20:33,570
hand that to cosmos it ultimately

00:20:31,890 --> 00:20:36,690
launches a single instance of the

00:20:33,570 --> 00:20:38,250
scheduler as a marathon app so which is

00:20:36,690 --> 00:20:40,740
great marathon will make sure the

00:20:38,250 --> 00:20:43,440
scheduler sticks around we operate under

00:20:40,740 --> 00:20:45,740
a concept we don't need the scheduler to

00:20:43,440 --> 00:20:48,720
be like hae or anything cuz it's like

00:20:45,740 --> 00:20:50,340
you know your tasks live if the

00:20:48,720 --> 00:20:52,559
scheduler is dead for a tiny little bit

00:20:50,340 --> 00:20:54,450
marathon will always bring it back in

00:20:52,559 --> 00:20:55,770
terms of configuration updates and

00:20:54,450 --> 00:20:58,200
things like that what it means is

00:20:55,770 --> 00:21:00,450
ultimately marathon is killing the

00:20:58,200 --> 00:21:02,549
scheduler and bringing it back up with a

00:21:00,450 --> 00:21:04,350
new configuration whenever you do any

00:21:02,549 --> 00:21:06,270
sort of configuration update upgrades

00:21:04,350 --> 00:21:08,220
are basically just configuration updates

00:21:06,270 --> 00:21:09,740
that change binaries so it's the same

00:21:08,220 --> 00:21:12,809
deal you know you're doing a package

00:21:09,740 --> 00:21:14,789
update and you're ultimately just

00:21:12,809 --> 00:21:17,460
restarting the marathon app with a new

00:21:14,789 --> 00:21:19,020
configuration it's gonna see oh this URI

00:21:17,460 --> 00:21:21,210
changed and it's gonna go and download

00:21:19,020 --> 00:21:24,000
it so certainly we're that mean right so

00:21:21,210 --> 00:21:26,820
cosmos the user issue is DC u.s. package

00:21:24,000 --> 00:21:28,770
install cosmos sees that it renders and

00:21:26,820 --> 00:21:30,480
launches the marathon app marathon

00:21:28,770 --> 00:21:32,669
receives that request it launches a

00:21:30,480 --> 00:21:34,620
single scheduler instance the service

00:21:32,669 --> 00:21:38,010
scheduler then comes up registers with

00:21:34,620 --> 00:21:42,240
mezzos as a framework and then it starts

00:21:38,010 --> 00:21:43,950
to receive offers and put tasks out so

00:21:42,240 --> 00:21:46,020
you can see in my terrible topology

00:21:43,950 --> 00:21:47,370
diagram that essentially that means you

00:21:46,020 --> 00:21:50,429
have the masters off to one side the

00:21:47,370 --> 00:21:52,740
scheduler is coexisting with its tasks

00:21:50,429 --> 00:21:54,360
and it's pods each of those pods is a

00:21:52,740 --> 00:21:59,059
little executor that's running some

00:21:54,360 --> 00:22:01,260
number of tasks okay anybody have like

00:21:59,059 --> 00:22:07,020
three minutes of questions anybody have

00:22:01,260 --> 00:22:13,020
questions no all right neat

00:22:07,020 --> 00:22:16,230
okay a note polyglots the sdk is complex

00:22:13,020 --> 00:22:19,170
it contains go for the CLI and our task

00:22:16,230 --> 00:22:22,679
bootstrap Java for the course scheduler

00:22:19,170 --> 00:22:24,720
about 55 thousand lines of it Python 3

00:22:22,679 --> 00:22:28,410
for testing there's some bash in there

00:22:24,720 --> 00:22:30,660
so what that means is we're all very sad

00:22:28,410 --> 00:22:32,309
about it but the good news is we

00:22:30,660 --> 00:22:33,960
recently added a docker container so you

00:22:32,309 --> 00:22:35,940
have all of that bundled together that

00:22:33,960 --> 00:22:38,730
is supposed to be the docker container

00:22:35,940 --> 00:22:39,870
you are all pulling already so what are

00:22:38,730 --> 00:22:41,760
we going to do to get set up we're

00:22:39,870 --> 00:22:44,250
basically gonna download a template so I

00:22:41,760 --> 00:22:46,110
have gone through the labor of making it

00:22:44,250 --> 00:22:47,760
so we have a nice little github

00:22:46,110 --> 00:22:49,679
repository where all we're gonna need to

00:22:47,760 --> 00:22:51,660
do is touch Gamel like we were we are

00:22:49,679 --> 00:22:53,370
not gonna touch the Java well take a

00:22:51,660 --> 00:22:55,650
peek at it we're not gonna have to go

00:22:53,370 --> 00:22:56,880
through the setup of like bootstrapping

00:22:55,650 --> 00:22:58,440
the whole configuration and all that

00:22:56,880 --> 00:23:02,040
stuff we're just gonna touch the amyl

00:22:58,440 --> 00:23:03,270
it'll speed things along nicely we're

00:23:02,040 --> 00:23:05,700
gonna do everything inside the docker

00:23:03,270 --> 00:23:08,880
container I'm going to show you some AWS

00:23:05,700 --> 00:23:11,580
credentials that are very temporary and

00:23:08,880 --> 00:23:13,740
will disappear after this and then we'll

00:23:11,580 --> 00:23:15,030
do a DC West CLI setup and I forgot to

00:23:13,740 --> 00:23:18,090
take it off but we're not actually gonna

00:23:15,030 --> 00:23:20,970
use the private key so neat this is all

00:23:18,090 --> 00:23:23,000
on the gist that I had you grab so

00:23:20,970 --> 00:23:25,650
basically you just want to do get clone

00:23:23,000 --> 00:23:26,550
of this then we're gonna change into

00:23:25,650 --> 00:23:34,410
that directory

00:23:26,550 --> 00:23:38,850
oh yeah I have my github set up a little

00:23:34,410 --> 00:23:43,400
weird does that make sense to people you

00:23:38,850 --> 00:23:43,400
can also switch it to here I'll show the

00:23:46,500 --> 00:23:55,480
also true this is going to be a great

00:23:49,510 --> 00:23:58,440
test of our conference Wi-Fi I'll throw

00:23:55,480 --> 00:23:58,440
the other one in here as well

00:24:11,630 --> 00:24:18,500
okay everybody good got the file did we

00:24:16,429 --> 00:24:19,760
change into the directory if you didn't

00:24:18,500 --> 00:24:25,940
change to the directory changes in the

00:24:19,760 --> 00:24:28,520
directory neat all right

00:24:25,940 --> 00:24:29,990
so into the docker container I mean you

00:24:28,520 --> 00:24:32,840
can even change the working directory

00:24:29,990 --> 00:24:35,240
and where I mounted it feel free but

00:24:32,840 --> 00:24:37,940
this command will get you in there with

00:24:35,240 --> 00:24:45,169
all the right things it was also in the

00:24:37,940 --> 00:24:52,549
gist that is the default of the repo

00:24:45,169 --> 00:24:53,750
yeah the animal thought yeah the mo file

00:24:52,549 --> 00:24:57,700
is already there we're basically just

00:24:53,750 --> 00:24:57,700
gonna hit build once we're all set up

00:24:57,760 --> 00:25:05,059
all right everybody in the docker

00:25:00,049 --> 00:25:11,210
container that wants to be oh it's still

00:25:05,059 --> 00:25:12,740
downloading all right neat all right

00:25:11,210 --> 00:25:15,470
well yeah right

00:25:12,740 --> 00:25:17,840
neat I was pretty sure this would happen

00:25:15,470 --> 00:25:21,500
I'm very glad we had not optimized that

00:25:17,840 --> 00:25:24,530
for size yet all right so let's just

00:25:21,500 --> 00:25:26,809
start going over it and if you can sort

00:25:24,530 --> 00:25:28,250
of just like I don't know we'll check in

00:25:26,809 --> 00:25:29,990
in ten minutes on how we're doing on the

00:25:28,250 --> 00:25:31,130
docker image who does not raise your

00:25:29,990 --> 00:25:34,340
hand if you want to have the docker

00:25:31,130 --> 00:25:35,570
image and you do not have it yet okay

00:25:34,340 --> 00:25:37,940
we're like 50 percent

00:25:35,570 --> 00:25:40,299
all right neat neat if you have a phone

00:25:37,940 --> 00:25:41,600
you can tether with it might be faster

00:25:40,299 --> 00:25:45,470
yeah

00:25:41,600 --> 00:25:46,820
all right love conference Wi-Fi if I was

00:25:45,470 --> 00:25:48,950
better at my job I would have told you

00:25:46,820 --> 00:25:52,850
all to download this sooner

00:25:48,950 --> 00:25:55,480
okay thanks cool your bad it emoji so

00:25:52,850 --> 00:25:58,190
let's talk about what we're gonna see so

00:25:55,480 --> 00:26:04,549
actually here I have so much time to

00:25:58,190 --> 00:26:07,580
kill I'm just gonna do it like this okay

00:26:04,549 --> 00:26:10,510
so this is the template essentially if

00:26:07,580 --> 00:26:13,070
you said build SH this would build and

00:26:10,510 --> 00:26:14,990
output what we call a stub universe so

00:26:13,070 --> 00:26:16,730
universe is the sort of package

00:26:14,990 --> 00:26:18,770
repository there are a couple different

00:26:16,730 --> 00:26:21,320
ways to generate one a stub universe is

00:26:18,770 --> 00:26:24,570
basically a JSON file that you can add

00:26:21,320 --> 00:26:27,750
to your cluster as a repository and

00:26:24,570 --> 00:26:30,919
and install from there so let's take a

00:26:27,750 --> 00:26:33,990
quick peek due to the wonders of Java

00:26:30,919 --> 00:26:36,870
what we end up with is very deeply

00:26:33,990 --> 00:26:39,000
nested our service tamil so as you can

00:26:36,870 --> 00:26:40,200
see I'm calling it memcache already

00:26:39,000 --> 00:26:42,240
because that's where we're headed and

00:26:40,200 --> 00:26:44,070
feel like changing it later

00:26:42,240 --> 00:26:45,659
I'm sitting here the scheduler it's

00:26:44,070 --> 00:26:48,330
gonna run everything as the user nobody

00:26:45,659 --> 00:26:52,289
and I'm basically just saying meet let's

00:26:48,330 --> 00:26:54,210
have a pod that says hello to us right

00:26:52,289 --> 00:26:56,909
so we viously have here's our pod hello

00:26:54,210 --> 00:26:58,889
it has a single task called server its

00:26:56,909 --> 00:27:01,409
goal state is running it's command is

00:26:58,889 --> 00:27:05,789
echo hello world it's going to use 0.1

00:27:01,409 --> 00:27:08,279
CPUs and 256 Meg's of RAM and it's

00:27:05,789 --> 00:27:10,259
basically the outcome of this is a task

00:27:08,279 --> 00:27:11,970
that is just gonna loop constantly right

00:27:10,259 --> 00:27:13,620
because it's gonna keep finishing it's

00:27:11,970 --> 00:27:15,659
gonna exit cleanly and then our

00:27:13,620 --> 00:27:21,080
scheduler is gonna identify no that is

00:27:15,659 --> 00:27:21,080
bad I want I want to keep you alive so I

00:27:21,409 --> 00:27:24,710
pop open

00:27:40,490 --> 00:27:43,490
okay

00:27:49,930 --> 00:27:59,470
and unlike you suckers I already have

00:27:55,960 --> 00:28:03,400
the docker container all right so now

00:27:59,470 --> 00:28:06,280
I'm in here and as you may have noticed

00:28:03,400 --> 00:28:10,150
we have this delightful thing where I

00:28:06,280 --> 00:28:12,130
just give you some AWS credentials so

00:28:10,150 --> 00:28:13,270
I'm kind of just gonna go ahead if if

00:28:12,130 --> 00:28:15,010
you already have the docker container

00:28:13,270 --> 00:28:16,810
follow along I think if you don't

00:28:15,010 --> 00:28:18,370
already have it by the time you get it

00:28:16,810 --> 00:28:19,900
you should be able to jump ahead we're

00:28:18,370 --> 00:28:21,040
gonna slow down as soon as we start like

00:28:19,900 --> 00:28:22,180
actually interacting with the cluster

00:28:21,040 --> 00:28:23,440
actually we're gonna to do the whole

00:28:22,180 --> 00:28:29,910
cluster provisioning thing so it should

00:28:23,440 --> 00:28:29,910
get to that anyways so you

00:28:42,990 --> 00:28:52,260
all right now for the fun part so I have

00:28:48,779 --> 00:28:55,200
my own cluster so all of these clusters

00:28:52,260 --> 00:29:03,830
are DC u.s. 1/10 or the enterprise are

00:28:55,200 --> 00:29:03,830
open jÃ¶rg oh yes yes

00:29:12,410 --> 00:29:26,490
okay so if we pop over here

00:29:16,799 --> 00:29:30,140
I lost the just so York has very kindly

00:29:26,490 --> 00:29:41,940
spun up lots and lots of clusters for us

00:29:30,140 --> 00:29:44,070
so all right we're gonna whoo so many so

00:29:41,940 --> 00:29:45,360
as I said I think do we have enough for

00:29:44,070 --> 00:29:48,570
everybody to have one are we doing Paris

00:29:45,360 --> 00:29:51,400
still Paris okay so I'm gonna point at

00:29:48,570 --> 00:29:52,669
people and tell you which one you are

00:29:51,400 --> 00:29:55,410
[Music]

00:29:52,669 --> 00:29:57,840
see how this goes

00:29:55,410 --> 00:30:09,320
can you give me edit on this jÃ¶rg so I

00:29:57,840 --> 00:30:09,320
can yeah let's just do that okay

00:30:11,920 --> 00:30:17,290
all right so momentarily we will all be

00:30:13,930 --> 00:30:19,540
able to edit this and then you will it

00:30:17,290 --> 00:30:21,190
will engage in a very fun distributed

00:30:19,540 --> 00:30:22,660
systems problem which is a bunch of

00:30:21,190 --> 00:30:24,880
human beings all trying to pick the same

00:30:22,660 --> 00:30:28,810
thing at the same time there we go

00:30:24,880 --> 00:30:30,280
alright so basically find a buddy and go

00:30:28,810 --> 00:30:31,840
ahead and grab a cluster just write your

00:30:30,280 --> 00:30:35,650
name down that you have taken it and

00:30:31,840 --> 00:30:37,480
once you got that look at me like stare

00:30:35,650 --> 00:30:41,010
at me so I know that you're done

00:30:37,480 --> 00:30:41,010
or raise your hand or something

00:30:51,980 --> 00:30:55,020
yeah everybody said I'm edit you might

00:30:53,970 --> 00:30:58,140
have to reload

00:30:55,020 --> 00:30:58,140
[Music]

00:31:14,230 --> 00:31:18,150
all right so once you have your cluster

00:31:18,419 --> 00:31:24,040
the command you want to run is DCOs

00:31:21,340 --> 00:31:26,770
cluster setup space and then your

00:31:24,040 --> 00:31:31,929
cluster URL it's not going to prompt you

00:31:26,770 --> 00:31:33,940
for a user the user is bootstrap user

00:31:31,929 --> 00:31:34,450
well first it's gonna ask you yes or no

00:31:33,940 --> 00:31:36,520
question

00:31:34,450 --> 00:31:38,679
you should blindly say yes you're

00:31:36,520 --> 00:31:42,160
actually technically agreeing to a UI

00:31:38,679 --> 00:31:48,660
let no it's just an ssh thing so user is

00:31:42,160 --> 00:31:52,360
bootstrap user and password is delete me

00:31:48,660 --> 00:31:53,650
it's just a default user that you get

00:31:52,360 --> 00:31:59,470
when you first install these us

00:31:53,650 --> 00:32:03,400
enterprise all right does anybody still

00:31:59,470 --> 00:32:05,740
not have the docker image impressive

00:32:03,400 --> 00:32:09,450
same exact people all right we're making

00:32:05,740 --> 00:32:09,450
great progress with the Internet

00:32:16,030 --> 00:32:19,630
okay so

00:32:26,160 --> 00:32:36,990
hello world alright so we all want to

00:32:29,580 --> 00:32:39,440
find in our favorite text editor the

00:32:36,990 --> 00:32:39,440
animal file

00:32:44,000 --> 00:32:48,680
so you can see here it's very simple it

00:32:47,150 --> 00:32:50,480
is basically just going to loop and say

00:32:48,680 --> 00:32:51,830
hello world so the first thing we're

00:32:50,480 --> 00:32:53,930
gonna do once we have everything set up

00:32:51,830 --> 00:32:55,490
you get your cluster you're gonna type

00:32:53,930 --> 00:32:57,500
in build that assay it

00:32:55,490 --> 00:32:59,120
your say AWS basically it's going to

00:32:57,500 --> 00:33:02,030
build its and I'm going to uh played

00:32:59,120 --> 00:33:06,380
upload the build assets plus the stub

00:33:02,030 --> 00:33:08,660
universe to a s3 bucket this is also

00:33:06,380 --> 00:33:17,480
going to take a while so this is a great

00:33:08,660 --> 00:33:32,350
time if people have questions is it what

00:33:17,480 --> 00:33:32,350
was the error was the error interesting

00:33:41,370 --> 00:33:50,919
yeah there should be a there should be

00:33:46,299 --> 00:33:55,809
very clear either access tonight or yeah

00:33:50,919 --> 00:33:59,700
oh okay we'll see how this it should

00:33:55,809 --> 00:33:59,700
work fine yes sir

00:34:14,440 --> 00:34:17,440
okay

00:34:52,909 --> 00:34:59,720
right yeah yeah yeah so the question is

00:34:56,480 --> 00:35:01,730
is basically can you use it for things

00:34:59,720 --> 00:35:04,430
like jobs right like can you use it for

00:35:01,730 --> 00:35:05,930
jobs to where you scale out and then you

00:35:04,430 --> 00:35:10,309
finish and you want it all to go away

00:35:05,930 --> 00:35:12,259
right yeah so we're gonna someone's

00:35:10,309 --> 00:35:13,750
doing that right now on the team right

00:35:12,259 --> 00:35:17,599
like we're working on that for spark

00:35:13,750 --> 00:35:19,220
essentially so it it's a very common

00:35:17,599 --> 00:35:21,380
right like and that also sort of speaks

00:35:19,220 --> 00:35:23,960
to a general thing you see like the edge

00:35:21,380 --> 00:35:25,279
will be that we've released there's sort

00:35:23,960 --> 00:35:27,950
of this concept of like a meta scheduler

00:35:25,279 --> 00:35:29,599
where like you want to deploy these

00:35:27,950 --> 00:35:31,009
things right I mean that's what spark is

00:35:29,599 --> 00:35:33,230
like the spark dispatcher is a meta

00:35:31,009 --> 00:35:36,109
scheduler that deploys spark jobs that

00:35:33,230 --> 00:35:38,089
are themselves schedulers and we're

00:35:36,109 --> 00:35:39,859
working towards start having sufficient

00:35:38,089 --> 00:35:41,630
support for doing that sort of thing of

00:35:39,859 --> 00:35:50,829
like go and do this and then finish and

00:35:41,630 --> 00:35:50,829
then go go away kind of thing yes sir

00:35:58,990 --> 00:36:05,320
right Marathon is focused yeah sorry

00:36:03,520 --> 00:36:07,300
the question is in comparison to

00:36:05,320 --> 00:36:10,720
Marathon what is the benefit of using

00:36:07,300 --> 00:36:13,540
the SDK so with marathon marathon is

00:36:10,720 --> 00:36:15,490
quite good at stateless scheduling it

00:36:13,540 --> 00:36:18,750
has some amount of support for

00:36:15,490 --> 00:36:20,850
persistence but not a ton and

00:36:18,750 --> 00:36:24,280
additionally it doesn't have

00:36:20,850 --> 00:36:27,280
particularly complex orchestration right

00:36:24,280 --> 00:36:31,420
so like if you sort of think about it

00:36:27,280 --> 00:36:32,920
like a marathon app is as far as I know

00:36:31,420 --> 00:36:34,990
you basically can get like a single

00:36:32,920 --> 00:36:37,780
image right like a marathon app would be

00:36:34,990 --> 00:36:40,480
like a single pod type right so if you

00:36:37,780 --> 00:36:41,950
wanted to sort of copy what the SDK does

00:36:40,480 --> 00:36:44,140
you would need to launch a bunch of

00:36:41,950 --> 00:36:45,760
marathon apps right so that's sort of

00:36:44,140 --> 00:36:48,370
one let the orchestration is quite

00:36:45,760 --> 00:36:52,510
simple our support for persistent

00:36:48,370 --> 00:36:56,560
resources is good amount stronger also

00:36:52,510 --> 00:36:59,440
additionally so when we make when we

00:36:56,560 --> 00:37:01,630
place tasks right when we deploy pods we

00:36:59,440 --> 00:37:03,520
do full reservation of everything right

00:37:01,630 --> 00:37:05,740
which means that we can always restart

00:37:03,520 --> 00:37:09,730
again and again in the same spot and

00:37:05,740 --> 00:37:10,600
never have to compete with other users

00:37:09,730 --> 00:37:12,250
of the cluster

00:37:10,600 --> 00:37:14,670
whereas marathon doesn't have those

00:37:12,250 --> 00:37:14,670
guarantees

00:37:30,760 --> 00:37:39,640
could be that the AWS yeah could be that

00:37:37,720 --> 00:37:41,020
the AWS nuclear credentials when you put

00:37:39,640 --> 00:37:46,290
them on the internet accidentally hammer

00:37:41,020 --> 00:37:52,930
has gotten a lot faster but we shall see

00:37:46,290 --> 00:37:54,220
cradle is very large okay so let's let's

00:37:52,930 --> 00:38:17,980
just sort of go through the presentation

00:37:54,220 --> 00:38:20,800
we can always see you're saying so the

00:38:17,980 --> 00:38:22,720
sort of question is his association with

00:38:20,800 --> 00:38:24,280
staple will be things like R x-ray for

00:38:22,720 --> 00:38:26,440
the and I guess you started specifically

00:38:24,280 --> 00:38:33,430
saying the ability to like move between

00:38:26,440 --> 00:38:36,340
hosts yeah so so our view would be so in

00:38:33,430 --> 00:38:38,400
terms of state so we don't actually

00:38:36,340 --> 00:38:42,030
support external storage providers yet

00:38:38,400 --> 00:38:47,020
but when we do support a persistent like

00:38:42,030 --> 00:38:48,730
yeah well the SDK does not I do you see

00:38:47,020 --> 00:38:51,280
wasn't Maysles do the SDK doesn't right

00:38:48,730 --> 00:38:53,980
so we focus on host mount and persistent

00:38:51,280 --> 00:38:55,510
volumes the Amazo s-- we're stateful

00:38:53,980 --> 00:38:57,280
like there are many reasons you want

00:38:55,510 --> 00:38:59,560
your tasks to keep the landing in the

00:38:57,280 --> 00:39:01,240
same spot right in terms of like you

00:38:59,560 --> 00:39:02,800
might have pinned it to very specific

00:39:01,240 --> 00:39:05,110
hosts that you want things to land on

00:39:02,800 --> 00:39:07,450
because they have fat drives for

00:39:05,110 --> 00:39:09,280
Cassandra that kind of thing

00:39:07,450 --> 00:39:11,560
many of the network attached storage

00:39:09,280 --> 00:39:13,720
choices might not have the performance

00:39:11,560 --> 00:39:15,490
that you want for a data service so in

00:39:13,720 --> 00:39:19,330
terms of stateful it's it's very much a

00:39:15,490 --> 00:39:21,370
like tasks don't get to just move like

00:39:19,330 --> 00:39:22,900
flit around a cluster right and there's

00:39:21,370 --> 00:39:24,010
a lot of different things over that

00:39:22,900 --> 00:39:25,930
would be true like memcache is not a

00:39:24,010 --> 00:39:27,400
great example for this tutorial because

00:39:25,930 --> 00:39:29,830
it's very quick to sort of throw

00:39:27,400 --> 00:39:31,480
together but in this sort of Cassandra

00:39:29,830 --> 00:39:32,860
is in HDFS is in the world right like

00:39:31,480 --> 00:39:37,030
you very much want things to keep

00:39:32,860 --> 00:39:38,520
landing in exactly the same spot ok so

00:39:37,030 --> 00:39:47,280
hello world

00:39:38,520 --> 00:39:50,079
in there either bring the host back or

00:39:47,280 --> 00:39:51,670
you would replace the pods that are

00:39:50,079 --> 00:39:55,329
sitting on that host and they will get

00:39:51,670 --> 00:39:57,460
moved to a different host no user

00:39:55,329 --> 00:39:58,270
intervention we do not touch data

00:39:57,460 --> 00:40:00,280
destructively

00:39:58,270 --> 00:40:11,260
unless someone says touch this data

00:40:00,280 --> 00:40:12,880
destructively yeah I mean so they would

00:40:11,260 --> 00:40:14,349
just be monitoring right like they'll be

00:40:12,880 --> 00:40:16,000
monitoring Cassandra and through that

00:40:14,349 --> 00:40:17,890
they would see like oh that node went

00:40:16,000 --> 00:40:19,359
away and then they would be able to go

00:40:17,890 --> 00:40:22,000
and reschedule it somewhere else

00:40:19,359 --> 00:40:24,280
okay so hello world a very simple

00:40:22,000 --> 00:40:26,020
example so what is sort of the

00:40:24,280 --> 00:40:28,859
development cycle look like with the SDK

00:40:26,020 --> 00:40:31,299
essentially we build then we install

00:40:28,859 --> 00:40:34,660
then we test whatever we wanted to test

00:40:31,299 --> 00:40:37,510
then we do an uninstall in this case oh

00:40:34,660 --> 00:40:39,490
how these slides are old but basically

00:40:37,510 --> 00:40:42,609
so uninstall what does it do it goes

00:40:39,490 --> 00:40:45,609
through and it puts the scheduler into

00:40:42,609 --> 00:40:47,799
an uninstall mode it then proceeds to

00:40:45,609 --> 00:40:50,140
unreserve everything ahead reserved and

00:40:47,799 --> 00:40:52,420
then walk away leaving a very clean

00:40:50,140 --> 00:40:54,400
cluster that you can put other things on

00:40:52,420 --> 00:41:03,150
and then you just sort of loop through

00:40:54,400 --> 00:41:03,150
that again and again yeah

00:41:04,070 --> 00:41:10,280
correct yeah yeah so if you're sharing a

00:41:07,040 --> 00:41:13,130
cluster I mean you could both run it and

00:41:10,280 --> 00:41:17,870
then you'll sort of just compete for

00:41:13,130 --> 00:41:19,370
whose memcache runs or not okay so let's

00:41:17,870 --> 00:41:21,110
look at how will actually start to do

00:41:19,370 --> 00:41:22,760
memcache right so I've I've built a

00:41:21,110 --> 00:41:24,950
docker image that has memcache on it

00:41:22,760 --> 00:41:27,140
it's not gonna come up and try to run it

00:41:24,950 --> 00:41:29,390
or anything like that so basically the

00:41:27,140 --> 00:41:31,790
simplest possible case of memcache is to

00:41:29,390 --> 00:41:33,560
say yes I want three of these using this

00:41:31,790 --> 00:41:35,770
docker image and then I'm gonna put the

00:41:33,560 --> 00:41:38,750
command in as memcache right it's gonna

00:41:35,770 --> 00:41:40,490
launch three tasks sorry three pods each

00:41:38,750 --> 00:41:43,820
of them has a single task it's gonna

00:41:40,490 --> 00:41:46,010
reserve one CPU and a gig of memory for

00:41:43,820 --> 00:41:49,370
each one memcache is just gonna turn on

00:41:46,010 --> 00:41:58,700
meat right it's a very simple most basic

00:41:49,370 --> 00:42:01,940
possible example okay so this was a bad

00:41:58,700 --> 00:42:03,830
like this was bad this this has created

00:42:01,940 --> 00:42:06,380
a toxic framework that is doing

00:42:03,830 --> 00:42:08,660
something very bad that maze O's has

00:42:06,380 --> 00:42:11,660
problems with which is port reservations

00:42:08,660 --> 00:42:14,270
so mezzos has zero enforcement about

00:42:11,660 --> 00:42:16,940
ports it is the honor system and like

00:42:14,270 --> 00:42:19,010
not a particularly honorable system so

00:42:16,940 --> 00:42:20,810
what we did and silently here in the

00:42:19,010 --> 00:42:24,740
background by turning on memcache is we

00:42:20,810 --> 00:42:26,330
stole the port 11 to 11 right so to be

00:42:24,740 --> 00:42:28,160
good citizens we can come in here

00:42:26,330 --> 00:42:29,990
instead and we can actually leverage

00:42:28,160 --> 00:42:31,580
some nice features like obviously hey I

00:42:29,990 --> 00:42:33,740
want to stack a bunch of different

00:42:31,580 --> 00:42:34,940
memcache frameworks that you know I have

00:42:33,740 --> 00:42:36,860
a bunch of developers I want to stack

00:42:34,940 --> 00:42:38,510
them all on the same cluster I don't

00:42:36,860 --> 00:42:40,750
really care about them overlapping

00:42:38,510 --> 00:42:42,830
because it's all different memcache is

00:42:40,750 --> 00:42:45,230
just some nice syntactic sugar it would

00:42:42,830 --> 00:42:48,230
be like hey give me a random port give

00:42:45,230 --> 00:42:49,430
it this n bar and then advertise we'll

00:42:48,230 --> 00:42:51,110
see in a bit basically it just means

00:42:49,430 --> 00:42:52,880
when someone calls the endpoints command

00:42:51,110 --> 00:42:55,670
tell them that this endpoint is

00:42:52,880 --> 00:42:58,850
available and then you can see we just

00:42:55,670 --> 00:43:01,280
modify to say hey you should listen on

00:42:58,850 --> 00:43:03,800
the mezzos container IP which is the

00:43:01,280 --> 00:43:06,650
private IP of the agent so it's whatever

00:43:03,800 --> 00:43:10,040
IP you start the agent with excuse me

00:43:06,650 --> 00:43:13,010
and then you should use this port which

00:43:10,040 --> 00:43:15,380
is the memcache port which again is

00:43:13,010 --> 00:43:17,270
coming from this random port that it is

00:43:15,380 --> 00:43:18,020
assigned pretty much always you're gonna

00:43:17,270 --> 00:43:19,580
get ten twenty

00:43:18,020 --> 00:43:21,800
because there's no other reports taken

00:43:19,580 --> 00:43:24,290
but that's just a side effect of having

00:43:21,800 --> 00:43:25,640
your own little empty cluster so again

00:43:24,290 --> 00:43:27,560
the surge of stresses right like we make

00:43:25,640 --> 00:43:30,020
all of these reservations some of them

00:43:27,560 --> 00:43:31,970
are not enforced right so a great

00:43:30,020 --> 00:43:33,890
example is when you have multiple tasks

00:43:31,970 --> 00:43:35,870
that you know they each have their own

00:43:33,890 --> 00:43:37,880
different CPU and memory settings cool

00:43:35,870 --> 00:43:39,830
they're just gonna share like everything

00:43:37,880 --> 00:43:41,420
in a pod is gonna share executor is like

00:43:39,830 --> 00:43:43,070
everything under an executor sheriff of

00:43:41,420 --> 00:43:45,290
C Group there's no enforcement there yet

00:43:43,070 --> 00:43:47,360
there probably will be someday

00:43:45,290 --> 00:43:49,910
essentially within a pod the things that

00:43:47,360 --> 00:43:53,300
are shared our network namespace C

00:43:49,910 --> 00:43:55,730
groups and then the only real isolation

00:43:53,300 --> 00:43:57,920
is that the sandbox and mounts are

00:43:55,730 --> 00:44:00,050
different right like if you if you want

00:43:57,920 --> 00:44:01,280
a volume to be available to all tasks in

00:44:00,050 --> 00:44:03,410
a pod you need to put it at the pod

00:44:01,280 --> 00:44:05,390
level if you put it at the task level it

00:44:03,410 --> 00:44:06,950
will not be visible to everybody

00:44:05,390 --> 00:44:08,660
same for the sandbox if you do something

00:44:06,950 --> 00:44:12,050
in the sandbox at one task you will not

00:44:08,660 --> 00:44:14,630
see it in the other tasks same for

00:44:12,050 --> 00:44:15,920
environment also write like tasks

00:44:14,630 --> 00:44:18,380
inherit the environment of their

00:44:15,920 --> 00:44:24,020
executor they do not share environments

00:44:18,380 --> 00:44:26,810
with their tasks neighbors so close

00:44:24,020 --> 00:44:29,120
this is doing a gogit of 50 kilobytes

00:44:26,810 --> 00:44:32,600
that takes a very long time on this

00:44:29,120 --> 00:44:34,940
network okay so let's talk a bit about

00:44:32,600 --> 00:44:37,640
so in terms of when you're developing

00:44:34,940 --> 00:44:39,920
task exec is your friend so task exec

00:44:37,640 --> 00:44:43,460
obviously a way to specify what is

00:44:39,920 --> 00:44:44,780
actually a regex cache 0 server is

00:44:43,460 --> 00:44:46,340
basically gonna match like if there's

00:44:44,780 --> 00:44:48,170
only a single task that matches that

00:44:46,340 --> 00:44:49,760
it'll hop into it otherwise it'll tell

00:44:48,170 --> 00:44:52,400
you like here's all the tasks that match

00:44:49,760 --> 00:44:55,010
the regex you've given me so task exec -

00:44:52,400 --> 00:44:57,500
ite been bash exactly the same as if you

00:44:55,010 --> 00:45:00,470
had SSH but the very cool thing is this

00:44:57,500 --> 00:45:02,720
is exactly as if you were that container

00:45:00,470 --> 00:45:04,850
we sort of just test exec is just

00:45:02,720 --> 00:45:06,350
plopping a little container right at the

00:45:04,850 --> 00:45:08,210
same level nesting you have to share the

00:45:06,350 --> 00:45:10,160
environment of whatever task you're

00:45:08,210 --> 00:45:11,390
hopping into you can see everything it

00:45:10,160 --> 00:45:13,550
can see super useful

00:45:11,390 --> 00:45:15,260
I used it while I was doing this to do

00:45:13,550 --> 00:45:16,700
some debugging around a shared volume

00:45:15,260 --> 00:45:18,080
because it was like I couldn't figure

00:45:16,700 --> 00:45:19,640
out why one task could see it and one

00:45:18,080 --> 00:45:21,590
task couldn't and I still don't really

00:45:19,640 --> 00:45:24,140
know but I made it work so I feel very

00:45:21,590 --> 00:45:26,270
accomplished and then in terms of trying

00:45:24,140 --> 00:45:28,130
it out basically the container Russell

00:45:26,270 --> 00:45:29,750
includes netcat and will be able to once

00:45:28,130 --> 00:45:30,650
we get running just do some simple

00:45:29,750 --> 00:45:32,030
netcat commands

00:45:30,650 --> 00:45:33,650
to memcache part of the reason I pick

00:45:32,030 --> 00:45:40,450
memcache it's very easy to talk to it

00:45:33,650 --> 00:45:42,800
with clients so configuration templates

00:45:40,450 --> 00:45:45,200
so obviously when you have these complex

00:45:42,800 --> 00:45:47,680
services they all pretty much all of

00:45:45,200 --> 00:45:49,940
them have these large unwieldy

00:45:47,680 --> 00:45:51,950
configuration files that you need to

00:45:49,940 --> 00:45:55,130
pipe things into the way that we handled

00:45:51,950 --> 00:45:58,760
that is that we essentially give you the

00:45:55,130 --> 00:46:00,680
ability to write mustache templates that

00:45:58,760 --> 00:46:02,900
are then populated from the environment

00:46:00,680 --> 00:46:05,810
of the task using our bootstrap utility

00:46:02,900 --> 00:46:07,910
so the bootstrap utility is available

00:46:05,810 --> 00:46:10,520
and all your frameworks you do have to

00:46:07,910 --> 00:46:13,130
explicitly include it as a URI at least

00:46:10,520 --> 00:46:13,610
for now and then you run it whenever you

00:46:13,130 --> 00:46:14,930
want

00:46:13,610 --> 00:46:16,460
right so you might not necessarily want

00:46:14,930 --> 00:46:18,230
to run it as the very first thing in the

00:46:16,460 --> 00:46:20,360
command you might want to do some other

00:46:18,230 --> 00:46:22,550
set up calculate some end bars that are

00:46:20,360 --> 00:46:25,460
then going to get templated in your

00:46:22,550 --> 00:46:26,570
template files and then but obviously

00:46:25,460 --> 00:46:29,980
you're gonna ultimately want to run it

00:46:26,570 --> 00:46:32,030
before you run your server tasks so

00:46:29,980 --> 00:46:35,150
bootstrap has a couple other nice things

00:46:32,030 --> 00:46:36,470
it'll allow you to wait for dns

00:46:35,150 --> 00:46:38,750
resolution on certain things

00:46:36,470 --> 00:46:41,750
so both mezzos dns and then spartan the

00:46:38,750 --> 00:46:43,160
slightly fancier DMS of DCOs are not

00:46:41,750 --> 00:46:45,980
instant right like it has to propagate

00:46:43,160 --> 00:46:48,440
to some extent so it'll let you do

00:46:45,980 --> 00:46:49,880
things a very common loop that we have

00:46:48,440 --> 00:46:51,530
in our stuff is to basically sit there

00:46:49,880 --> 00:46:54,380
waiting like okay like wait a minute

00:46:51,530 --> 00:46:56,360
until DNS has resolved because if I try

00:46:54,380 --> 00:46:57,710
to launch this thing and like it tries

00:46:56,360 --> 00:46:59,150
to talk to its fellow is like it's just

00:46:57,710 --> 00:47:01,250
gonna freak out so let's sort of wait

00:46:59,150 --> 00:47:04,880
until the DNS record actually exists

00:47:01,250 --> 00:47:07,220
before we proceed what other fun things

00:47:04,880 --> 00:47:07,910
can you do oh yeah you can also install

00:47:07,220 --> 00:47:10,370
certs

00:47:07,910 --> 00:47:12,110
we also default that to true this isn't

00:47:10,370 --> 00:47:13,310
really applicable going forward to 110

00:47:12,110 --> 00:47:17,240
we used to have a we have a custom

00:47:13,310 --> 00:47:22,760
executor in 1-9 and that needs the certs

00:47:17,240 --> 00:47:23,960
for certain things okay so if we look at

00:47:22,760 --> 00:47:26,300
our configuration templates so you can

00:47:23,960 --> 00:47:29,450
see that here we are adding configs

00:47:26,300 --> 00:47:31,400
we'll call it memcache the template that

00:47:29,450 --> 00:47:33,290
is just a communion 10 var to pick up

00:47:31,400 --> 00:47:35,180
the location this actually got a little

00:47:33,290 --> 00:47:36,530
bit better the next version of the SDK

00:47:35,180 --> 00:47:39,110
you won't have to remember to throw this

00:47:36,530 --> 00:47:40,460
magic and var in there so you might

00:47:39,110 --> 00:47:41,630
notice that there's actually like wait

00:47:40,460 --> 00:47:44,410
why is there mustache that I'm putting

00:47:41,630 --> 00:47:47,650
into my service camel so the way this

00:47:44,410 --> 00:47:48,520
works is the scheduler reads essentially

00:47:47,650 --> 00:47:51,790
a moustached

00:47:48,520 --> 00:47:53,650
gamal and it uses its environment to

00:47:51,790 --> 00:47:55,600
populate it right and that environment

00:47:53,650 --> 00:47:57,790
is coming from the marathon app and that

00:47:55,600 --> 00:47:59,440
is ultimately coming from the options

00:47:57,790 --> 00:48:02,320
that the user supplied when they install

00:47:59,440 --> 00:48:04,270
the package so you can see here we're

00:48:02,320 --> 00:48:06,580
basically taking this very simple

00:48:04,270 --> 00:48:09,280
configuration file we're throwing in the

00:48:06,580 --> 00:48:10,660
memory limit the memcache port and it

00:48:09,280 --> 00:48:12,250
made this container a P and then there's

00:48:10,660 --> 00:48:14,710
also a listen on localhost so it's a

00:48:12,250 --> 00:48:17,440
little bit easier to talk to you so you

00:48:14,710 --> 00:48:21,430
can see there we're also adding memory

00:48:17,440 --> 00:48:23,440
and limit to the environment and then so

00:48:21,430 --> 00:48:24,790
we're doing bootstrap memcache D and

00:48:23,440 --> 00:48:26,320
then I'm just catting the memcache

00:48:24,790 --> 00:48:27,430
decomp because in my container I

00:48:26,320 --> 00:48:29,770
couldn't figure out how to get it to

00:48:27,430 --> 00:48:34,660
read from it in the right place so we're

00:48:29,770 --> 00:48:37,660
just doing a cat and cool let's see how

00:48:34,660 --> 00:48:43,210
we're doing over here yes okay

00:48:37,660 --> 00:48:46,930
so jump all the way back so this is the

00:48:43,210 --> 00:48:48,580
very simple hello world so I can take a

00:48:46,930 --> 00:48:50,950
look at yours in a bit I'm not sure why

00:48:48,580 --> 00:48:53,050
it didn't upload does anybody else able

00:48:50,950 --> 00:48:57,280
to build there's anybody tried do use

00:48:53,050 --> 00:49:02,650
work I would double check your AWS

00:48:57,280 --> 00:49:04,120
configuration okay neat so essentially

00:49:02,650 --> 00:49:08,530
that devil loop again right so you build

00:49:04,120 --> 00:49:11,560
okay neat you've now built you have what

00:49:08,530 --> 00:49:13,030
you wind up with at the end is this

00:49:11,560 --> 00:49:15,640
right here is basically adding what you

00:49:13,030 --> 00:49:17,620
just built as a stub universe and then

00:49:15,640 --> 00:49:19,180
the package install is just gonna

00:49:17,620 --> 00:49:21,580
install it with one of the default

00:49:19,180 --> 00:49:24,010
options are as you noticed we aren't

00:49:21,580 --> 00:49:26,050
really templating very much in this so

00:49:24,010 --> 00:49:28,420
an actual production eyes install would

00:49:26,050 --> 00:49:29,380
have a bunch of mustache template and a

00:49:28,420 --> 00:49:31,000
bunch of things in your marathon

00:49:29,380 --> 00:49:33,430
environment and a bunch of things in

00:49:31,000 --> 00:49:35,800
your options file but that is neither a

00:49:33,430 --> 00:49:38,260
compelling demo and probably would scare

00:49:35,800 --> 00:49:39,400
you away so it's not super great so

00:49:38,260 --> 00:49:40,780
we're gonna do the very simple where

00:49:39,400 --> 00:49:45,630
we're just touching re amyl at least for

00:49:40,780 --> 00:49:45,630
today so I go ahead

00:49:47,320 --> 00:49:55,690
I have noticed the installing CLI

00:49:53,410 --> 00:50:00,670
sub-command is taking an atrocious a

00:49:55,690 --> 00:50:02,920
long time so hey there we go it worked

00:50:00,670 --> 00:50:07,000
neat so as you can see so DC West

00:50:02,920 --> 00:50:10,120
memcache is just the CLI module for this

00:50:07,000 --> 00:50:12,000
framework and we can do fun things with

00:50:10,120 --> 00:50:15,600
it

00:50:12,000 --> 00:50:15,600
see planned

00:50:15,780 --> 00:50:18,780
oops

00:50:21,150 --> 00:50:27,400
cool so as you can see the deploy plan

00:50:24,100 --> 00:50:29,500
that itself calculated is very simple it

00:50:27,400 --> 00:50:31,750
has the hello pod it has the hello zero

00:50:29,500 --> 00:50:34,930
server and it is bringing it up and

00:50:31,750 --> 00:50:39,520
saying yeah it's complete the fun part

00:50:34,930 --> 00:50:42,880
is so because of the fact that this one

00:50:39,520 --> 00:50:45,040
if you recall is literally just an echo

00:50:42,880 --> 00:50:48,340
it's just gonna keep finishing right so

00:50:45,040 --> 00:50:49,690
I should go to see here that our

00:50:48,340 --> 00:50:51,690
recovery plan is going to sit here

00:50:49,690 --> 00:50:54,370
constantly trying to restart this thing

00:50:51,690 --> 00:50:57,010
if you look at the output a DCOs task

00:50:54,370 --> 00:51:01,860
you'll see it's running right now no

00:50:57,010 --> 00:51:05,170
it's staging then and then if we go into

00:51:01,860 --> 00:51:07,330
what I would refer to as the maze O's

00:51:05,170 --> 00:51:09,460
framework developer UI or the Amazo cui

00:51:07,330 --> 00:51:15,640
because it is nice and speedy you can

00:51:09,460 --> 00:51:17,200
see here we have a bunch of hello zero

00:51:15,640 --> 00:51:20,350
server tasks they're all going through

00:51:17,200 --> 00:51:22,570
finished if we hop in here we can look

00:51:20,350 --> 00:51:29,620
at their standard out we can see hello

00:51:22,570 --> 00:51:30,940
world neat so so again that dev cycle

00:51:29,620 --> 00:51:32,830
right so okay we're gonna move on to the

00:51:30,940 --> 00:51:39,360
next one what do we want to do we want

00:51:32,830 --> 00:51:39,360
to do DCOs package uninstall memcache

00:51:39,690 --> 00:51:45,640
this is going to very annoyingly sorry I

00:51:43,210 --> 00:51:47,230
wrote this code prompt you to type in

00:51:45,640 --> 00:51:48,940
the name and there's also gonna bury

00:51:47,230 --> 00:51:50,710
scarily tell you this is going to delete

00:51:48,940 --> 00:51:52,420
all of your persistent data logs

00:51:50,710 --> 00:51:54,130
configurations database artifactset

00:51:52,420 --> 00:51:55,720
cetera that's because that is exactly

00:51:54,130 --> 00:51:57,820
what uninstalled does is going to go

00:51:55,720 --> 00:52:00,160
through and unreserve all your volumes

00:51:57,820 --> 00:52:03,850
gonna destroy your scheduler it is a

00:52:00,160 --> 00:52:05,140
gnarly and dangerous process don't do

00:52:03,850 --> 00:52:07,630
you want to install unless you don't

00:52:05,140 --> 00:52:09,580
want the data anymore you can actually

00:52:07,630 --> 00:52:13,150
do a - - yes and it will skip that

00:52:09,580 --> 00:52:17,850
warning so maybe don't tell everyone

00:52:13,150 --> 00:52:23,740
that you work with that so what happens

00:52:17,850 --> 00:52:25,540
so will actually see there we go so you

00:52:23,740 --> 00:52:27,130
can actually see so hello of zero server

00:52:25,540 --> 00:52:28,900
is sitting here in the failed state and

00:52:27,130 --> 00:52:31,120
the reason it's just that the scheduler

00:52:28,900 --> 00:52:32,240
has just been rebooted and it hasn't

00:52:31,120 --> 00:52:42,620
reconciled yet

00:52:32,240 --> 00:52:44,450
and acknowledged that task state so the

00:52:42,620 --> 00:52:47,840
way to uninstall works is we restart the

00:52:44,450 --> 00:52:49,520
scheduler so any new goal state for the

00:52:47,840 --> 00:52:51,020
scheduler is a restart right like any

00:52:49,520 --> 00:52:53,180
configuration change anything like that

00:52:51,020 --> 00:52:56,270
we restart the scheduler with a new sort

00:52:53,180 --> 00:52:58,490
of immutable goal state and in the

00:52:56,270 --> 00:53:01,430
uninstall case that goal state is get

00:52:58,490 --> 00:53:03,200
rid of everything and then die

00:53:01,430 --> 00:53:07,040
so essentially what it does cosmos

00:53:03,200 --> 00:53:09,500
restarts it in uninstall mode it kills

00:53:07,040 --> 00:53:11,780
all of its tasks it receives back all of

00:53:09,500 --> 00:53:14,000
the reservations that it had made it

00:53:11,780 --> 00:53:17,420
unreserved all of those things and then

00:53:14,000 --> 00:53:19,820
it deletes all of the bookkeeping that

00:53:17,420 --> 00:53:22,160
it's doing in ZK we keep state like we

00:53:19,820 --> 00:53:25,820
track everything in ZK and then it

00:53:22,160 --> 00:53:27,470
basically then just says I'm done via

00:53:25,820 --> 00:53:29,750
it's the ploy plan and then cosmos

00:53:27,470 --> 00:53:31,700
deletes it via marathon essentially

00:53:29,750 --> 00:53:34,190
because you have to have the you need

00:53:31,700 --> 00:53:36,170
user credentials to do the final step so

00:53:34,190 --> 00:53:39,820
cosmos essentially holds the user

00:53:36,170 --> 00:53:43,430
credentials in limbo while it's waiting

00:53:39,820 --> 00:53:44,960
yeah so there we go so yeah and so just

00:53:43,430 --> 00:53:47,030
what happens like right so if your

00:53:44,960 --> 00:53:48,470
scheduler is down and a task fails it

00:53:47,030 --> 00:53:51,410
will you actually get this weird state

00:53:48,470 --> 00:53:53,000
where it shows is active but failed and

00:53:51,410 --> 00:53:54,560
it's just because no scheduler has

00:53:53,000 --> 00:53:56,330
acknowledged like the scheduler has not

00:53:54,560 --> 00:53:59,810
acknowledged that like oh yes I agree

00:53:56,330 --> 00:54:05,320
that task is dead now all right so it's

00:53:59,810 --> 00:54:08,650
gone we're gonna go to our handy-dandy

00:54:05,320 --> 00:54:08,650
cheat sheet

00:54:11,470 --> 00:54:17,850
and copying the super basic memcache to

00:54:20,460 --> 00:54:26,290
a fortunately much faster build the

00:54:25,180 --> 00:54:28,840
network connection here is actually

00:54:26,290 --> 00:54:31,330
bizarrely asymmetric and the uploads are

00:54:28,840 --> 00:54:33,580
like four times the bandwidth of the

00:54:31,330 --> 00:54:35,940
downloads which I do not understand and

00:54:33,580 --> 00:54:35,940
never will

00:54:38,610 --> 00:54:47,010
does anybody have any questions but

00:54:40,660 --> 00:54:47,010
we've covered so far yes sir

00:55:00,300 --> 00:55:06,550
oh yeah

00:55:03,350 --> 00:55:06,550
[Music]

00:55:07,040 --> 00:55:12,020
let's see which one are you

00:55:23,760 --> 00:55:30,849
okay thanks York

00:55:28,930 --> 00:55:32,710
anyone anyone else technical

00:55:30,849 --> 00:55:39,480
difficulties let's do any technical

00:55:32,710 --> 00:55:39,480
difficulties otherwise no okay question

00:55:48,780 --> 00:55:56,050
yes so to be very yes to be very clear

00:55:53,589 --> 00:55:58,450
so the question was like can I use can I

00:55:56,050 --> 00:56:01,980
run Kafka or Casandra using this yes

00:55:58,450 --> 00:56:04,660
the Kafka Cassandra elastic hdfs

00:56:01,980 --> 00:56:08,920
confluent Kafka and DSC packages are

00:56:04,660 --> 00:56:15,880
this like it's Gamal and a bit of Java

00:56:08,920 --> 00:56:17,950
that is all they are ah I see

00:56:15,880 --> 00:56:20,290
no so it is a multi scheduler right

00:56:17,950 --> 00:56:22,660
every service has its own scheduler it

00:56:20,290 --> 00:56:25,750
is not a mono scheduler right it it is

00:56:22,660 --> 00:56:28,119
not Aurora or marathon or the new one

00:56:25,750 --> 00:56:30,040
uber is building right but it is a

00:56:28,119 --> 00:56:40,660
different model right it is the model of

00:56:30,040 --> 00:56:41,920
multi schedulers versus uh-huh yes yeah

00:56:40,660 --> 00:56:48,059
you can build all of them with the SDK

00:56:41,920 --> 00:56:48,059
and we have yeah I think yes

00:56:51,450 --> 00:56:54,450
mm-hm

00:57:06,890 --> 00:57:13,369
yeah so the question was when you have a

00:57:14,210 --> 00:57:20,670
right so our executor right is a set of

00:57:17,849 --> 00:57:23,400
task groups right so pod lines up with

00:57:20,670 --> 00:57:29,250
executor task group lines up with our

00:57:23,400 --> 00:57:32,309
tasks right so when we deploy a pod we

00:57:29,250 --> 00:57:35,069
statically reserve all of its resources

00:57:32,309 --> 00:57:36,900
we look at the total sum so there's a

00:57:35,069 --> 00:57:39,540
concept of resource sets where

00:57:36,900 --> 00:57:41,670
essentially a set of tasks some number

00:57:39,540 --> 00:57:43,500
of tasks under the pod can all use the

00:57:41,670 --> 00:57:45,299
same resource set they cannot it means

00:57:43,500 --> 00:57:47,490
those tasks cannot run at the same time

00:57:45,299 --> 00:57:50,880
but that they don't need their own sets

00:57:47,490 --> 00:57:52,470
of resources and so we look at the sum

00:57:50,880 --> 00:57:55,109
total of resource sets and then

00:57:52,470 --> 00:57:57,720
individual resource allocations within

00:57:55,109 --> 00:58:01,200
the tasks and we statically reserve that

00:57:57,720 --> 00:58:02,730
entire chunk and we never touch it we

00:58:01,200 --> 00:58:05,270
don't shrink it or grow it depending on

00:58:02,730 --> 00:58:05,270
what's running

00:58:18,039 --> 00:58:22,099
No

00:58:19,510 --> 00:58:24,200
yeah so the question was like if so

00:58:22,099 --> 00:58:29,680
today you had 10 tasks in your pod

00:58:24,200 --> 00:58:29,680
they're all running if one of them dies

00:58:38,440 --> 00:58:46,299
yeah I know I was I was gonna maybe hand

00:58:41,230 --> 00:58:49,390
it to someone to talking to but yeah

00:58:46,299 --> 00:58:52,000
sorry so the question yeah so okay so

00:58:49,390 --> 00:58:53,440
you do have ten tasks in your pod all of

00:58:52,000 --> 00:58:55,089
them are running one of them dies

00:58:53,440 --> 00:58:57,069
there's no changes to see groups or

00:58:55,089 --> 00:58:59,589
anything right like it is all one big

00:58:57,069 --> 00:59:01,859
atomic unit as far as the C group is

00:58:59,589 --> 00:59:01,859
concerned

00:59:01,920 --> 00:59:10,359
okay so neat so again I very

00:59:08,980 --> 00:59:11,970
conveniently can just copy this in

00:59:10,359 --> 00:59:14,740
basically gonna remove the existing

00:59:11,970 --> 00:59:17,289
package repository add in the new stub

00:59:14,740 --> 00:59:28,079
universe and then install it with

00:59:17,289 --> 00:59:28,079
default watch over here

00:59:28,260 --> 00:59:36,730
alright so our scheduler is coming up

00:59:31,319 --> 00:59:40,180
terms of let's look at some fun

00:59:36,730 --> 00:59:43,180
scheduler logs so you'll see the

00:59:40,180 --> 00:59:45,130
scheduler scheduler is brand new it had

00:59:43,180 --> 00:59:47,170
no previous configs we're just gonna see

00:59:45,130 --> 00:59:48,819
its current config it's gonna say neat

00:59:47,170 --> 00:59:49,180
there's no other configs to compare it

00:59:48,819 --> 00:59:51,069
to

00:59:49,180 --> 00:59:52,869
skipping kid I think yeah skipping

00:59:51,069 --> 00:59:58,089
config diff there's no old target config

00:59:52,869 --> 01:00:00,819
and so this point is just waiting to

00:59:58,089 --> 01:00:03,670
start it's API server it's already you

01:00:00,819 --> 01:00:04,930
can see here we acquire is EK lakh just

01:00:03,670 --> 01:00:06,339
to make sure that there are no two

01:00:04,930 --> 01:00:10,029
schedulers running that think they are

01:00:06,339 --> 01:00:15,359
the same scheduler and and it is waiting

01:00:10,029 --> 01:00:15,359
to have its API server up and running

01:00:19,140 --> 01:00:26,819
oh no it just got D synced okay let's

01:00:25,289 --> 01:00:28,109
walk through this so I think it's

01:00:26,819 --> 01:00:31,440
definitely useful to sort of see like

01:00:28,109 --> 01:00:37,579
how does the scheduler interact there we

01:00:31,440 --> 01:00:37,579
go okay so

01:00:41,540 --> 01:00:47,930
cool so you can see here we basically we

01:00:45,050 --> 01:00:50,540
get a offer set right and then process

01:00:47,930 --> 01:00:52,160
those offers we essentially build a set

01:00:50,540 --> 01:00:56,150
of launch criteria for the cash zero

01:00:52,160 --> 01:00:58,250
server you can see here we're then

01:00:56,150 --> 01:01:00,110
checking in evaluation stages we're just

01:00:58,250 --> 01:01:02,480
seeing like okay it has enough CPU it

01:01:00,110 --> 01:01:05,180
has enough memory it has the disk we're

01:01:02,480 --> 01:01:07,190
looking for which isn't really any so

01:01:05,180 --> 01:01:10,970
there is the executor we have to give it

01:01:07,190 --> 01:01:14,660
256 Meg's of like hostess or it doesn't

01:01:10,970 --> 01:01:16,970
work so we always end up doing that so

01:01:14,660 --> 01:01:19,970
you can see here what we essentially do

01:01:16,970 --> 01:01:22,010
so the astute and frequent maizlish

01:01:19,970 --> 01:01:25,790
users may be familiar with the fact that

01:01:22,010 --> 01:01:27,860
there is no feedback on operations with

01:01:25,790 --> 01:01:30,470
mezzos except for one which is launched

01:01:27,860 --> 01:01:32,300
so what we do is we stack everything

01:01:30,470 --> 01:01:34,700
into a big stack right so you see here

01:01:32,300 --> 01:01:36,710
like these are not sequential operations

01:01:34,700 --> 01:01:38,630
these are all sent as a single set to

01:01:36,710 --> 01:01:40,520
maze notes and we then get feedback on

01:01:38,630 --> 01:01:42,290
the launch right so if like any one of

01:01:40,520 --> 01:01:45,950
these like if the reserved like if this

01:01:42,290 --> 01:01:47,990
fourth reserved failed we'll just get a

01:01:45,950 --> 01:01:49,790
failure on the launch and the way we

01:01:47,990 --> 01:01:52,580
process that is we can then just sort of

01:01:49,790 --> 01:01:55,010
walk away from those resources and it'll

01:01:52,580 --> 01:01:56,660
come back around get offered to us and

01:01:55,010 --> 01:01:58,610
we'll be like wait I don't care about

01:01:56,660 --> 01:02:00,560
these resources I never used them we'll

01:01:58,610 --> 01:02:02,240
throw them away and we will have

01:02:00,560 --> 01:02:08,240
proceeded with different offers to try

01:02:02,240 --> 01:02:12,740
to schedule okay so you can kind of see

01:02:08,240 --> 01:02:16,130
you kind of get a sense for it so you

01:02:12,740 --> 01:02:19,250
can see here here's its final step right

01:02:16,130 --> 01:02:22,460
so it's saying okay it's processing the

01:02:19,250 --> 01:02:25,550
deploy plan has the candidate of cache

01:02:22,460 --> 01:02:28,040
to server it then looks at offers so it

01:02:25,550 --> 01:02:30,140
builds an offer evaluation pipeline then

01:02:28,040 --> 01:02:32,420
looks at the offers how to pass for all

01:02:30,140 --> 01:02:34,580
of them it's going to do the five

01:02:32,420 --> 01:02:37,990
reservation option operations and then

01:02:34,580 --> 01:02:37,990
it's going to finally issue the launch

01:02:38,440 --> 01:02:46,070
so you can see here we have all the

01:02:42,560 --> 01:02:49,390
cache servers running so let's go ahead

01:02:46,070 --> 01:02:49,390
and poke at it

01:02:54,650 --> 01:03:08,670
so I can do DCOs tasks exact - IT cache

01:03:03,119 --> 01:03:10,859
zero server so you can see there it pops

01:03:08,670 --> 01:03:14,700
them right into the sandbox of that task

01:03:10,859 --> 01:03:16,259
and if I do environment you can actually

01:03:14,700 --> 01:03:19,170
see so I'm sharing exactly the same

01:03:16,259 --> 01:03:23,430
environment let's see there's like maze

01:03:19,170 --> 01:03:27,089
those container IP there's my memcache

01:03:23,430 --> 01:03:29,549
version framework name etc let's see

01:03:27,089 --> 01:03:33,000
framework host so one thing I haven't

01:03:29,549 --> 01:03:36,150
commented on so every task winds up with

01:03:33,000 --> 01:03:38,670
a - DNS entries right there's a maze of

01:03:36,150 --> 01:03:40,920
CMS entry the primary entry that we use

01:03:38,670 --> 01:03:44,069
is the Spartan entry which looks like

01:03:40,920 --> 01:03:46,619
this so this tasks IP address would be

01:03:44,069 --> 01:03:50,880
cached at 0 its DNS address would be

01:03:46,619 --> 01:03:54,029
cache - 0 - server memcached auto IP

01:03:50,880 --> 01:03:57,029
DCOs not this DCOs directory because

01:03:54,029 --> 01:03:58,559
long dns names are fun i guess that can

01:03:57,029 --> 01:04:02,039
be the only reason that they made it

01:03:58,559 --> 01:04:05,910
that long is my assumption ok neat so if

01:04:02,039 --> 01:04:11,579
we do netcat localhost cuz we haven't

01:04:05,910 --> 01:04:16,230
configured anything yet so see there

01:04:11,579 --> 01:04:18,390
we're talking to memcache cool some cash

01:04:16,230 --> 01:04:20,099
is running at least but as I already

01:04:18,390 --> 01:04:21,869
talked about we didn't actually reserve

01:04:20,099 --> 01:04:25,109
the port that we're using so we're being

01:04:21,869 --> 01:04:27,690
very bad framework citizens so in lieu

01:04:25,109 --> 01:04:29,730
of doing that dev cycle yet another time

01:04:27,690 --> 01:04:35,009
I'm gonna kind of skip over this one and

01:04:29,730 --> 01:04:36,960
go right into adding a template so first

01:04:35,009 --> 01:04:39,690
because I'm installed does take a

01:04:36,960 --> 01:04:42,049
nonzero amount of time we're gonna kick

01:04:39,690 --> 01:04:48,619
off the uninstall so we will have a

01:04:42,049 --> 01:04:48,619
clean cluster and

01:04:50,940 --> 01:04:56,530
copy this over so you can see here so

01:04:54,700 --> 01:05:00,330
bootstrap is already in the marathon

01:04:56,530 --> 01:05:03,150
environment that is just a URI to a

01:05:00,330 --> 01:05:06,400
pre-built version of the bootstrap

01:05:03,150 --> 01:05:08,859
utility so when we release the SDK so we

01:05:06,400 --> 01:05:11,500
release so the current GA release is

01:05:08,859 --> 01:05:13,420
0.38 on 0 is the version so you actually

01:05:11,500 --> 01:05:15,070
see that here in terms of like the

01:05:13,420 --> 01:05:18,780
dependencies you'd be pulling in are

01:05:15,070 --> 01:05:21,550
just C's 3 and then we also release

01:05:18,780 --> 01:05:24,250
fixed versions of the custom executor

01:05:21,550 --> 01:05:26,230
for one nine clusters and the bootstrap

01:05:24,250 --> 01:05:30,190
utility for all clusters and those can

01:05:26,230 --> 01:05:34,150
be consumed and you can see that in the

01:05:30,190 --> 01:05:35,500
resource space on right here so there's

01:05:34,150 --> 01:05:38,050
our executor and there's our bootstrap

01:05:35,500 --> 01:05:44,200
and they're both version 0.30 that's

01:05:38,050 --> 01:05:46,780
zero okay so again just quickly so

01:05:44,200 --> 01:05:48,760
here's our config template we're going

01:05:46,780 --> 01:05:51,100
to run bootstrap that will template

01:05:48,760 --> 01:05:53,950
everything into it we obviously need the

01:05:51,100 --> 01:06:02,700
config template to do that so we'll pop

01:05:53,950 --> 01:06:02,700
a new file in and

01:06:04,490 --> 01:06:08,210
copy this over

01:06:10,990 --> 01:06:15,760
do that fun thing where I kill for time

01:06:13,630 --> 01:06:17,280
what builds alright anybody got any

01:06:15,760 --> 01:06:19,660
questions but we've gone over so far

01:06:17,280 --> 01:06:23,200
things that they are wondering about can

01:06:19,660 --> 01:06:29,980
the sdk solved this problem for me or

01:06:23,200 --> 01:06:31,240
this other problem no okay who wants to

01:06:29,980 --> 01:06:34,950
give an example of something they would

01:06:31,240 --> 01:06:34,950
be interested in building with the sdk

01:06:36,059 --> 01:06:53,369
okay oh yeah sorry what was that NC

01:06:47,200 --> 01:06:53,369
Rooter gotcha

01:07:03,400 --> 01:07:20,420
right ya know that would definitely be a

01:07:15,830 --> 01:07:23,990
good yes you can do that you can do HDFS

01:07:20,420 --> 01:07:26,120
if you can do HDFS you can do just about

01:07:23,990 --> 01:07:27,890
anything except for a relational

01:07:26,120 --> 01:07:30,160
database we have not added the correct

01:07:27,890 --> 01:07:37,720
primitives for relational databases yet

01:07:30,160 --> 01:07:37,720
all right so throwing that in there okay

01:07:41,590 --> 01:07:48,350
so one of the schedulers cool tricks is

01:07:45,770 --> 01:07:50,840
it serves as a very simple artifact

01:07:48,350 --> 01:07:52,430
server right like there is no sort of

01:07:50,840 --> 01:07:54,290
built-in blob store for mais OU store

01:07:52,430 --> 01:07:56,510
DCOs so we need somewhere to stick those

01:07:54,290 --> 01:07:58,400
configuration templates the scheduler is

01:07:56,510 --> 01:08:00,020
that place as you can see the dist file

01:07:58,400 --> 01:08:02,000
is where we put stuff that gets

01:08:00,020 --> 01:08:05,090
distributed with the jar the scheduler

01:08:02,000 --> 01:08:08,480
comes up one of the api's is artifacts

01:08:05,090 --> 01:08:10,510
and it then serves those out see if

01:08:08,480 --> 01:08:13,640
you've got cool so you can actually see

01:08:10,510 --> 01:08:17,960
config templates that got shot in there

01:08:13,640 --> 01:08:21,589
and yeah there we go so you can see here

01:08:17,960 --> 01:08:23,750
here's the untempered version and then

01:08:21,589 --> 01:08:27,200
if we look at standard error we can see

01:08:23,750 --> 01:08:29,450
the output at bootstrap so you can see

01:08:27,200 --> 01:08:31,580
bootstrapping bootstrap by default will

01:08:29,450 --> 01:08:33,260
print into your environment this is very

01:08:31,580 --> 01:08:35,990
very very helpful when you're debugging

01:08:33,260 --> 01:08:40,580
things so we can see here that dynamic

01:08:35,990 --> 01:08:43,069
port has been put in the environment via

01:08:40,580 --> 01:08:46,910
that environment variable we have the

01:08:43,069 --> 01:08:49,370
memory limit there and then you could

01:08:46,910 --> 01:08:51,050
actually see here bootstraps at there so

01:08:49,370 --> 01:08:53,780
by default bootstrap will just try to

01:08:51,050 --> 01:08:57,050
resolve its own host right and then move

01:08:53,780 --> 01:08:59,690
on so it was able to resolve it and then

01:08:57,050 --> 01:09:01,370
now it's sort of very nicely logged for

01:08:59,690 --> 01:09:03,200
you like hey here's the template I took

01:09:01,370 --> 01:09:03,859
the template here's the final output I

01:09:03,200 --> 01:09:07,080
wrote

01:09:03,859 --> 01:09:08,550
and then we can see that we start with

01:09:07,080 --> 01:09:12,170
successful and then here you can see the

01:09:08,550 --> 01:09:16,170
very verbose logging of memcache and

01:09:12,170 --> 01:09:21,050
sort of to prove that I'm not lying that

01:09:16,170 --> 01:09:27,020
it's actually using it it's hot back

01:09:21,050 --> 01:09:30,690
into that same task if I try localhost

01:09:27,020 --> 01:09:36,560
11 to 11 connection refused

01:09:30,690 --> 01:09:45,620
okay what if I do localhost memcache

01:09:36,560 --> 01:09:49,310
porch hey what do you know cool okay I

01:09:45,620 --> 01:09:49,310
sit back out of there okay

01:10:00,749 --> 01:10:05,429
okay cool so citecar plans so like we

01:10:03,780 --> 01:10:08,670
talked about psych our plans are

01:10:05,429 --> 01:10:10,469
essentially a way to have exposed to

01:10:08,670 --> 01:10:12,539
operators ways to interact with the

01:10:10,469 --> 01:10:14,249
service while leveraging all that

01:10:12,539 --> 01:10:15,989
orchestration right like obviously it

01:10:14,249 --> 01:10:17,849
would be very simple it's let's say

01:10:15,989 --> 01:10:20,070
right like why use this over marathon

01:10:17,849 --> 01:10:21,659
okay so let's say I wrote a marathon app

01:10:20,070 --> 01:10:23,639
that is just a bunch of them cache

01:10:21,659 --> 01:10:25,739
servers cool what if I want to flush the

01:10:23,639 --> 01:10:27,360
cache well it's easy you know you just

01:10:25,739 --> 01:10:29,039
like write a shell script it like calls

01:10:27,360 --> 01:10:30,119
netcat and then like echoes the flush

01:10:29,039 --> 01:10:31,920
command okay cool

01:10:30,119 --> 01:10:33,389
how do I run that against all of them

01:10:31,920 --> 01:10:35,489
well that's easy you write another

01:10:33,389 --> 01:10:36,690
script it like finds all of them and

01:10:35,489 --> 01:10:39,210
then like issues that commanding it

01:10:36,690 --> 01:10:41,489
starts getting very complicated sidecars

01:10:39,210 --> 01:10:44,039
are a great way to basically have a plan

01:10:41,489 --> 01:10:46,650
that runs against some number of the

01:10:44,039 --> 01:10:48,539
pods via additional little tasks that

01:10:46,650 --> 01:10:50,670
you've added into the pod definitions

01:10:48,539 --> 01:10:53,940
you can do all sorts of things so sort

01:10:50,670 --> 01:10:57,479
of the what are good examples right so

01:10:53,940 --> 01:10:59,610
Cassandra we have backup in the store so

01:10:57,479 --> 01:11:01,650
you can issue both a backup then you can

01:10:59,610 --> 01:11:03,539
also restore from a backup be assigned

01:11:01,650 --> 01:11:08,579
car plans where it'll you know send it

01:11:03,539 --> 01:11:10,710
up to Azure or s3 we also have I think

01:11:08,579 --> 01:11:13,289
we have yeah there's other various

01:11:10,710 --> 01:11:17,429
Cassandra side cars I think we have some

01:11:13,289 --> 01:11:18,960
an elastic but I'm not sure so neat what

01:11:17,429 --> 01:11:23,340
is our goal we want to flush each cash

01:11:18,960 --> 01:11:25,380
in each node flush each through Wow it's

01:11:23,340 --> 01:11:27,210
a great sentence alright so first thing

01:11:25,380 --> 01:11:29,880
we're gonna do we are going to add an

01:11:27,210 --> 01:11:32,219
executor volume so what is a cool thing

01:11:29,880 --> 01:11:34,229
is that I have a dynamic port very cool

01:11:32,219 --> 01:11:36,150
where does that dynamic port wind up

01:11:34,229 --> 01:11:39,360
winds up in the environment of my task

01:11:36,150 --> 01:11:41,729
oh I need another task for flushing the

01:11:39,360 --> 01:11:44,579
cache that doesn't share the same

01:11:41,729 --> 01:11:47,789
environment well shoot all right how can

01:11:44,579 --> 01:11:49,920
I get around this like well I as an SDK

01:11:47,789 --> 01:11:53,309
developer might just go ad pod level

01:11:49,920 --> 01:11:56,579
ports but in the interim what I can do

01:11:53,309 --> 01:11:58,769
is I can throw a volume on the pod so

01:11:56,579 --> 01:12:00,119
missing an executor level volume just a

01:11:58,769 --> 01:12:02,130
tiny little one I'll put it the path

01:12:00,119 --> 01:12:06,300
shared this will allow me to share state

01:12:02,130 --> 01:12:08,539
between sidecar tasks and the primary

01:12:06,300 --> 01:12:08,539
task

01:12:08,760 --> 01:12:15,249
so and we may see right all right so

01:12:13,749 --> 01:12:16,809
let's write down the dynamic port right

01:12:15,249 --> 01:12:19,119
so we're gonna echo the value of

01:12:16,809 --> 01:12:23,289
memcache port into shared slash memcache

01:12:19,119 --> 01:12:24,429
port and then in our sidecar task so we

01:12:23,289 --> 01:12:26,229
write down then we want the goal to be

01:12:24,429 --> 01:12:28,360
finished meaning like hey complete this

01:12:26,229 --> 01:12:32,349
and then you're done like run it till it

01:12:28,360 --> 01:12:34,229
completes but after that good so excuse

01:12:32,349 --> 01:12:37,510
me we're then I'm gonna echo flush all

01:12:34,229 --> 01:12:39,989
net tat dash Q 10 which just makes that

01:12:37,510 --> 01:12:42,459
cat finish when it receives into file

01:12:39,989 --> 01:12:45,010
localhost and then we'll just cat shared

01:12:42,459 --> 01:12:47,139
memcache port onto that so you can see

01:12:45,010 --> 01:12:50,110
here I'm using a very minimal number of

01:12:47,139 --> 01:12:52,689
CPUs in memory again the total footprint

01:12:50,110 --> 01:12:54,249
of your executor is a little tiny bit of

01:12:52,689 --> 01:12:57,670
overhead for the executor itself and

01:12:54,249 --> 01:12:59,829
then additionally the total CPU is a

01:12:57,670 --> 01:13:02,289
memory of all of your tasks added

01:12:59,829 --> 01:13:04,510
together and we do like right so that's

01:13:02,289 --> 01:13:06,999
sort of why if you have lots and lots of

01:13:04,510 --> 01:13:08,619
sidecar tasks you want them to use a

01:13:06,999 --> 01:13:11,019
single resource set a great example of

01:13:08,619 --> 01:13:13,599
that is Cassandra Cassandra has like ten

01:13:11,019 --> 01:13:16,150
sidecar tasks and if they all had their

01:13:13,599 --> 01:13:17,979
own sufficient resources allocated to

01:13:16,150 --> 01:13:20,050
them the footprint of Cassandra would be

01:13:17,979 --> 01:13:21,999
like here's Cassandra and then here's

01:13:20,050 --> 01:13:23,139
the sidecars so instead with a single

01:13:21,999 --> 01:13:26,769
resource set you're able to share

01:13:23,139 --> 01:13:30,670
resources between them but never at the

01:13:26,769 --> 01:13:33,670
same time for obvious reasons okay cool

01:13:30,670 --> 01:13:35,289
so our overall plans as soon as you add

01:13:33,670 --> 01:13:37,179
a single plan you then have to write

01:13:35,289 --> 01:13:39,729
down your deploy plan or it gets sad

01:13:37,179 --> 01:13:43,420
which is technically a bug so I filed a

01:13:39,729 --> 01:13:45,130
bug against that guy it's because deploy

01:13:43,420 --> 01:13:47,099
right you're never gonna have a naive

01:13:45,130 --> 01:13:49,570
deploy naive deploy is never gonna work

01:13:47,099 --> 01:13:51,999
all right so we'll write down flush all

01:13:49,570 --> 01:13:53,829
serial and flush all parallel the only

01:13:51,999 --> 01:13:56,070
difference being a serial versus

01:13:53,829 --> 01:14:00,249
parallel strategy right so serial means

01:13:56,070 --> 01:14:02,800
do this one wait for it to finish do the

01:14:00,249 --> 01:14:05,199
next one wait for it to finish do the

01:14:02,800 --> 01:14:10,749
next one wait for it to finish parallel

01:14:05,199 --> 01:14:14,949
means do all do all right now so aha

01:14:10,749 --> 01:14:17,429
all right so let's go ahead we pop over

01:14:14,949 --> 01:14:17,429
here

01:14:18,399 --> 01:14:21,399
go

01:14:25,429 --> 01:14:43,780
and oops I forgot to sing uninstall

01:14:34,550 --> 01:14:46,699
already okay

01:14:43,780 --> 01:14:48,040
so kick off the build is anybody have

01:14:46,699 --> 01:14:55,000
any questions about sidecars

01:14:48,040 --> 01:14:55,000
volumes yes sir

01:15:08,440 --> 01:15:14,300
gotcha so right the way we get around

01:15:11,960 --> 01:15:17,870
this is when we are evaluating can we

01:15:14,300 --> 01:15:19,370
yeah sorry yes the question is how do

01:15:17,870 --> 01:15:22,070
you ensure so right you you have some

01:15:19,370 --> 01:15:23,420
number of sidecar tasks how do you make

01:15:22,070 --> 01:15:24,860
sure that you can actually launch those

01:15:23,420 --> 01:15:28,250
where you're intending to watch them

01:15:24,860 --> 01:15:30,080
right so the way we do that is when we

01:15:28,250 --> 01:15:31,850
were making those reservations we make

01:15:30,080 --> 01:15:34,790
the reservation for the entire footprint

01:15:31,850 --> 01:15:37,010
of the pod right meaning if if you had

01:15:34,790 --> 01:15:39,800
eight tasks each one of those tasks

01:15:37,010 --> 01:15:41,960
requests one CPU and a gig of memory the

01:15:39,800 --> 01:15:43,730
total the total footprint we are looking

01:15:41,960 --> 01:15:45,820
for in a single offer is going to be

01:15:43,730 --> 01:15:49,700
eight CPUs and eight gigs of memory

01:15:45,820 --> 01:15:51,740
right so the reason for that is we want

01:15:49,700 --> 01:15:53,390
to make sure that we can SuperDuper for

01:15:51,740 --> 01:15:55,910
sure run that sidecar when you ask us to

01:15:53,390 --> 01:15:57,410
write it would be very easy to be like I

01:15:55,910 --> 01:15:58,790
mean that would be easy it actually kind

01:15:57,410 --> 01:16:00,290
of difficult to be like well let's wait

01:15:58,790 --> 01:16:01,850
until we get an offer that's not exactly

01:16:00,290 --> 01:16:03,740
the right agent that has like the right

01:16:01,850 --> 01:16:06,560
number of CPUs like no we want to

01:16:03,740 --> 01:16:08,900
statically reserve when we launch the

01:16:06,560 --> 01:16:10,460
pod the entire footprint of the pod so

01:16:08,900 --> 01:16:13,220
that at any time we can turn on or off

01:16:10,460 --> 01:16:15,950
any given site I'm not really turn on or

01:16:13,220 --> 01:16:17,510
off we can launch the tasks and the ones

01:16:15,950 --> 01:16:18,830
that reach finish states reach finish

01:16:17,510 --> 01:16:20,540
states and we stop trying to launch them

01:16:18,830 --> 01:16:22,880
the ones that have running States start

01:16:20,540 --> 01:16:30,400
running and we keep them running does

01:16:22,880 --> 01:16:30,400
that make sense any other questions

01:16:31,620 --> 01:16:36,030
ready to start this installing

01:16:43,459 --> 01:16:47,329
so this is a great example so I'll talk

01:16:45,199 --> 01:16:50,809
a little bit about this so while I was

01:16:47,329 --> 01:16:55,099
writing this I was doing this Echo real

01:16:50,809 --> 01:16:57,139
bad and so this task was winding up

01:16:55,099 --> 01:16:57,650
being able to so this task could see

01:16:57,139 --> 01:16:59,630
that file

01:16:57,650 --> 01:17:01,820
but then this task could not see that

01:16:59,630 --> 01:17:04,309
file so how did I do bug that right

01:17:01,820 --> 01:17:09,229
super annoying all I did is I went in

01:17:04,309 --> 01:17:11,630
here I said sleep forever and then that

01:17:09,229 --> 01:17:13,309
means my little flush cache task I can I

01:17:11,630 --> 01:17:15,409
can start the plan right it'll come up

01:17:13,309 --> 01:17:17,179
and it's just sleeping forever so I can

01:17:15,409 --> 01:17:19,519
hop into it with task exec and then I am

01:17:17,179 --> 01:17:21,380
exactly as though I am that task right I

01:17:19,519 --> 01:17:23,389
can see what it sees I can see that like

01:17:21,380 --> 01:17:25,369
okay I can see the shared volume but

01:17:23,389 --> 01:17:26,659
like why can't it see the file and I can

01:17:25,369 --> 01:17:28,249
compare the two different tasks and see

01:17:26,659 --> 01:17:31,159
like what are the permissions what weird

01:17:28,249 --> 01:17:33,349
thing have I done and then via that I

01:17:31,159 --> 01:17:38,689
was able to correct the bizarre way that

01:17:33,349 --> 01:17:40,219
I was writing that file and we're

01:17:38,689 --> 01:17:42,229
actually gonna work on features that are

01:17:40,219 --> 01:17:50,449
a better version than having to edit

01:17:42,229 --> 01:17:53,959
your thing and put in sleeps ok cool so

01:17:50,449 --> 01:17:57,349
you can see here that's actually in show

01:17:53,959 --> 01:18:00,769
deploy so you can see our deploy plan is

01:17:57,349 --> 01:18:05,059
complete very cool hey let's make sure

01:18:00,769 --> 01:18:08,329
nothing's in recovery nope no recoveries

01:18:05,059 --> 01:18:10,369
have been initiated ever let's do em

01:18:08,329 --> 01:18:14,840
cache it's like what was the name of

01:18:10,369 --> 01:18:19,689
that plan ok cool flash all serial or

01:18:14,840 --> 01:18:31,159
flush all parallel plan start flush all

01:18:19,689 --> 01:18:33,289
serial ok show so you can see there it's

01:18:31,159 --> 01:18:37,159
quite quick the first one already

01:18:33,289 --> 01:18:40,400
finished we go in here look at standard

01:18:37,159 --> 01:18:42,199
out so that is what you get when you act

01:18:40,400 --> 01:18:49,400
when you send flush all to memcache it

01:18:42,199 --> 01:18:53,559
just returns ok very cool very simple so

01:18:49,400 --> 01:18:53,559
let's use this a little bit so

01:18:54,150 --> 01:18:59,290
see here so here's the total set of

01:18:56,350 --> 01:19:02,010
commands so we have actions we can take

01:18:59,290 --> 01:19:04,560
on plans actions we can take on pods

01:19:02,010 --> 01:19:08,080
there's some debugging stuff down here

01:19:04,560 --> 01:19:10,210
updates or a feature in DC US Enterprise

01:19:08,080 --> 01:19:13,300
Edition only on 110 plus basically it's

01:19:10,210 --> 01:19:15,910
a way in your package metadata that you

01:19:13,300 --> 01:19:17,320
can codify an upgrade path meaning like

01:19:15,910 --> 01:19:18,550
you can go from this version of the

01:19:17,320 --> 01:19:20,380
package to this other version of the

01:19:18,550 --> 01:19:22,720
package and it'll like super duper for

01:19:20,380 --> 01:19:27,840
sure work no other paths being allowed

01:19:22,720 --> 01:19:31,990
outside of that mechanism all right so

01:19:27,840 --> 01:19:36,750
let's look at the pods so we have all

01:19:31,990 --> 01:19:39,220
these pods cool so if you look at let's

01:19:36,750 --> 01:19:41,650
touch this bad boy so cache to server

01:19:39,220 --> 01:19:44,170
right so I think someone had asked like

01:19:41,650 --> 01:19:46,480
what do you do when an agent dies okay

01:19:44,170 --> 01:19:48,520
cool well let's say it's catastrophic

01:19:46,480 --> 01:19:51,580
failure right like this agent is just

01:19:48,520 --> 01:20:01,840
never coming back then you would go in

01:19:51,580 --> 01:20:06,690
here would say pod replace what that's

01:20:01,840 --> 01:20:10,320
going to do is as you can see so we

01:20:06,690 --> 01:20:20,200
stopped so it killed cache zero server

01:20:10,320 --> 01:20:22,750
in the background the scheduler is it is

01:20:20,200 --> 01:20:25,960
unreserve all those resources and then

01:20:22,750 --> 01:20:27,670
it is rescheduling it right a fun thing

01:20:25,960 --> 01:20:31,240
about replace replace does not guarantee

01:20:27,670 --> 01:20:33,430
agent movement however if that agent had

01:20:31,240 --> 01:20:34,750
actually been dead right like there's no

01:20:33,430 --> 01:20:36,310
way you would have landed on it again

01:20:34,750 --> 01:20:39,970
because mais au s-- is not offering it

01:20:36,310 --> 01:20:41,680
to anyone so again like replace is

01:20:39,970 --> 01:20:42,930
destructive right so replace is

01:20:41,680 --> 01:20:47,530
basically saying like every volume

01:20:42,930 --> 01:20:48,490
unreserve it destroy where it's not on

01:20:47,530 --> 01:20:55,440
reserve for the volume it's just

01:20:48,490 --> 01:20:58,000
destroying so and same deal replace as

01:20:55,440 --> 01:21:01,990
it's much less destructive cousin

01:20:58,000 --> 01:21:03,770
restart so you can see here it started

01:21:01,990 --> 01:21:06,800
it again

01:21:03,770 --> 01:21:09,560
I can do a restart now if we look at our

01:21:06,800 --> 01:21:13,610
recovery plan let's see that that's

01:21:09,560 --> 01:21:14,990
where those were showing up yeah you can

01:21:13,610 --> 01:21:18,260
see there the restart goes through we

01:21:14,990 --> 01:21:24,580
can see it just started again go ahead

01:21:18,260 --> 01:21:24,580
look see it's bootstraps nicely

01:21:30,840 --> 01:21:45,869
all right okay what can't the SDK do yes

01:21:36,449 --> 01:21:50,190
sir yeah kernels to me great way to do

01:21:45,869 --> 01:21:53,699
it yeah no nothing built it and I would

01:21:50,190 --> 01:21:54,900
say the the SDK scheduler should not do

01:21:53,699 --> 01:21:57,570
that right like separation of concerns

01:21:54,900 --> 01:22:03,719
like you know use Jenkins use Chronos

01:21:57,570 --> 01:22:05,790
use cron yeah like the scheduler are we

01:22:03,719 --> 01:22:08,670
are fairly opinionated our view is that

01:22:05,790 --> 01:22:11,699
its job is to be a very good maze of

01:22:08,670 --> 01:22:13,679
scheduler and schedule tasks right like

01:22:11,699 --> 01:22:16,679
that that is what it does it is not an

01:22:13,679 --> 01:22:18,630
API server for connecting and all sorts

01:22:16,679 --> 01:22:20,940
of stuff like it is it is singular

01:22:18,630 --> 01:22:23,460
purpose and it is very good at the thing

01:22:20,940 --> 01:22:25,139
that it does so speaking of what what

01:22:23,460 --> 01:22:27,510
does it do right so what do we do today

01:22:25,139 --> 01:22:30,239
we have horizontal scale out meaning hey

01:22:27,510 --> 01:22:32,190
I want to add more instances of a pod at

01:22:30,239 --> 01:22:34,920
vertical scaling I want to go up or down

01:22:32,190 --> 01:22:37,500
for CPUs in memory of my pods right if I

01:22:34,920 --> 01:22:39,510
increase CPU or memory it's gonna do a

01:22:37,500 --> 01:22:41,489
rolling restart with whatever the update

01:22:39,510 --> 01:22:44,400
plan is rolling out across little

01:22:41,489 --> 01:22:46,260
clusters service discovery right you get

01:22:44,400 --> 01:22:48,750
automated DMS entries that are very

01:22:46,260 --> 01:22:50,900
predictable and reliable easy to consume

01:22:48,750 --> 01:22:53,760
within the framework for orchestration

01:22:50,900 --> 01:22:56,730
virtual networks so DC OS supports

01:22:53,760 --> 01:22:59,460
virtual networks basically vs CNI we

01:22:56,730 --> 01:23:00,780
interface nicely with that there's a

01:22:59,460 --> 01:23:03,500
built-in one in DCOs

01:23:00,780 --> 01:23:06,540
you can try out it's just called DCOs

01:23:03,500 --> 01:23:07,860
it's just the dcs overlay so we have

01:23:06,540 --> 01:23:10,050
readiness checks and health checks so

01:23:07,860 --> 01:23:12,630
readiness checks are I am NOT ready

01:23:10,050 --> 01:23:16,469
until this check returns thumbs up

01:23:12,630 --> 01:23:17,580
health checks are excuse me I am bad and

01:23:16,469 --> 01:23:20,730
should be killed

01:23:17,580 --> 01:23:23,880
when this health check is unhealthy a

01:23:20,730 --> 01:23:25,110
certain number of times right so pretty

01:23:23,880 --> 01:23:26,610
much anything productionize we

01:23:25,110 --> 01:23:29,130
definitely want to readiness check right

01:23:26,610 --> 01:23:31,619
Cassandra a great readiness check is

01:23:29,130 --> 01:23:35,190
like does node tool think you're part of

01:23:31,619 --> 01:23:36,750
the ring as an example health checks can

01:23:35,190 --> 01:23:38,820
actually kind of hurt more than they can

01:23:36,750 --> 01:23:41,340
help sometimes because it's right it's

01:23:38,820 --> 01:23:42,750
like do you you know you a great example

01:23:41,340 --> 01:23:43,739
is like elastic we were finding the

01:23:42,750 --> 01:23:44,340
health checks were actually really

01:23:43,739 --> 01:23:48,000
annoying for

01:23:44,340 --> 01:23:49,770
stick because you might have a bad GC

01:23:48,000 --> 01:23:51,330
like your GC is might overtime line up

01:23:49,770 --> 01:23:52,860
and then suddenly you don't have like

01:23:51,330 --> 01:23:54,239
availability on the data thing and then

01:23:52,860 --> 01:23:55,590
like wait it starts killing nodes and

01:23:54,239 --> 01:23:58,110
you're like wait a second no no it would

01:23:55,590 --> 01:24:00,690
have been fine just leave it so in terms

01:23:58,110 --> 01:24:02,550
of yeah health checks can be kind of a

01:24:00,690 --> 01:24:04,530
double-edged sword you can do custom

01:24:02,550 --> 01:24:06,360
recovery so in terms of you can write

01:24:04,530 --> 01:24:08,250
some Java to have custom recovery around

01:24:06,360 --> 01:24:10,739
specific node types things like that I

01:24:08,250 --> 01:24:14,280
gave the example of Cassandra cockroach

01:24:10,739 --> 01:24:18,690
DB for theirs they have a bit of extra

01:24:14,280 --> 01:24:21,150
logic around like are you a the master

01:24:18,690 --> 01:24:23,369
or one of the replicas and then the same

01:24:21,150 --> 01:24:24,690
deal for like initial start I think is a

01:24:23,369 --> 01:24:28,110
little bit different than if it's being

01:24:24,690 --> 01:24:29,520
brought back resource sets I talked

01:24:28,110 --> 01:24:31,020
about the didn't show an example of some

01:24:29,520 --> 01:24:33,000
resource sets or the idea of you to find

01:24:31,020 --> 01:24:35,010
a resource set at the pod level and then

01:24:33,000 --> 01:24:36,960
tasks can share that resource set they

01:24:35,010 --> 01:24:38,400
cannot use it at the same time but it's

01:24:36,960 --> 01:24:40,159
essentially a way to have lots and lots

01:24:38,400 --> 01:24:44,580
of tasks with a relatively small

01:24:40,159 --> 01:24:46,139
resource footprint for a pod operator

01:24:44,580 --> 01:24:48,540
friendly tools so you saw the api's

01:24:46,139 --> 01:24:51,300
around sort of pod management plan

01:24:48,540 --> 01:24:56,639
management in points I should show in

01:24:51,300 --> 01:24:58,320
points let's see so in points right if I

01:24:56,639 --> 01:25:01,530
want to actually connect and do

01:24:58,320 --> 01:25:03,739
something meaningful and then how I do

01:25:01,530 --> 01:25:03,739
that

01:25:08,520 --> 01:25:11,690
why are you sad

01:25:44,100 --> 01:25:50,680
thank you I like to think I would have

01:25:49,150 --> 01:26:10,840
actually figured it out but I probably

01:25:50,680 --> 01:26:13,620
wouldn't have I don't know here and tell

01:26:10,840 --> 01:26:13,620
me what the commander

01:26:29,330 --> 01:26:38,180
okay all right so in points you just

01:26:33,230 --> 01:26:41,120
have one memcache so you can see here

01:26:38,180 --> 01:26:43,960
provides all of the IP addresses and the

01:26:41,120 --> 01:26:46,370
DNS Oh a feature that I didn't show so

01:26:43,960 --> 01:26:48,230
DCOs has a concept of a VIP like a

01:26:46,370 --> 01:26:50,720
virtual IP it's just a load balance IP

01:26:48,230 --> 01:26:52,160
address you can use one of those like

01:26:50,720 --> 01:26:53,870
obviously a lot of data services don't

01:26:52,160 --> 01:26:54,650
necessarily consume those because data

01:26:53,870 --> 01:26:56,420
services

01:26:54,650 --> 01:26:58,160
the clients are pretty smart they want

01:26:56,420 --> 01:26:59,420
to know all the IP addresses of everyone

01:26:58,160 --> 01:27:01,670
they can talk to and then they do their

01:26:59,420 --> 01:27:07,240
own client-side logic but you definitely

01:27:01,670 --> 01:27:10,220
use them if you want to get cool

01:27:07,240 --> 01:27:11,420
sidecars the ability to find tasks that

01:27:10,220 --> 01:27:13,220
can then be run in their own little

01:27:11,420 --> 01:27:15,050
plans as additional maintenance or

01:27:13,220 --> 01:27:16,880
operational procedures placement

01:27:15,050 --> 01:27:19,640
constraints so we have full support of

01:27:16,880 --> 01:27:22,280
the sort of marathon style placement

01:27:19,640 --> 01:27:23,690
constraints so in terms of like hostname

01:27:22,280 --> 01:27:25,340
unique is kind of the default one that

01:27:23,690 --> 01:27:27,140
we always have because like hey data

01:27:25,340 --> 01:27:29,660
services like shouldn't land on the same

01:27:27,140 --> 01:27:31,190
host you can do things like haven't

01:27:29,660 --> 01:27:32,900
matched a regex of host names let's say

01:27:31,190 --> 01:27:34,640
you have specific storage instances you

01:27:32,900 --> 01:27:35,660
want your database to land on you would

01:27:34,640 --> 01:27:37,250
just put in a regex

01:27:35,660 --> 01:27:39,110
that'll match the right host names you

01:27:37,250 --> 01:27:41,630
could always have the brute force regex

01:27:39,110 --> 01:27:44,300
of like this host name or this one or

01:27:41,630 --> 01:27:45,860
this one configuration template as you

01:27:44,300 --> 01:27:48,170
saw the ability to template out

01:27:45,860 --> 01:27:51,260
configuration files just like you would

01:27:48,170 --> 01:27:54,740
with chef or puppet or others so rolling

01:27:51,260 --> 01:27:57,650
updates right so anytime you update the

01:27:54,740 --> 01:27:59,390
scheduler with a new configuration it is

01:27:57,650 --> 01:28:01,460
going to dip it it's going to see hey

01:27:59,390 --> 01:28:03,290
how do I move to that new state it's

01:28:01,460 --> 01:28:05,000
going to proceed in a safe manner to

01:28:03,290 --> 01:28:06,740
that new state basically dependent on

01:28:05,000 --> 01:28:08,330
whatever the update plan is or if there

01:28:06,740 --> 01:28:12,410
is no update plan it will follow the

01:28:08,330 --> 01:28:14,330
deploy plan rolling upgrades so that's

01:28:12,410 --> 01:28:16,370
binaries right same deal where the diff

01:28:14,330 --> 01:28:18,230
is that like hey the binaries changed

01:28:16,370 --> 01:28:19,970
like it's got a new URL that's supposed

01:28:18,230 --> 01:28:22,460
to download Java from so let's roll out

01:28:19,970 --> 01:28:25,070
the new Java to Cassandra we have

01:28:22,460 --> 01:28:28,130
support for GPUs so if your cluster has

01:28:25,070 --> 01:28:30,950
GPUs we can use them yay

01:28:28,130 --> 01:28:33,440
fine grained plan control so you can

01:28:30,950 --> 01:28:35,570
both define relatively complex plans

01:28:33,440 --> 01:28:37,970
there are api's I didn't show for

01:28:35,570 --> 01:28:38,990
interacting with plans around both sort

01:28:37,970 --> 01:28:40,580
of getting yourself out of sticky

01:28:38,990 --> 01:28:41,559
situations where you can force complete

01:28:40,580 --> 01:28:44,289
path steps

01:28:41,559 --> 01:28:47,110
or stopping and starting plans things

01:28:44,289 --> 01:28:48,460
like that there's some different there

01:28:47,110 --> 01:28:49,690
are two additional strategies I didn't

01:28:48,460 --> 01:28:51,570
show plus you can write your own custom

01:28:49,690 --> 01:28:54,309
strategies but those strategies are

01:28:51,570 --> 01:28:56,079
canary serial and canary parallel and

01:28:54,309 --> 01:28:58,599
the strategies they're basically mean do

01:28:56,079 --> 01:28:59,889
one and then wait until I tell you to do

01:28:58,599 --> 01:29:01,090
the next one right so that's a great

01:28:59,889 --> 01:29:03,039
candidate for like I'm going you do

01:29:01,090 --> 01:29:05,650
configuration update of Kafka I should

01:29:03,039 --> 01:29:07,389
try one right like I did it in staging

01:29:05,650 --> 01:29:11,679
but like let's try one in production

01:29:07,389 --> 01:29:15,280
before we hop on forward in the e we

01:29:11,679 --> 01:29:17,440
have deep support for secrets in DCOs we

01:29:15,280 --> 01:29:19,809
also have support for security so DCOs

01:29:17,440 --> 01:29:22,840
Enterprise has strict mode which is

01:29:19,809 --> 01:29:25,750
basically enforces a bunch of ACLs both

01:29:22,840 --> 01:29:26,500
in mezzos and DC Westland and then

01:29:25,750 --> 01:29:29,110
finally an EE

01:29:26,500 --> 01:29:30,340
we have automated TLS provisioning right

01:29:29,110 --> 01:29:33,280
so that's the base to be able to say

01:29:30,340 --> 01:29:34,289
like I want a TLS certificate with the

01:29:33,280 --> 01:29:36,849
right

01:29:34,289 --> 01:29:40,840
tl these for my tasks and that kind of

01:29:36,849 --> 01:29:45,030
thing so what did I not talk about so

01:29:40,840 --> 01:29:49,659
there is no horizontal scaling sorry

01:29:45,030 --> 01:29:52,239
yeah I know yes you guys never get to

01:29:49,659 --> 01:29:56,440
leave all right horizontal scale in so

01:29:52,239 --> 01:29:58,179
we horizontal scale it's tough harder to

01:29:56,440 --> 01:29:59,860
scale down right some services I don't

01:29:58,179 --> 01:30:02,739
even know what that means to say scale

01:29:59,860 --> 01:30:04,630
down some are like kind of easy and like

01:30:02,739 --> 01:30:05,889
well you know at a future date the SDK

01:30:04,630 --> 01:30:08,020
will build the primitives to make this

01:30:05,889 --> 01:30:11,199
possible but it's not something we

01:30:08,020 --> 01:30:13,690
support today racks support for racks is

01:30:11,199 --> 01:30:16,690
in mezzos we're working on like I think

01:30:13,690 --> 01:30:18,400
support for racks and DCOs is like a PR

01:30:16,690 --> 01:30:20,050
that's gonna close and then like we're

01:30:18,400 --> 01:30:21,670
gonna add racks and be great

01:30:20,050 --> 01:30:23,710
graceful shutdown we like sort of have

01:30:21,670 --> 01:30:25,900
it done but not in a way that people

01:30:23,710 --> 01:30:28,329
should use yet so that's right graceful

01:30:25,900 --> 01:30:30,940
shutdown is like send a signal that is

01:30:28,329 --> 01:30:32,770
agreed upon and then wait some amount of

01:30:30,940 --> 01:30:34,710
time and then send the other signal that

01:30:32,770 --> 01:30:38,699
means like no you actually die now

01:30:34,710 --> 01:30:41,170
external volumes like R X ray CSI so CSI

01:30:38,699 --> 01:30:42,909
that we're gonna sort of skip the Rex

01:30:41,170 --> 01:30:45,219
rays of the world and go right to CSI

01:30:42,909 --> 01:30:46,480
right like when CSI is done so container

01:30:45,219 --> 01:30:48,159
storage interface from that kind of

01:30:46,480 --> 01:30:51,070
stuff is done when port works and others

01:30:48,159 --> 01:30:53,559
implement it we will consume it to allow

01:30:51,070 --> 01:30:54,780
you to provision volumes on the fly for

01:30:53,559 --> 01:30:57,099
persistence and things like that

01:30:54,780 --> 01:30:58,900
stateless pods - sort of the idea of

01:30:57,099 --> 01:31:00,460
like having a pod that is a bit more

01:30:58,900 --> 01:31:02,590
ephemeral that's kind of coupled in some

01:31:00,460 --> 01:31:05,050
ways to scale in but it's useful for

01:31:02,590 --> 01:31:07,179
things like analytics stuff like that we

01:31:05,050 --> 01:31:09,460
also don't integrate with the

01:31:07,179 --> 01:31:12,389
maintenance primitives Amazo so yet

01:31:09,460 --> 01:31:16,239
I think no one sort of does supposedly

01:31:12,389 --> 01:31:19,840
one framework does but maybe we'll be

01:31:16,239 --> 01:31:22,270
the second one so yeah I think that's

01:31:19,840 --> 01:31:23,619
oh yeah the SDK seems real big this is

01:31:22,270 --> 01:31:27,219
actually the order in which people

01:31:23,619 --> 01:31:29,590
joined the team I haven't done that much

01:31:27,219 --> 01:31:31,300
of the SDK Gabriel right there everyone

01:31:29,590 --> 01:31:33,579
also asked him questions after this he

01:31:31,300 --> 01:31:35,679
is the first person on this list just to

01:31:33,579 --> 01:31:36,760
put him on the spot he also had a talk

01:31:35,679 --> 01:31:37,989
earlier if you want to watch the

01:31:36,760 --> 01:31:39,280
recording of that he's also got to talk

01:31:37,989 --> 01:31:41,530
to him last year kind of talking about

01:31:39,280 --> 01:31:42,520
like his talk from last year's like here

01:31:41,530 --> 01:31:43,809
are the principles of what we're going

01:31:42,520 --> 01:31:47,020
to build a nothing is here it was like

01:31:43,809 --> 01:31:52,119
we built it so yeah I think that's that

01:31:47,020 --> 01:31:53,770
is it does anybody have questions or do

01:31:52,119 --> 01:31:56,309
you just want to leave because this was

01:31:53,770 --> 01:31:56,309
very boring

01:32:10,230 --> 01:32:20,650
right right yeah so the question is will

01:32:18,040 --> 01:32:22,150
the SDK at some point support some sort

01:32:20,650 --> 01:32:27,310
of format that would let you run it on

01:32:22,150 --> 01:32:29,680
vanilla mezzos right so you get pretty

01:32:27,310 --> 01:32:31,270
close today like you could just do it on

01:32:29,680 --> 01:32:32,770
merit right so what does cosmos do

01:32:31,270 --> 01:32:34,690
cosmos basically just lets you define

01:32:32,770 --> 01:32:36,880
these options files that then get

01:32:34,690 --> 01:32:38,770
template into a marathon app if you just

01:32:36,880 --> 01:32:40,120
sort of handwrite the marathon app that

01:32:38,770 --> 01:32:42,940
has the you know sort of scheduled

01:32:40,120 --> 01:32:44,080
library the part that is missing is DNS

01:32:42,940 --> 01:32:46,180
right

01:32:44,080 --> 01:32:48,280
you aren't guaranteed with vanilla like

01:32:46,180 --> 01:32:49,840
vanilla mezzos great doesn't come with a

01:32:48,280 --> 01:32:50,980
lot like it's a very good hardware

01:32:49,840 --> 01:32:56,490
abstraction but it's kind of missing

01:32:50,980 --> 01:32:56,490
like DNS that's the big one night CNI

01:33:03,510 --> 01:33:16,960
maybe I don't think we wouldn't

01:33:06,160 --> 01:33:18,370
integrate with that right today yeah I

01:33:16,960 --> 01:33:19,720
mean I would say if the community comes

01:33:18,370 --> 01:33:20,830
up with a solution that would definitely

01:33:19,720 --> 01:33:23,430
be meat

01:33:20,830 --> 01:33:25,450
it is not on our near-term roadmap

01:33:23,430 --> 01:33:26,650
because everything right I think it runs

01:33:25,450 --> 01:33:35,160
on top of open DCOs

01:33:26,650 --> 01:33:35,160
so yeah other questions yes sir

01:33:36,540 --> 01:33:41,680
yeah wreck awareness the ability to say

01:33:39,010 --> 01:33:43,660
like hey like so the question was like

01:33:41,680 --> 01:33:45,300
what do I mean by racks so with

01:33:43,660 --> 01:33:47,800
Cassandra right like you don't want

01:33:45,300 --> 01:33:50,230
cassandra nodes on the same rack for

01:33:47,800 --> 01:33:51,490
sufficient availability so you would

01:33:50,230 --> 01:33:53,560
want to be able to define like what does

01:33:51,490 --> 01:33:55,180
a rack mean Maysles has support for

01:33:53,560 --> 01:33:57,460
being able to say like this agent is on

01:33:55,180 --> 01:33:59,260
this rack that support we just need it

01:33:57,460 --> 01:34:01,630
to exist in DCOs and then we'll consume

01:33:59,260 --> 01:34:03,310
it and obviously have like some default

01:34:01,630 --> 01:34:05,790
constraints of like don't put it on the

01:34:03,310 --> 01:34:05,790
same racks

01:34:11,610 --> 01:34:16,120
yeah yeah yeah you can do it today like

01:34:14,380 --> 01:34:18,070
right like attributes are sort of the

01:34:16,120 --> 01:34:22,170
Shem and then like mezzos has added

01:34:18,070 --> 01:34:22,170
racks as like a first class concept

01:34:23,340 --> 01:34:32,600
other folks okay

01:34:29,830 --> 01:34:33,160
I release you to leave

01:34:32,600 --> 01:34:36,680
[Applause]

01:34:33,160 --> 01:34:36,680

YouTube URL: https://www.youtube.com/watch?v=nSxp5mpuv3Y


