Title: Distributed Data on Distributed Infrastructure
Publication date: 2017-09-18
Playlist: MesosCon North America 2017
Description: 
	Distributed Data on Distributed Infrastructure - Jörg Schad, Mesosphere; Claudius Weinberger & Kunal Kusoorkar, ArangoDB

About


Jörg Schad
Software Engineer, Mesosphere
Jörg is a software engineer at Mesosphere in Hamburg. In his previous life he implemented distributed and in memory databases and conducted research in the Hadoop and Cloud area. His speaking experience includes various Meetups, international conferences, and lecture halls.

Claudius Weinberger
ArangoDB GmbH, CEO

Kunal Kusoorkar
Captions: 
	00:00:02,570 --> 00:00:08,580
okay I guess we are ready to go camera

00:00:06,569 --> 00:00:11,670
seems to be on it's blinking red so

00:00:08,580 --> 00:00:15,299
let's get started yeah welcome to our

00:00:11,670 --> 00:00:19,529
talk which is going to be about Arango

00:00:15,299 --> 00:00:21,869
DB running on Mesa so maybe just as the

00:00:19,529 --> 00:00:24,539
background information for the history

00:00:21,869 --> 00:00:27,480
of Rango DB and missus it's been like a

00:00:24,539 --> 00:00:29,939
really long relationship and those guys

00:00:27,480 --> 00:00:32,279
have been really really helpful in

00:00:29,939 --> 00:00:34,140
helping us to develop stateful

00:00:32,279 --> 00:00:35,760
frameworks because they were basically

00:00:34,140 --> 00:00:38,910
the first framework who were really

00:00:35,760 --> 00:00:41,040
running on those stateful primitives in

00:00:38,910 --> 00:00:42,719
Miso's and you'll also see more about

00:00:41,040 --> 00:00:44,340
that throughout the presentation but

00:00:42,719 --> 00:00:46,280
this is kind of like well we have a

00:00:44,340 --> 00:00:48,480
really close relationship between

00:00:46,280 --> 00:00:51,059
mesosphere DCOs

00:00:48,480 --> 00:00:54,350
and missiles and see Arango guys and

00:00:51,059 --> 00:00:57,149
this is actually also why I'm here I'm

00:00:54,350 --> 00:00:59,520
York with mesosphere you might have seen

00:00:57,149 --> 00:01:02,160
me this morning already and I'll gives

00:00:59,520 --> 00:01:06,240
this presentation together with Kunal

00:01:02,160 --> 00:01:09,409
and Claudius from Arango DB and I would

00:01:06,240 --> 00:01:10,670
actually do you want to get started sure

00:01:09,409 --> 00:01:13,350
thank you

00:01:10,670 --> 00:01:15,570
hello everyone and good afternoon my

00:01:13,350 --> 00:01:18,780
name is Kunal kusudama deliver solutions

00:01:15,570 --> 00:01:22,200
engineering at Arango DB I joined pretty

00:01:18,780 --> 00:01:24,509
recently but I have a history of working

00:01:22,200 --> 00:01:27,330
in the no sequel Big Data events

00:01:24,509 --> 00:01:30,030
processing messaging yes B es bees over

00:01:27,330 --> 00:01:35,430
my career last 12 years so with that let

00:01:30,030 --> 00:01:38,759
me quickly give it to you sure yes my

00:01:35,430 --> 00:01:41,189
name Clara's Weinberger I'm the CEO of I

00:01:38,759 --> 00:01:44,100
wanna to be I have founded the company

00:01:41,189 --> 00:01:46,649
together with my co-founder four years

00:01:44,100 --> 00:01:50,060
ago but we started the project let's say

00:01:46,649 --> 00:01:53,670
five five five and a half years ago and

00:01:50,060 --> 00:01:55,590
we building databases now for 18 years

00:01:53,670 --> 00:01:59,640
so we did a lot of different stuff

00:01:55,590 --> 00:02:02,100
customer customized solutions and so on

00:01:59,640 --> 00:02:04,259
and 2012 we sit together and thought

00:02:02,100 --> 00:02:06,119
about shop we built another database

00:02:04,259 --> 00:02:08,520
there are already a few on the market

00:02:06,119 --> 00:02:10,800
but you will see later that we found

00:02:08,520 --> 00:02:11,610
something what we call the native

00:02:10,800 --> 00:02:14,310
multimode

00:02:11,610 --> 00:02:17,250
what's mean from our perspective add

00:02:14,310 --> 00:02:22,230
something new to the market and gives

00:02:17,250 --> 00:02:24,960
more possibilities Thank You Claudius so

00:02:22,230 --> 00:02:28,650
let me start off by asking a question

00:02:24,960 --> 00:02:36,020
why distributed data to begin of it

00:02:28,650 --> 00:02:38,970
can anybody good ok huh

00:02:36,020 --> 00:02:40,680
perfect so why distributed data that's

00:02:38,970 --> 00:02:42,900
the question I really want to start this

00:02:40,680 --> 00:02:44,760
conversation off with of course the

00:02:42,900 --> 00:02:46,290
topic of today is distributed data on

00:02:44,760 --> 00:02:48,260
distributed infrastructure so I'm taking

00:02:46,290 --> 00:02:50,790
the first part and starting off there

00:02:48,260 --> 00:02:53,640
the question really stems from the

00:02:50,790 --> 00:02:55,440
challenge that what we saw over the last

00:02:53,640 --> 00:02:57,300
decade or so if you see an track history

00:02:55,440 --> 00:03:00,150
what you would see is we have seen a

00:02:57,300 --> 00:03:02,250
significant amount of growth in global

00:03:00,150 --> 00:03:05,550
web cloud deployments and mobile

00:03:02,250 --> 00:03:07,500
applications and that brought with it

00:03:05,550 --> 00:03:10,620
over period of the next I would say over

00:03:07,500 --> 00:03:13,230
the last decade plus it brought an

00:03:10,620 --> 00:03:16,830
unprecedented amount of data with it

00:03:13,230 --> 00:03:18,959
in terms of volume in terms of velocity

00:03:16,830 --> 00:03:21,299
and in terms of variety and a

00:03:18,959 --> 00:03:22,890
combination of those together brought in

00:03:21,299 --> 00:03:25,290
a certain level of combination pressure

00:03:22,890 --> 00:03:27,630
that really pressure our existing

00:03:25,290 --> 00:03:29,100
database systems in other words the

00:03:27,630 --> 00:03:30,780
database systems that we know the

00:03:29,100 --> 00:03:32,790
relational databases that we know and

00:03:30,780 --> 00:03:35,250
have worked well oily for us for a long

00:03:32,790 --> 00:03:38,400
time were just not suited because they

00:03:35,250 --> 00:03:39,870
were not made for it they exist the

00:03:38,400 --> 00:03:42,570
newer applications that we were building

00:03:39,870 --> 00:03:44,880
had a completely different requirements

00:03:42,570 --> 00:03:50,400
in terms of these three V's and any and

00:03:44,880 --> 00:03:52,739
all combinations there off so what was

00:03:50,400 --> 00:03:54,600
the frustration and then what happened

00:03:52,739 --> 00:03:57,450
overall was the attempts as it always

00:03:54,600 --> 00:03:59,100
happens is to figure out how are we

00:03:57,450 --> 00:04:01,110
going to solve that problem what do we

00:03:59,100 --> 00:04:03,840
do to solve the three V's problems that

00:04:01,110 --> 00:04:06,510
we have no matter how much hardware you

00:04:03,840 --> 00:04:08,610
give or how much you optimize it the

00:04:06,510 --> 00:04:10,950
monolithic backends just wouldn't scale

00:04:08,610 --> 00:04:12,510
up to that challenge to solve it they

00:04:10,950 --> 00:04:14,280
were made for a different era with a

00:04:12,510 --> 00:04:17,070
different purpose for different systems

00:04:14,280 --> 00:04:19,470
that were siloed at that time and to

00:04:17,070 --> 00:04:21,359
work on a limited data set overall they

00:04:19,470 --> 00:04:23,220
were really not made for voluminous data

00:04:21,359 --> 00:04:25,540
they were not made for a variety of data

00:04:23,220 --> 00:04:28,540
they were not made for a data with high

00:04:25,540 --> 00:04:32,110
Rupert and Hyde amount of reads that is

00:04:28,540 --> 00:04:34,690
essentially then at that point what was

00:04:32,110 --> 00:04:37,210
realized well the solution really lies

00:04:34,690 --> 00:04:39,700
in a way to think different to think

00:04:37,210 --> 00:04:41,920
what is really the missing thought to

00:04:39,700 --> 00:04:43,360
solve that problem and distribution was

00:04:41,920 --> 00:04:46,150
that answer and following that

00:04:43,360 --> 00:04:47,620
distributed data fundamentally what

00:04:46,150 --> 00:04:49,240
solved that problem are what really

00:04:47,620 --> 00:04:52,030
attempts to solve the problem now in the

00:04:49,240 --> 00:04:54,130
modern world is a database is a native

00:04:52,030 --> 00:04:56,560
multi model database that will fulfill

00:04:54,130 --> 00:04:59,800
that will provide a solution in three

00:04:56,560 --> 00:05:02,920
ways one be able to store and serve a

00:04:59,800 --> 00:05:05,800
variety of data that's the word multi

00:05:02,920 --> 00:05:07,750
model meaning you should be able to

00:05:05,800 --> 00:05:09,820
store any kind of data the new

00:05:07,750 --> 00:05:12,310
applications the web applications mobile

00:05:09,820 --> 00:05:13,630
applications they're not really just

00:05:12,310 --> 00:05:15,310
working on relational data they're

00:05:13,630 --> 00:05:17,200
working on documents they're working on

00:05:15,310 --> 00:05:20,500
key value stores they're working on

00:05:17,200 --> 00:05:23,230
graph data and all of that data needs to

00:05:20,500 --> 00:05:26,130
be used continuously as the applications

00:05:23,230 --> 00:05:29,680
are being built and as they evolve and

00:05:26,130 --> 00:05:31,480
also between them which means you at one

00:05:29,680 --> 00:05:34,600
given day your application might want to

00:05:31,480 --> 00:05:37,180
just use a lot of document stores on a

00:05:34,600 --> 00:05:38,830
given month or after few cycles of

00:05:37,180 --> 00:05:40,390
development where you realize well my

00:05:38,830 --> 00:05:41,920
data is more connected it's more

00:05:40,390 --> 00:05:43,630
relationship I'm trying to analyze

00:05:41,920 --> 00:05:45,700
relationships more than query entities

00:05:43,630 --> 00:05:48,790
well I need to switch to a graph data

00:05:45,700 --> 00:05:50,110
model the existing databases just don't

00:05:48,790 --> 00:05:52,420
allow you to do that you need a

00:05:50,110 --> 00:05:54,670
fundamentally new database that's at the

00:05:52,420 --> 00:05:56,800
core design for it organically and

00:05:54,670 --> 00:05:59,650
that's the word that is what makes it

00:05:56,800 --> 00:06:01,870
organic multi model native multi model

00:05:59,650 --> 00:06:03,250
database which will support documents

00:06:01,870 --> 00:06:05,620
which will support key value stores

00:06:03,250 --> 00:06:08,290
which will support graph data structures

00:06:05,620 --> 00:06:10,540
to begin with that is the first way to

00:06:08,290 --> 00:06:12,850
solve the variety of data problem now

00:06:10,540 --> 00:06:14,740
once we attack that the second is the

00:06:12,850 --> 00:06:16,870
ability to scale out across multiple

00:06:14,740 --> 00:06:19,750
machines to handle the velocity needed

00:06:16,870 --> 00:06:21,580
to handle the generally great amount of

00:06:19,750 --> 00:06:23,050
throughput that's asked of you to solve

00:06:21,580 --> 00:06:24,820
the number of write operations and

00:06:23,050 --> 00:06:27,220
number of read operations in a given day

00:06:24,820 --> 00:06:29,620
you need to be able to be up for that

00:06:27,220 --> 00:06:31,890
challenge of solving third one is the

00:06:29,620 --> 00:06:34,720
ability to spread out across machines

00:06:31,890 --> 00:06:37,120
when you need to handle volumes your

00:06:34,720 --> 00:06:38,590
data set is not going to stay the same

00:06:37,120 --> 00:06:38,980
when you start your bill mobile business

00:06:38,590 --> 00:06:41,080
or

00:06:38,980 --> 00:06:42,280
business and two years down four years

00:06:41,080 --> 00:06:43,960
down you're going to see exponential

00:06:42,280 --> 00:06:46,900
growth in the amount of data you're

00:06:43,960 --> 00:06:48,880
handling and you cannot solve that by

00:06:46,900 --> 00:06:50,890
scaling up machines giving more memory

00:06:48,880 --> 00:06:53,440
to you know make by bigger machines and

00:06:50,890 --> 00:06:55,300
absorb a higher cost of ownership you

00:06:53,440 --> 00:06:57,400
need to spread it out spread the data

00:06:55,300 --> 00:06:59,920
out over commodity Hardware on multiple

00:06:57,400 --> 00:07:01,810
machines and tackle the volume problem

00:06:59,920 --> 00:07:03,490
as well and this database exactly

00:07:01,810 --> 00:07:09,160
attempts to do that by attacking the

00:07:03,490 --> 00:07:12,370
very need of distributed data with that

00:07:09,160 --> 00:07:13,750
let me introduce Arango DB so as I spoke

00:07:12,370 --> 00:07:16,120
those were the characteristics the

00:07:13,750 --> 00:07:18,070
challenges the realizations upon

00:07:16,120 --> 00:07:20,950
frustrations and the solution approach a

00:07:18,070 --> 00:07:22,600
database like rango DB defines it we

00:07:20,950 --> 00:07:25,180
start off with that value proposition

00:07:22,600 --> 00:07:27,040
attacking that problem a native multi

00:07:25,180 --> 00:07:29,710
modal database that will provide a

00:07:27,040 --> 00:07:31,930
unified declarative query language a

00:07:29,710 --> 00:07:34,300
simple words a single query language to

00:07:31,930 --> 00:07:36,340
query graph information to query

00:07:34,300 --> 00:07:38,170
document information to carry key value

00:07:36,340 --> 00:07:40,350
information whatever information you

00:07:38,170 --> 00:07:42,700
store at a database in the database

00:07:40,350 --> 00:07:44,950
scalable and highly available with

00:07:42,700 --> 00:07:47,440
configurable consistency at times you

00:07:44,950 --> 00:07:49,330
need acidity you need strong consistency

00:07:47,440 --> 00:07:51,490
other times you're probably okay with

00:07:49,330 --> 00:07:54,010
asynchronous replication you're okay

00:07:51,490 --> 00:07:55,300
with getting a dirty read back because

00:07:54,010 --> 00:07:56,800
that's what your application needs at

00:07:55,300 --> 00:07:59,380
that time and you should be able to tune

00:07:56,800 --> 00:08:02,170
and change it as you need extensibility

00:07:59,380 --> 00:08:04,990
and then lastly I would say ability to

00:08:02,170 --> 00:08:08,050
expose your database operations over a

00:08:04,990 --> 00:08:10,090
microservice framework the ability your

00:08:08,050 --> 00:08:12,160
mobile applications web applications

00:08:10,090 --> 00:08:15,190
they need they are essentially built

00:08:12,160 --> 00:08:17,200
with the idea of microservices your data

00:08:15,190 --> 00:08:20,050
tier over over these years have not

00:08:17,200 --> 00:08:22,240
evolved as much Arango DB solves that we

00:08:20,050 --> 00:08:25,180
expose the database operations using an

00:08:22,240 --> 00:08:27,520
HTTP REST API and that API is also

00:08:25,180 --> 00:08:29,650
extensible using the Fox micro service

00:08:27,520 --> 00:08:32,440
framework and you can write service

00:08:29,650 --> 00:08:34,570
manifest that will go and push directly

00:08:32,440 --> 00:08:36,640
the information you write and read from

00:08:34,570 --> 00:08:40,090
the database exposed as micro services

00:08:36,640 --> 00:08:42,669
all together really becomes a modern

00:08:40,090 --> 00:08:44,910
database that you can use to service

00:08:42,669 --> 00:08:47,890
your micro services based applications

00:08:44,910 --> 00:08:49,450
I'll take a brief pause here before I go

00:08:47,890 --> 00:08:51,610
a little bit deeper explain each of

00:08:49,450 --> 00:08:52,420
these features to you any questions I

00:08:51,610 --> 00:08:53,740
can

00:08:52,420 --> 00:08:59,500
answer in the meanwhile any quick

00:08:53,740 --> 00:09:02,590
questions alright so multi-model I'll go

00:08:59,500 --> 00:09:04,360
ahead and explain what I mean by that as

00:09:02,590 --> 00:09:07,210
I was talking about different kinds the

00:09:04,360 --> 00:09:08,530
V the variety of data these are all the

00:09:07,210 --> 00:09:10,750
different types that we have in the

00:09:08,530 --> 00:09:12,430
market right now there are point

00:09:10,750 --> 00:09:14,320
solutions to solve wine problems

00:09:12,430 --> 00:09:16,180
historically like we have seen the

00:09:14,320 --> 00:09:18,640
relational world right relational tables

00:09:16,180 --> 00:09:21,490
that were built to solve order systems

00:09:18,640 --> 00:09:23,590
catalog systems but there were other

00:09:21,490 --> 00:09:25,240
data types that evolved there were

00:09:23,590 --> 00:09:27,640
documents there were graphs they were

00:09:25,240 --> 00:09:29,320
column nor stores time series key value

00:09:27,640 --> 00:09:29,890
databases all of these different kinds

00:09:29,320 --> 00:09:33,100
of model

00:09:29,890 --> 00:09:35,500
Arango DB is an attempt to solve that

00:09:33,100 --> 00:09:37,600
problem really well and we have taken

00:09:35,500 --> 00:09:39,970
the approach to solve B at native multi

00:09:37,600 --> 00:09:43,420
model database just due to three things

00:09:39,970 --> 00:09:45,040
really well absorb graph like

00:09:43,420 --> 00:09:47,500
information and serve it back really

00:09:45,040 --> 00:09:50,410
well absorb documents absorb key value

00:09:47,500 --> 00:09:52,810
stores all in a single deployment

00:09:50,410 --> 00:09:55,180
artifact and what I mean by that is a

00:09:52,810 --> 00:09:57,130
single engine a single demon that will

00:09:55,180 --> 00:10:00,220
encapsulate all this functionality and

00:09:57,130 --> 00:10:02,410
also provide you the freedom to run on

00:10:00,220 --> 00:10:05,470
all of this on a scale out

00:10:02,410 --> 00:10:07,180
infrastructure which mesos can handle so

00:10:05,470 --> 00:10:08,980
what do you get with it you get a

00:10:07,180 --> 00:10:11,830
unified query language for all these

00:10:08,980 --> 00:10:14,560
models you get a clutter free simplified

00:10:11,830 --> 00:10:17,130
cluster deployment scaling you get a

00:10:14,560 --> 00:10:19,510
native multi modal advantage overall and

00:10:17,130 --> 00:10:21,010
what it gives you from a developer

00:10:19,510 --> 00:10:22,390
standpoint what's the advantage what's

00:10:21,010 --> 00:10:24,670
the value that you're going to get out

00:10:22,390 --> 00:10:26,920
of it a significantly reduced

00:10:24,670 --> 00:10:29,170
operational moving part overhead right

00:10:26,920 --> 00:10:30,370
there is not much of an operational

00:10:29,170 --> 00:10:32,380
trouble that you will have to deal with

00:10:30,370 --> 00:10:35,110
unlike systems that you have seen

00:10:32,380 --> 00:10:36,160
probably there is Hadoop zookeeper most

00:10:35,110 --> 00:10:38,080
of these if you are familiar with these

00:10:36,160 --> 00:10:40,660
technologies bring in a lot of

00:10:38,080 --> 00:10:42,910
operational clutter even databases like

00:10:40,660 --> 00:10:45,340
Cassandra and others they will bring a

00:10:42,910 --> 00:10:47,050
lot of operational pain for you to to

00:10:45,340 --> 00:10:48,190
deal with or period of time we attempt

00:10:47,050 --> 00:10:50,560
to solve that with that with a

00:10:48,190 --> 00:10:52,750
simplified artifact that you can deploy

00:10:50,560 --> 00:10:54,670
and deploy across multiple machines and

00:10:52,750 --> 00:10:56,860
still serve the same workloads without

00:10:54,670 --> 00:11:00,040
you having to create a new point

00:10:56,860 --> 00:11:01,960
solution every single time faster

00:11:00,040 --> 00:11:03,790
development cycles with a unified query

00:11:01,960 --> 00:11:05,800
language a single query language you can

00:11:03,790 --> 00:11:06,160
query all the information stored in all

00:11:05,800 --> 00:11:08,230
these

00:11:06,160 --> 00:11:11,259
friend types and even joined them with a

00:11:08,230 --> 00:11:13,209
simple pseudocode like language that's a

00:11:11,259 --> 00:11:14,800
huge advantage from a development cycle

00:11:13,209 --> 00:11:18,550
from a time to development perspective

00:11:14,800 --> 00:11:21,040
and lastly Richard quality applications

00:11:18,550 --> 00:11:23,259
with multi model with attacking three

00:11:21,040 --> 00:11:25,389
V's that we spoke about you will

00:11:23,259 --> 00:11:27,250
definitely get an overall advantage in

00:11:25,389 --> 00:11:28,899
terms of building a high quality mobile

00:11:27,250 --> 00:11:30,550
application because you have a micro

00:11:28,899 --> 00:11:32,889
services layer that's really at a data

00:11:30,550 --> 00:11:34,389
tier you don't have to deal with it have

00:11:32,889 --> 00:11:36,160
to work with it at an application or a

00:11:34,389 --> 00:11:37,899
front-end side it's really done at a

00:11:36,160 --> 00:11:39,459
data to your side for it scaled

00:11:37,899 --> 00:11:41,860
accordingly as we will scale the data

00:11:39,459 --> 00:11:46,750
for you a significant advantage you'll

00:11:41,860 --> 00:11:48,339
get out this is a slightly expanded

00:11:46,750 --> 00:11:51,399
picture of how things will get deployed

00:11:48,339 --> 00:11:53,170
from a distribution standpoint these are

00:11:51,399 --> 00:11:56,050
the different roles how we will deploy

00:11:53,170 --> 00:11:57,339
Arango DB the data itself is kept on DB

00:11:56,050 --> 00:12:00,819
servers by the primary or secondary

00:11:57,339 --> 00:12:02,920
distributed across machines the micro

00:12:00,819 --> 00:12:05,379
services can be exposed using the Fox

00:12:02,920 --> 00:12:07,269
micro service framework which will run

00:12:05,379 --> 00:12:08,740
on the coordinator nodes as well

00:12:07,269 --> 00:12:10,689
coordinator nodes can be scaled

00:12:08,740 --> 00:12:13,089
independently from the DB server nodes

00:12:10,689 --> 00:12:14,860
which means you get computational

00:12:13,089 --> 00:12:16,540
scalability as well as you get data

00:12:14,860 --> 00:12:18,880
scalability based on what your

00:12:16,540 --> 00:12:23,110
application needs are to service your

00:12:18,880 --> 00:12:25,810
request and lastly the agency is really

00:12:23,110 --> 00:12:28,360
the consensus mechanism that we have

00:12:25,810 --> 00:12:30,100
which will do the job of stepping out of

00:12:28,360 --> 00:12:31,930
the cluster and overlooking it like a

00:12:30,100 --> 00:12:33,610
hawk and figuring out how are my

00:12:31,930 --> 00:12:35,350
coordinators working how are my machines

00:12:33,610 --> 00:12:38,079
doing how are my DB servers doing and

00:12:35,350 --> 00:12:40,630
how is health of everyone if anybody

00:12:38,079 --> 00:12:42,759
goes down it will make sure that it gets

00:12:40,630 --> 00:12:44,259
automatically started on different

00:12:42,759 --> 00:12:46,149
machines or that is a process that you

00:12:44,259 --> 00:12:48,699
can automate in the way you feel best as

00:12:46,149 --> 00:12:50,500
well it is essentially a very hardened

00:12:48,699 --> 00:12:53,259
way of figuring out what your cluster

00:12:50,500 --> 00:13:01,180
state is and tackling it as as you as

00:12:53,259 --> 00:13:02,860
you as your needs grow that is so and

00:13:01,180 --> 00:13:04,899
this is actually where missus is coming

00:13:02,860 --> 00:13:06,730
in as you can see this is like a really

00:13:04,899 --> 00:13:08,319
complex architecture which I have to

00:13:06,730 --> 00:13:10,000
deploy and actually also maintain

00:13:08,319 --> 00:13:12,459
beakers we're talking distributed

00:13:10,000 --> 00:13:14,709
systems there are failures each of those

00:13:12,459 --> 00:13:16,809
instances might fail at any time because

00:13:14,709 --> 00:13:19,540
the underlying nodus crashing because

00:13:16,809 --> 00:13:19,780
there is a network partition so this is

00:13:19,540 --> 00:13:22,540
why

00:13:19,780 --> 00:13:24,310
we actually have to do something about

00:13:22,540 --> 00:13:26,740
how we deploying it and this we all know

00:13:24,310 --> 00:13:30,040
we're at mrs. Kahn mrs. is really built

00:13:26,740 --> 00:13:31,930
for that but the seemingly easy couldn't

00:13:30,040 --> 00:13:34,630
HDMI connection isn't really built for

00:13:31,930 --> 00:13:36,730
it for we see already like Network

00:13:34,630 --> 00:13:39,100
partitions happening here between the

00:13:36,730 --> 00:13:41,220
laptop and Beamer so it's gonna happen

00:13:39,100 --> 00:13:44,980
even more in this big cluster over here

00:13:41,220 --> 00:13:46,530
yeah so and this is actually why is he a

00:13:44,980 --> 00:13:48,970
Rango guy started out pretty early

00:13:46,530 --> 00:13:51,730
talking to us in developing like a

00:13:48,970 --> 00:13:53,290
missus framework for it and developing

00:13:51,730 --> 00:13:55,000
such kind of missus framework is

00:13:53,290 --> 00:13:56,890
actually it's really really hard

00:13:55,000 --> 00:14:00,220
especially we're talking here about a

00:13:56,890 --> 00:14:01,660
database developing something I don't

00:14:00,220 --> 00:14:03,340
want to say even like Marilyn Vickers

00:14:01,660 --> 00:14:06,520
Merson also has like a lot of moving

00:14:03,340 --> 00:14:08,260
parts by now but in the beginning it was

00:14:06,520 --> 00:14:10,060
actually quite simple because it had

00:14:08,260 --> 00:14:11,440
very little state but here we're

00:14:10,060 --> 00:14:14,320
actually talking about a stateful

00:14:11,440 --> 00:14:17,260
framework which has to be resilient and

00:14:14,320 --> 00:14:21,190
so in the end you don't have to read all

00:14:17,260 --> 00:14:24,370
of this but kind of like the outcome was

00:14:21,190 --> 00:14:27,250
that we wrote about 5,000 lines of C++

00:14:24,370 --> 00:14:29,620
code just to maintain all states and I

00:14:27,250 --> 00:14:31,750
think this picture is even symbolizing

00:14:29,620 --> 00:14:33,820
it better because this actually shows

00:14:31,750 --> 00:14:36,460
the state diagram we had for all those

00:14:33,820 --> 00:14:38,320
components so in mazes itself they're

00:14:36,460 --> 00:14:40,540
like low level primitives for those of

00:14:38,320 --> 00:14:44,760
you F might have looked at it it's

00:14:40,540 --> 00:14:47,560
reservations and then

00:14:44,760 --> 00:14:50,020
dynamic volumes and so on and so

00:14:47,560 --> 00:14:52,180
persistent volumes so it was actually it

00:14:50,020 --> 00:14:54,490
was a rather a lot of code we needed to

00:14:52,180 --> 00:14:55,900
write here and maintain but now it's

00:14:54,490 --> 00:14:57,940
actually it's a pretty good framework

00:14:55,900 --> 00:15:01,120
and maybe this is also like one of those

00:14:57,940 --> 00:15:02,500
key takeaways from writing it if you

00:15:01,120 --> 00:15:04,330
really dare to write a framework

00:15:02,500 --> 00:15:06,640
yourself I'll tell you on the next slide

00:15:04,330 --> 00:15:09,940
why you shouldn't you should actually

00:15:06,640 --> 00:15:12,010
start out within like state diagram like

00:15:09,940 --> 00:15:16,780
this how you want to deal with your

00:15:12,010 --> 00:15:19,150
persistent volumes next slide but I said

00:15:16,780 --> 00:15:20,920
you actually you shouldn't be writing

00:15:19,150 --> 00:15:22,990
your own framework in most cases just

00:15:20,920 --> 00:15:26,080
quick raise of hands how many of you

00:15:22,990 --> 00:15:31,089
have either been to the SDK talk or have

00:15:26,080 --> 00:15:32,980
been to the SDK workshop even so yeah

00:15:31,089 --> 00:15:36,940
you know all of this so

00:15:32,980 --> 00:15:38,890
basic ideas that we don't want people to

00:15:36,940 --> 00:15:40,750
actually have to write frameworks we

00:15:38,890 --> 00:15:43,720
want to generate it resentments this is

00:15:40,750 --> 00:15:45,610
what's the SDK is actually about so the

00:15:43,720 --> 00:15:47,140
simple thing we also did for example in

00:15:45,610 --> 00:15:49,270
the workshop we don't have to do

00:15:47,140 --> 00:15:52,450
anything we just have a very simple Yama

00:15:49,270 --> 00:15:54,700
configuration and we can deploy it so we

00:15:52,450 --> 00:15:56,980
don't need any deep knowledge about DCs

00:15:54,700 --> 00:15:59,770
we don't need any deep knowledge about

00:15:56,980 --> 00:16:02,380
the framework we're want to run we

00:15:59,770 --> 00:16:04,900
simple they run these commands and then

00:16:02,380 --> 00:16:07,360
the framework will also generate such

00:16:04,900 --> 00:16:09,730
kind of framework scheduler for us in

00:16:07,360 --> 00:16:11,380
most cases also if we're dealing with

00:16:09,730 --> 00:16:14,290
like a database where we have certain

00:16:11,380 --> 00:16:16,210
startup constraints or certain recovery

00:16:14,290 --> 00:16:19,420
operations it might happen that we

00:16:16,210 --> 00:16:21,340
actually have to write some code so we

00:16:19,420 --> 00:16:23,500
see SDK currently this is some Java code

00:16:21,340 --> 00:16:27,850
and I need like a little understanding

00:16:23,500 --> 00:16:29,260
of DCOs but all of those up here this is

00:16:27,850 --> 00:16:32,890
actually this is something I can

00:16:29,260 --> 00:16:35,200
probably the highest up is a layer the

00:16:32,890 --> 00:16:36,970
default I can do that within a week this

00:16:35,200 --> 00:16:38,920
is probably somewhere within months and

00:16:36,970 --> 00:16:41,550
how long did it take us to develop the

00:16:38,920 --> 00:16:44,950
entire framework like nine months or so

00:16:41,550 --> 00:16:48,190
yeah rough yeah

00:16:44,950 --> 00:16:49,990
so that's actually a whole lot different

00:16:48,190 --> 00:16:52,300
timescale of developing such kind of

00:16:49,990 --> 00:16:53,830
code but thank you for again for doing

00:16:52,300 --> 00:16:56,950
it it was really really helpful because

00:16:53,830 --> 00:17:00,520
it actually helped us build the SDK with

00:16:56,950 --> 00:17:04,510
all the experience we got from this next

00:17:00,520 --> 00:17:07,570
slide and now that's actually we talked

00:17:04,510 --> 00:17:09,190
about the replicated data part now let's

00:17:07,570 --> 00:17:12,820
just talk about like the replicated

00:17:09,190 --> 00:17:15,160
infrastructure part one see slide it's

00:17:12,820 --> 00:17:18,699
not black anymore next slide

00:17:15,160 --> 00:17:20,230
yes so we're talking about data center

00:17:18,699 --> 00:17:22,360
replication and actually we have

00:17:20,230 --> 00:17:24,250
multiple options for that so maybe we

00:17:22,360 --> 00:17:27,190
should first clarify what we're talking

00:17:24,250 --> 00:17:29,770
about so we can either use replication

00:17:27,190 --> 00:17:32,020
or our goal could be to use replication

00:17:29,770 --> 00:17:33,910
just as like an off-site backup from

00:17:32,020 --> 00:17:36,490
where I might be able to restore my data

00:17:33,910 --> 00:17:38,410
this is option number one option number

00:17:36,490 --> 00:17:41,380
two is a little stricter requirements

00:17:38,410 --> 00:17:43,150
this is like disaster recovery where I

00:17:41,380 --> 00:17:45,760
actually want to switch over to my

00:17:43,150 --> 00:17:46,540
backup so my backup has to be something

00:17:45,760 --> 00:17:48,900
which can run

00:17:46,540 --> 00:17:52,810
and also serve curries in the end and

00:17:48,900 --> 00:17:55,900
the latest and probably strictest goal

00:17:52,810 --> 00:17:59,080
or option could be to offer geo local

00:17:55,900 --> 00:18:02,860
services and distribution of data the

00:17:59,080 --> 00:18:04,810
Beamer is really fun so in that case

00:18:02,860 --> 00:18:08,020
that I can actually surf queries from

00:18:04,810 --> 00:18:10,960
both data centers in peril which is good

00:18:08,020 --> 00:18:13,630
for example if I have customers around

00:18:10,960 --> 00:18:15,340
the world but it's of course it's also a

00:18:13,630 --> 00:18:17,410
lot harder because all the sudden I'm

00:18:15,340 --> 00:18:21,340
really dealing with hot master master

00:18:17,410 --> 00:18:24,220
replication so basically like the basic

00:18:21,340 --> 00:18:27,250
idea here is we have a cluster one a

00:18:24,220 --> 00:18:30,340
cluster two in some other zone and now

00:18:27,250 --> 00:18:32,860
we want to see how we can actually get

00:18:30,340 --> 00:18:38,530
that going in which different scenarios

00:18:32,860 --> 00:18:39,970
up there next slide yeah so and for the

00:18:38,530 --> 00:18:43,780
first iteration

00:18:39,970 --> 00:18:46,420
Arango DB after also discussing with us

00:18:43,780 --> 00:18:48,580
we decided to go for just to solve the

00:18:46,420 --> 00:18:50,500
first two options weaker so many people

00:18:48,580 --> 00:18:53,530
that's actually sufficient I don't

00:18:50,500 --> 00:18:57,370
necessarily have that much load that I

00:18:53,530 --> 00:18:59,620
need multiple sites serving requests so

00:18:57,370 --> 00:19:01,900
actually just being able to recover my

00:18:59,620 --> 00:19:06,010
data is something very useful if a data

00:19:01,900 --> 00:19:09,310
center is going down if an Amazon region

00:19:06,010 --> 00:19:14,680
isn't available anymore for example next

00:19:09,310 --> 00:19:17,710
slide and so what we decided as like C

00:19:14,680 --> 00:19:20,890
goals for this first iteration is to run

00:19:17,710 --> 00:19:22,660
a database clusters in all data centers

00:19:20,890 --> 00:19:25,420
involved in this replication procedure

00:19:22,660 --> 00:19:27,310
and then replicate data automatically

00:19:25,420 --> 00:19:28,750
this is nothing what I want to do is in

00:19:27,310 --> 00:19:31,990
operators this is something which should

00:19:28,750 --> 00:19:34,120
happen out of the box and then also be

00:19:31,990 --> 00:19:37,780
prepared to actually switch over to Z as

00:19:34,120 --> 00:19:39,640
a data center so at time point one all

00:19:37,780 --> 00:19:42,850
requests are going into data center one

00:19:39,640 --> 00:19:44,950
then a hurricane is coming as

00:19:42,850 --> 00:19:47,710
unfortunately it's happening too often

00:19:44,950 --> 00:19:50,440
and recent days that data centers

00:19:47,710 --> 00:19:52,870
offline powers cut and I can actually

00:19:50,440 --> 00:19:55,240
switch over the request to the second

00:19:52,870 --> 00:19:58,780
data center and then I can still keep on

00:19:55,240 --> 00:20:01,230
serving queries from the second data

00:19:58,780 --> 00:20:01,230
center

00:20:01,440 --> 00:20:08,440
so the first implementation we are

00:20:06,370 --> 00:20:11,980
currently implementing or they are

00:20:08,440 --> 00:20:14,500
currently implementing is to have this

00:20:11,980 --> 00:20:17,490
replicated Arango DB cluster which

00:20:14,500 --> 00:20:20,380
includes basically all user settings so

00:20:17,490 --> 00:20:24,460
also replicated between both clusters

00:20:20,380 --> 00:20:27,880
and Arango already has a replication API

00:20:24,460 --> 00:20:30,160
so we can we will utilize that together

00:20:27,880 --> 00:20:33,340
with an newly written tool called a

00:20:30,160 --> 00:20:35,470
Rango sync and then we actually we

00:20:33,340 --> 00:20:39,070
looked into different options in what we

00:20:35,470 --> 00:20:41,320
can use to here ships the data over and

00:20:39,070 --> 00:20:42,940
we looked at different implementations

00:20:41,320 --> 00:20:43,690
or how much effort it would be to do it

00:20:42,940 --> 00:20:45,929
ourselves

00:20:43,690 --> 00:20:49,210
and our decision was actually to use

00:20:45,929 --> 00:20:51,520
Kafka our more particular called Kafka

00:20:49,210 --> 00:20:54,880
Merle maker which allows me to run like

00:20:51,520 --> 00:20:58,059
it distributed replicated Kafka cluster

00:20:54,880 --> 00:21:01,450
across two data centers and that

00:20:58,059 --> 00:21:03,100
decision is actually it's kind of if you

00:21:01,450 --> 00:21:04,480
looked at all the other talks and this

00:21:03,100 --> 00:21:07,240
is also why this talk is actually in

00:21:04,480 --> 00:21:09,910
this Mac stack because of a lot of those

00:21:07,240 --> 00:21:13,120
architectures are starting to use other

00:21:09,910 --> 00:21:15,220
tools as for example Kafka here we have

00:21:13,120 --> 00:21:17,919
if you're talking about this Mac stack

00:21:15,220 --> 00:21:21,940
here we would replace the storage part

00:21:17,919 --> 00:21:23,950
with a rango DB but it's basically we

00:21:21,940 --> 00:21:27,730
not necessarily have to write all the

00:21:23,950 --> 00:21:30,220
tools ourselves because we have not 2017

00:21:27,730 --> 00:21:34,059
a really great tool box available of

00:21:30,220 --> 00:21:36,940
tools to use and so we use that and this

00:21:34,059 --> 00:21:39,010
helps us to write load spikes in in one

00:21:36,940 --> 00:21:41,730
datacenter because a Kafka can also

00:21:39,010 --> 00:21:44,980
queues them so it can just accumulate

00:21:41,730 --> 00:21:47,410
events as well and it can then

00:21:44,980 --> 00:21:49,270
distribute them across data centers and

00:21:47,410 --> 00:21:51,070
even if there's a network outage we

00:21:49,270 --> 00:21:53,290
might lose some of the events in there

00:21:51,070 --> 00:21:55,840
but it's still going to be running and

00:21:53,290 --> 00:21:59,260
Kafka can also reconnect and now the

00:21:55,840 --> 00:22:02,590
nice thing is that we can actually or

00:21:59,260 --> 00:22:05,260
natively implemented on to do anything

00:22:02,590 --> 00:22:07,390
to very little to get that is to

00:22:05,260 --> 00:22:10,210
implement back pressure meaning if the

00:22:07,390 --> 00:22:12,040
second database is getting too slow the

00:22:10,210 --> 00:22:13,480
second data center and just can't handle

00:22:12,040 --> 00:22:15,190
all the requests

00:22:13,480 --> 00:22:17,830
Kafka can just buffer that and we have

00:22:15,190 --> 00:22:21,400
automatic back pressure and we can even

00:22:17,830 --> 00:22:25,750
then pass it on to the tooling around

00:22:21,400 --> 00:22:28,240
Arango sink to further have further back

00:22:25,750 --> 00:22:32,590
pressure and not overload the Kafka

00:22:28,240 --> 00:22:34,270
cluster the TLS protection it's we're

00:22:32,590 --> 00:22:36,910
shipping that across datacenter so

00:22:34,270 --> 00:22:40,179
probably across some communication line

00:22:36,910 --> 00:22:42,640
where someone else might be listening so

00:22:40,179 --> 00:22:47,559
we need to make sure that all of this is

00:22:42,640 --> 00:22:49,210
encrypted next slide and so this is done

00:22:47,559 --> 00:22:52,900
basically this is similar to the picture

00:22:49,210 --> 00:22:55,710
before so just this these lines they're

00:22:52,900 --> 00:22:59,740
basically this is a Kafka connection and

00:22:55,710 --> 00:23:02,799
so rancor sync is just making sure at

00:22:59,740 --> 00:23:04,990
which time point we are or how much we

00:23:02,799 --> 00:23:08,440
have replicated and then basically the

00:23:04,990 --> 00:23:13,270
Kafka is sending us over the data we are

00:23:08,440 --> 00:23:15,850
still missing as event and that allows

00:23:13,270 --> 00:23:18,360
us if that data center data center a is

00:23:15,850 --> 00:23:21,820
failing we might lose some of the events

00:23:18,360 --> 00:23:24,400
which have not been replicated yet by

00:23:21,820 --> 00:23:26,710
Kafka so which might be in the DB server

00:23:24,400 --> 00:23:28,390
but have not been written yet in Kafka

00:23:26,710 --> 00:23:31,150
slash might have even been written to

00:23:28,390 --> 00:23:33,970
Kafka but haven't been mirrored yet to

00:23:31,150 --> 00:23:36,730
the second Kafka instance for most use

00:23:33,970 --> 00:23:38,080
cases this isn't the two big issue but

00:23:36,730 --> 00:23:41,200
it's just something you should be aware

00:23:38,080 --> 00:23:41,830
of in the first implementation next

00:23:41,200 --> 00:23:44,740
slide please

00:23:41,830 --> 00:23:46,929
so and this is actually also Z

00:23:44,740 --> 00:23:50,880
limitation and it's basically that it's

00:23:46,929 --> 00:23:53,679
asynchronous so as set in the beginning

00:23:50,880 --> 00:23:55,960
this is targeting the first two goals of

00:23:53,679 --> 00:23:59,500
just having a backup and having a data

00:23:55,960 --> 00:24:01,419
center to which I can switch over but it

00:23:59,500 --> 00:24:03,880
also has the advantages if we quickly

00:24:01,419 --> 00:24:06,640
get an implementation which helps to

00:24:03,880 --> 00:24:10,750
solve those first two use cases but it

00:24:06,640 --> 00:24:13,330
can help in unplanned outages to losing

00:24:10,750 --> 00:24:15,549
some of the events in the queue I say

00:24:13,330 --> 00:24:17,919
unplanned because actually if we plan

00:24:15,549 --> 00:24:20,860
our outages if we plan to take one

00:24:17,919 --> 00:24:22,900
datacenter offline because we want to

00:24:20,860 --> 00:24:24,760
migrate nodes we want to I don't know

00:24:22,900 --> 00:24:26,750
create a new cluster then we can

00:24:24,760 --> 00:24:29,150
actually just wait until the Kafka queue

00:24:26,750 --> 00:24:31,850
entirely depleted and then switch over

00:24:29,150 --> 00:24:34,940
so in that case we can actually do

00:24:31,850 --> 00:24:36,950
without data loss and yes it's a

00:24:34,940 --> 00:24:38,720
synchronous asset in the beginning we

00:24:36,950 --> 00:24:41,330
don't have any load balancing of Curie

00:24:38,720 --> 00:24:46,310
so no master master we can't kuribohs

00:24:41,330 --> 00:24:48,590
clusters in parallel next slide and yeah

00:24:46,310 --> 00:24:51,500
that's actually it's a good topic to

00:24:48,590 --> 00:24:54,950
just talk about what I like see current

00:24:51,500 --> 00:24:57,680
ways and plans for DC u.s. replication

00:24:54,950 --> 00:24:59,420
across data centers beakers the same

00:24:57,680 --> 00:25:01,460
problem you actually have will have for

00:24:59,420 --> 00:25:03,170
many clusters that you want to

00:25:01,460 --> 00:25:06,260
distribute that across different data

00:25:03,170 --> 00:25:09,740
centers or across different Amazon

00:25:06,260 --> 00:25:13,310
availability zones about Amazon regions

00:25:09,740 --> 00:25:15,080
and you have some options so the first

00:25:13,310 --> 00:25:17,510
one could be that you actually start

00:25:15,080 --> 00:25:19,520
spreading out your masters across those

00:25:17,510 --> 00:25:22,930
different data centers across those

00:25:19,520 --> 00:25:26,390
different zones and that actually works

00:25:22,930 --> 00:25:28,430
rather well if you're staying in the

00:25:26,390 --> 00:25:30,470
same availability if you're spreading

00:25:28,430 --> 00:25:33,320
out across different availability zones

00:25:30,470 --> 00:25:35,630
but stay was in the same region once you

00:25:33,320 --> 00:25:37,160
start so this is like Amazon talk if

00:25:35,630 --> 00:25:39,800
you're thinking about your own data

00:25:37,160 --> 00:25:42,680
center or Asher or GCE you just have to

00:25:39,800 --> 00:25:45,530
translate it to the respective names

00:25:42,680 --> 00:25:47,960
there it basically it tells you you

00:25:45,530 --> 00:25:50,510
can't spread them out across low latency

00:25:47,960 --> 00:25:52,970
links but not across high latency links

00:25:50,510 --> 00:25:55,100
and why since this case this is mainly

00:25:52,970 --> 00:25:57,940
zookeeper once you start spreading out a

00:25:55,100 --> 00:26:01,520
zookeeper cluster across high latency

00:25:57,940 --> 00:26:03,050
links you'll end up in some issues so

00:26:01,520 --> 00:26:04,790
you should be very careful with that

00:26:03,050 --> 00:26:06,650
and that's actually also one of the

00:26:04,790 --> 00:26:08,600
reasons why Ben in his keynote yesterday

00:26:06,650 --> 00:26:11,120
mentioned that we want to get rid of

00:26:08,600 --> 00:26:14,720
zookeeper is just to make that more

00:26:11,120 --> 00:26:16,550
scalable across high latency links the

00:26:14,720 --> 00:26:19,400
easy sync to spread us is actually a

00:26:16,550 --> 00:26:21,590
Junt so we have a lot of users who are

00:26:19,400 --> 00:26:25,280
spreading out either misses agents or

00:26:21,590 --> 00:26:29,180
dcs agents across for example there were

00:26:25,280 --> 00:26:31,940
at least one talk today about using spot

00:26:29,180 --> 00:26:34,040
instances and they don't matter too much

00:26:31,940 --> 00:26:35,780
whether they have a high latency in

00:26:34,040 --> 00:26:38,420
between or not so there are even people

00:26:35,780 --> 00:26:40,220
running there on Prem data centers and

00:26:38,420 --> 00:26:43,460
extending that with spa

00:26:40,220 --> 00:26:44,840
instances for spikey workloads because

00:26:43,460 --> 00:26:47,090
there isn't any synchronous

00:26:44,840 --> 00:26:49,970
communication required that's all

00:26:47,090 --> 00:26:54,650
asynchronous so latency doesn't impact

00:26:49,970 --> 00:26:57,289
it too severely at least the plans for

00:26:54,650 --> 00:26:59,780
the future are also to actually be able

00:26:57,289 --> 00:27:03,140
to link two clusters together in the

00:26:59,780 --> 00:27:04,909
beginning it's just gonna be you I CLI

00:27:03,140 --> 00:27:06,860
so mostly like control it's gonna make

00:27:04,909 --> 00:27:10,789
it easy to control two clusters in

00:27:06,860 --> 00:27:12,590
parallel but so there are people working

00:27:10,789 --> 00:27:15,049
on like a linker module it's called

00:27:12,590 --> 00:27:16,940
which makes it like those clusters aware

00:27:15,049 --> 00:27:19,570
of each other that it actually makes it

00:27:16,940 --> 00:27:23,270
very easy to support use cases like that

00:27:19,570 --> 00:27:27,799
next slide which I guess is a demo yes

00:27:23,270 --> 00:27:29,809
this is a demo so we can talk a lot

00:27:27,799 --> 00:27:34,940
about it I'll just spin up the cluster

00:27:29,809 --> 00:27:36,799
for you and you can take over okay so we

00:27:34,940 --> 00:27:38,990
can talk a lot but let's actually just

00:27:36,799 --> 00:27:41,030
see also what a Rango DB can do we

00:27:38,990 --> 00:27:43,789
obviously for time reasons we won't spin

00:27:41,030 --> 00:27:46,220
up two clusters and have the replication

00:27:43,789 --> 00:27:48,830
in between also as this is not quite

00:27:46,220 --> 00:27:51,650
working yet so we'll just show it to you

00:27:48,830 --> 00:27:53,480
on a single distributed cluster instance

00:27:51,650 --> 00:27:58,010
but already distributed within one data

00:27:53,480 --> 00:28:03,710
center so installing a Rango DB is quite

00:27:58,010 --> 00:28:05,870
easy the only thing we have to look out

00:28:03,710 --> 00:28:08,960
for is that there are actually two

00:28:05,870 --> 00:28:11,360
instances so a Rango DB is actually the

00:28:08,960 --> 00:28:13,850
old one we should add a prefix to that

00:28:11,360 --> 00:28:16,100
probably but we wants a new version

00:28:13,850 --> 00:28:19,580
Arango DB 3 so we are installing that

00:28:16,100 --> 00:28:22,250
and let's just have a look what's

00:28:19,580 --> 00:28:24,740
happening in the background because for

00:28:22,250 --> 00:28:27,890
those of you who might not be that

00:28:24,740 --> 00:28:29,659
familiar we see here is the first thing

00:28:27,890 --> 00:28:31,970
spinning up if we look at it this

00:28:29,659 --> 00:28:33,500
actually the framework scheduler so the

00:28:31,970 --> 00:28:36,049
framework schedule is is this thing

00:28:33,500 --> 00:28:39,049
which will deploy also afterwards all

00:28:36,049 --> 00:28:41,419
the other tasks and this is running now

00:28:39,049 --> 00:28:48,380
so rather soonish we should actually see

00:28:41,419 --> 00:28:50,149
the other tasks spinning up this is also

00:28:48,380 --> 00:28:52,250
why it's still unhealthy because yeah

00:28:50,149 --> 00:28:53,900
the other tasks they are still staging

00:28:52,250 --> 00:28:56,510
and so these are

00:28:53,900 --> 00:28:58,160
the actual of tasks which you're doings

00:28:56,510 --> 00:29:00,290
of work the first one is kind of like

00:28:58,160 --> 00:29:02,690
sea controller who's controlling all the

00:29:00,290 --> 00:29:06,320
other tasks in mrs. terms the framework

00:29:02,690 --> 00:29:10,690
scheduler and then the other tasks LBGT

00:29:06,320 --> 00:29:10,690
be service and controllers starting up

00:29:10,840 --> 00:29:14,540
while they slowly come up we could

00:29:13,130 --> 00:29:24,740
actually check whether we can already

00:29:14,540 --> 00:29:26,410
access the UI you're a pessimistic all

00:29:24,740 --> 00:29:28,640
right

00:29:26,410 --> 00:29:32,350
service unavailable because the

00:29:28,640 --> 00:29:32,350
coordinators are not quite there yet

00:29:32,560 --> 00:29:36,970
just wait for one more second

00:29:42,310 --> 00:29:49,750
distributed systems take time but it's

00:29:44,630 --> 00:29:54,100
still deploying let's just wait Oh wha

00:29:49,750 --> 00:29:54,100
now you need to click on the little icon

00:30:02,410 --> 00:30:08,440
just which bank do you want to tell more

00:30:05,620 --> 00:30:11,410
about the demo you'll be running no no

00:30:08,440 --> 00:30:15,250
we are coming up after sir thanks York

00:30:11,410 --> 00:30:18,340
for all the stuff you told us about our

00:30:15,250 --> 00:30:20,440
a synchronous multi data center

00:30:18,340 --> 00:30:23,170
replication but what I want to show you

00:30:20,440 --> 00:30:26,230
a little bit wrong would be cluster

00:30:23,170 --> 00:30:28,390
running on D so s so first of all we

00:30:26,230 --> 00:30:31,840
spin up with two clicks a cluster on

00:30:28,390 --> 00:30:33,550
three notes DCOs cluster pair default

00:30:31,840 --> 00:30:36,100
you're getting 2 DB service two

00:30:33,550 --> 00:30:39,430
coordinators and if you just want to add

00:30:36,100 --> 00:30:43,810
a new one that's really one click let's

00:30:39,430 --> 00:30:47,470
say and you start another coordinator in

00:30:43,810 --> 00:30:49,660
the cluster and Maria can already do in

00:30:47,470 --> 00:30:51,370
the same times maybe start a collection

00:30:49,660 --> 00:30:53,350
a collection you're wrong would be it's

00:30:51,370 --> 00:30:56,740
the same as a table in a relational

00:30:53,350 --> 00:30:59,260
database and you can really define for

00:30:56,740 --> 00:31:01,630
every collection first of all the number

00:30:59,260 --> 00:31:04,660
of charts so that's at the end limited

00:31:01,630 --> 00:31:07,300
scaling at the end you need one shard at

00:31:04,660 --> 00:31:09,310
every DB server and the other thing is

00:31:07,300 --> 00:31:12,190
the replication factor this is also

00:31:09,310 --> 00:31:22,000
configurable on every collection so

00:31:12,190 --> 00:31:23,980
let's start with two for the demo so now

00:31:22,000 --> 00:31:26,140
we have this collection this is empty

00:31:23,980 --> 00:31:32,620
add so we can just put in some

00:31:26,140 --> 00:31:38,520
information let's say some my own key in

00:31:32,620 --> 00:31:38,520
that case and then just adding some

00:31:40,560 --> 00:31:44,160
Jason couch you

00:31:46,460 --> 00:31:52,850
so I'm not used for English to use

00:31:49,789 --> 00:31:55,159
English you just want to tell me what I

00:31:52,850 --> 00:32:02,960
should type the Justin neighbor Trussell

00:31:55,159 --> 00:32:10,759
shot Jason document yes there's another

00:32:02,960 --> 00:32:20,240
value yeah sure fine just safe okay it's

00:32:10,759 --> 00:32:22,369
funny so if you go back to the cluster

00:32:20,240 --> 00:32:25,039
overview then we can also directly have

00:32:22,369 --> 00:32:27,649
a look at your notes and also on the

00:32:25,039 --> 00:32:31,519
charts so we created this collection we

00:32:27,649 --> 00:32:33,740
see now all the potential shots and now

00:32:31,519 --> 00:32:35,869
I can also move the shots around in the

00:32:33,740 --> 00:32:39,289
cluster for example if I want out of

00:32:35,869 --> 00:32:41,809
some reason manually clean up one of the

00:32:39,289 --> 00:32:44,119
server to maybe do some maintenance on

00:32:41,809 --> 00:32:46,820
that it can easily do that on the web

00:32:44,119 --> 00:32:49,549
interface but also we are wasteful API

00:32:46,820 --> 00:32:53,690
that's all possible against the

00:32:49,549 --> 00:32:55,970
framework and so on and what is also

00:32:53,690 --> 00:32:58,879
possible then if I want to have three

00:32:55,970 --> 00:33:01,639
nodes of the DB server let me also show

00:32:58,879 --> 00:33:03,740
that as a last short thing in the demo

00:33:01,639 --> 00:33:07,429
that maybe takes know a little bit more

00:33:03,740 --> 00:33:09,399
because a DV server is already a little

00:33:07,429 --> 00:33:11,450
bit more to start in just a coordinator

00:33:09,399 --> 00:33:12,919
maybe also to explain it on the

00:33:11,450 --> 00:33:15,289
coordinators the coordinators are

00:33:12,919 --> 00:33:17,119
completely stateless they only do their

00:33:15,289 --> 00:33:19,490
first phase of the query optimization

00:33:17,119 --> 00:33:22,309
the query handling in the direction of

00:33:19,490 --> 00:33:24,230
the application and also do these folks

00:33:22,309 --> 00:33:26,240
the Microsoft frameworks and as you can

00:33:24,230 --> 00:33:28,279
this is something about this at the end

00:33:26,240 --> 00:33:29,809
complete stateless you can have ten of

00:33:28,279 --> 00:33:31,549
them hundreds of them this really

00:33:29,809 --> 00:33:34,249
depends how much you use these features

00:33:31,549 --> 00:33:36,860
and if you lose one of them it makes no

00:33:34,249 --> 00:33:42,289
difference at all so now we have 3 DB

00:33:36,860 --> 00:33:47,149
servers let's go also on an another

00:33:42,289 --> 00:33:48,529
collection and like a replication factor

00:33:47,149 --> 00:33:57,039
now if we because I have two

00:33:48,529 --> 00:33:57,039
possibilities for that sorry tests of

00:34:01,390 --> 00:34:07,880
okay I know he go back to the notes now

00:34:05,600 --> 00:34:09,619
we have the two collections and you see

00:34:07,880 --> 00:34:11,629
we have a replication factor of 2 that

00:34:09,619 --> 00:34:14,179
means we have no spreaded over the

00:34:11,629 --> 00:34:17,629
cluster the leader and the two followers

00:34:14,179 --> 00:34:19,700
overall if we knows and now it's from

00:34:17,629 --> 00:34:25,159
for example it's not possible to scale

00:34:19,700 --> 00:34:27,169
down the classroom to one note you

00:34:25,159 --> 00:34:29,899
should think about it normally it would

00:34:27,169 --> 00:34:32,480
be not possible but it's something what

00:34:29,899 --> 00:34:34,280
we say it's up to you if you want to do

00:34:32,480 --> 00:34:37,159
that or not because it's mean that

00:34:34,280 --> 00:34:38,899
you're at the end in a situation where

00:34:37,159 --> 00:34:41,300
you have the leader and the two

00:34:38,899 --> 00:34:43,340
followers only on two notes so in the

00:34:41,300 --> 00:34:45,350
sense of a high availability

00:34:43,340 --> 00:34:48,139
it makes maybe not so much sense but

00:34:45,350 --> 00:34:50,179
it's something even if you need that for

00:34:48,139 --> 00:34:51,919
maybe scaling up the machines or use

00:34:50,179 --> 00:35:02,869
bigger machines for your classes it

00:34:51,919 --> 00:35:04,460
should still possible maybe also give

00:35:02,869 --> 00:35:12,470
you a short example of the query

00:35:04,460 --> 00:35:14,930
language so that is also very simple at

00:35:12,470 --> 00:35:18,530
the end is very similar to sequel you

00:35:14,930 --> 00:35:21,560
can do something like a four leg like a

00:35:18,530 --> 00:35:23,780
loop in some sense of a collection

00:35:21,560 --> 00:35:25,760
collection with documents then you're

00:35:23,780 --> 00:35:28,190
filtering on some stuff and then you

00:35:25,760 --> 00:35:31,010
make the projection of the result at the

00:35:28,190 --> 00:35:33,080
end of the of the query so maybe this is

00:35:31,010 --> 00:35:36,200
also the the the main difference between

00:35:33,080 --> 00:35:39,290
sequel and equality and what what you

00:35:36,200 --> 00:35:45,350
can also do with equal is to combine

00:35:39,290 --> 00:35:47,960
different different stuff what we often

00:35:45,350 --> 00:35:50,240
we can do graph queries and joins and

00:35:47,960 --> 00:35:52,400
document lookups really in one query so

00:35:50,240 --> 00:35:54,530
we have really use cases where people

00:35:52,400 --> 00:35:56,540
start with a graph database and then the

00:35:54,530 --> 00:35:58,220
optimization at the end if you use a one

00:35:56,540 --> 00:36:00,890
going to be is to use the combination

00:35:58,220 --> 00:36:03,800
from joins and go after use at the same

00:36:00,890 --> 00:36:06,140
times so so sample what we are always

00:36:03,800 --> 00:36:07,940
saying is if you have a fixed length in

00:36:06,140 --> 00:36:09,030
your path if you make a query or

00:36:07,940 --> 00:36:10,770
afterwards

00:36:09,030 --> 00:36:12,810
it's more efficient to use a joint

00:36:10,770 --> 00:36:15,180
instead of a graph traversal if you

00:36:12,810 --> 00:36:16,680
really can combine it in one query then

00:36:15,180 --> 00:36:18,330
you get really new possibilities and

00:36:16,680 --> 00:36:26,310
direction what is the performance what

00:36:18,330 --> 00:36:28,470
you're getting out of this stuff so also

00:36:26,310 --> 00:36:30,900
we offer in sub-query it's a really

00:36:28,470 --> 00:36:32,420
complex query language what you can

00:36:30,900 --> 00:36:44,610
really combine the different stuff so

00:36:32,420 --> 00:36:48,120
maybe let's go back to so we are still

00:36:44,610 --> 00:36:52,560
trying to bring down the number of shots

00:36:48,120 --> 00:36:55,620
and to be honest I missed something to

00:36:52,560 --> 00:36:58,020
tell you as at the beginning we changed

00:36:55,620 --> 00:36:59,880
that we cannot scale down the cluster

00:36:58,020 --> 00:37:05,250
until we have to free a replication

00:36:59,880 --> 00:37:08,850
factor so that's about that go back to

00:37:05,250 --> 00:37:11,100
the collections just delete the

00:37:08,850 --> 00:37:15,660
collection of the application factor of

00:37:11,100 --> 00:37:17,370
we go back to the nodes then let's have

00:37:15,660 --> 00:37:19,770
a look at the chart we have only the one

00:37:17,370 --> 00:37:24,750
connection with the replication factor

00:37:19,770 --> 00:37:27,090
of two and try the same again and now

00:37:24,750 --> 00:37:29,610
it's possible to get get out one of the

00:37:27,090 --> 00:37:31,440
DB reserves of the cluster so that is

00:37:29,610 --> 00:37:34,590
the different why we choose our own

00:37:31,440 --> 00:37:36,660
framework and D so as we really can take

00:37:34,590 --> 00:37:38,910
care of all the stuff if you want to

00:37:36,660 --> 00:37:40,770
take out one server it's no problem

00:37:38,910 --> 00:37:43,290
their framework will move the data if

00:37:40,770 --> 00:37:45,030
possible to the other nodes if it's not

00:37:43,290 --> 00:37:46,620
possible it's going to protect you that

00:37:45,030 --> 00:37:47,880
you don't come in the situation what

00:37:46,620 --> 00:37:51,690
makes not so much sense

00:37:47,880 --> 00:37:53,940
and notice moving maybe take a little

00:37:51,690 --> 00:37:55,980
bit before it's the the agency

00:37:53,940 --> 00:37:58,650
recognized that you have moved the data

00:37:55,980 --> 00:38:00,450
and so on it's what your already

00:37:58,650 --> 00:38:05,310
mentioned also with the agency this is a

00:38:00,450 --> 00:38:07,650
graph based key value store where we

00:38:05,310 --> 00:38:09,360
really hold the state of the cluster if

00:38:07,650 --> 00:38:12,690
you change something it's more or less

00:38:09,360 --> 00:38:15,300
like a changing of a plan in the agency

00:38:12,690 --> 00:38:17,760
and then do we have a supervision code

00:38:15,300 --> 00:38:19,440
what really then makes sure that all

00:38:17,760 --> 00:38:21,410
those things happens and that's also

00:38:19,440 --> 00:38:25,760
once on the leader of this

00:38:21,410 --> 00:38:27,860
left based key value cluster so it's

00:38:25,760 --> 00:38:30,290
sure that this only once once a time so

00:38:27,860 --> 00:38:33,230
now you see we have getting out one of

00:38:30,290 --> 00:38:36,530
the DB sub of our cluster and the data

00:38:33,230 --> 00:38:39,170
are still in the whale how we need it so

00:38:36,530 --> 00:38:43,700
it's only on DB sum of one and we take

00:38:39,170 --> 00:38:46,160
out number two so some questions on that

00:38:43,700 --> 00:38:50,060
so that's maybe for now for short

00:38:46,160 --> 00:38:51,580
demonstration should be good especially

00:38:50,060 --> 00:39:00,650
as we were running out of time

00:38:51,580 --> 00:39:02,810
especially that yes how many of you have

00:39:00,650 --> 00:39:07,400
used either graph database or document

00:39:02,810 --> 00:39:12,350
database before how many of service

00:39:07,400 --> 00:39:13,790
databases for a Rango DB okay we're half

00:39:12,350 --> 00:39:18,260
half okay

00:39:13,790 --> 00:39:20,300
so for me it's actually it's really so

00:39:18,260 --> 00:39:22,430
my background is actually databases like

00:39:20,300 --> 00:39:24,590
my PhD was under suppurative databases

00:39:22,430 --> 00:39:28,310
back in Germany and I really like almost

00:39:24,590 --> 00:39:30,710
all databases or all the databases which

00:39:28,310 --> 00:39:32,930
I allow themselves to call databases and

00:39:30,710 --> 00:39:35,390
so I think this is a really interesting

00:39:32,930 --> 00:39:39,740
space and just from what I see when

00:39:35,390 --> 00:39:41,660
talking to customers and users make sure

00:39:39,740 --> 00:39:44,200
that you choose the right database of

00:39:41,660 --> 00:39:46,700
right data model for your application

00:39:44,200 --> 00:39:49,220
because it actually it matters a lot how

00:39:46,700 --> 00:39:51,530
you model your data and how you get your

00:39:49,220 --> 00:39:53,810
data into those different systems so

00:39:51,530 --> 00:39:56,390
just seeing so many customers doing that

00:39:53,810 --> 00:39:58,370
mistake please think about which

00:39:56,390 --> 00:40:00,470
database to choose and then also how you

00:39:58,370 --> 00:40:02,390
to fit your data into that specific

00:40:00,470 --> 00:40:05,390
database into this specific data model

00:40:02,390 --> 00:40:09,889
thank you very much for listening

00:40:05,390 --> 00:40:09,889

YouTube URL: https://www.youtube.com/watch?v=FghX4Ch2_4M


