Title: Practical Container Scheduling: Juggling Optimizations, Guarantees, and Trade-Offs at Netflix -
Publication date: 2017-09-18
Playlist: MesosCon North America 2017
Description: 
	Practical Container Scheduling: Juggling Optimizations, Guarantees, and Trade-Offs at Netflix - Sharma Podila, Netflix

Assigning resources from distributed clusters to containers from disparate use cases can be tricky. It becomes even more so in practice when combining multiple scheduling objectives and constraints such as bin packing, task locality, and capacity guarantees, among others.

Containers are increasingly used to run microservices, batch, and stream processing applications in large scale shared Mesos clusters at Netflix. This talk dives deep into the challenges, design, and trade-offs achieved using open source scheduling library, Fenzo, that takes a holistic approach, along with plugins based extensibility, to provide a nimble a scheduling core for various independently evolving clusters. Using results, we highlight aspects of capacity guarantees, task placement, elasticity, and operational insights to tackle large scale operations.


Sharma Podila
Netflix
Senior Software Engineer
Los Gatos
Websitenetflix.com/
Sharma Podila is a Senior Software Enginner in the Edge Engineering team at Netflix, Inc. His current work includes Fenzo, an open source generic scheduler with plugin based optimizations, developing cloud native Mesos frameworks, and evolving the microservices platform at Netflix.
Captions: 
	00:00:00,060 --> 00:00:04,500
so maybe some of you maybe all of you

00:00:02,040 --> 00:00:07,470
have your own Apache mesas cluster

00:00:04,500 --> 00:00:10,559
running everything is going great that's

00:00:07,470 --> 00:00:13,740
awesome and maybe you got applications

00:00:10,559 --> 00:00:15,809
running in production as well so let's

00:00:13,740 --> 00:00:17,760
ask a few questions are you able to

00:00:15,809 --> 00:00:19,789
guarantee capacity for all your

00:00:17,760 --> 00:00:22,769
applications exactly when they need them

00:00:19,789 --> 00:00:24,689
are you able to optimize placements if

00:00:22,769 --> 00:00:28,230
that's important to you maybe there are

00:00:24,689 --> 00:00:31,260
some batch workloads that take can take

00:00:28,230 --> 00:00:34,380
care of affinity or locality or anti

00:00:31,260 --> 00:00:37,170
locality right do you keep your cluster

00:00:34,380 --> 00:00:38,850
size elastic or do you provision for

00:00:37,170 --> 00:00:41,940
peak if you're in a data center

00:00:38,850 --> 00:00:43,200
environment that would be true and are

00:00:41,940 --> 00:00:45,570
you able to optimize your maximum

00:00:43,200 --> 00:00:48,059
footprint well these are the questions

00:00:45,570 --> 00:00:52,199
I'll try to address today my name is

00:00:48,059 --> 00:00:55,920
Charma Padilla I have been that Netflix

00:00:52,199 --> 00:00:58,140
for about four years part of the what's

00:00:55,920 --> 00:01:00,270
called the edge organization edge

00:00:58,140 --> 00:01:01,379
engineering organization and I've worked

00:01:00,270 --> 00:01:05,519
on a couple of projects that are

00:01:01,379 --> 00:01:07,170
relevant to mesas one is called mantis

00:01:05,519 --> 00:01:11,130
and the other titus I'll briefly touch

00:01:07,170 --> 00:01:16,200
upon them and also we open source the

00:01:11,130 --> 00:01:19,590
Netflix fenzel scheduling library before

00:01:16,200 --> 00:01:22,619
that I spent time creating bad

00:01:19,590 --> 00:01:26,250
schedulers so this is what we're gonna

00:01:22,619 --> 00:01:28,049
cover I'll start with a brief context on

00:01:26,250 --> 00:01:31,259
well what are we trying to solve what

00:01:28,049 --> 00:01:33,180
did we start out to solve and my title

00:01:31,259 --> 00:01:37,439
of the presentation has the word juggle

00:01:33,180 --> 00:01:39,329
why do we need to juggle we'll take a

00:01:37,439 --> 00:01:43,320
look at the few challenges that are

00:01:39,329 --> 00:01:45,570
specific to large clusters and then dive

00:01:43,320 --> 00:01:47,729
deep into what we've created how it

00:01:45,570 --> 00:01:49,860
works for us and share some details with

00:01:47,729 --> 00:01:53,460
you and then a peek at what we are

00:01:49,860 --> 00:01:55,170
thinking about working on next so when

00:01:53,460 --> 00:01:58,200
we started about three and a half years

00:01:55,170 --> 00:02:00,630
ago one of the projects that was looking

00:01:58,200 --> 00:02:03,030
at misses it was called mantis it's a

00:02:00,630 --> 00:02:06,180
cloud native reactive stream processing

00:02:03,030 --> 00:02:08,459
system it was built to answer certain

00:02:06,180 --> 00:02:10,530
real-time queries like hey the Netflix

00:02:08,459 --> 00:02:13,180
service is running okay but maybe it's

00:02:10,530 --> 00:02:15,459
just a handful of users in one corner

00:02:13,180 --> 00:02:18,370
the world are not able to stream a few

00:02:15,459 --> 00:02:19,930
episodes of a show which gets lost as

00:02:18,370 --> 00:02:22,599
noise in the overall signal of

00:02:19,930 --> 00:02:24,099
availability of Netflix service so doing

00:02:22,599 --> 00:02:26,340
high cardinality anomaly detection

00:02:24,099 --> 00:02:28,950
things like that and for this we built a

00:02:26,340 --> 00:02:32,500
scheduler on top of mesas in order to

00:02:28,950 --> 00:02:34,659
run containers that are doing stream

00:02:32,500 --> 00:02:37,349
processing and there's a lot of

00:02:34,659 --> 00:02:40,659
interactive exploration of data that

00:02:37,349 --> 00:02:42,730
users can dig into by putting in new

00:02:40,659 --> 00:02:46,510
facets and and querying what's happening

00:02:42,730 --> 00:02:50,049
in real time around the same time

00:02:46,510 --> 00:02:52,780
another project that started is it's

00:02:50,049 --> 00:02:56,200
called Titus and that's a docker

00:02:52,780 --> 00:02:58,750
container orchestration system it runs

00:02:56,200 --> 00:03:02,079
on top of ec2 specifically in the V PC

00:02:58,750 --> 00:03:05,280
environment and it integrates into rest

00:03:02,079 --> 00:03:10,480
of the Netflix micro services ecosystem

00:03:05,280 --> 00:03:12,099
the discovery monitoring and Lourdes

00:03:10,480 --> 00:03:14,829
software based load balancing and things

00:03:12,099 --> 00:03:17,069
like that and spinnaker is our CI CD

00:03:14,829 --> 00:03:19,930
pipeline and a common UI to make

00:03:17,069 --> 00:03:25,540
application deployment easy with all its

00:03:19,930 --> 00:03:27,970
pipelines so both of these projects were

00:03:25,540 --> 00:03:31,479
starting out around the same time and

00:03:27,970 --> 00:03:33,340
what we saw was that what we needed from

00:03:31,479 --> 00:03:35,829
a cluster manager was a support for

00:03:33,340 --> 00:03:37,659
heterogeneous mix a workload because the

00:03:35,829 --> 00:03:39,549
workloads are going to vary not only in

00:03:37,659 --> 00:03:41,769
terms of how many CPUs each SAS might

00:03:39,549 --> 00:03:44,049
ask memory and network bandwidth et

00:03:41,769 --> 00:03:46,030
cetera but also in how critical they are

00:03:44,049 --> 00:03:49,060
we have a mix of some being more

00:03:46,030 --> 00:03:50,799
critical than others and their runtime

00:03:49,060 --> 00:03:52,629
profiles some of them are short running

00:03:50,799 --> 00:03:54,459
batch tasks some of them are a

00:03:52,629 --> 00:03:56,139
long-running batch but some of them are

00:03:54,459 --> 00:03:59,199
professionally running services right

00:03:56,139 --> 00:04:01,629
and then the resource demand it varies

00:03:59,199 --> 00:04:03,879
over time Netflix is definitely

00:04:01,629 --> 00:04:05,560
dependent on the time of the day in

00:04:03,879 --> 00:04:09,340
terms of how many active users there are

00:04:05,560 --> 00:04:11,290
and that means mantis has a different

00:04:09,340 --> 00:04:13,959
amount of data to process and it

00:04:11,290 --> 00:04:15,729
actually varies about 5x from peak to

00:04:13,959 --> 00:04:17,739
trough and similarly the number of

00:04:15,729 --> 00:04:20,019
containers running tight is also varies

00:04:17,739 --> 00:04:23,800
over time especially for bad systems

00:04:20,019 --> 00:04:25,720
where work comes in in in sporadically

00:04:23,800 --> 00:04:31,480
in lots of them and then just goes

00:04:25,720 --> 00:04:34,360
after they're done so okay all that

00:04:31,480 --> 00:04:37,150
sounds fine but why juggle we need to

00:04:34,360 --> 00:04:40,510
get one thing out of our way which is if

00:04:37,150 --> 00:04:42,280
you had unlimited resources I can tell

00:04:40,510 --> 00:04:45,910
you there's no need to juggle life is

00:04:42,280 --> 00:04:49,540
simple and I didn't say infinite because

00:04:45,910 --> 00:04:51,880
we just need practically unlimited as in

00:04:49,540 --> 00:04:53,350
more resources then we have demand for

00:04:51,880 --> 00:04:56,620
right if we had that there's absolutely

00:04:53,350 --> 00:04:57,700
no need to juggle it's very simple but

00:04:56,620 --> 00:04:59,770
the other question that comes up

00:04:57,700 --> 00:05:01,600
especially for us is since we run on the

00:04:59,770 --> 00:05:04,240
Amazon Cloud and it's an elastic cloud

00:05:01,600 --> 00:05:06,760
well don't we have an unlimited supply

00:05:04,240 --> 00:05:08,920
of resources whenever we need we just go

00:05:06,760 --> 00:05:11,200
to the cloud and ask for more why it

00:05:08,920 --> 00:05:13,360
would seem like that's the case and if

00:05:11,200 --> 00:05:15,940
we were to sort of represent that as

00:05:13,360 --> 00:05:18,130
demand versus supply and look at the

00:05:15,940 --> 00:05:21,850
whole aggregate of all resources we use

00:05:18,130 --> 00:05:24,610
maybe does look like that the demand is

00:05:21,850 --> 00:05:26,050
less than the supply so everything

00:05:24,610 --> 00:05:28,270
should be fine but when you start

00:05:26,050 --> 00:05:31,300
looking at it there's not just one

00:05:28,270 --> 00:05:33,070
server type in the cloud there are so

00:05:31,300 --> 00:05:35,530
many different instance types right and

00:05:33,070 --> 00:05:38,320
we started looking at it it looks like

00:05:35,530 --> 00:05:40,480
hey for some instance types maybe the

00:05:38,320 --> 00:05:43,600
demand is less than the supply but for

00:05:40,480 --> 00:05:46,000
others it's actually the opposite so we

00:05:43,600 --> 00:05:48,520
do have certain workloads that need to

00:05:46,000 --> 00:05:50,110
use certain resources for which the

00:05:48,520 --> 00:05:52,000
demand is higher than they supply so

00:05:50,110 --> 00:05:54,040
there is some demand versus supply

00:05:52,000 --> 00:05:58,120
juggling that we will have to look at

00:05:54,040 --> 00:05:59,890
and the other is efficiency some

00:05:58,120 --> 00:06:01,510
workloads need a lot of memory by the

00:05:59,890 --> 00:06:03,490
time you pick an instance type that can

00:06:01,510 --> 00:06:05,290
satisfy that you're automatically

00:06:03,490 --> 00:06:07,210
getting so many CPUs that that

00:06:05,290 --> 00:06:09,340
application is not gonna use so you're

00:06:07,210 --> 00:06:11,560
gonna start seeing holes in utilization

00:06:09,340 --> 00:06:14,590
so can we do something about it improve

00:06:11,560 --> 00:06:18,100
the efficiency and then there's

00:06:14,590 --> 00:06:21,340
different workloads types not only in

00:06:18,100 --> 00:06:23,470
criticality but there's a lot of pre

00:06:21,340 --> 00:06:25,360
computes that are done for production

00:06:23,470 --> 00:06:28,810
workloads to do data lookups

00:06:25,360 --> 00:06:31,150
there's experimentation and then there's

00:06:28,810 --> 00:06:34,900
testing and then there's something what

00:06:31,150 --> 00:06:38,110
I call as the idle soak which is this is

00:06:34,900 --> 00:06:39,129
not super critical workload but if I can

00:06:38,110 --> 00:06:41,589
learn more of air

00:06:39,129 --> 00:06:44,080
helps me maybe converging my algorithm

00:06:41,589 --> 00:06:46,389
better improve my conference interval so

00:06:44,080 --> 00:06:51,419
if there's any idle cycles just run this

00:06:46,389 --> 00:06:54,219
right there's all kinds of workload so

00:06:51,419 --> 00:06:56,709
okay are there any specific challenges

00:06:54,219 --> 00:06:59,499
to large clusters so by large I don't

00:06:56,709 --> 00:07:01,360
necessarily mean only in the number of

00:06:59,499 --> 00:07:03,369
servers number of agents that you use

00:07:01,360 --> 00:07:05,499
and if you if that's large well that's a

00:07:03,369 --> 00:07:08,679
large cluster but large is also in terms

00:07:05,499 --> 00:07:10,149
of how many users do you have that are

00:07:08,679 --> 00:07:12,639
trying to do different things how many

00:07:10,149 --> 00:07:14,589
different use cases you have what's the

00:07:12,639 --> 00:07:19,149
differences in the kind of resources

00:07:14,589 --> 00:07:21,279
that the jobs need the variety could be

00:07:19,149 --> 00:07:22,779
large the number of servers could be

00:07:21,279 --> 00:07:26,289
large or the number of users could be

00:07:22,779 --> 00:07:30,339
large so you started looking at

00:07:26,289 --> 00:07:33,669
scheduling you can think of doing a

00:07:30,339 --> 00:07:36,249
first fit kind of an assignment and it

00:07:33,669 --> 00:07:37,599
keeps things pretty simple and given the

00:07:36,249 --> 00:07:40,209
right environment it can actually be

00:07:37,599 --> 00:07:42,610
very fast you can probably achieve

00:07:40,209 --> 00:07:46,360
constant ordered time complexity for

00:07:42,610 --> 00:07:48,429
first fit kind of assignments however if

00:07:46,360 --> 00:07:50,129
you start doing the most optimal

00:07:48,429 --> 00:07:52,509
assignment this can be expensive

00:07:50,129 --> 00:07:54,909
computationally and even if you were to

00:07:52,509 --> 00:07:57,069
not reassign already running workload

00:07:54,909 --> 00:07:58,300
just figuring our assignments for the

00:07:57,069 --> 00:08:01,059
pending workload can be computationally

00:07:58,300 --> 00:08:02,860
expensive ideally in the real world we

00:08:01,059 --> 00:08:05,529
want to stay somewhere in between as

00:08:02,860 --> 00:08:08,229
close as possible to the speed but

00:08:05,529 --> 00:08:10,029
achieve as much optimal assignments as

00:08:08,229 --> 00:08:13,959
possible to the other end of the

00:08:10,029 --> 00:08:16,719
spectrum right that's our goal and speed

00:08:13,959 --> 00:08:18,909
is important for various reasons but but

00:08:16,719 --> 00:08:21,999
two things that I like to point out or

00:08:18,909 --> 00:08:24,639
if the scheduler were to be slow while

00:08:21,999 --> 00:08:26,490
it's figuring our assignments there are

00:08:24,639 --> 00:08:30,429
servers that are becoming idle

00:08:26,490 --> 00:08:32,860
efficiencies lost and one could argue

00:08:30,429 --> 00:08:35,919
that if the assignments were figured out

00:08:32,860 --> 00:08:37,329
assuming those servers were full and in

00:08:35,919 --> 00:08:39,759
the meantime they become empty this

00:08:37,329 --> 00:08:43,449
schedule is actually incorrect now so

00:08:39,759 --> 00:08:46,149
speed is definitely a concern so with

00:08:43,449 --> 00:08:48,309
all this in mind our initial goals were

00:08:46,149 --> 00:08:51,420
that we need to have a cluster manager

00:08:48,309 --> 00:08:52,510
and a scheduler that can take multiple

00:08:51,420 --> 00:08:55,270
multi

00:08:52,510 --> 00:09:00,010
scheduling goals in mind and achieve

00:08:55,270 --> 00:09:02,590
them we need to be auto-scaling our

00:09:00,010 --> 00:09:06,280
cluster size as we do with a lot of

00:09:02,590 --> 00:09:08,680
things at Netflix trying to be a cloud

00:09:06,280 --> 00:09:12,190
native and use and pay for the resources

00:09:08,680 --> 00:09:14,050
you need extensibility extensibility is

00:09:12,190 --> 00:09:15,970
something that well I've learned a lot

00:09:14,050 --> 00:09:18,550
of people have learned that if you try

00:09:15,970 --> 00:09:20,860
to keep adding one new feature at a time

00:09:18,550 --> 00:09:22,690
into a scheduler after some time it

00:09:20,860 --> 00:09:25,840
feels like you're adding a band-aid or a

00:09:22,690 --> 00:09:28,360
band-aid and instead it's easier to

00:09:25,840 --> 00:09:29,980
design a scheduler that is easy to

00:09:28,360 --> 00:09:33,550
extend so that it has to be a goal from

00:09:29,980 --> 00:09:34,990
the beginning but very soon we figured

00:09:33,550 --> 00:09:37,420
out that there's a few more goals we

00:09:34,990 --> 00:09:39,370
need to add security if we're going to

00:09:37,420 --> 00:09:42,130
have multi tenant workloads different

00:09:39,370 --> 00:09:44,770
applications then we need to have a

00:09:42,130 --> 00:09:48,490
secured security story around that

00:09:44,770 --> 00:09:52,180
capacity guarantees and can we reason

00:09:48,490 --> 00:09:54,970
about failures in operations so let's

00:09:52,180 --> 00:10:00,820
let's look at each of those so as far as

00:09:54,970 --> 00:10:04,390
multi goal scheduling objectives go we

00:10:00,820 --> 00:10:07,480
can think of four different camps that

00:10:04,390 --> 00:10:10,270
have an influence on how you should do

00:10:07,480 --> 00:10:11,650
these source assignments right the data

00:10:10,270 --> 00:10:14,980
center of the cloud operator is

00:10:11,650 --> 00:10:18,940
interested in making sure well they can

00:10:14,980 --> 00:10:23,020
do maintenance they can make sure that

00:10:18,940 --> 00:10:24,670
the cloud footprint is small etcetera so

00:10:23,020 --> 00:10:26,860
they're interested in making sure the

00:10:24,670 --> 00:10:28,840
scheduler behaves in certain ways to

00:10:26,860 --> 00:10:30,490
achieve their goals the application

00:10:28,840 --> 00:10:32,050
owner on the other hand is interested in

00:10:30,490 --> 00:10:35,290
making sure the application gets the

00:10:32,050 --> 00:10:38,130
best performance possible if I can get a

00:10:35,290 --> 00:10:41,080
performance by buying my own machine and

00:10:38,130 --> 00:10:42,790
running the application running it in

00:10:41,080 --> 00:10:44,560
your system should have a similar

00:10:42,790 --> 00:10:48,340
performance characteristic if not better

00:10:44,560 --> 00:10:49,030
right and high availability is another

00:10:48,340 --> 00:10:50,500
concern

00:10:49,030 --> 00:10:53,980
don't put all my tests on the same

00:10:50,500 --> 00:10:58,570
machine same drag etcetera and security

00:10:53,980 --> 00:11:01,210
concerns are that at least at Netflix we

00:10:58,570 --> 00:11:02,860
have certain applications with certain

00:11:01,210 --> 00:11:05,080
security profiles that can only access

00:11:02,860 --> 00:11:05,889
only certain other applications right

00:11:05,080 --> 00:11:07,480
everybody's guard

00:11:05,889 --> 00:11:09,369
security problems so if you're going to

00:11:07,480 --> 00:11:11,499
pour multiple applications on the same

00:11:09,369 --> 00:11:14,470
host you still need to guarantee that

00:11:11,499 --> 00:11:17,139
that will be true cost is interesting

00:11:14,470 --> 00:11:20,199
thing costs could mean so many different

00:11:17,139 --> 00:11:23,439
things it could mean hey use the

00:11:20,199 --> 00:11:24,189
cheapest instance size possible to get

00:11:23,439 --> 00:11:28,149
the work done

00:11:24,189 --> 00:11:29,949
it could mean in a data center make sure

00:11:28,149 --> 00:11:32,139
your power and cooling costs are under

00:11:29,949 --> 00:11:35,679
control you can actually schedule things

00:11:32,139 --> 00:11:40,779
and save on power and cooling so things

00:11:35,679 --> 00:11:45,489
like that so order scaling like I said

00:11:40,779 --> 00:11:47,290
mantis has 5 X or more peak to trough

00:11:45,489 --> 00:11:50,139
variation in the amount of data to

00:11:47,290 --> 00:11:52,470
process and we don't necessarily want to

00:11:50,139 --> 00:11:55,419
size our cluster for the peak there

00:11:52,470 --> 00:11:56,829
similarly Titus has thousands of

00:11:55,419 --> 00:12:00,220
containers or hundreds of containers

00:11:56,829 --> 00:12:03,040
running at different points of time it

00:12:00,220 --> 00:12:05,499
turns out scaling up is well it's not

00:12:03,040 --> 00:12:07,149
super easy but relatively easy you can

00:12:05,499 --> 00:12:08,919
for example watch for some kind of

00:12:07,149 --> 00:12:11,049
metrics that tell you here's the demand

00:12:08,919 --> 00:12:14,499
it's getting close to the cluster size

00:12:11,049 --> 00:12:16,449
and then if the buffer is very small

00:12:14,499 --> 00:12:18,879
then you scale up so scale up can be a

00:12:16,449 --> 00:12:21,279
little bit easier but it's a scaled down

00:12:18,879 --> 00:12:24,489
that's harder and it requires you to do

00:12:21,279 --> 00:12:28,059
bin packing so in the first row of these

00:12:24,489 --> 00:12:30,579
four hosts i've got similar number of

00:12:28,059 --> 00:12:32,139
CPUs being used about 50% but they're

00:12:30,579 --> 00:12:34,089
spread across all the machines and if I

00:12:32,139 --> 00:12:36,279
need to scale down I'll have to move

00:12:34,089 --> 00:12:38,139
those applications somewhere else but

00:12:36,279 --> 00:12:40,360
instead if my scheduling actually took

00:12:38,139 --> 00:12:42,970
that into consideration and they'd been

00:12:40,360 --> 00:12:44,919
packing then it leaves two machines

00:12:42,970 --> 00:12:47,819
completely idle and it's easy for me to

00:12:44,919 --> 00:12:52,269
scale down so that's the basic idea

00:12:47,819 --> 00:12:56,889
however there are other aspects to it

00:12:52,269 --> 00:12:58,779
where batch workloads can complete at

00:12:56,889 --> 00:13:01,509
different points of time and then can

00:12:58,779 --> 00:13:03,999
you actually look at that estimate the

00:13:01,509 --> 00:13:06,160
expected runtime and put them together

00:13:03,999 --> 00:13:07,899
so at about the same time the entire

00:13:06,160 --> 00:13:09,549
machine is going to free up there could

00:13:07,899 --> 00:13:13,239
be sophistication but this is the basic

00:13:09,549 --> 00:13:15,669
idea and for security we actually find

00:13:13,239 --> 00:13:18,199
right now that we've got applications we

00:13:15,669 --> 00:13:20,300
use security groups on Amazon

00:13:18,199 --> 00:13:22,850
some applications have a single security

00:13:20,300 --> 00:13:25,550
group some of them have multiple and

00:13:22,850 --> 00:13:30,500
there could be a mix of them we need to

00:13:25,550 --> 00:13:32,120
make sure if they are isolated and we

00:13:30,500 --> 00:13:35,300
look at capacity guarantees what we're

00:13:32,120 --> 00:13:36,649
seeing is that here's dozens of

00:13:35,300 --> 00:13:40,519
applications that are gonna be run on

00:13:36,649 --> 00:13:42,620
the cluster how can we make sure they

00:13:40,519 --> 00:13:45,709
have the right capacity when they need

00:13:42,620 --> 00:13:49,339
to and when people think about doing

00:13:45,709 --> 00:13:50,810
this there are broadly speaking two ways

00:13:49,339 --> 00:13:53,779
to think about it

00:13:50,810 --> 00:13:55,910
one is a priority which is only

00:13:53,779 --> 00:13:59,240
right-hand side of this slide and the

00:13:55,910 --> 00:14:01,610
other is some kind of a coder to say I'm

00:13:59,240 --> 00:14:04,639
gonna give more quarter to the more

00:14:01,610 --> 00:14:08,860
important workload so when you look at

00:14:04,639 --> 00:14:11,680
the quarters often it's a static

00:14:08,860 --> 00:14:14,569
fragmentation of the resources to say

00:14:11,680 --> 00:14:18,259
the critical for example get 75 percent

00:14:14,569 --> 00:14:20,990
and the other one flexible or flex for

00:14:18,259 --> 00:14:23,300
short gets 25 percent but what happens

00:14:20,990 --> 00:14:25,490
when there's a surge in the critical

00:14:23,300 --> 00:14:27,260
work load if they are limited to 75

00:14:25,490 --> 00:14:29,630
percent while you're in trouble because

00:14:27,260 --> 00:14:31,250
that is the critical workload right so

00:14:29,630 --> 00:14:33,500
then then you need to vary the quotas

00:14:31,250 --> 00:14:37,010
maybe so that's one problem that we

00:14:33,500 --> 00:14:40,459
could run into and the priorities may

00:14:37,010 --> 00:14:42,560
seem to work because first you make sure

00:14:40,459 --> 00:14:47,649
the highest priority workload is run and

00:14:42,560 --> 00:14:51,800
then the others but then that can starve

00:14:47,649 --> 00:14:53,389
resources for the Flex tier and even

00:14:51,800 --> 00:14:56,180
though flex tier is not critical for

00:14:53,389 --> 00:14:58,760
example it's not user facing services

00:14:56,180 --> 00:15:00,470
you still need to get batch work or done

00:14:58,760 --> 00:15:02,990
on time and if you're gonna starve them

00:15:00,470 --> 00:15:04,819
then it's not gonna affect you today

00:15:02,990 --> 00:15:07,040
it's gonna affect you tomorrow maybe so

00:15:04,819 --> 00:15:08,899
there's still certain throughput you

00:15:07,040 --> 00:15:11,750
need to guarantee for batch workload

00:15:08,899 --> 00:15:13,639
even though your critical workload is

00:15:11,750 --> 00:15:15,680
more important so just the strict

00:15:13,639 --> 00:15:17,689
priorities is also not going to work so

00:15:15,680 --> 00:15:22,610
those are some of the thoughts that that

00:15:17,689 --> 00:15:25,310
we go through to guarantee capacity and

00:15:22,610 --> 00:15:28,550
for failures I'm going to talk about

00:15:25,310 --> 00:15:29,470
specifically the failure in a job to get

00:15:28,550 --> 00:15:32,180
launched

00:15:29,470 --> 00:15:32,930
somebody submits workload it's not

00:15:32,180 --> 00:15:36,140
running

00:15:32,930 --> 00:15:38,240
you've got thousands of jobs submitted

00:15:36,140 --> 00:15:41,420
how do you know if why this particular

00:15:38,240 --> 00:15:43,339
job is not running okay if it's not

00:15:41,420 --> 00:15:45,200
running what are the resources that is

00:15:43,339 --> 00:15:48,070
asking that are not getting satisfied

00:15:45,200 --> 00:15:50,810
and how many servers are even available

00:15:48,070 --> 00:15:52,279
to satisfy that but are failing at the

00:15:50,810 --> 00:15:55,300
moment so these are some of the

00:15:52,279 --> 00:15:59,350
questions we want to be able to answer

00:15:55,300 --> 00:16:03,800
so with that context what did we create

00:15:59,350 --> 00:16:08,660
here's the overall architecture of what

00:16:03,800 --> 00:16:11,390
we have we're out on ec2 we've got mesas

00:16:08,660 --> 00:16:14,990
running there and on top of that we are

00:16:11,390 --> 00:16:16,910
running two frameworks one called Titus

00:16:14,990 --> 00:16:17,779
the other comment is that I spoke about

00:16:16,910 --> 00:16:20,810
before

00:16:17,779 --> 00:16:23,300
both of them have abstractions on jobs

00:16:20,810 --> 00:16:25,040
jobs our collection of tasks and there

00:16:23,300 --> 00:16:26,690
are a few different types of jobs batch

00:16:25,040 --> 00:16:30,260
service and then the stream processing

00:16:26,690 --> 00:16:31,880
job as well and both these frameworks

00:16:30,260 --> 00:16:34,640
they use the offense of scheduling

00:16:31,880 --> 00:16:36,380
library that I referred to before so

00:16:34,640 --> 00:16:38,990
let's look at this in a little bit more

00:16:36,380 --> 00:16:41,990
detail so the scheduling strategy that

00:16:38,990 --> 00:16:45,260
fens o has is that when we look at tasks

00:16:41,990 --> 00:16:50,300
and then say here's the potential list

00:16:45,260 --> 00:16:53,120
of agents that we could run them on some

00:16:50,300 --> 00:16:56,180
of the agents may at the moment fit the

00:16:53,120 --> 00:16:58,490
tasks perfectly or some of them may fit

00:16:56,180 --> 00:17:00,560
okay it's not bad but it's not a perfect

00:16:58,490 --> 00:17:03,560
fit and there's like a whole whole

00:17:00,560 --> 00:17:05,750
spectrum there also some tasks are

00:17:03,560 --> 00:17:08,240
urgent maybe they need to complete right

00:17:05,750 --> 00:17:09,949
away or they have their service type

00:17:08,240 --> 00:17:12,140
critical they need to run right away or

00:17:09,949 --> 00:17:15,530
some of them are not so urgent so the

00:17:12,140 --> 00:17:18,799
general strategy in infants o is that if

00:17:15,530 --> 00:17:21,890
it's either urgent or it fits perfectly

00:17:18,799 --> 00:17:23,750
let's go ahead and sign it if not let's

00:17:21,890 --> 00:17:26,559
keep it pending and look for other

00:17:23,750 --> 00:17:32,270
agents where they may fit perfectly so

00:17:26,559 --> 00:17:33,620
that's the general idea so friends o is

00:17:32,270 --> 00:17:36,350
actually open source and it can be used

00:17:33,620 --> 00:17:37,430
by any scheduling framework any mesas

00:17:36,350 --> 00:17:41,900
framework there

00:17:37,430 --> 00:17:44,240
runs on the JVM and then it provides you

00:17:41,900 --> 00:17:46,040
extensibility you can write plugins

00:17:44,240 --> 00:17:50,260
which are basically simple functions

00:17:46,040 --> 00:17:52,790
that you tell fans oh here's my function

00:17:50,260 --> 00:17:53,830
it gives you cluster or the scaling if

00:17:52,790 --> 00:17:57,260
that's important to you

00:17:53,830 --> 00:17:59,180
there's tiered queues with weighted DRF

00:17:57,260 --> 00:18:02,750
but then it's here

00:17:59,180 --> 00:18:06,650
and it gives you a control for speed of

00:18:02,750 --> 00:18:08,570
assignments and optimality and actually

00:18:06,650 --> 00:18:10,430
importantly it also gives you ease of

00:18:08,570 --> 00:18:12,760
experimentation so if you want to write

00:18:10,430 --> 00:18:15,560
new plugins or new scheduling algorithms

00:18:12,760 --> 00:18:17,630
and before you put it out into the wild

00:18:15,560 --> 00:18:20,030
you can actually say here's a snapshot

00:18:17,630 --> 00:18:23,840
of my production workload let's run it

00:18:20,030 --> 00:18:26,660
in fenzel and make sure that this new

00:18:23,840 --> 00:18:28,490
plugins would actually work well before

00:18:26,660 --> 00:18:32,030
you put it into production so it lets

00:18:28,490 --> 00:18:35,600
you experiment as the URL for where you

00:18:32,030 --> 00:18:38,540
can find it this is roughly the

00:18:35,600 --> 00:18:42,440
algorithm that Venza uses for each order

00:18:38,540 --> 00:18:45,620
task and we do have queuing for all

00:18:42,440 --> 00:18:46,970
available hosts we start validating what

00:18:45,620 --> 00:18:49,010
we call hard constraints hard

00:18:46,970 --> 00:18:52,240
constraints must be met in order for the

00:18:49,010 --> 00:18:56,450
task to run on that and then we evaluate

00:18:52,240 --> 00:19:01,630
scores for what we call a fitness

00:18:56,450 --> 00:19:04,400
function and soft constraints and then

00:19:01,630 --> 00:19:07,460
we don't need to do this on every agent

00:19:04,400 --> 00:19:09,230
we only need to do this until we find a

00:19:07,460 --> 00:19:12,500
fitness score that we think is good

00:19:09,230 --> 00:19:16,190
enough and that's where the speed comes

00:19:12,500 --> 00:19:19,010
if we relax the criteria a little bit

00:19:16,190 --> 00:19:21,140
that hey the score could be low enough

00:19:19,010 --> 00:19:24,980
I'm okay with it then you get speed if

00:19:21,140 --> 00:19:26,540
you make the criteria to be I need this

00:19:24,980 --> 00:19:30,310
score to be high then you get more

00:19:26,540 --> 00:19:33,020
optimality so you have that control and

00:19:30,310 --> 00:19:37,430
then we pick the house with the highest

00:19:33,020 --> 00:19:39,230
score within that so the constraints

00:19:37,430 --> 00:19:40,580
both the hard and soft constraints and

00:19:39,230 --> 00:19:42,320
the fitness functions are the plugins

00:19:40,580 --> 00:19:44,690
that you write if Enzo comes with a few

00:19:42,320 --> 00:19:46,070
built-in ones for bin packing but you

00:19:44,690 --> 00:19:51,270
can write any fitness function that you

00:19:46,070 --> 00:19:53,880
want so what do we use in our system

00:19:51,270 --> 00:19:55,920
we definitely use the CPU memory and

00:19:53,880 --> 00:19:58,020
network bin packing that Finn's already

00:19:55,920 --> 00:19:59,970
comes with and to understand how it

00:19:58,020 --> 00:20:02,310
works it's very simple let's take the

00:19:59,970 --> 00:20:04,740
example of CPU bin packing when we look

00:20:02,310 --> 00:20:06,420
at an agent and a task let's just assume

00:20:04,740 --> 00:20:09,150
they're all single CPU tasks for this

00:20:06,420 --> 00:20:11,610
example we've got five House here host

00:20:09,150 --> 00:20:15,060
five is already false it's obviously not

00:20:11,610 --> 00:20:18,930
gonna fit it but we evaluate the ratio

00:20:15,060 --> 00:20:21,150
of the used CPUs if we were to launch

00:20:18,930 --> 00:20:24,150
this task over the total CPS on the host

00:20:21,150 --> 00:20:27,210
that basically gives us a fitness score

00:20:24,150 --> 00:20:31,200
for CPU bin packing similarly you could

00:20:27,210 --> 00:20:35,040
do that for memory network bandwidth and

00:20:31,200 --> 00:20:37,740
we also do that for the runtime profiles

00:20:35,040 --> 00:20:40,410
so we can sort of dynamically segregate

00:20:37,740 --> 00:20:43,620
a short running tasks from long running

00:20:40,410 --> 00:20:45,750
tasks it helps us in down scaling like I

00:20:43,620 --> 00:20:47,760
was saying and speaking of extensibility

00:20:45,750 --> 00:20:51,510
recently we added another fitness

00:20:47,760 --> 00:20:54,540
function where we can control or limit

00:20:51,510 --> 00:20:57,090
the number of concurrent starts

00:20:54,540 --> 00:20:59,190
happening on machines this has to do

00:20:57,090 --> 00:21:02,250
with more on the executor side the whole

00:20:59,190 --> 00:21:04,560
talker ecosystem of how many tasks can

00:21:02,250 --> 00:21:06,900
you concurrently start downloading

00:21:04,560 --> 00:21:08,220
images in all of that stuff so we wanted

00:21:06,900 --> 00:21:10,740
to get a good control so we added a

00:21:08,220 --> 00:21:12,870
fitness function for that so and then we

00:21:10,740 --> 00:21:14,610
combine these so you can have multiple

00:21:12,870 --> 00:21:16,620
fitness functions and compose them

00:21:14,610 --> 00:21:19,920
together to form your overall fitness

00:21:16,620 --> 00:21:23,070
function and we give them weights to say

00:21:19,920 --> 00:21:25,800
hey bin packing is important to me but

00:21:23,070 --> 00:21:28,740
runtime segregation is also important

00:21:25,800 --> 00:21:30,060
and so is control on the launch so I'm

00:21:28,740 --> 00:21:31,500
gonna give you different weights so

00:21:30,060 --> 00:21:37,140
we're playing with weights to see what

00:21:31,500 --> 00:21:39,060
weight works best for us the hard

00:21:37,140 --> 00:21:40,980
constraint we used two hard constraints

00:21:39,060 --> 00:21:44,490
today one is for GPU so we're matching

00:21:40,980 --> 00:21:46,440
to say that a host that has GPUs will

00:21:44,490 --> 00:21:50,040
only run a task if the task is

00:21:46,440 --> 00:21:51,770
requesting the GPU simple enough there's

00:21:50,040 --> 00:21:54,990
just a hard constraint we put in and it

00:21:51,770 --> 00:21:57,150
automatically does that we also have

00:21:54,990 --> 00:21:59,700
some resources earmarked for certain

00:21:57,150 --> 00:22:02,240
kind of tasks so we use hard constraints

00:21:59,700 --> 00:22:02,240
for those as well

00:22:03,300 --> 00:22:09,600
soft constraints are mostly specified by

00:22:05,760 --> 00:22:11,720
the users at submit time and the popular

00:22:09,600 --> 00:22:15,270
one is to balance the tasks across

00:22:11,720 --> 00:22:18,450
availability zones Amazon the regions

00:22:15,270 --> 00:22:21,210
have multiple availability zones and by

00:22:18,450 --> 00:22:23,340
spreading them you are making it highly

00:22:21,210 --> 00:22:24,780
available that even if one zone were to

00:22:23,340 --> 00:22:27,410
go down your application is still

00:22:24,780 --> 00:22:30,420
available so they specify this

00:22:27,410 --> 00:22:33,480
declaratively to say balance my tasks

00:22:30,420 --> 00:22:36,660
across the availability zones some

00:22:33,480 --> 00:22:40,410
services especially those with a low

00:22:36,660 --> 00:22:43,290
instance count also require us to

00:22:40,410 --> 00:22:45,720
balance them across hosts so why it's a

00:22:43,290 --> 00:22:48,060
cloud and in instance could die for some

00:22:45,720 --> 00:22:50,850
reason and come back later and if one

00:22:48,060 --> 00:22:52,890
host were to go away we don't want too

00:22:50,850 --> 00:22:57,200
many of those instances to go away

00:22:52,890 --> 00:23:01,050
especially for those small services so

00:22:57,200 --> 00:23:02,970
how do we combine Fitness score and soft

00:23:01,050 --> 00:23:05,820
constraint soft constraint also gives us

00:23:02,970 --> 00:23:08,400
a score to say yeah this constraint is

00:23:05,820 --> 00:23:10,290
met perfectly or this constraint is sort

00:23:08,400 --> 00:23:13,110
of met it's okay the constrain itself is

00:23:10,290 --> 00:23:14,760
not failing so if we have such

00:23:13,110 --> 00:23:17,520
constraints then we can combine that

00:23:14,760 --> 00:23:19,050
with the fitness function so the reason

00:23:17,520 --> 00:23:21,870
these are different is that Fitness

00:23:19,050 --> 00:23:24,510
function is sort of a more globally

00:23:21,870 --> 00:23:26,010
applied to the cluster the people who

00:23:24,510 --> 00:23:27,540
are looking at cluster level

00:23:26,010 --> 00:23:29,850
optimization or writing Fitness

00:23:27,540 --> 00:23:31,560
functions whereas the constraints are

00:23:29,850 --> 00:23:34,530
being written by applications to say for

00:23:31,560 --> 00:23:36,990
my application I want this soft

00:23:34,530 --> 00:23:39,300
constraint so then we combine them with

00:23:36,990 --> 00:23:41,550
currently these are the weights that we

00:23:39,300 --> 00:23:43,710
use to combine them so it's 40% the

00:23:41,550 --> 00:23:50,640
global fitness we give more weight to

00:23:43,710 --> 00:23:54,690
the user specific constraints so if Enzo

00:23:50,640 --> 00:23:56,790
has multi-tiered queue setup you can

00:23:54,690 --> 00:23:59,760
theoretically have any number of tiers

00:23:56,790 --> 00:24:02,610
but in practice it makes sense to have a

00:23:59,760 --> 00:24:04,770
handful of tiers today we use two tiers

00:24:02,610 --> 00:24:07,950
the critical and the Flex tier and what

00:24:04,770 --> 00:24:09,750
we mean by critical in Flex is you can

00:24:07,950 --> 00:24:12,570
have important applications running in

00:24:09,750 --> 00:24:16,740
either tier what do you mean by critical

00:24:12,570 --> 00:24:21,300
is that it's critical for the task to be

00:24:16,740 --> 00:24:23,820
right away whereas for flex tear it's

00:24:21,300 --> 00:24:25,860
okay to launch them with a little bit

00:24:23,820 --> 00:24:28,290
delay I'm okay with that but they're

00:24:25,860 --> 00:24:31,260
still important but how quickly you

00:24:28,290 --> 00:24:33,060
launch them so for example user-facing

00:24:31,260 --> 00:24:35,670
micro-service that's latency-sensitive

00:24:33,060 --> 00:24:37,770
will be in the critical tier whereas a

00:24:35,670 --> 00:24:39,630
batch warlord that's okay finishing in

00:24:37,770 --> 00:24:41,370
the next hour or overnight will be in

00:24:39,630 --> 00:24:43,050
the Flex tier they both need to be

00:24:41,370 --> 00:24:45,420
guaranteed some capacity

00:24:43,050 --> 00:24:48,120
it's the difference is how quickly they

00:24:45,420 --> 00:24:50,070
need to be launched and within each tier

00:24:48,120 --> 00:24:54,480
we have multiple applications so there's

00:24:50,070 --> 00:24:56,220
multiple buckets and we do DRF which is

00:24:54,480 --> 00:24:58,860
dominant resource fair share across

00:24:56,220 --> 00:25:01,320
these buckets it's a way to DRF so one

00:24:58,860 --> 00:25:02,970
application may have more weight for the

00:25:01,320 --> 00:25:05,510
share that it gets within the tier

00:25:02,970 --> 00:25:09,090
versus another application

00:25:05,510 --> 00:25:13,110
so when finto looks at different tasks

00:25:09,090 --> 00:25:16,140
it goes through the tier 0 then it goes

00:25:13,110 --> 00:25:17,430
to tier 1 and then does drf there if

00:25:16,140 --> 00:25:24,510
there were other tiers it would have

00:25:17,430 --> 00:25:26,550
gone down each tier so this also we also

00:25:24,510 --> 00:25:29,010
wanted to make sure that the interface

00:25:26,550 --> 00:25:33,240
to the users is simple

00:25:29,010 --> 00:25:35,790
so users users have to do two things one

00:25:33,240 --> 00:25:41,060
is when submitting workload they specify

00:25:35,790 --> 00:25:45,150
an application name and then separately

00:25:41,060 --> 00:25:47,100
one time specify how much total

00:25:45,150 --> 00:25:49,110
resources this application would mean

00:25:47,100 --> 00:25:51,300
and that's in the form of here's the

00:25:49,110 --> 00:25:55,680
container size I anticipate it's a for

00:25:51,300 --> 00:25:58,160
CPU 8 gigabyte container and I think I'm

00:25:55,680 --> 00:26:00,300
going to run about 120 of them or

00:25:58,160 --> 00:26:02,540
thousands of them whatever the number is

00:26:00,300 --> 00:26:05,220
so once you give that to the application

00:26:02,540 --> 00:26:06,600
then the system is able to look at that

00:26:05,220 --> 00:26:09,000
and say ok I'm going to guarantee this

00:26:06,600 --> 00:26:10,890
capacity based on that I'm going to

00:26:09,000 --> 00:26:12,350
choose instance type the system does

00:26:10,890 --> 00:26:14,880
this I'm gonna choose instance types

00:26:12,350 --> 00:26:16,650
that have at least 4 CPUs otherwise I

00:26:14,880 --> 00:26:19,020
can't guarantee that your container will

00:26:16,650 --> 00:26:23,070
ever fit even if I have in aggregate

00:26:19,020 --> 00:26:24,630
more CPUs than 120 containers right we

00:26:23,070 --> 00:26:26,730
also want to make it easy for people who

00:26:24,630 --> 00:26:28,350
aren't experiment or running really

00:26:26,730 --> 00:26:31,230
small services so there's no

00:26:28,350 --> 00:26:33,750
we're headed in creating this SL ace so

00:26:31,230 --> 00:26:35,660
there's a default catch-all bucket we

00:26:33,750 --> 00:26:37,500
give it some buffer to say

00:26:35,660 --> 00:26:39,780
experimentation should run fine there

00:26:37,500 --> 00:26:42,630
and once experimentation is done they

00:26:39,780 --> 00:26:45,419
want to make it into full production

00:26:42,630 --> 00:26:52,470
with guaranteed capacity then they set

00:26:45,419 --> 00:26:54,510
up these relays so we don't need to go

00:26:52,470 --> 00:26:56,340
too much into detail but what we're

00:26:54,510 --> 00:26:59,220
trying to show here is that if we had

00:26:56,340 --> 00:27:01,980
say dozens of applications each of whom

00:26:59,220 --> 00:27:05,340
have given those SL A's how do we figure

00:27:01,980 --> 00:27:07,350
out how to size our clusters especially

00:27:05,340 --> 00:27:09,630
since we are going to be auto-scaling

00:27:07,350 --> 00:27:11,520
the cluster size itself how do we figure

00:27:09,630 --> 00:27:15,270
out how many instances do I need at the

00:27:11,520 --> 00:27:17,940
moment so we do that separately for each

00:27:15,270 --> 00:27:20,570
tier for the critical tier since we need

00:27:17,940 --> 00:27:23,220
to guarantee in near-instant launch time

00:27:20,570 --> 00:27:26,730
we sometimes end up having some idle

00:27:23,220 --> 00:27:29,159
capacity there because if the service

00:27:26,730 --> 00:27:31,350
spins have more instances then we can

00:27:29,159 --> 00:27:34,380
launch them right away however we still

00:27:31,350 --> 00:27:36,150
order scale based on some logic in

00:27:34,380 --> 00:27:37,440
figuring out the buffer that we can have

00:27:36,150 --> 00:27:39,630
and still be able to guarantee near

00:27:37,440 --> 00:27:42,690
instantaneous launch time whereas for

00:27:39,630 --> 00:27:45,450
the Flex tier we actually keep the

00:27:42,690 --> 00:27:49,289
current size of the cluster exactly

00:27:45,450 --> 00:27:51,450
where the demand is so this is what we

00:27:49,289 --> 00:27:54,570
mean by if you launch more tasks in the

00:27:51,450 --> 00:27:56,220
Flex here we will launch them you're

00:27:54,570 --> 00:27:58,230
going to guarantee your capacity but you

00:27:56,220 --> 00:28:02,010
may have to wait for us to spin up a new

00:27:58,230 --> 00:28:06,929
VM underneath in the ec2 cloud so that's

00:28:02,010 --> 00:28:10,980
where the difference is so reasoning

00:28:06,929 --> 00:28:13,409
about failures this slide has small font

00:28:10,980 --> 00:28:16,470
text it's okay if you can't read all of

00:28:13,409 --> 00:28:18,990
it the point to show here is that in our

00:28:16,470 --> 00:28:21,360
server we have an end point on the

00:28:18,990 --> 00:28:24,929
control plane that gives you failures

00:28:21,360 --> 00:28:27,169
for a task that is staying in the

00:28:24,929 --> 00:28:30,450
pending state and not getting launched

00:28:27,169 --> 00:28:33,289
this is just a raw JSON output from it

00:28:30,450 --> 00:28:36,270
what it's basically saying is that

00:28:33,289 --> 00:28:37,799
here's the constraints the hard

00:28:36,270 --> 00:28:40,980
constraints that are failing for this

00:28:37,799 --> 00:28:42,210
task in this example it says well you're

00:28:40,980 --> 00:28:47,070
not asking for GPU

00:28:42,210 --> 00:28:49,320
so it's not going to run on these

00:28:47,070 --> 00:28:52,380
machines that are GPU based machines and

00:28:49,320 --> 00:28:54,390
then the the first one only runs on

00:28:52,380 --> 00:28:56,880
agent clusters and gives you two cluster

00:28:54,390 --> 00:28:58,770
types is basically saying that like was

00:28:56,880 --> 00:29:00,090
referring before certain kind of tasks

00:28:58,770 --> 00:29:02,040
are earmarked to run on only certain

00:29:00,090 --> 00:29:03,990
machines that's how it's set up for us

00:29:02,040 --> 00:29:06,300
right now and that's why it's failing

00:29:03,990 --> 00:29:08,960
that constraint and beyond those

00:29:06,300 --> 00:29:11,100
constraints there are machines that

00:29:08,960 --> 00:29:12,870
satisfy the hard constraints but are

00:29:11,100 --> 00:29:14,670
still failing because they don't have

00:29:12,870 --> 00:29:16,290
enough resources to run this task right

00:29:14,670 --> 00:29:19,260
now at the moment so it tells you for

00:29:16,290 --> 00:29:21,060
each of those memory requirement is

00:29:19,260 --> 00:29:23,400
failing on these machines and it tells

00:29:21,060 --> 00:29:26,580
you by how much and for network

00:29:23,400 --> 00:29:28,950
bandwidth same thing and for CPU so it's

00:29:26,580 --> 00:29:31,350
been useful for the cluster operator to

00:29:28,950 --> 00:29:36,960
figure out why is it tasks not running

00:29:31,350 --> 00:29:40,650
at the moment so well I'm coming towards

00:29:36,960 --> 00:29:43,350
the end part of my presentation so what

00:29:40,650 --> 00:29:44,460
are we thinking about next there are

00:29:43,350 --> 00:29:48,690
several things but I wanted to highlight

00:29:44,460 --> 00:29:50,660
three here one is tasks evictions some

00:29:48,690 --> 00:29:53,820
people like to call preemptions

00:29:50,660 --> 00:29:56,310
evictions they're similar but some

00:29:53,820 --> 00:29:58,860
differences but regardless right now we

00:29:56,310 --> 00:30:02,130
seem to like calling them evictions so

00:29:58,860 --> 00:30:04,800
by task evictions we mean here's some

00:30:02,130 --> 00:30:07,020
idle resources that need to be up and

00:30:04,800 --> 00:30:09,030
running to guarantee capacity but maybe

00:30:07,020 --> 00:30:11,310
I can run some other lower priority

00:30:09,030 --> 00:30:14,070
workload right now and then evict them

00:30:11,310 --> 00:30:16,830
later that's one example similarly when

00:30:14,070 --> 00:30:18,900
we have weighted drf across its here if

00:30:16,830 --> 00:30:21,000
one application is not running as much

00:30:18,900 --> 00:30:24,000
we can let the other applications run

00:30:21,000 --> 00:30:28,050
more and then evict them to balance out

00:30:24,000 --> 00:30:29,550
the way to DRF algorithm so those are

00:30:28,050 --> 00:30:31,350
two examples of where evictions could be

00:30:29,550 --> 00:30:35,040
useful evictions could also be useful

00:30:31,350 --> 00:30:37,470
because of noisy neighbors uuugh tarde 2

00:30:35,040 --> 00:30:40,410
applications will do ok on an on an

00:30:37,470 --> 00:30:42,150
instance but you notice there is an

00:30:40,410 --> 00:30:44,670
impact one of them and then you can

00:30:42,150 --> 00:30:47,190
evict and maybe migrate some of their

00:30:44,670 --> 00:30:49,680
workload somewhere else so lots of

00:30:47,190 --> 00:30:51,450
interesting discussions there some of

00:30:49,680 --> 00:30:53,600
you probably have thought about this

00:30:51,450 --> 00:30:56,150
maybe have solutions

00:30:53,600 --> 00:31:01,120
to talk to you maybe in the Q&A after

00:30:56,150 --> 00:31:01,120
this or or after this session anytime

00:31:01,929 --> 00:31:08,059
okay so I covered noisy neighbors so

00:31:04,690 --> 00:31:09,380
besides evictions I think not one of the

00:31:08,059 --> 00:31:12,970
challenges we have with noisy neighbors

00:31:09,380 --> 00:31:16,370
is we're not sure yet what to monitor

00:31:12,970 --> 00:31:20,000
how do we measure the effects of noisy

00:31:16,370 --> 00:31:21,950
neighbors we have some ways of looking

00:31:20,000 --> 00:31:24,200
at them and we've come up with okay

00:31:21,950 --> 00:31:25,909
let's keep these applications apart but

00:31:24,200 --> 00:31:29,450
we want to be able to dynamically do

00:31:25,909 --> 00:31:32,059
that how do we guarantee that is service

00:31:29,450 --> 00:31:34,850
workload will meet its latency is the

00:31:32,059 --> 00:31:37,370
lace and and similarly through per

00:31:34,850 --> 00:31:39,530
decilitre batch workload so I think

00:31:37,370 --> 00:31:43,640
there's a lot of work that could be done

00:31:39,530 --> 00:31:46,250
that we are very useful there automated

00:31:43,640 --> 00:31:49,700
rollout of new agent code is another

00:31:46,250 --> 00:31:52,520
pain point for us at the moment when

00:31:49,700 --> 00:31:54,500
you've got lots of agents already

00:31:52,520 --> 00:31:58,100
running and you want to introduce new

00:31:54,500 --> 00:32:00,770
agents with new code then I wish there

00:31:58,100 --> 00:32:05,539
was an automated way of doing rolling

00:32:00,770 --> 00:32:09,530
upgrades which is which can take into

00:32:05,539 --> 00:32:11,120
account the specific measurements we

00:32:09,530 --> 00:32:12,890
would have to say that the new code is

00:32:11,120 --> 00:32:14,390
working or not right so some kind of

00:32:12,890 --> 00:32:17,720
automation they are we trying to build

00:32:14,390 --> 00:32:19,520
that so there's probably more I wanted

00:32:17,720 --> 00:32:21,500
to highlight these three and then I

00:32:19,520 --> 00:32:23,720
would love to hear from others what else

00:32:21,500 --> 00:32:26,830
that you guys working on or if you

00:32:23,720 --> 00:32:30,260
worked on part about some of these what

00:32:26,830 --> 00:32:32,630
what you have to offer at this moment so

00:32:30,260 --> 00:32:36,429
let's actually open it up for questions

00:32:32,630 --> 00:32:36,429
that's all I had in slides

00:32:50,740 --> 00:32:58,110
this one work yeah excuse me for fens oh

00:32:56,350 --> 00:33:00,250
are you thinking about putting in

00:32:58,110 --> 00:33:04,870
support for the maintenance primitives

00:33:00,250 --> 00:33:06,820
and how to prevent penso from scheduling

00:33:04,870 --> 00:33:11,440
on something that has a maintenance

00:33:06,820 --> 00:33:13,720
window or or things like that yeah that

00:33:11,440 --> 00:33:16,600
would make perfect sense we are not

00:33:13,720 --> 00:33:19,240
using maintenance primitives in Netflix

00:33:16,600 --> 00:33:22,420
right now because of how we deploy

00:33:19,240 --> 00:33:25,780
agents we have more of a red-black kind

00:33:22,420 --> 00:33:28,870
of deploy of agents so that's one reason

00:33:25,780 --> 00:33:32,020
we do not however what we are looking at

00:33:28,870 --> 00:33:33,520
is we have a case of bad agents or

00:33:32,020 --> 00:33:36,670
agents going bad some of them are dead

00:33:33,520 --> 00:33:38,520
on arrival but more interestingly some

00:33:36,670 --> 00:33:40,809
of them go bad after some time

00:33:38,520 --> 00:33:44,260
maintenance primitives may be useful

00:33:40,809 --> 00:33:47,470
there I don't think we have a specific

00:33:44,260 --> 00:33:48,940
use case for maintenance murders so when

00:33:47,470 --> 00:33:50,679
it would make sense if somebody wants to

00:33:48,940 --> 00:33:58,120
work on it for friends oh we would love

00:33:50,679 --> 00:33:59,920
to collaborate and capr Thanks if you

00:33:58,120 --> 00:34:02,559
know for sure what a work load requires

00:33:59,920 --> 00:34:04,809
in terms of memory disk network stuff

00:34:02,559 --> 00:34:07,540
like that why would you have a noisy

00:34:04,809 --> 00:34:11,290
neighbor if you've properly specified

00:34:07,540 --> 00:34:15,429
what a container is going to need it's

00:34:11,290 --> 00:34:17,530
probably the inability for us to specify

00:34:15,429 --> 00:34:19,389
everything an application needs I think

00:34:17,530 --> 00:34:22,600
it's easy to think of it in terms of

00:34:19,389 --> 00:34:25,690
what we know CPU memory amount of memory

00:34:22,600 --> 00:34:29,350
and amount of network bandwidth but

00:34:25,690 --> 00:34:32,109
there's caches on the CPUs there's the

00:34:29,350 --> 00:34:34,480
whole memory bandwidth issues numinous

00:34:32,109 --> 00:34:35,500
of the architecture on the cpus there's

00:34:34,480 --> 00:34:38,379
so many other things that are happening

00:34:35,500 --> 00:34:40,419
that have impact application performance

00:34:38,379 --> 00:34:43,450
so if you were to run that application

00:34:40,419 --> 00:34:44,800
in isolation on that machine and you

00:34:43,450 --> 00:34:47,369
would still use the same number of CPUs

00:34:44,800 --> 00:34:51,659
versus with other applications mixed

00:34:47,369 --> 00:34:51,659
there are performance implications

00:34:53,230 --> 00:35:01,480
I can speak to the noisy neighbor

00:34:59,440 --> 00:35:03,490
problem a little bit Intel's done some

00:35:01,480 --> 00:35:04,840
research on that and one thing is that

00:35:03,490 --> 00:35:07,200
one of the things it's finding out in

00:35:04,840 --> 00:35:10,450
noisy neighbor scenarios is oftentimes

00:35:07,200 --> 00:35:12,430
replicates of a sink of the same tasks

00:35:10,450 --> 00:35:14,020
that are given exactly the same resource

00:35:12,430 --> 00:35:16,090
requirements exactly the same thing they

00:35:14,020 --> 00:35:17,530
can beat each other's noisy neighbors so

00:35:16,090 --> 00:35:19,990
once you actually know what something

00:35:17,530 --> 00:35:21,940
does require you instantiate hundreds of

00:35:19,990 --> 00:35:23,560
those and they can actually interfere

00:35:21,940 --> 00:35:25,210
with one another which is an interesting

00:35:23,560 --> 00:35:27,580
point the question I wanted to ask you

00:35:25,210 --> 00:35:30,280
it has to do with whether you've

00:35:27,580 --> 00:35:32,800
considered applying a predictive

00:35:30,280 --> 00:35:36,340
analytics to determining noisy neighbor

00:35:32,800 --> 00:35:40,900
scenarios in the future or or being able

00:35:36,340 --> 00:35:42,460
to squelch those before they happen yeah

00:35:40,900 --> 00:35:44,080
I think that's a good question have you

00:35:42,460 --> 00:35:47,200
considered that I think we've dreamt

00:35:44,080 --> 00:35:49,540
about it we haven't solved that we

00:35:47,200 --> 00:35:51,609
touched upon an aspect of that in the

00:35:49,540 --> 00:35:56,920
user panel this morning so that would be

00:35:51,609 --> 00:35:59,859
wonderful to have yes I was curious

00:35:56,920 --> 00:36:01,690
about the availability zones being a

00:35:59,859 --> 00:36:03,730
soft constraint and whether that can

00:36:01,690 --> 00:36:05,619
allow services to end up being deployed

00:36:03,730 --> 00:36:07,990
in a way that are not you know highly

00:36:05,619 --> 00:36:10,420
available if that constraint happens to

00:36:07,990 --> 00:36:11,470
be satisfied and scheduled on that note

00:36:10,420 --> 00:36:14,500
even though it's not in another

00:36:11,470 --> 00:36:17,350
availability zone yeah that's an

00:36:14,500 --> 00:36:19,210
excellent catch it's a soft constraint

00:36:17,350 --> 00:36:21,970
or a hard constraint and it's deliberate

00:36:19,210 --> 00:36:24,820
for one specific reason which is if you

00:36:21,970 --> 00:36:26,590
were to have a zone outage we use three

00:36:24,820 --> 00:36:28,440
zones right now and if we were to have a

00:36:26,590 --> 00:36:31,510
zone outage and you launched the service

00:36:28,440 --> 00:36:32,740
then one third of your service will not

00:36:31,510 --> 00:36:34,750
be up and running if it's a hard

00:36:32,740 --> 00:36:37,270
constraint that's the reason we make it

00:36:34,750 --> 00:36:40,690
a soft constraint but the downside is

00:36:37,270 --> 00:36:42,910
that if the zone is down then the

00:36:40,690 --> 00:36:44,530
service is only running across two zones

00:36:42,910 --> 00:36:48,450
so right now we haven't solved that

00:36:44,530 --> 00:36:51,850
completely but what's coming later is

00:36:48,450 --> 00:36:53,890
dynamically reshuffling them to make

00:36:51,850 --> 00:36:55,450
sure that

00:36:53,890 --> 00:36:57,870
well balanced but we haven't done that

00:36:55,450 --> 00:36:57,870
work yet

00:37:05,510 --> 00:37:11,330
so fenzel right now has a dependency on

00:37:08,030 --> 00:37:14,180
mesas 0.21 what are the challenges to

00:37:11,330 --> 00:37:21,620
bring it up to 1.4 I think it's the

00:37:14,180 --> 00:37:23,720
latest mesos so we run well there's two

00:37:21,620 --> 00:37:26,680
different frameworks we run at Netflix

00:37:23,720 --> 00:37:29,630
one of them is running at one point one

00:37:26,680 --> 00:37:33,590
or if not one point two and the other is

00:37:29,630 --> 00:37:35,420
running at one point Oh dot something so

00:37:33,590 --> 00:37:39,020
and then we do the dependency management

00:37:35,420 --> 00:37:42,920
of course that winds over wordfence or

00:37:39,020 --> 00:37:47,090
provides offensive has we've not port

00:37:42,920 --> 00:37:49,130
the later maysa functionality into fence

00:37:47,090 --> 00:37:55,400
out so it's able to stay a little bit

00:37:49,130 --> 00:37:57,320
older if we were to move it to 1.4 I

00:37:55,400 --> 00:37:58,820
think if Enzo itself would work fine it

00:37:57,320 --> 00:38:02,450
does not use any specific missus

00:37:58,820 --> 00:38:05,090
features right now we haven't moved red

00:38:02,450 --> 00:38:07,400
because it was not needed this is no

00:38:05,090 --> 00:38:09,290
other reason but I think I don't know if

00:38:07,400 --> 00:38:11,720
you were also implying that there are

00:38:09,290 --> 00:38:13,700
newer features that we need to add in

00:38:11,720 --> 00:38:14,960
defense uh but I think we haven't done

00:38:13,700 --> 00:38:16,460
that yet we would love to get

00:38:14,960 --> 00:38:18,440
contributions if somebody's focused on

00:38:16,460 --> 00:38:19,730
it yeah mostly just knowing the

00:38:18,440 --> 00:38:22,340
challenges of what it would take to

00:38:19,730 --> 00:38:24,950
bring the current fenzel codebase into a

00:38:22,340 --> 00:38:30,620
compatibility with the latest nice those

00:38:24,950 --> 00:38:33,200
live library yeah it works because of

00:38:30,620 --> 00:38:35,240
thanks to mesas being pretty compatible

00:38:33,200 --> 00:38:37,100
across versions and we are not using

00:38:35,240 --> 00:38:41,210
some of the new features so it still

00:38:37,100 --> 00:38:44,870
works but yeah that should not be a

00:38:41,210 --> 00:38:46,280
problem thank you I think that's about

00:38:44,870 --> 00:38:47,040
all we have time for thank you very much

00:38:46,280 --> 00:38:49,170
all right

00:38:47,040 --> 00:38:52,269
[Applause]

00:38:49,170 --> 00:38:52,269

YouTube URL: https://www.youtube.com/watch?v=PiPXFvLZuik


