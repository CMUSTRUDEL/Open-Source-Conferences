Title: API Gateway Pattern & Kong in a Microservices World
Publication date: 2017-09-18
Playlist: MesosCon North America 2017
Description: 
	API Gateway Pattern & Kong in a Microservices World - Marco Palladino, Mashape

Kong (https://getkong.org/) is the most widely adopted OSS gateway for APIs and 
Microservices. Built on top of Lua and NGINX, Kong can is a high-performance 
gateway that can be elastically deployed behind the firewall to secure, protect 
and extend RESTful APIs and Microservices via Kong Plugins.

In a container world APIs are becoming increasingly more important as a
communication medium - inside and outside the firewall. The more services are 
being created, the harder it gets to efficiently secure, manage and extend them 
in a variety of environments, in singe or multi-DC setups.

API gateways can be used to centralized common functionality in one place, by 
providing a highly performant, extensible and lightweight layer for both 
internal and external services, including serverless functions.

About

Marco Palladino
Kong
CTO
San Francisco
Websitehttps://getkong.org
Marco Palladino is an inventor, software developer, and internet entrepreneur. He is the co-founder and CTO of Mashape, which was started in 2010 and is based in San Francisco, California. He is currently responsible for the design and delivery of the Mashape products, while also providing the technical thought leadership around APIs and Microservices within Mashape and the external community. This includes being one of the core maintainer of Kong, the most widely adopted open-source API gateway for Microservices, that came out of Mashape. He is also the creator of the largest API marketplace in the world.
Captions: 
	00:00:00,030 --> 00:00:06,779
okay I guess we can start my name is

00:00:04,110 --> 00:00:10,050
Marco I'm the CTO and co-founder of

00:00:06,779 --> 00:00:12,870
mashape misshape it's one of the makers

00:00:10,050 --> 00:00:14,759
of conch the API gateway and today we're

00:00:12,870 --> 00:00:17,490
going to talk about micro services we're

00:00:14,759 --> 00:00:20,220
going to talk about Khong gateways and

00:00:17,490 --> 00:00:22,170
how the two really work together and you

00:00:20,220 --> 00:00:24,689
know we're also going to show a demo of

00:00:22,170 --> 00:00:28,260
Kong running on top of messes so I've

00:00:24,689 --> 00:00:29,580
got my environment running so we're

00:00:28,260 --> 00:00:31,890
going to see Kong in action we're gonna

00:00:29,580 --> 00:00:41,760
add an API on top of Kong and see how

00:00:31,890 --> 00:00:43,980
all of this fits together so before I

00:00:41,760 --> 00:00:46,500
even start why are we talking about

00:00:43,980 --> 00:00:50,160
gateways and micro services what's

00:00:46,500 --> 00:00:53,039
happening right now well so micro

00:00:50,160 --> 00:00:55,320
services are the software answer to more

00:00:53,039 --> 00:00:57,449
and more complex demand to more and more

00:00:55,320 --> 00:01:00,629
complex requirements that our software

00:00:57,449 --> 00:01:03,090
has to take care of API is you know got

00:01:00,629 --> 00:01:05,040
very popular in 2007 you had a mobile

00:01:03,090 --> 00:01:07,860
app you had a public developer community

00:01:05,040 --> 00:01:10,110
so how do we you know make these

00:01:07,860 --> 00:01:13,049
developers consume these applications

00:01:10,110 --> 00:01:15,000
consume our API since I mean sometimes

00:01:13,049 --> 00:01:17,549
API is used to be an afterthought hey we

00:01:15,000 --> 00:01:20,729
have to create an API so that developers

00:01:17,549 --> 00:01:23,670
and mobile apps can consume our our

00:01:20,729 --> 00:01:25,710
system and then as we onboard more and

00:01:23,670 --> 00:01:28,710
more partners as we support more and

00:01:25,710 --> 00:01:31,290
more platforms software becomes more

00:01:28,710 --> 00:01:35,340
complex and micro services really in

00:01:31,290 --> 00:01:37,590
2014 start this huge trajectory and

00:01:35,340 --> 00:01:41,939
adoption and do you know why it's

00:01:37,590 --> 00:01:44,369
happening in 2014 well docker

00:01:41,939 --> 00:01:46,710
was released a year ago a year before

00:01:44,369 --> 00:01:49,350
I'm sorry in 2013 which means that

00:01:46,710 --> 00:01:51,630
docker in containers are finally giving

00:01:49,350 --> 00:01:53,850
the tooling for everybody else from the

00:01:51,630 --> 00:01:56,040
rest of the world to engage into this

00:01:53,850 --> 00:01:57,840
transition to micro services some

00:01:56,040 --> 00:02:00,030
companies have done it before think of

00:01:57,840 --> 00:02:02,340
Amazon think of Netflix some companies

00:02:00,030 --> 00:02:03,960
were progressive enough to adopt micro

00:02:02,340 --> 00:02:06,270
services before this tooling was in

00:02:03,960 --> 00:02:08,580
place but really containers are what

00:02:06,270 --> 00:02:10,289
enabled the rest of us product micro

00:02:08,580 --> 00:02:12,270
services and move forward with this new

00:02:10,289 --> 00:02:15,070
way of building software

00:02:12,270 --> 00:02:17,440
you know somebody somebody said that

00:02:15,070 --> 00:02:19,720
moving from monolithic to microservices

00:02:17,440 --> 00:02:22,090
it's like moving from a chicken -

00:02:19,720 --> 00:02:23,680
chicken McNuggets right so you have this

00:02:22,090 --> 00:02:25,750
whole chicken you have your monolithic

00:02:23,680 --> 00:02:27,610
app and you're transitioning now to

00:02:25,750 --> 00:02:30,850
smaller components that are working

00:02:27,610 --> 00:02:32,920
together with each other and the whole

00:02:30,850 --> 00:02:35,020
thing is during this transition which is

00:02:32,920 --> 00:02:36,490
a very painful transition that pretty

00:02:35,020 --> 00:02:38,320
much every Enterprise it's doing right

00:02:36,490 --> 00:02:40,270
now this transition you have to keep the

00:02:38,320 --> 00:02:42,010
chicken alive you can't kill the chicken

00:02:40,270 --> 00:02:43,600
you know you need to keep supporting

00:02:42,010 --> 00:02:45,700
your clients you need to keep your

00:02:43,600 --> 00:02:49,810
applications running you have to engage

00:02:45,700 --> 00:02:51,820
into this transition by you know making

00:02:49,810 --> 00:02:53,470
your system working again keep working

00:02:51,820 --> 00:02:55,300
and there are different strategies to

00:02:53,470 --> 00:02:57,280
move to micro services you know there

00:02:55,300 --> 00:02:59,110
are three main strategies I would say

00:02:57,280 --> 00:03:01,709
I've been talking with lots of people

00:02:59,110 --> 00:03:04,180
lots of companies who are approaching

00:03:01,709 --> 00:03:05,950
this this transition now or have

00:03:04,180 --> 00:03:08,050
approached the transition before and

00:03:05,950 --> 00:03:10,630
usually it comes down to three different

00:03:08,050 --> 00:03:12,790
options there is the ice cream scoop

00:03:10,630 --> 00:03:16,780
strategy so you have this huge ice cream

00:03:12,790 --> 00:03:19,209
Cup and you need to extract from your

00:03:16,780 --> 00:03:22,090
monolithic app individual components and

00:03:19,209 --> 00:03:24,010
micro services then now can leave and be

00:03:22,090 --> 00:03:26,590
scaled separately the leaves separately

00:03:24,010 --> 00:03:28,450
that can be built separately and then

00:03:26,590 --> 00:03:30,310
there is the nuclear bomb strategy so

00:03:28,450 --> 00:03:33,489
companies some companies are deciding

00:03:30,310 --> 00:03:35,650
that monolithic it's not a solution

00:03:33,489 --> 00:03:38,380
anymore and so how about we just rewrite

00:03:35,650 --> 00:03:40,150
the entire software in micro services so

00:03:38,380 --> 00:03:42,700
they get rid of their monolithic app and

00:03:40,150 --> 00:03:46,420
they transition a hundred percent to

00:03:42,700 --> 00:03:49,870
micro services in dendi's would like to

00:03:46,420 --> 00:03:52,420
call the legacy macro service right so

00:03:49,870 --> 00:03:54,340
you only build new technologies new

00:03:52,420 --> 00:03:56,320
software new products in a micro

00:03:54,340 --> 00:03:59,980
service-oriented architecture so you

00:03:56,320 --> 00:04:02,980
keep your legacy monolithic app there

00:03:59,980 --> 00:04:05,260
instead of your system as a gigantic

00:04:02,980 --> 00:04:08,350
service effectively that works together

00:04:05,260 --> 00:04:10,780
with those new micro services that new

00:04:08,350 --> 00:04:12,760
teams are creating you know by the way

00:04:10,780 --> 00:04:14,860
transitioning from monolithic to micro

00:04:12,760 --> 00:04:15,489
services it's not just a technological

00:04:14,860 --> 00:04:18,280
change

00:04:15,489 --> 00:04:19,630
it's a organizational transition when

00:04:18,280 --> 00:04:21,849
you're transitioning and making this

00:04:19,630 --> 00:04:24,099
transition to micro services you are

00:04:21,849 --> 00:04:25,750
also changing how your teams are built

00:04:24,099 --> 00:04:29,260
how your teams are working together

00:04:25,750 --> 00:04:32,640
in how your organization its you know

00:04:29,260 --> 00:04:35,020
communicating with each other you

00:04:32,640 --> 00:04:38,890
effectively transition from large teams

00:04:35,020 --> 00:04:41,020
to smaller pizza teams and these smaller

00:04:38,890 --> 00:04:43,330
teams they can experiment with different

00:04:41,020 --> 00:04:45,940
technologies but effectively they're

00:04:43,330 --> 00:04:48,610
working on separate code bases and they

00:04:45,940 --> 00:04:50,440
need to publicize to the other teams and

00:04:48,610 --> 00:04:55,540
need an easy-to-use interface for them

00:04:50,440 --> 00:04:58,420
to understand think of uber sober used

00:04:55,540 --> 00:05:00,520
to have a huge monolithic app that was

00:04:58,420 --> 00:05:04,000
baking together all of these different

00:05:00,520 --> 00:05:06,430
you know feature functions in one

00:05:04,000 --> 00:05:08,350
codebase effectively and then they

00:05:06,430 --> 00:05:10,150
decided to extract all of these in

00:05:08,350 --> 00:05:12,370
thousands of separate micro services

00:05:10,150 --> 00:05:16,540
that now can operate independently from

00:05:12,370 --> 00:05:18,220
each other running running micro

00:05:16,540 --> 00:05:19,990
services right separating these

00:05:18,220 --> 00:05:21,940
monolithic apps into smaller p

00:05:19,990 --> 00:05:24,700
components it's really a little bit like

00:05:21,940 --> 00:05:27,100
running a city you need to have roads

00:05:24,700 --> 00:05:29,260
for these micro services to use to

00:05:27,100 --> 00:05:30,490
communicate you need to have fire

00:05:29,260 --> 00:05:32,650
departments you need to have security

00:05:30,490 --> 00:05:35,200
police departments you need to have an

00:05:32,650 --> 00:05:36,640
infrastructure in place that can make

00:05:35,200 --> 00:05:42,520
you successful with this new way of

00:05:36,640 --> 00:05:43,930
building software so you know since this

00:05:42,520 --> 00:05:47,020
is one of those transitions that

00:05:43,930 --> 00:05:48,520
everybody's doing right now I have it

00:05:47,020 --> 00:05:49,000
here on my slide deck so we can do it

00:05:48,520 --> 00:05:51,840
together

00:05:49,000 --> 00:05:54,850
right so we start from a monolithic app

00:05:51,840 --> 00:05:57,340
with all of these components built in

00:05:54,850 --> 00:06:00,160
into one code base and then one team

00:05:57,340 --> 00:06:02,770
comes in and decides to extract one of

00:06:00,160 --> 00:06:04,930
these services outside of the monolithic

00:06:02,770 --> 00:06:08,380
app and so we have this items micro

00:06:04,930 --> 00:06:10,540
service now that lives separately from

00:06:08,380 --> 00:06:12,250
all the other components and guess what

00:06:10,540 --> 00:06:13,419
once you have this micro service you

00:06:12,250 --> 00:06:14,740
know it doesn't live in a vacuum you

00:06:13,419 --> 00:06:17,260
need to have that infrastructure that

00:06:14,740 --> 00:06:21,400
city in place in order to be successful

00:06:17,260 --> 00:06:22,660
and so the same team will come in and

00:06:21,400 --> 00:06:24,280
build more and more logic that's

00:06:22,660 --> 00:06:26,890
complementary to this micro services

00:06:24,280 --> 00:06:29,080
success you build security features

00:06:26,890 --> 00:06:31,060
authentication features you build

00:06:29,080 --> 00:06:33,760
logging transformations you build all of

00:06:31,060 --> 00:06:35,800
that stuff and then another team or

00:06:33,760 --> 00:06:38,530
maybe the same team goes ahead and

00:06:35,800 --> 00:06:39,639
extracts another micro service and now

00:06:38,530 --> 00:06:42,639
you end up

00:06:39,639 --> 00:06:46,330
with rebuilding over and over again

00:06:42,639 --> 00:06:48,310
these complementary the feature features

00:06:46,330 --> 00:06:51,729
that every micro service micro service

00:06:48,310 --> 00:06:53,500
will will have to implement with lots of

00:06:51,729 --> 00:06:57,849
fragmentation across the board right

00:06:53,500 --> 00:07:01,270
lots of duplicated features lots of you

00:06:57,849 --> 00:07:03,849
know duplicated code bases that

00:07:01,270 --> 00:07:06,550
eventually will will create problems

00:07:03,849 --> 00:07:09,099
down the road in so gateways and api

00:07:06,550 --> 00:07:12,279
gateways can help in two different ways

00:07:09,099 --> 00:07:14,379
number one they can help by becoming an

00:07:12,279 --> 00:07:17,379
abstraction layer that sits on the

00:07:14,379 --> 00:07:19,270
execution path of every request that's

00:07:17,379 --> 00:07:21,939
going to one of these micro services and

00:07:19,270 --> 00:07:23,740
centralized together into one place all

00:07:21,939 --> 00:07:26,289
of those common features that otherwise

00:07:23,740 --> 00:07:28,180
each team or each micro service would

00:07:26,289 --> 00:07:29,979
have to implement so think of

00:07:28,180 --> 00:07:31,689
authentication security again login

00:07:29,979 --> 00:07:35,229
transformations service discovery and

00:07:31,689 --> 00:07:38,009
stuff like that in this case the Gateway

00:07:35,229 --> 00:07:40,960
its kong and we call those features

00:07:38,009 --> 00:07:43,240
plugins plugins are effectively

00:07:40,960 --> 00:07:46,089
middleware functionality that you can

00:07:43,240 --> 00:07:48,490
dynamically apply on top of any microt

00:07:46,089 --> 00:07:51,310
service behind the your kong cluster and

00:07:48,490 --> 00:07:55,990
then another use case for api gateways

00:07:51,310 --> 00:07:58,479
it's you know aggregating and collapsing

00:07:55,990 --> 00:08:00,969
different responses into one response

00:07:58,479 --> 00:08:03,909
when you have a micro service consuming

00:08:00,969 --> 00:08:05,650
other micro services sometimes you know

00:08:03,909 --> 00:08:08,319
you'll have to make requests to more

00:08:05,650 --> 00:08:10,210
than one upstream service and so what

00:08:08,319 --> 00:08:12,550
the gate we can do it can become that

00:08:10,210 --> 00:08:15,009
abstraction layer that you put in front

00:08:12,550 --> 00:08:17,529
of your micro service-oriented

00:08:15,009 --> 00:08:21,159
architecture in order to collapse these

00:08:17,529 --> 00:08:22,750
responses into one response so the

00:08:21,159 --> 00:08:24,639
client makes one request

00:08:22,750 --> 00:08:26,439
but then the Gateway itself will trigger

00:08:24,639 --> 00:08:28,659
other requests in your infrastructure

00:08:26,439 --> 00:08:32,229
and return one response that's a

00:08:28,659 --> 00:08:35,500
especially useful if if you want to

00:08:32,229 --> 00:08:38,430
optimize for for a bandwidth and for

00:08:35,500 --> 00:08:41,320
size because you do not have to retrieve

00:08:38,430 --> 00:08:42,729
or trigger multiple requests and keep

00:08:41,320 --> 00:08:44,229
track of the state of those requests

00:08:42,729 --> 00:08:47,070
from your clients because the gate we

00:08:44,229 --> 00:08:47,070
will do that for you

00:08:47,310 --> 00:08:53,800
Gateway's are also been used for a third

00:08:49,630 --> 00:08:55,900
use case which is you know decoupling

00:08:53,800 --> 00:08:58,570
that monolithic app under the hood

00:08:55,900 --> 00:09:00,430
without having clients to deal with

00:08:58,570 --> 00:09:02,350
these changes so assuming you have a

00:09:00,430 --> 00:09:04,150
client consuming a monolithic app and

00:09:02,350 --> 00:09:06,160
assuming you are decoupling that

00:09:04,150 --> 00:09:09,310
monolithic app now the client needs to

00:09:06,160 --> 00:09:11,529
know you know where to make those

00:09:09,310 --> 00:09:13,390
requests but the Gateway can be that

00:09:11,529 --> 00:09:15,550
curtain you put in front of your

00:09:13,390 --> 00:09:17,890
monolithic application the client will

00:09:15,550 --> 00:09:19,839
deal with them with the Gateway only and

00:09:17,890 --> 00:09:22,029
then you can decouple your monolithic

00:09:19,839 --> 00:09:23,710
behind the curtain without having to

00:09:22,029 --> 00:09:25,420
worry about updating your clients and

00:09:23,710 --> 00:09:30,460
this is especially useful if you do not

00:09:25,420 --> 00:09:32,050
control your clients you know when you

00:09:30,460 --> 00:09:33,580
when you think of when you think of

00:09:32,050 --> 00:09:35,260
gateways you really think of something

00:09:33,580 --> 00:09:37,540
that stays in the edge because that

00:09:35,260 --> 00:09:40,450
would get api gateways used to do so you

00:09:37,540 --> 00:09:43,300
know back in the days you had your

00:09:40,450 --> 00:09:45,580
monolithic app you had your api api is

00:09:43,300 --> 00:09:48,160
sometimes where an afterthought and then

00:09:45,580 --> 00:09:50,260
the api management solutions you would

00:09:48,160 --> 00:09:52,270
adopt where monolithic black box is

00:09:50,260 --> 00:09:55,000
effectively closed source hard to extend

00:09:52,270 --> 00:09:56,800
and hard to scale in a way but then with

00:09:55,000 --> 00:09:59,440
containers and micro services something

00:09:56,800 --> 00:10:02,529
happen first of all the topology of our

00:09:59,440 --> 00:10:04,540
traffic it's increasingly being behind

00:10:02,529 --> 00:10:06,790
the firewall and not just outside of the

00:10:04,540 --> 00:10:10,779
firewall you have lock critical

00:10:06,790 --> 00:10:12,700
information happening here in in behind

00:10:10,779 --> 00:10:14,589
your firewall and you cannot put a black

00:10:12,700 --> 00:10:15,880
box you can control effectively you want

00:10:14,589 --> 00:10:18,580
to put something you can extend

00:10:15,880 --> 00:10:20,650
something that can scale alongside your

00:10:18,580 --> 00:10:22,650
micro services into pretty much any

00:10:20,650 --> 00:10:26,380
container contains a shim platform

00:10:22,650 --> 00:10:28,450
measures for example you still have the

00:10:26,380 --> 00:10:30,880
external client use case but that

00:10:28,450 --> 00:10:32,620
becomes one of the many clients that are

00:10:30,880 --> 00:10:34,150
now consuming those micro services and

00:10:32,620 --> 00:10:36,400
the reason is the reason why we have

00:10:34,150 --> 00:10:37,779
these you know increase of communication

00:10:36,400 --> 00:10:39,850
well you probably read you know it it's

00:10:37,779 --> 00:10:41,260
straightforward micro services have to

00:10:39,850 --> 00:10:42,850
communicate with each other in order to

00:10:41,260 --> 00:10:44,290
function a monolithic IP doesn't have

00:10:42,850 --> 00:10:44,740
this problem everything it's the same

00:10:44,290 --> 00:10:46,089
codebase

00:10:44,740 --> 00:10:48,370
so you don't really have to go on a

00:10:46,089 --> 00:10:51,930
network most of the times to provide

00:10:48,370 --> 00:10:55,030
what you have to do and so you know

00:10:51,930 --> 00:10:57,700
actively this changed how gateways are

00:10:55,030 --> 00:11:00,190
being used internally but when you think

00:10:57,700 --> 00:11:00,830
of of gateways again you usually think

00:11:00,190 --> 00:11:02,990
of us

00:11:00,830 --> 00:11:05,690
relized lair an extra hop in the network

00:11:02,990 --> 00:11:07,610
that are processing you know these

00:11:05,690 --> 00:11:09,770
additional features but that doesn't

00:11:07,610 --> 00:11:12,280
necessarily have to be true you can also

00:11:09,770 --> 00:11:15,770
run a system like conch for example

00:11:12,280 --> 00:11:18,920
alongside your existing micro service

00:11:15,770 --> 00:11:21,170
process you can effectively then get rid

00:11:18,920 --> 00:11:23,810
of that extra hop in the network and

00:11:21,170 --> 00:11:27,050
reduce the latency now latency it's

00:11:23,810 --> 00:11:30,620
another important factor you know in

00:11:27,050 --> 00:11:32,210
back in the days if that solution added

00:11:30,620 --> 00:11:34,220
a hundred milliseconds or 200

00:11:32,210 --> 00:11:35,780
milliseconds of latency on top of your

00:11:34,220 --> 00:11:37,880
requests and responses that was not

00:11:35,780 --> 00:11:41,390
ideal but it's something you could live

00:11:37,880 --> 00:11:43,910
with with micro services every latency

00:11:41,390 --> 00:11:45,800
compounds and so at the end of the day

00:11:43,910 --> 00:11:47,030
you will end up with an enormous latency

00:11:45,800 --> 00:11:52,670
if you don't take that into account

00:11:47,030 --> 00:11:56,240
immediately so I can show you how Cong

00:11:52,670 --> 00:11:59,420
can you know implement sub millisecond

00:11:56,240 --> 00:12:02,600
latency on most of these features you

00:11:59,420 --> 00:12:05,330
know micro services can provide internal

00:12:02,600 --> 00:12:07,250
communication private communication or

00:12:05,330 --> 00:12:08,780
maybe external with two partners for

00:12:07,250 --> 00:12:10,310
example or with a public developer

00:12:08,780 --> 00:12:12,260
community or maybe you're starting to

00:12:10,310 --> 00:12:14,810
adopt functions as a service or server

00:12:12,260 --> 00:12:18,380
lines functions with AWS lambda I be

00:12:14,810 --> 00:12:20,930
able a BM Open whisk and khÃ´ng supports

00:12:18,380 --> 00:12:23,990
all these use cases you put it in front

00:12:20,930 --> 00:12:25,850
and then Kahn can handle for you all of

00:12:23,990 --> 00:12:29,060
those common features you you need to

00:12:25,850 --> 00:12:31,400
execute on every request effectively you

00:12:29,060 --> 00:12:33,260
are reducing the fragmentation of your

00:12:31,400 --> 00:12:36,500
system you're moving from the picture to

00:12:33,260 --> 00:12:39,130
the left to the right you are putting in

00:12:36,500 --> 00:12:41,840
one logical place all of these

00:12:39,130 --> 00:12:43,730
functionalities so let's let's talk

00:12:41,840 --> 00:12:46,490
about concrete technology so what is

00:12:43,730 --> 00:12:49,400
Congress conch it's an open source API

00:12:46,490 --> 00:12:51,260
gateway it's the most widely adopted API

00:12:49,400 --> 00:12:53,990
gateway right now we have more than

00:12:51,260 --> 00:12:57,110
300,000 running instances per month

00:12:53,990 --> 00:12:59,900
across the world it's built on top of

00:12:57,110 --> 00:13:02,480
nginx and nginx it's a very solid

00:12:59,900 --> 00:13:05,540
foundation for us chances are if you

00:13:02,480 --> 00:13:07,340
have an API you're ready using nginx you

00:13:05,540 --> 00:13:10,190
know it's an engine X process that

00:13:07,340 --> 00:13:12,170
starts up and then it's being extended

00:13:10,190 --> 00:13:14,180
with all of the Gateway features we call

00:13:12,170 --> 00:13:15,920
those gateway features plugins and

00:13:14,180 --> 00:13:19,100
wagons are Middleware features you can

00:13:15,920 --> 00:13:22,040
apply dynamically on top of any API or

00:13:19,100 --> 00:13:25,610
micro service behind Kong you do that

00:13:22,040 --> 00:13:27,950
with an admin API that come provides so

00:13:25,610 --> 00:13:30,920
you have a JSON restful api that allows

00:13:27,950 --> 00:13:33,080
you to provision new services on top of

00:13:30,920 --> 00:13:35,450
Conch to provision new consumers new

00:13:33,080 --> 00:13:37,580
credentials to provision new plugins in

00:13:35,450 --> 00:13:39,410
a dynamic way doesn't matter if you have

00:13:37,580 --> 00:13:42,200
one kong node or a hundred kong nodes

00:13:39,410 --> 00:13:45,260
across five different data centers the

00:13:42,200 --> 00:13:47,390
admin API will eventually propagate all

00:13:45,260 --> 00:13:50,440
of these information across every node

00:13:47,390 --> 00:13:52,760
every kong node without you having to

00:13:50,440 --> 00:13:56,560
restart to reload those nodes without

00:13:52,760 --> 00:13:56,560
you having to reconfigure those nodes

00:14:00,370 --> 00:14:07,310
cache most of the dynamic information

00:14:04,370 --> 00:14:10,220
kong has to deal with in the process in

00:14:07,310 --> 00:14:12,380
memory so after Kong warms up and I'm

00:14:10,220 --> 00:14:14,089
gonna show you later in the demo Kong

00:14:12,380 --> 00:14:16,760
will cache all this information in the

00:14:14,089 --> 00:14:18,770
process and for most use cases we will

00:14:16,760 --> 00:14:21,830
achieve a sub-millisecond processing

00:14:18,770 --> 00:14:22,940
latency on top of those requests we

00:14:21,830 --> 00:14:24,529
support pretty much every

00:14:22,940 --> 00:14:27,230
containerization platform it's cloud

00:14:24,529 --> 00:14:30,140
native we have a native support for 4

00:14:27,230 --> 00:14:32,570
meses and for the CE OS we also have an

00:14:30,140 --> 00:14:37,029
official conch package on universe if

00:14:32,570 --> 00:14:38,870
you're using mesosphere extremely fast

00:14:37,029 --> 00:14:41,200
and then khan comes in two different

00:14:38,870 --> 00:14:44,089
flavors right so we also deal with

00:14:41,200 --> 00:14:45,470
enterprise use cases across the board

00:14:44,089 --> 00:14:47,270
you know when you have an API whenever

00:14:45,470 --> 00:14:48,920
micro service-oriented architecture it

00:14:47,270 --> 00:14:50,209
doesn't really matter what industry are

00:14:48,920 --> 00:14:52,870
working into right if you're a

00:14:50,209 --> 00:14:56,060
healthcare if you are IOT if you are

00:14:52,870 --> 00:14:58,010
government if you are bank you will end

00:14:56,060 --> 00:15:01,040
up with the same set of use cases that

00:14:58,010 --> 00:15:02,150
everybody else has and so Kong it's you

00:15:01,040 --> 00:15:05,060
know it's being adopted by these

00:15:02,150 --> 00:15:06,370
customers all across the world in in

00:15:05,060 --> 00:15:09,500
four different time zones

00:15:06,370 --> 00:15:11,240
you know Asia pack us West US East in

00:15:09,500 --> 00:15:13,420
Europe to help dealing with these

00:15:11,240 --> 00:15:13,420
problems

00:15:15,010 --> 00:15:19,630
so let's take a look at plugins what

00:15:17,199 --> 00:15:20,709
what are plugins crank it's built on top

00:15:19,630 --> 00:15:22,959
of nginx in Lua

00:15:20,709 --> 00:15:25,660
on a system on a framework called the

00:15:22,959 --> 00:15:28,149
open resting in plugins our Lua

00:15:25,660 --> 00:15:30,550
it's Lua code effectively that hooks

00:15:28,149 --> 00:15:33,010
into the life cycle of every request and

00:15:30,550 --> 00:15:34,870
every response and then executes some

00:15:33,010 --> 00:15:37,510
sort of operation it can also change how

00:15:34,870 --> 00:15:39,850
the request it's being made it can also

00:15:37,510 --> 00:15:42,100
change the response so for example there

00:15:39,850 --> 00:15:44,079
are authentication plugins like plugins

00:15:42,100 --> 00:15:45,820
of any kind there is authentication or

00:15:44,079 --> 00:15:47,589
security there is logging but for

00:15:45,820 --> 00:15:49,720
example authentication plugins you want

00:15:47,589 --> 00:15:51,250
to you have an API you want to start

00:15:49,720 --> 00:15:53,760
authenticating those requests with a

00:15:51,250 --> 00:15:56,550
third-party open the connect provider or

00:15:53,760 --> 00:15:58,660
you want to implement OAuth 2.0

00:15:56,550 --> 00:16:01,480
authentication on top of that API

00:15:58,660 --> 00:16:04,029
you let Khong do that for you by

00:16:01,480 --> 00:16:07,360
installing those plugins on top of of

00:16:04,029 --> 00:16:10,180
your micro service maybe you want to

00:16:07,360 --> 00:16:13,060
start invoking and reacting reacting to

00:16:10,180 --> 00:16:15,160
events and you want to trigger AWS

00:16:13,060 --> 00:16:17,230
lambda function invocations you want to

00:16:15,160 --> 00:16:18,820
trigger I blame open risk actions you

00:16:17,230 --> 00:16:20,980
can still do that on top of Kong and

00:16:18,820 --> 00:16:22,959
then add other plugins as well on top of

00:16:20,980 --> 00:16:24,699
your execution lifecycle to protect

00:16:22,959 --> 00:16:27,569
secure and rate limit how these

00:16:24,699 --> 00:16:30,639
functions are being invoked for example

00:16:27,569 --> 00:16:32,550
and and this is really how you use

00:16:30,639 --> 00:16:35,110
plugins so you've got this admin API

00:16:32,550 --> 00:16:39,040
which allows you to configure the system

00:16:35,110 --> 00:16:41,079
so in this example here I'm applying the

00:16:39,040 --> 00:16:43,690
rate-limiting plugin on top of that

00:16:41,079 --> 00:16:46,870
specific API with that specific ID I

00:16:43,690 --> 00:16:48,220
make this one request and I tell Kong ok

00:16:46,870 --> 00:16:50,170
every plugin has its own configuration

00:16:48,220 --> 00:16:52,199
right so in this case I'm telling Kong I

00:16:50,170 --> 00:16:55,540
want to allow 10 requests per second

00:16:52,199 --> 00:16:57,639
50,000 requests per hour I execute this

00:16:55,540 --> 00:17:00,370
request and now Kong will dynamically

00:16:57,639 --> 00:17:02,980
apply this plug-in on top of my API

00:17:00,370 --> 00:17:05,890
across every node so effectively if you

00:17:02,980 --> 00:17:08,020
have many data centers you have just you

00:17:05,890 --> 00:17:10,179
have just that you know apply that

00:17:08,020 --> 00:17:15,189
distributed rate limiting feature on top

00:17:10,179 --> 00:17:17,260
of your inter cluster its platform

00:17:15,189 --> 00:17:19,990
agnostic runs pretty much anywhere and

00:17:17,260 --> 00:17:23,350
most importantly it can run on in hybrid

00:17:19,990 --> 00:17:25,480
environments we do have you know came

00:17:23,350 --> 00:17:27,939
across some use cases of customers that

00:17:25,480 --> 00:17:28,780
are transitioning to containers not

00:17:27,939 --> 00:17:30,700
everybody is

00:17:28,780 --> 00:17:33,160
as progressive as the people here in

00:17:30,700 --> 00:17:34,870
this conference some companies some some

00:17:33,160 --> 00:17:36,460
teams are slowly transitioning in

00:17:34,870 --> 00:17:38,950
containers some things are still stuck

00:17:36,460 --> 00:17:40,810
with soap and you know they want soap to

00:17:38,950 --> 00:17:44,350
rest right so the world it's ten years

00:17:40,810 --> 00:17:46,300
behind what we are discussing here in

00:17:44,350 --> 00:17:48,910
containers the world is moving there so

00:17:46,300 --> 00:17:51,010
that's good news in some companies for

00:17:48,910 --> 00:17:53,020
example want to run hybrid clusters of

00:17:51,010 --> 00:17:55,030
Kong they are transitioning from bare

00:17:53,020 --> 00:17:56,560
metal to the cloud or bare metal to

00:17:55,030 --> 00:17:57,700
containers or maybe they are playing

00:17:56,560 --> 00:18:00,010
with different containers Asian

00:17:57,700 --> 00:18:02,410
platforms and they can spin up a con

00:18:00,010 --> 00:18:05,170
cluster that runs across the board and

00:18:02,410 --> 00:18:11,890
shares data with each other node across

00:18:05,170 --> 00:18:13,600
these other installations deployments if

00:18:11,890 --> 00:18:15,790
you're using mesosphere in this u.s.

00:18:13,600 --> 00:18:16,960
it's extremely fast to start getting up

00:18:15,790 --> 00:18:18,700
and running with Kong you just search

00:18:16,960 --> 00:18:21,840
for Kong and it's one one-click

00:18:18,700 --> 00:18:24,700
deployment and you and you're good to go

00:18:21,840 --> 00:18:27,550
so let's take a look at the architecture

00:18:24,700 --> 00:18:32,260
of Kong okay so Kong it's a stateless

00:18:27,550 --> 00:18:34,870
server you can run Kong you can add Kong

00:18:32,260 --> 00:18:35,380
nodes remove Kong nodes nothing will

00:18:34,870 --> 00:18:36,910
happen

00:18:35,380 --> 00:18:38,620
the state is being stored in either

00:18:36,910 --> 00:18:39,340
Cassandra post class you can choose it's

00:18:38,620 --> 00:18:42,250
either or

00:18:39,340 --> 00:18:44,290
we recommend Cassandra for distributed

00:18:42,250 --> 00:18:47,640
and more complex use cases we recommend

00:18:44,290 --> 00:18:50,470
Postgres for simpler use cases

00:18:47,640 --> 00:18:51,580
Postgres and the reason is post class

00:18:50,470 --> 00:18:54,250
it's you know a master/slave datastore

00:18:51,580 --> 00:18:56,440
so if you're running a con node in an ad

00:18:54,250 --> 00:18:59,350
or data center that connote will have to

00:18:56,440 --> 00:19:01,390
go all the way to the master DC of

00:18:59,350 --> 00:19:03,640
Postgres in order to write some

00:19:01,390 --> 00:19:05,530
information with cassandra instead you

00:19:03,640 --> 00:19:08,350
haven't eventually consisted consistent

00:19:05,530 --> 00:19:10,180
distributed data store you can its

00:19:08,350 --> 00:19:11,890
master less effectively you can write

00:19:10,180 --> 00:19:13,120
and read from any node in Cassandra

00:19:11,890 --> 00:19:15,220
itself will then take care of to

00:19:13,120 --> 00:19:17,800
replicate this information across the

00:19:15,220 --> 00:19:19,720
board and as long as your kong nodes

00:19:17,800 --> 00:19:22,330
communicate to the same cassandra key

00:19:19,720 --> 00:19:23,830
space or Postgres database then you're

00:19:22,330 --> 00:19:26,560
good to go they will all share the same

00:19:23,830 --> 00:19:28,870
data now the trick is kong doesn't make

00:19:26,560 --> 00:19:30,910
a request to the datastore on every

00:19:28,870 --> 00:19:32,980
request that comes in it only makes a

00:19:30,910 --> 00:19:35,170
request to the datastore the first time

00:19:32,980 --> 00:19:37,660
and then it will cache this information

00:19:35,170 --> 00:19:41,050
in memory in the process which means

00:19:37,660 --> 00:19:42,640
that after Kong warms up it will not it

00:19:41,050 --> 00:19:44,950
won't have to go again on the day

00:19:42,640 --> 00:19:47,890
you can tolerate a datastore failure in

00:19:44,950 --> 00:19:50,620
Kangol process of this in memory if

00:19:47,890 --> 00:19:54,760
you're changing the same data from a

00:19:50,620 --> 00:19:57,070
different connotation will propagate an

00:19:54,760 --> 00:19:59,050
invalidation event across every con note

00:19:57,070 --> 00:20:01,510
telling the Connaught hey this data has

00:19:59,050 --> 00:20:03,430
changed the local copy you have in

00:20:01,510 --> 00:20:06,310
memory it's not valid anymore so refetch

00:20:03,430 --> 00:20:09,270
it again from the datastore chunk it's

00:20:06,310 --> 00:20:14,200
built on top of nginx and open resting

00:20:09,270 --> 00:20:16,630
it's a very performant architecture

00:20:14,200 --> 00:20:19,420
we're running Lua code on top of the

00:20:16,630 --> 00:20:22,210
logit virtual machine legit it's a very

00:20:19,420 --> 00:20:24,670
fast c implementation of the Lua virtual

00:20:22,210 --> 00:20:30,460
machine and we can embed that into into

00:20:24,670 --> 00:20:32,170
nginx to script how nginx works on top

00:20:30,460 --> 00:20:34,090
of that we have added support for

00:20:32,170 --> 00:20:35,650
plastering in datastore so you don't

00:20:34,090 --> 00:20:37,450
have to worry once you start a Connaught

00:20:35,650 --> 00:20:39,040
you don't have to worry about restarting

00:20:37,450 --> 00:20:41,410
reloading it or reconfiguring it it's

00:20:39,040 --> 00:20:45,030
all dynamic in support for plugins

00:20:41,410 --> 00:20:47,650
plugins are written in Lua they

00:20:45,030 --> 00:20:50,200
basically request comes in took nginx

00:20:47,650 --> 00:20:52,840
and the implied ins takeover that

00:20:50,200 --> 00:20:54,820
requests in response and they change it

00:20:52,840 --> 00:20:56,680
if they have to do so and then they

00:20:54,820 --> 00:20:58,450
proxy to the upstream service and then

00:20:56,680 --> 00:21:00,970
when a response come back response

00:20:58,450 --> 00:21:03,340
plug-in can take again ownership of that

00:21:00,970 --> 00:21:05,470
process change with the response does

00:21:03,340 --> 00:21:07,990
and then return back to the client and

00:21:05,470 --> 00:21:11,350
on top of all of this we have got the

00:21:07,990 --> 00:21:13,300
admin API the admin API allows us to

00:21:11,350 --> 00:21:15,340
configure the entire system you can

00:21:13,300 --> 00:21:17,440
provision api's you can provision

00:21:15,340 --> 00:21:19,540
plugins you can provision credentials

00:21:17,440 --> 00:21:22,090
can't can run in two different modes you

00:21:19,540 --> 00:21:25,120
can decide for example to use Kong as

00:21:22,090 --> 00:21:26,950
your authentication store so Kong will

00:21:25,120 --> 00:21:28,720
store all the credentials and for

00:21:26,950 --> 00:21:31,150
example if you're using o out it will

00:21:28,720 --> 00:21:33,790
storage access tokens the Refresh tokens

00:21:31,150 --> 00:21:35,530
if you're using basic out it will store

00:21:33,790 --> 00:21:37,570
the username and passwords but that's

00:21:35,530 --> 00:21:39,160
not always ideal you can also use Kong

00:21:37,570 --> 00:21:41,260
in a different mode by leveraging a

00:21:39,160 --> 00:21:43,450
third-party authorization server to

00:21:41,260 --> 00:21:45,700
authenticate your request so for example

00:21:43,450 --> 00:21:47,410
any open ended connect compliant

00:21:45,700 --> 00:21:49,690
provider or allowed to open or

00:21:47,410 --> 00:21:52,140
introspection endpoint compliant

00:21:49,690 --> 00:21:52,140
providers

00:21:53,410 --> 00:21:59,830
when Kong starts it listens on on a few

00:21:56,290 --> 00:22:03,820
ports by default these ports are divided

00:21:59,830 --> 00:22:07,090
into proxy ports and admin API ports the

00:22:03,820 --> 00:22:09,880
proxy ports are the ports that your

00:22:07,090 --> 00:22:14,230
client will consume when he wants to

00:22:09,880 --> 00:22:15,760
consume a map Stream service so this is

00:22:14,230 --> 00:22:17,980
the one that would be made available to

00:22:15,760 --> 00:22:23,620
either other micro services or external

00:22:17,980 --> 00:22:24,160
clients in the admin API it's it's you

00:22:23,620 --> 00:22:25,480
know the one

00:22:24,160 --> 00:22:27,220
it's the API you're gonna use for

00:22:25,480 --> 00:22:31,390
configuring the system and of course you

00:22:27,220 --> 00:22:37,030
will fireball these ports to prevent

00:22:31,390 --> 00:22:38,830
external access in production so when

00:22:37,030 --> 00:22:41,680
dealing with Kong we're going to deal

00:22:38,830 --> 00:22:44,110
primarily with a few entities we're

00:22:41,680 --> 00:22:46,330
gonna deal with api's with plugins and

00:22:44,110 --> 00:22:48,970
with consumers these are core entities

00:22:46,330 --> 00:22:51,760
that sooner or that or later you will

00:22:48,970 --> 00:22:54,040
have to deal with when using Kong but

00:22:51,760 --> 00:22:57,010
then plugins themselves can extend the

00:22:54,040 --> 00:23:00,130
DAO the underlying Dao model of Kong by

00:22:57,010 --> 00:23:02,230
extending you know the system with new

00:23:00,130 --> 00:23:04,360
entities that you can use for example if

00:23:02,230 --> 00:23:07,180
you decide to adopt a key authentication

00:23:04,360 --> 00:23:09,100
plug-in well now you'll have a way on

00:23:07,180 --> 00:23:10,870
the Agni API to provision and store

00:23:09,100 --> 00:23:13,630
those key credentials and if you have

00:23:10,870 --> 00:23:15,160
for example again while 2.0 you will

00:23:13,630 --> 00:23:18,060
have api's that allows you to create

00:23:15,160 --> 00:23:27,040
world 2.0 applications tokens and

00:23:18,060 --> 00:23:30,570
authorization codes all right so I've

00:23:27,040 --> 00:23:35,740
got my demo environment running

00:23:30,570 --> 00:23:38,740
it's an Apache measures 1.3 open one on

00:23:35,740 --> 00:23:40,360
Amazon ec2 it's running it's very simple

00:23:38,740 --> 00:23:43,690
setup it's running one master two slaves

00:23:40,360 --> 00:23:45,930
and these are the URLs that I'm going to

00:23:43,690 --> 00:23:49,720
be using when configuring the system

00:23:45,930 --> 00:23:52,930
we've got Martin on port 8080 and then

00:23:49,720 --> 00:23:56,440
we've got the Kong proxy URL in the Kong

00:23:52,930 --> 00:24:02,100
admin URL on two different ports so I'll

00:23:56,440 --> 00:24:02,100
go ahead now and load my terminal

00:24:03,440 --> 00:24:16,309
first of all if I go here on my browser

00:24:11,049 --> 00:24:18,470
we can see this is Martin we can see the

00:24:16,309 --> 00:24:20,990
Cong the conga application running and

00:24:18,470 --> 00:24:23,149
if I clicking here we can see there are

00:24:20,990 --> 00:24:25,100
two different containers running there

00:24:23,149 --> 00:24:27,409
is Kong itself and then the respose

00:24:25,100 --> 00:24:30,710
grass so in this demo we're gonna use

00:24:27,409 --> 00:24:32,419
Postgres for storing all of these all

00:24:30,710 --> 00:24:36,440
the Kong State we only have one Kong

00:24:32,419 --> 00:24:41,210
node that's listening on two different

00:24:36,440 --> 00:24:44,210
ports so this is the proxy port so if

00:24:41,210 --> 00:24:45,710
you make a request to this port Kong

00:24:44,210 --> 00:24:47,240
it's not coming it's empty right now it

00:24:45,710 --> 00:24:51,440
doesn't know where to proxy this request

00:24:47,240 --> 00:24:54,139
to and then the other port it's the

00:24:51,440 --> 00:24:57,950
admin API of Kong so this is the default

00:24:54,139 --> 00:25:01,940
index index page for the admin API and

00:24:57,950 --> 00:25:03,559
for example if you go on slash api's we

00:25:01,940 --> 00:25:06,110
can see that there are no API is

00:25:03,559 --> 00:25:08,750
configuring the system so I'll go ahead

00:25:06,110 --> 00:25:11,389
and add and provision new API on top of

00:25:08,750 --> 00:25:13,669
Kong and then I will secure this API and

00:25:11,389 --> 00:25:17,809
then I will rate limit to this API using

00:25:13,669 --> 00:25:20,779
Kong plugins you can see a list of Kong

00:25:17,809 --> 00:25:22,460
plugins on the website these are the

00:25:20,779 --> 00:25:23,870
ones that come bundled with the system

00:25:22,460 --> 00:25:25,879
so these plugins are immediately

00:25:23,870 --> 00:25:27,470
available to you to be used but you can

00:25:25,879 --> 00:25:29,929
also extend the system with your own

00:25:27,470 --> 00:25:31,789
plugins so the RISM there is a guide in

00:25:29,929 --> 00:25:33,889
the docks which allows you to build new

00:25:31,789 --> 00:25:37,279
plugins and so these plugins that you're

00:25:33,889 --> 00:25:38,629
seeing here in the plugins hub so this

00:25:37,279 --> 00:25:40,879
is the guide for building new plugins

00:25:38,629 --> 00:25:44,570
and these plugins are seen here these

00:25:40,879 --> 00:25:46,250
are the ones that you know are the most

00:25:44,570 --> 00:25:47,659
common ones the most used ones but you

00:25:46,250 --> 00:25:49,639
can also go on the community on get up

00:25:47,659 --> 00:25:51,500
for example and find over 200

00:25:49,639 --> 00:25:53,269
contributions to plug-in skunk plugins

00:25:51,500 --> 00:25:56,419
to pretty much deal with any sort of use

00:25:53,269 --> 00:25:59,809
case you can also extend and build your

00:25:56,419 --> 00:26:01,610
own plugins for your own you know

00:25:59,809 --> 00:26:03,230
internal requirements so for example

00:26:01,610 --> 00:26:05,059
there are many users that have to deal

00:26:03,230 --> 00:26:06,860
with legacy authentication systems or

00:26:05,059 --> 00:26:08,870
have to deal with legacy transformations

00:26:06,860 --> 00:26:12,019
you can build plugins that are available

00:26:08,870 --> 00:26:14,119
only to you in your system that deal

00:26:12,019 --> 00:26:16,190
with that legacy use case for example so

00:26:14,119 --> 00:26:17,110
it's a highly extensible you effectively

00:26:16,190 --> 00:26:21,970
control

00:26:17,110 --> 00:26:23,789
everything about this gate will air okay

00:26:21,970 --> 00:26:27,629
[Music]

00:26:23,789 --> 00:26:30,399
so let's let's go ahead and provision an

00:26:27,629 --> 00:26:32,590
API so for this demo I'm going to use

00:26:30,399 --> 00:26:34,840
HTTP bin org I don't know if you're

00:26:32,590 --> 00:26:36,820
familiar with this service it's a cloud

00:26:34,840 --> 00:26:39,940
service that effectively provides

00:26:36,820 --> 00:26:42,070
provides some endpoints which we can

00:26:39,940 --> 00:26:44,019
consume to retrieve information about

00:26:42,070 --> 00:26:46,720
the request from making so for example

00:26:44,019 --> 00:26:50,830
use a slash get endpoint which returns

00:26:46,720 --> 00:26:53,169
back a JSON response with the headers

00:26:50,830 --> 00:26:55,809
the client in sending and this

00:26:53,169 --> 00:26:57,519
information we can use this for you know

00:26:55,809 --> 00:26:59,769
debugging really what's gonna what's

00:26:57,519 --> 00:27:06,639
happening between our client Kong and

00:26:59,769 --> 00:27:09,009
the final API all right so let's let's

00:27:06,639 --> 00:27:12,749
make a post request to provision our

00:27:09,009 --> 00:27:12,749
first API on top of conch

00:27:30,929 --> 00:27:36,330
effectively what I'm doing here it's

00:27:33,340 --> 00:27:39,190
telling Kong okay post a new object

00:27:36,330 --> 00:27:41,740
create a new object on your API whose

00:27:39,190 --> 00:27:45,220
name it's HTTP been the base upstream

00:27:41,740 --> 00:27:47,799
URL it's HTTP been org and the mapping

00:27:45,220 --> 00:27:49,929
it's going to be slash test you know

00:27:47,799 --> 00:27:52,029
when new requests coming to kong-kong

00:27:49,929 --> 00:27:53,830
needs to understand what upstream api

00:27:52,029 --> 00:27:55,299
were trying to consume and we can do

00:27:53,830 --> 00:27:57,669
that in different ways we can create a

00:27:55,299 --> 00:28:00,039
URI mapping we can create a host mapping

00:27:57,669 --> 00:28:02,080
or we can create a method HTTP method

00:28:00,039 --> 00:28:04,389
mapping or we can use any combination of

00:28:02,080 --> 00:28:06,399
this tree to create our custom mappings

00:28:04,389 --> 00:28:09,460
so effectively by doing this I'm telling

00:28:06,399 --> 00:28:13,139
Kong every request on slash test in Kong

00:28:09,460 --> 00:28:16,600
will have to go to this HTTP bin org API

00:28:13,139 --> 00:28:18,370
Kong can work very well with existing

00:28:16,600 --> 00:28:21,460
service discovery tools or you can use

00:28:18,370 --> 00:28:24,129
count as well its own built-in discovery

00:28:21,460 --> 00:28:27,549
tool for resolving dynamically those

00:28:24,129 --> 00:28:29,559
host names so for the demo I'm just in

00:28:27,549 --> 00:28:32,289
fact in putting Kong in front of a

00:28:29,559 --> 00:28:34,539
public API but you can put this in front

00:28:32,289 --> 00:28:38,470
of any internal or external API as well

00:28:34,539 --> 00:28:41,889
so if I make this request we've got our

00:28:38,470 --> 00:28:44,529
response Congress provision the API in

00:28:41,889 --> 00:28:48,070
the system and now it's ready to be

00:28:44,529 --> 00:28:50,169
consumed so if I if I make a request to

00:28:48,070 --> 00:28:53,879
the other port I can now consume that

00:28:50,169 --> 00:28:53,879
API so we'll see how it works

00:28:59,639 --> 00:29:05,159
if if I just make a dump request like

00:29:02,500 --> 00:29:07,480
this one here without any specific URI

00:29:05,159 --> 00:29:09,429
congo complain that no api's are found

00:29:07,480 --> 00:29:13,929
with value even if I do this you know

00:29:09,429 --> 00:29:16,450
there is no API that that matches you

00:29:13,929 --> 00:29:18,159
know that specific mapping but if I make

00:29:16,450 --> 00:29:19,899
a request on slash test which is the

00:29:18,159 --> 00:29:22,629
mapping we've created slash cat

00:29:19,899 --> 00:29:25,600
for example Kong will understand that

00:29:22,629 --> 00:29:29,500
we're trying to consume the HTTP API it

00:29:25,600 --> 00:29:32,799
will append on on the base URL we have

00:29:29,500 --> 00:29:35,529
configure the slash get endpoint it will

00:29:32,799 --> 00:29:38,529
strip out the slash test and then it

00:29:35,529 --> 00:29:38,910
will reverse proxy to http bin so this

00:29:38,529 --> 00:29:41,890
is

00:29:38,910 --> 00:29:45,610
Kong proxying - HTTP bean we can see how

00:29:41,890 --> 00:29:47,740
we have a few latency headers we have 11

00:29:45,610 --> 00:29:50,650
million seconds for Kong 9 for the

00:29:47,740 --> 00:29:52,059
upstream HTTP bin if we make requests

00:29:50,650 --> 00:29:55,390
with Kong

00:29:52,059 --> 00:29:57,850
eventually the Kong latency will go down

00:29:55,390 --> 00:30:01,090
to zero so this is the Kong in process

00:29:57,850 --> 00:30:03,130
caching mechanism that takes into into

00:30:01,090 --> 00:30:05,830
effect so Kong the first time needs to

00:30:03,130 --> 00:30:07,179
know from the data store what what API

00:30:05,830 --> 00:30:10,690
were trying to consume it will cache

00:30:07,179 --> 00:30:12,429
this in the memory of the of the process

00:30:10,690 --> 00:30:13,480
and then you won't have to go to the

00:30:12,429 --> 00:30:15,970
data store ever again

00:30:13,480 --> 00:30:18,550
ok great now we have an API in Kong

00:30:15,970 --> 00:30:21,280
simple reverse proxy let's start using

00:30:18,550 --> 00:30:25,330
some plugins to enhance what this API

00:30:21,280 --> 00:30:27,850
can do so like we can go on the plugins

00:30:25,330 --> 00:30:30,270
list for example and we can decide we

00:30:27,850 --> 00:30:34,150
want to protect this API with an API key

00:30:30,270 --> 00:30:37,480
so we apply this plugin by making a post

00:30:34,150 --> 00:30:39,370
request to the HTTP being API slash

00:30:37,480 --> 00:30:41,410
plugins and we tell the system we want

00:30:39,370 --> 00:30:42,820
to key out install and we want to

00:30:41,410 --> 00:30:45,970
configure this bug in a very specific

00:30:42,820 --> 00:30:48,790
way thanks thankfully for us we don't

00:30:45,970 --> 00:30:51,100
have any mandatory configuration

00:30:48,790 --> 00:30:53,020
parameter besides the name so that will

00:30:51,100 --> 00:30:55,320
be enough to protect this API so let's

00:30:53,020 --> 00:30:55,320
go ahead

00:31:15,760 --> 00:31:21,049
perfect now there is an API install a

00:31:18,799 --> 00:31:23,679
plugin installed on top of that API if I

00:31:21,049 --> 00:31:26,840
consume again the same way I did before

00:31:23,679 --> 00:31:31,299
this time Kong will complain there is no

00:31:26,840 --> 00:31:34,039
credential in the system in the request

00:31:31,299 --> 00:31:37,510
so let's provision a consumer and let's

00:31:34,039 --> 00:31:37,510
provision a credential for this consumer

00:31:43,690 --> 00:31:47,929
think of a consumer is anything that can

00:31:46,039 --> 00:31:49,549
consume the API so it can be a developer

00:31:47,929 --> 00:31:51,740
or can be another micro service or can

00:31:49,549 --> 00:32:05,840
be a mobile app so I'll create a

00:31:51,740 --> 00:32:07,880
developer called demo in this case and

00:32:05,840 --> 00:32:09,649
this demo user will have a key

00:32:07,880 --> 00:32:12,409
credential called secret one two three

00:32:09,649 --> 00:32:14,570
as you can see I'm effectively making

00:32:12,409 --> 00:32:17,179
requests to the admin API of Kong it's a

00:32:14,570 --> 00:32:19,250
regular HTTP request this also allows us

00:32:17,179 --> 00:32:21,140
to integrate Kong with our continuous

00:32:19,250 --> 00:32:22,820
integration systems with our existing

00:32:21,140 --> 00:32:24,950
applications or with scripts you can

00:32:22,820 --> 00:32:26,929
automate how Kong it's being configured

00:32:24,950 --> 00:32:28,850
in the entire cluster it's just a decent

00:32:26,929 --> 00:32:31,159
restful api so whatever can make a

00:32:28,850 --> 00:32:33,559
request to this API can also configure

00:32:31,159 --> 00:32:35,149
the system so now we have a consumer we

00:32:33,559 --> 00:32:37,070
have an API we have a plugin installed

00:32:35,149 --> 00:32:41,299
and we have a credential so we can

00:32:37,070 --> 00:32:43,130
consume our API by appending this API

00:32:41,299 --> 00:32:46,760
key that we have just created

00:32:43,130 --> 00:32:48,679
secret one two three if we do this Kong

00:32:46,760 --> 00:32:51,110
will validate the key it will validate

00:32:48,679 --> 00:32:53,240
the consumer we're trying to use and it

00:32:51,110 --> 00:32:55,789
will proxy the request to the upstream

00:32:53,240 --> 00:32:57,860
service if I use a different key that

00:32:55,789 --> 00:33:00,770
does not exist of course Kong will will

00:32:57,860 --> 00:33:02,570
block me again it doesn't matter if I

00:33:00,770 --> 00:33:04,460
had one Kong no there are hundred Kong

00:33:02,570 --> 00:33:06,740
nodes across five different data centers

00:33:04,460 --> 00:33:08,450
across five different clouds on top of

00:33:06,740 --> 00:33:10,070
measures for example all of these

00:33:08,450 --> 00:33:11,779
information would be propagated

00:33:10,070 --> 00:33:12,289
dynamically you don't have to worry

00:33:11,779 --> 00:33:14,539
about it

00:33:12,289 --> 00:33:17,510
so let's rate limit now how many

00:33:14,539 --> 00:33:18,919
requests this consumer can make and so

00:33:17,510 --> 00:33:21,710
for that we can go pick the

00:33:18,919 --> 00:33:24,929
rate-limiting plugin

00:33:21,710 --> 00:33:27,570
which is here in the rate-limiting

00:33:24,929 --> 00:33:29,820
plugin allows me to configure you know a

00:33:27,570 --> 00:33:32,159
few configuration options but

00:33:29,820 --> 00:33:33,899
effectively I can configure how many

00:33:32,159 --> 00:33:36,419
requests per second per minute per hour

00:33:33,899 --> 00:33:38,820
per day per month or per year I want to

00:33:36,419 --> 00:33:40,710
to use to rate limit to the users I can

00:33:38,820 --> 00:33:42,360
rate limit by IP address my consumer my

00:33:40,710 --> 00:33:44,820
credential so these it's a little bit

00:33:42,360 --> 00:33:47,399
more complicated but let's go ahead and

00:33:44,820 --> 00:33:49,669
rate limit by let's say five requests a

00:33:47,399 --> 00:33:49,669
minute

00:34:06,370 --> 00:34:10,760
I'm adding a new plugin

00:34:08,330 --> 00:34:14,450
this time it's rate limiting on top of

00:34:10,760 --> 00:34:16,970
the same API I consume with my key like

00:34:14,450 --> 00:34:18,770
the same thing I did before and this

00:34:16,970 --> 00:34:21,200
plugin will go into effect it will

00:34:18,770 --> 00:34:22,970
dynamically be fetched loaded and it

00:34:21,200 --> 00:34:25,220
will rate limit how many requests I can

00:34:22,970 --> 00:34:27,260
make it will also obtain some response

00:34:25,220 --> 00:34:29,330
headers telling me what's the number of

00:34:27,260 --> 00:34:30,710
total requests I can make and what's the

00:34:29,330 --> 00:34:34,340
number of remaining requests I can make

00:34:30,710 --> 00:34:36,590
and so if I make more than more requests

00:34:34,340 --> 00:34:38,929
we can see how the counter decreases and

00:34:36,590 --> 00:34:45,379
if I make more than five a minute the

00:34:38,929 --> 00:34:47,780
system will block my my requests now

00:34:45,379 --> 00:34:50,300
this is a very simple demo okay so I'm

00:34:47,780 --> 00:34:53,869
securing the API I'm rate-limiting the

00:34:50,300 --> 00:34:55,730
API this can be can get way more complex

00:34:53,869 --> 00:35:01,160
if you want to do so maybe we have

00:34:55,730 --> 00:35:02,869
consumers that only that should be able

00:35:01,160 --> 00:35:04,970
to make more requests or maybe we have

00:35:02,869 --> 00:35:06,980
internal clients that should be able to

00:35:04,970 --> 00:35:10,010
be blocked on specific your eyes we can

00:35:06,980 --> 00:35:11,869
stack together plugins as we wish to

00:35:10,010 --> 00:35:18,980
create these policies that will be then

00:35:11,869 --> 00:35:23,270
applied on the execution path I believe

00:35:18,980 --> 00:35:26,410
that we don't have much more time five

00:35:23,270 --> 00:35:26,410
minutes okay

00:35:29,280 --> 00:35:32,170
among the plugins that you can use with

00:35:31,660 --> 00:35:34,210
Kong

00:35:32,170 --> 00:35:38,920
besides authentication because besides

00:35:34,210 --> 00:35:41,230
security you can also apply you know

00:35:38,920 --> 00:35:44,170
request termination you can apply server

00:35:41,230 --> 00:35:47,010
less invocation so let's assume you want

00:35:44,170 --> 00:35:49,810
to be able to create a restful interface

00:35:47,010 --> 00:35:51,700
for your lambda function or IBM Open

00:35:49,810 --> 00:35:53,470
whisk function you can do that with this

00:35:51,700 --> 00:35:57,099
plugin and then you can stack together

00:35:53,470 --> 00:35:58,839
other plugin act secure rate limit how

00:35:57,099 --> 00:36:01,330
many requests these people can make you

00:35:58,839 --> 00:36:03,849
can then also plug this in with

00:36:01,330 --> 00:36:05,650
monitoring and analytics solution but if

00:36:03,849 --> 00:36:08,200
you have for example Splunk or the alex

00:36:05,650 --> 00:36:11,560
stack cabana elasticsearch you can use

00:36:08,200 --> 00:36:14,140
any of the logging plugins to push to

00:36:11,560 --> 00:36:16,089
these systems all the information about

00:36:14,140 --> 00:36:18,099
you know every request and the every

00:36:16,089 --> 00:36:20,080
response in order for you to keep track

00:36:18,099 --> 00:36:22,359
of what's going on across your micro

00:36:20,080 --> 00:36:24,760
service infrastructure we do also

00:36:22,359 --> 00:36:27,670
support dynamic load balancing and

00:36:24,760 --> 00:36:30,580
service discovery so if you use Kong you

00:36:27,670 --> 00:36:32,589
can actually tell Kong to be the dynamic

00:36:30,580 --> 00:36:35,349
load balancer for your upstream micro

00:36:32,589 --> 00:36:37,960
services the admin API gives you n

00:36:35,349 --> 00:36:41,380
points to add and remove target notes

00:36:37,960 --> 00:36:45,670
from a named upstream service that you

00:36:41,380 --> 00:36:48,640
can use on top of conch and and you know

00:36:45,670 --> 00:36:50,770
you can then also create your own

00:36:48,640 --> 00:36:53,050
plugins again and you can find plugins

00:36:50,770 --> 00:36:55,030
on the community as well so what we are

00:36:53,050 --> 00:36:56,500
so this is a static page what we're

00:36:55,030 --> 00:36:58,510
doing right now we're changing this to

00:36:56,500 --> 00:37:00,220
make it a searchable hub so you will be

00:36:58,510 --> 00:37:03,070
able to push your own plugins to the

00:37:00,220 --> 00:37:04,780
system and you will be able to fetch and

00:37:03,070 --> 00:37:07,650
search for other people's plugins to use

00:37:04,780 --> 00:37:07,650
on your system

00:37:22,400 --> 00:37:28,520
and this is it we do have a booth in the

00:37:27,110 --> 00:37:30,560
in the hallway so if you want to learn

00:37:28,520 --> 00:37:32,150
more if you want to see a live demo we

00:37:30,560 --> 00:37:34,280
can show you a demo there there are a

00:37:32,150 --> 00:37:37,030
few guys from Kong as well I really

00:37:34,280 --> 00:37:42,239
transfer your questions well thank you

00:37:37,030 --> 00:37:42,239
[Applause]

00:37:43,400 --> 00:37:46,599
[Music]

00:37:47,200 --> 00:37:51,890
can you put Kong in front of your user

00:37:49,550 --> 00:37:54,350
interfaces as well yes you can

00:37:51,890 --> 00:37:57,920
Kong it's an HTTP proxy that supports

00:37:54,350 --> 00:38:00,670
any HTTP or HTTPS ervice so you can use

00:37:57,920 --> 00:38:03,220
these also for your web applications

00:38:00,670 --> 00:38:06,650
[Music]

00:38:03,220 --> 00:38:09,380
what practical limitations are there to

00:38:06,650 --> 00:38:11,240
what you can do in a plugin like what do

00:38:09,380 --> 00:38:13,490
you recommend you don't do I could I go

00:38:11,240 --> 00:38:16,520
and host my entire web app as I plug in

00:38:13,490 --> 00:38:18,440
and Kong why shouldn't I do that what

00:38:16,520 --> 00:38:20,780
kind of guidance do you get people you

00:38:18,440 --> 00:38:22,820
you could as a matter of fact you could

00:38:20,780 --> 00:38:24,530
use Kong as your function as a service

00:38:22,820 --> 00:38:26,390
platform think of a plug-in it's

00:38:24,530 --> 00:38:28,550
something that can also terminate a

00:38:26,390 --> 00:38:30,050
request with a custom response so now if

00:38:28,550 --> 00:38:32,300
you think about it you can create

00:38:30,050 --> 00:38:34,280
functions instead of a plugins that can

00:38:32,300 --> 00:38:36,650
be invoked on top of an HTTP interface

00:38:34,280 --> 00:38:38,420
and run on top of Kong now the nice

00:38:36,650 --> 00:38:40,520
thing about it is that you're running on

00:38:38,420 --> 00:38:43,100
top of a very efficient architecture

00:38:40,520 --> 00:38:45,580
which is oak engine acts and Lua so you

00:38:43,100 --> 00:38:47,800
could effectively do that you can also

00:38:45,580 --> 00:38:49,940
synchronously or asynchronously

00:38:47,800 --> 00:38:52,460
communicate with third-party services

00:38:49,940 --> 00:38:55,340
instead of a plugin so you can receive a

00:38:52,460 --> 00:38:57,470
request by leveraging the asynchronous

00:38:55,340 --> 00:38:58,190
i/o of nginx you could make a request

00:38:57,470 --> 00:39:00,380
somewhere else

00:38:58,190 --> 00:39:03,200
you could aggregate multiple requests

00:39:00,380 --> 00:39:05,120
you can then return a custom response

00:39:03,200 --> 00:39:06,650
with whatever transformation you want to

00:39:05,120 --> 00:39:10,310
do in the meanwhile so you could pretty

00:39:06,650 --> 00:39:12,680
much do any you could also open new UDP

00:39:10,310 --> 00:39:16,090
or TCP ports in a plugin so we don't

00:39:12,680 --> 00:39:16,090
recommend that but you could do that

00:39:17,410 --> 00:39:22,160
so we we looked at configuring the admin

00:39:20,960 --> 00:39:23,510
API and that's how you configure a whole

00:39:22,160 --> 00:39:25,730
con cluster is there any sort of

00:39:23,510 --> 00:39:27,350
authentication mechanism or role based

00:39:25,730 --> 00:39:30,050
access control that you could find for

00:39:27,350 --> 00:39:32,420
Kong to protect the admin API yes so the

00:39:30,050 --> 00:39:34,130
admin API should be protected from

00:39:32,420 --> 00:39:36,020
external access because anybody who has

00:39:34,130 --> 00:39:36,320
access to that API will be able to mess

00:39:36,020 --> 00:39:39,710
with

00:39:36,320 --> 00:39:42,050
configuration we do have two different

00:39:39,710 --> 00:39:43,580
editions of Kong there is a community

00:39:42,050 --> 00:39:45,260
edition and then there is an enterprise

00:39:43,580 --> 00:39:46,820
edition so this is the community edition

00:39:45,260 --> 00:39:48,560
of Kong you can download it you can use

00:39:46,820 --> 00:39:50,090
it it's free to use there are no

00:39:48,560 --> 00:39:52,430
limitations and then there is an

00:39:50,090 --> 00:39:54,740
enterprise edition of Kong which extends

00:39:52,430 --> 00:39:57,920
Kong with some enterprise features among

00:39:54,740 --> 00:40:00,020
those features we also have role-based

00:39:57,920 --> 00:40:03,200
access control for the admin API so that

00:40:00,020 --> 00:40:07,580
you can control exactly what users what

00:40:03,200 --> 00:40:09,040
teams can access the admin interface so

00:40:07,580 --> 00:40:11,720
they don't mess with it

00:40:09,040 --> 00:40:14,360
you know the enterprise edition of Kong

00:40:11,720 --> 00:40:16,070
it's also a full cycle API management in

00:40:14,360 --> 00:40:17,900
micro service management solution so we

00:40:16,070 --> 00:40:20,270
also provide developer portals for your

00:40:17,900 --> 00:40:25,160
team for external consumption analytics

00:40:20,270 --> 00:40:26,540
and so on and so forth last question so

00:40:25,160 --> 00:40:28,550
how does come on integrate with

00:40:26,540 --> 00:40:31,250
something like marathon or is it just

00:40:28,550 --> 00:40:34,010
kind of up to you to to orchestrate both

00:40:31,250 --> 00:40:36,140
of them at the same time so-called it's

00:40:34,010 --> 00:40:38,570
being shipped with a official docker

00:40:36,140 --> 00:40:39,890
image right so it's a we provide a

00:40:38,570 --> 00:40:42,650
docker image you can use pretty much

00:40:39,890 --> 00:40:45,770
anywhere what we have done was to create

00:40:42,650 --> 00:40:47,510
a specific integration for the CE OS and

00:40:45,770 --> 00:40:50,210
you know you just use marathon to

00:40:47,510 --> 00:40:52,220
schedule your your con cluster like you

00:40:50,210 --> 00:40:55,370
would do for any other docker container

00:40:52,220 --> 00:40:57,950
effectively the the system itself can

00:40:55,370 --> 00:41:00,350
run anywhere so it's very simple it's

00:40:57,950 --> 00:41:02,690
stateless you can spin up as many kong

00:41:00,350 --> 00:41:06,530
nodes or you know instance replicas of

00:41:02,690 --> 00:41:09,440
your conch containers on top of of mezes

00:41:06,530 --> 00:41:12,850
just by using marathon or by using you

00:41:09,440 --> 00:41:12,850
know this cos it's it's straightforward

00:41:26,850 --> 00:41:33,660
a conch can integrate with that so

00:41:31,470 --> 00:41:38,060
Konkan out to discover your upstream

00:41:33,660 --> 00:41:38,060
services so we do have support for that

00:41:40,940 --> 00:41:46,320
thank you

00:41:43,120 --> 00:41:46,320

YouTube URL: https://www.youtube.com/watch?v=OUUiS28hZuw


