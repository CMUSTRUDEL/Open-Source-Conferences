Title: Streaming Data Pipelines on Apache Mesos: Lessons Learned
Publication date: 2017-09-18
Playlist: MesosCon North America 2017
Description: 
	Streaming Data Pipelines on Apache Mesos: Lessons Learned - Dean Wampler, Ph.D., Lightbend

Lightbend Fast Data Platform (http://lightbend.com/fast-data-platform) is a suite of open-source streaming tools, including Kafka, Spark, Flink, Akka Streams, and Kafka Streams, running on Mesosphere DC/OS. Lightbend picked Mesos for its flexibility to support the diverse requirements of streaming and batch data processing, as well as other microservices typically required in production environments.

Dean will begin by describing the features of Mesos that were important for Lightbend's needs. He will illustrate the details of those features using examples from how the tools mentioned above work with Mesos, both for long-running daemons and per-job processes. Dean will share lessons learned running applications built with these tools on Mesos and he will conclude with thoughts about future developments and improvements.

About 

Dean Wampler
Lightbend
Big Data Architect
Dean Wampler, Ph.D. (@deanwampler), is Vice President of Fast Data Engineering at Lightbend. He leads the development of Lightbend Fast Data Platform, a streaming data and microservices platform built on Lightbend Reactive Platform, Spark, Flink, Kafka, Mesosophere DC/OS, and other tools. He is the author of several books and reports for O'Reilly: "Fast Data Architectures for Streaming Applications", "Programming Scala, Second Edition", "Functional Programming for Java Developers", and the coauthor of "Programming Hive". Dean is a contributor to several open-source projects, a frequent conference speaker, and the co-organizer of several industry conferences and Chicago-based user groups.
Captions: 
	00:00:00,420 --> 00:00:04,410
well welcome everyone I know it's almost

00:00:02,550 --> 00:00:06,509
some beer o'clock on a Friday so I'm

00:00:04,410 --> 00:00:07,740
grateful that you showed up welcome to

00:00:06,509 --> 00:00:09,510
the North Pole I put a little

00:00:07,740 --> 00:00:12,120
thermometer on the board here to remind

00:00:09,510 --> 00:00:14,070
you how cold it is but at least you

00:00:12,120 --> 00:00:17,730
won't fall asleep I guess or or maybe

00:00:14,070 --> 00:00:19,590
it'll be hypothermia anyway so I my name

00:00:17,730 --> 00:00:22,080
is Dean Wampler I have this pretentious

00:00:19,590 --> 00:00:24,900
made-up title it like Bend VP of fast

00:00:22,080 --> 00:00:27,000
data engineering basically I lead the

00:00:24,900 --> 00:00:29,160
development team that's building a

00:00:27,000 --> 00:00:33,750
distribution of streaming technologies

00:00:29,160 --> 00:00:35,579
on top of DCOs you know spark Kafka Mesa

00:00:33,750 --> 00:00:38,969
well Mesa sits underneath obviously

00:00:35,579 --> 00:00:40,500
flank eventually aqua streams so forth

00:00:38,969 --> 00:00:42,780
I'll talk a little bit about the pieces

00:00:40,500 --> 00:00:44,160
in this you know I I know this you don't

00:00:42,780 --> 00:00:45,930
want a marketing talk and that's when

00:00:44,160 --> 00:00:48,989
not this is that's not what this is

00:00:45,930 --> 00:00:51,000
about but I did want to you know having

00:00:48,989 --> 00:00:53,160
played with these frameworks for a while

00:00:51,000 --> 00:00:55,199
in mezzos and actually made the choice

00:00:53,160 --> 00:00:57,420
that maze those over alternatives that's

00:00:55,199 --> 00:00:59,969
really what this talks about and what

00:00:57,420 --> 00:01:01,320
we've learned from that I've alright by

00:00:59,969 --> 00:01:02,850
the way if you look for the slides on

00:01:01,320 --> 00:01:04,320
the website I forgot to check if you

00:01:02,850 --> 00:01:06,240
could even get them yet but I uploaded

00:01:04,320 --> 00:01:07,979
them like an hour ago so that they are

00:01:06,240 --> 00:01:10,799
up there if you if you want to get the

00:01:07,979 --> 00:01:12,090
slides and there's some general themes I

00:01:10,799 --> 00:01:15,200
want to hit on I'm not going to do this

00:01:12,090 --> 00:01:16,979
in order but just some takeaways is

00:01:15,200 --> 00:01:18,540
first talk a little bit about how

00:01:16,979 --> 00:01:21,240
applications and application

00:01:18,540 --> 00:01:23,040
architectures are changing you know what

00:01:21,240 --> 00:01:25,200
why are they different today versus say

00:01:23,040 --> 00:01:26,880
five years ago or pick some time frame

00:01:25,200 --> 00:01:28,950
and how that's influenced everything

00:01:26,880 --> 00:01:31,229
else that I'm going to talk about you

00:01:28,950 --> 00:01:33,540
know why we picked meso sand some of the

00:01:31,229 --> 00:01:35,520
particular things about it that had

00:01:33,540 --> 00:01:37,500
proven really valuable for our needs and

00:01:35,520 --> 00:01:40,700
obviously for our customer needs and

00:01:37,500 --> 00:01:43,170
then talk about a few specific insights

00:01:40,700 --> 00:01:45,659
it won't be a highly technical talk by

00:01:43,170 --> 00:01:48,149
any means but hopefully you'll get some

00:01:45,659 --> 00:01:49,560
useful stuff out of it all right so

00:01:48,149 --> 00:01:51,720
first why do we care well I'm leading

00:01:49,560 --> 00:01:53,579
the team that's developing this product

00:01:51,720 --> 00:01:55,890
we're calling the fast data platform

00:01:53,579 --> 00:01:59,399
that's in beta now and will come out

00:01:55,890 --> 00:02:01,110
this fall just two slides about it so

00:01:59,399 --> 00:02:04,590
this is sort of a block diagram of the

00:02:01,110 --> 00:02:05,909
pieces well I don't know how useful this

00:02:04,590 --> 00:02:07,680
actually is let me just show you the

00:02:05,909 --> 00:02:10,050
interesting bits which is what's under

00:02:07,680 --> 00:02:13,319
the little blocks mostly we're going to

00:02:10,050 --> 00:02:15,060
talk about this sort of middle right

00:02:13,319 --> 00:02:17,129
which is the streaming engines and then

00:02:15,060 --> 00:02:21,269
also Kafka and kind of what we've

00:02:17,129 --> 00:02:23,849
learned from using those but also you

00:02:21,269 --> 00:02:25,890
know I'll get into a little bit how it

00:02:23,849 --> 00:02:27,829
turns out we're seeing a lot of need to

00:02:25,890 --> 00:02:30,420
build Micra services that integrate

00:02:27,829 --> 00:02:32,370
integrate with these other tools much

00:02:30,420 --> 00:02:34,500
more so than maybe in a classic dupe

00:02:32,370 --> 00:02:35,790
environment and then there's other

00:02:34,500 --> 00:02:38,129
pieces you need like management

00:02:35,790 --> 00:02:40,349
monitoring tools machine learning and

00:02:38,129 --> 00:02:42,480
all that and deployed on DCOs

00:02:40,349 --> 00:02:46,409
for you know having a commercially

00:02:42,480 --> 00:02:47,790
supported mezzos distribution the bottom

00:02:46,409 --> 00:02:50,159
actually that's sort of a little small

00:02:47,790 --> 00:02:51,930
to read is bringer on storage although

00:02:50,159 --> 00:02:54,930
we are actually supporting HDFS

00:02:51,930 --> 00:02:57,959
ourselves in this case ok so enough

00:02:54,930 --> 00:03:01,859
market texture well the first question

00:02:57,959 --> 00:03:03,359
that we came up with say three years ago

00:03:01,859 --> 00:03:05,609
when we really started thinking about

00:03:03,359 --> 00:03:07,919
what we should do in big data was well

00:03:05,609 --> 00:03:10,200
should we use Hadoop so let me step back

00:03:07,919 --> 00:03:13,829
a second and just to provide a little

00:03:10,200 --> 00:03:16,560
context so I've been working in like the

00:03:13,829 --> 00:03:19,979
spark rather the scala community for a

00:03:16,560 --> 00:03:22,199
long time and actually knew everybody at

00:03:19,979 --> 00:03:23,549
light band called typesafe at the time

00:03:22,199 --> 00:03:25,199
when they got started but I wasn't

00:03:23,549 --> 00:03:26,940
actually that interested in working on

00:03:25,199 --> 00:03:29,489
micro services which has been kind of

00:03:26,940 --> 00:03:30,959
the focus light band is the it was

00:03:29,489 --> 00:03:32,400
founded by the creator of the Scala

00:03:30,959 --> 00:03:34,620
programming language and the guy who

00:03:32,400 --> 00:03:37,370
created akka you probably heard about

00:03:34,620 --> 00:03:39,389
akka because it's the a and smack

00:03:37,370 --> 00:03:40,919
actually there was a really good talk I

00:03:39,389 --> 00:03:44,099
just went to by a couple of guys from

00:03:40,919 --> 00:03:46,319
Adobe who've been using open wisk which

00:03:44,099 --> 00:03:48,209
is the serverless framework that is

00:03:46,319 --> 00:03:49,319
written in akka so you probably if you

00:03:48,209 --> 00:03:51,209
had never seen it before

00:03:49,319 --> 00:03:53,519
you got a little taste of what akka is

00:03:51,209 --> 00:03:56,340
about there and I'll briefly talk a

00:03:53,519 --> 00:03:59,129
little bit about it as we go along but

00:03:56,340 --> 00:04:00,900
anyway so you know three or so years ago

00:03:59,129 --> 00:04:02,459
it turned out Scala was starting to get

00:04:00,900 --> 00:04:04,799
very interesting in the big data world

00:04:02,459 --> 00:04:07,290
because spark and Kafka written in Scala

00:04:04,799 --> 00:04:09,120
so people started talking to light Bend

00:04:07,290 --> 00:04:11,099
about it because they were it was kind

00:04:09,120 --> 00:04:12,629
of driving them to you Scala and then I

00:04:11,099 --> 00:04:14,400
got involved with light been to think

00:04:12,629 --> 00:04:16,079
about well how do we actually take what

00:04:14,400 --> 00:04:18,449
we've learned about micro service

00:04:16,079 --> 00:04:21,269
development and Scala programming and

00:04:18,449 --> 00:04:24,419
functional programming and apply that to

00:04:21,269 --> 00:04:26,550
the big data world if you know anything

00:04:24,419 --> 00:04:27,050
about me I have a lot of talks out there

00:04:26,550 --> 00:04:28,879
on

00:04:27,050 --> 00:04:30,379
YouTube and Twitter and I have a few

00:04:28,879 --> 00:04:32,300
where I rant and rave about how the

00:04:30,379 --> 00:04:33,860
Hadoop world is screwed up because it's

00:04:32,300 --> 00:04:37,159
not functional you know we don't we were

00:04:33,860 --> 00:04:39,169
using crappy languages and all this many

00:04:37,159 --> 00:04:40,940
way not to get into too much about that

00:04:39,169 --> 00:04:42,889
so fast-forward a little bit and you

00:04:40,940 --> 00:04:44,810
know a couple of years ago when we sort

00:04:42,889 --> 00:04:46,550
of crystallized this idea of well you

00:04:44,810 --> 00:04:48,169
know the world is kind of moving towards

00:04:46,550 --> 00:04:50,360
more stream oriented versus batch

00:04:48,169 --> 00:04:52,759
oriented not that batch is going away

00:04:50,360 --> 00:04:54,289
but people need answers faster you know

00:04:52,759 --> 00:04:57,020
it's the usual thing that time is money

00:04:54,289 --> 00:04:59,090
if I can extract value more quickly from

00:04:57,020 --> 00:05:00,770
data then that's better so that's been

00:04:59,090 --> 00:05:03,050
kind of one of the driving forces behind

00:05:00,770 --> 00:05:05,270
streaming apps the other one is just the

00:05:03,050 --> 00:05:06,560
pragmatics of how do I serve mobile how

00:05:05,270 --> 00:05:08,240
do I serve you know like map

00:05:06,560 --> 00:05:10,699
applications and all that stuff you

00:05:08,240 --> 00:05:12,229
can't do that in batch right well at

00:05:10,699 --> 00:05:14,479
least not completely you might do some

00:05:12,229 --> 00:05:17,900
data processing offline to have the data

00:05:14,479 --> 00:05:19,520
ready for your real-time serving but as

00:05:17,900 --> 00:05:21,800
we started thinking about how to support

00:05:19,520 --> 00:05:23,569
customers doing string processing at

00:05:21,800 --> 00:05:26,330
scale it became clear that Hadoop just

00:05:23,569 --> 00:05:28,879
isn't it wasn't really cut out for it

00:05:26,330 --> 00:05:31,460
this is sort of my schematic diagram of

00:05:28,879 --> 00:05:33,219
a dupe cluster really there's only three

00:05:31,460 --> 00:05:35,240
important pieces here and that is

00:05:33,219 --> 00:05:37,610
there's a you know some sort of

00:05:35,240 --> 00:05:39,830
distributed storage which is HDFS the

00:05:37,610 --> 00:05:41,900
Hadoop file system you know there's some

00:05:39,830 --> 00:05:44,240
sort of compute which used to be

00:05:41,900 --> 00:05:45,919
MapReduce and now it's mostly SPARC and

00:05:44,240 --> 00:05:48,020
then there's this thing called yarn

00:05:45,919 --> 00:05:49,909
which is yet another resource negotiator

00:05:48,020 --> 00:05:51,500
that's that's sort of the analog of maze

00:05:49,909 --> 00:05:53,870
those from you know roughly speaking

00:05:51,500 --> 00:05:55,430
that knows what to do when you say I

00:05:53,870 --> 00:05:56,900
want to run this job and the date is

00:05:55,430 --> 00:05:59,900
over here and it figures that how to

00:05:56,900 --> 00:06:02,389
partition that into tasks which you know

00:05:59,900 --> 00:06:05,060
are basically processes JVM processes

00:06:02,389 --> 00:06:08,029
and run them over the cluster over or

00:06:05,060 --> 00:06:09,860
over all this data and then there's a

00:06:08,029 --> 00:06:11,870
bunch of support stuff that people put

00:06:09,860 --> 00:06:13,310
in and if you buy a hadoop distribution

00:06:11,870 --> 00:06:16,479
today you can get some streaming

00:06:13,310 --> 00:06:19,099
technologies like storm and spark and

00:06:16,479 --> 00:06:22,190
sorry I actually am it's a Kafka storm

00:06:19,099 --> 00:06:25,219
and Kafka spark streaming and so forth

00:06:22,190 --> 00:06:26,629
but I want to make the case that that's

00:06:25,219 --> 00:06:28,129
not really good enough for what we need

00:06:26,629 --> 00:06:30,020
today and that's one of the reasons

00:06:28,129 --> 00:06:32,810
maize those is much better position for

00:06:30,020 --> 00:06:36,199
this so but what's not to like well

00:06:32,810 --> 00:06:38,899
three things limitations in yarn the

00:06:36,199 --> 00:06:39,930
sort of batch orientation and this idea

00:06:38,899 --> 00:06:41,580
of well what if

00:06:39,930 --> 00:06:43,229
need to write other services and I'm

00:06:41,580 --> 00:06:44,729
just going to use micro services that

00:06:43,229 --> 00:06:46,590
buzzword to talk about the other

00:06:44,729 --> 00:06:50,100
services I might need to write in my

00:06:46,590 --> 00:06:52,229
environment oh so let's talk about yarn

00:06:50,100 --> 00:06:54,690
first and I have to be you know to be

00:06:52,229 --> 00:06:56,490
honest to the Hadoop community a lot of

00:06:54,690 --> 00:06:58,560
these issues they're trying to fix to

00:06:56,490 --> 00:07:00,630
some level but you know it's it's it's

00:06:58,560 --> 00:07:03,900
relatively old software so it can be

00:07:00,630 --> 00:07:05,639
difficult to bring it up to you know

00:07:03,900 --> 00:07:09,240
what's what's we have today in maize

00:07:05,639 --> 00:07:10,710
those well yarn yet another resource ago

00:07:09,240 --> 00:07:12,750
she ate it was always designed with this

00:07:10,710 --> 00:07:14,580
idea that you're gonna submit a job to

00:07:12,750 --> 00:07:17,250
me and I'm going to partition it based

00:07:14,580 --> 00:07:18,900
on what resources are available in two

00:07:17,250 --> 00:07:20,720
tasks and I'm gonna run them and they're

00:07:18,900 --> 00:07:23,610
going to have some finite duration

00:07:20,720 --> 00:07:25,770
because I'm assuming it's a batch job

00:07:23,610 --> 00:07:27,479
that means I kind of know in advance how

00:07:25,770 --> 00:07:29,039
much data I'm gonna actually be working

00:07:27,479 --> 00:07:31,710
with so I kind of know roughly how many

00:07:29,039 --> 00:07:33,660
tasks to schedule why is that important

00:07:31,710 --> 00:07:35,669
well because in a streaming world I

00:07:33,660 --> 00:07:37,770
don't know how much data I'm going to be

00:07:35,669 --> 00:07:40,410
processed and you know superbowls happen

00:07:37,770 --> 00:07:41,910
but justin bieber tweets you know these

00:07:40,410 --> 00:07:44,460
kind of things happen and suddenly you

00:07:41,910 --> 00:07:46,169
get these big spikes in traffic you get

00:07:44,460 --> 00:07:47,970
network partitions if your run along

00:07:46,169 --> 00:07:50,490
enough and so forth so it's not terribly

00:07:47,970 --> 00:07:52,680
good if all I understand is batch jobs

00:07:50,490 --> 00:07:55,530
in fact it's so limited it can't even

00:07:52,680 --> 00:07:59,760
run the the demons for HDFS like the

00:07:55,530 --> 00:08:00,990
name note and data nodes so in fact this

00:07:59,760 --> 00:08:03,030
is kind of a theme if you're running

00:08:00,990 --> 00:08:06,479
Kafka if you're running storm if you're

00:08:03,030 --> 00:08:08,669
running HDFS you're not really going to

00:08:06,479 --> 00:08:10,919
be using the sort of Hadoop resource

00:08:08,669 --> 00:08:14,310
management when did that happen

00:08:10,919 --> 00:08:16,229
there it goes you're going to be kind of

00:08:14,310 --> 00:08:18,360
hardwiring these things a little bit on

00:08:16,229 --> 00:08:20,430
your own and then only getting the

00:08:18,360 --> 00:08:23,400
resource negotiation that we're used to

00:08:20,430 --> 00:08:28,139
that we really love about maze O's just

00:08:23,400 --> 00:08:29,280
when you run your data analysis jobs the

00:08:28,139 --> 00:08:33,060
other thing it's really bad these days

00:08:29,280 --> 00:08:34,950
is they do now support containers there

00:08:33,060 --> 00:08:36,899
is like effect I googled this right

00:08:34,950 --> 00:08:39,209
before to make sure that I wasn't lying

00:08:36,899 --> 00:08:40,829
about this there is actually additions

00:08:39,209 --> 00:08:43,890
for container support but it's way

00:08:40,829 --> 00:08:46,350
behind what we're used to like the open

00:08:43,890 --> 00:08:48,660
container initiative and C&I and those

00:08:46,350 --> 00:08:50,550
kind of things and once again because of

00:08:48,660 --> 00:08:52,730
that batch orientation it's kind of

00:08:50,550 --> 00:08:54,980
ideal for like big fat

00:08:52,730 --> 00:08:57,769
JVMs that are reading big chunks of

00:08:54,980 --> 00:09:01,160
filesystems but not so great if i made

00:08:57,769 --> 00:09:06,649
relatively you know small jobs for some

00:09:01,160 --> 00:09:08,600
things big jobs for others and so that

00:09:06,649 --> 00:09:10,130
means that if we don't want to do batch

00:09:08,600 --> 00:09:11,480
if you want to do streaming it's a

00:09:10,130 --> 00:09:13,339
little bit more like we're going to kind

00:09:11,480 --> 00:09:15,050
of roller on services we're going to

00:09:13,339 --> 00:09:18,860
kind of work around the limitations of

00:09:15,050 --> 00:09:23,500
of yarn and do things our own way like

00:09:18,860 --> 00:09:23,500
running Kafka Cassandra and so forth now

00:09:24,160 --> 00:09:28,459
one of the things I want to argue as we

00:09:26,269 --> 00:09:31,070
go along is that increasingly what we

00:09:28,459 --> 00:09:33,019
see customers doing is they're not only

00:09:31,070 --> 00:09:35,389
building like you know spark streaming

00:09:33,019 --> 00:09:36,769
jobs and they're running HDFS but

00:09:35,389 --> 00:09:38,720
they're also writing a lot of micro

00:09:36,769 --> 00:09:41,329
services that interoperate with these

00:09:38,720 --> 00:09:43,370
things I'll give you an example just

00:09:41,329 --> 00:09:45,139
from a lunchtime conversation I had

00:09:43,370 --> 00:09:47,600
where I might work for a healthcare

00:09:45,139 --> 00:09:49,970
company and even though I'm writing

00:09:47,600 --> 00:09:52,310
maybe classic data warehousing jobs with

00:09:49,970 --> 00:09:54,649
spark I'm also writing like micro

00:09:52,310 --> 00:09:57,110
services that embed the rules for like

00:09:54,649 --> 00:10:00,889
regulatory enforcement of you know data

00:09:57,110 --> 00:10:02,360
privacy and I don't know all the terms

00:10:00,889 --> 00:10:04,069
that they use for this stuff but

00:10:02,360 --> 00:10:05,630
basically you know anything I might need

00:10:04,069 --> 00:10:07,760
to know about you know healthcare

00:10:05,630 --> 00:10:09,709
billing and record management and all

00:10:07,760 --> 00:10:11,990
that and I really want those services to

00:10:09,709 --> 00:10:13,519
be accessible from my streaming job so

00:10:11,990 --> 00:10:16,220
that as you know data is coming through

00:10:13,519 --> 00:10:17,860
I can properly manage it with these

00:10:16,220 --> 00:10:22,399
requirements and sorry about the

00:10:17,860 --> 00:10:24,860
flickering display here so this kind of

00:10:22,399 --> 00:10:26,959
work mixed workload it's not so great

00:10:24,860 --> 00:10:28,880
when in Hadoop either it really Hadoop

00:10:26,959 --> 00:10:30,980
is kind of focused on I'm gonna do blots

00:10:28,880 --> 00:10:32,660
of batch jobs and if I want to mix in

00:10:30,980 --> 00:10:35,420
micro services you kind of have to sneak

00:10:32,660 --> 00:10:38,480
them in on the side or or partition your

00:10:35,420 --> 00:10:39,980
cluster in some way in fact if they even

00:10:38,480 --> 00:10:41,930
say if you're gonna run Kafka you want

00:10:39,980 --> 00:10:43,790
dedicated nodes for Kafka you don't want

00:10:41,930 --> 00:10:47,630
them mixed up with your and the rest of

00:10:43,790 --> 00:10:49,699
Hindu right okay so that brings us to

00:10:47,630 --> 00:10:51,410
why we picked mazes and I know some of

00:10:49,699 --> 00:10:53,329
this is preaching to the choir so I

00:10:51,410 --> 00:10:55,399
don't I won't belabor these points but

00:10:53,329 --> 00:10:56,480
just to sort of catalog him well I was

00:10:55,399 --> 00:10:57,980
thinking about what do I like about

00:10:56,480 --> 00:10:59,510
mazes and I thought you know I'm going

00:10:57,980 --> 00:11:01,670
to Google I'm just gonna go to the

00:10:59,510 --> 00:11:03,140
homepage for maze those for inspiration

00:11:01,670 --> 00:11:05,540
and I liked what I saw so much I just

00:11:03,140 --> 00:11:07,820
figured I'd do a screen capture

00:11:05,540 --> 00:11:09,079
so this is just mazes at Apache org I'm

00:11:07,820 --> 00:11:11,029
only going to talk about three of these

00:11:09,079 --> 00:11:13,459
I you know I want to go through all of

00:11:11,029 --> 00:11:14,930
them but three that I think really are

00:11:13,459 --> 00:11:17,300
important for the problems that we're

00:11:14,930 --> 00:11:20,240
facing in streaming and mixed

00:11:17,300 --> 00:11:23,149
micro-service architectures is container

00:11:20,240 --> 00:11:25,160
support and all of the benefits we get

00:11:23,149 --> 00:11:27,800
from that for isolation for running

00:11:25,160 --> 00:11:30,829
concurrent versions you know people who

00:11:27,800 --> 00:11:32,660
like deploy a container and then you

00:11:30,829 --> 00:11:34,819
know it like runs for a few seconds and

00:11:32,660 --> 00:11:37,399
it goes away or they're deploying a

00:11:34,819 --> 00:11:41,449
service it's going to run for months and

00:11:37,399 --> 00:11:43,959
all of that just kind of works sort of

00:11:41,449 --> 00:11:46,100
at a lower level is really actually

00:11:43,959 --> 00:11:48,709
fine-grained management of my cluster

00:11:46,100 --> 00:11:52,610
resources so that when I really do need

00:11:48,709 --> 00:11:54,620
to optimize usage of CPU GPU etc I get

00:11:52,610 --> 00:11:57,410
to do that you know just for free it

00:11:54,620 --> 00:12:00,110
just comes with my ecosystem and you

00:11:57,410 --> 00:12:02,810
know this list of resources that you can

00:12:00,110 --> 00:12:04,940
manage this is more than yarn is capable

00:12:02,810 --> 00:12:07,250
of today for example like it's they

00:12:04,940 --> 00:12:10,190
still haven't gotten GPU resource

00:12:07,250 --> 00:12:12,620
management done I had a chat recently

00:12:10,190 --> 00:12:14,389
with a guy from sky mine the company

00:12:12,620 --> 00:12:16,430
that does deep learning for Jay and you

00:12:14,389 --> 00:12:18,589
know there's machine learning guys

00:12:16,430 --> 00:12:21,230
especially in the AI world are all about

00:12:18,589 --> 00:12:25,510
you know GPUs now so if you can't manage

00:12:21,230 --> 00:12:28,310
your GPU GPU resources it's a bad deal

00:12:25,510 --> 00:12:31,550
oh and this reminds me of something I

00:12:28,310 --> 00:12:33,620
can never always find this amazing when

00:12:31,550 --> 00:12:34,730
I think back to the to the 90s so I've

00:12:33,620 --> 00:12:36,440
been around a little while as you can

00:12:34,730 --> 00:12:38,420
tell from my platinum blonde hair style

00:12:36,440 --> 00:12:40,490
but back in the 90s you know we would

00:12:38,420 --> 00:12:42,110
stand up servers and it was a bad deal

00:12:40,490 --> 00:12:44,060
if the server got more than like 30

00:12:42,110 --> 00:12:45,920
percent utilized you'd start worrying

00:12:44,060 --> 00:12:48,709
right like because that was all your

00:12:45,920 --> 00:12:51,110
capacity was and these are like massive

00:12:48,709 --> 00:12:52,760
Sun boxes - so we only had a few of them

00:12:51,110 --> 00:12:54,860
but these days we want to get much

00:12:52,760 --> 00:12:58,010
closer to a hundred percent without you

00:12:54,860 --> 00:13:01,610
know falling over for all the reasons of

00:12:58,010 --> 00:13:03,860
you know economy and the last one is our

00:13:01,610 --> 00:13:06,019
the famous two-level scheduling in Mesa

00:13:03,860 --> 00:13:07,699
I'd love the simplicity of the Mesa

00:13:06,019 --> 00:13:09,439
scheduler model that they've actually

00:13:07,699 --> 00:13:12,350
partitioned the notion of what

00:13:09,439 --> 00:13:15,709
scheduling means in sort of this tandem

00:13:12,350 --> 00:13:17,959
dance between the framework itself well

00:13:15,709 --> 00:13:19,270
I used the wrong word between mezzos

00:13:17,959 --> 00:13:21,490
itself and your app

00:13:19,270 --> 00:13:23,770
occasion which is a framework meaning

00:13:21,490 --> 00:13:25,450
that mais au s-- does not have to know

00:13:23,770 --> 00:13:28,720
everything there is to know about how to

00:13:25,450 --> 00:13:30,940
schedule a spark job instead it you know

00:13:28,720 --> 00:13:33,400
it offers resources to spark and then

00:13:30,940 --> 00:13:36,010
spark has the knowledge inside to know

00:13:33,400 --> 00:13:38,440
what resources it needs to take to do

00:13:36,010 --> 00:13:40,750
whatever it is it wants to do so if I

00:13:38,440 --> 00:13:43,090
want to add my own custom database or

00:13:40,750 --> 00:13:45,100
whatever then I can write the scheduler

00:13:43,090 --> 00:13:48,340
that knows how to how to accept resource

00:13:45,100 --> 00:13:49,960
offers and mais those remains relatively

00:13:48,340 --> 00:13:52,270
ignorant about what it is I'm going to

00:13:49,960 --> 00:13:53,800
do with those resources that's the

00:13:52,270 --> 00:13:55,870
opposite of the way yarn works where

00:13:53,800 --> 00:13:57,970
they've actually hard-coded information

00:13:55,870 --> 00:14:01,630
in in yarn about you know what it means

00:13:57,970 --> 00:14:03,070
to be a spark job or whatever and you

00:14:01,630 --> 00:14:04,900
know that has some advantages but the

00:14:03,070 --> 00:14:05,830
disadvantage is that spark doesn't know

00:14:04,900 --> 00:14:07,060
sorry

00:14:05,830 --> 00:14:09,070
you know Hadoop doesn't have the

00:14:07,060 --> 00:14:13,510
flexibility to run other weird things

00:14:09,070 --> 00:14:15,580
like file systems and databases so it's

00:14:13,510 --> 00:14:17,650
those things that lets us do crazy stuff

00:14:15,580 --> 00:14:19,630
like add these new frameworks and then

00:14:17,650 --> 00:14:21,550
have them work in a fairly optimal way

00:14:19,630 --> 00:14:23,590
so that this is just a diagram of how

00:14:21,550 --> 00:14:26,110
spark actually works when you submit

00:14:23,590 --> 00:14:28,810
your job the scheduler talks to the meso

00:14:26,110 --> 00:14:30,640
smashed ER and you know this dance goes

00:14:28,810 --> 00:14:33,010
on about allocating resources on

00:14:30,640 --> 00:14:36,330
different nodes under the aegis of a

00:14:33,010 --> 00:14:39,820
mais au s-- executor and inside is a

00:14:36,330 --> 00:14:41,380
spark executor I just said pronounce

00:14:39,820 --> 00:14:44,500
that word differently for no good reason

00:14:41,380 --> 00:14:46,690
and inside that will be the tasks that

00:14:44,500 --> 00:14:47,860
actually you know run your job so here's

00:14:46,690 --> 00:14:50,080
a little story I don't know if everybody

00:14:47,860 --> 00:14:52,270
knows this but maybe you do if you read

00:14:50,080 --> 00:14:54,670
the original meso research paper that

00:14:52,270 --> 00:14:56,470
ben wrote there's this hilarious

00:14:54,670 --> 00:14:58,750
paragraph in there where he says in

00:14:56,470 --> 00:15:00,310
order to prove our ideas about two-level

00:14:58,750 --> 00:15:03,160
scheduling we invented this little

00:15:00,310 --> 00:15:04,540
framework called spark now it's actually

00:15:03,160 --> 00:15:06,520
tested so yeah I figured most of you

00:15:04,540 --> 00:15:11,320
have heard that story before but

00:15:06,520 --> 00:15:13,450
obviously spark took off on its own all

00:15:11,320 --> 00:15:15,010
right let's dive into streaming a little

00:15:13,450 --> 00:15:16,540
bit more specifically then so what are

00:15:15,010 --> 00:15:18,340
some of the characteristics at a high

00:15:16,540 --> 00:15:21,220
level that streaming systems have to

00:15:18,340 --> 00:15:22,570
support one is well I'm going to go into

00:15:21,220 --> 00:15:25,090
these in detail but continuous

00:15:22,570 --> 00:15:26,920
processing variable lifespans of these

00:15:25,090 --> 00:15:30,370
streaming jobs resiliency and

00:15:26,920 --> 00:15:32,440
scalability so what's the deal here well

00:15:30,370 --> 00:15:32,990
continuous processing in a stream you

00:15:32,440 --> 00:15:34,880
know the the

00:15:32,990 --> 00:15:36,920
hopefully the input is never going to

00:15:34,880 --> 00:15:38,060
stop coming and if it does stop coming

00:15:36,920 --> 00:15:40,100
it probably means you went out of

00:15:38,060 --> 00:15:41,839
business or something and certainly

00:15:40,100 --> 00:15:43,970
you're gonna have to keep feeding output

00:15:41,839 --> 00:15:46,760
to a downstream consumers storage

00:15:43,970 --> 00:15:48,920
whatever and one of the implications of

00:15:46,760 --> 00:15:51,260
that is that you need your framework to

00:15:48,920 --> 00:15:53,839
really scale dynamically on demand like

00:15:51,260 --> 00:15:56,480
for those Super Bowl events or Justin

00:15:53,839 --> 00:15:57,890
Bieber tweets or whatever I'm going to

00:15:56,480 --> 00:15:58,820
come back to this one in a little bit in

00:15:57,890 --> 00:16:00,290
just a minute

00:15:58,820 --> 00:16:01,820
the other one though that I think it's

00:16:00,290 --> 00:16:04,760
kind of a cool thing in terms of

00:16:01,820 --> 00:16:06,529
optimization or tools like The Container

00:16:04,760 --> 00:16:09,470
network interface it lay you fine-tune

00:16:06,529 --> 00:16:11,720
how that your your container networking

00:16:09,470 --> 00:16:14,089
work so that you can optimize transport

00:16:11,720 --> 00:16:16,940
between various components so you really

00:16:14,089 --> 00:16:18,830
could fine-tune you know if you've got

00:16:16,940 --> 00:16:20,600
this high bandwidth stream coming and

00:16:18,830 --> 00:16:22,820
you could actually you know fine-tune

00:16:20,600 --> 00:16:25,160
how that is configured in the cluster

00:16:22,820 --> 00:16:27,290
and maybe take resources away from other

00:16:25,160 --> 00:16:29,810
things so stuff like that I think is

00:16:27,290 --> 00:16:33,680
going to further help us optimize how we

00:16:29,810 --> 00:16:35,450
use our clusters variable lifespan so

00:16:33,680 --> 00:16:37,700
you know normally a stream is going to

00:16:35,450 --> 00:16:40,010
run for weeks to months this isn't this

00:16:37,700 --> 00:16:41,779
is a big contrast with a batch job which

00:16:40,010 --> 00:16:43,820
you know might run for hours maybe

00:16:41,779 --> 00:16:46,490
overnight but there's only so much

00:16:43,820 --> 00:16:48,470
optimization you have to do or dynamism

00:16:46,490 --> 00:16:50,450
you need if you're going to be done in a

00:16:48,470 --> 00:16:52,370
few hours but if this thing is going to

00:16:50,450 --> 00:16:54,950
have to stand up and be resilient for

00:16:52,370 --> 00:16:58,160
for weeks or months maybe then it's it's

00:16:54,950 --> 00:16:59,540
a new ballgame and you know of course

00:16:58,160 --> 00:17:01,070
now why would you you wouldn't

00:16:59,540 --> 00:17:02,630
necessarily have a streaming job that

00:17:01,070 --> 00:17:05,390
only lasts for a few minutes or a few

00:17:02,630 --> 00:17:06,650
hours normally because I just said you

00:17:05,390 --> 00:17:09,410
know this is data that's supposed to

00:17:06,650 --> 00:17:11,209
never stop coming but in fact and this

00:17:09,410 --> 00:17:13,250
is something Jake reps from confluent

00:17:11,209 --> 00:17:15,470
likes to harp on a lot if you have a

00:17:13,250 --> 00:17:18,079
stream processing system that you can

00:17:15,470 --> 00:17:19,939
treat batch is just a finite stream in

00:17:18,079 --> 00:17:22,010
principle so I could take my batch

00:17:19,939 --> 00:17:24,949
stream processor if I realized I made a

00:17:22,010 --> 00:17:26,660
mistake in a calculation and I only want

00:17:24,949 --> 00:17:28,400
to rerun yesterday's data then I can

00:17:26,660 --> 00:17:30,230
just start up a stream job that's

00:17:28,400 --> 00:17:32,420
actually going to have a finite stream

00:17:30,230 --> 00:17:34,280
which is yesterday's data and I

00:17:32,420 --> 00:17:36,650
basically have one system that does it

00:17:34,280 --> 00:17:39,140
all in principle so that's why I'd still

00:17:36,650 --> 00:17:41,390
put you know minutes on here and of

00:17:39,140 --> 00:17:44,000
course mezzos is really good at managing

00:17:41,390 --> 00:17:45,559
very short-lived containers because it's

00:17:44,000 --> 00:17:46,770
fairly lightweight I mean you wouldn't

00:17:45,559 --> 00:17:48,150
do seconds necessary

00:17:46,770 --> 00:17:50,250
because there is some overhead with a

00:17:48,150 --> 00:17:52,380
resource negotiation and offer

00:17:50,250 --> 00:17:56,040
management but you could do minutes

00:17:52,380 --> 00:17:57,720
without too much pain and if you're

00:17:56,040 --> 00:18:00,060
actually running services or that are

00:17:57,720 --> 00:18:03,000
gonna last for you know ever like the

00:18:00,060 --> 00:18:07,350
demons that run HDFS the name node and

00:18:03,000 --> 00:18:09,870
so forth that that just works so coming

00:18:07,350 --> 00:18:11,850
back to this scalability resilience and

00:18:09,870 --> 00:18:14,970
scalability or that whether those last

00:18:11,850 --> 00:18:16,530
two high-level bullets you just get a

00:18:14,970 --> 00:18:18,420
lot of stuff for free that's been really

00:18:16,530 --> 00:18:20,640
useful like you know a federation

00:18:18,420 --> 00:18:22,320
through zookeeper actually then the open

00:18:20,640 --> 00:18:23,880
wisk talk that was discussion of not

00:18:22,320 --> 00:18:26,100
using zookeeper but using akka

00:18:23,880 --> 00:18:29,610
clustering instead for federation with

00:18:26,100 --> 00:18:31,680
and wisk the way they had modified it

00:18:29,610 --> 00:18:33,030
but there's a lot of full tolerant

00:18:31,680 --> 00:18:35,190
facilities like if you've submitted

00:18:33,030 --> 00:18:38,040
through a marathon you can have the job

00:18:35,190 --> 00:18:39,930
you know restarted if it fails but there

00:18:38,040 --> 00:18:41,460
is one important point that I'll come

00:18:39,930 --> 00:18:43,470
back to kind of at the end and that is

00:18:41,460 --> 00:18:45,810
if you're building stateful streaming

00:18:43,470 --> 00:18:48,750
services then you have to have some

00:18:45,810 --> 00:18:51,060
mechanism for checkpointing in the state

00:18:48,750 --> 00:18:53,820
so that if it goes down you can bring it

00:18:51,060 --> 00:18:55,410
back up where it was in fact there's it

00:18:53,820 --> 00:18:57,870
turns out there's a it's kind of a bad

00:18:55,410 --> 00:18:59,550
bug and spark streaming the older spark

00:18:57,870 --> 00:19:01,350
streaming versus the new structured

00:18:59,550 --> 00:19:03,450
streaming if you know that distinction

00:19:01,350 --> 00:19:05,490
the older spark streaming could

00:19:03,450 --> 00:19:07,260
successfully start up again with a check

00:19:05,490 --> 00:19:08,870
point but there's some particular kinds

00:19:07,260 --> 00:19:12,150
of data that actually gets lost

00:19:08,870 --> 00:19:14,370
basically the they have this notion of

00:19:12,150 --> 00:19:16,440
counters that you can build in those

00:19:14,370 --> 00:19:18,510
actually get reset to zero it turns out

00:19:16,440 --> 00:19:19,950
and spark streaming if you restart the

00:19:18,510 --> 00:19:21,960
reason I'm mentioning this is because

00:19:19,950 --> 00:19:23,820
I've been dealing with a customer issue

00:19:21,960 --> 00:19:26,340
the last few days on that particular

00:19:23,820 --> 00:19:28,110
point so but apparently the new

00:19:26,340 --> 00:19:30,330
structured streaming is much better at

00:19:28,110 --> 00:19:32,610
handling stuff like that so that this is

00:19:30,330 --> 00:19:35,220
a mechanism that you end up having to

00:19:32,610 --> 00:19:37,440
solve some way yourself or the tool

00:19:35,220 --> 00:19:39,380
they're using like spark has to handle

00:19:37,440 --> 00:19:41,970
it for you

00:19:39,380 --> 00:19:44,400
and then the scalability the fact that

00:19:41,970 --> 00:19:45,720
you you it's not that hard actually but

00:19:44,400 --> 00:19:48,000
this is something that you have to build

00:19:45,720 --> 00:19:50,100
into your your streaming system to

00:19:48,000 --> 00:19:51,120
actually do dynamic scaling up and down

00:19:50,100 --> 00:19:54,090
and we've got all kinds of facilities

00:19:51,120 --> 00:19:56,730
and meso so now to support this like you

00:19:54,090 --> 00:19:59,100
optimistic offers and dynamic resource

00:19:56,730 --> 00:20:00,210
allocation that lets us do this kind of

00:19:59,100 --> 00:20:02,160
stuff as long as

00:20:00,210 --> 00:20:06,060
it's built as long as your framework

00:20:02,160 --> 00:20:09,060
takes advantage of this we've actually

00:20:06,060 --> 00:20:10,890
worked with the mesosphere for spark for

00:20:09,060 --> 00:20:13,170
example to support these kind of newer

00:20:10,890 --> 00:20:14,910
capabilities so that spark jobs can be

00:20:13,170 --> 00:20:16,920
more dynamic you know to scale and

00:20:14,910 --> 00:20:20,280
demand there's still actually work to do

00:20:16,920 --> 00:20:21,930
though I have to be honest okay so

00:20:20,280 --> 00:20:23,280
that's kind of the high level picture of

00:20:21,930 --> 00:20:25,980
the sort of things you have to worry

00:20:23,280 --> 00:20:27,690
about with streaming apps in general I

00:20:25,980 --> 00:20:30,480
wanted to take a few minutes and talk

00:20:27,690 --> 00:20:33,110
about some particulars that of some of

00:20:30,480 --> 00:20:36,240
the streaming engines that we've used so

00:20:33,110 --> 00:20:38,310
we actually focus on four in this fast

00:20:36,240 --> 00:20:40,260
data platform and we picked these four

00:20:38,310 --> 00:20:42,630
because that we felt that they covered

00:20:40,260 --> 00:20:44,430
you know a reasonable percentage of this

00:20:42,630 --> 00:20:47,850
kind of a hundred percent of things you

00:20:44,430 --> 00:20:49,560
might need to do it but it kind of sucks

00:20:47,850 --> 00:20:51,750
that you have four I'd rather have like

00:20:49,560 --> 00:20:54,480
one or maybe two but kind of that sort

00:20:51,750 --> 00:20:55,890
of the world we live in is that if you

00:20:54,480 --> 00:20:57,420
really want to cover everything you kind

00:20:55,890 --> 00:20:59,400
of need to be able to pick from a list

00:20:57,420 --> 00:21:01,080
of four in our opinion and some other

00:20:59,400 --> 00:21:02,640
criteria that we use that I'm will get

00:21:01,080 --> 00:21:05,310
into in a lot of detail here are

00:21:02,640 --> 00:21:07,320
pragmatic things like are these actually

00:21:05,310 --> 00:21:08,940
viable projects and turns somebody wrote

00:21:07,320 --> 00:21:12,000
this great blog post a couple of years

00:21:08,940 --> 00:21:13,740
ago listing like 11 or 12 Apache

00:21:12,000 --> 00:21:15,300
projects that claim to be streaming

00:21:13,740 --> 00:21:18,060
engines so you know it's right you have

00:21:15,300 --> 00:21:19,470
this paradox of choice problem it's sort

00:21:18,060 --> 00:21:21,660
of like going in to Best Buy to buy a

00:21:19,470 --> 00:21:23,160
refrigerator and you see this line that

00:21:21,660 --> 00:21:25,260
goes down you know a little a football

00:21:23,160 --> 00:21:26,310
field of refrigerators so you kind of

00:21:25,260 --> 00:21:29,190
walk out of there because you're afraid

00:21:26,310 --> 00:21:30,450
to buy the wrong refrigerator so I don't

00:21:29,190 --> 00:21:33,270
really like giving people too many

00:21:30,450 --> 00:21:34,770
choices because of that problem but what

00:21:33,270 --> 00:21:36,630
I've tried to do is distill it down to

00:21:34,770 --> 00:21:38,670
four that cover the spectrum and then

00:21:36,630 --> 00:21:41,850
I'll talk briefly about how each one

00:21:38,670 --> 00:21:43,710
works from particular kinds of problems

00:21:41,850 --> 00:21:47,610
and then discuss how they fit into meso

00:21:43,710 --> 00:21:49,440
so how Mesa supports them so but to go

00:21:47,610 --> 00:21:51,450
over these sort of characteristics that

00:21:49,440 --> 00:21:53,100
you might use so now I'm at the level of

00:21:51,450 --> 00:21:54,270
I'm gonna write an application and I

00:21:53,100 --> 00:21:56,790
need to figure out which of these

00:21:54,270 --> 00:21:58,530
engines I want to pick so the first

00:21:56,790 --> 00:22:01,590
thing you might ask is what's my latency

00:21:58,530 --> 00:22:03,420
budget this is actually pretty important

00:22:01,590 --> 00:22:05,670
because if you're gonna do things like

00:22:03,420 --> 00:22:07,080
authorize credit cards it sort of the

00:22:05,670 --> 00:22:10,110
rule of thumb that I've heard in the

00:22:07,080 --> 00:22:12,930
banking world is if for usability

00:22:10,110 --> 00:22:13,510
reasons I have 200 milliseconds to like

00:22:12,930 --> 00:22:15,280
refresh

00:22:13,510 --> 00:22:17,770
a webpage you know you've heard that

00:22:15,280 --> 00:22:19,360
number probably it turns out of all the

00:22:17,770 --> 00:22:22,300
things that have to happen between me

00:22:19,360 --> 00:22:24,250
clicking by and getting a response the

00:22:22,300 --> 00:22:26,500
bank gets about 10 milliseconds to make

00:22:24,250 --> 00:22:29,650
a decision with your credit card you

00:22:26,500 --> 00:22:31,600
know and purchase that is way too short

00:22:29,650 --> 00:22:33,460
for something like spark streaming which

00:22:31,600 --> 00:22:35,020
is still mostly kind of a mini batch

00:22:33,460 --> 00:22:37,450
model where it likes to get data and

00:22:35,020 --> 00:22:41,530
chunks and then use the efficiency of

00:22:37,450 --> 00:22:44,200
the cluster to process in mass but for

00:22:41,530 --> 00:22:46,690
something like akka or Kafka streams are

00:22:44,200 --> 00:22:49,060
one of those you could recently do 10

00:22:46,690 --> 00:22:51,420
millisecond individual processing of

00:22:49,060 --> 00:22:55,060
events you know complex event processing

00:22:51,420 --> 00:22:56,680
sorry about that again volume is also

00:22:55,060 --> 00:22:58,300
important to some of the engines I'll

00:22:56,680 --> 00:23:00,970
talk about really don't scale

00:22:58,300 --> 00:23:03,610
horizontally so they're they're really

00:23:00,970 --> 00:23:05,950
great at low latency maybe but if you

00:23:03,610 --> 00:23:08,710
need to do a lot of stuff like process

00:23:05,950 --> 00:23:11,080
the Twitter firehose maybe I'll just

00:23:08,710 --> 00:23:13,120
hold this thing I think this is a bit of

00:23:11,080 --> 00:23:15,580
an old Mac and it might be the connector

00:23:13,120 --> 00:23:17,110
spring oh it does okay all right well I

00:23:15,580 --> 00:23:17,740
won't touch it then maybe that's been

00:23:17,110 --> 00:23:21,250
better

00:23:17,740 --> 00:23:22,750
um but volume so if you are processing

00:23:21,250 --> 00:23:25,210
the Twitter firehose and something like

00:23:22,750 --> 00:23:27,520
spark or flank is really great because

00:23:25,210 --> 00:23:29,130
they can partition that stream as it's

00:23:27,520 --> 00:23:31,780
coming in and then do things in parallel

00:23:29,130 --> 00:23:33,640
but you know if you don't have quite

00:23:31,780 --> 00:23:36,910
that scale but you need lower latency

00:23:33,640 --> 00:23:38,500
then maybe another tools better what

00:23:36,910 --> 00:23:40,630
kind of process you're going to do it

00:23:38,500 --> 00:23:42,490
seems like everybody is layering sequel

00:23:40,630 --> 00:23:45,070
on top of their streaming engine you may

00:23:42,490 --> 00:23:46,960
know that Kafka the confluent guys just

00:23:45,070 --> 00:23:49,270
announced this at Kafka summit like a

00:23:46,960 --> 00:23:51,220
week ago or two weeks ago

00:23:49,270 --> 00:23:52,210
if you want to do machine learning and

00:23:51,220 --> 00:23:54,280
here there's a really interesting

00:23:52,210 --> 00:23:57,190
problem in machine learning in the

00:23:54,280 --> 00:23:58,450
streaming context and that is I'd kind

00:23:57,190 --> 00:24:00,280
of like to be training models

00:23:58,450 --> 00:24:02,260
incrementally because you know let's

00:24:00,280 --> 00:24:04,500
just say spam is actually evolving more

00:24:02,260 --> 00:24:06,670
quickly than it really is I'd like to be

00:24:04,500 --> 00:24:08,740
adjusting my spam filters to the

00:24:06,670 --> 00:24:10,690
evolving threat and there's this notion

00:24:08,740 --> 00:24:13,240
of concept drift and machine learning

00:24:10,690 --> 00:24:16,690
where my model is getting stale over

00:24:13,240 --> 00:24:18,610
time I had a one of my the best managers

00:24:16,690 --> 00:24:20,200
I ever had used to say that software has

00:24:18,610 --> 00:24:21,840
a half-life you know whether you're

00:24:20,200 --> 00:24:24,190
touching it or not it's kind of decaying

00:24:21,840 --> 00:24:25,960
maybe because it's been growing

00:24:24,190 --> 00:24:27,160
irrelevant or something I think that's

00:24:25,960 --> 00:24:30,010
true and machine

00:24:27,160 --> 00:24:32,200
so but back to the point we would like

00:24:30,010 --> 00:24:34,660
to be able to train models but also

00:24:32,200 --> 00:24:36,430
serve them with lower latency than we

00:24:34,660 --> 00:24:39,610
can possibly train them so that kind of

00:24:36,430 --> 00:24:41,320
forces sometimes a choice between maybe

00:24:39,610 --> 00:24:43,300
I'll train with spark because it's

00:24:41,320 --> 00:24:45,820
pretty good at that kind of batch you

00:24:43,300 --> 00:24:47,440
know many batch stuff like I might do

00:24:45,820 --> 00:24:49,360
maybe every hour all I'm going to update

00:24:47,440 --> 00:24:51,850
my models but then how do I take that

00:24:49,360 --> 00:24:54,130
model and actually serve it from my low

00:24:51,850 --> 00:24:56,350
latency stream engine that may not be

00:24:54,130 --> 00:24:59,320
spark so there's some interesting

00:24:56,350 --> 00:25:01,420
problems there and if I'm just doing

00:24:59,320 --> 00:25:03,520
simple filtering and transformations you

00:25:01,420 --> 00:25:05,770
know like for say ETL kind of problems

00:25:03,520 --> 00:25:07,990
extract transform and load then then I

00:25:05,770 --> 00:25:09,100
have a lot more options and some things

00:25:07,990 --> 00:25:12,400
are going to be better than others for

00:25:09,100 --> 00:25:17,290
other reasons all right moving on to the

00:25:12,400 --> 00:25:18,880
third page of these trade offs this goes

00:25:17,290 --> 00:25:20,770
back to that thing I mentioned a minute

00:25:18,880 --> 00:25:22,120
ago where I might actually need to look

00:25:20,770 --> 00:25:24,100
at each event individually like

00:25:22,120 --> 00:25:26,170
authorizing a credit card doing like

00:25:24,100 --> 00:25:28,300
fraud detection that kind of stuff or

00:25:26,170 --> 00:25:30,490
maybe I'm just doing bulk processing or

00:25:28,300 --> 00:25:32,560
everything's coming in each of these

00:25:30,490 --> 00:25:35,110
records is actually kind of anonymous I

00:25:32,560 --> 00:25:37,120
just want to clean it up maybe join it

00:25:35,110 --> 00:25:39,700
with some other sideband data and then

00:25:37,120 --> 00:25:41,440
spew it out to its downstream consumers

00:25:39,700 --> 00:25:43,540
I don't need to process it individually

00:25:41,440 --> 00:25:45,730
I could kind of actually exploit the

00:25:43,540 --> 00:25:49,300
efficiency of doing things sort of in

00:25:45,730 --> 00:25:50,920
groups and then the last one is what

00:25:49,300 --> 00:25:52,420
kind of interoperability do I need to

00:25:50,920 --> 00:25:54,040
other tools so actually the reason this

00:25:52,420 --> 00:25:58,690
point is here is because it turns out

00:25:54,040 --> 00:26:00,430
kafka streams is really designed to read

00:25:58,690 --> 00:26:02,320
and write Kafka topics and it does that

00:26:00,430 --> 00:26:04,930
very very well but if you wanted to have

00:26:02,320 --> 00:26:07,270
it process like restful Rick you know be

00:26:04,930 --> 00:26:09,240
a hook for restful input then you'd have

00:26:07,270 --> 00:26:11,380
to use something else along with it so

00:26:09,240 --> 00:26:13,450
but other tools have a lot more

00:26:11,380 --> 00:26:14,830
flexibility in terms of just direct

00:26:13,450 --> 00:26:18,580
connection to this that and the other

00:26:14,830 --> 00:26:20,680
thing like writing to databases so let's

00:26:18,580 --> 00:26:22,600
talk about these four tools that I've

00:26:20,680 --> 00:26:24,670
sort of already mentioned and how they

00:26:22,600 --> 00:26:27,430
fit into this picture and then what's

00:26:24,670 --> 00:26:31,030
maysa does for us to make them you know

00:26:27,430 --> 00:26:32,230
really good tools to work with and I'm

00:26:31,030 --> 00:26:34,720
there actually fall into two groups

00:26:32,230 --> 00:26:36,970
there's Kafka streams and acha streams

00:26:34,720 --> 00:26:39,130
have a lot of synergies and various ways

00:26:36,970 --> 00:26:40,210
that I'll get into and then flank and

00:26:39,130 --> 00:26:42,970
SPARC kind of fit

00:26:40,210 --> 00:26:44,860
into their own little subgroup so if I'm

00:26:42,970 --> 00:26:47,860
going to do Kafka streams this again is

00:26:44,860 --> 00:26:49,540
the library that sits on top of cuff and

00:26:47,860 --> 00:26:51,310
that will actually to be more precise so

00:26:49,540 --> 00:26:53,620
this is actually important you write an

00:26:51,310 --> 00:26:55,960
application that embeds kafka streams is

00:26:53,620 --> 00:26:57,940
the library and so you manage your

00:26:55,960 --> 00:27:00,550
application your micro service whatever

00:26:57,940 --> 00:27:01,870
any way you want now the exception of

00:27:00,550 --> 00:27:04,890
that it turns out if you do use this

00:27:01,870 --> 00:27:07,210
Kafka string ugh Kafka sequel Kay sequel

00:27:04,890 --> 00:27:09,040
library that sits on top of Kafka

00:27:07,210 --> 00:27:12,280
streams there are some services that you

00:27:09,040 --> 00:27:14,470
do run in that case but anyway it's it

00:27:12,280 --> 00:27:16,390
can be pretty low latency latency here

00:27:14,470 --> 00:27:18,610
is actually more limited by how long you

00:27:16,390 --> 00:27:20,590
let your queues get your topic lengths

00:27:18,610 --> 00:27:23,910
become in Kafka that's going to be your

00:27:20,590 --> 00:27:26,440
kind of latency budget in Kafka streams

00:27:23,910 --> 00:27:28,000
it's not designed for it you know it's

00:27:26,440 --> 00:27:30,730
not a tool you used to shard this

00:27:28,000 --> 00:27:32,470
massive pipe of data across a cluster

00:27:30,730 --> 00:27:34,060
into partitions so you can run in

00:27:32,470 --> 00:27:36,010
parallel it's not really designed for

00:27:34,060 --> 00:27:37,750
that it's more like medium volume which

00:27:36,010 --> 00:27:40,000
I don't want to say low volume because

00:27:37,750 --> 00:27:43,270
that sounds bad but you know not volumes

00:27:40,000 --> 00:27:45,340
like spark can do it's fantastic it has

00:27:43,270 --> 00:27:47,860
a lot of really good primitives written

00:27:45,340 --> 00:27:50,310
in to make a lot of common problems easy

00:27:47,860 --> 00:27:52,720
to do like extract transform and load

00:27:50,310 --> 00:27:54,550
transformation kind of stuff where I'm

00:27:52,720 --> 00:27:56,770
just gonna my favorite example of this

00:27:54,550 --> 00:27:58,360
is that maybe I'm ingesting raw log data

00:27:56,770 --> 00:28:00,790
and I want to parse it into some sort of

00:27:58,360 --> 00:28:02,650
record format right into a new Kafka

00:28:00,790 --> 00:28:04,750
topic and then downstream consumers

00:28:02,650 --> 00:28:06,610
aren't parsing strings they're actually

00:28:04,750 --> 00:28:09,250
reading records that represent the log

00:28:06,610 --> 00:28:10,870
data but they also have some cool table

00:28:09,250 --> 00:28:12,610
abstractions so if I just need to do

00:28:10,870 --> 00:28:14,710
aggregations I don't actually need to

00:28:12,610 --> 00:28:16,630
see every record I want to see like the

00:28:14,710 --> 00:28:18,580
average over the last minute or

00:28:16,630 --> 00:28:21,850
something they have some nice facilities

00:28:18,580 --> 00:28:23,950
for that and so you can sort of if you

00:28:21,850 --> 00:28:25,960
think about how what that means in terms

00:28:23,950 --> 00:28:29,050
of individual record process and it kind

00:28:25,960 --> 00:28:29,650
of wrote this last bullet backwards in a

00:28:29,050 --> 00:28:31,630
way

00:28:29,650 --> 00:28:33,550
ETL would be like looking at each event

00:28:31,630 --> 00:28:35,410
one at a time whereas the table

00:28:33,550 --> 00:28:37,450
abstraction would be more like I'm doing

00:28:35,410 --> 00:28:41,710
sort of a data flow that's doing

00:28:37,450 --> 00:28:44,080
aggregations sort of anyway now akka

00:28:41,710 --> 00:28:47,920
streams is so again we're talking about

00:28:44,080 --> 00:28:50,140
the smack stack a placeholder akka

00:28:47,920 --> 00:28:52,540
streams is actually a dsl

00:28:50,140 --> 00:28:54,160
domain-specific language on top of akka

00:28:52,540 --> 00:28:56,650
actors so rather than having to write

00:28:54,160 --> 00:28:58,390
low-level actor primitives you can write

00:28:56,650 --> 00:29:02,020
things as data flows and then it will

00:28:58,390 --> 00:29:03,340
materialize actors for you it also is a

00:29:02,020 --> 00:29:05,320
library that you embed in your

00:29:03,340 --> 00:29:08,170
applications so it's sort of analogous

00:29:05,320 --> 00:29:10,300
to Kafka streams in that way it can be

00:29:08,170 --> 00:29:12,250
very low latency so even though there is

00:29:10,300 --> 00:29:14,470
a bit of overhead sending messages

00:29:12,250 --> 00:29:16,720
between akka actors it's pretty good

00:29:14,470 --> 00:29:18,070
down into the millisecond ish range I

00:29:16,720 --> 00:29:20,680
mean so you wouldn't use it for like

00:29:18,070 --> 00:29:23,710
controlling SpaceX Rockets when they're

00:29:20,680 --> 00:29:25,540
landing but it's pretty good for things

00:29:23,710 --> 00:29:27,850
like fraud detection credit card

00:29:25,540 --> 00:29:29,650
authorization and stuff like that again

00:29:27,850 --> 00:29:32,470
sort of medium volume not designed to

00:29:29,650 --> 00:29:33,900
partition your data it actually of all

00:29:32,470 --> 00:29:35,890
these tools that has the most

00:29:33,900 --> 00:29:38,110
sophistication in terms of the kind of

00:29:35,890 --> 00:29:39,760
event flows you can define it's the only

00:29:38,110 --> 00:29:41,770
one of these for example that lets you

00:29:39,760 --> 00:29:42,940
do like feedback loops although I really

00:29:41,770 --> 00:29:45,310
have no idea of what that would look

00:29:42,940 --> 00:29:46,920
like I'm not sure I would try it but you

00:29:45,310 --> 00:29:50,440
could do feedback loops if you wanted

00:29:46,920 --> 00:29:52,690
and so for and it's akka is kind of

00:29:50,440 --> 00:29:54,970
famous for doing the so-called complex

00:29:52,690 --> 00:29:56,800
event processing like you know fraud

00:29:54,970 --> 00:30:00,430
detection or credit card authorization

00:29:56,800 --> 00:30:02,620
and so forth so this is I drew this

00:30:00,430 --> 00:30:04,180
diagram like maybe two hours ago is so

00:30:02,620 --> 00:30:07,140
it's not very good but this sort of the

00:30:04,180 --> 00:30:10,120
idea of what you might what I mean by

00:30:07,140 --> 00:30:13,570
how you might embed akka or Kafka

00:30:10,120 --> 00:30:15,310
streams into an application that's or

00:30:13,570 --> 00:30:17,170
and actually the application here is

00:30:15,310 --> 00:30:19,000
represented as micro services that you'd

00:30:17,170 --> 00:30:22,510
be running that are all processing the

00:30:19,000 --> 00:30:24,640
stream of events the thing about this

00:30:22,510 --> 00:30:26,680
really the reason the slide mostly is

00:30:24,640 --> 00:30:28,330
here is to talk about how this is

00:30:26,680 --> 00:30:30,280
supported amaze us and once again

00:30:28,330 --> 00:30:32,740
because we have really good support for

00:30:30,280 --> 00:30:34,630
containers for you know lightweight

00:30:32,740 --> 00:30:36,940
containers as well as you know fairly

00:30:34,630 --> 00:30:40,150
big things it's pretty easy to have that

00:30:36,940 --> 00:30:43,150
event stream coming out of Kafka whether

00:30:40,150 --> 00:30:44,740
it's akka or Kafka streams and then I've

00:30:43,150 --> 00:30:47,410
got these micro services that are

00:30:44,740 --> 00:30:50,140
reading the data maybe really this this

00:30:47,410 --> 00:30:52,690
diagram is better for akka because it

00:30:50,140 --> 00:30:54,310
implies them gonna route this over to

00:30:52,690 --> 00:30:56,350
other micro services and do

00:30:54,310 --> 00:30:58,450
manipulations of some kind depending on

00:30:56,350 --> 00:31:00,610
what the events are and I'm not really

00:30:58,450 --> 00:31:03,190
showing output but you would imagine

00:31:00,610 --> 00:31:07,170
that maybe it goes back to a Kafka topic

00:31:03,190 --> 00:31:07,170
or a black screen or something like that

00:31:08,320 --> 00:31:14,090
now the other two that sort of fit into

00:31:11,480 --> 00:31:17,930
a different category spark and flank or

00:31:14,090 --> 00:31:20,480
are actually deployed as systems that

00:31:17,930 --> 00:31:23,060
are running their own services and then

00:31:20,480 --> 00:31:24,920
you submit jobs to them that they figure

00:31:23,060 --> 00:31:26,600
out how to partition and to work over

00:31:24,920 --> 00:31:29,330
the cluster and that's really actually

00:31:26,600 --> 00:31:36,170
even true for streaming it's true for

00:31:29,330 --> 00:31:38,210
queries etc okay so medium latency

00:31:36,170 --> 00:31:40,100
though because at least as of today and

00:31:38,210 --> 00:31:42,200
this is sort of going away over time

00:31:40,100 --> 00:31:44,810
spark actually is doing mini batches

00:31:42,200 --> 00:31:47,570
behind the scenes so when you say I want

00:31:44,810 --> 00:31:50,750
to run a stream job it's actually going

00:31:47,570 --> 00:31:52,670
to box up some amount of data and then

00:31:50,750 --> 00:31:54,710
do some processing over it so there's

00:31:52,670 --> 00:31:57,500
some latency there in the old spark

00:31:54,710 --> 00:32:00,110
streaming API the latency was maybe 200

00:31:57,500 --> 00:32:01,510
to 500 milliseconds as a minimum so that

00:32:00,110 --> 00:32:03,950
like that credit card authorization

00:32:01,510 --> 00:32:05,570
example no way you can it can you use

00:32:03,950 --> 00:32:08,300
spark streaming for that because you

00:32:05,570 --> 00:32:09,710
don't have 200 milliseconds to wait but

00:32:08,300 --> 00:32:11,750
it is great if your training machine

00:32:09,710 --> 00:32:14,750
learning models and you don't mind like

00:32:11,750 --> 00:32:16,460
having minutes or whatever windows where

00:32:14,750 --> 00:32:18,290
you just accumulate data then you know

00:32:16,460 --> 00:32:20,480
like do an incremental training of the

00:32:18,290 --> 00:32:23,330
model and then do something with the

00:32:20,480 --> 00:32:25,610
data downstream they will eventually get

00:32:23,330 --> 00:32:27,440
rid of this minimum latency and make it

00:32:25,610 --> 00:32:29,900
more of a true streaming inch and that's

00:32:27,440 --> 00:32:31,630
work that's actively being done but this

00:32:29,900 --> 00:32:34,130
is kind of the state of the art today I

00:32:31,630 --> 00:32:37,700
really love the sequel's support in

00:32:34,130 --> 00:32:38,860
SPARC it's now ANSI like 2002 compatible

00:32:37,700 --> 00:32:41,390
so it's kind of impressive

00:32:38,860 --> 00:32:43,520
and then of course if you've written

00:32:41,390 --> 00:32:45,830
your logic for SPARC streaming you can

00:32:43,520 --> 00:32:47,960
use it for batch mode processing too so

00:32:45,830 --> 00:32:50,090
a lot of your offline warehousing apps

00:32:47,960 --> 00:32:51,800
can be done this way but it isn't

00:32:50,090 --> 00:32:54,140
designed for single event processing

00:32:51,800 --> 00:32:57,200
that's what I mean by unmask processing

00:32:54,140 --> 00:32:59,420
more like you know just chunks so let

00:32:57,200 --> 00:33:01,040
the flink is the fourth one a year ago I

00:32:59,420 --> 00:33:02,510
wouldn't have included flink here but I

00:33:01,040 --> 00:33:04,520
really decided that there were two

00:33:02,510 --> 00:33:07,610
important reasons why I wanted to have

00:33:04,520 --> 00:33:10,250
flanking in as part of our product one

00:33:07,610 --> 00:33:12,830
is that it is designed as one of these

00:33:10,250 --> 00:33:14,510
high-volume tools but it was designed

00:33:12,830 --> 00:33:16,280
initially as a streaming engine from the

00:33:14,510 --> 00:33:18,440
get-go so it does actually do low

00:33:16,280 --> 00:33:19,080
latency but really well so if you need

00:33:18,440 --> 00:33:21,059
to do like

00:33:19,080 --> 00:33:23,610
this partitioning of data but still have

00:33:21,059 --> 00:33:26,250
reasonably low latency then flink is

00:33:23,610 --> 00:33:27,809
often picked by teams over spark for

00:33:26,250 --> 00:33:30,809
that reason it's really more of a true

00:33:27,809 --> 00:33:32,850
streaming engine from the get-go the

00:33:30,809 --> 00:33:35,690
other reason is that there is this

00:33:32,850 --> 00:33:39,779
Apache project called beam the II am

00:33:35,690 --> 00:33:41,850
that's Google data flows sort of topside

00:33:39,779 --> 00:33:44,010
and the reason I put it that way is

00:33:41,850 --> 00:33:46,710
Google did something rather clever they

00:33:44,010 --> 00:33:49,860
open-source the data flow definition

00:33:46,710 --> 00:33:51,840
part of data flow over loading terms a

00:33:49,860 --> 00:33:53,190
little bit I know but not the runner

00:33:51,840 --> 00:33:55,350
part the thing would actually

00:33:53,190 --> 00:33:57,210
materialize that data flow and run it so

00:33:55,350 --> 00:33:58,830
if you're in Google Cloud you get data

00:33:57,210 --> 00:34:00,120
flow and you can run it that way but if

00:33:58,830 --> 00:34:03,470
you're not you need something else to

00:34:00,120 --> 00:34:07,139
run it and as of today at least Apache

00:34:03,470 --> 00:34:08,820
link is the best tool for running beam

00:34:07,139 --> 00:34:10,889
data flows and what that meat why is

00:34:08,820 --> 00:34:13,349
that important well beam to me is like

00:34:10,889 --> 00:34:15,119
the small talk of our era I'm really

00:34:13,349 --> 00:34:16,919
dating myself here but small talk was

00:34:15,119 --> 00:34:19,109
like the programming language that

00:34:16,919 --> 00:34:22,169
everyone aspired to you know back in the

00:34:19,109 --> 00:34:23,970
80s okay yeah I know the 80s actually

00:34:22,169 --> 00:34:26,040
existed for most of you it's just a you

00:34:23,970 --> 00:34:28,379
know this thing that people the people

00:34:26,040 --> 00:34:30,030
my age claimed actually existed but but

00:34:28,379 --> 00:34:31,770
the thing was nobody you actually use

00:34:30,030 --> 00:34:34,200
small talk but they all talked about it

00:34:31,770 --> 00:34:36,210
is like the gold standard well I I feel

00:34:34,200 --> 00:34:38,099
that beam might sort of fall into the

00:34:36,210 --> 00:34:40,080
same category it's influencing

00:34:38,099 --> 00:34:41,970
everything that everybody else is doing

00:34:40,080 --> 00:34:44,280
the reason being that there they've done

00:34:41,970 --> 00:34:46,050
a really good job thinking about all the

00:34:44,280 --> 00:34:48,330
weird things that happen when you're

00:34:46,050 --> 00:34:51,510
processing data and you want actual

00:34:48,330 --> 00:34:54,720
accuracy not approximate numbers so for

00:34:51,510 --> 00:34:56,250
example suppose that you want to for

00:34:54,720 --> 00:34:58,200
your accounting purposes you need to

00:34:56,250 --> 00:35:00,930
know like let's say for every 10 minutes

00:34:58,200 --> 00:35:03,630
how many units of a particular you know

00:35:00,930 --> 00:35:05,369
SKU did I sell in my stores you know

00:35:03,630 --> 00:35:07,920
around the country you know I work for a

00:35:05,369 --> 00:35:09,869
physical retailer let's say well that

00:35:07,920 --> 00:35:12,690
sounds like not too bad I'll just set up

00:35:09,869 --> 00:35:14,280
this sort of bachelors mini-batch job or

00:35:12,690 --> 00:35:16,020
with something and streaming it looks at

00:35:14,280 --> 00:35:18,089
10-minute windows and then it just does

00:35:16,020 --> 00:35:20,250
these roll-ups and bang right into the

00:35:18,089 --> 00:35:22,500
accounting system well not so fast

00:35:20,250 --> 00:35:25,830
unfortunately because light has a finite

00:35:22,500 --> 00:35:28,470
speed chances are pretty high that most

00:35:25,830 --> 00:35:30,240
of those at least a lot of those numbers

00:35:28,470 --> 00:35:30,910
are actually going to show up later

00:35:30,240 --> 00:35:32,920
you

00:35:30,910 --> 00:35:35,140
because of the time it takes data trends

00:35:32,920 --> 00:35:37,089
to traverse the network but even worse

00:35:35,140 --> 00:35:39,039
if I get a network partition and data

00:35:37,089 --> 00:35:40,750
doesn't show up for maybe ten minutes or

00:35:39,039 --> 00:35:43,750
an hour you know how do I handle this

00:35:40,750 --> 00:35:45,940
late arrival of data do I decide alright

00:35:43,750 --> 00:35:48,460
I'll do some approximate provisional

00:35:45,940 --> 00:35:49,930
calculations and send those down but I

00:35:48,460 --> 00:35:52,329
have this mechanism for sending

00:35:49,930 --> 00:35:54,190
Corrections if I get data arriving late

00:35:52,329 --> 00:35:55,839
these are the kind of questions you end

00:35:54,190 --> 00:35:57,039
up asking yourself if you want to build

00:35:55,839 --> 00:35:59,319
something that doesn't just do

00:35:57,039 --> 00:36:01,569
approximate aggregations over Windows

00:35:59,319 --> 00:36:04,299
but tries to actually be you know sort

00:36:01,569 --> 00:36:05,650
of really really accurate like the kind

00:36:04,299 --> 00:36:07,839
of stuff you'd want in an accounting

00:36:05,650 --> 00:36:09,670
system so Google's thought about all of

00:36:07,839 --> 00:36:12,280
this the beam does a really

00:36:09,670 --> 00:36:15,880
sophisticated job of presenting this and

00:36:12,280 --> 00:36:18,069
that's why I really like fling because

00:36:15,880 --> 00:36:20,020
they're ahead of everybody else in terms

00:36:18,069 --> 00:36:22,210
of supporting these semantics if you

00:36:20,020 --> 00:36:23,349
need that kind of capability okay I'm

00:36:22,210 --> 00:36:25,180
running out of time so let me just

00:36:23,349 --> 00:36:27,520
quickly finish I showed this diagram

00:36:25,180 --> 00:36:28,150
before but just to emphasize both SPARC

00:36:27,520 --> 00:36:30,460
and flank

00:36:28,150 --> 00:36:32,589
they run services in the cluster you

00:36:30,460 --> 00:36:35,170
submit jobs and then they figure out how

00:36:32,589 --> 00:36:36,430
to partition it into tasks as opposed to

00:36:35,170 --> 00:36:39,130
embedding these tools in your

00:36:36,430 --> 00:36:41,020
applications the last point I want to

00:36:39,130 --> 00:36:42,670
get into a little bit that I've alluded

00:36:41,020 --> 00:36:44,470
to is the sort of merging of

00:36:42,670 --> 00:36:46,839
architectures that's kind of happening

00:36:44,470 --> 00:36:48,490
so if you go back a few years ago that

00:36:46,839 --> 00:36:50,380
there was the Big Data people who mostly

00:36:48,490 --> 00:36:52,299
worried about data availability and you

00:36:50,380 --> 00:36:54,430
know scaling to big data sets but didn't

00:36:52,299 --> 00:36:57,130
worry too much about you know high

00:36:54,430 --> 00:36:58,480
availability high resilience scalability

00:36:57,130 --> 00:37:00,250
those kind of things it wasn't as big a

00:36:58,480 --> 00:37:02,770
problem for them as it was for the guys

00:37:00,250 --> 00:37:04,930
building the web servers in in the your

00:37:02,770 --> 00:37:07,230
organization which I just lumped under

00:37:04,930 --> 00:37:09,940
services but I think today is we've

00:37:07,230 --> 00:37:11,500
moved to micro services and fast data

00:37:09,940 --> 00:37:13,059
they're kind of converging a little bit

00:37:11,500 --> 00:37:15,549
and let me just quickly make the case

00:37:13,059 --> 00:37:18,130
and then I'll quit so if you think about

00:37:15,549 --> 00:37:20,049
like a classic Microsystems architecture

00:37:18,130 --> 00:37:21,789
it's usually I've got each little micro

00:37:20,049 --> 00:37:23,950
service does its own thing has a one

00:37:21,789 --> 00:37:26,079
responsibility I can evolve them

00:37:23,950 --> 00:37:28,210
independently I can you know scale them

00:37:26,079 --> 00:37:30,400
independently I can drop in new ones and

00:37:28,210 --> 00:37:32,829
this fits the meso smaadahl really well

00:37:30,400 --> 00:37:34,480
because Mesa supports containers really

00:37:32,829 --> 00:37:37,299
well and I can easily you know deploy

00:37:34,480 --> 00:37:40,990
multiple things and and and do this kind

00:37:37,299 --> 00:37:42,279
of stuff pretty nicely that may not seem

00:37:40,990 --> 00:37:43,990
to represent what's going on is

00:37:42,279 --> 00:37:44,770
streaming very much but actually I think

00:37:43,990 --> 00:37:46,990
most of the

00:37:44,770 --> 00:37:48,700
people are building very similar things

00:37:46,990 --> 00:37:50,680
in streaming architectures I've got

00:37:48,700 --> 00:37:52,900
weather I've got spark or acha streams

00:37:50,680 --> 00:37:54,550
or whatever I'm usually writing an app

00:37:52,900 --> 00:37:56,830
that does one thing I'm going to deploy

00:37:54,550 --> 00:37:58,450
it I may need to deploy a lot of them I

00:37:56,830 --> 00:38:01,390
may need concurrent versions so I have a

00:37:58,450 --> 00:38:03,430
lot of the same concerns and I'll just

00:38:01,390 --> 00:38:05,740
get past this the synergy stuff just to

00:38:03,430 --> 00:38:07,690
get to the point but I think what's

00:38:05,740 --> 00:38:09,250
actually happening is that it's kind of

00:38:07,690 --> 00:38:11,200
forcing these architectures to look more

00:38:09,250 --> 00:38:13,810
alike than different if I'm a micro

00:38:11,200 --> 00:38:15,820
service person and I'm used to building

00:38:13,810 --> 00:38:17,530
I was building three-tier apps now I'm

00:38:15,820 --> 00:38:19,600
building micro services well if I'm

00:38:17,530 --> 00:38:21,880
successful then my data is going to

00:38:19,600 --> 00:38:23,020
become dominant as my business grows and

00:38:21,880 --> 00:38:24,730
so now I'm going to be worried about

00:38:23,020 --> 00:38:26,170
building more like stream data

00:38:24,730 --> 00:38:27,700
processing if you think about what the

00:38:26,170 --> 00:38:31,960
Twitter architecture must have looked

00:38:27,700 --> 00:38:33,400
like from 2007 ish or 8 to today and

00:38:31,960 --> 00:38:34,050
that's sort of the evolution that they

00:38:33,400 --> 00:38:36,760
went through

00:38:34,050 --> 00:38:39,280
conversely if I'm now going from Hadoop

00:38:36,760 --> 00:38:40,810
to streaming architectures now I have to

00:38:39,280 --> 00:38:43,420
learn how to write services that will

00:38:40,810 --> 00:38:47,140
live for months and you know resist

00:38:43,420 --> 00:38:48,580
network partitions and stuff ok last

00:38:47,140 --> 00:38:50,530
thing is one thing I think we need to

00:38:48,580 --> 00:38:52,090
still solve I'd love to see this solved

00:38:50,530 --> 00:38:54,730
sort of generically in the maysa world

00:38:52,090 --> 00:38:56,680
is like common mechanisms other than

00:38:54,730 --> 00:38:59,620
maybe zookeeper where I could have

00:38:56,680 --> 00:39:01,930
spadeful apps that can persist state in

00:38:59,620 --> 00:39:04,150
a globally available way so that if some

00:39:01,930 --> 00:39:06,700
of those processes go down I can easily

00:39:04,150 --> 00:39:08,980
reconstitute them and not lose where I

00:39:06,700 --> 00:39:11,230
was and right now like I said everybody

00:39:08,980 --> 00:39:14,950
sparked flink etc they all do it their

00:39:11,230 --> 00:39:19,420
own way or they don't do it at all ok

00:39:14,950 --> 00:39:25,410
that's it yeah any questions like

00:39:19,420 --> 00:39:25,410
where's the beer yeah

00:39:41,970 --> 00:39:47,380
so I'll repeat the question for the

00:39:44,050 --> 00:39:49,120
video if flank is so much better kind of

00:39:47,380 --> 00:39:50,920
the low latency stuff and the kind of

00:39:49,120 --> 00:39:54,040
sophisticated semantics why would I use

00:39:50,920 --> 00:39:57,070
spark I think it's a couple things one

00:39:54,040 --> 00:39:59,200
is I still think spark is probably your

00:39:57,070 --> 00:40:02,200
better choice for a lot of if you still

00:39:59,200 --> 00:40:03,640
need to do a lot of batch stuff and if

00:40:02,200 --> 00:40:05,250
you have an organization that's already

00:40:03,640 --> 00:40:08,920
bet on spark like maybe you have a

00:40:05,250 --> 00:40:10,390
shadow cluster Hadoop organization

00:40:08,920 --> 00:40:11,920
that's using spark it wouldn't make

00:40:10,390 --> 00:40:14,440
sense to use it and not everybody needs

00:40:11,920 --> 00:40:17,650
those semantics that I described you

00:40:14,440 --> 00:40:18,970
know briefly with fling yeah so I don't

00:40:17,650 --> 00:40:20,110
think anybody's going to use all four of

00:40:18,970 --> 00:40:21,430
these unless you're a really big

00:40:20,110 --> 00:40:22,990
organization where you're one of those

00:40:21,430 --> 00:40:25,060
places that uses everything in the world

00:40:22,990 --> 00:40:26,710
but that I think that's one of the

00:40:25,060 --> 00:40:28,300
challenges as people are going to see a

00:40:26,710 --> 00:40:30,190
lot of overlap in some of these tools

00:40:28,300 --> 00:40:32,200
and just kind of make an arbitrary or

00:40:30,190 --> 00:40:35,140
semi arbitrary choice between them and

00:40:32,200 --> 00:40:36,940
maybe have to like I'll use kafka

00:40:35,140 --> 00:40:38,740
streams and flink or I'll use akka

00:40:36,940 --> 00:40:49,480
streams and spark and but I won't use

00:40:38,740 --> 00:40:51,400
more than that kind of yeah yes the

00:40:49,480 --> 00:40:52,600
question is what about Samsa and there's

00:40:51,400 --> 00:40:54,190
some others you could throw in that I've

00:40:52,600 --> 00:40:58,030
heard about are people ask about like

00:40:54,190 --> 00:41:00,220
apex Apache apex and I think I think

00:40:58,030 --> 00:41:02,320
Samson's storm kind of fall into the

00:41:00,220 --> 00:41:05,350
same category for example of tools that

00:41:02,320 --> 00:41:07,990
kind of sort of were pioneers in the

00:41:05,350 --> 00:41:10,510
space but have kind of suffered a little

00:41:07,990 --> 00:41:12,220
bit from oh we kind of did that wrong we

00:41:10,510 --> 00:41:14,170
kind of did this wrong and now maybe we

00:41:12,220 --> 00:41:16,060
need to start over and you'll build the

00:41:14,170 --> 00:41:17,710
next generation so I think that they

00:41:16,060 --> 00:41:19,150
both kind of suffer from that a little

00:41:17,710 --> 00:41:20,530
bit although if you're a storm user you

00:41:19,150 --> 00:41:22,600
should really look at Twitter Herron

00:41:20,530 --> 00:41:25,750
which is like their complete rewrite of

00:41:22,600 --> 00:41:27,550
storm I can't say I've actually used

00:41:25,750 --> 00:41:28,990
Samsa but I think in general from what

00:41:27,550 --> 00:41:30,700
I've seen of it it sort of falls into

00:41:28,990 --> 00:41:33,160
that camp of this is a really good first

00:41:30,700 --> 00:41:35,610
generation but who probably need to move

00:41:33,160 --> 00:41:39,210
on to a second generation technology

00:41:35,610 --> 00:41:39,210
maybe time for one more

00:41:42,660 --> 00:41:49,580
okay thanks a lot

00:41:45,150 --> 00:41:49,580

YouTube URL: https://www.youtube.com/watch?v=OReDLTcd24k


