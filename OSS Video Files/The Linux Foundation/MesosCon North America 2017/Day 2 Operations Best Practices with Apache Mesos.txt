Title: Day 2 Operations Best Practices with Apache Mesos
Publication date: 2017-09-18
Playlist: MesosCon North America 2017
Description: 
	Day 2 Operations Best Practices with Apache Mesos - Janet Yu, SignalFx & Ben Lin, Mesosphere

Youâ€™ve got a Mesos cluster running, now what? Keeping up with a dynamic production environment requires an arsenal of flexible tools. Standing up the cluster is just the beginning. How do you know that the cluster is healthy and behaving as expected? What metrics should be measured to proactively discover inefficiencies and bottlenecks in the system? 

This is the realm of Day 2 Operations, the critical piece that keeps your applications humming and your pager silent. Common challenges that are faced in Day 2 Operations will be discussed, with a demo highlighting a fully integrated solution.

About 

Ben Lin
Mesosphere
Solutions Architect
SF
Ben Lin is the APAC Tech Lead for Mesosphere. Ben was one of the first Solutions Architects at Mesosphere and worked closely with customers on architecture design and enablement. He standardized and built out the Mesosphere consulting services portfolio. Prior to Mesosphere, Ben was a Principal Architect at VMware where he architected, implemented, and evangelized SDN (software defined networking) and cloud solutions (OpenStack). He has spoken at MesosCon Europe, VMWorld, VMWorld Europe, CTCC, and LISA conferences.


Janet Yu
SignalFx
Software Engineer
Websitehttps://signalfx.com/
Janet Yu works on the UI and REST API layers at SignalFx. Last year, she gave a lightning talk at MesosCon North America. Before that, she contributed to the OpenStack dashboard, networking, and cloud policy projects while at VMware. And before that, she was in the Junos Manageability/UI team at Juniper Networks. She earned her Computer Science degree at Stanford University.
Captions: 
	00:00:00,000 --> 00:00:05,879
Kahless we could start so next up is day

00:00:03,510 --> 00:00:07,649
two operations best practices and Janet

00:00:05,879 --> 00:00:13,429
from signal effects and been from the

00:00:07,649 --> 00:00:13,429
mesosphere cool thanks

00:00:15,920 --> 00:00:24,060
okay so we're doing do two operations

00:00:19,160 --> 00:00:26,130
the main impetus behind this is so so

00:00:24,060 --> 00:00:29,150
I'm primarily a customer facing role

00:00:26,130 --> 00:00:31,470
over the last year or so you notice that

00:00:29,150 --> 00:00:34,800
there's much more emphasis being placed

00:00:31,470 --> 00:00:37,320
on operations versus deployment and

00:00:34,800 --> 00:00:38,790
installation so that's a that's a great

00:00:37,320 --> 00:00:41,940
thing right that means that base is

00:00:38,790 --> 00:00:45,890
finally in a place where you know doing

00:00:41,940 --> 00:00:48,930
the the generic install is simple enough

00:00:45,890 --> 00:00:51,030
and depending on the the cut the the

00:00:48,930 --> 00:00:53,550
company's size right could be a small

00:00:51,030 --> 00:00:56,699
start-up you could be an enterprise you

00:00:53,550 --> 00:00:59,340
could be a service writer having a team

00:00:56,699 --> 00:01:01,949
ranging from one or two individuals to

00:00:59,340 --> 00:01:03,750
an entire DevOps team the the most

00:01:01,949 --> 00:01:06,090
common theme that we saw was you know

00:01:03,750 --> 00:01:09,450
people want simplified streamlined

00:01:06,090 --> 00:01:13,979
metrics pipelines so that's what we're

00:01:09,450 --> 00:01:16,259
gonna be talking about today so the

00:01:13,979 --> 00:01:19,110
agenda is we have a brief overview we're

00:01:16,259 --> 00:01:21,780
gonna talk about all the different

00:01:19,110 --> 00:01:24,330
categories of metrics and may shows and

00:01:21,780 --> 00:01:28,560
then we're gonna take a deeper dive at

00:01:24,330 --> 00:01:29,939
the metrics API actually got a live

00:01:28,560 --> 00:01:32,180
environment we're gonna have a demo

00:01:29,939 --> 00:01:35,100
where we run a script against the API

00:01:32,180 --> 00:01:36,540
pulling that information but most

00:01:35,100 --> 00:01:39,780
importantly we're gonna look at that

00:01:36,540 --> 00:01:42,090
data in a back-end monitoring system and

00:01:39,780 --> 00:01:44,610
we're going to interpret the data look

00:01:42,090 --> 00:01:46,170
at the different visualizations to give

00:01:44,610 --> 00:01:47,909
you guys some ideas on how you can build

00:01:46,170 --> 00:01:50,149
dashboards around what's meaningful to

00:01:47,909 --> 00:01:50,149
you

00:01:52,710 --> 00:01:56,430
so I've got a couple marketing slides

00:01:54,900 --> 00:01:59,670
here I'll zoom do these pretty quickly

00:01:56,430 --> 00:02:03,960
but generally for most companies it's

00:01:59,670 --> 00:02:06,240
all about data right so in most cases

00:02:03,960 --> 00:02:09,330
what they want is a single platform that

00:02:06,240 --> 00:02:12,510
runs on top of any infrastructure my

00:02:09,330 --> 00:02:15,150
cloud private cloud you name it and then

00:02:12,510 --> 00:02:18,209
this will connect with you know billions

00:02:15,150 --> 00:02:21,530
of different users and client devices as

00:02:18,209 --> 00:02:24,709
well as increasingly like IOT devices so

00:02:21,530 --> 00:02:28,050
one example is we were talking to a

00:02:24,709 --> 00:02:30,690
customer in Singapore they're actually

00:02:28,050 --> 00:02:34,709
running a project called smart city so

00:02:30,690 --> 00:02:35,790
things like schedules of buses down to

00:02:34,709 --> 00:02:37,410
the minute they want to be able to

00:02:35,790 --> 00:02:43,650
optimize and all that requires

00:02:37,410 --> 00:02:45,780
additional sensors and data this is

00:02:43,650 --> 00:02:48,120
largely led by the kind of developers

00:02:45,780 --> 00:02:49,739
right so we're transitioning from a

00:02:48,120 --> 00:02:52,620
model where we've got traditional

00:02:49,739 --> 00:02:56,239
enterprise applications so these are

00:02:52,620 --> 00:03:00,299
monolithic applications single codebase

00:02:56,239 --> 00:03:03,180
very kind of brittle and then they're

00:03:00,299 --> 00:03:04,049
persisted into like relational databases

00:03:03,180 --> 00:03:07,700
on the backend

00:03:04,049 --> 00:03:10,500
you've got like Oracle sequel server

00:03:07,700 --> 00:03:13,140
into more clouding of application so I

00:03:10,500 --> 00:03:16,140
see these are micro services using kind

00:03:13,140 --> 00:03:19,250
of stateless applications running in

00:03:16,140 --> 00:03:23,070
containers that are lightweight flexible

00:03:19,250 --> 00:03:26,820
modular communicating over restful api s

00:03:23,070 --> 00:03:29,519
and then increasingly you know companies

00:03:26,820 --> 00:03:32,640
are adopting all the latest open source

00:03:29,519 --> 00:03:36,890
technologies so SPARC Kafka Cassandra

00:03:32,640 --> 00:03:36,890
fleeing tensorflow so on and so forth

00:03:37,400 --> 00:03:45,510
and then the second thing is apart from

00:03:43,140 --> 00:03:48,420
kind of micro services customers want to

00:03:45,510 --> 00:03:50,760
build out data pipelines right so this

00:03:48,420 --> 00:03:52,380
involves ingesting data from all these

00:03:50,760 --> 00:03:56,209
different sources into something like

00:03:52,380 --> 00:04:00,239
Kafka and then persisting that into say

00:03:56,209 --> 00:04:04,290
Cassandra or HDFS running analytics on

00:04:00,239 --> 00:04:05,790
it using spark or flink and then writing

00:04:04,290 --> 00:04:08,970
applications that act

00:04:05,790 --> 00:04:11,700
on that particular set of data all right

00:04:08,970 --> 00:04:14,549
so the thing to note here is that these

00:04:11,700 --> 00:04:17,609
are all very complex distributed systems

00:04:14,549 --> 00:04:19,560
for the most part and each of these has

00:04:17,609 --> 00:04:22,229
metrics that operators need to be aware

00:04:19,560 --> 00:04:24,210
of right so the goal is really to paint

00:04:22,229 --> 00:04:25,919
a picture of this holistic view of

00:04:24,210 --> 00:04:34,710
everything that's running in this

00:04:25,919 --> 00:04:37,430
particular environment now for operators

00:04:34,710 --> 00:04:39,810
that are looking at applications we

00:04:37,430 --> 00:04:41,190
talked a bunch of customers these are

00:04:39,810 --> 00:04:41,789
some of the common challenges that they

00:04:41,190 --> 00:04:44,780
face

00:04:41,789 --> 00:04:50,970
scalable capacity dynamic architecture

00:04:44,780 --> 00:04:55,229
load balancing what is scalable capacity

00:04:50,970 --> 00:04:57,110
so this refers to when you're you have

00:04:55,229 --> 00:05:00,240
an application the application is

00:04:57,110 --> 00:05:03,360
elastic it's ephemeral it may scale up

00:05:00,240 --> 00:05:06,120
and down we need to know based on the

00:05:03,360 --> 00:05:08,880
characteristics of application when we

00:05:06,120 --> 00:05:10,919
need to add additional computer or

00:05:08,880 --> 00:05:13,260
networking infrastructure right so

00:05:10,919 --> 00:05:14,789
that's identifying what's important

00:05:13,260 --> 00:05:20,610
relative to the application and then

00:05:14,789 --> 00:05:22,560
scaling it up and down dynamic

00:05:20,610 --> 00:05:25,110
architectures this means that so now we

00:05:22,560 --> 00:05:27,690
have this new kind of developing

00:05:25,110 --> 00:05:29,460
developer pattern where we've got these

00:05:27,690 --> 00:05:32,039
modular services that talk to each other

00:05:29,460 --> 00:05:35,030
right and the nice thing about that is

00:05:32,039 --> 00:05:37,199
you can swap out services right you can

00:05:35,030 --> 00:05:40,199
exchange one component of your

00:05:37,199 --> 00:05:43,260
application kind of do a Bluegreen

00:05:40,199 --> 00:05:47,610
deploy or whatever but the idea here is

00:05:43,260 --> 00:05:50,490
that each application is now a set of

00:05:47,610 --> 00:05:52,409
constituent services right so instead of

00:05:50,490 --> 00:05:54,810
just monitoring for a single process

00:05:52,409 --> 00:05:57,810
that's running on a particular operating

00:05:54,810 --> 00:06:00,240
system now we might have you know tens

00:05:57,810 --> 00:06:03,360
or hundreds of different applications

00:06:00,240 --> 00:06:05,310
each of which has its own tasks right it

00:06:03,360 --> 00:06:07,260
could be bunches of tasks for

00:06:05,310 --> 00:06:08,669
application so we need to understand

00:06:07,260 --> 00:06:11,479
what that looks like and how to measure

00:06:08,669 --> 00:06:11,479
that moving forward

00:06:13,479 --> 00:06:17,110
and then load-balancing this is pretty

00:06:15,129 --> 00:06:18,370
straightforward so if all this says is

00:06:17,110 --> 00:06:21,219
you have an application it might have

00:06:18,370 --> 00:06:23,889
one or more instances typically using

00:06:21,219 --> 00:06:27,039
either east-west load balancer or some

00:06:23,889 --> 00:06:30,430
other load balancer like a TLB or maybe

00:06:27,039 --> 00:06:32,469
an f5 sitting in front how do you make

00:06:30,430 --> 00:06:34,569
sure that the load balancing algorithm

00:06:32,469 --> 00:06:42,099
is performing properly over time right

00:06:34,569 --> 00:06:44,770
so so next we're going to look at

00:06:42,099 --> 00:06:45,879
metrics right so metrics are just you

00:06:44,770 --> 00:06:47,800
know characteristics perform

00:06:45,879 --> 00:06:50,169
measurements that are used to determine

00:06:47,800 --> 00:06:51,099
the health and performance of the system

00:06:50,169 --> 00:06:53,889
right

00:06:51,099 --> 00:06:56,499
how is my cluster doing how is it

00:06:53,889 --> 00:06:58,740
performing over time do I have any

00:06:56,499 --> 00:07:01,330
specific issues with my infrastructure

00:06:58,740 --> 00:07:03,219
right how many leading how many masters

00:07:01,330 --> 00:07:06,639
do I have up is the leading master

00:07:03,219 --> 00:07:07,689
changing periodically and then most

00:07:06,639 --> 00:07:10,360
importantly it's really about the

00:07:07,689 --> 00:07:12,069
application performance right so part of

00:07:10,360 --> 00:07:14,349
the challenge previously is how do I get

00:07:12,069 --> 00:07:16,149
the application metrics from the

00:07:14,349 --> 00:07:21,339
container running in my maysa

00:07:16,149 --> 00:07:24,029
environment we're primarily gonna be

00:07:21,339 --> 00:07:27,039
covering the first two categories so

00:07:24,029 --> 00:07:32,080
infrastructure that CPU memory disk as

00:07:27,039 --> 00:07:35,129
well as the application metrics but you

00:07:32,080 --> 00:07:39,399
can also capture things like users

00:07:35,129 --> 00:07:41,669
things like login and usage for use

00:07:39,399 --> 00:07:43,419
cases such as chargeback right so

00:07:41,669 --> 00:07:47,229
increasingly we're seeing more more

00:07:43,419 --> 00:07:49,689
customers want wanting multi-tenancy out

00:07:47,229 --> 00:07:51,789
of their maysa environments so charge

00:07:49,689 --> 00:07:54,039
rack is going to be key for being able

00:07:51,789 --> 00:07:57,240
to understand these different

00:07:54,039 --> 00:07:59,680
characteristics as far as how much

00:07:57,240 --> 00:08:05,289
resources each individual group is

00:07:59,680 --> 00:08:09,189
consuming okay who's seen this diagram

00:08:05,289 --> 00:08:12,639
before so this is like the the canonical

00:08:09,189 --> 00:08:14,409
mesas architectural diagram again the

00:08:12,639 --> 00:08:16,240
goal is to reinforce the fact that

00:08:14,409 --> 00:08:19,599
there's different sources for all these

00:08:16,240 --> 00:08:22,419
different metrics so from zookeeper to

00:08:19,599 --> 00:08:24,310
the mesas Masters to the agents to the

00:08:22,419 --> 00:08:26,650
frameworks that are running on top

00:08:24,310 --> 00:08:29,110
the Macy's environment which our

00:08:26,650 --> 00:08:31,840
scheduling tasks right and then down to

00:08:29,110 --> 00:08:34,289
the executives who are running the

00:08:31,840 --> 00:08:34,289
actual task

00:08:41,780 --> 00:08:47,480
so that the the metric source is right

00:08:44,150 --> 00:08:49,370
so we have the the basis metrics we also

00:08:47,480 --> 00:08:51,560
have container metrics so these are more

00:08:49,370 --> 00:08:53,840
or less OS level metrics that we capture

00:08:51,560 --> 00:08:55,010
and then for the application what's

00:08:53,840 --> 00:08:58,160
really interesting is things like

00:08:55,010 --> 00:09:06,190
request for seconds latency you know

00:08:58,160 --> 00:09:09,110
active users response time so for the

00:09:06,190 --> 00:09:10,610
masters the agents and for marathon each

00:09:09,110 --> 00:09:12,770
of these has their own kind of metrics

00:09:10,610 --> 00:09:15,050
endpoint and that's what we use to

00:09:12,770 --> 00:09:18,830
capture the information and funnel it to

00:09:15,050 --> 00:09:20,780
our back-end system so I won't go

00:09:18,830 --> 00:09:23,240
through these in detail you can actually

00:09:20,780 --> 00:09:26,600
ask Janet to show off a couple

00:09:23,240 --> 00:09:33,170
dashboards that she built to kind of

00:09:26,600 --> 00:09:34,720
convey the same information so we're

00:09:33,170 --> 00:09:36,680
gonna take a quick look at this

00:09:34,720 --> 00:09:39,620
observability metrics page from the

00:09:36,680 --> 00:09:40,970
mezzos documentation it details all the

00:09:39,620 --> 00:09:42,380
metrics you can get from the different

00:09:40,970 --> 00:09:45,860
resource that it's like the master knows

00:09:42,380 --> 00:09:49,040
the agents frameworks applicators etc so

00:09:45,860 --> 00:09:51,680
lots and lots of data coming in it also

00:09:49,040 --> 00:09:52,880
outlines some recommendations for things

00:09:51,680 --> 00:09:55,339
you want to look out for in your cluster

00:09:52,880 --> 00:09:55,700
to know if it's performing normally or

00:09:55,339 --> 00:09:58,580
not

00:09:55,700 --> 00:10:01,160
so using that information we I built I

00:09:58,580 --> 00:10:03,380
collect a plugin that will grab metrics

00:10:01,160 --> 00:10:05,870
from the master in agent nodes and then

00:10:03,380 --> 00:10:08,690
send them off to our monitoring app and

00:10:05,870 --> 00:10:12,440
then here's one of the dashboards for

00:10:08,690 --> 00:10:14,380
that so it's the problem indicators on

00:10:12,440 --> 00:10:17,000
the side um further charts we use

00:10:14,380 --> 00:10:20,570
digraphs and d3 that javascript

00:10:17,000 --> 00:10:22,520
libraries to build these charts so this

00:10:20,570 --> 00:10:25,670
first chart here on the Left cluster

00:10:22,520 --> 00:10:28,070
health it gives us an idea of whether or

00:10:25,670 --> 00:10:30,350
not the agents are performing normally

00:10:28,070 --> 00:10:32,290
taking a look into that chart we're

00:10:30,350 --> 00:10:35,030
using the agents connected metric

00:10:32,290 --> 00:10:36,890
comparing that with the active one and

00:10:35,030 --> 00:10:39,020
then seeing what that ratio is so

00:10:36,890 --> 00:10:42,530
luckily for us our percentage is 100%

00:10:39,020 --> 00:10:43,670
but if we wanted to know if it's

00:10:42,530 --> 00:10:45,740
performing less than a hundred percent

00:10:43,670 --> 00:10:48,470
we've got these rules set up to notify

00:10:45,740 --> 00:10:50,060
ourselves if it's within certain ranges

00:10:48,470 --> 00:10:52,330
House of your made up right the problem

00:10:50,060 --> 00:10:52,330
be

00:10:52,970 --> 00:10:56,720
I'm back to the dashboard another

00:10:54,740 --> 00:10:58,910
example a number of leading active

00:10:56,720 --> 00:11:01,310
masters you want that to be one right

00:10:58,910 --> 00:11:05,089
too many masters not good too few also

00:11:01,310 --> 00:11:07,069
not good so we got this one that sums up

00:11:05,089 --> 00:11:10,990
how many are being reported is being

00:11:07,069 --> 00:11:14,509
active as well as master uptime

00:11:10,990 --> 00:11:16,879
something for that when we look out for

00:11:14,509 --> 00:11:20,329
it is if it's below the recommend value

00:11:16,879 --> 00:11:24,519
of five minutes or if it's below a

00:11:20,329 --> 00:11:26,720
minute for some duration of time that's

00:11:24,519 --> 00:11:28,430
indicative that it may be flopping so

00:11:26,720 --> 00:11:32,230
we'll notify ourselves if that's a

00:11:28,430 --> 00:11:35,839
problem so Jen I have a question for you

00:11:32,230 --> 00:11:37,370
totally unrehearsed so when you're

00:11:35,839 --> 00:11:40,040
actually building these dashboards can

00:11:37,370 --> 00:11:43,389
you talk about kind of how you decide

00:11:40,040 --> 00:11:45,949
what the bubble up you know based on the

00:11:43,389 --> 00:11:49,910
requirements or whatever like what what

00:11:45,949 --> 00:11:52,610
what's important to actually convey on

00:11:49,910 --> 00:11:54,889
these screens that's a great question so

00:11:52,610 --> 00:11:56,420
from users we talked to you people are

00:11:54,889 --> 00:11:58,550
interested in knowing if our my tasks

00:11:56,420 --> 00:12:00,370
running is my workload being handled and

00:11:58,550 --> 00:12:03,430
if not what is the thing that's causing

00:12:00,370 --> 00:12:05,870
preventing that from happening so we

00:12:03,430 --> 00:12:08,089
organize our information mostly around

00:12:05,870 --> 00:12:10,399
the infrastructure so like the CPU does

00:12:08,089 --> 00:12:11,899
memory as well as what's going on with

00:12:10,399 --> 00:12:14,779
the task like what is the throughput of

00:12:11,899 --> 00:12:16,850
that so if we want to drill down further

00:12:14,779 --> 00:12:18,769
we have a dashboard with the clusters

00:12:16,850 --> 00:12:23,180
overview so this shows me all my

00:12:18,769 --> 00:12:26,740
clusters what's going on in them my CPU

00:12:23,180 --> 00:12:29,870
memory something maybe interesting is

00:12:26,740 --> 00:12:31,519
the number of tasks running so in blue

00:12:29,870 --> 00:12:33,500
here we have how many are running

00:12:31,519 --> 00:12:35,720
currently and then we compare that with

00:12:33,500 --> 00:12:37,790
this red dotted line of the week over

00:12:35,720 --> 00:12:39,829
week growth so looking at past data

00:12:37,790 --> 00:12:41,930
comparing it with the current data if

00:12:39,829 --> 00:12:43,550
your growth is continually increasing

00:12:41,930 --> 00:12:46,550
you may need for capacity to it to

00:12:43,550 --> 00:12:49,309
handle your workloads so going further

00:12:46,550 --> 00:12:51,589
down we have another dashboard of a

00:12:49,309 --> 00:12:53,540
specific cluster what's what are the

00:12:51,589 --> 00:12:57,559
tasks running in that what is the CPU

00:12:53,540 --> 00:13:00,980
memory usage look like should let me go

00:12:57,559 --> 00:13:04,100
back one to here for the overall cluster

00:13:00,980 --> 00:13:04,830
see uh something we commonly use is

00:13:04,100 --> 00:13:06,720
comparing

00:13:04,830 --> 00:13:10,560
and titles so in this chart we have the

00:13:06,720 --> 00:13:12,030
CPU percentiles over all of our hosts so

00:13:10,560 --> 00:13:13,650
there's something running in here that's

00:13:12,030 --> 00:13:16,230
taking a hundred percent that's the max

00:13:13,650 --> 00:13:20,130
value as well as the p90 whereas the

00:13:16,230 --> 00:13:22,560
median or P 50 is only around 33 so here

00:13:20,130 --> 00:13:24,270
this other chart that sorts all the

00:13:22,560 --> 00:13:26,040
hosts by their CPU usage and we can see

00:13:24,270 --> 00:13:28,260
that the top two take one hundred

00:13:26,040 --> 00:13:29,970
percent so maybe we want to log into

00:13:28,260 --> 00:13:31,500
those instances and see what's going on

00:13:29,970 --> 00:13:33,810
if that's something we're not expecting

00:13:31,500 --> 00:13:34,910
to happen with the current expected

00:13:33,810 --> 00:13:38,910
workload

00:13:34,910 --> 00:13:42,450
alright so cluster detail per node we

00:13:38,910 --> 00:13:43,830
have the master node view so how many

00:13:42,450 --> 00:13:47,730
tests are running on that specific

00:13:43,830 --> 00:13:51,420
master node the uptime frameworks tasks

00:13:47,730 --> 00:13:53,550
running and then similarly for the agent

00:13:51,420 --> 00:13:56,490
tasks uptime

00:13:53,550 --> 00:14:01,820
yep so we're gonna search it back to

00:13:56,490 --> 00:14:01,820
slides give it back to them

00:14:04,810 --> 00:14:09,889
okay so thanks yeah night so I'm not

00:14:08,779 --> 00:14:12,259
gonna go through all these but again

00:14:09,889 --> 00:14:15,709
it's examples where you can look at

00:14:12,259 --> 00:14:18,290
particular metrics and then based on the

00:14:15,709 --> 00:14:21,019
current value understand what's

00:14:18,290 --> 00:14:22,550
happening with your cluster right so for

00:14:21,019 --> 00:14:24,680
instance if your uptime for the master

00:14:22,550 --> 00:14:28,190
is low obviously you know the Masters we

00:14:24,680 --> 00:14:30,790
started and then if your number of

00:14:28,190 --> 00:14:32,389
elected masters is zero right then

00:14:30,790 --> 00:14:38,750
obviously there's something wrong with

00:14:32,389 --> 00:14:40,519
your cluster okay so that's from a Mesa

00:14:38,750 --> 00:14:44,089
standpoint next we're gonna look at

00:14:40,519 --> 00:14:47,019
container level metrics so traditionally

00:14:44,089 --> 00:14:48,920
what do we do for like traditional apps

00:14:47,019 --> 00:14:52,100
typically you'll have your application

00:14:48,920 --> 00:14:55,040
running you might have a specific agent

00:14:52,100 --> 00:14:58,130
that pulls metrics from that particular

00:14:55,040 --> 00:14:59,899
application but when we move to a

00:14:58,130 --> 00:15:02,089
containerized world sure you can still

00:14:59,899 --> 00:15:05,300
do this with pods right just have a

00:15:02,089 --> 00:15:08,269
sidecar container pull metrics from the

00:15:05,300 --> 00:15:09,740
the primary container but the problem

00:15:08,269 --> 00:15:13,250
that we found here was that this

00:15:09,740 --> 00:15:17,740
approach isn't very scalable right and

00:15:13,250 --> 00:15:17,740
it's kind of unnecessary footprint so

00:15:17,920 --> 00:15:24,709
what we did is we both this metrics

00:15:21,259 --> 00:15:26,569
module for me says right so the great

00:15:24,709 --> 00:15:28,310
the United does here is you get

00:15:26,569 --> 00:15:31,130
basically the application metrics for

00:15:28,310 --> 00:15:33,639
free right the metrics module is bundled

00:15:31,130 --> 00:15:36,769
in with the agent as an isolator and

00:15:33,639 --> 00:15:39,790
when the maysa container Iser brings up

00:15:36,769 --> 00:15:42,410
the container it will expose these two

00:15:39,790 --> 00:15:45,829
environmental variables stats the UDP

00:15:42,410 --> 00:15:48,170
host stats the UDP port so as a

00:15:45,829 --> 00:15:50,630
developer all I need to do is write to

00:15:48,170 --> 00:15:52,519
those environmental variables and the

00:15:50,630 --> 00:15:54,589
metrics module will capture that

00:15:52,519 --> 00:15:56,899
information and then it's also going to

00:15:54,589 --> 00:16:00,769
tag it with context all right so that's

00:15:56,899 --> 00:16:02,959
the second thing is understanding the

00:16:00,769 --> 00:16:04,399
context surrounding those metrics so you

00:16:02,959 --> 00:16:06,350
have things like container ID you have

00:16:04,399 --> 00:16:07,759
things like agent ID and it allows you

00:16:06,350 --> 00:16:09,970
to filter through all these metrics very

00:16:07,759 --> 00:16:09,970
easily

00:16:13,500 --> 00:16:20,050
so this is the general architecture as

00:16:16,330 --> 00:16:23,650
you see here we have a set of hosts each

00:16:20,050 --> 00:16:26,589
of these house has your mesas agent with

00:16:23,650 --> 00:16:29,920
the metrics module we have containers

00:16:26,589 --> 00:16:31,870
one two and three right and we have

00:16:29,920 --> 00:16:36,040
applications that are writing to those

00:16:31,870 --> 00:16:38,380
environmental variables so those are

00:16:36,040 --> 00:16:41,140
sent to the metrics module the metrics

00:16:38,380 --> 00:16:43,450
module will then afford them to the

00:16:41,140 --> 00:16:46,450
collector which is a systemd unit that

00:16:43,450 --> 00:16:49,930
runs on every single host the collector

00:16:46,450 --> 00:16:53,350
is also collecting stats from the

00:16:49,930 --> 00:16:55,120
operating system as well and then we're

00:16:53,350 --> 00:16:58,890
exposing a metrics API which you'll see

00:16:55,120 --> 00:17:01,570
shortly this allows you to easily pull

00:16:58,890 --> 00:17:04,329
the API grab that information and send

00:17:01,570 --> 00:17:12,400
it off to whatever back-end of your

00:17:04,329 --> 00:17:13,780
choice I'll quickly show the environment

00:17:12,400 --> 00:17:20,650
that we have here so we spun up an

00:17:13,780 --> 00:17:23,470
environment on AWS we have total of

00:17:20,650 --> 00:17:27,699
eight nodes so seven private agents one

00:17:23,470 --> 00:17:29,530
public agent and then we've got a

00:17:27,699 --> 00:17:32,950
variety of different services so we have

00:17:29,530 --> 00:17:35,230
Cassandra Kafka kubernetes and then we

00:17:32,950 --> 00:17:38,590
have a marathon app so this app all it

00:17:35,230 --> 00:17:41,950
really does is it emits stats the so

00:17:38,590 --> 00:17:47,170
you'll see that as part of the demo

00:17:41,950 --> 00:17:49,840
later on okay so I'm going to turn over

00:17:47,170 --> 00:17:52,410
to Janet who's going to talk about the

00:17:49,840 --> 00:17:52,410
API

00:17:57,340 --> 00:18:03,020
so using the metrics API we can get

00:18:00,950 --> 00:18:05,000
information about the cluster it's like

00:18:03,020 --> 00:18:07,820
about the hosts containers applications

00:18:05,000 --> 00:18:11,660
and this is a collection of basically

00:18:07,820 --> 00:18:13,910
get requests you can make to pull from

00:18:11,660 --> 00:18:16,610
information so here's an example it's

00:18:13,910 --> 00:18:18,800
getting metrics from in a specific agent

00:18:16,610 --> 00:18:20,960
using the agent ID and then at some

00:18:18,800 --> 00:18:23,270
resource path and then takes two headers

00:18:20,960 --> 00:18:27,350
of the accept header for the response

00:18:23,270 --> 00:18:28,340
type and then an authorization token and

00:18:27,350 --> 00:18:30,620
your response is gonna look something

00:18:28,340 --> 00:18:34,490
like this you'll get a list of data

00:18:30,620 --> 00:18:36,110
points that come back and then an object

00:18:34,490 --> 00:18:38,450
of dimension properties so I'm gonna go

00:18:36,110 --> 00:18:42,140
into detail now about what these data

00:18:38,450 --> 00:18:44,750
points and dimensions are so a data

00:18:42,140 --> 00:18:46,880
point is a single value you'll get for a

00:18:44,750 --> 00:18:49,670
specific metric from a specific source

00:18:46,880 --> 00:18:51,560
at a specific point in time right so

00:18:49,670 --> 00:18:53,390
there's there's a few attributes that

00:18:51,560 --> 00:18:55,730
are inside that unipoint first three

00:18:53,390 --> 00:18:57,770
hopefully are self-explanatory metric

00:18:55,730 --> 00:18:59,060
name the metric value and the time stamp

00:18:57,770 --> 00:19:01,160
in which you were getting that data

00:18:59,060 --> 00:19:06,140
point and then there's metric type and

00:19:01,160 --> 00:19:09,140
dimensions so meses exposes two types of

00:19:06,140 --> 00:19:10,370
metric types there's counters so like it

00:19:09,140 --> 00:19:13,430
sounds at the count or something

00:19:10,370 --> 00:19:14,960
happening it's increasing in value so

00:19:13,430 --> 00:19:18,500
like the number of successful tasks

00:19:14,960 --> 00:19:20,660
number of failed house number of agent

00:19:18,500 --> 00:19:22,850
restorations in comparison there's

00:19:20,660 --> 00:19:25,220
gauges which is a value that could

00:19:22,850 --> 00:19:26,090
increase or decrease over time and then

00:19:25,220 --> 00:19:28,520
you're it's like you're getting a

00:19:26,090 --> 00:19:31,520
snapshot of the value at a specific

00:19:28,520 --> 00:19:33,740
point so it's something like the current

00:19:31,520 --> 00:19:36,200
memory usage in a cluster or the current

00:19:33,740 --> 00:19:41,120
disk space being used or a number of

00:19:36,200 --> 00:19:43,250
connected agents and dimensions are key

00:19:41,120 --> 00:19:46,810
value pairs that describe the source of

00:19:43,250 --> 00:19:50,780
your metrics so it's a one set of unique

00:19:46,810 --> 00:19:52,160
unique set of dimensions will tell you a

00:19:50,780 --> 00:19:54,890
little bit of information like the host

00:19:52,160 --> 00:19:56,960
or let's say the region that DS and

00:19:54,890 --> 00:19:58,640
values are coming in from and with these

00:19:56,960 --> 00:20:00,590
dimensions you can help correlate your

00:19:58,640 --> 00:20:02,360
data points so you don't just have your

00:20:00,590 --> 00:20:05,090
random values you can actually link them

00:20:02,360 --> 00:20:05,420
together into a lot of patterns and I

00:20:05,090 --> 00:20:08,270
don't

00:20:05,420 --> 00:20:11,300
trends over time and what the dimensions

00:20:08,270 --> 00:20:13,250
you can classify your data it helps you

00:20:11,300 --> 00:20:15,140
aggregate and group them do some

00:20:13,250 --> 00:20:16,850
filtering so it's a way to manage your

00:20:15,140 --> 00:20:21,860
data so you don't just have like a

00:20:16,850 --> 00:20:23,690
random collection of numbers here's the

00:20:21,860 --> 00:20:26,120
site at comparing the metrics versus

00:20:23,690 --> 00:20:28,190
dimensions so examples of metrics are

00:20:26,120 --> 00:20:30,560
like we've seen like CPU idle disk

00:20:28,190 --> 00:20:33,410
operations load versus dimensions are

00:20:30,560 --> 00:20:34,610
descriptions of the sources so like the

00:20:33,410 --> 00:20:38,630
data center of our region we can

00:20:34,610 --> 00:20:40,400
mentioned and when you come when you

00:20:38,630 --> 00:20:42,650
combine them you can make a time series

00:20:40,400 --> 00:20:47,570
so the data points and dimensions define

00:20:42,650 --> 00:20:49,130
a pattern or a plot line you can

00:20:47,570 --> 00:20:51,590
actually put it into a chart and look at

00:20:49,130 --> 00:20:54,230
your data in a more cohesive manner so

00:20:51,590 --> 00:20:56,450
like in Figure 1 we have CPU idle one

00:20:54,230 --> 00:20:59,030
plot of that so that's one set of data

00:20:56,450 --> 00:21:01,400
points coming from one source versus in

00:20:59,030 --> 00:21:03,770
figure 2 we have two different plots

00:21:01,400 --> 00:21:05,030
because we have one that's in the data

00:21:03,770 --> 00:21:06,920
center in the east and then one coming

00:21:05,030 --> 00:21:08,330
from a data center in the West so when

00:21:06,920 --> 00:21:10,640
you plot them together we can compare

00:21:08,330 --> 00:21:15,740
them based on their dimensions and do

00:21:10,640 --> 00:21:17,450
groupings and whatnot so while using the

00:21:15,740 --> 00:21:20,030
new metrics API a few things I noted

00:21:17,450 --> 00:21:22,910
that may be useful if you're using it to

00:21:20,030 --> 00:21:24,650
know one thing is you can get an

00:21:22,910 --> 00:21:27,080
authentication token using this post

00:21:24,650 --> 00:21:28,760
request so off login get to you that

00:21:27,080 --> 00:21:30,650
token and you'll send with every get

00:21:28,760 --> 00:21:34,880
request you make following that first

00:21:30,650 --> 00:21:36,890
request the time stamp or the data

00:21:34,880 --> 00:21:39,620
points that come back may vary in format

00:21:36,890 --> 00:21:41,060
so if you're trying to parse that time

00:21:39,620 --> 00:21:43,180
stamp out you want to look out for

00:21:41,060 --> 00:21:46,370
longer strings or so shorter strings

00:21:43,180 --> 00:21:49,100
another thing to check is the data point

00:21:46,370 --> 00:21:50,300
value so it should be a number typically

00:21:49,100 --> 00:21:52,670
because that's what you're gonna that's

00:21:50,300 --> 00:21:55,280
what you'll plot on charts and compare

00:21:52,670 --> 00:21:57,080
against each other but for example in

00:21:55,280 --> 00:22:01,940
this data point we got back the value

00:21:57,080 --> 00:22:03,350
was not a number and then in general for

00:22:01,940 --> 00:22:05,560
sending metrics like if you're making

00:22:03,350 --> 00:22:09,080
your own metrics and sending the custom

00:22:05,560 --> 00:22:09,920
custom values sometimes for that you may

00:22:09,080 --> 00:22:11,420
want to structure your names

00:22:09,920 --> 00:22:14,120
hierarchically just but a way to

00:22:11,420 --> 00:22:15,490
organize your metrics and within those

00:22:14,120 --> 00:22:18,760
names use a consistent

00:22:15,490 --> 00:22:21,490
like a period or - which could help with

00:22:18,760 --> 00:22:24,040
wildcard searches also if you're using

00:22:21,490 --> 00:22:26,320
dimensions on your metrics you don't

00:22:24,040 --> 00:22:27,670
need to put that same information in the

00:22:26,320 --> 00:22:28,900
metric name it just kind of clutters

00:22:27,670 --> 00:22:32,679
then makes it longer than you really

00:22:28,900 --> 00:22:36,460
need it to be one thing we see that our

00:22:32,679 --> 00:22:38,170
user is doing that really helps what

00:22:36,460 --> 00:22:40,090
works against managing their data is

00:22:38,170 --> 00:22:42,460
using dimensions with high cardinality

00:22:40,090 --> 00:22:45,730
so something like timestamps or really

00:22:42,460 --> 00:22:46,929
long error messages or IDs that are only

00:22:45,730 --> 00:22:50,800
used for a very brief amount of time

00:22:46,929 --> 00:22:52,690
those kind of things will not well you

00:22:50,800 --> 00:22:54,580
won't be able to use them to organize to

00:22:52,690 --> 00:22:56,830
group and how great your data because

00:22:54,580 --> 00:22:57,210
it's always changing there's it's not

00:22:56,830 --> 00:22:59,500
gonna

00:22:57,210 --> 00:23:03,010
there's not not gonna be a way to link

00:22:59,500 --> 00:23:07,900
your data together with values that keep

00:23:03,010 --> 00:23:10,990
varying very frequently so just want to

00:23:07,900 --> 00:23:14,559
show how we send the data to our app we

00:23:10,990 --> 00:23:17,650
send post requests to this URL with the

00:23:14,559 --> 00:23:18,850
content type token and then lists of the

00:23:17,650 --> 00:23:22,480
different metrics that we have the

00:23:18,850 --> 00:23:26,860
gauges the counters so I'm gonna just

00:23:22,480 --> 00:23:28,780
show that script that we have that gets

00:23:26,860 --> 00:23:32,800
metrics from our you saw us cluster and

00:23:28,780 --> 00:23:34,120
then sends it off to our app so using

00:23:32,800 --> 00:23:36,929
that cluster that Ben had showed earlier

00:23:34,120 --> 00:23:39,429
we're gonna kick off the script it will

00:23:36,929 --> 00:23:41,740
do the login and then send all these get

00:23:39,429 --> 00:23:43,840
requests to the cluster every 10 seconds

00:23:41,740 --> 00:23:45,160
to get everything about our different

00:23:43,840 --> 00:23:51,480
nodes our containers and our apps

00:23:45,160 --> 00:23:53,320
running in it so while that is fillion

00:23:51,480 --> 00:23:56,260
into these charts that I had built

00:23:53,320 --> 00:24:02,080
before we can take a quick look at the

00:23:56,260 --> 00:24:04,480
script so it just loops over making

00:24:02,080 --> 00:24:05,020
these requests we get the host from the

00:24:04,480 --> 00:24:09,160
master

00:24:05,020 --> 00:24:12,100
so master URL here and then for each

00:24:09,160 --> 00:24:14,160
host get metrics about that get the

00:24:12,100 --> 00:24:16,300
containers inside that hosts the

00:24:14,160 --> 00:24:18,670
information about the containers and

00:24:16,300 --> 00:24:20,640
then get all the information about the

00:24:18,670 --> 00:24:22,750
apps running in those containers so it's

00:24:20,640 --> 00:24:24,730
just gathering all this information up

00:24:22,750 --> 00:24:26,679
and then sending them off into something

00:24:24,730 --> 00:24:27,080
we can use to take a look at that data a

00:24:26,679 --> 00:24:30,860
little bit

00:24:27,080 --> 00:24:35,210
more easily so it looks like that's

00:24:30,860 --> 00:24:37,429
still going on something I did to help

00:24:35,210 --> 00:24:39,259
myself find what's being sent in is I

00:24:37,429 --> 00:24:45,259
added a dimension for the source so I

00:24:39,259 --> 00:24:46,429
have this source the DCOs metrics where

00:24:45,259 --> 00:24:47,869
I could search for it and then it shows

00:24:46,429 --> 00:24:49,580
me all the matching ones that I have and

00:24:47,869 --> 00:24:51,289
then I built some charts that I thought

00:24:49,580 --> 00:24:56,690
might be useful for myself to figure out

00:24:51,289 --> 00:24:58,909
what's going on in a cluster see stuff

00:24:56,690 --> 00:25:02,169
coming in yet maybe slow

00:24:58,909 --> 00:25:04,809
let me network but let's take a look at

00:25:02,169 --> 00:25:10,149
some data we had collected in the past

00:25:04,809 --> 00:25:13,789
so here's a 3-hour chunk that we had

00:25:10,149 --> 00:25:14,960
collecting the metrics we'll take a

00:25:13,789 --> 00:25:18,230
little closer look at that container

00:25:14,960 --> 00:25:20,359
bytes or saved one so it has this

00:25:18,230 --> 00:25:22,609
message here about there being too much

00:25:20,359 --> 00:25:25,179
data to show within what but real estate

00:25:22,609 --> 00:25:27,289
I have on my screen so I had mentioned

00:25:25,179 --> 00:25:30,759
several times we can use dimensions to

00:25:27,289 --> 00:25:33,789
help us filter out this data so we can

00:25:30,759 --> 00:25:36,649
get a closer look maybe by host name

00:25:33,789 --> 00:25:42,289
maybe I only want to know the ones

00:25:36,649 --> 00:25:43,549
coming from here so we get a little bit

00:25:42,289 --> 00:25:47,749
less a there that fits more into the

00:25:43,549 --> 00:25:51,109
chart name is ooh min for time timespan

00:25:47,749 --> 00:25:59,230
I can also maybe some my host name so

00:25:51,109 --> 00:26:03,379
then each bar will show me by host what

00:25:59,230 --> 00:26:06,919
is going on so let me take off the host

00:26:03,379 --> 00:26:10,480
filter which I got there so we have or

00:26:06,919 --> 00:26:14,359
to house mainly doing most of the work

00:26:10,480 --> 00:26:16,249
what's going on in there and then

00:26:14,359 --> 00:26:18,109
different visualization types can help

00:26:16,249 --> 00:26:20,359
you also see what's happening so in this

00:26:18,109 --> 00:26:23,629
so that when I had used the bar chart

00:26:20,359 --> 00:26:25,039
for JVM memory with the lines it's

00:26:23,629 --> 00:26:27,109
pretty clear there's some through the

00:26:25,039 --> 00:26:28,700
shark tooth pattern going on probably at

00:26:27,109 --> 00:26:30,559
these points garbage collection is

00:26:28,700 --> 00:26:31,909
happening but it's very easy to see

00:26:30,559 --> 00:26:35,259
right that there is definitely a pattern

00:26:31,909 --> 00:26:37,370
there CPA user time heat map

00:26:35,259 --> 00:26:39,890
visualization

00:26:37,370 --> 00:26:43,670
can very easily see what's the outlier

00:26:39,890 --> 00:26:48,080
this dark green square and for disk

00:26:43,670 --> 00:26:49,790
usage this bar sorry the area chart it

00:26:48,080 --> 00:26:51,470
gives us an idea of blocks of time where

00:26:49,790 --> 00:26:54,410
disk was being used by different

00:26:51,470 --> 00:26:56,930
resources and then some of the metrics

00:26:54,410 --> 00:27:02,360
about coffee usage we had a client

00:26:56,930 --> 00:27:08,000
Cassandra app running also so some more

00:27:02,360 --> 00:27:11,950
metrics about that maybe show the one

00:27:08,000 --> 00:27:11,950
with all the dimensions at the bottom oh

00:27:15,310 --> 00:27:20,420
right so just just so you get a better

00:27:18,920 --> 00:27:24,590
idea of like what the data looks like

00:27:20,420 --> 00:27:27,260
like that's coming in everything to the

00:27:24,590 --> 00:27:28,970
right of the value column here is all

00:27:27,260 --> 00:27:32,090
the dimensions were getting from the

00:27:28,970 --> 00:27:33,890
different metrics so you can use that

00:27:32,090 --> 00:27:43,760
information to help you navigate through

00:27:33,890 --> 00:27:46,700
your your data coming in okay so we've

00:27:43,760 --> 00:27:48,560
had 2 minutes left before lunch key

00:27:46,700 --> 00:27:50,780
takeaways right so we touched on all

00:27:48,560 --> 00:27:54,110
three in our presentation scalable

00:27:50,780 --> 00:27:57,830
capacity identify system application

00:27:54,110 --> 00:27:59,470
metrics that are meaningful dynamic

00:27:57,830 --> 00:28:02,360
architecture right so your app may be

00:27:59,470 --> 00:28:05,930
composed of multiple elements right so

00:28:02,360 --> 00:28:08,750
use dimensions to simplify your overall

00:28:05,930 --> 00:28:10,160
view of the application and then for for

00:28:08,750 --> 00:28:13,550
load balancing again this is really just

00:28:10,160 --> 00:28:18,320
keeping track of how each if instances

00:28:13,550 --> 00:28:19,670
is doing over time so if you want more

00:28:18,320 --> 00:28:22,510
information we're certainly happy to

00:28:19,670 --> 00:28:26,320
talk to you come visit us our booths and

00:28:22,510 --> 00:28:26,320
with that we'll open up for questions

00:28:32,590 --> 00:28:45,650
nobody okay yeah so question is do we

00:28:43,730 --> 00:28:48,020
need this us-saudi cos makes it a lot

00:28:45,650 --> 00:28:50,140
easier but now you could you could take

00:28:48,020 --> 00:28:53,150
that and you can you could roll yourself

00:28:50,140 --> 00:28:57,110
it's open source the the the missus

00:28:53,150 --> 00:29:03,490
metrics module so the answer is now but

00:28:57,110 --> 00:29:03,490
it's easier if you see cos question

00:29:18,299 --> 00:29:23,759
right so so the question is I believe

00:29:21,089 --> 00:29:24,779
it's about like uptime for tasks and

00:29:23,759 --> 00:29:28,859
jobs and things like that

00:29:24,779 --> 00:29:31,139
okay so again that'll be so typically

00:29:28,859 --> 00:29:34,019
that's done at the framework level like

00:29:31,139 --> 00:29:36,899
whichever scheduler handles I may expose

00:29:34,019 --> 00:29:38,729
information a lot of the new frameworks

00:29:36,899 --> 00:29:41,009
that are being built off of the SDK

00:29:38,729 --> 00:29:43,320
they're all stats D compliant so they

00:29:41,009 --> 00:29:44,519
will send metrics automatically and we

00:29:43,320 --> 00:29:55,440
can pick that up using our metrics

00:29:44,519 --> 00:29:57,899
module okay any last questions all right

00:29:55,440 --> 00:29:59,110
well thank you guys for coming and we'll

00:29:57,899 --> 00:30:04,360
let you go for lunch for now

00:29:59,110 --> 00:30:04,360

YouTube URL: https://www.youtube.com/watch?v=zZHsqG71vM4


