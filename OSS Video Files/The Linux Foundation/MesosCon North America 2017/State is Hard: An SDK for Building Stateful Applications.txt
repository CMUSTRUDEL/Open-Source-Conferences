Title: State is Hard: An SDK for Building Stateful Applications
Publication date: 2017-09-18
Playlist: MesosCon North America 2017
Description: 
	State is Hard: An SDK for Building Stateful Applications - Gabriel Hartmann, Mesosphere, Inc.

Apache Mesos and DC/OS are powerful tools to manage, deploy, and maintain services. But, rolling your own stateful application on top of DC/OS requires a deep understanding of Apache Mesos primitives and DC/OS components. Enter the DC/OS SDK.

From a birdâ€™s eye view, most stateful systems look quite similar. Kafka, Cassandra, HDFS, Elastic and the rest of Big Data systems all have their own very specific concerns, but fundamentally they all need to: 

The DC/OS SDK codifies the 95% of code that is shared between most services, standardizing how those services interact with Mesos. 

In this talk, we will present an overview of the interface and briefly demonstrate how to write a service. We'll also present deep dive on the the internal design and implementation of services.

About 

Gabriel Hartmann
Mesosphere, Inc.
Technical Lead
Gabriel is the lead engineer on the DC/OS Stateful SDK team at Mesosphere. Prior to Mesosphere, Gabriel worked on SQLAzure, the best database in the world. Before Mesosphere he worked at Microsoft working on the high availability team developing the second generation of SQL Azure. Prior to that, in an academic setting, he pursued monocular computer vision research in the context of driver assistance systems.
Captions: 
	00:00:00,149 --> 00:00:05,009
alright so next up we got Gabriel

00:00:02,639 --> 00:00:07,259
Hartman a technical lead at mesosphere

00:00:05,009 --> 00:00:11,420
who's gonna talk about an SDK for

00:00:07,259 --> 00:00:11,420
building stateful applications what eCos

00:00:12,170 --> 00:00:18,960
thanks Robbie everybody can hear me okay

00:00:15,379 --> 00:00:26,490
all right louder all right that better

00:00:18,960 --> 00:00:28,920
all right cool okay we've spent about

00:00:26,490 --> 00:00:31,560
two years building an SDK so that you

00:00:28,920 --> 00:00:36,690
can write stateful applications on maize

00:00:31,560 --> 00:00:39,090
O's and I'm going to talk about it's a

00:00:36,690 --> 00:00:40,829
high level design and then we're gonna

00:00:39,090 --> 00:00:42,300
drill down into like what are the staple

00:00:40,829 --> 00:00:45,690
problems it solves and there's gonna be

00:00:42,300 --> 00:00:48,000
a bunch of demos along the way let's see

00:00:45,690 --> 00:00:49,800
I skipped Who I am Robbie's told you I'm

00:00:48,000 --> 00:00:51,930
Gabriel Hartman I'm a tech lead at

00:00:49,800 --> 00:00:53,879
mesosphere for the last two years that's

00:00:51,930 --> 00:00:55,350
my Twitter handle but I don't use it but

00:00:53,879 --> 00:01:00,210
everybody puts them on their slides so I

00:00:55,350 --> 00:01:03,270
do - all right so we're gonna do

00:01:00,210 --> 00:01:05,729
disclaimers there's only one and then

00:01:03,270 --> 00:01:07,110
we'll talk about stateful problems in

00:01:05,729 --> 00:01:09,090
general I don't know has anybody here

00:01:07,110 --> 00:01:11,610
written a stateful application on top of

00:01:09,090 --> 00:01:14,400
mazes like actually stored State what

00:01:11,610 --> 00:01:15,960
like it okay okay cool we'll talk about

00:01:14,400 --> 00:01:18,450
the framework landscape in general and

00:01:15,960 --> 00:01:22,530
like where where does this SDK or this

00:01:18,450 --> 00:01:24,509
framework fit into that picture there's

00:01:22,530 --> 00:01:25,740
a the SDK does a lot of things many many

00:01:24,509 --> 00:01:27,150
many things and we're only going to talk

00:01:25,740 --> 00:01:28,890
about a few of them so I'll go over all

00:01:27,150 --> 00:01:30,930
the features real quick just so you know

00:01:28,890 --> 00:01:34,229
what they are and then we'll dig into

00:01:30,930 --> 00:01:36,150
the state problem and where we're going

00:01:34,229 --> 00:01:38,369
so amazed of familiarity everybody here

00:01:36,150 --> 00:01:41,159
is at maze OSCON so everybody knows what

00:01:38,369 --> 00:01:44,820
an offer is and our resource and a

00:01:41,159 --> 00:01:46,799
framework that a is that I guess okay I

00:01:44,820 --> 00:01:48,840
see some nodding heads right so I'm I'm

00:01:46,799 --> 00:01:51,509
not going to go over like how maze works

00:01:48,840 --> 00:01:56,060
again if that's a problem please ask

00:01:51,509 --> 00:01:58,409
questions any time okay so I break down

00:01:56,060 --> 00:02:02,189
staple problems into kind of two main

00:01:58,409 --> 00:02:04,049
areas and they they all derive from one

00:02:02,189 --> 00:02:06,450
assumption all these many staple

00:02:04,049 --> 00:02:08,399
services have a legacy view of the world

00:02:06,450 --> 00:02:11,550
that there's some persistent context

00:02:08,399 --> 00:02:13,800
where you can go and run commands any

00:02:11,550 --> 00:02:14,820
time you like this you

00:02:13,800 --> 00:02:16,080
is very inconvenient in the

00:02:14,820 --> 00:02:17,790
containerized world because there is no

00:02:16,080 --> 00:02:18,930
persistent context right you bring up a

00:02:17,790 --> 00:02:23,790
container you do something and then it

00:02:18,930 --> 00:02:25,710
goes away so here's like one main

00:02:23,790 --> 00:02:26,790
category of that problem is you want to

00:02:25,710 --> 00:02:28,080
do something before you do the main

00:02:26,790 --> 00:02:30,660
thing right there's often this like

00:02:28,080 --> 00:02:34,080
prepare task is anybody here familiar

00:02:30,660 --> 00:02:35,600
with like HDFS anybody use HDFS if

00:02:34,080 --> 00:02:37,740
you're a deployed HDFS there's like

00:02:35,600 --> 00:02:39,270
format the name node and there's

00:02:37,740 --> 00:02:40,830
bootstrap the name know then there's run

00:02:39,270 --> 00:02:42,390
the actual name node there's all these

00:02:40,830 --> 00:02:44,370
these tasks you have to do before you do

00:02:42,390 --> 00:02:45,960
the real thing that's a common pattern

00:02:44,370 --> 00:02:48,780
that we saw and then you want to do

00:02:45,960 --> 00:02:51,360
things after you deployed the service so

00:02:48,780 --> 00:02:54,000
if anybody's run Cassandra there's like

00:02:51,360 --> 00:02:55,650
repair tasks that you want to run you've

00:02:54,000 --> 00:02:57,330
got Cassandra running but then you want

00:02:55,650 --> 00:02:58,920
to run tasks in that container later

00:02:57,330 --> 00:03:00,930
while it's still running and do

00:02:58,920 --> 00:03:01,890
something without disrupting it so

00:03:00,930 --> 00:03:05,520
that's what I mean by these like

00:03:01,890 --> 00:03:07,620
maintenance or user-defined tasks um

00:03:05,520 --> 00:03:09,060
here's some examples you'll see HDFS

00:03:07,620 --> 00:03:11,400
comes up a lot it's sort of a motivating

00:03:09,060 --> 00:03:13,350
case for the SDK because it is so legacy

00:03:11,400 --> 00:03:16,110
and has it's very very difficult to

00:03:13,350 --> 00:03:18,360
deploy if you go read HDFS is like

00:03:16,110 --> 00:03:20,820
deployment Docs it's like 17 steps long

00:03:18,360 --> 00:03:25,340
and they assume you can SSH into a node

00:03:20,820 --> 00:03:28,080
and mutate state so for Cassandra

00:03:25,340 --> 00:03:31,790
replacing a dead node or a seed note

00:03:28,080 --> 00:03:31,790
like have you seen in these directions

00:03:32,330 --> 00:03:41,340
right there's step 1 2 3 4 5 6 7 8 9 10

00:03:37,890 --> 00:03:43,890
11 12 13 steps where you like SSH into

00:03:41,340 --> 00:03:46,380
the node and like read some file and

00:03:43,890 --> 00:03:48,239
query it and like so we were able to

00:03:46,380 --> 00:03:50,790
automate this I'm just saying that in

00:03:48,239 --> 00:03:51,930
general stateful things have this kind

00:03:50,790 --> 00:03:53,670
of problem where they assume that you

00:03:51,930 --> 00:04:00,840
can go to the node and like do something

00:03:53,670 --> 00:04:02,400
with it let's see is it still alright so

00:04:00,840 --> 00:04:05,160
let's talk about the framework landscape

00:04:02,400 --> 00:04:06,739
in general you guys have probably heard

00:04:05,160 --> 00:04:10,590
of all these frameworks out there

00:04:06,739 --> 00:04:12,000
there's a Aurora Marathon fens Oh coach

00:04:10,590 --> 00:04:13,470
Jarvis spark like some of these might

00:04:12,000 --> 00:04:14,700
not be might be a little bit

00:04:13,470 --> 00:04:17,040
controversial to call them frameworks

00:04:14,700 --> 00:04:18,239
but generally these are the big general

00:04:17,040 --> 00:04:20,190
purpose frameworks that exist in the

00:04:18,239 --> 00:04:21,269
world and and now we're we've got this

00:04:20,190 --> 00:04:23,669
other one it's a general-purpose

00:04:21,269 --> 00:04:27,389
framework we call DCOs Commons or the

00:04:23,669 --> 00:04:29,580
SDK and I want to like try to play

00:04:27,389 --> 00:04:30,870
in the world of framework so you can

00:04:29,580 --> 00:04:32,610
sort of have some context about what

00:04:30,870 --> 00:04:35,370
it's trying to do I'm generally speaking

00:04:32,610 --> 00:04:36,689
there's like two kinds of schedulers in

00:04:35,370 --> 00:04:39,389
the world there's either mono schedulers

00:04:36,689 --> 00:04:41,759
or multi schedulers approach to

00:04:39,389 --> 00:04:43,969
deploying tasks on mazes right like

00:04:41,759 --> 00:04:46,050
Aurora marathon cook these things

00:04:43,969 --> 00:04:47,460
consume all the offers in the cluster

00:04:46,050 --> 00:04:49,199
they have sort of a global view of the

00:04:47,460 --> 00:04:50,400
thing they're a mono scheduler and then

00:04:49,199 --> 00:04:51,719
you've got a multi scheduler approach

00:04:50,400 --> 00:04:53,009
where you launch lots of different

00:04:51,719 --> 00:04:55,129
frameworks and they all sort of

00:04:53,009 --> 00:04:56,789
cooperate and and fight for resources

00:04:55,129 --> 00:04:58,800
we're over here

00:04:56,789 --> 00:05:01,680
we're on the multi scheduler end of the

00:04:58,800 --> 00:05:04,740
spectrum so the SDK Jena is a factory

00:05:01,680 --> 00:05:06,289
for frameworks for schedulers and then

00:05:04,740 --> 00:05:08,580
there's like this other spectrum like

00:05:06,289 --> 00:05:10,259
generalized versus like specific

00:05:08,580 --> 00:05:12,659
schedulers so some people have written a

00:05:10,259 --> 00:05:14,460
scheduler that is just MongoDB right

00:05:12,659 --> 00:05:15,810
it's Jessica Sandra does does one thing

00:05:14,460 --> 00:05:16,979
and on the other hand you have like

00:05:15,810 --> 00:05:18,210
marathon on the other end of the

00:05:16,979 --> 00:05:19,710
spectrum it's very general you say I

00:05:18,210 --> 00:05:21,659
want to run my application in this

00:05:19,710 --> 00:05:24,840
container so on that spectrum we're on

00:05:21,659 --> 00:05:27,379
the generalized end of things um and

00:05:24,840 --> 00:05:31,229
then there's this another axis right

00:05:27,379 --> 00:05:32,940
long live versus job or anted so many of

00:05:31,229 --> 00:05:34,949
these frameworks are focused on either

00:05:32,940 --> 00:05:38,669
running tasks that last for a long time

00:05:34,949 --> 00:05:41,699
or running tasks that come and go don't

00:05:38,669 --> 00:05:44,069
step on the wire and we're on the

00:05:41,699 --> 00:05:45,569
long-lived end of the spectrum so this

00:05:44,069 --> 00:05:48,120
is a this is something that launches

00:05:45,569 --> 00:05:53,009
tasks and they they last for a long time

00:05:48,120 --> 00:05:56,159
generally speaking so amongst our peers

00:05:53,009 --> 00:05:58,319
I think the closest comparison is a Rory

00:05:56,159 --> 00:05:59,879
marathon fens oh right there we have

00:05:58,319 --> 00:06:01,529
these things in common where we want to

00:05:59,879 --> 00:06:04,050
do long live things and we want to

00:06:01,529 --> 00:06:05,909
provide rich orchestration of tasks

00:06:04,050 --> 00:06:10,560
deployment and then we have these

00:06:05,909 --> 00:06:13,319
additional emphasis in the SDK based

00:06:10,560 --> 00:06:17,789
around stateful applications and being

00:06:13,319 --> 00:06:19,949
extensible so by extensible I mean you

00:06:17,789 --> 00:06:21,930
should be able to create your instance

00:06:19,949 --> 00:06:23,370
of a framework and the special little

00:06:21,930 --> 00:06:25,770
problems that are associated with your

00:06:23,370 --> 00:06:31,229
application like Cassandra or HDFS you

00:06:25,770 --> 00:06:34,219
should be able to solve just there so to

00:06:31,229 --> 00:06:37,860
sum up the SDK is a multi scheduler

00:06:34,219 --> 00:06:39,719
general-purpose framework generator that

00:06:37,860 --> 00:06:41,309
has a special emphasis on stateful

00:06:39,719 --> 00:06:45,569
orchestration and extent

00:06:41,309 --> 00:06:47,429
so here's the SDK features section there

00:06:45,569 --> 00:06:49,139
are many many many of them I would say

00:06:47,429 --> 00:06:51,539
did it go away again

00:06:49,139 --> 00:06:52,919
I would say that the the core mechanic

00:06:51,539 --> 00:06:55,229
of the whole system is this rolling

00:06:52,919 --> 00:06:58,109
configurations and software updates so

00:06:55,229 --> 00:07:00,469
you say I want to make a change to my

00:06:58,109 --> 00:07:03,479
service and it restarts all your tasks

00:07:00,469 --> 00:07:05,549
we have a lot of other things this

00:07:03,479 --> 00:07:08,729
separate deployment and update plans

00:07:05,549 --> 00:07:10,379
means sometimes you want to install a

00:07:08,729 --> 00:07:13,709
service one way but you want to run a

00:07:10,379 --> 00:07:15,329
different orchestration pattern for when

00:07:13,709 --> 00:07:19,110
you will do an update or an upgrade so

00:07:15,329 --> 00:07:20,459
you can you can decide to use different

00:07:19,110 --> 00:07:22,799
deployment strategies based on that

00:07:20,459 --> 00:07:28,039
scenario there's a million maze those

00:07:22,799 --> 00:07:30,839
features that it integrates with it does

00:07:28,039 --> 00:07:34,499
resource reservation for everything all

00:07:30,839 --> 00:07:36,049
the time right now and it it's getting

00:07:34,499 --> 00:07:38,879
pretty good at it

00:07:36,049 --> 00:07:41,719
is anybody here familiar with resource

00:07:38,879 --> 00:07:43,919
or I'm sorry reservation refinement

00:07:41,719 --> 00:07:45,929
anybody it's a brand new feature in May

00:07:43,919 --> 00:07:47,249
so some will demo it later it's it's

00:07:45,929 --> 00:07:49,709
pretty cool

00:07:47,249 --> 00:07:51,839
oh and we also have these placement

00:07:49,709 --> 00:07:53,669
constraints is if you guys use the

00:07:51,839 --> 00:07:55,379
marathon placement constraint language

00:07:53,669 --> 00:07:57,719
you use that before it yeah that's fully

00:07:55,379 --> 00:07:59,729
natively supported by the SDK so you can

00:07:57,719 --> 00:08:01,409
every time you describe a pod or a task

00:07:59,729 --> 00:08:07,469
you can apply those same placement

00:08:01,409 --> 00:08:09,179
constraints so far we've built all these

00:08:07,469 --> 00:08:12,269
services using the SDK and they're all

00:08:09,179 --> 00:08:14,639
available in DCOs right now kubernetes

00:08:12,269 --> 00:08:17,729
was announced I think recently that was

00:08:14,639 --> 00:08:21,989
built on the SDK kafka Cassandra elastic

00:08:17,729 --> 00:08:24,749
HDFS have all been deployed using the

00:08:21,989 --> 00:08:28,709
SDK um we can go look at them later edge

00:08:24,749 --> 00:08:30,059
lb is a something for enterprise DCOs

00:08:28,709 --> 00:08:33,269
and that was built on there and there's

00:08:30,059 --> 00:08:35,219
a bunch of other ones too so let's let's

00:08:33,269 --> 00:08:36,449
talk about it in general what does it

00:08:35,219 --> 00:08:37,860
look like and how does it behave and

00:08:36,449 --> 00:08:41,550
then we'll talk a little bit about the

00:08:37,860 --> 00:08:43,709
special things it does for state so we

00:08:41,550 --> 00:08:45,180
have pods I don't know there's like four

00:08:43,709 --> 00:08:47,189
different definitions of pods we made up

00:08:45,180 --> 00:08:50,759
another one it's just a group of tasks

00:08:47,189 --> 00:08:54,490
okay so here we have a pod named hello

00:08:50,759 --> 00:08:57,360
we want two instances of that pod

00:08:54,490 --> 00:09:00,340
and it has one task in it called server

00:08:57,360 --> 00:09:05,200
it has a goal state of running a command

00:09:00,340 --> 00:09:06,820
and some resources so clear the only

00:09:05,200 --> 00:09:09,280
thing that might be everything here is

00:09:06,820 --> 00:09:12,250
sort of native mezzos terminology right

00:09:09,280 --> 00:09:14,350
this is a mezzos task a pod is an

00:09:12,250 --> 00:09:16,480
executor in this case the only thing

00:09:14,350 --> 00:09:18,790
that's like not maze OSI is this goal

00:09:16,480 --> 00:09:20,950
state of running so you say when when

00:09:18,790 --> 00:09:23,410
this task crashes or whatever something

00:09:20,950 --> 00:09:24,760
bad happens to it we try to maintain its

00:09:23,410 --> 00:09:26,980
goal State all the time the other choice

00:09:24,760 --> 00:09:28,720
besides running is finished so those

00:09:26,980 --> 00:09:30,430
configuration tasks I was talking about

00:09:28,720 --> 00:09:32,020
before that you would want to run before

00:09:30,430 --> 00:09:33,940
your main thing those usually have a

00:09:32,020 --> 00:09:35,530
goal state of finished like format name

00:09:33,940 --> 00:09:37,600
note okay if we're matted the name node

00:09:35,530 --> 00:09:38,860
now we run the real thing so the the

00:09:37,600 --> 00:09:41,530
first one has a goal state of finished

00:09:38,860 --> 00:09:45,130
so that's if you if you want to talk

00:09:41,530 --> 00:09:47,770
about it there's two main pieces pods

00:09:45,130 --> 00:09:50,080
and plans pods is like what is your

00:09:47,770 --> 00:09:51,670
service and plans are how are you going

00:09:50,080 --> 00:09:55,030
to deploy your service so we have like a

00:09:51,670 --> 00:09:56,590
pretty rich orchestration system you

00:09:55,030 --> 00:09:58,660
don't have to understand every little

00:09:56,590 --> 00:10:01,750
detail about what this is but basically

00:09:58,660 --> 00:10:05,260
we have two two pods hello and world

00:10:01,750 --> 00:10:09,100
they can be deployed using various

00:10:05,260 --> 00:10:10,540
strategies and they're maintained

00:10:09,100 --> 00:10:15,460
according to their goal state for you

00:10:10,540 --> 00:10:17,140
forever okay so if you remember the the

00:10:15,460 --> 00:10:20,380
stateful problems I talked about at the

00:10:17,140 --> 00:10:22,900
beginning I'd like to present this idea

00:10:20,380 --> 00:10:25,060
as the main the main idea that resolves

00:10:22,900 --> 00:10:29,020
those problems and it's the fact that

00:10:25,060 --> 00:10:32,470
we've decoupled tasks from resources in

00:10:29,020 --> 00:10:34,870
maze O's so it made us you can apply you

00:10:32,470 --> 00:10:36,970
can reserve resources which we do and

00:10:34,870 --> 00:10:40,270
then you can run tasks on those

00:10:36,970 --> 00:10:42,670
resources now usually in every scheduler

00:10:40,270 --> 00:10:44,440
I've ever seen you launch a task with

00:10:42,670 --> 00:10:46,150
the resources always right and you don't

00:10:44,440 --> 00:10:47,560
have a you don't mutate you never launch

00:10:46,150 --> 00:10:50,380
a different task with the same resources

00:10:47,560 --> 00:10:52,300
and that's that's what we allow here you

00:10:50,380 --> 00:10:55,360
see we've defined this resource set

00:10:52,300 --> 00:10:57,640
there's just a bag of resources and you

00:10:55,360 --> 00:11:00,940
can apply different tasks to that

00:10:57,640 --> 00:11:02,560
resource set so here's that prepared

00:11:00,940 --> 00:11:04,900
task I was talking about right like you

00:11:02,560 --> 00:11:07,180
can run this prepare task use on that

00:11:04,900 --> 00:11:08,259
resource set it has some effect on your

00:11:07,180 --> 00:11:12,339
persistent volume

00:11:08,259 --> 00:11:14,979
hangs around and then and then when you

00:11:12,339 --> 00:11:16,839
later run the server task it can see the

00:11:14,979 --> 00:11:18,129
the effect of that preparer task and its

00:11:16,839 --> 00:11:23,369
persistent volume because they're

00:11:18,129 --> 00:11:26,229
staring resources so so far I presented

00:11:23,369 --> 00:11:27,429
the service spec and the plans so this

00:11:26,229 --> 00:11:29,439
is this is everything that I've shown

00:11:27,429 --> 00:11:33,009
you so it's like what 45 lines of Y amel

00:11:29,439 --> 00:11:35,229
and you've defined a service I think

00:11:33,009 --> 00:11:36,759
we're gonna demo this in a second and

00:11:35,229 --> 00:11:38,789
what you're gonna see is this is what

00:11:36,759 --> 00:11:41,559
this is what a plan looks like you said

00:11:38,789 --> 00:11:43,059
here's the deployment plan and here's

00:11:41,559 --> 00:11:45,850
the hello pod being deployed and here's

00:11:43,059 --> 00:11:47,709
the world pod being deployed and they

00:11:45,850 --> 00:11:49,869
even have their prepare and serve our

00:11:47,709 --> 00:11:52,479
tasks either complete and running and

00:11:49,869 --> 00:11:55,059
you'll see that the goal state of

00:11:52,479 --> 00:11:59,319
finished and running pans out in bezos

00:11:55,059 --> 00:12:01,329
so we prepared world pod 0 we were

00:11:59,319 --> 00:12:03,129
prepared world pot 1 and then they

00:12:01,329 --> 00:12:04,629
started running and so that the goal

00:12:03,129 --> 00:12:06,220
states are achieved right that first has

00:12:04,629 --> 00:12:11,970
finished and then we run this next one

00:12:06,220 --> 00:12:11,970
so let me do it a demo real quick

00:12:18,130 --> 00:12:25,140
this is DCS just starting a scheduler

00:12:22,060 --> 00:12:25,140
it's nothing

00:12:25,560 --> 00:12:30,340
everybody hold your breath okay so

00:12:28,510 --> 00:12:34,090
here's the scheduler coming up that's

00:12:30,340 --> 00:12:36,250
the hello world scheduler takes a few

00:12:34,090 --> 00:12:45,640
seconds it brings up an API server it's

00:12:36,250 --> 00:12:49,350
gonna there we go its running then in a

00:12:45,640 --> 00:12:49,350
second the tasks are going to come

00:12:57,670 --> 00:13:03,430
ah there we go so the hello hello zero

00:13:01,570 --> 00:13:07,380
and hello server up and then we're gonna

00:13:03,430 --> 00:13:07,380
see those world pods come up in a second

00:13:07,620 --> 00:13:13,600
yeah and see you'll see that this this

00:13:11,290 --> 00:13:15,280
world zero prepare thing once you've

00:13:13,600 --> 00:13:19,000
finished and this thing is running now

00:13:15,280 --> 00:13:23,380
let's go look if you recall let's see

00:13:19,000 --> 00:13:27,310
here if I go up here there's a you gotta

00:13:23,380 --> 00:13:30,400
go out here you see the output C so

00:13:27,310 --> 00:13:32,230
we're maintaining this cumulative state

00:13:30,400 --> 00:13:34,210
right that first prepare task did

00:13:32,230 --> 00:13:35,680
something to that your your context and

00:13:34,210 --> 00:13:37,420
then the next thing is able to see that

00:13:35,680 --> 00:13:39,220
context and continue working right we're

00:13:37,420 --> 00:13:43,630
just like one of the core problems that

00:13:39,220 --> 00:13:44,620
staple services are presented with so

00:13:43,630 --> 00:13:46,480
let's go back here

00:13:44,620 --> 00:13:48,340
alright that's so that's like the one

00:13:46,480 --> 00:13:50,440
that's like one use case where you do

00:13:48,340 --> 00:13:51,790
this preparatory task and then are able

00:13:50,440 --> 00:13:56,140
to see the results of that preparation

00:13:51,790 --> 00:13:59,470
later on yeah generating this cumulative

00:13:56,140 --> 00:14:02,980
State so what why did why do we bother

00:13:59,470 --> 00:14:04,810
building this feature basically this is

00:14:02,980 --> 00:14:08,800
something that HDFS does all the time I

00:14:04,810 --> 00:14:10,060
can show you our HDFS plan this is so

00:14:08,800 --> 00:14:11,320
what does it look like when you build

00:14:10,060 --> 00:14:13,750
like a production ready one of these

00:14:11,320 --> 00:14:15,900
it's like 355 lines of Hamel instead of

00:14:13,750 --> 00:14:19,470
like the 45 in the hello world example

00:14:15,900 --> 00:14:24,310
that I was showing no if we look here

00:14:19,470 --> 00:14:26,410
you'll see that sorry you'll see that I

00:14:24,310 --> 00:14:28,600
have these same finished and running

00:14:26,410 --> 00:14:29,980
goal states right format is one of those

00:14:28,600 --> 00:14:31,180
finished tasks that runs before the

00:14:29,980 --> 00:14:32,830
other one then we run the MIT and you

00:14:31,180 --> 00:14:34,840
may note bootstrap is one of those

00:14:32,830 --> 00:14:37,690
finish guys and then then we run the

00:14:34,840 --> 00:14:39,280
main node zkf see format is another one

00:14:37,690 --> 00:14:41,940
right you want to run this finish it and

00:14:39,280 --> 00:14:43,780
then run run the main thing and then

00:14:41,940 --> 00:14:45,340
there's this other feature that I

00:14:43,780 --> 00:14:47,140
alluded to earlier so this is how you

00:14:45,340 --> 00:14:48,450
deploy HDFS but it's not how you update

00:14:47,140 --> 00:14:50,500
it if you want to do a rolling update

00:14:48,450 --> 00:14:51,850
you you run all these things together

00:14:50,500 --> 00:14:53,380
right you restart the name notes

00:14:51,850 --> 00:15:00,280
together where there's EKF so you knows

00:14:53,380 --> 00:15:02,290
you restart the data notes together okay

00:15:00,280 --> 00:15:04,360
okay so the next

00:15:02,290 --> 00:15:05,860
main feature instead of this like

00:15:04,360 --> 00:15:07,899
cumulative effect where you can sequence

00:15:05,860 --> 00:15:10,060
operations on the same resources is what

00:15:07,899 --> 00:15:11,589
I call sidecars I think it's a pretty

00:15:10,060 --> 00:15:14,290
normal term but basically your service

00:15:11,589 --> 00:15:16,329
is running and then you're your executor

00:15:14,290 --> 00:15:17,980
and your tasks stay up and then you run

00:15:16,329 --> 00:15:19,930
another task inside that executor that

00:15:17,980 --> 00:15:22,899
can go see the other tasks context and

00:15:19,930 --> 00:15:24,819
like do things to it right so let's

00:15:22,899 --> 00:15:28,149
let's look at that so here's an example

00:15:24,819 --> 00:15:31,209
of using resources resource sets again

00:15:28,149 --> 00:15:32,709
to enable this sidecar pattern so you

00:15:31,209 --> 00:15:36,009
see I have to find another resource set

00:15:32,709 --> 00:15:39,009
called the sidecar resource hold on and

00:15:36,009 --> 00:15:41,319
then and then you have then we have

00:15:39,009 --> 00:15:42,670
three tasks the preparer and the server

00:15:41,319 --> 00:15:43,779
that we had before and I've added

00:15:42,670 --> 00:15:45,790
another finished task

00:15:43,779 --> 00:15:48,069
sidecar okay I can just inject this task

00:15:45,790 --> 00:15:53,500
into the executor and shared context and

00:15:48,069 --> 00:15:58,180
and run it on demand and you can tick

00:15:53,500 --> 00:16:00,790
off such work by defining a plan I call

00:15:58,180 --> 00:16:02,829
it a sidecar plan that says go run those

00:16:00,790 --> 00:16:04,420
sidecar tasks on the world pod and so

00:16:02,829 --> 00:16:06,220
you can just hit an API endpoint and say

00:16:04,420 --> 00:16:08,260
hey run the sidecar plan and it's going

00:16:06,220 --> 00:16:12,190
to run all those tasks in your executor

00:16:08,260 --> 00:16:14,199
context and like perform sort of a

00:16:12,190 --> 00:16:19,630
maintenance operation on your service so

00:16:14,199 --> 00:16:21,839
hold on they wanted to uninstall hello

00:16:19,630 --> 00:16:21,839
world

00:16:28,560 --> 00:16:38,250
okay wait for that to be uninstalled one

00:16:32,110 --> 00:16:40,360
second so we're gonna see the same thing

00:16:38,250 --> 00:16:42,490
we're gonna have a we're gonna be able

00:16:40,360 --> 00:16:45,420
to launch that those sidecar tasks into

00:16:42,490 --> 00:16:49,570
the running containers context by

00:16:45,420 --> 00:16:51,010
executing the sidecar plan and you this

00:16:49,570 --> 00:16:53,440
is this is the result you're gonna see

00:16:51,010 --> 00:16:54,640
is the can you see these timestamps you

00:16:53,440 --> 00:16:57,580
see it that says three minutes up here

00:16:54,640 --> 00:17:00,520
and two minutes down here that means

00:16:57,580 --> 00:17:03,160
that the world servers stayed up the

00:17:00,520 --> 00:17:05,319
whole time and I was able to inject a

00:17:03,160 --> 00:17:07,929
sidecar task into that container without

00:17:05,319 --> 00:17:10,260
affecting the running service right you

00:17:07,929 --> 00:17:14,189
want to maintain the service being up so

00:17:10,260 --> 00:17:14,189
I can show that

00:17:22,020 --> 00:17:25,490
yep it's gone

00:17:32,430 --> 00:17:35,060
so

00:17:39,450 --> 00:17:46,060
the new scheduler coming up just one

00:17:43,390 --> 00:17:47,950
second let it deploy the surface again

00:17:46,060 --> 00:17:49,180
and then we will run the sidecar plan

00:17:47,950 --> 00:17:51,040
and what we're going to see at the end

00:17:49,180 --> 00:17:53,170
of this remember we had that prepare and

00:17:51,040 --> 00:17:54,580
then we had server and the output now

00:17:53,170 --> 00:17:56,530
you're going to see prepare a server and

00:17:54,580 --> 00:17:58,090
then you're gonna see sidecar injected

00:17:56,530 --> 00:18:01,060
into that same like context that

00:17:58,090 --> 00:18:11,920
everybody is sharing now give it a

00:18:01,060 --> 00:18:15,910
second plan let's see you can list all

00:18:11,920 --> 00:18:17,230
the plans these are these are DCOs CLI

00:18:15,910 --> 00:18:19,330
commands but all it's hitting is a REST

00:18:17,230 --> 00:18:25,780
API - which is served by the by the

00:18:19,330 --> 00:18:29,620
scheduler there's so if you say plan

00:18:25,780 --> 00:18:31,770
show deploy you'll see the deployment

00:18:29,620 --> 00:18:31,770
plan

00:18:36,240 --> 00:18:41,259
there you go so the deployment the

00:18:38,110 --> 00:18:50,549
deployment has completed so let's go

00:18:41,259 --> 00:18:50,549
start that sidecar plan right

00:18:55,600 --> 00:19:04,030
there it's already almost done see

00:18:58,929 --> 00:19:07,230
so those prepare tests are done and the

00:19:04,030 --> 00:19:14,410
sidecar tasks are done and if we go look

00:19:07,230 --> 00:19:17,260
into that volume we'll see that it's

00:19:14,410 --> 00:19:19,510
affecting that persistent state that

00:19:17,260 --> 00:19:25,870
shared context that staple service is

00:19:19,510 --> 00:19:28,900
like cool so why did we build this

00:19:25,870 --> 00:19:30,100
feature we did that I mean the real

00:19:28,900 --> 00:19:32,200
motivating news case for this feature

00:19:30,100 --> 00:19:33,490
was Cassandra because Cassandra has a

00:19:32,200 --> 00:19:35,409
number of tasks that you want to roll

00:19:33,490 --> 00:19:37,890
out across the cluster there's repair

00:19:35,409 --> 00:19:42,940
there's cleanup there's backup restore

00:19:37,890 --> 00:19:47,230
we can go look at those so you see we

00:19:42,940 --> 00:19:51,580
defined a number of plans here's the

00:19:47,230 --> 00:19:53,110
back-up s3 plan for Cassandra this is a

00:19:51,580 --> 00:19:55,120
lot more complicated than that world

00:19:53,110 --> 00:19:57,159
scenario but it backs up the schema it

00:19:55,120 --> 00:19:59,020
creates snapshots it uploads those to s3

00:19:57,159 --> 00:20:00,309
and then it cleans up the snapshots

00:19:59,020 --> 00:20:02,020
right and you've got the you've got the

00:20:00,309 --> 00:20:04,299
inverse over here for restore you can go

00:20:02,020 --> 00:20:06,010
fetch everything from s3 restore the

00:20:04,299 --> 00:20:07,510
schema and restore the snapshot so and

00:20:06,010 --> 00:20:10,270
this all occurs while your Cassandra

00:20:07,510 --> 00:20:12,250
cluster is still running it unaffected

00:20:10,270 --> 00:20:13,630
you can define how you want to run these

00:20:12,250 --> 00:20:15,789
plans right would you like to do them

00:20:13,630 --> 00:20:17,919
serially are you in a hurry you want to

00:20:15,789 --> 00:20:21,100
run all this backup in parallel

00:20:17,919 --> 00:20:22,720
do you want to do it 10% at a time you

00:20:21,100 --> 00:20:24,220
know all this is up to you right you can

00:20:22,720 --> 00:20:31,510
define how you want to operate your

00:20:24,220 --> 00:20:33,250
system okay so so far we've gone over

00:20:31,510 --> 00:20:34,960
sort of the stateful aspects of the

00:20:33,250 --> 00:20:36,130
surface and some of the the

00:20:34,960 --> 00:20:37,720
orchestration capabilities of the

00:20:36,130 --> 00:20:40,870
service and I want to touch briefly on

00:20:37,720 --> 00:20:43,659
the extensibility of this so far you've

00:20:40,870 --> 00:20:46,000
only seen the amyl in brief uh-huh so

00:20:43,659 --> 00:20:48,909
you can modify that yeah Mille what we

00:20:46,000 --> 00:20:51,549
call the service spec is instantiated as

00:20:48,909 --> 00:20:53,980
a Java object and you are free to modify

00:20:51,549 --> 00:20:56,230
it before the service starts at will

00:20:53,980 --> 00:20:58,539
that that example service I talked about

00:20:56,230 --> 00:21:00,429
edge Elbe it's an edge load balancer it

00:20:58,539 --> 00:21:03,880
uses us a lot it programmatically

00:21:00,429 --> 00:21:09,309
modifies the port characteristics of its

00:21:03,880 --> 00:21:11,230
service let's see and then

00:21:09,309 --> 00:21:14,049
sort of the the first-class easy things

00:21:11,230 --> 00:21:16,600
that we allow you to extend your service

00:21:14,049 --> 00:21:18,129
with our api's so you saw that eight all

00:21:16,600 --> 00:21:20,820
those commands I was running there's a

00:21:18,129 --> 00:21:22,509
whole bunch of them so if you say D cos

00:21:20,820 --> 00:21:24,850
hello world

00:21:22,509 --> 00:21:27,669
I think it'll spew them all yeah like

00:21:24,850 --> 00:21:30,539
there there are many many many endpoints

00:21:27,669 --> 00:21:33,549
that you get for free in your scheduler

00:21:30,539 --> 00:21:34,929
but you can add your own Kafka does this

00:21:33,549 --> 00:21:36,490
so if you wanted to expose like the

00:21:34,929 --> 00:21:39,899
ability to create Kafka topics through

00:21:36,490 --> 00:21:43,539
your API server you can you can do this

00:21:39,899 --> 00:21:48,070
and so that's api's and then there's

00:21:43,539 --> 00:21:51,039
failure recovery so anybody know how to

00:21:48,070 --> 00:21:52,960
replace a name node that's failed like

00:21:51,039 --> 00:21:55,059
what if you know the in HDFS there are

00:21:52,960 --> 00:21:58,080
two name nodes usually and if one of

00:21:55,059 --> 00:22:00,159
them permanently fails you need to

00:21:58,080 --> 00:22:02,049
bootstrap it off of the other one like

00:22:00,159 --> 00:22:05,350
copy over all the bits and then start it

00:22:02,049 --> 00:22:08,289
and so that's like custom recovery logic

00:22:05,350 --> 00:22:13,330
for a permanent failure case what we you

00:22:08,289 --> 00:22:16,360
can extend that we're go so you so you

00:22:13,330 --> 00:22:19,320
can define your own custom recovery

00:22:16,360 --> 00:22:23,309
logic in Java and add it to the service

00:22:19,320 --> 00:22:23,309
let's see if I can just show you that

00:22:26,039 --> 00:22:33,519
yeah here's the HDFS example for for

00:22:28,929 --> 00:22:35,110
failure recovery you see you were able

00:22:33,519 --> 00:22:36,820
to write a little Java I don't know

00:22:35,110 --> 00:22:39,039
maybe that's too small there you go you

00:22:36,820 --> 00:22:41,440
wrote a little Java it says oh I'm

00:22:39,039 --> 00:22:43,509
replacing name node 0 or name node 1 Oh

00:22:41,440 --> 00:22:45,789
bootstrap off the other guy and then

00:22:43,509 --> 00:22:47,799
start the name node like this is not a

00:22:45,789 --> 00:22:49,899
lot of Java and you but you have this

00:22:47,799 --> 00:22:51,190
programmatic extensibility so you can

00:22:49,899 --> 00:22:55,080
handle all the special failure cases

00:22:51,190 --> 00:22:55,080
that many stateful services had

00:22:58,559 --> 00:23:02,860
Cassandra does the same thing so

00:23:01,330 --> 00:23:05,019
Cassandra when you when you want to

00:23:02,860 --> 00:23:06,999
replace a Cassandra node you have to

00:23:05,019 --> 00:23:09,429
tell it or if you want to do it right

00:23:06,999 --> 00:23:11,590
you should tell it which IP address it's

00:23:09,429 --> 00:23:15,970
replacing so that it can take over the

00:23:11,590 --> 00:23:17,649
the token range so you see this we you

00:23:15,970 --> 00:23:19,299
should modify the command that you run

00:23:17,649 --> 00:23:20,830
in this special case instead of just

00:23:19,299 --> 00:23:22,450
starting the Cassandra no you say Sandra

00:23:20,830 --> 00:23:23,200
node replace IP and then you give it

00:23:22,450 --> 00:23:25,299
this special IP

00:23:23,200 --> 00:23:28,360
a dress and then you rebuild the pod

00:23:25,299 --> 00:23:29,649
spec and then you'll see down here if

00:23:28,360 --> 00:23:31,360
it's a seed node you need to do this

00:23:29,649 --> 00:23:33,519
extra special thing right like all this

00:23:31,360 --> 00:23:34,600
if-else if-else logic makes sense in a

00:23:33,519 --> 00:23:36,399
programming language it doesn't really

00:23:34,600 --> 00:23:41,380
make sense in y amal so we allow you to

00:23:36,399 --> 00:23:43,809
extend your services in this way very

00:23:41,380 --> 00:23:45,100
did that okay so nobody was familiar

00:23:43,809 --> 00:23:47,350
with reservation refinements a new

00:23:45,100 --> 00:23:53,250
feature in maize owes that M Park wrote

00:23:47,350 --> 00:23:55,570
thank you know Park and it allows you to

00:23:53,250 --> 00:23:56,679
you guys know about static reservations

00:23:55,570 --> 00:23:58,659
what you can start an agent with

00:23:56,679 --> 00:24:00,070
statically reserved resources now I

00:23:58,659 --> 00:24:01,620
showed you a bunch of neat things that

00:24:00,070 --> 00:24:04,210
you can do with stateful services great

00:24:01,620 --> 00:24:05,950
but still there are probably edge cases

00:24:04,210 --> 00:24:07,720
where you want to isolate sort of

00:24:05,950 --> 00:24:09,899
permanently your storage services you

00:24:07,720 --> 00:24:11,980
say like here are my ten storage nodes

00:24:09,899 --> 00:24:13,059
I'm gonna isolate that from the rest of

00:24:11,980 --> 00:24:15,190
my cluster so I want to statically

00:24:13,059 --> 00:24:17,919
reserve those resources if you're

00:24:15,190 --> 00:24:19,389
running multiple frameworks you would in

00:24:17,919 --> 00:24:21,039
the past you would be stuck with saying

00:24:19,389 --> 00:24:22,750
I want to statically reserve these

00:24:21,039 --> 00:24:24,190
resources for Cassandra zero

00:24:22,750 --> 00:24:25,720
I want to statically reserve these

00:24:24,190 --> 00:24:27,850
resources for Cassandra one and you sort

00:24:25,720 --> 00:24:29,320
of have to know every single time you

00:24:27,850 --> 00:24:31,330
want to install a service what

00:24:29,320 --> 00:24:34,510
reservations you want to want to perform

00:24:31,330 --> 00:24:37,389
now with reservation refinement you can

00:24:34,510 --> 00:24:39,370
say look I'm gonna reserve these ten

00:24:37,389 --> 00:24:41,019
nodes for the storage role okay they're

00:24:39,370 --> 00:24:42,760
just storage and every time I want to

00:24:41,019 --> 00:24:45,429
install it Cassandra I say hey Cassandra

00:24:42,760 --> 00:24:47,049
go consume some portion of that storage

00:24:45,429 --> 00:24:48,549
role so you can say I'm gonna refine

00:24:47,049 --> 00:24:50,380
that resource I'm gonna refine that

00:24:48,549 --> 00:24:52,299
reservation it was reserved to Kassam or

00:24:50,380 --> 00:24:54,250
to storage and now I'm gonna reserve it

00:24:52,299 --> 00:24:56,559
even further into storage SAS slash

00:24:54,250 --> 00:24:58,179
Cassandra and and the real power of that

00:24:56,559 --> 00:25:01,570
is that you maintain a clean offer

00:24:58,179 --> 00:25:04,480
stream so each one of the frameworks

00:25:01,570 --> 00:25:06,399
that consumes resources in that way but

00:25:04,480 --> 00:25:09,279
doesn't have to cooperate with other

00:25:06,399 --> 00:25:11,200
frameworks and say oh I'm using some

00:25:09,279 --> 00:25:12,370
portion of the storage role but you and

00:25:11,200 --> 00:25:14,169
you should not use it like how do you

00:25:12,370 --> 00:25:16,090
how do you do that you do that by having

00:25:14,169 --> 00:25:19,480
an one-to-one mapping between frameworks

00:25:16,090 --> 00:25:26,159
and roles so I have a demo that shows

00:25:19,480 --> 00:25:26,159
this working come on

00:25:31,440 --> 00:25:42,090
Oh hold on I get out and install the

00:25:33,210 --> 00:25:44,370
last one one second um I don't know if

00:25:42,090 --> 00:25:46,559
you guys are familiar with DC OS but DC

00:25:44,370 --> 00:25:48,179
Wes has out of the box it's got

00:25:46,559 --> 00:25:50,250
something called public agents or public

00:25:48,179 --> 00:25:53,669
slaves and those are statically reserved

00:25:50,250 --> 00:25:55,080
so I'm gonna refine the reservation of

00:25:53,669 --> 00:25:57,779
those statically reserved resources and

00:25:55,080 --> 00:25:59,940
I'm going to run some of my tasks on

00:25:57,779 --> 00:26:01,350
those statically reserved resources that

00:25:59,940 --> 00:26:03,769
have been refined and some of them on

00:26:01,350 --> 00:26:08,580
the normal like private agent pool I

00:26:03,769 --> 00:26:12,029
have the yeah Mille for that if you'd

00:26:08,580 --> 00:26:13,740
like to see it so you see the only thing

00:26:12,029 --> 00:26:16,110
I had to do was say the pre reserved

00:26:13,740 --> 00:26:19,080
role here the statically reserved role

00:26:16,110 --> 00:26:20,220
is slave public and now all these hello

00:26:19,080 --> 00:26:25,730
tasks are going to refine that

00:26:20,220 --> 00:26:28,940
reservation so let's see if we all die

00:26:25,730 --> 00:26:28,940
it's still

00:26:32,110 --> 00:26:39,870
hello oh no I touched the wire

00:26:48,799 --> 00:26:54,520
back cool go back to the slides

00:27:00,519 --> 00:27:03,269
all right

00:27:04,950 --> 00:27:09,210
see whoops wrong cluster

00:27:09,409 --> 00:27:19,019
so what we should see what we're going

00:27:12,570 --> 00:27:19,830
to see is that we're gonna get three

00:27:19,019 --> 00:27:21,690
hellos

00:27:19,830 --> 00:27:23,339
hello pods that are on these refined

00:27:21,690 --> 00:27:28,609
resources and three world pods that are

00:27:23,339 --> 00:27:28,609
on unrefined resources Oh not working

00:27:39,180 --> 00:27:43,760
you're gonna go okay cool

00:27:44,740 --> 00:27:47,740
okay

00:27:48,930 --> 00:27:55,530
so you can you guys see that you see you

00:27:53,310 --> 00:27:59,460
see the role here so that for the hello

00:27:55,530 --> 00:28:08,430
pods its slave public / hello world role

00:27:59,460 --> 00:28:10,560
yeah god take my word for it do you see

00:28:08,430 --> 00:28:14,430
that that that those are refined

00:28:10,560 --> 00:28:17,460
resources so there's only one framework

00:28:14,430 --> 00:28:19,260
in the world that has hello world slack

00:28:17,460 --> 00:28:20,790
or a slave public / hello world role

00:28:19,260 --> 00:28:22,380
resources and so it has a clean offer

00:28:20,790 --> 00:28:26,160
stream those resources are for it and it

00:28:22,380 --> 00:28:28,080
alone this is actually also made

00:28:26,160 --> 00:28:32,090
possible by the use of multi roles so

00:28:28,080 --> 00:28:32,090
you see maybe you do maybe you don't

00:28:33,500 --> 00:28:40,080
the framework is registered with two

00:28:36,450 --> 00:28:43,620
roles the hello world role see the hello

00:28:40,080 --> 00:28:45,390
world role and the hello world / or the

00:28:43,620 --> 00:28:47,250
slave public / hello world role so it's

00:28:45,390 --> 00:28:49,800
it's able to create reservations in both

00:28:47,250 --> 00:28:52,260
of those roles so you need both multi

00:28:49,800 --> 00:28:56,250
role and reservation refinement to make

00:28:52,260 --> 00:28:58,260
this work I can do one more thing I want

00:28:56,250 --> 00:29:02,690
to show is that I can install another

00:28:58,260 --> 00:29:05,700
one and they both refine resources and

00:29:02,690 --> 00:29:09,800
they don't conflict I want to show that

00:29:05,700 --> 00:29:09,800
real quickly behaves

00:29:26,920 --> 00:29:33,850
so we can install another one with a

00:29:30,040 --> 00:29:36,360
different name and it's going to do the

00:29:33,850 --> 00:29:36,360
same thing

00:29:39,030 --> 00:29:43,080
so let's see hello world 2 is stating

00:29:41,340 --> 00:29:44,580
there so that's the new scheduler coming

00:29:43,080 --> 00:29:46,230
up and you're gonna see that it's going

00:29:44,580 --> 00:29:48,690
to refine resources from slave public

00:29:46,230 --> 00:29:51,360
into hello world roll 2 and so now they

00:29:48,690 --> 00:29:54,690
they each have clean reserved resource

00:29:51,360 --> 00:29:56,640
streams through multi role registration

00:29:54,690 --> 00:29:58,260
and reservation refinement which is kind

00:29:56,640 --> 00:30:01,230
of neat so so the idea here is that

00:29:58,260 --> 00:30:02,820
instead so read slave public as storage

00:30:01,230 --> 00:30:04,350
so you could have like pre reserved a

00:30:02,820 --> 00:30:06,630
whole bunch of storage nodes and then

00:30:04,350 --> 00:30:09,210
you could have installed Cassandra HDFS

00:30:06,630 --> 00:30:11,130
elastic Kafka into that pre reserved

00:30:09,210 --> 00:30:14,970
storage pool and they would have all

00:30:11,130 --> 00:30:16,590
played nicely without having sort of the

00:30:14,970 --> 00:30:18,900
data center operator have to talk to the

00:30:16,590 --> 00:30:25,590
guy who's installing the stateful

00:30:18,900 --> 00:30:28,050
services see hello world to roll ok ok

00:30:25,590 --> 00:30:30,320
so where are we going to go from here so

00:30:28,050 --> 00:30:33,150
at the beginning I talked about these

00:30:30,320 --> 00:30:36,270
sort of axes that the the framework or

00:30:33,150 --> 00:30:38,670
this sdk lives on and right now we're

00:30:36,270 --> 00:30:40,110
very very focused on long-lived services

00:30:38,670 --> 00:30:42,090
but that's going to move where we're

00:30:40,110 --> 00:30:47,310
going to start to support sort of

00:30:42,090 --> 00:30:49,710
short-lived job oriented tasks it's a

00:30:47,310 --> 00:30:51,930
very general purpose framework right now

00:30:49,710 --> 00:30:54,030
and I say that's gonna move to be a more

00:30:51,930 --> 00:30:55,650
specific so what do I mean by that so

00:30:54,030 --> 00:30:57,360
right now it's like a really fancy

00:30:55,650 --> 00:30:59,340
deployment mechanism for somebody else's

00:30:57,360 --> 00:31:00,360
software right like I wanted to play

00:30:59,340 --> 00:31:02,280
Cassandra somebody else wrote a

00:31:00,360 --> 00:31:04,440
distributed system already and I'm just

00:31:02,280 --> 00:31:06,390
deploying in the future we'd like the

00:31:04,440 --> 00:31:09,090
SDK to be able to be used to build new

00:31:06,390 --> 00:31:10,650
distributed systems that are like it's

00:31:09,090 --> 00:31:12,210
not just deploying kafka brokers or

00:31:10,650 --> 00:31:14,580
something

00:31:12,210 --> 00:31:16,740
right now it is very a hundred percent

00:31:14,580 --> 00:31:19,140
focused on stateful services it's like

00:31:16,740 --> 00:31:20,640
it reserves every resource it's very

00:31:19,140 --> 00:31:22,980
interested in volumes it doesn't let you

00:31:20,640 --> 00:31:24,510
blow your foot off if a task goes away

00:31:22,980 --> 00:31:25,530
it doesn't like automatically replace it

00:31:24,510 --> 00:31:28,620
and throw away your data it's very

00:31:25,530 --> 00:31:29,850
focused on that but I'd like it to move

00:31:28,620 --> 00:31:32,430
in a more stateless direction so we'll

00:31:29,850 --> 00:31:34,080
have pods that are not solely focused on

00:31:32,430 --> 00:31:36,540
state but can be stateless and by that I

00:31:34,080 --> 00:31:37,710
mean if they crash that's fine we can

00:31:36,540 --> 00:31:39,390
launch them somewhere else it's not

00:31:37,710 --> 00:31:41,130
obsessed with the idea that it has to

00:31:39,390 --> 00:31:42,630
come back exactly the same place exactly

00:31:41,130 --> 00:31:45,270
the same resource is exactly the same

00:31:42,630 --> 00:31:48,090
volume then there's a bunch of stuff to

00:31:45,270 --> 00:31:49,830
just make it more fun to use but this is

00:31:48,090 --> 00:31:51,510
this is something we're working on

00:31:49,830 --> 00:31:52,500
better operations and tooling and debug

00:31:51,510 --> 00:31:54,960
and stop pods

00:31:52,500 --> 00:31:58,470
I keep talking about this shared context

00:31:54,960 --> 00:32:00,990
is what is what makes stateful services

00:31:58,470 --> 00:32:02,670
so annoying to work with so these debug

00:32:00,990 --> 00:32:04,080
pause is what I mean is that you should

00:32:02,670 --> 00:32:05,550
be able to say to one of those hello

00:32:04,080 --> 00:32:08,070
pods or Cassandra pot or something say

00:32:05,550 --> 00:32:09,720
put it in debug mode which is what it's

00:32:08,070 --> 00:32:11,730
gonna be the moral equivalent of restart

00:32:09,720 --> 00:32:13,890
that pod and suppress the command and

00:32:11,730 --> 00:32:15,090
make it sleep for infinite and so you

00:32:13,890 --> 00:32:16,830
just have the containers sitting there

00:32:15,090 --> 00:32:18,060
not doing anything and it's like a VM

00:32:16,830 --> 00:32:19,560
it's like a server and you can go in

00:32:18,060 --> 00:32:22,710
there and modify the state and run

00:32:19,560 --> 00:32:25,590
interactive commands and fix it so for

00:32:22,710 --> 00:32:28,290
example HDFS name nodes what what do you

00:32:25,590 --> 00:32:30,690
do when your HDFS metadata is corrupted

00:32:28,290 --> 00:32:32,610
you run this command it's like name node

00:32:30,690 --> 00:32:34,020
recover and it's interactive and it asks

00:32:32,610 --> 00:32:35,070
you questions and you answer them like

00:32:34,020 --> 00:32:36,840
how do you do that in a containerized

00:32:35,070 --> 00:32:38,820
world I think you do it like this you

00:32:36,840 --> 00:32:40,350
stand up this debug pod and you start

00:32:38,820 --> 00:32:43,170
modifying the state and then when you're

00:32:40,350 --> 00:32:45,360
done you let it do its thing again the

00:32:43,170 --> 00:32:46,500
programmatic extensibility is like that

00:32:45,360 --> 00:32:48,540
you saw in the Java is like really

00:32:46,500 --> 00:32:50,820
focused on a couple use cases like api's

00:32:48,540 --> 00:32:55,050
or modifying the service spec at start

00:32:50,820 --> 00:32:57,120
time or custom recovery but five minutes

00:32:55,050 --> 00:32:58,910
left there those aren't super easy to

00:32:57,120 --> 00:33:01,560
use and we'd like to make it better

00:32:58,910 --> 00:33:03,060
service composition okay so you have a

00:33:01,560 --> 00:33:05,030
bunch of hope all these services right

00:33:03,060 --> 00:33:06,810
you wrote Cassandra you wrote elastic I

00:33:05,030 --> 00:33:08,400
don't know if you guys were here for the

00:33:06,810 --> 00:33:10,410
ESRI talk like they had this big stack

00:33:08,400 --> 00:33:12,060
of like five different services it would

00:33:10,410 --> 00:33:13,860
be nice to have Azria in a box you like

00:33:12,060 --> 00:33:15,390
push a button and it says oh I want one

00:33:13,860 --> 00:33:16,590
elastic that looks like this I want a

00:33:15,390 --> 00:33:18,060
spark that looks like that

00:33:16,590 --> 00:33:22,140
I want a coffee that looks like this

00:33:18,060 --> 00:33:24,420
boom and our development tooling could

00:33:22,140 --> 00:33:25,710
use some work that's it does anybody

00:33:24,420 --> 00:33:28,580
have any questions I think we have just

00:33:25,710 --> 00:33:28,580
five minutes left

00:33:30,380 --> 00:33:36,409
I'm sorry would you yeah

00:33:41,870 --> 00:34:07,340
elasticity meaning oh yeah so you want

00:33:57,029 --> 00:34:07,340
to the question was how do we yeah right

00:34:07,879 --> 00:34:16,230
yeah yeah okay so the question was how

00:34:13,889 --> 00:34:18,000
do we expand Kassandra capacity in an

00:34:16,230 --> 00:34:21,139
online fashion like add nodes with

00:34:18,000 --> 00:34:24,119
leaving the server's uninterrupted so

00:34:21,139 --> 00:34:26,369
the core mechanism of the of the sdk is

00:34:24,119 --> 00:34:28,169
that that yeah mul whatever whatever you

00:34:26,369 --> 00:34:29,940
want to call it that service spec you

00:34:28,169 --> 00:34:31,200
you compare old configuration and new

00:34:29,940 --> 00:34:32,760
configuration right so your old

00:34:31,200 --> 00:34:34,679
configuration said I wanted three nodes

00:34:32,760 --> 00:34:36,659
of Cassandra your new new configuration

00:34:34,679 --> 00:34:39,060
says you want six nodes of Cassandra it

00:34:36,659 --> 00:34:40,260
is smart and goes oh you already got

00:34:39,060 --> 00:34:42,240
three we'll leave those alone and it

00:34:40,260 --> 00:34:43,980
adds three more with a readiness check

00:34:42,240 --> 00:34:45,599
and says oh here's a new one it joins

00:34:43,980 --> 00:34:48,089
the ring waits for it to be up and

00:34:45,599 --> 00:34:51,619
normal adds the next one joins the ring

00:34:48,089 --> 00:34:51,619
waits for it to be up and normal is that

00:34:53,419 --> 00:35:00,359
no no that's not a thing you need to do

00:34:55,679 --> 00:35:03,089
we know we don't scale in right now it's

00:35:00,359 --> 00:35:04,619
something that I don't I don't know we

00:35:03,089 --> 00:35:08,099
might do it someday it's very dangerous

00:35:04,619 --> 00:35:09,960
to scale in and you and I would the risk

00:35:08,099 --> 00:35:11,730
of data loss is very concerning to me

00:35:09,960 --> 00:35:14,339
and so if somebody they had this service

00:35:11,730 --> 00:35:16,080
spec that had like six nodes in it and

00:35:14,339 --> 00:35:18,900
then somebody screwed up and said oh now

00:35:16,080 --> 00:35:20,400
it has three nodes what should I do

00:35:18,900 --> 00:35:21,720
should I knock off the last three nodes

00:35:20,400 --> 00:35:24,540
and throw that data away like I don't

00:35:21,720 --> 00:35:26,250
really know where that data is so if we

00:35:24,540 --> 00:35:27,930
were to ever do it I would probably say

00:35:26,250 --> 00:35:30,300
that you have to have user input say

00:35:27,930 --> 00:35:32,849
yeah I want to go from six to three and

00:35:30,300 --> 00:35:35,960
I want those three nodes to go away and

00:35:32,849 --> 00:35:35,960
no others right

00:35:42,080 --> 00:35:56,270
yeah yeah we have readiness checks it

00:35:44,490 --> 00:35:56,270
watches what's going on I'm sorry yeah

00:36:02,120 --> 00:36:05,660
the question was does the service

00:36:04,190 --> 00:36:07,280
support the capability of waiting for

00:36:05,660 --> 00:36:08,720
something to happen or be ready before

00:36:07,280 --> 00:36:10,700
you move on yes there are health checks

00:36:08,720 --> 00:36:12,620
and readiness checks so writing this

00:36:10,700 --> 00:36:14,270
checks means run this thing until it

00:36:12,620 --> 00:36:16,280
passes and then that means that that

00:36:14,270 --> 00:36:17,180
step of the deployment plan is finished

00:36:16,280 --> 00:36:19,640
and then we move on to the next thing

00:36:17,180 --> 00:36:21,680
held checks are oh if something is sick

00:36:19,640 --> 00:36:24,500
we should kill it and it just runs that

00:36:21,680 --> 00:36:26,300
on intervals or defined by time like run

00:36:24,500 --> 00:36:27,500
this every 30 seconds it's a problem

00:36:26,300 --> 00:36:39,020
cool

00:36:27,500 --> 00:36:44,000
anybody else yes sir yeah I'm I'm sorry

00:36:39,020 --> 00:36:45,800
oh yeah sure the question was stateful

00:36:44,000 --> 00:36:47,930
services are very sensitive to

00:36:45,800 --> 00:36:51,290
maintenance and do we support their

00:36:47,930 --> 00:36:52,970
rescinding of offers yes we support

00:36:51,290 --> 00:36:54,800
rescinding of offers when they're in

00:36:52,970 --> 00:36:57,350
process by the scheduler so if you have

00:36:54,800 --> 00:36:58,850
like a thousand offers come to you we

00:36:57,350 --> 00:37:01,430
have like an offer queue of a particular

00:36:58,850 --> 00:37:03,110
size we drop some and then while we're

00:37:01,430 --> 00:37:04,670
processing those offers if a rescind

00:37:03,110 --> 00:37:06,080
offer comes in or ever send request

00:37:04,670 --> 00:37:07,160
comes in we say oh we removed that from

00:37:06,080 --> 00:37:08,990
the queue and we're not going to process

00:37:07,160 --> 00:37:12,080
it anymore but you're talking about like

00:37:08,990 --> 00:37:19,850
taking running tasks down yeah we we

00:37:12,080 --> 00:37:20,920
have not crossed that Rubicon that is

00:37:19,850 --> 00:37:23,650
correct

00:37:20,920 --> 00:37:26,030
yes I'm unaware of any framework that's

00:37:23,650 --> 00:37:29,290
taking full advantage of maze those

00:37:26,030 --> 00:37:31,640
maintenance primitives it is unfortunate

00:37:29,290 --> 00:37:36,290
got time for one more question okay

00:37:31,640 --> 00:37:40,090
anybody I'll talk to you later I know

00:37:36,290 --> 00:37:40,090
you yeah what's up

00:37:42,240 --> 00:37:51,670
yeah not yet the question is do we

00:37:49,869 --> 00:37:53,319
support external disks for these data

00:37:51,670 --> 00:37:54,609
services not right now it's all local

00:37:53,319 --> 00:37:57,609
persistent volumes we're sort of waiting

00:37:54,609 --> 00:37:59,619
on CSI when one CSI lands we'll support

00:37:57,609 --> 00:38:03,220
that and everything that's yes I can do

00:37:59,619 --> 00:38:07,920
this we'll be able to do okay I think

00:38:03,220 --> 00:38:07,920

YouTube URL: https://www.youtube.com/watch?v=TG9To4h4MmI


