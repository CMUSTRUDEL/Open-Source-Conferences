Title: Lessons Learned: Deploying Microservices Software Product in Customer Environments
Publication date: 2017-09-18
Playlist: MesosCon North America 2017
Description: 
	Lessons Learned: Deploying Microservices Software Product in Customer Environments - Mark Galpin, JFrog, Inc.

Any team with strong DevOps practices wants to move to a microservices model to get the most out of them. But honestly, a lot of DevOps, and the best practices laid out for microservices, assumes that you have control over the deployment environment. But what if you don’t?
At JFrog we developed a microservices, cloud-native container-based design, and then we had to help our customers deploy it to diverse environments. Some of which didn’t allow containers. We will discuss our love for Apache Mesos and DC/OS, and why its always central to our thinking in deployment design, but what we do to help customers who can’t use it. What did we learn? What are we taking into older products we are now trying to break into microservices? What do we take forward? What mistakes have we sworn never to make again? Come and find out!

About

Mark Galpin
JFrog, Inc.
Senior Solution Engineer
Santa Clara, CA
Twitter Tweet  Websitejfrog.com
Mark Galpin is a Senior Solution Engineer at JFrog, experts in binary management and distribution making the products JFrog Artifactory, JFrog Bintray, and JFrog Xray. Before coming to JFrog in 2015, he spent eight years working on software, interoperability, and data standards as a contractor for the United States Army. He played a major role in a number of efforts that improved communication between army software applications on the battlefield.
Mark speaks at conferences such as JenkinsWorld, DockerCon, DevOps Days, Oracle Code and others on DevOps and container-related topics.
Captions: 
	00:00:00,030 --> 00:00:05,250
so in addition to coming out here and

00:00:01,560 --> 00:00:08,580
speaking mazes con I also get to work

00:00:05,250 --> 00:00:10,790
with partners like mesosphere on cool

00:00:08,580 --> 00:00:15,320
new things to do with J frogs products

00:00:10,790 --> 00:00:19,380
as well as work a lot with customers on

00:00:15,320 --> 00:00:23,100
how to do DevOps with the J frog tool

00:00:19,380 --> 00:00:27,779
suite so a lot of interesting different

00:00:23,100 --> 00:00:30,300
perspectives I get in my job and today

00:00:27,779 --> 00:00:32,700
as the talk of the talks as the title of

00:00:30,300 --> 00:00:34,440
the talk suggests I want to talk kind of

00:00:32,700 --> 00:00:37,910
about sort of a mix of that of kind of

00:00:34,440 --> 00:00:41,940
what was the experience of some of our

00:00:37,910 --> 00:00:44,309
R&D efforts on the one hand and versus

00:00:41,940 --> 00:00:46,440
what we expected from R&D versus kind of

00:00:44,309 --> 00:00:52,050
what happened as we got out there in the

00:00:46,440 --> 00:00:53,730
real world so to think about that you

00:00:52,050 --> 00:00:56,370
know we start with the you know core

00:00:53,730 --> 00:00:57,960
concept micro services are cool if I

00:00:56,370 --> 00:00:59,609
need to explain what a micro service is

00:00:57,960 --> 00:01:03,949
you're probably at the wrong conference

00:00:59,609 --> 00:01:06,479
so I'm gonna skip that part of things

00:01:03,949 --> 00:01:07,740
but if you do have questions about micro

00:01:06,479 --> 00:01:08,790
services and why they're cool I'd be

00:01:07,740 --> 00:01:16,229
more than happy to talk about it

00:01:08,790 --> 00:01:17,580
afterwards but a lot of the time when we

00:01:16,229 --> 00:01:18,990
think about micro services we tend to

00:01:17,580 --> 00:01:23,549
think about micro services in a SAS

00:01:18,990 --> 00:01:25,080
environment and if I now have to provide

00:01:23,549 --> 00:01:27,479
instructions for deploying your micro

00:01:25,080 --> 00:01:28,829
services environment well how many of

00:01:27,479 --> 00:01:31,680
you have a micro services environment

00:01:28,829 --> 00:01:33,180
out there and how many of you would like

00:01:31,680 --> 00:01:36,329
to try to explain to a customer how to

00:01:33,180 --> 00:01:41,579
get it set up and running yes that's

00:01:36,329 --> 00:01:43,560
what I thought no hands raised so you

00:01:41,579 --> 00:01:45,450
know this is something that we've been

00:01:43,560 --> 00:01:46,799
spending for the last year you know

00:01:45,450 --> 00:01:49,350
really putting some thought into and

00:01:46,799 --> 00:01:51,720
trying to figure out so first what's the

00:01:49,350 --> 00:01:55,439
big difference between SAS and

00:01:51,720 --> 00:01:59,790
on-premises well the big difference is

00:01:55,439 --> 00:02:01,950
ownership with a SAS environment I

00:01:59,790 --> 00:02:04,590
understand my target environment quite

00:02:01,950 --> 00:02:09,420
well I own my target environment I can

00:02:04,590 --> 00:02:12,840
change my target environment as needed I

00:02:09,420 --> 00:02:13,350
have direct access to the developers if

00:02:12,840 --> 00:02:16,380
they need to

00:02:13,350 --> 00:02:19,740
change code to conform to some aspect of

00:02:16,380 --> 00:02:21,600
the target environment each service can

00:02:19,740 --> 00:02:24,240
be individually owned by a DevOps team

00:02:21,600 --> 00:02:25,770
that takes the service from development

00:02:24,240 --> 00:02:28,230
all the way to production and owns it

00:02:25,770 --> 00:02:30,330
for the entire lifecycle where is

00:02:28,230 --> 00:02:32,790
on-premises the customer owns everything

00:02:30,330 --> 00:02:37,470
their environment has their weird quirks

00:02:32,790 --> 00:02:38,940
whatever they are the customer has to be

00:02:37,470 --> 00:02:40,440
able to take ownership the only

00:02:38,940 --> 00:02:43,260
communication the customer is going to

00:02:40,440 --> 00:02:46,890
have with the developers is going to be

00:02:43,260 --> 00:02:51,180
mediated through customer support it's a

00:02:46,890 --> 00:02:54,450
very different scenario and it's been

00:02:51,180 --> 00:02:56,550
interesting so I'm going to talk a

00:02:54,450 --> 00:03:00,090
little bit about three different

00:02:56,550 --> 00:03:03,240
products and you know we're we're kind

00:03:00,090 --> 00:03:05,070
of at so the first of products that I

00:03:03,240 --> 00:03:10,500
want to talk about is J Prague

00:03:05,070 --> 00:03:12,240
artifactory J Prague artifactory is the

00:03:10,500 --> 00:03:15,750
premier universal binary repository

00:03:12,240 --> 00:03:16,890
manager out there on the market although

00:03:15,750 --> 00:03:19,470
for the purposes of this discussion

00:03:16,890 --> 00:03:23,630
perhaps the more salient point about it

00:03:19,470 --> 00:03:26,210
is that it's you know a ten-year-olds

00:03:23,630 --> 00:03:29,820
monolithic web application architecture

00:03:26,210 --> 00:03:32,580
running on Tomcat that's been deployed

00:03:29,820 --> 00:03:35,100
to thousands of customers worldwide and

00:03:32,580 --> 00:03:36,600
tens of thousands even hundreds of

00:03:35,100 --> 00:03:40,770
thousands if you consider the open

00:03:36,600 --> 00:03:44,390
source distribution we also have J probe

00:03:40,770 --> 00:03:46,770
entry micro services SAS application

00:03:44,390 --> 00:03:50,460
does software distribution if you've

00:03:46,770 --> 00:03:52,680
used J Center maybe doing Android or

00:03:50,460 --> 00:03:54,320
Gradle development or other types of

00:03:52,680 --> 00:03:57,390
Java development or if you've used

00:03:54,320 --> 00:04:00,300
homebrew you've leveraged downloads from

00:03:57,390 --> 00:04:02,940
J frog bin tray about two billion

00:04:00,300 --> 00:04:07,380
downloads a month very scalable very

00:04:02,940 --> 00:04:10,680
micro services e been operating for

00:04:07,380 --> 00:04:14,630
about five years in the future we're

00:04:10,680 --> 00:04:14,630
going to want to take this on premises

00:04:14,660 --> 00:04:20,400
and the other project I want to talk

00:04:18,180 --> 00:04:24,780
about is J projects are a fairly new

00:04:20,400 --> 00:04:26,370
project it came out in 2016 it was

00:04:24,780 --> 00:04:28,110
designed from the start

00:04:26,370 --> 00:04:32,550
for this idea of on-premises

00:04:28,110 --> 00:04:34,440
microservices and we'll talk kind of

00:04:32,550 --> 00:04:38,669
about how in the first year and a half

00:04:34,440 --> 00:04:41,880
of its evolution what if we learned from

00:04:38,669 --> 00:04:45,630
that experience so we'll talk first

00:04:41,880 --> 00:04:48,120
about artifactory migrating that legacy

00:04:45,630 --> 00:04:51,180
monolith into a containerization into

00:04:48,120 --> 00:04:54,360
orchestration systems then we'll talk

00:04:51,180 --> 00:04:56,850
about the x-ray experience what we did

00:04:54,360 --> 00:04:59,250
over the last year and how are we taking

00:04:56,850 --> 00:05:04,830
that forward into moving Ventre

00:04:59,250 --> 00:05:08,760
on-premises so let's start here with

00:05:04,830 --> 00:05:12,260
artifactory so this is the architecture

00:05:08,760 --> 00:05:17,820
of artifactory that I started with

00:05:12,260 --> 00:05:21,240
several years ago and it's a fairly

00:05:17,820 --> 00:05:25,139
solid architecture out front you have a

00:05:21,240 --> 00:05:28,650
load balancer on the back end you have a

00:05:25,139 --> 00:05:33,780
shared storage layer of a database and

00:05:28,650 --> 00:05:34,380
some sort of file storage mechanism such

00:05:33,780 --> 00:05:38,490
as NFS

00:05:34,380 --> 00:05:43,560
and in between you have very very nearly

00:05:38,490 --> 00:05:45,810
stateless artifactory notes we thought

00:05:43,560 --> 00:05:50,030
that this was pretty much pre-made and

00:05:45,810 --> 00:05:55,860
ready to go for a cloud native

00:05:50,030 --> 00:05:59,700
application so the very first attempt we

00:05:55,860 --> 00:06:03,750
were doing back in 2015 involved work

00:05:59,700 --> 00:06:06,150
with VM orchestration with one of the

00:06:03,750 --> 00:06:10,080
major VM orchestration pass providers

00:06:06,150 --> 00:06:11,580
and we learned a lot of interesting

00:06:10,080 --> 00:06:15,720
things about our product in this first

00:06:11,580 --> 00:06:17,880
attempt and a lot about separating the

00:06:15,720 --> 00:06:22,500
application layer and the configuration

00:06:17,880 --> 00:06:25,349
layer so a real example of this is the

00:06:22,500 --> 00:06:27,720
health check pretty basic function of

00:06:25,349 --> 00:06:28,979
any sort of orchestration platform you

00:06:27,720 --> 00:06:31,080
want to have a health check artifactory

00:06:28,979 --> 00:06:34,560
has long had our really great health

00:06:31,080 --> 00:06:36,180
check you know API system ping it you

00:06:34,560 --> 00:06:38,070
know goes out it tests network

00:06:36,180 --> 00:06:39,960
connectivity but it also you know does

00:06:38,070 --> 00:06:45,509
some basic health check functions

00:06:39,960 --> 00:06:49,830
on the application itself the problem

00:06:45,509 --> 00:06:52,349
was it required a real user now if your

00:06:49,830 --> 00:06:53,970
artifactory has as many do anonymous

00:06:52,349 --> 00:06:55,830
access enabled you don't have didn't

00:06:53,970 --> 00:06:57,270
have to put any credentials in but if

00:06:55,830 --> 00:06:59,160
somebody wanted to lock down their

00:06:57,270 --> 00:07:01,530
artifactory and turn off all on honest

00:06:59,160 --> 00:07:07,590
access then you needed to insert

00:07:01,530 --> 00:07:11,389
credentials and this wasn't a problem in

00:07:07,590 --> 00:07:14,820
our SAS edition where you know we have a

00:07:11,389 --> 00:07:19,259
backdoor account that can do things like

00:07:14,820 --> 00:07:22,380
this on the systems and it's not a

00:07:19,259 --> 00:07:25,199
problem on premises where you know you

00:07:22,380 --> 00:07:26,729
own your architecture so you know where

00:07:25,199 --> 00:07:28,410
you have to go if you change the

00:07:26,729 --> 00:07:29,729
credentials of a certain service account

00:07:28,410 --> 00:07:32,159
you know all the places you have to go

00:07:29,729 --> 00:07:33,840
to make the changes but you move into an

00:07:32,159 --> 00:07:35,370
orchestration layer where the health

00:07:33,840 --> 00:07:38,970
checks are usually buried pretty deep

00:07:35,370 --> 00:07:40,770
into the code and unless you want to

00:07:38,970 --> 00:07:42,900
have a whole bunch of extra

00:07:40,770 --> 00:07:45,330
configuration that a user has to do you

00:07:42,900 --> 00:07:45,990
know they when they do things things can

00:07:45,330 --> 00:07:50,940
go badly wrong

00:07:45,990 --> 00:07:52,889
I discovered this bug when I was doing a

00:07:50,940 --> 00:07:54,449
test I happen to need to force

00:07:52,889 --> 00:07:58,500
authentication on something so I shut

00:07:54,449 --> 00:08:00,960
off anonymous access and suddenly my

00:07:58,500 --> 00:08:03,030
services all went down right because

00:08:00,960 --> 00:08:05,430
what does an orchestration layer do when

00:08:03,030 --> 00:08:07,560
you fail the helps check it takes it

00:08:05,430 --> 00:08:09,030
down and tries to restart it and it kept

00:08:07,560 --> 00:08:11,699
trying to restart it and kept trying to

00:08:09,030 --> 00:08:13,979
restart it and I was kicking myself for

00:08:11,699 --> 00:08:16,979
you know an hour trying to figure out

00:08:13,979 --> 00:08:19,409
what the heck had gone wrong and then I

00:08:16,979 --> 00:08:21,780
realized oh the reason it keeps

00:08:19,409 --> 00:08:22,830
restarting the service is that it gets

00:08:21,780 --> 00:08:28,349
to the health check and the health check

00:08:22,830 --> 00:08:30,210
fails and so we had to make a way to

00:08:28,349 --> 00:08:33,300
access the health check that was a

00:08:30,210 --> 00:08:35,579
hundred percent independent of user

00:08:33,300 --> 00:08:38,130
credentials you know I'm gonna give a

00:08:35,579 --> 00:08:39,419
lot of fairly specific examples in this

00:08:38,130 --> 00:08:41,579
because I want to tell you you know the

00:08:39,419 --> 00:08:43,440
real pains that we suffered I'm hoping

00:08:41,579 --> 00:08:45,060
that you can you know generalize these

00:08:43,440 --> 00:08:48,810
examples on your own to things in your

00:08:45,060 --> 00:08:51,260
own use case you know that you may want

00:08:48,810 --> 00:08:51,260
to think about

00:08:51,800 --> 00:08:57,920
so you know this was the first thing the

00:08:54,949 --> 00:09:02,509
first major lesson that we learned so

00:08:57,920 --> 00:09:06,069
after we done the VM orchestration you

00:09:02,509 --> 00:09:06,069
know the world evolved a little bit and

00:09:06,970 --> 00:09:14,959
you know we were looking at startup

00:09:09,860 --> 00:09:17,809
scripts the healthcheck was a continuing

00:09:14,959 --> 00:09:21,379
problem in the sense that when do you

00:09:17,809 --> 00:09:22,759
start running the health check it's a

00:09:21,379 --> 00:09:25,009
real health check so until the service

00:09:22,759 --> 00:09:26,809
is up it doesn't return okay if the

00:09:25,009 --> 00:09:28,999
service takes longer than usual to start

00:09:26,809 --> 00:09:30,889
what does that mean either I have to

00:09:28,999 --> 00:09:33,860
have some sort of very complex startup

00:09:30,889 --> 00:09:37,730
script that tries to identify when is

00:09:33,860 --> 00:09:39,799
the system actually up and somehow then

00:09:37,730 --> 00:09:41,860
wait to trigger the health check until

00:09:39,799 --> 00:09:44,660
that happens or I just wait long enough

00:09:41,860 --> 00:09:46,009
both of those answers have problems and

00:09:44,660 --> 00:09:47,899
I have to be honest we still don't have

00:09:46,009 --> 00:09:51,079
a really good satisfactory solution to

00:09:47,899 --> 00:09:53,239
that for the artifactory application in

00:09:51,079 --> 00:09:54,860
some of our orchestration solutions that

00:09:53,239 --> 00:09:57,379
we built over the years for artifactory

00:09:54,860 --> 00:09:59,869
we just wait in other ones we try the

00:09:57,379 --> 00:10:06,170
complex script approach we've run into

00:09:59,869 --> 00:10:07,549
problems both ways and we still haven't

00:10:06,170 --> 00:10:15,220
really settled on what we think the best

00:10:07,549 --> 00:10:15,220
practice is on this one yes

00:10:16,690 --> 00:10:21,069
so there's nothing wrong in artifactory

00:10:19,449 --> 00:10:23,019
you know artifactory can fail its health

00:10:21,069 --> 00:10:24,730
check and it'll sit there right but

00:10:23,019 --> 00:10:26,079
generally speaking if you fail to help

00:10:24,730 --> 00:10:28,000
check-in artifactory it means that a

00:10:26,079 --> 00:10:28,209
user will also fail to do or to do all

00:10:28,000 --> 00:10:31,920
right

00:10:28,209 --> 00:10:31,920
and in some cases Arita

00:10:33,389 --> 00:10:38,889
so startup scripts are something that

00:10:37,120 --> 00:10:41,170
have kind of been a recurring theme and

00:10:38,889 --> 00:10:42,639
we'll talk some more about them as time

00:10:41,170 --> 00:10:45,189
goes on it's something you really have

00:10:42,639 --> 00:10:46,720
to put some real thought into the

00:10:45,189 --> 00:10:50,620
startup scripts in general for our

00:10:46,720 --> 00:10:53,560
containerized versions of other

00:10:50,620 --> 00:10:56,139
applications and for orchestrating those

00:10:53,560 --> 00:11:00,250
containers tend to be more complex than

00:10:56,139 --> 00:11:01,629
when we were expecting somebody to run

00:11:00,250 --> 00:11:10,569
the startup commands from the command

00:11:01,629 --> 00:11:13,269
line so then we containerized it we'd

00:11:10,569 --> 00:11:14,889
had an RPM installed for a while

00:11:13,269 --> 00:11:16,839
the very first container we ever wrote

00:11:14,889 --> 00:11:20,350
we just installed the RPM in the

00:11:16,839 --> 00:11:23,110
container everything was good but back

00:11:20,350 --> 00:11:25,300
then at least when we went to you then

00:11:23,110 --> 00:11:26,769
make that container highly available we

00:11:25,300 --> 00:11:28,689
ran into problems that are highly

00:11:26,769 --> 00:11:30,180
available structure typically had a

00:11:28,689 --> 00:11:35,319
slightly different directory structure

00:11:30,180 --> 00:11:38,980
to manage the shared storage you ended

00:11:35,319 --> 00:11:41,019
up needing NFS which you can't really

00:11:38,980 --> 00:11:45,660
easily make NFS in containers unless

00:11:41,019 --> 00:11:45,660
you've got that built out ahead of time

00:11:46,199 --> 00:11:50,980
anybody who wanted to do a che basically

00:11:49,180 --> 00:11:55,209
they had to take our default image and

00:11:50,980 --> 00:11:58,449
build on top of it which is indeed what

00:11:55,209 --> 00:12:02,170
we did when we did our first Maysles

00:11:58,449 --> 00:12:04,329
implementation so mezzos was the first

00:12:02,170 --> 00:12:06,730
platform that we attempted to deploy

00:12:04,329 --> 00:12:09,639
containerized artifactory through

00:12:06,730 --> 00:12:11,980
orchestration with self-healing we've

00:12:09,639 --> 00:12:14,559
done it before as I said with some VM

00:12:11,980 --> 00:12:15,970
orchestration tools but the maze host

00:12:14,559 --> 00:12:18,399
really took it to the next level where

00:12:15,970 --> 00:12:22,629
you have to get much more serious about

00:12:18,399 --> 00:12:24,550
being cattle and the set of pets again

00:12:22,629 --> 00:12:27,970
thank you to the mesosphere team for

00:12:24,550 --> 00:12:30,410
assisting us with that and of course

00:12:27,970 --> 00:12:34,129
most of the self-healing aspects

00:12:30,410 --> 00:12:39,560
and the orchestration you know DCOs and

00:12:34,129 --> 00:12:42,920
marathon took care of right you know it

00:12:39,560 --> 00:12:44,180
it just works service goes down it

00:12:42,920 --> 00:12:46,490
checks its health check it'll restart

00:12:44,180 --> 00:12:49,550
itself I want to scale it horizontally

00:12:46,490 --> 00:12:52,279
it just goes and does it

00:12:49,550 --> 00:12:56,959
I need a database several great database

00:12:52,279 --> 00:13:00,139
services out there for mesosphere the

00:12:56,959 --> 00:13:02,720
problems we had were twofold the first

00:13:00,139 --> 00:13:05,569
was that the user had to supply an

00:13:02,720 --> 00:13:07,370
external NFS mount at this time in

00:13:05,569 --> 00:13:11,000
artifact thérèse architecture there was

00:13:07,370 --> 00:13:14,240
absolutely no way to start highly

00:13:11,000 --> 00:13:17,180
available artifactory without NFS you

00:13:14,240 --> 00:13:19,160
didn't need very much NFS space but

00:13:17,180 --> 00:13:21,620
certain configuration files had to be

00:13:19,160 --> 00:13:26,110
shared on NFS in certain caches had to

00:13:21,620 --> 00:13:29,870
be shared on NFS the other big issue

00:13:26,110 --> 00:13:33,560
artifactory is paid software in highly

00:13:29,870 --> 00:13:40,220
available mode and we do licensing of /

00:13:33,560 --> 00:13:42,889
running JVM and so you know the tool has

00:13:40,220 --> 00:13:44,899
things built into it to identify have I

00:13:42,889 --> 00:13:48,860
seen this license before is this license

00:13:44,899 --> 00:13:50,630
being used correctly etc and the

00:13:48,860 --> 00:13:52,699
expectation was that you would easily be

00:13:50,630 --> 00:13:54,079
able to allocate a license to a node and

00:13:52,699 --> 00:13:55,639
that you would understand that that

00:13:54,079 --> 00:13:59,089
license belonged to that node for all

00:13:55,639 --> 00:14:02,959
time and you would know you know how to

00:13:59,089 --> 00:14:04,790
replace that node etc and that wasn't

00:14:02,959 --> 00:14:07,490
true in mezzos where node IDs were

00:14:04,790 --> 00:14:09,079
changing regularly you know whenever it

00:14:07,490 --> 00:14:12,589
regenerated a node I got a different

00:14:09,079 --> 00:14:15,259
node ID different location so we had to

00:14:12,589 --> 00:14:18,230
do some fairly extensive hacking to the

00:14:15,259 --> 00:14:23,269
management of licenses in order to get

00:14:18,230 --> 00:14:25,160
it working and again I want to stress we

00:14:23,269 --> 00:14:29,240
started with effectively a stateless

00:14:25,160 --> 00:14:30,740
application on top of shared storage you

00:14:29,240 --> 00:14:32,959
know it wasn't that the core

00:14:30,740 --> 00:14:35,959
architecture of artifactory was the

00:14:32,959 --> 00:14:37,850
problem here just little tiny

00:14:35,959 --> 00:14:40,069
implementation decisions we'd made along

00:14:37,850 --> 00:14:44,330
the way that we hadn't thought about

00:14:40,069 --> 00:14:47,950
what it means when you deploy it try to

00:14:44,330 --> 00:14:47,950
something is cattle instead of a patent

00:14:48,430 --> 00:14:55,370
so this cows start a factory five so

00:14:53,450 --> 00:14:59,090
we've been on artifactory three and

00:14:55,370 --> 00:15:00,830
artifactory four before this we had to

00:14:59,090 --> 00:15:02,660
do a new major version of artifactory to

00:15:00,830 --> 00:15:07,510
react detect the system behind the

00:15:02,660 --> 00:15:07,510
scenes to address these concerns

00:15:08,260 --> 00:15:13,970
probably the very first time that we

00:15:10,640 --> 00:15:16,880
reacted artifactory not because of

00:15:13,970 --> 00:15:18,590
performance issues or because of you

00:15:16,880 --> 00:15:20,810
know any sort of issue in terms of how

00:15:18,590 --> 00:15:22,460
it was actually functioning but purely

00:15:20,810 --> 00:15:29,210
to address infrastructure related

00:15:22,460 --> 00:15:30,740
concerns so artifactory five is cloud

00:15:29,210 --> 00:15:33,830
native ready what do we have to do for

00:15:30,740 --> 00:15:35,870
it well we addressed the anonymous ping

00:15:33,830 --> 00:15:38,240
issue quite some time ago but for this

00:15:35,870 --> 00:15:39,980
the very first thing we did is we had to

00:15:38,240 --> 00:15:42,710
make it so you no longer needed shared

00:15:39,980 --> 00:15:44,690
storage for the config so the nodes had

00:15:42,710 --> 00:15:46,280
to be able to retrieve their

00:15:44,690 --> 00:15:48,350
configuration information and share it

00:15:46,280 --> 00:15:49,610
you know somebody made a change to

00:15:48,350 --> 00:15:53,680
configuration that had to be able to be

00:15:49,610 --> 00:15:53,680
shared between the nodes more easily

00:15:54,820 --> 00:16:01,270
that involved creating a slightly more

00:15:58,070 --> 00:16:03,710
extensive crosstalk between the nodes

00:16:01,270 --> 00:16:05,450
so those config files could be moved

00:16:03,710 --> 00:16:07,610
from one to the other and so that they

00:16:05,450 --> 00:16:10,510
could be and so that cached artifacts

00:16:07,610 --> 00:16:13,820
could be accessed from another node

00:16:10,510 --> 00:16:15,590
no more NFS required made a lot of

00:16:13,820 --> 00:16:17,000
customers really happy because a lot of

00:16:15,590 --> 00:16:23,600
may those implementations in the world

00:16:17,000 --> 00:16:25,250
have no access to NFS at all and the

00:16:23,600 --> 00:16:27,950
other big thing we did is we shifted the

00:16:25,250 --> 00:16:30,800
license management so that rather than

00:16:27,950 --> 00:16:32,480
licenses being managed where each node

00:16:30,800 --> 00:16:34,430
was expected to manage its own license

00:16:32,480 --> 00:16:38,720
the cluster managed the licenses

00:16:34,430 --> 00:16:41,030
holistically so that you know you put in

00:16:38,720 --> 00:16:42,620
a set of licenses built into the cluster

00:16:41,030 --> 00:16:45,200
and then it just allocates them as as

00:16:42,620 --> 00:16:49,700
nodes go up and down it gives out those

00:16:45,200 --> 00:16:55,660
licenses accordingly simple stuff in

00:16:49,700 --> 00:16:59,020
some ways but needed and so today

00:16:55,660 --> 00:17:00,430
well the it's not a master/slave it's a

00:16:59,020 --> 00:17:01,960
full active/active a che but there is

00:17:00,430 --> 00:17:03,400
still a primary node that has some

00:17:01,960 --> 00:17:06,160
special things it's still a little bit

00:17:03,400 --> 00:17:08,050
pet like for the most part we've got

00:17:06,160 --> 00:17:09,880
kind of a cloud native cattle type

00:17:08,050 --> 00:17:12,339
deployments that works for artifactory

00:17:09,880 --> 00:17:19,810
for maize O's for kubernetes for docker

00:17:12,339 --> 00:17:22,589
swarm and we've managed to break the

00:17:19,810 --> 00:17:25,420
first micro service out of this monolith

00:17:22,589 --> 00:17:28,030
we call it J frog access it manages

00:17:25,420 --> 00:17:29,650
permissions and authentication so we've

00:17:28,030 --> 00:17:31,450
started to be able to break the monolith

00:17:29,650 --> 00:17:33,610
which was the other big goal we had with

00:17:31,450 --> 00:17:35,260
artifactory v we didn't just want to

00:17:33,610 --> 00:17:37,000
become cloud native we wanted to set the

00:17:35,260 --> 00:17:40,000
architectural framework so we could

00:17:37,000 --> 00:17:42,450
start breaking our monolith up slowly

00:17:40,000 --> 00:17:45,400
but surely in a way that would be nice

00:17:42,450 --> 00:17:48,790
now it's still not separate containers

00:17:45,400 --> 00:17:52,810
it's two monoliths to war files in the

00:17:48,790 --> 00:17:56,410
same Tomcat for now but you know as our

00:17:52,810 --> 00:17:57,700
architect chief architect puts it you

00:17:56,410 --> 00:17:59,500
know it's conceptually completely

00:17:57,700 --> 00:18:01,330
separate you know they communicate with

00:17:59,500 --> 00:18:03,970
each other via REST API is that sort of

00:18:01,330 --> 00:18:08,710
thing if it's even though it's not yet

00:18:03,970 --> 00:18:11,200
deployment separate so that was one

00:18:08,710 --> 00:18:12,670
journey took a couple of years were

00:18:11,200 --> 00:18:14,680
fairly satisfied it's not to say we

00:18:12,670 --> 00:18:17,260
don't have further to go we're always

00:18:14,680 --> 00:18:19,890
working on streamlining this taking

00:18:17,260 --> 00:18:21,970
these lessons learned putting it back in

00:18:19,890 --> 00:18:23,470
artifactory was in some ways the hardest

00:18:21,970 --> 00:18:27,940
because we couldn't afford for anything

00:18:23,470 --> 00:18:30,220
to go wrong because you know thousands

00:18:27,940 --> 00:18:32,230
of customers wanting to update fairly

00:18:30,220 --> 00:18:34,810
regularly we make it too hard for them

00:18:32,230 --> 00:18:42,430
to do that and it's gonna be very very

00:18:34,810 --> 00:18:45,070
painful for us so now I want to go back

00:18:42,430 --> 00:18:50,380
and talk a little bit about the xray

00:18:45,070 --> 00:18:53,110
journey JPEG x-ray went GA just over a

00:18:50,380 --> 00:18:55,960
year ago and of course it had been in

00:18:53,110 --> 00:18:59,290
development for about six to nine months

00:18:55,960 --> 00:19:06,200
before that so basically we started it

00:18:59,290 --> 00:19:09,230
basically at the beginning of 2016 and

00:19:06,200 --> 00:19:12,410
this one you know we thought to

00:19:09,230 --> 00:19:15,320
ourselves okay you know we're creating a

00:19:12,410 --> 00:19:16,030
greenfield project we want to start from

00:19:15,320 --> 00:19:19,610
the beginning

00:19:16,030 --> 00:19:21,230
with a microservices architecture

00:19:19,610 --> 00:19:23,240
there's lots of reasons to go with

00:19:21,230 --> 00:19:25,550
micro-services we know that there's

00:19:23,240 --> 00:19:28,310
risks to deploying it on premises but

00:19:25,550 --> 00:19:29,690
with the advent of docker and containers

00:19:28,310 --> 00:19:33,140
and other things we think that this is

00:19:29,690 --> 00:19:36,680
something we can do now and this is the

00:19:33,140 --> 00:19:39,140
base architecture of X ray it's eight

00:19:36,680 --> 00:19:40,970
micro services plus one micro service

00:19:39,140 --> 00:19:47,750
that's used only during installation and

00:19:40,970 --> 00:19:51,620
upgrade three of them are three of them

00:19:47,750 --> 00:19:56,120
are kind of standard services you know a

00:19:51,620 --> 00:19:58,430
rabbit which does event queuing a

00:19:56,120 --> 00:20:01,310
and a post grass for persistence of

00:19:58,430 --> 00:20:07,010
various aspects of the data that x-ray

00:20:01,310 --> 00:20:09,200
uses and you know one web service that's

00:20:07,010 --> 00:20:15,430
the front end and then for worker

00:20:09,200 --> 00:20:21,980
services and we deployed it to docker

00:20:15,430 --> 00:20:23,660
seem pretty logical and we were fairly

00:20:21,980 --> 00:20:25,700
happy with it it had all of the growing

00:20:23,660 --> 00:20:29,090
pains you would expect with version 1.0

00:20:25,700 --> 00:20:30,680
software and there was lots of work of

00:20:29,090 --> 00:20:35,390
course to do to improve it bring in new

00:20:30,680 --> 00:20:37,430
features fix bugs etc as it came out but

00:20:35,390 --> 00:20:39,020
on the deployment side we were actually

00:20:37,430 --> 00:20:41,270
a little bit surprised we architected

00:20:39,020 --> 00:20:45,620
this thing very carefully we thought we

00:20:41,270 --> 00:20:47,780
were good and the first thing that

00:20:45,620 --> 00:20:57,230
happened is our customers said do you

00:20:47,780 --> 00:21:00,500
have an RPM for that yeah so X ray goes

00:20:57,230 --> 00:21:04,100
to you know one of its primary use cases

00:21:00,500 --> 00:21:05,600
is security and compliance the customers

00:21:04,100 --> 00:21:07,010
that are most interested in security and

00:21:05,600 --> 00:21:09,200
compliance tend to be the most

00:21:07,010 --> 00:21:12,740
conservative on their deployment

00:21:09,200 --> 00:21:14,480
architectures and very very few of them

00:21:12,740 --> 00:21:17,780
were willing to use docker containers in

00:21:14,480 --> 00:21:19,420
production period this is something

00:21:17,780 --> 00:21:23,980
that's beginning to change

00:21:19,420 --> 00:21:27,490
you know where we were at the you know

00:21:23,980 --> 00:21:31,530
in in mid-2016 is not where we are as we

00:21:27,490 --> 00:21:33,730
move into q4 of 2017 on this subject but

00:21:31,530 --> 00:21:35,740
even today you know there's a lot of

00:21:33,730 --> 00:21:37,930
customers where you say oh I want to

00:21:35,740 --> 00:21:39,670
give you a deployment based on docker

00:21:37,930 --> 00:21:41,980
and I want you to put that in production

00:21:39,670 --> 00:21:43,870
and they look at you and say yeah well

00:21:41,980 --> 00:21:47,860
someday we'll want it we'll be we want

00:21:43,870 --> 00:21:49,840
to be able to do that but not today so

00:21:47,860 --> 00:21:53,470
the first thing we've come to understand

00:21:49,840 --> 00:21:54,760
is that at least for now you know if you

00:21:53,470 --> 00:21:58,540
say you're only going to deploy on

00:21:54,760 --> 00:22:00,520
docker that's gonna severely limit who

00:21:58,540 --> 00:22:05,290
can use your software or at least what

00:22:00,520 --> 00:22:07,150
environments they can use it in so we

00:22:05,290 --> 00:22:12,400
ended up putting out rpm and debian

00:22:07,150 --> 00:22:14,700
services that you could use the second

00:22:12,400 --> 00:22:18,610
lesson is a little bit more embarrassing

00:22:14,700 --> 00:22:20,350
honestly speaking and so the second

00:22:18,610 --> 00:22:23,650
lesson is really just start like you

00:22:20,350 --> 00:22:25,120
mean to go on it's not entirely clear

00:22:23,650 --> 00:22:27,130
but hopefully when you kind of looked at

00:22:25,120 --> 00:22:28,180
that architecture you know it was an

00:22:27,130 --> 00:22:31,030
event-based worker queue

00:22:28,180 --> 00:22:34,660
producer-consumer queueing very scalable

00:22:31,030 --> 00:22:38,770
horizontally should be very easy to go

00:22:34,660 --> 00:22:40,360
highly available but you know for the

00:22:38,770 --> 00:22:43,090
1-0 release in the interest of

00:22:40,360 --> 00:22:45,700
simplicity we focused on I want to be

00:22:43,090 --> 00:22:52,630
able to deploy it with docker compose to

00:22:45,700 --> 00:22:55,840
one server and it took us most of a year

00:22:52,630 --> 00:22:57,310
to find all of the things that you know

00:22:55,840 --> 00:22:59,860
based on that that that was our only

00:22:57,310 --> 00:23:01,690
testing infrastructure to find all of

00:22:59,860 --> 00:23:05,940
the places where we made assumptions

00:23:01,690 --> 00:23:09,370
about how the file system works about

00:23:05,940 --> 00:23:11,710
what the IPS were you know just little

00:23:09,370 --> 00:23:12,610
places where a developer had hard-coded

00:23:11,710 --> 00:23:15,670
something they should not have

00:23:12,610 --> 00:23:17,440
hard-coded and it always worked because

00:23:15,670 --> 00:23:25,840
it was always deployed in exactly the

00:23:17,440 --> 00:23:27,070
same way so this problem you know we

00:23:25,840 --> 00:23:28,540
should have known better we're a company

00:23:27,070 --> 00:23:31,330
that advocates for DevOps for our

00:23:28,540 --> 00:23:32,740
customers for ourselves and basically

00:23:31,330 --> 00:23:33,040
what happened here is that we let the

00:23:32,740 --> 00:23:35,080
develop

00:23:33,040 --> 00:23:36,040
purrs go off without really talking

00:23:35,080 --> 00:23:39,610
about what the deployment architecture

00:23:36,040 --> 00:23:41,740
would really look like and you know how

00:23:39,610 --> 00:23:43,870
how to deploy it as being a primary

00:23:41,740 --> 00:23:46,870
concern from the beginning and its cost

00:23:43,870 --> 00:23:50,460
us and it's something that we probably

00:23:46,870 --> 00:23:50,460
aren't going to make that mistake again

00:23:51,330 --> 00:24:01,050
and kind of along the same lines it's

00:23:55,390 --> 00:24:07,210
about flexibility on a deployment side

00:24:01,050 --> 00:24:09,430
every fourth customer for a very long

00:24:07,210 --> 00:24:11,860
time maybe faster than that at the very

00:24:09,430 --> 00:24:13,180
beginning was asking for more

00:24:11,860 --> 00:24:14,020
flexibility in their deployment

00:24:13,180 --> 00:24:18,400
architecture than we'd originally

00:24:14,020 --> 00:24:20,740
planned whether that was hey I see you

00:24:18,400 --> 00:24:22,360
have a post grass container my policy

00:24:20,740 --> 00:24:23,830
says that I'm only allowed to use the

00:24:22,360 --> 00:24:27,190
official blessed version of post grass

00:24:23,830 --> 00:24:28,480
at my company I can't use your post

00:24:27,190 --> 00:24:37,000
grass container I need to reuse my own

00:24:28,480 --> 00:24:42,480
post grass database or I need to specify

00:24:37,000 --> 00:24:45,820
custom paths because by policy this

00:24:42,480 --> 00:24:49,270
partition in the file system can only be

00:24:45,820 --> 00:24:50,920
one gigabyte to prevent people from from

00:24:49,270 --> 00:24:52,570
storing certain types of data on it and

00:24:50,920 --> 00:24:53,710
you're storing those types of data

00:24:52,570 --> 00:24:54,790
you're not supposed to store I need to

00:24:53,710 --> 00:25:00,240
be able to store that data in a

00:24:54,790 --> 00:25:04,420
different path on my file system or I

00:25:00,240 --> 00:25:06,130
don't have access to the web I can't

00:25:04,420 --> 00:25:09,370
upgrade my docker containers because I

00:25:06,130 --> 00:25:11,650
can't do darker pull to your main docker

00:25:09,370 --> 00:25:13,150
registry I need to be able to pull your

00:25:11,650 --> 00:25:15,460
containers down to a private docker

00:25:13,150 --> 00:25:18,670
registry and manage the services that

00:25:15,460 --> 00:25:20,590
way that one's particularly embarrassing

00:25:18,670 --> 00:25:22,120
for us in the sense that we're one of

00:25:20,590 --> 00:25:24,640
the primary providers or private Dhokla

00:25:22,120 --> 00:25:25,810
registries out there and we hadn't

00:25:24,640 --> 00:25:31,030
considered the need for people to be

00:25:25,810 --> 00:25:32,350
able to use it but no I mean flexibility

00:25:31,030 --> 00:25:34,210
and deployment architectures again it

00:25:32,350 --> 00:25:36,990
comes down to that fact you don't

00:25:34,210 --> 00:25:40,450
control the customer environment and

00:25:36,990 --> 00:25:43,540
customers have really really weird

00:25:40,450 --> 00:25:46,000
requirements sometimes that made sense

00:25:43,540 --> 00:25:46,300
20 years ago and they will even admit to

00:25:46,000 --> 00:25:50,170
you

00:25:46,300 --> 00:25:51,880
make no sense today but you know if they

00:25:50,170 --> 00:25:54,490
have to figure out a way to change them

00:25:51,880 --> 00:25:56,740
you know deploying your software is

00:25:54,490 --> 00:25:58,600
gonna go from something that you know

00:25:56,740 --> 00:25:59,860
they should be able to do in a day to

00:25:58,600 --> 00:26:09,160
something that takes a year's worth of

00:25:59,860 --> 00:26:11,290
paperwork so finally with x-ray I wanted

00:26:09,160 --> 00:26:15,190
to get back to the question of startup

00:26:11,290 --> 00:26:16,900
scripts so with artifactory

00:26:15,190 --> 00:26:19,570
there were a lot of kind of complex

00:26:16,900 --> 00:26:20,890
factors in the startup script x-ray was

00:26:19,570 --> 00:26:24,610
built as a micro services architecture

00:26:20,890 --> 00:26:27,930
from the start so the services are truly

00:26:24,610 --> 00:26:31,210
completely stateless between each other

00:26:27,930 --> 00:26:32,740
there's no dependencies for one you know

00:26:31,210 --> 00:26:34,060
there's no requirement that one service

00:26:32,740 --> 00:26:36,910
be opted in order for another one to

00:26:34,060 --> 00:26:40,300
start or anything like that

00:26:36,910 --> 00:26:44,470
despite that when we actually run our

00:26:40,300 --> 00:26:46,900
official you know x-ray start script we

00:26:44,470 --> 00:26:48,370
actually do before we start each service

00:26:46,900 --> 00:26:52,920
confirm that the dependencies are there

00:26:48,370 --> 00:26:56,950
that allow that service to operate fully

00:26:52,920 --> 00:26:58,840
we went back and forth on this a lot did

00:26:56,950 --> 00:27:00,220
we want to do this or not and and we

00:26:58,840 --> 00:27:02,740
looked around we tried to do some

00:27:00,220 --> 00:27:05,110
investigation because effectively what

00:27:02,740 --> 00:27:07,270
we're doing is introducing state into

00:27:05,110 --> 00:27:12,850
our startup script that theoretically

00:27:07,270 --> 00:27:16,380
doesn't need to be there and you might

00:27:12,850 --> 00:27:22,720
ask why on earth would you do that and

00:27:16,380 --> 00:27:24,580
the answer is that our customers mostly

00:27:22,720 --> 00:27:27,760
came from a world of deploying

00:27:24,580 --> 00:27:30,070
monolithic applications and they're

00:27:27,760 --> 00:27:32,560
accustomed to an idea that when the

00:27:30,070 --> 00:27:34,870
startup script finishes and says this

00:27:32,560 --> 00:27:39,550
application is started they can start

00:27:34,870 --> 00:27:41,530
using it and so we had deployed this

00:27:39,550 --> 00:27:43,540
state basically to make it easier for a

00:27:41,530 --> 00:27:46,690
customer to understand what was going

00:27:43,540 --> 00:27:51,550
wrong if anything when they tried to

00:27:46,690 --> 00:27:53,890
start the system it was an interesting

00:27:51,550 --> 00:27:55,240
decision like I said it's a matter of at

00:27:53,890 --> 00:27:58,990
some level it's a matter of personal

00:27:55,240 --> 00:27:59,920
taste but we felt based on what we were

00:27:58,990 --> 00:28:01,740
seeing that it made it

00:27:59,920 --> 00:28:04,900
easier for the customer to understand

00:28:01,740 --> 00:28:09,120
what was happening at deploy time and to

00:28:04,900 --> 00:28:09,120
track how the architecture really worked

00:28:09,270 --> 00:28:16,570
and so you have to kind of I guess the

00:28:15,190 --> 00:28:18,640
real lesson here isn't really so much

00:28:16,570 --> 00:28:20,500
about startup scripts is about trying to

00:28:18,640 --> 00:28:27,750
make it easier for the customers

00:28:20,500 --> 00:28:33,660
headspace to track this system so

00:28:27,750 --> 00:28:38,050
artifactory and x-ray moving forward

00:28:33,660 --> 00:28:40,120
bean tray on-premises and in fact an

00:28:38,050 --> 00:28:43,120
entirely new initiative that goes with

00:28:40,120 --> 00:28:47,650
that we call the j frog platform so what

00:28:43,120 --> 00:28:52,900
do I mean by that well this is the

00:28:47,650 --> 00:28:54,460
architecture of the platform and the

00:28:52,900 --> 00:28:58,840
numbers that you see next to each name

00:28:54,460 --> 00:29:01,300
are how many micro services I think are

00:28:58,840 --> 00:29:03,100
in each one it's a little bit

00:29:01,300 --> 00:29:04,930
indeterminate for some of these and this

00:29:03,100 --> 00:29:07,900
is more or less the count as it stands

00:29:04,930 --> 00:29:10,630
today or as it's currently projected so

00:29:07,900 --> 00:29:13,030
J frog access is going to be one service

00:29:10,630 --> 00:29:15,460
artifactory will probably be around two

00:29:13,030 --> 00:29:18,370
services by the time this is deployed J

00:29:15,460 --> 00:29:19,900
frog x-ray is currently nine J frog

00:29:18,370 --> 00:29:22,450
mission control is looking like it's

00:29:19,900 --> 00:29:26,860
going to be about five and J frog bin

00:29:22,450 --> 00:29:28,570
tray today is twenty five or more and

00:29:26,860 --> 00:29:31,330
that twenty five or more is a pretty

00:29:28,570 --> 00:29:33,880
scary number you know again this is a

00:29:31,330 --> 00:29:37,630
SAS architecture you know it runs in

00:29:33,880 --> 00:29:44,290
about 60 containers and service service

00:29:37,630 --> 00:29:46,180
options globally and as we're looking to

00:29:44,290 --> 00:29:48,210
move Ventre on-premises as well as

00:29:46,180 --> 00:29:50,290
provide sort of this integrated

00:29:48,210 --> 00:29:52,840
deployment architecture to deploy all of

00:29:50,290 --> 00:29:54,550
the tools together we really are

00:29:52,840 --> 00:29:58,900
thinking carefully about what have we

00:29:54,550 --> 00:30:01,060
learned over the last several years from

00:29:58,900 --> 00:30:02,800
the artifactory journey from the X ray

00:30:01,060 --> 00:30:06,390
journey and how are we going to carry

00:30:02,800 --> 00:30:06,390
that forward into the next one

00:30:08,319 --> 00:30:16,729
so what are we going to do so the first

00:30:12,769 --> 00:30:19,309
thing that we've decided which hopefully

00:30:16,729 --> 00:30:25,609
isn't a surprise to anybody is that

00:30:19,309 --> 00:30:28,190
simple is better when we started with

00:30:25,609 --> 00:30:29,989
x-ray in particular you know figuring

00:30:28,190 --> 00:30:31,999
out how do you debug a set of 30

00:30:29,989 --> 00:30:34,069
micro-services when something a set of

00:30:31,999 --> 00:30:37,369
even eight micro-services when something

00:30:34,069 --> 00:30:40,369
goes wrong debug remotely again by

00:30:37,369 --> 00:30:41,929
customer support not you know able to go

00:30:40,369 --> 00:30:47,419
in and and instrument the service

00:30:41,929 --> 00:30:50,089
directly whenever you want to the idea

00:30:47,419 --> 00:30:54,979
of trying to do that for 40 services at

00:30:50,089 --> 00:30:56,359
once scares us so on the one hand we

00:30:54,979 --> 00:30:58,099
want to try to consolidate our

00:30:56,359 --> 00:31:02,869
infrastructure services as best we can

00:30:58,099 --> 00:31:05,569
at a given location and also while we

00:31:02,869 --> 00:31:07,369
want to keep with small services so that

00:31:05,569 --> 00:31:09,979
you have that scalability you have that

00:31:07,369 --> 00:31:14,449
developer flexibility and that micro

00:31:09,979 --> 00:31:17,029
services provide we also want to pay

00:31:14,449 --> 00:31:18,769
attention to proliferating services it's

00:31:17,029 --> 00:31:20,179
not like a SAS environment where it's

00:31:18,769 --> 00:31:23,079
actually cheaper to proliferate a new

00:31:20,179 --> 00:31:28,789
service in some ways than it is to

00:31:23,079 --> 00:31:30,739
consolidate old ones so it's a little

00:31:28,789 --> 00:31:31,869
bit of a violation of the pure micro

00:31:30,739 --> 00:31:34,159
services architecture

00:31:31,869 --> 00:31:35,869
I'm almost calling it more of the small

00:31:34,159 --> 00:31:41,569
services rather than the micro services

00:31:35,869 --> 00:31:43,940
architecture but we think it's going to

00:31:41,569 --> 00:31:47,149
be important at least until the market

00:31:43,940 --> 00:31:51,529
matures more on how you do this sort of

00:31:47,149 --> 00:31:53,359
thing the second thing is we are going

00:31:51,529 --> 00:31:55,489
to start with that enterprise

00:31:53,359 --> 00:31:57,619
architecture deployment we're gonna plan

00:31:55,489 --> 00:31:59,659
for scalability and flexibility not just

00:31:57,619 --> 00:32:02,149
from an architectural perspective which

00:31:59,659 --> 00:32:04,249
we did quite well with x-ray I mean the

00:32:02,149 --> 00:32:06,829
architecture was never broken for

00:32:04,249 --> 00:32:08,569
scalability and flexibility just the

00:32:06,829 --> 00:32:11,419
deployment model so from the beginning

00:32:08,569 --> 00:32:13,279
we're gonna deploy it and test it with

00:32:11,419 --> 00:32:17,899
the idea that that's our target

00:32:13,279 --> 00:32:19,249
environment and try to build in some of

00:32:17,899 --> 00:32:20,880
the different types of customer

00:32:19,249 --> 00:32:25,650
environments that we've learned

00:32:20,880 --> 00:32:27,870
as we do this and as part of that we're

00:32:25,650 --> 00:32:30,780
actually going to start with container

00:32:27,870 --> 00:32:34,050
orchestration implication because what

00:32:30,780 --> 00:32:35,010
we've learned from artifactory is that

00:32:34,050 --> 00:32:36,570
the container orchestration

00:32:35,010 --> 00:32:40,110
implementation imposes the most

00:32:36,570 --> 00:32:41,910
discipline on you on making sure that

00:32:40,110 --> 00:32:45,540
you've actually created proper cattle

00:32:41,910 --> 00:32:47,220
services you know there's a lot of

00:32:45,540 --> 00:32:49,530
cheats you can do with pretty much any

00:32:47,220 --> 00:32:52,410
other implementation that proper

00:32:49,530 --> 00:32:54,180
containerization at least doesn't make

00:32:52,410 --> 00:32:56,640
impossible you can always cheat the

00:32:54,180 --> 00:33:01,140
system if you want to but it makes it

00:32:56,640 --> 00:33:02,820
much harder so we're going to start with

00:33:01,140 --> 00:33:05,160
the container orchestration mechanism as

00:33:02,820 --> 00:33:06,450
we do this but we're also bearing in

00:33:05,160 --> 00:33:07,680
mind from the beginning we're probably

00:33:06,450 --> 00:33:08,970
not going to be able to end there we're

00:33:07,680 --> 00:33:11,870
probably going to have to be able to

00:33:08,970 --> 00:33:15,690
build you know platform native

00:33:11,870 --> 00:33:20,330
distributions for CentOS and the various

00:33:15,690 --> 00:33:22,800
Debian flavored distributions

00:33:20,330 --> 00:33:26,010
you know rpm and Debian releases are

00:33:22,800 --> 00:33:32,280
pretty much an a must still and you know

00:33:26,010 --> 00:33:36,360
possibly even a Windows one and you know

00:33:32,280 --> 00:33:37,710
that's gonna be a bit of a challenge but

00:33:36,360 --> 00:33:38,850
like I said we're going to start with

00:33:37,710 --> 00:33:40,920
container orchestration because we

00:33:38,850 --> 00:33:46,740
consider that to impose the right

00:33:40,920 --> 00:33:52,380
architectural discipline on us so

00:33:46,740 --> 00:33:54,720
finally as my final takeaway it's really

00:33:52,380 --> 00:33:55,590
one word hopefully it's a word that

00:33:54,720 --> 00:33:58,920
you've heard before

00:33:55,590 --> 00:34:01,020
DevOps so DevOps means a little bit

00:33:58,920 --> 00:34:05,550
different thing when you're talking

00:34:01,020 --> 00:34:08,280
about on-premises software because

00:34:05,550 --> 00:34:11,669
you're no longer talking about owning a

00:34:08,280 --> 00:34:14,040
service in production by definition you

00:34:11,669 --> 00:34:17,879
can't own a service in a customer in a

00:34:14,040 --> 00:34:20,490
customer owned environment but it does

00:34:17,879 --> 00:34:22,860
mean that the people that are

00:34:20,490 --> 00:34:26,970
responsible for managing packaging and

00:34:22,860 --> 00:34:29,129
deployment of the system and testing

00:34:26,970 --> 00:34:31,500
sort of the deployment side of things

00:34:29,129 --> 00:34:33,280
need to be working very closely with the

00:34:31,500 --> 00:34:38,590
developers from the beginning

00:34:33,280 --> 00:34:41,860
and the values of DevOps may remain the

00:34:38,590 --> 00:34:44,830
value of ownership of all aspects of the

00:34:41,860 --> 00:34:50,649
architecture remain throughout the

00:34:44,830 --> 00:34:54,010
system so yeah hopefully you found this

00:34:50,649 --> 00:34:56,320
interesting I'd love be happy to take

00:34:54,010 --> 00:34:58,300
any questions you have it looks like

00:34:56,320 --> 00:35:01,030
I've got about five minutes for

00:34:58,300 --> 00:35:03,310
questions oh and by the way also if you

00:35:01,030 --> 00:35:05,380
want to come work on this sort of lovely

00:35:03,310 --> 00:35:07,410
stuff J froggy is hiring feel free to

00:35:05,380 --> 00:35:12,560
talk to me about that afterwards as well

00:35:07,410 --> 00:35:15,739
any questions yes

00:35:12,560 --> 00:35:15,739
[Music]

00:35:16,240 --> 00:35:21,610
configuration for things like paths or

00:35:18,970 --> 00:35:24,030
anything else how are you guys

00:35:21,610 --> 00:35:26,380
managing those as inputs from these

00:35:24,030 --> 00:35:28,750
customer environments and I think this

00:35:26,380 --> 00:35:31,930
isn't like a docker file and change or

00:35:28,750 --> 00:35:34,330
something like that no that's a great

00:35:31,930 --> 00:35:36,760
question so pretty much any of the the

00:35:34,330 --> 00:35:39,880
pass or maze osore you know any of these

00:35:36,760 --> 00:35:41,740
they have some set of inputs that the

00:35:39,880 --> 00:35:45,040
customer is expected to fill out and so

00:35:41,740 --> 00:35:46,030
we want to have those configurations you

00:35:45,040 --> 00:35:48,100
know the things that are customer

00:35:46,030 --> 00:35:50,320
specific you want to expose but you want

00:35:48,100 --> 00:35:53,830
to have as few settings there as

00:35:50,320 --> 00:35:56,590
possible obviously to keep that simple

00:35:53,830 --> 00:35:58,450
the rest you try to bury underneath you

00:35:56,590 --> 00:36:00,850
know detect the situation and make the

00:35:58,450 --> 00:36:03,130
best decision based on what you detect

00:36:00,850 --> 00:36:09,910
when you get to the environment that

00:36:03,130 --> 00:36:13,000
makes sense with regard to getting rid

00:36:09,910 --> 00:36:15,280
of an NFS in artifactory once you move

00:36:13,000 --> 00:36:17,830
to a more containerized stance what did

00:36:15,280 --> 00:36:20,220
you end up doing for storage for larger

00:36:17,830 --> 00:36:24,910
repositories and whatnot

00:36:20,220 --> 00:36:26,470
excellent questions so the storage

00:36:24,910 --> 00:36:29,080
solution then is object stores basically

00:36:26,470 --> 00:36:30,940
anything that follows the s3 API or the

00:36:29,080 --> 00:36:32,830
Google Cloud API or the Azure you know

00:36:30,940 --> 00:36:35,710
the sort of cloud native API is but the

00:36:32,830 --> 00:36:37,600
s3 API in particular you know is fairly

00:36:35,710 --> 00:36:39,910
widely followed with on-premises you can

00:36:37,600 --> 00:36:41,740
get several implementations in may Zoe's

00:36:39,910 --> 00:36:43,930
of several storage solutions for example

00:36:41,740 --> 00:36:45,550
that do that you know most container

00:36:43,930 --> 00:36:46,309
platforms have some sort of solution

00:36:45,550 --> 00:36:53,209
that will give me

00:36:46,309 --> 00:36:54,680
three Gateway other questions when you

00:36:53,209 --> 00:36:57,289
guys were building your micro services

00:36:54,680 --> 00:37:00,019
how did you wanna things we run into is

00:36:57,289 --> 00:37:01,489
is that kind of conflicts with the don't

00:37:00,019 --> 00:37:04,430
repeat yourself principle in your code

00:37:01,489 --> 00:37:05,900
where you don't want to use the same how

00:37:04,430 --> 00:37:07,339
do you deal with those those common

00:37:05,900 --> 00:37:08,809
things that you do in every micro

00:37:07,339 --> 00:37:10,579
service do you do you have like a

00:37:08,809 --> 00:37:12,019
utility library or you just make each

00:37:10,579 --> 00:37:17,660
developer just implement the same

00:37:12,019 --> 00:37:21,589
requirements so with the common things

00:37:17,660 --> 00:37:23,809
that we do you know a lot of that comes

00:37:21,589 --> 00:37:25,749
down to building a base docker container

00:37:23,809 --> 00:37:28,309
that has those common elements built in

00:37:25,749 --> 00:37:30,009
so this is where kind of the layering of

00:37:28,309 --> 00:37:32,719
docker containers can be really awesome

00:37:30,009 --> 00:37:34,549
so if there are common elements then

00:37:32,719 --> 00:37:36,349
I'll build you know some sort of very

00:37:34,549 --> 00:37:38,719
thin application layer that implements

00:37:36,349 --> 00:37:41,630
those common common elements and then

00:37:38,719 --> 00:37:42,829
I'll share that container so that I

00:37:41,630 --> 00:37:45,439
don't have to re-implement the code

00:37:42,829 --> 00:37:47,569
that's the ideal scenario like everybody

00:37:45,439 --> 00:37:48,949
in the world for as long as we've been

00:37:47,569 --> 00:37:52,189
talking about common elements cut and

00:37:48,949 --> 00:37:53,630
paste still happens of course but we've

00:37:52,189 --> 00:37:59,420
gotten a lot better about it I think

00:37:53,630 --> 00:38:05,179
over time but yeah that's basically how

00:37:59,420 --> 00:38:07,939
we do it okay could you please maybe

00:38:05,179 --> 00:38:10,929
disclosure how the biggest issues you

00:38:07,939 --> 00:38:14,449
met when containerized in your

00:38:10,929 --> 00:38:20,259
application so what's the best over the

00:38:14,449 --> 00:38:20,259
worst cases you met during this road

00:38:21,670 --> 00:38:27,049
yeah no I I understand what you're

00:38:23,989 --> 00:38:29,329
saying I mean in some ways I shared some

00:38:27,049 --> 00:38:32,029
of them so for container izing the

00:38:29,329 --> 00:38:34,279
monolith is a single standalone you know

00:38:32,029 --> 00:38:37,779
one container service that was pretty

00:38:34,279 --> 00:38:37,779
easy you know I mean

00:38:53,000 --> 00:39:06,710
yeah yeah

00:39:03,759 --> 00:39:08,779
yeah no this this is yes so as I said

00:39:06,710 --> 00:39:10,940
for a standalone service right there

00:39:08,779 --> 00:39:13,700
weren't a lot of issues when we got into

00:39:10,940 --> 00:39:15,589
the highly available service we're now

00:39:13,700 --> 00:39:19,400
the containers need to communicate with

00:39:15,589 --> 00:39:22,430
each other at some level a lot of it did

00:39:19,400 --> 00:39:25,039
really come down to while the system was

00:39:22,430 --> 00:39:26,839
robust against fairly standard network

00:39:25,039 --> 00:39:29,210
failures you know I mean that's been

00:39:26,839 --> 00:39:31,579
built in from you know from much earlier

00:39:29,210 --> 00:39:33,200
when we done kind of the original you

00:39:31,579 --> 00:39:37,400
know hand-built highly available

00:39:33,200 --> 00:39:39,319
versions of artifactory we still

00:39:37,400 --> 00:39:41,779
discovered that a lot of those kind of

00:39:39,319 --> 00:39:43,819
assumed static infrastructure right I

00:39:41,779 --> 00:39:46,220
had to be able to put the IP address in

00:39:43,819 --> 00:39:48,049
of all of the different nodes in my

00:39:46,220 --> 00:39:50,660
cluster and know that ahead of time and

00:39:48,049 --> 00:39:52,369
as you go to container orchestration as

00:39:50,660 --> 00:39:54,740
you say that can get a little bit more

00:39:52,369 --> 00:39:56,539
complicated as the orchestration tools

00:39:54,740 --> 00:39:58,190
get more sophisticated interestingly

00:39:56,539 --> 00:40:00,200
enough that's getting back easier again

00:39:58,190 --> 00:40:02,960
because the orchestration tools are

00:40:00,200 --> 00:40:04,309
getting good enough to the point where I

00:40:02,960 --> 00:40:05,869
can actually start making some

00:40:04,309 --> 00:40:07,430
assumptions I can't quite go as far as

00:40:05,869 --> 00:40:09,859
assuming static IPS but I can at least

00:40:07,430 --> 00:40:11,480
make some pretty basic assumptions about

00:40:09,859 --> 00:40:13,519
how the networks are structured and how

00:40:11,480 --> 00:40:15,170
they you know and how they relate to

00:40:13,519 --> 00:40:16,910
each other in that it's gonna pass in

00:40:15,170 --> 00:40:18,920
from the network layer of the

00:40:16,910 --> 00:40:21,950
orchestration system and there's

00:40:18,920 --> 00:40:26,569
well-understood mechanisms to ask to

00:40:21,950 --> 00:40:28,940
access and to poll that network layer so

00:40:26,569 --> 00:40:31,309
in reality that aspect of things I mean

00:40:28,940 --> 00:40:33,710
setting aside those places where we had

00:40:31,309 --> 00:40:36,019
stuff hard-coded and we had to learn

00:40:33,710 --> 00:40:37,849
okay you know I've got to pass in this

00:40:36,019 --> 00:40:41,150
variable or on startup I've got to go

00:40:37,849 --> 00:40:44,690
ask you know go ask this thing what I

00:40:41,150 --> 00:40:46,460
should put here that part was actually

00:40:44,690 --> 00:40:48,259
the network layer was in some ways the

00:40:46,460 --> 00:40:51,619
easy part this is what the orchestration

00:40:48,259 --> 00:40:56,710
system handles for you as it were is to

00:40:51,619 --> 00:41:00,049
try to make that as easy as possible but

00:40:56,710 --> 00:41:01,880
you know there were you know it's always

00:41:00,049 --> 00:41:03,529
about where are the places where I

00:41:01,880 --> 00:41:06,680
assume that I understand my

00:41:03,529 --> 00:41:08,869
infrastructure and in an orchestration

00:41:06,680 --> 00:41:10,730
system even in an orchestration system

00:41:08,869 --> 00:41:12,349
as much as they try to make it so that

00:41:10,730 --> 00:41:14,029
the infrastructure is clearly

00:41:12,349 --> 00:41:15,920
understandable the level of

00:41:14,029 --> 00:41:17,060
understanding is not the same as a

00:41:15,920 --> 00:41:19,280
static

00:41:17,060 --> 00:41:21,410
infrastructure and those are the places

00:41:19,280 --> 00:41:23,120
where we always run into trouble is you

00:41:21,410 --> 00:41:24,350
know I assume that I understand how

00:41:23,120 --> 00:41:26,600
these two things are going to connect to

00:41:24,350 --> 00:41:28,460
each other I may not know what that is

00:41:26,600 --> 00:41:31,460
ahead of time but I assume whoever is

00:41:28,460 --> 00:41:33,590
installing it understands it and knows

00:41:31,460 --> 00:41:36,530
how to make point a and point B talk to

00:41:33,590 --> 00:41:38,480
each other and so those are the things

00:41:36,530 --> 00:41:41,270
that really get you pretty much every

00:41:38,480 --> 00:41:44,930
time on premises is that suddenly as you

00:41:41,270 --> 00:41:47,450
move to a past platform right you're

00:41:44,930 --> 00:41:50,510
you're you're at a situation where

00:41:47,450 --> 00:41:52,490
you're hiding from the consumer the

00:41:50,510 --> 00:41:54,170
ability to alter those things if they're

00:41:52,490 --> 00:41:56,210
doing something weird that you didn't

00:41:54,170 --> 00:41:57,710
expect and so you actually have to study

00:41:56,210 --> 00:42:00,080
that past service and say what are all

00:41:57,710 --> 00:42:07,100
the weird things somebody can do and how

00:42:00,080 --> 00:42:08,300
do i account for them yes I think I have

00:42:07,100 --> 00:42:12,770
time for one more question

00:42:08,300 --> 00:42:17,050
oh no I'm done okay thank you very much

00:42:12,770 --> 00:42:17,050

YouTube URL: https://www.youtube.com/watch?v=_NZtvo6mz9o


