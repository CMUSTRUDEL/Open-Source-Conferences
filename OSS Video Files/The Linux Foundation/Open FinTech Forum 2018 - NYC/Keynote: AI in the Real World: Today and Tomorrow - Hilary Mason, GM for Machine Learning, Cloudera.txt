Title: Keynote: AI in the Real World: Today and Tomorrow - Hilary Mason, GM for Machine Learning, Cloudera
Publication date: 2018-10-11
Playlist: Open FinTech Forum 2018 - NYC
Description: 
	Keynote: AI in the Real World: Today and Tomorrow - Hilary Mason, General Manager for Machine Learning, ClouderaÂ 

About Hilary Mason
Hilary Mason is the General Manager for Machine Learning at Cloudera. Previously, she founded Fast Forward Labs, an applied machine learning research and advisory company, which was acquired by Cloudera in 2017. Hilary is the Data Scientist in Residence at Accel Partners and is on the board of the Anita Borg Institute. Previously, she co-founded HackNY.org, a non-profit that helps engineering students find opportunities in New York's creative technical economy, served on Mayer Bloomberg's Technology Advisory Council and was the Chief Scientist at Bitly. Hilary can be reached on Twitter @hmason and on LinkedIn.
Captions: 
	00:00:00,000 --> 00:00:04,080
[Music]

00:00:01,100 --> 00:00:06,660
and it's really fun for me to follow a

00:00:04,080 --> 00:00:09,179
talk about you know essentially

00:00:06,660 --> 00:00:10,349
blockchain technologies and distributed

00:00:09,179 --> 00:00:12,960
Ledger's because I'm talking about

00:00:10,349 --> 00:00:15,000
something entirely different so we'll

00:00:12,960 --> 00:00:19,170
have a bit of intellectual whiplash this

00:00:15,000 --> 00:00:21,539
morning so just so you know my

00:00:19,170 --> 00:00:23,070
perspective on the world is that I am a

00:00:21,539 --> 00:00:24,660
computer scientist I've worked in

00:00:23,070 --> 00:00:27,420
machine learning and data science for a

00:00:24,660 --> 00:00:29,070
very long time and most recently have

00:00:27,420 --> 00:00:31,260
been working in the context of the

00:00:29,070 --> 00:00:33,450
enterprise but not only in financial

00:00:31,260 --> 00:00:36,719
services so financial services is the

00:00:33,450 --> 00:00:39,570
largest cluster of companies that we do

00:00:36,719 --> 00:00:41,309
work with and certainly there are many

00:00:39,570 --> 00:00:42,960
interesting use cases there and I'll

00:00:41,309 --> 00:00:45,690
touch on several of those as I go

00:00:42,960 --> 00:00:47,879
through the talk but but I like to

00:00:45,690 --> 00:00:50,239
maintain a pretty broad perspective on

00:00:47,879 --> 00:00:52,800
the world and look at you know use cases

00:00:50,239 --> 00:00:55,050
for machine learning and AI technology

00:00:52,800 --> 00:00:57,090
that cross everything from sort of

00:00:55,050 --> 00:00:58,800
consumer applications through retail

00:00:57,090 --> 00:01:03,780
lots of pharmaceutical health care

00:00:58,800 --> 00:01:07,080
insurance financial services wherever

00:01:03,780 --> 00:01:09,119
else we may go and so I wanted to say

00:01:07,080 --> 00:01:11,670
good morning I hope that you will walk

00:01:09,119 --> 00:01:13,380
out of my talk with an understanding of

00:01:11,670 --> 00:01:15,060
the current state of what is actually

00:01:13,380 --> 00:01:18,330
practical with AI and machine learning

00:01:15,060 --> 00:01:20,250
and a few new ideas and also a process

00:01:18,330 --> 00:01:21,990
for thinking through those ideas and

00:01:20,250 --> 00:01:24,270
doing your own technical discovery and

00:01:21,990 --> 00:01:26,340
diligence in the space and so that's my

00:01:24,270 --> 00:01:27,840
goal for the next 20 minutes I have a

00:01:26,340 --> 00:01:29,520
lot of material and so I'm going to talk

00:01:27,840 --> 00:01:31,890
through it really fast but if you have

00:01:29,520 --> 00:01:34,170
any questions you can find me later or

00:01:31,890 --> 00:01:37,340
you can find me on Twitter at each Mason

00:01:34,170 --> 00:01:40,530
or Hillary at Cloudera comm with one out

00:01:37,340 --> 00:01:42,780
we are living in the future it is just

00:01:40,530 --> 00:01:45,570
unevenly distributed if you want to see

00:01:42,780 --> 00:01:47,579
hilarious stock photos look for stock

00:01:45,570 --> 00:01:50,579
photos of people using VR headsets

00:01:47,579 --> 00:01:52,290
because you'll see them like you know in

00:01:50,579 --> 00:01:54,630
the pool with their VR headsets on

00:01:52,290 --> 00:01:57,360
you'll see things like bets

00:01:54,630 --> 00:01:59,189
when we look at the media coverage of

00:01:57,360 --> 00:02:01,560
this technology we see a lot of stuff

00:01:59,189 --> 00:02:03,600
that's fairly nonsensical so things like

00:02:01,560 --> 00:02:05,490
you know okay the future corporate

00:02:03,600 --> 00:02:08,789
growth is fueled by AI that's pretty

00:02:05,490 --> 00:02:10,000
recent maybe that makes sense teenager

00:02:08,789 --> 00:02:14,230
teaches an AI it

00:02:10,000 --> 00:02:16,720
rap like Kanye West okay that's pretty

00:02:14,230 --> 00:02:19,800
cool but what were you seeing happening

00:02:16,720 --> 00:02:22,210
is a outstanding amount of hype and this

00:02:19,800 --> 00:02:24,730
anthropomorphism of what the technology

00:02:22,210 --> 00:02:26,980
can actually provide for us so if you

00:02:24,730 --> 00:02:28,120
take one thing away from my discussion

00:02:26,980 --> 00:02:30,010
here it's really that we're talking

00:02:28,120 --> 00:02:31,959
about computer programs that are built

00:02:30,010 --> 00:02:33,760
on top of data that improve with the

00:02:31,959 --> 00:02:36,190
introduction of more data into those

00:02:33,760 --> 00:02:38,740
systems and feedback loops we are not

00:02:36,190 --> 00:02:40,650
talking about some actual recreation of

00:02:38,740 --> 00:02:43,840
human intelligence there's some kind of

00:02:40,650 --> 00:02:46,780
you know science fiction type type thing

00:02:43,840 --> 00:02:49,209
though I do love science fiction now I

00:02:46,780 --> 00:02:52,120
like to put it in a framework because it

00:02:49,209 --> 00:02:54,850
feels like we have AI coming out of

00:02:52,120 --> 00:02:56,050
nowhere over the last year but this is

00:02:54,850 --> 00:02:59,050
actually not the case

00:02:56,050 --> 00:03:02,320
AI has existed as its own academic field

00:02:59,050 --> 00:03:04,750
of research for you know about since the

00:03:02,320 --> 00:03:08,500
knight mid-1950s was really the first

00:03:04,750 --> 00:03:10,750
wave of AI research but if we were here

00:03:08,500 --> 00:03:12,670
having this conference 10 years ago we

00:03:10,750 --> 00:03:15,040
would be talking about this part here

00:03:12,670 --> 00:03:17,019
we'd be talking about big data and what

00:03:15,040 --> 00:03:18,450
that meant at the time was that we now

00:03:17,019 --> 00:03:20,530
had open source and available

00:03:18,450 --> 00:03:22,480
infrastructure that allowed us to get

00:03:20,530 --> 00:03:24,850
all of our data in one place and to

00:03:22,480 --> 00:03:27,940
query that data without building our own

00:03:24,850 --> 00:03:31,810
unique proprietary platform and without

00:03:27,940 --> 00:03:35,200
you know doing a lot of custom work that

00:03:31,810 --> 00:03:37,630
was a revolution but it was a revolution

00:03:35,200 --> 00:03:40,110
in cost reduction which is not merely as

00:03:37,630 --> 00:03:42,610
exciting to talk about as smart robots

00:03:40,110 --> 00:03:44,440
but it was one where now all of a sudden

00:03:42,610 --> 00:03:46,420
this technology that people have

00:03:44,440 --> 00:03:48,970
particularly in finance been applying

00:03:46,420 --> 00:03:51,100
for 30 years to only very high value

00:03:48,970 --> 00:03:53,950
problems could now be applied to trivial

00:03:51,100 --> 00:03:55,870
problems for example I was the chief

00:03:53,950 --> 00:03:59,200
scientist at bitly which really is those

00:03:55,870 --> 00:04:01,120
little short URLs on social media and we

00:03:59,200 --> 00:04:03,070
were able to study questions like do

00:04:01,120 --> 00:04:07,060
people click on more photos of cats or

00:04:03,070 --> 00:04:09,640
dogs on social media involving things

00:04:07,060 --> 00:04:12,760
like 10 billion documents which was

00:04:09,640 --> 00:04:14,410
something 10 years ago that was really

00:04:12,760 --> 00:04:16,390
not so you never would have invested

00:04:14,410 --> 00:04:19,000
that kind of envelop

00:04:16,390 --> 00:04:20,739
understanding cats versus dogs but that

00:04:19,000 --> 00:04:22,960
was ten years ago and once you can count

00:04:20,739 --> 00:04:24,639
things in your data you can do analytic

00:04:22,960 --> 00:04:28,780
that is counting things for some

00:04:24,639 --> 00:04:30,310
business purpose right okay so once you

00:04:28,780 --> 00:04:32,889
can do that you can count things

00:04:30,310 --> 00:04:34,690
cleverly and that gave us data science

00:04:32,889 --> 00:04:36,430
which is not just counting things and

00:04:34,690 --> 00:04:40,000
historical data but building predictive

00:04:36,430 --> 00:04:43,690
models building you know sort of ideas

00:04:40,000 --> 00:04:45,550
and representations off that data that

00:04:43,690 --> 00:04:48,310
can teach us something that's perhaps a

00:04:45,550 --> 00:04:52,210
non-obvious or B's to predict even the

00:04:48,310 --> 00:04:54,460
future or infer missing information if

00:04:52,210 --> 00:04:56,050
you've ever used the zillow.com sort of

00:04:54,460 --> 00:04:57,610
you know what is this property worth

00:04:56,050 --> 00:04:59,500
that's what we're talking about right

00:04:57,610 --> 00:05:01,150
and now we have machine learning where

00:04:59,500 --> 00:05:02,770
we're counting cleverly and then we have

00:05:01,150 --> 00:05:04,630
these feedback loops such that our

00:05:02,770 --> 00:05:08,020
systems continue to improve over time

00:05:04,630 --> 00:05:09,580
with the introduction of more data and

00:05:08,020 --> 00:05:12,130
so you see how these things are related

00:05:09,580 --> 00:05:13,900
machine learning provides a set of

00:05:12,130 --> 00:05:16,210
techniques that you can put under that

00:05:13,900 --> 00:05:19,509
broad umbrella of data science and so

00:05:16,210 --> 00:05:21,580
today we have AI which has returned from

00:05:19,509 --> 00:05:23,380
a terminology point of view because of

00:05:21,580 --> 00:05:26,319
the rise of deep learning which is a

00:05:23,380 --> 00:05:28,840
subset of techniques used in machine

00:05:26,319 --> 00:05:30,909
learning that are based around neural

00:05:28,840 --> 00:05:34,349
networks that have given us that not

00:05:30,909 --> 00:05:36,729
just more efficient and cost worthy

00:05:34,349 --> 00:05:38,409
capabilities but have actually given us

00:05:36,729 --> 00:05:40,630
the ability to do some things we

00:05:38,409 --> 00:05:43,509
couldn't do at all five years ago I'll

00:05:40,630 --> 00:05:45,430
get into more of that later but we're

00:05:43,509 --> 00:05:47,409
talking about things like solving image

00:05:45,430 --> 00:05:49,330
object recognition problems where you

00:05:47,409 --> 00:05:51,580
can take a photo and it'll say oh there

00:05:49,330 --> 00:05:55,990
are 20 human beings in this photo one

00:05:51,580 --> 00:05:59,139
camera and one clock right so all of

00:05:55,990 --> 00:06:01,900
this creates a technical foundation on

00:05:59,139 --> 00:06:04,000
which we can start to imagine the future

00:06:01,900 --> 00:06:06,580
that's the tomorrow part of this talk

00:06:04,000 --> 00:06:08,409
but before we really get into that I

00:06:06,580 --> 00:06:11,530
want to talk about what this looks like

00:06:08,409 --> 00:06:13,539
when it's successful and my favorite way

00:06:11,530 --> 00:06:15,820
to frame AI and machine learning today

00:06:13,539 --> 00:06:17,860
is to say the work we have we had to do

00:06:15,820 --> 00:06:21,009
five years ago was to make it exciting

00:06:17,860 --> 00:06:22,900
to get anyone to care so that when you

00:06:21,009 --> 00:06:24,310
go to a cocktail party or networking

00:06:22,900 --> 00:06:25,630
event and you say I work in machine

00:06:24,310 --> 00:06:27,550
learning people don't just turn their

00:06:25,630 --> 00:06:29,110
back and walk away and say oh maybe the

00:06:27,550 --> 00:06:30,300
blockchain guy I'll be more interesting

00:06:29,110 --> 00:06:34,530
to talk to

00:06:30,300 --> 00:06:36,900
um this is about making it boring and

00:06:34,530 --> 00:06:38,550
what I mean by that is that we have to

00:06:36,900 --> 00:06:40,560
let the technology fade into the

00:06:38,550 --> 00:06:42,389
background so this is my favorite

00:06:40,560 --> 00:06:44,639
machine learning application I don't

00:06:42,389 --> 00:06:47,430
work for Google I never have this is the

00:06:44,639 --> 00:06:49,860
Google Maps traffic view the most

00:06:47,430 --> 00:06:52,530
remarkable thing about this is that it

00:06:49,860 --> 00:06:54,240
is really boring in that you can glance

00:06:52,530 --> 00:06:56,460
at it you make a decision you put it

00:06:54,240 --> 00:07:00,330
away you don't think about it you do not

00:06:56,460 --> 00:07:02,220
have to know that there is an incredible

00:07:00,330 --> 00:07:03,389
amount of data analysis machine learning

00:07:02,220 --> 00:07:05,069
that goes on to produce this

00:07:03,389 --> 00:07:06,810
visualization for you they're getting

00:07:05,069 --> 00:07:08,310
real-time data from people's phones

00:07:06,810 --> 00:07:10,259
they're integrating it with public

00:07:08,310 --> 00:07:13,229
datasets they're making predictions off

00:07:10,259 --> 00:07:15,120
of historical data they're visualizing

00:07:13,229 --> 00:07:18,509
it they are streaming it to you over a

00:07:15,120 --> 00:07:20,159
mobile network onto a device so you can

00:07:18,509 --> 00:07:21,599
be in your car and by the way I live

00:07:20,159 --> 00:07:22,860
here in New York so I don't drive and I

00:07:21,599 --> 00:07:24,840
think this is nuts that people are

00:07:22,860 --> 00:07:26,610
driving cars looking at their phones and

00:07:24,840 --> 00:07:30,990
making a decision about where they're

00:07:26,610 --> 00:07:33,120
going to go and you do that and you can

00:07:30,990 --> 00:07:34,860
do it so well with this application that

00:07:33,120 --> 00:07:36,479
even if you know how to get where you're

00:07:34,860 --> 00:07:38,060
going you're still gonna load it up

00:07:36,479 --> 00:07:40,500
because you want that real-time

00:07:38,060 --> 00:07:42,960
contextual information to make a better

00:07:40,500 --> 00:07:45,210
decision you can do that with no

00:07:42,960 --> 00:07:48,000
understanding of the technology this is

00:07:45,210 --> 00:07:50,580
one of my favorite AI applications in

00:07:48,000 --> 00:07:52,710
the world however this is really hard

00:07:50,580 --> 00:07:54,389
and one of the things we do in our

00:07:52,710 --> 00:07:56,400
practice of machine learning is try to

00:07:54,389 --> 00:07:58,440
understand not just the possibilities

00:07:56,400 --> 00:08:00,000
but the boundaries of how to apply

00:07:58,440 --> 00:08:03,000
techniques and so I'm going to share

00:08:00,000 --> 00:08:06,210
with you a personal example of being a

00:08:03,000 --> 00:08:08,400
machine learning edge case so this story

00:08:06,210 --> 00:08:10,889
begins with my name which is a little

00:08:08,400 --> 00:08:13,919
weird so it's Hillary with one L Mason

00:08:10,889 --> 00:08:16,080
right it's not a very uncommon name it's

00:08:13,919 --> 00:08:17,849
not a very common name I happen to share

00:08:16,080 --> 00:08:20,099
this name with a British character

00:08:17,849 --> 00:08:22,860
actress it's quite a bit older than me

00:08:20,099 --> 00:08:26,340
she passed away in about 2005 at a very

00:08:22,860 --> 00:08:28,979
old age she had a very successful career

00:08:26,340 --> 00:08:31,560
now why this matters is that because in

00:08:28,979 --> 00:08:35,430
her later career she played roles like

00:08:31,560 --> 00:08:37,919
which ugly hag and this was a search

00:08:35,430 --> 00:08:40,169
engine from 2009 where they had the

00:08:37,919 --> 00:08:42,120
innovation of combining photos

00:08:40,169 --> 00:08:44,190
with text results and of course here is

00:08:42,120 --> 00:08:47,339
my bio at the time I was a professor

00:08:44,190 --> 00:08:50,220
that is her in the role of ugly hag and

00:08:47,339 --> 00:08:52,800
the implication here is obvious right

00:08:50,220 --> 00:08:55,470
and this named entity disambiguation

00:08:52,800 --> 00:08:56,490
problem is still a problem for us in

00:08:55,470 --> 00:08:59,010
machine learning

00:08:56,490 --> 00:09:00,420
in every domain and so you're gonna say

00:08:59,010 --> 00:09:02,880
Hillary you're making fun of some

00:09:00,420 --> 00:09:04,410
startup from 2009 and nobody cares so

00:09:02,880 --> 00:09:07,620
let me make fun of somebody a little bit

00:09:04,410 --> 00:09:10,440
more more expert expert at this which is

00:09:07,620 --> 00:09:12,089
Microsoft Bing search engine the Bing

00:09:10,440 --> 00:09:14,220
folks by the way do not get the credit

00:09:12,089 --> 00:09:17,399
they deserve for building a brilliant

00:09:14,220 --> 00:09:20,190
search engine but once again named

00:09:17,399 --> 00:09:21,959
entity disambiguation that is my photo I

00:09:20,190 --> 00:09:24,899
think you can see the resemblance here

00:09:21,959 --> 00:09:28,800
um that is not my date of birth and that

00:09:24,899 --> 00:09:31,889
is not my date of death and it's also

00:09:28,800 --> 00:09:34,320
not my middle name but um this is a hard

00:09:31,889 --> 00:09:36,449
problem right this this entity

00:09:34,320 --> 00:09:39,690
disambiguation problem the idea that

00:09:36,449 --> 00:09:41,250
there could be - not at all famous but

00:09:39,690 --> 00:09:43,230
well-known enough Hillary's in the

00:09:41,250 --> 00:09:46,050
world's just blowing Microsoft's mind

00:09:43,230 --> 00:09:48,089
unless we just make fun of Microsoft my

00:09:46,050 --> 00:09:51,000
friends at Google you know if you

00:09:48,089 --> 00:09:52,800
searched not today because I checked but

00:09:51,000 --> 00:09:55,529
if you search for this movie robot jocks

00:09:52,800 --> 00:09:58,170
which is an awesome 1991 movie about

00:09:55,529 --> 00:10:02,070
giant robots punching each other so a

00:09:58,170 --> 00:10:06,420
fine piece of cinema there I was right

00:10:02,070 --> 00:10:08,760
this was a few years ago and you know I

00:10:06,420 --> 00:10:11,130
made fun of this on Twitter and Google+

00:10:08,760 --> 00:10:12,810
at the time which it was the best way to

00:10:11,130 --> 00:10:14,220
get in touch with Google employees or

00:10:12,810 --> 00:10:16,589
friends who work at Google and of course

00:10:14,220 --> 00:10:18,300
they fixed it right away and it was just

00:10:16,589 --> 00:10:19,949
funny but then about a year ago I

00:10:18,300 --> 00:10:22,370
thought hi I wonder what's going on

00:10:19,949 --> 00:10:26,910
there and there I was back again in

00:10:22,370 --> 00:10:30,779
robot jocks yeah I don't even know where

00:10:26,910 --> 00:10:33,540
that photo came from and so I share this

00:10:30,779 --> 00:10:35,459
example because the not to you know pick

00:10:33,540 --> 00:10:36,839
on anyone here especially who works at

00:10:35,459 --> 00:10:38,720
Google or Microsoft I think you're all

00:10:36,839 --> 00:10:42,180
wonderful and you build amazing things

00:10:38,720 --> 00:10:45,029
but rather to say that this technology

00:10:42,180 --> 00:10:46,769
has a tremendous amount of potential to

00:10:45,029 --> 00:10:49,920
make our lives more efficient to build

00:10:46,769 --> 00:10:51,779
new products but it also has limitations

00:10:49,920 --> 00:10:53,730
and when we have conferences like this

00:10:51,779 --> 00:10:55,920
we tend to talk about the potential

00:10:53,730 --> 00:10:57,560
but not about the limitations and not

00:10:55,920 --> 00:11:00,720
about where things tend to go a bit

00:10:57,560 --> 00:11:02,310
wrong and I have a bit of a twisted

00:11:00,720 --> 00:11:04,710
sense of humor so that's usually what I

00:11:02,310 --> 00:11:06,780
want to hear about like where where are

00:11:04,710 --> 00:11:10,080
we using this that we need to be a

00:11:06,780 --> 00:11:11,910
little bit more thoughtful and so what

00:11:10,080 --> 00:11:14,400
we're still waiting today for the way we

00:11:11,910 --> 00:11:15,900
may be this problem will never be solved

00:11:14,400 --> 00:11:18,060
but we are waiting for the way that we

00:11:15,900 --> 00:11:20,390
broadly think about the use of the

00:11:18,060 --> 00:11:23,220
technology to catch up to what's real

00:11:20,390 --> 00:11:25,290
and in order to accomplish that we have

00:11:23,220 --> 00:11:27,120
to make it boring we have to say a eye

00:11:25,290 --> 00:11:29,910
is not something that we're excited

00:11:27,120 --> 00:11:34,200
about is just one tool it's just as

00:11:29,910 --> 00:11:35,730
exciting as your C compiler I also want

00:11:34,200 --> 00:11:37,470
to mention here in this audience that

00:11:35,730 --> 00:11:39,780
the biggest opportunities will be

00:11:37,470 --> 00:11:41,850
surprising to you so a lot of people

00:11:39,780 --> 00:11:43,350
think this innovation specifically in

00:11:41,850 --> 00:11:46,440
machine learning happens only in

00:11:43,350 --> 00:11:48,420
academia or perhaps in startups they

00:11:46,440 --> 00:11:50,490
certainly do good work but I can tell

00:11:48,420 --> 00:11:53,310
you from experience that academics are

00:11:50,490 --> 00:11:55,530
generally focused not specifically on

00:11:53,310 --> 00:11:57,930
work that will help you build production

00:11:55,530 --> 00:12:00,570
systems that solve your problems but

00:11:57,930 --> 00:12:03,240
rather on ideas that are novel on

00:12:00,570 --> 00:12:05,130
meeting fairly arbitrary benchmarks that

00:12:03,240 --> 00:12:06,840
will get their papers published you

00:12:05,130 --> 00:12:08,730
should fund the heck out of them but

00:12:06,840 --> 00:12:10,860
don't expect them to solve your problem

00:12:08,730 --> 00:12:13,500
in production in a scalable and

00:12:10,860 --> 00:12:15,720
repeatable way startups likewise our

00:12:13,500 --> 00:12:17,400
highly resource constrained so they

00:12:15,720 --> 00:12:19,800
don't health people sometimes they don't

00:12:17,400 --> 00:12:21,120
even have domain expertise and the the

00:12:19,800 --> 00:12:24,360
parts of the industry they want to

00:12:21,120 --> 00:12:25,950
impact they don't have data and they

00:12:24,360 --> 00:12:28,230
haven't been doing this for a very long

00:12:25,950 --> 00:12:30,450
time and so we have the enterprise we

00:12:28,230 --> 00:12:33,180
have large companies operating complex

00:12:30,450 --> 00:12:37,320
businesses huge amounts of human and

00:12:33,180 --> 00:12:40,440
technical expertise on where the ROI

00:12:37,320 --> 00:12:43,020
would be in that domain huge amounts of

00:12:40,440 --> 00:12:45,330
data generally created as a side-effect

00:12:43,020 --> 00:12:47,970
of operating those businesses for some

00:12:45,330 --> 00:12:49,980
time and these are the people who are

00:12:47,970 --> 00:12:52,050
looking to those academics and startups

00:12:49,980 --> 00:12:53,730
to solve their problems and so I want to

00:12:52,050 --> 00:12:55,800
point out for everyone in this room you

00:12:53,730 --> 00:12:58,710
can do this you are in fact the best

00:12:55,800 --> 00:13:00,720
position people to do this and in

00:12:58,710 --> 00:13:02,880
financial services we see a ton of

00:13:00,720 --> 00:13:04,710
interesting use cases so I have a rule

00:13:02,880 --> 00:13:06,690
of thumb when I work with companies

00:13:04,710 --> 00:13:07,059
which is generally we have to find some

00:13:06,690 --> 00:13:09,399
clear

00:13:07,059 --> 00:13:12,329
ROI on a cost savings or process

00:13:09,399 --> 00:13:15,069
improvement basis using machine learning

00:13:12,329 --> 00:13:18,279
lots of people in FinTech especially

00:13:15,069 --> 00:13:20,349
want to start in security anti money

00:13:18,279 --> 00:13:22,449
laundering in fraud detection these are

00:13:20,349 --> 00:13:23,919
really fruitful areas because a small

00:13:22,449 --> 00:13:26,319
percentage improvement is very

00:13:23,919 --> 00:13:27,939
high-impact there are other areas as

00:13:26,319 --> 00:13:30,219
well things like understanding your

00:13:27,939 --> 00:13:31,779
customers turn analysis some of the

00:13:30,219 --> 00:13:35,439
marketing techniques which are pretty

00:13:31,779 --> 00:13:39,099
easy to get started in but one if you

00:13:35,439 --> 00:13:41,169
only think about those ROI the ROI and

00:13:39,099 --> 00:13:43,719
the terms of cost reduction you put a

00:13:41,169 --> 00:13:47,859
boundary on the amount of potential your

00:13:43,719 --> 00:13:50,339
use of a I will have think also about

00:13:47,859 --> 00:13:53,079
new revenue opportunities new growth

00:13:50,339 --> 00:13:56,649
opportunities that can come out of the

00:13:53,079 --> 00:13:58,629
same technologies that's where the real

00:13:56,649 --> 00:14:00,639
potential is so I have to go fast I'm

00:13:58,629 --> 00:14:02,979
gonna do this and I want to give you our

00:14:00,639 --> 00:14:04,869
framework for looking ahead where the

00:14:02,979 --> 00:14:07,659
technology is going and then share some

00:14:04,869 --> 00:14:09,219
specific things we've come up with but I

00:14:07,659 --> 00:14:11,349
really encourage you to take this home

00:14:09,219 --> 00:14:14,169
and give it a try and see what you come

00:14:11,349 --> 00:14:16,539
up with so this is how we look six

00:14:14,169 --> 00:14:18,429
months to two years ahead in machine

00:14:16,539 --> 00:14:20,379
learning for the enterprise and we do

00:14:18,429 --> 00:14:22,809
have a research product around this but

00:14:20,379 --> 00:14:25,779
we publish a lot in the open and also

00:14:22,809 --> 00:14:28,209
publish a fair bit of open source first

00:14:25,779 --> 00:14:30,219
thing is to drink coffee have ideas I

00:14:28,209 --> 00:14:31,689
visit a lot of companies when I see

00:14:30,219 --> 00:14:34,599
their list of projects they're always

00:14:31,689 --> 00:14:36,669
good ideas I get very worried because

00:14:34,599 --> 00:14:38,349
you aren't missing out on a huge amount

00:14:36,669 --> 00:14:40,989
of opportunity that would likely look

00:14:38,349 --> 00:14:44,139
like bad ideas on the surface that's why

00:14:40,989 --> 00:14:46,629
it's really big validate against robust

00:14:44,139 --> 00:14:49,179
criteria so step one this is create a

00:14:46,629 --> 00:14:51,939
very broad sweep get as many ideas

00:14:49,179 --> 00:14:53,829
potential projects as possible and then

00:14:51,939 --> 00:14:56,109
go through and validate capabilities so

00:14:53,829 --> 00:14:57,879
is there research activity that is at

00:14:56,109 --> 00:14:59,049
all relevant to what you're doing is

00:14:57,879 --> 00:15:01,449
there work in one domain you can

00:14:59,049 --> 00:15:02,979
transfer to another domain has somebody

00:15:01,449 --> 00:15:05,079
done something in another industry that

00:15:02,979 --> 00:15:07,419
you can use or in a you know academic

00:15:05,079 --> 00:15:09,699
context that you can use is there a

00:15:07,419 --> 00:15:11,979
meaningful change in economics that

00:15:09,699 --> 00:15:14,919
would enable you to actually implement

00:15:11,979 --> 00:15:17,319
something at scale meaning that we knew

00:15:14,919 --> 00:15:20,049
how to use deep learning effectively for

00:15:17,319 --> 00:15:20,800
example for a few years before it became

00:15:20,049 --> 00:15:24,189
very

00:15:20,800 --> 00:15:26,050
and even now it's not very common but we

00:15:24,189 --> 00:15:28,179
couldn't afford it because GPUs were too

00:15:26,050 --> 00:15:31,300
expensive and so I could draw a graph

00:15:28,179 --> 00:15:33,279
like this for pretty much any of the the

00:15:31,300 --> 00:15:35,860
constraining financial factors on

00:15:33,279 --> 00:15:38,439
machine learning implementations cost of

00:15:35,860 --> 00:15:42,009
storage cost of compute cost of

00:15:38,439 --> 00:15:44,049
bandwidth all of that and it looks like

00:15:42,009 --> 00:15:47,110
this this is my favorite example though

00:15:44,049 --> 00:15:50,139
this is the same sized chip from 20 2005

00:15:47,110 --> 00:15:53,049
and 2014 cost the same price 128 Meg's

00:15:50,139 --> 00:15:56,949
128 gigs so if you can't afford it today

00:15:53,049 --> 00:15:58,899
just wait is it becoming commoditized in

00:15:56,949 --> 00:16:01,179
open source that means that you have

00:15:58,899 --> 00:16:03,129
robust software and infrastructure you

00:16:01,179 --> 00:16:04,899
can build on without having to own and

00:16:03,129 --> 00:16:07,720
create it yourself I do being the

00:16:04,899 --> 00:16:09,160
classic example in Big Data but I don't

00:16:07,720 --> 00:16:11,889
need to tell you all about that in this

00:16:09,160 --> 00:16:14,769
room and then is data available either

00:16:11,889 --> 00:16:17,230
data inside of your company or that's

00:16:14,769 --> 00:16:19,149
proprietary data you can purchase data

00:16:17,230 --> 00:16:21,129
you can partner for or data you can get

00:16:19,149 --> 00:16:24,249
from the big wide open world of data

00:16:21,129 --> 00:16:26,740
either from sensors or from Wikipedia

00:16:24,249 --> 00:16:30,610
which is the dirty secret of any every

00:16:26,740 --> 00:16:32,470
natural language startup there are in

00:16:30,610 --> 00:16:34,059
fact errors in Wikipedia that you can

00:16:32,470 --> 00:16:36,189
actually track through to the Train

00:16:34,059 --> 00:16:38,920
models that these startups are selling

00:16:36,189 --> 00:16:41,529
it's pretty fund and then progressively

00:16:38,920 --> 00:16:44,860
explore the risky capabilities that

00:16:41,529 --> 00:16:46,720
means you know have a phased investment

00:16:44,860 --> 00:16:48,879
plan in machine learning we do this in

00:16:46,720 --> 00:16:50,740
three phases so we do validation and

00:16:48,879 --> 00:16:52,540
exploration does the data exist can I

00:16:50,740 --> 00:16:55,480
build a very simple model that's better

00:16:52,540 --> 00:16:57,730
than random in a week then I do

00:16:55,480 --> 00:17:00,279
algorithmic excellence what is the best

00:16:57,730 --> 00:17:03,309
possible way to solve this then we do

00:17:00,279 --> 00:17:05,319
operationalization in scale at each one

00:17:03,309 --> 00:17:06,819
you have a cost gate to make sure you're

00:17:05,319 --> 00:17:10,270
not investing in things that aren't

00:17:06,819 --> 00:17:13,179
ready and to make sure that your people

00:17:10,270 --> 00:17:14,770
are you know happy making progress and

00:17:13,179 --> 00:17:16,059
not going down little rabbit holes that

00:17:14,770 --> 00:17:18,240
are technically interesting but

00:17:16,059 --> 00:17:20,770
ultimately not tied to the application

00:17:18,240 --> 00:17:23,319
until I've managed technical people for

00:17:20,770 --> 00:17:25,990
a long time predicting the future is

00:17:23,319 --> 00:17:28,750
really hard so this is a set of

00:17:25,990 --> 00:17:30,039
postcards from 1900 in France and

00:17:28,750 --> 00:17:32,070
they're trying to predict what the year

00:17:30,039 --> 00:17:34,110
2000 will be like

00:17:32,070 --> 00:17:36,210
I love them because they actually sort

00:17:34,110 --> 00:17:38,010
of got the problem statements but the

00:17:36,210 --> 00:17:39,660
actual implementations are a little

00:17:38,010 --> 00:17:43,020
weird so like these are firefighters

00:17:39,660 --> 00:17:45,180
with wings and the this is a school

00:17:43,020 --> 00:17:46,710
where there's sort of wiring things into

00:17:45,180 --> 00:17:49,440
people's brains because they hadn't

00:17:46,710 --> 00:17:51,270
thought about wireless and this is a

00:17:49,440 --> 00:17:53,220
farm where they've got a robot and this

00:17:51,270 --> 00:17:54,690
one actually kind of exists though the

00:17:53,220 --> 00:17:57,840
control panels don't really look like

00:17:54,690 --> 00:18:01,770
that of course but predicting the future

00:17:57,840 --> 00:18:03,660
is really hard so we write these reports

00:18:01,770 --> 00:18:05,490
on different technologies they are

00:18:03,660 --> 00:18:06,720
designed to be six months to two years

00:18:05,490 --> 00:18:09,420
ahead of what you would put in

00:18:06,720 --> 00:18:11,010
production which means practically we're

00:18:09,420 --> 00:18:12,300
the ones reading through D papers and

00:18:11,010 --> 00:18:14,670
then writing some code that'll actually

00:18:12,300 --> 00:18:16,770
work in the enterprise context and also

00:18:14,670 --> 00:18:18,750
is aware of all of the security

00:18:16,770 --> 00:18:21,300
governance and other fun requirements

00:18:18,750 --> 00:18:23,250
that many of us are subject to you I'm

00:18:21,300 --> 00:18:24,780
selected a few to tell you about because

00:18:23,250 --> 00:18:26,760
these are the things I'm most excited

00:18:24,780 --> 00:18:28,650
about so one is natural language

00:18:26,760 --> 00:18:31,080
generation or the ability to take

00:18:28,650 --> 00:18:33,210
structured data and output narrative if

00:18:31,080 --> 00:18:35,040
you hear about this in the news it's

00:18:33,210 --> 00:18:37,410
about reporters freaking out that their

00:18:35,040 --> 00:18:39,300
jobs are getting replaced we have a

00:18:37,410 --> 00:18:41,400
prototype here that writes real estate

00:18:39,300 --> 00:18:44,850
advertisements so that one's pretty fun

00:18:41,400 --> 00:18:47,250
the real impact here is not in replacing

00:18:44,850 --> 00:18:48,960
reporters it is in making structured

00:18:47,250 --> 00:18:52,290
data accessible to a wide audience

00:18:48,960 --> 00:18:56,070
without requiring sophisticated parsing

00:18:52,290 --> 00:18:57,600
of things like graphs or raw data we

00:18:56,070 --> 00:18:59,820
have several use cases that have come

00:18:57,600 --> 00:19:02,520
out of this work everything from a

00:18:59,820 --> 00:19:04,350
celebrity fashion magazine that is able

00:19:02,520 --> 00:19:06,660
to take the structured data of what Kim

00:19:04,350 --> 00:19:09,540
Kardashian wears and automatically

00:19:06,660 --> 00:19:11,660
generate the reporting around that all

00:19:09,540 --> 00:19:14,700
the way to a very large financial

00:19:11,660 --> 00:19:17,760
services company that is supporting

00:19:14,700 --> 00:19:19,760
their customers with portfolio report

00:19:17,760 --> 00:19:21,960
emails that are customized to them

00:19:19,760 --> 00:19:24,210
increasing engagement that they also

00:19:21,960 --> 00:19:25,560
tend to be retirees so there's a lot of

00:19:24,210 --> 00:19:28,020
value there in language for that

00:19:25,560 --> 00:19:29,730
audience the third use case that I get

00:19:28,020 --> 00:19:32,160
excited about is actually one of our

00:19:29,730 --> 00:19:35,160
bank customers that is now writing about

00:19:32,160 --> 00:19:37,590
80% of their compliance reports using

00:19:35,160 --> 00:19:39,750
some of this technology believe me those

00:19:37,590 --> 00:19:42,560
people were really happy not to have to

00:19:39,750 --> 00:19:45,030
write the same thing again and again I

00:19:42,560 --> 00:19:45,630
have to talk about deep learning and

00:19:45,030 --> 00:19:48,450
he's hot

00:19:45,630 --> 00:19:51,000
that has AI and the title this is

00:19:48,450 --> 00:19:54,150
fundamentally a new capability and it is

00:19:51,000 --> 00:19:57,030
based on something that is inspired by

00:19:54,150 --> 00:19:58,320
the way we thought the brain worked 60

00:19:57,030 --> 00:20:01,020
to 70 years ago

00:19:58,320 --> 00:20:03,210
it is not itself a brain this is the

00:20:01,020 --> 00:20:05,460
fundamental element of a neural network

00:20:03,210 --> 00:20:08,400
it's a neuron you have inputs that are

00:20:05,460 --> 00:20:10,410
ones and zeros you have weights sums and

00:20:08,400 --> 00:20:12,420
biases which are really in the this

00:20:10,410 --> 00:20:14,070
simplest formulation just adding it all

00:20:12,420 --> 00:20:16,080
up and then you have an activation

00:20:14,070 --> 00:20:18,420
function which in this formulation again

00:20:16,080 --> 00:20:20,070
is just a rule and you have layers and

00:20:18,420 --> 00:20:21,630
networks of these and if you want to

00:20:20,070 --> 00:20:24,870
know why it's deep learning it's because

00:20:21,630 --> 00:20:27,480
you have more than one layer deep is not

00:20:24,870 --> 00:20:28,980
itself a technical term and in fact

00:20:27,480 --> 00:20:32,280
there's some deep learning that's just

00:20:28,980 --> 00:20:33,720
one layer anyway but this is the

00:20:32,280 --> 00:20:36,000
fundamental unit that we're talking

00:20:33,720 --> 00:20:38,820
about here and what's exciting is that

00:20:36,000 --> 00:20:41,430
these networks do not require you to do

00:20:38,820 --> 00:20:43,380
manual feature engineering you do manual

00:20:41,430 --> 00:20:45,810
network design and then the network does

00:20:43,380 --> 00:20:47,670
the feature engineering which allows us

00:20:45,810 --> 00:20:49,500
to apply it to problems where humans

00:20:47,670 --> 00:20:53,610
were really bad at the future design

00:20:49,500 --> 00:20:54,900
like recognizing objects and images this

00:20:53,610 --> 00:20:56,820
is another one where I'm going to show

00:20:54,900 --> 00:20:58,650
you something that went wrong so we

00:20:56,820 --> 00:21:00,840
created this thing that recognizes

00:20:58,650 --> 00:21:02,700
objects and Instagram photos you can add

00:21:00,840 --> 00:21:04,140
your Instagram photos to it and I added

00:21:02,700 --> 00:21:06,810
Bleeker burger because I love

00:21:04,140 --> 00:21:08,760
cheeseburgers you can see that there's

00:21:06,810 --> 00:21:10,140
one photo of a flag and then everything

00:21:08,760 --> 00:21:13,440
else is a photo of burgers

00:21:10,140 --> 00:21:15,030
so it nailed hamburgers dishes is where

00:21:13,440 --> 00:21:16,770
it thinks it's a food but it's not

00:21:15,030 --> 00:21:18,540
entirely sure what food those are mostly

00:21:16,770 --> 00:21:20,550
cut in half it thinks some are hot dogs

00:21:18,540 --> 00:21:24,630
or meatloaf you know lots of the

00:21:20,550 --> 00:21:27,150
American culinary stuff crabs is worth

00:21:24,630 --> 00:21:29,040
looking at though because as a human you

00:21:27,150 --> 00:21:30,720
look at this and you know you slowly

00:21:29,040 --> 00:21:32,370
realize okay this neural network has

00:21:30,720 --> 00:21:36,840
learned that anything with french fries

00:21:32,370 --> 00:21:39,450
near water or a dock is a crab um it's

00:21:36,840 --> 00:21:41,400
kind of a problem and this you know

00:21:39,450 --> 00:21:44,940
again I'm sharing this here because this

00:21:41,400 --> 00:21:47,460
is funny but this seam edge case has had

00:21:44,940 --> 00:21:49,290
has caused major issues for companies

00:21:47,460 --> 00:21:51,750
like Google when they've misclassified

00:21:49,290 --> 00:21:54,570
you know people in photos it's animals

00:21:51,750 --> 00:21:57,300
and in autonomous driving contacts in

00:21:54,570 --> 00:21:58,680
medical contacts and so it's important

00:21:57,300 --> 00:21:59,309
again to understand what we're doing

00:21:58,680 --> 00:22:01,740
here

00:21:59,309 --> 00:22:03,809
incredibly powerful techniques we have a

00:22:01,740 --> 00:22:05,940
medical device company changing the way

00:22:03,809 --> 00:22:08,820
they build surgical robots around this

00:22:05,940 --> 00:22:11,460
math we have people who are able to do

00:22:08,820 --> 00:22:13,799
very fast scalable analysis of satellite

00:22:11,460 --> 00:22:18,149
photos to get information in front of

00:22:13,799 --> 00:22:20,519
people making investments right but you

00:22:18,149 --> 00:22:22,799
have to think about it you can apply

00:22:20,519 --> 00:22:24,659
some of these same techniques to text so

00:22:22,799 --> 00:22:26,730
Auto summarization is something I've

00:22:24,659 --> 00:22:29,039
been following and pretty passionate

00:22:26,730 --> 00:22:31,590
about for years is taken article

00:22:29,039 --> 00:22:33,690
simplify the article and then in this

00:22:31,590 --> 00:22:35,220
system extract the set of sentences from

00:22:33,690 --> 00:22:36,990
the article that contain the same

00:22:35,220 --> 00:22:39,749
information contained in the full

00:22:36,990 --> 00:22:41,970
article now this relies on a technique

00:22:39,749 --> 00:22:44,730
called word embeddings where you're

00:22:41,970 --> 00:22:47,549
actually able to create a vector that in

00:22:44,730 --> 00:22:49,769
some sense represents the meaning and

00:22:47,549 --> 00:22:53,970
this is metaphorical of what is in the

00:22:49,769 --> 00:22:55,649
sentence this is pretty cool it's mildly

00:22:53,970 --> 00:22:58,320
useful it gets more useful when you have

00:22:55,649 --> 00:22:59,879
a corpus of say 60,000 documents and

00:22:58,320 --> 00:23:02,820
then you say oh there are 10 points of

00:22:59,879 --> 00:23:05,730
view in this cluster of documents here's

00:23:02,820 --> 00:23:07,830
a summary of each point of view we've

00:23:05,730 --> 00:23:11,549
seen this particular technique useful

00:23:07,830 --> 00:23:14,580
again in an investment context in you

00:23:11,549 --> 00:23:17,220
know medical patient records the math is

00:23:14,580 --> 00:23:19,230
the same many applications here and we

00:23:17,220 --> 00:23:21,539
also just saw a really great paper from

00:23:19,230 --> 00:23:23,369
Facebook that used these same techniques

00:23:21,539 --> 00:23:25,409
to do automatic translation between

00:23:23,369 --> 00:23:27,990
languages where there's no pair corpus

00:23:25,409 --> 00:23:29,399
available so you can build a model of

00:23:27,990 --> 00:23:30,960
language build a second model of a

00:23:29,399 --> 00:23:32,190
language and translate from that first

00:23:30,960 --> 00:23:35,669
one to that second one which is

00:23:32,190 --> 00:23:37,590
incredibly powerful I'm almost up so

00:23:35,669 --> 00:23:39,570
interpretability is solving the black

00:23:37,590 --> 00:23:41,580
box problem that is a set of techniques

00:23:39,570 --> 00:23:43,679
you put on top of black box algorithms

00:23:41,580 --> 00:23:45,659
that permeate inputs look at outputs and

00:23:43,679 --> 00:23:47,759
figure out how they work here we've

00:23:45,659 --> 00:23:49,559
applied it to a black box churn analysis

00:23:47,759 --> 00:23:50,999
you can see all the features and you can

00:23:49,559 --> 00:23:53,009
play with the features and see how it

00:23:50,999 --> 00:23:55,110
changes the classification probabilities

00:23:53,009 --> 00:23:57,210
this is important for those of you in

00:23:55,110 --> 00:23:59,159
this room if you are legally obligated

00:23:57,210 --> 00:24:00,899
to be able to tell someone how a system

00:23:59,159 --> 00:24:03,629
you build works you need to know how

00:24:00,899 --> 00:24:05,369
this works because otherwise you just

00:24:03,629 --> 00:24:07,409
have to use purely interpretable

00:24:05,369 --> 00:24:08,789
techniques which is a tiny subset of the

00:24:07,409 --> 00:24:11,519
full spectrum of machine learning

00:24:08,789 --> 00:24:13,080
capabilities I should point out as well

00:24:11,519 --> 00:24:15,120
that a black box might be a

00:24:13,080 --> 00:24:17,400
lack box for mathematical reasons it's a

00:24:15,120 --> 00:24:19,110
compression of a feature space or it

00:24:17,400 --> 00:24:20,400
might be a black box because the person

00:24:19,110 --> 00:24:22,200
who built it just doesn't want to tell

00:24:20,400 --> 00:24:26,100
you how it works so this works on either

00:24:22,200 --> 00:24:27,810
case lots of fun stuff there and as we

00:24:26,100 --> 00:24:29,430
progress in the development of these

00:24:27,810 --> 00:24:31,830
technologies there's still a few things

00:24:29,430 --> 00:24:34,470
we need to keep in mind one of the

00:24:31,830 --> 00:24:38,100
biggest topics in our field right now is

00:24:34,470 --> 00:24:40,770
how we incorporate ethics how we comply

00:24:38,100 --> 00:24:42,750
with expectations of privacy in the

00:24:40,770 --> 00:24:45,390
practice of data science and so I'm

00:24:42,750 --> 00:24:48,060
gonna take this opportunity to push a

00:24:45,390 --> 00:24:49,980
short ebook that I wrote along with DJ

00:24:48,060 --> 00:24:52,680
Patil who worked for President Obama's

00:24:49,980 --> 00:24:55,560
his chief data scientist it's pretty

00:24:52,680 --> 00:24:58,020
short and it's very free and our goal

00:24:55,560 --> 00:24:59,940
with this is really to try and get folks

00:24:58,020 --> 00:25:01,410
who are practicing out in the world of

00:24:59,940 --> 00:25:04,290
machine learning and data science to

00:25:01,410 --> 00:25:07,380
think about their tools for them to sort

00:25:04,290 --> 00:25:08,160
of practice ethics in the context of

00:25:07,380 --> 00:25:10,470
their work

00:25:08,160 --> 00:25:12,870
now I'm gonna end with a lot of optimism

00:25:10,470 --> 00:25:15,090
I think we are in fact building this AI

00:25:12,870 --> 00:25:17,310
first enterprise this technology will

00:25:15,090 --> 00:25:19,380
find its way into many fundamental

00:25:17,310 --> 00:25:22,230
processes of the businesses that we all

00:25:19,380 --> 00:25:24,510
run so when I say let's make it boring I

00:25:22,230 --> 00:25:26,730
actually think that's what makes it more

00:25:24,510 --> 00:25:28,500
exciting and I will end with that

00:25:26,730 --> 00:25:30,000
extremely confusing

00:25:28,500 --> 00:25:31,980
what are your thinking about the world

00:25:30,000 --> 00:25:34,610
so thank you very much and thanks for

00:25:31,980 --> 00:25:34,610

YouTube URL: https://www.youtube.com/watch?v=XsIAqv8Blxw


