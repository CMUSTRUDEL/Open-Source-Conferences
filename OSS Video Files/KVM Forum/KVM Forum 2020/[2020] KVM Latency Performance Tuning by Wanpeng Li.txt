Title: [2020] KVM Latency Performance Tuning by Wanpeng Li
Publication date: 2020-12-09
Playlist: KVM Forum 2020
Description: 
	The KVM hypervisor is at the core of cloud computing, some customers from financial, online shopping, and gaming etc are sensitive to latency, IPI and Timer cause the main MSRs write vmexit in cloud environment. Preempted vCPU can block synchronized multicast function call IPIs or worse Lock Waiter Preemption Issue. In this presentation, we will introduce some features that can reduce latency in kvm hypervisor, including Fast IPI delivery, Fast timer emulation, and some features that can improve scalability, including Boost preempted vCPU, Yield to IPI target, and so on.

---

Wanpeng Li
Tencent Cloud, Linux Kernel Contributor

Wanpeng Li is a 8 years experienced Linux kernel/virtualization developer who works in Tencent Cloud currently. He mainly focus on KVM, scheduler and memory management. In KVM, he contributes a lot of features to improve performance and stability. He has experience worked in IBM LTC kernel team and INTEL OTC virtualization team before. He was invited to speak at some conferences: KVM FORUM 2019, China CLK 2019, KVM FORUM 2018, LinuxCon 2018, LinuxCon 2017, China CLK 2017.
Captions: 
	00:00:05,839 --> 00:00:09,360
hello

00:00:06,480 --> 00:00:11,200
i'm muan pang li from tencent cloud i'm

00:00:09,360 --> 00:00:14,480
a long-term active km

00:00:11,200 --> 00:00:17,039
contributor in community today i will

00:00:14,480 --> 00:00:18,359
introduce some kvm latency and the

00:00:17,039 --> 00:00:21,359
scalability

00:00:18,359 --> 00:00:21,359
optimizations

00:00:21,840 --> 00:00:26,160
this is today's agenda firstly i will

00:00:25,119 --> 00:00:29,519
introduce

00:00:26,160 --> 00:00:32,399
fastpass for both ipa delivery

00:00:29,519 --> 00:00:33,200
on the tsc data line camera then i will

00:00:32,399 --> 00:00:36,800
introduce

00:00:33,200 --> 00:00:39,520
how to boost vcpus that are delivering

00:00:36,800 --> 00:00:39,520
interrupts

00:00:41,040 --> 00:00:49,039
icr on the tfc deadline i miss our ride

00:00:44,800 --> 00:00:52,480
calls the main missiles right via mexico

00:00:49,039 --> 00:00:56,000
in cloud environment over the region

00:00:52,480 --> 00:00:59,600
multicast apis are not as common as

00:00:56,000 --> 00:01:02,960
unique cast api like reschedule vector

00:00:59,600 --> 00:01:06,400
on the call function single vector we

00:01:02,960 --> 00:01:09,520
introduced fastpass handler to handle

00:01:06,400 --> 00:01:11,280
certain performance critical msrs in a

00:01:09,520 --> 00:01:15,040
very early stage

00:01:11,280 --> 00:01:18,560
of kvm via mexico handler

00:01:15,040 --> 00:01:21,840
after writing icr vm exit

00:01:18,560 --> 00:01:22,640
various guest states save on the host

00:01:21,840 --> 00:01:25,759
states

00:01:22,640 --> 00:01:28,240
load various condition checking

00:01:25,759 --> 00:01:29,520
host interrupts on the preemption

00:01:28,240 --> 00:01:32,880
enabled

00:01:29,520 --> 00:01:36,640
and also expensive rcu

00:01:32,880 --> 00:01:40,320
operations we even can be interrupt or

00:01:36,640 --> 00:01:43,759
preempted after host interrupts on the

00:01:40,320 --> 00:01:47,200
preempted enabled

00:01:43,759 --> 00:01:50,399
this mechanism is specifically

00:01:47,200 --> 00:01:54,000
used for accelerating rights to

00:01:50,399 --> 00:01:57,759
x to a peak icr that attempt to send

00:01:54,000 --> 00:01:58,560
a virtual api with physical destination

00:01:57,759 --> 00:02:01,680
mode

00:01:58,560 --> 00:02:03,840
fix the delivery mode on the single

00:02:01,680 --> 00:02:07,360
target

00:02:03,840 --> 00:02:08,080
the region is mechanism significantly

00:02:07,360 --> 00:02:11,200
reduce

00:02:08,080 --> 00:02:14,239
the latency of such virtual

00:02:11,200 --> 00:02:18,400
ipi is by sending the virtual api

00:02:14,239 --> 00:02:19,440
to the target vcpu in a very early stage

00:02:18,400 --> 00:02:22,640
of km

00:02:19,440 --> 00:02:25,360
access handler before horse interrupts

00:02:22,640 --> 00:02:26,239
are enabled and before expensive

00:02:25,360 --> 00:02:32,080
operations

00:02:26,239 --> 00:02:32,080
such as requiring kvm as rcu lock

00:02:32,160 --> 00:02:40,280
we can observe 30 percent latency

00:02:35,360 --> 00:02:42,000
reduce for api benchmark and

00:02:40,280 --> 00:02:46,879
22.3 percent

00:02:42,000 --> 00:02:46,879
latency reduce for kvm unit test

00:02:48,080 --> 00:02:54,080
emd svm introduced hardware

00:02:51,280 --> 00:02:55,440
acceleration to boost virtual api

00:02:54,080 --> 00:02:59,519
performance

00:02:55,440 --> 00:03:02,560
the source ipi doesn't need to vm exit

00:02:59,519 --> 00:03:05,760
while sending unique cast api or

00:03:02,560 --> 00:03:08,720
multicast apis in most conditions

00:03:05,760 --> 00:03:10,959
the virtual api can be sent to target

00:03:08,720 --> 00:03:14,159
virtual cpu directly

00:03:10,959 --> 00:03:14,480
we run hack bench and ipa benchmark on

00:03:14,159 --> 00:03:18,159
one

00:03:14,480 --> 00:03:21,680
amd rom server two sockets

00:03:18,159 --> 00:03:25,360
96 cars 192 strikes

00:03:21,680 --> 00:03:29,440
the vm is 180 vcpus with

00:03:25,360 --> 00:03:33,599
sap exposed we can observe

00:03:29,440 --> 00:03:37,040
three percent hackbench performance

00:03:33,599 --> 00:03:42,480
improve it benefits single target ibi

00:03:37,040 --> 00:03:45,760
however we overload 55.2 percent

00:03:42,480 --> 00:03:48,720
ipi benchmark performance drop

00:03:45,760 --> 00:03:50,319
for multi-cast apis it is aware that

00:03:48,720 --> 00:03:54,319
hardware acceleration

00:03:50,319 --> 00:03:54,319
worse than software emulation

00:03:54,879 --> 00:04:00,239
now i will introduce virtual tnc

00:03:57,599 --> 00:04:02,959
deadline camera for the past

00:04:00,239 --> 00:04:04,400
both arm timer and thermo fare incur

00:04:02,959 --> 00:04:07,280
vmxs

00:04:04,400 --> 00:04:10,239
kvm does various housekeeping tasks

00:04:07,280 --> 00:04:10,239
before emulation

00:04:11,439 --> 00:04:15,200
we implement a further path for

00:04:14,000 --> 00:04:18,479
emulation of

00:04:15,200 --> 00:04:20,639
rights to the tsa deadline msr

00:04:18,479 --> 00:04:22,000
besides shortcutting various

00:04:20,639 --> 00:04:26,000
housekeeping tasks

00:04:22,000 --> 00:04:26,720
in the v cpu loop the fastpass can also

00:04:26,000 --> 00:04:29,759
deliver

00:04:26,720 --> 00:04:32,080
the timer interrupt directly

00:04:29,759 --> 00:04:34,639
without going through a qm request

00:04:32,080 --> 00:04:38,000
pending timer because

00:04:34,639 --> 00:04:41,199
it runs in this pure contacts

00:04:38,000 --> 00:04:44,560
we also implement our fast pass for the

00:04:41,199 --> 00:04:47,199
primition camera vm exit

00:04:44,560 --> 00:04:48,400
the vm access can be handled clearly so

00:04:47,199 --> 00:04:51,600
it can be

00:04:48,400 --> 00:04:54,960
performed with inner wraps of on going

00:04:51,600 --> 00:04:58,560
back directly to the host

00:04:54,960 --> 00:04:59,280
we can observe cylinder test latency

00:04:58,560 --> 00:05:04,400
reduced

00:04:59,280 --> 00:05:04,400
by 16.5 percent

00:05:05,680 --> 00:05:09,440
next i will introduce the mechanism to

00:05:08,880 --> 00:05:13,280
boost

00:05:09,440 --> 00:05:17,039
preempted vcpus to mitigate

00:05:13,280 --> 00:05:20,240
long holder preemption issue bcpu which

00:05:17,039 --> 00:05:23,039
spin is detected by hardware

00:05:20,240 --> 00:05:24,320
while in host vcpu use time to

00:05:23,039 --> 00:05:27,840
lockholder candidate

00:05:24,320 --> 00:05:32,240
vcpu which is selected by

00:05:27,840 --> 00:05:35,120
heuristic algorithm now we want to boost

00:05:32,240 --> 00:05:37,919
not just the log holders but also with

00:05:35,120 --> 00:05:38,400
fuels that are delivering in the roughs

00:05:37,919 --> 00:05:41,280
most

00:05:38,400 --> 00:05:42,560
smp core functions many codes are

00:05:41,280 --> 00:05:45,280
synchronous

00:05:42,560 --> 00:05:47,120
so the ipi target with fuels are also

00:05:45,280 --> 00:05:50,160
good your candidates

00:05:47,120 --> 00:05:53,840
we boost vcpus during recap and

00:05:50,160 --> 00:05:53,840
in the route delivery time

00:05:54,720 --> 00:06:01,199
next is a boost q-hat vcpu

00:05:58,080 --> 00:06:04,160
due to the flfo order spin log

00:06:01,199 --> 00:06:04,960
algorithm whenever i have a weather

00:06:04,160 --> 00:06:07,520
preempts

00:06:04,960 --> 00:06:08,720
the next winter that has not yet

00:06:07,520 --> 00:06:12,240
acquired the lock

00:06:08,720 --> 00:06:12,880
even if the law is released no other

00:06:12,240 --> 00:06:15,840
slide

00:06:12,880 --> 00:06:18,560
is allowed to acquire it until the next

00:06:15,840 --> 00:06:21,440
winter is allowed to run

00:06:18,560 --> 00:06:23,600
over commitment increase the likelihood

00:06:21,440 --> 00:06:27,120
that the queue had with appeal

00:06:23,600 --> 00:06:28,720
may have been preempted and not actively

00:06:27,120 --> 00:06:31,840
spinning

00:06:28,720 --> 00:06:34,160
reschedule could have disappeared timely

00:06:31,840 --> 00:06:34,960
to acquire the law can get better

00:06:34,160 --> 00:06:38,080
performance

00:06:34,960 --> 00:06:42,319
than just depending on lock ceiling in

00:06:38,080 --> 00:06:42,319
order to the right scenario

00:06:42,720 --> 00:06:48,960
the lock holder vcpu used to the q

00:06:45,919 --> 00:06:52,360
hat with cpu when unlocked to boost

00:06:48,960 --> 00:06:55,199
q hat with pure which is involuntary

00:06:52,360 --> 00:06:58,000
preemption of the one which is a

00:06:55,199 --> 00:06:58,800
voluntary how due to fuel to acquire the

00:06:58,000 --> 00:07:02,800
lock

00:06:58,800 --> 00:07:05,199
after a short spin in the guest

00:07:02,800 --> 00:07:06,800
the last one is the new helper call to

00:07:05,199 --> 00:07:10,560
you to api target

00:07:06,800 --> 00:07:14,400
while sending a call function ipr menu

00:07:10,560 --> 00:07:17,759
to vcpu used if any of the ipa target

00:07:14,400 --> 00:07:21,120
vcpu was printed we just select

00:07:17,759 --> 00:07:24,479
the printed target recipe which we found

00:07:21,120 --> 00:07:25,120
since the stage of target risk field can

00:07:24,479 --> 00:07:28,840
change

00:07:25,120 --> 00:07:31,680
underneath and to avoid the risk

00:07:28,840 --> 00:07:34,240
conditions

00:07:31,680 --> 00:07:35,919
let's see the performance number we

00:07:34,240 --> 00:07:39,680
tested this on

00:07:35,919 --> 00:07:43,120
a leong's cascade league two sockets

00:07:39,680 --> 00:07:46,240
48 cars 96 strikes

00:07:43,120 --> 00:07:48,879
each vm is 96 vcpu

00:07:46,240 --> 00:07:52,160
when vm is running a basic benchmark

00:07:48,879 --> 00:07:55,840
other vm running cpu bond workloads

00:07:52,160 --> 00:08:00,560
we can allow 3.4 improvement

00:07:55,840 --> 00:08:04,960
for 1 vm 224

00:08:00,560 --> 00:08:08,000
improvement for 2 vms 48.3

00:08:04,960 --> 00:08:10,720
improvement for 3 vms smp

00:08:08,000 --> 00:08:12,000
core function many cores can be in core

00:08:10,720 --> 00:08:15,199
function interrupts

00:08:12,000 --> 00:08:17,840
on the tlb shootdown pass with disable

00:08:15,199 --> 00:08:19,440
para virtual tlb shootdown feature in

00:08:17,840 --> 00:08:21,919
this testing

00:08:19,440 --> 00:08:24,840
since call function interrupt is not

00:08:21,919 --> 00:08:27,840
easy to be triggered by user space

00:08:24,840 --> 00:08:27,840

YouTube URL: https://www.youtube.com/watch?v=eQVH-zZK3so


