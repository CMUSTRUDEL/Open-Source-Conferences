Title: [2020] vDPA Support in Linux Kernel by Jason Wang
Publication date: 2020-12-09
Playlist: KVM Forum 2020
Description: 
	vDPA device means a type of device whose datapath complies with the virtio specification but with a vendor specific control path. In this session, the support for vDPA in Linux Kernel will be presented. A brief review of vDPA about its history, motivation and status will be briefed first. Then the design and implementation of kernel vDPA subsystem will be discussed. vDPA kernel subsystem is designed to work for any type of vDPA device with the flexibility to be easily integrated with new hardware technologies. The vDPA kernel subsystem cooperates with virtio and vhost subsystem for providing a unified and safe API for kernel virtio and userspace vhost driver to use. Vendor vDPA hardware driver is required for accepting request from vDPA subsystem and translate them to vendor specific command. Management integration and future work will be covered at the end of the session.

---

Jason Wang
Red Hat, Principal Software Engineer

Experienced Senior Software Engineer working for Red Hat with a demonstrated history of working in the computer software industry. Maintainer of qemu networking subsystem. Co-maintainer of Linux virtio, vhost and vdpa driver.
Captions: 
	00:00:05,759 --> 00:00:09,840
hello everybody

00:00:07,120 --> 00:00:11,599
this is jason wong from red hat welcome

00:00:09,840 --> 00:00:14,639
to the keyboard firm

00:00:11,599 --> 00:00:15,280
today i will give a talk about how vdp

00:00:14,639 --> 00:00:18,320
support

00:00:15,280 --> 00:00:18,320
in the linux kernel

00:00:19,119 --> 00:00:24,240
here is the outline we will first go

00:00:21,600 --> 00:00:26,720
through the virtual architecture

00:00:24,240 --> 00:00:30,080
and then we will try to introduce a new

00:00:26,720 --> 00:00:31,760
type of device called mdp device

00:00:30,080 --> 00:00:33,200
and after that we will discuss the

00:00:31,760 --> 00:00:34,399
design and implementations of

00:00:33,200 --> 00:00:37,920
probability framework

00:00:34,399 --> 00:00:41,280
in the linux kernel and we will conclude

00:00:37,920 --> 00:00:43,600
the presentation and will be a q a

00:00:41,280 --> 00:00:43,600
session

00:00:43,760 --> 00:00:46,879
so here is the virtual architecture

00:00:45,840 --> 00:00:48,879
overview

00:00:46,879 --> 00:00:51,120
so you can see that the retail

00:00:48,879 --> 00:00:52,399
architecture could be split into three

00:00:51,120 --> 00:00:56,399
layers

00:00:52,399 --> 00:00:58,960
in the upper layers bertel defines

00:00:56,399 --> 00:01:00,559
several different type of device for

00:00:58,960 --> 00:01:02,719
example it could be

00:01:00,559 --> 00:01:04,879
a networking device custody device block

00:01:02,719 --> 00:01:08,080
directly etc

00:01:04,879 --> 00:01:11,200
in the middle is the core device model

00:01:08,080 --> 00:01:12,560
it could be split into the definitions

00:01:11,200 --> 00:01:16,240
of the word queues

00:01:12,560 --> 00:01:18,560
feature bits and config space

00:01:16,240 --> 00:01:20,240
and on the lower layer it defines

00:01:18,560 --> 00:01:23,280
several transport

00:01:20,240 --> 00:01:24,560
which ties to device type to an extra

00:01:23,280 --> 00:01:28,560
bus

00:01:24,560 --> 00:01:32,560
so this back defines pci

00:01:28,560 --> 00:01:34,320
transport mmo and ccw transport

00:01:32,560 --> 00:01:37,759
so several different types of protocol

00:01:34,320 --> 00:01:39,920
devices has been implemented in software

00:01:37,759 --> 00:01:41,119
the first device implementation is done

00:01:39,920 --> 00:01:43,439
in qmo

00:01:41,119 --> 00:01:44,880
but its performance cannot satisfy our

00:01:43,439 --> 00:01:47,200
requirement

00:01:44,880 --> 00:01:48,320
then they move the data plane to the

00:01:47,200 --> 00:01:51,840
kernel

00:01:48,320 --> 00:01:54,399
by using the host protocol

00:01:51,840 --> 00:01:56,399
it can do better than qmo but it's still

00:01:54,399 --> 00:01:59,280
not sufficient

00:01:56,399 --> 00:02:01,119
so we offload the data plane from camera

00:01:59,280 --> 00:02:05,280
to another dedicated remote

00:02:01,119 --> 00:02:08,000
process through the rehost user protocol

00:02:05,280 --> 00:02:09,759
then it can achieve the best performance

00:02:08,000 --> 00:02:12,239
that a software data plane can even

00:02:09,759 --> 00:02:15,760
achieve

00:02:12,239 --> 00:02:18,640
so with the water specifications and

00:02:15,760 --> 00:02:19,920
software implementations of motor device

00:02:18,640 --> 00:02:23,040
we get good

00:02:19,920 --> 00:02:24,879
application usability we get a unified

00:02:23,040 --> 00:02:29,040
device in the facebook guest

00:02:24,879 --> 00:02:31,280
and we even get lab migration support

00:02:29,040 --> 00:02:32,720
but there are still several drawbacks

00:02:31,280 --> 00:02:34,879
the first is that

00:02:32,720 --> 00:02:36,160
the software implementations request

00:02:34,879 --> 00:02:40,239
extra cpu cycles

00:02:36,160 --> 00:02:41,840
to be spent and it requires extra

00:02:40,239 --> 00:02:44,959
management costs

00:02:41,840 --> 00:02:46,720
for settings such as cpu or memory

00:02:44,959 --> 00:02:48,640
affinity

00:02:46,720 --> 00:02:50,879
and the last and probably most important

00:02:48,640 --> 00:02:53,200
one is that it can't be

00:02:50,879 --> 00:02:54,800
reached the very speed due to the

00:02:53,200 --> 00:02:59,120
software overhead

00:02:54,800 --> 00:03:01,519
considered high the community highlight

00:02:59,120 --> 00:03:03,200
high speed internet and the network

00:03:01,519 --> 00:03:05,840
become

00:03:03,200 --> 00:03:05,840
available

00:03:06,959 --> 00:03:11,120
in order to address all the limitations

00:03:09,200 --> 00:03:13,680
found in the software hotel

00:03:11,120 --> 00:03:14,720
implementations some hardware vendors

00:03:13,680 --> 00:03:16,640
start to

00:03:14,720 --> 00:03:18,080
implement the hardware implementation

00:03:16,640 --> 00:03:20,400
for retail

00:03:18,080 --> 00:03:22,400
which means the device is fully

00:03:20,400 --> 00:03:23,680
compatible in both control paths and

00:03:22,400 --> 00:03:26,480
data paths

00:03:23,680 --> 00:03:27,519
with the water specification then it

00:03:26,480 --> 00:03:30,840
could reach

00:03:27,519 --> 00:03:32,959
rare speed and there will be no cpu

00:03:30,840 --> 00:03:34,799
overhang since all the

00:03:32,959 --> 00:03:36,159
data plane has been uploaded to the

00:03:34,799 --> 00:03:38,319
hardware

00:03:36,159 --> 00:03:41,519
the unified device was preserved and

00:03:38,319 --> 00:03:41,519
there will be no vendor log

00:03:42,560 --> 00:03:46,319
but there are several issues of hardware

00:03:44,239 --> 00:03:48,720
volatile implementation

00:03:46,319 --> 00:03:51,360
the first issue is that the current

00:03:48,720 --> 00:03:54,480
hotel is not designed to be virtualized

00:03:51,360 --> 00:03:55,599
there's no api for save and restore

00:03:54,480 --> 00:03:58,319
device state

00:03:55,599 --> 00:03:59,040
in the current model specification this

00:03:58,319 --> 00:04:01,519
means

00:03:59,040 --> 00:04:02,319
if you just expose raw water divide to

00:04:01,519 --> 00:04:05,519
the guest

00:04:02,319 --> 00:04:06,879
it can't be like migrated the second

00:04:05,519 --> 00:04:10,239
issue is that

00:04:06,879 --> 00:04:10,959
vertel is same and simple which means it

00:04:10,239 --> 00:04:13,280
will be

00:04:10,959 --> 00:04:14,480
hard to be integrated with existing

00:04:13,280 --> 00:04:16,160
converse deck

00:04:14,480 --> 00:04:18,400
so modern real hardware is much more

00:04:16,160 --> 00:04:21,120
complicated

00:04:18,400 --> 00:04:21,120
for example

00:04:21,600 --> 00:04:25,600
the srv capable ethernet card usually

00:04:25,280 --> 00:04:28,639
have

00:04:25,600 --> 00:04:31,520
embedded switch this means vendor

00:04:28,639 --> 00:04:32,320
may have their own specific api to

00:04:31,520 --> 00:04:35,440
config

00:04:32,320 --> 00:04:36,240
to program the switch all of this api

00:04:35,440 --> 00:04:39,440
must miss

00:04:36,240 --> 00:04:40,960
inverter specification and to be fully

00:04:39,440 --> 00:04:42,880
compatible in the control path

00:04:40,960 --> 00:04:46,240
also means a redesign of the control

00:04:42,880 --> 00:04:49,199
path which tends to be a challenge

00:04:46,240 --> 00:04:50,720
and it will be very hard to add many

00:04:49,199 --> 00:04:52,560
specific values

00:04:50,720 --> 00:04:54,639
which only requires many specific

00:04:52,560 --> 00:04:57,680
extensions

00:04:54,639 --> 00:04:58,960
and manageability is also bad since

00:04:57,680 --> 00:05:04,080
there's no management

00:04:58,960 --> 00:05:04,080
api defined in the retail specification

00:05:04,880 --> 00:05:08,880
so in order to address all the

00:05:06,560 --> 00:05:10,160
limitations we found in hardware hotel

00:05:08,880 --> 00:05:12,880
implementations

00:05:10,160 --> 00:05:14,479
may introduce the concept of bdpa so

00:05:12,880 --> 00:05:16,320
what is vdpa

00:05:14,479 --> 00:05:18,000
it's short for rehost datapass

00:05:16,320 --> 00:05:20,960
accelerations originally

00:05:18,000 --> 00:05:23,039
but then we realized we host distrust

00:05:20,960 --> 00:05:26,960
cancel fertility passive load

00:05:23,039 --> 00:05:30,400
so we change the definitions to the

00:05:26,960 --> 00:05:32,320
workflow data pass acceleration minipe

00:05:30,400 --> 00:05:35,520
device is basically a kind of hardware

00:05:32,320 --> 00:05:38,240
that has a wattel compatible database

00:05:35,520 --> 00:05:38,560
which is defined by inverters spec but

00:05:38,240 --> 00:05:42,240
it

00:05:38,560 --> 00:05:44,400
loads one specific control path

00:05:42,240 --> 00:05:46,479
and it was required diet such control

00:05:44,400 --> 00:05:48,960
parts should be functional equivalent

00:05:46,479 --> 00:05:51,600
or subside of the vertical control parts

00:05:48,960 --> 00:05:53,600
define the spec

00:05:51,600 --> 00:05:55,360
in order to support migrations the vdp

00:05:53,600 --> 00:05:58,560
data is also required to help

00:05:55,360 --> 00:06:01,680
part of the work b host features such as

00:05:58,560 --> 00:06:03,600
device recovery or 30 page tracking note

00:06:01,680 --> 00:06:07,280
that the dtp tracking is

00:06:03,600 --> 00:06:10,000
not a must

00:06:07,280 --> 00:06:12,240
so from hardware's perspective mdp

00:06:10,000 --> 00:06:15,280
device is a functional super side

00:06:12,240 --> 00:06:18,479
of the workout device so it contains

00:06:15,280 --> 00:06:21,759
the verticals the virtual features

00:06:18,479 --> 00:06:25,039
the host features and vendor specific

00:06:21,759 --> 00:06:27,600
config method which is functional

00:06:25,039 --> 00:06:31,120
equivalent to the portal config says

00:06:27,600 --> 00:06:35,840
and beyond that it was a load to add

00:06:31,120 --> 00:06:35,840
many specific features on top

00:06:36,160 --> 00:06:41,759
so why we need vdp you can see that

00:06:39,520 --> 00:06:43,840
making almost every advantage of

00:06:41,759 --> 00:06:47,280
hardware model implementations

00:06:43,840 --> 00:06:50,000
for example it has a unified datapath

00:06:47,280 --> 00:06:52,319
opens down nerd and it can reach wear

00:06:50,000 --> 00:06:52,319
speed

00:06:52,639 --> 00:06:56,240
besides those advantages they also gain

00:06:55,520 --> 00:06:59,039
more

00:06:56,240 --> 00:07:01,039
so we get live migration support by

00:06:59,039 --> 00:07:04,639
supporting the host features like

00:07:01,039 --> 00:07:07,599
device data recovery it was also a load

00:07:04,639 --> 00:07:11,280
bundle to add their

00:07:07,599 --> 00:07:14,080
add-on features on top but if we just

00:07:11,280 --> 00:07:16,240
expose raw vdp device with software

00:07:14,080 --> 00:07:20,080
there could be still several gaps

00:07:16,240 --> 00:07:22,319
for the end-to-end delivery for example

00:07:20,080 --> 00:07:24,080
do we really want to expose all the

00:07:22,319 --> 00:07:27,039
complexity and difference

00:07:24,080 --> 00:07:29,520
of the raw vp device with our player or

00:07:27,039 --> 00:07:30,960
do we want to integrate

00:07:29,520 --> 00:07:33,520
the military device with the existing

00:07:30,960 --> 00:07:37,199
systems only prevent the view

00:07:33,520 --> 00:07:40,319
for new dedicated subsystems

00:07:37,199 --> 00:07:40,720
and also how about manageability is

00:07:40,319 --> 00:07:44,560
there

00:07:40,720 --> 00:07:49,039
a vendor-specific mesh api or

00:07:44,560 --> 00:07:50,960
it could be a unified one and how about

00:07:49,039 --> 00:07:53,360
heavyweight dreamers or lightweight

00:07:50,960 --> 00:07:53,360
virus

00:07:54,720 --> 00:07:58,479
so in order to answer all of those

00:07:56,960 --> 00:08:01,520
questions

00:07:58,479 --> 00:08:03,599
or these comments we want to introduce

00:08:01,520 --> 00:08:05,919
the vdp kernel framework

00:08:03,599 --> 00:08:07,599
the main goal is to bridge the usability

00:08:05,919 --> 00:08:10,160
and manageability gap

00:08:07,599 --> 00:08:10,800
with the raw vdp device so it's

00:08:10,160 --> 00:08:13,120
basically

00:08:10,800 --> 00:08:14,960
a framework with the following features

00:08:13,120 --> 00:08:18,160
that is described

00:08:14,960 --> 00:08:19,840
first it should hide the complexity and

00:08:18,160 --> 00:08:23,039
difference of the underlayer device

00:08:19,840 --> 00:08:26,080
and present a simple thing device

00:08:23,039 --> 00:08:29,360
api to the software

00:08:26,080 --> 00:08:32,800
it also tried to present a unified

00:08:29,360 --> 00:08:35,919
imagine bible to simplify the task of

00:08:32,800 --> 00:08:38,560
a player's deck and if you try

00:08:35,919 --> 00:08:40,560
spice to be integrated seamlessly with

00:08:38,560 --> 00:08:42,959
all the existing subsystems

00:08:40,560 --> 00:08:43,839
which means it tries it will try his

00:08:42,959 --> 00:08:46,080
bias

00:08:43,839 --> 00:08:48,640
to reuse the codes in both kernel and

00:08:46,080 --> 00:08:50,560
user space applications

00:08:48,640 --> 00:08:51,839
and this framework should not be

00:08:50,560 --> 00:08:54,399
designed for

00:08:51,839 --> 00:08:55,760
user space streamers only it should

00:08:54,399 --> 00:08:58,560
serve for both

00:08:55,760 --> 00:09:00,320
kernel and user space drivers and the

00:08:58,560 --> 00:09:03,279
framework should be designed

00:09:00,320 --> 00:09:03,600
to be bus or device agnostics which

00:09:03,279 --> 00:09:06,839
means

00:09:03,600 --> 00:09:08,000
it will allow any types of device such

00:09:06,839 --> 00:09:10,880
as

00:09:08,000 --> 00:09:11,600
non-pci device fpga device or even

00:09:10,880 --> 00:09:14,320
software

00:09:11,600 --> 00:09:15,120
analytic device and you try to keep the

00:09:14,320 --> 00:09:18,320
drivers

00:09:15,120 --> 00:09:18,320
as lightweight as possible

00:09:20,480 --> 00:09:24,480
so here's the overview of the bdp

00:09:22,480 --> 00:09:26,399
framework so you can see that

00:09:24,480 --> 00:09:28,160
on hardware level there could be several

00:09:26,399 --> 00:09:29,680
types of pdp device

00:09:28,160 --> 00:09:32,160
which is all connected to the vp

00:09:29,680 --> 00:09:33,600
framework and to the up layers it can

00:09:32,160 --> 00:09:36,160
choose to connect

00:09:33,600 --> 00:09:37,839
the pdp device to both the host systems

00:09:36,160 --> 00:09:38,959
and vertical drivers

00:09:37,839 --> 00:09:41,279
so when connected to the whole

00:09:38,959 --> 00:09:44,240
subsystems it will present a vehicle's

00:09:41,279 --> 00:09:47,600
device and let applications to use

00:09:44,240 --> 00:09:50,720
the osu api to control the device

00:09:47,600 --> 00:09:52,080
as if it was a host device

00:09:50,720 --> 00:09:53,839
and when connected to the virtual

00:09:52,080 --> 00:09:56,320
drivers our kernel

00:09:53,839 --> 00:09:57,279
visible water interface will present to

00:09:56,320 --> 00:10:00,080
the kernel i o

00:09:57,279 --> 00:10:00,480
subsystems so the applications can

00:10:00,080 --> 00:10:03,600
choose

00:10:00,480 --> 00:10:05,279
any of the material

00:10:03,600 --> 00:10:07,839
uapi supported by the current iowa

00:10:05,279 --> 00:10:10,959
substance to control the

00:10:07,839 --> 00:10:13,360
midhouse device sorry the minidp device

00:10:10,959 --> 00:10:15,200
is federal retail device

00:10:13,360 --> 00:10:16,880
and the framework will also try to

00:10:15,200 --> 00:10:18,880
present a unified

00:10:16,880 --> 00:10:21,519
management api for the management

00:10:18,880 --> 00:10:21,519
applications

00:10:24,079 --> 00:10:28,160
so as discard as discussed the framework

00:10:27,200 --> 00:10:30,240
is tries to allow

00:10:28,160 --> 00:10:32,079
several different types of device and

00:10:30,240 --> 00:10:34,880
different types of travels

00:10:32,079 --> 00:10:36,000
so it's natural to consider to introduce

00:10:34,880 --> 00:10:38,720
the bus

00:10:36,000 --> 00:10:39,279
so the bdp bus is the core concept for

00:10:38,720 --> 00:10:42,000
the

00:10:39,279 --> 00:10:42,880
framework for abstracting the hardware

00:10:42,000 --> 00:10:45,120
which allows

00:10:42,880 --> 00:10:46,880
different bdp devices and drivers to be

00:10:45,120 --> 00:10:48,959
attached

00:10:46,880 --> 00:10:51,200
and the vdp bus also defines the

00:10:48,959 --> 00:10:54,800
communication protocol

00:10:51,200 --> 00:10:57,440
between the bus driver and the device

00:10:54,800 --> 00:10:58,399
so those communication protocol is a set

00:10:57,440 --> 00:11:02,000
of callbacks

00:10:58,399 --> 00:11:05,120
which is called vdp configurations

00:11:02,000 --> 00:11:06,959
and video device is the device

00:11:05,120 --> 00:11:12,000
abstractions provided by the minip

00:11:06,959 --> 00:11:14,720
private device driver which

00:11:12,000 --> 00:11:15,279
have several common attributes of the vp

00:11:14,720 --> 00:11:18,959
device

00:11:15,279 --> 00:11:22,640
and also the implementation of the vdp

00:11:18,959 --> 00:11:23,440
config operations so on top of the vtp

00:11:22,640 --> 00:11:25,200
bus

00:11:23,440 --> 00:11:28,160
several different types of vp bus

00:11:25,200 --> 00:11:31,839
drivers were allowed to be attached

00:11:28,160 --> 00:11:34,320
those tasks is to connect the pdb device

00:11:31,839 --> 00:11:37,120
to the existing

00:11:34,320 --> 00:11:38,880
kernel subsystems and use the vertel

00:11:37,120 --> 00:11:44,000
sorry mdp config

00:11:38,880 --> 00:11:46,480
operations to talk with the bdp device

00:11:44,000 --> 00:11:48,560
so you can see from the view of the bdp

00:11:46,480 --> 00:11:49,680
bus server you can only see the mini p

00:11:48,560 --> 00:11:52,720
device

00:11:49,680 --> 00:11:54,399
and vdp config operations all the

00:11:52,720 --> 00:11:56,720
complexity and difference

00:11:54,399 --> 00:11:57,839
was highlighted they are the bdp device

00:11:56,720 --> 00:12:00,240
abstraction

00:11:57,839 --> 00:12:00,240
and bus

00:12:01,680 --> 00:12:08,240
so wikipedia device is for the common

00:12:04,959 --> 00:12:09,040
abstractions and vdp parent is the

00:12:08,240 --> 00:12:12,240
module that

00:12:09,040 --> 00:12:13,200
provides such abstractions so it needs

00:12:12,240 --> 00:12:15,440
to

00:12:13,200 --> 00:12:16,560
provide the com attributes and to

00:12:15,440 --> 00:12:19,680
implement

00:12:16,560 --> 00:12:22,560
the config operations of the bdp

00:12:19,680 --> 00:12:24,720
bus so config options usually contain

00:12:22,560 --> 00:12:27,519
several different

00:12:24,720 --> 00:12:28,959
types for example it will contain the

00:12:27,519 --> 00:12:31,200
retail

00:12:28,959 --> 00:12:33,200
specific operations such as the word

00:12:31,200 --> 00:12:36,399
queue

00:12:33,200 --> 00:12:38,880
attribute setting the divide state speed

00:12:36,399 --> 00:12:41,519
chart negotiation

00:12:38,880 --> 00:12:42,560
and something etc yeah and it will also

00:12:41,519 --> 00:12:44,079
contain

00:12:42,560 --> 00:12:45,839
the interrupt and the doorbell

00:12:44,079 --> 00:12:49,440
acceleration method for

00:12:45,839 --> 00:12:54,480
fast success to the interrupt enterprise

00:12:49,440 --> 00:12:54,480
and in order to be more generic

00:12:54,720 --> 00:13:02,560
it will also contain the dna map

00:12:58,079 --> 00:13:05,519
method which could be very convenient

00:13:02,560 --> 00:13:06,959
for device that has on-chip mmu or have

00:13:05,519 --> 00:13:09,920
a sophisticated

00:13:06,959 --> 00:13:12,160
dma mapping logic and it will also

00:13:09,920 --> 00:13:14,399
contain the host

00:13:12,160 --> 00:13:16,320
operations for device state recovery and

00:13:14,399 --> 00:13:18,800
dirty page tracking

00:13:16,320 --> 00:13:20,000
so the parent can be any type for

00:13:18,800 --> 00:13:22,160
example it could be a

00:13:20,000 --> 00:13:24,079
real parent device driver that talks to

00:13:22,160 --> 00:13:26,880
the vdp device directly

00:13:24,079 --> 00:13:29,920
or it could be an intermediate layer on

00:13:26,880 --> 00:13:32,560
top of another device driver framework

00:13:29,920 --> 00:13:36,000
or it could be even a software emulated

00:13:32,560 --> 00:13:38,560
pdp device or a proxy or relay

00:13:36,000 --> 00:13:42,079
of turbidity protocol to some other

00:13:38,560 --> 00:13:42,079
modules or even user space

00:13:44,880 --> 00:13:48,000
so we know several different types of

00:13:47,440 --> 00:13:50,560
pdp

00:13:48,000 --> 00:13:51,600
bus drivers to be attached so we will

00:13:50,560 --> 00:13:54,639
first talk

00:13:51,600 --> 00:13:56,240
that we host vdp bus driver so this bus

00:13:54,639 --> 00:13:57,760
driver is used to present

00:13:56,240 --> 00:14:00,320
a v-host device through the v-host

00:13:57,760 --> 00:14:01,360
subsystems so it serves mainly for the

00:14:00,320 --> 00:14:03,839
user space

00:14:01,360 --> 00:14:05,120
virtual drivers for example it could

00:14:03,839 --> 00:14:08,240
serve for

00:14:05,120 --> 00:14:11,760
qmlb host packet for camera to present

00:14:08,240 --> 00:14:14,079
a virtual data path to vm or it could

00:14:11,760 --> 00:14:17,199
serve for dpdk voter pmb

00:14:14,079 --> 00:14:18,959
which serves for nfv use case so the

00:14:17,199 --> 00:14:21,680
idea is trying to

00:14:18,959 --> 00:14:22,399
reuse as much we host dynamic ups

00:14:21,680 --> 00:14:25,279
possible

00:14:22,399 --> 00:14:27,360
for data path setting but it also

00:14:25,279 --> 00:14:29,839
requires some dedicated

00:14:27,360 --> 00:14:30,560
uap extensions for four device

00:14:29,839 --> 00:14:32,720
abstractions

00:14:30,560 --> 00:14:34,639
which is missed in the generic viewhoseo

00:14:32,720 --> 00:14:37,279
api

00:14:34,639 --> 00:14:37,920
so those who usually contains something

00:14:37,279 --> 00:14:41,440
like uh

00:14:37,920 --> 00:14:45,839
configure space success this devices get

00:14:41,440 --> 00:14:45,839
inside copy interrupt etc

00:14:46,160 --> 00:14:49,920
so the traditional you a-host user

00:14:48,720 --> 00:14:53,040
applications

00:14:49,920 --> 00:14:56,240
only need very minimal changes

00:14:53,040 --> 00:14:58,720
then it can use to be host bdp

00:14:56,240 --> 00:14:59,519
bus travelers to control the vdp device

00:14:58,720 --> 00:15:02,560
as if

00:14:59,519 --> 00:15:02,560
they were virtual device

00:15:04,079 --> 00:15:08,240
the second bus driver we provide is the

00:15:05,920 --> 00:15:10,320
retail vdp bus driver

00:15:08,240 --> 00:15:12,800
so its goal is to present a v host

00:15:10,320 --> 00:15:16,639
device to the virtualbox

00:15:12,800 --> 00:15:19,680
then this pseudo or proxy motel device

00:15:16,639 --> 00:15:22,800
could be probed by the mortal drivers

00:15:19,680 --> 00:15:22,800
so the water driver will be

00:15:23,040 --> 00:15:28,480
so the virtual device will be visible to

00:15:25,199 --> 00:15:28,480
the kernel io subsystems

00:15:28,800 --> 00:15:32,720
this is done by introducing a new vdp

00:15:31,440 --> 00:15:36,000
transport

00:15:32,720 --> 00:15:40,320
for the retail bus

00:15:36,000 --> 00:15:43,199
then the kernel io subsystems can use

00:15:40,320 --> 00:15:44,639
vedic device as if they were virtual

00:15:43,199 --> 00:15:47,519
device

00:15:44,639 --> 00:15:48,079
this means the applications can use for

00:15:47,519 --> 00:15:52,560
example

00:15:48,079 --> 00:15:55,600
tcp stack storage stack aero xct or any

00:15:52,560 --> 00:15:59,440
kernel systems

00:15:55,600 --> 00:16:00,959
to a transfer date between cells and bdp

00:15:59,440 --> 00:16:03,120
device

00:16:00,959 --> 00:16:05,519
the main use case for the water vdp

00:16:03,120 --> 00:16:09,839
device is for bare metal applications or

00:16:05,519 --> 00:16:09,839
containerized applications

00:16:11,440 --> 00:16:14,959
and for the management api we will try

00:16:13,279 --> 00:16:18,560
to introduce a dedicated

00:16:14,959 --> 00:16:22,079
multi-specific netlink protocol for the

00:16:18,560 --> 00:16:25,120
bdp device management which mainly can

00:16:22,079 --> 00:16:25,839
contains the first is a lifecycle

00:16:25,120 --> 00:16:29,040
management

00:16:25,839 --> 00:16:29,839
to create destroy enable disable and

00:16:29,040 --> 00:16:33,839
also

00:16:29,839 --> 00:16:37,519
to setting attributes or provision

00:16:33,839 --> 00:16:39,440
wp device the idea is to introduce a new

00:16:37,519 --> 00:16:41,120
vp programs that will be integrated into

00:16:39,440 --> 00:16:44,240
iplode 2

00:16:41,120 --> 00:16:46,399
and then the management api will use

00:16:44,240 --> 00:16:49,040
either these programs or the netlink

00:16:46,399 --> 00:16:53,600
direct protocol directly

00:16:49,040 --> 00:16:56,079
for unified configuration interface

00:16:53,600 --> 00:16:57,839
all vdp device pyro device is required

00:16:56,079 --> 00:17:00,320
to implement vdp network

00:16:57,839 --> 00:17:00,320
protocol

00:17:03,600 --> 00:17:09,439
so currently linux kernel have supported

00:17:06,720 --> 00:17:11,280
three midip parents the first is the

00:17:09,439 --> 00:17:13,360
intel fcvf

00:17:11,280 --> 00:17:14,959
so from the hardware perspective it

00:17:13,360 --> 00:17:18,160
address a retail

00:17:14,959 --> 00:17:19,839
device plus into specific extensions

00:17:18,160 --> 00:17:21,919
and vdp is implemented through a

00:17:19,839 --> 00:17:25,120
dedicated via

00:17:21,919 --> 00:17:27,280
so each parent driver is simply a pci vf

00:17:25,120 --> 00:17:29,280
device driver

00:17:27,280 --> 00:17:31,679
the second vdp parent is the main lux

00:17:29,280 --> 00:17:35,760
5vdpa parent

00:17:31,679 --> 00:17:38,559
so this device is also

00:17:35,760 --> 00:17:41,280
implementing a dedicated vf but it has a

00:17:38,559 --> 00:17:43,760
total vendor specific control path

00:17:41,280 --> 00:17:46,080
this parent is an intermediate layer on

00:17:43,760 --> 00:17:49,360
top of the existing malnox file core

00:17:46,080 --> 00:17:50,400
module and the third parent is the vdp

00:17:49,360 --> 00:17:54,160
simulator

00:17:50,400 --> 00:17:58,320
which is basically used for uh

00:17:54,160 --> 00:18:00,400
device testing feature prototyping etc

00:17:58,320 --> 00:18:02,720
so this pattern is implemented purely

00:18:00,400 --> 00:18:04,400
through software emulation

00:18:02,720 --> 00:18:06,160
and we are working with blenders for

00:18:04,400 --> 00:18:09,280
more types of

00:18:06,160 --> 00:18:11,600
vp parents such as the adi

00:18:09,280 --> 00:18:13,200
which complies the intel scalable lv

00:18:11,600 --> 00:18:16,400
specification

00:18:13,200 --> 00:18:17,039
or device or one specific device slides

00:18:16,400 --> 00:18:20,240
such as

00:18:17,039 --> 00:18:20,720
soft function or even a pcie endpoint

00:18:20,240 --> 00:18:23,760
device

00:18:20,720 --> 00:18:29,679
which means the vdp is implemented

00:18:23,760 --> 00:18:32,640
via a remote sock

00:18:29,679 --> 00:18:35,360
so here's basically the status of the

00:18:32,640 --> 00:18:39,360
vdp support in the current link kernel

00:18:35,360 --> 00:18:42,720
so basic functions such as vtp core

00:18:39,360 --> 00:18:45,360
bus drivers and three vdp

00:18:42,720 --> 00:18:48,000
parents has been merged and the basic

00:18:45,360 --> 00:18:50,000
thermal function has been made by qmo

00:18:48,000 --> 00:18:51,600
and then we are working on for example

00:18:50,000 --> 00:18:54,880
networking based main benefit

00:18:51,600 --> 00:18:56,799
which would be post soon

00:18:54,880 --> 00:18:58,640
and the live migration support is also

00:18:56,799 --> 00:19:00,480
under development

00:18:58,640 --> 00:19:02,720
for life migration we will probably

00:19:00,480 --> 00:19:06,559
probably start from a software

00:19:02,720 --> 00:19:09,200
assisted uh lab micro first

00:19:06,559 --> 00:19:11,360
this means it doesn't require any device

00:19:09,200 --> 00:19:13,600
support for thirty page tracking

00:19:11,360 --> 00:19:15,760
camera will try to assist the device for

00:19:13,600 --> 00:19:18,320
30 page tracking

00:19:15,760 --> 00:19:19,039
and after this we will try to implant

00:19:18,320 --> 00:19:24,240
new api

00:19:19,039 --> 00:19:26,080
for supporting wp tracking from hardware

00:19:24,240 --> 00:19:29,840
and you can see also the controlled

00:19:26,080 --> 00:19:32,160
queue work is being development upstream

00:19:29,840 --> 00:19:33,039
and we are working with vendors to make

00:19:32,160 --> 00:19:34,799
sure that

00:19:33,039 --> 00:19:36,799
the framework and the drivers can work

00:19:34,799 --> 00:19:38,880
for device not the networking

00:19:36,799 --> 00:19:41,280
we will probably start from the block

00:19:38,880 --> 00:19:41,280
device

00:19:42,799 --> 00:19:46,240
and for the future there are several

00:19:44,799 --> 00:19:49,520
things in our mind

00:19:46,240 --> 00:19:51,679
the first is we will need to finalize

00:19:49,520 --> 00:19:54,240
the documentations in the kernel source

00:19:51,679 --> 00:19:58,559
which contains both the vdp device

00:19:54,240 --> 00:20:01,679
api definitions and the host vdp uapi

00:19:58,559 --> 00:20:03,520
and we also plan to collab with

00:20:01,679 --> 00:20:04,960
the platform windows to support shared

00:20:03,520 --> 00:20:09,440
virtual address or even

00:20:04,960 --> 00:20:12,080
virtual shadow first first address

00:20:09,440 --> 00:20:13,440
and i will also plan to extend whatever

00:20:12,080 --> 00:20:18,159
specifications

00:20:13,440 --> 00:20:18,159
for some vdp specific extension

00:20:19,200 --> 00:20:22,799
okay so let's conclude these

00:20:21,520 --> 00:20:25,360
presentations

00:20:22,799 --> 00:20:27,200
first we introduce a new type of device

00:20:25,360 --> 00:20:30,080
called bdp device

00:20:27,200 --> 00:20:32,640
the mdp device has retail data paths

00:20:30,080 --> 00:20:35,600
with manual specific control paths

00:20:32,640 --> 00:20:37,039
and we host features and we've

00:20:35,600 --> 00:20:38,080
introduced the host framework in the

00:20:37,039 --> 00:20:39,840
linux kernel

00:20:38,080 --> 00:20:42,000
which tries to hide the difference in

00:20:39,840 --> 00:20:43,280
complexity of different types of vb

00:20:42,000 --> 00:20:46,840
device and present

00:20:43,280 --> 00:20:49,919
a unified device manual api to the upper

00:20:46,840 --> 00:20:50,960
layer the vp framework contains the bdp

00:20:49,919 --> 00:20:52,799
bus

00:20:50,960 --> 00:20:54,080
and the device for obstructing the

00:20:52,799 --> 00:20:56,640
device

00:20:54,080 --> 00:20:57,520
and we also allows different types of bb

00:20:56,640 --> 00:21:00,000
bus drivers

00:20:57,520 --> 00:21:02,400
for connecting the bbp device to various

00:21:00,000 --> 00:21:05,440
kernel subsystems

00:21:02,400 --> 00:21:07,840
so we support both v-host

00:21:05,440 --> 00:21:10,320
and retail drivers to light the mtp

00:21:07,840 --> 00:21:12,320
device to be used by

00:21:10,320 --> 00:21:15,280
both the kernel hotel drivers and user

00:21:12,320 --> 00:21:18,000
space retail drivers

00:21:15,280 --> 00:21:19,919
with the helps of the both uh multiple

00:21:18,000 --> 00:21:22,559
device and relative framework

00:21:19,919 --> 00:21:23,360
we could achieve wire speed vertel with

00:21:22,559 --> 00:21:26,000
the best

00:21:23,360 --> 00:21:26,720
usability and management ability so

00:21:26,000 --> 00:21:29,039
there will be no

00:21:26,720 --> 00:21:31,200
underlog and there will be level

00:21:29,039 --> 00:21:33,120
migraine support or even cross vendor

00:21:31,200 --> 00:21:36,320
left migration

00:21:33,120 --> 00:21:38,480
a unified management interface

00:21:36,320 --> 00:21:39,679
was provided for ease the task of the

00:21:38,480 --> 00:21:42,559
management stack

00:21:39,679 --> 00:21:44,240
and we will get material software stack

00:21:42,559 --> 00:21:48,000
in both house and gas

00:21:44,240 --> 00:21:51,280
since we present mortal or we host

00:21:48,000 --> 00:21:51,280
device to the player

00:21:54,080 --> 00:21:57,679
so here are some good reference first is

00:21:56,559 --> 00:22:02,080
the predicted

00:21:57,679 --> 00:22:04,480
done by stu in the previous uh kvm forum

00:22:02,080 --> 00:22:05,280
the second is two series of blog load by

00:22:04,480 --> 00:22:08,000
us

00:22:05,280 --> 00:22:08,640
which contains almost every aspect of

00:22:08,000 --> 00:22:12,480
both

00:22:08,640 --> 00:22:15,120
retail and bdpa and it also contains

00:22:12,480 --> 00:22:17,600
several deep dive for the vdp kernel

00:22:15,120 --> 00:22:20,159
framework and it's the typical use case

00:22:17,600 --> 00:22:21,120
so you are welcome to go through those

00:22:20,159 --> 00:22:24,960
blog series

00:22:21,120 --> 00:22:26,960
and give us feedback and it's

00:22:24,960 --> 00:22:29,360
also be useful for review and have a

00:22:26,960 --> 00:22:33,200
look at virtual specification

00:22:29,360 --> 00:22:36,000
and if you want to ask or hear from what

00:22:33,200 --> 00:22:36,720
is recently being developed for vdp

00:22:36,000 --> 00:22:40,240
expect

00:22:36,720 --> 00:22:43,840
you are welcome to subscribe the bdp

00:22:40,240 --> 00:22:43,840
development mailing list

00:22:44,799 --> 00:22:51,520
so vdp has come to real life it's not

00:22:48,240 --> 00:22:54,960
a concept in the paper you are welcome

00:22:51,520 --> 00:22:55,840
to consider to deployment the vdp device

00:22:54,960 --> 00:22:59,039
in your cloud

00:22:55,840 --> 00:23:01,120
or you want vdp-based hardware

00:22:59,039 --> 00:23:02,159
and you are also welcome to test and

00:23:01,120 --> 00:23:05,600
contribute

00:23:02,159 --> 00:23:05,600
to the vdp framework

00:23:06,000 --> 00:23:09,520
please contact us if you have any

00:23:08,159 --> 00:23:12,400
questions

00:23:09,520 --> 00:23:13,760
for example the hardware uh design

00:23:12,400 --> 00:23:17,200
driver implementation

00:23:13,760 --> 00:23:20,480
deploys inclusion and management issues

00:23:17,200 --> 00:23:23,600
or even feature requests you can drop

00:23:20,480 --> 00:23:25,360
a mail to either the mertel networking

00:23:23,600 --> 00:23:30,320
mailing list or

00:23:25,360 --> 00:23:30,320
private mail to me that's it

00:23:34,840 --> 00:23:38,559
thanks

00:23:36,480 --> 00:23:38,559

YouTube URL: https://www.youtube.com/watch?v=HarITOZ0hIw


