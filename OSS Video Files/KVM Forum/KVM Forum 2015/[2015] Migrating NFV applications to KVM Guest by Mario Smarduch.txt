Title: [2015] Migrating NFV applications to KVM Guest by Mario Smarduch
Publication date: 2015-09-08
Playlist: KVM Forum 2015
Description: 
	Network Functions Virtualization (NFV) promises to extend the network management benefits that are currently enjoyed in IT environments, but so far the focus has mostly been on the cloud portion of NFV with little effort being spent on the hypervisor, guest, and emulation layers. You can't simply move an NFV application from native environments to guest environments because it will be bound to fail, or at best, perform sporadically. This presentation will address the subtle differences between native and virtualized behaviors by systematically walking through guest, hypervisor, and emulation features. In addition, it will cover the challenges encountered by typical state machine protocols, real-time applications, and guests that deal with passed-through devices. Lastly, this talk will propose enhancements to all levels of the virtualization stack and application design.

Mario Smarduch
Samsung
Senior Virtualization Architect
Mario Smarduch is a Senior Virtualization Architect at Samsung's Open Source Group. Currently, he's working on ARM-KVM features and optimizations for Samsung products. He's also engaged in the Linux kernel KVM open source community, recently upstreaming dirty page logging support for ARM versions 7 and 8 supporting rapid migration for memory intensive workloads. Prior to Samsung, Mario worked at Huawei Technologies where he was focusing on ETSI ISG NFV KVM-ARM virtualization extensions for Telco gear - features like real-time, interrupt optimization, zero copy inter guest communication, optimized
device-passthrough. In the past he's presented in LinuxCon Japan, Korea Linux Forum, Keio Univesity.

Slides: https://drive.google.com/open?id=0BzyAwvVlQckeQlM4T3Z0amhpeUU
Captions: 
	00:00:14,330 --> 00:00:19,880
alright everyone thanks for attending

00:00:17,010 --> 00:00:22,289
this car I mean this meeting go here and

00:00:19,880 --> 00:00:24,060
first of all we had a pretty big hiccup

00:00:22,289 --> 00:00:28,980
of here trying to get the server up and

00:00:24,060 --> 00:00:31,050
working and the display working so this

00:00:28,980 --> 00:00:33,270
presentation is basically about porting

00:00:31,050 --> 00:00:36,809
network functions and took a vm cast

00:00:33,270 --> 00:00:39,300
environment and approach that we took is

00:00:36,809 --> 00:00:42,030
essentially trying to before calling

00:00:39,300 --> 00:00:45,420
anything real time we first tried to

00:00:42,030 --> 00:00:49,829
port most of the enhanced packet core

00:00:45,420 --> 00:00:55,530
network elements and try to essentially

00:00:49,829 --> 00:01:00,440
assess how how fit kvm is for these

00:00:55,530 --> 00:01:02,399
applications so from the previous

00:01:00,440 --> 00:01:05,970
presentations you know I've kind of

00:01:02,399 --> 00:01:08,729
scaled back a little bit because you

00:01:05,970 --> 00:01:10,680
know folks have talked about it NFS I

00:01:08,729 --> 00:01:13,049
think everybody knows what nfe is and

00:01:10,680 --> 00:01:18,689
everybody knows you know what the

00:01:13,049 --> 00:01:21,119
advantages of n fer also as far as you

00:01:18,689 --> 00:01:22,710
know why we want full virtualization I

00:01:21,119 --> 00:01:25,340
me there's you know lots of ways to

00:01:22,710 --> 00:01:27,479
virtualize a guest you know there's also

00:01:25,340 --> 00:01:31,140
container is about full virtualization

00:01:27,479 --> 00:01:32,820
is one area which kind of gives us a lot

00:01:31,140 --> 00:01:35,189
of advantages you know the ability to

00:01:32,820 --> 00:01:37,439
run mix the buses and mix the shows and

00:01:35,189 --> 00:01:41,400
you are just basically on the whole

00:01:37,439 --> 00:01:43,890
stack and live migration and deliver a

00:01:41,400 --> 00:01:46,079
hoe vm without any kind of strings

00:01:43,890 --> 00:01:49,890
attached as far as libraries or anything

00:01:46,079 --> 00:01:53,600
us so I think everybody's very well

00:01:49,890 --> 00:01:57,000
aware of this this is more of a

00:01:53,600 --> 00:01:59,219
throwback to a previous effort which is

00:01:57,000 --> 00:02:02,369
carry a great line XO I'm not gone to a

00:01:59,219 --> 00:02:04,799
to too much on this about the only thing

00:02:02,369 --> 00:02:06,810
I would say is that this kind of is

00:02:04,799 --> 00:02:10,470
similar to what we have today where we

00:02:06,810 --> 00:02:12,060
had essentially a lot of gaps and Linus

00:02:10,470 --> 00:02:15,209
was simply not fit to go and

00:02:12,060 --> 00:02:16,590
Carrie great environment and so what

00:02:15,209 --> 00:02:20,160
happened is that these gaps were

00:02:16,590 --> 00:02:22,200
identified so you had so so what a gap

00:02:20,160 --> 00:02:24,090
is really what it really is as the

00:02:22,200 --> 00:02:25,980
expectation versus the implementation

00:02:24,090 --> 00:02:28,380
and in some case there was no

00:02:25,980 --> 00:02:30,959
implementation and I think in the case

00:02:28,380 --> 00:02:33,480
of n fe we kind of have the same

00:02:30,959 --> 00:02:35,280
situation so we have this so we have the

00:02:33,480 --> 00:02:38,280
situation of the things where the user

00:02:35,280 --> 00:02:40,140
has to be aware you know just the way

00:02:38,280 --> 00:02:42,630
things operate you know there's things

00:02:40,140 --> 00:02:45,350
where we have missing features there's

00:02:42,630 --> 00:02:49,980
things where we need Hardware extensions

00:02:45,350 --> 00:02:52,200
and you know there's also of course kvm

00:02:49,980 --> 00:02:54,810
and Colonel enhancements and things of

00:02:52,200 --> 00:02:56,519
that nature so eventually you know the

00:02:54,810 --> 00:02:59,150
community got together all these things

00:02:56,519 --> 00:03:01,890
got resolved now when we're talking and

00:02:59,150 --> 00:03:04,769
IV it's a much more complex situation

00:03:01,890 --> 00:03:07,019
because besides the fact that we're just

00:03:04,769 --> 00:03:08,670
dealing with Linux and kvm we have a lot

00:03:07,019 --> 00:03:12,110
of different proprietary players and

00:03:08,670 --> 00:03:15,959
these players are in many ways much more

00:03:12,110 --> 00:03:18,989
focused and you know they could kind of

00:03:15,959 --> 00:03:22,290
just beam down to the problem and and in

00:03:18,989 --> 00:03:25,769
many ways be able to deliver a better

00:03:22,290 --> 00:03:28,769
better solution so it's very important

00:03:25,769 --> 00:03:30,359
that we look at these gaps and the gaps

00:03:28,769 --> 00:03:32,640
that we talked about and here is not

00:03:30,359 --> 00:03:35,760
just real time but you know many many

00:03:32,640 --> 00:03:37,709
other type of issues and you know having

00:03:35,760 --> 00:03:41,310
worked and the carrier great environment

00:03:37,709 --> 00:03:43,319
and you know I've been out to in all

00:03:41,310 --> 00:03:44,910
sorts of different deployment sites and

00:03:43,319 --> 00:03:48,569
you know supportive customers and so

00:03:44,910 --> 00:03:50,340
forth I got a fairly good idea of what

00:03:48,569 --> 00:03:54,299
the carriers are really looking for when

00:03:50,340 --> 00:03:56,100
you deliver something to them so this

00:03:54,299 --> 00:03:59,160
one I just kind of shortly summarized

00:03:56,100 --> 00:04:01,650
you know so we know that the carrier

00:03:59,160 --> 00:04:05,010
great environment is extremely demanding

00:04:01,650 --> 00:04:07,079
you know there's a lot of metrics but to

00:04:05,010 --> 00:04:09,660
take away from this one is that from

00:04:07,079 --> 00:04:11,310
this slide is the fact that the ability

00:04:09,660 --> 00:04:15,959
to root cause problems and root cause

00:04:11,310 --> 00:04:18,030
them very quickly so when you develop a

00:04:15,959 --> 00:04:19,709
network element you know you pretty much

00:04:18,030 --> 00:04:21,780
are going to be stuck with the most

00:04:19,709 --> 00:04:23,099
basic tools to root cause a problem so

00:04:21,780 --> 00:04:24,340
you're not going to have access to pmu

00:04:23,099 --> 00:04:27,790
and debug and things

00:04:24,340 --> 00:04:31,090
like that and so before deployment is

00:04:27,790 --> 00:04:33,010
very very important to use the tools

00:04:31,090 --> 00:04:36,250
that you would actually use out in the

00:04:33,010 --> 00:04:40,060
field and essentially use the same same

00:04:36,250 --> 00:04:41,590
tools for for development now in as far

00:04:40,060 --> 00:04:44,760
as the rest of the thing you know as far

00:04:41,590 --> 00:04:47,229
as the stringent retired stringent

00:04:44,760 --> 00:04:49,750
requirements like on data plane and you

00:04:47,229 --> 00:04:51,580
know control plane and things like that

00:04:49,750 --> 00:04:53,770
you know that's probably something that

00:04:51,580 --> 00:04:55,590
you know it's very would probably take

00:04:53,770 --> 00:04:59,410
up too much time to go to this type of

00:04:55,590 --> 00:05:01,660
discussion so just kind of a little bit

00:04:59,410 --> 00:05:04,720
of a diamond into a wireless environment

00:05:01,660 --> 00:05:07,090
and I looks and so you know pretty much

00:05:04,720 --> 00:05:09,520
no matter if you look at 2g or 4G you

00:05:07,090 --> 00:05:10,900
pretty much come down to several factors

00:05:09,520 --> 00:05:12,850
you have the control plane you have the

00:05:10,900 --> 00:05:15,490
data plane and you have the operations

00:05:12,850 --> 00:05:17,350
and maintenance and when you look at the

00:05:15,490 --> 00:05:21,220
control plane as well three events on

00:05:17,350 --> 00:05:23,860
timers and you know these things can

00:05:21,220 --> 00:05:25,270
range from extremes like land mobile

00:05:23,860 --> 00:05:28,930
radio networks where you have

00:05:25,270 --> 00:05:33,700
push-to-talk technology to just normal

00:05:28,930 --> 00:05:35,979
you know plmn which is much much more of

00:05:33,700 --> 00:05:38,200
a relaxed you know type of Layton sees

00:05:35,979 --> 00:05:40,090
that we will be dealing with so I mean

00:05:38,200 --> 00:05:42,160
when you take something like LTE I'm yo

00:05:40,090 --> 00:05:45,310
te has done a lot of things than the

00:05:42,160 --> 00:05:47,500
packet core because you know we got rid

00:05:45,310 --> 00:05:49,380
of circuit switched and there is a lot

00:05:47,500 --> 00:05:51,400
of what we call non-access stratum

00:05:49,380 --> 00:05:53,349
procedures that have been combined with

00:05:51,400 --> 00:05:55,900
excess fat and procedures but still the

00:05:53,349 --> 00:05:59,280
bottom line is is the radio interface

00:05:55,900 --> 00:06:02,860
that's really has improved over over

00:05:59,280 --> 00:06:05,860
well and 4G that's that's really you

00:06:02,860 --> 00:06:07,930
know that that by far as giving us

00:06:05,860 --> 00:06:12,729
mostly the capacity you know that we're

00:06:07,930 --> 00:06:16,090
getting so essentially you know when we

00:06:12,729 --> 00:06:17,710
when we look at let's say you know in

00:06:16,090 --> 00:06:19,690
this in this slide what we have is we

00:06:17,710 --> 00:06:21,940
have yellow which is trying to do a push

00:06:19,690 --> 00:06:24,370
to talk to green so there's a lot of

00:06:21,940 --> 00:06:27,340
control messages going back and forth

00:06:24,370 --> 00:06:30,130
and when you get down to it each network

00:06:27,340 --> 00:06:33,610
government has a pre-allocated latency

00:06:30,130 --> 00:06:37,680
and each link also has a pre-allocated

00:06:33,610 --> 00:06:39,849
agency so for from control

00:06:37,680 --> 00:06:41,740
control plane point of view what we're

00:06:39,849 --> 00:06:45,819
really dealing with as deterministic

00:06:41,740 --> 00:06:48,930
execution but not just any determinant

00:06:45,819 --> 00:06:51,969
not just any deterministic execution but

00:06:48,930 --> 00:06:53,590
latency on their specific capacity so

00:06:51,969 --> 00:06:56,530
each another government is kind of scope

00:06:53,590 --> 00:06:59,229
to a certain capacity and we have to be

00:06:56,530 --> 00:07:01,090
able to meet the latency for various

00:06:59,229 --> 00:07:07,509
signaling that's flowing through the

00:07:01,090 --> 00:07:09,729
network okay LTE so this is like one

00:07:07,509 --> 00:07:12,689
side and sad difficult to you know

00:07:09,729 --> 00:07:15,599
explained LTE and a single slide but

00:07:12,689 --> 00:07:18,340
really you know when you look at it so

00:07:15,599 --> 00:07:20,669
it comes down to several things when you

00:07:18,340 --> 00:07:23,439
look at ltu first of all have the

00:07:20,669 --> 00:07:24,789
control plane and the data plane and you

00:07:23,439 --> 00:07:26,439
could really look at the control plane

00:07:24,789 --> 00:07:29,349
you know just like a normal switch where

00:07:26,439 --> 00:07:31,270
you're configuring routes and then the

00:07:29,349 --> 00:07:33,879
then the data plane is pretty much like

00:07:31,270 --> 00:07:36,490
the switching portion of it you know of

00:07:33,879 --> 00:07:38,590
course LT is much more complex it has

00:07:36,490 --> 00:07:41,639
the EU tram portion and it has the

00:07:38,590 --> 00:07:44,259
enhanced back packet core portion and

00:07:41,639 --> 00:07:46,029
most of the focus is really on the

00:07:44,259 --> 00:07:48,219
packet core right now because the packet

00:07:46,029 --> 00:07:49,960
core for the most part is just a

00:07:48,219 --> 00:07:55,779
standard server with ethernet and

00:07:49,960 --> 00:07:57,250
storage and so the radio part of it and

00:07:55,779 --> 00:07:59,080
we'll see wait you know and we'll see

00:07:57,250 --> 00:08:02,110
later on why why it's so hard to

00:07:59,080 --> 00:08:04,419
virtualize a note be so there is the

00:08:02,110 --> 00:08:05,979
radio part of it is kind of pushed off

00:08:04,419 --> 00:08:08,370
to the side right now you know

00:08:05,979 --> 00:08:11,800
definitely for initialed appointments

00:08:08,370 --> 00:08:13,089
but eventually it's going to get there i

00:08:11,800 --> 00:08:15,099
mean there's this whole talk of a

00:08:13,089 --> 00:08:16,870
centralized ran and you know talk a

00:08:15,099 --> 00:08:18,789
little bit about that but not too much

00:08:16,870 --> 00:08:21,250
you know i won't get into too much

00:08:18,789 --> 00:08:23,439
detail on that so now we know when you

00:08:21,250 --> 00:08:25,389
kind of take a look at the EU trance so

00:08:23,439 --> 00:08:29,289
the in oadby is kind of responsible for

00:08:25,389 --> 00:08:32,099
the you know radio frequencies for the

00:08:29,289 --> 00:08:35,229
for the radio technology and also for

00:08:32,099 --> 00:08:38,039
allocating bandwidth doing a lot of

00:08:35,229 --> 00:08:41,490
power management quality management of

00:08:38,039 --> 00:08:46,029
mobiles that are roaming and also

00:08:41,490 --> 00:08:49,000
standard eps procedures such as

00:08:46,029 --> 00:08:52,740
attachment attachment and handover and

00:08:49,000 --> 00:08:55,569
things like that and the packet core has

00:08:52,740 --> 00:08:57,190
network elements when you look at it in

00:08:55,569 --> 00:09:02,380
on the top you have that many which is

00:08:57,190 --> 00:09:04,899
the pretty much the brains of call

00:09:02,380 --> 00:09:07,839
processing and then you have the home

00:09:04,899 --> 00:09:11,290
serving server pcrf which is the key

00:09:07,839 --> 00:09:13,149
west part and then you have the data

00:09:11,290 --> 00:09:17,800
pipelines which is the serving gateway

00:09:13,149 --> 00:09:19,569
and pdn gateway and pj and gateways rate

00:09:17,800 --> 00:09:21,040
that thing that's in your phone and so

00:09:19,569 --> 00:09:22,510
if you look at your phone you'll notice

00:09:21,040 --> 00:09:23,470
that you have the sapient thing and

00:09:22,510 --> 00:09:26,620
that's the thing that you're really

00:09:23,470 --> 00:09:29,410
connecting to so the whole point here is

00:09:26,620 --> 00:09:32,589
that a mobile attaches once a mobile

00:09:29,410 --> 00:09:36,310
attaches a bearer setup the bearer

00:09:32,589 --> 00:09:38,260
simply a GTP Utah know that gtp utano is

00:09:36,310 --> 00:09:42,970
essentially used as a default gateway

00:09:38,260 --> 00:09:44,800
for a given ue and essentially those

00:09:42,970 --> 00:09:47,260
packets just go through this tunnel

00:09:44,800 --> 00:09:49,750
their tunnel to that and then they

00:09:47,260 --> 00:09:52,870
reappear at a pdn gateway and then the

00:09:49,750 --> 00:09:55,360
pdn gateway then goes out to either like

00:09:52,870 --> 00:09:57,100
kobe ims services you know like a sub

00:09:55,360 --> 00:10:00,069
server or it could just go out to

00:09:57,100 --> 00:10:02,829
internet another way to look at it is

00:10:00,069 --> 00:10:05,890
just it's just a really big big state

00:10:02,829 --> 00:10:09,130
machine so for example if I have a

00:10:05,890 --> 00:10:11,170
mobile and that mobile has just attached

00:10:09,130 --> 00:10:13,360
and then demo bio happens to go inactive

00:10:11,170 --> 00:10:17,380
and typically carry a set that to about

00:10:13,360 --> 00:10:19,149
10 seconds or so then I issue so that

00:10:17,380 --> 00:10:21,279
mobile will issue a release procedure

00:10:19,149 --> 00:10:24,670
you know that Reese procedure will go up

00:10:21,279 --> 00:10:27,190
to the enemy that many without serving

00:10:24,670 --> 00:10:28,510
gate waiter down the tunnel today not be

00:10:27,190 --> 00:10:30,399
because there's no point of following

00:10:28,510 --> 00:10:34,690
that mobile as its roaming through

00:10:30,399 --> 00:10:36,339
different tracking areas and then

00:10:34,690 --> 00:10:38,620
eventually you know something coming

00:10:36,339 --> 00:10:39,440
down for that mobile it hits the serving

00:10:38,620 --> 00:10:41,090
gateway

00:10:39,440 --> 00:10:44,150
or the mobile can instigate some data

00:10:41,090 --> 00:10:46,300
the serving Gateway tells Mme Mme then

00:10:44,150 --> 00:10:48,560
basically does a paging request and then

00:10:46,300 --> 00:10:51,080
what happens is that the ue does a

00:10:48,560 --> 00:10:52,760
service request and then it once it does

00:10:51,080 --> 00:10:54,650
that then the bearers are set up and

00:10:52,760 --> 00:10:59,720
then you have a pipeline that allows you

00:10:54,650 --> 00:11:01,100
to go out to the internet okay on the

00:10:59,720 --> 00:11:03,110
radio side it gets a little bit more

00:11:01,100 --> 00:11:07,040
complicated so for a 20 megahertz

00:11:03,110 --> 00:11:09,080
carrier for a 20 megahertz frequency and

00:11:07,040 --> 00:11:11,120
I'm not going to go through the actual

00:11:09,080 --> 00:11:14,510
protocols but just just the amount of

00:11:11,120 --> 00:11:17,390
processing that in oadby has to do so

00:11:14,510 --> 00:11:21,740
you have approximately 1200 sub carriers

00:11:17,390 --> 00:11:27,110
and so that's about 14 K symbols for

00:11:21,740 --> 00:11:28,640
each subcarrier and you divide the whole

00:11:27,110 --> 00:11:30,560
resource written to what we call

00:11:28,640 --> 00:11:34,340
resource blocks and this resource box is

00:11:30,560 --> 00:11:38,120
basically 12 sub carriers by seven what

00:11:34,340 --> 00:11:40,610
we called symbols and so now the

00:11:38,120 --> 00:11:43,370
capacity of a resource black can range

00:11:40,610 --> 00:11:45,790
can really range because of its control

00:11:43,370 --> 00:11:49,100
type of information the resource black

00:11:45,790 --> 00:11:51,980
you know the modulation can be maybe two

00:11:49,100 --> 00:11:53,810
bits per you know it could be two bits

00:11:51,980 --> 00:11:56,570
for each resource element or if it's

00:11:53,810 --> 00:11:59,030
quam 64 you know you could reach maximum

00:11:56,570 --> 00:12:02,270
bandwidth so of course these so there's

00:11:59,030 --> 00:12:05,120
approximately 200,000 resource blocks of

00:12:02,270 --> 00:12:09,410
you dealing with something like a 20

00:12:05,120 --> 00:12:12,320
megahertz 20 megahertz band with LTE

00:12:09,410 --> 00:12:14,630
system and of course these resource box

00:12:12,320 --> 00:12:16,070
are not just allocated for data I mean

00:12:14,630 --> 00:12:18,560
they're allocated for all sorts of

00:12:16,070 --> 00:12:21,140
different resources reasons you know

00:12:18,560 --> 00:12:23,960
such as option downlink control channels

00:12:21,140 --> 00:12:27,530
and they're allocated for system

00:12:23,960 --> 00:12:29,810
information base and you know for the ue

00:12:27,530 --> 00:12:31,790
to be able to acquire bandwidth and so

00:12:29,810 --> 00:12:34,339
forth but the bottom line is that when

00:12:31,790 --> 00:12:38,690
you look at the note B it has this real

00:12:34,339 --> 00:12:40,310
nasty scheduling algorithm and so this

00:12:38,690 --> 00:12:42,980
scheduling algorithm has to be actually

00:12:40,310 --> 00:12:44,900
smart it has to be able to for example

00:12:42,980 --> 00:12:47,839
figure out fairness versus throughput

00:12:44,900 --> 00:12:50,060
has to do a lot of power control fading

00:12:47,839 --> 00:12:51,740
spreading and things like that and

00:12:50,060 --> 00:12:53,520
there's a lot of

00:12:51,740 --> 00:12:55,140
you know you know there's a lot of

00:12:53,520 --> 00:12:57,020
engineering that goes into this things

00:12:55,140 --> 00:13:00,450
such as dimensioning and stuff like that

00:12:57,020 --> 00:13:02,460
so when you look at the base processing

00:13:00,450 --> 00:13:04,530
of e nobi I mean what does it really

00:13:02,460 --> 00:13:10,200
have to do first of all it has to tunnel

00:13:04,530 --> 00:13:11,790
a lot of data plane so a lot of resource

00:13:10,200 --> 00:13:13,920
blocks have to be allocated the data

00:13:11,790 --> 00:13:18,060
playing so you know when people say that

00:13:13,920 --> 00:13:20,130
it's hundred megabits per second panda

00:13:18,060 --> 00:13:22,170
well that's only if you had one ue and

00:13:20,130 --> 00:13:26,310
you have no control traffic whatsoever

00:13:22,170 --> 00:13:29,880
but in reality you know you may get two

00:13:26,310 --> 00:13:33,800
three you know megabits per second so

00:13:29,880 --> 00:13:37,590
the in OB has to do stuff like tunnel

00:13:33,800 --> 00:13:40,140
you know a lot of GTP you tunnel well

00:13:37,590 --> 00:13:42,660
actually at the yeah yeah so GTP you ton

00:13:40,140 --> 00:13:45,390
of data to the serving gateway and out

00:13:42,660 --> 00:13:48,090
to the pdn gateway in addition that has

00:13:45,390 --> 00:13:51,030
to do a lot of mobile control so you

00:13:48,090 --> 00:13:53,250
know that's a lot of POS feedback that

00:13:51,030 --> 00:13:54,750
it gets from various mobiles and then it

00:13:53,250 --> 00:13:57,900
also has to go through all sorts of

00:13:54,750 --> 00:14:00,780
procedures that were like procedures

00:13:57,900 --> 00:14:03,390
such as attached detach and and things

00:14:00,780 --> 00:14:05,340
of that nature so later on you know

00:14:03,390 --> 00:14:08,340
we'll kind of see what shapes the

00:14:05,340 --> 00:14:10,220
network you know why is it that we need

00:14:08,340 --> 00:14:13,500
this type of a ODP type of

00:14:10,220 --> 00:14:20,040
implementation to work with something

00:14:13,500 --> 00:14:21,240
like like not be so this is just a

00:14:20,040 --> 00:14:23,220
little bit closer look at the

00:14:21,240 --> 00:14:25,650
resource-rich so the only take away from

00:14:23,220 --> 00:14:28,290
this is that things happen very quickly

00:14:25,650 --> 00:14:29,670
on the ingleby so you have things that

00:14:28,290 --> 00:14:32,280
may happen every five hundred

00:14:29,670 --> 00:14:35,310
microseconds things that may happen

00:14:32,280 --> 00:14:37,980
every sub frame one millisecond or every

00:14:35,310 --> 00:14:39,930
10 milliseconds but the bottom line is

00:14:37,980 --> 00:14:41,640
that the ingleby has extremely busy

00:14:39,930 --> 00:14:44,880
scanning all these different resource

00:14:41,640 --> 00:14:50,910
blocks and reacting to them you know

00:14:44,880 --> 00:14:53,940
whatever the request may be so just an

00:14:50,910 --> 00:14:57,090
example of like what call processing

00:14:53,940 --> 00:15:00,420
looks like and this is just a simple you

00:14:57,090 --> 00:15:04,780
know one service request where mobile

00:15:00,420 --> 00:15:08,650
for example has to go from idle to actor

00:15:04,780 --> 00:15:10,390
and we're talking about 60 to 70

00:15:08,650 --> 00:15:13,270
milliseconds before that mobile goes

00:15:10,390 --> 00:15:15,520
from idle to active and so you have

00:15:13,270 --> 00:15:17,440
about 20 milliseconds for the ue to

00:15:15,520 --> 00:15:20,290
connector in oadby and the story called

00:15:17,440 --> 00:15:24,630
the RSC conducted state and at that

00:15:20,290 --> 00:15:28,150
point the ue is actually able to issue

00:15:24,630 --> 00:15:30,640
scheduling grants and is able to talk to

00:15:28,150 --> 00:15:32,830
the core and then we have additional

00:15:30,640 --> 00:15:35,380
maybe 40 50 milliseconds where we could

00:15:32,830 --> 00:15:36,970
actually be fully connected where the

00:15:35,380 --> 00:15:40,090
Bears are established and now we could

00:15:36,970 --> 00:15:43,020
talk and to end so you know you could

00:15:40,090 --> 00:15:45,790
just imagine you have a yeah for example

00:15:43,020 --> 00:15:49,120
you know fifty or sixty thousand of

00:15:45,790 --> 00:15:51,760
these type of service requests you know

00:15:49,120 --> 00:15:55,410
hitting the packet core you could just

00:15:51,760 --> 00:15:58,060
see the overall messaging the overall

00:15:55,410 --> 00:15:59,800
latencies involved and then the overall

00:15:58,060 --> 00:16:02,650
timers and just the number of timers

00:15:59,800 --> 00:16:08,230
that we have to support to be able to to

00:16:02,650 --> 00:16:11,590
make that happen so when you look at

00:16:08,230 --> 00:16:13,420
anti-v so I don't put the e not be and

00:16:11,590 --> 00:16:14,980
the virtualized column because they not

00:16:13,420 --> 00:16:16,570
be is a pretty challenging thing to

00:16:14,980 --> 00:16:19,300
really put it put into a virtualized

00:16:16,570 --> 00:16:21,730
column but when you look at an aveda

00:16:19,300 --> 00:16:25,060
composition you kind of come up with

00:16:21,730 --> 00:16:27,310
control plane and you come up with data

00:16:25,060 --> 00:16:31,540
plane and the control plane is typically

00:16:27,310 --> 00:16:33,790
a something like ODP or DP DK so you're

00:16:31,540 --> 00:16:35,920
dealing with a very tight through you

00:16:33,790 --> 00:16:38,380
pretty much want the scheduler out

00:16:35,920 --> 00:16:40,020
interrupts out the time result and this

00:16:38,380 --> 00:16:43,000
is a lot of stuff that Rick and yon

00:16:40,020 --> 00:16:45,640
essentially talked about yesterday so

00:16:43,000 --> 00:16:48,520
you want firm isolation and the node V

00:16:45,640 --> 00:16:50,260
part and then control processing you

00:16:48,520 --> 00:16:51,820
know that's just a whole different it

00:16:50,260 --> 00:16:53,260
not a not a whole different thing but

00:16:51,820 --> 00:16:55,240
it's quite different because there you

00:16:53,260 --> 00:16:57,160
could kind of deal with standard

00:16:55,240 --> 00:17:00,730
scheduling standard line of scheduling

00:16:57,160 --> 00:17:02,500
so things like our are 50 and things

00:17:00,730 --> 00:17:05,380
like that but still nevertheless there

00:17:02,500 --> 00:17:07,420
is a lot of tuning that has to go on you

00:17:05,380 --> 00:17:08,560
have to worry about all sorts of kernel

00:17:07,420 --> 00:17:13,150
threads that are there may be

00:17:08,560 --> 00:17:16,060
interfering with your Layton sees you

00:17:13,150 --> 00:17:18,450
know a lot of tuning as far as the

00:17:16,060 --> 00:17:21,670
colonel is concerned and so forth

00:17:18,450 --> 00:17:24,190
so you kind of delivery so you cannot

00:17:21,670 --> 00:17:27,430
divide it up like this and the in oadby

00:17:24,190 --> 00:17:32,590
part is kind of interesting because the

00:17:27,430 --> 00:17:34,480
in lv part has to has to do way more

00:17:32,590 --> 00:17:35,980
than for example the serving gateway

00:17:34,480 --> 00:17:38,140
because the serving gateway can

00:17:35,980 --> 00:17:42,090
practically become just the open flow

00:17:38,140 --> 00:17:45,670
switch configured from the control plane

00:17:42,090 --> 00:17:51,430
but the in obedience has to shuffle so

00:17:45,670 --> 00:17:53,500
much data to control processing and at

00:17:51,430 --> 00:17:56,830
the same time it also has to do so much

00:17:53,500 --> 00:18:01,840
radio management of the mobiles and it

00:17:56,830 --> 00:18:05,050
also has to shell for so much data so

00:18:01,840 --> 00:18:06,760
the individual is slightly different but

00:18:05,050 --> 00:18:08,740
this is kind of the decomposition so I

00:18:06,760 --> 00:18:12,420
don't put in the PD and gateway and all

00:18:08,740 --> 00:18:16,270
the other network elements you also have

00:18:12,420 --> 00:18:18,100
IMS and so most of the IMS signaling you

00:18:16,270 --> 00:18:20,500
know if you go back to this slide over

00:18:18,100 --> 00:18:22,570
here you know if you have a sip server

00:18:20,500 --> 00:18:25,600
someplace within the ims most of that

00:18:22,570 --> 00:18:28,810
signaling actually just goes over normal

00:18:25,600 --> 00:18:31,330
data as far as LTE is concerned it has

00:18:28,810 --> 00:18:33,010
no clue that it's actually you know you

00:18:31,330 --> 00:18:38,800
know that you have a sip session going

00:18:33,010 --> 00:18:41,110
through that to those channels so what

00:18:38,800 --> 00:18:43,150
sort of you know so I guess I take away

00:18:41,110 --> 00:18:44,950
you know one of the takeaways or

00:18:43,150 --> 00:18:46,390
actually quite a few takeaways is that

00:18:44,950 --> 00:18:48,430
if we're running in a virtualized

00:18:46,390 --> 00:18:51,040
environment you know we need

00:18:48,430 --> 00:18:53,800
deterministic execution so you know that

00:18:51,040 --> 00:18:57,190
was underline yesterday and the initial

00:18:53,800 --> 00:19:00,220
presentation we need to have a lot of

00:18:57,190 --> 00:19:03,430
coexistence between between different

00:19:00,220 --> 00:19:08,560
type of execution loads and so we're

00:19:03,430 --> 00:19:11,470
talking about things like data plane you

00:19:08,560 --> 00:19:14,350
know control plane you know which is and

00:19:11,470 --> 00:19:17,290
so we have ODP real-time time sharing

00:19:14,350 --> 00:19:19,360
and so forth and it's still really not

00:19:17,290 --> 00:19:21,270
quite clear that all these things can

00:19:19,360 --> 00:19:24,190
really quite exist within the same vm

00:19:21,270 --> 00:19:28,630
it's very likely that we may have to

00:19:24,190 --> 00:19:31,120
decompose these and have some very very

00:19:28,630 --> 00:19:33,580
high rate IPC between different

00:19:31,120 --> 00:19:36,340
EMS and I think the previous talk kind

00:19:33,580 --> 00:19:37,450
of had a good deal internet except I

00:19:36,340 --> 00:19:41,410
kind of didn't like to interrupt

00:19:37,450 --> 00:19:44,620
injection part of it then we have timers

00:19:41,410 --> 00:19:48,370
so you know anyone that's work with you

00:19:44,620 --> 00:19:50,080
know if with not working you know it

00:19:48,370 --> 00:19:51,550
just knows that there's just that you

00:19:50,080 --> 00:19:53,320
know there's just thousands and

00:19:51,550 --> 00:19:55,840
thousands of timers you know that are

00:19:53,320 --> 00:19:57,760
involved so typically the way things

00:19:55,840 --> 00:20:00,730
work in control plane is that you get a

00:19:57,760 --> 00:20:02,980
request you queue it up you associate a

00:20:00,730 --> 00:20:04,990
timer with it you send that off

00:20:02,980 --> 00:20:08,110
something doesn't happen the timer fires

00:20:04,990 --> 00:20:11,470
then you retry again and so a simple

00:20:08,110 --> 00:20:15,910
example is like for example a he not be

00:20:11,470 --> 00:20:18,640
going up to Mme and you know saying okay

00:20:15,910 --> 00:20:20,470
give me your pd pd CB contacts right it

00:20:18,640 --> 00:20:23,610
doesn't get the PDC p contacts so the

00:20:20,470 --> 00:20:25,929
timer fires and it tries it again so

00:20:23,610 --> 00:20:27,760
timers you know we have to deal with

00:20:25,929 --> 00:20:30,120
that now the question is how do you get

00:20:27,760 --> 00:20:33,640
a lot of timer interrupts into a guest

00:20:30,120 --> 00:20:36,250
so far you know not a not a whole lot of

00:20:33,640 --> 00:20:39,130
luck I mean you know we can't get a lot

00:20:36,250 --> 00:20:42,220
of timers into the guest but with a lot

00:20:39,130 --> 00:20:43,330
of overhead another one that I think a

00:20:42,220 --> 00:20:45,820
lot of people don't pay too much

00:20:43,330 --> 00:20:49,809
attention to but carriers do is CPU

00:20:45,820 --> 00:20:52,210
accounting and with cpu Akane ink as

00:20:49,809 --> 00:20:53,830
soon as you introduce vm exits you know

00:20:52,210 --> 00:20:58,120
the carrier's really don't care that

00:20:53,830 --> 00:20:58,990
you're running a vm and that vm is not

00:20:58,120 --> 00:21:02,380
supposed to know that it's not

00:20:58,990 --> 00:21:06,340
virtualized i mean they will want to

00:21:02,380 --> 00:21:07,720
know exactly you know why why why is it

00:21:06,340 --> 00:21:09,700
that they're not getting enough time to

00:21:07,720 --> 00:21:11,309
run so the because you know they are

00:21:09,700 --> 00:21:14,440
very complex what we call loadshedding

00:21:11,309 --> 00:21:17,640
algorithms so when you go over a certain

00:21:14,440 --> 00:21:20,590
threshold they will start denying

00:21:17,640 --> 00:21:23,260
requests and so now for example if

00:21:20,590 --> 00:21:24,370
you're vcpu is exiting well you know

00:21:23,260 --> 00:21:26,950
they might just try to spin up

00:21:24,370 --> 00:21:31,750
additional v CPUs you know to compensate

00:21:26,950 --> 00:21:33,100
for that but what's very important well

00:21:31,750 --> 00:21:34,690
actually know what's something that I go

00:21:33,100 --> 00:21:36,580
into later on so there's no point you

00:21:34,690 --> 00:21:40,120
know kind of be laboring this topic and

00:21:36,580 --> 00:21:42,809
then we still have a few few other gaps

00:21:40,120 --> 00:21:44,850
you know that that will be high

00:21:42,809 --> 00:21:47,309
the leader but the bottom line the

00:21:44,850 --> 00:21:49,980
challenges are latency performance at a

00:21:47,309 --> 00:21:52,320
certain capacity you know with

00:21:49,980 --> 00:21:57,590
reasonable over has so we don't expect

00:21:52,320 --> 00:22:00,539
that you know we could run you know epc

00:21:57,590 --> 00:22:02,039
network element you know with like let's

00:22:00,539 --> 00:22:03,840
say five percent overhead I think

00:22:02,039 --> 00:22:07,169
fifteen to twenty percent overhead is

00:22:03,840 --> 00:22:09,360
something that's more in line but then

00:22:07,169 --> 00:22:12,659
again just the kind of flexibility that

00:22:09,360 --> 00:22:18,960
you gain is really worth it to go to an

00:22:12,659 --> 00:22:21,509
affy so we so as always you know Alan

00:22:18,960 --> 00:22:23,100
bench is always the preferable benchmark

00:22:21,509 --> 00:22:26,249
when you're dealing with wireless

00:22:23,100 --> 00:22:28,529
because other veg allows us to measure

00:22:26,249 --> 00:22:34,409
the basic cost of operations and be

00:22:28,529 --> 00:22:36,240
given that wireless loads are typically

00:22:34,409 --> 00:22:39,899
so unpredictable you know you can just

00:22:36,240 --> 00:22:42,289
take any benchmark off the shelf and

00:22:39,899 --> 00:22:45,419
just run it so Alan benches are

00:22:42,289 --> 00:22:48,269
preferable way of doing things and of

00:22:45,419 --> 00:22:49,919
course artistas cyclic test and you know

00:22:48,269 --> 00:22:53,190
cyclic does to a certain extent is

00:22:49,919 --> 00:22:54,629
pretty okay and i think the previous

00:22:53,190 --> 00:22:57,629
presentation had a little bit better

00:22:54,629 --> 00:23:01,259
approach as far as being able to measure

00:22:57,629 --> 00:23:03,749
latency and i think in my opinion we

00:23:01,259 --> 00:23:05,940
need to develop some kind of latency

00:23:03,749 --> 00:23:07,950
test where we could test agency from the

00:23:05,940 --> 00:23:10,519
time something happens in the host at a

00:23:07,950 --> 00:23:13,230
time that something happens in a guest

00:23:10,519 --> 00:23:15,450
but but anyways I mean so what we have

00:23:13,230 --> 00:23:17,340
we work with and we try to make the most

00:23:15,450 --> 00:23:20,149
of it and so some of the energy

00:23:17,340 --> 00:23:23,070
attributes we test for is like

00:23:20,149 --> 00:23:25,350
commercial off-the-shelf hardware well

00:23:23,070 --> 00:23:28,289
you know how suitable is it for the

00:23:25,350 --> 00:23:30,269
enough support via enough decomposition

00:23:28,289 --> 00:23:31,409
so we're pretty sure that there's no way

00:23:30,269 --> 00:23:34,169
that will be able to run everything

00:23:31,409 --> 00:23:36,690
within one vnf and then improve

00:23:34,169 --> 00:23:38,960
operational efficiency scalability so we

00:23:36,690 --> 00:23:42,119
have issues with you know so primarily

00:23:38,960 --> 00:23:45,389
scaling gods so live migration plays a

00:23:42,119 --> 00:23:46,570
big role there scalability so I'm we're

00:23:45,389 --> 00:23:48,659
talking scalability

00:23:46,570 --> 00:23:53,230
were you know also talking a lot of

00:23:48,659 --> 00:23:55,000
memory hot blog and overcommit so there

00:23:53,230 --> 00:23:58,210
are certain add services that can be

00:23:55,000 --> 00:24:00,639
over committed so the core network

00:23:58,210 --> 00:24:04,539
elements are not those but some other

00:24:00,639 --> 00:24:06,130
ones can be over committed so this is

00:24:04,539 --> 00:24:08,110
just I don't know this site is kind of

00:24:06,130 --> 00:24:10,809
out of place but this disguise shows you

00:24:08,110 --> 00:24:13,029
how you do network element developments

00:24:10,809 --> 00:24:16,600
they just kind of you know have a call

00:24:13,029 --> 00:24:18,370
processing and you run some traffic and

00:24:16,600 --> 00:24:20,289
you kind of get a good fuzzy feeling

00:24:18,370 --> 00:24:22,600
that everything is kind of working fine

00:24:20,289 --> 00:24:25,149
and then the real requirements come in

00:24:22,600 --> 00:24:27,519
and when the real requirements come in

00:24:25,149 --> 00:24:29,200
it's not just a call processing portion

00:24:27,519 --> 00:24:31,860
of it but there's just all sorts of

00:24:29,200 --> 00:24:35,950
other things like auditing lawful

00:24:31,860 --> 00:24:37,929
entering and you know you know things

00:24:35,950 --> 00:24:39,970
like local maintenance terminal and

00:24:37,929 --> 00:24:42,009
tracing and stuff like that and so that

00:24:39,970 --> 00:24:46,779
just that just goes to prove that you

00:24:42,009 --> 00:24:49,149
just have such a mixed set of you know

00:24:46,779 --> 00:24:54,490
processes and threads that are executing

00:24:49,149 --> 00:24:58,350
that really make wireless that network

00:24:54,490 --> 00:24:58,350
infrastructure so unique painting us

00:24:58,710 --> 00:25:04,299
okay it's on an to the real problem so

00:25:01,570 --> 00:25:05,740
on top is where we have today and for

00:25:04,299 --> 00:25:08,200
the most part we've been able to run

00:25:05,740 --> 00:25:11,620
with preempt you know we haven't had to

00:25:08,200 --> 00:25:13,840
resort to pre and RT you know although

00:25:11,620 --> 00:25:16,419
when you look at the colonel corner I

00:25:13,840 --> 00:25:18,639
mean did it so the kernel corn kernel

00:25:16,419 --> 00:25:22,149
has a lot of pre mrt in it you know such

00:25:18,639 --> 00:25:24,220
as you know interrupts running as

00:25:22,149 --> 00:25:26,529
threads and high resolution timers but

00:25:24,220 --> 00:25:29,379
you know we're still not using mutexes

00:25:26,529 --> 00:25:31,179
and things like you know priority

00:25:29,379 --> 00:25:34,029
inheritance and you know things of that

00:25:31,179 --> 00:25:36,190
nature but things are good you know in

00:25:34,029 --> 00:25:38,799
this sense things are working and you

00:25:36,190 --> 00:25:42,820
know the deadlines are met both in the

00:25:38,799 --> 00:25:44,830
EPC and then the and the BTS but now

00:25:42,820 --> 00:25:49,090
we're kind of winding up with the stuff

00:25:44,830 --> 00:25:50,679
on the bottom and so it's kind of

00:25:49,090 --> 00:25:53,080
interesting because in I listened to the

00:25:50,679 --> 00:25:55,779
presentations yesterday and we seem to

00:25:53,080 --> 00:25:57,879
be coming to the same conclusions as far

00:25:55,779 --> 00:25:59,140
as you know how to harden some of those

00:25:57,879 --> 00:26:01,910
execution

00:25:59,140 --> 00:26:04,010
and so some benchmarks you know that

00:26:01,910 --> 00:26:06,650
Iran and this is a totally idle system

00:26:04,010 --> 00:26:10,580
you know we basically is nothing running

00:26:06,650 --> 00:26:13,880
on this and you know so what we did is

00:26:10,580 --> 00:26:15,740
we basically move the eye of threads off

00:26:13,880 --> 00:26:17,960
of the vcp threat so there is no

00:26:15,740 --> 00:26:20,030
interaction between them this is not a

00:26:17,960 --> 00:26:23,630
NUMA system you know totally off the

00:26:20,030 --> 00:26:25,640
shelf 12 CPUs and I use the real-time

00:26:23,630 --> 00:26:29,350
options so we wouldn't be using too much

00:26:25,640 --> 00:26:32,690
Beijing and so you run around a host and

00:26:29,350 --> 00:26:34,250
cyclic does looks perfect you know you

00:26:32,690 --> 00:26:36,230
have one point you know one to two

00:26:34,250 --> 00:26:39,170
percent CPU overhead which is really

00:26:36,230 --> 00:26:41,559
great but then as soon as you move to

00:26:39,170 --> 00:26:43,820
the guest you get some pretty pretty

00:26:41,559 --> 00:26:45,890
well first of all you get bad numbers

00:26:43,820 --> 00:26:47,540
but the bigger one is the overhead that

00:26:45,890 --> 00:26:50,690
you get and that's that's the real

00:26:47,540 --> 00:26:53,059
killer because with with BNF

00:26:50,690 --> 00:26:56,690
decomposition it is possible to kind of

00:26:53,059 --> 00:27:00,920
be able to decompose the vnf and kind of

00:26:56,690 --> 00:27:03,620
lower these numbers but or I should say

00:27:00,920 --> 00:27:06,080
and prove these macs numbers but with

00:27:03,620 --> 00:27:09,410
this type of an overhead there's really

00:27:06,080 --> 00:27:11,990
not much that you can do and as you move

00:27:09,410 --> 00:27:16,670
towards 50 and RR for the DCP threats

00:27:11,990 --> 00:27:18,200
you get better max times and so that's a

00:27:16,670 --> 00:27:20,179
good sign because that means that we

00:27:18,200 --> 00:27:22,070
could probably move to pre and RT for

00:27:20,179 --> 00:27:26,270
hosts and that or even give us better

00:27:22,070 --> 00:27:28,850
numbers and you know one I guess point

00:27:26,270 --> 00:27:31,160
is that when we're talking about max you

00:27:28,850 --> 00:27:33,500
know it's not necessarily too bad if

00:27:31,160 --> 00:27:36,740
your max is out there it's just the

00:27:33,500 --> 00:27:38,270
question of it's an outlier or if it's

00:27:36,740 --> 00:27:40,970
something that's like within two or

00:27:38,270 --> 00:27:42,800
three or four or five percent of time of

00:27:40,970 --> 00:27:44,990
occurrences when you get scheduled and

00:27:42,800 --> 00:27:46,550
so that's probably something that we

00:27:44,990 --> 00:27:48,950
should add to cyclic to us where we

00:27:46,550 --> 00:27:51,260
could kind of see okay well less than

00:27:48,950 --> 00:27:53,750
half a percent got this next time but

00:27:51,260 --> 00:27:55,490
then most of it we never actually hit

00:27:53,750 --> 00:28:00,679
that next time because this could be

00:27:55,490 --> 00:28:03,530
kind of misleading so you know the

00:28:00,679 --> 00:28:05,600
conclusion here is the way things are

00:28:03,530 --> 00:28:08,570
right now with basically kills cats

00:28:05,600 --> 00:28:10,910
because you know we would have to you

00:28:08,570 --> 00:28:11,760
know get some big server that is like 64

00:28:10,910 --> 00:28:14,160
way

00:28:11,760 --> 00:28:15,630
and you know that's not something you

00:28:14,160 --> 00:28:20,040
know that's not a direction we want to

00:28:15,630 --> 00:28:24,870
move into studying vcp use to our five

00:28:20,040 --> 00:28:27,680
for the sub limit the max future

00:28:24,870 --> 00:28:30,900
direction is host running and p.m. RT

00:28:27,680 --> 00:28:33,000
you know so either isolate CPUs on our

00:28:30,900 --> 00:28:38,040
hurts pool so this would be primary for

00:28:33,000 --> 00:28:40,710
data data plane applications and offload

00:28:38,040 --> 00:28:43,260
the RCU processing so you know just

00:28:40,710 --> 00:28:46,440
standard practicing that was talked

00:28:43,260 --> 00:28:48,630
about yesterday as far as moving pre mrt

00:28:46,440 --> 00:28:50,850
interrogates probably unlikely because

00:28:48,630 --> 00:28:53,490
the problem is that p.m. RT does have

00:28:50,850 --> 00:28:55,440
its own costs you know when you're

00:28:53,490 --> 00:28:59,370
dealing with new taxes and priority

00:28:55,440 --> 00:29:01,290
inheritance and transitive you know

00:28:59,370 --> 00:29:02,910
priority inheritance and those type of

00:29:01,290 --> 00:29:04,830
things you know does have its own costs

00:29:02,910 --> 00:29:07,620
but you never know you know you know we

00:29:04,830 --> 00:29:11,370
might wind up there and for control

00:29:07,620 --> 00:29:13,860
plane you know just standard you know

00:29:11,370 --> 00:29:17,430
standard lined eggs with your files and

00:29:13,860 --> 00:29:19,530
our hours and things of that nature the

00:29:17,430 --> 00:29:22,620
issue again is driving in our timer

00:29:19,530 --> 00:29:25,740
interrupt so we could actually process

00:29:22,620 --> 00:29:28,170
events on time and again you know where

00:29:25,740 --> 00:29:30,270
dhanteras control plane data playing

00:29:28,170 --> 00:29:33,510
decomposition you know that's kind of a

00:29:30,270 --> 00:29:37,710
something we do not want to do but if we

00:29:33,510 --> 00:29:41,700
need to then something we will do timers

00:29:37,710 --> 00:29:44,040
so Alan branch you know you run you know

00:29:41,700 --> 00:29:46,590
the timer Lynch benchmark and what

00:29:44,040 --> 00:29:49,170
happens here there's actually two hits

00:29:46,590 --> 00:29:52,020
you take so the benchmark first of all

00:29:49,170 --> 00:29:55,200
it has very high overhead if you're

00:29:52,020 --> 00:29:57,180
running it in a guest and secondly again

00:29:55,200 --> 00:29:58,860
your CPU is twenty percent higher well

00:29:57,180 --> 00:30:00,930
that's no wonder because it's kind of

00:29:58,860 --> 00:30:04,080
similar to what cyclic does test is

00:30:00,930 --> 00:30:07,380
doing but I think for that one we have a

00:30:04,080 --> 00:30:10,140
pretty good work around and actually is

00:30:07,380 --> 00:30:11,550
the solution that I've seen with most of

00:30:10,140 --> 00:30:13,770
the network elements that I work with

00:30:11,550 --> 00:30:18,930
there's typically a dedicated timer task

00:30:13,770 --> 00:30:20,850
and so you essentially call s timers so

00:30:18,930 --> 00:30:22,580
if somebody asks you ok I want to do a

00:30:20,850 --> 00:30:25,130
timer five hundred microseconds

00:30:22,580 --> 00:30:28,250
well you call us the timer to like two

00:30:25,130 --> 00:30:30,710
milliseconds and actually if you look at

00:30:28,250 --> 00:30:32,090
driver timers I mean climber drivers I

00:30:30,710 --> 00:30:33,289
mean they tend to do the same thing they

00:30:32,090 --> 00:30:35,899
taint you know you know they tend to

00:30:33,289 --> 00:30:40,720
call us as well and so when we do that

00:30:35,899 --> 00:30:43,130
the CPU prima drops the negligible and

00:30:40,720 --> 00:30:46,159
the butt but then of course the big

00:30:43,130 --> 00:30:48,169
question is when we load up a full

00:30:46,159 --> 00:30:50,570
system and we have a let's say we have

00:30:48,169 --> 00:30:54,200
Mme pool that is covering like six

00:30:50,570 --> 00:30:56,510
million subscribers and we get 20,000

00:30:54,200 --> 00:31:00,019
service requests you know that's 250

00:30:56,510 --> 00:31:04,370
micro 250 microseconds per each service

00:31:00,019 --> 00:31:06,440
request you know can we actually scale

00:31:04,370 --> 00:31:11,000
this way you know that would be the big

00:31:06,440 --> 00:31:14,630
question so this is the TBD but this I

00:31:11,000 --> 00:31:19,850
think appears to be realistic to be able

00:31:14,630 --> 00:31:22,130
to to do this within a guest and then

00:31:19,850 --> 00:31:26,240
comes the real troubled one and this is

00:31:22,130 --> 00:31:28,730
the real scary one because Iran latency

00:31:26,240 --> 00:31:31,100
memory read and what happens is that

00:31:28,730 --> 00:31:33,860
your CPU goes to one hundred percent and

00:31:31,100 --> 00:31:37,429
this benchmark tends to just kind of hop

00:31:33,860 --> 00:31:42,230
around and randomly read different

00:31:37,429 --> 00:31:44,990
strides of memory and so its first of

00:31:42,230 --> 00:31:47,059
all trying to go outside of the TLB and

00:31:44,990 --> 00:31:51,529
also trying to go outside of the cash

00:31:47,059 --> 00:31:55,159
and so this is this is not good you know

00:31:51,529 --> 00:31:56,779
this is this is really of all the of all

00:31:55,159 --> 00:31:58,370
the drawbacks you know of all the issues

00:31:56,779 --> 00:32:01,279
that I pointed out here this is probably

00:31:58,370 --> 00:32:03,500
the biggest one when you run bandwidth

00:32:01,279 --> 00:32:05,600
memory everything looks great I mean you

00:32:03,500 --> 00:32:09,200
know this is like very realistic no

00:32:05,600 --> 00:32:11,600
problems here latency I'm map latency

00:32:09,200 --> 00:32:13,340
context so a map is off but we could

00:32:11,600 --> 00:32:15,320
live with my maps I mean you know how

00:32:13,340 --> 00:32:16,880
often do you do forks and xx and things

00:32:15,320 --> 00:32:19,669
like that you know that there we can

00:32:16,880 --> 00:32:22,070
handle but you know we cannot handle the

00:32:19,669 --> 00:32:26,299
context which is if you introduce eight

00:32:22,070 --> 00:32:27,919
megabytes of noise you're dealing with

00:32:26,299 --> 00:32:30,919
about eighty one percent overhead

00:32:27,919 --> 00:32:34,460
eighty-one percent CPU extra cpu usage

00:32:30,919 --> 00:32:35,220
and I mean so this benchmark all it's

00:32:34,460 --> 00:32:36,299
doing is just got

00:32:35,220 --> 00:32:38,190
that switching so we're not talking

00:32:36,299 --> 00:32:40,559
context switching of the overall

00:32:38,190 --> 00:32:46,470
application but that's what the

00:32:40,559 --> 00:32:48,840
benchmark is testing so you know we I

00:32:46,470 --> 00:32:51,120
looked at this very closely and I went

00:32:48,840 --> 00:32:53,850
through you know profiling and so forth

00:32:51,120 --> 00:32:57,600
and the only thing I could point to is

00:32:53,850 --> 00:33:00,059
the nested walk so you know we're doing

00:32:57,600 --> 00:33:02,490
24 memory lookups instead of four memory

00:33:00,059 --> 00:33:04,860
lookups you know that's about the only

00:33:02,490 --> 00:33:06,690
thing that I could point to and to

00:33:04,860 --> 00:33:10,320
mitigate the thing is is basically

00:33:06,690 --> 00:33:13,559
spread your kind of spread your memory

00:33:10,320 --> 00:33:17,640
across four different CPUs and now

00:33:13,559 --> 00:33:19,679
everybody kind of has their own you know

00:33:17,640 --> 00:33:22,010
has their own cash and has a hazard on

00:33:19,679 --> 00:33:24,960
and intermediate page table what cash

00:33:22,010 --> 00:33:28,140
but the conclusion here is really the

00:33:24,960 --> 00:33:32,000
nested page table walk and the question

00:33:28,140 --> 00:33:35,549
is you know when you look at the actual

00:33:32,000 --> 00:33:37,020
processors out there the question is you

00:33:35,549 --> 00:33:39,539
know where is this intermediate page

00:33:37,020 --> 00:33:42,510
table all cash and how can you tune it I

00:33:39,539 --> 00:33:44,340
mean how can you even access it and you

00:33:42,510 --> 00:33:47,880
know when you get it like you know we

00:33:44,340 --> 00:33:49,350
work with some vendors you ask him they

00:33:47,880 --> 00:33:52,080
don't know is that you know they don't

00:33:49,350 --> 00:33:56,190
they don't know you know what it's sizes

00:33:52,080 --> 00:33:58,200
and you know from our point of view I

00:33:56,190 --> 00:33:59,940
mean arm has some very funny flushing

00:33:58,200 --> 00:34:01,980
where it's able to flash the leaf on

00:33:59,940 --> 00:34:05,730
trees you know currently that's not in

00:34:01,980 --> 00:34:10,589
the colonel but at least it leaves the

00:34:05,730 --> 00:34:16,349
gf1 to pfn mappings intact for page

00:34:10,589 --> 00:34:18,540
table wats so this one really needs a

00:34:16,349 --> 00:34:20,609
lot of more work but I think the big

00:34:18,540 --> 00:34:24,240
thing here is to talk to the hardware

00:34:20,609 --> 00:34:26,129
vendors and I think that's where a lot

00:34:24,240 --> 00:34:30,720
of differentiation comes into play if

00:34:26,129 --> 00:34:36,060
you're talking to hardware vendors let's

00:34:30,720 --> 00:34:39,149
see okay so that one is done cpu organic

00:34:36,060 --> 00:34:40,889
so sleepy iconic you know so first of

00:34:39,149 --> 00:34:42,869
all it has to be psycho basic earnings

00:34:40,889 --> 00:34:44,460
so if you go into wireless environment

00:34:42,869 --> 00:34:45,899
and you're dealing with click based

00:34:44,460 --> 00:34:47,929
accounting that's completely out of the

00:34:45,899 --> 00:34:47,929
question

00:34:48,339 --> 00:34:55,250
secondly preferably per CPU and in this

00:34:52,429 --> 00:34:58,130
case we will be dealing pervy CPU now

00:34:55,250 --> 00:35:00,220
carriers like to like to manage

00:34:58,130 --> 00:35:04,040
themselves and there's anything wrong

00:35:00,220 --> 00:35:07,190
they want to be able to root cause and

00:35:04,040 --> 00:35:09,050
analyze the problem immediately so you

00:35:07,190 --> 00:35:11,000
know before we had like all sorts of

00:35:09,050 --> 00:35:12,800
different modes execution modes and they

00:35:11,000 --> 00:35:15,800
wanted to know okay well why this mode

00:35:12,800 --> 00:35:18,740
is longer or shorter well now we have

00:35:15,800 --> 00:35:20,420
exits so all of a sudden you know we do

00:35:18,740 --> 00:35:22,720
an exit then we're stuck in some mode

00:35:20,420 --> 00:35:25,819
for like who knows how many milliseconds

00:35:22,720 --> 00:35:28,010
well the carrier really doesn't care

00:35:25,819 --> 00:35:29,690
that you're running within the vm as far

00:35:28,010 --> 00:35:32,000
as far as the carrier is concerned this

00:35:29,690 --> 00:35:35,270
is a real network element and the

00:35:32,000 --> 00:35:37,369
carrier you know so we tend to be very

00:35:35,270 --> 00:35:40,130
religious about the fact that you don't

00:35:37,369 --> 00:35:42,619
want to expose that your vm but to the

00:35:40,130 --> 00:35:47,270
carrier the carrie has to know that ok

00:35:42,619 --> 00:35:49,550
I'm exiting and the reason that I'm not

00:35:47,270 --> 00:35:52,310
getting enough cpu Tehran is because I'm

00:35:49,550 --> 00:35:56,060
like sitting and so then the carrier is

00:35:52,310 --> 00:36:01,730
you know can apply certain load shedding

00:35:56,060 --> 00:36:04,490
type of algorithms and more importantly

00:36:01,730 --> 00:36:07,250
you know as far as the move like the

00:36:04,490 --> 00:36:08,900
SNMP SNMP made by me most of the stuff

00:36:07,250 --> 00:36:11,089
with them the infrastructure is done

00:36:08,900 --> 00:36:14,470
through us and that be traps you know

00:36:11,089 --> 00:36:18,290
that can be augmented with exit exit

00:36:14,470 --> 00:36:20,119
statistics as well and the reason I

00:36:18,290 --> 00:36:23,300
mentioned that is because you know i

00:36:20,119 --> 00:36:25,280
worked at bell labs where we did you

00:36:23,300 --> 00:36:27,619
know life Curren apache and worked it

00:36:25,280 --> 00:36:30,470
with push-to-talk technology at motorola

00:36:27,619 --> 00:36:33,200
and that's always been the biggest issue

00:36:30,470 --> 00:36:35,690
and the problem is that when you go out

00:36:33,200 --> 00:36:38,000
into the field you can use p.m. you typo

00:36:35,690 --> 00:36:39,920
tools you can use DDD's you can use any

00:36:38,000 --> 00:36:42,950
other stuff the only thing that I could

00:36:39,920 --> 00:36:44,150
really use is pretty much data of

00:36:42,950 --> 00:36:47,329
accounting and that's about the only

00:36:44,150 --> 00:36:49,400
only stuff that I mean I mean if you're

00:36:47,329 --> 00:36:51,319
lucky just to get some tech to go out

00:36:49,400 --> 00:36:53,900
there and just do some PS come as for

00:36:51,319 --> 00:36:55,480
you or runs on command that's about as

00:36:53,900 --> 00:36:58,640
much as you get out of it or you go

00:36:55,480 --> 00:36:59,970
climb sears tower like in my case is in

00:36:58,640 --> 00:37:02,369
my case I've been in summer

00:36:59,970 --> 00:37:04,740
real situation where I had to go and

00:37:02,369 --> 00:37:08,400
retrieve logs from some odd places and

00:37:04,740 --> 00:37:10,080
things like that so you know this I

00:37:08,400 --> 00:37:13,410
think is not a critical path to

00:37:10,080 --> 00:37:14,760
releasing to make nfe happen but it's

00:37:13,410 --> 00:37:17,910
something that would definitely come up

00:37:14,760 --> 00:37:22,140
I mean that is my mind I appreciate that

00:37:17,910 --> 00:37:25,020
would happen next one is the composition

00:37:22,140 --> 00:37:27,630
the end of decomposition so a lot of

00:37:25,020 --> 00:37:31,619
folks you know there's thing there's

00:37:27,630 --> 00:37:34,880
there's this whole thing called vnf what

00:37:31,619 --> 00:37:36,660
we call function guy think and

00:37:34,880 --> 00:37:39,060
essentially you know if you want to

00:37:36,660 --> 00:37:40,980
scale you know there's two ways to scare

00:37:39,060 --> 00:37:43,380
you could scale vertically and you could

00:37:40,980 --> 00:37:45,210
scale horizontally and essentially

00:37:43,380 --> 00:37:48,750
horizontal scaling is a much more

00:37:45,210 --> 00:37:50,310
difficult thing to do just simply

00:37:48,750 --> 00:37:52,020
because you have to take network

00:37:50,310 --> 00:37:53,849
elements and you have to make sure that

00:37:52,020 --> 00:37:57,930
they are able to sustain that kind of

00:37:53,849 --> 00:38:00,300
capacity so vertical vertical scaling

00:37:57,930 --> 00:38:02,010
where you throw a lot of via nerves onto

00:38:00,300 --> 00:38:04,460
single box is pretty much the way that

00:38:02,010 --> 00:38:10,349
things are going so here what we see is

00:38:04,460 --> 00:38:17,339
big requirements for very robust enter

00:38:10,349 --> 00:38:19,290
guest communication you know share

00:38:17,339 --> 00:38:21,420
memory which is really discoverable odd

00:38:19,290 --> 00:38:26,190
demands so in not something like just

00:38:21,420 --> 00:38:27,930
plugging in an IV sure man but for a V

00:38:26,190 --> 00:38:30,119
enough to be able just to probe and

00:38:27,930 --> 00:38:33,300
discover a share memory segment map it

00:38:30,119 --> 00:38:36,450
map to it directly and of course we also

00:38:33,300 --> 00:38:38,460
need very fast signaling so something

00:38:36,450 --> 00:38:40,650
like IV Sherman type of signaling where

00:38:38,460 --> 00:38:42,720
you have event at the you know title and

00:38:40,650 --> 00:38:45,780
I or qfd and things like that you know

00:38:42,720 --> 00:38:48,540
that's kind of most likely won't cut it

00:38:45,780 --> 00:38:50,730
because you know typically natively you

00:38:48,540 --> 00:38:52,440
know you're using you know like you know

00:38:50,730 --> 00:38:55,740
POSIX type of calls and things like that

00:38:52,440 --> 00:38:57,349
so you know one way is to maybe leverage

00:38:55,740 --> 00:38:59,369
off of some of the power management

00:38:57,349 --> 00:39:00,930
instructions it's just that some of

00:38:59,369 --> 00:39:03,839
these instructions are not too

00:39:00,930 --> 00:39:05,550
intelligent if you an arm for example if

00:39:03,839 --> 00:39:07,380
you do a SAT event that just kind of

00:39:05,550 --> 00:39:09,150
tends to wake up everybody but if you

00:39:07,380 --> 00:39:12,590
had extensions where you could like

00:39:09,150 --> 00:39:14,840
associate each one of these with a guest

00:39:12,590 --> 00:39:18,440
and then the guests can be in asleep and

00:39:14,840 --> 00:39:21,260
then you could just issue a set the van

00:39:18,440 --> 00:39:23,240
with the immediate well you know that I

00:39:21,260 --> 00:39:31,430
think is something that is more likely

00:39:23,240 --> 00:39:33,500
to scale a vm management operations so a

00:39:31,430 --> 00:39:35,480
lot of work has been done on Darren are

00:39:33,500 --> 00:39:37,640
so what we've done is we what we do

00:39:35,480 --> 00:39:40,280
basically where we migrate we

00:39:37,640 --> 00:39:43,190
essentially break up each pages into

00:39:40,280 --> 00:39:46,640
small pages and so that allows us to

00:39:43,190 --> 00:39:48,740
migrate very quickly you know from one

00:39:46,640 --> 00:39:50,600
machine to another and then as soon as

00:39:48,740 --> 00:39:52,820
we get the right today for the

00:39:50,600 --> 00:39:54,980
destination you know we call us and we

00:39:52,820 --> 00:39:57,290
get the performance you know of course

00:39:54,980 --> 00:39:59,840
there's more work to be done in this

00:39:57,290 --> 00:40:02,000
case and you know I'm you're looking at

00:39:59,840 --> 00:40:03,710
the x86 there's a lot of reverse mapping

00:40:02,000 --> 00:40:06,410
a lot of optimization that's been done

00:40:03,710 --> 00:40:08,900
there but I mean we've seen migration

00:40:06,410 --> 00:40:11,540
times which are like literally like

00:40:08,900 --> 00:40:14,960
hundred X as far as migrating from one

00:40:11,540 --> 00:40:17,210
host to another another big issue is

00:40:14,960 --> 00:40:19,910
like memory over commit so we have an

00:40:17,210 --> 00:40:23,690
issue with ballooning so right now if

00:40:19,910 --> 00:40:25,790
you inflate there is a race condition so

00:40:23,690 --> 00:40:29,090
your inflate this for example asking for

00:40:25,790 --> 00:40:32,210
X amount of memory but by the time it

00:40:29,090 --> 00:40:34,460
gets to the vm from km you to the vm you

00:40:32,210 --> 00:40:36,440
know that vm may have grabbed a lot of

00:40:34,460 --> 00:40:39,800
memory and that essentially leads to a

00:40:36,440 --> 00:40:41,450
complete lack of and there's a lot of

00:40:39,800 --> 00:40:44,570
services that we want to be able to

00:40:41,450 --> 00:40:47,090
overcome it on and so this is something

00:40:44,570 --> 00:40:49,430
that you know we worked on a patch you

00:40:47,090 --> 00:40:50,840
know the patch is not complete it's

00:40:49,430 --> 00:40:52,270
something better what's out there right

00:40:50,840 --> 00:40:58,160
now but it's something that we have to

00:40:52,270 --> 00:41:00,950
do more work on and make that happen and

00:40:58,160 --> 00:41:04,250
then some bad ones which I can't explain

00:41:00,950 --> 00:41:09,020
it from Ellen been so system calls so I

00:41:04,250 --> 00:41:10,460
have no idea or signal delivery I mean

00:41:09,020 --> 00:41:13,730
in my mind you know there should be no

00:41:10,460 --> 00:41:15,110
difference between native and guest you

00:41:13,730 --> 00:41:19,670
know I don't know why is it that guest

00:41:15,110 --> 00:41:22,490
is longer than native you know things

00:41:19,670 --> 00:41:23,690
like latency for four kegs actual I mean

00:41:22,490 --> 00:41:25,880
that's understandable

00:41:23,690 --> 00:41:29,960
there's a lot of IP eyes that go back

00:41:25,880 --> 00:41:34,670
and forth so I PISD now fortunately are

00:41:29,960 --> 00:41:38,000
still you know unlike posted or v TD

00:41:34,670 --> 00:41:42,859
posted interrupts or you know jake v

00:41:38,000 --> 00:41:45,770
Jake before enter up injection there's

00:41:42,859 --> 00:41:47,720
not much we could do here and typically

00:41:45,770 --> 00:41:49,400
and carry great we don't like to deal

00:41:47,720 --> 00:41:52,609
with threats because threads are

00:41:49,400 --> 00:41:54,560
troublesome we usually like to say that

00:41:52,609 --> 00:41:56,210
these checkpoint estate and then we

00:41:54,560 --> 00:42:00,310
start the process and if you have

00:41:56,210 --> 00:42:05,089
threads involved it gets more cumbersome

00:42:00,310 --> 00:42:08,510
but but you know it's something that may

00:42:05,089 --> 00:42:11,060
change but I think the big deal here is

00:42:08,510 --> 00:42:13,609
like putting software pulling off the

00:42:11,060 --> 00:42:15,589
shelf software essentially that is just

00:42:13,609 --> 00:42:17,119
expecting to do a lot of forks and execs

00:42:15,589 --> 00:42:18,890
and then all of a sudden you run into

00:42:17,119 --> 00:42:23,900
something you know this kind of a

00:42:18,890 --> 00:42:25,880
situation and this kind of wood finish

00:42:23,900 --> 00:42:28,940
up the presentation I mean when you look

00:42:25,880 --> 00:42:30,740
at though the overall gaps and I'm not

00:42:28,940 --> 00:42:33,319
going to go through each one of them but

00:42:30,740 --> 00:42:36,980
I mean you have gaps which are related

00:42:33,319 --> 00:42:38,540
to awareness you have gaps related to

00:42:36,980 --> 00:42:41,780
hardware you have gaps related to

00:42:38,540 --> 00:42:43,790
enhancements and this is really not an

00:42:41,780 --> 00:42:47,060
issue that's kind of that can be

00:42:43,790 --> 00:42:49,190
addressed by any one person or maybe

00:42:47,060 --> 00:42:50,990
even any one company i think you know

00:42:49,190 --> 00:42:53,240
similar to like carrier grade where

00:42:50,990 --> 00:42:56,869
there was a lot of synergy a lot of

00:42:53,240 --> 00:43:00,560
people working together it really takes

00:42:56,869 --> 00:43:02,770
a lot of people in a low level i think

00:43:00,560 --> 00:43:07,730
people that really show up to these

00:43:02,770 --> 00:43:11,630
conferences to be aware of like okay

00:43:07,730 --> 00:43:13,280
well what are we doing and NFV and it's

00:43:11,630 --> 00:43:16,010
these people that can actually close

00:43:13,280 --> 00:43:18,260
these gaps and it's also it also

00:43:16,010 --> 00:43:21,740
requires very close working with the

00:43:18,260 --> 00:43:23,390
hardware vendors and you know to close

00:43:21,740 --> 00:43:25,400
some of these gaps i mean some of the

00:43:23,390 --> 00:43:27,920
interaction I've had with you know I'm

00:43:25,400 --> 00:43:30,349
not gonna name that under but like for

00:43:27,920 --> 00:43:33,020
example you know they can't do crypto

00:43:30,349 --> 00:43:36,740
because the deal is that like you know

00:43:33,020 --> 00:43:40,430
if it's behind the iommu and you

00:43:36,740 --> 00:43:44,480
they basically offload a IPA address you

00:43:40,430 --> 00:43:46,910
know there's you know device past VF iOS

00:43:44,480 --> 00:43:48,530
broken it's not going to work and a lot

00:43:46,910 --> 00:43:51,890
of devices for example get passed

00:43:48,530 --> 00:43:54,350
through but they have no you know I p is

00:43:51,890 --> 00:43:57,440
associated with them or no smmu

00:43:54,350 --> 00:44:00,320
associated with them so V fil just like

00:43:57,440 --> 00:44:03,940
kind of just gives up because you know

00:44:00,320 --> 00:44:06,680
it doesn't have a kind of devices so

00:44:03,940 --> 00:44:10,030
that's pretty much it I don't know

00:44:06,680 --> 00:44:10,030

YouTube URL: https://www.youtube.com/watch?v=nPz59EI4STo


