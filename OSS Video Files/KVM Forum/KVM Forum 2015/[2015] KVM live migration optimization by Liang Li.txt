Title: [2015] KVM live migration optimization by Liang Li
Publication date: 2015-08-27
Playlist: KVM Forum 2015
Description: 
	Live migration plays a very important role in cloud computing technology. It facilitates maintenance, load balancing, hardware failover, energy saving and geographic migration. Because the application areas are so wide, the live migration function should be made flexible enough to meet the performance requirements of different usages. In this presentation, we would like to give the details of the multiple thread compression mechanism on KVM/QEMU which helps to reduce the total migration time, VM downtime and network traffic. We will also mention how to use Intelâ€™s hardware (de)compression accelerator and the optimized algorithm to reduce the CPU usage in live migration, and live migration based on DPDK which can make full use of the 10/40 Gigabit NICs (Network Interface Cards). At last, we will show some data of performance gain of these optimizations. 

Liang Li
Intel

I am a software engineer of Intel OTC (Open source Technology Center), and I am in the KVM/XEN enabling team. Before working for Intel, I worked as an embedded software engineer for 7 years.
Captions: 
	00:00:20,060 --> 00:00:29,310
Allah by Islam and I'm from Intel as a

00:00:26,550 --> 00:00:31,099
beginner in the area awkward position is

00:00:29,310 --> 00:00:34,980
my great pleasure to attend a sporting

00:00:31,099 --> 00:00:38,550
and today however you power color some

00:00:34,980 --> 00:00:45,660
talk samsung pod kol lower migration

00:00:38,550 --> 00:00:47,789
optimization here we go at first i will

00:00:45,660 --> 00:00:51,059
introduce the background or lamb a

00:00:47,789 --> 00:00:54,320
grecian some problems we have to serve

00:00:51,059 --> 00:00:57,660
and some issues in the current qu

00:00:54,320 --> 00:01:01,230
implementation some i will describe our

00:00:57,660 --> 00:01:03,930
solutions and show you some show you the

00:01:01,230 --> 00:01:06,869
performance tater at last i will

00:01:03,930 --> 00:01:15,780
released the work while playing what

00:01:06,869 --> 00:01:19,259
going to do low migration plays an

00:01:15,780 --> 00:01:22,590
important role in cloud computing it can

00:01:19,259 --> 00:01:26,570
be used for pesticide radium maintenance

00:01:22,590 --> 00:01:29,450
load balancing and the energy see you in

00:01:26,570 --> 00:01:32,759
the main optimization goal are to reduce

00:01:29,450 --> 00:01:37,790
the total i omega routine time reduce

00:01:32,759 --> 00:01:42,060
the week am down time and under improved

00:01:37,790 --> 00:01:45,000
now migration successful racial q emu

00:01:42,060 --> 00:01:47,939
and the qm have already implemented some

00:01:45,000 --> 00:01:52,740
work Harrison for optimization for

00:01:47,939 --> 00:01:56,850
example using the Rema to accelerate

00:01:52,740 --> 00:02:00,390
certain data transmission using X busy

00:01:56,850 --> 00:02:03,899
rle to reduce at air traffic and the

00:02:00,390 --> 00:02:06,810
reduced allow migration time and using

00:02:03,899 --> 00:02:09,750
Auto urgency more Harrison to improve

00:02:06,810 --> 00:02:13,039
the law migration successful ratio but

00:02:09,750 --> 00:02:13,039
it is large enough

00:02:16,329 --> 00:02:22,430
this slide shows the problems that we

00:02:19,700 --> 00:02:25,310
help 20 and some of these use in the

00:02:22,430 --> 00:02:27,530
current QE view implementation the first

00:02:25,310 --> 00:02:30,319
problem is about maggot set of facts

00:02:27,530 --> 00:02:32,870
allowed migration performance in

00:02:30,319 --> 00:02:36,980
practice the leatherwork Pennywise is

00:02:32,870 --> 00:02:40,489
most likely to be the boat leg poor

00:02:36,980 --> 00:02:45,019
results are some fast league products

00:02:40,489 --> 00:02:49,790
those can support the clink acha PP so40

00:02:45,019 --> 00:02:53,290
kbps penalize let this is still true for

00:02:49,790 --> 00:02:56,900
the following reason the first reason is

00:02:53,290 --> 00:03:01,159
network it is Yuri shelled so that we

00:02:56,900 --> 00:03:05,840
can't use the full penalize full on mega

00:03:01,159 --> 00:03:08,569
region the second reason 1 Giga PPS

00:03:05,840 --> 00:03:12,620
league is still widely used for Kosta

00:03:08,569 --> 00:03:15,439
consideration and the third reason for

00:03:12,620 --> 00:03:18,439
some use case like a geography Kalam

00:03:15,439 --> 00:03:21,849
accretion so in tulalip network

00:03:18,439 --> 00:03:25,819
Pennywise will be much lower some local

00:03:21,849 --> 00:03:28,159
network and wise so we should do some

00:03:25,819 --> 00:03:32,439
Sun to improve the lower megavision

00:03:28,159 --> 00:03:32,439
performance in this case

00:03:36,120 --> 00:03:44,940
a lot of issue is the Middle East page

00:03:40,319 --> 00:03:50,610
processing in the rain backstage at

00:03:44,940 --> 00:03:54,900
yellow in the LA migration before the

00:03:50,610 --> 00:03:59,720
ribbon back stage or the page was mug or

00:03:54,900 --> 00:04:03,120
mug with Magda yesterday as dirty and

00:03:59,720 --> 00:04:06,450
this will cost horse page to be

00:04:03,120 --> 00:04:10,170
processed one by one the data processing

00:04:06,450 --> 00:04:19,049
include 0p checking and sending the data

00:04:10,170 --> 00:04:26,160
out to the translation in fact so a lot

00:04:19,049 --> 00:04:31,410
of pages that are not used by the gas so

00:04:26,160 --> 00:04:34,949
we can skip processing these pages in

00:04:31,410 --> 00:04:38,750
the cast there are still some pages that

00:04:34,949 --> 00:04:43,289
I used by the gas before and then free

00:04:38,750 --> 00:04:48,599
this page is useless focused and can

00:04:43,289 --> 00:04:51,349
also be skipped q has optimization 40

00:04:48,599 --> 00:04:54,930
pages if you're several page is a

00:04:51,349 --> 00:04:58,080
detected early still revised as an

00:04:54,930 --> 00:05:01,950
artist a decision instead of sending a

00:04:58,080 --> 00:05:04,080
whole page of 06 mark allison can

00:05:01,950 --> 00:05:08,880
superior can speed up the lamination

00:05:04,080 --> 00:05:12,660
process but a way we can do more

00:05:08,880 --> 00:05:16,110
organization by visualizing all the

00:05:12,660 --> 00:05:20,849
desolation gas rampage 20 and skip the

00:05:16,110 --> 00:05:24,060
transmission of the terror pages by

00:05:20,849 --> 00:05:26,180
doing this we can minimize the pace that

00:05:24,060 --> 00:05:34,229
lead to be processed in the ram

00:05:26,180 --> 00:05:37,260
backstage the sole problem is there a to

00:05:34,229 --> 00:05:40,169
clean up function called during pause

00:05:37,260 --> 00:05:42,870
and cough stage which prolongs we am

00:05:40,169 --> 00:05:45,900
done time especially with the latest

00:05:42,870 --> 00:05:49,349
latest in his corner which contained a

00:05:45,900 --> 00:05:49,740
patch the drops just more page table

00:05:49,349 --> 00:05:52,560
entry

00:05:49,740 --> 00:05:54,240
when stops the dark dirty the migration

00:05:52,560 --> 00:06:03,660
and the function core will take

00:05:54,240 --> 00:06:07,259
thousands of milliseconds for these

00:06:03,660 --> 00:06:09,120
problems we have some solutions we use

00:06:07,259 --> 00:06:11,460
martes rare compression to improve the

00:06:09,120 --> 00:06:13,699
performance or lamb a grecian you know

00:06:11,460 --> 00:06:18,720
letter in the letter work penalize

00:06:13,699 --> 00:06:21,810
environment and skipping unused page in

00:06:18,720 --> 00:06:25,919
the ram backstage to avoid literally

00:06:21,810 --> 00:06:28,409
speedy data processing and the delay is

00:06:25,919 --> 00:06:36,479
a low emergency clean-up operation aunt

00:06:28,409 --> 00:06:38,430
iris data transmission it's done let me

00:06:36,479 --> 00:06:42,180
explain why Marcus Kruger compression

00:06:38,430 --> 00:06:44,759
can accelerate llama grecian the first

00:06:42,180 --> 00:06:48,030
chart shows the time spent on different

00:06:44,759 --> 00:06:51,479
stage when processing select as a

00:06:48,030 --> 00:06:54,990
rampage in the indole at work and wise

00:06:51,479 --> 00:06:58,699
environment most of all the time spent

00:06:54,990 --> 00:07:01,440
on sending data to the laceration

00:06:58,699 --> 00:07:06,000
compression can make space tethers model

00:07:01,440 --> 00:07:10,169
so stain is compressed it page will take

00:07:06,000 --> 00:07:14,520
less time but compression is surf will

00:07:10,169 --> 00:07:17,190
take extra time if compression is fast

00:07:14,520 --> 00:07:20,940
enough we can shorten the total aromatic

00:07:17,190 --> 00:07:25,500
total time spent on processing that the

00:07:20,940 --> 00:07:28,639
page later Marcus ran is used for

00:07:25,500 --> 00:07:28,639
speeding of the compression

00:07:32,910 --> 00:07:38,880
large rally is a mozzarella compression

00:07:35,920 --> 00:07:41,440
is a new feature for low migration

00:07:38,880 --> 00:07:43,420
instead of sending the guest Paige a

00:07:41,440 --> 00:07:48,550
directory this feature compress the

00:07:43,420 --> 00:07:51,250
rampage before sending and the order

00:07:48,550 --> 00:07:58,090
related patch helping all red he'll

00:07:51,250 --> 00:08:01,810
already be merged into Q mu 2.4 Marcus

00:07:58,090 --> 00:08:04,960
red compression is different from X busy

00:08:01,810 --> 00:08:11,320
I ali also bottoms and use some kind of

00:08:04,960 --> 00:08:14,350
compression xvi le compressed page page

00:08:11,320 --> 00:08:17,170
updates watermarks were multiple air

00:08:14,350 --> 00:08:20,770
compression compress the original page

00:08:17,170 --> 00:08:23,620
data a lot of difference is multi

00:08:20,770 --> 00:08:28,390
storied compression transfers compressed

00:08:23,620 --> 00:08:35,250
data in the RAM backstage but x pci l XV

00:08:28,390 --> 00:08:39,760
di le cannot do that mozzarella

00:08:35,250 --> 00:08:44,320
compression code works with xvi le can

00:08:39,760 --> 00:08:48,180
minimize the dead traffic in theory so

00:08:44,320 --> 00:08:51,700
if X VCR le and the martyrs read

00:08:48,180 --> 00:08:54,490
compression are both turned on a marsh

00:08:51,700 --> 00:08:57,540
res comprehension Oh details of fact

00:08:54,490 --> 00:09:08,710
takes effect in the rain backstage and

00:08:57,540 --> 00:09:10,810
xvi le will take over to rest world this

00:09:08,710 --> 00:09:13,000
chart shows the relationship we turn the

00:09:10,810 --> 00:09:15,880
migration strata and it's conversions

00:09:13,000 --> 00:09:19,810
read in the migrations ran after

00:09:15,880 --> 00:09:22,960
carrying orderly page it will check if

00:09:19,810 --> 00:09:24,700
the payee 20 page if flawed some

00:09:22,960 --> 00:09:26,560
migrations rather will notify the

00:09:24,700 --> 00:09:31,180
compressions read to do is compression

00:09:26,560 --> 00:09:35,320
and Sam will fall notification if all

00:09:31,180 --> 00:09:37,480
the comparisons res are busy when

00:09:35,320 --> 00:09:41,140
notification arrives it puts a

00:09:37,480 --> 00:09:43,720
compressive danger to the same buffer if

00:09:41,140 --> 00:09:47,220
the sandbar is for the compressor tater

00:09:43,720 --> 00:09:47,220
will be sent out to legislation

00:09:47,849 --> 00:09:54,909
in the compression thread at first the

00:09:52,059 --> 00:09:57,789
thread we're we're wait to start until

00:09:54,909 --> 00:10:00,729
it receives alert ification from the

00:09:57,789 --> 00:10:02,979
migration strata let's receive the

00:10:00,729 --> 00:10:06,899
notification it starts to use

00:10:02,979 --> 00:10:09,689
compression when the compression is done

00:10:06,899 --> 00:10:16,299
it allowed to find the migrations thread

00:10:09,689 --> 00:10:19,269
and then repeated this process so

00:10:16,299 --> 00:10:28,989
mutters ready decompression works in the

00:10:19,269 --> 00:10:31,749
same way one time or did copy haven't

00:10:28,989 --> 00:10:36,669
been put in the compress compress the

00:10:31,749 --> 00:10:40,539
page data to the qemu file in the block

00:10:36,669 --> 00:10:42,909
arrange it slowly to keep the sequence

00:10:40,539 --> 00:10:46,449
of pages but one thing we should make

00:10:42,909 --> 00:10:49,149
make sure is that if a loop clock begins

00:10:46,449 --> 00:10:53,979
or pages that belongs to the previous

00:10:49,149 --> 00:10:56,699
blocks should be used in our first it's

00:10:53,979 --> 00:10:56,699
very important

00:11:00,540 --> 00:11:05,580
with autumn with other multiples red

00:11:03,600 --> 00:11:08,480
compression to cpu youth age on the

00:11:05,580 --> 00:11:12,660
south side during our migration is about

00:11:08,480 --> 00:11:15,270
fifty percent with mozzarella

00:11:12,660 --> 00:11:17,610
compression if using the lab to do the

00:11:15,270 --> 00:11:21,300
compression to see if you use a on

00:11:17,610 --> 00:11:25,290
society is about seven hundred and sixty

00:11:21,300 --> 00:11:30,240
percent it is very high there are two

00:11:25,290 --> 00:11:32,360
solutions to reduce the cpu usage 11 is

00:11:30,240 --> 00:11:38,810
to use the faster compression of reason

00:11:32,360 --> 00:11:41,840
like PL d 0 LD for instead of de la

00:11:38,810 --> 00:11:44,250
pelota solution is to use a hardware

00:11:41,840 --> 00:11:49,320
compression compression accelerator to

00:11:44,250 --> 00:11:51,780
offload overhead a from cpu intel future

00:11:49,320 --> 00:11:54,530
chipset we were provided this kind of

00:11:51,780 --> 00:11:54,530
hardware spot

00:11:59,580 --> 00:12:05,720
a lot of optimization we can do is to

00:12:02,760 --> 00:12:09,690
skips unused page in the rain backstage

00:12:05,720 --> 00:12:13,310
in ramberg stage old pages are marked as

00:12:09,690 --> 00:12:16,560
dirty and unprocessed one by one is

00:12:13,310 --> 00:12:19,190
inefficient because Sarah Mary is exists

00:12:16,560 --> 00:12:22,980
some page the lever used by gas

00:12:19,190 --> 00:12:27,990
especially for an hour guests Oh a light

00:12:22,980 --> 00:12:33,720
weight overhead cast it slowly that to

00:12:27,990 --> 00:12:38,310
process the unused page when we optimize

00:12:33,720 --> 00:12:42,600
this by using but we can we can optimize

00:12:38,310 --> 00:12:48,810
this by using a third page that only

00:12:42,600 --> 00:12:51,510
contains a used pages we're gonna choose

00:12:48,810 --> 00:12:54,840
despite starting legged ready before we

00:12:51,510 --> 00:12:57,150
am running the site of fact of this this

00:12:54,840 --> 00:13:00,120
way is celebrity wear of fact cast

00:12:57,150 --> 00:13:04,590
performance if huge page is used in the

00:13:00,120 --> 00:13:08,820
custom was there trying to find out some

00:13:04,590 --> 00:13:12,180
other bad ways to serve this issue for

00:13:08,820 --> 00:13:15,510
example Justice abilities huge page into

00:13:12,180 --> 00:13:18,950
two megabytes ATP for two in July

00:13:15,510 --> 00:13:26,130
migration and switch to the four key

00:13:18,950 --> 00:13:28,530
type HD Rinzler migration by the way m40

00:13:26,130 --> 00:13:32,240
sees you will still need more

00:13:28,530 --> 00:13:32,240
investigation and bite mark

00:13:37,699 --> 00:13:44,209
do some cream do some clean-up operation

00:13:41,179 --> 00:13:47,600
in the pod and carcass stage may more or

00:13:44,209 --> 00:13:50,029
less prolonged we em down time so clean

00:13:47,600 --> 00:13:52,040
up origin so clean up operation should

00:13:50,029 --> 00:13:55,459
be delayed until its data transmission

00:13:52,040 --> 00:13:58,749
is finished the migration end and the

00:13:55,459 --> 00:14:01,850
block we clean up operation at two or

00:13:58,749 --> 00:14:09,649
two of the operations that compile a can

00:14:01,850 --> 00:14:13,720
be delayed okay let me show you some of

00:14:09,649 --> 00:14:16,249
the performance gain after optimization

00:14:13,720 --> 00:14:19,489
this slide shows a performance

00:14:16,249 --> 00:14:22,009
improvement with Mario compression so

00:14:19,489 --> 00:14:26,749
about table shows the results when

00:14:22,009 --> 00:14:29,179
migrating and I our guest the total of

00:14:26,749 --> 00:14:33,759
migration time reduced about forty five

00:14:29,179 --> 00:14:38,059
percent so we am down time reduced about

00:14:33,759 --> 00:14:40,759
thirty thirty three percent and it's a

00:14:38,059 --> 00:14:43,749
take the trap network that trip in

00:14:40,759 --> 00:14:46,639
traffic reduce so about seventy percent

00:14:43,749 --> 00:14:49,519
the table below shows the test results

00:14:46,639 --> 00:14:52,279
with my grading or guests with were

00:14:49,519 --> 00:14:55,419
closed which writing/reading ambos

00:14:52,279 --> 00:15:00,379
retweet the numbers to one gigabyte

00:14:55,419 --> 00:15:02,649
memory arrow aerial puri decree the

00:15:00,379 --> 00:15:06,379
total of migration time reduced about

00:15:02,649 --> 00:15:11,169
fifty seven percent and we am down time

00:15:06,379 --> 00:15:14,480
reduced about forty-eight percent

00:15:11,169 --> 00:15:18,019
network network traffic reduce about

00:15:14,480 --> 00:15:21,279
sixty percent the performance game is

00:15:18,019 --> 00:15:21,279
where we obvious

00:15:25,020 --> 00:15:31,780
this table shows the performance

00:15:27,480 --> 00:15:35,890
comparison p term markzware compression

00:15:31,780 --> 00:15:39,790
and XP cioÃ¨ the guests rounds were

00:15:35,890 --> 00:15:43,270
closed which rice read lambert to a 2

00:15:39,790 --> 00:15:46,420
gigabytes memory area theoretically the

00:15:43,270 --> 00:15:49,810
results shows that a monstrous Marcus

00:15:46,420 --> 00:16:00,640
read compression combined with xvz le

00:15:49,810 --> 00:16:02,980
how to best performance this table shows

00:16:00,640 --> 00:16:06,580
a performance gain when skipping the

00:16:02,980 --> 00:16:09,360
unused page in the rain backstage the

00:16:06,580 --> 00:16:14,290
total of migration time reduced about

00:16:09,360 --> 00:16:16,150
six sixty five percent the results

00:16:14,290 --> 00:16:18,970
showed show the possibility or

00:16:16,150 --> 00:16:23,020
performance gain that way can see you by

00:16:18,970 --> 00:16:26,700
doing such an optimization or so we need

00:16:23,020 --> 00:16:30,510
to do more to dismiss performance impact

00:16:26,700 --> 00:16:30,510
but it seems worse

00:16:34,800 --> 00:16:41,550
this table shows the performance game if

00:16:37,399 --> 00:16:46,260
delays clean-up operation so we am down

00:16:41,550 --> 00:16:48,149
time reduce about eighty four percent so

00:16:46,260 --> 00:16:51,860
improvement the improvement is so

00:16:48,149 --> 00:16:55,170
obvious because some changes in the QM

00:16:51,860 --> 00:17:04,770
that make the clean-up operation much

00:16:55,170 --> 00:17:08,250
more time consuming than before there

00:17:04,770 --> 00:17:11,309
are some works that were up going while

00:17:08,250 --> 00:17:14,400
doing Oh in our place including

00:17:11,309 --> 00:17:17,400
improving the performance of artifice

00:17:14,400 --> 00:17:21,620
rare compression in tunica PPS network

00:17:17,400 --> 00:17:24,300
environment improve the performance of

00:17:21,620 --> 00:17:29,610
the Halliwell compression accelerator

00:17:24,300 --> 00:17:33,540
and using a way x instruction to our to

00:17:29,610 --> 00:17:37,260
accelerate set zero paycheck in using

00:17:33,540 --> 00:17:40,260
the rules pateros using user space

00:17:37,260 --> 00:17:43,830
network stack to accelerate data

00:17:40,260 --> 00:17:46,950
transmission and now my coalition

00:17:43,830 --> 00:17:50,760
performance optimization for the 40

00:17:46,950 --> 00:17:54,710
pickup eps network so if you are

00:17:50,760 --> 00:17:54,710
interested maybe we can do it together

00:17:56,600 --> 00:18:03,650
ok said or is there a question

00:18:10,770 --> 00:18:16,770
the way you identify unused pages if I

00:18:14,430 --> 00:18:19,830
understood is that you have dirty

00:18:16,770 --> 00:18:21,930
tracking from the start of execution of

00:18:19,830 --> 00:18:24,450
the viet of the vm and dirty page

00:18:21,930 --> 00:18:27,840
tracking is on all the time that the vm

00:18:24,450 --> 00:18:29,820
is executing is that correct yes have

00:18:27,840 --> 00:18:32,640
you measured the performance impact of

00:18:29,820 --> 00:18:34,440
having dirty page tracking on all the

00:18:32,640 --> 00:18:38,580
time rather than just while we're

00:18:34,440 --> 00:18:41,640
migrating yes how much impact how much

00:18:38,580 --> 00:18:43,530
does that slow down a vm when we are not

00:18:41,640 --> 00:18:47,790
migrating actually where who didn't

00:18:43,530 --> 00:18:51,870
deserve to merriment okay yes but we

00:18:47,790 --> 00:18:55,020
were we were to eat yes in that case the

00:18:51,870 --> 00:18:56,610
guest order was idle so they weren't

00:18:55,020 --> 00:18:58,320
actually doing anything in the guest so

00:18:56,610 --> 00:19:04,590
they're just measuring how fast the

00:18:58,320 --> 00:19:07,140
migration is which is ya know in order

00:19:04,590 --> 00:19:11,220
to locate veggies yes so so yeah that's

00:19:07,140 --> 00:19:13,980
something they haven't done yet if we if

00:19:11,220 --> 00:19:16,140
we can find some some better way to

00:19:13,980 --> 00:19:21,170
serve this issue maybe we can we can do

00:19:16,140 --> 00:19:21,170
this is wary as in he's worse to do this

00:19:22,850 --> 00:19:28,530
the way that we were thinking about

00:19:25,590 --> 00:19:31,680
doing is that when we asked for the

00:19:28,530 --> 00:19:34,860
dirty bit map we start a when we start

00:19:31,680 --> 00:19:37,650
the live debate mapped blog we have

00:19:34,860 --> 00:19:39,990
studied as claimed we can start it with

00:19:37,650 --> 00:19:43,050
the pages that are already in the page

00:19:39,990 --> 00:19:44,910
table must if we start with that we

00:19:43,050 --> 00:19:48,630
don't need to start with all the pages

00:19:44,910 --> 00:19:52,070
map with the little bit right now we set

00:19:48,630 --> 00:19:56,550
the Delta Lima Inc emu as all pages

00:19:52,070 --> 00:20:00,450
dirty and then we called the camera that

00:19:56,550 --> 00:20:02,820
locker a lock pages from now we can

00:20:00,450 --> 00:20:05,720
change that opera theater operation to

00:20:02,820 --> 00:20:11,450
lock all the kernels that our map it now

00:20:05,720 --> 00:20:11,450
these are the databases that what

00:20:14,679 --> 00:20:20,539
not all of them need to be if they

00:20:17,869 --> 00:20:23,389
haven't been used it yet they will not

00:20:20,539 --> 00:20:28,729
be in the page table jet nothing will be

00:20:23,389 --> 00:20:31,519
there the use it once understood not

00:20:28,729 --> 00:20:33,789
there so this what idea but this is not

00:20:31,519 --> 00:20:33,789
that

00:20:39,040 --> 00:20:50,740
so any more question was a bit quick for

00:20:46,570 --> 00:20:52,360
me to see how many cpu cores you use for

00:20:50,740 --> 00:20:55,720
the multi-threaded compression and

00:20:52,360 --> 00:20:58,990
decompression and I'm also interested if

00:20:55,720 --> 00:21:01,860
you will do that as well when you have

00:20:58,990 --> 00:21:03,940
the new CPU instructions that does the

00:21:01,860 --> 00:21:07,390
compression the comparison huh why do

00:21:03,940 --> 00:21:11,650
you do also multi-threaded than okay and

00:21:07,390 --> 00:21:13,210
so cpu you age is depend on the or the

00:21:11,650 --> 00:21:17,560
compression and the decompression

00:21:13,210 --> 00:21:21,550
operations that you use for some

00:21:17,560 --> 00:21:24,580
lab yellow is weary slow so so security

00:21:21,550 --> 00:21:27,250
is very high at set as I just described

00:21:24,580 --> 00:21:29,980
is about say one hundred and sixty

00:21:27,250 --> 00:21:33,460
percent when I if I do a compression

00:21:29,980 --> 00:21:37,210
with a distress but which lc4 is much

00:21:33,460 --> 00:21:43,180
slower if Y to the compression with six

00:21:37,210 --> 00:21:48,100
red so if you use AG is including the

00:21:43,180 --> 00:21:52,930
commute is the alpha is all about one

00:21:48,100 --> 00:21:59,530
hundred percent guess only takes 50 suit

00:21:52,930 --> 00:22:02,440
50 a 50-percent extras of you yeah sir

00:21:59,530 --> 00:22:04,540
isn't it a bit unrealistic in an NF v

00:22:02,440 --> 00:22:08,190
environment where you have really all

00:22:04,540 --> 00:22:10,810
cpus fully on the load usually and

00:22:08,190 --> 00:22:12,130
you're using then suddenly six cpu

00:22:10,810 --> 00:22:15,580
courses on like that just for

00:22:12,130 --> 00:22:19,390
compressing one vm for migration no the

00:22:15,580 --> 00:22:22,510
car in current implementation mm to see

00:22:19,390 --> 00:22:26,050
just look just just just to compare said

00:22:22,510 --> 00:22:29,020
it's not always busy it in most muscle

00:22:26,050 --> 00:22:32,920
time isn't it I really ought to wait

00:22:29,020 --> 00:22:35,770
wait for the way for the instruction to

00:22:32,920 --> 00:22:38,080
do is compression no but I mean the

00:22:35,770 --> 00:22:40,090
usually you have a machine with let's

00:22:38,080 --> 00:22:42,100
say 12 course so sound like go then you

00:22:40,090 --> 00:22:45,700
have like a high performance which which

00:22:42,100 --> 00:22:47,980
uses four or two cores then you have

00:22:45,700 --> 00:22:50,440
let's say three or two VMs running and

00:22:47,980 --> 00:22:52,160
each of them have been another don't

00:22:50,440 --> 00:22:54,110
know I need to do the math but another

00:22:52,160 --> 00:22:56,570
for courses on like that that there's

00:22:54,110 --> 00:22:58,910
not that much cause left then if you

00:22:56,570 --> 00:23:00,680
have really lots of network processing

00:22:58,910 --> 00:23:03,500
running there that's why I'm asking how

00:23:00,680 --> 00:23:05,390
realistic is it to scale up to multiple

00:23:03,500 --> 00:23:07,370
threats in the compression decompression

00:23:05,390 --> 00:23:14,020
phase because you would slow down the

00:23:07,370 --> 00:23:18,530
other network functions yes actually

00:23:14,020 --> 00:23:20,990
Marcus ready is not necessary if you can

00:23:18,530 --> 00:23:23,600
do the compression fast enough you can

00:23:20,990 --> 00:23:26,330
do all sends you what you want save us

00:23:23,600 --> 00:23:29,000
read that ok that's what I'm asking if

00:23:26,330 --> 00:23:30,200
you plan to do when you have these CPU

00:23:29,000 --> 00:23:31,910
instructions I don't know how they

00:23:30,200 --> 00:23:35,960
looked like for now it's black magic

00:23:31,910 --> 00:23:39,650
right if you plan to do the math reading

00:23:35,960 --> 00:23:41,750
even there or you plan to go back to a

00:23:39,650 --> 00:23:44,360
single threaded compression and

00:23:41,750 --> 00:23:51,320
decompression again because you cpu is

00:23:44,360 --> 00:23:56,450
anyway accelerating it you know what i

00:23:51,320 --> 00:23:58,750
mean i'm sorry i don't believe but maybe

00:23:56,450 --> 00:24:01,250
these question is too early because i

00:23:58,750 --> 00:24:03,680
don't know the details about the harbor

00:24:01,250 --> 00:24:05,480
instruction but the question is like do

00:24:03,680 --> 00:24:08,240
you plan to reduce the number of

00:24:05,480 --> 00:24:12,560
compression and decompression threats no

00:24:08,240 --> 00:24:16,040
no no IIIi no display i justed to modify

00:24:12,560 --> 00:24:19,370
the current marvel compression so if we

00:24:16,040 --> 00:24:21,020
I just need is one in the current

00:24:19,370 --> 00:24:22,760
implication just read it can be set by

00:24:21,020 --> 00:24:27,470
the user so you can set as the

00:24:22,760 --> 00:24:35,420
compression spirit for 11 at least 10

00:24:27,470 --> 00:24:37,340
with maxime and 250 and 50s well so we

00:24:35,420 --> 00:24:40,580
can what we can change up the

00:24:37,340 --> 00:24:44,630
implementation and unjust the mega sir

00:24:40,580 --> 00:24:46,790
the case for once read he said is

00:24:44,630 --> 00:24:52,880
motivation it's and some of the current

00:24:46,790 --> 00:24:55,600
limitation I significant this same okay

00:24:52,880 --> 00:24:55,600
thank you

00:24:56,980 --> 00:25:01,510
so you had two experiments that you did

00:24:59,980 --> 00:25:03,880
and one of the more was that Idol vm and

00:25:01,510 --> 00:25:05,049
the member was mostly unused and then

00:25:03,880 --> 00:25:09,370
the other one you had been writing to

00:25:05,049 --> 00:25:12,549
two gigabyte region right yes so do you

00:25:09,370 --> 00:25:15,160
have some measurements on how much data

00:25:12,549 --> 00:25:16,600
actually went over the wire with and

00:25:15,160 --> 00:25:20,530
without your compression in those two

00:25:16,600 --> 00:25:23,380
different experiments uh yes well we

00:25:20,530 --> 00:25:26,980
really have got some data but it's not a

00:25:23,380 --> 00:25:31,330
it's not containing slice can you tell

00:25:26,980 --> 00:25:33,280
me about it i I'm sorry I can't remember

00:25:31,330 --> 00:25:35,919
that you'd side of it it's time for

00:25:33,280 --> 00:25:39,690
maybe if you want i can i can send to

00:25:35,919 --> 00:25:45,220
you by email that'd be great the i'm

00:25:39,690 --> 00:25:47,679
mike @ google.com mich e so this legs

00:25:45,220 --> 00:25:49,990
went by pretty fast but it and so I

00:25:47,679 --> 00:25:52,809
probably read this wrong but it looked

00:25:49,990 --> 00:25:54,610
like the blackout time in the instance

00:25:52,809 --> 00:25:56,260
where you had been dirtying memory was

00:25:54,610 --> 00:25:57,820
shorter than the blackout time where you

00:25:56,260 --> 00:26:01,860
didn't dirty memory and that surprised

00:25:57,820 --> 00:26:01,860
the heck out of me did I see that wrong

00:26:03,270 --> 00:26:06,630
you want to Mike

00:26:11,030 --> 00:26:19,330
so the one where the guest was idle was

00:26:14,020 --> 00:26:23,330
where he started the pace dirty logging

00:26:19,330 --> 00:26:26,180
before the vm was even running and so

00:26:23,330 --> 00:26:27,620
that was one experiment and the other

00:26:26,180 --> 00:26:29,540
experiment was something else which I

00:26:27,620 --> 00:26:31,730
don't recall right now but these are two

00:26:29,540 --> 00:26:34,460
completely different approaches and two

00:26:31,730 --> 00:26:42,590
different workloads so I mean not

00:26:34,460 --> 00:26:48,170
comparable okay is this one I the 2gb

00:26:42,590 --> 00:26:58,640
one the one where the yeah okay so k

00:26:48,170 --> 00:27:16,220
this one did you see this light did you

00:26:58,640 --> 00:27:18,370
see this light go back for okay sees

00:27:16,220 --> 00:27:18,370
what

00:27:24,210 --> 00:27:27,210
why

00:27:40,320 --> 00:27:45,040
I'm sorry I'm not quite an ounce than

00:27:42,760 --> 00:27:50,650
you cousin maybe I we can just cause you

00:27:45,040 --> 00:27:53,490
later okay I remember that you have

00:27:50,650 --> 00:27:56,830
mentioned that you will delay the

00:27:53,490 --> 00:28:00,100
migrating end function but as far as i

00:27:56,830 --> 00:28:03,550
know the mac reaching end want to merge

00:28:00,100 --> 00:28:07,420
work so i was wondering by delaying my

00:28:03,550 --> 00:28:10,630
cruising end what how much time you

00:28:07,420 --> 00:28:13,660
saved 00 me the only that function i

00:28:10,630 --> 00:28:16,300
know i like a question i also used to

00:28:13,660 --> 00:28:20,140
that usually refers ladies in its corner

00:28:16,300 --> 00:28:24,070
and there is a practice which drops a

00:28:20,140 --> 00:28:29,650
naga turkey drops a small page table

00:28:24,070 --> 00:28:33,670
entries when stops naga dirty yellow in

00:28:29,650 --> 00:28:36,490
the means of fungus a minor and once i

00:28:33,670 --> 00:28:39,280
wish to do is to stop naga 30 and the

00:28:36,490 --> 00:28:41,890
pendant and is also catch is a ratio of

00:28:39,280 --> 00:28:46,840
fact it's a total agreement and just

00:28:41,890 --> 00:28:49,360
which prolongs time and so the time

00:28:46,840 --> 00:28:54,429
consuming operation is just in the eye

00:28:49,360 --> 00:28:57,309
open trail i will control so at the time

00:28:54,429 --> 00:29:02,830
consuming operation is just to disable

00:28:57,309 --> 00:29:06,179
the lock 30 yes the previous the

00:29:02,830 --> 00:29:10,110
previous to a corner has lost adhesive

00:29:06,179 --> 00:29:10,110
okay I understand

00:29:14,510 --> 00:29:24,020
so so if though said or thank you I have

00:29:20,850 --> 00:29:27,120
a question at the moment sorry okay I I

00:29:24,020 --> 00:29:30,890
the compression a question how about is

00:29:27,120 --> 00:29:34,169
performance under heavy memory pressure

00:29:30,890 --> 00:29:39,779
he remember name repair shop pressure

00:29:34,169 --> 00:29:43,950
yeah I guess I this date was scared from

00:29:39,779 --> 00:29:50,850
a very very little memory pressure right

00:29:43,950 --> 00:29:54,059
no actually in the this in this lies the

00:29:50,850 --> 00:29:57,840
following table shows shows that the

00:29:54,059 --> 00:30:02,399
performance data in Ohio you know you

00:29:57,840 --> 00:30:08,549
know your higher overhead remember or

00:30:02,399 --> 00:30:13,500
hell which straight so to below to below

00:30:08,549 --> 00:30:19,110
the table below 30 yes in in this in

00:30:13,500 --> 00:30:22,649
this table we-we-we to get around or

00:30:19,110 --> 00:30:25,620
workload which runs which right right in

00:30:22,649 --> 00:30:29,610
with numbers 2 0 1 gigabyte memory error

00:30:25,620 --> 00:30:32,850
theoretically with with fast feed okay

00:30:29,610 --> 00:30:36,090
so they're all of this out of this we

00:30:32,850 --> 00:30:40,500
can't have a problem you started under

00:30:36,090 --> 00:30:43,770
very heavy memory workload a the by

00:30:40,500 --> 00:30:45,929
magazine that usually fill and that does

00:30:43,770 --> 00:30:51,630
this algorithm help to solve this

00:30:45,929 --> 00:30:55,260
problem it depends on how heavy your

00:30:51,630 --> 00:31:00,240
workload is is really early to have an

00:30:55,260 --> 00:31:03,299
accent compression can you can continue

00:31:00,240 --> 00:31:11,159
to have but I food it's a workload is

00:31:03,299 --> 00:31:13,679
just a little example just 22 times some

00:31:11,159 --> 00:31:17,330
people to x them before I think as

00:31:13,679 --> 00:31:21,899
compression where where where we have

00:31:17,330 --> 00:31:27,299
okay I currently the I Kevin librarians

00:31:21,899 --> 00:31:31,259
have have a hybrid have a value I if the

00:31:27,299 --> 00:31:35,070
either iteration it it calculator time

00:31:31,259 --> 00:31:38,730
over the the value it will stop by

00:31:35,070 --> 00:31:41,519
migration I know we in our environmental

00:31:38,730 --> 00:31:45,389
testing environment we usually find even

00:31:41,519 --> 00:31:49,350
we adjusted this value to 2 seconds it's

00:31:45,389 --> 00:32:08,989
still usually film I i hope this I hope

00:31:49,350 --> 00:32:08,989

YouTube URL: https://www.youtube.com/watch?v=wqg7scBqa8w


