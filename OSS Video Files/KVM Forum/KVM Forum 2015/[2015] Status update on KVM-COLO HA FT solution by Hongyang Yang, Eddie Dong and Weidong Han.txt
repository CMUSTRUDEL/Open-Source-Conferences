Title: [2015] Status update on KVM-COLO HA FT solution by Hongyang Yang, Eddie Dong and Weidong Han
Publication date: 2015-09-02
Playlist: KVM Forum 2015
Description: 
	COLO is a VM replication technique which provides application-agnostic software-implemented hardware fault tolerance "non-stop service". Under COLO mode, both primary VM (PVM) and secondary VM (SVM) are run in parallel. They receive the same request from client, and generate response in parallel too. If the response packets from PVM and SVM are identical, they are released immediately. Otherwise, a VM checkpoint (on demand) is conducted. COLO patches for QEMU have already been sent to the dev maillist and are under review. In this talk, we will talk about the COLO implementation in QEMU, the new designed block replication, discussing on problems we've met while developing COLO. Apart from the technical part, we will also present the latest progress from Fujitsu, Intel and Huawei. For more info, refer to COLO project wiki: http://wiki.qemu.org/Features/COLO

Eddie Dong
Intel
Eddie Dong is a virtualization architect of Intel Corporate, working in KVM from very beginning, and has given talks in the past at KVM Forum  well as many in other conferences too.

Hongyang Yang
Fujitsu
Yang Hongyang is a software engineer at Fujitsu for 7 years. Has been | working on a wide range of software projects at fujitsu, and has contributed | to opensource projects such as Linux, Xen and QEMU. Currently focus on | Virtual Machine (VM) replication projects (Remus on Xen, COLO on QEMU).

Weidong Han
Huawei

Slides: https://drive.google.com/file/d/0BzyAwvVlQckeSEs4WmdJbkpHNFE/view?usp=sharing
Captions: 
	00:00:16,310 --> 00:00:26,750
good afternoon everyone my name is Boyd

00:00:21,330 --> 00:00:32,730
I work for my way this is my partner

00:00:26,750 --> 00:00:39,750
wonderful position yum yum today I will

00:00:32,730 --> 00:00:44,390
present the state update hers abid abid

00:00:39,750 --> 00:00:47,010
each about the coral about Carl is

00:00:44,390 --> 00:00:52,590
introduced many times in the past the

00:00:47,010 --> 00:00:57,300
time by Eddie intro so this this time I

00:00:52,590 --> 00:01:01,820
will show the the burst currents leaders

00:00:57,300 --> 00:01:08,189
about a coral and I will don't show the

00:01:01,820 --> 00:01:11,580
concepts of coral this is an agenda

00:01:08,189 --> 00:01:20,000
first I want to introduce the background

00:01:11,580 --> 00:01:26,420
about Carl so what is coral coral named

00:01:20,000 --> 00:01:26,420
across green rocks teman is an

00:01:27,290 --> 00:01:33,119
application agnostic solution for

00:01:30,390 --> 00:01:38,610
nonstop service in the crowd computing

00:01:33,119 --> 00:01:44,790
as know as higher available or for

00:01:38,610 --> 00:01:49,579
tolerance solutions the typical nonstop

00:01:44,790 --> 00:01:53,909
service requires maybe have two solution

00:01:49,579 --> 00:01:59,480
the first maybe you can choose hardware

00:01:53,909 --> 00:02:06,830
solutions but you will buy some

00:01:59,480 --> 00:02:11,020
hard work spend too much money or some

00:02:06,830 --> 00:02:15,050
other hard work to support your

00:02:11,020 --> 00:02:19,340
requirements the other way you can

00:02:15,050 --> 00:02:23,540
choose the software solutions but it may

00:02:19,340 --> 00:02:27,430
be should customize your software world

00:02:23,540 --> 00:02:32,800
for the solution but in our colors

00:02:27,430 --> 00:02:42,880
solution is an application agnostic

00:02:32,800 --> 00:02:50,150
solution so this solution is good for

00:02:42,880 --> 00:02:55,330
washer hydrogen machine in the high

00:02:50,150 --> 00:03:00,620
higher available and for the tolerance

00:02:55,330 --> 00:03:07,600
so what happened coral concept was the

00:03:00,620 --> 00:03:15,100
first published in the paper in 2013 and

00:03:07,600 --> 00:03:23,480
in the same year in tow NFR we announced

00:03:15,100 --> 00:03:33,530
the first industry use industrious about

00:03:23,480 --> 00:03:37,390
the coral in fusion severe 3.0 and 2013

00:03:33,530 --> 00:03:45,110
kayvyun form Eddie introduced the coral

00:03:37,390 --> 00:03:50,590
in the in 2014 inter Valley and the food

00:03:45,110 --> 00:03:59,739
issue cooperate workable for coral and

00:03:50,590 --> 00:03:59,739
our focus is make coral open source

00:04:00,920 --> 00:04:11,390
in this mere coral was introduced to

00:04:05,959 --> 00:04:15,680
then and the carrion and we received

00:04:11,390 --> 00:04:19,820
Mary commands we will rain we will ring

00:04:15,680 --> 00:04:25,880
commands and many people give us some

00:04:19,820 --> 00:04:31,160
suggesting about the solutions ok in

00:04:25,880 --> 00:04:36,070
this year we all go about coral is make

00:04:31,160 --> 00:04:40,970
color can't upstream both p.m. and then

00:04:36,070 --> 00:04:45,370
and we get to confirm the information

00:04:40,970 --> 00:04:56,000
from then community that color will be

00:04:45,370 --> 00:05:01,910
Madrid in then 4.74 kvm community we

00:04:56,000 --> 00:05:06,680
also send the color framework a division

00:05:01,910 --> 00:05:11,470
worth watching aight aight in the next

00:05:06,680 --> 00:05:11,470
we will show the details about the coral

00:05:11,919 --> 00:05:21,520
this is the AG capture of coral we can

00:05:16,010 --> 00:05:25,760
see from the pic from the picture from

00:05:21,520 --> 00:05:29,380
we have to note photo torrance the

00:05:25,760 --> 00:05:33,860
primary node and the secondary node

00:05:29,380 --> 00:05:42,289
primary node had several parts about

00:05:33,860 --> 00:05:46,340
coral the first is a hot bit habit we

00:05:42,289 --> 00:05:51,560
defined a interface about a habit the

00:05:46,340 --> 00:05:58,100
users can realize the old habit module

00:05:51,560 --> 00:06:04,669
or can use the linux open source linux h

00:05:58,100 --> 00:06:07,220
eight modules the next fail-over is just

00:06:04,669 --> 00:06:09,820
of all when the primary node or the

00:06:07,220 --> 00:06:21,250
second node take

00:06:09,820 --> 00:06:25,590
some force or some failure what each is

00:06:21,250 --> 00:06:35,980
no that can take care take over under

00:06:25,590 --> 00:06:40,120
contour can sure just just like if the

00:06:35,980 --> 00:06:42,970
primary node fair over the second you

00:06:40,120 --> 00:06:47,350
know that will take over and then the

00:06:42,970 --> 00:06:53,710
response about each request will be

00:06:47,350 --> 00:06:58,540
changed and in the desert part is we'll

00:06:53,710 --> 00:07:02,800
check point module chill point is very

00:06:58,540 --> 00:07:08,410
similar with Rimmer's in the end

00:07:02,800 --> 00:07:13,420
community just it means we can use this

00:07:08,410 --> 00:07:17,680
module to transmit some just like memory

00:07:13,420 --> 00:07:21,840
tell page from primary node which

00:07:17,680 --> 00:07:21,840
machine to the secondary virtual machine

00:07:22,500 --> 00:07:32,680
next is hollow disk manager this

00:07:27,850 --> 00:07:37,590
marriage we used a very new solution in

00:07:32,680 --> 00:07:42,610
kuna community right now just it named

00:07:37,590 --> 00:07:47,580
broker a replication scheme and we get

00:07:42,610 --> 00:07:50,830
many evil commands from Red Hat guys

00:07:47,580 --> 00:07:56,200
just like a polo about mvd server and

00:07:50,830 --> 00:07:59,490
the client just Stephanie and fam then

00:07:56,200 --> 00:07:59,490
and some other guys

00:08:00,200 --> 00:08:10,550
and the next is a promising module about

00:08:05,270 --> 00:08:15,410
this module we have two solutions in the

00:08:10,550 --> 00:08:20,270
first ideas we put this module in the

00:08:15,410 --> 00:08:27,200
kernel space but in the condo space

00:08:20,270 --> 00:08:32,210
there are some issues is to defend too

00:08:27,200 --> 00:08:37,400
so first we should change it iptables

00:08:32,210 --> 00:08:43,250
and meanwhile we should change the elf

00:08:37,400 --> 00:08:48,470
net link module in cano and the most the

00:08:43,250 --> 00:08:53,000
most problem that the most difficult

00:08:48,470 --> 00:08:58,090
problem is if with the problem module

00:08:53,000 --> 00:09:03,680
put a load in kernel space we cannot

00:08:58,090 --> 00:09:08,030
solution that scenario that just like we

00:09:03,680 --> 00:09:12,320
host the user plus DB degree if the

00:09:08,030 --> 00:09:18,050
network packet to not just loo the linux

00:09:12,320 --> 00:09:28,340
kernel network stack we cannot chase the

00:09:18,050 --> 00:09:31,490
packet packet passing path and the

00:09:28,340 --> 00:09:39,170
second the second solution we put this

00:09:31,490 --> 00:09:45,680
module into Q because Q me have her user

00:09:39,170 --> 00:09:55,100
space network stack sleep but now this

00:09:45,680 --> 00:09:59,030
slip as it'll nobody maintain this this

00:09:55,100 --> 00:10:04,460
module or this subsystem and the

00:09:59,030 --> 00:10:07,750
Stephanie had Oscar someone can maintain

00:10:04,460 --> 00:10:07,750
this subsystem

00:10:08,239 --> 00:10:19,259
if we put the processing model in the

00:10:13,790 --> 00:10:27,779
user space we can easily handle in the

00:10:19,259 --> 00:10:35,179
packet and we don't need changes occur

00:10:27,779 --> 00:10:43,669
no of course this solution other his

00:10:35,179 --> 00:10:48,899
habit some difficult problem to solve

00:10:43,669 --> 00:10:53,929
just like we use the useless space that

00:10:48,899 --> 00:10:53,929
we cannot handle that

00:10:57,680 --> 00:11:06,410
we cannot use just like we host Nanette

00:11:02,110 --> 00:11:11,149
so this this solutions performance will

00:11:06,410 --> 00:11:17,589
be weaker than the fastest solution it

00:11:11,149 --> 00:11:26,779
means to solution has each solution has

00:11:17,589 --> 00:11:30,770
its good concept and negative was a

00:11:26,779 --> 00:11:38,270
sector maybe but we want to realize the

00:11:30,770 --> 00:11:41,920
two solutions in the next step ok this

00:11:38,270 --> 00:11:41,920
is the architecture of the coral

00:11:45,970 --> 00:11:51,649
next I want to introduce the current

00:11:49,459 --> 00:12:00,339
status about the coral in chemical

00:11:51,649 --> 00:12:05,390
military to academia paper published in

00:12:00,339 --> 00:12:12,200
2013 and the industry announcement we

00:12:05,390 --> 00:12:17,899
also said Holly huge in severe uses

00:12:12,200 --> 00:12:25,279
coral 2013 but this solution aids for

00:12:17,899 --> 00:12:28,010
them platform wiki page curl on them you

00:12:25,279 --> 00:12:32,300
guys can't get the information from the

00:12:28,010 --> 00:12:39,829
website and the color on Camille kvm we

00:12:32,300 --> 00:12:45,230
also write the widget pages about

00:12:39,829 --> 00:12:49,540
upstream Staters color flim-flam work

00:12:45,230 --> 00:12:55,970
has been passed as submitted to the cube

00:12:49,540 --> 00:12:58,990
mail list of vision eight and the

00:12:55,970 --> 00:12:58,990
broader application

00:13:00,250 --> 00:13:11,800
is also sent the washroom eight but the

00:13:09,370 --> 00:13:16,510
currents leaders about the proctor

00:13:11,800 --> 00:13:24,160
application it will be I think it will

00:13:16,510 --> 00:13:28,150
be madrid in the in the future and the

00:13:24,160 --> 00:13:32,320
color proxy in qml pure say had been

00:13:28,150 --> 00:13:40,530
posted on Camille mail list and many

00:13:32,320 --> 00:13:47,820
people also send the opinion about this

00:13:40,530 --> 00:13:47,820
solution just like a dairy and Stephanie

00:13:48,960 --> 00:13:57,970
patches for then ascent to the mailing

00:13:51,850 --> 00:14:04,270
list as also question eight and i said

00:13:57,970 --> 00:14:13,710
before then color will be married in

00:14:04,270 --> 00:14:18,210
then 4.7 version next is the performance

00:14:13,710 --> 00:14:26,490
to be honest the next performance

00:14:18,210 --> 00:14:32,940
benchmark it's tested in 2013 is not the

00:14:26,490 --> 00:14:40,140
newest and the results came from them

00:14:32,940 --> 00:14:40,140
4.1 version but

00:14:40,760 --> 00:14:43,540
just

00:14:43,960 --> 00:14:56,730
so when you use the 2013 worship we can

00:14:51,130 --> 00:15:02,070
also get good performance than rumors

00:14:56,730 --> 00:15:05,340
because you you can see from this figure

00:15:02,070 --> 00:15:08,950
kalo achieves one hundred percent

00:15:05,340 --> 00:15:13,690
ninety-nine percent and eighty-nine

00:15:08,950 --> 00:15:20,830
percent of native performance and it all

00:15:13,690 --> 00:15:26,140
depends remus 40 by 100 and the 27-13 I

00:15:20,830 --> 00:15:29,970
and the City eight percent in cases

00:15:26,140 --> 00:15:35,790
involve 14 and the 16th words

00:15:29,970 --> 00:15:39,420
respectively this issues the

00:15:35,790 --> 00:15:44,770
multiprocessors testing about workbench

00:15:39,420 --> 00:15:47,160
is also showed a good performance than

00:15:44,770 --> 00:15:47,160
rumors

00:15:50,590 --> 00:16:00,520
this is the opposed to the gray circle

00:15:53,800 --> 00:16:04,140
performers and Nicola also achieves 82.4

00:16:00,520 --> 00:16:07,990
percent of native months in average and

00:16:04,140 --> 00:16:10,870
the eight eighty five point five percent

00:16:07,990 --> 00:16:15,190
of native peak performance which

00:16:10,870 --> 00:16:19,920
outperform reamers by forty six percent

00:16:15,190 --> 00:16:19,920
and the city four percent respective

00:16:23,020 --> 00:16:31,150
this is a multiprocessor testing about

00:16:26,740 --> 00:16:34,150
benchmark his revenge to performance or

00:16:31,150 --> 00:16:36,910
post grocery multiprocessor guests it's

00:16:34,150 --> 00:16:41,950
a similar to the guests with unique

00:16:36,910 --> 00:16:44,530
processor the mouse treating that Colo

00:16:41,950 --> 00:16:52,510
can scare well with Maurice abuse as

00:16:44,530 --> 00:16:57,850
well okay next I will make a brief

00:16:52,510 --> 00:17:00,930
summarize about the presentation first

00:16:57,850 --> 00:17:07,000
caller can achieve native performance

00:17:00,930 --> 00:17:10,360
forcibly intensive work Road and a

00:17:07,000 --> 00:17:13,089
second chorus mulch neutral and all the

00:17:10,360 --> 00:17:16,380
performance rumors by nineteen

00:17:13,089 --> 00:17:19,800
sixty-nine percent in Weber bunch and

00:17:16,380 --> 00:17:26,050
the forty six percent in PG bunch

00:17:19,800 --> 00:17:31,900
respectively it means coral is a very

00:17:26,050 --> 00:17:38,740
good solution for high available or for

00:17:31,900 --> 00:17:43,270
tolerance of course we have more works

00:17:38,740 --> 00:17:50,590
need to do in the next just like fix

00:17:43,270 --> 00:17:55,710
based on revealing commands but from

00:17:50,590 --> 00:17:59,410
four color frameworks and I talked about

00:17:55,710 --> 00:18:05,530
the migration maintenance of all of one

00:17:59,410 --> 00:18:12,830
and Ericsson and and I help

00:18:05,530 --> 00:18:16,010
they can help me or our part of my

00:18:12,830 --> 00:18:19,460
partners to reveal the color framework

00:18:16,010 --> 00:18:24,070
patch serious maybe this patch patch

00:18:19,460 --> 00:18:28,040
Aceros is very large and it may be 38

00:18:24,070 --> 00:18:33,980
patches in this sterile so maybe it's

00:18:28,040 --> 00:18:43,280
different but I hope they can take a

00:18:33,980 --> 00:18:50,450
help us optimize the performance is an

00:18:43,280 --> 00:18:55,060
is another good another important design

00:18:50,450 --> 00:18:59,240
needed to do because in the realize

00:18:55,060 --> 00:19:02,600
evelopment to client is all customers

00:18:59,240 --> 00:19:13,970
about ford taurus care about the

00:19:02,600 --> 00:19:20,380
performance latency and slew a pass yes

00:19:13,970 --> 00:19:23,380
Oh overheard about the foot of network

00:19:20,380 --> 00:19:23,380
packet

00:19:24,340 --> 00:19:34,360
and the next step is kala proxy in

00:19:30,940 --> 00:19:40,450
Camille that means the coral proxy

00:19:34,360 --> 00:19:47,200
realized in the queue user space and we

00:19:40,450 --> 00:19:50,230
will do this to rewrite the tooth

00:19:47,200 --> 00:19:56,520
erosion about the coral about network

00:19:50,230 --> 00:20:00,480
proxy okay

00:19:56,520 --> 00:20:00,480
thank you any question

00:20:09,160 --> 00:20:16,100
hi um so I was wondering the Zen

00:20:12,590 --> 00:20:20,330
solution I guess it has support for

00:20:16,100 --> 00:20:22,730
network and also for block and I didn't

00:20:20,330 --> 00:20:23,900
really know that that that existed and

00:20:22,730 --> 00:20:26,600
that it's something that's being merged

00:20:23,900 --> 00:20:28,250
the Q mu code seems to be you know

00:20:26,600 --> 00:20:31,610
written from scratch integrated directly

00:20:28,250 --> 00:20:34,040
from Q mu but what can we learn from the

00:20:31,610 --> 00:20:35,810
Zen code that you mentioned will be

00:20:34,040 --> 00:20:39,230
merged how do they handle block or

00:20:35,810 --> 00:20:40,700
application and the network proxy

00:20:39,230 --> 00:20:42,650
inspection you don't have to go into a

00:20:40,700 --> 00:20:45,770
lot of detail but I'm just interested

00:20:42,650 --> 00:20:49,370
because I wasn't aware of that all about

00:20:45,770 --> 00:21:00,230
it then solutions may be my partner can

00:20:49,370 --> 00:21:05,420
give some detail then plug solution then

00:21:00,230 --> 00:21:11,660
uses q block replication yeah we support

00:21:05,420 --> 00:21:14,390
color on then hvm platform so then can

00:21:11,660 --> 00:21:19,310
use Q's blocker application as well and

00:21:14,390 --> 00:21:24,470
also a prop for proxy part we all we use

00:21:19,310 --> 00:21:28,250
kernel module yeah and Q and then also

00:21:24,470 --> 00:21:33,100
can both use the color module solution

00:21:28,250 --> 00:21:33,100
for color yeah

00:21:41,920 --> 00:21:47,190
so you had some nice nice comparison of

00:21:44,680 --> 00:21:51,460
the the open source implementations of

00:21:47,190 --> 00:21:54,400
fail over there is a semi-important know

00:21:51,460 --> 00:21:56,920
as commercial solution for this as well

00:21:54,400 --> 00:21:59,560
on the market do you have some estimate

00:21:56,920 --> 00:22:03,750
on how is this performs in comparison

00:21:59,560 --> 00:22:06,880
specifically now as it gains SMP support

00:22:03,750 --> 00:22:08,530
sorry BM there what is vm they are doing

00:22:06,880 --> 00:22:10,210
in this area how is it does it compare

00:22:08,530 --> 00:22:16,000
basically the Fae or a failover

00:22:10,210 --> 00:22:22,780
performance wise to do Colo roughly so

00:22:16,000 --> 00:22:27,910
sorry I I can't touch you is it no I'm

00:22:22,780 --> 00:22:29,860
trying to speak louder ah ok and what do

00:22:27,910 --> 00:22:31,510
you have any feeling or maybe even the

00:22:29,860 --> 00:22:35,350
measurement Prakash they're probably and

00:22:31,510 --> 00:22:37,780
how the embers failover feature compare

00:22:35,350 --> 00:22:39,490
performance wise to colo specifically

00:22:37,780 --> 00:22:44,980
the newer version which are supposed no

00:22:39,490 --> 00:22:51,190
support SMP as we know vmware does not

00:22:44,980 --> 00:22:54,640
support color like fair / they support i

00:22:51,190 --> 00:22:58,150
think in this fair six-point oh they

00:22:54,640 --> 00:23:01,090
support multi-process processor fair /

00:22:58,150 --> 00:23:05,680
but they are using remote rumors like

00:23:01,090 --> 00:23:08,590
solutions so as as we mentioned our

00:23:05,680 --> 00:23:11,800
performance is better than dreamers so I

00:23:08,590 --> 00:23:16,110
think our solutions is also better than

00:23:11,800 --> 00:23:19,140
remember but we have not measured yeah

00:23:16,110 --> 00:23:19,140
thank you

00:23:19,770 --> 00:23:28,440

YouTube URL: https://www.youtube.com/watch?v=nNPHw_3pzts


