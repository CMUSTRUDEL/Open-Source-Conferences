Title: "Hybrid" Nesting: KVM on Hyper-V by Vitaly Kuznetsov & Tianyu Lan
Publication date: 2018-11-14
Playlist: KVM Forum 2018
Description: 
	This may come as a surprise but it is already possible to run nested KVM inside Hyper-V VMs and this includes several instance types on Azure. Such workloads, however, may not always perform very well. Some limitations come from x86 architecture and conceptual differences between KVM and Hyper-V, other issues could be dealt with within KVM. In this talk we will go through different performance bottlenecks of nested KVM-on-Hyper-V deployments. The presentation will highligh recent developments in the area: Englightened VMCS, Enlightened MSR-Bitmap, stable clocksource and others. We will also try to describe our work in progress and possible future improvements for nested KVM in general and KVM on Hyper-V in particular.

---

Vitaly Kuznetsov
Senior Software Engineer
Red Hat

Vitaly works at Red Hat Virtualization Engineering group, his job duties include supporting Linux as a guest on 3rd party hypervisors. He mainly contributes to Linux kernel and related projects. His recent public speaking experience includes events like LinuxCon 2017 China, FOSDEM 2018, DevConf 2016 and 2018, Xen Project Developer Summit 2015 and others.

Tianyu Lan
Senior Software Engineer, Enterprise Open Source Group
Microsoft

Tianyu is Senior Software Engineer in Enterprise Open Source Group at Microsoft. He focuses on the performance optimization of Linux VMs on Hyper-V. Previously, Tianyu worked on ACPI, power management, KVM and Xen opens source projects at Intel Open source technology center. He gave “High-performance Virtualization for HPC Cloud on Xen” talk during Xen Project Developer Summit 2016.
Captions: 
	00:00:01,040 --> 00:00:09,510
[Music]

00:00:05,930 --> 00:00:12,300
hello everyone my name is Vitaly and I

00:00:09,510 --> 00:00:15,059
work for Red Hat and at red head

00:00:12,300 --> 00:00:17,609
I'm usually responsible for rail as a

00:00:15,059 --> 00:00:20,039
guest efforts like running guests on

00:00:17,609 --> 00:00:23,640
rail guests on third-party hypervisors

00:00:20,039 --> 00:00:26,519
and public clouds and here next to me in

00:00:23,640 --> 00:00:28,140
general and from Microsoft can you

00:00:26,519 --> 00:00:30,929
please introduce yourself yes I'm

00:00:28,140 --> 00:00:33,149
Carolyn and for Microsoft I'm walking

00:00:30,929 --> 00:00:35,370
the Microsoft earnings cano team focus

00:00:33,149 --> 00:00:38,790
on the net virtualization improvement

00:00:35,370 --> 00:00:41,160
now recently we introduced a lot of we

00:00:38,790 --> 00:00:43,530
United feature for net virtualization

00:00:41,160 --> 00:00:45,539
and we also focused on the i/o

00:00:43,530 --> 00:00:51,539
performance for the next virtualization

00:00:45,539 --> 00:00:53,550
okay yeah so like a year ago I got

00:00:51,539 --> 00:00:56,370
pregnant as a nesting space I was

00:00:53,550 --> 00:00:58,379
testing hyper-v and I thought like it

00:00:56,370 --> 00:01:00,899
would be cool to try running not only

00:00:58,379 --> 00:01:04,080
Linux on hyper-v but also TV I'm on

00:01:00,899 --> 00:01:07,890
hyper-v would it work I tried and

00:01:04,080 --> 00:01:09,960
surprisingly it worked so today we are

00:01:07,890 --> 00:01:12,510
going to talk about running KVM on

00:01:09,960 --> 00:01:14,790
hyper-v the current state of affairs

00:01:12,510 --> 00:01:18,960
like what have done over the last year

00:01:14,790 --> 00:01:20,750
and what challenges are ahead and my

00:01:18,960 --> 00:01:23,670
usual carry at once speaking about

00:01:20,750 --> 00:01:26,490
nesting is that it's really really easy

00:01:23,670 --> 00:01:27,840
to confuse the audience when talking

00:01:26,490 --> 00:01:30,329
about nesting it's really easy to

00:01:27,840 --> 00:01:31,470
confuse yourself right so if you're not

00:01:30,329 --> 00:01:35,640
confused you're not paying attention

00:01:31,470 --> 00:01:38,400
guys okay so let's start with the

00:01:35,640 --> 00:01:41,340
terminology and for this talk we're

00:01:38,400 --> 00:01:43,890
gonna be talking about this simple setup

00:01:41,340 --> 00:01:46,200
when you run a VM on top of hyper-v as

00:01:43,890 --> 00:01:48,119
you know how can we is a type 1

00:01:46,200 --> 00:01:51,479
hypervisor which means that it's more

00:01:48,119 --> 00:01:52,860
similar to them than to kbm it has a

00:01:51,479 --> 00:01:55,560
separate hypervisor

00:01:52,860 --> 00:01:58,020
and then its management domain like root

00:01:55,560 --> 00:02:02,460
partition is a Windows partition it runs

00:01:58,020 --> 00:02:05,219
already inside the guest and as level 1

00:02:02,460 --> 00:02:07,829
guest we will have Linux running with a

00:02:05,219 --> 00:02:10,200
VM and on top of that we will run our

00:02:07,829 --> 00:02:12,810
level 2 guest which will be

00:02:10,200 --> 00:02:16,830
Linux for this talk

00:02:12,810 --> 00:02:19,440
so the question the main question is

00:02:16,830 --> 00:02:22,740
like why doing this why bothering right

00:02:19,440 --> 00:02:26,190
and yeah so there are several reasons

00:02:22,740 --> 00:02:28,050
for that the first one is and the

00:02:26,190 --> 00:02:33,360
probably the main one for running on

00:02:28,050 --> 00:02:35,430
hyper-v is Asia so we have this second

00:02:33,360 --> 00:02:40,110
biggest cloud in the world right and it

00:02:35,430 --> 00:02:43,170
runs on hyper-v and the hypervisor there

00:02:40,110 --> 00:02:46,560
is basically the partitioning hypervisor

00:02:43,170 --> 00:02:49,050
if you think about it so if you run like

00:02:46,560 --> 00:02:51,750
a big enough instance on Asia you're not

00:02:49,050 --> 00:02:53,910
doing something like shared core or like

00:02:51,750 --> 00:02:57,239
memory overcome it you will always have

00:02:53,910 --> 00:03:00,540
your own resources there so it's very

00:02:57,239 --> 00:03:02,790
reasonable to try to run whatever

00:03:00,540 --> 00:03:06,060
workload you want there including

00:03:02,790 --> 00:03:08,340
virtualized workloads and for example

00:03:06,060 --> 00:03:11,850
some instances there have hundreds of

00:03:08,340 --> 00:03:14,880
CPUs they have like terabytes of memory

00:03:11,850 --> 00:03:16,950
literally and you may want to actually

00:03:14,880 --> 00:03:19,170
partition them for several different use

00:03:16,950 --> 00:03:21,870
cases but still stay on the same

00:03:19,170 --> 00:03:26,100
instance for for example economical

00:03:21,870 --> 00:03:30,830
reasons the other may the other reason

00:03:26,100 --> 00:03:34,200
to try this is because of these new

00:03:30,830 --> 00:03:37,290
secured containers efforts and yesterday

00:03:34,200 --> 00:03:40,170
there was an interesting talk by erik

00:03:37,290 --> 00:03:42,329
ernst and KY and if you haven't been

00:03:40,170 --> 00:03:44,700
there I encourage you to watch the

00:03:42,329 --> 00:03:49,410
recording they talked about running

00:03:44,700 --> 00:03:53,100
Kutta containers and when you run them

00:03:49,410 --> 00:03:55,590
this includes that puts your container

00:03:53,100 --> 00:03:57,810
in a VM and if you are running already

00:03:55,590 --> 00:03:59,130
in a cloud for example in Asia that

00:03:57,810 --> 00:04:03,769
means that you're actually running

00:03:59,130 --> 00:04:07,410
nested the other non obvious reason to

00:04:03,769 --> 00:04:11,040
do this is that we are also interested

00:04:07,410 --> 00:04:13,019
in running hyper-v on Korea and for that

00:04:11,040 --> 00:04:14,700
we're implementing also these

00:04:13,019 --> 00:04:17,519
Enlightenment's which are required to

00:04:14,700 --> 00:04:20,340
make them perform well and we would like

00:04:17,519 --> 00:04:22,140
to test them for example so it would be

00:04:20,340 --> 00:04:25,050
really helpful if we can have both

00:04:22,140 --> 00:04:26,220
server and client implementation well

00:04:25,050 --> 00:04:29,430
and of course when

00:04:26,220 --> 00:04:31,860
look at how things are done on paper we

00:04:29,430 --> 00:04:35,280
we got some inspiration and we do

00:04:31,860 --> 00:04:40,170
similar things on KVM for example one

00:04:35,280 --> 00:04:44,940
hand Lee did PV IP is inspired by our

00:04:40,170 --> 00:04:46,770
work for hyper-v so over the last year

00:04:44,940 --> 00:04:48,960
have done several things and I'm gonna

00:04:46,770 --> 00:04:51,330
walk through them like and quickly

00:04:48,960 --> 00:04:54,030
explain why these things are important

00:04:51,330 --> 00:04:55,620
and what we've done yeah

00:04:54,030 --> 00:04:58,830
so the first one is gonna be like the

00:04:55,620 --> 00:05:01,350
clock source then Latin 3 MCS and then

00:04:58,830 --> 00:05:06,240
John you is gonna talk about PV EPT

00:05:01,350 --> 00:05:11,550
invalidation so the clock source so some

00:05:06,240 --> 00:05:14,310
applications want to have to know what

00:05:11,550 --> 00:05:17,730
time is it now and they want to know it

00:05:14,310 --> 00:05:20,790
very frequently right so they keep doing

00:05:17,730 --> 00:05:23,760
these requests trying to figure out the

00:05:20,790 --> 00:05:26,250
current timestamp and we want it to be

00:05:23,760 --> 00:05:29,070
as fast as possible and for that

00:05:26,250 --> 00:05:31,350
KVM and hyper-v they use different

00:05:29,070 --> 00:05:34,140
technologies in KVM it's called KVM

00:05:31,350 --> 00:05:38,100
clock in hyper it's called hyper which

00:05:34,140 --> 00:05:41,100
EST pages wait both use the same idea

00:05:38,100 --> 00:05:42,780
it's basically a page which is shared

00:05:41,100 --> 00:05:43,200
with your hypervisor which has two

00:05:42,780 --> 00:05:46,500
numbers

00:05:43,200 --> 00:05:50,760
it has like a multiplier and an offset

00:05:46,500 --> 00:05:52,440
so you get your TC region and T C's for

00:05:50,760 --> 00:05:54,210
who doesn't know that it's like a

00:05:52,440 --> 00:05:56,040
register in your CPU so you can do it

00:05:54,210 --> 00:05:57,960
it's very fast even from your software

00:05:56,040 --> 00:05:59,669
you don't need to go like in the kernel

00:05:57,960 --> 00:06:02,610
mode for that so you read it you

00:05:59,669 --> 00:06:06,090
multiply you add you get the answer like

00:06:02,610 --> 00:06:08,820
what time is it now and it all works

00:06:06,090 --> 00:06:10,680
both for KVM and for hyper-v but when

00:06:08,820 --> 00:06:15,690
we're running nested it didn't work

00:06:10,680 --> 00:06:18,479
because in KVM hypervisor you will get

00:06:15,690 --> 00:06:20,700
stable clock source for your guest only

00:06:18,479 --> 00:06:24,030
when you're right when your main clock

00:06:20,700 --> 00:06:28,950
source is TC and T stick page hyper-v is

00:06:24,030 --> 00:06:32,490
not this one so yeah we just what we've

00:06:28,950 --> 00:06:35,880
done we've enable it so we explain to

00:06:32,490 --> 00:06:38,330
KVM that hyper-v TST pages in equally

00:06:35,880 --> 00:06:40,280
good clock souls and

00:06:38,330 --> 00:06:43,009
it works after that you get stable talks

00:06:40,280 --> 00:06:45,439
or senior level-2 guests so we can read

00:06:43,009 --> 00:06:48,830
the time stamp with the same basically

00:06:45,439 --> 00:06:52,159
cost at the same cost but there is one

00:06:48,830 --> 00:06:54,439
problem with that so your level one

00:06:52,159 --> 00:06:56,599
guest with it's all level two guests can

00:06:54,439 --> 00:06:58,129
migrate and what happens when you

00:06:56,599 --> 00:07:00,560
migrate and that's actually the reason

00:06:58,129 --> 00:07:02,990
why we have these clock sources and we

00:07:00,560 --> 00:07:06,110
are not exposed and Rafi is see the

00:07:02,990 --> 00:07:08,210
reason is that when you migrate your TC

00:07:06,110 --> 00:07:10,370
reading changes first the offset is

00:07:08,210 --> 00:07:14,449
different second the frequency is

00:07:10,370 --> 00:07:16,099
different so your hypervisor can adjust

00:07:14,449 --> 00:07:18,949
its values for you if you are using this

00:07:16,099 --> 00:07:21,080
pv clock source like kb m clock you will

00:07:18,949 --> 00:07:23,000
again do the multiplication addition and

00:07:21,080 --> 00:07:24,500
you will get the correct result but

00:07:23,000 --> 00:07:27,650
what's going to happen to your level two

00:07:24,500 --> 00:07:29,449
guest so Microsoft came up with

00:07:27,650 --> 00:07:32,629
so-called tree entitlement features they

00:07:29,449 --> 00:07:37,159
like this part right so what happens is

00:07:32,629 --> 00:07:40,819
that level one migration happens usually

00:07:37,159 --> 00:07:42,560
like transparently but if you are

00:07:40,819 --> 00:07:44,210
running your own guests then you

00:07:42,560 --> 00:07:48,400
actually need to be aware of it

00:07:44,210 --> 00:07:51,349
and the features I've done is that you

00:07:48,400 --> 00:07:53,990
can enable the feature so telling your

00:07:51,349 --> 00:07:56,479
level zero hypervisor which is hyper-v

00:07:53,990 --> 00:07:58,669
that you are actually interested in the

00:07:56,479 --> 00:08:02,449
information about migration so when you

00:07:58,669 --> 00:08:08,089
migrate your TC access become emulated

00:08:02,449 --> 00:08:10,819
and the hypervisor tries to preserve the

00:08:08,089 --> 00:08:12,469
frequency and the offset so from your

00:08:10,819 --> 00:08:14,029
point of view and some the most

00:08:12,469 --> 00:08:17,060
important from your guest point of view

00:08:14,029 --> 00:08:19,580
nothing changes but in level one you get

00:08:17,060 --> 00:08:22,099
an interrupt you're supposed to stop all

00:08:19,580 --> 00:08:25,120
your guests adjust their tasty pages you

00:08:22,099 --> 00:08:27,560
already know the new TC frequency and

00:08:25,120 --> 00:08:31,849
disable the emulation and running them

00:08:27,560 --> 00:08:36,229
again so we have this now in KVM it

00:08:31,849 --> 00:08:38,180
works so it's possible to migrate KVM

00:08:36,229 --> 00:08:41,949
with all these guests and level 2

00:08:38,180 --> 00:08:44,630
o'clock sources will remain stable

00:08:41,949 --> 00:08:50,240
doesn't feature I wanted to talk about

00:08:44,630 --> 00:08:51,710
is a hyper-v enlightened vm CS so you

00:08:50,240 --> 00:08:53,840
all probably know how

00:08:51,710 --> 00:08:58,160
virtualization is implemented on Intel

00:08:53,840 --> 00:09:00,410
platform right so basically how you run

00:08:58,160 --> 00:09:02,780
a virtual machine on intohe right you

00:09:00,410 --> 00:09:05,780
create a structure in memory like page

00:09:02,780 --> 00:09:09,020
size and then with special instructions

00:09:05,780 --> 00:09:11,570
you set the require state like registers

00:09:09,020 --> 00:09:14,270
and other stuff and then you tell your

00:09:11,570 --> 00:09:16,100
CPU please run this is my virtual

00:09:14,270 --> 00:09:17,960
machine then it will run natively on

00:09:16,100 --> 00:09:20,570
your CPU and only when some special

00:09:17,960 --> 00:09:22,850
event happens it will get back to you

00:09:20,570 --> 00:09:26,000
and you can analyze the state again in

00:09:22,850 --> 00:09:29,180
the structure and do something with it

00:09:26,000 --> 00:09:31,490
modify I can continue executing so when

00:09:29,180 --> 00:09:32,230
we are talking about nesting how would

00:09:31,490 --> 00:09:35,750
it work

00:09:32,230 --> 00:09:38,210
level 1 hypervisor thinks that he knows

00:09:35,750 --> 00:09:40,460
he can create such a structure and he

00:09:38,210 --> 00:09:42,080
can do something with it but actually he

00:09:40,460 --> 00:09:45,400
doesn't own the structure it's still

00:09:42,080 --> 00:09:48,560
level 0 who owns it so all that being

00:09:45,400 --> 00:09:51,050
right Liam breed accesses and that the

00:09:48,560 --> 00:09:54,530
instructions you use to actually edit

00:09:51,050 --> 00:09:56,750
the structure because you don't know it

00:09:54,530 --> 00:09:58,640
right it's hidden from you it's there in

00:09:56,750 --> 00:10:01,910
the memory but you don't know where

00:09:58,640 --> 00:10:05,120
these fields are so all these memories

00:10:01,910 --> 00:10:07,190
being rights will go into level 0 it

00:10:05,120 --> 00:10:10,670
will emulate them for you we'll get back

00:10:07,190 --> 00:10:13,460
to you it's not in English super fast so

00:10:10,670 --> 00:10:15,800
they came up with the shadowy idea I'm

00:10:13,460 --> 00:10:17,990
trying to speed up a little bit and we

00:10:15,800 --> 00:10:20,690
said we MCS basically there is a

00:10:17,990 --> 00:10:23,900
structure in memory it is a hardware

00:10:20,690 --> 00:10:26,150
feature and level 1 hypervisor can

00:10:23,900 --> 00:10:29,270
access fields there natively without

00:10:26,150 --> 00:10:31,580
doing VM exits but the problem is when

00:10:29,270 --> 00:10:34,520
we are trying to then execute this level

00:10:31,580 --> 00:10:36,110
2 guest probe level 0 we need to merge

00:10:34,520 --> 00:10:38,150
the information so we need to ruin the

00:10:36,110 --> 00:10:39,860
whole structure merge it with our

00:10:38,150 --> 00:10:42,290
understanding of what's allowed and

00:10:39,860 --> 00:10:44,330
what's not for the guest and continue

00:10:42,290 --> 00:10:47,240
executing so from that point of view

00:10:44,330 --> 00:10:49,070
that's also not that fast as it could be

00:10:47,240 --> 00:10:51,320
so Microsoft came out with us

00:10:49,070 --> 00:10:53,210
enlightened GMCs idea which is a

00:10:51,320 --> 00:10:56,660
software feature and basically it

00:10:53,210 --> 00:10:59,630
exposes the structure of this VM CS from

00:10:56,660 --> 00:11:02,860
level 0 to level 1 so level 1 can access

00:10:59,630 --> 00:11:05,089
it with normal memory accesses and

00:11:02,860 --> 00:11:07,339
moreover there is an interesting

00:11:05,089 --> 00:11:10,939
think there that you have a field which

00:11:07,339 --> 00:11:13,339
tells level zero hypervisor which fields

00:11:10,939 --> 00:11:16,009
were changed by level 1 hypervisor so if

00:11:13,339 --> 00:11:17,689
no changes were done then it doesn't

00:11:16,009 --> 00:11:21,349
need to read the whole structure can

00:11:17,689 --> 00:11:24,439
read only what was changed there so that

00:11:21,349 --> 00:11:29,799
becomes much faster and that's

00:11:24,439 --> 00:11:34,129
enlightened VM CF it basically yeah as

00:11:29,799 --> 00:11:37,219
that it tastes like if you do like cpuid

00:11:34,129 --> 00:11:39,589
loop and level 2 guest it will stay the

00:11:37,219 --> 00:11:42,379
feature will save you like 1500 CPU

00:11:39,589 --> 00:11:46,039
cycles we haven't noticed already for

00:11:42,379 --> 00:11:47,929
quite a while the other idea which is

00:11:46,039 --> 00:11:51,939
just an extension of the previous idea

00:11:47,929 --> 00:11:55,069
is enlightened MS are bitmaps what is it

00:11:51,939 --> 00:11:56,749
as you know into platform has machine

00:11:55,069 --> 00:11:59,749
specific registers and you sometimes

00:11:56,749 --> 00:12:01,009
want to access them and when you are

00:11:59,749 --> 00:12:03,889
running in the virtual machine there is

00:12:01,009 --> 00:12:05,599
a bitmap which tells which MS are

00:12:03,889 --> 00:12:07,579
accesses you're interested in and which

00:12:05,599 --> 00:12:09,559
you are not when you are running nested

00:12:07,579 --> 00:12:12,079
it's the same story but now you have

00:12:09,559 --> 00:12:13,999
like two levels of it so this feature is

00:12:12,079 --> 00:12:17,149
basically again the same PV interface

00:12:13,999 --> 00:12:20,989
which tells level 0 hypervisor what was

00:12:17,149 --> 00:12:25,579
changed by l1 and using the feature you

00:12:20,989 --> 00:12:27,079
can make accesses to this Emma stars

00:12:25,579 --> 00:12:28,699
which are the most important and most

00:12:27,079 --> 00:12:30,979
stars which are being used when you

00:12:28,699 --> 00:12:34,639
switch between tasks basically between

00:12:30,979 --> 00:12:39,619
tasks and kernel you can use them via

00:12:34,639 --> 00:12:42,259
makes it less and say again a lot so the

00:12:39,619 --> 00:12:44,959
third feature when I talk about is apt

00:12:42,259 --> 00:12:46,999
invalidation and tianni is gonna talk

00:12:44,959 --> 00:12:50,119
about it hyper-v provides the two kind

00:12:46,999 --> 00:12:53,989
of would have accomplished

00:12:50,119 --> 00:12:56,899
you know EPT trps firstly Ernest sees

00:12:53,989 --> 00:12:59,539
how the general solution to flush it

00:12:56,899 --> 00:13:03,169
EPT are being the parameter in the

00:12:59,539 --> 00:13:05,299
nether virtualization environment in

00:13:03,169 --> 00:13:07,729
culture provides the English inventor

00:13:05,299 --> 00:13:09,019
impeaching instruction to flush the

00:13:07,729 --> 00:13:10,659
impurity trp

00:13:09,019 --> 00:13:15,429
but since an instruction needs to

00:13:10,659 --> 00:13:18,050
exclude the on the target cpu and

00:13:15,429 --> 00:13:20,869
actually accept

00:13:18,050 --> 00:13:24,889
EPT page table at the year flash unit

00:13:20,869 --> 00:13:28,879
that means M we want to flashes a remote

00:13:24,889 --> 00:13:33,499
to EPT GRB we need to change the IP I to

00:13:28,879 --> 00:13:36,199
the target CPU CPU that's well cause the

00:13:33,499 --> 00:13:38,929
air to get a running on the CPU we need

00:13:36,199 --> 00:13:42,649
full force so able to get their message

00:13:38,929 --> 00:13:46,040
and to switch back switch from energy to

00:13:42,649 --> 00:13:49,160
the l1 and then inject ipi and a well

00:13:46,040 --> 00:13:51,199
happy by the world you execute the

00:13:49,160 --> 00:13:54,170
invalid EPT instruction the instruction

00:13:51,199 --> 00:13:56,809
that emulated by the l0 hypervisor so as

00:13:54,170 --> 00:13:59,540
well trip back to the l0 happen again

00:13:56,809 --> 00:14:02,209
and finally I also wanna have a visor I

00:13:59,540 --> 00:14:05,029
need to know how to get again

00:14:02,209 --> 00:14:07,459
so as still needed to trap to back to l0

00:14:05,029 --> 00:14:11,290
happen again so your friends they are

00:14:07,459 --> 00:14:16,850
civil to jump between the air 1 & 0

00:14:11,290 --> 00:14:19,100
hypervisors and otherwise the test of

00:14:16,850 --> 00:14:22,759
the whole process will be repeated for

00:14:19,100 --> 00:14:25,610
the all that the effector cpu to reduce

00:14:22,759 --> 00:14:28,309
such kind of warheads

00:14:25,610 --> 00:14:30,559
happily provides the first course is

00:14:28,309 --> 00:14:34,610
called the flash guest physical address

00:14:30,559 --> 00:14:39,350
space have a call so hop call can help

00:14:34,610 --> 00:14:43,160
to the hypervisor to flash you if your

00:14:39,350 --> 00:14:45,819
your EPT trp without just you know one

00:14:43,160 --> 00:14:49,160
have a very involved involvement and

00:14:45,819 --> 00:14:52,459
this one single to hyper calkins will

00:14:49,160 --> 00:14:54,850
work for all the effectors appeal so

00:14:52,459 --> 00:15:01,819
just one we integer to flush all the

00:14:54,850 --> 00:15:04,639
attack CPUs so ii have cause the less

00:15:01,819 --> 00:15:08,449
the less near see how the net the EPT

00:15:04,639 --> 00:15:10,699
work first the target of nether ye e PG

00:15:08,449 --> 00:15:14,209
function as the chill translates the

00:15:10,699 --> 00:15:17,959
energy GPA to the the host physical

00:15:14,209 --> 00:15:19,999
adjust but normally the l0 to the

00:15:17,959 --> 00:15:22,339
hyper-violent have the mapping to map

00:15:19,999 --> 00:15:26,660
using the arrow to the ph of the air 1

00:15:22,339 --> 00:15:29,660
GPA so no need to shadows our ones

00:15:26,660 --> 00:15:31,320
EPT page tables how to share those the

00:15:29,660 --> 00:15:34,730
pivot table normally well

00:15:31,320 --> 00:15:37,019
the Rack Attack mode but the right

00:15:34,730 --> 00:15:39,149
technology introduces a lot of games

00:15:37,019 --> 00:15:42,750
into a from the only one hypervisor

00:15:39,149 --> 00:15:45,420
Chinese that the vegetable very

00:15:42,750 --> 00:15:50,639
recognized and finally s2 ninja tool

00:15:45,420 --> 00:15:53,250
uses a you know flash instruction so for

00:15:50,639 --> 00:15:55,860
such case the happy be provided as a

00:15:53,250 --> 00:15:59,040
second flash to have course because

00:15:55,860 --> 00:16:01,560
flash guest to address this have course

00:15:59,040 --> 00:16:06,300
so the hawk rocket except to the apt

00:16:01,560 --> 00:16:09,269
page table and the specific addressed as

00:16:06,300 --> 00:16:11,880
just range list that means L 1

00:16:09,269 --> 00:16:16,199
hypervisor can use the hypercar to tell

00:16:11,880 --> 00:16:19,680
what what has changed for the for the

00:16:16,199 --> 00:16:22,230
EPT page table in here once so that cam

00:16:19,680 --> 00:16:25,500
improves the flash efficiency and

00:16:22,230 --> 00:16:28,500
otherwise we we don't need to write the

00:16:25,500 --> 00:16:30,990
text air 1 the EPT page tables so that

00:16:28,500 --> 00:16:33,750
Candra reduce the VM pitch caused by the

00:16:30,990 --> 00:16:35,850
modification of air one apt page table

00:16:33,750 --> 00:16:40,170
okay that's the email

00:16:35,850 --> 00:16:43,170
EPG you know sectors next we also

00:16:40,170 --> 00:16:46,920
compare the data storage performance

00:16:43,170 --> 00:16:51,510
taters with provost in England feature

00:16:46,920 --> 00:16:54,060
and without the Tennyson so so yah to

00:16:51,510 --> 00:16:56,519
testing momentum we pass to the ambient

00:16:54,060 --> 00:16:59,459
me to the l1 guest and exposed

00:16:56,519 --> 00:17:03,060
amia me my own server trial Scotty from

00:16:59,459 --> 00:17:07,079
the a1 to the l2 and wrong FIO benchmark

00:17:03,060 --> 00:17:09,390
about 30 members against who compares

00:17:07,079 --> 00:17:14,339
the data to the when we use the version

00:17:09,390 --> 00:17:15,689
photo aging and version the 4015 in the

00:17:14,339 --> 00:17:21,600
air one guest

00:17:15,689 --> 00:17:24,689
so first so every juicer I want to

00:17:21,600 --> 00:17:27,540
provoke story performance to go up about

00:17:24,689 --> 00:17:30,179
still 17% in our testing environments

00:17:27,540 --> 00:17:30,630
most contributions come from the MS they

00:17:30,179 --> 00:17:34,679
are

00:17:30,630 --> 00:17:41,549
emulation and the VM rewrites emulations

00:17:34,679 --> 00:17:44,690
so msi access to job about 39% and with

00:17:41,549 --> 00:17:47,929
the enlightened mcs the

00:17:44,690 --> 00:17:51,499
very right well not to cause the

00:17:47,929 --> 00:17:58,039
immediate yeah okay thank you

00:17:51,499 --> 00:18:00,320
so now let's get to challenges direct

00:17:58,039 --> 00:18:05,210
ill be flush there is a feature in a

00:18:00,320 --> 00:18:08,330
hyper-v which allows level 0 hypervisor

00:18:05,210 --> 00:18:11,960
to be utilized by a level 2 to do it

00:18:08,330 --> 00:18:15,019
still be flushes because house our table

00:18:11,960 --> 00:18:17,419
our procedure done on int oh well if you

00:18:15,019 --> 00:18:20,539
want to do to be shut down on other CPUs

00:18:17,419 --> 00:18:22,220
you need to send IP is there the problem

00:18:20,539 --> 00:18:23,899
is that in virtualized environments you

00:18:22,220 --> 00:18:28,909
don't really know if this CPUs are

00:18:23,899 --> 00:18:33,019
running or not so it's more that when

00:18:28,909 --> 00:18:34,909
you are nesting because it may happen

00:18:33,019 --> 00:18:37,039
that there is some other level 2 guest

00:18:34,909 --> 00:18:38,840
or there is level one guest there you

00:18:37,039 --> 00:18:40,940
don't know but when you're doing till be

00:18:38,840 --> 00:18:42,529
shutdown you're sending IP is there and

00:18:40,940 --> 00:18:46,279
you're waiting for them to perform they

00:18:42,529 --> 00:18:50,570
should down so that's why we have PV

00:18:46,279 --> 00:18:53,029
Tilby or sedan for both like Linux and

00:18:50,570 --> 00:18:54,919
hardware we and Linux on KVM but what

00:18:53,029 --> 00:18:57,529
happens when you are running nested your

00:18:54,919 --> 00:18:59,269
level one hip hypervisor doesn't really

00:18:57,529 --> 00:19:01,580
know if the particularly CPU is

00:18:59,269 --> 00:19:04,489
currently being executed or not so it

00:19:01,580 --> 00:19:05,929
cannot really save much and hyper-v

00:19:04,489 --> 00:19:08,869
folks they came up with the idea that

00:19:05,929 --> 00:19:10,549
you can send the request directly to the

00:19:08,869 --> 00:19:13,119
level 0 which will perform the request

00:19:10,549 --> 00:19:20,720
for you it's great

00:19:13,119 --> 00:19:22,970
but we face like a problem there hyper

00:19:20,720 --> 00:19:27,529
cool conventions are very different

00:19:22,970 --> 00:19:31,129
between KVM and hyper-v in k vm we use

00:19:27,529 --> 00:19:33,739
these registers in hyper we'd reuse that

00:19:31,129 --> 00:19:35,989
so the thing is that we if we just

00:19:33,739 --> 00:19:39,259
enable the feature and try doing this

00:19:35,989 --> 00:19:43,220
then a couple of k vm hypercars which

00:19:39,259 --> 00:19:45,379
use like r6 for a parameter will be

00:19:43,220 --> 00:19:49,820
intercepted and executed a still be

00:19:45,379 --> 00:19:54,009
flush hyper calls yes so that's not

00:19:49,820 --> 00:19:58,300
gonna work so what are our options

00:19:54,009 --> 00:20:01,000
well we can fully disabled

00:19:58,300 --> 00:20:03,400
style Piper calls and KVM and only leave

00:20:01,000 --> 00:20:05,380
with Capri style hyper calls there we

00:20:03,400 --> 00:20:08,940
have them implemented for Windows

00:20:05,380 --> 00:20:15,430
running and KVM we can do that

00:20:08,940 --> 00:20:19,320
the second is we can probably not do

00:20:15,430 --> 00:20:21,970
anything right and don't use the picture

00:20:19,320 --> 00:20:25,090
may not be very good we can also ask

00:20:21,970 --> 00:20:27,220
Microsoft to make this their interface

00:20:25,090 --> 00:20:32,460
switchable to give me m style hyper

00:20:27,220 --> 00:20:35,950
calls weren't really successful so far

00:20:32,460 --> 00:20:38,020
so yeah for now the feature stays

00:20:35,950 --> 00:20:41,530
unimplemented just because of that right

00:20:38,020 --> 00:20:42,460
so we cannot enable with the current

00:20:41,530 --> 00:20:49,300
hypercolor

00:20:42,460 --> 00:20:51,900
ABI what else yeah so the more

00:20:49,300 --> 00:20:55,210
challengers for the next virtualization

00:20:51,900 --> 00:20:58,150
SVM's io performance too heavily

00:20:55,210 --> 00:21:02,170
supported and supported virtually

00:20:58,150 --> 00:21:05,500
supports so we cannot pass through the

00:21:02,170 --> 00:21:10,210
physical device from the l1 to the a or

00:21:05,500 --> 00:21:12,790
to an sides so faster posting drops

00:21:10,210 --> 00:21:16,570
cannot work with the next virtualization

00:21:12,790 --> 00:21:18,280
on the clear hyper-v that means even

00:21:16,570 --> 00:21:20,230
when she pass through the physical

00:21:18,280 --> 00:21:23,050
device to the l1 with data

00:21:20,230 --> 00:21:25,540
virtualization Nibelungs we are lost the

00:21:23,050 --> 00:21:28,780
posting to option so in 12 we were to

00:21:25,540 --> 00:21:33,160
arrive with hyper-v hypervisor first and

00:21:28,780 --> 00:21:36,610
the jump and inject to the l1 the your

00:21:33,160 --> 00:21:40,840
VM so that's where I introduced a lot of

00:21:36,610 --> 00:21:44,680
overhead to accounts such kind of

00:21:40,840 --> 00:21:48,730
challenges we in evaluate the us-based

00:21:44,680 --> 00:21:51,340
polling mode driver db2 K and s PDK to

00:21:48,730 --> 00:21:54,520
accelerate our performance for the nest

00:21:51,340 --> 00:21:56,950
vm divitiacus PDK

00:21:54,520 --> 00:22:00,550
first they used as no poly mode so it

00:21:56,950 --> 00:22:02,890
can reduce interrupt all head and as

00:22:00,550 --> 00:22:06,490
well uses the L to get the memory

00:22:02,890 --> 00:22:10,420
directly for the DMA trip EMA memory so

00:22:06,490 --> 00:22:11,660
the data can arrive dug able to get the

00:22:10,420 --> 00:22:15,620
memory with

00:22:11,660 --> 00:22:18,710
with sterile kabhi thank you

00:22:15,620 --> 00:22:21,380
so what are our plans

00:22:18,710 --> 00:22:25,310
I didn't where were a simple benchmark

00:22:21,380 --> 00:22:27,920
running tight cpuid loop in l2 when

00:22:25,310 --> 00:22:32,660
running hyper-v hyper-v and KVM on hyper

00:22:27,920 --> 00:22:36,110
with as you can see we're worse but not

00:22:32,660 --> 00:22:37,490
ten even like twenty percent so I was

00:22:36,110 --> 00:22:40,400
gonna take a look like what's going on

00:22:37,490 --> 00:22:45,980
and if it can be improved so we reach

00:22:40,400 --> 00:22:47,960
like parity with hyper-v hyper-v or the

00:22:45,980 --> 00:22:51,020
other thing is with the direct slash we

00:22:47,960 --> 00:22:55,310
can try to send an air of C like

00:22:51,020 --> 00:22:56,690
disabling KVM hyper : k vm not sure if k

00:22:55,310 --> 00:22:59,720
very maintenance will like such an

00:22:56,690 --> 00:23:01,850
approach that in some cases linux 1 k vm

00:22:59,720 --> 00:23:05,450
will leave hyper-v hypercolor

00:23:01,850 --> 00:23:07,820
exclusively we are also working on

00:23:05,450 --> 00:23:09,920
putting the same features the server

00:23:07,820 --> 00:23:12,470
side of the same features in k vm

00:23:09,920 --> 00:23:15,110
enabling hyper-v and KVM so when it's

00:23:12,470 --> 00:23:17,960
done we are going to enable testing

00:23:15,110 --> 00:23:20,630
we'll be able to do that so like in k vm

00:23:17,960 --> 00:23:23,630
unit tests will be able to run all the

00:23:20,630 --> 00:23:27,560
mix tests using enlightened vm c s for

00:23:23,630 --> 00:23:30,110
example and then there's to decay and DP

00:23:27,560 --> 00:23:32,020
decay work can you just mentioned and we

00:23:30,110 --> 00:23:34,700
also have a new version of hyper-v

00:23:32,020 --> 00:23:38,930
coming out soon so let's see what it

00:23:34,700 --> 00:23:44,800
brings us so thank you thank you Oh any

00:23:38,930 --> 00:23:44,800
questions yes

00:23:45,649 --> 00:23:51,000
in your comparison is 4:15 against 4:18

00:23:48,690 --> 00:23:52,740
the colonel's yeah do we need first of

00:23:51,000 --> 00:23:55,139
all either enable anything special to

00:23:52,740 --> 00:23:57,269
get it if you have 418 and or any user

00:23:55,139 --> 00:24:00,779
space components to make use of that no

00:23:57,269 --> 00:24:03,330
no it all works yes you can yeah if you

00:24:00,779 --> 00:24:05,370
run on hyper we KVM will detect the

00:24:03,330 --> 00:24:07,620
switches automatically we don't have any

00:24:05,370 --> 00:24:11,240
enablement in user space for them we

00:24:07,620 --> 00:24:14,899
don't require them happens automatically

00:24:11,240 --> 00:24:14,899
okay thank you very much

00:24:15,280 --> 00:24:23,619
[Applause]

00:24:17,840 --> 00:24:23,619

YouTube URL: https://www.youtube.com/watch?v=Fn7mQYObkvs


