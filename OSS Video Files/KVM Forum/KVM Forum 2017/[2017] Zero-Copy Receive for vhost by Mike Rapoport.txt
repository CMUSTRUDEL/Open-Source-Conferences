Title: [2017] Zero-Copy Receive for vhost by Mike Rapoport
Publication date: 2017-11-20
Playlist: KVM Forum 2017
Description: 
	In para-virtual networking with virtio-net/vhost, the copying of packet between the hypervisor and the guest is one of the major sources of the overhead, especially for the large packets. And, although, zero-copy transmit was merged into the Linux kernel a few years ago, the "receive side zero copy" item is still in the KVM NetworkingTodo.

This talk presents an approach to implementation of zero-copy receive for virtio-net and vhost that leverages receive-side steering abilities of the modern high speed network cards.

---

Mike Rapoport
IBM Research
Researcher

Mike has lots of programming experience in different areas ranging from medical equipment to visual simulation, but most of all he likes hacking on Linux kernel and low level stuff. Throughout his career Mike promoted use of free and open source software and made quite a few contributions to the Linux kernel. Now Mike works at IBM Research - Haifa focusing on containers and virtualization.

---

Note: Due to technical issues video recording was broken so there're parts with lower quality or completely missing video stream. There should be no problems with audio stream.
Captions: 
	00:00:00,390 --> 00:00:02,709
[Music]

00:00:06,200 --> 00:00:18,119
hello everybody I think it's all it's

00:00:12,210 --> 00:00:20,540
time to start so I'm a Mike Rappaport

00:00:18,119 --> 00:00:22,939
I'm working for IBM Research and

00:00:20,540 --> 00:00:25,410
[Applause]

00:00:22,939 --> 00:00:29,580
actually I'm presenting the work that

00:00:25,410 --> 00:00:31,920
has a person common who I actually work

00:00:29,580 --> 00:00:36,300
on this project but he couldn't arrive

00:00:31,920 --> 00:00:38,370
so I kind of volunteered to present and

00:00:36,300 --> 00:00:42,840
I'll be talking about implementation

00:00:38,370 --> 00:00:53,100
approach for zero copy received for

00:00:42,840 --> 00:00:56,100
virtual i/o so in any case when you're

00:00:53,100 --> 00:00:59,370
more generalized you're usually more

00:00:56,100 --> 00:01:04,229
slow so what happens with iron

00:00:59,370 --> 00:01:08,090
particularly in virtual IO as you move

00:01:04,229 --> 00:01:12,650
away from bare metal you get lower speed

00:01:08,090 --> 00:01:15,600
with the emulated device is like a

00:01:12,650 --> 00:01:17,670
thousand being the slowest possible

00:01:15,600 --> 00:01:24,630
implementation for virtual networking

00:01:17,670 --> 00:01:27,390
and having direct device assignment much

00:01:24,630 --> 00:01:30,600
closer to hardware but in this case you

00:01:27,390 --> 00:01:33,119
lose lots of flexibility and a pair of

00:01:30,600 --> 00:01:36,329
virtual int VM implementation we're

00:01:33,119 --> 00:01:38,219
timing in particular is sour between the

00:01:36,329 --> 00:01:42,450
emulator device and

00:01:38,219 --> 00:01:46,530
direct device assignment so we we are

00:01:42,450 --> 00:01:49,700
hoping to some coal bridge the gap

00:01:46,530 --> 00:01:54,929
between a direct device assignment and

00:01:49,700 --> 00:01:57,030
paravirtualized ending the zero copy

00:01:54,929 --> 00:01:59,929
parts in virtual i/o like ticks is all

00:01:57,030 --> 00:02:03,840
the available and so we are hoping to

00:01:59,929 --> 00:02:06,569
succeed with zero copy rx as well in

00:02:03,840 --> 00:02:13,260
this way reduce the amount of for former

00:02:06,569 --> 00:02:16,459
heads of review Chile introduces why why

00:02:13,260 --> 00:02:20,879
we just why you started this project

00:02:16,459 --> 00:02:23,310
well obviously if you don't copies much

00:02:20,879 --> 00:02:25,200
better than if you do coding so even if

00:02:23,310 --> 00:02:27,540
we don't get much improvement in

00:02:25,200 --> 00:02:32,069
throughput we will be able to use CPU

00:02:27,540 --> 00:02:34,349
cycles and the zero copy implementation

00:02:32,069 --> 00:02:37,290
in due to a liar is half complete

00:02:34,349 --> 00:02:40,230
because we only take 20 experts and we

00:02:37,290 --> 00:02:43,590
don't don't don't know how to do our X

00:02:40,230 --> 00:02:46,590
here and for us as researcher it was a

00:02:43,590 --> 00:02:48,230
challenging project and nobody tried to

00:02:46,590 --> 00:02:51,950
implement it for more than seven years

00:02:48,230 --> 00:03:01,079
since the last attempt was made so we

00:02:51,950 --> 00:03:04,230
kind of jumped on it was like taking an

00:03:01,079 --> 00:03:08,010
actual a machining self showing the

00:03:04,230 --> 00:03:10,590
thing four pockets larger than a 1k for

00:03:08,010 --> 00:03:13,200
instance most of the time spent on the

00:03:10,590 --> 00:03:17,099
rigs part on the rigs pass for which

00:03:13,200 --> 00:03:19,200
Alaia is in Pocket user actually it

00:03:17,099 --> 00:03:21,620
happens between the top device and

00:03:19,200 --> 00:03:21,620
community

00:03:23,670 --> 00:03:33,100
so why TX is wall time there and the

00:03:29,230 --> 00:03:39,120
arocs is not yet there are several

00:03:33,100 --> 00:03:44,230
things first of all for for the dig site

00:03:39,120 --> 00:03:48,370
when guest pushers say the packet data

00:03:44,230 --> 00:03:50,380
to the post sowards the level of top or

00:03:48,370 --> 00:03:51,850
market of devices is key B is created

00:03:50,380 --> 00:03:54,340
and from their networking networking

00:03:51,850 --> 00:03:56,070
part will manage to deliver the packet

00:03:54,340 --> 00:04:01,540
to the appropriate hardware device and

00:03:56,070 --> 00:04:05,290
so on to the actual network the memory

00:04:01,540 --> 00:04:09,220
part is pre-allocated and in snow at the

00:04:05,290 --> 00:04:11,950
time the transmission of ascii be starts

00:04:09,220 --> 00:04:15,220
and you can easily pin it the still go

00:04:11,950 --> 00:04:19,110
problems with nothing in it but as of

00:04:15,220 --> 00:04:24,970
now I think just two or three weeks ago

00:04:19,110 --> 00:04:28,060
there was a fight that thing as in ways

00:04:24,970 --> 00:04:30,940
it resolved the problem with saying head

00:04:28,060 --> 00:04:34,480
of line blocking by falling back to the

00:04:30,940 --> 00:04:38,710
copy mode for zero copy came for the

00:04:34,480 --> 00:04:43,000
Riggs part when the packet arrives the

00:04:38,710 --> 00:04:48,700
harbor mink driver doesn't know how it

00:04:43,000 --> 00:04:53,290
should be routed of the stick so you

00:04:48,700 --> 00:04:55,620
need some way to distinguish the package

00:04:53,290 --> 00:04:58,440
that come to a particular virtual link

00:04:55,620 --> 00:05:01,120
so they will be available only to that

00:04:58,440 --> 00:05:03,550
particular tunic and the rest of the

00:05:01,120 --> 00:05:07,240
packet which you use some other flows

00:05:03,550 --> 00:05:11,770
and in that way I not another problem is

00:05:07,240 --> 00:05:14,830
that you need the memory to D major so

00:05:11,770 --> 00:05:18,220
it should be the memories it will be

00:05:14,830 --> 00:05:21,850
visible to the guests and you either

00:05:18,220 --> 00:05:24,010
have to be made to normal memory normal

00:05:21,850 --> 00:05:24,889
pages allocated by the hardware driver

00:05:24,010 --> 00:05:28,280
and then

00:05:24,889 --> 00:05:29,930
that memory includes a guest all the

00:05:28,280 --> 00:05:34,189
other way around which he actually what

00:05:29,930 --> 00:05:38,449
we prefer to do is to be in the guest rx

00:05:34,189 --> 00:05:41,199
buffers and make the hardware t-rex

00:05:38,449 --> 00:05:47,810
descriptors point to those buffers and

00:05:41,199 --> 00:05:56,120
gate still doesn't exist so some

00:05:47,810 --> 00:06:00,949
overview of how bucket moves along the

00:05:56,120 --> 00:06:04,490
stick and for the future life days after

00:06:00,949 --> 00:06:06,889
its Damon after we do you make to the

00:06:04,490 --> 00:06:10,039
host memory allocated by the Ethernet

00:06:06,889 --> 00:06:11,330
adapter driver then in some way

00:06:10,039 --> 00:06:14,689
depending on the networking

00:06:11,330 --> 00:06:21,169
configuration is the end etc etc we gets

00:06:14,689 --> 00:06:23,719
into topo map feature drivers and this

00:06:21,169 --> 00:06:27,620
coordination with envy post which

00:06:23,719 --> 00:06:31,219
transferred to the built I ring and it

00:06:27,620 --> 00:06:35,060
is a shared by the kernel and the guest

00:06:31,219 --> 00:06:40,520
and at the guest site will tie on net

00:06:35,060 --> 00:06:42,740
driver receives the data and then the

00:06:40,520 --> 00:06:46,750
guest networking state operates on the

00:06:42,740 --> 00:06:46,750
data is on the dataset prophecy

00:06:47,560 --> 00:06:55,920
so in our porch we made several

00:06:51,229 --> 00:07:00,630
assumptions that seem to us

00:06:55,920 --> 00:07:04,020
the valid first of all more than a

00:07:00,630 --> 00:07:07,560
high-speed the Knicks have been a lot of

00:07:04,020 --> 00:07:12,390
fish a lot of kids and it should be

00:07:07,560 --> 00:07:17,660
possible to associate hardwood fuel

00:07:12,390 --> 00:07:20,460
using a beauty on networking devices I

00:07:17,660 --> 00:07:23,370
mean the second assumption we've made is

00:07:20,460 --> 00:07:27,540
that allocation is done by guest and the

00:07:23,370 --> 00:07:29,940
host only needs to pin receive buffer in

00:07:27,540 --> 00:07:34,320
memory so we want to swap the way or

00:07:29,940 --> 00:07:37,290
something like that and then and then we

00:07:34,320 --> 00:07:39,750
can just use the post-iraq swing to

00:07:37,290 --> 00:07:45,660
point to the buffers that were allocated

00:07:39,750 --> 00:07:48,690
by the guest and sensor is a there

00:07:45,660 --> 00:07:51,810
should be some one-to-one coupling

00:07:48,690 --> 00:07:55,650
between a virtual Nick and physical cue

00:07:51,810 --> 00:08:00,300
we restrict our implementation company

00:07:55,650 --> 00:08:01,920
only from our beta and frankly we don't

00:08:00,300 --> 00:08:09,780
know how to support generic table

00:08:01,920 --> 00:08:14,790
devices so the idea is the one gets

00:08:09,780 --> 00:08:18,300
allocates butters those buffers are

00:08:14,790 --> 00:08:22,170
pushed down the stack to the Ethernet

00:08:18,300 --> 00:08:27,930
adapter driver and the Ethernet adapter

00:08:22,170 --> 00:08:30,720
driver makes sure that the it's a Erik's

00:08:27,930 --> 00:08:35,280
a descriptor links point to those

00:08:30,720 --> 00:08:37,200
buffers so then when the packet arrives

00:08:35,280 --> 00:08:40,689
it will be made directly to the guest

00:08:37,200 --> 00:08:44,600
and then guests will be notified with

00:08:40,689 --> 00:08:50,179
so you're tiring that tinia there is new

00:08:44,600 --> 00:08:52,879
data to process so the buffers actually

00:08:50,179 --> 00:08:56,239
go through relatively long way until

00:08:52,879 --> 00:09:00,009
they reach in actually this actual new

00:08:56,239 --> 00:09:03,079
driver goes like you're Te'o

00:09:00,009 --> 00:09:06,230
Marquita schmuck villain and only Linda

00:09:03,079 --> 00:09:13,549
can they somehow have access to net

00:09:06,230 --> 00:09:20,329
device structure of the actual Nick so

00:09:13,549 --> 00:09:24,499
what we do we creating some filtering

00:09:20,329 --> 00:09:27,109
roots in the hardening driver to isolate

00:09:24,499 --> 00:09:30,879
set of cues in order to create one on

00:09:27,109 --> 00:09:34,429
one to one correspondence between qi

00:09:30,879 --> 00:09:38,809
physical cue and virtual networking

00:09:34,429 --> 00:09:42,040
device we clear the Eric's descriptor

00:09:38,809 --> 00:09:48,489
ring that was initially created with a

00:09:42,040 --> 00:09:51,589
normal let's say a driver path and we

00:09:48,489 --> 00:09:57,169
drop the buffers that were allocated for

00:09:51,589 --> 00:10:00,350
drivers are X so we can then push our

00:09:57,169 --> 00:10:05,899
guest allocated buffers to that Nick

00:10:00,350 --> 00:10:07,639
driver on the memory location part we

00:10:05,899 --> 00:10:15,319
assume again as we assume that guest

00:10:07,639 --> 00:10:17,899
allocates all the bottles in there is a

00:10:15,319 --> 00:10:21,550
routine entertainer driver that there

00:10:17,899 --> 00:10:24,010
are actually several that allocate

00:10:21,550 --> 00:10:27,010
memory for our expert we needed to

00:10:24,010 --> 00:10:32,080
extend and that yet another allocation

00:10:27,010 --> 00:10:35,440
routine because we needed a 4k aligned

00:10:32,080 --> 00:10:37,290
in 4k vigilant buffers and what your dad

00:10:35,440 --> 00:10:42,720
does now is

00:10:37,290 --> 00:10:42,720
unaligned buffer over the net frame size

00:10:42,750 --> 00:10:51,310
then after the bottles are located and

00:10:46,320 --> 00:10:57,940
preparing to point to them at the

00:10:51,310 --> 00:11:02,470
weakest part we transfer we we translate

00:10:57,940 --> 00:11:07,510
the view type descriptors to skb that

00:11:02,470 --> 00:11:13,769
will point to the same buffers and force

00:11:07,510 --> 00:11:18,880
that skb down to the physical driver and

00:11:13,769 --> 00:11:21,250
in the physical driver so when we when

00:11:18,880 --> 00:11:26,770
it when it's metaphor pushing escape

00:11:21,250 --> 00:11:29,940
this is called the Erikson erectus a

00:11:26,770 --> 00:11:35,050
descriptor ring is really initialized to

00:11:29,940 --> 00:11:40,450
properly set up the pointers when the

00:11:35,050 --> 00:11:44,620
packet arrives it is be made directly to

00:11:40,450 --> 00:11:47,050
the guest butters because they set up

00:11:44,620 --> 00:11:49,260
the next descriptor rink and the first

00:11:47,050 --> 00:11:49,260
step

00:11:49,310 --> 00:11:57,050
the SPP is usually Skippy's created and

00:11:54,410 --> 00:12:01,960
updated and set up this poker pointer

00:11:57,050 --> 00:12:05,870
and then we call a normal metaphoric so

00:12:01,960 --> 00:12:11,180
it's riveting to push the risky be filed

00:12:05,870 --> 00:12:15,440
after state eventually SPB arrives to

00:12:11,180 --> 00:12:21,260
marquita and then in mark beatab scandal

00:12:15,440 --> 00:12:23,450
or explained the queen is giving as is

00:12:21,260 --> 00:12:28,370
ready for the userspace 4% for further

00:12:23,450 --> 00:12:33,100
processing in because and you notify be

00:12:28,370 --> 00:12:33,100
cost about arrival of the new data

00:12:34,120 --> 00:12:46,700
because translating skb pointers to to

00:12:41,029 --> 00:12:50,450
you tearing these pictures and kicks

00:12:46,700 --> 00:12:53,390
again much data so that Marquita breed

00:12:50,450 --> 00:12:55,940
will be able to move transfer the

00:12:53,390 --> 00:12:59,710
father's father to tear and eventually

00:12:55,940 --> 00:12:59,710
to return and the translator get

00:13:02,690 --> 00:13:09,730
we've made a bit of API changes inside

00:13:06,800 --> 00:13:13,970
the kernel to implement this mechanism

00:13:09,730 --> 00:13:18,079
so what we are currently using we have a

00:13:13,970 --> 00:13:22,160
method for net device that performs the

00:13:18,079 --> 00:13:24,639
initial setup of the network driver we

00:13:22,160 --> 00:13:29,149
called it in the Oh Sergio cochlea Rex

00:13:24,639 --> 00:13:31,579
it's pretty much similar to the existing

00:13:29,149 --> 00:13:35,029
method doing a zip to initialize

00:13:31,579 --> 00:13:43,819
yourself to offloading I think it's in

00:13:35,029 --> 00:13:46,699
the oil to GW w something so the purpose

00:13:43,819 --> 00:13:49,310
of this method is to all implementers of

00:13:46,699 --> 00:13:52,790
hardware drivers to visit there are

00:13:49,310 --> 00:13:56,750
x-rayed and to set up receive site

00:13:52,790 --> 00:14:00,980
steering to create correspondence

00:13:56,750 --> 00:14:03,220
between hardware to to your tonic which

00:14:00,980 --> 00:14:06,230
is in this case will be presented by

00:14:03,220 --> 00:14:09,170
marquita Macmillan device which should

00:14:06,230 --> 00:14:11,630
be deathly and we've added another

00:14:09,170 --> 00:14:14,779
method to net definite device drug in

00:14:11,630 --> 00:14:18,170
sposta X backers which actually fold on

00:14:14,779 --> 00:14:21,589
the memory location path and they when

00:14:18,170 --> 00:14:24,290
your tire locates memory this method to

00:14:21,589 --> 00:14:28,880
allow us to push all the memory down to

00:14:24,290 --> 00:14:31,310
the carver device driver for mock

00:14:28,880 --> 00:14:36,110
beat-up it was kinda experimental we

00:14:31,310 --> 00:14:40,490
equated to control messages that that we

00:14:36,110 --> 00:14:46,010
are using one in Israel for posting the

00:14:40,490 --> 00:14:50,120
buffers on the allocation past so that

00:14:46,010 --> 00:14:51,950
we because net can send a these these

00:14:50,120 --> 00:14:57,710
control messages too much meat effective

00:14:51,950 --> 00:15:01,790
people will be able to push the buffers

00:14:57,710 --> 00:15:04,790
down to stay and they we've edited

00:15:01,790 --> 00:15:07,810
flagging and message pop is a message

00:15:04,790 --> 00:15:10,760
zero copy rx that indicates is that

00:15:07,810 --> 00:15:14,120
current package should be zero pulpit

00:15:10,760 --> 00:15:16,850
and there is no no need to call for

00:15:14,120 --> 00:15:20,500
coffee for you for coffee to user in

00:15:16,850 --> 00:15:20,500
order to transfer it to the user space

00:15:20,710 --> 00:15:28,250
and for the your tile net we needed to

00:15:24,680 --> 00:15:30,380
do routine that allocates 4k page

00:15:28,250 --> 00:15:37,820
aligned buffers so the memory will be

00:15:30,380 --> 00:15:40,940
disabled and probably we can just we can

00:15:37,820 --> 00:15:45,280
just extend existing allocation methods

00:15:40,940 --> 00:15:45,280
where real time networks in the future

00:15:46,990 --> 00:15:52,520
the issues we've identified during the

00:15:50,090 --> 00:15:56,990
implementation which is actually not yet

00:15:52,520 --> 00:16:00,200
complete that to implement their

00:15:56,990 --> 00:16:02,630
copyrights of your July oh you need to

00:16:00,200 --> 00:16:07,010
part each and every hardware to buy a

00:16:02,630 --> 00:16:09,230
new driver causing like internal drivers

00:16:07,010 --> 00:16:11,630
allocate memory in their way and vinyl

00:16:09,230 --> 00:16:14,960
nut drivers do it in another way and the

00:16:11,630 --> 00:16:17,690
Broadcom do it in a third way and there

00:16:14,960 --> 00:16:19,940
is no unified mechanism for locating a

00:16:17,690 --> 00:16:24,730
receive side memory in the networking

00:16:19,940 --> 00:16:28,690
step there was a project

00:16:24,730 --> 00:16:30,970
a redhead while the goals that we're

00:16:28,690 --> 00:16:33,610
trying to implement beach pool mechanism

00:16:30,970 --> 00:16:35,170
for locating the bridge poles for

00:16:33,610 --> 00:16:37,209
networking device drivers and then

00:16:35,170 --> 00:16:40,589
converting all the networking device

00:16:37,209 --> 00:16:43,510
drivers to use a page book maybe we can

00:16:40,589 --> 00:16:45,190
give when it will be implemented we can

00:16:43,510 --> 00:16:46,959
use the same you can easily just provide

00:16:45,190 --> 00:16:51,130
the different back-end for the page for

00:16:46,959 --> 00:16:54,850
implementation with the people the next

00:16:51,130 --> 00:16:57,010
question is what should we do when the

00:16:54,850 --> 00:17:02,470
buffers are allocated to the guests I'd

00:16:57,010 --> 00:17:05,589
already finished and the there are still

00:17:02,470 --> 00:17:09,040
new packets coming into the from the

00:17:05,589 --> 00:17:12,040
network so there are we see at least two

00:17:09,040 --> 00:17:13,809
possibilities one is just drop and

00:17:12,040 --> 00:17:15,370
another possibility is the

00:17:13,809 --> 00:17:18,939
implementation of some fallback

00:17:15,370 --> 00:17:21,189
mechanism to the copy method but that

00:17:18,939 --> 00:17:27,010
reads another complexity because of

00:17:21,189 --> 00:17:30,160
we're ordering between the ordering

00:17:27,010 --> 00:17:32,080
inside will turn your ring for packets

00:17:30,160 --> 00:17:36,669
it was there is zero competent that were

00:17:32,080 --> 00:17:43,059
copied using the normal copy and we

00:17:36,669 --> 00:17:45,610
don't know yet how to tackle it another

00:17:43,059 --> 00:17:50,020
problem we've seen is pretty much

00:17:45,610 --> 00:17:52,929
related to 4k is that we had to turn on

00:17:50,020 --> 00:17:55,860
gyro for initial implementation because

00:17:52,929 --> 00:17:59,740
we denote packets

00:17:55,860 --> 00:18:02,049
data lives at some offsets relatively to

00:17:59,740 --> 00:18:05,110
the beginning of the page and you're

00:18:02,049 --> 00:18:07,929
tiring at the moment cannot handle as I

00:18:05,110 --> 00:18:13,210
think it presumes that all the segment

00:18:07,929 --> 00:18:15,669
data is is continuous in memory just

00:18:13,210 --> 00:18:18,000
pointed by different descriptors so

00:18:15,669 --> 00:18:20,620
there should be some money

00:18:18,000 --> 00:18:23,320
mechanism that allows extend your tie

00:18:20,620 --> 00:18:30,299
protocol to handle something like the

00:18:23,320 --> 00:18:33,720
page offset of fragment in escaping and

00:18:30,299 --> 00:18:37,539
again allocation of 4k of each size and

00:18:33,720 --> 00:18:40,659
buffers is a bit wasteful especially on

00:18:37,539 --> 00:18:45,700
architectures that do not use 4k pages

00:18:40,659 --> 00:18:47,970
like some arm 64 chips and power of

00:18:45,700 --> 00:18:47,970
course

00:18:51,180 --> 00:18:56,790
so as as of now the implementation is

00:18:54,630 --> 00:18:58,830
pretty much proof of concept it

00:18:56,790 --> 00:19:00,510
progresses much slower than we expected

00:18:58,830 --> 00:19:02,100
at the beginning so when we submitted

00:19:00,510 --> 00:19:05,400
the abstract for the stop we really hope

00:19:02,100 --> 00:19:08,220
to show real numbers and we whoa we all

00:19:05,400 --> 00:19:08,640
perform like 20 percent it doesn't

00:19:08,220 --> 00:19:11,190
matter

00:19:08,640 --> 00:19:14,550
hey we still can't outperform anything

00:19:11,190 --> 00:19:17,040
because the best we can do is up to one

00:19:14,550 --> 00:19:20,809
second to a live network session and

00:19:17,040 --> 00:19:24,090
then they just everything crashes so

00:19:20,809 --> 00:19:27,660
it's it's working progress and we hope

00:19:24,090 --> 00:19:29,160
to finish it some some time zone and

00:19:27,660 --> 00:19:34,610
then this happen to see how we're going

00:19:29,160 --> 00:19:42,559
to upstream or the whole thing and I

00:19:34,610 --> 00:19:42,559
believe this all more questions

00:19:46,470 --> 00:19:58,020
how long does it what we've been talking

00:19:53,880 --> 00:20:00,090
about it for like year and a half but we

00:19:58,020 --> 00:20:10,200
started we really started to work on it

00:20:00,090 --> 00:20:12,120
it's the end of spring still most of the

00:20:10,200 --> 00:20:15,500
number timers are switching away from

00:20:12,120 --> 00:20:15,500
allocated SBB

00:20:42,790 --> 00:20:49,100
we considered even skb but I'm not

00:20:47,270 --> 00:20:50,990
really an expert not even to be retired

00:20:49,100 --> 00:20:54,740
on networking but I've talked with

00:20:50,990 --> 00:21:03,170
Jasper and he said that most probably

00:20:54,740 --> 00:21:06,050
Skippy want to tell xk p XD people the

00:21:03,170 --> 00:21:13,220
problem the problem is that XD p will

00:21:06,050 --> 00:21:16,750
run after you DMA when I met with run

00:21:13,220 --> 00:21:20,350
txt me open it would decide whether to

00:21:16,750 --> 00:21:20,350
run another hook

00:21:39,870 --> 00:21:46,030
okay in that case yes but just using the

00:21:43,450 --> 00:21:46,540
XD pickle container weeks early at our

00:21:46,030 --> 00:22:07,059
exit

00:21:46,540 --> 00:22:15,400
there is no early look at college right

00:22:07,059 --> 00:22:17,559
the policy there to talk to this now

00:22:15,400 --> 00:22:20,460
there's a certain security race in terms

00:22:17,559 --> 00:22:20,460
of check

00:22:26,809 --> 00:22:32,330
- the desk guest you never see it other

00:22:30,389 --> 00:22:36,740
words we're trying to protect the guests

00:22:32,330 --> 00:22:36,740
from getting boss attack

00:22:39,050 --> 00:22:43,340
the second case were you

00:22:51,890 --> 00:22:56,660
seven probably we can do some marriage

00:22:54,770 --> 00:22:58,400
between the two approaches and do the

00:22:56,660 --> 00:23:00,740
location and guess and propagate all the

00:22:58,400 --> 00:23:02,420
memory down on the stack and then to run

00:23:00,740 --> 00:23:04,549
some excuse me hooks at the very

00:23:02,420 --> 00:23:07,370
beginning of the processing but still

00:23:04,549 --> 00:23:09,799
the the D maze goes to directly to the

00:23:07,370 --> 00:23:30,080
guest memory but you can clear it to fix

00:23:09,799 --> 00:23:33,200
typical says no more questions at IBM we

00:23:30,080 --> 00:23:35,900
need to well since we need to do all the

00:23:33,200 --> 00:23:36,500
legal stuff before pushing it to to the

00:23:35,900 --> 00:23:38,540
public

00:23:36,500 --> 00:23:51,919
we prefer film for us to finish what we

00:23:38,540 --> 00:23:55,640
have and don't do it twice probably but

00:23:51,919 --> 00:23:59,770
we hope that the dead stage we can kind

00:23:55,640 --> 00:23:59,770
of oeid the second legal review

00:24:07,330 --> 00:24:10,330
operations

00:24:13,330 --> 00:24:16,320
thank you everybody

00:24:19,250 --> 00:24:25,710
[Applause]

00:24:19,840 --> 00:24:25,710

YouTube URL: https://www.youtube.com/watch?v=szA5h7od634


