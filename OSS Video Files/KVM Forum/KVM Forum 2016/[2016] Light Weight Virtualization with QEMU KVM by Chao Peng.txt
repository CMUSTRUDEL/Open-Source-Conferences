Title: [2016] Light Weight Virtualization with QEMU KVM by Chao Peng
Publication date: 2016-09-13
Playlist: KVM Forum 2016
Description: 
	Comparing to traditional full-blown VM based virtualization,light weight virtualization like Linux container boots much faster and runs more efficiently.But it also has drawback:the software-level isolation makes it not as secure as traditional hardware-enforced hypervisor.In this talk Anthony/Chao will share their work on tailoring and improving the traditional hypervisor to run a light weight VM, to gain both performance and scalability, while at the same time maintaining hardware-based isolation. Specifically, you will see how the open-source and industry-proven QEMU/KVM can be optimized to achieve near native container performance/scalability (e.g. fast boot and small memory footprint). Firstly,you will see how QEMU boot time can be shortened from ~300ms to ~50ms. Secondly, you will also see how these improvements be used in the related projects like Intel Clear Container and Docker.


Chao Peng
Sr. Software Engineer, Intel

Chao is a senior software engineer from Intel and his job content includes hardware virtualization feature enabling for open source hypervisors like KVM/Xen, as well as the performance tuning for virtualization and cloud products. Recently he focuses on light-weight virtualization solutions like Linux container and try to improve the security of container using hardware isolation technologies.

Slides: http://www.linux-kvm.org/images/d/d2/03x05B-Chao_Peng-Light_Weight_Virtualization_with_QEMU_KVM.pdf
Captions: 
	00:00:09,860 --> 00:00:15,719
good afternoon everyone my name is Hong

00:00:12,840 --> 00:00:18,330
Jong today I will present to walk on the

00:00:15,719 --> 00:00:23,760
light wastewater ization with kiri kiri

00:00:18,330 --> 00:00:27,990
me and p.m. i I present on behalf of

00:00:23,760 --> 00:00:31,769
chalk who cannot make his tribal here so

00:00:27,990 --> 00:00:34,440
first I will introduce the background

00:00:31,769 --> 00:00:38,129
and motivation of this project and then

00:00:34,440 --> 00:00:40,890
I will go to the TV optimization we made

00:00:38,129 --> 00:00:43,680
for the long Steinman memory footprint

00:00:40,890 --> 00:00:47,600
and then I will talk something about the

00:00:43,680 --> 00:00:51,899
integration visa with some production

00:00:47,600 --> 00:00:55,800
the Intel tender and then it's about

00:00:51,899 --> 00:00:58,649
something about a effort to make make a

00:00:55,800 --> 00:01:01,469
walk upstream and and the final I will

00:00:58,649 --> 00:01:06,990
summarized by the commentators and some

00:01:01,469 --> 00:01:11,299
toodles firstly that container on linux

00:01:06,990 --> 00:01:14,939
nowadays are very popular and and it's

00:01:11,299 --> 00:01:17,580
actually replaced the tradition the

00:01:14,939 --> 00:01:20,369
traditional authorization in lots of

00:01:17,580 --> 00:01:23,090
areas because compelled to the

00:01:20,369 --> 00:01:28,590
traditional authorization the container

00:01:23,090 --> 00:01:32,820
tests are much faster can consume less

00:01:28,590 --> 00:01:35,610
memory so it can so so with container

00:01:32,820 --> 00:01:38,180
you can get much higher test days and

00:01:35,610 --> 00:01:45,350
the traditional polarization and

00:01:38,180 --> 00:01:49,009
intuition some container some contender

00:01:45,350 --> 00:01:51,750
like docker our rockets and provide some

00:01:49,009 --> 00:01:56,549
convenient way to let you deployment to

00:01:51,750 --> 00:01:58,680
their applications but but however the

00:01:56,549 --> 00:02:02,570
contender country has one problem is

00:01:58,680 --> 00:02:05,490
that his country relies on the software

00:02:02,570 --> 00:02:10,349
isolation to escalate it and our instant

00:02:05,490 --> 00:02:12,829
from each other so it can be considered

00:02:10,349 --> 00:02:15,629
as less security

00:02:12,829 --> 00:02:18,510
as a traditional weatherization which

00:02:15,629 --> 00:02:20,219
use the hardware water ization here the

00:02:18,510 --> 00:02:25,379
knowledge is - do they have the

00:02:20,219 --> 00:02:28,709
isolation so in order to guarantee the

00:02:25,379 --> 00:02:32,670
security of the container an intuitive

00:02:28,709 --> 00:02:35,700
idea is to run the container in the in

00:02:32,670 --> 00:02:38,819
the traditional voting machine but then

00:02:35,700 --> 00:02:44,400
you just lose all the benefits of the

00:02:38,819 --> 00:02:48,780
container so so they propose a life line

00:02:44,400 --> 00:02:52,829
of its water ization that is that is we

00:02:48,780 --> 00:02:57,689
may we may make some optimization to the

00:02:52,829 --> 00:03:00,919
current hypervisor software stack to

00:02:57,689 --> 00:03:04,819
meet it to make it much lighter for the

00:03:00,919 --> 00:03:09,540
for the container like applications and

00:03:04,819 --> 00:03:11,669
that is our purchased cumulate it struct

00:03:09,540 --> 00:03:13,730
for the container rocket uses scenarios

00:03:11,669 --> 00:03:17,099
and the currently is specifically

00:03:13,730 --> 00:03:20,489
optimized for the lunchtime and the and

00:03:17,099 --> 00:03:24,870
and the memory footprint for the

00:03:20,489 --> 00:03:26,819
lunchtime we currently can reduce long

00:03:24,870 --> 00:03:28,829
child and can reduce the long time of

00:03:26,819 --> 00:03:33,329
one whatamachine from more than by

00:03:28,829 --> 00:03:35,209
second to just two justice Rees three

00:03:33,329 --> 00:03:38,340
hundred and thirty five milliseconds and

00:03:35,209 --> 00:03:40,799
also it's currently that human eye the

00:03:38,340 --> 00:03:44,190
currently integrated with inhale clear

00:03:40,799 --> 00:03:46,979
container so it's so it can use the talk

00:03:44,190 --> 00:03:50,970
like engine in the in health clear

00:03:46,979 --> 00:03:55,439
container to deploy to to get convenient

00:03:50,970 --> 00:03:58,560
deployment so that is a background and

00:03:55,439 --> 00:04:03,799
and and then I will go through of some

00:03:58,560 --> 00:04:06,310
optimizations we made force is about the

00:04:03,799 --> 00:04:11,830
optimization on the

00:04:06,310 --> 00:04:14,530
I am long Stein the baseline of this the

00:04:11,830 --> 00:04:16,299
Pacer of this walk is a either be

00:04:14,530 --> 00:04:20,080
married

00:04:16,299 --> 00:04:26,290
the p.m. last time cube under a modified

00:04:20,080 --> 00:04:30,400
qmu 2.6 the VM is the VM the VM we use

00:04:26,290 --> 00:04:34,840
has six what every CPUs what CPU bank

00:04:30,400 --> 00:04:38,470
expand memory and it's the guest corner

00:04:34,840 --> 00:04:41,590
is loaded while the accumulation -

00:04:38,470 --> 00:04:45,330
colonel and the dual file system is put

00:04:41,590 --> 00:04:49,390
on water I'll block device and we do not

00:04:45,330 --> 00:04:52,300
assign any network to eight and the

00:04:49,390 --> 00:04:54,880
baseline is at and and and the lunch

00:04:52,300 --> 00:04:57,670
time is Mary from the from the very

00:04:54,880 --> 00:05:00,250
beginning of the of the start of the Q

00:04:57,670 --> 00:05:03,880
mu to the end to the moment that the

00:05:00,250 --> 00:05:04,990
guest user space finish all

00:05:03,880 --> 00:05:08,410
initializations

00:05:04,990 --> 00:05:13,110
and and and and the baseline time in

00:05:08,410 --> 00:05:17,830
that is twelve hundred and sixty sixty

00:05:13,110 --> 00:05:22,810
seventy six milliseconds the first

00:05:17,830 --> 00:05:25,990
optimization we do is that we try to we

00:05:22,810 --> 00:05:29,280
try we try some optimization that the

00:05:25,990 --> 00:05:33,669
data that does not need to modify q mu

00:05:29,280 --> 00:05:37,000
and the gas kernel the force bang is

00:05:33,669 --> 00:05:40,240
that we try to disable some QM you

00:05:37,000 --> 00:05:43,000
features and some devices emulated by Q

00:05:40,240 --> 00:05:47,860
as a compile time and by this

00:05:43,000 --> 00:05:55,360
optimization we can reduce the reduce ik

00:05:47,860 --> 00:05:59,440
q mobile time by eleven milliseconds and

00:05:55,360 --> 00:06:04,060
also we customize the guest cannot put a

00:05:59,440 --> 00:06:06,850
parameters to to use them total as a the

00:06:04,060 --> 00:06:09,550
guest cannot use some use some messages

00:06:06,850 --> 00:06:13,150
that has a lower light

00:06:09,550 --> 00:06:16,700
latency and and and allow the guests

00:06:13,150 --> 00:06:22,610
cannot to to not

00:06:16,700 --> 00:06:25,190
enumerators some some some devices by

00:06:22,610 --> 00:06:31,520
this optimization the castable time can

00:06:25,190 --> 00:06:35,990
be reduced by eating percent and then we

00:06:31,520 --> 00:06:39,530
try to make some general optimization on

00:06:35,990 --> 00:06:43,070
the cube by general optimization I mean

00:06:39,530 --> 00:06:48,500
those open of optimization can also

00:06:43,070 --> 00:06:51,520
apply to other VM yudhisthira's is an

00:06:48,500 --> 00:06:54,620
area not limited to the container like

00:06:51,520 --> 00:06:56,300
applications the fourth point is that we

00:06:54,620 --> 00:07:00,730
found that during the human

00:06:56,300 --> 00:07:03,710
initialization it will call the this kbm

00:07:00,730 --> 00:07:08,560
it will call this came in LCD able to

00:07:03,710 --> 00:07:11,750
get the information of the CPI D for

00:07:08,560 --> 00:07:14,630
4000 downtime and and well only the

00:07:11,750 --> 00:07:18,050
foster call really get some some

00:07:14,630 --> 00:07:21,560
variable information and all the foreign

00:07:18,050 --> 00:07:24,560
calls just just gets a exactly the same

00:07:21,560 --> 00:07:26,390
same results so we think that so we

00:07:24,560 --> 00:07:29,150
think that why why why couldn't we just

00:07:26,390 --> 00:07:32,000
the capture of fosters character for

00:07:29,150 --> 00:07:34,940
score and the less and replace the

00:07:32,000 --> 00:07:37,130
foreign cop to analyze the foreign code

00:07:34,940 --> 00:07:40,220
to just the reads reread the cached

00:07:37,130 --> 00:07:42,200
value so we made a survey made such we

00:07:40,220 --> 00:07:46,010
made a patch through this and by this

00:07:42,200 --> 00:07:49,490
and and by this patch we can reduce the

00:07:46,010 --> 00:07:51,680
cube the cube maple time significantly

00:07:49,490 --> 00:07:54,860
from more than 200 milliseconds with

00:07:51,680 --> 00:07:58,220
Justin 20 milliseconds and and and the

00:07:54,860 --> 00:08:01,010
sector optimization we made is try to

00:07:58,220 --> 00:08:03,170
paralyze the basic inner ization

00:08:01,010 --> 00:08:07,010
currently in qumu all the ways if you

00:08:03,170 --> 00:08:09,560
are initialized one by one and and we

00:08:07,010 --> 00:08:12,460
just try to make them make major

00:08:09,560 --> 00:08:15,790
analyzation imperiling in parallel and

00:08:12,460 --> 00:08:19,940
currently this optimization is still

00:08:15,790 --> 00:08:23,480
it's not very stable because because

00:08:19,940 --> 00:08:24,890
because the qmu at least was further

00:08:23,480 --> 00:08:27,200
further for the visible in the

00:08:24,890 --> 00:08:33,650
transition color is not some

00:08:27,200 --> 00:08:36,380
it's not it was not implemented very

00:08:33,650 --> 00:08:39,640
that was implement isn't it it didn't

00:08:36,380 --> 00:08:45,440
conceal much water for the concurrency

00:08:39,640 --> 00:08:50,180
but but but in in some uncrushed the

00:08:45,440 --> 00:08:53,270
best market we have observed the creamy

00:08:50,180 --> 00:08:58,930
boot time we have observed the reduction

00:08:53,270 --> 00:09:02,930
of the chemical time by almost 50% and

00:08:58,930 --> 00:09:07,220
then we made some some specific

00:09:02,930 --> 00:09:10,550
optimizations for the content usage for

00:09:07,220 --> 00:09:14,150
most content of applications we actually

00:09:10,550 --> 00:09:19,670
to not need so much devices and features

00:09:14,150 --> 00:09:21,650
so raising so so we just made made a new

00:09:19,670 --> 00:09:24,620
machine type called PC light which only

00:09:21,650 --> 00:09:27,410
provides a very minimal side all devices

00:09:24,620 --> 00:09:33,710
that is just enough to put the cat Linux

00:09:27,410 --> 00:09:37,460
and and launch the the the container

00:09:33,710 --> 00:09:41,990
applications in this in this new machine

00:09:37,460 --> 00:09:44,750
type we we use a peg 44 the interrupt

00:09:41,990 --> 00:09:48,490
controller and the what are you console

00:09:44,750 --> 00:09:52,310
as a console console and we only

00:09:48,490 --> 00:09:55,460
implement a very simple PCI host and we

00:09:52,310 --> 00:09:58,820
do not provide provide any starter

00:09:55,460 --> 00:10:02,780
devices instead we use only team to host

00:09:58,820 --> 00:10:06,650
a to host the guest this image this

00:10:02,780 --> 00:10:10,070
image by by this optimization the casted

00:10:06,650 --> 00:10:13,460
the casted software does not need to in

00:10:10,070 --> 00:10:17,420
a new enumerator and a set up so many

00:10:13,460 --> 00:10:23,600
devices so so we can reduce the the

00:10:17,420 --> 00:10:25,120
castable time significantly and there

00:10:23,600 --> 00:10:29,540
are there are also some other

00:10:25,120 --> 00:10:32,840
optimization one is then we used very

00:10:29,540 --> 00:10:35,350
team devices to host our cast destroy

00:10:32,840 --> 00:10:38,649
the reason that we use

00:10:35,350 --> 00:10:42,130
the reason we use only demon is that we

00:10:38,649 --> 00:10:45,519
want to use the X feature that is the TX

00:10:42,130 --> 00:10:49,600
is is a so-called direct access

00:10:45,519 --> 00:10:54,970
technology with TX the cast of the guest

00:10:49,600 --> 00:11:00,220
can can avoid quite a lot pitch caches

00:10:54,970 --> 00:11:03,850
in the in the block layer so so that so

00:11:00,220 --> 00:11:11,769
that so that the IO IO latency in a

00:11:03,850 --> 00:11:14,199
guest can be reduced and this can be and

00:11:11,769 --> 00:11:17,829
and the benefit can be seen from the

00:11:14,199 --> 00:11:20,380
reduction of the castable time and the

00:11:17,829 --> 00:11:23,529
most aggressive optimization we made is

00:11:20,380 --> 00:11:26,259
that we completely remove the cast of

00:11:23,529 --> 00:11:30,610
form well which including the cast of

00:11:26,259 --> 00:11:33,190
piles and and and the cast link again

00:11:30,610 --> 00:11:34,509
casts the option norm that is Linux

00:11:33,190 --> 00:11:37,540
fault

00:11:34,509 --> 00:11:40,839
the reason that we do that is a very we

00:11:37,540 --> 00:11:42,790
found the castle for mail just just

00:11:40,839 --> 00:11:46,449
consume too much time

00:11:42,790 --> 00:11:49,029
it's almost 50% of the of the total

00:11:46,449 --> 00:11:54,190
lunch time so we think so we just can

00:11:49,029 --> 00:11:57,310
see the Y can can we can we remove it so

00:11:54,190 --> 00:11:59,410
they also remove it so we move some we

00:11:57,310 --> 00:12:02,800
move some walk that such that histories

00:11:59,410 --> 00:12:05,769
you know down by the best guess for mail

00:12:02,800 --> 00:12:09,459
to the QM use such as search such as a

00:12:05,769 --> 00:12:13,630
paging of the gases API and and the load

00:12:09,459 --> 00:12:16,899
of the cast EFL kernel and with these

00:12:13,630 --> 00:12:20,350
optimizations we can totally remove the

00:12:16,899 --> 00:12:24,939
control removes that more than 50

00:12:20,350 --> 00:12:27,639
minutes 500 milliseconds of the gas from

00:12:24,939 --> 00:12:33,160
wearable time and the gas kernel can be

00:12:27,639 --> 00:12:36,130
posed much faster as well so by all

00:12:33,160 --> 00:12:43,199
these optimizations we finally would use

00:12:36,130 --> 00:12:48,980
the total BAM long time by 74%

00:12:43,199 --> 00:12:52,920
and if you are interested in the benefit

00:12:48,980 --> 00:12:59,730
from each optimization you can you can

00:12:52,920 --> 00:13:03,089
see them on this diagram so this is this

00:12:59,730 --> 00:13:07,230
this is our current optimization of the

00:13:03,089 --> 00:13:11,970
very lunchtime also and the next part of

00:13:07,230 --> 00:13:14,100
the optimization we are we're still they

00:13:11,970 --> 00:13:16,109
are still doing is is above the memory

00:13:14,100 --> 00:13:20,029
footprint currently we have done we

00:13:16,109 --> 00:13:24,299
haven't done much about that so the

00:13:20,029 --> 00:13:29,040
result is not as impressive as a a as

00:13:24,299 --> 00:13:32,369
the is a reduction on the vm long time

00:13:29,040 --> 00:13:39,179
currently country accumulate consume

00:13:32,369 --> 00:13:43,610
only 8 percent 80 percent of the of the

00:13:39,179 --> 00:13:46,370
vanilla Qumu and but it's still much

00:13:43,610 --> 00:13:48,920
much larger than the KVM to which he

00:13:46,370 --> 00:13:51,920
which is another light way which another

00:13:48,920 --> 00:13:54,680
lightweight device emulator our

00:13:51,920 --> 00:13:59,930
long-term goal is to reduce the memory

00:13:54,680 --> 00:14:05,410
footprint of qumu to the same label f as

00:13:59,930 --> 00:14:10,240
kb m to so that we can get get higher

00:14:05,410 --> 00:14:15,050
density of the of the voting machines

00:14:10,240 --> 00:14:17,900
and here is some optimization we have

00:14:15,050 --> 00:14:21,170
done we have done and this too and we

00:14:17,900 --> 00:14:24,680
are doing and we have and we are going

00:14:21,170 --> 00:14:27,830
to do the first bung is KSM this is the

00:14:24,680 --> 00:14:31,840
most obvious one that can be used to

00:14:27,830 --> 00:14:34,520
reduce reduce the memory footprint of

00:14:31,840 --> 00:14:37,640
multiple whatamachine especially when

00:14:34,520 --> 00:14:41,570
soda bottle machine use use a same

00:14:37,640 --> 00:14:45,880
kernel and and similar user space

00:14:41,570 --> 00:14:50,530
applications and the second one is that

00:14:45,880 --> 00:14:54,740
in cumulous we remove the lots of

00:14:50,530 --> 00:14:57,530
unnecessary devices and so the memory

00:14:54,740 --> 00:15:02,240
consumption by consume the pile q mr it

00:14:57,530 --> 00:15:05,480
also reduced and one optimization we're

00:15:02,240 --> 00:15:10,640
currently doing is that we've we found

00:15:05,480 --> 00:15:14,650
that some wrong in in q is actively

00:15:10,640 --> 00:15:17,840
shared between host and guest but but I

00:15:14,650 --> 00:15:22,340
mean I mean I mean I mean for those

00:15:17,840 --> 00:15:25,190
wrong the Q mu the Q mu has a copy on

00:15:22,340 --> 00:15:29,420
the Q side but the guest also has

00:15:25,190 --> 00:15:31,400
another copy on the right side so we for

00:15:29,420 --> 00:15:34,730
for example for example for example

00:15:31,400 --> 00:15:38,030
incurring human life we use a - Colonel

00:15:34,730 --> 00:15:41,600
option - too low the guest kernel and

00:15:38,030 --> 00:15:45,710
the Q mu we will create a ROM for that

00:15:41,600 --> 00:15:48,740
code for that kernels always in and and

00:15:45,710 --> 00:15:52,550
and and and for the gasta its own it

00:15:48,740 --> 00:15:55,190
it may modify that could that's Colonel

00:15:52,550 --> 00:15:58,940
but but but but among of the

00:15:55,190 --> 00:16:02,690
modification is really very small so we

00:15:58,940 --> 00:16:06,800
sing while we think can we can we share

00:16:02,690 --> 00:16:09,740
this room in a copy on right away so

00:16:06,800 --> 00:16:12,820
that we can reduce the duplicated hosts

00:16:09,740 --> 00:16:15,880
and guests copies of those rooms and

00:16:12,820 --> 00:16:18,920
another one and there are two

00:16:15,880 --> 00:16:22,400
optimization we are still investigating

00:16:18,920 --> 00:16:25,730
one is that one is a positive memory

00:16:22,400 --> 00:16:29,840
bitmap we found that we found that

00:16:25,730 --> 00:16:35,060
memory p-type is used only only as a

00:16:29,840 --> 00:16:39,490
moment of the of the migration so is so

00:16:35,060 --> 00:16:42,380
we we are we are thinking could we 84

00:16:39,490 --> 00:16:45,290
before the creation of the memory of the

00:16:42,380 --> 00:16:50,990
30 memory pit map to the moment of the

00:16:45,290 --> 00:16:55,190
of the migration so so that we can say

00:16:50,990 --> 00:16:59,150
quite a loss a lost memory and another

00:16:55,190 --> 00:17:03,080
one is VM full of them clone a recently

00:16:59,150 --> 00:17:09,110
there is a patch in the a patch service

00:17:03,080 --> 00:17:12,410
in the cumulus from hyper is is about

00:17:09,110 --> 00:17:17,420
this vamp full of em chrome in VM for

00:17:12,410 --> 00:17:20,630
nvm clone the one you are a you you

00:17:17,420 --> 00:17:24,880
first start so called template what

00:17:20,630 --> 00:17:29,570
emerging and then you you you you

00:17:24,880 --> 00:17:33,020
you a clone that the template what

00:17:29,570 --> 00:17:34,850
emotion into multiple into multiple

00:17:33,020 --> 00:17:37,130
emotion and all this what emotions show

00:17:34,850 --> 00:17:39,380
their shells they'll get the memory in

00:17:37,130 --> 00:17:42,050
the copy on right away so for the

00:17:39,380 --> 00:17:45,740
contender like using scenarios I think I

00:17:42,050 --> 00:17:50,690
think this VM four of em chrome can save

00:17:45,740 --> 00:17:53,840
quite a lot of memories and once and and

00:17:50,690 --> 00:17:57,200
during the during me to these outputs

00:17:53,840 --> 00:17:58,760
all this optimization on memory

00:17:57,200 --> 00:18:01,640
footprint early

00:17:58,760 --> 00:18:04,370
I found there is there is no convenient

00:18:01,640 --> 00:18:07,669
tools for us to to profile I'll trace

00:18:04,370 --> 00:18:10,490
the memory consumption of each component

00:18:07,669 --> 00:18:13,490
of Colombia and guests so we are

00:18:10,490 --> 00:18:17,450
currently sinking force for such kinda

00:18:13,490 --> 00:18:19,669
tools and and and we hope the community

00:18:17,450 --> 00:18:24,890
came and can provide some suggestion of

00:18:19,669 --> 00:18:27,580
these and then is about the integration

00:18:24,890 --> 00:18:29,720
with in the Oakland cloud container

00:18:27,580 --> 00:18:34,460
country cumulates

00:18:29,720 --> 00:18:37,220
is integrating in the wording to entail

00:18:34,460 --> 00:18:42,020
crack container which that there is

00:18:37,220 --> 00:18:46,100
replaced Kibum to used in the v1 and the

00:18:42,020 --> 00:18:48,650
benefits of the benefit of the from the

00:18:46,100 --> 00:18:52,610
from the integration is that we can use

00:18:48,650 --> 00:18:55,730
we can use a using the the talker or

00:18:52,610 --> 00:18:58,760
rocket compatible interface implemented

00:18:55,730 --> 00:19:02,179
in the intel cleaner so we can we can

00:18:58,760 --> 00:19:08,450
deploy applications in a similar way to

00:19:02,179 --> 00:19:12,160
the to the container and it is always in

00:19:08,450 --> 00:19:18,740
it can provide a better user experience

00:19:12,160 --> 00:19:23,299
and talk about our effort to make of a

00:19:18,740 --> 00:19:27,950
walk upstream we have seen we have seen

00:19:23,299 --> 00:19:33,470
out of zip histories one two months ago

00:19:27,950 --> 00:19:36,470
and in that in that personal reserve

00:19:33,470 --> 00:19:39,500
there are there are several problems one

00:19:36,470 --> 00:19:42,740
is that all optimizations in this

00:19:39,500 --> 00:19:45,559
pressure are all going to the new

00:19:42,740 --> 00:19:51,350
merchant IPC light because at that time

00:19:45,559 --> 00:19:54,140
we think that by by putting all the

00:19:51,350 --> 00:19:56,600
minging in the new pc light we can

00:19:54,140 --> 00:19:58,490
introduce let's a pollution for other

00:19:56,600 --> 00:20:01,270
machine types like usage

00:19:58,490 --> 00:20:04,700
certified and it's also easier for us to

00:20:01,270 --> 00:20:08,809
to make to make optimizations but

00:20:04,700 --> 00:20:09,880
definitely it's we introduce extra costs

00:20:08,809 --> 00:20:15,330
for the maintenance

00:20:09,880 --> 00:20:19,140
so ultimately we as suggested by the

00:20:15,330 --> 00:20:22,510
anomalies in the Middle East and some

00:20:19,140 --> 00:20:24,850
offline discussion that we're

00:20:22,510 --> 00:20:28,690
considering why we were considering to

00:20:24,850 --> 00:20:33,370
optimize apply over optimizations to

00:20:28,690 --> 00:20:36,280
queue status kill 35 so that so that so

00:20:33,370 --> 00:20:40,030
that overall can be made more widely

00:20:36,280 --> 00:20:44,289
useful and and the way to do this is

00:20:40,030 --> 00:20:48,549
that we are adding some some komlang

00:20:44,289 --> 00:20:52,630
command-line options to kill you too to

00:20:48,549 --> 00:20:58,570
disable to disable features and devices

00:20:52,630 --> 00:21:01,690
if if you want to use q35 these in the

00:20:58,570 --> 00:21:05,650
in the container like it uses scenarios

00:21:01,690 --> 00:21:08,700
and another problem is that in their

00:21:05,650 --> 00:21:15,039
service we completely removes removed in

00:21:08,700 --> 00:21:18,159
gaza form well though though the remove

00:21:15,039 --> 00:21:25,270
can can provide a significant raise

00:21:18,159 --> 00:21:28,240
speed up but s user would be limited to

00:21:25,270 --> 00:21:30,760
the linux and especially if we want to

00:21:28,240 --> 00:21:31,390
apply over ization to 35 it would be a

00:21:30,760 --> 00:21:34,150
problem

00:21:31,390 --> 00:21:37,570
so we considering to use some

00:21:34,150 --> 00:21:41,650
lightweight firmware like Cupid so that

00:21:37,570 --> 00:21:45,820
is possible to support more guest

00:21:41,650 --> 00:21:48,250
operating systems and purpose but in our

00:21:45,820 --> 00:21:52,090
benchmark we found that cupid is due to

00:21:48,250 --> 00:21:55,630
slow so optimization are still needed

00:21:52,090 --> 00:21:58,110
and we also want to keep the no formal

00:21:55,630 --> 00:22:02,710
as an option so that for users that

00:21:58,110 --> 00:22:08,080
actually want to extreme speed

00:22:02,710 --> 00:22:11,500
applicants do usage and in fact

00:22:08,080 --> 00:22:14,860
yesterday we have sent out another of

00:22:11,500 --> 00:22:15,850
the patch in this press service we may

00:22:14,860 --> 00:22:19,570
be actually

00:22:15,850 --> 00:22:22,750
most of my decisions to q35 so there is

00:22:19,570 --> 00:22:27,340
no new machine-type no no no pc lighting

00:22:22,750 --> 00:22:31,270
that's in that page service and and the

00:22:27,340 --> 00:22:33,910
way to the optimization is to also baby

00:22:31,270 --> 00:22:36,880
control the optimization is added quite

00:22:33,910 --> 00:22:41,460
a lot comments which is to control to

00:22:36,880 --> 00:22:45,700
enable disable each optimizations and

00:22:41,460 --> 00:22:48,220
and so the current status of our work is

00:22:45,700 --> 00:22:51,430
that we have sent out two of the page

00:22:48,220 --> 00:22:55,020
service to the community list and we

00:22:51,430 --> 00:22:58,930
also have a github repository for the

00:22:55,020 --> 00:23:01,450
for the force awarding of the of subsea

00:22:58,930 --> 00:23:03,610
patch service and in that github

00:23:01,450 --> 00:23:08,350
repository but also provides some tools

00:23:03,610 --> 00:23:14,890
and the scripts to to to teach you how

00:23:08,350 --> 00:23:19,900
to set up set up to set up accumulate

00:23:14,890 --> 00:23:22,360
and to play with it and it's also the

00:23:19,900 --> 00:23:25,540
the fourth version of the cumulated

00:23:22,360 --> 00:23:30,070
integrated in the in the inhale

00:23:25,540 --> 00:23:31,960
orbital and we have more optimization on

00:23:30,070 --> 00:23:34,990
the launch time and the memory for it to

00:23:31,960 --> 00:23:39,100
underway and we are also doing the

00:23:34,990 --> 00:23:41,280
upstream walk so that is all any

00:23:39,100 --> 00:23:41,280
questions

00:23:42,559 --> 00:24:06,379
Oh question is no machine type does it

00:24:00,889 --> 00:24:09,200
refer to the CPU type no if I much time

00:24:06,379 --> 00:24:11,330
I mean for example the type of the old

00:24:09,200 --> 00:24:13,820
of the motherboard currently the

00:24:11,330 --> 00:24:16,669
community are to accumulate provide to

00:24:13,820 --> 00:24:23,019
type too much Taiwanese q35 and another

00:24:16,669 --> 00:24:27,769
is I 44 Europe I think and and and it

00:24:23,019 --> 00:24:33,159
the emerging type has has been able to

00:24:27,769 --> 00:24:37,820
do with sleep you I think okay so but

00:24:33,159 --> 00:24:39,499
not for live migration it doesn't help

00:24:37,820 --> 00:24:43,009
us Oh

00:24:39,499 --> 00:24:45,799
currently yeah country we incur some

00:24:43,009 --> 00:24:48,710
problem while we're doing to the live

00:24:45,799 --> 00:24:52,369
migration West you still fix those

00:24:48,710 --> 00:24:55,809
things but at the very beginning we just

00:24:52,369 --> 00:24:58,070
we had very beginning we just want to

00:24:55,809 --> 00:25:00,019
optimize a long time and memory

00:24:58,070 --> 00:25:03,470
footprint and all other functionality

00:25:00,019 --> 00:25:07,789
will be at in the future okay thank you

00:25:03,470 --> 00:25:10,340
I saw that you are using

00:25:07,789 --> 00:25:15,340
KSM and I was wondering if you had any

00:25:10,340 --> 00:25:19,759
data about how much post memory you save

00:25:15,340 --> 00:25:22,070
it really depends on how many what in

00:25:19,759 --> 00:25:28,389
watching you start and how similar those

00:25:22,070 --> 00:25:30,720
workloads of guess whoa close

00:25:28,389 --> 00:25:35,840
currently I have

00:25:30,720 --> 00:25:40,140
i we have done some benchmark but it's

00:25:35,840 --> 00:25:44,310
but it's not very stable for the result

00:25:40,140 --> 00:25:47,780
I mean the reduction from kkm it's not

00:25:44,310 --> 00:25:52,230
very stable so so we are thinking other

00:25:47,780 --> 00:25:55,800
other optimizations on the memory

00:25:52,230 --> 00:25:58,650
footprint so such as a van full of em

00:25:55,800 --> 00:26:02,570
chrome which is dumb possibly by Q news

00:25:58,650 --> 00:26:08,280
and the result should be much stable

00:26:02,570 --> 00:26:09,420
thanks first of all I wanted to say it's

00:26:08,280 --> 00:26:11,700
it's really cool that some of the

00:26:09,420 --> 00:26:13,380
optimizations you are doing are not just

00:26:11,700 --> 00:26:14,400
helping lightweight VMS but also

00:26:13,380 --> 00:26:17,240
traditional VM is you're making

00:26:14,400 --> 00:26:20,640
everything faster so that's really nice

00:26:17,240 --> 00:26:23,940
one thing I want to mention is that last

00:26:20,640 --> 00:26:26,370
summer some folks at Red Hat were also

00:26:23,940 --> 00:26:31,440
looking at the optimizing the launch

00:26:26,370 --> 00:26:34,350
time and so we we played with Q boot and

00:26:31,440 --> 00:26:36,570
we played with C by us and actually the

00:26:34,350 --> 00:26:39,600
conclusion we came to is that even Q

00:26:36,570 --> 00:26:41,990
boot versus C by us if you optimize T by

00:26:39,600 --> 00:26:44,820
us it's not worth having a separate

00:26:41,990 --> 00:26:47,640
firmware that you men have to maintain

00:26:44,820 --> 00:26:51,120
so we think it's probably possible to

00:26:47,640 --> 00:26:54,030
make C buy us fast enough just as fast

00:26:51,120 --> 00:26:57,180
as Q boot if not faster and the

00:26:54,030 --> 00:26:59,970
maintainer Kevin O'Connor I think he was

00:26:57,180 --> 00:27:02,700
also very willing to work with people on

00:26:59,970 --> 00:27:04,500
this and he even posted on the C buys

00:27:02,700 --> 00:27:07,350
mailing list threads he even posted

00:27:04,500 --> 00:27:09,540
shell scripts or config options that

00:27:07,350 --> 00:27:12,450
will tweak C by us and make it faster so

00:27:09,540 --> 00:27:14,820
I think it would be great to work with

00:27:12,450 --> 00:27:16,290
him again and see what we can do if you

00:27:14,820 --> 00:27:18,240
look back on your slides where you

00:27:16,290 --> 00:27:19,440
showed the big graph with all the

00:27:18,240 --> 00:27:21,330
different timelines we had those

00:27:19,440 --> 00:27:23,880
different trunks so on that graph that

00:27:21,330 --> 00:27:26,450
big green thing I think if you use qumu

00:27:23,880 --> 00:27:29,670
get upstream today that should be gone

00:27:26,450 --> 00:27:31,470
because since then the firmware conflict

00:27:29,670 --> 00:27:34,230
DMA interface was introduced which

00:27:31,470 --> 00:27:36,720
removed that really slow pio access that

00:27:34,230 --> 00:27:40,500
the Linux boot ROM was doing okay okay

00:27:36,720 --> 00:27:42,900
yeah yeah we also have one we do all

00:27:40,500 --> 00:27:47,410
benchmark we also try to use

00:27:42,900 --> 00:27:50,650
FWC ppm in the face and and yes it can

00:27:47,410 --> 00:27:55,270
reduce quite a lot or IO in latency but

00:27:50,650 --> 00:27:59,890
by the waveform that still I mean it

00:27:55,270 --> 00:28:06,250
still it still takes much longer time

00:27:59,890 --> 00:28:08,860
than you know firmware scenario so yeah

00:28:06,250 --> 00:28:11,170
definitely we can we can meet and we can

00:28:08,860 --> 00:28:18,730
make more of my vision on say bells of

00:28:11,170 --> 00:28:21,300
any kind of fumble to accelerate that's

00:28:18,730 --> 00:28:21,300
great thanks

00:28:23,520 --> 00:28:28,330
have you done much optimization on the

00:28:26,530 --> 00:28:30,040
Linux kernel itself I mean you mentioned

00:28:28,330 --> 00:28:31,510
you haven't you said a few kernel

00:28:30,040 --> 00:28:34,870
parameters but it seems to me that

00:28:31,510 --> 00:28:37,810
there's scope for adding more kernel

00:28:34,870 --> 00:28:42,600
parameters to Linux to optimize the

00:28:37,810 --> 00:28:46,390
guest colonel yeah yeah because because

00:28:42,600 --> 00:28:49,600
yeah we had quite a lot put parameters I

00:28:46,390 --> 00:28:54,040
mean I mean use that existing kernel put

00:28:49,600 --> 00:28:59,130
parameters to true less the kernel to

00:28:54,040 --> 00:29:04,210
not enumerate some device which which

00:28:59,130 --> 00:29:06,490
which is not provided by Q light and and

00:29:04,210 --> 00:29:10,630
and we also use some like like this

00:29:06,490 --> 00:29:13,030
after you I still a parameter to to

00:29:10,630 --> 00:29:17,290
reduce the latency introduced by us to

00:29:13,030 --> 00:29:19,840
you yeah but I mean have you have you

00:29:17,290 --> 00:29:22,240
considered adding more parameters to the

00:29:19,840 --> 00:29:24,580
Linux kernel just turn off even more

00:29:22,240 --> 00:29:27,340
stuff that's not possible today yeah

00:29:24,580 --> 00:29:33,640
definitely yeah definitely we can add

00:29:27,340 --> 00:29:36,370
more compare meters to to avoid this

00:29:33,640 --> 00:29:40,060
some it's the initialization of the

00:29:36,370 --> 00:29:44,080
detection of some devices to to reduce

00:29:40,060 --> 00:29:49,580
the ripple time folder

00:29:44,080 --> 00:29:50,750
second unrelated question containers as

00:29:49,580 --> 00:29:54,950
they're deployed today are often

00:29:50,750 --> 00:29:56,450
deployed inside KVM instances so if you

00:29:54,950 --> 00:29:59,930
want to replace existing container usage

00:29:56,450 --> 00:30:02,930
with qmu based containers you're going

00:29:59,930 --> 00:30:04,940
to need nested virtualization have you

00:30:02,930 --> 00:30:08,150
done any any investigation of work

00:30:04,940 --> 00:30:10,790
around that you mean you mean you mean

00:30:08,150 --> 00:30:13,070
we can disable nest data when we use it

00:30:10,790 --> 00:30:16,060
when we use kill me your cater and KVM

00:30:13,070 --> 00:30:19,790
for the container right

00:30:16,060 --> 00:30:22,120
currently we haven't done that but good

00:30:19,790 --> 00:30:22,120
point

00:30:30,940 --> 00:30:35,740

YouTube URL: https://www.youtube.com/watch?v=qGgkE5-7-2M


