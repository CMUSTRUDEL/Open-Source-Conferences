Title: [2019] How KVM-based Hybrid Deployment Powers Bytedance’s Biggest Day Ever by Lu Ye & Zhenwei Pi
Publication date: 2019-11-09
Playlist: KVM Forum 2019
Description: 
	During the Spring Festival Gala, the instantaneous traffic is several hundred times that of normal, and the burst traffic during the activity greatly exceeds the current capacity of the IDCs. At the same time, to ensure the QoS of the mixed deployment online services, the isolation level of various resources is very high in every aspect, not limited to page cache, cpu scheduling capability, memory bandwidth, etc. In this session, Ye Lu & Zhenwei will introduce how the decision KVM-based Hybrid deployment solution is made, the performance optimization at the landing, and the system monitoring after virtualization, such as more accurate network analysis tools to distinguish app backend error, physical network outage, virtualized network failure. The solution help services go through the traffic peaks and improve the overall resource utilization of the IDCs.

---

Zhenwei Pi
Bytedance

Zhenwei Pi is working as a cloud computing engineer in ByteDance. He is responsible for the IaaS architecture of ByteDance’s production environment, including private cloud and edge computing cloud.

Ye Lu
Bytedance
Cloud Computing Enginneer

Yelu is working as a cloud computing engineer in ByteDance, which has more than 600 millions active users and hundreds of thousands of servers all over the world. She is responsible for the IaaS architecture of ByteDance’s production environment, including private cloud and edge computing cloud. Also she is a OpenStack ambassador for more than 5 years.
Captions: 
	00:00:00,390 --> 00:00:02,750
[Music]

00:00:06,950 --> 00:00:20,460
hi everyone welcome to our session today

00:00:16,949 --> 00:00:23,430
our topic is how given based have rated

00:00:20,460 --> 00:00:24,570
deployments powers by Don's biggest day

00:00:23,430 --> 00:00:26,939
ever

00:00:24,570 --> 00:00:29,160
Joey and I would complete the session

00:00:26,939 --> 00:00:32,820
together we are from the infrastructure

00:00:29,160 --> 00:00:35,070
team of pythons first I want to

00:00:32,820 --> 00:00:38,309
introduce our company a little bit here

00:00:35,070 --> 00:00:40,920
is the global footprint of our company

00:00:38,309 --> 00:00:42,930
you may have not heard about the

00:00:40,920 --> 00:00:46,140
violence but you may have heard about

00:00:42,930 --> 00:00:50,309
tik-tok a popular short video

00:00:46,140 --> 00:00:52,620
application we have 600 million daily

00:00:50,309 --> 00:00:55,680
active users all over the world and

00:00:52,620 --> 00:00:59,640
tik-tok is also the user of the hybrid

00:00:55,680 --> 00:01:02,520
cloud we are introduced today first I

00:00:59,640 --> 00:01:04,769
want to talk about the agenda of our

00:01:02,520 --> 00:01:07,320
session firstly I will introduce the

00:01:04,769 --> 00:01:09,750
background of our session next I will

00:01:07,320 --> 00:01:12,439
talk about the tech decisions we've made

00:01:09,750 --> 00:01:15,030
so why virtualization why not other

00:01:12,439 --> 00:01:17,729
solutions and Jim way we have shared

00:01:15,030 --> 00:01:20,880
some improvements and some work we have

00:01:17,729 --> 00:01:27,799
done at last will show some of our

00:01:20,880 --> 00:01:31,110
achievements first is the backgrounds at

00:01:27,799 --> 00:01:34,079
this time of last year we run into a

00:01:31,110 --> 00:01:37,320
sweet pain that is our business is

00:01:34,079 --> 00:01:40,590
growing quite fast that brings more that

00:01:37,320 --> 00:01:43,049
prints as more users but also more

00:01:40,590 --> 00:01:45,299
challenges for the instructor team as

00:01:43,049 --> 00:01:48,329
you know that the Spring Festival gala

00:01:45,299 --> 00:01:51,570
is the biggest Chinese traditional

00:01:48,329 --> 00:01:54,420
festival events billions of people will

00:01:51,570 --> 00:01:59,340
watch the TV show as Chinese traditional

00:01:54,420 --> 00:02:01,320
if China Chinese New Year Eve and Python

00:01:59,340 --> 00:02:05,610
sponsored the events last year

00:02:01,320 --> 00:02:09,770
this prince has a real problem so all

00:02:05,610 --> 00:02:12,810
the physical resources has used out but

00:02:09,770 --> 00:02:15,840
we have sponsored the event

00:02:12,810 --> 00:02:18,599
so many users will come to our

00:02:15,840 --> 00:02:20,940
applications at the peak hours and we

00:02:18,599 --> 00:02:25,709
need to find millions of course in their

00:02:20,940 --> 00:02:27,959
shorten to prepare for it so the there

00:02:25,709 --> 00:02:31,380
are some good news you may know that

00:02:27,959 --> 00:02:35,010
tick tock is a short video applications

00:02:31,380 --> 00:02:37,140
so we have a lot of service servers the

00:02:35,010 --> 00:02:40,130
CPU and memory usage is quite low on

00:02:37,140 --> 00:02:43,110
those abridged objects storage servers

00:02:40,130 --> 00:02:46,080
so we need to find a way to take

00:02:43,110 --> 00:02:50,370
advantage of those resources we think

00:02:46,080 --> 00:02:53,190
that hybrid deployment is the answer so

00:02:50,370 --> 00:02:56,580
to make usage of the CPU and memory

00:02:53,190 --> 00:03:00,720
wasting running server is just like cut

00:02:56,580 --> 00:03:02,940
a cake in flight we don't want the users

00:03:00,720 --> 00:03:05,549
and the services fills of turbulence

00:03:02,940 --> 00:03:10,319
especially for the hosted users that has

00:03:05,549 --> 00:03:13,260
run for several years maybe from the

00:03:10,319 --> 00:03:16,140
start of our company so the isolation of

00:03:13,260 --> 00:03:19,109
various resources is quite important

00:03:16,140 --> 00:03:21,660
such as the CPU scheduler the memory

00:03:19,109 --> 00:03:27,299
usage and the management and also the

00:03:21,660 --> 00:03:28,970
i/o and many many other aspects so next

00:03:27,299 --> 00:03:32,519
I will introduce why we choose

00:03:28,970 --> 00:03:35,130
virtualization actually at that time we

00:03:32,519 --> 00:03:38,660
have several solutions we can choose

00:03:35,130 --> 00:03:41,549
such as the visualization and the group

00:03:38,660 --> 00:03:44,489
here is the disclaimer I'm not saying

00:03:41,549 --> 00:03:46,290
that this group or other solutions is

00:03:44,489 --> 00:03:49,410
not good but the thing is you need to

00:03:46,290 --> 00:03:51,840
find out it is suitable for your station

00:03:49,410 --> 00:03:54,000
as I mentioned before we need to

00:03:51,840 --> 00:03:57,450
complete the hybrid deployment without

00:03:54,000 --> 00:03:59,639
any harm to the hosted services those

00:03:57,450 --> 00:04:02,970
services may have exist for several

00:03:59,639 --> 00:04:05,459
years so the kernel we got varies a lot

00:04:02,970 --> 00:04:07,889
we may have 10 versions of the kernel so

00:04:05,459 --> 00:04:10,260
we cannot use maybe we cannot use the

00:04:07,889 --> 00:04:13,109
new capabilities of the kernel such as

00:04:10,260 --> 00:04:17,880
the secure video or other fantastical

00:04:13,109 --> 00:04:21,000
features the first thing we need to take

00:04:17,880 --> 00:04:24,980
consideration is the CPU isolation about

00:04:21,000 --> 00:04:27,530
the CPU scheduler here is a

00:04:24,980 --> 00:04:30,560
application modeling our data in our

00:04:27,530 --> 00:04:34,460
data center maybe it's not a typical one

00:04:30,560 --> 00:04:39,020
but it does happens let me simplify it

00:04:34,460 --> 00:04:43,220
it's process contains 16 trails running

00:04:39,020 --> 00:04:45,920
in 4 CPUs here is the problem with why

00:04:43,220 --> 00:04:49,870
we use CBO quartiles group to limit the

00:04:45,920 --> 00:04:55,280
CPU usage on the left you can see the

00:04:49,870 --> 00:04:57,800
why you counter the CPU time in one per

00:04:55,280 --> 00:05:00,470
seconds you can find the CPU usage is

00:04:57,800 --> 00:05:04,670
quite a bit stable but while you look

00:05:00,470 --> 00:05:07,400
into it you counter the CPU time every

00:05:04,670 --> 00:05:10,070
10 microseconds you can find out that

00:05:07,400 --> 00:05:10,760
the CPU usage is just like a roller

00:05:10,070 --> 00:05:14,630
coaster

00:05:10,760 --> 00:05:19,160
it can turbo into 16 CPU at some time

00:05:14,630 --> 00:05:22,610
but a human have not noticed that that

00:05:19,160 --> 00:05:26,080
it does hum the applications on the host

00:05:22,610 --> 00:05:29,780
as you can see in on the right is

00:05:26,080 --> 00:05:34,720
obvious TV has jobs in the micro Mexico

00:05:29,780 --> 00:05:38,750
server so it's not accessible for the

00:05:34,720 --> 00:05:41,360
applications we have we can't take the

00:05:38,750 --> 00:05:45,980
risk at the peak hours but we do the

00:05:41,360 --> 00:05:48,170
events the case I just talked about is

00:05:45,980 --> 00:05:50,660
just just the neighbors performance

00:05:48,170 --> 00:05:53,660
makeup affected by each other here is

00:05:50,660 --> 00:05:56,450
another case that the host service may

00:05:53,660 --> 00:05:58,910
also got found while there are some

00:05:56,450 --> 00:06:01,490
naughty applications in the guest we did

00:05:58,910 --> 00:06:05,390
a comparison using the virtualization

00:06:01,490 --> 00:06:07,490
and is a messy group my using C group

00:06:05,390 --> 00:06:10,180
the guestbook loads increase intensively

00:06:07,490 --> 00:06:13,880
the host service latency increased lot

00:06:10,180 --> 00:06:15,890
but Wow use virtualization the services

00:06:13,880 --> 00:06:20,330
on the host account protected and the

00:06:15,890 --> 00:06:23,030
latency does not change much the next

00:06:20,330 --> 00:06:25,310
key resources in the system is memory

00:06:23,030 --> 00:06:27,850
the memory model and the management is

00:06:25,310 --> 00:06:30,320
quite complicated in the system without

00:06:27,850 --> 00:06:33,440
virtualization on the host if you use

00:06:30,320 --> 00:06:35,960
the C group we have many kinds of

00:06:33,440 --> 00:06:37,490
memories such as the slabs they active

00:06:35,960 --> 00:06:39,710
file mapping and

00:06:37,490 --> 00:06:43,009
interactive mapping enormous memory and

00:06:39,710 --> 00:06:46,160
so on and applications are sharing page

00:06:43,009 --> 00:06:50,360
caches even if you use this group or

00:06:46,160 --> 00:06:52,970
other isolation solutions also the kiss

00:06:50,360 --> 00:06:56,360
Wapiti cans when can scan and the

00:06:52,970 --> 00:06:59,240
proclaim the memory system wide so while

00:06:56,360 --> 00:07:01,039
the kernel system the kernel process to

00:06:59,240 --> 00:07:03,380
their job the all the application made

00:07:01,039 --> 00:07:05,660
called affected so you may have

00:07:03,380 --> 00:07:10,039
encounter problems while the kernel to a

00:07:05,660 --> 00:07:12,710
page cache brought back while we use a

00:07:10,039 --> 00:07:15,620
virtualization the memory on host is

00:07:12,710 --> 00:07:19,520
much simpler it just active not enormous

00:07:15,620 --> 00:07:21,830
napping on host the pitch cast is fully

00:07:19,520 --> 00:07:24,710
isolated and the kiss property is

00:07:21,830 --> 00:07:26,720
limited in per VM the simplify of the

00:07:24,710 --> 00:07:29,360
memory management bring else is much

00:07:26,720 --> 00:07:32,150
less pain in the cluster operation which

00:07:29,360 --> 00:07:35,330
is very important you know from the IDC

00:07:32,150 --> 00:07:38,180
operators it serves as a lost hard time

00:07:35,330 --> 00:07:42,770
to debug for the user applications the

00:07:38,180 --> 00:07:48,020
performance issues the last point that

00:07:42,770 --> 00:07:50,539
affect our decision for the hybrid is IO

00:07:48,020 --> 00:07:52,880
actually there are a lot of resource

00:07:50,539 --> 00:07:56,389
bridges in the system some of them you

00:07:52,880 --> 00:07:59,030
may have never noticed that such as the

00:07:56,389 --> 00:08:01,280
ext for journal before you encounter a

00:07:59,030 --> 00:08:05,120
problem you may never think about the

00:08:01,280 --> 00:08:07,789
ext for journalists this matters if you

00:08:05,120 --> 00:08:10,699
if you are lucky to find the root causes

00:08:07,789 --> 00:08:14,180
it may have taken a lot of time to debug

00:08:10,699 --> 00:08:17,449
for it here is the practical outage in

00:08:14,180 --> 00:08:20,090
our server we found that the user

00:08:17,449 --> 00:08:22,900
reports this report as there is T bells

00:08:20,090 --> 00:08:25,520
drop in their microcycle server and

00:08:22,900 --> 00:08:28,400
after a long time debugger we found out

00:08:25,520 --> 00:08:33,500
that it's actually because the ext for

00:08:28,400 --> 00:08:36,020
journal is locked in at that time there

00:08:33,500 --> 00:08:39,050
is a huge file is deleted on the host at

00:08:36,020 --> 00:08:42,620
that time so the meta info like the

00:08:39,050 --> 00:08:45,350
inode and the metal info like the

00:08:42,620 --> 00:08:47,440
fastest and journal is not processed in

00:08:45,350 --> 00:08:51,230
parallel in a share the kernel

00:08:47,440 --> 00:08:53,140
so those three main aspects

00:08:51,230 --> 00:08:59,000
made our decision to choose

00:08:53,140 --> 00:09:01,430
personalization and the hybrid

00:08:59,000 --> 00:09:05,600
deployment solution has run in product

00:09:01,430 --> 00:09:07,790
for almost a year in our IDC in this

00:09:05,600 --> 00:09:10,940
year we have encountered lots of issues

00:09:07,790 --> 00:09:13,550
and practical issues so next I will

00:09:10,940 --> 00:09:25,580
introduce John way to introduce the

00:09:13,550 --> 00:09:27,649
issues and how we Soviet next let me

00:09:25,580 --> 00:09:31,339
introduce some improvements for

00:09:27,649 --> 00:09:33,860
localization and we did last year when

00:09:31,339 --> 00:09:37,640
we started the hybrid deployment we hit

00:09:33,860 --> 00:09:40,190
the first problem because the object

00:09:37,640 --> 00:09:43,610
storage resource was still running on

00:09:40,190 --> 00:09:45,860
hoster server so we can't upgrade a HOSA

00:09:43,610 --> 00:09:49,250
kernel and the kernel modules but

00:09:45,860 --> 00:09:53,450
trouble fujian was the own ancestry so

00:09:49,250 --> 00:09:57,380
we developed a VM you chose KVM you

00:09:53,450 --> 00:09:59,450
choose is based on K problems so it

00:09:57,380 --> 00:10:02,810
could be installed or removed very

00:09:59,450 --> 00:10:05,750
easily on the other hand we also develop

00:10:02,810 --> 00:10:08,770
a benchmark or two aside the micro

00:10:05,750 --> 00:10:13,190
benchmark will include p AO manao

00:10:08,770 --> 00:10:15,980
timer api we also built a micro

00:10:13,190 --> 00:10:20,390
benchmark into our kernel working flow

00:10:15,980 --> 00:10:25,040
so a patch before being merged into our

00:10:20,390 --> 00:10:30,200
kernel it would be fully tested so we

00:10:25,040 --> 00:10:39,140
can know a pipe hurt the performance or

00:10:30,200 --> 00:10:43,790
not it's a example of curiosity backup

00:10:39,140 --> 00:10:47,120
function on the left aside a key Remo X

00:10:43,790 --> 00:10:54,500
the reason that hiss take this picture

00:10:47,120 --> 00:10:58,130
we can see that the rata Meza and how to

00:10:54,500 --> 00:11:02,480
as the main way max to the reason on the

00:10:58,130 --> 00:11:03,800
right side it's the resume saw detailed

00:11:02,480 --> 00:11:09,880
information

00:11:03,800 --> 00:11:13,940
in this picture we can see there are

00:11:09,880 --> 00:11:17,930
40,000 I see our requests so we can know

00:11:13,940 --> 00:11:24,160
a lot a moment a lot of 'fl IPI occur in

00:11:17,930 --> 00:11:27,350
guys Kirra mucosa helped us a lot to

00:11:24,160 --> 00:11:32,480
find the performance bottleneck of who

00:11:27,350 --> 00:11:36,890
our system and application here is the

00:11:32,480 --> 00:11:40,850
two case Oh kiss one about several

00:11:36,890 --> 00:11:45,680
months ago someone told me that the

00:11:40,850 --> 00:11:52,100
Cisco get him off day a response slowly

00:11:45,680 --> 00:11:55,640
than gyro and I found that Pio vmx it in

00:11:52,100 --> 00:11:58,940
paris' intensively oh it turned out it

00:11:55,640 --> 00:12:03,710
turned out of that guest OS o'clock

00:11:58,940 --> 00:12:09,500
sauce is sized AC TI p.m. Ronnie because

00:12:03,710 --> 00:12:15,980
we disable the km o'clock and mr. the

00:12:09,500 --> 00:12:19,730
TLC reliable in food argument the second

00:12:15,980 --> 00:12:22,900
case Retta MSR consisted lie we are

00:12:19,730 --> 00:12:26,570
Marx's over 1 million the reason or that

00:12:22,900 --> 00:12:31,180
TCP congestion control PBR right time

00:12:26,570 --> 00:12:38,030
allowed after trending to Westwood the

00:12:31,180 --> 00:12:44,030
performance.get critic improvement the

00:12:38,030 --> 00:12:49,070
second problem there are 48 co-host or

00:12:44,030 --> 00:12:54,950
is so trial CPU for OSS to the server

00:12:49,070 --> 00:12:57,260
and the launch of VM with 36 VCO there

00:12:54,950 --> 00:13:01,040
are accused of water function interface

00:12:57,260 --> 00:13:08,780
we Europe and Acura phonetic who we see

00:13:01,040 --> 00:13:11,720
fuel 0 to 7 but there are only about 150

00:13:08,780 --> 00:13:15,650
K to 500k interrupt of a second in

00:13:11,720 --> 00:13:20,370
castle so we see fuel 0 to 7

00:13:15,650 --> 00:13:25,980
always not be say enough a typical case

00:13:20,370 --> 00:13:28,860
like this net packet reaches at work

00:13:25,980 --> 00:13:31,800
true function interface learns basic you

00:13:28,860 --> 00:13:34,800
will be picked up by posted interrupted

00:13:31,800 --> 00:13:38,370
recap event after processing the net

00:13:34,800 --> 00:13:42,240
packet the visual will run how the

00:13:38,370 --> 00:13:42,890
instruction and live via modem so to

00:13:42,240 --> 00:13:47,400
many

00:13:42,890 --> 00:13:53,600
remag siddharta narrated by how and PIV

00:13:47,400 --> 00:13:59,070
hub worse yet the latency of who

00:13:53,600 --> 00:14:02,700
interrupted processing gets unstable the

00:13:59,070 --> 00:14:09,150
ladies density of online stories also

00:14:02,700 --> 00:14:13,350
get affected we want to reduce this via

00:14:09,150 --> 00:14:18,090
magazine but currently the Kuna only

00:14:13,350 --> 00:14:20,700
supports idle poor or no how can it mean

00:14:18,090 --> 00:14:23,610
that all of the CEO would rein in poly

00:14:20,700 --> 00:14:27,090
model we need the avoider performance to

00:14:23,610 --> 00:14:30,660
occupy help us read the podium pylons

00:14:27,090 --> 00:14:33,510
host and guests secure consumption so we

00:14:30,660 --> 00:14:36,600
developed a know how to list oh no

00:14:33,510 --> 00:14:39,090
hollister no parameter allows the

00:14:36,600 --> 00:14:44,130
best-paid the CPU to run in poly mode or

00:14:39,090 --> 00:14:49,290
we can copy put arguments like this

00:14:44,130 --> 00:14:54,210
Accio or affinity 0 to 7 know how to

00:14:49,290 --> 00:14:57,380
list 0 to 7 then only we secure 0 to 7

00:14:54,210 --> 00:14:57,380
we arranged in poly model

00:14:59,720 --> 00:15:07,590
mmm I selected a random 1,000 online

00:15:04,080 --> 00:15:10,140
server collected a posted in a wrapper

00:15:07,590 --> 00:15:13,580
we have event every second draw the

00:15:10,140 --> 00:15:15,830
distribution and graph on the left side

00:15:13,580 --> 00:15:22,610
result to know how to Lisa Fischer

00:15:15,830 --> 00:15:22,610
there are about a 500 so er how about

00:15:23,000 --> 00:15:31,800
20,000 piw per second about 300 the

00:15:27,630 --> 00:15:35,360
server how 14000 pwo per second the

00:15:31,800 --> 00:15:40,230
others or how more on the right side

00:15:35,360 --> 00:15:43,830
with no heart ELISA feature almost of

00:15:40,230 --> 00:15:47,960
the secure of the server have only a few

00:15:43,830 --> 00:15:52,290
piw almost zero

00:15:47,960 --> 00:15:57,180
hmm at the same time the latency of our

00:15:52,290 --> 00:16:07,680
online service get paid her and most

00:15:57,180 --> 00:16:11,130
stable sort of problem we reheat several

00:16:07,680 --> 00:16:15,540
performance drop amplified in IBM for

00:16:11,130 --> 00:16:18,860
example it hop is a Linux system under

00:16:15,540 --> 00:16:21,810
12 it always tried to collect

00:16:18,860 --> 00:16:25,800
instruction per sec hosts did her

00:16:21,810 --> 00:16:29,520
information by p.m. you you were

00:16:25,800 --> 00:16:30,960
correctly you would receive in case SOS

00:16:29,520 --> 00:16:34,820
will trigger

00:16:30,960 --> 00:16:38,850
Retta Meza and RDP MC every 10 seconds

00:16:34,820 --> 00:16:43,850
we want to resolve this problem so we

00:16:38,850 --> 00:16:46,680
made it home smart it hope you

00:16:43,850 --> 00:16:50,910
auto-detects have either during startup

00:16:46,680 --> 00:16:55,740
if detecting successfully in hope you

00:16:50,910 --> 00:17:01,290
ought to disable a PC collection so the

00:16:55,740 --> 00:17:06,210
eighth hope you never trigger extra we

00:17:01,290 --> 00:17:08,910
max it you know gues another case team a

00:17:06,210 --> 00:17:13,439
lock is a yellow space memory management

00:17:08,910 --> 00:17:17,549
the library it has better performance

00:17:13,439 --> 00:17:20,459
Zann gilepsy Peeta Mellark my log of

00:17:17,549 --> 00:17:27,419
three especially our mountains right the

00:17:20,459 --> 00:17:30,779
case but I am a log try to free physical

00:17:27,419 --> 00:17:35,340
memory to Colonel by the Sisko I'm

00:17:30,779 --> 00:17:40,559
otherwise don't need then trigger a lot

00:17:35,340 --> 00:17:47,419
of who care be food on as well-known IPI

00:17:40,559 --> 00:17:47,419
is really expensive in in vocalization

00:17:49,460 --> 00:17:58,710
peevish and I prefer makes the IP I

00:17:55,379 --> 00:18:02,779
broadcast more effective but in my

00:17:58,710 --> 00:18:07,820
experience the API is still the

00:18:02,779 --> 00:18:07,820
performance bottleneck Hawkeye stories

00:18:10,070 --> 00:18:21,049
about several problems and solution I

00:18:16,320 --> 00:18:26,639
mentioned about I want to introduce

00:18:21,049 --> 00:18:32,129
common mess or how to find performance

00:18:26,639 --> 00:18:36,379
bottleneck then we can optimize not only

00:18:32,129 --> 00:18:42,090
the Kuna side but also application I

00:18:36,379 --> 00:18:46,279
think maybe more applications should be

00:18:42,090 --> 00:18:46,279
adapt to vocalization case

00:18:50,250 --> 00:18:57,310
the last I want to share is the

00:18:52,690 --> 00:19:02,140
achievement that we have made the other

00:18:57,310 --> 00:19:06,610
side is random or 7,000 hosts left aside

00:19:02,140 --> 00:19:10,480
if before hybrid deployment all most of

00:19:06,610 --> 00:19:14,020
the server run under 10% scipio

00:19:10,480 --> 00:19:17,830
utilization on the right side after a

00:19:14,020 --> 00:19:22,360
hybrid deployment most of the solar how

00:19:17,830 --> 00:19:26,440
higher civilization at the same time we

00:19:22,360 --> 00:19:30,700
can provide millions of costs for online

00:19:26,440 --> 00:19:37,900
choice because of the high level

00:19:30,700 --> 00:19:47,070
solution from KVM the host object

00:19:37,900 --> 00:19:50,650
storage resource get protected and after

00:19:47,070 --> 00:19:55,870
Union the performance in Gaza get close

00:19:50,650 --> 00:19:56,740
to the bare metal so I can see these

00:19:55,870 --> 00:20:02,110
competence that

00:19:56,740 --> 00:20:08,710
KVM could do better hybrid deployment in

00:20:02,110 --> 00:20:11,670
the future thank you

00:20:08,710 --> 00:20:17,769
it's the QA time

00:20:11,670 --> 00:20:17,769
[Applause]

00:20:21,970 --> 00:20:30,190
how did you reduce the frequency of the

00:20:25,669 --> 00:20:30,190
TSC deadline timer exits

00:20:36,130 --> 00:20:51,750
Oh in fact we didn't reduce the the

00:20:47,530 --> 00:20:55,750
latest offer to resume Sarkis that I

00:20:51,750 --> 00:21:00,100
because the TCP congestion control

00:20:55,750 --> 00:21:04,150
I was a real algorithm PPR writes time

00:21:00,100 --> 00:21:10,110
allowed we change the algorithm to way

00:21:04,150 --> 00:21:18,159
so wouldn't we just let the guest rise

00:21:10,110 --> 00:21:23,919
timer nice sorry did you say you let the

00:21:18,159 --> 00:21:26,830
guest right through actually it's

00:21:23,919 --> 00:21:30,760
because from in the guests that we have

00:21:26,830 --> 00:21:35,200
several kids TCP congestion control

00:21:30,760 --> 00:21:39,520
measures such as PBRs as best food Wow

00:21:35,200 --> 00:21:41,440
and Kuby and maybe some others the we

00:21:39,520 --> 00:21:45,280
found that while we use in VP are the

00:21:41,440 --> 00:21:47,880
radius performance drops a lot compared

00:21:45,280 --> 00:21:52,150
to the pear mental so we try to find out

00:21:47,880 --> 00:21:55,210
the reason and we found out it's because

00:21:52,150 --> 00:21:58,230
the to many tests deadlines exceed and

00:21:55,210 --> 00:22:01,960
we so we change the TCP congestion

00:21:58,230 --> 00:22:05,530
control method yeah so we don't reduce

00:22:01,960 --> 00:22:10,299
with we don't find the way in QM we just

00:22:05,530 --> 00:22:18,789
find the way the applications use it yes

00:22:10,299 --> 00:22:22,000
yes we because we provide a puppet more

00:22:18,789 --> 00:22:29,140
private a cloud we can control the

00:22:22,000 --> 00:22:35,220
guests so we use the best mmm TCP

00:22:29,140 --> 00:22:38,919
congestion control algorithm using that

00:22:35,220 --> 00:22:41,460
Westwood has better performances and VBR

00:22:38,919 --> 00:22:41,460
in gas

00:22:47,600 --> 00:22:51,670
okay no more customs

00:22:52,190 --> 00:22:55,570
thank you very much

00:22:55,590 --> 00:23:04,780
[Applause]

00:22:57,590 --> 00:23:04,780

YouTube URL: https://www.youtube.com/watch?v=tvHRQQkguC0


