Title: [2019] virtio-vsock in QEMU, Firecracker and Linux: Status, Performance and Challenges
Publication date: 2019-11-09
Playlist: KVM Forum 2019
Description: 
	The virtio-vsock device provides a zero-configuration communication
channel between guest agents and hypervisor services independent of the
guest network configuration. QEMU and the Linux kernel have virtio-vsock
vhost support. Firecracker is a new open source Virtual Machine Monitor
(VMM) that makes use of KVM and includes support for virtio-vsock.

Andra will give an intro on the state of the art of virtio-vsock and its
use cases. She will then present multiple proposed options for
communication channels between a virtual machine and the host or between
virtual machines using Firecracker. These options include the vhost
backend as well as UNIX domain sockets. She will share performance
metrics with regard to the discussed alternatives.

Stefano will describe the latest performance improvements within the
Linux kernel and QEMU. He will also give an overview of tools that
recently added vsock support (e.g. wireshark, tcpdump, iproute2-ss,
ncat). Finally, he will present the next challenges that will be faced
to improve virtio-vsock, such as support for nested VMs and network
namespaces.

---

Stefano Garzarella
Red Hat
Software Engineer

Stefano is a Software Engineer at Red Hat. He is working on virtualization and networking topics in QEMU and Linux kernel. Current projects cover virtio-vsock, QEMU network storage, and lightweight VMs.

Stefano has presented at EuroBSDCon 2014 and AsiaBSDCon 2015.

Andra Paraschiv
Amazon Web Services
Software Development Engineer

Andra is a Software Development Engineer at Amazon Development Center, Romania, Bucharest, part of Amazon Web Services (AWS). She has been working on the virtualization stack of EC2, both on Xen and Nitro hypervisors. Before AWS, she was a Software Engineer at Intel, focusing on research. She worked on operating systems, virtualization, network technologies and the Linux kernel.

Note: We apologize for lower video quality due to technical problems.
Captions: 
	00:00:00,390 --> 00:00:02,750
[Music]

00:00:06,859 --> 00:00:10,320
thanks for coming

00:00:08,490 --> 00:00:12,179
I'm Andra and together with the father

00:00:10,320 --> 00:00:14,190
today we'll be talking about whatever is

00:00:12,179 --> 00:00:16,980
talking here Moo firecracker and Linux

00:00:14,190 --> 00:00:19,470
I'm working at Amazon and I'm a software

00:00:16,980 --> 00:00:21,660
development engineer there and I'm

00:00:19,470 --> 00:00:24,539
working mainly on the ec2 infrastructure

00:00:21,660 --> 00:00:27,510
on the Nitro and then hypervisors where

00:00:24,539 --> 00:00:30,060
nitro is based on KPM and stephanopoulos

00:00:27,510 --> 00:00:32,399
and I'm Stephan I'm working at reddit in

00:00:30,060 --> 00:00:34,290
the virtualization team and birthday

00:00:32,399 --> 00:00:38,129
yoga sock is one of the topic where I'm

00:00:34,290 --> 00:00:40,140
working on so let's project you what

00:00:38,129 --> 00:00:41,820
we're talking about today we'll be

00:00:40,140 --> 00:00:43,890
talking why we'll need to have the water

00:00:41,820 --> 00:00:46,500
be soaked implementation several

00:00:43,890 --> 00:00:49,320
instances and then go through more into

00:00:46,500 --> 00:00:50,820
details of the backend and which are the

00:00:49,320 --> 00:00:52,680
updates on the Firecracker

00:00:50,820 --> 00:00:56,309
here mo and the Linux kernel side and

00:00:52,680 --> 00:01:00,420
which will be the next steps so first of

00:00:56,309 --> 00:01:02,879
all let's see we have this diagram where

00:01:00,420 --> 00:01:05,280
we show we have a guest and host and we

00:01:02,879 --> 00:01:07,200
have an application on both ends and we

00:01:05,280 --> 00:01:10,470
would like to have a local communication

00:01:07,200 --> 00:01:12,840
channel between the two so we can use a

00:01:10,470 --> 00:01:14,850
network device there and we need for

00:01:12,840 --> 00:01:17,490
example to set up the IP address and

00:01:14,850 --> 00:01:18,320
also the routing and we can use the

00:01:17,490 --> 00:01:21,240
socket API

00:01:18,320 --> 00:01:24,509
while the addressing will be the IP and

00:01:21,240 --> 00:01:26,250
port so why not instead have no

00:01:24,509 --> 00:01:29,790
configuration regarding the addressing

00:01:26,250 --> 00:01:32,520
import and routing and use instead of at

00:01:29,790 --> 00:01:34,890
every sub device what we need to change

00:01:32,520 --> 00:01:37,079
from the app perspective is the

00:01:34,890 --> 00:01:39,600
addressing so we will change the same

00:01:37,079 --> 00:01:44,310
socket API but we have now instead of

00:01:39,600 --> 00:01:46,860
the IP the cid the contact ID in the

00:01:44,310 --> 00:01:49,320
guest and the host we need support from

00:01:46,860 --> 00:01:51,360
the kernel side so on the gear side we

00:01:49,320 --> 00:01:53,340
need to have a turkey stock support and

00:01:51,360 --> 00:01:56,460
on the house side we need to have fig

00:01:53,340 --> 00:01:58,979
off support and the device that it's

00:01:56,460 --> 00:02:01,500
available on the gas side can be either

00:01:58,979 --> 00:02:04,490
mio and PCI or PCI

00:02:01,500 --> 00:02:06,770
it's available to the guests to chose

00:02:04,490 --> 00:02:11,390
what will be available

00:02:06,770 --> 00:02:14,150
Oh text several use cases we can have

00:02:11,390 --> 00:02:17,930
guest agents or hypervisor services and

00:02:14,150 --> 00:02:21,310
for example we can have file-sharing log

00:02:17,930 --> 00:02:23,720
and matrix sharing and see which are the

00:02:21,310 --> 00:02:25,519
updates on the side and which is the

00:02:23,720 --> 00:02:29,180
behavior of the gate for example and

00:02:25,519 --> 00:02:32,239
talking about the socket API before we

00:02:29,180 --> 00:02:34,310
can have network applications but we can

00:02:32,239 --> 00:02:37,700
move these applications from one little

00:02:34,310 --> 00:02:39,890
device or whatever device in a seamless

00:02:37,700 --> 00:02:42,980
way because we do not need to change

00:02:39,890 --> 00:02:45,080
this how their API is called but only

00:02:42,980 --> 00:02:47,569
change the addressing we keep the port

00:02:45,080 --> 00:02:52,069
and now we have instead of the IP a

00:02:47,569 --> 00:02:54,410
context ID and now until now we will be

00:02:52,069 --> 00:02:57,319
talking about a communication between

00:02:54,410 --> 00:02:59,989
the guest and the host why if we need

00:02:57,319 --> 00:03:01,910
the communication between two VMs we can

00:02:59,989 --> 00:03:04,519
get that but we will need to have

00:03:01,910 --> 00:03:07,640
additional implementation on the host ID

00:03:04,519 --> 00:03:09,500
so we can have the routing done or we

00:03:07,640 --> 00:03:14,510
can have share memory between the VMS

00:03:09,500 --> 00:03:17,000
and this can be done seamlessly next few

00:03:14,510 --> 00:03:19,370
more details so let's dive deeper and

00:03:17,000 --> 00:03:21,829
how the backend looks for from now we

00:03:19,370 --> 00:03:23,720
will be looking from the host and guest

00:03:21,829 --> 00:03:26,420
perspective and how the application

00:03:23,720 --> 00:03:28,910
looks and which are the needs to do a

00:03:26,420 --> 00:03:31,400
weak needs to be done to have the

00:03:28,910 --> 00:03:34,519
changes from current implementation and

00:03:31,400 --> 00:03:37,790
port to avert a vista implementation in

00:03:34,519 --> 00:03:40,280
this perspective there is the host that

00:03:37,790 --> 00:03:42,109
needs to have support for whateva so

00:03:40,280 --> 00:03:44,660
that's mainly the V hosts V stock

00:03:42,109 --> 00:03:47,120
implementation and we have upstream

00:03:44,660 --> 00:03:50,930
available support for net for Scotty and

00:03:47,120 --> 00:03:52,579
for visa so how will this look entire

00:03:50,930 --> 00:03:54,980
communication and the set up of the

00:03:52,579 --> 00:03:56,780
device so first of all we need to set up

00:03:54,980 --> 00:03:58,489
the device we need to have the

00:03:56,780 --> 00:04:01,040
interaction with the VM M so that we

00:03:58,489 --> 00:04:03,620
have the configuration done and then the

00:04:01,040 --> 00:04:05,450
data can flow without the need of the

00:04:03,620 --> 00:04:07,940
cooperation from the VM em because the

00:04:05,450 --> 00:04:11,750
host has access directly to the buffers

00:04:07,940 --> 00:04:14,750
from the guest and fourth signaling will

00:04:11,750 --> 00:04:15,130
use event of T's so when the guest has

00:04:14,750 --> 00:04:17,800
something

00:04:15,130 --> 00:04:21,489
for the host will signal using I event

00:04:17,800 --> 00:04:23,620
of T when the host has need has data to

00:04:21,489 --> 00:04:27,640
send to the guest will signal using

00:04:23,620 --> 00:04:29,800
arrow key of T's and this all works

00:04:27,640 --> 00:04:32,590
after doing the setup of the device and

00:04:29,800 --> 00:04:34,890
we can send data in this way and we can

00:04:32,590 --> 00:04:37,300
keep the application using the same API

00:04:34,890 --> 00:04:41,620
but we need support from the kernel

00:04:37,300 --> 00:04:44,200
drivers next what's available in

00:04:41,620 --> 00:04:47,200
firecracker so far cracker there was

00:04:44,200 --> 00:04:50,050
talk before about firecracker but in a

00:04:47,200 --> 00:04:52,300
nutshell there is of open source mmmm

00:04:50,050 --> 00:04:54,940
it was released the previous year at a

00:04:52,300 --> 00:04:56,920
table spring event and it's used in the

00:04:54,940 --> 00:04:59,530
Internet infrastructure by lambda F

00:04:56,920 --> 00:05:01,660
arcade and externally by cata containers

00:04:59,530 --> 00:05:05,140
for example because they use in addition

00:05:01,660 --> 00:05:07,570
to PMO also firecracker so let's say we

00:05:05,140 --> 00:05:09,430
have a function or a container task and

00:05:07,570 --> 00:05:11,950
we want to run this in an AWS

00:05:09,430 --> 00:05:15,910
infrastructure a VM will be launched and

00:05:11,950 --> 00:05:18,870
this VM will use the vm m that it's

00:05:15,910 --> 00:05:21,940
using the firecracker implementation and

00:05:18,870 --> 00:05:25,180
regarding the host implementation it was

00:05:21,940 --> 00:05:27,910
available as an experimental till v0 18

00:05:25,180 --> 00:05:31,000
but why we need to move to another

00:05:27,910 --> 00:05:33,190
implementation because at that time if

00:05:31,000 --> 00:05:36,940
you want to have support for Part IV so

00:05:33,190 --> 00:05:39,040
you need to specify this in the build

00:05:36,940 --> 00:05:41,320
time uh W time because it was not

00:05:39,040 --> 00:05:43,180
available by default you need to specify

00:05:41,320 --> 00:05:45,490
this as a feature and then you'll have

00:05:43,180 --> 00:05:49,450
the possibility to add the water with

00:05:45,490 --> 00:05:52,090
some device to the vm so we moved from

00:05:49,450 --> 00:05:53,740
this implementation with v host to an

00:05:52,090 --> 00:05:56,080
implementation using kinase domain

00:05:53,740 --> 00:05:57,940
sockets and why you loose domain sockets

00:05:56,080 --> 00:06:01,480
because we human change the same socket

00:05:57,940 --> 00:06:04,510
API so we keep the same logic but will

00:06:01,480 --> 00:06:09,130
have like different now we are using a

00:06:04,510 --> 00:06:11,220
path instead of an IP important and why

00:06:09,130 --> 00:06:13,960
we need to move from from that

00:06:11,220 --> 00:06:16,390
implementation to the one with the UNIX

00:06:13,960 --> 00:06:19,210
domain socket first of all it was the

00:06:16,390 --> 00:06:21,790
security impact before we'll be talking

00:06:19,210 --> 00:06:25,030
about the host having direct access to

00:06:21,790 --> 00:06:28,510
the guest to the buffers so there could

00:06:25,030 --> 00:06:30,450
be a issue in the V host driver

00:06:28,510 --> 00:06:32,980
so there could be also privileged

00:06:30,450 --> 00:06:36,010
excavation from this perspective so

00:06:32,980 --> 00:06:39,160
using the UNIX domain socket instead of

00:06:36,010 --> 00:06:41,620
the V host implementation on the host we

00:06:39,160 --> 00:06:44,080
can this way is reduce the security

00:06:41,620 --> 00:06:47,950
impact of what could happen if there is

00:06:44,080 --> 00:06:50,470
a security bug on the gas side or on the

00:06:47,950 --> 00:06:53,230
hot side and for example there was a

00:06:50,470 --> 00:06:55,840
recent CV regarding the V host kernel

00:06:53,230 --> 00:06:58,180
implementation when there was a buffer

00:06:55,840 --> 00:07:00,820
overflow and this could lead to

00:06:58,180 --> 00:07:02,170
privilege escalation with the guest so

00:07:00,820 --> 00:07:05,250
this is from the security perspective

00:07:02,170 --> 00:07:09,220
now from the functionality perspective

00:07:05,250 --> 00:07:11,620
what if we need to have by default the V

00:07:09,220 --> 00:07:14,230
hosts implementation on the host we

00:07:11,620 --> 00:07:16,750
would not want to have that and this way

00:07:14,230 --> 00:07:18,250
we reduce the code base or the available

00:07:16,750 --> 00:07:20,740
functionality that needs to be there to

00:07:18,250 --> 00:07:23,770
have a proper communication between the

00:07:20,740 --> 00:07:25,990
guest and the host and the vertebra stop

00:07:23,770 --> 00:07:29,770
device model is now available in the VM

00:07:25,990 --> 00:07:31,720
in the Firecracker VMM and on the host

00:07:29,770 --> 00:07:35,890
side we only see the UNIX domain sockets

00:07:31,720 --> 00:07:39,640
but what we need to do for configuration

00:07:35,890 --> 00:07:42,040
so we will have a one vertebra stop

00:07:39,640 --> 00:07:44,680
device per diem so that's the available

00:07:42,040 --> 00:07:48,070
implementation in firecracker and till

00:07:44,680 --> 00:07:51,070
now we've been using KML and we have a

00:07:48,070 --> 00:07:54,130
guest yet he needs to be set up there in

00:07:51,070 --> 00:07:56,620
addition to that we now are using a UNIX

00:07:54,130 --> 00:07:58,720
domain socket path and the VM M is

00:07:56,620 --> 00:08:01,810
listening by default on that UNIX domain

00:07:58,720 --> 00:08:04,060
socket bat and the Vista connection can

00:08:01,810 --> 00:08:05,950
be established from the guest site or

00:08:04,060 --> 00:08:08,350
from the whole site so we have this

00:08:05,950 --> 00:08:12,790
possibility of these possibilities on

00:08:08,350 --> 00:08:15,790
both ends next let's see how this works

00:08:12,790 --> 00:08:17,800
from from the host perspective so let's

00:08:15,790 --> 00:08:21,430
say we have a host and it wants to

00:08:17,800 --> 00:08:23,590
connect to the guest we have in the gas

00:08:21,430 --> 00:08:25,600
side an application that listen on a

00:08:23,590 --> 00:08:28,990
certain port and it's using a water with

00:08:25,600 --> 00:08:30,940
some device on the hot side we have an

00:08:28,990 --> 00:08:32,979
application that connects to the UNIX

00:08:30,940 --> 00:08:37,599
domain socket path that was configured

00:08:32,979 --> 00:08:39,870
at vm lodge nearby something needs to do

00:08:37,599 --> 00:08:43,140
the mapping between the two connections

00:08:39,870 --> 00:08:45,690
here comes firecracker where we have a

00:08:43,140 --> 00:08:48,900
whistle end point with the CID of the

00:08:45,690 --> 00:08:50,580
host that's two and we have a UNIX

00:08:48,900 --> 00:08:52,380
domain socket pad for the one that was

00:08:50,580 --> 00:08:56,040
configured and I was mentioning before

00:08:52,380 --> 00:08:58,830
and the vmm is listening on the socket

00:08:56,040 --> 00:09:02,730
pad so the connection mapping is done

00:08:58,830 --> 00:09:06,240
between the two and when the host sends

00:09:02,730 --> 00:09:09,360
data to the gate before that it needs to

00:09:06,240 --> 00:09:11,850
send a special message let's connect to

00:09:09,360 --> 00:09:13,830
a certainly support because the

00:09:11,850 --> 00:09:15,480
application is listening to a certain

00:09:13,830 --> 00:09:18,240
port and firecracker needs to do the

00:09:15,480 --> 00:09:21,000
mapping between which socket path from

00:09:18,240 --> 00:09:24,750
the host it's going the data to which

00:09:21,000 --> 00:09:26,700
end point on the guest after we have all

00:09:24,750 --> 00:09:29,940
the setup done and the connection of

00:09:26,700 --> 00:09:32,190
connection mappings are established we

00:09:29,940 --> 00:09:35,850
further can send data without the need

00:09:32,190 --> 00:09:37,950
to have other things different done than

00:09:35,850 --> 00:09:42,690
it was before so we can use the same

00:09:37,950 --> 00:09:43,230
same socket API then the other way

00:09:42,690 --> 00:09:45,510
around

00:09:43,230 --> 00:09:48,330
from the guest we want to connect to the

00:09:45,510 --> 00:09:50,520
host we have an application that

00:09:48,330 --> 00:09:53,190
connects to CID tool and a certain port

00:09:50,520 --> 00:09:56,280
and then on the host we need to listen

00:09:53,190 --> 00:09:58,650
to a certain UNIX domain path but now

00:09:56,280 --> 00:10:00,660
there is a different unit domain circuit

00:09:58,650 --> 00:10:03,120
path because we need to identify that

00:10:00,660 --> 00:10:06,900
specific connection with a specific port

00:10:03,120 --> 00:10:09,110
and for now it's the UNIX domain so CAD

00:10:06,900 --> 00:10:11,730
pad that was configured at VM launched

00:10:09,110 --> 00:10:14,400
together or appended with the port

00:10:11,730 --> 00:10:18,839
that's the visa application connects to

00:10:14,400 --> 00:10:21,690
and in the middle fire cracker also has

00:10:18,839 --> 00:10:25,200
the Vista endpoint as before and it's

00:10:21,690 --> 00:10:27,030
acting like a host and then is the UNIX

00:10:25,200 --> 00:10:29,070
domain socket that that is used to

00:10:27,030 --> 00:10:32,070
connect to the host that is listening on

00:10:29,070 --> 00:10:34,740
that and after that we do not need to

00:10:32,070 --> 00:10:37,140
have an additional message centers in

00:10:34,740 --> 00:10:39,570
the previous example but can send

00:10:37,140 --> 00:10:43,370
directly data from the host to the guest

00:10:39,570 --> 00:10:43,370
application and the other way around

00:10:43,580 --> 00:10:49,290
talking about guest the host

00:10:46,370 --> 00:10:51,690
implementation now let's see a few of

00:10:49,290 --> 00:10:53,290
the metrics because we've been looking

00:10:51,690 --> 00:10:58,270
on the throughput side

00:10:53,290 --> 00:11:01,630
and we've been using iperf and socket on

00:10:58,270 --> 00:11:04,390
the other end we have a VM that's

00:11:01,630 --> 00:11:06,850
running on a metal instance and we are

00:11:04,390 --> 00:11:10,270
looking on the user space before side

00:11:06,850 --> 00:11:12,520
that is sent to the iperf and also on

00:11:10,270 --> 00:11:14,320
the throughput that we gain when we send

00:11:12,520 --> 00:11:17,470
data from the guest application to the

00:11:14,320 --> 00:11:19,780
host application and here you can see a

00:11:17,470 --> 00:11:23,560
connection takes both sides mentioned in

00:11:19,780 --> 00:11:26,920
the legend so that's the buffer that is

00:11:23,560 --> 00:11:29,590
used by Firecracker to get the data from

00:11:26,920 --> 00:11:32,260
the water we stock device to the Linux

00:11:29,590 --> 00:11:34,630
Thomas ok device and why we need this

00:11:32,260 --> 00:11:37,060
kind of buffer it's a simpler buffer

00:11:34,630 --> 00:11:39,670
that's because we need to actually take

00:11:37,060 --> 00:11:43,390
the data from the water Vista filter

00:11:39,670 --> 00:11:45,700
wisdom device and send it to a buffer if

00:11:43,390 --> 00:11:48,100
we cannot cope on the whole side to

00:11:45,700 --> 00:11:52,240
receive the data immediately on the UNIX

00:11:48,100 --> 00:11:54,370
domain socket so we are looking on this

00:11:52,240 --> 00:11:57,400
from this perspective and from the

00:11:54,370 --> 00:12:00,100
perspective of a buffer user space from

00:11:57,400 --> 00:12:03,520
the iperf aside and we can see that

00:12:00,100 --> 00:12:06,130
growing the user space buffers and also

00:12:03,520 --> 00:12:08,950
that takes both side we still grow from

00:12:06,130 --> 00:12:11,560
few megabits per second to thank gabbi's

00:12:08,950 --> 00:12:14,110
per second and that's the implication of

00:12:11,560 --> 00:12:16,840
what will be needed to be done on the

00:12:14,110 --> 00:12:19,000
visa side and also on the Firecracker vm

00:12:16,840 --> 00:12:23,230
website so that we can send a data

00:12:19,000 --> 00:12:25,650
between the guest and the host oh just

00:12:23,230 --> 00:12:28,840
to sum up of what will be done until now

00:12:25,650 --> 00:12:30,490
firecracker has available since v-0 it

00:12:28,840 --> 00:12:32,800
in the water with some device

00:12:30,490 --> 00:12:37,090
implementation it's using the in

00:12:32,800 --> 00:12:39,160
Islamist okay and you can get it you can

00:12:37,090 --> 00:12:42,520
clone it and you can check it out on a

00:12:39,160 --> 00:12:43,330
KVM based box because it's available out

00:12:42,520 --> 00:12:47,950
of the box

00:12:43,330 --> 00:12:50,410
and you can get it run and get us your

00:12:47,950 --> 00:12:52,780
feedback so that we can see what we can

00:12:50,410 --> 00:12:55,200
improve on that side and also what we

00:12:52,780 --> 00:12:58,720
can do further from this perspective and

00:12:55,200 --> 00:12:59,920
now let's move further to what is needed

00:12:58,720 --> 00:13:01,899
on the PMO on the

00:12:59,920 --> 00:13:03,970
can decide which are the updates and the

00:13:01,899 --> 00:13:07,560
performance there and which will be the

00:13:03,970 --> 00:13:09,660
next steps so Stefan our daily change

00:13:07,560 --> 00:13:13,209
okay thanks

00:13:09,660 --> 00:13:16,149
let's talk about Cuomo and V so Cuomo

00:13:13,209 --> 00:13:19,329
provides the VFA aviso device using the

00:13:16,149 --> 00:13:21,660
B host miss or Canon driver so the

00:13:19,329 --> 00:13:24,519
device in Kokomo handled only the

00:13:21,660 --> 00:13:26,920
configuration and the live migration it

00:13:24,519 --> 00:13:30,490
allowed the user or the management tool

00:13:26,920 --> 00:13:32,829
to configure the gas CID and to migrate

00:13:30,490 --> 00:13:35,769
Abraham that is using be sought in this

00:13:32,829 --> 00:13:38,889
case connected stream socket become

00:13:35,769 --> 00:13:40,720
disconnected and so in the application

00:13:38,889 --> 00:13:44,769
must handle a connection result error

00:13:40,720 --> 00:13:46,990
and should reconnect and the gas CID

00:13:44,769 --> 00:13:49,000
cannot be available in the new host

00:13:46,990 --> 00:13:51,730
because for example is a Sonya to

00:13:49,000 --> 00:13:55,199
another BM in this case the host the

00:13:51,730 --> 00:13:57,970
guest is notified about the CID change

00:13:55,199 --> 00:14:00,550
most of the work in the host is done in

00:13:57,970 --> 00:14:02,680
the B host kernel driver so it handles

00:14:00,550 --> 00:14:05,250
the communication with the guests I mean

00:14:02,680 --> 00:14:08,019
the birth queue operations providing

00:14:05,250 --> 00:14:10,500
internal vertigo device simulation this

00:14:08,019 --> 00:14:13,600
allow us to have better performance and

00:14:10,500 --> 00:14:16,060
in addition the B host kernel driver

00:14:13,600 --> 00:14:19,060
implements the interface with the host

00:14:16,060 --> 00:14:21,790
socket layer allowing a user space

00:14:19,060 --> 00:14:25,779
application to use the socket API with

00:14:21,790 --> 00:14:29,949
this address with the visa address

00:14:25,779 --> 00:14:33,430
family to communicate directly with with

00:14:29,949 --> 00:14:36,550
the host with a guest so in the crew hem

00:14:33,430 --> 00:14:38,949
okay VM environment we use to be sub

00:14:36,550 --> 00:14:40,839
transport drivers the Vertigo transport

00:14:38,949 --> 00:14:45,850
running in the guest and the V host

00:14:40,839 --> 00:14:48,610
transport in the host about the V sock

00:14:45,850 --> 00:14:51,399
Linux drivers the story of the shock in

00:14:48,610 --> 00:14:53,350
the Linux three starts in 2013 when the

00:14:51,399 --> 00:14:57,790
first implementation was merged with the

00:14:53,350 --> 00:15:00,990
VM CI transport then in 2016 the rear

00:14:57,790 --> 00:15:03,010
tire and B host transport were added and

00:15:00,990 --> 00:15:06,120
in 2017

00:15:03,010 --> 00:15:08,680
it was also had the hyper-v transport

00:15:06,120 --> 00:15:11,949
this of the changes in the last year we

00:15:08,680 --> 00:15:13,390
had 45 comets from 16 developers I put

00:15:11,949 --> 00:15:15,579
some statistics for employer

00:15:13,390 --> 00:15:18,190
regards the entire vizac subsystem

00:15:15,579 --> 00:15:20,890
including the missile core and all its

00:15:18,190 --> 00:15:24,640
transport BMC hi vertigo we host and I

00:15:20,890 --> 00:15:27,399
repeat so this changes made in regard

00:15:24,640 --> 00:15:29,110
fixes we fix at several bugs races

00:15:27,399 --> 00:15:31,000
memory leaks in the core in the trance

00:15:29,110 --> 00:15:34,209
and the transport but focusing on

00:15:31,000 --> 00:15:36,010
vertigo we host transport in addition to

00:15:34,209 --> 00:15:38,579
the fixes we also improved the

00:15:36,010 --> 00:15:41,680
performance with small changes that

00:15:38,579 --> 00:15:43,750
allow us to gain throughput what we did

00:15:41,680 --> 00:15:46,320
was to reduce the number of credit

00:15:43,750 --> 00:15:50,350
update messages exchanging between

00:15:46,320 --> 00:15:53,769
guests and O's and we increase it the

00:15:50,350 --> 00:15:56,890
sides of packets cube so the first

00:15:53,769 --> 00:15:59,440
improvement can regards the credit basic

00:15:56,890 --> 00:16:02,890
flow control implemented in the Vertigo

00:15:59,440 --> 00:16:07,390
we sought devices to provide relabel

00:16:02,890 --> 00:16:09,640
connection HP r stores this variables in

00:16:07,390 --> 00:16:11,800
the circuit state and exchange some of

00:16:09,640 --> 00:16:13,930
them with the harder pair to update it

00:16:11,800 --> 00:16:19,750
about the status of the receiving queue

00:16:13,930 --> 00:16:21,970
and this two variables are exchanges in

00:16:19,750 --> 00:16:24,699
every packet header or with an explicit

00:16:21,970 --> 00:16:27,430
message that only updates the credit

00:16:24,699 --> 00:16:29,920
available without carrying any data so

00:16:27,430 --> 00:16:32,529
using local variables plus plus those

00:16:29,920 --> 00:16:35,529
receive it from the remote peer we are

00:16:32,529 --> 00:16:37,660
able to reconstruct the status of the

00:16:35,529 --> 00:16:40,329
receiving the remote receiving queue and

00:16:37,660 --> 00:16:42,699
we can calculate the available credit in

00:16:40,329 --> 00:16:45,490
this way we can stop sending bytes when

00:16:42,699 --> 00:16:49,899
we have no more credit in the next slide

00:16:45,490 --> 00:16:52,360
we will use this credit box that show

00:16:49,899 --> 00:16:54,370
the status of the credit the white part

00:16:52,360 --> 00:16:58,380
is the available credit and the red part

00:16:54,370 --> 00:17:01,779
is the credit already used so in the

00:16:58,380 --> 00:17:03,880
previous implementation the receiver in

00:17:01,779 --> 00:17:05,740
this case the pure to send

00:17:03,880 --> 00:17:08,709
credit update messages to the

00:17:05,740 --> 00:17:10,990
transmitter every time the user consumed

00:17:08,709 --> 00:17:13,990
any bites from the receiving queue so a

00:17:10,990 --> 00:17:17,410
lot of messages were exchanged to reduce

00:17:13,990 --> 00:17:20,260
these messages we put a trash on this

00:17:17,410 --> 00:17:23,559
line in the credit box and that means

00:17:20,260 --> 00:17:26,919
that in this case the receiver sent the

00:17:23,559 --> 00:17:29,270
credit update messages only when the

00:17:26,919 --> 00:17:31,340
the credit available seen by the

00:17:29,270 --> 00:17:34,240
transmitter so the white part in the

00:17:31,340 --> 00:17:37,190
credit box is less than the threshold

00:17:34,240 --> 00:17:38,720
however we continue to update the

00:17:37,190 --> 00:17:41,690
hardware Pierre when we have to send

00:17:38,720 --> 00:17:43,070
some data because in every packet eaters

00:17:41,690 --> 00:17:46,640
there are the fields for this

00:17:43,070 --> 00:17:49,220
information the other improvements

00:17:46,640 --> 00:17:51,470
concerned the sending path in the

00:17:49,220 --> 00:17:53,179
picture there is a sketch of the part of

00:17:51,470 --> 00:17:56,600
the path that the packet must follow to

00:17:53,179 --> 00:18:00,080
be same starting from the user space to

00:17:56,600 --> 00:18:02,900
to the device so the B sock stream send

00:18:00,080 --> 00:18:05,419
the message the send Cole back in the B

00:18:02,900 --> 00:18:07,610
so core called multiple time the Vertigo

00:18:05,419 --> 00:18:09,520
transport stream main queue to send an

00:18:07,610 --> 00:18:12,350
entire buffer coming from the user space

00:18:09,520 --> 00:18:14,480
that's because the birthday Etruscan

00:18:12,350 --> 00:18:16,900
streaming queue creates limited size of

00:18:14,480 --> 00:18:19,909
packet and this limit was 4 kilobytes

00:18:16,900 --> 00:18:22,700
because this part of code is in common

00:18:19,909 --> 00:18:25,730
between guests and those drivers and the

00:18:22,700 --> 00:18:28,580
host is limited to 4 kilobytes buffer

00:18:25,730 --> 00:18:32,360
pre allocated by the guests so in order

00:18:28,580 --> 00:18:34,909
to improve the throughput we increase it

00:18:32,360 --> 00:18:37,400
the size of the packet generated by the

00:18:34,909 --> 00:18:39,200
vertical transport streaming queue to 64

00:18:37,400 --> 00:18:43,159
kilobytes the maximum packet size

00:18:39,200 --> 00:18:45,679
handled by vertebras of devices and we

00:18:43,159 --> 00:18:47,990
change the host driver to split large

00:18:45,679 --> 00:18:50,210
buckets according to the size of the

00:18:47,990 --> 00:18:53,990
buffer be allocated by the guest which

00:18:50,210 --> 00:18:56,900
still are 4 kilobytes this also allowed

00:18:53,990 --> 00:18:59,690
the guest to send up to 64 kilobyte

00:18:56,900 --> 00:19:01,429
packet directly to the host we plan

00:18:59,690 --> 00:19:03,950
another improvement to explore like to

00:19:01,429 --> 00:19:07,250
enable buffer size multiple buffers but

00:19:03,950 --> 00:19:09,200
there is no time to discuss them now so

00:19:07,250 --> 00:19:11,840
these two improvements were included in

00:19:09,200 --> 00:19:13,850
this patch in the series a method

00:19:11,840 --> 00:19:17,690
upstream that will be released with

00:19:13,850 --> 00:19:20,470
linux 5.4 during the development of the

00:19:17,690 --> 00:19:22,940
the series we discovered an huge memory

00:19:20,470 --> 00:19:29,030
usage with small pocket in the guest

00:19:22,940 --> 00:19:31,039
when it to receive a small packet and so

00:19:29,030 --> 00:19:34,460
we headed a patch to limit the memory

00:19:31,039 --> 00:19:38,820
use it adding an extra copy to avoid

00:19:34,460 --> 00:19:41,820
this this huge memory consumption

00:19:38,820 --> 00:19:44,279
this or the result for the gas to host

00:19:41,820 --> 00:19:46,169
communication so there is this is the

00:19:44,279 --> 00:19:48,509
true put we the blue line is the

00:19:46,169 --> 00:19:53,849
reference is the status before the

00:19:48,509 --> 00:19:57,359
series the red line using the heading

00:19:53,849 --> 00:19:59,579
the extra copy for the small packets the

00:19:57,359 --> 00:20:03,229
green line reducing the crate update

00:19:59,579 --> 00:20:06,029
messages and finally the light blue line

00:20:03,229 --> 00:20:08,759
using 64 kilobytes pocket in the sending

00:20:06,029 --> 00:20:10,469
pot so they are community that means

00:20:08,759 --> 00:20:14,089
that the light blue line includes all

00:20:10,469 --> 00:20:16,229
the patch in the series and we have a

00:20:14,089 --> 00:20:18,690
big boost especially with the last

00:20:16,229 --> 00:20:21,029
change because now the guest can send up

00:20:18,690 --> 00:20:24,089
to 64 kilobytes instead of 4 kilobytes

00:20:21,029 --> 00:20:25,769
directly to the host these are the same

00:20:24,089 --> 00:20:27,869
result but for the host to gas

00:20:25,769 --> 00:20:30,029
communication as you can see here we

00:20:27,869 --> 00:20:31,979
don't we don't have the peak as in the

00:20:30,029 --> 00:20:34,649
previous results because we are the

00:20:31,979 --> 00:20:37,619
guest is still using 4 kilobytes buffer

00:20:34,649 --> 00:20:39,269
we are located by the gas but we can see

00:20:37,619 --> 00:20:43,589
a better improvement

00:20:39,269 --> 00:20:49,769
thanks to reducing of the quality update

00:20:43,589 --> 00:20:52,109
messages these are some ok we can talk

00:20:49,769 --> 00:20:54,419
about now that about tools and languages

00:20:52,109 --> 00:20:56,909
that support pisaq on the Left we have

00:20:54,419 --> 00:20:58,979
useful tools that introduced the visual

00:20:56,909 --> 00:21:01,739
support in the last few here with this

00:20:58,979 --> 00:21:03,749
tool we can dump traffic statistics we

00:21:01,739 --> 00:21:07,139
can test the host to guest communication

00:21:03,749 --> 00:21:09,959
we can access block devices using MBD

00:21:07,139 --> 00:21:12,749
and we saw or we can measure the

00:21:09,959 --> 00:21:14,849
performance with high path on the right

00:21:12,749 --> 00:21:18,179
we have some of the languages that allow

00:21:14,849 --> 00:21:20,339
us to write application using visual

00:21:18,179 --> 00:21:24,629
sockets so they mainly provides the

00:21:20,339 --> 00:21:26,039
binding for the visa card dressing these

00:21:24,629 --> 00:21:26,639
are the next steps that we want to

00:21:26,039 --> 00:21:28,529
follow

00:21:26,639 --> 00:21:31,799
first of all multiple transport to

00:21:28,529 --> 00:21:34,649
support nested we hams the other slides

00:21:31,799 --> 00:21:36,690
to talk about that and another step is

00:21:34,649 --> 00:21:39,449
network namespace to create independent

00:21:36,690 --> 00:21:41,579
address domains that could be useful for

00:21:39,449 --> 00:21:44,759
example to partition Bham in different

00:21:41,579 --> 00:21:47,279
domains or in a nested VM environment to

00:21:44,759 --> 00:21:49,219
isolate cost application from guest

00:21:47,279 --> 00:21:51,470
application bound to the same port

00:21:49,219 --> 00:21:56,030
another step

00:21:51,470 --> 00:21:58,370
could be the the usage of Bertha Annette

00:21:56,030 --> 00:22:00,440
is a transport of birthday on birthday

00:21:58,370 --> 00:22:03,170
you'll be sought to avoid your implement

00:22:00,440 --> 00:22:07,750
features already done inverter unit like

00:22:03,170 --> 00:22:10,370
Mirabal buffers about the nested we hams

00:22:07,750 --> 00:22:14,470
the problem that we have now is that the

00:22:10,370 --> 00:22:17,390
current implementation allow only one

00:22:14,470 --> 00:22:19,730
transport model loaded at runtime so in

00:22:17,390 --> 00:22:21,800
a nested VM environment we can't load

00:22:19,730 --> 00:22:24,410
birthday transported via host transport

00:22:21,800 --> 00:22:26,930
together so for this reason we need the

00:22:24,410 --> 00:22:29,360
multi transport support I already sent

00:22:26,930 --> 00:22:31,640
some patches upstream we are still

00:22:29,360 --> 00:22:33,200
working on it but in this planning and

00:22:31,640 --> 00:22:34,880
implementation we are allowed to load

00:22:33,200 --> 00:22:38,210
the visual coreg artless of the

00:22:34,880 --> 00:22:40,640
transport and now the core is able to

00:22:38,210 --> 00:22:42,830
handle two type of transport the host to

00:22:40,640 --> 00:22:45,200
gas transport that handles the host part

00:22:42,830 --> 00:22:48,830
in the communication and in this case in

00:22:45,200 --> 00:22:51,530
the Cuomo cavium case is the V host

00:22:48,830 --> 00:22:53,720
transport and the harder type of

00:22:51,530 --> 00:22:56,120
transfer is guest to host that handles

00:22:53,720 --> 00:22:58,490
the harder parts of the guest part in

00:22:56,120 --> 00:23:01,910
the communication and in our case is

00:22:58,490 --> 00:23:04,880
that Bertha your transport each stream

00:23:01,910 --> 00:23:07,610
socket is a sanitary transport when the

00:23:04,880 --> 00:23:10,070
remote jet is known and because we are

00:23:07,610 --> 00:23:12,680
using the remote CID to decide which

00:23:10,070 --> 00:23:14,870
transport to use and it happens during a

00:23:12,680 --> 00:23:17,600
connect because the user specified the

00:23:14,870 --> 00:23:19,820
remote CID to connect to cork when we

00:23:17,600 --> 00:23:21,380
receive a connection request an

00:23:19,820 --> 00:23:24,340
Easterner socket because in this case

00:23:21,380 --> 00:23:26,840
the remote CD is the CID of the register

00:23:24,340 --> 00:23:30,140
listener socket are not bound to any

00:23:26,840 --> 00:23:32,180
transport so they can recreate read they

00:23:30,140 --> 00:23:35,570
can be created also if the transport are

00:23:32,180 --> 00:23:38,630
not loaded or using vml to see the any

00:23:35,570 --> 00:23:41,000
traditional transport concluding this

00:23:38,630 --> 00:23:43,090
work is starting to be used and well

00:23:41,000 --> 00:23:45,560
supported and we are trying to improve

00:23:43,090 --> 00:23:48,140
visual core and Verteron B host

00:23:45,560 --> 00:23:52,960
transport to make it more robust and

00:23:48,140 --> 00:23:52,960
performing question

00:23:58,380 --> 00:24:06,160
could you go to slide I think 24 or 23

00:24:02,110 --> 00:24:07,390
oh sorry no about 25 actually so just

00:24:06,160 --> 00:24:11,050
very quick comment

00:24:07,390 --> 00:24:14,410
FIO now has support for Lib m BD Lib MB

00:24:11,050 --> 00:24:17,380
DS has support for V sock m BD kit has

00:24:14,410 --> 00:24:21,100
support for V sock and for RAM disks so

00:24:17,380 --> 00:24:24,550
you can now use fio2 test performance

00:24:21,100 --> 00:24:27,400
between your host and guest using m BD

00:24:24,550 --> 00:24:30,400
which is extremely efficient and now one

00:24:27,400 --> 00:24:34,570
question as well which is you can't have

00:24:30,400 --> 00:24:35,950
two V Sox on the host one listening and

00:24:34,570 --> 00:24:38,230
one connecting they don't connect to

00:24:35,950 --> 00:24:41,800
each other do you mean look back yeah

00:24:38,230 --> 00:24:47,020
like a loopback between two hosts yes an

00:24:41,800 --> 00:24:49,660
imitation I mean because for then the

00:24:47,020 --> 00:24:52,570
problem is the nested VM environment so

00:24:49,660 --> 00:24:54,670
we don't have any for now any hard dress

00:24:52,570 --> 00:24:57,580
to say okay this is a for loop back an

00:24:54,670 --> 00:25:00,100
idea could be to introduce a loopback

00:24:57,580 --> 00:25:02,910
address because for now the only way is

00:25:00,100 --> 00:25:07,570
to use for example in the host use the

00:25:02,910 --> 00:25:09,730
OCAD u but in it could not work on the

00:25:07,570 --> 00:25:12,940
nested bahama moment because the hell

00:25:09,730 --> 00:25:14,320
one cannot reach l0 this is the reason I

00:25:12,940 --> 00:25:24,340
mean that makes it very hard for us to

00:25:14,320 --> 00:25:26,320
actually write tests without quick

00:25:24,340 --> 00:25:30,150
question Oh what is the status of

00:25:26,320 --> 00:25:30,150
Windows driver support for be soaked

00:25:31,560 --> 00:25:37,090
drivers and there is the serial but it's

00:25:34,840 --> 00:25:38,590
not mystic available till now so yeah

00:25:37,090 --> 00:25:40,510
that's what I know about it and I've

00:25:38,590 --> 00:25:43,530
been working as reference on the windows

00:25:40,510 --> 00:25:46,540
side and I think that was like

00:25:43,530 --> 00:25:49,960
discussion with with the machinist there

00:25:46,540 --> 00:25:52,090
and we could add that but there is no

00:25:49,960 --> 00:25:53,830
like traction of why we could use that

00:25:52,090 --> 00:25:54,720
so that we have several these cases and

00:25:53,830 --> 00:25:56,669
convinced

00:25:54,720 --> 00:25:58,980
that on the size of the tool and also

00:25:56,669 --> 00:26:03,390
supported me so yeah but that's what I I

00:25:58,980 --> 00:26:07,530
know what is about different transport

00:26:03,390 --> 00:26:10,650
in host if different transport by type

00:26:07,530 --> 00:26:13,559
if some VMs are running VMware and

00:26:10,650 --> 00:26:18,090
communicate via the embryo transfer some

00:26:13,559 --> 00:26:25,830
transport running Microsoft is being bus

00:26:18,090 --> 00:26:28,950
transport and Linux guest is at once yes

00:26:25,830 --> 00:26:30,990
for we planet as a future work we are we

00:26:28,950 --> 00:26:43,350
thinking about it but for now there is

00:26:30,990 --> 00:26:45,630
no support for this case you mentioned

00:26:43,350 --> 00:26:48,030
that in the beginning to use research to

00:26:45,630 --> 00:26:53,850
communicate between two guests and not

00:26:48,030 --> 00:26:56,460
between guests and house actually the

00:26:53,850 --> 00:26:58,740
primary use case is guest host but I was

00:26:56,460 --> 00:27:01,460
actually asked by several people can we

00:26:58,740 --> 00:27:04,080
have some kind of configuration less

00:27:01,460 --> 00:27:06,150
communication between guests because

00:27:04,080 --> 00:27:07,679
other hypervisors seem to have these

00:27:06,150 --> 00:27:10,080
kind of functionality and would be

00:27:07,679 --> 00:27:12,870
really cool to have the just uses cid

00:27:10,080 --> 00:27:14,820
bit and that you have some kind of known

00:27:12,870 --> 00:27:21,539
guests that can trigger some action and

00:27:14,820 --> 00:27:24,210
some service before but it was i get

00:27:21,539 --> 00:27:26,370
down because could be a potential attack

00:27:24,210 --> 00:27:27,960
surface between the two guest so there

00:27:26,370 --> 00:27:30,960
was an implementation there available

00:27:27,960 --> 00:27:32,549
but it was like not available anymore so

00:27:30,960 --> 00:27:35,039
that's why i also take this into

00:27:32,549 --> 00:27:37,590
discussion because this could be done

00:27:35,039 --> 00:27:43,500
but it's additional implementation in

00:27:37,590 --> 00:27:47,490
addition the problem is the nested Bham

00:27:43,500 --> 00:27:49,049
so if you we can think about this work

00:27:47,490 --> 00:27:52,020
as a point-to-point connection because

00:27:49,049 --> 00:27:54,480
we are not in knowledge in routing or

00:27:52,020 --> 00:27:57,179
something like that so that we are using

00:27:54,480 --> 00:28:01,530
the vm the remote cid to know if there

00:27:57,179 --> 00:28:04,460
isn't a theorem or there's someone

00:28:01,530 --> 00:28:06,769
talking to a cid either than the host

00:28:04,460 --> 00:28:08,720
have this packets round to the other so

00:28:06,769 --> 00:28:10,480
the current implementation doesn't know

00:28:08,720 --> 00:28:14,179
to do that

00:28:10,480 --> 00:28:18,769
hi on the slide about the UNIX domain

00:28:14,179 --> 00:28:22,730
sockets the the graph the performance

00:28:18,769 --> 00:28:24,740
compares various TX buffer sizes and I

00:28:22,730 --> 00:28:28,369
didn't I didn't quite understand so is

00:28:24,740 --> 00:28:32,149
that TX buffer size is that the UNIX

00:28:28,369 --> 00:28:34,940
domain sockets send buff like sock opt

00:28:32,149 --> 00:28:38,570
is it the kernel host kernel is that the

00:28:34,940 --> 00:28:41,179
buffer size when you have the packet

00:28:38,570 --> 00:28:42,889
from the water V so device if the host

00:28:41,179 --> 00:28:44,389
cannot hope to get that packets

00:28:42,889 --> 00:28:46,190
immediately there is a ring buffer

00:28:44,389 --> 00:28:47,869
available so that we can immediately

00:28:46,190 --> 00:28:49,909
when we receive the packet from the

00:28:47,869 --> 00:28:53,509
guest side on the water base or device

00:28:49,909 --> 00:28:55,610
we process it and if the host cannot get

00:28:53,509 --> 00:28:57,590
to the packet at the time we push it in

00:28:55,610 --> 00:29:00,169
the ring buffer and the rig buffering of

00:28:57,590 --> 00:29:02,179
this takes buffer size so it's on that

00:29:00,169 --> 00:29:05,450
path on the receive path there is no

00:29:02,179 --> 00:29:08,450
buffer because we send directly the data

00:29:05,450 --> 00:29:10,330
from the unis Thomas okay stream in the

00:29:08,450 --> 00:29:13,340
Eric box

00:29:10,330 --> 00:29:15,830
so do you do UNIX domain sockets not

00:29:13,340 --> 00:29:18,080
supports and Bob because it seems the

00:29:15,830 --> 00:29:21,289
kernel already has this functionality

00:29:18,080 --> 00:29:23,720
and if you also reflect that buffer size

00:29:21,289 --> 00:29:25,940
in in the credit mechanism then I guess

00:29:23,720 --> 00:29:27,980
you you would maybe never end up in a

00:29:25,940 --> 00:29:31,009
situation where the guest was send more

00:29:27,980 --> 00:29:33,139
than you're prepared to receive then the

00:29:31,009 --> 00:29:35,210
host can can be able to receive via and

00:29:33,139 --> 00:29:37,789
if we cannot cope with that we include

00:29:35,210 --> 00:29:40,129
that packet and that they time can be

00:29:37,789 --> 00:29:43,070
processed later okay it should be that

00:29:40,129 --> 00:29:47,240
that possibility and actually when I've

00:29:43,070 --> 00:29:49,100
done the performance evaluation if I did

00:29:47,240 --> 00:29:50,990
not get the socket and the receive

00:29:49,100 --> 00:29:54,710
buffer zone the host ID high enough I

00:29:50,990 --> 00:29:56,929
would have had less so performance less

00:29:54,710 --> 00:30:00,139
stupid because it would have been

00:29:56,929 --> 00:30:02,409
impacted by by the buffer size okay

00:30:00,139 --> 00:30:02,409
thank you

00:30:06,000 --> 00:30:11,200
it's like no more questions so thank you

00:30:09,370 --> 00:30:14,420
okay thanks

00:30:11,200 --> 00:30:21,279
[Applause]

00:30:14,420 --> 00:30:21,279

YouTube URL: https://www.youtube.com/watch?v=LFqz-VZPhFE


