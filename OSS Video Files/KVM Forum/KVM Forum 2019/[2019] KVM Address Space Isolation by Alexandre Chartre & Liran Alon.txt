Title: [2019] KVM Address Space Isolation by Alexandre Chartre & Liran Alon
Publication date: 2019-11-09
Playlist: KVM Forum 2019
Description: 
	Recent vulnerabilities like L1 Terminal Fault (L1TF) and Microarchitectural Data Sampling (MDS) have shown that the cpu hyper-threading architecture is prone to leaking data with speculative execution attacks.

With KVM, a guest VM can use speculative execution attacks to leak data from the sibling hyper-thread, thus potentially accessing data from the host kernel, from the hypervisor or from another VM.

Kernel Address Space Isolation is a project aims to use address spaces to isolate some parts of the kernel to prevent leaking sensitive data. If KVM can be run in an address space containing no sensitive data, and separated from the full kernel address space, then KVM would be immune from leaking secrets.

A first proposal to implement KVM Address Space Isolation and early discussions are available here: https://lkml.org/lkml/2019/5/13/515

---

Liran Alon
Oracle
Virtualization Architect

Liran Alon is the Virtualization Architect of OCI Israel (Oracle Cloud Infrastructure).

He is involved and lead projects in multiple areas of the company's public cloud offering such as Compute, Networking and Virtualization.
In addition, Liran is a very active KVM contributor (mostly, but not limited to, nVMX).

He has been involved in the past few years in advancing state-of-the-art of KVM nested-virtualization and the adjustment of QEMU/SeaBIOS/OVMF to support VMs from other hypervisors. In addition he worked on, and lead, the development of Oracle Ravello's propriety binary-translation hypervisor, which is optimized to run as a nested-hypervisor (on top of the public cloud) and able to expose AMD SVM with NPT (on CPU with no HW virt-extensions), and many more virtualization challenges.

Previous to his work at Oracle, Liran has worked for over 6 years as Security Researcher & Developer for Israel PMO & IDF. There he has gained vast experience on OS Internals (Windows & Linux), kernel development, x86 architecture,
reverse-engineering, vulnerabilities, exploits, exploit mitigations and security-products internals.

Liran has a B.Sc. in Computer Science From Tel-Aviv University. In addition, he regularly lectures on various OS Internals courses.

Alexandre Chartre
Oracle

Senior Principal Engineer - Oracle Linux and VIrtualization
Alexandre Chartre is a Senior Principal Engineer in the Linux and Virtualization engineering team at Oracle. Lately, he has been focusing on security issues on Linux, in particular on Spectre and Meltdown issues (and all variants and derivatives) and their impact on virtualization and KVM in particular. Alexandre has more than 20 years experience in kernel development and virtualization, more recently with Linux and KVM on x86 systems, and previously with Solaris and Logical Domains (LDoms) on SPARC systems.
Captions: 
	00:00:00,390 --> 00:00:02,750
[Music]

00:00:06,799 --> 00:00:13,769
hi everybody my name is LaRon this is

00:00:12,090 --> 00:00:16,800
Alex and we're going to present to you

00:00:13,769 --> 00:00:18,570
today about kvms I wear a size stands

00:00:16,800 --> 00:00:21,600
for other spaces today at the special

00:00:18,570 --> 00:00:23,970
solution so who are we just a short

00:00:21,600 --> 00:00:25,920
introduction so I'm an architect at LCI

00:00:23,970 --> 00:00:27,660
which is Oracle public cloud offering I

00:00:25,920 --> 00:00:29,640
come with a background of cloud

00:00:27,660 --> 00:00:31,199
computing and virtual networking and

00:00:29,640 --> 00:00:33,239
previously I have worked for many years

00:00:31,199 --> 00:00:34,920
in the cyber security area and I'm

00:00:33,239 --> 00:00:36,180
currently an active KVM contributor

00:00:34,920 --> 00:00:38,100
especially around the news

00:00:36,180 --> 00:00:39,989
virtualization and I'm very active

00:00:38,100 --> 00:00:42,809
Twitter yourself so feel free to follow

00:00:39,989 --> 00:00:44,610
me or direct messages any time and this

00:00:42,809 --> 00:00:45,840
is Alex he is a senior principal

00:00:44,610 --> 00:00:47,430
engineer in Oracle Linux in

00:00:45,840 --> 00:00:49,230
virtualization cool and we have

00:00:47,430 --> 00:00:52,530
extensive experience in every television

00:00:49,230 --> 00:00:55,050
content in general and so what are we

00:00:52,530 --> 00:00:56,760
going to talk about today so we will

00:00:55,050 --> 00:00:58,230
start with a very brief background about

00:00:56,760 --> 00:01:00,300
what is the problem we are attempting to

00:00:58,230 --> 00:01:02,579
solve which is L 1 TF hyper fighting

00:01:00,300 --> 00:01:04,350
attack scenario and but we want deep

00:01:02,579 --> 00:01:05,700
dive into the details of L 1 TF because

00:01:04,350 --> 00:01:06,810
we don't need to understand that in

00:01:05,700 --> 00:01:09,240
order to understand the rest of the

00:01:06,810 --> 00:01:11,340
presentation and after we understand the

00:01:09,240 --> 00:01:13,680
problem that we are trying to solve we

00:01:11,340 --> 00:01:15,750
will number 8 various community attempts

00:01:13,680 --> 00:01:18,000
to in order to mitigate this and we'll

00:01:15,750 --> 00:01:19,680
analyze what did they do good and what

00:01:18,000 --> 00:01:21,930
did they do well and this will lead us

00:01:19,680 --> 00:01:24,119
to present a new proposal which is kV

00:01:21,930 --> 00:01:26,310
MSI on how to maybe mitigate this issue

00:01:24,119 --> 00:01:27,960
and only if time will permit and it

00:01:26,310 --> 00:01:31,619
probably won't because we have only half

00:01:27,960 --> 00:01:34,950
an hour I will show also a glimpse of a

00:01:31,619 --> 00:01:37,229
new mitigation we also think about so

00:01:34,950 --> 00:01:39,780
let's start with the background the path

00:01:37,229 --> 00:01:41,369
so the only thing you need to understand

00:01:39,780 --> 00:01:43,229
about element EF in order to understand

00:01:41,369 --> 00:01:44,759
the rest of the presentation is what the

00:01:43,229 --> 00:01:46,890
primitives that it provides for the

00:01:44,759 --> 00:01:48,240
attacker so the pivot is the primitive

00:01:46,890 --> 00:01:50,759
that it provides to the attacker that

00:01:48,240 --> 00:01:52,530
you need to assume is that I guess an

00:01:50,759 --> 00:01:54,600
attacker running code inside the guest

00:01:52,530 --> 00:01:56,939
can use this vulnerability to basically

00:01:54,600 --> 00:02:00,360
leak any any host data to this currently

00:01:56,939 --> 00:02:02,490
president the l1d cache and now sorry

00:02:00,360 --> 00:02:04,860
now the way that Intel me try to

00:02:02,490 --> 00:02:07,409
mitigate this vulnerability is not buys

00:02:04,860 --> 00:02:09,149
a doing some kind of change that

00:02:07,409 --> 00:02:11,730
prevents the guest from actually using

00:02:09,149 --> 00:02:13,180
l1 TF but instead they provided this new

00:02:11,730 --> 00:02:15,250
CPU microcode

00:02:13,180 --> 00:02:17,439
basically expose a new Amissah that

00:02:15,250 --> 00:02:19,480
allows you to allows you to modify the

00:02:17,439 --> 00:02:21,219
hypervisor such that before every time

00:02:19,480 --> 00:02:24,250
you enter to the guest the hypervisor

00:02:21,219 --> 00:02:25,870
such as KVM can flush the l1d cache just

00:02:24,250 --> 00:02:27,519
before entering to the guest so the

00:02:25,870 --> 00:02:29,230
guests can still leave the entire l1d

00:02:27,519 --> 00:02:32,730
cache but now it doesn't contain any

00:02:29,230 --> 00:02:35,500
more hosts populated data and now the

00:02:32,730 --> 00:02:37,629
way that this mitigation breaks is when

00:02:35,500 --> 00:02:39,489
you consider hyper threading so the

00:02:37,629 --> 00:02:41,590
problem with hyper threading is that it

00:02:39,489 --> 00:02:43,900
turns out that the l1d cache is actually

00:02:41,590 --> 00:02:46,150
a shared between the hyper threads on

00:02:43,900 --> 00:02:47,859
the same cpu call and this creates two

00:02:46,150 --> 00:02:50,919
different problematic scenarios shown

00:02:47,859 --> 00:02:54,250
above so one of them the the one shown

00:02:50,919 --> 00:02:55,090
here is basically a CPU code that has a

00:02:54,250 --> 00:02:57,129
two hyperfest

00:02:55,090 --> 00:02:59,500
and each one of them runs a virtual CPU

00:02:57,129 --> 00:03:01,359
task of the different VM now the problem

00:02:59,500 --> 00:03:03,760
is is that while the one hyper fed

00:03:01,359 --> 00:03:06,489
populates the l1d cache with data of one

00:03:03,760 --> 00:03:08,560
VM the cycling hyper fed that runs a

00:03:06,489 --> 00:03:10,150
different VM can use that one TF to lick

00:03:08,560 --> 00:03:10,989
that data because it's shared between

00:03:10,150 --> 00:03:12,790
the high preference

00:03:10,989 --> 00:03:15,310
so this basically breaks the security

00:03:12,790 --> 00:03:17,139
isolation between the VMS so and this is

00:03:15,310 --> 00:03:19,510
the first problematic scenario so the

00:03:17,139 --> 00:03:21,940
second attack vector is that even if

00:03:19,510 --> 00:03:25,030
both hyper fades on the same CPU call on

00:03:21,940 --> 00:03:26,530
a virtual CPU tasks of the same VM then

00:03:25,030 --> 00:03:28,120
still we can reach a scenario that one

00:03:26,530 --> 00:03:29,799
hyper Fred is running inside the guest

00:03:28,120 --> 00:03:31,810
when it's cycling hyper fred is

00:03:29,799 --> 00:03:33,579
currently running a VM exit tender

00:03:31,810 --> 00:03:35,680
because it includes some exit condition

00:03:33,579 --> 00:03:37,180
now the problem is is that the moment

00:03:35,680 --> 00:03:39,189
that the VM exit tend to read something

00:03:37,180 --> 00:03:40,930
from the virtual address space it

00:03:39,189 --> 00:03:42,699
populates the l1d cache and at the

00:03:40,930 --> 00:03:44,650
moment that the l1d cache is populated

00:03:42,699 --> 00:03:46,780
it's cycling hyper fed that still runs

00:03:44,650 --> 00:03:49,540
inside the guests can use l1 TF to lick

00:03:46,780 --> 00:03:51,430
that data even if the AVM exit handle

00:03:49,540 --> 00:03:54,069
will flush it when it will reenter into

00:03:51,430 --> 00:03:55,540
the guest that will be too late so this

00:03:54,069 --> 00:03:56,680
is basically the two attack vectors that

00:03:55,540 --> 00:04:00,400
will try to mitigate in this

00:03:56,680 --> 00:04:02,229
presentation and now one cool I argued

00:04:00,400 --> 00:04:04,599
that let's just disable hyper fighting

00:04:02,229 --> 00:04:06,790
it's a valid mitigation so yeah this is

00:04:04,599 --> 00:04:08,560
a valid investigation it works however

00:04:06,790 --> 00:04:10,180
it doesn't fit well all the production

00:04:08,560 --> 00:04:12,459
use cases for example when you consider

00:04:10,180 --> 00:04:14,109
the public cloud applying such a

00:04:12,459 --> 00:04:15,729
mitigation we basically cause the public

00:04:14,109 --> 00:04:18,669
cloud to you to lose half of its compute

00:04:15,729 --> 00:04:21,009
capacity so this leads to revenue loss

00:04:18,669 --> 00:04:23,800
and therefore it's not a well feed

00:04:21,009 --> 00:04:25,240
solution for all the use cases and so

00:04:23,800 --> 00:04:25,790
for the rest of the presentation we'll

00:04:25,240 --> 00:04:27,560
assume that

00:04:25,790 --> 00:04:29,870
we want to mitigate attacks and nails

00:04:27,560 --> 00:04:32,180
even with keeping a hyper fielding

00:04:29,870 --> 00:04:33,500
enabled so now after we understand this

00:04:32,180 --> 00:04:35,720
background we can talk about various

00:04:33,500 --> 00:04:38,630
attempts at which attempted to mitigate

00:04:35,720 --> 00:04:40,820
this issue so first a disclaimer all the

00:04:38,630 --> 00:04:43,340
things I'm going to show right now I'll

00:04:40,820 --> 00:04:45,890
just proposal none of them get been a

00:04:43,340 --> 00:04:48,950
major upstream so just take note of that

00:04:45,890 --> 00:04:51,650
and and we already had a talk yesterday

00:04:48,950 --> 00:04:53,150
about call scheduling and so this is a

00:04:51,650 --> 00:04:54,920
mechanism that can be used to mitigate

00:04:53,150 --> 00:04:57,020
the first attack scenario that represent

00:04:54,920 --> 00:04:58,460
them so basically it's a new schedule or

00:04:57,020 --> 00:05:01,520
policy that allows you to group together

00:04:58,460 --> 00:05:03,230
a bunch of tasks by giving them the same

00:05:01,520 --> 00:05:05,510
let's call it a security domain ID and

00:05:03,230 --> 00:05:07,730
that's the new schedule policy will

00:05:05,510 --> 00:05:10,400
basically guarantee that does that have

00:05:07,730 --> 00:05:12,890
different domain IDs will never run a

00:05:10,400 --> 00:05:14,660
cycling hyper feeds on the same call so

00:05:12,890 --> 00:05:16,670
in our context we can use that to tag

00:05:14,660 --> 00:05:19,130
the virtual CPU tasks of different VMs

00:05:16,670 --> 00:05:21,530
with different humanities and therefore

00:05:19,130 --> 00:05:23,330
the left sinner can never happen anymore

00:05:21,530 --> 00:05:25,760
and will only left with the scenario

00:05:23,330 --> 00:05:28,190
that both hyper phase of the same CPU

00:05:25,760 --> 00:05:30,380
call runs the same virtual CPU toss of

00:05:28,190 --> 00:05:31,820
the same VM and so this mitigates

00:05:30,380 --> 00:05:33,800
completely the first scenario and

00:05:31,820 --> 00:05:35,150
therefore from this point on what we'll

00:05:33,800 --> 00:05:37,910
only talk about the second scenario

00:05:35,150 --> 00:05:39,560
which is more complex to mitigate so

00:05:37,910 --> 00:05:42,320
just to reiterate what was the second

00:05:39,560 --> 00:05:44,510
scenario and we have a single CPU code

00:05:42,320 --> 00:05:46,910
that have two high profits both of them

00:05:44,510 --> 00:05:48,350
run virtual CPU tests of the same VM but

00:05:46,910 --> 00:05:50,030
one is running inside the guest while

00:05:48,350 --> 00:05:52,340
the other is running a VM exit changer

00:05:50,030 --> 00:05:54,440
and the problem is is that the VM exit

00:05:52,340 --> 00:05:57,200
handler if any read operation that it

00:05:54,440 --> 00:05:59,360
does it reads something from the virtual

00:05:57,200 --> 00:06:01,040
address space and it populates their one

00:05:59,360 --> 00:06:02,840
D cash at the moment this data is

00:06:01,040 --> 00:06:05,300
populated to the l1d cache it's lickable

00:06:02,840 --> 00:06:07,610
by L 1 TF from the solving hyper FET

00:06:05,300 --> 00:06:09,440
that still runs inside the guest now one

00:06:07,610 --> 00:06:12,110
could argue that the VM exit handler

00:06:09,440 --> 00:06:13,670
should access a information that is only

00:06:12,110 --> 00:06:15,710
relevant for this VM anyway and

00:06:13,670 --> 00:06:18,040
therefore this is not an issue however

00:06:15,710 --> 00:06:21,410
if you consider a speculative execution

00:06:18,040 --> 00:06:23,570
this is not true because think of it

00:06:21,410 --> 00:06:26,150
think that the VM a considered the case

00:06:23,570 --> 00:06:28,250
that the VM exit tender and have an if

00:06:26,150 --> 00:06:31,310
the checks a if some read operation is

00:06:28,250 --> 00:06:33,320
going to happen in bounds and if is that

00:06:31,310 --> 00:06:35,330
true it will do the read operation now

00:06:33,320 --> 00:06:37,250
the CPU can miss predict this branch and

00:06:35,330 --> 00:06:38,960
do the read operation anyway in a

00:06:37,250 --> 00:06:41,090
speculative execution manner

00:06:38,960 --> 00:06:43,310
and the the speculative execution rate

00:06:41,090 --> 00:06:44,930
will also populate their 1d cache so it

00:06:43,310 --> 00:06:49,280
basically means that we it will allow

00:06:44,930 --> 00:06:51,740
the guest to read out of bounds so this

00:06:49,280 --> 00:06:53,449
this leads us to the only conclusion

00:06:51,740 --> 00:06:55,970
that everything individual address space

00:06:53,449 --> 00:06:57,229
can be licked by this technique and the

00:06:55,970 --> 00:06:59,660
only way that we can actually mitigate

00:06:57,229 --> 00:07:01,789
this attack scenario is by reducing the

00:06:59,660 --> 00:07:03,470
sensitive information that we don't want

00:07:01,789 --> 00:07:04,910
to be lift from the virtual address

00:07:03,470 --> 00:07:09,169
space in which the VM exits handle

00:07:04,910 --> 00:07:11,210
executing and so in order to follow with

00:07:09,169 --> 00:07:13,460
that idea we first need to have a look

00:07:11,210 --> 00:07:15,259
at how the wheels on outer space of a VM

00:07:13,460 --> 00:07:17,690
exit handle looks like so this is a

00:07:15,259 --> 00:07:19,520
village to market a schematic diagram

00:07:17,690 --> 00:07:21,289
so I'd say upper part you see the user

00:07:19,520 --> 00:07:24,110
space portion and the bottom you see the

00:07:21,289 --> 00:07:25,970
ACO no space portion so I just emphasize

00:07:24,110 --> 00:07:28,099
in the kernel suppose a space portions

00:07:25,970 --> 00:07:30,770
some example of things that are

00:07:28,099 --> 00:07:33,289
considered sensitive so for example KVA

00:07:30,770 --> 00:07:35,300
maintains level locations of curvature

00:07:33,289 --> 00:07:37,940
cpu stocks which also holds the

00:07:35,300 --> 00:07:41,690
registers of the filter CPUs so this

00:07:37,940 --> 00:07:43,669
virtual a VI region doesn't map only a

00:07:41,690 --> 00:07:46,580
virtual CPUs tracks of this specific

00:07:43,669 --> 00:07:48,770
variable CPU it also mapped the virtual

00:07:46,580 --> 00:07:51,139
CPU stocks of other velocity use on the

00:07:48,770 --> 00:07:53,720
same horse so this also will allow the

00:07:51,139 --> 00:07:57,229
the VM extender to populate the l1d

00:07:53,720 --> 00:07:59,960
cache we say with contact of registers

00:07:57,229 --> 00:08:01,490
of virtual CPUs of other gas therefore

00:07:59,960 --> 00:08:02,900
this is should consider a sensitive

00:08:01,490 --> 00:08:05,570
information that we will want to remove

00:08:02,900 --> 00:08:07,460
from the VI space another example is the

00:08:05,570 --> 00:08:09,979
direct map VL region basically it's a

00:08:07,460 --> 00:08:11,810
very region that map's linearly all the

00:08:09,979 --> 00:08:14,419
physical pages of the host one by one

00:08:11,810 --> 00:08:16,340
and these physical pages also includes

00:08:14,419 --> 00:08:18,229
the physical pages that are used to back

00:08:16,340 --> 00:08:19,909
the memory of other guests on the horse

00:08:18,229 --> 00:08:21,650
so of course this should be also

00:08:19,909 --> 00:08:25,009
considered sensitive information that we

00:08:21,650 --> 00:08:26,870
don't want it to believe so one example

00:08:25,009 --> 00:08:30,080
of a community attempt in order to

00:08:26,870 --> 00:08:31,729
mitigate this was experience very simple

00:08:30,080 --> 00:08:33,349
it was basically to remove physical

00:08:31,729 --> 00:08:35,450
pages that are only used by user space

00:08:33,349 --> 00:08:36,979
from being mapped with direct map and

00:08:35,450 --> 00:08:40,130
it's originally aimed for a different

00:08:36,979 --> 00:08:41,539
purpose to mitigate asthma bypass

00:08:40,130 --> 00:08:43,370
because you could cause the kernel to

00:08:41,539 --> 00:08:45,860
the reference the direct map instead of

00:08:43,370 --> 00:08:47,570
a user space page however in our context

00:08:45,860 --> 00:08:49,430
it can also be useful to remove the

00:08:47,570 --> 00:08:52,120
pages that are used

00:08:49,430 --> 00:08:55,880
too bad gasps memory from the direct man

00:08:52,120 --> 00:08:58,340
however expect for currently have two

00:08:55,880 --> 00:09:00,590
high performances and for example it -

00:08:58,340 --> 00:09:02,780
we won't be able to map the direct map

00:09:00,590 --> 00:09:05,030
anymore with one gigabyte pities and we

00:09:02,780 --> 00:09:08,060
also it will result in a lot of frequent

00:09:05,030 --> 00:09:10,670
TLB invalidation and so this is illegal

00:09:08,060 --> 00:09:12,380
just one example another example is the

00:09:10,670 --> 00:09:14,570
deposit another pass series which is

00:09:12,380 --> 00:09:17,420
called a post local kill Navy region

00:09:14,570 --> 00:09:19,610
which was submitted by AWS basically the

00:09:17,420 --> 00:09:21,380
idea is that some parts of the kernel

00:09:19,610 --> 00:09:23,390
space map information that is only

00:09:21,380 --> 00:09:25,640
relevant pill process and every process

00:09:23,390 --> 00:09:27,920
has its own page table anyway so why not

00:09:25,640 --> 00:09:29,690
take a region individual other space of

00:09:27,920 --> 00:09:31,280
the color space and make it map

00:09:29,690 --> 00:09:33,440
differently between different processes

00:09:31,280 --> 00:09:35,450
and implementation is extremely trivial

00:09:33,440 --> 00:09:37,460
basically just take a PDD entry and

00:09:35,450 --> 00:09:40,790
define to it a different PFN between

00:09:37,460 --> 00:09:43,000
different tasks however and in our

00:09:40,790 --> 00:09:44,990
context it can be very useful because

00:09:43,000 --> 00:09:46,940
everything that we will map in this

00:09:44,990 --> 00:09:48,500
built reduce region we are guaranteed

00:09:46,940 --> 00:09:50,240
that will be mapped only in this virtual

00:09:48,500 --> 00:09:52,610
CPU toss but won't be mapped in the

00:09:50,240 --> 00:09:54,950
bilges CPU tasks VI space of other VMs

00:09:52,610 --> 00:09:57,380
and therefore everything that is per VM

00:09:54,950 --> 00:09:59,150
opal will show CPU we can make sure to

00:09:57,380 --> 00:10:00,740
map in this V a region in order to hide

00:09:59,150 --> 00:10:03,650
it from being lickable individual

00:10:00,740 --> 00:10:05,510
address space of other VMs so for

00:10:03,650 --> 00:10:07,730
example we can map the Purvi enter will

00:10:05,510 --> 00:10:09,560
show cpu starts the temporal decay maps

00:10:07,730 --> 00:10:11,960
that are done doing vm x simulations

00:10:09,560 --> 00:10:14,450
like mapping the vm cs1 to during vm

00:10:11,960 --> 00:10:17,900
pointer load or came up in general that

00:10:14,450 --> 00:10:20,390
via scan and back ends though and this

00:10:17,900 --> 00:10:23,930
this was after we understand this point

00:10:20,390 --> 00:10:25,400
we can talk about KVM ASI and so

00:10:23,930 --> 00:10:26,420
basically if you look at all the

00:10:25,400 --> 00:10:29,360
mitigation that we have just seen

00:10:26,420 --> 00:10:30,560
basically the idea is that we look at

00:10:29,360 --> 00:10:33,230
the virtual address space that currently

00:10:30,560 --> 00:10:34,760
exists and we try to explicitly spot

00:10:33,230 --> 00:10:36,770
things that are considered sensitive and

00:10:34,760 --> 00:10:38,450
we move it from the address space and

00:10:36,770 --> 00:10:40,490
now the problem is is that this

00:10:38,450 --> 00:10:41,870
approaches is a result of the fact that

00:10:40,490 --> 00:10:44,060
the virtual address space of the vm x

00:10:41,870 --> 00:10:46,670
assembler is coupled with the standard

00:10:44,060 --> 00:10:48,080
view space of the entire host in general

00:10:46,670 --> 00:10:50,030
so they try to modify the memory

00:10:48,080 --> 00:10:51,620
management of the earth in general so a

00:10:50,030 --> 00:10:54,260
different approach can be which is what

00:10:51,620 --> 00:10:55,790
gave him si does to decouple the virtual

00:10:54,260 --> 00:10:58,040
address space that the vm x it handles

00:10:55,790 --> 00:10:59,600
executing from the standard wheelchair

00:10:58,040 --> 00:11:02,240
address space that standard host asked

00:10:59,600 --> 00:11:03,620
to use increment space and and that

00:11:02,240 --> 00:11:06,020
would allow us to create a new virtual

00:11:03,620 --> 00:11:07,610
address space and that is built in a

00:11:06,020 --> 00:11:10,130
whitelist approach that we selectively

00:11:07,610 --> 00:11:13,250
choose what is mapped in that out of the

00:11:10,130 --> 00:11:16,580
space and this was introduced in a last

00:11:13,250 --> 00:11:17,750
year POF and Alex which stands besides

00:11:16,580 --> 00:11:21,830
me here you have done most of the

00:11:17,750 --> 00:11:24,260
implementations since then so regarding

00:11:21,830 --> 00:11:26,480
kvms I just another points about the

00:11:24,260 --> 00:11:28,610
high level idea and then I pass Alex for

00:11:26,480 --> 00:11:30,380
more details is that basically the idea

00:11:28,610 --> 00:11:32,990
is that when you provision a new VM you

00:11:30,380 --> 00:11:35,000
create a new virtual address space that

00:11:32,990 --> 00:11:36,920
only Maps the Perl VM information and

00:11:35,000 --> 00:11:40,400
call kernel mappings like the k vm model

00:11:36,920 --> 00:11:42,140
the Linux kernel model and the ID t the

00:11:40,400 --> 00:11:43,940
GD t the current stack and trampolines

00:11:42,140 --> 00:11:45,800
needed for handling external interrupts

00:11:43,940 --> 00:11:47,000
and then when you enter to the guest for

00:11:45,800 --> 00:11:49,340
the first time you switch to this

00:11:47,000 --> 00:11:50,660
isolated address space now what is

00:11:49,340 --> 00:11:52,610
interesting is that when you encounter

00:11:50,660 --> 00:11:55,340
the VM exit you are still running in

00:11:52,610 --> 00:11:57,320
this isolated address space and we hope

00:11:55,340 --> 00:11:59,060
that the address space was built such

00:11:57,320 --> 00:12:00,950
that the majority of the vm x it can

00:11:59,060 --> 00:12:03,290
actually be completely function can

00:12:00,950 --> 00:12:04,760
complete the function properly just we

00:12:03,290 --> 00:12:07,220
are staying in this outer space and

00:12:04,760 --> 00:12:08,990
because they are executing in an

00:12:07,220 --> 00:12:10,670
isolated other space we know that

00:12:08,990 --> 00:12:12,530
nothing sensitive can be populated to

00:12:10,670 --> 00:12:14,030
Elder Wand e cache and therefore we

00:12:12,530 --> 00:12:15,910
don't clear that the cycling type of

00:12:14,030 --> 00:12:19,640
that is still running inside the guest

00:12:15,910 --> 00:12:21,410
however some vmx it's like exhibiting to

00:12:19,640 --> 00:12:24,200
user space for the Vice simulation would

00:12:21,410 --> 00:12:26,120
still need to run in the full wheelchair

00:12:24,200 --> 00:12:27,590
address space so in this case we have no

00:12:26,120 --> 00:12:29,480
choice but we need to kick the serving

00:12:27,590 --> 00:12:31,280
hyper fat and switch to the full via

00:12:29,480 --> 00:12:33,800
space and allow the sibling hyperfit to

00:12:31,280 --> 00:12:36,590
return to the guest only once we switch

00:12:33,800 --> 00:12:38,540
back to the isolated VI space but the

00:12:36,590 --> 00:12:40,190
assumption here again is that the

00:12:38,540 --> 00:12:41,600
majority of vm x it doesn't need to do

00:12:40,190 --> 00:12:43,520
that and this is what we need to prove

00:12:41,600 --> 00:12:45,950
with numbers and performance benchmarks

00:12:43,520 --> 00:12:48,620
and another point worth mentioning is

00:12:45,950 --> 00:12:51,230
that because if we know that during the

00:12:48,620 --> 00:12:53,870
vm exit tender were assuming that we

00:12:51,230 --> 00:12:55,190
didn't exit the isolate v8 space l1d

00:12:53,870 --> 00:12:57,850
cache could not be populated with

00:12:55,190 --> 00:13:00,350
sensitive data we don't need anymore

00:12:57,850 --> 00:13:02,270
to flush the l1d cache on every

00:13:00,350 --> 00:13:05,000
elementary which will also improve the

00:13:02,270 --> 00:13:05,810
performance and so this is the idea in

00:13:05,000 --> 00:13:14,000
high level

00:13:05,810 --> 00:13:17,900
I will let Alexa continue from here so

00:13:14,000 --> 00:13:21,290
yeah this idea to for KVM is to create a

00:13:17,900 --> 00:13:24,380
new address space and so there was a

00:13:21,290 --> 00:13:26,240
first proposal about this idea and there

00:13:24,380 --> 00:13:28,160
was a lot of comment saying yeah this is

00:13:26,240 --> 00:13:30,920
kind of similar to what we have KP with

00:13:28,160 --> 00:13:33,890
kpti with when you are running the user

00:13:30,920 --> 00:13:36,170
space you are actually part of the

00:13:33,890 --> 00:13:38,330
cannon mapping so it's kind of reducing

00:13:36,170 --> 00:13:40,070
our address space so we are trying to

00:13:38,330 --> 00:13:44,300
find some similarity and to merge with

00:13:40,070 --> 00:13:46,339
both both of them because we have some

00:13:44,300 --> 00:13:48,950
explicit point where we are going to

00:13:46,339 --> 00:13:51,800
enter this isolated address space some

00:13:48,950 --> 00:13:56,480
point where we are going to exit this is

00:13:51,800 --> 00:13:58,400
explicit enter our exit for for kpti but

00:13:56,480 --> 00:14:00,020
would be for example on the cisco at the

00:13:58,400 --> 00:14:01,910
end of the sis code we will enter but

00:14:00,020 --> 00:14:05,810
reduced address base and exit on the

00:14:01,910 --> 00:14:09,350
cisco hunter for KVM address space that

00:14:05,810 --> 00:14:11,660
will be explicitly into KVM and also

00:14:09,350 --> 00:14:13,430
they are implicit exits when you take an

00:14:11,660 --> 00:14:16,370
interrupt or anything of things like

00:14:13,430 --> 00:14:18,680
that we are going to exit and that's why

00:14:16,370 --> 00:14:21,770
we are considering an absolutely Rob

00:14:18,680 --> 00:14:24,350
about merging the two so we can provide

00:14:21,770 --> 00:14:29,480
more generic key and ASI and not

00:14:24,350 --> 00:14:32,480
something limited to two KVM what we

00:14:29,480 --> 00:14:34,010
need to do the implementation is so to

00:14:32,480 --> 00:14:37,190
have some mechanism to switch between

00:14:34,010 --> 00:14:39,200
the page table to apps mechanism to do

00:14:37,190 --> 00:14:43,250
the transition so to enter and to exit

00:14:39,200 --> 00:14:46,610
ASI and some generic mechanism for the

00:14:43,250 --> 00:14:48,560
increase its enter an egg and exit for

00:14:46,610 --> 00:14:51,740
example during the enter at an exception

00:14:48,560 --> 00:14:54,020
as probably some work would like to do

00:14:51,740 --> 00:14:55,790
we need to do around the memory

00:14:54,020 --> 00:14:58,970
allocation because we don't want for

00:14:55,790 --> 00:15:01,820
example to modify past isolated

00:14:58,970 --> 00:15:04,779
address space when doing a memory

00:15:01,820 --> 00:15:06,800
allocation otherwise we will have some

00:15:04,779 --> 00:15:09,050
discrepancy between the full Cannell

00:15:06,800 --> 00:15:14,750
address space and this limited early

00:15:09,050 --> 00:15:16,380
space so so far I have something working

00:15:14,750 --> 00:15:19,320
at

00:15:16,380 --> 00:15:21,450
not very stable so I'm able to run an

00:15:19,320 --> 00:15:25,770
idle VM so it's works fine if you want

00:15:21,450 --> 00:15:28,500
to protect an idle VM I've tried to

00:15:25,770 --> 00:15:30,270
collect the data the problem is as I can

00:15:28,500 --> 00:15:33,630
not run some workload because it's

00:15:30,270 --> 00:15:36,630
hanging the data you're saying are very

00:15:33,630 --> 00:15:40,279
limited and just boot sequence so I

00:15:36,630 --> 00:15:47,339
start with VM and iconic data up to be

00:15:40,279 --> 00:15:51,180
logging prompt and what you can see is

00:15:47,339 --> 00:15:53,610
that we are able to run k vm + vm exit

00:15:51,180 --> 00:15:58,170
and be a mentor most of the times saying

00:15:53,610 --> 00:16:00,839
it but isolated address space so we put

00:15:58,170 --> 00:16:03,360
the entry into the address space into

00:16:00,839 --> 00:16:06,000
the recipient or guest so we enter this

00:16:03,360 --> 00:16:09,630
reduce at this space do WebM enter BM

00:16:06,000 --> 00:16:11,630
exit process by VM exit and when we go

00:16:09,630 --> 00:16:13,950
back we check if we are still on this

00:16:11,630 --> 00:16:20,190
isolated address space and what's fake

00:16:13,950 --> 00:16:22,440
is in 97% of the case which yeah that

00:16:20,190 --> 00:16:23,550
was a surprising number for me I was

00:16:22,440 --> 00:16:25,529
expecting nest

00:16:23,550 --> 00:16:27,390
I've tried also with nested VM it

00:16:25,529 --> 00:16:31,170
dropped to 75 percent I haven't

00:16:27,390 --> 00:16:33,900
investigated exactly why so this is my

00:16:31,170 --> 00:16:35,970
main loop so main up we stay most of the

00:16:33,900 --> 00:16:39,720
time and then I've tried to rub this

00:16:35,970 --> 00:16:42,959
down into the angler themselves

00:16:39,720 --> 00:16:45,870
depending on the VM exit reason so in

00:16:42,959 --> 00:16:48,360
that case we are in various address

00:16:45,870 --> 00:16:51,000
space we are going to call BM exit and

00:16:48,360 --> 00:16:53,430
or invocation and I check afterward if

00:16:51,000 --> 00:16:56,209
I'm still in the via in the radius of

00:16:53,430 --> 00:16:59,520
the red space and this is the case for

00:16:56,209 --> 00:17:01,110
the most common VM exit reason so we

00:16:59,520 --> 00:17:02,940
don't take into account whether it needs

00:17:01,110 --> 00:17:08,730
to return to Rios or none because that's

00:17:02,940 --> 00:17:11,360
different from ASI and so the numbers

00:17:08,730 --> 00:17:14,720
pretty good so far for what we have and

00:17:11,360 --> 00:17:17,160
we can probably have further improvement

00:17:14,720 --> 00:17:21,390
may be needed by the workflow to see

00:17:17,160 --> 00:17:26,120
also if we need and so this is a

00:17:21,390 --> 00:17:26,120
breakdown of the bmxing processing

00:17:26,290 --> 00:17:31,600
some of them are not processed at all

00:17:28,360 --> 00:17:37,299
but you can see our this is very well

00:17:31,600 --> 00:17:40,419
under more for most of the cases so the

00:17:37,299 --> 00:17:42,700
current state of for Kiana ASI is as I

00:17:40,419 --> 00:17:45,280
said very well some patches sound

00:17:42,700 --> 00:17:50,169
upstream there was a first version which

00:17:45,280 --> 00:17:52,299
was anti mostly implemented in KVM the

00:17:50,169 --> 00:17:55,480
second version provide the Kiana ASI

00:17:52,299 --> 00:17:57,460
which is more generic so user born

00:17:55,480 --> 00:17:59,350
provides in framework you can use but it

00:17:57,460 --> 00:18:02,770
for different part of the kernel but

00:17:59,350 --> 00:18:04,480
it's not merge with kpti so the next

00:18:02,770 --> 00:18:07,600
version I am the agent is to provide a

00:18:04,480 --> 00:18:13,320
new air RFC where I have something where

00:18:07,600 --> 00:18:16,929
a can Ras I would be used by kpti

00:18:13,320 --> 00:18:19,929
something we don't do also is when we

00:18:16,929 --> 00:18:22,540
exit ASI we should notify the other

00:18:19,929 --> 00:18:24,010
sibling at a perfed but it should exit

00:18:22,540 --> 00:18:27,730
with the end but it's not something we

00:18:24,010 --> 00:18:29,980
have yet and there's a bunch of

00:18:27,730 --> 00:18:32,169
unresolved issue that's the stability

00:18:29,980 --> 00:18:35,650
issue I mentioned on download it's

00:18:32,169 --> 00:18:37,720
hanging it's a nasty issue there was

00:18:35,650 --> 00:18:39,309
reissue I don't find all the different

00:18:37,720 --> 00:18:44,169
data but you need to map into

00:18:39,309 --> 00:18:46,240
battledress ways so but KVM can run it

00:18:44,169 --> 00:18:49,990
was a big concern to me initially but

00:18:46,240 --> 00:18:52,720
over time I realize that's not so bad

00:18:49,990 --> 00:18:54,940
so the way it works currently is if you

00:18:52,720 --> 00:18:57,130
are running an ESI or something is not

00:18:54,940 --> 00:18:58,929
mapped it's going to page fourth we are

00:18:57,130 --> 00:19:00,580
going to end all the page four switch

00:18:58,929 --> 00:19:02,830
back to the food counter address space

00:19:00,580 --> 00:19:06,010
and continue execution and during the

00:19:02,830 --> 00:19:08,190
page Fernando we are going to log some

00:19:06,010 --> 00:19:12,070
information we are the fault or cure and

00:19:08,190 --> 00:19:14,410
for example you've got the instruction

00:19:12,070 --> 00:19:16,059
powder where the stain and the stack and

00:19:14,410 --> 00:19:19,080
that way you can go back to your code

00:19:16,059 --> 00:19:22,210
and try to identify what is missing it's

00:19:19,080 --> 00:19:24,730
it's working while most of the time we

00:19:22,210 --> 00:19:27,070
could think about more complex solution

00:19:24,730 --> 00:19:31,559
like static corner and eyesore to try to

00:19:27,070 --> 00:19:31,559
find out what may be overkill depending

00:19:32,130 --> 00:19:37,350
and yeah but the different approach also

00:19:35,190 --> 00:19:39,480
we can have is currently so we are

00:19:37,350 --> 00:19:41,190
building the cannon KVM address space

00:19:39,480 --> 00:19:44,010
from scratch or you need to figure out

00:19:41,190 --> 00:19:46,110
exactly what you need to map we could do

00:19:44,010 --> 00:19:47,940
the different approach which is to start

00:19:46,110 --> 00:19:51,900
with a full canal address space and try

00:19:47,940 --> 00:19:54,270
to reduce it this was being is short

00:19:51,900 --> 00:19:55,560
food we are but we eventually move to

00:19:54,270 --> 00:19:59,700
the second solution because I think

00:19:55,560 --> 00:20:03,390
that's safer because but let's secure by

00:19:59,700 --> 00:20:05,070
default and I think we would have issue

00:20:03,390 --> 00:20:07,730
if we start with full canal address

00:20:05,070 --> 00:20:11,010
space and then try to decrease it

00:20:07,730 --> 00:20:14,460
especially regarding memory education or

00:20:11,010 --> 00:20:19,110
anything that could change your your

00:20:14,460 --> 00:20:21,180
address space when you are doing it very

00:20:19,110 --> 00:20:25,860
some mapping changing into bed right

00:20:21,180 --> 00:20:33,090
space so thing neuron is going to

00:20:25,860 --> 00:20:34,920
conclude about this work thanks so just

00:20:33,090 --> 00:20:37,020
to sum up well the high-level idea that

00:20:34,920 --> 00:20:39,090
is presented here so basically we saw

00:20:37,020 --> 00:20:40,980
that element EF has two hyper fighting

00:20:39,090 --> 00:20:43,350
attack scenarios right one of them was

00:20:40,980 --> 00:20:44,820
that cycling hyper Fred run basically

00:20:43,350 --> 00:20:47,160
which was the filters of different VMs

00:20:44,820 --> 00:20:48,900
and this was mitigated by Kolkata and

00:20:47,160 --> 00:20:51,240
then we were left with only this

00:20:48,900 --> 00:20:52,950
situation that one hyper FET is running

00:20:51,240 --> 00:20:54,990
inside the guest when it's cycling hyper

00:20:52,950 --> 00:20:57,060
fed is running a VM exit handler that

00:20:54,990 --> 00:20:59,430
populates the n1d cache with a sensitive

00:20:57,060 --> 00:21:01,320
data and then we decided to redo to

00:20:59,430 --> 00:21:03,240
mitigate this by reducing sensitive

00:21:01,320 --> 00:21:05,430
information from the VA space so we

00:21:03,240 --> 00:21:07,560
experienced local kernel VA region try

00:21:05,430 --> 00:21:09,660
to do general modification to memory

00:21:07,560 --> 00:21:12,000
management and kernel is I basically

00:21:09,660 --> 00:21:14,370
took a different approach of decoupling

00:21:12,000 --> 00:21:17,100
the VM exit execution environment from

00:21:14,370 --> 00:21:20,100
how they start at their hosts standard

00:21:17,100 --> 00:21:21,810
tasks a VA space looks like and then

00:21:20,100 --> 00:21:23,640
with this allows us to build the address

00:21:21,810 --> 00:21:25,470
space in a whitelist approach which also

00:21:23,640 --> 00:21:28,110
allowed us to not flush the l1d cache on

00:21:25,470 --> 00:21:29,640
every VM entry and another point worth

00:21:28,110 --> 00:21:32,280
mentioning but I won't explain details

00:21:29,640 --> 00:21:34,020
because a lack of time is that I think

00:21:32,280 --> 00:21:36,930
that kernel is is the only method to

00:21:34,020 --> 00:21:38,940
mitigate the user to kernel attack MDS

00:21:36,930 --> 00:21:41,490
attack vector when you keep a hyper

00:21:38,940 --> 00:21:44,130
threading enable and so that's also an

00:21:41,490 --> 00:21:46,950
interesting evolution of KVM ASI

00:21:44,130 --> 00:21:50,700
and so I don't how much I'm not sure how

00:21:46,950 --> 00:21:53,880
much time we have left and okay so I

00:21:50,700 --> 00:21:54,960
would just say that in general that we

00:21:53,880 --> 00:21:57,180
originated when I originally thought

00:21:54,960 --> 00:21:59,130
about the kV MSI I didn't consider a

00:21:57,180 --> 00:22:01,820
better mitigation the time we are

00:21:59,130 --> 00:22:04,680
currently working on and which is

00:22:01,820 --> 00:22:06,720
basically the idea to not polish

00:22:04,680 --> 00:22:08,790
individual address space but instead to

00:22:06,720 --> 00:22:11,460
petition the physical pages between the

00:22:08,790 --> 00:22:13,650
what L used to use by the Gast memo and

00:22:11,460 --> 00:22:16,290
those that are used by the host and this

00:22:13,650 --> 00:22:19,110
has many pot good properties from a

00:22:16,290 --> 00:22:21,990
performance optimization perspective for

00:22:19,110 --> 00:22:23,820
example you don't need to occupy a lot

00:22:21,990 --> 00:22:25,650
of horse memory pages buy the stock page

00:22:23,820 --> 00:22:27,690
but it also have nice security

00:22:25,650 --> 00:22:30,920
properties for example all the pages

00:22:27,690 --> 00:22:33,480
that are used in the non excellia

00:22:30,920 --> 00:22:35,670
event map in the direct map to begin

00:22:33,480 --> 00:22:37,440
with and that's it and all the non leaks

00:22:35,670 --> 00:22:40,080
physical memory will just basically be

00:22:37,440 --> 00:22:42,180
used to back guest memory so it will

00:22:40,080 --> 00:22:45,000
allow us to remove the problem of the

00:22:42,180 --> 00:22:46,500
data and also if we keep if every

00:22:45,000 --> 00:22:48,540
sensitive information that we want will

00:22:46,500 --> 00:22:51,510
be mapped only in posts local pitties

00:22:48,540 --> 00:22:53,820
which is either apt or user space patÃ­s

00:22:51,510 --> 00:22:55,920
or the kernel space via Allegiant

00:22:53,820 --> 00:22:57,570
pitties then it is considered safe

00:22:55,920 --> 00:23:00,270
because it's mapped only on the velocity

00:22:57,570 --> 00:23:01,740
putative the specific VM and this allows

00:23:00,270 --> 00:23:03,960
for a clear mental model or that

00:23:01,740 --> 00:23:06,720
everything that holds this condition is

00:23:03,960 --> 00:23:09,180
safe and it's not likable anymore so

00:23:06,720 --> 00:23:10,680
this was just a glimpse to this idea and

00:23:09,180 --> 00:23:12,810
there's also a bunch of issues with that

00:23:10,680 --> 00:23:15,300
with considering v OS kernel backends

00:23:12,810 --> 00:23:17,700
but we don't have time to dip to die you

00:23:15,300 --> 00:23:19,560
can see the slides later and just a

00:23:17,700 --> 00:23:21,780
sudden conclusion we can see that even

00:23:19,560 --> 00:23:24,000
though the problem is being welcomed for

00:23:21,780 --> 00:23:25,290
a amount and for a significant amount of

00:23:24,000 --> 00:23:27,450
time there is still no public

00:23:25,290 --> 00:23:31,890
solution this is perfect for anyone TF

00:23:27,450 --> 00:23:33,360
mts attack vector and in kvms I can

00:23:31,890 --> 00:23:35,400
erase and general shouldn't be viewed to

00:23:33,360 --> 00:23:37,410
just mitigate this attack vector in

00:23:35,400 --> 00:23:40,830
general you can view it as a generic

00:23:37,410 --> 00:23:42,900
arbitrary read primitive mitigation even

00:23:40,830 --> 00:23:45,210
if info leak that happen or it actually

00:23:42,900 --> 00:23:46,800
you still want to prevent in the VM

00:23:45,210 --> 00:23:49,500
exists and well you still want them to

00:23:46,800 --> 00:23:51,120
prevent the info League and my personal

00:23:49,500 --> 00:23:52,770
insight about this is that first of all

00:23:51,120 --> 00:23:55,200
I think the kayvyun community should

00:23:52,770 --> 00:23:57,060
better review they worked all down on

00:23:55,200 --> 00:23:57,370
the hypervisor that are outside of the

00:23:57,060 --> 00:23:59,080
line of

00:23:57,370 --> 00:24:02,020
community such as the work that I've

00:23:59,080 --> 00:24:04,270
done in hyper-v and also that in general

00:24:02,020 --> 00:24:06,640
both men equals x and the ASR technique

00:24:04,270 --> 00:24:08,320
they both try to decouple the execution

00:24:06,640 --> 00:24:11,170
environment of KVM from the rest of the

00:24:08,320 --> 00:24:12,910
host so it's kind of for me it kind of

00:24:11,170 --> 00:24:15,220
raised questions about the security

00:24:12,910 --> 00:24:19,240
posture in general of type 2 hypervisors

00:24:15,220 --> 00:24:21,970
and so this is all we had to say thanks

00:24:19,240 --> 00:24:22,540
for listening and if we have time for

00:24:21,970 --> 00:24:28,840
questions

00:24:22,540 --> 00:24:31,030
like one question probably so when you

00:24:28,840 --> 00:24:32,920
talk about kicking out the sibling are

00:24:31,030 --> 00:24:34,540
you saying you're just having it migrate

00:24:32,920 --> 00:24:37,480
to let the scheduler migrate it to

00:24:34,540 --> 00:24:39,610
another core so it's basically doing an

00:24:37,480 --> 00:24:42,190
IP I write to get it out of the guest

00:24:39,610 --> 00:24:44,650
and then block it in a KVM virtual CPU

00:24:42,190 --> 00:24:46,690
block loop and then it will allow it to

00:24:44,650 --> 00:24:49,090
get released from the KPM virtual CPU

00:24:46,690 --> 00:24:51,220
block loop until only when you return

00:24:49,090 --> 00:24:53,670
back from the cycling hyperventilated

00:24:51,220 --> 00:24:53,670
other space

00:25:02,690 --> 00:25:07,099
so you still have the kernel stack

00:25:04,820 --> 00:25:09,139
mapped in that limited address space are

00:25:07,099 --> 00:25:12,700
you sure there is nothing on there that

00:25:09,139 --> 00:25:15,889
is worth leaking so you are right the

00:25:12,700 --> 00:25:17,960
virtual CPU threads the stack also needs

00:25:15,889 --> 00:25:20,479
to be hidden from the very space and it

00:25:17,960 --> 00:25:22,249
is in in the in the isolated address

00:25:20,479 --> 00:25:25,009
space you can make sure to map it only

00:25:22,249 --> 00:25:27,229
there but in that in the memory POSIX

00:25:25,009 --> 00:25:29,239
you can make sure to back the stack in a

00:25:27,229 --> 00:25:31,639
non X physical page and map it in the

00:25:29,239 --> 00:25:32,869
kernel space VA region that is different

00:25:31,639 --> 00:25:38,370
between different tests and that will

00:25:32,869 --> 00:25:40,630
also hold you thank you

00:25:38,370 --> 00:25:47,499
[Applause]

00:25:40,630 --> 00:25:47,499

YouTube URL: https://www.youtube.com/watch?v=Qh07k5tI5G0


