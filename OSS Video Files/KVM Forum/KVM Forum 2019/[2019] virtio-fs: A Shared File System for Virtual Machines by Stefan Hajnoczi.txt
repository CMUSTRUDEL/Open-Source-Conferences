Title: [2019] virtio-fs: A Shared File System for Virtual Machines by Stefan Hajnoczi
Publication date: 2019-11-07
Playlist: KVM Forum 2019
Description: 
	virtio-fs is a new shared file system for virtual machines. Unlike previous approaches, it is designed to take advantage of the co-location of virtual machines and the hypervisor to achieve local file system semantics and performance. This talk covers the status of virtio-fs, its key features, and use cases.

Amongst its features, the ability to share the host page cache with the guest is unique and not available in other shared file systems. This leads to interesting applications, including local file system mmap MAP_SHARED semantics, memory footprint reduction, and efficient page cache sharing between guests.

This talk also covers metadata coherence and the shared memory version table that is being developed to achieve this. The table allows guests accessing the same files and directories to have a consistent view even when other guests make changes to the file system.

---

Stefan Hajnoczi
Red Hat
Senior Principle Software Engineer

Stefan has been active in QEMU since 2010 and works in Red Hat's virtualization team with a focus on storage. He works on virtio drivers in Linux and helps maintain the block layer and tracing in QEMU. He also organizes and mentors in the Google Summer of Code and Outreachy internship programs, and participates in the VIRTIO Technical Committee.

Current projects include the virtio-fs shared file system, the virtio-vsock communications device, and lightweight virtual machines.

Stefan has presented at previous KVM Forums, as well as FOSDEM, LinuxCon, and Linux Plumbers.

Note: We apologize for lower video quality due to technical problems.
Captions: 
	00:00:00,390 --> 00:00:02,750
[Music]

00:00:06,560 --> 00:00:13,320
okay thanks for coming today we're going

00:00:09,780 --> 00:00:16,170
to talk about Verdi OFS which is a new

00:00:13,320 --> 00:00:19,050
file system for virtual machines it's a

00:00:16,170 --> 00:00:22,230
shared file system the point of work of

00:00:19,050 --> 00:00:23,939
Verdi OFS is to pass through a host

00:00:22,230 --> 00:00:26,820
directory into the guest so that the

00:00:23,939 --> 00:00:29,820
guest can access files that live on the

00:00:26,820 --> 00:00:32,340
host and the semantics that were going

00:00:29,820 --> 00:00:34,079
for the goals is that it needs to be a

00:00:32,340 --> 00:00:36,210
positive file system so that existing

00:00:34,079 --> 00:00:37,920
applications can run correctly on it

00:00:36,210 --> 00:00:43,050
and we do want the modern extensions

00:00:37,920 --> 00:00:44,789
things that the Linux VFS has and we

00:00:43,050 --> 00:00:48,239
want to have concurrent access from

00:00:44,789 --> 00:00:50,489
multiple guests and we would like to

00:00:48,239 --> 00:00:54,500
give them local file system semantics

00:00:50,489 --> 00:00:57,149
which means coherency where possible and

00:00:54,500 --> 00:00:58,949
currently VAR AFS has achieved some of

00:00:57,149 --> 00:01:02,550
these goals and it's still under

00:00:58,949 --> 00:01:05,040
development and you know the this this

00:01:02,550 --> 00:01:07,409
is this is the the goal that were we're

00:01:05,040 --> 00:01:11,250
striving towards the project was started

00:01:07,409 --> 00:01:17,159
in 2018 and since then we've published

00:01:11,250 --> 00:01:19,200
the source code and Dave and Mike Josh

00:01:17,159 --> 00:01:21,780
and Vivek and I we work on the qmu

00:01:19,200 --> 00:01:24,450
implementation of this and the Linux

00:01:21,780 --> 00:01:26,520
kernel guest drivers but the community

00:01:24,450 --> 00:01:31,110
has also started implementing Verdejo FS

00:01:26,520 --> 00:01:34,200
in other hypervisors and also writing

00:01:31,110 --> 00:01:36,170
other file servers for it too because

00:01:34,200 --> 00:01:40,799
it's actually an interface that you can

00:01:36,170 --> 00:01:43,619
you can implement yourself okay so

00:01:40,799 --> 00:01:45,119
before I go too deep into what it is I'd

00:01:43,619 --> 00:01:47,729
like to quickly tell you about the use

00:01:45,119 --> 00:01:52,170
cases for why we even need this what the

00:01:47,729 --> 00:01:53,909
requirements are first of all we have

00:01:52,170 --> 00:01:55,079
lightweight VMs in container with the

00:01:53,909 --> 00:01:58,320
ends which are now becoming popular

00:01:55,079 --> 00:02:00,960
things like micro vm's cata containers

00:01:58,320 --> 00:02:02,460
and function as a service although these

00:02:00,960 --> 00:02:04,770
are the different things they're not the

00:02:02,460 --> 00:02:06,869
same they do have similar requirements

00:02:04,770 --> 00:02:10,500
those requirements are fast boot times

00:02:06,869 --> 00:02:12,239
and low memory overhead and basically

00:02:10,500 --> 00:02:12,840
what they do is they need to access host

00:02:12,239 --> 00:02:15,780
files

00:02:12,840 --> 00:02:17,550
because for containers typically the

00:02:15,780 --> 00:02:19,860
container images are coming from the

00:02:17,550 --> 00:02:21,780
host because if you have a guest in a

00:02:19,860 --> 00:02:23,580
container VM that container VM may be

00:02:21,780 --> 00:02:25,610
short-lived so the container image does

00:02:23,580 --> 00:02:28,230
not live in there it lives on the host

00:02:25,610 --> 00:02:30,750
and there's also dynamic configuration

00:02:28,230 --> 00:02:32,430
files that get generated per VM by your

00:02:30,750 --> 00:02:35,190
container runtime these might be things

00:02:32,430 --> 00:02:36,870
like etc' resolve confer they're not

00:02:35,190 --> 00:02:39,530
part of the container image they need to

00:02:36,870 --> 00:02:42,150
be generated at runtime for each

00:02:39,530 --> 00:02:44,549
container so how do we get it in well if

00:02:42,150 --> 00:02:46,110
we have a pass-through file system we

00:02:44,549 --> 00:02:49,920
can do it we can get it into the guest

00:02:46,110 --> 00:02:52,019
and then into the container actually

00:02:49,920 --> 00:02:54,959
cotta containers merged Verdejo FS

00:02:52,019 --> 00:02:57,599
support as an experimental feature in

00:02:54,959 --> 00:02:59,190
1.7 so it's already available if you

00:02:57,599 --> 00:03:02,579
want to play with cotta containers you

00:02:59,190 --> 00:03:05,910
can give it a try the next use case is

00:03:02,579 --> 00:03:09,090
file system as a service and here the

00:03:05,910 --> 00:03:11,610
idea is if you have a cloud and you want

00:03:09,090 --> 00:03:14,640
to provide file system volumes to

00:03:11,610 --> 00:03:18,840
instances in that cloud you can already

00:03:14,640 --> 00:03:22,980
do it if you use say NFS or cluster or

00:03:18,840 --> 00:03:26,130
SAFF or any other network tax storage

00:03:22,980 --> 00:03:28,170
type of technology but the problem is if

00:03:26,130 --> 00:03:30,480
you do that then the guests have to have

00:03:28,170 --> 00:03:32,010
access to your storage network they have

00:03:30,480 --> 00:03:34,970
to have the configuration in order to be

00:03:32,010 --> 00:03:37,590
able to log in and get to their storage

00:03:34,970 --> 00:03:39,299
which means you're limited now you can

00:03:37,590 --> 00:03:42,150
no longer migrate away and say you

00:03:39,299 --> 00:03:43,769
decide to change from NFS to SAP because

00:03:42,150 --> 00:03:45,480
you have to change all of your guests

00:03:43,769 --> 00:03:47,400
you'd have to go into the guest which

00:03:45,480 --> 00:03:50,669
you don't even administrate which you

00:03:47,400 --> 00:03:52,079
don't even own so what Verdi ofs can do

00:03:50,669 --> 00:03:54,750
for you therefore file system as a

00:03:52,079 --> 00:03:56,130
service is it can be a layer of

00:03:54,750 --> 00:03:58,290
indirection you can use it as the

00:03:56,130 --> 00:04:00,060
interface the guest sees of Verdi o

00:03:58,290 --> 00:04:02,970
device it does not know about the

00:04:00,060 --> 00:04:04,739
storage network it does not have to have

00:04:02,970 --> 00:04:06,660
the configuration details to log into

00:04:04,739 --> 00:04:08,310
your safe cluster and so on so that

00:04:06,660 --> 00:04:13,049
makes it attractive for doing that kind

00:04:08,310 --> 00:04:14,970
of use case and then the final thing is

00:04:13,049 --> 00:04:17,070
just traditional virtualization we want

00:04:14,970 --> 00:04:20,930
to be able to take a host directory and

00:04:17,070 --> 00:04:23,180
say make it available in my VM let me

00:04:20,930 --> 00:04:26,840
the reasons for doing this are for

00:04:23,180 --> 00:04:28,910
development for getting files into a

00:04:26,840 --> 00:04:30,980
guest early on maybe when you're you

00:04:28,910 --> 00:04:33,140
need to install some things and you're

00:04:30,980 --> 00:04:36,350
setting up your VM but also for things

00:04:33,140 --> 00:04:38,840
like booting from a host directory just

00:04:36,350 --> 00:04:40,580
you know creating essentially a chroot

00:04:38,840 --> 00:04:42,740
on the host and using that as the root

00:04:40,580 --> 00:04:44,570
filesystem for your guest not even using

00:04:42,740 --> 00:04:46,430
disk images anymore just being able to

00:04:44,570 --> 00:04:47,840
do a pass-through filesystem which is

00:04:46,430 --> 00:04:49,970
very neat because if you want to

00:04:47,840 --> 00:04:51,890
recompile software or kernels on the

00:04:49,970 --> 00:04:53,330
host and then quickly test it inside a

00:04:51,890 --> 00:04:58,610
grass this is great you don't need to

00:04:53,330 --> 00:04:59,930
build disk images yeah so the some

00:04:58,610 --> 00:05:01,820
special requirements what's unique about

00:04:59,930 --> 00:05:04,580
this is it's important to be able to

00:05:01,820 --> 00:05:05,960
offer this kind of functionality in an

00:05:04,580 --> 00:05:08,240
automated way that doesn't require

00:05:05,960 --> 00:05:10,130
manual steps that means not having to

00:05:08,240 --> 00:05:12,380
add a network adapter not needing to

00:05:10,130 --> 00:05:14,690
assign IP addresses and configure NFS

00:05:12,380 --> 00:05:16,700
and so on and that's doable with Verta

00:05:14,690 --> 00:05:18,020
fest because the configuration is very

00:05:16,700 --> 00:05:20,330
very simple

00:05:18,020 --> 00:05:22,040
that means levert and other tools can

00:05:20,330 --> 00:05:23,750
implement this as an automatic way so

00:05:22,040 --> 00:05:26,120
that the user just says please share

00:05:23,750 --> 00:05:30,350
this directory and it's like it just

00:05:26,120 --> 00:05:31,660
works ok so we had these requirements

00:05:30,350 --> 00:05:34,690
and we were thinking about what to do

00:05:31,660 --> 00:05:37,450
but why did we decide to start four FS

00:05:34,690 --> 00:05:40,300
and the main the main reason is because

00:05:37,450 --> 00:05:44,960
Kuhn KVM need a production quality

00:05:40,300 --> 00:05:46,820
shared file system the Verto 9-p has

00:05:44,960 --> 00:05:49,370
been around for a while but active

00:05:46,820 --> 00:05:52,460
development stopped in 2012 active

00:05:49,370 --> 00:05:54,410
maintainer ship stopped this year so it

00:05:52,460 --> 00:05:58,040
never reached the kind of production

00:05:54,410 --> 00:05:59,660
quality that we were looking for and in

00:05:58,040 --> 00:06:02,360
addition we had been thinking about some

00:05:59,660 --> 00:06:04,250
new ideas for how to go further than

00:06:02,360 --> 00:06:08,630
just using a network file system between

00:06:04,250 --> 00:06:10,370
a VM and a host what can we do if we

00:06:08,630 --> 00:06:12,200
take advantage of the fact that a VM and

00:06:10,370 --> 00:06:15,050
a hypervisor are Kolok located on the

00:06:12,200 --> 00:06:15,950
same machine network file systems use

00:06:15,050 --> 00:06:18,530
message passing

00:06:15,950 --> 00:06:20,990
they send requests and responses to each

00:06:18,530 --> 00:06:23,090
other but as we're gonna see later on

00:06:20,990 --> 00:06:24,650
Verdejo FS has some features that go

00:06:23,090 --> 00:06:26,420
beyond that things that you can't do in

00:06:24,650 --> 00:06:31,550
a network file system to get advanced

00:06:26,420 --> 00:06:34,330
features ok so I'll give you a quick

00:06:31,550 --> 00:06:34,330
overview of the architecture

00:06:35,499 --> 00:06:41,509
verda FS is built on fuse so we didn't

00:06:38,960 --> 00:06:44,300
invent a new protocol a new RPC protocol

00:06:41,509 --> 00:06:46,969
we used the Linux file system user space

00:06:44,300 --> 00:06:48,830
infrastructure that's already there but

00:06:46,969 --> 00:06:50,990
we extended it and in order to use it

00:06:48,830 --> 00:06:54,620
for this use case it's actually not

00:06:50,990 --> 00:06:56,569
compatible with say sshfs and existing

00:06:54,620 --> 00:07:00,199
fuse and we'll explain the differences

00:06:56,569 --> 00:07:01,939
soon later in the presentation but it's

00:07:00,199 --> 00:07:04,729
based on fuse and it reuses the the

00:07:01,939 --> 00:07:08,029
client code which has been great and

00:07:04,729 --> 00:07:10,159
then there's a vert o FS device which is

00:07:08,029 --> 00:07:12,740
a new Verdejo device that has been

00:07:10,159 --> 00:07:15,050
defined that we've put into the spec and

00:07:12,740 --> 00:07:18,050
on the host side there's a demon there's

00:07:15,050 --> 00:07:21,500
a file server that handles requests for

00:07:18,050 --> 00:07:24,500
that device and we've implemented it

00:07:21,500 --> 00:07:27,949
it's called Verdejo fsd and it's a user

00:07:24,500 --> 00:07:29,810
fee host user process so it's a separate

00:07:27,949 --> 00:07:31,610
process from your hypervisor you can use

00:07:29,810 --> 00:07:33,409
it with qmu you can also use it with

00:07:31,610 --> 00:07:37,479
other hypervisors that support the v

00:07:33,409 --> 00:07:40,039
host user protocol and it's sandbox so

00:07:37,479 --> 00:07:42,830
it when it starts up and makes sure that

00:07:40,039 --> 00:07:44,689
the only files available to that process

00:07:42,830 --> 00:07:49,490
are the shared directory and nothing

00:07:44,689 --> 00:07:53,240
else it can also communicate with qmu in

00:07:49,490 --> 00:07:54,050
order to set up shared file mappings and

00:07:53,240 --> 00:07:55,430
this is some of the advanced

00:07:54,050 --> 00:07:57,860
functionality that a network file system

00:07:55,430 --> 00:08:00,889
wouldn't be able to do server TFS is

00:07:57,860 --> 00:08:04,129
able to take a file and map it into the

00:08:00,889 --> 00:08:06,680
guest memory a memory space not into

00:08:04,129 --> 00:08:08,270
guest ROM into the memory space so you

00:08:06,680 --> 00:08:10,159
don't have to copy the contents of files

00:08:08,270 --> 00:08:12,620
into guest memory instead the guest can

00:08:10,159 --> 00:08:17,120
just directly access files from the host

00:08:12,620 --> 00:08:19,159
from the host page cache and finally it

00:08:17,120 --> 00:08:20,629
supports remote storage for its local

00:08:19,159 --> 00:08:22,219
storage so what you put underneath

00:08:20,629 --> 00:08:24,680
Verdejo FS it's just a pass-through

00:08:22,219 --> 00:08:27,860
filesystem you it could be an NFS mount

00:08:24,680 --> 00:08:37,430
if you want or it could be a local XFS

00:08:27,860 --> 00:08:40,250
filesystem okay for our implementation

00:08:37,430 --> 00:08:44,970
of the daemon we started with two

00:08:40,250 --> 00:08:49,560
existing parts we started with Lib fuse

00:08:44,970 --> 00:08:51,569
is library which provides the code for

00:08:49,560 --> 00:08:54,750
pulling apart and building fused

00:08:51,569 --> 00:08:56,970
messages and interpreting them and then

00:08:54,750 --> 00:09:00,269
it provides that to an abstract

00:08:56,970 --> 00:09:03,360
interface of a file system and again

00:09:00,269 --> 00:09:07,230
from the fuses distribution we talked

00:09:03,360 --> 00:09:10,439
the pass-through ll example file system

00:09:07,230 --> 00:09:13,490
which provides a back-end pretty much

00:09:10,439 --> 00:09:17,879
straight through to a POSIX back and

00:09:13,490 --> 00:09:20,550
from qmu we talked lib v host user which

00:09:17,879 --> 00:09:24,600
is a library that provides transport

00:09:20,550 --> 00:09:28,339
over virtio using the Lib V using the V

00:09:24,600 --> 00:09:32,430
hoe to use a transport B host user is a

00:09:28,339 --> 00:09:36,329
transport which takes virtio messages

00:09:32,430 --> 00:09:41,279
and passes them in an external process

00:09:36,329 --> 00:09:44,579
to q mu and the V host user does all the

00:09:41,279 --> 00:09:48,350
setup and the handling of the protocol

00:09:44,579 --> 00:09:51,350
over a socket week does the vo settled

00:09:48,350 --> 00:09:53,910
the lib fuse library is not ABI

00:09:51,350 --> 00:09:56,040
compatible with the existing lib views

00:09:53,910 --> 00:10:00,870
because we've had to go in and wire in

00:09:56,040 --> 00:10:04,709
the different transport we've modified

00:10:00,870 --> 00:10:09,029
the backend filesystem to add some

00:10:04,709 --> 00:10:11,790
threading as well now that's just one

00:10:09,029 --> 00:10:15,300
potential implementation two other ways

00:10:11,790 --> 00:10:17,100
of doing it you could go off and use

00:10:15,300 --> 00:10:19,860
something other than POSIX as the

00:10:17,100 --> 00:10:23,360
backend for example there are existing

00:10:19,860 --> 00:10:26,850
fuse daemons that instead of talking to

00:10:23,360 --> 00:10:30,360
a positive filesystem go off and talk to

00:10:26,850 --> 00:10:34,889
a network file system directly or you

00:10:30,360 --> 00:10:37,410
can go and speak some block storage via

00:10:34,889 --> 00:10:39,420
a user space in the external process

00:10:37,410 --> 00:10:43,110
instead which I believe is being talked

00:10:39,420 --> 00:10:46,620
about in the next talk oh you can go off

00:10:43,110 --> 00:10:51,329
and do other implementations there's a

00:10:46,620 --> 00:10:54,569
rust implementation in cross VM but it's

00:10:51,329 --> 00:10:56,670
not using v host users the communication

00:10:54,569 --> 00:10:59,640
with QM you

00:10:56,670 --> 00:11:04,980
we're looking at how to wire the two

00:10:59,640 --> 00:11:10,230
bits together at some point now one of

00:11:04,980 --> 00:11:14,190
the tricks that we can do using virtio

00:11:10,230 --> 00:11:17,310
FS is to map parts of the file from the

00:11:14,190 --> 00:11:20,580
host file system directly through into

00:11:17,310 --> 00:11:23,610
the guest and this saves any copying and

00:11:20,580 --> 00:11:26,070
it also share saved on buffer cache

00:11:23,610 --> 00:11:28,730
because on a really good day you've got

00:11:26,070 --> 00:11:32,430
one copy of the file sitting amendment

00:11:28,730 --> 00:11:36,150
now the way we do this is that the fuse

00:11:32,430 --> 00:11:38,370
client that's the guest Colonel sends a

00:11:36,150 --> 00:11:42,960
message to the host over virtio

00:11:38,370 --> 00:11:45,390
asking to map a section of a file which

00:11:42,960 --> 00:11:50,460
is already opened using standard fuse

00:11:45,390 --> 00:11:53,970
commands the daemon then opens the file

00:11:50,460 --> 00:11:56,340
descriptor and passes that to qmu that

00:11:53,970 --> 00:11:59,490
then M maps that file into a chunk of

00:11:56,340 --> 00:12:03,080
memory and that memory is exposed into

00:11:59,490 --> 00:12:08,910
the guest on our PCI implementation as

00:12:03,080 --> 00:12:12,360
part of a PCI ball in the guest these

00:12:08,910 --> 00:12:14,370
mappings are allocated by the guest

00:12:12,360 --> 00:12:16,800
driver where it would like the mappings

00:12:14,370 --> 00:12:21,510
and that makes it a lot easier than

00:12:16,800 --> 00:12:23,100
giving the mapping job to the daemon one

00:12:21,510 --> 00:12:26,160
of the problems is we've got a finite

00:12:23,100 --> 00:12:28,320
size window here so we can't map all of

00:12:26,160 --> 00:12:32,760
the files that you have open we've got

00:12:28,320 --> 00:12:35,610
to our gate and reuse so what are the

00:12:32,760 --> 00:12:37,920
differences from normal fuse well

00:12:35,610 --> 00:12:41,970
instead of using dev fuse we've got our

00:12:37,920 --> 00:12:43,980
own transport every host user and that

00:12:41,970 --> 00:12:44,700
means we can't use standard lit fuse

00:12:43,980 --> 00:12:47,760
daemons

00:12:44,700 --> 00:12:50,340
we can't also just package up the

00:12:47,760 --> 00:12:54,030
messages and stuff the mobile live free

00:12:50,340 --> 00:12:57,030
host there's some security in versions

00:12:54,030 --> 00:13:01,050
that we only realized after we'd started

00:12:57,030 --> 00:13:03,750
in a traditional fuse system the kernel

00:13:01,050 --> 00:13:06,390
that's providing the fused messages is

00:13:03,750 --> 00:13:08,930
the trusted part of the equation the

00:13:06,390 --> 00:13:10,939
demon is typically a user process

00:13:08,930 --> 00:13:14,990
it's running under the control of that

00:13:10,939 --> 00:13:17,749
colonel in our environment is inverted

00:13:14,990 --> 00:13:21,139
the colonel in this case is the

00:13:17,749 --> 00:13:23,629
untrusted guest our demon is running on

00:13:21,139 --> 00:13:26,600
the host and providing access to the

00:13:23,629 --> 00:13:28,790
file system so we've got to be

00:13:26,600 --> 00:13:30,769
completely untrusting of the guest we've

00:13:28,790 --> 00:13:34,369
got to check all the paths don't try and

00:13:30,769 --> 00:13:38,689
do escapes and we really lock it down

00:13:34,369 --> 00:13:40,459
son boxset comped everything another

00:13:38,689 --> 00:13:43,879
thing we've got to deal with it reboot

00:13:40,459 --> 00:13:46,339
in a traditional fuse system since the

00:13:43,879 --> 00:13:47,300
demon is running under the kernel if the

00:13:46,339 --> 00:13:50,389
kernel reboots

00:13:47,300 --> 00:13:55,279
well the demon has to restart in our

00:13:50,389 --> 00:13:57,079
world the guest can reboot maybe cleanly

00:13:55,279 --> 00:13:59,809
maybe uncleanly maybe somebody just

00:13:57,079 --> 00:14:02,329
echoes beetus it work

00:13:59,809 --> 00:14:04,129
or you're mounted remount it and the

00:14:02,329 --> 00:14:06,019
demon has to handle that which is

00:14:04,129 --> 00:14:10,759
something a traditional fused demon

00:14:06,019 --> 00:14:14,540
doesn't have to do here's some point is

00:14:10,759 --> 00:14:17,360
how to get it and some example command

00:14:14,540 --> 00:14:23,199
lines which you can cut and paste later

00:14:17,360 --> 00:14:25,670
at your leisure now here's some

00:14:23,199 --> 00:14:28,009
benchmark measurements that we've acted

00:14:25,670 --> 00:14:32,269
and the link to the data is at the

00:14:28,009 --> 00:14:35,629
bottom in pretty much all the cases even

00:14:32,269 --> 00:14:39,139
without the DAX so that's the red bars

00:14:35,629 --> 00:14:47,779
we're a little bit faster than 9p and

00:14:39,139 --> 00:14:50,179
with Dax were a lot faster now there

00:14:47,779 --> 00:14:53,749
were some cases where Dax is a little

00:14:50,179 --> 00:14:55,699
bit harder so most of these cases it's

00:14:53,749 --> 00:14:58,459
faster but if you have a look at the run

00:14:55,699 --> 00:15:01,699
to read multi you can see the Dax case

00:14:58,459 --> 00:15:03,379
is a little bit slower and the problem

00:15:01,699 --> 00:15:05,929
we have here is that there is some

00:15:03,379 --> 00:15:06,649
latency and the guest saying hey I'd

00:15:05,929 --> 00:15:10,249
liked him

00:15:06,649 --> 00:15:11,990
and mapped this part of the file so it

00:15:10,249 --> 00:15:13,910
sends a request up to the demon the

00:15:11,990 --> 00:15:15,949
demon opens the file sends a request but

00:15:13,910 --> 00:15:18,860
to qmu in their maps and then carries on

00:15:15,949 --> 00:15:20,630
so there's some work we've got to adduce

00:15:18,860 --> 00:15:23,840
that latency

00:15:20,630 --> 00:15:34,180
and look at heuristics for trying to map

00:15:23,840 --> 00:15:37,040
what we need so I'm going to talk about

00:15:34,180 --> 00:15:40,460
specific part of this problem of

00:15:37,040 --> 00:15:45,110
improving performance of the tyre FS

00:15:40,460 --> 00:15:48,290
that's how to deal with caches or at

00:15:45,110 --> 00:15:54,380
least data cache was already introduced

00:15:48,290 --> 00:15:56,540
by Dave but we have other kind of file

00:15:54,380 --> 00:16:01,370
system cache is like metadata and path

00:15:56,540 --> 00:16:07,670
name lookup and each facet of operation

00:16:01,370 --> 00:16:10,130
will in if not cached it will cause at

00:16:07,670 --> 00:16:13,850
least one but usually more than one

00:16:10,130 --> 00:16:17,300
round trip between host and guest to be

00:16:13,850 --> 00:16:19,670
able to perform fiefdom operation so

00:16:17,300 --> 00:16:25,000
caches are critically important in

00:16:19,670 --> 00:16:26,290
providing good performance so if

00:16:25,000 --> 00:16:29,330
[Music]

00:16:26,290 --> 00:16:31,750
metadata in bathroom lookup cache can be

00:16:29,330 --> 00:16:39,250
the host

00:16:31,750 --> 00:16:41,900
unlike data cache so we it's not shared

00:16:39,250 --> 00:16:47,060
then we need to have some way of

00:16:41,900 --> 00:16:49,370
invalidating the guest caches that cache

00:16:47,060 --> 00:16:53,150
invalidation is synchronous then we have

00:16:49,370 --> 00:16:57,860
strong coherency so if if operation that

00:16:53,150 --> 00:17:04,240
changes directory or some metadata on a

00:16:57,860 --> 00:17:07,970
file only finishes when all instances of

00:17:04,240 --> 00:17:10,250
the caches have been invalidated then we

00:17:07,970 --> 00:17:12,560
can provide strong coherency between all

00:17:10,250 --> 00:17:15,430
the guests and the host file system if

00:17:12,560 --> 00:17:19,819
we can only provide asynchronous

00:17:15,430 --> 00:17:21,900
invalidation then that will be weak

00:17:19,819 --> 00:17:25,260
coherency

00:17:21,900 --> 00:17:32,059
it doesn't guarantee that changes are

00:17:25,260 --> 00:17:37,110
seen from our guests at the same time if

00:17:32,059 --> 00:17:40,620
invalidation in the inn guests can block

00:17:37,110 --> 00:17:42,930
then malfunctioning

00:17:40,620 --> 00:17:47,280
guests can cause denial of service

00:17:42,930 --> 00:17:49,470
because a synchronous invalidation that

00:17:47,280 --> 00:17:53,840
will cause the actual fascism operation

00:17:49,470 --> 00:17:53,840
that changes the fastest time to block

00:17:54,440 --> 00:18:04,620
so one way of implementing synchronous

00:17:59,670 --> 00:18:08,840
and non blocking invalidation is to have

00:18:04,620 --> 00:18:12,090
a piece of shared memory containing

00:18:08,840 --> 00:18:15,780
table which has a version number for

00:18:12,090 --> 00:18:18,720
each file if the file called if file

00:18:15,780 --> 00:18:21,750
metadata is changed or for example

00:18:18,720 --> 00:18:25,320
directory contents are changed then the

00:18:21,750 --> 00:18:28,320
version number is incremented and the

00:18:25,320 --> 00:18:31,290
same piece of memory is seen by all the

00:18:28,320 --> 00:18:35,220
guests so this version tables shared

00:18:31,290 --> 00:18:38,490
between the between the guest and and is

00:18:35,220 --> 00:18:41,850
also seen by the server the Vitara SD

00:18:38,490 --> 00:18:45,590
and if some file is changed then that

00:18:41,850 --> 00:18:51,240
number is incremented and this will have

00:18:45,590 --> 00:18:58,200
soda so when the gas file system is

00:18:51,240 --> 00:18:59,820
looking at certain metadata or partner

00:18:58,200 --> 00:19:01,890
look up in the cache you can validate

00:18:59,820 --> 00:19:04,590
that cache very easily because we can

00:19:01,890 --> 00:19:08,790
just compare the previous version with

00:19:04,590 --> 00:19:11,640
the one in the shared memory and so it

00:19:08,790 --> 00:19:15,929
will be a very fast operation to check

00:19:11,640 --> 00:19:18,840
the validity of the cache currently this

00:19:15,929 --> 00:19:19,760
is not yet working for changes made

00:19:18,840 --> 00:19:25,970
through

00:19:19,760 --> 00:19:28,929
the host file system but so but that's

00:19:25,970 --> 00:19:35,510
also something that for the future to

00:19:28,929 --> 00:19:38,090
implement okay and the current status if

00:19:35,510 --> 00:19:41,029
you're wondering because this this fits

00:19:38,090 --> 00:19:43,610
in several components is that the vert

00:19:41,029 --> 00:19:45,289
our device spec itself is now in the

00:19:43,610 --> 00:19:47,450
vertical is back it has been accepted in

00:19:45,289 --> 00:19:50,240
one point to the Linux guest driver is

00:19:47,450 --> 00:19:52,490
in Linux 5.4 but the DAX feature is not

00:19:50,240 --> 00:19:55,370
included that's a separate thing on top

00:19:52,490 --> 00:19:59,029
and then the QE patches are being merged

00:19:55,370 --> 00:20:01,100
as well the verdure FS demon is the last

00:19:59,029 --> 00:20:05,510
piece that we need to get upstream but

00:20:01,100 --> 00:20:09,830
it's all available already on the

00:20:05,510 --> 00:20:12,549
verdurous website so that's the end

00:20:09,830 --> 00:20:12,549
thank you very much

00:20:28,590 --> 00:20:33,870
so you probably won't like this question

00:20:31,200 --> 00:20:38,820
but any work on drivers for other

00:20:33,870 --> 00:20:40,830
operating systems like Windows so for

00:20:38,820 --> 00:20:45,480
Windows at the moment there are no

00:20:40,830 --> 00:20:49,799
Verdejo drivers for VAR AFS yet but we

00:20:45,480 --> 00:21:00,179
hope that we hope that they will exist

00:20:49,799 --> 00:21:03,090
soon so you are mentioning that because

00:21:00,179 --> 00:21:06,330
you use version numbers you can't have a

00:21:03,090 --> 00:21:08,490
same mechanism being used for the hosts

00:21:06,330 --> 00:21:10,590
file system so how would you plan to

00:21:08,490 --> 00:21:11,999
authorize that in the long term and in

00:21:10,590 --> 00:21:13,080
particular in the case where other hosts

00:21:11,999 --> 00:21:17,129
as you say it could be underneath

00:21:13,080 --> 00:21:19,860
network file system okay so there's two

00:21:17,129 --> 00:21:23,460
parts to this so if you have a network

00:21:19,860 --> 00:21:25,619
file system that does have coherency

00:21:23,460 --> 00:21:28,679
features in its network protocol so it

00:21:25,619 --> 00:21:30,539
can do notifications then it would

00:21:28,679 --> 00:21:32,580
theoretically be possible to wire it all

00:21:30,539 --> 00:21:35,730
up so all the way through the gas down

00:21:32,580 --> 00:21:37,799
that we could get you know a level of

00:21:35,730 --> 00:21:39,690
coherency of course that's gonna have

00:21:37,799 --> 00:21:43,159
overhead if the network file system

00:21:39,690 --> 00:21:45,570
because you're going off the machine

00:21:43,159 --> 00:21:47,369
that's one thing I think the other thing

00:21:45,570 --> 00:21:49,470
that might be interesting to people is

00:21:47,369 --> 00:21:52,080
that we've been thinking about how to

00:21:49,470 --> 00:21:54,600
solve the problem of if the host itself

00:21:52,080 --> 00:21:56,249
if processes on the host are modifying

00:21:54,600 --> 00:22:00,330
the files that the guest also wants to

00:21:56,249 --> 00:22:03,749
see how can we make that coherent as

00:22:00,330 --> 00:22:05,759
well and one of the interesting things

00:22:03,749 --> 00:22:07,559
now with the EM dev developments that

00:22:05,759 --> 00:22:12,119
are happening is we might actually be

00:22:07,559 --> 00:22:14,159
able to reuse the V host user device and

00:22:12,119 --> 00:22:18,090
M dev to essentially just share the same

00:22:14,159 --> 00:22:20,249
code and attach the verdure FS device on

00:22:18,090 --> 00:22:22,320
the host as well so they are all going

00:22:20,249 --> 00:22:26,730
through the same code path and they're

00:22:22,320 --> 00:22:29,580
all using the same shared memory data

00:22:26,730 --> 00:22:32,779
structure so that's what we're hoping to

00:22:29,580 --> 00:22:35,220
do but we haven't started work on that

00:22:32,779 --> 00:22:37,679
so that means you would have to mount it

00:22:35,220 --> 00:22:39,960
in a special way you know you'd have to

00:22:37,679 --> 00:22:41,190
host mount it on the host side in a

00:22:39,960 --> 00:22:45,090
special way in order to get

00:22:41,190 --> 00:22:46,680
right so so that's when I I don't I

00:22:45,090 --> 00:22:48,480
haven't looked in detail about how to do

00:22:46,680 --> 00:22:50,850
that I mean there are possibilities like

00:22:48,480 --> 00:22:54,390
to make sure that in that mount name

00:22:50,850 --> 00:22:56,550
space you do a bind mount on top so your

00:22:54,390 --> 00:22:58,830
process is and for the user it looks

00:22:56,550 --> 00:22:59,850
like those are just their local files

00:22:58,830 --> 00:23:02,280
they don't need to go to a different

00:22:59,850 --> 00:23:04,590
directory okay so you are not thinking

00:23:02,280 --> 00:23:07,320
about adding browser numbers to fill a

00:23:04,590 --> 00:23:08,940
face or whatever I didn't hear that I'm

00:23:07,320 --> 00:23:10,620
sorry you are not thinking about adding

00:23:08,940 --> 00:23:13,280
version numbers in VFS or stuff like

00:23:10,620 --> 00:23:13,280
that yeah

00:23:24,660 --> 00:23:32,160
I you didn't mention live migration in

00:23:28,370 --> 00:23:36,960
your talk are there some key reads and

00:23:32,160 --> 00:23:39,530
something to address so yeah there's a

00:23:36,960 --> 00:23:42,540
few different parts to live migration

00:23:39,530 --> 00:23:46,620
we've not started looking at it yet but

00:23:42,540 --> 00:23:50,550
my hope is to use the code from creo

00:23:46,620 --> 00:23:53,280
which does process live migration on the

00:23:50,550 --> 00:23:55,440
hope that it's probably already got code

00:23:53,280 --> 00:23:57,780
for dealing with migrating file

00:23:55,440 --> 00:24:00,840
descriptors and we've got a pile of file

00:23:57,780 --> 00:24:03,330
descriptors to my grades other than that

00:24:00,840 --> 00:24:05,780
side of it the V host part of the

00:24:03,330 --> 00:24:09,120
migration should be very similar to

00:24:05,780 --> 00:24:12,450
migration of V host NAT or anything like

00:24:09,120 --> 00:24:14,540
that so I think it's really just a case

00:24:12,450 --> 00:24:17,280
of getting the file descriptors across

00:24:14,540 --> 00:24:19,350
except when we talk about Dax so we've

00:24:17,280 --> 00:24:22,020
got to figure out how to do the dark

00:24:19,350 --> 00:24:23,730
side of it but the non dark side I think

00:24:22,020 --> 00:24:26,910
it's just a matter of moving the file

00:24:23,730 --> 00:24:30,210
descriptors across and abstracting on

00:24:26,910 --> 00:24:32,510
the demon that's assuming that the host

00:24:30,210 --> 00:24:35,460
you're migrating between have a shared

00:24:32,510 --> 00:24:39,090
file system backing them if they don't

00:24:35,460 --> 00:24:42,270
life is more interesting if they've got

00:24:39,090 --> 00:24:43,980
some type of arcing swarm then yeah that

00:24:42,270 --> 00:24:45,510
that's much more interesting question

00:24:43,980 --> 00:24:52,230
but I'd start by looking at something

00:24:45,510 --> 00:24:59,630
like Wii U and going from that we have

00:24:52,230 --> 00:24:59,630
time for one last questions thank you

00:25:01,630 --> 00:25:10,449
[Applause]

00:25:03,160 --> 00:25:10,449

YouTube URL: https://www.youtube.com/watch?v=969sXbNX01U


