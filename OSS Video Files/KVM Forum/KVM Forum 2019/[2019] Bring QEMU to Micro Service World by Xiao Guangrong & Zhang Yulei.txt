Title: [2019] Bring QEMU to Micro Service World by Xiao Guangrong & Zhang Yulei
Publication date: 2019-11-12
Playlist: KVM Forum 2019
Description: 
	Recently more and more services, particularly micro services, have been moved from VMs to containers. Due to container's native infrastructure, cloud providers are seeking tech to create a more secured multi-tenant environment such as firecrack from AWS.
But using a dedicated hypervisor for micro service would bring extra burden to develop and maintain respectively. Furthermore, the improvement we add for one could benifit another. How about leveraging QEMU to fulfill the requirements of micro services? That is exactly what we did at Tencent Cloud.
We will share our works to adapt QEMU to fast deploy intensive micro services in a extremely short period ( less than 35 ms) with less resource utilization which is comparable to containers that includes directly starting a VM from the parent, C/R QEMU to start a new VM, modularizing QEMU, reducing resource usage for both QEMU & Linux VMs etc.

---

Xiao Guangrong
Tencent Cloud
Senior Software Engineer

Xiao Guangrong is a Linux Kernel developer working on Ftrace, MM, Btrfs but his main interest is KVM. As a active contributor, he was invited to give some presentations at some conferences: Japan LinuxCon 2011, Japan LinuxCon 2012 China CLK 2012, KVM Forum 2016, 2017, 2018. He is the maintainer of NVDIMM in Qemuâ€™s community who designed and implemented NVDIMM in KVM

Zhang Yulei
Tencent Cloud
Senior Software Engineer

More than 10 years experienced software developer working in Virtualization area. Used to design and implement Intel GPU virtualization technology(a.k.a Intel GVT-g). Recent presentation was: as technique speaker presented "Enable media cloud with intel Graphics virtualization technology" at Alibaba computer conference in 2015 and "Adaptive Live Migration" at KVM Forum 2018.

Note: We apologize for lower video quality due to technical problems.
Captions: 
	00:00:00,390 --> 00:00:02,750
[Music]

00:00:07,309 --> 00:00:13,380
okay good afternoon everyone

00:00:10,380 --> 00:00:17,760
second Sofia coming Monday is a

00:00:13,380 --> 00:00:21,380
chaperone today my colleague Julie and

00:00:17,760 --> 00:00:25,080
myself oh well to representation to you

00:00:21,380 --> 00:00:27,869
the topic is about Beringia me to micro

00:00:25,080 --> 00:00:32,610
service award CC is what we have a

00:00:27,869 --> 00:00:38,030
tongue and technical out to make Chima

00:00:32,610 --> 00:00:38,030
suitable to Rosa workload of maker so is

00:00:38,480 --> 00:00:44,760
in this topic we were first talked about

00:00:42,000 --> 00:00:49,649
it's a bare ground in distinguishing are

00:00:44,760 --> 00:00:52,289
we are we I explain what it's repeat

00:00:49,649 --> 00:00:54,870
what is the requirement of micro service

00:00:52,289 --> 00:00:58,890
and why we need that you do which is

00:00:54,870 --> 00:01:02,340
work later we were in J'Accuse

00:00:58,890 --> 00:01:06,170
QE meal adoption physically this is

00:01:02,340 --> 00:01:11,369
exactly what we have done on Q email to

00:01:06,170 --> 00:01:13,799
to make to to make creamy suitable to

00:01:11,369 --> 00:01:18,360
Rosa walk alone it is an asked where I

00:01:13,799 --> 00:01:21,479
shoot the future work this is the to the

00:01:18,360 --> 00:01:24,840
list by the way are we introduced the

00:01:21,479 --> 00:01:28,020
background and the part of chima

00:01:24,840 --> 00:01:35,640
adoption and really we are well do the

00:01:28,020 --> 00:01:39,479
last so consent Claude has a huge number

00:01:35,640 --> 00:01:44,250
of resource we have 25 regions also we

00:01:39,479 --> 00:01:51,240
have a huge number of servers and huge

00:01:44,250 --> 00:01:55,470
number of storages our business goes up

00:01:51,240 --> 00:01:59,399
very quickly we have lots of companies

00:01:55,470 --> 00:02:05,930
came from different areas all over them

00:01:59,399 --> 00:02:10,069
has a different requirement as we know

00:02:05,930 --> 00:02:13,180
more the more customers love microserver

00:02:10,069 --> 00:02:18,120
maker service

00:02:13,180 --> 00:02:22,000
micro-service is messy we need deployed

00:02:18,120 --> 00:02:29,230
also either has a very short or four

00:02:22,000 --> 00:02:33,540
left circle so so that it'll cross very

00:02:29,230 --> 00:02:40,260
fast put up and less memory for the pond

00:02:33,540 --> 00:02:43,569
also it requires a level of was curity

00:02:40,260 --> 00:02:48,669
maybe currently we have some solutions

00:02:43,569 --> 00:02:52,120
such as folk rock from AWS and cross the

00:02:48,669 --> 00:02:57,519
vm from Google may be rusty MMO is also

00:02:52,120 --> 00:03:01,269
a good choice all these solutions are

00:02:57,519 --> 00:03:06,700
very good but with the approver to queue

00:03:01,269 --> 00:03:08,769
email why because our infrastructure is

00:03:06,700 --> 00:03:12,669
based on her email and we are using

00:03:08,769 --> 00:03:16,689
premium for so many years her email is

00:03:12,669 --> 00:03:21,010
excellent and stubble and is a way

00:03:16,689 --> 00:03:23,979
stable our on our production if we

00:03:21,010 --> 00:03:26,530
switch to another project that means we

00:03:23,979 --> 00:03:30,699
needed human tend to different projects

00:03:26,530 --> 00:03:33,659
that is a huge burden for us

00:03:30,699 --> 00:03:37,150
another reason is that our people have

00:03:33,659 --> 00:03:41,829
where's John background have q email

00:03:37,150 --> 00:03:44,290
they can detect and fix any issues on Q

00:03:41,829 --> 00:03:49,659
email where you quickening so based on

00:03:44,290 --> 00:03:54,639
that we prefer to adapt QEMU to meet our

00:03:49,659 --> 00:03:59,650
requirements of course crema is not

00:03:54,639 --> 00:04:00,280
perfect it has idiots benefit that also

00:03:59,650 --> 00:04:03,669
has a sound

00:04:00,280 --> 00:04:06,150
these are the one pages for the benefits

00:04:03,669 --> 00:04:10,810
Karimi has the worst John Halliwell

00:04:06,150 --> 00:04:16,449
oscillation and also it it gets part of

00:04:10,810 --> 00:04:20,709
very interesting features but lots of

00:04:16,449 --> 00:04:25,479
code you in Q II know we didn't use it

00:04:20,709 --> 00:04:26,850
we didn't use it at all and it in a

00:04:25,479 --> 00:04:29,650
Western

00:04:26,850 --> 00:04:37,320
we haven't put up all so either way I

00:04:29,650 --> 00:04:41,580
use more resource so better than that

00:04:37,320 --> 00:04:44,860
our solution we call it to my best point

00:04:41,580 --> 00:04:52,380
by using our solution weakest data we

00:04:44,860 --> 00:04:55,960
can start up VM just for about 35 35

00:04:52,380 --> 00:04:59,710
milliseconds on the vault and it used

00:04:55,960 --> 00:05:03,340
very lead to memory best Kony our

00:04:59,710 --> 00:05:05,710
solution camp a past guest the kernel

00:05:03,340 --> 00:05:10,480
you need and also kept a pad

00:05:05,710 --> 00:05:13,450
karema you need first elastic let's look

00:05:10,480 --> 00:05:18,120
into how does our solution I passed

00:05:13,450 --> 00:05:21,150
guess that you need a grenade the idea

00:05:18,120 --> 00:05:24,780
behind I was launching the very simple

00:05:21,150 --> 00:05:30,490
way leverage a current mechanism of

00:05:24,780 --> 00:05:33,970
migration we use micro region to to to

00:05:30,490 --> 00:05:38,979
us never short of of a running way I'm

00:05:33,970 --> 00:05:44,020
so that it's a new creative we can

00:05:38,979 --> 00:05:47,770
direct any good answers snapshot in

00:05:44,020 --> 00:05:51,430
order to speed up the same well we use

00:05:47,770 --> 00:05:55,120
share the memory so the shared memory

00:05:51,430 --> 00:05:58,240
can be packed on huge TFS or even

00:05:55,120 --> 00:06:06,789
temporary FS as a temporary s get the

00:05:58,240 --> 00:06:10,750
support of just parent huge page so as a

00:06:06,789 --> 00:06:14,380
share the memory naturally persistent so

00:06:10,750 --> 00:06:19,830
we so we don't need that you save and

00:06:14,380 --> 00:06:25,600
restore the memory during creating the

00:06:19,830 --> 00:06:27,610
snapshot we should a sense to cut a

00:06:25,600 --> 00:06:35,110
container because we get us an idea of

00:06:27,610 --> 00:06:38,110
right so you know that you put a new VM

00:06:35,110 --> 00:06:42,070
we just directly put

00:06:38,110 --> 00:06:45,490
butit from frozen ever shot but pay

00:06:42,070 --> 00:06:47,889
attention is that when we when we put a

00:06:45,490 --> 00:06:52,419
new VM we should tensor share the memory

00:06:47,889 --> 00:06:54,220
off so that later if we if any change is

00:06:52,419 --> 00:06:57,580
manifested we are moved to the memory

00:06:54,220 --> 00:07:00,669
it'll either be a trigger copy all right

00:06:57,580 --> 00:07:07,060
that means a new memory we are be

00:07:00,669 --> 00:07:09,370
allocated for the new VM so later let's

00:07:07,060 --> 00:07:13,419
look into how does our solution bypass

00:07:09,370 --> 00:07:21,940
human Jeremy unit but I leave the rest

00:07:13,419 --> 00:07:24,669
to my colleague unit good afternoon

00:07:21,940 --> 00:07:27,700
everyone my name is Ellie I will finish

00:07:24,669 --> 00:07:30,130
the remaining introduction as Warren has

00:07:27,700 --> 00:07:33,010
mentioned after skip the gas the colonel

00:07:30,130 --> 00:07:34,650
put a period we will be able to shrink

00:07:33,010 --> 00:07:37,600
the gas that would have done quite a lot

00:07:34,650 --> 00:07:42,190
but is there any further improvement or

00:07:37,600 --> 00:07:45,100
optimization we quote made after

00:07:42,190 --> 00:07:48,640
investigation we find communion in your

00:07:45,100 --> 00:07:51,340
initialization will introduce proceed

00:07:48,640 --> 00:07:56,650
for latency during the gas to put up

00:07:51,340 --> 00:08:00,160
does it necessary for each VN boot up to

00:07:56,650 --> 00:08:02,050
use this latency we don't think so so in

00:08:00,160 --> 00:08:05,710
this second stage we are trying to

00:08:02,050 --> 00:08:08,740
eliminate eliminate the initial

00:08:05,710 --> 00:08:13,950
isolation cost to use fork to further

00:08:08,740 --> 00:08:13,950
speed up the service instance start up

00:08:14,250 --> 00:08:18,789
the implementation is quite

00:08:16,630 --> 00:08:21,639
straightforward as you can see in this

00:08:18,789 --> 00:08:25,479
picture on the top left you will see the

00:08:21,639 --> 00:08:28,419
base VM properly we can call it V M 0

00:08:25,479 --> 00:08:31,360
after boots up it will reach base point

00:08:28,419 --> 00:08:33,669
mode which will finish most of the Kumu

00:08:31,360 --> 00:08:37,690
initialization but not all the retailer

00:08:33,669 --> 00:08:39,430
works still some interactive still some

00:08:37,690 --> 00:08:42,370
interactive with the kernel kayvyun

00:08:39,430 --> 00:08:45,160
module need to return after folk

00:08:42,370 --> 00:08:47,770
throwing it so after finish all the

00:08:45,160 --> 00:08:50,260
neutralization the base point VN is

00:08:47,770 --> 00:08:51,620
ready for use we well create the

00:08:50,260 --> 00:08:54,080
template for it

00:08:51,620 --> 00:08:57,320
which will be used for other VN to

00:08:54,080 --> 00:08:59,480
restore from so as you can see the

00:08:57,320 --> 00:09:01,970
following VN one two three

00:08:59,480 --> 00:09:05,630
 up from the VM zero as well as

00:09:01,970 --> 00:09:07,670
the base point VN since it will be able

00:09:05,630 --> 00:09:10,880
to restore from the base point to skip

00:09:07,670 --> 00:09:15,290
the kernel boot up time to get her

00:09:10,880 --> 00:09:21,590
extremely faster put up for the micro

00:09:15,290 --> 00:09:23,600
service usage this page well should

00:09:21,590 --> 00:09:27,650
guess the boot up time with different

00:09:23,600 --> 00:09:30,860
confirmations so originally Camille with

00:09:27,650 --> 00:09:34,480
optimized the Linux kernel we can get

00:09:30,860 --> 00:09:37,940
about 500 milliseconds the boot up and

00:09:34,480 --> 00:09:41,240
after we apply the first optimization

00:09:37,940 --> 00:09:46,190
bypassed the canonical initialization we

00:09:41,240 --> 00:09:50,060
will achieve about 105 150 milliseconds

00:09:46,190 --> 00:09:52,880
and after we applied the bypass the

00:09:50,060 --> 00:09:56,870
communal mineralization we will achieve

00:09:52,880 --> 00:10:03,590
about 35 milliseconds for the VM to boot

00:09:56,870 --> 00:10:06,160
up which is a huge improvement and let's

00:10:03,590 --> 00:10:09,050
talk about the security of restored

00:10:06,160 --> 00:10:11,900
VMs since they are created from the same

00:10:09,050 --> 00:10:15,320
base point template is it possible for

00:10:11,900 --> 00:10:18,860
the malicious application to interpret

00:10:15,320 --> 00:10:21,080
what is going on in the other restore

00:10:18,860 --> 00:10:23,990
the VMS and intend to steal some

00:10:21,080 --> 00:10:28,550
information from them that is what we

00:10:23,990 --> 00:10:31,340
may need worry about so in order to

00:10:28,550 --> 00:10:34,820
enhance the security mechanism we will

00:10:31,340 --> 00:10:38,930
use the word hi Oh ing as the random

00:10:34,820 --> 00:10:41,780
number generator for guest and receiving

00:10:38,930 --> 00:10:44,540
the proper random numbers into the guest

00:10:41,780 --> 00:10:47,030
entry pose after restore T gets the from

00:10:44,540 --> 00:10:50,650
the base pointer template to make it a

00:10:47,030 --> 00:10:52,730
different Asian for each of them but

00:10:50,650 --> 00:10:55,130
still some openings

00:10:52,730 --> 00:10:57,410
unfortunately after as we skip the

00:10:55,130 --> 00:11:01,640
kernel boot up so we won't won't be able

00:10:57,410 --> 00:11:03,980
to utilize the kernel randomness to help

00:11:01,640 --> 00:11:06,500
protect the gasps the kernel

00:11:03,980 --> 00:11:09,590
but alternatively we could provide the

00:11:06,500 --> 00:11:16,430
dedicated template for each tenant to

00:11:09,590 --> 00:11:20,840
avoid this issue that let's talk about

00:11:16,430 --> 00:11:23,330
some future works so we will continue

00:11:20,840 --> 00:11:25,370
optimize the current comer code to find

00:11:23,330 --> 00:11:28,130
you the guest of all time to achieve

00:11:25,370 --> 00:11:30,380
much more faster and in the meanwhile

00:11:28,130 --> 00:11:32,870
meantime we want to introduce Camille

00:11:30,380 --> 00:11:36,980
modernization which will be flexible for

00:11:32,870 --> 00:11:38,660
device model hot plug and upgrade and of

00:11:36,980 --> 00:11:41,030
course we will continue working on the

00:11:38,660 --> 00:11:48,560
guest Colonel security enhancement as we

00:11:41,030 --> 00:11:50,480
just talked about so sis is the lastest

00:11:48,560 --> 00:11:53,230
rise for this session so we have proved

00:11:50,480 --> 00:11:56,690
that cumulative ID that to achieve

00:11:53,230 --> 00:11:59,960
requirement to faster deployment deploy

00:11:56,690 --> 00:12:04,040
intensive micro services in extremely

00:11:59,960 --> 00:12:05,930
short period so meanwhile the same

00:12:04,040 --> 00:12:08,570
McKenzie is also useful for our

00:12:05,930 --> 00:12:11,090
traditional VM based the production

00:12:08,570 --> 00:12:13,820
environment to help our customer to

00:12:11,090 --> 00:12:18,920
deploy our legacy service as fast as

00:12:13,820 --> 00:12:23,900
possible so this work we may call it

00:12:18,920 --> 00:12:28,930
Winston for two birds that's all for our

00:12:23,900 --> 00:12:28,930
introduction sex so in a question

00:12:36,210 --> 00:12:42,070
could you go back a few slides I just

00:12:38,620 --> 00:12:44,200
wanted to understand you do a fork to

00:12:42,070 --> 00:12:46,120
create a number of different cremes that

00:12:44,200 --> 00:12:48,370
are ready to run yeah and that one and

00:12:46,120 --> 00:12:49,270
then but then you restore from your

00:12:48,370 --> 00:12:53,440
template

00:12:49,270 --> 00:12:55,570
after the fork so does a fork only ever

00:12:53,440 --> 00:12:58,090
run one microservice and then it's done

00:12:55,570 --> 00:12:59,560
and get thrown away or does it get

00:12:58,090 --> 00:13:02,890
reused to run an additional

00:12:59,560 --> 00:13:06,250
microcircuits later I was just confused

00:13:02,890 --> 00:13:08,110
as to you you just saw the top line so

00:13:06,250 --> 00:13:12,910
this is we what we used to create a

00:13:08,110 --> 00:13:15,880
template so we put at the base vm 2 to a

00:13:12,910 --> 00:13:19,960
base pay to a base point mode and it's

00:13:15,880 --> 00:13:23,020
then forked from the original process to

00:13:19,960 --> 00:13:24,160
get a base point of vm and then we use

00:13:23,020 --> 00:13:26,500
the base point of vm to create a

00:13:24,160 --> 00:13:28,660
template all right so the yes so the

00:13:26,500 --> 00:13:30,880
template isn't already there it's the

00:13:28,660 --> 00:13:34,470
first thing created yeah we first create

00:13:30,880 --> 00:13:34,470
a template yeah understand oh thanks

00:13:45,730 --> 00:13:49,620
there are no other questions thank you

00:13:48,059 --> 00:13:51,710
thank you

00:13:49,620 --> 00:13:58,570
[Applause]

00:13:51,710 --> 00:13:58,570

YouTube URL: https://www.youtube.com/watch?v=5hIDwkpXUiw


