Title: KVM Forum 2013: RDMA Live Migration and RDMA Fault Tolerance by Michael Hines
Publication date: 2014-10-30
Playlist: KVM Forum 2013
Description: 
	Slides: https://docs.google.com/file/d/0BzyAwvVlQckebVBrNXdlaTdWVUk

This talk discusses the development RDMA Migration and Fault Tolerance as part of the migration system within QEMU and the challenges involved in developing both pieces of inter-related work. 

RDMA helps make your migration more deterministic under heavy load because of the lower latency and higher throughput over TCP/IP. In particular, a TCP-based migration, under certain types of memory-bound workloads, may take a more unpredicatable amount of time to complete the migration if the amount of memory tracked during each live migration iteration round cannot keep pace with the rate of dirty memory produced by the workload. Fault Tolerance in the virtualization community has gone through lots of growing pains, including implementations from Xen, VMWare, Marathon, and academia. This talk also summaries our attempt to perform Micro-Checkpointing inside KVM, making use of RDMA as well.
Captions: 
	00:00:00,060 --> 00:00:10,309
okay good afternoon everybody

00:00:04,100 --> 00:00:10,309
hello p.m. my Maximizer

00:00:29,260 --> 00:01:32,500
my name is Michael I'm here because

00:02:26,349 --> 00:02:39,469
technical changes you and go straight to

00:02:29,060 --> 00:02:40,500
the demo base based on the earlier maybe

00:02:39,469 --> 00:02:42,240
so

00:02:40,500 --> 00:03:15,330
 that was introduced a couple of

00:02:42,240 --> 00:03:24,840
months ago running a standard Ubuntu

00:03:15,330 --> 00:03:35,690
gift i okay Ubuntu gift it's like that

00:03:24,840 --> 00:04:04,950
example sessions pink we have on one

00:03:35,690 --> 00:04:07,769
physical evidence which the way and you

00:04:04,950 --> 00:04:18,810
can think of it basically as a lot of

00:04:07,769 --> 00:04:32,100
migrations that never end a lot of

00:04:18,810 --> 00:04:39,510
migration logic iterations of every

00:04:32,100 --> 00:04:43,010
second disturbing 2013 so migration

00:04:39,510 --> 00:04:43,010
iteration point

00:06:48,279 --> 00:06:55,400
also checkpointing Network IO so I can

00:06:53,300 --> 00:06:57,740
go into more detail about a complex

00:06:55,400 --> 00:07:00,319
topic probably too much of too much for

00:06:57,740 --> 00:07:02,990
a presentation and literally what I

00:07:00,319 --> 00:07:04,789
would do is so this is this is

00:07:02,990 --> 00:07:06,199
checkpoint inconvenience about 10 times

00:07:04,789 --> 00:07:08,780
per second

00:07:06,199 --> 00:07:14,740
everything millisecond and literally

00:07:08,780 --> 00:07:14,740
whatever new is is a little bit the host

00:07:14,770 --> 00:07:27,979
and killed the primary process just nuke

00:07:20,810 --> 00:07:36,529
easy and there's only BNC search I can

00:07:27,979 --> 00:07:43,009
continue interacting with goal is a

00:07:36,529 --> 00:07:45,080
complete network I'll say with missing

00:07:43,009 --> 00:08:22,839
as of today in terms of implementation

00:07:45,080 --> 00:08:27,490
is all simply a lack of manpower you

00:08:22,839 --> 00:08:27,490
would Monica can you monitor command or

00:08:29,409 --> 00:08:36,800
the application is very heavy right now

00:08:33,560 --> 00:08:38,839
it's the JDM it's just really really

00:08:36,800 --> 00:08:42,440
busy and the checkpoint of traffic is

00:08:38,839 --> 00:08:45,290
too high and I've made some decision

00:08:42,440 --> 00:08:46,970
that maybe I don't want to pay for the

00:08:45,290 --> 00:08:58,130
cost of checkpointing right now maybe I

00:08:46,970 --> 00:09:07,029
just want to do ours right you could

00:08:58,130 --> 00:09:07,029
turn you can let the initial

00:09:11,710 --> 00:09:22,070
questions well the more that a

00:09:15,530 --> 00:09:29,440
particular show back in slides so this

00:09:22,070 --> 00:09:33,440
would be that's exactly right

00:09:29,440 --> 00:09:36,020
especially detector 88 connection with

00:09:33,440 --> 00:09:39,110
TCP it's either a broken socket or with

00:09:36,020 --> 00:09:44,330
already amazed people I've made myself

00:09:39,110 --> 00:09:47,030
doesn't provide that level of connection

00:09:44,330 --> 00:09:48,290
lost information that I need to provide

00:09:47,030 --> 00:09:50,660
fault tolerance but basically when the

00:09:48,290 --> 00:09:53,150
connection breaks within a few

00:09:50,660 --> 00:09:56,120
checkpoints typically within a few

00:09:53,150 --> 00:09:57,230
milliseconds you immediately roll back

00:09:56,120 --> 00:10:00,080
to the previous checkpoint

00:09:57,230 --> 00:10:02,480
so I have a complete copy of the latest

00:10:00,080 --> 00:10:05,360
difference of winning races from about

00:10:02,480 --> 00:10:09,440
10 to 20 milliseconds ago I want to

00:10:05,360 --> 00:10:13,220
connect to brick I say okay let's load

00:10:09,440 --> 00:10:15,020
that check back I had to the VM using

00:10:13,220 --> 00:10:17,930
exactly the same code passes live

00:10:15,020 --> 00:10:20,360
migration so we striving to not avoid

00:10:17,930 --> 00:10:27,080
changing too much in in the in the call

00:10:20,360 --> 00:10:29,720
stack and then run the processor good

00:10:27,080 --> 00:10:32,120
question I'll talk about that now so in

00:10:29,720 --> 00:10:33,310
this in this is a classic problem in

00:10:32,120 --> 00:10:35,510
fault tolerance

00:10:33,310 --> 00:10:38,080
there's been a lot of attention at

00:10:35,510 --> 00:10:40,970
implementing this then it's done it

00:10:38,080 --> 00:10:43,370
there was a previous attempt with kumari

00:10:40,970 --> 00:10:44,510
for KTM it doesn't apply to commune

00:10:43,370 --> 00:10:47,330
master anymore

00:10:44,510 --> 00:10:51,290
but there was a very noble attempt so I

00:10:47,330 --> 00:10:53,600
would say the time supported but and

00:10:51,290 --> 00:10:55,190
also in the solutions had already made

00:10:53,600 --> 00:10:59,510
support which is critical for Network

00:10:55,190 --> 00:11:02,089
throughput and the classic problem with

00:10:59,510 --> 00:11:05,330
was fault tolerance is Iowa

00:11:02,089 --> 00:11:08,000
you cannot present a fully fault

00:11:05,330 --> 00:11:11,500
tolerant view of the virtual machine to

00:11:08,000 --> 00:11:13,790
the outside world without handling Eyal

00:11:11,500 --> 00:11:18,589
the network is particularly tricky

00:11:13,790 --> 00:11:21,800
because when a packet and then

00:11:18,589 --> 00:11:23,360
subsequently failed the me

00:11:21,800 --> 00:11:25,879
I'm immediately going to resume

00:11:23,360 --> 00:11:28,279
execution I'm not on the destination and

00:11:25,879 --> 00:11:30,170
that brings us a possibility of a

00:11:28,279 --> 00:11:33,379
duplicate packet you don't want to allow

00:11:30,170 --> 00:11:35,779
the virtual machine to transmit anything

00:11:33,379 --> 00:11:38,449
that may look duplicate or a Peter that

00:11:35,779 --> 00:11:41,929
state was lost any external clients tcpi

00:11:38,449 --> 00:11:44,269
IP or or or an external storage system

00:11:41,929 --> 00:11:47,119
so that require that you introduce a

00:11:44,269 --> 00:11:50,779
buffer it's very heavy weight buffer as

00:11:47,119 --> 00:11:57,559
of today we've got ideas for or have a

00:11:50,779 --> 00:12:03,589
diagram so basically what we do will

00:11:57,559 --> 00:12:10,749
screen this is the most performance

00:12:03,589 --> 00:12:13,040
anyways part of the of the solution is

00:12:10,749 --> 00:12:16,160
network buffering so basically we have

00:12:13,040 --> 00:12:18,529
two needles we have a thread ordinarily

00:12:16,160 --> 00:12:24,639
this to be live migration thread and in

00:12:18,529 --> 00:12:28,160
the face we do it over to my project

00:12:24,639 --> 00:12:43,209
during the procedure we have all Network

00:12:28,160 --> 00:12:43,209
packets they had open source software

00:12:47,049 --> 00:12:52,549
and then we need to send the control

00:12:50,209 --> 00:12:53,569
signal a physical to say okay the text

00:12:52,549 --> 00:12:55,910
is completed

00:12:53,569 --> 00:12:57,949
it's safe it's stored on the destination

00:12:55,910 --> 00:13:04,759
now release all the package to the

00:12:57,949 --> 00:13:08,199
outside world that's typically matters

00:13:04,759 --> 00:13:08,199
me something is sending assistant call

00:13:08,410 --> 00:13:12,439
happen which doesn't exist today free

00:13:10,699 --> 00:13:15,799
storage so this is demo I did it was

00:13:12,439 --> 00:13:17,899
basically I had this I stood the

00:13:15,799 --> 00:13:20,269
initiator inside the guest Colonel

00:13:17,899 --> 00:13:22,429
talking which ends up being that were

00:13:20,269 --> 00:13:24,199
traffic anyway so it was allowed to be

00:13:22,429 --> 00:13:26,360
fully fault all right but if you have a

00:13:24,199 --> 00:13:32,179
look at this you need something like

00:13:26,360 --> 00:13:34,730
drive mirror I think something like

00:13:32,179 --> 00:13:38,570
drive here to do mirroring of everything

00:13:34,730 --> 00:13:46,750
no destination and that would look

00:13:38,570 --> 00:14:00,680
something like this this is strong and

00:13:46,750 --> 00:14:04,370
picture what it might look like all and

00:14:00,680 --> 00:14:08,690
be complete we would really see the

00:14:04,370 --> 00:14:12,649
aisles straight to the disk and on

00:14:08,690 --> 00:14:17,930
targets I believe the idols to the side

00:14:12,649 --> 00:14:20,420
as well that doesn't exist today so but

00:14:17,930 --> 00:14:21,740
hopefully in a few months and a little

00:14:20,420 --> 00:14:25,100
bit more implementation it shouldn't be

00:14:21,740 --> 00:14:28,399
there so adds up it will have to mount

00:14:25,100 --> 00:14:32,120
it run it and the most recent version of

00:14:28,399 --> 00:14:35,480
community would have to mount this over

00:14:32,120 --> 00:14:37,970
a faculty or directly inside to get or

00:14:35,480 --> 00:14:45,110
in affairs of something similar I to get

00:14:37,970 --> 00:14:47,600
it to work so I give this talk I've

00:14:45,110 --> 00:14:50,290
given a lot of times and inevitably end

00:14:47,600 --> 00:14:52,310
up spending half the conversation

00:14:50,290 --> 00:14:55,069
answering questions from people who say

00:14:52,310 --> 00:14:58,370
ok my application is already all power

00:14:55,069 --> 00:15:01,670
are already highly available I'm using

00:14:58,370 --> 00:15:04,670
some well designed you know you store

00:15:01,670 --> 00:15:06,410
somewhere I've already packed my

00:15:04,670 --> 00:15:09,800
application server my database two

00:15:06,410 --> 00:15:14,930
pieces and it's already high why do I

00:15:09,800 --> 00:15:16,730
care about this well you know but I end

00:15:14,930 --> 00:15:24,440
up spending half the talk saying well

00:15:16,730 --> 00:15:27,470
you don't you don't need it at all and

00:15:24,440 --> 00:15:29,480
you've done an excellent job at making

00:15:27,470 --> 00:15:31,490
your application how highly available

00:15:29,480 --> 00:15:33,860
then that is the way to go you should

00:15:31,490 --> 00:15:35,959
keep using that you know input

00:15:33,860 --> 00:15:38,810
proliferate that through your theater so

00:15:35,959 --> 00:15:42,050
your product you don't have that yeah

00:15:38,810 --> 00:15:45,769
something legacy that you can't tolerate

00:15:42,050 --> 00:15:48,019
go down and then and then then then this

00:15:45,769 --> 00:15:48,499
would help you a lot and we have a lot

00:15:48,019 --> 00:15:52,599
of soft

00:15:48,499 --> 00:15:57,039
like that in IBM that's very old that

00:15:52,599 --> 00:15:59,869
this very old and can't be changed ever

00:15:57,039 --> 00:16:03,909
running in virtualized environments that

00:15:59,869 --> 00:16:07,659
needs some ability and this was a

00:16:03,909 --> 00:16:12,139
stepping stone to get you to that point

00:16:07,659 --> 00:16:14,089
again when should you not use it if your

00:16:12,139 --> 00:16:18,109
software is already written to be highly

00:16:14,089 --> 00:16:24,679
available that's all I have to say about

00:16:18,109 --> 00:16:35,779
this particular questions about fall

00:16:24,679 --> 00:16:38,569
time specifically our work yes now that

00:16:35,779 --> 00:16:41,169
we have our DMA overwhelmingly now the

00:16:38,569 --> 00:16:47,419
highest cost and fault tolerance is

00:16:41,169 --> 00:16:48,949
identifying dirty memory and I just just

00:16:47,419 --> 00:16:52,279
means we need more heads than the

00:16:48,949 --> 00:16:54,619
problem currently the infamy of needle

00:16:52,279 --> 00:16:56,949
when you initiated a lot of migration

00:16:54,619 --> 00:17:00,109
you have to identified will change

00:16:56,949 --> 00:17:02,869
standard procedure it's very expensive

00:17:00,109 --> 00:17:04,879
today I take about one millisecond to

00:17:02,869 --> 00:17:06,769
get a log 30 bitmap from the kernel last

00:17:04,879 --> 00:17:11,000
time I timed it let me get a companion

00:17:06,769 --> 00:17:12,769
it takes five mils processed a lot of

00:17:11,000 --> 00:17:16,429
every business into a might miss might

00:17:12,769 --> 00:17:17,089
map for a 4gb ended I that's not even

00:17:16,429 --> 00:17:23,959
doing anything

00:17:17,089 --> 00:17:25,639
if you very large be second worst

00:17:23,959 --> 00:17:27,980
kitties and that's overwhelmingly the

00:17:25,639 --> 00:17:29,649
largest performance model night that has

00:17:27,980 --> 00:17:33,259
to be solved before this King

00:17:29,649 --> 00:17:35,840
ballistically be deployed without

00:17:33,259 --> 00:17:39,619
without hurting your application too

00:17:35,840 --> 00:17:44,659
much and just just we just need more

00:17:39,619 --> 00:17:47,840
need more heads at the problem so let's

00:17:44,659 --> 00:17:55,960
go to the end here with a very simple

00:17:47,840 --> 00:17:58,789
graph where did the cost come from

00:17:55,960 --> 00:18:02,389
biting preparation is this big red line

00:17:58,789 --> 00:18:05,539
and milliseconds

00:18:02,389 --> 00:18:11,869
last time I kinda idle the endless

00:18:05,539 --> 00:18:17,749
building huge just verify that it's

00:18:11,869 --> 00:18:20,479
mostly all my time so what happens the

00:18:17,749 --> 00:18:22,609
completely different man puts it into a

00:18:20,479 --> 00:18:27,320
local state dinner held in the same

00:18:22,609 --> 00:18:29,779
being once that stage copy is made the

00:18:27,320 --> 00:18:31,489
process resumed immediately we don't

00:18:29,779 --> 00:18:33,889
want we don't want to keep the processor

00:18:31,489 --> 00:18:35,809
down too long then that strength that

00:18:33,889 --> 00:18:38,659
checkpoint that's been copied is

00:18:35,809 --> 00:18:40,549
transmitted over our DNA and that's

00:18:38,659 --> 00:18:42,200
roughly how I say so there's a big red

00:18:40,549 --> 00:18:47,869
bar in the middle it's really where we

00:18:42,200 --> 00:18:49,700
need to tackle to to speed this up so

00:18:47,869 --> 00:18:52,489
now I'll go back to the still live

00:18:49,700 --> 00:18:56,299
migration we never could have gotten

00:18:52,489 --> 00:18:58,039
this far without without without without

00:18:56,299 --> 00:19:00,259
really without already made just because

00:18:58,039 --> 00:19:02,479
we have these 40 gigabit if any man

00:19:00,259 --> 00:19:07,249
cards sitting in and our and our office

00:19:02,479 --> 00:19:09,799
and it was pegging 100% just to just to

00:19:07,249 --> 00:19:11,839
keep them each network full and it works

00:19:09,799 --> 00:19:14,089
if I'm if I run TCP over that it would

00:19:11,839 --> 00:19:16,339
work it works fine it's just that I've

00:19:14,089 --> 00:19:25,820
lost that process basically spending all

00:19:16,339 --> 00:19:27,950
that time moving data so so this

00:19:25,820 --> 00:19:31,489
probably be my last line I think and and

00:19:27,950 --> 00:19:34,339
I was only five thirty minutes you can

00:19:31,489 --> 00:19:39,229
prep for next connection easy other way

00:19:34,339 --> 00:19:40,940
this works is we find the entire fault

00:19:39,229 --> 00:19:43,249
tolerance implementation we need to

00:19:40,940 --> 00:19:45,289
solve this problem so starting about

00:19:43,249 --> 00:19:49,369
January or so we went through the review

00:19:45,289 --> 00:19:51,019
process and the way it works if you

00:19:49,369 --> 00:19:53,479
don't already know or correct me if I'm

00:19:51,019 --> 00:19:54,889
wrong I'm I was originally amazed person

00:19:53,479 --> 00:19:59,749
before I started this I just started

00:19:54,889 --> 00:20:01,339
reading van pages in 2012 figuring out

00:19:59,749 --> 00:20:05,119
what functions to call in the infinite

00:20:01,339 --> 00:20:07,309
and cost and what it works is you have

00:20:05,119 --> 00:20:09,469
to register memory on both sides so the

00:20:07,309 --> 00:20:13,129
initial live migration iteration and a

00:20:09,469 --> 00:20:16,479
little bit of time three maka memory and

00:20:13,129 --> 00:20:16,479
remember side

00:20:19,260 --> 00:20:32,710
our kings ass and that's what this a

00:20:25,380 --> 00:20:37,240
little font issue what this shows is

00:20:32,710 --> 00:20:39,190
what we get with spec CPU which is not

00:20:37,240 --> 00:20:41,800
entirely realistic but it but it but uh

00:20:39,190 --> 00:20:43,420
it gives you an idea of what kind of

00:20:41,800 --> 00:20:48,220
benefit you will get with already a made

00:20:43,420 --> 00:20:49,960
by itself fault tolerant set aside just

00:20:48,220 --> 00:21:08,170
what is it you're getting for that

00:20:49,960 --> 00:21:10,809
feature I'll just explain the bar so all

00:21:08,170 --> 00:21:13,240
of these bars are generated with 40

00:21:10,809 --> 00:21:15,600
gigabit Mellanox adapters running over

00:21:13,240 --> 00:21:18,100
overawed in advance so we also have some

00:21:15,600 --> 00:21:20,679
RTA over ethernet adapters and i'd say

00:21:18,100 --> 00:21:23,230
that this is a good time to write this

00:21:20,679 --> 00:21:25,740
because are you I'd say already giving

00:21:23,230 --> 00:21:28,120
over Ethernet is almost commodity I

00:21:25,740 --> 00:21:30,820
think that's a fair statement to make

00:21:28,120 --> 00:21:38,080
you can buy them fairly cheaply you can

00:21:30,820 --> 00:21:42,100
get a $700 you are getting every connect

00:21:38,080 --> 00:21:44,050
card and plug it into your service so

00:21:42,100 --> 00:21:51,010
they're pretty easy to get your hands on

00:21:44,050 --> 00:21:55,840
so these bars are one gigabit 40 gigabit

00:21:51,010 --> 00:21:59,500
10 gigabit and 42 gibbet basically what

00:21:55,840 --> 00:22:03,220
they say is the downtime associated that

00:21:59,500 --> 00:22:05,380
I can achieve running spec CPU 2006 I

00:22:03,220 --> 00:22:08,350
believe as about a seven hundred

00:22:05,380 --> 00:22:11,380
megabits footprint so compared to some

00:22:08,350 --> 00:22:13,059
of the used to that's not too big

00:22:11,380 --> 00:22:18,309
actually but it's just to give you an

00:22:13,059 --> 00:22:20,730
idea of comparative down times without

00:22:18,309 --> 00:22:24,010
without it just running a standard TCP

00:22:20,730 --> 00:22:27,790
down down times can be as high as high

00:22:24,010 --> 00:22:28,500
as seconds just you can get to the point

00:22:27,790 --> 00:22:31,680
where you

00:22:28,500 --> 00:22:34,850
they don't convert so there's a range

00:22:31,680 --> 00:22:39,470
where opportunities are extremely

00:22:34,850 --> 00:22:39,470
everything it can possibly do this man

00:22:45,260 --> 00:22:50,430
you know the case was extremely busy and

00:22:48,690 --> 00:22:51,990
it's uncontrollably busy

00:22:50,430 --> 00:22:55,050
there was anesthesia actually didn't

00:22:51,990 --> 00:22:57,990
release a couple months ago that

00:22:55,050 --> 00:23:00,330
throttle that's probably something he

00:22:57,990 --> 00:23:01,650
would actually slow down you should at

00:23:00,330 --> 00:23:04,470
the end in order for it to be my

00:23:01,650 --> 00:23:08,130
gradable then he started getting workers

00:23:04,470 --> 00:23:12,120
into this area where they're not made

00:23:08,130 --> 00:23:14,370
admitted to the point where TCC could

00:23:12,120 --> 00:23:17,280
handle the migration and converge up to

00:23:14,370 --> 00:23:20,640
a point and then between that and being

00:23:17,280 --> 00:23:33,060
absolutely crazy saying that's we're

00:23:20,640 --> 00:23:34,890
already making it you space until it so

00:23:33,060 --> 00:23:37,280
in this case like even we have a seven

00:23:34,890 --> 00:23:39,540
hundred megabyte footprint

00:23:37,280 --> 00:23:42,360
ordinarily when we were running TCP

00:23:39,540 --> 00:23:44,670
migrations it would take you know

00:23:42,360 --> 00:23:46,350
several tens of seconds and with our

00:23:44,670 --> 00:23:54,150
team a turned on we can get migrations

00:23:46,350 --> 00:23:56,900
to under a second with spec CPU blasting

00:23:54,150 --> 00:23:56,900
away right

00:23:59,220 --> 00:24:04,530
it's not a panacea for everything

00:24:01,520 --> 00:24:07,590
particularly the one thing I wanted to

00:24:04,530 --> 00:24:09,660
mention last was I think one of the

00:24:07,590 --> 00:24:30,510
hardest parts we had to do to it with

00:24:09,660 --> 00:24:32,310
argument migration was so one of the one

00:24:30,510 --> 00:24:34,440
of the last remaining parts in getting

00:24:32,310 --> 00:24:38,930
getting the bachelors over-committing so

00:24:34,440 --> 00:24:42,070
the participation

00:24:38,930 --> 00:24:44,510
the destination host can can be

00:24:42,070 --> 00:24:47,630
opportunities and that means that you

00:24:44,510 --> 00:24:49,190
don't actually have to have all of the

00:24:47,630 --> 00:24:52,580
memory that you need the whole virtual

00:24:49,190 --> 00:25:00,400
machine argot available the migration

00:24:52,580 --> 00:25:11,690
hat even do this so I could have a

00:25:00,400 --> 00:25:15,320
hundred million only available on this

00:25:11,690 --> 00:25:17,320
nation this will just work because you

00:25:15,320 --> 00:25:20,090
don't need to register in America

00:25:17,320 --> 00:25:22,130
that's a clear disadvantage Marty MA

00:25:20,090 --> 00:25:28,130
so if you if you need that kind of

00:25:22,130 --> 00:25:30,350
ability if you don't and you know you've

00:25:28,130 --> 00:25:51,230
done proper planning the hosts

00:25:30,350 --> 00:25:59,170
sufficiently large as efficiently to do

00:25:51,230 --> 00:26:02,480
much for you because your and

00:25:59,170 --> 00:26:04,220
application isn't very active it doesn't

00:26:02,480 --> 00:26:08,270
really help you use it you should just

00:26:04,220 --> 00:26:12,110
leave off to the factory very young I

00:26:08,270 --> 00:26:15,860
say young and full of zero as well you

00:26:12,110 --> 00:26:18,080
mean not zeros it smart enough to know

00:26:15,860 --> 00:26:19,640
that if a is zero there's no need for

00:26:18,080 --> 00:26:24,860
argument you don't need to spend less

00:26:19,640 --> 00:26:26,270
and you also have some powerful

00:26:24,860 --> 00:26:29,510
information that your being doesn't

00:26:26,270 --> 00:26:31,970
converge and you pretty much know that

00:26:29,510 --> 00:26:34,670
if you sparta might converge you you you

00:26:31,970 --> 00:26:37,250
got prior knowledge you know you know

00:26:34,670 --> 00:26:39,020
how your application is you really need

00:26:37,250 --> 00:26:40,610
the other converge feature that was

00:26:39,020 --> 00:26:42,530
recently introduced into community you

00:26:40,610 --> 00:26:45,590
need to throttle it before you can

00:26:42,530 --> 00:26:49,910
attend to migrate but if you do fall

00:26:45,590 --> 00:26:51,930
into that predictable range of dirty

00:26:49,910 --> 00:26:54,530
race where

00:26:51,930 --> 00:27:04,470
you need to get higher than higher than

00:26:54,530 --> 00:27:07,200
and you want to be cycles initially so

00:27:04,470 --> 00:27:09,690
that's a lot more work to do on fault

00:27:07,200 --> 00:27:17,960
tolerance there's a lot of bottlenecks

00:27:09,690 --> 00:27:21,059
in there well thank everybody for

00:27:17,960 --> 00:27:25,860
English I'm I intend to devote more

00:27:21,059 --> 00:27:30,200
review time myself I think thank you are

00:27:25,860 --> 00:27:34,400
there any questions about station design

00:27:30,200 --> 00:27:34,400
articular fault tolerance in particular

00:27:48,800 --> 00:27:57,179
I learned a lot it's important to follow

00:27:54,990 --> 00:27:59,250
the closed path of my great migration is

00:27:57,179 --> 00:28:00,960
created you don't want to have a lot of

00:27:59,250 --> 00:28:04,580
side channel you don't want to have a

00:28:00,960 --> 00:28:06,780
lot of weird cash or they to go if you

00:28:04,580 --> 00:28:08,910
have the right additional management

00:28:06,780 --> 00:28:12,000
software additional controls to deal

00:28:08,910 --> 00:28:13,860
with so hopefully I'm in a few months we

00:28:12,000 --> 00:28:17,429
should have something they just called

00:28:13,860 --> 00:28:49,110
drive mirror turns it on held it waiting

00:28:17,429 --> 00:28:55,800
to stop and start so this is a great

00:28:49,110 --> 00:29:00,030
question this is a great question so I'm

00:28:55,800 --> 00:29:01,500
gonna post copy and I presented it and

00:29:00,030 --> 00:29:04,020
the first thing that happened was a

00:29:01,500 --> 00:29:05,970
vmware employee came up to me instead

00:29:04,020 --> 00:29:07,590
Michael post got me sounds interesting

00:29:05,970 --> 00:29:10,830
but what happens if the destination

00:29:07,590 --> 00:29:13,020
fails and I didn't have a good answer at

00:29:10,830 --> 00:29:16,140
that time and the reality is it free

00:29:13,020 --> 00:29:18,840
copy and in a picture scenario where the

00:29:16,140 --> 00:29:21,450
destination fails will continues working

00:29:18,840 --> 00:29:23,610
you know you don't care if the

00:29:21,450 --> 00:29:25,260
destination I mean think about failure

00:29:23,610 --> 00:29:28,620
when you when you start to think about a

00:29:25,260 --> 00:29:32,700
close copy in general and that is the

00:29:28,620 --> 00:29:34,890
biggest problem the post copy idea if I

00:29:32,700 --> 00:29:38,910
were a freak about migration then your

00:29:34,890 --> 00:29:41,280
live migration mission will fail if it

00:29:38,910 --> 00:29:43,679
fails the means are still there

00:29:41,280 --> 00:29:45,840
you know all of its data still there all

00:29:43,679 --> 00:29:48,300
the execution is there just keeps

00:29:45,840 --> 00:29:50,580
running you solve this problem with

00:29:48,300 --> 00:29:53,820
those copy you can if you lose one or

00:29:50,580 --> 00:29:56,970
more holes in that post copy laughing

00:29:53,820 --> 00:29:58,830
you lose everything the memes destroyed

00:29:56,970 --> 00:30:00,780
essentially if it's totally inconsistent

00:29:58,830 --> 00:30:02,370
you've got state here and state in the

00:30:00,780 --> 00:30:06,110
other location they need to be

00:30:02,370 --> 00:30:08,790
reconciled so far and my Sophos

00:30:06,110 --> 00:30:12,929
depending on how well at the polls you

00:30:08,790 --> 00:30:15,210
could back replicate the changes on the

00:30:12,929 --> 00:30:17,130
destinations to the source and that way

00:30:15,210 --> 00:30:19,110
you might have a consistent environment

00:30:17,130 --> 00:30:20,970
in book locations but it's a long way

00:30:19,110 --> 00:30:23,370
away I mean just there's so much code

00:30:20,970 --> 00:30:25,890
that needs to be optimized in order for

00:30:23,370 --> 00:30:28,620
that to happen so I think so stop your

00:30:25,890 --> 00:30:31,290
school that has serious flaws and these

00:30:28,620 --> 00:30:35,360
blocks can't be ignored and oh no in

00:30:31,290 --> 00:30:35,360
order for it speed production-ready

00:30:41,179 --> 00:31:05,900
backwards right that happens that's a

00:31:03,000 --> 00:31:05,900
one-time operation

00:31:15,750 --> 00:31:20,590
so there is one bouncer that had to

00:31:18,550 --> 00:31:24,520
happen in the intolerance and the

00:31:20,590 --> 00:31:26,380
involve implementation so the main

00:31:24,520 --> 00:31:29,110
concern is I want the processor running

00:31:26,380 --> 00:31:31,690
I don't want to process it down this is

00:31:29,110 --> 00:31:34,840
a library from the never hidden so I

00:31:31,690 --> 00:31:38,020
want the the process specifically now

00:31:34,840 --> 00:31:40,390
all the time for any milliseconds

00:31:38,020 --> 00:31:42,370
further you know while the application

00:31:40,390 --> 00:31:45,880
is running if I do that the VM won't

00:31:42,370 --> 00:31:47,320
make any forward progress so we the same

00:31:45,880 --> 00:31:50,260
way that other implementations have done

00:31:47,320 --> 00:31:52,390
it you make a complete copy of the Delta

00:31:50,260 --> 00:31:54,340
that the live migration call path used

00:31:52,390 --> 00:31:57,160
to me and then I just take it directly

00:31:54,340 --> 00:32:00,760
from that but I dump it into a copy in

00:31:57,160 --> 00:32:05,860
memory and then I started spraying out

00:32:00,760 --> 00:32:07,420
to the destination right so we're with

00:32:05,860 --> 00:32:11,710
fault tolerance I only have to register

00:32:07,420 --> 00:32:12,910
the Delta Area a staging area that needs

00:32:11,710 --> 00:32:18,730
to be transmitted I don't have to

00:32:12,910 --> 00:32:22,510
register the rest of it necessarily yes

00:32:18,730 --> 00:32:24,280
you have to and that's exactly what was

00:32:22,510 --> 00:32:25,690
what I was describing with which was

00:32:24,280 --> 00:32:26,410
which call of the problem for

00:32:25,690 --> 00:32:28,150
over-commitment

00:32:26,410 --> 00:32:30,610
because I don't need to do this with TCP

00:32:28,150 --> 00:32:35,890
so if I have a black migration it takes

00:32:30,610 --> 00:32:40,660
a very long time the a minute which is a

00:32:35,890 --> 00:32:42,630
lot of Baltimore or 10 seconds you could

00:32:40,660 --> 00:32:45,760
arbiter

00:32:42,630 --> 00:32:59,890
swap out for the VM in the middle of the

00:32:45,760 --> 00:33:02,490
migration which can't do that if you ask

00:32:59,890 --> 00:33:02,490
me there

00:33:11,700 --> 00:33:24,880
yeah that would be really cool it's just

00:33:20,080 --> 00:33:30,210
a matter of manpower I'm sort of already

00:33:24,880 --> 00:33:30,210
made registration window or yeah

00:33:32,130 --> 00:33:35,610

YouTube URL: https://www.youtube.com/watch?v=hRWeoWHLa90


