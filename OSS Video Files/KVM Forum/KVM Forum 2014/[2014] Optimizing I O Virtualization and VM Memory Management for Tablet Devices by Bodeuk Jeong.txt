Title: [2014] Optimizing I O Virtualization and VM Memory Management for Tablet Devices by Bodeuk Jeong
Publication date: 2014-10-23
Playlist: KVM Forum 2014
Description: 
	In this talk, we present our production-level optimization effort in both Android and QEMU/KVM for bringing out the virtualization tech to tablet devices. There are two key requirements for running Windows as an Android app: 1.To achieve good performance in terms of user perception; Starting up a Windows VM and switching from and to other apps should be done in a short period of time. Human interactive IO devices should be in no delay. 2.To seamlessly interface QEMU with Android framework. We develop automatic ballooning with low memory killer and activity manager. We also implement virtual IO devices such as multi-touch, audio w/ openSL, bluetooth w/ Bluedroid, etc. In addition, we optimize VM snapshot loader by modifying qcow2 and utilizing transparent huge pages. As a result, VM boot-time is reduced by 90% and VM performance is not compromised with IO delay on a recent Atom tablet.


Bokdeuk Jeong
Samsung Electronics
Bokdeuk Jeong is a senior engineer at Software R&D center in Samsung Electronics. She is currenlty involved in a mobile virtualization project.


Slides: http://events.linuxfoundation.org/sites/events/files/slides/KVMForum2014_BokdeukJeong_final.pdf


KVM Forum Schedule: http://sched.co/1pkqKEr
Captions: 
	00:00:08,360 --> 00:00:15,510
today I'm going to talk about our

00:00:11,460 --> 00:00:17,939
efforts in Android and kayvyun qmu to

00:00:15,510 --> 00:00:21,360
bring out the virtualization technology

00:00:17,939 --> 00:00:24,119
to W divided we focused on optimizing

00:00:21,360 --> 00:00:32,460
our virtualization and vm memory

00:00:24,119 --> 00:00:35,430
management from a tablet we run Windows

00:00:32,460 --> 00:00:39,329
8.1 in a virtual machine on Android

00:00:35,430 --> 00:00:43,289
KitKat OS with the atom tablet these are

00:00:39,329 --> 00:00:47,100
screenshots that we take to on our

00:00:43,289 --> 00:00:51,449
target tablet in the first one windows

00:00:47,100 --> 00:00:53,699
always runs it is seen in the list of

00:00:51,449 --> 00:00:56,699
the applications that are currently

00:00:53,699 --> 00:01:01,109
running on Android in the second

00:00:56,699 --> 00:01:04,500
screenshot the Android notification bar

00:01:01,109 --> 00:01:07,470
is dragged down to check some message or

00:01:04,500 --> 00:01:10,710
arrival while Windows OS is that

00:01:07,470 --> 00:01:13,920
currently displayed as our target

00:01:10,710 --> 00:01:17,540
Hardware spec we used pay trail Intel

00:01:13,920 --> 00:01:21,810
Atom processor and four gigabytes of RAM

00:01:17,540 --> 00:01:25,820
64 gigabytes of emmc for our tests we

00:01:21,810 --> 00:01:28,800
reduced the host - RAM - 3 gigabytes for

00:01:25,820 --> 00:01:32,520
virtual machine we assigned for virtual

00:01:28,800 --> 00:01:35,580
CPUs 1 gigabyte of RAM and 32 gigabytes

00:01:32,520 --> 00:01:41,640
of virtual disk on both Android and

00:01:35,580 --> 00:01:45,060
Windows it has a 32-bit OS to run

00:01:41,640 --> 00:01:48,360
Windows on Android we had two references

00:01:45,060 --> 00:01:51,090
one is a limbo and rate and another is

00:01:48,360 --> 00:01:54,060
Intel's talk last year to briefly

00:01:51,090 --> 00:01:57,860
introduce them the limbo Android is a

00:01:54,060 --> 00:02:01,650
wrapper program to run qemu on Android

00:01:57,860 --> 00:02:04,680
Intel enabled the limbo with the KVM

00:02:01,650 --> 00:02:07,410
support and added some system calls and

00:02:04,680 --> 00:02:10,349
functions which is missing in Bionic sea

00:02:07,410 --> 00:02:13,440
and in folders Samsung rebates the

00:02:10,349 --> 00:02:16,470
Limbo's QEMU version to 1.7

00:02:13,440 --> 00:02:19,980
which was most recent and stable version

00:02:16,470 --> 00:02:20,540
at the beginning of this year as we use

00:02:19,980 --> 00:02:22,760
00:02:20,540 --> 00:02:25,670
dividend rate colonel we had to

00:02:22,760 --> 00:02:29,000
configure its colonel with the PA you

00:02:25,670 --> 00:02:33,829
support so as Windows to be able to use

00:02:29,000 --> 00:02:36,439
an XP for its memory management we

00:02:33,829 --> 00:02:39,530
enable the VM to use more than one

00:02:36,439 --> 00:02:42,560
gigabyte of RAM in the very limited

00:02:39,530 --> 00:02:46,180
space in the limited virtual address

00:02:42,560 --> 00:02:51,049
space in limbo on 32-bit hosts in

00:02:46,180 --> 00:02:54,409
addition we virtualized IO devices that

00:02:51,049 --> 00:02:55,549
users users would frequently use on

00:02:54,409 --> 00:02:58,579
tablet devices

00:02:55,549 --> 00:03:02,510
those are multitask Bluetooth Wi-Fi

00:02:58,579 --> 00:03:06,500
access battery status monitoring audio

00:03:02,510 --> 00:03:10,579
and 2d 3d graphics rendering to overcome

00:03:06,500 --> 00:03:13,489
the slow speed of VGA emulation we had

00:03:10,579 --> 00:03:21,620
an approach of a forwarding graphics API

00:03:13,489 --> 00:03:24,859
from guest VM to host host machine but

00:03:21,620 --> 00:03:28,819
there's a still missing part it is there

00:03:24,859 --> 00:03:32,239
windows runs and runs as an application

00:03:28,819 --> 00:03:36,290
on android according to some survey

00:03:32,239 --> 00:03:38,919
users will wait five seconds and most

00:03:36,290 --> 00:03:42,260
for loading applications

00:03:38,919 --> 00:03:46,310
putting windows VM may take a minute and

00:03:42,260 --> 00:03:49,400
this doesn't meet user expectation for e

00:03:46,310 --> 00:03:51,709
for this we had an approach of starting

00:03:49,400 --> 00:03:55,639
of a virtual machine with a snapshot

00:03:51,709 --> 00:03:56,090
image another is when Android is low on

00:03:55,639 --> 00:03:58,669
memory

00:03:56,090 --> 00:04:00,970
it kills an application in background

00:03:58,669 --> 00:04:05,030
with the heaviest memory usage first

00:04:00,970 --> 00:04:07,159
that means when VM goes in background it

00:04:05,030 --> 00:04:12,919
will be the number one target to be

00:04:07,159 --> 00:04:16,400
killed as a as a solution we utilize the

00:04:12,919 --> 00:04:19,340
automatic memory belonging to reserve a

00:04:16,400 --> 00:04:23,240
free memory space for four steps and

00:04:19,340 --> 00:04:26,690
take a snapshot when VM is get killed by

00:04:23,240 --> 00:04:30,169
Android and resume from the state later

00:04:26,690 --> 00:04:33,660
the last one is personalized i/o devices

00:04:30,169 --> 00:04:38,600
in QAM use should interface with and

00:04:33,660 --> 00:04:38,600
the word to use physical i/o devices I

00:04:38,690 --> 00:04:45,510
will talk about how we were able to run

00:04:42,360 --> 00:04:49,250
a virtual machine with around five

00:04:45,510 --> 00:04:52,620
seconds we measure the time from

00:04:49,250 --> 00:04:56,100
initializing qvm util display Metro UI

00:04:52,620 --> 00:04:58,170
inside the windows we set automatic

00:04:56,100 --> 00:05:02,490
login it in Windows

00:04:58,170 --> 00:05:07,380
it took about 50 seconds in total out of

00:05:02,490 --> 00:05:11,130
50 33 was coming from booting Windows 12

00:05:07,380 --> 00:05:13,740
12 seconds from automatic login if there

00:05:11,130 --> 00:05:16,140
was a major change in configuration in

00:05:13,740 --> 00:05:20,730
vedyam or a disk image it was very dirty

00:05:16,140 --> 00:05:24,030
it took additional 7 seconds if we take

00:05:20,730 --> 00:05:28,470
a snapshot and start from it it took

00:05:24,030 --> 00:05:30,570
about 10 seconds and at the time we took

00:05:28,470 --> 00:05:33,170
the snapshot the snapshot size was

00:05:30,570 --> 00:05:38,880
around 580 megabytes

00:05:33,170 --> 00:05:44,310
by modifying qemu properly we got five

00:05:38,880 --> 00:05:50,430
seconds I'll talk about how we were able

00:05:44,310 --> 00:05:55,470
to get a four seconds for loading VM

00:05:50,430 --> 00:06:00,720
snapshot first first we had a separate

00:05:55,470 --> 00:06:03,450
file to store a VM state we were using

00:06:00,720 --> 00:06:06,090
to code to file for storing for sure

00:06:03,450 --> 00:06:09,120
disk image and that the size of a cou

00:06:06,090 --> 00:06:11,460
couple had increased more than 15

00:06:09,120 --> 00:06:15,270
gigabytes after installing a few

00:06:11,460 --> 00:06:18,630
applications including MS Office the

00:06:15,270 --> 00:06:21,900
larger size of a file causes the latency

00:06:18,630 --> 00:06:23,130
inserting metadata at two layer one is

00:06:21,900 --> 00:06:25,710
@qq

00:06:23,130 --> 00:06:29,280
looking up the l1 and l2 table and

00:06:25,710 --> 00:06:32,580
another one is at the host file system

00:06:29,280 --> 00:06:37,470
looking up the blog index corresponding

00:06:32,580 --> 00:06:39,680
to a file offset snapshot is larger size

00:06:37,470 --> 00:06:42,870
of sequentially stored data

00:06:39,680 --> 00:06:44,010
considering its a sequential property we

00:06:42,870 --> 00:06:46,710
increase it

00:06:44,010 --> 00:06:50,550
we increase the buffer size of a QEMU

00:06:46,710 --> 00:06:54,450
pounder QEMU file data structure from 32

00:06:50,550 --> 00:06:57,530
kilobyte to 500 kilobyte to access

00:06:54,450 --> 00:07:00,870
histories at full bandwidth

00:06:57,530 --> 00:07:03,900
additionally additionally we had we

00:07:00,870 --> 00:07:07,320
added long api to give a read or header

00:07:03,900 --> 00:07:09,990
hint to the virtual block layer when

00:07:07,320 --> 00:07:13,410
queue culture prepares to load snapshot

00:07:09,990 --> 00:07:16,080
it gives the reader a healthy hand with

00:07:13,410 --> 00:07:19,200
the start offset of a snapshot as well

00:07:16,080 --> 00:07:21,630
as each size internally it is

00:07:19,200 --> 00:07:25,170
implemented with Apple device function

00:07:21,630 --> 00:07:25,830
with the conjurer attribute at raw

00:07:25,170 --> 00:07:28,830
projects

00:07:25,830 --> 00:07:35,610
blog layer which Kakao to eventually

00:07:28,830 --> 00:07:39,000
cause there was a they were also changed

00:07:35,610 --> 00:07:42,090
in the layout of store the RAM state so

00:07:39,000 --> 00:07:47,400
in the upper diagram it is from existing

00:07:42,090 --> 00:07:51,240
QEMU except 0 pages each for gigabyte of

00:07:47,400 --> 00:07:53,730
memories are saved with APIs 8 bytes of

00:07:51,240 --> 00:07:57,420
header together and sequential details

00:07:53,730 --> 00:08:00,360
quit sequentially stored later on it is

00:07:57,420 --> 00:08:05,130
loaded into cue a new paper first and

00:08:00,360 --> 00:08:08,160
then copied to VM Ram area to avoid

00:08:05,130 --> 00:08:11,490
memory copy overhead we save the

00:08:08,160 --> 00:08:14,400
contiguous non 0 pages larger than 500

00:08:11,490 --> 00:08:17,580
kilobytes together after single header

00:08:14,400 --> 00:08:21,810
and then loaded it into the VM ran

00:08:17,580 --> 00:08:25,470
directly so using all these features we

00:08:21,810 --> 00:08:30,210
were able to save 3 seconds out of 7

00:08:25,470 --> 00:08:34,020
seconds for loading snapchat to reduce

00:08:30,210 --> 00:08:35,610
the time for initializing qemu we

00:08:34,020 --> 00:08:38,120
disable the unused

00:08:35,610 --> 00:08:41,099
unused virtual device and modules and

00:08:38,120 --> 00:08:44,490
use the no default apps option

00:08:41,099 --> 00:08:47,730
especially disabling QEMU monitor and

00:08:44,490 --> 00:08:51,720
qmp socket we save the 1 seconds out of

00:08:47,730 --> 00:08:54,570
a 3 we also enable the transparent hues

00:08:51,720 --> 00:08:56,930
pages where the share pages are disabled

00:08:54,570 --> 00:08:59,449
and there is another

00:08:56,930 --> 00:09:01,759
we eliminated the redundant function

00:08:59,449 --> 00:09:05,300
call which is a queue in your system

00:09:01,759 --> 00:09:08,720
result reset it is a cold inside in

00:09:05,300 --> 00:09:11,869
Maine right before calling low the VM

00:09:08,720 --> 00:09:15,410
State again it is cold inside a lot of

00:09:11,869 --> 00:09:20,050
vamps k-state so we remove remove the

00:09:15,410 --> 00:09:23,089
first function call and it worked okay

00:09:20,050 --> 00:09:25,339
now I will talk about our to learning

00:09:23,089 --> 00:09:28,790
approach according to the four grandest

00:09:25,339 --> 00:09:37,040
screen display to conform with Android

00:09:28,790 --> 00:09:41,749
the memory management currently in

00:09:37,040 --> 00:09:45,790
currently qemu the host memory pressure

00:09:41,749 --> 00:09:49,639
is measured with the page reclaim ratio

00:09:45,790 --> 00:09:52,579
but as android has additional memory man

00:09:49,639 --> 00:09:56,029
don't want policy we have a different

00:09:52,579 --> 00:10:00,379
metric there are two models which kills

00:09:56,029 --> 00:10:03,769
Android process when Android is a lower

00:10:00,379 --> 00:10:06,199
memory one is low molecular and in

00:10:03,769 --> 00:10:10,759
kernel and another is activity many

00:10:06,199 --> 00:10:13,309
manager service at usual level low

00:10:10,759 --> 00:10:17,149
memory killer maintains a memory table

00:10:13,309 --> 00:10:21,199
and based based on this mentor it may be

00:10:17,149 --> 00:10:23,929
free table it kills process there is an

00:10:21,199 --> 00:10:27,319
example of memory table at the bottom of

00:10:23,929 --> 00:10:30,079
this slide meaning free table consists

00:10:27,319 --> 00:10:33,199
of tuples of a minimum as an adjustment

00:10:30,079 --> 00:10:37,009
value of a victim process and the

00:10:33,199 --> 00:10:39,290
minimum free memory size if current free

00:10:37,009 --> 00:10:42,259
memory is about 90 megabytes it

00:10:39,290 --> 00:10:46,759
corresponds to the fifth column

00:10:42,259 --> 00:10:49,189
so LMK will inspect processes with the

00:10:46,759 --> 00:10:53,240
adjustment value greater than or equal

00:10:49,189 --> 00:10:56,540
to 9 and to find the process with the

00:10:53,240 --> 00:10:59,749
biggest adjustment value and the largest

00:10:56,540 --> 00:11:00,619
memory usage activity main service and

00:10:59,749 --> 00:11:04,429
user level

00:11:00,619 --> 00:11:09,250
updates each processes adjustment value

00:11:04,429 --> 00:11:12,340
on every activity change as well besides

00:11:09,250 --> 00:11:16,090
it tries to keep free memory size and

00:11:12,340 --> 00:11:18,880
page case cache size greater than some

00:11:16,090 --> 00:11:22,800
of the low water marks in each a memory

00:11:18,880 --> 00:11:28,510
zone by killing background processes in

00:11:22,800 --> 00:11:33,010
LRU order so by listening those two

00:11:28,510 --> 00:11:38,350
modules via event FD balloon bag and

00:11:33,010 --> 00:11:41,710
measures host a memory pressure this is

00:11:38,350 --> 00:11:44,950
our ballooning policy we said different

00:11:41,710 --> 00:11:47,400
the level of memory and threshold to

00:11:44,950 --> 00:11:50,830
coaster and guest

00:11:47,400 --> 00:11:54,490
according to reinstate either info at

00:11:50,830 --> 00:11:57,520
foreground or background when VM is a

00:11:54,490 --> 00:12:01,210
foreground guest has a higher priority

00:11:57,520 --> 00:12:05,740
over using memory so we left VM freely

00:12:01,210 --> 00:12:09,280
use its memory we try to keep get the vm

00:12:05,740 --> 00:12:13,120
memory pressures small guess the memory

00:12:09,280 --> 00:12:16,690
pressure is expressed with the memory

00:12:13,120 --> 00:12:20,410
usage out of a total memory but we don't

00:12:16,690 --> 00:12:23,800
want to let you don't want to enter it

00:12:20,410 --> 00:12:26,560
to sacrifice important apps for virtual

00:12:23,800 --> 00:12:30,940
machine such as a visible perceptible

00:12:26,560 --> 00:12:35,110
apps answer services flow over

00:12:30,940 --> 00:12:37,420
controlling a memory opponent cast a

00:12:35,110 --> 00:12:41,680
balloon at foreground is shown at the

00:12:37,420 --> 00:12:44,260
bottom of the diagram when following bag

00:12:41,680 --> 00:12:47,860
and in qemu detects guest memory

00:12:44,260 --> 00:12:52,120
pressure refers to inspects host to free

00:12:47,860 --> 00:12:55,720
memory size if host 'memories is enough

00:12:52,120 --> 00:12:58,750
to keep important the apps then it sends

00:12:55,720 --> 00:13:02,410
the command to it stands deeply to

00:12:58,750 --> 00:13:05,440
command to guest and then guess the

00:13:02,410 --> 00:13:08,710
balloon driver deflates by bringing its

00:13:05,440 --> 00:13:10,780
own memory and returning it gets the

00:13:08,710 --> 00:13:13,750
physical page the frames that it

00:13:10,780 --> 00:13:19,210
recently freed to balloon back end and

00:13:13,750 --> 00:13:21,800
then balloon bagans gives some memory

00:13:19,210 --> 00:13:29,450
advice to is a foster kernel

00:13:21,800 --> 00:13:32,029
that if the memory pages will need when

00:13:29,450 --> 00:13:34,640
virtual machine is at background host

00:13:32,029 --> 00:13:38,180
applications have a higher priority of

00:13:34,640 --> 00:13:41,810
using memory so ilda guest memory as

00:13:38,180 --> 00:13:44,860
much as it can we try to keep host every

00:13:41,810 --> 00:13:48,230
memory up to the level then no other

00:13:44,860 --> 00:13:52,880
background application in enhanced

00:13:48,230 --> 00:13:56,240
doesn't have to be killed but we don't

00:13:52,880 --> 00:13:59,149
want to push gas to memory pressure too

00:13:56,240 --> 00:14:04,100
high because it will in those induce

00:13:59,149 --> 00:14:07,310
page swap the flow is the same as the

00:14:04,100 --> 00:14:10,490
previous one except that the host to

00:14:07,310 --> 00:14:13,040
memory pressure is received from under

00:14:10,490 --> 00:14:18,800
the activity manager service and low

00:14:13,040 --> 00:14:22,250
memory killer this is our experimental

00:14:18,800 --> 00:14:25,670
resort we set guest the virtual machines

00:14:22,250 --> 00:14:29,600
RAM to one gigabyte and to see the

00:14:25,670 --> 00:14:32,230
maximum balloon size we set virtual

00:14:29,600 --> 00:14:36,770
machines memory pressure at background

00:14:32,230 --> 00:14:39,709
200% yellow line is the caste available

00:14:36,770 --> 00:14:42,829
memory in kilobytes and green is for

00:14:39,709 --> 00:14:47,899
host free size and the red line is for

00:14:42,829 --> 00:14:51,860
volume size we field guest the memory

00:14:47,899 --> 00:14:55,430
uses to up to 80 percent by executing

00:14:51,860 --> 00:14:59,029
heavy memory usage applications and then

00:14:55,430 --> 00:15:02,450
switch it to Android world and thirded

00:14:59,029 --> 00:15:06,589
on host application which allocates

00:15:02,450 --> 00:15:10,459
memory 500 megabytes of an upon user

00:15:06,589 --> 00:15:14,630
request when the hosted application has

00:15:10,459 --> 00:15:18,070
risk rigid to allocate to allocate 300

00:15:14,630 --> 00:15:23,149
megabytes balloon has inserted the

00:15:18,070 --> 00:15:26,360
inflating and right after killing the

00:15:23,149 --> 00:15:29,360
host application we came back to the

00:15:26,360 --> 00:15:32,570
window windows worried again because the

00:15:29,360 --> 00:15:34,960
cost of memory pressure was very high it

00:15:32,570 --> 00:15:37,810
30 the deflation right

00:15:34,960 --> 00:15:42,190
way without ballooning freedom was

00:15:37,810 --> 00:15:45,160
killed at the point that Windows Android

00:15:42,190 --> 00:15:50,380
host application has allocated 300

00:15:45,160 --> 00:15:53,500
megabytes now I will talk about how we

00:15:50,380 --> 00:15:58,690
interface the Android with QEMU virtual

00:15:53,500 --> 00:16:02,050
devices this is the architecture of our

00:15:58,690 --> 00:16:04,780
newly added virtual devices we had a

00:16:02,050 --> 00:16:09,280
modification in blue droid and limbo and

00:16:04,780 --> 00:16:12,870
qemu together 240 regarding the

00:16:09,280 --> 00:16:17,350
Bluetooth it is virtualized as a USB

00:16:12,870 --> 00:16:21,480
bluetooth and to handle the ro h CI

00:16:17,350 --> 00:16:25,300
packet at blue droid we had modified

00:16:21,480 --> 00:16:31,510
blue droid and regarding the multi-touch

00:16:25,300 --> 00:16:34,540
we had to add USB add some models inside

00:16:31,510 --> 00:16:37,240
the USB stick as well as qme hid

00:16:34,540 --> 00:16:40,600
subsystem and to interface the Android

00:16:37,240 --> 00:16:43,840
world we had an Android you are event

00:16:40,600 --> 00:16:47,500
handler inside QEMU and to release in

00:16:43,840 --> 00:16:51,010
some hid event we also had modification

00:16:47,500 --> 00:16:55,090
in surface view together and audio is

00:16:51,010 --> 00:16:58,150
directly interfaced with opensl es and 2

00:16:55,090 --> 00:17:00,790
to get the battery status monitoring we

00:16:58,150 --> 00:17:04,120
added the three object inside the API

00:17:00,790 --> 00:17:08,730
names namespace which is power source

00:17:04,120 --> 00:17:11,860
battery and SMB controller as as the

00:17:08,730 --> 00:17:16,420
those battery status monitoring is done

00:17:11,860 --> 00:17:24,330
via SMB SM pass we had also modification

00:17:16,420 --> 00:17:28,930
in SM pass those are features we con

00:17:24,330 --> 00:17:32,650
regarding HID multi-touch is virtualized

00:17:28,930 --> 00:17:35,530
as a USB multi-touch and most three

00:17:32,650 --> 00:17:38,740
buttons and hover functionalities is

00:17:35,530 --> 00:17:44,830
also supported which is missing in limbo

00:17:38,740 --> 00:17:46,250
and politicus the virtualized and using

00:17:44,830 --> 00:17:49,450
HTC H

00:17:46,250 --> 00:17:54,800
see a pester mechanism sundae's

00:17:49,450 --> 00:17:58,400
interface to it open SL and the opener

00:17:54,800 --> 00:18:01,430
set interface in qemu maintains a lock

00:17:58,400 --> 00:18:04,700
for the ring buffer to pass samples to

00:18:01,430 --> 00:18:07,900
open SL and we also used our synchronous

00:18:04,700 --> 00:18:11,960
kill processing maintained by open SL

00:18:07,900 --> 00:18:14,690
the ACP a part I will skip this part

00:18:11,960 --> 00:18:19,360
because I have to explained in the

00:18:14,690 --> 00:18:23,140
previous slide this is the last one I

00:18:19,360 --> 00:18:25,940
talked about how how we were able to

00:18:23,140 --> 00:18:29,270
assign virtual machine with more than

00:18:25,940 --> 00:18:32,620
one gigabyte in the left of us if this

00:18:29,270 --> 00:18:38,450
is Limbo's virtual memory address space

00:18:32,620 --> 00:18:42,800
before limbo and QEMU run to a virtual

00:18:38,450 --> 00:18:47,830
machine though only though blue - the

00:18:42,800 --> 00:18:50,780
Lions area is unused when qemu tries to

00:18:47,830 --> 00:18:53,900
reserve a memory space for a cast of

00:18:50,780 --> 00:18:58,280
physical memory using the N map function

00:18:53,900 --> 00:19:02,330
but without any specific start address

00:18:58,280 --> 00:19:05,780
address it will only get the address

00:19:02,330 --> 00:19:10,060
space with the right side of blue stripe

00:19:05,780 --> 00:19:13,430
area because it is according to the

00:19:10,060 --> 00:19:18,200
Android application characteristic the

00:19:13,430 --> 00:19:23,060
left to the left area is unused so we

00:19:18,200 --> 00:19:25,520
had the explicit and met and then we for

00:19:23,060 --> 00:19:30,800
the rest of the memory area we call

00:19:25,520 --> 00:19:32,840
another n net function so this is the

00:19:30,800 --> 00:19:38,890
list and thank you for listening and

00:19:32,840 --> 00:19:41,620
questions yes

00:19:38,890 --> 00:19:44,919
if so you usually start your windows

00:19:41,620 --> 00:19:46,809
guests from a snapshot image what

00:19:44,919 --> 00:19:48,159
happens if the guests crashes or for

00:19:46,809 --> 00:19:50,039
some of the reason you need to really

00:19:48,159 --> 00:19:55,240
reboot it you have to do a slaughter

00:19:50,039 --> 00:19:59,110
rebooting so for that although I use the

00:19:55,240 --> 00:20:02,409
separate snapshot Palani we may use the

00:19:59,110 --> 00:20:06,820
backing file and overlay using by using

00:20:02,409 --> 00:20:09,669
overlay file and as the backing file is

00:20:06,820 --> 00:20:12,549
read only and as long as we can make

00:20:09,669 --> 00:20:15,519
sure that previous of VM run was not

00:20:12,549 --> 00:20:22,240
crashed we can do the block omit from

00:20:15,519 --> 00:20:24,309
overlay file to base file won't the CPU

00:20:22,240 --> 00:20:26,169
state of the snapshot then be consistent

00:20:24,309 --> 00:20:27,779
it is you've changed the configuration

00:20:26,169 --> 00:20:34,799
in Windows Oh

00:20:27,779 --> 00:20:40,029
so if the the VM was crashed we have to

00:20:34,799 --> 00:20:45,580
discard the vm state but I would expect

00:20:40,029 --> 00:20:48,399
there would be rarely happen for that we

00:20:45,580 --> 00:20:54,090
need a baby we need another mechanism to

00:20:48,399 --> 00:20:54,090
make sure that the VM state is okay

00:21:00,420 --> 00:21:07,100
if the user installs application do you

00:21:04,440 --> 00:21:11,540
immediately make additional snapshot and

00:21:07,100 --> 00:21:14,810
resume it in the next stage or how this

00:21:11,540 --> 00:21:18,990
case for their machine is okay

00:21:14,810 --> 00:21:21,660
Metro screen okay but what if user

00:21:18,990 --> 00:21:25,680
presents alkalotic of the game all right

00:21:21,660 --> 00:21:30,240
so the point that when we take a

00:21:25,680 --> 00:21:32,910
snapshot by running on some agent and

00:21:30,240 --> 00:21:36,480
when our user tries to shut down the

00:21:32,910 --> 00:21:39,720
virtual machine at that point all the

00:21:36,480 --> 00:21:41,880
applications will be shut down at at

00:21:39,720 --> 00:21:46,440
that point we make we can take a

00:21:41,880 --> 00:21:50,250
snapshot so we can still keep the small

00:21:46,440 --> 00:21:54,060
size of snapshot and we have the some

00:21:50,250 --> 00:21:57,840
several application ran including the X

00:21:54,060 --> 00:22:01,950
polar explorer browser and including the

00:21:57,840 --> 00:22:07,190
VGA and RAM area it increased up to

00:22:01,950 --> 00:22:07,190
around nine nine nine hundred megabytes

00:22:13,530 --> 00:22:16,530
yes

00:22:17,610 --> 00:22:22,460

YouTube URL: https://www.youtube.com/watch?v=1Ex7r5DEiNY


