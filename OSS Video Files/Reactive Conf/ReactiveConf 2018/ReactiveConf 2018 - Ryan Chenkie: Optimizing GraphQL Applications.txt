Title: ReactiveConf 2018 - Ryan Chenkie: Optimizing GraphQL Applications
Publication date: 2018-11-05
Playlist: ReactiveConf 2018
Description: 
	29th - 31st October 2018, Prague, Czech Republic
https://reactiveconf.com/
Discovery stage
-------------------------------------------------------------------
Optimizing GraphQL Applications

The promise of GraphQL is clear and compelling: allow your clients to ask for exactly the data they need at exactly the time they need it. Add the fact that you get a strongly-typed API and automatic introspection out-of-the-box and it’s easy to see why so many companies are making the switch to GraphQL.
The default tooling that comes with GraphQL works well for small applications. However, once our apps start to get sizeable, it becomes easy to hit bottlenecks and performance degradations. Fortunately, there are several optimizations we can add without a ton of effort.
In this talk, we’ll look at some of the best bang-for-buck GraphQL optimizations available. We’ll take a deep-dive into query batching to limit server requests. We’ll look at schema stitching to optimize how we call into multiple GraphQL endpoints. We’ll also talk about features offered by Apollo to improve perceived performance such as the optimistic UI pattern. Finally, we’ll look at some of the best ways to profile and monitor your GraphQL API.
Captions: 
	00:00:02,490 --> 00:00:08,960
[Music]

00:00:12,280 --> 00:00:17,450
hi everyone how are you my name is Ryan

00:00:15,410 --> 00:00:20,930
and I want to talk to you today about

00:00:17,450 --> 00:00:23,750
graph QL quick show of hands here who's

00:00:20,930 --> 00:00:24,980
using graph QL right now that's a fair

00:00:23,750 --> 00:00:27,559
number of us that's great

00:00:24,980 --> 00:00:30,349
anybody thinking about using graph QL

00:00:27,559 --> 00:00:33,050
want to start using it maybe great

00:00:30,349 --> 00:00:33,950
anybody here that thinks graph QL sucks

00:00:33,050 --> 00:00:36,379
they hate it

00:00:33,950 --> 00:00:39,530
anybody dull that's good that's

00:00:36,379 --> 00:00:42,320
encouraging that's really good to see my

00:00:39,530 --> 00:00:43,850
name is Ryan Chang key I'm a an angular

00:00:42,320 --> 00:00:46,370
and node consultants so I work a lot

00:00:43,850 --> 00:00:48,020
with angular and node I created

00:00:46,370 --> 00:00:49,910
applications for companies kind of go in

00:00:48,020 --> 00:00:51,950
and help to solve business problems with

00:00:49,910 --> 00:00:55,790
new technology I'm a Google developer

00:00:51,950 --> 00:00:57,230
experts and I teach at angular cassio so

00:00:55,790 --> 00:00:59,780
if anybody here is doing angular and

00:00:57,230 --> 00:01:01,340
you're looking for some some courses on

00:00:59,780 --> 00:01:05,210
angular I'd encourage you to check out

00:01:01,340 --> 00:01:07,700
angular casts so graph QL is everywhere

00:01:05,210 --> 00:01:08,990
is what I would say and it's not hard to

00:01:07,700 --> 00:01:10,399
see that that's the case when we see

00:01:08,990 --> 00:01:12,679
that there's all these well-known

00:01:10,399 --> 00:01:14,090
companies who are making use of it I'm

00:01:12,679 --> 00:01:16,789
sure we're all pretty familiar with

00:01:14,090 --> 00:01:20,450
these logos so graph QL is really on the

00:01:16,789 --> 00:01:22,490
rise and aside from just these big name

00:01:20,450 --> 00:01:25,280
logos that are using graph QL these days

00:01:22,490 --> 00:01:27,530
the numbers also show as a trend that

00:01:25,280 --> 00:01:30,740
there's a lot of adoption happening so

00:01:27,530 --> 00:01:33,709
this is the Downloads per day from NPM

00:01:30,740 --> 00:01:36,709
for graph QL j/s which I would argue is

00:01:33,709 --> 00:01:39,499
probably the the most widely used graph

00:01:36,709 --> 00:01:41,719
QL implementation out there it's not the

00:01:39,499 --> 00:01:44,359
only one there's you know graph QL is

00:01:41,719 --> 00:01:45,740
not tied to JavaScript in any way but

00:01:44,359 --> 00:01:48,319
it's probably the most widely used one

00:01:45,740 --> 00:01:50,479
and so we're reaching from so middle of

00:01:48,319 --> 00:01:52,759
2015 to now we're reaching almost

00:01:50,479 --> 00:01:55,249
200,000 downloads per day so it's

00:01:52,759 --> 00:01:57,079
starting to climb quite a bit and I mean

00:01:55,249 --> 00:01:58,999
what's not to like right you can take a

00:01:57,079 --> 00:02:01,909
simple structure like this on the left

00:01:58,999 --> 00:02:04,130
to represent some data that you want and

00:02:01,909 --> 00:02:05,810
you can get back the data kind of

00:02:04,130 --> 00:02:08,450
mapping exactly to that shape and then

00:02:05,810 --> 00:02:10,550
if you have so maybe that's for one

00:02:08,450 --> 00:02:12,349
client application and then maybe if

00:02:10,550 --> 00:02:14,150
you've got another one that needs data

00:02:12,349 --> 00:02:16,579
from the same data source but just a

00:02:14,150 --> 00:02:18,800
little bit less it's very easy to take

00:02:16,579 --> 00:02:20,570
just a subset of that query

00:02:18,800 --> 00:02:22,460
and ask for exactly what you want so

00:02:20,570 --> 00:02:24,560
it's very compelling graph QL is a very

00:02:22,460 --> 00:02:26,270
compelling technology to be using which

00:02:24,560 --> 00:02:30,440
is probably why a lot of you are using

00:02:26,270 --> 00:02:32,090
it now you get using graph QL it's in

00:02:30,440 --> 00:02:35,930
production you've been using it for a

00:02:32,090 --> 00:02:38,090
while and eventually the excitement

00:02:35,930 --> 00:02:40,460
about it kind of starts to fade a bit in

00:02:38,090 --> 00:02:42,410
a lot of cases hopefully not but you

00:02:40,460 --> 00:02:43,820
know that initial kind of nice feeling

00:02:42,410 --> 00:02:46,430
you get with graph QL can start to fade

00:02:43,820 --> 00:02:47,570
and oftentimes that's because of some of

00:02:46,430 --> 00:02:51,110
the bottlenecks we can hit it's

00:02:47,570 --> 00:02:53,090
performance wise with graph QL now the

00:02:51,110 --> 00:02:53,660
thing is graph yields early if we think

00:02:53,090 --> 00:02:55,820
about it

00:02:53,660 --> 00:02:59,180
Facebook kind of came out with it back

00:02:55,820 --> 00:03:02,810
in 2012 so six years ago in technology

00:02:59,180 --> 00:03:05,300
terms that's a pretty long time ago but

00:03:02,810 --> 00:03:07,520
it wasn't till 2015 that the spec was

00:03:05,300 --> 00:03:09,320
released so we're talking only three

00:03:07,520 --> 00:03:12,530
years ago the the graph QL spec was

00:03:09,320 --> 00:03:14,900
first released and it wasn't until last

00:03:12,530 --> 00:03:18,530
year that graph qlj has passed a daily

00:03:14,900 --> 00:03:20,270
download mark of 50k downloads here we

00:03:18,530 --> 00:03:22,220
are today so really there's not a whole

00:03:20,270 --> 00:03:24,830
lot of time that is past year since it's

00:03:22,220 --> 00:03:27,170
been released and so the point here is

00:03:24,830 --> 00:03:29,240
that graph QL hasn't had the time for

00:03:27,170 --> 00:03:30,680
people to realize all of these potential

00:03:29,240 --> 00:03:32,420
all these bottlenecks all these

00:03:30,680 --> 00:03:35,180
performance issues that you could hit in

00:03:32,420 --> 00:03:37,280
production and come up with solutions to

00:03:35,180 --> 00:03:39,230
them with things like rest we've had

00:03:37,280 --> 00:03:42,620
much more time to experience the pain

00:03:39,230 --> 00:03:45,500
that we can get out in the wilds with

00:03:42,620 --> 00:03:48,980
large scale applications and people have

00:03:45,500 --> 00:03:50,209
come up with solutions to that so the

00:03:48,980 --> 00:03:51,650
question is what can we do to optimize

00:03:50,209 --> 00:03:53,690
graph kill what are some of the issues

00:03:51,650 --> 00:03:55,790
and what can we do even though it's

00:03:53,690 --> 00:03:58,370
still early even though it hasn't been

00:03:55,790 --> 00:03:59,360
out in the wild for a long time well

00:03:58,370 --> 00:04:00,200
there are some things we can do and

00:03:59,360 --> 00:04:02,930
that's what I'd like to take you through

00:04:00,200 --> 00:04:05,300
today one caveat first though is I'd

00:04:02,930 --> 00:04:09,020
like everybody to maybe just taken this

00:04:05,300 --> 00:04:12,320
quote and maybe just consider this for a

00:04:09,020 --> 00:04:14,300
second so this is an author Donald Knuth

00:04:12,320 --> 00:04:17,180
said premature optimization is the root

00:04:14,300 --> 00:04:19,430
of all evil and so what I would

00:04:17,180 --> 00:04:21,049
encourage you to consider is that maybe

00:04:19,430 --> 00:04:23,840
it's not the best thing to go and take

00:04:21,049 --> 00:04:25,730
all of these suggestions and go try to

00:04:23,840 --> 00:04:28,150
code against them immediately

00:04:25,730 --> 00:04:31,610
because you can spend a lot of time

00:04:28,150 --> 00:04:32,420
micro optimizing without getting really

00:04:31,610 --> 00:04:35,420
strong results

00:04:32,420 --> 00:04:36,800
so I would say do what you want but

00:04:35,420 --> 00:04:39,320
ultimately it might be better to wait

00:04:36,800 --> 00:04:42,170
until you feel some pain in production

00:04:39,320 --> 00:04:44,870
before you put optimization strategies

00:04:42,170 --> 00:04:46,940
in place with that said let's talk about

00:04:44,870 --> 00:04:48,470
the first way that you might optimize

00:04:46,940 --> 00:04:51,320
your graph QL app so let's talk about

00:04:48,470 --> 00:04:54,260
query batching so here is a pretty

00:04:51,320 --> 00:04:55,220
typical looking application a lot of

00:04:54,260 --> 00:04:57,710
applications will have some kind of

00:04:55,220 --> 00:05:00,530
dashboard and maybe you've got you know

00:04:57,710 --> 00:05:03,230
three or more content areas and with a

00:05:00,530 --> 00:05:05,120
REST API you might furnish the data for

00:05:03,230 --> 00:05:06,590
these content areas from three different

00:05:05,120 --> 00:05:08,360
endpoints so you've got a customer's

00:05:06,590 --> 00:05:11,270
endpoint maybe then some kind of totals

00:05:08,360 --> 00:05:12,830
endpoint and a jobs endpoint these are

00:05:11,270 --> 00:05:16,030
three parallel requests that are going

00:05:12,830 --> 00:05:18,500
to go to your API in the rest scenario

00:05:16,030 --> 00:05:21,470
now if we look at this if we're doing

00:05:18,500 --> 00:05:23,450
graph QL typically if we have things set

00:05:21,470 --> 00:05:25,880
up I'm kind of out of the box if you

00:05:23,450 --> 00:05:28,160
will that's going to be three different

00:05:25,880 --> 00:05:29,840
graphic you-all queries and in the same

00:05:28,160 --> 00:05:32,060
way that we did three parallel requests

00:05:29,840 --> 00:05:35,470
to our REST API this is kind of three

00:05:32,060 --> 00:05:37,730
parallel requests to our graph QL API so

00:05:35,470 --> 00:05:39,560
what would be good is if we could take

00:05:37,730 --> 00:05:41,960
these queries and batch them up to only

00:05:39,560 --> 00:05:45,170
send one single request to our graph uol

00:05:41,960 --> 00:05:47,000
endpoint and that might look like this

00:05:45,170 --> 00:05:48,230
this is kind of one way to do it I know

00:05:47,000 --> 00:05:50,330
it's a little bit tough to see with a

00:05:48,230 --> 00:05:51,470
split in the screen but essentially what

00:05:50,330 --> 00:05:53,330
we've done is we've just started to

00:05:51,470 --> 00:05:56,150
group all these crazy together so you

00:05:53,330 --> 00:05:57,890
can group as many different query fields

00:05:56,150 --> 00:06:00,080
as you want into a single query

00:05:57,890 --> 00:06:02,810
operation and you might be able to get

00:06:00,080 --> 00:06:04,670
all of your data this way and if we run

00:06:02,810 --> 00:06:08,450
into issues with name spacing if we're

00:06:04,670 --> 00:06:10,220
trying to request the same resource but

00:06:08,450 --> 00:06:12,380
multiple times we can use a feature of

00:06:10,220 --> 00:06:15,410
graph QL called aliasing which is where

00:06:12,380 --> 00:06:17,510
we give an alias to one of our fields so

00:06:15,410 --> 00:06:20,600
that we can pull out the same resource

00:06:17,510 --> 00:06:22,300
multiple times so this would just send

00:06:20,600 --> 00:06:24,920
one single request to the API

00:06:22,300 --> 00:06:27,200
however group queries like this do have

00:06:24,920 --> 00:06:29,480
some problems the first problem is that

00:06:27,200 --> 00:06:31,280
all queries need to finish they all need

00:06:29,480 --> 00:06:33,230
to complete before we get anything back

00:06:31,280 --> 00:06:35,630
at all so before we get any kind of

00:06:33,230 --> 00:06:37,960
results back from our API everything

00:06:35,630 --> 00:06:40,100
that we've requested has to finish and

00:06:37,960 --> 00:06:41,660
maybe one of the bigger ones especially

00:06:40,100 --> 00:06:43,790
for the assuming a lot of people are

00:06:41,660 --> 00:06:44,729
using react is that you can't really

00:06:43,790 --> 00:06:46,589
Cole okay

00:06:44,729 --> 00:06:48,479
easily your components with your queries

00:06:46,589 --> 00:06:49,710
and that's if you're using reaction

00:06:48,479 --> 00:06:51,870
graph QL you probably know that that's I

00:06:49,710 --> 00:06:54,449
mean that's encouraged you want to have

00:06:51,870 --> 00:06:56,129
your queries live with your components

00:06:54,449 --> 00:06:57,689
like in this example you've got your

00:06:56,129 --> 00:07:00,330
component definition and then you've got

00:06:57,689 --> 00:07:01,830
your query rate under it and so it's

00:07:00,330 --> 00:07:04,499
difficult to do this with typical

00:07:01,830 --> 00:07:06,389
grouping if you're using Apollo client

00:07:04,499 --> 00:07:08,069
though you can start to batch up your

00:07:06,389 --> 00:07:09,210
queries in an intelligent way and it's

00:07:08,069 --> 00:07:11,039
actually really simple to do

00:07:09,210 --> 00:07:13,110
if you're using the clients you can just

00:07:11,039 --> 00:07:15,059
set should match to true and that's

00:07:13,110 --> 00:07:18,270
going to turn on this batching feature

00:07:15,059 --> 00:07:21,270
of Apollo where what happens is you've

00:07:18,270 --> 00:07:22,979
got 10 millisecond slices and every 10

00:07:21,270 --> 00:07:25,169
milliseconds Apollo's gonna look for

00:07:22,979 --> 00:07:28,020
outgoing queries and if it gets an

00:07:25,169 --> 00:07:30,180
outgoing query it's going to wait until

00:07:28,020 --> 00:07:32,370
that 10 millisecond frame finishes and

00:07:30,180 --> 00:07:34,409
then it will send the request so what

00:07:32,370 --> 00:07:36,120
this means is that say in the next 10

00:07:34,409 --> 00:07:38,099
millisecond frame we might have two

00:07:36,120 --> 00:07:40,409
queries that need to go out they're

00:07:38,099 --> 00:07:42,270
gonna wait it's gonna appalled is going

00:07:40,409 --> 00:07:44,460
to wait before sending that request and

00:07:42,270 --> 00:07:46,289
it's gonna batch those together and so

00:07:44,460 --> 00:07:48,029
time goes on maybe the next 10

00:07:46,289 --> 00:07:49,499
millisecond frame is just 1 and then

00:07:48,029 --> 00:07:50,039
maybe you've got multiple in the next

00:07:49,499 --> 00:07:53,729
one

00:07:50,039 --> 00:07:55,860
so one caveat here though is batching

00:07:53,729 --> 00:07:59,069
like this is only as fast as the slowest

00:07:55,860 --> 00:08:01,139
query so every 10 milliseconds you might

00:07:59,069 --> 00:08:02,969
have multiple queries going out but if

00:08:01,139 --> 00:08:04,499
one of them takes a long time to resolve

00:08:02,969 --> 00:08:06,930
well you're gonna get back to some

00:08:04,499 --> 00:08:09,659
issues getting your data back you know

00:08:06,930 --> 00:08:11,129
it might be slow to get back so I'd say

00:08:09,659 --> 00:08:14,459
don't be tempted to batch too early but

00:08:11,129 --> 00:08:16,830
it can be effective at giving you some

00:08:14,459 --> 00:08:18,120
performance boost the next thing I'd

00:08:16,830 --> 00:08:22,469
like to talk about is something called

00:08:18,120 --> 00:08:24,569
automatic persisted queries so when you

00:08:22,469 --> 00:08:26,430
make a query with graph QL we've got

00:08:24,569 --> 00:08:28,620
that nice structure gives us a

00:08:26,430 --> 00:08:31,379
representation of the data we want when

00:08:28,620 --> 00:08:33,419
it ends up going to your server this is

00:08:31,379 --> 00:08:35,430
kind of what it looks like you've got

00:08:33,419 --> 00:08:37,889
the string representation of that query

00:08:35,430 --> 00:08:40,709
and if you've got a larger query well

00:08:37,889 --> 00:08:44,670
that things going to grow and it's gonna

00:08:40,709 --> 00:08:47,459
grow and it's gonna grow it's gonna get

00:08:44,670 --> 00:08:51,120
very very big they've seen some really

00:08:47,459 --> 00:08:53,399
huge query strings out in the wild this

00:08:51,120 --> 00:08:56,490
is a scale representation if I think the

00:08:53,399 --> 00:08:57,720
longest one that's been seen out in

00:08:56,490 --> 00:08:59,639
production

00:08:57,720 --> 00:09:00,930
it cut right down the middle where that

00:08:59,639 --> 00:09:03,810
query stern was but there's a query

00:09:00,930 --> 00:09:07,769
string right in the middle here going

00:09:03,810 --> 00:09:09,810
from earth to the moon and it's kind of

00:09:07,769 --> 00:09:13,290
to scale it's plus or minus hundred

00:09:09,810 --> 00:09:15,060
meters anyway point is they've seen some

00:09:13,290 --> 00:09:18,779
really really big query strings in the

00:09:15,060 --> 00:09:21,329
wild the thing is the larger your query

00:09:18,779 --> 00:09:23,370
string the slower the network request is

00:09:21,329 --> 00:09:25,589
going to be and this is actually a big

00:09:23,370 --> 00:09:28,129
bottleneck the network request layer the

00:09:25,589 --> 00:09:30,089
larger your query string at this level

00:09:28,129 --> 00:09:32,670
the more of a performance that you're

00:09:30,089 --> 00:09:36,649
going to take and this is significant

00:09:32,670 --> 00:09:39,810
like they've seen 10 kilobyte request

00:09:36,649 --> 00:09:41,519
strings out in the wild and that's huge

00:09:39,810 --> 00:09:44,310
compared to the couple bytes we would

00:09:41,519 --> 00:09:46,589
get with a rest query so what do we do

00:09:44,310 --> 00:09:48,540
well one thing we can do it would be

00:09:46,589 --> 00:09:50,519
nice if we get instead of this long

00:09:48,540 --> 00:09:52,709
query string if we could represent it

00:09:50,519 --> 00:09:56,550
with something like this which is just

00:09:52,709 --> 00:09:58,649
the sha-256 hash so down here below is

00:09:56,550 --> 00:10:02,879
the exact same thing as you see up top

00:09:58,649 --> 00:10:04,860
just run through sha-256 and this is

00:10:02,879 --> 00:10:06,449
what automatic persisted queries gives

00:10:04,860 --> 00:10:08,129
us so here's how it looks so you got

00:10:06,449 --> 00:10:10,709
your browser that's gonna send a request

00:10:08,129 --> 00:10:12,870
to your server if you turn this feature

00:10:10,709 --> 00:10:15,420
on what you're going to get is the

00:10:12,870 --> 00:10:18,269
browser is going to send optimistically

00:10:15,420 --> 00:10:19,829
that hash to the server and if the

00:10:18,269 --> 00:10:21,600
server knows about it that's great

00:10:19,829 --> 00:10:23,639
it's going to just send back it's gonna

00:10:21,600 --> 00:10:25,620
resolve the query that's represented by

00:10:23,639 --> 00:10:27,059
that hash immediately but let's say it

00:10:25,620 --> 00:10:29,040
doesn't know about it so what's gonna

00:10:27,059 --> 00:10:31,139
happen as the server is going to send

00:10:29,040 --> 00:10:33,509
back to the client that it doesn't know

00:10:31,139 --> 00:10:35,639
about it and then the client says ok

00:10:33,509 --> 00:10:38,699
well in that case I'll send you the full

00:10:35,639 --> 00:10:41,399
query string and it only needs to send

00:10:38,699 --> 00:10:42,750
the full query string once once it gets

00:10:41,399 --> 00:10:45,180
to the server the server is going to

00:10:42,750 --> 00:10:47,610
cache it it's going to know about it and

00:10:45,180 --> 00:10:50,370
then it's going to be able to resolve

00:10:47,610 --> 00:10:52,230
that same hash in the future so this is

00:10:50,370 --> 00:10:53,399
great because quite often in your

00:10:52,230 --> 00:10:55,350
application you're gonna have the same

00:10:53,399 --> 00:10:57,540
queries being sent over and over again

00:10:55,350 --> 00:11:00,120
and if they're huge well you can save a

00:10:57,540 --> 00:11:02,250
lot of time in that network layer by

00:11:00,120 --> 00:11:07,439
putting in a hash instead of a full

00:11:02,250 --> 00:11:08,860
string how do you use it I wish I could

00:11:07,439 --> 00:11:12,400
show you

00:11:08,860 --> 00:11:13,180
I was gonna add it on the fly but I

00:11:12,400 --> 00:11:15,970
probably shouldn't

00:11:13,180 --> 00:11:19,270
this says npm install Apollo link

00:11:15,970 --> 00:11:19,900
persisted queries so if you want to

00:11:19,270 --> 00:11:21,550
check it out

00:11:19,900 --> 00:11:25,210
Apollo's got a library that will allow

00:11:21,550 --> 00:11:27,250
you to use it easily here's what it

00:11:25,210 --> 00:11:29,140
looks like it's very easy to use when

00:11:27,250 --> 00:11:30,640
you're creating your clients you

00:11:29,140 --> 00:11:32,380
generally create a link when you're

00:11:30,640 --> 00:11:34,360
creating your Apollo client when you're

00:11:32,380 --> 00:11:36,460
using persistent queries you call for

00:11:34,360 --> 00:11:38,260
create persistent query link you use

00:11:36,460 --> 00:11:42,820
that as your link that you passed your

00:11:38,260 --> 00:11:44,440
client and then on the server side if

00:11:42,820 --> 00:11:46,540
you're using Apollo server it's super

00:11:44,440 --> 00:11:48,760
easy as well Apollo server gives us a

00:11:46,540 --> 00:11:51,100
lot of kind of out-of-the-box features

00:11:48,760 --> 00:11:52,720
like this that we can use the way that

00:11:51,100 --> 00:11:55,120
it works is it uses memcache in the

00:11:52,720 --> 00:11:57,180
backend and if you pass some

00:11:55,120 --> 00:11:59,530
configuration to the persistent queries

00:11:57,180 --> 00:12:01,450
property here in your Apollo server

00:11:59,530 --> 00:12:03,460
definition you're just gonna get this

00:12:01,450 --> 00:12:05,800
thing syncing up out of the box so

00:12:03,460 --> 00:12:07,870
that's very nice now this ties in nicely

00:12:05,800 --> 00:12:15,090
with something that comes from Apollo

00:12:07,870 --> 00:12:15,090
oops go back here I went way ahead now

00:12:15,450 --> 00:12:21,700
this ties in very nicely with Apollo

00:12:18,100 --> 00:12:24,730
engine Apollo engine is this tool it's a

00:12:21,700 --> 00:12:25,900
service that comes from Apollo that

00:12:24,730 --> 00:12:28,660
gives you a lot of nice things so what

00:12:25,900 --> 00:12:30,070
it gives you is stuff like you can you

00:12:28,660 --> 00:12:31,600
can handle your automatic persistent

00:12:30,070 --> 00:12:34,540
queries much more easily you can track

00:12:31,600 --> 00:12:36,730
errors do tracing all this kind of stuff

00:12:34,540 --> 00:12:40,150
so if you use tools for errors like

00:12:36,730 --> 00:12:41,080
maybe sentry this is a good way to do

00:12:40,150 --> 00:12:45,610
additional tracking that's more

00:12:41,080 --> 00:12:47,350
particular to graph QL it's it runs on

00:12:45,610 --> 00:12:48,670
your own instance so you would deploy it

00:12:47,350 --> 00:12:50,860
to ec2 or kubernetes

00:12:48,670 --> 00:12:52,360
and it's free to get started with so I'd

00:12:50,860 --> 00:12:54,340
recommend checking it out if you're

00:12:52,360 --> 00:12:55,990
interested it's very easy to set up on

00:12:54,340 --> 00:12:57,670
your server as well you just provide

00:12:55,990 --> 00:13:00,610
your API key and then you've got data

00:12:57,670 --> 00:13:04,000
syncing back and forth between Apollo

00:13:00,610 --> 00:13:05,140
Engine and your app okay so automatic

00:13:04,000 --> 00:13:06,930
versus a query is really nice feature

00:13:05,140 --> 00:13:09,730
another one that I'd like to talk about

00:13:06,930 --> 00:13:12,090
that is a bit more advanced would be

00:13:09,730 --> 00:13:16,810
thinking about how to make our resolvers

00:13:12,090 --> 00:13:18,750
more smart more adaptable and so let's

00:13:16,810 --> 00:13:21,600
think about this for a second

00:13:18,750 --> 00:13:24,149
generally when we have a query

00:13:21,600 --> 00:13:27,360
every field that exists in the query has

00:13:24,149 --> 00:13:29,670
a resolver that it attaches to and that

00:13:27,360 --> 00:13:30,920
needs to be run to get some data say out

00:13:29,670 --> 00:13:33,540
of our database and back to the client

00:13:30,920 --> 00:13:35,670
so every fields got a resolver and that

00:13:33,540 --> 00:13:36,810
means that you have if you have a big

00:13:35,670 --> 00:13:40,160
query like this you've got to run

00:13:36,810 --> 00:13:43,290
multiple resolvers on your server and

00:13:40,160 --> 00:13:45,209
potentially you have to wait a long time

00:13:43,290 --> 00:13:47,880
for any of those resolvers to complete

00:13:45,209 --> 00:13:49,470
and it gets worse when you start nesting

00:13:47,880 --> 00:13:51,240
we don't really know quite often its

00:13:49,470 --> 00:13:53,730
client developers what's happening at

00:13:51,240 --> 00:13:55,769
the resolver level and what might be

00:13:53,730 --> 00:13:58,199
creating bottlenecks what might be

00:13:55,769 --> 00:14:00,480
causing slowdowns we don't know for

00:13:58,199 --> 00:14:02,730
instance if maybe the resolver is

00:14:00,480 --> 00:14:06,240
fetching too much data itself that we

00:14:02,730 --> 00:14:08,220
don't actually need for the client so

00:14:06,240 --> 00:14:10,949
here's a resolver there's a resolver

00:14:08,220 --> 00:14:12,990
there's another resolver there's a lot

00:14:10,949 --> 00:14:15,839
of them that need to run and this ties

00:14:12,990 --> 00:14:18,110
in to the n plus 1 query problem anybody

00:14:15,839 --> 00:14:21,750
familiar with u n plus 1 query problem

00:14:18,110 --> 00:14:23,880
so what that says is this let's say

00:14:21,750 --> 00:14:26,010
we've got maybe two tables thinking

00:14:23,880 --> 00:14:27,990
about like a relational database we've

00:14:26,010 --> 00:14:30,209
got two tables we want to take some data

00:14:27,990 --> 00:14:31,560
from one and tie it together with data

00:14:30,209 --> 00:14:33,930
from another so we might say something

00:14:31,560 --> 00:14:36,959
like give me all the posts for author

00:14:33,930 --> 00:14:39,449
with a certain ID and maybe the query

00:14:36,959 --> 00:14:42,449
looks like this select a couple fields

00:14:39,449 --> 00:14:45,420
from that vet table where the author ID

00:14:42,449 --> 00:14:47,610
equals the ID and now and then we might

00:14:45,420 --> 00:14:50,160
say give me all the comments for all

00:14:47,610 --> 00:14:51,540
those posts right so what happens there

00:14:50,160 --> 00:14:54,120
is we'd have to do something like this

00:14:51,540 --> 00:14:56,610
we'd have to say let's iterate through

00:14:54,120 --> 00:14:59,069
all of those posts that came back and

00:14:56,610 --> 00:15:02,339
for each of them let's go fetch the

00:14:59,069 --> 00:15:06,180
comments based on that ID so you've got

00:15:02,339 --> 00:15:09,180
one query up at the top and let's say

00:15:06,180 --> 00:15:11,100
that returns a hundred results well then

00:15:09,180 --> 00:15:13,139
you've got to run a hundred queries for

00:15:11,100 --> 00:15:17,100
that second one down below see you've

00:15:13,139 --> 00:15:17,880
got n which is one plus a hundred

00:15:17,100 --> 00:15:19,889
because there were a hundred results

00:15:17,880 --> 00:15:22,230
under more queries you've got 101

00:15:19,889 --> 00:15:28,350
queries to deal with and that's super

00:15:22,230 --> 00:15:30,630
slow so we can optimize things here and

00:15:28,350 --> 00:15:32,160
we can kind of make assumptions in our

00:15:30,630 --> 00:15:34,230
resolvers about how we might like to

00:15:32,160 --> 00:15:35,390
optimize but ultimately that can make

00:15:34,230 --> 00:15:36,860
our API a little bit

00:15:35,390 --> 00:15:38,810
flexible a little bit less usable

00:15:36,860 --> 00:15:41,570
especially if we want to have maybe a

00:15:38,810 --> 00:15:43,640
public graphical API so it can be a

00:15:41,570 --> 00:15:47,060
little bit difficult to make big

00:15:43,640 --> 00:15:48,770
assumptions about how the API and the

00:15:47,060 --> 00:15:52,040
database should tie together if we want

00:15:48,770 --> 00:15:55,040
to be super flexible makes it hard for

00:15:52,040 --> 00:15:57,890
having a high performance API so I was

00:15:55,040 --> 00:16:00,260
talking to Tanmay he runs a company

00:15:57,890 --> 00:16:03,320
called has sura a server basically gives

00:16:00,260 --> 00:16:05,210
you instant graph QL api's on top of a

00:16:03,320 --> 00:16:07,790
Postgres database so if you have a

00:16:05,210 --> 00:16:10,220
Postgres database you can just run a

00:16:07,790 --> 00:16:13,640
sura on it and immediately you can query

00:16:10,220 --> 00:16:15,500
it with graph QL pretty easily so he was

00:16:13,640 --> 00:16:18,470
saying you know they ran it ran into

00:16:15,500 --> 00:16:20,990
this problem they found because they

00:16:18,470 --> 00:16:23,090
have users who want to query tables with

00:16:20,990 --> 00:16:25,690
billions of rows that it was difficult

00:16:23,090 --> 00:16:28,130
to be able to make graph QL queries

00:16:25,690 --> 00:16:32,120
efficient for getting data out of their

00:16:28,130 --> 00:16:34,310
Postgres databases so they use some

00:16:32,120 --> 00:16:37,010
libraries like data loader whose library

00:16:34,310 --> 00:16:39,710
called data loader by Facebook I believe

00:16:37,010 --> 00:16:41,240
that helps with caching and batching he

00:16:39,710 --> 00:16:45,050
said that wasn't super effective and

00:16:41,240 --> 00:16:49,670
then he said what if we can turn our

00:16:45,050 --> 00:16:51,980
graph QL query itself into raw SQL and

00:16:49,670 --> 00:16:55,190
use that to fetch data from our database

00:16:51,980 --> 00:16:55,990
and that's what they did so here's how

00:16:55,190 --> 00:16:59,420
it works

00:16:55,990 --> 00:17:02,480
basura will take the graph QL query that

00:16:59,420 --> 00:17:07,310
you send to the API and it will run it

00:17:02,480 --> 00:17:08,750
through an AST so when you send a query

00:17:07,310 --> 00:17:11,720
to the server you're gonna get an

00:17:08,750 --> 00:17:13,970
abstract syntax tree it's basically got

00:17:11,720 --> 00:17:15,770
everything that's happening in the query

00:17:13,970 --> 00:17:18,880
in a way that you can parse and

00:17:15,770 --> 00:17:23,209
manipulate and they take that and they

00:17:18,880 --> 00:17:26,290
turn that into raw SQL so this is

00:17:23,209 --> 00:17:30,920
awesome because the query that gets made

00:17:26,290 --> 00:17:33,710
Maps exactly to the SQL command that is

00:17:30,920 --> 00:17:35,540
needed to fetch exactly that data so

00:17:33,710 --> 00:17:37,610
there's no there's no guessing of the

00:17:35,540 --> 00:17:40,880
resolver level there's no kind of making

00:17:37,610 --> 00:17:41,600
assumptions about how your data should

00:17:40,880 --> 00:17:44,840
be fetched

00:17:41,600 --> 00:17:47,180
it's a one-for-one mapping the other

00:17:44,840 --> 00:17:49,220
benefit that they got here is that you

00:17:47,180 --> 00:17:51,230
can make use database features

00:17:49,220 --> 00:17:54,350
that might otherwise be hard to make use

00:17:51,230 --> 00:17:56,150
of so for example one of the bottlenecks

00:17:54,350 --> 00:18:00,020
that they realize with Postgres in

00:17:56,150 --> 00:18:02,289
particular is it takes a long time to

00:18:00,020 --> 00:18:05,570
turn that result from the database into

00:18:02,289 --> 00:18:07,970
JSON it's a bit of a bottleneck they

00:18:05,570 --> 00:18:09,890
were taking a lot of time to complete

00:18:07,970 --> 00:18:12,500
that but there's a feature of Postgres

00:18:09,890 --> 00:18:15,260
called JSON aggregation which handles

00:18:12,500 --> 00:18:16,400
that in a more efficient way and they

00:18:15,260 --> 00:18:18,169
wanted to make use of it

00:18:16,400 --> 00:18:20,059
so with this kind of setup they were

00:18:18,169 --> 00:18:23,480
able to make use of JSON aggregation

00:18:20,059 --> 00:18:25,850
right away alright so what else can we

00:18:23,480 --> 00:18:27,770
do there's some kind of things that we

00:18:25,850 --> 00:18:29,799
can do to affect the numbers but what

00:18:27,770 --> 00:18:32,450
else can we do well I would say we can

00:18:29,799 --> 00:18:34,130
affect perceived performance as well and

00:18:32,450 --> 00:18:38,419
this is a really important way to

00:18:34,130 --> 00:18:40,820
improve the the overall performance of

00:18:38,419 --> 00:18:43,700
your app even if it's just perceived so

00:18:40,820 --> 00:18:46,130
query splitting is one method here and

00:18:43,700 --> 00:18:48,110
what that is basically we said before

00:18:46,130 --> 00:18:49,700
that we can group our queries to make

00:18:48,110 --> 00:18:52,340
things more efficient it might make

00:18:49,700 --> 00:18:54,080
sense in your application to actually if

00:18:52,340 --> 00:18:56,270
you have a big query like this to split

00:18:54,080 --> 00:18:58,669
it up into two separate queries because

00:18:56,270 --> 00:19:01,970
maybe part of your application that's

00:18:58,669 --> 00:19:03,650
above the fold or maybe just is the main

00:19:01,970 --> 00:19:05,600
point of contact when somebody first

00:19:03,650 --> 00:19:07,760
logs in maybe that's all that needs to

00:19:05,600 --> 00:19:09,260
be furnished immediately so you could

00:19:07,760 --> 00:19:11,120
split up your queries and you can make

00:19:09,260 --> 00:19:13,600
the initial one and then you could wait

00:19:11,120 --> 00:19:16,520
some time later to make the second query

00:19:13,600 --> 00:19:19,610
another thing you can do is run what's

00:19:16,520 --> 00:19:21,500
called optimistic UI so optimistic UI

00:19:19,610 --> 00:19:23,270
basically looks like this if you have a

00:19:21,500 --> 00:19:25,970
mutation or graph QL mutation we're

00:19:23,270 --> 00:19:28,669
saving some data it's nice to be able to

00:19:25,970 --> 00:19:31,789
hit the Save button and once that

00:19:28,669 --> 00:19:34,460
happens immediately show the user the

00:19:31,789 --> 00:19:37,340
result on the screen but not the result

00:19:34,460 --> 00:19:39,860
that comes back from your server the

00:19:37,340 --> 00:19:41,510
result just operating on the initial

00:19:39,860 --> 00:19:42,980
data that they render that they were

00:19:41,510 --> 00:19:45,620
that they save and that can be rendered

00:19:42,980 --> 00:19:48,230
immediately so you render the result

00:19:45,620 --> 00:19:50,299
immediately and then once the result

00:19:48,230 --> 00:19:53,990
comes back the actual result comes back

00:19:50,299 --> 00:19:55,429
from the API you render that now of

00:19:53,990 --> 00:19:57,890
course there's some caveats here you've

00:19:55,429 --> 00:19:59,149
got to make sure that if there's some

00:19:57,890 --> 00:20:01,070
critical information that might be

00:19:59,149 --> 00:20:02,270
different once it comes back from the

00:20:01,070 --> 00:20:04,160
API

00:20:02,270 --> 00:20:06,650
than what the the user initially sees

00:20:04,160 --> 00:20:10,010
that you give them a heads up or do

00:20:06,650 --> 00:20:11,690
whatever you need to to for the purposes

00:20:10,010 --> 00:20:13,910
of your application but it's a good way

00:20:11,690 --> 00:20:15,740
to be able to improve the perceived

00:20:13,910 --> 00:20:17,410
performance so if the user thinks the

00:20:15,740 --> 00:20:19,910
application application is faster

00:20:17,410 --> 00:20:23,990
oftentimes that's one of the most

00:20:19,910 --> 00:20:25,340
important most important aspects all

00:20:23,990 --> 00:20:27,370
right so just some final thoughts here

00:20:25,340 --> 00:20:30,920
before we wrap up before we wrap up

00:20:27,370 --> 00:20:34,090
again don't optimize too early I would

00:20:30,920 --> 00:20:36,950
say wait until you run into the pain of

00:20:34,090 --> 00:20:39,770
the bottlenecks you might encounter wait

00:20:36,950 --> 00:20:43,490
until you hit that pain first before you

00:20:39,770 --> 00:20:44,120
dive in with optimization expect things

00:20:43,490 --> 00:20:46,850
to change

00:20:44,120 --> 00:20:49,880
so again graph QL is early on in its

00:20:46,850 --> 00:20:52,250
life there's there's going to be changes

00:20:49,880 --> 00:20:54,890
coming there's gonna be things methods

00:20:52,250 --> 00:20:57,320
that we use next year that are going to

00:20:54,890 --> 00:21:00,940
make this year's methods look silly so

00:20:57,320 --> 00:21:03,590
expect that change and don't be shy to

00:21:00,940 --> 00:21:05,240
to make those changes if necessary and

00:21:03,590 --> 00:21:08,120
the final thing would be to just go and

00:21:05,240 --> 00:21:10,190
experiment I mean again there's there's

00:21:08,120 --> 00:21:11,570
not that same period of time that's gone

00:21:10,190 --> 00:21:13,400
by it that allows us to have

00:21:11,570 --> 00:21:14,780
battle-tested and kind of

00:21:13,400 --> 00:21:17,240
well-thought-out solutions to all this

00:21:14,780 --> 00:21:19,760
stuff so experiment find what works for

00:21:17,240 --> 00:21:23,050
you and that's all so thanks very much

00:21:19,760 --> 00:21:23,050
happy to take any questions

00:21:26,890 --> 00:21:34,090
Thank You Ryan all right got a few

00:21:31,480 --> 00:21:35,950
questions here can automated persisted

00:21:34,090 --> 00:21:40,600
queries be used with Redis instead of

00:21:35,950 --> 00:21:42,250
memcache so I think that uh with Apollo

00:21:40,600 --> 00:21:45,820
I think they only support memcached

00:21:42,250 --> 00:21:49,000
right now but I wouldn't be surprised if

00:21:45,820 --> 00:21:51,940
it if it's easy to swap in another store

00:21:49,000 --> 00:21:53,470
to use whatever you want it might it

00:21:51,940 --> 00:21:55,929
might be something that you need to kind

00:21:53,470 --> 00:21:59,110
of extend the server with but as far as

00:21:55,929 --> 00:22:02,590
I know it's just memcache right now next

00:21:59,110 --> 00:22:06,669
one is the ast to SQL query code open

00:22:02,590 --> 00:22:09,040
source it well I don't know if a sir has

00:22:06,669 --> 00:22:10,660
got any open source code out there I was

00:22:09,040 --> 00:22:13,590
talking to Tanmay directly about this

00:22:10,660 --> 00:22:16,240
but I would reach out to ten me he is

00:22:13,590 --> 00:22:19,530
what is I'll just find his handle really

00:22:16,240 --> 00:22:22,000
quickly here I had it on the screen

00:22:19,530 --> 00:22:28,600
because he's a great guy to talk to

00:22:22,000 --> 00:22:31,360
about this stuff so his handle is tan me

00:22:28,600 --> 00:22:36,490
go on Twitter so I know you can't see it

00:22:31,360 --> 00:22:38,620
but it's ta n ma IG oh all right next

00:22:36,490 --> 00:22:40,570
one how do you feel about using graph QL

00:22:38,620 --> 00:22:42,730
for parts of an application some use

00:22:40,570 --> 00:22:45,880
cases are arguably still easier to cover

00:22:42,730 --> 00:22:48,280
with rest this is uh yet this is true

00:22:45,880 --> 00:22:51,460
some some are one area that you'll see

00:22:48,280 --> 00:22:53,200
quite often where people will default to

00:22:51,460 --> 00:22:56,650
rest would be things like file uploads

00:22:53,200 --> 00:22:58,510
for example there's kind of more

00:22:56,650 --> 00:23:00,940
out-of-the-box solutions perhaps that

00:22:58,510 --> 00:23:03,250
make that doable with a typical rest

00:23:00,940 --> 00:23:06,880
scenario however it's very doable with

00:23:03,250 --> 00:23:09,370
graph QL as well I take the approach

00:23:06,880 --> 00:23:11,440
where I use a mix quite often I'll use a

00:23:09,370 --> 00:23:13,150
mix of graph QL and rest sometimes

00:23:11,440 --> 00:23:15,220
that's because I have to write if I'm

00:23:13,150 --> 00:23:18,250
using a service that only operates on a

00:23:15,220 --> 00:23:20,169
REST API then I'll use rest for that but

00:23:18,250 --> 00:23:21,610
sometimes with my own API I'll create a

00:23:20,169 --> 00:23:23,790
mix just depending on the scenario so I

00:23:21,610 --> 00:23:26,020
I like it some people are pretty

00:23:23,790 --> 00:23:28,360
stringent though and they like to just

00:23:26,020 --> 00:23:32,590
use graph QL but I I personally would

00:23:28,360 --> 00:23:35,410
use both right now the question from

00:23:32,590 --> 00:23:37,450
dude are there any open source

00:23:35,410 --> 00:23:38,710
alternatives for Apollo engine I'd like

00:23:37,450 --> 00:23:40,540
to use it my company

00:23:38,710 --> 00:23:44,430
don't allows it because of

00:23:40,540 --> 00:23:47,290
privacy about planes well so there are

00:23:44,430 --> 00:23:49,420
there are some other solutions out there

00:23:47,290 --> 00:23:51,480
I can't think of the names I've thought

00:23:49,420 --> 00:23:55,150
my head I really just use Apollo stuff

00:23:51,480 --> 00:23:57,100
my advice in this scenario would be try

00:23:55,150 --> 00:23:59,100
to work on your employer try to tell

00:23:57,100 --> 00:24:01,630
them that it's all good to use Apollo

00:23:59,100 --> 00:24:02,680
but there there are are other things out

00:24:01,630 --> 00:24:03,940
there I don't think you'll find anything

00:24:02,680 --> 00:24:06,520
it's fully featured though

00:24:03,940 --> 00:24:07,930
Apollo's got you know they've gotten a

00:24:06,520 --> 00:24:10,630
massive amount of features that are

00:24:07,930 --> 00:24:13,810
super valuable so you can work on your

00:24:10,630 --> 00:24:16,420
company that would be my advice all

00:24:13,810 --> 00:24:18,790
right and last question how about HTTP

00:24:16,420 --> 00:24:21,250
caching yeah so like if you're using

00:24:18,790 --> 00:24:24,970
things like Apollo engine they give you

00:24:21,250 --> 00:24:27,310
ways to cache really intelligently and

00:24:24,970 --> 00:24:28,750
easily so you might want to look to

00:24:27,310 --> 00:24:30,700
Apollo in you know for that there's also

00:24:28,750 --> 00:24:33,130
ways that you can kind of cash at the

00:24:30,700 --> 00:24:35,290
HTTP layer without it there's some

00:24:33,130 --> 00:24:37,690
libraries out there to do that so yeah

00:24:35,290 --> 00:24:39,010
it's worth a shot as well caching all

00:24:37,690 --> 00:24:41,310
right fantastic let's give it up for

00:24:39,010 --> 00:24:41,310
Ryan

00:24:43,230 --> 00:24:45,290

YouTube URL: https://www.youtube.com/watch?v=BwxIBV792r0


