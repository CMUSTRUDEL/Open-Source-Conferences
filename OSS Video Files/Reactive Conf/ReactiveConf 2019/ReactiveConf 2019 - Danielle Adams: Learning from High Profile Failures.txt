Title: ReactiveConf 2019 - Danielle Adams: Learning from High Profile Failures
Publication date: 2019-10-30
Playlist: ReactiveConf 2019
Description: 
	Oct 30 - Nov 1, 2019
Prague, Czech Republic
https://reactiveconf.com/
Discovery stage
-------------------------------------------------------------------
Tech companies of all sizes have dropped the ball when it comes to the privacy of their users. Many users find themselves asking, “How could this breach have happened?” and “What happened to my data?”. Surprisingly, many of these large-scale data breaches have been 100% preventable. I’d like to walk through the pitfalls of some of the largest data breaches of the past few years, what we’ve learned from them and how engineering teams can avoid them going forward.
Captions: 
	00:00:02,720 --> 00:00:11,850
[Music]

00:00:16,320 --> 00:00:22,689
stragglers welcome everyone hello my

00:00:19,990 --> 00:00:24,220
name is Danielle full disclosure I

00:00:22,689 --> 00:00:26,200
didn't think I was nervous but then

00:00:24,220 --> 00:00:28,600
while I was waiting to speak I realized

00:00:26,200 --> 00:00:30,760
I lost my backpack so if anyone finds it

00:00:28,600 --> 00:00:32,790
please just leave it where it is I will

00:00:30,760 --> 00:00:35,350
come get it later

00:00:32,790 --> 00:00:37,989
so yeah so like I was introduced I'm

00:00:35,350 --> 00:00:40,019
Danielle Adams I'm coming here from New

00:00:37,989 --> 00:00:42,970
York and we're gonna be talking about

00:00:40,019 --> 00:00:46,360
high-profile failures so a little bit

00:00:42,970 --> 00:00:49,510
about me for first I work at Heroku I'm

00:00:46,360 --> 00:00:51,549
the node.js language owner over there so

00:00:49,510 --> 00:00:54,010
that means I maintain the build pack and

00:00:51,549 --> 00:00:57,120
I'm responsible for all of the users

00:00:54,010 --> 00:00:59,110
builds and runtime environments on node

00:00:57,120 --> 00:01:00,250
but we're not gonna be talking about no

00:00:59,110 --> 00:01:01,839
today we're actually gonna be talking

00:01:00,250 --> 00:01:05,560
about security the reason why I'm up

00:01:01,839 --> 00:01:07,840
here is because I work so I work during

00:01:05,560 --> 00:01:09,549
the day but then I also at nighttime I'm

00:01:07,840 --> 00:01:12,549
a student at a university in New York

00:01:09,549 --> 00:01:14,950
where I'm studying cybersecurity and as

00:01:12,549 --> 00:01:18,159
I've been doing this I've realized that

00:01:14,950 --> 00:01:20,380
so it's been about a year and a half now

00:01:18,159 --> 00:01:21,909
and I've realized that as I'm learning

00:01:20,380 --> 00:01:23,530
more about security and information

00:01:21,909 --> 00:01:26,320
security and application security I

00:01:23,530 --> 00:01:28,960
realized that it's actually making me a

00:01:26,320 --> 00:01:30,909
better developer so even if I end my

00:01:28,960 --> 00:01:32,649
program and I decide I hate security I

00:01:30,909 --> 00:01:33,939
don't want to do this it's definitely

00:01:32,649 --> 00:01:37,270
made me think about software development

00:01:33,939 --> 00:01:38,590
a little bit differently so that's what

00:01:37,270 --> 00:01:40,659
we're gonna talk about learning from

00:01:38,590 --> 00:01:43,450
high-profile failures what can we learn

00:01:40,659 --> 00:01:46,780
from all of these big hacks that have

00:01:43,450 --> 00:01:49,210
happened big hacks small Havoc's and how

00:01:46,780 --> 00:01:50,799
we can use them to make our software

00:01:49,210 --> 00:01:53,560
development process a little bit better

00:01:50,799 --> 00:01:55,630
or what I would just like to call it my

00:01:53,560 --> 00:01:58,210
favorite hacks things that have seemed

00:01:55,630 --> 00:02:02,789
to have gone so wrong but have done it

00:01:58,210 --> 00:02:06,520
they have happened from such simple

00:02:02,789 --> 00:02:08,380
issues so before we get started I think

00:02:06,520 --> 00:02:10,479
we need to get some of the terminology

00:02:08,380 --> 00:02:13,030
down there's a bunch of people coming in

00:02:10,479 --> 00:02:15,850
hey everyone

00:02:13,030 --> 00:02:17,230
okay so some of the terminology so cyber

00:02:15,850 --> 00:02:19,030
security when people think about

00:02:17,230 --> 00:02:22,180
cybersecurity there's a common

00:02:19,030 --> 00:02:24,709
misconception that it is the practice of

00:02:22,180 --> 00:02:26,480
trying to keep people out

00:02:24,709 --> 00:02:28,760
and that's not the case at all what

00:02:26,480 --> 00:02:30,799
you're trying to do is make it so hard

00:02:28,760 --> 00:02:32,900
and so tedious

00:02:30,799 --> 00:02:34,609
to break into other people's software

00:02:32,900 --> 00:02:37,040
into their servers into their databases

00:02:34,609 --> 00:02:38,480
that it's too costly it's too

00:02:37,040 --> 00:02:40,040
time-consuming that they don't want to

00:02:38,480 --> 00:02:43,459
do it and they just move on to the next

00:02:40,040 --> 00:02:45,230
easiest one so a couple other

00:02:43,459 --> 00:02:48,079
terminologies that we want to keep in

00:02:45,230 --> 00:02:49,969
mind so I'm gonna be saying threat a lot

00:02:48,079 --> 00:02:51,379
a threat is something that it can

00:02:49,969 --> 00:02:54,680
compromise the confidentiality integrity

00:02:51,379 --> 00:02:56,209
and availability of any sort of assets

00:02:54,680 --> 00:03:00,919
database would be an asset

00:02:56,209 --> 00:03:01,909
CIA is a common kind of triple term that

00:03:00,919 --> 00:03:05,389
you'll hear when you're studying

00:03:01,909 --> 00:03:08,000
information security and it's what it's

00:03:05,389 --> 00:03:08,870
what we're really trying to protect and

00:03:08,000 --> 00:03:11,000
then there's vulnerabilities

00:03:08,870 --> 00:03:13,310
vulnerabilities is an a weakness in any

00:03:11,000 --> 00:03:15,019
infrastructure that makes it susceptible

00:03:13,310 --> 00:03:16,969
to a threat so this doesn't just have to

00:03:15,019 --> 00:03:18,769
be a server or database this could be

00:03:16,969 --> 00:03:20,810
hardware this could be a physical

00:03:18,769 --> 00:03:24,799
building anywhere where somebody can

00:03:20,810 --> 00:03:27,010
break in and and access something

00:03:24,799 --> 00:03:29,510
they're not supposed to be to see and

00:03:27,010 --> 00:03:32,840
then there's an attack and so this is

00:03:29,510 --> 00:03:34,430
probably the most self-explanatory an

00:03:32,840 --> 00:03:37,629
attack is an exploitation of a

00:03:34,430 --> 00:03:40,250
vulnerability in one way or another so

00:03:37,629 --> 00:03:42,290
case number one we're going to be going

00:03:40,250 --> 00:03:44,750
through real cases that have happened

00:03:42,290 --> 00:03:46,699
and how we can learn from them so I'm

00:03:44,750 --> 00:03:49,010
going to call this Alice agency I'm not

00:03:46,699 --> 00:03:52,760
using any names because I'm not here to

00:03:49,010 --> 00:03:54,650
shame people or any companies everyone

00:03:52,760 --> 00:03:56,209
makes mistakes and what we really want

00:03:54,650 --> 00:03:58,040
to get take away from this is the

00:03:56,209 --> 00:04:02,620
lessons that we weren't learned and not

00:03:58,040 --> 00:04:02,620
actually look at the details like names

00:04:03,970 --> 00:04:10,759
so first of all so in March 2017 there

00:04:08,720 --> 00:04:12,799
was a vulnerability and a Java web

00:04:10,759 --> 00:04:15,370
framework that was discovered and it was

00:04:12,799 --> 00:04:18,109
disclosed it was an and a vulnerability

00:04:15,370 --> 00:04:20,630
and the vulnerability allowed remote

00:04:18,109 --> 00:04:23,210
code to execute when passed into content

00:04:20,630 --> 00:04:25,460
type content disposition and content

00:04:23,210 --> 00:04:27,530
length headers so if you can imagine

00:04:25,460 --> 00:04:31,370
you're making an HTTP request and you

00:04:27,530 --> 00:04:33,680
include executable code in one of those

00:04:31,370 --> 00:04:36,050
content headers it means that the

00:04:33,680 --> 00:04:37,370
middleware or the web framework was not

00:04:36,050 --> 00:04:38,510
parsing these correctly and it was

00:04:37,370 --> 00:04:41,630
allowing remote

00:04:38,510 --> 00:04:44,660
code to execute in these web servers of

00:04:41,630 --> 00:04:47,900
these Java apps and it was an enterprise

00:04:44,660 --> 00:04:50,270
piece of software which we'll talk about

00:04:47,900 --> 00:04:52,760
why that's important later so what is an

00:04:50,270 --> 00:04:55,540
end a vulnerability so it's been

00:04:52,760 --> 00:05:00,200
disclosed to some sort of vulnerability

00:04:55,540 --> 00:05:01,790
database and so this is a lesser known

00:05:00,200 --> 00:05:03,290
version what's really popular is

00:05:01,790 --> 00:05:04,550
zero-day vulnerabilities and those are

00:05:03,290 --> 00:05:07,400
the vulnerabilities so there's two types

00:05:04,550 --> 00:05:10,460
there's end a and zero day zero day is a

00:05:07,400 --> 00:05:12,020
vulnerability that is has been dissed it

00:05:10,460 --> 00:05:13,730
hasn't been disclosed but it's been

00:05:12,020 --> 00:05:16,700
discovered and it's been exploited in

00:05:13,730 --> 00:05:20,630
that moment or on that day why it's just

00:05:16,700 --> 00:05:22,730
wide zero day and then n day is you're

00:05:20,630 --> 00:05:24,740
given the the reason it's n day is

00:05:22,730 --> 00:05:28,280
because you have day zero when it's been

00:05:24,740 --> 00:05:30,200
discovered and then you have a couple

00:05:28,280 --> 00:05:33,020
days there's a patch that might come out

00:05:30,200 --> 00:05:36,020
in seven days and then maybe in another

00:05:33,020 --> 00:05:40,040
seven days you've issued a patch and so

00:05:36,020 --> 00:05:44,780
of a study of 6300 vulnerabilities over

00:05:40,040 --> 00:05:47,600
99% were n day so it's a kind of a myth

00:05:44,780 --> 00:05:50,030
that zero days are the scariest because

00:05:47,600 --> 00:05:53,450
there are the least common most common

00:05:50,030 --> 00:05:55,490
are ending Valle 'nor abilities they

00:05:53,450 --> 00:05:58,100
shouldn't be because they could be fixed

00:05:55,490 --> 00:06:00,020
by just making a patch but the same

00:05:58,100 --> 00:06:03,670
study found that it takes an average of

00:06:00,020 --> 00:06:06,620
30 days to fix a critical patch so that

00:06:03,670 --> 00:06:08,690
means from the time that the that the

00:06:06,620 --> 00:06:11,450
vulnerability has been disclosed to the

00:06:08,690 --> 00:06:13,040
time that a patch is released to the

00:06:11,450 --> 00:06:16,640
time that it actually gets fixed that's

00:06:13,040 --> 00:06:20,060
30 days that's a lot of damage that can

00:06:16,640 --> 00:06:24,230
happen in 30 days and we will kind of we

00:06:20,060 --> 00:06:26,420
will see why so this is OK yeah so this

00:06:24,230 --> 00:06:28,760
is just a sample HTTP request for to

00:06:26,420 --> 00:06:30,560
give everyone a visual using content

00:06:28,760 --> 00:06:33,050
length and content type is not an

00:06:30,560 --> 00:06:36,050
uncommon thing this is a sample request

00:06:33,050 --> 00:06:39,740
headers from an elixir server at Heroku

00:06:36,050 --> 00:06:42,650
and just to make it bigger this is what

00:06:39,740 --> 00:06:47,260
we would usually see for the values for

00:06:42,650 --> 00:06:49,520
these types of headers and so when the

00:06:47,260 --> 00:06:51,560
vulnerability was first disclosed this

00:06:49,520 --> 00:06:52,230
is what it was found is that this person

00:06:51,560 --> 00:06:54,030
this is a screen

00:06:52,230 --> 00:06:59,130
shot from the server from the researcher

00:06:54,030 --> 00:07:00,570
that had disclosed this and so and so

00:06:59,130 --> 00:07:02,940
what they found was that they had this

00:07:00,570 --> 00:07:05,910
this these headers that they were able

00:07:02,940 --> 00:07:08,430
to do to put into this request and then

00:07:05,910 --> 00:07:11,220
they were able to create a little line

00:07:08,430 --> 00:07:13,350
that just executed some some code and

00:07:11,220 --> 00:07:19,590
then they were able to see that

00:07:13,350 --> 00:07:21,450
execution in the server logs so six

00:07:19,590 --> 00:07:26,280
months later it was disclosed that this

00:07:21,450 --> 00:07:27,990
agency had 145 point five million people

00:07:26,280 --> 00:07:30,180
their sensitive data had been accessed

00:07:27,990 --> 00:07:32,520
by an unauthorized party and so the

00:07:30,180 --> 00:07:34,140
agency discloses it actually they

00:07:32,520 --> 00:07:34,590
disclosed it six months later and it

00:07:34,140 --> 00:07:36,090
happened

00:07:34,590 --> 00:07:37,800
for months before which means it

00:07:36,090 --> 00:07:39,840
happened two months after the

00:07:37,800 --> 00:07:42,180
vulnerability was disclosed that's a

00:07:39,840 --> 00:07:47,910
full sixty days that they just didn't

00:07:42,180 --> 00:07:49,830
patch this and it was a not good and so

00:07:47,910 --> 00:07:52,050
what we want to take away from this is

00:07:49,830 --> 00:07:54,900
that the confidentiality of the user had

00:07:52,050 --> 00:07:56,790
been had been breached so kind of that

00:07:54,900 --> 00:07:58,380
term that I was talking about and so

00:07:56,790 --> 00:08:00,540
when we are protecting data and we're

00:07:58,380 --> 00:08:02,970
protecting assets confidentiality of

00:08:00,540 --> 00:08:09,480
data is really important and so it was

00:08:02,970 --> 00:08:13,470
just completely exploited so so how do

00:08:09,480 --> 00:08:16,560
we want to prevent this so just to kind

00:08:13,470 --> 00:08:19,200
of switch gears for a little bit um so

00:08:16,560 --> 00:08:21,480
static analysis is a pretty common way

00:08:19,200 --> 00:08:23,160
to prevent security vulnerabilities

00:08:21,480 --> 00:08:25,050
there's a lot of different types of

00:08:23,160 --> 00:08:28,080
static analysis and I think that there's

00:08:25,050 --> 00:08:31,830
this misconception that just having any

00:08:28,080 --> 00:08:34,140
static analysis on a code a code base is

00:08:31,830 --> 00:08:36,450
just like automatically it's going to

00:08:34,140 --> 00:08:38,010
prevent regressions and it's kind of you

00:08:36,450 --> 00:08:40,650
know prevent tests and make my code

00:08:38,010 --> 00:08:42,120
better and it's important to understand

00:08:40,650 --> 00:08:44,520
the difference between all of these and

00:08:42,120 --> 00:08:46,920
so for people that don't know static

00:08:44,520 --> 00:08:49,050
analysis is running an analysis on code

00:08:46,920 --> 00:08:52,140
without actually having to execute it so

00:08:49,050 --> 00:08:55,890
yes lint in typescript or both forms of

00:08:52,140 --> 00:08:59,430
this eastland being a linter and then

00:08:55,890 --> 00:09:01,340
typescript doing type checking so when

00:08:59,430 --> 00:09:03,780
we're looking at static analysis for

00:09:01,340 --> 00:09:05,410
security applications we want to make

00:09:03,780 --> 00:09:09,190
sure that so this is a

00:09:05,410 --> 00:09:11,530
diagram that I stole from the OWASP

00:09:09,190 --> 00:09:13,570
website which I will talk about what

00:09:11,530 --> 00:09:15,280
that is and a little bit later but so we

00:09:13,570 --> 00:09:18,100
have this line in the middle and so we

00:09:15,280 --> 00:09:21,040
see that the x-axis is false positive

00:09:18,100 --> 00:09:23,770
rate and the y-axis is true positive

00:09:21,040 --> 00:09:27,190
rate and so we see high false positive

00:09:23,770 --> 00:09:29,290
and high true positive that's usually I

00:09:27,190 --> 00:09:33,010
would say that's where a lot of static

00:09:29,290 --> 00:09:34,390
analysis tools fall then we have tools

00:09:33,010 --> 00:09:36,610
that report vulnerabilities in the

00:09:34,390 --> 00:09:40,120
middle we don't really want that that

00:09:36,610 --> 00:09:41,530
could be flaky tests false positive and

00:09:40,120 --> 00:09:43,060
true positive we don't want anything

00:09:41,530 --> 00:09:45,520
like that it's useless just throw it

00:09:43,060 --> 00:09:48,550
away but what we want is false positive

00:09:45,520 --> 00:09:49,750
to be down to zero and true positive to

00:09:48,550 --> 00:09:52,720
be in the hundred percent and that's

00:09:49,750 --> 00:09:55,170
where we want our static analysis for

00:09:52,720 --> 00:09:58,870
security tools to be so that's the ideal

00:09:55,170 --> 00:10:02,140
vulnerability detection and so a

00:09:58,870 --> 00:10:04,030
dependency scanner is a really good use

00:10:02,140 --> 00:10:07,990
case for this and it analyzes your

00:10:04,030 --> 00:10:10,300
source code dependencies our open source

00:10:07,990 --> 00:10:12,790
libraries that we use and we don't

00:10:10,300 --> 00:10:14,020
necessarily we haven't written the code

00:10:12,790 --> 00:10:15,640
and we haven't looked at the code and

00:10:14,020 --> 00:10:17,350
most likely we haven't really tested the

00:10:15,640 --> 00:10:20,890
code unless it's we've tested that it

00:10:17,350 --> 00:10:25,180
works and so when we use a dependency

00:10:20,890 --> 00:10:30,330
scanner that is we can kind of see if

00:10:25,180 --> 00:10:34,260
it's vulnerable just based on the the

00:10:30,330 --> 00:10:38,320
databases that have for detection or for

00:10:34,260 --> 00:10:41,820
disclosures so I really like sneak I

00:10:38,320 --> 00:10:45,400
think it's a good tool for NPM and

00:10:41,820 --> 00:10:47,560
anything in the node ecosystem I believe

00:10:45,400 --> 00:10:51,190
I could be wrong about this I believe

00:10:47,560 --> 00:10:53,260
that it was first built for node project

00:10:51,190 --> 00:10:54,700
so front-end back-end and so what it

00:10:53,260 --> 00:10:57,250
does is it goes through all of your

00:10:54,700 --> 00:11:00,370
dependencies and it takes the scan at

00:10:57,250 --> 00:11:01,630
them and looks to see matches those

00:11:00,370 --> 00:11:05,040
dependencies to see if there's any

00:11:01,630 --> 00:11:08,220
critical or medium or lower

00:11:05,040 --> 00:11:11,980
vulnerabilities which is kind of how

00:11:08,220 --> 00:11:13,900
vulnerabilities are classified severity

00:11:11,980 --> 00:11:15,550
are severe is the ones that you want to

00:11:13,900 --> 00:11:18,550
patch pretty quickly or have a schedule

00:11:15,550 --> 00:11:19,030
for low is um you know you can kind of

00:11:18,550 --> 00:11:20,590
get to that

00:11:19,030 --> 00:11:23,290
later and especially if there isn't a

00:11:20,590 --> 00:11:26,680
path forward and then it also sorry this

00:11:23,290 --> 00:11:28,150
little blurry but and there's also gives

00:11:26,680 --> 00:11:29,890
like a full description so you can

00:11:28,150 --> 00:11:35,290
really understand how to move forward

00:11:29,890 --> 00:11:37,690
with these vulnerabilities so case

00:11:35,290 --> 00:11:41,350
number two I'm gonna call it Bob and Co

00:11:37,690 --> 00:11:43,710
Bob and Co was a is a a dating website

00:11:41,350 --> 00:11:46,840
which so we can all imagine how

00:11:43,710 --> 00:11:49,660
important privacy is or confidentiality

00:11:46,840 --> 00:11:52,690
is in a dating website as well and so it

00:11:49,660 --> 00:11:55,810
was hacked and so in December of 2015

00:11:52,690 --> 00:11:58,660
data dump containing user data that was

00:11:55,810 --> 00:12:02,530
found online and confirmed to be long to

00:11:58,660 --> 00:12:05,650
the site I don't know how it got there

00:12:02,530 --> 00:12:07,570
but that isn't really the important part

00:12:05,650 --> 00:12:10,120
with this what happened afterwards is

00:12:07,570 --> 00:12:11,970
kind of the crazy part so after the data

00:12:10,120 --> 00:12:16,090
dump was found so the data dump being

00:12:11,970 --> 00:12:20,680
their database of user data emails hash

00:12:16,090 --> 00:12:22,510
passwords some other values and this

00:12:20,680 --> 00:12:24,310
didn't really matter because emails

00:12:22,510 --> 00:12:26,170
anyone can make a fake account like it

00:12:24,310 --> 00:12:28,390
could be inactive whatever so that was

00:12:26,170 --> 00:12:29,860
fine but then a second dump was released

00:12:28,390 --> 00:12:31,660
and it was the source code for the

00:12:29,860 --> 00:12:33,970
website and internal emails and this is

00:12:31,660 --> 00:12:36,520
where it got really crazy and so

00:12:33,970 --> 00:12:38,470
initially like I said it was a dump of

00:12:36,520 --> 00:12:41,290
the username and password and the user

00:12:38,470 --> 00:12:45,040
or sorry the passwords were encrypted

00:12:41,290 --> 00:12:48,340
with bcrypt and so bcrypt is a one-way

00:12:45,040 --> 00:12:51,820
hashing algorithm you to use on password

00:12:48,340 --> 00:12:53,860
storage and so it's by design very slow

00:12:51,820 --> 00:12:57,250
so when it does perform and you can make

00:12:53,860 --> 00:12:59,500
it even slower so you can run it a few

00:12:57,250 --> 00:13:02,650
times up to however many times and it'll

00:12:59,500 --> 00:13:04,690
just the algorithm will be very slow to

00:13:02,650 --> 00:13:08,740
perform and it's like that by design and

00:13:04,690 --> 00:13:13,510
so when this dump was first revealed it

00:13:08,740 --> 00:13:14,830
was it was it was decided that oh people

00:13:13,510 --> 00:13:16,300
were like oh we could see that it's

00:13:14,830 --> 00:13:18,580
using decrypt that's gonna take a long

00:13:16,300 --> 00:13:19,900
time but at least we're gonna try but

00:13:18,580 --> 00:13:22,600
then when the source code came out oh

00:13:19,900 --> 00:13:25,000
okay so this is what a functionality

00:13:22,600 --> 00:13:26,920
error this is what a kind of a diagram

00:13:25,000 --> 00:13:28,750
of what a password cracking program

00:13:26,920 --> 00:13:31,150
would look like there on the internet

00:13:28,750 --> 00:13:32,290
you can look them up and so all you have

00:13:31,150 --> 00:13:34,959
to do is

00:13:32,290 --> 00:13:37,480
this is a common password cracking

00:13:34,959 --> 00:13:39,850
tactic where you take a dictionary list

00:13:37,480 --> 00:13:42,519
and it's just any lit you can find a

00:13:39,850 --> 00:13:44,649
list of the most common passwords it's

00:13:42,519 --> 00:13:46,870
just you know my password

00:13:44,649 --> 00:13:48,940
you know my dog spike like all of these

00:13:46,870 --> 00:13:51,399
words that people just use because

00:13:48,940 --> 00:13:53,920
they're not using secure passwords and

00:13:51,399 --> 00:13:56,079
so what it does is it runs against the

00:13:53,920 --> 00:13:58,300
hash dump that's been found and it'll

00:13:56,079 --> 00:14:01,149
look for matches and so that it can see

00:13:58,300 --> 00:14:04,420
okay this hash equals this hash from

00:14:01,149 --> 00:14:05,410
this plaintext word and so with bcrypt

00:14:04,420 --> 00:14:08,290
that would have taken a long time

00:14:05,410 --> 00:14:11,160
because of the nature of the because it

00:14:08,290 --> 00:14:15,250
was a CPU consuming and a time consuming

00:14:11,160 --> 00:14:19,540
hashing algorithm and so when the source

00:14:15,250 --> 00:14:21,579
code came out so we have this code and

00:14:19,540 --> 00:14:23,170
this is the most interesting part and

00:14:21,579 --> 00:14:25,089
just take a moment and look at this

00:14:23,170 --> 00:14:27,970
hopefully everyone's back and see it too

00:14:25,089 --> 00:14:30,550
and I just want to see if anyone

00:14:27,970 --> 00:14:37,600
recognizes what is kind of weird about

00:14:30,550 --> 00:14:41,560
this code and that's your hint so what's

00:14:37,600 --> 00:14:43,990
happening here is we have this first

00:14:41,560 --> 00:14:45,910
initial password value we're running an

00:14:43,990 --> 00:14:48,279
encryption on it which presumably is the

00:14:45,910 --> 00:14:50,100
bcrypt great and then we get here

00:14:48,279 --> 00:14:52,510
it takes the original plain test

00:14:50,100 --> 00:14:54,730
plaintext password and then it runs

00:14:52,510 --> 00:14:58,839
another encryption value on it or

00:14:54,730 --> 00:15:01,029
encryption algorithm on it md5 and then

00:14:58,839 --> 00:15:02,589
it assigns it to a login key so we're

00:15:01,029 --> 00:15:04,389
taking what we've done to make this

00:15:02,589 --> 00:15:06,399
application secure and we're completely

00:15:04,389 --> 00:15:09,670
sidestepping it by encrypting it with

00:15:06,399 --> 00:15:13,300
another encryption algorithm and then

00:15:09,670 --> 00:15:15,430
storing that too so what is the

00:15:13,300 --> 00:15:17,889
difference between md5 and bcrypt

00:15:15,430 --> 00:15:20,380
well they're both one-way hashing

00:15:17,889 --> 00:15:23,230
algorithms empty five once upon a time

00:15:20,380 --> 00:15:24,880
was a it's better than plaintext we'll

00:15:23,230 --> 00:15:29,889
just put it that way

00:15:24,880 --> 00:15:31,720
and so md5 it outputs and 128 bit hash

00:15:29,889 --> 00:15:33,100
value whereas bcrypt the way that they

00:15:31,720 --> 00:15:34,899
knew it was be crypt is that it starts

00:15:33,100 --> 00:15:38,529
with a dollar sign to value so they saw

00:15:34,899 --> 00:15:42,250
those in the the dump and so md5 is fast

00:15:38,529 --> 00:15:45,310
to brute-force and fast to D curve not

00:15:42,250 --> 00:15:49,730
really decrypting to on to crack

00:15:45,310 --> 00:15:51,350
and md5 though it would take days to run

00:15:49,730 --> 00:15:54,620
because it's it's less time-consuming

00:15:51,350 --> 00:15:58,100
and it's less expensive in terms of CPU

00:15:54,620 --> 00:16:00,770
power and bcrypt would have taken years

00:15:58,100 --> 00:16:04,700
so what happened so entire profiles of

00:16:00,770 --> 00:16:06,560
p.m. in users were exposed on the

00:16:04,700 --> 00:16:09,050
internet including names emails phone

00:16:06,560 --> 00:16:11,180
numbers credit card numbers purchase

00:16:09,050 --> 00:16:13,550
history profile descriptions weight

00:16:11,180 --> 00:16:15,410
height everything so you could see who

00:16:13,550 --> 00:16:17,690
the clearly the active users were and

00:16:15,410 --> 00:16:19,460
the inactive users were this would not

00:16:17,690 --> 00:16:21,380
have happened if the second password

00:16:19,460 --> 00:16:23,330
hashing had not been created I just want

00:16:21,380 --> 00:16:25,250
to make that clear confidentiality was

00:16:23,330 --> 00:16:30,770
imposed on but most importantly privacy

00:16:25,250 --> 00:16:32,210
of users was also breached and so just

00:16:30,770 --> 00:16:34,840
to make a distinction between

00:16:32,210 --> 00:16:37,670
confidentiality and privacy

00:16:34,840 --> 00:16:39,290
confidentiality refers to data whereas

00:16:37,670 --> 00:16:41,240
when we're talking about privacy we're

00:16:39,290 --> 00:16:43,640
really talking about the person and so

00:16:41,240 --> 00:16:45,920
everyone is entitled to privacy

00:16:43,640 --> 00:16:49,460
if privacy is breached that could lead

00:16:45,920 --> 00:16:51,650
to an endangerment of somebody's life

00:16:49,460 --> 00:16:54,830
that can lead to them going through

00:16:51,650 --> 00:16:56,510
emotional turmoil and so you know I can

00:16:54,830 --> 00:17:00,560
my credit card can go on the internet

00:16:56,510 --> 00:17:03,170
but the and that's a breach of my of

00:17:00,560 --> 00:17:04,580
confidentiality in terms of data but if

00:17:03,170 --> 00:17:06,820
someone were to see my credit card

00:17:04,580 --> 00:17:09,350
history that's a breach of my privacy

00:17:06,820 --> 00:17:15,110
something that I would argue that I

00:17:09,350 --> 00:17:17,330
deserve so prevention on this so I'm

00:17:15,110 --> 00:17:19,640
just looking at the source code I see

00:17:17,330 --> 00:17:21,350
two stories here and I don't know what

00:17:19,640 --> 00:17:24,140
happened I wasn't there I'm not gonna

00:17:21,350 --> 00:17:27,170
pretend like I understand what happened

00:17:24,140 --> 00:17:31,460
this day but what I will say is that I

00:17:27,170 --> 00:17:33,800
do see two kind of sides here I see this

00:17:31,460 --> 00:17:37,940
password encryption which was an effort

00:17:33,800 --> 00:17:42,290
to obviously keep the passwords and the

00:17:37,940 --> 00:17:45,140
users privacy protected and then I also

00:17:42,290 --> 00:17:46,820
see another story where someone decided

00:17:45,140 --> 00:17:48,800
that that was too slow and they also

00:17:46,820 --> 00:17:52,400
wanted to make problem there might have

00:17:48,800 --> 00:17:53,210
been something with sessions I don't

00:17:52,400 --> 00:17:54,770
know

00:17:53,210 --> 00:17:56,900
and what they were doing is they were

00:17:54,770 --> 00:17:58,620
sidestepping probably the slow and the

00:17:56,900 --> 00:18:00,330
slowness of bcrypt

00:17:58,620 --> 00:18:02,070
and making it so that the password was

00:18:00,330 --> 00:18:05,400
available in case they wanted to maybe

00:18:02,070 --> 00:18:06,930
login or whatever and so this person was

00:18:05,400 --> 00:18:09,180
really looking at user experience and

00:18:06,930 --> 00:18:11,309
this other person was wanting to make

00:18:09,180 --> 00:18:12,720
this application more secure and they

00:18:11,309 --> 00:18:15,570
completely butted heads with each other

00:18:12,720 --> 00:18:17,670
neither make you know no one really want

00:18:15,570 --> 00:18:22,340
in this scenario oh yeah okay so this is

00:18:17,670 --> 00:18:25,440
see this and this so this is kind of

00:18:22,340 --> 00:18:27,180
this is easier said than done

00:18:25,440 --> 00:18:30,300
but I just want to highlight that I

00:18:27,180 --> 00:18:31,830
think that there is oftentimes a kind of

00:18:30,300 --> 00:18:34,050
a separation between the development

00:18:31,830 --> 00:18:35,160
teams and security teams security

00:18:34,050 --> 00:18:37,050
engineers are there to break things

00:18:35,160 --> 00:18:40,380
development teams build things and so

00:18:37,050 --> 00:18:42,900
but when when the two want to say two

00:18:40,380 --> 00:18:44,400
sides but when everyone collaborates you

00:18:42,900 --> 00:18:45,900
do come out with a better product and it

00:18:44,400 --> 00:18:48,150
still is your responsibility as

00:18:45,900 --> 00:18:56,040
developers to make sure that product is

00:18:48,150 --> 00:18:59,510
secure and it's also cool and awesome so

00:18:56,040 --> 00:19:02,160
number three is oh yeah that's fine

00:18:59,510 --> 00:19:06,929
International Airlines again names are

00:19:02,160 --> 00:19:09,960
changed to defend the hacks so in late

00:19:06,929 --> 00:19:11,400
2018 there were reports of JavaScript

00:19:09,960 --> 00:19:14,429
assets that had been tampered with

00:19:11,400 --> 00:19:17,309
on this Airlines desktop app and mobile

00:19:14,429 --> 00:19:21,420
apps so they were using I assume like a

00:19:17,309 --> 00:19:24,720
cordova around their HTML and javascript

00:19:21,420 --> 00:19:26,910
and CSS to create a native app I'm

00:19:24,720 --> 00:19:28,590
pretty sure and so that's why the same

00:19:26,910 --> 00:19:33,480
JavaScript assets were being used on the

00:19:28,590 --> 00:19:37,559
website and in their mobile app so this

00:19:33,480 --> 00:19:39,840
is the this is the JavaScript that was

00:19:37,559 --> 00:19:44,809
found running on the page that had may

00:19:39,840 --> 00:19:51,809
have there may not have been subject to

00:19:44,809 --> 00:19:56,520
exploiting a user's data so did I skip

00:19:51,809 --> 00:19:59,910
something no okay so so let's look at

00:19:56,520 --> 00:20:02,520
this this already looks shady here it's

00:19:59,910 --> 00:20:07,520
wiping the entire payment form and it's

00:20:02,520 --> 00:20:07,520
assigning it to a JavaScript object

00:20:08,480 --> 00:20:15,179
and then what is it doing it's sending a

00:20:10,919 --> 00:20:18,690
post request to some other random web

00:20:15,179 --> 00:20:20,340
site and then and as you could see oh

00:20:18,690 --> 00:20:22,379
yeah and that's important so you could

00:20:20,340 --> 00:20:24,480
see it's even using HTTP so it wasn't

00:20:22,379 --> 00:20:29,570
just like a random site these people

00:20:24,480 --> 00:20:32,279
took the time to let's just assume that

00:20:29,570 --> 00:20:34,950
the you or the domain looked very

00:20:32,279 --> 00:20:37,529
similar to the source domain and then

00:20:34,950 --> 00:20:41,879
they also took the time to create a to

00:20:37,529 --> 00:20:43,409
get it to register the the the domain

00:20:41,879 --> 00:20:48,870
with a certificate authority because it

00:20:43,409 --> 00:20:52,259
is using HTTP so an external analysis

00:20:48,870 --> 00:20:54,539
and all of this by the way is very this

00:20:52,259 --> 00:20:57,360
is all third party like research so a

00:20:54,539 --> 00:20:58,769
lot of these attacks happen the

00:20:57,360 --> 00:21:00,960
company's not going to talk about it but

00:20:58,769 --> 00:21:02,220
researchers they study in they look at

00:21:00,960 --> 00:21:04,259
what happened and that's how we kind of

00:21:02,220 --> 00:21:05,940
learn and so this this one especially

00:21:04,259 --> 00:21:08,220
since this one is actually pretty recent

00:21:05,940 --> 00:21:10,409
external analysis of the code was

00:21:08,220 --> 00:21:13,470
conducted and it was likely a stored

00:21:10,409 --> 00:21:15,299
cross-site scripting attack the

00:21:13,470 --> 00:21:17,399
malicious code had been appended to one

00:21:15,299 --> 00:21:18,899
of the Airlines JavaScript files and

00:21:17,399 --> 00:21:20,789
that contained an open source library

00:21:18,899 --> 00:21:24,690
used for their own distribution so if

00:21:20,789 --> 00:21:26,009
you can imagine they had a library for

00:21:24,690 --> 00:21:30,539
some reason they had uploaded it to

00:21:26,009 --> 00:21:31,679
their own CDN I don't know why there's a

00:21:30,539 --> 00:21:34,289
couple of reasons why you would do that

00:21:31,679 --> 00:21:37,500
but and so this someone had gained

00:21:34,289 --> 00:21:38,970
credentials to this other asset through

00:21:37,500 --> 00:21:40,559
their CDN and then they had appended to

00:21:38,970 --> 00:21:42,299
the javascript file so the other

00:21:40,559 --> 00:21:46,799
JavaScript was running and it went

00:21:42,299 --> 00:21:50,100
completely undetected so cross-site

00:21:46,799 --> 00:21:52,080
scripting just to go through it's number

00:21:50,100 --> 00:21:53,460
7 on the top vulnerabilities released by

00:21:52,080 --> 00:21:57,840
the open web application security

00:21:53,460 --> 00:22:00,990
project a wasp a wasp is an unbiased a

00:21:57,840 --> 00:22:03,179
kind of international non-for-profit

00:22:00,990 --> 00:22:04,919
organization that makes sure to create

00:22:03,179 --> 00:22:08,070
standards for web security across the

00:22:04,919 --> 00:22:10,230
internet and so they have a top 10 every

00:22:08,070 --> 00:22:12,269
year cross-site scripting is always on

00:22:10,230 --> 00:22:16,919
it because it affects something like two

00:22:12,269 --> 00:22:19,799
thirds of all browser applications which

00:22:16,919 --> 00:22:21,840
is not a small number and browsers don't

00:22:19,799 --> 00:22:22,230
have a secure default so it's up to the

00:22:21,840 --> 00:22:28,800
develop

00:22:22,230 --> 00:22:30,300
to create a safe experience so there's

00:22:28,800 --> 00:22:33,120
three types of cross-site scripting the

00:22:30,300 --> 00:22:35,580
type that we saw was a source towards

00:22:33,120 --> 00:22:37,410
cross-site scripting there were there

00:22:35,580 --> 00:22:39,300
was something from the company server

00:22:37,410 --> 00:22:40,740
that had been injected with code and

00:22:39,300 --> 00:22:43,050
then it had been returned to the client

00:22:40,740 --> 00:22:46,010
the client being the browser or the app

00:22:43,050 --> 00:22:49,050
and run and executed

00:22:46,010 --> 00:22:52,080
there's also reflective the best way to

00:22:49,050 --> 00:22:54,300
describe this is JavaScript that has not

00:22:52,080 --> 00:22:57,980
been injected into the source code but

00:22:54,300 --> 00:23:00,930
it has actually been executed from being

00:22:57,980 --> 00:23:04,520
kind of put into the browser by a third

00:23:00,930 --> 00:23:07,830
party so using a phishing email to

00:23:04,520 --> 00:23:09,930
append query params to a URL and then

00:23:07,830 --> 00:23:11,970
opening that into another company's

00:23:09,930 --> 00:23:14,220
website where they know that they can

00:23:11,970 --> 00:23:16,440
run JavaScript through an input field or

00:23:14,220 --> 00:23:18,570
whatever that would be an example of

00:23:16,440 --> 00:23:20,810
reflective and then there's Dom base and

00:23:18,570 --> 00:23:22,770
so this one is lesser-known but this is

00:23:20,810 --> 00:23:25,830
manipulation of the Dom not the

00:23:22,770 --> 00:23:28,080
reflective not through stormed and that

00:23:25,830 --> 00:23:30,270
will change the environment of the

00:23:28,080 --> 00:23:34,650
victim to do something that they don't

00:23:30,270 --> 00:23:36,060
want it to do so 380,000 users I

00:23:34,650 --> 00:23:38,280
shouldn't be laughing had their

00:23:36,060 --> 00:23:40,710
personality or personality personal and

00:23:38,280 --> 00:23:42,180
financial details stolen while booking

00:23:40,710 --> 00:23:44,340
and updating reservations during the

00:23:42,180 --> 00:23:46,350
span of 15 days so this one 15 days

00:23:44,340 --> 00:23:49,770
where people were just going online

00:23:46,350 --> 00:23:52,500
making reservations checking their I

00:23:49,770 --> 00:23:53,850
don't know their status or whatever 15

00:23:52,500 --> 00:23:56,310
days and all of their credit card

00:23:53,850 --> 00:23:59,790
information just swipe send to a random

00:23:56,310 --> 00:24:01,590
person and then that's it so why was a

00:23:59,790 --> 00:24:04,070
case of stored stolen data the integrity

00:24:01,590 --> 00:24:07,080
of the website had also been compromised

00:24:04,070 --> 00:24:10,530
so I wanted to highlight that as well

00:24:07,080 --> 00:24:12,390
because this was because the website had

00:24:10,530 --> 00:24:14,790
been tampered with and these are kind of

00:24:12,390 --> 00:24:19,410
assets of the company the integrity of

00:24:14,790 --> 00:24:24,180
this website had been had been exploited

00:24:19,410 --> 00:24:27,420
and so prevention of this this was a

00:24:24,180 --> 00:24:30,240
specific case first off because what had

00:24:27,420 --> 00:24:32,370
likely happened was there was I think I

00:24:30,240 --> 00:24:36,150
said this before was that somebody

00:24:32,370 --> 00:24:38,550
somehow got access to this their own CDN

00:24:36,150 --> 00:24:41,030
and so because it what where this code

00:24:38,550 --> 00:24:44,100
was coming from it was an authorized

00:24:41,030 --> 00:24:46,680
JavaScript file that had been loaded

00:24:44,100 --> 00:24:49,650
from the company CDN for whatever reason

00:24:46,680 --> 00:24:51,260
and then it had been executed but when I

00:24:49,650 --> 00:24:54,390
was looking at this I was thinking well

00:24:51,260 --> 00:24:55,950
even if they had done that shouldn't

00:24:54,390 --> 00:24:59,160
there have been some sort of policy

00:24:55,950 --> 00:25:01,710
where this origin website would not have

00:24:59,160 --> 00:25:03,630
been making calls to a third party

00:25:01,710 --> 00:25:06,540
because that's what cores so

00:25:03,630 --> 00:25:07,860
cross-origin resource sharing by default

00:25:06,540 --> 00:25:11,520
actually this is one of the better

00:25:07,860 --> 00:25:12,870
defaults of most browsers this policy

00:25:11,520 --> 00:25:14,790
should have helped and they shouldn't

00:25:12,870 --> 00:25:18,000
have been able to make the call so that

00:25:14,790 --> 00:25:21,690
tells me that the the company probably

00:25:18,000 --> 00:25:24,240
had some lacks cores policies which

00:25:21,690 --> 00:25:26,970
would have made it easy in the the the

00:25:24,240 --> 00:25:29,670
attacker probably saw that when they

00:25:26,970 --> 00:25:31,140
were making the call to when they were

00:25:29,670 --> 00:25:32,910
kind of like looking at the website and

00:25:31,140 --> 00:25:35,730
figuring out you know what's what their

00:25:32,910 --> 00:25:36,870
next victim would be I saw hey we can we

00:25:35,730 --> 00:25:40,650
can attack this because they have a

00:25:36,870 --> 00:25:42,300
pretty open course policy yeah so using

00:25:40,650 --> 00:25:43,590
a course policy with a trusted whitelist

00:25:42,300 --> 00:25:45,600
is probably would have helps on the

00:25:43,590 --> 00:25:47,940
client is adhering to the design

00:25:45,600 --> 00:25:50,700
principle of secure default so there's a

00:25:47,940 --> 00:25:52,050
set of design principles which I have no

00:25:50,700 --> 00:25:54,180
time to go into but if you want to talk

00:25:52,050 --> 00:25:55,860
about afterwards we can and so this

00:25:54,180 --> 00:25:58,530
would be what they have done is just

00:25:55,860 --> 00:26:00,560
kind of opened it up to everyone and

00:25:58,530 --> 00:26:05,790
this would have been a security vault

00:26:00,560 --> 00:26:07,950
and so this is what this looks like yeah

00:26:05,790 --> 00:26:10,200
if you're so if I'm a source you're or

00:26:07,950 --> 00:26:12,030
if I'm a source application and I load

00:26:10,200 --> 00:26:14,700
my website I want to make sure and I

00:26:12,030 --> 00:26:18,030
want to use a subdomain or I want to

00:26:14,700 --> 00:26:21,780
authorize another website maybe like a

00:26:18,030 --> 00:26:24,500
Google Analytics or something to be able

00:26:21,780 --> 00:26:27,720
to send HTTP requests or Ajax requests

00:26:24,500 --> 00:26:31,200
from my browser then you should do that

00:26:27,720 --> 00:26:34,260
through this so using this principle of

00:26:31,200 --> 00:26:36,030
safe default it's really important to

00:26:34,260 --> 00:26:39,450
understand what the browser and what the

00:26:36,030 --> 00:26:41,730
protocol this is comes from HTTP with

00:26:39,450 --> 00:26:43,680
this what you're really getting with

00:26:41,730 --> 00:26:45,990
these because you can actually go pretty

00:26:43,680 --> 00:26:48,660
far with securing your websites and

00:26:45,990 --> 00:26:50,220
having you know just being open to the

00:26:48,660 --> 00:26:53,340
Internet doesn't always serve

00:26:50,220 --> 00:26:55,169
your users best and so just keeping up

00:26:53,340 --> 00:26:56,789
with what the browsers are offering in

00:26:55,169 --> 00:26:58,380
terms of security is actually really

00:26:56,789 --> 00:27:06,140
important too because this is always

00:26:58,380 --> 00:27:09,330
changing and evolving so so yeah so

00:27:06,140 --> 00:27:11,549
really what I'm hoping you're taking

00:27:09,330 --> 00:27:15,000
away from this is that there are a lot

00:27:11,549 --> 00:27:15,720
of big hacks that happen most of them

00:27:15,000 --> 00:27:17,580
are pretty simple

00:27:15,720 --> 00:27:19,320
these aren't masterminds that these are

00:27:17,580 --> 00:27:21,140
happening to as long as you're aware of

00:27:19,320 --> 00:27:23,460
what's going on with your software

00:27:21,140 --> 00:27:25,470
easier said than done I know but there

00:27:23,460 --> 00:27:28,440
are little ways to do that the more that

00:27:25,470 --> 00:27:30,780
you make it harder to actually break

00:27:28,440 --> 00:27:33,929
into your software and put your users at

00:27:30,780 --> 00:27:36,409
risk and so using these failures as an

00:27:33,929 --> 00:27:39,659
opportunity to create better software is

00:27:36,409 --> 00:27:44,690
really what I'm hoping that you all will

00:27:39,659 --> 00:27:48,970
do and that's all I have thank you

00:27:44,690 --> 00:27:53,809
[Applause]

00:27:48,970 --> 00:27:53,809

YouTube URL: https://www.youtube.com/watch?v=vr1zF8A7Jfc


