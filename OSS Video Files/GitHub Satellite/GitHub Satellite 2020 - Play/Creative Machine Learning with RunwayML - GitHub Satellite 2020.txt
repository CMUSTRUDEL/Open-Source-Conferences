Title: Creative Machine Learning with RunwayML - GitHub Satellite 2020
Publication date: 2020-05-07
Playlist: GitHub Satellite 2020 - Play
Description: 
	Presented by Cristóbal Valenzuela Barrera, and Anastasis Germanidis

Explore and experiment with the creative possibilities of machine 
learning with this hands-on session exploring how to use and train your 
own models with RunwayML.

Cristóbal Valenzuela is a Chilean-born technologist and software 
developer. He is a co-founder of RunwayML. Previously, he was a 
researcher at New York University mainly working on the development of 
ml5.js.

Anastasis Germanidis is a software engineer and artist interested in 
generative media. He's currently co-founder and CTO at Runway, where 
he’s focusing on making machine learning accessible to designers, 
artists, and other creators. His artwork has been shown internationally 
across the US and Europe, including at Ars Electronica Festival, 
Festival de Cannes - Le Marché du Film, Megaron - The Athens Concert 
Hall, and the The Museum of Moving Image, and featured in The Telegraph,
 Die Zeit, WIRED, Fast Company, and Mashable, among other outlets.

GitHub Satellite: A community connected by code

On May 6th, we threw a free virtual event featuring developers working together on the world’s software, announcements from the GitHub team, and inspiring performances by artists who code.

More information: https://githubsatellite.com
Schedule: https://githubsatellite.com/schedule/
Captions: 
	00:00:04,070 --> 00:00:09,850
[Music]

00:00:10,790 --> 00:00:16,440
hi everyone I'm super excited to be here

00:00:13,679 --> 00:00:19,350
I'm Chris one of the cofounders of

00:00:16,440 --> 00:00:22,230
runway mail Anna sees the video as well

00:00:19,350 --> 00:00:25,170
I am honest essence also one of the

00:00:22,230 --> 00:00:26,760
cofounders of runway and today we're

00:00:25,170 --> 00:00:29,670
gonna show you some very cool stuff with

00:00:26,760 --> 00:00:31,859
runway now if you do no runway mail you

00:00:29,670 --> 00:00:34,020
can head down to run Rimmel become and

00:00:31,859 --> 00:00:36,360
done with this offer today we're gonna

00:00:34,020 --> 00:00:38,040
be playing with a lot of creative things

00:00:36,360 --> 00:00:40,829
you can do with mature learning Widow

00:00:38,040 --> 00:00:41,610
without curry Kogan experience and so to

00:00:40,829 --> 00:00:43,379
get things started

00:00:41,610 --> 00:00:45,329
if you don't have runway you can just go

00:00:43,379 --> 00:00:49,680
ahead and download runway from runway

00:00:45,329 --> 00:00:51,420
melt calm until Iran that down better so

00:00:49,680 --> 00:00:54,000
today we're gonna go over kind of like

00:00:51,420 --> 00:00:55,379
the overview of runway using some of the

00:00:54,000 --> 00:00:57,300
few models that we have in the platform

00:00:55,379 --> 00:00:59,789
and then we're actually gonna train our

00:00:57,300 --> 00:01:03,930
own custom models using using the

00:00:59,789 --> 00:01:06,030
platform so to get them started make

00:01:03,930 --> 00:01:07,590
sure to download runway and I'm gonna go

00:01:06,030 --> 00:01:09,240
ahead I already don't know it so I'm

00:01:07,590 --> 00:01:11,700
gonna go ahead and start this runway is

00:01:09,240 --> 00:01:15,030
the desktop application that runs on all

00:01:11,700 --> 00:01:17,100
platforms so you have Mac Linux it will

00:01:15,030 --> 00:01:18,509
be available for you and once you

00:01:17,100 --> 00:01:21,540
download once you create an account and

00:01:18,509 --> 00:01:22,920
sign in you'll see this I'm gonna I'm

00:01:21,540 --> 00:01:25,619
gonna explain what all these are on

00:01:22,920 --> 00:01:27,270
during the session but to get things

00:01:25,619 --> 00:01:31,470
started first I'll go into the model

00:01:27,270 --> 00:01:33,540
directory so so the model directory is

00:01:31,470 --> 00:01:35,939
basically a space for you to browse and

00:01:33,540 --> 00:01:37,680
discover a very peripheral interesting

00:01:35,939 --> 00:01:39,299
machine learning models that you can use

00:01:37,680 --> 00:01:43,470
for a variety of different purposes so

00:01:39,299 --> 00:01:46,200
we have 152 models right here and you

00:01:43,470 --> 00:01:48,659
can browse them over here there are for

00:01:46,200 --> 00:01:51,180
a lot of different use cases you can

00:01:48,659 --> 00:01:53,189
filter them by case the community for

00:01:51,180 --> 00:01:55,829
instance image synthesis motion capture

00:01:53,189 --> 00:01:58,560
text base models you can use recognition

00:01:55,829 --> 00:02:01,469
you can search by data types the way you

00:01:58,560 --> 00:02:04,140
fit data into the models or by the ones

00:02:01,469 --> 00:02:05,670
that are trending or most popular this

00:02:04,140 --> 00:02:07,469
is a very cool space if you want to just

00:02:05,670 --> 00:02:09,170
like discover what's possible if you're

00:02:07,469 --> 00:02:10,880
new to my to learning and you wanna like

00:02:09,170 --> 00:02:12,380
learn about of the range of

00:02:10,880 --> 00:02:15,680
possibilities of things you can do so

00:02:12,380 --> 00:02:17,989
will encourage everyone to check this if

00:02:15,680 --> 00:02:19,430
you want to like understand most of all

00:02:17,989 --> 00:02:20,989
things you can do with my to learning

00:02:19,430 --> 00:02:22,640
and if you're really familiar with the

00:02:20,989 --> 00:02:26,630
topic if you bring know what kind of

00:02:22,640 --> 00:02:28,550
like what you can do with ml this some

00:02:26,630 --> 00:02:31,340
of the models inside or inside here will

00:02:28,550 --> 00:02:33,370
be very familiar to you so today we're

00:02:31,340 --> 00:02:37,010
going to demo two models specifically

00:02:33,370 --> 00:02:39,130
we're gonna be demoing image generative

00:02:37,010 --> 00:02:42,530
model that allows you to create custom

00:02:39,130 --> 00:02:44,390
generative images and we're gonna be

00:02:42,530 --> 00:02:47,150
demoing text generation model that

00:02:44,390 --> 00:02:49,940
allows you to create custom tags and so

00:02:47,150 --> 00:02:52,010
it's gonna be super fun so let me show

00:02:49,940 --> 00:02:55,730
you one one of the models that I run a

00:02:52,010 --> 00:02:58,910
demo today this is a model I trained on

00:02:55,730 --> 00:03:01,370
runway so you can search here this is a

00:02:58,910 --> 00:03:02,870
model next click here you can see I'm

00:03:01,370 --> 00:03:04,519
learning more about the model itself you

00:03:02,870 --> 00:03:07,940
can learn about who made it in this case

00:03:04,519 --> 00:03:10,400
I did some tribution around kind of like

00:03:07,940 --> 00:03:13,700
model itself in kind that's kind of the

00:03:10,400 --> 00:03:15,799
architecture that's in use you can see a

00:03:13,700 --> 00:03:17,870
lot of other stuff the repo itself so

00:03:15,799 --> 00:03:21,109
every model has a corresponding github

00:03:17,870 --> 00:03:22,519
repo so just to kind of like demo how

00:03:21,109 --> 00:03:24,200
this works and you know you'll get a

00:03:22,519 --> 00:03:26,720
better sense once it's running I'm gonna

00:03:24,200 --> 00:03:29,320
add this to a new workspace so I'm gonna

00:03:26,720 --> 00:03:32,510
go by the default name really good name

00:03:29,320 --> 00:03:34,880
and now I mean runway stuff like

00:03:32,510 --> 00:03:37,850
workspace view and this is the main view

00:03:34,880 --> 00:03:40,579
of how you use this material models in

00:03:37,850 --> 00:03:43,070
runway and so the first thing I did was

00:03:40,579 --> 00:03:46,310
I went ahead and click start and what

00:03:43,070 --> 00:03:48,109
this does is basically starts career

00:03:46,310 --> 00:03:52,069
running the session or running the model

00:03:48,109 --> 00:03:55,160
for you to start using and now once the

00:03:52,069 --> 00:03:58,459
model is it's ready we're gonna go ahead

00:03:55,160 --> 00:04:00,980
and select vector and vector is the way

00:03:58,459 --> 00:04:02,959
you interact with the model as so as you

00:04:00,980 --> 00:04:05,540
know every single model has different

00:04:02,959 --> 00:04:07,370
ways of interacting with you with it and

00:04:05,540 --> 00:04:09,650
this is specifically one very particular

00:04:07,370 --> 00:04:11,420
one that we're super excited that's

00:04:09,650 --> 00:04:12,889
different from any other kind of like

00:04:11,420 --> 00:04:16,090
interface that I'll let honest s is

00:04:12,889 --> 00:04:18,910
explain how it works yeah

00:04:16,090 --> 00:04:21,609
so this model is called style gun and

00:04:18,910 --> 00:04:22,870
it's one of the most interesting image

00:04:21,609 --> 00:04:27,370
generation models that have come

00:04:22,870 --> 00:04:29,410
recently and how this specific interface

00:04:27,370 --> 00:04:31,630
works is the a system that we called

00:04:29,410 --> 00:04:34,740
Lake and Explorer and it allows you to

00:04:31,630 --> 00:04:37,389
explore the latent space of the model so

00:04:34,740 --> 00:04:39,910
well the model is being trained on tens

00:04:37,389 --> 00:04:42,340
of thousands of images it players to

00:04:39,910 --> 00:04:44,320
mount and different images in that

00:04:42,340 --> 00:04:48,700
original data set in a high dimensional

00:04:44,320 --> 00:04:51,970
space in this case and it is 512

00:04:48,700 --> 00:04:55,270
dimensions and this vector interface

00:04:51,970 --> 00:04:58,540
allows you to pick very specific points

00:04:55,270 --> 00:05:01,210
in the high dimensional space and as a

00:04:58,540 --> 00:05:06,160
way of sampling the possible outputs

00:05:01,210 --> 00:05:08,560
from the model and this this way you can

00:05:06,160 --> 00:05:10,690
generate an infinite range of images

00:05:08,560 --> 00:05:12,250
that exist between the images of the

00:05:10,690 --> 00:05:15,250
original data set in this case the

00:05:12,250 --> 00:05:16,810
develop students serve each tile in this

00:05:15,250 --> 00:05:18,910
vector grid corresponds to a different

00:05:16,810 --> 00:05:21,880
vector that we passed the models

00:05:18,910 --> 00:05:24,810
generate a different image and tiles

00:05:21,880 --> 00:05:28,360
that are close together correspond to

00:05:24,810 --> 00:05:29,950
vectors that are close together so that

00:05:28,360 --> 00:05:32,260
means that they generate outputs are

00:05:29,950 --> 00:05:34,780
similar to each other and do further

00:05:32,260 --> 00:05:37,840
build an intuition around this we can

00:05:34,780 --> 00:05:40,830
tweak the subject distance and something

00:05:37,840 --> 00:05:42,729
distance determines how close the points

00:05:40,830 --> 00:05:45,820
corresponding to each other to each

00:05:42,729 --> 00:05:52,960
other so if we pick a very low something

00:05:45,820 --> 00:05:54,430
distance like say if we say is 0.01 we

00:05:52,960 --> 00:05:56,310
will see that the output saturated by

00:05:54,430 --> 00:05:59,789
the model are very similar to each other

00:05:56,310 --> 00:06:08,380
but if we slightly increase that value

00:05:59,789 --> 00:06:11,380
we can get still similar but much more

00:06:08,380 --> 00:06:14,770
different include some before and this

00:06:11,380 --> 00:06:17,380
way we can associate li explorer i so i

00:06:14,770 --> 00:06:19,419
certainly explore the space of possible

00:06:17,380 --> 00:06:21,930
image from model we can start from an

00:06:19,419 --> 00:06:24,250
image that looks interesting and then

00:06:21,930 --> 00:06:26,530
find images that look similar to that

00:06:24,250 --> 00:06:31,289
originally mentioned associatively I

00:06:26,530 --> 00:06:31,289
arrive at the Altamonte myself

00:06:31,940 --> 00:06:36,330
thanks for that intro that was great

00:06:34,680 --> 00:06:38,790
until explaining how the late an expert

00:06:36,330 --> 00:06:41,400
that we haven't run works I would

00:06:38,790 --> 00:06:43,110
encourage everyone to to play with it

00:06:41,400 --> 00:06:44,640
explore it look just like zooming in and

00:06:43,110 --> 00:06:46,950
out and seeing the possible and rate of

00:06:44,640 --> 00:06:50,250
images again these are all generated

00:06:46,950 --> 00:06:51,780
image by the model that we train them

00:06:50,250 --> 00:06:54,960
they were actually gonna train a bit so

00:06:51,780 --> 00:06:57,890
you can see how they're works I'm gonna

00:06:54,960 --> 00:07:01,890
get stuck here I'm gonna go back to my

00:06:57,890 --> 00:07:05,040
bro's model sections over here and let's

00:07:01,890 --> 00:07:07,620
do let's show you guys another model and

00:07:05,040 --> 00:07:10,470
then we go into training other words so

00:07:07,620 --> 00:07:13,170
you can custom create your own models

00:07:10,470 --> 00:07:15,930
I'm gonna go ahead and show you guys

00:07:13,170 --> 00:07:17,460
this and so you're familiar to the

00:07:15,930 --> 00:07:20,040
mature learning world you'll probably

00:07:17,460 --> 00:07:22,110
have her about GPT - it's a model that

00:07:20,040 --> 00:07:24,570
you're opening I will is I think almost

00:07:22,110 --> 00:07:27,330
a year ago or so it's very good at

00:07:24,570 --> 00:07:29,940
creating text generating tax it's

00:07:27,330 --> 00:07:31,410
another language processing model and in

00:07:29,940 --> 00:07:34,620
this case what you can do in wrong ways

00:07:31,410 --> 00:07:36,930
you can retrain that GPT - model with a

00:07:34,620 --> 00:07:39,390
specific data set that you have and in

00:07:36,930 --> 00:07:41,610
this case we kind of like to get for a

00:07:39,390 --> 00:07:43,620
different spin and we use the g2 model

00:07:41,610 --> 00:07:45,900
but instead of training like normal text

00:07:43,620 --> 00:07:49,260
or English text we train it on

00:07:45,900 --> 00:07:50,580
JavaScript code and this is a really

00:07:49,260 --> 00:07:56,340
interesting data set that we actually

00:07:50,580 --> 00:07:59,100
took from github which is reco they gave

00:07:56,340 --> 00:08:00,360
here is also gonna do and I studies I

00:07:59,100 --> 00:08:02,760
think you have more more information

00:08:00,360 --> 00:08:05,900
about the co search net that was used to

00:08:02,760 --> 00:08:09,330
train this model ma'am yeah so this is a

00:08:05,900 --> 00:08:11,460
github released around a year ago and

00:08:09,330 --> 00:08:13,920
the purpose of the Vedas that originally

00:08:11,460 --> 00:08:16,500
is to help accelerate research in

00:08:13,920 --> 00:08:21,030
something called code retrieval which

00:08:16,500 --> 00:08:23,490
means being able to search the keywords

00:08:21,030 --> 00:08:25,800
or as a short sentence description for a

00:08:23,490 --> 00:08:28,200
piece of code and then retrieve the most

00:08:25,800 --> 00:08:31,380
relevant code snippets out of a large

00:08:28,200 --> 00:08:33,510
data set of codes but we're gonna do

00:08:31,380 --> 00:08:36,450
something different and kind of use this

00:08:33,510 --> 00:08:38,450
data set not for its intended original

00:08:36,450 --> 00:08:42,169
purpose

00:08:38,450 --> 00:08:44,690
just by taking all the code snippets

00:08:42,169 --> 00:08:46,250
from the data set and then training a

00:08:44,690 --> 00:08:48,890
text animation model on those code

00:08:46,250 --> 00:08:50,380
snippets in order to generate new code

00:08:48,890 --> 00:08:51,740
snippets that hopefully are

00:08:50,380 --> 00:08:55,130
syntactically

00:08:51,740 --> 00:08:57,110
Colet and synthetic incorrect so as you

00:08:55,130 --> 00:09:00,500
can see an example of that coming from

00:08:57,110 --> 00:09:04,450
the data set we will just take the code

00:09:00,500 --> 00:09:08,780
field from that JSON blob and then

00:09:04,450 --> 00:09:11,660
collect all the all those strings of

00:09:08,780 --> 00:09:16,070
code from Earth containing data set and

00:09:11,660 --> 00:09:18,950
then train 52 model on those codes cool

00:09:16,070 --> 00:09:20,990
so with that in mind I'm gonna go here

00:09:18,950 --> 00:09:22,940
I'm gonna show you how it works first

00:09:20,990 --> 00:09:24,170
and then I'm gonna go ahead and train

00:09:22,940 --> 00:09:27,470
these from scratch so you can follow

00:09:24,170 --> 00:09:29,630
along and try this on your own I'm gonna

00:09:27,470 --> 00:09:30,890
first write so you can see how we can

00:09:29,630 --> 00:09:32,510
play with this model once it's trained

00:09:30,890 --> 00:09:34,640
so you see here you get the idea we're

00:09:32,510 --> 00:09:36,310
like piling up or grouping up models

00:09:34,640 --> 00:09:38,840
this is the one way we're using before

00:09:36,310 --> 00:09:42,050
I'm gonna click run here and now I'm

00:09:38,840 --> 00:09:44,840
running my train GPT to model on the

00:09:42,050 --> 00:09:47,570
JavaScript source stack that as

00:09:44,840 --> 00:09:49,430
described in the in the case new form

00:09:47,570 --> 00:09:51,890
where we had this vector interface to

00:09:49,430 --> 00:09:54,170
explore the lady in space of generated

00:09:51,890 --> 00:09:56,930
images or the latest face of the model

00:09:54,170 --> 00:09:58,790
itself with the JavaScript on the tax

00:09:56,930 --> 00:10:00,230
base model we're gonna have a different

00:09:58,790 --> 00:10:01,700
interface and this is very cool for

00:10:00,230 --> 00:10:03,260
runway because every model has a

00:10:01,700 --> 00:10:04,610
different set of parameters in the

00:10:03,260 --> 00:10:07,160
different ways different ways of using

00:10:04,610 --> 00:10:08,750
those and as as you know in the model

00:10:07,160 --> 00:10:11,690
directory there are models for a variety

00:10:08,750 --> 00:10:13,820
of different things and use cases you

00:10:11,690 --> 00:10:16,640
can find models for object detection

00:10:13,820 --> 00:10:19,790
will like we'll use images to kind of

00:10:16,640 --> 00:10:21,710
like detect objects in the scenes there

00:10:19,790 --> 00:10:23,690
are models really the ones very popular

00:10:21,710 --> 00:10:27,140
like to style transfer images the taste

00:10:23,690 --> 00:10:28,610
I'd also use images and in runway every

00:10:27,140 --> 00:10:30,740
single model has a different interface

00:10:28,610 --> 00:10:33,350
or a custom interface to explore how to

00:10:30,740 --> 00:10:34,730
use it and that's that's very very

00:10:33,350 --> 00:10:37,070
interesting because it kind of like

00:10:34,730 --> 00:10:38,750
abstracts you from the complexities and

00:10:37,070 --> 00:10:41,120
allows you to focused on using the

00:10:38,750 --> 00:10:43,370
models um so in this case as a message

00:10:41,120 --> 00:10:46,130
was saying this was trained on a corpus

00:10:43,370 --> 00:10:48,440
of JavaScript code and I have the model

00:10:46,130 --> 00:10:51,930
running over here I'm gonna type some

00:10:48,440 --> 00:10:54,990
JavaScript let's see it's these words

00:10:51,930 --> 00:10:56,520
and so what you're seeing over here of

00:10:54,990 --> 00:11:00,420
the bottom is the model can play

00:10:56,520 --> 00:11:02,310
completing the the sentence of what I'm

00:11:00,420 --> 00:11:03,960
what I'm reading and it's in this case

00:11:02,310 --> 00:11:06,900
completing a sentence based on a

00:11:03,960 --> 00:11:08,339
JavaScript code let's see if it come up

00:11:06,900 --> 00:11:11,370
with yeah it's coming up with

00:11:08,339 --> 00:11:16,580
interesting interesting combinations of

00:11:11,370 --> 00:11:19,560
followers or that let me see if it works

00:11:16,580 --> 00:11:22,110
it probably will keep the semantics yep

00:11:19,560 --> 00:11:23,580
so we're talking like a function

00:11:22,110 --> 00:11:26,160
anything you want address that seems

00:11:23,580 --> 00:11:28,529
your should we go into training we can

00:11:26,160 --> 00:11:32,370
try adding a large number of characters

00:11:28,529 --> 00:11:35,310
justice here longer code snippets so

00:11:32,370 --> 00:11:38,040
here I'm gonna just these lighter to the

00:11:35,310 --> 00:11:39,810
right and this basically means how many

00:11:38,040 --> 00:11:41,610
characters do I want so every perk 3 in

00:11:39,810 --> 00:11:44,400
this case will be one single elements um

00:11:41,610 --> 00:11:49,830
yeah no I think it's running note yeah

00:11:44,400 --> 00:11:53,520
or no that's the nose you can say it's

00:11:49,830 --> 00:11:56,670
not fully functional code you probably

00:11:53,520 --> 00:11:58,529
wouldn't even be able to interpret that

00:11:56,670 --> 00:12:02,029
code but it still has captured some of

00:11:58,529 --> 00:12:06,510
the syntactic the aspects of JavaScript

00:12:02,029 --> 00:12:09,089
yeah this is one thing one thing I will

00:12:06,510 --> 00:12:11,970
mention eventually or gonna mention it

00:12:09,089 --> 00:12:14,160
now at some point is this you can

00:12:11,970 --> 00:12:15,959
interact with models through runway

00:12:14,160 --> 00:12:17,870
through this visual interface or this do

00:12:15,959 --> 00:12:21,029
we we don't need into kind of like

00:12:17,870 --> 00:12:24,120
program or access anything but you can

00:12:21,029 --> 00:12:26,550
also have a programmatic API so you can

00:12:24,120 --> 00:12:28,680
deploy this model through runway and

00:12:26,550 --> 00:12:30,959
manage it through through a remote

00:12:28,680 --> 00:12:33,480
endpoints you can string data in and out

00:12:30,959 --> 00:12:34,920
of runway this allows you to create very

00:12:33,480 --> 00:12:36,120
interesting or complete creative

00:12:34,920 --> 00:12:38,880
applications of Blatz

00:12:36,120 --> 00:12:40,830
slugbots or I don't know the Twitter box

00:12:38,880 --> 00:12:42,300
or maybe you can like send the string

00:12:40,830 --> 00:12:44,820
and the body will reply with something

00:12:42,300 --> 00:12:46,500
and this is for every single model main

00:12:44,820 --> 00:12:48,959
runway every single modern runway allows

00:12:46,500 --> 00:12:51,990
you to host it in a network and use it

00:12:48,959 --> 00:12:54,390
through an API am so that's that's very

00:12:51,990 --> 00:12:57,209
cool I'm gonna show that if we have time

00:12:54,390 --> 00:12:58,950
for that I'm gonna go ahead now and stop

00:12:57,209 --> 00:13:00,600
this gp2 model and I'm gonna actually

00:12:58,950 --> 00:13:03,300
show you how to train these two models

00:13:00,600 --> 00:13:05,750
in runway and so in assesses let's start

00:13:03,300 --> 00:13:05,750
first with

00:13:05,820 --> 00:13:16,540
yeah I'm gonna go ahead go ahead

00:13:13,710 --> 00:13:20,320
okay let's go let's go ahead and click

00:13:16,540 --> 00:13:21,730
on training you on the image photo let's

00:13:20,320 --> 00:13:24,100
use the default name I'm just gonna go

00:13:21,730 --> 00:13:28,180
training experiment number 4 I'm gonna

00:13:24,100 --> 00:13:30,430
click create and here we could see a

00:13:28,180 --> 00:13:33,730
variety of datasets that we've already

00:13:30,430 --> 00:13:35,760
uploaded in the past so the idea is that

00:13:33,730 --> 00:13:38,710
we can provide some guidelines of how

00:13:35,760 --> 00:13:41,260
large the data should be should be at

00:13:38,710 --> 00:13:43,630
least a few hundred images otherwise the

00:13:41,260 --> 00:13:46,260
model will not have enough data to work

00:13:43,630 --> 00:13:49,570
with we have the preprocessdataset

00:13:46,260 --> 00:13:53,650
functionality that it basically allows

00:13:49,570 --> 00:13:56,410
you to crop the images in your data set

00:13:53,650 --> 00:13:57,850
to to align them together so that the

00:13:56,410 --> 00:14:01,090
stock and we have to deal with mass

00:13:57,850 --> 00:14:04,510
variety and in the data solidity strain

00:14:01,090 --> 00:14:10,330
with stock and the outputs of Soglin

00:14:04,510 --> 00:14:12,340
tend to be tend to have a lot to do with

00:14:10,330 --> 00:14:14,950
how consistent the data said the

00:14:12,340 --> 00:14:16,780
original dataset is so we use this

00:14:14,950 --> 00:14:19,450
pre-processing to make every machine

00:14:16,780 --> 00:14:23,230
address it consistent enough that duggan

00:14:19,450 --> 00:14:24,640
will learn the right features from it we

00:14:23,230 --> 00:14:25,990
also have this very cool auto crop

00:14:24,640 --> 00:14:29,260
function under no necessity when i

00:14:25,990 --> 00:14:31,980
mention what's going on here yes oh oh

00:14:29,260 --> 00:14:35,340
the crop will try to find the ideal

00:14:31,980 --> 00:14:38,200
bounding box on which to crop the image

00:14:35,340 --> 00:14:40,870
in order to make all the image that I

00:14:38,200 --> 00:14:43,030
said consistent in terms of dimensions

00:14:40,870 --> 00:14:45,580
that know but also in terms of where the

00:14:43,030 --> 00:14:47,620
subject is placed in the image exactly

00:14:45,580 --> 00:14:49,120
and this is this is basically saving you

00:14:47,620 --> 00:14:50,140
a lot of time if you have a large data

00:14:49,120 --> 00:14:53,260
set you need to kind of like

00:14:50,140 --> 00:14:55,450
preprocessor select specific regions of

00:14:53,260 --> 00:14:56,770
interest for you to train a model you

00:14:55,450 --> 00:14:58,930
can use the alter curve function to

00:14:56,770 --> 00:15:02,920
basically do that process automatically

00:14:58,930 --> 00:15:04,960
for you so I'm gonna go ahead and choose

00:15:02,920 --> 00:15:06,760
the since we're gonna recreate the

00:15:04,960 --> 00:15:08,500
sneakers models that we trained to

00:15:06,760 --> 00:15:10,390
generate new imager so I'm gonna go

00:15:08,500 --> 00:15:13,240
ahead and select as an assessment Stein

00:15:10,390 --> 00:15:14,440
the dataset I had here with shoes and

00:15:13,240 --> 00:15:15,790
these are by the way these are real

00:15:14,440 --> 00:15:16,750
shoes

00:15:15,790 --> 00:15:19,180
and what we're gonna do is we're gonna

00:15:16,750 --> 00:15:22,420
train the model the model learn patterns

00:15:19,180 --> 00:15:25,840
throw those images and then we can use

00:15:22,420 --> 00:15:29,050
that that model to create new images so

00:15:25,840 --> 00:15:32,380
I'm gonna go here and click Next what do

00:15:29,050 --> 00:15:34,270
we have here so first we have to pick

00:15:32,380 --> 00:15:37,990
the architecture of the model and

00:15:34,270 --> 00:15:40,180
there's been two iterations of salgan

00:15:37,990 --> 00:15:42,190
released so slogan is a model that was

00:15:40,180 --> 00:15:45,430
released by nvidia a few years ago and

00:15:42,190 --> 00:15:48,220
then like late last year they released a

00:15:45,430 --> 00:15:52,720
follow-up model that's similar in its

00:15:48,220 --> 00:15:55,390
architecture called star gantu so we can

00:15:52,720 --> 00:15:56,590
pick here stallion - as the results are

00:15:55,390 --> 00:15:58,960
slightly better and there's more variety

00:15:56,590 --> 00:16:02,410
in the generate output and then we have

00:15:58,960 --> 00:16:04,570
to pick a pre trained model the way

00:16:02,410 --> 00:16:07,270
training works in runway is that we

00:16:04,570 --> 00:16:09,130
don't train models from scratch we start

00:16:07,270 --> 00:16:11,530
from models have been trained over a

00:16:09,130 --> 00:16:13,510
really large data set for a long period

00:16:11,530 --> 00:16:16,420
of time and then we fine-tune those

00:16:13,510 --> 00:16:18,220
models on our own scholar data sets and

00:16:16,420 --> 00:16:21,490
the reason we do that is it it's much

00:16:18,220 --> 00:16:23,170
faster and it's much less expensive and

00:16:21,490 --> 00:16:26,260
it allows you to get really good results

00:16:23,170 --> 00:16:28,540
with a small number of images and

00:16:26,260 --> 00:16:30,250
without having to wait for days to see

00:16:28,540 --> 00:16:33,940
themselves and this allows you to

00:16:30,250 --> 00:16:36,400
iterate quicker and try to different

00:16:33,940 --> 00:16:39,940
experiments more experience that you

00:16:36,400 --> 00:16:43,630
otherwise perform and then once we've

00:16:39,940 --> 00:16:47,520
picked our free training model we will

00:16:43,630 --> 00:16:51,730
have to be the square of options so

00:16:47,520 --> 00:16:54,700
style gun works with square images and

00:16:51,730 --> 00:16:56,860
if if they image each one image analyst

00:16:54,700 --> 00:16:58,450
is not already square then we kind of

00:16:56,860 --> 00:17:00,640
pick the method by which we want to crop

00:16:58,450 --> 00:17:03,610
the image Center pro makes it just takes

00:17:00,640 --> 00:17:06,430
a crop of the center of English random

00:17:03,610 --> 00:17:09,400
krob means it just takes a random part

00:17:06,430 --> 00:17:13,840
of the image and at the end we training

00:17:09,400 --> 00:17:16,450
steps so this determines how long we

00:17:13,840 --> 00:17:18,700
will perform training for so I leave

00:17:16,450 --> 00:17:22,750
said in the training the model slightly

00:17:18,700 --> 00:17:24,860
becomes better at understanding space of

00:17:22,750 --> 00:17:28,259
images that straight up

00:17:24,860 --> 00:17:31,230
specifically in this case Salman is

00:17:28,259 --> 00:17:33,480
what's called genitive adversarial

00:17:31,230 --> 00:17:35,279
Network and this means that we're

00:17:33,480 --> 00:17:40,409
training two models with training a

00:17:35,279 --> 00:17:42,360
generator in the screen never and we and

00:17:40,409 --> 00:17:45,120
during the course of training the

00:17:42,360 --> 00:17:47,009
generator tries to create fake images

00:17:45,120 --> 00:17:50,179
that look like damaged in the dataset

00:17:47,009 --> 00:17:52,259
well the discriminator tries to

00:17:50,179 --> 00:17:54,690
distinguish between images that are

00:17:52,259 --> 00:17:56,820
created by the generator and images that

00:17:54,690 --> 00:18:00,269
are in the original dataset and through

00:17:56,820 --> 00:18:02,940
this iterative game both the generator

00:18:00,269 --> 00:18:04,200
becomes better at generating images that

00:18:02,940 --> 00:18:06,539
look more and more like the original

00:18:04,200 --> 00:18:08,850
image of the dataset and a discriminator

00:18:06,539 --> 00:18:10,519
becomes better at telling apart which he

00:18:08,850 --> 00:18:13,080
must have faked and which were out

00:18:10,519 --> 00:18:16,230
indeed we finally only use the generator

00:18:13,080 --> 00:18:18,210
but this process allows us this process

00:18:16,230 --> 00:18:20,100
odd result training has created some of

00:18:18,210 --> 00:18:25,610
the most impressive results in recent

00:18:20,100 --> 00:18:28,400
years in generating images text or audio

00:18:25,610 --> 00:18:29,840
awesome thank you for that intro so now

00:18:28,400 --> 00:18:35,510
with that in mind I'm gonna go ahead and

00:18:29,840 --> 00:18:38,780
click start training cool and now we are

00:18:35,510 --> 00:18:41,000
basically training our own gun our own

00:18:38,780 --> 00:18:43,160
stall gun model that we'll be able to

00:18:41,000 --> 00:18:44,660
generate new images based on our data

00:18:43,160 --> 00:18:47,360
set and the patterns that it finds in

00:18:44,660 --> 00:18:48,920
the data set so as an assassin was

00:18:47,360 --> 00:18:51,530
mentioning this might actually take some

00:18:48,920 --> 00:18:53,390
hours I think for 3,000 steps it takes

00:18:51,530 --> 00:18:57,530
like 2 hours to process or comes like

00:18:53,390 --> 00:19:01,490
train so since this is a cooking show we

00:18:57,530 --> 00:19:04,310
already have the bake ready so I'm gonna

00:19:01,490 --> 00:19:07,010
go ahead and show you how this looks

00:19:04,310 --> 00:19:10,070
after has been trained I'm gonna have

00:19:07,010 --> 00:19:14,000
some fun exploring how it works so this

00:19:10,070 --> 00:19:16,460
is model that we trained but after he

00:19:14,000 --> 00:19:19,400
has it's finished the process so you see

00:19:16,460 --> 00:19:21,110
here we have 3000 steps completed this

00:19:19,400 --> 00:19:23,540
is the fit score which is an indicator

00:19:21,110 --> 00:19:24,560
of how well the model perform unless I

00:19:23,540 --> 00:19:31,760
said I maybe want to mention anything

00:19:24,560 --> 00:19:34,280
here close the image attach a magnifier

00:19:31,760 --> 00:19:36,950
a new model art to the original images

00:19:34,280 --> 00:19:39,290
and the lower this course gets that

00:19:36,950 --> 00:19:41,690
means that the images are essentially

00:19:39,290 --> 00:19:43,820
closer to the original image to the data

00:19:41,690 --> 00:19:45,920
set and that means that our model has

00:19:43,820 --> 00:19:48,650
done a better job of creating accurate

00:19:45,920 --> 00:19:49,850
images so when you're training it's

00:19:48,650 --> 00:19:52,400
always important to look at this number

00:19:49,850 --> 00:19:55,100
to see how good your model is being is

00:19:52,400 --> 00:19:56,360
performing on your data set and one very

00:19:55,100 --> 00:19:58,190
cool thing that you can do REME is you

00:19:56,360 --> 00:20:00,200
can monitor the progress of how the

00:19:58,190 --> 00:20:01,670
model is actually going through the face

00:20:00,200 --> 00:20:03,710
of training and going through the

00:20:01,670 --> 00:20:06,110
samples of your idea to understand

00:20:03,710 --> 00:20:08,120
what's in it and what you can see here

00:20:06,110 --> 00:20:09,440
is that remember we started before our

00:20:08,120 --> 00:20:10,880
actually trained intern that were

00:20:09,440 --> 00:20:12,950
running here we started with a

00:20:10,880 --> 00:20:15,010
checkpoint of faces because an Assessor

00:20:12,950 --> 00:20:18,350
was saying that was just easier and more

00:20:15,010 --> 00:20:20,420
kind of like faster to train in this

00:20:18,350 --> 00:20:22,670
case I started this model instead of

00:20:20,420 --> 00:20:25,220
faces with a checkpoint of cars and

00:20:22,670 --> 00:20:27,730
these are generated cards so what you

00:20:25,220 --> 00:20:30,500
see here is the progression of the model

00:20:27,730 --> 00:20:32,240
translating from cars into sneakers

00:20:30,500 --> 00:20:33,530
which is which is I I always find really

00:20:32,240 --> 00:20:36,250
really compelling I'm interesting to

00:20:33,530 --> 00:20:38,169
export have the visual exploration of

00:20:36,250 --> 00:20:39,539
transferring from one

00:20:38,169 --> 00:20:42,249
so much into another so you can like

00:20:39,539 --> 00:20:45,070
look at one and see how that car turns

00:20:42,249 --> 00:20:48,070
into issue which is which is always

00:20:45,070 --> 00:20:50,619
wrinkled to say and you get did you get

00:20:48,070 --> 00:20:52,480
this at every single step in runway and

00:20:50,619 --> 00:20:55,090
by the way when you finish the training

00:20:52,480 --> 00:20:57,759
session you always also get something

00:20:55,090 --> 00:21:00,429
video or later space video - does you

00:20:57,759 --> 00:21:03,789
want explain what's going on here yeah

00:21:00,429 --> 00:21:07,330
so this is a what's in the interpolation

00:21:03,789 --> 00:21:11,769
and the idea is that we as we explained

00:21:07,330 --> 00:21:13,749
before stager uses a random vector to

00:21:11,769 --> 00:21:15,549
generate outputs so what we do is we

00:21:13,749 --> 00:21:18,549
start with from from a random vector

00:21:15,549 --> 00:21:20,649
then we slowly tweak it just to get like

00:21:18,549 --> 00:21:24,070
consecutive frames are of letter of

00:21:20,649 --> 00:21:25,539
similar images starting from one vector

00:21:24,070 --> 00:21:27,570
to another vector and then we explore

00:21:25,539 --> 00:21:30,489
the entire space between those vectors

00:21:27,570 --> 00:21:35,889
and this leads to a very interesting

00:21:30,489 --> 00:21:38,529
exploration of all the of all the images

00:21:35,889 --> 00:21:41,409
the possibilities are between two images

00:21:38,529 --> 00:21:44,289
so we can start from two existences for

00:21:41,409 --> 00:21:48,039
example and then see the entire space of

00:21:44,289 --> 00:21:50,289
possibilities between those two scenes

00:21:48,039 --> 00:21:51,879
and this is always I always like to look

00:21:50,289 --> 00:21:54,789
at this when training I feel like it

00:21:51,879 --> 00:21:56,169
percents how well your model data it's

00:21:54,789 --> 00:21:58,509
really cool to see those animated

00:21:56,169 --> 00:22:01,179
transitions so you can say that model

00:21:58,509 --> 00:22:04,299
expert with it and you can also view the

00:22:01,179 --> 00:22:07,659
model and use it so as we started the

00:22:04,299 --> 00:22:09,519
session I show you all how to use this

00:22:07,659 --> 00:22:10,899
model so this is actually the model who

00:22:09,519 --> 00:22:12,970
trained on the model we just before to

00:22:10,899 --> 00:22:16,600
generate these sneakers that you saw

00:22:12,970 --> 00:22:18,009
over here okay we have like around 8

00:22:16,600 --> 00:22:19,659
more minutes so I'm gonna go ahead and

00:22:18,009 --> 00:22:21,849
show you guys how to train the

00:22:19,659 --> 00:22:25,239
JavaScript generator that we showed you

00:22:21,849 --> 00:22:28,239
before this one again from scratch let's

00:22:25,239 --> 00:22:30,299
go create new and in this case I'm going

00:22:28,239 --> 00:22:32,590
to click here train a new text model

00:22:30,299 --> 00:22:36,970
let's go by the defaults you can always

00:22:32,590 --> 00:22:39,099
change the name I never do so now in

00:22:36,970 --> 00:22:41,039
this case we have represented with a

00:22:39,099 --> 00:22:44,169
different set of options for data sets

00:22:41,039 --> 00:22:45,909
remember before we had only images in

00:22:44,169 --> 00:22:48,669
this case your training at space model

00:22:45,909 --> 00:22:51,220
or an NLP based model so we're not gonna

00:22:48,669 --> 00:22:53,499
see this thing that's that we saw over

00:22:51,220 --> 00:22:56,799
here when we're training this because

00:22:53,499 --> 00:23:00,429
these data sets are not gonna be able to

00:22:56,799 --> 00:23:03,840
fit into the model for tax so I'm gonna

00:23:00,429 --> 00:23:06,070
go ahead and use the JavaScript code

00:23:03,840 --> 00:23:08,049
school search that we talked about

00:23:06,070 --> 00:23:11,019
before you can see here a bunch of

00:23:08,049 --> 00:23:13,059
samples so this is real JavaScript this

00:23:11,019 --> 00:23:16,090
is the source text the models using to

00:23:13,059 --> 00:23:17,559
to Train I'm gonna go ahead and in the

00:23:16,090 --> 00:23:18,999
same manner that we did with stalkin

00:23:17,559 --> 00:23:21,369
before I'm gonna go ahead and click Next

00:23:18,999 --> 00:23:22,840
I know this is different now when Isis

00:23:21,369 --> 00:23:25,299
is we see a bunch of different new

00:23:22,840 --> 00:23:27,099
options over here we have a prompt

00:23:25,299 --> 00:23:29,080
selection and an initial pre-trained

00:23:27,099 --> 00:23:33,159
model should we explain what this is

00:23:29,080 --> 00:23:36,099
doing yeah so in a similar manner with

00:23:33,159 --> 00:23:38,499
how we started training we also using

00:23:36,099 --> 00:23:40,929
transfer learning in this case and

00:23:38,499 --> 00:23:42,429
transfer learning again means starting

00:23:40,929 --> 00:23:44,649
from a model has been trained on the

00:23:42,429 --> 00:23:47,080
really large corpus data and then

00:23:44,649 --> 00:23:50,289
fine-tuning it in our as much smaller

00:23:47,080 --> 00:23:53,200
hope that we provide specifically in

00:23:50,289 --> 00:23:55,929
this case original 52 more model was

00:23:53,200 --> 00:23:59,039
trained on 8 million different webpages

00:23:55,929 --> 00:24:01,299
across a script from across the web and

00:23:59,039 --> 00:24:04,360
that's too many

00:24:01,299 --> 00:24:06,070
to complete and it cost some something

00:24:04,360 --> 00:24:10,659
on the order of tens of thousands of

00:24:06,070 --> 00:24:12,730
dollars so by doing transfer learning

00:24:10,659 --> 00:24:16,480
and by fine-tuning the data set we can

00:24:12,730 --> 00:24:17,710
get really good results by basically

00:24:16,480 --> 00:24:20,169
taking advantage of all the knowledge

00:24:17,710 --> 00:24:22,269
that cheaply because Freddie learned in

00:24:20,169 --> 00:24:24,970
those August having trained over a long

00:24:22,269 --> 00:24:27,460
period of time specifically here there

00:24:24,970 --> 00:24:28,840
is a few different models and the main

00:24:27,460 --> 00:24:31,690
difference of them is that the number of

00:24:28,840 --> 00:24:35,139
parameters that they have and generally

00:24:31,690 --> 00:24:37,840
speaking and smaller the model master it

00:24:35,139 --> 00:24:41,230
is to train like each steps instead

00:24:37,840 --> 00:24:44,080
takes less time but the more parameters

00:24:41,230 --> 00:24:46,200
the model has then the more the better

00:24:44,080 --> 00:24:48,700
it becomes with an understanding and

00:24:46,200 --> 00:24:51,309
presenting the rich data set and the

00:24:48,700 --> 00:24:53,619
better the results tend to be so in this

00:24:51,309 --> 00:24:55,330
case we can just pick a medium because

00:24:53,619 --> 00:25:00,779
we're interested in getting the best

00:24:55,330 --> 00:25:05,350
possible results what should we use fail

00:25:00,779 --> 00:25:15,039
we can do something like cones bars

00:25:05,350 --> 00:25:16,299
equals together with the pretty model

00:25:15,039 --> 00:25:17,769
this is also going to be used for the

00:25:16,299 --> 00:25:19,749
model in the training session now this

00:25:17,769 --> 00:25:25,090
is the model will start using this to

00:25:19,749 --> 00:25:27,519
sample or every step right yeah so these

00:25:25,090 --> 00:25:29,200
prompt text people use as a way for us

00:25:27,519 --> 00:25:32,470
to understand how the model is getting

00:25:29,200 --> 00:25:34,629
better we'll just give you the same

00:25:32,470 --> 00:25:37,149
prompt at different steps and see how it

00:25:34,629 --> 00:25:38,859
becomes better at completing that prompt

00:25:37,149 --> 00:25:40,720
so we're gonna pass that same initial

00:25:38,859 --> 00:25:43,419
prompt to the model at different steps

00:25:40,720 --> 00:25:45,519
and then be able to look over time how

00:25:43,419 --> 00:25:48,609
it's becoming better at generating Texas

00:25:45,519 --> 00:25:50,739
closer to the result is exactly coupe so

00:25:48,609 --> 00:25:53,830
with that in mind I'm gonna just go

00:25:50,739 --> 00:25:56,289
ahead and click start training and now

00:25:53,830 --> 00:25:59,830
we are training our own gptt model train

00:25:56,289 --> 00:26:03,249
our own JavaScript data set that we took

00:25:59,830 --> 00:26:05,320
actually from over here again if you're

00:26:03,249 --> 00:26:08,230
just joining this we are showing how to

00:26:05,320 --> 00:26:11,289
train your own gbt to model or text

00:26:08,230 --> 00:26:13,419
generation models to runway using the

00:26:11,289 --> 00:26:14,800
training model interface that we have

00:26:13,419 --> 00:26:16,750
right here which

00:26:14,800 --> 00:26:21,340
allows you to do all kind of interesting

00:26:16,750 --> 00:26:23,620
stuff with or without coding so again we

00:26:21,340 --> 00:26:25,210
are showing you this and it might take

00:26:23,620 --> 00:26:27,670
some time I think for this it might take

00:26:25,210 --> 00:26:31,180
like an hour so two hours you need we

00:26:27,670 --> 00:26:32,980
only gave it like a thousand steps but

00:26:31,180 --> 00:26:35,050
you can always kind of like monitor this

00:26:32,980 --> 00:26:36,700
also you can just close run me and come

00:26:35,050 --> 00:26:38,920
back to it later and you get an email

00:26:36,700 --> 00:26:42,100
once the model is ready and you can just

00:26:38,920 --> 00:26:44,710
use it and I'm gonna go here I'm gonna

00:26:42,100 --> 00:26:47,350
go to you I'm gonna show you the final

00:26:44,710 --> 00:26:50,230
result so again this is the model we

00:26:47,350 --> 00:26:53,910
trained you can go here perform with

00:26:50,230 --> 00:26:56,620
well now is in perplexity score yeah

00:26:53,910 --> 00:26:59,140
this is an indicator of how well the

00:26:56,620 --> 00:27:00,850
model did over the training session and

00:26:59,140 --> 00:27:02,350
you can see here it's this is the the

00:27:00,850 --> 00:27:04,570
prom that we gave it at the very

00:27:02,350 --> 00:27:09,760
beginning from Kapoor's this is a text

00:27:04,570 --> 00:27:12,220
from shows and this is the result of the

00:27:09,760 --> 00:27:14,200
journey model I mean actually this is

00:27:12,220 --> 00:27:17,140
nice I added like comments inline

00:27:14,200 --> 00:27:18,850
comments to the model I mean it kind of

00:27:17,140 --> 00:27:22,270
like matches some of the actions

00:27:18,850 --> 00:27:24,430
functions so that's that's interesting

00:27:22,270 --> 00:27:27,430
to see some of the semantics of the

00:27:24,430 --> 00:27:29,890
model understands the data it's very

00:27:27,430 --> 00:27:32,200
interesting that it manages if it

00:27:29,890 --> 00:27:34,630
generates a function then it can use the

00:27:32,200 --> 00:27:37,180
arguments that providing the function so

00:27:34,630 --> 00:27:41,830
it has some like longer term memory in

00:27:37,180 --> 00:27:43,900
the way it's generating so once the

00:27:41,830 --> 00:27:46,120
release train we can go ahead and just

00:27:43,900 --> 00:27:49,810
like we did before with stun gun view my

00:27:46,120 --> 00:27:52,510
model and to recap the modeled and as I

00:27:49,810 --> 00:27:53,920
showed before we can use this model in

00:27:52,510 --> 00:27:55,840
the workspace which is the one we have

00:27:53,920 --> 00:27:57,730
over here and now we can start playing

00:27:55,840 --> 00:28:02,020
with a generating text or any kind of

00:27:57,730 --> 00:28:04,390
like whatever we turn it on we have two

00:28:02,020 --> 00:28:06,940
more minutes left and before we go I

00:28:04,390 --> 00:28:08,620
want to show you guys another very cool

00:28:06,940 --> 00:28:12,040
feature that we recent really amazing

00:28:08,620 --> 00:28:13,660
runway which is which is like this

00:28:12,040 --> 00:28:15,100
allows you to interact with runway

00:28:13,660 --> 00:28:17,740
through all the models that we have in

00:28:15,100 --> 00:28:20,530
the platform through a GUI but as I

00:28:17,740 --> 00:28:23,710
mentioned early on you also have this so

00:28:20,530 --> 00:28:25,350
let's say we train the GPT to JavaScript

00:28:23,710 --> 00:28:30,059
models and now we have our

00:28:25,350 --> 00:28:32,520
custom modeled - Jared code I'm gonna

00:28:30,059 --> 00:28:34,770
keep here close this model and this is

00:28:32,520 --> 00:28:36,120
super interesting what's what this is

00:28:34,770 --> 00:28:38,640
doing it's basically allowing you to

00:28:36,120 --> 00:28:40,440
host this model through a remote

00:28:38,640 --> 00:28:41,490
endpoints you can see here I can choose

00:28:40,440 --> 00:28:45,870
whatever I want

00:28:41,490 --> 00:28:48,150
JavaScript generator and this will allow

00:28:45,870 --> 00:28:50,070
us to create a remote endpoint that we

00:28:48,150 --> 00:28:52,890
can connect through any application a

00:28:50,070 --> 00:28:55,919
web application a phone application on

00:28:52,890 --> 00:28:57,720
iOS Android a node server any kind of

00:28:55,919 --> 00:28:59,370
application that you have you can stream

00:28:57,720 --> 00:29:02,070
data in and out of that so I'm gonna go

00:28:59,370 --> 00:29:03,929
here and if you Coast and now you can

00:29:02,070 --> 00:29:07,080
see here I have my model being hosted on

00:29:03,929 --> 00:29:08,970
the Internet to a permanent URL you can

00:29:07,080 --> 00:29:13,260
configure how this works over here you

00:29:08,970 --> 00:29:15,299
can set it up and there's a lot more to

00:29:13,260 --> 00:29:17,850
explore I think we ran out of time

00:29:15,299 --> 00:29:19,950
but uh please feel free to reach out to

00:29:17,850 --> 00:29:22,440
us if you want to explore to learn more

00:29:19,950 --> 00:29:24,120
about hoodies runway make sure to

00:29:22,440 --> 00:29:26,549
download it into so start playing with

00:29:24,120 --> 00:29:28,320
it and if you have any questions just

00:29:26,549 --> 00:29:30,630
feel free to reach out to us at any

00:29:28,320 --> 00:29:32,450
point and if this is do you wanna say

00:29:30,630 --> 00:29:35,659
something with you before we choose it

00:29:32,450 --> 00:29:38,809
thank you for watching yeah thank you

00:29:35,659 --> 00:29:38,809

YouTube URL: https://www.youtube.com/watch?v=0OHzS5lOlpo


