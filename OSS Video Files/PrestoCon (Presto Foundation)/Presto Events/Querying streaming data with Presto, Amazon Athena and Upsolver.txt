Title: Querying streaming data with Presto, Amazon Athena and Upsolver
Publication date: 2021-01-18
Playlist: Presto Events
Description: 
	Speaker: Yoni Eini, CTO and Cofounder, Upsolver

In this session, Yoni will present on querying streaming data with Presto and Amazon Athena including performance, data partitioning and compaction. In addition, we will demo using the Upsolver platform with Amazon Athena. In addition, he will share what they are working on with Prestodb.
Captions: 
	00:00:00,000 --> 00:00:06,160
mentioned my talk is going to be about

00:00:03,120 --> 00:00:08,240
using presto with streaming data um

00:00:06,160 --> 00:00:10,800
so just a bit of background about me uh

00:00:08,240 --> 00:00:12,400
i'm the cto and co-founder of upsolver

00:00:10,800 --> 00:00:15,679
upsolver is a streaming

00:00:12,400 --> 00:00:17,279
uh data lake platform um uh

00:00:15,679 --> 00:00:18,960
very integrated with presto because

00:00:17,279 --> 00:00:20,720
we're obviously populating the data that

00:00:18,960 --> 00:00:22,960
presto is going to be querying on later

00:00:20,720 --> 00:00:24,880
uh i used to be the cto of uh the

00:00:22,960 --> 00:00:25,599
largest data science department in the

00:00:24,880 --> 00:00:28,240
idf

00:00:25,599 --> 00:00:30,240
before working at upsolver and uh

00:00:28,240 --> 00:00:31,279
basically my entire professional career

00:00:30,240 --> 00:00:33,920
has been around

00:00:31,279 --> 00:00:34,559
uh data data science uh distributed

00:00:33,920 --> 00:00:36,719
systems

00:00:34,559 --> 00:00:39,040
uh things like that um so i've pretty

00:00:36,719 --> 00:00:40,960
much seen data from all directions be it

00:00:39,040 --> 00:00:43,760
like the producer the consumer

00:00:40,960 --> 00:00:45,360
uh building machine learning models etc

00:00:43,760 --> 00:00:47,840
um

00:00:45,360 --> 00:00:50,079
so just a very quick and i'm gonna do

00:00:47,840 --> 00:00:52,399
exactly 10 seconds on this slide

00:00:50,079 --> 00:00:53,920
um just to give you kind of a background

00:00:52,399 --> 00:00:55,600
on what upsolver is

00:00:53,920 --> 00:00:57,440
so up solver is basically as i was

00:00:55,600 --> 00:00:58,160
saying data lake platform dealing with

00:00:57,440 --> 00:01:00,160
streaming data

00:00:58,160 --> 00:01:02,000
so if you look at our architecture you

00:01:00,160 --> 00:01:03,840
have streaming data coming in

00:01:02,000 --> 00:01:05,920
on the left it would often be coming

00:01:03,840 --> 00:01:07,760
from a system like kafka kinesis

00:01:05,920 --> 00:01:08,560
possibly files landing on s3 or things

00:01:07,760 --> 00:01:10,640
like that

00:01:08,560 --> 00:01:12,960
and then finally streaming out to

00:01:10,640 --> 00:01:14,560
systems like presto athena or

00:01:12,960 --> 00:01:16,080
more traditional data warehouses like

00:01:14,560 --> 00:01:18,799
snowflake or redshift or

00:01:16,080 --> 00:01:20,479
elasticsearch um and many many more on

00:01:18,799 --> 00:01:20,720
the left and on the right uh this isn't

00:01:20,479 --> 00:01:22,960
a

00:01:20,720 --> 00:01:24,640
exhaustive list and then in the middle

00:01:22,960 --> 00:01:26,320
you basically have an etl platform so

00:01:24,640 --> 00:01:26,960
something that takes the data populates

00:01:26,320 --> 00:01:28,960
the data lake

00:01:26,960 --> 00:01:30,640
builds it out manages the storage layer

00:01:28,960 --> 00:01:31,840
for you and manages the metadata layer

00:01:30,640 --> 00:01:34,560
for you as well

00:01:31,840 --> 00:01:35,439
and um i'm really only touching on this

00:01:34,560 --> 00:01:38,960
for a second here

00:01:35,439 --> 00:01:41,520
to to uh uh point out that having

00:01:38,960 --> 00:01:42,560
uh and we're going to see later on the

00:01:41,520 --> 00:01:44,799
future slides

00:01:42,560 --> 00:01:46,960
that having all of this centralized

00:01:44,799 --> 00:01:48,799
together and and running in tandem is

00:01:46,960 --> 00:01:51,520
very very important

00:01:48,799 --> 00:01:52,000
um so i'm going to jump right into the

00:01:51,520 --> 00:01:55,119
uh

00:01:52,000 --> 00:01:57,040
streaming data um uh processing so

00:01:55,119 --> 00:01:58,399
um first of all and i don't have a slide

00:01:57,040 --> 00:01:59,840
for this um

00:01:58,399 --> 00:02:01,360
let me talk a bit about what we're

00:01:59,840 --> 00:02:02,399
trying to accomplish here like what's

00:02:01,360 --> 00:02:05,119
what's the goal

00:02:02,399 --> 00:02:06,719
uh working with streaming data so presto

00:02:05,119 --> 00:02:08,800
is kind of like a rockstar dealing with

00:02:06,719 --> 00:02:12,480
giant amounts of data

00:02:08,800 --> 00:02:14,720
you can store data super cheaply on s3

00:02:12,480 --> 00:02:16,640
run presto either using athena or run

00:02:14,720 --> 00:02:20,239
presto in your own cluster

00:02:16,640 --> 00:02:22,239
using a bunch of different systems

00:02:20,239 --> 00:02:25,280
and query data really easily really

00:02:22,239 --> 00:02:27,760
quickly and scanning huge volumes

00:02:25,280 --> 00:02:29,440
um and that's really good for batch data

00:02:27,760 --> 00:02:31,360
because you kind of need to figure out

00:02:29,440 --> 00:02:33,920
how you're going to be storing the data

00:02:31,360 --> 00:02:35,200
um so so if you just put a bunch of

00:02:33,920 --> 00:02:37,680
parquet files there

00:02:35,200 --> 00:02:39,120
and they're big enough you can pretty

00:02:37,680 --> 00:02:40,000
much scale to whatever size you want and

00:02:39,120 --> 00:02:43,120
that's going to work

00:02:40,000 --> 00:02:44,480
great the challenge comes when you want

00:02:43,120 --> 00:02:48,319
to deal with data that's

00:02:44,480 --> 00:02:50,480
more live so and this is very

00:02:48,319 --> 00:02:52,319
common for large data sets in general

00:02:50,480 --> 00:02:52,959
where do large data sets come from is

00:02:52,319 --> 00:02:54,879
usually

00:02:52,959 --> 00:02:56,400
some system that's emitting events so

00:02:54,879 --> 00:02:57,200
you have lots of events coming in all

00:02:56,400 --> 00:03:00,400
the time

00:02:57,200 --> 00:03:02,239
and and sure we can have a one-day delay

00:03:00,400 --> 00:03:03,760
in data processing so i'm going to have

00:03:02,239 --> 00:03:05,840
a bunch of files that are created every

00:03:03,760 --> 00:03:08,480
day i'll organize everything

00:03:05,840 --> 00:03:09,200
and and that's kind of my view um but

00:03:08,480 --> 00:03:12,159
that really

00:03:09,200 --> 00:03:13,760
relegates presto to a secondary role

00:03:12,159 --> 00:03:14,879
rather than being able to see data

00:03:13,760 --> 00:03:18,080
that's up to date

00:03:14,879 --> 00:03:20,800
now um i can only use presto for

00:03:18,080 --> 00:03:22,319
kind of like the historic uh um

00:03:20,800 --> 00:03:24,480
long-term analytics

00:03:22,319 --> 00:03:26,239
um and it leaves out a lot of value that

00:03:24,480 --> 00:03:28,319
i could get with data that's

00:03:26,239 --> 00:03:29,760
kind of fresh and and and as it's being

00:03:28,319 --> 00:03:30,959
generated and then

00:03:29,760 --> 00:03:32,480
often what you're going to see is a

00:03:30,959 --> 00:03:33,040
hybrid solution where you have presto

00:03:32,480 --> 00:03:35,040
doing the

00:03:33,040 --> 00:03:36,799
long term queries whereas you have some

00:03:35,040 --> 00:03:37,280
other database system doing short term

00:03:36,799 --> 00:03:39,120
queries

00:03:37,280 --> 00:03:40,480
and having that separation really sucks

00:03:39,120 --> 00:03:42,319
because first of all you have to

00:03:40,480 --> 00:03:43,840
maintain two systems and the database is

00:03:42,319 --> 00:03:44,959
generally going to be very expensive as

00:03:43,840 --> 00:03:46,400
well

00:03:44,959 --> 00:03:47,760
but more than that you don't even have

00:03:46,400 --> 00:03:49,040
all the data in one place so if you want

00:03:47,760 --> 00:03:50,879
to do a query that's

00:03:49,040 --> 00:03:52,239
spanning a lot of time back but also

00:03:50,879 --> 00:03:54,480
looks at data from now

00:03:52,239 --> 00:03:56,080
you're kind of stuck so all that's

00:03:54,480 --> 00:03:57,280
saying is that dealing with streaming

00:03:56,080 --> 00:03:58,799
data is

00:03:57,280 --> 00:04:01,200
often going to be very valuable to

00:03:58,799 --> 00:04:02,879
organizations and as close as we can get

00:04:01,200 --> 00:04:04,239
to real time with the data

00:04:02,879 --> 00:04:05,920
the better insights we're going to get

00:04:04,239 --> 00:04:09,200
the faster turnaround time to

00:04:05,920 --> 00:04:11,040
uh to analytics to uh to action

00:04:09,200 --> 00:04:12,640
so so this is generally something that a

00:04:11,040 --> 00:04:15,360
lot of people are looking at

00:04:12,640 --> 00:04:16,959
um but it's really hard and uh the next

00:04:15,360 --> 00:04:18,720
uh bunch of slides are gonna be talking

00:04:16,959 --> 00:04:20,720
about why it's so hard um

00:04:18,720 --> 00:04:22,320
and what we're doing at upsolver to uh

00:04:20,720 --> 00:04:23,840
to mitigate this because

00:04:22,320 --> 00:04:26,000
as i was saying in the beginning uh

00:04:23,840 --> 00:04:27,600
upsolver is a unified solution so we

00:04:26,000 --> 00:04:29,199
take care of all of the

00:04:27,600 --> 00:04:30,960
interactions that need to be done in

00:04:29,199 --> 00:04:31,520
order for streaming data processing to

00:04:30,960 --> 00:04:34,560
work

00:04:31,520 --> 00:04:36,160
properly so i'm going to start with

00:04:34,560 --> 00:04:38,400
orchestration

00:04:36,160 --> 00:04:40,560
if we're dealing with batch data you

00:04:38,400 --> 00:04:42,160
have to run a task once a day

00:04:40,560 --> 00:04:44,160
in the end that's not that hard we have

00:04:42,160 --> 00:04:46,400
tools like airflow

00:04:44,160 --> 00:04:47,440
they're good at managing that kind of

00:04:46,400 --> 00:04:49,199
process they're

00:04:47,440 --> 00:04:50,880
resilient in the face of errors and

00:04:49,199 --> 00:04:53,199
things like that

00:04:50,880 --> 00:04:55,360
and also even if a job fails i can

00:04:53,199 --> 00:04:56,000
always notify an engineer they'll take a

00:04:55,360 --> 00:04:58,560
look

00:04:56,000 --> 00:05:00,560
rerun the job and all's well when we're

00:04:58,560 --> 00:05:03,759
talking about stream processing

00:05:00,560 --> 00:05:05,440
it's a lot harder not only do i have to

00:05:03,759 --> 00:05:06,800
have everything completely automated

00:05:05,440 --> 00:05:07,840
because an engineer isn't going to be

00:05:06,800 --> 00:05:11,039
able to pop in

00:05:07,840 --> 00:05:12,240
in a timely manner and and fix that but

00:05:11,039 --> 00:05:15,280
also there are a lot of

00:05:12,240 --> 00:05:17,919
uh interactions of the data between

00:05:15,280 --> 00:05:19,039
within itself that become very difficult

00:05:17,919 --> 00:05:22,000
to manage

00:05:19,039 --> 00:05:22,960
so um all sorts of things like timing

00:05:22,000 --> 00:05:24,880
and

00:05:22,960 --> 00:05:26,800
what data window i want to look at and

00:05:24,880 --> 00:05:27,840
if i'm doing any kind of partitioning or

00:05:26,800 --> 00:05:30,000
things like that

00:05:27,840 --> 00:05:32,160
um these things become very tricky

00:05:30,000 --> 00:05:34,160
because data is constantly coming in

00:05:32,160 --> 00:05:36,560
and i have to decide when am i cutting

00:05:34,160 --> 00:05:38,080
off and that cutoff point can

00:05:36,560 --> 00:05:40,400
if it's not consistent it can either

00:05:38,080 --> 00:05:41,840
lead to data loss or or data duplication

00:05:40,400 --> 00:05:45,680
uh which we're going to touch on

00:05:41,840 --> 00:05:48,800
later on um so basically i need

00:05:45,680 --> 00:05:49,280
some way to to look at all this data in

00:05:48,800 --> 00:05:52,320
a

00:05:49,280 --> 00:05:54,240
in a consolidated way and saying like um

00:05:52,320 --> 00:05:55,919
whereas in a normal batch process all

00:05:54,240 --> 00:05:56,479
the data up until a certain point in

00:05:55,919 --> 00:05:59,360
time

00:05:56,479 --> 00:06:00,639
that data is going to stream in um when

00:05:59,360 --> 00:06:03,360
the batch process runs

00:06:00,639 --> 00:06:04,960
in a streaming sense there isn't a very

00:06:03,360 --> 00:06:07,039
clear boundary and i have to kind of

00:06:04,960 --> 00:06:09,680
figure that out as i'm doing my

00:06:07,039 --> 00:06:11,360
joins as i'm doing my aggregations etc

00:06:09,680 --> 00:06:13,440
and i'm just going to quickly show you

00:06:11,360 --> 00:06:16,479
what that looks like

00:06:13,440 --> 00:06:18,479
as a query in upsolver and

00:06:16,479 --> 00:06:20,080
really there isn't we're not going to

00:06:18,479 --> 00:06:21,360
like look at this query too much i just

00:06:20,080 --> 00:06:24,720
wanted to point out

00:06:21,360 --> 00:06:27,120
um three three main parts

00:06:24,720 --> 00:06:28,160
um so this is just up solver in the end

00:06:27,120 --> 00:06:30,479
is a ui

00:06:28,160 --> 00:06:31,919
platform that also uses sql as an

00:06:30,479 --> 00:06:34,400
underlying language so you can switch

00:06:31,919 --> 00:06:36,400
between the ui and the sql um

00:06:34,400 --> 00:06:37,680
and if i'm looking at the sql statement

00:06:36,400 --> 00:06:39,280
a few things are going to

00:06:37,680 --> 00:06:40,960
stand out first of all that we're doing

00:06:39,280 --> 00:06:42,960
a join between two streams

00:06:40,960 --> 00:06:44,960
um in this case this stream is actually

00:06:42,960 --> 00:06:45,840
a group by on top of the same stream but

00:06:44,960 --> 00:06:49,919
that's uh

00:06:45,840 --> 00:06:51,120
uh um out of scope um but the two things

00:06:49,919 --> 00:06:52,880
that are very interesting

00:06:51,120 --> 00:06:54,800
are first of all this window clause

00:06:52,880 --> 00:06:57,199
which is not nc sql

00:06:54,800 --> 00:06:58,639
and kind of tells the system or tells

00:06:57,199 --> 00:07:00,880
the etl process

00:06:58,639 --> 00:07:02,000
i want to look at 90 days when doing

00:07:00,880 --> 00:07:05,440
this aggregation

00:07:02,000 --> 00:07:06,080
so i want to look at at a certain window

00:07:05,440 --> 00:07:10,080
at a certain

00:07:06,080 --> 00:07:11,919
range of time where data came in

00:07:10,080 --> 00:07:13,199
and that's very very important when i'm

00:07:11,919 --> 00:07:16,000
doing a streaming join

00:07:13,199 --> 00:07:16,800
because because as data collects as data

00:07:16,000 --> 00:07:19,120
comes in

00:07:16,800 --> 00:07:21,039
i want to be able to be very accurate in

00:07:19,120 --> 00:07:22,479
in how much data back am i'm going to be

00:07:21,039 --> 00:07:24,479
looking at

00:07:22,479 --> 00:07:25,919
and same thing for synchronization

00:07:24,479 --> 00:07:27,759
between streams so notice the second

00:07:25,919 --> 00:07:30,080
keyword after five minutes

00:07:27,759 --> 00:07:31,759
which is telling me that the mainstream

00:07:30,080 --> 00:07:34,160
i actually wanted to wait around

00:07:31,759 --> 00:07:35,759
for for five minutes until enough data

00:07:34,160 --> 00:07:36,960
collects on the on the other side and

00:07:35,759 --> 00:07:38,400
that's very important when i have for

00:07:36,960 --> 00:07:41,039
example two events that

00:07:38,400 --> 00:07:42,319
happen staggered and so when i'm joining

00:07:41,039 --> 00:07:44,080
between them i'm gonna have to wait for

00:07:42,319 --> 00:07:46,560
the second event to happen before i can

00:07:44,080 --> 00:07:48,479
actually pull it in and populate

00:07:46,560 --> 00:07:50,400
now this kind of thing is very very hard

00:07:48,479 --> 00:07:54,080
to orchestrate manually because

00:07:50,400 --> 00:07:57,440
it's happening constantly it's running

00:07:54,080 --> 00:08:00,400
all the time so just being able to

00:07:57,440 --> 00:08:02,080
to grab a snapshot in time is is quite

00:08:00,400 --> 00:08:04,479
challenging if i don't have the tools to

00:08:02,080 --> 00:08:04,479
do that

00:08:04,560 --> 00:08:09,280
um all right so so that's a bit about

00:08:07,919 --> 00:08:11,360
just orchestration

00:08:09,280 --> 00:08:12,479
um now i'm going to touch on file

00:08:11,360 --> 00:08:14,240
management which is

00:08:12,479 --> 00:08:16,400
a lot closer i mean the orchestration

00:08:14,240 --> 00:08:18,319
part is really general to all streaming

00:08:16,400 --> 00:08:20,960
systems there's nothing special

00:08:18,319 --> 00:08:24,080
related to presto file management is a

00:08:20,960 --> 00:08:26,240
lot more important to presto itself

00:08:24,080 --> 00:08:28,240
the reason is is that if i'm pushing

00:08:26,240 --> 00:08:29,440
streaming data into a database which is

00:08:28,240 --> 00:08:31,039
generally what the solution's going to

00:08:29,440 --> 00:08:34,240
be

00:08:31,039 --> 00:08:36,320
up until now for that kind of system um

00:08:34,240 --> 00:08:38,399
the database takes care of all of the

00:08:36,320 --> 00:08:39,519
consolidation and optimizations and

00:08:38,399 --> 00:08:40,959
stuff like that

00:08:39,519 --> 00:08:42,560
at most i'm going to have to run some

00:08:40,959 --> 00:08:45,279
kind of vacuum or or

00:08:42,560 --> 00:08:46,080
or gather statistics or something along

00:08:45,279 --> 00:08:47,600
those lines

00:08:46,080 --> 00:08:49,200
but generally it's going to take care of

00:08:47,600 --> 00:08:51,120
it whereas if i'm

00:08:49,200 --> 00:08:52,800
expecting to use presto as the query

00:08:51,120 --> 00:08:55,519
layer and i want to just have parquet

00:08:52,800 --> 00:08:57,279
files on s3 to have cheap storage

00:08:55,519 --> 00:08:58,560
i need to decide which files i'm going

00:08:57,279 --> 00:09:01,519
to be creating

00:08:58,560 --> 00:09:02,880
and this actually becomes quite

00:09:01,519 --> 00:09:05,360
complicated when you're talking about

00:09:02,880 --> 00:09:07,839
streaming data for a bunch of reasons

00:09:05,360 --> 00:09:09,440
i mean obviously in batch so i have once

00:09:07,839 --> 00:09:12,160
a day i'm writing a file and

00:09:09,440 --> 00:09:14,000
if i have five gigs of data every day so

00:09:12,160 --> 00:09:17,040
maybe i'll write five files

00:09:14,000 --> 00:09:18,800
each of one gig one gig each

00:09:17,040 --> 00:09:21,360
but if i have five gigs of data coming

00:09:18,800 --> 00:09:24,480
in but i want a latency of one minute so

00:09:21,360 --> 00:09:26,240
i want new data to be available to query

00:09:24,480 --> 00:09:29,600
as it's emitted or within a minute of it

00:09:26,240 --> 00:09:30,880
being emitted i have to generate 1440

00:09:29,600 --> 00:09:33,680
files

00:09:30,880 --> 00:09:34,800
per day so these files can't be a gig

00:09:33,680 --> 00:09:37,680
each they'll be like

00:09:34,800 --> 00:09:39,760
a few megabytes each and that means that

00:09:37,680 --> 00:09:42,240
as the day progresses

00:09:39,760 --> 00:09:43,680
my partition becomes super uh it just

00:09:42,240 --> 00:09:45,200
has a lot of small files which means

00:09:43,680 --> 00:09:46,640
query performance is going to be really

00:09:45,200 --> 00:09:49,279
bad

00:09:46,640 --> 00:09:51,040
not exactly what we wanted to achieve

00:09:49,279 --> 00:09:52,959
when using presto for this kind of use

00:09:51,040 --> 00:09:54,880
case

00:09:52,959 --> 00:09:56,480
that's just even in a simple scenario

00:09:54,880 --> 00:09:58,160
where my partitions

00:09:56,480 --> 00:09:59,760
aren't anything special so i'm just

00:09:58,160 --> 00:10:01,440
looking at partitioning by

00:09:59,760 --> 00:10:03,839
as new data comes in i just want to push

00:10:01,440 --> 00:10:05,920
it into the same partition

00:10:03,839 --> 00:10:06,880
but let's say if and here i'll again

00:10:05,920 --> 00:10:10,000
jump to show you

00:10:06,880 --> 00:10:12,160
a a sql statement um

00:10:10,000 --> 00:10:13,680
so if we look at this example where

00:10:12,160 --> 00:10:14,880
we're again running on top of a resource

00:10:13,680 --> 00:10:16,959
utilization stream

00:10:14,880 --> 00:10:18,240
but in this case i want to partition by

00:10:16,959 --> 00:10:21,600
both the

00:10:18,240 --> 00:10:23,600
date of the of the event but also by the

00:10:21,600 --> 00:10:25,279
aws region so i have events coming in

00:10:23,600 --> 00:10:26,640
from all sorts of regions and my query

00:10:25,279 --> 00:10:28,480
pattern is going to be

00:10:26,640 --> 00:10:31,279
such that i'm only ever going to look at

00:10:28,480 --> 00:10:33,600
a specific region at once

00:10:31,279 --> 00:10:34,640
so now partitioning by date and region

00:10:33,600 --> 00:10:36,399
so okay all the new

00:10:34,640 --> 00:10:38,560
data is going to go into the same date

00:10:36,399 --> 00:10:40,800
but i'm constantly going to be pushing

00:10:38,560 --> 00:10:43,519
data into each of the different regions

00:10:40,800 --> 00:10:45,360
so my challenge is multiplied by the

00:10:43,519 --> 00:10:46,720
amount of regions that i'm working in

00:10:45,360 --> 00:10:48,720
whereas it used to be that i needed to

00:10:46,720 --> 00:10:50,079
write one file every minute if i wanted

00:10:48,720 --> 00:10:51,760
a one minute latency

00:10:50,079 --> 00:10:53,839
now i'm going to need to write maybe 10

00:10:51,760 --> 00:10:55,680
or 20 files each minute

00:10:53,839 --> 00:10:57,680
which is going to make the problem of

00:10:55,680 --> 00:10:59,680
querying it 20 times worth

00:10:57,680 --> 00:11:01,680
worse or at least the data management

00:10:59,680 --> 00:11:04,560
problem of having a lot of files uh

00:11:01,680 --> 00:11:07,600
sitting around on s3

00:11:04,560 --> 00:11:08,480
um so the solution to this problem is

00:11:07,600 --> 00:11:11,040
actually quite

00:11:08,480 --> 00:11:12,720
quite simple uh it's just writing small

00:11:11,040 --> 00:11:15,600
files and then as they collect

00:11:12,720 --> 00:11:17,120
we need to rewrite them as bigger files

00:11:15,600 --> 00:11:18,320
the problem is is that we need to make

00:11:17,120 --> 00:11:20,720
sure that

00:11:18,320 --> 00:11:22,240
when a user is querying they get a

00:11:20,720 --> 00:11:24,959
consistent view of the data

00:11:22,240 --> 00:11:26,480
so on the one hand they don't want to be

00:11:24,959 --> 00:11:27,279
running queries and then suddenly data

00:11:26,480 --> 00:11:28,640
disappears

00:11:27,279 --> 00:11:31,360
and on the other hand they don't want

00:11:28,640 --> 00:11:33,040
that as a compaction occurs

00:11:31,360 --> 00:11:34,720
uh suddenly they have delays in the data

00:11:33,040 --> 00:11:36,240
they still want to have they don't care

00:11:34,720 --> 00:11:37,360
that this background process is running

00:11:36,240 --> 00:11:40,240
they want to query and get

00:11:37,360 --> 00:11:40,959
get results and that's it that's

00:11:40,240 --> 00:11:43,120
something that

00:11:40,959 --> 00:11:45,200
um that's generally very challenging to

00:11:43,120 --> 00:11:46,959
manage and again upsolver uh kind of

00:11:45,200 --> 00:11:49,360
manages that for you

00:11:46,959 --> 00:11:50,240
as you saw also with the um with the

00:11:49,360 --> 00:11:53,120
queries that just

00:11:50,240 --> 00:11:55,360
define the partitions but file

00:11:53,120 --> 00:11:56,000
management is a very very important part

00:11:55,360 --> 00:11:57,519
of getting

00:11:56,000 --> 00:11:59,680
good performance in general out of

00:11:57,519 --> 00:12:01,200
presto it's just that it's more

00:11:59,680 --> 00:12:02,880
challenging with streaming data but this

00:12:01,200 --> 00:12:04,480
is just as important when you're dealing

00:12:02,880 --> 00:12:06,480
with batch data

00:12:04,480 --> 00:12:08,560
and this is on top of of course doing

00:12:06,480 --> 00:12:10,320
best practices like file compression and

00:12:08,560 --> 00:12:11,600
using columnar formats and things like

00:12:10,320 --> 00:12:15,040
that

00:12:11,600 --> 00:12:15,040
partitioning your tables of course

00:12:15,839 --> 00:12:18,959
another challenge which is really not

00:12:17,920 --> 00:12:22,160
well addressed

00:12:18,959 --> 00:12:22,720
in general for presto and is kind of the

00:12:22,160 --> 00:12:24,399
point where

00:12:22,720 --> 00:12:27,519
often people are going to be going

00:12:24,399 --> 00:12:31,360
towards databases instead of data lakes

00:12:27,519 --> 00:12:32,800
um apache hoodie is an example of

00:12:31,360 --> 00:12:34,560
open source that's kind of trying to

00:12:32,800 --> 00:12:35,760
tackle this solution

00:12:34,560 --> 00:12:38,000
but in general is dealing with

00:12:35,760 --> 00:12:41,920
mutability so data that can be

00:12:38,000 --> 00:12:43,760
uh can be modified um a lot of data sets

00:12:41,920 --> 00:12:46,480
don't need to be modified they're append

00:12:43,760 --> 00:12:50,240
only by nature so if i have a log

00:12:46,480 --> 00:12:51,600
of of website views when a view happens

00:12:50,240 --> 00:12:53,279
it happened and there isn't going to be

00:12:51,600 --> 00:12:54,000
any update to that or any changes in

00:12:53,279 --> 00:12:55,519
that data

00:12:54,000 --> 00:12:57,680
it's it's a single point in time of

00:12:55,519 --> 00:12:58,959
event a point in time event and then it

00:12:57,680 --> 00:13:01,680
and then it finished

00:12:58,959 --> 00:13:03,360
but sometimes uh it's very important to

00:13:01,680 --> 00:13:03,920
update data in the past like for example

00:13:03,360 --> 00:13:07,760
if i have

00:13:03,920 --> 00:13:10,720
a stream of orders and an order can

00:13:07,760 --> 00:13:11,200
uh get new statuses or it can be deleted

00:13:10,720 --> 00:13:12,880
uh

00:13:11,200 --> 00:13:14,320
refunded et cetera so there are a lot of

00:13:12,880 --> 00:13:15,200
things that can apply to that in

00:13:14,320 --> 00:13:17,040
retrospect

00:13:15,200 --> 00:13:18,560
which i really don't want to then start

00:13:17,040 --> 00:13:19,200
looking around in all sorts of different

00:13:18,560 --> 00:13:22,160
files

00:13:19,200 --> 00:13:23,839
in order to consolidate that my analysts

00:13:22,160 --> 00:13:27,600
they just want to be able to see

00:13:23,839 --> 00:13:30,800
the one record for the order um

00:13:27,600 --> 00:13:33,680
also gdpr and ccpa

00:13:30,800 --> 00:13:34,959
contain rights to be forgotten so often

00:13:33,680 --> 00:13:35,600
larger companies are going to get

00:13:34,959 --> 00:13:38,399
requests

00:13:35,600 --> 00:13:39,120
to delete records from the data lake and

00:13:38,399 --> 00:13:40,720
that can be

00:13:39,120 --> 00:13:42,399
extremely challenging when i just have a

00:13:40,720 --> 00:13:43,920
bunch of parquet files

00:13:42,399 --> 00:13:45,600
i don't even know where the user's

00:13:43,920 --> 00:13:47,199
records are

00:13:45,600 --> 00:13:49,760
let alone have necessarily the

00:13:47,199 --> 00:13:52,639
capability to to rewrite the files

00:13:49,760 --> 00:13:54,000
in a meaningful way without without

00:13:52,639 --> 00:13:56,959
doing a lot of processing or doing

00:13:54,000 --> 00:14:01,600
damage to the rest of the like

00:13:56,959 --> 00:14:03,839
um also often even if there isn't uh

00:14:01,600 --> 00:14:05,279
let's say strong necessity to have

00:14:03,839 --> 00:14:07,440
mutable data

00:14:05,279 --> 00:14:08,959
being able to consolidate records so for

00:14:07,440 --> 00:14:11,120
example um

00:14:08,959 --> 00:14:12,320
having a table where i want the

00:14:11,120 --> 00:14:13,920
aggregation of

00:14:12,320 --> 00:14:16,000
all the events of the last hour just the

00:14:13,920 --> 00:14:20,079
count star and but i still don't want

00:14:16,000 --> 00:14:22,000
to give up on my on the speed of uh of

00:14:20,079 --> 00:14:23,279
update so as the current hour is

00:14:22,000 --> 00:14:25,760
happening i want the

00:14:23,279 --> 00:14:27,680
counter to continually increase until it

00:14:25,760 --> 00:14:31,120
finally stabilizes at the end of the

00:14:27,680 --> 00:14:33,199
hour that kind of use case is is very

00:14:31,120 --> 00:14:36,320
powerful for reducing data cardinality

00:14:33,199 --> 00:14:38,560
but again requires updating the data set

00:14:36,320 --> 00:14:40,720
so all these things are kind of talking

00:14:38,560 --> 00:14:42,880
to why i would want to do mutability

00:14:40,720 --> 00:14:44,720
but how can i do that on a data lake

00:14:42,880 --> 00:14:47,440
it's super challenging

00:14:44,720 --> 00:14:48,079
um so using a system like hoodie is one

00:14:47,440 --> 00:14:51,440
solution

00:14:48,079 --> 00:14:54,240
upsolver also has a built-in approach to

00:14:51,440 --> 00:14:55,360
handling mutable data but let's say this

00:14:54,240 --> 00:14:56,480
is the kind of thing that i would say

00:14:55,360 --> 00:14:59,519
don't try this at home

00:14:56,480 --> 00:15:00,160
so running your own mutable data

00:14:59,519 --> 00:15:02,800
pipeline

00:15:00,160 --> 00:15:04,800
is going to be insanely difficult um so

00:15:02,800 --> 00:15:07,839
i do strongly recommend using a tool

00:15:04,800 --> 00:15:08,320
uh to manage it um the way up solver

00:15:07,839 --> 00:15:10,800
does it

00:15:08,320 --> 00:15:12,480
is that we try to or we don't try we

00:15:10,800 --> 00:15:15,360
actually succeed in

00:15:12,480 --> 00:15:16,880
uh in keeping the data mutable while

00:15:15,360 --> 00:15:19,120
it's still consistent

00:15:16,880 --> 00:15:21,519
using views within presto so essentially

00:15:19,120 --> 00:15:23,120
we just add an additional partition

00:15:21,519 --> 00:15:24,399
it's just vanilla parquet files there

00:15:23,120 --> 00:15:26,160
isn't any kind of proprietary

00:15:24,399 --> 00:15:26,800
transaction log we use a separate

00:15:26,160 --> 00:15:29,360
partition

00:15:26,800 --> 00:15:30,079
with parquet files in order to manage

00:15:29,360 --> 00:15:33,199
that

00:15:30,079 --> 00:15:34,800
and continuously compact which as i was

00:15:33,199 --> 00:15:36,399
talking about in the previous slide

00:15:34,800 --> 00:15:38,240
dealing with file management and needing

00:15:36,399 --> 00:15:40,399
compaction so we're using the exact same

00:15:38,240 --> 00:15:41,360
mechanism to compact the right ahead log

00:15:40,399 --> 00:15:43,680
as well

00:15:41,360 --> 00:15:46,000
to make sure that that again performs

00:15:43,680 --> 00:15:48,000
well but just using views on top of

00:15:46,000 --> 00:15:49,600
fresh data that's being added to the

00:15:48,000 --> 00:15:51,120
write ahead log to make sure that there

00:15:49,600 --> 00:15:53,839
is a consistent view

00:15:51,120 --> 00:15:55,839
of the of the data at all times and

00:15:53,839 --> 00:15:58,480
representing the latest

00:15:55,839 --> 00:15:58,480
the latest view

00:15:58,959 --> 00:16:04,399
if i jump back into this

00:16:02,240 --> 00:16:06,320
aggregation query so this is actually an

00:16:04,399 --> 00:16:08,639
example of an updating table

00:16:06,320 --> 00:16:10,160
so in this case we have the replace on

00:16:08,639 --> 00:16:12,480
duplicate keyword

00:16:10,160 --> 00:16:13,759
um as again as an extension to the sql

00:16:12,480 --> 00:16:14,800
so basically what's happening here is

00:16:13,759 --> 00:16:18,000
that i'm saying

00:16:14,800 --> 00:16:20,880
um i want each host to have a single row

00:16:18,000 --> 00:16:22,480
the aggregation is by host and by region

00:16:20,880 --> 00:16:23,759
and by partition date of course a host

00:16:22,480 --> 00:16:25,199
is only going to ever appear in one

00:16:23,759 --> 00:16:26,720
region so that's not going to create any

00:16:25,199 --> 00:16:29,120
kind of duplications

00:16:26,720 --> 00:16:30,320
um if there were by the way the system

00:16:29,120 --> 00:16:32,240
would jump the host between the

00:16:30,320 --> 00:16:33,279
partitions so since the duplicate is

00:16:32,240 --> 00:16:34,839
only host

00:16:33,279 --> 00:16:37,199
a host will only appear in a single

00:16:34,839 --> 00:16:38,720
partition and then i want some simple

00:16:37,199 --> 00:16:40,240
aggregations i want to know when was the

00:16:38,720 --> 00:16:42,639
first time i saw the host

00:16:40,240 --> 00:16:44,480
when was the last time and what's the

00:16:42,639 --> 00:16:46,399
average cpu usage

00:16:44,480 --> 00:16:49,120
so this is kind of how you would do this

00:16:46,399 --> 00:16:50,800
kind of updating table definition

00:16:49,120 --> 00:16:52,720
within upsolver and the nice thing here

00:16:50,800 --> 00:16:54,720
is it's completely declarative

00:16:52,720 --> 00:16:56,320
you don't need to get into the weeds of

00:16:54,720 --> 00:16:58,240
what files are going to be created how

00:16:56,320 --> 00:16:59,839
is it managing the partitions how is it

00:16:58,240 --> 00:17:00,560
doing the compaction process behind the

00:16:59,839 --> 00:17:02,480
scenes

00:17:00,560 --> 00:17:04,959
uh upsolver's execution engine kind of

00:17:02,480 --> 00:17:07,600
takes care of all that for you

00:17:04,959 --> 00:17:08,880
and this is again getting back to when

00:17:07,600 --> 00:17:10,720
you're dealing with streaming data

00:17:08,880 --> 00:17:12,160
especially it's very important that the

00:17:10,720 --> 00:17:14,319
platform that you're using

00:17:12,160 --> 00:17:16,400
kind of needs to do everything for you

00:17:14,319 --> 00:17:17,919
uh in the sense of the file management

00:17:16,400 --> 00:17:19,039
because as soon as you have any kind of

00:17:17,919 --> 00:17:21,439
manual management

00:17:19,039 --> 00:17:22,240
you really need to know a lot about what

00:17:21,439 --> 00:17:24,799
you need to do

00:17:22,240 --> 00:17:25,439
to make things work properly um and

00:17:24,799 --> 00:17:27,760
that's like

00:17:25,439 --> 00:17:28,960
uh it's just a huge overhead that most

00:17:27,760 --> 00:17:33,440
organizations aren't going to want to

00:17:28,960 --> 00:17:36,400
take on

00:17:33,440 --> 00:17:37,360
all right so um so lastly i'm going to

00:17:36,400 --> 00:17:39,840
talk a bit about

00:17:37,360 --> 00:17:42,400
stream processing and kind of what are

00:17:39,840 --> 00:17:44,000
the actual technical gotchas so up until

00:17:42,400 --> 00:17:47,120
now i've been talking about

00:17:44,000 --> 00:17:50,400
um um value to the users

00:17:47,120 --> 00:17:51,919
and kind of design paradigms um but what

00:17:50,400 --> 00:17:53,679
actually are the things that i need to

00:17:51,919 --> 00:17:55,280
watch out for when i'm designing a

00:17:53,679 --> 00:17:56,720
stream processing system and again all

00:17:55,280 --> 00:17:59,760
of this is kind of taken

00:17:56,720 --> 00:18:00,960
care for you within up solver so you

00:17:59,760 --> 00:18:02,559
don't need to worry about it

00:18:00,960 --> 00:18:04,320
but it's very important especially if

00:18:02,559 --> 00:18:05,440
you are planning to deal with stream

00:18:04,320 --> 00:18:08,480
processing

00:18:05,440 --> 00:18:11,679
on top of data in the lake

00:18:08,480 --> 00:18:14,320
to kind of think about these challenges

00:18:11,679 --> 00:18:15,039
and i'd say that most of them come down

00:18:14,320 --> 00:18:18,960
to

00:18:15,039 --> 00:18:21,520
exactly once message processing so um

00:18:18,960 --> 00:18:23,120
if i know how to deal with each message

00:18:21,520 --> 00:18:26,080
exactly one time

00:18:23,120 --> 00:18:27,679
and give it a correct context for that

00:18:26,080 --> 00:18:28,000
message so being able to pull in the

00:18:27,679 --> 00:18:29,760
right

00:18:28,000 --> 00:18:31,520
history or the right data from the

00:18:29,760 --> 00:18:34,799
future in order to enrich it

00:18:31,520 --> 00:18:37,600
uh i'm golden um that of course isn't

00:18:34,799 --> 00:18:39,280
a really well uh defined or easy thing

00:18:37,600 --> 00:18:42,799
to do or even necessarily a

00:18:39,280 --> 00:18:44,240
mathematically possible thing to do

00:18:42,799 --> 00:18:46,320
but essentially like when we talk about

00:18:44,240 --> 00:18:47,280
exactly once processing we want to avoid

00:18:46,320 --> 00:18:49,120
duplicate events

00:18:47,280 --> 00:18:50,640
so i want to make sure that if i have an

00:18:49,120 --> 00:18:52,480
event coming in from a stream

00:18:50,640 --> 00:18:54,799
i don't process it twice and put it into

00:18:52,480 --> 00:18:56,480
two different files on s3

00:18:54,799 --> 00:18:58,320
i want to avoid missing events so i

00:18:56,480 --> 00:19:00,080
don't want to accidentally skip it

00:18:58,320 --> 00:19:01,520
because the process crashed and started

00:19:00,080 --> 00:19:04,559
running on another uh

00:19:01,520 --> 00:19:05,120
another server i want to be able to deal

00:19:04,559 --> 00:19:07,360
with

00:19:05,120 --> 00:19:08,640
events that arrive out of order but also

00:19:07,360 --> 00:19:10,000
i want to make sure that the order of

00:19:08,640 --> 00:19:13,039
the events is maintained

00:19:10,000 --> 00:19:15,600
so if i have an event that happened

00:19:13,039 --> 00:19:17,200
now but it actually was supposed to have

00:19:15,600 --> 00:19:18,240
happened three hours ago and i just got

00:19:17,200 --> 00:19:20,559
it now because of some

00:19:18,240 --> 00:19:23,039
network outage i want to process it in

00:19:20,559 --> 00:19:24,400
the right position of my stream

00:19:23,039 --> 00:19:26,960
and that's something that's kind of very

00:19:24,400 --> 00:19:28,480
hard to to to even understand what i'm

00:19:26,960 --> 00:19:31,679
trying to explain there

00:19:28,480 --> 00:19:34,320
uh let alone uh deal with that

00:19:31,679 --> 00:19:35,280
in code and then finally i want to be

00:19:34,320 --> 00:19:36,720
able to deal with

00:19:35,280 --> 00:19:38,640
old data as well so i don't want to

00:19:36,720 --> 00:19:39,520
commit to a certain data pipeline and

00:19:38,640 --> 00:19:41,200
then

00:19:39,520 --> 00:19:43,120
if i have a bug in it then then i can

00:19:41,200 --> 00:19:44,080
only run data from now because all data

00:19:43,120 --> 00:19:46,400
has a lot of value

00:19:44,080 --> 00:19:47,919
so i want to be able to back process all

00:19:46,400 --> 00:19:50,240
that data

00:19:47,919 --> 00:19:51,679
and and again making sure that when i'm

00:19:50,240 --> 00:19:53,600
doing the back processing i'm again

00:19:51,679 --> 00:19:55,760
dealing with the data only exactly once

00:19:53,600 --> 00:19:57,440
so i need a back processing system

00:19:55,760 --> 00:19:58,799
that's aware of the stream system and

00:19:57,440 --> 00:20:02,400
make sure that there isn't

00:19:58,799 --> 00:20:03,679
uh stuff going on in parallel um

00:20:02,400 --> 00:20:06,320
so there are a bunch of ways that

00:20:03,679 --> 00:20:09,200
systems tend to deal with this

00:20:06,320 --> 00:20:09,679
general exactly once processing paradigm

00:20:09,200 --> 00:20:12,240
and

00:20:09,679 --> 00:20:13,679
the uh let's say safest solution that

00:20:12,240 --> 00:20:15,280
kind of sidesteps the

00:20:13,679 --> 00:20:16,720
problem and this is also what upsolver

00:20:15,280 --> 00:20:20,320
does is it uses

00:20:16,720 --> 00:20:22,159
idempotent operations um to anyone who

00:20:20,320 --> 00:20:23,520
doesn't know idempotent operations means

00:20:22,159 --> 00:20:26,559
that i'm going to write this

00:20:23,520 --> 00:20:28,320
a file to one place and make sure that

00:20:26,559 --> 00:20:29,600
if i ever have to run it again it's not

00:20:28,320 --> 00:20:32,480
going to change anything

00:20:29,600 --> 00:20:33,039
um so so the idempotent actually means

00:20:32,480 --> 00:20:35,120
that

00:20:33,039 --> 00:20:38,080
i can reapply the same operation without

00:20:35,120 --> 00:20:40,480
changing the final state

00:20:38,080 --> 00:20:42,720
so basically if i'm using a file system

00:20:40,480 --> 00:20:45,520
that guarantees that any operation i do

00:20:42,720 --> 00:20:47,520
writes a file and and then that file can

00:20:45,520 --> 00:20:49,360
never be overwritten in a different way

00:20:47,520 --> 00:20:50,720
and then operations just take files from

00:20:49,360 --> 00:20:52,960
one place and write

00:20:50,720 --> 00:20:54,720
write modified files to another that

00:20:52,960 --> 00:20:55,919
kind of takes care of all of these

00:20:54,720 --> 00:20:58,320
different

00:20:55,919 --> 00:20:59,919
issues for me because everything has to

00:20:58,320 --> 00:21:02,080
be consistent in order for it to work

00:20:59,919 --> 00:21:05,520
and it leans on guarantees of the

00:21:02,080 --> 00:21:06,000
uh of blob storage in order to ensure

00:21:05,520 --> 00:21:08,720
that

00:21:06,000 --> 00:21:09,600
um basically the guarantee is that if a

00:21:08,720 --> 00:21:11,679
file is written

00:21:09,600 --> 00:21:12,880
then it's going to be read in the exact

00:21:11,679 --> 00:21:16,480
same way regardless

00:21:12,880 --> 00:21:18,640
who is reading it and when um

00:21:16,480 --> 00:21:19,760
so upsolver really relies on this kind

00:21:18,640 --> 00:21:23,360
of idempotent

00:21:19,760 --> 00:21:25,360
operations on s3 and and again kind of

00:21:23,360 --> 00:21:26,400
um illustrates how important it is for

00:21:25,360 --> 00:21:28,080
everything to be

00:21:26,400 --> 00:21:30,080
synchronized within one system because

00:21:28,080 --> 00:21:32,240
if i have someone else writing files

00:21:30,080 --> 00:21:34,000
then then i lose all my guarantees you

00:21:32,240 --> 00:21:35,760
need to kind of kind of have one system

00:21:34,000 --> 00:21:39,520
that's reading the data from the source

00:21:35,760 --> 00:21:41,360
be it kafka be it s3 or whatever it is

00:21:39,520 --> 00:21:42,880
doing all the different processing steps

00:21:41,360 --> 00:21:44,640
and finally outputting it to parquet

00:21:42,880 --> 00:21:47,360
files which i'm querying from

00:21:44,640 --> 00:21:47,360
from presto

00:21:48,720 --> 00:21:54,960
all right i'm jumping back again to the

00:21:52,640 --> 00:21:56,080
architecture slide just to consolidate

00:21:54,960 --> 00:21:58,159
everything into one

00:21:56,080 --> 00:21:59,840
one picture so you have streaming data

00:21:58,159 --> 00:22:01,919
coming in um

00:21:59,840 --> 00:22:03,360
for example being emitted from uh into

00:22:01,919 --> 00:22:06,480
kafka uh

00:22:03,360 --> 00:22:07,520
using uh from from some system in the

00:22:06,480 --> 00:22:09,280
wild

00:22:07,520 --> 00:22:11,440
you have the data lake platform which

00:22:09,280 --> 00:22:14,320
pulls the data in from the source

00:22:11,440 --> 00:22:16,000
stores it on s3 make sure that

00:22:14,320 --> 00:22:18,480
everything is optimized as

00:22:16,000 --> 00:22:21,360
as a usable data lake runs the

00:22:18,480 --> 00:22:23,520
transformations which are defined in sql

00:22:21,360 --> 00:22:24,960
which can consolidate multiple sources

00:22:23,520 --> 00:22:27,280
together

00:22:24,960 --> 00:22:28,320
pushes that into parquet files which are

00:22:27,280 --> 00:22:31,760
then managed

00:22:28,320 --> 00:22:33,280
um as well as after being written the

00:22:31,760 --> 00:22:34,880
first time they're also managed as part

00:22:33,280 --> 00:22:37,039
of a compaction process

00:22:34,880 --> 00:22:38,400
their metadata is is managed in the glue

00:22:37,039 --> 00:22:40,320
data catalog

00:22:38,400 --> 00:22:42,559
so i can always just go to a presto

00:22:40,320 --> 00:22:44,640
cluster run a query and get results

00:22:42,559 --> 00:22:45,840
on the actual full data uh without

00:22:44,640 --> 00:22:49,360
needing to worry about

00:22:45,840 --> 00:22:52,159
compactions and exactly ones and uh

00:22:49,360 --> 00:22:53,520
and uh um and mutable data and all sorts

00:22:52,159 --> 00:22:54,080
of things like that all that needs to be

00:22:53,520 --> 00:22:56,240
done

00:22:54,080 --> 00:22:58,559
declaratively either using sql or using

00:22:56,240 --> 00:23:02,400
the ui

00:22:58,559 --> 00:23:06,159
um so i hope that was informative

00:23:02,400 --> 00:23:08,159
the goal of this talk was

00:23:06,159 --> 00:23:09,919
hold on the goal of this talk was really

00:23:08,159 --> 00:23:11,440
to just illustrate the points the

00:23:09,919 --> 00:23:11,919
difficulties of dealing with streaming

00:23:11,440 --> 00:23:14,240
data

00:23:11,919 --> 00:23:15,840
and a bit talk about why people actually

00:23:14,240 --> 00:23:17,600
want to use streaming data and i really

00:23:15,840 --> 00:23:19,840
think that the more people who get

00:23:17,600 --> 00:23:22,480
streaming data into their data lakes

00:23:19,840 --> 00:23:23,200
the more powerful let's say the more uh

00:23:22,480 --> 00:23:26,000
following

00:23:23,200 --> 00:23:27,679
presto is going to have because uh the

00:23:26,000 --> 00:23:29,039
the nearer to real time you are when

00:23:27,679 --> 00:23:30,240
you're querying your data the more value

00:23:29,039 --> 00:23:32,240
the organization gets

00:23:30,240 --> 00:23:33,919
and the more exposure the system that's

00:23:32,240 --> 00:23:34,480
that's actually providing that value is

00:23:33,919 --> 00:23:35,760
going to get

00:23:34,480 --> 00:23:37,840
so that's something i'm very excited

00:23:35,760 --> 00:23:37,840
about

00:23:38,960 --> 00:23:43,039
i'm going to add just a little bit about

00:23:40,720 --> 00:23:44,960
what we as upsolver are working on

00:23:43,039 --> 00:23:46,320
so everything i talked about up until

00:23:44,960 --> 00:23:48,720
now is uh is

00:23:46,320 --> 00:23:51,520
ga so that's a up solver that you can

00:23:48,720 --> 00:23:54,159
buy off the shelf at the moment

00:23:51,520 --> 00:23:55,039
in the future in the near future so

00:23:54,159 --> 00:23:58,400
we're working on

00:23:55,039 --> 00:24:01,039
extending presto essentially adding

00:23:58,400 --> 00:24:04,080
support for

00:24:01,039 --> 00:24:06,000
mostly dmls and specifically inserts

00:24:04,080 --> 00:24:07,679
updates and deletes so adding update

00:24:06,000 --> 00:24:10,240
functionality entirely presto

00:24:07,679 --> 00:24:11,760
today doesn't have that syntax so adding

00:24:10,240 --> 00:24:14,000
that into presto

00:24:11,760 --> 00:24:15,760
inserts and deletes from the data lake

00:24:14,000 --> 00:24:16,240
in kind of a general way so today you

00:24:15,760 --> 00:24:18,880
have

00:24:16,240 --> 00:24:19,760
a very simple delete so you can run on

00:24:18,880 --> 00:24:22,559
hive

00:24:19,760 --> 00:24:24,320
but um being able to interact with your

00:24:22,559 --> 00:24:27,120
data lake as you would

00:24:24,320 --> 00:24:29,039
with a database opens up a lot of use

00:24:27,120 --> 00:24:30,880
cases which are very

00:24:29,039 --> 00:24:33,919
difficult today like for example gdpr

00:24:30,880 --> 00:24:35,520
being able to delete a specific user

00:24:33,919 --> 00:24:37,279
what's easier than running a delete

00:24:35,520 --> 00:24:38,880
command on top of the lake and

00:24:37,279 --> 00:24:41,279
having something happen that just makes

00:24:38,880 --> 00:24:43,039
it work of course that needs to be

00:24:41,279 --> 00:24:44,000
integrated with the storage layer in a

00:24:43,039 --> 00:24:47,919
very very

00:24:44,000 --> 00:24:49,679
tightly coupled way but using up solver

00:24:47,919 --> 00:24:51,600
and then using presto in order to

00:24:49,679 --> 00:24:53,600
actually do the interfacing

00:24:51,600 --> 00:24:55,360
and and run the commands you're going to

00:24:53,600 --> 00:24:58,880
be able to get kind of a whole

00:24:55,360 --> 00:24:59,919
uh holistic solution to that

00:24:58,880 --> 00:25:02,480
so that's something that we're very

00:24:59,919 --> 00:25:04,400
excited about um of course

00:25:02,480 --> 00:25:06,799
improving performance that's something

00:25:04,400 --> 00:25:09,520
that's always going to be a huge uh

00:25:06,799 --> 00:25:10,640
uh challenge and desire as performance

00:25:09,520 --> 00:25:14,240
gets better and this is

00:25:10,640 --> 00:25:16,880
on presto in the query layer uh

00:25:14,240 --> 00:25:17,279
query spin up time metadata discovery

00:25:16,880 --> 00:25:18,960
time

00:25:17,279 --> 00:25:20,880
all these things as performance gets

00:25:18,960 --> 00:25:23,440
better we're going to

00:25:20,880 --> 00:25:25,520
expose more and more use cases today

00:25:23,440 --> 00:25:25,919
presto is excellent for ad hoc queries

00:25:25,520 --> 00:25:29,039
and

00:25:25,919 --> 00:25:32,159
and analytics building kind of reporting

00:25:29,039 --> 00:25:34,400
um dashboards are often uh

00:25:32,159 --> 00:25:36,080
challenging because performance isn't

00:25:34,400 --> 00:25:37,679
quite there yet

00:25:36,080 --> 00:25:39,440
but hopefully very very soon the

00:25:37,679 --> 00:25:40,320
performance is going to get good enough

00:25:39,440 --> 00:25:43,120
that

00:25:40,320 --> 00:25:44,720
dashboarding as well can be served by uh

00:25:43,120 --> 00:25:46,559
by just presto

00:25:44,720 --> 00:25:48,000
um and i think that's the point where

00:25:46,559 --> 00:25:49,760
we're gonna see uh

00:25:48,000 --> 00:25:51,919
very massive adoption because that's

00:25:49,760 --> 00:25:54,480
pretty much the last use case that a

00:25:51,919 --> 00:25:56,080
uh analyst or a bi user is gonna be

00:25:54,480 --> 00:25:58,400
running

00:25:56,080 --> 00:26:00,240
on top of their data that today again

00:25:58,400 --> 00:26:01,200
you can do but it's not necessarily

00:26:00,240 --> 00:26:05,279
going to be the best

00:26:01,200 --> 00:26:05,279
uh the best fit great um

00:26:05,440 --> 00:26:13,360
oh yeah i don't have a clock

00:26:10,400 --> 00:26:14,240
awesome thank you so much yani uh great

00:26:13,360 --> 00:26:16,000
um

00:26:14,240 --> 00:26:17,440
a great presentation there are a couple

00:26:16,000 --> 00:26:20,000
of questions so i do want to

00:26:17,440 --> 00:26:21,039
uh ask those uh out so that our

00:26:20,000 --> 00:26:23,039
attendees

00:26:21,039 --> 00:26:25,440
get these answered here first question

00:26:23,039 --> 00:26:27,919
is why not just use presto kafka

00:26:25,440 --> 00:26:28,480
besides querying your offline data that

00:26:27,919 --> 00:26:31,120
need

00:26:28,480 --> 00:26:34,000
uh that needs one day to be batched to

00:26:31,120 --> 00:26:34,000
the warehouse

00:26:34,159 --> 00:26:39,120
so you're saying using presto and

00:26:36,799 --> 00:26:41,520
querying the data directly off of kafka

00:26:39,120 --> 00:26:43,200
yeah so presto has a kafka connector uh

00:26:41,520 --> 00:26:43,840
and that where you can stream directly

00:26:43,200 --> 00:26:46,000
off the

00:26:43,840 --> 00:26:47,840
of the kafka stream so i think that's

00:26:46,000 --> 00:26:50,480
that's what the question is about

00:26:47,840 --> 00:26:52,320
yeah so i'd say that there are two main

00:26:50,480 --> 00:26:53,919
issues with that the first is that it

00:26:52,320 --> 00:26:56,240
means that any ad hoc where you run

00:26:53,919 --> 00:26:58,559
is going to be putting pressure on your

00:26:56,240 --> 00:26:59,600
kafka cluster and kafka is very powerful

00:26:58,559 --> 00:27:01,840
as a system

00:26:59,600 --> 00:27:03,440
but it's also very sensitive often

00:27:01,840 --> 00:27:05,360
you're going to have it scaled for the

00:27:03,440 --> 00:27:07,120
ingestion and you don't really want

00:27:05,360 --> 00:27:08,559
querying to be ad hoc

00:27:07,120 --> 00:27:10,159
on on kafka you want to be always

00:27:08,559 --> 00:27:11,600
reading the tip

00:27:10,159 --> 00:27:13,440
um definitely you don't want to be

00:27:11,600 --> 00:27:15,039
reading a day of data out of kafka now

00:27:13,440 --> 00:27:16,720
i'm not saying that it's impossible

00:27:15,039 --> 00:27:19,039
there's also the challenge that if for

00:27:16,720 --> 00:27:20,080
example you're getting 100 000 events

00:27:19,039 --> 00:27:23,120
per second

00:27:20,080 --> 00:27:24,559
um getting an amount of data from kafka

00:27:23,120 --> 00:27:26,080
equal to a day of data

00:27:24,559 --> 00:27:27,360
is going to be it's going to take a very

00:27:26,080 --> 00:27:28,640
long time so you're not going to get

00:27:27,360 --> 00:27:30,240
kind of the query

00:27:28,640 --> 00:27:31,760
performance that you expect to get that

00:27:30,240 --> 00:27:33,679
you would get if it was in parquet

00:27:31,760 --> 00:27:36,080
format

00:27:33,679 --> 00:27:37,200
so i'd say like it's a combination of a

00:27:36,080 --> 00:27:39,200
lot of things

00:27:37,200 --> 00:27:41,200
but generally stitching together two

00:27:39,200 --> 00:27:42,640
solutions especially when one of them is

00:27:41,200 --> 00:27:46,240
not built to query

00:27:42,640 --> 00:27:48,880
real-time data um is you're gonna get

00:27:46,240 --> 00:27:50,799
kind of an iffy if you result all right

00:27:48,880 --> 00:27:51,120
and then one last question and we'll uh

00:27:50,799 --> 00:27:52,880
wrap

00:27:51,120 --> 00:27:54,799
up here uh how do you manage the

00:27:52,880 --> 00:27:56,640
partitioning keys for creating presto

00:27:54,799 --> 00:27:58,080
tables when adding new events you talked

00:27:56,640 --> 00:28:00,480
a little bit about it but

00:27:58,080 --> 00:28:03,039
uh and how do you evolve the schema of

00:28:00,480 --> 00:28:06,399
the partitioning key changes

00:28:03,039 --> 00:28:09,360
yeah so um upsolver basically manages

00:28:06,399 --> 00:28:11,440
metadata layer itself on s3 and that

00:28:09,360 --> 00:28:12,080
metadata as new events come in gets

00:28:11,440 --> 00:28:14,559
updated

00:28:12,080 --> 00:28:16,640
so if a new event comes in and that

00:28:14,559 --> 00:28:18,799
event has a new aws region

00:28:16,640 --> 00:28:21,039
um we're gonna have to add a partition

00:28:18,799 --> 00:28:22,720
immediately uh that maps to those new

00:28:21,039 --> 00:28:24,640
files so that's basically what upsolver

00:28:22,720 --> 00:28:26,480
does it manages the partitions

00:28:24,640 --> 00:28:27,919
and it's a bit more complicated than

00:28:26,480 --> 00:28:29,360
that that's really just a high level

00:28:27,919 --> 00:28:31,279
thing because

00:28:29,360 --> 00:28:33,120
in the end the partition is dynamic as

00:28:31,279 --> 00:28:34,960
you're running compactions the location

00:28:33,120 --> 00:28:36,960
of that partition changes over time

00:28:34,960 --> 00:28:38,000
so you both need to discover new

00:28:36,960 --> 00:28:40,240
partitions

00:28:38,000 --> 00:28:41,120
um you need to delete partitions that

00:28:40,240 --> 00:28:43,120
were

00:28:41,120 --> 00:28:44,799
retained out or all the data was deleted

00:28:43,120 --> 00:28:46,799
from them but also

00:28:44,799 --> 00:28:48,399
just existing partitions need to change

00:28:46,799 --> 00:28:50,320
their location as

00:28:48,399 --> 00:28:51,840
as compactions happen and you have kind

00:28:50,320 --> 00:28:53,919
of better copies of the data

00:28:51,840 --> 00:28:55,120
that need to be consumed and eventually

00:28:53,919 --> 00:28:55,760
you're going to be deleting the old data

00:28:55,120 --> 00:28:56,960
as well

00:28:55,760 --> 00:28:59,279
because you don't want to maintain a lot

00:28:56,960 --> 00:29:01,440
of copies of partitions

00:28:59,279 --> 00:29:01,440

YouTube URL: https://www.youtube.com/watch?v=XOldUGyHTlE


