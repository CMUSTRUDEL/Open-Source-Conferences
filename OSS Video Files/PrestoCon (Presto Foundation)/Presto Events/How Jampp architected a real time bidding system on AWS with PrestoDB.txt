Title: How Jampp architected a real time bidding system on AWS with PrestoDB
Publication date: 2020-07-15
Playlist: Presto Events
Description: 
	Dante Pawlow, Data Engineer at Jampp
Fede Palladoro, DevOps & Data Infrastructure Lead at Jampp

Jampp is a mobile app marketing platform that uses programmatic ads to acquire new users and retarget those users with relevant ads. It sits between advertisers and their audiences, so real time bidding of media advertising space is critical for their business. The amount of data Jampp generates as part of the bidding cycle is massive - 1.7B events are tracked per day, 550K/sec requests are received, and 100TB of data is processed by AWS elastic load balancers per day.

PrestoDB plays a critical role in their data infrastructure. Jampp relies on EMR Presto for their ad-hoc queries and performs over 3K ad-hoc queries/day on over 600TB of queryable data. In this presentation, Dante and Fede will show Jampp’s data architecture, how they’re training their machine learning algorithms directly from Presto to identify potential purchasers, and why Presto has become 24/7 critical to ensure ads are relevant to users.

Join the PrestoDB slack channel: https://prestodb.slack.com/
Join the PrestoDB meetup group: https://www.meetup.com/prestodb/
Follow us on Twitter: https://twitter.com/prestodb
Follow us on LinkedIn: https://www.linkedin.com/company/presto-foundation/
Captions: 
	00:00:00,160 --> 00:00:05,680
and we have um two speakers dante and

00:00:03,520 --> 00:00:08,000
fede uh let me do a quick introduction

00:00:05,680 --> 00:00:10,240
to them before i hand it over to them

00:00:08,000 --> 00:00:12,559
uh dante and perry are both from buna

00:00:10,240 --> 00:00:13,599
cyrus uh dante has been part of the data

00:00:12,559 --> 00:00:16,560
engineering team

00:00:13,599 --> 00:00:18,240
at jam for two uh two years uh but

00:00:16,560 --> 00:00:20,320
something interesting he mentioned that

00:00:18,240 --> 00:00:22,480
he's also a circus performer

00:00:20,320 --> 00:00:23,680
oh okay i don't know if we get to see

00:00:22,480 --> 00:00:25,680
anything today

00:00:23,680 --> 00:00:27,920
uh but you know it's good to know thank

00:00:25,680 --> 00:00:31,359
you for you know sharing that insight

00:00:27,920 --> 00:00:33,040
and fede is leading the devops and data

00:00:31,359 --> 00:00:35,520
infrastructure teams at jam

00:00:33,040 --> 00:00:37,600
and he's also from unifiers uh spent

00:00:35,520 --> 00:00:39,360
more than 10 years in the iit industry

00:00:37,600 --> 00:00:41,120
on infrastructure cloud and data

00:00:39,360 --> 00:00:42,719
solutions

00:00:41,120 --> 00:00:44,320
and i don't think he'll do any circus

00:00:42,719 --> 00:00:45,280
performance but he is a hiking

00:00:44,320 --> 00:00:47,680
enthusiast

00:00:45,280 --> 00:00:49,440
um you know seattle where i am also is a

00:00:47,680 --> 00:00:51,600
great place for hiking so if

00:00:49,440 --> 00:00:52,800
and when this covert thing gets over if

00:00:51,600 --> 00:00:55,360
you come this way

00:00:52,800 --> 00:00:56,719
we could go for a hike together and this

00:00:55,360 --> 00:00:58,800
couple of these little

00:00:56,719 --> 00:01:00,879
mountains that people climb here the

00:00:58,800 --> 00:01:02,960
mount sai which they use for prepping up

00:01:00,879 --> 00:01:05,760
for big mountain climbs as well

00:01:02,960 --> 00:01:07,520
so hopefully um you know we can get to

00:01:05,760 --> 00:01:08,320
see you in person one of these days but

00:01:07,520 --> 00:01:09,920
if not

00:01:08,320 --> 00:01:12,560
we'll continue with the meetup in a

00:01:09,920 --> 00:01:15,200
virtual format and i will

00:01:12,560 --> 00:01:16,320
stop sharing my screen and give you a

00:01:15,200 --> 00:01:19,759
chance to

00:01:16,320 --> 00:01:26,720
present your deck over to you then

00:01:19,759 --> 00:01:30,479
thanks amit so i'll share

00:01:26,720 --> 00:01:33,759
yeah um so hi uh i'm dante

00:01:30,479 --> 00:01:36,479
as amit said and i'm trained by feli

00:01:33,759 --> 00:01:37,520
and we'll be talking about using presto

00:01:36,479 --> 00:01:39,600
in a context of

00:01:37,520 --> 00:01:41,680
high volumes of data within a business

00:01:39,600 --> 00:01:42,960
model that has that has naturally low

00:01:41,680 --> 00:01:46,880
profit margins

00:01:42,960 --> 00:01:50,320
so optimizing for cost is uh crucial

00:01:46,880 --> 00:01:53,520
so um what do we do at champ

00:01:50,320 --> 00:01:54,000
we basically conduct programmatic mobile

00:01:53,520 --> 00:01:56,399
marketing

00:01:54,000 --> 00:01:58,240
campaigns and we have two campaign types

00:01:56,399 --> 00:01:59,920
a user acquisition to find more people

00:01:58,240 --> 00:02:02,159
to install and use an app

00:01:59,920 --> 00:02:03,759
and app retargeting to re-engage

00:02:02,159 --> 00:02:07,759
existing users

00:02:03,759 --> 00:02:09,280
so we do this through a real-time

00:02:07,759 --> 00:02:12,720
bidding system

00:02:09,280 --> 00:02:16,319
um in which whenever a nut spot is

00:02:12,720 --> 00:02:19,440
available in a in a device

00:02:16,319 --> 00:02:23,200
an exchange fires up an auction

00:02:19,440 --> 00:02:26,239
on in which jump participates

00:02:23,200 --> 00:02:29,200
this auction uh comes with some

00:02:26,239 --> 00:02:30,160
contextual data on the device so we can

00:02:29,200 --> 00:02:33,519
use the data

00:02:30,160 --> 00:02:36,720
with our um predicting algorithms

00:02:33,519 --> 00:02:40,160
to set a price for the for the bid

00:02:36,720 --> 00:02:42,879
and whether to bid or not um

00:02:40,160 --> 00:02:44,480
so when we decide all of this we send a

00:02:42,879 --> 00:02:47,519
bit and if we win

00:02:44,480 --> 00:02:48,840
we can show an impression or an ad at

00:02:47,519 --> 00:02:51,280
the

00:02:48,840 --> 00:02:53,760
device on this model

00:02:51,280 --> 00:02:55,920
uh oh sorry all of this has to be done

00:02:53,760 --> 00:02:58,400
in 70 milliseconds or less

00:02:55,920 --> 00:02:59,760
so there are actually millions of of

00:02:58,400 --> 00:03:02,879
auctions running on

00:02:59,760 --> 00:03:06,319
and at every given minute

00:03:02,879 --> 00:03:08,000
so um all of this leads to what we call

00:03:06,319 --> 00:03:10,560
the attack funnel

00:03:08,000 --> 00:03:13,040
as we saw the auction leads to a bid

00:03:10,560 --> 00:03:15,760
which is an impression and also

00:03:13,040 --> 00:03:17,120
then we have clicks and installs and

00:03:15,760 --> 00:03:20,959
events

00:03:17,120 --> 00:03:23,040
as you might imagine uh every step um

00:03:20,959 --> 00:03:24,159
doesn't necessarily continue the funnel

00:03:23,040 --> 00:03:27,280
so we

00:03:24,159 --> 00:03:29,680
not everybody it's an impression and not

00:03:27,280 --> 00:03:32,720
every impression is the click and so on

00:03:29,680 --> 00:03:34,239
so actually each step has an order of

00:03:32,720 --> 00:03:37,440
magnitude in decrease

00:03:34,239 --> 00:03:39,519
in volume um but also

00:03:37,440 --> 00:03:40,799
the data criticality increases increases

00:03:39,519 --> 00:03:43,760
with each step so

00:03:40,799 --> 00:03:45,360
installs and events are rare but very

00:03:43,760 --> 00:03:48,000
important

00:03:45,360 --> 00:03:50,000
to keep all the messages and information

00:03:48,000 --> 00:03:53,040
but auctions for example

00:03:50,000 --> 00:03:53,360
are very frequent and we actually don't

00:03:53,040 --> 00:03:55,680
need

00:03:53,360 --> 00:03:57,760
uh to store all of them so to optimize

00:03:55,680 --> 00:03:58,959
costs we actually sample auctions for

00:03:57,760 --> 00:04:01,920
example

00:03:58,959 --> 00:04:03,120
we store about 25 percent of them but we

00:04:01,920 --> 00:04:04,959
have to

00:04:03,120 --> 00:04:07,280
make sure that every click and every

00:04:04,959 --> 00:04:10,319
install and event is

00:04:07,280 --> 00:04:13,360
is safe and keep

00:04:10,319 --> 00:04:15,519
so uh giving all of this each tail has

00:04:13,360 --> 00:04:16,880
different access patterns uh because of

00:04:15,519 --> 00:04:18,799
the volume and the

00:04:16,880 --> 00:04:20,239
nature of the data so we need different

00:04:18,799 --> 00:04:23,440
partition schemes

00:04:20,239 --> 00:04:27,040
uh in each table um

00:04:23,440 --> 00:04:27,840
so uh going on to the data limitation on

00:04:27,040 --> 00:04:31,120
the table

00:04:27,840 --> 00:04:31,919
themselves we have one of them event

00:04:31,120 --> 00:04:34,320
type

00:04:31,919 --> 00:04:35,840
but we also have um many more event

00:04:34,320 --> 00:04:36,400
types we have organic installs and

00:04:35,840 --> 00:04:39,520
events

00:04:36,400 --> 00:04:42,080
which are those that occur naturally

00:04:39,520 --> 00:04:43,120
in the app whenever a user does

00:04:42,080 --> 00:04:45,199
something without

00:04:43,120 --> 00:04:46,160
an app that's an organic install or an

00:04:45,199 --> 00:04:48,880
event

00:04:46,160 --> 00:04:50,240
and those are sent to us from the

00:04:48,880 --> 00:04:52,639
clients

00:04:50,240 --> 00:04:53,280
we also have event types that are meant

00:04:52,639 --> 00:04:56,000
for

00:04:53,280 --> 00:04:56,720
tracking the performance of a campaign

00:04:56,000 --> 00:04:59,280
and

00:04:56,720 --> 00:05:00,479
we also have a bunch of tables that are

00:04:59,280 --> 00:05:03,520
denormalized

00:05:00,479 --> 00:05:05,600
data from every other table

00:05:03,520 --> 00:05:07,360
joints and unions that further down the

00:05:05,600 --> 00:05:10,400
line will increase

00:05:07,360 --> 00:05:13,520
queries will increase

00:05:10,400 --> 00:05:17,199
queries up speed quite soft

00:05:13,520 --> 00:05:20,320
so uh our data infrastructure

00:05:17,199 --> 00:05:21,199
um we have three steps basically in that

00:05:20,320 --> 00:05:25,120
injection

00:05:21,199 --> 00:05:28,560
that uh manipulation and data

00:05:25,120 --> 00:05:31,680
querying so for that injection we have

00:05:28,560 --> 00:05:33,520
our pipeline unit uh which

00:05:31,680 --> 00:05:34,880
it's basically a stream of data with an

00:05:33,520 --> 00:05:38,080
internal data source

00:05:34,880 --> 00:05:39,600
uh which sends the message to amazon

00:05:38,080 --> 00:05:42,880
guiness streams

00:05:39,600 --> 00:05:47,280
and through apache flume we store it

00:05:42,880 --> 00:05:48,320
in amazon s3 i call this a unit because

00:05:47,280 --> 00:05:50,960
we have one per

00:05:48,320 --> 00:05:52,400
event type we used to have them

00:05:50,960 --> 00:05:55,680
concentrated

00:05:52,400 --> 00:05:58,000
many event types for parkinson's stream

00:05:55,680 --> 00:05:59,919
for example but we've been focusing on

00:05:58,000 --> 00:06:01,759
modularity and separation of concerns

00:05:59,919 --> 00:06:04,000
which allows us to

00:06:01,759 --> 00:06:05,120
optimize for cost without fear of losing

00:06:04,000 --> 00:06:08,560
critical messages

00:06:05,120 --> 00:06:09,680
so going back to bits and clicks for

00:06:08,560 --> 00:06:12,800
example

00:06:09,680 --> 00:06:17,440
we can optimize the

00:06:12,800 --> 00:06:20,960
bid pipeline to minimize costs

00:06:17,440 --> 00:06:24,160
at the cost of reliability but um

00:06:20,960 --> 00:06:27,520
the the event and clicks pipeline

00:06:24,160 --> 00:06:31,199
is uh more much more robust

00:06:27,520 --> 00:06:32,240
so um and also something that i'd like

00:06:31,199 --> 00:06:34,400
to mention

00:06:32,240 --> 00:06:36,479
in this pipeline we we saved a lot of

00:06:34,400 --> 00:06:39,039
cost by replacing aws

00:06:36,479 --> 00:06:39,919
lambda plus fire hose with apache plume

00:06:39,039 --> 00:06:42,240
so

00:06:39,919 --> 00:06:44,720
i recommend to give it a try if you if

00:06:42,240 --> 00:06:48,240
you have some have something like this

00:06:44,720 --> 00:06:49,919
um so the next step is details on the

00:06:48,240 --> 00:06:52,639
insertion we do that

00:06:49,919 --> 00:06:54,639
with spark and hive and we also

00:06:52,639 --> 00:06:57,680
orchestrate it with airflow

00:06:54,639 --> 00:06:58,400
um sparge and hive are very reliable for

00:06:57,680 --> 00:07:01,759
etl's

00:06:58,400 --> 00:07:03,120
and insertion both run on top of yarn so

00:07:01,759 --> 00:07:07,280
they can leave together on the same

00:07:03,120 --> 00:07:08,800
aws emr cluster more on that later

00:07:07,280 --> 00:07:10,319
and we use the high vented store at the

00:07:08,800 --> 00:07:14,720
main interface within engines

00:07:10,319 --> 00:07:16,639
and also with presto so spark hype and

00:07:14,720 --> 00:07:18,880
presto all interface through the height

00:07:16,639 --> 00:07:21,199
of the store

00:07:18,880 --> 00:07:23,120
and also i'd like to mention that

00:07:21,199 --> 00:07:26,319
airflow is an amazing tool for scaling

00:07:23,120 --> 00:07:29,039
orchestration uh it's very flexible and

00:07:26,319 --> 00:07:32,400
robust and we use it a lot so i also

00:07:29,039 --> 00:07:35,520
recommend it giving it a try

00:07:32,400 --> 00:07:37,599
so we come to presto uh presa is

00:07:35,520 --> 00:07:40,560
basically our main interface

00:07:37,599 --> 00:07:41,440
with the the whole data warehouse uh

00:07:40,560 --> 00:07:45,039
internally we

00:07:41,440 --> 00:07:45,759
we use spark and hype to to move data

00:07:45,039 --> 00:07:47,440
around and

00:07:45,759 --> 00:07:48,800
to perform insertions and everything

00:07:47,440 --> 00:07:52,800
else but

00:07:48,800 --> 00:07:56,720
uh the querying of the data is basically

00:07:52,800 --> 00:07:58,800
almost exclusively done through presto

00:07:56,720 --> 00:08:00,080
either our team or every other team in

00:07:58,800 --> 00:08:02,080
the in the company

00:08:00,080 --> 00:08:04,000
and through the years it actually became

00:08:02,080 --> 00:08:05,440
very important for us to maintain a

00:08:04,000 --> 00:08:08,240
reliable presto

00:08:05,440 --> 00:08:08,560
because there are there are lots of of

00:08:08,240 --> 00:08:11,039
uh

00:08:08,560 --> 00:08:12,960
production ready applications that are

00:08:11,039 --> 00:08:15,520
using it constantly

00:08:12,960 --> 00:08:16,800
so we use it for output queries through

00:08:15,520 --> 00:08:19,520
apache superset

00:08:16,800 --> 00:08:20,960
or templating reports through a custom

00:08:19,520 --> 00:08:23,440
ui

00:08:20,960 --> 00:08:24,639
filling our machine learning algorithms

00:08:23,440 --> 00:08:26,720
um

00:08:24,639 --> 00:08:29,039
constructing the data sets monitoring

00:08:26,720 --> 00:08:31,759
data quality with a custom tool

00:08:29,039 --> 00:08:32,800
uh building automatic audience segments

00:08:31,759 --> 00:08:35,839
and and

00:08:32,800 --> 00:08:38,800
lots of more stuff so

00:08:35,839 --> 00:08:39,599
basically it's the the only way the data

00:08:38,800 --> 00:08:43,039
comes on

00:08:39,599 --> 00:08:46,720
or goes it square it from the

00:08:43,039 --> 00:08:50,000
data warehouse and some

00:08:46,720 --> 00:08:50,640
numbers to exemplify uh all of these we

00:08:50,000 --> 00:08:53,519
have

00:08:50,640 --> 00:08:55,040
lots of feed requests we have sent 100

00:08:53,519 --> 00:08:57,519
000 of them per second

00:08:55,040 --> 00:08:58,320
not all of them go through the full

00:08:57,519 --> 00:09:01,360
funnel

00:08:58,320 --> 00:09:05,519
but uh many of them become

00:09:01,360 --> 00:09:09,360
bits impressions clicks etc

00:09:05,519 --> 00:09:09,839
so we have a lot of a lot of data moving

00:09:09,360 --> 00:09:13,760
around

00:09:09,839 --> 00:09:16,880
and we we sometimes we have

00:09:13,760 --> 00:09:20,560
over uh 1 000 queries per hour

00:09:16,880 --> 00:09:21,279
uh obviously it it goes ups and down

00:09:20,560 --> 00:09:24,640
depending on

00:09:21,279 --> 00:09:25,440
the data science teams and everything

00:09:24,640 --> 00:09:28,640
else but

00:09:25,440 --> 00:09:32,080
we have uh we have to be able to

00:09:28,640 --> 00:09:33,519
to perform uh plus 1000 queries per hour

00:09:32,080 --> 00:09:36,480
to do that we have three playstore

00:09:33,519 --> 00:09:38,640
clusters one for production uh

00:09:36,480 --> 00:09:40,320
applications one for output queries and

00:09:38,640 --> 00:09:43,360
and and another one for

00:09:40,320 --> 00:09:46,399
uh our machine learning uh

00:09:43,360 --> 00:09:50,640
experimented experiments and and

00:09:46,399 --> 00:09:52,959
data training uh sorry model training um

00:09:50,640 --> 00:09:54,240
and the interesting part of this is that

00:09:52,959 --> 00:09:57,839
we we have that

00:09:54,240 --> 00:09:58,560
on cluster running on on spot instances

00:09:57,839 --> 00:10:01,839
with

00:09:58,560 --> 00:10:02,720
a custom autoscaling so we we oscillate

00:10:01,839 --> 00:10:06,160
between

00:10:02,720 --> 00:10:09,440
30 and 100 workers

00:10:06,160 --> 00:10:12,079
working instances and

00:10:09,440 --> 00:10:13,519
fede we'll talk more about this which i

00:10:12,079 --> 00:10:16,000
think it's it's

00:10:13,519 --> 00:10:17,200
one of the most interesting things we we

00:10:16,000 --> 00:10:21,200
have been doing to

00:10:17,200 --> 00:10:26,160
to cut costs at jumps so i'll stop

00:10:21,200 --> 00:10:28,640
presenting and hand it to

00:10:26,160 --> 00:10:32,320
great thank you dante i will start

00:10:28,640 --> 00:10:37,200
presenting myself

00:10:32,320 --> 00:10:37,200
uh so there we go you should be

00:10:37,360 --> 00:10:40,399
just a second please

00:10:40,880 --> 00:10:43,920
there you go you should be seeing my my

00:10:42,480 --> 00:10:46,959
slide so

00:10:43,920 --> 00:10:49,839
as i said i will talk about

00:10:46,959 --> 00:10:51,680
uh how we manage our breast clusters and

00:10:49,839 --> 00:10:52,800
our concerns regarding cost efficiency

00:10:51,680 --> 00:10:55,200
of them

00:10:52,800 --> 00:10:57,040
and on top of that how we monitor and

00:10:55,200 --> 00:11:00,959
how we ensure that the service is

00:10:57,040 --> 00:11:04,560
available for the whole company

00:11:00,959 --> 00:11:05,920
so and if we start to to talk about the

00:11:04,560 --> 00:11:09,600
cluster management

00:11:05,920 --> 00:11:11,360
the central component of our setup

00:11:09,600 --> 00:11:14,560
relies on on aws

00:11:11,360 --> 00:11:15,120
elastic map reviews or vmr for short in

00:11:14,560 --> 00:11:16,800
case

00:11:15,120 --> 00:11:18,240
someone doesn't know it you match the

00:11:16,800 --> 00:11:20,640
als service to help

00:11:18,240 --> 00:11:22,240
evolution and manage the big data

00:11:20,640 --> 00:11:24,160
clusters for a lot of mainstream

00:11:22,240 --> 00:11:26,640
applications used in the industry like

00:11:24,160 --> 00:11:28,720
hive and spark and of course crystalline

00:11:26,640 --> 00:11:30,880
in this case

00:11:28,720 --> 00:11:32,000
and i want to clarify the goods on the

00:11:30,880 --> 00:11:35,360
box

00:11:32,000 --> 00:11:37,120
new small highlights and

00:11:35,360 --> 00:11:39,519
the benefits are pretty clear you can

00:11:37,120 --> 00:11:40,640
find you find them everywhere

00:11:39,519 --> 00:11:42,320
you can provision a cluster with a

00:11:40,640 --> 00:11:43,680
couple of clicks it's super simple to to

00:11:42,320 --> 00:11:46,959
spin up new clusters

00:11:43,680 --> 00:11:48,800
it has flexibility to turn to tune sorry

00:11:46,959 --> 00:11:51,360
the whole cluster and every application

00:11:48,800 --> 00:11:53,680
with a unified interface that

00:11:51,360 --> 00:11:54,800
makes the living much more easier for

00:11:53,680 --> 00:11:57,519
for the

00:11:54,800 --> 00:11:59,120
my devops part my daughter's role so

00:11:57,519 --> 00:12:02,959
it's it's a breeze

00:11:59,120 --> 00:12:04,639
and like every aws service it has a

00:12:02,959 --> 00:12:06,560
great integration with the rest of the

00:12:04,639 --> 00:12:09,680
the ecosystem so

00:12:06,560 --> 00:12:12,160
uh you can natively integrate like with

00:12:09,680 --> 00:12:13,440
s3 drivers with dynamodb with glue for

00:12:12,160 --> 00:12:16,720
example for metadata

00:12:13,440 --> 00:12:18,320
and stuff like that and they from time

00:12:16,720 --> 00:12:19,360
to time they add new applications to the

00:12:18,320 --> 00:12:21,920
catalog so

00:12:19,360 --> 00:12:24,160
you surely will find that brand new

00:12:21,920 --> 00:12:24,800
application that is being used in the

00:12:24,160 --> 00:12:27,839
industry

00:12:24,800 --> 00:12:28,399
eventually will be added to emr so it's

00:12:27,839 --> 00:12:31,040
very good

00:12:28,399 --> 00:12:33,440
to be already integrated with mr and

00:12:31,040 --> 00:12:36,800
just one click you you already have that

00:12:33,440 --> 00:12:38,800
obligation for example so

00:12:36,800 --> 00:12:39,839
but what about the part of the not so

00:12:38,800 --> 00:12:41,040
good part that

00:12:39,839 --> 00:12:43,040
that the the things that you will

00:12:41,040 --> 00:12:46,480
probably find on a production cluster on

00:12:43,040 --> 00:12:46,480
a saturday at cim right

00:12:46,800 --> 00:12:53,040
the dark issues that no way talk about

00:12:49,839 --> 00:12:55,600
so the first of all the it's a bad idea

00:12:53,040 --> 00:12:57,760
to mix yarn-based applications with

00:12:55,600 --> 00:13:00,240
applications using the ring their own

00:12:57,760 --> 00:13:02,880
scaler like question b in this case

00:13:00,240 --> 00:13:03,360
and that's because each of them will use

00:13:02,880 --> 00:13:05,200
will

00:13:03,360 --> 00:13:06,959
assume that they have the control of the

00:13:05,200 --> 00:13:08,959
whole cluster uh

00:13:06,959 --> 00:13:11,200
and nothing nothing got nothing good

00:13:08,959 --> 00:13:14,880
could ever come from the

00:13:11,200 --> 00:13:18,000
very bad idea another thing it's

00:13:14,880 --> 00:13:19,040
a missing feature particular that became

00:13:18,000 --> 00:13:21,680
important for us

00:13:19,040 --> 00:13:23,040
is the usage of auto scaling on on

00:13:21,680 --> 00:13:25,360
instant flips

00:13:23,040 --> 00:13:26,800
i will talk about this in a little later

00:13:25,360 --> 00:13:30,000
but

00:13:26,800 --> 00:13:32,800
you can set a auto scaling or

00:13:30,000 --> 00:13:34,000
you can use instance fleet but not both

00:13:32,800 --> 00:13:35,680
there are not compatible

00:13:34,000 --> 00:13:37,760
between each other so there's an issue

00:13:35,680 --> 00:13:39,600
there

00:13:37,760 --> 00:13:41,519
and regarding brexit in particular we

00:13:39,600 --> 00:13:43,920
find two issues one

00:13:41,519 --> 00:13:45,600
is that the upgrade frequency is kind of

00:13:43,920 --> 00:13:47,680
slow

00:13:45,600 --> 00:13:50,160
i mean the depressed is moving pretty

00:13:47,680 --> 00:13:53,360
fast and and the official releases is

00:13:50,160 --> 00:13:53,760
it's it's very quick uh and emr is kind

00:13:53,360 --> 00:13:56,160
of

00:13:53,760 --> 00:13:57,040
behind that the those releases for

00:13:56,160 --> 00:13:59,519
example

00:13:57,040 --> 00:14:00,560
in the last dmr version in five three

00:13:59,519 --> 00:14:03,600
zero zero

00:14:00,560 --> 00:14:06,720
uh you have prison db 0 to

00:14:03,600 --> 00:14:09,199
32 sorry while the the last piece of db

00:14:06,720 --> 00:14:11,440
version is 0 to 37 so

00:14:09,199 --> 00:14:13,040
if you are expecting that bug fix that

00:14:11,440 --> 00:14:15,199
new feature that presto

00:14:13,040 --> 00:14:16,160
just released you may have to wait a

00:14:15,199 --> 00:14:19,279
couple of months

00:14:16,160 --> 00:14:21,839
or or weeks at least until emr released

00:14:19,279 --> 00:14:25,360
that on on their version

00:14:21,839 --> 00:14:26,240
uh and on the other hand and emr lacks

00:14:25,360 --> 00:14:28,160
of support

00:14:26,240 --> 00:14:30,160
for a presto db integration with

00:14:28,160 --> 00:14:32,560
cloudwatch via the monitoring solution

00:14:30,160 --> 00:14:33,760
on aws so you have almost zero

00:14:32,560 --> 00:14:36,480
visibility of

00:14:33,760 --> 00:14:38,079
how presto is running i mean how many

00:14:36,480 --> 00:14:39,120
queries is running if the queries are

00:14:38,079 --> 00:14:42,560
taking too long

00:14:39,120 --> 00:14:45,040
how much memory the cluster has occupied

00:14:42,560 --> 00:14:45,760
and stuff like that so you have to do it

00:14:45,040 --> 00:14:48,240
on our own

00:14:45,760 --> 00:14:50,639
i i will talk about this in a couple of

00:14:48,240 --> 00:14:50,639
slides

00:14:51,199 --> 00:14:55,199
so um regarding the our emr clusters in

00:14:54,399 --> 00:14:57,440
particular

00:14:55,199 --> 00:14:58,800
and this is how we design them and how

00:14:57,440 --> 00:15:00,959
we're running

00:14:58,800 --> 00:15:02,160
on on one side we have a single etl

00:15:00,959 --> 00:15:04,639
cluster with spark

00:15:02,160 --> 00:15:05,760
hive and test like i said before that

00:15:04,639 --> 00:15:08,320
those applications

00:15:05,760 --> 00:15:10,480
are yarn based so we can live together

00:15:08,320 --> 00:15:12,079
and coexist in the same cluster

00:15:10,480 --> 00:15:14,880
and as accidentally said we are using

00:15:12,079 --> 00:15:18,000
them for for running our rtl workloads

00:15:14,880 --> 00:15:20,480
and uh on the other side on the other

00:15:18,000 --> 00:15:22,160
side sorry um depending on the workload

00:15:20,480 --> 00:15:25,440
we have two or three

00:15:22,160 --> 00:15:27,120
presto clusters uh to target different

00:15:25,440 --> 00:15:29,040
kind of queries uh

00:15:27,120 --> 00:15:30,720
like i hope queries like like mentioned

00:15:29,040 --> 00:15:32,480
don't tell like the the feeding the

00:15:30,720 --> 00:15:35,759
machine learnings training and

00:15:32,480 --> 00:15:38,839
and generation of models uh and

00:15:35,759 --> 00:15:40,480
other production level or staging

00:15:38,839 --> 00:15:43,440
workloads

00:15:40,480 --> 00:15:45,360
uh one important aspect in in in that

00:15:43,440 --> 00:15:46,720
you know this is that we store our data

00:15:45,360 --> 00:15:49,120
on the three yeah

00:15:46,720 --> 00:15:51,120
we have decoupled the the storage layer

00:15:49,120 --> 00:15:52,639
from the computing so we are not using

00:15:51,120 --> 00:15:56,000
hdfs like

00:15:52,639 --> 00:15:59,759
like the standard maybe a solution

00:15:56,000 --> 00:16:02,880
and and that's allowed us to to

00:15:59,759 --> 00:16:05,440
to easily scale the compute layer i mean

00:16:02,880 --> 00:16:08,160
it's just instances and compute power

00:16:05,440 --> 00:16:08,880
that you can easily scale on demand

00:16:08,160 --> 00:16:11,839
depending on

00:16:08,880 --> 00:16:13,600
on your workload and the storage uh you

00:16:11,839 --> 00:16:16,399
we are leveraging

00:16:13,600 --> 00:16:17,360
the practically infinite scalability of

00:16:16,399 --> 00:16:20,480
the three right

00:16:17,360 --> 00:16:24,000
to store as much data as we

00:16:20,480 --> 00:16:26,800
want uh to have to give an example

00:16:24,000 --> 00:16:28,240
about the numbers that dante said before

00:16:26,800 --> 00:16:32,160
we are storing like

00:16:28,240 --> 00:16:35,519
600 terabytes of queryable data so

00:16:32,160 --> 00:16:36,079
that's a lot and that's a great use case

00:16:35,519 --> 00:16:38,560
for for

00:16:36,079 --> 00:16:38,560
resto

00:16:39,519 --> 00:16:43,199
so like like we said before each cluster

00:16:42,320 --> 00:16:44,959
is um

00:16:43,199 --> 00:16:46,880
auto scalable depending on how many

00:16:44,959 --> 00:16:47,279
queries or how many homicides are

00:16:46,880 --> 00:16:49,279
running

00:16:47,279 --> 00:16:51,360
or pending depending on on the on the

00:16:49,279 --> 00:16:54,880
use case i will talk about

00:16:51,360 --> 00:16:58,320
this later and we also have to share

00:16:54,880 --> 00:17:00,320
shared services between every cluster

00:16:58,320 --> 00:17:01,440
those are the the metadata store that

00:17:00,320 --> 00:17:04,319
where we

00:17:01,440 --> 00:17:06,319
store the table schemas and and the the

00:17:04,319 --> 00:17:07,839
partitioning information

00:17:06,319 --> 00:17:09,919
the metadata information about those

00:17:07,839 --> 00:17:13,120
tables we store them on my

00:17:09,919 --> 00:17:15,919
mysql database running on rds

00:17:13,120 --> 00:17:18,000
and a dynamodb table to handle the mrfs

00:17:15,919 --> 00:17:19,839
constituting checks

00:17:18,000 --> 00:17:21,199
i don't want to to extend too much on

00:17:19,839 --> 00:17:24,799
this but

00:17:21,199 --> 00:17:26,079
s3 is eventually conscious consistent

00:17:24,799 --> 00:17:29,120
sorry

00:17:26,079 --> 00:17:31,600
internally so if you plan to

00:17:29,120 --> 00:17:32,960
do rights and immediate reads on on the

00:17:31,600 --> 00:17:35,760
data you could not find

00:17:32,960 --> 00:17:37,200
already there so you have to to manage

00:17:35,760 --> 00:17:39,760
an external key value to

00:17:37,200 --> 00:17:41,679
use sorry an external key value to to

00:17:39,760 --> 00:17:45,360
manage those constitute checks

00:17:41,679 --> 00:17:48,480
and and and implement

00:17:45,360 --> 00:17:52,080
a mechanism of retries if you don't find

00:17:48,480 --> 00:17:56,080
a file that you just write

00:17:52,080 --> 00:17:57,280
and that's emrss it's it's almost

00:17:56,080 --> 00:17:59,679
transparent you don't have to do

00:17:57,280 --> 00:18:02,320
anything about that

00:17:59,679 --> 00:18:03,760
so moving to to how we tune and and set

00:18:02,320 --> 00:18:07,360
up our armor clusters we have

00:18:03,760 --> 00:18:09,520
a freight feature there called called

00:18:07,360 --> 00:18:11,840
bootstrap scripts that allow us to run

00:18:09,520 --> 00:18:14,960
bash scripts on each node

00:18:11,840 --> 00:18:15,600
when when it's provisioned we can

00:18:14,960 --> 00:18:18,160
control

00:18:15,600 --> 00:18:19,200
the execution order of those scripts so

00:18:18,160 --> 00:18:21,840
uh

00:18:19,200 --> 00:18:22,640
you you can ensure that or it's more

00:18:21,840 --> 00:18:24,559
probably that

00:18:22,640 --> 00:18:26,240
your script will be executed just the

00:18:24,559 --> 00:18:28,400
same moment that the software

00:18:26,240 --> 00:18:31,760
application is being provisioned

00:18:28,400 --> 00:18:34,320
so probably when when the

00:18:31,760 --> 00:18:36,240
this bash scripts are executed presto is

00:18:34,320 --> 00:18:40,080
not even started yet so

00:18:36,240 --> 00:18:42,960
if you plan to modify

00:18:40,080 --> 00:18:45,039
a file a configuration file or or write

00:18:42,960 --> 00:18:46,799
a file in a directory of

00:18:45,039 --> 00:18:48,960
inside of presto configuration for

00:18:46,799 --> 00:18:51,200
example uh those elements

00:18:48,960 --> 00:18:52,559
are not there yet so you have to

00:18:51,200 --> 00:18:57,360
implement some mechanism

00:18:52,559 --> 00:19:00,080
i will talk about this in in a minute um

00:18:57,360 --> 00:19:00,480
and in our case we use those to do both

00:19:00,080 --> 00:19:02,720
track

00:19:00,480 --> 00:19:04,240
scripts to handle uh some parameters

00:19:02,720 --> 00:19:05,200
that are not supported from emr

00:19:04,240 --> 00:19:08,720
interface

00:19:05,200 --> 00:19:12,000
uh for example the the jbl

00:19:08,720 --> 00:19:15,280
jbm config file sorry and

00:19:12,000 --> 00:19:17,520
some os level parameters and

00:19:15,280 --> 00:19:19,760
and we also use these scripts to install

00:19:17,520 --> 00:19:21,919
use the user defined functions like

00:19:19,760 --> 00:19:23,120
for example custom code that we

00:19:21,919 --> 00:19:26,400
developed

00:19:23,120 --> 00:19:27,200
and we also some some of them are open

00:19:26,400 --> 00:19:30,559
source

00:19:27,200 --> 00:19:32,640
to to improve the performance of some

00:19:30,559 --> 00:19:36,840
queries and some particular use case

00:19:32,640 --> 00:19:38,000
to to better analyze information more

00:19:36,840 --> 00:19:41,280
data

00:19:38,000 --> 00:19:42,480
so as i said before um we will be

00:19:41,280 --> 00:19:45,360
running the website crypt

00:19:42,480 --> 00:19:47,520
before presto is installed so we can

00:19:45,360 --> 00:19:50,240
modify the those those files

00:19:47,520 --> 00:19:50,880
the the most useful case you can see it

00:19:50,240 --> 00:19:54,240
in

00:19:50,880 --> 00:19:56,919
in this in this slide and

00:19:54,240 --> 00:19:58,880
the that where we're modifying the the

00:19:56,919 --> 00:20:01,440
jbm.config file uh

00:19:58,880 --> 00:20:03,280
to to for example replace the the garage

00:20:01,440 --> 00:20:06,480
collector setting

00:20:03,280 --> 00:20:10,480
and anything related to

00:20:06,480 --> 00:20:11,760
to that file and the hat we we have to

00:20:10,480 --> 00:20:12,480
do is what you're seeing at the

00:20:11,760 --> 00:20:15,360
admission

00:20:12,480 --> 00:20:15,840
at the first lines of the script and is

00:20:15,360 --> 00:20:18,720
that we

00:20:15,840 --> 00:20:21,760
in in fact we are creating a background

00:20:18,720 --> 00:20:24,880
script using bash here documents yeah

00:20:21,760 --> 00:20:25,440
here docs and underscript will be

00:20:24,880 --> 00:20:27,600
looping

00:20:25,440 --> 00:20:29,360
in background until presto is starting

00:20:27,600 --> 00:20:32,240
uh while uh yeah

00:20:29,360 --> 00:20:32,799
while we're checking the bid file once

00:20:32,240 --> 00:20:34,960
the

00:20:32,799 --> 00:20:37,120
the services started we do whatever the

00:20:34,960 --> 00:20:39,600
task we need i unpressed the final and

00:20:37,120 --> 00:20:42,799
finally we'll restart presto

00:20:39,600 --> 00:20:42,799
to to apply the changes

00:20:44,799 --> 00:20:48,000
so moving up going to the the cost

00:20:47,039 --> 00:20:51,280
efficient part

00:20:48,000 --> 00:20:52,880
um dante mentioned mentioned before that

00:20:51,280 --> 00:20:54,640
we have some cost restrictions due to

00:20:52,880 --> 00:20:56,159
low margin industry

00:20:54,640 --> 00:20:57,919
that challenge force us to leverage

00:20:56,159 --> 00:20:59,840
design patterns to reduce

00:20:57,919 --> 00:21:00,960
infrastructure cost whenever it's

00:20:59,840 --> 00:21:02,640
possible

00:21:00,960 --> 00:21:04,240
and if we're talking about reducing

00:21:02,640 --> 00:21:07,039
costs not nothing big

00:21:04,240 --> 00:21:08,880
beats the usage of spot instances uh for

00:21:07,039 --> 00:21:10,559
the ones who don't know them the the

00:21:08,880 --> 00:21:12,720
spot instances are similar to

00:21:10,559 --> 00:21:14,159
to regular on demand instances but with

00:21:12,720 --> 00:21:16,640
the particularly that

00:21:14,159 --> 00:21:17,200
aws could reclaim that instance in any

00:21:16,640 --> 00:21:20,799
time

00:21:17,200 --> 00:21:23,679
killing it and in return aws sells

00:21:20,799 --> 00:21:25,120
the these spot instances to a much lower

00:21:23,679 --> 00:21:27,679
and dynamic price

00:21:25,120 --> 00:21:28,799
based on a supply demand balance and

00:21:27,679 --> 00:21:31,280
when i say

00:21:28,799 --> 00:21:33,200
much lower is like 80 percent lower so

00:21:31,280 --> 00:21:35,919
it's a lot

00:21:33,200 --> 00:21:37,039
the issue is that the spot instances are

00:21:35,919 --> 00:21:39,120
ignorantly

00:21:37,039 --> 00:21:40,720
unstable so we have to define our

00:21:39,120 --> 00:21:42,960
solution with that in mind

00:21:40,720 --> 00:21:44,240
one particular recommendation also given

00:21:42,960 --> 00:21:47,039
by the ls is to

00:21:44,240 --> 00:21:49,280
diversify diversification or some

00:21:47,039 --> 00:21:52,559
families because of a scenario of ma

00:21:49,280 --> 00:21:55,840
of massive killing of instances

00:21:52,559 --> 00:21:58,480
and are mostly scoped to one instant

00:21:55,840 --> 00:22:00,400
in particular so when you have multiple

00:21:58,480 --> 00:22:03,039
instances you reduce that chance of of

00:22:00,400 --> 00:22:05,200
killing your your whole cluster

00:22:03,039 --> 00:22:06,159
uh fedex uh we should be starting up

00:22:05,200 --> 00:22:10,000
shortly

00:22:06,159 --> 00:22:10,000
okay okay i will speed up and

00:22:10,880 --> 00:22:15,679
okay well i will uh a passing moving to

00:22:13,679 --> 00:22:18,080
to total scaling

00:22:15,679 --> 00:22:19,200
we we found that our ad hoc clusters

00:22:18,080 --> 00:22:23,039
should be

00:22:19,200 --> 00:22:24,960
are are uh are defined by a usage

00:22:23,039 --> 00:22:27,760
pattern very focused on use it

00:22:24,960 --> 00:22:29,760
on office hours so uh trying to reduce

00:22:27,760 --> 00:22:31,919
the size of those clusters will

00:22:29,760 --> 00:22:32,880
reduce up to or save up to seventy

00:22:31,919 --> 00:22:35,360
percent of

00:22:32,880 --> 00:22:37,360
our known hours per month so out of

00:22:35,360 --> 00:22:40,400
screening is a big feature

00:22:37,360 --> 00:22:43,280
to sum up uh everything

00:22:40,400 --> 00:22:44,000
we are facing here will allow us to

00:22:43,280 --> 00:22:46,480
reduce

00:22:44,000 --> 00:22:48,480
uh or compare what was spending on an

00:22:46,480 --> 00:22:51,840
on-demand cluster of a fixed site

00:22:48,480 --> 00:22:53,600
let's say for example 100 nodes versus

00:22:51,840 --> 00:22:54,720
an auto scaling cluster with spot

00:22:53,600 --> 00:22:57,120
instances

00:22:54,720 --> 00:22:58,320
we can see here that we were spending

00:22:57,120 --> 00:23:01,280
over comparing

00:22:58,320 --> 00:23:02,000
a cluster of 52 cases per month versus

00:23:01,280 --> 00:23:03,919
just

00:23:02,000 --> 00:23:05,120
9k per month that's that's a lot of

00:23:03,919 --> 00:23:08,400
money so

00:23:05,120 --> 00:23:11,600
it really does worth it

00:23:08,400 --> 00:23:15,039
how we implement the auto tailor i will

00:23:11,600 --> 00:23:15,760
pass very fast for this uh we implement

00:23:15,039 --> 00:23:18,080
our custom

00:23:15,760 --> 00:23:19,280
solution for auto scaling based on a

00:23:18,080 --> 00:23:22,480
serverless

00:23:19,280 --> 00:23:25,600
mix of service uh an

00:23:22,480 --> 00:23:28,080
an a central engine with lambda

00:23:25,600 --> 00:23:28,880
to scale the to tweak decisions when to

00:23:28,080 --> 00:23:30,799
scale

00:23:28,880 --> 00:23:32,159
based on information from cloud watch

00:23:30,799 --> 00:23:35,440
alarms and

00:23:32,159 --> 00:23:37,520
a parameter and state storage on on lana

00:23:35,440 --> 00:23:39,840
motivia's key value

00:23:37,520 --> 00:23:40,799
and the decision when when lambda

00:23:39,840 --> 00:23:42,799
decides to

00:23:40,799 --> 00:23:44,159
to that the that the cluster needs to be

00:23:42,799 --> 00:23:46,720
scaled up or down

00:23:44,159 --> 00:23:48,799
it just modifies the instance fleet

00:23:46,720 --> 00:23:52,480
parameter on the cluster

00:23:48,799 --> 00:23:52,480
changing the cluster size basically

00:23:53,120 --> 00:23:58,640
i have to to move along but we

00:23:56,240 --> 00:24:00,000
we monitor all of this with a solution

00:23:58,640 --> 00:24:03,360
with prometheus

00:24:00,000 --> 00:24:04,720
three promises with two exporters one

00:24:03,360 --> 00:24:08,880
low-level exporter

00:24:04,720 --> 00:24:12,480
on jmx and one high-level exporter using

00:24:08,880 --> 00:24:14,480
an https creator the low level

00:24:12,480 --> 00:24:16,880
as i said use jmx to get the data and

00:24:14,480 --> 00:24:17,679
the high level use the presto http

00:24:16,880 --> 00:24:20,400
endpoints uh

00:24:17,679 --> 00:24:21,840
v1 cluster and d1 query so to get what

00:24:20,400 --> 00:24:22,559
queries have been executed and get

00:24:21,840 --> 00:24:25,679
counters

00:24:22,559 --> 00:24:28,159
of uh what information

00:24:25,679 --> 00:24:30,640
what what our users are using on the on

00:24:28,159 --> 00:24:30,640
the cluster

00:24:30,799 --> 00:24:34,240
here are just examples examples of what

00:24:33,039 --> 00:24:36,720
we are um

00:24:34,240 --> 00:24:37,840
querying as i said lower and high level

00:24:36,720 --> 00:24:41,360
i move

00:24:37,840 --> 00:24:42,960
along and for closing

00:24:41,360 --> 00:24:44,559
our next steps what we are trying

00:24:42,960 --> 00:24:47,360
planning to do uh

00:24:44,559 --> 00:24:48,400
one is upgrade to mr60 that it comes

00:24:47,360 --> 00:24:50,880
with apache

00:24:48,400 --> 00:24:52,480
a good halo and a high on amazon linux

00:24:50,880 --> 00:24:55,520
does almost minus two

00:24:52,480 --> 00:24:57,520
sorry about that uh we plan to to

00:24:55,520 --> 00:24:59,520
orchestrate our own pre-stock cluster

00:24:57,520 --> 00:25:02,640
using standalone institutions

00:24:59,520 --> 00:25:04,000
i mean without emr er

00:25:02,640 --> 00:25:06,000
we're trying to open source on

00:25:04,000 --> 00:25:07,039
components like scalar and exporters

00:25:06,000 --> 00:25:10,159
like i mentioned

00:25:07,039 --> 00:25:12,640
and and that's it that

00:25:10,159 --> 00:25:13,600
are kind of minor the last one is very

00:25:12,640 --> 00:25:15,520
important

00:25:13,600 --> 00:25:17,279
we're planning to move air flow to to

00:25:15,520 --> 00:25:19,919
docker on containers uh

00:25:17,279 --> 00:25:21,760
with with no math and all kubernetes are

00:25:19,919 --> 00:25:24,799
registered

00:25:21,760 --> 00:25:29,760
that's it sorry for the last rush but

00:25:24,799 --> 00:25:29,760
i think we have two minutes for q a uh

00:25:30,080 --> 00:25:34,080
sorry except for it for no no no worries

00:25:32,480 --> 00:25:37,120
thank you dante and uh

00:25:34,080 --> 00:25:38,559
uh what we can do is uh you know while

00:25:37,120 --> 00:25:39,200
you look at some of the questions as

00:25:38,559 --> 00:25:41,440
they come in

00:25:39,200 --> 00:25:42,960
uh we will have uh the twitter team come

00:25:41,440 --> 00:25:43,679
and do their part as well so that you

00:25:42,960 --> 00:25:46,080
know they get

00:25:43,679 --> 00:25:47,520
enough time and you'll have time to you

00:25:46,080 --> 00:25:51,039
know answer questions together

00:25:47,520 --> 00:25:54,159
at the end if that's okay um so

00:25:51,039 --> 00:25:56,720
i if you can stop sharing then i can

00:25:54,159 --> 00:25:59,600
share my screen and introduce okay our

00:25:56,720 --> 00:25:59,600
next speakers

00:26:00,159 --> 00:26:05,760
um second place

00:26:06,720 --> 00:26:12,799
my did window move into a full screen

00:26:10,559 --> 00:26:12,799
mode

00:26:13,360 --> 00:26:16,559
i think you're still sharing but sharing

00:26:15,279 --> 00:26:19,840
yeah your desktop

00:26:16,559 --> 00:26:23,919
sorry there you go okay thank you

00:26:19,840 --> 00:26:25,200
i will start and while people can ask

00:26:23,919 --> 00:26:26,640
their questions we'll either try and

00:26:25,200 --> 00:26:30,640
answer them online or

00:26:26,640 --> 00:26:30,640

YouTube URL: https://www.youtube.com/watch?v=JQsFDVBwinA


