Title: Predicting Resource Usages of Future Queries Based on 10M Presto Queries   at Twitter
Publication date: 2020-07-15
Playlist: Presto Events
Description: 
	Chunxu Tang, Software Engineer at Twitter
Beinan Wang, Sr. Software Engineer at Twitter

At Twitter, engineers maintain several large Presto clusters with over 2000 nodes in total. A Presto router service, sitting between clients and Presto clusters, employs a round-robin algorithm to redirect queries. Twitter's engineers observed that CPU and memory usages on these clusters were not balanced and the performance of the overall Presto system was impacted.

Here, Chunxu and Beinan would like to share what they have learned in developing a highly-scalable query predictor service through applying machine learning algorithms to ~10 million historical Presto queries to classify queries based on their CPU times and peak memory bytes. At Twitter, this service is helping to improve the performance of Presto clusters and provide expected execution statistics on Business Intelligence dashboards.

Join the PrestoDB slack channel: https://prestodb.slack.com/
Join the PrestoDB meetup group: https://www.meetup.com/prestodb/
Follow us on Twitter: https://twitter.com/prestodb
Follow us on LinkedIn: https://www.linkedin.com/company/presto-foundation/
Captions: 
	00:00:00,080 --> 00:00:06,720
um so for our next talk

00:00:03,360 --> 00:00:08,400
um we'll be having two engineers from uh

00:00:06,720 --> 00:00:10,160
twitter i'm going to talk about

00:00:08,400 --> 00:00:12,240
predicting resource usage of future

00:00:10,160 --> 00:00:15,440
queries based on 10 million

00:00:12,240 --> 00:00:18,640
presto db queries um did i

00:00:15,440 --> 00:00:21,600
move my slide accidentally hang on okay

00:00:18,640 --> 00:00:24,000
and uh shinsu uh is a software engineer

00:00:21,600 --> 00:00:26,240
in the interactive query team at twitter

00:00:24,000 --> 00:00:27,439
i've been working on presto and zeppelin

00:00:26,240 --> 00:00:29,760
services um

00:00:27,439 --> 00:00:30,480
and he loves hiking playing badminton

00:00:29,760 --> 00:00:33,040
and cooking

00:00:30,480 --> 00:00:34,320
okay that's one of my hobbies as well uh

00:00:33,040 --> 00:00:36,719
just the cooking part

00:00:34,320 --> 00:00:37,440
um and bainin is also an engineer with

00:00:36,719 --> 00:00:39,760
twitter

00:00:37,440 --> 00:00:42,079
interactive query team uh he's helped

00:00:39,760 --> 00:00:45,200
scale presto to fit twitter's data

00:00:42,079 --> 00:00:47,120
platform and prior to the iq team he

00:00:45,200 --> 00:00:48,000
worked for the core services team at

00:00:47,120 --> 00:00:51,120
twitter

00:00:48,000 --> 00:00:53,039
so i will take let you take on from here

00:00:51,120 --> 00:00:54,960
and see if you can wrap it up in about

00:00:53,039 --> 00:00:56,239
20 25 minutes so we'll have seven eight

00:00:54,960 --> 00:00:58,640
ten minutes in the end

00:00:56,239 --> 00:01:00,079
for people to ask questions to both of

00:00:58,640 --> 00:01:13,840
you

00:01:00,079 --> 00:01:13,840
sure thanks

00:01:14,400 --> 00:01:20,320
so okay hi good morning everyone

00:01:17,520 --> 00:01:21,520
uh here uh this is a transfer town uh

00:01:20,320 --> 00:01:24,320
today my colleague

00:01:21,520 --> 00:01:25,439
uh bainan and i will talk about how to

00:01:24,320 --> 00:01:28,320
predict the

00:01:25,439 --> 00:01:29,360
resource usages of future press aquarius

00:01:28,320 --> 00:01:32,079
based on

00:01:29,360 --> 00:01:33,040
around 10 mailing historical principle

00:01:32,079 --> 00:01:35,840
queries

00:01:33,040 --> 00:01:37,680
so it's a story about how to use machine

00:01:35,840 --> 00:01:39,840
learning techniques to help us to

00:01:37,680 --> 00:01:41,040
improve the productivity of pressure at

00:01:39,840 --> 00:01:43,119
twitter

00:01:41,040 --> 00:01:44,560
so i don't know what's your folks are

00:01:43,119 --> 00:01:46,720
pending on this topic

00:01:44,560 --> 00:01:48,399
at first the one being and i talk this

00:01:46,720 --> 00:01:51,040
idea to some of

00:01:48,399 --> 00:01:53,119
our colleagues at twitter they feel kind

00:01:51,040 --> 00:01:55,360
of weird or confused about it

00:01:53,119 --> 00:01:57,280
how machine learning and presto could

00:01:55,360 --> 00:01:59,840
use combined together

00:01:57,280 --> 00:02:01,280
to improve the productivity can it

00:01:59,840 --> 00:02:04,240
really work

00:02:01,280 --> 00:02:06,240
and the answer here is yes today ben and

00:02:04,240 --> 00:02:08,959
i would like to share some stories

00:02:06,240 --> 00:02:10,000
about how to use that kind of tactics to

00:02:08,959 --> 00:02:12,879
help us to solve

00:02:10,000 --> 00:02:14,239
problems in data systems and also

00:02:12,879 --> 00:02:15,920
there's another thing

00:02:14,239 --> 00:02:17,520
that i want to mention here is that

00:02:15,920 --> 00:02:20,160
machine learning is quite

00:02:17,520 --> 00:02:22,400
broad and complicated concept and

00:02:20,160 --> 00:02:23,120
sometimes women even need a series of

00:02:22,400 --> 00:02:25,599
classes

00:02:23,120 --> 00:02:26,879
to learn about it but here today we

00:02:25,599 --> 00:02:29,760
don't expect

00:02:26,879 --> 00:02:30,720
you folks have any background of machine

00:02:29,760 --> 00:02:33,599
learning

00:02:30,720 --> 00:02:34,640
but what we would like to focus on is

00:02:33,599 --> 00:02:38,480
how to come up with

00:02:34,640 --> 00:02:40,239
kind of methodology kind of ideas how to

00:02:38,480 --> 00:02:42,239
come up with this approaches

00:02:40,239 --> 00:02:43,280
to use machine learning to help us to

00:02:42,239 --> 00:02:46,879
solve the problems

00:02:43,280 --> 00:02:48,959
at data platform so

00:02:46,879 --> 00:02:50,400
our story there are three stories that

00:02:48,959 --> 00:02:52,959
would like to share today

00:02:50,400 --> 00:02:53,920
the first story is about the presto

00:02:52,959 --> 00:02:55,680
story at twitter

00:02:53,920 --> 00:02:56,959
and uh my colleague paina would like to

00:02:55,680 --> 00:02:58,959
talk more about it

00:02:56,959 --> 00:03:00,480
and then i'll talk about the queer

00:02:58,959 --> 00:03:02,720
particular story and twitter

00:03:00,480 --> 00:03:04,239
and then we'll do some wrap-up about

00:03:02,720 --> 00:03:06,800
what we have learned

00:03:04,239 --> 00:03:07,360
so let's invite bainan to talk about the

00:03:06,800 --> 00:03:11,680
story

00:03:07,360 --> 00:03:12,640
at twitter thank you trishi i'm being

00:03:11,680 --> 00:03:16,159
from twitter

00:03:12,640 --> 00:03:16,159
okay yeah next page

00:03:16,480 --> 00:03:22,640
uh yeah we started presto i think from

00:03:19,519 --> 00:03:25,360
five or six years years ago uh

00:03:22,640 --> 00:03:26,560
we start uh with a very small cluster

00:03:25,360 --> 00:03:28,720
cluster at first

00:03:26,560 --> 00:03:31,360
but then after we are building more and

00:03:28,720 --> 00:03:32,319
more users especially for some huge data

00:03:31,360 --> 00:03:35,760
science

00:03:32,319 --> 00:03:38,319
we are seeing some scalability issues

00:03:35,760 --> 00:03:40,000
on twitter because we need more workers

00:03:38,319 --> 00:03:43,680
but when we screw up

00:03:40,000 --> 00:03:46,319
when we have more than um 500 800

00:03:43,680 --> 00:03:47,360
1000 workers we are seeing the

00:03:46,319 --> 00:03:49,920
coordinator

00:03:47,360 --> 00:03:50,400
become more vulnerable yeah because for

00:03:49,920 --> 00:03:52,159
each

00:03:50,400 --> 00:03:53,840
pressure cluster we only have one

00:03:52,159 --> 00:03:55,439
plastic coordinator but we can have

00:03:53,840 --> 00:03:58,480
multiple workers

00:03:55,439 --> 00:04:00,319
yeah but the the coordinators

00:03:58,480 --> 00:04:01,920
will become you know we are suffering

00:04:00,319 --> 00:04:04,799
some these issues

00:04:01,920 --> 00:04:05,920
uh cpu solutions when we have more

00:04:04,799 --> 00:04:09,519
workers

00:04:05,920 --> 00:04:10,159
and also uh because we have a huge user

00:04:09,519 --> 00:04:13,120
side

00:04:10,159 --> 00:04:14,000
in twitter we have a longer reading

00:04:13,120 --> 00:04:17,120
queue and also

00:04:14,000 --> 00:04:19,519
we have a lot of guys they love the ui

00:04:17,120 --> 00:04:22,160
they check their query status in the

00:04:19,519 --> 00:04:24,160
price of ui all the time it makes

00:04:22,160 --> 00:04:25,759
the coordinator the status coordinator

00:04:24,160 --> 00:04:29,600
even worse

00:04:25,759 --> 00:04:32,639
and also we have a lot of

00:04:29,600 --> 00:04:35,440
scheduled jobs like etr jobs in twitter

00:04:32,639 --> 00:04:37,680
um we are seeing some availability

00:04:35,440 --> 00:04:39,520
issues because the

00:04:37,680 --> 00:04:40,720
the coordinator is a single point

00:04:39,520 --> 00:04:44,400
failure there

00:04:40,720 --> 00:04:48,000
and when we deploy the the presto

00:04:44,400 --> 00:04:50,320
um the the entire presto cluster will go

00:04:48,000 --> 00:04:54,479
down right we cannot handle any

00:04:50,320 --> 00:04:54,479
uh quite red anymore okay next page

00:04:54,639 --> 00:05:00,720
yeah so um i think it's last year

00:04:58,080 --> 00:05:01,440
another team member in my team uh how

00:05:00,720 --> 00:05:03,919
and i

00:05:01,440 --> 00:05:06,160
uh we developed a router it's just

00:05:03,919 --> 00:05:07,440
something like a load balancer just in

00:05:06,160 --> 00:05:10,880
front of all the

00:05:07,440 --> 00:05:13,280
crystal clusters then we can have more

00:05:10,880 --> 00:05:15,759
clusters work together

00:05:13,280 --> 00:05:16,639
for each uh subclass tester price to

00:05:15,759 --> 00:05:20,639
cluster

00:05:16,639 --> 00:05:25,199
uh we just have 200 or 400 workers there

00:05:20,639 --> 00:05:28,639
so we are seeing much less

00:05:25,199 --> 00:05:30,400
issues in the coordinators so in total

00:05:28,639 --> 00:05:31,520
we can have more than one thousand works

00:05:30,400 --> 00:05:34,080
actually we are running

00:05:31,520 --> 00:05:34,800
uh two thousand to three thousand

00:05:34,080 --> 00:05:38,160
workers

00:05:34,800 --> 00:05:41,600
uh for the trip in twitter and

00:05:38,160 --> 00:05:43,759
uh because we also implement a ui

00:05:41,600 --> 00:05:46,240
uh in the router so the users can just

00:05:43,759 --> 00:05:49,520
check the ui in the in the router

00:05:46,240 --> 00:05:53,120
and the major uh difference of this

00:05:49,520 --> 00:05:56,560
price to router from the price to

00:05:53,120 --> 00:05:58,720
proxy is we are using the redirect

00:05:56,560 --> 00:06:00,800
it's quite lightweight for each launcher

00:05:58,720 --> 00:06:05,680
instance that means

00:06:00,800 --> 00:06:08,000
we won't hold any data transferring

00:06:05,680 --> 00:06:08,880
during the query running for each new

00:06:08,000 --> 00:06:10,960
query

00:06:08,880 --> 00:06:12,240
the data just redirects the query to the

00:06:10,960 --> 00:06:14,479
sub clusters

00:06:12,240 --> 00:06:16,479
so during the running the client will

00:06:14,479 --> 00:06:17,520
fetch result from the sub cluster

00:06:16,479 --> 00:06:21,280
directly

00:06:17,520 --> 00:06:21,919
so we can easily to scale up and scale

00:06:21,280 --> 00:06:24,639
down the

00:06:21,919 --> 00:06:26,960
uh each clusters and also the the price

00:06:24,639 --> 00:06:30,000
to routers

00:06:26,960 --> 00:06:30,560
uh we can start rolling and which means

00:06:30,000 --> 00:06:33,120
we

00:06:30,560 --> 00:06:34,560
we have zero downtime during the

00:06:33,120 --> 00:06:37,199
deployment

00:06:34,560 --> 00:06:37,199
okay next week

00:06:38,400 --> 00:06:44,000
yeah this one yeah at first we we have

00:06:41,840 --> 00:06:46,880
some basic scheduling uh

00:06:44,000 --> 00:06:48,160
method for this this router just like

00:06:46,880 --> 00:06:50,160
some other uh

00:06:48,160 --> 00:06:51,599
normal backhand load balancing uh maybe

00:06:50,160 --> 00:06:54,880
we use a long lobby

00:06:51,599 --> 00:06:57,840
also we try some random

00:06:54,880 --> 00:06:59,840
dispatch also because we do have some uh

00:06:57,840 --> 00:07:00,080
some special use case for tableau users

00:06:59,840 --> 00:07:03,039
and

00:07:00,080 --> 00:07:04,560
for the schedule users so we also have

00:07:03,039 --> 00:07:07,599
some fixed routing we just

00:07:04,560 --> 00:07:10,800
logged the tableau user to some

00:07:07,599 --> 00:07:13,680
certain crystal tableau cluster but

00:07:10,800 --> 00:07:14,400
based on this kind of uh balancing

00:07:13,680 --> 00:07:17,520
approach

00:07:14,400 --> 00:07:20,000
we are seeing some the results using it

00:07:17,520 --> 00:07:21,199
it's not very perfect we are seeing some

00:07:20,000 --> 00:07:23,280
starving

00:07:21,199 --> 00:07:24,720
clusters we are seeing some cancer too

00:07:23,280 --> 00:07:26,639
busy all the

00:07:24,720 --> 00:07:28,000
queries are stuck there because just

00:07:26,639 --> 00:07:31,199
because it's too busy

00:07:28,000 --> 00:07:34,960
and somehow with the results and

00:07:31,199 --> 00:07:37,039
for some busy clusters we are seeing the

00:07:34,960 --> 00:07:38,400
longer execution time especially some

00:07:37,039 --> 00:07:41,520
reaching time because

00:07:38,400 --> 00:07:45,599
the the waiting queue is it's too low

00:07:41,520 --> 00:07:48,560
okay next yeah so we're just thinking

00:07:45,599 --> 00:07:50,720
about what's the difference between the

00:07:48,560 --> 00:07:52,639
uh the price to router and some other

00:07:50,720 --> 00:07:56,000
load balancing and just because

00:07:52,639 --> 00:07:58,400
uh the resource usage of each query

00:07:56,000 --> 00:08:00,160
are quite different uh for some query it

00:07:58,400 --> 00:08:03,199
just takes a

00:08:00,160 --> 00:08:05,599
100 millisecond but for some huge query

00:08:03,199 --> 00:08:07,840
it will take you maybe more than four

00:08:05,599 --> 00:08:12,240
hours or eight hours or a whole day

00:08:07,840 --> 00:08:15,840
to run so if we dispatch the huge query

00:08:12,240 --> 00:08:19,599
to one sub cluster it will make that

00:08:15,840 --> 00:08:22,720
cluster crazy so we're just thinking

00:08:19,599 --> 00:08:25,039
maybe we can collect some some data some

00:08:22,720 --> 00:08:28,720
logs

00:08:25,039 --> 00:08:31,120
and then do some uh

00:08:28,720 --> 00:08:33,440
analysis uh we will call the query

00:08:31,120 --> 00:08:36,800
predictor which we will probably

00:08:33,440 --> 00:08:38,240
provide more details later and then we

00:08:36,800 --> 00:08:40,719
can have more

00:08:38,240 --> 00:08:42,560
knowledge about each query we can do the

00:08:40,719 --> 00:08:45,920
query scheduler

00:08:42,560 --> 00:08:49,440
better that's the uh the basic

00:08:45,920 --> 00:08:50,480
idea of this uh price to a router

00:08:49,440 --> 00:08:54,800
predictor and

00:08:50,480 --> 00:08:57,680
scheduler next page

00:08:54,800 --> 00:08:58,800
okay yeah let's leave the the remaining

00:08:57,680 --> 00:09:01,519
of this presentation

00:08:58,800 --> 00:09:02,640
to 2g which is the most juicy part of

00:09:01,519 --> 00:09:05,920
this presentation

00:09:02,640 --> 00:09:06,720
the query predictor okay okay thanks

00:09:05,920 --> 00:09:09,760
veda

00:09:06,720 --> 00:09:11,440
for sharing so uh let's go further on

00:09:09,760 --> 00:09:14,000
the journal to the

00:09:11,440 --> 00:09:15,760
on the journey to the club predictor so

00:09:14,000 --> 00:09:18,080
here i would like to share now about the

00:09:15,760 --> 00:09:19,360
story of chiropractic of twitter like

00:09:18,080 --> 00:09:21,920
how we used

00:09:19,360 --> 00:09:23,279
a machine learning techniques to help us

00:09:21,920 --> 00:09:26,480
to predict the cost

00:09:23,279 --> 00:09:28,640
of a sql query so as what banan have

00:09:26,480 --> 00:09:30,880
had shared so we would like to have a

00:09:28,640 --> 00:09:32,240
query predictor which is which could be

00:09:30,880 --> 00:09:36,000
used to predict

00:09:32,240 --> 00:09:38,480
the cpu and the memory sources of each

00:09:36,000 --> 00:09:39,360
filter sql query the query predictor

00:09:38,480 --> 00:09:42,320
could be used

00:09:39,360 --> 00:09:43,200
by various platforms for example it

00:09:42,320 --> 00:09:46,399
could be used

00:09:43,200 --> 00:09:48,800
by a web application which we have

00:09:46,399 --> 00:09:50,720
created it could be used by business

00:09:48,800 --> 00:09:51,519
intelligence tools like local and

00:09:50,720 --> 00:09:54,560
tableau

00:09:51,519 --> 00:09:55,200
it can also be used by notebooks such as

00:09:54,560 --> 00:09:58,480
zeppelin

00:09:55,200 --> 00:10:00,080
and jupiter to provide some estimated

00:09:58,480 --> 00:10:03,040
execution statistics

00:10:00,080 --> 00:10:04,959
to end users to customers at the same

00:10:03,040 --> 00:10:07,200
time this curve predictor

00:10:04,959 --> 00:10:08,320
is also used by the router press the

00:10:07,200 --> 00:10:11,680
router side

00:10:08,320 --> 00:10:14,160
to schedule the queries intelligently

00:10:11,680 --> 00:10:15,519
so here is a high level design of the

00:10:14,160 --> 00:10:18,079
query predictor

00:10:15,519 --> 00:10:19,600
so on the very left we have lots of

00:10:18,079 --> 00:10:23,040
historical queries

00:10:19,600 --> 00:10:26,079
and these queries will be fed to some

00:10:23,040 --> 00:10:27,040
models for training so two models will

00:10:26,079 --> 00:10:30,000
be generated

00:10:27,040 --> 00:10:32,079
after the training one is the cpu model

00:10:30,000 --> 00:10:35,519
which is used to predict the cpu

00:10:32,079 --> 00:10:38,399
time of a sql query and the other is a

00:10:35,519 --> 00:10:41,279
memory model which is used to predict

00:10:38,399 --> 00:10:42,000
the peak memory bytes of a query in the

00:10:41,279 --> 00:10:44,880
future

00:10:42,000 --> 00:10:46,880
and the two models are wrapped into a

00:10:44,880 --> 00:10:49,120
service called query predictor service

00:10:46,880 --> 00:10:50,560
and the service provides some apis to

00:10:49,120 --> 00:10:52,800
the external world

00:10:50,560 --> 00:10:55,120
and could be called by some other

00:10:52,800 --> 00:10:58,079
services at twitter

00:10:55,120 --> 00:11:00,160
so here is uh the web application we

00:10:58,079 --> 00:11:02,959
have created at twitter so

00:11:00,160 --> 00:11:03,360
here is a text area so the user can just

00:11:02,959 --> 00:11:06,320
fill

00:11:03,360 --> 00:11:07,480
in a query here so here i put a very

00:11:06,320 --> 00:11:10,800
simple query from

00:11:07,480 --> 00:11:14,160
tpch benchmark and then the user can

00:11:10,800 --> 00:11:16,399
just click the predict button here to

00:11:14,160 --> 00:11:18,320
get a predicted cpu time for example

00:11:16,399 --> 00:11:21,120
here it is 30 seconds to one hour

00:11:18,320 --> 00:11:21,680
and also the predicted peak memory byte

00:11:21,120 --> 00:11:24,959
here

00:11:21,680 --> 00:11:27,440
for the specific sql query

00:11:24,959 --> 00:11:30,079
okay so let's talk about about the

00:11:27,440 --> 00:11:33,120
machine learning pipeline here

00:11:30,079 --> 00:11:35,200
before we jump into the specific

00:11:33,120 --> 00:11:36,240
implementation of the query predictor i

00:11:35,200 --> 00:11:38,320
would like to

00:11:36,240 --> 00:11:39,600
say more about the general machine on

00:11:38,320 --> 00:11:41,600
your pipeline because

00:11:39,600 --> 00:11:44,160
for this tech talk today what we would

00:11:41,600 --> 00:11:46,560
like to focus on is not just a specific

00:11:44,160 --> 00:11:47,839
implementation of curb predictor but

00:11:46,560 --> 00:11:50,800
what we can get

00:11:47,839 --> 00:11:53,040
what we can benefit from the main main

00:11:50,800 --> 00:11:55,839
concepts of the main ideas

00:11:53,040 --> 00:11:58,320
of the curb predictor behind that is

00:11:55,839 --> 00:11:59,920
maybe sometimes we can apply some kind

00:11:58,320 --> 00:12:01,920
of machine learning techniques

00:11:59,920 --> 00:12:04,480
to help her to solve problems and data

00:12:01,920 --> 00:12:06,240
systems not just the presto or maybe not

00:12:04,480 --> 00:12:08,240
just the clear predictor

00:12:06,240 --> 00:12:10,480
so for a machine learning pipeline the

00:12:08,240 --> 00:12:12,800
very first thing we need to think about

00:12:10,480 --> 00:12:14,639
is to define the problem what is the

00:12:12,800 --> 00:12:17,040
problem we would like to solve

00:12:14,639 --> 00:12:17,920
and what is the input and output of that

00:12:17,040 --> 00:12:20,240
problem

00:12:17,920 --> 00:12:21,519
and then we can prepare some data from

00:12:20,240 --> 00:12:24,160
data ingestion

00:12:21,519 --> 00:12:25,600
and then we could do some model training

00:12:24,160 --> 00:12:28,160
to get some models and we

00:12:25,600 --> 00:12:30,480
serve these models and finally when the

00:12:28,160 --> 00:12:31,519
models helping online we also need to do

00:12:30,480 --> 00:12:34,480
some monitoring

00:12:31,519 --> 00:12:35,120
to continuously monitor the performance

00:12:34,480 --> 00:12:38,959
of these

00:12:35,120 --> 00:12:41,200
models okay so the very first

00:12:38,959 --> 00:12:42,160
thing and the most important part in my

00:12:41,200 --> 00:12:44,800
mind

00:12:42,160 --> 00:12:45,600
is about the problem definition so here

00:12:44,800 --> 00:12:48,320
our task

00:12:45,600 --> 00:12:50,560
is to predict the cpu time and the peak

00:12:48,320 --> 00:12:54,000
memory bytes of a sql query

00:12:50,560 --> 00:12:57,279
so the very first question is that

00:12:54,000 --> 00:13:00,079
what should we output like

00:12:57,279 --> 00:13:00,480
do we need to output the specific cpu

00:13:00,079 --> 00:13:04,160
time

00:13:00,480 --> 00:13:07,200
like a 1.0123 second

00:13:04,160 --> 00:13:08,079
or so other experiment experiments what

00:13:07,200 --> 00:13:10,480
we have found

00:13:08,079 --> 00:13:12,800
is that for query scheduling all four

00:13:10,480 --> 00:13:15,839
customers to get some quick sense

00:13:12,800 --> 00:13:16,880
of their queries we don't need to have a

00:13:15,839 --> 00:13:20,240
very specific

00:13:16,880 --> 00:13:22,880
very accurate estimate of the cpu time

00:13:20,240 --> 00:13:23,839
what we may need to do for example is to

00:13:22,880 --> 00:13:26,880
differentiate

00:13:23,839 --> 00:13:27,680
whether this is a really long query as

00:13:26,880 --> 00:13:30,320
banan has

00:13:27,680 --> 00:13:31,680
mentioned it may cost like uh longer

00:13:30,320 --> 00:13:34,800
than one hour to

00:13:31,680 --> 00:13:35,279
execute or it may be a very short query

00:13:34,800 --> 00:13:37,279
it just

00:13:35,279 --> 00:13:38,720
caught for example 30 seconds to

00:13:37,279 --> 00:13:42,079
complete right

00:13:38,720 --> 00:13:43,920
so based on that kind of idea we come up

00:13:42,079 --> 00:13:45,760
with this problem definition

00:13:43,920 --> 00:13:47,279
that we don't need to predict the

00:13:45,760 --> 00:13:50,399
specific accurate

00:13:47,279 --> 00:13:53,040
time of cpu time or

00:13:50,399 --> 00:13:54,079
memory bytes of a specific query but we

00:13:53,040 --> 00:13:57,040
would like to

00:13:54,079 --> 00:13:57,760
put this metrics into different

00:13:57,040 --> 00:14:00,560
categories

00:13:57,760 --> 00:14:01,199
into different buckets take the cpu time

00:14:00,560 --> 00:14:03,839
as

00:14:01,199 --> 00:14:04,399
a as an example we have four buckets

00:14:03,839 --> 00:14:06,639
small

00:14:04,399 --> 00:14:07,519
long shorter than 30 seconds 30 seconds

00:14:06,639 --> 00:14:10,160
to one hour

00:14:07,519 --> 00:14:11,040
one hour to five hours and longer than

00:14:10,160 --> 00:14:14,639
five hours

00:14:11,040 --> 00:14:15,360
and almost the same for the memory bite

00:14:14,639 --> 00:14:19,279
side

00:14:15,360 --> 00:14:23,079
so in that case our model will be

00:14:19,279 --> 00:14:26,320
like converted from a

00:14:23,079 --> 00:14:29,680
regression model to a classification

00:14:26,320 --> 00:14:30,480
problem okay so the next question is

00:14:29,680 --> 00:14:33,120
that

00:14:30,480 --> 00:14:35,440
what data do we have at least we need

00:14:33,120 --> 00:14:38,399
some data for the training right

00:14:35,440 --> 00:14:40,880
luckily for pestocide we have a huge

00:14:38,399 --> 00:14:44,160
amount of presto query logs

00:14:40,880 --> 00:14:45,360
we have around 10 mailing or query logs

00:14:44,160 --> 00:14:47,839
here and that's

00:14:45,360 --> 00:14:49,120
what we have built the whole curve

00:14:47,839 --> 00:14:51,519
predictor pipeline

00:14:49,120 --> 00:14:54,240
for our project so we have the raw

00:14:51,519 --> 00:14:56,720
plaster logs and these logs will be

00:14:54,240 --> 00:14:58,639
converted into categories into different

00:14:56,720 --> 00:15:00,560
categories and the step here is called

00:14:58,639 --> 00:15:02,959
data discretization

00:15:00,560 --> 00:15:04,000
and then we'll do some data cleaning and

00:15:02,959 --> 00:15:05,760
then if

00:15:04,000 --> 00:15:07,360
you folks have some background of

00:15:05,760 --> 00:15:10,000
machine learning usually for

00:15:07,360 --> 00:15:10,720
classification problems we need to split

00:15:10,000 --> 00:15:12,959
the data set

00:15:10,720 --> 00:15:14,480
into a training one and the testing one

00:15:12,959 --> 00:15:15,360
and we will train the model on the

00:15:14,480 --> 00:15:17,920
trained data set

00:15:15,360 --> 00:15:19,360
and then evaluate these models on the

00:15:17,920 --> 00:15:22,240
testing data set

00:15:19,360 --> 00:15:23,519
so we split that into 80 training data

00:15:22,240 --> 00:15:25,760
set and 20

00:15:23,519 --> 00:15:27,120
testing data set and then we'll apply

00:15:25,760 --> 00:15:30,959
vectorization

00:15:27,120 --> 00:15:33,120
tf idf which is a very uh common concept

00:15:30,959 --> 00:15:34,399
in natural language processing on these

00:15:33,120 --> 00:15:37,120
sql statements

00:15:34,399 --> 00:15:39,519
and then we use actually boost which is

00:15:37,120 --> 00:15:42,560
a gradient boosting decision tree model

00:15:39,519 --> 00:15:43,600
to train these models and then on the

00:15:42,560 --> 00:15:46,320
testing data set

00:15:43,600 --> 00:15:48,000
we do the data transformation based on

00:15:46,320 --> 00:15:50,320
the vectorizer we have trained

00:15:48,000 --> 00:15:52,320
we have trained and we'll also evaluate

00:15:50,320 --> 00:15:55,360
these models

00:15:52,320 --> 00:15:58,160
okay so here are some results

00:15:55,360 --> 00:15:58,880
we have obtained in our training so for

00:15:58,160 --> 00:16:01,920
the cpu

00:15:58,880 --> 00:16:05,440
time model the accuracy is as high

00:16:01,920 --> 00:16:08,079
as more than 94 and for the peak

00:16:05,440 --> 00:16:08,800
memory bytes model the accuracy is as

00:16:08,079 --> 00:16:12,160
high

00:16:08,800 --> 00:16:15,199
as around 92

00:16:12,160 --> 00:16:19,920
but here a question may be raised is

00:16:15,199 --> 00:16:22,480
accuracy always be a good

00:16:19,920 --> 00:16:23,920
metric to evaluate the performance of

00:16:22,480 --> 00:16:26,560
the model

00:16:23,920 --> 00:16:27,279
the answer may not be true and here what

00:16:26,560 --> 00:16:30,399
i want to share

00:16:27,279 --> 00:16:32,959
with you guys is about some other

00:16:30,399 --> 00:16:34,720
metrics for model evaluation such as

00:16:32,959 --> 00:16:38,399
precession and recall

00:16:34,720 --> 00:16:41,199
take the recall as an example to recall

00:16:38,399 --> 00:16:41,759
is used to evaluate how many relevant

00:16:41,199 --> 00:16:44,800
items

00:16:41,759 --> 00:16:46,480
have been selected correctly so take the

00:16:44,800 --> 00:16:49,120
cpu time model as

00:16:46,480 --> 00:16:51,279
as an example here we have a row which

00:16:49,120 --> 00:16:52,399
about the query is longer than 5 hours

00:16:51,279 --> 00:16:55,600
the recall here

00:16:52,399 --> 00:16:58,720
is 90 which means of

00:16:55,600 --> 00:17:00,560
90 of the large queries have been

00:16:58,720 --> 00:17:03,120
predicted correctly

00:17:00,560 --> 00:17:04,000
so suppose that we have a quite stupid

00:17:03,120 --> 00:17:06,559
very simple

00:17:04,000 --> 00:17:08,240
query predictor which always predicts

00:17:06,559 --> 00:17:11,199
all the queries

00:17:08,240 --> 00:17:12,400
cpu time is smaller than 30 seconds and

00:17:11,199 --> 00:17:16,319
then we have

00:17:12,400 --> 00:17:18,079
100 queries here 99 queries

00:17:16,319 --> 00:17:20,000
their cpu time is smaller than 30

00:17:18,079 --> 00:17:23,520
seconds and

00:17:20,000 --> 00:17:24,160
only once once a cpu time is longer than

00:17:23,520 --> 00:17:28,559
5 hours

00:17:24,160 --> 00:17:30,799
the accuracy here could be as high as 99

00:17:28,559 --> 00:17:32,000
but the recall of the queries longer

00:17:30,799 --> 00:17:34,320
than 5 hours will be

00:17:32,000 --> 00:17:35,200
zero because none of the queries in this

00:17:34,320 --> 00:17:38,400
category

00:17:35,200 --> 00:17:41,200
can't be predicted correctly so that's

00:17:38,400 --> 00:17:42,080
something that we need to be especially

00:17:41,200 --> 00:17:45,200
concentrate

00:17:42,080 --> 00:17:47,280
or need to be

00:17:45,200 --> 00:17:49,039
keeping our minds that when we would

00:17:47,280 --> 00:17:50,880
like to evaluate some models we also

00:17:49,039 --> 00:17:53,200
need to take care of other features

00:17:50,880 --> 00:17:54,240
other metrics to help us to get a

00:17:53,200 --> 00:17:56,480
broader concept

00:17:54,240 --> 00:17:58,640
a broader understanding of these models

00:17:56,480 --> 00:18:00,559
we have trained

00:17:58,640 --> 00:18:02,720
so the last thing we want to share is

00:18:00,559 --> 00:18:05,039
about what we have learned

00:18:02,720 --> 00:18:07,120
i think that's a also a very important

00:18:05,039 --> 00:18:09,200
part of this presentation today

00:18:07,120 --> 00:18:10,640
and there here are some key takeaways

00:18:09,200 --> 00:18:12,480
that we would like to share with the

00:18:10,640 --> 00:18:14,559
whole presto community

00:18:12,480 --> 00:18:15,679
the first thing is that machine learning

00:18:14,559 --> 00:18:18,720
can be how

00:18:15,679 --> 00:18:21,760
can be useful can be really helpful

00:18:18,720 --> 00:18:22,960
on our side some basic models like what

00:18:21,760 --> 00:18:25,840
we have trained

00:18:22,960 --> 00:18:27,280
can give quite good results and the

00:18:25,840 --> 00:18:30,240
second takeaway is

00:18:27,280 --> 00:18:31,840
logs are a kind of reliable starting

00:18:30,240 --> 00:18:33,280
point for machine learning

00:18:31,840 --> 00:18:34,880
and we also need to know that machine

00:18:33,280 --> 00:18:35,840
learning requires lots of models for

00:18:34,880 --> 00:18:38,640
training

00:18:35,840 --> 00:18:40,799
and the last thing is that be careful

00:18:38,640 --> 00:18:42,400
machine learning is not dependency

00:18:40,799 --> 00:18:44,320
it's not a silver bullet that can be

00:18:42,400 --> 00:18:47,440
used to solve all our

00:18:44,320 --> 00:18:49,840
pinpoint no it's not models should be

00:18:47,440 --> 00:18:54,080
evaluated on various

00:18:49,840 --> 00:18:56,480
metrics not just accuracy

00:18:54,080 --> 00:18:58,640
okay so that's all about uh our tech

00:18:56,480 --> 00:19:00,880
talk uh and i have today

00:18:58,640 --> 00:19:02,559
and we are here ready to help uh if you

00:19:00,880 --> 00:19:04,400
have any questions you can also ping us

00:19:02,559 --> 00:19:07,679
in the presto slack channel

00:19:04,400 --> 00:19:07,679
thanks so much for your attendance

00:19:07,919 --> 00:19:14,640
great thank you so much uh chunzu and uh

00:19:11,039 --> 00:19:15,200
bainan a great talk uh we do have a

00:19:14,640 --> 00:19:17,440
question

00:19:15,200 --> 00:19:18,960
that uh i'll read out for you so that we

00:19:17,440 --> 00:19:21,200
can uh take it live

00:19:18,960 --> 00:19:22,240
um question from ash do the query logs

00:19:21,200 --> 00:19:24,320
uh uh

00:19:22,240 --> 00:19:26,559
fed into the model include the explain

00:19:24,320 --> 00:19:28,480
plans or just the query text

00:19:26,559 --> 00:19:30,080
uh because uh two similar looking

00:19:28,480 --> 00:19:34,080
queries might have different plans

00:19:30,080 --> 00:19:34,080
um uh that will affect the prediction

00:19:34,799 --> 00:19:38,720
yeah i think i can answer this question

00:19:37,600 --> 00:19:41,280
the question is

00:19:38,720 --> 00:19:42,559
mainly about some techniques in the

00:19:41,280 --> 00:19:44,640
model training part

00:19:42,559 --> 00:19:46,720
so in our case on the twitter side in

00:19:44,640 --> 00:19:49,440
our case in the query log

00:19:46,720 --> 00:19:50,960
what we have is about a sql statement

00:19:49,440 --> 00:19:53,840
and then we'll have the

00:19:50,960 --> 00:19:55,360
cpu time the accurate cpu time of the

00:19:53,840 --> 00:19:58,559
specific sql query

00:19:55,360 --> 00:19:59,520
and the peak memory bytes of this sql

00:19:58,559 --> 00:20:01,760
statement

00:19:59,520 --> 00:20:02,640
and then we feed this kind of thing to

00:20:01,760 --> 00:20:05,200
the

00:20:02,640 --> 00:20:06,320
models for the training so the next

00:20:05,200 --> 00:20:08,720
question is about

00:20:06,320 --> 00:20:09,520
whether two similar looking queries

00:20:08,720 --> 00:20:11,919
might have

00:20:09,520 --> 00:20:12,880
uh different plans that may have the

00:20:11,919 --> 00:20:16,080
very different

00:20:12,880 --> 00:20:18,799
results right uh so that's a kind of

00:20:16,080 --> 00:20:19,440
amazing part for the machine learning

00:20:18,799 --> 00:20:21,760
side

00:20:19,440 --> 00:20:22,960
in our experiment for now that what we

00:20:21,760 --> 00:20:26,240
have learned

00:20:22,960 --> 00:20:27,440
is that uh similar similar queries at

00:20:26,240 --> 00:20:29,120
twitter usually have

00:20:27,440 --> 00:20:30,720
kind of a similar results and the

00:20:29,120 --> 00:20:33,440
machine learning part the

00:20:30,720 --> 00:20:34,320
machine learning uh algorithms can

00:20:33,440 --> 00:20:38,080
predict them

00:20:34,320 --> 00:20:38,480
quite accurately and we also know that

00:20:38,080 --> 00:20:41,520
there

00:20:38,480 --> 00:20:43,440
is a small amount of queries similar

00:20:41,520 --> 00:20:44,159
queries really generate some different

00:20:43,440 --> 00:20:45,919
results

00:20:44,159 --> 00:20:48,080
and interestingly the machine learning

00:20:45,919 --> 00:20:51,200
organisms also predict them

00:20:48,080 --> 00:20:53,520
quite accurately that's also one reason

00:20:51,200 --> 00:20:55,760
why we choose a decision tree

00:20:53,520 --> 00:20:57,360
model here because if you have some

00:20:55,760 --> 00:20:59,200
background of machine learning you know

00:20:57,360 --> 00:20:59,600
that for decentral trade usually we can

00:20:59,200 --> 00:21:01,440
it's

00:20:59,600 --> 00:21:03,600
quite easy for us to utilize the tree

00:21:01,440 --> 00:21:06,400
structure and find some rules that

00:21:03,600 --> 00:21:07,200
how the algorithm help us to clarify the

00:21:06,400 --> 00:21:09,200
problems

00:21:07,200 --> 00:21:11,440
so that's also something that we can

00:21:09,200 --> 00:21:11,919
learn from the machine learning side to

00:21:11,440 --> 00:21:14,159
help

00:21:11,919 --> 00:21:15,039
our engineers to know better about our

00:21:14,159 --> 00:21:18,000
systems

00:21:15,039 --> 00:21:19,520
yeah yes great thanks for answering that

00:21:18,000 --> 00:21:20,000
uh just we'll just take one more

00:21:19,520 --> 00:21:22,880
question

00:21:20,000 --> 00:21:25,440
and then wrap up uh how do you take care

00:21:22,880 --> 00:21:28,080
of the same query on different data sets

00:21:25,440 --> 00:21:28,080
or tables

00:21:29,120 --> 00:21:32,880
uh i think uh banan maybe know more

00:21:32,159 --> 00:21:35,360
about it

00:21:32,880 --> 00:21:37,520
you in my opinion actually at twitter's

00:21:35,360 --> 00:21:39,840
side we don't have same queries

00:21:37,520 --> 00:21:41,200
on different data sets because like for

00:21:39,840 --> 00:21:42,960
example we have a

00:21:41,200 --> 00:21:44,240
tweets data set and the twist data set

00:21:42,960 --> 00:21:46,080
only one data set

00:21:44,240 --> 00:21:47,919
suppose there's another data set that

00:21:46,080 --> 00:21:49,760
then there won't be like tweets we need

00:21:47,919 --> 00:21:50,320
to write another different query for

00:21:49,760 --> 00:21:52,960
that

00:21:50,320 --> 00:21:54,960
but not uh am i correct would you like

00:21:52,960 --> 00:21:56,640
to add some more materials on that

00:21:54,960 --> 00:21:58,080
that's true uh in twitter there's

00:21:56,640 --> 00:22:01,360
something different

00:21:58,080 --> 00:22:02,480
we have something called ufs and based

00:22:01,360 --> 00:22:05,360
on that

00:22:02,480 --> 00:22:05,919
we only have one meta store so that

00:22:05,360 --> 00:22:08,320
means

00:22:05,919 --> 00:22:08,960
each data side will be there just like a

00:22:08,320 --> 00:22:12,159
unique

00:22:08,960 --> 00:22:13,760
data size we won't copy the dataset i

00:22:12,159 --> 00:22:16,720
mean everywhere to other

00:22:13,760 --> 00:22:17,760
uh cluster we do but if we're doing

00:22:16,720 --> 00:22:20,400
something like that

00:22:17,760 --> 00:22:21,520
that means we create a totally new data

00:22:20,400 --> 00:22:24,799
side

00:22:21,520 --> 00:22:25,200
so the query there won't be exactly the

00:22:24,799 --> 00:22:27,520
same

00:22:25,200 --> 00:22:28,480
at least the table name should be

00:22:27,520 --> 00:22:32,240
different

00:22:28,480 --> 00:22:34,159
and also the data range

00:22:32,240 --> 00:22:35,360
must be different because we just copy

00:22:34,159 --> 00:22:37,919
maybe a small range

00:22:35,360 --> 00:22:41,840
from some data cell to another or

00:22:37,919 --> 00:22:41,840
something like that

00:22:43,200 --> 00:22:49,600
great thank you so much the twitter team

00:22:46,559 --> 00:22:52,720
as well as the jam team

00:22:49,600 --> 00:22:54,320
on behalf of the outreach committee

00:22:52,720 --> 00:22:55,760
uh really a big thank you to all our

00:22:54,320 --> 00:22:58,240
speakers today uh

00:22:55,760 --> 00:22:59,679
two great sessions uh folks if you have

00:22:58,240 --> 00:23:02,960
more questions um

00:22:59,679 --> 00:23:03,600
um uh you can uh uh uh type them in

00:23:02,960 --> 00:23:05,760
right now

00:23:03,600 --> 00:23:06,720
and we we have access to this so we can

00:23:05,760 --> 00:23:09,679
answer them

00:23:06,720 --> 00:23:10,480
um after the session in addition uh we'd

00:23:09,679 --> 00:23:13,039
like to say

00:23:10,480 --> 00:23:13,760
that we have a new channel for feedback

00:23:13,039 --> 00:23:15,679
from you

00:23:13,760 --> 00:23:17,520
so we'd like to hear from you are there

00:23:15,679 --> 00:23:18,960
other sessions other topics that you

00:23:17,520 --> 00:23:21,679
would like to hear from

00:23:18,960 --> 00:23:23,200
um in our virtual meetups this is our

00:23:21,679 --> 00:23:25,760
third virtual session

00:23:23,200 --> 00:23:26,320
this month uh we already have a great uh

00:23:25,760 --> 00:23:28,400
set of

00:23:26,320 --> 00:23:29,840
sessions planned for next month uh but

00:23:28,400 --> 00:23:33,039
would be great to hear from you at

00:23:29,840 --> 00:23:35,200
feedback at lists.prestodb.io

00:23:33,039 --> 00:23:36,799
if you would like to present or if you

00:23:35,200 --> 00:23:39,840
have suggestions uh

00:23:36,799 --> 00:23:40,880
let us know in addition right after this

00:23:39,840 --> 00:23:43,279
uh we'll uh

00:23:40,880 --> 00:23:45,520
send out a survey uh to the meetup group

00:23:43,279 --> 00:23:49,039
uh to hear your feedback as well

00:23:45,520 --> 00:23:50,720
uh and amit and i and the outreach team

00:23:49,039 --> 00:23:52,880
are always looking at ways to engage

00:23:50,720 --> 00:23:55,360
better with everyone

00:23:52,880 --> 00:23:56,480
in the community and looking forward to

00:23:55,360 --> 00:23:58,799
hearing from you

00:23:56,480 --> 00:23:59,600
the recording from today will be

00:23:58,799 --> 00:24:01,520
available

00:23:59,600 --> 00:24:03,279
on our new youtube channel that amit

00:24:01,520 --> 00:24:06,480
announced earlier

00:24:03,279 --> 00:24:08,320
uh in the session and with that

00:24:06,480 --> 00:24:10,159
uh we'd like to wrap up today's session

00:24:08,320 --> 00:24:11,919
thank you so much for joining everyone

00:24:10,159 --> 00:24:13,440
and thanks again to the twitter team as

00:24:11,919 --> 00:24:16,159
well as the jam team

00:24:13,440 --> 00:24:17,039
um for presenting take care cheers

00:24:16,159 --> 00:24:19,039
bye-bye

00:24:17,039 --> 00:24:32,640
thank you thank you everyone thank you

00:24:19,039 --> 00:24:32,640

YouTube URL: https://www.youtube.com/watch?v=Zuk5AUi6ASQ


