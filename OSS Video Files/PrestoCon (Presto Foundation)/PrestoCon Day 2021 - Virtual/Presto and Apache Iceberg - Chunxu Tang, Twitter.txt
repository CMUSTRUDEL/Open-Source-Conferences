Title: Presto and Apache Iceberg - Chunxu Tang, Twitter
Publication date: 2021-03-27
Playlist: PrestoCon Day 2021 - Virtual
Description: 
	Presto and Apache Iceberg - Chunxu Tang, Twitter

Apache Iceberg is an open table format for huge analytic datasets. At Twitter, engineers are working on the Presto-Iceberg connector, aiming to bring high-performance data analytics on Iceberg to the Presto ecosystem. Here, Chunxu would like to share what they have learned during the development, hoping to shed light on the future work of interactive queries. 

For more info about Presto, the open source distributed SQL query engine for running interactive analytic queries against data sources of all sizes ranging from gigabytes to petabytes, see: https://prestodb.io/
Captions: 
	00:00:00,080 --> 00:00:03,840
hi everyone this is trent yutan from

00:00:02,800 --> 00:00:06,319
twitter

00:00:03,840 --> 00:00:07,440
today i would like to talk about the

00:00:06,319 --> 00:00:09,760
experience

00:00:07,440 --> 00:00:12,320
of development of the presto aspect

00:00:09,760 --> 00:00:15,360
connector at twitter

00:00:12,320 --> 00:00:17,920
so there are mainly two sections that

00:00:15,360 --> 00:00:18,480
in this presentation for the first

00:00:17,920 --> 00:00:20,720
section

00:00:18,480 --> 00:00:22,960
i would like to introduce a little bit

00:00:20,720 --> 00:00:23,840
more about the presto ecosystem at

00:00:22,960 --> 00:00:26,000
twitter

00:00:23,840 --> 00:00:27,199
and then for the second part i would

00:00:26,000 --> 00:00:31,840
like to concentrate

00:00:27,199 --> 00:00:31,840
on the presto aspect connector

00:00:34,160 --> 00:00:38,559
so for the first part i would like to

00:00:36,559 --> 00:00:41,360
talk about the presto ecosystem

00:00:38,559 --> 00:00:42,879
actuator at twitter actually we are

00:00:41,360 --> 00:00:46,160
maintaining a really

00:00:42,879 --> 00:00:47,200
large hadoop clusters so it means that

00:00:46,160 --> 00:00:50,160
we have a

00:00:47,200 --> 00:00:50,800
really large amount of data so in that

00:00:50,160 --> 00:00:53,600
case

00:00:50,800 --> 00:00:55,600
to maintain the press ecosystem they're

00:00:53,600 --> 00:00:57,760
really a long path for us

00:00:55,600 --> 00:00:59,840
pursuing for scalability and

00:00:57,760 --> 00:01:03,120
availability

00:00:59,840 --> 00:01:06,159
so here is the basic statistics of

00:01:03,120 --> 00:01:07,200
presto at twitter we have more than nine

00:01:06,159 --> 00:01:09,840
clusters

00:01:07,200 --> 00:01:10,880
some of them are on premise and some of

00:01:09,840 --> 00:01:14,400
them are on the

00:01:10,880 --> 00:01:17,680
on the cloud and we are having more than

00:01:14,400 --> 00:01:19,520
3 000 pressed workers and for the whole

00:01:17,680 --> 00:01:22,640
presto cluster at twitter

00:01:19,520 --> 00:01:25,840
we have executed more than 16

00:01:22,640 --> 00:01:28,159
mailing queries so there is really a

00:01:25,840 --> 00:01:30,400
large cluster

00:01:28,159 --> 00:01:32,640
so in that case there will be some

00:01:30,400 --> 00:01:35,280
issues related to scalability and

00:01:32,640 --> 00:01:37,360
availability that we need to resolve

00:01:35,280 --> 00:01:39,280
that's why we proposed a presto

00:01:37,360 --> 00:01:42,079
federation system

00:01:39,280 --> 00:01:42,960
where we introduce a pressed router

00:01:42,079 --> 00:01:45,040
service

00:01:42,960 --> 00:01:46,240
among the customers and the presto

00:01:45,040 --> 00:01:50,000
clusters

00:01:46,240 --> 00:01:50,560
so in with the the advance of the router

00:01:50,000 --> 00:01:53,520
service

00:01:50,560 --> 00:01:54,640
when a customer send a request to a

00:01:53,520 --> 00:01:56,719
press ecosystem

00:01:54,640 --> 00:01:57,680
the client will just send a request to

00:01:56,719 --> 00:02:00,079
the router

00:01:57,680 --> 00:02:00,880
and the router will apply kind of

00:02:00,079 --> 00:02:03,759
scheduling

00:02:00,880 --> 00:02:04,640
mechanism such as round-robin or fix the

00:02:03,759 --> 00:02:07,200
routing

00:02:04,640 --> 00:02:08,080
to route the request or redirect your

00:02:07,200 --> 00:02:11,200
request

00:02:08,080 --> 00:02:11,840
to a specific presto cluster so in that

00:02:11,200 --> 00:02:14,560
case

00:02:11,840 --> 00:02:16,560
the customer doesn't need to directly

00:02:14,560 --> 00:02:19,680
send a presto cluster

00:02:16,560 --> 00:02:21,280
with by memorizing the specific endpoint

00:02:19,680 --> 00:02:23,520
of that

00:02:21,280 --> 00:02:25,440
this will give us some benefits for

00:02:23,520 --> 00:02:28,480
example for the scalability

00:02:25,440 --> 00:02:31,440
this makes the whole system very easily

00:02:28,480 --> 00:02:33,200
scaled out for example while we want to

00:02:31,440 --> 00:02:36,879
add a new presto cluster

00:02:33,200 --> 00:02:37,519
we can just add at the cluster and

00:02:36,879 --> 00:02:39,599
register

00:02:37,519 --> 00:02:41,599
the information in the presto router

00:02:39,599 --> 00:02:43,840
site so in that case

00:02:41,599 --> 00:02:44,800
when a client sends a request to the

00:02:43,840 --> 00:02:48,720
presto router

00:02:44,800 --> 00:02:51,200
the the router can help to

00:02:48,720 --> 00:02:52,000
balance the workload across different

00:02:51,200 --> 00:02:54,560
clusters

00:02:52,000 --> 00:02:56,000
and sending some requests to the new

00:02:54,560 --> 00:02:58,800
presto cluster

00:02:56,000 --> 00:03:00,959
so that's also why for the scalability

00:02:58,800 --> 00:03:03,680
the waiting queue will be splitted

00:03:00,959 --> 00:03:04,319
to subclusters to help us to balance the

00:03:03,680 --> 00:03:07,440
load

00:03:04,319 --> 00:03:08,879
onto different clusters and on the other

00:03:07,440 --> 00:03:12,400
side we also have

00:03:08,879 --> 00:03:14,800
aggregated ui and apis set up

00:03:12,400 --> 00:03:16,879
for the presto router service so in that

00:03:14,800 --> 00:03:19,599
case we don't have to

00:03:16,879 --> 00:03:20,319
check the ui of each presto cluster one

00:03:19,599 --> 00:03:23,040
by one

00:03:20,319 --> 00:03:23,840
but we can directly monitor the whole

00:03:23,040 --> 00:03:27,120
status

00:03:23,840 --> 00:03:28,239
of the presto ecosystem by checking the

00:03:27,120 --> 00:03:31,200
aggregated ui

00:03:28,239 --> 00:03:32,239
provided by the press-to-router service

00:03:31,200 --> 00:03:35,200
so that's for

00:03:32,239 --> 00:03:36,400
the scalability and for the availability

00:03:35,200 --> 00:03:39,440
we are using

00:03:36,400 --> 00:03:40,080
a rolling deployment strategy so in that

00:03:39,440 --> 00:03:43,360
case

00:03:40,080 --> 00:03:44,720
even though sometimes one presto cluster

00:03:43,360 --> 00:03:46,480
may be offline

00:03:44,720 --> 00:03:48,640
but there's still some clusters are

00:03:46,480 --> 00:03:50,720
online and then when the

00:03:48,640 --> 00:03:52,720
customer send a request to the presto

00:03:50,720 --> 00:03:53,439
router the router will adjust the router

00:03:52,720 --> 00:03:56,879
request

00:03:53,439 --> 00:03:57,760
to the existing clusters so these are

00:03:56,879 --> 00:04:00,959
some benefits

00:03:57,760 --> 00:04:01,519
of the presto federation system but we

00:04:00,959 --> 00:04:04,000
are still

00:04:01,519 --> 00:04:05,840
seeing some some issues while

00:04:04,000 --> 00:04:07,760
maintaining the previous federation

00:04:05,840 --> 00:04:09,120
system such as sometimes we find that

00:04:07,760 --> 00:04:11,200
they still

00:04:09,120 --> 00:04:12,720
unbalance the workload onto different

00:04:11,200 --> 00:04:14,879
presto clusters

00:04:12,720 --> 00:04:15,760
so that's why we also propose an

00:04:14,879 --> 00:04:18,400
intelligent

00:04:15,760 --> 00:04:19,359
cluster management system where we

00:04:18,400 --> 00:04:22,400
introduce

00:04:19,359 --> 00:04:23,360
two more modules one is a query

00:04:22,400 --> 00:04:26,479
predictor

00:04:23,360 --> 00:04:27,120
and the other is the query scheduler the

00:04:26,479 --> 00:04:30,800
purpose

00:04:27,120 --> 00:04:33,520
of the query predictor is to predict

00:04:30,800 --> 00:04:34,639
the expected results usage of each sql

00:04:33,520 --> 00:04:37,680
query

00:04:34,639 --> 00:04:38,639
with this kind of information the query

00:04:37,680 --> 00:04:41,840
scheduler

00:04:38,639 --> 00:04:42,639
will help to intelligently schedule

00:04:41,840 --> 00:04:47,759
different

00:04:42,639 --> 00:04:47,759
requests to different presto clusters

00:04:48,240 --> 00:04:52,000
one interesting point here for the query

00:04:51,120 --> 00:04:54,880
predictor

00:04:52,000 --> 00:04:57,600
is that we introduce machine learning

00:04:54,880 --> 00:05:01,280
algorithms to try to help us

00:04:57,600 --> 00:05:04,479
to estimate the cpu and memory sources

00:05:01,280 --> 00:05:06,720
expected for each sql query so here

00:05:04,479 --> 00:05:08,800
is a high level design of the query

00:05:06,720 --> 00:05:11,360
predictor service

00:05:08,800 --> 00:05:12,960
first we have some presto logs these are

00:05:11,360 --> 00:05:16,479
some locks generated from

00:05:12,960 --> 00:05:18,400
historical queries so with this request

00:05:16,479 --> 00:05:20,000
logs we apply some machine learning

00:05:18,400 --> 00:05:24,000
mechanisms such as

00:05:20,000 --> 00:05:28,080
random forest or xg boost to train

00:05:24,000 --> 00:05:31,199
two models from the previous presto logs

00:05:28,080 --> 00:05:32,160
one is a cpu model which is used to

00:05:31,199 --> 00:05:35,280
predict

00:05:32,160 --> 00:05:38,400
the cpu time of each sql query

00:05:35,280 --> 00:05:40,400
and we also have a memory model which is

00:05:38,400 --> 00:05:44,639
used to predict the memory

00:05:40,400 --> 00:05:48,080
the peak memory bytes of each sql query

00:05:44,639 --> 00:05:52,080
and then with these two models we

00:05:48,080 --> 00:05:55,280
assemble them into a predictor service

00:05:52,080 --> 00:05:58,080
so in this case for example

00:05:55,280 --> 00:06:00,000
a customer send a request to the router

00:05:58,080 --> 00:06:02,800
and the router may forward

00:06:00,000 --> 00:06:04,000
the query to the predictor service to

00:06:02,800 --> 00:06:07,360
get a sense

00:06:04,000 --> 00:06:08,720
about the results usages needed for sql

00:06:07,360 --> 00:06:11,520
query

00:06:08,720 --> 00:06:11,919
uh at twitter we have also open sourced

00:06:11,520 --> 00:06:13,440
the

00:06:11,919 --> 00:06:15,759
the whole code base of the query

00:06:13,440 --> 00:06:16,400
predictor we have put it in the twitter

00:06:15,759 --> 00:06:20,319
fox

00:06:16,400 --> 00:06:23,600
presto repository

00:06:20,319 --> 00:06:25,919
also with with this we created the web

00:06:23,600 --> 00:06:28,400
application for the query predictor

00:06:25,919 --> 00:06:28,720
where there's a form that the user can

00:06:28,400 --> 00:06:31,600
just

00:06:28,720 --> 00:06:33,199
fill in some sql statements in the form

00:06:31,600 --> 00:06:36,720
and click the predict

00:06:33,199 --> 00:06:40,240
button to get an expected cpu time

00:06:36,720 --> 00:06:44,240
and pick memory bytes of each sql query

00:06:40,240 --> 00:06:47,600
field in the form so that's mainly about

00:06:44,240 --> 00:06:50,160
the work that we have done at twitter

00:06:47,600 --> 00:06:50,720
so that's mainly for the first section

00:06:50,160 --> 00:06:53,039
um

00:06:50,720 --> 00:06:54,080
and then for the second section i would

00:06:53,039 --> 00:06:56,880
like to introduce

00:06:54,080 --> 00:06:58,479
more about the presto aspect connector

00:06:56,880 --> 00:07:02,400
which is used to empower

00:06:58,479 --> 00:07:05,280
sql queries on the open table format

00:07:02,400 --> 00:07:06,479
i know that some of you folks may not

00:07:05,280 --> 00:07:09,520
have much background

00:07:06,479 --> 00:07:11,120
of apache aspect so here i would like to

00:07:09,520 --> 00:07:14,639
give you some like quick

00:07:11,120 --> 00:07:17,759
introduction about this opentable format

00:07:14,639 --> 00:07:20,880
especially filtered for huge analytic

00:07:17,759 --> 00:07:24,000
data sets there are some very useful

00:07:20,880 --> 00:07:26,720
features for apache aspect

00:07:24,000 --> 00:07:28,000
i list some of them here there are some

00:07:26,720 --> 00:07:30,080
schema evolution

00:07:28,000 --> 00:07:31,039
hidden partitioning partition layout

00:07:30,080 --> 00:07:34,560
evolution

00:07:31,039 --> 00:07:38,800
time travel and version drawback

00:07:34,560 --> 00:07:39,280
so so take the first schema evolution as

00:07:38,800 --> 00:07:42,319
a

00:07:39,280 --> 00:07:45,440
as an example so in the

00:07:42,319 --> 00:07:48,160
modern data platform it is quite common

00:07:45,440 --> 00:07:49,759
that sometimes we may need to change the

00:07:48,160 --> 00:07:52,720
schema of a data set

00:07:49,759 --> 00:07:53,919
for example we may add a new column when

00:07:52,720 --> 00:07:57,280
we drop a column

00:07:53,919 --> 00:07:59,440
we may rename a column etc so

00:07:57,280 --> 00:08:02,000
this kind of mechanism the schema

00:07:59,440 --> 00:08:04,720
evolution is naturally supported

00:08:02,000 --> 00:08:06,560
by apache aspect so in that case we

00:08:04,720 --> 00:08:09,039
don't have to worry about

00:08:06,560 --> 00:08:09,759
the changes of schema we'll have we'll

00:08:09,039 --> 00:08:12,479
break some

00:08:09,759 --> 00:08:14,080
some queries this will be handled by

00:08:12,479 --> 00:08:16,800
aspect itself

00:08:14,080 --> 00:08:18,639
for hidden petitioning it means that we

00:08:16,800 --> 00:08:21,759
don't need to explicitly

00:08:18,639 --> 00:08:24,240
assign a petition to a table which

00:08:21,759 --> 00:08:25,520
and this can be handled by asperger

00:08:24,240 --> 00:08:29,199
underneath

00:08:25,520 --> 00:08:31,680
and also it points to another feature

00:08:29,199 --> 00:08:33,760
partition layout evolution which means

00:08:31,680 --> 00:08:36,320
that not only the schema can

00:08:33,760 --> 00:08:37,279
involve but the partition can also

00:08:36,320 --> 00:08:40,159
involve

00:08:37,279 --> 00:08:40,880
for example for for a table previously

00:08:40,159 --> 00:08:44,080
we may

00:08:40,880 --> 00:08:46,160
partition it uh for example by by dates

00:08:44,080 --> 00:08:47,440
but then we may change the petition to

00:08:46,160 --> 00:08:50,720
partition it by

00:08:47,440 --> 00:08:53,680
a month so this kind of thing can

00:08:50,720 --> 00:08:56,080
automatically be taken care by the

00:08:53,680 --> 00:08:57,680
apache aspect table

00:08:56,080 --> 00:08:59,519
and also there are some other useful

00:08:57,680 --> 00:09:02,000
features like time travel

00:08:59,519 --> 00:09:03,600
that a user can travel back to a

00:09:02,000 --> 00:09:06,320
specific timestamp

00:09:03,600 --> 00:09:08,560
to run some queries against that table

00:09:06,320 --> 00:09:11,440
and then there's also a version drawback

00:09:08,560 --> 00:09:12,880
that a user can roll back to a specific

00:09:11,440 --> 00:09:15,760
version

00:09:12,880 --> 00:09:16,399
so here are some some view very useful

00:09:15,760 --> 00:09:20,839
features

00:09:16,399 --> 00:09:23,760
of apache aspect and for the next

00:09:20,839 --> 00:09:27,760
let's maybe uh

00:09:23,760 --> 00:09:30,800
have a maybe a little bit deeper dive

00:09:27,760 --> 00:09:33,760
into the structure into the format of

00:09:30,800 --> 00:09:36,240
uh aspect table and see what is the

00:09:33,760 --> 00:09:39,279
inner mechanism of it

00:09:36,240 --> 00:09:42,480
there are some keywords or some

00:09:39,279 --> 00:09:46,080
uh important specs

00:09:42,480 --> 00:09:49,680
of uh aspect table

00:09:46,080 --> 00:09:52,720
uh i put them here like snapshots

00:09:49,680 --> 00:09:53,200
manifesto list manifesto file partition

00:09:52,720 --> 00:09:56,399
spike

00:09:53,200 --> 00:10:00,240
partition tuple and snapshot log

00:09:56,399 --> 00:10:02,800
snapshot is kind of a state of a table

00:10:00,240 --> 00:10:04,480
at a specific timestamp for example we

00:10:02,800 --> 00:10:07,600
may have a snapshot zero

00:10:04,480 --> 00:10:08,720
or snapshot one shown on the diagram on

00:10:07,600 --> 00:10:11,600
the right

00:10:08,720 --> 00:10:12,959
and then we may have a manifesto list so

00:10:11,600 --> 00:10:16,240
each snapshot

00:10:12,959 --> 00:10:20,079
will have a manifestly list which

00:10:16,240 --> 00:10:23,279
points to a list of manifesto files

00:10:20,079 --> 00:10:27,040
each manifesto file will store

00:10:23,279 --> 00:10:30,399
some metadata information of

00:10:27,040 --> 00:10:34,079
of data files so in that case a manifest

00:10:30,399 --> 00:10:37,279
may point to multiple data files

00:10:34,079 --> 00:10:40,399
and each data file store the

00:10:37,279 --> 00:10:42,079
data start the data set and then we may

00:10:40,399 --> 00:10:45,279
have the petition spike

00:10:42,079 --> 00:10:48,399
partition spike is it's just about

00:10:45,279 --> 00:10:49,680
how to partition the data in a table and

00:10:48,399 --> 00:10:53,360
then partition

00:10:49,680 --> 00:10:56,720
tuple is just a tuple or our struct

00:10:53,360 --> 00:11:00,240
of partition data stored in uh in each

00:10:56,720 --> 00:11:03,040
data file then we have a snapshot log

00:11:00,240 --> 00:11:05,680
snapshot log is installed in a table

00:11:03,040 --> 00:11:08,720
metadata it's just about a log of

00:11:05,680 --> 00:11:12,079
snapshots so here is

00:11:08,720 --> 00:11:15,120
a high level description of the format

00:11:12,079 --> 00:11:18,240
of the does the structure

00:11:15,120 --> 00:11:21,200
of an aspect table so

00:11:18,240 --> 00:11:21,680
maybe it's better to go with an example

00:11:21,200 --> 00:11:24,800
to see

00:11:21,680 --> 00:11:28,640
how it really works

00:11:24,800 --> 00:11:31,920
so here i want to introduce a example

00:11:28,640 --> 00:11:32,880
this is an example from the tpch data

00:11:31,920 --> 00:11:36,160
set

00:11:32,880 --> 00:11:37,360
we especially created aspect table from

00:11:36,160 --> 00:11:39,440
the written data set

00:11:37,360 --> 00:11:41,040
already in the written data set there

00:11:39,440 --> 00:11:44,959
are three columns

00:11:41,040 --> 00:11:48,079
a written key name and comment

00:11:44,959 --> 00:11:51,120
so this is the aspect table created

00:11:48,079 --> 00:11:54,160
from the tbch written table

00:11:51,120 --> 00:11:55,360
there are three files manifest file a

00:11:54,160 --> 00:11:58,720
manifesto list

00:11:55,360 --> 00:12:02,959
manifest and table metadata

00:11:58,720 --> 00:12:06,480
on the left here is the manifesto list

00:12:02,959 --> 00:12:10,160
it is actually stored in an avro format

00:12:06,480 --> 00:12:12,800
file but to make it more humanly

00:12:10,160 --> 00:12:14,000
readable we convert it into a json

00:12:12,800 --> 00:12:17,440
format

00:12:14,000 --> 00:12:20,720
so you see here it has a manifest path

00:12:17,440 --> 00:12:21,519
uh it has like a partition spike id edit

00:12:20,720 --> 00:12:24,720
snapshot

00:12:21,519 --> 00:12:27,519
edit data files count etc this kind of

00:12:24,720 --> 00:12:27,920
data information and then in the middle

00:12:27,519 --> 00:12:31,440
here

00:12:27,920 --> 00:12:34,639
is a manifest it is also stored in an

00:12:31,440 --> 00:12:38,160
avro format but we convert

00:12:34,639 --> 00:12:38,800
convert it into a json format to make it

00:12:38,160 --> 00:12:42,399
more human

00:12:38,800 --> 00:12:44,959
readable it has like status snapshot id

00:12:42,399 --> 00:12:46,079
and then data file remember that for

00:12:44,959 --> 00:12:49,760
each manifest

00:12:46,079 --> 00:12:52,639
it can point to one or more data files

00:12:49,760 --> 00:12:53,920
so here it points to one data file which

00:12:52,639 --> 00:12:57,839
which is the parquet

00:12:53,920 --> 00:13:01,519
file especially used to store the data

00:12:57,839 --> 00:13:03,920
of the written table

00:13:01,519 --> 00:13:04,800
and then on the right here is the table

00:13:03,920 --> 00:13:08,000
metadata

00:13:04,800 --> 00:13:12,000
it is stored in a json file

00:13:08,000 --> 00:13:12,800
it requests metadata information of this

00:13:12,000 --> 00:13:15,600
table

00:13:12,800 --> 00:13:16,480
like the location like the schema you

00:13:15,600 --> 00:13:19,600
see here

00:13:16,480 --> 00:13:23,040
it has a three fields a region key

00:13:19,600 --> 00:13:24,880
name and comment and also there's a

00:13:23,040 --> 00:13:29,040
whether this is required or not

00:13:24,880 --> 00:13:32,160
what is the type of this field etc

00:13:29,040 --> 00:13:33,600
and also you see that here are some

00:13:32,160 --> 00:13:36,639
relationships

00:13:33,600 --> 00:13:39,199
among these three files for example

00:13:36,639 --> 00:13:40,000
for the manifesto here as what i have

00:13:39,199 --> 00:13:43,120
mentioned

00:13:40,000 --> 00:13:43,760
is it has like a data file it has a file

00:13:43,120 --> 00:13:47,120
path

00:13:43,760 --> 00:13:50,160
and a file format which is a parkit file

00:13:47,120 --> 00:13:53,279
and then for example uh here you see

00:13:50,160 --> 00:13:55,120
there's a partition spike id shown in

00:13:53,279 --> 00:13:58,160
the manifesto list

00:13:55,120 --> 00:14:02,399
also this is reflected

00:13:58,160 --> 00:14:05,440
in the table metadata here

00:14:02,399 --> 00:14:08,079
so because when we create the aspect

00:14:05,440 --> 00:14:10,720
table we didn't

00:14:08,079 --> 00:14:11,600
especially assign the partition

00:14:10,720 --> 00:14:16,160
mechanism

00:14:11,600 --> 00:14:18,399
so the fields here is just an empty list

00:14:16,160 --> 00:14:19,519
also you see here on the on the

00:14:18,399 --> 00:14:22,639
manifesto list

00:14:19,519 --> 00:14:23,519
there is added snapshot id and then the

00:14:22,639 --> 00:14:27,680
id is

00:14:23,519 --> 00:14:28,320
of a long type in the manifest you see

00:14:27,680 --> 00:14:30,959
here

00:14:28,320 --> 00:14:31,440
there's also a corresponding information

00:14:30,959 --> 00:14:34,880
about

00:14:31,440 --> 00:14:37,920
related to that this status is one

00:14:34,880 --> 00:14:40,000
one means this is added and then there's

00:14:37,920 --> 00:14:42,560
also the same snapshot id

00:14:40,000 --> 00:14:43,600
exactly the same and recorded in this

00:14:42,560 --> 00:14:46,639
field

00:14:43,600 --> 00:14:47,279
so here is some some structures related

00:14:46,639 --> 00:14:49,199
to

00:14:47,279 --> 00:14:51,040
these files and i'll put them all

00:14:49,199 --> 00:14:54,399
together to construct

00:14:51,040 --> 00:14:57,440
an aspect table so

00:14:54,399 --> 00:15:01,040
how we achieve the mechanism

00:14:57,440 --> 00:15:03,600
to load the data and to write the

00:15:01,040 --> 00:15:04,160
data and to rate the data so there are

00:15:03,600 --> 00:15:07,360
two

00:15:04,160 --> 00:15:09,120
paths one is a write path and the other

00:15:07,360 --> 00:15:11,360
is a read path

00:15:09,120 --> 00:15:12,480
so here what i want to do is to

00:15:11,360 --> 00:15:15,839
introduce more

00:15:12,480 --> 00:15:17,360
about this to path in the presto aspect

00:15:15,839 --> 00:15:21,279
connector

00:15:17,360 --> 00:15:24,880
to take first let's go to the right path

00:15:21,279 --> 00:15:25,519
suppose that the customer found a ctas

00:15:24,880 --> 00:15:28,800
request

00:15:25,519 --> 00:15:31,519
a create table and select request to

00:15:28,800 --> 00:15:32,880
the presto server and then the press of

00:15:31,519 --> 00:15:35,920
server will first

00:15:32,880 --> 00:15:38,720
load data from the data source

00:15:35,920 --> 00:15:40,160
and then for the next step it will need

00:15:38,720 --> 00:15:43,759
to write metadata

00:15:40,160 --> 00:15:46,000
to the meta store because we need to

00:15:43,759 --> 00:15:46,560
construct the metadata related to the

00:15:46,000 --> 00:15:49,120
expert

00:15:46,560 --> 00:15:50,800
table first about some like manifest

00:15:49,120 --> 00:15:53,600
this kind of information

00:15:50,800 --> 00:15:55,360
and then we'll need to write data files

00:15:53,600 --> 00:15:58,560
for example

00:15:55,360 --> 00:16:00,959
take take the previous tph dataset as

00:15:58,560 --> 00:16:03,920
an example it will be like a parquet

00:16:00,959 --> 00:16:06,800
file would store the reader information

00:16:03,920 --> 00:16:08,720
so we'll write this packet file into a

00:16:06,800 --> 00:16:13,199
data sync it can be

00:16:08,720 --> 00:16:16,480
for example hdfs or gcs bucket

00:16:13,199 --> 00:16:19,040
at the same time we'll have a read path

00:16:16,480 --> 00:16:20,000
in a read path the customer will send a

00:16:19,040 --> 00:16:23,040
sql query

00:16:20,000 --> 00:16:25,360
to a presto server and then it's

00:16:23,040 --> 00:16:26,480
it's quite straightforward compared with

00:16:25,360 --> 00:16:29,199
the red path

00:16:26,480 --> 00:16:30,800
the depressor server will load metadata

00:16:29,199 --> 00:16:33,440
information from the

00:16:30,800 --> 00:16:35,279
meta store for example from manifesto

00:16:33,440 --> 00:16:36,320
files from the aspect table to get

00:16:35,279 --> 00:16:38,880
information

00:16:36,320 --> 00:16:40,000
about the data files and then it will

00:16:38,880 --> 00:16:43,199
load data

00:16:40,000 --> 00:16:43,600
from the hdfs or gcs buckets for example

00:16:43,199 --> 00:16:46,880
load

00:16:43,600 --> 00:16:48,800
the dbch packet file and get information

00:16:46,880 --> 00:16:51,519
about it and then return it

00:16:48,800 --> 00:16:52,240
return the results to the customer so

00:16:51,519 --> 00:16:55,519
that's

00:16:52,240 --> 00:16:59,360
the rig path of this information

00:16:55,519 --> 00:17:01,920
and here we also uh deployed

00:16:59,360 --> 00:17:02,800
the whole thing in a double presto

00:17:01,920 --> 00:17:05,839
server

00:17:02,800 --> 00:17:08,319
and at twitter we are using exactly

00:17:05,839 --> 00:17:10,400
notebooks which is a web-based

00:17:08,319 --> 00:17:12,480
analytical tool

00:17:10,400 --> 00:17:14,000
to help us to run some queries against

00:17:12,480 --> 00:17:16,959
the presto servers

00:17:14,000 --> 00:17:18,480
to get some results so here is an

00:17:16,959 --> 00:17:22,160
example

00:17:18,480 --> 00:17:25,039
notebook that we have created to query

00:17:22,160 --> 00:17:26,480
uh the data through presto aspect

00:17:25,039 --> 00:17:29,360
connector

00:17:26,480 --> 00:17:32,240
so here in a zeppelin notebook here's a

00:17:29,360 --> 00:17:34,640
prefix you see here this is a jdbc

00:17:32,240 --> 00:17:35,919
presto dash aspect this is called the

00:17:34,640 --> 00:17:39,039
prefix

00:17:35,919 --> 00:17:40,720
in doubling it means that it usually

00:17:39,039 --> 00:17:43,360
give us

00:17:40,720 --> 00:17:43,760
it is called the interpreter that can

00:17:43,360 --> 00:17:46,960
have

00:17:43,760 --> 00:17:47,520
access to a specific presto cluster so

00:17:46,960 --> 00:17:50,000
here

00:17:47,520 --> 00:17:51,440
this is actually points to a double

00:17:50,000 --> 00:17:54,080
presto server

00:17:51,440 --> 00:17:55,200
which we have enabled presto aspect

00:17:54,080 --> 00:17:58,720
connector

00:17:55,200 --> 00:18:01,840
and then we use aspect.tpch

00:17:58,720 --> 00:18:04,400
and then we ran two uh ctas

00:18:01,840 --> 00:18:05,120
statements uh create create table if not

00:18:04,400 --> 00:18:08,400
exist

00:18:05,120 --> 00:18:09,520
of from the nation and customer so these

00:18:08,400 --> 00:18:12,720
are two

00:18:09,520 --> 00:18:16,320
new uh tables in

00:18:12,720 --> 00:18:19,679
apache aspect format and then we ran

00:18:16,320 --> 00:18:21,039
a sequel statement with a join with a

00:18:19,679 --> 00:18:24,400
join

00:18:21,039 --> 00:18:27,360
join command to join the customer

00:18:24,400 --> 00:18:28,720
the newly created customer and the newly

00:18:27,360 --> 00:18:31,200
created

00:18:28,720 --> 00:18:32,080
nation table together and get some

00:18:31,200 --> 00:18:35,120
information

00:18:32,080 --> 00:18:38,400
about customers name and their

00:18:35,120 --> 00:18:41,760
nations so here you see that this

00:18:38,400 --> 00:18:44,799
is the table underneath

00:18:41,760 --> 00:18:47,840
shows the query results from

00:18:44,799 --> 00:18:51,440
the presta site which has enabled

00:18:47,840 --> 00:18:54,799
the presto aspect connector

00:18:51,440 --> 00:18:57,039
so you'll see this is a general idea

00:18:54,799 --> 00:18:59,919
of the whole thing that how we use the

00:18:57,039 --> 00:19:03,840
query the presto aspect connector

00:18:59,919 --> 00:19:08,240
to query data or the right data

00:19:03,840 --> 00:19:08,240
to to the iceberg table

00:19:09,039 --> 00:19:15,280
and also we are having some future work

00:19:12,080 --> 00:19:16,400
to do to improve the work improve the

00:19:15,280 --> 00:19:19,520
current work

00:19:16,400 --> 00:19:22,799
for now we have sent a pr to the

00:19:19,520 --> 00:19:24,000
presto repository uh which has a basic

00:19:22,799 --> 00:19:26,960
support like the red

00:19:24,000 --> 00:19:27,840
path the read path for the presto aspect

00:19:26,960 --> 00:19:29,919
connector

00:19:27,840 --> 00:19:31,679
we are planning some future work that to

00:19:29,919 --> 00:19:34,480
help us to improve

00:19:31,679 --> 00:19:36,720
uh the current work for example for now

00:19:34,480 --> 00:19:39,919
we only support packet files

00:19:36,720 --> 00:19:41,200
we also want to add orc support into the

00:19:39,919 --> 00:19:43,520
file format

00:19:41,200 --> 00:19:44,320
uh for now we also would like to add a

00:19:43,520 --> 00:19:46,960
snapchat

00:19:44,320 --> 00:19:48,320
snapshot support to help us to add like

00:19:46,960 --> 00:19:51,600
like snapshots

00:19:48,320 --> 00:19:54,720
uh so in that case when the user send a

00:19:51,600 --> 00:19:56,880
random query the user can select

00:19:54,720 --> 00:19:57,919
with the specific snapshot to run the

00:19:56,880 --> 00:20:00,000
query

00:19:57,919 --> 00:20:02,400
and also we want to support a schema

00:20:00,000 --> 00:20:06,159
evolution like adding new columns

00:20:02,400 --> 00:20:08,880
dropping columns renaming columns etc

00:20:06,159 --> 00:20:10,240
uh also we we also would like to add

00:20:08,880 --> 00:20:13,039
like time travel

00:20:10,240 --> 00:20:15,440
and also the version rollback features

00:20:13,039 --> 00:20:18,320
in the press to as per connect

00:20:15,440 --> 00:20:19,600
yeah so that's supposedly what i want to

00:20:18,320 --> 00:20:22,559
talk about today

00:20:19,600 --> 00:20:24,320
i am always ready to help so if you have

00:20:22,559 --> 00:20:26,640
any questions related to like

00:20:24,320 --> 00:20:27,520
presto twitter or the presto aspect

00:20:26,640 --> 00:20:29,679
connector

00:20:27,520 --> 00:20:30,880
feel free to reach out to me in the

00:20:29,679 --> 00:20:32,559
slack channel

00:20:30,880 --> 00:20:35,200
and that's all i want to talk about

00:20:32,559 --> 00:20:38,559
today and thank you

00:20:35,200 --> 00:20:38,559

YouTube URL: https://www.youtube.com/watch?v=M8HLX2CivpI


