Title: How Carbon uses PrestoDB in the Cloud with Ahana to Power its Real-time Customer D... Jordan Hoggart
Publication date: 2021-03-27
Playlist: PrestoCon Day 2021 - Virtual
Description: 
	How Carbon uses PrestoDB in the Cloud with Ahana to Power its Real-time Customer Dashboards - Jordan Hoggart, Carbon

Carbon is a real-time revenue management platform that consolidates revenue and audience analytics, data management, and yield operations into a single solution. Real-time analytics is super critical - their customers rely on real-time data to make revenue decisions. After facing issues around performance, visibility & ease of use, and serverless pricing model with AWS Athena, the team moved to a managed service for PrestoDB in the cloud - Ahana Cloud - to power their customer-facing dashboards. In this session, Jordan will discuss some of the reasons the team moved from AWS Athena to a managed PrestoDB on Intel-optimized AWS instances. He will also dive into their current architecture that includes an Ahana-managed Hive Metastore along with Apache ORC file format and an S3-based data lake. Last, he’ll share some performance benchmarks and talk about what’s next for PrestoDB at Carbon. 

For more info about Presto, the open source distributed SQL query engine for running interactive analytic queries against data sources of all sizes ranging from gigabytes to petabytes, see: https://prestodb.io/
Captions: 
	00:00:00,480 --> 00:00:04,000
so hey there i'm jordan and i'm a data

00:00:03,040 --> 00:00:06,240
engineer at carbon

00:00:04,000 --> 00:00:08,080
i'm just going to be going over uh how

00:00:06,240 --> 00:00:11,120
we make use of presto

00:00:08,080 --> 00:00:12,639
and particularly how we end up powering

00:00:11,120 --> 00:00:16,560
one of our customer fishing

00:00:12,639 --> 00:00:19,760
dashboards with it

00:00:16,560 --> 00:00:21,279
so to start off with uh i'm just going

00:00:19,760 --> 00:00:24,080
to go over a quick introduction

00:00:21,279 --> 00:00:24,560
of carbon and kind of what it is we do

00:00:24,080 --> 00:00:27,039
um

00:00:24,560 --> 00:00:28,160
just for a bit of background context to

00:00:27,039 --> 00:00:30,320
some of the

00:00:28,160 --> 00:00:31,679
problems we're kind of coming up to

00:00:30,320 --> 00:00:33,760
related to um

00:00:31,679 --> 00:00:36,000
scaling as we start to uh as we start to

00:00:33,760 --> 00:00:39,360
grow and get more volume coming through

00:00:36,000 --> 00:00:42,840
and why we kind of chose

00:00:39,360 --> 00:00:46,000
presto uh to power the dashboard

00:00:42,840 --> 00:00:49,920
and it's kind of split into

00:00:46,000 --> 00:00:51,840
two phases and the first is the kind of

00:00:49,920 --> 00:00:53,920
first solution that we use which was

00:00:51,840 --> 00:00:54,160
using a serverless version of presto

00:00:53,920 --> 00:00:57,120
with

00:00:54,160 --> 00:00:58,399
address athena and what we've been doing

00:00:57,120 --> 00:01:00,320
more recently

00:00:58,399 --> 00:01:03,600
which was moving over to a managed

00:01:00,320 --> 00:01:06,000
service with um with a hana

00:01:03,600 --> 00:01:07,439
and then questions at the end but uh if

00:01:06,000 --> 00:01:10,640
there's any questions as we go through

00:01:07,439 --> 00:01:12,240
just probably in the chat okay so who

00:01:10,640 --> 00:01:14,560
are we and what do we do

00:01:12,240 --> 00:01:16,080
well there's a little bit of information

00:01:14,560 --> 00:01:19,119
on our vision mission there

00:01:16,080 --> 00:01:22,159
but for a quick tldr we

00:01:19,119 --> 00:01:25,280
are an ad tech focused business and we

00:01:22,159 --> 00:01:26,080
are focused on publishers and we also

00:01:25,280 --> 00:01:29,040
recognize the

00:01:26,080 --> 00:01:29,439
uh the importance of advertising that

00:01:29,040 --> 00:01:31,920
and

00:01:29,439 --> 00:01:33,759
the way we provide value is by taking

00:01:31,920 --> 00:01:35,040
their first party data in from a number

00:01:33,759 --> 00:01:37,040
of different streams

00:01:35,040 --> 00:01:38,400
uh enriching it with our different data

00:01:37,040 --> 00:01:40,560
pipelines we've got

00:01:38,400 --> 00:01:41,759
and then displaying that back in front

00:01:40,560 --> 00:01:44,479
of them in a

00:01:41,759 --> 00:01:46,000
easier to digest where and along without

00:01:44,479 --> 00:01:47,840
the platform there's also some

00:01:46,000 --> 00:01:49,280
kind of simpler solutions to the more

00:01:47,840 --> 00:01:50,079
complex problems that they're having

00:01:49,280 --> 00:01:53,439
that surround their

00:01:50,079 --> 00:01:54,240
revenue operations and while we're doing

00:01:53,439 --> 00:01:55,680
that we're also

00:01:54,240 --> 00:01:57,680
kind of committed to the long-term

00:01:55,680 --> 00:01:59,280
success of the tech industry

00:01:57,680 --> 00:02:01,200
and we're kind of at the front of the

00:01:59,280 --> 00:02:02,880
privacy and consent and

00:02:01,200 --> 00:02:05,360
all that stuff because that space is

00:02:02,880 --> 00:02:09,200
changing quite a lot these days

00:02:05,360 --> 00:02:12,160
so how exactly do we do that well

00:02:09,200 --> 00:02:13,040
we kind of sit in the middle of a bunch

00:02:12,160 --> 00:02:14,879
of different

00:02:13,040 --> 00:02:17,120
uh important questions that um

00:02:14,879 --> 00:02:18,959
publishers might have things like

00:02:17,120 --> 00:02:20,480
who's my audience what are they doing

00:02:18,959 --> 00:02:22,319
and probably the most important one how

00:02:20,480 --> 00:02:25,360
much is my audience worth

00:02:22,319 --> 00:02:25,680
and we aim to simplify those questions

00:02:25,360 --> 00:02:27,599
and

00:02:25,680 --> 00:02:28,800
provide answers to them uh with the

00:02:27,599 --> 00:02:31,120
dashboard

00:02:28,800 --> 00:02:32,720
um to provide insights there for that

00:02:31,120 --> 00:02:34,640
and once they have those

00:02:32,720 --> 00:02:36,400
that deer in front of them they can then

00:02:34,640 --> 00:02:37,760
action it and do things like export the

00:02:36,400 --> 00:02:38,480
audience to something like google ad

00:02:37,760 --> 00:02:41,680
manager for

00:02:38,480 --> 00:02:45,200
to run a campaign for example

00:02:41,680 --> 00:02:46,879
and just to get an idea of these sort of

00:02:45,200 --> 00:02:49,519
different data streams we've got coming

00:02:46,879 --> 00:02:51,760
in we've got things like demographic and

00:02:49,519 --> 00:02:53,680
technographic information

00:02:51,760 --> 00:02:55,120
a custom taxonomy that we curate

00:02:53,680 --> 00:02:56,879
ourselves and

00:02:55,120 --> 00:02:58,720
various bits of pieces of real-time

00:02:56,879 --> 00:02:59,760
information so we've kind of got a lot

00:02:58,720 --> 00:03:02,000
of different streams that we take

00:02:59,760 --> 00:03:05,200
together for ingress process and then

00:03:02,000 --> 00:03:07,760
we have to kind of do all of these um

00:03:05,200 --> 00:03:09,360
aggregations and display in a meaningful

00:03:07,760 --> 00:03:11,040
way

00:03:09,360 --> 00:03:13,680
and the way we do that is the data

00:03:11,040 --> 00:03:16,480
eventually ends up in our revenue

00:03:13,680 --> 00:03:18,000
management platform where kind of you

00:03:16,480 --> 00:03:19,120
can see all the different breakdowns for

00:03:18,000 --> 00:03:22,000
a bunch of different things

00:03:19,120 --> 00:03:22,800
and i'll go a bit more into that in a

00:03:22,000 --> 00:03:25,440
moment

00:03:22,800 --> 00:03:26,799
uh but just to get an idea of the kind

00:03:25,440 --> 00:03:30,560
of um

00:03:26,799 --> 00:03:32,879
skill that we're operating up uh

00:03:30,560 --> 00:03:34,799
recently uh it's been around eight

00:03:32,879 --> 00:03:35,920
billion monthly events and over 100

00:03:34,799 --> 00:03:39,519
million web pages

00:03:35,920 --> 00:03:43,280
which i understand isn't crazy numbers

00:03:39,519 --> 00:03:45,680
but it's certainly not trivial and

00:03:43,280 --> 00:03:46,640
the kind of problem we're facing now is

00:03:45,680 --> 00:03:48,879
those numbers

00:03:46,640 --> 00:03:50,319
are only going up at quite a quite a

00:03:48,879 --> 00:03:52,239
quite a big rate

00:03:50,319 --> 00:03:53,760
and we need to make sure that different

00:03:52,239 --> 00:03:54,959
parts of the platform are kind of ready

00:03:53,760 --> 00:03:57,519
to handle that

00:03:54,959 --> 00:03:59,280
and that includes scaling um the

00:03:57,519 --> 00:04:02,000
solutions are powering

00:03:59,280 --> 00:04:03,920
something like the insights view and

00:04:02,000 --> 00:04:04,959
this insights view is kind of one of the

00:04:03,920 --> 00:04:07,040
most

00:04:04,959 --> 00:04:08,480
uh important parts of platform arguments

00:04:07,040 --> 00:04:10,879
it's kind of has all of the different

00:04:08,480 --> 00:04:14,400
breakdowns for um

00:04:10,879 --> 00:04:15,599
for the publishers and there are a bunch

00:04:14,400 --> 00:04:17,440
of different presto breweries that are

00:04:15,599 --> 00:04:19,359
feeding the information into this

00:04:17,440 --> 00:04:21,440
uh there's all bits and pieces to do you

00:04:19,359 --> 00:04:23,040
know some are just doing simple counts

00:04:21,440 --> 00:04:24,720
others doing things like category

00:04:23,040 --> 00:04:26,800
grouping and date grouping

00:04:24,720 --> 00:04:28,160
but there are a few that are doing a bit

00:04:26,800 --> 00:04:30,960
a bit more complex stuff

00:04:28,160 --> 00:04:31,600
like um there are some tiles that have

00:04:30,960 --> 00:04:34,080
like

00:04:31,600 --> 00:04:35,919
uh trending sort of values to kind of

00:04:34,080 --> 00:04:37,520
show that or maybe a brand over the last

00:04:35,919 --> 00:04:39,120
few days has picked a bit of traction

00:04:37,520 --> 00:04:40,560
and there's been increasing that

00:04:39,120 --> 00:04:42,720
it's those sort of things are important

00:04:40,560 --> 00:04:44,000
to point out that publishers can then

00:04:42,720 --> 00:04:46,240
take that information then go do

00:04:44,000 --> 00:04:47,120
something with it and that's why we need

00:04:46,240 --> 00:04:50,080
something like

00:04:47,120 --> 00:04:51,199
press store to query against it and

00:04:50,080 --> 00:04:53,199
they're kind of seven

00:04:51,199 --> 00:04:54,960
main breakdowns or significant

00:04:53,199 --> 00:04:56,720
breakdowns on there

00:04:54,960 --> 00:04:58,639
and it would be nice if we could just

00:04:56,720 --> 00:04:59,280
pre-compute a lot of the values onto it

00:04:58,639 --> 00:05:01,360
and just

00:04:59,280 --> 00:05:02,880
kind of be done it sort of like a daily

00:05:01,360 --> 00:05:04,639
pipeline flow

00:05:02,880 --> 00:05:06,720
but the problem is is there's a lot of

00:05:04,639 --> 00:05:09,199
ways to kind of interact with the data

00:05:06,720 --> 00:05:11,039
the first being customizable data ranges

00:05:09,199 --> 00:05:13,759
so the default views give you

00:05:11,039 --> 00:05:14,560
like a week time range but users can

00:05:13,759 --> 00:05:16,720
select

00:05:14,560 --> 00:05:18,720
any sort of date range within a 30 day

00:05:16,720 --> 00:05:21,120
window so

00:05:18,720 --> 00:05:22,639
there's quite a lot of choice there and

00:05:21,120 --> 00:05:24,240
okay maybe we could do

00:05:22,639 --> 00:05:25,919
different kind of accumulations with

00:05:24,240 --> 00:05:28,320
date partitions

00:05:25,919 --> 00:05:29,919
but the problem we also have is there

00:05:28,320 --> 00:05:31,280
are more ways to drill into the like

00:05:29,919 --> 00:05:34,320
doing things like

00:05:31,280 --> 00:05:35,759
uh you could add a filter to say take

00:05:34,320 --> 00:05:37,120
all of these insights you just showed me

00:05:35,759 --> 00:05:40,240
but she'll be for

00:05:37,120 --> 00:05:42,000
only people who have uh a desktop or are

00:05:40,240 --> 00:05:43,520
interested in video games or something

00:05:42,000 --> 00:05:45,199
and all of those different breakdowns

00:05:43,520 --> 00:05:45,759
like the intent demographic and brand

00:05:45,199 --> 00:05:48,080
would have to

00:05:45,759 --> 00:05:49,120
update so we needed a query engine to

00:05:48,080 --> 00:05:50,880
kind of sit behind

00:05:49,120 --> 00:05:52,880
and serve that presto was the choice we

00:05:50,880 --> 00:05:56,319
went for and that's been working out

00:05:52,880 --> 00:05:57,919
really well so far um i won't go into

00:05:56,319 --> 00:05:59,520
this too much but he's kind of just a

00:05:57,919 --> 00:06:00,960
sample query of one of the simpler ones

00:05:59,520 --> 00:06:02,880
for the brand breakdown

00:06:00,960 --> 00:06:04,400
so a lot of conditional aggregation in

00:06:02,880 --> 00:06:06,960
there

00:06:04,400 --> 00:06:09,039
has a decent amount of data so again

00:06:06,960 --> 00:06:11,199
nothing crazy for someone like this but

00:06:09,039 --> 00:06:12,240
as the data starts to bump up it can

00:06:11,199 --> 00:06:15,840
really get nasty

00:06:12,240 --> 00:06:17,759
uh in terms of cluster killing and

00:06:15,840 --> 00:06:20,720
speaking of data this is kind of the

00:06:17,759 --> 00:06:23,840
dimensions we're working on recently um

00:06:20,720 --> 00:06:25,759
so like 180 billion profiles with 56

00:06:23,840 --> 00:06:27,360
million brands isn't too bad

00:06:25,759 --> 00:06:29,199
but when you get into the billions with

00:06:27,360 --> 00:06:31,199
the interest and demographics

00:06:29,199 --> 00:06:32,960
this is where it's starting to kind of

00:06:31,199 --> 00:06:36,720
hurt a little bit

00:06:32,960 --> 00:06:38,960
and the solution that we've been using

00:06:36,720 --> 00:06:39,919
so far so for the first two years of

00:06:38,960 --> 00:06:43,600
operation

00:06:39,919 --> 00:06:44,960
was athena and i think a lot of people

00:06:43,600 --> 00:06:45,759
would be familiar with thinner but it's

00:06:44,960 --> 00:06:47,919
basically

00:06:45,759 --> 00:06:49,039
amazon's serverless query engine what

00:06:47,919 --> 00:06:50,080
they offer up

00:06:49,039 --> 00:06:52,479
and under the hood it's running a

00:06:50,080 --> 00:06:54,080
modified version of presto and so it

00:06:52,479 --> 00:06:56,400
seemed like an ideal fit for us

00:06:54,080 --> 00:06:57,599
and it was because it was serverless so

00:06:56,400 --> 00:06:59,280
the setup was simple

00:06:57,599 --> 00:07:00,800
because there basically was no setup you

00:06:59,280 --> 00:07:03,759
could just start writing queries and get

00:07:00,800 --> 00:07:05,199
get going with things um and it also had

00:07:03,759 --> 00:07:05,599
all the different connectors in place to

00:07:05,199 --> 00:07:08,080
make

00:07:05,599 --> 00:07:09,680
uh to make use of so we could query the

00:07:08,080 --> 00:07:11,840
data that we output in s3

00:07:09,680 --> 00:07:13,039
straight away there was no need to move

00:07:11,840 --> 00:07:14,319
the data anywhere we could just kind of

00:07:13,039 --> 00:07:17,440
get going with it

00:07:14,319 --> 00:07:19,199
and it's also maintained by the adverse

00:07:17,440 --> 00:07:20,720
team so there's no need to worry about

00:07:19,199 --> 00:07:21,759
kind of setting up infrastructure and

00:07:20,720 --> 00:07:23,840
managing all of that

00:07:21,759 --> 00:07:25,120
the operational overhead again simple to

00:07:23,840 --> 00:07:27,280
get going

00:07:25,120 --> 00:07:30,080
and one of the best things early on was

00:07:27,280 --> 00:07:32,560
the kind of pricing model which uh you

00:07:30,080 --> 00:07:34,880
just paid based off the data scanned

00:07:32,560 --> 00:07:36,400
which sounds bad in the long run but

00:07:34,880 --> 00:07:37,919
when you're starting off and you've only

00:07:36,400 --> 00:07:39,280
got a limited amount of data through and

00:07:37,919 --> 00:07:40,319
there's only a few clients going on the

00:07:39,280 --> 00:07:41,759
dashboard

00:07:40,319 --> 00:07:43,680
it made sense because we didn't have to

00:07:41,759 --> 00:07:45,520
think about uh under or over

00:07:43,680 --> 00:07:47,360
provisioning an expensive course to run

00:07:45,520 --> 00:07:48,960
the queries we could just let athena

00:07:47,360 --> 00:07:50,400
hand all of that and

00:07:48,960 --> 00:07:52,400
just pay for the small amount of usage

00:07:50,400 --> 00:07:53,520
we had with it which was great for a

00:07:52,400 --> 00:07:55,440
while

00:07:53,520 --> 00:07:56,560
uh although even then when we were using

00:07:55,440 --> 00:08:00,000
it there were a couple of

00:07:56,560 --> 00:08:01,919
bad points about it um one was that

00:08:00,000 --> 00:08:03,280
it could be a little bit unpredictable

00:08:01,919 --> 00:08:07,039
sometimes and

00:08:03,280 --> 00:08:10,160
um what i mean by that is

00:08:07,039 --> 00:08:11,599
you could run a query and it would fail

00:08:10,160 --> 00:08:13,840
then you could rerun it a minute later

00:08:11,599 --> 00:08:15,440
it would succeed with no changes to the

00:08:13,840 --> 00:08:17,360
data or query

00:08:15,440 --> 00:08:18,960
and kind of one of the working theories

00:08:17,360 --> 00:08:20,560
we had there was maybe edwards was

00:08:18,960 --> 00:08:21,520
running out like a service update or

00:08:20,560 --> 00:08:22,960
something in the background it wouldn't

00:08:21,520 --> 00:08:25,199
happen often but

00:08:22,960 --> 00:08:26,319
it did occur and it was kind of unusual

00:08:25,199 --> 00:08:29,680
when it did so

00:08:26,319 --> 00:08:30,080
that was a bit strange um and speaking

00:08:29,680 --> 00:08:31,520
of

00:08:30,080 --> 00:08:33,599
not too much control i know what's going

00:08:31,520 --> 00:08:34,959
on uh going on um

00:08:33,599 --> 00:08:37,039
you'd have no control of the session

00:08:34,959 --> 00:08:38,560
parameters so the queries that you

00:08:37,039 --> 00:08:39,360
submit to athena just running a single

00:08:38,560 --> 00:08:40,959
session

00:08:39,360 --> 00:08:43,279
and you can't do anything like change

00:08:40,959 --> 00:08:44,560
the um change the join types of things

00:08:43,279 --> 00:08:46,880
like that and tweak the

00:08:44,560 --> 00:08:47,839
tweak the settings on it which was kind

00:08:46,880 --> 00:08:51,120
of a shame

00:08:47,839 --> 00:08:52,800
um and one of the big things was

00:08:51,120 --> 00:08:54,640
that it's running kind of a mysterious

00:08:52,800 --> 00:08:57,120
version of presto under the hood

00:08:54,640 --> 00:08:58,480
and up until recently i think back in

00:08:57,120 --> 00:09:00,480
december it was that

00:08:58,480 --> 00:09:02,560
they brought up a new version of it but

00:09:00,480 --> 00:09:05,519
the first version of athena was running

00:09:02,560 --> 00:09:06,640
back on presto 172 which from the other

00:09:05,519 --> 00:09:08,160
talks today you can see there are quite

00:09:06,640 --> 00:09:09,040
a lot of improvements that go into

00:09:08,160 --> 00:09:12,080
presto

00:09:09,040 --> 00:09:14,240
i think we're on like nearly 250 now and

00:09:12,080 --> 00:09:15,200
kind of athena was stuck on that older

00:09:14,240 --> 00:09:17,920
version and

00:09:15,200 --> 00:09:18,959
not only that it was uh amazon's

00:09:17,920 --> 00:09:22,480
modified version

00:09:18,959 --> 00:09:24,560
of athena so what it was

00:09:22,480 --> 00:09:25,680
not entirely sure but the syntax is ever

00:09:24,560 --> 00:09:28,160
so slightly different

00:09:25,680 --> 00:09:29,680
just just annoyingly enough to uh where

00:09:28,160 --> 00:09:30,240
copied certain things across won't quite

00:09:29,680 --> 00:09:33,360
work

00:09:30,240 --> 00:09:36,399
um so that was a shame but not a

00:09:33,360 --> 00:09:39,120
kind of deal killer but

00:09:36,399 --> 00:09:40,320
the the deal breakers that we did get uh

00:09:39,120 --> 00:09:42,880
recently

00:09:40,320 --> 00:09:44,240
are related more to scaling and it's

00:09:42,880 --> 00:09:46,320
that

00:09:44,240 --> 00:09:47,279
once your query kind of hits a certain

00:09:46,320 --> 00:09:49,279
size

00:09:47,279 --> 00:09:50,720
athena just won't be able to handle it

00:09:49,279 --> 00:09:52,080
it could won't really scale past a

00:09:50,720 --> 00:09:54,240
certain point

00:09:52,080 --> 00:09:55,760
and there's no real option to say or can

00:09:54,240 --> 00:09:57,440
i run this query in like

00:09:55,760 --> 00:09:59,920
super mode or something to give you you

00:09:57,440 --> 00:10:01,200
know maybe pay more to get more but that

00:09:59,920 --> 00:10:03,360
just isn't an option at a certain point

00:10:01,200 --> 00:10:04,959
queries will just stop running and their

00:10:03,360 --> 00:10:05,680
only real advice is to write different

00:10:04,959 --> 00:10:07,360
queries

00:10:05,680 --> 00:10:08,800
which i mean yeah it's good to rewrite

00:10:07,360 --> 00:10:10,959
your queries but

00:10:08,800 --> 00:10:12,240
if the dashboard's starting to die and

00:10:10,959 --> 00:10:12,640
we can't really do anything more about

00:10:12,240 --> 00:10:15,839
that

00:10:12,640 --> 00:10:18,720
that's really not ideal so

00:10:15,839 --> 00:10:20,880
another big problem is there's only one

00:10:18,720 --> 00:10:22,800
athena service that's alive

00:10:20,880 --> 00:10:24,880
and it's also shared between other

00:10:22,800 --> 00:10:27,120
people's airways accounts not just yours

00:10:24,880 --> 00:10:28,880
so if other people are running a lot of

00:10:27,120 --> 00:10:30,959
big previews against athena

00:10:28,880 --> 00:10:32,240
then your performance from it can

00:10:30,959 --> 00:10:35,600
actually suffer as well

00:10:32,240 --> 00:10:36,560
which again not ideal and all of this is

00:10:35,600 --> 00:10:39,120
sat behind

00:10:36,560 --> 00:10:40,240
a single queue so if the data scientist

00:10:39,120 --> 00:10:41,600
wanted to do some

00:10:40,240 --> 00:10:44,000
ad hoc queries against something that

00:10:41,600 --> 00:10:46,079
would be taking i don't know a long time

00:10:44,000 --> 00:10:47,600
doing a bunch of different things um

00:10:46,079 --> 00:10:49,760
that could end up blocking

00:10:47,600 --> 00:10:51,279
the dashboard from loading because those

00:10:49,760 --> 00:10:52,240
other queries would be sat behind that

00:10:51,279 --> 00:10:54,720
one

00:10:52,240 --> 00:10:56,399
and in the documentation it mentions a

00:10:54,720 --> 00:10:57,279
concurrency limit of around 20 for an

00:10:56,399 --> 00:11:00,640
account

00:10:57,279 --> 00:11:03,440
but we saw was hitting the acute status

00:11:00,640 --> 00:11:04,240
as low as two queries which we weren't

00:11:03,440 --> 00:11:06,320
too bothered about

00:11:04,240 --> 00:11:07,279
having high concurrency but two queries

00:11:06,320 --> 00:11:10,320
at a time was

00:11:07,279 --> 00:11:11,200
really not working for us so it led to

00:11:10,320 --> 00:11:13,680
us looking to

00:11:11,200 --> 00:11:15,680
a different solution which was running

00:11:13,680 --> 00:11:17,760
oppressor across ourselves

00:11:15,680 --> 00:11:19,279
but what we stumbled upon was a hana

00:11:17,760 --> 00:11:20,160
which would be a managed service for

00:11:19,279 --> 00:11:22,959
that

00:11:20,160 --> 00:11:24,000
so we still kind of got that benefit of

00:11:22,959 --> 00:11:25,920
um

00:11:24,000 --> 00:11:27,680
the low operational overhead it was just

00:11:25,920 --> 00:11:28,000
deploying a cloud formation template and

00:11:27,680 --> 00:11:30,480
getting

00:11:28,000 --> 00:11:31,440
running and using things like superset

00:11:30,480 --> 00:11:35,360
coming built in

00:11:31,440 --> 00:11:38,959
to do some work with it uh which is nice

00:11:35,360 --> 00:11:42,399
but without all of the uh

00:11:38,959 --> 00:11:43,760
limitations that athena had and

00:11:42,399 --> 00:11:45,680
one of the first things we did was do a

00:11:43,760 --> 00:11:49,360
bit of benchmarking

00:11:45,680 --> 00:11:50,880
because the initial fear was that um

00:11:49,360 --> 00:11:52,639
athena actually in the background this

00:11:50,880 --> 00:11:54,079
is super beast of a cluster that's just

00:11:52,639 --> 00:11:56,000
got it's saying about compute power that

00:11:54,079 --> 00:11:59,279
we'd have to pay a ridiculous amount to

00:11:56,000 --> 00:12:00,480
try and match but you can see here in

00:11:59,279 --> 00:12:03,440
some of the benchmarking

00:12:00,480 --> 00:12:04,560
that even on smaller clusters like the

00:12:03,440 --> 00:12:07,680
three times

00:12:04,560 --> 00:12:10,720
c52x large which is pounded our cluster

00:12:07,680 --> 00:12:12,480
um that was actually getting you know

00:12:10,720 --> 00:12:13,760
not too close to athena queries but it

00:12:12,480 --> 00:12:15,680
was surprising that it was

00:12:13,760 --> 00:12:18,000
um matching on something like the

00:12:15,680 --> 00:12:20,720
overview query the first query there

00:12:18,000 --> 00:12:22,000
and as we scaled up the cluster even by

00:12:20,720 --> 00:12:24,320
small amounts

00:12:22,000 --> 00:12:26,160
we could actually start to get close to

00:12:24,320 --> 00:12:27,839
athena level numbers for a lot of the

00:12:26,160 --> 00:12:29,120
main queries of the dashboard which was

00:12:27,839 --> 00:12:30,800
a big surprise at first it thought it

00:12:29,120 --> 00:12:34,240
was going to be a lot harder to uh

00:12:30,800 --> 00:12:37,120
to home in on that athena performance um

00:12:34,240 --> 00:12:38,480
and another important thing is being

00:12:37,120 --> 00:12:41,920
able to control

00:12:38,480 --> 00:12:44,800
the configuration of the cluster um

00:12:41,920 --> 00:12:45,440
just by changing the node type so having

00:12:44,800 --> 00:12:49,360
more

00:12:45,440 --> 00:12:50,959
smaller nodes versus a few bigger nodes

00:12:49,360 --> 00:12:52,160
in our case it was actually able to

00:12:50,959 --> 00:12:53,279
improve the performance of some of the

00:12:52,160 --> 00:12:55,519
queries

00:12:53,279 --> 00:12:57,040
so that's something we wouldn't have had

00:12:55,519 --> 00:12:58,480
any control over with athena it was just

00:12:57,040 --> 00:12:59,680
we had to use whatever thing this

00:12:58,480 --> 00:13:01,040
configuration was

00:12:59,680 --> 00:13:03,279
whereas now we have a lot more control

00:13:01,040 --> 00:13:06,480
of that kind of fine tune it to

00:13:03,279 --> 00:13:07,279
meet our workloads um some of the bigger

00:13:06,480 --> 00:13:09,279
queries like

00:13:07,279 --> 00:13:10,800
characterization demographic with those

00:13:09,279 --> 00:13:12,240
billions of rows were still a little bit

00:13:10,800 --> 00:13:15,200
tougher to hold in on

00:13:12,240 --> 00:13:16,160
but even then not as not as bad as we

00:13:15,200 --> 00:13:18,959
initially expected

00:13:16,160 --> 00:13:20,399
so that was that was nice to see but it

00:13:18,959 --> 00:13:21,839
did lead us to doing a little bit more

00:13:20,399 --> 00:13:25,120
work to try and

00:13:21,839 --> 00:13:27,120
optimize things a little bit more um

00:13:25,120 --> 00:13:28,160
and one of the big things actually was

00:13:27,120 --> 00:13:29,600
session parameters

00:13:28,160 --> 00:13:31,279
and it was surprising just how much of

00:13:29,600 --> 00:13:33,600
an impact um

00:13:31,279 --> 00:13:34,720
session parameters could have so just by

00:13:33,600 --> 00:13:37,760
doing things like changing

00:13:34,720 --> 00:13:39,600
the um some of the joint strategies

00:13:37,760 --> 00:13:41,120
actually had a pretty decent impact of

00:13:39,600 --> 00:13:42,560
performance and it was around this time

00:13:41,120 --> 00:13:43,519
we also experimented with doing things

00:13:42,560 --> 00:13:46,560
like switching to

00:13:43,519 --> 00:13:48,959
awk format and the

00:13:46,560 --> 00:13:50,399
hana cluster also had just a tick box

00:13:48,959 --> 00:13:52,160
option when you launched it to attach a

00:13:50,399 --> 00:13:53,040
hive meta store so we also added that to

00:13:52,160 --> 00:13:55,519
have a look that we

00:13:53,040 --> 00:13:56,639
play around with and all of those added

00:13:55,519 --> 00:13:58,079
up to around a 90

00:13:56,639 --> 00:14:00,399
improvement across all of the queries

00:13:58,079 --> 00:14:02,000
which was really good to see for just

00:14:00,399 --> 00:14:04,800
changing a couple of different settings

00:14:02,000 --> 00:14:07,279
that before we had no control over but

00:14:04,800 --> 00:14:07,279
now we do

00:14:07,519 --> 00:14:10,959
and what we're looking at the moment is

00:14:09,279 --> 00:14:12,079
kind of a bit more work on

00:14:10,959 --> 00:14:14,959
right sizing and figuring out what

00:14:12,079 --> 00:14:16,959
cluster we can get and uh

00:14:14,959 --> 00:14:18,399
you know to kind of what's suitable for

00:14:16,959 --> 00:14:20,800
us now that we can

00:14:18,399 --> 00:14:22,079
fine-tune it uh we also need to do a bit

00:14:20,800 --> 00:14:23,440
of stress testing on the concurrency

00:14:22,079 --> 00:14:24,720
because we've experimented with and it

00:14:23,440 --> 00:14:26,240
was definitely better than athena but we

00:14:24,720 --> 00:14:27,199
haven't found the tipping point to where

00:14:26,240 --> 00:14:29,360
it starts breaking

00:14:27,199 --> 00:14:30,720
so excited to kind of give that a try

00:14:29,360 --> 00:14:34,000
and break things

00:14:30,720 --> 00:14:35,279
um and another thing we can do now is

00:14:34,000 --> 00:14:36,320
experiment with using

00:14:35,279 --> 00:14:37,920
different clusters for different

00:14:36,320 --> 00:14:40,000
workloads because before we were kind of

00:14:37,920 --> 00:14:40,880
stuck on this one athena key that served

00:14:40,000 --> 00:14:43,600
everything

00:14:40,880 --> 00:14:44,079
whereas now we can if we want to kind of

00:14:43,600 --> 00:14:45,519
spin up

00:14:44,079 --> 00:14:46,880
a couple different clusters that have

00:14:45,519 --> 00:14:48,320
different configurations that we've kind

00:14:46,880 --> 00:14:49,920
of fine-tuned them for

00:14:48,320 --> 00:14:51,199
so maybe the categorization demographic

00:14:49,920 --> 00:14:52,639
preview might be super to a different

00:14:51,199 --> 00:14:54,320
cluster again we're still we're still

00:14:52,639 --> 00:14:56,000
trying that at the moment

00:14:54,320 --> 00:14:58,240
and as well just continued querying

00:14:56,000 --> 00:15:00,000
their optimizations now that we're

00:14:58,240 --> 00:15:02,880
kind of switched over to this we have a

00:15:00,000 --> 00:15:02,880
few more options for that

00:15:03,040 --> 00:15:06,480
and so just to kind of sum things up

00:15:04,560 --> 00:15:09,760
quickly a few takeaways is that

00:15:06,480 --> 00:15:11,680
presto's grip um i've been able to

00:15:09,760 --> 00:15:12,720
query date without having to worry about

00:15:11,680 --> 00:15:13,920
kind of where it is with all the

00:15:12,720 --> 00:15:14,959
different connectors and made it really

00:15:13,920 --> 00:15:16,399
easy to get going

00:15:14,959 --> 00:15:18,399
and there are a lot of different

00:15:16,399 --> 00:15:19,120
solutions out there like athena and a

00:15:18,399 --> 00:15:21,360
hana to

00:15:19,120 --> 00:15:22,560
get going fast which is good for good

00:15:21,360 --> 00:15:25,600
for us

00:15:22,560 --> 00:15:27,120
um athena's still a really good service

00:15:25,600 --> 00:15:28,720
uh so say if you have like smaller

00:15:27,120 --> 00:15:31,360
volume workloads that aren't kind of

00:15:28,720 --> 00:15:32,639
sensitive to that single qr compute uh

00:15:31,360 --> 00:15:35,440
ceiling i think it could be

00:15:32,639 --> 00:15:36,880
still really good for that um but if

00:15:35,440 --> 00:15:38,880
those sound like

00:15:36,880 --> 00:15:40,560
they're gonna be a problem then maybe

00:15:38,880 --> 00:15:43,360
using something like a hana

00:15:40,560 --> 00:15:45,120
to provision a cluster or even going to

00:15:43,360 --> 00:15:46,639
uh your dc2 instances and setting that

00:15:45,120 --> 00:15:49,680
up would be kind of like a

00:15:46,639 --> 00:15:51,040
the next step on that we think um

00:15:49,680 --> 00:15:53,040
and yeah once you have your own

00:15:51,040 --> 00:15:54,480
you've got more control over it and

00:15:53,040 --> 00:15:56,880
the performance is predictable too

00:15:54,480 --> 00:15:59,600
instead of having to worry about um

00:15:56,880 --> 00:16:00,320
athena updating the version whenever it

00:15:59,600 --> 00:16:02,079
feels like you

00:16:00,320 --> 00:16:04,160
kind of have a bit more uh a bit more

00:16:02,079 --> 00:16:05,920
control on that

00:16:04,160 --> 00:16:07,680
so i think that's it so if there's any

00:16:05,920 --> 00:16:08,000
other questions i'll answer them but

00:16:07,680 --> 00:16:11,279
i'll be

00:16:08,000 --> 00:16:12,079
i'll be around for a bit oh i saw

00:16:11,279 --> 00:16:14,320
someone

00:16:12,079 --> 00:16:15,600
mention about redshift and redshift was

00:16:14,320 --> 00:16:20,000
uh

00:16:15,600 --> 00:16:21,920
i think we tried that initially um

00:16:20,000 --> 00:16:23,680
i'll have to find out some numbers for

00:16:21,920 --> 00:16:24,720
that but i do think we did have a go at

00:16:23,680 --> 00:16:29,040
that

00:16:24,720 --> 00:16:29,040
so yeah yeah i'll hand it back over now

00:16:29,759 --> 00:16:33,600
nobody's okay you still have a couple of

00:16:31,360 --> 00:16:35,040
minutes uh for more q a i mean

00:16:33,600 --> 00:16:37,120
thank you for keeping the session on

00:16:35,040 --> 00:16:38,880
time and you know both sharing your very

00:16:37,120 --> 00:16:40,639
interesting insights uh

00:16:38,880 --> 00:16:42,800
on how you thought about you know this

00:16:40,639 --> 00:16:46,720
shift uh

00:16:42,800 --> 00:16:46,720
you are you uh are you still there

00:16:47,279 --> 00:16:50,480
yep there we go okay so one more

00:16:48,800 --> 00:16:52,480
question that came in like how many

00:16:50,480 --> 00:16:54,079
hana instances are you running and how

00:16:52,480 --> 00:16:55,519
does it compare to what you were running

00:16:54,079 --> 00:16:57,279
on athena

00:16:55,519 --> 00:16:59,759
yeah so tell you what i'll share screens

00:16:57,279 --> 00:17:05,839
again quickly

00:16:59,759 --> 00:17:05,839
there we go so go back to that

00:17:07,600 --> 00:17:11,439
so this is kind of an overview of it

00:17:09,360 --> 00:17:14,720
here um

00:17:11,439 --> 00:17:15,919
so for kind of okay performance compared

00:17:14,720 --> 00:17:17,919
to athena i think

00:17:15,919 --> 00:17:20,160
probably like cluster set up c where it

00:17:17,919 --> 00:17:22,400
was 10 times c5 x largest

00:17:20,160 --> 00:17:23,839
we're looking pretty similar like you

00:17:22,400 --> 00:17:26,240
can see there for

00:17:23,839 --> 00:17:27,679
cluster c is pretty close to athena on

00:17:26,240 --> 00:17:29,840
the site

00:17:27,679 --> 00:17:31,200
better than it for location similar for

00:17:29,840 --> 00:17:32,880
date

00:17:31,200 --> 00:17:35,200
a bit slow for brand better for all

00:17:32,880 --> 00:17:37,440
views it's up and down depending on

00:17:35,200 --> 00:17:41,120
which queries been run but that's i

00:17:37,440 --> 00:17:41,120
think a decent approximation for it

00:17:42,799 --> 00:17:47,200
okay we got one more question people did

00:17:45,440 --> 00:17:48,160
you create a lot of partitioning in your

00:17:47,200 --> 00:17:51,280
s3 structure

00:17:48,160 --> 00:17:52,799
or to minimize scans yeah so

00:17:51,280 --> 00:17:55,200
things like i mentioned before about the

00:17:52,799 --> 00:17:55,840
dates um we did partition by date which

00:17:55,200 --> 00:17:57,039
meant that if

00:17:55,840 --> 00:17:58,400
if a user selected sort of like a

00:17:57,039 --> 00:17:59,280
three-day window it would only select

00:17:58,400 --> 00:18:01,919
that

00:17:59,280 --> 00:18:03,600
and it's also split up by the parents

00:18:01,919 --> 00:18:05,440
that go on the dashboard

00:18:03,600 --> 00:18:07,679
and there's a couple other properties

00:18:05,440 --> 00:18:10,000
that we have like related to

00:18:07,679 --> 00:18:11,440
um all of the consent management stuff

00:18:10,000 --> 00:18:12,880
there's a partition for whether or not

00:18:11,440 --> 00:18:14,000
data can be kind of

00:18:12,880 --> 00:18:15,600
acted a point like whether or not

00:18:14,000 --> 00:18:16,880
someone's consented to it so there's a

00:18:15,600 --> 00:18:18,240
boolean for that so that's another

00:18:16,880 --> 00:18:20,160
partition we have

00:18:18,240 --> 00:18:22,080
um that's kind of a delicate balance to

00:18:20,160 --> 00:18:24,080
get right between you know

00:18:22,080 --> 00:18:25,919
a ridiculous amount of partitions versus

00:18:24,080 --> 00:18:28,160
extra filler stuff um

00:18:25,919 --> 00:18:32,080
reducing data scan but we seem like

00:18:28,160 --> 00:18:32,080
we've hit a pretty awkward spot for that

00:18:33,440 --> 00:18:38,240
okay i hope that helped answer your

00:18:35,039 --> 00:18:38,240
question uh nishant

00:18:39,280 --> 00:18:43,039
maybe give it another minute if folks

00:18:40,960 --> 00:18:44,080
are still thinking otherwise nobody

00:18:43,039 --> 00:18:45,919
jordan

00:18:44,080 --> 00:18:48,640
just hang around and if you see any

00:18:45,919 --> 00:18:50,799
questions coming up in the chat window

00:18:48,640 --> 00:18:52,880
feel free to answer that one last

00:18:50,799 --> 00:18:54,080
question we have maybe two more minutes

00:18:52,880 --> 00:18:55,360
you could take that

00:18:54,080 --> 00:18:58,160
how can i get your feedback on the

00:18:55,360 --> 00:19:00,640
redship uh investigation

00:18:58,160 --> 00:19:01,840
uh i think you may just find me on i

00:19:00,640 --> 00:19:02,720
guess linkedin or something might be an

00:19:01,840 --> 00:19:04,080
easy way to do it but

00:19:02,720 --> 00:19:05,840
i'm guessing that would be kind of the

00:19:04,080 --> 00:19:07,919
the way to go like this

00:19:05,840 --> 00:19:10,080
sure okay that that sounds good so i

00:19:07,919 --> 00:19:11,840
think looks like uh you know people

00:19:10,080 --> 00:19:15,520
enjoyed the session thank you

00:19:11,840 --> 00:19:17,679
uh jordan and uh you know i take this uh

00:19:15,520 --> 00:19:19,120
question maybe offline i know slava has

00:19:17,679 --> 00:19:20,720
a question have you tried comparing

00:19:19,120 --> 00:19:23,440
athena to bigquery

00:19:20,720 --> 00:19:24,640
uh you know i'll get the new the next

00:19:23,440 --> 00:19:27,280
set of uh

00:19:24,640 --> 00:19:28,799
speakers actually uh starting up here in

00:19:27,280 --> 00:19:30,080
a few minutes the session starts in

00:19:28,799 --> 00:19:32,240
about two minutes

00:19:30,080 --> 00:19:33,840
so take it offline and uh you know thank

00:19:32,240 --> 00:19:34,240
you once again for you know being part

00:19:33,840 --> 00:19:36,080
of

00:19:34,240 --> 00:19:37,600
prestocon day and you know sharing your

00:19:36,080 --> 00:19:39,840
thoughts with us right

00:19:37,600 --> 00:19:39,840

YouTube URL: https://www.youtube.com/watch?v=RbRJ35p9GkU


