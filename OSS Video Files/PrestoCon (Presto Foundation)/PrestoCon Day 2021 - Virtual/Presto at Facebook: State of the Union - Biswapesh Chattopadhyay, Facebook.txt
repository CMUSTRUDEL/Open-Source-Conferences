Title: Presto at Facebook: State of the Union - Biswapesh Chattopadhyay, Facebook
Publication date: 2021-03-27
Playlist: PrestoCon Day 2021 - Virtual
Description: 
	Presto at Facebook: State of the Union - Biswapesh Chattopadhyay, Facebook

An overview of how we are evolving Presto to be the next generation query engine at Facebook and beyond. 

For more info about Presto, the open source distributed SQL query engine for running interactive analytic queries against data sources of all sizes ranging from gigabytes to petabytes, see: https://prestodb.io/
Captions: 
	00:00:00,320 --> 00:00:03,919
so um i don't know how much time i have

00:00:02,960 --> 00:00:07,919
20 minutes

00:00:03,919 --> 00:00:11,519
let's just um go over this stuff quickly

00:00:07,919 --> 00:00:14,920
um and by the way i'm not sure if i'm

00:00:11,519 --> 00:00:16,320
still on the old session in terms of the

00:00:14,920 --> 00:00:18,080
chats so

00:00:16,320 --> 00:00:19,840
uh press start facebook okay let me

00:00:18,080 --> 00:00:22,880
click on this what happens oh

00:00:19,840 --> 00:00:26,080
should it ask me to leave oh my

00:00:22,880 --> 00:00:28,160
i'll just take it um i'm able to see you

00:00:26,080 --> 00:00:29,760
i think we should be good

00:00:28,160 --> 00:00:31,279
yeah no i'm just wondering if i'm in the

00:00:29,760 --> 00:00:33,040
chat in the right chat session because

00:00:31,279 --> 00:00:33,920
i'm still in the old chat session it

00:00:33,040 --> 00:00:36,480
seems

00:00:33,920 --> 00:00:38,160
for the uh no it should be fine i think

00:00:36,480 --> 00:00:41,040
this is like one unified session

00:00:38,160 --> 00:00:41,840
so i think okay okay okay i'm just going

00:00:41,040 --> 00:00:44,960
to do a

00:00:41,840 --> 00:00:47,840
test let's see if you can see that okay

00:00:44,960 --> 00:00:48,719
cool and then by the way please uh feel

00:00:47,840 --> 00:00:50,160
free to post

00:00:48,719 --> 00:00:51,920
questions in the session as we go

00:00:50,160 --> 00:00:54,719
through this i'll try to be brief

00:00:51,920 --> 00:00:55,760
so tim i think uh covered a lot of this

00:00:54,719 --> 00:00:57,680
um

00:00:55,760 --> 00:00:58,879
earlier today so i'll try to kind of

00:00:57,680 --> 00:01:00,480
zoom through the stuff that is already

00:00:58,879 --> 00:01:03,199
covered and focus more on things that

00:01:00,480 --> 00:01:04,960
maybe are slightly more long-range right

00:01:03,199 --> 00:01:07,200
and this was kind of a mission statement

00:01:04,960 --> 00:01:08,960
that we had at facebook we created

00:01:07,200 --> 00:01:10,560
uh this as part of a you know

00:01:08,960 --> 00:01:15,520
trustworthy mission

00:01:10,560 --> 00:01:19,040
um i'll just let that be right uh

00:01:15,520 --> 00:01:20,640
you know it's the usual yeah

00:01:19,040 --> 00:01:22,400
okay but but this is an interesting one

00:01:20,640 --> 00:01:23,360
right uh i want to spend a little bit of

00:01:22,400 --> 00:01:25,119
time on this i think

00:01:23,360 --> 00:01:26,320
there are two types of trends there's

00:01:25,119 --> 00:01:27,680
this usage trends and there's

00:01:26,320 --> 00:01:29,280
environmental trends

00:01:27,680 --> 00:01:30,880
so on the usage side i think we've heard

00:01:29,280 --> 00:01:32,799
a lot like there's an explosion of data

00:01:30,880 --> 00:01:35,200
people need to scale

00:01:32,799 --> 00:01:37,119
there's a real strong need for freshness

00:01:35,200 --> 00:01:38,079
and latency like real-time data really

00:01:37,119 --> 00:01:40,640
fast queries

00:01:38,079 --> 00:01:42,560
lots of queries standardization is a big

00:01:40,640 --> 00:01:44,479
problem we have n metal stores we have n

00:01:42,560 --> 00:01:45,040
query dialects you know we have n ways

00:01:44,479 --> 00:01:48,240
of

00:01:45,040 --> 00:01:51,280
uh transforming data etc etc

00:01:48,240 --> 00:01:52,720
um a lot of people i think kishore

00:01:51,280 --> 00:01:54,799
touched upon this earlier we're talking

00:01:52,720 --> 00:01:57,119
about exporting analytics to our users

00:01:54,799 --> 00:01:58,479
so a very trivial example of this is you

00:01:57,119 --> 00:02:00,000
know when you go to youtube you see the

00:01:58,479 --> 00:02:01,920
number of like count

00:02:00,000 --> 00:02:03,280
on a given video it's kind of analytics

00:02:01,920 --> 00:02:05,439
right that you're

00:02:03,280 --> 00:02:06,479
measuring the likes and views and things

00:02:05,439 --> 00:02:08,640
like that on youtube but you're

00:02:06,479 --> 00:02:10,560
exporting this at like a million qps

00:02:08,640 --> 00:02:12,400
you know billions of people that's an

00:02:10,560 --> 00:02:14,480
interesting uh different

00:02:12,400 --> 00:02:16,720
uh kind of analytics like so it's not

00:02:14,480 --> 00:02:19,360
really the traditional data warehousing

00:02:16,720 --> 00:02:20,959
um privacy and security i think multiple

00:02:19,360 --> 00:02:22,160
people touched upon this is becoming a

00:02:20,959 --> 00:02:24,160
very big deal like with

00:02:22,160 --> 00:02:25,840
gdpr with all sorts of hacks going on

00:02:24,160 --> 00:02:28,400
you know how can we prevent

00:02:25,840 --> 00:02:31,200
um people from you know how can we

00:02:28,400 --> 00:02:34,720
prevent data leakage how can we

00:02:31,200 --> 00:02:37,920
deploy all this privacy and kind of

00:02:34,720 --> 00:02:39,440
compliance rules on our on our query

00:02:37,920 --> 00:02:42,000
engines and our data

00:02:39,440 --> 00:02:43,680
um auto awesome this is the key name

00:02:42,000 --> 00:02:44,879
that have coined i think this comes from

00:02:43,680 --> 00:02:46,400
the bigquery term but

00:02:44,879 --> 00:02:48,720
fundamentally like there is less and

00:02:46,400 --> 00:02:50,319
less patience for people to actually

00:02:48,720 --> 00:02:51,920
spend hours fine-tuning their query

00:02:50,319 --> 00:02:53,599
performance because they need to

00:02:51,920 --> 00:02:55,680
run at hot queries very quickly right

00:02:53,599 --> 00:02:56,959
and you know time is money and people

00:02:55,680 --> 00:02:57,599
want to say that hey i'm just going to

00:02:56,959 --> 00:02:59,840
tell you the

00:02:57,599 --> 00:03:01,599
sequel and you should just automatically

00:02:59,840 --> 00:03:03,360
figure out how to run it really fast how

00:03:01,599 --> 00:03:06,159
to optimize my data underneath it

00:03:03,360 --> 00:03:06,560
and if you look at cloud warehouses like

00:03:06,159 --> 00:03:08,800
you know

00:03:06,560 --> 00:03:10,480
bigquery snowflake redshift like a lot

00:03:08,800 --> 00:03:12,159
of they are doing this kind of thing and

00:03:10,480 --> 00:03:13,360
this requires actually a whole ecosystem

00:03:12,159 --> 00:03:14,640
optimization i'll talk a little bit

00:03:13,360 --> 00:03:16,400
about that later

00:03:14,640 --> 00:03:17,760
data models are becoming very complex

00:03:16,400 --> 00:03:18,879
how do we represent graph data

00:03:17,760 --> 00:03:20,560
structures

00:03:18,879 --> 00:03:22,560
how do we do full textures how do we do

00:03:20,560 --> 00:03:24,560
you know really rich

00:03:22,560 --> 00:03:26,080
models like how do we represent classes

00:03:24,560 --> 00:03:27,360
in our structures like how do we have

00:03:26,080 --> 00:03:29,200
maps and arrays and have really

00:03:27,360 --> 00:03:31,519
efficient processing on them

00:03:29,200 --> 00:03:32,959
and and finally reach our query methods

00:03:31,519 --> 00:03:34,319
so we talked about you know we started

00:03:32,959 --> 00:03:36,000
with simple sql

00:03:34,319 --> 00:03:37,519
now we are talking about graph queries

00:03:36,000 --> 00:03:39,120
we're talking about streaming extensions

00:03:37,519 --> 00:03:40,080
to sql we're talking about time series

00:03:39,120 --> 00:03:43,200
extensions

00:03:40,080 --> 00:03:44,080
uh json processing semi structured and

00:03:43,200 --> 00:03:45,440
these require like

00:03:44,080 --> 00:03:47,519
different kinds of optimization

00:03:45,440 --> 00:03:50,400
different kinds of query strategies

00:03:47,519 --> 00:03:52,239
um so moving on to environmental trends

00:03:50,400 --> 00:03:52,799
uh this is like how the industry is

00:03:52,239 --> 00:03:54,799
evolving

00:03:52,799 --> 00:03:56,159
right i don't mean environment in the

00:03:54,799 --> 00:03:56,640
environment environment sense right this

00:03:56,159 --> 00:03:58,720
is about

00:03:56,640 --> 00:04:00,720
what about like the computer

00:03:58,720 --> 00:04:02,720
environmental trends

00:04:00,720 --> 00:04:04,640
storage disaggregation is a big deal

00:04:02,720 --> 00:04:06,080
right s3 and all these blob stores like

00:04:04,640 --> 00:04:07,040
your storage is separately a computer

00:04:06,080 --> 00:04:08,400
separate

00:04:07,040 --> 00:04:10,239
a lot of people talked about this

00:04:08,400 --> 00:04:11,360
scaling horizontal scaling this comes

00:04:10,239 --> 00:04:12,959
from the data explosion

00:04:11,360 --> 00:04:14,959
your machines are getting smaller but

00:04:12,959 --> 00:04:17,120
you get way more of them

00:04:14,959 --> 00:04:18,639
right how do how do we scale to you know

00:04:17,120 --> 00:04:20,880
thousand node cluster ten thousand node

00:04:18,639 --> 00:04:23,680
clusters like hundreds of clusters

00:04:20,880 --> 00:04:25,440
and and then kind of uh with that is

00:04:23,680 --> 00:04:28,080
elastic compute how do we kind of

00:04:25,440 --> 00:04:29,680
gain elasticity like machines are coming

00:04:28,080 --> 00:04:31,120
in going out spot instances

00:04:29,680 --> 00:04:33,040
like you want to be able to leverage

00:04:31,120 --> 00:04:34,479
quickly spin up turn down

00:04:33,040 --> 00:04:36,639
machines and kind of still the query

00:04:34,479 --> 00:04:37,360
should continue to work power efficiency

00:04:36,639 --> 00:04:38,720
is one of the

00:04:37,360 --> 00:04:40,479
interesting things that is coming in at

00:04:38,720 --> 00:04:41,199
facebook a lot hey we have a lot of data

00:04:40,479 --> 00:04:43,120
centers

00:04:41,199 --> 00:04:44,639
our data centers consume a lot of power

00:04:43,120 --> 00:04:46,080
we might become power constrained in the

00:04:44,639 --> 00:04:47,759
future like how do we

00:04:46,080 --> 00:04:49,199
make things more efficient just from a

00:04:47,759 --> 00:04:50,880
power consumption standpoint whether it

00:04:49,199 --> 00:04:52,240
is you know power consumed by cpus or

00:04:50,880 --> 00:04:55,120
ram or network

00:04:52,240 --> 00:04:57,040
and things like that and i think global

00:04:55,120 --> 00:04:58,720
optimization i touched on like how do we

00:04:57,040 --> 00:04:59,840
it's not it's beyond the query engine

00:04:58,720 --> 00:05:01,840
like how do you have much richer

00:04:59,840 --> 00:05:03,680
metadata or much richer stats how do we

00:05:01,840 --> 00:05:06,639
automatically optimize the data layout

00:05:03,680 --> 00:05:09,520
so that query patterns can get faster

00:05:06,639 --> 00:05:10,560
and finally engineering efficiency we

00:05:09,520 --> 00:05:12,479
have

00:05:10,560 --> 00:05:14,000
an explosion in the number of tables and

00:05:12,479 --> 00:05:16,080
the amount of data and the number of

00:05:14,000 --> 00:05:18,320
users who want to be data enabled

00:05:16,080 --> 00:05:19,759
so to say and we can't really scale our

00:05:18,320 --> 00:05:21,840
engineering so we have to

00:05:19,759 --> 00:05:24,479
find our super scalar or the sub you

00:05:21,840 --> 00:05:26,479
know super scalar ways of scaling our

00:05:24,479 --> 00:05:28,080
data with not really the linear scaling

00:05:26,479 --> 00:05:30,080
of the number of engineers so

00:05:28,080 --> 00:05:32,160
so facebook data is growing by whatever

00:05:30,080 --> 00:05:32,960
two x 10x lot of our data is growing by

00:05:32,160 --> 00:05:34,720
10x

00:05:32,960 --> 00:05:36,320
in some cases right you cannot just keep

00:05:34,720 --> 00:05:38,479
connecting your engineering team

00:05:36,320 --> 00:05:40,479
so we have to find much more engineering

00:05:38,479 --> 00:05:41,360
efficiencies out of the system to figure

00:05:40,479 --> 00:05:45,919
out how to

00:05:41,360 --> 00:05:48,639
uh deal with that so i was

00:05:45,919 --> 00:05:49,759
going through my old albums and this one

00:05:48,639 --> 00:05:52,720
was interesting this

00:05:49,759 --> 00:05:53,120
i don't know if people know about this

00:05:52,720 --> 00:05:55,680
group

00:05:53,120 --> 00:05:56,479
uh this group is called four non-blondes

00:05:55,680 --> 00:06:00,240
um

00:05:56,479 --> 00:06:02,000
they were really good um all girls raw

00:06:00,240 --> 00:06:04,240
group right and their

00:06:02,000 --> 00:06:05,120
big hit album was called bigger better

00:06:04,240 --> 00:06:06,639
faster more

00:06:05,120 --> 00:06:08,720
and it got me to thinking that hey this

00:06:06,639 --> 00:06:10,639
is a great way to describe some of the

00:06:08,720 --> 00:06:14,000
stuff we are doing in presto and in the

00:06:10,639 --> 00:06:14,720
ecosystem at facebook and the number

00:06:14,000 --> 00:06:16,960
three song

00:06:14,720 --> 00:06:19,039
i don't know if you can notice this on

00:06:16,960 --> 00:06:21,680
their album was actually the most

00:06:19,039 --> 00:06:23,039
popular or hit song it was called what's

00:06:21,680 --> 00:06:26,160
up

00:06:23,039 --> 00:06:26,800
right so what's really up and i think

00:06:26,160 --> 00:06:29,039
and what's up

00:06:26,800 --> 00:06:29,919
is really bigger better faster more so

00:06:29,039 --> 00:06:32,080
let's talk about that

00:06:29,919 --> 00:06:33,759
uh starting like on the way down so

00:06:32,080 --> 00:06:35,120
preston spark we talked about it like

00:06:33,759 --> 00:06:36,639
how do we go big

00:06:35,120 --> 00:06:38,240
like running 10 hour queries you know

00:06:36,639 --> 00:06:40,319
without failing disaggregated

00:06:38,240 --> 00:06:41,919
coordinators how do we go big on scale

00:06:40,319 --> 00:06:43,440
intelligent workload placement presto

00:06:41,919 --> 00:06:43,919
pack we didn't talk much about that how

00:06:43,440 --> 00:06:45,360
do we

00:06:43,919 --> 00:06:47,039
we can touch upon that a little bit how

00:06:45,360 --> 00:06:48,240
do we space out our

00:06:47,039 --> 00:06:50,240
tasks in a way that is really

00:06:48,240 --> 00:06:52,319
intelligent can make our workers do more

00:06:50,240 --> 00:06:53,599
auto awesome eyes right we touched upon

00:06:52,319 --> 00:06:55,960
this in the first trend

00:06:53,599 --> 00:06:57,199
uh trend slide storage and metadata

00:06:55,960 --> 00:06:58,800
co-optimization

00:06:57,199 --> 00:07:00,479
again like holds how do we do global

00:06:58,800 --> 00:07:02,240
optima um

00:07:00,479 --> 00:07:03,680
we talked a lot about raptor x and

00:07:02,240 --> 00:07:05,440
caching and affinity this is getting

00:07:03,680 --> 00:07:07,039
gradually from the better to the

00:07:05,440 --> 00:07:08,800
you know kind of the faster part of the

00:07:07,039 --> 00:07:10,400
equation right and the native code

00:07:08,800 --> 00:07:11,360
accelerator belongs i saw a bunch of

00:07:10,400 --> 00:07:13,520
questions

00:07:11,360 --> 00:07:14,720
uh around that so i'll touch upon that a

00:07:13,520 --> 00:07:16,800
little more

00:07:14,720 --> 00:07:18,080
uh then core sequel we'll talk a little

00:07:16,800 --> 00:07:19,440
bit about course equal how do we take

00:07:18,080 --> 00:07:20,000
cluster sql and take it to the next

00:07:19,440 --> 00:07:21,520
level

00:07:20,000 --> 00:07:23,840
in terms of just the language richness

00:07:21,520 --> 00:07:25,440
right and portable udfs

00:07:23,840 --> 00:07:27,039
which kind of on the similar lines like

00:07:25,440 --> 00:07:29,360
how do we go beyond sql

00:07:27,039 --> 00:07:30,080
when we really need to go into your java

00:07:29,360 --> 00:07:32,880
and c plus plus

00:07:30,080 --> 00:07:34,000
or whatever like how do we enrich sql uh

00:07:32,880 --> 00:07:36,080
using that

00:07:34,000 --> 00:07:37,680
um so let's let's let's start with uh

00:07:36,080 --> 00:07:40,240
presto on spark

00:07:37,680 --> 00:07:41,120
i think we touched upon this in multiple

00:07:40,240 --> 00:07:42,479
last

00:07:41,120 --> 00:07:43,759
multiple sessions but i'm this is

00:07:42,479 --> 00:07:45,759
something that i'm really excited about

00:07:43,759 --> 00:07:46,879
because we see that

00:07:45,759 --> 00:07:48,960
essentially breaking down the

00:07:46,879 --> 00:07:50,960
scalability limits of presto making make

00:07:48,960 --> 00:07:52,240
it run reliably on elastic hardware on

00:07:50,960 --> 00:07:53,919
spot instances

00:07:52,240 --> 00:07:56,879
on queries that learn around for you

00:07:53,919 --> 00:07:59,599
know tens of hours or even days

00:07:56,879 --> 00:08:00,080
but with 100 presto sql compatibility

00:07:59,599 --> 00:08:02,000
right

00:08:00,080 --> 00:08:04,000
so we do that by essentially leveraging

00:08:02,000 --> 00:08:04,800
spark as the underlying distribution

00:08:04,000 --> 00:08:06,160
framework

00:08:04,800 --> 00:08:08,800
so it gives you a split level check

00:08:06,160 --> 00:08:11,039
pointing retry job level isolation

00:08:08,800 --> 00:08:12,400
like much higher reliability like much

00:08:11,039 --> 00:08:14,000
better isolation

00:08:12,400 --> 00:08:15,759
uh running able to run on elastic

00:08:14,000 --> 00:08:17,199
compute this isn't this is feature

00:08:15,759 --> 00:08:18,879
complete like we are kind of

00:08:17,199 --> 00:08:20,560
this is an open source we are

00:08:18,879 --> 00:08:22,560
productionizing the first few pipelines

00:08:20,560 --> 00:08:24,720
we are seeing some really great results

00:08:22,560 --> 00:08:26,960
uh we are able to share resources with

00:08:24,720 --> 00:08:30,400
our you know broader spark clusters

00:08:26,960 --> 00:08:31,759
uh and the overall kind of uh

00:08:30,400 --> 00:08:34,320
of the machine kind of resource

00:08:31,759 --> 00:08:36,080
allocation framework um

00:08:34,320 --> 00:08:37,440
this is really cool right so this is

00:08:36,080 --> 00:08:38,320
kind of from the bigger end of the

00:08:37,440 --> 00:08:40,000
spectrum

00:08:38,320 --> 00:08:41,440
and then software swapnil just talked

00:08:40,000 --> 00:08:43,360
about this one which is

00:08:41,440 --> 00:08:45,680
uh what we internally called fireball

00:08:43,360 --> 00:08:47,200
but basically how do we do disaggregated

00:08:45,680 --> 00:08:48,080
coordinators so that we can have you

00:08:47,200 --> 00:08:50,080
know thousand node

00:08:48,080 --> 00:08:51,920
two thousand node five thousand node

00:08:50,080 --> 00:08:54,000
plus two clusters with like

00:08:51,920 --> 00:08:55,279
maybe a dozen coordinators right and it

00:08:54,000 --> 00:08:58,160
still works there's no

00:08:55,279 --> 00:09:00,160
so it has two aspects one is it allows

00:08:58,160 --> 00:09:01,600
us to run larger fewer clusters

00:09:00,160 --> 00:09:03,680
with elasticity and all that kind of

00:09:01,600 --> 00:09:04,480
stuff but another important aspect is

00:09:03,680 --> 00:09:06,240
that that

00:09:04,480 --> 00:09:08,080
this gives you much higher availability

00:09:06,240 --> 00:09:09,600
so there is no single point of failure

00:09:08,080 --> 00:09:11,040
right the resource manager is kind of

00:09:09,600 --> 00:09:11,839
duplicated the discovery service is

00:09:11,040 --> 00:09:13,839
duplicated

00:09:11,839 --> 00:09:15,440
the coordinators are disaggregated uh

00:09:13,839 --> 00:09:17,360
the workers were obviously

00:09:15,440 --> 00:09:19,120
you know horizontally scalable before

00:09:17,360 --> 00:09:21,760
but this brings this capability to a you

00:09:19,120 --> 00:09:23,920
know whole new dimension

00:09:21,760 --> 00:09:25,920
again uh we are going through the final

00:09:23,920 --> 00:09:27,839
um this is not quite in production yet

00:09:25,920 --> 00:09:29,279
we it is going under heavy testing most

00:09:27,839 --> 00:09:31,200
of it is kind of feature complete in

00:09:29,279 --> 00:09:34,399
development this is an open source

00:09:31,200 --> 00:09:35,839
uh totally tried out presto pacquiao

00:09:34,399 --> 00:09:36,399
didn't talk a lot about that this is

00:09:35,839 --> 00:09:37,839
this is a

00:09:36,399 --> 00:09:40,320
really cool little piece of work that

00:09:37,839 --> 00:09:40,800
gem and others did the idea is basically

00:09:40,320 --> 00:09:42,880
about

00:09:40,800 --> 00:09:44,320
today the workload placement is pretty

00:09:42,880 --> 00:09:46,720
random and this is actually

00:09:44,320 --> 00:09:47,519
cool because with exactly the storage

00:09:46,720 --> 00:09:49,120
you can do

00:09:47,519 --> 00:09:51,440
you know you any work can run on any

00:09:49,120 --> 00:09:55,200
node but this doesn't really give you

00:09:51,440 --> 00:09:57,680
a very good kind of what should i say

00:09:55,200 --> 00:09:58,720
uniform placement so so we should be

00:09:57,680 --> 00:10:00,959
able to

00:09:58,720 --> 00:10:02,480
do much better by intelligently deciding

00:10:00,959 --> 00:10:03,120
which piece of task goes where so for

00:10:02,480 --> 00:10:05,120
example

00:10:03,120 --> 00:10:07,040
in raptor x we choose an affinity based

00:10:05,120 --> 00:10:07,680
model so that we can better leverage

00:10:07,040 --> 00:10:09,600
caching

00:10:07,680 --> 00:10:11,360
but in batch mode where there is no

00:10:09,600 --> 00:10:13,440
caching you should be able to choose

00:10:11,360 --> 00:10:14,720
say a cpu based model or a memory

00:10:13,440 --> 00:10:15,920
available based model

00:10:14,720 --> 00:10:18,240
so we have been trying these different

00:10:15,920 --> 00:10:20,000
models for batch we tried uh you know

00:10:18,240 --> 00:10:21,600
memory availability based model and we

00:10:20,000 --> 00:10:23,040
got it 23 percent higher throughput

00:10:21,600 --> 00:10:25,360
which is actually a pretty big deal at

00:10:23,040 --> 00:10:25,360
facebook

00:10:25,680 --> 00:10:28,880
and again this is kind of uh beginning

00:10:28,160 --> 00:10:32,880
to land

00:10:28,880 --> 00:10:35,680
i think we are doing some shadow testing

00:10:32,880 --> 00:10:37,040
okay this is an area that we haven't

00:10:35,680 --> 00:10:38,640
done a lot of work and this is something

00:10:37,040 --> 00:10:40,079
that i think we should do a lot of work

00:10:38,640 --> 00:10:41,600
on and we'll probably do it

00:10:40,079 --> 00:10:43,839
but how do we make our warehouse how to

00:10:41,600 --> 00:10:45,040
optimize and and what do i mean by auto

00:10:43,839 --> 00:10:46,720
awesome is that

00:10:45,040 --> 00:10:48,560
not only do we smart rewrites on the

00:10:46,720 --> 00:10:50,560
queries like we employ

00:10:48,560 --> 00:10:52,959
cost based optimizations this requires

00:10:50,560 --> 00:10:55,360
tight meta store integration right so we

00:10:52,959 --> 00:10:56,880
need to have richer stats we need to do

00:10:55,360 --> 00:10:58,640
history based optimization this is

00:10:56,880 --> 00:11:00,079
something we are beginning to look at we

00:10:58,640 --> 00:11:01,120
haven't done a lot we have done a little

00:11:00,079 --> 00:11:03,760
bit i think

00:11:01,120 --> 00:11:05,360
um which is like how do we determine hey

00:11:03,760 --> 00:11:06,399
should this be a broadcast join or a

00:11:05,360 --> 00:11:08,240
hashtag

00:11:06,399 --> 00:11:09,519
we don't know right today today in most

00:11:08,240 --> 00:11:11,200
cases we don't know or we can we can

00:11:09,519 --> 00:11:11,839
guess based on stats but it's not very

00:11:11,200 --> 00:11:14,240
accurate

00:11:11,839 --> 00:11:15,680
but we can guess based on history and

00:11:14,240 --> 00:11:18,079
and this is something that we are

00:11:15,680 --> 00:11:19,760
beginning to poke at say we have a lot

00:11:18,079 --> 00:11:21,600
of these repetitive query patterns can

00:11:19,760 --> 00:11:24,160
we use historical data

00:11:21,600 --> 00:11:24,959
to make much better judgment calls on uh

00:11:24,160 --> 00:11:27,760
what the right

00:11:24,959 --> 00:11:29,040
uh execution strategy should be

00:11:27,760 --> 00:11:30,240
execution somebody asked me this

00:11:29,040 --> 00:11:32,560
question yes we are

00:11:30,240 --> 00:11:34,079
looking at it basically if your machine

00:11:32,560 --> 00:11:35,600
is stuck or failed does it mean that the

00:11:34,079 --> 00:11:36,720
entire query needs to be retried which

00:11:35,600 --> 00:11:39,040
is kind of expensive

00:11:36,720 --> 00:11:40,000
or can we actually only retry those

00:11:39,040 --> 00:11:42,800
fragments today

00:11:40,000 --> 00:11:43,760
presto's design makes that kind of

00:11:42,800 --> 00:11:45,680
tricky

00:11:43,760 --> 00:11:49,120
right and and we are we have to

00:11:45,680 --> 00:11:49,120
disentangle a lot of these

00:11:49,200 --> 00:11:52,720
details in order to make this happen so

00:11:51,200 --> 00:11:54,639
we're going through that and this

00:11:52,720 --> 00:11:56,079
actually allows you another very

00:11:54,639 --> 00:11:58,399
interesting characteristic which is

00:11:56,079 --> 00:12:00,000
adaptive execution so can we change

00:11:58,399 --> 00:12:02,480
your joint parallelism or even your

00:12:00,000 --> 00:12:04,800
joint type or your aggregate parallelism

00:12:02,480 --> 00:12:06,800
depending on where in the running stage

00:12:04,800 --> 00:12:09,760
you are and this requires you to

00:12:06,800 --> 00:12:11,600
disaggregate not only your kind of not

00:12:09,760 --> 00:12:13,519
only the stance but it requires the data

00:12:11,600 --> 00:12:14,800
it requires you to disaggregate your

00:12:13,519 --> 00:12:18,000
intermediate data what we call the

00:12:14,800 --> 00:12:20,000
shuffle because you might want to make a

00:12:18,000 --> 00:12:21,920
different decision or change the plan on

00:12:20,000 --> 00:12:22,639
the fly why that while the query is

00:12:21,920 --> 00:12:24,639
running

00:12:22,639 --> 00:12:26,079
based on you know the results of where

00:12:24,639 --> 00:12:27,600
the query is today and what you have

00:12:26,079 --> 00:12:29,360
found out about the query based on where

00:12:27,600 --> 00:12:31,279
it is today

00:12:29,360 --> 00:12:33,120
so this is something again kind of

00:12:31,279 --> 00:12:34,639
tricky it requires a bunch of

00:12:33,120 --> 00:12:36,399
fairly intricate surgery we are

00:12:34,639 --> 00:12:38,160
beginning to look at it uh

00:12:36,399 --> 00:12:39,920
talk to me offline if you are interested

00:12:38,160 --> 00:12:42,160
in the space

00:12:39,920 --> 00:12:42,160
um

00:12:42,959 --> 00:12:47,120
okay this is another area uh where i

00:12:45,920 --> 00:12:49,920
feel like we are

00:12:47,120 --> 00:12:50,320
lagging behind uh and i touched upon

00:12:49,920 --> 00:12:53,440
this

00:12:50,320 --> 00:12:55,440
in earlier in the in the chat group

00:12:53,440 --> 00:12:57,120
that one of the problems we have today

00:12:55,440 --> 00:12:58,240
is that the storage and metadata space

00:12:57,120 --> 00:13:00,160
is very fragmented

00:12:58,240 --> 00:13:01,360
so even though all of us use presto and

00:13:00,160 --> 00:13:02,880
spark

00:13:01,360 --> 00:13:04,480
the reality is that you know some people

00:13:02,880 --> 00:13:07,519
use orcs some people use parque some

00:13:04,480 --> 00:13:10,720
people use s3 some people use

00:13:07,519 --> 00:13:12,320
gcs some people use hdfs some people

00:13:10,720 --> 00:13:14,320
use high metastore some people use

00:13:12,320 --> 00:13:16,240
iceberg some people use delta

00:13:14,320 --> 00:13:18,079
and the problem with this fragmentation

00:13:16,240 --> 00:13:19,839
is that it very difficult becomes very

00:13:18,079 --> 00:13:21,839
difficult for us to do this whole stage

00:13:19,839 --> 00:13:23,760
optimization

00:13:21,839 --> 00:13:25,040
so so we are we are taking a bunch of

00:13:23,760 --> 00:13:27,279
small steps and this is a

00:13:25,040 --> 00:13:28,880
relatively new area we are looking at

00:13:27,279 --> 00:13:30,959
you know introducing z order and

00:13:28,880 --> 00:13:32,480
granular partitioning in our data right

00:13:30,959 --> 00:13:34,000
and and making press to take advantage

00:13:32,480 --> 00:13:35,920
of richer partitioning methods

00:13:34,000 --> 00:13:37,760
we're looking at improving arc through

00:13:35,920 --> 00:13:39,920
better encoding and other kind of format

00:13:37,760 --> 00:13:42,959
enhancement like smarter footers

00:13:39,920 --> 00:13:43,360
more richer metadata embedded in arc we

00:13:42,959 --> 00:13:46,240
are

00:13:43,360 --> 00:13:47,839
one thing that i'm particularly excited

00:13:46,240 --> 00:13:49,040
about is this usage based layout

00:13:47,839 --> 00:13:51,040
decisions

00:13:49,040 --> 00:13:53,120
this is something actually snowflake and

00:13:51,040 --> 00:13:54,880
bigquery and a lot of the warehouses do

00:13:53,120 --> 00:13:56,320
which is looking at the query patterns

00:13:54,880 --> 00:13:57,680
to say these are the most frequently

00:13:56,320 --> 00:13:59,680
used columns maybe you know when i

00:13:57,680 --> 00:14:01,680
create the arc file i write them first

00:13:59,680 --> 00:14:02,880
or or these are the most frequently used

00:14:01,680 --> 00:14:04,320
filter columns maybe i should

00:14:02,880 --> 00:14:06,240
automatically partition

00:14:04,320 --> 00:14:08,000
the data on that so that all you know

00:14:06,240 --> 00:14:09,760
queries become better or these files are

00:14:08,000 --> 00:14:11,839
too small it only has like

00:14:09,760 --> 00:14:13,440
10 rows per stripe maybe we should

00:14:11,839 --> 00:14:15,760
automatically compact these files into

00:14:13,440 --> 00:14:18,079
bigger files like how do we

00:14:15,760 --> 00:14:19,600
do this automated column ordering or you

00:14:18,079 --> 00:14:22,079
know reordering

00:14:19,600 --> 00:14:23,760
uh racial metadata based decision

00:14:22,079 --> 00:14:25,680
history based decision in terms of not

00:14:23,760 --> 00:14:26,720
only the query optimization but in terms

00:14:25,680 --> 00:14:28,880
of data layout

00:14:26,720 --> 00:14:31,279
and and we have a team who is kind of a

00:14:28,880 --> 00:14:33,360
v team

00:14:31,279 --> 00:14:34,880
that that is looking at this automating

00:14:33,360 --> 00:14:36,800
this entire process and then also

00:14:34,880 --> 00:14:40,639
introducing richer

00:14:36,800 --> 00:14:43,519
kind of z-order clustering but

00:14:40,639 --> 00:14:45,199
again it's early days but we are very uh

00:14:43,519 --> 00:14:47,760
excited by the initial promise that is

00:14:45,199 --> 00:14:47,760
shown by this

00:14:48,720 --> 00:14:54,320
area we talked a lot about raptor x this

00:14:51,920 --> 00:14:55,440
i think uh james gave a very good talk

00:14:54,320 --> 00:14:57,680
on this

00:14:55,440 --> 00:14:59,199
briefly speaking uh it's all about

00:14:57,680 --> 00:15:00,560
caching and affinity

00:14:59,199 --> 00:15:03,920
right roughly speaking we are caching

00:15:00,560 --> 00:15:06,959
data at various stages raw data metadata

00:15:03,920 --> 00:15:10,399
partially computed fragments

00:15:06,959 --> 00:15:11,760
result caches we are getting really

00:15:10,399 --> 00:15:13,279
really good performance the goal is

00:15:11,760 --> 00:15:14,959
obviously to beat

00:15:13,279 --> 00:15:17,279
to at least match if not beat the

00:15:14,959 --> 00:15:19,519
performance of co-located storage

00:15:17,279 --> 00:15:20,959
while the story is still disaggregated

00:15:19,519 --> 00:15:21,839
we have actually achieved that in some

00:15:20,959 --> 00:15:23,760
cases we

00:15:21,839 --> 00:15:25,279
actually get better results than the

00:15:23,760 --> 00:15:27,360
co-located

00:15:25,279 --> 00:15:29,519
raptor model and this is because of like

00:15:27,360 --> 00:15:31,519
a complex set of issues like we can

00:15:29,519 --> 00:15:33,360
for example soft affinity allows us to

00:15:31,519 --> 00:15:34,880
reroute the individual spirit to a

00:15:33,360 --> 00:15:35,600
different worker if one worker is

00:15:34,880 --> 00:15:37,759
overloaded

00:15:35,600 --> 00:15:39,600
so in aggregate you actually met may get

00:15:37,759 --> 00:15:41,360
better utilization better throughput and

00:15:39,600 --> 00:15:43,360
you know better latencies

00:15:41,360 --> 00:15:45,600
this is all in production you should

00:15:43,360 --> 00:15:47,680
definitely try it out

00:15:45,600 --> 00:15:48,720
okay lot of questions about native code

00:15:47,680 --> 00:15:50,160
acceleration

00:15:48,720 --> 00:15:51,920
so let me spend a little bit of time on

00:15:50,160 --> 00:15:55,120
that this is this little graph

00:15:51,920 --> 00:15:55,680
on the right uh the leftmost bar which

00:15:55,120 --> 00:15:58,480
is 0

00:15:55,680 --> 00:15:59,279
this indicates where the java code is

00:15:58,480 --> 00:16:01,360
faster

00:15:59,279 --> 00:16:02,639
and the right most bar is 10 which is

00:16:01,360 --> 00:16:04,800
indicate where the c

00:16:02,639 --> 00:16:06,399
plus node is 10x faster than an order of

00:16:04,800 --> 00:16:08,160
magnitude faster than java

00:16:06,399 --> 00:16:10,000
now the graphs on the two extremes are

00:16:08,160 --> 00:16:12,000
really thin right

00:16:10,000 --> 00:16:13,920
but if you notice the median of this is

00:16:12,000 --> 00:16:16,639
kind of five or four

00:16:13,920 --> 00:16:17,519
zero one two three four which is pretty

00:16:16,639 --> 00:16:19,279
astonishing

00:16:17,519 --> 00:16:21,360
because we have spent a lot of time you

00:16:19,279 --> 00:16:23,519
know tuning our java eval

00:16:21,360 --> 00:16:25,360
and what we are finding now with our c

00:16:23,519 --> 00:16:26,079
plus plus native vectorized eval is that

00:16:25,360 --> 00:16:28,800
we can

00:16:26,079 --> 00:16:30,480
on at least the initial fairly simple

00:16:28,800 --> 00:16:32,000
and admittedly somewhat biased query

00:16:30,480 --> 00:16:33,839
pattern side which are just doing filter

00:16:32,000 --> 00:16:36,079
project aggregate whatever

00:16:33,839 --> 00:16:38,639
uh on a single node we are seeing 4x

00:16:36,079 --> 00:16:40,399
better cpu performance

00:16:38,639 --> 00:16:42,240
and memory performance is better too we

00:16:40,399 --> 00:16:44,240
haven't fully measured that so how do we

00:16:42,240 --> 00:16:47,759
achieve that

00:16:44,240 --> 00:16:50,240
we essentially have taken this fairly

00:16:47,759 --> 00:16:51,279
large task of rewriting the core eval

00:16:50,240 --> 00:16:54,160
engine of presto

00:16:51,279 --> 00:16:56,000
in c process right and during this

00:16:54,160 --> 00:16:56,560
process we are really going all out like

00:16:56,000 --> 00:16:59,199
we

00:16:56,560 --> 00:17:01,360
we are doing very very tight native

00:16:59,199 --> 00:17:03,199
memory control we are

00:17:01,360 --> 00:17:04,880
exploiting all the nooks and crannies of

00:17:03,199 --> 00:17:05,520
c plus plus temperature meta programming

00:17:04,880 --> 00:17:07,280
we are

00:17:05,520 --> 00:17:09,360
you know explicitly calling simply

00:17:07,280 --> 00:17:10,880
intrinsics we are doing state-of-the-art

00:17:09,360 --> 00:17:11,839
vectorize and coaching techniques we

00:17:10,880 --> 00:17:13,839
have a team

00:17:11,839 --> 00:17:15,280
in llvm we're trying to code jen the

00:17:13,839 --> 00:17:17,919
most um

00:17:15,280 --> 00:17:19,439
up like the most uh the slowest and the

00:17:17,919 --> 00:17:21,919
most complex expressions

00:17:19,439 --> 00:17:24,000
and then hook them in into this uh into

00:17:21,919 --> 00:17:25,039
the kind of the eval tree on the fly to

00:17:24,000 --> 00:17:26,720
get better

00:17:25,039 --> 00:17:28,480
results and these levels don't reflect

00:17:26,720 --> 00:17:30,000
that value um

00:17:28,480 --> 00:17:31,600
and the other nice thing what we are

00:17:30,000 --> 00:17:34,559
doing uh going back toward this

00:17:31,600 --> 00:17:36,720
unification convergence theme that

00:17:34,559 --> 00:17:38,720
this is being built as a standalone

00:17:36,720 --> 00:17:40,559
library and this can potentially be used

00:17:38,720 --> 00:17:42,400
beyond crystal so we are

00:17:40,559 --> 00:17:43,840
using it in spark initial results look

00:17:42,400 --> 00:17:45,120
really good you can think of it like a

00:17:43,840 --> 00:17:46,799
photon equivalent

00:17:45,120 --> 00:17:48,640
we are using it in our streaming

00:17:46,799 --> 00:17:50,400
processing system called extreme

00:17:48,640 --> 00:17:52,080
uh it's not in production yet this is

00:17:50,400 --> 00:17:54,240
fairly early in the development phase

00:17:52,080 --> 00:17:55,440
initial numbers are really good we

00:17:54,240 --> 00:17:57,120
intend to us

00:17:55,440 --> 00:17:58,960
open source it at some point we are

00:17:57,120 --> 00:17:59,760
gradually opening up access to some of

00:17:58,960 --> 00:18:02,160
our

00:17:59,760 --> 00:18:03,760
you know early adopters partners again

00:18:02,160 --> 00:18:06,080
if you're interested

00:18:03,760 --> 00:18:07,679
talk to me offline um we can we can give

00:18:06,080 --> 00:18:10,240
you more details or early access and

00:18:07,679 --> 00:18:10,240
things like that

00:18:10,799 --> 00:18:15,280
okay sql sql standardization is a big

00:18:14,640 --> 00:18:17,360
problem

00:18:15,280 --> 00:18:19,840
and and this is this core sql project is

00:18:17,360 --> 00:18:22,320
essentially about taking crystal sql

00:18:19,840 --> 00:18:23,039
enriching it with all the latest sql 16

00:18:22,320 --> 00:18:24,640
goodness with

00:18:23,039 --> 00:18:26,480
graph extensions streaming extensions

00:18:24,640 --> 00:18:28,080
rich types like you know distinct types

00:18:26,480 --> 00:18:31,840
enums

00:18:28,080 --> 00:18:33,360
name types and making that available to

00:18:31,840 --> 00:18:34,720
all the surfaces to going back to the

00:18:33,360 --> 00:18:37,440
preston spark

00:18:34,720 --> 00:18:39,120
presto on spark is actually if you think

00:18:37,440 --> 00:18:40,559
about it another way of looking at

00:18:39,120 --> 00:18:41,679
restaurant spark is now you have the

00:18:40,559 --> 00:18:44,480
full richness and

00:18:41,679 --> 00:18:45,360
functionality of crystal sql but using

00:18:44,480 --> 00:18:47,039
the spark

00:18:45,360 --> 00:18:48,799
as the execution framework so you don't

00:18:47,039 --> 00:18:50,720
have to rewrite your queries into spark

00:18:48,799 --> 00:18:52,400
sql or sql if you just want to leverage

00:18:50,720 --> 00:18:53,200
path you can still keep using bristol

00:18:52,400 --> 00:18:54,320
sql

00:18:53,200 --> 00:18:56,000
we are doing the same thing with our

00:18:54,320 --> 00:18:56,720
streaming engine which is kind of an

00:18:56,000 --> 00:18:58,559
internal

00:18:56,720 --> 00:19:00,640
uh proprietary c plus based thing which

00:18:58,559 --> 00:19:04,160
is called extreme we are embedding vlogs

00:19:00,640 --> 00:19:07,360
we have a score sql uh c plus plus uh

00:19:04,160 --> 00:19:09,200
front end that a team is writing the upm

00:19:07,360 --> 00:19:12,320
team is writing

00:19:09,200 --> 00:19:14,720
um it's uh i i think this is a very

00:19:12,320 --> 00:19:16,320
uh interesting and exciting kind of

00:19:14,720 --> 00:19:19,440
world where we really want to

00:19:16,320 --> 00:19:23,039
align on the dialect right

00:19:19,440 --> 00:19:24,960
so the grammar and the main parser of

00:19:23,039 --> 00:19:26,799
course equals srini has written this new

00:19:24,960 --> 00:19:28,559
javascript grammar this is directly

00:19:26,799 --> 00:19:30,480
derived from sequel 16 standard

00:19:28,559 --> 00:19:31,919
we have added all the presto extensions

00:19:30,480 --> 00:19:33,360
to it we have added

00:19:31,919 --> 00:19:35,200
graph and streaming extensions we are

00:19:33,360 --> 00:19:35,440
adding graph and streaming extensions to

00:19:35,200 --> 00:19:37,600
it

00:19:35,440 --> 00:19:39,280
check it out it's already open source we

00:19:37,600 --> 00:19:40,559
are doing some lightweight integration

00:19:39,280 --> 00:19:42,000
with presto right now

00:19:40,559 --> 00:19:43,600
hopefully a deeper integration which

00:19:42,000 --> 00:19:45,280
will essentially get rid of the existing

00:19:43,600 --> 00:19:46,559
plus to antler-based parser and replace

00:19:45,280 --> 00:19:49,039
it with this one

00:19:46,559 --> 00:19:49,039
is on the way

00:19:49,679 --> 00:19:54,080
and portable udfs so this is a very

00:19:53,200 --> 00:19:55,919
common

00:19:54,080 --> 00:19:58,160
problem people often say that hey high

00:19:55,919 --> 00:19:59,679
udfs are only java only the running

00:19:58,160 --> 00:20:01,200
spark they don't come in plus two

00:19:59,679 --> 00:20:03,280
crystal has its own way of writing

00:20:01,200 --> 00:20:06,320
functions but that is embedded java

00:20:03,280 --> 00:20:08,240
we have a lot of code

00:20:06,320 --> 00:20:09,919
which is in java but we also have a lot

00:20:08,240 --> 00:20:12,080
of code which is in c plus plus which

00:20:09,919 --> 00:20:13,679
hack in python and how do we reuse this

00:20:12,080 --> 00:20:15,120
when we want to break the shackles of

00:20:13,679 --> 00:20:16,159
sql and go into you know deeper

00:20:15,120 --> 00:20:19,280
programming

00:20:16,159 --> 00:20:20,799
um so portable udf is our method wrong

00:20:19,280 --> 00:20:22,080
wrong is the person driving this from

00:20:20,799 --> 00:20:25,039
the facebook side

00:20:22,080 --> 00:20:27,679
the idea is that you establish certain

00:20:25,039 --> 00:20:29,919
protocols of metadata and the data plane

00:20:27,679 --> 00:20:31,520
on how to interface with out of process

00:20:29,919 --> 00:20:33,600
and we are we currently have thrift we

00:20:31,520 --> 00:20:35,600
want to add presto page to it

00:20:33,600 --> 00:20:37,600
to efficiently execute out of process

00:20:35,600 --> 00:20:39,200
functions and and make the result of

00:20:37,600 --> 00:20:40,080
that function available to the to the

00:20:39,200 --> 00:20:44,000
eval engine

00:20:40,080 --> 00:20:46,000
and we have this working for java we

00:20:44,000 --> 00:20:48,559
hope to have this working soon for c

00:20:46,000 --> 00:20:50,240
plus this gives a lot of flexibility

00:20:48,559 --> 00:20:51,360
in terms of extending the engine with

00:20:50,240 --> 00:20:52,240
you know functionality that you have

00:20:51,360 --> 00:20:54,080
already built

00:20:52,240 --> 00:20:55,440
in the form of libraries especially if

00:20:54,080 --> 00:20:59,440
it is in other languages

00:20:55,440 --> 00:21:01,600
non-java language so that was kind of

00:20:59,440 --> 00:21:02,480
our bigger better faster and more so one

00:21:01,600 --> 00:21:05,440
final thought

00:21:02,480 --> 00:21:07,200
uh i wanted to leave everyone with this

00:21:05,440 --> 00:21:09,360
like do we have too much

00:21:07,200 --> 00:21:11,200
uh and should we kind of look at less is

00:21:09,360 --> 00:21:13,039
more so today we have multiple engines

00:21:11,200 --> 00:21:15,200
we have spark presto multiple dialects

00:21:13,039 --> 00:21:16,880
presto sequel hul

00:21:15,200 --> 00:21:18,159
very different modes and each of them

00:21:16,880 --> 00:21:18,960
each of these modes have like a

00:21:18,159 --> 00:21:20,640
vertically

00:21:18,960 --> 00:21:22,480
vertical stack where they don't reuse

00:21:20,640 --> 00:21:23,679
anything like even at facebook the

00:21:22,480 --> 00:21:25,120
streaming and the batch and the

00:21:23,679 --> 00:21:27,200
interactive and the graph are

00:21:25,120 --> 00:21:28,880
almost completely different code bases

00:21:27,200 --> 00:21:30,240
right they don't share the eval they

00:21:28,880 --> 00:21:31,760
don't share the language

00:21:30,240 --> 00:21:34,400
they don't share the underlying io

00:21:31,760 --> 00:21:35,679
libraries and so on and so forth

00:21:34,400 --> 00:21:37,360
they don't share the software shuffle in

00:21:35,679 --> 00:21:38,480
some cases for example multiple meta

00:21:37,360 --> 00:21:40,320
stores facebook has

00:21:38,480 --> 00:21:42,159
high metastore we have enhanced it a lot

00:21:40,320 --> 00:21:44,880
so it's like high metastore plus plus

00:21:42,159 --> 00:21:46,640
plus uh in open source we have iceberg

00:21:44,880 --> 00:21:48,240
delta a lot of people are migrating from

00:21:46,640 --> 00:21:50,400
hybrid district five

00:21:48,240 --> 00:21:52,080
and uh like high middle store to iceberg

00:21:50,400 --> 00:21:53,919
we have many different formats arc and

00:21:52,080 --> 00:21:55,280
party are common like alibaba has its

00:21:53,919 --> 00:21:57,120
own internal format

00:21:55,280 --> 00:21:58,640
uh snowflake has its own internal format

00:21:57,120 --> 00:21:59,280
we probably don't want to get into this

00:21:58,640 --> 00:22:01,360
kind of

00:21:59,280 --> 00:22:03,840
wall garden right google like bigquery

00:22:01,360 --> 00:22:06,240
has its own format capacitor

00:22:03,840 --> 00:22:08,080
um and then there is ml right we have a

00:22:06,240 --> 00:22:08,960
lot of people who are using pytorch and

00:22:08,080 --> 00:22:11,280
tensorflow

00:22:08,960 --> 00:22:13,039
and these ml pipelines also need feature

00:22:11,280 --> 00:22:14,880
engineering they also want

00:22:13,039 --> 00:22:16,559
you know to dynamically transform the

00:22:14,880 --> 00:22:17,280
data as it goes up into the training

00:22:16,559 --> 00:22:19,440
stack

00:22:17,280 --> 00:22:20,559
right so what are the opportunities here

00:22:19,440 --> 00:22:22,080
and i feel there are a lot of

00:22:20,559 --> 00:22:24,240
opportunities for convergence

00:22:22,080 --> 00:22:26,400
like western spark is a good example of

00:22:24,240 --> 00:22:27,039
convergence on the language front velox

00:22:26,400 --> 00:22:29,600
is a good

00:22:27,039 --> 00:22:30,799
example of like convergence in the you

00:22:29,600 --> 00:22:33,840
know eval front

00:22:30,799 --> 00:22:35,919
right can we converge on metastore for

00:22:33,840 --> 00:22:37,919
example can we converge on file formats

00:22:35,919 --> 00:22:40,320
are or can parquet really that different

00:22:37,919 --> 00:22:42,080
if we put our you know minds together

00:22:40,320 --> 00:22:44,000
and created a

00:22:42,080 --> 00:22:45,840
really really good format maybe take

00:22:44,000 --> 00:22:48,640
either alcohol parque and extend that

00:22:45,840 --> 00:22:50,080
so that it covers all of our needs do we

00:22:48,640 --> 00:22:51,840
need multiple formats because it

00:22:50,080 --> 00:22:53,919
generates a lot of additional work

00:22:51,840 --> 00:22:55,440
like the aria project did a lot of work

00:22:53,919 --> 00:22:57,520
optimizing for all but none of that

00:22:55,440 --> 00:22:59,360
benefits goes to part

00:22:57,520 --> 00:23:00,880
similarly on the meta store i feel in

00:22:59,360 --> 00:23:03,440
order to

00:23:00,880 --> 00:23:04,240
create a truly competing open source

00:23:03,440 --> 00:23:05,840
ecosystem

00:23:04,240 --> 00:23:08,400
by competing i mean competing with the

00:23:05,840 --> 00:23:09,360
closed counterparts like bigquery and

00:23:08,400 --> 00:23:12,080
snowflake

00:23:09,360 --> 00:23:13,520
we really need to think about this as a

00:23:12,080 --> 00:23:16,320
holistic unit

00:23:13,520 --> 00:23:18,720
right where we have presto and spark and

00:23:16,320 --> 00:23:19,760
high metastore and orc and hdfs and all

00:23:18,720 --> 00:23:22,080
this kind of

00:23:19,760 --> 00:23:23,440
object stores and think about how we

00:23:22,080 --> 00:23:25,919
reach a global optima

00:23:23,440 --> 00:23:27,120
a global maxima and this requires us

00:23:25,919 --> 00:23:29,360
probably to

00:23:27,120 --> 00:23:30,640
converge at least on the api front on

00:23:29,360 --> 00:23:32,400
the language front if not on the

00:23:30,640 --> 00:23:34,480
implementation front but ideally on the

00:23:32,400 --> 00:23:36,320
implementation front as well

00:23:34,480 --> 00:23:39,120
so that we can pull our resources and

00:23:36,320 --> 00:23:42,720
build the next best thing together

00:23:39,120 --> 00:23:46,320
and uh that's all i have

00:23:42,720 --> 00:23:48,960
thank you any questions feel free to hop

00:23:46,320 --> 00:23:48,960
into the session

00:23:49,600 --> 00:23:54,080
okay uh i'll dip this here great session

00:23:53,440 --> 00:23:56,640
bishwa

00:23:54,080 --> 00:23:58,400
that was um that was uh pretty

00:23:56,640 --> 00:24:01,520
phenomenal the vision is

00:23:58,400 --> 00:24:04,000
exciting and uh what a

00:24:01,520 --> 00:24:05,760
what a great way to end the day uh here

00:24:04,000 --> 00:24:06,720
at presto con folks if you have any last

00:24:05,760 --> 00:24:08,559
questions uh

00:24:06,720 --> 00:24:10,320
please bring them up i think there were

00:24:08,559 --> 00:24:11,919
many that you answered along the way

00:24:10,320 --> 00:24:14,159
there were questions with the native

00:24:11,919 --> 00:24:16,159
worker there were questions on um

00:24:14,159 --> 00:24:18,080
uh the resilience and the the fault

00:24:16,159 --> 00:24:19,440
tolerance of it for spark things like

00:24:18,080 --> 00:24:20,799
that so a lot of things that are

00:24:19,440 --> 00:24:23,919
answered along the way

00:24:20,799 --> 00:24:28,000
uh so thank you so much uh for uh

00:24:23,919 --> 00:24:28,000

YouTube URL: https://www.youtube.com/watch?v=JuWiWmUtn3M


