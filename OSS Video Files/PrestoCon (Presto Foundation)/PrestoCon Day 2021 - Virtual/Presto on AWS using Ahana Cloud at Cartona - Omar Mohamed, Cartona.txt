Title: Presto on AWS using Ahana Cloud at Cartona - Omar Mohamed, Cartona
Publication date: 2021-03-27
Playlist: PrestoCon Day 2021 - Virtual
Description: 
	Presto on AWS using Ahana Cloud at Cartona - Omar Mohamed, Cartona

Cartona is one of the fastest growing B2B e-commerce marketplaces in Egypt that connects retailers with suppliers, wholesalers, and production companies. We needed to federate across multiple data sources, including transactional databases like Postgres and AWS S3 data lake. In this session, we’ll talk about how Presto allows us to join across all of these data sources without having to copy or ingest data - it’s all done in place.
In addition, we’ll talk about how we were up and running in less than an hour with the Ahana Cloud managed service. It gives us the power of Presto and the ease of use without the need to manage it or have deep skills to deploy and operate it.

For more info about Presto, the open source distributed SQL query engine for running interactive analytic queries against data sources of all sizes ranging from gigabytes to petabytes, see: https://prestodb.io/
Captions: 
	00:00:00,080 --> 00:00:05,359
hello everyone my name is omar muhammad

00:00:02,720 --> 00:00:07,759
i'm a data engineer here at cartoon

00:00:05,359 --> 00:00:08,960
i'm here to talk about our experience

00:00:07,759 --> 00:00:12,160
using prestu

00:00:08,960 --> 00:00:13,840
and ohana why we needed to use bristol

00:00:12,160 --> 00:00:16,960
in the first place

00:00:13,840 --> 00:00:20,480
and how it benefited our business

00:00:16,960 --> 00:00:24,480
and made our lives easier but first

00:00:20,480 --> 00:00:26,960
let me introduce you to cartoon

00:00:24,480 --> 00:00:28,080
cartoon is one of the fastest growing

00:00:26,960 --> 00:00:30,960
b2b

00:00:28,080 --> 00:00:31,599
e-commerce marketplaces in the mena

00:00:30,960 --> 00:00:34,960
region

00:00:31,599 --> 00:00:37,520
in north africa and the middle east

00:00:34,960 --> 00:00:38,480
that connects retailers with suppliers

00:00:37,520 --> 00:00:41,360
wholesalers

00:00:38,480 --> 00:00:44,079
and production companies will provide a

00:00:41,360 --> 00:00:45,920
mobile application ios and android

00:00:44,079 --> 00:00:47,440
for retailers to browse different

00:00:45,920 --> 00:00:50,239
products and

00:00:47,440 --> 00:00:52,239
suppliers compare prices place their

00:00:50,239 --> 00:00:55,039
orders and have them delivered

00:00:52,239 --> 00:00:56,640
in just a few steps we also have an app

00:00:55,039 --> 00:00:59,680
for suppliers to update

00:00:56,640 --> 00:01:02,239
update their prices place special offers

00:00:59,680 --> 00:01:04,799
and track their orders we're also

00:01:02,239 --> 00:01:06,080
providing 24-hour support for retailers

00:01:04,799 --> 00:01:08,240
and suppliers

00:01:06,080 --> 00:01:09,840
to make sure everything is always

00:01:08,240 --> 00:01:12,640
running smoothly

00:01:09,840 --> 00:01:12,880
we are exponentially growing with tens

00:01:12,640 --> 00:01:15,439
of

00:01:12,880 --> 00:01:16,880
thousands of orders placed monthly

00:01:15,439 --> 00:01:19,920
through the app

00:01:16,880 --> 00:01:22,560
we continue to directly integrate with

00:01:19,920 --> 00:01:23,920
egypts and the middle east's biggest

00:01:22,560 --> 00:01:28,479
suppliers

00:01:23,920 --> 00:01:30,320
including unilever and coca-cola

00:01:28,479 --> 00:01:32,240
to stay ahead in a highly competitive

00:01:30,320 --> 00:01:34,640
market we need to study the incoming

00:01:32,240 --> 00:01:37,520
data and quickly adapt to the changes

00:01:34,640 --> 00:01:39,680
and trends we have a fantastic bi and

00:01:37,520 --> 00:01:42,159
growth team that is continuously working

00:01:39,680 --> 00:01:45,360
hard to drive our business forward

00:01:42,159 --> 00:01:49,040
and help us focus on the right metrics

00:01:45,360 --> 00:01:50,159
the the the bi team uh mainly uses

00:01:49,040 --> 00:01:53,119
redash as we

00:01:50,159 --> 00:01:54,560
see in this figure to connect to our

00:01:53,119 --> 00:01:58,240
different databases and

00:01:54,560 --> 00:01:59,280
data warehouses so basically we have the

00:01:58,240 --> 00:02:01,840
transactional

00:01:59,280 --> 00:02:04,640
database which is our main database that

00:02:01,840 --> 00:02:07,840
logs the main transaction in our system

00:02:04,640 --> 00:02:10,160
like orders and users and we have an

00:02:07,840 --> 00:02:13,599
analytics database which is

00:02:10,160 --> 00:02:16,959
which is a playground for the analytics

00:02:13,599 --> 00:02:20,640
and bi team to to make their

00:02:16,959 --> 00:02:24,080
experiments and calculate other

00:02:20,640 --> 00:02:25,360
metrics that could be important we also

00:02:24,080 --> 00:02:29,520
have a time scale db

00:02:25,360 --> 00:02:32,879
to to lock the changes in our data

00:02:29,520 --> 00:02:36,000
like the prices and so on

00:02:32,879 --> 00:02:37,760
and we have the retailer

00:02:36,000 --> 00:02:39,440
events warehouse and the supplier events

00:02:37,760 --> 00:02:42,959
warehouse we are

00:02:39,440 --> 00:02:46,160
using segments uh to track uh events

00:02:42,959 --> 00:02:48,560
uh across our apps uh and

00:02:46,160 --> 00:02:50,000
look uh the different interaction that

00:02:48,560 --> 00:02:53,200
users have with our

00:02:50,000 --> 00:02:56,239
applications to help uh

00:02:53,200 --> 00:02:58,879
recommend and personalize uh

00:02:56,239 --> 00:02:59,519
their experiences and like mentioned

00:02:58,879 --> 00:03:04,000
earlier

00:02:59,519 --> 00:03:07,920
earlier we have redash at the heart uh

00:03:04,000 --> 00:03:11,120
of the operation uh to help the bi team

00:03:07,920 --> 00:03:14,480
visualize uh and

00:03:11,120 --> 00:03:15,360
and bring forth their the important

00:03:14,480 --> 00:03:19,840
metrics

00:03:15,360 --> 00:03:19,840
to the business team

00:03:20,400 --> 00:03:23,920
so this is a number of records that gets

00:03:22,800 --> 00:03:27,920
synchronized

00:03:23,920 --> 00:03:30,480
every 12 hours from segments

00:03:27,920 --> 00:03:31,680
of course we're using segments on

00:03:30,480 --> 00:03:33,760
different

00:03:31,680 --> 00:03:36,560
so with different sources and

00:03:33,760 --> 00:03:39,360
destinations this is a single source

00:03:36,560 --> 00:03:40,239
uh which is a retailer app writing uh

00:03:39,360 --> 00:03:43,599
into our

00:03:40,239 --> 00:03:46,159
data warehouse so we can see that every

00:03:43,599 --> 00:03:47,040
12 hours or every synchronize we get

00:03:46,159 --> 00:03:50,400
around

00:03:47,040 --> 00:03:53,920
200 000 events

00:03:50,400 --> 00:03:58,000
written to the database and with our

00:03:53,920 --> 00:03:58,000
increased number of users and

00:03:58,239 --> 00:04:02,400
growth we can imagine how difficult it

00:04:01,200 --> 00:04:05,599
will be

00:04:02,400 --> 00:04:09,040
in the upcoming months uh to keep track

00:04:05,599 --> 00:04:13,680
uh of all this uh information and drive

00:04:09,040 --> 00:04:17,519
insights from them so uh it began

00:04:13,680 --> 00:04:21,359
to make sense that we need some tool

00:04:17,519 --> 00:04:24,639
that can help us in

00:04:21,359 --> 00:04:27,840
keeping track of all this information

00:04:24,639 --> 00:04:31,040
so the data size grew larger

00:04:27,840 --> 00:04:32,800
some limitations started to appear uh

00:04:31,040 --> 00:04:34,960
for instance getting the whole picture

00:04:32,800 --> 00:04:39,040
is now uh was proving

00:04:34,960 --> 00:04:40,639
difficult as as a number of databases

00:04:39,040 --> 00:04:43,919
and data warehouses

00:04:40,639 --> 00:04:45,840
were was increasing uh it became

00:04:43,919 --> 00:04:48,560
difficult to make reports that leverage

00:04:45,840 --> 00:04:50,400
information from from our different uh

00:04:48,560 --> 00:04:53,520
sources

00:04:50,400 --> 00:04:56,240
and the bi team started uh

00:04:53,520 --> 00:04:57,280
writing different syntaxes and query

00:04:56,240 --> 00:04:59,840
languages

00:04:57,280 --> 00:05:01,680
depending on the source they were

00:04:59,840 --> 00:05:05,520
dealing with

00:05:01,680 --> 00:05:09,520
so it it was getting more

00:05:05,520 --> 00:05:12,880
complicated each week

00:05:09,520 --> 00:05:15,360
and we also started noticing uh some

00:05:12,880 --> 00:05:16,479
some with some complex queries with our

00:05:15,360 --> 00:05:20,479
increased

00:05:16,479 --> 00:05:21,280
uh data sizes that some queries were

00:05:20,479 --> 00:05:25,840
were taking

00:05:21,280 --> 00:05:25,840
uh a long time to execute

00:05:28,080 --> 00:05:32,960
so it became clear to us that we need to

00:05:30,800 --> 00:05:34,720
use something like presto as it will

00:05:32,960 --> 00:05:36,720
enable the bi team

00:05:34,720 --> 00:05:38,560
to join across our different databases

00:05:36,720 --> 00:05:42,240
and data warehouses

00:05:38,560 --> 00:05:47,280
while unifying the syntax and

00:05:42,240 --> 00:05:47,280
making the queries run faster

00:05:48,160 --> 00:05:55,680
but deploying ris2 into a production

00:05:52,400 --> 00:05:57,759
level i can get a bit challenging

00:05:55,680 --> 00:05:59,360
first you need to deploy and configure

00:05:57,759 --> 00:06:02,240
your different

00:05:59,360 --> 00:06:04,319
workers the coordinator and the hive

00:06:02,240 --> 00:06:07,840
meta store

00:06:04,319 --> 00:06:10,000
if you don't have it uh and you need to

00:06:07,840 --> 00:06:13,039
uh to be able to scale up

00:06:10,000 --> 00:06:16,400
or down depending on your usage

00:06:13,039 --> 00:06:20,240
either vertically or horizontally

00:06:16,400 --> 00:06:23,360
and you also need to be able to monitor

00:06:20,240 --> 00:06:26,479
the cluster at all times get notified if

00:06:23,360 --> 00:06:27,680
anything unexpected happens and health

00:06:26,479 --> 00:06:30,960
check

00:06:27,680 --> 00:06:33,199
the cluster at all times and this is

00:06:30,960 --> 00:06:36,479
where ahanna comes in

00:06:33,199 --> 00:06:38,639
hannah removed all the difficulties and

00:06:36,479 --> 00:06:40,800
challenges of deploying presto

00:06:38,639 --> 00:06:42,560
to our production environment and

00:06:40,800 --> 00:06:44,560
granted us control

00:06:42,560 --> 00:06:47,360
over the cluster with scaling up and

00:06:44,560 --> 00:06:49,759
down options

00:06:47,360 --> 00:06:50,720
this was uh we were able to accomplish

00:06:49,759 --> 00:06:54,479
that uh

00:06:50,720 --> 00:06:57,520
within an hour uh in a call

00:06:54,479 --> 00:06:59,680
uh after that where we were able to

00:06:57,520 --> 00:07:01,360
easily connect 3 dash to breast 2

00:06:59,680 --> 00:07:04,479
directly

00:07:01,360 --> 00:07:06,240
and could fully enjoy the full benefits

00:07:04,479 --> 00:07:09,919
of having breast too

00:07:06,240 --> 00:07:14,840
in our disposal we performed

00:07:09,919 --> 00:07:18,639
a benchmark on one of our most important

00:07:14,840 --> 00:07:22,319
dashboards the dashboard is includes

00:07:18,639 --> 00:07:25,120
around 38 heavy queries

00:07:22,319 --> 00:07:27,120
that are vital to our business and

00:07:25,120 --> 00:07:30,400
growth

00:07:27,120 --> 00:07:34,479
so we see in the figure that before

00:07:30,400 --> 00:07:37,440
using pres2 to refresh

00:07:34,479 --> 00:07:38,080
the whole dashboard and the whole

00:07:37,440 --> 00:07:41,360
queries

00:07:38,080 --> 00:07:45,120
it took around 60 seconds

00:07:41,360 --> 00:07:48,080
uh after presto it went down to 27

00:07:45,120 --> 00:07:49,680
which is impressive enough but with some

00:07:48,080 --> 00:07:52,639
small optimization

00:07:49,680 --> 00:07:54,160
uh like using approximates when we don't

00:07:52,639 --> 00:07:58,240
need the exact

00:07:54,160 --> 00:08:00,400
numbers and using a regular expressions

00:07:58,240 --> 00:08:01,440
instead of writing multiple like

00:08:00,400 --> 00:08:04,240
statements

00:08:01,440 --> 00:08:06,560
we went down to 15 seconds which is

00:08:04,240 --> 00:08:09,599
around 75

00:08:06,560 --> 00:08:11,840
percent decrease in time

00:08:09,599 --> 00:08:13,680
so now we are able to join across our

00:08:11,840 --> 00:08:14,800
different databases without having to

00:08:13,680 --> 00:08:18,879
copy or ingest

00:08:14,800 --> 00:08:22,800
data it's all done in in place impress2

00:08:18,879 --> 00:08:27,199
which saved us hours of planning and

00:08:22,800 --> 00:08:31,280
and manual work from the pi team

00:08:27,199 --> 00:08:34,959
also our pi team has only now to write

00:08:31,280 --> 00:08:37,599
sql syntax no matter the database that

00:08:34,959 --> 00:08:40,159
they are communicating with

00:08:37,599 --> 00:08:41,200
our pi team managed to make new

00:08:40,159 --> 00:08:44,080
dashboards

00:08:41,200 --> 00:08:47,360
uh linking between the analytics

00:08:44,080 --> 00:08:49,120
database and the events warehouse

00:08:47,360 --> 00:08:50,800
and with the help of these dashboards we

00:08:49,120 --> 00:08:54,959
managed to to make

00:08:50,800 --> 00:08:58,399
new recommendations for for our users

00:08:54,959 --> 00:09:01,680
and make their their experience more

00:08:58,399 --> 00:09:04,240
personalized and

00:09:01,680 --> 00:09:05,040
now we have symbol configuration control

00:09:04,240 --> 00:09:08,560
over our

00:09:05,040 --> 00:09:10,320
presto cluster the power to scale up and

00:09:08,560 --> 00:09:12,800
down the workers

00:09:10,320 --> 00:09:14,800
and change the instance type if we want

00:09:12,800 --> 00:09:18,399
to uh

00:09:14,800 --> 00:09:21,519
to to scale up or down vertically

00:09:18,399 --> 00:09:23,839
and we don't have to worry about

00:09:21,519 --> 00:09:24,720
health checking the cluster to make sure

00:09:23,839 --> 00:09:27,760
everything is

00:09:24,720 --> 00:09:30,160
is working as intended

00:09:27,760 --> 00:09:31,200
so now we can focus on reaching a

00:09:30,160 --> 00:09:33,839
million order

00:09:31,200 --> 00:09:35,440
and growing our business further without

00:09:33,839 --> 00:09:42,160
having to worry about

00:09:35,440 --> 00:09:42,160

YouTube URL: https://www.youtube.com/watch?v=fibzqwCz4ok


